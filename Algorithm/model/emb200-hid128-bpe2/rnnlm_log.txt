[epoch1, step1]: loss 1.397367
[epoch1, step2]: loss 1.391177
[epoch1, step3]: loss 1.385038
[epoch1, step4]: loss 1.378905
[epoch1, step5]: loss 1.372776
[epoch1, step6]: loss 1.366679
[epoch1, step7]: loss 1.360516
[epoch1, step8]: loss 1.354474
[epoch1, step9]: loss 1.348239
[epoch1, step10]: loss 1.342067
[epoch1, step11]: loss 1.335998
[epoch1, step12]: loss 1.329803
[epoch1, step13]: loss 1.323424
[epoch1, step14]: loss 1.317152
[epoch1, step15]: loss 1.310952
[epoch1, step16]: loss 1.304391
[epoch1, step17]: loss 1.298274
[epoch1, step18]: loss 1.291572
[epoch1, step19]: loss 1.284868
[epoch1, step20]: loss 1.278596
[epoch1, step21]: loss 1.271841
[epoch1, step22]: loss 1.264710
[epoch1, step23]: loss 1.257771
[epoch1, step24]: loss 1.251145
[epoch1, step25]: loss 1.243617
[epoch1, step26]: loss 1.236907
[epoch1, step27]: loss 1.229143
[epoch1, step28]: loss 1.221578
[epoch1, step29]: loss 1.214472
[epoch1, step30]: loss 1.206839
[epoch1, step31]: loss 1.198213
[epoch1, step32]: loss 1.190279
[epoch1, step33]: loss 1.182467
[epoch1, step34]: loss 1.173402
[epoch1, step35]: loss 1.165457
[epoch1, step36]: loss 1.155710
[epoch1, step37]: loss 1.146278
[epoch1, step38]: loss 1.137558
[epoch1, step39]: loss 1.127931
[epoch1, step40]: loss 1.117237
[epoch1, step41]: loss 1.106650
[epoch1, step42]: loss 1.096886
[epoch1, step43]: loss 1.084800
[epoch1, step44]: loss 1.074775
[epoch1, step45]: loss 1.061707
[epoch1, step46]: loss 1.049003
[epoch1, step47]: loss 1.037212
[epoch1, step48]: loss 1.024007
[epoch1, step49]: loss 1.008341
[epoch1, step50]: loss 0.994611
[epoch1, step51]: loss 0.980338
[epoch1, step52]: loss 0.963110
[epoch1, step53]: loss 0.948963
[epoch1, step54]: loss 0.929308
[epoch1, step55]: loss 0.910661
[epoch1, step56]: loss 0.893687
[epoch1, step57]: loss 0.873293
[epoch1, step58]: loss 0.849500
[epoch1, step59]: loss 0.826086
[epoch1, step60]: loss 0.804922
[epoch1, step61]: loss 0.775958
[epoch1, step62]: loss 0.752668
[epoch1, step63]: loss 0.720601
[epoch1, step64]: loss 0.689063
[epoch1, step65]: loss 0.661164
[epoch1, step66]: loss 0.627219
[epoch1, step67]: loss 0.587542
[epoch1, step68]: loss 0.549781
[epoch1, step69]: loss 0.514407
[epoch1, step70]: loss 0.469475
[epoch1, step71]: loss 0.436676
[epoch1, step72]: loss 0.392228
[epoch1, step73]: loss 0.352141
[epoch1, step74]: loss 0.325660
[epoch1, step75]: loss 0.294941
[epoch1, step76]: loss 0.261103
[epoch1, step77]: loss 0.236937
[epoch1, step78]: loss 0.220358
[epoch1, step79]: loss 0.193009
[epoch1, step80]: loss 0.190890
[epoch1, step81]: loss 0.167491
[epoch1, step82]: loss 0.152457
[epoch1, step83]: loss 0.150022
[epoch1, step84]: loss 0.145012
[epoch1, step85]: loss 0.131527
[epoch1, step86]: loss 0.124741
[epoch1, step87]: loss 0.127891
[epoch1, step88]: loss 0.110827
[epoch1, step89]: loss 0.119033
[epoch1, step90]: loss 0.109849
[epoch1, step91]: loss 0.102166
[epoch1, step92]: loss 0.109808
[epoch1, step93]: loss 0.107976
[epoch1, step94]: loss 0.098777
[epoch1, step95]: loss 0.099041
[epoch1, step96]: loss 0.101717
[epoch1, step97]: loss 0.095527
[epoch1, step98]: loss 0.102703
[epoch1, step99]: loss 0.094142
[epoch1, step100]: loss 0.088032
[epoch1, step101]: loss 0.099099
[epoch1, step102]: loss 0.097622
[epoch1, step103]: loss 0.089736
[epoch1, step104]: loss 0.089873
[epoch1, step105]: loss 0.095191
[epoch1, step106]: loss 0.087008
[epoch1, step107]: loss 0.096192
[epoch1, step108]: loss 0.088854
[epoch1, step109]: loss 0.084215
[epoch1, step110]: loss 0.094435
[epoch1, step111]: loss 0.092644
[epoch1, step112]: loss 0.086265
[epoch1, step113]: loss 0.087743
[epoch1, step114]: loss 0.090761
[epoch1, step115]: loss 0.083794
[epoch1, step116]: loss 0.094747
[epoch1, step117]: loss 0.085186
[epoch1, step118]: loss 0.083442
[epoch1, step119]: loss 0.091065
[epoch1, step120]: loss 0.090655
[epoch1, step121]: loss 0.082586
[epoch1, step122]: loss 0.083048
[epoch1, step123]: loss 0.089580
[epoch1, step124]: loss 0.082031
[epoch1, step125]: loss 0.091749
[epoch1, step126]: loss 0.082848
[epoch1, step127]: loss 0.079729
[epoch1, step128]: loss 0.087652
[epoch1, step129]: loss 0.087241
[epoch1, step130]: loss 0.081561
[epoch1, step131]: loss 0.079920
[epoch1, step132]: loss 0.087088
[epoch1, step133]: loss 0.079040
[epoch1, step134]: loss 0.087454
[epoch1, step135]: loss 0.082446
[epoch1, step136]: loss 0.080586
[epoch1, step137]: loss 0.085320
[epoch1, step138]: loss 0.086173
[epoch1, step139]: loss 0.079197
[epoch1, step140]: loss 0.080779
[epoch1, step141]: loss 0.085455
[epoch1, step142]: loss 0.077802
[epoch1, step143]: loss 0.086036
[epoch1, step144]: loss 0.080373
[epoch1, step145]: loss 0.076986
[epoch1, step146]: loss 0.084711
[epoch1, step147]: loss 0.087805
[epoch1, step148]: loss 0.077719
[epoch1, step149]: loss 0.077170
[epoch1, step150]: loss 0.082636
[epoch1, step151]: loss 0.076787
[epoch1, step152]: loss 0.085531
[epoch1, step153]: loss 0.078774
[epoch1, step154]: loss 0.074422
[epoch1, step155]: loss 0.083052
[epoch1, step156]: loss 0.082634
[epoch1, step157]: loss 0.077228
[epoch1, step158]: loss 0.077453
[epoch1, step159]: loss 0.082745
[epoch1, step160]: loss 0.076002
[epoch1, step161]: loss 0.085335
[epoch1, step162]: loss 0.077592
[epoch1, step163]: loss 0.073860
[epoch1, step164]: loss 0.082406
[epoch1, step165]: loss 0.082260
[epoch1, step166]: loss 0.076350
[epoch1, step167]: loss 0.074850
[epoch1, step168]: loss 0.082041
[epoch1, step169]: loss 0.073497
[epoch1, step170]: loss 0.083493
[epoch1, step171]: loss 0.076519
[epoch1, step172]: loss 0.073225
[epoch1, step173]: loss 0.081187
[epoch1, step174]: loss 0.080519
[epoch1, step175]: loss 0.076167
[epoch1, step176]: loss 0.075388
[epoch1, step177]: loss 0.080362
[epoch1, step178]: loss 0.073154
[epoch1, step179]: loss 0.079790
[epoch1, step180]: loss 0.075640
[epoch1, step181]: loss 0.072265
[epoch1, step182]: loss 0.079919
[epoch1, step183]: loss 0.081151
[epoch1, step184]: loss 0.075618
[epoch1, step185]: loss 0.074294
[epoch1, step186]: loss 0.078819
[epoch1, step187]: loss 0.072260
[epoch1, step188]: loss 0.079888
[epoch1, step189]: loss 0.073916
[epoch1, step190]: loss 0.070060
[epoch1, step191]: loss 0.077597
[epoch1, step192]: loss 0.079663
[epoch1, step193]: loss 0.068812
[epoch1, step194]: loss 0.071003
[epoch1, step195]: loss 0.078178
[epoch1, step196]: loss 0.071217
[epoch1, step197]: loss 0.079069
[epoch1, step198]: loss 0.071048
[epoch1, step199]: loss 0.070168
[epoch1, step200]: loss 0.078192
[epoch1, step201]: loss 0.078683
[epoch1, step202]: loss 0.071028
[epoch1, step203]: loss 0.071883
[epoch1, step204]: loss 0.077268
[epoch1, step205]: loss 0.068927
[epoch1, step206]: loss 0.077712
[epoch1, step207]: loss 0.071694
[epoch1, step208]: loss 0.070035
[epoch1, step209]: loss 0.076705
[epoch1, step210]: loss 0.078532
[epoch1, step211]: loss 0.071970
[epoch1, step212]: loss 0.071801
[epoch1, step213]: loss 0.075002
[epoch1, step214]: loss 0.068219
[epoch1, step215]: loss 0.077828
[epoch1, step216]: loss 0.071644
[epoch1, step217]: loss 0.066546
[epoch1, step218]: loss 0.075849
[epoch1, step219]: loss 0.075351
[epoch1, step220]: loss 0.070536
[epoch1, step221]: loss 0.070640
[epoch1, step222]: loss 0.074920
[epoch1, step223]: loss 0.068976
[epoch1, step224]: loss 0.075840
[epoch1, step225]: loss 0.070265
[epoch1, step226]: loss 0.067422
[epoch1, step227]: loss 0.072688
[epoch1, step228]: loss 0.076010
[epoch1, step229]: loss 0.067601
[epoch1, step230]: loss 0.069848
[epoch1, step231]: loss 0.074656
[epoch1, step232]: loss 0.066798
[epoch1, step233]: loss 0.074079
[epoch1, step234]: loss 0.068647
[epoch1, step235]: loss 0.067425
[epoch1, step236]: loss 0.073880
[epoch1, step237]: loss 0.074342
[epoch1, step238]: loss 0.067931
[epoch1, step239]: loss 0.067125
[epoch1, step240]: loss 0.072100
[epoch1, step241]: loss 0.067956
[epoch1, step242]: loss 0.074508
[epoch1, step243]: loss 0.070007
[epoch1, step244]: loss 0.065976
[epoch1, step245]: loss 0.072109
[epoch1, step246]: loss 0.073304
[epoch1, step247]: loss 0.068251
[epoch1, step248]: loss 0.067127
[epoch1, step249]: loss 0.071378
[epoch1, step250]: loss 0.066512
[epoch1, step251]: loss 0.075081
[epoch1, step252]: loss 0.069058
[epoch1, step253]: loss 0.064789
[epoch1, step254]: loss 0.070819
[epoch1, step255]: loss 0.072729
[epoch1, step256]: loss 0.066518
[epoch1, step257]: loss 0.066603
[epoch1, step258]: loss 0.072665
[epoch1, step259]: loss 0.065359
[epoch1, step260]: loss 0.072036
[epoch1, step261]: loss 0.068863
[epoch1, step262]: loss 0.065497
[epoch1, step263]: loss 0.069909
[epoch1, step264]: loss 0.071225
[epoch1, step265]: loss 0.066780
[epoch1, step266]: loss 0.066361
[epoch1, step267]: loss 0.069645
[epoch1, step268]: loss 0.064791
[epoch1, step269]: loss 0.072509
[epoch1, step270]: loss 0.065974
[epoch1, step271]: loss 0.064218
[epoch1, step272]: loss 0.070630
[epoch1, step273]: loss 0.070617
[epoch1, step274]: loss 0.066573
[epoch1, step275]: loss 0.064943
[epoch1, step276]: loss 0.069259
[epoch1, step277]: loss 0.065088
[epoch1, step278]: loss 0.072003
[epoch1, step279]: loss 0.065476
[epoch1, step280]: loss 0.063244
[epoch1, step281]: loss 0.069499
[epoch1, step282]: loss 0.071080
[epoch1, step283]: loss 0.064295
[epoch1, step284]: loss 0.064115
[epoch1, step285]: loss 0.070671
[epoch1, step286]: loss 0.062291
[epoch1, step287]: loss 0.071313
[epoch1, step288]: loss 0.064697
[epoch1, step289]: loss 0.064361
[epoch1, step290]: loss 0.069475
[epoch1, step291]: loss 0.070243
[epoch1, step292]: loss 0.062971
[epoch1, step293]: loss 0.063798
[epoch1, step294]: loss 0.067247
[epoch1, step295]: loss 0.062217
[epoch1, step296]: loss 0.071717
[epoch1, step297]: loss 0.064239
[epoch1, step298]: loss 0.063065
[epoch1, step299]: loss 0.067218
[epoch1, step300]: loss 0.069555
[epoch1, step301]: loss 0.063902
[epoch1, step302]: loss 0.064542
[epoch1, step303]: loss 0.068872
[epoch1, step304]: loss 0.061786
[epoch1, step305]: loss 0.069174
[epoch1, step306]: loss 0.064341
[epoch1, step307]: loss 0.060890
[epoch1, step308]: loss 0.068976
[epoch1, step309]: loss 0.068948
[epoch1, step310]: loss 0.063578
[epoch1, step311]: loss 0.064001
[epoch1, step312]: loss 0.067029
[epoch1, step313]: loss 0.062704
[epoch1, step314]: loss 0.069078
[epoch1, step315]: loss 0.065382
[epoch1, step316]: loss 0.060874
[epoch1, step317]: loss 0.067761
[epoch1, step318]: loss 0.068102
[epoch1, step319]: loss 0.061975
[epoch1, step320]: loss 0.061072
[epoch1, step321]: loss 0.066245
[epoch1, step322]: loss 0.061200
[epoch1, step323]: loss 0.067430
[epoch1, step324]: loss 0.064225
[epoch1, step325]: loss 0.061024
[epoch1, step326]: loss 0.066443
[epoch1, step327]: loss 0.066307
[epoch1, step328]: loss 0.062568
[epoch1, step329]: loss 0.061830
[epoch1, step330]: loss 0.065813
[epoch1, step331]: loss 0.061118
[epoch1, step332]: loss 0.066950
[epoch1, step333]: loss 0.062554
[epoch1, step334]: loss 0.060054
[epoch1, step335]: loss 0.066547
[epoch1, step336]: loss 0.068306
[epoch1, step337]: loss 0.062068
[epoch1, step338]: loss 0.060960
[epoch1, step339]: loss 0.065295
[epoch1, step340]: loss 0.061041
[epoch1, step341]: loss 0.066579
[epoch1, step342]: loss 0.061575
[epoch1, step343]: loss 0.060071
[epoch1, step344]: loss 0.065095
[epoch1, step345]: loss 0.065155
[epoch1, step346]: loss 0.060386
[epoch1, step347]: loss 0.060700
[epoch1, step348]: loss 0.065397
[epoch1, step349]: loss 0.060714
[epoch1, step350]: loss 0.065981
[epoch1, step351]: loss 0.060392
[epoch1, step352]: loss 0.059106
[epoch1, step353]: loss 0.064852
[epoch1, step354]: loss 0.064089
[epoch1, step355]: loss 0.059139
[epoch1, step356]: loss 0.061832
[epoch1, step357]: loss 0.064763
[epoch1, step358]: loss 0.057340
[epoch1, step359]: loss 0.067743
[epoch1, step360]: loss 0.059316
[epoch1, step361]: loss 0.057706
[epoch1, step362]: loss 0.065562
[epoch1, step363]: loss 0.064842
[epoch1, step364]: loss 0.060003
[epoch1, step365]: loss 0.059793
[epoch1, step366]: loss 0.064865
[epoch1, step367]: loss 0.058956
[epoch1, step368]: loss 0.064810
[epoch1, step369]: loss 0.060425
[epoch1, step370]: loss 0.059311
[epoch1, step371]: loss 0.065528
[epoch1, step372]: loss 0.064077
[epoch1, step373]: loss 0.058938
[epoch1, step374]: loss 0.058540
[epoch1, step375]: loss 0.064578
[epoch1, step376]: loss 0.058541
[epoch1, step377]: loss 0.065564
[epoch1, step378]: loss 0.060828
[epoch1, step379]: loss 0.058859
[epoch1, step380]: loss 0.064582
[epoch1, step381]: loss 0.063732
[epoch1, step382]: loss 0.059852
[epoch1, step383]: loss 0.057842
[epoch1, step384]: loss 0.062278
[epoch1, step385]: loss 0.058113
[epoch1, step386]: loss 0.065088
[epoch1, step387]: loss 0.059910
[epoch1, step388]: loss 0.058658
[epoch1, step389]: loss 0.063347
[epoch1, step390]: loss 0.065040
[epoch1, step391]: loss 0.058359
[epoch1, step392]: loss 0.059764
[epoch1, step393]: loss 0.061863
[epoch1, step394]: loss 0.057777
[epoch1, step395]: loss 0.063953
[epoch1, step396]: loss 0.059528
[epoch1, step397]: loss 0.056614
[epoch1, step398]: loss 0.063057
[epoch1, step399]: loss 0.063166
[epoch1, step400]: loss 0.058087
[epoch1, step401]: loss 0.058156
[epoch1, step402]: loss 0.061773
[epoch1, step403]: loss 0.057266
[epoch1, step404]: loss 0.064369
[epoch1, step405]: loss 0.059269
[epoch1, step406]: loss 0.057120
[epoch1, step407]: loss 0.061978
[epoch1, step408]: loss 0.062932
[epoch1, step409]: loss 0.060073
[epoch1, step410]: loss 0.059084
[epoch1, step411]: loss 0.061707
[epoch1, step412]: loss 0.056161
[epoch1, step413]: loss 0.063307
[epoch1, step414]: loss 0.057970
[epoch1, step415]: loss 0.056875
[epoch1, step416]: loss 0.061028
[epoch1, step417]: loss 0.062841
[epoch1, step418]: loss 0.057497
[epoch1, step419]: loss 0.056521
[epoch1, step420]: loss 0.061873
[epoch1, step421]: loss 0.056090
[epoch1, step422]: loss 0.062955
[epoch1, step423]: loss 0.058322
[epoch1, step424]: loss 0.056310
[epoch1, step425]: loss 0.061855
[epoch1, step426]: loss 0.062618
[epoch1, step427]: loss 0.057754
[epoch1, step428]: loss 0.057092
[epoch1, step429]: loss 0.062180
[epoch1, step430]: loss 0.055983
[epoch1, step431]: loss 0.063197
[epoch1, step432]: loss 0.057678
[epoch1, step433]: loss 0.056742
[epoch1, step434]: loss 0.061145
[epoch1, step435]: loss 0.062343
[epoch1, step436]: loss 0.056369
[epoch1, step437]: loss 0.057352
[epoch1, step438]: loss 0.061591
[epoch1, step439]: loss 0.056278
[epoch1, step440]: loss 0.062146
[epoch1, step441]: loss 0.057996
[epoch1, step442]: loss 0.055218
[epoch1, step443]: loss 0.061552
[epoch1, step444]: loss 0.061028
[epoch1, step445]: loss 0.057415
[epoch1, step446]: loss 0.057375
[epoch1, step447]: loss 0.061685
[epoch1, step448]: loss 0.055823
[epoch1, step449]: loss 0.061660
[epoch1, step450]: loss 0.056033
[epoch1, step451]: loss 0.054627
[epoch1, step452]: loss 0.058637
[epoch1, step453]: loss 0.061178
[epoch1, step454]: loss 0.056157
[epoch1, step455]: loss 0.056534
[epoch1, step456]: loss 0.058525
[epoch1, step457]: loss 0.056248
[epoch1, step458]: loss 0.061021
[epoch1, step459]: loss 0.057770
[epoch1, step460]: loss 0.054883
[epoch1, step461]: loss 0.061237
[epoch1, step462]: loss 0.059599
[epoch1, step463]: loss 0.056329
[epoch1, step464]: loss 0.055825
[epoch1, step465]: loss 0.061576
[epoch1, step466]: loss 0.054677
[epoch1, step467]: loss 0.060628
[epoch1, step468]: loss 0.056329
[epoch1, step469]: loss 0.054539
[epoch1, step470]: loss 0.060167
[epoch1, step471]: loss 0.059495
[epoch1, step472]: loss 0.056282
[epoch1, step473]: loss 0.055021
[epoch1, step474]: loss 0.059280
[epoch1, step475]: loss 0.054826
[epoch1, step476]: loss 0.061518
[epoch1, step477]: loss 0.055919
[epoch1, step478]: loss 0.053398
[epoch1, step479]: loss 0.059105
[epoch1, step480]: loss 0.058404
[epoch1, step481]: loss 0.054563
[epoch1, step482]: loss 0.054379
[epoch1, step483]: loss 0.059569
[epoch1, step484]: loss 0.054607
[epoch1, step485]: loss 0.060648
[epoch1, step486]: loss 0.056399
[epoch1, step487]: loss 0.052783
[epoch1, step488]: loss 0.059597
[epoch1, step489]: loss 0.058455
[epoch1, step490]: loss 0.055527
[epoch1, step491]: loss 0.055171
[epoch1, step492]: loss 0.058074
[epoch1, step493]: loss 0.053447
[epoch1, step494]: loss 0.059109
[epoch1, step495]: loss 0.057193
[epoch1, step496]: loss 0.053409
[epoch1, step497]: loss 0.058731
[epoch1, step498]: loss 0.058658
[epoch1, step499]: loss 0.055121
[epoch1, step500]: loss 0.054053
[epoch1, step501]: loss 0.057545
[epoch1, step502]: loss 0.053404
[epoch1, step503]: loss 0.059922
[epoch1, step504]: loss 0.054787
[epoch1, step505]: loss 0.052024
[epoch1, step506]: loss 0.058911
[epoch1, step507]: loss 0.058978
[epoch1, step508]: loss 0.055179
[epoch1, step509]: loss 0.054238
[epoch1, step510]: loss 0.058056
[epoch1, step511]: loss 0.053747
[epoch1, step512]: loss 0.059770
[epoch1, step513]: loss 0.055011
[epoch1, step514]: loss 0.053240
[epoch1, step515]: loss 0.057946
[epoch1, step516]: loss 0.059003
[epoch1, step517]: loss 0.054040
[epoch1, step518]: loss 0.054144
[epoch1, step519]: loss 0.057464
[epoch1, step520]: loss 0.052272
[epoch1, step521]: loss 0.058309
[epoch1, step522]: loss 0.053567
[epoch1, step523]: loss 0.052465
[epoch1, step524]: loss 0.056646
[epoch1, step525]: loss 0.058452
[epoch1, step526]: loss 0.053919
[epoch1, step527]: loss 0.053313
[epoch1, step528]: loss 0.057456
[epoch1, step529]: loss 0.051907
[epoch1, step530]: loss 0.059108
[epoch1, step531]: loss 0.053930
[epoch1, step532]: loss 0.051463
[epoch1, step533]: loss 0.058657
[epoch1, step534]: loss 0.057550
[epoch1, step535]: loss 0.053929
[epoch1, step536]: loss 0.053505
[epoch1, step537]: loss 0.056790
[epoch1, step538]: loss 0.052468
[epoch1, step539]: loss 0.057814
[epoch1, step540]: loss 0.053200
[epoch1, step541]: loss 0.051098
[epoch1, step542]: loss 0.056823
[epoch1, step543]: loss 0.056713
[epoch1, step544]: loss 0.052881
[epoch1, step545]: loss 0.051860
[epoch1, step546]: loss 0.057164
[epoch1, step547]: loss 0.051461
[epoch1, step548]: loss 0.057542
[epoch1, step549]: loss 0.053790
[epoch1, step550]: loss 0.051397
[epoch1, step551]: loss 0.056257
[epoch1, step552]: loss 0.055981
[epoch1, step553]: loss 0.053255
[epoch1, step554]: loss 0.052301
[epoch1, step555]: loss 0.055571
[epoch1, step556]: loss 0.051406
[epoch1, step557]: loss 0.056413
[epoch1, step558]: loss 0.053305
[epoch1, step559]: loss 0.050140
[epoch1, step560]: loss 0.055938
[epoch1, step561]: loss 0.056082
[epoch1, step562]: loss 0.052146
[epoch1, step563]: loss 0.036147
[epoch1, step564]: loss 0.032233
[epoch1, step565]: loss 0.030913
[epoch1, step566]: loss 0.038724
[epoch1, step567]: loss 0.030242
[epoch1, step568]: loss 0.030293
[epoch1, step569]: loss 0.027050
[epoch1, step570]: loss 0.037691
[epoch1, step571]: loss 0.032888
[epoch1, step572]: loss 0.031013
[epoch1, step573]: loss 0.035028
[epoch1, step574]: loss 0.032984
[epoch1, step575]: loss 0.024325
[epoch1, step576]: loss 0.025580
[epoch1, step577]: loss 0.031364
[epoch1, step578]: loss 0.022397
[epoch1, step579]: loss 0.034387
[epoch1, step580]: loss 0.024097
[epoch1, step581]: loss 0.031205
[epoch1, step582]: loss 0.030756
[epoch1, step583]: loss 0.026046
[epoch1, step584]: loss 0.028583
[epoch1, step585]: loss 0.031731
[epoch1, step586]: loss 0.026060
[epoch1, step587]: loss 0.033877
[epoch1, step588]: loss 0.027660
[epoch1, step589]: loss 0.027653
[epoch1, step590]: loss 0.034017
[epoch1, step591]: loss 0.024818
[epoch1, step592]: loss 0.031500
[epoch1, step593]: loss 0.027103
[epoch1, step594]: loss 0.031429
[epoch1, step595]: loss 0.032511
[epoch1, step596]: loss 0.026979
[epoch1, step597]: loss 0.030418
[epoch1, step598]: loss 0.032240
[epoch1, step599]: loss 0.030619
[epoch1, step600]: loss 0.033584
[epoch1, step601]: loss 0.022952
[epoch1, step602]: loss 0.026993
[epoch1, step603]: loss 0.031641
[epoch1, step604]: loss 0.032245
[epoch1, step605]: loss 0.030498
[epoch1, step606]: loss 0.029761
[epoch1, step607]: loss 0.033944
[epoch1, step608]: loss 0.031342
[epoch1, step609]: loss 0.032641
[epoch1, step610]: loss 0.030654
[epoch1, step611]: loss 0.031868
[epoch1, step612]: loss 0.031383
[epoch1, step613]: loss 0.022930
[epoch1, step614]: loss 0.030671
[epoch1, step615]: loss 0.034527
[epoch1, step616]: loss 0.028910
[epoch1, step617]: loss 0.028422
[epoch1, step618]: loss 0.031092
[epoch1, step619]: loss 0.031987
[epoch1, step620]: loss 0.029396
[epoch1, step621]: loss 0.031598
[epoch1, step622]: loss 0.024409
[epoch1, step623]: loss 0.029534
[epoch1, step624]: loss 0.031809
[epoch1, step625]: loss 0.031825
[epoch1, step626]: loss 0.034537
[epoch1, step627]: loss 0.027547
[epoch1, step628]: loss 0.031821
[epoch1, step629]: loss 0.024755
[epoch1, step630]: loss 0.027988
[epoch1, step631]: loss 0.037646
[epoch1, step632]: loss 0.028266
[epoch1, step633]: loss 0.029678
[epoch1, step634]: loss 0.032179
[epoch1, step635]: loss 0.030872
[epoch1, step636]: loss 0.024285
[epoch1, step637]: loss 0.033028
[epoch1, step638]: loss 0.032694
[epoch1, step639]: loss 0.027428
[epoch1, step640]: loss 0.035207
[epoch1, step641]: loss 0.036698
[epoch1, step642]: loss 0.029859
[epoch1, step643]: loss 0.030845
[epoch1, step644]: loss 0.031544
[epoch1, step645]: loss 0.028270
[epoch1, step646]: loss 0.032120
[epoch1, step647]: loss 0.028385
[epoch1, step648]: loss 0.027750
[epoch1, step649]: loss 0.035007
[epoch1, step650]: loss 0.026589
[epoch1, step651]: loss 0.031369
[epoch1, step652]: loss 0.032484
[epoch1, step653]: loss 0.033848
[epoch1, step654]: loss 0.027819
[epoch1, step655]: loss 0.028855
[epoch1, step656]: loss 0.025437
[epoch1, step657]: loss 0.033800
[epoch1, step658]: loss 0.030384
[epoch1, step659]: loss 0.033273
[epoch1, step660]: loss 0.028088
[epoch1, step661]: loss 0.032455
[epoch1, step662]: loss 0.028293
[epoch1, step663]: loss 0.025303
[epoch1, step664]: loss 0.029844
[epoch1, step665]: loss 0.033624
[epoch1, step666]: loss 0.032467
[epoch1, step667]: loss 0.031837
[epoch1, step668]: loss 0.026803
[epoch1, step669]: loss 0.031266
[epoch1, step670]: loss 0.032330
[epoch1, step671]: loss 0.024535
[epoch1, step672]: loss 0.028267
[epoch1, step673]: loss 0.026261
[epoch1, step674]: loss 0.025055
[epoch1, step675]: loss 0.023491
[epoch1, step676]: loss 0.028990
[epoch1, step677]: loss 0.030403
[epoch1, step678]: loss 0.027739
[epoch1, step679]: loss 0.028216
[epoch1, step680]: loss 0.036789
[epoch1, step681]: loss 0.026146
[epoch1, step682]: loss 0.031046
[epoch1, step683]: loss 0.030685
[epoch1, step684]: loss 0.029816
[epoch1, step685]: loss 0.028203
[epoch1, step686]: loss 0.032939
[epoch1, step687]: loss 0.032176
[epoch1, step688]: loss 0.027307
[epoch1, step689]: loss 0.028748
[epoch1, step690]: loss 0.030086
[epoch1, step691]: loss 0.029022
[epoch1, step692]: loss 0.026887
[epoch1, step693]: loss 0.033316
[epoch1, step694]: loss 0.026994
[epoch1, step695]: loss 0.031812
[epoch1, step696]: loss 0.030779
[epoch1, step697]: loss 0.032583
[epoch1, step698]: loss 0.029575
[epoch1, step699]: loss 0.027497
[epoch1, step700]: loss 0.025646
[epoch1, step701]: loss 0.030837
[epoch1, step702]: loss 0.025570
[epoch1, step703]: loss 0.027393
[epoch1, step704]: loss 0.030835
[epoch1, step705]: loss 0.029197
[epoch1, step706]: loss 0.028382
[epoch1, step707]: loss 0.028393
[epoch1, step708]: loss 0.030921
[epoch1, step709]: loss 0.032585
[epoch1, step710]: loss 0.028572
[epoch1, step711]: loss 0.028225
[epoch1, step712]: loss 0.031521
[epoch1, step713]: loss 0.031524
[epoch1, step714]: loss 0.025109
[epoch1, step715]: loss 0.027162
[epoch1, step716]: loss 0.031061
[epoch1, step717]: loss 0.027810
[epoch1, step718]: loss 0.029188
[epoch1, step719]: loss 0.039509
[epoch1, step720]: loss 0.029457
[epoch1, step721]: loss 0.027376
[epoch1, step722]: loss 0.037448
[epoch1, step723]: loss 0.031625
[epoch1, step724]: loss 0.027112
[epoch1, step725]: loss 0.033901
[epoch1, step726]: loss 0.025908
[epoch1, step727]: loss 0.028562
[epoch1, step728]: loss 0.031225
[epoch1, step729]: loss 0.025034
[epoch1, step730]: loss 0.026464
[epoch1, step731]: loss 0.030987
[epoch1, step732]: loss 0.030323
[epoch1, step733]: loss 0.028100
[epoch1, step734]: loss 0.027202
[epoch1, step735]: loss 0.031941
[epoch1, step736]: loss 0.029221
[epoch1, step737]: loss 0.031119
[epoch1, step738]: loss 0.024111
[epoch1, step739]: loss 0.029800
[epoch1, step740]: loss 0.026660
[epoch1, step741]: loss 0.029427
[epoch1, step742]: loss 0.025858
[epoch1, step743]: loss 0.027292
[epoch1, step744]: loss 0.027872
[epoch1, step745]: loss 0.029204
[epoch1, step746]: loss 0.030044
[epoch1, step747]: loss 0.032607
[epoch1, step748]: loss 0.030174
[epoch1, step749]: loss 0.030905
[epoch1, step750]: loss 0.032738
[epoch1, step751]: loss 0.025105
[epoch1, step752]: loss 0.029140
[epoch1, step753]: loss 0.030183
[epoch1, step754]: loss 0.026508
[epoch1, step755]: loss 0.030889
[epoch1, step756]: loss 0.027151
[epoch1, step757]: loss 0.024045
[epoch1, step758]: loss 0.029209
[epoch1, step759]: loss 0.027107
[epoch1, step760]: loss 0.028313
[epoch1, step761]: loss 0.030542
[epoch1, step762]: loss 0.025037
[epoch1, step763]: loss 0.030106
[epoch1, step764]: loss 0.028352
[epoch1, step765]: loss 0.030541
[epoch1, step766]: loss 0.028823
[epoch1, step767]: loss 0.031724
[epoch1, step768]: loss 0.024782
[epoch1, step769]: loss 0.031394
[epoch1, step770]: loss 0.030757
[epoch1, step771]: loss 0.026745
[epoch1, step772]: loss 0.033871
[epoch1, step773]: loss 0.030607
[epoch1, step774]: loss 0.027300
[epoch1, step775]: loss 0.023860
[epoch1, step776]: loss 0.030394
[epoch1, step777]: loss 0.026151
[epoch1, step778]: loss 0.033441
[epoch1, step779]: loss 0.028058
[epoch1, step780]: loss 0.023044
[epoch1, step781]: loss 0.028567
[epoch1, step782]: loss 0.026119
[epoch1, step783]: loss 0.022438
[epoch1, step784]: loss 0.023565
[epoch1, step785]: loss 0.024235
[epoch1, step786]: loss 0.028160
[epoch1, step787]: loss 0.027240
[epoch1, step788]: loss 0.028524
[epoch1, step789]: loss 0.026206
[epoch1, step790]: loss 0.027018
[epoch1, step791]: loss 0.031031
[epoch1, step792]: loss 0.029010
[epoch1, step793]: loss 0.031636
[epoch1, step794]: loss 0.023381
[epoch1, step795]: loss 0.029861
[epoch1, step796]: loss 0.032363
[epoch1, step797]: loss 0.032697
[epoch1, step798]: loss 0.031506
[epoch1, step799]: loss 0.029417
[epoch1, step800]: loss 0.024879
[epoch1, step801]: loss 0.025162
[epoch1, step802]: loss 0.026355
[epoch1, step803]: loss 0.030224
[epoch1, step804]: loss 0.031994
[epoch1, step805]: loss 0.034004
[epoch1, step806]: loss 0.024691
[epoch1, step807]: loss 0.023592
[epoch1, step808]: loss 0.026528
[epoch1, step809]: loss 0.026395
[epoch1, step810]: loss 0.030051
[epoch1, step811]: loss 0.030018
[epoch1, step812]: loss 0.028563
[epoch1, step813]: loss 0.027478
[epoch1, step814]: loss 0.028983
[epoch1, step815]: loss 0.028637
[epoch1, step816]: loss 0.028222
[epoch1, step817]: loss 0.028667
[epoch1, step818]: loss 0.025675
[epoch1, step819]: loss 0.023515
[epoch1, step820]: loss 0.027215
[epoch1, step821]: loss 0.025046
[epoch1, step822]: loss 0.036211
[epoch1, step823]: loss 0.027648
[epoch1, step824]: loss 0.030749
[epoch1, step825]: loss 0.029295
[epoch1, step826]: loss 0.028053
[epoch1, step827]: loss 0.030803
[epoch1, step828]: loss 0.033366
[epoch1, step829]: loss 0.030107
[epoch1, step830]: loss 0.025895
[epoch1, step831]: loss 0.029938
[epoch1, step832]: loss 0.023769
[epoch1, step833]: loss 0.033853
[epoch1, step834]: loss 0.029815
[epoch1, step835]: loss 0.023470
[epoch1, step836]: loss 0.030958
[epoch1, step837]: loss 0.028963
[epoch1, step838]: loss 0.030020
[epoch1, step839]: loss 0.032857
[epoch1, step840]: loss 0.023209
[epoch1, step841]: loss 0.027592
[epoch1, step842]: loss 0.031979
[epoch1, step843]: loss 0.029260
[epoch1, step844]: loss 0.029160
[epoch1, step845]: loss 0.023939
[epoch1, step846]: loss 0.029387
[epoch1, step847]: loss 0.031207
[epoch1, step848]: loss 0.029172
[epoch1, step849]: loss 0.028819
[epoch1, step850]: loss 0.026607
[epoch1, step851]: loss 0.027440
[epoch1, step852]: loss 0.026007
[epoch1, step853]: loss 0.034088
[epoch1, step854]: loss 0.025274
[epoch1, step855]: loss 0.031075
[epoch1, step856]: loss 0.025206
[epoch1, step857]: loss 0.030033
[epoch1, step858]: loss 0.027521
[epoch1, step859]: loss 0.026639
[epoch1, step860]: loss 0.025469
[epoch1, step861]: loss 0.026439
[epoch1, step862]: loss 0.025914
[epoch1, step863]: loss 0.023117
[epoch1, step864]: loss 0.030390
[epoch1, step865]: loss 0.026471
[epoch1, step866]: loss 0.028454
[epoch1, step867]: loss 0.029750
[epoch1, step868]: loss 0.030411
[epoch1, step869]: loss 0.026561
[epoch1, step870]: loss 0.035425
[epoch1, step871]: loss 0.025051
[epoch1, step872]: loss 0.028945
[epoch1, step873]: loss 0.029272
[epoch1, step874]: loss 0.026522
[epoch1, step875]: loss 0.027556
[epoch1, step876]: loss 0.027708
[epoch1, step877]: loss 0.021321
[epoch1, step878]: loss 0.026375
[epoch1, step879]: loss 0.031820
[epoch1, step880]: loss 0.028835
[epoch1, step881]: loss 0.024849
[epoch1, step882]: loss 0.027734
[epoch1, step883]: loss 0.027476
[epoch1, step884]: loss 0.029789
[epoch1, step885]: loss 0.029240
[epoch1, step886]: loss 0.029740
[epoch1, step887]: loss 0.026771
[epoch1, step888]: loss 0.027823
[epoch1, step889]: loss 0.026853
[epoch1, step890]: loss 0.026624
[epoch1, step891]: loss 0.028604
[epoch1, step892]: loss 0.023516
[epoch1, step893]: loss 0.027177
[epoch1, step894]: loss 0.027540
[epoch1, step895]: loss 0.025510
[epoch1, step896]: loss 0.024653
[epoch1, step897]: loss 0.027255
[epoch1, step898]: loss 0.028965
[epoch1, step899]: loss 0.031817
[epoch1, step900]: loss 0.030591
[epoch1, step901]: loss 0.029043
[epoch1, step902]: loss 0.026889
[epoch1, step903]: loss 0.027700
[epoch1, step904]: loss 0.031962
[epoch1, step905]: loss 0.031550
[epoch1, step906]: loss 0.025000
[epoch1, step907]: loss 0.026025
[epoch1, step908]: loss 0.025318
[epoch1, step909]: loss 0.029037
[epoch1, step910]: loss 0.025871
[epoch1, step911]: loss 0.028319
[epoch1, step912]: loss 0.026485
[epoch1, step913]: loss 0.027374
[epoch1, step914]: loss 0.034763
[epoch1, step915]: loss 0.027044
[epoch1, step916]: loss 0.026261
[epoch1, step917]: loss 0.028063
[epoch1, step918]: loss 0.031760
[epoch1, step919]: loss 0.026865
[epoch1, step920]: loss 0.030455
[epoch1, step921]: loss 0.027353
[epoch1, step922]: loss 0.025936
[epoch1, step923]: loss 0.025469
[epoch1, step924]: loss 0.023637
[epoch1, step925]: loss 0.028552
[epoch1, step926]: loss 0.029742
[epoch1, step927]: loss 0.029020
[epoch1, step928]: loss 0.028030
[epoch1, step929]: loss 0.031067
[epoch1, step930]: loss 0.029001
[epoch1, step931]: loss 0.031157
[epoch1, step932]: loss 0.024221
[epoch1, step933]: loss 0.031885
[epoch1, step934]: loss 0.024636
[epoch1, step935]: loss 0.024873
[epoch1, step936]: loss 0.025224
[epoch1, step937]: loss 0.030921
[epoch1, step938]: loss 0.028203
[epoch1, step939]: loss 0.023048
[epoch1, step940]: loss 0.025604
[epoch1, step941]: loss 0.029837
[epoch1, step942]: loss 0.028485
[epoch1, step943]: loss 0.026154
[epoch1, step944]: loss 0.031084
[epoch1, step945]: loss 0.022335
[epoch1, step946]: loss 0.028528
[epoch1, step947]: loss 0.031205
[epoch1, step948]: loss 0.021835
[epoch1, step949]: loss 0.025178
[epoch1, step950]: loss 0.029160
[epoch1, step951]: loss 0.032251
[epoch1, step952]: loss 0.027882
[epoch1, step953]: loss 0.030719
[epoch1, step954]: loss 0.024770
[epoch1, step955]: loss 0.039846
[epoch1, step956]: loss 0.053516
[epoch1, step957]: loss 0.048083
[epoch1, step958]: loss 0.046670
[epoch1, step959]: loss 0.051761
[epoch1, step960]: loss 0.048572
[epoch1, step961]: loss 0.049987
[epoch1, step962]: loss 0.049191
[epoch1, step963]: loss 0.048226
[epoch1, step964]: loss 0.049393
[epoch1, step965]: loss 0.050991
[epoch1, step966]: loss 0.048040
[epoch1, step967]: loss 0.046921
[epoch1, step968]: loss 0.050757
[epoch1, step969]: loss 0.049702
[epoch1, step970]: loss 0.049396
[epoch1, step971]: loss 0.048497
[epoch1, step972]: loss 0.049048
[epoch1, step973]: loss 0.047928
[epoch1, step974]: loss 0.052068
[epoch1, step975]: loss 0.048025
[epoch1, step976]: loss 0.046268
[epoch1, step977]: loss 0.051089
[epoch1, step978]: loss 0.048785
[epoch1, step979]: loss 0.048639
[epoch1, step980]: loss 0.047413
[epoch1, step981]: loss 0.048025
[epoch1, step982]: loss 0.048385
[epoch1, step983]: loss 0.051184
[epoch1, step984]: loss 0.046506
[epoch1, step985]: loss 0.046565
[epoch1, step986]: loss 0.051258
[epoch1, step987]: loss 0.048939
[epoch1, step988]: loss 0.049297
[epoch1, step989]: loss 0.048488
[epoch1, step990]: loss 0.047610
[epoch1, step991]: loss 0.048615
[epoch1, step992]: loss 0.050312
[epoch1, step993]: loss 0.047146
[epoch1, step994]: loss 0.045567
[epoch1, step995]: loss 0.049978
[epoch1, step996]: loss 0.047521
[epoch1, step997]: loss 0.048344
[epoch1, step998]: loss 0.048024
[epoch1, step999]: loss 0.047447
[epoch1, step1000]: loss 0.047596
[epoch1, step1001]: loss 0.049965
[epoch1, step1002]: loss 0.046830
[epoch1, step1003]: loss 0.045559
[epoch1, step1004]: loss 0.049352
[epoch1, step1005]: loss 0.046449
[epoch1, step1006]: loss 0.047776
[epoch1, step1007]: loss 0.046486
[epoch1, step1008]: loss 0.046303
[epoch1, step1009]: loss 0.046999
[epoch1, step1010]: loss 0.050091
[epoch1, step1011]: loss 0.046123
[epoch1, step1012]: loss 0.045692
[epoch1, step1013]: loss 0.049165
[epoch1, step1014]: loss 0.047695
[epoch1, step1015]: loss 0.047916
[epoch1, step1016]: loss 0.046114
[epoch1, step1017]: loss 0.046027
[epoch1, step1018]: loss 0.046487
[epoch1, step1019]: loss 0.049391
[epoch1, step1020]: loss 0.045547
[epoch1, step1021]: loss 0.044634
[epoch1, step1022]: loss 0.048444
[epoch1, step1023]: loss 0.046663
[epoch1, step1024]: loss 0.047994
[epoch1, step1025]: loss 0.045695
[epoch1, step1026]: loss 0.045401
[epoch1, step1027]: loss 0.046076
[epoch1, step1028]: loss 0.048841
[epoch1, step1029]: loss 0.045459
[epoch1, step1030]: loss 0.044301
[epoch1, step1031]: loss 0.047029
[epoch1, step1032]: loss 0.046698
[epoch1, step1033]: loss 0.046548
[epoch1, step1034]: loss 0.045669
[epoch1, step1035]: loss 0.045338
[epoch1, step1036]: loss 0.046443
[epoch1, step1037]: loss 0.048355
[epoch1, step1038]: loss 0.045420
[epoch1, step1039]: loss 0.044856
[epoch1, step1040]: loss 0.047693
[epoch1, step1041]: loss 0.046131
[epoch1, step1042]: loss 0.045750
[epoch1, step1043]: loss 0.045685
[epoch1, step1044]: loss 0.045622
[epoch1, step1045]: loss 0.046154
[epoch1, step1046]: loss 0.048611
[epoch1, step1047]: loss 0.045494
[epoch1, step1048]: loss 0.044096
[epoch1, step1049]: loss 0.047967
[epoch1, step1050]: loss 0.046326
[epoch1, step1051]: loss 0.046629
[epoch1, step1052]: loss 0.045990
[epoch1, step1053]: loss 0.045924
[epoch1, step1054]: loss 0.045887
[epoch1, step1055]: loss 0.047547
[epoch1, step1056]: loss 0.044512
[epoch1, step1057]: loss 0.044891
[epoch1, step1058]: loss 0.048466
[epoch1, step1059]: loss 0.046082
[epoch1, step1060]: loss 0.046450
[epoch1, step1061]: loss 0.044647
[epoch1, step1062]: loss 0.045713
[epoch1, step1063]: loss 0.045724
[epoch1, step1064]: loss 0.048012
[epoch1, step1065]: loss 0.044820
[epoch1, step1066]: loss 0.043551
[epoch1, step1067]: loss 0.047466
[epoch1, step1068]: loss 0.044271
[epoch1, step1069]: loss 0.045459
[epoch1, step1070]: loss 0.045075
[epoch1, step1071]: loss 0.045650
[epoch1, step1072]: loss 0.046298
[epoch1, step1073]: loss 0.047569
[epoch1, step1074]: loss 0.044813
[epoch1, step1075]: loss 0.044186
[epoch1, step1076]: loss 0.047722
[epoch1, step1077]: loss 0.045735
[epoch1, step1078]: loss 0.046221
[epoch1, step1079]: loss 0.046470
[epoch1, step1080]: loss 0.045261
[epoch1, step1081]: loss 0.045443
[epoch1, step1082]: loss 0.047505
[epoch1, step1083]: loss 0.045455
[epoch1, step1084]: loss 0.044353
[epoch1, step1085]: loss 0.046853
[epoch1, step1086]: loss 0.045118
[epoch1, step1087]: loss 0.046414
[epoch1, step1088]: loss 0.044738
[epoch1, step1089]: loss 0.045402
[epoch1, step1090]: loss 0.045919
[epoch1, step1091]: loss 0.047927
[epoch1, step1092]: loss 0.044515
[epoch1, step1093]: loss 0.043578
[epoch1, step1094]: loss 0.046060
[epoch1, step1095]: loss 0.044870
[epoch1, step1096]: loss 0.045283
[epoch1, step1097]: loss 0.044774
[epoch1, step1098]: loss 0.044673
[epoch1, step1099]: loss 0.044864
[epoch1, step1100]: loss 0.048028
[epoch1, step1101]: loss 0.044868
[epoch1, step1102]: loss 0.043574
[epoch1, step1103]: loss 0.046499
[epoch1, step1104]: loss 0.044958
[epoch1, step1105]: loss 0.045833
[epoch1, step1106]: loss 0.043732
[epoch1, step1107]: loss 0.044846
[epoch1, step1108]: loss 0.044696
[epoch1, step1109]: loss 0.047661
[epoch1, step1110]: loss 0.045104
[epoch1, step1111]: loss 0.043741
[epoch1, step1112]: loss 0.047517
[epoch1, step1113]: loss 0.044647
[epoch1, step1114]: loss 0.045911
[epoch1, step1115]: loss 0.044691
[epoch1, step1116]: loss 0.044721
[epoch1, step1117]: loss 0.045361
[epoch1, step1118]: loss 0.047160
[epoch1, step1119]: loss 0.044170
[epoch1, step1120]: loss 0.043437
[epoch1, step1121]: loss 0.046625
[epoch1, step1122]: loss 0.044636
[epoch1, step1123]: loss 0.044689
[epoch1, step1124]: loss 0.045293
[epoch1, step1125]: loss 0.044975
[epoch1, step1126]: loss 0.045844
[epoch1, step1127]: loss 0.047290
[epoch1, step1128]: loss 0.044356
[epoch1, step1129]: loss 0.043366
[epoch1, step1130]: loss 0.047240
[epoch1, step1131]: loss 0.045194
[epoch1, step1132]: loss 0.045925
[epoch1, step1133]: loss 0.043977
[epoch1, step1134]: loss 0.044358
[epoch1, step1135]: loss 0.045804
[epoch1, step1136]: loss 0.047617
[epoch1, step1137]: loss 0.044276
[epoch1, step1138]: loss 0.043403
[epoch1, step1139]: loss 0.046586
[epoch1, step1140]: loss 0.044025
[epoch1, step1141]: loss 0.044971
[epoch1, step1142]: loss 0.044096
[epoch1, step1143]: loss 0.043911
[epoch1, step1144]: loss 0.044855
[epoch1, step1145]: loss 0.046372
[epoch1, step1146]: loss 0.043659
[epoch1, step1147]: loss 0.043939
[epoch1, step1148]: loss 0.046564
[epoch1, step1149]: loss 0.044348
[epoch1, step1150]: loss 0.044882
[epoch1, step1151]: loss 0.044457
[epoch1, step1152]: loss 0.044735
[epoch1, step1153]: loss 0.044043
[epoch1, step1154]: loss 0.047180
[epoch1, step1155]: loss 0.044066
[epoch1, step1156]: loss 0.042384
[epoch1, step1157]: loss 0.046606
[epoch1, step1158]: loss 0.044736
[epoch1, step1159]: loss 0.045296
[epoch1, step1160]: loss 0.045073
[epoch1, step1161]: loss 0.044656
[epoch1, step1162]: loss 0.044700
[epoch1, step1163]: loss 0.046066
[epoch1, step1164]: loss 0.043739
[epoch1, step1165]: loss 0.044217
[epoch1, step1166]: loss 0.046295
[epoch1, step1167]: loss 0.043790
[epoch1, step1168]: loss 0.045106
[epoch1, step1169]: loss 0.043812
[epoch1, step1170]: loss 0.044262
[epoch1, step1171]: loss 0.044282
[epoch1, step1172]: loss 0.046725
[epoch1, step1173]: loss 0.043813
[epoch1, step1174]: loss 0.043356
[epoch1, step1175]: loss 0.046022
[epoch1, step1176]: loss 0.044008
[epoch1, step1177]: loss 0.045196
[epoch1, step1178]: loss 0.044086
[epoch1, step1179]: loss 0.043777
[epoch1, step1180]: loss 0.044487
[epoch1, step1181]: loss 0.047117
[epoch1, step1182]: loss 0.042983
[epoch1, step1183]: loss 0.043362
[epoch1, step1184]: loss 0.045550
[epoch1, step1185]: loss 0.044330
[epoch1, step1186]: loss 0.044047
[epoch1, step1187]: loss 0.043077
[epoch1, step1188]: loss 0.043314
[epoch1, step1189]: loss 0.044018
[epoch1, step1190]: loss 0.046017
[epoch1, step1191]: loss 0.044258
[epoch1, step1192]: loss 0.042790
[epoch1, step1193]: loss 0.045897
[epoch1, step1194]: loss 0.043966
[epoch1, step1195]: loss 0.043605
[epoch1, step1196]: loss 0.043115
[epoch1, step1197]: loss 0.044130
[epoch1, step1198]: loss 0.044401
[epoch1, step1199]: loss 0.045936
[epoch1, step1200]: loss 0.043329
[epoch1, step1201]: loss 0.043301
[epoch1, step1202]: loss 0.046664
[epoch1, step1203]: loss 0.044399
[epoch1, step1204]: loss 0.043966
[epoch1, step1205]: loss 0.043321
[epoch1, step1206]: loss 0.043459
[epoch1, step1207]: loss 0.044316
[epoch1, step1208]: loss 0.046513
[epoch1, step1209]: loss 0.042275
[epoch1, step1210]: loss 0.043216
[epoch1, step1211]: loss 0.045254
[epoch1, step1212]: loss 0.043770
[epoch1, step1213]: loss 0.044182
[epoch1, step1214]: loss 0.043792
[epoch1, step1215]: loss 0.044346
[epoch1, step1216]: loss 0.043696
[epoch1, step1217]: loss 0.046732
[epoch1, step1218]: loss 0.042972
[epoch1, step1219]: loss 0.043259
[epoch1, step1220]: loss 0.045951
[epoch1, step1221]: loss 0.043118
[epoch1, step1222]: loss 0.044533
[epoch1, step1223]: loss 0.043424
[epoch1, step1224]: loss 0.044018
[epoch1, step1225]: loss 0.044008
[epoch1, step1226]: loss 0.045767
[epoch1, step1227]: loss 0.043219
[epoch1, step1228]: loss 0.042194
[epoch1, step1229]: loss 0.045401
[epoch1, step1230]: loss 0.044065
[epoch1, step1231]: loss 0.044188
[epoch1, step1232]: loss 0.044551
[epoch1, step1233]: loss 0.043494
[epoch1, step1234]: loss 0.043872
[epoch1, step1235]: loss 0.046601
[epoch1, step1236]: loss 0.043585
[epoch1, step1237]: loss 0.042267
[epoch1, step1238]: loss 0.045050
[epoch1, step1239]: loss 0.044313
[epoch1, step1240]: loss 0.044645
[epoch1, step1241]: loss 0.043183
[epoch1, step1242]: loss 0.043529
[epoch1, step1243]: loss 0.043803
[epoch1, step1244]: loss 0.046155
[epoch1, step1245]: loss 0.043486
[epoch1, step1246]: loss 0.042851
[epoch1, step1247]: loss 0.044643
[epoch1, step1248]: loss 0.043983
[epoch1, step1249]: loss 0.044630
[epoch1, step1250]: loss 0.043396
[epoch1, step1251]: loss 0.043672
[epoch1, step1252]: loss 0.044663
[epoch1, step1253]: loss 0.046165
[epoch1, step1254]: loss 0.043161
[epoch1, step1255]: loss 0.042698
[epoch1, step1256]: loss 0.045830
[epoch1, step1257]: loss 0.043882
[epoch1, step1258]: loss 0.044419
[epoch1, step1259]: loss 0.043046
[epoch1, step1260]: loss 0.043623
[epoch1, step1261]: loss 0.043569
[epoch1, step1262]: loss 0.044744
[epoch1, step1263]: loss 0.043578
[epoch1, step1264]: loss 0.042310
[epoch1, step1265]: loss 0.044203
[epoch1, step1266]: loss 0.043566
[epoch1, step1267]: loss 0.044189
[epoch1, step1268]: loss 0.043453
[epoch1, step1269]: loss 0.043496
[epoch1, step1270]: loss 0.043107
[epoch1, step1271]: loss 0.046200
[epoch1, step1272]: loss 0.043087
[epoch1, step1273]: loss 0.042204
[epoch1, step1274]: loss 0.045064
[epoch1, step1275]: loss 0.044021
[epoch1, step1276]: loss 0.043758
[epoch1, step1277]: loss 0.043232
[epoch1, step1278]: loss 0.043917
[epoch1, step1279]: loss 0.043876
[epoch1, step1280]: loss 0.045973
[epoch1, step1281]: loss 0.042913
[epoch1, step1282]: loss 0.042124
[epoch1, step1283]: loss 0.044687
[epoch1, step1284]: loss 0.043104
[epoch1, step1285]: loss 0.044437
[epoch1, step1286]: loss 0.042592
[epoch1, step1287]: loss 0.043904
[epoch1, step1288]: loss 0.044376
[epoch1, step1289]: loss 0.046488
[epoch1, step1290]: loss 0.043048
[epoch1, step1291]: loss 0.042088
[epoch1, step1292]: loss 0.045520
[epoch1, step1293]: loss 0.042846
[epoch1, step1294]: loss 0.043882
[epoch1, step1295]: loss 0.043585
[epoch1, step1296]: loss 0.043488
[epoch1, step1297]: loss 0.043219
[epoch1, step1298]: loss 0.046207
[epoch1, step1299]: loss 0.043038
[epoch1, step1300]: loss 0.042951
[epoch1, step1301]: loss 0.044337
[epoch1, step1302]: loss 0.043453
[epoch1, step1303]: loss 0.044196
[epoch1, step1304]: loss 0.042569
[epoch1, step1305]: loss 0.043480
[epoch1, step1306]: loss 0.043272
[epoch1, step1307]: loss 0.045055
[epoch1, step1308]: loss 0.042979
[epoch1, step1309]: loss 0.041525
[epoch1, step1310]: loss 0.044937
[epoch1, step1311]: loss 0.042444
[epoch1, step1312]: loss 0.044492
[epoch1, step1313]: loss 0.043099
[epoch1, step1314]: loss 0.043128
[epoch1, step1315]: loss 0.043159
[epoch1, step1316]: loss 0.046826
[epoch1, step1317]: loss 0.042267
[epoch1, step1318]: loss 0.041734
[epoch1, step1319]: loss 0.044469
[epoch1, step1320]: loss 0.043511
[epoch1, step1321]: loss 0.044204
[epoch1, step1322]: loss 0.042763
[epoch1, step1323]: loss 0.043423
[epoch1, step1324]: loss 0.043100
[epoch1, step1325]: loss 0.045382
[epoch1, step1326]: loss 0.042551
[epoch1, step1327]: loss 0.041925
[epoch1, step1328]: loss 0.044977
[epoch1, step1329]: loss 0.043245
[epoch1, step1330]: loss 0.043967
[epoch1, step1331]: loss 0.042830
[epoch1, step1332]: loss 0.043033
[epoch1, step1333]: loss 0.042526
[epoch1, step1334]: loss 0.045720
[epoch1, step1335]: loss 0.043223
[epoch1, step1336]: loss 0.042005
[epoch1, step1337]: loss 0.044331
[epoch1, step1338]: loss 0.043089
[epoch1, step1339]: loss 0.043806
[epoch1, step1340]: loss 0.042595
[epoch1, step1341]: loss 0.043281
[epoch1, step1342]: loss 0.043099
[epoch1, step1343]: loss 0.045587
[epoch1, step1344]: loss 0.042760
[epoch1, step1345]: loss 0.041948
[epoch1, step1346]: loss 0.044471
[epoch1, step1347]: loss 0.043752
[epoch1, step1348]: loss 0.043232
[epoch1, step1349]: loss 0.042932
[epoch1, step1350]: loss 0.042950
[epoch1, step1351]: loss 0.042769
[epoch1, step1352]: loss 0.044719
[epoch1, step1353]: loss 0.042296
[epoch1, step1354]: loss 0.041640
[epoch1, step1355]: loss 0.044818
[epoch1, step1356]: loss 0.042720
[epoch1, step1357]: loss 0.043069
[epoch1, step1358]: loss 0.042575
[epoch1, step1359]: loss 0.042562
[epoch1, step1360]: loss 0.043264
[epoch1, step1361]: loss 0.045564
[epoch1, step1362]: loss 0.043075
[epoch1, step1363]: loss 0.042288
[epoch1, step1364]: loss 0.044604
[epoch1, step1365]: loss 0.043071
[epoch1, step1366]: loss 0.043416
[epoch1, step1367]: loss 0.042054
[epoch1, step1368]: loss 0.043597
[epoch1, step1369]: loss 0.043251
[epoch1, step1370]: loss 0.044989
[epoch1, step1371]: loss 0.042727
[epoch1, step1372]: loss 0.041658
[epoch1, step1373]: loss 0.044613
[epoch1, step1374]: loss 0.043767
[epoch1, step1375]: loss 0.044215
[epoch1, step1376]: loss 0.042614
[epoch1, step1377]: loss 0.042151
[epoch1, step1378]: loss 0.043281
[epoch1, step1379]: loss 0.044827
[epoch1, step1380]: loss 0.042744
[epoch1, step1381]: loss 0.041857
[epoch1, step1382]: loss 0.044861
[epoch1, step1383]: loss 0.042844
[epoch1, step1384]: loss 0.043418
[epoch1, step1385]: loss 0.042130
[epoch1, step1386]: loss 0.043077
[epoch1, step1387]: loss 0.043449
[epoch1, step1388]: loss 0.044255
[epoch1, step1389]: loss 0.041756
[epoch1, step1390]: loss 0.041848
[epoch1, step1391]: loss 0.044341
[epoch1, step1392]: loss 0.042767
[epoch1, step1393]: loss 0.043728
[epoch1, step1394]: loss 0.043079
[epoch1, step1395]: loss 0.042940
[epoch1, step1396]: loss 0.042669
[epoch1, step1397]: loss 0.044819
[epoch1, step1398]: loss 0.042274
[epoch1, step1399]: loss 0.042470
[epoch1, step1400]: loss 0.044935
[epoch1, step1401]: loss 0.042775
[epoch1, step1402]: loss 0.043492
[epoch1, step1403]: loss 0.041683
[epoch1, step1404]: loss 0.042318
[epoch1, step1405]: loss 0.042876
[epoch1, step1406]: loss 0.044758
[epoch1, step1407]: loss 0.043275
[epoch1, step1408]: loss 0.041212
[epoch1, step1409]: loss 0.044068
[epoch1, step1410]: loss 0.042941
[epoch1, step1411]: loss 0.042449
[epoch1, step1412]: loss 0.042677
[epoch1, step1413]: loss 0.042802
[epoch1, step1414]: loss 0.042649
[epoch1, step1415]: loss 0.044651
[epoch1, step1416]: loss 0.042197
[epoch1, step1417]: loss 0.041662
[epoch1, step1418]: loss 0.044337
[epoch1, step1419]: loss 0.043493
[epoch1, step1420]: loss 0.043594
[epoch1, step1421]: loss 0.042888
[epoch1, step1422]: loss 0.042745
[epoch1, step1423]: loss 0.042535
[epoch1, step1424]: loss 0.045179
[epoch1, step1425]: loss 0.041383
[epoch1, step1426]: loss 0.041795
[epoch1, step1427]: loss 0.044997
[epoch1, step1428]: loss 0.043536
[epoch1, step1429]: loss 0.043374
[epoch1, step1430]: loss 0.042521
[epoch1, step1431]: loss 0.042836
[epoch1, step1432]: loss 0.042610
[epoch1, step1433]: loss 0.045159
[epoch1, step1434]: loss 0.041668
[epoch1, step1435]: loss 0.042074
[epoch1, step1436]: loss 0.044700
[epoch1, step1437]: loss 0.042957
[epoch1, step1438]: loss 0.043758
[epoch1, step1439]: loss 0.042301
[epoch1, step1440]: loss 0.042370
[epoch1, step1441]: loss 0.043382
[epoch1, step1442]: loss 0.044247
[epoch1, step1443]: loss 0.041887
[epoch1, step1444]: loss 0.040940
[epoch1, step1445]: loss 0.044709
[epoch1, step1446]: loss 0.042946
[epoch1, step1447]: loss 0.043864
[epoch1, step1448]: loss 0.042302
[epoch1, step1449]: loss 0.042006
[epoch1, step1450]: loss 0.042904
[epoch1, step1451]: loss 0.045021
[epoch1, step1452]: loss 0.041921
[epoch1, step1453]: loss 0.042498
[epoch1, step1454]: loss 0.044631
[epoch1, step1455]: loss 0.043376
[epoch1, step1456]: loss 0.042922
[epoch1, step1457]: loss 0.042913
[epoch1, step1458]: loss 0.042610
[epoch1, step1459]: loss 0.042742
[epoch1, step1460]: loss 0.045328
[epoch1, step1461]: loss 0.042644
[epoch1, step1462]: loss 0.042053
[epoch1, step1463]: loss 0.044218
[epoch1, step1464]: loss 0.043063
[epoch1, step1465]: loss 0.042775
[epoch1, step1466]: loss 0.042028
[epoch1, step1467]: loss 0.042468
[epoch1, step1468]: loss 0.042241
[epoch1, step1469]: loss 0.044826
[epoch1, step1470]: loss 0.042112
[epoch1, step1471]: loss 0.041332
[epoch1, step1472]: loss 0.043987
[epoch1, step1473]: loss 0.042700
[epoch1, step1474]: loss 0.043722
[epoch1, step1475]: loss 0.041969
[epoch1, step1476]: loss 0.043268
[epoch1, step1477]: loss 0.042438
[epoch1, step1478]: loss 0.044940
[epoch1, step1479]: loss 0.041930
[epoch1, step1480]: loss 0.041477
[epoch1, step1481]: loss 0.043320
[epoch1, step1482]: loss 0.042661
[epoch1, step1483]: loss 0.043278
[epoch1, step1484]: loss 0.042605
[epoch1, step1485]: loss 0.042117
[epoch1, step1486]: loss 0.041684
[epoch1, step1487]: loss 0.044561
[epoch1, step1488]: loss 0.042066
[epoch1, step1489]: loss 0.041280
[epoch1, step1490]: loss 0.044108
[epoch1, step1491]: loss 0.042697
[epoch1, step1492]: loss 0.042944
[epoch1, step1493]: loss 0.042273
[epoch1, step1494]: loss 0.042594
[epoch1, step1495]: loss 0.042301
[epoch1, step1496]: loss 0.043921
[epoch1, step1497]: loss 0.042185
[epoch1, step1498]: loss 0.041547
[epoch1, step1499]: loss 0.043680
[epoch1, step1500]: loss 0.042688
[epoch1, step1501]: loss 0.043118
[epoch1, step1502]: loss 0.042045
[epoch1, step1503]: loss 0.042363
[epoch1, step1504]: loss 0.042146
[epoch1, step1505]: loss 0.044990
[epoch1, step1506]: loss 0.041435
[epoch1, step1507]: loss 0.041784
[epoch1, step1508]: loss 0.044639
[epoch1, step1509]: loss 0.042405
[epoch1, step1510]: loss 0.042282
[epoch1, step1511]: loss 0.042730
[epoch1, step1512]: loss 0.042377
[epoch1, step1513]: loss 0.041456
[epoch1, step1514]: loss 0.044644
[epoch1, step1515]: loss 0.042286
[epoch1, step1516]: loss 0.041376

[epoch1]: avg loss 0.098248

[epoch2, step1]: loss 0.036725
[epoch2, step2]: loss 0.044003
[epoch2, step3]: loss 0.044097
[epoch2, step4]: loss 0.041484
[epoch2, step5]: loss 0.042022
[epoch2, step6]: loss 0.043981
[epoch2, step7]: loss 0.041705
[epoch2, step8]: loss 0.045108
[epoch2, step9]: loss 0.041706
[epoch2, step10]: loss 0.041498
[epoch2, step11]: loss 0.044157
[epoch2, step12]: loss 0.044345
[epoch2, step13]: loss 0.041764
[epoch2, step14]: loss 0.042009
[epoch2, step15]: loss 0.043931
[epoch2, step16]: loss 0.041446
[epoch2, step17]: loss 0.045372
[epoch2, step18]: loss 0.042742
[epoch2, step19]: loss 0.041291
[epoch2, step20]: loss 0.044859
[epoch2, step21]: loss 0.044323
[epoch2, step22]: loss 0.041438
[epoch2, step23]: loss 0.041084
[epoch2, step24]: loss 0.043915
[epoch2, step25]: loss 0.040913
[epoch2, step26]: loss 0.044337
[epoch2, step27]: loss 0.041606
[epoch2, step28]: loss 0.041148
[epoch2, step29]: loss 0.044171
[epoch2, step30]: loss 0.044835
[epoch2, step31]: loss 0.041274
[epoch2, step32]: loss 0.042187
[epoch2, step33]: loss 0.044480
[epoch2, step34]: loss 0.042032
[epoch2, step35]: loss 0.045246
[epoch2, step36]: loss 0.041981
[epoch2, step37]: loss 0.041105
[epoch2, step38]: loss 0.043893
[epoch2, step39]: loss 0.044213
[epoch2, step40]: loss 0.042005
[epoch2, step41]: loss 0.041313
[epoch2, step42]: loss 0.044165
[epoch2, step43]: loss 0.041306
[epoch2, step44]: loss 0.045220
[epoch2, step45]: loss 0.042067
[epoch2, step46]: loss 0.041210
[epoch2, step47]: loss 0.043711
[epoch2, step48]: loss 0.044005
[epoch2, step49]: loss 0.040237
[epoch2, step50]: loss 0.041920
[epoch2, step51]: loss 0.043652
[epoch2, step52]: loss 0.041239
[epoch2, step53]: loss 0.045517
[epoch2, step54]: loss 0.041817
[epoch2, step55]: loss 0.041438
[epoch2, step56]: loss 0.044848
[epoch2, step57]: loss 0.044705
[epoch2, step58]: loss 0.041698
[epoch2, step59]: loss 0.040950
[epoch2, step60]: loss 0.044255
[epoch2, step61]: loss 0.040704
[epoch2, step62]: loss 0.044424
[epoch2, step63]: loss 0.041359
[epoch2, step64]: loss 0.040649
[epoch2, step65]: loss 0.044169
[epoch2, step66]: loss 0.044248
[epoch2, step67]: loss 0.041791
[epoch2, step68]: loss 0.041765
[epoch2, step69]: loss 0.043786
[epoch2, step70]: loss 0.041166
[epoch2, step71]: loss 0.044486
[epoch2, step72]: loss 0.041969
[epoch2, step73]: loss 0.040818
[epoch2, step74]: loss 0.044133
[epoch2, step75]: loss 0.044350
[epoch2, step76]: loss 0.042158
[epoch2, step77]: loss 0.042271
[epoch2, step78]: loss 0.043965
[epoch2, step79]: loss 0.040803
[epoch2, step80]: loss 0.045546
[epoch2, step81]: loss 0.041999
[epoch2, step82]: loss 0.040703
[epoch2, step83]: loss 0.043300
[epoch2, step84]: loss 0.044449
[epoch2, step85]: loss 0.042165
[epoch2, step86]: loss 0.041851
[epoch2, step87]: loss 0.044762
[epoch2, step88]: loss 0.040284
[epoch2, step89]: loss 0.044474
[epoch2, step90]: loss 0.042299
[epoch2, step91]: loss 0.040504
[epoch2, step92]: loss 0.044105
[epoch2, step93]: loss 0.044182
[epoch2, step94]: loss 0.041477
[epoch2, step95]: loss 0.042107
[epoch2, step96]: loss 0.043575
[epoch2, step97]: loss 0.041824
[epoch2, step98]: loss 0.044796
[epoch2, step99]: loss 0.042010
[epoch2, step100]: loss 0.040098
[epoch2, step101]: loss 0.044460
[epoch2, step102]: loss 0.044185
[epoch2, step103]: loss 0.041521
[epoch2, step104]: loss 0.041762
[epoch2, step105]: loss 0.043934
[epoch2, step106]: loss 0.041161
[epoch2, step107]: loss 0.044697
[epoch2, step108]: loss 0.042133
[epoch2, step109]: loss 0.040568
[epoch2, step110]: loss 0.044539
[epoch2, step111]: loss 0.044008
[epoch2, step112]: loss 0.041760
[epoch2, step113]: loss 0.042403
[epoch2, step114]: loss 0.043662
[epoch2, step115]: loss 0.041232
[epoch2, step116]: loss 0.045402
[epoch2, step117]: loss 0.041920
[epoch2, step118]: loss 0.041362
[epoch2, step119]: loss 0.044360
[epoch2, step120]: loss 0.044296
[epoch2, step121]: loss 0.041346
[epoch2, step122]: loss 0.041584
[epoch2, step123]: loss 0.044142
[epoch2, step124]: loss 0.041437
[epoch2, step125]: loss 0.045163
[epoch2, step126]: loss 0.041861
[epoch2, step127]: loss 0.040753
[epoch2, step128]: loss 0.043876
[epoch2, step129]: loss 0.043802
[epoch2, step130]: loss 0.041692
[epoch2, step131]: loss 0.041113
[epoch2, step132]: loss 0.043945
[epoch2, step133]: loss 0.040972
[epoch2, step134]: loss 0.044266
[epoch2, step135]: loss 0.042375
[epoch2, step136]: loss 0.041728
[epoch2, step137]: loss 0.043670
[epoch2, step138]: loss 0.044075
[epoch2, step139]: loss 0.041403
[epoch2, step140]: loss 0.042061
[epoch2, step141]: loss 0.043977
[epoch2, step142]: loss 0.041083
[epoch2, step143]: loss 0.044364
[epoch2, step144]: loss 0.042175
[epoch2, step145]: loss 0.040896
[epoch2, step146]: loss 0.044060
[epoch2, step147]: loss 0.045354
[epoch2, step148]: loss 0.041391
[epoch2, step149]: loss 0.041205
[epoch2, step150]: loss 0.043457
[epoch2, step151]: loss 0.041234
[epoch2, step152]: loss 0.044764
[epoch2, step153]: loss 0.042099
[epoch2, step154]: loss 0.040402
[epoch2, step155]: loss 0.043972
[epoch2, step156]: loss 0.043861
[epoch2, step157]: loss 0.041718
[epoch2, step158]: loss 0.041839
[epoch2, step159]: loss 0.044059
[epoch2, step160]: loss 0.041422
[epoch2, step161]: loss 0.045257
[epoch2, step162]: loss 0.042132
[epoch2, step163]: loss 0.040658
[epoch2, step164]: loss 0.044251
[epoch2, step165]: loss 0.044244
[epoch2, step166]: loss 0.041858
[epoch2, step167]: loss 0.041264
[epoch2, step168]: loss 0.044296
[epoch2, step169]: loss 0.040871
[epoch2, step170]: loss 0.045031
[epoch2, step171]: loss 0.042176
[epoch2, step172]: loss 0.040859
[epoch2, step173]: loss 0.044259
[epoch2, step174]: loss 0.044026
[epoch2, step175]: loss 0.042256
[epoch2, step176]: loss 0.041949
[epoch2, step177]: loss 0.044098
[epoch2, step178]: loss 0.041182
[epoch2, step179]: loss 0.043978
[epoch2, step180]: loss 0.042274
[epoch2, step181]: loss 0.040895
[epoch2, step182]: loss 0.044218
[epoch2, step183]: loss 0.044778
[epoch2, step184]: loss 0.042481
[epoch2, step185]: loss 0.041937
[epoch2, step186]: loss 0.043919
[epoch2, step187]: loss 0.041237
[epoch2, step188]: loss 0.044491
[epoch2, step189]: loss 0.041985
[epoch2, step190]: loss 0.040376
[epoch2, step191]: loss 0.043682
[epoch2, step192]: loss 0.044620
[epoch2, step193]: loss 0.039978
[epoch2, step194]: loss 0.040945
[epoch2, step195]: loss 0.044097
[epoch2, step196]: loss 0.041175
[epoch2, step197]: loss 0.044613
[epoch2, step198]: loss 0.041128
[epoch2, step199]: loss 0.040798
[epoch2, step200]: loss 0.044382
[epoch2, step201]: loss 0.044659
[epoch2, step202]: loss 0.041307
[epoch2, step203]: loss 0.041698
[epoch2, step204]: loss 0.044145
[epoch2, step205]: loss 0.040533
[epoch2, step206]: loss 0.044457
[epoch2, step207]: loss 0.041795
[epoch2, step208]: loss 0.041109
[epoch2, step209]: loss 0.044163
[epoch2, step210]: loss 0.045015
[epoch2, step211]: loss 0.042124
[epoch2, step212]: loss 0.042051
[epoch2, step213]: loss 0.043551
[epoch2, step214]: loss 0.040610
[epoch2, step215]: loss 0.044914
[epoch2, step216]: loss 0.042180
[epoch2, step217]: loss 0.039928
[epoch2, step218]: loss 0.044195
[epoch2, step219]: loss 0.043986
[epoch2, step220]: loss 0.041870
[epoch2, step221]: loss 0.041921
[epoch2, step222]: loss 0.043907
[epoch2, step223]: loss 0.041327
[epoch2, step224]: loss 0.044418
[epoch2, step225]: loss 0.041938
[epoch2, step226]: loss 0.040679
[epoch2, step227]: loss 0.043141
[epoch2, step228]: loss 0.044696
[epoch2, step229]: loss 0.040884
[epoch2, step230]: loss 0.041933
[epoch2, step231]: loss 0.044170
[epoch2, step232]: loss 0.040662
[epoch2, step233]: loss 0.044018
[epoch2, step234]: loss 0.041521
[epoch2, step235]: loss 0.041013
[epoch2, step236]: loss 0.044046
[epoch2, step237]: loss 0.044316
[epoch2, step238]: loss 0.041358
[epoch2, step239]: loss 0.040987
[epoch2, step240]: loss 0.043362
[epoch2, step241]: loss 0.041508
[epoch2, step242]: loss 0.044586
[epoch2, step243]: loss 0.042485
[epoch2, step244]: loss 0.040646
[epoch2, step245]: loss 0.043600
[epoch2, step246]: loss 0.044182
[epoch2, step247]: loss 0.041849
[epoch2, step248]: loss 0.041312
[epoch2, step249]: loss 0.043380
[epoch2, step250]: loss 0.041173
[epoch2, step251]: loss 0.045214
[epoch2, step252]: loss 0.042400
[epoch2, step253]: loss 0.040408
[epoch2, step254]: loss 0.043354
[epoch2, step255]: loss 0.044258
[epoch2, step256]: loss 0.041365
[epoch2, step257]: loss 0.041406
[epoch2, step258]: loss 0.044327
[epoch2, step259]: loss 0.040958
[epoch2, step260]: loss 0.044114
[epoch2, step261]: loss 0.042638
[epoch2, step262]: loss 0.041064
[epoch2, step263]: loss 0.043230
[epoch2, step264]: loss 0.043899
[epoch2, step265]: loss 0.041787
[epoch2, step266]: loss 0.041600
[epoch2, step267]: loss 0.043214
[epoch2, step268]: loss 0.040969
[epoch2, step269]: loss 0.044690
[epoch2, step270]: loss 0.041542
[epoch2, step271]: loss 0.040746
[epoch2, step272]: loss 0.043893
[epoch2, step273]: loss 0.043932
[epoch2, step274]: loss 0.041988
[epoch2, step275]: loss 0.041194
[epoch2, step276]: loss 0.043349
[epoch2, step277]: loss 0.041399
[epoch2, step278]: loss 0.044773
[epoch2, step279]: loss 0.041596
[epoch2, step280]: loss 0.040548
[epoch2, step281]: loss 0.043683
[epoch2, step282]: loss 0.044471
[epoch2, step283]: loss 0.041183
[epoch2, step284]: loss 0.041083
[epoch2, step285]: loss 0.044366
[epoch2, step286]: loss 0.040325
[epoch2, step287]: loss 0.044762
[epoch2, step288]: loss 0.041522
[epoch2, step289]: loss 0.041383
[epoch2, step290]: loss 0.043999
[epoch2, step291]: loss 0.044380
[epoch2, step292]: loss 0.040819
[epoch2, step293]: loss 0.041225
[epoch2, step294]: loss 0.042979
[epoch2, step295]: loss 0.040577
[epoch2, step296]: loss 0.045287
[epoch2, step297]: loss 0.041586
[epoch2, step298]: loss 0.041032
[epoch2, step299]: loss 0.043160
[epoch2, step300]: loss 0.044372
[epoch2, step301]: loss 0.041547
[epoch2, step302]: loss 0.041879
[epoch2, step303]: loss 0.044092
[epoch2, step304]: loss 0.040614
[epoch2, step305]: loss 0.044330
[epoch2, step306]: loss 0.041897
[epoch2, step307]: loss 0.040207
[epoch2, step308]: loss 0.044334
[epoch2, step309]: loss 0.044356
[epoch2, step310]: loss 0.041659
[epoch2, step311]: loss 0.041865
[epoch2, step312]: loss 0.043453
[epoch2, step313]: loss 0.041347
[epoch2, step314]: loss 0.044565
[epoch2, step315]: loss 0.042705
[epoch2, step316]: loss 0.040454
[epoch2, step317]: loss 0.044037
[epoch2, step318]: loss 0.044195
[epoch2, step319]: loss 0.041136
[epoch2, step320]: loss 0.040655
[epoch2, step321]: loss 0.043343
[epoch2, step322]: loss 0.040861
[epoch2, step323]: loss 0.044015
[epoch2, step324]: loss 0.042410
[epoch2, step325]: loss 0.040785
[epoch2, step326]: loss 0.043650
[epoch2, step327]: loss 0.043575
[epoch2, step328]: loss 0.041685
[epoch2, step329]: loss 0.041307
[epoch2, step330]: loss 0.043391
[epoch2, step331]: loss 0.041061
[epoch2, step332]: loss 0.044060
[epoch2, step333]: loss 0.041789
[epoch2, step334]: loss 0.040536
[epoch2, step335]: loss 0.043946
[epoch2, step336]: loss 0.044915
[epoch2, step337]: loss 0.041659
[epoch2, step338]: loss 0.041079
[epoch2, step339]: loss 0.043391
[epoch2, step340]: loss 0.041238
[epoch2, step341]: loss 0.044135
[epoch2, step342]: loss 0.041506
[epoch2, step343]: loss 0.040772
[epoch2, step344]: loss 0.043460
[epoch2, step345]: loss 0.043505
[epoch2, step346]: loss 0.041033
[epoch2, step347]: loss 0.041174
[epoch2, step348]: loss 0.043710
[epoch2, step349]: loss 0.041320
[epoch2, step350]: loss 0.044084
[epoch2, step351]: loss 0.041151
[epoch2, step352]: loss 0.040493
[epoch2, step353]: loss 0.043634
[epoch2, step354]: loss 0.043193
[epoch2, step355]: loss 0.040624
[epoch2, step356]: loss 0.042029
[epoch2, step357]: loss 0.043640
[epoch2, step358]: loss 0.039776
[epoch2, step359]: loss 0.045289
[epoch2, step360]: loss 0.040818
[epoch2, step361]: loss 0.039984
[epoch2, step362]: loss 0.044232
[epoch2, step363]: loss 0.043881
[epoch2, step364]: loss 0.041284
[epoch2, step365]: loss 0.041175
[epoch2, step366]: loss 0.043941
[epoch2, step367]: loss 0.040834
[epoch2, step368]: loss 0.043983
[epoch2, step369]: loss 0.041603
[epoch2, step370]: loss 0.041063
[epoch2, step371]: loss 0.044451
[epoch2, step372]: loss 0.043694
[epoch2, step373]: loss 0.040942
[epoch2, step374]: loss 0.040707
[epoch2, step375]: loss 0.044022
[epoch2, step376]: loss 0.040840
[epoch2, step377]: loss 0.044614
[epoch2, step378]: loss 0.042062
[epoch2, step379]: loss 0.041034
[epoch2, step380]: loss 0.044234
[epoch2, step381]: loss 0.043728
[epoch2, step382]: loss 0.041698
[epoch2, step383]: loss 0.040561
[epoch2, step384]: loss 0.043045
[epoch2, step385]: loss 0.040851
[epoch2, step386]: loss 0.044609
[epoch2, step387]: loss 0.041839
[epoch2, step388]: loss 0.041157
[epoch2, step389]: loss 0.043794
[epoch2, step390]: loss 0.044701
[epoch2, step391]: loss 0.041085
[epoch2, step392]: loss 0.041870
[epoch2, step393]: loss 0.043022
[epoch2, step394]: loss 0.040870
[epoch2, step395]: loss 0.044257
[epoch2, step396]: loss 0.041766
[epoch2, step397]: loss 0.040258
[epoch2, step398]: loss 0.043811
[epoch2, step399]: loss 0.043904
[epoch2, step400]: loss 0.041124
[epoch2, step401]: loss 0.041102
[epoch2, step402]: loss 0.043197
[epoch2, step403]: loss 0.040748
[epoch2, step404]: loss 0.044678
[epoch2, step405]: loss 0.041828
[epoch2, step406]: loss 0.040699
[epoch2, step407]: loss 0.043484
[epoch2, step408]: loss 0.043982
[epoch2, step409]: loss 0.042448
[epoch2, step410]: loss 0.041819
[epoch2, step411]: loss 0.043448
[epoch2, step412]: loss 0.040310
[epoch2, step413]: loss 0.044341
[epoch2, step414]: loss 0.041358
[epoch2, step415]: loss 0.040719
[epoch2, step416]: loss 0.043231
[epoch2, step417]: loss 0.044069
[epoch2, step418]: loss 0.041080
[epoch2, step419]: loss 0.039832
[epoch2, step420]: loss 0.043373
[epoch2, step421]: loss 0.039829
[epoch2, step422]: loss 0.043870
[epoch2, step423]: loss 0.041180
[epoch2, step424]: loss 0.040026
[epoch2, step425]: loss 0.043456
[epoch2, step426]: loss 0.043612
[epoch2, step427]: loss 0.040642
[epoch2, step428]: loss 0.040153
[epoch2, step429]: loss 0.043505
[epoch2, step430]: loss 0.039752
[epoch2, step431]: loss 0.043844
[epoch2, step432]: loss 0.040522
[epoch2, step433]: loss 0.040272
[epoch2, step434]: loss 0.043213
[epoch2, step435]: loss 0.043375
[epoch2, step436]: loss 0.040021
[epoch2, step437]: loss 0.040581
[epoch2, step438]: loss 0.043048
[epoch2, step439]: loss 0.040581
[epoch2, step440]: loss 0.043465
[epoch2, step441]: loss 0.040917
[epoch2, step442]: loss 0.039916
[epoch2, step443]: loss 0.043279
[epoch2, step444]: loss 0.042708
[epoch2, step445]: loss 0.041258
[epoch2, step446]: loss 0.040556
[epoch2, step447]: loss 0.043353
[epoch2, step448]: loss 0.040326
[epoch2, step449]: loss 0.043328
[epoch2, step450]: loss 0.039733
[epoch2, step451]: loss 0.039749
[epoch2, step452]: loss 0.042614
[epoch2, step453]: loss 0.042923
[epoch2, step454]: loss 0.040180
[epoch2, step455]: loss 0.040602
[epoch2, step456]: loss 0.041774
[epoch2, step457]: loss 0.040295
[epoch2, step458]: loss 0.043507
[epoch2, step459]: loss 0.041171
[epoch2, step460]: loss 0.039579
[epoch2, step461]: loss 0.043369
[epoch2, step462]: loss 0.042337
[epoch2, step463]: loss 0.040246
[epoch2, step464]: loss 0.039723
[epoch2, step465]: loss 0.043939
[epoch2, step466]: loss 0.039570
[epoch2, step467]: loss 0.042878
[epoch2, step468]: loss 0.040571
[epoch2, step469]: loss 0.039843
[epoch2, step470]: loss 0.042836
[epoch2, step471]: loss 0.042254
[epoch2, step472]: loss 0.040939
[epoch2, step473]: loss 0.039485
[epoch2, step474]: loss 0.042342
[epoch2, step475]: loss 0.039961
[epoch2, step476]: loss 0.043790
[epoch2, step477]: loss 0.040135
[epoch2, step478]: loss 0.038900
[epoch2, step479]: loss 0.043381
[epoch2, step480]: loss 0.042642
[epoch2, step481]: loss 0.039410
[epoch2, step482]: loss 0.039415
[epoch2, step483]: loss 0.042873
[epoch2, step484]: loss 0.039812
[epoch2, step485]: loss 0.043071
[epoch2, step486]: loss 0.040352
[epoch2, step487]: loss 0.038633
[epoch2, step488]: loss 0.042718
[epoch2, step489]: loss 0.041914
[epoch2, step490]: loss 0.040152
[epoch2, step491]: loss 0.039760
[epoch2, step492]: loss 0.041843
[epoch2, step493]: loss 0.039257
[epoch2, step494]: loss 0.042215
[epoch2, step495]: loss 0.041162
[epoch2, step496]: loss 0.039304
[epoch2, step497]: loss 0.042291
[epoch2, step498]: loss 0.042194
[epoch2, step499]: loss 0.039934
[epoch2, step500]: loss 0.039227
[epoch2, step501]: loss 0.041624
[epoch2, step502]: loss 0.039233
[epoch2, step503]: loss 0.042776
[epoch2, step504]: loss 0.039587
[epoch2, step505]: loss 0.038476
[epoch2, step506]: loss 0.042529
[epoch2, step507]: loss 0.042454
[epoch2, step508]: loss 0.040096
[epoch2, step509]: loss 0.039437
[epoch2, step510]: loss 0.042034
[epoch2, step511]: loss 0.039712
[epoch2, step512]: loss 0.042813
[epoch2, step513]: loss 0.039953
[epoch2, step514]: loss 0.039405
[epoch2, step515]: loss 0.042127
[epoch2, step516]: loss 0.042585
[epoch2, step517]: loss 0.039511
[epoch2, step518]: loss 0.039512
[epoch2, step519]: loss 0.041810
[epoch2, step520]: loss 0.038894
[epoch2, step521]: loss 0.042011
[epoch2, step522]: loss 0.039179
[epoch2, step523]: loss 0.039041
[epoch2, step524]: loss 0.041413
[epoch2, step525]: loss 0.042372
[epoch2, step526]: loss 0.039501
[epoch2, step527]: loss 0.039098
[epoch2, step528]: loss 0.042256
[epoch2, step529]: loss 0.038581
[epoch2, step530]: loss 0.042854
[epoch2, step531]: loss 0.038611
[epoch2, step532]: loss 0.038089
[epoch2, step533]: loss 0.042622
[epoch2, step534]: loss 0.041719
[epoch2, step535]: loss 0.039132
[epoch2, step536]: loss 0.037451
[epoch2, step537]: loss 0.041408
[epoch2, step538]: loss 0.038342
[epoch2, step539]: loss 0.041408
[epoch2, step540]: loss 0.038423
[epoch2, step541]: loss 0.037610
[epoch2, step542]: loss 0.041612
[epoch2, step543]: loss 0.041290
[epoch2, step544]: loss 0.038311
[epoch2, step545]: loss 0.037755
[epoch2, step546]: loss 0.041347
[epoch2, step547]: loss 0.038198
[epoch2, step548]: loss 0.041806
[epoch2, step549]: loss 0.038367
[epoch2, step550]: loss 0.037945
[epoch2, step551]: loss 0.040832
[epoch2, step552]: loss 0.040221
[epoch2, step553]: loss 0.038889
[epoch2, step554]: loss 0.037885
[epoch2, step555]: loss 0.040270
[epoch2, step556]: loss 0.037632
[epoch2, step557]: loss 0.040186
[epoch2, step558]: loss 0.038041
[epoch2, step559]: loss 0.036934
[epoch2, step560]: loss 0.040742
[epoch2, step561]: loss 0.040415
[epoch2, step562]: loss 0.037675
[epoch2, step563]: loss 0.029167
[epoch2, step564]: loss 0.027515
[epoch2, step565]: loss 0.026278
[epoch2, step566]: loss 0.033734
[epoch2, step567]: loss 0.029007
[epoch2, step568]: loss 0.035559
[epoch2, step569]: loss 0.031367
[epoch2, step570]: loss 0.045236
[epoch2, step571]: loss 0.038925
[epoch2, step572]: loss 0.036406
[epoch2, step573]: loss 0.041490
[epoch2, step574]: loss 0.038715
[epoch2, step575]: loss 0.027437
[epoch2, step576]: loss 0.028913
[epoch2, step577]: loss 0.036111
[epoch2, step578]: loss 0.024525
[epoch2, step579]: loss 0.038829
[epoch2, step580]: loss 0.025963
[epoch2, step581]: loss 0.034447
[epoch2, step582]: loss 0.033600
[epoch2, step583]: loss 0.027653
[epoch2, step584]: loss 0.030442
[epoch2, step585]: loss 0.033947
[epoch2, step586]: loss 0.027042
[epoch2, step587]: loss 0.036004
[epoch2, step588]: loss 0.028543
[epoch2, step589]: loss 0.028350
[epoch2, step590]: loss 0.035494
[epoch2, step591]: loss 0.024739
[epoch2, step592]: loss 0.032188
[epoch2, step593]: loss 0.027008
[epoch2, step594]: loss 0.031705
[epoch2, step595]: loss 0.032715
[epoch2, step596]: loss 0.026358
[epoch2, step597]: loss 0.029990
[epoch2, step598]: loss 0.031799
[epoch2, step599]: loss 0.029831
[epoch2, step600]: loss 0.032845
[epoch2, step601]: loss 0.021220
[epoch2, step602]: loss 0.025391
[epoch2, step603]: loss 0.029846
[epoch2, step604]: loss 0.030647
[epoch2, step605]: loss 0.028678
[epoch2, step606]: loss 0.027747
[epoch2, step607]: loss 0.031777
[epoch2, step608]: loss 0.028617
[epoch2, step609]: loss 0.029059
[epoch2, step610]: loss 0.026781
[epoch2, step611]: loss 0.027745
[epoch2, step612]: loss 0.027307
[epoch2, step613]: loss 0.020043
[epoch2, step614]: loss 0.026705
[epoch2, step615]: loss 0.029992
[epoch2, step616]: loss 0.025250
[epoch2, step617]: loss 0.024859
[epoch2, step618]: loss 0.027127
[epoch2, step619]: loss 0.027895
[epoch2, step620]: loss 0.025750
[epoch2, step621]: loss 0.027612
[epoch2, step622]: loss 0.021652
[epoch2, step623]: loss 0.025909
[epoch2, step624]: loss 0.027833
[epoch2, step625]: loss 0.027853
[epoch2, step626]: loss 0.030103
[epoch2, step627]: loss 0.024298
[epoch2, step628]: loss 0.027855
[epoch2, step629]: loss 0.021984
[epoch2, step630]: loss 0.024673
[epoch2, step631]: loss 0.032722
[epoch2, step632]: loss 0.024910
[epoch2, step633]: loss 0.026093
[epoch2, step634]: loss 0.028189
[epoch2, step635]: loss 0.027107
[epoch2, step636]: loss 0.021588
[epoch2, step637]: loss 0.028954
[epoch2, step638]: loss 0.028607
[epoch2, step639]: loss 0.024224
[epoch2, step640]: loss 0.030766
[epoch2, step641]: loss 0.032026
[epoch2, step642]: loss 0.026241
[epoch2, step643]: loss 0.027076
[epoch2, step644]: loss 0.027670
[epoch2, step645]: loss 0.024893
[epoch2, step646]: loss 0.028167
[epoch2, step647]: loss 0.024992
[epoch2, step648]: loss 0.024452
[epoch2, step649]: loss 0.030647
[epoch2, step650]: loss 0.023464
[epoch2, step651]: loss 0.027553
[epoch2, step652]: loss 0.028513
[epoch2, step653]: loss 0.029690
[epoch2, step654]: loss 0.024527
[epoch2, step655]: loss 0.025420
[epoch2, step656]: loss 0.022489
[epoch2, step657]: loss 0.029680
[epoch2, step658]: loss 0.026750
[epoch2, step659]: loss 0.029242
[epoch2, step660]: loss 0.024784
[epoch2, step661]: loss 0.028552
[epoch2, step662]: loss 0.024971
[epoch2, step663]: loss 0.022397
[epoch2, step664]: loss 0.026320
[epoch2, step665]: loss 0.029589
[epoch2, step666]: loss 0.028597
[epoch2, step667]: loss 0.028059
[epoch2, step668]: loss 0.023716
[epoch2, step669]: loss 0.027579
[epoch2, step670]: loss 0.028505
[epoch2, step671]: loss 0.021771
[epoch2, step672]: loss 0.025004
[epoch2, step673]: loss 0.023274
[epoch2, step674]: loss 0.022235
[epoch2, step675]: loss 0.020886
[epoch2, step676]: loss 0.025652
[epoch2, step677]: loss 0.026881
[epoch2, step678]: loss 0.024578
[epoch2, step679]: loss 0.024997
[epoch2, step680]: loss 0.032439
[epoch2, step681]: loss 0.023212
[epoch2, step682]: loss 0.027470
[epoch2, step683]: loss 0.027162
[epoch2, step684]: loss 0.026413
[epoch2, step685]: loss 0.025019
[epoch2, step686]: loss 0.029136
[epoch2, step687]: loss 0.028479
[epoch2, step688]: loss 0.024258
[epoch2, step689]: loss 0.025514
[epoch2, step690]: loss 0.026682
[epoch2, step691]: loss 0.025763
[epoch2, step692]: loss 0.023915
[epoch2, step693]: loss 0.029504
[epoch2, step694]: loss 0.024019
[epoch2, step695]: loss 0.028208
[epoch2, step696]: loss 0.027317
[epoch2, step697]: loss 0.028890
[epoch2, step698]: loss 0.026283
[epoch2, step699]: loss 0.024483
[epoch2, step700]: loss 0.022880
[epoch2, step701]: loss 0.027396
[epoch2, step702]: loss 0.022825
[epoch2, step703]: loss 0.024415
[epoch2, step704]: loss 0.027412
[epoch2, step705]: loss 0.025993
[epoch2, step706]: loss 0.025290
[epoch2, step707]: loss 0.025305
[epoch2, step708]: loss 0.027511
[epoch2, step709]: loss 0.028965
[epoch2, step710]: loss 0.025477
[epoch2, step711]: loss 0.025181
[epoch2, step712]: loss 0.028057
[epoch2, step713]: loss 0.028066
[epoch2, step714]: loss 0.022482
[epoch2, step715]: loss 0.024276
[epoch2, step716]: loss 0.027680
[epoch2, step717]: loss 0.024851
[epoch2, step718]: loss 0.026058
[epoch2, step719]: loss 0.035070
[epoch2, step720]: loss 0.026305
[epoch2, step721]: loss 0.024494
[epoch2, step722]: loss 0.033293
[epoch2, step723]: loss 0.028215
[epoch2, step724]: loss 0.024280
[epoch2, step725]: loss 0.030215
[epoch2, step726]: loss 0.023241
[epoch2, step727]: loss 0.025565
[epoch2, step728]: loss 0.027897
[epoch2, step729]: loss 0.022493
[epoch2, step730]: loss 0.023748
[epoch2, step731]: loss 0.027708
[epoch2, step732]: loss 0.027133
[epoch2, step733]: loss 0.025194
[epoch2, step734]: loss 0.024414
[epoch2, step735]: loss 0.028569
[epoch2, step736]: loss 0.026193
[epoch2, step737]: loss 0.027862
[epoch2, step738]: loss 0.021725
[epoch2, step739]: loss 0.026717
[epoch2, step740]: loss 0.023969
[epoch2, step741]: loss 0.026402
[epoch2, step742]: loss 0.023275
[epoch2, step743]: loss 0.024539
[epoch2, step744]: loss 0.025053
[epoch2, step745]: loss 0.026229
[epoch2, step746]: loss 0.026974
[epoch2, step747]: loss 0.029234
[epoch2, step748]: loss 0.027100
[epoch2, step749]: loss 0.027750
[epoch2, step750]: loss 0.029372
[epoch2, step751]: loss 0.022653
[epoch2, step752]: loss 0.026215
[epoch2, step753]: loss 0.027142
[epoch2, step754]: loss 0.023906
[epoch2, step755]: loss 0.027777
[epoch2, step756]: loss 0.024485
[epoch2, step757]: loss 0.021747
[epoch2, step758]: loss 0.026315
[epoch2, step759]: loss 0.024463
[epoch2, step760]: loss 0.025536
[epoch2, step761]: loss 0.027514
[epoch2, step762]: loss 0.022651
[epoch2, step763]: loss 0.027143
[epoch2, step764]: loss 0.025599
[epoch2, step765]: loss 0.027543
[epoch2, step766]: loss 0.026030
[epoch2, step767]: loss 0.028610
[epoch2, step768]: loss 0.022467
[epoch2, step769]: loss 0.028339
[epoch2, step770]: loss 0.027785
[epoch2, step771]: loss 0.024240
[epoch2, step772]: loss 0.030568
[epoch2, step773]: loss 0.027695
[epoch2, step774]: loss 0.024774
[epoch2, step775]: loss 0.021736
[epoch2, step776]: loss 0.027472
[epoch2, step777]: loss 0.023751
[epoch2, step778]: loss 0.030246
[epoch2, step779]: loss 0.025434
[epoch2, step780]: loss 0.020959
[epoch2, step781]: loss 0.025876
[epoch2, step782]: loss 0.023694
[epoch2, step783]: loss 0.020417
[epoch2, step784]: loss 0.021420
[epoch2, step785]: loss 0.022017
[epoch2, step786]: loss 0.025521
[epoch2, step787]: loss 0.024703
[epoch2, step788]: loss 0.025855
[epoch2, step789]: loss 0.023787
[epoch2, step790]: loss 0.024517
[epoch2, step791]: loss 0.028114
[epoch2, step792]: loss 0.026308
[epoch2, step793]: loss 0.028657
[epoch2, step794]: loss 0.021291
[epoch2, step795]: loss 0.027061
[epoch2, step796]: loss 0.029240
[epoch2, step797]: loss 0.029270
[epoch2, step798]: loss 0.028458
[epoch2, step799]: loss 0.026860
[epoch2, step800]: loss 0.023224
[epoch2, step801]: loss 0.023325
[epoch2, step802]: loss 0.024027
[epoch2, step803]: loss 0.027462
[epoch2, step804]: loss 0.029140
[epoch2, step805]: loss 0.031031
[epoch2, step806]: loss 0.022520
[epoch2, step807]: loss 0.021537
[epoch2, step808]: loss 0.024254
[epoch2, step809]: loss 0.024148
[epoch2, step810]: loss 0.027421
[epoch2, step811]: loss 0.027512
[epoch2, step812]: loss 0.026146
[epoch2, step813]: loss 0.025126
[epoch2, step814]: loss 0.026512
[epoch2, step815]: loss 0.026190
[epoch2, step816]: loss 0.025802
[epoch2, step817]: loss 0.026212
[epoch2, step818]: loss 0.023449
[epoch2, step819]: loss 0.021458
[epoch2, step820]: loss 0.024877
[epoch2, step821]: loss 0.022883
[epoch2, step822]: loss 0.033164
[epoch2, step823]: loss 0.025290
[epoch2, step824]: loss 0.028134
[epoch2, step825]: loss 0.026810
[epoch2, step826]: loss 0.025676
[epoch2, step827]: loss 0.028194
[epoch2, step828]: loss 0.030549
[epoch2, step829]: loss 0.027564
[epoch2, step830]: loss 0.023773
[epoch2, step831]: loss 0.027441
[epoch2, step832]: loss 0.021855
[epoch2, step833]: loss 0.030941
[epoch2, step834]: loss 0.027370
[epoch2, step835]: loss 0.021574
[epoch2, step836]: loss 0.028353
[epoch2, step837]: loss 0.026535
[epoch2, step838]: loss 0.027496
[epoch2, step839]: loss 0.030060
[epoch2, step840]: loss 0.021339
[epoch2, step841]: loss 0.025302
[epoch2, step842]: loss 0.029278
[epoch2, step843]: loss 0.026833
[epoch2, step844]: loss 0.026755
[epoch2, step845]: loss 0.022051
[epoch2, step846]: loss 0.026981
[epoch2, step847]: loss 0.028700
[epoch2, step848]: loss 0.026753
[epoch2, step849]: loss 0.026514
[epoch2, step850]: loss 0.024500
[epoch2, step851]: loss 0.025220
[epoch2, step852]: loss 0.023936
[epoch2, step853]: loss 0.031189
[epoch2, step854]: loss 0.023276
[epoch2, step855]: loss 0.028478
[epoch2, step856]: loss 0.023216
[epoch2, step857]: loss 0.027572
[epoch2, step858]: loss 0.025282
[epoch2, step859]: loss 0.024503
[epoch2, step860]: loss 0.023425
[epoch2, step861]: loss 0.024400
[epoch2, step862]: loss 0.023816
[epoch2, step863]: loss 0.021243
[epoch2, step864]: loss 0.027964
[epoch2, step865]: loss 0.024351
[epoch2, step866]: loss 0.026093
[epoch2, step867]: loss 0.027092
[epoch2, step868]: loss 0.027677
[epoch2, step869]: loss 0.024671
[epoch2, step870]: loss 0.031890
[epoch2, step871]: loss 0.023343
[epoch2, step872]: loss 0.026395
[epoch2, step873]: loss 0.026699
[epoch2, step874]: loss 0.024377
[epoch2, step875]: loss 0.025149
[epoch2, step876]: loss 0.025254
[epoch2, step877]: loss 0.019932
[epoch2, step878]: loss 0.024133
[epoch2, step879]: loss 0.028898
[epoch2, step880]: loss 0.026356
[epoch2, step881]: loss 0.022847
[epoch2, step882]: loss 0.025373
[epoch2, step883]: loss 0.025170
[epoch2, step884]: loss 0.027158
[epoch2, step885]: loss 0.026658
[epoch2, step886]: loss 0.027124
[epoch2, step887]: loss 0.024551
[epoch2, step888]: loss 0.025386
[epoch2, step889]: loss 0.024473
[epoch2, step890]: loss 0.024304
[epoch2, step891]: loss 0.026132
[epoch2, step892]: loss 0.021564
[epoch2, step893]: loss 0.024896
[epoch2, step894]: loss 0.025211
[epoch2, step895]: loss 0.023315
[epoch2, step896]: loss 0.022607
[epoch2, step897]: loss 0.024850
[epoch2, step898]: loss 0.026433
[epoch2, step899]: loss 0.028934
[epoch2, step900]: loss 0.027771
[epoch2, step901]: loss 0.026483
[epoch2, step902]: loss 0.024606
[epoch2, step903]: loss 0.025295
[epoch2, step904]: loss 0.028835
[epoch2, step905]: loss 0.028542
[epoch2, step906]: loss 0.023006
[epoch2, step907]: loss 0.023981
[epoch2, step908]: loss 0.023360
[epoch2, step909]: loss 0.026425
[epoch2, step910]: loss 0.023755
[epoch2, step911]: loss 0.025896
[epoch2, step912]: loss 0.024279
[epoch2, step913]: loss 0.025107
[epoch2, step914]: loss 0.031545
[epoch2, step915]: loss 0.024761
[epoch2, step916]: loss 0.024229
[epoch2, step917]: loss 0.025917
[epoch2, step918]: loss 0.029006
[epoch2, step919]: loss 0.024717
[epoch2, step920]: loss 0.027971
[epoch2, step921]: loss 0.025261
[epoch2, step922]: loss 0.023973
[epoch2, step923]: loss 0.023525
[epoch2, step924]: loss 0.021738
[epoch2, step925]: loss 0.026254
[epoch2, step926]: loss 0.027325
[epoch2, step927]: loss 0.026785
[epoch2, step928]: loss 0.025752
[epoch2, step929]: loss 0.028427
[epoch2, step930]: loss 0.026811
[epoch2, step931]: loss 0.028754
[epoch2, step932]: loss 0.022633
[epoch2, step933]: loss 0.029334
[epoch2, step934]: loss 0.022944
[epoch2, step935]: loss 0.022962
[epoch2, step936]: loss 0.023237
[epoch2, step937]: loss 0.028412
[epoch2, step938]: loss 0.026086
[epoch2, step939]: loss 0.021419
[epoch2, step940]: loss 0.023586
[epoch2, step941]: loss 0.027351
[epoch2, step942]: loss 0.026152
[epoch2, step943]: loss 0.024060
[epoch2, step944]: loss 0.028541
[epoch2, step945]: loss 0.020741
[epoch2, step946]: loss 0.026216
[epoch2, step947]: loss 0.028631
[epoch2, step948]: loss 0.020257
[epoch2, step949]: loss 0.023304
[epoch2, step950]: loss 0.026873
[epoch2, step951]: loss 0.029528
[epoch2, step952]: loss 0.025643
[epoch2, step953]: loss 0.028128
[epoch2, step954]: loss 0.022928
[epoch2, step955]: loss 0.037485
[epoch2, step956]: loss 0.048912
[epoch2, step957]: loss 0.043476
[epoch2, step958]: loss 0.042431
[epoch2, step959]: loss 0.046948
[epoch2, step960]: loss 0.044193
[epoch2, step961]: loss 0.045439
[epoch2, step962]: loss 0.044777
[epoch2, step963]: loss 0.043987
[epoch2, step964]: loss 0.045030
[epoch2, step965]: loss 0.046444
[epoch2, step966]: loss 0.043981
[epoch2, step967]: loss 0.043089
[epoch2, step968]: loss 0.046421
[epoch2, step969]: loss 0.045586
[epoch2, step970]: loss 0.045390
[epoch2, step971]: loss 0.044689
[epoch2, step972]: loss 0.045234
[epoch2, step973]: loss 0.044351
[epoch2, step974]: loss 0.048004
[epoch2, step975]: loss 0.044431
[epoch2, step976]: loss 0.043029
[epoch2, step977]: loss 0.047252
[epoch2, step978]: loss 0.045223
[epoch2, step979]: loss 0.045084
[epoch2, step980]: loss 0.044006
[epoch2, step981]: loss 0.044572
[epoch2, step982]: loss 0.044889
[epoch2, step983]: loss 0.047299
[epoch2, step984]: loss 0.043145
[epoch2, step985]: loss 0.043149
[epoch2, step986]: loss 0.047337
[epoch2, step987]: loss 0.045206
[epoch2, step988]: loss 0.045498
[epoch2, step989]: loss 0.044651
[epoch2, step990]: loss 0.043804
[epoch2, step991]: loss 0.044592
[epoch2, step992]: loss 0.046009
[epoch2, step993]: loss 0.043082
[epoch2, step994]: loss 0.041738
[epoch2, step995]: loss 0.045891
[epoch2, step996]: loss 0.043371
[epoch2, step997]: loss 0.044030
[epoch2, step998]: loss 0.043756
[epoch2, step999]: loss 0.043307
[epoch2, step1000]: loss 0.043595
[epoch2, step1001]: loss 0.045704
[epoch2, step1002]: loss 0.043051
[epoch2, step1003]: loss 0.041833
[epoch2, step1004]: loss 0.045146
[epoch2, step1005]: loss 0.042631
[epoch2, step1006]: loss 0.043853
[epoch2, step1007]: loss 0.042573
[epoch2, step1008]: loss 0.042548
[epoch2, step1009]: loss 0.043090
[epoch2, step1010]: loss 0.045766
[epoch2, step1011]: loss 0.042461
[epoch2, step1012]: loss 0.042129
[epoch2, step1013]: loss 0.045007
[epoch2, step1014]: loss 0.043832
[epoch2, step1015]: loss 0.044011
[epoch2, step1016]: loss 0.042443
[epoch2, step1017]: loss 0.042422
[epoch2, step1018]: loss 0.042789
[epoch2, step1019]: loss 0.045280
[epoch2, step1020]: loss 0.042040
[epoch2, step1021]: loss 0.041237
[epoch2, step1022]: loss 0.044480
[epoch2, step1023]: loss 0.042968
[epoch2, step1024]: loss 0.044150
[epoch2, step1025]: loss 0.042207
[epoch2, step1026]: loss 0.041936
[epoch2, step1027]: loss 0.042666
[epoch2, step1028]: loss 0.044904
[epoch2, step1029]: loss 0.042118
[epoch2, step1030]: loss 0.040978
[epoch2, step1031]: loss 0.043419
[epoch2, step1032]: loss 0.043150
[epoch2, step1033]: loss 0.042954
[epoch2, step1034]: loss 0.042266
[epoch2, step1035]: loss 0.041822
[epoch2, step1036]: loss 0.042940
[epoch2, step1037]: loss 0.044630
[epoch2, step1038]: loss 0.041928
[epoch2, step1039]: loss 0.041559
[epoch2, step1040]: loss 0.043857
[epoch2, step1041]: loss 0.042633
[epoch2, step1042]: loss 0.042296
[epoch2, step1043]: loss 0.042152
[epoch2, step1044]: loss 0.042282
[epoch2, step1045]: loss 0.042684
[epoch2, step1046]: loss 0.044864
[epoch2, step1047]: loss 0.042022
[epoch2, step1048]: loss 0.040894
[epoch2, step1049]: loss 0.044233
[epoch2, step1050]: loss 0.042867
[epoch2, step1051]: loss 0.042975
[epoch2, step1052]: loss 0.042486
[epoch2, step1053]: loss 0.042491
[epoch2, step1054]: loss 0.042459
[epoch2, step1055]: loss 0.043818
[epoch2, step1056]: loss 0.041061
[epoch2, step1057]: loss 0.041432
[epoch2, step1058]: loss 0.044772
[epoch2, step1059]: loss 0.042526
[epoch2, step1060]: loss 0.042847
[epoch2, step1061]: loss 0.041104
[epoch2, step1062]: loss 0.042214
[epoch2, step1063]: loss 0.042214
[epoch2, step1064]: loss 0.044161
[epoch2, step1065]: loss 0.041352
[epoch2, step1066]: loss 0.040118
[epoch2, step1067]: loss 0.044183
[epoch2, step1068]: loss 0.040783
[epoch2, step1069]: loss 0.041853
[epoch2, step1070]: loss 0.041526
[epoch2, step1071]: loss 0.042036
[epoch2, step1072]: loss 0.042812
[epoch2, step1073]: loss 0.043437
[epoch2, step1074]: loss 0.041046
[epoch2, step1075]: loss 0.040717
[epoch2, step1076]: loss 0.043287
[epoch2, step1077]: loss 0.041852
[epoch2, step1078]: loss 0.041654
[epoch2, step1079]: loss 0.041952
[epoch2, step1080]: loss 0.041209
[epoch2, step1081]: loss 0.041193
[epoch2, step1082]: loss 0.042943
[epoch2, step1083]: loss 0.041014
[epoch2, step1084]: loss 0.039882
[epoch2, step1085]: loss 0.042202
[epoch2, step1086]: loss 0.040756
[epoch2, step1087]: loss 0.041338
[epoch2, step1088]: loss 0.040058
[epoch2, step1089]: loss 0.040826
[epoch2, step1090]: loss 0.041778
[epoch2, step1091]: loss 0.042890
[epoch2, step1092]: loss 0.039773
[epoch2, step1093]: loss 0.039069
[epoch2, step1094]: loss 0.041441
[epoch2, step1095]: loss 0.040046
[epoch2, step1096]: loss 0.040283
[epoch2, step1097]: loss 0.039501
[epoch2, step1098]: loss 0.040386
[epoch2, step1099]: loss 0.040857
[epoch2, step1100]: loss 0.042624
[epoch2, step1101]: loss 0.040220
[epoch2, step1102]: loss 0.038681
[epoch2, step1103]: loss 0.041504
[epoch2, step1104]: loss 0.040999
[epoch2, step1105]: loss 0.041196
[epoch2, step1106]: loss 0.038286
[epoch2, step1107]: loss 0.040035
[epoch2, step1108]: loss 0.040287
[epoch2, step1109]: loss 0.042579
[epoch2, step1110]: loss 0.039409
[epoch2, step1111]: loss 0.038274
[epoch2, step1112]: loss 0.042010
[epoch2, step1113]: loss 0.039520
[epoch2, step1114]: loss 0.040350
[epoch2, step1115]: loss 0.038889
[epoch2, step1116]: loss 0.039654
[epoch2, step1117]: loss 0.039840
[epoch2, step1118]: loss 0.041441
[epoch2, step1119]: loss 0.038442
[epoch2, step1120]: loss 0.037935
[epoch2, step1121]: loss 0.041199
[epoch2, step1122]: loss 0.039177
[epoch2, step1123]: loss 0.039015
[epoch2, step1124]: loss 0.039494
[epoch2, step1125]: loss 0.039837
[epoch2, step1126]: loss 0.040662
[epoch2, step1127]: loss 0.041478
[epoch2, step1128]: loss 0.038705
[epoch2, step1129]: loss 0.038000
[epoch2, step1130]: loss 0.041987
[epoch2, step1131]: loss 0.039975
[epoch2, step1132]: loss 0.040038
[epoch2, step1133]: loss 0.037946
[epoch2, step1134]: loss 0.039110
[epoch2, step1135]: loss 0.040583
[epoch2, step1136]: loss 0.041942
[epoch2, step1137]: loss 0.038488
[epoch2, step1138]: loss 0.038026
[epoch2, step1139]: loss 0.041128
[epoch2, step1140]: loss 0.039025
[epoch2, step1141]: loss 0.039461
[epoch2, step1142]: loss 0.038033
[epoch2, step1143]: loss 0.038753
[epoch2, step1144]: loss 0.039663
[epoch2, step1145]: loss 0.040584
[epoch2, step1146]: loss 0.037843
[epoch2, step1147]: loss 0.039629
[epoch2, step1148]: loss 0.042412
[epoch2, step1149]: loss 0.039837
[epoch2, step1150]: loss 0.040000
[epoch2, step1151]: loss 0.039412
[epoch2, step1152]: loss 0.042697
[epoch2, step1153]: loss 0.042953
[epoch2, step1154]: loss 0.042436
[epoch2, step1155]: loss 0.040631
[epoch2, step1156]: loss 0.039680
[epoch2, step1157]: loss 0.042398
[epoch2, step1158]: loss 0.039454
[epoch2, step1159]: loss 0.040946
[epoch2, step1160]: loss 0.040831
[epoch2, step1161]: loss 0.040619
[epoch2, step1162]: loss 0.040507
[epoch2, step1163]: loss 0.042522
[epoch2, step1164]: loss 0.039875
[epoch2, step1165]: loss 0.040423
[epoch2, step1166]: loss 0.042650
[epoch2, step1167]: loss 0.040021
[epoch2, step1168]: loss 0.041045
[epoch2, step1169]: loss 0.039514
[epoch2, step1170]: loss 0.040475
[epoch2, step1171]: loss 0.040657
[epoch2, step1172]: loss 0.042640
[epoch2, step1173]: loss 0.039573
[epoch2, step1174]: loss 0.039265
[epoch2, step1175]: loss 0.041916
[epoch2, step1176]: loss 0.039809
[epoch2, step1177]: loss 0.040373
[epoch2, step1178]: loss 0.038977
[epoch2, step1179]: loss 0.039516
[epoch2, step1180]: loss 0.040192
[epoch2, step1181]: loss 0.042070
[epoch2, step1182]: loss 0.038035
[epoch2, step1183]: loss 0.038603
[epoch2, step1184]: loss 0.040868
[epoch2, step1185]: loss 0.041002
[epoch2, step1186]: loss 0.039051
[epoch2, step1187]: loss 0.037778
[epoch2, step1188]: loss 0.038849
[epoch2, step1189]: loss 0.040642
[epoch2, step1190]: loss 0.041899
[epoch2, step1191]: loss 0.039191
[epoch2, step1192]: loss 0.038599
[epoch2, step1193]: loss 0.041674
[epoch2, step1194]: loss 0.039549
[epoch2, step1195]: loss 0.038834
[epoch2, step1196]: loss 0.037919
[epoch2, step1197]: loss 0.039936
[epoch2, step1198]: loss 0.040044
[epoch2, step1199]: loss 0.041000
[epoch2, step1200]: loss 0.038153
[epoch2, step1201]: loss 0.038577
[epoch2, step1202]: loss 0.042036
[epoch2, step1203]: loss 0.039666
[epoch2, step1204]: loss 0.038994
[epoch2, step1205]: loss 0.037952
[epoch2, step1206]: loss 0.038707
[epoch2, step1207]: loss 0.040360
[epoch2, step1208]: loss 0.041311
[epoch2, step1209]: loss 0.037375
[epoch2, step1210]: loss 0.038952
[epoch2, step1211]: loss 0.040617
[epoch2, step1212]: loss 0.039430
[epoch2, step1213]: loss 0.039210
[epoch2, step1214]: loss 0.038452
[epoch2, step1215]: loss 0.040126
[epoch2, step1216]: loss 0.039033
[epoch2, step1217]: loss 0.041702
[epoch2, step1218]: loss 0.037810
[epoch2, step1219]: loss 0.038609
[epoch2, step1220]: loss 0.041256
[epoch2, step1221]: loss 0.038583
[epoch2, step1222]: loss 0.039458
[epoch2, step1223]: loss 0.038124
[epoch2, step1224]: loss 0.039611
[epoch2, step1225]: loss 0.039604
[epoch2, step1226]: loss 0.040607
[epoch2, step1227]: loss 0.038059
[epoch2, step1228]: loss 0.037678
[epoch2, step1229]: loss 0.040553
[epoch2, step1230]: loss 0.039724
[epoch2, step1231]: loss 0.039171
[epoch2, step1232]: loss 0.039370
[epoch2, step1233]: loss 0.039028
[epoch2, step1234]: loss 0.039305
[epoch2, step1235]: loss 0.041280
[epoch2, step1236]: loss 0.038462
[epoch2, step1237]: loss 0.037661
[epoch2, step1238]: loss 0.040171
[epoch2, step1239]: loss 0.040326
[epoch2, step1240]: loss 0.039665
[epoch2, step1241]: loss 0.038012
[epoch2, step1242]: loss 0.039537
[epoch2, step1243]: loss 0.039218
[epoch2, step1244]: loss 0.041683
[epoch2, step1245]: loss 0.038933
[epoch2, step1246]: loss 0.038041
[epoch2, step1247]: loss 0.039970
[epoch2, step1248]: loss 0.039201
[epoch2, step1249]: loss 0.039735
[epoch2, step1250]: loss 0.037870
[epoch2, step1251]: loss 0.039303
[epoch2, step1252]: loss 0.040246
[epoch2, step1253]: loss 0.041061
[epoch2, step1254]: loss 0.038062
[epoch2, step1255]: loss 0.037875
[epoch2, step1256]: loss 0.041180
[epoch2, step1257]: loss 0.039467
[epoch2, step1258]: loss 0.039455
[epoch2, step1259]: loss 0.037939
[epoch2, step1260]: loss 0.038490
[epoch2, step1261]: loss 0.039132
[epoch2, step1262]: loss 0.039495
[epoch2, step1263]: loss 0.038513
[epoch2, step1264]: loss 0.037533
[epoch2, step1265]: loss 0.039691
[epoch2, step1266]: loss 0.039135
[epoch2, step1267]: loss 0.039471
[epoch2, step1268]: loss 0.038232
[epoch2, step1269]: loss 0.039124
[epoch2, step1270]: loss 0.039208
[epoch2, step1271]: loss 0.041293
[epoch2, step1272]: loss 0.038394
[epoch2, step1273]: loss 0.038153
[epoch2, step1274]: loss 0.040715
[epoch2, step1275]: loss 0.039682
[epoch2, step1276]: loss 0.039390
[epoch2, step1277]: loss 0.037899
[epoch2, step1278]: loss 0.039863
[epoch2, step1279]: loss 0.039600
[epoch2, step1280]: loss 0.040821
[epoch2, step1281]: loss 0.037907
[epoch2, step1282]: loss 0.037639
[epoch2, step1283]: loss 0.040002
[epoch2, step1284]: loss 0.038519
[epoch2, step1285]: loss 0.039457
[epoch2, step1286]: loss 0.037275
[epoch2, step1287]: loss 0.039621
[epoch2, step1288]: loss 0.040200
[epoch2, step1289]: loss 0.041436
[epoch2, step1290]: loss 0.038080
[epoch2, step1291]: loss 0.037649
[epoch2, step1292]: loss 0.041098
[epoch2, step1293]: loss 0.038699
[epoch2, step1294]: loss 0.039305
[epoch2, step1295]: loss 0.038434
[epoch2, step1296]: loss 0.039529
[epoch2, step1297]: loss 0.039147
[epoch2, step1298]: loss 0.041383
[epoch2, step1299]: loss 0.038113
[epoch2, step1300]: loss 0.038231
[epoch2, step1301]: loss 0.039632
[epoch2, step1302]: loss 0.038986
[epoch2, step1303]: loss 0.039267
[epoch2, step1304]: loss 0.037161
[epoch2, step1305]: loss 0.039424
[epoch2, step1306]: loss 0.039243
[epoch2, step1307]: loss 0.040046
[epoch2, step1308]: loss 0.038022
[epoch2, step1309]: loss 0.036990
[epoch2, step1310]: loss 0.040632
[epoch2, step1311]: loss 0.037996
[epoch2, step1312]: loss 0.039837
[epoch2, step1313]: loss 0.038062
[epoch2, step1314]: loss 0.038822
[epoch2, step1315]: loss 0.040071
[epoch2, step1316]: loss 0.042806
[epoch2, step1317]: loss 0.037253
[epoch2, step1318]: loss 0.037391
[epoch2, step1319]: loss 0.040044
[epoch2, step1320]: loss 0.039145
[epoch2, step1321]: loss 0.039050
[epoch2, step1322]: loss 0.037389
[epoch2, step1323]: loss 0.039874
[epoch2, step1324]: loss 0.039318
[epoch2, step1325]: loss 0.040581
[epoch2, step1326]: loss 0.038596
[epoch2, step1327]: loss 0.038678
[epoch2, step1328]: loss 0.040940
[epoch2, step1329]: loss 0.039126
[epoch2, step1330]: loss 0.039911
[epoch2, step1331]: loss 0.037857
[epoch2, step1332]: loss 0.038877
[epoch2, step1333]: loss 0.039418
[epoch2, step1334]: loss 0.041788
[epoch2, step1335]: loss 0.038572
[epoch2, step1336]: loss 0.037998
[epoch2, step1337]: loss 0.040199
[epoch2, step1338]: loss 0.038867
[epoch2, step1339]: loss 0.039482
[epoch2, step1340]: loss 0.037702
[epoch2, step1341]: loss 0.039415
[epoch2, step1342]: loss 0.039202
[epoch2, step1343]: loss 0.040799
[epoch2, step1344]: loss 0.037998
[epoch2, step1345]: loss 0.037484
[epoch2, step1346]: loss 0.040005
[epoch2, step1347]: loss 0.039562
[epoch2, step1348]: loss 0.038331
[epoch2, step1349]: loss 0.037872
[epoch2, step1350]: loss 0.038987
[epoch2, step1351]: loss 0.038911
[epoch2, step1352]: loss 0.039926
[epoch2, step1353]: loss 0.037554
[epoch2, step1354]: loss 0.037420
[epoch2, step1355]: loss 0.040610
[epoch2, step1356]: loss 0.038929
[epoch2, step1357]: loss 0.038416
[epoch2, step1358]: loss 0.037662
[epoch2, step1359]: loss 0.038703
[epoch2, step1360]: loss 0.039327
[epoch2, step1361]: loss 0.040989
[epoch2, step1362]: loss 0.038314
[epoch2, step1363]: loss 0.038164
[epoch2, step1364]: loss 0.040296
[epoch2, step1365]: loss 0.038969
[epoch2, step1366]: loss 0.038750
[epoch2, step1367]: loss 0.036903
[epoch2, step1368]: loss 0.039912
[epoch2, step1369]: loss 0.039399
[epoch2, step1370]: loss 0.040135
[epoch2, step1371]: loss 0.037976
[epoch2, step1372]: loss 0.037530
[epoch2, step1373]: loss 0.040371
[epoch2, step1374]: loss 0.040027
[epoch2, step1375]: loss 0.039694
[epoch2, step1376]: loss 0.037576
[epoch2, step1377]: loss 0.038637
[epoch2, step1378]: loss 0.039254
[epoch2, step1379]: loss 0.039977
[epoch2, step1380]: loss 0.038213
[epoch2, step1381]: loss 0.037359
[epoch2, step1382]: loss 0.040609
[epoch2, step1383]: loss 0.038563
[epoch2, step1384]: loss 0.038607
[epoch2, step1385]: loss 0.037322
[epoch2, step1386]: loss 0.039098
[epoch2, step1387]: loss 0.039512
[epoch2, step1388]: loss 0.039248
[epoch2, step1389]: loss 0.036821
[epoch2, step1390]: loss 0.037417
[epoch2, step1391]: loss 0.040357
[epoch2, step1392]: loss 0.038798
[epoch2, step1393]: loss 0.039192
[epoch2, step1394]: loss 0.038474
[epoch2, step1395]: loss 0.039148
[epoch2, step1396]: loss 0.039290
[epoch2, step1397]: loss 0.041493
[epoch2, step1398]: loss 0.037637
[epoch2, step1399]: loss 0.038709
[epoch2, step1400]: loss 0.041450
[epoch2, step1401]: loss 0.038797
[epoch2, step1402]: loss 0.038905
[epoch2, step1403]: loss 0.036801
[epoch2, step1404]: loss 0.038295
[epoch2, step1405]: loss 0.038851
[epoch2, step1406]: loss 0.040039
[epoch2, step1407]: loss 0.038644
[epoch2, step1408]: loss 0.036588
[epoch2, step1409]: loss 0.039720
[epoch2, step1410]: loss 0.038594
[epoch2, step1411]: loss 0.037969
[epoch2, step1412]: loss 0.037980
[epoch2, step1413]: loss 0.038821
[epoch2, step1414]: loss 0.039505
[epoch2, step1415]: loss 0.041470
[epoch2, step1416]: loss 0.037853
[epoch2, step1417]: loss 0.038454
[epoch2, step1418]: loss 0.040911
[epoch2, step1419]: loss 0.039924
[epoch2, step1420]: loss 0.038997
[epoch2, step1421]: loss 0.038767
[epoch2, step1422]: loss 0.039583
[epoch2, step1423]: loss 0.038750
[epoch2, step1424]: loss 0.040927
[epoch2, step1425]: loss 0.037128
[epoch2, step1426]: loss 0.037987
[epoch2, step1427]: loss 0.041237
[epoch2, step1428]: loss 0.040694
[epoch2, step1429]: loss 0.040561
[epoch2, step1430]: loss 0.038107
[epoch2, step1431]: loss 0.039210
[epoch2, step1432]: loss 0.039142
[epoch2, step1433]: loss 0.040893
[epoch2, step1434]: loss 0.036995
[epoch2, step1435]: loss 0.037773
[epoch2, step1436]: loss 0.041075
[epoch2, step1437]: loss 0.039140
[epoch2, step1438]: loss 0.039467
[epoch2, step1439]: loss 0.037584
[epoch2, step1440]: loss 0.038672
[epoch2, step1441]: loss 0.039345
[epoch2, step1442]: loss 0.039801
[epoch2, step1443]: loss 0.037320
[epoch2, step1444]: loss 0.036507
[epoch2, step1445]: loss 0.040507
[epoch2, step1446]: loss 0.038825
[epoch2, step1447]: loss 0.039618
[epoch2, step1448]: loss 0.037309
[epoch2, step1449]: loss 0.038310
[epoch2, step1450]: loss 0.039126
[epoch2, step1451]: loss 0.040584
[epoch2, step1452]: loss 0.037209
[epoch2, step1453]: loss 0.038303
[epoch2, step1454]: loss 0.040721
[epoch2, step1455]: loss 0.039289
[epoch2, step1456]: loss 0.038258
[epoch2, step1457]: loss 0.037952
[epoch2, step1458]: loss 0.038818
[epoch2, step1459]: loss 0.039131
[epoch2, step1460]: loss 0.040682
[epoch2, step1461]: loss 0.038213
[epoch2, step1462]: loss 0.038686
[epoch2, step1463]: loss 0.040519
[epoch2, step1464]: loss 0.037772
[epoch2, step1465]: loss 0.037166
[epoch2, step1466]: loss 0.037641
[epoch2, step1467]: loss 0.039874
[epoch2, step1468]: loss 0.039390
[epoch2, step1469]: loss 0.040207
[epoch2, step1470]: loss 0.035391
[epoch2, step1471]: loss 0.035589
[epoch2, step1472]: loss 0.038827
[epoch2, step1473]: loss 0.038746
[epoch2, step1474]: loss 0.039544
[epoch2, step1475]: loss 0.037132
[epoch2, step1476]: loss 0.039739
[epoch2, step1477]: loss 0.039481
[epoch2, step1478]: loss 0.041093
[epoch2, step1479]: loss 0.037612
[epoch2, step1480]: loss 0.037852
[epoch2, step1481]: loss 0.039569
[epoch2, step1482]: loss 0.039149
[epoch2, step1483]: loss 0.039549
[epoch2, step1484]: loss 0.037784
[epoch2, step1485]: loss 0.038849
[epoch2, step1486]: loss 0.037935
[epoch2, step1487]: loss 0.040292
[epoch2, step1488]: loss 0.037512
[epoch2, step1489]: loss 0.037322
[epoch2, step1490]: loss 0.040498
[epoch2, step1491]: loss 0.039011
[epoch2, step1492]: loss 0.038741
[epoch2, step1493]: loss 0.037304
[epoch2, step1494]: loss 0.039110
[epoch2, step1495]: loss 0.038871
[epoch2, step1496]: loss 0.039628
[epoch2, step1497]: loss 0.037750
[epoch2, step1498]: loss 0.037618
[epoch2, step1499]: loss 0.039668
[epoch2, step1500]: loss 0.039211
[epoch2, step1501]: loss 0.038734
[epoch2, step1502]: loss 0.037234
[epoch2, step1503]: loss 0.039018
[epoch2, step1504]: loss 0.038388
[epoch2, step1505]: loss 0.040727
[epoch2, step1506]: loss 0.036709
[epoch2, step1507]: loss 0.037781
[epoch2, step1508]: loss 0.040816
[epoch2, step1509]: loss 0.038628
[epoch2, step1510]: loss 0.037915
[epoch2, step1511]: loss 0.038073
[epoch2, step1512]: loss 0.039116
[epoch2, step1513]: loss 0.037541
[epoch2, step1514]: loss 0.040246
[epoch2, step1515]: loss 0.037890
[epoch2, step1516]: loss 0.037261

[epoch2]: avg loss 0.037416

[epoch3, step1]: loss 0.032401
[epoch3, step2]: loss 0.043402
[epoch3, step3]: loss 0.044633
[epoch3, step4]: loss 0.040086
[epoch3, step5]: loss 0.037436
[epoch3, step6]: loss 0.041042
[epoch3, step7]: loss 0.039194
[epoch3, step8]: loss 0.041892
[epoch3, step9]: loss 0.037239
[epoch3, step10]: loss 0.038156
[epoch3, step11]: loss 0.042355
[epoch3, step12]: loss 0.042916
[epoch3, step13]: loss 0.038711
[epoch3, step14]: loss 0.037391
[epoch3, step15]: loss 0.040318
[epoch3, step16]: loss 0.038304
[epoch3, step17]: loss 0.040831
[epoch3, step18]: loss 0.037641
[epoch3, step19]: loss 0.037603
[epoch3, step20]: loss 0.041594
[epoch3, step21]: loss 0.039725
[epoch3, step22]: loss 0.036862
[epoch3, step23]: loss 0.036978
[epoch3, step24]: loss 0.040185
[epoch3, step25]: loss 0.037522
[epoch3, step26]: loss 0.040491
[epoch3, step27]: loss 0.036666
[epoch3, step28]: loss 0.038106
[epoch3, step29]: loss 0.040882
[epoch3, step30]: loss 0.041235
[epoch3, step31]: loss 0.036691
[epoch3, step32]: loss 0.037674
[epoch3, step33]: loss 0.040898
[epoch3, step34]: loss 0.038778
[epoch3, step35]: loss 0.041117
[epoch3, step36]: loss 0.037415
[epoch3, step37]: loss 0.037873
[epoch3, step38]: loss 0.039978
[epoch3, step39]: loss 0.040401
[epoch3, step40]: loss 0.037416
[epoch3, step41]: loss 0.037352
[epoch3, step42]: loss 0.040837
[epoch3, step43]: loss 0.037722
[epoch3, step44]: loss 0.040706
[epoch3, step45]: loss 0.037415
[epoch3, step46]: loss 0.037685
[epoch3, step47]: loss 0.039615
[epoch3, step48]: loss 0.039655
[epoch3, step49]: loss 0.035964
[epoch3, step50]: loss 0.037717
[epoch3, step51]: loss 0.039766
[epoch3, step52]: loss 0.037614
[epoch3, step53]: loss 0.041151
[epoch3, step54]: loss 0.036949
[epoch3, step55]: loss 0.038331
[epoch3, step56]: loss 0.041635
[epoch3, step57]: loss 0.040845
[epoch3, step58]: loss 0.037052
[epoch3, step59]: loss 0.037239
[epoch3, step60]: loss 0.041114
[epoch3, step61]: loss 0.037395
[epoch3, step62]: loss 0.039802
[epoch3, step63]: loss 0.037074
[epoch3, step64]: loss 0.037126
[epoch3, step65]: loss 0.040425
[epoch3, step66]: loss 0.039855
[epoch3, step67]: loss 0.037287
[epoch3, step68]: loss 0.037610
[epoch3, step69]: loss 0.040121
[epoch3, step70]: loss 0.037367
[epoch3, step71]: loss 0.039998
[epoch3, step72]: loss 0.036944
[epoch3, step73]: loss 0.037423
[epoch3, step74]: loss 0.040069
[epoch3, step75]: loss 0.040154
[epoch3, step76]: loss 0.037724
[epoch3, step77]: loss 0.037794
[epoch3, step78]: loss 0.040120
[epoch3, step79]: loss 0.036627
[epoch3, step80]: loss 0.040915
[epoch3, step81]: loss 0.036832
[epoch3, step82]: loss 0.037037
[epoch3, step83]: loss 0.039569
[epoch3, step84]: loss 0.039681
[epoch3, step85]: loss 0.037805
[epoch3, step86]: loss 0.037646
[epoch3, step87]: loss 0.041032
[epoch3, step88]: loss 0.036547
[epoch3, step89]: loss 0.040045
[epoch3, step90]: loss 0.037817
[epoch3, step91]: loss 0.037242
[epoch3, step92]: loss 0.040422
[epoch3, step93]: loss 0.040100
[epoch3, step94]: loss 0.037383
[epoch3, step95]: loss 0.037805
[epoch3, step96]: loss 0.040150
[epoch3, step97]: loss 0.037860
[epoch3, step98]: loss 0.040210
[epoch3, step99]: loss 0.037489
[epoch3, step100]: loss 0.036790
[epoch3, step101]: loss 0.040475
[epoch3, step102]: loss 0.040288
[epoch3, step103]: loss 0.036916
[epoch3, step104]: loss 0.036938
[epoch3, step105]: loss 0.040003
[epoch3, step106]: loss 0.037791
[epoch3, step107]: loss 0.040151
[epoch3, step108]: loss 0.037055
[epoch3, step109]: loss 0.036931
[epoch3, step110]: loss 0.040762
[epoch3, step111]: loss 0.040032
[epoch3, step112]: loss 0.037239
[epoch3, step113]: loss 0.038047
[epoch3, step114]: loss 0.039945
[epoch3, step115]: loss 0.037201
[epoch3, step116]: loss 0.041251
[epoch3, step117]: loss 0.036747
[epoch3, step118]: loss 0.038134
[epoch3, step119]: loss 0.040262
[epoch3, step120]: loss 0.040432
[epoch3, step121]: loss 0.036951
[epoch3, step122]: loss 0.036966
[epoch3, step123]: loss 0.040210
[epoch3, step124]: loss 0.037579
[epoch3, step125]: loss 0.040541
[epoch3, step126]: loss 0.037122
[epoch3, step127]: loss 0.037033
[epoch3, step128]: loss 0.040301
[epoch3, step129]: loss 0.040180
[epoch3, step130]: loss 0.036974
[epoch3, step131]: loss 0.036598
[epoch3, step132]: loss 0.040031
[epoch3, step133]: loss 0.036850
[epoch3, step134]: loss 0.039475
[epoch3, step135]: loss 0.037121
[epoch3, step136]: loss 0.038238
[epoch3, step137]: loss 0.039897
[epoch3, step138]: loss 0.040009
[epoch3, step139]: loss 0.036946
[epoch3, step140]: loss 0.037949
[epoch3, step141]: loss 0.040414
[epoch3, step142]: loss 0.037060
[epoch3, step143]: loss 0.039651
[epoch3, step144]: loss 0.038275
[epoch3, step145]: loss 0.038427
[epoch3, step146]: loss 0.040312
[epoch3, step147]: loss 0.041696
[epoch3, step148]: loss 0.037329
[epoch3, step149]: loss 0.037164
[epoch3, step150]: loss 0.040217
[epoch3, step151]: loss 0.037586
[epoch3, step152]: loss 0.040049
[epoch3, step153]: loss 0.037389
[epoch3, step154]: loss 0.037236
[epoch3, step155]: loss 0.040866
[epoch3, step156]: loss 0.039508
[epoch3, step157]: loss 0.036890
[epoch3, step158]: loss 0.038280
[epoch3, step159]: loss 0.040513
[epoch3, step160]: loss 0.037127
[epoch3, step161]: loss 0.040666
[epoch3, step162]: loss 0.037532
[epoch3, step163]: loss 0.036682
[epoch3, step164]: loss 0.040354
[epoch3, step165]: loss 0.039954
[epoch3, step166]: loss 0.037400
[epoch3, step167]: loss 0.036516
[epoch3, step168]: loss 0.040898
[epoch3, step169]: loss 0.036535
[epoch3, step170]: loss 0.040190
[epoch3, step171]: loss 0.037002
[epoch3, step172]: loss 0.037096
[epoch3, step173]: loss 0.040406
[epoch3, step174]: loss 0.039327
[epoch3, step175]: loss 0.037960
[epoch3, step176]: loss 0.037292
[epoch3, step177]: loss 0.040045
[epoch3, step178]: loss 0.037599
[epoch3, step179]: loss 0.039279
[epoch3, step180]: loss 0.036859
[epoch3, step181]: loss 0.037382
[epoch3, step182]: loss 0.040559
[epoch3, step183]: loss 0.040936
[epoch3, step184]: loss 0.038057
[epoch3, step185]: loss 0.037695
[epoch3, step186]: loss 0.040421
[epoch3, step187]: loss 0.037154
[epoch3, step188]: loss 0.039955
[epoch3, step189]: loss 0.036615
[epoch3, step190]: loss 0.036850
[epoch3, step191]: loss 0.042295
[epoch3, step192]: loss 0.043026
[epoch3, step193]: loss 0.037275
[epoch3, step194]: loss 0.038459
[epoch3, step195]: loss 0.041236
[epoch3, step196]: loss 0.035617
[epoch3, step197]: loss 0.039481
[epoch3, step198]: loss 0.037078
[epoch3, step199]: loss 0.037288
[epoch3, step200]: loss 0.039322
[epoch3, step201]: loss 0.039403
[epoch3, step202]: loss 0.035829
[epoch3, step203]: loss 0.037087
[epoch3, step204]: loss 0.040295
[epoch3, step205]: loss 0.034692
[epoch3, step206]: loss 0.037820
[epoch3, step207]: loss 0.034303
[epoch3, step208]: loss 0.037241
[epoch3, step209]: loss 0.039937
[epoch3, step210]: loss 0.040828
[epoch3, step211]: loss 0.036964
[epoch3, step212]: loss 0.035796
[epoch3, step213]: loss 0.039488
[epoch3, step214]: loss 0.037115
[epoch3, step215]: loss 0.039515
[epoch3, step216]: loss 0.035546
[epoch3, step217]: loss 0.035280
[epoch3, step218]: loss 0.040807
[epoch3, step219]: loss 0.039909
[epoch3, step220]: loss 0.038038
[epoch3, step221]: loss 0.038043
[epoch3, step222]: loss 0.040827
[epoch3, step223]: loss 0.036667
[epoch3, step224]: loss 0.039054
[epoch3, step225]: loss 0.036933
[epoch3, step226]: loss 0.037283
[epoch3, step227]: loss 0.039916
[epoch3, step228]: loss 0.039476
[epoch3, step229]: loss 0.036554
[epoch3, step230]: loss 0.035982
[epoch3, step231]: loss 0.038673
[epoch3, step232]: loss 0.035720
[epoch3, step233]: loss 0.038996
[epoch3, step234]: loss 0.035593
[epoch3, step235]: loss 0.038077
[epoch3, step236]: loss 0.039972
[epoch3, step237]: loss 0.038192
[epoch3, step238]: loss 0.035263
[epoch3, step239]: loss 0.035776
[epoch3, step240]: loss 0.039179
[epoch3, step241]: loss 0.036191
[epoch3, step242]: loss 0.039711
[epoch3, step243]: loss 0.036306
[epoch3, step244]: loss 0.035465
[epoch3, step245]: loss 0.039346
[epoch3, step246]: loss 0.039275
[epoch3, step247]: loss 0.037361
[epoch3, step248]: loss 0.036392
[epoch3, step249]: loss 0.037655
[epoch3, step250]: loss 0.037081
[epoch3, step251]: loss 0.040223
[epoch3, step252]: loss 0.036556
[epoch3, step253]: loss 0.036980
[epoch3, step254]: loss 0.039911
[epoch3, step255]: loss 0.040340
[epoch3, step256]: loss 0.037459
[epoch3, step257]: loss 0.036815
[epoch3, step258]: loss 0.039759
[epoch3, step259]: loss 0.036456
[epoch3, step260]: loss 0.039319
[epoch3, step261]: loss 0.036294
[epoch3, step262]: loss 0.037150
[epoch3, step263]: loss 0.038822
[epoch3, step264]: loss 0.038049
[epoch3, step265]: loss 0.036402
[epoch3, step266]: loss 0.035748
[epoch3, step267]: loss 0.038558
[epoch3, step268]: loss 0.035878
[epoch3, step269]: loss 0.039063
[epoch3, step270]: loss 0.035445
[epoch3, step271]: loss 0.035897
[epoch3, step272]: loss 0.039766
[epoch3, step273]: loss 0.039033
[epoch3, step274]: loss 0.035578
[epoch3, step275]: loss 0.035307
[epoch3, step276]: loss 0.038330
[epoch3, step277]: loss 0.038486
[epoch3, step278]: loss 0.040927
[epoch3, step279]: loss 0.034746
[epoch3, step280]: loss 0.037049
[epoch3, step281]: loss 0.038533
[epoch3, step282]: loss 0.039645
[epoch3, step283]: loss 0.035237
[epoch3, step284]: loss 0.035059
[epoch3, step285]: loss 0.040134
[epoch3, step286]: loss 0.036390
[epoch3, step287]: loss 0.040212
[epoch3, step288]: loss 0.035511
[epoch3, step289]: loss 0.036473
[epoch3, step290]: loss 0.039012
[epoch3, step291]: loss 0.038556
[epoch3, step292]: loss 0.035394
[epoch3, step293]: loss 0.035554
[epoch3, step294]: loss 0.038581
[epoch3, step295]: loss 0.034848
[epoch3, step296]: loss 0.042076
[epoch3, step297]: loss 0.036351
[epoch3, step298]: loss 0.037607
[epoch3, step299]: loss 0.039025
[epoch3, step300]: loss 0.039056
[epoch3, step301]: loss 0.035977
[epoch3, step302]: loss 0.035757
[epoch3, step303]: loss 0.039498
[epoch3, step304]: loss 0.037030
[epoch3, step305]: loss 0.039776
[epoch3, step306]: loss 0.036804
[epoch3, step307]: loss 0.036746
[epoch3, step308]: loss 0.040657
[epoch3, step309]: loss 0.041086
[epoch3, step310]: loss 0.036374
[epoch3, step311]: loss 0.036351
[epoch3, step312]: loss 0.038868
[epoch3, step313]: loss 0.036116
[epoch3, step314]: loss 0.038897
[epoch3, step315]: loss 0.037709
[epoch3, step316]: loss 0.035962
[epoch3, step317]: loss 0.040230
[epoch3, step318]: loss 0.039432
[epoch3, step319]: loss 0.035556
[epoch3, step320]: loss 0.035792
[epoch3, step321]: loss 0.039136
[epoch3, step322]: loss 0.036677
[epoch3, step323]: loss 0.038060
[epoch3, step324]: loss 0.037594
[epoch3, step325]: loss 0.036216
[epoch3, step326]: loss 0.038696
[epoch3, step327]: loss 0.038402
[epoch3, step328]: loss 0.036275
[epoch3, step329]: loss 0.034491
[epoch3, step330]: loss 0.038147
[epoch3, step331]: loss 0.036570
[epoch3, step332]: loss 0.037687
[epoch3, step333]: loss 0.035898
[epoch3, step334]: loss 0.036066
[epoch3, step335]: loss 0.038677
[epoch3, step336]: loss 0.040082
[epoch3, step337]: loss 0.036006
[epoch3, step338]: loss 0.035913
[epoch3, step339]: loss 0.039460
[epoch3, step340]: loss 0.036192
[epoch3, step341]: loss 0.038880
[epoch3, step342]: loss 0.035575
[epoch3, step343]: loss 0.036675
[epoch3, step344]: loss 0.038259
[epoch3, step345]: loss 0.037999
[epoch3, step346]: loss 0.036668
[epoch3, step347]: loss 0.037217
[epoch3, step348]: loss 0.041328
[epoch3, step349]: loss 0.039390
[epoch3, step350]: loss 0.039778
[epoch3, step351]: loss 0.037781
[epoch3, step352]: loss 0.038560
[epoch3, step353]: loss 0.040910
[epoch3, step354]: loss 0.039816
[epoch3, step355]: loss 0.036048
[epoch3, step356]: loss 0.039187
[epoch3, step357]: loss 0.040640
[epoch3, step358]: loss 0.034554
[epoch3, step359]: loss 0.040793
[epoch3, step360]: loss 0.035260
[epoch3, step361]: loss 0.036286
[epoch3, step362]: loss 0.039867
[epoch3, step363]: loss 0.039151
[epoch3, step364]: loss 0.036203
[epoch3, step365]: loss 0.036012
[epoch3, step366]: loss 0.040831
[epoch3, step367]: loss 0.036533
[epoch3, step368]: loss 0.038870
[epoch3, step369]: loss 0.036663
[epoch3, step370]: loss 0.037545
[epoch3, step371]: loss 0.039575
[epoch3, step372]: loss 0.038823
[epoch3, step373]: loss 0.036380
[epoch3, step374]: loss 0.039644
[epoch3, step375]: loss 0.044571
[epoch3, step376]: loss 0.037757
[epoch3, step377]: loss 0.038803
[epoch3, step378]: loss 0.036691
[epoch3, step379]: loss 0.036808
[epoch3, step380]: loss 0.040374
[epoch3, step381]: loss 0.039610
[epoch3, step382]: loss 0.036474
[epoch3, step383]: loss 0.035505
[epoch3, step384]: loss 0.041373
[epoch3, step385]: loss 0.038461
[epoch3, step386]: loss 0.040871
[epoch3, step387]: loss 0.035045
[epoch3, step388]: loss 0.036647
[epoch3, step389]: loss 0.040406
[epoch3, step390]: loss 0.040120
[epoch3, step391]: loss 0.037092
[epoch3, step392]: loss 0.036485
[epoch3, step393]: loss 0.038914
[epoch3, step394]: loss 0.037006
[epoch3, step395]: loss 0.041693
[epoch3, step396]: loss 0.037107
[epoch3, step397]: loss 0.035463
[epoch3, step398]: loss 0.038964
[epoch3, step399]: loss 0.039131
[epoch3, step400]: loss 0.035306
[epoch3, step401]: loss 0.035052
[epoch3, step402]: loss 0.038156
[epoch3, step403]: loss 0.036020
[epoch3, step404]: loss 0.040123
[epoch3, step405]: loss 0.035182
[epoch3, step406]: loss 0.036480
[epoch3, step407]: loss 0.038944
[epoch3, step408]: loss 0.038795
[epoch3, step409]: loss 0.037234
[epoch3, step410]: loss 0.035536
[epoch3, step411]: loss 0.038571
[epoch3, step412]: loss 0.035333
[epoch3, step413]: loss 0.038498
[epoch3, step414]: loss 0.035798
[epoch3, step415]: loss 0.036767
[epoch3, step416]: loss 0.037669
[epoch3, step417]: loss 0.040101
[epoch3, step418]: loss 0.036876
[epoch3, step419]: loss 0.034251
[epoch3, step420]: loss 0.039596
[epoch3, step421]: loss 0.035889
[epoch3, step422]: loss 0.039383
[epoch3, step423]: loss 0.035677
[epoch3, step424]: loss 0.036672
[epoch3, step425]: loss 0.038854
[epoch3, step426]: loss 0.038602
[epoch3, step427]: loss 0.035916
[epoch3, step428]: loss 0.035173
[epoch3, step429]: loss 0.039491
[epoch3, step430]: loss 0.036155
[epoch3, step431]: loss 0.039201
[epoch3, step432]: loss 0.034936
[epoch3, step433]: loss 0.037913
[epoch3, step434]: loss 0.038843
[epoch3, step435]: loss 0.039307
[epoch3, step436]: loss 0.034832
[epoch3, step437]: loss 0.036187
[epoch3, step438]: loss 0.039631
[epoch3, step439]: loss 0.036036
[epoch3, step440]: loss 0.039145
[epoch3, step441]: loss 0.035635
[epoch3, step442]: loss 0.035240
[epoch3, step443]: loss 0.038982
[epoch3, step444]: loss 0.038237
[epoch3, step445]: loss 0.035579
[epoch3, step446]: loss 0.035502
[epoch3, step447]: loss 0.038921
[epoch3, step448]: loss 0.036627
[epoch3, step449]: loss 0.038145
[epoch3, step450]: loss 0.034807
[epoch3, step451]: loss 0.034515
[epoch3, step452]: loss 0.038165
[epoch3, step453]: loss 0.039105
[epoch3, step454]: loss 0.035419
[epoch3, step455]: loss 0.036628
[epoch3, step456]: loss 0.038406
[epoch3, step457]: loss 0.035822
[epoch3, step458]: loss 0.038427
[epoch3, step459]: loss 0.035627
[epoch3, step460]: loss 0.035423
[epoch3, step461]: loss 0.039291
[epoch3, step462]: loss 0.038252
[epoch3, step463]: loss 0.036493
[epoch3, step464]: loss 0.035067
[epoch3, step465]: loss 0.041767
[epoch3, step466]: loss 0.035221
[epoch3, step467]: loss 0.037724
[epoch3, step468]: loss 0.035468
[epoch3, step469]: loss 0.035238
[epoch3, step470]: loss 0.038902
[epoch3, step471]: loss 0.038407
[epoch3, step472]: loss 0.035749
[epoch3, step473]: loss 0.035871
[epoch3, step474]: loss 0.039176
[epoch3, step475]: loss 0.036339
[epoch3, step476]: loss 0.039127
[epoch3, step477]: loss 0.035445
[epoch3, step478]: loss 0.035113
[epoch3, step479]: loss 0.039334
[epoch3, step480]: loss 0.038066
[epoch3, step481]: loss 0.034513
[epoch3, step482]: loss 0.034448
[epoch3, step483]: loss 0.040969
[epoch3, step484]: loss 0.037248
[epoch3, step485]: loss 0.040766
[epoch3, step486]: loss 0.037479
[epoch3, step487]: loss 0.035249
[epoch3, step488]: loss 0.040020
[epoch3, step489]: loss 0.038135
[epoch3, step490]: loss 0.036546
[epoch3, step491]: loss 0.035493
[epoch3, step492]: loss 0.038864
[epoch3, step493]: loss 0.035566
[epoch3, step494]: loss 0.038436
[epoch3, step495]: loss 0.037988
[epoch3, step496]: loss 0.035875
[epoch3, step497]: loss 0.039812
[epoch3, step498]: loss 0.038465
[epoch3, step499]: loss 0.035394
[epoch3, step500]: loss 0.034710
[epoch3, step501]: loss 0.038100
[epoch3, step502]: loss 0.035770
[epoch3, step503]: loss 0.041271
[epoch3, step504]: loss 0.036576
[epoch3, step505]: loss 0.035363
[epoch3, step506]: loss 0.040047
[epoch3, step507]: loss 0.039839
[epoch3, step508]: loss 0.036701
[epoch3, step509]: loss 0.034991
[epoch3, step510]: loss 0.038588
[epoch3, step511]: loss 0.036705
[epoch3, step512]: loss 0.038920
[epoch3, step513]: loss 0.035920
[epoch3, step514]: loss 0.035856
[epoch3, step515]: loss 0.039025
[epoch3, step516]: loss 0.038631
[epoch3, step517]: loss 0.035474
[epoch3, step518]: loss 0.035679
[epoch3, step519]: loss 0.039111
[epoch3, step520]: loss 0.035749
[epoch3, step521]: loss 0.038344
[epoch3, step522]: loss 0.034981
[epoch3, step523]: loss 0.035797
[epoch3, step524]: loss 0.038400
[epoch3, step525]: loss 0.040506
[epoch3, step526]: loss 0.037305
[epoch3, step527]: loss 0.036246
[epoch3, step528]: loss 0.039656
[epoch3, step529]: loss 0.034576
[epoch3, step530]: loss 0.038841
[epoch3, step531]: loss 0.035138
[epoch3, step532]: loss 0.036245
[epoch3, step533]: loss 0.039566
[epoch3, step534]: loss 0.038907
[epoch3, step535]: loss 0.036435
[epoch3, step536]: loss 0.035984
[epoch3, step537]: loss 0.039510
[epoch3, step538]: loss 0.036259
[epoch3, step539]: loss 0.038232
[epoch3, step540]: loss 0.036684
[epoch3, step541]: loss 0.035348
[epoch3, step542]: loss 0.037912
[epoch3, step543]: loss 0.038241
[epoch3, step544]: loss 0.035556
[epoch3, step545]: loss 0.035116
[epoch3, step546]: loss 0.040444
[epoch3, step547]: loss 0.035637
[epoch3, step548]: loss 0.038643
[epoch3, step549]: loss 0.036246
[epoch3, step550]: loss 0.034933
[epoch3, step551]: loss 0.040302
[epoch3, step552]: loss 0.038983
[epoch3, step553]: loss 0.037115
[epoch3, step554]: loss 0.034641
[epoch3, step555]: loss 0.038410
[epoch3, step556]: loss 0.035499
[epoch3, step557]: loss 0.037602
[epoch3, step558]: loss 0.036006
[epoch3, step559]: loss 0.035613
[epoch3, step560]: loss 0.039883
[epoch3, step561]: loss 0.037797
[epoch3, step562]: loss 0.036023
[epoch3, step563]: loss 0.030622
[epoch3, step564]: loss 0.030494
[epoch3, step565]: loss 0.027741
[epoch3, step566]: loss 0.035783
[epoch3, step567]: loss 0.027982
[epoch3, step568]: loss 0.026174
[epoch3, step569]: loss 0.025069
[epoch3, step570]: loss 0.032860
[epoch3, step571]: loss 0.026007
[epoch3, step572]: loss 0.026367
[epoch3, step573]: loss 0.032828
[epoch3, step574]: loss 0.030829
[epoch3, step575]: loss 0.021043
[epoch3, step576]: loss 0.022737
[epoch3, step577]: loss 0.026456
[epoch3, step578]: loss 0.018696
[epoch3, step579]: loss 0.030562
[epoch3, step580]: loss 0.020902
[epoch3, step581]: loss 0.028186
[epoch3, step582]: loss 0.024442
[epoch3, step583]: loss 0.021906
[epoch3, step584]: loss 0.024138
[epoch3, step585]: loss 0.025732
[epoch3, step586]: loss 0.021543
[epoch3, step587]: loss 0.027719
[epoch3, step588]: loss 0.024011
[epoch3, step589]: loss 0.022969
[epoch3, step590]: loss 0.026977
[epoch3, step591]: loss 0.021021
[epoch3, step592]: loss 0.027109
[epoch3, step593]: loss 0.021960
[epoch3, step594]: loss 0.024903
[epoch3, step595]: loss 0.026680
[epoch3, step596]: loss 0.023372
[epoch3, step597]: loss 0.025838
[epoch3, step598]: loss 0.027427
[epoch3, step599]: loss 0.024740
[epoch3, step600]: loss 0.026710
[epoch3, step601]: loss 0.019879
[epoch3, step602]: loss 0.023924
[epoch3, step603]: loss 0.026488
[epoch3, step604]: loss 0.027035
[epoch3, step605]: loss 0.024966
[epoch3, step606]: loss 0.024836
[epoch3, step607]: loss 0.026301
[epoch3, step608]: loss 0.025761
[epoch3, step609]: loss 0.026422
[epoch3, step610]: loss 0.026491
[epoch3, step611]: loss 0.026189
[epoch3, step612]: loss 0.025746
[epoch3, step613]: loss 0.019525
[epoch3, step614]: loss 0.024888
[epoch3, step615]: loss 0.027922
[epoch3, step616]: loss 0.024231
[epoch3, step617]: loss 0.023205
[epoch3, step618]: loss 0.025526
[epoch3, step619]: loss 0.027196
[epoch3, step620]: loss 0.024465
[epoch3, step621]: loss 0.026569
[epoch3, step622]: loss 0.020753
[epoch3, step623]: loss 0.024909
[epoch3, step624]: loss 0.026452
[epoch3, step625]: loss 0.026173
[epoch3, step626]: loss 0.028174
[epoch3, step627]: loss 0.023149
[epoch3, step628]: loss 0.026481
[epoch3, step629]: loss 0.021894
[epoch3, step630]: loss 0.024592
[epoch3, step631]: loss 0.031944
[epoch3, step632]: loss 0.024872
[epoch3, step633]: loss 0.025408
[epoch3, step634]: loss 0.027279
[epoch3, step635]: loss 0.026280
[epoch3, step636]: loss 0.021382
[epoch3, step637]: loss 0.027617
[epoch3, step638]: loss 0.027304
[epoch3, step639]: loss 0.023707
[epoch3, step640]: loss 0.029563
[epoch3, step641]: loss 0.030570
[epoch3, step642]: loss 0.025592
[epoch3, step643]: loss 0.026444
[epoch3, step644]: loss 0.026365
[epoch3, step645]: loss 0.024227
[epoch3, step646]: loss 0.026964
[epoch3, step647]: loss 0.024160
[epoch3, step648]: loss 0.023708
[epoch3, step649]: loss 0.028926
[epoch3, step650]: loss 0.022735
[epoch3, step651]: loss 0.026675
[epoch3, step652]: loss 0.027061
[epoch3, step653]: loss 0.028379
[epoch3, step654]: loss 0.023529
[epoch3, step655]: loss 0.024275
[epoch3, step656]: loss 0.021869
[epoch3, step657]: loss 0.028192
[epoch3, step658]: loss 0.025575
[epoch3, step659]: loss 0.028029
[epoch3, step660]: loss 0.024058
[epoch3, step661]: loss 0.027078
[epoch3, step662]: loss 0.024188
[epoch3, step663]: loss 0.021567
[epoch3, step664]: loss 0.025289
[epoch3, step665]: loss 0.028387
[epoch3, step666]: loss 0.027034
[epoch3, step667]: loss 0.026906
[epoch3, step668]: loss 0.022677
[epoch3, step669]: loss 0.026880
[epoch3, step670]: loss 0.027803
[epoch3, step671]: loss 0.021399
[epoch3, step672]: loss 0.024359
[epoch3, step673]: loss 0.022368
[epoch3, step674]: loss 0.021545
[epoch3, step675]: loss 0.020382
[epoch3, step676]: loss 0.024639
[epoch3, step677]: loss 0.025653
[epoch3, step678]: loss 0.023586
[epoch3, step679]: loss 0.024355
[epoch3, step680]: loss 0.030746
[epoch3, step681]: loss 0.022324
[epoch3, step682]: loss 0.026379
[epoch3, step683]: loss 0.025923
[epoch3, step684]: loss 0.025124
[epoch3, step685]: loss 0.024449
[epoch3, step686]: loss 0.027554
[epoch3, step687]: loss 0.026931
[epoch3, step688]: loss 0.023379
[epoch3, step689]: loss 0.024573
[epoch3, step690]: loss 0.025812
[epoch3, step691]: loss 0.024664
[epoch3, step692]: loss 0.022891
[epoch3, step693]: loss 0.028189
[epoch3, step694]: loss 0.023088
[epoch3, step695]: loss 0.027031
[epoch3, step696]: loss 0.025836
[epoch3, step697]: loss 0.027792
[epoch3, step698]: loss 0.025256
[epoch3, step699]: loss 0.023615
[epoch3, step700]: loss 0.022088
[epoch3, step701]: loss 0.026279
[epoch3, step702]: loss 0.022093
[epoch3, step703]: loss 0.023565
[epoch3, step704]: loss 0.026112
[epoch3, step705]: loss 0.025202
[epoch3, step706]: loss 0.024073
[epoch3, step707]: loss 0.024382
[epoch3, step708]: loss 0.026473
[epoch3, step709]: loss 0.027749
[epoch3, step710]: loss 0.024381
[epoch3, step711]: loss 0.024380
[epoch3, step712]: loss 0.027319
[epoch3, step713]: loss 0.026637
[epoch3, step714]: loss 0.022054
[epoch3, step715]: loss 0.023386
[epoch3, step716]: loss 0.026308
[epoch3, step717]: loss 0.023986
[epoch3, step718]: loss 0.025331
[epoch3, step719]: loss 0.033849
[epoch3, step720]: loss 0.025153
[epoch3, step721]: loss 0.023562
[epoch3, step722]: loss 0.031490
[epoch3, step723]: loss 0.026766
[epoch3, step724]: loss 0.023505
[epoch3, step725]: loss 0.028859
[epoch3, step726]: loss 0.022441
[epoch3, step727]: loss 0.024940
[epoch3, step728]: loss 0.026792
[epoch3, step729]: loss 0.021820
[epoch3, step730]: loss 0.023087
[epoch3, step731]: loss 0.026503
[epoch3, step732]: loss 0.026205
[epoch3, step733]: loss 0.024202
[epoch3, step734]: loss 0.023502
[epoch3, step735]: loss 0.027473
[epoch3, step736]: loss 0.025308
[epoch3, step737]: loss 0.026726
[epoch3, step738]: loss 0.020888
[epoch3, step739]: loss 0.025923
[epoch3, step740]: loss 0.023011
[epoch3, step741]: loss 0.025862
[epoch3, step742]: loss 0.022478
[epoch3, step743]: loss 0.023669
[epoch3, step744]: loss 0.024184
[epoch3, step745]: loss 0.024927
[epoch3, step746]: loss 0.025887
[epoch3, step747]: loss 0.028034
[epoch3, step748]: loss 0.026344
[epoch3, step749]: loss 0.027062
[epoch3, step750]: loss 0.028052
[epoch3, step751]: loss 0.022142
[epoch3, step752]: loss 0.025448
[epoch3, step753]: loss 0.025780
[epoch3, step754]: loss 0.023425
[epoch3, step755]: loss 0.026764
[epoch3, step756]: loss 0.023767
[epoch3, step757]: loss 0.021048
[epoch3, step758]: loss 0.025175
[epoch3, step759]: loss 0.023474
[epoch3, step760]: loss 0.024405
[epoch3, step761]: loss 0.026645
[epoch3, step762]: loss 0.021933
[epoch3, step763]: loss 0.025980
[epoch3, step764]: loss 0.024193
[epoch3, step765]: loss 0.026995
[epoch3, step766]: loss 0.025268
[epoch3, step767]: loss 0.027311
[epoch3, step768]: loss 0.021714
[epoch3, step769]: loss 0.027123
[epoch3, step770]: loss 0.026693
[epoch3, step771]: loss 0.023561
[epoch3, step772]: loss 0.029491
[epoch3, step773]: loss 0.026751
[epoch3, step774]: loss 0.024165
[epoch3, step775]: loss 0.021387
[epoch3, step776]: loss 0.026490
[epoch3, step777]: loss 0.023385
[epoch3, step778]: loss 0.028872
[epoch3, step779]: loss 0.024599
[epoch3, step780]: loss 0.020654
[epoch3, step781]: loss 0.025165
[epoch3, step782]: loss 0.023123
[epoch3, step783]: loss 0.020074
[epoch3, step784]: loss 0.020978
[epoch3, step785]: loss 0.021419
[epoch3, step786]: loss 0.024683
[epoch3, step787]: loss 0.024060
[epoch3, step788]: loss 0.025023
[epoch3, step789]: loss 0.023260
[epoch3, step790]: loss 0.023680
[epoch3, step791]: loss 0.027225
[epoch3, step792]: loss 0.025394
[epoch3, step793]: loss 0.027590
[epoch3, step794]: loss 0.020697
[epoch3, step795]: loss 0.026069
[epoch3, step796]: loss 0.028259
[epoch3, step797]: loss 0.028750
[epoch3, step798]: loss 0.027535
[epoch3, step799]: loss 0.025938
[epoch3, step800]: loss 0.021872
[epoch3, step801]: loss 0.022410
[epoch3, step802]: loss 0.023185
[epoch3, step803]: loss 0.026615
[epoch3, step804]: loss 0.027892
[epoch3, step805]: loss 0.029427
[epoch3, step806]: loss 0.022076
[epoch3, step807]: loss 0.021004
[epoch3, step808]: loss 0.023552
[epoch3, step809]: loss 0.023381
[epoch3, step810]: loss 0.026284
[epoch3, step811]: loss 0.026262
[epoch3, step812]: loss 0.025134
[epoch3, step813]: loss 0.024294
[epoch3, step814]: loss 0.025431
[epoch3, step815]: loss 0.025075
[epoch3, step816]: loss 0.024750
[epoch3, step817]: loss 0.025180
[epoch3, step818]: loss 0.022804
[epoch3, step819]: loss 0.020902
[epoch3, step820]: loss 0.023771
[epoch3, step821]: loss 0.022200
[epoch3, step822]: loss 0.031624
[epoch3, step823]: loss 0.024341
[epoch3, step824]: loss 0.027384
[epoch3, step825]: loss 0.025700
[epoch3, step826]: loss 0.024766
[epoch3, step827]: loss 0.027518
[epoch3, step828]: loss 0.029098
[epoch3, step829]: loss 0.026899
[epoch3, step830]: loss 0.022954
[epoch3, step831]: loss 0.026525
[epoch3, step832]: loss 0.021423
[epoch3, step833]: loss 0.029629
[epoch3, step834]: loss 0.026246
[epoch3, step835]: loss 0.021265
[epoch3, step836]: loss 0.027432
[epoch3, step837]: loss 0.025773
[epoch3, step838]: loss 0.026492
[epoch3, step839]: loss 0.028767
[epoch3, step840]: loss 0.021050
[epoch3, step841]: loss 0.024584
[epoch3, step842]: loss 0.027967
[epoch3, step843]: loss 0.025618
[epoch3, step844]: loss 0.025644
[epoch3, step845]: loss 0.021640
[epoch3, step846]: loss 0.026038
[epoch3, step847]: loss 0.027223
[epoch3, step848]: loss 0.025765
[epoch3, step849]: loss 0.025738
[epoch3, step850]: loss 0.023852
[epoch3, step851]: loss 0.024820
[epoch3, step852]: loss 0.023440
[epoch3, step853]: loss 0.029824
[epoch3, step854]: loss 0.022778
[epoch3, step855]: loss 0.027490
[epoch3, step856]: loss 0.022585
[epoch3, step857]: loss 0.026546
[epoch3, step858]: loss 0.024803
[epoch3, step859]: loss 0.024034
[epoch3, step860]: loss 0.023053
[epoch3, step861]: loss 0.023857
[epoch3, step862]: loss 0.023363
[epoch3, step863]: loss 0.021205
[epoch3, step864]: loss 0.027107
[epoch3, step865]: loss 0.023816
[epoch3, step866]: loss 0.025489
[epoch3, step867]: loss 0.026610
[epoch3, step868]: loss 0.027207
[epoch3, step869]: loss 0.024131
[epoch3, step870]: loss 0.031557
[epoch3, step871]: loss 0.022588
[epoch3, step872]: loss 0.026012
[epoch3, step873]: loss 0.026300
[epoch3, step874]: loss 0.024065
[epoch3, step875]: loss 0.024842
[epoch3, step876]: loss 0.024926
[epoch3, step877]: loss 0.019493
[epoch3, step878]: loss 0.023752
[epoch3, step879]: loss 0.028649
[epoch3, step880]: loss 0.025784
[epoch3, step881]: loss 0.022409
[epoch3, step882]: loss 0.024872
[epoch3, step883]: loss 0.024639
[epoch3, step884]: loss 0.026921
[epoch3, step885]: loss 0.026377
[epoch3, step886]: loss 0.026981
[epoch3, step887]: loss 0.024386
[epoch3, step888]: loss 0.025128
[epoch3, step889]: loss 0.024172
[epoch3, step890]: loss 0.023973
[epoch3, step891]: loss 0.025739
[epoch3, step892]: loss 0.021384
[epoch3, step893]: loss 0.024717
[epoch3, step894]: loss 0.025062
[epoch3, step895]: loss 0.023031
[epoch3, step896]: loss 0.022333
[epoch3, step897]: loss 0.024527
[epoch3, step898]: loss 0.026278
[epoch3, step899]: loss 0.028642
[epoch3, step900]: loss 0.027434
[epoch3, step901]: loss 0.026284
[epoch3, step902]: loss 0.024408
[epoch3, step903]: loss 0.025074
[epoch3, step904]: loss 0.028596
[epoch3, step905]: loss 0.028092
[epoch3, step906]: loss 0.022815
[epoch3, step907]: loss 0.023796
[epoch3, step908]: loss 0.022983
[epoch3, step909]: loss 0.026242
[epoch3, step910]: loss 0.023481
[epoch3, step911]: loss 0.025582
[epoch3, step912]: loss 0.024038
[epoch3, step913]: loss 0.024748
[epoch3, step914]: loss 0.031425
[epoch3, step915]: loss 0.024372
[epoch3, step916]: loss 0.023824
[epoch3, step917]: loss 0.025321
[epoch3, step918]: loss 0.028992
[epoch3, step919]: loss 0.024769
[epoch3, step920]: loss 0.027890
[epoch3, step921]: loss 0.024703
[epoch3, step922]: loss 0.023714
[epoch3, step923]: loss 0.023312
[epoch3, step924]: loss 0.021521
[epoch3, step925]: loss 0.025775
[epoch3, step926]: loss 0.026878
[epoch3, step927]: loss 0.026398
[epoch3, step928]: loss 0.025190
[epoch3, step929]: loss 0.028000
[epoch3, step930]: loss 0.026212
[epoch3, step931]: loss 0.028118
[epoch3, step932]: loss 0.022043
[epoch3, step933]: loss 0.028600
[epoch3, step934]: loss 0.022517
[epoch3, step935]: loss 0.022855
[epoch3, step936]: loss 0.023002
[epoch3, step937]: loss 0.028064
[epoch3, step938]: loss 0.025929
[epoch3, step939]: loss 0.021364
[epoch3, step940]: loss 0.023480
[epoch3, step941]: loss 0.027046
[epoch3, step942]: loss 0.025797
[epoch3, step943]: loss 0.023909
[epoch3, step944]: loss 0.028433
[epoch3, step945]: loss 0.020744
[epoch3, step946]: loss 0.025761
[epoch3, step947]: loss 0.028619
[epoch3, step948]: loss 0.020147
[epoch3, step949]: loss 0.023193
[epoch3, step950]: loss 0.026624
[epoch3, step951]: loss 0.029107
[epoch3, step952]: loss 0.025413
[epoch3, step953]: loss 0.027778
[epoch3, step954]: loss 0.022907
[epoch3, step955]: loss 0.038008
[epoch3, step956]: loss 0.053543
[epoch3, step957]: loss 0.044735
[epoch3, step958]: loss 0.041333
[epoch3, step959]: loss 0.045711
[epoch3, step960]: loss 0.043098
[epoch3, step961]: loss 0.044347
[epoch3, step962]: loss 0.043712
[epoch3, step963]: loss 0.042931
[epoch3, step964]: loss 0.043930
[epoch3, step965]: loss 0.045277
[epoch3, step966]: loss 0.042882
[epoch3, step967]: loss 0.042007
[epoch3, step968]: loss 0.045163
[epoch3, step969]: loss 0.044343
[epoch3, step970]: loss 0.044134
[epoch3, step971]: loss 0.043448
[epoch3, step972]: loss 0.043918
[epoch3, step973]: loss 0.043059
[epoch3, step974]: loss 0.046370
[epoch3, step975]: loss 0.043013
[epoch3, step976]: loss 0.041643
[epoch3, step977]: loss 0.045356
[epoch3, step978]: loss 0.043371
[epoch3, step979]: loss 0.043067
[epoch3, step980]: loss 0.041887
[epoch3, step981]: loss 0.042133
[epoch3, step982]: loss 0.042466
[epoch3, step983]: loss 0.045306
[epoch3, step984]: loss 0.041730
[epoch3, step985]: loss 0.040987
[epoch3, step986]: loss 0.044625
[epoch3, step987]: loss 0.042898
[epoch3, step988]: loss 0.043320
[epoch3, step989]: loss 0.042716
[epoch3, step990]: loss 0.042073
[epoch3, step991]: loss 0.042794
[epoch3, step992]: loss 0.044060
[epoch3, step993]: loss 0.041688
[epoch3, step994]: loss 0.040402
[epoch3, step995]: loss 0.044059
[epoch3, step996]: loss 0.042122
[epoch3, step997]: loss 0.042760
[epoch3, step998]: loss 0.042573
[epoch3, step999]: loss 0.042272
[epoch3, step1000]: loss 0.042460
[epoch3, step1001]: loss 0.044266
[epoch3, step1002]: loss 0.041894
[epoch3, step1003]: loss 0.040702
[epoch3, step1004]: loss 0.043892
[epoch3, step1005]: loss 0.041697
[epoch3, step1006]: loss 0.042734
[epoch3, step1007]: loss 0.041536
[epoch3, step1008]: loss 0.041556
[epoch3, step1009]: loss 0.042121
[epoch3, step1010]: loss 0.044560
[epoch3, step1011]: loss 0.041485
[epoch3, step1012]: loss 0.041132
[epoch3, step1013]: loss 0.043889
[epoch3, step1014]: loss 0.042827
[epoch3, step1015]: loss 0.042973
[epoch3, step1016]: loss 0.041430
[epoch3, step1017]: loss 0.041488
[epoch3, step1018]: loss 0.041852
[epoch3, step1019]: loss 0.044213
[epoch3, step1020]: loss 0.041137
[epoch3, step1021]: loss 0.040348
[epoch3, step1022]: loss 0.043492
[epoch3, step1023]: loss 0.042033
[epoch3, step1024]: loss 0.043179
[epoch3, step1025]: loss 0.041226
[epoch3, step1026]: loss 0.041091
[epoch3, step1027]: loss 0.041676
[epoch3, step1028]: loss 0.043873
[epoch3, step1029]: loss 0.041154
[epoch3, step1030]: loss 0.040118
[epoch3, step1031]: loss 0.042461
[epoch3, step1032]: loss 0.042250
[epoch3, step1033]: loss 0.042054
[epoch3, step1034]: loss 0.041302
[epoch3, step1035]: loss 0.041017
[epoch3, step1036]: loss 0.042011
[epoch3, step1037]: loss 0.043676
[epoch3, step1038]: loss 0.041088
[epoch3, step1039]: loss 0.040702
[epoch3, step1040]: loss 0.042986
[epoch3, step1041]: loss 0.041739
[epoch3, step1042]: loss 0.041519
[epoch3, step1043]: loss 0.041278
[epoch3, step1044]: loss 0.041497
[epoch3, step1045]: loss 0.041904
[epoch3, step1046]: loss 0.043884
[epoch3, step1047]: loss 0.041182
[epoch3, step1048]: loss 0.039906
[epoch3, step1049]: loss 0.043127
[epoch3, step1050]: loss 0.041616
[epoch3, step1051]: loss 0.041615
[epoch3, step1052]: loss 0.040801
[epoch3, step1053]: loss 0.040777
[epoch3, step1054]: loss 0.040644
[epoch3, step1055]: loss 0.042056
[epoch3, step1056]: loss 0.038955
[epoch3, step1057]: loss 0.039384
[epoch3, step1058]: loss 0.042872
[epoch3, step1059]: loss 0.040863
[epoch3, step1060]: loss 0.040711
[epoch3, step1061]: loss 0.038837
[epoch3, step1062]: loss 0.040199
[epoch3, step1063]: loss 0.040255
[epoch3, step1064]: loss 0.042171
[epoch3, step1065]: loss 0.039601
[epoch3, step1066]: loss 0.038717
[epoch3, step1067]: loss 0.041952
[epoch3, step1068]: loss 0.039276
[epoch3, step1069]: loss 0.040035
[epoch3, step1070]: loss 0.039314
[epoch3, step1071]: loss 0.040301
[epoch3, step1072]: loss 0.040775
[epoch3, step1073]: loss 0.041490
[epoch3, step1074]: loss 0.039012
[epoch3, step1075]: loss 0.038602
[epoch3, step1076]: loss 0.041609
[epoch3, step1077]: loss 0.039969
[epoch3, step1078]: loss 0.040437
[epoch3, step1079]: loss 0.039414
[epoch3, step1080]: loss 0.039516
[epoch3, step1081]: loss 0.039671
[epoch3, step1082]: loss 0.041169
[epoch3, step1083]: loss 0.039104
[epoch3, step1084]: loss 0.038629
[epoch3, step1085]: loss 0.040628
[epoch3, step1086]: loss 0.039415
[epoch3, step1087]: loss 0.039999
[epoch3, step1088]: loss 0.038228
[epoch3, step1089]: loss 0.039965
[epoch3, step1090]: loss 0.040243
[epoch3, step1091]: loss 0.041575
[epoch3, step1092]: loss 0.038246
[epoch3, step1093]: loss 0.037777
[epoch3, step1094]: loss 0.040204
[epoch3, step1095]: loss 0.039272
[epoch3, step1096]: loss 0.039024
[epoch3, step1097]: loss 0.038382
[epoch3, step1098]: loss 0.039189
[epoch3, step1099]: loss 0.039432
[epoch3, step1100]: loss 0.041676
[epoch3, step1101]: loss 0.038667
[epoch3, step1102]: loss 0.038129
[epoch3, step1103]: loss 0.040617
[epoch3, step1104]: loss 0.039572
[epoch3, step1105]: loss 0.040051
[epoch3, step1106]: loss 0.037175
[epoch3, step1107]: loss 0.039515
[epoch3, step1108]: loss 0.039106
[epoch3, step1109]: loss 0.041396
[epoch3, step1110]: loss 0.038761
[epoch3, step1111]: loss 0.037997
[epoch3, step1112]: loss 0.041443
[epoch3, step1113]: loss 0.039239
[epoch3, step1114]: loss 0.039653
[epoch3, step1115]: loss 0.038252
[epoch3, step1116]: loss 0.039507
[epoch3, step1117]: loss 0.039516
[epoch3, step1118]: loss 0.040888
[epoch3, step1119]: loss 0.037889
[epoch3, step1120]: loss 0.037736
[epoch3, step1121]: loss 0.040925
[epoch3, step1122]: loss 0.039009
[epoch3, step1123]: loss 0.038505
[epoch3, step1124]: loss 0.038830
[epoch3, step1125]: loss 0.039750
[epoch3, step1126]: loss 0.040383
[epoch3, step1127]: loss 0.041159
[epoch3, step1128]: loss 0.038283
[epoch3, step1129]: loss 0.037696
[epoch3, step1130]: loss 0.041746
[epoch3, step1131]: loss 0.039784
[epoch3, step1132]: loss 0.039722
[epoch3, step1133]: loss 0.037369
[epoch3, step1134]: loss 0.039020
[epoch3, step1135]: loss 0.040399
[epoch3, step1136]: loss 0.041277
[epoch3, step1137]: loss 0.038051
[epoch3, step1138]: loss 0.037682
[epoch3, step1139]: loss 0.040930
[epoch3, step1140]: loss 0.038735
[epoch3, step1141]: loss 0.038772
[epoch3, step1142]: loss 0.037738
[epoch3, step1143]: loss 0.038746
[epoch3, step1144]: loss 0.039644
[epoch3, step1145]: loss 0.040148
[epoch3, step1146]: loss 0.037735
[epoch3, step1147]: loss 0.038724
[epoch3, step1148]: loss 0.041045
[epoch3, step1149]: loss 0.039262
[epoch3, step1150]: loss 0.039096
[epoch3, step1151]: loss 0.038188
[epoch3, step1152]: loss 0.039873
[epoch3, step1153]: loss 0.038763
[epoch3, step1154]: loss 0.041107
[epoch3, step1155]: loss 0.038094
[epoch3, step1156]: loss 0.036911
[epoch3, step1157]: loss 0.040694
[epoch3, step1158]: loss 0.039454
[epoch3, step1159]: loss 0.039311
[epoch3, step1160]: loss 0.038610
[epoch3, step1161]: loss 0.039726
[epoch3, step1162]: loss 0.039284
[epoch3, step1163]: loss 0.039969
[epoch3, step1164]: loss 0.037798
[epoch3, step1165]: loss 0.038636
[epoch3, step1166]: loss 0.040891
[epoch3, step1167]: loss 0.038486
[epoch3, step1168]: loss 0.039222
[epoch3, step1169]: loss 0.037536
[epoch3, step1170]: loss 0.039287
[epoch3, step1171]: loss 0.039087
[epoch3, step1172]: loss 0.040783
[epoch3, step1173]: loss 0.037982
[epoch3, step1174]: loss 0.038027
[epoch3, step1175]: loss 0.040675
[epoch3, step1176]: loss 0.038848
[epoch3, step1177]: loss 0.039350
[epoch3, step1178]: loss 0.037816
[epoch3, step1179]: loss 0.038938
[epoch3, step1180]: loss 0.039418
[epoch3, step1181]: loss 0.041120
[epoch3, step1182]: loss 0.037185
[epoch3, step1183]: loss 0.037954
[epoch3, step1184]: loss 0.040183
[epoch3, step1185]: loss 0.039166
[epoch3, step1186]: loss 0.038256
[epoch3, step1187]: loss 0.036841
[epoch3, step1188]: loss 0.038548
[epoch3, step1189]: loss 0.038913
[epoch3, step1190]: loss 0.040162
[epoch3, step1191]: loss 0.038367
[epoch3, step1192]: loss 0.037472
[epoch3, step1193]: loss 0.040547
[epoch3, step1194]: loss 0.038959
[epoch3, step1195]: loss 0.037739
[epoch3, step1196]: loss 0.036916
[epoch3, step1197]: loss 0.039366
[epoch3, step1198]: loss 0.039171
[epoch3, step1199]: loss 0.040162
[epoch3, step1200]: loss 0.037449
[epoch3, step1201]: loss 0.037987
[epoch3, step1202]: loss 0.041569
[epoch3, step1203]: loss 0.039199
[epoch3, step1204]: loss 0.038300
[epoch3, step1205]: loss 0.037070
[epoch3, step1206]: loss 0.038572
[epoch3, step1207]: loss 0.039393
[epoch3, step1208]: loss 0.040592
[epoch3, step1209]: loss 0.036564
[epoch3, step1210]: loss 0.037899
[epoch3, step1211]: loss 0.040049
[epoch3, step1212]: loss 0.038738
[epoch3, step1213]: loss 0.038409
[epoch3, step1214]: loss 0.037703
[epoch3, step1215]: loss 0.039613
[epoch3, step1216]: loss 0.038683
[epoch3, step1217]: loss 0.041064
[epoch3, step1218]: loss 0.037275
[epoch3, step1219]: loss 0.038193
[epoch3, step1220]: loss 0.040961
[epoch3, step1221]: loss 0.038025
[epoch3, step1222]: loss 0.038967
[epoch3, step1223]: loss 0.037304
[epoch3, step1224]: loss 0.039385
[epoch3, step1225]: loss 0.039113
[epoch3, step1226]: loss 0.040123
[epoch3, step1227]: loss 0.037539
[epoch3, step1228]: loss 0.037083
[epoch3, step1229]: loss 0.040263
[epoch3, step1230]: loss 0.039137
[epoch3, step1231]: loss 0.038608
[epoch3, step1232]: loss 0.038529
[epoch3, step1233]: loss 0.038888
[epoch3, step1234]: loss 0.038813
[epoch3, step1235]: loss 0.040893
[epoch3, step1236]: loss 0.037822
[epoch3, step1237]: loss 0.037058
[epoch3, step1238]: loss 0.039916
[epoch3, step1239]: loss 0.039528
[epoch3, step1240]: loss 0.039142
[epoch3, step1241]: loss 0.037035
[epoch3, step1242]: loss 0.038949
[epoch3, step1243]: loss 0.038946
[epoch3, step1244]: loss 0.040572
[epoch3, step1245]: loss 0.037879
[epoch3, step1246]: loss 0.037718
[epoch3, step1247]: loss 0.039675
[epoch3, step1248]: loss 0.038972
[epoch3, step1249]: loss 0.039186
[epoch3, step1250]: loss 0.037280
[epoch3, step1251]: loss 0.039111
[epoch3, step1252]: loss 0.039969
[epoch3, step1253]: loss 0.040559
[epoch3, step1254]: loss 0.037601
[epoch3, step1255]: loss 0.037574
[epoch3, step1256]: loss 0.040900
[epoch3, step1257]: loss 0.039144
[epoch3, step1258]: loss 0.038930
[epoch3, step1259]: loss 0.037049
[epoch3, step1260]: loss 0.039022
[epoch3, step1261]: loss 0.038808
[epoch3, step1262]: loss 0.039126
[epoch3, step1263]: loss 0.038106
[epoch3, step1264]: loss 0.037321
[epoch3, step1265]: loss 0.039166
[epoch3, step1266]: loss 0.038832
[epoch3, step1267]: loss 0.038827
[epoch3, step1268]: loss 0.037529
[epoch3, step1269]: loss 0.039052
[epoch3, step1270]: loss 0.038289
[epoch3, step1271]: loss 0.040795
[epoch3, step1272]: loss 0.037587
[epoch3, step1273]: loss 0.037182
[epoch3, step1274]: loss 0.040099
[epoch3, step1275]: loss 0.039186
[epoch3, step1276]: loss 0.038374
[epoch3, step1277]: loss 0.037260
[epoch3, step1278]: loss 0.039509
[epoch3, step1279]: loss 0.039119
[epoch3, step1280]: loss 0.040591
[epoch3, step1281]: loss 0.037332
[epoch3, step1282]: loss 0.037226
[epoch3, step1283]: loss 0.039733
[epoch3, step1284]: loss 0.038320
[epoch3, step1285]: loss 0.039193
[epoch3, step1286]: loss 0.036585
[epoch3, step1287]: loss 0.039632
[epoch3, step1288]: loss 0.039710
[epoch3, step1289]: loss 0.041124
[epoch3, step1290]: loss 0.037465
[epoch3, step1291]: loss 0.037059
[epoch3, step1292]: loss 0.040846
[epoch3, step1293]: loss 0.037991
[epoch3, step1294]: loss 0.038593
[epoch3, step1295]: loss 0.037763
[epoch3, step1296]: loss 0.039098
[epoch3, step1297]: loss 0.038679
[epoch3, step1298]: loss 0.040793
[epoch3, step1299]: loss 0.037603
[epoch3, step1300]: loss 0.038024
[epoch3, step1301]: loss 0.039359
[epoch3, step1302]: loss 0.038767
[epoch3, step1303]: loss 0.038841
[epoch3, step1304]: loss 0.036654
[epoch3, step1305]: loss 0.039198
[epoch3, step1306]: loss 0.038719
[epoch3, step1307]: loss 0.039700
[epoch3, step1308]: loss 0.037514
[epoch3, step1309]: loss 0.036651
[epoch3, step1310]: loss 0.040215
[epoch3, step1311]: loss 0.037658
[epoch3, step1312]: loss 0.039319
[epoch3, step1313]: loss 0.037283
[epoch3, step1314]: loss 0.038819
[epoch3, step1315]: loss 0.038621
[epoch3, step1316]: loss 0.041644
[epoch3, step1317]: loss 0.036811
[epoch3, step1318]: loss 0.036749
[epoch3, step1319]: loss 0.039690
[epoch3, step1320]: loss 0.038946
[epoch3, step1321]: loss 0.039078
[epoch3, step1322]: loss 0.036891
[epoch3, step1323]: loss 0.039252
[epoch3, step1324]: loss 0.038446
[epoch3, step1325]: loss 0.040105
[epoch3, step1326]: loss 0.037103
[epoch3, step1327]: loss 0.037135
[epoch3, step1328]: loss 0.040276
[epoch3, step1329]: loss 0.038566
[epoch3, step1330]: loss 0.038821
[epoch3, step1331]: loss 0.036923
[epoch3, step1332]: loss 0.038737
[epoch3, step1333]: loss 0.037967
[epoch3, step1334]: loss 0.040506
[epoch3, step1335]: loss 0.037869
[epoch3, step1336]: loss 0.037130
[epoch3, step1337]: loss 0.039658
[epoch3, step1338]: loss 0.038424
[epoch3, step1339]: loss 0.038699
[epoch3, step1340]: loss 0.036746
[epoch3, step1341]: loss 0.039043
[epoch3, step1342]: loss 0.038622
[epoch3, step1343]: loss 0.040283
[epoch3, step1344]: loss 0.037378
[epoch3, step1345]: loss 0.037104
[epoch3, step1346]: loss 0.039706
[epoch3, step1347]: loss 0.039229
[epoch3, step1348]: loss 0.037951
[epoch3, step1349]: loss 0.037232
[epoch3, step1350]: loss 0.038833
[epoch3, step1351]: loss 0.038279
[epoch3, step1352]: loss 0.039479
[epoch3, step1353]: loss 0.036932
[epoch3, step1354]: loss 0.036818
[epoch3, step1355]: loss 0.040166
[epoch3, step1356]: loss 0.038218
[epoch3, step1357]: loss 0.037937
[epoch3, step1358]: loss 0.036854
[epoch3, step1359]: loss 0.038324
[epoch3, step1360]: loss 0.038898
[epoch3, step1361]: loss 0.040342
[epoch3, step1362]: loss 0.037825
[epoch3, step1363]: loss 0.037588
[epoch3, step1364]: loss 0.040030
[epoch3, step1365]: loss 0.038526
[epoch3, step1366]: loss 0.038323
[epoch3, step1367]: loss 0.036208
[epoch3, step1368]: loss 0.039593
[epoch3, step1369]: loss 0.038864
[epoch3, step1370]: loss 0.039777
[epoch3, step1371]: loss 0.037370
[epoch3, step1372]: loss 0.036950
[epoch3, step1373]: loss 0.040040
[epoch3, step1374]: loss 0.039373
[epoch3, step1375]: loss 0.039226
[epoch3, step1376]: loss 0.036779
[epoch3, step1377]: loss 0.037925
[epoch3, step1378]: loss 0.038850
[epoch3, step1379]: loss 0.039633
[epoch3, step1380]: loss 0.037539
[epoch3, step1381]: loss 0.037089
[epoch3, step1382]: loss 0.040327
[epoch3, step1383]: loss 0.038381
[epoch3, step1384]: loss 0.038298
[epoch3, step1385]: loss 0.036311
[epoch3, step1386]: loss 0.038985
[epoch3, step1387]: loss 0.039213
[epoch3, step1388]: loss 0.038964
[epoch3, step1389]: loss 0.036409
[epoch3, step1390]: loss 0.037232
[epoch3, step1391]: loss 0.039725
[epoch3, step1392]: loss 0.038391
[epoch3, step1393]: loss 0.038644
[epoch3, step1394]: loss 0.037528
[epoch3, step1395]: loss 0.038860
[epoch3, step1396]: loss 0.038226
[epoch3, step1397]: loss 0.039741
[epoch3, step1398]: loss 0.036989
[epoch3, step1399]: loss 0.037968
[epoch3, step1400]: loss 0.040405
[epoch3, step1401]: loss 0.038288
[epoch3, step1402]: loss 0.038503
[epoch3, step1403]: loss 0.035952
[epoch3, step1404]: loss 0.038255
[epoch3, step1405]: loss 0.038511
[epoch3, step1406]: loss 0.039643
[epoch3, step1407]: loss 0.038136
[epoch3, step1408]: loss 0.036467
[epoch3, step1409]: loss 0.039461
[epoch3, step1410]: loss 0.038441
[epoch3, step1411]: loss 0.037329
[epoch3, step1412]: loss 0.037028
[epoch3, step1413]: loss 0.038710
[epoch3, step1414]: loss 0.038301
[epoch3, step1415]: loss 0.039580
[epoch3, step1416]: loss 0.036933
[epoch3, step1417]: loss 0.037018
[epoch3, step1418]: loss 0.039850
[epoch3, step1419]: loss 0.039180
[epoch3, step1420]: loss 0.038601
[epoch3, step1421]: loss 0.037272
[epoch3, step1422]: loss 0.038831
[epoch3, step1423]: loss 0.038167
[epoch3, step1424]: loss 0.040104
[epoch3, step1425]: loss 0.036037
[epoch3, step1426]: loss 0.037134
[epoch3, step1427]: loss 0.040588
[epoch3, step1428]: loss 0.039232
[epoch3, step1429]: loss 0.038303
[epoch3, step1430]: loss 0.036929
[epoch3, step1431]: loss 0.038777
[epoch3, step1432]: loss 0.038362
[epoch3, step1433]: loss 0.040087
[epoch3, step1434]: loss 0.036405
[epoch3, step1435]: loss 0.037545
[epoch3, step1436]: loss 0.040259
[epoch3, step1437]: loss 0.038694
[epoch3, step1438]: loss 0.038905
[epoch3, step1439]: loss 0.036743
[epoch3, step1440]: loss 0.038422
[epoch3, step1441]: loss 0.039203
[epoch3, step1442]: loss 0.039125
[epoch3, step1443]: loss 0.036641
[epoch3, step1444]: loss 0.036334
[epoch3, step1445]: loss 0.040250
[epoch3, step1446]: loss 0.038623
[epoch3, step1447]: loss 0.038990
[epoch3, step1448]: loss 0.036797
[epoch3, step1449]: loss 0.038002
[epoch3, step1450]: loss 0.038634
[epoch3, step1451]: loss 0.040141
[epoch3, step1452]: loss 0.036642
[epoch3, step1453]: loss 0.038108
[epoch3, step1454]: loss 0.040276
[epoch3, step1455]: loss 0.039036
[epoch3, step1456]: loss 0.037861
[epoch3, step1457]: loss 0.037398
[epoch3, step1458]: loss 0.038672
[epoch3, step1459]: loss 0.038510
[epoch3, step1460]: loss 0.040340
[epoch3, step1461]: loss 0.037613
[epoch3, step1462]: loss 0.037693
[epoch3, step1463]: loss 0.039757
[epoch3, step1464]: loss 0.038724
[epoch3, step1465]: loss 0.037929
[epoch3, step1466]: loss 0.036455
[epoch3, step1467]: loss 0.038559
[epoch3, step1468]: loss 0.037959
[epoch3, step1469]: loss 0.039858
[epoch3, step1470]: loss 0.036981
[epoch3, step1471]: loss 0.036676
[epoch3, step1472]: loss 0.039604
[epoch3, step1473]: loss 0.038298
[epoch3, step1474]: loss 0.038871
[epoch3, step1475]: loss 0.036419
[epoch3, step1476]: loss 0.039396
[epoch3, step1477]: loss 0.038223
[epoch3, step1478]: loss 0.039899
[epoch3, step1479]: loss 0.036829
[epoch3, step1480]: loss 0.037026
[epoch3, step1481]: loss 0.038818
[epoch3, step1482]: loss 0.038414
[epoch3, step1483]: loss 0.038393
[epoch3, step1484]: loss 0.037232
[epoch3, step1485]: loss 0.038373
[epoch3, step1486]: loss 0.037389
[epoch3, step1487]: loss 0.039713
[epoch3, step1488]: loss 0.036941
[epoch3, step1489]: loss 0.036786
[epoch3, step1490]: loss 0.039922
[epoch3, step1491]: loss 0.038288
[epoch3, step1492]: loss 0.038110
[epoch3, step1493]: loss 0.036637
[epoch3, step1494]: loss 0.038667
[epoch3, step1495]: loss 0.038065
[epoch3, step1496]: loss 0.038802
[epoch3, step1497]: loss 0.037160
[epoch3, step1498]: loss 0.037048
[epoch3, step1499]: loss 0.039142
[epoch3, step1500]: loss 0.038598
[epoch3, step1501]: loss 0.038167
[epoch3, step1502]: loss 0.036571
[epoch3, step1503]: loss 0.038403
[epoch3, step1504]: loss 0.038058
[epoch3, step1505]: loss 0.040097
[epoch3, step1506]: loss 0.036266
[epoch3, step1507]: loss 0.037411
[epoch3, step1508]: loss 0.040356
[epoch3, step1509]: loss 0.038130
[epoch3, step1510]: loss 0.037528
[epoch3, step1511]: loss 0.037317
[epoch3, step1512]: loss 0.038604
[epoch3, step1513]: loss 0.037084
[epoch3, step1514]: loss 0.039724
[epoch3, step1515]: loss 0.037271
[epoch3, step1516]: loss 0.036845

[epoch3]: avg loss 0.035238

[epoch4, step1]: loss 0.033004
[epoch4, step2]: loss 0.039591
[epoch4, step3]: loss 0.039364
[epoch4, step4]: loss 0.036610
[epoch4, step5]: loss 0.037309
[epoch4, step6]: loss 0.039694
[epoch4, step7]: loss 0.037945
[epoch4, step8]: loss 0.040546
[epoch4, step9]: loss 0.036146
[epoch4, step10]: loss 0.038014
[epoch4, step11]: loss 0.039783
[epoch4, step12]: loss 0.039575
[epoch4, step13]: loss 0.036906
[epoch4, step14]: loss 0.037128
[epoch4, step15]: loss 0.039677
[epoch4, step16]: loss 0.037512
[epoch4, step17]: loss 0.040145
[epoch4, step18]: loss 0.037498
[epoch4, step19]: loss 0.037574
[epoch4, step20]: loss 0.040721
[epoch4, step21]: loss 0.039576
[epoch4, step22]: loss 0.036442
[epoch4, step23]: loss 0.036328
[epoch4, step24]: loss 0.039692
[epoch4, step25]: loss 0.037090
[epoch4, step26]: loss 0.039818
[epoch4, step27]: loss 0.035995
[epoch4, step28]: loss 0.037685
[epoch4, step29]: loss 0.039897
[epoch4, step30]: loss 0.040224
[epoch4, step31]: loss 0.036282
[epoch4, step32]: loss 0.037341
[epoch4, step33]: loss 0.040286
[epoch4, step34]: loss 0.037998
[epoch4, step35]: loss 0.040186
[epoch4, step36]: loss 0.036503
[epoch4, step37]: loss 0.037415
[epoch4, step38]: loss 0.039753
[epoch4, step39]: loss 0.039630
[epoch4, step40]: loss 0.037058
[epoch4, step41]: loss 0.036557
[epoch4, step42]: loss 0.039987
[epoch4, step43]: loss 0.037557
[epoch4, step44]: loss 0.040821
[epoch4, step45]: loss 0.036475
[epoch4, step46]: loss 0.037698
[epoch4, step47]: loss 0.039366
[epoch4, step48]: loss 0.039219
[epoch4, step49]: loss 0.035260
[epoch4, step50]: loss 0.036900
[epoch4, step51]: loss 0.039454
[epoch4, step52]: loss 0.037035
[epoch4, step53]: loss 0.040396
[epoch4, step54]: loss 0.036319
[epoch4, step55]: loss 0.037724
[epoch4, step56]: loss 0.040891
[epoch4, step57]: loss 0.040125
[epoch4, step58]: loss 0.036829
[epoch4, step59]: loss 0.036209
[epoch4, step60]: loss 0.040167
[epoch4, step61]: loss 0.036957
[epoch4, step62]: loss 0.040223
[epoch4, step63]: loss 0.035913
[epoch4, step64]: loss 0.037277
[epoch4, step65]: loss 0.040537
[epoch4, step66]: loss 0.039972
[epoch4, step67]: loss 0.036853
[epoch4, step68]: loss 0.037103
[epoch4, step69]: loss 0.039729
[epoch4, step70]: loss 0.037026
[epoch4, step71]: loss 0.039627
[epoch4, step72]: loss 0.036707
[epoch4, step73]: loss 0.037086
[epoch4, step74]: loss 0.040651
[epoch4, step75]: loss 0.040447
[epoch4, step76]: loss 0.037282
[epoch4, step77]: loss 0.037947
[epoch4, step78]: loss 0.040444
[epoch4, step79]: loss 0.036589
[epoch4, step80]: loss 0.040886
[epoch4, step81]: loss 0.036859
[epoch4, step82]: loss 0.036747
[epoch4, step83]: loss 0.038987
[epoch4, step84]: loss 0.039824
[epoch4, step85]: loss 0.037344
[epoch4, step86]: loss 0.037002
[epoch4, step87]: loss 0.040695
[epoch4, step88]: loss 0.036041
[epoch4, step89]: loss 0.039418
[epoch4, step90]: loss 0.037059
[epoch4, step91]: loss 0.036579
[epoch4, step92]: loss 0.040462
[epoch4, step93]: loss 0.039922
[epoch4, step94]: loss 0.036440
[epoch4, step95]: loss 0.037636
[epoch4, step96]: loss 0.039601
[epoch4, step97]: loss 0.037940
[epoch4, step98]: loss 0.040081
[epoch4, step99]: loss 0.036558
[epoch4, step100]: loss 0.036306
[epoch4, step101]: loss 0.040268
[epoch4, step102]: loss 0.039586
[epoch4, step103]: loss 0.036586
[epoch4, step104]: loss 0.036946
[epoch4, step105]: loss 0.039846
[epoch4, step106]: loss 0.037387
[epoch4, step107]: loss 0.039828
[epoch4, step108]: loss 0.037111
[epoch4, step109]: loss 0.037207
[epoch4, step110]: loss 0.040329
[epoch4, step111]: loss 0.039649
[epoch4, step112]: loss 0.037193
[epoch4, step113]: loss 0.037632
[epoch4, step114]: loss 0.039577
[epoch4, step115]: loss 0.037089
[epoch4, step116]: loss 0.040575
[epoch4, step117]: loss 0.036530
[epoch4, step118]: loss 0.037859
[epoch4, step119]: loss 0.040361
[epoch4, step120]: loss 0.039821
[epoch4, step121]: loss 0.036570
[epoch4, step122]: loss 0.037021
[epoch4, step123]: loss 0.040058
[epoch4, step124]: loss 0.037947
[epoch4, step125]: loss 0.041007
[epoch4, step126]: loss 0.036455
[epoch4, step127]: loss 0.037338
[epoch4, step128]: loss 0.040024
[epoch4, step129]: loss 0.039363
[epoch4, step130]: loss 0.037224
[epoch4, step131]: loss 0.036558
[epoch4, step132]: loss 0.039814
[epoch4, step133]: loss 0.036937
[epoch4, step134]: loss 0.039349
[epoch4, step135]: loss 0.037083
[epoch4, step136]: loss 0.038227
[epoch4, step137]: loss 0.040019
[epoch4, step138]: loss 0.039563
[epoch4, step139]: loss 0.036816
[epoch4, step140]: loss 0.037917
[epoch4, step141]: loss 0.040199
[epoch4, step142]: loss 0.037354
[epoch4, step143]: loss 0.040326
[epoch4, step144]: loss 0.037130
[epoch4, step145]: loss 0.037334
[epoch4, step146]: loss 0.039978
[epoch4, step147]: loss 0.040946
[epoch4, step148]: loss 0.036660
[epoch4, step149]: loss 0.036321
[epoch4, step150]: loss 0.039425
[epoch4, step151]: loss 0.037188
[epoch4, step152]: loss 0.039687
[epoch4, step153]: loss 0.036684
[epoch4, step154]: loss 0.036607
[epoch4, step155]: loss 0.039816
[epoch4, step156]: loss 0.039211
[epoch4, step157]: loss 0.036907
[epoch4, step158]: loss 0.037096
[epoch4, step159]: loss 0.040024
[epoch4, step160]: loss 0.037533
[epoch4, step161]: loss 0.040348
[epoch4, step162]: loss 0.037025
[epoch4, step163]: loss 0.036956
[epoch4, step164]: loss 0.040623
[epoch4, step165]: loss 0.040341
[epoch4, step166]: loss 0.037135
[epoch4, step167]: loss 0.036950
[epoch4, step168]: loss 0.041299
[epoch4, step169]: loss 0.037197
[epoch4, step170]: loss 0.040057
[epoch4, step171]: loss 0.037552
[epoch4, step172]: loss 0.037574
[epoch4, step173]: loss 0.040374
[epoch4, step174]: loss 0.039614
[epoch4, step175]: loss 0.037827
[epoch4, step176]: loss 0.037367
[epoch4, step177]: loss 0.040129
[epoch4, step178]: loss 0.037643
[epoch4, step179]: loss 0.039144
[epoch4, step180]: loss 0.037121
[epoch4, step181]: loss 0.037670
[epoch4, step182]: loss 0.040160
[epoch4, step183]: loss 0.040543
[epoch4, step184]: loss 0.038004
[epoch4, step185]: loss 0.037132
[epoch4, step186]: loss 0.040036
[epoch4, step187]: loss 0.037269
[epoch4, step188]: loss 0.039638
[epoch4, step189]: loss 0.036684
[epoch4, step190]: loss 0.036586
[epoch4, step191]: loss 0.039693
[epoch4, step192]: loss 0.040227
[epoch4, step193]: loss 0.034932
[epoch4, step194]: loss 0.036246
[epoch4, step195]: loss 0.040089
[epoch4, step196]: loss 0.037590
[epoch4, step197]: loss 0.040115
[epoch4, step198]: loss 0.035710
[epoch4, step199]: loss 0.037435
[epoch4, step200]: loss 0.040333
[epoch4, step201]: loss 0.040140
[epoch4, step202]: loss 0.036453
[epoch4, step203]: loss 0.036998
[epoch4, step204]: loss 0.040275
[epoch4, step205]: loss 0.036602
[epoch4, step206]: loss 0.039524
[epoch4, step207]: loss 0.036664
[epoch4, step208]: loss 0.037729
[epoch4, step209]: loss 0.040064
[epoch4, step210]: loss 0.040713
[epoch4, step211]: loss 0.037389
[epoch4, step212]: loss 0.037479
[epoch4, step213]: loss 0.039442
[epoch4, step214]: loss 0.036729
[epoch4, step215]: loss 0.040365
[epoch4, step216]: loss 0.036906
[epoch4, step217]: loss 0.036351
[epoch4, step218]: loss 0.040103
[epoch4, step219]: loss 0.039551
[epoch4, step220]: loss 0.037077
[epoch4, step221]: loss 0.037288
[epoch4, step222]: loss 0.039993
[epoch4, step223]: loss 0.037503
[epoch4, step224]: loss 0.039580
[epoch4, step225]: loss 0.036671
[epoch4, step226]: loss 0.037091
[epoch4, step227]: loss 0.038851
[epoch4, step228]: loss 0.040359
[epoch4, step229]: loss 0.035951
[epoch4, step230]: loss 0.037384
[epoch4, step231]: loss 0.040235
[epoch4, step232]: loss 0.036977
[epoch4, step233]: loss 0.039235
[epoch4, step234]: loss 0.036239
[epoch4, step235]: loss 0.037590
[epoch4, step236]: loss 0.039819
[epoch4, step237]: loss 0.039825
[epoch4, step238]: loss 0.036504
[epoch4, step239]: loss 0.036293
[epoch4, step240]: loss 0.039227
[epoch4, step241]: loss 0.037851
[epoch4, step242]: loss 0.039871
[epoch4, step243]: loss 0.037341
[epoch4, step244]: loss 0.037170
[epoch4, step245]: loss 0.039382
[epoch4, step246]: loss 0.039764
[epoch4, step247]: loss 0.037057
[epoch4, step248]: loss 0.036625
[epoch4, step249]: loss 0.039215
[epoch4, step250]: loss 0.037575
[epoch4, step251]: loss 0.040465
[epoch4, step252]: loss 0.037265
[epoch4, step253]: loss 0.036887
[epoch4, step254]: loss 0.039182
[epoch4, step255]: loss 0.039872
[epoch4, step256]: loss 0.036473
[epoch4, step257]: loss 0.036738
[epoch4, step258]: loss 0.040386
[epoch4, step259]: loss 0.037325
[epoch4, step260]: loss 0.039465
[epoch4, step261]: loss 0.037440
[epoch4, step262]: loss 0.037683
[epoch4, step263]: loss 0.039058
[epoch4, step264]: loss 0.039470
[epoch4, step265]: loss 0.037011
[epoch4, step266]: loss 0.036931
[epoch4, step267]: loss 0.039015
[epoch4, step268]: loss 0.037227
[epoch4, step269]: loss 0.039938
[epoch4, step270]: loss 0.036318
[epoch4, step271]: loss 0.037412
[epoch4, step272]: loss 0.039693
[epoch4, step273]: loss 0.039529
[epoch4, step274]: loss 0.037228
[epoch4, step275]: loss 0.036583
[epoch4, step276]: loss 0.039521
[epoch4, step277]: loss 0.037630
[epoch4, step278]: loss 0.040006
[epoch4, step279]: loss 0.036311
[epoch4, step280]: loss 0.037100
[epoch4, step281]: loss 0.039635
[epoch4, step282]: loss 0.040142
[epoch4, step283]: loss 0.036404
[epoch4, step284]: loss 0.036458
[epoch4, step285]: loss 0.040477
[epoch4, step286]: loss 0.036590
[epoch4, step287]: loss 0.040140
[epoch4, step288]: loss 0.036300
[epoch4, step289]: loss 0.038089
[epoch4, step290]: loss 0.039778
[epoch4, step291]: loss 0.040060
[epoch4, step292]: loss 0.035918
[epoch4, step293]: loss 0.036626
[epoch4, step294]: loss 0.039133
[epoch4, step295]: loss 0.036607
[epoch4, step296]: loss 0.040707
[epoch4, step297]: loss 0.036298
[epoch4, step298]: loss 0.037596
[epoch4, step299]: loss 0.038800
[epoch4, step300]: loss 0.039960
[epoch4, step301]: loss 0.036749
[epoch4, step302]: loss 0.037282
[epoch4, step303]: loss 0.040110
[epoch4, step304]: loss 0.036895
[epoch4, step305]: loss 0.039585
[epoch4, step306]: loss 0.036726
[epoch4, step307]: loss 0.036773
[epoch4, step308]: loss 0.040276
[epoch4, step309]: loss 0.039966
[epoch4, step310]: loss 0.036896
[epoch4, step311]: loss 0.037332
[epoch4, step312]: loss 0.039326
[epoch4, step313]: loss 0.037684
[epoch4, step314]: loss 0.039765
[epoch4, step315]: loss 0.037793
[epoch4, step316]: loss 0.037166
[epoch4, step317]: loss 0.039986
[epoch4, step318]: loss 0.039931
[epoch4, step319]: loss 0.036461
[epoch4, step320]: loss 0.035828
[epoch4, step321]: loss 0.039406
[epoch4, step322]: loss 0.036900
[epoch4, step323]: loss 0.039070
[epoch4, step324]: loss 0.037464
[epoch4, step325]: loss 0.037326
[epoch4, step326]: loss 0.039558
[epoch4, step327]: loss 0.039058
[epoch4, step328]: loss 0.036938
[epoch4, step329]: loss 0.036704
[epoch4, step330]: loss 0.039189
[epoch4, step331]: loss 0.037516
[epoch4, step332]: loss 0.039498
[epoch4, step333]: loss 0.036522
[epoch4, step334]: loss 0.037247
[epoch4, step335]: loss 0.039879
[epoch4, step336]: loss 0.040560
[epoch4, step337]: loss 0.037069
[epoch4, step338]: loss 0.036445
[epoch4, step339]: loss 0.039632
[epoch4, step340]: loss 0.037493
[epoch4, step341]: loss 0.039222
[epoch4, step342]: loss 0.036364
[epoch4, step343]: loss 0.037295
[epoch4, step344]: loss 0.039322
[epoch4, step345]: loss 0.038962
[epoch4, step346]: loss 0.036303
[epoch4, step347]: loss 0.036595
[epoch4, step348]: loss 0.039797
[epoch4, step349]: loss 0.037808
[epoch4, step350]: loss 0.039563
[epoch4, step351]: loss 0.035805
[epoch4, step352]: loss 0.037093
[epoch4, step353]: loss 0.039520
[epoch4, step354]: loss 0.038709
[epoch4, step355]: loss 0.035670
[epoch4, step356]: loss 0.037501
[epoch4, step357]: loss 0.039776
[epoch4, step358]: loss 0.035661
[epoch4, step359]: loss 0.040648
[epoch4, step360]: loss 0.035395
[epoch4, step361]: loss 0.036449
[epoch4, step362]: loss 0.040197
[epoch4, step363]: loss 0.039314
[epoch4, step364]: loss 0.036509
[epoch4, step365]: loss 0.036512
[epoch4, step366]: loss 0.039962
[epoch4, step367]: loss 0.037201
[epoch4, step368]: loss 0.039071
[epoch4, step369]: loss 0.036608
[epoch4, step370]: loss 0.037947
[epoch4, step371]: loss 0.040445
[epoch4, step372]: loss 0.039436
[epoch4, step373]: loss 0.036407
[epoch4, step374]: loss 0.035930
[epoch4, step375]: loss 0.040293
[epoch4, step376]: loss 0.036884
[epoch4, step377]: loss 0.039784
[epoch4, step378]: loss 0.036980
[epoch4, step379]: loss 0.037586
[epoch4, step380]: loss 0.040352
[epoch4, step381]: loss 0.039336
[epoch4, step382]: loss 0.036959
[epoch4, step383]: loss 0.035910
[epoch4, step384]: loss 0.038877
[epoch4, step385]: loss 0.037193
[epoch4, step386]: loss 0.040238
[epoch4, step387]: loss 0.036541
[epoch4, step388]: loss 0.038059
[epoch4, step389]: loss 0.039753
[epoch4, step390]: loss 0.040421
[epoch4, step391]: loss 0.036414
[epoch4, step392]: loss 0.037209
[epoch4, step393]: loss 0.039066
[epoch4, step394]: loss 0.036943
[epoch4, step395]: loss 0.039293
[epoch4, step396]: loss 0.036651
[epoch4, step397]: loss 0.036575
[epoch4, step398]: loss 0.040073
[epoch4, step399]: loss 0.039701
[epoch4, step400]: loss 0.036273
[epoch4, step401]: loss 0.036724
[epoch4, step402]: loss 0.039453
[epoch4, step403]: loss 0.037104
[epoch4, step404]: loss 0.040546
[epoch4, step405]: loss 0.036842
[epoch4, step406]: loss 0.037651
[epoch4, step407]: loss 0.039914
[epoch4, step408]: loss 0.039870
[epoch4, step409]: loss 0.038021
[epoch4, step410]: loss 0.037431
[epoch4, step411]: loss 0.039423
[epoch4, step412]: loss 0.036371
[epoch4, step413]: loss 0.039494
[epoch4, step414]: loss 0.036128
[epoch4, step415]: loss 0.037132
[epoch4, step416]: loss 0.039124
[epoch4, step417]: loss 0.039733
[epoch4, step418]: loss 0.036528
[epoch4, step419]: loss 0.035915
[epoch4, step420]: loss 0.039867
[epoch4, step421]: loss 0.036837
[epoch4, step422]: loss 0.039450
[epoch4, step423]: loss 0.036846
[epoch4, step424]: loss 0.037289
[epoch4, step425]: loss 0.039916
[epoch4, step426]: loss 0.040077
[epoch4, step427]: loss 0.036865
[epoch4, step428]: loss 0.036722
[epoch4, step429]: loss 0.040331
[epoch4, step430]: loss 0.037109
[epoch4, step431]: loss 0.040500
[epoch4, step432]: loss 0.036450
[epoch4, step433]: loss 0.038190
[epoch4, step434]: loss 0.039991
[epoch4, step435]: loss 0.040110
[epoch4, step436]: loss 0.036512
[epoch4, step437]: loss 0.037186
[epoch4, step438]: loss 0.040203
[epoch4, step439]: loss 0.037194
[epoch4, step440]: loss 0.039746
[epoch4, step441]: loss 0.036792
[epoch4, step442]: loss 0.036881
[epoch4, step443]: loss 0.040668
[epoch4, step444]: loss 0.039353
[epoch4, step445]: loss 0.037417
[epoch4, step446]: loss 0.037960
[epoch4, step447]: loss 0.040874
[epoch4, step448]: loss 0.037053
[epoch4, step449]: loss 0.039890
[epoch4, step450]: loss 0.036131
[epoch4, step451]: loss 0.036747
[epoch4, step452]: loss 0.038561
[epoch4, step453]: loss 0.039707
[epoch4, step454]: loss 0.036574
[epoch4, step455]: loss 0.036844
[epoch4, step456]: loss 0.038671
[epoch4, step457]: loss 0.037633
[epoch4, step458]: loss 0.039270
[epoch4, step459]: loss 0.037340
[epoch4, step460]: loss 0.037102
[epoch4, step461]: loss 0.040736
[epoch4, step462]: loss 0.039363
[epoch4, step463]: loss 0.036733
[epoch4, step464]: loss 0.036926
[epoch4, step465]: loss 0.041427
[epoch4, step466]: loss 0.036770
[epoch4, step467]: loss 0.039584
[epoch4, step468]: loss 0.036732
[epoch4, step469]: loss 0.037063
[epoch4, step470]: loss 0.039841
[epoch4, step471]: loss 0.039056
[epoch4, step472]: loss 0.037092
[epoch4, step473]: loss 0.036278
[epoch4, step474]: loss 0.039413
[epoch4, step475]: loss 0.037156
[epoch4, step476]: loss 0.039967
[epoch4, step477]: loss 0.036539
[epoch4, step478]: loss 0.036556
[epoch4, step479]: loss 0.039777
[epoch4, step480]: loss 0.039080
[epoch4, step481]: loss 0.036120
[epoch4, step482]: loss 0.036454
[epoch4, step483]: loss 0.040598
[epoch4, step484]: loss 0.037144
[epoch4, step485]: loss 0.040070
[epoch4, step486]: loss 0.037445
[epoch4, step487]: loss 0.036259
[epoch4, step488]: loss 0.040046
[epoch4, step489]: loss 0.038867
[epoch4, step490]: loss 0.036997
[epoch4, step491]: loss 0.036834
[epoch4, step492]: loss 0.039237
[epoch4, step493]: loss 0.036602
[epoch4, step494]: loss 0.038899
[epoch4, step495]: loss 0.037734
[epoch4, step496]: loss 0.036963
[epoch4, step497]: loss 0.040121
[epoch4, step498]: loss 0.039451
[epoch4, step499]: loss 0.037040
[epoch4, step500]: loss 0.036573
[epoch4, step501]: loss 0.039123
[epoch4, step502]: loss 0.037167
[epoch4, step503]: loss 0.040832
[epoch4, step504]: loss 0.036590
[epoch4, step505]: loss 0.036294
[epoch4, step506]: loss 0.040316
[epoch4, step507]: loss 0.039837
[epoch4, step508]: loss 0.037383
[epoch4, step509]: loss 0.036710
[epoch4, step510]: loss 0.039722
[epoch4, step511]: loss 0.037275
[epoch4, step512]: loss 0.039865
[epoch4, step513]: loss 0.036756
[epoch4, step514]: loss 0.037182
[epoch4, step515]: loss 0.039738
[epoch4, step516]: loss 0.039948
[epoch4, step517]: loss 0.036711
[epoch4, step518]: loss 0.036767
[epoch4, step519]: loss 0.039686
[epoch4, step520]: loss 0.036480
[epoch4, step521]: loss 0.039178
[epoch4, step522]: loss 0.036244
[epoch4, step523]: loss 0.037063
[epoch4, step524]: loss 0.039226
[epoch4, step525]: loss 0.040379
[epoch4, step526]: loss 0.036820
[epoch4, step527]: loss 0.036871
[epoch4, step528]: loss 0.040648
[epoch4, step529]: loss 0.036687
[epoch4, step530]: loss 0.039860
[epoch4, step531]: loss 0.036610
[epoch4, step532]: loss 0.036512
[epoch4, step533]: loss 0.040610
[epoch4, step534]: loss 0.039551
[epoch4, step535]: loss 0.037094
[epoch4, step536]: loss 0.036780
[epoch4, step537]: loss 0.039606
[epoch4, step538]: loss 0.036964
[epoch4, step539]: loss 0.039334
[epoch4, step540]: loss 0.036149
[epoch4, step541]: loss 0.036332
[epoch4, step542]: loss 0.040026
[epoch4, step543]: loss 0.039351
[epoch4, step544]: loss 0.036665
[epoch4, step545]: loss 0.036201
[epoch4, step546]: loss 0.040202
[epoch4, step547]: loss 0.037105
[epoch4, step548]: loss 0.040646
[epoch4, step549]: loss 0.037332
[epoch4, step550]: loss 0.037011
[epoch4, step551]: loss 0.039553
[epoch4, step552]: loss 0.038876
[epoch4, step553]: loss 0.037178
[epoch4, step554]: loss 0.036450
[epoch4, step555]: loss 0.039253
[epoch4, step556]: loss 0.036702
[epoch4, step557]: loss 0.038946
[epoch4, step558]: loss 0.036897
[epoch4, step559]: loss 0.036352
[epoch4, step560]: loss 0.040005
[epoch4, step561]: loss 0.039662
[epoch4, step562]: loss 0.036619
[epoch4, step563]: loss 0.029372
[epoch4, step564]: loss 0.028830
[epoch4, step565]: loss 0.027715
[epoch4, step566]: loss 0.034974
[epoch4, step567]: loss 0.026471
[epoch4, step568]: loss 0.025237
[epoch4, step569]: loss 0.022891
[epoch4, step570]: loss 0.030295
[epoch4, step571]: loss 0.026695
[epoch4, step572]: loss 0.025626
[epoch4, step573]: loss 0.028067
[epoch4, step574]: loss 0.027279
[epoch4, step575]: loss 0.020601
[epoch4, step576]: loss 0.021818
[epoch4, step577]: loss 0.025307
[epoch4, step578]: loss 0.019275
[epoch4, step579]: loss 0.027509
[epoch4, step580]: loss 0.020293
[epoch4, step581]: loss 0.025047
[epoch4, step582]: loss 0.024851
[epoch4, step583]: loss 0.022123
[epoch4, step584]: loss 0.023724
[epoch4, step585]: loss 0.026534
[epoch4, step586]: loss 0.021925
[epoch4, step587]: loss 0.027756
[epoch4, step588]: loss 0.023087
[epoch4, step589]: loss 0.023197
[epoch4, step590]: loss 0.027627
[epoch4, step591]: loss 0.020747
[epoch4, step592]: loss 0.026166
[epoch4, step593]: loss 0.022370
[epoch4, step594]: loss 0.025961
[epoch4, step595]: loss 0.026655
[epoch4, step596]: loss 0.022743
[epoch4, step597]: loss 0.025118
[epoch4, step598]: loss 0.026525
[epoch4, step599]: loss 0.025354
[epoch4, step600]: loss 0.027269
[epoch4, step601]: loss 0.019507
[epoch4, step602]: loss 0.022634
[epoch4, step603]: loss 0.025791
[epoch4, step604]: loss 0.026670
[epoch4, step605]: loss 0.025570
[epoch4, step606]: loss 0.024790
[epoch4, step607]: loss 0.027622
[epoch4, step608]: loss 0.025717
[epoch4, step609]: loss 0.027024
[epoch4, step610]: loss 0.026294
[epoch4, step611]: loss 0.026381
[epoch4, step612]: loss 0.025565
[epoch4, step613]: loss 0.019587
[epoch4, step614]: loss 0.025343
[epoch4, step615]: loss 0.028335
[epoch4, step616]: loss 0.024063
[epoch4, step617]: loss 0.023793
[epoch4, step618]: loss 0.025768
[epoch4, step619]: loss 0.026786
[epoch4, step620]: loss 0.024520
[epoch4, step621]: loss 0.026163
[epoch4, step622]: loss 0.020829
[epoch4, step623]: loss 0.024571
[epoch4, step624]: loss 0.026538
[epoch4, step625]: loss 0.026092
[epoch4, step626]: loss 0.028598
[epoch4, step627]: loss 0.023233
[epoch4, step628]: loss 0.025936
[epoch4, step629]: loss 0.020973
[epoch4, step630]: loss 0.023346
[epoch4, step631]: loss 0.031469
[epoch4, step632]: loss 0.023340
[epoch4, step633]: loss 0.024641
[epoch4, step634]: loss 0.027331
[epoch4, step635]: loss 0.025849
[epoch4, step636]: loss 0.020994
[epoch4, step637]: loss 0.027355
[epoch4, step638]: loss 0.027171
[epoch4, step639]: loss 0.022919
[epoch4, step640]: loss 0.029547
[epoch4, step641]: loss 0.030744
[epoch4, step642]: loss 0.025040
[epoch4, step643]: loss 0.026027
[epoch4, step644]: loss 0.026205
[epoch4, step645]: loss 0.023762
[epoch4, step646]: loss 0.026765
[epoch4, step647]: loss 0.023754
[epoch4, step648]: loss 0.023235
[epoch4, step649]: loss 0.028730
[epoch4, step650]: loss 0.022411
[epoch4, step651]: loss 0.026236
[epoch4, step652]: loss 0.026726
[epoch4, step653]: loss 0.028355
[epoch4, step654]: loss 0.023315
[epoch4, step655]: loss 0.024097
[epoch4, step656]: loss 0.021738
[epoch4, step657]: loss 0.027881
[epoch4, step658]: loss 0.025349
[epoch4, step659]: loss 0.027663
[epoch4, step660]: loss 0.024025
[epoch4, step661]: loss 0.026844
[epoch4, step662]: loss 0.023957
[epoch4, step663]: loss 0.021334
[epoch4, step664]: loss 0.025061
[epoch4, step665]: loss 0.028258
[epoch4, step666]: loss 0.027025
[epoch4, step667]: loss 0.026644
[epoch4, step668]: loss 0.022599
[epoch4, step669]: loss 0.026352
[epoch4, step670]: loss 0.027091
[epoch4, step671]: loss 0.021269
[epoch4, step672]: loss 0.024282
[epoch4, step673]: loss 0.022432
[epoch4, step674]: loss 0.021590
[epoch4, step675]: loss 0.020374
[epoch4, step676]: loss 0.024577
[epoch4, step677]: loss 0.025606
[epoch4, step678]: loss 0.023460
[epoch4, step679]: loss 0.024083
[epoch4, step680]: loss 0.030864
[epoch4, step681]: loss 0.022117
[epoch4, step682]: loss 0.026382
[epoch4, step683]: loss 0.025955
[epoch4, step684]: loss 0.025019
[epoch4, step685]: loss 0.024298
[epoch4, step686]: loss 0.027396
[epoch4, step687]: loss 0.026940
[epoch4, step688]: loss 0.023054
[epoch4, step689]: loss 0.024426
[epoch4, step690]: loss 0.025372
[epoch4, step691]: loss 0.024354
[epoch4, step692]: loss 0.022719
[epoch4, step693]: loss 0.027856
[epoch4, step694]: loss 0.022982
[epoch4, step695]: loss 0.026408
[epoch4, step696]: loss 0.026048
[epoch4, step697]: loss 0.027356
[epoch4, step698]: loss 0.025065
[epoch4, step699]: loss 0.023558
[epoch4, step700]: loss 0.022018
[epoch4, step701]: loss 0.026275
[epoch4, step702]: loss 0.021867
[epoch4, step703]: loss 0.023293
[epoch4, step704]: loss 0.025667
[epoch4, step705]: loss 0.025244
[epoch4, step706]: loss 0.023893
[epoch4, step707]: loss 0.024614
[epoch4, step708]: loss 0.026124
[epoch4, step709]: loss 0.027803
[epoch4, step710]: loss 0.024014
[epoch4, step711]: loss 0.024021
[epoch4, step712]: loss 0.027277
[epoch4, step713]: loss 0.026505
[epoch4, step714]: loss 0.021675
[epoch4, step715]: loss 0.022897
[epoch4, step716]: loss 0.026133
[epoch4, step717]: loss 0.023784
[epoch4, step718]: loss 0.025075
[epoch4, step719]: loss 0.033561
[epoch4, step720]: loss 0.024950
[epoch4, step721]: loss 0.023212
[epoch4, step722]: loss 0.031188
[epoch4, step723]: loss 0.026334
[epoch4, step724]: loss 0.023414
[epoch4, step725]: loss 0.028313
[epoch4, step726]: loss 0.022556
[epoch4, step727]: loss 0.024971
[epoch4, step728]: loss 0.026838
[epoch4, step729]: loss 0.021493
[epoch4, step730]: loss 0.023156
[epoch4, step731]: loss 0.026266
[epoch4, step732]: loss 0.026043
[epoch4, step733]: loss 0.023994
[epoch4, step734]: loss 0.022976
[epoch4, step735]: loss 0.027428
[epoch4, step736]: loss 0.025159
[epoch4, step737]: loss 0.026466
[epoch4, step738]: loss 0.020714
[epoch4, step739]: loss 0.025539
[epoch4, step740]: loss 0.022633
[epoch4, step741]: loss 0.025361
[epoch4, step742]: loss 0.021982
[epoch4, step743]: loss 0.023197
[epoch4, step744]: loss 0.024010
[epoch4, step745]: loss 0.024830
[epoch4, step746]: loss 0.025515
[epoch4, step747]: loss 0.027781
[epoch4, step748]: loss 0.026032
[epoch4, step749]: loss 0.026877
[epoch4, step750]: loss 0.027822
[epoch4, step751]: loss 0.021835
[epoch4, step752]: loss 0.025248
[epoch4, step753]: loss 0.025583
[epoch4, step754]: loss 0.022900
[epoch4, step755]: loss 0.026404
[epoch4, step756]: loss 0.023601
[epoch4, step757]: loss 0.020745
[epoch4, step758]: loss 0.025084
[epoch4, step759]: loss 0.023214
[epoch4, step760]: loss 0.024056
[epoch4, step761]: loss 0.026517
[epoch4, step762]: loss 0.021735
[epoch4, step763]: loss 0.025662
[epoch4, step764]: loss 0.023729
[epoch4, step765]: loss 0.026352
[epoch4, step766]: loss 0.024902
[epoch4, step767]: loss 0.026675
[epoch4, step768]: loss 0.021461
[epoch4, step769]: loss 0.027007
[epoch4, step770]: loss 0.026202
[epoch4, step771]: loss 0.023496
[epoch4, step772]: loss 0.029155
[epoch4, step773]: loss 0.026694
[epoch4, step774]: loss 0.024009
[epoch4, step775]: loss 0.021001
[epoch4, step776]: loss 0.025744
[epoch4, step777]: loss 0.023249
[epoch4, step778]: loss 0.028224
[epoch4, step779]: loss 0.023807
[epoch4, step780]: loss 0.020171
[epoch4, step781]: loss 0.024632
[epoch4, step782]: loss 0.022883
[epoch4, step783]: loss 0.019403
[epoch4, step784]: loss 0.020629
[epoch4, step785]: loss 0.021488
[epoch4, step786]: loss 0.024392
[epoch4, step787]: loss 0.023575
[epoch4, step788]: loss 0.024944
[epoch4, step789]: loss 0.022596
[epoch4, step790]: loss 0.023205
[epoch4, step791]: loss 0.026956
[epoch4, step792]: loss 0.025136
[epoch4, step793]: loss 0.027197
[epoch4, step794]: loss 0.020430
[epoch4, step795]: loss 0.025759
[epoch4, step796]: loss 0.027972
[epoch4, step797]: loss 0.028015
[epoch4, step798]: loss 0.027216
[epoch4, step799]: loss 0.025742
[epoch4, step800]: loss 0.021695
[epoch4, step801]: loss 0.022093
[epoch4, step802]: loss 0.023068
[epoch4, step803]: loss 0.026277
[epoch4, step804]: loss 0.027562
[epoch4, step805]: loss 0.028642
[epoch4, step806]: loss 0.021736
[epoch4, step807]: loss 0.020763
[epoch4, step808]: loss 0.023075
[epoch4, step809]: loss 0.023110
[epoch4, step810]: loss 0.025982
[epoch4, step811]: loss 0.025977
[epoch4, step812]: loss 0.024616
[epoch4, step813]: loss 0.023818
[epoch4, step814]: loss 0.025390
[epoch4, step815]: loss 0.024940
[epoch4, step816]: loss 0.024457
[epoch4, step817]: loss 0.024704
[epoch4, step818]: loss 0.022537
[epoch4, step819]: loss 0.020396
[epoch4, step820]: loss 0.023582
[epoch4, step821]: loss 0.021898
[epoch4, step822]: loss 0.030869
[epoch4, step823]: loss 0.023902
[epoch4, step824]: loss 0.027066
[epoch4, step825]: loss 0.025370
[epoch4, step826]: loss 0.024458
[epoch4, step827]: loss 0.027241
[epoch4, step828]: loss 0.028840
[epoch4, step829]: loss 0.026456
[epoch4, step830]: loss 0.022607
[epoch4, step831]: loss 0.026388
[epoch4, step832]: loss 0.021136
[epoch4, step833]: loss 0.029437
[epoch4, step834]: loss 0.025578
[epoch4, step835]: loss 0.020754
[epoch4, step836]: loss 0.026907
[epoch4, step837]: loss 0.025537
[epoch4, step838]: loss 0.026250
[epoch4, step839]: loss 0.028496
[epoch4, step840]: loss 0.020864
[epoch4, step841]: loss 0.024162
[epoch4, step842]: loss 0.027739
[epoch4, step843]: loss 0.025012
[epoch4, step844]: loss 0.025143
[epoch4, step845]: loss 0.021286
[epoch4, step846]: loss 0.025476
[epoch4, step847]: loss 0.026836
[epoch4, step848]: loss 0.025077
[epoch4, step849]: loss 0.025290
[epoch4, step850]: loss 0.023366
[epoch4, step851]: loss 0.024255
[epoch4, step852]: loss 0.023243
[epoch4, step853]: loss 0.029237
[epoch4, step854]: loss 0.022724
[epoch4, step855]: loss 0.027333
[epoch4, step856]: loss 0.022255
[epoch4, step857]: loss 0.026426
[epoch4, step858]: loss 0.024545
[epoch4, step859]: loss 0.024057
[epoch4, step860]: loss 0.022689
[epoch4, step861]: loss 0.023713
[epoch4, step862]: loss 0.023267
[epoch4, step863]: loss 0.020827
[epoch4, step864]: loss 0.026689
[epoch4, step865]: loss 0.023526
[epoch4, step866]: loss 0.025195
[epoch4, step867]: loss 0.026298
[epoch4, step868]: loss 0.027049
[epoch4, step869]: loss 0.024052
[epoch4, step870]: loss 0.031615
[epoch4, step871]: loss 0.022112
[epoch4, step872]: loss 0.025610
[epoch4, step873]: loss 0.025879
[epoch4, step874]: loss 0.023864
[epoch4, step875]: loss 0.024312
[epoch4, step876]: loss 0.024274
[epoch4, step877]: loss 0.019265
[epoch4, step878]: loss 0.023480
[epoch4, step879]: loss 0.028544
[epoch4, step880]: loss 0.025435
[epoch4, step881]: loss 0.022403
[epoch4, step882]: loss 0.024561
[epoch4, step883]: loss 0.024187
[epoch4, step884]: loss 0.026475
[epoch4, step885]: loss 0.026056
[epoch4, step886]: loss 0.026639
[epoch4, step887]: loss 0.024118
[epoch4, step888]: loss 0.024744
[epoch4, step889]: loss 0.023696
[epoch4, step890]: loss 0.023564
[epoch4, step891]: loss 0.025599
[epoch4, step892]: loss 0.021016
[epoch4, step893]: loss 0.024733
[epoch4, step894]: loss 0.024967
[epoch4, step895]: loss 0.022652
[epoch4, step896]: loss 0.021841
[epoch4, step897]: loss 0.024118
[epoch4, step898]: loss 0.025623
[epoch4, step899]: loss 0.028158
[epoch4, step900]: loss 0.027175
[epoch4, step901]: loss 0.025617
[epoch4, step902]: loss 0.024008
[epoch4, step903]: loss 0.024460
[epoch4, step904]: loss 0.028230
[epoch4, step905]: loss 0.027586
[epoch4, step906]: loss 0.022474
[epoch4, step907]: loss 0.023645
[epoch4, step908]: loss 0.022671
[epoch4, step909]: loss 0.025675
[epoch4, step910]: loss 0.023166
[epoch4, step911]: loss 0.025194
[epoch4, step912]: loss 0.023920
[epoch4, step913]: loss 0.024257
[epoch4, step914]: loss 0.030786
[epoch4, step915]: loss 0.024083
[epoch4, step916]: loss 0.023883
[epoch4, step917]: loss 0.025146
[epoch4, step918]: loss 0.028667
[epoch4, step919]: loss 0.024369
[epoch4, step920]: loss 0.027761
[epoch4, step921]: loss 0.024595
[epoch4, step922]: loss 0.023359
[epoch4, step923]: loss 0.022687
[epoch4, step924]: loss 0.021149
[epoch4, step925]: loss 0.025603
[epoch4, step926]: loss 0.026715
[epoch4, step927]: loss 0.025904
[epoch4, step928]: loss 0.024863
[epoch4, step929]: loss 0.027670
[epoch4, step930]: loss 0.025948
[epoch4, step931]: loss 0.027420
[epoch4, step932]: loss 0.021695
[epoch4, step933]: loss 0.028142
[epoch4, step934]: loss 0.022094
[epoch4, step935]: loss 0.022131
[epoch4, step936]: loss 0.022540
[epoch4, step937]: loss 0.027496
[epoch4, step938]: loss 0.025340
[epoch4, step939]: loss 0.020947
[epoch4, step940]: loss 0.022912
[epoch4, step941]: loss 0.026850
[epoch4, step942]: loss 0.025485
[epoch4, step943]: loss 0.023333
[epoch4, step944]: loss 0.027838
[epoch4, step945]: loss 0.020612
[epoch4, step946]: loss 0.025447
[epoch4, step947]: loss 0.028123
[epoch4, step948]: loss 0.019618
[epoch4, step949]: loss 0.022964
[epoch4, step950]: loss 0.026673
[epoch4, step951]: loss 0.028656
[epoch4, step952]: loss 0.025368
[epoch4, step953]: loss 0.027658
[epoch4, step954]: loss 0.022170
[epoch4, step955]: loss 0.037026
[epoch4, step956]: loss 0.052431
[epoch4, step957]: loss 0.045445
[epoch4, step958]: loss 0.039563
[epoch4, step959]: loss 0.042136
[epoch4, step960]: loss 0.040111
[epoch4, step961]: loss 0.041599
[epoch4, step962]: loss 0.041200
[epoch4, step963]: loss 0.040981
[epoch4, step964]: loss 0.041275
[epoch4, step965]: loss 0.040383
[epoch4, step966]: loss 0.037691
[epoch4, step967]: loss 0.037596
[epoch4, step968]: loss 0.041577
[epoch4, step969]: loss 0.040790
[epoch4, step970]: loss 0.039186
[epoch4, step971]: loss 0.037914
[epoch4, step972]: loss 0.039800
[epoch4, step973]: loss 0.039070
[epoch4, step974]: loss 0.041419
[epoch4, step975]: loss 0.038070
[epoch4, step976]: loss 0.037041
[epoch4, step977]: loss 0.040860
[epoch4, step978]: loss 0.039319
[epoch4, step979]: loss 0.038508
[epoch4, step980]: loss 0.036608
[epoch4, step981]: loss 0.038753
[epoch4, step982]: loss 0.038935
[epoch4, step983]: loss 0.040093
[epoch4, step984]: loss 0.036277
[epoch4, step985]: loss 0.036670
[epoch4, step986]: loss 0.041170
[epoch4, step987]: loss 0.039138
[epoch4, step988]: loss 0.038945
[epoch4, step989]: loss 0.037753
[epoch4, step990]: loss 0.038488
[epoch4, step991]: loss 0.039318
[epoch4, step992]: loss 0.039855
[epoch4, step993]: loss 0.037020
[epoch4, step994]: loss 0.036371
[epoch4, step995]: loss 0.040232
[epoch4, step996]: loss 0.038211
[epoch4, step997]: loss 0.038535
[epoch4, step998]: loss 0.037577
[epoch4, step999]: loss 0.038771
[epoch4, step1000]: loss 0.038834
[epoch4, step1001]: loss 0.039731
[epoch4, step1002]: loss 0.037412
[epoch4, step1003]: loss 0.036504
[epoch4, step1004]: loss 0.040192
[epoch4, step1005]: loss 0.037777
[epoch4, step1006]: loss 0.038345
[epoch4, step1007]: loss 0.036545
[epoch4, step1008]: loss 0.037966
[epoch4, step1009]: loss 0.038595
[epoch4, step1010]: loss 0.040179
[epoch4, step1011]: loss 0.037042
[epoch4, step1012]: loss 0.037310
[epoch4, step1013]: loss 0.040215
[epoch4, step1014]: loss 0.039196
[epoch4, step1015]: loss 0.038690
[epoch4, step1016]: loss 0.036599
[epoch4, step1017]: loss 0.038220
[epoch4, step1018]: loss 0.038328
[epoch4, step1019]: loss 0.039754
[epoch4, step1020]: loss 0.036637
[epoch4, step1021]: loss 0.036293
[epoch4, step1022]: loss 0.039810
[epoch4, step1023]: loss 0.038336
[epoch4, step1024]: loss 0.038837
[epoch4, step1025]: loss 0.036280
[epoch4, step1026]: loss 0.037681
[epoch4, step1027]: loss 0.038087
[epoch4, step1028]: loss 0.039545
[epoch4, step1029]: loss 0.036645
[epoch4, step1030]: loss 0.036131
[epoch4, step1031]: loss 0.038640
[epoch4, step1032]: loss 0.038717
[epoch4, step1033]: loss 0.037794
[epoch4, step1034]: loss 0.036491
[epoch4, step1035]: loss 0.037700
[epoch4, step1036]: loss 0.038492
[epoch4, step1037]: loss 0.039361
[epoch4, step1038]: loss 0.036594
[epoch4, step1039]: loss 0.036858
[epoch4, step1040]: loss 0.039265
[epoch4, step1041]: loss 0.038050
[epoch4, step1042]: loss 0.037190
[epoch4, step1043]: loss 0.036541
[epoch4, step1044]: loss 0.038347
[epoch4, step1045]: loss 0.038410
[epoch4, step1046]: loss 0.039670
[epoch4, step1047]: loss 0.036878
[epoch4, step1048]: loss 0.036256
[epoch4, step1049]: loss 0.039830
[epoch4, step1050]: loss 0.038614
[epoch4, step1051]: loss 0.038174
[epoch4, step1052]: loss 0.037086
[epoch4, step1053]: loss 0.038595
[epoch4, step1054]: loss 0.038411
[epoch4, step1055]: loss 0.038972
[epoch4, step1056]: loss 0.036142
[epoch4, step1057]: loss 0.037303
[epoch4, step1058]: loss 0.040552
[epoch4, step1059]: loss 0.038524
[epoch4, step1060]: loss 0.038311
[epoch4, step1061]: loss 0.036071
[epoch4, step1062]: loss 0.038618
[epoch4, step1063]: loss 0.038235
[epoch4, step1064]: loss 0.039564
[epoch4, step1065]: loss 0.036667
[epoch4, step1066]: loss 0.036217
[epoch4, step1067]: loss 0.039734
[epoch4, step1068]: loss 0.036921
[epoch4, step1069]: loss 0.037509
[epoch4, step1070]: loss 0.036542
[epoch4, step1071]: loss 0.038828
[epoch4, step1072]: loss 0.038995
[epoch4, step1073]: loss 0.039251
[epoch4, step1074]: loss 0.036831
[epoch4, step1075]: loss 0.036968
[epoch4, step1076]: loss 0.039804
[epoch4, step1077]: loss 0.038216
[epoch4, step1078]: loss 0.037869
[epoch4, step1079]: loss 0.037595
[epoch4, step1080]: loss 0.038418
[epoch4, step1081]: loss 0.038000
[epoch4, step1082]: loss 0.039307
[epoch4, step1083]: loss 0.037413
[epoch4, step1084]: loss 0.036885
[epoch4, step1085]: loss 0.039162
[epoch4, step1086]: loss 0.037908
[epoch4, step1087]: loss 0.038130
[epoch4, step1088]: loss 0.036436
[epoch4, step1089]: loss 0.038665
[epoch4, step1090]: loss 0.038869
[epoch4, step1091]: loss 0.039795
[epoch4, step1092]: loss 0.036505
[epoch4, step1093]: loss 0.036588
[epoch4, step1094]: loss 0.038777
[epoch4, step1095]: loss 0.037791
[epoch4, step1096]: loss 0.037616
[epoch4, step1097]: loss 0.036606
[epoch4, step1098]: loss 0.038212
[epoch4, step1099]: loss 0.037824
[epoch4, step1100]: loss 0.040066
[epoch4, step1101]: loss 0.037015
[epoch4, step1102]: loss 0.036514
[epoch4, step1103]: loss 0.039159
[epoch4, step1104]: loss 0.038077
[epoch4, step1105]: loss 0.038260
[epoch4, step1106]: loss 0.035665
[epoch4, step1107]: loss 0.038468
[epoch4, step1108]: loss 0.037877
[epoch4, step1109]: loss 0.039829
[epoch4, step1110]: loss 0.037355
[epoch4, step1111]: loss 0.036808
[epoch4, step1112]: loss 0.040008
[epoch4, step1113]: loss 0.037837
[epoch4, step1114]: loss 0.038392
[epoch4, step1115]: loss 0.036735
[epoch4, step1116]: loss 0.038401
[epoch4, step1117]: loss 0.038270
[epoch4, step1118]: loss 0.039385
[epoch4, step1119]: loss 0.036554
[epoch4, step1120]: loss 0.036507
[epoch4, step1121]: loss 0.039585
[epoch4, step1122]: loss 0.037617
[epoch4, step1123]: loss 0.037335
[epoch4, step1124]: loss 0.037292
[epoch4, step1125]: loss 0.038640
[epoch4, step1126]: loss 0.039189
[epoch4, step1127]: loss 0.039574
[epoch4, step1128]: loss 0.036904
[epoch4, step1129]: loss 0.036498
[epoch4, step1130]: loss 0.040325
[epoch4, step1131]: loss 0.038540
[epoch4, step1132]: loss 0.038384
[epoch4, step1133]: loss 0.036194
[epoch4, step1134]: loss 0.038121
[epoch4, step1135]: loss 0.039190
[epoch4, step1136]: loss 0.040151
[epoch4, step1137]: loss 0.036816
[epoch4, step1138]: loss 0.036869
[epoch4, step1139]: loss 0.039598
[epoch4, step1140]: loss 0.037511
[epoch4, step1141]: loss 0.037735
[epoch4, step1142]: loss 0.036340
[epoch4, step1143]: loss 0.037788
[epoch4, step1144]: loss 0.038358
[epoch4, step1145]: loss 0.038961
[epoch4, step1146]: loss 0.036390
[epoch4, step1147]: loss 0.037410
[epoch4, step1148]: loss 0.039729
[epoch4, step1149]: loss 0.037801
[epoch4, step1150]: loss 0.037836
[epoch4, step1151]: loss 0.036927
[epoch4, step1152]: loss 0.038863
[epoch4, step1153]: loss 0.037691
[epoch4, step1154]: loss 0.039834
[epoch4, step1155]: loss 0.036831
[epoch4, step1156]: loss 0.035999
[epoch4, step1157]: loss 0.039355
[epoch4, step1158]: loss 0.038301
[epoch4, step1159]: loss 0.038190
[epoch4, step1160]: loss 0.037436
[epoch4, step1161]: loss 0.038796
[epoch4, step1162]: loss 0.038172
[epoch4, step1163]: loss 0.038790
[epoch4, step1164]: loss 0.036624
[epoch4, step1165]: loss 0.037727
[epoch4, step1166]: loss 0.039776
[epoch4, step1167]: loss 0.037253
[epoch4, step1168]: loss 0.038177
[epoch4, step1169]: loss 0.036345
[epoch4, step1170]: loss 0.038315
[epoch4, step1171]: loss 0.038162
[epoch4, step1172]: loss 0.039377
[epoch4, step1173]: loss 0.036825
[epoch4, step1174]: loss 0.037035
[epoch4, step1175]: loss 0.039468
[epoch4, step1176]: loss 0.037768
[epoch4, step1177]: loss 0.038191
[epoch4, step1178]: loss 0.036650
[epoch4, step1179]: loss 0.038119
[epoch4, step1180]: loss 0.038369
[epoch4, step1181]: loss 0.039968
[epoch4, step1182]: loss 0.036006
[epoch4, step1183]: loss 0.037116
[epoch4, step1184]: loss 0.039072
[epoch4, step1185]: loss 0.038189
[epoch4, step1186]: loss 0.037148
[epoch4, step1187]: loss 0.035693
[epoch4, step1188]: loss 0.037650
[epoch4, step1189]: loss 0.037851
[epoch4, step1190]: loss 0.038975
[epoch4, step1191]: loss 0.037266
[epoch4, step1192]: loss 0.036660
[epoch4, step1193]: loss 0.039532
[epoch4, step1194]: loss 0.037828
[epoch4, step1195]: loss 0.036781
[epoch4, step1196]: loss 0.035786
[epoch4, step1197]: loss 0.038517
[epoch4, step1198]: loss 0.038217
[epoch4, step1199]: loss 0.039052
[epoch4, step1200]: loss 0.036346
[epoch4, step1201]: loss 0.037143
[epoch4, step1202]: loss 0.040406
[epoch4, step1203]: loss 0.038106
[epoch4, step1204]: loss 0.037268
[epoch4, step1205]: loss 0.036039
[epoch4, step1206]: loss 0.037672
[epoch4, step1207]: loss 0.038458
[epoch4, step1208]: loss 0.039598
[epoch4, step1209]: loss 0.035518
[epoch4, step1210]: loss 0.037144
[epoch4, step1211]: loss 0.039124
[epoch4, step1212]: loss 0.037755
[epoch4, step1213]: loss 0.037434
[epoch4, step1214]: loss 0.036601
[epoch4, step1215]: loss 0.038877
[epoch4, step1216]: loss 0.037674
[epoch4, step1217]: loss 0.039933
[epoch4, step1218]: loss 0.036247
[epoch4, step1219]: loss 0.037272
[epoch4, step1220]: loss 0.039868
[epoch4, step1221]: loss 0.037137
[epoch4, step1222]: loss 0.038043
[epoch4, step1223]: loss 0.036450
[epoch4, step1224]: loss 0.038674
[epoch4, step1225]: loss 0.038213
[epoch4, step1226]: loss 0.038973
[epoch4, step1227]: loss 0.036486
[epoch4, step1228]: loss 0.036337
[epoch4, step1229]: loss 0.039214
[epoch4, step1230]: loss 0.038181
[epoch4, step1231]: loss 0.037795
[epoch4, step1232]: loss 0.037506
[epoch4, step1233]: loss 0.038048
[epoch4, step1234]: loss 0.037864
[epoch4, step1235]: loss 0.039753
[epoch4, step1236]: loss 0.036808
[epoch4, step1237]: loss 0.036181
[epoch4, step1238]: loss 0.038903
[epoch4, step1239]: loss 0.038569
[epoch4, step1240]: loss 0.038153
[epoch4, step1241]: loss 0.036094
[epoch4, step1242]: loss 0.038187
[epoch4, step1243]: loss 0.037949
[epoch4, step1244]: loss 0.039589
[epoch4, step1245]: loss 0.036947
[epoch4, step1246]: loss 0.036914
[epoch4, step1247]: loss 0.038607
[epoch4, step1248]: loss 0.038013
[epoch4, step1249]: loss 0.038374
[epoch4, step1250]: loss 0.036377
[epoch4, step1251]: loss 0.038480
[epoch4, step1252]: loss 0.039013
[epoch4, step1253]: loss 0.039617
[epoch4, step1254]: loss 0.036638
[epoch4, step1255]: loss 0.036691
[epoch4, step1256]: loss 0.039909
[epoch4, step1257]: loss 0.038263
[epoch4, step1258]: loss 0.038129
[epoch4, step1259]: loss 0.036291
[epoch4, step1260]: loss 0.038354
[epoch4, step1261]: loss 0.037974
[epoch4, step1262]: loss 0.038190
[epoch4, step1263]: loss 0.037122
[epoch4, step1264]: loss 0.036492
[epoch4, step1265]: loss 0.038342
[epoch4, step1266]: loss 0.037945
[epoch4, step1267]: loss 0.038106
[epoch4, step1268]: loss 0.036635
[epoch4, step1269]: loss 0.038341
[epoch4, step1270]: loss 0.037417
[epoch4, step1271]: loss 0.039703
[epoch4, step1272]: loss 0.036698
[epoch4, step1273]: loss 0.036335
[epoch4, step1274]: loss 0.039330
[epoch4, step1275]: loss 0.038295
[epoch4, step1276]: loss 0.037567
[epoch4, step1277]: loss 0.036466
[epoch4, step1278]: loss 0.038809
[epoch4, step1279]: loss 0.038433
[epoch4, step1280]: loss 0.039502
[epoch4, step1281]: loss 0.036446
[epoch4, step1282]: loss 0.036677
[epoch4, step1283]: loss 0.038848
[epoch4, step1284]: loss 0.037460
[epoch4, step1285]: loss 0.038300
[epoch4, step1286]: loss 0.035882
[epoch4, step1287]: loss 0.038973
[epoch4, step1288]: loss 0.038852
[epoch4, step1289]: loss 0.040164
[epoch4, step1290]: loss 0.036604
[epoch4, step1291]: loss 0.036311
[epoch4, step1292]: loss 0.040097
[epoch4, step1293]: loss 0.037154
[epoch4, step1294]: loss 0.037904
[epoch4, step1295]: loss 0.036931
[epoch4, step1296]: loss 0.038456
[epoch4, step1297]: loss 0.038013
[epoch4, step1298]: loss 0.039846
[epoch4, step1299]: loss 0.036757
[epoch4, step1300]: loss 0.037274
[epoch4, step1301]: loss 0.038490
[epoch4, step1302]: loss 0.037886
[epoch4, step1303]: loss 0.037973
[epoch4, step1304]: loss 0.035859
[epoch4, step1305]: loss 0.038589
[epoch4, step1306]: loss 0.038101
[epoch4, step1307]: loss 0.038754
[epoch4, step1308]: loss 0.036659
[epoch4, step1309]: loss 0.035992
[epoch4, step1310]: loss 0.039345
[epoch4, step1311]: loss 0.036885
[epoch4, step1312]: loss 0.038557
[epoch4, step1313]: loss 0.036536
[epoch4, step1314]: loss 0.038110
[epoch4, step1315]: loss 0.037819
[epoch4, step1316]: loss 0.040607
[epoch4, step1317]: loss 0.036041
[epoch4, step1318]: loss 0.036026
[epoch4, step1319]: loss 0.038824
[epoch4, step1320]: loss 0.038131
[epoch4, step1321]: loss 0.038259
[epoch4, step1322]: loss 0.036121
[epoch4, step1323]: loss 0.038600
[epoch4, step1324]: loss 0.037744
[epoch4, step1325]: loss 0.039188
[epoch4, step1326]: loss 0.036335
[epoch4, step1327]: loss 0.036470
[epoch4, step1328]: loss 0.039457
[epoch4, step1329]: loss 0.037755
[epoch4, step1330]: loss 0.038061
[epoch4, step1331]: loss 0.036125
[epoch4, step1332]: loss 0.038144
[epoch4, step1333]: loss 0.037193
[epoch4, step1334]: loss 0.039621
[epoch4, step1335]: loss 0.037196
[epoch4, step1336]: loss 0.036484
[epoch4, step1337]: loss 0.038794
[epoch4, step1338]: loss 0.037781
[epoch4, step1339]: loss 0.037854
[epoch4, step1340]: loss 0.036093
[epoch4, step1341]: loss 0.038481
[epoch4, step1342]: loss 0.037864
[epoch4, step1343]: loss 0.039444
[epoch4, step1344]: loss 0.036639
[epoch4, step1345]: loss 0.036597
[epoch4, step1346]: loss 0.038925
[epoch4, step1347]: loss 0.038512
[epoch4, step1348]: loss 0.037166
[epoch4, step1349]: loss 0.036507
[epoch4, step1350]: loss 0.038349
[epoch4, step1351]: loss 0.037576
[epoch4, step1352]: loss 0.038750
[epoch4, step1353]: loss 0.036194
[epoch4, step1354]: loss 0.036270
[epoch4, step1355]: loss 0.039510
[epoch4, step1356]: loss 0.037576
[epoch4, step1357]: loss 0.037331
[epoch4, step1358]: loss 0.036152
[epoch4, step1359]: loss 0.037812
[epoch4, step1360]: loss 0.038266
[epoch4, step1361]: loss 0.039486
[epoch4, step1362]: loss 0.037116
[epoch4, step1363]: loss 0.037016
[epoch4, step1364]: loss 0.039215
[epoch4, step1365]: loss 0.037852
[epoch4, step1366]: loss 0.037576
[epoch4, step1367]: loss 0.035531
[epoch4, step1368]: loss 0.039097
[epoch4, step1369]: loss 0.038312
[epoch4, step1370]: loss 0.038965
[epoch4, step1371]: loss 0.036709
[epoch4, step1372]: loss 0.036438
[epoch4, step1373]: loss 0.039401
[epoch4, step1374]: loss 0.038669
[epoch4, step1375]: loss 0.038538
[epoch4, step1376]: loss 0.036104
[epoch4, step1377]: loss 0.037537
[epoch4, step1378]: loss 0.038124
[epoch4, step1379]: loss 0.038746
[epoch4, step1380]: loss 0.036860
[epoch4, step1381]: loss 0.036408
[epoch4, step1382]: loss 0.039558
[epoch4, step1383]: loss 0.037663
[epoch4, step1384]: loss 0.037530
[epoch4, step1385]: loss 0.035660
[epoch4, step1386]: loss 0.038343
[epoch4, step1387]: loss 0.038540
[epoch4, step1388]: loss 0.038184
[epoch4, step1389]: loss 0.035769
[epoch4, step1390]: loss 0.036759
[epoch4, step1391]: loss 0.039007
[epoch4, step1392]: loss 0.037778
[epoch4, step1393]: loss 0.037991
[epoch4, step1394]: loss 0.036920
[epoch4, step1395]: loss 0.038339
[epoch4, step1396]: loss 0.037620
[epoch4, step1397]: loss 0.038885
[epoch4, step1398]: loss 0.036347
[epoch4, step1399]: loss 0.037327
[epoch4, step1400]: loss 0.039738
[epoch4, step1401]: loss 0.037560
[epoch4, step1402]: loss 0.037770
[epoch4, step1403]: loss 0.035301
[epoch4, step1404]: loss 0.037609
[epoch4, step1405]: loss 0.037893
[epoch4, step1406]: loss 0.038920
[epoch4, step1407]: loss 0.037447
[epoch4, step1408]: loss 0.035995
[epoch4, step1409]: loss 0.038910
[epoch4, step1410]: loss 0.037802
[epoch4, step1411]: loss 0.036767
[epoch4, step1412]: loss 0.036361
[epoch4, step1413]: loss 0.038276
[epoch4, step1414]: loss 0.037640
[epoch4, step1415]: loss 0.038778
[epoch4, step1416]: loss 0.036362
[epoch4, step1417]: loss 0.036278
[epoch4, step1418]: loss 0.039203
[epoch4, step1419]: loss 0.038460
[epoch4, step1420]: loss 0.037850
[epoch4, step1421]: loss 0.036693
[epoch4, step1422]: loss 0.038303
[epoch4, step1423]: loss 0.037646
[epoch4, step1424]: loss 0.039336
[epoch4, step1425]: loss 0.035442
[epoch4, step1426]: loss 0.036653
[epoch4, step1427]: loss 0.040133
[epoch4, step1428]: loss 0.038641
[epoch4, step1429]: loss 0.037785
[epoch4, step1430]: loss 0.036261
[epoch4, step1431]: loss 0.038331
[epoch4, step1432]: loss 0.037798
[epoch4, step1433]: loss 0.039196
[epoch4, step1434]: loss 0.035951
[epoch4, step1435]: loss 0.036746
[epoch4, step1436]: loss 0.039534
[epoch4, step1437]: loss 0.038007
[epoch4, step1438]: loss 0.038298
[epoch4, step1439]: loss 0.036094
[epoch4, step1440]: loss 0.037831
[epoch4, step1441]: loss 0.038737
[epoch4, step1442]: loss 0.038391
[epoch4, step1443]: loss 0.036102
[epoch4, step1444]: loss 0.035916
[epoch4, step1445]: loss 0.039605
[epoch4, step1446]: loss 0.038003
[epoch4, step1447]: loss 0.038490
[epoch4, step1448]: loss 0.036154
[epoch4, step1449]: loss 0.037609
[epoch4, step1450]: loss 0.038058
[epoch4, step1451]: loss 0.039367
[epoch4, step1452]: loss 0.036124
[epoch4, step1453]: loss 0.037367
[epoch4, step1454]: loss 0.039657
[epoch4, step1455]: loss 0.038358
[epoch4, step1456]: loss 0.037201
[epoch4, step1457]: loss 0.036857
[epoch4, step1458]: loss 0.038143
[epoch4, step1459]: loss 0.038061
[epoch4, step1460]: loss 0.039729
[epoch4, step1461]: loss 0.037040
[epoch4, step1462]: loss 0.037291
[epoch4, step1463]: loss 0.039327
[epoch4, step1464]: loss 0.038051
[epoch4, step1465]: loss 0.037449
[epoch4, step1466]: loss 0.035907
[epoch4, step1467]: loss 0.038047
[epoch4, step1468]: loss 0.037515
[epoch4, step1469]: loss 0.038951
[epoch4, step1470]: loss 0.036536
[epoch4, step1471]: loss 0.036017
[epoch4, step1472]: loss 0.039054
[epoch4, step1473]: loss 0.037732
[epoch4, step1474]: loss 0.038147
[epoch4, step1475]: loss 0.035990
[epoch4, step1476]: loss 0.038805
[epoch4, step1477]: loss 0.037808
[epoch4, step1478]: loss 0.039289
[epoch4, step1479]: loss 0.036265
[epoch4, step1480]: loss 0.036638
[epoch4, step1481]: loss 0.038439
[epoch4, step1482]: loss 0.037752
[epoch4, step1483]: loss 0.037907
[epoch4, step1484]: loss 0.036629
[epoch4, step1485]: loss 0.037873
[epoch4, step1486]: loss 0.036998
[epoch4, step1487]: loss 0.038841
[epoch4, step1488]: loss 0.036448
[epoch4, step1489]: loss 0.036142
[epoch4, step1490]: loss 0.039221
[epoch4, step1491]: loss 0.037797
[epoch4, step1492]: loss 0.037317
[epoch4, step1493]: loss 0.036293
[epoch4, step1494]: loss 0.038094
[epoch4, step1495]: loss 0.037751
[epoch4, step1496]: loss 0.038305
[epoch4, step1497]: loss 0.036618
[epoch4, step1498]: loss 0.036950
[epoch4, step1499]: loss 0.038658
[epoch4, step1500]: loss 0.038053
[epoch4, step1501]: loss 0.037813
[epoch4, step1502]: loss 0.035971
[epoch4, step1503]: loss 0.037927
[epoch4, step1504]: loss 0.037503
[epoch4, step1505]: loss 0.039236
[epoch4, step1506]: loss 0.035799
[epoch4, step1507]: loss 0.036621
[epoch4, step1508]: loss 0.039715
[epoch4, step1509]: loss 0.037414
[epoch4, step1510]: loss 0.036962
[epoch4, step1511]: loss 0.036876
[epoch4, step1512]: loss 0.038065
[epoch4, step1513]: loss 0.036736
[epoch4, step1514]: loss 0.039145
[epoch4, step1515]: loss 0.036809
[epoch4, step1516]: loss 0.036607

[epoch4]: avg loss 0.034695

[epoch5, step1]: loss 0.030188
[epoch5, step2]: loss 0.038865
[epoch5, step3]: loss 0.038896
[epoch5, step4]: loss 0.036130
[epoch5, step5]: loss 0.036791
[epoch5, step6]: loss 0.039286
[epoch5, step7]: loss 0.037102
[epoch5, step8]: loss 0.039436
[epoch5, step9]: loss 0.035809
[epoch5, step10]: loss 0.037605
[epoch5, step11]: loss 0.039163
[epoch5, step12]: loss 0.038995
[epoch5, step13]: loss 0.036421
[epoch5, step14]: loss 0.036723
[epoch5, step15]: loss 0.039115
[epoch5, step16]: loss 0.037003
[epoch5, step17]: loss 0.039539
[epoch5, step18]: loss 0.036972
[epoch5, step19]: loss 0.037075
[epoch5, step20]: loss 0.040026
[epoch5, step21]: loss 0.038974
[epoch5, step22]: loss 0.035951
[epoch5, step23]: loss 0.035790
[epoch5, step24]: loss 0.039292
[epoch5, step25]: loss 0.036292
[epoch5, step26]: loss 0.038894
[epoch5, step27]: loss 0.035653
[epoch5, step28]: loss 0.037238
[epoch5, step29]: loss 0.039334
[epoch5, step30]: loss 0.039680
[epoch5, step31]: loss 0.035809
[epoch5, step32]: loss 0.036976
[epoch5, step33]: loss 0.039781
[epoch5, step34]: loss 0.037448
[epoch5, step35]: loss 0.039614
[epoch5, step36]: loss 0.035970
[epoch5, step37]: loss 0.036985
[epoch5, step38]: loss 0.039226
[epoch5, step39]: loss 0.039061
[epoch5, step40]: loss 0.036476
[epoch5, step41]: loss 0.036069
[epoch5, step42]: loss 0.039480
[epoch5, step43]: loss 0.036857
[epoch5, step44]: loss 0.039898
[epoch5, step45]: loss 0.036209
[epoch5, step46]: loss 0.037210
[epoch5, step47]: loss 0.038728
[epoch5, step48]: loss 0.038680
[epoch5, step49]: loss 0.034747
[epoch5, step50]: loss 0.036536
[epoch5, step51]: loss 0.039045
[epoch5, step52]: loss 0.036581
[epoch5, step53]: loss 0.039765
[epoch5, step54]: loss 0.035910
[epoch5, step55]: loss 0.037427
[epoch5, step56]: loss 0.040187
[epoch5, step57]: loss 0.039543
[epoch5, step58]: loss 0.036201
[epoch5, step59]: loss 0.035656
[epoch5, step60]: loss 0.039707
[epoch5, step61]: loss 0.036168
[epoch5, step62]: loss 0.038921
[epoch5, step63]: loss 0.035560
[epoch5, step64]: loss 0.036680
[epoch5, step65]: loss 0.039477
[epoch5, step66]: loss 0.039060
[epoch5, step67]: loss 0.036493
[epoch5, step68]: loss 0.036433
[epoch5, step69]: loss 0.039139
[epoch5, step70]: loss 0.036559
[epoch5, step71]: loss 0.038832
[epoch5, step72]: loss 0.036153
[epoch5, step73]: loss 0.036904
[epoch5, step74]: loss 0.039185
[epoch5, step75]: loss 0.039316
[epoch5, step76]: loss 0.036780
[epoch5, step77]: loss 0.037131
[epoch5, step78]: loss 0.039357
[epoch5, step79]: loss 0.036261
[epoch5, step80]: loss 0.040088
[epoch5, step81]: loss 0.036269
[epoch5, step82]: loss 0.036627
[epoch5, step83]: loss 0.038690
[epoch5, step84]: loss 0.039326
[epoch5, step85]: loss 0.037003
[epoch5, step86]: loss 0.036880
[epoch5, step87]: loss 0.040235
[epoch5, step88]: loss 0.035630
[epoch5, step89]: loss 0.039035
[epoch5, step90]: loss 0.036646
[epoch5, step91]: loss 0.036412
[epoch5, step92]: loss 0.039405
[epoch5, step93]: loss 0.039134
[epoch5, step94]: loss 0.036016
[epoch5, step95]: loss 0.036989
[epoch5, step96]: loss 0.038914
[epoch5, step97]: loss 0.037440
[epoch5, step98]: loss 0.039320
[epoch5, step99]: loss 0.036241
[epoch5, step100]: loss 0.035892
[epoch5, step101]: loss 0.039853
[epoch5, step102]: loss 0.039046
[epoch5, step103]: loss 0.036140
[epoch5, step104]: loss 0.036565
[epoch5, step105]: loss 0.039514
[epoch5, step106]: loss 0.036839
[epoch5, step107]: loss 0.039483
[epoch5, step108]: loss 0.036541
[epoch5, step109]: loss 0.036664
[epoch5, step110]: loss 0.039850
[epoch5, step111]: loss 0.038860
[epoch5, step112]: loss 0.036476
[epoch5, step113]: loss 0.037319
[epoch5, step114]: loss 0.039002
[epoch5, step115]: loss 0.036656
[epoch5, step116]: loss 0.040052
[epoch5, step117]: loss 0.036092
[epoch5, step118]: loss 0.037619
[epoch5, step119]: loss 0.039747
[epoch5, step120]: loss 0.039367
[epoch5, step121]: loss 0.036078
[epoch5, step122]: loss 0.036529
[epoch5, step123]: loss 0.039585
[epoch5, step124]: loss 0.037200
[epoch5, step125]: loss 0.039785
[epoch5, step126]: loss 0.036224
[epoch5, step127]: loss 0.036730
[epoch5, step128]: loss 0.039173
[epoch5, step129]: loss 0.039026
[epoch5, step130]: loss 0.036530
[epoch5, step131]: loss 0.035925
[epoch5, step132]: loss 0.039372
[epoch5, step133]: loss 0.036520
[epoch5, step134]: loss 0.038649
[epoch5, step135]: loss 0.036799
[epoch5, step136]: loss 0.037933
[epoch5, step137]: loss 0.039035
[epoch5, step138]: loss 0.039093
[epoch5, step139]: loss 0.036151
[epoch5, step140]: loss 0.037104
[epoch5, step141]: loss 0.039551
[epoch5, step142]: loss 0.036769
[epoch5, step143]: loss 0.038910
[epoch5, step144]: loss 0.036534
[epoch5, step145]: loss 0.036973
[epoch5, step146]: loss 0.039316
[epoch5, step147]: loss 0.040465
[epoch5, step148]: loss 0.036003
[epoch5, step149]: loss 0.036090
[epoch5, step150]: loss 0.039070
[epoch5, step151]: loss 0.036761
[epoch5, step152]: loss 0.039177
[epoch5, step153]: loss 0.036362
[epoch5, step154]: loss 0.036608
[epoch5, step155]: loss 0.039144
[epoch5, step156]: loss 0.038700
[epoch5, step157]: loss 0.036397
[epoch5, step158]: loss 0.036842
[epoch5, step159]: loss 0.039430
[epoch5, step160]: loss 0.037045
[epoch5, step161]: loss 0.039819
[epoch5, step162]: loss 0.036542
[epoch5, step163]: loss 0.036878
[epoch5, step164]: loss 0.039517
[epoch5, step165]: loss 0.039153
[epoch5, step166]: loss 0.036616
[epoch5, step167]: loss 0.036162
[epoch5, step168]: loss 0.039987
[epoch5, step169]: loss 0.036505
[epoch5, step170]: loss 0.039731
[epoch5, step171]: loss 0.036632
[epoch5, step172]: loss 0.037116
[epoch5, step173]: loss 0.039601
[epoch5, step174]: loss 0.038940
[epoch5, step175]: loss 0.037050
[epoch5, step176]: loss 0.036826
[epoch5, step177]: loss 0.039693
[epoch5, step178]: loss 0.036707
[epoch5, step179]: loss 0.038449
[epoch5, step180]: loss 0.036564
[epoch5, step181]: loss 0.037080
[epoch5, step182]: loss 0.039688
[epoch5, step183]: loss 0.039872
[epoch5, step184]: loss 0.037341
[epoch5, step185]: loss 0.036882
[epoch5, step186]: loss 0.039510
[epoch5, step187]: loss 0.036936
[epoch5, step188]: loss 0.039157
[epoch5, step189]: loss 0.036306
[epoch5, step190]: loss 0.036304
[epoch5, step191]: loss 0.039239
[epoch5, step192]: loss 0.039760
[epoch5, step193]: loss 0.034537
[epoch5, step194]: loss 0.035700
[epoch5, step195]: loss 0.039674
[epoch5, step196]: loss 0.036790
[epoch5, step197]: loss 0.039096
[epoch5, step198]: loss 0.035464
[epoch5, step199]: loss 0.036888
[epoch5, step200]: loss 0.039870
[epoch5, step201]: loss 0.039658
[epoch5, step202]: loss 0.035933
[epoch5, step203]: loss 0.036757
[epoch5, step204]: loss 0.039822
[epoch5, step205]: loss 0.036317
[epoch5, step206]: loss 0.039202
[epoch5, step207]: loss 0.036180
[epoch5, step208]: loss 0.037452
[epoch5, step209]: loss 0.039825
[epoch5, step210]: loss 0.040088
[epoch5, step211]: loss 0.037108
[epoch5, step212]: loss 0.036969
[epoch5, step213]: loss 0.038953
[epoch5, step214]: loss 0.036043
[epoch5, step215]: loss 0.039453
[epoch5, step216]: loss 0.036609
[epoch5, step217]: loss 0.035937
[epoch5, step218]: loss 0.039705
[epoch5, step219]: loss 0.038952
[epoch5, step220]: loss 0.036641
[epoch5, step221]: loss 0.036987
[epoch5, step222]: loss 0.039664
[epoch5, step223]: loss 0.037105
[epoch5, step224]: loss 0.039097
[epoch5, step225]: loss 0.036277
[epoch5, step226]: loss 0.036723
[epoch5, step227]: loss 0.038522
[epoch5, step228]: loss 0.039646
[epoch5, step229]: loss 0.035839
[epoch5, step230]: loss 0.037072
[epoch5, step231]: loss 0.039776
[epoch5, step232]: loss 0.036367
[epoch5, step233]: loss 0.038518
[epoch5, step234]: loss 0.035941
[epoch5, step235]: loss 0.036963
[epoch5, step236]: loss 0.039579
[epoch5, step237]: loss 0.039277
[epoch5, step238]: loss 0.036244
[epoch5, step239]: loss 0.036027
[epoch5, step240]: loss 0.038814
[epoch5, step241]: loss 0.037464
[epoch5, step242]: loss 0.039444
[epoch5, step243]: loss 0.037121
[epoch5, step244]: loss 0.036903
[epoch5, step245]: loss 0.039055
[epoch5, step246]: loss 0.039236
[epoch5, step247]: loss 0.036912
[epoch5, step248]: loss 0.036213
[epoch5, step249]: loss 0.038825
[epoch5, step250]: loss 0.037000
[epoch5, step251]: loss 0.039723
[epoch5, step252]: loss 0.036878
[epoch5, step253]: loss 0.036240
[epoch5, step254]: loss 0.038898
[epoch5, step255]: loss 0.039407
[epoch5, step256]: loss 0.036081
[epoch5, step257]: loss 0.036387
[epoch5, step258]: loss 0.039944
[epoch5, step259]: loss 0.036897
[epoch5, step260]: loss 0.038808
[epoch5, step261]: loss 0.037224
[epoch5, step262]: loss 0.037385
[epoch5, step263]: loss 0.038731
[epoch5, step264]: loss 0.039045
[epoch5, step265]: loss 0.036680
[epoch5, step266]: loss 0.036571
[epoch5, step267]: loss 0.038772
[epoch5, step268]: loss 0.036605
[epoch5, step269]: loss 0.039382
[epoch5, step270]: loss 0.035845
[epoch5, step271]: loss 0.036982
[epoch5, step272]: loss 0.039253
[epoch5, step273]: loss 0.038949
[epoch5, step274]: loss 0.036837
[epoch5, step275]: loss 0.036084
[epoch5, step276]: loss 0.039036
[epoch5, step277]: loss 0.037228
[epoch5, step278]: loss 0.039455
[epoch5, step279]: loss 0.036007
[epoch5, step280]: loss 0.036962
[epoch5, step281]: loss 0.039150
[epoch5, step282]: loss 0.039744
[epoch5, step283]: loss 0.036001
[epoch5, step284]: loss 0.036078
[epoch5, step285]: loss 0.040196
[epoch5, step286]: loss 0.035962
[epoch5, step287]: loss 0.039571
[epoch5, step288]: loss 0.035891
[epoch5, step289]: loss 0.037671
[epoch5, step290]: loss 0.039371
[epoch5, step291]: loss 0.039527
[epoch5, step292]: loss 0.035548
[epoch5, step293]: loss 0.036169
[epoch5, step294]: loss 0.038742
[epoch5, step295]: loss 0.036199
[epoch5, step296]: loss 0.040083
[epoch5, step297]: loss 0.036088
[epoch5, step298]: loss 0.037307
[epoch5, step299]: loss 0.038411
[epoch5, step300]: loss 0.039504
[epoch5, step301]: loss 0.036368
[epoch5, step302]: loss 0.036908
[epoch5, step303]: loss 0.039759
[epoch5, step304]: loss 0.036450
[epoch5, step305]: loss 0.039110
[epoch5, step306]: loss 0.036405
[epoch5, step307]: loss 0.036572
[epoch5, step308]: loss 0.039820
[epoch5, step309]: loss 0.039507
[epoch5, step310]: loss 0.036580
[epoch5, step311]: loss 0.036970
[epoch5, step312]: loss 0.039022
[epoch5, step313]: loss 0.037055
[epoch5, step314]: loss 0.039153
[epoch5, step315]: loss 0.037328
[epoch5, step316]: loss 0.036566
[epoch5, step317]: loss 0.039772
[epoch5, step318]: loss 0.039370
[epoch5, step319]: loss 0.035791
[epoch5, step320]: loss 0.035760
[epoch5, step321]: loss 0.039005
[epoch5, step322]: loss 0.036603
[epoch5, step323]: loss 0.038849
[epoch5, step324]: loss 0.037158
[epoch5, step325]: loss 0.036970
[epoch5, step326]: loss 0.039086
[epoch5, step327]: loss 0.038524
[epoch5, step328]: loss 0.036588
[epoch5, step329]: loss 0.036220
[epoch5, step330]: loss 0.038791
[epoch5, step331]: loss 0.036839
[epoch5, step332]: loss 0.038544
[epoch5, step333]: loss 0.036267
[epoch5, step334]: loss 0.036794
[epoch5, step335]: loss 0.039461
[epoch5, step336]: loss 0.040081
[epoch5, step337]: loss 0.036748
[epoch5, step338]: loss 0.036205
[epoch5, step339]: loss 0.039164
[epoch5, step340]: loss 0.037341
[epoch5, step341]: loss 0.038995
[epoch5, step342]: loss 0.036065
[epoch5, step343]: loss 0.037142
[epoch5, step344]: loss 0.038927
[epoch5, step345]: loss 0.038478
[epoch5, step346]: loss 0.035981
[epoch5, step347]: loss 0.036088
[epoch5, step348]: loss 0.039537
[epoch5, step349]: loss 0.037136
[epoch5, step350]: loss 0.038653
[epoch5, step351]: loss 0.035517
[epoch5, step352]: loss 0.036528
[epoch5, step353]: loss 0.039108
[epoch5, step354]: loss 0.038210
[epoch5, step355]: loss 0.035223
[epoch5, step356]: loss 0.037208
[epoch5, step357]: loss 0.039300
[epoch5, step358]: loss 0.035334
[epoch5, step359]: loss 0.040236
[epoch5, step360]: loss 0.035052
[epoch5, step361]: loss 0.036404
[epoch5, step362]: loss 0.040035
[epoch5, step363]: loss 0.038879
[epoch5, step364]: loss 0.036347
[epoch5, step365]: loss 0.036141
[epoch5, step366]: loss 0.039647
[epoch5, step367]: loss 0.036625
[epoch5, step368]: loss 0.038514
[epoch5, step369]: loss 0.036140
[epoch5, step370]: loss 0.037214
[epoch5, step371]: loss 0.040031
[epoch5, step372]: loss 0.038755
[epoch5, step373]: loss 0.035716
[epoch5, step374]: loss 0.035739
[epoch5, step375]: loss 0.039854
[epoch5, step376]: loss 0.036806
[epoch5, step377]: loss 0.039403
[epoch5, step378]: loss 0.036758
[epoch5, step379]: loss 0.037446
[epoch5, step380]: loss 0.039803
[epoch5, step381]: loss 0.038896
[epoch5, step382]: loss 0.036648
[epoch5, step383]: loss 0.035484
[epoch5, step384]: loss 0.038580
[epoch5, step385]: loss 0.036462
[epoch5, step386]: loss 0.039330
[epoch5, step387]: loss 0.036281
[epoch5, step388]: loss 0.037746
[epoch5, step389]: loss 0.039202
[epoch5, step390]: loss 0.040146
[epoch5, step391]: loss 0.035868
[epoch5, step392]: loss 0.037021
[epoch5, step393]: loss 0.038702
[epoch5, step394]: loss 0.036743
[epoch5, step395]: loss 0.038966
[epoch5, step396]: loss 0.036429
[epoch5, step397]: loss 0.036464
[epoch5, step398]: loss 0.039374
[epoch5, step399]: loss 0.039103
[epoch5, step400]: loss 0.035932
[epoch5, step401]: loss 0.036291
[epoch5, step402]: loss 0.039247
[epoch5, step403]: loss 0.036606
[epoch5, step404]: loss 0.039684
[epoch5, step405]: loss 0.036556
[epoch5, step406]: loss 0.037062
[epoch5, step407]: loss 0.039036
[epoch5, step408]: loss 0.039260
[epoch5, step409]: loss 0.037615
[epoch5, step410]: loss 0.037081
[epoch5, step411]: loss 0.039114
[epoch5, step412]: loss 0.036088
[epoch5, step413]: loss 0.039080
[epoch5, step414]: loss 0.035972
[epoch5, step415]: loss 0.036961
[epoch5, step416]: loss 0.038566
[epoch5, step417]: loss 0.039389
[epoch5, step418]: loss 0.036132
[epoch5, step419]: loss 0.035712
[epoch5, step420]: loss 0.039408
[epoch5, step421]: loss 0.036423
[epoch5, step422]: loss 0.039218
[epoch5, step423]: loss 0.036340
[epoch5, step424]: loss 0.036983
[epoch5, step425]: loss 0.039399
[epoch5, step426]: loss 0.039508
[epoch5, step427]: loss 0.036630
[epoch5, step428]: loss 0.036247
[epoch5, step429]: loss 0.039874
[epoch5, step430]: loss 0.036476
[epoch5, step431]: loss 0.039424
[epoch5, step432]: loss 0.036114
[epoch5, step433]: loss 0.037536
[epoch5, step434]: loss 0.039113
[epoch5, step435]: loss 0.039563
[epoch5, step436]: loss 0.035897
[epoch5, step437]: loss 0.036637
[epoch5, step438]: loss 0.039855
[epoch5, step439]: loss 0.036808
[epoch5, step440]: loss 0.039041
[epoch5, step441]: loss 0.036544
[epoch5, step442]: loss 0.036591
[epoch5, step443]: loss 0.039855
[epoch5, step444]: loss 0.038961
[epoch5, step445]: loss 0.036717
[epoch5, step446]: loss 0.036999
[epoch5, step447]: loss 0.039973
[epoch5, step448]: loss 0.036931
[epoch5, step449]: loss 0.039187
[epoch5, step450]: loss 0.035610
[epoch5, step451]: loss 0.036812
[epoch5, step452]: loss 0.038412
[epoch5, step453]: loss 0.039415
[epoch5, step454]: loss 0.036291
[epoch5, step455]: loss 0.036631
[epoch5, step456]: loss 0.038528
[epoch5, step457]: loss 0.037354
[epoch5, step458]: loss 0.038974
[epoch5, step459]: loss 0.037049
[epoch5, step460]: loss 0.037019
[epoch5, step461]: loss 0.040020
[epoch5, step462]: loss 0.038569
[epoch5, step463]: loss 0.036417
[epoch5, step464]: loss 0.036348
[epoch5, step465]: loss 0.040677
[epoch5, step466]: loss 0.036615
[epoch5, step467]: loss 0.039084
[epoch5, step468]: loss 0.036313
[epoch5, step469]: loss 0.036996
[epoch5, step470]: loss 0.039469
[epoch5, step471]: loss 0.038693
[epoch5, step472]: loss 0.036777
[epoch5, step473]: loss 0.035998
[epoch5, step474]: loss 0.039108
[epoch5, step475]: loss 0.036738
[epoch5, step476]: loss 0.039528
[epoch5, step477]: loss 0.036128
[epoch5, step478]: loss 0.036141
[epoch5, step479]: loss 0.039123
[epoch5, step480]: loss 0.038439
[epoch5, step481]: loss 0.035805
[epoch5, step482]: loss 0.035873
[epoch5, step483]: loss 0.039658
[epoch5, step484]: loss 0.036892
[epoch5, step485]: loss 0.039424
[epoch5, step486]: loss 0.036693
[epoch5, step487]: loss 0.036288
[epoch5, step488]: loss 0.039658
[epoch5, step489]: loss 0.038452
[epoch5, step490]: loss 0.036693
[epoch5, step491]: loss 0.036648
[epoch5, step492]: loss 0.038897
[epoch5, step493]: loss 0.036342
[epoch5, step494]: loss 0.038558
[epoch5, step495]: loss 0.037398
[epoch5, step496]: loss 0.037120
[epoch5, step497]: loss 0.039443
[epoch5, step498]: loss 0.039117
[epoch5, step499]: loss 0.036642
[epoch5, step500]: loss 0.035955
[epoch5, step501]: loss 0.038826
[epoch5, step502]: loss 0.036408
[epoch5, step503]: loss 0.039385
[epoch5, step504]: loss 0.036018
[epoch5, step505]: loss 0.035882
[epoch5, step506]: loss 0.039630
[epoch5, step507]: loss 0.039465
[epoch5, step508]: loss 0.036677
[epoch5, step509]: loss 0.036333
[epoch5, step510]: loss 0.039431
[epoch5, step511]: loss 0.037022
[epoch5, step512]: loss 0.039639
[epoch5, step513]: loss 0.036476
[epoch5, step514]: loss 0.037079
[epoch5, step515]: loss 0.039250
[epoch5, step516]: loss 0.039581
[epoch5, step517]: loss 0.036322
[epoch5, step518]: loss 0.036448
[epoch5, step519]: loss 0.039324
[epoch5, step520]: loss 0.035979
[epoch5, step521]: loss 0.039798
[epoch5, step522]: loss 0.036842
[epoch5, step523]: loss 0.037662
[epoch5, step524]: loss 0.039171
[epoch5, step525]: loss 0.040265
[epoch5, step526]: loss 0.037197
[epoch5, step527]: loss 0.036909
[epoch5, step528]: loss 0.040078
[epoch5, step529]: loss 0.037148
[epoch5, step530]: loss 0.040297
[epoch5, step531]: loss 0.036862
[epoch5, step532]: loss 0.037232
[epoch5, step533]: loss 0.040920
[epoch5, step534]: loss 0.039716
[epoch5, step535]: loss 0.037591
[epoch5, step536]: loss 0.037338
[epoch5, step537]: loss 0.039921
[epoch5, step538]: loss 0.037397
[epoch5, step539]: loss 0.039561
[epoch5, step540]: loss 0.036413
[epoch5, step541]: loss 0.036899
[epoch5, step542]: loss 0.039725
[epoch5, step543]: loss 0.039394
[epoch5, step544]: loss 0.036813
[epoch5, step545]: loss 0.036075
[epoch5, step546]: loss 0.040217
[epoch5, step547]: loss 0.037194
[epoch5, step548]: loss 0.039512
[epoch5, step549]: loss 0.037174
[epoch5, step550]: loss 0.037385
[epoch5, step551]: loss 0.039496
[epoch5, step552]: loss 0.038938
[epoch5, step553]: loss 0.037206
[epoch5, step554]: loss 0.036786
[epoch5, step555]: loss 0.039197
[epoch5, step556]: loss 0.036831
[epoch5, step557]: loss 0.039146
[epoch5, step558]: loss 0.036901
[epoch5, step559]: loss 0.036569
[epoch5, step560]: loss 0.039707
[epoch5, step561]: loss 0.039244
[epoch5, step562]: loss 0.036766
[epoch5, step563]: loss 0.030130
[epoch5, step564]: loss 0.029760
[epoch5, step565]: loss 0.028643
[epoch5, step566]: loss 0.036111
[epoch5, step567]: loss 0.027573
[epoch5, step568]: loss 0.025882
[epoch5, step569]: loss 0.026254
[epoch5, step570]: loss 0.035009
[epoch5, step571]: loss 0.041414
[epoch5, step572]: loss 0.035555
[epoch5, step573]: loss 0.034915
[epoch5, step574]: loss 0.033405
[epoch5, step575]: loss 0.022870
[epoch5, step576]: loss 0.024988
[epoch5, step577]: loss 0.029177
[epoch5, step578]: loss 0.019613
[epoch5, step579]: loss 0.030901
[epoch5, step580]: loss 0.020665
[epoch5, step581]: loss 0.028080
[epoch5, step582]: loss 0.027158
[epoch5, step583]: loss 0.022636
[epoch5, step584]: loss 0.024169
[epoch5, step585]: loss 0.026773
[epoch5, step586]: loss 0.022013
[epoch5, step587]: loss 0.028218
[epoch5, step588]: loss 0.023351
[epoch5, step589]: loss 0.023425
[epoch5, step590]: loss 0.028007
[epoch5, step591]: loss 0.020911
[epoch5, step592]: loss 0.026109
[epoch5, step593]: loss 0.022674
[epoch5, step594]: loss 0.026195
[epoch5, step595]: loss 0.026696
[epoch5, step596]: loss 0.022893
[epoch5, step597]: loss 0.025285
[epoch5, step598]: loss 0.026399
[epoch5, step599]: loss 0.025402
[epoch5, step600]: loss 0.027698
[epoch5, step601]: loss 0.019880
[epoch5, step602]: loss 0.022764
[epoch5, step603]: loss 0.026054
[epoch5, step604]: loss 0.026834
[epoch5, step605]: loss 0.025483
[epoch5, step606]: loss 0.025079
[epoch5, step607]: loss 0.028086
[epoch5, step608]: loss 0.026190
[epoch5, step609]: loss 0.027190
[epoch5, step610]: loss 0.025785
[epoch5, step611]: loss 0.026616
[epoch5, step612]: loss 0.026138
[epoch5, step613]: loss 0.019683
[epoch5, step614]: loss 0.025493
[epoch5, step615]: loss 0.028537
[epoch5, step616]: loss 0.024165
[epoch5, step617]: loss 0.023828
[epoch5, step618]: loss 0.026035
[epoch5, step619]: loss 0.026881
[epoch5, step620]: loss 0.024558
[epoch5, step621]: loss 0.026420
[epoch5, step622]: loss 0.020849
[epoch5, step623]: loss 0.024537
[epoch5, step624]: loss 0.026737
[epoch5, step625]: loss 0.026229
[epoch5, step626]: loss 0.028687
[epoch5, step627]: loss 0.023265
[epoch5, step628]: loss 0.026231
[epoch5, step629]: loss 0.021022
[epoch5, step630]: loss 0.023579
[epoch5, step631]: loss 0.031249
[epoch5, step632]: loss 0.023594
[epoch5, step633]: loss 0.024759
[epoch5, step634]: loss 0.027249
[epoch5, step635]: loss 0.025918
[epoch5, step636]: loss 0.021137
[epoch5, step637]: loss 0.027504
[epoch5, step638]: loss 0.027165
[epoch5, step639]: loss 0.023066
[epoch5, step640]: loss 0.029658
[epoch5, step641]: loss 0.030617
[epoch5, step642]: loss 0.025196
[epoch5, step643]: loss 0.026027
[epoch5, step644]: loss 0.026234
[epoch5, step645]: loss 0.023922
[epoch5, step646]: loss 0.026809
[epoch5, step647]: loss 0.023941
[epoch5, step648]: loss 0.023444
[epoch5, step649]: loss 0.028868
[epoch5, step650]: loss 0.022587
[epoch5, step651]: loss 0.026480
[epoch5, step652]: loss 0.027033
[epoch5, step653]: loss 0.028308
[epoch5, step654]: loss 0.023485
[epoch5, step655]: loss 0.024203
[epoch5, step656]: loss 0.021769
[epoch5, step657]: loss 0.028050
[epoch5, step658]: loss 0.025405
[epoch5, step659]: loss 0.027773
[epoch5, step660]: loss 0.024056
[epoch5, step661]: loss 0.026867
[epoch5, step662]: loss 0.024014
[epoch5, step663]: loss 0.021487
[epoch5, step664]: loss 0.025119
[epoch5, step665]: loss 0.028322
[epoch5, step666]: loss 0.026955
[epoch5, step667]: loss 0.026777
[epoch5, step668]: loss 0.022838
[epoch5, step669]: loss 0.026379
[epoch5, step670]: loss 0.027350
[epoch5, step671]: loss 0.021418
[epoch5, step672]: loss 0.024476
[epoch5, step673]: loss 0.022428
[epoch5, step674]: loss 0.021526
[epoch5, step675]: loss 0.020346
[epoch5, step676]: loss 0.024709
[epoch5, step677]: loss 0.025548
[epoch5, step678]: loss 0.023442
[epoch5, step679]: loss 0.024272
[epoch5, step680]: loss 0.030926
[epoch5, step681]: loss 0.022217
[epoch5, step682]: loss 0.026291
[epoch5, step683]: loss 0.025927
[epoch5, step684]: loss 0.025160
[epoch5, step685]: loss 0.024365
[epoch5, step686]: loss 0.027645
[epoch5, step687]: loss 0.027121
[epoch5, step688]: loss 0.023206
[epoch5, step689]: loss 0.024598
[epoch5, step690]: loss 0.025623
[epoch5, step691]: loss 0.024551
[epoch5, step692]: loss 0.022829
[epoch5, step693]: loss 0.028094
[epoch5, step694]: loss 0.023095
[epoch5, step695]: loss 0.026851
[epoch5, step696]: loss 0.025880
[epoch5, step697]: loss 0.027649
[epoch5, step698]: loss 0.025115
[epoch5, step699]: loss 0.023500
[epoch5, step700]: loss 0.022049
[epoch5, step701]: loss 0.026149
[epoch5, step702]: loss 0.022024
[epoch5, step703]: loss 0.023467
[epoch5, step704]: loss 0.025949
[epoch5, step705]: loss 0.025001
[epoch5, step706]: loss 0.024035
[epoch5, step707]: loss 0.024411
[epoch5, step708]: loss 0.026343
[epoch5, step709]: loss 0.027656
[epoch5, step710]: loss 0.024202
[epoch5, step711]: loss 0.024195
[epoch5, step712]: loss 0.027141
[epoch5, step713]: loss 0.026568
[epoch5, step714]: loss 0.021824
[epoch5, step715]: loss 0.023194
[epoch5, step716]: loss 0.026263
[epoch5, step717]: loss 0.023800
[epoch5, step718]: loss 0.025200
[epoch5, step719]: loss 0.033600
[epoch5, step720]: loss 0.025118
[epoch5, step721]: loss 0.023406
[epoch5, step722]: loss 0.031226
[epoch5, step723]: loss 0.026669
[epoch5, step724]: loss 0.023302
[epoch5, step725]: loss 0.028564
[epoch5, step726]: loss 0.022365
[epoch5, step727]: loss 0.024789
[epoch5, step728]: loss 0.026694
[epoch5, step729]: loss 0.021570
[epoch5, step730]: loss 0.023052
[epoch5, step731]: loss 0.026289
[epoch5, step732]: loss 0.026003
[epoch5, step733]: loss 0.024109
[epoch5, step734]: loss 0.023158
[epoch5, step735]: loss 0.027412
[epoch5, step736]: loss 0.025175
[epoch5, step737]: loss 0.026519
[epoch5, step738]: loss 0.020825
[epoch5, step739]: loss 0.025630
[epoch5, step740]: loss 0.022777
[epoch5, step741]: loss 0.025351
[epoch5, step742]: loss 0.022069
[epoch5, step743]: loss 0.023284
[epoch5, step744]: loss 0.024137
[epoch5, step745]: loss 0.024832
[epoch5, step746]: loss 0.025633
[epoch5, step747]: loss 0.027877
[epoch5, step748]: loss 0.026199
[epoch5, step749]: loss 0.026918
[epoch5, step750]: loss 0.027917
[epoch5, step751]: loss 0.021716
[epoch5, step752]: loss 0.025504
[epoch5, step753]: loss 0.025960
[epoch5, step754]: loss 0.022956
[epoch5, step755]: loss 0.026302
[epoch5, step756]: loss 0.023584
[epoch5, step757]: loss 0.020704
[epoch5, step758]: loss 0.025195
[epoch5, step759]: loss 0.023369
[epoch5, step760]: loss 0.024237
[epoch5, step761]: loss 0.026492
[epoch5, step762]: loss 0.021695
[epoch5, step763]: loss 0.025709
[epoch5, step764]: loss 0.024086
[epoch5, step765]: loss 0.026042
[epoch5, step766]: loss 0.024916
[epoch5, step767]: loss 0.026571
[epoch5, step768]: loss 0.021620
[epoch5, step769]: loss 0.027124
[epoch5, step770]: loss 0.026029
[epoch5, step771]: loss 0.023484
[epoch5, step772]: loss 0.029005
[epoch5, step773]: loss 0.026570
[epoch5, step774]: loss 0.024190
[epoch5, step775]: loss 0.020769
[epoch5, step776]: loss 0.025951
[epoch5, step777]: loss 0.023147
[epoch5, step778]: loss 0.028393
[epoch5, step779]: loss 0.023863
[epoch5, step780]: loss 0.020266
[epoch5, step781]: loss 0.024597
[epoch5, step782]: loss 0.022988
[epoch5, step783]: loss 0.019541
[epoch5, step784]: loss 0.020531
[epoch5, step785]: loss 0.021371
[epoch5, step786]: loss 0.024604
[epoch5, step787]: loss 0.023744
[epoch5, step788]: loss 0.024937
[epoch5, step789]: loss 0.022619
[epoch5, step790]: loss 0.023253
[epoch5, step791]: loss 0.027001
[epoch5, step792]: loss 0.025220
[epoch5, step793]: loss 0.027221
[epoch5, step794]: loss 0.020606
[epoch5, step795]: loss 0.025930
[epoch5, step796]: loss 0.027867
[epoch5, step797]: loss 0.028002
[epoch5, step798]: loss 0.027227
[epoch5, step799]: loss 0.025633
[epoch5, step800]: loss 0.021675
[epoch5, step801]: loss 0.022004
[epoch5, step802]: loss 0.023084
[epoch5, step803]: loss 0.026307
[epoch5, step804]: loss 0.027531
[epoch5, step805]: loss 0.028607
[epoch5, step806]: loss 0.021487
[epoch5, step807]: loss 0.020679
[epoch5, step808]: loss 0.022995
[epoch5, step809]: loss 0.023060
[epoch5, step810]: loss 0.025958
[epoch5, step811]: loss 0.025986
[epoch5, step812]: loss 0.024780
[epoch5, step813]: loss 0.023801
[epoch5, step814]: loss 0.025204
[epoch5, step815]: loss 0.025154
[epoch5, step816]: loss 0.024412
[epoch5, step817]: loss 0.024762
[epoch5, step818]: loss 0.022614
[epoch5, step819]: loss 0.020327
[epoch5, step820]: loss 0.023530
[epoch5, step821]: loss 0.021911
[epoch5, step822]: loss 0.030922
[epoch5, step823]: loss 0.023974
[epoch5, step824]: loss 0.027110
[epoch5, step825]: loss 0.025486
[epoch5, step826]: loss 0.024482
[epoch5, step827]: loss 0.027155
[epoch5, step828]: loss 0.028914
[epoch5, step829]: loss 0.026605
[epoch5, step830]: loss 0.022741
[epoch5, step831]: loss 0.026352
[epoch5, step832]: loss 0.021009
[epoch5, step833]: loss 0.029577
[epoch5, step834]: loss 0.025709
[epoch5, step835]: loss 0.020517
[epoch5, step836]: loss 0.026994
[epoch5, step837]: loss 0.025728
[epoch5, step838]: loss 0.026279
[epoch5, step839]: loss 0.028471
[epoch5, step840]: loss 0.020895
[epoch5, step841]: loss 0.024381
[epoch5, step842]: loss 0.027796
[epoch5, step843]: loss 0.024975
[epoch5, step844]: loss 0.025173
[epoch5, step845]: loss 0.021234
[epoch5, step846]: loss 0.025503
[epoch5, step847]: loss 0.027180
[epoch5, step848]: loss 0.025219
[epoch5, step849]: loss 0.025197
[epoch5, step850]: loss 0.023108
[epoch5, step851]: loss 0.023886
[epoch5, step852]: loss 0.023215
[epoch5, step853]: loss 0.029239
[epoch5, step854]: loss 0.022850
[epoch5, step855]: loss 0.027303
[epoch5, step856]: loss 0.022274
[epoch5, step857]: loss 0.026044
[epoch5, step858]: loss 0.024437
[epoch5, step859]: loss 0.023725
[epoch5, step860]: loss 0.022775
[epoch5, step861]: loss 0.023405
[epoch5, step862]: loss 0.023033
[epoch5, step863]: loss 0.020714
[epoch5, step864]: loss 0.026877
[epoch5, step865]: loss 0.023447
[epoch5, step866]: loss 0.025253
[epoch5, step867]: loss 0.026096
[epoch5, step868]: loss 0.026840
[epoch5, step869]: loss 0.024148
[epoch5, step870]: loss 0.031235
[epoch5, step871]: loss 0.022316
[epoch5, step872]: loss 0.025567
[epoch5, step873]: loss 0.025784
[epoch5, step874]: loss 0.023870
[epoch5, step875]: loss 0.024325
[epoch5, step876]: loss 0.024340
[epoch5, step877]: loss 0.019225
[epoch5, step878]: loss 0.023511
[epoch5, step879]: loss 0.028182
[epoch5, step880]: loss 0.025712
[epoch5, step881]: loss 0.022294
[epoch5, step882]: loss 0.024427
[epoch5, step883]: loss 0.024013
[epoch5, step884]: loss 0.026583
[epoch5, step885]: loss 0.026119
[epoch5, step886]: loss 0.026403
[epoch5, step887]: loss 0.024277
[epoch5, step888]: loss 0.024758
[epoch5, step889]: loss 0.023740
[epoch5, step890]: loss 0.023531
[epoch5, step891]: loss 0.025630
[epoch5, step892]: loss 0.020978
[epoch5, step893]: loss 0.024720
[epoch5, step894]: loss 0.024932
[epoch5, step895]: loss 0.022676
[epoch5, step896]: loss 0.022213
[epoch5, step897]: loss 0.024137
[epoch5, step898]: loss 0.025627
[epoch5, step899]: loss 0.028269
[epoch5, step900]: loss 0.027131
[epoch5, step901]: loss 0.025584
[epoch5, step902]: loss 0.024248
[epoch5, step903]: loss 0.024233
[epoch5, step904]: loss 0.028215
[epoch5, step905]: loss 0.027678
[epoch5, step906]: loss 0.022506
[epoch5, step907]: loss 0.023673
[epoch5, step908]: loss 0.022650
[epoch5, step909]: loss 0.025529
[epoch5, step910]: loss 0.023134
[epoch5, step911]: loss 0.025294
[epoch5, step912]: loss 0.023963
[epoch5, step913]: loss 0.024223
[epoch5, step914]: loss 0.030965
[epoch5, step915]: loss 0.024138
[epoch5, step916]: loss 0.023978
[epoch5, step917]: loss 0.025290
[epoch5, step918]: loss 0.028619
[epoch5, step919]: loss 0.024177
[epoch5, step920]: loss 0.027756
[epoch5, step921]: loss 0.024568
[epoch5, step922]: loss 0.023299
[epoch5, step923]: loss 0.022737
[epoch5, step924]: loss 0.021192
[epoch5, step925]: loss 0.025784
[epoch5, step926]: loss 0.026807
[epoch5, step927]: loss 0.026185
[epoch5, step928]: loss 0.025010
[epoch5, step929]: loss 0.027577
[epoch5, step930]: loss 0.026093
[epoch5, step931]: loss 0.027621
[epoch5, step932]: loss 0.022098
[epoch5, step933]: loss 0.028315
[epoch5, step934]: loss 0.022349
[epoch5, step935]: loss 0.022181
[epoch5, step936]: loss 0.022494
[epoch5, step937]: loss 0.027627
[epoch5, step938]: loss 0.025441
[epoch5, step939]: loss 0.020866
[epoch5, step940]: loss 0.023051
[epoch5, step941]: loss 0.027080
[epoch5, step942]: loss 0.025604
[epoch5, step943]: loss 0.023419
[epoch5, step944]: loss 0.027882
[epoch5, step945]: loss 0.020717
[epoch5, step946]: loss 0.025525
[epoch5, step947]: loss 0.027870
[epoch5, step948]: loss 0.019622
[epoch5, step949]: loss 0.023168
[epoch5, step950]: loss 0.026706
[epoch5, step951]: loss 0.028718
[epoch5, step952]: loss 0.025211
[epoch5, step953]: loss 0.027614
[epoch5, step954]: loss 0.022140
[epoch5, step955]: loss 0.036669
[epoch5, step956]: loss 0.051630
[epoch5, step957]: loss 0.044762
[epoch5, step958]: loss 0.039740
[epoch5, step959]: loss 0.041599
[epoch5, step960]: loss 0.040424
[epoch5, step961]: loss 0.041707
[epoch5, step962]: loss 0.040963
[epoch5, step963]: loss 0.040448
[epoch5, step964]: loss 0.040459
[epoch5, step965]: loss 0.039723
[epoch5, step966]: loss 0.038499
[epoch5, step967]: loss 0.041119
[epoch5, step968]: loss 0.047437
[epoch5, step969]: loss 0.046283
[epoch5, step970]: loss 0.042372
[epoch5, step971]: loss 0.037719
[epoch5, step972]: loss 0.039753
[epoch5, step973]: loss 0.039512
[epoch5, step974]: loss 0.042196
[epoch5, step975]: loss 0.038705
[epoch5, step976]: loss 0.037148
[epoch5, step977]: loss 0.041059
[epoch5, step978]: loss 0.040717
[epoch5, step979]: loss 0.040193
[epoch5, step980]: loss 0.037452
[epoch5, step981]: loss 0.038758
[epoch5, step982]: loss 0.039254
[epoch5, step983]: loss 0.040868
[epoch5, step984]: loss 0.037026
[epoch5, step985]: loss 0.037095
[epoch5, step986]: loss 0.041469
[epoch5, step987]: loss 0.040119
[epoch5, step988]: loss 0.039486
[epoch5, step989]: loss 0.038110
[epoch5, step990]: loss 0.038854
[epoch5, step991]: loss 0.039638
[epoch5, step992]: loss 0.040130
[epoch5, step993]: loss 0.037497
[epoch5, step994]: loss 0.036390
[epoch5, step995]: loss 0.040671
[epoch5, step996]: loss 0.038630
[epoch5, step997]: loss 0.038787
[epoch5, step998]: loss 0.038318
[epoch5, step999]: loss 0.039040
[epoch5, step1000]: loss 0.039091
[epoch5, step1001]: loss 0.040307
[epoch5, step1002]: loss 0.037790
[epoch5, step1003]: loss 0.036834
[epoch5, step1004]: loss 0.040437
[epoch5, step1005]: loss 0.038075
[epoch5, step1006]: loss 0.038600
[epoch5, step1007]: loss 0.036836
[epoch5, step1008]: loss 0.038120
[epoch5, step1009]: loss 0.038771
[epoch5, step1010]: loss 0.040453
[epoch5, step1011]: loss 0.037322
[epoch5, step1012]: loss 0.037442
[epoch5, step1013]: loss 0.040402
[epoch5, step1014]: loss 0.039530
[epoch5, step1015]: loss 0.038869
[epoch5, step1016]: loss 0.036825
[epoch5, step1017]: loss 0.038294
[epoch5, step1018]: loss 0.038460
[epoch5, step1019]: loss 0.040087
[epoch5, step1020]: loss 0.036845
[epoch5, step1021]: loss 0.036462
[epoch5, step1022]: loss 0.039957
[epoch5, step1023]: loss 0.038558
[epoch5, step1024]: loss 0.039062
[epoch5, step1025]: loss 0.036498
[epoch5, step1026]: loss 0.037760
[epoch5, step1027]: loss 0.038296
[epoch5, step1028]: loss 0.039757
[epoch5, step1029]: loss 0.036828
[epoch5, step1030]: loss 0.036243
[epoch5, step1031]: loss 0.039293
[epoch5, step1032]: loss 0.038813
[epoch5, step1033]: loss 0.037840
[epoch5, step1034]: loss 0.036588
[epoch5, step1035]: loss 0.037621
[epoch5, step1036]: loss 0.038808
[epoch5, step1037]: loss 0.039469
[epoch5, step1038]: loss 0.036898
[epoch5, step1039]: loss 0.037118
[epoch5, step1040]: loss 0.039447
[epoch5, step1041]: loss 0.038429
[epoch5, step1042]: loss 0.037492
[epoch5, step1043]: loss 0.036681
[epoch5, step1044]: loss 0.038527
[epoch5, step1045]: loss 0.038607
[epoch5, step1046]: loss 0.039855
[epoch5, step1047]: loss 0.037038
[epoch5, step1048]: loss 0.036354
[epoch5, step1049]: loss 0.039979
[epoch5, step1050]: loss 0.038829
[epoch5, step1051]: loss 0.038205
[epoch5, step1052]: loss 0.037186
[epoch5, step1053]: loss 0.038628
[epoch5, step1054]: loss 0.038750
[epoch5, step1055]: loss 0.039247
[epoch5, step1056]: loss 0.036256
[epoch5, step1057]: loss 0.037476
[epoch5, step1058]: loss 0.040757
[epoch5, step1059]: loss 0.038727
[epoch5, step1060]: loss 0.038415
[epoch5, step1061]: loss 0.036123
[epoch5, step1062]: loss 0.038779
[epoch5, step1063]: loss 0.038421
[epoch5, step1064]: loss 0.039688
[epoch5, step1065]: loss 0.036747
[epoch5, step1066]: loss 0.036218
[epoch5, step1067]: loss 0.039928
[epoch5, step1068]: loss 0.037142
[epoch5, step1069]: loss 0.037460
[epoch5, step1070]: loss 0.036684
[epoch5, step1071]: loss 0.038825
[epoch5, step1072]: loss 0.039283
[epoch5, step1073]: loss 0.039311
[epoch5, step1074]: loss 0.036973
[epoch5, step1075]: loss 0.037160
[epoch5, step1076]: loss 0.039936
[epoch5, step1077]: loss 0.038504
[epoch5, step1078]: loss 0.038029
[epoch5, step1079]: loss 0.037684
[epoch5, step1080]: loss 0.038539
[epoch5, step1081]: loss 0.038172
[epoch5, step1082]: loss 0.039450
[epoch5, step1083]: loss 0.037502
[epoch5, step1084]: loss 0.036871
[epoch5, step1085]: loss 0.039319
[epoch5, step1086]: loss 0.038005
[epoch5, step1087]: loss 0.038193
[epoch5, step1088]: loss 0.036436
[epoch5, step1089]: loss 0.038730
[epoch5, step1090]: loss 0.039026
[epoch5, step1091]: loss 0.039847
[epoch5, step1092]: loss 0.036626
[epoch5, step1093]: loss 0.036593
[epoch5, step1094]: loss 0.038884
[epoch5, step1095]: loss 0.038022
[epoch5, step1096]: loss 0.037629
[epoch5, step1097]: loss 0.036742
[epoch5, step1098]: loss 0.038229
[epoch5, step1099]: loss 0.038020
[epoch5, step1100]: loss 0.040205
[epoch5, step1101]: loss 0.037092
[epoch5, step1102]: loss 0.036619
[epoch5, step1103]: loss 0.039303
[epoch5, step1104]: loss 0.038165
[epoch5, step1105]: loss 0.038262
[epoch5, step1106]: loss 0.035759
[epoch5, step1107]: loss 0.038442
[epoch5, step1108]: loss 0.038021
[epoch5, step1109]: loss 0.039863
[epoch5, step1110]: loss 0.037424
[epoch5, step1111]: loss 0.036924
[epoch5, step1112]: loss 0.040135
[epoch5, step1113]: loss 0.037982
[epoch5, step1114]: loss 0.038399
[epoch5, step1115]: loss 0.036824
[epoch5, step1116]: loss 0.038475
[epoch5, step1117]: loss 0.038431
[epoch5, step1118]: loss 0.039504
[epoch5, step1119]: loss 0.036582
[epoch5, step1120]: loss 0.036569
[epoch5, step1121]: loss 0.039705
[epoch5, step1122]: loss 0.037716
[epoch5, step1123]: loss 0.037307
[epoch5, step1124]: loss 0.037346
[epoch5, step1125]: loss 0.038655
[epoch5, step1126]: loss 0.039348
[epoch5, step1127]: loss 0.039579
[epoch5, step1128]: loss 0.036984
[epoch5, step1129]: loss 0.036615
[epoch5, step1130]: loss 0.040384
[epoch5, step1131]: loss 0.038704
[epoch5, step1132]: loss 0.038395
[epoch5, step1133]: loss 0.036304
[epoch5, step1134]: loss 0.038155
[epoch5, step1135]: loss 0.039359
[epoch5, step1136]: loss 0.040203
[epoch5, step1137]: loss 0.036841
[epoch5, step1138]: loss 0.036918
[epoch5, step1139]: loss 0.039729
[epoch5, step1140]: loss 0.037629
[epoch5, step1141]: loss 0.037706
[epoch5, step1142]: loss 0.036439
[epoch5, step1143]: loss 0.037832
[epoch5, step1144]: loss 0.038518
[epoch5, step1145]: loss 0.039022
[epoch5, step1146]: loss 0.036435
[epoch5, step1147]: loss 0.037505
[epoch5, step1148]: loss 0.039850
[epoch5, step1149]: loss 0.037944
[epoch5, step1150]: loss 0.037793
[epoch5, step1151]: loss 0.037000
[epoch5, step1152]: loss 0.038873
[epoch5, step1153]: loss 0.037803
[epoch5, step1154]: loss 0.039904
[epoch5, step1155]: loss 0.036868
[epoch5, step1156]: loss 0.036050
[epoch5, step1157]: loss 0.039489
[epoch5, step1158]: loss 0.038420
[epoch5, step1159]: loss 0.038169
[epoch5, step1160]: loss 0.037493
[epoch5, step1161]: loss 0.038844
[epoch5, step1162]: loss 0.038301
[epoch5, step1163]: loss 0.038852
[epoch5, step1164]: loss 0.036632
[epoch5, step1165]: loss 0.037774
[epoch5, step1166]: loss 0.039851
[epoch5, step1167]: loss 0.037372
[epoch5, step1168]: loss 0.038148
[epoch5, step1169]: loss 0.036405
[epoch5, step1170]: loss 0.038348
[epoch5, step1171]: loss 0.038252
[epoch5, step1172]: loss 0.039482
[epoch5, step1173]: loss 0.036852
[epoch5, step1174]: loss 0.037114
[epoch5, step1175]: loss 0.039574
[epoch5, step1176]: loss 0.037869
[epoch5, step1177]: loss 0.038198
[epoch5, step1178]: loss 0.036743
[epoch5, step1179]: loss 0.038111
[epoch5, step1180]: loss 0.038506
[epoch5, step1181]: loss 0.040030
[epoch5, step1182]: loss 0.036051
[epoch5, step1183]: loss 0.037173
[epoch5, step1184]: loss 0.039176
[epoch5, step1185]: loss 0.038283
[epoch5, step1186]: loss 0.037134
[epoch5, step1187]: loss 0.035772
[epoch5, step1188]: loss 0.037657
[epoch5, step1189]: loss 0.038011
[epoch5, step1190]: loss 0.039031
[epoch5, step1191]: loss 0.037307
[epoch5, step1192]: loss 0.036726
[epoch5, step1193]: loss 0.039596
[epoch5, step1194]: loss 0.037947
[epoch5, step1195]: loss 0.036753
[epoch5, step1196]: loss 0.035876
[epoch5, step1197]: loss 0.038556
[epoch5, step1198]: loss 0.038348
[epoch5, step1199]: loss 0.039091
[epoch5, step1200]: loss 0.036389
[epoch5, step1201]: loss 0.037198
[epoch5, step1202]: loss 0.040523
[epoch5, step1203]: loss 0.038230
[epoch5, step1204]: loss 0.037249
[epoch5, step1205]: loss 0.036111
[epoch5, step1206]: loss 0.037717
[epoch5, step1207]: loss 0.038600
[epoch5, step1208]: loss 0.039626
[epoch5, step1209]: loss 0.035549
[epoch5, step1210]: loss 0.037217
[epoch5, step1211]: loss 0.039185
[epoch5, step1212]: loss 0.037871
[epoch5, step1213]: loss 0.037427
[epoch5, step1214]: loss 0.036716
[epoch5, step1215]: loss 0.038901
[epoch5, step1216]: loss 0.037847
[epoch5, step1217]: loss 0.040033
[epoch5, step1218]: loss 0.036284
[epoch5, step1219]: loss 0.037376
[epoch5, step1220]: loss 0.039991
[epoch5, step1221]: loss 0.037209
[epoch5, step1222]: loss 0.038032
[epoch5, step1223]: loss 0.036485
[epoch5, step1224]: loss 0.038696
[epoch5, step1225]: loss 0.038337
[epoch5, step1226]: loss 0.039058
[epoch5, step1227]: loss 0.036527
[epoch5, step1228]: loss 0.036356
[epoch5, step1229]: loss 0.039320
[epoch5, step1230]: loss 0.038309
[epoch5, step1231]: loss 0.037726
[epoch5, step1232]: loss 0.037621
[epoch5, step1233]: loss 0.038111
[epoch5, step1234]: loss 0.038042
[epoch5, step1235]: loss 0.039878
[epoch5, step1236]: loss 0.036861
[epoch5, step1237]: loss 0.036302
[epoch5, step1238]: loss 0.039032
[epoch5, step1239]: loss 0.038666
[epoch5, step1240]: loss 0.038166
[epoch5, step1241]: loss 0.036177
[epoch5, step1242]: loss 0.038238
[epoch5, step1243]: loss 0.038113
[epoch5, step1244]: loss 0.039668
[epoch5, step1245]: loss 0.036970
[epoch5, step1246]: loss 0.037001
[epoch5, step1247]: loss 0.038739
[epoch5, step1248]: loss 0.038131
[epoch5, step1249]: loss 0.038358
[epoch5, step1250]: loss 0.036467
[epoch5, step1251]: loss 0.038501
[epoch5, step1252]: loss 0.039173
[epoch5, step1253]: loss 0.039689
[epoch5, step1254]: loss 0.036681
[epoch5, step1255]: loss 0.036796
[epoch5, step1256]: loss 0.040031
[epoch5, step1257]: loss 0.038335
[epoch5, step1258]: loss 0.038086
[epoch5, step1259]: loss 0.036333
[epoch5, step1260]: loss 0.038371
[epoch5, step1261]: loss 0.038127
[epoch5, step1262]: loss 0.038257
[epoch5, step1263]: loss 0.037163
[epoch5, step1264]: loss 0.036604
[epoch5, step1265]: loss 0.038417
[epoch5, step1266]: loss 0.038062
[epoch5, step1267]: loss 0.038048
[epoch5, step1268]: loss 0.036755
[epoch5, step1269]: loss 0.038410
[epoch5, step1270]: loss 0.037571
[epoch5, step1271]: loss 0.039858
[epoch5, step1272]: loss 0.036744
[epoch5, step1273]: loss 0.036472
[epoch5, step1274]: loss 0.039441
[epoch5, step1275]: loss 0.038396
[epoch5, step1276]: loss 0.037598
[epoch5, step1277]: loss 0.036521
[epoch5, step1278]: loss 0.038905
[epoch5, step1279]: loss 0.038496
[epoch5, step1280]: loss 0.039593
[epoch5, step1281]: loss 0.036494
[epoch5, step1282]: loss 0.036646
[epoch5, step1283]: loss 0.038955
[epoch5, step1284]: loss 0.037545
[epoch5, step1285]: loss 0.038278
[epoch5, step1286]: loss 0.035953
[epoch5, step1287]: loss 0.038995
[epoch5, step1288]: loss 0.039009
[epoch5, step1289]: loss 0.040267
[epoch5, step1290]: loss 0.036651
[epoch5, step1291]: loss 0.036415
[epoch5, step1292]: loss 0.040145
[epoch5, step1293]: loss 0.037261
[epoch5, step1294]: loss 0.037859
[epoch5, step1295]: loss 0.037025
[epoch5, step1296]: loss 0.038513
[epoch5, step1297]: loss 0.038102
[epoch5, step1298]: loss 0.039976
[epoch5, step1299]: loss 0.036810
[epoch5, step1300]: loss 0.037387
[epoch5, step1301]: loss 0.038625
[epoch5, step1302]: loss 0.038003
[epoch5, step1303]: loss 0.038036
[epoch5, step1304]: loss 0.035968
[epoch5, step1305]: loss 0.038637
[epoch5, step1306]: loss 0.038165
[epoch5, step1307]: loss 0.038830
[epoch5, step1308]: loss 0.036726
[epoch5, step1309]: loss 0.036042
[epoch5, step1310]: loss 0.039446
[epoch5, step1311]: loss 0.036982
[epoch5, step1312]: loss 0.038534
[epoch5, step1313]: loss 0.036670
[epoch5, step1314]: loss 0.038210
[epoch5, step1315]: loss 0.037957
[epoch5, step1316]: loss 0.040779
[epoch5, step1317]: loss 0.036091
[epoch5, step1318]: loss 0.036172
[epoch5, step1319]: loss 0.038978
[epoch5, step1320]: loss 0.038222
[epoch5, step1321]: loss 0.038296
[epoch5, step1322]: loss 0.036227
[epoch5, step1323]: loss 0.038660
[epoch5, step1324]: loss 0.037873
[epoch5, step1325]: loss 0.039284
[epoch5, step1326]: loss 0.036392
[epoch5, step1327]: loss 0.036538
[epoch5, step1328]: loss 0.039562
[epoch5, step1329]: loss 0.037878
[epoch5, step1330]: loss 0.038065
[epoch5, step1331]: loss 0.036277
[epoch5, step1332]: loss 0.038211
[epoch5, step1333]: loss 0.037328
[epoch5, step1334]: loss 0.039757
[epoch5, step1335]: loss 0.037238
[epoch5, step1336]: loss 0.036601
[epoch5, step1337]: loss 0.038944
[epoch5, step1338]: loss 0.037852
[epoch5, step1339]: loss 0.037923
[epoch5, step1340]: loss 0.036183
[epoch5, step1341]: loss 0.038553
[epoch5, step1342]: loss 0.037988
[epoch5, step1343]: loss 0.039564
[epoch5, step1344]: loss 0.036721
[epoch5, step1345]: loss 0.036630
[epoch5, step1346]: loss 0.039053
[epoch5, step1347]: loss 0.038612
[epoch5, step1348]: loss 0.037188
[epoch5, step1349]: loss 0.036616
[epoch5, step1350]: loss 0.038338
[epoch5, step1351]: loss 0.037729
[epoch5, step1352]: loss 0.038837
[epoch5, step1353]: loss 0.036259
[epoch5, step1354]: loss 0.036368
[epoch5, step1355]: loss 0.039607
[epoch5, step1356]: loss 0.037666
[epoch5, step1357]: loss 0.037299
[epoch5, step1358]: loss 0.036305
[epoch5, step1359]: loss 0.037870
[epoch5, step1360]: loss 0.038388
[epoch5, step1361]: loss 0.039647
[epoch5, step1362]: loss 0.037176
[epoch5, step1363]: loss 0.037147
[epoch5, step1364]: loss 0.039356
[epoch5, step1365]: loss 0.037969
[epoch5, step1366]: loss 0.037670
[epoch5, step1367]: loss 0.035659
[epoch5, step1368]: loss 0.039179
[epoch5, step1369]: loss 0.038406
[epoch5, step1370]: loss 0.039068
[epoch5, step1371]: loss 0.036794
[epoch5, step1372]: loss 0.036470
[epoch5, step1373]: loss 0.039478
[epoch5, step1374]: loss 0.038771
[epoch5, step1375]: loss 0.038519
[epoch5, step1376]: loss 0.036274
[epoch5, step1377]: loss 0.037539
[epoch5, step1378]: loss 0.038286
[epoch5, step1379]: loss 0.038946
[epoch5, step1380]: loss 0.036919
[epoch5, step1381]: loss 0.036609
[epoch5, step1382]: loss 0.039741
[epoch5, step1383]: loss 0.037778
[epoch5, step1384]: loss 0.037665
[epoch5, step1385]: loss 0.035769
[epoch5, step1386]: loss 0.038486
[epoch5, step1387]: loss 0.038645
[epoch5, step1388]: loss 0.038292
[epoch5, step1389]: loss 0.035849
[epoch5, step1390]: loss 0.036756
[epoch5, step1391]: loss 0.039134
[epoch5, step1392]: loss 0.037847
[epoch5, step1393]: loss 0.037964
[epoch5, step1394]: loss 0.037074
[epoch5, step1395]: loss 0.038400
[epoch5, step1396]: loss 0.037773
[epoch5, step1397]: loss 0.039093
[epoch5, step1398]: loss 0.036401
[epoch5, step1399]: loss 0.037508
[epoch5, step1400]: loss 0.039906
[epoch5, step1401]: loss 0.037667
[epoch5, step1402]: loss 0.037921
[epoch5, step1403]: loss 0.035408
[epoch5, step1404]: loss 0.037764
[epoch5, step1405]: loss 0.037967
[epoch5, step1406]: loss 0.039016
[epoch5, step1407]: loss 0.037553
[epoch5, step1408]: loss 0.035999
[epoch5, step1409]: loss 0.038983
[epoch5, step1410]: loss 0.037879
[epoch5, step1411]: loss 0.036719
[epoch5, step1412]: loss 0.036511
[epoch5, step1413]: loss 0.038305
[epoch5, step1414]: loss 0.037753
[epoch5, step1415]: loss 0.038982
[epoch5, step1416]: loss 0.036363
[epoch5, step1417]: loss 0.036541
[epoch5, step1418]: loss 0.039349
[epoch5, step1419]: loss 0.038623
[epoch5, step1420]: loss 0.037999
[epoch5, step1421]: loss 0.036827
[epoch5, step1422]: loss 0.038468
[epoch5, step1423]: loss 0.037657
[epoch5, step1424]: loss 0.039439
[epoch5, step1425]: loss 0.035530
[epoch5, step1426]: loss 0.036641
[epoch5, step1427]: loss 0.040176
[epoch5, step1428]: loss 0.038691
[epoch5, step1429]: loss 0.037706
[epoch5, step1430]: loss 0.036406
[epoch5, step1431]: loss 0.038354
[epoch5, step1432]: loss 0.037857
[epoch5, step1433]: loss 0.039424
[epoch5, step1434]: loss 0.035933
[epoch5, step1435]: loss 0.037062
[epoch5, step1436]: loss 0.039705
[epoch5, step1437]: loss 0.038170
[epoch5, step1438]: loss 0.038432
[epoch5, step1439]: loss 0.036256
[epoch5, step1440]: loss 0.038073
[epoch5, step1441]: loss 0.038743
[epoch5, step1442]: loss 0.038519
[epoch5, step1443]: loss 0.036168
[epoch5, step1444]: loss 0.035873
[epoch5, step1445]: loss 0.039716
[epoch5, step1446]: loss 0.038059
[epoch5, step1447]: loss 0.038480
[epoch5, step1448]: loss 0.036310
[epoch5, step1449]: loss 0.037648
[epoch5, step1450]: loss 0.038155
[epoch5, step1451]: loss 0.039571
[epoch5, step1452]: loss 0.036145
[epoch5, step1453]: loss 0.037590
[epoch5, step1454]: loss 0.039805
[epoch5, step1455]: loss 0.038474
[epoch5, step1456]: loss 0.037348
[epoch5, step1457]: loss 0.036956
[epoch5, step1458]: loss 0.038328
[epoch5, step1459]: loss 0.038070
[epoch5, step1460]: loss 0.039757
[epoch5, step1461]: loss 0.037112
[epoch5, step1462]: loss 0.037233
[epoch5, step1463]: loss 0.039330
[epoch5, step1464]: loss 0.038163
[epoch5, step1465]: loss 0.037385
[epoch5, step1466]: loss 0.036042
[epoch5, step1467]: loss 0.038159
[epoch5, step1468]: loss 0.037576
[epoch5, step1469]: loss 0.039187
[epoch5, step1470]: loss 0.036577
[epoch5, step1471]: loss 0.036289
[epoch5, step1472]: loss 0.039204
[epoch5, step1473]: loss 0.037842
[epoch5, step1474]: loss 0.038336
[epoch5, step1475]: loss 0.036069
[epoch5, step1476]: loss 0.039030
[epoch5, step1477]: loss 0.037784
[epoch5, step1478]: loss 0.039312
[epoch5, step1479]: loss 0.036351
[epoch5, step1480]: loss 0.036571
[epoch5, step1481]: loss 0.038422
[epoch5, step1482]: loss 0.037832
[epoch5, step1483]: loss 0.037780
[epoch5, step1484]: loss 0.036742
[epoch5, step1485]: loss 0.037916
[epoch5, step1486]: loss 0.037035
[epoch5, step1487]: loss 0.039083
[epoch5, step1488]: loss 0.036435
[epoch5, step1489]: loss 0.036422
[epoch5, step1490]: loss 0.039361
[epoch5, step1491]: loss 0.037940
[epoch5, step1492]: loss 0.037493
[epoch5, step1493]: loss 0.036401
[epoch5, step1494]: loss 0.038328
[epoch5, step1495]: loss 0.037739
[epoch5, step1496]: loss 0.038352
[epoch5, step1497]: loss 0.036701
[epoch5, step1498]: loss 0.036862
[epoch5, step1499]: loss 0.038697
[epoch5, step1500]: loss 0.038143
[epoch5, step1501]: loss 0.037731
[epoch5, step1502]: loss 0.036108
[epoch5, step1503]: loss 0.038021
[epoch5, step1504]: loss 0.037552
[epoch5, step1505]: loss 0.039475
[epoch5, step1506]: loss 0.035821
[epoch5, step1507]: loss 0.036903
[epoch5, step1508]: loss 0.039864
[epoch5, step1509]: loss 0.037550
[epoch5, step1510]: loss 0.037091
[epoch5, step1511]: loss 0.036969
[epoch5, step1512]: loss 0.038303
[epoch5, step1513]: loss 0.036679
[epoch5, step1514]: loss 0.039170
[epoch5, step1515]: loss 0.036891
[epoch5, step1516]: loss 0.036519

[epoch5]: avg loss 0.034648

[epoch6, step1]: loss 0.031802
[epoch6, step2]: loss 0.038990
[epoch6, step3]: loss 0.038936
[epoch6, step4]: loss 0.036171
[epoch6, step5]: loss 0.036890
[epoch6, step6]: loss 0.039268
[epoch6, step7]: loss 0.037302
[epoch6, step8]: loss 0.039536
[epoch6, step9]: loss 0.035866
[epoch6, step10]: loss 0.037699
[epoch6, step11]: loss 0.039267
[epoch6, step12]: loss 0.039104
[epoch6, step13]: loss 0.036460
[epoch6, step14]: loss 0.036859
[epoch6, step15]: loss 0.039219
[epoch6, step16]: loss 0.037079
[epoch6, step17]: loss 0.039648
[epoch6, step18]: loss 0.037124
[epoch6, step19]: loss 0.037178
[epoch6, step20]: loss 0.040134
[epoch6, step21]: loss 0.039091
[epoch6, step22]: loss 0.035967
[epoch6, step23]: loss 0.035915
[epoch6, step24]: loss 0.039349
[epoch6, step25]: loss 0.036473
[epoch6, step26]: loss 0.038899
[epoch6, step27]: loss 0.035746
[epoch6, step28]: loss 0.037319
[epoch6, step29]: loss 0.039389
[epoch6, step30]: loss 0.039791
[epoch6, step31]: loss 0.035798
[epoch6, step32]: loss 0.037140
[epoch6, step33]: loss 0.039846
[epoch6, step34]: loss 0.037635
[epoch6, step35]: loss 0.039766
[epoch6, step36]: loss 0.036163
[epoch6, step37]: loss 0.037193
[epoch6, step38]: loss 0.039258
[epoch6, step39]: loss 0.039240
[epoch6, step40]: loss 0.036561
[epoch6, step41]: loss 0.036160
[epoch6, step42]: loss 0.039620
[epoch6, step43]: loss 0.036922
[epoch6, step44]: loss 0.039942
[epoch6, step45]: loss 0.036304
[epoch6, step46]: loss 0.037219
[epoch6, step47]: loss 0.038775
[epoch6, step48]: loss 0.038836
[epoch6, step49]: loss 0.034723
[epoch6, step50]: loss 0.036770
[epoch6, step51]: loss 0.039049
[epoch6, step52]: loss 0.036787
[epoch6, step53]: loss 0.039915
[epoch6, step54]: loss 0.036120
[epoch6, step55]: loss 0.037619
[epoch6, step56]: loss 0.040200
[epoch6, step57]: loss 0.039670
[epoch6, step58]: loss 0.036245
[epoch6, step59]: loss 0.035698
[epoch6, step60]: loss 0.039807
[epoch6, step61]: loss 0.036173
[epoch6, step62]: loss 0.038864
[epoch6, step63]: loss 0.035646
[epoch6, step64]: loss 0.036686
[epoch6, step65]: loss 0.039442
[epoch6, step66]: loss 0.039165
[epoch6, step67]: loss 0.036427
[epoch6, step68]: loss 0.036613
[epoch6, step69]: loss 0.039142
[epoch6, step70]: loss 0.036757
[epoch6, step71]: loss 0.038990
[epoch6, step72]: loss 0.036308
[epoch6, step73]: loss 0.037113
[epoch6, step74]: loss 0.039182
[epoch6, step75]: loss 0.039535
[epoch6, step76]: loss 0.036832
[epoch6, step77]: loss 0.037281
[epoch6, step78]: loss 0.039500
[epoch6, step79]: loss 0.036264
[epoch6, step80]: loss 0.040235
[epoch6, step81]: loss 0.036275
[epoch6, step82]: loss 0.036617
[epoch6, step83]: loss 0.038681
[epoch6, step84]: loss 0.039322
[epoch6, step85]: loss 0.036978
[epoch6, step86]: loss 0.036948
[epoch6, step87]: loss 0.040240
[epoch6, step88]: loss 0.035776
[epoch6, step89]: loss 0.039077
[epoch6, step90]: loss 0.036772
[epoch6, step91]: loss 0.036519
[epoch6, step92]: loss 0.039474
[epoch6, step93]: loss 0.039273
[epoch6, step94]: loss 0.036035
[epoch6, step95]: loss 0.037133
[epoch6, step96]: loss 0.038925
[epoch6, step97]: loss 0.037594
[epoch6, step98]: loss 0.039533
[epoch6, step99]: loss 0.036319
[epoch6, step100]: loss 0.035998
[epoch6, step101]: loss 0.039883
[epoch6, step102]: loss 0.039087
[epoch6, step103]: loss 0.036197
[epoch6, step104]: loss 0.036626
[epoch6, step105]: loss 0.039532
[epoch6, step106]: loss 0.036883
[epoch6, step107]: loss 0.039387
[epoch6, step108]: loss 0.036709
[epoch6, step109]: loss 0.036679
[epoch6, step110]: loss 0.039928
[epoch6, step111]: loss 0.039001
[epoch6, step112]: loss 0.036422
[epoch6, step113]: loss 0.037534
[epoch6, step114]: loss 0.039040
[epoch6, step115]: loss 0.036842
[epoch6, step116]: loss 0.040355
[epoch6, step117]: loss 0.036140
[epoch6, step118]: loss 0.037766
[epoch6, step119]: loss 0.039768
[epoch6, step120]: loss 0.039438
[epoch6, step121]: loss 0.036182
[epoch6, step122]: loss 0.036499
[epoch6, step123]: loss 0.039617
[epoch6, step124]: loss 0.037155
[epoch6, step125]: loss 0.039762
[epoch6, step126]: loss 0.036309
[epoch6, step127]: loss 0.036733
[epoch6, step128]: loss 0.039223
[epoch6, step129]: loss 0.039052
[epoch6, step130]: loss 0.036486
[epoch6, step131]: loss 0.036128
[epoch6, step132]: loss 0.039387
[epoch6, step133]: loss 0.036739
[epoch6, step134]: loss 0.038892
[epoch6, step135]: loss 0.036844
[epoch6, step136]: loss 0.038082
[epoch6, step137]: loss 0.039111
[epoch6, step138]: loss 0.039119
[epoch6, step139]: loss 0.036252
[epoch6, step140]: loss 0.037092
[epoch6, step141]: loss 0.039609
[epoch6, step142]: loss 0.036754
[epoch6, step143]: loss 0.038872
[epoch6, step144]: loss 0.036646
[epoch6, step145]: loss 0.036922
[epoch6, step146]: loss 0.039377
[epoch6, step147]: loss 0.040563
[epoch6, step148]: loss 0.035956
[epoch6, step149]: loss 0.036291
[epoch6, step150]: loss 0.039069
[epoch6, step151]: loss 0.036939
[epoch6, step152]: loss 0.039351
[epoch6, step153]: loss 0.036392
[epoch6, step154]: loss 0.036644
[epoch6, step155]: loss 0.039185
[epoch6, step156]: loss 0.038751
[epoch6, step157]: loss 0.036449
[epoch6, step158]: loss 0.036855
[epoch6, step159]: loss 0.039505
[epoch6, step160]: loss 0.037053
[epoch6, step161]: loss 0.039822
[epoch6, step162]: loss 0.036610
[epoch6, step163]: loss 0.036869
[epoch6, step164]: loss 0.039542
[epoch6, step165]: loss 0.039216
[epoch6, step166]: loss 0.036620
[epoch6, step167]: loss 0.036257
[epoch6, step168]: loss 0.040041
[epoch6, step169]: loss 0.036575
[epoch6, step170]: loss 0.039747
[epoch6, step171]: loss 0.036700
[epoch6, step172]: loss 0.037113
[epoch6, step173]: loss 0.039617
[epoch6, step174]: loss 0.039024
[epoch6, step175]: loss 0.037015
[epoch6, step176]: loss 0.036915
[epoch6, step177]: loss 0.039716
[epoch6, step178]: loss 0.036799
[epoch6, step179]: loss 0.038562
[epoch6, step180]: loss 0.036666
[epoch6, step181]: loss 0.037126
[epoch6, step182]: loss 0.039695
[epoch6, step183]: loss 0.039918
[epoch6, step184]: loss 0.037312
[epoch6, step185]: loss 0.037004
[epoch6, step186]: loss 0.039500
[epoch6, step187]: loss 0.037043
[epoch6, step188]: loss 0.039233
[epoch6, step189]: loss 0.036401
[epoch6, step190]: loss 0.036356
[epoch6, step191]: loss 0.039176
[epoch6, step192]: loss 0.039820
[epoch6, step193]: loss 0.034535
[epoch6, step194]: loss 0.035845
[epoch6, step195]: loss 0.039695
[epoch6, step196]: loss 0.036931
[epoch6, step197]: loss 0.039176
[epoch6, step198]: loss 0.035588
[epoch6, step199]: loss 0.037029
[epoch6, step200]: loss 0.039847
[epoch6, step201]: loss 0.039793
[epoch6, step202]: loss 0.035967
[epoch6, step203]: loss 0.036771
[epoch6, step204]: loss 0.039910
[epoch6, step205]: loss 0.036304
[epoch6, step206]: loss 0.039135
[epoch6, step207]: loss 0.036235
[epoch6, step208]: loss 0.037422
[epoch6, step209]: loss 0.039712
[epoch6, step210]: loss 0.040204
[epoch6, step211]: loss 0.036966
[epoch6, step212]: loss 0.037088
[epoch6, step213]: loss 0.039028
[epoch6, step214]: loss 0.036190
[epoch6, step215]: loss 0.039614
[epoch6, step216]: loss 0.036718
[epoch6, step217]: loss 0.036119
[epoch6, step218]: loss 0.039629
[epoch6, step219]: loss 0.039075
[epoch6, step220]: loss 0.036655
[epoch6, step221]: loss 0.037029
[epoch6, step222]: loss 0.039713
[epoch6, step223]: loss 0.037025
[epoch6, step224]: loss 0.039008
[epoch6, step225]: loss 0.036332
[epoch6, step226]: loss 0.036712
[epoch6, step227]: loss 0.038412
[epoch6, step228]: loss 0.039956
[epoch6, step229]: loss 0.035508
[epoch6, step230]: loss 0.037061
[epoch6, step231]: loss 0.039891
[epoch6, step232]: loss 0.036525
[epoch6, step233]: loss 0.038639
[epoch6, step234]: loss 0.036035
[epoch6, step235]: loss 0.037281
[epoch6, step236]: loss 0.039425
[epoch6, step237]: loss 0.039379
[epoch6, step238]: loss 0.036143
[epoch6, step239]: loss 0.036068
[epoch6, step240]: loss 0.038935
[epoch6, step241]: loss 0.037246
[epoch6, step242]: loss 0.039328
[epoch6, step243]: loss 0.037143
[epoch6, step244]: loss 0.036843
[epoch6, step245]: loss 0.038917
[epoch6, step246]: loss 0.039287
[epoch6, step247]: loss 0.036679
[epoch6, step248]: loss 0.036311
[epoch6, step249]: loss 0.038836
[epoch6, step250]: loss 0.037125
[epoch6, step251]: loss 0.039891
[epoch6, step252]: loss 0.037011
[epoch6, step253]: loss 0.036459
[epoch6, step254]: loss 0.038832
[epoch6, step255]: loss 0.039471
[epoch6, step256]: loss 0.036102
[epoch6, step257]: loss 0.036458
[epoch6, step258]: loss 0.039967
[epoch6, step259]: loss 0.036904
[epoch6, step260]: loss 0.038946
[epoch6, step261]: loss 0.037128
[epoch6, step262]: loss 0.037345
[epoch6, step263]: loss 0.038714
[epoch6, step264]: loss 0.039049
[epoch6, step265]: loss 0.036601
[epoch6, step266]: loss 0.036576
[epoch6, step267]: loss 0.038691
[epoch6, step268]: loss 0.036669
[epoch6, step269]: loss 0.039310
[epoch6, step270]: loss 0.035960
[epoch6, step271]: loss 0.036971
[epoch6, step272]: loss 0.039234
[epoch6, step273]: loss 0.039028
[epoch6, step274]: loss 0.036747
[epoch6, step275]: loss 0.036246
[epoch6, step276]: loss 0.039062
[epoch6, step277]: loss 0.037359
[epoch6, step278]: loss 0.039577
[epoch6, step279]: loss 0.036015
[epoch6, step280]: loss 0.036975
[epoch6, step281]: loss 0.039159
[epoch6, step282]: loss 0.039780
[epoch6, step283]: loss 0.035996
[epoch6, step284]: loss 0.036117
[epoch6, step285]: loss 0.040143
[epoch6, step286]: loss 0.036040
[epoch6, step287]: loss 0.039535
[epoch6, step288]: loss 0.036010
[epoch6, step289]: loss 0.037667
[epoch6, step290]: loss 0.039333
[epoch6, step291]: loss 0.039629
[epoch6, step292]: loss 0.035544
[epoch6, step293]: loss 0.036380
[epoch6, step294]: loss 0.038809
[epoch6, step295]: loss 0.036323
[epoch6, step296]: loss 0.040214
[epoch6, step297]: loss 0.036054
[epoch6, step298]: loss 0.037294
[epoch6, step299]: loss 0.038390
[epoch6, step300]: loss 0.039533
[epoch6, step301]: loss 0.036357
[epoch6, step302]: loss 0.036955
[epoch6, step303]: loss 0.039730
[epoch6, step304]: loss 0.036472
[epoch6, step305]: loss 0.039019
[epoch6, step306]: loss 0.036494
[epoch6, step307]: loss 0.036592
[epoch6, step308]: loss 0.039771
[epoch6, step309]: loss 0.039630
[epoch6, step310]: loss 0.036454
[epoch6, step311]: loss 0.037074
[epoch6, step312]: loss 0.038970
[epoch6, step313]: loss 0.037138
[epoch6, step314]: loss 0.039286
[epoch6, step315]: loss 0.037366
[epoch6, step316]: loss 0.036706
[epoch6, step317]: loss 0.039652
[epoch6, step318]: loss 0.039291
[epoch6, step319]: loss 0.035808
[epoch6, step320]: loss 0.035630
[epoch6, step321]: loss 0.038905
[epoch6, step322]: loss 0.036611
[epoch6, step323]: loss 0.038612
[epoch6, step324]: loss 0.037210
[epoch6, step325]: loss 0.037039
[epoch6, step326]: loss 0.039004
[epoch6, step327]: loss 0.038614
[epoch6, step328]: loss 0.036516
[epoch6, step329]: loss 0.036395
[epoch6, step330]: loss 0.038804
[epoch6, step331]: loss 0.037018
[epoch6, step332]: loss 0.038739
[epoch6, step333]: loss 0.036316
[epoch6, step334]: loss 0.036950
[epoch6, step335]: loss 0.039360
[epoch6, step336]: loss 0.040035
[epoch6, step337]: loss 0.036763
[epoch6, step338]: loss 0.036140
[epoch6, step339]: loss 0.039225
[epoch6, step340]: loss 0.037237
[epoch6, step341]: loss 0.038734
[epoch6, step342]: loss 0.036119
[epoch6, step343]: loss 0.037065
[epoch6, step344]: loss 0.038778
[epoch6, step345]: loss 0.038559
[epoch6, step346]: loss 0.035864
[epoch6, step347]: loss 0.036299
[epoch6, step348]: loss 0.039535
[epoch6, step349]: loss 0.037280
[epoch6, step350]: loss 0.038834
[epoch6, step351]: loss 0.035535
[epoch6, step352]: loss 0.036674
[epoch6, step353]: loss 0.039044
[epoch6, step354]: loss 0.038201
[epoch6, step355]: loss 0.035259
[epoch6, step356]: loss 0.037163
[epoch6, step357]: loss 0.039289
[epoch6, step358]: loss 0.035225
[epoch6, step359]: loss 0.040119
[epoch6, step360]: loss 0.035153
[epoch6, step361]: loss 0.036258
[epoch6, step362]: loss 0.039878
[epoch6, step363]: loss 0.038869
[epoch6, step364]: loss 0.036127
[epoch6, step365]: loss 0.036284
[epoch6, step366]: loss 0.039601
[epoch6, step367]: loss 0.036815
[epoch6, step368]: loss 0.038587
[epoch6, step369]: loss 0.036135
[epoch6, step370]: loss 0.037350
[epoch6, step371]: loss 0.039953
[epoch6, step372]: loss 0.038806
[epoch6, step373]: loss 0.035732
[epoch6, step374]: loss 0.035780
[epoch6, step375]: loss 0.039871
[epoch6, step376]: loss 0.036723
[epoch6, step377]: loss 0.039354
[epoch6, step378]: loss 0.036790
[epoch6, step379]: loss 0.037372
[epoch6, step380]: loss 0.039775
[epoch6, step381]: loss 0.038850
[epoch6, step382]: loss 0.036516
[epoch6, step383]: loss 0.035523
[epoch6, step384]: loss 0.038457
[epoch6, step385]: loss 0.036525
[epoch6, step386]: loss 0.039360
[epoch6, step387]: loss 0.036363
[epoch6, step388]: loss 0.037735
[epoch6, step389]: loss 0.039127
[epoch6, step390]: loss 0.040151
[epoch6, step391]: loss 0.035829
[epoch6, step392]: loss 0.037075
[epoch6, step393]: loss 0.038749
[epoch6, step394]: loss 0.036702
[epoch6, step395]: loss 0.038986
[epoch6, step396]: loss 0.036409
[epoch6, step397]: loss 0.036415
[epoch6, step398]: loss 0.039338
[epoch6, step399]: loss 0.039108
[epoch6, step400]: loss 0.035912
[epoch6, step401]: loss 0.036363
[epoch6, step402]: loss 0.039129
[epoch6, step403]: loss 0.036641
[epoch6, step404]: loss 0.039600
[epoch6, step405]: loss 0.036665
[epoch6, step406]: loss 0.037092
[epoch6, step407]: loss 0.038995
[epoch6, step408]: loss 0.039298
[epoch6, step409]: loss 0.037577
[epoch6, step410]: loss 0.037177
[epoch6, step411]: loss 0.039043
[epoch6, step412]: loss 0.036182
[epoch6, step413]: loss 0.039215
[epoch6, step414]: loss 0.036050
[epoch6, step415]: loss 0.037038
[epoch6, step416]: loss 0.038504
[epoch6, step417]: loss 0.039344
[epoch6, step418]: loss 0.036190
[epoch6, step419]: loss 0.035701
[epoch6, step420]: loss 0.039424
[epoch6, step421]: loss 0.036407
[epoch6, step422]: loss 0.039100
[epoch6, step423]: loss 0.036411
[epoch6, step424]: loss 0.036960
[epoch6, step425]: loss 0.039333
[epoch6, step426]: loss 0.039547
[epoch6, step427]: loss 0.036613
[epoch6, step428]: loss 0.036507
[epoch6, step429]: loss 0.039871
[epoch6, step430]: loss 0.036695
[epoch6, step431]: loss 0.039553
[epoch6, step432]: loss 0.036137
[epoch6, step433]: loss 0.037661
[epoch6, step434]: loss 0.039056
[epoch6, step435]: loss 0.039574
[epoch6, step436]: loss 0.035955
[epoch6, step437]: loss 0.036640
[epoch6, step438]: loss 0.039802
[epoch6, step439]: loss 0.036914
[epoch6, step440]: loss 0.039127
[epoch6, step441]: loss 0.036615
[epoch6, step442]: loss 0.036710
[epoch6, step443]: loss 0.039672
[epoch6, step444]: loss 0.038877
[epoch6, step445]: loss 0.036667
[epoch6, step446]: loss 0.036937
[epoch6, step447]: loss 0.039923
[epoch6, step448]: loss 0.036838
[epoch6, step449]: loss 0.039096
[epoch6, step450]: loss 0.035656
[epoch6, step451]: loss 0.036705
[epoch6, step452]: loss 0.038278
[epoch6, step453]: loss 0.039273
[epoch6, step454]: loss 0.036189
[epoch6, step455]: loss 0.036632
[epoch6, step456]: loss 0.038454
[epoch6, step457]: loss 0.037392
[epoch6, step458]: loss 0.038981
[epoch6, step459]: loss 0.037080
[epoch6, step460]: loss 0.037011
[epoch6, step461]: loss 0.039954
[epoch6, step462]: loss 0.038524
[epoch6, step463]: loss 0.036312
[epoch6, step464]: loss 0.036437
[epoch6, step465]: loss 0.040680
[epoch6, step466]: loss 0.036757
[epoch6, step467]: loss 0.039134
[epoch6, step468]: loss 0.036375
[epoch6, step469]: loss 0.037090
[epoch6, step470]: loss 0.039396
[epoch6, step471]: loss 0.038758
[epoch6, step472]: loss 0.036804
[epoch6, step473]: loss 0.036028
[epoch6, step474]: loss 0.039145
[epoch6, step475]: loss 0.036729
[epoch6, step476]: loss 0.039629
[epoch6, step477]: loss 0.036163
[epoch6, step478]: loss 0.036189
[epoch6, step479]: loss 0.038987
[epoch6, step480]: loss 0.038364
[epoch6, step481]: loss 0.035787
[epoch6, step482]: loss 0.035914
[epoch6, step483]: loss 0.039628
[epoch6, step484]: loss 0.036892
[epoch6, step485]: loss 0.039422
[epoch6, step486]: loss 0.036694
[epoch6, step487]: loss 0.036271
[epoch6, step488]: loss 0.039582
[epoch6, step489]: loss 0.038427
[epoch6, step490]: loss 0.036665
[epoch6, step491]: loss 0.036771
[epoch6, step492]: loss 0.038885
[epoch6, step493]: loss 0.036392
[epoch6, step494]: loss 0.038531
[epoch6, step495]: loss 0.037489
[epoch6, step496]: loss 0.037013
[epoch6, step497]: loss 0.039295
[epoch6, step498]: loss 0.039030
[epoch6, step499]: loss 0.036520
[epoch6, step500]: loss 0.036061
[epoch6, step501]: loss 0.038724
[epoch6, step502]: loss 0.036470
[epoch6, step503]: loss 0.039446
[epoch6, step504]: loss 0.036056
[epoch6, step505]: loss 0.035882
[epoch6, step506]: loss 0.039554
[epoch6, step507]: loss 0.039601
[epoch6, step508]: loss 0.036718
[epoch6, step509]: loss 0.036445
[epoch6, step510]: loss 0.039501
[epoch6, step511]: loss 0.037085
[epoch6, step512]: loss 0.039588
[epoch6, step513]: loss 0.036559
[epoch6, step514]: loss 0.037118
[epoch6, step515]: loss 0.039177
[epoch6, step516]: loss 0.039592
[epoch6, step517]: loss 0.036289
[epoch6, step518]: loss 0.036562
[epoch6, step519]: loss 0.039322
[epoch6, step520]: loss 0.036036
[epoch6, step521]: loss 0.039040
[epoch6, step522]: loss 0.035977
[epoch6, step523]: loss 0.036789
[epoch6, step524]: loss 0.038408
[epoch6, step525]: loss 0.039514
[epoch6, step526]: loss 0.036355
[epoch6, step527]: loss 0.036155
[epoch6, step528]: loss 0.039398
[epoch6, step529]: loss 0.036196
[epoch6, step530]: loss 0.039613
[epoch6, step531]: loss 0.036098
[epoch6, step532]: loss 0.036487
[epoch6, step533]: loss 0.040078
[epoch6, step534]: loss 0.039022
[epoch6, step535]: loss 0.036843
[epoch6, step536]: loss 0.036700
[epoch6, step537]: loss 0.039336
[epoch6, step538]: loss 0.036701
[epoch6, step539]: loss 0.038918
[epoch6, step540]: loss 0.035890
[epoch6, step541]: loss 0.036296
[epoch6, step542]: loss 0.039187
[epoch6, step543]: loss 0.038921
[epoch6, step544]: loss 0.036100
[epoch6, step545]: loss 0.035691
[epoch6, step546]: loss 0.039716
[epoch6, step547]: loss 0.036571
[epoch6, step548]: loss 0.039178
[epoch6, step549]: loss 0.036592
[epoch6, step550]: loss 0.036850
[epoch6, step551]: loss 0.038929
[epoch6, step552]: loss 0.038545
[epoch6, step553]: loss 0.036668
[epoch6, step554]: loss 0.036332
[epoch6, step555]: loss 0.038820
[epoch6, step556]: loss 0.036373
[epoch6, step557]: loss 0.038578
[epoch6, step558]: loss 0.036559
[epoch6, step559]: loss 0.036223
[epoch6, step560]: loss 0.039291
[epoch6, step561]: loss 0.038883
[epoch6, step562]: loss 0.036171
[epoch6, step563]: loss 0.029256
[epoch6, step564]: loss 0.028666
[epoch6, step565]: loss 0.027342
[epoch6, step566]: loss 0.033822
[epoch6, step567]: loss 0.025648
[epoch6, step568]: loss 0.024979
[epoch6, step569]: loss 0.022702
[epoch6, step570]: loss 0.030201
[epoch6, step571]: loss 0.026673
[epoch6, step572]: loss 0.025527
[epoch6, step573]: loss 0.028420
[epoch6, step574]: loss 0.027493
[epoch6, step575]: loss 0.020513
[epoch6, step576]: loss 0.021454
[epoch6, step577]: loss 0.025455
[epoch6, step578]: loss 0.018608
[epoch6, step579]: loss 0.028312
[epoch6, step580]: loss 0.020023
[epoch6, step581]: loss 0.025069
[epoch6, step582]: loss 0.024667
[epoch6, step583]: loss 0.021706
[epoch6, step584]: loss 0.023395
[epoch6, step585]: loss 0.025691
[epoch6, step586]: loss 0.021502
[epoch6, step587]: loss 0.027167
[epoch6, step588]: loss 0.022812
[epoch6, step589]: loss 0.022734
[epoch6, step590]: loss 0.026894
[epoch6, step591]: loss 0.020511
[epoch6, step592]: loss 0.025711
[epoch6, step593]: loss 0.021993
[epoch6, step594]: loss 0.025726
[epoch6, step595]: loss 0.026474
[epoch6, step596]: loss 0.022207
[epoch6, step597]: loss 0.024858
[epoch6, step598]: loss 0.026759
[epoch6, step599]: loss 0.025071
[epoch6, step600]: loss 0.026956
[epoch6, step601]: loss 0.019490
[epoch6, step602]: loss 0.022492
[epoch6, step603]: loss 0.025547
[epoch6, step604]: loss 0.026365
[epoch6, step605]: loss 0.025291
[epoch6, step606]: loss 0.024890
[epoch6, step607]: loss 0.026738
[epoch6, step608]: loss 0.025625
[epoch6, step609]: loss 0.026513
[epoch6, step610]: loss 0.026079
[epoch6, step611]: loss 0.026103
[epoch6, step612]: loss 0.025551
[epoch6, step613]: loss 0.019291
[epoch6, step614]: loss 0.025137
[epoch6, step615]: loss 0.028031
[epoch6, step616]: loss 0.023950
[epoch6, step617]: loss 0.023340
[epoch6, step618]: loss 0.025584
[epoch6, step619]: loss 0.026881
[epoch6, step620]: loss 0.024464
[epoch6, step621]: loss 0.026078
[epoch6, step622]: loss 0.020494
[epoch6, step623]: loss 0.024673
[epoch6, step624]: loss 0.026324
[epoch6, step625]: loss 0.025865
[epoch6, step626]: loss 0.028079
[epoch6, step627]: loss 0.022650
[epoch6, step628]: loss 0.025468
[epoch6, step629]: loss 0.020681
[epoch6, step630]: loss 0.023316
[epoch6, step631]: loss 0.031502
[epoch6, step632]: loss 0.023272
[epoch6, step633]: loss 0.024580
[epoch6, step634]: loss 0.027174
[epoch6, step635]: loss 0.025509
[epoch6, step636]: loss 0.020859
[epoch6, step637]: loss 0.027142
[epoch6, step638]: loss 0.026895
[epoch6, step639]: loss 0.023101
[epoch6, step640]: loss 0.029031
[epoch6, step641]: loss 0.030337
[epoch6, step642]: loss 0.024958
[epoch6, step643]: loss 0.025613
[epoch6, step644]: loss 0.025670
[epoch6, step645]: loss 0.023658
[epoch6, step646]: loss 0.026208
[epoch6, step647]: loss 0.023753
[epoch6, step648]: loss 0.023136
[epoch6, step649]: loss 0.028644
[epoch6, step650]: loss 0.021838
[epoch6, step651]: loss 0.025817
[epoch6, step652]: loss 0.026587
[epoch6, step653]: loss 0.027793
[epoch6, step654]: loss 0.023127
[epoch6, step655]: loss 0.024361
[epoch6, step656]: loss 0.021336
[epoch6, step657]: loss 0.027683
[epoch6, step658]: loss 0.025399
[epoch6, step659]: loss 0.027754
[epoch6, step660]: loss 0.023884
[epoch6, step661]: loss 0.026295
[epoch6, step662]: loss 0.023990
[epoch6, step663]: loss 0.020987
[epoch6, step664]: loss 0.024885
[epoch6, step665]: loss 0.027683
[epoch6, step666]: loss 0.026592
[epoch6, step667]: loss 0.026334
[epoch6, step668]: loss 0.022242
[epoch6, step669]: loss 0.026405
[epoch6, step670]: loss 0.026828
[epoch6, step671]: loss 0.021426
[epoch6, step672]: loss 0.023676
[epoch6, step673]: loss 0.022104
[epoch6, step674]: loss 0.021245
[epoch6, step675]: loss 0.020037
[epoch6, step676]: loss 0.024453
[epoch6, step677]: loss 0.025111
[epoch6, step678]: loss 0.023199
[epoch6, step679]: loss 0.023868
[epoch6, step680]: loss 0.030666
[epoch6, step681]: loss 0.021931
[epoch6, step682]: loss 0.026049
[epoch6, step683]: loss 0.025799
[epoch6, step684]: loss 0.024737
[epoch6, step685]: loss 0.024188
[epoch6, step686]: loss 0.027171
[epoch6, step687]: loss 0.026639
[epoch6, step688]: loss 0.022701
[epoch6, step689]: loss 0.024444
[epoch6, step690]: loss 0.025155
[epoch6, step691]: loss 0.024234
[epoch6, step692]: loss 0.022441
[epoch6, step693]: loss 0.027232
[epoch6, step694]: loss 0.022966
[epoch6, step695]: loss 0.026179
[epoch6, step696]: loss 0.026205
[epoch6, step697]: loss 0.026817
[epoch6, step698]: loss 0.024700
[epoch6, step699]: loss 0.023513
[epoch6, step700]: loss 0.021767
[epoch6, step701]: loss 0.026167
[epoch6, step702]: loss 0.021741
[epoch6, step703]: loss 0.022952
[epoch6, step704]: loss 0.025290
[epoch6, step705]: loss 0.024910
[epoch6, step706]: loss 0.023736
[epoch6, step707]: loss 0.024611
[epoch6, step708]: loss 0.026107
[epoch6, step709]: loss 0.027379
[epoch6, step710]: loss 0.023780
[epoch6, step711]: loss 0.023589
[epoch6, step712]: loss 0.026789
[epoch6, step713]: loss 0.026161
[epoch6, step714]: loss 0.021485
[epoch6, step715]: loss 0.023195
[epoch6, step716]: loss 0.025912
[epoch6, step717]: loss 0.023607
[epoch6, step718]: loss 0.024991
[epoch6, step719]: loss 0.033013
[epoch6, step720]: loss 0.024728
[epoch6, step721]: loss 0.023067
[epoch6, step722]: loss 0.030734
[epoch6, step723]: loss 0.026061
[epoch6, step724]: loss 0.022893
[epoch6, step725]: loss 0.027849
[epoch6, step726]: loss 0.022417
[epoch6, step727]: loss 0.024657
[epoch6, step728]: loss 0.026623
[epoch6, step729]: loss 0.021072
[epoch6, step730]: loss 0.022685
[epoch6, step731]: loss 0.025853
[epoch6, step732]: loss 0.025987
[epoch6, step733]: loss 0.023906
[epoch6, step734]: loss 0.022683
[epoch6, step735]: loss 0.027510
[epoch6, step736]: loss 0.025110
[epoch6, step737]: loss 0.026623
[epoch6, step738]: loss 0.020636
[epoch6, step739]: loss 0.025512
[epoch6, step740]: loss 0.022217
[epoch6, step741]: loss 0.025318
[epoch6, step742]: loss 0.021701
[epoch6, step743]: loss 0.023186
[epoch6, step744]: loss 0.024138
[epoch6, step745]: loss 0.024574
[epoch6, step746]: loss 0.025224
[epoch6, step747]: loss 0.027453
[epoch6, step748]: loss 0.025557
[epoch6, step749]: loss 0.026212
[epoch6, step750]: loss 0.027475
[epoch6, step751]: loss 0.021536
[epoch6, step752]: loss 0.024961
[epoch6, step753]: loss 0.025654
[epoch6, step754]: loss 0.022521
[epoch6, step755]: loss 0.026069
[epoch6, step756]: loss 0.023484
[epoch6, step757]: loss 0.020454
[epoch6, step758]: loss 0.025249
[epoch6, step759]: loss 0.022977
[epoch6, step760]: loss 0.023871
[epoch6, step761]: loss 0.026444
[epoch6, step762]: loss 0.021584
[epoch6, step763]: loss 0.025523
[epoch6, step764]: loss 0.023280
[epoch6, step765]: loss 0.026213
[epoch6, step766]: loss 0.024470
[epoch6, step767]: loss 0.026474
[epoch6, step768]: loss 0.021387
[epoch6, step769]: loss 0.026686
[epoch6, step770]: loss 0.025819
[epoch6, step771]: loss 0.023589
[epoch6, step772]: loss 0.028757
[epoch6, step773]: loss 0.026686
[epoch6, step774]: loss 0.024259
[epoch6, step775]: loss 0.020579
[epoch6, step776]: loss 0.025537
[epoch6, step777]: loss 0.022972
[epoch6, step778]: loss 0.028042
[epoch6, step779]: loss 0.023718
[epoch6, step780]: loss 0.020064
[epoch6, step781]: loss 0.024387
[epoch6, step782]: loss 0.022715
[epoch6, step783]: loss 0.019152
[epoch6, step784]: loss 0.020198
[epoch6, step785]: loss 0.021551
[epoch6, step786]: loss 0.024388
[epoch6, step787]: loss 0.023224
[epoch6, step788]: loss 0.024856
[epoch6, step789]: loss 0.022403
[epoch6, step790]: loss 0.023219
[epoch6, step791]: loss 0.026766
[epoch6, step792]: loss 0.024993
[epoch6, step793]: loss 0.026805
[epoch6, step794]: loss 0.020483
[epoch6, step795]: loss 0.025451
[epoch6, step796]: loss 0.027742
[epoch6, step797]: loss 0.027558
[epoch6, step798]: loss 0.027062
[epoch6, step799]: loss 0.025748
[epoch6, step800]: loss 0.021532
[epoch6, step801]: loss 0.021845
[epoch6, step802]: loss 0.022895
[epoch6, step803]: loss 0.026003
[epoch6, step804]: loss 0.027178
[epoch6, step805]: loss 0.028160
[epoch6, step806]: loss 0.021319
[epoch6, step807]: loss 0.020480
[epoch6, step808]: loss 0.022848
[epoch6, step809]: loss 0.022957
[epoch6, step810]: loss 0.025985
[epoch6, step811]: loss 0.025700
[epoch6, step812]: loss 0.024543
[epoch6, step813]: loss 0.023479
[epoch6, step814]: loss 0.025277
[epoch6, step815]: loss 0.024926
[epoch6, step816]: loss 0.024150
[epoch6, step817]: loss 0.024731
[epoch6, step818]: loss 0.022427
[epoch6, step819]: loss 0.020086
[epoch6, step820]: loss 0.023536
[epoch6, step821]: loss 0.021769
[epoch6, step822]: loss 0.030322
[epoch6, step823]: loss 0.023918
[epoch6, step824]: loss 0.026664
[epoch6, step825]: loss 0.025167
[epoch6, step826]: loss 0.024371
[epoch6, step827]: loss 0.026942
[epoch6, step828]: loss 0.028773
[epoch6, step829]: loss 0.026242
[epoch6, step830]: loss 0.022594
[epoch6, step831]: loss 0.026351
[epoch6, step832]: loss 0.020912
[epoch6, step833]: loss 0.029187
[epoch6, step834]: loss 0.025457
[epoch6, step835]: loss 0.020676
[epoch6, step836]: loss 0.026832
[epoch6, step837]: loss 0.025480
[epoch6, step838]: loss 0.026232
[epoch6, step839]: loss 0.028405
[epoch6, step840]: loss 0.020849
[epoch6, step841]: loss 0.024111
[epoch6, step842]: loss 0.027421
[epoch6, step843]: loss 0.024828
[epoch6, step844]: loss 0.024791
[epoch6, step845]: loss 0.021058
[epoch6, step846]: loss 0.025335
[epoch6, step847]: loss 0.026938
[epoch6, step848]: loss 0.025003
[epoch6, step849]: loss 0.025045
[epoch6, step850]: loss 0.022933
[epoch6, step851]: loss 0.023955
[epoch6, step852]: loss 0.023243
[epoch6, step853]: loss 0.029380
[epoch6, step854]: loss 0.022637
[epoch6, step855]: loss 0.027240
[epoch6, step856]: loss 0.022064
[epoch6, step857]: loss 0.025825
[epoch6, step858]: loss 0.024361
[epoch6, step859]: loss 0.023755
[epoch6, step860]: loss 0.022579
[epoch6, step861]: loss 0.023279
[epoch6, step862]: loss 0.023145
[epoch6, step863]: loss 0.020687
[epoch6, step864]: loss 0.026350
[epoch6, step865]: loss 0.023534
[epoch6, step866]: loss 0.025153
[epoch6, step867]: loss 0.026228
[epoch6, step868]: loss 0.026688
[epoch6, step869]: loss 0.023986
[epoch6, step870]: loss 0.031156
[epoch6, step871]: loss 0.022019
[epoch6, step872]: loss 0.025166
[epoch6, step873]: loss 0.025766
[epoch6, step874]: loss 0.023644
[epoch6, step875]: loss 0.024286
[epoch6, step876]: loss 0.024172
[epoch6, step877]: loss 0.019321
[epoch6, step878]: loss 0.023262
[epoch6, step879]: loss 0.028028
[epoch6, step880]: loss 0.025404
[epoch6, step881]: loss 0.022206
[epoch6, step882]: loss 0.024223
[epoch6, step883]: loss 0.023872
[epoch6, step884]: loss 0.026526
[epoch6, step885]: loss 0.026100
[epoch6, step886]: loss 0.026383
[epoch6, step887]: loss 0.024274
[epoch6, step888]: loss 0.024696
[epoch6, step889]: loss 0.023484
[epoch6, step890]: loss 0.023346
[epoch6, step891]: loss 0.025728
[epoch6, step892]: loss 0.020899
[epoch6, step893]: loss 0.024674
[epoch6, step894]: loss 0.025018
[epoch6, step895]: loss 0.022574
[epoch6, step896]: loss 0.021708
[epoch6, step897]: loss 0.023968
[epoch6, step898]: loss 0.025416
[epoch6, step899]: loss 0.027860
[epoch6, step900]: loss 0.027082
[epoch6, step901]: loss 0.025414
[epoch6, step902]: loss 0.023968
[epoch6, step903]: loss 0.024255
[epoch6, step904]: loss 0.028006
[epoch6, step905]: loss 0.027508
[epoch6, step906]: loss 0.022336
[epoch6, step907]: loss 0.023653
[epoch6, step908]: loss 0.022410
[epoch6, step909]: loss 0.025381
[epoch6, step910]: loss 0.023022
[epoch6, step911]: loss 0.025227
[epoch6, step912]: loss 0.023881
[epoch6, step913]: loss 0.024071
[epoch6, step914]: loss 0.030608
[epoch6, step915]: loss 0.024088
[epoch6, step916]: loss 0.023878
[epoch6, step917]: loss 0.025005
[epoch6, step918]: loss 0.028592
[epoch6, step919]: loss 0.024098
[epoch6, step920]: loss 0.027656
[epoch6, step921]: loss 0.024599
[epoch6, step922]: loss 0.023254
[epoch6, step923]: loss 0.022511
[epoch6, step924]: loss 0.021081
[epoch6, step925]: loss 0.025449
[epoch6, step926]: loss 0.026514
[epoch6, step927]: loss 0.025743
[epoch6, step928]: loss 0.024793
[epoch6, step929]: loss 0.027586
[epoch6, step930]: loss 0.025590
[epoch6, step931]: loss 0.027232
[epoch6, step932]: loss 0.021727
[epoch6, step933]: loss 0.027942
[epoch6, step934]: loss 0.022091
[epoch6, step935]: loss 0.022142
[epoch6, step936]: loss 0.022474
[epoch6, step937]: loss 0.027183
[epoch6, step938]: loss 0.025337
[epoch6, step939]: loss 0.020827
[epoch6, step940]: loss 0.022899
[epoch6, step941]: loss 0.026727
[epoch6, step942]: loss 0.025395
[epoch6, step943]: loss 0.023001
[epoch6, step944]: loss 0.027692
[epoch6, step945]: loss 0.020589
[epoch6, step946]: loss 0.025450
[epoch6, step947]: loss 0.028259
[epoch6, step948]: loss 0.019418
[epoch6, step949]: loss 0.022938
[epoch6, step950]: loss 0.026511
[epoch6, step951]: loss 0.028450
[epoch6, step952]: loss 0.025059
[epoch6, step953]: loss 0.027664
[epoch6, step954]: loss 0.022168
[epoch6, step955]: loss 0.037004
[epoch6, step956]: loss 0.052636
[epoch6, step957]: loss 0.046686
[epoch6, step958]: loss 0.043440
[epoch6, step959]: loss 0.046435
[epoch6, step960]: loss 0.041459
[epoch6, step961]: loss 0.038776
[epoch6, step962]: loss 0.038166
[epoch6, step963]: loss 0.040620
[epoch6, step964]: loss 0.042315
[epoch6, step965]: loss 0.042083
[epoch6, step966]: loss 0.039193
[epoch6, step967]: loss 0.037737
[epoch6, step968]: loss 0.040157
[epoch6, step969]: loss 0.041832
[epoch6, step970]: loss 0.042673
[epoch6, step971]: loss 0.040084
[epoch6, step972]: loss 0.039364
[epoch6, step973]: loss 0.038167
[epoch6, step974]: loss 0.040360
[epoch6, step975]: loss 0.037659
[epoch6, step976]: loss 0.037349
[epoch6, step977]: loss 0.040859
[epoch6, step978]: loss 0.038826
[epoch6, step979]: loss 0.037992
[epoch6, step980]: loss 0.037107
[epoch6, step981]: loss 0.038539
[epoch6, step982]: loss 0.039179
[epoch6, step983]: loss 0.040060
[epoch6, step984]: loss 0.036158
[epoch6, step985]: loss 0.036978
[epoch6, step986]: loss 0.040946
[epoch6, step987]: loss 0.038986
[epoch6, step988]: loss 0.038319
[epoch6, step989]: loss 0.037452
[epoch6, step990]: loss 0.038094
[epoch6, step991]: loss 0.039375
[epoch6, step992]: loss 0.039251
[epoch6, step993]: loss 0.036726
[epoch6, step994]: loss 0.036542
[epoch6, step995]: loss 0.040308
[epoch6, step996]: loss 0.037982
[epoch6, step997]: loss 0.038055
[epoch6, step998]: loss 0.037429
[epoch6, step999]: loss 0.038299
[epoch6, step1000]: loss 0.038370
[epoch6, step1001]: loss 0.039259
[epoch6, step1002]: loss 0.037033
[epoch6, step1003]: loss 0.036068
[epoch6, step1004]: loss 0.040161
[epoch6, step1005]: loss 0.037557
[epoch6, step1006]: loss 0.037788
[epoch6, step1007]: loss 0.036308
[epoch6, step1008]: loss 0.037732
[epoch6, step1009]: loss 0.038107
[epoch6, step1010]: loss 0.039962
[epoch6, step1011]: loss 0.036516
[epoch6, step1012]: loss 0.036882
[epoch6, step1013]: loss 0.039800
[epoch6, step1014]: loss 0.038731
[epoch6, step1015]: loss 0.038173
[epoch6, step1016]: loss 0.036149
[epoch6, step1017]: loss 0.037721
[epoch6, step1018]: loss 0.037901
[epoch6, step1019]: loss 0.039196
[epoch6, step1020]: loss 0.036099
[epoch6, step1021]: loss 0.035963
[epoch6, step1022]: loss 0.039224
[epoch6, step1023]: loss 0.037952
[epoch6, step1024]: loss 0.038175
[epoch6, step1025]: loss 0.035891
[epoch6, step1026]: loss 0.037339
[epoch6, step1027]: loss 0.037540
[epoch6, step1028]: loss 0.039147
[epoch6, step1029]: loss 0.036021
[epoch6, step1030]: loss 0.035817
[epoch6, step1031]: loss 0.038164
[epoch6, step1032]: loss 0.038234
[epoch6, step1033]: loss 0.037373
[epoch6, step1034]: loss 0.035932
[epoch6, step1035]: loss 0.037252
[epoch6, step1036]: loss 0.037872
[epoch6, step1037]: loss 0.038769
[epoch6, step1038]: loss 0.036044
[epoch6, step1039]: loss 0.036333
[epoch6, step1040]: loss 0.038563
[epoch6, step1041]: loss 0.037553
[epoch6, step1042]: loss 0.036472
[epoch6, step1043]: loss 0.036070
[epoch6, step1044]: loss 0.037825
[epoch6, step1045]: loss 0.037846
[epoch6, step1046]: loss 0.039208
[epoch6, step1047]: loss 0.036270
[epoch6, step1048]: loss 0.035823
[epoch6, step1049]: loss 0.039310
[epoch6, step1050]: loss 0.038256
[epoch6, step1051]: loss 0.037664
[epoch6, step1052]: loss 0.036536
[epoch6, step1053]: loss 0.038112
[epoch6, step1054]: loss 0.037890
[epoch6, step1055]: loss 0.038391
[epoch6, step1056]: loss 0.035679
[epoch6, step1057]: loss 0.036704
[epoch6, step1058]: loss 0.040003
[epoch6, step1059]: loss 0.037982
[epoch6, step1060]: loss 0.037602
[epoch6, step1061]: loss 0.035669
[epoch6, step1062]: loss 0.038009
[epoch6, step1063]: loss 0.037782
[epoch6, step1064]: loss 0.038942
[epoch6, step1065]: loss 0.036131
[epoch6, step1066]: loss 0.035942
[epoch6, step1067]: loss 0.039138
[epoch6, step1068]: loss 0.036500
[epoch6, step1069]: loss 0.037049
[epoch6, step1070]: loss 0.035987
[epoch6, step1071]: loss 0.038233
[epoch6, step1072]: loss 0.038444
[epoch6, step1073]: loss 0.038776
[epoch6, step1074]: loss 0.036397
[epoch6, step1075]: loss 0.036375
[epoch6, step1076]: loss 0.039265
[epoch6, step1077]: loss 0.037678
[epoch6, step1078]: loss 0.037173
[epoch6, step1079]: loss 0.037149
[epoch6, step1080]: loss 0.037898
[epoch6, step1081]: loss 0.037534
[epoch6, step1082]: loss 0.038796
[epoch6, step1083]: loss 0.036865
[epoch6, step1084]: loss 0.036487
[epoch6, step1085]: loss 0.038749
[epoch6, step1086]: loss 0.037398
[epoch6, step1087]: loss 0.037641
[epoch6, step1088]: loss 0.035904
[epoch6, step1089]: loss 0.038060
[epoch6, step1090]: loss 0.038310
[epoch6, step1091]: loss 0.039068
[epoch6, step1092]: loss 0.036030
[epoch6, step1093]: loss 0.036049
[epoch6, step1094]: loss 0.038191
[epoch6, step1095]: loss 0.037248
[epoch6, step1096]: loss 0.036907
[epoch6, step1097]: loss 0.036116
[epoch6, step1098]: loss 0.037779
[epoch6, step1099]: loss 0.037398
[epoch6, step1100]: loss 0.039540
[epoch6, step1101]: loss 0.036576
[epoch6, step1102]: loss 0.036100
[epoch6, step1103]: loss 0.038625
[epoch6, step1104]: loss 0.037541
[epoch6, step1105]: loss 0.037686
[epoch6, step1106]: loss 0.035098
[epoch6, step1107]: loss 0.037998
[epoch6, step1108]: loss 0.037406
[epoch6, step1109]: loss 0.039262
[epoch6, step1110]: loss 0.036858
[epoch6, step1111]: loss 0.036237
[epoch6, step1112]: loss 0.039401
[epoch6, step1113]: loss 0.037306
[epoch6, step1114]: loss 0.037715
[epoch6, step1115]: loss 0.036317
[epoch6, step1116]: loss 0.037803
[epoch6, step1117]: loss 0.037810
[epoch6, step1118]: loss 0.038849
[epoch6, step1119]: loss 0.036055
[epoch6, step1120]: loss 0.036097
[epoch6, step1121]: loss 0.039086
[epoch6, step1122]: loss 0.037189
[epoch6, step1123]: loss 0.036821
[epoch6, step1124]: loss 0.036752
[epoch6, step1125]: loss 0.038079
[epoch6, step1126]: loss 0.038670
[epoch6, step1127]: loss 0.038922
[epoch6, step1128]: loss 0.036392
[epoch6, step1129]: loss 0.035887
[epoch6, step1130]: loss 0.039796
[epoch6, step1131]: loss 0.038009
[epoch6, step1132]: loss 0.037751
[epoch6, step1133]: loss 0.035745
[epoch6, step1134]: loss 0.037490
[epoch6, step1135]: loss 0.038708
[epoch6, step1136]: loss 0.039763
[epoch6, step1137]: loss 0.036328
[epoch6, step1138]: loss 0.036430
[epoch6, step1139]: loss 0.039151
[epoch6, step1140]: loss 0.037018
[epoch6, step1141]: loss 0.037239
[epoch6, step1142]: loss 0.035858
[epoch6, step1143]: loss 0.037201
[epoch6, step1144]: loss 0.037928
[epoch6, step1145]: loss 0.038293
[epoch6, step1146]: loss 0.035885
[epoch6, step1147]: loss 0.036795
[epoch6, step1148]: loss 0.039165
[epoch6, step1149]: loss 0.037273
[epoch6, step1150]: loss 0.037168
[epoch6, step1151]: loss 0.036572
[epoch6, step1152]: loss 0.038220
[epoch6, step1153]: loss 0.037243
[epoch6, step1154]: loss 0.039308
[epoch6, step1155]: loss 0.036319
[epoch6, step1156]: loss 0.035612
[epoch6, step1157]: loss 0.038901
[epoch6, step1158]: loss 0.037858
[epoch6, step1159]: loss 0.037714
[epoch6, step1160]: loss 0.036937
[epoch6, step1161]: loss 0.038218
[epoch6, step1162]: loss 0.037695
[epoch6, step1163]: loss 0.038141
[epoch6, step1164]: loss 0.036217
[epoch6, step1165]: loss 0.037130
[epoch6, step1166]: loss 0.039308
[epoch6, step1167]: loss 0.036777
[epoch6, step1168]: loss 0.037506
[epoch6, step1169]: loss 0.035995
[epoch6, step1170]: loss 0.037729
[epoch6, step1171]: loss 0.037883
[epoch6, step1172]: loss 0.038964
[epoch6, step1173]: loss 0.036343
[epoch6, step1174]: loss 0.036647
[epoch6, step1175]: loss 0.039071
[epoch6, step1176]: loss 0.037285
[epoch6, step1177]: loss 0.037792
[epoch6, step1178]: loss 0.036200
[epoch6, step1179]: loss 0.037724
[epoch6, step1180]: loss 0.037882
[epoch6, step1181]: loss 0.039407
[epoch6, step1182]: loss 0.035501
[epoch6, step1183]: loss 0.036625
[epoch6, step1184]: loss 0.038550
[epoch6, step1185]: loss 0.037792
[epoch6, step1186]: loss 0.036522
[epoch6, step1187]: loss 0.035327
[epoch6, step1188]: loss 0.037045
[epoch6, step1189]: loss 0.037483
[epoch6, step1190]: loss 0.038530
[epoch6, step1191]: loss 0.036811
[epoch6, step1192]: loss 0.036379
[epoch6, step1193]: loss 0.039166
[epoch6, step1194]: loss 0.037422
[epoch6, step1195]: loss 0.036369
[epoch6, step1196]: loss 0.035354
[epoch6, step1197]: loss 0.037992
[epoch6, step1198]: loss 0.037774
[epoch6, step1199]: loss 0.038411
[epoch6, step1200]: loss 0.035908
[epoch6, step1201]: loss 0.036576
[epoch6, step1202]: loss 0.039888
[epoch6, step1203]: loss 0.037633
[epoch6, step1204]: loss 0.036617
[epoch6, step1205]: loss 0.035637
[epoch6, step1206]: loss 0.037111
[epoch6, step1207]: loss 0.038084
[epoch6, step1208]: loss 0.039322
[epoch6, step1209]: loss 0.035013
[epoch6, step1210]: loss 0.036794
[epoch6, step1211]: loss 0.038832
[epoch6, step1212]: loss 0.037363
[epoch6, step1213]: loss 0.037059
[epoch6, step1214]: loss 0.036204
[epoch6, step1215]: loss 0.038370
[epoch6, step1216]: loss 0.037276
[epoch6, step1217]: loss 0.039344
[epoch6, step1218]: loss 0.035789
[epoch6, step1219]: loss 0.036706
[epoch6, step1220]: loss 0.039301
[epoch6, step1221]: loss 0.036717
[epoch6, step1222]: loss 0.037435
[epoch6, step1223]: loss 0.036194
[epoch6, step1224]: loss 0.038209
[epoch6, step1225]: loss 0.037820
[epoch6, step1226]: loss 0.038593
[epoch6, step1227]: loss 0.036073
[epoch6, step1228]: loss 0.035968
[epoch6, step1229]: loss 0.038870
[epoch6, step1230]: loss 0.037757
[epoch6, step1231]: loss 0.037394
[epoch6, step1232]: loss 0.037116
[epoch6, step1233]: loss 0.037550
[epoch6, step1234]: loss 0.037433
[epoch6, step1235]: loss 0.039170
[epoch6, step1236]: loss 0.036352
[epoch6, step1237]: loss 0.035584
[epoch6, step1238]: loss 0.038491
[epoch6, step1239]: loss 0.038249
[epoch6, step1240]: loss 0.037511
[epoch6, step1241]: loss 0.035712
[epoch6, step1242]: loss 0.037590
[epoch6, step1243]: loss 0.037550
[epoch6, step1244]: loss 0.039288
[epoch6, step1245]: loss 0.036520
[epoch6, step1246]: loss 0.036545
[epoch6, step1247]: loss 0.038230
[epoch6, step1248]: loss 0.037616
[epoch6, step1249]: loss 0.038000
[epoch6, step1250]: loss 0.035982
[epoch6, step1251]: loss 0.037995
[epoch6, step1252]: loss 0.038599
[epoch6, step1253]: loss 0.039034
[epoch6, step1254]: loss 0.036220
[epoch6, step1255]: loss 0.036129
[epoch6, step1256]: loss 0.039377
[epoch6, step1257]: loss 0.037887
[epoch6, step1258]: loss 0.037551
[epoch6, step1259]: loss 0.036156
[epoch6, step1260]: loss 0.037772
[epoch6, step1261]: loss 0.037598
[epoch6, step1262]: loss 0.037889
[epoch6, step1263]: loss 0.036752
[epoch6, step1264]: loss 0.036222
[epoch6, step1265]: loss 0.037975
[epoch6, step1266]: loss 0.037535
[epoch6, step1267]: loss 0.037864
[epoch6, step1268]: loss 0.036256
[epoch6, step1269]: loss 0.037857
[epoch6, step1270]: loss 0.037018
[epoch6, step1271]: loss 0.039151
[epoch6, step1272]: loss 0.036262
[epoch6, step1273]: loss 0.035792
[epoch6, step1274]: loss 0.039103
[epoch6, step1275]: loss 0.037892
[epoch6, step1276]: loss 0.037248
[epoch6, step1277]: loss 0.036183
[epoch6, step1278]: loss 0.038316
[epoch6, step1279]: loss 0.038307
[epoch6, step1280]: loss 0.039211
[epoch6, step1281]: loss 0.036004
[epoch6, step1282]: loss 0.036506
[epoch6, step1283]: loss 0.038466
[epoch6, step1284]: loss 0.037040
[epoch6, step1285]: loss 0.037980
[epoch6, step1286]: loss 0.035536
[epoch6, step1287]: loss 0.038399
[epoch6, step1288]: loss 0.038454
[epoch6, step1289]: loss 0.039640
[epoch6, step1290]: loss 0.036248
[epoch6, step1291]: loss 0.035766
[epoch6, step1292]: loss 0.039692
[epoch6, step1293]: loss 0.036797
[epoch6, step1294]: loss 0.037383
[epoch6, step1295]: loss 0.036678
[epoch6, step1296]: loss 0.037901
[epoch6, step1297]: loss 0.037805
[epoch6, step1298]: loss 0.039601
[epoch6, step1299]: loss 0.036438
[epoch6, step1300]: loss 0.037031
[epoch6, step1301]: loss 0.038243
[epoch6, step1302]: loss 0.037544
[epoch6, step1303]: loss 0.037747
[epoch6, step1304]: loss 0.035447
[epoch6, step1305]: loss 0.038147
[epoch6, step1306]: loss 0.037800
[epoch6, step1307]: loss 0.038271
[epoch6, step1308]: loss 0.036302
[epoch6, step1309]: loss 0.035411
[epoch6, step1310]: loss 0.038845
[epoch6, step1311]: loss 0.036513
[epoch6, step1312]: loss 0.037969
[epoch6, step1313]: loss 0.036230
[epoch6, step1314]: loss 0.037624
[epoch6, step1315]: loss 0.037438
[epoch6, step1316]: loss 0.040381
[epoch6, step1317]: loss 0.035630
[epoch6, step1318]: loss 0.035732
[epoch6, step1319]: loss 0.038516
[epoch6, step1320]: loss 0.037691
[epoch6, step1321]: loss 0.037983
[epoch6, step1322]: loss 0.035658
[epoch6, step1323]: loss 0.038086
[epoch6, step1324]: loss 0.037302
[epoch6, step1325]: loss 0.038628
[epoch6, step1326]: loss 0.035927
[epoch6, step1327]: loss 0.035847
[epoch6, step1328]: loss 0.038934
[epoch6, step1329]: loss 0.037370
[epoch6, step1330]: loss 0.037460
[epoch6, step1331]: loss 0.035842
[epoch6, step1332]: loss 0.037565
[epoch6, step1333]: loss 0.036794
[epoch6, step1334]: loss 0.039411
[epoch6, step1335]: loss 0.036836
[epoch6, step1336]: loss 0.036251
[epoch6, step1337]: loss 0.038521
[epoch6, step1338]: loss 0.037543
[epoch6, step1339]: loss 0.037566
[epoch6, step1340]: loss 0.035696
[epoch6, step1341]: loss 0.037958
[epoch6, step1342]: loss 0.037444
[epoch6, step1343]: loss 0.038901
[epoch6, step1344]: loss 0.036276
[epoch6, step1345]: loss 0.035964
[epoch6, step1346]: loss 0.038425
[epoch6, step1347]: loss 0.038079
[epoch6, step1348]: loss 0.036588
[epoch6, step1349]: loss 0.036146
[epoch6, step1350]: loss 0.037939
[epoch6, step1351]: loss 0.037273
[epoch6, step1352]: loss 0.038671
[epoch6, step1353]: loss 0.035775
[epoch6, step1354]: loss 0.035972
[epoch6, step1355]: loss 0.039164
[epoch6, step1356]: loss 0.037221
[epoch6, step1357]: loss 0.037072
[epoch6, step1358]: loss 0.035896
[epoch6, step1359]: loss 0.037335
[epoch6, step1360]: loss 0.037868
[epoch6, step1361]: loss 0.039050
[epoch6, step1362]: loss 0.036803
[epoch6, step1363]: loss 0.036432
[epoch6, step1364]: loss 0.038743
[epoch6, step1365]: loss 0.037463
[epoch6, step1366]: loss 0.037075
[epoch6, step1367]: loss 0.035143
[epoch6, step1368]: loss 0.038621
[epoch6, step1369]: loss 0.038144
[epoch6, step1370]: loss 0.038642
[epoch6, step1371]: loss 0.036298
[epoch6, step1372]: loss 0.036080
[epoch6, step1373]: loss 0.039042
[epoch6, step1374]: loss 0.038308
[epoch6, step1375]: loss 0.038305
[epoch6, step1376]: loss 0.035779
[epoch6, step1377]: loss 0.037087
[epoch6, step1378]: loss 0.037770
[epoch6, step1379]: loss 0.038313
[epoch6, step1380]: loss 0.036478
[epoch6, step1381]: loss 0.035944
[epoch6, step1382]: loss 0.039060
[epoch6, step1383]: loss 0.037271
[epoch6, step1384]: loss 0.037085
[epoch6, step1385]: loss 0.035277
[epoch6, step1386]: loss 0.037809
[epoch6, step1387]: loss 0.038141
[epoch6, step1388]: loss 0.037892
[epoch6, step1389]: loss 0.035365
[epoch6, step1390]: loss 0.036469
[epoch6, step1391]: loss 0.038633
[epoch6, step1392]: loss 0.037494
[epoch6, step1393]: loss 0.037665
[epoch6, step1394]: loss 0.036580
[epoch6, step1395]: loss 0.037805
[epoch6, step1396]: loss 0.037213
[epoch6, step1397]: loss 0.038413
[epoch6, step1398]: loss 0.035988
[epoch6, step1399]: loss 0.036780
[epoch6, step1400]: loss 0.039214
[epoch6, step1401]: loss 0.037115
[epoch6, step1402]: loss 0.037382
[epoch6, step1403]: loss 0.034918
[epoch6, step1404]: loss 0.037076
[epoch6, step1405]: loss 0.037435
[epoch6, step1406]: loss 0.038651
[epoch6, step1407]: loss 0.036997
[epoch6, step1408]: loss 0.035583
[epoch6, step1409]: loss 0.038559
[epoch6, step1410]: loss 0.037207
[epoch6, step1411]: loss 0.039789
[epoch6, step1412]: loss 0.039884
[epoch6, step1413]: loss 0.037509
[epoch6, step1414]: loss 0.037209
[epoch6, step1415]: loss 0.038446
[epoch6, step1416]: loss 0.036059
[epoch6, step1417]: loss 0.035811
[epoch6, step1418]: loss 0.038965
[epoch6, step1419]: loss 0.038061
[epoch6, step1420]: loss 0.037432
[epoch6, step1421]: loss 0.036510
[epoch6, step1422]: loss 0.038101
[epoch6, step1423]: loss 0.037313
[epoch6, step1424]: loss 0.039469
[epoch6, step1425]: loss 0.035200
[epoch6, step1426]: loss 0.036157
[epoch6, step1427]: loss 0.040269
[epoch6, step1428]: loss 0.038222
[epoch6, step1429]: loss 0.037176
[epoch6, step1430]: loss 0.036047
[epoch6, step1431]: loss 0.037502
[epoch6, step1432]: loss 0.037210
[epoch6, step1433]: loss 0.038628
[epoch6, step1434]: loss 0.035510
[epoch6, step1435]: loss 0.036129
[epoch6, step1436]: loss 0.039594
[epoch6, step1437]: loss 0.037623
[epoch6, step1438]: loss 0.037951
[epoch6, step1439]: loss 0.035945
[epoch6, step1440]: loss 0.037347
[epoch6, step1441]: loss 0.038393
[epoch6, step1442]: loss 0.038415
[epoch6, step1443]: loss 0.035863
[epoch6, step1444]: loss 0.035612
[epoch6, step1445]: loss 0.039536
[epoch6, step1446]: loss 0.037493
[epoch6, step1447]: loss 0.038075
[epoch6, step1448]: loss 0.035846
[epoch6, step1449]: loss 0.036927
[epoch6, step1450]: loss 0.037556
[epoch6, step1451]: loss 0.038924
[epoch6, step1452]: loss 0.035572
[epoch6, step1453]: loss 0.036778
[epoch6, step1454]: loss 0.039176
[epoch6, step1455]: loss 0.037871
[epoch6, step1456]: loss 0.036693
[epoch6, step1457]: loss 0.036472
[epoch6, step1458]: loss 0.037566
[epoch6, step1459]: loss 0.037633
[epoch6, step1460]: loss 0.039355
[epoch6, step1461]: loss 0.036613
[epoch6, step1462]: loss 0.036766
[epoch6, step1463]: loss 0.038811
[epoch6, step1464]: loss 0.037552
[epoch6, step1465]: loss 0.036983
[epoch6, step1466]: loss 0.035439
[epoch6, step1467]: loss 0.037505
[epoch6, step1468]: loss 0.037009
[epoch6, step1469]: loss 0.038461
[epoch6, step1470]: loss 0.036057
[epoch6, step1471]: loss 0.035447
[epoch6, step1472]: loss 0.040581
[epoch6, step1473]: loss 0.037196
[epoch6, step1474]: loss 0.037687
[epoch6, step1475]: loss 0.035728
[epoch6, step1476]: loss 0.038375
[epoch6, step1477]: loss 0.037577
[epoch6, step1478]: loss 0.039098
[epoch6, step1479]: loss 0.036149
[epoch6, step1480]: loss 0.036329
[epoch6, step1481]: loss 0.037870
[epoch6, step1482]: loss 0.037484
[epoch6, step1483]: loss 0.037658
[epoch6, step1484]: loss 0.036052
[epoch6, step1485]: loss 0.037639
[epoch6, step1486]: loss 0.036718
[epoch6, step1487]: loss 0.038437
[epoch6, step1488]: loss 0.035950
[epoch6, step1489]: loss 0.035700
[epoch6, step1490]: loss 0.038742
[epoch6, step1491]: loss 0.037322
[epoch6, step1492]: loss 0.036848
[epoch6, step1493]: loss 0.035818
[epoch6, step1494]: loss 0.037545
[epoch6, step1495]: loss 0.037162
[epoch6, step1496]: loss 0.037854
[epoch6, step1497]: loss 0.036193
[epoch6, step1498]: loss 0.036354
[epoch6, step1499]: loss 0.038095
[epoch6, step1500]: loss 0.037711
[epoch6, step1501]: loss 0.037318
[epoch6, step1502]: loss 0.035435
[epoch6, step1503]: loss 0.037294
[epoch6, step1504]: loss 0.036853
[epoch6, step1505]: loss 0.038748
[epoch6, step1506]: loss 0.035219
[epoch6, step1507]: loss 0.036104
[epoch6, step1508]: loss 0.039028
[epoch6, step1509]: loss 0.036905
[epoch6, step1510]: loss 0.036482
[epoch6, step1511]: loss 0.036407
[epoch6, step1512]: loss 0.037454
[epoch6, step1513]: loss 0.036120
[epoch6, step1514]: loss 0.039014
[epoch6, step1515]: loss 0.036422
[epoch6, step1516]: loss 0.035994

[epoch6]: avg loss 0.034339

[epoch7, step1]: loss 0.033303
[epoch7, step2]: loss 0.038446
[epoch7, step3]: loss 0.038387
[epoch7, step4]: loss 0.036162
[epoch7, step5]: loss 0.035924
[epoch7, step6]: loss 0.038541
[epoch7, step7]: loss 0.036136
[epoch7, step8]: loss 0.040346
[epoch7, step9]: loss 0.037829
[epoch7, step10]: loss 0.036763
[epoch7, step11]: loss 0.038811
[epoch7, step12]: loss 0.038862
[epoch7, step13]: loss 0.036286
[epoch7, step14]: loss 0.036706
[epoch7, step15]: loss 0.039347
[epoch7, step16]: loss 0.037004
[epoch7, step17]: loss 0.039532
[epoch7, step18]: loss 0.037349
[epoch7, step19]: loss 0.037012
[epoch7, step20]: loss 0.040169
[epoch7, step21]: loss 0.039356
[epoch7, step22]: loss 0.035860
[epoch7, step23]: loss 0.035811
[epoch7, step24]: loss 0.039557
[epoch7, step25]: loss 0.036025
[epoch7, step26]: loss 0.038519
[epoch7, step27]: loss 0.035473
[epoch7, step28]: loss 0.036693
[epoch7, step29]: loss 0.038898
[epoch7, step30]: loss 0.039180
[epoch7, step31]: loss 0.035267
[epoch7, step32]: loss 0.036390
[epoch7, step33]: loss 0.039199
[epoch7, step34]: loss 0.037084
[epoch7, step35]: loss 0.039026
[epoch7, step36]: loss 0.035552
[epoch7, step37]: loss 0.036183
[epoch7, step38]: loss 0.038848
[epoch7, step39]: loss 0.038715
[epoch7, step40]: loss 0.035979
[epoch7, step41]: loss 0.035595
[epoch7, step42]: loss 0.039096
[epoch7, step43]: loss 0.036089
[epoch7, step44]: loss 0.039876
[epoch7, step45]: loss 0.036068
[epoch7, step46]: loss 0.036060
[epoch7, step47]: loss 0.038108
[epoch7, step48]: loss 0.038069
[epoch7, step49]: loss 0.034314
[epoch7, step50]: loss 0.035814
[epoch7, step51]: loss 0.038201
[epoch7, step52]: loss 0.035741
[epoch7, step53]: loss 0.038902
[epoch7, step54]: loss 0.035197
[epoch7, step55]: loss 0.036402
[epoch7, step56]: loss 0.039276
[epoch7, step57]: loss 0.038743
[epoch7, step58]: loss 0.035599
[epoch7, step59]: loss 0.034767
[epoch7, step60]: loss 0.039266
[epoch7, step61]: loss 0.035493
[epoch7, step62]: loss 0.037808
[epoch7, step63]: loss 0.035211
[epoch7, step64]: loss 0.035829
[epoch7, step65]: loss 0.038657
[epoch7, step66]: loss 0.038556
[epoch7, step67]: loss 0.035912
[epoch7, step68]: loss 0.036528
[epoch7, step69]: loss 0.038712
[epoch7, step70]: loss 0.036014
[epoch7, step71]: loss 0.038102
[epoch7, step72]: loss 0.035727
[epoch7, step73]: loss 0.036497
[epoch7, step74]: loss 0.038454
[epoch7, step75]: loss 0.038945
[epoch7, step76]: loss 0.036153
[epoch7, step77]: loss 0.036568
[epoch7, step78]: loss 0.039117
[epoch7, step79]: loss 0.035072
[epoch7, step80]: loss 0.040112
[epoch7, step81]: loss 0.036315
[epoch7, step82]: loss 0.036057
[epoch7, step83]: loss 0.038601
[epoch7, step84]: loss 0.038677
[epoch7, step85]: loss 0.036725
[epoch7, step86]: loss 0.036626
[epoch7, step87]: loss 0.039719
[epoch7, step88]: loss 0.035529
[epoch7, step89]: loss 0.039573
[epoch7, step90]: loss 0.037160
[epoch7, step91]: loss 0.036579
[epoch7, step92]: loss 0.039595
[epoch7, step93]: loss 0.039123
[epoch7, step94]: loss 0.036663
[epoch7, step95]: loss 0.037549
[epoch7, step96]: loss 0.039114
[epoch7, step97]: loss 0.037791
[epoch7, step98]: loss 0.040396
[epoch7, step99]: loss 0.036479
[epoch7, step100]: loss 0.035796
[epoch7, step101]: loss 0.040012
[epoch7, step102]: loss 0.038942
[epoch7, step103]: loss 0.036529
[epoch7, step104]: loss 0.036421
[epoch7, step105]: loss 0.039174
[epoch7, step106]: loss 0.036128
[epoch7, step107]: loss 0.038776
[epoch7, step108]: loss 0.036106
[epoch7, step109]: loss 0.035981
[epoch7, step110]: loss 0.039748
[epoch7, step111]: loss 0.038541
[epoch7, step112]: loss 0.036296
[epoch7, step113]: loss 0.037113
[epoch7, step114]: loss 0.038496
[epoch7, step115]: loss 0.036544
[epoch7, step116]: loss 0.040102
[epoch7, step117]: loss 0.035879
[epoch7, step118]: loss 0.037413
[epoch7, step119]: loss 0.039440
[epoch7, step120]: loss 0.039058
[epoch7, step121]: loss 0.036051
[epoch7, step122]: loss 0.036252
[epoch7, step123]: loss 0.039227
[epoch7, step124]: loss 0.036890
[epoch7, step125]: loss 0.039417
[epoch7, step126]: loss 0.036052
[epoch7, step127]: loss 0.036216
[epoch7, step128]: loss 0.038838
[epoch7, step129]: loss 0.038833
[epoch7, step130]: loss 0.036268
[epoch7, step131]: loss 0.035839
[epoch7, step132]: loss 0.039127
[epoch7, step133]: loss 0.036331
[epoch7, step134]: loss 0.038411
[epoch7, step135]: loss 0.036588
[epoch7, step136]: loss 0.037809
[epoch7, step137]: loss 0.038594
[epoch7, step138]: loss 0.038905
[epoch7, step139]: loss 0.036093
[epoch7, step140]: loss 0.036728
[epoch7, step141]: loss 0.039227
[epoch7, step142]: loss 0.036313
[epoch7, step143]: loss 0.038442
[epoch7, step144]: loss 0.036067
[epoch7, step145]: loss 0.036287
[epoch7, step146]: loss 0.038783
[epoch7, step147]: loss 0.040239
[epoch7, step148]: loss 0.035773
[epoch7, step149]: loss 0.035666
[epoch7, step150]: loss 0.038596
[epoch7, step151]: loss 0.036434
[epoch7, step152]: loss 0.038985
[epoch7, step153]: loss 0.036020
[epoch7, step154]: loss 0.036087
[epoch7, step155]: loss 0.038717
[epoch7, step156]: loss 0.038438
[epoch7, step157]: loss 0.035962
[epoch7, step158]: loss 0.036513
[epoch7, step159]: loss 0.039174
[epoch7, step160]: loss 0.036418
[epoch7, step161]: loss 0.039380
[epoch7, step162]: loss 0.036153
[epoch7, step163]: loss 0.036494
[epoch7, step164]: loss 0.039196
[epoch7, step165]: loss 0.038772
[epoch7, step166]: loss 0.036386
[epoch7, step167]: loss 0.035800
[epoch7, step168]: loss 0.039642
[epoch7, step169]: loss 0.036173
[epoch7, step170]: loss 0.039267
[epoch7, step171]: loss 0.036421
[epoch7, step172]: loss 0.036605
[epoch7, step173]: loss 0.039189
[epoch7, step174]: loss 0.038666
[epoch7, step175]: loss 0.036558
[epoch7, step176]: loss 0.036513
[epoch7, step177]: loss 0.039159
[epoch7, step178]: loss 0.036514
[epoch7, step179]: loss 0.038261
[epoch7, step180]: loss 0.036171
[epoch7, step181]: loss 0.036574
[epoch7, step182]: loss 0.039195
[epoch7, step183]: loss 0.039507
[epoch7, step184]: loss 0.037073
[epoch7, step185]: loss 0.036346
[epoch7, step186]: loss 0.039069
[epoch7, step187]: loss 0.036471
[epoch7, step188]: loss 0.038640
[epoch7, step189]: loss 0.035924
[epoch7, step190]: loss 0.035727
[epoch7, step191]: loss 0.038755
[epoch7, step192]: loss 0.039411
[epoch7, step193]: loss 0.034121
[epoch7, step194]: loss 0.035420
[epoch7, step195]: loss 0.039164
[epoch7, step196]: loss 0.036546
[epoch7, step197]: loss 0.038909
[epoch7, step198]: loss 0.035056
[epoch7, step199]: loss 0.036513
[epoch7, step200]: loss 0.039336
[epoch7, step201]: loss 0.039268
[epoch7, step202]: loss 0.035725
[epoch7, step203]: loss 0.036125
[epoch7, step204]: loss 0.039340
[epoch7, step205]: loss 0.035770
[epoch7, step206]: loss 0.038516
[epoch7, step207]: loss 0.035830
[epoch7, step208]: loss 0.036770
[epoch7, step209]: loss 0.039057
[epoch7, step210]: loss 0.039782
[epoch7, step211]: loss 0.036575
[epoch7, step212]: loss 0.036673
[epoch7, step213]: loss 0.038560
[epoch7, step214]: loss 0.035726
[epoch7, step215]: loss 0.039412
[epoch7, step216]: loss 0.036149
[epoch7, step217]: loss 0.035620
[epoch7, step218]: loss 0.039246
[epoch7, step219]: loss 0.038628
[epoch7, step220]: loss 0.036399
[epoch7, step221]: loss 0.036338
[epoch7, step222]: loss 0.039226
[epoch7, step223]: loss 0.036374
[epoch7, step224]: loss 0.038384
[epoch7, step225]: loss 0.035859
[epoch7, step226]: loss 0.036007
[epoch7, step227]: loss 0.037845
[epoch7, step228]: loss 0.039468
[epoch7, step229]: loss 0.035175
[epoch7, step230]: loss 0.036537
[epoch7, step231]: loss 0.039354
[epoch7, step232]: loss 0.036087
[epoch7, step233]: loss 0.038430
[epoch7, step234]: loss 0.035366
[epoch7, step235]: loss 0.036673
[epoch7, step236]: loss 0.038924
[epoch7, step237]: loss 0.038716
[epoch7, step238]: loss 0.035808
[epoch7, step239]: loss 0.035337
[epoch7, step240]: loss 0.038300
[epoch7, step241]: loss 0.036644
[epoch7, step242]: loss 0.038658
[epoch7, step243]: loss 0.036652
[epoch7, step244]: loss 0.036170
[epoch7, step245]: loss 0.038343
[epoch7, step246]: loss 0.038944
[epoch7, step247]: loss 0.036245
[epoch7, step248]: loss 0.035808
[epoch7, step249]: loss 0.038486
[epoch7, step250]: loss 0.036457
[epoch7, step251]: loss 0.039425
[epoch7, step252]: loss 0.036461
[epoch7, step253]: loss 0.035869
[epoch7, step254]: loss 0.038527
[epoch7, step255]: loss 0.038771
[epoch7, step256]: loss 0.035691
[epoch7, step257]: loss 0.035835
[epoch7, step258]: loss 0.039454
[epoch7, step259]: loss 0.036368
[epoch7, step260]: loss 0.038224
[epoch7, step261]: loss 0.036844
[epoch7, step262]: loss 0.036831
[epoch7, step263]: loss 0.038164
[epoch7, step264]: loss 0.038770
[epoch7, step265]: loss 0.036362
[epoch7, step266]: loss 0.036020
[epoch7, step267]: loss 0.038169
[epoch7, step268]: loss 0.036034
[epoch7, step269]: loss 0.038830
[epoch7, step270]: loss 0.035433
[epoch7, step271]: loss 0.036334
[epoch7, step272]: loss 0.038683
[epoch7, step273]: loss 0.038531
[epoch7, step274]: loss 0.036420
[epoch7, step275]: loss 0.035654
[epoch7, step276]: loss 0.038581
[epoch7, step277]: loss 0.036752
[epoch7, step278]: loss 0.038986
[epoch7, step279]: loss 0.035470
[epoch7, step280]: loss 0.036382
[epoch7, step281]: loss 0.038605
[epoch7, step282]: loss 0.039357
[epoch7, step283]: loss 0.035496
[epoch7, step284]: loss 0.035580
[epoch7, step285]: loss 0.039710
[epoch7, step286]: loss 0.035526
[epoch7, step287]: loss 0.039141
[epoch7, step288]: loss 0.035518
[epoch7, step289]: loss 0.036983
[epoch7, step290]: loss 0.038810
[epoch7, step291]: loss 0.038934
[epoch7, step292]: loss 0.035188
[epoch7, step293]: loss 0.035672
[epoch7, step294]: loss 0.038256
[epoch7, step295]: loss 0.035676
[epoch7, step296]: loss 0.039638
[epoch7, step297]: loss 0.035526
[epoch7, step298]: loss 0.036538
[epoch7, step299]: loss 0.037755
[epoch7, step300]: loss 0.039015
[epoch7, step301]: loss 0.035911
[epoch7, step302]: loss 0.036471
[epoch7, step303]: loss 0.039268
[epoch7, step304]: loss 0.035834
[epoch7, step305]: loss 0.038514
[epoch7, step306]: loss 0.035902
[epoch7, step307]: loss 0.035916
[epoch7, step308]: loss 0.039180
[epoch7, step309]: loss 0.039161
[epoch7, step310]: loss 0.036067
[epoch7, step311]: loss 0.036482
[epoch7, step312]: loss 0.038488
[epoch7, step313]: loss 0.036404
[epoch7, step314]: loss 0.038670
[epoch7, step315]: loss 0.036854
[epoch7, step316]: loss 0.036034
[epoch7, step317]: loss 0.039137
[epoch7, step318]: loss 0.038807
[epoch7, step319]: loss 0.035408
[epoch7, step320]: loss 0.035110
[epoch7, step321]: loss 0.038422
[epoch7, step322]: loss 0.036018
[epoch7, step323]: loss 0.038110
[epoch7, step324]: loss 0.036733
[epoch7, step325]: loss 0.036405
[epoch7, step326]: loss 0.038380
[epoch7, step327]: loss 0.038060
[epoch7, step328]: loss 0.036134
[epoch7, step329]: loss 0.035774
[epoch7, step330]: loss 0.038326
[epoch7, step331]: loss 0.036251
[epoch7, step332]: loss 0.038189
[epoch7, step333]: loss 0.035776
[epoch7, step334]: loss 0.036234
[epoch7, step335]: loss 0.038784
[epoch7, step336]: loss 0.039519
[epoch7, step337]: loss 0.036408
[epoch7, step338]: loss 0.035579
[epoch7, step339]: loss 0.038786
[epoch7, step340]: loss 0.036632
[epoch7, step341]: loss 0.038164
[epoch7, step342]: loss 0.035581
[epoch7, step343]: loss 0.036352
[epoch7, step344]: loss 0.038131
[epoch7, step345]: loss 0.037971
[epoch7, step346]: loss 0.035511
[epoch7, step347]: loss 0.035667
[epoch7, step348]: loss 0.038982
[epoch7, step349]: loss 0.036635
[epoch7, step350]: loss 0.038221
[epoch7, step351]: loss 0.035050
[epoch7, step352]: loss 0.035918
[epoch7, step353]: loss 0.038437
[epoch7, step354]: loss 0.037767
[epoch7, step355]: loss 0.034747
[epoch7, step356]: loss 0.036638
[epoch7, step357]: loss 0.038705
[epoch7, step358]: loss 0.034736
[epoch7, step359]: loss 0.039596
[epoch7, step360]: loss 0.034684
[epoch7, step361]: loss 0.035661
[epoch7, step362]: loss 0.039215
[epoch7, step363]: loss 0.038337
[epoch7, step364]: loss 0.035686
[epoch7, step365]: loss 0.035755
[epoch7, step366]: loss 0.039160
[epoch7, step367]: loss 0.036137
[epoch7, step368]: loss 0.038042
[epoch7, step369]: loss 0.035651
[epoch7, step370]: loss 0.036650
[epoch7, step371]: loss 0.039461
[epoch7, step372]: loss 0.038224
[epoch7, step373]: loss 0.035316
[epoch7, step374]: loss 0.035181
[epoch7, step375]: loss 0.039262
[epoch7, step376]: loss 0.036148
[epoch7, step377]: loss 0.038771
[epoch7, step378]: loss 0.036285
[epoch7, step379]: loss 0.036650
[epoch7, step380]: loss 0.039135
[epoch7, step381]: loss 0.038306
[epoch7, step382]: loss 0.035999
[epoch7, step383]: loss 0.035017
[epoch7, step384]: loss 0.037894
[epoch7, step385]: loss 0.035963
[epoch7, step386]: loss 0.038690
[epoch7, step387]: loss 0.035777
[epoch7, step388]: loss 0.036905
[epoch7, step389]: loss 0.038518
[epoch7, step390]: loss 0.039731
[epoch7, step391]: loss 0.035372
[epoch7, step392]: loss 0.036606
[epoch7, step393]: loss 0.038435
[epoch7, step394]: loss 0.036024
[epoch7, step395]: loss 0.038450
[epoch7, step396]: loss 0.035765
[epoch7, step397]: loss 0.035716
[epoch7, step398]: loss 0.038842
[epoch7, step399]: loss 0.038434
[epoch7, step400]: loss 0.035486
[epoch7, step401]: loss 0.035636
[epoch7, step402]: loss 0.038392
[epoch7, step403]: loss 0.036022
[epoch7, step404]: loss 0.038877
[epoch7, step405]: loss 0.036255
[epoch7, step406]: loss 0.036479
[epoch7, step407]: loss 0.038440
[epoch7, step408]: loss 0.038843
[epoch7, step409]: loss 0.037231
[epoch7, step410]: loss 0.036551
[epoch7, step411]: loss 0.038611
[epoch7, step412]: loss 0.035489
[epoch7, step413]: loss 0.038634
[epoch7, step414]: loss 0.035462
[epoch7, step415]: loss 0.036234
[epoch7, step416]: loss 0.037903
[epoch7, step417]: loss 0.038775
[epoch7, step418]: loss 0.035759
[epoch7, step419]: loss 0.035127
[epoch7, step420]: loss 0.038797
[epoch7, step421]: loss 0.035868
[epoch7, step422]: loss 0.038464
[epoch7, step423]: loss 0.035882
[epoch7, step424]: loss 0.036189
[epoch7, step425]: loss 0.038668
[epoch7, step426]: loss 0.039003
[epoch7, step427]: loss 0.036143
[epoch7, step428]: loss 0.035912
[epoch7, step429]: loss 0.039285
[epoch7, step430]: loss 0.035866
[epoch7, step431]: loss 0.038831
[epoch7, step432]: loss 0.035636
[epoch7, step433]: loss 0.036901
[epoch7, step434]: loss 0.038564
[epoch7, step435]: loss 0.039016
[epoch7, step436]: loss 0.035703
[epoch7, step437]: loss 0.036076
[epoch7, step438]: loss 0.039102
[epoch7, step439]: loss 0.036348
[epoch7, step440]: loss 0.038509
[epoch7, step441]: loss 0.036047
[epoch7, step442]: loss 0.036081
[epoch7, step443]: loss 0.039048
[epoch7, step444]: loss 0.038347
[epoch7, step445]: loss 0.036273
[epoch7, step446]: loss 0.036385
[epoch7, step447]: loss 0.039613
[epoch7, step448]: loss 0.036069
[epoch7, step449]: loss 0.038480
[epoch7, step450]: loss 0.035445
[epoch7, step451]: loss 0.035808
[epoch7, step452]: loss 0.037771
[epoch7, step453]: loss 0.038502
[epoch7, step454]: loss 0.035576
[epoch7, step455]: loss 0.035986
[epoch7, step456]: loss 0.037877
[epoch7, step457]: loss 0.036562
[epoch7, step458]: loss 0.037924
[epoch7, step459]: loss 0.036514
[epoch7, step460]: loss 0.036323
[epoch7, step461]: loss 0.039183
[epoch7, step462]: loss 0.038059
[epoch7, step463]: loss 0.035658
[epoch7, step464]: loss 0.036026
[epoch7, step465]: loss 0.040038
[epoch7, step466]: loss 0.036143
[epoch7, step467]: loss 0.038544
[epoch7, step468]: loss 0.035904
[epoch7, step469]: loss 0.036199
[epoch7, step470]: loss 0.038747
[epoch7, step471]: loss 0.038026
[epoch7, step472]: loss 0.036272
[epoch7, step473]: loss 0.035295
[epoch7, step474]: loss 0.038304
[epoch7, step475]: loss 0.036091
[epoch7, step476]: loss 0.038843
[epoch7, step477]: loss 0.035926
[epoch7, step478]: loss 0.035485
[epoch7, step479]: loss 0.038374
[epoch7, step480]: loss 0.037888
[epoch7, step481]: loss 0.035396
[epoch7, step482]: loss 0.035211
[epoch7, step483]: loss 0.039319
[epoch7, step484]: loss 0.036139
[epoch7, step485]: loss 0.039184
[epoch7, step486]: loss 0.036438
[epoch7, step487]: loss 0.035279
[epoch7, step488]: loss 0.038974
[epoch7, step489]: loss 0.037518
[epoch7, step490]: loss 0.036077
[epoch7, step491]: loss 0.036109
[epoch7, step492]: loss 0.038151
[epoch7, step493]: loss 0.035753
[epoch7, step494]: loss 0.037750
[epoch7, step495]: loss 0.037057
[epoch7, step496]: loss 0.036338
[epoch7, step497]: loss 0.038787
[epoch7, step498]: loss 0.038350
[epoch7, step499]: loss 0.035878
[epoch7, step500]: loss 0.035161
[epoch7, step501]: loss 0.037861
[epoch7, step502]: loss 0.037121
[epoch7, step503]: loss 0.040195
[epoch7, step504]: loss 0.038346
[epoch7, step505]: loss 0.037871
[epoch7, step506]: loss 0.039664
[epoch7, step507]: loss 0.038320
[epoch7, step508]: loss 0.041147
[epoch7, step509]: loss 0.039063
[epoch7, step510]: loss 0.039912
[epoch7, step511]: loss 0.036636
[epoch7, step512]: loss 0.038624
[epoch7, step513]: loss 0.035419
[epoch7, step514]: loss 0.036151
[epoch7, step515]: loss 0.038941
[epoch7, step516]: loss 0.040595
[epoch7, step517]: loss 0.037072
[epoch7, step518]: loss 0.035906
[epoch7, step519]: loss 0.037670
[epoch7, step520]: loss 0.034620
[epoch7, step521]: loss 0.040588
[epoch7, step522]: loss 0.034387
[epoch7, step523]: loss 0.036487
[epoch7, step524]: loss 0.038043
[epoch7, step525]: loss 0.038461
[epoch7, step526]: loss 0.035348
[epoch7, step527]: loss 0.034460
[epoch7, step528]: loss 0.041765
[epoch7, step529]: loss 0.035143
[epoch7, step530]: loss 0.038905
[epoch7, step531]: loss 0.035771
[epoch7, step532]: loss 0.035323
[epoch7, step533]: loss 0.039148
[epoch7, step534]: loss 0.038357
[epoch7, step535]: loss 0.035542
[epoch7, step536]: loss 0.035213
[epoch7, step537]: loss 0.038411
[epoch7, step538]: loss 0.035455
[epoch7, step539]: loss 0.037463
[epoch7, step540]: loss 0.036482
[epoch7, step541]: loss 0.034783
[epoch7, step542]: loss 0.038453
[epoch7, step543]: loss 0.037552
[epoch7, step544]: loss 0.034444
[epoch7, step545]: loss 0.034443
[epoch7, step546]: loss 0.037676
[epoch7, step547]: loss 0.034730
[epoch7, step548]: loss 0.037454
[epoch7, step549]: loss 0.036948
[epoch7, step550]: loss 0.040240
[epoch7, step551]: loss 0.040300
[epoch7, step552]: loss 0.039256
[epoch7, step553]: loss 0.041125
[epoch7, step554]: loss 0.035504
[epoch7, step555]: loss 0.038248
[epoch7, step556]: loss 0.034463
[epoch7, step557]: loss 0.037206
[epoch7, step558]: loss 0.035934
[epoch7, step559]: loss 0.035871
[epoch7, step560]: loss 0.038625
[epoch7, step561]: loss 0.037382
[epoch7, step562]: loss 0.034438
[epoch7, step563]: loss 0.032042
[epoch7, step564]: loss 0.030879
[epoch7, step565]: loss 0.028518
[epoch7, step566]: loss 0.035943
[epoch7, step567]: loss 0.028313
[epoch7, step568]: loss 0.027190
[epoch7, step569]: loss 0.025351
[epoch7, step570]: loss 0.032190
[epoch7, step571]: loss 0.024952
[epoch7, step572]: loss 0.025405
[epoch7, step573]: loss 0.029368
[epoch7, step574]: loss 0.026961
[epoch7, step575]: loss 0.020636
[epoch7, step576]: loss 0.021475
[epoch7, step577]: loss 0.025303
[epoch7, step578]: loss 0.018527
[epoch7, step579]: loss 0.028350
[epoch7, step580]: loss 0.020137
[epoch7, step581]: loss 0.025733
[epoch7, step582]: loss 0.025476
[epoch7, step583]: loss 0.022070
[epoch7, step584]: loss 0.023647
[epoch7, step585]: loss 0.026184
[epoch7, step586]: loss 0.021630
[epoch7, step587]: loss 0.027682
[epoch7, step588]: loss 0.023004
[epoch7, step589]: loss 0.022787
[epoch7, step590]: loss 0.027308
[epoch7, step591]: loss 0.020480
[epoch7, step592]: loss 0.025792
[epoch7, step593]: loss 0.022141
[epoch7, step594]: loss 0.025707
[epoch7, step595]: loss 0.026218
[epoch7, step596]: loss 0.022099
[epoch7, step597]: loss 0.024723
[epoch7, step598]: loss 0.026529
[epoch7, step599]: loss 0.025036
[epoch7, step600]: loss 0.026704
[epoch7, step601]: loss 0.019498
[epoch7, step602]: loss 0.022485
[epoch7, step603]: loss 0.025461
[epoch7, step604]: loss 0.026224
[epoch7, step605]: loss 0.025113
[epoch7, step606]: loss 0.024929
[epoch7, step607]: loss 0.026673
[epoch7, step608]: loss 0.025553
[epoch7, step609]: loss 0.026370
[epoch7, step610]: loss 0.026163
[epoch7, step611]: loss 0.026189
[epoch7, step612]: loss 0.025412
[epoch7, step613]: loss 0.019135
[epoch7, step614]: loss 0.025127
[epoch7, step615]: loss 0.027957
[epoch7, step616]: loss 0.023810
[epoch7, step617]: loss 0.023377
[epoch7, step618]: loss 0.025771
[epoch7, step619]: loss 0.026711
[epoch7, step620]: loss 0.024079
[epoch7, step621]: loss 0.025958
[epoch7, step622]: loss 0.020351
[epoch7, step623]: loss 0.024537
[epoch7, step624]: loss 0.026050
[epoch7, step625]: loss 0.025654
[epoch7, step626]: loss 0.027945
[epoch7, step627]: loss 0.022632
[epoch7, step628]: loss 0.025188
[epoch7, step629]: loss 0.020653
[epoch7, step630]: loss 0.023331
[epoch7, step631]: loss 0.031082
[epoch7, step632]: loss 0.023264
[epoch7, step633]: loss 0.024578
[epoch7, step634]: loss 0.026948
[epoch7, step635]: loss 0.025514
[epoch7, step636]: loss 0.020583
[epoch7, step637]: loss 0.027103
[epoch7, step638]: loss 0.026662
[epoch7, step639]: loss 0.022823
[epoch7, step640]: loss 0.028902
[epoch7, step641]: loss 0.029937
[epoch7, step642]: loss 0.024730
[epoch7, step643]: loss 0.025659
[epoch7, step644]: loss 0.025705
[epoch7, step645]: loss 0.023604
[epoch7, step646]: loss 0.025986
[epoch7, step647]: loss 0.023611
[epoch7, step648]: loss 0.022845
[epoch7, step649]: loss 0.028198
[epoch7, step650]: loss 0.021876
[epoch7, step651]: loss 0.025829
[epoch7, step652]: loss 0.026664
[epoch7, step653]: loss 0.027521
[epoch7, step654]: loss 0.022876
[epoch7, step655]: loss 0.024298
[epoch7, step656]: loss 0.021386
[epoch7, step657]: loss 0.027305
[epoch7, step658]: loss 0.024957
[epoch7, step659]: loss 0.027532
[epoch7, step660]: loss 0.023885
[epoch7, step661]: loss 0.026330
[epoch7, step662]: loss 0.023848
[epoch7, step663]: loss 0.020787
[epoch7, step664]: loss 0.025083
[epoch7, step665]: loss 0.027729
[epoch7, step666]: loss 0.026587
[epoch7, step667]: loss 0.026648
[epoch7, step668]: loss 0.021995
[epoch7, step669]: loss 0.026493
[epoch7, step670]: loss 0.026477
[epoch7, step671]: loss 0.021129
[epoch7, step672]: loss 0.023636
[epoch7, step673]: loss 0.022058
[epoch7, step674]: loss 0.021045
[epoch7, step675]: loss 0.020169
[epoch7, step676]: loss 0.024360
[epoch7, step677]: loss 0.025268
[epoch7, step678]: loss 0.022960
[epoch7, step679]: loss 0.023850
[epoch7, step680]: loss 0.030297
[epoch7, step681]: loss 0.021855
[epoch7, step682]: loss 0.026111
[epoch7, step683]: loss 0.025912
[epoch7, step684]: loss 0.024538
[epoch7, step685]: loss 0.024129
[epoch7, step686]: loss 0.027300
[epoch7, step687]: loss 0.026487
[epoch7, step688]: loss 0.022245
[epoch7, step689]: loss 0.024435
[epoch7, step690]: loss 0.024800
[epoch7, step691]: loss 0.024325
[epoch7, step692]: loss 0.022541
[epoch7, step693]: loss 0.026739
[epoch7, step694]: loss 0.022742
[epoch7, step695]: loss 0.026511
[epoch7, step696]: loss 0.025752
[epoch7, step697]: loss 0.026716
[epoch7, step698]: loss 0.024590
[epoch7, step699]: loss 0.023456
[epoch7, step700]: loss 0.021517
[epoch7, step701]: loss 0.025619
[epoch7, step702]: loss 0.021618
[epoch7, step703]: loss 0.022734
[epoch7, step704]: loss 0.024853
[epoch7, step705]: loss 0.024844
[epoch7, step706]: loss 0.023826
[epoch7, step707]: loss 0.024477
[epoch7, step708]: loss 0.025926
[epoch7, step709]: loss 0.027337
[epoch7, step710]: loss 0.023350
[epoch7, step711]: loss 0.023345
[epoch7, step712]: loss 0.026526
[epoch7, step713]: loss 0.026191
[epoch7, step714]: loss 0.021175
[epoch7, step715]: loss 0.023278
[epoch7, step716]: loss 0.025463
[epoch7, step717]: loss 0.023321
[epoch7, step718]: loss 0.024875
[epoch7, step719]: loss 0.032774
[epoch7, step720]: loss 0.024401
[epoch7, step721]: loss 0.023096
[epoch7, step722]: loss 0.030586
[epoch7, step723]: loss 0.025618
[epoch7, step724]: loss 0.022981
[epoch7, step725]: loss 0.027659
[epoch7, step726]: loss 0.022488
[epoch7, step727]: loss 0.024647
[epoch7, step728]: loss 0.026475
[epoch7, step729]: loss 0.021058
[epoch7, step730]: loss 0.022609
[epoch7, step731]: loss 0.025553
[epoch7, step732]: loss 0.025538
[epoch7, step733]: loss 0.023733
[epoch7, step734]: loss 0.022775
[epoch7, step735]: loss 0.027713
[epoch7, step736]: loss 0.024861
[epoch7, step737]: loss 0.026701
[epoch7, step738]: loss 0.020492
[epoch7, step739]: loss 0.025394
[epoch7, step740]: loss 0.022290
[epoch7, step741]: loss 0.025048
[epoch7, step742]: loss 0.021784
[epoch7, step743]: loss 0.023336
[epoch7, step744]: loss 0.023962
[epoch7, step745]: loss 0.024569
[epoch7, step746]: loss 0.024825
[epoch7, step747]: loss 0.027125
[epoch7, step748]: loss 0.025245
[epoch7, step749]: loss 0.025976
[epoch7, step750]: loss 0.027271
[epoch7, step751]: loss 0.021576
[epoch7, step752]: loss 0.025057
[epoch7, step753]: loss 0.025619
[epoch7, step754]: loss 0.022607
[epoch7, step755]: loss 0.025894
[epoch7, step756]: loss 0.023557
[epoch7, step757]: loss 0.020476
[epoch7, step758]: loss 0.025366
[epoch7, step759]: loss 0.022610
[epoch7, step760]: loss 0.023747
[epoch7, step761]: loss 0.026195
[epoch7, step762]: loss 0.021589
[epoch7, step763]: loss 0.025398
[epoch7, step764]: loss 0.023395
[epoch7, step765]: loss 0.025702
[epoch7, step766]: loss 0.024404
[epoch7, step767]: loss 0.026365
[epoch7, step768]: loss 0.021414
[epoch7, step769]: loss 0.026312
[epoch7, step770]: loss 0.025750
[epoch7, step771]: loss 0.023173
[epoch7, step772]: loss 0.028515
[epoch7, step773]: loss 0.026260
[epoch7, step774]: loss 0.024192
[epoch7, step775]: loss 0.020594
[epoch7, step776]: loss 0.025402
[epoch7, step777]: loss 0.022938
[epoch7, step778]: loss 0.027885
[epoch7, step779]: loss 0.023763
[epoch7, step780]: loss 0.020124
[epoch7, step781]: loss 0.024148
[epoch7, step782]: loss 0.022470
[epoch7, step783]: loss 0.019036
[epoch7, step784]: loss 0.020042
[epoch7, step785]: loss 0.021447
[epoch7, step786]: loss 0.024109
[epoch7, step787]: loss 0.023052
[epoch7, step788]: loss 0.024605
[epoch7, step789]: loss 0.022306
[epoch7, step790]: loss 0.023305
[epoch7, step791]: loss 0.026737
[epoch7, step792]: loss 0.025090
[epoch7, step793]: loss 0.026796
[epoch7, step794]: loss 0.020346
[epoch7, step795]: loss 0.025502
[epoch7, step796]: loss 0.027580
[epoch7, step797]: loss 0.027611
[epoch7, step798]: loss 0.027162
[epoch7, step799]: loss 0.025780
[epoch7, step800]: loss 0.021179
[epoch7, step801]: loss 0.021361
[epoch7, step802]: loss 0.022413
[epoch7, step803]: loss 0.025996
[epoch7, step804]: loss 0.027258
[epoch7, step805]: loss 0.027954
[epoch7, step806]: loss 0.021319
[epoch7, step807]: loss 0.020601
[epoch7, step808]: loss 0.022812
[epoch7, step809]: loss 0.022787
[epoch7, step810]: loss 0.025891
[epoch7, step811]: loss 0.025625
[epoch7, step812]: loss 0.024165
[epoch7, step813]: loss 0.023444
[epoch7, step814]: loss 0.025031
[epoch7, step815]: loss 0.024766
[epoch7, step816]: loss 0.024113
[epoch7, step817]: loss 0.024578
[epoch7, step818]: loss 0.022263
[epoch7, step819]: loss 0.019775
[epoch7, step820]: loss 0.023208
[epoch7, step821]: loss 0.021595
[epoch7, step822]: loss 0.030393
[epoch7, step823]: loss 0.023721
[epoch7, step824]: loss 0.026531
[epoch7, step825]: loss 0.024910
[epoch7, step826]: loss 0.024376
[epoch7, step827]: loss 0.026684
[epoch7, step828]: loss 0.028632
[epoch7, step829]: loss 0.025928
[epoch7, step830]: loss 0.022452
[epoch7, step831]: loss 0.026275
[epoch7, step832]: loss 0.020887
[epoch7, step833]: loss 0.029117
[epoch7, step834]: loss 0.025084
[epoch7, step835]: loss 0.020499
[epoch7, step836]: loss 0.026550
[epoch7, step837]: loss 0.025004
[epoch7, step838]: loss 0.026165
[epoch7, step839]: loss 0.028001
[epoch7, step840]: loss 0.020677
[epoch7, step841]: loss 0.024212
[epoch7, step842]: loss 0.027405
[epoch7, step843]: loss 0.024749
[epoch7, step844]: loss 0.024711
[epoch7, step845]: loss 0.020988
[epoch7, step846]: loss 0.025505
[epoch7, step847]: loss 0.026546
[epoch7, step848]: loss 0.024857
[epoch7, step849]: loss 0.025091
[epoch7, step850]: loss 0.022736
[epoch7, step851]: loss 0.023704
[epoch7, step852]: loss 0.023206
[epoch7, step853]: loss 0.029185
[epoch7, step854]: loss 0.022602
[epoch7, step855]: loss 0.027117
[epoch7, step856]: loss 0.022137
[epoch7, step857]: loss 0.025612
[epoch7, step858]: loss 0.024257
[epoch7, step859]: loss 0.023485
[epoch7, step860]: loss 0.022594
[epoch7, step861]: loss 0.022953
[epoch7, step862]: loss 0.022877
[epoch7, step863]: loss 0.020453
[epoch7, step864]: loss 0.026532
[epoch7, step865]: loss 0.023386
[epoch7, step866]: loss 0.025004
[epoch7, step867]: loss 0.026127
[epoch7, step868]: loss 0.026347
[epoch7, step869]: loss 0.023843
[epoch7, step870]: loss 0.030794
[epoch7, step871]: loss 0.022134
[epoch7, step872]: loss 0.025104
[epoch7, step873]: loss 0.025677
[epoch7, step874]: loss 0.023726
[epoch7, step875]: loss 0.024171
[epoch7, step876]: loss 0.023990
[epoch7, step877]: loss 0.019095
[epoch7, step878]: loss 0.023125
[epoch7, step879]: loss 0.027504
[epoch7, step880]: loss 0.025393
[epoch7, step881]: loss 0.022129
[epoch7, step882]: loss 0.023814
[epoch7, step883]: loss 0.023893
[epoch7, step884]: loss 0.026198
[epoch7, step885]: loss 0.025832
[epoch7, step886]: loss 0.026351
[epoch7, step887]: loss 0.023898
[epoch7, step888]: loss 0.024315
[epoch7, step889]: loss 0.023445
[epoch7, step890]: loss 0.023386
[epoch7, step891]: loss 0.025403
[epoch7, step892]: loss 0.020796
[epoch7, step893]: loss 0.024634
[epoch7, step894]: loss 0.025091
[epoch7, step895]: loss 0.022419
[epoch7, step896]: loss 0.021685
[epoch7, step897]: loss 0.023695
[epoch7, step898]: loss 0.025242
[epoch7, step899]: loss 0.027721
[epoch7, step900]: loss 0.027072
[epoch7, step901]: loss 0.025093
[epoch7, step902]: loss 0.023895
[epoch7, step903]: loss 0.024127
[epoch7, step904]: loss 0.027962
[epoch7, step905]: loss 0.027768
[epoch7, step906]: loss 0.022047
[epoch7, step907]: loss 0.023455
[epoch7, step908]: loss 0.022213
[epoch7, step909]: loss 0.025196
[epoch7, step910]: loss 0.022913
[epoch7, step911]: loss 0.025255
[epoch7, step912]: loss 0.024113
[epoch7, step913]: loss 0.023662
[epoch7, step914]: loss 0.030045
[epoch7, step915]: loss 0.023885
[epoch7, step916]: loss 0.023584
[epoch7, step917]: loss 0.025020
[epoch7, step918]: loss 0.028244
[epoch7, step919]: loss 0.024063
[epoch7, step920]: loss 0.027466
[epoch7, step921]: loss 0.024359
[epoch7, step922]: loss 0.022987
[epoch7, step923]: loss 0.022327
[epoch7, step924]: loss 0.021225
[epoch7, step925]: loss 0.025391
[epoch7, step926]: loss 0.026440
[epoch7, step927]: loss 0.025496
[epoch7, step928]: loss 0.024654
[epoch7, step929]: loss 0.027652
[epoch7, step930]: loss 0.025594
[epoch7, step931]: loss 0.026875
[epoch7, step932]: loss 0.021536
[epoch7, step933]: loss 0.027901
[epoch7, step934]: loss 0.021945
[epoch7, step935]: loss 0.022022
[epoch7, step936]: loss 0.022330
[epoch7, step937]: loss 0.027023
[epoch7, step938]: loss 0.024786
[epoch7, step939]: loss 0.020564
[epoch7, step940]: loss 0.022714
[epoch7, step941]: loss 0.026767
[epoch7, step942]: loss 0.025444
[epoch7, step943]: loss 0.022921
[epoch7, step944]: loss 0.027511
[epoch7, step945]: loss 0.020401
[epoch7, step946]: loss 0.025377
[epoch7, step947]: loss 0.027960
[epoch7, step948]: loss 0.019432
[epoch7, step949]: loss 0.022658
[epoch7, step950]: loss 0.026526
[epoch7, step951]: loss 0.028550
[epoch7, step952]: loss 0.025037
[epoch7, step953]: loss 0.027514
[epoch7, step954]: loss 0.022158
[epoch7, step955]: loss 0.036410
[epoch7, step956]: loss 0.051409
[epoch7, step957]: loss 0.046077
[epoch7, step958]: loss 0.043624
[epoch7, step959]: loss 0.047106
[epoch7, step960]: loss 0.043232
[epoch7, step961]: loss 0.042974
[epoch7, step962]: loss 0.040049
[epoch7, step963]: loss 0.039297
[epoch7, step964]: loss 0.040637
[epoch7, step965]: loss 0.041485
[epoch7, step966]: loss 0.039525
[epoch7, step967]: loss 0.038189
[epoch7, step968]: loss 0.039403
[epoch7, step969]: loss 0.039560
[epoch7, step970]: loss 0.040458
[epoch7, step971]: loss 0.039019
[epoch7, step972]: loss 0.039474
[epoch7, step973]: loss 0.038186
[epoch7, step974]: loss 0.040169
[epoch7, step975]: loss 0.037537
[epoch7, step976]: loss 0.037263
[epoch7, step977]: loss 0.040873
[epoch7, step978]: loss 0.038692
[epoch7, step979]: loss 0.037553
[epoch7, step980]: loss 0.036398
[epoch7, step981]: loss 0.038161
[epoch7, step982]: loss 0.038679
[epoch7, step983]: loss 0.039586
[epoch7, step984]: loss 0.036065
[epoch7, step985]: loss 0.036800
[epoch7, step986]: loss 0.040724
[epoch7, step987]: loss 0.038804
[epoch7, step988]: loss 0.038323
[epoch7, step989]: loss 0.037184
[epoch7, step990]: loss 0.037826
[epoch7, step991]: loss 0.039136
[epoch7, step992]: loss 0.039329
[epoch7, step993]: loss 0.036524
[epoch7, step994]: loss 0.035953
[epoch7, step995]: loss 0.039836
[epoch7, step996]: loss 0.037770
[epoch7, step997]: loss 0.037771
[epoch7, step998]: loss 0.037141
[epoch7, step999]: loss 0.038001
[epoch7, step1000]: loss 0.038374
[epoch7, step1001]: loss 0.039024
[epoch7, step1002]: loss 0.036884
[epoch7, step1003]: loss 0.036238
[epoch7, step1004]: loss 0.039693
[epoch7, step1005]: loss 0.037300
[epoch7, step1006]: loss 0.037743
[epoch7, step1007]: loss 0.035963
[epoch7, step1008]: loss 0.037330
[epoch7, step1009]: loss 0.037818
[epoch7, step1010]: loss 0.039446
[epoch7, step1011]: loss 0.036405
[epoch7, step1012]: loss 0.036493
[epoch7, step1013]: loss 0.039473
[epoch7, step1014]: loss 0.038514
[epoch7, step1015]: loss 0.037930
[epoch7, step1016]: loss 0.035936
[epoch7, step1017]: loss 0.037431
[epoch7, step1018]: loss 0.037612
[epoch7, step1019]: loss 0.038871
[epoch7, step1020]: loss 0.035902
[epoch7, step1021]: loss 0.035499
[epoch7, step1022]: loss 0.038930
[epoch7, step1023]: loss 0.037588
[epoch7, step1024]: loss 0.037949
[epoch7, step1025]: loss 0.035464
[epoch7, step1026]: loss 0.036916
[epoch7, step1027]: loss 0.037286
[epoch7, step1028]: loss 0.038699
[epoch7, step1029]: loss 0.035846
[epoch7, step1030]: loss 0.035327
[epoch7, step1031]: loss 0.037815
[epoch7, step1032]: loss 0.037961
[epoch7, step1033]: loss 0.037016
[epoch7, step1034]: loss 0.035650
[epoch7, step1035]: loss 0.036888
[epoch7, step1036]: loss 0.037713
[epoch7, step1037]: loss 0.038400
[epoch7, step1038]: loss 0.035934
[epoch7, step1039]: loss 0.035906
[epoch7, step1040]: loss 0.038403
[epoch7, step1041]: loss 0.037280
[epoch7, step1042]: loss 0.036298
[epoch7, step1043]: loss 0.035718
[epoch7, step1044]: loss 0.037474
[epoch7, step1045]: loss 0.037666
[epoch7, step1046]: loss 0.038791
[epoch7, step1047]: loss 0.036166
[epoch7, step1048]: loss 0.035397
[epoch7, step1049]: loss 0.038988
[epoch7, step1050]: loss 0.037915
[epoch7, step1051]: loss 0.037332
[epoch7, step1052]: loss 0.036196
[epoch7, step1053]: loss 0.037796
[epoch7, step1054]: loss 0.037652
[epoch7, step1055]: loss 0.038040
[epoch7, step1056]: loss 0.035378
[epoch7, step1057]: loss 0.036319
[epoch7, step1058]: loss 0.039742
[epoch7, step1059]: loss 0.037711
[epoch7, step1060]: loss 0.037381
[epoch7, step1061]: loss 0.035200
[epoch7, step1062]: loss 0.037716
[epoch7, step1063]: loss 0.037466
[epoch7, step1064]: loss 0.038588
[epoch7, step1065]: loss 0.035922
[epoch7, step1066]: loss 0.035327
[epoch7, step1067]: loss 0.038902
[epoch7, step1068]: loss 0.036149
[epoch7, step1069]: loss 0.036602
[epoch7, step1070]: loss 0.035652
[epoch7, step1071]: loss 0.037851
[epoch7, step1072]: loss 0.038242
[epoch7, step1073]: loss 0.038303
[epoch7, step1074]: loss 0.036066
[epoch7, step1075]: loss 0.036007
[epoch7, step1076]: loss 0.038944
[epoch7, step1077]: loss 0.037382
[epoch7, step1078]: loss 0.036915
[epoch7, step1079]: loss 0.036711
[epoch7, step1080]: loss 0.037521
[epoch7, step1081]: loss 0.037228
[epoch7, step1082]: loss 0.038456
[epoch7, step1083]: loss 0.036708
[epoch7, step1084]: loss 0.035919
[epoch7, step1085]: loss 0.038456
[epoch7, step1086]: loss 0.036976
[epoch7, step1087]: loss 0.037323
[epoch7, step1088]: loss 0.035521
[epoch7, step1089]: loss 0.037650
[epoch7, step1090]: loss 0.038101
[epoch7, step1091]: loss 0.038631
[epoch7, step1092]: loss 0.035735
[epoch7, step1093]: loss 0.035496
[epoch7, step1094]: loss 0.037883
[epoch7, step1095]: loss 0.036924
[epoch7, step1096]: loss 0.036589
[epoch7, step1097]: loss 0.035731
[epoch7, step1098]: loss 0.037234
[epoch7, step1099]: loss 0.037087
[epoch7, step1100]: loss 0.039244
[epoch7, step1101]: loss 0.036297
[epoch7, step1102]: loss 0.035679
[epoch7, step1103]: loss 0.038497
[epoch7, step1104]: loss 0.037162
[epoch7, step1105]: loss 0.037478
[epoch7, step1106]: loss 0.034875
[epoch7, step1107]: loss 0.037454
[epoch7, step1108]: loss 0.037220
[epoch7, step1109]: loss 0.038690
[epoch7, step1110]: loss 0.036574
[epoch7, step1111]: loss 0.035676
[epoch7, step1112]: loss 0.039098
[epoch7, step1113]: loss 0.036960
[epoch7, step1114]: loss 0.037323
[epoch7, step1115]: loss 0.035892
[epoch7, step1116]: loss 0.037321
[epoch7, step1117]: loss 0.037503
[epoch7, step1118]: loss 0.038500
[epoch7, step1119]: loss 0.035732
[epoch7, step1120]: loss 0.035710
[epoch7, step1121]: loss 0.038877
[epoch7, step1122]: loss 0.036794
[epoch7, step1123]: loss 0.036620
[epoch7, step1124]: loss 0.036415
[epoch7, step1125]: loss 0.037703
[epoch7, step1126]: loss 0.038531
[epoch7, step1127]: loss 0.038436
[epoch7, step1128]: loss 0.036165
[epoch7, step1129]: loss 0.035396
[epoch7, step1130]: loss 0.039440
[epoch7, step1131]: loss 0.037636
[epoch7, step1132]: loss 0.037366
[epoch7, step1133]: loss 0.035291
[epoch7, step1134]: loss 0.037044
[epoch7, step1135]: loss 0.038391
[epoch7, step1136]: loss 0.039318
[epoch7, step1137]: loss 0.035986
[epoch7, step1138]: loss 0.036011
[epoch7, step1139]: loss 0.038899
[epoch7, step1140]: loss 0.036667
[epoch7, step1141]: loss 0.036984
[epoch7, step1142]: loss 0.035479
[epoch7, step1143]: loss 0.036854
[epoch7, step1144]: loss 0.037683
[epoch7, step1145]: loss 0.037871
[epoch7, step1146]: loss 0.035635
[epoch7, step1147]: loss 0.036372
[epoch7, step1148]: loss 0.038821
[epoch7, step1149]: loss 0.036975
[epoch7, step1150]: loss 0.036868
[epoch7, step1151]: loss 0.036150
[epoch7, step1152]: loss 0.037851
[epoch7, step1153]: loss 0.036890
[epoch7, step1154]: loss 0.039112
[epoch7, step1155]: loss 0.036132
[epoch7, step1156]: loss 0.035221
[epoch7, step1157]: loss 0.038888
[epoch7, step1158]: loss 0.037470
[epoch7, step1159]: loss 0.037410
[epoch7, step1160]: loss 0.036778
[epoch7, step1161]: loss 0.037648
[epoch7, step1162]: loss 0.037489
[epoch7, step1163]: loss 0.037621
[epoch7, step1164]: loss 0.035868
[epoch7, step1165]: loss 0.036525
[epoch7, step1166]: loss 0.038893
[epoch7, step1167]: loss 0.036400
[epoch7, step1168]: loss 0.037097
[epoch7, step1169]: loss 0.035566
[epoch7, step1170]: loss 0.037212
[epoch7, step1171]: loss 0.037485
[epoch7, step1172]: loss 0.038497
[epoch7, step1173]: loss 0.036039
[epoch7, step1174]: loss 0.036297
[epoch7, step1175]: loss 0.038703
[epoch7, step1176]: loss 0.037032
[epoch7, step1177]: loss 0.037513
[epoch7, step1178]: loss 0.035748
[epoch7, step1179]: loss 0.037281
[epoch7, step1180]: loss 0.037653
[epoch7, step1181]: loss 0.038999
[epoch7, step1182]: loss 0.035343
[epoch7, step1183]: loss 0.036108
[epoch7, step1184]: loss 0.038231
[epoch7, step1185]: loss 0.037332
[epoch7, step1186]: loss 0.036308
[epoch7, step1187]: loss 0.034830
[epoch7, step1188]: loss 0.036668
[epoch7, step1189]: loss 0.037084
[epoch7, step1190]: loss 0.038145
[epoch7, step1191]: loss 0.036535
[epoch7, step1192]: loss 0.035801
[epoch7, step1193]: loss 0.038881
[epoch7, step1194]: loss 0.037004
[epoch7, step1195]: loss 0.036013
[epoch7, step1196]: loss 0.034980
[epoch7, step1197]: loss 0.037548
[epoch7, step1198]: loss 0.037503
[epoch7, step1199]: loss 0.038038
[epoch7, step1200]: loss 0.035624
[epoch7, step1201]: loss 0.036143
[epoch7, step1202]: loss 0.039536
[epoch7, step1203]: loss 0.037307
[epoch7, step1204]: loss 0.036337
[epoch7, step1205]: loss 0.035276
[epoch7, step1206]: loss 0.036749
[epoch7, step1207]: loss 0.037684
[epoch7, step1208]: loss 0.038965
[epoch7, step1209]: loss 0.034849
[epoch7, step1210]: loss 0.036311
[epoch7, step1211]: loss 0.038646
[epoch7, step1212]: loss 0.036928
[epoch7, step1213]: loss 0.036685
[epoch7, step1214]: loss 0.035981
[epoch7, step1215]: loss 0.037739
[epoch7, step1216]: loss 0.037001
[epoch7, step1217]: loss 0.038792
[epoch7, step1218]: loss 0.035484
[epoch7, step1219]: loss 0.036145
[epoch7, step1220]: loss 0.038980
[epoch7, step1221]: loss 0.036316
[epoch7, step1222]: loss 0.036981
[epoch7, step1223]: loss 0.035698
[epoch7, step1224]: loss 0.037585
[epoch7, step1225]: loss 0.037499
[epoch7, step1226]: loss 0.038168
[epoch7, step1227]: loss 0.035768
[epoch7, step1228]: loss 0.035599
[epoch7, step1229]: loss 0.038513
[epoch7, step1230]: loss 0.037406
[epoch7, step1231]: loss 0.037069
[epoch7, step1232]: loss 0.036656
[epoch7, step1233]: loss 0.037171
[epoch7, step1234]: loss 0.037203
[epoch7, step1235]: loss 0.038816
[epoch7, step1236]: loss 0.036125
[epoch7, step1237]: loss 0.035205
[epoch7, step1238]: loss 0.038158
[epoch7, step1239]: loss 0.037774
[epoch7, step1240]: loss 0.037289
[epoch7, step1241]: loss 0.035240
[epoch7, step1242]: loss 0.037223
[epoch7, step1243]: loss 0.037168
[epoch7, step1244]: loss 0.038793
[epoch7, step1245]: loss 0.036274
[epoch7, step1246]: loss 0.036071
[epoch7, step1247]: loss 0.038031
[epoch7, step1248]: loss 0.037160
[epoch7, step1249]: loss 0.037654
[epoch7, step1250]: loss 0.035648
[epoch7, step1251]: loss 0.037482
[epoch7, step1252]: loss 0.038363
[epoch7, step1253]: loss 0.038557
[epoch7, step1254]: loss 0.035931
[epoch7, step1255]: loss 0.035702
[epoch7, step1256]: loss 0.039019
[epoch7, step1257]: loss 0.037472
[epoch7, step1258]: loss 0.037146
[epoch7, step1259]: loss 0.035632
[epoch7, step1260]: loss 0.037340
[epoch7, step1261]: loss 0.037239
[epoch7, step1262]: loss 0.037558
[epoch7, step1263]: loss 0.036416
[epoch7, step1264]: loss 0.035787
[epoch7, step1265]: loss 0.037862
[epoch7, step1266]: loss 0.037160
[epoch7, step1267]: loss 0.037460
[epoch7, step1268]: loss 0.036061
[epoch7, step1269]: loss 0.037226
[epoch7, step1270]: loss 0.036770
[epoch7, step1271]: loss 0.038621
[epoch7, step1272]: loss 0.035957
[epoch7, step1273]: loss 0.035266
[epoch7, step1274]: loss 0.038513
[epoch7, step1275]: loss 0.037456
[epoch7, step1276]: loss 0.036661
[epoch7, step1277]: loss 0.035722
[epoch7, step1278]: loss 0.037759
[epoch7, step1279]: loss 0.037777
[epoch7, step1280]: loss 0.038700
[epoch7, step1281]: loss 0.035726
[epoch7, step1282]: loss 0.035961
[epoch7, step1283]: loss 0.038101
[epoch7, step1284]: loss 0.036728
[epoch7, step1285]: loss 0.037671
[epoch7, step1286]: loss 0.035050
[epoch7, step1287]: loss 0.038045
[epoch7, step1288]: loss 0.038216
[epoch7, step1289]: loss 0.039269
[epoch7, step1290]: loss 0.036024
[epoch7, step1291]: loss 0.035294
[epoch7, step1292]: loss 0.039318
[epoch7, step1293]: loss 0.036389
[epoch7, step1294]: loss 0.037007
[epoch7, step1295]: loss 0.036173
[epoch7, step1296]: loss 0.037470
[epoch7, step1297]: loss 0.037264
[epoch7, step1298]: loss 0.039112
[epoch7, step1299]: loss 0.036121
[epoch7, step1300]: loss 0.036525
[epoch7, step1301]: loss 0.037892
[epoch7, step1302]: loss 0.037046
[epoch7, step1303]: loss 0.037361
[epoch7, step1304]: loss 0.035075
[epoch7, step1305]: loss 0.037734
[epoch7, step1306]: loss 0.037533
[epoch7, step1307]: loss 0.037836
[epoch7, step1308]: loss 0.035972
[epoch7, step1309]: loss 0.034987
[epoch7, step1310]: loss 0.038476
[epoch7, step1311]: loss 0.036142
[epoch7, step1312]: loss 0.037600
[epoch7, step1313]: loss 0.035881
[epoch7, step1314]: loss 0.037250
[epoch7, step1315]: loss 0.037040
[epoch7, step1316]: loss 0.040058
[epoch7, step1317]: loss 0.035482
[epoch7, step1318]: loss 0.035199
[epoch7, step1319]: loss 0.038307
[epoch7, step1320]: loss 0.037315
[epoch7, step1321]: loss 0.037577
[epoch7, step1322]: loss 0.035405
[epoch7, step1323]: loss 0.037616
[epoch7, step1324]: loss 0.037058
[epoch7, step1325]: loss 0.038187
[epoch7, step1326]: loss 0.035654
[epoch7, step1327]: loss 0.035458
[epoch7, step1328]: loss 0.038568
[epoch7, step1329]: loss 0.036992
[epoch7, step1330]: loss 0.037120
[epoch7, step1331]: loss 0.035492
[epoch7, step1332]: loss 0.037242
[epoch7, step1333]: loss 0.036471
[epoch7, step1334]: loss 0.039116
[epoch7, step1335]: loss 0.036620
[epoch7, step1336]: loss 0.035672
[epoch7, step1337]: loss 0.038263
[epoch7, step1338]: loss 0.037000
[epoch7, step1339]: loss 0.037212
[epoch7, step1340]: loss 0.035411
[epoch7, step1341]: loss 0.037527
[epoch7, step1342]: loss 0.037229
[epoch7, step1343]: loss 0.038478
[epoch7, step1344]: loss 0.035951
[epoch7, step1345]: loss 0.035577
[epoch7, step1346]: loss 0.038076
[epoch7, step1347]: loss 0.037748
[epoch7, step1348]: loss 0.036250
[epoch7, step1349]: loss 0.035846
[epoch7, step1350]: loss 0.037483
[epoch7, step1351]: loss 0.036831
[epoch7, step1352]: loss 0.038243
[epoch7, step1353]: loss 0.035667
[epoch7, step1354]: loss 0.035432
[epoch7, step1355]: loss 0.038920
[epoch7, step1356]: loss 0.036789
[epoch7, step1357]: loss 0.036622
[epoch7, step1358]: loss 0.035532
[epoch7, step1359]: loss 0.036838
[epoch7, step1360]: loss 0.037613
[epoch7, step1361]: loss 0.038565
[epoch7, step1362]: loss 0.036428
[epoch7, step1363]: loss 0.036062
[epoch7, step1364]: loss 0.038380
[epoch7, step1365]: loss 0.037164
[epoch7, step1366]: loss 0.036725
[epoch7, step1367]: loss 0.034922
[epoch7, step1368]: loss 0.038248
[epoch7, step1369]: loss 0.037516
[epoch7, step1370]: loss 0.038420
[epoch7, step1371]: loss 0.036275
[epoch7, step1372]: loss 0.035481
[epoch7, step1373]: loss 0.038694
[epoch7, step1374]: loss 0.037848
[epoch7, step1375]: loss 0.037788
[epoch7, step1376]: loss 0.035325
[epoch7, step1377]: loss 0.036617
[epoch7, step1378]: loss 0.037389
[epoch7, step1379]: loss 0.038068
[epoch7, step1380]: loss 0.036236
[epoch7, step1381]: loss 0.035656
[epoch7, step1382]: loss 0.038921
[epoch7, step1383]: loss 0.036905
[epoch7, step1384]: loss 0.036927
[epoch7, step1385]: loss 0.034879
[epoch7, step1386]: loss 0.037504
[epoch7, step1387]: loss 0.037788
[epoch7, step1388]: loss 0.037380
[epoch7, step1389]: loss 0.035188
[epoch7, step1390]: loss 0.035811
[epoch7, step1391]: loss 0.038294
[epoch7, step1392]: loss 0.037049
[epoch7, step1393]: loss 0.037219
[epoch7, step1394]: loss 0.036137
[epoch7, step1395]: loss 0.037406
[epoch7, step1396]: loss 0.036854
[epoch7, step1397]: loss 0.038243
[epoch7, step1398]: loss 0.035785
[epoch7, step1399]: loss 0.036494
[epoch7, step1400]: loss 0.039073
[epoch7, step1401]: loss 0.036762
[epoch7, step1402]: loss 0.037196
[epoch7, step1403]: loss 0.034525
[epoch7, step1404]: loss 0.036769
[epoch7, step1405]: loss 0.037124
[epoch7, step1406]: loss 0.038129
[epoch7, step1407]: loss 0.036839
[epoch7, step1408]: loss 0.035053
[epoch7, step1409]: loss 0.038202
[epoch7, step1410]: loss 0.036947
[epoch7, step1411]: loss 0.036035
[epoch7, step1412]: loss 0.035601
[epoch7, step1413]: loss 0.037333
[epoch7, step1414]: loss 0.036921
[epoch7, step1415]: loss 0.038072
[epoch7, step1416]: loss 0.035690
[epoch7, step1417]: loss 0.035542
[epoch7, step1418]: loss 0.038536
[epoch7, step1419]: loss 0.037734
[epoch7, step1420]: loss 0.037234
[epoch7, step1421]: loss 0.035866
[epoch7, step1422]: loss 0.037540
[epoch7, step1423]: loss 0.036760
[epoch7, step1424]: loss 0.038601
[epoch7, step1425]: loss 0.034895
[epoch7, step1426]: loss 0.035703
[epoch7, step1427]: loss 0.039446
[epoch7, step1428]: loss 0.037750
[epoch7, step1429]: loss 0.036999
[epoch7, step1430]: loss 0.035539
[epoch7, step1431]: loss 0.037347
[epoch7, step1432]: loss 0.037097
[epoch7, step1433]: loss 0.038430
[epoch7, step1434]: loss 0.035299
[epoch7, step1435]: loss 0.035992
[epoch7, step1436]: loss 0.038792
[epoch7, step1437]: loss 0.037333
[epoch7, step1438]: loss 0.037695
[epoch7, step1439]: loss 0.035361
[epoch7, step1440]: loss 0.037096
[epoch7, step1441]: loss 0.037845
[epoch7, step1442]: loss 0.037759
[epoch7, step1443]: loss 0.035485
[epoch7, step1444]: loss 0.035041
[epoch7, step1445]: loss 0.039067
[epoch7, step1446]: loss 0.037135
[epoch7, step1447]: loss 0.037797
[epoch7, step1448]: loss 0.035585
[epoch7, step1449]: loss 0.036593
[epoch7, step1450]: loss 0.037403
[epoch7, step1451]: loss 0.038492
[epoch7, step1452]: loss 0.035419
[epoch7, step1453]: loss 0.036517
[epoch7, step1454]: loss 0.038816
[epoch7, step1455]: loss 0.037618
[epoch7, step1456]: loss 0.036425
[epoch7, step1457]: loss 0.036200
[epoch7, step1458]: loss 0.037368
[epoch7, step1459]: loss 0.037254
[epoch7, step1460]: loss 0.039064
[epoch7, step1461]: loss 0.036433
[epoch7, step1462]: loss 0.036477
[epoch7, step1463]: loss 0.038852
[epoch7, step1464]: loss 0.037283
[epoch7, step1465]: loss 0.036789
[epoch7, step1466]: loss 0.035588
[epoch7, step1467]: loss 0.037057
[epoch7, step1468]: loss 0.036880
[epoch7, step1469]: loss 0.038128
[epoch7, step1470]: loss 0.035846
[epoch7, step1471]: loss 0.035130
[epoch7, step1472]: loss 0.038264
[epoch7, step1473]: loss 0.036919
[epoch7, step1474]: loss 0.037338
[epoch7, step1475]: loss 0.035250
[epoch7, step1476]: loss 0.037842
[epoch7, step1477]: loss 0.037010
[epoch7, step1478]: loss 0.038256
[epoch7, step1479]: loss 0.035828
[epoch7, step1480]: loss 0.036037
[epoch7, step1481]: loss 0.037653
[epoch7, step1482]: loss 0.037208
[epoch7, step1483]: loss 0.037692
[epoch7, step1484]: loss 0.036086
[epoch7, step1485]: loss 0.036957
[epoch7, step1486]: loss 0.036440
[epoch7, step1487]: loss 0.037924
[epoch7, step1488]: loss 0.035799
[epoch7, step1489]: loss 0.035258
[epoch7, step1490]: loss 0.038416
[epoch7, step1491]: loss 0.037012
[epoch7, step1492]: loss 0.036527
[epoch7, step1493]: loss 0.035540
[epoch7, step1494]: loss 0.037197
[epoch7, step1495]: loss 0.036974
[epoch7, step1496]: loss 0.037485
[epoch7, step1497]: loss 0.035979
[epoch7, step1498]: loss 0.036064
[epoch7, step1499]: loss 0.037838
[epoch7, step1500]: loss 0.037480
[epoch7, step1501]: loss 0.037261
[epoch7, step1502]: loss 0.035236
[epoch7, step1503]: loss 0.037188
[epoch7, step1504]: loss 0.036915
[epoch7, step1505]: loss 0.038377
[epoch7, step1506]: loss 0.035141
[epoch7, step1507]: loss 0.035792
[epoch7, step1508]: loss 0.038898
[epoch7, step1509]: loss 0.036726
[epoch7, step1510]: loss 0.036315
[epoch7, step1511]: loss 0.036232
[epoch7, step1512]: loss 0.037431
[epoch7, step1513]: loss 0.035849
[epoch7, step1514]: loss 0.038537
[epoch7, step1515]: loss 0.036288
[epoch7, step1516]: loss 0.035737

[epoch7]: avg loss 0.034018

[epoch8, step1]: loss 0.031638
[epoch8, step2]: loss 0.038264
[epoch8, step3]: loss 0.038079
[epoch8, step4]: loss 0.035886
[epoch8, step5]: loss 0.035812
[epoch8, step6]: loss 0.038500
[epoch8, step7]: loss 0.036282
[epoch8, step8]: loss 0.038465
[epoch8, step9]: loss 0.035082
[epoch8, step10]: loss 0.036645
[epoch8, step11]: loss 0.038357
[epoch8, step12]: loss 0.038203
[epoch8, step13]: loss 0.035736
[epoch8, step14]: loss 0.036057
[epoch8, step15]: loss 0.038313
[epoch8, step16]: loss 0.036359
[epoch8, step17]: loss 0.038905
[epoch8, step18]: loss 0.036253
[epoch8, step19]: loss 0.036356
[epoch8, step20]: loss 0.039262
[epoch8, step21]: loss 0.038269
[epoch8, step22]: loss 0.035559
[epoch8, step23]: loss 0.034886
[epoch8, step24]: loss 0.038614
[epoch8, step25]: loss 0.035529
[epoch8, step26]: loss 0.038000
[epoch8, step27]: loss 0.034912
[epoch8, step28]: loss 0.036328
[epoch8, step29]: loss 0.038513
[epoch8, step30]: loss 0.038892
[epoch8, step31]: loss 0.035136
[epoch8, step32]: loss 0.036317
[epoch8, step33]: loss 0.039007
[epoch8, step34]: loss 0.036807
[epoch8, step35]: loss 0.038958
[epoch8, step36]: loss 0.035247
[epoch8, step37]: loss 0.036266
[epoch8, step38]: loss 0.038495
[epoch8, step39]: loss 0.038412
[epoch8, step40]: loss 0.035998
[epoch8, step41]: loss 0.035128
[epoch8, step42]: loss 0.038719
[epoch8, step43]: loss 0.035984
[epoch8, step44]: loss 0.039033
[epoch8, step45]: loss 0.035456
[epoch8, step46]: loss 0.036322
[epoch8, step47]: loss 0.037940
[epoch8, step48]: loss 0.037984
[epoch8, step49]: loss 0.034112
[epoch8, step50]: loss 0.035871
[epoch8, step51]: loss 0.038343
[epoch8, step52]: loss 0.035844
[epoch8, step53]: loss 0.039125
[epoch8, step54]: loss 0.035177
[epoch8, step55]: loss 0.036674
[epoch8, step56]: loss 0.039420
[epoch8, step57]: loss 0.038709
[epoch8, step58]: loss 0.035666
[epoch8, step59]: loss 0.034709
[epoch8, step60]: loss 0.038917
[epoch8, step61]: loss 0.035297
[epoch8, step62]: loss 0.037967
[epoch8, step63]: loss 0.034842
[epoch8, step64]: loss 0.035787
[epoch8, step65]: loss 0.038587
[epoch8, step66]: loss 0.038365
[epoch8, step67]: loss 0.035808
[epoch8, step68]: loss 0.035757
[epoch8, step69]: loss 0.038430
[epoch8, step70]: loss 0.035831
[epoch8, step71]: loss 0.038240
[epoch8, step72]: loss 0.035466
[epoch8, step73]: loss 0.036227
[epoch8, step74]: loss 0.038458
[epoch8, step75]: loss 0.038584
[epoch8, step76]: loss 0.036185
[epoch8, step77]: loss 0.036277
[epoch8, step78]: loss 0.038609
[epoch8, step79]: loss 0.035413
[epoch8, step80]: loss 0.039306
[epoch8, step81]: loss 0.035487
[epoch8, step82]: loss 0.035708
[epoch8, step83]: loss 0.037944
[epoch8, step84]: loss 0.038554
[epoch8, step85]: loss 0.036383
[epoch8, step86]: loss 0.036122
[epoch8, step87]: loss 0.039489
[epoch8, step88]: loss 0.034899
[epoch8, step89]: loss 0.038335
[epoch8, step90]: loss 0.035936
[epoch8, step91]: loss 0.035635
[epoch8, step92]: loss 0.038718
[epoch8, step93]: loss 0.038351
[epoch8, step94]: loss 0.035480
[epoch8, step95]: loss 0.036136
[epoch8, step96]: loss 0.038118
[epoch8, step97]: loss 0.036656
[epoch8, step98]: loss 0.038554
[epoch8, step99]: loss 0.035504
[epoch8, step100]: loss 0.035076
[epoch8, step101]: loss 0.039043
[epoch8, step102]: loss 0.038325
[epoch8, step103]: loss 0.035584
[epoch8, step104]: loss 0.035848
[epoch8, step105]: loss 0.038904
[epoch8, step106]: loss 0.035989
[epoch8, step107]: loss 0.038739
[epoch8, step108]: loss 0.035950
[epoch8, step109]: loss 0.035762
[epoch8, step110]: loss 0.039167
[epoch8, step111]: loss 0.037985
[epoch8, step112]: loss 0.035776
[epoch8, step113]: loss 0.036481
[epoch8, step114]: loss 0.038141
[epoch8, step115]: loss 0.035966
[epoch8, step116]: loss 0.039275
[epoch8, step117]: loss 0.035443
[epoch8, step118]: loss 0.036842
[epoch8, step119]: loss 0.038906
[epoch8, step120]: loss 0.038721
[epoch8, step121]: loss 0.035511
[epoch8, step122]: loss 0.035879
[epoch8, step123]: loss 0.039115
[epoch8, step124]: loss 0.036340
[epoch8, step125]: loss 0.039149
[epoch8, step126]: loss 0.035665
[epoch8, step127]: loss 0.035720
[epoch8, step128]: loss 0.038464
[epoch8, step129]: loss 0.038089
[epoch8, step130]: loss 0.035843
[epoch8, step131]: loss 0.035096
[epoch8, step132]: loss 0.038460
[epoch8, step133]: loss 0.035840
[epoch8, step134]: loss 0.037759
[epoch8, step135]: loss 0.036211
[epoch8, step136]: loss 0.037212
[epoch8, step137]: loss 0.038198
[epoch8, step138]: loss 0.038504
[epoch8, step139]: loss 0.035739
[epoch8, step140]: loss 0.036222
[epoch8, step141]: loss 0.038835
[epoch8, step142]: loss 0.035904
[epoch8, step143]: loss 0.038076
[epoch8, step144]: loss 0.035773
[epoch8, step145]: loss 0.036049
[epoch8, step146]: loss 0.038566
[epoch8, step147]: loss 0.039701
[epoch8, step148]: loss 0.035429
[epoch8, step149]: loss 0.035270
[epoch8, step150]: loss 0.038301
[epoch8, step151]: loss 0.035998
[epoch8, step152]: loss 0.038400
[epoch8, step153]: loss 0.035601
[epoch8, step154]: loss 0.035746
[epoch8, step155]: loss 0.038363
[epoch8, step156]: loss 0.037993
[epoch8, step157]: loss 0.035809
[epoch8, step158]: loss 0.036073
[epoch8, step159]: loss 0.038790
[epoch8, step160]: loss 0.036191
[epoch8, step161]: loss 0.039081
[epoch8, step162]: loss 0.035811
[epoch8, step163]: loss 0.036018
[epoch8, step164]: loss 0.038859
[epoch8, step165]: loss 0.038223
[epoch8, step166]: loss 0.036009
[epoch8, step167]: loss 0.035303
[epoch8, step168]: loss 0.039126
[epoch8, step169]: loss 0.035696
[epoch8, step170]: loss 0.038757
[epoch8, step171]: loss 0.035964
[epoch8, step172]: loss 0.036204
[epoch8, step173]: loss 0.038762
[epoch8, step174]: loss 0.038276
[epoch8, step175]: loss 0.036322
[epoch8, step176]: loss 0.036182
[epoch8, step177]: loss 0.039143
[epoch8, step178]: loss 0.035925
[epoch8, step179]: loss 0.037879
[epoch8, step180]: loss 0.036038
[epoch8, step181]: loss 0.036070
[epoch8, step182]: loss 0.038989
[epoch8, step183]: loss 0.038871
[epoch8, step184]: loss 0.036651
[epoch8, step185]: loss 0.035976
[epoch8, step186]: loss 0.038608
[epoch8, step187]: loss 0.036157
[epoch8, step188]: loss 0.038155
[epoch8, step189]: loss 0.035718
[epoch8, step190]: loss 0.035479
[epoch8, step191]: loss 0.038447
[epoch8, step192]: loss 0.039224
[epoch8, step193]: loss 0.033984
[epoch8, step194]: loss 0.035107
[epoch8, step195]: loss 0.039159
[epoch8, step196]: loss 0.036066
[epoch8, step197]: loss 0.038520
[epoch8, step198]: loss 0.034993
[epoch8, step199]: loss 0.035983
[epoch8, step200]: loss 0.039090
[epoch8, step201]: loss 0.038676
[epoch8, step202]: loss 0.035304
[epoch8, step203]: loss 0.035718
[epoch8, step204]: loss 0.038989
[epoch8, step205]: loss 0.035470
[epoch8, step206]: loss 0.038018
[epoch8, step207]: loss 0.035602
[epoch8, step208]: loss 0.036527
[epoch8, step209]: loss 0.038847
[epoch8, step210]: loss 0.039503
[epoch8, step211]: loss 0.036352
[epoch8, step212]: loss 0.036471
[epoch8, step213]: loss 0.038670
[epoch8, step214]: loss 0.035407
[epoch8, step215]: loss 0.038983
[epoch8, step216]: loss 0.036356
[epoch8, step217]: loss 0.035128
[epoch8, step218]: loss 0.038940
[epoch8, step219]: loss 0.038099
[epoch8, step220]: loss 0.035989
[epoch8, step221]: loss 0.035958
[epoch8, step222]: loss 0.038832
[epoch8, step223]: loss 0.036058
[epoch8, step224]: loss 0.037901
[epoch8, step225]: loss 0.035529
[epoch8, step226]: loss 0.035633
[epoch8, step227]: loss 0.037723
[epoch8, step228]: loss 0.039014
[epoch8, step229]: loss 0.034923
[epoch8, step230]: loss 0.036314
[epoch8, step231]: loss 0.038973
[epoch8, step232]: loss 0.035930
[epoch8, step233]: loss 0.038052
[epoch8, step234]: loss 0.035197
[epoch8, step235]: loss 0.036515
[epoch8, step236]: loss 0.038769
[epoch8, step237]: loss 0.038427
[epoch8, step238]: loss 0.035539
[epoch8, step239]: loss 0.035073
[epoch8, step240]: loss 0.038074
[epoch8, step241]: loss 0.036420
[epoch8, step242]: loss 0.038326
[epoch8, step243]: loss 0.036344
[epoch8, step244]: loss 0.035885
[epoch8, step245]: loss 0.038088
[epoch8, step246]: loss 0.038537
[epoch8, step247]: loss 0.036035
[epoch8, step248]: loss 0.035604
[epoch8, step249]: loss 0.038301
[epoch8, step250]: loss 0.036259
[epoch8, step251]: loss 0.039141
[epoch8, step252]: loss 0.036282
[epoch8, step253]: loss 0.035471
[epoch8, step254]: loss 0.038205
[epoch8, step255]: loss 0.038484
[epoch8, step256]: loss 0.035428
[epoch8, step257]: loss 0.035491
[epoch8, step258]: loss 0.039073
[epoch8, step259]: loss 0.036097
[epoch8, step260]: loss 0.037877
[epoch8, step261]: loss 0.036584
[epoch8, step262]: loss 0.036641
[epoch8, step263]: loss 0.037972
[epoch8, step264]: loss 0.038524
[epoch8, step265]: loss 0.036416
[epoch8, step266]: loss 0.035601
[epoch8, step267]: loss 0.038067
[epoch8, step268]: loss 0.036037
[epoch8, step269]: loss 0.038297
[epoch8, step270]: loss 0.035170
[epoch8, step271]: loss 0.035934
[epoch8, step272]: loss 0.038430
[epoch8, step273]: loss 0.038015
[epoch8, step274]: loss 0.036073
[epoch8, step275]: loss 0.035283
[epoch8, step276]: loss 0.038152
[epoch8, step277]: loss 0.036572
[epoch8, step278]: loss 0.038503
[epoch8, step279]: loss 0.035551
[epoch8, step280]: loss 0.036457
[epoch8, step281]: loss 0.038430
[epoch8, step282]: loss 0.039363
[epoch8, step283]: loss 0.036260
[epoch8, step284]: loss 0.035536
[epoch8, step285]: loss 0.039275
[epoch8, step286]: loss 0.035415
[epoch8, step287]: loss 0.038557
[epoch8, step288]: loss 0.035266
[epoch8, step289]: loss 0.036576
[epoch8, step290]: loss 0.038510
[epoch8, step291]: loss 0.038568
[epoch8, step292]: loss 0.034891
[epoch8, step293]: loss 0.035299
[epoch8, step294]: loss 0.037926
[epoch8, step295]: loss 0.035438
[epoch8, step296]: loss 0.039072
[epoch8, step297]: loss 0.035537
[epoch8, step298]: loss 0.036336
[epoch8, step299]: loss 0.037802
[epoch8, step300]: loss 0.038950
[epoch8, step301]: loss 0.035698
[epoch8, step302]: loss 0.036409
[epoch8, step303]: loss 0.039410
[epoch8, step304]: loss 0.035756
[epoch8, step305]: loss 0.038505
[epoch8, step306]: loss 0.036246
[epoch8, step307]: loss 0.035597
[epoch8, step308]: loss 0.039138
[epoch8, step309]: loss 0.038704
[epoch8, step310]: loss 0.035825
[epoch8, step311]: loss 0.036102
[epoch8, step312]: loss 0.038089
[epoch8, step313]: loss 0.036243
[epoch8, step314]: loss 0.038218
[epoch8, step315]: loss 0.036527
[epoch8, step316]: loss 0.035647
[epoch8, step317]: loss 0.038982
[epoch8, step318]: loss 0.038309
[epoch8, step319]: loss 0.035277
[epoch8, step320]: loss 0.034928
[epoch8, step321]: loss 0.038005
[epoch8, step322]: loss 0.036057
[epoch8, step323]: loss 0.038008
[epoch8, step324]: loss 0.036395
[epoch8, step325]: loss 0.036306
[epoch8, step326]: loss 0.038352
[epoch8, step327]: loss 0.037833
[epoch8, step328]: loss 0.036140
[epoch8, step329]: loss 0.035346
[epoch8, step330]: loss 0.038071
[epoch8, step331]: loss 0.036092
[epoch8, step332]: loss 0.037787
[epoch8, step333]: loss 0.035516
[epoch8, step334]: loss 0.035999
[epoch8, step335]: loss 0.038563
[epoch8, step336]: loss 0.039233
[epoch8, step337]: loss 0.036148
[epoch8, step338]: loss 0.035381
[epoch8, step339]: loss 0.038637
[epoch8, step340]: loss 0.036388
[epoch8, step341]: loss 0.038046
[epoch8, step342]: loss 0.035361
[epoch8, step343]: loss 0.036214
[epoch8, step344]: loss 0.038210
[epoch8, step345]: loss 0.037544
[epoch8, step346]: loss 0.035293
[epoch8, step347]: loss 0.035256
[epoch8, step348]: loss 0.038635
[epoch8, step349]: loss 0.036410
[epoch8, step350]: loss 0.037836
[epoch8, step351]: loss 0.034910
[epoch8, step352]: loss 0.035784
[epoch8, step353]: loss 0.038285
[epoch8, step354]: loss 0.037548
[epoch8, step355]: loss 0.034567
[epoch8, step356]: loss 0.036468
[epoch8, step357]: loss 0.038777
[epoch8, step358]: loss 0.034425
[epoch8, step359]: loss 0.039436
[epoch8, step360]: loss 0.034474
[epoch8, step361]: loss 0.035365
[epoch8, step362]: loss 0.039209
[epoch8, step363]: loss 0.037909
[epoch8, step364]: loss 0.035542
[epoch8, step365]: loss 0.035360
[epoch8, step366]: loss 0.038739
[epoch8, step367]: loss 0.035980
[epoch8, step368]: loss 0.037675
[epoch8, step369]: loss 0.035539
[epoch8, step370]: loss 0.036589
[epoch8, step371]: loss 0.039150
[epoch8, step372]: loss 0.038263
[epoch8, step373]: loss 0.035360
[epoch8, step374]: loss 0.034842
[epoch8, step375]: loss 0.039175
[epoch8, step376]: loss 0.035862
[epoch8, step377]: loss 0.038524
[epoch8, step378]: loss 0.035995
[epoch8, step379]: loss 0.036505
[epoch8, step380]: loss 0.039016
[epoch8, step381]: loss 0.038081
[epoch8, step382]: loss 0.036061
[epoch8, step383]: loss 0.034612
[epoch8, step384]: loss 0.037727
[epoch8, step385]: loss 0.035704
[epoch8, step386]: loss 0.038521
[epoch8, step387]: loss 0.035525
[epoch8, step388]: loss 0.036871
[epoch8, step389]: loss 0.038367
[epoch8, step390]: loss 0.039422
[epoch8, step391]: loss 0.035300
[epoch8, step392]: loss 0.036280
[epoch8, step393]: loss 0.038141
[epoch8, step394]: loss 0.035859
[epoch8, step395]: loss 0.038290
[epoch8, step396]: loss 0.035727
[epoch8, step397]: loss 0.035584
[epoch8, step398]: loss 0.038756
[epoch8, step399]: loss 0.038118
[epoch8, step400]: loss 0.035298
[epoch8, step401]: loss 0.035392
[epoch8, step402]: loss 0.038318
[epoch8, step403]: loss 0.035821
[epoch8, step404]: loss 0.038653
[epoch8, step405]: loss 0.035965
[epoch8, step406]: loss 0.036268
[epoch8, step407]: loss 0.038226
[epoch8, step408]: loss 0.038639
[epoch8, step409]: loss 0.036989
[epoch8, step410]: loss 0.036500
[epoch8, step411]: loss 0.038712
[epoch8, step412]: loss 0.035395
[epoch8, step413]: loss 0.038550
[epoch8, step414]: loss 0.035723
[epoch8, step415]: loss 0.035978
[epoch8, step416]: loss 0.037887
[epoch8, step417]: loss 0.038429
[epoch8, step418]: loss 0.035515
[epoch8, step419]: loss 0.034754
[epoch8, step420]: loss 0.038530
[epoch8, step421]: loss 0.035546
[epoch8, step422]: loss 0.038147
[epoch8, step423]: loss 0.035626
[epoch8, step424]: loss 0.035909
[epoch8, step425]: loss 0.038606
[epoch8, step426]: loss 0.038594
[epoch8, step427]: loss 0.036087
[epoch8, step428]: loss 0.035799
[epoch8, step429]: loss 0.039013
[epoch8, step430]: loss 0.036164
[epoch8, step431]: loss 0.039315
[epoch8, step432]: loss 0.035547
[epoch8, step433]: loss 0.036934
[epoch8, step434]: loss 0.039005
[epoch8, step435]: loss 0.038788
[epoch8, step436]: loss 0.035391
[epoch8, step437]: loss 0.035822
[epoch8, step438]: loss 0.038923
[epoch8, step439]: loss 0.036095
[epoch8, step440]: loss 0.038162
[epoch8, step441]: loss 0.035725
[epoch8, step442]: loss 0.035707
[epoch8, step443]: loss 0.038894
[epoch8, step444]: loss 0.037893
[epoch8, step445]: loss 0.036071
[epoch8, step446]: loss 0.035990
[epoch8, step447]: loss 0.039073
[epoch8, step448]: loss 0.036129
[epoch8, step449]: loss 0.037978
[epoch8, step450]: loss 0.035229
[epoch8, step451]: loss 0.036095
[epoch8, step452]: loss 0.037503
[epoch8, step453]: loss 0.038932
[epoch8, step454]: loss 0.036233
[epoch8, step455]: loss 0.035844
[epoch8, step456]: loss 0.037896
[epoch8, step457]: loss 0.037070
[epoch8, step458]: loss 0.038170
[epoch8, step459]: loss 0.036436
[epoch8, step460]: loss 0.036127
[epoch8, step461]: loss 0.039114
[epoch8, step462]: loss 0.037642
[epoch8, step463]: loss 0.035724
[epoch8, step464]: loss 0.035359
[epoch8, step465]: loss 0.039903
[epoch8, step466]: loss 0.035887
[epoch8, step467]: loss 0.038013
[epoch8, step468]: loss 0.035658
[epoch8, step469]: loss 0.035933
[epoch8, step470]: loss 0.038802
[epoch8, step471]: loss 0.037994
[epoch8, step472]: loss 0.036120
[epoch8, step473]: loss 0.035502
[epoch8, step474]: loss 0.038323
[epoch8, step475]: loss 0.036241
[epoch8, step476]: loss 0.039360
[epoch8, step477]: loss 0.035514
[epoch8, step478]: loss 0.035565
[epoch8, step479]: loss 0.038943
[epoch8, step480]: loss 0.037635
[epoch8, step481]: loss 0.035328
[epoch8, step482]: loss 0.035139
[epoch8, step483]: loss 0.038783
[epoch8, step484]: loss 0.036047
[epoch8, step485]: loss 0.038362
[epoch8, step486]: loss 0.035918
[epoch8, step487]: loss 0.035206
[epoch8, step488]: loss 0.038831
[epoch8, step489]: loss 0.037432
[epoch8, step490]: loss 0.036040
[epoch8, step491]: loss 0.035786
[epoch8, step492]: loss 0.038095
[epoch8, step493]: loss 0.035719
[epoch8, step494]: loss 0.037514
[epoch8, step495]: loss 0.036975
[epoch8, step496]: loss 0.036267
[epoch8, step497]: loss 0.038584
[epoch8, step498]: loss 0.038547
[epoch8, step499]: loss 0.036104
[epoch8, step500]: loss 0.035170
[epoch8, step501]: loss 0.038035
[epoch8, step502]: loss 0.035655
[epoch8, step503]: loss 0.038651
[epoch8, step504]: loss 0.035265
[epoch8, step505]: loss 0.035111
[epoch8, step506]: loss 0.038925
[epoch8, step507]: loss 0.038877
[epoch8, step508]: loss 0.036359
[epoch8, step509]: loss 0.035408
[epoch8, step510]: loss 0.038761
[epoch8, step511]: loss 0.036208
[epoch8, step512]: loss 0.038708
[epoch8, step513]: loss 0.035783
[epoch8, step514]: loss 0.036237
[epoch8, step515]: loss 0.038429
[epoch8, step516]: loss 0.038851
[epoch8, step517]: loss 0.035737
[epoch8, step518]: loss 0.035845
[epoch8, step519]: loss 0.038799
[epoch8, step520]: loss 0.035235
[epoch8, step521]: loss 0.038409
[epoch8, step522]: loss 0.035333
[epoch8, step523]: loss 0.035869
[epoch8, step524]: loss 0.037782
[epoch8, step525]: loss 0.038615
[epoch8, step526]: loss 0.035743
[epoch8, step527]: loss 0.035325
[epoch8, step528]: loss 0.038635
[epoch8, step529]: loss 0.035456
[epoch8, step530]: loss 0.038788
[epoch8, step531]: loss 0.035324
[epoch8, step532]: loss 0.035712
[epoch8, step533]: loss 0.039349
[epoch8, step534]: loss 0.038414
[epoch8, step535]: loss 0.036496
[epoch8, step536]: loss 0.035718
[epoch8, step537]: loss 0.038652
[epoch8, step538]: loss 0.035842
[epoch8, step539]: loss 0.038131
[epoch8, step540]: loss 0.035136
[epoch8, step541]: loss 0.035434
[epoch8, step542]: loss 0.038413
[epoch8, step543]: loss 0.038148
[epoch8, step544]: loss 0.035655
[epoch8, step545]: loss 0.034851
[epoch8, step546]: loss 0.039056
[epoch8, step547]: loss 0.035696
[epoch8, step548]: loss 0.038341
[epoch8, step549]: loss 0.035807
[epoch8, step550]: loss 0.036013
[epoch8, step551]: loss 0.038322
[epoch8, step552]: loss 0.037822
[epoch8, step553]: loss 0.036263
[epoch8, step554]: loss 0.035345
[epoch8, step555]: loss 0.038116
[epoch8, step556]: loss 0.035562
[epoch8, step557]: loss 0.037793
[epoch8, step558]: loss 0.035738
[epoch8, step559]: loss 0.035383
[epoch8, step560]: loss 0.038555
[epoch8, step561]: loss 0.038169
[epoch8, step562]: loss 0.035683
[epoch8, step563]: loss 0.029092
[epoch8, step564]: loss 0.029154
[epoch8, step565]: loss 0.027730
[epoch8, step566]: loss 0.034460
[epoch8, step567]: loss 0.026733
[epoch8, step568]: loss 0.025838
[epoch8, step569]: loss 0.023293
[epoch8, step570]: loss 0.031211
[epoch8, step571]: loss 0.026901
[epoch8, step572]: loss 0.025857
[epoch8, step573]: loss 0.029271
[epoch8, step574]: loss 0.028019
[epoch8, step575]: loss 0.020810
[epoch8, step576]: loss 0.021604
[epoch8, step577]: loss 0.026455
[epoch8, step578]: loss 0.018742
[epoch8, step579]: loss 0.028399
[epoch8, step580]: loss 0.020151
[epoch8, step581]: loss 0.025773
[epoch8, step582]: loss 0.024924
[epoch8, step583]: loss 0.021694
[epoch8, step584]: loss 0.023649
[epoch8, step585]: loss 0.025689
[epoch8, step586]: loss 0.021383
[epoch8, step587]: loss 0.027138
[epoch8, step588]: loss 0.022799
[epoch8, step589]: loss 0.022680
[epoch8, step590]: loss 0.026973
[epoch8, step591]: loss 0.020611
[epoch8, step592]: loss 0.025608
[epoch8, step593]: loss 0.021972
[epoch8, step594]: loss 0.025754
[epoch8, step595]: loss 0.026519
[epoch8, step596]: loss 0.021966
[epoch8, step597]: loss 0.024903
[epoch8, step598]: loss 0.026510
[epoch8, step599]: loss 0.025000
[epoch8, step600]: loss 0.026745
[epoch8, step601]: loss 0.019312
[epoch8, step602]: loss 0.022493
[epoch8, step603]: loss 0.025748
[epoch8, step604]: loss 0.026660
[epoch8, step605]: loss 0.025176
[epoch8, step606]: loss 0.024789
[epoch8, step607]: loss 0.026922
[epoch8, step608]: loss 0.025665
[epoch8, step609]: loss 0.026344
[epoch8, step610]: loss 0.025796
[epoch8, step611]: loss 0.026263
[epoch8, step612]: loss 0.025505
[epoch8, step613]: loss 0.019226
[epoch8, step614]: loss 0.025066
[epoch8, step615]: loss 0.028057
[epoch8, step616]: loss 0.024013
[epoch8, step617]: loss 0.023484
[epoch8, step618]: loss 0.025638
[epoch8, step619]: loss 0.026770
[epoch8, step620]: loss 0.024310
[epoch8, step621]: loss 0.026222
[epoch8, step622]: loss 0.020424
[epoch8, step623]: loss 0.024656
[epoch8, step624]: loss 0.026255
[epoch8, step625]: loss 0.025961
[epoch8, step626]: loss 0.028036
[epoch8, step627]: loss 0.022705
[epoch8, step628]: loss 0.025556
[epoch8, step629]: loss 0.020753
[epoch8, step630]: loss 0.023249
[epoch8, step631]: loss 0.031033
[epoch8, step632]: loss 0.023275
[epoch8, step633]: loss 0.024720
[epoch8, step634]: loss 0.026930
[epoch8, step635]: loss 0.025401
[epoch8, step636]: loss 0.020605
[epoch8, step637]: loss 0.027083
[epoch8, step638]: loss 0.026929
[epoch8, step639]: loss 0.022969
[epoch8, step640]: loss 0.029108
[epoch8, step641]: loss 0.030138
[epoch8, step642]: loss 0.024757
[epoch8, step643]: loss 0.025650
[epoch8, step644]: loss 0.025734
[epoch8, step645]: loss 0.023560
[epoch8, step646]: loss 0.026141
[epoch8, step647]: loss 0.023614
[epoch8, step648]: loss 0.022888
[epoch8, step649]: loss 0.028428
[epoch8, step650]: loss 0.021874
[epoch8, step651]: loss 0.025697
[epoch8, step652]: loss 0.026577
[epoch8, step653]: loss 0.027834
[epoch8, step654]: loss 0.023007
[epoch8, step655]: loss 0.024128
[epoch8, step656]: loss 0.021405
[epoch8, step657]: loss 0.027544
[epoch8, step658]: loss 0.025203
[epoch8, step659]: loss 0.027554
[epoch8, step660]: loss 0.023839
[epoch8, step661]: loss 0.026333
[epoch8, step662]: loss 0.024006
[epoch8, step663]: loss 0.021075
[epoch8, step664]: loss 0.024870
[epoch8, step665]: loss 0.027515
[epoch8, step666]: loss 0.026704
[epoch8, step667]: loss 0.026245
[epoch8, step668]: loss 0.022162
[epoch8, step669]: loss 0.026406
[epoch8, step670]: loss 0.026717
[epoch8, step671]: loss 0.021373
[epoch8, step672]: loss 0.023520
[epoch8, step673]: loss 0.022105
[epoch8, step674]: loss 0.021226
[epoch8, step675]: loss 0.020020
[epoch8, step676]: loss 0.024395
[epoch8, step677]: loss 0.025107
[epoch8, step678]: loss 0.023181
[epoch8, step679]: loss 0.023755
[epoch8, step680]: loss 0.030473
[epoch8, step681]: loss 0.021866
[epoch8, step682]: loss 0.026044
[epoch8, step683]: loss 0.025843
[epoch8, step684]: loss 0.024652
[epoch8, step685]: loss 0.024174
[epoch8, step686]: loss 0.027075
[epoch8, step687]: loss 0.026589
[epoch8, step688]: loss 0.022560
[epoch8, step689]: loss 0.024445
[epoch8, step690]: loss 0.025128
[epoch8, step691]: loss 0.024167
[epoch8, step692]: loss 0.022359
[epoch8, step693]: loss 0.026936
[epoch8, step694]: loss 0.022830
[epoch8, step695]: loss 0.026344
[epoch8, step696]: loss 0.026008
[epoch8, step697]: loss 0.026834
[epoch8, step698]: loss 0.024717
[epoch8, step699]: loss 0.023505
[epoch8, step700]: loss 0.021553
[epoch8, step701]: loss 0.025922
[epoch8, step702]: loss 0.021711
[epoch8, step703]: loss 0.022709
[epoch8, step704]: loss 0.025163
[epoch8, step705]: loss 0.024922
[epoch8, step706]: loss 0.023676
[epoch8, step707]: loss 0.024478
[epoch8, step708]: loss 0.026043
[epoch8, step709]: loss 0.027250
[epoch8, step710]: loss 0.023693
[epoch8, step711]: loss 0.023424
[epoch8, step712]: loss 0.026705
[epoch8, step713]: loss 0.026247
[epoch8, step714]: loss 0.021317
[epoch8, step715]: loss 0.023243
[epoch8, step716]: loss 0.025753
[epoch8, step717]: loss 0.023606
[epoch8, step718]: loss 0.024931
[epoch8, step719]: loss 0.032592
[epoch8, step720]: loss 0.024650
[epoch8, step721]: loss 0.023043
[epoch8, step722]: loss 0.030480
[epoch8, step723]: loss 0.025895
[epoch8, step724]: loss 0.022826
[epoch8, step725]: loss 0.027778
[epoch8, step726]: loss 0.022379
[epoch8, step727]: loss 0.024627
[epoch8, step728]: loss 0.026383
[epoch8, step729]: loss 0.021138
[epoch8, step730]: loss 0.022685
[epoch8, step731]: loss 0.025727
[epoch8, step732]: loss 0.025808
[epoch8, step733]: loss 0.023947
[epoch8, step734]: loss 0.022693
[epoch8, step735]: loss 0.027443
[epoch8, step736]: loss 0.025072
[epoch8, step737]: loss 0.026470
[epoch8, step738]: loss 0.020544
[epoch8, step739]: loss 0.025423
[epoch8, step740]: loss 0.022301
[epoch8, step741]: loss 0.025201
[epoch8, step742]: loss 0.021680
[epoch8, step743]: loss 0.023267
[epoch8, step744]: loss 0.023972
[epoch8, step745]: loss 0.024571
[epoch8, step746]: loss 0.025131
[epoch8, step747]: loss 0.027367
[epoch8, step748]: loss 0.025453
[epoch8, step749]: loss 0.026140
[epoch8, step750]: loss 0.027317
[epoch8, step751]: loss 0.021519
[epoch8, step752]: loss 0.024952
[epoch8, step753]: loss 0.025637
[epoch8, step754]: loss 0.022592
[epoch8, step755]: loss 0.026037
[epoch8, step756]: loss 0.023359
[epoch8, step757]: loss 0.020457
[epoch8, step758]: loss 0.025239
[epoch8, step759]: loss 0.022989
[epoch8, step760]: loss 0.023918
[epoch8, step761]: loss 0.026361
[epoch8, step762]: loss 0.021589
[epoch8, step763]: loss 0.025542
[epoch8, step764]: loss 0.023343
[epoch8, step765]: loss 0.025911
[epoch8, step766]: loss 0.024475
[epoch8, step767]: loss 0.026361
[epoch8, step768]: loss 0.021386
[epoch8, step769]: loss 0.026544
[epoch8, step770]: loss 0.025723
[epoch8, step771]: loss 0.023304
[epoch8, step772]: loss 0.028553
[epoch8, step773]: loss 0.026478
[epoch8, step774]: loss 0.024102
[epoch8, step775]: loss 0.020550
[epoch8, step776]: loss 0.025496
[epoch8, step777]: loss 0.023005
[epoch8, step778]: loss 0.028014
[epoch8, step779]: loss 0.023830
[epoch8, step780]: loss 0.020139
[epoch8, step781]: loss 0.024282
[epoch8, step782]: loss 0.022724
[epoch8, step783]: loss 0.019291
[epoch8, step784]: loss 0.020220
[epoch8, step785]: loss 0.021431
[epoch8, step786]: loss 0.024144
[epoch8, step787]: loss 0.023271
[epoch8, step788]: loss 0.024662
[epoch8, step789]: loss 0.022424
[epoch8, step790]: loss 0.023227
[epoch8, step791]: loss 0.026799
[epoch8, step792]: loss 0.025038
[epoch8, step793]: loss 0.026948
[epoch8, step794]: loss 0.020340
[epoch8, step795]: loss 0.025507
[epoch8, step796]: loss 0.027846
[epoch8, step797]: loss 0.027748
[epoch8, step798]: loss 0.027171
[epoch8, step799]: loss 0.025799
[epoch8, step800]: loss 0.021441
[epoch8, step801]: loss 0.021709
[epoch8, step802]: loss 0.022713
[epoch8, step803]: loss 0.026026
[epoch8, step804]: loss 0.027250
[epoch8, step805]: loss 0.028081
[epoch8, step806]: loss 0.021258
[epoch8, step807]: loss 0.020538
[epoch8, step808]: loss 0.022815
[epoch8, step809]: loss 0.023090
[epoch8, step810]: loss 0.025705
[epoch8, step811]: loss 0.025579
[epoch8, step812]: loss 0.024697
[epoch8, step813]: loss 0.023422
[epoch8, step814]: loss 0.025173
[epoch8, step815]: loss 0.024802
[epoch8, step816]: loss 0.024253
[epoch8, step817]: loss 0.024847
[epoch8, step818]: loss 0.022419
[epoch8, step819]: loss 0.019936
[epoch8, step820]: loss 0.023493
[epoch8, step821]: loss 0.021747
[epoch8, step822]: loss 0.030366
[epoch8, step823]: loss 0.023926
[epoch8, step824]: loss 0.026631
[epoch8, step825]: loss 0.025161
[epoch8, step826]: loss 0.024280
[epoch8, step827]: loss 0.026819
[epoch8, step828]: loss 0.028854
[epoch8, step829]: loss 0.026283
[epoch8, step830]: loss 0.022570
[epoch8, step831]: loss 0.026341
[epoch8, step832]: loss 0.020915
[epoch8, step833]: loss 0.029027
[epoch8, step834]: loss 0.025396
[epoch8, step835]: loss 0.020698
[epoch8, step836]: loss 0.026801
[epoch8, step837]: loss 0.025558
[epoch8, step838]: loss 0.026124
[epoch8, step839]: loss 0.028232
[epoch8, step840]: loss 0.020640
[epoch8, step841]: loss 0.024297
[epoch8, step842]: loss 0.027478
[epoch8, step843]: loss 0.024820
[epoch8, step844]: loss 0.024827
[epoch8, step845]: loss 0.020913
[epoch8, step846]: loss 0.025386
[epoch8, step847]: loss 0.026764
[epoch8, step848]: loss 0.024989
[epoch8, step849]: loss 0.025103
[epoch8, step850]: loss 0.022855
[epoch8, step851]: loss 0.023738
[epoch8, step852]: loss 0.023202
[epoch8, step853]: loss 0.029150
[epoch8, step854]: loss 0.022596
[epoch8, step855]: loss 0.027220
[epoch8, step856]: loss 0.022151
[epoch8, step857]: loss 0.025563
[epoch8, step858]: loss 0.024291
[epoch8, step859]: loss 0.023539
[epoch8, step860]: loss 0.022553
[epoch8, step861]: loss 0.023153
[epoch8, step862]: loss 0.023077
[epoch8, step863]: loss 0.020566
[epoch8, step864]: loss 0.026339
[epoch8, step865]: loss 0.023396
[epoch8, step866]: loss 0.025127
[epoch8, step867]: loss 0.026062
[epoch8, step868]: loss 0.026633
[epoch8, step869]: loss 0.023863
[epoch8, step870]: loss 0.031048
[epoch8, step871]: loss 0.022006
[epoch8, step872]: loss 0.025253
[epoch8, step873]: loss 0.025613
[epoch8, step874]: loss 0.023758
[epoch8, step875]: loss 0.024146
[epoch8, step876]: loss 0.024156
[epoch8, step877]: loss 0.019158
[epoch8, step878]: loss 0.023355
[epoch8, step879]: loss 0.027727
[epoch8, step880]: loss 0.025396
[epoch8, step881]: loss 0.022036
[epoch8, step882]: loss 0.024137
[epoch8, step883]: loss 0.024014
[epoch8, step884]: loss 0.026371
[epoch8, step885]: loss 0.025887
[epoch8, step886]: loss 0.026448
[epoch8, step887]: loss 0.024063
[epoch8, step888]: loss 0.024427
[epoch8, step889]: loss 0.023456
[epoch8, step890]: loss 0.023488
[epoch8, step891]: loss 0.025430
[epoch8, step892]: loss 0.020906
[epoch8, step893]: loss 0.024528
[epoch8, step894]: loss 0.024895
[epoch8, step895]: loss 0.022538
[epoch8, step896]: loss 0.021708
[epoch8, step897]: loss 0.023842
[epoch8, step898]: loss 0.025403
[epoch8, step899]: loss 0.027936
[epoch8, step900]: loss 0.026860
[epoch8, step901]: loss 0.025307
[epoch8, step902]: loss 0.024007
[epoch8, step903]: loss 0.024048
[epoch8, step904]: loss 0.027946
[epoch8, step905]: loss 0.027321
[epoch8, step906]: loss 0.022321
[epoch8, step907]: loss 0.023561
[epoch8, step908]: loss 0.022417
[epoch8, step909]: loss 0.025356
[epoch8, step910]: loss 0.022986
[epoch8, step911]: loss 0.025245
[epoch8, step912]: loss 0.023826
[epoch8, step913]: loss 0.023878
[epoch8, step914]: loss 0.030451
[epoch8, step915]: loss 0.023964
[epoch8, step916]: loss 0.023722
[epoch8, step917]: loss 0.024908
[epoch8, step918]: loss 0.028524
[epoch8, step919]: loss 0.024167
[epoch8, step920]: loss 0.027556
[epoch8, step921]: loss 0.024472
[epoch8, step922]: loss 0.023213
[epoch8, step923]: loss 0.022521
[epoch8, step924]: loss 0.021169
[epoch8, step925]: loss 0.025284
[epoch8, step926]: loss 0.026411
[epoch8, step927]: loss 0.025615
[epoch8, step928]: loss 0.024805
[epoch8, step929]: loss 0.027536
[epoch8, step930]: loss 0.025653
[epoch8, step931]: loss 0.027127
[epoch8, step932]: loss 0.021724
[epoch8, step933]: loss 0.027989
[epoch8, step934]: loss 0.022027
[epoch8, step935]: loss 0.021979
[epoch8, step936]: loss 0.022406
[epoch8, step937]: loss 0.027107
[epoch8, step938]: loss 0.025049
[epoch8, step939]: loss 0.020667
[epoch8, step940]: loss 0.022715
[epoch8, step941]: loss 0.026813
[epoch8, step942]: loss 0.025429
[epoch8, step943]: loss 0.022898
[epoch8, step944]: loss 0.027544
[epoch8, step945]: loss 0.020465
[epoch8, step946]: loss 0.025494
[epoch8, step947]: loss 0.028064
[epoch8, step948]: loss 0.019205
[epoch8, step949]: loss 0.022866
[epoch8, step950]: loss 0.026575
[epoch8, step951]: loss 0.028436
[epoch8, step952]: loss 0.025007
[epoch8, step953]: loss 0.027511
[epoch8, step954]: loss 0.022226
[epoch8, step955]: loss 0.036678
[epoch8, step956]: loss 0.051894
[epoch8, step957]: loss 0.046126
[epoch8, step958]: loss 0.043680
[epoch8, step959]: loss 0.047180
[epoch8, step960]: loss 0.043510
[epoch8, step961]: loss 0.043843
[epoch8, step962]: loss 0.042147
[epoch8, step963]: loss 0.039388
[epoch8, step964]: loss 0.039237
[epoch8, step965]: loss 0.039562
[epoch8, step966]: loss 0.037434
[epoch8, step967]: loss 0.036447
[epoch8, step968]: loss 0.039076
[epoch8, step969]: loss 0.038619
[epoch8, step970]: loss 0.038118
[epoch8, step971]: loss 0.036288
[epoch8, step972]: loss 0.038361
[epoch8, step973]: loss 0.037862
[epoch8, step974]: loss 0.039765
[epoch8, step975]: loss 0.036881
[epoch8, step976]: loss 0.036302
[epoch8, step977]: loss 0.039745
[epoch8, step978]: loss 0.038406
[epoch8, step979]: loss 0.037355
[epoch8, step980]: loss 0.036027
[epoch8, step981]: loss 0.038184
[epoch8, step982]: loss 0.038099
[epoch8, step983]: loss 0.039418
[epoch8, step984]: loss 0.035711
[epoch8, step985]: loss 0.036224
[epoch8, step986]: loss 0.040864
[epoch8, step987]: loss 0.038474
[epoch8, step988]: loss 0.037943
[epoch8, step989]: loss 0.036909
[epoch8, step990]: loss 0.037813
[epoch8, step991]: loss 0.038694
[epoch8, step992]: loss 0.038835
[epoch8, step993]: loss 0.036481
[epoch8, step994]: loss 0.035890
[epoch8, step995]: loss 0.039497
[epoch8, step996]: loss 0.037951
[epoch8, step997]: loss 0.037735
[epoch8, step998]: loss 0.037108
[epoch8, step999]: loss 0.038577
[epoch8, step1000]: loss 0.038247
[epoch8, step1001]: loss 0.039195
[epoch8, step1002]: loss 0.036771
[epoch8, step1003]: loss 0.035951
[epoch8, step1004]: loss 0.039993
[epoch8, step1005]: loss 0.037288
[epoch8, step1006]: loss 0.037638
[epoch8, step1007]: loss 0.035910
[epoch8, step1008]: loss 0.037417
[epoch8, step1009]: loss 0.037883
[epoch8, step1010]: loss 0.039552
[epoch8, step1011]: loss 0.036353
[epoch8, step1012]: loss 0.036578
[epoch8, step1013]: loss 0.039554
[epoch8, step1014]: loss 0.038585
[epoch8, step1015]: loss 0.038009
[epoch8, step1016]: loss 0.035944
[epoch8, step1017]: loss 0.037621
[epoch8, step1018]: loss 0.037790
[epoch8, step1019]: loss 0.039309
[epoch8, step1020]: loss 0.036037
[epoch8, step1021]: loss 0.035762
[epoch8, step1022]: loss 0.039240
[epoch8, step1023]: loss 0.037812
[epoch8, step1024]: loss 0.038224
[epoch8, step1025]: loss 0.035690
[epoch8, step1026]: loss 0.037001
[epoch8, step1027]: loss 0.037498
[epoch8, step1028]: loss 0.038887
[epoch8, step1029]: loss 0.036000
[epoch8, step1030]: loss 0.035558
[epoch8, step1031]: loss 0.038205
[epoch8, step1032]: loss 0.038157
[epoch8, step1033]: loss 0.037299
[epoch8, step1034]: loss 0.035832
[epoch8, step1035]: loss 0.037168
[epoch8, step1036]: loss 0.037942
[epoch8, step1037]: loss 0.038708
[epoch8, step1038]: loss 0.036081
[epoch8, step1039]: loss 0.036110
[epoch8, step1040]: loss 0.038620
[epoch8, step1041]: loss 0.037485
[epoch8, step1042]: loss 0.036470
[epoch8, step1043]: loss 0.035842
[epoch8, step1044]: loss 0.037682
[epoch8, step1045]: loss 0.037893
[epoch8, step1046]: loss 0.039123
[epoch8, step1047]: loss 0.036257
[epoch8, step1048]: loss 0.035669
[epoch8, step1049]: loss 0.039237
[epoch8, step1050]: loss 0.038144
[epoch8, step1051]: loss 0.037707
[epoch8, step1052]: loss 0.036500
[epoch8, step1053]: loss 0.038051
[epoch8, step1054]: loss 0.037875
[epoch8, step1055]: loss 0.038240
[epoch8, step1056]: loss 0.035601
[epoch8, step1057]: loss 0.036421
[epoch8, step1058]: loss 0.039931
[epoch8, step1059]: loss 0.037948
[epoch8, step1060]: loss 0.037535
[epoch8, step1061]: loss 0.035398
[epoch8, step1062]: loss 0.037948
[epoch8, step1063]: loss 0.037751
[epoch8, step1064]: loss 0.039020
[epoch8, step1065]: loss 0.036063
[epoch8, step1066]: loss 0.035736
[epoch8, step1067]: loss 0.039210
[epoch8, step1068]: loss 0.036518
[epoch8, step1069]: loss 0.036890
[epoch8, step1070]: loss 0.035900
[epoch8, step1071]: loss 0.038090
[epoch8, step1072]: loss 0.038476
[epoch8, step1073]: loss 0.038733
[epoch8, step1074]: loss 0.036325
[epoch8, step1075]: loss 0.036144
[epoch8, step1076]: loss 0.039141
[epoch8, step1077]: loss 0.037666
[epoch8, step1078]: loss 0.037184
[epoch8, step1079]: loss 0.036952
[epoch8, step1080]: loss 0.037813
[epoch8, step1081]: loss 0.037472
[epoch8, step1082]: loss 0.038834
[epoch8, step1083]: loss 0.036892
[epoch8, step1084]: loss 0.036152
[epoch8, step1085]: loss 0.038698
[epoch8, step1086]: loss 0.037316
[epoch8, step1087]: loss 0.037476
[epoch8, step1088]: loss 0.035754
[epoch8, step1089]: loss 0.037918
[epoch8, step1090]: loss 0.038288
[epoch8, step1091]: loss 0.039047
[epoch8, step1092]: loss 0.035920
[epoch8, step1093]: loss 0.035875
[epoch8, step1094]: loss 0.038141
[epoch8, step1095]: loss 0.037241
[epoch8, step1096]: loss 0.036939
[epoch8, step1097]: loss 0.035970
[epoch8, step1098]: loss 0.037670
[epoch8, step1099]: loss 0.037363
[epoch8, step1100]: loss 0.039453
[epoch8, step1101]: loss 0.036570
[epoch8, step1102]: loss 0.035801
[epoch8, step1103]: loss 0.038605
[epoch8, step1104]: loss 0.037443
[epoch8, step1105]: loss 0.037548
[epoch8, step1106]: loss 0.034974
[epoch8, step1107]: loss 0.037819
[epoch8, step1108]: loss 0.037352
[epoch8, step1109]: loss 0.039234
[epoch8, step1110]: loss 0.036759
[epoch8, step1111]: loss 0.036156
[epoch8, step1112]: loss 0.039505
[epoch8, step1113]: loss 0.037336
[epoch8, step1114]: loss 0.037860
[epoch8, step1115]: loss 0.036078
[epoch8, step1116]: loss 0.037786
[epoch8, step1117]: loss 0.037819
[epoch8, step1118]: loss 0.038730
[epoch8, step1119]: loss 0.035956
[epoch8, step1120]: loss 0.035746
[epoch8, step1121]: loss 0.039004
[epoch8, step1122]: loss 0.037121
[epoch8, step1123]: loss 0.036686
[epoch8, step1124]: loss 0.036635
[epoch8, step1125]: loss 0.038035
[epoch8, step1126]: loss 0.038673
[epoch8, step1127]: loss 0.038987
[epoch8, step1128]: loss 0.036362
[epoch8, step1129]: loss 0.035782
[epoch8, step1130]: loss 0.039835
[epoch8, step1131]: loss 0.037955
[epoch8, step1132]: loss 0.037856
[epoch8, step1133]: loss 0.035524
[epoch8, step1134]: loss 0.037395
[epoch8, step1135]: loss 0.038678
[epoch8, step1136]: loss 0.039459
[epoch8, step1137]: loss 0.036227
[epoch8, step1138]: loss 0.035986
[epoch8, step1139]: loss 0.039057
[epoch8, step1140]: loss 0.036922
[epoch8, step1141]: loss 0.037016
[epoch8, step1142]: loss 0.035704
[epoch8, step1143]: loss 0.037156
[epoch8, step1144]: loss 0.037879
[epoch8, step1145]: loss 0.038446
[epoch8, step1146]: loss 0.035856
[epoch8, step1147]: loss 0.036728
[epoch8, step1148]: loss 0.039275
[epoch8, step1149]: loss 0.037256
[epoch8, step1150]: loss 0.037198
[epoch8, step1151]: loss 0.036330
[epoch8, step1152]: loss 0.038065
[epoch8, step1153]: loss 0.037121
[epoch8, step1154]: loss 0.039062
[epoch8, step1155]: loss 0.036241
[epoch8, step1156]: loss 0.035181
[epoch8, step1157]: loss 0.038795
[epoch8, step1158]: loss 0.037760
[epoch8, step1159]: loss 0.037443
[epoch8, step1160]: loss 0.036739
[epoch8, step1161]: loss 0.038118
[epoch8, step1162]: loss 0.037670
[epoch8, step1163]: loss 0.038362
[epoch8, step1164]: loss 0.036252
[epoch8, step1165]: loss 0.036964
[epoch8, step1166]: loss 0.039308
[epoch8, step1167]: loss 0.036783
[epoch8, step1168]: loss 0.037582
[epoch8, step1169]: loss 0.035731
[epoch8, step1170]: loss 0.037610
[epoch8, step1171]: loss 0.037639
[epoch8, step1172]: loss 0.038738
[epoch8, step1173]: loss 0.036224
[epoch8, step1174]: loss 0.036204
[epoch8, step1175]: loss 0.038876
[epoch8, step1176]: loss 0.037188
[epoch8, step1177]: loss 0.037528
[epoch8, step1178]: loss 0.036028
[epoch8, step1179]: loss 0.037632
[epoch8, step1180]: loss 0.037797
[epoch8, step1181]: loss 0.039516
[epoch8, step1182]: loss 0.035527
[epoch8, step1183]: loss 0.036393
[epoch8, step1184]: loss 0.038609
[epoch8, step1185]: loss 0.037567
[epoch8, step1186]: loss 0.036616
[epoch8, step1187]: loss 0.035071
[epoch8, step1188]: loss 0.036900
[epoch8, step1189]: loss 0.037372
[epoch8, step1190]: loss 0.038230
[epoch8, step1191]: loss 0.036653
[epoch8, step1192]: loss 0.035928
[epoch8, step1193]: loss 0.038860
[epoch8, step1194]: loss 0.037315
[epoch8, step1195]: loss 0.036084
[epoch8, step1196]: loss 0.035205
[epoch8, step1197]: loss 0.037897
[epoch8, step1198]: loss 0.037631
[epoch8, step1199]: loss 0.038573
[epoch8, step1200]: loss 0.035879
[epoch8, step1201]: loss 0.036406
[epoch8, step1202]: loss 0.040017
[epoch8, step1203]: loss 0.037522
[epoch8, step1204]: loss 0.036681
[epoch8, step1205]: loss 0.035390
[epoch8, step1206]: loss 0.036959
[epoch8, step1207]: loss 0.037919
[epoch8, step1208]: loss 0.038944
[epoch8, step1209]: loss 0.034911
[epoch8, step1210]: loss 0.036168
[epoch8, step1211]: loss 0.038587
[epoch8, step1212]: loss 0.037168
[epoch8, step1213]: loss 0.036714
[epoch8, step1214]: loss 0.036018
[epoch8, step1215]: loss 0.038080
[epoch8, step1216]: loss 0.037168
[epoch8, step1217]: loss 0.039383
[epoch8, step1218]: loss 0.035623
[epoch8, step1219]: loss 0.036593
[epoch8, step1220]: loss 0.039368
[epoch8, step1221]: loss 0.036479
[epoch8, step1222]: loss 0.037416
[epoch8, step1223]: loss 0.035860
[epoch8, step1224]: loss 0.037904
[epoch8, step1225]: loss 0.037630
[epoch8, step1226]: loss 0.038286
[epoch8, step1227]: loss 0.035979
[epoch8, step1228]: loss 0.035445
[epoch8, step1229]: loss 0.038653
[epoch8, step1230]: loss 0.037574
[epoch8, step1231]: loss 0.036930
[epoch8, step1232]: loss 0.036825
[epoch8, step1233]: loss 0.037392
[epoch8, step1234]: loss 0.037274
[epoch8, step1235]: loss 0.039318
[epoch8, step1236]: loss 0.036268
[epoch8, step1237]: loss 0.035486
[epoch8, step1238]: loss 0.038485
[epoch8, step1239]: loss 0.037926
[epoch8, step1240]: loss 0.037593
[epoch8, step1241]: loss 0.035535
[epoch8, step1242]: loss 0.037359
[epoch8, step1243]: loss 0.037495
[epoch8, step1244]: loss 0.038662
[epoch8, step1245]: loss 0.036280
[epoch8, step1246]: loss 0.035889
[epoch8, step1247]: loss 0.037978
[epoch8, step1248]: loss 0.037386
[epoch8, step1249]: loss 0.037466
[epoch8, step1250]: loss 0.035597
[epoch8, step1251]: loss 0.037673
[epoch8, step1252]: loss 0.038445
[epoch8, step1253]: loss 0.038869
[epoch8, step1254]: loss 0.036042
[epoch8, step1255]: loss 0.036077
[epoch8, step1256]: loss 0.039300
[epoch8, step1257]: loss 0.037622
[epoch8, step1258]: loss 0.037411
[epoch8, step1259]: loss 0.035699
[epoch8, step1260]: loss 0.037564
[epoch8, step1261]: loss 0.037340
[epoch8, step1262]: loss 0.037612
[epoch8, step1263]: loss 0.036448
[epoch8, step1264]: loss 0.035642
[epoch8, step1265]: loss 0.037686
[epoch8, step1266]: loss 0.037238
[epoch8, step1267]: loss 0.037342
[epoch8, step1268]: loss 0.035807
[epoch8, step1269]: loss 0.037470
[epoch8, step1270]: loss 0.036746
[epoch8, step1271]: loss 0.039038
[epoch8, step1272]: loss 0.035984
[epoch8, step1273]: loss 0.035528
[epoch8, step1274]: loss 0.038835
[epoch8, step1275]: loss 0.037610
[epoch8, step1276]: loss 0.036798
[epoch8, step1277]: loss 0.035528
[epoch8, step1278]: loss 0.037924
[epoch8, step1279]: loss 0.037703
[epoch8, step1280]: loss 0.038765
[epoch8, step1281]: loss 0.035678
[epoch8, step1282]: loss 0.035561
[epoch8, step1283]: loss 0.038123
[epoch8, step1284]: loss 0.036628
[epoch8, step1285]: loss 0.037493
[epoch8, step1286]: loss 0.034838
[epoch8, step1287]: loss 0.037959
[epoch8, step1288]: loss 0.038079
[epoch8, step1289]: loss 0.039264
[epoch8, step1290]: loss 0.035788
[epoch8, step1291]: loss 0.035212
[epoch8, step1292]: loss 0.039263
[epoch8, step1293]: loss 0.036247
[epoch8, step1294]: loss 0.036738
[epoch8, step1295]: loss 0.035911
[epoch8, step1296]: loss 0.037402
[epoch8, step1297]: loss 0.037264
[epoch8, step1298]: loss 0.039006
[epoch8, step1299]: loss 0.035805
[epoch8, step1300]: loss 0.036177
[epoch8, step1301]: loss 0.037717
[epoch8, step1302]: loss 0.037297
[epoch8, step1303]: loss 0.036955
[epoch8, step1304]: loss 0.034978
[epoch8, step1305]: loss 0.037511
[epoch8, step1306]: loss 0.036987
[epoch8, step1307]: loss 0.037880
[epoch8, step1308]: loss 0.035911
[epoch8, step1309]: loss 0.035046
[epoch8, step1310]: loss 0.038799
[epoch8, step1311]: loss 0.036338
[epoch8, step1312]: loss 0.037660
[epoch8, step1313]: loss 0.035437
[epoch8, step1314]: loss 0.037245
[epoch8, step1315]: loss 0.037102
[epoch8, step1316]: loss 0.039398
[epoch8, step1317]: loss 0.035313
[epoch8, step1318]: loss 0.035020
[epoch8, step1319]: loss 0.037998
[epoch8, step1320]: loss 0.037061
[epoch8, step1321]: loss 0.037024
[epoch8, step1322]: loss 0.035067
[epoch8, step1323]: loss 0.037391
[epoch8, step1324]: loss 0.036766
[epoch8, step1325]: loss 0.038138
[epoch8, step1326]: loss 0.035239
[epoch8, step1327]: loss 0.035290
[epoch8, step1328]: loss 0.038446
[epoch8, step1329]: loss 0.036737
[epoch8, step1330]: loss 0.036998
[epoch8, step1331]: loss 0.034918
[epoch8, step1332]: loss 0.036922
[epoch8, step1333]: loss 0.036159
[epoch8, step1334]: loss 0.043095
[epoch8, step1335]: loss 0.041892
[epoch8, step1336]: loss 0.040476
[epoch8, step1337]: loss 0.041996
[epoch8, step1338]: loss 0.040546
[epoch8, step1339]: loss 0.040129
[epoch8, step1340]: loss 0.038418
[epoch8, step1341]: loss 0.040203
[epoch8, step1342]: loss 0.039799
[epoch8, step1343]: loss 0.040847
[epoch8, step1344]: loss 0.038475
[epoch8, step1345]: loss 0.038860
[epoch8, step1346]: loss 0.040413
[epoch8, step1347]: loss 0.039571
[epoch8, step1348]: loss 0.038634
[epoch8, step1349]: loss 0.038532
[epoch8, step1350]: loss 0.039396
[epoch8, step1351]: loss 0.038780
[epoch8, step1352]: loss 0.039594
[epoch8, step1353]: loss 0.037644
[epoch8, step1354]: loss 0.037182
[epoch8, step1355]: loss 0.040220
[epoch8, step1356]: loss 0.038512
[epoch8, step1357]: loss 0.037518
[epoch8, step1358]: loss 0.036489
[epoch8, step1359]: loss 0.038025
[epoch8, step1360]: loss 0.037875
[epoch8, step1361]: loss 0.038889
[epoch8, step1362]: loss 0.036323
[epoch8, step1363]: loss 0.039003
[epoch8, step1364]: loss 0.041168
[epoch8, step1365]: loss 0.036452
[epoch8, step1366]: loss 0.035627
[epoch8, step1367]: loss 0.034806
[epoch8, step1368]: loss 0.037108
[epoch8, step1369]: loss 0.037181
[epoch8, step1370]: loss 0.037998
[epoch8, step1371]: loss 0.035046
[epoch8, step1372]: loss 0.034961
[epoch8, step1373]: loss 0.038454
[epoch8, step1374]: loss 0.037042
[epoch8, step1375]: loss 0.037955
[epoch8, step1376]: loss 0.034159
[epoch8, step1377]: loss 0.035885
[epoch8, step1378]: loss 0.036487
[epoch8, step1379]: loss 0.037051
[epoch8, step1380]: loss 0.035301
[epoch8, step1381]: loss 0.034214
[epoch8, step1382]: loss 0.037675
[epoch8, step1383]: loss 0.036199
[epoch8, step1384]: loss 0.035758
[epoch8, step1385]: loss 0.033895
[epoch8, step1386]: loss 0.036401
[epoch8, step1387]: loss 0.036516
[epoch8, step1388]: loss 0.036939
[epoch8, step1389]: loss 0.034808
[epoch8, step1390]: loss 0.035224
[epoch8, step1391]: loss 0.037888
[epoch8, step1392]: loss 0.036471
[epoch8, step1393]: loss 0.035720
[epoch8, step1394]: loss 0.035128
[epoch8, step1395]: loss 0.036704
[epoch8, step1396]: loss 0.036199
[epoch8, step1397]: loss 0.037676
[epoch8, step1398]: loss 0.035002
[epoch8, step1399]: loss 0.034925
[epoch8, step1400]: loss 0.037893
[epoch8, step1401]: loss 0.036084
[epoch8, step1402]: loss 0.035639
[epoch8, step1403]: loss 0.033111
[epoch8, step1404]: loss 0.036084
[epoch8, step1405]: loss 0.036769
[epoch8, step1406]: loss 0.036863
[epoch8, step1407]: loss 0.035428
[epoch8, step1408]: loss 0.034442
[epoch8, step1409]: loss 0.037619
[epoch8, step1410]: loss 0.036262
[epoch8, step1411]: loss 0.035134
[epoch8, step1412]: loss 0.034097
[epoch8, step1413]: loss 0.036260
[epoch8, step1414]: loss 0.035746
[epoch8, step1415]: loss 0.037053
[epoch8, step1416]: loss 0.034696
[epoch8, step1417]: loss 0.034655
[epoch8, step1418]: loss 0.038179
[epoch8, step1419]: loss 0.037006
[epoch8, step1420]: loss 0.036543
[epoch8, step1421]: loss 0.034793
[epoch8, step1422]: loss 0.036815
[epoch8, step1423]: loss 0.035578
[epoch8, step1424]: loss 0.038604
[epoch8, step1425]: loss 0.033934
[epoch8, step1426]: loss 0.036401
[epoch8, step1427]: loss 0.040787
[epoch8, step1428]: loss 0.038957
[epoch8, step1429]: loss 0.036032
[epoch8, step1430]: loss 0.034474
[epoch8, step1431]: loss 0.036982
[epoch8, step1432]: loss 0.036713
[epoch8, step1433]: loss 0.038347
[epoch8, step1434]: loss 0.034972
[epoch8, step1435]: loss 0.035412
[epoch8, step1436]: loss 0.038345
[epoch8, step1437]: loss 0.036685
[epoch8, step1438]: loss 0.037858
[epoch8, step1439]: loss 0.034368
[epoch8, step1440]: loss 0.036441
[epoch8, step1441]: loss 0.036730
[epoch8, step1442]: loss 0.037037
[epoch8, step1443]: loss 0.034452
[epoch8, step1444]: loss 0.033782
[epoch8, step1445]: loss 0.038880
[epoch8, step1446]: loss 0.036272
[epoch8, step1447]: loss 0.036427
[epoch8, step1448]: loss 0.034350
[epoch8, step1449]: loss 0.036081
[epoch8, step1450]: loss 0.036614
[epoch8, step1451]: loss 0.037972
[epoch8, step1452]: loss 0.034804
[epoch8, step1453]: loss 0.035372
[epoch8, step1454]: loss 0.037917
[epoch8, step1455]: loss 0.037068
[epoch8, step1456]: loss 0.035741
[epoch8, step1457]: loss 0.034395
[epoch8, step1458]: loss 0.036321
[epoch8, step1459]: loss 0.036485
[epoch8, step1460]: loss 0.038118
[epoch8, step1461]: loss 0.035163
[epoch8, step1462]: loss 0.035067
[epoch8, step1463]: loss 0.037448
[epoch8, step1464]: loss 0.035918
[epoch8, step1465]: loss 0.035138
[epoch8, step1466]: loss 0.034085
[epoch8, step1467]: loss 0.036366
[epoch8, step1468]: loss 0.035853
[epoch8, step1469]: loss 0.037296
[epoch8, step1470]: loss 0.034835
[epoch8, step1471]: loss 0.034403
[epoch8, step1472]: loss 0.037751
[epoch8, step1473]: loss 0.035970
[epoch8, step1474]: loss 0.036204
[epoch8, step1475]: loss 0.034039
[epoch8, step1476]: loss 0.037264
[epoch8, step1477]: loss 0.035788
[epoch8, step1478]: loss 0.037130
[epoch8, step1479]: loss 0.034095
[epoch8, step1480]: loss 0.034063
[epoch8, step1481]: loss 0.036585
[epoch8, step1482]: loss 0.036953
[epoch8, step1483]: loss 0.036491
[epoch8, step1484]: loss 0.035001
[epoch8, step1485]: loss 0.036178
[epoch8, step1486]: loss 0.035739
[epoch8, step1487]: loss 0.037755
[epoch8, step1488]: loss 0.035264
[epoch8, step1489]: loss 0.034452
[epoch8, step1490]: loss 0.037672
[epoch8, step1491]: loss 0.035805
[epoch8, step1492]: loss 0.035444
[epoch8, step1493]: loss 0.035794
[epoch8, step1494]: loss 0.036095
[epoch8, step1495]: loss 0.036101
[epoch8, step1496]: loss 0.037381
[epoch8, step1497]: loss 0.035016
[epoch8, step1498]: loss 0.034884
[epoch8, step1499]: loss 0.037725
[epoch8, step1500]: loss 0.036375
[epoch8, step1501]: loss 0.035785
[epoch8, step1502]: loss 0.033825
[epoch8, step1503]: loss 0.036486
[epoch8, step1504]: loss 0.035908
[epoch8, step1505]: loss 0.038193
[epoch8, step1506]: loss 0.033789
[epoch8, step1507]: loss 0.034573
[epoch8, step1508]: loss 0.038070
[epoch8, step1509]: loss 0.035922
[epoch8, step1510]: loss 0.035744
[epoch8, step1511]: loss 0.034923
[epoch8, step1512]: loss 0.036559
[epoch8, step1513]: loss 0.035346
[epoch8, step1514]: loss 0.037425
[epoch8, step1515]: loss 0.034755
[epoch8, step1516]: loss 0.033952

[epoch8]: avg loss 0.033897

[epoch9, step1]: loss 0.030580
[epoch9, step2]: loss 0.037172
[epoch9, step3]: loss 0.036742
[epoch9, step4]: loss 0.034894
[epoch9, step5]: loss 0.034481
[epoch9, step6]: loss 0.037543
[epoch9, step7]: loss 0.034912
[epoch9, step8]: loss 0.037491
[epoch9, step9]: loss 0.033954
[epoch9, step10]: loss 0.035334
[epoch9, step11]: loss 0.037337
[epoch9, step12]: loss 0.037007
[epoch9, step13]: loss 0.034679
[epoch9, step14]: loss 0.034468
[epoch9, step15]: loss 0.037055
[epoch9, step16]: loss 0.035082
[epoch9, step17]: loss 0.037726
[epoch9, step18]: loss 0.034522
[epoch9, step19]: loss 0.034881
[epoch9, step20]: loss 0.037814
[epoch9, step21]: loss 0.036727
[epoch9, step22]: loss 0.033988
[epoch9, step23]: loss 0.034528
[epoch9, step24]: loss 0.037802
[epoch9, step25]: loss 0.034044
[epoch9, step26]: loss 0.036818
[epoch9, step27]: loss 0.033663
[epoch9, step28]: loss 0.035251
[epoch9, step29]: loss 0.037280
[epoch9, step30]: loss 0.037431
[epoch9, step31]: loss 0.034106
[epoch9, step32]: loss 0.034633
[epoch9, step33]: loss 0.037363
[epoch9, step34]: loss 0.035828
[epoch9, step35]: loss 0.037873
[epoch9, step36]: loss 0.034071
[epoch9, step37]: loss 0.035175
[epoch9, step38]: loss 0.038065
[epoch9, step39]: loss 0.037580
[epoch9, step40]: loss 0.034515
[epoch9, step41]: loss 0.034003
[epoch9, step42]: loss 0.037340
[epoch9, step43]: loss 0.034483
[epoch9, step44]: loss 0.038354
[epoch9, step45]: loss 0.034155
[epoch9, step46]: loss 0.034829
[epoch9, step47]: loss 0.037285
[epoch9, step48]: loss 0.037164
[epoch9, step49]: loss 0.033732
[epoch9, step50]: loss 0.034100
[epoch9, step51]: loss 0.037144
[epoch9, step52]: loss 0.034431
[epoch9, step53]: loss 0.037826
[epoch9, step54]: loss 0.033856
[epoch9, step55]: loss 0.034825
[epoch9, step56]: loss 0.038196
[epoch9, step57]: loss 0.037528
[epoch9, step58]: loss 0.034453
[epoch9, step59]: loss 0.034029
[epoch9, step60]: loss 0.038011
[epoch9, step61]: loss 0.034144
[epoch9, step62]: loss 0.036720
[epoch9, step63]: loss 0.033665
[epoch9, step64]: loss 0.034103
[epoch9, step65]: loss 0.037702
[epoch9, step66]: loss 0.036778
[epoch9, step67]: loss 0.034066
[epoch9, step68]: loss 0.034576
[epoch9, step69]: loss 0.036919
[epoch9, step70]: loss 0.034212
[epoch9, step71]: loss 0.036851
[epoch9, step72]: loss 0.033862
[epoch9, step73]: loss 0.035085
[epoch9, step74]: loss 0.036870
[epoch9, step75]: loss 0.037827
[epoch9, step76]: loss 0.034593
[epoch9, step77]: loss 0.034842
[epoch9, step78]: loss 0.037557
[epoch9, step79]: loss 0.034795
[epoch9, step80]: loss 0.038397
[epoch9, step81]: loss 0.034670
[epoch9, step82]: loss 0.034808
[epoch9, step83]: loss 0.037880
[epoch9, step84]: loss 0.037289
[epoch9, step85]: loss 0.035378
[epoch9, step86]: loss 0.034885
[epoch9, step87]: loss 0.038245
[epoch9, step88]: loss 0.034009
[epoch9, step89]: loss 0.037156
[epoch9, step90]: loss 0.035001
[epoch9, step91]: loss 0.034571
[epoch9, step92]: loss 0.037418
[epoch9, step93]: loss 0.037838
[epoch9, step94]: loss 0.033748
[epoch9, step95]: loss 0.034897
[epoch9, step96]: loss 0.036857
[epoch9, step97]: loss 0.035508
[epoch9, step98]: loss 0.037292
[epoch9, step99]: loss 0.034435
[epoch9, step100]: loss 0.034358
[epoch9, step101]: loss 0.037841
[epoch9, step102]: loss 0.037783
[epoch9, step103]: loss 0.034829
[epoch9, step104]: loss 0.034585
[epoch9, step105]: loss 0.037835
[epoch9, step106]: loss 0.034387
[epoch9, step107]: loss 0.037224
[epoch9, step108]: loss 0.034507
[epoch9, step109]: loss 0.033824
[epoch9, step110]: loss 0.038542
[epoch9, step111]: loss 0.037286
[epoch9, step112]: loss 0.034143
[epoch9, step113]: loss 0.034954
[epoch9, step114]: loss 0.037331
[epoch9, step115]: loss 0.034551
[epoch9, step116]: loss 0.038224
[epoch9, step117]: loss 0.034326
[epoch9, step118]: loss 0.035841
[epoch9, step119]: loss 0.037926
[epoch9, step120]: loss 0.038218
[epoch9, step121]: loss 0.034311
[epoch9, step122]: loss 0.034072
[epoch9, step123]: loss 0.037605
[epoch9, step124]: loss 0.035044
[epoch9, step125]: loss 0.037882
[epoch9, step126]: loss 0.033976
[epoch9, step127]: loss 0.034798
[epoch9, step128]: loss 0.037422
[epoch9, step129]: loss 0.037619
[epoch9, step130]: loss 0.034650
[epoch9, step131]: loss 0.034120
[epoch9, step132]: loss 0.037027
[epoch9, step133]: loss 0.034335
[epoch9, step134]: loss 0.036654
[epoch9, step135]: loss 0.035021
[epoch9, step136]: loss 0.036696
[epoch9, step137]: loss 0.037627
[epoch9, step138]: loss 0.037011
[epoch9, step139]: loss 0.035047
[epoch9, step140]: loss 0.035077
[epoch9, step141]: loss 0.038055
[epoch9, step142]: loss 0.034915
[epoch9, step143]: loss 0.037148
[epoch9, step144]: loss 0.035166
[epoch9, step145]: loss 0.034033
[epoch9, step146]: loss 0.037167
[epoch9, step147]: loss 0.040211
[epoch9, step148]: loss 0.033791
[epoch9, step149]: loss 0.034446
[epoch9, step150]: loss 0.037652
[epoch9, step151]: loss 0.034795
[epoch9, step152]: loss 0.037605
[epoch9, step153]: loss 0.034119
[epoch9, step154]: loss 0.034885
[epoch9, step155]: loss 0.037709
[epoch9, step156]: loss 0.036554
[epoch9, step157]: loss 0.033940
[epoch9, step158]: loss 0.035525
[epoch9, step159]: loss 0.037376
[epoch9, step160]: loss 0.034324
[epoch9, step161]: loss 0.037109
[epoch9, step162]: loss 0.034258
[epoch9, step163]: loss 0.034444
[epoch9, step164]: loss 0.037524
[epoch9, step165]: loss 0.037236
[epoch9, step166]: loss 0.034348
[epoch9, step167]: loss 0.034409
[epoch9, step168]: loss 0.039444
[epoch9, step169]: loss 0.033978
[epoch9, step170]: loss 0.037954
[epoch9, step171]: loss 0.034651
[epoch9, step172]: loss 0.034776
[epoch9, step173]: loss 0.037854
[epoch9, step174]: loss 0.037193
[epoch9, step175]: loss 0.034656
[epoch9, step176]: loss 0.034641
[epoch9, step177]: loss 0.037475
[epoch9, step178]: loss 0.034521
[epoch9, step179]: loss 0.036406
[epoch9, step180]: loss 0.033795
[epoch9, step181]: loss 0.034782
[epoch9, step182]: loss 0.037616
[epoch9, step183]: loss 0.037217
[epoch9, step184]: loss 0.034605
[epoch9, step185]: loss 0.034738
[epoch9, step186]: loss 0.037582
[epoch9, step187]: loss 0.034650
[epoch9, step188]: loss 0.036882
[epoch9, step189]: loss 0.033990
[epoch9, step190]: loss 0.034435
[epoch9, step191]: loss 0.037296
[epoch9, step192]: loss 0.038646
[epoch9, step193]: loss 0.032781
[epoch9, step194]: loss 0.033308
[epoch9, step195]: loss 0.037821
[epoch9, step196]: loss 0.034294
[epoch9, step197]: loss 0.037004
[epoch9, step198]: loss 0.033929
[epoch9, step199]: loss 0.034583
[epoch9, step200]: loss 0.037563
[epoch9, step201]: loss 0.037503
[epoch9, step202]: loss 0.033630
[epoch9, step203]: loss 0.035259
[epoch9, step204]: loss 0.038668
[epoch9, step205]: loss 0.034054
[epoch9, step206]: loss 0.036752
[epoch9, step207]: loss 0.033752
[epoch9, step208]: loss 0.035731
[epoch9, step209]: loss 0.037291
[epoch9, step210]: loss 0.038317
[epoch9, step211]: loss 0.034839
[epoch9, step212]: loss 0.035062
[epoch9, step213]: loss 0.038147
[epoch9, step214]: loss 0.034882
[epoch9, step215]: loss 0.037753
[epoch9, step216]: loss 0.034619
[epoch9, step217]: loss 0.034891
[epoch9, step218]: loss 0.037848
[epoch9, step219]: loss 0.037204
[epoch9, step220]: loss 0.035250
[epoch9, step221]: loss 0.034962
[epoch9, step222]: loss 0.037697
[epoch9, step223]: loss 0.034458
[epoch9, step224]: loss 0.037344
[epoch9, step225]: loss 0.034125
[epoch9, step226]: loss 0.034363
[epoch9, step227]: loss 0.036549
[epoch9, step228]: loss 0.037968
[epoch9, step229]: loss 0.033232
[epoch9, step230]: loss 0.034882
[epoch9, step231]: loss 0.037782
[epoch9, step232]: loss 0.034229
[epoch9, step233]: loss 0.036908
[epoch9, step234]: loss 0.034060
[epoch9, step235]: loss 0.034786
[epoch9, step236]: loss 0.037374
[epoch9, step237]: loss 0.036909
[epoch9, step238]: loss 0.033830
[epoch9, step239]: loss 0.033877
[epoch9, step240]: loss 0.036521
[epoch9, step241]: loss 0.036244
[epoch9, step242]: loss 0.037666
[epoch9, step243]: loss 0.035114
[epoch9, step244]: loss 0.034247
[epoch9, step245]: loss 0.037179
[epoch9, step246]: loss 0.037085
[epoch9, step247]: loss 0.034652
[epoch9, step248]: loss 0.034253
[epoch9, step249]: loss 0.037046
[epoch9, step250]: loss 0.034576
[epoch9, step251]: loss 0.037798
[epoch9, step252]: loss 0.034948
[epoch9, step253]: loss 0.033947
[epoch9, step254]: loss 0.037239
[epoch9, step255]: loss 0.037140
[epoch9, step256]: loss 0.033824
[epoch9, step257]: loss 0.034240
[epoch9, step258]: loss 0.038725
[epoch9, step259]: loss 0.034791
[epoch9, step260]: loss 0.036785
[epoch9, step261]: loss 0.034556
[epoch9, step262]: loss 0.035049
[epoch9, step263]: loss 0.037546
[epoch9, step264]: loss 0.037288
[epoch9, step265]: loss 0.034060
[epoch9, step266]: loss 0.033836
[epoch9, step267]: loss 0.036748
[epoch9, step268]: loss 0.034365
[epoch9, step269]: loss 0.037986
[epoch9, step270]: loss 0.034487
[epoch9, step271]: loss 0.034489
[epoch9, step272]: loss 0.037064
[epoch9, step273]: loss 0.036955
[epoch9, step274]: loss 0.034800
[epoch9, step275]: loss 0.033864
[epoch9, step276]: loss 0.037255
[epoch9, step277]: loss 0.034898
[epoch9, step278]: loss 0.036748
[epoch9, step279]: loss 0.033781
[epoch9, step280]: loss 0.034738
[epoch9, step281]: loss 0.036999
[epoch9, step282]: loss 0.038448
[epoch9, step283]: loss 0.033393
[epoch9, step284]: loss 0.033468
[epoch9, step285]: loss 0.038995
[epoch9, step286]: loss 0.034139
[epoch9, step287]: loss 0.038721
[epoch9, step288]: loss 0.033840
[epoch9, step289]: loss 0.035813
[epoch9, step290]: loss 0.037234
[epoch9, step291]: loss 0.036707
[epoch9, step292]: loss 0.033701
[epoch9, step293]: loss 0.033756
[epoch9, step294]: loss 0.037117
[epoch9, step295]: loss 0.033581
[epoch9, step296]: loss 0.039288
[epoch9, step297]: loss 0.034404
[epoch9, step298]: loss 0.034926
[epoch9, step299]: loss 0.036521
[epoch9, step300]: loss 0.037173
[epoch9, step301]: loss 0.034245
[epoch9, step302]: loss 0.034559
[epoch9, step303]: loss 0.037881
[epoch9, step304]: loss 0.034241
[epoch9, step305]: loss 0.036979
[epoch9, step306]: loss 0.034296
[epoch9, step307]: loss 0.034365
[epoch9, step308]: loss 0.037818
[epoch9, step309]: loss 0.037550
[epoch9, step310]: loss 0.033837
[epoch9, step311]: loss 0.034844
[epoch9, step312]: loss 0.036955
[epoch9, step313]: loss 0.034524
[epoch9, step314]: loss 0.036659
[epoch9, step315]: loss 0.035567
[epoch9, step316]: loss 0.034713
[epoch9, step317]: loss 0.037946
[epoch9, step318]: loss 0.037411
[epoch9, step319]: loss 0.033723
[epoch9, step320]: loss 0.033914
[epoch9, step321]: loss 0.036941
[epoch9, step322]: loss 0.034538
[epoch9, step323]: loss 0.036457
[epoch9, step324]: loss 0.037452
[epoch9, step325]: loss 0.035542
[epoch9, step326]: loss 0.036898
[epoch9, step327]: loss 0.036283
[epoch9, step328]: loss 0.034711
[epoch9, step329]: loss 0.033613
[epoch9, step330]: loss 0.036948
[epoch9, step331]: loss 0.034321
[epoch9, step332]: loss 0.036284
[epoch9, step333]: loss 0.034173
[epoch9, step334]: loss 0.034857
[epoch9, step335]: loss 0.037183
[epoch9, step336]: loss 0.038097
[epoch9, step337]: loss 0.034747
[epoch9, step338]: loss 0.034429
[epoch9, step339]: loss 0.037848
[epoch9, step340]: loss 0.035090
[epoch9, step341]: loss 0.037607
[epoch9, step342]: loss 0.034303
[epoch9, step343]: loss 0.035316
[epoch9, step344]: loss 0.036697
[epoch9, step345]: loss 0.036154
[epoch9, step346]: loss 0.034508
[epoch9, step347]: loss 0.035011
[epoch9, step348]: loss 0.038267
[epoch9, step349]: loss 0.035075
[epoch9, step350]: loss 0.037294
[epoch9, step351]: loss 0.034129
[epoch9, step352]: loss 0.034792
[epoch9, step353]: loss 0.037802
[epoch9, step354]: loss 0.037090
[epoch9, step355]: loss 0.034182
[epoch9, step356]: loss 0.036005
[epoch9, step357]: loss 0.038432
[epoch9, step358]: loss 0.033666
[epoch9, step359]: loss 0.038594
[epoch9, step360]: loss 0.033863
[epoch9, step361]: loss 0.034919
[epoch9, step362]: loss 0.038158
[epoch9, step363]: loss 0.036991
[epoch9, step364]: loss 0.033985
[epoch9, step365]: loss 0.034300
[epoch9, step366]: loss 0.038113
[epoch9, step367]: loss 0.034527
[epoch9, step368]: loss 0.036724
[epoch9, step369]: loss 0.033937
[epoch9, step370]: loss 0.035148
[epoch9, step371]: loss 0.037664
[epoch9, step372]: loss 0.036715
[epoch9, step373]: loss 0.033732
[epoch9, step374]: loss 0.033749
[epoch9, step375]: loss 0.037657
[epoch9, step376]: loss 0.034791
[epoch9, step377]: loss 0.037100
[epoch9, step378]: loss 0.035090
[epoch9, step379]: loss 0.034454
[epoch9, step380]: loss 0.037669
[epoch9, step381]: loss 0.037137
[epoch9, step382]: loss 0.034856
[epoch9, step383]: loss 0.034320
[epoch9, step384]: loss 0.037541
[epoch9, step385]: loss 0.033981
[epoch9, step386]: loss 0.037051
[epoch9, step387]: loss 0.034112
[epoch9, step388]: loss 0.035417
[epoch9, step389]: loss 0.037560
[epoch9, step390]: loss 0.038404
[epoch9, step391]: loss 0.033531
[epoch9, step392]: loss 0.034348
[epoch9, step393]: loss 0.037552
[epoch9, step394]: loss 0.034191
[epoch9, step395]: loss 0.036805
[epoch9, step396]: loss 0.034109
[epoch9, step397]: loss 0.034235
[epoch9, step398]: loss 0.037092
[epoch9, step399]: loss 0.037103
[epoch9, step400]: loss 0.033484
[epoch9, step401]: loss 0.033686
[epoch9, step402]: loss 0.037157
[epoch9, step403]: loss 0.034431
[epoch9, step404]: loss 0.037990
[epoch9, step405]: loss 0.034062
[epoch9, step406]: loss 0.034860
[epoch9, step407]: loss 0.037474
[epoch9, step408]: loss 0.037058
[epoch9, step409]: loss 0.035640
[epoch9, step410]: loss 0.034454
[epoch9, step411]: loss 0.037176
[epoch9, step412]: loss 0.034453
[epoch9, step413]: loss 0.037043
[epoch9, step414]: loss 0.034442
[epoch9, step415]: loss 0.034015
[epoch9, step416]: loss 0.036567
[epoch9, step417]: loss 0.037335
[epoch9, step418]: loss 0.035221
[epoch9, step419]: loss 0.033017
[epoch9, step420]: loss 0.037452
[epoch9, step421]: loss 0.034039
[epoch9, step422]: loss 0.036962
[epoch9, step423]: loss 0.034159
[epoch9, step424]: loss 0.035075
[epoch9, step425]: loss 0.037284
[epoch9, step426]: loss 0.037305
[epoch9, step427]: loss 0.034619
[epoch9, step428]: loss 0.034578
[epoch9, step429]: loss 0.038052
[epoch9, step430]: loss 0.035135
[epoch9, step431]: loss 0.037263
[epoch9, step432]: loss 0.033815
[epoch9, step433]: loss 0.035824
[epoch9, step434]: loss 0.037043
[epoch9, step435]: loss 0.037511
[epoch9, step436]: loss 0.033791
[epoch9, step437]: loss 0.034380
[epoch9, step438]: loss 0.037431
[epoch9, step439]: loss 0.034504
[epoch9, step440]: loss 0.037033
[epoch9, step441]: loss 0.033893
[epoch9, step442]: loss 0.033916
[epoch9, step443]: loss 0.037580
[epoch9, step444]: loss 0.036202
[epoch9, step445]: loss 0.034002
[epoch9, step446]: loss 0.034023
[epoch9, step447]: loss 0.037221
[epoch9, step448]: loss 0.034773
[epoch9, step449]: loss 0.037139
[epoch9, step450]: loss 0.034485
[epoch9, step451]: loss 0.034644
[epoch9, step452]: loss 0.037098
[epoch9, step453]: loss 0.036684
[epoch9, step454]: loss 0.033616
[epoch9, step455]: loss 0.034885
[epoch9, step456]: loss 0.036808
[epoch9, step457]: loss 0.035093
[epoch9, step458]: loss 0.036363
[epoch9, step459]: loss 0.034348
[epoch9, step460]: loss 0.034658
[epoch9, step461]: loss 0.037315
[epoch9, step462]: loss 0.036599
[epoch9, step463]: loss 0.033899
[epoch9, step464]: loss 0.033833
[epoch9, step465]: loss 0.039789
[epoch9, step466]: loss 0.034200
[epoch9, step467]: loss 0.036721
[epoch9, step468]: loss 0.034268
[epoch9, step469]: loss 0.034134
[epoch9, step470]: loss 0.036727
[epoch9, step471]: loss 0.037069
[epoch9, step472]: loss 0.034751
[epoch9, step473]: loss 0.033383
[epoch9, step474]: loss 0.037038
[epoch9, step475]: loss 0.034510
[epoch9, step476]: loss 0.037270
[epoch9, step477]: loss 0.034076
[epoch9, step478]: loss 0.033559
[epoch9, step479]: loss 0.037481
[epoch9, step480]: loss 0.036637
[epoch9, step481]: loss 0.033543
[epoch9, step482]: loss 0.033562
[epoch9, step483]: loss 0.037636
[epoch9, step484]: loss 0.034951
[epoch9, step485]: loss 0.037318
[epoch9, step486]: loss 0.034433
[epoch9, step487]: loss 0.034228
[epoch9, step488]: loss 0.037813
[epoch9, step489]: loss 0.036749
[epoch9, step490]: loss 0.034502
[epoch9, step491]: loss 0.034402
[epoch9, step492]: loss 0.037096
[epoch9, step493]: loss 0.034020
[epoch9, step494]: loss 0.036595
[epoch9, step495]: loss 0.036092
[epoch9, step496]: loss 0.034635
[epoch9, step497]: loss 0.037578
[epoch9, step498]: loss 0.036620
[epoch9, step499]: loss 0.034223
[epoch9, step500]: loss 0.033756
[epoch9, step501]: loss 0.036674
[epoch9, step502]: loss 0.033568
[epoch9, step503]: loss 0.037600
[epoch9, step504]: loss 0.034523
[epoch9, step505]: loss 0.033598
[epoch9, step506]: loss 0.038221
[epoch9, step507]: loss 0.038226
[epoch9, step508]: loss 0.034725
[epoch9, step509]: loss 0.034211
[epoch9, step510]: loss 0.037684
[epoch9, step511]: loss 0.034632
[epoch9, step512]: loss 0.037655
[epoch9, step513]: loss 0.034855
[epoch9, step514]: loss 0.034567
[epoch9, step515]: loss 0.037317
[epoch9, step516]: loss 0.036886
[epoch9, step517]: loss 0.033946
[epoch9, step518]: loss 0.033897
[epoch9, step519]: loss 0.037362
[epoch9, step520]: loss 0.033732
[epoch9, step521]: loss 0.036778
[epoch9, step522]: loss 0.033953
[epoch9, step523]: loss 0.033854
[epoch9, step524]: loss 0.036704
[epoch9, step525]: loss 0.037405
[epoch9, step526]: loss 0.034087
[epoch9, step527]: loss 0.033859
[epoch9, step528]: loss 0.037165
[epoch9, step529]: loss 0.033888
[epoch9, step530]: loss 0.037987
[epoch9, step531]: loss 0.034128
[epoch9, step532]: loss 0.034600
[epoch9, step533]: loss 0.038955
[epoch9, step534]: loss 0.036276
[epoch9, step535]: loss 0.035044
[epoch9, step536]: loss 0.033956
[epoch9, step537]: loss 0.037284
[epoch9, step538]: loss 0.034648
[epoch9, step539]: loss 0.036704
[epoch9, step540]: loss 0.034557
[epoch9, step541]: loss 0.034000
[epoch9, step542]: loss 0.036890
[epoch9, step543]: loss 0.036675
[epoch9, step544]: loss 0.033848
[epoch9, step545]: loss 0.033680
[epoch9, step546]: loss 0.038514
[epoch9, step547]: loss 0.034230
[epoch9, step548]: loss 0.036856
[epoch9, step549]: loss 0.034450
[epoch9, step550]: loss 0.034261
[epoch9, step551]: loss 0.037746
[epoch9, step552]: loss 0.036880
[epoch9, step553]: loss 0.034334
[epoch9, step554]: loss 0.034099
[epoch9, step555]: loss 0.036836
[epoch9, step556]: loss 0.033846
[epoch9, step557]: loss 0.036154
[epoch9, step558]: loss 0.035003
[epoch9, step559]: loss 0.034319
[epoch9, step560]: loss 0.037982
[epoch9, step561]: loss 0.036491
[epoch9, step562]: loss 0.033806
[epoch9, step563]: loss 0.031746
[epoch9, step564]: loss 0.031430
[epoch9, step565]: loss 0.028521
[epoch9, step566]: loss 0.035184
[epoch9, step567]: loss 0.027290
[epoch9, step568]: loss 0.025387
[epoch9, step569]: loss 0.022952
[epoch9, step570]: loss 0.030558
[epoch9, step571]: loss 0.025450
[epoch9, step572]: loss 0.025407
[epoch9, step573]: loss 0.028019
[epoch9, step574]: loss 0.027724
[epoch9, step575]: loss 0.020814
[epoch9, step576]: loss 0.021308
[epoch9, step577]: loss 0.025530
[epoch9, step578]: loss 0.019327
[epoch9, step579]: loss 0.028869
[epoch9, step580]: loss 0.020811
[epoch9, step581]: loss 0.025246
[epoch9, step582]: loss 0.025040
[epoch9, step583]: loss 0.022165
[epoch9, step584]: loss 0.023253
[epoch9, step585]: loss 0.025869
[epoch9, step586]: loss 0.022239
[epoch9, step587]: loss 0.027442
[epoch9, step588]: loss 0.022505
[epoch9, step589]: loss 0.023100
[epoch9, step590]: loss 0.027541
[epoch9, step591]: loss 0.020978
[epoch9, step592]: loss 0.025773
[epoch9, step593]: loss 0.022490
[epoch9, step594]: loss 0.025111
[epoch9, step595]: loss 0.026052
[epoch9, step596]: loss 0.022805
[epoch9, step597]: loss 0.024324
[epoch9, step598]: loss 0.026589
[epoch9, step599]: loss 0.024584
[epoch9, step600]: loss 0.026688
[epoch9, step601]: loss 0.019445
[epoch9, step602]: loss 0.022432
[epoch9, step603]: loss 0.026388
[epoch9, step604]: loss 0.026834
[epoch9, step605]: loss 0.025621
[epoch9, step606]: loss 0.024765
[epoch9, step607]: loss 0.026799
[epoch9, step608]: loss 0.025637
[epoch9, step609]: loss 0.026550
[epoch9, step610]: loss 0.026181
[epoch9, step611]: loss 0.026050
[epoch9, step612]: loss 0.025342
[epoch9, step613]: loss 0.019132
[epoch9, step614]: loss 0.024812
[epoch9, step615]: loss 0.027861
[epoch9, step616]: loss 0.023764
[epoch9, step617]: loss 0.023231
[epoch9, step618]: loss 0.025731
[epoch9, step619]: loss 0.026683
[epoch9, step620]: loss 0.023922
[epoch9, step621]: loss 0.025459
[epoch9, step622]: loss 0.020049
[epoch9, step623]: loss 0.025031
[epoch9, step624]: loss 0.025957
[epoch9, step625]: loss 0.025896
[epoch9, step626]: loss 0.027103
[epoch9, step627]: loss 0.023247
[epoch9, step628]: loss 0.025339
[epoch9, step629]: loss 0.020801
[epoch9, step630]: loss 0.022492
[epoch9, step631]: loss 0.031373
[epoch9, step632]: loss 0.022666
[epoch9, step633]: loss 0.024198
[epoch9, step634]: loss 0.026788
[epoch9, step635]: loss 0.025030
[epoch9, step636]: loss 0.020519
[epoch9, step637]: loss 0.026767
[epoch9, step638]: loss 0.026467
[epoch9, step639]: loss 0.022205
[epoch9, step640]: loss 0.028830
[epoch9, step641]: loss 0.030119
[epoch9, step642]: loss 0.024270
[epoch9, step643]: loss 0.024866
[epoch9, step644]: loss 0.025664
[epoch9, step645]: loss 0.023157
[epoch9, step646]: loss 0.025564
[epoch9, step647]: loss 0.022455
[epoch9, step648]: loss 0.023791
[epoch9, step649]: loss 0.028613
[epoch9, step650]: loss 0.022262
[epoch9, step651]: loss 0.025947
[epoch9, step652]: loss 0.026094
[epoch9, step653]: loss 0.027158
[epoch9, step654]: loss 0.022286
[epoch9, step655]: loss 0.024377
[epoch9, step656]: loss 0.021542
[epoch9, step657]: loss 0.027076
[epoch9, step658]: loss 0.024716
[epoch9, step659]: loss 0.026550
[epoch9, step660]: loss 0.022788
[epoch9, step661]: loss 0.025609
[epoch9, step662]: loss 0.023300
[epoch9, step663]: loss 0.020977
[epoch9, step664]: loss 0.024654
[epoch9, step665]: loss 0.026767
[epoch9, step666]: loss 0.026150
[epoch9, step667]: loss 0.026041
[epoch9, step668]: loss 0.022890
[epoch9, step669]: loss 0.025850
[epoch9, step670]: loss 0.026024
[epoch9, step671]: loss 0.020605
[epoch9, step672]: loss 0.023939
[epoch9, step673]: loss 0.022885
[epoch9, step674]: loss 0.020664
[epoch9, step675]: loss 0.019535
[epoch9, step676]: loss 0.024070
[epoch9, step677]: loss 0.024837
[epoch9, step678]: loss 0.022307
[epoch9, step679]: loss 0.023263
[epoch9, step680]: loss 0.030840
[epoch9, step681]: loss 0.020996
[epoch9, step682]: loss 0.025786
[epoch9, step683]: loss 0.026310
[epoch9, step684]: loss 0.025031
[epoch9, step685]: loss 0.024135
[epoch9, step686]: loss 0.027480
[epoch9, step687]: loss 0.026885
[epoch9, step688]: loss 0.023152
[epoch9, step689]: loss 0.024670
[epoch9, step690]: loss 0.025199
[epoch9, step691]: loss 0.024236
[epoch9, step692]: loss 0.022398
[epoch9, step693]: loss 0.026921
[epoch9, step694]: loss 0.022772
[epoch9, step695]: loss 0.026313
[epoch9, step696]: loss 0.025421
[epoch9, step697]: loss 0.026608
[epoch9, step698]: loss 0.024357
[epoch9, step699]: loss 0.023403
[epoch9, step700]: loss 0.021949
[epoch9, step701]: loss 0.026080
[epoch9, step702]: loss 0.021460
[epoch9, step703]: loss 0.023398
[epoch9, step704]: loss 0.025503
[epoch9, step705]: loss 0.024438
[epoch9, step706]: loss 0.023315
[epoch9, step707]: loss 0.024922
[epoch9, step708]: loss 0.026211
[epoch9, step709]: loss 0.028025
[epoch9, step710]: loss 0.024034
[epoch9, step711]: loss 0.023444
[epoch9, step712]: loss 0.027162
[epoch9, step713]: loss 0.026578
[epoch9, step714]: loss 0.021112
[epoch9, step715]: loss 0.023270
[epoch9, step716]: loss 0.026166
[epoch9, step717]: loss 0.023653
[epoch9, step718]: loss 0.024724
[epoch9, step719]: loss 0.032172
[epoch9, step720]: loss 0.024471
[epoch9, step721]: loss 0.022871
[epoch9, step722]: loss 0.030064
[epoch9, step723]: loss 0.026402
[epoch9, step724]: loss 0.022856
[epoch9, step725]: loss 0.027967
[epoch9, step726]: loss 0.022521
[epoch9, step727]: loss 0.024701
[epoch9, step728]: loss 0.026509
[epoch9, step729]: loss 0.021616
[epoch9, step730]: loss 0.022951
[epoch9, step731]: loss 0.026254
[epoch9, step732]: loss 0.026126
[epoch9, step733]: loss 0.023788
[epoch9, step734]: loss 0.022943
[epoch9, step735]: loss 0.027395
[epoch9, step736]: loss 0.024835
[epoch9, step737]: loss 0.026829
[epoch9, step738]: loss 0.020501
[epoch9, step739]: loss 0.025278
[epoch9, step740]: loss 0.022480
[epoch9, step741]: loss 0.024989
[epoch9, step742]: loss 0.021881
[epoch9, step743]: loss 0.022523
[epoch9, step744]: loss 0.023494
[epoch9, step745]: loss 0.024362
[epoch9, step746]: loss 0.025102
[epoch9, step747]: loss 0.027477
[epoch9, step748]: loss 0.025096
[epoch9, step749]: loss 0.025264
[epoch9, step750]: loss 0.026919
[epoch9, step751]: loss 0.021494
[epoch9, step752]: loss 0.024784
[epoch9, step753]: loss 0.025484
[epoch9, step754]: loss 0.022891
[epoch9, step755]: loss 0.026006
[epoch9, step756]: loss 0.023699
[epoch9, step757]: loss 0.020845
[epoch9, step758]: loss 0.025117
[epoch9, step759]: loss 0.022919
[epoch9, step760]: loss 0.023669
[epoch9, step761]: loss 0.026958
[epoch9, step762]: loss 0.021693
[epoch9, step763]: loss 0.025816
[epoch9, step764]: loss 0.023898
[epoch9, step765]: loss 0.025590
[epoch9, step766]: loss 0.024627
[epoch9, step767]: loss 0.027224
[epoch9, step768]: loss 0.020962
[epoch9, step769]: loss 0.026777
[epoch9, step770]: loss 0.025604
[epoch9, step771]: loss 0.023166
[epoch9, step772]: loss 0.028664
[epoch9, step773]: loss 0.026455
[epoch9, step774]: loss 0.024425
[epoch9, step775]: loss 0.020408
[epoch9, step776]: loss 0.025211
[epoch9, step777]: loss 0.022480
[epoch9, step778]: loss 0.027281
[epoch9, step779]: loss 0.023393
[epoch9, step780]: loss 0.020027
[epoch9, step781]: loss 0.024494
[epoch9, step782]: loss 0.022284
[epoch9, step783]: loss 0.019290
[epoch9, step784]: loss 0.020560
[epoch9, step785]: loss 0.021619
[epoch9, step786]: loss 0.024718
[epoch9, step787]: loss 0.023363
[epoch9, step788]: loss 0.025126
[epoch9, step789]: loss 0.022703
[epoch9, step790]: loss 0.023537
[epoch9, step791]: loss 0.026728
[epoch9, step792]: loss 0.025480
[epoch9, step793]: loss 0.027095
[epoch9, step794]: loss 0.020766
[epoch9, step795]: loss 0.025935
[epoch9, step796]: loss 0.028198
[epoch9, step797]: loss 0.026981
[epoch9, step798]: loss 0.026723
[epoch9, step799]: loss 0.025796
[epoch9, step800]: loss 0.022412
[epoch9, step801]: loss 0.023079
[epoch9, step802]: loss 0.023423
[epoch9, step803]: loss 0.026678
[epoch9, step804]: loss 0.028039
[epoch9, step805]: loss 0.028499
[epoch9, step806]: loss 0.022109
[epoch9, step807]: loss 0.021135
[epoch9, step808]: loss 0.023432
[epoch9, step809]: loss 0.022957
[epoch9, step810]: loss 0.025925
[epoch9, step811]: loss 0.025743
[epoch9, step812]: loss 0.024311
[epoch9, step813]: loss 0.024303
[epoch9, step814]: loss 0.025415
[epoch9, step815]: loss 0.024486
[epoch9, step816]: loss 0.024218
[epoch9, step817]: loss 0.024768
[epoch9, step818]: loss 0.022035
[epoch9, step819]: loss 0.020890
[epoch9, step820]: loss 0.023348
[epoch9, step821]: loss 0.021573
[epoch9, step822]: loss 0.030720
[epoch9, step823]: loss 0.024056
[epoch9, step824]: loss 0.027050
[epoch9, step825]: loss 0.025368
[epoch9, step826]: loss 0.024039
[epoch9, step827]: loss 0.026604
[epoch9, step828]: loss 0.028446
[epoch9, step829]: loss 0.026814
[epoch9, step830]: loss 0.022454
[epoch9, step831]: loss 0.026412
[epoch9, step832]: loss 0.021262
[epoch9, step833]: loss 0.028937
[epoch9, step834]: loss 0.025511
[epoch9, step835]: loss 0.020720
[epoch9, step836]: loss 0.027010
[epoch9, step837]: loss 0.025498
[epoch9, step838]: loss 0.025849
[epoch9, step839]: loss 0.028626
[epoch9, step840]: loss 0.020482
[epoch9, step841]: loss 0.023820
[epoch9, step842]: loss 0.027791
[epoch9, step843]: loss 0.024721
[epoch9, step844]: loss 0.024437
[epoch9, step845]: loss 0.020969
[epoch9, step846]: loss 0.025739
[epoch9, step847]: loss 0.026998
[epoch9, step848]: loss 0.024736
[epoch9, step849]: loss 0.024380
[epoch9, step850]: loss 0.022537
[epoch9, step851]: loss 0.023654
[epoch9, step852]: loss 0.022479
[epoch9, step853]: loss 0.028614
[epoch9, step854]: loss 0.022468
[epoch9, step855]: loss 0.027617
[epoch9, step856]: loss 0.021444
[epoch9, step857]: loss 0.025125
[epoch9, step858]: loss 0.023733
[epoch9, step859]: loss 0.023189
[epoch9, step860]: loss 0.022297
[epoch9, step861]: loss 0.023055
[epoch9, step862]: loss 0.022700
[epoch9, step863]: loss 0.021176
[epoch9, step864]: loss 0.026293
[epoch9, step865]: loss 0.023661
[epoch9, step866]: loss 0.025408
[epoch9, step867]: loss 0.025753
[epoch9, step868]: loss 0.026696
[epoch9, step869]: loss 0.023757
[epoch9, step870]: loss 0.030967
[epoch9, step871]: loss 0.022215
[epoch9, step872]: loss 0.025429
[epoch9, step873]: loss 0.025444
[epoch9, step874]: loss 0.022758
[epoch9, step875]: loss 0.023640
[epoch9, step876]: loss 0.023958
[epoch9, step877]: loss 0.018824
[epoch9, step878]: loss 0.022812
[epoch9, step879]: loss 0.028458
[epoch9, step880]: loss 0.024791
[epoch9, step881]: loss 0.022352
[epoch9, step882]: loss 0.023873
[epoch9, step883]: loss 0.023610
[epoch9, step884]: loss 0.026131
[epoch9, step885]: loss 0.025885
[epoch9, step886]: loss 0.026142
[epoch9, step887]: loss 0.024186
[epoch9, step888]: loss 0.024425
[epoch9, step889]: loss 0.023147
[epoch9, step890]: loss 0.023809
[epoch9, step891]: loss 0.025478
[epoch9, step892]: loss 0.020811
[epoch9, step893]: loss 0.024715
[epoch9, step894]: loss 0.024902
[epoch9, step895]: loss 0.022203
[epoch9, step896]: loss 0.022308
[epoch9, step897]: loss 0.023885
[epoch9, step898]: loss 0.024841
[epoch9, step899]: loss 0.027808
[epoch9, step900]: loss 0.026625
[epoch9, step901]: loss 0.025289
[epoch9, step902]: loss 0.023574
[epoch9, step903]: loss 0.023879
[epoch9, step904]: loss 0.028311
[epoch9, step905]: loss 0.027277
[epoch9, step906]: loss 0.021970
[epoch9, step907]: loss 0.023409
[epoch9, step908]: loss 0.022683
[epoch9, step909]: loss 0.025102
[epoch9, step910]: loss 0.023307
[epoch9, step911]: loss 0.024443
[epoch9, step912]: loss 0.023579
[epoch9, step913]: loss 0.023248
[epoch9, step914]: loss 0.029731
[epoch9, step915]: loss 0.023822
[epoch9, step916]: loss 0.023866
[epoch9, step917]: loss 0.025114
[epoch9, step918]: loss 0.028327
[epoch9, step919]: loss 0.023358
[epoch9, step920]: loss 0.027167
[epoch9, step921]: loss 0.023817
[epoch9, step922]: loss 0.023015
[epoch9, step923]: loss 0.022623
[epoch9, step924]: loss 0.020584
[epoch9, step925]: loss 0.024850
[epoch9, step926]: loss 0.025871
[epoch9, step927]: loss 0.024789
[epoch9, step928]: loss 0.024551
[epoch9, step929]: loss 0.027007
[epoch9, step930]: loss 0.025325
[epoch9, step931]: loss 0.026487
[epoch9, step932]: loss 0.020843
[epoch9, step933]: loss 0.027514
[epoch9, step934]: loss 0.022271
[epoch9, step935]: loss 0.022263
[epoch9, step936]: loss 0.021652
[epoch9, step937]: loss 0.026888
[epoch9, step938]: loss 0.025814
[epoch9, step939]: loss 0.020874
[epoch9, step940]: loss 0.023454
[epoch9, step941]: loss 0.026378
[epoch9, step942]: loss 0.025047
[epoch9, step943]: loss 0.023043
[epoch9, step944]: loss 0.026806
[epoch9, step945]: loss 0.020326
[epoch9, step946]: loss 0.025375
[epoch9, step947]: loss 0.027521
[epoch9, step948]: loss 0.019541
[epoch9, step949]: loss 0.022704
[epoch9, step950]: loss 0.026058
[epoch9, step951]: loss 0.028135
[epoch9, step952]: loss 0.024792
[epoch9, step953]: loss 0.027285
[epoch9, step954]: loss 0.021817
[epoch9, step955]: loss 0.035723
[epoch9, step956]: loss 0.051442
[epoch9, step957]: loss 0.045412
[epoch9, step958]: loss 0.042570
[epoch9, step959]: loss 0.045653
[epoch9, step960]: loss 0.040499
[epoch9, step961]: loss 0.039689
[epoch9, step962]: loss 0.038019
[epoch9, step963]: loss 0.038327
[epoch9, step964]: loss 0.038777
[epoch9, step965]: loss 0.038130
[epoch9, step966]: loss 0.036430
[epoch9, step967]: loss 0.036165
[epoch9, step968]: loss 0.039443
[epoch9, step969]: loss 0.038448
[epoch9, step970]: loss 0.037786
[epoch9, step971]: loss 0.036217
[epoch9, step972]: loss 0.038651
[epoch9, step973]: loss 0.037555
[epoch9, step974]: loss 0.039553
[epoch9, step975]: loss 0.035984
[epoch9, step976]: loss 0.035555
[epoch9, step977]: loss 0.039436
[epoch9, step978]: loss 0.037842
[epoch9, step979]: loss 0.037337
[epoch9, step980]: loss 0.036072
[epoch9, step981]: loss 0.037558
[epoch9, step982]: loss 0.037427
[epoch9, step983]: loss 0.038767
[epoch9, step984]: loss 0.034673
[epoch9, step985]: loss 0.035646
[epoch9, step986]: loss 0.040192
[epoch9, step987]: loss 0.037707
[epoch9, step988]: loss 0.037388
[epoch9, step989]: loss 0.036410
[epoch9, step990]: loss 0.037389
[epoch9, step991]: loss 0.038057
[epoch9, step992]: loss 0.038799
[epoch9, step993]: loss 0.036120
[epoch9, step994]: loss 0.035490
[epoch9, step995]: loss 0.039252
[epoch9, step996]: loss 0.037322
[epoch9, step997]: loss 0.037366
[epoch9, step998]: loss 0.036460
[epoch9, step999]: loss 0.037452
[epoch9, step1000]: loss 0.037230
[epoch9, step1001]: loss 0.038377
[epoch9, step1002]: loss 0.035334
[epoch9, step1003]: loss 0.034877
[epoch9, step1004]: loss 0.039217
[epoch9, step1005]: loss 0.036297
[epoch9, step1006]: loss 0.036987
[epoch9, step1007]: loss 0.034977
[epoch9, step1008]: loss 0.036623
[epoch9, step1009]: loss 0.036802
[epoch9, step1010]: loss 0.038516
[epoch9, step1011]: loss 0.035183
[epoch9, step1012]: loss 0.035209
[epoch9, step1013]: loss 0.038509
[epoch9, step1014]: loss 0.037610
[epoch9, step1015]: loss 0.036815
[epoch9, step1016]: loss 0.034831
[epoch9, step1017]: loss 0.036591
[epoch9, step1018]: loss 0.036666
[epoch9, step1019]: loss 0.037897
[epoch9, step1020]: loss 0.034860
[epoch9, step1021]: loss 0.034547
[epoch9, step1022]: loss 0.038160
[epoch9, step1023]: loss 0.037034
[epoch9, step1024]: loss 0.037416
[epoch9, step1025]: loss 0.034303
[epoch9, step1026]: loss 0.035974
[epoch9, step1027]: loss 0.036112
[epoch9, step1028]: loss 0.037811
[epoch9, step1029]: loss 0.034819
[epoch9, step1030]: loss 0.034279
[epoch9, step1031]: loss 0.037043
[epoch9, step1032]: loss 0.037454
[epoch9, step1033]: loss 0.036385
[epoch9, step1034]: loss 0.034814
[epoch9, step1035]: loss 0.035890
[epoch9, step1036]: loss 0.036535
[epoch9, step1037]: loss 0.037643
[epoch9, step1038]: loss 0.034876
[epoch9, step1039]: loss 0.035108
[epoch9, step1040]: loss 0.037348
[epoch9, step1041]: loss 0.036153
[epoch9, step1042]: loss 0.035291
[epoch9, step1043]: loss 0.034793
[epoch9, step1044]: loss 0.036393
[epoch9, step1045]: loss 0.036356
[epoch9, step1046]: loss 0.037911
[epoch9, step1047]: loss 0.035153
[epoch9, step1048]: loss 0.034497
[epoch9, step1049]: loss 0.037977
[epoch9, step1050]: loss 0.036801
[epoch9, step1051]: loss 0.036409
[epoch9, step1052]: loss 0.034972
[epoch9, step1053]: loss 0.036426
[epoch9, step1054]: loss 0.036655
[epoch9, step1055]: loss 0.037298
[epoch9, step1056]: loss 0.034455
[epoch9, step1057]: loss 0.035229
[epoch9, step1058]: loss 0.038805
[epoch9, step1059]: loss 0.036788
[epoch9, step1060]: loss 0.036548
[epoch9, step1061]: loss 0.034798
[epoch9, step1062]: loss 0.037069
[epoch9, step1063]: loss 0.036811
[epoch9, step1064]: loss 0.038017
[epoch9, step1065]: loss 0.034968
[epoch9, step1066]: loss 0.034420
[epoch9, step1067]: loss 0.038030
[epoch9, step1068]: loss 0.035317
[epoch9, step1069]: loss 0.036133
[epoch9, step1070]: loss 0.035440
[epoch9, step1071]: loss 0.037365
[epoch9, step1072]: loss 0.037327
[epoch9, step1073]: loss 0.037743
[epoch9, step1074]: loss 0.035328
[epoch9, step1075]: loss 0.035344
[epoch9, step1076]: loss 0.038407
[epoch9, step1077]: loss 0.037006
[epoch9, step1078]: loss 0.036584
[epoch9, step1079]: loss 0.035996
[epoch9, step1080]: loss 0.036943
[epoch9, step1081]: loss 0.036557
[epoch9, step1082]: loss 0.037810
[epoch9, step1083]: loss 0.035341
[epoch9, step1084]: loss 0.034856
[epoch9, step1085]: loss 0.037597
[epoch9, step1086]: loss 0.036102
[epoch9, step1087]: loss 0.036353
[epoch9, step1088]: loss 0.034437
[epoch9, step1089]: loss 0.036528
[epoch9, step1090]: loss 0.037108
[epoch9, step1091]: loss 0.037820
[epoch9, step1092]: loss 0.034831
[epoch9, step1093]: loss 0.034628
[epoch9, step1094]: loss 0.037168
[epoch9, step1095]: loss 0.035781
[epoch9, step1096]: loss 0.035363
[epoch9, step1097]: loss 0.035106
[epoch9, step1098]: loss 0.036717
[epoch9, step1099]: loss 0.035811
[epoch9, step1100]: loss 0.038031
[epoch9, step1101]: loss 0.035232
[epoch9, step1102]: loss 0.034770
[epoch9, step1103]: loss 0.037778
[epoch9, step1104]: loss 0.036361
[epoch9, step1105]: loss 0.036342
[epoch9, step1106]: loss 0.033933
[epoch9, step1107]: loss 0.036341
[epoch9, step1108]: loss 0.035946
[epoch9, step1109]: loss 0.038568
[epoch9, step1110]: loss 0.036169
[epoch9, step1111]: loss 0.034594
[epoch9, step1112]: loss 0.037944
[epoch9, step1113]: loss 0.036042
[epoch9, step1114]: loss 0.036375
[epoch9, step1115]: loss 0.034833
[epoch9, step1116]: loss 0.036484
[epoch9, step1117]: loss 0.036596
[epoch9, step1118]: loss 0.037333
[epoch9, step1119]: loss 0.035150
[epoch9, step1120]: loss 0.034389
[epoch9, step1121]: loss 0.037717
[epoch9, step1122]: loss 0.035673
[epoch9, step1123]: loss 0.035293
[epoch9, step1124]: loss 0.035534
[epoch9, step1125]: loss 0.036734
[epoch9, step1126]: loss 0.036940
[epoch9, step1127]: loss 0.037856
[epoch9, step1128]: loss 0.035224
[epoch9, step1129]: loss 0.034565
[epoch9, step1130]: loss 0.038393
[epoch9, step1131]: loss 0.036269
[epoch9, step1132]: loss 0.036037
[epoch9, step1133]: loss 0.034198
[epoch9, step1134]: loss 0.035707
[epoch9, step1135]: loss 0.037741
[epoch9, step1136]: loss 0.038389
[epoch9, step1137]: loss 0.034684
[epoch9, step1138]: loss 0.034726
[epoch9, step1139]: loss 0.037824
[epoch9, step1140]: loss 0.035768
[epoch9, step1141]: loss 0.035629
[epoch9, step1142]: loss 0.034255
[epoch9, step1143]: loss 0.036151
[epoch9, step1144]: loss 0.037196
[epoch9, step1145]: loss 0.037126
[epoch9, step1146]: loss 0.034335
[epoch9, step1147]: loss 0.035163
[epoch9, step1148]: loss 0.037937
[epoch9, step1149]: loss 0.036349
[epoch9, step1150]: loss 0.036258
[epoch9, step1151]: loss 0.035274
[epoch9, step1152]: loss 0.036929
[epoch9, step1153]: loss 0.036085
[epoch9, step1154]: loss 0.038079
[epoch9, step1155]: loss 0.034443
[epoch9, step1156]: loss 0.033843
[epoch9, step1157]: loss 0.037777
[epoch9, step1158]: loss 0.037546
[epoch9, step1159]: loss 0.037167
[epoch9, step1160]: loss 0.036737
[epoch9, step1161]: loss 0.037367
[epoch9, step1162]: loss 0.036188
[epoch9, step1163]: loss 0.037084
[epoch9, step1164]: loss 0.034949
[epoch9, step1165]: loss 0.035553
[epoch9, step1166]: loss 0.038195
[epoch9, step1167]: loss 0.036097
[epoch9, step1168]: loss 0.036223
[epoch9, step1169]: loss 0.034488
[epoch9, step1170]: loss 0.036156
[epoch9, step1171]: loss 0.036412
[epoch9, step1172]: loss 0.037883
[epoch9, step1173]: loss 0.035451
[epoch9, step1174]: loss 0.035100
[epoch9, step1175]: loss 0.037682
[epoch9, step1176]: loss 0.036061
[epoch9, step1177]: loss 0.036390
[epoch9, step1178]: loss 0.034896
[epoch9, step1179]: loss 0.036463
[epoch9, step1180]: loss 0.036361
[epoch9, step1181]: loss 0.037855
[epoch9, step1182]: loss 0.033817
[epoch9, step1183]: loss 0.035712
[epoch9, step1184]: loss 0.037523
[epoch9, step1185]: loss 0.037023
[epoch9, step1186]: loss 0.035605
[epoch9, step1187]: loss 0.033978
[epoch9, step1188]: loss 0.035903
[epoch9, step1189]: loss 0.036343
[epoch9, step1190]: loss 0.037081
[epoch9, step1191]: loss 0.035085
[epoch9, step1192]: loss 0.034328
[epoch9, step1193]: loss 0.037604
[epoch9, step1194]: loss 0.035838
[epoch9, step1195]: loss 0.034713
[epoch9, step1196]: loss 0.033795
[epoch9, step1197]: loss 0.036297
[epoch9, step1198]: loss 0.036572
[epoch9, step1199]: loss 0.037280
[epoch9, step1200]: loss 0.034319
[epoch9, step1201]: loss 0.034842
[epoch9, step1202]: loss 0.038662
[epoch9, step1203]: loss 0.036175
[epoch9, step1204]: loss 0.035515
[epoch9, step1205]: loss 0.033980
[epoch9, step1206]: loss 0.035615
[epoch9, step1207]: loss 0.037176
[epoch9, step1208]: loss 0.038570
[epoch9, step1209]: loss 0.033456
[epoch9, step1210]: loss 0.035778
[epoch9, step1211]: loss 0.037168
[epoch9, step1212]: loss 0.035702
[epoch9, step1213]: loss 0.035436
[epoch9, step1214]: loss 0.034303
[epoch9, step1215]: loss 0.036644
[epoch9, step1216]: loss 0.035743
[epoch9, step1217]: loss 0.037860
[epoch9, step1218]: loss 0.033960
[epoch9, step1219]: loss 0.035390
[epoch9, step1220]: loss 0.037752
[epoch9, step1221]: loss 0.035518
[epoch9, step1222]: loss 0.035878
[epoch9, step1223]: loss 0.034261
[epoch9, step1224]: loss 0.036395
[epoch9, step1225]: loss 0.036139
[epoch9, step1226]: loss 0.037086
[epoch9, step1227]: loss 0.034369
[epoch9, step1228]: loss 0.033864
[epoch9, step1229]: loss 0.037134
[epoch9, step1230]: loss 0.036503
[epoch9, step1231]: loss 0.035672
[epoch9, step1232]: loss 0.035628
[epoch9, step1233]: loss 0.036361
[epoch9, step1234]: loss 0.036633
[epoch9, step1235]: loss 0.038158
[epoch9, step1236]: loss 0.035275
[epoch9, step1237]: loss 0.034657
[epoch9, step1238]: loss 0.037285
[epoch9, step1239]: loss 0.036543
[epoch9, step1240]: loss 0.036128
[epoch9, step1241]: loss 0.034701
[epoch9, step1242]: loss 0.036177
[epoch9, step1243]: loss 0.035793
[epoch9, step1244]: loss 0.037628
[epoch9, step1245]: loss 0.034703
[epoch9, step1246]: loss 0.034634
[epoch9, step1247]: loss 0.037046
[epoch9, step1248]: loss 0.035985
[epoch9, step1249]: loss 0.036392
[epoch9, step1250]: loss 0.033934
[epoch9, step1251]: loss 0.036732
[epoch9, step1252]: loss 0.037457
[epoch9, step1253]: loss 0.037541
[epoch9, step1254]: loss 0.034325
[epoch9, step1255]: loss 0.034264
[epoch9, step1256]: loss 0.038105
[epoch9, step1257]: loss 0.036506
[epoch9, step1258]: loss 0.035967
[epoch9, step1259]: loss 0.034298
[epoch9, step1260]: loss 0.036361
[epoch9, step1261]: loss 0.035754
[epoch9, step1262]: loss 0.036454
[epoch9, step1263]: loss 0.035858
[epoch9, step1264]: loss 0.034892
[epoch9, step1265]: loss 0.036519
[epoch9, step1266]: loss 0.035537
[epoch9, step1267]: loss 0.035856
[epoch9, step1268]: loss 0.034161
[epoch9, step1269]: loss 0.035963
[epoch9, step1270]: loss 0.035518
[epoch9, step1271]: loss 0.037424
[epoch9, step1272]: loss 0.034086
[epoch9, step1273]: loss 0.034017
[epoch9, step1274]: loss 0.037639
[epoch9, step1275]: loss 0.036262
[epoch9, step1276]: loss 0.035596
[epoch9, step1277]: loss 0.034306
[epoch9, step1278]: loss 0.036525
[epoch9, step1279]: loss 0.036450
[epoch9, step1280]: loss 0.037507
[epoch9, step1281]: loss 0.034337
[epoch9, step1282]: loss 0.034569
[epoch9, step1283]: loss 0.036893
[epoch9, step1284]: loss 0.035297
[epoch9, step1285]: loss 0.037839
[epoch9, step1286]: loss 0.034941
[epoch9, step1287]: loss 0.038278
[epoch9, step1288]: loss 0.038021
[epoch9, step1289]: loss 0.038328
[epoch9, step1290]: loss 0.034996
[epoch9, step1291]: loss 0.035229
[epoch9, step1292]: loss 0.038739
[epoch9, step1293]: loss 0.036700
[epoch9, step1294]: loss 0.036670
[epoch9, step1295]: loss 0.035492
[epoch9, step1296]: loss 0.037044
[epoch9, step1297]: loss 0.036401
[epoch9, step1298]: loss 0.038418
[epoch9, step1299]: loss 0.034940
[epoch9, step1300]: loss 0.035633
[epoch9, step1301]: loss 0.037500
[epoch9, step1302]: loss 0.036566
[epoch9, step1303]: loss 0.036606
[epoch9, step1304]: loss 0.034226
[epoch9, step1305]: loss 0.036684
[epoch9, step1306]: loss 0.036055
[epoch9, step1307]: loss 0.037045
[epoch9, step1308]: loss 0.034642
[epoch9, step1309]: loss 0.034003
[epoch9, step1310]: loss 0.037280
[epoch9, step1311]: loss 0.035429
[epoch9, step1312]: loss 0.037379
[epoch9, step1313]: loss 0.035310
[epoch9, step1314]: loss 0.035802
[epoch9, step1315]: loss 0.035621
[epoch9, step1316]: loss 0.038338
[epoch9, step1317]: loss 0.034595
[epoch9, step1318]: loss 0.034827
[epoch9, step1319]: loss 0.037810
[epoch9, step1320]: loss 0.036904
[epoch9, step1321]: loss 0.036732
[epoch9, step1322]: loss 0.034611
[epoch9, step1323]: loss 0.036667
[epoch9, step1324]: loss 0.035763
[epoch9, step1325]: loss 0.037212
[epoch9, step1326]: loss 0.035105
[epoch9, step1327]: loss 0.034827
[epoch9, step1328]: loss 0.038670
[epoch9, step1329]: loss 0.035533
[epoch9, step1330]: loss 0.035816
[epoch9, step1331]: loss 0.034076
[epoch9, step1332]: loss 0.036345
[epoch9, step1333]: loss 0.035744
[epoch9, step1334]: loss 0.037907
[epoch9, step1335]: loss 0.035050
[epoch9, step1336]: loss 0.034637
[epoch9, step1337]: loss 0.037207
[epoch9, step1338]: loss 0.036074
[epoch9, step1339]: loss 0.035861
[epoch9, step1340]: loss 0.034429
[epoch9, step1341]: loss 0.036427
[epoch9, step1342]: loss 0.035698
[epoch9, step1343]: loss 0.037394
[epoch9, step1344]: loss 0.034434
[epoch9, step1345]: loss 0.034203
[epoch9, step1346]: loss 0.037077
[epoch9, step1347]: loss 0.036664
[epoch9, step1348]: loss 0.035167
[epoch9, step1349]: loss 0.034725
[epoch9, step1350]: loss 0.036251
[epoch9, step1351]: loss 0.035783
[epoch9, step1352]: loss 0.037081
[epoch9, step1353]: loss 0.034268
[epoch9, step1354]: loss 0.034007
[epoch9, step1355]: loss 0.037566
[epoch9, step1356]: loss 0.035534
[epoch9, step1357]: loss 0.035300
[epoch9, step1358]: loss 0.033762
[epoch9, step1359]: loss 0.035559
[epoch9, step1360]: loss 0.036237
[epoch9, step1361]: loss 0.037464
[epoch9, step1362]: loss 0.034639
[epoch9, step1363]: loss 0.034695
[epoch9, step1364]: loss 0.037501
[epoch9, step1365]: loss 0.035844
[epoch9, step1366]: loss 0.035448
[epoch9, step1367]: loss 0.033179
[epoch9, step1368]: loss 0.039446
[epoch9, step1369]: loss 0.038985
[epoch9, step1370]: loss 0.037771
[epoch9, step1371]: loss 0.036756
[epoch9, step1372]: loss 0.034504
[epoch9, step1373]: loss 0.037442
[epoch9, step1374]: loss 0.036371
[epoch9, step1375]: loss 0.036408
[epoch9, step1376]: loss 0.034818
[epoch9, step1377]: loss 0.036352
[epoch9, step1378]: loss 0.036921
[epoch9, step1379]: loss 0.037770
[epoch9, step1380]: loss 0.034812
[epoch9, step1381]: loss 0.034585
[epoch9, step1382]: loss 0.037850
[epoch9, step1383]: loss 0.035741
[epoch9, step1384]: loss 0.036077
[epoch9, step1385]: loss 0.033688
[epoch9, step1386]: loss 0.036555
[epoch9, step1387]: loss 0.037028
[epoch9, step1388]: loss 0.036498
[epoch9, step1389]: loss 0.033954
[epoch9, step1390]: loss 0.034403
[epoch9, step1391]: loss 0.037407
[epoch9, step1392]: loss 0.035921
[epoch9, step1393]: loss 0.035477
[epoch9, step1394]: loss 0.034844
[epoch9, step1395]: loss 0.035997
[epoch9, step1396]: loss 0.035837
[epoch9, step1397]: loss 0.037142
[epoch9, step1398]: loss 0.033943
[epoch9, step1399]: loss 0.035765
[epoch9, step1400]: loss 0.038246
[epoch9, step1401]: loss 0.035765
[epoch9, step1402]: loss 0.035515
[epoch9, step1403]: loss 0.033526
[epoch9, step1404]: loss 0.035658
[epoch9, step1405]: loss 0.036001
[epoch9, step1406]: loss 0.037222
[epoch9, step1407]: loss 0.036610
[epoch9, step1408]: loss 0.033436
[epoch9, step1409]: loss 0.036978
[epoch9, step1410]: loss 0.035572
[epoch9, step1411]: loss 0.034577
[epoch9, step1412]: loss 0.034209
[epoch9, step1413]: loss 0.036120
[epoch9, step1414]: loss 0.035148
[epoch9, step1415]: loss 0.037141
[epoch9, step1416]: loss 0.034628
[epoch9, step1417]: loss 0.034479
[epoch9, step1418]: loss 0.037542
[epoch9, step1419]: loss 0.036131
[epoch9, step1420]: loss 0.035846
[epoch9, step1421]: loss 0.034329
[epoch9, step1422]: loss 0.036241
[epoch9, step1423]: loss 0.035254
[epoch9, step1424]: loss 0.037598
[epoch9, step1425]: loss 0.033592
[epoch9, step1426]: loss 0.035568
[epoch9, step1427]: loss 0.040076
[epoch9, step1428]: loss 0.037635
[epoch9, step1429]: loss 0.035435
[epoch9, step1430]: loss 0.034367
[epoch9, step1431]: loss 0.036357
[epoch9, step1432]: loss 0.036253
[epoch9, step1433]: loss 0.037651
[epoch9, step1434]: loss 0.034560
[epoch9, step1435]: loss 0.034508
[epoch9, step1436]: loss 0.037644
[epoch9, step1437]: loss 0.036049
[epoch9, step1438]: loss 0.036632
[epoch9, step1439]: loss 0.033721
[epoch9, step1440]: loss 0.035897
[epoch9, step1441]: loss 0.036414
[epoch9, step1442]: loss 0.036940
[epoch9, step1443]: loss 0.034155
[epoch9, step1444]: loss 0.033879
[epoch9, step1445]: loss 0.037665
[epoch9, step1446]: loss 0.035599
[epoch9, step1447]: loss 0.036527
[epoch9, step1448]: loss 0.034095
[epoch9, step1449]: loss 0.035379
[epoch9, step1450]: loss 0.036008
[epoch9, step1451]: loss 0.037170
[epoch9, step1452]: loss 0.034019
[epoch9, step1453]: loss 0.034722
[epoch9, step1454]: loss 0.037672
[epoch9, step1455]: loss 0.036405
[epoch9, step1456]: loss 0.035678
[epoch9, step1457]: loss 0.034376
[epoch9, step1458]: loss 0.036071
[epoch9, step1459]: loss 0.036046
[epoch9, step1460]: loss 0.037269
[epoch9, step1461]: loss 0.034527
[epoch9, step1462]: loss 0.034700
[epoch9, step1463]: loss 0.037356
[epoch9, step1464]: loss 0.035719
[epoch9, step1465]: loss 0.035000
[epoch9, step1466]: loss 0.033315
[epoch9, step1467]: loss 0.036404
[epoch9, step1468]: loss 0.035696
[epoch9, step1469]: loss 0.037085
[epoch9, step1470]: loss 0.033908
[epoch9, step1471]: loss 0.034028
[epoch9, step1472]: loss 0.037488
[epoch9, step1473]: loss 0.036175
[epoch9, step1474]: loss 0.036250
[epoch9, step1475]: loss 0.033953
[epoch9, step1476]: loss 0.036949
[epoch9, step1477]: loss 0.035642
[epoch9, step1478]: loss 0.036827
[epoch9, step1479]: loss 0.033697
[epoch9, step1480]: loss 0.033542
[epoch9, step1481]: loss 0.036608
[epoch9, step1482]: loss 0.035598
[epoch9, step1483]: loss 0.035143
[epoch9, step1484]: loss 0.034390
[epoch9, step1485]: loss 0.036033
[epoch9, step1486]: loss 0.035402
[epoch9, step1487]: loss 0.037081
[epoch9, step1488]: loss 0.034042
[epoch9, step1489]: loss 0.033859
[epoch9, step1490]: loss 0.037395
[epoch9, step1491]: loss 0.035715
[epoch9, step1492]: loss 0.034915
[epoch9, step1493]: loss 0.033967
[epoch9, step1494]: loss 0.035715
[epoch9, step1495]: loss 0.035784
[epoch9, step1496]: loss 0.037280
[epoch9, step1497]: loss 0.034331
[epoch9, step1498]: loss 0.034701
[epoch9, step1499]: loss 0.037070
[epoch9, step1500]: loss 0.035770
[epoch9, step1501]: loss 0.035097
[epoch9, step1502]: loss 0.033652
[epoch9, step1503]: loss 0.036363
[epoch9, step1504]: loss 0.035409
[epoch9, step1505]: loss 0.037698
[epoch9, step1506]: loss 0.033589
[epoch9, step1507]: loss 0.034040
[epoch9, step1508]: loss 0.037681
[epoch9, step1509]: loss 0.035757
[epoch9, step1510]: loss 0.035632
[epoch9, step1511]: loss 0.034270
[epoch9, step1512]: loss 0.035900
[epoch9, step1513]: loss 0.034872
[epoch9, step1514]: loss 0.037110
[epoch9, step1515]: loss 0.036331
[epoch9, step1516]: loss 0.035258

[epoch9]: avg loss 0.033046

[epoch10, step1]: loss 0.035720
[epoch10, step2]: loss 0.036971
[epoch10, step3]: loss 0.037010
[epoch10, step4]: loss 0.034996
[epoch10, step5]: loss 0.034041
[epoch10, step6]: loss 0.037353
[epoch10, step7]: loss 0.034704
[epoch10, step8]: loss 0.036966
[epoch10, step9]: loss 0.033997
[epoch10, step10]: loss 0.034995
[epoch10, step11]: loss 0.036919
[epoch10, step12]: loss 0.036709
[epoch10, step13]: loss 0.034249
[epoch10, step14]: loss 0.034043
[epoch10, step15]: loss 0.036678
[epoch10, step16]: loss 0.035126
[epoch10, step17]: loss 0.037130
[epoch10, step18]: loss 0.034253
[epoch10, step19]: loss 0.034706
[epoch10, step20]: loss 0.037499
[epoch10, step21]: loss 0.037185
[epoch10, step22]: loss 0.034005
[epoch10, step23]: loss 0.034316
[epoch10, step24]: loss 0.036963
[epoch10, step25]: loss 0.033807
[epoch10, step26]: loss 0.037282
[epoch10, step27]: loss 0.033092
[epoch10, step28]: loss 0.035613
[epoch10, step29]: loss 0.037009
[epoch10, step30]: loss 0.037429
[epoch10, step31]: loss 0.033944
[epoch10, step32]: loss 0.034337
[epoch10, step33]: loss 0.037402
[epoch10, step34]: loss 0.035263
[epoch10, step35]: loss 0.037540
[epoch10, step36]: loss 0.033859
[epoch10, step37]: loss 0.034170
[epoch10, step38]: loss 0.037029
[epoch10, step39]: loss 0.037482
[epoch10, step40]: loss 0.035016
[epoch10, step41]: loss 0.033377
[epoch10, step42]: loss 0.037253
[epoch10, step43]: loss 0.034369
[epoch10, step44]: loss 0.037183
[epoch10, step45]: loss 0.034255
[epoch10, step46]: loss 0.034641
[epoch10, step47]: loss 0.037075
[epoch10, step48]: loss 0.036815
[epoch10, step49]: loss 0.033349
[epoch10, step50]: loss 0.034102
[epoch10, step51]: loss 0.037021
[epoch10, step52]: loss 0.034554
[epoch10, step53]: loss 0.037410
[epoch10, step54]: loss 0.033720
[epoch10, step55]: loss 0.034484
[epoch10, step56]: loss 0.038241
[epoch10, step57]: loss 0.037640
[epoch10, step58]: loss 0.034206
[epoch10, step59]: loss 0.034280
[epoch10, step60]: loss 0.038257
[epoch10, step61]: loss 0.033997
[epoch10, step62]: loss 0.036582
[epoch10, step63]: loss 0.033904
[epoch10, step64]: loss 0.034271
[epoch10, step65]: loss 0.037493
[epoch10, step66]: loss 0.036514
[epoch10, step67]: loss 0.033660
[epoch10, step68]: loss 0.034230
[epoch10, step69]: loss 0.037106
[epoch10, step70]: loss 0.034421
[epoch10, step71]: loss 0.036860
[epoch10, step72]: loss 0.034002
[epoch10, step73]: loss 0.034742
[epoch10, step74]: loss 0.036883
[epoch10, step75]: loss 0.037722
[epoch10, step76]: loss 0.035207
[epoch10, step77]: loss 0.035483
[epoch10, step78]: loss 0.037952
[epoch10, step79]: loss 0.034413
[epoch10, step80]: loss 0.038141
[epoch10, step81]: loss 0.034754
[epoch10, step82]: loss 0.034719
[epoch10, step83]: loss 0.037447
[epoch10, step84]: loss 0.036763
[epoch10, step85]: loss 0.035454
[epoch10, step86]: loss 0.035194
[epoch10, step87]: loss 0.038366
[epoch10, step88]: loss 0.033853
[epoch10, step89]: loss 0.037176
[epoch10, step90]: loss 0.034686
[epoch10, step91]: loss 0.034790
[epoch10, step92]: loss 0.037553
[epoch10, step93]: loss 0.037446
[epoch10, step94]: loss 0.033982
[epoch10, step95]: loss 0.034560
[epoch10, step96]: loss 0.036901
[epoch10, step97]: loss 0.036086
[epoch10, step98]: loss 0.037448
[epoch10, step99]: loss 0.034759
[epoch10, step100]: loss 0.033881
[epoch10, step101]: loss 0.037712
[epoch10, step102]: loss 0.037656
[epoch10, step103]: loss 0.033886
[epoch10, step104]: loss 0.033914
[epoch10, step105]: loss 0.037435
[epoch10, step106]: loss 0.034107
[epoch10, step107]: loss 0.037151
[epoch10, step108]: loss 0.034150
[epoch10, step109]: loss 0.033978
[epoch10, step110]: loss 0.037967
[epoch10, step111]: loss 0.037228
[epoch10, step112]: loss 0.033874
[epoch10, step113]: loss 0.034839
[epoch10, step114]: loss 0.037502
[epoch10, step115]: loss 0.034491
[epoch10, step116]: loss 0.037828
[epoch10, step117]: loss 0.034353
[epoch10, step118]: loss 0.035131
[epoch10, step119]: loss 0.037400
[epoch10, step120]: loss 0.037527
[epoch10, step121]: loss 0.033713
[epoch10, step122]: loss 0.033637
[epoch10, step123]: loss 0.037590
[epoch10, step124]: loss 0.035448
[epoch10, step125]: loss 0.038074
[epoch10, step126]: loss 0.033945
[epoch10, step127]: loss 0.034448
[epoch10, step128]: loss 0.037403
[epoch10, step129]: loss 0.037514
[epoch10, step130]: loss 0.034436
[epoch10, step131]: loss 0.034141
[epoch10, step132]: loss 0.037410
[epoch10, step133]: loss 0.034276
[epoch10, step134]: loss 0.036476
[epoch10, step135]: loss 0.034446
[epoch10, step136]: loss 0.037089
[epoch10, step137]: loss 0.037408
[epoch10, step138]: loss 0.037211
[epoch10, step139]: loss 0.034051
[epoch10, step140]: loss 0.034864
[epoch10, step141]: loss 0.037945
[epoch10, step142]: loss 0.034066
[epoch10, step143]: loss 0.036705
[epoch10, step144]: loss 0.034943
[epoch10, step145]: loss 0.034414
[epoch10, step146]: loss 0.037216
[epoch10, step147]: loss 0.038335
[epoch10, step148]: loss 0.033636
[epoch10, step149]: loss 0.033764
[epoch10, step150]: loss 0.036954
[epoch10, step151]: loss 0.034456
[epoch10, step152]: loss 0.037150
[epoch10, step153]: loss 0.034058
[epoch10, step154]: loss 0.034194
[epoch10, step155]: loss 0.037503
[epoch10, step156]: loss 0.036680
[epoch10, step157]: loss 0.033946
[epoch10, step158]: loss 0.034108
[epoch10, step159]: loss 0.037324
[epoch10, step160]: loss 0.034305
[epoch10, step161]: loss 0.036976
[epoch10, step162]: loss 0.033976
[epoch10, step163]: loss 0.034360
[epoch10, step164]: loss 0.037446
[epoch10, step165]: loss 0.037358
[epoch10, step166]: loss 0.034793
[epoch10, step167]: loss 0.033877
[epoch10, step168]: loss 0.039030
[epoch10, step169]: loss 0.033827
[epoch10, step170]: loss 0.037344
[epoch10, step171]: loss 0.034116
[epoch10, step172]: loss 0.034596
[epoch10, step173]: loss 0.037443
[epoch10, step174]: loss 0.037142
[epoch10, step175]: loss 0.034449
[epoch10, step176]: loss 0.034742
[epoch10, step177]: loss 0.037809
[epoch10, step178]: loss 0.034418
[epoch10, step179]: loss 0.036721
[epoch10, step180]: loss 0.034272
[epoch10, step181]: loss 0.034223
[epoch10, step182]: loss 0.037449
[epoch10, step183]: loss 0.037439
[epoch10, step184]: loss 0.034510
[epoch10, step185]: loss 0.034364
[epoch10, step186]: loss 0.037647
[epoch10, step187]: loss 0.035031
[epoch10, step188]: loss 0.037266
[epoch10, step189]: loss 0.034604
[epoch10, step190]: loss 0.034875
[epoch10, step191]: loss 0.037555
[epoch10, step192]: loss 0.038060
[epoch10, step193]: loss 0.032958
[epoch10, step194]: loss 0.033655
[epoch10, step195]: loss 0.039846
[epoch10, step196]: loss 0.036640
[epoch10, step197]: loss 0.037339
[epoch10, step198]: loss 0.032911
[epoch10, step199]: loss 0.034721
[epoch10, step200]: loss 0.038234
[epoch10, step201]: loss 0.037530
[epoch10, step202]: loss 0.033842
[epoch10, step203]: loss 0.034502
[epoch10, step204]: loss 0.037671
[epoch10, step205]: loss 0.034534
[epoch10, step206]: loss 0.037298
[epoch10, step207]: loss 0.034220
[epoch10, step208]: loss 0.035082
[epoch10, step209]: loss 0.037595
[epoch10, step210]: loss 0.038307
[epoch10, step211]: loss 0.034790
[epoch10, step212]: loss 0.034297
[epoch10, step213]: loss 0.037146
[epoch10, step214]: loss 0.034176
[epoch10, step215]: loss 0.037080
[epoch10, step216]: loss 0.034018
[epoch10, step217]: loss 0.034389
[epoch10, step218]: loss 0.037664
[epoch10, step219]: loss 0.037157
[epoch10, step220]: loss 0.035347
[epoch10, step221]: loss 0.034516
[epoch10, step222]: loss 0.037772
[epoch10, step223]: loss 0.034248
[epoch10, step224]: loss 0.036657
[epoch10, step225]: loss 0.033875
[epoch10, step226]: loss 0.034264
[epoch10, step227]: loss 0.036583
[epoch10, step228]: loss 0.037988
[epoch10, step229]: loss 0.033034
[epoch10, step230]: loss 0.035345
[epoch10, step231]: loss 0.038813
[epoch10, step232]: loss 0.034789
[epoch10, step233]: loss 0.036191
[epoch10, step234]: loss 0.033765
[epoch10, step235]: loss 0.034430
[epoch10, step236]: loss 0.037097
[epoch10, step237]: loss 0.036845
[epoch10, step238]: loss 0.033727
[epoch10, step239]: loss 0.033335
[epoch10, step240]: loss 0.036611
[epoch10, step241]: loss 0.035774
[epoch10, step242]: loss 0.037037
[epoch10, step243]: loss 0.035600
[epoch10, step244]: loss 0.034542
[epoch10, step245]: loss 0.037481
[epoch10, step246]: loss 0.036967
[epoch10, step247]: loss 0.034793
[epoch10, step248]: loss 0.034389
[epoch10, step249]: loss 0.037177
[epoch10, step250]: loss 0.034969
[epoch10, step251]: loss 0.037232
[epoch10, step252]: loss 0.034280
[epoch10, step253]: loss 0.034021
[epoch10, step254]: loss 0.037240
[epoch10, step255]: loss 0.037009
[epoch10, step256]: loss 0.033755
[epoch10, step257]: loss 0.034285
[epoch10, step258]: loss 0.039011
[epoch10, step259]: loss 0.035393
[epoch10, step260]: loss 0.036996
[epoch10, step261]: loss 0.035606
[epoch10, step262]: loss 0.035583
[epoch10, step263]: loss 0.037455
[epoch10, step264]: loss 0.036707
[epoch10, step265]: loss 0.034187
[epoch10, step266]: loss 0.034261
[epoch10, step267]: loss 0.037036
[epoch10, step268]: loss 0.034262
[epoch10, step269]: loss 0.036800
[epoch10, step270]: loss 0.033589
[epoch10, step271]: loss 0.033950
[epoch10, step272]: loss 0.036907
[epoch10, step273]: loss 0.036557
[epoch10, step274]: loss 0.034564
[epoch10, step275]: loss 0.033483
[epoch10, step276]: loss 0.036736
[epoch10, step277]: loss 0.035508
[epoch10, step278]: loss 0.037579
[epoch10, step279]: loss 0.033664
[epoch10, step280]: loss 0.034692
[epoch10, step281]: loss 0.037434
[epoch10, step282]: loss 0.038129
[epoch10, step283]: loss 0.033922
[epoch10, step284]: loss 0.033933
[epoch10, step285]: loss 0.038141
[epoch10, step286]: loss 0.034378
[epoch10, step287]: loss 0.037509
[epoch10, step288]: loss 0.033685
[epoch10, step289]: loss 0.035159
[epoch10, step290]: loss 0.036993
[epoch10, step291]: loss 0.036807
[epoch10, step292]: loss 0.033477
[epoch10, step293]: loss 0.033386
[epoch10, step294]: loss 0.036366
[epoch10, step295]: loss 0.033645
[epoch10, step296]: loss 0.039105
[epoch10, step297]: loss 0.034126
[epoch10, step298]: loss 0.035450
[epoch10, step299]: loss 0.036611
[epoch10, step300]: loss 0.037213
[epoch10, step301]: loss 0.034109
[epoch10, step302]: loss 0.034044
[epoch10, step303]: loss 0.037647
[epoch10, step304]: loss 0.034702
[epoch10, step305]: loss 0.037039
[epoch10, step306]: loss 0.034452
[epoch10, step307]: loss 0.034651
[epoch10, step308]: loss 0.037386
[epoch10, step309]: loss 0.037131
[epoch10, step310]: loss 0.033673
[epoch10, step311]: loss 0.034622
[epoch10, step312]: loss 0.037008
[epoch10, step313]: loss 0.034747
[epoch10, step314]: loss 0.036666
[epoch10, step315]: loss 0.035865
[epoch10, step316]: loss 0.034327
[epoch10, step317]: loss 0.037872
[epoch10, step318]: loss 0.037603
[epoch10, step319]: loss 0.034677
[epoch10, step320]: loss 0.034088
[epoch10, step321]: loss 0.036970
[epoch10, step322]: loss 0.034590
[epoch10, step323]: loss 0.036348
[epoch10, step324]: loss 0.034610
[epoch10, step325]: loss 0.034215
[epoch10, step326]: loss 0.036761
[epoch10, step327]: loss 0.036339
[epoch10, step328]: loss 0.034177
[epoch10, step329]: loss 0.033363
[epoch10, step330]: loss 0.036614
[epoch10, step331]: loss 0.034656
[epoch10, step332]: loss 0.035880
[epoch10, step333]: loss 0.034107
[epoch10, step334]: loss 0.034679
[epoch10, step335]: loss 0.037262
[epoch10, step336]: loss 0.038499
[epoch10, step337]: loss 0.034533
[epoch10, step338]: loss 0.034223
[epoch10, step339]: loss 0.038424
[epoch10, step340]: loss 0.035155
[epoch10, step341]: loss 0.036967
[epoch10, step342]: loss 0.034631
[epoch10, step343]: loss 0.034918
[epoch10, step344]: loss 0.037245
[epoch10, step345]: loss 0.036813
[epoch10, step346]: loss 0.033665
[epoch10, step347]: loss 0.033723
[epoch10, step348]: loss 0.036966
[epoch10, step349]: loss 0.035164
[epoch10, step350]: loss 0.036975
[epoch10, step351]: loss 0.033009
[epoch10, step352]: loss 0.034067
[epoch10, step353]: loss 0.036855
[epoch10, step354]: loss 0.036159
[epoch10, step355]: loss 0.033041
[epoch10, step356]: loss 0.035094
[epoch10, step357]: loss 0.036980
[epoch10, step358]: loss 0.033408
[epoch10, step359]: loss 0.039006
[epoch10, step360]: loss 0.033018
[epoch10, step361]: loss 0.034409
[epoch10, step362]: loss 0.038340
[epoch10, step363]: loss 0.036272
[epoch10, step364]: loss 0.033699
[epoch10, step365]: loss 0.033751
[epoch10, step366]: loss 0.037996
[epoch10, step367]: loss 0.034258
[epoch10, step368]: loss 0.036328
[epoch10, step369]: loss 0.033770
[epoch10, step370]: loss 0.034697
[epoch10, step371]: loss 0.037432
[epoch10, step372]: loss 0.036924
[epoch10, step373]: loss 0.033888
[epoch10, step374]: loss 0.033773
[epoch10, step375]: loss 0.037404
[epoch10, step376]: loss 0.034636
[epoch10, step377]: loss 0.036897
[epoch10, step378]: loss 0.034649
[epoch10, step379]: loss 0.034901
[epoch10, step380]: loss 0.037888
[epoch10, step381]: loss 0.037038
[epoch10, step382]: loss 0.034793
[epoch10, step383]: loss 0.033595
[epoch10, step384]: loss 0.037128
[epoch10, step385]: loss 0.034146
[epoch10, step386]: loss 0.036868
[epoch10, step387]: loss 0.033781
[epoch10, step388]: loss 0.034977
[epoch10, step389]: loss 0.037423
[epoch10, step390]: loss 0.038096
[epoch10, step391]: loss 0.033508
[epoch10, step392]: loss 0.034321
[epoch10, step393]: loss 0.037134
[epoch10, step394]: loss 0.034232
[epoch10, step395]: loss 0.036725
[epoch10, step396]: loss 0.033761
[epoch10, step397]: loss 0.034167
[epoch10, step398]: loss 0.037017
[epoch10, step399]: loss 0.036976
[epoch10, step400]: loss 0.033618
[epoch10, step401]: loss 0.033224
[epoch10, step402]: loss 0.037007
[epoch10, step403]: loss 0.034501
[epoch10, step404]: loss 0.038108
[epoch10, step405]: loss 0.034335
[epoch10, step406]: loss 0.034604
[epoch10, step407]: loss 0.036846
[epoch10, step408]: loss 0.036846
[epoch10, step409]: loss 0.035270
[epoch10, step410]: loss 0.034478
[epoch10, step411]: loss 0.037320
[epoch10, step412]: loss 0.034681
[epoch10, step413]: loss 0.036982
[epoch10, step414]: loss 0.034487
[epoch10, step415]: loss 0.034778
[epoch10, step416]: loss 0.036867
[epoch10, step417]: loss 0.037422
[epoch10, step418]: loss 0.034477
[epoch10, step419]: loss 0.033104
[epoch10, step420]: loss 0.037724
[epoch10, step421]: loss 0.034432
[epoch10, step422]: loss 0.037166
[epoch10, step423]: loss 0.034426
[epoch10, step424]: loss 0.034794
[epoch10, step425]: loss 0.036898
[epoch10, step426]: loss 0.036890
[epoch10, step427]: loss 0.034256
[epoch10, step428]: loss 0.034016
[epoch10, step429]: loss 0.037940
[epoch10, step430]: loss 0.034884
[epoch10, step431]: loss 0.036896
[epoch10, step432]: loss 0.034119
[epoch10, step433]: loss 0.034987
[epoch10, step434]: loss 0.037443
[epoch10, step435]: loss 0.037682
[epoch10, step436]: loss 0.033831
[epoch10, step437]: loss 0.034715
[epoch10, step438]: loss 0.038595
[epoch10, step439]: loss 0.035224
[epoch10, step440]: loss 0.037062
[epoch10, step441]: loss 0.034013
[epoch10, step442]: loss 0.034071
[epoch10, step443]: loss 0.037327
[epoch10, step444]: loss 0.036818
[epoch10, step445]: loss 0.033964
[epoch10, step446]: loss 0.034184
[epoch10, step447]: loss 0.037845
[epoch10, step448]: loss 0.034904
[epoch10, step449]: loss 0.036822
[epoch10, step450]: loss 0.033885
[epoch10, step451]: loss 0.034097
[epoch10, step452]: loss 0.036552
[epoch10, step453]: loss 0.036964
[epoch10, step454]: loss 0.033508
[epoch10, step455]: loss 0.034440
[epoch10, step456]: loss 0.036820
[epoch10, step457]: loss 0.034586
[epoch10, step458]: loss 0.036496
[epoch10, step459]: loss 0.034312
[epoch10, step460]: loss 0.034479
[epoch10, step461]: loss 0.037381
[epoch10, step462]: loss 0.036719
[epoch10, step463]: loss 0.034247
[epoch10, step464]: loss 0.033572
[epoch10, step465]: loss 0.039153
[epoch10, step466]: loss 0.033964
[epoch10, step467]: loss 0.036386
[epoch10, step468]: loss 0.034094
[epoch10, step469]: loss 0.034246
[epoch10, step470]: loss 0.036977
[epoch10, step471]: loss 0.036882
[epoch10, step472]: loss 0.034510
[epoch10, step473]: loss 0.033396
[epoch10, step474]: loss 0.036887
[epoch10, step475]: loss 0.034656
[epoch10, step476]: loss 0.037409
[epoch10, step477]: loss 0.033728
[epoch10, step478]: loss 0.033771
[epoch10, step479]: loss 0.037455
[epoch10, step480]: loss 0.036384
[epoch10, step481]: loss 0.033503
[epoch10, step482]: loss 0.032963
[epoch10, step483]: loss 0.037609
[epoch10, step484]: loss 0.035047
[epoch10, step485]: loss 0.037001
[epoch10, step486]: loss 0.034289
[epoch10, step487]: loss 0.034209
[epoch10, step488]: loss 0.037725
[epoch10, step489]: loss 0.036758
[epoch10, step490]: loss 0.034119
[epoch10, step491]: loss 0.034291
[epoch10, step492]: loss 0.037126
[epoch10, step493]: loss 0.034152
[epoch10, step494]: loss 0.036598
[epoch10, step495]: loss 0.035059
[epoch10, step496]: loss 0.034627
[epoch10, step497]: loss 0.037729
[epoch10, step498]: loss 0.036703
[epoch10, step499]: loss 0.034001
[epoch10, step500]: loss 0.033427
[epoch10, step501]: loss 0.036705
[epoch10, step502]: loss 0.033608
[epoch10, step503]: loss 0.037465
[epoch10, step504]: loss 0.034307
[epoch10, step505]: loss 0.033711
[epoch10, step506]: loss 0.037909
[epoch10, step507]: loss 0.037659
[epoch10, step508]: loss 0.034197
[epoch10, step509]: loss 0.033947
[epoch10, step510]: loss 0.037673
[epoch10, step511]: loss 0.034720
[epoch10, step512]: loss 0.037360
[epoch10, step513]: loss 0.034524
[epoch10, step514]: loss 0.034775
[epoch10, step515]: loss 0.037526
[epoch10, step516]: loss 0.037089
[epoch10, step517]: loss 0.033881
[epoch10, step518]: loss 0.033730
[epoch10, step519]: loss 0.037235
[epoch10, step520]: loss 0.033807
[epoch10, step521]: loss 0.036750
[epoch10, step522]: loss 0.033459
[epoch10, step523]: loss 0.034419
[epoch10, step524]: loss 0.036390
[epoch10, step525]: loss 0.037234
[epoch10, step526]: loss 0.033845
[epoch10, step527]: loss 0.033558
[epoch10, step528]: loss 0.037156
[epoch10, step529]: loss 0.033636
[epoch10, step530]: loss 0.037042
[epoch10, step531]: loss 0.033619
[epoch10, step532]: loss 0.034643
[epoch10, step533]: loss 0.038561
[epoch10, step534]: loss 0.036427
[epoch10, step535]: loss 0.034850
[epoch10, step536]: loss 0.033782
[epoch10, step537]: loss 0.037115
[epoch10, step538]: loss 0.034379
[epoch10, step539]: loss 0.036397
[epoch10, step540]: loss 0.034186
[epoch10, step541]: loss 0.034252
[epoch10, step542]: loss 0.037141
[epoch10, step543]: loss 0.036886
[epoch10, step544]: loss 0.033624
[epoch10, step545]: loss 0.033438
[epoch10, step546]: loss 0.037610
[epoch10, step547]: loss 0.034115
[epoch10, step548]: loss 0.036732
[epoch10, step549]: loss 0.034378
[epoch10, step550]: loss 0.034178
[epoch10, step551]: loss 0.037927
[epoch10, step552]: loss 0.036347
[epoch10, step553]: loss 0.034418
[epoch10, step554]: loss 0.033515
[epoch10, step555]: loss 0.036832
[epoch10, step556]: loss 0.033990
[epoch10, step557]: loss 0.036129
[epoch10, step558]: loss 0.034253
[epoch10, step559]: loss 0.034003
[epoch10, step560]: loss 0.037324
[epoch10, step561]: loss 0.036639
[epoch10, step562]: loss 0.033499
[epoch10, step563]: loss 0.030455
[epoch10, step564]: loss 0.031099
[epoch10, step565]: loss 0.027868
[epoch10, step566]: loss 0.035527
[epoch10, step567]: loss 0.027755
[epoch10, step568]: loss 0.025296
[epoch10, step569]: loss 0.024997
[epoch10, step570]: loss 0.032128
[epoch10, step571]: loss 0.025539
[epoch10, step572]: loss 0.026003
[epoch10, step573]: loss 0.028635
[epoch10, step574]: loss 0.028537
[epoch10, step575]: loss 0.024225
[epoch10, step576]: loss 0.023903
[epoch10, step577]: loss 0.028725
[epoch10, step578]: loss 0.021096
[epoch10, step579]: loss 0.028800
[epoch10, step580]: loss 0.019795
[epoch10, step581]: loss 0.025236
[epoch10, step582]: loss 0.025537
[epoch10, step583]: loss 0.023381
[epoch10, step584]: loss 0.024460
[epoch10, step585]: loss 0.026487
[epoch10, step586]: loss 0.021935
[epoch10, step587]: loss 0.028185
[epoch10, step588]: loss 0.023271
[epoch10, step589]: loss 0.023677
[epoch10, step590]: loss 0.027545
[epoch10, step591]: loss 0.020296
[epoch10, step592]: loss 0.026392
[epoch10, step593]: loss 0.022321
[epoch10, step594]: loss 0.025675
[epoch10, step595]: loss 0.026525
[epoch10, step596]: loss 0.022936
[epoch10, step597]: loss 0.024856
[epoch10, step598]: loss 0.026183
[epoch10, step599]: loss 0.024878
[epoch10, step600]: loss 0.026618
[epoch10, step601]: loss 0.019754
[epoch10, step602]: loss 0.022712
[epoch10, step603]: loss 0.025608
[epoch10, step604]: loss 0.026560
[epoch10, step605]: loss 0.024811
[epoch10, step606]: loss 0.024634
[epoch10, step607]: loss 0.027067
[epoch10, step608]: loss 0.026138
[epoch10, step609]: loss 0.026989
[epoch10, step610]: loss 0.027865
[epoch10, step611]: loss 0.026357
[epoch10, step612]: loss 0.025046
[epoch10, step613]: loss 0.019142
[epoch10, step614]: loss 0.024649
[epoch10, step615]: loss 0.027940
[epoch10, step616]: loss 0.024045
[epoch10, step617]: loss 0.023111
[epoch10, step618]: loss 0.025404
[epoch10, step619]: loss 0.027990
[epoch10, step620]: loss 0.024066
[epoch10, step621]: loss 0.025943
[epoch10, step622]: loss 0.020434
[epoch10, step623]: loss 0.025035
[epoch10, step624]: loss 0.026237
[epoch10, step625]: loss 0.025784
[epoch10, step626]: loss 0.028058
[epoch10, step627]: loss 0.023463
[epoch10, step628]: loss 0.025714
[epoch10, step629]: loss 0.021196
[epoch10, step630]: loss 0.022906
[epoch10, step631]: loss 0.032794
[epoch10, step632]: loss 0.022775
[epoch10, step633]: loss 0.023976
[epoch10, step634]: loss 0.027473
[epoch10, step635]: loss 0.025679
[epoch10, step636]: loss 0.021348
[epoch10, step637]: loss 0.027314
[epoch10, step638]: loss 0.026838
[epoch10, step639]: loss 0.022486
[epoch10, step640]: loss 0.029645
[epoch10, step641]: loss 0.030396
[epoch10, step642]: loss 0.025590
[epoch10, step643]: loss 0.025496
[epoch10, step644]: loss 0.026822
[epoch10, step645]: loss 0.024007
[epoch10, step646]: loss 0.026214
[epoch10, step647]: loss 0.023315
[epoch10, step648]: loss 0.024731
[epoch10, step649]: loss 0.030228
[epoch10, step650]: loss 0.023003
[epoch10, step651]: loss 0.026335
[epoch10, step652]: loss 0.027129
[epoch10, step653]: loss 0.029112
[epoch10, step654]: loss 0.023522
[epoch10, step655]: loss 0.024986
[epoch10, step656]: loss 0.022675
[epoch10, step657]: loss 0.028668
[epoch10, step658]: loss 0.026204
[epoch10, step659]: loss 0.027121
[epoch10, step660]: loss 0.024132
[epoch10, step661]: loss 0.026655
[epoch10, step662]: loss 0.024555
[epoch10, step663]: loss 0.021564
[epoch10, step664]: loss 0.025390
[epoch10, step665]: loss 0.027560
[epoch10, step666]: loss 0.026970
[epoch10, step667]: loss 0.026371
[epoch10, step668]: loss 0.023017
[epoch10, step669]: loss 0.026026
[epoch10, step670]: loss 0.026252
[epoch10, step671]: loss 0.020978
[epoch10, step672]: loss 0.024065
[epoch10, step673]: loss 0.022757
[epoch10, step674]: loss 0.021089
[epoch10, step675]: loss 0.020129
[epoch10, step676]: loss 0.024271
[epoch10, step677]: loss 0.025118
[epoch10, step678]: loss 0.022962
[epoch10, step679]: loss 0.023181
[epoch10, step680]: loss 0.030566
[epoch10, step681]: loss 0.021361
[epoch10, step682]: loss 0.025895
[epoch10, step683]: loss 0.025643
[epoch10, step684]: loss 0.025229
[epoch10, step685]: loss 0.024453
[epoch10, step686]: loss 0.027414
[epoch10, step687]: loss 0.026728
[epoch10, step688]: loss 0.023200
[epoch10, step689]: loss 0.024304
[epoch10, step690]: loss 0.025219
[epoch10, step691]: loss 0.024600
[epoch10, step692]: loss 0.022517
[epoch10, step693]: loss 0.027585
[epoch10, step694]: loss 0.021981
[epoch10, step695]: loss 0.026242
[epoch10, step696]: loss 0.025990
[epoch10, step697]: loss 0.028052
[epoch10, step698]: loss 0.024518
[epoch10, step699]: loss 0.023595
[epoch10, step700]: loss 0.022612
[epoch10, step701]: loss 0.026266
[epoch10, step702]: loss 0.021436
[epoch10, step703]: loss 0.023645
[epoch10, step704]: loss 0.025574
[epoch10, step705]: loss 0.024304
[epoch10, step706]: loss 0.023376
[epoch10, step707]: loss 0.024738
[epoch10, step708]: loss 0.026762
[epoch10, step709]: loss 0.027190
[epoch10, step710]: loss 0.023603
[epoch10, step711]: loss 0.023898
[epoch10, step712]: loss 0.026117
[epoch10, step713]: loss 0.025767
[epoch10, step714]: loss 0.021153
[epoch10, step715]: loss 0.022527
[epoch10, step716]: loss 0.026916
[epoch10, step717]: loss 0.023139
[epoch10, step718]: loss 0.024836
[epoch10, step719]: loss 0.033402
[epoch10, step720]: loss 0.024392
[epoch10, step721]: loss 0.022624
[epoch10, step722]: loss 0.030186
[epoch10, step723]: loss 0.026212
[epoch10, step724]: loss 0.022595
[epoch10, step725]: loss 0.027425
[epoch10, step726]: loss 0.022863
[epoch10, step727]: loss 0.023902
[epoch10, step728]: loss 0.025852
[epoch10, step729]: loss 0.021746
[epoch10, step730]: loss 0.022228
[epoch10, step731]: loss 0.025762
[epoch10, step732]: loss 0.025209
[epoch10, step733]: loss 0.023604
[epoch10, step734]: loss 0.022044
[epoch10, step735]: loss 0.028018
[epoch10, step736]: loss 0.024787
[epoch10, step737]: loss 0.026232
[epoch10, step738]: loss 0.020538
[epoch10, step739]: loss 0.025728
[epoch10, step740]: loss 0.023256
[epoch10, step741]: loss 0.025781
[epoch10, step742]: loss 0.023229
[epoch10, step743]: loss 0.023208
[epoch10, step744]: loss 0.023707
[epoch10, step745]: loss 0.024828
[epoch10, step746]: loss 0.024849
[epoch10, step747]: loss 0.027310
[epoch10, step748]: loss 0.025617
[epoch10, step749]: loss 0.025584
[epoch10, step750]: loss 0.027264
[epoch10, step751]: loss 0.021970
[epoch10, step752]: loss 0.026121
[epoch10, step753]: loss 0.027276
[epoch10, step754]: loss 0.022899
[epoch10, step755]: loss 0.025357
[epoch10, step756]: loss 0.023180
[epoch10, step757]: loss 0.020581
[epoch10, step758]: loss 0.024888
[epoch10, step759]: loss 0.022614
[epoch10, step760]: loss 0.024239
[epoch10, step761]: loss 0.026644
[epoch10, step762]: loss 0.021409
[epoch10, step763]: loss 0.025178
[epoch10, step764]: loss 0.024391
[epoch10, step765]: loss 0.025378
[epoch10, step766]: loss 0.024648
[epoch10, step767]: loss 0.026604
[epoch10, step768]: loss 0.020801
[epoch10, step769]: loss 0.026914
[epoch10, step770]: loss 0.026003
[epoch10, step771]: loss 0.022643
[epoch10, step772]: loss 0.028565
[epoch10, step773]: loss 0.026210
[epoch10, step774]: loss 0.024196
[epoch10, step775]: loss 0.021120
[epoch10, step776]: loss 0.025971
[epoch10, step777]: loss 0.022524
[epoch10, step778]: loss 0.027974
[epoch10, step779]: loss 0.024269
[epoch10, step780]: loss 0.020053
[epoch10, step781]: loss 0.024755
[epoch10, step782]: loss 0.022622
[epoch10, step783]: loss 0.019677
[epoch10, step784]: loss 0.020775
[epoch10, step785]: loss 0.021141
[epoch10, step786]: loss 0.025135
[epoch10, step787]: loss 0.023252
[epoch10, step788]: loss 0.024523
[epoch10, step789]: loss 0.022944
[epoch10, step790]: loss 0.022928
[epoch10, step791]: loss 0.027277
[epoch10, step792]: loss 0.024865
[epoch10, step793]: loss 0.027217
[epoch10, step794]: loss 0.020241
[epoch10, step795]: loss 0.025825
[epoch10, step796]: loss 0.027980
[epoch10, step797]: loss 0.027477
[epoch10, step798]: loss 0.026415
[epoch10, step799]: loss 0.025328
[epoch10, step800]: loss 0.021143
[epoch10, step801]: loss 0.022161
[epoch10, step802]: loss 0.022835
[epoch10, step803]: loss 0.025804
[epoch10, step804]: loss 0.027837
[epoch10, step805]: loss 0.029395
[epoch10, step806]: loss 0.022052
[epoch10, step807]: loss 0.021457
[epoch10, step808]: loss 0.023450
[epoch10, step809]: loss 0.022703
[epoch10, step810]: loss 0.025173
[epoch10, step811]: loss 0.025369
[epoch10, step812]: loss 0.023959
[epoch10, step813]: loss 0.022961
[epoch10, step814]: loss 0.024629
[epoch10, step815]: loss 0.024816
[epoch10, step816]: loss 0.023822
[epoch10, step817]: loss 0.024553
[epoch10, step818]: loss 0.022121
[epoch10, step819]: loss 0.020766
[epoch10, step820]: loss 0.023202
[epoch10, step821]: loss 0.021292
[epoch10, step822]: loss 0.030553
[epoch10, step823]: loss 0.023896
[epoch10, step824]: loss 0.026947
[epoch10, step825]: loss 0.024978
[epoch10, step826]: loss 0.024102
[epoch10, step827]: loss 0.026226
[epoch10, step828]: loss 0.028275
[epoch10, step829]: loss 0.026892
[epoch10, step830]: loss 0.022117
[epoch10, step831]: loss 0.026406
[epoch10, step832]: loss 0.021438
[epoch10, step833]: loss 0.028434
[epoch10, step834]: loss 0.025366
[epoch10, step835]: loss 0.020754
[epoch10, step836]: loss 0.026677
[epoch10, step837]: loss 0.025514
[epoch10, step838]: loss 0.026071
[epoch10, step839]: loss 0.028354
[epoch10, step840]: loss 0.020556
[epoch10, step841]: loss 0.023908
[epoch10, step842]: loss 0.028036
[epoch10, step843]: loss 0.024908
[epoch10, step844]: loss 0.024739
[epoch10, step845]: loss 0.021205
[epoch10, step846]: loss 0.025999
[epoch10, step847]: loss 0.026602
[epoch10, step848]: loss 0.024902
[epoch10, step849]: loss 0.024624
[epoch10, step850]: loss 0.022648
[epoch10, step851]: loss 0.024264
[epoch10, step852]: loss 0.022238
[epoch10, step853]: loss 0.028937
[epoch10, step854]: loss 0.023031
[epoch10, step855]: loss 0.026840
[epoch10, step856]: loss 0.021667
[epoch10, step857]: loss 0.025376
[epoch10, step858]: loss 0.024000
[epoch10, step859]: loss 0.023363
[epoch10, step860]: loss 0.022364
[epoch10, step861]: loss 0.022931
[epoch10, step862]: loss 0.022461
[epoch10, step863]: loss 0.021032
[epoch10, step864]: loss 0.026449
[epoch10, step865]: loss 0.023180
[epoch10, step866]: loss 0.024650
[epoch10, step867]: loss 0.025326
[epoch10, step868]: loss 0.026529
[epoch10, step869]: loss 0.023355
[epoch10, step870]: loss 0.030643
[epoch10, step871]: loss 0.022745
[epoch10, step872]: loss 0.025048
[epoch10, step873]: loss 0.025087
[epoch10, step874]: loss 0.023042
[epoch10, step875]: loss 0.024095
[epoch10, step876]: loss 0.024214
[epoch10, step877]: loss 0.019383
[epoch10, step878]: loss 0.023671
[epoch10, step879]: loss 0.027744
[epoch10, step880]: loss 0.026015
[epoch10, step881]: loss 0.022665
[epoch10, step882]: loss 0.023466
[epoch10, step883]: loss 0.023270
[epoch10, step884]: loss 0.025879
[epoch10, step885]: loss 0.025331
[epoch10, step886]: loss 0.026075
[epoch10, step887]: loss 0.023863
[epoch10, step888]: loss 0.024046
[epoch10, step889]: loss 0.022719
[epoch10, step890]: loss 0.024162
[epoch10, step891]: loss 0.024956
[epoch10, step892]: loss 0.020279
[epoch10, step893]: loss 0.024273
[epoch10, step894]: loss 0.024348
[epoch10, step895]: loss 0.022193
[epoch10, step896]: loss 0.023405
[epoch10, step897]: loss 0.024076
[epoch10, step898]: loss 0.025147
[epoch10, step899]: loss 0.027892
[epoch10, step900]: loss 0.026807
[epoch10, step901]: loss 0.025633
[epoch10, step902]: loss 0.023433
[epoch10, step903]: loss 0.024401
[epoch10, step904]: loss 0.028134
[epoch10, step905]: loss 0.027280
[epoch10, step906]: loss 0.022443
[epoch10, step907]: loss 0.023294
[epoch10, step908]: loss 0.023090
[epoch10, step909]: loss 0.025382
[epoch10, step910]: loss 0.023494
[epoch10, step911]: loss 0.024714
[epoch10, step912]: loss 0.023558
[epoch10, step913]: loss 0.023273
[epoch10, step914]: loss 0.029920
[epoch10, step915]: loss 0.023924
[epoch10, step916]: loss 0.023287
[epoch10, step917]: loss 0.024567
[epoch10, step918]: loss 0.028267
[epoch10, step919]: loss 0.023508
[epoch10, step920]: loss 0.027116
[epoch10, step921]: loss 0.023439
[epoch10, step922]: loss 0.022706
[epoch10, step923]: loss 0.022887
[epoch10, step924]: loss 0.021128
[epoch10, step925]: loss 0.024504
[epoch10, step926]: loss 0.026645
[epoch10, step927]: loss 0.024913
[epoch10, step928]: loss 0.024806
[epoch10, step929]: loss 0.027010
[epoch10, step930]: loss 0.025682
[epoch10, step931]: loss 0.026783
[epoch10, step932]: loss 0.020941
[epoch10, step933]: loss 0.028370
[epoch10, step934]: loss 0.022834
[epoch10, step935]: loss 0.022841
[epoch10, step936]: loss 0.021847
[epoch10, step937]: loss 0.026744
[epoch10, step938]: loss 0.025911
[epoch10, step939]: loss 0.021358
[epoch10, step940]: loss 0.024248
[epoch10, step941]: loss 0.026521
[epoch10, step942]: loss 0.025180
[epoch10, step943]: loss 0.023162
[epoch10, step944]: loss 0.027130
[epoch10, step945]: loss 0.020419
[epoch10, step946]: loss 0.025361
[epoch10, step947]: loss 0.027172
[epoch10, step948]: loss 0.019750
[epoch10, step949]: loss 0.022703
[epoch10, step950]: loss 0.026240
[epoch10, step951]: loss 0.028380
[epoch10, step952]: loss 0.024531
[epoch10, step953]: loss 0.027879
[epoch10, step954]: loss 0.022418
[epoch10, step955]: loss 0.036162
[epoch10, step956]: loss 0.050387
[epoch10, step957]: loss 0.043127
[epoch10, step958]: loss 0.039738
[epoch10, step959]: loss 0.042379
[epoch10, step960]: loss 0.038623
[epoch10, step961]: loss 0.039473
[epoch10, step962]: loss 0.037599
[epoch10, step963]: loss 0.039004
[epoch10, step964]: loss 0.039754
[epoch10, step965]: loss 0.039373
[epoch10, step966]: loss 0.037864
[epoch10, step967]: loss 0.037066
[epoch10, step968]: loss 0.040289
[epoch10, step969]: loss 0.038754
[epoch10, step970]: loss 0.037680
[epoch10, step971]: loss 0.035636
[epoch10, step972]: loss 0.037936
[epoch10, step973]: loss 0.036772
[epoch10, step974]: loss 0.038858
[epoch10, step975]: loss 0.035676
[epoch10, step976]: loss 0.034955
[epoch10, step977]: loss 0.038919
[epoch10, step978]: loss 0.037166
[epoch10, step979]: loss 0.036289
[epoch10, step980]: loss 0.035027
[epoch10, step981]: loss 0.036769
[epoch10, step982]: loss 0.036882
[epoch10, step983]: loss 0.037906
[epoch10, step984]: loss 0.034334
[epoch10, step985]: loss 0.034780
[epoch10, step986]: loss 0.038988
[epoch10, step987]: loss 0.037167
[epoch10, step988]: loss 0.036764
[epoch10, step989]: loss 0.035704
[epoch10, step990]: loss 0.036593
[epoch10, step991]: loss 0.037120
[epoch10, step992]: loss 0.037629
[epoch10, step993]: loss 0.035089
[epoch10, step994]: loss 0.034128
[epoch10, step995]: loss 0.038154
[epoch10, step996]: loss 0.036453
[epoch10, step997]: loss 0.036524
[epoch10, step998]: loss 0.035568
[epoch10, step999]: loss 0.036730
[epoch10, step1000]: loss 0.037039
[epoch10, step1001]: loss 0.037965
[epoch10, step1002]: loss 0.035425
[epoch10, step1003]: loss 0.035028
[epoch10, step1004]: loss 0.038245
[epoch10, step1005]: loss 0.036024
[epoch10, step1006]: loss 0.036328
[epoch10, step1007]: loss 0.034446
[epoch10, step1008]: loss 0.036245
[epoch10, step1009]: loss 0.036430
[epoch10, step1010]: loss 0.038390
[epoch10, step1011]: loss 0.034911
[epoch10, step1012]: loss 0.034961
[epoch10, step1013]: loss 0.038226
[epoch10, step1014]: loss 0.037002
[epoch10, step1015]: loss 0.036435
[epoch10, step1016]: loss 0.034661
[epoch10, step1017]: loss 0.035979
[epoch10, step1018]: loss 0.036299
[epoch10, step1019]: loss 0.037951
[epoch10, step1020]: loss 0.034487
[epoch10, step1021]: loss 0.034234
[epoch10, step1022]: loss 0.037824
[epoch10, step1023]: loss 0.036116
[epoch10, step1024]: loss 0.036441
[epoch10, step1025]: loss 0.034394
[epoch10, step1026]: loss 0.035661
[epoch10, step1027]: loss 0.036261
[epoch10, step1028]: loss 0.037387
[epoch10, step1029]: loss 0.034395
[epoch10, step1030]: loss 0.033731
[epoch10, step1031]: loss 0.036494
[epoch10, step1032]: loss 0.037018
[epoch10, step1033]: loss 0.035566
[epoch10, step1034]: loss 0.034354
[epoch10, step1035]: loss 0.035672
[epoch10, step1036]: loss 0.036340
[epoch10, step1037]: loss 0.037094
[epoch10, step1038]: loss 0.034317
[epoch10, step1039]: loss 0.034709
[epoch10, step1040]: loss 0.036901
[epoch10, step1041]: loss 0.035879
[epoch10, step1042]: loss 0.034856
[epoch10, step1043]: loss 0.034480
[epoch10, step1044]: loss 0.035879
[epoch10, step1045]: loss 0.036145
[epoch10, step1046]: loss 0.037496
[epoch10, step1047]: loss 0.034668
[epoch10, step1048]: loss 0.034335
[epoch10, step1049]: loss 0.037442
[epoch10, step1050]: loss 0.036369
[epoch10, step1051]: loss 0.035952
[epoch10, step1052]: loss 0.034677
[epoch10, step1053]: loss 0.036079
[epoch10, step1054]: loss 0.036116
[epoch10, step1055]: loss 0.036863
[epoch10, step1056]: loss 0.033996
[epoch10, step1057]: loss 0.034841
[epoch10, step1058]: loss 0.038478
[epoch10, step1059]: loss 0.036594
[epoch10, step1060]: loss 0.036059
[epoch10, step1061]: loss 0.034380
[epoch10, step1062]: loss 0.036564
[epoch10, step1063]: loss 0.036092
[epoch10, step1064]: loss 0.037348
[epoch10, step1065]: loss 0.034381
[epoch10, step1066]: loss 0.033859
[epoch10, step1067]: loss 0.037725
[epoch10, step1068]: loss 0.034881
[epoch10, step1069]: loss 0.035401
[epoch10, step1070]: loss 0.034180
[epoch10, step1071]: loss 0.036090
[epoch10, step1072]: loss 0.036707
[epoch10, step1073]: loss 0.037491
[epoch10, step1074]: loss 0.035051
[epoch10, step1075]: loss 0.034977
[epoch10, step1076]: loss 0.037934
[epoch10, step1077]: loss 0.036502
[epoch10, step1078]: loss 0.035693
[epoch10, step1079]: loss 0.035142
[epoch10, step1080]: loss 0.035963
[epoch10, step1081]: loss 0.035686
[epoch10, step1082]: loss 0.037078
[epoch10, step1083]: loss 0.036215
[epoch10, step1084]: loss 0.034176
[epoch10, step1085]: loss 0.037055
[epoch10, step1086]: loss 0.035730
[epoch10, step1087]: loss 0.035713
[epoch10, step1088]: loss 0.034593
[epoch10, step1089]: loss 0.036522
[epoch10, step1090]: loss 0.036722
[epoch10, step1091]: loss 0.037896
[epoch10, step1092]: loss 0.034420
[epoch10, step1093]: loss 0.033724
[epoch10, step1094]: loss 0.036584
[epoch10, step1095]: loss 0.035402
[epoch10, step1096]: loss 0.034914
[epoch10, step1097]: loss 0.033857
[epoch10, step1098]: loss 0.035541
[epoch10, step1099]: loss 0.035562
[epoch10, step1100]: loss 0.037423
[epoch10, step1101]: loss 0.034799
[epoch10, step1102]: loss 0.034130
[epoch10, step1103]: loss 0.036936
[epoch10, step1104]: loss 0.035890
[epoch10, step1105]: loss 0.035687
[epoch10, step1106]: loss 0.033430
[epoch10, step1107]: loss 0.035991
[epoch10, step1108]: loss 0.035641
[epoch10, step1109]: loss 0.038004
[epoch10, step1110]: loss 0.035134
[epoch10, step1111]: loss 0.034200
[epoch10, step1112]: loss 0.038003
[epoch10, step1113]: loss 0.036243
[epoch10, step1114]: loss 0.036247
[epoch10, step1115]: loss 0.034781
[epoch10, step1116]: loss 0.036186
[epoch10, step1117]: loss 0.036266
[epoch10, step1118]: loss 0.037058
[epoch10, step1119]: loss 0.034935
[epoch10, step1120]: loss 0.034169
[epoch10, step1121]: loss 0.037183
[epoch10, step1122]: loss 0.035354
[epoch10, step1123]: loss 0.035054
[epoch10, step1124]: loss 0.036040
[epoch10, step1125]: loss 0.036379
[epoch10, step1126]: loss 0.037033
[epoch10, step1127]: loss 0.037272
[epoch10, step1128]: loss 0.034502
[epoch10, step1129]: loss 0.034406
[epoch10, step1130]: loss 0.038285
[epoch10, step1131]: loss 0.036299
[epoch10, step1132]: loss 0.035865
[epoch10, step1133]: loss 0.033734
[epoch10, step1134]: loss 0.035477
[epoch10, step1135]: loss 0.038134
[epoch10, step1136]: loss 0.039088
[epoch10, step1137]: loss 0.034844
[epoch10, step1138]: loss 0.033813
[epoch10, step1139]: loss 0.037287
[epoch10, step1140]: loss 0.035478
[epoch10, step1141]: loss 0.035475
[epoch10, step1142]: loss 0.034112
[epoch10, step1143]: loss 0.035462
[epoch10, step1144]: loss 0.035879
[epoch10, step1145]: loss 0.036292
[epoch10, step1146]: loss 0.033837
[epoch10, step1147]: loss 0.035969
[epoch10, step1148]: loss 0.037157
[epoch10, step1149]: loss 0.035191
[epoch10, step1150]: loss 0.035253
[epoch10, step1151]: loss 0.034667
[epoch10, step1152]: loss 0.036160
[epoch10, step1153]: loss 0.035439
[epoch10, step1154]: loss 0.037366
[epoch10, step1155]: loss 0.034328
[epoch10, step1156]: loss 0.033782
[epoch10, step1157]: loss 0.037446
[epoch10, step1158]: loss 0.035712
[epoch10, step1159]: loss 0.035965
[epoch10, step1160]: loss 0.035454
[epoch10, step1161]: loss 0.036398
[epoch10, step1162]: loss 0.035758
[epoch10, step1163]: loss 0.036806
[epoch10, step1164]: loss 0.034506
[epoch10, step1165]: loss 0.034655
[epoch10, step1166]: loss 0.037348
[epoch10, step1167]: loss 0.034993
[epoch10, step1168]: loss 0.035645
[epoch10, step1169]: loss 0.033956
[epoch10, step1170]: loss 0.035383
[epoch10, step1171]: loss 0.035571
[epoch10, step1172]: loss 0.036730
[epoch10, step1173]: loss 0.033952
[epoch10, step1174]: loss 0.033947
[epoch10, step1175]: loss 0.036922
[epoch10, step1176]: loss 0.035154
[epoch10, step1177]: loss 0.035189
[epoch10, step1178]: loss 0.033692
[epoch10, step1179]: loss 0.035499
[epoch10, step1180]: loss 0.035544
[epoch10, step1181]: loss 0.037477
[epoch10, step1182]: loss 0.033607
[epoch10, step1183]: loss 0.034040
[epoch10, step1184]: loss 0.036643
[epoch10, step1185]: loss 0.035368
[epoch10, step1186]: loss 0.034735
[epoch10, step1187]: loss 0.033792
[epoch10, step1188]: loss 0.034788
[epoch10, step1189]: loss 0.035111
[epoch10, step1190]: loss 0.036641
[epoch10, step1191]: loss 0.034770
[epoch10, step1192]: loss 0.033928
[epoch10, step1193]: loss 0.037156
[epoch10, step1194]: loss 0.035765
[epoch10, step1195]: loss 0.034967
[epoch10, step1196]: loss 0.033468
[epoch10, step1197]: loss 0.035647
[epoch10, step1198]: loss 0.036111
[epoch10, step1199]: loss 0.037511
[epoch10, step1200]: loss 0.034560
[epoch10, step1201]: loss 0.035650
[epoch10, step1202]: loss 0.038743
[epoch10, step1203]: loss 0.035533
[epoch10, step1204]: loss 0.035006
[epoch10, step1205]: loss 0.034375
[epoch10, step1206]: loss 0.035733
[epoch10, step1207]: loss 0.036289
[epoch10, step1208]: loss 0.037311
[epoch10, step1209]: loss 0.033753
[epoch10, step1210]: loss 0.034363
[epoch10, step1211]: loss 0.036563
[epoch10, step1212]: loss 0.035514
[epoch10, step1213]: loss 0.036163
[epoch10, step1214]: loss 0.034497
[epoch10, step1215]: loss 0.036761
[epoch10, step1216]: loss 0.035404
[epoch10, step1217]: loss 0.037117
[epoch10, step1218]: loss 0.034057
[epoch10, step1219]: loss 0.034332
[epoch10, step1220]: loss 0.037445
[epoch10, step1221]: loss 0.035221
[epoch10, step1222]: loss 0.035204
[epoch10, step1223]: loss 0.033864
[epoch10, step1224]: loss 0.036169
[epoch10, step1225]: loss 0.035773
[epoch10, step1226]: loss 0.036319
[epoch10, step1227]: loss 0.033723
[epoch10, step1228]: loss 0.033756
[epoch10, step1229]: loss 0.036683
[epoch10, step1230]: loss 0.035637
[epoch10, step1231]: loss 0.034875
[epoch10, step1232]: loss 0.035397
[epoch10, step1233]: loss 0.035264
[epoch10, step1234]: loss 0.035384
[epoch10, step1235]: loss 0.036989
[epoch10, step1236]: loss 0.034421
[epoch10, step1237]: loss 0.033858
[epoch10, step1238]: loss 0.036708
[epoch10, step1239]: loss 0.036307
[epoch10, step1240]: loss 0.035429
[epoch10, step1241]: loss 0.034190
[epoch10, step1242]: loss 0.035453
[epoch10, step1243]: loss 0.035523
[epoch10, step1244]: loss 0.036837
[epoch10, step1245]: loss 0.034419
[epoch10, step1246]: loss 0.034044
[epoch10, step1247]: loss 0.036477
[epoch10, step1248]: loss 0.035382
[epoch10, step1249]: loss 0.035821
[epoch10, step1250]: loss 0.033585
[epoch10, step1251]: loss 0.036193
[epoch10, step1252]: loss 0.036901
[epoch10, step1253]: loss 0.036731
[epoch10, step1254]: loss 0.033757
[epoch10, step1255]: loss 0.033710
[epoch10, step1256]: loss 0.037454
[epoch10, step1257]: loss 0.036303
[epoch10, step1258]: loss 0.035548
[epoch10, step1259]: loss 0.033935
[epoch10, step1260]: loss 0.035667
[epoch10, step1261]: loss 0.035332
[epoch10, step1262]: loss 0.036292
[epoch10, step1263]: loss 0.034947
[epoch10, step1264]: loss 0.034107
[epoch10, step1265]: loss 0.036042
[epoch10, step1266]: loss 0.035313
[epoch10, step1267]: loss 0.035695
[epoch10, step1268]: loss 0.033639
[epoch10, step1269]: loss 0.035251
[epoch10, step1270]: loss 0.035272
[epoch10, step1271]: loss 0.037004
[epoch10, step1272]: loss 0.033968
[epoch10, step1273]: loss 0.033612
[epoch10, step1274]: loss 0.036781
[epoch10, step1275]: loss 0.036545
[epoch10, step1276]: loss 0.034991
[epoch10, step1277]: loss 0.034216
[epoch10, step1278]: loss 0.036559
[epoch10, step1279]: loss 0.036072
[epoch10, step1280]: loss 0.037128
[epoch10, step1281]: loss 0.034348
[epoch10, step1282]: loss 0.034349
[epoch10, step1283]: loss 0.036649
[epoch10, step1284]: loss 0.035151
[epoch10, step1285]: loss 0.035572
[epoch10, step1286]: loss 0.033582
[epoch10, step1287]: loss 0.036949
[epoch10, step1288]: loss 0.036750
[epoch10, step1289]: loss 0.038404
[epoch10, step1290]: loss 0.034243
[epoch10, step1291]: loss 0.034310
[epoch10, step1292]: loss 0.038214
[epoch10, step1293]: loss 0.035670
[epoch10, step1294]: loss 0.035764
[epoch10, step1295]: loss 0.034471
[epoch10, step1296]: loss 0.035487
[epoch10, step1297]: loss 0.035908
[epoch10, step1298]: loss 0.037406
[epoch10, step1299]: loss 0.034206
[epoch10, step1300]: loss 0.035088
[epoch10, step1301]: loss 0.036341
[epoch10, step1302]: loss 0.035460
[epoch10, step1303]: loss 0.035433
[epoch10, step1304]: loss 0.033574
[epoch10, step1305]: loss 0.036100
[epoch10, step1306]: loss 0.035736
[epoch10, step1307]: loss 0.036842
[epoch10, step1308]: loss 0.034146
[epoch10, step1309]: loss 0.033674
[epoch10, step1310]: loss 0.036694
[epoch10, step1311]: loss 0.035103
[epoch10, step1312]: loss 0.036633
[epoch10, step1313]: loss 0.034246
[epoch10, step1314]: loss 0.034880
[epoch10, step1315]: loss 0.034890
[epoch10, step1316]: loss 0.038490
[epoch10, step1317]: loss 0.033837
[epoch10, step1318]: loss 0.033767
[epoch10, step1319]: loss 0.036913
[epoch10, step1320]: loss 0.035732
[epoch10, step1321]: loss 0.035311
[epoch10, step1322]: loss 0.034208
[epoch10, step1323]: loss 0.035819
[epoch10, step1324]: loss 0.034793
[epoch10, step1325]: loss 0.036777
[epoch10, step1326]: loss 0.034071
[epoch10, step1327]: loss 0.033316
[epoch10, step1328]: loss 0.037368
[epoch10, step1329]: loss 0.035323
[epoch10, step1330]: loss 0.035713
[epoch10, step1331]: loss 0.033785
[epoch10, step1332]: loss 0.035903
[epoch10, step1333]: loss 0.035449
[epoch10, step1334]: loss 0.037321
[epoch10, step1335]: loss 0.034839
[epoch10, step1336]: loss 0.033737
[epoch10, step1337]: loss 0.036618
[epoch10, step1338]: loss 0.035452
[epoch10, step1339]: loss 0.035147
[epoch10, step1340]: loss 0.033770
[epoch10, step1341]: loss 0.035438
[epoch10, step1342]: loss 0.035126
[epoch10, step1343]: loss 0.036660
[epoch10, step1344]: loss 0.033709
[epoch10, step1345]: loss 0.033539
[epoch10, step1346]: loss 0.036009
[epoch10, step1347]: loss 0.036864
[epoch10, step1348]: loss 0.034492
[epoch10, step1349]: loss 0.034334
[epoch10, step1350]: loss 0.036013
[epoch10, step1351]: loss 0.035586
[epoch10, step1352]: loss 0.037079
[epoch10, step1353]: loss 0.033894
[epoch10, step1354]: loss 0.033945
[epoch10, step1355]: loss 0.037034
[epoch10, step1356]: loss 0.035210
[epoch10, step1357]: loss 0.035053
[epoch10, step1358]: loss 0.033433
[epoch10, step1359]: loss 0.034999
[epoch10, step1360]: loss 0.035981
[epoch10, step1361]: loss 0.036863
[epoch10, step1362]: loss 0.034196
[epoch10, step1363]: loss 0.034086
[epoch10, step1364]: loss 0.037380
[epoch10, step1365]: loss 0.036040
[epoch10, step1366]: loss 0.035597
[epoch10, step1367]: loss 0.033579
[epoch10, step1368]: loss 0.036130
[epoch10, step1369]: loss 0.035697
[epoch10, step1370]: loss 0.036788
[epoch10, step1371]: loss 0.034021
[epoch10, step1372]: loss 0.033269
[epoch10, step1373]: loss 0.036744
[epoch10, step1374]: loss 0.035955
[epoch10, step1375]: loss 0.036011
[epoch10, step1376]: loss 0.033740
[epoch10, step1377]: loss 0.035639
[epoch10, step1378]: loss 0.035637
[epoch10, step1379]: loss 0.036793
[epoch10, step1380]: loss 0.034337
[epoch10, step1381]: loss 0.033490
[epoch10, step1382]: loss 0.036675
[epoch10, step1383]: loss 0.035416
[epoch10, step1384]: loss 0.035337
[epoch10, step1385]: loss 0.032762
[epoch10, step1386]: loss 0.035701
[epoch10, step1387]: loss 0.036103
[epoch10, step1388]: loss 0.036108
[epoch10, step1389]: loss 0.033636
[epoch10, step1390]: loss 0.034140
[epoch10, step1391]: loss 0.036837
[epoch10, step1392]: loss 0.035804
[epoch10, step1393]: loss 0.035325
[epoch10, step1394]: loss 0.033945
[epoch10, step1395]: loss 0.035153
[epoch10, step1396]: loss 0.035168
[epoch10, step1397]: loss 0.036052
[epoch10, step1398]: loss 0.033981
[epoch10, step1399]: loss 0.035779
[epoch10, step1400]: loss 0.037308
[epoch10, step1401]: loss 0.035005
[epoch10, step1402]: loss 0.035177
[epoch10, step1403]: loss 0.033444
[epoch10, step1404]: loss 0.035547
[epoch10, step1405]: loss 0.035160
[epoch10, step1406]: loss 0.036738
[epoch10, step1407]: loss 0.035100
[epoch10, step1408]: loss 0.033321
[epoch10, step1409]: loss 0.036410
[epoch10, step1410]: loss 0.034943
[epoch10, step1411]: loss 0.034300
[epoch10, step1412]: loss 0.033409
[epoch10, step1413]: loss 0.035281
[epoch10, step1414]: loss 0.034525
[epoch10, step1415]: loss 0.036501
[epoch10, step1416]: loss 0.033850
[epoch10, step1417]: loss 0.034171
[epoch10, step1418]: loss 0.037236
[epoch10, step1419]: loss 0.035828
[epoch10, step1420]: loss 0.034882
[epoch10, step1421]: loss 0.033844
[epoch10, step1422]: loss 0.035964
[epoch10, step1423]: loss 0.035122
[epoch10, step1424]: loss 0.036890
[epoch10, step1425]: loss 0.033256
[epoch10, step1426]: loss 0.034146
[epoch10, step1427]: loss 0.038601
[epoch10, step1428]: loss 0.036723
[epoch10, step1429]: loss 0.035169
[epoch10, step1430]: loss 0.033918
[epoch10, step1431]: loss 0.035273
[epoch10, step1432]: loss 0.035326
[epoch10, step1433]: loss 0.036472
[epoch10, step1434]: loss 0.033637
[epoch10, step1435]: loss 0.033629
[epoch10, step1436]: loss 0.037208
[epoch10, step1437]: loss 0.035681
[epoch10, step1438]: loss 0.036113
[epoch10, step1439]: loss 0.033398
[epoch10, step1440]: loss 0.035194
[epoch10, step1441]: loss 0.036301
[epoch10, step1442]: loss 0.036466
[epoch10, step1443]: loss 0.033625
[epoch10, step1444]: loss 0.033368
[epoch10, step1445]: loss 0.036859
[epoch10, step1446]: loss 0.034908
[epoch10, step1447]: loss 0.035825
[epoch10, step1448]: loss 0.033598
[epoch10, step1449]: loss 0.034788
[epoch10, step1450]: loss 0.035359
[epoch10, step1451]: loss 0.036906
[epoch10, step1452]: loss 0.033264
[epoch10, step1453]: loss 0.035251
[epoch10, step1454]: loss 0.037047
[epoch10, step1455]: loss 0.036247
[epoch10, step1456]: loss 0.035343
[epoch10, step1457]: loss 0.034096
[epoch10, step1458]: loss 0.035743
[epoch10, step1459]: loss 0.035542
[epoch10, step1460]: loss 0.036746
[epoch10, step1461]: loss 0.034133
[epoch10, step1462]: loss 0.034305
[epoch10, step1463]: loss 0.036952
[epoch10, step1464]: loss 0.035273
[epoch10, step1465]: loss 0.034532
[epoch10, step1466]: loss 0.033244
[epoch10, step1467]: loss 0.035059
[epoch10, step1468]: loss 0.035294
[epoch10, step1469]: loss 0.036643
[epoch10, step1470]: loss 0.034190
[epoch10, step1471]: loss 0.033693
[epoch10, step1472]: loss 0.036787
[epoch10, step1473]: loss 0.034999
[epoch10, step1474]: loss 0.035667
[epoch10, step1475]: loss 0.033472
[epoch10, step1476]: loss 0.036159
[epoch10, step1477]: loss 0.035097
[epoch10, step1478]: loss 0.036485
[epoch10, step1479]: loss 0.033467
[epoch10, step1480]: loss 0.032979
[epoch10, step1481]: loss 0.035651
[epoch10, step1482]: loss 0.035767
[epoch10, step1483]: loss 0.035635
[epoch10, step1484]: loss 0.034594
[epoch10, step1485]: loss 0.035416
[epoch10, step1486]: loss 0.034696
[epoch10, step1487]: loss 0.036640
[epoch10, step1488]: loss 0.033382
[epoch10, step1489]: loss 0.033675
[epoch10, step1490]: loss 0.037514
[epoch10, step1491]: loss 0.035024
[epoch10, step1492]: loss 0.034632
[epoch10, step1493]: loss 0.033712
[epoch10, step1494]: loss 0.035222
[epoch10, step1495]: loss 0.035622
[epoch10, step1496]: loss 0.037293
[epoch10, step1497]: loss 0.033984
[epoch10, step1498]: loss 0.034214
[epoch10, step1499]: loss 0.036676
[epoch10, step1500]: loss 0.035441
[epoch10, step1501]: loss 0.034826
[epoch10, step1502]: loss 0.033239
[epoch10, step1503]: loss 0.035810
[epoch10, step1504]: loss 0.035038
[epoch10, step1505]: loss 0.037599
[epoch10, step1506]: loss 0.033028
[epoch10, step1507]: loss 0.034766
[epoch10, step1508]: loss 0.037661
[epoch10, step1509]: loss 0.034761
[epoch10, step1510]: loss 0.035301
[epoch10, step1511]: loss 0.034327
[epoch10, step1512]: loss 0.035732
[epoch10, step1513]: loss 0.035326
[epoch10, step1514]: loss 0.036428
[epoch10, step1515]: loss 0.034248
[epoch10, step1516]: loss 0.033102

[epoch10]: avg loss 0.032843

[epoch11, step1]: loss 0.030737
[epoch11, step2]: loss 0.036374
[epoch11, step3]: loss 0.036124
[epoch11, step4]: loss 0.034604
[epoch11, step5]: loss 0.034361
[epoch11, step6]: loss 0.036412
[epoch11, step7]: loss 0.034579
[epoch11, step8]: loss 0.036323
[epoch11, step9]: loss 0.033556
[epoch11, step10]: loss 0.035396
[epoch11, step11]: loss 0.037075
[epoch11, step12]: loss 0.037016
[epoch11, step13]: loss 0.034194
[epoch11, step14]: loss 0.033685
[epoch11, step15]: loss 0.036324
[epoch11, step16]: loss 0.035015
[epoch11, step17]: loss 0.037257
[epoch11, step18]: loss 0.034916
[epoch11, step19]: loss 0.033806
[epoch11, step20]: loss 0.037021
[epoch11, step21]: loss 0.036569
[epoch11, step22]: loss 0.034431
[epoch11, step23]: loss 0.035054
[epoch11, step24]: loss 0.037072
[epoch11, step25]: loss 0.034272
[epoch11, step26]: loss 0.037310
[epoch11, step27]: loss 0.033926
[epoch11, step28]: loss 0.034996
[epoch11, step29]: loss 0.036612
[epoch11, step30]: loss 0.037237
[epoch11, step31]: loss 0.033189
[epoch11, step32]: loss 0.033992
[epoch11, step33]: loss 0.036786
[epoch11, step34]: loss 0.034589
[epoch11, step35]: loss 0.037066
[epoch11, step36]: loss 0.034115
[epoch11, step37]: loss 0.034388
[epoch11, step38]: loss 0.037439
[epoch11, step39]: loss 0.037256
[epoch11, step40]: loss 0.033979
[epoch11, step41]: loss 0.033852
[epoch11, step42]: loss 0.037021
[epoch11, step43]: loss 0.033735
[epoch11, step44]: loss 0.037881
[epoch11, step45]: loss 0.033808
[epoch11, step46]: loss 0.034094
[epoch11, step47]: loss 0.036462
[epoch11, step48]: loss 0.036598
[epoch11, step49]: loss 0.033257
[epoch11, step50]: loss 0.033423
[epoch11, step51]: loss 0.036369
[epoch11, step52]: loss 0.034089
[epoch11, step53]: loss 0.037162
[epoch11, step54]: loss 0.033179
[epoch11, step55]: loss 0.034317
[epoch11, step56]: loss 0.037906
[epoch11, step57]: loss 0.036903
[epoch11, step58]: loss 0.033784
[epoch11, step59]: loss 0.033481
[epoch11, step60]: loss 0.037290
[epoch11, step61]: loss 0.033519
[epoch11, step62]: loss 0.036070
[epoch11, step63]: loss 0.033277
[epoch11, step64]: loss 0.033917
[epoch11, step65]: loss 0.037127
[epoch11, step66]: loss 0.036236
[epoch11, step67]: loss 0.033479
[epoch11, step68]: loss 0.034166
[epoch11, step69]: loss 0.036578
[epoch11, step70]: loss 0.034189
[epoch11, step71]: loss 0.036933
[epoch11, step72]: loss 0.034079
[epoch11, step73]: loss 0.034194
[epoch11, step74]: loss 0.036591
[epoch11, step75]: loss 0.037163
[epoch11, step76]: loss 0.034599
[epoch11, step77]: loss 0.035048
[epoch11, step78]: loss 0.037266
[epoch11, step79]: loss 0.033473
[epoch11, step80]: loss 0.038838
[epoch11, step81]: loss 0.033339
[epoch11, step82]: loss 0.034121
[epoch11, step83]: loss 0.036777
[epoch11, step84]: loss 0.036624
[epoch11, step85]: loss 0.034486
[epoch11, step86]: loss 0.034057
[epoch11, step87]: loss 0.037463
[epoch11, step88]: loss 0.033839
[epoch11, step89]: loss 0.036550
[epoch11, step90]: loss 0.034498
[epoch11, step91]: loss 0.033888
[epoch11, step92]: loss 0.036867
[epoch11, step93]: loss 0.037409
[epoch11, step94]: loss 0.033312
[epoch11, step95]: loss 0.034837
[epoch11, step96]: loss 0.036614
[epoch11, step97]: loss 0.035312
[epoch11, step98]: loss 0.036882
[epoch11, step99]: loss 0.034184
[epoch11, step100]: loss 0.033719
[epoch11, step101]: loss 0.037218
[epoch11, step102]: loss 0.037408
[epoch11, step103]: loss 0.034542
[epoch11, step104]: loss 0.034183
[epoch11, step105]: loss 0.037458
[epoch11, step106]: loss 0.034108
[epoch11, step107]: loss 0.036778
[epoch11, step108]: loss 0.033692
[epoch11, step109]: loss 0.033542
[epoch11, step110]: loss 0.037934
[epoch11, step111]: loss 0.036751
[epoch11, step112]: loss 0.034155
[epoch11, step113]: loss 0.035707
[epoch11, step114]: loss 0.036530
[epoch11, step115]: loss 0.033866
[epoch11, step116]: loss 0.038228
[epoch11, step117]: loss 0.033409
[epoch11, step118]: loss 0.034992
[epoch11, step119]: loss 0.037062
[epoch11, step120]: loss 0.037533
[epoch11, step121]: loss 0.034154
[epoch11, step122]: loss 0.033643
[epoch11, step123]: loss 0.036805
[epoch11, step124]: loss 0.034227
[epoch11, step125]: loss 0.037245
[epoch11, step126]: loss 0.033642
[epoch11, step127]: loss 0.033669
[epoch11, step128]: loss 0.036726
[epoch11, step129]: loss 0.037194
[epoch11, step130]: loss 0.034138
[epoch11, step131]: loss 0.034047
[epoch11, step132]: loss 0.036868
[epoch11, step133]: loss 0.034201
[epoch11, step134]: loss 0.036359
[epoch11, step135]: loss 0.034186
[epoch11, step136]: loss 0.036155
[epoch11, step137]: loss 0.036822
[epoch11, step138]: loss 0.036736
[epoch11, step139]: loss 0.033852
[epoch11, step140]: loss 0.034435
[epoch11, step141]: loss 0.037505
[epoch11, step142]: loss 0.033488
[epoch11, step143]: loss 0.035892
[epoch11, step144]: loss 0.034380
[epoch11, step145]: loss 0.033754
[epoch11, step146]: loss 0.036443
[epoch11, step147]: loss 0.038393
[epoch11, step148]: loss 0.033217
[epoch11, step149]: loss 0.033312
[epoch11, step150]: loss 0.036352
[epoch11, step151]: loss 0.033963
[epoch11, step152]: loss 0.036628
[epoch11, step153]: loss 0.033412
[epoch11, step154]: loss 0.033877
[epoch11, step155]: loss 0.037018
[epoch11, step156]: loss 0.036198
[epoch11, step157]: loss 0.033415
[epoch11, step158]: loss 0.034064
[epoch11, step159]: loss 0.036475
[epoch11, step160]: loss 0.033528
[epoch11, step161]: loss 0.036258
[epoch11, step162]: loss 0.033810
[epoch11, step163]: loss 0.033940
[epoch11, step164]: loss 0.037144
[epoch11, step165]: loss 0.036901
[epoch11, step166]: loss 0.034694
[epoch11, step167]: loss 0.034096
[epoch11, step168]: loss 0.038993
[epoch11, step169]: loss 0.033362
[epoch11, step170]: loss 0.037001
[epoch11, step171]: loss 0.033854
[epoch11, step172]: loss 0.034057
[epoch11, step173]: loss 0.037007
[epoch11, step174]: loss 0.036755
[epoch11, step175]: loss 0.033963
[epoch11, step176]: loss 0.034222
[epoch11, step177]: loss 0.036866
[epoch11, step178]: loss 0.034157
[epoch11, step179]: loss 0.036002
[epoch11, step180]: loss 0.033482
[epoch11, step181]: loss 0.033917
[epoch11, step182]: loss 0.036789
[epoch11, step183]: loss 0.036962
[epoch11, step184]: loss 0.034163
[epoch11, step185]: loss 0.034205
[epoch11, step186]: loss 0.037197
[epoch11, step187]: loss 0.034859
[epoch11, step188]: loss 0.037100
[epoch11, step189]: loss 0.034425
[epoch11, step190]: loss 0.034519
[epoch11, step191]: loss 0.037111
[epoch11, step192]: loss 0.037441
[epoch11, step193]: loss 0.032553
[epoch11, step194]: loss 0.033253
[epoch11, step195]: loss 0.038717
[epoch11, step196]: loss 0.035839
[epoch11, step197]: loss 0.037370
[epoch11, step198]: loss 0.032582
[epoch11, step199]: loss 0.034067
[epoch11, step200]: loss 0.037168
[epoch11, step201]: loss 0.037001
[epoch11, step202]: loss 0.033945
[epoch11, step203]: loss 0.034759
[epoch11, step204]: loss 0.037546
[epoch11, step205]: loss 0.034489
[epoch11, step206]: loss 0.036760
[epoch11, step207]: loss 0.033655
[epoch11, step208]: loss 0.035040
[epoch11, step209]: loss 0.037015
[epoch11, step210]: loss 0.038255
[epoch11, step211]: loss 0.034710
[epoch11, step212]: loss 0.034552
[epoch11, step213]: loss 0.037212
[epoch11, step214]: loss 0.034442
[epoch11, step215]: loss 0.037024
[epoch11, step216]: loss 0.033946
[epoch11, step217]: loss 0.034817
[epoch11, step218]: loss 0.037312
[epoch11, step219]: loss 0.036500
[epoch11, step220]: loss 0.035102
[epoch11, step221]: loss 0.035092
[epoch11, step222]: loss 0.038225
[epoch11, step223]: loss 0.034206
[epoch11, step224]: loss 0.036269
[epoch11, step225]: loss 0.033464
[epoch11, step226]: loss 0.033663
[epoch11, step227]: loss 0.036462
[epoch11, step228]: loss 0.037216
[epoch11, step229]: loss 0.034105
[epoch11, step230]: loss 0.033924
[epoch11, step231]: loss 0.037111
[epoch11, step232]: loss 0.034291
[epoch11, step233]: loss 0.036046
[epoch11, step234]: loss 0.033268
[epoch11, step235]: loss 0.035095
[epoch11, step236]: loss 0.037108
[epoch11, step237]: loss 0.036819
[epoch11, step238]: loss 0.033877
[epoch11, step239]: loss 0.033093
[epoch11, step240]: loss 0.036264
[epoch11, step241]: loss 0.033879
[epoch11, step242]: loss 0.036648
[epoch11, step243]: loss 0.034556
[epoch11, step244]: loss 0.033828
[epoch11, step245]: loss 0.036474
[epoch11, step246]: loss 0.036776
[epoch11, step247]: loss 0.034123
[epoch11, step248]: loss 0.033223
[epoch11, step249]: loss 0.036053
[epoch11, step250]: loss 0.034961
[epoch11, step251]: loss 0.037646
[epoch11, step252]: loss 0.034478
[epoch11, step253]: loss 0.033106
[epoch11, step254]: loss 0.036673
[epoch11, step255]: loss 0.036417
[epoch11, step256]: loss 0.033351
[epoch11, step257]: loss 0.033517
[epoch11, step258]: loss 0.037716
[epoch11, step259]: loss 0.034570
[epoch11, step260]: loss 0.036150
[epoch11, step261]: loss 0.035422
[epoch11, step262]: loss 0.034925
[epoch11, step263]: loss 0.035977
[epoch11, step264]: loss 0.036070
[epoch11, step265]: loss 0.033710
[epoch11, step266]: loss 0.033182
[epoch11, step267]: loss 0.036331
[epoch11, step268]: loss 0.033945
[epoch11, step269]: loss 0.036157
[epoch11, step270]: loss 0.033744
[epoch11, step271]: loss 0.033862
[epoch11, step272]: loss 0.036472
[epoch11, step273]: loss 0.036410
[epoch11, step274]: loss 0.034068
[epoch11, step275]: loss 0.032804
[epoch11, step276]: loss 0.036319
[epoch11, step277]: loss 0.035267
[epoch11, step278]: loss 0.037301
[epoch11, step279]: loss 0.032894
[epoch11, step280]: loss 0.034730
[epoch11, step281]: loss 0.037066
[epoch11, step282]: loss 0.037733
[epoch11, step283]: loss 0.033272
[epoch11, step284]: loss 0.033305
[epoch11, step285]: loss 0.037807
[epoch11, step286]: loss 0.033784
[epoch11, step287]: loss 0.037637
[epoch11, step288]: loss 0.033362
[epoch11, step289]: loss 0.035227
[epoch11, step290]: loss 0.036785
[epoch11, step291]: loss 0.036593
[epoch11, step292]: loss 0.033314
[epoch11, step293]: loss 0.033873
[epoch11, step294]: loss 0.036471
[epoch11, step295]: loss 0.033977
[epoch11, step296]: loss 0.038494
[epoch11, step297]: loss 0.033585
[epoch11, step298]: loss 0.033948
[epoch11, step299]: loss 0.036276
[epoch11, step300]: loss 0.036584
[epoch11, step301]: loss 0.033841
[epoch11, step302]: loss 0.034494
[epoch11, step303]: loss 0.037313
[epoch11, step304]: loss 0.033476
[epoch11, step305]: loss 0.036160
[epoch11, step306]: loss 0.033927
[epoch11, step307]: loss 0.033646
[epoch11, step308]: loss 0.037585
[epoch11, step309]: loss 0.037591
[epoch11, step310]: loss 0.033618
[epoch11, step311]: loss 0.034397
[epoch11, step312]: loss 0.037107
[epoch11, step313]: loss 0.034064
[epoch11, step314]: loss 0.036063
[epoch11, step315]: loss 0.035210
[epoch11, step316]: loss 0.033676
[epoch11, step317]: loss 0.037545
[epoch11, step318]: loss 0.036750
[epoch11, step319]: loss 0.032942
[epoch11, step320]: loss 0.032512
[epoch11, step321]: loss 0.035636
[epoch11, step322]: loss 0.034013
[epoch11, step323]: loss 0.035357
[epoch11, step324]: loss 0.035888
[epoch11, step325]: loss 0.033918
[epoch11, step326]: loss 0.036140
[epoch11, step327]: loss 0.036054
[epoch11, step328]: loss 0.033744
[epoch11, step329]: loss 0.033449
[epoch11, step330]: loss 0.036302
[epoch11, step331]: loss 0.033885
[epoch11, step332]: loss 0.035920
[epoch11, step333]: loss 0.033583
[epoch11, step334]: loss 0.034168
[epoch11, step335]: loss 0.036702
[epoch11, step336]: loss 0.037976
[epoch11, step337]: loss 0.034833
[epoch11, step338]: loss 0.032849
[epoch11, step339]: loss 0.037027
[epoch11, step340]: loss 0.034708
[epoch11, step341]: loss 0.035669
[epoch11, step342]: loss 0.033103
[epoch11, step343]: loss 0.034471
[epoch11, step344]: loss 0.035955
[epoch11, step345]: loss 0.035790
[epoch11, step346]: loss 0.033274
[epoch11, step347]: loss 0.033762
[epoch11, step348]: loss 0.036939
[epoch11, step349]: loss 0.034947
[epoch11, step350]: loss 0.036869
[epoch11, step351]: loss 0.033390
[epoch11, step352]: loss 0.033940
[epoch11, step353]: loss 0.036576
[epoch11, step354]: loss 0.036233
[epoch11, step355]: loss 0.033359
[epoch11, step356]: loss 0.034579
[epoch11, step357]: loss 0.036347
[epoch11, step358]: loss 0.032659
[epoch11, step359]: loss 0.038182
[epoch11, step360]: loss 0.032342
[epoch11, step361]: loss 0.033572
[epoch11, step362]: loss 0.038332
[epoch11, step363]: loss 0.036436
[epoch11, step364]: loss 0.034032
[epoch11, step365]: loss 0.033581
[epoch11, step366]: loss 0.037243
[epoch11, step367]: loss 0.033857
[epoch11, step368]: loss 0.036338
[epoch11, step369]: loss 0.034151
[epoch11, step370]: loss 0.034653
[epoch11, step371]: loss 0.037176
[epoch11, step372]: loss 0.036601
[epoch11, step373]: loss 0.033454
[epoch11, step374]: loss 0.033314
[epoch11, step375]: loss 0.037411
[epoch11, step376]: loss 0.034183
[epoch11, step377]: loss 0.036899
[epoch11, step378]: loss 0.034556
[epoch11, step379]: loss 0.034929
[epoch11, step380]: loss 0.037723
[epoch11, step381]: loss 0.036499
[epoch11, step382]: loss 0.034348
[epoch11, step383]: loss 0.034023
[epoch11, step384]: loss 0.037379
[epoch11, step385]: loss 0.033680
[epoch11, step386]: loss 0.036340
[epoch11, step387]: loss 0.033443
[epoch11, step388]: loss 0.034803
[epoch11, step389]: loss 0.036859
[epoch11, step390]: loss 0.038169
[epoch11, step391]: loss 0.032757
[epoch11, step392]: loss 0.034715
[epoch11, step393]: loss 0.036783
[epoch11, step394]: loss 0.034048
[epoch11, step395]: loss 0.036643
[epoch11, step396]: loss 0.033460
[epoch11, step397]: loss 0.033925
[epoch11, step398]: loss 0.036541
[epoch11, step399]: loss 0.036191
[epoch11, step400]: loss 0.033078
[epoch11, step401]: loss 0.032772
[epoch11, step402]: loss 0.036343
[epoch11, step403]: loss 0.033748
[epoch11, step404]: loss 0.036902
[epoch11, step405]: loss 0.033887
[epoch11, step406]: loss 0.034268
[epoch11, step407]: loss 0.036840
[epoch11, step408]: loss 0.036490
[epoch11, step409]: loss 0.035089
[epoch11, step410]: loss 0.033958
[epoch11, step411]: loss 0.036324
[epoch11, step412]: loss 0.033507
[epoch11, step413]: loss 0.036601
[epoch11, step414]: loss 0.033882
[epoch11, step415]: loss 0.033784
[epoch11, step416]: loss 0.035954
[epoch11, step417]: loss 0.036502
[epoch11, step418]: loss 0.034209
[epoch11, step419]: loss 0.032734
[epoch11, step420]: loss 0.036618
[epoch11, step421]: loss 0.033293
[epoch11, step422]: loss 0.036204
[epoch11, step423]: loss 0.033462
[epoch11, step424]: loss 0.033966
[epoch11, step425]: loss 0.036334
[epoch11, step426]: loss 0.036477
[epoch11, step427]: loss 0.034034
[epoch11, step428]: loss 0.033526
[epoch11, step429]: loss 0.036979
[epoch11, step430]: loss 0.034225
[epoch11, step431]: loss 0.036714
[epoch11, step432]: loss 0.033119
[epoch11, step433]: loss 0.035253
[epoch11, step434]: loss 0.036314
[epoch11, step435]: loss 0.036957
[epoch11, step436]: loss 0.033362
[epoch11, step437]: loss 0.034033
[epoch11, step438]: loss 0.036774
[epoch11, step439]: loss 0.034045
[epoch11, step440]: loss 0.036660
[epoch11, step441]: loss 0.033577
[epoch11, step442]: loss 0.033602
[epoch11, step443]: loss 0.036787
[epoch11, step444]: loss 0.035959
[epoch11, step445]: loss 0.033932
[epoch11, step446]: loss 0.033838
[epoch11, step447]: loss 0.037005
[epoch11, step448]: loss 0.034190
[epoch11, step449]: loss 0.036330
[epoch11, step450]: loss 0.033725
[epoch11, step451]: loss 0.034049
[epoch11, step452]: loss 0.036304
[epoch11, step453]: loss 0.036661
[epoch11, step454]: loss 0.033410
[epoch11, step455]: loss 0.034360
[epoch11, step456]: loss 0.036172
[epoch11, step457]: loss 0.034574
[epoch11, step458]: loss 0.035965
[epoch11, step459]: loss 0.033814
[epoch11, step460]: loss 0.034028
[epoch11, step461]: loss 0.036923
[epoch11, step462]: loss 0.036337
[epoch11, step463]: loss 0.033889
[epoch11, step464]: loss 0.033494
[epoch11, step465]: loss 0.038076
[epoch11, step466]: loss 0.033680
[epoch11, step467]: loss 0.035973
[epoch11, step468]: loss 0.033613
[epoch11, step469]: loss 0.033780
[epoch11, step470]: loss 0.036427
[epoch11, step471]: loss 0.036591
[epoch11, step472]: loss 0.034103
[epoch11, step473]: loss 0.033163
[epoch11, step474]: loss 0.036012
[epoch11, step475]: loss 0.034066
[epoch11, step476]: loss 0.036718
[epoch11, step477]: loss 0.033614
[epoch11, step478]: loss 0.032948
[epoch11, step479]: loss 0.036542
[epoch11, step480]: loss 0.035901
[epoch11, step481]: loss 0.033103
[epoch11, step482]: loss 0.032653
[epoch11, step483]: loss 0.037789
[epoch11, step484]: loss 0.034572
[epoch11, step485]: loss 0.036607
[epoch11, step486]: loss 0.033744
[epoch11, step487]: loss 0.034136
[epoch11, step488]: loss 0.037332
[epoch11, step489]: loss 0.036757
[epoch11, step490]: loss 0.034469
[epoch11, step491]: loss 0.033720
[epoch11, step492]: loss 0.036758
[epoch11, step493]: loss 0.033745
[epoch11, step494]: loss 0.035747
[epoch11, step495]: loss 0.035589
[epoch11, step496]: loss 0.034162
[epoch11, step497]: loss 0.036793
[epoch11, step498]: loss 0.035906
[epoch11, step499]: loss 0.033731
[epoch11, step500]: loss 0.033163
[epoch11, step501]: loss 0.036209
[epoch11, step502]: loss 0.033359
[epoch11, step503]: loss 0.036695
[epoch11, step504]: loss 0.033867
[epoch11, step505]: loss 0.033081
[epoch11, step506]: loss 0.036895
[epoch11, step507]: loss 0.037449
[epoch11, step508]: loss 0.033867
[epoch11, step509]: loss 0.033524
[epoch11, step510]: loss 0.037204
[epoch11, step511]: loss 0.034419
[epoch11, step512]: loss 0.036735
[epoch11, step513]: loss 0.034412
[epoch11, step514]: loss 0.033753
[epoch11, step515]: loss 0.036445
[epoch11, step516]: loss 0.036422
[epoch11, step517]: loss 0.033444
[epoch11, step518]: loss 0.033255
[epoch11, step519]: loss 0.036924
[epoch11, step520]: loss 0.033461
[epoch11, step521]: loss 0.036415
[epoch11, step522]: loss 0.033439
[epoch11, step523]: loss 0.033454
[epoch11, step524]: loss 0.035999
[epoch11, step525]: loss 0.036837
[epoch11, step526]: loss 0.033461
[epoch11, step527]: loss 0.032971
[epoch11, step528]: loss 0.036354
[epoch11, step529]: loss 0.033554
[epoch11, step530]: loss 0.037265
[epoch11, step531]: loss 0.033772
[epoch11, step532]: loss 0.033733
[epoch11, step533]: loss 0.038458
[epoch11, step534]: loss 0.036164
[epoch11, step535]: loss 0.034659
[epoch11, step536]: loss 0.033531
[epoch11, step537]: loss 0.036601
[epoch11, step538]: loss 0.034114
[epoch11, step539]: loss 0.036433
[epoch11, step540]: loss 0.034061
[epoch11, step541]: loss 0.033853
[epoch11, step542]: loss 0.036881
[epoch11, step543]: loss 0.036408
[epoch11, step544]: loss 0.033521
[epoch11, step545]: loss 0.033601
[epoch11, step546]: loss 0.037986
[epoch11, step547]: loss 0.033909
[epoch11, step548]: loss 0.036758
[epoch11, step549]: loss 0.034057
[epoch11, step550]: loss 0.033512
[epoch11, step551]: loss 0.037050
[epoch11, step552]: loss 0.036213
[epoch11, step553]: loss 0.033823
[epoch11, step554]: loss 0.033396
[epoch11, step555]: loss 0.036158
[epoch11, step556]: loss 0.033561
[epoch11, step557]: loss 0.035569
[epoch11, step558]: loss 0.034478
[epoch11, step559]: loss 0.034210
[epoch11, step560]: loss 0.037409
[epoch11, step561]: loss 0.036031
[epoch11, step562]: loss 0.033295
[epoch11, step563]: loss 0.030989
[epoch11, step564]: loss 0.032450
[epoch11, step565]: loss 0.028245
[epoch11, step566]: loss 0.036482
[epoch11, step567]: loss 0.028557
[epoch11, step568]: loss 0.027847
[epoch11, step569]: loss 0.024923
[epoch11, step570]: loss 0.033286
[epoch11, step571]: loss 0.026150
[epoch11, step572]: loss 0.026448
[epoch11, step573]: loss 0.030290
[epoch11, step574]: loss 0.028860
[epoch11, step575]: loss 0.022161
[epoch11, step576]: loss 0.022622
[epoch11, step577]: loss 0.028614
[epoch11, step578]: loss 0.020816
[epoch11, step579]: loss 0.030371
[epoch11, step580]: loss 0.021914
[epoch11, step581]: loss 0.027507
[epoch11, step582]: loss 0.027579
[epoch11, step583]: loss 0.023738
[epoch11, step584]: loss 0.025487
[epoch11, step585]: loss 0.027794
[epoch11, step586]: loss 0.022970
[epoch11, step587]: loss 0.029439
[epoch11, step588]: loss 0.025280
[epoch11, step589]: loss 0.024316
[epoch11, step590]: loss 0.029396
[epoch11, step591]: loss 0.022594
[epoch11, step592]: loss 0.027035
[epoch11, step593]: loss 0.023677
[epoch11, step594]: loss 0.028041
[epoch11, step595]: loss 0.027523
[epoch11, step596]: loss 0.022836
[epoch11, step597]: loss 0.025323
[epoch11, step598]: loss 0.028329
[epoch11, step599]: loss 0.025502
[epoch11, step600]: loss 0.027497
[epoch11, step601]: loss 0.020039
[epoch11, step602]: loss 0.023932
[epoch11, step603]: loss 0.027179
[epoch11, step604]: loss 0.026559
[epoch11, step605]: loss 0.025432
[epoch11, step606]: loss 0.026412
[epoch11, step607]: loss 0.027693
[epoch11, step608]: loss 0.026438
[epoch11, step609]: loss 0.026974
[epoch11, step610]: loss 0.027129
[epoch11, step611]: loss 0.026713
[epoch11, step612]: loss 0.026581
[epoch11, step613]: loss 0.019622
[epoch11, step614]: loss 0.025952
[epoch11, step615]: loss 0.028866
[epoch11, step616]: loss 0.024760
[epoch11, step617]: loss 0.023602
[epoch11, step618]: loss 0.025980
[epoch11, step619]: loss 0.027719
[epoch11, step620]: loss 0.024520
[epoch11, step621]: loss 0.026156
[epoch11, step622]: loss 0.020352
[epoch11, step623]: loss 0.024633
[epoch11, step624]: loss 0.026554
[epoch11, step625]: loss 0.026481
[epoch11, step626]: loss 0.027938
[epoch11, step627]: loss 0.023052
[epoch11, step628]: loss 0.025636
[epoch11, step629]: loss 0.021099
[epoch11, step630]: loss 0.023073
[epoch11, step631]: loss 0.031008
[epoch11, step632]: loss 0.023534
[epoch11, step633]: loss 0.024470
[epoch11, step634]: loss 0.026670
[epoch11, step635]: loss 0.025397
[epoch11, step636]: loss 0.020373
[epoch11, step637]: loss 0.027154
[epoch11, step638]: loss 0.026807
[epoch11, step639]: loss 0.022739
[epoch11, step640]: loss 0.029243
[epoch11, step641]: loss 0.029906
[epoch11, step642]: loss 0.024572
[epoch11, step643]: loss 0.024943
[epoch11, step644]: loss 0.025698
[epoch11, step645]: loss 0.023575
[epoch11, step646]: loss 0.025795
[epoch11, step647]: loss 0.023137
[epoch11, step648]: loss 0.023343
[epoch11, step649]: loss 0.028688
[epoch11, step650]: loss 0.021834
[epoch11, step651]: loss 0.025680
[epoch11, step652]: loss 0.026571
[epoch11, step653]: loss 0.027806
[epoch11, step654]: loss 0.022587
[epoch11, step655]: loss 0.024217
[epoch11, step656]: loss 0.021349
[epoch11, step657]: loss 0.027452
[epoch11, step658]: loss 0.025067
[epoch11, step659]: loss 0.026983
[epoch11, step660]: loss 0.023355
[epoch11, step661]: loss 0.026066
[epoch11, step662]: loss 0.023745
[epoch11, step663]: loss 0.021103
[epoch11, step664]: loss 0.024912
[epoch11, step665]: loss 0.027197
[epoch11, step666]: loss 0.026297
[epoch11, step667]: loss 0.025933
[epoch11, step668]: loss 0.022535
[epoch11, step669]: loss 0.025976
[epoch11, step670]: loss 0.026110
[epoch11, step671]: loss 0.021076
[epoch11, step672]: loss 0.023522
[epoch11, step673]: loss 0.022378
[epoch11, step674]: loss 0.020818
[epoch11, step675]: loss 0.019596
[epoch11, step676]: loss 0.024027
[epoch11, step677]: loss 0.024948
[epoch11, step678]: loss 0.022579
[epoch11, step679]: loss 0.023318
[epoch11, step680]: loss 0.030615
[epoch11, step681]: loss 0.021262
[epoch11, step682]: loss 0.025768
[epoch11, step683]: loss 0.025830
[epoch11, step684]: loss 0.024664
[epoch11, step685]: loss 0.024002
[epoch11, step686]: loss 0.027114
[epoch11, step687]: loss 0.026474
[epoch11, step688]: loss 0.022807
[epoch11, step689]: loss 0.024316
[epoch11, step690]: loss 0.024887
[epoch11, step691]: loss 0.024091
[epoch11, step692]: loss 0.022162
[epoch11, step693]: loss 0.026839
[epoch11, step694]: loss 0.022248
[epoch11, step695]: loss 0.026035
[epoch11, step696]: loss 0.025581
[epoch11, step697]: loss 0.026860
[epoch11, step698]: loss 0.024154
[epoch11, step699]: loss 0.023242
[epoch11, step700]: loss 0.021658
[epoch11, step701]: loss 0.025738
[epoch11, step702]: loss 0.021329
[epoch11, step703]: loss 0.022987
[epoch11, step704]: loss 0.025137
[epoch11, step705]: loss 0.024201
[epoch11, step706]: loss 0.023226
[epoch11, step707]: loss 0.024864
[epoch11, step708]: loss 0.025260
[epoch11, step709]: loss 0.027027
[epoch11, step710]: loss 0.023057
[epoch11, step711]: loss 0.023367
[epoch11, step712]: loss 0.025794
[epoch11, step713]: loss 0.025819
[epoch11, step714]: loss 0.020871
[epoch11, step715]: loss 0.022260
[epoch11, step716]: loss 0.025767
[epoch11, step717]: loss 0.022966
[epoch11, step718]: loss 0.024504
[epoch11, step719]: loss 0.032463
[epoch11, step720]: loss 0.023852
[epoch11, step721]: loss 0.022411
[epoch11, step722]: loss 0.030113
[epoch11, step723]: loss 0.026114
[epoch11, step724]: loss 0.022272
[epoch11, step725]: loss 0.027354
[epoch11, step726]: loss 0.022951
[epoch11, step727]: loss 0.024371
[epoch11, step728]: loss 0.026068
[epoch11, step729]: loss 0.020640
[epoch11, step730]: loss 0.022413
[epoch11, step731]: loss 0.025651
[epoch11, step732]: loss 0.025564
[epoch11, step733]: loss 0.023740
[epoch11, step734]: loss 0.022218
[epoch11, step735]: loss 0.027177
[epoch11, step736]: loss 0.024723
[epoch11, step737]: loss 0.026388
[epoch11, step738]: loss 0.020110
[epoch11, step739]: loss 0.025282
[epoch11, step740]: loss 0.021890
[epoch11, step741]: loss 0.024613
[epoch11, step742]: loss 0.021643
[epoch11, step743]: loss 0.022588
[epoch11, step744]: loss 0.023264
[epoch11, step745]: loss 0.024098
[epoch11, step746]: loss 0.024615
[epoch11, step747]: loss 0.026833
[epoch11, step748]: loss 0.025074
[epoch11, step749]: loss 0.025576
[epoch11, step750]: loss 0.026905
[epoch11, step751]: loss 0.021289
[epoch11, step752]: loss 0.024449
[epoch11, step753]: loss 0.025354
[epoch11, step754]: loss 0.022278
[epoch11, step755]: loss 0.025638
[epoch11, step756]: loss 0.023268
[epoch11, step757]: loss 0.020290
[epoch11, step758]: loss 0.024521
[epoch11, step759]: loss 0.022401
[epoch11, step760]: loss 0.023644
[epoch11, step761]: loss 0.026414
[epoch11, step762]: loss 0.021050
[epoch11, step763]: loss 0.024880
[epoch11, step764]: loss 0.023523
[epoch11, step765]: loss 0.025360
[epoch11, step766]: loss 0.024458
[epoch11, step767]: loss 0.026539
[epoch11, step768]: loss 0.020230
[epoch11, step769]: loss 0.026303
[epoch11, step770]: loss 0.025153
[epoch11, step771]: loss 0.022690
[epoch11, step772]: loss 0.027968
[epoch11, step773]: loss 0.025916
[epoch11, step774]: loss 0.024280
[epoch11, step775]: loss 0.020390
[epoch11, step776]: loss 0.025116
[epoch11, step777]: loss 0.022232
[epoch11, step778]: loss 0.027145
[epoch11, step779]: loss 0.023349
[epoch11, step780]: loss 0.019630
[epoch11, step781]: loss 0.024083
[epoch11, step782]: loss 0.022058
[epoch11, step783]: loss 0.018972
[epoch11, step784]: loss 0.020520
[epoch11, step785]: loss 0.021124
[epoch11, step786]: loss 0.024839
[epoch11, step787]: loss 0.023106
[epoch11, step788]: loss 0.024365
[epoch11, step789]: loss 0.022381
[epoch11, step790]: loss 0.022469
[epoch11, step791]: loss 0.026571
[epoch11, step792]: loss 0.024765
[epoch11, step793]: loss 0.026312
[epoch11, step794]: loss 0.020240
[epoch11, step795]: loss 0.025153
[epoch11, step796]: loss 0.027498
[epoch11, step797]: loss 0.026983
[epoch11, step798]: loss 0.026294
[epoch11, step799]: loss 0.025100
[epoch11, step800]: loss 0.021298
[epoch11, step801]: loss 0.021856
[epoch11, step802]: loss 0.022428
[epoch11, step803]: loss 0.025619
[epoch11, step804]: loss 0.027178
[epoch11, step805]: loss 0.028694
[epoch11, step806]: loss 0.020886
[epoch11, step807]: loss 0.020646
[epoch11, step808]: loss 0.022726
[epoch11, step809]: loss 0.022021
[epoch11, step810]: loss 0.025030
[epoch11, step811]: loss 0.024794
[epoch11, step812]: loss 0.023827
[epoch11, step813]: loss 0.022660
[epoch11, step814]: loss 0.024694
[epoch11, step815]: loss 0.024666
[epoch11, step816]: loss 0.023446
[epoch11, step817]: loss 0.024021
[epoch11, step818]: loss 0.021366
[epoch11, step819]: loss 0.020192
[epoch11, step820]: loss 0.022903
[epoch11, step821]: loss 0.020871
[epoch11, step822]: loss 0.029742
[epoch11, step823]: loss 0.023727
[epoch11, step824]: loss 0.026557
[epoch11, step825]: loss 0.024753
[epoch11, step826]: loss 0.023661
[epoch11, step827]: loss 0.025861
[epoch11, step828]: loss 0.027942
[epoch11, step829]: loss 0.026172
[epoch11, step830]: loss 0.022163
[epoch11, step831]: loss 0.026326
[epoch11, step832]: loss 0.021482
[epoch11, step833]: loss 0.028381
[epoch11, step834]: loss 0.025240
[epoch11, step835]: loss 0.020434
[epoch11, step836]: loss 0.026534
[epoch11, step837]: loss 0.024936
[epoch11, step838]: loss 0.026166
[epoch11, step839]: loss 0.028344
[epoch11, step840]: loss 0.020138
[epoch11, step841]: loss 0.023318
[epoch11, step842]: loss 0.027388
[epoch11, step843]: loss 0.024408
[epoch11, step844]: loss 0.024543
[epoch11, step845]: loss 0.020502
[epoch11, step846]: loss 0.025918
[epoch11, step847]: loss 0.026605
[epoch11, step848]: loss 0.024401
[epoch11, step849]: loss 0.024343
[epoch11, step850]: loss 0.022248
[epoch11, step851]: loss 0.023741
[epoch11, step852]: loss 0.022363
[epoch11, step853]: loss 0.028578
[epoch11, step854]: loss 0.022676
[epoch11, step855]: loss 0.026483
[epoch11, step856]: loss 0.021065
[epoch11, step857]: loss 0.024902
[epoch11, step858]: loss 0.023720
[epoch11, step859]: loss 0.022964
[epoch11, step860]: loss 0.022332
[epoch11, step861]: loss 0.022696
[epoch11, step862]: loss 0.022397
[epoch11, step863]: loss 0.020645
[epoch11, step864]: loss 0.026300
[epoch11, step865]: loss 0.023159
[epoch11, step866]: loss 0.024678
[epoch11, step867]: loss 0.025209
[epoch11, step868]: loss 0.026480
[epoch11, step869]: loss 0.023349
[epoch11, step870]: loss 0.030414
[epoch11, step871]: loss 0.022323
[epoch11, step872]: loss 0.025104
[epoch11, step873]: loss 0.025382
[epoch11, step874]: loss 0.023253
[epoch11, step875]: loss 0.023483
[epoch11, step876]: loss 0.023976
[epoch11, step877]: loss 0.018810
[epoch11, step878]: loss 0.022857
[epoch11, step879]: loss 0.027869
[epoch11, step880]: loss 0.025159
[epoch11, step881]: loss 0.021980
[epoch11, step882]: loss 0.023121
[epoch11, step883]: loss 0.022922
[epoch11, step884]: loss 0.025616
[epoch11, step885]: loss 0.025294
[epoch11, step886]: loss 0.026099
[epoch11, step887]: loss 0.023638
[epoch11, step888]: loss 0.023809
[epoch11, step889]: loss 0.022482
[epoch11, step890]: loss 0.023525
[epoch11, step891]: loss 0.024695
[epoch11, step892]: loss 0.020317
[epoch11, step893]: loss 0.024249
[epoch11, step894]: loss 0.024691
[epoch11, step895]: loss 0.021901
[epoch11, step896]: loss 0.022210
[epoch11, step897]: loss 0.023427
[epoch11, step898]: loss 0.024795
[epoch11, step899]: loss 0.027465
[epoch11, step900]: loss 0.026463
[epoch11, step901]: loss 0.025066
[epoch11, step902]: loss 0.023269
[epoch11, step903]: loss 0.023539
[epoch11, step904]: loss 0.027784
[epoch11, step905]: loss 0.027133
[epoch11, step906]: loss 0.021789
[epoch11, step907]: loss 0.023296
[epoch11, step908]: loss 0.022681
[epoch11, step909]: loss 0.024839
[epoch11, step910]: loss 0.023292
[epoch11, step911]: loss 0.024679
[epoch11, step912]: loss 0.023494
[epoch11, step913]: loss 0.023281
[epoch11, step914]: loss 0.029668
[epoch11, step915]: loss 0.023576
[epoch11, step916]: loss 0.023755
[epoch11, step917]: loss 0.025098
[epoch11, step918]: loss 0.028284
[epoch11, step919]: loss 0.023516
[epoch11, step920]: loss 0.027378
[epoch11, step921]: loss 0.023628
[epoch11, step922]: loss 0.022760
[epoch11, step923]: loss 0.022357
[epoch11, step924]: loss 0.020470
[epoch11, step925]: loss 0.024939
[epoch11, step926]: loss 0.026552
[epoch11, step927]: loss 0.024615
[epoch11, step928]: loss 0.024382
[epoch11, step929]: loss 0.026898
[epoch11, step930]: loss 0.025344
[epoch11, step931]: loss 0.026370
[epoch11, step932]: loss 0.020981
[epoch11, step933]: loss 0.027961
[epoch11, step934]: loss 0.022533
[epoch11, step935]: loss 0.023031
[epoch11, step936]: loss 0.022331
[epoch11, step937]: loss 0.026867
[epoch11, step938]: loss 0.025624
[epoch11, step939]: loss 0.021049
[epoch11, step940]: loss 0.022930
[epoch11, step941]: loss 0.026353
[epoch11, step942]: loss 0.024973
[epoch11, step943]: loss 0.022957
[epoch11, step944]: loss 0.027154
[epoch11, step945]: loss 0.020112
[epoch11, step946]: loss 0.025097
[epoch11, step947]: loss 0.027453
[epoch11, step948]: loss 0.019409
[epoch11, step949]: loss 0.022673
[epoch11, step950]: loss 0.026095
[epoch11, step951]: loss 0.028006
[epoch11, step952]: loss 0.024656
[epoch11, step953]: loss 0.027098
[epoch11, step954]: loss 0.021753
[epoch11, step955]: loss 0.036316
[epoch11, step956]: loss 0.052014
[epoch11, step957]: loss 0.046438
[epoch11, step958]: loss 0.044177
[epoch11, step959]: loss 0.048330
[epoch11, step960]: loss 0.044724
[epoch11, step961]: loss 0.046219
[epoch11, step962]: loss 0.045353
[epoch11, step963]: loss 0.042848
[epoch11, step964]: loss 0.043650
[epoch11, step965]: loss 0.043379
[epoch11, step966]: loss 0.039236
[epoch11, step967]: loss 0.037773
[epoch11, step968]: loss 0.040956
[epoch11, step969]: loss 0.040839
[epoch11, step970]: loss 0.040196
[epoch11, step971]: loss 0.038874
[epoch11, step972]: loss 0.039555
[epoch11, step973]: loss 0.038159
[epoch11, step974]: loss 0.040069
[epoch11, step975]: loss 0.037464
[epoch11, step976]: loss 0.036793
[epoch11, step977]: loss 0.040135
[epoch11, step978]: loss 0.039110
[epoch11, step979]: loss 0.037919
[epoch11, step980]: loss 0.036263
[epoch11, step981]: loss 0.037906
[epoch11, step982]: loss 0.038233
[epoch11, step983]: loss 0.039072
[epoch11, step984]: loss 0.035540
[epoch11, step985]: loss 0.035565
[epoch11, step986]: loss 0.040019
[epoch11, step987]: loss 0.038007
[epoch11, step988]: loss 0.037404
[epoch11, step989]: loss 0.036782
[epoch11, step990]: loss 0.037644
[epoch11, step991]: loss 0.038171
[epoch11, step992]: loss 0.038999
[epoch11, step993]: loss 0.036086
[epoch11, step994]: loss 0.035405
[epoch11, step995]: loss 0.039184
[epoch11, step996]: loss 0.037219
[epoch11, step997]: loss 0.037500
[epoch11, step998]: loss 0.036447
[epoch11, step999]: loss 0.037596
[epoch11, step1000]: loss 0.037428
[epoch11, step1001]: loss 0.038606
[epoch11, step1002]: loss 0.035966
[epoch11, step1003]: loss 0.035264
[epoch11, step1004]: loss 0.039387
[epoch11, step1005]: loss 0.036803
[epoch11, step1006]: loss 0.037106
[epoch11, step1007]: loss 0.035066
[epoch11, step1008]: loss 0.037035
[epoch11, step1009]: loss 0.036890
[epoch11, step1010]: loss 0.039261
[epoch11, step1011]: loss 0.035301
[epoch11, step1012]: loss 0.035287
[epoch11, step1013]: loss 0.038709
[epoch11, step1014]: loss 0.037330
[epoch11, step1015]: loss 0.036881
[epoch11, step1016]: loss 0.034959
[epoch11, step1017]: loss 0.036489
[epoch11, step1018]: loss 0.037137
[epoch11, step1019]: loss 0.037822
[epoch11, step1020]: loss 0.034863
[epoch11, step1021]: loss 0.034891
[epoch11, step1022]: loss 0.038444
[epoch11, step1023]: loss 0.036828
[epoch11, step1024]: loss 0.037093
[epoch11, step1025]: loss 0.035007
[epoch11, step1026]: loss 0.036192
[epoch11, step1027]: loss 0.036406
[epoch11, step1028]: loss 0.038127
[epoch11, step1029]: loss 0.035004
[epoch11, step1030]: loss 0.034063
[epoch11, step1031]: loss 0.037199
[epoch11, step1032]: loss 0.037762
[epoch11, step1033]: loss 0.036099
[epoch11, step1034]: loss 0.034413
[epoch11, step1035]: loss 0.035841
[epoch11, step1036]: loss 0.036433
[epoch11, step1037]: loss 0.037361
[epoch11, step1038]: loss 0.034255
[epoch11, step1039]: loss 0.035077
[epoch11, step1040]: loss 0.037762
[epoch11, step1041]: loss 0.036863
[epoch11, step1042]: loss 0.035369
[epoch11, step1043]: loss 0.034395
[epoch11, step1044]: loss 0.036201
[epoch11, step1045]: loss 0.036112
[epoch11, step1046]: loss 0.037346
[epoch11, step1047]: loss 0.035864
[epoch11, step1048]: loss 0.033954
[epoch11, step1049]: loss 0.037591
[epoch11, step1050]: loss 0.036653
[epoch11, step1051]: loss 0.036352
[epoch11, step1052]: loss 0.035367
[epoch11, step1053]: loss 0.037197
[epoch11, step1054]: loss 0.036848
[epoch11, step1055]: loss 0.037511
[epoch11, step1056]: loss 0.034167
[epoch11, step1057]: loss 0.036478
[epoch11, step1058]: loss 0.040824
[epoch11, step1059]: loss 0.037731
[epoch11, step1060]: loss 0.037306
[epoch11, step1061]: loss 0.034438
[epoch11, step1062]: loss 0.036606
[epoch11, step1063]: loss 0.036654
[epoch11, step1064]: loss 0.037894
[epoch11, step1065]: loss 0.035183
[epoch11, step1066]: loss 0.034915
[epoch11, step1067]: loss 0.038084
[epoch11, step1068]: loss 0.035699
[epoch11, step1069]: loss 0.035536
[epoch11, step1070]: loss 0.034623
[epoch11, step1071]: loss 0.037698
[epoch11, step1072]: loss 0.037955
[epoch11, step1073]: loss 0.037847
[epoch11, step1074]: loss 0.035103
[epoch11, step1075]: loss 0.035170
[epoch11, step1076]: loss 0.038387
[epoch11, step1077]: loss 0.036797
[epoch11, step1078]: loss 0.036418
[epoch11, step1079]: loss 0.035745
[epoch11, step1080]: loss 0.036858
[epoch11, step1081]: loss 0.036509
[epoch11, step1082]: loss 0.037680
[epoch11, step1083]: loss 0.035412
[epoch11, step1084]: loss 0.034802
[epoch11, step1085]: loss 0.037572
[epoch11, step1086]: loss 0.035953
[epoch11, step1087]: loss 0.036169
[epoch11, step1088]: loss 0.034472
[epoch11, step1089]: loss 0.036414
[epoch11, step1090]: loss 0.037101
[epoch11, step1091]: loss 0.037649
[epoch11, step1092]: loss 0.034713
[epoch11, step1093]: loss 0.034563
[epoch11, step1094]: loss 0.037140
[epoch11, step1095]: loss 0.035711
[epoch11, step1096]: loss 0.035256
[epoch11, step1097]: loss 0.034519
[epoch11, step1098]: loss 0.036033
[epoch11, step1099]: loss 0.036292
[epoch11, step1100]: loss 0.037765
[epoch11, step1101]: loss 0.035193
[epoch11, step1102]: loss 0.034760
[epoch11, step1103]: loss 0.037456
[epoch11, step1104]: loss 0.035883
[epoch11, step1105]: loss 0.036186
[epoch11, step1106]: loss 0.033507
[epoch11, step1107]: loss 0.036699
[epoch11, step1108]: loss 0.036020
[epoch11, step1109]: loss 0.038128
[epoch11, step1110]: loss 0.035671
[epoch11, step1111]: loss 0.034575
[epoch11, step1112]: loss 0.038099
[epoch11, step1113]: loss 0.036151
[epoch11, step1114]: loss 0.036201
[epoch11, step1115]: loss 0.034582
[epoch11, step1116]: loss 0.036506
[epoch11, step1117]: loss 0.036831
[epoch11, step1118]: loss 0.037166
[epoch11, step1119]: loss 0.035385
[epoch11, step1120]: loss 0.034371
[epoch11, step1121]: loss 0.037688
[epoch11, step1122]: loss 0.035711
[epoch11, step1123]: loss 0.035346
[epoch11, step1124]: loss 0.035417
[epoch11, step1125]: loss 0.036519
[epoch11, step1126]: loss 0.036913
[epoch11, step1127]: loss 0.037631
[epoch11, step1128]: loss 0.034837
[epoch11, step1129]: loss 0.034554
[epoch11, step1130]: loss 0.038377
[epoch11, step1131]: loss 0.036136
[epoch11, step1132]: loss 0.035908
[epoch11, step1133]: loss 0.034114
[epoch11, step1134]: loss 0.035679
[epoch11, step1135]: loss 0.038398
[epoch11, step1136]: loss 0.038996
[epoch11, step1137]: loss 0.034576
[epoch11, step1138]: loss 0.034512
[epoch11, step1139]: loss 0.038008
[epoch11, step1140]: loss 0.036129
[epoch11, step1141]: loss 0.035739
[epoch11, step1142]: loss 0.034294
[epoch11, step1143]: loss 0.036153
[epoch11, step1144]: loss 0.036569
[epoch11, step1145]: loss 0.036985
[epoch11, step1146]: loss 0.034059
[epoch11, step1147]: loss 0.035318
[epoch11, step1148]: loss 0.037678
[epoch11, step1149]: loss 0.035761
[epoch11, step1150]: loss 0.035604
[epoch11, step1151]: loss 0.035163
[epoch11, step1152]: loss 0.036700
[epoch11, step1153]: loss 0.035895
[epoch11, step1154]: loss 0.038341
[epoch11, step1155]: loss 0.034491
[epoch11, step1156]: loss 0.034497
[epoch11, step1157]: loss 0.038080
[epoch11, step1158]: loss 0.036156
[epoch11, step1159]: loss 0.035929
[epoch11, step1160]: loss 0.035525
[epoch11, step1161]: loss 0.036835
[epoch11, step1162]: loss 0.036154
[epoch11, step1163]: loss 0.036940
[epoch11, step1164]: loss 0.034360
[epoch11, step1165]: loss 0.035856
[epoch11, step1166]: loss 0.038142
[epoch11, step1167]: loss 0.035364
[epoch11, step1168]: loss 0.036043
[epoch11, step1169]: loss 0.034225
[epoch11, step1170]: loss 0.035876
[epoch11, step1171]: loss 0.036069
[epoch11, step1172]: loss 0.037009
[epoch11, step1173]: loss 0.034261
[epoch11, step1174]: loss 0.034640
[epoch11, step1175]: loss 0.037655
[epoch11, step1176]: loss 0.036061
[epoch11, step1177]: loss 0.035829
[epoch11, step1178]: loss 0.033977
[epoch11, step1179]: loss 0.035991
[epoch11, step1180]: loss 0.037515
[epoch11, step1181]: loss 0.038789
[epoch11, step1182]: loss 0.034104
[epoch11, step1183]: loss 0.034423
[epoch11, step1184]: loss 0.037600
[epoch11, step1185]: loss 0.036111
[epoch11, step1186]: loss 0.035635
[epoch11, step1187]: loss 0.034344
[epoch11, step1188]: loss 0.035339
[epoch11, step1189]: loss 0.036050
[epoch11, step1190]: loss 0.037390
[epoch11, step1191]: loss 0.036919
[epoch11, step1192]: loss 0.035011
[epoch11, step1193]: loss 0.037919
[epoch11, step1194]: loss 0.036032
[epoch11, step1195]: loss 0.035559
[epoch11, step1196]: loss 0.034574
[epoch11, step1197]: loss 0.036641
[epoch11, step1198]: loss 0.036786
[epoch11, step1199]: loss 0.037382
[epoch11, step1200]: loss 0.034597
[epoch11, step1201]: loss 0.034983
[epoch11, step1202]: loss 0.038953
[epoch11, step1203]: loss 0.036278
[epoch11, step1204]: loss 0.035338
[epoch11, step1205]: loss 0.033954
[epoch11, step1206]: loss 0.035622
[epoch11, step1207]: loss 0.037136
[epoch11, step1208]: loss 0.038184
[epoch11, step1209]: loss 0.033231
[epoch11, step1210]: loss 0.035482
[epoch11, step1211]: loss 0.037123
[epoch11, step1212]: loss 0.035664
[epoch11, step1213]: loss 0.035800
[epoch11, step1214]: loss 0.034227
[epoch11, step1215]: loss 0.036558
[epoch11, step1216]: loss 0.036383
[epoch11, step1217]: loss 0.037663
[epoch11, step1218]: loss 0.034387
[epoch11, step1219]: loss 0.035256
[epoch11, step1220]: loss 0.037892
[epoch11, step1221]: loss 0.035329
[epoch11, step1222]: loss 0.035871
[epoch11, step1223]: loss 0.034600
[epoch11, step1224]: loss 0.036431
[epoch11, step1225]: loss 0.036105
[epoch11, step1226]: loss 0.037372
[epoch11, step1227]: loss 0.034734
[epoch11, step1228]: loss 0.034704
[epoch11, step1229]: loss 0.037692
[epoch11, step1230]: loss 0.036079
[epoch11, step1231]: loss 0.035516
[epoch11, step1232]: loss 0.036301
[epoch11, step1233]: loss 0.035866
[epoch11, step1234]: loss 0.035783
[epoch11, step1235]: loss 0.037823
[epoch11, step1236]: loss 0.034916
[epoch11, step1237]: loss 0.034260
[epoch11, step1238]: loss 0.037471
[epoch11, step1239]: loss 0.036399
[epoch11, step1240]: loss 0.035868
[epoch11, step1241]: loss 0.034640
[epoch11, step1242]: loss 0.036094
[epoch11, step1243]: loss 0.035855
[epoch11, step1244]: loss 0.037415
[epoch11, step1245]: loss 0.034864
[epoch11, step1246]: loss 0.034643
[epoch11, step1247]: loss 0.036967
[epoch11, step1248]: loss 0.036137
[epoch11, step1249]: loss 0.036205
[epoch11, step1250]: loss 0.034228
[epoch11, step1251]: loss 0.036602
[epoch11, step1252]: loss 0.037305
[epoch11, step1253]: loss 0.037386
[epoch11, step1254]: loss 0.034230
[epoch11, step1255]: loss 0.034479
[epoch11, step1256]: loss 0.038073
[epoch11, step1257]: loss 0.036620
[epoch11, step1258]: loss 0.036016
[epoch11, step1259]: loss 0.034286
[epoch11, step1260]: loss 0.036357
[epoch11, step1261]: loss 0.035639
[epoch11, step1262]: loss 0.036649
[epoch11, step1263]: loss 0.035724
[epoch11, step1264]: loss 0.035067
[epoch11, step1265]: loss 0.036896
[epoch11, step1266]: loss 0.035656
[epoch11, step1267]: loss 0.035954
[epoch11, step1268]: loss 0.034240
[epoch11, step1269]: loss 0.035955
[epoch11, step1270]: loss 0.035614
[epoch11, step1271]: loss 0.037435
[epoch11, step1272]: loss 0.034069
[epoch11, step1273]: loss 0.034322
[epoch11, step1274]: loss 0.037546
[epoch11, step1275]: loss 0.036668
[epoch11, step1276]: loss 0.035540
[epoch11, step1277]: loss 0.034414
[epoch11, step1278]: loss 0.036479
[epoch11, step1279]: loss 0.036565
[epoch11, step1280]: loss 0.037406
[epoch11, step1281]: loss 0.034428
[epoch11, step1282]: loss 0.034510
[epoch11, step1283]: loss 0.037068
[epoch11, step1284]: loss 0.035337
[epoch11, step1285]: loss 0.037451
[epoch11, step1286]: loss 0.034762
[epoch11, step1287]: loss 0.038044
[epoch11, step1288]: loss 0.038026
[epoch11, step1289]: loss 0.038719
[epoch11, step1290]: loss 0.034744
[epoch11, step1291]: loss 0.035020
[epoch11, step1292]: loss 0.038631
[epoch11, step1293]: loss 0.036145
[epoch11, step1294]: loss 0.036527
[epoch11, step1295]: loss 0.035516
[epoch11, step1296]: loss 0.037028
[epoch11, step1297]: loss 0.037218
[epoch11, step1298]: loss 0.038380
[epoch11, step1299]: loss 0.035363
[epoch11, step1300]: loss 0.035665
[epoch11, step1301]: loss 0.037414
[epoch11, step1302]: loss 0.036439
[epoch11, step1303]: loss 0.036211
[epoch11, step1304]: loss 0.034427
[epoch11, step1305]: loss 0.036855
[epoch11, step1306]: loss 0.036269
[epoch11, step1307]: loss 0.037359
[epoch11, step1308]: loss 0.035064
[epoch11, step1309]: loss 0.034053
[epoch11, step1310]: loss 0.037432
[epoch11, step1311]: loss 0.035645
[epoch11, step1312]: loss 0.036470
[epoch11, step1313]: loss 0.034517
[epoch11, step1314]: loss 0.035605
[epoch11, step1315]: loss 0.035745
[epoch11, step1316]: loss 0.039465
[epoch11, step1317]: loss 0.034343
[epoch11, step1318]: loss 0.034602
[epoch11, step1319]: loss 0.037308
[epoch11, step1320]: loss 0.035923
[epoch11, step1321]: loss 0.036417
[epoch11, step1322]: loss 0.034801
[epoch11, step1323]: loss 0.036682
[epoch11, step1324]: loss 0.036370
[epoch11, step1325]: loss 0.037523
[epoch11, step1326]: loss 0.034343
[epoch11, step1327]: loss 0.033772
[epoch11, step1328]: loss 0.038683
[epoch11, step1329]: loss 0.036053
[epoch11, step1330]: loss 0.036337
[epoch11, step1331]: loss 0.034360
[epoch11, step1332]: loss 0.036066
[epoch11, step1333]: loss 0.035853
[epoch11, step1334]: loss 0.037568
[epoch11, step1335]: loss 0.035063
[epoch11, step1336]: loss 0.034785
[epoch11, step1337]: loss 0.037608
[epoch11, step1338]: loss 0.036288
[epoch11, step1339]: loss 0.035719
[epoch11, step1340]: loss 0.034421
[epoch11, step1341]: loss 0.036565
[epoch11, step1342]: loss 0.035840
[epoch11, step1343]: loss 0.037185
[epoch11, step1344]: loss 0.034199
[epoch11, step1345]: loss 0.033982
[epoch11, step1346]: loss 0.037136
[epoch11, step1347]: loss 0.036632
[epoch11, step1348]: loss 0.034958
[epoch11, step1349]: loss 0.034865
[epoch11, step1350]: loss 0.036242
[epoch11, step1351]: loss 0.035892
[epoch11, step1352]: loss 0.037322
[epoch11, step1353]: loss 0.034358
[epoch11, step1354]: loss 0.034536
[epoch11, step1355]: loss 0.037882
[epoch11, step1356]: loss 0.035757
[epoch11, step1357]: loss 0.035656
[epoch11, step1358]: loss 0.033932
[epoch11, step1359]: loss 0.035523
[epoch11, step1360]: loss 0.036763
[epoch11, step1361]: loss 0.037388
[epoch11, step1362]: loss 0.034786
[epoch11, step1363]: loss 0.034596
[epoch11, step1364]: loss 0.037650
[epoch11, step1365]: loss 0.036211
[epoch11, step1366]: loss 0.035760
[epoch11, step1367]: loss 0.034206
[epoch11, step1368]: loss 0.036813
[epoch11, step1369]: loss 0.036291
[epoch11, step1370]: loss 0.037518
[epoch11, step1371]: loss 0.034482
[epoch11, step1372]: loss 0.034134
[epoch11, step1373]: loss 0.037654
[epoch11, step1374]: loss 0.036796
[epoch11, step1375]: loss 0.036733
[epoch11, step1376]: loss 0.034233
[epoch11, step1377]: loss 0.036152
[epoch11, step1378]: loss 0.036282
[epoch11, step1379]: loss 0.037118
[epoch11, step1380]: loss 0.034854
[epoch11, step1381]: loss 0.034031
[epoch11, step1382]: loss 0.037337
[epoch11, step1383]: loss 0.035699
[epoch11, step1384]: loss 0.035669
[epoch11, step1385]: loss 0.033073
[epoch11, step1386]: loss 0.036797
[epoch11, step1387]: loss 0.037305
[epoch11, step1388]: loss 0.036545
[epoch11, step1389]: loss 0.033698
[epoch11, step1390]: loss 0.034829
[epoch11, step1391]: loss 0.037209
[epoch11, step1392]: loss 0.035651
[epoch11, step1393]: loss 0.035766
[epoch11, step1394]: loss 0.035082
[epoch11, step1395]: loss 0.035882
[epoch11, step1396]: loss 0.035871
[epoch11, step1397]: loss 0.036986
[epoch11, step1398]: loss 0.034168
[epoch11, step1399]: loss 0.035263
[epoch11, step1400]: loss 0.037653
[epoch11, step1401]: loss 0.035719
[epoch11, step1402]: loss 0.035502
[epoch11, step1403]: loss 0.033594
[epoch11, step1404]: loss 0.035843
[epoch11, step1405]: loss 0.036049
[epoch11, step1406]: loss 0.037302
[epoch11, step1407]: loss 0.037079
[epoch11, step1408]: loss 0.033718
[epoch11, step1409]: loss 0.037024
[epoch11, step1410]: loss 0.035452
[epoch11, step1411]: loss 0.034846
[epoch11, step1412]: loss 0.034026
[epoch11, step1413]: loss 0.035912
[epoch11, step1414]: loss 0.035491
[epoch11, step1415]: loss 0.036968
[epoch11, step1416]: loss 0.034320
[epoch11, step1417]: loss 0.034864
[epoch11, step1418]: loss 0.037690
[epoch11, step1419]: loss 0.036631
[epoch11, step1420]: loss 0.035679
[epoch11, step1421]: loss 0.034257
[epoch11, step1422]: loss 0.036276
[epoch11, step1423]: loss 0.035774
[epoch11, step1424]: loss 0.037255
[epoch11, step1425]: loss 0.033931
[epoch11, step1426]: loss 0.034567
[epoch11, step1427]: loss 0.038671
[epoch11, step1428]: loss 0.037129
[epoch11, step1429]: loss 0.035588
[epoch11, step1430]: loss 0.034491
[epoch11, step1431]: loss 0.036191
[epoch11, step1432]: loss 0.035661
[epoch11, step1433]: loss 0.037045
[epoch11, step1434]: loss 0.034092
[epoch11, step1435]: loss 0.034500
[epoch11, step1436]: loss 0.037841
[epoch11, step1437]: loss 0.036064
[epoch11, step1438]: loss 0.036390
[epoch11, step1439]: loss 0.033982
[epoch11, step1440]: loss 0.035894
[epoch11, step1441]: loss 0.036765
[epoch11, step1442]: loss 0.036758
[epoch11, step1443]: loss 0.034146
[epoch11, step1444]: loss 0.033607
[epoch11, step1445]: loss 0.037822
[epoch11, step1446]: loss 0.035715
[epoch11, step1447]: loss 0.036493
[epoch11, step1448]: loss 0.034216
[epoch11, step1449]: loss 0.035647
[epoch11, step1450]: loss 0.036069
[epoch11, step1451]: loss 0.037244
[epoch11, step1452]: loss 0.034190
[epoch11, step1453]: loss 0.035187
[epoch11, step1454]: loss 0.037739
[epoch11, step1455]: loss 0.036648
[epoch11, step1456]: loss 0.035591
[epoch11, step1457]: loss 0.034387
[epoch11, step1458]: loss 0.036010
[epoch11, step1459]: loss 0.036249
[epoch11, step1460]: loss 0.037322
[epoch11, step1461]: loss 0.034580
[epoch11, step1462]: loss 0.034954
[epoch11, step1463]: loss 0.037684
[epoch11, step1464]: loss 0.036108
[epoch11, step1465]: loss 0.035527
[epoch11, step1466]: loss 0.034152
[epoch11, step1467]: loss 0.035883
[epoch11, step1468]: loss 0.035832
[epoch11, step1469]: loss 0.037116
[epoch11, step1470]: loss 0.035238
[epoch11, step1471]: loss 0.034571
[epoch11, step1472]: loss 0.037251
[epoch11, step1473]: loss 0.035673
[epoch11, step1474]: loss 0.036154
[epoch11, step1475]: loss 0.033979
[epoch11, step1476]: loss 0.036884
[epoch11, step1477]: loss 0.035968
[epoch11, step1478]: loss 0.037339
[epoch11, step1479]: loss 0.034195
[epoch11, step1480]: loss 0.034223
[epoch11, step1481]: loss 0.036839
[epoch11, step1482]: loss 0.035938
[epoch11, step1483]: loss 0.035625
[epoch11, step1484]: loss 0.035147
[epoch11, step1485]: loss 0.035992
[epoch11, step1486]: loss 0.035091
[epoch11, step1487]: loss 0.036894
[epoch11, step1488]: loss 0.033929
[epoch11, step1489]: loss 0.034234
[epoch11, step1490]: loss 0.037388
[epoch11, step1491]: loss 0.035769
[epoch11, step1492]: loss 0.035483
[epoch11, step1493]: loss 0.034228
[epoch11, step1494]: loss 0.035925
[epoch11, step1495]: loss 0.036197
[epoch11, step1496]: loss 0.037573
[epoch11, step1497]: loss 0.034838
[epoch11, step1498]: loss 0.034418
[epoch11, step1499]: loss 0.036794
[epoch11, step1500]: loss 0.035844
[epoch11, step1501]: loss 0.035017
[epoch11, step1502]: loss 0.033659
[epoch11, step1503]: loss 0.036069
[epoch11, step1504]: loss 0.035367
[epoch11, step1505]: loss 0.037540
[epoch11, step1506]: loss 0.033503
[epoch11, step1507]: loss 0.034454
[epoch11, step1508]: loss 0.037988
[epoch11, step1509]: loss 0.035446
[epoch11, step1510]: loss 0.035159
[epoch11, step1511]: loss 0.035343
[epoch11, step1512]: loss 0.035981
[epoch11, step1513]: loss 0.035361
[epoch11, step1514]: loss 0.036978
[epoch11, step1515]: loss 0.034385
[epoch11, step1516]: loss 0.034178

[epoch11]: avg loss 0.032889

[epoch12, step1]: loss 0.032073
[epoch12, step2]: loss 0.037119
[epoch12, step3]: loss 0.036744
[epoch12, step4]: loss 0.034800
[epoch12, step5]: loss 0.035031
[epoch12, step6]: loss 0.037437
[epoch12, step7]: loss 0.035657
[epoch12, step8]: loss 0.037488
[epoch12, step9]: loss 0.033838
[epoch12, step10]: loss 0.035308
[epoch12, step11]: loss 0.037455
[epoch12, step12]: loss 0.037323
[epoch12, step13]: loss 0.034318
[epoch12, step14]: loss 0.034529
[epoch12, step15]: loss 0.037308
[epoch12, step16]: loss 0.034976
[epoch12, step17]: loss 0.037529
[epoch12, step18]: loss 0.035253
[epoch12, step19]: loss 0.034698
[epoch12, step20]: loss 0.037864
[epoch12, step21]: loss 0.037201
[epoch12, step22]: loss 0.034326
[epoch12, step23]: loss 0.034916
[epoch12, step24]: loss 0.037661
[epoch12, step25]: loss 0.034465
[epoch12, step26]: loss 0.037046
[epoch12, step27]: loss 0.033709
[epoch12, step28]: loss 0.035627
[epoch12, step29]: loss 0.037597
[epoch12, step30]: loss 0.038484
[epoch12, step31]: loss 0.033491
[epoch12, step32]: loss 0.035718
[epoch12, step33]: loss 0.037984
[epoch12, step34]: loss 0.035417
[epoch12, step35]: loss 0.037632
[epoch12, step36]: loss 0.034581
[epoch12, step37]: loss 0.035122
[epoch12, step38]: loss 0.037953
[epoch12, step39]: loss 0.037790
[epoch12, step40]: loss 0.034740
[epoch12, step41]: loss 0.034591
[epoch12, step42]: loss 0.037728
[epoch12, step43]: loss 0.034591
[epoch12, step44]: loss 0.037974
[epoch12, step45]: loss 0.034366
[epoch12, step46]: loss 0.035195
[epoch12, step47]: loss 0.036840
[epoch12, step48]: loss 0.037022
[epoch12, step49]: loss 0.033151
[epoch12, step50]: loss 0.034974
[epoch12, step51]: loss 0.037211
[epoch12, step52]: loss 0.034903
[epoch12, step53]: loss 0.038386
[epoch12, step54]: loss 0.033698
[epoch12, step55]: loss 0.035299
[epoch12, step56]: loss 0.038443
[epoch12, step57]: loss 0.037568
[epoch12, step58]: loss 0.034601
[epoch12, step59]: loss 0.034865
[epoch12, step60]: loss 0.038063
[epoch12, step61]: loss 0.034771
[epoch12, step62]: loss 0.037092
[epoch12, step63]: loss 0.034094
[epoch12, step64]: loss 0.034405
[epoch12, step65]: loss 0.037506
[epoch12, step66]: loss 0.037281
[epoch12, step67]: loss 0.034573
[epoch12, step68]: loss 0.034825
[epoch12, step69]: loss 0.037886
[epoch12, step70]: loss 0.034632
[epoch12, step71]: loss 0.036877
[epoch12, step72]: loss 0.034116
[epoch12, step73]: loss 0.035297
[epoch12, step74]: loss 0.037375
[epoch12, step75]: loss 0.037693
[epoch12, step76]: loss 0.034602
[epoch12, step77]: loss 0.035027
[epoch12, step78]: loss 0.037831
[epoch12, step79]: loss 0.034691
[epoch12, step80]: loss 0.037913
[epoch12, step81]: loss 0.034157
[epoch12, step82]: loss 0.034682
[epoch12, step83]: loss 0.036933
[epoch12, step84]: loss 0.037483
[epoch12, step85]: loss 0.035987
[epoch12, step86]: loss 0.035558
[epoch12, step87]: loss 0.038562
[epoch12, step88]: loss 0.034156
[epoch12, step89]: loss 0.037355
[epoch12, step90]: loss 0.035090
[epoch12, step91]: loss 0.034978
[epoch12, step92]: loss 0.038008
[epoch12, step93]: loss 0.037869
[epoch12, step94]: loss 0.034442
[epoch12, step95]: loss 0.035383
[epoch12, step96]: loss 0.037566
[epoch12, step97]: loss 0.035799
[epoch12, step98]: loss 0.037669
[epoch12, step99]: loss 0.034879
[epoch12, step100]: loss 0.034441
[epoch12, step101]: loss 0.038194
[epoch12, step102]: loss 0.037727
[epoch12, step103]: loss 0.034332
[epoch12, step104]: loss 0.034513
[epoch12, step105]: loss 0.037781
[epoch12, step106]: loss 0.034486
[epoch12, step107]: loss 0.037445
[epoch12, step108]: loss 0.034410
[epoch12, step109]: loss 0.034034
[epoch12, step110]: loss 0.038062
[epoch12, step111]: loss 0.037476
[epoch12, step112]: loss 0.034074
[epoch12, step113]: loss 0.035602
[epoch12, step114]: loss 0.037395
[epoch12, step115]: loss 0.034366
[epoch12, step116]: loss 0.038752
[epoch12, step117]: loss 0.034054
[epoch12, step118]: loss 0.035785
[epoch12, step119]: loss 0.037232
[epoch12, step120]: loss 0.037971
[epoch12, step121]: loss 0.033698
[epoch12, step122]: loss 0.033841
[epoch12, step123]: loss 0.037719
[epoch12, step124]: loss 0.035045
[epoch12, step125]: loss 0.037622
[epoch12, step126]: loss 0.034366
[epoch12, step127]: loss 0.034806
[epoch12, step128]: loss 0.037731
[epoch12, step129]: loss 0.038168
[epoch12, step130]: loss 0.034635
[epoch12, step131]: loss 0.034033
[epoch12, step132]: loss 0.037063
[epoch12, step133]: loss 0.034326
[epoch12, step134]: loss 0.036663
[epoch12, step135]: loss 0.035915
[epoch12, step136]: loss 0.037486
[epoch12, step137]: loss 0.037645
[epoch12, step138]: loss 0.037244
[epoch12, step139]: loss 0.034180
[epoch12, step140]: loss 0.034771
[epoch12, step141]: loss 0.037851
[epoch12, step142]: loss 0.034795
[epoch12, step143]: loss 0.037389
[epoch12, step144]: loss 0.035277
[epoch12, step145]: loss 0.034964
[epoch12, step146]: loss 0.037587
[epoch12, step147]: loss 0.038612
[epoch12, step148]: loss 0.033921
[epoch12, step149]: loss 0.034014
[epoch12, step150]: loss 0.037053
[epoch12, step151]: loss 0.034670
[epoch12, step152]: loss 0.037247
[epoch12, step153]: loss 0.034379
[epoch12, step154]: loss 0.034462
[epoch12, step155]: loss 0.037846
[epoch12, step156]: loss 0.036692
[epoch12, step157]: loss 0.033642
[epoch12, step158]: loss 0.035191
[epoch12, step159]: loss 0.037619
[epoch12, step160]: loss 0.034299
[epoch12, step161]: loss 0.037264
[epoch12, step162]: loss 0.034378
[epoch12, step163]: loss 0.034724
[epoch12, step164]: loss 0.037834
[epoch12, step165]: loss 0.037577
[epoch12, step166]: loss 0.034298
[epoch12, step167]: loss 0.034036
[epoch12, step168]: loss 0.039330
[epoch12, step169]: loss 0.034192
[epoch12, step170]: loss 0.037606
[epoch12, step171]: loss 0.034273
[epoch12, step172]: loss 0.034880
[epoch12, step173]: loss 0.037873
[epoch12, step174]: loss 0.037410
[epoch12, step175]: loss 0.034407
[epoch12, step176]: loss 0.034985
[epoch12, step177]: loss 0.037472
[epoch12, step178]: loss 0.034920
[epoch12, step179]: loss 0.036563
[epoch12, step180]: loss 0.034006
[epoch12, step181]: loss 0.034879
[epoch12, step182]: loss 0.037612
[epoch12, step183]: loss 0.038086
[epoch12, step184]: loss 0.035341
[epoch12, step185]: loss 0.034925
[epoch12, step186]: loss 0.037659
[epoch12, step187]: loss 0.034724
[epoch12, step188]: loss 0.037307
[epoch12, step189]: loss 0.034372
[epoch12, step190]: loss 0.034849
[epoch12, step191]: loss 0.037530
[epoch12, step192]: loss 0.038053
[epoch12, step193]: loss 0.032980
[epoch12, step194]: loss 0.033473
[epoch12, step195]: loss 0.038182
[epoch12, step196]: loss 0.035242
[epoch12, step197]: loss 0.037360
[epoch12, step198]: loss 0.033360
[epoch12, step199]: loss 0.034461
[epoch12, step200]: loss 0.037864
[epoch12, step201]: loss 0.037557
[epoch12, step202]: loss 0.034100
[epoch12, step203]: loss 0.034901
[epoch12, step204]: loss 0.037880
[epoch12, step205]: loss 0.034846
[epoch12, step206]: loss 0.037340
[epoch12, step207]: loss 0.034221
[epoch12, step208]: loss 0.035546
[epoch12, step209]: loss 0.037669
[epoch12, step210]: loss 0.038490
[epoch12, step211]: loss 0.034974
[epoch12, step212]: loss 0.035026
[epoch12, step213]: loss 0.037142
[epoch12, step214]: loss 0.033990
[epoch12, step215]: loss 0.037268
[epoch12, step216]: loss 0.034428
[epoch12, step217]: loss 0.034660
[epoch12, step218]: loss 0.037683
[epoch12, step219]: loss 0.037131
[epoch12, step220]: loss 0.034521
[epoch12, step221]: loss 0.034785
[epoch12, step222]: loss 0.037700
[epoch12, step223]: loss 0.034569
[epoch12, step224]: loss 0.037101
[epoch12, step225]: loss 0.033863
[epoch12, step226]: loss 0.034836
[epoch12, step227]: loss 0.036728
[epoch12, step228]: loss 0.038171
[epoch12, step229]: loss 0.033408
[epoch12, step230]: loss 0.034628
[epoch12, step231]: loss 0.037587
[epoch12, step232]: loss 0.034797
[epoch12, step233]: loss 0.037049
[epoch12, step234]: loss 0.034466
[epoch12, step235]: loss 0.034693
[epoch12, step236]: loss 0.037451
[epoch12, step237]: loss 0.036937
[epoch12, step238]: loss 0.033860
[epoch12, step239]: loss 0.033846
[epoch12, step240]: loss 0.036608
[epoch12, step241]: loss 0.036055
[epoch12, step242]: loss 0.037648
[epoch12, step243]: loss 0.035827
[epoch12, step244]: loss 0.033997
[epoch12, step245]: loss 0.037140
[epoch12, step246]: loss 0.037443
[epoch12, step247]: loss 0.034628
[epoch12, step248]: loss 0.034669
[epoch12, step249]: loss 0.037623
[epoch12, step250]: loss 0.035211
[epoch12, step251]: loss 0.037568
[epoch12, step252]: loss 0.034726
[epoch12, step253]: loss 0.034248
[epoch12, step254]: loss 0.037137
[epoch12, step255]: loss 0.037368
[epoch12, step256]: loss 0.034012
[epoch12, step257]: loss 0.034163
[epoch12, step258]: loss 0.038859
[epoch12, step259]: loss 0.035209
[epoch12, step260]: loss 0.036833
[epoch12, step261]: loss 0.035439
[epoch12, step262]: loss 0.035169
[epoch12, step263]: loss 0.037496
[epoch12, step264]: loss 0.037042
[epoch12, step265]: loss 0.034056
[epoch12, step266]: loss 0.034164
[epoch12, step267]: loss 0.037154
[epoch12, step268]: loss 0.034387
[epoch12, step269]: loss 0.037407
[epoch12, step270]: loss 0.034490
[epoch12, step271]: loss 0.034939
[epoch12, step272]: loss 0.037247
[epoch12, step273]: loss 0.037044
[epoch12, step274]: loss 0.034310
[epoch12, step275]: loss 0.034144
[epoch12, step276]: loss 0.037490
[epoch12, step277]: loss 0.034878
[epoch12, step278]: loss 0.037315
[epoch12, step279]: loss 0.034115
[epoch12, step280]: loss 0.035274
[epoch12, step281]: loss 0.037390
[epoch12, step282]: loss 0.038326
[epoch12, step283]: loss 0.033644
[epoch12, step284]: loss 0.033922
[epoch12, step285]: loss 0.038960
[epoch12, step286]: loss 0.034316
[epoch12, step287]: loss 0.038021
[epoch12, step288]: loss 0.033934
[epoch12, step289]: loss 0.035317
[epoch12, step290]: loss 0.037338
[epoch12, step291]: loss 0.037176
[epoch12, step292]: loss 0.033897
[epoch12, step293]: loss 0.033992
[epoch12, step294]: loss 0.036772
[epoch12, step295]: loss 0.033991
[epoch12, step296]: loss 0.038697
[epoch12, step297]: loss 0.034251
[epoch12, step298]: loss 0.035214
[epoch12, step299]: loss 0.036745
[epoch12, step300]: loss 0.037510
[epoch12, step301]: loss 0.034106
[epoch12, step302]: loss 0.034766
[epoch12, step303]: loss 0.037824
[epoch12, step304]: loss 0.034687
[epoch12, step305]: loss 0.037357
[epoch12, step306]: loss 0.034608
[epoch12, step307]: loss 0.035057
[epoch12, step308]: loss 0.037716
[epoch12, step309]: loss 0.037532
[epoch12, step310]: loss 0.033962
[epoch12, step311]: loss 0.034824
[epoch12, step312]: loss 0.037286
[epoch12, step313]: loss 0.034631
[epoch12, step314]: loss 0.037010
[epoch12, step315]: loss 0.035804
[epoch12, step316]: loss 0.034166
[epoch12, step317]: loss 0.038015
[epoch12, step318]: loss 0.037487
[epoch12, step319]: loss 0.033814
[epoch12, step320]: loss 0.034129
[epoch12, step321]: loss 0.036884
[epoch12, step322]: loss 0.034426
[epoch12, step323]: loss 0.036153
[epoch12, step324]: loss 0.036580
[epoch12, step325]: loss 0.035450
[epoch12, step326]: loss 0.037047
[epoch12, step327]: loss 0.036427
[epoch12, step328]: loss 0.034478
[epoch12, step329]: loss 0.033751
[epoch12, step330]: loss 0.036894
[epoch12, step331]: loss 0.034629
[epoch12, step332]: loss 0.036630
[epoch12, step333]: loss 0.034369
[epoch12, step334]: loss 0.034831
[epoch12, step335]: loss 0.037206
[epoch12, step336]: loss 0.038050
[epoch12, step337]: loss 0.034875
[epoch12, step338]: loss 0.034106
[epoch12, step339]: loss 0.038137
[epoch12, step340]: loss 0.034926
[epoch12, step341]: loss 0.036832
[epoch12, step342]: loss 0.033989
[epoch12, step343]: loss 0.035014
[epoch12, step344]: loss 0.036785
[epoch12, step345]: loss 0.036455
[epoch12, step346]: loss 0.033922
[epoch12, step347]: loss 0.034868
[epoch12, step348]: loss 0.037873
[epoch12, step349]: loss 0.035769
[epoch12, step350]: loss 0.037410
[epoch12, step351]: loss 0.033583
[epoch12, step352]: loss 0.034407
[epoch12, step353]: loss 0.037097
[epoch12, step354]: loss 0.036732
[epoch12, step355]: loss 0.033532
[epoch12, step356]: loss 0.035299
[epoch12, step357]: loss 0.037306
[epoch12, step358]: loss 0.033310
[epoch12, step359]: loss 0.038536
[epoch12, step360]: loss 0.033035
[epoch12, step361]: loss 0.034414
[epoch12, step362]: loss 0.038615
[epoch12, step363]: loss 0.036966
[epoch12, step364]: loss 0.034375
[epoch12, step365]: loss 0.034420
[epoch12, step366]: loss 0.038123
[epoch12, step367]: loss 0.034715
[epoch12, step368]: loss 0.037188
[epoch12, step369]: loss 0.034241
[epoch12, step370]: loss 0.035331
[epoch12, step371]: loss 0.037604
[epoch12, step372]: loss 0.037417
[epoch12, step373]: loss 0.034408
[epoch12, step374]: loss 0.034440
[epoch12, step375]: loss 0.037645
[epoch12, step376]: loss 0.034640
[epoch12, step377]: loss 0.037085
[epoch12, step378]: loss 0.034784
[epoch12, step379]: loss 0.035085
[epoch12, step380]: loss 0.038217
[epoch12, step381]: loss 0.037232
[epoch12, step382]: loss 0.034391
[epoch12, step383]: loss 0.033796
[epoch12, step384]: loss 0.037123
[epoch12, step385]: loss 0.034232
[epoch12, step386]: loss 0.036934
[epoch12, step387]: loss 0.033985
[epoch12, step388]: loss 0.035834
[epoch12, step389]: loss 0.037538
[epoch12, step390]: loss 0.038641
[epoch12, step391]: loss 0.033614
[epoch12, step392]: loss 0.035055
[epoch12, step393]: loss 0.037515
[epoch12, step394]: loss 0.034459
[epoch12, step395]: loss 0.037068
[epoch12, step396]: loss 0.034163
[epoch12, step397]: loss 0.034460
[epoch12, step398]: loss 0.037205
[epoch12, step399]: loss 0.036954
[epoch12, step400]: loss 0.033481
[epoch12, step401]: loss 0.033617
[epoch12, step402]: loss 0.037069
[epoch12, step403]: loss 0.034508
[epoch12, step404]: loss 0.038270
[epoch12, step405]: loss 0.034830
[epoch12, step406]: loss 0.034802
[epoch12, step407]: loss 0.037195
[epoch12, step408]: loss 0.037135
[epoch12, step409]: loss 0.035355
[epoch12, step410]: loss 0.034802
[epoch12, step411]: loss 0.037788
[epoch12, step412]: loss 0.034879
[epoch12, step413]: loss 0.037199
[epoch12, step414]: loss 0.034605
[epoch12, step415]: loss 0.034294
[epoch12, step416]: loss 0.036626
[epoch12, step417]: loss 0.037395
[epoch12, step418]: loss 0.034467
[epoch12, step419]: loss 0.033198
[epoch12, step420]: loss 0.037953
[epoch12, step421]: loss 0.034129
[epoch12, step422]: loss 0.036969
[epoch12, step423]: loss 0.034241
[epoch12, step424]: loss 0.034811
[epoch12, step425]: loss 0.037235
[epoch12, step426]: loss 0.037313
[epoch12, step427]: loss 0.034442
[epoch12, step428]: loss 0.034568
[epoch12, step429]: loss 0.037911
[epoch12, step430]: loss 0.034951
[epoch12, step431]: loss 0.037154
[epoch12, step432]: loss 0.033764
[epoch12, step433]: loss 0.036502
[epoch12, step434]: loss 0.037173
[epoch12, step435]: loss 0.037639
[epoch12, step436]: loss 0.033685
[epoch12, step437]: loss 0.034451
[epoch12, step438]: loss 0.037745
[epoch12, step439]: loss 0.034478
[epoch12, step440]: loss 0.037146
[epoch12, step441]: loss 0.034150
[epoch12, step442]: loss 0.034212
[epoch12, step443]: loss 0.037453
[epoch12, step444]: loss 0.036788
[epoch12, step445]: loss 0.033986
[epoch12, step446]: loss 0.034324
[epoch12, step447]: loss 0.037589
[epoch12, step448]: loss 0.035031
[epoch12, step449]: loss 0.037147
[epoch12, step450]: loss 0.034537
[epoch12, step451]: loss 0.034708
[epoch12, step452]: loss 0.037116
[epoch12, step453]: loss 0.037408
[epoch12, step454]: loss 0.034052
[epoch12, step455]: loss 0.035187
[epoch12, step456]: loss 0.037089
[epoch12, step457]: loss 0.035474
[epoch12, step458]: loss 0.036629
[epoch12, step459]: loss 0.034696
[epoch12, step460]: loss 0.034860
[epoch12, step461]: loss 0.037763
[epoch12, step462]: loss 0.037273
[epoch12, step463]: loss 0.034570
[epoch12, step464]: loss 0.034510
[epoch12, step465]: loss 0.038801
[epoch12, step466]: loss 0.034390
[epoch12, step467]: loss 0.036736
[epoch12, step468]: loss 0.034326
[epoch12, step469]: loss 0.034477
[epoch12, step470]: loss 0.037341
[epoch12, step471]: loss 0.037229
[epoch12, step472]: loss 0.034613
[epoch12, step473]: loss 0.033581
[epoch12, step474]: loss 0.036883
[epoch12, step475]: loss 0.034740
[epoch12, step476]: loss 0.037327
[epoch12, step477]: loss 0.034145
[epoch12, step478]: loss 0.034038
[epoch12, step479]: loss 0.037437
[epoch12, step480]: loss 0.036580
[epoch12, step481]: loss 0.033529
[epoch12, step482]: loss 0.033233
[epoch12, step483]: loss 0.038437
[epoch12, step484]: loss 0.035176
[epoch12, step485]: loss 0.037507
[epoch12, step486]: loss 0.034666
[epoch12, step487]: loss 0.034670
[epoch12, step488]: loss 0.037877
[epoch12, step489]: loss 0.037104
[epoch12, step490]: loss 0.034457
[epoch12, step491]: loss 0.034508
[epoch12, step492]: loss 0.037204
[epoch12, step493]: loss 0.034268
[epoch12, step494]: loss 0.036472
[epoch12, step495]: loss 0.035939
[epoch12, step496]: loss 0.035123
[epoch12, step497]: loss 0.037560
[epoch12, step498]: loss 0.036910
[epoch12, step499]: loss 0.034394
[epoch12, step500]: loss 0.033841
[epoch12, step501]: loss 0.037016
[epoch12, step502]: loss 0.033840
[epoch12, step503]: loss 0.037799
[epoch12, step504]: loss 0.034526
[epoch12, step505]: loss 0.034021
[epoch12, step506]: loss 0.037774
[epoch12, step507]: loss 0.037698
[epoch12, step508]: loss 0.034552
[epoch12, step509]: loss 0.034073
[epoch12, step510]: loss 0.037408
[epoch12, step511]: loss 0.034784
[epoch12, step512]: loss 0.036941
[epoch12, step513]: loss 0.034847
[epoch12, step514]: loss 0.034579
[epoch12, step515]: loss 0.037217
[epoch12, step516]: loss 0.037191
[epoch12, step517]: loss 0.033953
[epoch12, step518]: loss 0.034086
[epoch12, step519]: loss 0.037750
[epoch12, step520]: loss 0.034176
[epoch12, step521]: loss 0.037033
[epoch12, step522]: loss 0.034075
[epoch12, step523]: loss 0.034341
[epoch12, step524]: loss 0.036800
[epoch12, step525]: loss 0.037627
[epoch12, step526]: loss 0.034179
[epoch12, step527]: loss 0.033602
[epoch12, step528]: loss 0.036968
[epoch12, step529]: loss 0.033744
[epoch12, step530]: loss 0.037255
[epoch12, step531]: loss 0.033921
[epoch12, step532]: loss 0.034772
[epoch12, step533]: loss 0.038774
[epoch12, step534]: loss 0.036741
[epoch12, step535]: loss 0.035035
[epoch12, step536]: loss 0.034496
[epoch12, step537]: loss 0.037417
[epoch12, step538]: loss 0.034858
[epoch12, step539]: loss 0.036879
[epoch12, step540]: loss 0.035094
[epoch12, step541]: loss 0.034637
[epoch12, step542]: loss 0.037017
[epoch12, step543]: loss 0.036765
[epoch12, step544]: loss 0.033867
[epoch12, step545]: loss 0.033616
[epoch12, step546]: loss 0.038574
[epoch12, step547]: loss 0.034254
[epoch12, step548]: loss 0.037078
[epoch12, step549]: loss 0.034605
[epoch12, step550]: loss 0.034098
[epoch12, step551]: loss 0.037942
[epoch12, step552]: loss 0.037087
[epoch12, step553]: loss 0.034332
[epoch12, step554]: loss 0.034339
[epoch12, step555]: loss 0.037349
[epoch12, step556]: loss 0.034329
[epoch12, step557]: loss 0.036456
[epoch12, step558]: loss 0.034440
[epoch12, step559]: loss 0.034354
[epoch12, step560]: loss 0.037764
[epoch12, step561]: loss 0.036884
[epoch12, step562]: loss 0.034280
[epoch12, step563]: loss 0.030443
[epoch12, step564]: loss 0.031430
[epoch12, step565]: loss 0.027590
[epoch12, step566]: loss 0.035755
[epoch12, step567]: loss 0.027166
[epoch12, step568]: loss 0.025982
[epoch12, step569]: loss 0.024005
[epoch12, step570]: loss 0.031763
[epoch12, step571]: loss 0.025884
[epoch12, step572]: loss 0.026282
[epoch12, step573]: loss 0.029409
[epoch12, step574]: loss 0.028630
[epoch12, step575]: loss 0.021888
[epoch12, step576]: loss 0.022713
[epoch12, step577]: loss 0.026416
[epoch12, step578]: loss 0.019714
[epoch12, step579]: loss 0.028546
[epoch12, step580]: loss 0.020490
[epoch12, step581]: loss 0.025475
[epoch12, step582]: loss 0.026205
[epoch12, step583]: loss 0.023366
[epoch12, step584]: loss 0.024953
[epoch12, step585]: loss 0.026804
[epoch12, step586]: loss 0.022062
[epoch12, step587]: loss 0.028416
[epoch12, step588]: loss 0.023267
[epoch12, step589]: loss 0.024033
[epoch12, step590]: loss 0.027991
[epoch12, step591]: loss 0.020472
[epoch12, step592]: loss 0.026114
[epoch12, step593]: loss 0.021582
[epoch12, step594]: loss 0.025469
[epoch12, step595]: loss 0.026671
[epoch12, step596]: loss 0.022919
[epoch12, step597]: loss 0.024583
[epoch12, step598]: loss 0.027138
[epoch12, step599]: loss 0.024836
[epoch12, step600]: loss 0.026608
[epoch12, step601]: loss 0.019312
[epoch12, step602]: loss 0.022964
[epoch12, step603]: loss 0.025395
[epoch12, step604]: loss 0.026932
[epoch12, step605]: loss 0.025152
[epoch12, step606]: loss 0.024560
[epoch12, step607]: loss 0.026759
[epoch12, step608]: loss 0.025745
[epoch12, step609]: loss 0.026994
[epoch12, step610]: loss 0.027010
[epoch12, step611]: loss 0.028151
[epoch12, step612]: loss 0.026479
[epoch12, step613]: loss 0.019557
[epoch12, step614]: loss 0.024829
[epoch12, step615]: loss 0.028900
[epoch12, step616]: loss 0.024826
[epoch12, step617]: loss 0.024174
[epoch12, step618]: loss 0.026980
[epoch12, step619]: loss 0.028910
[epoch12, step620]: loss 0.024383
[epoch12, step621]: loss 0.026650
[epoch12, step622]: loss 0.020359
[epoch12, step623]: loss 0.024841
[epoch12, step624]: loss 0.026286
[epoch12, step625]: loss 0.025644
[epoch12, step626]: loss 0.029361
[epoch12, step627]: loss 0.023644
[epoch12, step628]: loss 0.024699
[epoch12, step629]: loss 0.020619
[epoch12, step630]: loss 0.022659
[epoch12, step631]: loss 0.032816
[epoch12, step632]: loss 0.022495
[epoch12, step633]: loss 0.023888
[epoch12, step634]: loss 0.027695
[epoch12, step635]: loss 0.025820
[epoch12, step636]: loss 0.021223
[epoch12, step637]: loss 0.027457
[epoch12, step638]: loss 0.026837
[epoch12, step639]: loss 0.022129
[epoch12, step640]: loss 0.029585
[epoch12, step641]: loss 0.030635
[epoch12, step642]: loss 0.025276
[epoch12, step643]: loss 0.025166
[epoch12, step644]: loss 0.026614
[epoch12, step645]: loss 0.024035
[epoch12, step646]: loss 0.025964
[epoch12, step647]: loss 0.022902
[epoch12, step648]: loss 0.023623
[epoch12, step649]: loss 0.029309
[epoch12, step650]: loss 0.021739
[epoch12, step651]: loss 0.025839
[epoch12, step652]: loss 0.026380
[epoch12, step653]: loss 0.028576
[epoch12, step654]: loss 0.022514
[epoch12, step655]: loss 0.024266
[epoch12, step656]: loss 0.021412
[epoch12, step657]: loss 0.027596
[epoch12, step658]: loss 0.024959
[epoch12, step659]: loss 0.026276
[epoch12, step660]: loss 0.023364
[epoch12, step661]: loss 0.025777
[epoch12, step662]: loss 0.024068
[epoch12, step663]: loss 0.021057
[epoch12, step664]: loss 0.025273
[epoch12, step665]: loss 0.027067
[epoch12, step666]: loss 0.025780
[epoch12, step667]: loss 0.026387
[epoch12, step668]: loss 0.022724
[epoch12, step669]: loss 0.026091
[epoch12, step670]: loss 0.025992
[epoch12, step671]: loss 0.020913
[epoch12, step672]: loss 0.023762
[epoch12, step673]: loss 0.022435
[epoch12, step674]: loss 0.021347
[epoch12, step675]: loss 0.019768
[epoch12, step676]: loss 0.024539
[epoch12, step677]: loss 0.024568
[epoch12, step678]: loss 0.022552
[epoch12, step679]: loss 0.023493
[epoch12, step680]: loss 0.030913
[epoch12, step681]: loss 0.020886
[epoch12, step682]: loss 0.025678
[epoch12, step683]: loss 0.026443
[epoch12, step684]: loss 0.025270
[epoch12, step685]: loss 0.024413
[epoch12, step686]: loss 0.027339
[epoch12, step687]: loss 0.026573
[epoch12, step688]: loss 0.022570
[epoch12, step689]: loss 0.024351
[epoch12, step690]: loss 0.024847
[epoch12, step691]: loss 0.024109
[epoch12, step692]: loss 0.022074
[epoch12, step693]: loss 0.026516
[epoch12, step694]: loss 0.021732
[epoch12, step695]: loss 0.026080
[epoch12, step696]: loss 0.025994
[epoch12, step697]: loss 0.028086
[epoch12, step698]: loss 0.024085
[epoch12, step699]: loss 0.023165
[epoch12, step700]: loss 0.021458
[epoch12, step701]: loss 0.025310
[epoch12, step702]: loss 0.020931
[epoch12, step703]: loss 0.022373
[epoch12, step704]: loss 0.024939
[epoch12, step705]: loss 0.024429
[epoch12, step706]: loss 0.023226
[epoch12, step707]: loss 0.024867
[epoch12, step708]: loss 0.025491
[epoch12, step709]: loss 0.027322
[epoch12, step710]: loss 0.023053
[epoch12, step711]: loss 0.023625
[epoch12, step712]: loss 0.025851
[epoch12, step713]: loss 0.025558
[epoch12, step714]: loss 0.020923
[epoch12, step715]: loss 0.022731
[epoch12, step716]: loss 0.025994
[epoch12, step717]: loss 0.022824
[epoch12, step718]: loss 0.024662
[epoch12, step719]: loss 0.033214
[epoch12, step720]: loss 0.024285
[epoch12, step721]: loss 0.022726
[epoch12, step722]: loss 0.029868
[epoch12, step723]: loss 0.026271
[epoch12, step724]: loss 0.022064
[epoch12, step725]: loss 0.027384
[epoch12, step726]: loss 0.022163
[epoch12, step727]: loss 0.023403
[epoch12, step728]: loss 0.026064
[epoch12, step729]: loss 0.020441
[epoch12, step730]: loss 0.022161
[epoch12, step731]: loss 0.025161
[epoch12, step732]: loss 0.025697
[epoch12, step733]: loss 0.023285
[epoch12, step734]: loss 0.021989
[epoch12, step735]: loss 0.027426
[epoch12, step736]: loss 0.024676
[epoch12, step737]: loss 0.026137
[epoch12, step738]: loss 0.020196
[epoch12, step739]: loss 0.025816
[epoch12, step740]: loss 0.021820
[epoch12, step741]: loss 0.025036
[epoch12, step742]: loss 0.021385
[epoch12, step743]: loss 0.022672
[epoch12, step744]: loss 0.023198
[epoch12, step745]: loss 0.024249
[epoch12, step746]: loss 0.024414
[epoch12, step747]: loss 0.026764
[epoch12, step748]: loss 0.025246
[epoch12, step749]: loss 0.025771
[epoch12, step750]: loss 0.027150
[epoch12, step751]: loss 0.020950
[epoch12, step752]: loss 0.024439
[epoch12, step753]: loss 0.025530
[epoch12, step754]: loss 0.021914
[epoch12, step755]: loss 0.025685
[epoch12, step756]: loss 0.023537
[epoch12, step757]: loss 0.020155
[epoch12, step758]: loss 0.024679
[epoch12, step759]: loss 0.022411
[epoch12, step760]: loss 0.023824
[epoch12, step761]: loss 0.027025
[epoch12, step762]: loss 0.021350
[epoch12, step763]: loss 0.024793
[epoch12, step764]: loss 0.023534
[epoch12, step765]: loss 0.024993
[epoch12, step766]: loss 0.024446
[epoch12, step767]: loss 0.026511
[epoch12, step768]: loss 0.019945
[epoch12, step769]: loss 0.026797
[epoch12, step770]: loss 0.025697
[epoch12, step771]: loss 0.022621
[epoch12, step772]: loss 0.028005
[epoch12, step773]: loss 0.025697
[epoch12, step774]: loss 0.024595
[epoch12, step775]: loss 0.020156
[epoch12, step776]: loss 0.025757
[epoch12, step777]: loss 0.022071
[epoch12, step778]: loss 0.027227
[epoch12, step779]: loss 0.024120
[epoch12, step780]: loss 0.019525
[epoch12, step781]: loss 0.024983
[epoch12, step782]: loss 0.022035
[epoch12, step783]: loss 0.019241
[epoch12, step784]: loss 0.020673
[epoch12, step785]: loss 0.021335
[epoch12, step786]: loss 0.025420
[epoch12, step787]: loss 0.022776
[epoch12, step788]: loss 0.024540
[epoch12, step789]: loss 0.022380
[epoch12, step790]: loss 0.023312
[epoch12, step791]: loss 0.026730
[epoch12, step792]: loss 0.024613
[epoch12, step793]: loss 0.026564
[epoch12, step794]: loss 0.020445
[epoch12, step795]: loss 0.025574
[epoch12, step796]: loss 0.027371
[epoch12, step797]: loss 0.026985
[epoch12, step798]: loss 0.026502
[epoch12, step799]: loss 0.025504
[epoch12, step800]: loss 0.021184
[epoch12, step801]: loss 0.021871
[epoch12, step802]: loss 0.022384
[epoch12, step803]: loss 0.025544
[epoch12, step804]: loss 0.027057
[epoch12, step805]: loss 0.028080
[epoch12, step806]: loss 0.021647
[epoch12, step807]: loss 0.020909
[epoch12, step808]: loss 0.023276
[epoch12, step809]: loss 0.022776
[epoch12, step810]: loss 0.025959
[epoch12, step811]: loss 0.025172
[epoch12, step812]: loss 0.024125
[epoch12, step813]: loss 0.023030
[epoch12, step814]: loss 0.025436
[epoch12, step815]: loss 0.024941
[epoch12, step816]: loss 0.024063
[epoch12, step817]: loss 0.024550
[epoch12, step818]: loss 0.021970
[epoch12, step819]: loss 0.019975
[epoch12, step820]: loss 0.023300
[epoch12, step821]: loss 0.021246
[epoch12, step822]: loss 0.030320
[epoch12, step823]: loss 0.023584
[epoch12, step824]: loss 0.026899
[epoch12, step825]: loss 0.025644
[epoch12, step826]: loss 0.024005
[epoch12, step827]: loss 0.026408
[epoch12, step828]: loss 0.028794
[epoch12, step829]: loss 0.026590
[epoch12, step830]: loss 0.022195
[epoch12, step831]: loss 0.026366
[epoch12, step832]: loss 0.020673
[epoch12, step833]: loss 0.028909
[epoch12, step834]: loss 0.025344
[epoch12, step835]: loss 0.019940
[epoch12, step836]: loss 0.026856
[epoch12, step837]: loss 0.025363
[epoch12, step838]: loss 0.026078
[epoch12, step839]: loss 0.028036
[epoch12, step840]: loss 0.020290
[epoch12, step841]: loss 0.023771
[epoch12, step842]: loss 0.027977
[epoch12, step843]: loss 0.024878
[epoch12, step844]: loss 0.024708
[epoch12, step845]: loss 0.020680
[epoch12, step846]: loss 0.025196
[epoch12, step847]: loss 0.026667
[epoch12, step848]: loss 0.024917
[epoch12, step849]: loss 0.024158
[epoch12, step850]: loss 0.022507
[epoch12, step851]: loss 0.023485
[epoch12, step852]: loss 0.022254
[epoch12, step853]: loss 0.028786
[epoch12, step854]: loss 0.022810
[epoch12, step855]: loss 0.026713
[epoch12, step856]: loss 0.021423
[epoch12, step857]: loss 0.025178
[epoch12, step858]: loss 0.024070
[epoch12, step859]: loss 0.023243
[epoch12, step860]: loss 0.021796
[epoch12, step861]: loss 0.022845
[epoch12, step862]: loss 0.022390
[epoch12, step863]: loss 0.020406
[epoch12, step864]: loss 0.026397
[epoch12, step865]: loss 0.023090
[epoch12, step866]: loss 0.024565
[epoch12, step867]: loss 0.024953
[epoch12, step868]: loss 0.026299
[epoch12, step869]: loss 0.023037
[epoch12, step870]: loss 0.030463
[epoch12, step871]: loss 0.022271
[epoch12, step872]: loss 0.025032
[epoch12, step873]: loss 0.025144
[epoch12, step874]: loss 0.022574
[epoch12, step875]: loss 0.023853
[epoch12, step876]: loss 0.024079
[epoch12, step877]: loss 0.018792
[epoch12, step878]: loss 0.022814
[epoch12, step879]: loss 0.027802
[epoch12, step880]: loss 0.025391
[epoch12, step881]: loss 0.021699
[epoch12, step882]: loss 0.022993
[epoch12, step883]: loss 0.022950
[epoch12, step884]: loss 0.025668
[epoch12, step885]: loss 0.025032
[epoch12, step886]: loss 0.026053
[epoch12, step887]: loss 0.023839
[epoch12, step888]: loss 0.023938
[epoch12, step889]: loss 0.022283
[epoch12, step890]: loss 0.023494
[epoch12, step891]: loss 0.024595
[epoch12, step892]: loss 0.020565
[epoch12, step893]: loss 0.024220
[epoch12, step894]: loss 0.024659
[epoch12, step895]: loss 0.022149
[epoch12, step896]: loss 0.023175
[epoch12, step897]: loss 0.023439
[epoch12, step898]: loss 0.024917
[epoch12, step899]: loss 0.027722
[epoch12, step900]: loss 0.026626
[epoch12, step901]: loss 0.026494
[epoch12, step902]: loss 0.023223
[epoch12, step903]: loss 0.023398
[epoch12, step904]: loss 0.027659
[epoch12, step905]: loss 0.026964
[epoch12, step906]: loss 0.023120
[epoch12, step907]: loss 0.023837
[epoch12, step908]: loss 0.022551
[epoch12, step909]: loss 0.025019
[epoch12, step910]: loss 0.024031
[epoch12, step911]: loss 0.024095
[epoch12, step912]: loss 0.023826
[epoch12, step913]: loss 0.022876
[epoch12, step914]: loss 0.029808
[epoch12, step915]: loss 0.023528
[epoch12, step916]: loss 0.023329
[epoch12, step917]: loss 0.024706
[epoch12, step918]: loss 0.028033
[epoch12, step919]: loss 0.023033
[epoch12, step920]: loss 0.027046
[epoch12, step921]: loss 0.023408
[epoch12, step922]: loss 0.022678
[epoch12, step923]: loss 0.022257
[epoch12, step924]: loss 0.021493
[epoch12, step925]: loss 0.024730
[epoch12, step926]: loss 0.026200
[epoch12, step927]: loss 0.024685
[epoch12, step928]: loss 0.024514
[epoch12, step929]: loss 0.026495
[epoch12, step930]: loss 0.025426
[epoch12, step931]: loss 0.026273
[epoch12, step932]: loss 0.021429
[epoch12, step933]: loss 0.028315
[epoch12, step934]: loss 0.022852
[epoch12, step935]: loss 0.022670
[epoch12, step936]: loss 0.022158
[epoch12, step937]: loss 0.026599
[epoch12, step938]: loss 0.025713
[epoch12, step939]: loss 0.021093
[epoch12, step940]: loss 0.022882
[epoch12, step941]: loss 0.026653
[epoch12, step942]: loss 0.025334
[epoch12, step943]: loss 0.022831
[epoch12, step944]: loss 0.026840
[epoch12, step945]: loss 0.020167
[epoch12, step946]: loss 0.025229
[epoch12, step947]: loss 0.027612
[epoch12, step948]: loss 0.020059
[epoch12, step949]: loss 0.022691
[epoch12, step950]: loss 0.025957
[epoch12, step951]: loss 0.027728
[epoch12, step952]: loss 0.024682
[epoch12, step953]: loss 0.027111
[epoch12, step954]: loss 0.021906
[epoch12, step955]: loss 0.034865
[epoch12, step956]: loss 0.050302
[epoch12, step957]: loss 0.044252
[epoch12, step958]: loss 0.041716
[epoch12, step959]: loss 0.045258
[epoch12, step960]: loss 0.041960
[epoch12, step961]: loss 0.042427
[epoch12, step962]: loss 0.040862
[epoch12, step963]: loss 0.038579
[epoch12, step964]: loss 0.038667
[epoch12, step965]: loss 0.040312
[epoch12, step966]: loss 0.038015
[epoch12, step967]: loss 0.037493
[epoch12, step968]: loss 0.040043
[epoch12, step969]: loss 0.039741
[epoch12, step970]: loss 0.038491
[epoch12, step971]: loss 0.037884
[epoch12, step972]: loss 0.038670
[epoch12, step973]: loss 0.037527
[epoch12, step974]: loss 0.039212
[epoch12, step975]: loss 0.036058
[epoch12, step976]: loss 0.036009
[epoch12, step977]: loss 0.039224
[epoch12, step978]: loss 0.037608
[epoch12, step979]: loss 0.036536
[epoch12, step980]: loss 0.035201
[epoch12, step981]: loss 0.036623
[epoch12, step982]: loss 0.037506
[epoch12, step983]: loss 0.038469
[epoch12, step984]: loss 0.034286
[epoch12, step985]: loss 0.035045
[epoch12, step986]: loss 0.039621
[epoch12, step987]: loss 0.037261
[epoch12, step988]: loss 0.036914
[epoch12, step989]: loss 0.035876
[epoch12, step990]: loss 0.036731
[epoch12, step991]: loss 0.037803
[epoch12, step992]: loss 0.038445
[epoch12, step993]: loss 0.035622
[epoch12, step994]: loss 0.035128
[epoch12, step995]: loss 0.038675
[epoch12, step996]: loss 0.036515
[epoch12, step997]: loss 0.036924
[epoch12, step998]: loss 0.036514
[epoch12, step999]: loss 0.036939
[epoch12, step1000]: loss 0.036848
[epoch12, step1001]: loss 0.037553
[epoch12, step1002]: loss 0.035084
[epoch12, step1003]: loss 0.034763
[epoch12, step1004]: loss 0.038525
[epoch12, step1005]: loss 0.035803
[epoch12, step1006]: loss 0.036691
[epoch12, step1007]: loss 0.034407
[epoch12, step1008]: loss 0.036272
[epoch12, step1009]: loss 0.036163
[epoch12, step1010]: loss 0.038900
[epoch12, step1011]: loss 0.034981
[epoch12, step1012]: loss 0.034682
[epoch12, step1013]: loss 0.038039
[epoch12, step1014]: loss 0.036661
[epoch12, step1015]: loss 0.036760
[epoch12, step1016]: loss 0.035263
[epoch12, step1017]: loss 0.036606
[epoch12, step1018]: loss 0.036628
[epoch12, step1019]: loss 0.037510
[epoch12, step1020]: loss 0.034478
[epoch12, step1021]: loss 0.034334
[epoch12, step1022]: loss 0.038047
[epoch12, step1023]: loss 0.037151
[epoch12, step1024]: loss 0.037990
[epoch12, step1025]: loss 0.034487
[epoch12, step1026]: loss 0.035704
[epoch12, step1027]: loss 0.035680
[epoch12, step1028]: loss 0.037233
[epoch12, step1029]: loss 0.034708
[epoch12, step1030]: loss 0.034357
[epoch12, step1031]: loss 0.037571
[epoch12, step1032]: loss 0.036510
[epoch12, step1033]: loss 0.035858
[epoch12, step1034]: loss 0.034268
[epoch12, step1035]: loss 0.035631
[epoch12, step1036]: loss 0.036442
[epoch12, step1037]: loss 0.036991
[epoch12, step1038]: loss 0.034164
[epoch12, step1039]: loss 0.034802
[epoch12, step1040]: loss 0.037098
[epoch12, step1041]: loss 0.035730
[epoch12, step1042]: loss 0.035120
[epoch12, step1043]: loss 0.034076
[epoch12, step1044]: loss 0.035779
[epoch12, step1045]: loss 0.035849
[epoch12, step1046]: loss 0.036940
[epoch12, step1047]: loss 0.035253
[epoch12, step1048]: loss 0.033998
[epoch12, step1049]: loss 0.037313
[epoch12, step1050]: loss 0.036242
[epoch12, step1051]: loss 0.035799
[epoch12, step1052]: loss 0.034322
[epoch12, step1053]: loss 0.036031
[epoch12, step1054]: loss 0.036122
[epoch12, step1055]: loss 0.036929
[epoch12, step1056]: loss 0.033994
[epoch12, step1057]: loss 0.035082
[epoch12, step1058]: loss 0.039332
[epoch12, step1059]: loss 0.036606
[epoch12, step1060]: loss 0.035911
[epoch12, step1061]: loss 0.034153
[epoch12, step1062]: loss 0.036190
[epoch12, step1063]: loss 0.036279
[epoch12, step1064]: loss 0.037720
[epoch12, step1065]: loss 0.034149
[epoch12, step1066]: loss 0.034014
[epoch12, step1067]: loss 0.037673
[epoch12, step1068]: loss 0.035082
[epoch12, step1069]: loss 0.035453
[epoch12, step1070]: loss 0.034861
[epoch12, step1071]: loss 0.037568
[epoch12, step1072]: loss 0.037580
[epoch12, step1073]: loss 0.037582
[epoch12, step1074]: loss 0.034520
[epoch12, step1075]: loss 0.034526
[epoch12, step1076]: loss 0.037930
[epoch12, step1077]: loss 0.036348
[epoch12, step1078]: loss 0.036158
[epoch12, step1079]: loss 0.034834
[epoch12, step1080]: loss 0.036337
[epoch12, step1081]: loss 0.036047
[epoch12, step1082]: loss 0.037187
[epoch12, step1083]: loss 0.035202
[epoch12, step1084]: loss 0.034573
[epoch12, step1085]: loss 0.037244
[epoch12, step1086]: loss 0.035610
[epoch12, step1087]: loss 0.035983
[epoch12, step1088]: loss 0.034131
[epoch12, step1089]: loss 0.036178
[epoch12, step1090]: loss 0.036619
[epoch12, step1091]: loss 0.037044
[epoch12, step1092]: loss 0.034384
[epoch12, step1093]: loss 0.034017
[epoch12, step1094]: loss 0.036881
[epoch12, step1095]: loss 0.035516
[epoch12, step1096]: loss 0.034992
[epoch12, step1097]: loss 0.033840
[epoch12, step1098]: loss 0.035918
[epoch12, step1099]: loss 0.035422
[epoch12, step1100]: loss 0.038309
[epoch12, step1101]: loss 0.035166
[epoch12, step1102]: loss 0.034285
[epoch12, step1103]: loss 0.036927
[epoch12, step1104]: loss 0.035364
[epoch12, step1105]: loss 0.035666
[epoch12, step1106]: loss 0.033447
[epoch12, step1107]: loss 0.035695
[epoch12, step1108]: loss 0.035425
[epoch12, step1109]: loss 0.037544
[epoch12, step1110]: loss 0.035497
[epoch12, step1111]: loss 0.034141
[epoch12, step1112]: loss 0.037409
[epoch12, step1113]: loss 0.035197
[epoch12, step1114]: loss 0.035370
[epoch12, step1115]: loss 0.033828
[epoch12, step1116]: loss 0.036065
[epoch12, step1117]: loss 0.036555
[epoch12, step1118]: loss 0.036696
[epoch12, step1119]: loss 0.035302
[epoch12, step1120]: loss 0.033807
[epoch12, step1121]: loss 0.037150
[epoch12, step1122]: loss 0.034996
[epoch12, step1123]: loss 0.034926
[epoch12, step1124]: loss 0.035770
[epoch12, step1125]: loss 0.036235
[epoch12, step1126]: loss 0.037628
[epoch12, step1127]: loss 0.036975
[epoch12, step1128]: loss 0.034473
[epoch12, step1129]: loss 0.034489
[epoch12, step1130]: loss 0.037819
[epoch12, step1131]: loss 0.036066
[epoch12, step1132]: loss 0.035857
[epoch12, step1133]: loss 0.034001
[epoch12, step1134]: loss 0.035309
[epoch12, step1135]: loss 0.037612
[epoch12, step1136]: loss 0.038841
[epoch12, step1137]: loss 0.034673
[epoch12, step1138]: loss 0.034399
[epoch12, step1139]: loss 0.037152
[epoch12, step1140]: loss 0.035534
[epoch12, step1141]: loss 0.035463
[epoch12, step1142]: loss 0.033998
[epoch12, step1143]: loss 0.036090
[epoch12, step1144]: loss 0.036023
[epoch12, step1145]: loss 0.036762
[epoch12, step1146]: loss 0.033907
[epoch12, step1147]: loss 0.034799
[epoch12, step1148]: loss 0.037108
[epoch12, step1149]: loss 0.035277
[epoch12, step1150]: loss 0.035036
[epoch12, step1151]: loss 0.034810
[epoch12, step1152]: loss 0.036243
[epoch12, step1153]: loss 0.035548
[epoch12, step1154]: loss 0.037945
[epoch12, step1155]: loss 0.034071
[epoch12, step1156]: loss 0.034131
[epoch12, step1157]: loss 0.037841
[epoch12, step1158]: loss 0.035731
[epoch12, step1159]: loss 0.035697
[epoch12, step1160]: loss 0.035052
[epoch12, step1161]: loss 0.036669
[epoch12, step1162]: loss 0.035695
[epoch12, step1163]: loss 0.036602
[epoch12, step1164]: loss 0.034173
[epoch12, step1165]: loss 0.035059
[epoch12, step1166]: loss 0.037746
[epoch12, step1167]: loss 0.035018
[epoch12, step1168]: loss 0.035639
[epoch12, step1169]: loss 0.033814
[epoch12, step1170]: loss 0.035313
[epoch12, step1171]: loss 0.035980
[epoch12, step1172]: loss 0.036642
[epoch12, step1173]: loss 0.033881
[epoch12, step1174]: loss 0.034115
[epoch12, step1175]: loss 0.037222
[epoch12, step1176]: loss 0.035704
[epoch12, step1177]: loss 0.035801
[epoch12, step1178]: loss 0.033710
[epoch12, step1179]: loss 0.035843
[epoch12, step1180]: loss 0.035528
[epoch12, step1181]: loss 0.037855
[epoch12, step1182]: loss 0.033600
[epoch12, step1183]: loss 0.034296
[epoch12, step1184]: loss 0.037046
[epoch12, step1185]: loss 0.035449
[epoch12, step1186]: loss 0.035735
[epoch12, step1187]: loss 0.034207
[epoch12, step1188]: loss 0.035471
[epoch12, step1189]: loss 0.035451
[epoch12, step1190]: loss 0.036657
[epoch12, step1191]: loss 0.035463
[epoch12, step1192]: loss 0.033722
[epoch12, step1193]: loss 0.037329
[epoch12, step1194]: loss 0.035592
[epoch12, step1195]: loss 0.035262
[epoch12, step1196]: loss 0.033508
[epoch12, step1197]: loss 0.035623
[epoch12, step1198]: loss 0.036332
[epoch12, step1199]: loss 0.037373
[epoch12, step1200]: loss 0.033833
[epoch12, step1201]: loss 0.034323
[epoch12, step1202]: loss 0.038783
[epoch12, step1203]: loss 0.035844
[epoch12, step1204]: loss 0.035573
[epoch12, step1205]: loss 0.034143
[epoch12, step1206]: loss 0.036110
[epoch12, step1207]: loss 0.036195
[epoch12, step1208]: loss 0.037872
[epoch12, step1209]: loss 0.033788
[epoch12, step1210]: loss 0.034268
[epoch12, step1211]: loss 0.037014
[epoch12, step1212]: loss 0.035469
[epoch12, step1213]: loss 0.036002
[epoch12, step1214]: loss 0.033969
[epoch12, step1215]: loss 0.037011
[epoch12, step1216]: loss 0.035515
[epoch12, step1217]: loss 0.037483
[epoch12, step1218]: loss 0.034001
[epoch12, step1219]: loss 0.034568
[epoch12, step1220]: loss 0.037355
[epoch12, step1221]: loss 0.035548
[epoch12, step1222]: loss 0.035575
[epoch12, step1223]: loss 0.034139
[epoch12, step1224]: loss 0.036094
[epoch12, step1225]: loss 0.035742
[epoch12, step1226]: loss 0.036554
[epoch12, step1227]: loss 0.033955
[epoch12, step1228]: loss 0.033647
[epoch12, step1229]: loss 0.036883
[epoch12, step1230]: loss 0.036224
[epoch12, step1231]: loss 0.035598
[epoch12, step1232]: loss 0.036157
[epoch12, step1233]: loss 0.035749
[epoch12, step1234]: loss 0.035505
[epoch12, step1235]: loss 0.037354
[epoch12, step1236]: loss 0.034724
[epoch12, step1237]: loss 0.034313
[epoch12, step1238]: loss 0.037600
[epoch12, step1239]: loss 0.036050
[epoch12, step1240]: loss 0.035666
[epoch12, step1241]: loss 0.034427
[epoch12, step1242]: loss 0.035736
[epoch12, step1243]: loss 0.035493
[epoch12, step1244]: loss 0.037187
[epoch12, step1245]: loss 0.034801
[epoch12, step1246]: loss 0.034217
[epoch12, step1247]: loss 0.036389
[epoch12, step1248]: loss 0.035916
[epoch12, step1249]: loss 0.036109
[epoch12, step1250]: loss 0.033737
[epoch12, step1251]: loss 0.036492
[epoch12, step1252]: loss 0.037085
[epoch12, step1253]: loss 0.037167
[epoch12, step1254]: loss 0.033974
[epoch12, step1255]: loss 0.034274
[epoch12, step1256]: loss 0.037697
[epoch12, step1257]: loss 0.036131
[epoch12, step1258]: loss 0.035727
[epoch12, step1259]: loss 0.034114
[epoch12, step1260]: loss 0.036122
[epoch12, step1261]: loss 0.035187
[epoch12, step1262]: loss 0.036159
[epoch12, step1263]: loss 0.035471
[epoch12, step1264]: loss 0.034729
[epoch12, step1265]: loss 0.036539
[epoch12, step1266]: loss 0.035155
[epoch12, step1267]: loss 0.035814
[epoch12, step1268]: loss 0.033742
[epoch12, step1269]: loss 0.035508
[epoch12, step1270]: loss 0.035578
[epoch12, step1271]: loss 0.037040
[epoch12, step1272]: loss 0.033730
[epoch12, step1273]: loss 0.034399
[epoch12, step1274]: loss 0.037580
[epoch12, step1275]: loss 0.036779
[epoch12, step1276]: loss 0.035284
[epoch12, step1277]: loss 0.033863
[epoch12, step1278]: loss 0.036856
[epoch12, step1279]: loss 0.036693
[epoch12, step1280]: loss 0.036818
[epoch12, step1281]: loss 0.033912
[epoch12, step1282]: loss 0.034052
[epoch12, step1283]: loss 0.037069
[epoch12, step1284]: loss 0.035689
[epoch12, step1285]: loss 0.035342
[epoch12, step1286]: loss 0.033967
[epoch12, step1287]: loss 0.036813
[epoch12, step1288]: loss 0.036851
[epoch12, step1289]: loss 0.038747
[epoch12, step1290]: loss 0.034388
[epoch12, step1291]: loss 0.034410
[epoch12, step1292]: loss 0.038567
[epoch12, step1293]: loss 0.035925
[epoch12, step1294]: loss 0.036136
[epoch12, step1295]: loss 0.034497
[epoch12, step1296]: loss 0.035988
[epoch12, step1297]: loss 0.036686
[epoch12, step1298]: loss 0.037582
[epoch12, step1299]: loss 0.034128
[epoch12, step1300]: loss 0.034603
[epoch12, step1301]: loss 0.036799
[epoch12, step1302]: loss 0.035525
[epoch12, step1303]: loss 0.035883
[epoch12, step1304]: loss 0.033502
[epoch12, step1305]: loss 0.036540
[epoch12, step1306]: loss 0.035989
[epoch12, step1307]: loss 0.037229
[epoch12, step1308]: loss 0.034756
[epoch12, step1309]: loss 0.033694
[epoch12, step1310]: loss 0.036989
[epoch12, step1311]: loss 0.035597
[epoch12, step1312]: loss 0.036529
[epoch12, step1313]: loss 0.034017
[epoch12, step1314]: loss 0.035498
[epoch12, step1315]: loss 0.035402
[epoch12, step1316]: loss 0.039187
[epoch12, step1317]: loss 0.033735
[epoch12, step1318]: loss 0.034014
[epoch12, step1319]: loss 0.036884
[epoch12, step1320]: loss 0.035373
[epoch12, step1321]: loss 0.035376
[epoch12, step1322]: loss 0.034443
[epoch12, step1323]: loss 0.036152
[epoch12, step1324]: loss 0.035405
[epoch12, step1325]: loss 0.036948
[epoch12, step1326]: loss 0.034124
[epoch12, step1327]: loss 0.033555
[epoch12, step1328]: loss 0.038330
[epoch12, step1329]: loss 0.035024
[epoch12, step1330]: loss 0.035587
[epoch12, step1331]: loss 0.034070
[epoch12, step1332]: loss 0.035820
[epoch12, step1333]: loss 0.035430
[epoch12, step1334]: loss 0.037044
[epoch12, step1335]: loss 0.035654
[epoch12, step1336]: loss 0.034328
[epoch12, step1337]: loss 0.037397
[epoch12, step1338]: loss 0.036267
[epoch12, step1339]: loss 0.035608
[epoch12, step1340]: loss 0.034315
[epoch12, step1341]: loss 0.036142
[epoch12, step1342]: loss 0.035673
[epoch12, step1343]: loss 0.036995
[epoch12, step1344]: loss 0.033993
[epoch12, step1345]: loss 0.033745
[epoch12, step1346]: loss 0.036716
[epoch12, step1347]: loss 0.036748
[epoch12, step1348]: loss 0.035142
[epoch12, step1349]: loss 0.034832
[epoch12, step1350]: loss 0.036311
[epoch12, step1351]: loss 0.035250
[epoch12, step1352]: loss 0.036659
[epoch12, step1353]: loss 0.034147
[epoch12, step1354]: loss 0.033861
[epoch12, step1355]: loss 0.037361
[epoch12, step1356]: loss 0.035646
[epoch12, step1357]: loss 0.035509
[epoch12, step1358]: loss 0.033577
[epoch12, step1359]: loss 0.035268
[epoch12, step1360]: loss 0.035997
[epoch12, step1361]: loss 0.037178
[epoch12, step1362]: loss 0.035042
[epoch12, step1363]: loss 0.034593
[epoch12, step1364]: loss 0.037027
[epoch12, step1365]: loss 0.035524
[epoch12, step1366]: loss 0.035234
[epoch12, step1367]: loss 0.033513
[epoch12, step1368]: loss 0.036823
[epoch12, step1369]: loss 0.035847
[epoch12, step1370]: loss 0.037286
[epoch12, step1371]: loss 0.034230
[epoch12, step1372]: loss 0.033330
[epoch12, step1373]: loss 0.037274
[epoch12, step1374]: loss 0.036815
[epoch12, step1375]: loss 0.036568
[epoch12, step1376]: loss 0.033528
[epoch12, step1377]: loss 0.036180
[epoch12, step1378]: loss 0.035879
[epoch12, step1379]: loss 0.036799
[epoch12, step1380]: loss 0.034449
[epoch12, step1381]: loss 0.033796
[epoch12, step1382]: loss 0.036931
[epoch12, step1383]: loss 0.035379
[epoch12, step1384]: loss 0.035493
[epoch12, step1385]: loss 0.032833
[epoch12, step1386]: loss 0.036122
[epoch12, step1387]: loss 0.036655
[epoch12, step1388]: loss 0.035964
[epoch12, step1389]: loss 0.033395
[epoch12, step1390]: loss 0.034179
[epoch12, step1391]: loss 0.036660
[epoch12, step1392]: loss 0.035266
[epoch12, step1393]: loss 0.035581
[epoch12, step1394]: loss 0.034823
[epoch12, step1395]: loss 0.035374
[epoch12, step1396]: loss 0.035818
[epoch12, step1397]: loss 0.036990
[epoch12, step1398]: loss 0.034077
[epoch12, step1399]: loss 0.034895
[epoch12, step1400]: loss 0.037515
[epoch12, step1401]: loss 0.035487
[epoch12, step1402]: loss 0.035466
[epoch12, step1403]: loss 0.033267
[epoch12, step1404]: loss 0.035539
[epoch12, step1405]: loss 0.035675
[epoch12, step1406]: loss 0.036898
[epoch12, step1407]: loss 0.036951
[epoch12, step1408]: loss 0.033276
[epoch12, step1409]: loss 0.036748
[epoch12, step1410]: loss 0.035130
[epoch12, step1411]: loss 0.034665
[epoch12, step1412]: loss 0.033446
[epoch12, step1413]: loss 0.035565
[epoch12, step1414]: loss 0.035228
[epoch12, step1415]: loss 0.037064
[epoch12, step1416]: loss 0.034313
[epoch12, step1417]: loss 0.034686
[epoch12, step1418]: loss 0.037670
[epoch12, step1419]: loss 0.036422
[epoch12, step1420]: loss 0.035894
[epoch12, step1421]: loss 0.034014
[epoch12, step1422]: loss 0.036162
[epoch12, step1423]: loss 0.035325
[epoch12, step1424]: loss 0.036715
[epoch12, step1425]: loss 0.033953
[epoch12, step1426]: loss 0.034097
[epoch12, step1427]: loss 0.037773
[epoch12, step1428]: loss 0.036691
[epoch12, step1429]: loss 0.035373
[epoch12, step1430]: loss 0.034368
[epoch12, step1431]: loss 0.035743
[epoch12, step1432]: loss 0.035481
[epoch12, step1433]: loss 0.036769
[epoch12, step1434]: loss 0.034122
[epoch12, step1435]: loss 0.034429
[epoch12, step1436]: loss 0.037702
[epoch12, step1437]: loss 0.035991
[epoch12, step1438]: loss 0.036727
[epoch12, step1439]: loss 0.033614
[epoch12, step1440]: loss 0.035730
[epoch12, step1441]: loss 0.036574
[epoch12, step1442]: loss 0.036751
[epoch12, step1443]: loss 0.034196
[epoch12, step1444]: loss 0.033531
[epoch12, step1445]: loss 0.037310
[epoch12, step1446]: loss 0.035240
[epoch12, step1447]: loss 0.036084
[epoch12, step1448]: loss 0.034010
[epoch12, step1449]: loss 0.035241
[epoch12, step1450]: loss 0.036039
[epoch12, step1451]: loss 0.037412
[epoch12, step1452]: loss 0.033907
[epoch12, step1453]: loss 0.035816
[epoch12, step1454]: loss 0.038473
[epoch12, step1455]: loss 0.036228
[epoch12, step1456]: loss 0.035600
[epoch12, step1457]: loss 0.034034
[epoch12, step1458]: loss 0.035621
[epoch12, step1459]: loss 0.035984
[epoch12, step1460]: loss 0.036762
[epoch12, step1461]: loss 0.034167
[epoch12, step1462]: loss 0.034396
[epoch12, step1463]: loss 0.037597
[epoch12, step1464]: loss 0.035360
[epoch12, step1465]: loss 0.034798
[epoch12, step1466]: loss 0.033142
[epoch12, step1467]: loss 0.035739
[epoch12, step1468]: loss 0.035428
[epoch12, step1469]: loss 0.037230
[epoch12, step1470]: loss 0.034957
[epoch12, step1471]: loss 0.034295
[epoch12, step1472]: loss 0.036768
[epoch12, step1473]: loss 0.035516
[epoch12, step1474]: loss 0.036144
[epoch12, step1475]: loss 0.033568
[epoch12, step1476]: loss 0.036592
[epoch12, step1477]: loss 0.035648
[epoch12, step1478]: loss 0.036937
[epoch12, step1479]: loss 0.033727
[epoch12, step1480]: loss 0.033267
[epoch12, step1481]: loss 0.036402
[epoch12, step1482]: loss 0.035858
[epoch12, step1483]: loss 0.035754
[epoch12, step1484]: loss 0.035063
[epoch12, step1485]: loss 0.035783
[epoch12, step1486]: loss 0.034778
[epoch12, step1487]: loss 0.036660
[epoch12, step1488]: loss 0.033837
[epoch12, step1489]: loss 0.033887
[epoch12, step1490]: loss 0.037137
[epoch12, step1491]: loss 0.035455
[epoch12, step1492]: loss 0.035508
[epoch12, step1493]: loss 0.033876
[epoch12, step1494]: loss 0.035590
[epoch12, step1495]: loss 0.035928
[epoch12, step1496]: loss 0.037432
[epoch12, step1497]: loss 0.034636
[epoch12, step1498]: loss 0.033883
[epoch12, step1499]: loss 0.036668
[epoch12, step1500]: loss 0.035867
[epoch12, step1501]: loss 0.034889
[epoch12, step1502]: loss 0.033277
[epoch12, step1503]: loss 0.035923
[epoch12, step1504]: loss 0.035126
[epoch12, step1505]: loss 0.037601
[epoch12, step1506]: loss 0.033318
[epoch12, step1507]: loss 0.034243
[epoch12, step1508]: loss 0.037786
[epoch12, step1509]: loss 0.035342
[epoch12, step1510]: loss 0.035005
[epoch12, step1511]: loss 0.034861
[epoch12, step1512]: loss 0.035700
[epoch12, step1513]: loss 0.034819
[epoch12, step1514]: loss 0.036735
[epoch12, step1515]: loss 0.034624
[epoch12, step1516]: loss 0.033174

[epoch12]: avg loss 0.032944

[epoch13, step1]: loss 0.035401
[epoch13, step2]: loss 0.036891
[epoch13, step3]: loss 0.036336
[epoch13, step4]: loss 0.034851
[epoch13, step5]: loss 0.034266
[epoch13, step6]: loss 0.036747
[epoch13, step7]: loss 0.034864
[epoch13, step8]: loss 0.036987
[epoch13, step9]: loss 0.033701
[epoch13, step10]: loss 0.034776
[epoch13, step11]: loss 0.037051
[epoch13, step12]: loss 0.036928
[epoch13, step13]: loss 0.034004
[epoch13, step14]: loss 0.033749
[epoch13, step15]: loss 0.036615
[epoch13, step16]: loss 0.035240
[epoch13, step17]: loss 0.037460
[epoch13, step18]: loss 0.034856
[epoch13, step19]: loss 0.034374
[epoch13, step20]: loss 0.037108
[epoch13, step21]: loss 0.037271
[epoch13, step22]: loss 0.034647
[epoch13, step23]: loss 0.035117
[epoch13, step24]: loss 0.037418
[epoch13, step25]: loss 0.034016
[epoch13, step26]: loss 0.037062
[epoch13, step27]: loss 0.033186
[epoch13, step28]: loss 0.035441
[epoch13, step29]: loss 0.037235
[epoch13, step30]: loss 0.038327
[epoch13, step31]: loss 0.033383
[epoch13, step32]: loss 0.035510
[epoch13, step33]: loss 0.038056
[epoch13, step34]: loss 0.035833
[epoch13, step35]: loss 0.037673
[epoch13, step36]: loss 0.033886
[epoch13, step37]: loss 0.034454
[epoch13, step38]: loss 0.037287
[epoch13, step39]: loss 0.037396
[epoch13, step40]: loss 0.034411
[epoch13, step41]: loss 0.034043
[epoch13, step42]: loss 0.037461
[epoch13, step43]: loss 0.034301
[epoch13, step44]: loss 0.037609
[epoch13, step45]: loss 0.033885
[epoch13, step46]: loss 0.034598
[epoch13, step47]: loss 0.036677
[epoch13, step48]: loss 0.036513
[epoch13, step49]: loss 0.033182
[epoch13, step50]: loss 0.034385
[epoch13, step51]: loss 0.036795
[epoch13, step52]: loss 0.034422
[epoch13, step53]: loss 0.038080
[epoch13, step54]: loss 0.033431
[epoch13, step55]: loss 0.035108
[epoch13, step56]: loss 0.038182
[epoch13, step57]: loss 0.037081
[epoch13, step58]: loss 0.034195
[epoch13, step59]: loss 0.034181
[epoch13, step60]: loss 0.037677
[epoch13, step61]: loss 0.034405
[epoch13, step62]: loss 0.037064
[epoch13, step63]: loss 0.033885
[epoch13, step64]: loss 0.034129
[epoch13, step65]: loss 0.037224
[epoch13, step66]: loss 0.036628
[epoch13, step67]: loss 0.034209
[epoch13, step68]: loss 0.034087
[epoch13, step69]: loss 0.037461
[epoch13, step70]: loss 0.034227
[epoch13, step71]: loss 0.036576
[epoch13, step72]: loss 0.033732
[epoch13, step73]: loss 0.035120
[epoch13, step74]: loss 0.036994
[epoch13, step75]: loss 0.037448
[epoch13, step76]: loss 0.034523
[epoch13, step77]: loss 0.034687
[epoch13, step78]: loss 0.037273
[epoch13, step79]: loss 0.034108
[epoch13, step80]: loss 0.037981
[epoch13, step81]: loss 0.033655
[epoch13, step82]: loss 0.034564
[epoch13, step83]: loss 0.037346
[epoch13, step84]: loss 0.036712
[epoch13, step85]: loss 0.035036
[epoch13, step86]: loss 0.034293
[epoch13, step87]: loss 0.038226
[epoch13, step88]: loss 0.034003
[epoch13, step89]: loss 0.036818
[epoch13, step90]: loss 0.034575
[epoch13, step91]: loss 0.034236
[epoch13, step92]: loss 0.037117
[epoch13, step93]: loss 0.037603
[epoch13, step94]: loss 0.033707
[epoch13, step95]: loss 0.034371
[epoch13, step96]: loss 0.036746
[epoch13, step97]: loss 0.035487
[epoch13, step98]: loss 0.036849
[epoch13, step99]: loss 0.034459
[epoch13, step100]: loss 0.033571
[epoch13, step101]: loss 0.037723
[epoch13, step102]: loss 0.037651
[epoch13, step103]: loss 0.033546
[epoch13, step104]: loss 0.033854
[epoch13, step105]: loss 0.037263
[epoch13, step106]: loss 0.034213
[epoch13, step107]: loss 0.037558
[epoch13, step108]: loss 0.033866
[epoch13, step109]: loss 0.034141
[epoch13, step110]: loss 0.037686
[epoch13, step111]: loss 0.037088
[epoch13, step112]: loss 0.033954
[epoch13, step113]: loss 0.034789
[epoch13, step114]: loss 0.036933
[epoch13, step115]: loss 0.033840
[epoch13, step116]: loss 0.038306
[epoch13, step117]: loss 0.033539
[epoch13, step118]: loss 0.035156
[epoch13, step119]: loss 0.036864
[epoch13, step120]: loss 0.037488
[epoch13, step121]: loss 0.033449
[epoch13, step122]: loss 0.033438
[epoch13, step123]: loss 0.037174
[epoch13, step124]: loss 0.034771
[epoch13, step125]: loss 0.037454
[epoch13, step126]: loss 0.034036
[epoch13, step127]: loss 0.034437
[epoch13, step128]: loss 0.037346
[epoch13, step129]: loss 0.038198
[epoch13, step130]: loss 0.034649
[epoch13, step131]: loss 0.034177
[epoch13, step132]: loss 0.037029
[epoch13, step133]: loss 0.034011
[epoch13, step134]: loss 0.036623
[epoch13, step135]: loss 0.034350
[epoch13, step136]: loss 0.036464
[epoch13, step137]: loss 0.037289
[epoch13, step138]: loss 0.036876
[epoch13, step139]: loss 0.033899
[epoch13, step140]: loss 0.034725
[epoch13, step141]: loss 0.037616
[epoch13, step142]: loss 0.033990
[epoch13, step143]: loss 0.036352
[epoch13, step144]: loss 0.034811
[epoch13, step145]: loss 0.034122
[epoch13, step146]: loss 0.036934
[epoch13, step147]: loss 0.038272
[epoch13, step148]: loss 0.033946
[epoch13, step149]: loss 0.034042
[epoch13, step150]: loss 0.037018
[epoch13, step151]: loss 0.034415
[epoch13, step152]: loss 0.037335
[epoch13, step153]: loss 0.033802
[epoch13, step154]: loss 0.034282
[epoch13, step155]: loss 0.037646
[epoch13, step156]: loss 0.036220
[epoch13, step157]: loss 0.033704
[epoch13, step158]: loss 0.034690
[epoch13, step159]: loss 0.037159
[epoch13, step160]: loss 0.034121
[epoch13, step161]: loss 0.037035
[epoch13, step162]: loss 0.034056
[epoch13, step163]: loss 0.034626
[epoch13, step164]: loss 0.037517
[epoch13, step165]: loss 0.037509
[epoch13, step166]: loss 0.034422
[epoch13, step167]: loss 0.034514
[epoch13, step168]: loss 0.038370
[epoch13, step169]: loss 0.034223
[epoch13, step170]: loss 0.037442
[epoch13, step171]: loss 0.033991
[epoch13, step172]: loss 0.034719
[epoch13, step173]: loss 0.037457
[epoch13, step174]: loss 0.036513
[epoch13, step175]: loss 0.034670
[epoch13, step176]: loss 0.034232
[epoch13, step177]: loss 0.037339
[epoch13, step178]: loss 0.034505
[epoch13, step179]: loss 0.036386
[epoch13, step180]: loss 0.033428
[epoch13, step181]: loss 0.034347
[epoch13, step182]: loss 0.037111
[epoch13, step183]: loss 0.037162
[epoch13, step184]: loss 0.034339
[epoch13, step185]: loss 0.034693
[epoch13, step186]: loss 0.037449
[epoch13, step187]: loss 0.034532
[epoch13, step188]: loss 0.037255
[epoch13, step189]: loss 0.034084
[epoch13, step190]: loss 0.034919
[epoch13, step191]: loss 0.036897
[epoch13, step192]: loss 0.038153
[epoch13, step193]: loss 0.033158
[epoch13, step194]: loss 0.033077
[epoch13, step195]: loss 0.038040
[epoch13, step196]: loss 0.034921
[epoch13, step197]: loss 0.037080
[epoch13, step198]: loss 0.033002
[epoch13, step199]: loss 0.034075
[epoch13, step200]: loss 0.037619
[epoch13, step201]: loss 0.037246
[epoch13, step202]: loss 0.033778
[epoch13, step203]: loss 0.034552
[epoch13, step204]: loss 0.037683
[epoch13, step205]: loss 0.034371
[epoch13, step206]: loss 0.036962
[epoch13, step207]: loss 0.033762
[epoch13, step208]: loss 0.035119
[epoch13, step209]: loss 0.037446
[epoch13, step210]: loss 0.038321
[epoch13, step211]: loss 0.034681
[epoch13, step212]: loss 0.034271
[epoch13, step213]: loss 0.037177
[epoch13, step214]: loss 0.034109
[epoch13, step215]: loss 0.037168
[epoch13, step216]: loss 0.033999
[epoch13, step217]: loss 0.034514
[epoch13, step218]: loss 0.037362
[epoch13, step219]: loss 0.036726
[epoch13, step220]: loss 0.034869
[epoch13, step221]: loss 0.034343
[epoch13, step222]: loss 0.037374
[epoch13, step223]: loss 0.034071
[epoch13, step224]: loss 0.036860
[epoch13, step225]: loss 0.033597
[epoch13, step226]: loss 0.034238
[epoch13, step227]: loss 0.036547
[epoch13, step228]: loss 0.037653
[epoch13, step229]: loss 0.033061
[epoch13, step230]: loss 0.034637
[epoch13, step231]: loss 0.038030
[epoch13, step232]: loss 0.034334
[epoch13, step233]: loss 0.036462
[epoch13, step234]: loss 0.033346
[epoch13, step235]: loss 0.034086
[epoch13, step236]: loss 0.036910
[epoch13, step237]: loss 0.036471
[epoch13, step238]: loss 0.033728
[epoch13, step239]: loss 0.033581
[epoch13, step240]: loss 0.036469
[epoch13, step241]: loss 0.034545
[epoch13, step242]: loss 0.036866
[epoch13, step243]: loss 0.035130
[epoch13, step244]: loss 0.033676
[epoch13, step245]: loss 0.036840
[epoch13, step246]: loss 0.037115
[epoch13, step247]: loss 0.034690
[epoch13, step248]: loss 0.033380
[epoch13, step249]: loss 0.036627
[epoch13, step250]: loss 0.034458
[epoch13, step251]: loss 0.037325
[epoch13, step252]: loss 0.034317
[epoch13, step253]: loss 0.033815
[epoch13, step254]: loss 0.036883
[epoch13, step255]: loss 0.036706
[epoch13, step256]: loss 0.033512
[epoch13, step257]: loss 0.033829
[epoch13, step258]: loss 0.038059
[epoch13, step259]: loss 0.034881
[epoch13, step260]: loss 0.036647
[epoch13, step261]: loss 0.035339
[epoch13, step262]: loss 0.035392
[epoch13, step263]: loss 0.036727
[epoch13, step264]: loss 0.036280
[epoch13, step265]: loss 0.033984
[epoch13, step266]: loss 0.033401
[epoch13, step267]: loss 0.036787
[epoch13, step268]: loss 0.034038
[epoch13, step269]: loss 0.036748
[epoch13, step270]: loss 0.033766
[epoch13, step271]: loss 0.033816
[epoch13, step272]: loss 0.036638
[epoch13, step273]: loss 0.036601
[epoch13, step274]: loss 0.034061
[epoch13, step275]: loss 0.033316
[epoch13, step276]: loss 0.036628
[epoch13, step277]: loss 0.035108
[epoch13, step278]: loss 0.037219
[epoch13, step279]: loss 0.032974
[epoch13, step280]: loss 0.035095
[epoch13, step281]: loss 0.036802
[epoch13, step282]: loss 0.037792
[epoch13, step283]: loss 0.033398
[epoch13, step284]: loss 0.033363
[epoch13, step285]: loss 0.038220
[epoch13, step286]: loss 0.034304
[epoch13, step287]: loss 0.037753
[epoch13, step288]: loss 0.033478
[epoch13, step289]: loss 0.035124
[epoch13, step290]: loss 0.036558
[epoch13, step291]: loss 0.036563
[epoch13, step292]: loss 0.033671
[epoch13, step293]: loss 0.033306
[epoch13, step294]: loss 0.036451
[epoch13, step295]: loss 0.033785
[epoch13, step296]: loss 0.038134
[epoch13, step297]: loss 0.033850
[epoch13, step298]: loss 0.034942
[epoch13, step299]: loss 0.036481
[epoch13, step300]: loss 0.037411
[epoch13, step301]: loss 0.034201
[epoch13, step302]: loss 0.034621
[epoch13, step303]: loss 0.037476
[epoch13, step304]: loss 0.033913
[epoch13, step305]: loss 0.036240
[epoch13, step306]: loss 0.033916
[epoch13, step307]: loss 0.033814
[epoch13, step308]: loss 0.037343
[epoch13, step309]: loss 0.036874
[epoch13, step310]: loss 0.033654
[epoch13, step311]: loss 0.034313
[epoch13, step312]: loss 0.037039
[epoch13, step313]: loss 0.034370
[epoch13, step314]: loss 0.036536
[epoch13, step315]: loss 0.035471
[epoch13, step316]: loss 0.034015
[epoch13, step317]: loss 0.037615
[epoch13, step318]: loss 0.037313
[epoch13, step319]: loss 0.033657
[epoch13, step320]: loss 0.033033
[epoch13, step321]: loss 0.035971
[epoch13, step322]: loss 0.034352
[epoch13, step323]: loss 0.035671
[epoch13, step324]: loss 0.036124
[epoch13, step325]: loss 0.034193
[epoch13, step326]: loss 0.036439
[epoch13, step327]: loss 0.036408
[epoch13, step328]: loss 0.034034
[epoch13, step329]: loss 0.033674
[epoch13, step330]: loss 0.036598
[epoch13, step331]: loss 0.034637
[epoch13, step332]: loss 0.036261
[epoch13, step333]: loss 0.033994
[epoch13, step334]: loss 0.034791
[epoch13, step335]: loss 0.037190
[epoch13, step336]: loss 0.038147
[epoch13, step337]: loss 0.034979
[epoch13, step338]: loss 0.033385
[epoch13, step339]: loss 0.037525
[epoch13, step340]: loss 0.034982
[epoch13, step341]: loss 0.036140
[epoch13, step342]: loss 0.033379
[epoch13, step343]: loss 0.034516
[epoch13, step344]: loss 0.036368
[epoch13, step345]: loss 0.036239
[epoch13, step346]: loss 0.033243
[epoch13, step347]: loss 0.033996
[epoch13, step348]: loss 0.037302
[epoch13, step349]: loss 0.035180
[epoch13, step350]: loss 0.037147
[epoch13, step351]: loss 0.032795
[epoch13, step352]: loss 0.033727
[epoch13, step353]: loss 0.036730
[epoch13, step354]: loss 0.035953
[epoch13, step355]: loss 0.032995
[epoch13, step356]: loss 0.034995
[epoch13, step357]: loss 0.036761
[epoch13, step358]: loss 0.032977
[epoch13, step359]: loss 0.038443
[epoch13, step360]: loss 0.032521
[epoch13, step361]: loss 0.033875
[epoch13, step362]: loss 0.037926
[epoch13, step363]: loss 0.036213
[epoch13, step364]: loss 0.033705
[epoch13, step365]: loss 0.033785
[epoch13, step366]: loss 0.037596
[epoch13, step367]: loss 0.034308
[epoch13, step368]: loss 0.037000
[epoch13, step369]: loss 0.033780
[epoch13, step370]: loss 0.034912
[epoch13, step371]: loss 0.037299
[epoch13, step372]: loss 0.036583
[epoch13, step373]: loss 0.033668
[epoch13, step374]: loss 0.033561
[epoch13, step375]: loss 0.037330
[epoch13, step376]: loss 0.034196
[epoch13, step377]: loss 0.036605
[epoch13, step378]: loss 0.034282
[epoch13, step379]: loss 0.034439
[epoch13, step380]: loss 0.037677
[epoch13, step381]: loss 0.036740
[epoch13, step382]: loss 0.034041
[epoch13, step383]: loss 0.033374
[epoch13, step384]: loss 0.036803
[epoch13, step385]: loss 0.033869
[epoch13, step386]: loss 0.036899
[epoch13, step387]: loss 0.033608
[epoch13, step388]: loss 0.035516
[epoch13, step389]: loss 0.037211
[epoch13, step390]: loss 0.038035
[epoch13, step391]: loss 0.033198
[epoch13, step392]: loss 0.034592
[epoch13, step393]: loss 0.036930
[epoch13, step394]: loss 0.034091
[epoch13, step395]: loss 0.036528
[epoch13, step396]: loss 0.033461
[epoch13, step397]: loss 0.033781
[epoch13, step398]: loss 0.036821
[epoch13, step399]: loss 0.036487
[epoch13, step400]: loss 0.033235
[epoch13, step401]: loss 0.033279
[epoch13, step402]: loss 0.036548
[epoch13, step403]: loss 0.034148
[epoch13, step404]: loss 0.037843
[epoch13, step405]: loss 0.034228
[epoch13, step406]: loss 0.034607
[epoch13, step407]: loss 0.037166
[epoch13, step408]: loss 0.036203
[epoch13, step409]: loss 0.035341
[epoch13, step410]: loss 0.033881
[epoch13, step411]: loss 0.037243
[epoch13, step412]: loss 0.034743
[epoch13, step413]: loss 0.036653
[epoch13, step414]: loss 0.034546
[epoch13, step415]: loss 0.033576
[epoch13, step416]: loss 0.036162
[epoch13, step417]: loss 0.036844
[epoch13, step418]: loss 0.034255
[epoch13, step419]: loss 0.032660
[epoch13, step420]: loss 0.037457
[epoch13, step421]: loss 0.033931
[epoch13, step422]: loss 0.036672
[epoch13, step423]: loss 0.033950
[epoch13, step424]: loss 0.034536
[epoch13, step425]: loss 0.036597
[epoch13, step426]: loss 0.036993
[epoch13, step427]: loss 0.034134
[epoch13, step428]: loss 0.034078
[epoch13, step429]: loss 0.037754
[epoch13, step430]: loss 0.034731
[epoch13, step431]: loss 0.036815
[epoch13, step432]: loss 0.033691
[epoch13, step433]: loss 0.034676
[epoch13, step434]: loss 0.036823
[epoch13, step435]: loss 0.037055
[epoch13, step436]: loss 0.033356
[epoch13, step437]: loss 0.033901
[epoch13, step438]: loss 0.037379
[epoch13, step439]: loss 0.034300
[epoch13, step440]: loss 0.036638
[epoch13, step441]: loss 0.033841
[epoch13, step442]: loss 0.033576
[epoch13, step443]: loss 0.037247
[epoch13, step444]: loss 0.036352
[epoch13, step445]: loss 0.033551
[epoch13, step446]: loss 0.033831
[epoch13, step447]: loss 0.037100
[epoch13, step448]: loss 0.034774
[epoch13, step449]: loss 0.036750
[epoch13, step450]: loss 0.034060
[epoch13, step451]: loss 0.033374
[epoch13, step452]: loss 0.035873
[epoch13, step453]: loss 0.037542
[epoch13, step454]: loss 0.034721
[epoch13, step455]: loss 0.035115
[epoch13, step456]: loss 0.037488
[epoch13, step457]: loss 0.036293
[epoch13, step458]: loss 0.037167
[epoch13, step459]: loss 0.036372
[epoch13, step460]: loss 0.036115
[epoch13, step461]: loss 0.038397
[epoch13, step462]: loss 0.035974
[epoch13, step463]: loss 0.034633
[epoch13, step464]: loss 0.033315
[epoch13, step465]: loss 0.038855
[epoch13, step466]: loss 0.034172
[epoch13, step467]: loss 0.036319
[epoch13, step468]: loss 0.034116
[epoch13, step469]: loss 0.034182
[epoch13, step470]: loss 0.036796
[epoch13, step471]: loss 0.036862
[epoch13, step472]: loss 0.034294
[epoch13, step473]: loss 0.033292
[epoch13, step474]: loss 0.036314
[epoch13, step475]: loss 0.034433
[epoch13, step476]: loss 0.037103
[epoch13, step477]: loss 0.033847
[epoch13, step478]: loss 0.033648
[epoch13, step479]: loss 0.036822
[epoch13, step480]: loss 0.036202
[epoch13, step481]: loss 0.033358
[epoch13, step482]: loss 0.033001
[epoch13, step483]: loss 0.037706
[epoch13, step484]: loss 0.034375
[epoch13, step485]: loss 0.036962
[epoch13, step486]: loss 0.034188
[epoch13, step487]: loss 0.033862
[epoch13, step488]: loss 0.037521
[epoch13, step489]: loss 0.036092
[epoch13, step490]: loss 0.034601
[epoch13, step491]: loss 0.033900
[epoch13, step492]: loss 0.036399
[epoch13, step493]: loss 0.033916
[epoch13, step494]: loss 0.035885
[epoch13, step495]: loss 0.035244
[epoch13, step496]: loss 0.034447
[epoch13, step497]: loss 0.036971
[epoch13, step498]: loss 0.036475
[epoch13, step499]: loss 0.033770
[epoch13, step500]: loss 0.033338
[epoch13, step501]: loss 0.036653
[epoch13, step502]: loss 0.033270
[epoch13, step503]: loss 0.037077
[epoch13, step504]: loss 0.034141
[epoch13, step505]: loss 0.033425
[epoch13, step506]: loss 0.037253
[epoch13, step507]: loss 0.037434
[epoch13, step508]: loss 0.034581
[epoch13, step509]: loss 0.033278
[epoch13, step510]: loss 0.036816
[epoch13, step511]: loss 0.034291
[epoch13, step512]: loss 0.036622
[epoch13, step513]: loss 0.034357
[epoch13, step514]: loss 0.034313
[epoch13, step515]: loss 0.037094
[epoch13, step516]: loss 0.036889
[epoch13, step517]: loss 0.033852
[epoch13, step518]: loss 0.033732
[epoch13, step519]: loss 0.037202
[epoch13, step520]: loss 0.033873
[epoch13, step521]: loss 0.036879
[epoch13, step522]: loss 0.033561
[epoch13, step523]: loss 0.034107
[epoch13, step524]: loss 0.036354
[epoch13, step525]: loss 0.037249
[epoch13, step526]: loss 0.033781
[epoch13, step527]: loss 0.033048
[epoch13, step528]: loss 0.036849
[epoch13, step529]: loss 0.033265
[epoch13, step530]: loss 0.037110
[epoch13, step531]: loss 0.033446
[epoch13, step532]: loss 0.034421
[epoch13, step533]: loss 0.037699
[epoch13, step534]: loss 0.036276
[epoch13, step535]: loss 0.034412
[epoch13, step536]: loss 0.033792
[epoch13, step537]: loss 0.036956
[epoch13, step538]: loss 0.034204
[epoch13, step539]: loss 0.036118
[epoch13, step540]: loss 0.034900
[epoch13, step541]: loss 0.033544
[epoch13, step542]: loss 0.036354
[epoch13, step543]: loss 0.036259
[epoch13, step544]: loss 0.033626
[epoch13, step545]: loss 0.033313
[epoch13, step546]: loss 0.037480
[epoch13, step547]: loss 0.033930
[epoch13, step548]: loss 0.036737
[epoch13, step549]: loss 0.033969
[epoch13, step550]: loss 0.033974
[epoch13, step551]: loss 0.037528
[epoch13, step552]: loss 0.036705
[epoch13, step553]: loss 0.034688
[epoch13, step554]: loss 0.033382
[epoch13, step555]: loss 0.036703
[epoch13, step556]: loss 0.033797
[epoch13, step557]: loss 0.035867
[epoch13, step558]: loss 0.034076
[epoch13, step559]: loss 0.033647
[epoch13, step560]: loss 0.037027
[epoch13, step561]: loss 0.036093
[epoch13, step562]: loss 0.033818
[epoch13, step563]: loss 0.031052
[epoch13, step564]: loss 0.032526
[epoch13, step565]: loss 0.027698
[epoch13, step566]: loss 0.036299
[epoch13, step567]: loss 0.027447
[epoch13, step568]: loss 0.025443
[epoch13, step569]: loss 0.024011
[epoch13, step570]: loss 0.031713
[epoch13, step571]: loss 0.025359
[epoch13, step572]: loss 0.026187
[epoch13, step573]: loss 0.029530
[epoch13, step574]: loss 0.028706
[epoch13, step575]: loss 0.021407
[epoch13, step576]: loss 0.022122
[epoch13, step577]: loss 0.025953
[epoch13, step578]: loss 0.019297
[epoch13, step579]: loss 0.029083
[epoch13, step580]: loss 0.020545
[epoch13, step581]: loss 0.025932
[epoch13, step582]: loss 0.026627
[epoch13, step583]: loss 0.023039
[epoch13, step584]: loss 0.024889
[epoch13, step585]: loss 0.026262
[epoch13, step586]: loss 0.021811
[epoch13, step587]: loss 0.027829
[epoch13, step588]: loss 0.023730
[epoch13, step589]: loss 0.022790
[epoch13, step590]: loss 0.027672
[epoch13, step591]: loss 0.020583
[epoch13, step592]: loss 0.026791
[epoch13, step593]: loss 0.022069
[epoch13, step594]: loss 0.025769
[epoch13, step595]: loss 0.027276
[epoch13, step596]: loss 0.022923
[epoch13, step597]: loss 0.025159
[epoch13, step598]: loss 0.027660
[epoch13, step599]: loss 0.025355
[epoch13, step600]: loss 0.027085
[epoch13, step601]: loss 0.020509
[epoch13, step602]: loss 0.023065
[epoch13, step603]: loss 0.025653
[epoch13, step604]: loss 0.026634
[epoch13, step605]: loss 0.025818
[epoch13, step606]: loss 0.024888
[epoch13, step607]: loss 0.026016
[epoch13, step608]: loss 0.025371
[epoch13, step609]: loss 0.026086
[epoch13, step610]: loss 0.026629
[epoch13, step611]: loss 0.026558
[epoch13, step612]: loss 0.025087
[epoch13, step613]: loss 0.020036
[epoch13, step614]: loss 0.024656
[epoch13, step615]: loss 0.027761
[epoch13, step616]: loss 0.023601
[epoch13, step617]: loss 0.022837
[epoch13, step618]: loss 0.025965
[epoch13, step619]: loss 0.028162
[epoch13, step620]: loss 0.023402
[epoch13, step621]: loss 0.025642
[epoch13, step622]: loss 0.020191
[epoch13, step623]: loss 0.025231
[epoch13, step624]: loss 0.026284
[epoch13, step625]: loss 0.025238
[epoch13, step626]: loss 0.027651
[epoch13, step627]: loss 0.022917
[epoch13, step628]: loss 0.024792
[epoch13, step629]: loss 0.020684
[epoch13, step630]: loss 0.022713
[epoch13, step631]: loss 0.032035
[epoch13, step632]: loss 0.022454
[epoch13, step633]: loss 0.024029
[epoch13, step634]: loss 0.027378
[epoch13, step635]: loss 0.025292
[epoch13, step636]: loss 0.021144
[epoch13, step637]: loss 0.028112
[epoch13, step638]: loss 0.026767
[epoch13, step639]: loss 0.021892
[epoch13, step640]: loss 0.029299
[epoch13, step641]: loss 0.030020
[epoch13, step642]: loss 0.024731
[epoch13, step643]: loss 0.025111
[epoch13, step644]: loss 0.025726
[epoch13, step645]: loss 0.023732
[epoch13, step646]: loss 0.025370
[epoch13, step647]: loss 0.022775
[epoch13, step648]: loss 0.023807
[epoch13, step649]: loss 0.028122
[epoch13, step650]: loss 0.022040
[epoch13, step651]: loss 0.025671
[epoch13, step652]: loss 0.026584
[epoch13, step653]: loss 0.027460
[epoch13, step654]: loss 0.022410
[epoch13, step655]: loss 0.023886
[epoch13, step656]: loss 0.021384
[epoch13, step657]: loss 0.027489
[epoch13, step658]: loss 0.024699
[epoch13, step659]: loss 0.026689
[epoch13, step660]: loss 0.023040
[epoch13, step661]: loss 0.025559
[epoch13, step662]: loss 0.023916
[epoch13, step663]: loss 0.021334
[epoch13, step664]: loss 0.024582
[epoch13, step665]: loss 0.027429
[epoch13, step666]: loss 0.025745
[epoch13, step667]: loss 0.026436
[epoch13, step668]: loss 0.022981
[epoch13, step669]: loss 0.025989
[epoch13, step670]: loss 0.026097
[epoch13, step671]: loss 0.020664
[epoch13, step672]: loss 0.024001
[epoch13, step673]: loss 0.023232
[epoch13, step674]: loss 0.020711
[epoch13, step675]: loss 0.019861
[epoch13, step676]: loss 0.023923
[epoch13, step677]: loss 0.024422
[epoch13, step678]: loss 0.022286
[epoch13, step679]: loss 0.023322
[epoch13, step680]: loss 0.030352
[epoch13, step681]: loss 0.020920
[epoch13, step682]: loss 0.025277
[epoch13, step683]: loss 0.025531
[epoch13, step684]: loss 0.024681
[epoch13, step685]: loss 0.024229
[epoch13, step686]: loss 0.026779
[epoch13, step687]: loss 0.026131
[epoch13, step688]: loss 0.022784
[epoch13, step689]: loss 0.024348
[epoch13, step690]: loss 0.024650
[epoch13, step691]: loss 0.024108
[epoch13, step692]: loss 0.022585
[epoch13, step693]: loss 0.026473
[epoch13, step694]: loss 0.021971
[epoch13, step695]: loss 0.026004
[epoch13, step696]: loss 0.025940
[epoch13, step697]: loss 0.027061
[epoch13, step698]: loss 0.024000
[epoch13, step699]: loss 0.023440
[epoch13, step700]: loss 0.022247
[epoch13, step701]: loss 0.026110
[epoch13, step702]: loss 0.021045
[epoch13, step703]: loss 0.023436
[epoch13, step704]: loss 0.025284
[epoch13, step705]: loss 0.023862
[epoch13, step706]: loss 0.023775
[epoch13, step707]: loss 0.024781
[epoch13, step708]: loss 0.025643
[epoch13, step709]: loss 0.027345
[epoch13, step710]: loss 0.023040
[epoch13, step711]: loss 0.023770
[epoch13, step712]: loss 0.025698
[epoch13, step713]: loss 0.025877
[epoch13, step714]: loss 0.021241
[epoch13, step715]: loss 0.022313
[epoch13, step716]: loss 0.025553
[epoch13, step717]: loss 0.022836
[epoch13, step718]: loss 0.024597
[epoch13, step719]: loss 0.032888
[epoch13, step720]: loss 0.023826
[epoch13, step721]: loss 0.022242
[epoch13, step722]: loss 0.030560
[epoch13, step723]: loss 0.025610
[epoch13, step724]: loss 0.021899
[epoch13, step725]: loss 0.027134
[epoch13, step726]: loss 0.022060
[epoch13, step727]: loss 0.023420
[epoch13, step728]: loss 0.025865
[epoch13, step729]: loss 0.021387
[epoch13, step730]: loss 0.022111
[epoch13, step731]: loss 0.025154
[epoch13, step732]: loss 0.024960
[epoch13, step733]: loss 0.023353
[epoch13, step734]: loss 0.021700
[epoch13, step735]: loss 0.027920
[epoch13, step736]: loss 0.024504
[epoch13, step737]: loss 0.025905
[epoch13, step738]: loss 0.019951
[epoch13, step739]: loss 0.025344
[epoch13, step740]: loss 0.022186
[epoch13, step741]: loss 0.024743
[epoch13, step742]: loss 0.021626
[epoch13, step743]: loss 0.022639
[epoch13, step744]: loss 0.023055
[epoch13, step745]: loss 0.024116
[epoch13, step746]: loss 0.024256
[epoch13, step747]: loss 0.026611
[epoch13, step748]: loss 0.024953
[epoch13, step749]: loss 0.025522
[epoch13, step750]: loss 0.026879
[epoch13, step751]: loss 0.021195
[epoch13, step752]: loss 0.024477
[epoch13, step753]: loss 0.025666
[epoch13, step754]: loss 0.022055
[epoch13, step755]: loss 0.025609
[epoch13, step756]: loss 0.023198
[epoch13, step757]: loss 0.020456
[epoch13, step758]: loss 0.024994
[epoch13, step759]: loss 0.022223
[epoch13, step760]: loss 0.023865
[epoch13, step761]: loss 0.026938
[epoch13, step762]: loss 0.021082
[epoch13, step763]: loss 0.025047
[epoch13, step764]: loss 0.024047
[epoch13, step765]: loss 0.025471
[epoch13, step766]: loss 0.024282
[epoch13, step767]: loss 0.027059
[epoch13, step768]: loss 0.020669
[epoch13, step769]: loss 0.026515
[epoch13, step770]: loss 0.024832
[epoch13, step771]: loss 0.022625
[epoch13, step772]: loss 0.027786
[epoch13, step773]: loss 0.026072
[epoch13, step774]: loss 0.024464
[epoch13, step775]: loss 0.020375
[epoch13, step776]: loss 0.025040
[epoch13, step777]: loss 0.021747
[epoch13, step778]: loss 0.027108
[epoch13, step779]: loss 0.023641
[epoch13, step780]: loss 0.019792
[epoch13, step781]: loss 0.023960
[epoch13, step782]: loss 0.021929
[epoch13, step783]: loss 0.019114
[epoch13, step784]: loss 0.020174
[epoch13, step785]: loss 0.021051
[epoch13, step786]: loss 0.024492
[epoch13, step787]: loss 0.022384
[epoch13, step788]: loss 0.024189
[epoch13, step789]: loss 0.022506
[epoch13, step790]: loss 0.022537
[epoch13, step791]: loss 0.026461
[epoch13, step792]: loss 0.024531
[epoch13, step793]: loss 0.026379
[epoch13, step794]: loss 0.020412
[epoch13, step795]: loss 0.025235
[epoch13, step796]: loss 0.027443
[epoch13, step797]: loss 0.027030
[epoch13, step798]: loss 0.026500
[epoch13, step799]: loss 0.025492
[epoch13, step800]: loss 0.021036
[epoch13, step801]: loss 0.021603
[epoch13, step802]: loss 0.021979
[epoch13, step803]: loss 0.025571
[epoch13, step804]: loss 0.027145
[epoch13, step805]: loss 0.027891
[epoch13, step806]: loss 0.021055
[epoch13, step807]: loss 0.020900
[epoch13, step808]: loss 0.023114
[epoch13, step809]: loss 0.022051
[epoch13, step810]: loss 0.024938
[epoch13, step811]: loss 0.024627
[epoch13, step812]: loss 0.023426
[epoch13, step813]: loss 0.022866
[epoch13, step814]: loss 0.024569
[epoch13, step815]: loss 0.024568
[epoch13, step816]: loss 0.023166
[epoch13, step817]: loss 0.024058
[epoch13, step818]: loss 0.021338
[epoch13, step819]: loss 0.020430
[epoch13, step820]: loss 0.023080
[epoch13, step821]: loss 0.020752
[epoch13, step822]: loss 0.029569
[epoch13, step823]: loss 0.023781
[epoch13, step824]: loss 0.026131
[epoch13, step825]: loss 0.024519
[epoch13, step826]: loss 0.024012
[epoch13, step827]: loss 0.026408
[epoch13, step828]: loss 0.028139
[epoch13, step829]: loss 0.026234
[epoch13, step830]: loss 0.021807
[epoch13, step831]: loss 0.026281
[epoch13, step832]: loss 0.020952
[epoch13, step833]: loss 0.028677
[epoch13, step834]: loss 0.025063
[epoch13, step835]: loss 0.020474
[epoch13, step836]: loss 0.026350
[epoch13, step837]: loss 0.025133
[epoch13, step838]: loss 0.026000
[epoch13, step839]: loss 0.028029
[epoch13, step840]: loss 0.020365
[epoch13, step841]: loss 0.023323
[epoch13, step842]: loss 0.027155
[epoch13, step843]: loss 0.024257
[epoch13, step844]: loss 0.024164
[epoch13, step845]: loss 0.020605
[epoch13, step846]: loss 0.026117
[epoch13, step847]: loss 0.026375
[epoch13, step848]: loss 0.024234
[epoch13, step849]: loss 0.024271
[epoch13, step850]: loss 0.022279
[epoch13, step851]: loss 0.023832
[epoch13, step852]: loss 0.022389
[epoch13, step853]: loss 0.028729
[epoch13, step854]: loss 0.022723
[epoch13, step855]: loss 0.026619
[epoch13, step856]: loss 0.021239
[epoch13, step857]: loss 0.024508
[epoch13, step858]: loss 0.023714
[epoch13, step859]: loss 0.022980
[epoch13, step860]: loss 0.022742
[epoch13, step861]: loss 0.022628
[epoch13, step862]: loss 0.022323
[epoch13, step863]: loss 0.020570
[epoch13, step864]: loss 0.025916
[epoch13, step865]: loss 0.023020
[epoch13, step866]: loss 0.024533
[epoch13, step867]: loss 0.025064
[epoch13, step868]: loss 0.026092
[epoch13, step869]: loss 0.023378
[epoch13, step870]: loss 0.030192
[epoch13, step871]: loss 0.022400
[epoch13, step872]: loss 0.024946
[epoch13, step873]: loss 0.025070
[epoch13, step874]: loss 0.022879
[epoch13, step875]: loss 0.023439
[epoch13, step876]: loss 0.024083
[epoch13, step877]: loss 0.018966
[epoch13, step878]: loss 0.022779
[epoch13, step879]: loss 0.027657
[epoch13, step880]: loss 0.025323
[epoch13, step881]: loss 0.022209
[epoch13, step882]: loss 0.023078
[epoch13, step883]: loss 0.023183
[epoch13, step884]: loss 0.025850
[epoch13, step885]: loss 0.025132
[epoch13, step886]: loss 0.025927
[epoch13, step887]: loss 0.023938
[epoch13, step888]: loss 0.024089
[epoch13, step889]: loss 0.022323
[epoch13, step890]: loss 0.023714
[epoch13, step891]: loss 0.024585
[epoch13, step892]: loss 0.020247
[epoch13, step893]: loss 0.024386
[epoch13, step894]: loss 0.024779
[epoch13, step895]: loss 0.022116
[epoch13, step896]: loss 0.022725
[epoch13, step897]: loss 0.023641
[epoch13, step898]: loss 0.024797
[epoch13, step899]: loss 0.027482
[epoch13, step900]: loss 0.026249
[epoch13, step901]: loss 0.025121
[epoch13, step902]: loss 0.023407
[epoch13, step903]: loss 0.024203
[epoch13, step904]: loss 0.027410
[epoch13, step905]: loss 0.026810
[epoch13, step906]: loss 0.022289
[epoch13, step907]: loss 0.023472
[epoch13, step908]: loss 0.022967
[epoch13, step909]: loss 0.024854
[epoch13, step910]: loss 0.022898
[epoch13, step911]: loss 0.024456
[epoch13, step912]: loss 0.023447
[epoch13, step913]: loss 0.022837
[epoch13, step914]: loss 0.029583
[epoch13, step915]: loss 0.023613
[epoch13, step916]: loss 0.023304
[epoch13, step917]: loss 0.024463
[epoch13, step918]: loss 0.028277
[epoch13, step919]: loss 0.023291
[epoch13, step920]: loss 0.026972
[epoch13, step921]: loss 0.023308
[epoch13, step922]: loss 0.022578
[epoch13, step923]: loss 0.022848
[epoch13, step924]: loss 0.020940
[epoch13, step925]: loss 0.024250
[epoch13, step926]: loss 0.025747
[epoch13, step927]: loss 0.024844
[epoch13, step928]: loss 0.024614
[epoch13, step929]: loss 0.026793
[epoch13, step930]: loss 0.024641
[epoch13, step931]: loss 0.026091
[epoch13, step932]: loss 0.020984
[epoch13, step933]: loss 0.027735
[epoch13, step934]: loss 0.022469
[epoch13, step935]: loss 0.022407
[epoch13, step936]: loss 0.021861
[epoch13, step937]: loss 0.026292
[epoch13, step938]: loss 0.025672
[epoch13, step939]: loss 0.020846
[epoch13, step940]: loss 0.024111
[epoch13, step941]: loss 0.026231
[epoch13, step942]: loss 0.025061
[epoch13, step943]: loss 0.023012
[epoch13, step944]: loss 0.026521
[epoch13, step945]: loss 0.020385
[epoch13, step946]: loss 0.025274
[epoch13, step947]: loss 0.027409
[epoch13, step948]: loss 0.019714
[epoch13, step949]: loss 0.022780
[epoch13, step950]: loss 0.025932
[epoch13, step951]: loss 0.027922
[epoch13, step952]: loss 0.024278
[epoch13, step953]: loss 0.027103
[epoch13, step954]: loss 0.022058
[epoch13, step955]: loss 0.036488
[epoch13, step956]: loss 0.052600
[epoch13, step957]: loss 0.045150
[epoch13, step958]: loss 0.041540
[epoch13, step959]: loss 0.044557
[epoch13, step960]: loss 0.040535
[epoch13, step961]: loss 0.039431
[epoch13, step962]: loss 0.037366
[epoch13, step963]: loss 0.037310
[epoch13, step964]: loss 0.037576
[epoch13, step965]: loss 0.037843
[epoch13, step966]: loss 0.036251
[epoch13, step967]: loss 0.035678
[epoch13, step968]: loss 0.038681
[epoch13, step969]: loss 0.038595
[epoch13, step970]: loss 0.037537
[epoch13, step971]: loss 0.035929
[epoch13, step972]: loss 0.037951
[epoch13, step973]: loss 0.036744
[epoch13, step974]: loss 0.038649
[epoch13, step975]: loss 0.035080
[epoch13, step976]: loss 0.034277
[epoch13, step977]: loss 0.038578
[epoch13, step978]: loss 0.037063
[epoch13, step979]: loss 0.036003
[epoch13, step980]: loss 0.034961
[epoch13, step981]: loss 0.036714
[epoch13, step982]: loss 0.037171
[epoch13, step983]: loss 0.038294
[epoch13, step984]: loss 0.034644
[epoch13, step985]: loss 0.034669
[epoch13, step986]: loss 0.039198
[epoch13, step987]: loss 0.037082
[epoch13, step988]: loss 0.036507
[epoch13, step989]: loss 0.035657
[epoch13, step990]: loss 0.036151
[epoch13, step991]: loss 0.037243
[epoch13, step992]: loss 0.037635
[epoch13, step993]: loss 0.035082
[epoch13, step994]: loss 0.034340
[epoch13, step995]: loss 0.038188
[epoch13, step996]: loss 0.036422
[epoch13, step997]: loss 0.036230
[epoch13, step998]: loss 0.034938
[epoch13, step999]: loss 0.036460
[epoch13, step1000]: loss 0.036394
[epoch13, step1001]: loss 0.037501
[epoch13, step1002]: loss 0.034809
[epoch13, step1003]: loss 0.034252
[epoch13, step1004]: loss 0.038580
[epoch13, step1005]: loss 0.035590
[epoch13, step1006]: loss 0.036784
[epoch13, step1007]: loss 0.033743
[epoch13, step1008]: loss 0.036364
[epoch13, step1009]: loss 0.035893
[epoch13, step1010]: loss 0.038412
[epoch13, step1011]: loss 0.034383
[epoch13, step1012]: loss 0.034266
[epoch13, step1013]: loss 0.037828
[epoch13, step1014]: loss 0.036724
[epoch13, step1015]: loss 0.036008
[epoch13, step1016]: loss 0.034164
[epoch13, step1017]: loss 0.035937
[epoch13, step1018]: loss 0.036518
[epoch13, step1019]: loss 0.038203
[epoch13, step1020]: loss 0.034288
[epoch13, step1021]: loss 0.034457
[epoch13, step1022]: loss 0.038639
[epoch13, step1023]: loss 0.035912
[epoch13, step1024]: loss 0.036877
[epoch13, step1025]: loss 0.033775
[epoch13, step1026]: loss 0.035414
[epoch13, step1027]: loss 0.035564
[epoch13, step1028]: loss 0.036805
[epoch13, step1029]: loss 0.033919
[epoch13, step1030]: loss 0.033255
[epoch13, step1031]: loss 0.036400
[epoch13, step1032]: loss 0.036722
[epoch13, step1033]: loss 0.035137
[epoch13, step1034]: loss 0.033747
[epoch13, step1035]: loss 0.035216
[epoch13, step1036]: loss 0.036100
[epoch13, step1037]: loss 0.036832
[epoch13, step1038]: loss 0.033505
[epoch13, step1039]: loss 0.034398
[epoch13, step1040]: loss 0.036788
[epoch13, step1041]: loss 0.035599
[epoch13, step1042]: loss 0.035368
[epoch13, step1043]: loss 0.033425
[epoch13, step1044]: loss 0.035742
[epoch13, step1045]: loss 0.035664
[epoch13, step1046]: loss 0.036631
[epoch13, step1047]: loss 0.034766
[epoch13, step1048]: loss 0.033556
[epoch13, step1049]: loss 0.036711
[epoch13, step1050]: loss 0.036115
[epoch13, step1051]: loss 0.035382
[epoch13, step1052]: loss 0.033959
[epoch13, step1053]: loss 0.035696
[epoch13, step1054]: loss 0.035901
[epoch13, step1055]: loss 0.037007
[epoch13, step1056]: loss 0.033782
[epoch13, step1057]: loss 0.034922
[epoch13, step1058]: loss 0.039689
[epoch13, step1059]: loss 0.036523
[epoch13, step1060]: loss 0.035902
[epoch13, step1061]: loss 0.034036
[epoch13, step1062]: loss 0.035986
[epoch13, step1063]: loss 0.035730
[epoch13, step1064]: loss 0.037258
[epoch13, step1065]: loss 0.033728
[epoch13, step1066]: loss 0.033312
[epoch13, step1067]: loss 0.037378
[epoch13, step1068]: loss 0.035326
[epoch13, step1069]: loss 0.034847
[epoch13, step1070]: loss 0.034124
[epoch13, step1071]: loss 0.037148
[epoch13, step1072]: loss 0.037484
[epoch13, step1073]: loss 0.037866
[epoch13, step1074]: loss 0.034878
[epoch13, step1075]: loss 0.033831
[epoch13, step1076]: loss 0.037929
[epoch13, step1077]: loss 0.035941
[epoch13, step1078]: loss 0.035253
[epoch13, step1079]: loss 0.034484
[epoch13, step1080]: loss 0.035799
[epoch13, step1081]: loss 0.035824
[epoch13, step1082]: loss 0.036789
[epoch13, step1083]: loss 0.034432
[epoch13, step1084]: loss 0.033621
[epoch13, step1085]: loss 0.036807
[epoch13, step1086]: loss 0.035392
[epoch13, step1087]: loss 0.035106
[epoch13, step1088]: loss 0.033756
[epoch13, step1089]: loss 0.036140
[epoch13, step1090]: loss 0.036795
[epoch13, step1091]: loss 0.037388
[epoch13, step1092]: loss 0.033816
[epoch13, step1093]: loss 0.034217
[epoch13, step1094]: loss 0.037852
[epoch13, step1095]: loss 0.035373
[epoch13, step1096]: loss 0.035312
[epoch13, step1097]: loss 0.033992
[epoch13, step1098]: loss 0.035140
[epoch13, step1099]: loss 0.035156
[epoch13, step1100]: loss 0.037538
[epoch13, step1101]: loss 0.034537
[epoch13, step1102]: loss 0.033456
[epoch13, step1103]: loss 0.036314
[epoch13, step1104]: loss 0.034963
[epoch13, step1105]: loss 0.035473
[epoch13, step1106]: loss 0.033475
[epoch13, step1107]: loss 0.035243
[epoch13, step1108]: loss 0.035181
[epoch13, step1109]: loss 0.038084
[epoch13, step1110]: loss 0.035068
[epoch13, step1111]: loss 0.033942
[epoch13, step1112]: loss 0.037891
[epoch13, step1113]: loss 0.035392
[epoch13, step1114]: loss 0.035357
[epoch13, step1115]: loss 0.033679
[epoch13, step1116]: loss 0.035867
[epoch13, step1117]: loss 0.036178
[epoch13, step1118]: loss 0.036346
[epoch13, step1119]: loss 0.034961
[epoch13, step1120]: loss 0.033348
[epoch13, step1121]: loss 0.037098
[epoch13, step1122]: loss 0.034859
[epoch13, step1123]: loss 0.034506
[epoch13, step1124]: loss 0.035689
[epoch13, step1125]: loss 0.035867
[epoch13, step1126]: loss 0.037231
[epoch13, step1127]: loss 0.037235
[epoch13, step1128]: loss 0.034254
[epoch13, step1129]: loss 0.034598
[epoch13, step1130]: loss 0.038426
[epoch13, step1131]: loss 0.036186
[epoch13, step1132]: loss 0.035828
[epoch13, step1133]: loss 0.033961
[epoch13, step1134]: loss 0.035405
[epoch13, step1135]: loss 0.036958
[epoch13, step1136]: loss 0.037908
[epoch13, step1137]: loss 0.033875
[epoch13, step1138]: loss 0.033717
[epoch13, step1139]: loss 0.036909
[epoch13, step1140]: loss 0.035536
[epoch13, step1141]: loss 0.034682
[epoch13, step1142]: loss 0.033897
[epoch13, step1143]: loss 0.036273
[epoch13, step1144]: loss 0.035550
[epoch13, step1145]: loss 0.036828
[epoch13, step1146]: loss 0.034231
[epoch13, step1147]: loss 0.034681
[epoch13, step1148]: loss 0.036937
[epoch13, step1149]: loss 0.035554
[epoch13, step1150]: loss 0.034732
[epoch13, step1151]: loss 0.034391
[epoch13, step1152]: loss 0.036123
[epoch13, step1153]: loss 0.035149
[epoch13, step1154]: loss 0.037737
[epoch13, step1155]: loss 0.033716
[epoch13, step1156]: loss 0.033267
[epoch13, step1157]: loss 0.037707
[epoch13, step1158]: loss 0.035612
[epoch13, step1159]: loss 0.035305
[epoch13, step1160]: loss 0.035587
[epoch13, step1161]: loss 0.036694
[epoch13, step1162]: loss 0.035498
[epoch13, step1163]: loss 0.036997
[epoch13, step1164]: loss 0.034522
[epoch13, step1165]: loss 0.034495
[epoch13, step1166]: loss 0.037687
[epoch13, step1167]: loss 0.035586
[epoch13, step1168]: loss 0.035433
[epoch13, step1169]: loss 0.033628
[epoch13, step1170]: loss 0.035025
[epoch13, step1171]: loss 0.035863
[epoch13, step1172]: loss 0.036452
[epoch13, step1173]: loss 0.033903
[epoch13, step1174]: loss 0.034183
[epoch13, step1175]: loss 0.036715
[epoch13, step1176]: loss 0.034766
[epoch13, step1177]: loss 0.035224
[epoch13, step1178]: loss 0.033353
[epoch13, step1179]: loss 0.035979
[epoch13, step1180]: loss 0.035281
[epoch13, step1181]: loss 0.037865
[epoch13, step1182]: loss 0.033766
[epoch13, step1183]: loss 0.033880
[epoch13, step1184]: loss 0.037067
[epoch13, step1185]: loss 0.035580
[epoch13, step1186]: loss 0.035565
[epoch13, step1187]: loss 0.033988
[epoch13, step1188]: loss 0.034965
[epoch13, step1189]: loss 0.035207
[epoch13, step1190]: loss 0.036709
[epoch13, step1191]: loss 0.035544
[epoch13, step1192]: loss 0.033920
[epoch13, step1193]: loss 0.037563
[epoch13, step1194]: loss 0.035431
[epoch13, step1195]: loss 0.035337
[epoch13, step1196]: loss 0.033442
[epoch13, step1197]: loss 0.035613
[epoch13, step1198]: loss 0.036528
[epoch13, step1199]: loss 0.037080
[epoch13, step1200]: loss 0.033588
[epoch13, step1201]: loss 0.033632
[epoch13, step1202]: loss 0.038247
[epoch13, step1203]: loss 0.035547
[epoch13, step1204]: loss 0.034681
[epoch13, step1205]: loss 0.033088
[epoch13, step1206]: loss 0.034941
[epoch13, step1207]: loss 0.036439
[epoch13, step1208]: loss 0.037840
[epoch13, step1209]: loss 0.032342
[epoch13, step1210]: loss 0.035717
[epoch13, step1211]: loss 0.037081
[epoch13, step1212]: loss 0.035743
[epoch13, step1213]: loss 0.036472
[epoch13, step1214]: loss 0.033323
[epoch13, step1215]: loss 0.036637
[epoch13, step1216]: loss 0.036369
[epoch13, step1217]: loss 0.037097
[epoch13, step1218]: loss 0.034411
[epoch13, step1219]: loss 0.034143
[epoch13, step1220]: loss 0.037194
[epoch13, step1221]: loss 0.035955
[epoch13, step1222]: loss 0.035199
[epoch13, step1223]: loss 0.033526
[epoch13, step1224]: loss 0.035786
[epoch13, step1225]: loss 0.035721
[epoch13, step1226]: loss 0.036542
[epoch13, step1227]: loss 0.033800
[epoch13, step1228]: loss 0.033558
[epoch13, step1229]: loss 0.036422
[epoch13, step1230]: loss 0.036001
[epoch13, step1231]: loss 0.035600
[epoch13, step1232]: loss 0.035311
[epoch13, step1233]: loss 0.035514
[epoch13, step1234]: loss 0.035317
[epoch13, step1235]: loss 0.037315
[epoch13, step1236]: loss 0.034387
[epoch13, step1237]: loss 0.033902
[epoch13, step1238]: loss 0.036988
[epoch13, step1239]: loss 0.035898
[epoch13, step1240]: loss 0.035410
[epoch13, step1241]: loss 0.033950
[epoch13, step1242]: loss 0.035440
[epoch13, step1243]: loss 0.035158
[epoch13, step1244]: loss 0.037524
[epoch13, step1245]: loss 0.034595
[epoch13, step1246]: loss 0.033897
[epoch13, step1247]: loss 0.036315
[epoch13, step1248]: loss 0.035834
[epoch13, step1249]: loss 0.035932
[epoch13, step1250]: loss 0.033396
[epoch13, step1251]: loss 0.036299
[epoch13, step1252]: loss 0.036918
[epoch13, step1253]: loss 0.037399
[epoch13, step1254]: loss 0.033659
[epoch13, step1255]: loss 0.033811
[epoch13, step1256]: loss 0.037321
[epoch13, step1257]: loss 0.036014
[epoch13, step1258]: loss 0.035744
[epoch13, step1259]: loss 0.033840
[epoch13, step1260]: loss 0.036037
[epoch13, step1261]: loss 0.035380
[epoch13, step1262]: loss 0.036325
[epoch13, step1263]: loss 0.034909
[epoch13, step1264]: loss 0.034367
[epoch13, step1265]: loss 0.036182
[epoch13, step1266]: loss 0.035048
[epoch13, step1267]: loss 0.035457
[epoch13, step1268]: loss 0.033539
[epoch13, step1269]: loss 0.035116
[epoch13, step1270]: loss 0.035483
[epoch13, step1271]: loss 0.036661
[epoch13, step1272]: loss 0.033834
[epoch13, step1273]: loss 0.034125
[epoch13, step1274]: loss 0.037021
[epoch13, step1275]: loss 0.036423
[epoch13, step1276]: loss 0.035006
[epoch13, step1277]: loss 0.033694
[epoch13, step1278]: loss 0.036364
[epoch13, step1279]: loss 0.036375
[epoch13, step1280]: loss 0.037855
[epoch13, step1281]: loss 0.034261
[epoch13, step1282]: loss 0.033875
[epoch13, step1283]: loss 0.036625
[epoch13, step1284]: loss 0.035341
[epoch13, step1285]: loss 0.035119
[epoch13, step1286]: loss 0.033474
[epoch13, step1287]: loss 0.036371
[epoch13, step1288]: loss 0.036271
[epoch13, step1289]: loss 0.038357
[epoch13, step1290]: loss 0.034216
[epoch13, step1291]: loss 0.033895
[epoch13, step1292]: loss 0.037966
[epoch13, step1293]: loss 0.036051
[epoch13, step1294]: loss 0.036434
[epoch13, step1295]: loss 0.034064
[epoch13, step1296]: loss 0.035889
[epoch13, step1297]: loss 0.036709
[epoch13, step1298]: loss 0.037446
[epoch13, step1299]: loss 0.033952
[epoch13, step1300]: loss 0.033874
[epoch13, step1301]: loss 0.036735
[epoch13, step1302]: loss 0.035375
[epoch13, step1303]: loss 0.035223
[epoch13, step1304]: loss 0.033110
[epoch13, step1305]: loss 0.036149
[epoch13, step1306]: loss 0.035735
[epoch13, step1307]: loss 0.037108
[epoch13, step1308]: loss 0.034562
[epoch13, step1309]: loss 0.033344
[epoch13, step1310]: loss 0.036804
[epoch13, step1311]: loss 0.035306
[epoch13, step1312]: loss 0.036296
[epoch13, step1313]: loss 0.033515
[epoch13, step1314]: loss 0.035310
[epoch13, step1315]: loss 0.035597
[epoch13, step1316]: loss 0.038724
[epoch13, step1317]: loss 0.033464
[epoch13, step1318]: loss 0.033728
[epoch13, step1319]: loss 0.036627
[epoch13, step1320]: loss 0.035170
[epoch13, step1321]: loss 0.034914
[epoch13, step1322]: loss 0.033996
[epoch13, step1323]: loss 0.035660
[epoch13, step1324]: loss 0.035049
[epoch13, step1325]: loss 0.036318
[epoch13, step1326]: loss 0.033904
[epoch13, step1327]: loss 0.033461
[epoch13, step1328]: loss 0.037705
[epoch13, step1329]: loss 0.035208
[epoch13, step1330]: loss 0.035700
[epoch13, step1331]: loss 0.033450
[epoch13, step1332]: loss 0.035580
[epoch13, step1333]: loss 0.035695
[epoch13, step1334]: loss 0.036820
[epoch13, step1335]: loss 0.035502
[epoch13, step1336]: loss 0.033609
[epoch13, step1337]: loss 0.037057
[epoch13, step1338]: loss 0.035950
[epoch13, step1339]: loss 0.035171
[epoch13, step1340]: loss 0.033760
[epoch13, step1341]: loss 0.035857
[epoch13, step1342]: loss 0.035128
[epoch13, step1343]: loss 0.037046
[epoch13, step1344]: loss 0.034118
[epoch13, step1345]: loss 0.033129
[epoch13, step1346]: loss 0.036330
[epoch13, step1347]: loss 0.035956
[epoch13, step1348]: loss 0.034563
[epoch13, step1349]: loss 0.034078
[epoch13, step1350]: loss 0.035843
[epoch13, step1351]: loss 0.035007
[epoch13, step1352]: loss 0.036547
[epoch13, step1353]: loss 0.033662
[epoch13, step1354]: loss 0.033650
[epoch13, step1355]: loss 0.037065
[epoch13, step1356]: loss 0.035114
[epoch13, step1357]: loss 0.035234
[epoch13, step1358]: loss 0.033182
[epoch13, step1359]: loss 0.034841
[epoch13, step1360]: loss 0.035852
[epoch13, step1361]: loss 0.037243
[epoch13, step1362]: loss 0.034430
[epoch13, step1363]: loss 0.033881
[epoch13, step1364]: loss 0.037095
[epoch13, step1365]: loss 0.035150
[epoch13, step1366]: loss 0.034828
[epoch13, step1367]: loss 0.033034
[epoch13, step1368]: loss 0.036414
[epoch13, step1369]: loss 0.035600
[epoch13, step1370]: loss 0.037145
[epoch13, step1371]: loss 0.033925
[epoch13, step1372]: loss 0.032894
[epoch13, step1373]: loss 0.036797
[epoch13, step1374]: loss 0.036127
[epoch13, step1375]: loss 0.036194
[epoch13, step1376]: loss 0.033339
[epoch13, step1377]: loss 0.035775
[epoch13, step1378]: loss 0.035405
[epoch13, step1379]: loss 0.036552
[epoch13, step1380]: loss 0.034024
[epoch13, step1381]: loss 0.033327
[epoch13, step1382]: loss 0.037135
[epoch13, step1383]: loss 0.034874
[epoch13, step1384]: loss 0.035454
[epoch13, step1385]: loss 0.033467
[epoch13, step1386]: loss 0.035549
[epoch13, step1387]: loss 0.036449
[epoch13, step1388]: loss 0.036255
[epoch13, step1389]: loss 0.033546
[epoch13, step1390]: loss 0.033783
[epoch13, step1391]: loss 0.036778
[epoch13, step1392]: loss 0.035862
[epoch13, step1393]: loss 0.036099
[epoch13, step1394]: loss 0.034224
[epoch13, step1395]: loss 0.035929
[epoch13, step1396]: loss 0.036709
[epoch13, step1397]: loss 0.037421
[epoch13, step1398]: loss 0.033611
[epoch13, step1399]: loss 0.034694
[epoch13, step1400]: loss 0.038315
[epoch13, step1401]: loss 0.035998
[epoch13, step1402]: loss 0.035372
[epoch13, step1403]: loss 0.033308
[epoch13, step1404]: loss 0.036424
[epoch13, step1405]: loss 0.035882
[epoch13, step1406]: loss 0.036676
[epoch13, step1407]: loss 0.036083
[epoch13, step1408]: loss 0.032943
[epoch13, step1409]: loss 0.036493
[epoch13, step1410]: loss 0.034809
[epoch13, step1411]: loss 0.034647
[epoch13, step1412]: loss 0.033392
[epoch13, step1413]: loss 0.035006
[epoch13, step1414]: loss 0.035151
[epoch13, step1415]: loss 0.037056
[epoch13, step1416]: loss 0.033938
[epoch13, step1417]: loss 0.034852
[epoch13, step1418]: loss 0.038108
[epoch13, step1419]: loss 0.036085
[epoch13, step1420]: loss 0.035385
[epoch13, step1421]: loss 0.034127
[epoch13, step1422]: loss 0.035597
[epoch13, step1423]: loss 0.034734
[epoch13, step1424]: loss 0.036399
[epoch13, step1425]: loss 0.033482
[epoch13, step1426]: loss 0.033453
[epoch13, step1427]: loss 0.037846
[epoch13, step1428]: loss 0.036567
[epoch13, step1429]: loss 0.034708
[epoch13, step1430]: loss 0.033665
[epoch13, step1431]: loss 0.035320
[epoch13, step1432]: loss 0.035212
[epoch13, step1433]: loss 0.036243
[epoch13, step1434]: loss 0.033652
[epoch13, step1435]: loss 0.034163
[epoch13, step1436]: loss 0.037503
[epoch13, step1437]: loss 0.035595
[epoch13, step1438]: loss 0.036452
[epoch13, step1439]: loss 0.033695
[epoch13, step1440]: loss 0.035150
[epoch13, step1441]: loss 0.036242
[epoch13, step1442]: loss 0.036035
[epoch13, step1443]: loss 0.033614
[epoch13, step1444]: loss 0.032451
[epoch13, step1445]: loss 0.037017
[epoch13, step1446]: loss 0.035245
[epoch13, step1447]: loss 0.035692
[epoch13, step1448]: loss 0.033585
[epoch13, step1449]: loss 0.035039
[epoch13, step1450]: loss 0.035610
[epoch13, step1451]: loss 0.037173
[epoch13, step1452]: loss 0.033637
[epoch13, step1453]: loss 0.035059
[epoch13, step1454]: loss 0.038213
[epoch13, step1455]: loss 0.036284
[epoch13, step1456]: loss 0.035140
[epoch13, step1457]: loss 0.033792
[epoch13, step1458]: loss 0.035203
[epoch13, step1459]: loss 0.035726
[epoch13, step1460]: loss 0.036387
[epoch13, step1461]: loss 0.034235
[epoch13, step1462]: loss 0.034106
[epoch13, step1463]: loss 0.037318
[epoch13, step1464]: loss 0.035677
[epoch13, step1465]: loss 0.034912
[epoch13, step1466]: loss 0.033585
[epoch13, step1467]: loss 0.035588
[epoch13, step1468]: loss 0.035280
[epoch13, step1469]: loss 0.036838
[epoch13, step1470]: loss 0.034578
[epoch13, step1471]: loss 0.033656
[epoch13, step1472]: loss 0.036642
[epoch13, step1473]: loss 0.035357
[epoch13, step1474]: loss 0.035711
[epoch13, step1475]: loss 0.033013
[epoch13, step1476]: loss 0.036241
[epoch13, step1477]: loss 0.035278
[epoch13, step1478]: loss 0.036706
[epoch13, step1479]: loss 0.033709
[epoch13, step1480]: loss 0.033203
[epoch13, step1481]: loss 0.036423
[epoch13, step1482]: loss 0.035447
[epoch13, step1483]: loss 0.035131
[epoch13, step1484]: loss 0.034901
[epoch13, step1485]: loss 0.035977
[epoch13, step1486]: loss 0.034588
[epoch13, step1487]: loss 0.036883
[epoch13, step1488]: loss 0.034614
[epoch13, step1489]: loss 0.033686
[epoch13, step1490]: loss 0.036743
[epoch13, step1491]: loss 0.035156
[epoch13, step1492]: loss 0.034508
[epoch13, step1493]: loss 0.033518
[epoch13, step1494]: loss 0.035284
[epoch13, step1495]: loss 0.035637
[epoch13, step1496]: loss 0.037141
[epoch13, step1497]: loss 0.034165
[epoch13, step1498]: loss 0.033729
[epoch13, step1499]: loss 0.036570
[epoch13, step1500]: loss 0.035394
[epoch13, step1501]: loss 0.034453
[epoch13, step1502]: loss 0.033116
[epoch13, step1503]: loss 0.035481
[epoch13, step1504]: loss 0.034774
[epoch13, step1505]: loss 0.037659
[epoch13, step1506]: loss 0.033127
[epoch13, step1507]: loss 0.034027
[epoch13, step1508]: loss 0.037637
[epoch13, step1509]: loss 0.034699
[epoch13, step1510]: loss 0.034732
[epoch13, step1511]: loss 0.034083
[epoch13, step1512]: loss 0.035565
[epoch13, step1513]: loss 0.035242
[epoch13, step1514]: loss 0.036388
[epoch13, step1515]: loss 0.033869
[epoch13, step1516]: loss 0.033457

[epoch13]: avg loss 0.032664

[epoch14, step1]: loss 0.034952
[epoch14, step2]: loss 0.036335
[epoch14, step3]: loss 0.036244
[epoch14, step4]: loss 0.034316
[epoch14, step5]: loss 0.034096
[epoch14, step6]: loss 0.036670
[epoch14, step7]: loss 0.034690
[epoch14, step8]: loss 0.036698
[epoch14, step9]: loss 0.033072
[epoch14, step10]: loss 0.034796
[epoch14, step11]: loss 0.036770
[epoch14, step12]: loss 0.036758
[epoch14, step13]: loss 0.033826
[epoch14, step14]: loss 0.033438
[epoch14, step15]: loss 0.036341
[epoch14, step16]: loss 0.034756
[epoch14, step17]: loss 0.037087
[epoch14, step18]: loss 0.034358
[epoch14, step19]: loss 0.034098
[epoch14, step20]: loss 0.037153
[epoch14, step21]: loss 0.036599
[epoch14, step22]: loss 0.033997
[epoch14, step23]: loss 0.034571
[epoch14, step24]: loss 0.036933
[epoch14, step25]: loss 0.033702
[epoch14, step26]: loss 0.036275
[epoch14, step27]: loss 0.033032
[epoch14, step28]: loss 0.035136
[epoch14, step29]: loss 0.036851
[epoch14, step30]: loss 0.037836
[epoch14, step31]: loss 0.032987
[epoch14, step32]: loss 0.034663
[epoch14, step33]: loss 0.037008
[epoch14, step34]: loss 0.034486
[epoch14, step35]: loss 0.037211
[epoch14, step36]: loss 0.033769
[epoch14, step37]: loss 0.034465
[epoch14, step38]: loss 0.037698
[epoch14, step39]: loss 0.037117
[epoch14, step40]: loss 0.034002
[epoch14, step41]: loss 0.033594
[epoch14, step42]: loss 0.036761
[epoch14, step43]: loss 0.033714
[epoch14, step44]: loss 0.037607
[epoch14, step45]: loss 0.033664
[epoch14, step46]: loss 0.034457
[epoch14, step47]: loss 0.036056
[epoch14, step48]: loss 0.036315
[epoch14, step49]: loss 0.032909
[epoch14, step50]: loss 0.033838
[epoch14, step51]: loss 0.036450
[epoch14, step52]: loss 0.033857
[epoch14, step53]: loss 0.037246
[epoch14, step54]: loss 0.032939
[epoch14, step55]: loss 0.034217
[epoch14, step56]: loss 0.037584
[epoch14, step57]: loss 0.036685
[epoch14, step58]: loss 0.033909
[epoch14, step59]: loss 0.033748
[epoch14, step60]: loss 0.037521
[epoch14, step61]: loss 0.033896
[epoch14, step62]: loss 0.036364
[epoch14, step63]: loss 0.033777
[epoch14, step64]: loss 0.033648
[epoch14, step65]: loss 0.036806
[epoch14, step66]: loss 0.036248
[epoch14, step67]: loss 0.033793
[epoch14, step68]: loss 0.033921
[epoch14, step69]: loss 0.036939
[epoch14, step70]: loss 0.033511
[epoch14, step71]: loss 0.036095
[epoch14, step72]: loss 0.033614
[epoch14, step73]: loss 0.034199
[epoch14, step74]: loss 0.036493
[epoch14, step75]: loss 0.037230
[epoch14, step76]: loss 0.033886
[epoch14, step77]: loss 0.034472
[epoch14, step78]: loss 0.037420
[epoch14, step79]: loss 0.033296
[epoch14, step80]: loss 0.037500
[epoch14, step81]: loss 0.033276
[epoch14, step82]: loss 0.033875
[epoch14, step83]: loss 0.036700
[epoch14, step84]: loss 0.036264
[epoch14, step85]: loss 0.034696
[epoch14, step86]: loss 0.034220
[epoch14, step87]: loss 0.037806
[epoch14, step88]: loss 0.033397
[epoch14, step89]: loss 0.036632
[epoch14, step90]: loss 0.034576
[epoch14, step91]: loss 0.034006
[epoch14, step92]: loss 0.037021
[epoch14, step93]: loss 0.037131
[epoch14, step94]: loss 0.033139
[epoch14, step95]: loss 0.033613
[epoch14, step96]: loss 0.036284
[epoch14, step97]: loss 0.034428
[epoch14, step98]: loss 0.036197
[epoch14, step99]: loss 0.033954
[epoch14, step100]: loss 0.033205
[epoch14, step101]: loss 0.036998
[epoch14, step102]: loss 0.037610
[epoch14, step103]: loss 0.033658
[epoch14, step104]: loss 0.033013
[epoch14, step105]: loss 0.037096
[epoch14, step106]: loss 0.033765
[epoch14, step107]: loss 0.036554
[epoch14, step108]: loss 0.033518
[epoch14, step109]: loss 0.033401
[epoch14, step110]: loss 0.037057
[epoch14, step111]: loss 0.036408
[epoch14, step112]: loss 0.033339
[epoch14, step113]: loss 0.034368
[epoch14, step114]: loss 0.036578
[epoch14, step115]: loss 0.033553
[epoch14, step116]: loss 0.037667
[epoch14, step117]: loss 0.033406
[epoch14, step118]: loss 0.034649
[epoch14, step119]: loss 0.036623
[epoch14, step120]: loss 0.037372
[epoch14, step121]: loss 0.033364
[epoch14, step122]: loss 0.033308
[epoch14, step123]: loss 0.036760
[epoch14, step124]: loss 0.034285
[epoch14, step125]: loss 0.037192
[epoch14, step126]: loss 0.033675
[epoch14, step127]: loss 0.033912
[epoch14, step128]: loss 0.036566
[epoch14, step129]: loss 0.037058
[epoch14, step130]: loss 0.033868
[epoch14, step131]: loss 0.033377
[epoch14, step132]: loss 0.036496
[epoch14, step133]: loss 0.033556
[epoch14, step134]: loss 0.035960
[epoch14, step135]: loss 0.033979
[epoch14, step136]: loss 0.035948
[epoch14, step137]: loss 0.036770
[epoch14, step138]: loss 0.036391
[epoch14, step139]: loss 0.033660
[epoch14, step140]: loss 0.033656
[epoch14, step141]: loss 0.037119
[epoch14, step142]: loss 0.033487
[epoch14, step143]: loss 0.035925
[epoch14, step144]: loss 0.034688
[epoch14, step145]: loss 0.033691
[epoch14, step146]: loss 0.036597
[epoch14, step147]: loss 0.038224
[epoch14, step148]: loss 0.033145
[epoch14, step149]: loss 0.033160
[epoch14, step150]: loss 0.035994
[epoch14, step151]: loss 0.033782
[epoch14, step152]: loss 0.036840
[epoch14, step153]: loss 0.033330
[epoch14, step154]: loss 0.033824
[epoch14, step155]: loss 0.038085
[epoch14, step156]: loss 0.035822
[epoch14, step157]: loss 0.033297
[epoch14, step158]: loss 0.034309
[epoch14, step159]: loss 0.036487
[epoch14, step160]: loss 0.033638
[epoch14, step161]: loss 0.036574
[epoch14, step162]: loss 0.033730
[epoch14, step163]: loss 0.033758
[epoch14, step164]: loss 0.037243
[epoch14, step165]: loss 0.036803
[epoch14, step166]: loss 0.033965
[epoch14, step167]: loss 0.033984
[epoch14, step168]: loss 0.037543
[epoch14, step169]: loss 0.033477
[epoch14, step170]: loss 0.037451
[epoch14, step171]: loss 0.033715
[epoch14, step172]: loss 0.034018
[epoch14, step173]: loss 0.037124
[epoch14, step174]: loss 0.036024
[epoch14, step175]: loss 0.034161
[epoch14, step176]: loss 0.033710
[epoch14, step177]: loss 0.036585
[epoch14, step178]: loss 0.034045
[epoch14, step179]: loss 0.036120
[epoch14, step180]: loss 0.033188
[epoch14, step181]: loss 0.033743
[epoch14, step182]: loss 0.036421
[epoch14, step183]: loss 0.036915
[epoch14, step184]: loss 0.034702
[epoch14, step185]: loss 0.033931
[epoch14, step186]: loss 0.036785
[epoch14, step187]: loss 0.033595
[epoch14, step188]: loss 0.036437
[epoch14, step189]: loss 0.033761
[epoch14, step190]: loss 0.034173
[epoch14, step191]: loss 0.036543
[epoch14, step192]: loss 0.037179
[epoch14, step193]: loss 0.032887
[epoch14, step194]: loss 0.032484
[epoch14, step195]: loss 0.037031
[epoch14, step196]: loss 0.034233
[epoch14, step197]: loss 0.036281
[epoch14, step198]: loss 0.032908
[epoch14, step199]: loss 0.033709
[epoch14, step200]: loss 0.037233
[epoch14, step201]: loss 0.037034
[epoch14, step202]: loss 0.033144
[epoch14, step203]: loss 0.034450
[epoch14, step204]: loss 0.038219
[epoch14, step205]: loss 0.033919
[epoch14, step206]: loss 0.036070
[epoch14, step207]: loss 0.033351
[epoch14, step208]: loss 0.034836
[epoch14, step209]: loss 0.036682
[epoch14, step210]: loss 0.037756
[epoch14, step211]: loss 0.034087
[epoch14, step212]: loss 0.033793
[epoch14, step213]: loss 0.036805
[epoch14, step214]: loss 0.034021
[epoch14, step215]: loss 0.036586
[epoch14, step216]: loss 0.033742
[epoch14, step217]: loss 0.034164
[epoch14, step218]: loss 0.036820
[epoch14, step219]: loss 0.036419
[epoch14, step220]: loss 0.034116
[epoch14, step221]: loss 0.034335
[epoch14, step222]: loss 0.037658
[epoch14, step223]: loss 0.033868
[epoch14, step224]: loss 0.036614
[epoch14, step225]: loss 0.033670
[epoch14, step226]: loss 0.033431
[epoch14, step227]: loss 0.035755
[epoch14, step228]: loss 0.037071
[epoch14, step229]: loss 0.032713
[epoch14, step230]: loss 0.033561
[epoch14, step231]: loss 0.036994
[epoch14, step232]: loss 0.033795
[epoch14, step233]: loss 0.035790
[epoch14, step234]: loss 0.032996
[epoch14, step235]: loss 0.033932
[epoch14, step236]: loss 0.036526
[epoch14, step237]: loss 0.036413
[epoch14, step238]: loss 0.033283
[epoch14, step239]: loss 0.033278
[epoch14, step240]: loss 0.036247
[epoch14, step241]: loss 0.034200
[epoch14, step242]: loss 0.036864
[epoch14, step243]: loss 0.034878
[epoch14, step244]: loss 0.033180
[epoch14, step245]: loss 0.036457
[epoch14, step246]: loss 0.036217
[epoch14, step247]: loss 0.033904
[epoch14, step248]: loss 0.033143
[epoch14, step249]: loss 0.036040
[epoch14, step250]: loss 0.033926
[epoch14, step251]: loss 0.036743
[epoch14, step252]: loss 0.034367
[epoch14, step253]: loss 0.033454
[epoch14, step254]: loss 0.036297
[epoch14, step255]: loss 0.036667
[epoch14, step256]: loss 0.034108
[epoch14, step257]: loss 0.033287
[epoch14, step258]: loss 0.037765
[epoch14, step259]: loss 0.034511
[epoch14, step260]: loss 0.036069
[epoch14, step261]: loss 0.034346
[epoch14, step262]: loss 0.034207
[epoch14, step263]: loss 0.036440
[epoch14, step264]: loss 0.036029
[epoch14, step265]: loss 0.033356
[epoch14, step266]: loss 0.032993
[epoch14, step267]: loss 0.036297
[epoch14, step268]: loss 0.033898
[epoch14, step269]: loss 0.036206
[epoch14, step270]: loss 0.033850
[epoch14, step271]: loss 0.034158
[epoch14, step272]: loss 0.036158
[epoch14, step273]: loss 0.036350
[epoch14, step274]: loss 0.034566
[epoch14, step275]: loss 0.032691
[epoch14, step276]: loss 0.036639
[epoch14, step277]: loss 0.034415
[epoch14, step278]: loss 0.036126
[epoch14, step279]: loss 0.033021
[epoch14, step280]: loss 0.033996
[epoch14, step281]: loss 0.036415
[epoch14, step282]: loss 0.037755
[epoch14, step283]: loss 0.032910
[epoch14, step284]: loss 0.032972
[epoch14, step285]: loss 0.038003
[epoch14, step286]: loss 0.033845
[epoch14, step287]: loss 0.037130
[epoch14, step288]: loss 0.033352
[epoch14, step289]: loss 0.034853
[epoch14, step290]: loss 0.036363
[epoch14, step291]: loss 0.036387
[epoch14, step292]: loss 0.033464
[epoch14, step293]: loss 0.033103
[epoch14, step294]: loss 0.036103
[epoch14, step295]: loss 0.032901
[epoch14, step296]: loss 0.038234
[epoch14, step297]: loss 0.033535
[epoch14, step298]: loss 0.034454
[epoch14, step299]: loss 0.035838
[epoch14, step300]: loss 0.036686
[epoch14, step301]: loss 0.033576
[epoch14, step302]: loss 0.034123
[epoch14, step303]: loss 0.037023
[epoch14, step304]: loss 0.033471
[epoch14, step305]: loss 0.036129
[epoch14, step306]: loss 0.033732
[epoch14, step307]: loss 0.034054
[epoch14, step308]: loss 0.036987
[epoch14, step309]: loss 0.036523
[epoch14, step310]: loss 0.033351
[epoch14, step311]: loss 0.034204
[epoch14, step312]: loss 0.036767
[epoch14, step313]: loss 0.033568
[epoch14, step314]: loss 0.036553
[epoch14, step315]: loss 0.035294
[epoch14, step316]: loss 0.033138
[epoch14, step317]: loss 0.037429
[epoch14, step318]: loss 0.036476
[epoch14, step319]: loss 0.033147
[epoch14, step320]: loss 0.032625
[epoch14, step321]: loss 0.035675
[epoch14, step322]: loss 0.033495
[epoch14, step323]: loss 0.035360
[epoch14, step324]: loss 0.035346
[epoch14, step325]: loss 0.033870
[epoch14, step326]: loss 0.036066
[epoch14, step327]: loss 0.035600
[epoch14, step328]: loss 0.033591
[epoch14, step329]: loss 0.033084
[epoch14, step330]: loss 0.036116
[epoch14, step331]: loss 0.033974
[epoch14, step332]: loss 0.036355
[epoch14, step333]: loss 0.033567
[epoch14, step334]: loss 0.034036
[epoch14, step335]: loss 0.036638
[epoch14, step336]: loss 0.037382
[epoch14, step337]: loss 0.034448
[epoch14, step338]: loss 0.032722
[epoch14, step339]: loss 0.037005
[epoch14, step340]: loss 0.034253
[epoch14, step341]: loss 0.035549
[epoch14, step342]: loss 0.032949
[epoch14, step343]: loss 0.034253
[epoch14, step344]: loss 0.036044
[epoch14, step345]: loss 0.035835
[epoch14, step346]: loss 0.032843
[epoch14, step347]: loss 0.033852
[epoch14, step348]: loss 0.036782
[epoch14, step349]: loss 0.034967
[epoch14, step350]: loss 0.037186
[epoch14, step351]: loss 0.032550
[epoch14, step352]: loss 0.033254
[epoch14, step353]: loss 0.036251
[epoch14, step354]: loss 0.035607
[epoch14, step355]: loss 0.033020
[epoch14, step356]: loss 0.034518
[epoch14, step357]: loss 0.036226
[epoch14, step358]: loss 0.032724
[epoch14, step359]: loss 0.038455
[epoch14, step360]: loss 0.032370
[epoch14, step361]: loss 0.033492
[epoch14, step362]: loss 0.037262
[epoch14, step363]: loss 0.035644
[epoch14, step364]: loss 0.033269
[epoch14, step365]: loss 0.033221
[epoch14, step366]: loss 0.037012
[epoch14, step367]: loss 0.034027
[epoch14, step368]: loss 0.036527
[epoch14, step369]: loss 0.033488
[epoch14, step370]: loss 0.034743
[epoch14, step371]: loss 0.037106
[epoch14, step372]: loss 0.036196
[epoch14, step373]: loss 0.033395
[epoch14, step374]: loss 0.032854
[epoch14, step375]: loss 0.037259
[epoch14, step376]: loss 0.034064
[epoch14, step377]: loss 0.036139
[epoch14, step378]: loss 0.033809
[epoch14, step379]: loss 0.033889
[epoch14, step380]: loss 0.036973
[epoch14, step381]: loss 0.036091
[epoch14, step382]: loss 0.033834
[epoch14, step383]: loss 0.033002
[epoch14, step384]: loss 0.036578
[epoch14, step385]: loss 0.033246
[epoch14, step386]: loss 0.036038
[epoch14, step387]: loss 0.033403
[epoch14, step388]: loss 0.034981
[epoch14, step389]: loss 0.036384
[epoch14, step390]: loss 0.037847
[epoch14, step391]: loss 0.032751
[epoch14, step392]: loss 0.034066
[epoch14, step393]: loss 0.037218
[epoch14, step394]: loss 0.033580
[epoch14, step395]: loss 0.036475
[epoch14, step396]: loss 0.033246
[epoch14, step397]: loss 0.033697
[epoch14, step398]: loss 0.036376
[epoch14, step399]: loss 0.036018
[epoch14, step400]: loss 0.033119
[epoch14, step401]: loss 0.032825
[epoch14, step402]: loss 0.036484
[epoch14, step403]: loss 0.033318
[epoch14, step404]: loss 0.036494
[epoch14, step405]: loss 0.034050
[epoch14, step406]: loss 0.034233
[epoch14, step407]: loss 0.036448
[epoch14, step408]: loss 0.036488
[epoch14, step409]: loss 0.035477
[epoch14, step410]: loss 0.033596
[epoch14, step411]: loss 0.036642
[epoch14, step412]: loss 0.033891
[epoch14, step413]: loss 0.036438
[epoch14, step414]: loss 0.034317
[epoch14, step415]: loss 0.033829
[epoch14, step416]: loss 0.036436
[epoch14, step417]: loss 0.036171
[epoch14, step418]: loss 0.033809
[epoch14, step419]: loss 0.032192
[epoch14, step420]: loss 0.036396
[epoch14, step421]: loss 0.032973
[epoch14, step422]: loss 0.036283
[epoch14, step423]: loss 0.033374
[epoch14, step424]: loss 0.034196
[epoch14, step425]: loss 0.036592
[epoch14, step426]: loss 0.036650
[epoch14, step427]: loss 0.033759
[epoch14, step428]: loss 0.033623
[epoch14, step429]: loss 0.037293
[epoch14, step430]: loss 0.034012
[epoch14, step431]: loss 0.036835
[epoch14, step432]: loss 0.033508
[epoch14, step433]: loss 0.034267
[epoch14, step434]: loss 0.037070
[epoch14, step435]: loss 0.036958
[epoch14, step436]: loss 0.033070
[epoch14, step437]: loss 0.033848
[epoch14, step438]: loss 0.036440
[epoch14, step439]: loss 0.033770
[epoch14, step440]: loss 0.036220
[epoch14, step441]: loss 0.033257
[epoch14, step442]: loss 0.033098
[epoch14, step443]: loss 0.036889
[epoch14, step444]: loss 0.035755
[epoch14, step445]: loss 0.033465
[epoch14, step446]: loss 0.033887
[epoch14, step447]: loss 0.036870
[epoch14, step448]: loss 0.034422
[epoch14, step449]: loss 0.036275
[epoch14, step450]: loss 0.033646
[epoch14, step451]: loss 0.033569
[epoch14, step452]: loss 0.035806
[epoch14, step453]: loss 0.036386
[epoch14, step454]: loss 0.033448
[epoch14, step455]: loss 0.034549
[epoch14, step456]: loss 0.036518
[epoch14, step457]: loss 0.035006
[epoch14, step458]: loss 0.035719
[epoch14, step459]: loss 0.033891
[epoch14, step460]: loss 0.033582
[epoch14, step461]: loss 0.036711
[epoch14, step462]: loss 0.036329
[epoch14, step463]: loss 0.033939
[epoch14, step464]: loss 0.033563
[epoch14, step465]: loss 0.037641
[epoch14, step466]: loss 0.033940
[epoch14, step467]: loss 0.035792
[epoch14, step468]: loss 0.033472
[epoch14, step469]: loss 0.033839
[epoch14, step470]: loss 0.036656
[epoch14, step471]: loss 0.036541
[epoch14, step472]: loss 0.034216
[epoch14, step473]: loss 0.032986
[epoch14, step474]: loss 0.036025
[epoch14, step475]: loss 0.033923
[epoch14, step476]: loss 0.036866
[epoch14, step477]: loss 0.033430
[epoch14, step478]: loss 0.033458
[epoch14, step479]: loss 0.036560
[epoch14, step480]: loss 0.035893
[epoch14, step481]: loss 0.032996
[epoch14, step482]: loss 0.032456
[epoch14, step483]: loss 0.036521
[epoch14, step484]: loss 0.034267
[epoch14, step485]: loss 0.036541
[epoch14, step486]: loss 0.033732
[epoch14, step487]: loss 0.033050
[epoch14, step488]: loss 0.037024
[epoch14, step489]: loss 0.035735
[epoch14, step490]: loss 0.033996
[epoch14, step491]: loss 0.033496
[epoch14, step492]: loss 0.036155
[epoch14, step493]: loss 0.033192
[epoch14, step494]: loss 0.035745
[epoch14, step495]: loss 0.034424
[epoch14, step496]: loss 0.033963
[epoch14, step497]: loss 0.036478
[epoch14, step498]: loss 0.035927
[epoch14, step499]: loss 0.033491
[epoch14, step500]: loss 0.032995
[epoch14, step501]: loss 0.036189
[epoch14, step502]: loss 0.033016
[epoch14, step503]: loss 0.036465
[epoch14, step504]: loss 0.033978
[epoch14, step505]: loss 0.032995
[epoch14, step506]: loss 0.036713
[epoch14, step507]: loss 0.036915
[epoch14, step508]: loss 0.033872
[epoch14, step509]: loss 0.032969
[epoch14, step510]: loss 0.036528
[epoch14, step511]: loss 0.034062
[epoch14, step512]: loss 0.036726
[epoch14, step513]: loss 0.033946
[epoch14, step514]: loss 0.033678
[epoch14, step515]: loss 0.036498
[epoch14, step516]: loss 0.036010
[epoch14, step517]: loss 0.033178
[epoch14, step518]: loss 0.032996
[epoch14, step519]: loss 0.036485
[epoch14, step520]: loss 0.033442
[epoch14, step521]: loss 0.036147
[epoch14, step522]: loss 0.033118
[epoch14, step523]: loss 0.033248
[epoch14, step524]: loss 0.036560
[epoch14, step525]: loss 0.037223
[epoch14, step526]: loss 0.033717
[epoch14, step527]: loss 0.033031
[epoch14, step528]: loss 0.036631
[epoch14, step529]: loss 0.033243
[epoch14, step530]: loss 0.036793
[epoch14, step531]: loss 0.033623
[epoch14, step532]: loss 0.034257
[epoch14, step533]: loss 0.037043
[epoch14, step534]: loss 0.036033
[epoch14, step535]: loss 0.033985
[epoch14, step536]: loss 0.033334
[epoch14, step537]: loss 0.036071
[epoch14, step538]: loss 0.033767
[epoch14, step539]: loss 0.035715
[epoch14, step540]: loss 0.034003
[epoch14, step541]: loss 0.033167
[epoch14, step542]: loss 0.036375
[epoch14, step543]: loss 0.035614
[epoch14, step544]: loss 0.033333
[epoch14, step545]: loss 0.033104
[epoch14, step546]: loss 0.036874
[epoch14, step547]: loss 0.033621
[epoch14, step548]: loss 0.036939
[epoch14, step549]: loss 0.033643
[epoch14, step550]: loss 0.033547
[epoch14, step551]: loss 0.037924
[epoch14, step552]: loss 0.035659
[epoch14, step553]: loss 0.034103
[epoch14, step554]: loss 0.032981
[epoch14, step555]: loss 0.036027
[epoch14, step556]: loss 0.033359
[epoch14, step557]: loss 0.035472
[epoch14, step558]: loss 0.033455
[epoch14, step559]: loss 0.033240
[epoch14, step560]: loss 0.036781
[epoch14, step561]: loss 0.035956
[epoch14, step562]: loss 0.033136
[epoch14, step563]: loss 0.032283
[epoch14, step564]: loss 0.034447
[epoch14, step565]: loss 0.028284
[epoch14, step566]: loss 0.036744
[epoch14, step567]: loss 0.028167
[epoch14, step568]: loss 0.026400
[epoch14, step569]: loss 0.024601
[epoch14, step570]: loss 0.033238
[epoch14, step571]: loss 0.025910
[epoch14, step572]: loss 0.026532
[epoch14, step573]: loss 0.030218
[epoch14, step574]: loss 0.029460
[epoch14, step575]: loss 0.021600
[epoch14, step576]: loss 0.022756
[epoch14, step577]: loss 0.026503
[epoch14, step578]: loss 0.020162
[epoch14, step579]: loss 0.028981
[epoch14, step580]: loss 0.020468
[epoch14, step581]: loss 0.026349
[epoch14, step582]: loss 0.025096
[epoch14, step583]: loss 0.023417
[epoch14, step584]: loss 0.025262
[epoch14, step585]: loss 0.026572
[epoch14, step586]: loss 0.023139
[epoch14, step587]: loss 0.028787
[epoch14, step588]: loss 0.022980
[epoch14, step589]: loss 0.024231
[epoch14, step590]: loss 0.027929
[epoch14, step591]: loss 0.020871
[epoch14, step592]: loss 0.027129
[epoch14, step593]: loss 0.022997
[epoch14, step594]: loss 0.025200
[epoch14, step595]: loss 0.026380
[epoch14, step596]: loss 0.023533
[epoch14, step597]: loss 0.024608
[epoch14, step598]: loss 0.027382
[epoch14, step599]: loss 0.025006
[epoch14, step600]: loss 0.026278
[epoch14, step601]: loss 0.020306
[epoch14, step602]: loss 0.023200
[epoch14, step603]: loss 0.026176
[epoch14, step604]: loss 0.027024
[epoch14, step605]: loss 0.025237
[epoch14, step606]: loss 0.024641
[epoch14, step607]: loss 0.026262
[epoch14, step608]: loss 0.025286
[epoch14, step609]: loss 0.027024
[epoch14, step610]: loss 0.028073
[epoch14, step611]: loss 0.026465
[epoch14, step612]: loss 0.025146
[epoch14, step613]: loss 0.019854
[epoch14, step614]: loss 0.024645
[epoch14, step615]: loss 0.027747
[epoch14, step616]: loss 0.023813
[epoch14, step617]: loss 0.023042
[epoch14, step618]: loss 0.025368
[epoch14, step619]: loss 0.028435
[epoch14, step620]: loss 0.023634
[epoch14, step621]: loss 0.025696
[epoch14, step622]: loss 0.020371
[epoch14, step623]: loss 0.024879
[epoch14, step624]: loss 0.026101
[epoch14, step625]: loss 0.025439
[epoch14, step626]: loss 0.026992
[epoch14, step627]: loss 0.023549
[epoch14, step628]: loss 0.025395
[epoch14, step629]: loss 0.020575
[epoch14, step630]: loss 0.022194
[epoch14, step631]: loss 0.032267
[epoch14, step632]: loss 0.022235
[epoch14, step633]: loss 0.024205
[epoch14, step634]: loss 0.027584
[epoch14, step635]: loss 0.025068
[epoch14, step636]: loss 0.021001
[epoch14, step637]: loss 0.027185
[epoch14, step638]: loss 0.026755
[epoch14, step639]: loss 0.022567
[epoch14, step640]: loss 0.028936
[epoch14, step641]: loss 0.030601
[epoch14, step642]: loss 0.024127
[epoch14, step643]: loss 0.025046
[epoch14, step644]: loss 0.025915
[epoch14, step645]: loss 0.024096
[epoch14, step646]: loss 0.026318
[epoch14, step647]: loss 0.023103
[epoch14, step648]: loss 0.024316
[epoch14, step649]: loss 0.028471
[epoch14, step650]: loss 0.022171
[epoch14, step651]: loss 0.025844
[epoch14, step652]: loss 0.026023
[epoch14, step653]: loss 0.027229
[epoch14, step654]: loss 0.022069
[epoch14, step655]: loss 0.024234
[epoch14, step656]: loss 0.022345
[epoch14, step657]: loss 0.027900
[epoch14, step658]: loss 0.025952
[epoch14, step659]: loss 0.028119
[epoch14, step660]: loss 0.024142
[epoch14, step661]: loss 0.026416
[epoch14, step662]: loss 0.023306
[epoch14, step663]: loss 0.021422
[epoch14, step664]: loss 0.024855
[epoch14, step665]: loss 0.026781
[epoch14, step666]: loss 0.025770
[epoch14, step667]: loss 0.026322
[epoch14, step668]: loss 0.023456
[epoch14, step669]: loss 0.026384
[epoch14, step670]: loss 0.025918
[epoch14, step671]: loss 0.020875
[epoch14, step672]: loss 0.024113
[epoch14, step673]: loss 0.023070
[epoch14, step674]: loss 0.020587
[epoch14, step675]: loss 0.020251
[epoch14, step676]: loss 0.024079
[epoch14, step677]: loss 0.024961
[epoch14, step678]: loss 0.022742
[epoch14, step679]: loss 0.023487
[epoch14, step680]: loss 0.030263
[epoch14, step681]: loss 0.021192
[epoch14, step682]: loss 0.025444
[epoch14, step683]: loss 0.026481
[epoch14, step684]: loss 0.024922
[epoch14, step685]: loss 0.024273
[epoch14, step686]: loss 0.027054
[epoch14, step687]: loss 0.026587
[epoch14, step688]: loss 0.023205
[epoch14, step689]: loss 0.024681
[epoch14, step690]: loss 0.025489
[epoch14, step691]: loss 0.024408
[epoch14, step692]: loss 0.022573
[epoch14, step693]: loss 0.027065
[epoch14, step694]: loss 0.022125
[epoch14, step695]: loss 0.026345
[epoch14, step696]: loss 0.025416
[epoch14, step697]: loss 0.027615
[epoch14, step698]: loss 0.024670
[epoch14, step699]: loss 0.022945
[epoch14, step700]: loss 0.022233
[epoch14, step701]: loss 0.025851
[epoch14, step702]: loss 0.021869
[epoch14, step703]: loss 0.022891
[epoch14, step704]: loss 0.025080
[epoch14, step705]: loss 0.024182
[epoch14, step706]: loss 0.023163
[epoch14, step707]: loss 0.025383
[epoch14, step708]: loss 0.025220
[epoch14, step709]: loss 0.027473
[epoch14, step710]: loss 0.023151
[epoch14, step711]: loss 0.023815
[epoch14, step712]: loss 0.026335
[epoch14, step713]: loss 0.025793
[epoch14, step714]: loss 0.021175
[epoch14, step715]: loss 0.022504
[epoch14, step716]: loss 0.025759
[epoch14, step717]: loss 0.023089
[epoch14, step718]: loss 0.024664
[epoch14, step719]: loss 0.032989
[epoch14, step720]: loss 0.024048
[epoch14, step721]: loss 0.022656
[epoch14, step722]: loss 0.030007
[epoch14, step723]: loss 0.026225
[epoch14, step724]: loss 0.022053
[epoch14, step725]: loss 0.027614
[epoch14, step726]: loss 0.021797
[epoch14, step727]: loss 0.023698
[epoch14, step728]: loss 0.026146
[epoch14, step729]: loss 0.021294
[epoch14, step730]: loss 0.022368
[epoch14, step731]: loss 0.025100
[epoch14, step732]: loss 0.025313
[epoch14, step733]: loss 0.023458
[epoch14, step734]: loss 0.022091
[epoch14, step735]: loss 0.027648
[epoch14, step736]: loss 0.024943
[epoch14, step737]: loss 0.026116
[epoch14, step738]: loss 0.020193
[epoch14, step739]: loss 0.025541
[epoch14, step740]: loss 0.022170
[epoch14, step741]: loss 0.024819
[epoch14, step742]: loss 0.022172
[epoch14, step743]: loss 0.022397
[epoch14, step744]: loss 0.023082
[epoch14, step745]: loss 0.024301
[epoch14, step746]: loss 0.024492
[epoch14, step747]: loss 0.027004
[epoch14, step748]: loss 0.025172
[epoch14, step749]: loss 0.025808
[epoch14, step750]: loss 0.026989
[epoch14, step751]: loss 0.021236
[epoch14, step752]: loss 0.024273
[epoch14, step753]: loss 0.025096
[epoch14, step754]: loss 0.022102
[epoch14, step755]: loss 0.025668
[epoch14, step756]: loss 0.023239
[epoch14, step757]: loss 0.020148
[epoch14, step758]: loss 0.024304
[epoch14, step759]: loss 0.022255
[epoch14, step760]: loss 0.023741
[epoch14, step761]: loss 0.026707
[epoch14, step762]: loss 0.021166
[epoch14, step763]: loss 0.025147
[epoch14, step764]: loss 0.023334
[epoch14, step765]: loss 0.024814
[epoch14, step766]: loss 0.024149
[epoch14, step767]: loss 0.026662
[epoch14, step768]: loss 0.020170
[epoch14, step769]: loss 0.026331
[epoch14, step770]: loss 0.025444
[epoch14, step771]: loss 0.023067
[epoch14, step772]: loss 0.028095
[epoch14, step773]: loss 0.025990
[epoch14, step774]: loss 0.024390
[epoch14, step775]: loss 0.019876
[epoch14, step776]: loss 0.025060
[epoch14, step777]: loss 0.022046
[epoch14, step778]: loss 0.026764
[epoch14, step779]: loss 0.023308
[epoch14, step780]: loss 0.019737
[epoch14, step781]: loss 0.024137
[epoch14, step782]: loss 0.022118
[epoch14, step783]: loss 0.019219
[epoch14, step784]: loss 0.020536
[epoch14, step785]: loss 0.021315
[epoch14, step786]: loss 0.025096
[epoch14, step787]: loss 0.022704
[epoch14, step788]: loss 0.024723
[epoch14, step789]: loss 0.022661
[epoch14, step790]: loss 0.022449
[epoch14, step791]: loss 0.026735
[epoch14, step792]: loss 0.024664
[epoch14, step793]: loss 0.026492
[epoch14, step794]: loss 0.020271
[epoch14, step795]: loss 0.025144
[epoch14, step796]: loss 0.027743
[epoch14, step797]: loss 0.027101
[epoch14, step798]: loss 0.026251
[epoch14, step799]: loss 0.025122
[epoch14, step800]: loss 0.021173
[epoch14, step801]: loss 0.021761
[epoch14, step802]: loss 0.022329
[epoch14, step803]: loss 0.025804
[epoch14, step804]: loss 0.027495
[epoch14, step805]: loss 0.028204
[epoch14, step806]: loss 0.020486
[epoch14, step807]: loss 0.020354
[epoch14, step808]: loss 0.022627
[epoch14, step809]: loss 0.021970
[epoch14, step810]: loss 0.024901
[epoch14, step811]: loss 0.024631
[epoch14, step812]: loss 0.023709
[epoch14, step813]: loss 0.022827
[epoch14, step814]: loss 0.024878
[epoch14, step815]: loss 0.024317
[epoch14, step816]: loss 0.023354
[epoch14, step817]: loss 0.023894
[epoch14, step818]: loss 0.020927
[epoch14, step819]: loss 0.019763
[epoch14, step820]: loss 0.022925
[epoch14, step821]: loss 0.020705
[epoch14, step822]: loss 0.029670
[epoch14, step823]: loss 0.023692
[epoch14, step824]: loss 0.026611
[epoch14, step825]: loss 0.024833
[epoch14, step826]: loss 0.023872
[epoch14, step827]: loss 0.026265
[epoch14, step828]: loss 0.028400
[epoch14, step829]: loss 0.026616
[epoch14, step830]: loss 0.022207
[epoch14, step831]: loss 0.026447
[epoch14, step832]: loss 0.020499
[epoch14, step833]: loss 0.029502
[epoch14, step834]: loss 0.024898
[epoch14, step835]: loss 0.019992
[epoch14, step836]: loss 0.026471
[epoch14, step837]: loss 0.024906
[epoch14, step838]: loss 0.025828
[epoch14, step839]: loss 0.028432
[epoch14, step840]: loss 0.020357
[epoch14, step841]: loss 0.023199
[epoch14, step842]: loss 0.027415
[epoch14, step843]: loss 0.024291
[epoch14, step844]: loss 0.024308
[epoch14, step845]: loss 0.020484
[epoch14, step846]: loss 0.025648
[epoch14, step847]: loss 0.026475
[epoch14, step848]: loss 0.024352
[epoch14, step849]: loss 0.024466
[epoch14, step850]: loss 0.022247
[epoch14, step851]: loss 0.023373
[epoch14, step852]: loss 0.022210
[epoch14, step853]: loss 0.028621
[epoch14, step854]: loss 0.022840
[epoch14, step855]: loss 0.026459
[epoch14, step856]: loss 0.020997
[epoch14, step857]: loss 0.024856
[epoch14, step858]: loss 0.023998
[epoch14, step859]: loss 0.023084
[epoch14, step860]: loss 0.022348
[epoch14, step861]: loss 0.022709
[epoch14, step862]: loss 0.022345
[epoch14, step863]: loss 0.020387
[epoch14, step864]: loss 0.026057
[epoch14, step865]: loss 0.023254
[epoch14, step866]: loss 0.024535
[epoch14, step867]: loss 0.025214
[epoch14, step868]: loss 0.026091
[epoch14, step869]: loss 0.023381
[epoch14, step870]: loss 0.030430
[epoch14, step871]: loss 0.022814
[epoch14, step872]: loss 0.025202
[epoch14, step873]: loss 0.024975
[epoch14, step874]: loss 0.022908
[epoch14, step875]: loss 0.023505
[epoch14, step876]: loss 0.023811
[epoch14, step877]: loss 0.018940
[epoch14, step878]: loss 0.022866
[epoch14, step879]: loss 0.028228
[epoch14, step880]: loss 0.025219
[epoch14, step881]: loss 0.021718
[epoch14, step882]: loss 0.022987
[epoch14, step883]: loss 0.022970
[epoch14, step884]: loss 0.025725
[epoch14, step885]: loss 0.025316
[epoch14, step886]: loss 0.025849
[epoch14, step887]: loss 0.023887
[epoch14, step888]: loss 0.023948
[epoch14, step889]: loss 0.022222
[epoch14, step890]: loss 0.023657
[epoch14, step891]: loss 0.024497
[epoch14, step892]: loss 0.020143
[epoch14, step893]: loss 0.024114
[epoch14, step894]: loss 0.025005
[epoch14, step895]: loss 0.022162
[epoch14, step896]: loss 0.022134
[epoch14, step897]: loss 0.023505
[epoch14, step898]: loss 0.024710
[epoch14, step899]: loss 0.027517
[epoch14, step900]: loss 0.026615
[epoch14, step901]: loss 0.025351
[epoch14, step902]: loss 0.023239
[epoch14, step903]: loss 0.023775
[epoch14, step904]: loss 0.027504
[epoch14, step905]: loss 0.026929
[epoch14, step906]: loss 0.022054
[epoch14, step907]: loss 0.023511
[epoch14, step908]: loss 0.022388
[epoch14, step909]: loss 0.025042
[epoch14, step910]: loss 0.023105
[epoch14, step911]: loss 0.024364
[epoch14, step912]: loss 0.023718
[epoch14, step913]: loss 0.022841
[epoch14, step914]: loss 0.029488
[epoch14, step915]: loss 0.023537
[epoch14, step916]: loss 0.023352
[epoch14, step917]: loss 0.024612
[epoch14, step918]: loss 0.028186
[epoch14, step919]: loss 0.023209
[epoch14, step920]: loss 0.026920
[epoch14, step921]: loss 0.023516
[epoch14, step922]: loss 0.022851
[epoch14, step923]: loss 0.023337
[epoch14, step924]: loss 0.020755
[epoch14, step925]: loss 0.025036
[epoch14, step926]: loss 0.026447
[epoch14, step927]: loss 0.024577
[epoch14, step928]: loss 0.024795
[epoch14, step929]: loss 0.026934
[epoch14, step930]: loss 0.025421
[epoch14, step931]: loss 0.026193
[epoch14, step932]: loss 0.021347
[epoch14, step933]: loss 0.027979
[epoch14, step934]: loss 0.022445
[epoch14, step935]: loss 0.022804
[epoch14, step936]: loss 0.023013
[epoch14, step937]: loss 0.027736
[epoch14, step938]: loss 0.025501
[epoch14, step939]: loss 0.021290
[epoch14, step940]: loss 0.022346
[epoch14, step941]: loss 0.026106
[epoch14, step942]: loss 0.025227
[epoch14, step943]: loss 0.022416
[epoch14, step944]: loss 0.026576
[epoch14, step945]: loss 0.020597
[epoch14, step946]: loss 0.025010
[epoch14, step947]: loss 0.027860
[epoch14, step948]: loss 0.020607
[epoch14, step949]: loss 0.023087
[epoch14, step950]: loss 0.026048
[epoch14, step951]: loss 0.028307
[epoch14, step952]: loss 0.024668
[epoch14, step953]: loss 0.027088
[epoch14, step954]: loss 0.021717
[epoch14, step955]: loss 0.036590
[epoch14, step956]: loss 0.051959
[epoch14, step957]: loss 0.045289
[epoch14, step958]: loss 0.041281
[epoch14, step959]: loss 0.044283
[epoch14, step960]: loss 0.041287
[epoch14, step961]: loss 0.041275
[epoch14, step962]: loss 0.039520
[epoch14, step963]: loss 0.038838
[epoch14, step964]: loss 0.038665
[epoch14, step965]: loss 0.039886
[epoch14, step966]: loss 0.037207
[epoch14, step967]: loss 0.036953
[epoch14, step968]: loss 0.039648
[epoch14, step969]: loss 0.038854
[epoch14, step970]: loss 0.038233
[epoch14, step971]: loss 0.036446
[epoch14, step972]: loss 0.038100
[epoch14, step973]: loss 0.037252
[epoch14, step974]: loss 0.039803
[epoch14, step975]: loss 0.035840
[epoch14, step976]: loss 0.035455
[epoch14, step977]: loss 0.039189
[epoch14, step978]: loss 0.037966
[epoch14, step979]: loss 0.036953
[epoch14, step980]: loss 0.035474
[epoch14, step981]: loss 0.037278
[epoch14, step982]: loss 0.037317
[epoch14, step983]: loss 0.038909
[epoch14, step984]: loss 0.035226
[epoch14, step985]: loss 0.034992
[epoch14, step986]: loss 0.039264
[epoch14, step987]: loss 0.037438
[epoch14, step988]: loss 0.037336
[epoch14, step989]: loss 0.036431
[epoch14, step990]: loss 0.036694
[epoch14, step991]: loss 0.037651
[epoch14, step992]: loss 0.038240
[epoch14, step993]: loss 0.035674
[epoch14, step994]: loss 0.034751
[epoch14, step995]: loss 0.038636
[epoch14, step996]: loss 0.036887
[epoch14, step997]: loss 0.036782
[epoch14, step998]: loss 0.035551
[epoch14, step999]: loss 0.036928
[epoch14, step1000]: loss 0.036511
[epoch14, step1001]: loss 0.038139
[epoch14, step1002]: loss 0.035158
[epoch14, step1003]: loss 0.034834
[epoch14, step1004]: loss 0.038646
[epoch14, step1005]: loss 0.036054
[epoch14, step1006]: loss 0.036905
[epoch14, step1007]: loss 0.034229
[epoch14, step1008]: loss 0.036447
[epoch14, step1009]: loss 0.036234
[epoch14, step1010]: loss 0.038945
[epoch14, step1011]: loss 0.034828
[epoch14, step1012]: loss 0.035105
[epoch14, step1013]: loss 0.038153
[epoch14, step1014]: loss 0.037012
[epoch14, step1015]: loss 0.036414
[epoch14, step1016]: loss 0.034692
[epoch14, step1017]: loss 0.036452
[epoch14, step1018]: loss 0.036538
[epoch14, step1019]: loss 0.037660
[epoch14, step1020]: loss 0.034541
[epoch14, step1021]: loss 0.034523
[epoch14, step1022]: loss 0.038174
[epoch14, step1023]: loss 0.036028
[epoch14, step1024]: loss 0.036654
[epoch14, step1025]: loss 0.033988
[epoch14, step1026]: loss 0.035705
[epoch14, step1027]: loss 0.035979
[epoch14, step1028]: loss 0.037392
[epoch14, step1029]: loss 0.034370
[epoch14, step1030]: loss 0.033719
[epoch14, step1031]: loss 0.036626
[epoch14, step1032]: loss 0.036988
[epoch14, step1033]: loss 0.035817
[epoch14, step1034]: loss 0.034232
[epoch14, step1035]: loss 0.035531
[epoch14, step1036]: loss 0.036422
[epoch14, step1037]: loss 0.037047
[epoch14, step1038]: loss 0.034230
[epoch14, step1039]: loss 0.034827
[epoch14, step1040]: loss 0.037183
[epoch14, step1041]: loss 0.035939
[epoch14, step1042]: loss 0.035012
[epoch14, step1043]: loss 0.034057
[epoch14, step1044]: loss 0.036225
[epoch14, step1045]: loss 0.035899
[epoch14, step1046]: loss 0.037459
[epoch14, step1047]: loss 0.034790
[epoch14, step1048]: loss 0.033878
[epoch14, step1049]: loss 0.037398
[epoch14, step1050]: loss 0.036657
[epoch14, step1051]: loss 0.036209
[epoch14, step1052]: loss 0.034854
[epoch14, step1053]: loss 0.036390
[epoch14, step1054]: loss 0.036542
[epoch14, step1055]: loss 0.036797
[epoch14, step1056]: loss 0.034287
[epoch14, step1057]: loss 0.034961
[epoch14, step1058]: loss 0.038517
[epoch14, step1059]: loss 0.036399
[epoch14, step1060]: loss 0.035976
[epoch14, step1061]: loss 0.034111
[epoch14, step1062]: loss 0.036132
[epoch14, step1063]: loss 0.036038
[epoch14, step1064]: loss 0.037836
[epoch14, step1065]: loss 0.034627
[epoch14, step1066]: loss 0.034233
[epoch14, step1067]: loss 0.037867
[epoch14, step1068]: loss 0.035162
[epoch14, step1069]: loss 0.035276
[epoch14, step1070]: loss 0.034008
[epoch14, step1071]: loss 0.036908
[epoch14, step1072]: loss 0.037247
[epoch14, step1073]: loss 0.037334
[epoch14, step1074]: loss 0.034514
[epoch14, step1075]: loss 0.034531
[epoch14, step1076]: loss 0.037850
[epoch14, step1077]: loss 0.036161
[epoch14, step1078]: loss 0.035704
[epoch14, step1079]: loss 0.035176
[epoch14, step1080]: loss 0.036182
[epoch14, step1081]: loss 0.036102
[epoch14, step1082]: loss 0.037600
[epoch14, step1083]: loss 0.035163
[epoch14, step1084]: loss 0.034775
[epoch14, step1085]: loss 0.037561
[epoch14, step1086]: loss 0.035421
[epoch14, step1087]: loss 0.035710
[epoch14, step1088]: loss 0.033972
[epoch14, step1089]: loss 0.036036
[epoch14, step1090]: loss 0.037001
[epoch14, step1091]: loss 0.037112
[epoch14, step1092]: loss 0.034157
[epoch14, step1093]: loss 0.034117
[epoch14, step1094]: loss 0.036907
[epoch14, step1095]: loss 0.035343
[epoch14, step1096]: loss 0.035204
[epoch14, step1097]: loss 0.033941
[epoch14, step1098]: loss 0.035829
[epoch14, step1099]: loss 0.035545
[epoch14, step1100]: loss 0.037610
[epoch14, step1101]: loss 0.034729
[epoch14, step1102]: loss 0.033859
[epoch14, step1103]: loss 0.036617
[epoch14, step1104]: loss 0.035673
[epoch14, step1105]: loss 0.035852
[epoch14, step1106]: loss 0.033570
[epoch14, step1107]: loss 0.035993
[epoch14, step1108]: loss 0.035427
[epoch14, step1109]: loss 0.038180
[epoch14, step1110]: loss 0.035406
[epoch14, step1111]: loss 0.035339
[epoch14, step1112]: loss 0.038522
[epoch14, step1113]: loss 0.036080
[epoch14, step1114]: loss 0.036045
[epoch14, step1115]: loss 0.034388
[epoch14, step1116]: loss 0.035908
[epoch14, step1117]: loss 0.036535
[epoch14, step1118]: loss 0.036748
[epoch14, step1119]: loss 0.034877
[epoch14, step1120]: loss 0.034097
[epoch14, step1121]: loss 0.037472
[epoch14, step1122]: loss 0.035592
[epoch14, step1123]: loss 0.035240
[epoch14, step1124]: loss 0.035087
[epoch14, step1125]: loss 0.036348
[epoch14, step1126]: loss 0.036781
[epoch14, step1127]: loss 0.037534
[epoch14, step1128]: loss 0.034621
[epoch14, step1129]: loss 0.034201
[epoch14, step1130]: loss 0.038611
[epoch14, step1131]: loss 0.036006
[epoch14, step1132]: loss 0.036226
[epoch14, step1133]: loss 0.033931
[epoch14, step1134]: loss 0.035426
[epoch14, step1135]: loss 0.036916
[epoch14, step1136]: loss 0.037345
[epoch14, step1137]: loss 0.034166
[epoch14, step1138]: loss 0.034249
[epoch14, step1139]: loss 0.037215
[epoch14, step1140]: loss 0.035653
[epoch14, step1141]: loss 0.035075
[epoch14, step1142]: loss 0.034010
[epoch14, step1143]: loss 0.035807
[epoch14, step1144]: loss 0.035913
[epoch14, step1145]: loss 0.036281
[epoch14, step1146]: loss 0.033862
[epoch14, step1147]: loss 0.035964
[epoch14, step1148]: loss 0.037060
[epoch14, step1149]: loss 0.035334
[epoch14, step1150]: loss 0.035335
[epoch14, step1151]: loss 0.034921
[epoch14, step1152]: loss 0.036208
[epoch14, step1153]: loss 0.035324
[epoch14, step1154]: loss 0.037592
[epoch14, step1155]: loss 0.034288
[epoch14, step1156]: loss 0.033688
[epoch14, step1157]: loss 0.037242
[epoch14, step1158]: loss 0.035733
[epoch14, step1159]: loss 0.035423
[epoch14, step1160]: loss 0.035244
[epoch14, step1161]: loss 0.036090
[epoch14, step1162]: loss 0.035729
[epoch14, step1163]: loss 0.036717
[epoch14, step1164]: loss 0.034453
[epoch14, step1165]: loss 0.034960
[epoch14, step1166]: loss 0.037656
[epoch14, step1167]: loss 0.034861
[epoch14, step1168]: loss 0.035521
[epoch14, step1169]: loss 0.033899
[epoch14, step1170]: loss 0.035533
[epoch14, step1171]: loss 0.036060
[epoch14, step1172]: loss 0.036491
[epoch14, step1173]: loss 0.033996
[epoch14, step1174]: loss 0.034188
[epoch14, step1175]: loss 0.036841
[epoch14, step1176]: loss 0.034940
[epoch14, step1177]: loss 0.035236
[epoch14, step1178]: loss 0.033737
[epoch14, step1179]: loss 0.035918
[epoch14, step1180]: loss 0.035551
[epoch14, step1181]: loss 0.037783
[epoch14, step1182]: loss 0.033510
[epoch14, step1183]: loss 0.034197
[epoch14, step1184]: loss 0.036820
[epoch14, step1185]: loss 0.035575
[epoch14, step1186]: loss 0.034760
[epoch14, step1187]: loss 0.033784
[epoch14, step1188]: loss 0.035005
[epoch14, step1189]: loss 0.035246
[epoch14, step1190]: loss 0.036705
[epoch14, step1191]: loss 0.034601
[epoch14, step1192]: loss 0.034002
[epoch14, step1193]: loss 0.037524
[epoch14, step1194]: loss 0.035235
[epoch14, step1195]: loss 0.034884
[epoch14, step1196]: loss 0.033426
[epoch14, step1197]: loss 0.035620
[epoch14, step1198]: loss 0.037093
[epoch14, step1199]: loss 0.037101
[epoch14, step1200]: loss 0.033410
[epoch14, step1201]: loss 0.034003
[epoch14, step1202]: loss 0.038469
[epoch14, step1203]: loss 0.035393
[epoch14, step1204]: loss 0.034863
[epoch14, step1205]: loss 0.034081
[epoch14, step1206]: loss 0.035574
[epoch14, step1207]: loss 0.036002
[epoch14, step1208]: loss 0.037900
[epoch14, step1209]: loss 0.033546
[epoch14, step1210]: loss 0.034419
[epoch14, step1211]: loss 0.037292
[epoch14, step1212]: loss 0.035485
[epoch14, step1213]: loss 0.035519
[epoch14, step1214]: loss 0.033873
[epoch14, step1215]: loss 0.037045
[epoch14, step1216]: loss 0.035514
[epoch14, step1217]: loss 0.037424
[epoch14, step1218]: loss 0.033383
[epoch14, step1219]: loss 0.034401
[epoch14, step1220]: loss 0.037123
[epoch14, step1221]: loss 0.035033
[epoch14, step1222]: loss 0.035136
[epoch14, step1223]: loss 0.034632
[epoch14, step1224]: loss 0.036462
[epoch14, step1225]: loss 0.035563
[epoch14, step1226]: loss 0.037198
[epoch14, step1227]: loss 0.034676
[epoch14, step1228]: loss 0.033714
[epoch14, step1229]: loss 0.036725
[epoch14, step1230]: loss 0.035563
[epoch14, step1231]: loss 0.035196
[epoch14, step1232]: loss 0.035868
[epoch14, step1233]: loss 0.035205
[epoch14, step1234]: loss 0.035300
[epoch14, step1235]: loss 0.037327
[epoch14, step1236]: loss 0.034598
[epoch14, step1237]: loss 0.034377
[epoch14, step1238]: loss 0.036938
[epoch14, step1239]: loss 0.036264
[epoch14, step1240]: loss 0.036557
[epoch14, step1241]: loss 0.035383
[epoch14, step1242]: loss 0.035804
[epoch14, step1243]: loss 0.035409
[epoch14, step1244]: loss 0.036868
[epoch14, step1245]: loss 0.034369
[epoch14, step1246]: loss 0.034189
[epoch14, step1247]: loss 0.036266
[epoch14, step1248]: loss 0.036534
[epoch14, step1249]: loss 0.036244
[epoch14, step1250]: loss 0.033861
[epoch14, step1251]: loss 0.037206
[epoch14, step1252]: loss 0.037889
[epoch14, step1253]: loss 0.036868
[epoch14, step1254]: loss 0.033907
[epoch14, step1255]: loss 0.033767
[epoch14, step1256]: loss 0.037219
[epoch14, step1257]: loss 0.036107
[epoch14, step1258]: loss 0.035347
[epoch14, step1259]: loss 0.034228
[epoch14, step1260]: loss 0.035635
[epoch14, step1261]: loss 0.035400
[epoch14, step1262]: loss 0.036634
[epoch14, step1263]: loss 0.034479
[epoch14, step1264]: loss 0.034024
[epoch14, step1265]: loss 0.036287
[epoch14, step1266]: loss 0.035159
[epoch14, step1267]: loss 0.035648
[epoch14, step1268]: loss 0.034321
[epoch14, step1269]: loss 0.035659
[epoch14, step1270]: loss 0.034897
[epoch14, step1271]: loss 0.037010
[epoch14, step1272]: loss 0.034018
[epoch14, step1273]: loss 0.033561
[epoch14, step1274]: loss 0.036900
[epoch14, step1275]: loss 0.035560
[epoch14, step1276]: loss 0.035022
[epoch14, step1277]: loss 0.033902
[epoch14, step1278]: loss 0.035631
[epoch14, step1279]: loss 0.036016
[epoch14, step1280]: loss 0.037249
[epoch14, step1281]: loss 0.033933
[epoch14, step1282]: loss 0.034321
[epoch14, step1283]: loss 0.036159
[epoch14, step1284]: loss 0.035002
[epoch14, step1285]: loss 0.035637
[epoch14, step1286]: loss 0.033547
[epoch14, step1287]: loss 0.037356
[epoch14, step1288]: loss 0.036808
[epoch14, step1289]: loss 0.038093
[epoch14, step1290]: loss 0.034399
[epoch14, step1291]: loss 0.034183
[epoch14, step1292]: loss 0.038060
[epoch14, step1293]: loss 0.035635
[epoch14, step1294]: loss 0.036174
[epoch14, step1295]: loss 0.035047
[epoch14, step1296]: loss 0.035970
[epoch14, step1297]: loss 0.036421
[epoch14, step1298]: loss 0.037707
[epoch14, step1299]: loss 0.034168
[epoch14, step1300]: loss 0.034537
[epoch14, step1301]: loss 0.036905
[epoch14, step1302]: loss 0.035515
[epoch14, step1303]: loss 0.035413
[epoch14, step1304]: loss 0.033486
[epoch14, step1305]: loss 0.036340
[epoch14, step1306]: loss 0.036030
[epoch14, step1307]: loss 0.036604
[epoch14, step1308]: loss 0.034331
[epoch14, step1309]: loss 0.033398
[epoch14, step1310]: loss 0.036945
[epoch14, step1311]: loss 0.034963
[epoch14, step1312]: loss 0.036280
[epoch14, step1313]: loss 0.033889
[epoch14, step1314]: loss 0.035263
[epoch14, step1315]: loss 0.035633
[epoch14, step1316]: loss 0.038044
[epoch14, step1317]: loss 0.033818
[epoch14, step1318]: loss 0.033491
[epoch14, step1319]: loss 0.036710
[epoch14, step1320]: loss 0.035297
[epoch14, step1321]: loss 0.035282
[epoch14, step1322]: loss 0.034020
[epoch14, step1323]: loss 0.035626
[epoch14, step1324]: loss 0.035094
[epoch14, step1325]: loss 0.036333
[epoch14, step1326]: loss 0.033738
[epoch14, step1327]: loss 0.033290
[epoch14, step1328]: loss 0.037239
[epoch14, step1329]: loss 0.035091
[epoch14, step1330]: loss 0.035567
[epoch14, step1331]: loss 0.033649
[epoch14, step1332]: loss 0.035447
[epoch14, step1333]: loss 0.035235
[epoch14, step1334]: loss 0.037026
[epoch14, step1335]: loss 0.035270
[epoch14, step1336]: loss 0.033837
[epoch14, step1337]: loss 0.036745
[epoch14, step1338]: loss 0.035655
[epoch14, step1339]: loss 0.035264
[epoch14, step1340]: loss 0.033705
[epoch14, step1341]: loss 0.035706
[epoch14, step1342]: loss 0.035196
[epoch14, step1343]: loss 0.036843
[epoch14, step1344]: loss 0.033912
[epoch14, step1345]: loss 0.033430
[epoch14, step1346]: loss 0.036327
[epoch14, step1347]: loss 0.035741
[epoch14, step1348]: loss 0.034470
[epoch14, step1349]: loss 0.034143
[epoch14, step1350]: loss 0.036380
[epoch14, step1351]: loss 0.035079
[epoch14, step1352]: loss 0.036627
[epoch14, step1353]: loss 0.033597
[epoch14, step1354]: loss 0.033507
[epoch14, step1355]: loss 0.037227
[epoch14, step1356]: loss 0.035006
[epoch14, step1357]: loss 0.035353
[epoch14, step1358]: loss 0.033194
[epoch14, step1359]: loss 0.034789
[epoch14, step1360]: loss 0.036012
[epoch14, step1361]: loss 0.036686
[epoch14, step1362]: loss 0.034277
[epoch14, step1363]: loss 0.033882
[epoch14, step1364]: loss 0.036737
[epoch14, step1365]: loss 0.035244
[epoch14, step1366]: loss 0.035172
[epoch14, step1367]: loss 0.033048
[epoch14, step1368]: loss 0.036149
[epoch14, step1369]: loss 0.035611
[epoch14, step1370]: loss 0.036612
[epoch14, step1371]: loss 0.033915
[epoch14, step1372]: loss 0.033287
[epoch14, step1373]: loss 0.036488
[epoch14, step1374]: loss 0.035677
[epoch14, step1375]: loss 0.036076
[epoch14, step1376]: loss 0.033300
[epoch14, step1377]: loss 0.035262
[epoch14, step1378]: loss 0.035109
[epoch14, step1379]: loss 0.036207
[epoch14, step1380]: loss 0.034018
[epoch14, step1381]: loss 0.033192
[epoch14, step1382]: loss 0.036682
[epoch14, step1383]: loss 0.034577
[epoch14, step1384]: loss 0.035289
[epoch14, step1385]: loss 0.032903
[epoch14, step1386]: loss 0.035153
[epoch14, step1387]: loss 0.035985
[epoch14, step1388]: loss 0.035413
[epoch14, step1389]: loss 0.032834
[epoch14, step1390]: loss 0.034224
[epoch14, step1391]: loss 0.035948
[epoch14, step1392]: loss 0.034869
[epoch14, step1393]: loss 0.035048
[epoch14, step1394]: loss 0.034137
[epoch14, step1395]: loss 0.035029
[epoch14, step1396]: loss 0.035159
[epoch14, step1397]: loss 0.036608
[epoch14, step1398]: loss 0.033686
[epoch14, step1399]: loss 0.033896
[epoch14, step1400]: loss 0.036975
[epoch14, step1401]: loss 0.034815
[epoch14, step1402]: loss 0.035138
[epoch14, step1403]: loss 0.032676
[epoch14, step1404]: loss 0.034749
[epoch14, step1405]: loss 0.034666
[epoch14, step1406]: loss 0.037155
[epoch14, step1407]: loss 0.037760
[epoch14, step1408]: loss 0.033340
[epoch14, step1409]: loss 0.036898
[epoch14, step1410]: loss 0.034631
[epoch14, step1411]: loss 0.034218
[epoch14, step1412]: loss 0.032954
[epoch14, step1413]: loss 0.034806
[epoch14, step1414]: loss 0.034980
[epoch14, step1415]: loss 0.036107
[epoch14, step1416]: loss 0.033956
[epoch14, step1417]: loss 0.033851
[epoch14, step1418]: loss 0.036648
[epoch14, step1419]: loss 0.035323
[epoch14, step1420]: loss 0.035070
[epoch14, step1421]: loss 0.033695
[epoch14, step1422]: loss 0.035361
[epoch14, step1423]: loss 0.034561
[epoch14, step1424]: loss 0.036604
[epoch14, step1425]: loss 0.033715
[epoch14, step1426]: loss 0.033399
[epoch14, step1427]: loss 0.037576
[epoch14, step1428]: loss 0.036029
[epoch14, step1429]: loss 0.034947
[epoch14, step1430]: loss 0.033481
[epoch14, step1431]: loss 0.035220
[epoch14, step1432]: loss 0.034807
[epoch14, step1433]: loss 0.036063
[epoch14, step1434]: loss 0.033341
[epoch14, step1435]: loss 0.033797
[epoch14, step1436]: loss 0.036972
[epoch14, step1437]: loss 0.034999
[epoch14, step1438]: loss 0.036020
[epoch14, step1439]: loss 0.033195
[epoch14, step1440]: loss 0.034850
[epoch14, step1441]: loss 0.035353
[epoch14, step1442]: loss 0.035842
[epoch14, step1443]: loss 0.033568
[epoch14, step1444]: loss 0.032764
[epoch14, step1445]: loss 0.036435
[epoch14, step1446]: loss 0.034724
[epoch14, step1447]: loss 0.036380
[epoch14, step1448]: loss 0.033473
[epoch14, step1449]: loss 0.034676
[epoch14, step1450]: loss 0.034948
[epoch14, step1451]: loss 0.036118
[epoch14, step1452]: loss 0.033496
[epoch14, step1453]: loss 0.034092
[epoch14, step1454]: loss 0.036878
[epoch14, step1455]: loss 0.035805
[epoch14, step1456]: loss 0.035308
[epoch14, step1457]: loss 0.033470
[epoch14, step1458]: loss 0.035244
[epoch14, step1459]: loss 0.035489
[epoch14, step1460]: loss 0.036332
[epoch14, step1461]: loss 0.033831
[epoch14, step1462]: loss 0.034201
[epoch14, step1463]: loss 0.036676
[epoch14, step1464]: loss 0.034931
[epoch14, step1465]: loss 0.034334
[epoch14, step1466]: loss 0.032993
[epoch14, step1467]: loss 0.034846
[epoch14, step1468]: loss 0.034812
[epoch14, step1469]: loss 0.036114
[epoch14, step1470]: loss 0.033721
[epoch14, step1471]: loss 0.033581
[epoch14, step1472]: loss 0.036803
[epoch14, step1473]: loss 0.034783
[epoch14, step1474]: loss 0.036161
[epoch14, step1475]: loss 0.032803
[epoch14, step1476]: loss 0.036452
[epoch14, step1477]: loss 0.034819
[epoch14, step1478]: loss 0.036111
[epoch14, step1479]: loss 0.033540
[epoch14, step1480]: loss 0.032876
[epoch14, step1481]: loss 0.035747
[epoch14, step1482]: loss 0.034575
[epoch14, step1483]: loss 0.034601
[epoch14, step1484]: loss 0.034439
[epoch14, step1485]: loss 0.035275
[epoch14, step1486]: loss 0.034103
[epoch14, step1487]: loss 0.036312
[epoch14, step1488]: loss 0.033372
[epoch14, step1489]: loss 0.033496
[epoch14, step1490]: loss 0.036964
[epoch14, step1491]: loss 0.035146
[epoch14, step1492]: loss 0.034641
[epoch14, step1493]: loss 0.033421
[epoch14, step1494]: loss 0.034945
[epoch14, step1495]: loss 0.035526
[epoch14, step1496]: loss 0.036579
[epoch14, step1497]: loss 0.034233
[epoch14, step1498]: loss 0.033771
[epoch14, step1499]: loss 0.035526
[epoch14, step1500]: loss 0.035253
[epoch14, step1501]: loss 0.034495
[epoch14, step1502]: loss 0.032677
[epoch14, step1503]: loss 0.035204
[epoch14, step1504]: loss 0.034547
[epoch14, step1505]: loss 0.036853
[epoch14, step1506]: loss 0.033116
[epoch14, step1507]: loss 0.033354
[epoch14, step1508]: loss 0.037080
[epoch14, step1509]: loss 0.034399
[epoch14, step1510]: loss 0.034655
[epoch14, step1511]: loss 0.034035
[epoch14, step1512]: loss 0.035190
[epoch14, step1513]: loss 0.034159
[epoch14, step1514]: loss 0.035907
[epoch14, step1515]: loss 0.033969
[epoch14, step1516]: loss 0.033170

[epoch14]: avg loss 0.032548

[epoch15, step1]: loss 0.031198
[epoch15, step2]: loss 0.035804
[epoch15, step3]: loss 0.035893
[epoch15, step4]: loss 0.034058
[epoch15, step5]: loss 0.033610
[epoch15, step6]: loss 0.036398
[epoch15, step7]: loss 0.034094
[epoch15, step8]: loss 0.036449
[epoch15, step9]: loss 0.033028
[epoch15, step10]: loss 0.034903
[epoch15, step11]: loss 0.036585
[epoch15, step12]: loss 0.036167
[epoch15, step13]: loss 0.033673
[epoch15, step14]: loss 0.033065
[epoch15, step15]: loss 0.036161
[epoch15, step16]: loss 0.034758
[epoch15, step17]: loss 0.037306
[epoch15, step18]: loss 0.033864
[epoch15, step19]: loss 0.033703
[epoch15, step20]: loss 0.036394
[epoch15, step21]: loss 0.036138
[epoch15, step22]: loss 0.033637
[epoch15, step23]: loss 0.034251
[epoch15, step24]: loss 0.036602
[epoch15, step25]: loss 0.033323
[epoch15, step26]: loss 0.036385
[epoch15, step27]: loss 0.032657
[epoch15, step28]: loss 0.036111
[epoch15, step29]: loss 0.036756
[epoch15, step30]: loss 0.037801
[epoch15, step31]: loss 0.033188
[epoch15, step32]: loss 0.033817
[epoch15, step33]: loss 0.036446
[epoch15, step34]: loss 0.033677
[epoch15, step35]: loss 0.036982
[epoch15, step36]: loss 0.033775
[epoch15, step37]: loss 0.034067
[epoch15, step38]: loss 0.037119
[epoch15, step39]: loss 0.037076
[epoch15, step40]: loss 0.033780
[epoch15, step41]: loss 0.033526
[epoch15, step42]: loss 0.036560
[epoch15, step43]: loss 0.033069
[epoch15, step44]: loss 0.038014
[epoch15, step45]: loss 0.034043
[epoch15, step46]: loss 0.034029
[epoch15, step47]: loss 0.035824
[epoch15, step48]: loss 0.035873
[epoch15, step49]: loss 0.032648
[epoch15, step50]: loss 0.033721
[epoch15, step51]: loss 0.036134
[epoch15, step52]: loss 0.033834
[epoch15, step53]: loss 0.037487
[epoch15, step54]: loss 0.032829
[epoch15, step55]: loss 0.034019
[epoch15, step56]: loss 0.037253
[epoch15, step57]: loss 0.036378
[epoch15, step58]: loss 0.033903
[epoch15, step59]: loss 0.033800
[epoch15, step60]: loss 0.037016
[epoch15, step61]: loss 0.033589
[epoch15, step62]: loss 0.036755
[epoch15, step63]: loss 0.034240
[epoch15, step64]: loss 0.033717
[epoch15, step65]: loss 0.036626
[epoch15, step66]: loss 0.035700
[epoch15, step67]: loss 0.033451
[epoch15, step68]: loss 0.033445
[epoch15, step69]: loss 0.036582
[epoch15, step70]: loss 0.033344
[epoch15, step71]: loss 0.036257
[epoch15, step72]: loss 0.033561
[epoch15, step73]: loss 0.034178
[epoch15, step74]: loss 0.035830
[epoch15, step75]: loss 0.036746
[epoch15, step76]: loss 0.034142
[epoch15, step77]: loss 0.034170
[epoch15, step78]: loss 0.036582
[epoch15, step79]: loss 0.034021
[epoch15, step80]: loss 0.038037
[epoch15, step81]: loss 0.033772
[epoch15, step82]: loss 0.033930
[epoch15, step83]: loss 0.037495
[epoch15, step84]: loss 0.036232
[epoch15, step85]: loss 0.034058
[epoch15, step86]: loss 0.034101
[epoch15, step87]: loss 0.037001
[epoch15, step88]: loss 0.032955
[epoch15, step89]: loss 0.036366
[epoch15, step90]: loss 0.034779
[epoch15, step91]: loss 0.033208
[epoch15, step92]: loss 0.036649
[epoch15, step93]: loss 0.038121
[epoch15, step94]: loss 0.032904
[epoch15, step95]: loss 0.035115
[epoch15, step96]: loss 0.037237
[epoch15, step97]: loss 0.035476
[epoch15, step98]: loss 0.035998
[epoch15, step99]: loss 0.033894
[epoch15, step100]: loss 0.033037
[epoch15, step101]: loss 0.036502
[epoch15, step102]: loss 0.036767
[epoch15, step103]: loss 0.033490
[epoch15, step104]: loss 0.032995
[epoch15, step105]: loss 0.036308
[epoch15, step106]: loss 0.033083
[epoch15, step107]: loss 0.036829
[epoch15, step108]: loss 0.033610
[epoch15, step109]: loss 0.033160
[epoch15, step110]: loss 0.036753
[epoch15, step111]: loss 0.036202
[epoch15, step112]: loss 0.033321
[epoch15, step113]: loss 0.034723
[epoch15, step114]: loss 0.036731
[epoch15, step115]: loss 0.033178
[epoch15, step116]: loss 0.037530
[epoch15, step117]: loss 0.033082
[epoch15, step118]: loss 0.034796
[epoch15, step119]: loss 0.036118
[epoch15, step120]: loss 0.036770
[epoch15, step121]: loss 0.033137
[epoch15, step122]: loss 0.032741
[epoch15, step123]: loss 0.036777
[epoch15, step124]: loss 0.033485
[epoch15, step125]: loss 0.036995
[epoch15, step126]: loss 0.034129
[epoch15, step127]: loss 0.033736
[epoch15, step128]: loss 0.036484
[epoch15, step129]: loss 0.036530
[epoch15, step130]: loss 0.033606
[epoch15, step131]: loss 0.033167
[epoch15, step132]: loss 0.035939
[epoch15, step133]: loss 0.033526
[epoch15, step134]: loss 0.036035
[epoch15, step135]: loss 0.034365
[epoch15, step136]: loss 0.036191
[epoch15, step137]: loss 0.036867
[epoch15, step138]: loss 0.036124
[epoch15, step139]: loss 0.033617
[epoch15, step140]: loss 0.033592
[epoch15, step141]: loss 0.036622
[epoch15, step142]: loss 0.033307
[epoch15, step143]: loss 0.036153
[epoch15, step144]: loss 0.034244
[epoch15, step145]: loss 0.033639
[epoch15, step146]: loss 0.036648
[epoch15, step147]: loss 0.037514
[epoch15, step148]: loss 0.033203
[epoch15, step149]: loss 0.033186
[epoch15, step150]: loss 0.035707
[epoch15, step151]: loss 0.033656
[epoch15, step152]: loss 0.037144
[epoch15, step153]: loss 0.033633
[epoch15, step154]: loss 0.033495
[epoch15, step155]: loss 0.037660
[epoch15, step156]: loss 0.035516
[epoch15, step157]: loss 0.033288
[epoch15, step158]: loss 0.033974
[epoch15, step159]: loss 0.036545
[epoch15, step160]: loss 0.033506
[epoch15, step161]: loss 0.036917
[epoch15, step162]: loss 0.034030
[epoch15, step163]: loss 0.033619
[epoch15, step164]: loss 0.037251
[epoch15, step165]: loss 0.037492
[epoch15, step166]: loss 0.034155
[epoch15, step167]: loss 0.033503
[epoch15, step168]: loss 0.037413
[epoch15, step169]: loss 0.033591
[epoch15, step170]: loss 0.036576
[epoch15, step171]: loss 0.033316
[epoch15, step172]: loss 0.033452
[epoch15, step173]: loss 0.036726
[epoch15, step174]: loss 0.035703
[epoch15, step175]: loss 0.034457
[epoch15, step176]: loss 0.033641
[epoch15, step177]: loss 0.036409
[epoch15, step178]: loss 0.033724
[epoch15, step179]: loss 0.036285
[epoch15, step180]: loss 0.033806
[epoch15, step181]: loss 0.033934
[epoch15, step182]: loss 0.036372
[epoch15, step183]: loss 0.036766
[epoch15, step184]: loss 0.034820
[epoch15, step185]: loss 0.033767
[epoch15, step186]: loss 0.036388
[epoch15, step187]: loss 0.033337
[epoch15, step188]: loss 0.035990
[epoch15, step189]: loss 0.033364
[epoch15, step190]: loss 0.033340
[epoch15, step191]: loss 0.036514
[epoch15, step192]: loss 0.036666
[epoch15, step193]: loss 0.032067
[epoch15, step194]: loss 0.032129
[epoch15, step195]: loss 0.036397
[epoch15, step196]: loss 0.034163
[epoch15, step197]: loss 0.036421
[epoch15, step198]: loss 0.032462
[epoch15, step199]: loss 0.033754
[epoch15, step200]: loss 0.036994
[epoch15, step201]: loss 0.036900
[epoch15, step202]: loss 0.032846
[epoch15, step203]: loss 0.034111
[epoch15, step204]: loss 0.037430
[epoch15, step205]: loss 0.033330
[epoch15, step206]: loss 0.036529
[epoch15, step207]: loss 0.033445
[epoch15, step208]: loss 0.034577
[epoch15, step209]: loss 0.036656
[epoch15, step210]: loss 0.037358
[epoch15, step211]: loss 0.034195
[epoch15, step212]: loss 0.033786
[epoch15, step213]: loss 0.036218
[epoch15, step214]: loss 0.034088
[epoch15, step215]: loss 0.036428
[epoch15, step216]: loss 0.033620
[epoch15, step217]: loss 0.034257
[epoch15, step218]: loss 0.036562
[epoch15, step219]: loss 0.035695
[epoch15, step220]: loss 0.034118
[epoch15, step221]: loss 0.033354
[epoch15, step222]: loss 0.036440
[epoch15, step223]: loss 0.033474
[epoch15, step224]: loss 0.036228
[epoch15, step225]: loss 0.033004
[epoch15, step226]: loss 0.033284
[epoch15, step227]: loss 0.035420
[epoch15, step228]: loss 0.037063
[epoch15, step229]: loss 0.032518
[epoch15, step230]: loss 0.033862
[epoch15, step231]: loss 0.036373
[epoch15, step232]: loss 0.033795
[epoch15, step233]: loss 0.035756
[epoch15, step234]: loss 0.032912
[epoch15, step235]: loss 0.033971
[epoch15, step236]: loss 0.035784
[epoch15, step237]: loss 0.036176
[epoch15, step238]: loss 0.033332
[epoch15, step239]: loss 0.032449
[epoch15, step240]: loss 0.035500
[epoch15, step241]: loss 0.034876
[epoch15, step242]: loss 0.037370
[epoch15, step243]: loss 0.034791
[epoch15, step244]: loss 0.033314
[epoch15, step245]: loss 0.036500
[epoch15, step246]: loss 0.035695
[epoch15, step247]: loss 0.034043
[epoch15, step248]: loss 0.033203
[epoch15, step249]: loss 0.036312
[epoch15, step250]: loss 0.033619
[epoch15, step251]: loss 0.036607
[epoch15, step252]: loss 0.033944
[epoch15, step253]: loss 0.032863
[epoch15, step254]: loss 0.035831
[epoch15, step255]: loss 0.036020
[epoch15, step256]: loss 0.033222
[epoch15, step257]: loss 0.034100
[epoch15, step258]: loss 0.039068
[epoch15, step259]: loss 0.035519
[epoch15, step260]: loss 0.036522
[epoch15, step261]: loss 0.037723
[epoch15, step262]: loss 0.035219
[epoch15, step263]: loss 0.035499
[epoch15, step264]: loss 0.035394
[epoch15, step265]: loss 0.033228
[epoch15, step266]: loss 0.032691
[epoch15, step267]: loss 0.036415
[epoch15, step268]: loss 0.033650
[epoch15, step269]: loss 0.035811
[epoch15, step270]: loss 0.033566
[epoch15, step271]: loss 0.032826
[epoch15, step272]: loss 0.035837
[epoch15, step273]: loss 0.035586
[epoch15, step274]: loss 0.034688
[epoch15, step275]: loss 0.032756
[epoch15, step276]: loss 0.036354
[epoch15, step277]: loss 0.035221
[epoch15, step278]: loss 0.036530
[epoch15, step279]: loss 0.033025
[epoch15, step280]: loss 0.033369
[epoch15, step281]: loss 0.036546
[epoch15, step282]: loss 0.037530
[epoch15, step283]: loss 0.033302
[epoch15, step284]: loss 0.032723
[epoch15, step285]: loss 0.037822
[epoch15, step286]: loss 0.033739
[epoch15, step287]: loss 0.037711
[epoch15, step288]: loss 0.033075
[epoch15, step289]: loss 0.034807
[epoch15, step290]: loss 0.036121
[epoch15, step291]: loss 0.036036
[epoch15, step292]: loss 0.033150
[epoch15, step293]: loss 0.033066
[epoch15, step294]: loss 0.035562
[epoch15, step295]: loss 0.033106
[epoch15, step296]: loss 0.038537
[epoch15, step297]: loss 0.033258
[epoch15, step298]: loss 0.034338
[epoch15, step299]: loss 0.035581
[epoch15, step300]: loss 0.036566
[epoch15, step301]: loss 0.033609
[epoch15, step302]: loss 0.033942
[epoch15, step303]: loss 0.036930
[epoch15, step304]: loss 0.032829
[epoch15, step305]: loss 0.035720
[epoch15, step306]: loss 0.033306
[epoch15, step307]: loss 0.033155
[epoch15, step308]: loss 0.036786
[epoch15, step309]: loss 0.036261
[epoch15, step310]: loss 0.033155
[epoch15, step311]: loss 0.033657
[epoch15, step312]: loss 0.036526
[epoch15, step313]: loss 0.032983
[epoch15, step314]: loss 0.036142
[epoch15, step315]: loss 0.034258
[epoch15, step316]: loss 0.033176
[epoch15, step317]: loss 0.037154
[epoch15, step318]: loss 0.036693
[epoch15, step319]: loss 0.033598
[epoch15, step320]: loss 0.032808
[epoch15, step321]: loss 0.035767
[epoch15, step322]: loss 0.033363
[epoch15, step323]: loss 0.035753
[epoch15, step324]: loss 0.034658
[epoch15, step325]: loss 0.033290
[epoch15, step326]: loss 0.035682
[epoch15, step327]: loss 0.035133
[epoch15, step328]: loss 0.033707
[epoch15, step329]: loss 0.032880
[epoch15, step330]: loss 0.035439
[epoch15, step331]: loss 0.033818
[epoch15, step332]: loss 0.035111
[epoch15, step333]: loss 0.033300
[epoch15, step334]: loss 0.033457
[epoch15, step335]: loss 0.036512
[epoch15, step336]: loss 0.037585
[epoch15, step337]: loss 0.034415
[epoch15, step338]: loss 0.033081
[epoch15, step339]: loss 0.037742
[epoch15, step340]: loss 0.034119
[epoch15, step341]: loss 0.035726
[epoch15, step342]: loss 0.032616
[epoch15, step343]: loss 0.034271
[epoch15, step344]: loss 0.035624
[epoch15, step345]: loss 0.035432
[epoch15, step346]: loss 0.033067
[epoch15, step347]: loss 0.033607
[epoch15, step348]: loss 0.036316
[epoch15, step349]: loss 0.034843
[epoch15, step350]: loss 0.036775
[epoch15, step351]: loss 0.032665
[epoch15, step352]: loss 0.033061
[epoch15, step353]: loss 0.035776
[epoch15, step354]: loss 0.035594
[epoch15, step355]: loss 0.033302
[epoch15, step356]: loss 0.034137
[epoch15, step357]: loss 0.036209
[epoch15, step358]: loss 0.032501
[epoch15, step359]: loss 0.038501
[epoch15, step360]: loss 0.032204
[epoch15, step361]: loss 0.033257
[epoch15, step362]: loss 0.037470
[epoch15, step363]: loss 0.035583
[epoch15, step364]: loss 0.033460
[epoch15, step365]: loss 0.033056
[epoch15, step366]: loss 0.037275
[epoch15, step367]: loss 0.033839
[epoch15, step368]: loss 0.036205
[epoch15, step369]: loss 0.033143
[epoch15, step370]: loss 0.035297
[epoch15, step371]: loss 0.037174
[epoch15, step372]: loss 0.036236
[epoch15, step373]: loss 0.034029
[epoch15, step374]: loss 0.032776
[epoch15, step375]: loss 0.036926
[epoch15, step376]: loss 0.033953
[epoch15, step377]: loss 0.037282
[epoch15, step378]: loss 0.034160
[epoch15, step379]: loss 0.033416
[epoch15, step380]: loss 0.037833
[epoch15, step381]: loss 0.037785
[epoch15, step382]: loss 0.034480
[epoch15, step383]: loss 0.032780
[epoch15, step384]: loss 0.036785
[epoch15, step385]: loss 0.033242
[epoch15, step386]: loss 0.035904
[epoch15, step387]: loss 0.033053
[epoch15, step388]: loss 0.034446
[epoch15, step389]: loss 0.036079
[epoch15, step390]: loss 0.037355
[epoch15, step391]: loss 0.032677
[epoch15, step392]: loss 0.033693
[epoch15, step393]: loss 0.036498
[epoch15, step394]: loss 0.033631
[epoch15, step395]: loss 0.036077
[epoch15, step396]: loss 0.033435
[epoch15, step397]: loss 0.034170
[epoch15, step398]: loss 0.036487
[epoch15, step399]: loss 0.035534
[epoch15, step400]: loss 0.033230
[epoch15, step401]: loss 0.032388
[epoch15, step402]: loss 0.035904
[epoch15, step403]: loss 0.033155
[epoch15, step404]: loss 0.036528
[epoch15, step405]: loss 0.034046
[epoch15, step406]: loss 0.034309
[epoch15, step407]: loss 0.035912
[epoch15, step408]: loss 0.036338
[epoch15, step409]: loss 0.036337
[epoch15, step410]: loss 0.033346
[epoch15, step411]: loss 0.036136
[epoch15, step412]: loss 0.033483
[epoch15, step413]: loss 0.036093
[epoch15, step414]: loss 0.034249
[epoch15, step415]: loss 0.033436
[epoch15, step416]: loss 0.035966
[epoch15, step417]: loss 0.035648
[epoch15, step418]: loss 0.033642
[epoch15, step419]: loss 0.032141
[epoch15, step420]: loss 0.036428
[epoch15, step421]: loss 0.032920
[epoch15, step422]: loss 0.036645
[epoch15, step423]: loss 0.033892
[epoch15, step424]: loss 0.033961
[epoch15, step425]: loss 0.036437
[epoch15, step426]: loss 0.036682
[epoch15, step427]: loss 0.033781
[epoch15, step428]: loss 0.033621
[epoch15, step429]: loss 0.038008
[epoch15, step430]: loss 0.034805
[epoch15, step431]: loss 0.037149
[epoch15, step432]: loss 0.034738
[epoch15, step433]: loss 0.033815
[epoch15, step434]: loss 0.037183
[epoch15, step435]: loss 0.036633
[epoch15, step436]: loss 0.033923
[epoch15, step437]: loss 0.033604
[epoch15, step438]: loss 0.036664
[epoch15, step439]: loss 0.034441
[epoch15, step440]: loss 0.036471
[epoch15, step441]: loss 0.033743
[epoch15, step442]: loss 0.033435
[epoch15, step443]: loss 0.037065
[epoch15, step444]: loss 0.036052
[epoch15, step445]: loss 0.033667
[epoch15, step446]: loss 0.034082
[epoch15, step447]: loss 0.037585
[epoch15, step448]: loss 0.034453
[epoch15, step449]: loss 0.035851
[epoch15, step450]: loss 0.033085
[epoch15, step451]: loss 0.033397
[epoch15, step452]: loss 0.035451
[epoch15, step453]: loss 0.036710
[epoch15, step454]: loss 0.033341
[epoch15, step455]: loss 0.034154
[epoch15, step456]: loss 0.036202
[epoch15, step457]: loss 0.034144
[epoch15, step458]: loss 0.035829
[epoch15, step459]: loss 0.033947
[epoch15, step460]: loss 0.033697
[epoch15, step461]: loss 0.037038
[epoch15, step462]: loss 0.035495
[epoch15, step463]: loss 0.034001
[epoch15, step464]: loss 0.033208
[epoch15, step465]: loss 0.037502
[epoch15, step466]: loss 0.033531
[epoch15, step467]: loss 0.035798
[epoch15, step468]: loss 0.033539
[epoch15, step469]: loss 0.033542
[epoch15, step470]: loss 0.036261
[epoch15, step471]: loss 0.035794
[epoch15, step472]: loss 0.034006
[epoch15, step473]: loss 0.033251
[epoch15, step474]: loss 0.035716
[epoch15, step475]: loss 0.034098
[epoch15, step476]: loss 0.036574
[epoch15, step477]: loss 0.034231
[epoch15, step478]: loss 0.033811
[epoch15, step479]: loss 0.036717
[epoch15, step480]: loss 0.035509
[epoch15, step481]: loss 0.033471
[epoch15, step482]: loss 0.032451
[epoch15, step483]: loss 0.035881
[epoch15, step484]: loss 0.034019
[epoch15, step485]: loss 0.036382
[epoch15, step486]: loss 0.033464
[epoch15, step487]: loss 0.033020
[epoch15, step488]: loss 0.036729
[epoch15, step489]: loss 0.035410
[epoch15, step490]: loss 0.034013
[epoch15, step491]: loss 0.033642
[epoch15, step492]: loss 0.035667
[epoch15, step493]: loss 0.033306
[epoch15, step494]: loss 0.036702
[epoch15, step495]: loss 0.034489
[epoch15, step496]: loss 0.033447
[epoch15, step497]: loss 0.036631
[epoch15, step498]: loss 0.036052
[epoch15, step499]: loss 0.033225
[epoch15, step500]: loss 0.033239
[epoch15, step501]: loss 0.035963
[epoch15, step502]: loss 0.032317
[epoch15, step503]: loss 0.037007
[epoch15, step504]: loss 0.034066
[epoch15, step505]: loss 0.032458
[epoch15, step506]: loss 0.037767
[epoch15, step507]: loss 0.037904
[epoch15, step508]: loss 0.034733
[epoch15, step509]: loss 0.033101
[epoch15, step510]: loss 0.037035
[epoch15, step511]: loss 0.034532
[epoch15, step512]: loss 0.036241
[epoch15, step513]: loss 0.033704
[epoch15, step514]: loss 0.033158
[epoch15, step515]: loss 0.036006
[epoch15, step516]: loss 0.035729
[epoch15, step517]: loss 0.033065
[epoch15, step518]: loss 0.033465
[epoch15, step519]: loss 0.036823
[epoch15, step520]: loss 0.032990
[epoch15, step521]: loss 0.036550
[epoch15, step522]: loss 0.032863
[epoch15, step523]: loss 0.032649
[epoch15, step524]: loss 0.036688
[epoch15, step525]: loss 0.036100
[epoch15, step526]: loss 0.033576
[epoch15, step527]: loss 0.033758
[epoch15, step528]: loss 0.036966
[epoch15, step529]: loss 0.033377
[epoch15, step530]: loss 0.037438
[epoch15, step531]: loss 0.034907
[epoch15, step532]: loss 0.034610
[epoch15, step533]: loss 0.037874
[epoch15, step534]: loss 0.035787
[epoch15, step535]: loss 0.035509
[epoch15, step536]: loss 0.033781
[epoch15, step537]: loss 0.035697
[epoch15, step538]: loss 0.034664
[epoch15, step539]: loss 0.038286
[epoch15, step540]: loss 0.034873
[epoch15, step541]: loss 0.033731
[epoch15, step542]: loss 0.036332
[epoch15, step543]: loss 0.036056
[epoch15, step544]: loss 0.033820
[epoch15, step545]: loss 0.033132
[epoch15, step546]: loss 0.036477
[epoch15, step547]: loss 0.033892
[epoch15, step548]: loss 0.036643
[epoch15, step549]: loss 0.034004
[epoch15, step550]: loss 0.033727
[epoch15, step551]: loss 0.037069
[epoch15, step552]: loss 0.035529
[epoch15, step553]: loss 0.034402
[epoch15, step554]: loss 0.032986
[epoch15, step555]: loss 0.036084
[epoch15, step556]: loss 0.033351
[epoch15, step557]: loss 0.035237
[epoch15, step558]: loss 0.033496
[epoch15, step559]: loss 0.033181
[epoch15, step560]: loss 0.036369
[epoch15, step561]: loss 0.035976
[epoch15, step562]: loss 0.032867
[epoch15, step563]: loss 0.031157
[epoch15, step564]: loss 0.032627
[epoch15, step565]: loss 0.028122
[epoch15, step566]: loss 0.036890
[epoch15, step567]: loss 0.028011
[epoch15, step568]: loss 0.026495
[epoch15, step569]: loss 0.024525
[epoch15, step570]: loss 0.032951
[epoch15, step571]: loss 0.026147
[epoch15, step572]: loss 0.026518
[epoch15, step573]: loss 0.030184
[epoch15, step574]: loss 0.029043
[epoch15, step575]: loss 0.021532
[epoch15, step576]: loss 0.022462
[epoch15, step577]: loss 0.026965
[epoch15, step578]: loss 0.019977
[epoch15, step579]: loss 0.029551
[epoch15, step580]: loss 0.019942
[epoch15, step581]: loss 0.025412
[epoch15, step582]: loss 0.025449
[epoch15, step583]: loss 0.021629
[epoch15, step584]: loss 0.023852
[epoch15, step585]: loss 0.025349
[epoch15, step586]: loss 0.021824
[epoch15, step587]: loss 0.027975
[epoch15, step588]: loss 0.023098
[epoch15, step589]: loss 0.022935
[epoch15, step590]: loss 0.027147
[epoch15, step591]: loss 0.020218
[epoch15, step592]: loss 0.026291
[epoch15, step593]: loss 0.021471
[epoch15, step594]: loss 0.024922
[epoch15, step595]: loss 0.025925
[epoch15, step596]: loss 0.022083
[epoch15, step597]: loss 0.024054
[epoch15, step598]: loss 0.026520
[epoch15, step599]: loss 0.024639
[epoch15, step600]: loss 0.026441
[epoch15, step601]: loss 0.019154
[epoch15, step602]: loss 0.022691
[epoch15, step603]: loss 0.025525
[epoch15, step604]: loss 0.026127
[epoch15, step605]: loss 0.024573
[epoch15, step606]: loss 0.024361
[epoch15, step607]: loss 0.026233
[epoch15, step608]: loss 0.024835
[epoch15, step609]: loss 0.026397
[epoch15, step610]: loss 0.026417
[epoch15, step611]: loss 0.025880
[epoch15, step612]: loss 0.024918
[epoch15, step613]: loss 0.018828
[epoch15, step614]: loss 0.024850
[epoch15, step615]: loss 0.027482
[epoch15, step616]: loss 0.023907
[epoch15, step617]: loss 0.023208
[epoch15, step618]: loss 0.025849
[epoch15, step619]: loss 0.027688
[epoch15, step620]: loss 0.023768
[epoch15, step621]: loss 0.025997
[epoch15, step622]: loss 0.020045
[epoch15, step623]: loss 0.025184
[epoch15, step624]: loss 0.026382
[epoch15, step625]: loss 0.025605
[epoch15, step626]: loss 0.028171
[epoch15, step627]: loss 0.022420
[epoch15, step628]: loss 0.024398
[epoch15, step629]: loss 0.020777
[epoch15, step630]: loss 0.022715
[epoch15, step631]: loss 0.031770
[epoch15, step632]: loss 0.022991
[epoch15, step633]: loss 0.024183
[epoch15, step634]: loss 0.026539
[epoch15, step635]: loss 0.024779
[epoch15, step636]: loss 0.020401
[epoch15, step637]: loss 0.027529
[epoch15, step638]: loss 0.026387
[epoch15, step639]: loss 0.022947
[epoch15, step640]: loss 0.029158
[epoch15, step641]: loss 0.029538
[epoch15, step642]: loss 0.024554
[epoch15, step643]: loss 0.024870
[epoch15, step644]: loss 0.025602
[epoch15, step645]: loss 0.023242
[epoch15, step646]: loss 0.024844
[epoch15, step647]: loss 0.022190
[epoch15, step648]: loss 0.023297
[epoch15, step649]: loss 0.028612
[epoch15, step650]: loss 0.021465
[epoch15, step651]: loss 0.025398
[epoch15, step652]: loss 0.026522
[epoch15, step653]: loss 0.027634
[epoch15, step654]: loss 0.022227
[epoch15, step655]: loss 0.024022
[epoch15, step656]: loss 0.022013
[epoch15, step657]: loss 0.027042
[epoch15, step658]: loss 0.024558
[epoch15, step659]: loss 0.026036
[epoch15, step660]: loss 0.022891
[epoch15, step661]: loss 0.025575
[epoch15, step662]: loss 0.023606
[epoch15, step663]: loss 0.021308
[epoch15, step664]: loss 0.024876
[epoch15, step665]: loss 0.026923
[epoch15, step666]: loss 0.025478
[epoch15, step667]: loss 0.025737
[epoch15, step668]: loss 0.023046
[epoch15, step669]: loss 0.025898
[epoch15, step670]: loss 0.026408
[epoch15, step671]: loss 0.020954
[epoch15, step672]: loss 0.024071
[epoch15, step673]: loss 0.022636
[epoch15, step674]: loss 0.020682
[epoch15, step675]: loss 0.019370
[epoch15, step676]: loss 0.023707
[epoch15, step677]: loss 0.025305
[epoch15, step678]: loss 0.022898
[epoch15, step679]: loss 0.023105
[epoch15, step680]: loss 0.030451
[epoch15, step681]: loss 0.020879
[epoch15, step682]: loss 0.026230
[epoch15, step683]: loss 0.026084
[epoch15, step684]: loss 0.025238
[epoch15, step685]: loss 0.024138
[epoch15, step686]: loss 0.027733
[epoch15, step687]: loss 0.027251
[epoch15, step688]: loss 0.022610
[epoch15, step689]: loss 0.025055
[epoch15, step690]: loss 0.025399
[epoch15, step691]: loss 0.024386
[epoch15, step692]: loss 0.022555
[epoch15, step693]: loss 0.026678
[epoch15, step694]: loss 0.022179
[epoch15, step695]: loss 0.026262
[epoch15, step696]: loss 0.026031
[epoch15, step697]: loss 0.026822
[epoch15, step698]: loss 0.024197
[epoch15, step699]: loss 0.023509
[epoch15, step700]: loss 0.021393
[epoch15, step701]: loss 0.025573
[epoch15, step702]: loss 0.020972
[epoch15, step703]: loss 0.022329
[epoch15, step704]: loss 0.024470
[epoch15, step705]: loss 0.023959
[epoch15, step706]: loss 0.023336
[epoch15, step707]: loss 0.024672
[epoch15, step708]: loss 0.025164
[epoch15, step709]: loss 0.027163
[epoch15, step710]: loss 0.022945
[epoch15, step711]: loss 0.023289
[epoch15, step712]: loss 0.025589
[epoch15, step713]: loss 0.025721
[epoch15, step714]: loss 0.020602
[epoch15, step715]: loss 0.023210
[epoch15, step716]: loss 0.025926
[epoch15, step717]: loss 0.022830
[epoch15, step718]: loss 0.024703
[epoch15, step719]: loss 0.032546
[epoch15, step720]: loss 0.024158
[epoch15, step721]: loss 0.022694
[epoch15, step722]: loss 0.029926
[epoch15, step723]: loss 0.025764
[epoch15, step724]: loss 0.022310
[epoch15, step725]: loss 0.027291
[epoch15, step726]: loss 0.022477
[epoch15, step727]: loss 0.024456
[epoch15, step728]: loss 0.025938
[epoch15, step729]: loss 0.021585
[epoch15, step730]: loss 0.022206
[epoch15, step731]: loss 0.025134
[epoch15, step732]: loss 0.025318
[epoch15, step733]: loss 0.023516
[epoch15, step734]: loss 0.021598
[epoch15, step735]: loss 0.027085
[epoch15, step736]: loss 0.025140
[epoch15, step737]: loss 0.026318
[epoch15, step738]: loss 0.020014
[epoch15, step739]: loss 0.025595
[epoch15, step740]: loss 0.022105
[epoch15, step741]: loss 0.025112
[epoch15, step742]: loss 0.021980
[epoch15, step743]: loss 0.022795
[epoch15, step744]: loss 0.023558
[epoch15, step745]: loss 0.024420
[epoch15, step746]: loss 0.024403
[epoch15, step747]: loss 0.026779
[epoch15, step748]: loss 0.025284
[epoch15, step749]: loss 0.025509
[epoch15, step750]: loss 0.026979
[epoch15, step751]: loss 0.021196
[epoch15, step752]: loss 0.024324
[epoch15, step753]: loss 0.025783
[epoch15, step754]: loss 0.021946
[epoch15, step755]: loss 0.025596
[epoch15, step756]: loss 0.023108
[epoch15, step757]: loss 0.020138
[epoch15, step758]: loss 0.024831
[epoch15, step759]: loss 0.021951
[epoch15, step760]: loss 0.023754
[epoch15, step761]: loss 0.026414
[epoch15, step762]: loss 0.021002
[epoch15, step763]: loss 0.024488
[epoch15, step764]: loss 0.023164
[epoch15, step765]: loss 0.025086
[epoch15, step766]: loss 0.024123
[epoch15, step767]: loss 0.025818
[epoch15, step768]: loss 0.020166
[epoch15, step769]: loss 0.026516
[epoch15, step770]: loss 0.025054
[epoch15, step771]: loss 0.022872
[epoch15, step772]: loss 0.027809
[epoch15, step773]: loss 0.025884
[epoch15, step774]: loss 0.024364
[epoch15, step775]: loss 0.019759
[epoch15, step776]: loss 0.025227
[epoch15, step777]: loss 0.022104
[epoch15, step778]: loss 0.026987
[epoch15, step779]: loss 0.023621
[epoch15, step780]: loss 0.019764
[epoch15, step781]: loss 0.024417
[epoch15, step782]: loss 0.022207
[epoch15, step783]: loss 0.019225
[epoch15, step784]: loss 0.020010
[epoch15, step785]: loss 0.021618
[epoch15, step786]: loss 0.023840
[epoch15, step787]: loss 0.022272
[epoch15, step788]: loss 0.024282
[epoch15, step789]: loss 0.022352
[epoch15, step790]: loss 0.022714
[epoch15, step791]: loss 0.026821
[epoch15, step792]: loss 0.024719
[epoch15, step793]: loss 0.026100
[epoch15, step794]: loss 0.019977
[epoch15, step795]: loss 0.024975
[epoch15, step796]: loss 0.027671
[epoch15, step797]: loss 0.026880
[epoch15, step798]: loss 0.026417
[epoch15, step799]: loss 0.025649
[epoch15, step800]: loss 0.020989
[epoch15, step801]: loss 0.021873
[epoch15, step802]: loss 0.022749
[epoch15, step803]: loss 0.025732
[epoch15, step804]: loss 0.027387
[epoch15, step805]: loss 0.027517
[epoch15, step806]: loss 0.020389
[epoch15, step807]: loss 0.020431
[epoch15, step808]: loss 0.022911
[epoch15, step809]: loss 0.022311
[epoch15, step810]: loss 0.025317
[epoch15, step811]: loss 0.024962
[epoch15, step812]: loss 0.023561
[epoch15, step813]: loss 0.023040
[epoch15, step814]: loss 0.024609
[epoch15, step815]: loss 0.024605
[epoch15, step816]: loss 0.023321
[epoch15, step817]: loss 0.024263
[epoch15, step818]: loss 0.021462
[epoch15, step819]: loss 0.020255
[epoch15, step820]: loss 0.023116
[epoch15, step821]: loss 0.020741
[epoch15, step822]: loss 0.029572
[epoch15, step823]: loss 0.023619
[epoch15, step824]: loss 0.026400
[epoch15, step825]: loss 0.025028
[epoch15, step826]: loss 0.023811
[epoch15, step827]: loss 0.026133
[epoch15, step828]: loss 0.028236
[epoch15, step829]: loss 0.026179
[epoch15, step830]: loss 0.021926
[epoch15, step831]: loss 0.026318
[epoch15, step832]: loss 0.021132
[epoch15, step833]: loss 0.028629
[epoch15, step834]: loss 0.025106
[epoch15, step835]: loss 0.019976
[epoch15, step836]: loss 0.026372
[epoch15, step837]: loss 0.024971
[epoch15, step838]: loss 0.026136
[epoch15, step839]: loss 0.028875
[epoch15, step840]: loss 0.020574
[epoch15, step841]: loss 0.023464
[epoch15, step842]: loss 0.027392
[epoch15, step843]: loss 0.024414
[epoch15, step844]: loss 0.024428
[epoch15, step845]: loss 0.020613
[epoch15, step846]: loss 0.025055
[epoch15, step847]: loss 0.026543
[epoch15, step848]: loss 0.024432
[epoch15, step849]: loss 0.024799
[epoch15, step850]: loss 0.022670
[epoch15, step851]: loss 0.023696
[epoch15, step852]: loss 0.022497
[epoch15, step853]: loss 0.029170
[epoch15, step854]: loss 0.022925
[epoch15, step855]: loss 0.026618
[epoch15, step856]: loss 0.021181
[epoch15, step857]: loss 0.024684
[epoch15, step858]: loss 0.023760
[epoch15, step859]: loss 0.023122
[epoch15, step860]: loss 0.022600
[epoch15, step861]: loss 0.022642
[epoch15, step862]: loss 0.022155
[epoch15, step863]: loss 0.020628
[epoch15, step864]: loss 0.026233
[epoch15, step865]: loss 0.023133
[epoch15, step866]: loss 0.024602
[epoch15, step867]: loss 0.025198
[epoch15, step868]: loss 0.026563
[epoch15, step869]: loss 0.023383
[epoch15, step870]: loss 0.030499
[epoch15, step871]: loss 0.022261
[epoch15, step872]: loss 0.025175
[epoch15, step873]: loss 0.025021
[epoch15, step874]: loss 0.022620
[epoch15, step875]: loss 0.023661
[epoch15, step876]: loss 0.024206
[epoch15, step877]: loss 0.018839
[epoch15, step878]: loss 0.022841
[epoch15, step879]: loss 0.027879
[epoch15, step880]: loss 0.025518
[epoch15, step881]: loss 0.021900
[epoch15, step882]: loss 0.023013
[epoch15, step883]: loss 0.022793
[epoch15, step884]: loss 0.025491
[epoch15, step885]: loss 0.025246
[epoch15, step886]: loss 0.026026
[epoch15, step887]: loss 0.023707
[epoch15, step888]: loss 0.023789
[epoch15, step889]: loss 0.022288
[epoch15, step890]: loss 0.023890
[epoch15, step891]: loss 0.024618
[epoch15, step892]: loss 0.020296
[epoch15, step893]: loss 0.024376
[epoch15, step894]: loss 0.024615
[epoch15, step895]: loss 0.021941
[epoch15, step896]: loss 0.021988
[epoch15, step897]: loss 0.023238
[epoch15, step898]: loss 0.025205
[epoch15, step899]: loss 0.027893
[epoch15, step900]: loss 0.026460
[epoch15, step901]: loss 0.025322
[epoch15, step902]: loss 0.023426
[epoch15, step903]: loss 0.023031
[epoch15, step904]: loss 0.027739
[epoch15, step905]: loss 0.027003
[epoch15, step906]: loss 0.021961
[epoch15, step907]: loss 0.023073
[epoch15, step908]: loss 0.022231
[epoch15, step909]: loss 0.024779
[epoch15, step910]: loss 0.023290
[epoch15, step911]: loss 0.024273
[epoch15, step912]: loss 0.023367
[epoch15, step913]: loss 0.022725
[epoch15, step914]: loss 0.029188
[epoch15, step915]: loss 0.023522
[epoch15, step916]: loss 0.023274
[epoch15, step917]: loss 0.024637
[epoch15, step918]: loss 0.027908
[epoch15, step919]: loss 0.023217
[epoch15, step920]: loss 0.026878
[epoch15, step921]: loss 0.023180
[epoch15, step922]: loss 0.022468
[epoch15, step923]: loss 0.022534
[epoch15, step924]: loss 0.020636
[epoch15, step925]: loss 0.024279
[epoch15, step926]: loss 0.026229
[epoch15, step927]: loss 0.024536
[epoch15, step928]: loss 0.024164
[epoch15, step929]: loss 0.026895
[epoch15, step930]: loss 0.025412
[epoch15, step931]: loss 0.026271
[epoch15, step932]: loss 0.020941
[epoch15, step933]: loss 0.027804
[epoch15, step934]: loss 0.022632
[epoch15, step935]: loss 0.022449
[epoch15, step936]: loss 0.022409
[epoch15, step937]: loss 0.026997
[epoch15, step938]: loss 0.025273
[epoch15, step939]: loss 0.020873
[epoch15, step940]: loss 0.022242
[epoch15, step941]: loss 0.026663
[epoch15, step942]: loss 0.025331
[epoch15, step943]: loss 0.022504
[epoch15, step944]: loss 0.026597
[epoch15, step945]: loss 0.020311
[epoch15, step946]: loss 0.024837
[epoch15, step947]: loss 0.027548
[epoch15, step948]: loss 0.019509
[epoch15, step949]: loss 0.022871
[epoch15, step950]: loss 0.026890
[epoch15, step951]: loss 0.028184
[epoch15, step952]: loss 0.024275
[epoch15, step953]: loss 0.027067
[epoch15, step954]: loss 0.021866
[epoch15, step955]: loss 0.035392
[epoch15, step956]: loss 0.050612
[epoch15, step957]: loss 0.044846
[epoch15, step958]: loss 0.042556
[epoch15, step959]: loss 0.046328
[epoch15, step960]: loss 0.042892
[epoch15, step961]: loss 0.043055
[epoch15, step962]: loss 0.041708
[epoch15, step963]: loss 0.039538
[epoch15, step964]: loss 0.040351
[epoch15, step965]: loss 0.040265
[epoch15, step966]: loss 0.038209
[epoch15, step967]: loss 0.036619
[epoch15, step968]: loss 0.039539
[epoch15, step969]: loss 0.037944
[epoch15, step970]: loss 0.037871
[epoch15, step971]: loss 0.035455
[epoch15, step972]: loss 0.037339
[epoch15, step973]: loss 0.036508
[epoch15, step974]: loss 0.038410
[epoch15, step975]: loss 0.035746
[epoch15, step976]: loss 0.034953
[epoch15, step977]: loss 0.039483
[epoch15, step978]: loss 0.037308
[epoch15, step979]: loss 0.036420
[epoch15, step980]: loss 0.033763
[epoch15, step981]: loss 0.035769
[epoch15, step982]: loss 0.036946
[epoch15, step983]: loss 0.037183
[epoch15, step984]: loss 0.033284
[epoch15, step985]: loss 0.033920
[epoch15, step986]: loss 0.038257
[epoch15, step987]: loss 0.036612
[epoch15, step988]: loss 0.035979
[epoch15, step989]: loss 0.035323
[epoch15, step990]: loss 0.035475
[epoch15, step991]: loss 0.036226
[epoch15, step992]: loss 0.036904
[epoch15, step993]: loss 0.034525
[epoch15, step994]: loss 0.034456
[epoch15, step995]: loss 0.037527
[epoch15, step996]: loss 0.035811
[epoch15, step997]: loss 0.035844
[epoch15, step998]: loss 0.034116
[epoch15, step999]: loss 0.035862
[epoch15, step1000]: loss 0.035500
[epoch15, step1001]: loss 0.036892
[epoch15, step1002]: loss 0.034143
[epoch15, step1003]: loss 0.033643
[epoch15, step1004]: loss 0.037888
[epoch15, step1005]: loss 0.034772
[epoch15, step1006]: loss 0.036347
[epoch15, step1007]: loss 0.033296
[epoch15, step1008]: loss 0.035591
[epoch15, step1009]: loss 0.034822
[epoch15, step1010]: loss 0.037925
[epoch15, step1011]: loss 0.033631
[epoch15, step1012]: loss 0.033220
[epoch15, step1013]: loss 0.037017
[epoch15, step1014]: loss 0.035574
[epoch15, step1015]: loss 0.035456
[epoch15, step1016]: loss 0.033717
[epoch15, step1017]: loss 0.034991
[epoch15, step1018]: loss 0.036013
[epoch15, step1019]: loss 0.037929
[epoch15, step1020]: loss 0.034306
[epoch15, step1021]: loss 0.033562
[epoch15, step1022]: loss 0.037762
[epoch15, step1023]: loss 0.034876
[epoch15, step1024]: loss 0.036698
[epoch15, step1025]: loss 0.033023
[epoch15, step1026]: loss 0.035152
[epoch15, step1027]: loss 0.035106
[epoch15, step1028]: loss 0.036363
[epoch15, step1029]: loss 0.033519
[epoch15, step1030]: loss 0.032644
[epoch15, step1031]: loss 0.035834
[epoch15, step1032]: loss 0.035850
[epoch15, step1033]: loss 0.034947
[epoch15, step1034]: loss 0.032596
[epoch15, step1035]: loss 0.034515
[epoch15, step1036]: loss 0.035100
[epoch15, step1037]: loss 0.036136
[epoch15, step1038]: loss 0.032994
[epoch15, step1039]: loss 0.033518
[epoch15, step1040]: loss 0.035594
[epoch15, step1041]: loss 0.034967
[epoch15, step1042]: loss 0.034190
[epoch15, step1043]: loss 0.032978
[epoch15, step1044]: loss 0.035379
[epoch15, step1045]: loss 0.035023
[epoch15, step1046]: loss 0.036115
[epoch15, step1047]: loss 0.034408
[epoch15, step1048]: loss 0.033700
[epoch15, step1049]: loss 0.037081
[epoch15, step1050]: loss 0.035752
[epoch15, step1051]: loss 0.035975
[epoch15, step1052]: loss 0.034237
[epoch15, step1053]: loss 0.036241
[epoch15, step1054]: loss 0.036284
[epoch15, step1055]: loss 0.036689
[epoch15, step1056]: loss 0.034852
[epoch15, step1057]: loss 0.034567
[epoch15, step1058]: loss 0.037572
[epoch15, step1059]: loss 0.035874
[epoch15, step1060]: loss 0.035489
[epoch15, step1061]: loss 0.033452
[epoch15, step1062]: loss 0.035178
[epoch15, step1063]: loss 0.036225
[epoch15, step1064]: loss 0.036884
[epoch15, step1065]: loss 0.033647
[epoch15, step1066]: loss 0.033291
[epoch15, step1067]: loss 0.036898
[epoch15, step1068]: loss 0.034268
[epoch15, step1069]: loss 0.035132
[epoch15, step1070]: loss 0.032867
[epoch15, step1071]: loss 0.035582
[epoch15, step1072]: loss 0.035977
[epoch15, step1073]: loss 0.036585
[epoch15, step1074]: loss 0.033742
[epoch15, step1075]: loss 0.033233
[epoch15, step1076]: loss 0.036726
[epoch15, step1077]: loss 0.034954
[epoch15, step1078]: loss 0.035034
[epoch15, step1079]: loss 0.033997
[epoch15, step1080]: loss 0.034851
[epoch15, step1081]: loss 0.034811
[epoch15, step1082]: loss 0.035688
[epoch15, step1083]: loss 0.033948
[epoch15, step1084]: loss 0.033354
[epoch15, step1085]: loss 0.036405
[epoch15, step1086]: loss 0.034973
[epoch15, step1087]: loss 0.034662
[epoch15, step1088]: loss 0.033014
[epoch15, step1089]: loss 0.035055
[epoch15, step1090]: loss 0.036223
[epoch15, step1091]: loss 0.036054
[epoch15, step1092]: loss 0.033450
[epoch15, step1093]: loss 0.033325
[epoch15, step1094]: loss 0.036209
[epoch15, step1095]: loss 0.034424
[epoch15, step1096]: loss 0.034389
[epoch15, step1097]: loss 0.032859
[epoch15, step1098]: loss 0.035093
[epoch15, step1099]: loss 0.034656
[epoch15, step1100]: loss 0.037453
[epoch15, step1101]: loss 0.034458
[epoch15, step1102]: loss 0.033530
[epoch15, step1103]: loss 0.035853
[epoch15, step1104]: loss 0.034208
[epoch15, step1105]: loss 0.034961
[epoch15, step1106]: loss 0.032407
[epoch15, step1107]: loss 0.034640
[epoch15, step1108]: loss 0.034364
[epoch15, step1109]: loss 0.036649
[epoch15, step1110]: loss 0.034490
[epoch15, step1111]: loss 0.033143
[epoch15, step1112]: loss 0.036204
[epoch15, step1113]: loss 0.034747
[epoch15, step1114]: loss 0.035264
[epoch15, step1115]: loss 0.032671
[epoch15, step1116]: loss 0.035352
[epoch15, step1117]: loss 0.036254
[epoch15, step1118]: loss 0.036007
[epoch15, step1119]: loss 0.034870
[epoch15, step1120]: loss 0.032748
[epoch15, step1121]: loss 0.036340
[epoch15, step1122]: loss 0.033872
[epoch15, step1123]: loss 0.034441
[epoch15, step1124]: loss 0.034627
[epoch15, step1125]: loss 0.035427
[epoch15, step1126]: loss 0.037357
[epoch15, step1127]: loss 0.036003
[epoch15, step1128]: loss 0.034062
[epoch15, step1129]: loss 0.033128
[epoch15, step1130]: loss 0.036764
[epoch15, step1131]: loss 0.035491
[epoch15, step1132]: loss 0.036522
[epoch15, step1133]: loss 0.034359
[epoch15, step1134]: loss 0.035064
[epoch15, step1135]: loss 0.036546
[epoch15, step1136]: loss 0.036687
[epoch15, step1137]: loss 0.033901
[epoch15, step1138]: loss 0.032798
[epoch15, step1139]: loss 0.036025
[epoch15, step1140]: loss 0.034535
[epoch15, step1141]: loss 0.034115
[epoch15, step1142]: loss 0.033086
[epoch15, step1143]: loss 0.034796
[epoch15, step1144]: loss 0.035547
[epoch15, step1145]: loss 0.035619
[epoch15, step1146]: loss 0.033072
[epoch15, step1147]: loss 0.034086
[epoch15, step1148]: loss 0.035919
[epoch15, step1149]: loss 0.034436
[epoch15, step1150]: loss 0.034336
[epoch15, step1151]: loss 0.033799
[epoch15, step1152]: loss 0.035667
[epoch15, step1153]: loss 0.034652
[epoch15, step1154]: loss 0.037274
[epoch15, step1155]: loss 0.032823
[epoch15, step1156]: loss 0.032563
[epoch15, step1157]: loss 0.036533
[epoch15, step1158]: loss 0.035175
[epoch15, step1159]: loss 0.035125
[epoch15, step1160]: loss 0.034632
[epoch15, step1161]: loss 0.035737
[epoch15, step1162]: loss 0.034912
[epoch15, step1163]: loss 0.036113
[epoch15, step1164]: loss 0.033371
[epoch15, step1165]: loss 0.034223
[epoch15, step1166]: loss 0.036765
[epoch15, step1167]: loss 0.035053
[epoch15, step1168]: loss 0.034862
[epoch15, step1169]: loss 0.033098
[epoch15, step1170]: loss 0.034637
[epoch15, step1171]: loss 0.035657
[epoch15, step1172]: loss 0.036135
[epoch15, step1173]: loss 0.032948
[epoch15, step1174]: loss 0.033421
[epoch15, step1175]: loss 0.036756
[epoch15, step1176]: loss 0.034018
[epoch15, step1177]: loss 0.035062
[epoch15, step1178]: loss 0.033383
[epoch15, step1179]: loss 0.034841
[epoch15, step1180]: loss 0.034612
[epoch15, step1181]: loss 0.037108
[epoch15, step1182]: loss 0.033279
[epoch15, step1183]: loss 0.033183
[epoch15, step1184]: loss 0.036607
[epoch15, step1185]: loss 0.035084
[epoch15, step1186]: loss 0.034691
[epoch15, step1187]: loss 0.033553
[epoch15, step1188]: loss 0.034320
[epoch15, step1189]: loss 0.034145
[epoch15, step1190]: loss 0.035617
[epoch15, step1191]: loss 0.034607
[epoch15, step1192]: loss 0.033023
[epoch15, step1193]: loss 0.035754
[epoch15, step1194]: loss 0.034360
[epoch15, step1195]: loss 0.034891
[epoch15, step1196]: loss 0.032573
[epoch15, step1197]: loss 0.034969
[epoch15, step1198]: loss 0.035949
[epoch15, step1199]: loss 0.036197
[epoch15, step1200]: loss 0.032987
[epoch15, step1201]: loss 0.033841
[epoch15, step1202]: loss 0.038189
[epoch15, step1203]: loss 0.034741
[epoch15, step1204]: loss 0.034184
[epoch15, step1205]: loss 0.032658
[epoch15, step1206]: loss 0.034438
[epoch15, step1207]: loss 0.035686
[epoch15, step1208]: loss 0.036876
[epoch15, step1209]: loss 0.032241
[epoch15, step1210]: loss 0.034065
[epoch15, step1211]: loss 0.036165
[epoch15, step1212]: loss 0.034511
[epoch15, step1213]: loss 0.035139
[epoch15, step1214]: loss 0.032868
[epoch15, step1215]: loss 0.035776
[epoch15, step1216]: loss 0.034551
[epoch15, step1217]: loss 0.036255
[epoch15, step1218]: loss 0.032779
[epoch15, step1219]: loss 0.033520
[epoch15, step1220]: loss 0.035977
[epoch15, step1221]: loss 0.035076
[epoch15, step1222]: loss 0.035122
[epoch15, step1223]: loss 0.033388
[epoch15, step1224]: loss 0.035434
[epoch15, step1225]: loss 0.034752
[epoch15, step1226]: loss 0.035479
[epoch15, step1227]: loss 0.033238
[epoch15, step1228]: loss 0.032218
[epoch15, step1229]: loss 0.035734
[epoch15, step1230]: loss 0.034686
[epoch15, step1231]: loss 0.034588
[epoch15, step1232]: loss 0.035312
[epoch15, step1233]: loss 0.033970
[epoch15, step1234]: loss 0.034447
[epoch15, step1235]: loss 0.036685
[epoch15, step1236]: loss 0.033892
[epoch15, step1237]: loss 0.033003
[epoch15, step1238]: loss 0.035888
[epoch15, step1239]: loss 0.035138
[epoch15, step1240]: loss 0.035214
[epoch15, step1241]: loss 0.034065
[epoch15, step1242]: loss 0.034506
[epoch15, step1243]: loss 0.034540
[epoch15, step1244]: loss 0.036177
[epoch15, step1245]: loss 0.033782
[epoch15, step1246]: loss 0.033522
[epoch15, step1247]: loss 0.035243
[epoch15, step1248]: loss 0.035261
[epoch15, step1249]: loss 0.035203
[epoch15, step1250]: loss 0.032952
[epoch15, step1251]: loss 0.035496
[epoch15, step1252]: loss 0.036569
[epoch15, step1253]: loss 0.036930
[epoch15, step1254]: loss 0.033069
[epoch15, step1255]: loss 0.033292
[epoch15, step1256]: loss 0.037516
[epoch15, step1257]: loss 0.036126
[epoch15, step1258]: loss 0.034711
[epoch15, step1259]: loss 0.033419
[epoch15, step1260]: loss 0.034815
[epoch15, step1261]: loss 0.034432
[epoch15, step1262]: loss 0.035899
[epoch15, step1263]: loss 0.033934
[epoch15, step1264]: loss 0.033860
[epoch15, step1265]: loss 0.035864
[epoch15, step1266]: loss 0.033868
[epoch15, step1267]: loss 0.035047
[epoch15, step1268]: loss 0.033506
[epoch15, step1269]: loss 0.034710
[epoch15, step1270]: loss 0.035146
[epoch15, step1271]: loss 0.036669
[epoch15, step1272]: loss 0.033380
[epoch15, step1273]: loss 0.032916
[epoch15, step1274]: loss 0.036735
[epoch15, step1275]: loss 0.035301
[epoch15, step1276]: loss 0.034534
[epoch15, step1277]: loss 0.033185
[epoch15, step1278]: loss 0.035398
[epoch15, step1279]: loss 0.035338
[epoch15, step1280]: loss 0.035784
[epoch15, step1281]: loss 0.033067
[epoch15, step1282]: loss 0.033012
[epoch15, step1283]: loss 0.035672
[epoch15, step1284]: loss 0.034438
[epoch15, step1285]: loss 0.034683
[epoch15, step1286]: loss 0.032767
[epoch15, step1287]: loss 0.035855
[epoch15, step1288]: loss 0.035812
[epoch15, step1289]: loss 0.037616
[epoch15, step1290]: loss 0.033905
[epoch15, step1291]: loss 0.033304
[epoch15, step1292]: loss 0.036923
[epoch15, step1293]: loss 0.034967
[epoch15, step1294]: loss 0.035624
[epoch15, step1295]: loss 0.033265
[epoch15, step1296]: loss 0.035218
[epoch15, step1297]: loss 0.035864
[epoch15, step1298]: loss 0.037196
[epoch15, step1299]: loss 0.033716
[epoch15, step1300]: loss 0.033351
[epoch15, step1301]: loss 0.036020
[epoch15, step1302]: loss 0.034899
[epoch15, step1303]: loss 0.034754
[epoch15, step1304]: loss 0.032671
[epoch15, step1305]: loss 0.035326
[epoch15, step1306]: loss 0.034882
[epoch15, step1307]: loss 0.036084
[epoch15, step1308]: loss 0.033884
[epoch15, step1309]: loss 0.032361
[epoch15, step1310]: loss 0.035890
[epoch15, step1311]: loss 0.034531
[epoch15, step1312]: loss 0.035874
[epoch15, step1313]: loss 0.033042
[epoch15, step1314]: loss 0.034605
[epoch15, step1315]: loss 0.034576
[epoch15, step1316]: loss 0.037682
[epoch15, step1317]: loss 0.033078
[epoch15, step1318]: loss 0.033263
[epoch15, step1319]: loss 0.036035
[epoch15, step1320]: loss 0.034648
[epoch15, step1321]: loss 0.034872
[epoch15, step1322]: loss 0.033581
[epoch15, step1323]: loss 0.034781
[epoch15, step1324]: loss 0.034668
[epoch15, step1325]: loss 0.035380
[epoch15, step1326]: loss 0.033333
[epoch15, step1327]: loss 0.032197
[epoch15, step1328]: loss 0.036994
[epoch15, step1329]: loss 0.034684
[epoch15, step1330]: loss 0.034487
[epoch15, step1331]: loss 0.033121
[epoch15, step1332]: loss 0.035348
[epoch15, step1333]: loss 0.034979
[epoch15, step1334]: loss 0.036312
[epoch15, step1335]: loss 0.035697
[epoch15, step1336]: loss 0.032747
[epoch15, step1337]: loss 0.036006
[epoch15, step1338]: loss 0.034946
[epoch15, step1339]: loss 0.034682
[epoch15, step1340]: loss 0.032929
[epoch15, step1341]: loss 0.034551
[epoch15, step1342]: loss 0.034235
[epoch15, step1343]: loss 0.036029
[epoch15, step1344]: loss 0.033271
[epoch15, step1345]: loss 0.032611
[epoch15, step1346]: loss 0.035796
[epoch15, step1347]: loss 0.035125
[epoch15, step1348]: loss 0.034636
[epoch15, step1349]: loss 0.033637
[epoch15, step1350]: loss 0.035036
[epoch15, step1351]: loss 0.034112
[epoch15, step1352]: loss 0.035731
[epoch15, step1353]: loss 0.033383
[epoch15, step1354]: loss 0.032791
[epoch15, step1355]: loss 0.036908
[epoch15, step1356]: loss 0.034143
[epoch15, step1357]: loss 0.035137
[epoch15, step1358]: loss 0.032112
[epoch15, step1359]: loss 0.033984
[epoch15, step1360]: loss 0.035789
[epoch15, step1361]: loss 0.036404
[epoch15, step1362]: loss 0.034094
[epoch15, step1363]: loss 0.033100
[epoch15, step1364]: loss 0.036040
[epoch15, step1365]: loss 0.034781
[epoch15, step1366]: loss 0.035070
[epoch15, step1367]: loss 0.033420
[epoch15, step1368]: loss 0.035377
[epoch15, step1369]: loss 0.035014
[epoch15, step1370]: loss 0.036962
[epoch15, step1371]: loss 0.033736
[epoch15, step1372]: loss 0.032601
[epoch15, step1373]: loss 0.035889
[epoch15, step1374]: loss 0.034881
[epoch15, step1375]: loss 0.035594
[epoch15, step1376]: loss 0.032645
[epoch15, step1377]: loss 0.034653
[epoch15, step1378]: loss 0.034441
[epoch15, step1379]: loss 0.035356
[epoch15, step1380]: loss 0.033763
[epoch15, step1381]: loss 0.032270
[epoch15, step1382]: loss 0.035961
[epoch15, step1383]: loss 0.033982
[epoch15, step1384]: loss 0.034794
[epoch15, step1385]: loss 0.032683
[epoch15, step1386]: loss 0.034748
[epoch15, step1387]: loss 0.035002
[epoch15, step1388]: loss 0.035445
[epoch15, step1389]: loss 0.032626
[epoch15, step1390]: loss 0.032924
[epoch15, step1391]: loss 0.035731
[epoch15, step1392]: loss 0.034338
[epoch15, step1393]: loss 0.034822
[epoch15, step1394]: loss 0.033777
[epoch15, step1395]: loss 0.034996
[epoch15, step1396]: loss 0.034645
[epoch15, step1397]: loss 0.034943
[epoch15, step1398]: loss 0.032744
[epoch15, step1399]: loss 0.033828
[epoch15, step1400]: loss 0.036634
[epoch15, step1401]: loss 0.034123
[epoch15, step1402]: loss 0.034342
[epoch15, step1403]: loss 0.032304
[epoch15, step1404]: loss 0.034453
[epoch15, step1405]: loss 0.034131
[epoch15, step1406]: loss 0.036271
[epoch15, step1407]: loss 0.035000
[epoch15, step1408]: loss 0.032807
[epoch15, step1409]: loss 0.036461
[epoch15, step1410]: loss 0.034259
[epoch15, step1411]: loss 0.034070
[epoch15, step1412]: loss 0.032456
[epoch15, step1413]: loss 0.034270
[epoch15, step1414]: loss 0.033796
[epoch15, step1415]: loss 0.035719
[epoch15, step1416]: loss 0.034062
[epoch15, step1417]: loss 0.033963
[epoch15, step1418]: loss 0.036441
[epoch15, step1419]: loss 0.035194
[epoch15, step1420]: loss 0.035015
[epoch15, step1421]: loss 0.033151
[epoch15, step1422]: loss 0.035007
[epoch15, step1423]: loss 0.034751
[epoch15, step1424]: loss 0.035486
[epoch15, step1425]: loss 0.034150
[epoch15, step1426]: loss 0.033323
[epoch15, step1427]: loss 0.036907
[epoch15, step1428]: loss 0.036340
[epoch15, step1429]: loss 0.034687
[epoch15, step1430]: loss 0.033381
[epoch15, step1431]: loss 0.035163
[epoch15, step1432]: loss 0.034414
[epoch15, step1433]: loss 0.035661
[epoch15, step1434]: loss 0.032981
[epoch15, step1435]: loss 0.033482
[epoch15, step1436]: loss 0.037126
[epoch15, step1437]: loss 0.034493
[epoch15, step1438]: loss 0.036004
[epoch15, step1439]: loss 0.033319
[epoch15, step1440]: loss 0.034353
[epoch15, step1441]: loss 0.035114
[epoch15, step1442]: loss 0.035825
[epoch15, step1443]: loss 0.033403
[epoch15, step1444]: loss 0.032131
[epoch15, step1445]: loss 0.035971
[epoch15, step1446]: loss 0.034318
[epoch15, step1447]: loss 0.035354
[epoch15, step1448]: loss 0.032821
[epoch15, step1449]: loss 0.034128
[epoch15, step1450]: loss 0.035108
[epoch15, step1451]: loss 0.036002
[epoch15, step1452]: loss 0.032921
[epoch15, step1453]: loss 0.034548
[epoch15, step1454]: loss 0.037279
[epoch15, step1455]: loss 0.035180
[epoch15, step1456]: loss 0.035229
[epoch15, step1457]: loss 0.033740
[epoch15, step1458]: loss 0.034905
[epoch15, step1459]: loss 0.035521
[epoch15, step1460]: loss 0.036021
[epoch15, step1461]: loss 0.033529
[epoch15, step1462]: loss 0.033321
[epoch15, step1463]: loss 0.037247
[epoch15, step1464]: loss 0.035032
[epoch15, step1465]: loss 0.034224
[epoch15, step1466]: loss 0.032709
[epoch15, step1467]: loss 0.034453
[epoch15, step1468]: loss 0.034707
[epoch15, step1469]: loss 0.036420
[epoch15, step1470]: loss 0.033508
[epoch15, step1471]: loss 0.033164
[epoch15, step1472]: loss 0.036519
[epoch15, step1473]: loss 0.034708
[epoch15, step1474]: loss 0.035404
[epoch15, step1475]: loss 0.032742
[epoch15, step1476]: loss 0.035760
[epoch15, step1477]: loss 0.034599
[epoch15, step1478]: loss 0.035527
[epoch15, step1479]: loss 0.033045
[epoch15, step1480]: loss 0.032629
[epoch15, step1481]: loss 0.035996
[epoch15, step1482]: loss 0.034351
[epoch15, step1483]: loss 0.034472
[epoch15, step1484]: loss 0.033052
[epoch15, step1485]: loss 0.034533
[epoch15, step1486]: loss 0.033963
[epoch15, step1487]: loss 0.035803
[epoch15, step1488]: loss 0.032882
[epoch15, step1489]: loss 0.033226
[epoch15, step1490]: loss 0.036323
[epoch15, step1491]: loss 0.034839
[epoch15, step1492]: loss 0.034132
[epoch15, step1493]: loss 0.033193
[epoch15, step1494]: loss 0.034641
[epoch15, step1495]: loss 0.034818
[epoch15, step1496]: loss 0.036919
[epoch15, step1497]: loss 0.033598
[epoch15, step1498]: loss 0.033130
[epoch15, step1499]: loss 0.035731
[epoch15, step1500]: loss 0.034235
[epoch15, step1501]: loss 0.034257
[epoch15, step1502]: loss 0.032277
[epoch15, step1503]: loss 0.035200
[epoch15, step1504]: loss 0.034571
[epoch15, step1505]: loss 0.036713
[epoch15, step1506]: loss 0.032542
[epoch15, step1507]: loss 0.032971
[epoch15, step1508]: loss 0.037199
[epoch15, step1509]: loss 0.033824
[epoch15, step1510]: loss 0.034137
[epoch15, step1511]: loss 0.033234
[epoch15, step1512]: loss 0.034447
[epoch15, step1513]: loss 0.034540
[epoch15, step1514]: loss 0.035500
[epoch15, step1515]: loss 0.033319
[epoch15, step1516]: loss 0.032763

[epoch15]: avg loss 0.032237

[epoch16, step1]: loss 0.042420
[epoch16, step2]: loss 0.035582
[epoch16, step3]: loss 0.035679
[epoch16, step4]: loss 0.033682
[epoch16, step5]: loss 0.033673
[epoch16, step6]: loss 0.036143
[epoch16, step7]: loss 0.034524
[epoch16, step8]: loss 0.036463
[epoch16, step9]: loss 0.032339
[epoch16, step10]: loss 0.034188
[epoch16, step11]: loss 0.036108
[epoch16, step12]: loss 0.035443
[epoch16, step13]: loss 0.033242
[epoch16, step14]: loss 0.032810
[epoch16, step15]: loss 0.035817
[epoch16, step16]: loss 0.033772
[epoch16, step17]: loss 0.036795
[epoch16, step18]: loss 0.033074
[epoch16, step19]: loss 0.033166
[epoch16, step20]: loss 0.036226
[epoch16, step21]: loss 0.035620
[epoch16, step22]: loss 0.032925
[epoch16, step23]: loss 0.033669
[epoch16, step24]: loss 0.035704
[epoch16, step25]: loss 0.032856
[epoch16, step26]: loss 0.036100
[epoch16, step27]: loss 0.032327
[epoch16, step28]: loss 0.034842
[epoch16, step29]: loss 0.036423
[epoch16, step30]: loss 0.036782
[epoch16, step31]: loss 0.032749
[epoch16, step32]: loss 0.034061
[epoch16, step33]: loss 0.036223
[epoch16, step34]: loss 0.033995
[epoch16, step35]: loss 0.036472
[epoch16, step36]: loss 0.033161
[epoch16, step37]: loss 0.032960
[epoch16, step38]: loss 0.036234
[epoch16, step39]: loss 0.036140
[epoch16, step40]: loss 0.033486
[epoch16, step41]: loss 0.033071
[epoch16, step42]: loss 0.035898
[epoch16, step43]: loss 0.032919
[epoch16, step44]: loss 0.037266
[epoch16, step45]: loss 0.033375
[epoch16, step46]: loss 0.033992
[epoch16, step47]: loss 0.035475
[epoch16, step48]: loss 0.035844
[epoch16, step49]: loss 0.033143
[epoch16, step50]: loss 0.033459
[epoch16, step51]: loss 0.036039
[epoch16, step52]: loss 0.033757
[epoch16, step53]: loss 0.037367
[epoch16, step54]: loss 0.032547
[epoch16, step55]: loss 0.034144
[epoch16, step56]: loss 0.036869
[epoch16, step57]: loss 0.035593
[epoch16, step58]: loss 0.033485
[epoch16, step59]: loss 0.033125
[epoch16, step60]: loss 0.035966
[epoch16, step61]: loss 0.032909
[epoch16, step62]: loss 0.035656
[epoch16, step63]: loss 0.033190
[epoch16, step64]: loss 0.033061
[epoch16, step65]: loss 0.036031
[epoch16, step66]: loss 0.035824
[epoch16, step67]: loss 0.033373
[epoch16, step68]: loss 0.033173
[epoch16, step69]: loss 0.036498
[epoch16, step70]: loss 0.033042
[epoch16, step71]: loss 0.035908
[epoch16, step72]: loss 0.032637
[epoch16, step73]: loss 0.033877
[epoch16, step74]: loss 0.035251
[epoch16, step75]: loss 0.036576
[epoch16, step76]: loss 0.033570
[epoch16, step77]: loss 0.033700
[epoch16, step78]: loss 0.036638
[epoch16, step79]: loss 0.033033
[epoch16, step80]: loss 0.036869
[epoch16, step81]: loss 0.032477
[epoch16, step82]: loss 0.033696
[epoch16, step83]: loss 0.036041
[epoch16, step84]: loss 0.035538
[epoch16, step85]: loss 0.034555
[epoch16, step86]: loss 0.033398
[epoch16, step87]: loss 0.037453
[epoch16, step88]: loss 0.032732
[epoch16, step89]: loss 0.035893
[epoch16, step90]: loss 0.034384
[epoch16, step91]: loss 0.032816
[epoch16, step92]: loss 0.035711
[epoch16, step93]: loss 0.037151
[epoch16, step94]: loss 0.032630
[epoch16, step95]: loss 0.033383
[epoch16, step96]: loss 0.035947
[epoch16, step97]: loss 0.033530
[epoch16, step98]: loss 0.035914
[epoch16, step99]: loss 0.033523
[epoch16, step100]: loss 0.032866
[epoch16, step101]: loss 0.036704
[epoch16, step102]: loss 0.036880
[epoch16, step103]: loss 0.033036
[epoch16, step104]: loss 0.032373
[epoch16, step105]: loss 0.035874
[epoch16, step106]: loss 0.032563
[epoch16, step107]: loss 0.036604
[epoch16, step108]: loss 0.032841
[epoch16, step109]: loss 0.032483
[epoch16, step110]: loss 0.036585
[epoch16, step111]: loss 0.035650
[epoch16, step112]: loss 0.032678
[epoch16, step113]: loss 0.033707
[epoch16, step114]: loss 0.036287
[epoch16, step115]: loss 0.033136
[epoch16, step116]: loss 0.036980
[epoch16, step117]: loss 0.033072
[epoch16, step118]: loss 0.034353
[epoch16, step119]: loss 0.035680
[epoch16, step120]: loss 0.036876
[epoch16, step121]: loss 0.033113
[epoch16, step122]: loss 0.032414
[epoch16, step123]: loss 0.036413
[epoch16, step124]: loss 0.033033
[epoch16, step125]: loss 0.036835
[epoch16, step126]: loss 0.033580
[epoch16, step127]: loss 0.033493
[epoch16, step128]: loss 0.035966
[epoch16, step129]: loss 0.036328
[epoch16, step130]: loss 0.033495
[epoch16, step131]: loss 0.032973
[epoch16, step132]: loss 0.035683
[epoch16, step133]: loss 0.033149
[epoch16, step134]: loss 0.035623
[epoch16, step135]: loss 0.033275
[epoch16, step136]: loss 0.034583
[epoch16, step137]: loss 0.036463
[epoch16, step138]: loss 0.036292
[epoch16, step139]: loss 0.033081
[epoch16, step140]: loss 0.033327
[epoch16, step141]: loss 0.036450
[epoch16, step142]: loss 0.032860
[epoch16, step143]: loss 0.035768
[epoch16, step144]: loss 0.034536
[epoch16, step145]: loss 0.033497
[epoch16, step146]: loss 0.036264
[epoch16, step147]: loss 0.037112
[epoch16, step148]: loss 0.032790
[epoch16, step149]: loss 0.032985
[epoch16, step150]: loss 0.035523
[epoch16, step151]: loss 0.033047
[epoch16, step152]: loss 0.035882
[epoch16, step153]: loss 0.032775
[epoch16, step154]: loss 0.033206
[epoch16, step155]: loss 0.036522
[epoch16, step156]: loss 0.034987
[epoch16, step157]: loss 0.032891
[epoch16, step158]: loss 0.033670
[epoch16, step159]: loss 0.036022
[epoch16, step160]: loss 0.033529
[epoch16, step161]: loss 0.036770
[epoch16, step162]: loss 0.033260
[epoch16, step163]: loss 0.033014
[epoch16, step164]: loss 0.036638
[epoch16, step165]: loss 0.036196
[epoch16, step166]: loss 0.033113
[epoch16, step167]: loss 0.033333
[epoch16, step168]: loss 0.036900
[epoch16, step169]: loss 0.033223
[epoch16, step170]: loss 0.036549
[epoch16, step171]: loss 0.032873
[epoch16, step172]: loss 0.033322
[epoch16, step173]: loss 0.036204
[epoch16, step174]: loss 0.035265
[epoch16, step175]: loss 0.034186
[epoch16, step176]: loss 0.033471
[epoch16, step177]: loss 0.036169
[epoch16, step178]: loss 0.033275
[epoch16, step179]: loss 0.036041
[epoch16, step180]: loss 0.033287
[epoch16, step181]: loss 0.033093
[epoch16, step182]: loss 0.035901
[epoch16, step183]: loss 0.036123
[epoch16, step184]: loss 0.034407
[epoch16, step185]: loss 0.033371
[epoch16, step186]: loss 0.035890
[epoch16, step187]: loss 0.032818
[epoch16, step188]: loss 0.036069
[epoch16, step189]: loss 0.033350
[epoch16, step190]: loss 0.033344
[epoch16, step191]: loss 0.036521
[epoch16, step192]: loss 0.037039
[epoch16, step193]: loss 0.032402
[epoch16, step194]: loss 0.031821
[epoch16, step195]: loss 0.036575
[epoch16, step196]: loss 0.033948
[epoch16, step197]: loss 0.036222
[epoch16, step198]: loss 0.032541
[epoch16, step199]: loss 0.034476
[epoch16, step200]: loss 0.036908
[epoch16, step201]: loss 0.036764
[epoch16, step202]: loss 0.033310
[epoch16, step203]: loss 0.033792
[epoch16, step204]: loss 0.036613
[epoch16, step205]: loss 0.032847
[epoch16, step206]: loss 0.035358
[epoch16, step207]: loss 0.032165
[epoch16, step208]: loss 0.034012
[epoch16, step209]: loss 0.036536
[epoch16, step210]: loss 0.036901
[epoch16, step211]: loss 0.033636
[epoch16, step212]: loss 0.033614
[epoch16, step213]: loss 0.036143
[epoch16, step214]: loss 0.033371
[epoch16, step215]: loss 0.036204
[epoch16, step216]: loss 0.033385
[epoch16, step217]: loss 0.033589
[epoch16, step218]: loss 0.036095
[epoch16, step219]: loss 0.036063
[epoch16, step220]: loss 0.033980
[epoch16, step221]: loss 0.033437
[epoch16, step222]: loss 0.036856
[epoch16, step223]: loss 0.033661
[epoch16, step224]: loss 0.036154
[epoch16, step225]: loss 0.032758
[epoch16, step226]: loss 0.033149
[epoch16, step227]: loss 0.035190
[epoch16, step228]: loss 0.036515
[epoch16, step229]: loss 0.032197
[epoch16, step230]: loss 0.032900
[epoch16, step231]: loss 0.036194
[epoch16, step232]: loss 0.033742
[epoch16, step233]: loss 0.035792
[epoch16, step234]: loss 0.032853
[epoch16, step235]: loss 0.033501
[epoch16, step236]: loss 0.035904
[epoch16, step237]: loss 0.035897
[epoch16, step238]: loss 0.032979
[epoch16, step239]: loss 0.032716
[epoch16, step240]: loss 0.035757
[epoch16, step241]: loss 0.033546
[epoch16, step242]: loss 0.036355
[epoch16, step243]: loss 0.034709
[epoch16, step244]: loss 0.032828
[epoch16, step245]: loss 0.035813
[epoch16, step246]: loss 0.035507
[epoch16, step247]: loss 0.033951
[epoch16, step248]: loss 0.032259
[epoch16, step249]: loss 0.035489
[epoch16, step250]: loss 0.033169
[epoch16, step251]: loss 0.036872
[epoch16, step252]: loss 0.033599
[epoch16, step253]: loss 0.032493
[epoch16, step254]: loss 0.035530
[epoch16, step255]: loss 0.035773
[epoch16, step256]: loss 0.033406
[epoch16, step257]: loss 0.032530
[epoch16, step258]: loss 0.036945
[epoch16, step259]: loss 0.033879
[epoch16, step260]: loss 0.035517
[epoch16, step261]: loss 0.034116
[epoch16, step262]: loss 0.033540
[epoch16, step263]: loss 0.035636
[epoch16, step264]: loss 0.035057
[epoch16, step265]: loss 0.032939
[epoch16, step266]: loss 0.032303
[epoch16, step267]: loss 0.036246
[epoch16, step268]: loss 0.033381
[epoch16, step269]: loss 0.035746
[epoch16, step270]: loss 0.033274
[epoch16, step271]: loss 0.032888
[epoch16, step272]: loss 0.035636
[epoch16, step273]: loss 0.035553
[epoch16, step274]: loss 0.033487
[epoch16, step275]: loss 0.032577
[epoch16, step276]: loss 0.036026
[epoch16, step277]: loss 0.033605
[epoch16, step278]: loss 0.036619
[epoch16, step279]: loss 0.032534
[epoch16, step280]: loss 0.033358
[epoch16, step281]: loss 0.036153
[epoch16, step282]: loss 0.036859
[epoch16, step283]: loss 0.033328
[epoch16, step284]: loss 0.032793
[epoch16, step285]: loss 0.036750
[epoch16, step286]: loss 0.033323
[epoch16, step287]: loss 0.036479
[epoch16, step288]: loss 0.032656
[epoch16, step289]: loss 0.034657
[epoch16, step290]: loss 0.035866
[epoch16, step291]: loss 0.035660
[epoch16, step292]: loss 0.032957
[epoch16, step293]: loss 0.032521
[epoch16, step294]: loss 0.035504
[epoch16, step295]: loss 0.032902
[epoch16, step296]: loss 0.037242
[epoch16, step297]: loss 0.032932
[epoch16, step298]: loss 0.033874
[epoch16, step299]: loss 0.035756
[epoch16, step300]: loss 0.036506
[epoch16, step301]: loss 0.033582
[epoch16, step302]: loss 0.034009
[epoch16, step303]: loss 0.036588
[epoch16, step304]: loss 0.032955
[epoch16, step305]: loss 0.035296
[epoch16, step306]: loss 0.033393
[epoch16, step307]: loss 0.032810
[epoch16, step308]: loss 0.036553
[epoch16, step309]: loss 0.036101
[epoch16, step310]: loss 0.032843
[epoch16, step311]: loss 0.033065
[epoch16, step312]: loss 0.036756
[epoch16, step313]: loss 0.032902
[epoch16, step314]: loss 0.035780
[epoch16, step315]: loss 0.034223
[epoch16, step316]: loss 0.032977
[epoch16, step317]: loss 0.036629
[epoch16, step318]: loss 0.036664
[epoch16, step319]: loss 0.032753
[epoch16, step320]: loss 0.032306
[epoch16, step321]: loss 0.035266
[epoch16, step322]: loss 0.033059
[epoch16, step323]: loss 0.035270
[epoch16, step324]: loss 0.034449
[epoch16, step325]: loss 0.032919
[epoch16, step326]: loss 0.035511
[epoch16, step327]: loss 0.035121
[epoch16, step328]: loss 0.033445
[epoch16, step329]: loss 0.032600
[epoch16, step330]: loss 0.035626
[epoch16, step331]: loss 0.033417
[epoch16, step332]: loss 0.035152
[epoch16, step333]: loss 0.032811
[epoch16, step334]: loss 0.033464
[epoch16, step335]: loss 0.036113
[epoch16, step336]: loss 0.037384
[epoch16, step337]: loss 0.034214
[epoch16, step338]: loss 0.032317
[epoch16, step339]: loss 0.036415
[epoch16, step340]: loss 0.033920
[epoch16, step341]: loss 0.035573
[epoch16, step342]: loss 0.032065
[epoch16, step343]: loss 0.033939
[epoch16, step344]: loss 0.035882
[epoch16, step345]: loss 0.035638
[epoch16, step346]: loss 0.032490
[epoch16, step347]: loss 0.033172
[epoch16, step348]: loss 0.036105
[epoch16, step349]: loss 0.033946
[epoch16, step350]: loss 0.036049
[epoch16, step351]: loss 0.032069
[epoch16, step352]: loss 0.032648
[epoch16, step353]: loss 0.035717
[epoch16, step354]: loss 0.034425
[epoch16, step355]: loss 0.032418
[epoch16, step356]: loss 0.034899
[epoch16, step357]: loss 0.036049
[epoch16, step358]: loss 0.032154
[epoch16, step359]: loss 0.038765
[epoch16, step360]: loss 0.031781
[epoch16, step361]: loss 0.033241
[epoch16, step362]: loss 0.037426
[epoch16, step363]: loss 0.035208
[epoch16, step364]: loss 0.033131
[epoch16, step365]: loss 0.032955
[epoch16, step366]: loss 0.036701
[epoch16, step367]: loss 0.033665
[epoch16, step368]: loss 0.036651
[epoch16, step369]: loss 0.032747
[epoch16, step370]: loss 0.034133
[epoch16, step371]: loss 0.036412
[epoch16, step372]: loss 0.035506
[epoch16, step373]: loss 0.033238
[epoch16, step374]: loss 0.032065
[epoch16, step375]: loss 0.037036
[epoch16, step376]: loss 0.033510
[epoch16, step377]: loss 0.035850
[epoch16, step378]: loss 0.033012
[epoch16, step379]: loss 0.033471
[epoch16, step380]: loss 0.036660
[epoch16, step381]: loss 0.035750
[epoch16, step382]: loss 0.033299
[epoch16, step383]: loss 0.032579
[epoch16, step384]: loss 0.036442
[epoch16, step385]: loss 0.032674
[epoch16, step386]: loss 0.035753
[epoch16, step387]: loss 0.032585
[epoch16, step388]: loss 0.034158
[epoch16, step389]: loss 0.036029
[epoch16, step390]: loss 0.037233
[epoch16, step391]: loss 0.032300
[epoch16, step392]: loss 0.033991
[epoch16, step393]: loss 0.036237
[epoch16, step394]: loss 0.033296
[epoch16, step395]: loss 0.036474
[epoch16, step396]: loss 0.032904
[epoch16, step397]: loss 0.032954
[epoch16, step398]: loss 0.036023
[epoch16, step399]: loss 0.035151
[epoch16, step400]: loss 0.032818
[epoch16, step401]: loss 0.032151
[epoch16, step402]: loss 0.035585
[epoch16, step403]: loss 0.032835
[epoch16, step404]: loss 0.036045
[epoch16, step405]: loss 0.033129
[epoch16, step406]: loss 0.033457
[epoch16, step407]: loss 0.035904
[epoch16, step408]: loss 0.035253
[epoch16, step409]: loss 0.035318
[epoch16, step410]: loss 0.033605
[epoch16, step411]: loss 0.036094
[epoch16, step412]: loss 0.033645
[epoch16, step413]: loss 0.036273
[epoch16, step414]: loss 0.034382
[epoch16, step415]: loss 0.033395
[epoch16, step416]: loss 0.036331
[epoch16, step417]: loss 0.035645
[epoch16, step418]: loss 0.033722
[epoch16, step419]: loss 0.032043
[epoch16, step420]: loss 0.035878
[epoch16, step421]: loss 0.032472
[epoch16, step422]: loss 0.036256
[epoch16, step423]: loss 0.033036
[epoch16, step424]: loss 0.033365
[epoch16, step425]: loss 0.036050
[epoch16, step426]: loss 0.036317
[epoch16, step427]: loss 0.033875
[epoch16, step428]: loss 0.033088
[epoch16, step429]: loss 0.037565
[epoch16, step430]: loss 0.034168
[epoch16, step431]: loss 0.036535
[epoch16, step432]: loss 0.033431
[epoch16, step433]: loss 0.033380
[epoch16, step434]: loss 0.036244
[epoch16, step435]: loss 0.036170
[epoch16, step436]: loss 0.033895
[epoch16, step437]: loss 0.033563
[epoch16, step438]: loss 0.036221
[epoch16, step439]: loss 0.034375
[epoch16, step440]: loss 0.036027
[epoch16, step441]: loss 0.033067
[epoch16, step442]: loss 0.033446
[epoch16, step443]: loss 0.036394
[epoch16, step444]: loss 0.035427
[epoch16, step445]: loss 0.034017
[epoch16, step446]: loss 0.033215
[epoch16, step447]: loss 0.036096
[epoch16, step448]: loss 0.034381
[epoch16, step449]: loss 0.036117
[epoch16, step450]: loss 0.033624
[epoch16, step451]: loss 0.033612
[epoch16, step452]: loss 0.036071
[epoch16, step453]: loss 0.035826
[epoch16, step454]: loss 0.032876
[epoch16, step455]: loss 0.033930
[epoch16, step456]: loss 0.035493
[epoch16, step457]: loss 0.034515
[epoch16, step458]: loss 0.036249
[epoch16, step459]: loss 0.033917
[epoch16, step460]: loss 0.033485
[epoch16, step461]: loss 0.037470
[epoch16, step462]: loss 0.035074
[epoch16, step463]: loss 0.034640
[epoch16, step464]: loss 0.032759
[epoch16, step465]: loss 0.037319
[epoch16, step466]: loss 0.033150
[epoch16, step467]: loss 0.035496
[epoch16, step468]: loss 0.033258
[epoch16, step469]: loss 0.033325
[epoch16, step470]: loss 0.036184
[epoch16, step471]: loss 0.035771
[epoch16, step472]: loss 0.033305
[epoch16, step473]: loss 0.032229
[epoch16, step474]: loss 0.035408
[epoch16, step475]: loss 0.033915
[epoch16, step476]: loss 0.036822
[epoch16, step477]: loss 0.032985
[epoch16, step478]: loss 0.032512
[epoch16, step479]: loss 0.035878
[epoch16, step480]: loss 0.035422
[epoch16, step481]: loss 0.032466
[epoch16, step482]: loss 0.032491
[epoch16, step483]: loss 0.036646
[epoch16, step484]: loss 0.033972
[epoch16, step485]: loss 0.035945
[epoch16, step486]: loss 0.033331
[epoch16, step487]: loss 0.032881
[epoch16, step488]: loss 0.036683
[epoch16, step489]: loss 0.035186
[epoch16, step490]: loss 0.033690
[epoch16, step491]: loss 0.033145
[epoch16, step492]: loss 0.035615
[epoch16, step493]: loss 0.032874
[epoch16, step494]: loss 0.035624
[epoch16, step495]: loss 0.033706
[epoch16, step496]: loss 0.033348
[epoch16, step497]: loss 0.036114
[epoch16, step498]: loss 0.035655
[epoch16, step499]: loss 0.033069
[epoch16, step500]: loss 0.032928
[epoch16, step501]: loss 0.035955
[epoch16, step502]: loss 0.032742
[epoch16, step503]: loss 0.036792
[epoch16, step504]: loss 0.033232
[epoch16, step505]: loss 0.032464
[epoch16, step506]: loss 0.036466
[epoch16, step507]: loss 0.036470
[epoch16, step508]: loss 0.033701
[epoch16, step509]: loss 0.032491
[epoch16, step510]: loss 0.035864
[epoch16, step511]: loss 0.033532
[epoch16, step512]: loss 0.036117
[epoch16, step513]: loss 0.032972
[epoch16, step514]: loss 0.033185
[epoch16, step515]: loss 0.035964
[epoch16, step516]: loss 0.035556
[epoch16, step517]: loss 0.033010
[epoch16, step518]: loss 0.032986
[epoch16, step519]: loss 0.036259
[epoch16, step520]: loss 0.032878
[epoch16, step521]: loss 0.036106
[epoch16, step522]: loss 0.032730
[epoch16, step523]: loss 0.032661
[epoch16, step524]: loss 0.036556
[epoch16, step525]: loss 0.036990
[epoch16, step526]: loss 0.033389
[epoch16, step527]: loss 0.032518
[epoch16, step528]: loss 0.036826
[epoch16, step529]: loss 0.032955
[epoch16, step530]: loss 0.036314
[epoch16, step531]: loss 0.032604
[epoch16, step532]: loss 0.033821
[epoch16, step533]: loss 0.036618
[epoch16, step534]: loss 0.035678
[epoch16, step535]: loss 0.034018
[epoch16, step536]: loss 0.033037
[epoch16, step537]: loss 0.035720
[epoch16, step538]: loss 0.033989
[epoch16, step539]: loss 0.035982
[epoch16, step540]: loss 0.033758
[epoch16, step541]: loss 0.033273
[epoch16, step542]: loss 0.035979
[epoch16, step543]: loss 0.035357
[epoch16, step544]: loss 0.032893
[epoch16, step545]: loss 0.032836
[epoch16, step546]: loss 0.036919
[epoch16, step547]: loss 0.033262
[epoch16, step548]: loss 0.036471
[epoch16, step549]: loss 0.033585
[epoch16, step550]: loss 0.033260
[epoch16, step551]: loss 0.036661
[epoch16, step552]: loss 0.035390
[epoch16, step553]: loss 0.034135
[epoch16, step554]: loss 0.032281
[epoch16, step555]: loss 0.035581
[epoch16, step556]: loss 0.033091
[epoch16, step557]: loss 0.035395
[epoch16, step558]: loss 0.032841
[epoch16, step559]: loss 0.033157
[epoch16, step560]: loss 0.035812
[epoch16, step561]: loss 0.035665
[epoch16, step562]: loss 0.032770
[epoch16, step563]: loss 0.031752
[epoch16, step564]: loss 0.034716
[epoch16, step565]: loss 0.028208
[epoch16, step566]: loss 0.037508
[epoch16, step567]: loss 0.028255
[epoch16, step568]: loss 0.026909
[epoch16, step569]: loss 0.024415
[epoch16, step570]: loss 0.033712
[epoch16, step571]: loss 0.025632
[epoch16, step572]: loss 0.026076
[epoch16, step573]: loss 0.030182
[epoch16, step574]: loss 0.028750
[epoch16, step575]: loss 0.022101
[epoch16, step576]: loss 0.022048
[epoch16, step577]: loss 0.026254
[epoch16, step578]: loss 0.019549
[epoch16, step579]: loss 0.028746
[epoch16, step580]: loss 0.019877
[epoch16, step581]: loss 0.026999
[epoch16, step582]: loss 0.024987
[epoch16, step583]: loss 0.023464
[epoch16, step584]: loss 0.023722
[epoch16, step585]: loss 0.025887
[epoch16, step586]: loss 0.022228
[epoch16, step587]: loss 0.027860
[epoch16, step588]: loss 0.022667
[epoch16, step589]: loss 0.023281
[epoch16, step590]: loss 0.027583
[epoch16, step591]: loss 0.021121
[epoch16, step592]: loss 0.026262
[epoch16, step593]: loss 0.022340
[epoch16, step594]: loss 0.026030
[epoch16, step595]: loss 0.026416
[epoch16, step596]: loss 0.022852
[epoch16, step597]: loss 0.024152
[epoch16, step598]: loss 0.027372
[epoch16, step599]: loss 0.024850
[epoch16, step600]: loss 0.026141
[epoch16, step601]: loss 0.019608
[epoch16, step602]: loss 0.023072
[epoch16, step603]: loss 0.025779
[epoch16, step604]: loss 0.026066
[epoch16, step605]: loss 0.024826
[epoch16, step606]: loss 0.024866
[epoch16, step607]: loss 0.026576
[epoch16, step608]: loss 0.025286
[epoch16, step609]: loss 0.026409
[epoch16, step610]: loss 0.026373
[epoch16, step611]: loss 0.025943
[epoch16, step612]: loss 0.024992
[epoch16, step613]: loss 0.019855
[epoch16, step614]: loss 0.024607
[epoch16, step615]: loss 0.027339
[epoch16, step616]: loss 0.023710
[epoch16, step617]: loss 0.023129
[epoch16, step618]: loss 0.025615
[epoch16, step619]: loss 0.027478
[epoch16, step620]: loss 0.023386
[epoch16, step621]: loss 0.025763
[epoch16, step622]: loss 0.020492
[epoch16, step623]: loss 0.024480
[epoch16, step624]: loss 0.026099
[epoch16, step625]: loss 0.025488
[epoch16, step626]: loss 0.027469
[epoch16, step627]: loss 0.023367
[epoch16, step628]: loss 0.024176
[epoch16, step629]: loss 0.020351
[epoch16, step630]: loss 0.022222
[epoch16, step631]: loss 0.031636
[epoch16, step632]: loss 0.022284
[epoch16, step633]: loss 0.023855
[epoch16, step634]: loss 0.027233
[epoch16, step635]: loss 0.025112
[epoch16, step636]: loss 0.020684
[epoch16, step637]: loss 0.026821
[epoch16, step638]: loss 0.026216
[epoch16, step639]: loss 0.021815
[epoch16, step640]: loss 0.029174
[epoch16, step641]: loss 0.029937
[epoch16, step642]: loss 0.024453
[epoch16, step643]: loss 0.025133
[epoch16, step644]: loss 0.026109
[epoch16, step645]: loss 0.023313
[epoch16, step646]: loss 0.025484
[epoch16, step647]: loss 0.022416
[epoch16, step648]: loss 0.024007
[epoch16, step649]: loss 0.028405
[epoch16, step650]: loss 0.022192
[epoch16, step651]: loss 0.025922
[epoch16, step652]: loss 0.026109
[epoch16, step653]: loss 0.027722
[epoch16, step654]: loss 0.022290
[epoch16, step655]: loss 0.024125
[epoch16, step656]: loss 0.021771
[epoch16, step657]: loss 0.027210
[epoch16, step658]: loss 0.024422
[epoch16, step659]: loss 0.026303
[epoch16, step660]: loss 0.023265
[epoch16, step661]: loss 0.025821
[epoch16, step662]: loss 0.023919
[epoch16, step663]: loss 0.021137
[epoch16, step664]: loss 0.025077
[epoch16, step665]: loss 0.027526
[epoch16, step666]: loss 0.025983
[epoch16, step667]: loss 0.026187
[epoch16, step668]: loss 0.023089
[epoch16, step669]: loss 0.025938
[epoch16, step670]: loss 0.025873
[epoch16, step671]: loss 0.021082
[epoch16, step672]: loss 0.024490
[epoch16, step673]: loss 0.022999
[epoch16, step674]: loss 0.020719
[epoch16, step675]: loss 0.019926
[epoch16, step676]: loss 0.024011
[epoch16, step677]: loss 0.024842
[epoch16, step678]: loss 0.022139
[epoch16, step679]: loss 0.023373
[epoch16, step680]: loss 0.030356
[epoch16, step681]: loss 0.021041
[epoch16, step682]: loss 0.026071
[epoch16, step683]: loss 0.025930
[epoch16, step684]: loss 0.024906
[epoch16, step685]: loss 0.023998
[epoch16, step686]: loss 0.027123
[epoch16, step687]: loss 0.026671
[epoch16, step688]: loss 0.022707
[epoch16, step689]: loss 0.024510
[epoch16, step690]: loss 0.024782
[epoch16, step691]: loss 0.023910
[epoch16, step692]: loss 0.022516
[epoch16, step693]: loss 0.026949
[epoch16, step694]: loss 0.022094
[epoch16, step695]: loss 0.026264
[epoch16, step696]: loss 0.025356
[epoch16, step697]: loss 0.027265
[epoch16, step698]: loss 0.024172
[epoch16, step699]: loss 0.023015
[epoch16, step700]: loss 0.022232
[epoch16, step701]: loss 0.025400
[epoch16, step702]: loss 0.020989
[epoch16, step703]: loss 0.023439
[epoch16, step704]: loss 0.025097
[epoch16, step705]: loss 0.024098
[epoch16, step706]: loss 0.023293
[epoch16, step707]: loss 0.024921
[epoch16, step708]: loss 0.024670
[epoch16, step709]: loss 0.027351
[epoch16, step710]: loss 0.022928
[epoch16, step711]: loss 0.023942
[epoch16, step712]: loss 0.026476
[epoch16, step713]: loss 0.025855
[epoch16, step714]: loss 0.021040
[epoch16, step715]: loss 0.022639
[epoch16, step716]: loss 0.025898
[epoch16, step717]: loss 0.022849
[epoch16, step718]: loss 0.024843
[epoch16, step719]: loss 0.032984
[epoch16, step720]: loss 0.024285
[epoch16, step721]: loss 0.022714
[epoch16, step722]: loss 0.030407
[epoch16, step723]: loss 0.025819
[epoch16, step724]: loss 0.022560
[epoch16, step725]: loss 0.027964
[epoch16, step726]: loss 0.021887
[epoch16, step727]: loss 0.024325
[epoch16, step728]: loss 0.026234
[epoch16, step729]: loss 0.021687
[epoch16, step730]: loss 0.022656
[epoch16, step731]: loss 0.025881
[epoch16, step732]: loss 0.025656
[epoch16, step733]: loss 0.023694
[epoch16, step734]: loss 0.022161
[epoch16, step735]: loss 0.027194
[epoch16, step736]: loss 0.024523
[epoch16, step737]: loss 0.026290
[epoch16, step738]: loss 0.020087
[epoch16, step739]: loss 0.025489
[epoch16, step740]: loss 0.022228
[epoch16, step741]: loss 0.024684
[epoch16, step742]: loss 0.021882
[epoch16, step743]: loss 0.022683
[epoch16, step744]: loss 0.023334
[epoch16, step745]: loss 0.024266
[epoch16, step746]: loss 0.024328
[epoch16, step747]: loss 0.026931
[epoch16, step748]: loss 0.025136
[epoch16, step749]: loss 0.025249
[epoch16, step750]: loss 0.026752
[epoch16, step751]: loss 0.021611
[epoch16, step752]: loss 0.024708
[epoch16, step753]: loss 0.025648
[epoch16, step754]: loss 0.022576
[epoch16, step755]: loss 0.025603
[epoch16, step756]: loss 0.022965
[epoch16, step757]: loss 0.020311
[epoch16, step758]: loss 0.024569
[epoch16, step759]: loss 0.022271
[epoch16, step760]: loss 0.023526
[epoch16, step761]: loss 0.026702
[epoch16, step762]: loss 0.020873
[epoch16, step763]: loss 0.024754
[epoch16, step764]: loss 0.024062
[epoch16, step765]: loss 0.025137
[epoch16, step766]: loss 0.024358
[epoch16, step767]: loss 0.026669
[epoch16, step768]: loss 0.020347
[epoch16, step769]: loss 0.026341
[epoch16, step770]: loss 0.024652
[epoch16, step771]: loss 0.022488
[epoch16, step772]: loss 0.027852
[epoch16, step773]: loss 0.026060
[epoch16, step774]: loss 0.024067
[epoch16, step775]: loss 0.020735
[epoch16, step776]: loss 0.025154
[epoch16, step777]: loss 0.022227
[epoch16, step778]: loss 0.027561
[epoch16, step779]: loss 0.023573
[epoch16, step780]: loss 0.019907
[epoch16, step781]: loss 0.024673
[epoch16, step782]: loss 0.022159
[epoch16, step783]: loss 0.019607
[epoch16, step784]: loss 0.020672
[epoch16, step785]: loss 0.021782
[epoch16, step786]: loss 0.023378
[epoch16, step787]: loss 0.022527
[epoch16, step788]: loss 0.024651
[epoch16, step789]: loss 0.022803
[epoch16, step790]: loss 0.022521
[epoch16, step791]: loss 0.026924
[epoch16, step792]: loss 0.024815
[epoch16, step793]: loss 0.026167
[epoch16, step794]: loss 0.020232
[epoch16, step795]: loss 0.025593
[epoch16, step796]: loss 0.027727
[epoch16, step797]: loss 0.027017
[epoch16, step798]: loss 0.026251
[epoch16, step799]: loss 0.025361
[epoch16, step800]: loss 0.021102
[epoch16, step801]: loss 0.021858
[epoch16, step802]: loss 0.022335
[epoch16, step803]: loss 0.025747
[epoch16, step804]: loss 0.027538
[epoch16, step805]: loss 0.027964
[epoch16, step806]: loss 0.021236
[epoch16, step807]: loss 0.021262
[epoch16, step808]: loss 0.023050
[epoch16, step809]: loss 0.022113
[epoch16, step810]: loss 0.025366
[epoch16, step811]: loss 0.025129
[epoch16, step812]: loss 0.023847
[epoch16, step813]: loss 0.022634
[epoch16, step814]: loss 0.024534
[epoch16, step815]: loss 0.024598
[epoch16, step816]: loss 0.023279
[epoch16, step817]: loss 0.024133
[epoch16, step818]: loss 0.021636
[epoch16, step819]: loss 0.020597
[epoch16, step820]: loss 0.022917
[epoch16, step821]: loss 0.020835
[epoch16, step822]: loss 0.029672
[epoch16, step823]: loss 0.023581
[epoch16, step824]: loss 0.026575
[epoch16, step825]: loss 0.024625
[epoch16, step826]: loss 0.023619
[epoch16, step827]: loss 0.025792
[epoch16, step828]: loss 0.028155
[epoch16, step829]: loss 0.026506
[epoch16, step830]: loss 0.021752
[epoch16, step831]: loss 0.026197
[epoch16, step832]: loss 0.021147
[epoch16, step833]: loss 0.028595
[epoch16, step834]: loss 0.024917
[epoch16, step835]: loss 0.020605
[epoch16, step836]: loss 0.026548
[epoch16, step837]: loss 0.025191
[epoch16, step838]: loss 0.025880
[epoch16, step839]: loss 0.027856
[epoch16, step840]: loss 0.020424
[epoch16, step841]: loss 0.023518
[epoch16, step842]: loss 0.027370
[epoch16, step843]: loss 0.024166
[epoch16, step844]: loss 0.024041
[epoch16, step845]: loss 0.020906
[epoch16, step846]: loss 0.026455
[epoch16, step847]: loss 0.026267
[epoch16, step848]: loss 0.024308
[epoch16, step849]: loss 0.024216
[epoch16, step850]: loss 0.022290
[epoch16, step851]: loss 0.024112
[epoch16, step852]: loss 0.022196
[epoch16, step853]: loss 0.028886
[epoch16, step854]: loss 0.022822
[epoch16, step855]: loss 0.026787
[epoch16, step856]: loss 0.021325
[epoch16, step857]: loss 0.025034
[epoch16, step858]: loss 0.023655
[epoch16, step859]: loss 0.022921
[epoch16, step860]: loss 0.022288
[epoch16, step861]: loss 0.022606
[epoch16, step862]: loss 0.022270
[epoch16, step863]: loss 0.020684
[epoch16, step864]: loss 0.026257
[epoch16, step865]: loss 0.022762
[epoch16, step866]: loss 0.024208
[epoch16, step867]: loss 0.025264
[epoch16, step868]: loss 0.026479
[epoch16, step869]: loss 0.023213
[epoch16, step870]: loss 0.029959
[epoch16, step871]: loss 0.022471
[epoch16, step872]: loss 0.025007
[epoch16, step873]: loss 0.024908
[epoch16, step874]: loss 0.022780
[epoch16, step875]: loss 0.023743
[epoch16, step876]: loss 0.024325
[epoch16, step877]: loss 0.019109
[epoch16, step878]: loss 0.023027
[epoch16, step879]: loss 0.027900
[epoch16, step880]: loss 0.025517
[epoch16, step881]: loss 0.022385
[epoch16, step882]: loss 0.023247
[epoch16, step883]: loss 0.022950
[epoch16, step884]: loss 0.025589
[epoch16, step885]: loss 0.025337
[epoch16, step886]: loss 0.025979
[epoch16, step887]: loss 0.023977
[epoch16, step888]: loss 0.023939
[epoch16, step889]: loss 0.022336
[epoch16, step890]: loss 0.023882
[epoch16, step891]: loss 0.024689
[epoch16, step892]: loss 0.020205
[epoch16, step893]: loss 0.024287
[epoch16, step894]: loss 0.024541
[epoch16, step895]: loss 0.022003
[epoch16, step896]: loss 0.022868
[epoch16, step897]: loss 0.023608
[epoch16, step898]: loss 0.024888
[epoch16, step899]: loss 0.027543
[epoch16, step900]: loss 0.026205
[epoch16, step901]: loss 0.025043
[epoch16, step902]: loss 0.023273
[epoch16, step903]: loss 0.024140
[epoch16, step904]: loss 0.027856
[epoch16, step905]: loss 0.027067
[epoch16, step906]: loss 0.021717
[epoch16, step907]: loss 0.023163
[epoch16, step908]: loss 0.022852
[epoch16, step909]: loss 0.024869
[epoch16, step910]: loss 0.023112
[epoch16, step911]: loss 0.024436
[epoch16, step912]: loss 0.023521
[epoch16, step913]: loss 0.022727
[epoch16, step914]: loss 0.029500
[epoch16, step915]: loss 0.023521
[epoch16, step916]: loss 0.023371
[epoch16, step917]: loss 0.024788
[epoch16, step918]: loss 0.028111
[epoch16, step919]: loss 0.023528
[epoch16, step920]: loss 0.027073
[epoch16, step921]: loss 0.023248
[epoch16, step922]: loss 0.022361
[epoch16, step923]: loss 0.022673
[epoch16, step924]: loss 0.020697
[epoch16, step925]: loss 0.024320
[epoch16, step926]: loss 0.026012
[epoch16, step927]: loss 0.024605
[epoch16, step928]: loss 0.024294
[epoch16, step929]: loss 0.026973
[epoch16, step930]: loss 0.025080
[epoch16, step931]: loss 0.026280
[epoch16, step932]: loss 0.020752
[epoch16, step933]: loss 0.027632
[epoch16, step934]: loss 0.022703
[epoch16, step935]: loss 0.022880
[epoch16, step936]: loss 0.021989
[epoch16, step937]: loss 0.026670
[epoch16, step938]: loss 0.025705
[epoch16, step939]: loss 0.021075
[epoch16, step940]: loss 0.023304
[epoch16, step941]: loss 0.026401
[epoch16, step942]: loss 0.025062
[epoch16, step943]: loss 0.023037
[epoch16, step944]: loss 0.026651
[epoch16, step945]: loss 0.020036
[epoch16, step946]: loss 0.025123
[epoch16, step947]: loss 0.027655
[epoch16, step948]: loss 0.019613
[epoch16, step949]: loss 0.022627
[epoch16, step950]: loss 0.026620
[epoch16, step951]: loss 0.028105
[epoch16, step952]: loss 0.024419
[epoch16, step953]: loss 0.027249
[epoch16, step954]: loss 0.021970
[epoch16, step955]: loss 0.036343
[epoch16, step956]: loss 0.052466
[epoch16, step957]: loss 0.046194
[epoch16, step958]: loss 0.042961
[epoch16, step959]: loss 0.046638
[epoch16, step960]: loss 0.042596
[epoch16, step961]: loss 0.042285
[epoch16, step962]: loss 0.040978
[epoch16, step963]: loss 0.039657
[epoch16, step964]: loss 0.039452
[epoch16, step965]: loss 0.039996
[epoch16, step966]: loss 0.037260
[epoch16, step967]: loss 0.036396
[epoch16, step968]: loss 0.039068
[epoch16, step969]: loss 0.038381
[epoch16, step970]: loss 0.036932
[epoch16, step971]: loss 0.035874
[epoch16, step972]: loss 0.037646
[epoch16, step973]: loss 0.036650
[epoch16, step974]: loss 0.038434
[epoch16, step975]: loss 0.035331
[epoch16, step976]: loss 0.035237
[epoch16, step977]: loss 0.038187
[epoch16, step978]: loss 0.036808
[epoch16, step979]: loss 0.035744
[epoch16, step980]: loss 0.033948
[epoch16, step981]: loss 0.035986
[epoch16, step982]: loss 0.036473
[epoch16, step983]: loss 0.036995
[epoch16, step984]: loss 0.033530
[epoch16, step985]: loss 0.034057
[epoch16, step986]: loss 0.038463
[epoch16, step987]: loss 0.036557
[epoch16, step988]: loss 0.035742
[epoch16, step989]: loss 0.034952
[epoch16, step990]: loss 0.036021
[epoch16, step991]: loss 0.036617
[epoch16, step992]: loss 0.037083
[epoch16, step993]: loss 0.034563
[epoch16, step994]: loss 0.034001
[epoch16, step995]: loss 0.037809
[epoch16, step996]: loss 0.035778
[epoch16, step997]: loss 0.035635
[epoch16, step998]: loss 0.034520
[epoch16, step999]: loss 0.035937
[epoch16, step1000]: loss 0.035638
[epoch16, step1001]: loss 0.037032
[epoch16, step1002]: loss 0.034217
[epoch16, step1003]: loss 0.033503
[epoch16, step1004]: loss 0.037796
[epoch16, step1005]: loss 0.034810
[epoch16, step1006]: loss 0.035696
[epoch16, step1007]: loss 0.032987
[epoch16, step1008]: loss 0.035465
[epoch16, step1009]: loss 0.034960
[epoch16, step1010]: loss 0.037724
[epoch16, step1011]: loss 0.034036
[epoch16, step1012]: loss 0.033597
[epoch16, step1013]: loss 0.037315
[epoch16, step1014]: loss 0.035769
[epoch16, step1015]: loss 0.035165
[epoch16, step1016]: loss 0.033844
[epoch16, step1017]: loss 0.035350
[epoch16, step1018]: loss 0.035388
[epoch16, step1019]: loss 0.037095
[epoch16, step1020]: loss 0.033558
[epoch16, step1021]: loss 0.033499
[epoch16, step1022]: loss 0.037683
[epoch16, step1023]: loss 0.035485
[epoch16, step1024]: loss 0.036423
[epoch16, step1025]: loss 0.033040
[epoch16, step1026]: loss 0.034683
[epoch16, step1027]: loss 0.034620
[epoch16, step1028]: loss 0.036109
[epoch16, step1029]: loss 0.033287
[epoch16, step1030]: loss 0.032880
[epoch16, step1031]: loss 0.035717
[epoch16, step1032]: loss 0.035608
[epoch16, step1033]: loss 0.034701
[epoch16, step1034]: loss 0.033152
[epoch16, step1035]: loss 0.034623
[epoch16, step1036]: loss 0.035242
[epoch16, step1037]: loss 0.035860
[epoch16, step1038]: loss 0.033125
[epoch16, step1039]: loss 0.034000
[epoch16, step1040]: loss 0.035801
[epoch16, step1041]: loss 0.034998
[epoch16, step1042]: loss 0.034099
[epoch16, step1043]: loss 0.033350
[epoch16, step1044]: loss 0.035065
[epoch16, step1045]: loss 0.034890
[epoch16, step1046]: loss 0.036023
[epoch16, step1047]: loss 0.034018
[epoch16, step1048]: loss 0.032863
[epoch16, step1049]: loss 0.036333
[epoch16, step1050]: loss 0.035062
[epoch16, step1051]: loss 0.034850
[epoch16, step1052]: loss 0.033567
[epoch16, step1053]: loss 0.034893
[epoch16, step1054]: loss 0.035121
[epoch16, step1055]: loss 0.035608
[epoch16, step1056]: loss 0.033421
[epoch16, step1057]: loss 0.034590
[epoch16, step1058]: loss 0.038689
[epoch16, step1059]: loss 0.035926
[epoch16, step1060]: loss 0.035008
[epoch16, step1061]: loss 0.033468
[epoch16, step1062]: loss 0.034876
[epoch16, step1063]: loss 0.034969
[epoch16, step1064]: loss 0.036382
[epoch16, step1065]: loss 0.033495
[epoch16, step1066]: loss 0.032953
[epoch16, step1067]: loss 0.036172
[epoch16, step1068]: loss 0.034213
[epoch16, step1069]: loss 0.034149
[epoch16, step1070]: loss 0.033544
[epoch16, step1071]: loss 0.036077
[epoch16, step1072]: loss 0.036553
[epoch16, step1073]: loss 0.036870
[epoch16, step1074]: loss 0.033670
[epoch16, step1075]: loss 0.033439
[epoch16, step1076]: loss 0.036843
[epoch16, step1077]: loss 0.034920
[epoch16, step1078]: loss 0.034617
[epoch16, step1079]: loss 0.033913
[epoch16, step1080]: loss 0.035175
[epoch16, step1081]: loss 0.035219
[epoch16, step1082]: loss 0.036016
[epoch16, step1083]: loss 0.033812
[epoch16, step1084]: loss 0.033526
[epoch16, step1085]: loss 0.036258
[epoch16, step1086]: loss 0.034702
[epoch16, step1087]: loss 0.034447
[epoch16, step1088]: loss 0.032937
[epoch16, step1089]: loss 0.035011
[epoch16, step1090]: loss 0.036046
[epoch16, step1091]: loss 0.036438
[epoch16, step1092]: loss 0.033569
[epoch16, step1093]: loss 0.032875
[epoch16, step1094]: loss 0.036003
[epoch16, step1095]: loss 0.034370
[epoch16, step1096]: loss 0.034085
[epoch16, step1097]: loss 0.033001
[epoch16, step1098]: loss 0.034513
[epoch16, step1099]: loss 0.034352
[epoch16, step1100]: loss 0.036243
[epoch16, step1101]: loss 0.033794
[epoch16, step1102]: loss 0.033037
[epoch16, step1103]: loss 0.035592
[epoch16, step1104]: loss 0.034281
[epoch16, step1105]: loss 0.034758
[epoch16, step1106]: loss 0.032237
[epoch16, step1107]: loss 0.034702
[epoch16, step1108]: loss 0.034279
[epoch16, step1109]: loss 0.036413
[epoch16, step1110]: loss 0.034425
[epoch16, step1111]: loss 0.033071
[epoch16, step1112]: loss 0.036082
[epoch16, step1113]: loss 0.034506
[epoch16, step1114]: loss 0.034729
[epoch16, step1115]: loss 0.032962
[epoch16, step1116]: loss 0.034837
[epoch16, step1117]: loss 0.035353
[epoch16, step1118]: loss 0.035560
[epoch16, step1119]: loss 0.034127
[epoch16, step1120]: loss 0.033051
[epoch16, step1121]: loss 0.036308
[epoch16, step1122]: loss 0.033659
[epoch16, step1123]: loss 0.034549
[epoch16, step1124]: loss 0.034289
[epoch16, step1125]: loss 0.034916
[epoch16, step1126]: loss 0.035835
[epoch16, step1127]: loss 0.035811
[epoch16, step1128]: loss 0.033594
[epoch16, step1129]: loss 0.033238
[epoch16, step1130]: loss 0.036703
[epoch16, step1131]: loss 0.035017
[epoch16, step1132]: loss 0.035092
[epoch16, step1133]: loss 0.033074
[epoch16, step1134]: loss 0.034502
[epoch16, step1135]: loss 0.036030
[epoch16, step1136]: loss 0.036496
[epoch16, step1137]: loss 0.033355
[epoch16, step1138]: loss 0.033176
[epoch16, step1139]: loss 0.036216
[epoch16, step1140]: loss 0.034136
[epoch16, step1141]: loss 0.034875
[epoch16, step1142]: loss 0.033135
[epoch16, step1143]: loss 0.034650
[epoch16, step1144]: loss 0.035363
[epoch16, step1145]: loss 0.035554
[epoch16, step1146]: loss 0.032716
[epoch16, step1147]: loss 0.034173
[epoch16, step1148]: loss 0.035965
[epoch16, step1149]: loss 0.034081
[epoch16, step1150]: loss 0.034045
[epoch16, step1151]: loss 0.033764
[epoch16, step1152]: loss 0.035192
[epoch16, step1153]: loss 0.034833
[epoch16, step1154]: loss 0.037247
[epoch16, step1155]: loss 0.033108
[epoch16, step1156]: loss 0.032726
[epoch16, step1157]: loss 0.036831
[epoch16, step1158]: loss 0.034240
[epoch16, step1159]: loss 0.034636
[epoch16, step1160]: loss 0.034096
[epoch16, step1161]: loss 0.035100
[epoch16, step1162]: loss 0.034418
[epoch16, step1163]: loss 0.035342
[epoch16, step1164]: loss 0.032823
[epoch16, step1165]: loss 0.034076
[epoch16, step1166]: loss 0.036370
[epoch16, step1167]: loss 0.034039
[epoch16, step1168]: loss 0.034737
[epoch16, step1169]: loss 0.032592
[epoch16, step1170]: loss 0.034305
[epoch16, step1171]: loss 0.035059
[epoch16, step1172]: loss 0.035041
[epoch16, step1173]: loss 0.033561
[epoch16, step1174]: loss 0.033588
[epoch16, step1175]: loss 0.035825
[epoch16, step1176]: loss 0.034307
[epoch16, step1177]: loss 0.034531
[epoch16, step1178]: loss 0.032672
[epoch16, step1179]: loss 0.034498
[epoch16, step1180]: loss 0.034840
[epoch16, step1181]: loss 0.036131
[epoch16, step1182]: loss 0.032890
[epoch16, step1183]: loss 0.033510
[epoch16, step1184]: loss 0.036057
[epoch16, step1185]: loss 0.035248
[epoch16, step1186]: loss 0.034722
[epoch16, step1187]: loss 0.033346
[epoch16, step1188]: loss 0.034140
[epoch16, step1189]: loss 0.034290
[epoch16, step1190]: loss 0.035456
[epoch16, step1191]: loss 0.033959
[epoch16, step1192]: loss 0.032501
[epoch16, step1193]: loss 0.035867
[epoch16, step1194]: loss 0.034019
[epoch16, step1195]: loss 0.033902
[epoch16, step1196]: loss 0.032434
[epoch16, step1197]: loss 0.034815
[epoch16, step1198]: loss 0.035131
[epoch16, step1199]: loss 0.035905
[epoch16, step1200]: loss 0.032603
[epoch16, step1201]: loss 0.033245
[epoch16, step1202]: loss 0.037010
[epoch16, step1203]: loss 0.034654
[epoch16, step1204]: loss 0.033827
[epoch16, step1205]: loss 0.032631
[epoch16, step1206]: loss 0.034138
[epoch16, step1207]: loss 0.035033
[epoch16, step1208]: loss 0.036623
[epoch16, step1209]: loss 0.031931
[epoch16, step1210]: loss 0.033984
[epoch16, step1211]: loss 0.036049
[epoch16, step1212]: loss 0.034305
[epoch16, step1213]: loss 0.034923
[epoch16, step1214]: loss 0.033522
[epoch16, step1215]: loss 0.036075
[epoch16, step1216]: loss 0.034105
[epoch16, step1217]: loss 0.036004
[epoch16, step1218]: loss 0.032544
[epoch16, step1219]: loss 0.033250
[epoch16, step1220]: loss 0.035883
[epoch16, step1221]: loss 0.034739
[epoch16, step1222]: loss 0.035184
[epoch16, step1223]: loss 0.032879
[epoch16, step1224]: loss 0.034890
[epoch16, step1225]: loss 0.035133
[epoch16, step1226]: loss 0.035129
[epoch16, step1227]: loss 0.033395
[epoch16, step1228]: loss 0.032420
[epoch16, step1229]: loss 0.036392
[epoch16, step1230]: loss 0.034717
[epoch16, step1231]: loss 0.034372
[epoch16, step1232]: loss 0.035803
[epoch16, step1233]: loss 0.034011
[epoch16, step1234]: loss 0.034096
[epoch16, step1235]: loss 0.036352
[epoch16, step1236]: loss 0.034002
[epoch16, step1237]: loss 0.033459
[epoch16, step1238]: loss 0.036073
[epoch16, step1239]: loss 0.034856
[epoch16, step1240]: loss 0.035201
[epoch16, step1241]: loss 0.034432
[epoch16, step1242]: loss 0.034732
[epoch16, step1243]: loss 0.034671
[epoch16, step1244]: loss 0.035976
[epoch16, step1245]: loss 0.033139
[epoch16, step1246]: loss 0.032993
[epoch16, step1247]: loss 0.035232
[epoch16, step1248]: loss 0.034900
[epoch16, step1249]: loss 0.035004
[epoch16, step1250]: loss 0.033234
[epoch16, step1251]: loss 0.035745
[epoch16, step1252]: loss 0.036076
[epoch16, step1253]: loss 0.036869
[epoch16, step1254]: loss 0.033435
[epoch16, step1255]: loss 0.032573
[epoch16, step1256]: loss 0.036381
[epoch16, step1257]: loss 0.035267
[epoch16, step1258]: loss 0.034538
[epoch16, step1259]: loss 0.033189
[epoch16, step1260]: loss 0.034810
[epoch16, step1261]: loss 0.034619
[epoch16, step1262]: loss 0.035723
[epoch16, step1263]: loss 0.033543
[epoch16, step1264]: loss 0.033149
[epoch16, step1265]: loss 0.035451
[epoch16, step1266]: loss 0.034190
[epoch16, step1267]: loss 0.034725
[epoch16, step1268]: loss 0.033552
[epoch16, step1269]: loss 0.034601
[epoch16, step1270]: loss 0.034244
[epoch16, step1271]: loss 0.036284
[epoch16, step1272]: loss 0.032971
[epoch16, step1273]: loss 0.032860
[epoch16, step1274]: loss 0.036268
[epoch16, step1275]: loss 0.035086
[epoch16, step1276]: loss 0.034346
[epoch16, step1277]: loss 0.032866
[epoch16, step1278]: loss 0.035018
[epoch16, step1279]: loss 0.034929
[epoch16, step1280]: loss 0.035781
[epoch16, step1281]: loss 0.033210
[epoch16, step1282]: loss 0.033400
[epoch16, step1283]: loss 0.035463
[epoch16, step1284]: loss 0.034281
[epoch16, step1285]: loss 0.034670
[epoch16, step1286]: loss 0.032517
[epoch16, step1287]: loss 0.036002
[epoch16, step1288]: loss 0.035791
[epoch16, step1289]: loss 0.038320
[epoch16, step1290]: loss 0.033714
[epoch16, step1291]: loss 0.032511
[epoch16, step1292]: loss 0.037268
[epoch16, step1293]: loss 0.034003
[epoch16, step1294]: loss 0.034589
[epoch16, step1295]: loss 0.033268
[epoch16, step1296]: loss 0.034688
[epoch16, step1297]: loss 0.035388
[epoch16, step1298]: loss 0.036258
[epoch16, step1299]: loss 0.033139
[epoch16, step1300]: loss 0.033053
[epoch16, step1301]: loss 0.035856
[epoch16, step1302]: loss 0.034270
[epoch16, step1303]: loss 0.034146
[epoch16, step1304]: loss 0.032351
[epoch16, step1305]: loss 0.035179
[epoch16, step1306]: loss 0.034286
[epoch16, step1307]: loss 0.035381
[epoch16, step1308]: loss 0.033645
[epoch16, step1309]: loss 0.032191
[epoch16, step1310]: loss 0.035151
[epoch16, step1311]: loss 0.034626
[epoch16, step1312]: loss 0.035411
[epoch16, step1313]: loss 0.032803
[epoch16, step1314]: loss 0.033944
[epoch16, step1315]: loss 0.034163
[epoch16, step1316]: loss 0.037376
[epoch16, step1317]: loss 0.033354
[epoch16, step1318]: loss 0.033147
[epoch16, step1319]: loss 0.035701
[epoch16, step1320]: loss 0.034237
[epoch16, step1321]: loss 0.034320
[epoch16, step1322]: loss 0.033746
[epoch16, step1323]: loss 0.034645
[epoch16, step1324]: loss 0.034126
[epoch16, step1325]: loss 0.035185
[epoch16, step1326]: loss 0.033191
[epoch16, step1327]: loss 0.032463
[epoch16, step1328]: loss 0.036499
[epoch16, step1329]: loss 0.034270
[epoch16, step1330]: loss 0.035026
[epoch16, step1331]: loss 0.032468
[epoch16, step1332]: loss 0.034714
[epoch16, step1333]: loss 0.034280
[epoch16, step1334]: loss 0.036694
[epoch16, step1335]: loss 0.035217
[epoch16, step1336]: loss 0.032531
[epoch16, step1337]: loss 0.035956
[epoch16, step1338]: loss 0.034687
[epoch16, step1339]: loss 0.034531
[epoch16, step1340]: loss 0.032969
[epoch16, step1341]: loss 0.034558
[epoch16, step1342]: loss 0.033846
[epoch16, step1343]: loss 0.035664
[epoch16, step1344]: loss 0.032909
[epoch16, step1345]: loss 0.032450
[epoch16, step1346]: loss 0.035365
[epoch16, step1347]: loss 0.034744
[epoch16, step1348]: loss 0.033711
[epoch16, step1349]: loss 0.034104
[epoch16, step1350]: loss 0.035977
[epoch16, step1351]: loss 0.034270
[epoch16, step1352]: loss 0.035980
[epoch16, step1353]: loss 0.033965
[epoch16, step1354]: loss 0.032646
[epoch16, step1355]: loss 0.036543
[epoch16, step1356]: loss 0.034612
[epoch16, step1357]: loss 0.034366
[epoch16, step1358]: loss 0.032261
[epoch16, step1359]: loss 0.034308
[epoch16, step1360]: loss 0.035231
[epoch16, step1361]: loss 0.035612
[epoch16, step1362]: loss 0.033593
[epoch16, step1363]: loss 0.034219
[epoch16, step1364]: loss 0.036503
[epoch16, step1365]: loss 0.034259
[epoch16, step1366]: loss 0.034239
[epoch16, step1367]: loss 0.032264
[epoch16, step1368]: loss 0.035596
[epoch16, step1369]: loss 0.034882
[epoch16, step1370]: loss 0.035591
[epoch16, step1371]: loss 0.033185
[epoch16, step1372]: loss 0.032393
[epoch16, step1373]: loss 0.035536
[epoch16, step1374]: loss 0.034995
[epoch16, step1375]: loss 0.035223
[epoch16, step1376]: loss 0.032570
[epoch16, step1377]: loss 0.034734
[epoch16, step1378]: loss 0.034125
[epoch16, step1379]: loss 0.035303
[epoch16, step1380]: loss 0.033136
[epoch16, step1381]: loss 0.032215
[epoch16, step1382]: loss 0.035614
[epoch16, step1383]: loss 0.034024
[epoch16, step1384]: loss 0.034265
[epoch16, step1385]: loss 0.031706
[epoch16, step1386]: loss 0.034827
[epoch16, step1387]: loss 0.035341
[epoch16, step1388]: loss 0.034693
[epoch16, step1389]: loss 0.032226
[epoch16, step1390]: loss 0.033281
[epoch16, step1391]: loss 0.035630
[epoch16, step1392]: loss 0.034013
[epoch16, step1393]: loss 0.034429
[epoch16, step1394]: loss 0.033063
[epoch16, step1395]: loss 0.034343
[epoch16, step1396]: loss 0.034723
[epoch16, step1397]: loss 0.035671
[epoch16, step1398]: loss 0.032732
[epoch16, step1399]: loss 0.033448
[epoch16, step1400]: loss 0.036117
[epoch16, step1401]: loss 0.034093
[epoch16, step1402]: loss 0.034129
[epoch16, step1403]: loss 0.031828
[epoch16, step1404]: loss 0.034322
[epoch16, step1405]: loss 0.034448
[epoch16, step1406]: loss 0.036073
[epoch16, step1407]: loss 0.035983
[epoch16, step1408]: loss 0.032369
[epoch16, step1409]: loss 0.035800
[epoch16, step1410]: loss 0.033777
[epoch16, step1411]: loss 0.033682
[epoch16, step1412]: loss 0.032160
[epoch16, step1413]: loss 0.034563
[epoch16, step1414]: loss 0.033721
[epoch16, step1415]: loss 0.035376
[epoch16, step1416]: loss 0.033129
[epoch16, step1417]: loss 0.033377
[epoch16, step1418]: loss 0.035968
[epoch16, step1419]: loss 0.034880
[epoch16, step1420]: loss 0.034386
[epoch16, step1421]: loss 0.032849
[epoch16, step1422]: loss 0.034666
[epoch16, step1423]: loss 0.033744
[epoch16, step1424]: loss 0.035359
[epoch16, step1425]: loss 0.032948
[epoch16, step1426]: loss 0.032786
[epoch16, step1427]: loss 0.036871
[epoch16, step1428]: loss 0.035506
[epoch16, step1429]: loss 0.034443
[epoch16, step1430]: loss 0.032929
[epoch16, step1431]: loss 0.034515
[epoch16, step1432]: loss 0.033922
[epoch16, step1433]: loss 0.035521
[epoch16, step1434]: loss 0.033543
[epoch16, step1435]: loss 0.033017
[epoch16, step1436]: loss 0.036583
[epoch16, step1437]: loss 0.035254
[epoch16, step1438]: loss 0.034831
[epoch16, step1439]: loss 0.032652
[epoch16, step1440]: loss 0.034348
[epoch16, step1441]: loss 0.034631
[epoch16, step1442]: loss 0.034975
[epoch16, step1443]: loss 0.032894
[epoch16, step1444]: loss 0.031811
[epoch16, step1445]: loss 0.035870
[epoch16, step1446]: loss 0.034593
[epoch16, step1447]: loss 0.035491
[epoch16, step1448]: loss 0.033383
[epoch16, step1449]: loss 0.035455
[epoch16, step1450]: loss 0.034997
[epoch16, step1451]: loss 0.035544
[epoch16, step1452]: loss 0.033185
[epoch16, step1453]: loss 0.033598
[epoch16, step1454]: loss 0.036344
[epoch16, step1455]: loss 0.034957
[epoch16, step1456]: loss 0.034386
[epoch16, step1457]: loss 0.032788
[epoch16, step1458]: loss 0.034357
[epoch16, step1459]: loss 0.034706
[epoch16, step1460]: loss 0.035166
[epoch16, step1461]: loss 0.033206
[epoch16, step1462]: loss 0.033204
[epoch16, step1463]: loss 0.036603
[epoch16, step1464]: loss 0.034977
[epoch16, step1465]: loss 0.033893
[epoch16, step1466]: loss 0.032513
[epoch16, step1467]: loss 0.034784
[epoch16, step1468]: loss 0.034748
[epoch16, step1469]: loss 0.035116
[epoch16, step1470]: loss 0.033515
[epoch16, step1471]: loss 0.032679
[epoch16, step1472]: loss 0.036061
[epoch16, step1473]: loss 0.034504
[epoch16, step1474]: loss 0.035064
[epoch16, step1475]: loss 0.032336
[epoch16, step1476]: loss 0.035571
[epoch16, step1477]: loss 0.034379
[epoch16, step1478]: loss 0.034918
[epoch16, step1479]: loss 0.032779
[epoch16, step1480]: loss 0.032210
[epoch16, step1481]: loss 0.035506
[epoch16, step1482]: loss 0.033927
[epoch16, step1483]: loss 0.034001
[epoch16, step1484]: loss 0.033507
[epoch16, step1485]: loss 0.034366
[epoch16, step1486]: loss 0.033675
[epoch16, step1487]: loss 0.035499
[epoch16, step1488]: loss 0.032639
[epoch16, step1489]: loss 0.033142
[epoch16, step1490]: loss 0.035896
[epoch16, step1491]: loss 0.034650
[epoch16, step1492]: loss 0.034402
[epoch16, step1493]: loss 0.033110
[epoch16, step1494]: loss 0.034530
[epoch16, step1495]: loss 0.035288
[epoch16, step1496]: loss 0.036162
[epoch16, step1497]: loss 0.033565
[epoch16, step1498]: loss 0.033129
[epoch16, step1499]: loss 0.035356
[epoch16, step1500]: loss 0.034730
[epoch16, step1501]: loss 0.033743
[epoch16, step1502]: loss 0.031953
[epoch16, step1503]: loss 0.034740
[epoch16, step1504]: loss 0.033857
[epoch16, step1505]: loss 0.035763
[epoch16, step1506]: loss 0.031973
[epoch16, step1507]: loss 0.032956
[epoch16, step1508]: loss 0.036707
[epoch16, step1509]: loss 0.033611
[epoch16, step1510]: loss 0.033718
[epoch16, step1511]: loss 0.033967
[epoch16, step1512]: loss 0.034944
[epoch16, step1513]: loss 0.033659
[epoch16, step1514]: loss 0.035343
[epoch16, step1515]: loss 0.033592
[epoch16, step1516]: loss 0.032658

[epoch16]: avg loss 0.032038

[epoch17, step1]: loss 0.028762
[epoch17, step2]: loss 0.035473
[epoch17, step3]: loss 0.035279
[epoch17, step4]: loss 0.033616
[epoch17, step5]: loss 0.033273
[epoch17, step6]: loss 0.036189
[epoch17, step7]: loss 0.033997
[epoch17, step8]: loss 0.035570
[epoch17, step9]: loss 0.032303
[epoch17, step10]: loss 0.033914
[epoch17, step11]: loss 0.036051
[epoch17, step12]: loss 0.035502
[epoch17, step13]: loss 0.033270
[epoch17, step14]: loss 0.032512
[epoch17, step15]: loss 0.035169
[epoch17, step16]: loss 0.033923
[epoch17, step17]: loss 0.036231
[epoch17, step18]: loss 0.033550
[epoch17, step19]: loss 0.033543
[epoch17, step20]: loss 0.036486
[epoch17, step21]: loss 0.035321
[epoch17, step22]: loss 0.033382
[epoch17, step23]: loss 0.033846
[epoch17, step24]: loss 0.035386
[epoch17, step25]: loss 0.032304
[epoch17, step26]: loss 0.035294
[epoch17, step27]: loss 0.032528
[epoch17, step28]: loss 0.034090
[epoch17, step29]: loss 0.035688
[epoch17, step30]: loss 0.036101
[epoch17, step31]: loss 0.032845
[epoch17, step32]: loss 0.032949
[epoch17, step33]: loss 0.035978
[epoch17, step34]: loss 0.032937
[epoch17, step35]: loss 0.036603
[epoch17, step36]: loss 0.033460
[epoch17, step37]: loss 0.033302
[epoch17, step38]: loss 0.036311
[epoch17, step39]: loss 0.036363
[epoch17, step40]: loss 0.033413
[epoch17, step41]: loss 0.032659
[epoch17, step42]: loss 0.035721
[epoch17, step43]: loss 0.032948
[epoch17, step44]: loss 0.037362
[epoch17, step45]: loss 0.033130
[epoch17, step46]: loss 0.033693
[epoch17, step47]: loss 0.035162
[epoch17, step48]: loss 0.035306
[epoch17, step49]: loss 0.032385
[epoch17, step50]: loss 0.033174
[epoch17, step51]: loss 0.035845
[epoch17, step52]: loss 0.033306
[epoch17, step53]: loss 0.036472
[epoch17, step54]: loss 0.032289
[epoch17, step55]: loss 0.033925
[epoch17, step56]: loss 0.036769
[epoch17, step57]: loss 0.035700
[epoch17, step58]: loss 0.033450
[epoch17, step59]: loss 0.033713
[epoch17, step60]: loss 0.036557
[epoch17, step61]: loss 0.033401
[epoch17, step62]: loss 0.036525
[epoch17, step63]: loss 0.034297
[epoch17, step64]: loss 0.033187
[epoch17, step65]: loss 0.035653
[epoch17, step66]: loss 0.035588
[epoch17, step67]: loss 0.033024
[epoch17, step68]: loss 0.032605
[epoch17, step69]: loss 0.036251
[epoch17, step70]: loss 0.033001
[epoch17, step71]: loss 0.035644
[epoch17, step72]: loss 0.033247
[epoch17, step73]: loss 0.033972
[epoch17, step74]: loss 0.034950
[epoch17, step75]: loss 0.036807
[epoch17, step76]: loss 0.034503
[epoch17, step77]: loss 0.033690
[epoch17, step78]: loss 0.036447
[epoch17, step79]: loss 0.032891
[epoch17, step80]: loss 0.036343
[epoch17, step81]: loss 0.033102
[epoch17, step82]: loss 0.033851
[epoch17, step83]: loss 0.036098
[epoch17, step84]: loss 0.035645
[epoch17, step85]: loss 0.033482
[epoch17, step86]: loss 0.033272
[epoch17, step87]: loss 0.036613
[epoch17, step88]: loss 0.032785
[epoch17, step89]: loss 0.035733
[epoch17, step90]: loss 0.033781
[epoch17, step91]: loss 0.032806
[epoch17, step92]: loss 0.035888
[epoch17, step93]: loss 0.036599
[epoch17, step94]: loss 0.032199
[epoch17, step95]: loss 0.033738
[epoch17, step96]: loss 0.035637
[epoch17, step97]: loss 0.033968
[epoch17, step98]: loss 0.036075
[epoch17, step99]: loss 0.033401
[epoch17, step100]: loss 0.032427
[epoch17, step101]: loss 0.036987
[epoch17, step102]: loss 0.036168
[epoch17, step103]: loss 0.033253
[epoch17, step104]: loss 0.033074
[epoch17, step105]: loss 0.035896
[epoch17, step106]: loss 0.032992
[epoch17, step107]: loss 0.036242
[epoch17, step108]: loss 0.033096
[epoch17, step109]: loss 0.032631
[epoch17, step110]: loss 0.036716
[epoch17, step111]: loss 0.035787
[epoch17, step112]: loss 0.032721
[epoch17, step113]: loss 0.034504
[epoch17, step114]: loss 0.036403
[epoch17, step115]: loss 0.032624
[epoch17, step116]: loss 0.037429
[epoch17, step117]: loss 0.032462
[epoch17, step118]: loss 0.034219
[epoch17, step119]: loss 0.035851
[epoch17, step120]: loss 0.035937
[epoch17, step121]: loss 0.032645
[epoch17, step122]: loss 0.032434
[epoch17, step123]: loss 0.036076
[epoch17, step124]: loss 0.033151
[epoch17, step125]: loss 0.036061
[epoch17, step126]: loss 0.033378
[epoch17, step127]: loss 0.033052
[epoch17, step128]: loss 0.036272
[epoch17, step129]: loss 0.036516
[epoch17, step130]: loss 0.033311
[epoch17, step131]: loss 0.033102
[epoch17, step132]: loss 0.036097
[epoch17, step133]: loss 0.032928
[epoch17, step134]: loss 0.035417
[epoch17, step135]: loss 0.033719
[epoch17, step136]: loss 0.034984
[epoch17, step137]: loss 0.036071
[epoch17, step138]: loss 0.035674
[epoch17, step139]: loss 0.032938
[epoch17, step140]: loss 0.033051
[epoch17, step141]: loss 0.036176
[epoch17, step142]: loss 0.032711
[epoch17, step143]: loss 0.035281
[epoch17, step144]: loss 0.034018
[epoch17, step145]: loss 0.033002
[epoch17, step146]: loss 0.036446
[epoch17, step147]: loss 0.037011
[epoch17, step148]: loss 0.032644
[epoch17, step149]: loss 0.032870
[epoch17, step150]: loss 0.035381
[epoch17, step151]: loss 0.032876
[epoch17, step152]: loss 0.035732
[epoch17, step153]: loss 0.032548
[epoch17, step154]: loss 0.033084
[epoch17, step155]: loss 0.037162
[epoch17, step156]: loss 0.034819
[epoch17, step157]: loss 0.032539
[epoch17, step158]: loss 0.033594
[epoch17, step159]: loss 0.035664
[epoch17, step160]: loss 0.033075
[epoch17, step161]: loss 0.036049
[epoch17, step162]: loss 0.033032
[epoch17, step163]: loss 0.033339
[epoch17, step164]: loss 0.036162
[epoch17, step165]: loss 0.035979
[epoch17, step166]: loss 0.033336
[epoch17, step167]: loss 0.032861
[epoch17, step168]: loss 0.036638
[epoch17, step169]: loss 0.032731
[epoch17, step170]: loss 0.035876
[epoch17, step171]: loss 0.033550
[epoch17, step172]: loss 0.033523
[epoch17, step173]: loss 0.036033
[epoch17, step174]: loss 0.035667
[epoch17, step175]: loss 0.034378
[epoch17, step176]: loss 0.032913
[epoch17, step177]: loss 0.036500
[epoch17, step178]: loss 0.034224
[epoch17, step179]: loss 0.035545
[epoch17, step180]: loss 0.033117
[epoch17, step181]: loss 0.033307
[epoch17, step182]: loss 0.035698
[epoch17, step183]: loss 0.035642
[epoch17, step184]: loss 0.034179
[epoch17, step185]: loss 0.033383
[epoch17, step186]: loss 0.035770
[epoch17, step187]: loss 0.032759
[epoch17, step188]: loss 0.035472
[epoch17, step189]: loss 0.033113
[epoch17, step190]: loss 0.033532
[epoch17, step191]: loss 0.035257
[epoch17, step192]: loss 0.037099
[epoch17, step193]: loss 0.032617
[epoch17, step194]: loss 0.032025
[epoch17, step195]: loss 0.036454
[epoch17, step196]: loss 0.034348
[epoch17, step197]: loss 0.036174
[epoch17, step198]: loss 0.031773
[epoch17, step199]: loss 0.033731
[epoch17, step200]: loss 0.036644
[epoch17, step201]: loss 0.035895
[epoch17, step202]: loss 0.032478
[epoch17, step203]: loss 0.033763
[epoch17, step204]: loss 0.036138
[epoch17, step205]: loss 0.033188
[epoch17, step206]: loss 0.036539
[epoch17, step207]: loss 0.032766
[epoch17, step208]: loss 0.033658
[epoch17, step209]: loss 0.036378
[epoch17, step210]: loss 0.036485
[epoch17, step211]: loss 0.033532
[epoch17, step212]: loss 0.033265
[epoch17, step213]: loss 0.035835
[epoch17, step214]: loss 0.032911
[epoch17, step215]: loss 0.035788
[epoch17, step216]: loss 0.032918
[epoch17, step217]: loss 0.033043
[epoch17, step218]: loss 0.035937
[epoch17, step219]: loss 0.035231
[epoch17, step220]: loss 0.033760
[epoch17, step221]: loss 0.032915
[epoch17, step222]: loss 0.035670
[epoch17, step223]: loss 0.033229
[epoch17, step224]: loss 0.035971
[epoch17, step225]: loss 0.032731
[epoch17, step226]: loss 0.033079
[epoch17, step227]: loss 0.035532
[epoch17, step228]: loss 0.035977
[epoch17, step229]: loss 0.032275
[epoch17, step230]: loss 0.033111
[epoch17, step231]: loss 0.036343
[epoch17, step232]: loss 0.033235
[epoch17, step233]: loss 0.035669
[epoch17, step234]: loss 0.032187
[epoch17, step235]: loss 0.033545
[epoch17, step236]: loss 0.035590
[epoch17, step237]: loss 0.035347
[epoch17, step238]: loss 0.033010
[epoch17, step239]: loss 0.032384
[epoch17, step240]: loss 0.035509
[epoch17, step241]: loss 0.033276
[epoch17, step242]: loss 0.036156
[epoch17, step243]: loss 0.034013
[epoch17, step244]: loss 0.033034
[epoch17, step245]: loss 0.035911
[epoch17, step246]: loss 0.035637
[epoch17, step247]: loss 0.033543
[epoch17, step248]: loss 0.032572
[epoch17, step249]: loss 0.035537
[epoch17, step250]: loss 0.033007
[epoch17, step251]: loss 0.036599
[epoch17, step252]: loss 0.033812
[epoch17, step253]: loss 0.032406
[epoch17, step254]: loss 0.035310
[epoch17, step255]: loss 0.035661
[epoch17, step256]: loss 0.033355
[epoch17, step257]: loss 0.032461
[epoch17, step258]: loss 0.036859
[epoch17, step259]: loss 0.033839
[epoch17, step260]: loss 0.035566
[epoch17, step261]: loss 0.034201
[epoch17, step262]: loss 0.033574
[epoch17, step263]: loss 0.035202
[epoch17, step264]: loss 0.034864
[epoch17, step265]: loss 0.032723
[epoch17, step266]: loss 0.032184
[epoch17, step267]: loss 0.036195
[epoch17, step268]: loss 0.033179
[epoch17, step269]: loss 0.035558
[epoch17, step270]: loss 0.033213
[epoch17, step271]: loss 0.032433
[epoch17, step272]: loss 0.035283
[epoch17, step273]: loss 0.035232
[epoch17, step274]: loss 0.033473
[epoch17, step275]: loss 0.032261
[epoch17, step276]: loss 0.035640
[epoch17, step277]: loss 0.033834
[epoch17, step278]: loss 0.036176
[epoch17, step279]: loss 0.032104
[epoch17, step280]: loss 0.033472
[epoch17, step281]: loss 0.036022
[epoch17, step282]: loss 0.036778
[epoch17, step283]: loss 0.032897
[epoch17, step284]: loss 0.032900
[epoch17, step285]: loss 0.037375
[epoch17, step286]: loss 0.033387
[epoch17, step287]: loss 0.037041
[epoch17, step288]: loss 0.032673
[epoch17, step289]: loss 0.033955
[epoch17, step290]: loss 0.036262
[epoch17, step291]: loss 0.035552
[epoch17, step292]: loss 0.033169
[epoch17, step293]: loss 0.033279
[epoch17, step294]: loss 0.035826
[epoch17, step295]: loss 0.033108
[epoch17, step296]: loss 0.037886
[epoch17, step297]: loss 0.032607
[epoch17, step298]: loss 0.033258
[epoch17, step299]: loss 0.035652
[epoch17, step300]: loss 0.035983
[epoch17, step301]: loss 0.033157
[epoch17, step302]: loss 0.033694
[epoch17, step303]: loss 0.036309
[epoch17, step304]: loss 0.032759
[epoch17, step305]: loss 0.035099
[epoch17, step306]: loss 0.033006
[epoch17, step307]: loss 0.032630
[epoch17, step308]: loss 0.036599
[epoch17, step309]: loss 0.035722
[epoch17, step310]: loss 0.032769
[epoch17, step311]: loss 0.033263
[epoch17, step312]: loss 0.036383
[epoch17, step313]: loss 0.032617
[epoch17, step314]: loss 0.035450
[epoch17, step315]: loss 0.034377
[epoch17, step316]: loss 0.032669
[epoch17, step317]: loss 0.036400
[epoch17, step318]: loss 0.036546
[epoch17, step319]: loss 0.033065
[epoch17, step320]: loss 0.032263
[epoch17, step321]: loss 0.035438
[epoch17, step322]: loss 0.032964
[epoch17, step323]: loss 0.034781
[epoch17, step324]: loss 0.034623
[epoch17, step325]: loss 0.033222
[epoch17, step326]: loss 0.035474
[epoch17, step327]: loss 0.034684
[epoch17, step328]: loss 0.033409
[epoch17, step329]: loss 0.032301
[epoch17, step330]: loss 0.035159
[epoch17, step331]: loss 0.033256
[epoch17, step332]: loss 0.035024
[epoch17, step333]: loss 0.033061
[epoch17, step334]: loss 0.033327
[epoch17, step335]: loss 0.035802
[epoch17, step336]: loss 0.036763
[epoch17, step337]: loss 0.033763
[epoch17, step338]: loss 0.032341
[epoch17, step339]: loss 0.036643
[epoch17, step340]: loss 0.033636
[epoch17, step341]: loss 0.035399
[epoch17, step342]: loss 0.032331
[epoch17, step343]: loss 0.033686
[epoch17, step344]: loss 0.035314
[epoch17, step345]: loss 0.035170
[epoch17, step346]: loss 0.032375
[epoch17, step347]: loss 0.033122
[epoch17, step348]: loss 0.035824
[epoch17, step349]: loss 0.034220
[epoch17, step350]: loss 0.035861
[epoch17, step351]: loss 0.032005
[epoch17, step352]: loss 0.032399
[epoch17, step353]: loss 0.035711
[epoch17, step354]: loss 0.034717
[epoch17, step355]: loss 0.032281
[epoch17, step356]: loss 0.034157
[epoch17, step357]: loss 0.035935
[epoch17, step358]: loss 0.031838
[epoch17, step359]: loss 0.039158
[epoch17, step360]: loss 0.031621
[epoch17, step361]: loss 0.032850
[epoch17, step362]: loss 0.037501
[epoch17, step363]: loss 0.035051
[epoch17, step364]: loss 0.033056
[epoch17, step365]: loss 0.032441
[epoch17, step366]: loss 0.036438
[epoch17, step367]: loss 0.032915
[epoch17, step368]: loss 0.036035
[epoch17, step369]: loss 0.032738
[epoch17, step370]: loss 0.033860
[epoch17, step371]: loss 0.036071
[epoch17, step372]: loss 0.035828
[epoch17, step373]: loss 0.033221
[epoch17, step374]: loss 0.033297
[epoch17, step375]: loss 0.036698
[epoch17, step376]: loss 0.033207
[epoch17, step377]: loss 0.035974
[epoch17, step378]: loss 0.033007
[epoch17, step379]: loss 0.033343
[epoch17, step380]: loss 0.036573
[epoch17, step381]: loss 0.035525
[epoch17, step382]: loss 0.033404
[epoch17, step383]: loss 0.032091
[epoch17, step384]: loss 0.035840
[epoch17, step385]: loss 0.032474
[epoch17, step386]: loss 0.035681
[epoch17, step387]: loss 0.032496
[epoch17, step388]: loss 0.034168
[epoch17, step389]: loss 0.035763
[epoch17, step390]: loss 0.037106
[epoch17, step391]: loss 0.032568
[epoch17, step392]: loss 0.033674
[epoch17, step393]: loss 0.036280
[epoch17, step394]: loss 0.033021
[epoch17, step395]: loss 0.035849
[epoch17, step396]: loss 0.032423
[epoch17, step397]: loss 0.032963
[epoch17, step398]: loss 0.035629
[epoch17, step399]: loss 0.035488
[epoch17, step400]: loss 0.033126
[epoch17, step401]: loss 0.032058
[epoch17, step402]: loss 0.035535
[epoch17, step403]: loss 0.033088
[epoch17, step404]: loss 0.036051
[epoch17, step405]: loss 0.033260
[epoch17, step406]: loss 0.033666
[epoch17, step407]: loss 0.035737
[epoch17, step408]: loss 0.036107
[epoch17, step409]: loss 0.035696
[epoch17, step410]: loss 0.033082
[epoch17, step411]: loss 0.035984
[epoch17, step412]: loss 0.033658
[epoch17, step413]: loss 0.035485
[epoch17, step414]: loss 0.033714
[epoch17, step415]: loss 0.032892
[epoch17, step416]: loss 0.035378
[epoch17, step417]: loss 0.035071
[epoch17, step418]: loss 0.033662
[epoch17, step419]: loss 0.031952
[epoch17, step420]: loss 0.035948
[epoch17, step421]: loss 0.032737
[epoch17, step422]: loss 0.036036
[epoch17, step423]: loss 0.032996
[epoch17, step424]: loss 0.034156
[epoch17, step425]: loss 0.036250
[epoch17, step426]: loss 0.035770
[epoch17, step427]: loss 0.033406
[epoch17, step428]: loss 0.032586
[epoch17, step429]: loss 0.036702
[epoch17, step430]: loss 0.033687
[epoch17, step431]: loss 0.035802
[epoch17, step432]: loss 0.032568
[epoch17, step433]: loss 0.033538
[epoch17, step434]: loss 0.035800
[epoch17, step435]: loss 0.035892
[epoch17, step436]: loss 0.032790
[epoch17, step437]: loss 0.033389
[epoch17, step438]: loss 0.036019
[epoch17, step439]: loss 0.034210
[epoch17, step440]: loss 0.036188
[epoch17, step441]: loss 0.032921
[epoch17, step442]: loss 0.033656
[epoch17, step443]: loss 0.037935
[epoch17, step444]: loss 0.035346
[epoch17, step445]: loss 0.032865
[epoch17, step446]: loss 0.033182
[epoch17, step447]: loss 0.035997
[epoch17, step448]: loss 0.033604
[epoch17, step449]: loss 0.035339
[epoch17, step450]: loss 0.033509
[epoch17, step451]: loss 0.033029
[epoch17, step452]: loss 0.035988
[epoch17, step453]: loss 0.036670
[epoch17, step454]: loss 0.032805
[epoch17, step455]: loss 0.033244
[epoch17, step456]: loss 0.035846
[epoch17, step457]: loss 0.033722
[epoch17, step458]: loss 0.035385
[epoch17, step459]: loss 0.033683
[epoch17, step460]: loss 0.032982
[epoch17, step461]: loss 0.036793
[epoch17, step462]: loss 0.035186
[epoch17, step463]: loss 0.033676
[epoch17, step464]: loss 0.032528
[epoch17, step465]: loss 0.036842
[epoch17, step466]: loss 0.033028
[epoch17, step467]: loss 0.035320
[epoch17, step468]: loss 0.032919
[epoch17, step469]: loss 0.032671
[epoch17, step470]: loss 0.035592
[epoch17, step471]: loss 0.035599
[epoch17, step472]: loss 0.033999
[epoch17, step473]: loss 0.032183
[epoch17, step474]: loss 0.035058
[epoch17, step475]: loss 0.033787
[epoch17, step476]: loss 0.036497
[epoch17, step477]: loss 0.033652
[epoch17, step478]: loss 0.032691
[epoch17, step479]: loss 0.036055
[epoch17, step480]: loss 0.035789
[epoch17, step481]: loss 0.034254
[epoch17, step482]: loss 0.032625
[epoch17, step483]: loss 0.035677
[epoch17, step484]: loss 0.034431
[epoch17, step485]: loss 0.036740
[epoch17, step486]: loss 0.034105
[epoch17, step487]: loss 0.033153
[epoch17, step488]: loss 0.036932
[epoch17, step489]: loss 0.036597
[epoch17, step490]: loss 0.035098
[epoch17, step491]: loss 0.032864
[epoch17, step492]: loss 0.036398
[epoch17, step493]: loss 0.034644
[epoch17, step494]: loss 0.035742
[epoch17, step495]: loss 0.034985
[epoch17, step496]: loss 0.033315
[epoch17, step497]: loss 0.037523
[epoch17, step498]: loss 0.036787
[epoch17, step499]: loss 0.033242
[epoch17, step500]: loss 0.032506
[epoch17, step501]: loss 0.036430
[epoch17, step502]: loss 0.033114
[epoch17, step503]: loss 0.036044
[epoch17, step504]: loss 0.033046
[epoch17, step505]: loss 0.032330
[epoch17, step506]: loss 0.036292
[epoch17, step507]: loss 0.035958
[epoch17, step508]: loss 0.033502
[epoch17, step509]: loss 0.032171
[epoch17, step510]: loss 0.035828
[epoch17, step511]: loss 0.033204
[epoch17, step512]: loss 0.035516
[epoch17, step513]: loss 0.033295
[epoch17, step514]: loss 0.032889
[epoch17, step515]: loss 0.035977
[epoch17, step516]: loss 0.035546
[epoch17, step517]: loss 0.032648
[epoch17, step518]: loss 0.032964
[epoch17, step519]: loss 0.036093
[epoch17, step520]: loss 0.032404
[epoch17, step521]: loss 0.036033
[epoch17, step522]: loss 0.032056
[epoch17, step523]: loss 0.032593
[epoch17, step524]: loss 0.035527
[epoch17, step525]: loss 0.035460
[epoch17, step526]: loss 0.032564
[epoch17, step527]: loss 0.031920
[epoch17, step528]: loss 0.035091
[epoch17, step529]: loss 0.032580
[epoch17, step530]: loss 0.036211
[epoch17, step531]: loss 0.032005
[epoch17, step532]: loss 0.034412
[epoch17, step533]: loss 0.038366
[epoch17, step534]: loss 0.034962
[epoch17, step535]: loss 0.034023
[epoch17, step536]: loss 0.033062
[epoch17, step537]: loss 0.035416
[epoch17, step538]: loss 0.033844
[epoch17, step539]: loss 0.035436
[epoch17, step540]: loss 0.033453
[epoch17, step541]: loss 0.033313
[epoch17, step542]: loss 0.036058
[epoch17, step543]: loss 0.035038
[epoch17, step544]: loss 0.032991
[epoch17, step545]: loss 0.032467
[epoch17, step546]: loss 0.035881
[epoch17, step547]: loss 0.033014
[epoch17, step548]: loss 0.036028
[epoch17, step549]: loss 0.035014
[epoch17, step550]: loss 0.035414
[epoch17, step551]: loss 0.038644
[epoch17, step552]: loss 0.034980
[epoch17, step553]: loss 0.034556
[epoch17, step554]: loss 0.033508
[epoch17, step555]: loss 0.036341
[epoch17, step556]: loss 0.033003
[epoch17, step557]: loss 0.034947
[epoch17, step558]: loss 0.034087
[epoch17, step559]: loss 0.033499
[epoch17, step560]: loss 0.036143
[epoch17, step561]: loss 0.035873
[epoch17, step562]: loss 0.033827
[epoch17, step563]: loss 0.032277
[epoch17, step564]: loss 0.034873
[epoch17, step565]: loss 0.028639
[epoch17, step566]: loss 0.038913
[epoch17, step567]: loss 0.029111
[epoch17, step568]: loss 0.027861
[epoch17, step569]: loss 0.024939
[epoch17, step570]: loss 0.033300
[epoch17, step571]: loss 0.025481
[epoch17, step572]: loss 0.025951
[epoch17, step573]: loss 0.029725
[epoch17, step574]: loss 0.028472
[epoch17, step575]: loss 0.022195
[epoch17, step576]: loss 0.021681
[epoch17, step577]: loss 0.026358
[epoch17, step578]: loss 0.019754
[epoch17, step579]: loss 0.028933
[epoch17, step580]: loss 0.019597
[epoch17, step581]: loss 0.027227
[epoch17, step582]: loss 0.024443
[epoch17, step583]: loss 0.022828
[epoch17, step584]: loss 0.024126
[epoch17, step585]: loss 0.025610
[epoch17, step586]: loss 0.022286
[epoch17, step587]: loss 0.027159
[epoch17, step588]: loss 0.022912
[epoch17, step589]: loss 0.022898
[epoch17, step590]: loss 0.027989
[epoch17, step591]: loss 0.020665
[epoch17, step592]: loss 0.026077
[epoch17, step593]: loss 0.022184
[epoch17, step594]: loss 0.025793
[epoch17, step595]: loss 0.027417
[epoch17, step596]: loss 0.022731
[epoch17, step597]: loss 0.024545
[epoch17, step598]: loss 0.027999
[epoch17, step599]: loss 0.025352
[epoch17, step600]: loss 0.027354
[epoch17, step601]: loss 0.019998
[epoch17, step602]: loss 0.023258
[epoch17, step603]: loss 0.026080
[epoch17, step604]: loss 0.025968
[epoch17, step605]: loss 0.024135
[epoch17, step606]: loss 0.024761
[epoch17, step607]: loss 0.026391
[epoch17, step608]: loss 0.025023
[epoch17, step609]: loss 0.025661
[epoch17, step610]: loss 0.025901
[epoch17, step611]: loss 0.026635
[epoch17, step612]: loss 0.025228
[epoch17, step613]: loss 0.020468
[epoch17, step614]: loss 0.025216
[epoch17, step615]: loss 0.027491
[epoch17, step616]: loss 0.023753
[epoch17, step617]: loss 0.022952
[epoch17, step618]: loss 0.025424
[epoch17, step619]: loss 0.027027
[epoch17, step620]: loss 0.023686
[epoch17, step621]: loss 0.025862
[epoch17, step622]: loss 0.020518
[epoch17, step623]: loss 0.024139
[epoch17, step624]: loss 0.026122
[epoch17, step625]: loss 0.025753
[epoch17, step626]: loss 0.027379
[epoch17, step627]: loss 0.022870
[epoch17, step628]: loss 0.024544
[epoch17, step629]: loss 0.020156
[epoch17, step630]: loss 0.022296
[epoch17, step631]: loss 0.031534
[epoch17, step632]: loss 0.022360
[epoch17, step633]: loss 0.023769
[epoch17, step634]: loss 0.027089
[epoch17, step635]: loss 0.024987
[epoch17, step636]: loss 0.020671
[epoch17, step637]: loss 0.026684
[epoch17, step638]: loss 0.026137
[epoch17, step639]: loss 0.021956
[epoch17, step640]: loss 0.029093
[epoch17, step641]: loss 0.029707
[epoch17, step642]: loss 0.024427
[epoch17, step643]: loss 0.024788
[epoch17, step644]: loss 0.025526
[epoch17, step645]: loss 0.022963
[epoch17, step646]: loss 0.025386
[epoch17, step647]: loss 0.022349
[epoch17, step648]: loss 0.023492
[epoch17, step649]: loss 0.027979
[epoch17, step650]: loss 0.022026
[epoch17, step651]: loss 0.025774
[epoch17, step652]: loss 0.026226
[epoch17, step653]: loss 0.027531
[epoch17, step654]: loss 0.022458
[epoch17, step655]: loss 0.024163
[epoch17, step656]: loss 0.021887
[epoch17, step657]: loss 0.027816
[epoch17, step658]: loss 0.025241
[epoch17, step659]: loss 0.027407
[epoch17, step660]: loss 0.024165
[epoch17, step661]: loss 0.026806
[epoch17, step662]: loss 0.024054
[epoch17, step663]: loss 0.021494
[epoch17, step664]: loss 0.025318
[epoch17, step665]: loss 0.028068
[epoch17, step666]: loss 0.026300
[epoch17, step667]: loss 0.026152
[epoch17, step668]: loss 0.023051
[epoch17, step669]: loss 0.025973
[epoch17, step670]: loss 0.026101
[epoch17, step671]: loss 0.021743
[epoch17, step672]: loss 0.024405
[epoch17, step673]: loss 0.023046
[epoch17, step674]: loss 0.021315
[epoch17, step675]: loss 0.020110
[epoch17, step676]: loss 0.024283
[epoch17, step677]: loss 0.024492
[epoch17, step678]: loss 0.022328
[epoch17, step679]: loss 0.023207
[epoch17, step680]: loss 0.030762
[epoch17, step681]: loss 0.021338
[epoch17, step682]: loss 0.025700
[epoch17, step683]: loss 0.025191
[epoch17, step684]: loss 0.024441
[epoch17, step685]: loss 0.024117
[epoch17, step686]: loss 0.027040
[epoch17, step687]: loss 0.026494
[epoch17, step688]: loss 0.022660
[epoch17, step689]: loss 0.024276
[epoch17, step690]: loss 0.024925
[epoch17, step691]: loss 0.024069
[epoch17, step692]: loss 0.022538
[epoch17, step693]: loss 0.026437
[epoch17, step694]: loss 0.021796
[epoch17, step695]: loss 0.026011
[epoch17, step696]: loss 0.025432
[epoch17, step697]: loss 0.026899
[epoch17, step698]: loss 0.024223
[epoch17, step699]: loss 0.022834
[epoch17, step700]: loss 0.021915
[epoch17, step701]: loss 0.025339
[epoch17, step702]: loss 0.020931
[epoch17, step703]: loss 0.023218
[epoch17, step704]: loss 0.025175
[epoch17, step705]: loss 0.024004
[epoch17, step706]: loss 0.023039
[epoch17, step707]: loss 0.024573
[epoch17, step708]: loss 0.024971
[epoch17, step709]: loss 0.027284
[epoch17, step710]: loss 0.022844
[epoch17, step711]: loss 0.023753
[epoch17, step712]: loss 0.025400
[epoch17, step713]: loss 0.025625
[epoch17, step714]: loss 0.021045
[epoch17, step715]: loss 0.022633
[epoch17, step716]: loss 0.025648
[epoch17, step717]: loss 0.022797
[epoch17, step718]: loss 0.024737
[epoch17, step719]: loss 0.032883
[epoch17, step720]: loss 0.023930
[epoch17, step721]: loss 0.022295
[epoch17, step722]: loss 0.030049
[epoch17, step723]: loss 0.025648
[epoch17, step724]: loss 0.022012
[epoch17, step725]: loss 0.027245
[epoch17, step726]: loss 0.021936
[epoch17, step727]: loss 0.023612
[epoch17, step728]: loss 0.025587
[epoch17, step729]: loss 0.021310
[epoch17, step730]: loss 0.022089
[epoch17, step731]: loss 0.025283
[epoch17, step732]: loss 0.024971
[epoch17, step733]: loss 0.023210
[epoch17, step734]: loss 0.021738
[epoch17, step735]: loss 0.027365
[epoch17, step736]: loss 0.024211
[epoch17, step737]: loss 0.026006
[epoch17, step738]: loss 0.020100
[epoch17, step739]: loss 0.025268
[epoch17, step740]: loss 0.022150
[epoch17, step741]: loss 0.024857
[epoch17, step742]: loss 0.021786
[epoch17, step743]: loss 0.022766
[epoch17, step744]: loss 0.023079
[epoch17, step745]: loss 0.024074
[epoch17, step746]: loss 0.024113
[epoch17, step747]: loss 0.026463
[epoch17, step748]: loss 0.024888
[epoch17, step749]: loss 0.025206
[epoch17, step750]: loss 0.026508
[epoch17, step751]: loss 0.021910
[epoch17, step752]: loss 0.025099
[epoch17, step753]: loss 0.026022
[epoch17, step754]: loss 0.022299
[epoch17, step755]: loss 0.025753
[epoch17, step756]: loss 0.023006
[epoch17, step757]: loss 0.020542
[epoch17, step758]: loss 0.025269
[epoch17, step759]: loss 0.022148
[epoch17, step760]: loss 0.023812
[epoch17, step761]: loss 0.026854
[epoch17, step762]: loss 0.020933
[epoch17, step763]: loss 0.024858
[epoch17, step764]: loss 0.024066
[epoch17, step765]: loss 0.025421
[epoch17, step766]: loss 0.024306
[epoch17, step767]: loss 0.026865
[epoch17, step768]: loss 0.020283
[epoch17, step769]: loss 0.026416
[epoch17, step770]: loss 0.025082
[epoch17, step771]: loss 0.022346
[epoch17, step772]: loss 0.027925
[epoch17, step773]: loss 0.026109
[epoch17, step774]: loss 0.024137
[epoch17, step775]: loss 0.020791
[epoch17, step776]: loss 0.025133
[epoch17, step777]: loss 0.022129
[epoch17, step778]: loss 0.027426
[epoch17, step779]: loss 0.024022
[epoch17, step780]: loss 0.020076
[epoch17, step781]: loss 0.024234
[epoch17, step782]: loss 0.022007
[epoch17, step783]: loss 0.019461
[epoch17, step784]: loss 0.020480
[epoch17, step785]: loss 0.021179
[epoch17, step786]: loss 0.024107
[epoch17, step787]: loss 0.022517
[epoch17, step788]: loss 0.024427
[epoch17, step789]: loss 0.022760
[epoch17, step790]: loss 0.022853
[epoch17, step791]: loss 0.026819
[epoch17, step792]: loss 0.024390
[epoch17, step793]: loss 0.026338
[epoch17, step794]: loss 0.020275
[epoch17, step795]: loss 0.025290
[epoch17, step796]: loss 0.027410
[epoch17, step797]: loss 0.027055
[epoch17, step798]: loss 0.026330
[epoch17, step799]: loss 0.025218
[epoch17, step800]: loss 0.021256
[epoch17, step801]: loss 0.022000
[epoch17, step802]: loss 0.022412
[epoch17, step803]: loss 0.025741
[epoch17, step804]: loss 0.027228
[epoch17, step805]: loss 0.028079
[epoch17, step806]: loss 0.021329
[epoch17, step807]: loss 0.020968
[epoch17, step808]: loss 0.023001
[epoch17, step809]: loss 0.021996
[epoch17, step810]: loss 0.024995
[epoch17, step811]: loss 0.024827
[epoch17, step812]: loss 0.023591
[epoch17, step813]: loss 0.022797
[epoch17, step814]: loss 0.024478
[epoch17, step815]: loss 0.024501
[epoch17, step816]: loss 0.023163
[epoch17, step817]: loss 0.024194
[epoch17, step818]: loss 0.021514
[epoch17, step819]: loss 0.020455
[epoch17, step820]: loss 0.022817
[epoch17, step821]: loss 0.020724
[epoch17, step822]: loss 0.029598
[epoch17, step823]: loss 0.023495
[epoch17, step824]: loss 0.026376
[epoch17, step825]: loss 0.024457
[epoch17, step826]: loss 0.023778
[epoch17, step827]: loss 0.026183
[epoch17, step828]: loss 0.028051
[epoch17, step829]: loss 0.025898
[epoch17, step830]: loss 0.021864
[epoch17, step831]: loss 0.025789
[epoch17, step832]: loss 0.020866
[epoch17, step833]: loss 0.028826
[epoch17, step834]: loss 0.024895
[epoch17, step835]: loss 0.020446
[epoch17, step836]: loss 0.026577
[epoch17, step837]: loss 0.025179
[epoch17, step838]: loss 0.025896
[epoch17, step839]: loss 0.028199
[epoch17, step840]: loss 0.020300
[epoch17, step841]: loss 0.023498
[epoch17, step842]: loss 0.027344
[epoch17, step843]: loss 0.024362
[epoch17, step844]: loss 0.024209
[epoch17, step845]: loss 0.020966
[epoch17, step846]: loss 0.026574
[epoch17, step847]: loss 0.026338
[epoch17, step848]: loss 0.024572
[epoch17, step849]: loss 0.024416
[epoch17, step850]: loss 0.022648
[epoch17, step851]: loss 0.024397
[epoch17, step852]: loss 0.022413
[epoch17, step853]: loss 0.028922
[epoch17, step854]: loss 0.022780
[epoch17, step855]: loss 0.026614
[epoch17, step856]: loss 0.021364
[epoch17, step857]: loss 0.025060
[epoch17, step858]: loss 0.023653
[epoch17, step859]: loss 0.022793
[epoch17, step860]: loss 0.022404
[epoch17, step861]: loss 0.022584
[epoch17, step862]: loss 0.022031
[epoch17, step863]: loss 0.020705
[epoch17, step864]: loss 0.026060
[epoch17, step865]: loss 0.022873
[epoch17, step866]: loss 0.024324
[epoch17, step867]: loss 0.025125
[epoch17, step868]: loss 0.026254
[epoch17, step869]: loss 0.023306
[epoch17, step870]: loss 0.030168
[epoch17, step871]: loss 0.022462
[epoch17, step872]: loss 0.024768
[epoch17, step873]: loss 0.025091
[epoch17, step874]: loss 0.022880
[epoch17, step875]: loss 0.023686
[epoch17, step876]: loss 0.024008
[epoch17, step877]: loss 0.018930
[epoch17, step878]: loss 0.022962
[epoch17, step879]: loss 0.027854
[epoch17, step880]: loss 0.025342
[epoch17, step881]: loss 0.022399
[epoch17, step882]: loss 0.022877
[epoch17, step883]: loss 0.023154
[epoch17, step884]: loss 0.025969
[epoch17, step885]: loss 0.025307
[epoch17, step886]: loss 0.026006
[epoch17, step887]: loss 0.023952
[epoch17, step888]: loss 0.023815
[epoch17, step889]: loss 0.022372
[epoch17, step890]: loss 0.023877
[epoch17, step891]: loss 0.024705
[epoch17, step892]: loss 0.020129
[epoch17, step893]: loss 0.024185
[epoch17, step894]: loss 0.024585
[epoch17, step895]: loss 0.022069
[epoch17, step896]: loss 0.022780
[epoch17, step897]: loss 0.023771
[epoch17, step898]: loss 0.024966
[epoch17, step899]: loss 0.027474
[epoch17, step900]: loss 0.026475
[epoch17, step901]: loss 0.025109
[epoch17, step902]: loss 0.023407
[epoch17, step903]: loss 0.024211
[epoch17, step904]: loss 0.027764
[epoch17, step905]: loss 0.027152
[epoch17, step906]: loss 0.022106
[epoch17, step907]: loss 0.023254
[epoch17, step908]: loss 0.022900
[epoch17, step909]: loss 0.025129
[epoch17, step910]: loss 0.023259
[epoch17, step911]: loss 0.024677
[epoch17, step912]: loss 0.023495
[epoch17, step913]: loss 0.023237
[epoch17, step914]: loss 0.029685
[epoch17, step915]: loss 0.023483
[epoch17, step916]: loss 0.023392
[epoch17, step917]: loss 0.024652
[epoch17, step918]: loss 0.028055
[epoch17, step919]: loss 0.023325
[epoch17, step920]: loss 0.027053
[epoch17, step921]: loss 0.023419
[epoch17, step922]: loss 0.022359
[epoch17, step923]: loss 0.022598
[epoch17, step924]: loss 0.020778
[epoch17, step925]: loss 0.024414
[epoch17, step926]: loss 0.026113
[epoch17, step927]: loss 0.024546
[epoch17, step928]: loss 0.024273
[epoch17, step929]: loss 0.026775
[epoch17, step930]: loss 0.025111
[epoch17, step931]: loss 0.026377
[epoch17, step932]: loss 0.020995
[epoch17, step933]: loss 0.027775
[epoch17, step934]: loss 0.022512
[epoch17, step935]: loss 0.022705
[epoch17, step936]: loss 0.022025
[epoch17, step937]: loss 0.026544
[epoch17, step938]: loss 0.025740
[epoch17, step939]: loss 0.021004
[epoch17, step940]: loss 0.023196
[epoch17, step941]: loss 0.026000
[epoch17, step942]: loss 0.024783
[epoch17, step943]: loss 0.023065
[epoch17, step944]: loss 0.026617
[epoch17, step945]: loss 0.020254
[epoch17, step946]: loss 0.025157
[epoch17, step947]: loss 0.027524
[epoch17, step948]: loss 0.019646
[epoch17, step949]: loss 0.022601
[epoch17, step950]: loss 0.026034
[epoch17, step951]: loss 0.028447
[epoch17, step952]: loss 0.024402
[epoch17, step953]: loss 0.027769
[epoch17, step954]: loss 0.022375
[epoch17, step955]: loss 0.035761
[epoch17, step956]: loss 0.051044
[epoch17, step957]: loss 0.045610
[epoch17, step958]: loss 0.043012
[epoch17, step959]: loss 0.046889
[epoch17, step960]: loss 0.043302
[epoch17, step961]: loss 0.043948
[epoch17, step962]: loss 0.041930
[epoch17, step963]: loss 0.039861
[epoch17, step964]: loss 0.040410
[epoch17, step965]: loss 0.040180
[epoch17, step966]: loss 0.037256
[epoch17, step967]: loss 0.036368
[epoch17, step968]: loss 0.039372
[epoch17, step969]: loss 0.038531
[epoch17, step970]: loss 0.037294
[epoch17, step971]: loss 0.036317
[epoch17, step972]: loss 0.038289
[epoch17, step973]: loss 0.036821
[epoch17, step974]: loss 0.038332
[epoch17, step975]: loss 0.035730
[epoch17, step976]: loss 0.034860
[epoch17, step977]: loss 0.038658
[epoch17, step978]: loss 0.037035
[epoch17, step979]: loss 0.035645
[epoch17, step980]: loss 0.034437
[epoch17, step981]: loss 0.036283
[epoch17, step982]: loss 0.036114
[epoch17, step983]: loss 0.036945
[epoch17, step984]: loss 0.034045
[epoch17, step985]: loss 0.033866
[epoch17, step986]: loss 0.038616
[epoch17, step987]: loss 0.036465
[epoch17, step988]: loss 0.036175
[epoch17, step989]: loss 0.034820
[epoch17, step990]: loss 0.035579
[epoch17, step991]: loss 0.036410
[epoch17, step992]: loss 0.036586
[epoch17, step993]: loss 0.034099
[epoch17, step994]: loss 0.033088
[epoch17, step995]: loss 0.037060
[epoch17, step996]: loss 0.035254
[epoch17, step997]: loss 0.035303
[epoch17, step998]: loss 0.034122
[epoch17, step999]: loss 0.035269
[epoch17, step1000]: loss 0.035381
[epoch17, step1001]: loss 0.036422
[epoch17, step1002]: loss 0.033954
[epoch17, step1003]: loss 0.033196
[epoch17, step1004]: loss 0.037187
[epoch17, step1005]: loss 0.034627
[epoch17, step1006]: loss 0.035279
[epoch17, step1007]: loss 0.032751
[epoch17, step1008]: loss 0.034898
[epoch17, step1009]: loss 0.034799
[epoch17, step1010]: loss 0.037130
[epoch17, step1011]: loss 0.033529
[epoch17, step1012]: loss 0.033203
[epoch17, step1013]: loss 0.036927
[epoch17, step1014]: loss 0.035597
[epoch17, step1015]: loss 0.034897
[epoch17, step1016]: loss 0.033451
[epoch17, step1017]: loss 0.034874
[epoch17, step1018]: loss 0.035022
[epoch17, step1019]: loss 0.036592
[epoch17, step1020]: loss 0.033780
[epoch17, step1021]: loss 0.032692
[epoch17, step1022]: loss 0.036816
[epoch17, step1023]: loss 0.035381
[epoch17, step1024]: loss 0.035989
[epoch17, step1025]: loss 0.032603
[epoch17, step1026]: loss 0.034148
[epoch17, step1027]: loss 0.034551
[epoch17, step1028]: loss 0.035737
[epoch17, step1029]: loss 0.033133
[epoch17, step1030]: loss 0.032743
[epoch17, step1031]: loss 0.035601
[epoch17, step1032]: loss 0.035147
[epoch17, step1033]: loss 0.034867
[epoch17, step1034]: loss 0.032535
[epoch17, step1035]: loss 0.033962
[epoch17, step1036]: loss 0.035205
[epoch17, step1037]: loss 0.035111
[epoch17, step1038]: loss 0.032995
[epoch17, step1039]: loss 0.032993
[epoch17, step1040]: loss 0.035126
[epoch17, step1041]: loss 0.033992
[epoch17, step1042]: loss 0.033458
[epoch17, step1043]: loss 0.032390
[epoch17, step1044]: loss 0.034309
[epoch17, step1045]: loss 0.034332
[epoch17, step1046]: loss 0.035689
[epoch17, step1047]: loss 0.033811
[epoch17, step1048]: loss 0.032872
[epoch17, step1049]: loss 0.035887
[epoch17, step1050]: loss 0.034960
[epoch17, step1051]: loss 0.035100
[epoch17, step1052]: loss 0.032991
[epoch17, step1053]: loss 0.034510
[epoch17, step1054]: loss 0.035540
[epoch17, step1055]: loss 0.035604
[epoch17, step1056]: loss 0.033515
[epoch17, step1057]: loss 0.033343
[epoch17, step1058]: loss 0.037012
[epoch17, step1059]: loss 0.035172
[epoch17, step1060]: loss 0.034306
[epoch17, step1061]: loss 0.032925
[epoch17, step1062]: loss 0.034414
[epoch17, step1063]: loss 0.034609
[epoch17, step1064]: loss 0.035806
[epoch17, step1065]: loss 0.033351
[epoch17, step1066]: loss 0.032249
[epoch17, step1067]: loss 0.036031
[epoch17, step1068]: loss 0.034149
[epoch17, step1069]: loss 0.033999
[epoch17, step1070]: loss 0.033633
[epoch17, step1071]: loss 0.036780
[epoch17, step1072]: loss 0.036721
[epoch17, step1073]: loss 0.036077
[epoch17, step1074]: loss 0.034048
[epoch17, step1075]: loss 0.032806
[epoch17, step1076]: loss 0.036641
[epoch17, step1077]: loss 0.034423
[epoch17, step1078]: loss 0.034112
[epoch17, step1079]: loss 0.033301
[epoch17, step1080]: loss 0.034341
[epoch17, step1081]: loss 0.034817
[epoch17, step1082]: loss 0.035160
[epoch17, step1083]: loss 0.033311
[epoch17, step1084]: loss 0.032627
[epoch17, step1085]: loss 0.035566
[epoch17, step1086]: loss 0.033945
[epoch17, step1087]: loss 0.033876
[epoch17, step1088]: loss 0.032405
[epoch17, step1089]: loss 0.034344
[epoch17, step1090]: loss 0.035438
[epoch17, step1091]: loss 0.035594
[epoch17, step1092]: loss 0.033135
[epoch17, step1093]: loss 0.033497
[epoch17, step1094]: loss 0.037521
[epoch17, step1095]: loss 0.034919
[epoch17, step1096]: loss 0.033594
[epoch17, step1097]: loss 0.032972
[epoch17, step1098]: loss 0.034951
[epoch17, step1099]: loss 0.034539
[epoch17, step1100]: loss 0.035845
[epoch17, step1101]: loss 0.033831
[epoch17, step1102]: loss 0.033918
[epoch17, step1103]: loss 0.036226
[epoch17, step1104]: loss 0.033948
[epoch17, step1105]: loss 0.035345
[epoch17, step1106]: loss 0.033243
[epoch17, step1107]: loss 0.035595
[epoch17, step1108]: loss 0.033916
[epoch17, step1109]: loss 0.036234
[epoch17, step1110]: loss 0.034922
[epoch17, step1111]: loss 0.033592
[epoch17, step1112]: loss 0.036119
[epoch17, step1113]: loss 0.034021
[epoch17, step1114]: loss 0.035306
[epoch17, step1115]: loss 0.033168
[epoch17, step1116]: loss 0.034251
[epoch17, step1117]: loss 0.035137
[epoch17, step1118]: loss 0.035263
[epoch17, step1119]: loss 0.033827
[epoch17, step1120]: loss 0.032355
[epoch17, step1121]: loss 0.035591
[epoch17, step1122]: loss 0.033227
[epoch17, step1123]: loss 0.033605
[epoch17, step1124]: loss 0.035175
[epoch17, step1125]: loss 0.035224
[epoch17, step1126]: loss 0.036503
[epoch17, step1127]: loss 0.035688
[epoch17, step1128]: loss 0.033425
[epoch17, step1129]: loss 0.032422
[epoch17, step1130]: loss 0.036759
[epoch17, step1131]: loss 0.034414
[epoch17, step1132]: loss 0.035270
[epoch17, step1133]: loss 0.033129
[epoch17, step1134]: loss 0.034313
[epoch17, step1135]: loss 0.035431
[epoch17, step1136]: loss 0.035922
[epoch17, step1137]: loss 0.032951
[epoch17, step1138]: loss 0.032680
[epoch17, step1139]: loss 0.035787
[epoch17, step1140]: loss 0.033939
[epoch17, step1141]: loss 0.034226
[epoch17, step1142]: loss 0.032389
[epoch17, step1143]: loss 0.033942
[epoch17, step1144]: loss 0.035007
[epoch17, step1145]: loss 0.034835
[epoch17, step1146]: loss 0.032528
[epoch17, step1147]: loss 0.033736
[epoch17, step1148]: loss 0.035578
[epoch17, step1149]: loss 0.033803
[epoch17, step1150]: loss 0.033859
[epoch17, step1151]: loss 0.033493
[epoch17, step1152]: loss 0.035131
[epoch17, step1153]: loss 0.034625
[epoch17, step1154]: loss 0.036561
[epoch17, step1155]: loss 0.032905
[epoch17, step1156]: loss 0.032754
[epoch17, step1157]: loss 0.036476
[epoch17, step1158]: loss 0.033782
[epoch17, step1159]: loss 0.034196
[epoch17, step1160]: loss 0.034282
[epoch17, step1161]: loss 0.035169
[epoch17, step1162]: loss 0.034137
[epoch17, step1163]: loss 0.034812
[epoch17, step1164]: loss 0.032871
[epoch17, step1165]: loss 0.033798
[epoch17, step1166]: loss 0.036085
[epoch17, step1167]: loss 0.033715
[epoch17, step1168]: loss 0.034876
[epoch17, step1169]: loss 0.032431
[epoch17, step1170]: loss 0.034283
[epoch17, step1171]: loss 0.035000
[epoch17, step1172]: loss 0.035129
[epoch17, step1173]: loss 0.033126
[epoch17, step1174]: loss 0.033350
[epoch17, step1175]: loss 0.035503
[epoch17, step1176]: loss 0.033823
[epoch17, step1177]: loss 0.033943
[epoch17, step1178]: loss 0.032235
[epoch17, step1179]: loss 0.034050
[epoch17, step1180]: loss 0.034238
[epoch17, step1181]: loss 0.035583
[epoch17, step1182]: loss 0.033167
[epoch17, step1183]: loss 0.032914
[epoch17, step1184]: loss 0.035719
[epoch17, step1185]: loss 0.034639
[epoch17, step1186]: loss 0.034421
[epoch17, step1187]: loss 0.032877
[epoch17, step1188]: loss 0.033795
[epoch17, step1189]: loss 0.033786
[epoch17, step1190]: loss 0.035949
[epoch17, step1191]: loss 0.035134
[epoch17, step1192]: loss 0.032377
[epoch17, step1193]: loss 0.036101
[epoch17, step1194]: loss 0.034000
[epoch17, step1195]: loss 0.033504
[epoch17, step1196]: loss 0.032271
[epoch17, step1197]: loss 0.034541
[epoch17, step1198]: loss 0.035635
[epoch17, step1199]: loss 0.035595
[epoch17, step1200]: loss 0.032387
[epoch17, step1201]: loss 0.032604
[epoch17, step1202]: loss 0.037388
[epoch17, step1203]: loss 0.034398
[epoch17, step1204]: loss 0.033740
[epoch17, step1205]: loss 0.032405
[epoch17, step1206]: loss 0.033862
[epoch17, step1207]: loss 0.035082
[epoch17, step1208]: loss 0.036413
[epoch17, step1209]: loss 0.032360
[epoch17, step1210]: loss 0.032954
[epoch17, step1211]: loss 0.035823
[epoch17, step1212]: loss 0.033982
[epoch17, step1213]: loss 0.034235
[epoch17, step1214]: loss 0.032617
[epoch17, step1215]: loss 0.035367
[epoch17, step1216]: loss 0.033730
[epoch17, step1217]: loss 0.036202
[epoch17, step1218]: loss 0.032827
[epoch17, step1219]: loss 0.032997
[epoch17, step1220]: loss 0.035844
[epoch17, step1221]: loss 0.033592
[epoch17, step1222]: loss 0.034291
[epoch17, step1223]: loss 0.032305
[epoch17, step1224]: loss 0.034431
[epoch17, step1225]: loss 0.034119
[epoch17, step1226]: loss 0.034762
[epoch17, step1227]: loss 0.032788
[epoch17, step1228]: loss 0.032411
[epoch17, step1229]: loss 0.035635
[epoch17, step1230]: loss 0.034233
[epoch17, step1231]: loss 0.034086
[epoch17, step1232]: loss 0.034171
[epoch17, step1233]: loss 0.033663
[epoch17, step1234]: loss 0.033889
[epoch17, step1235]: loss 0.036064
[epoch17, step1236]: loss 0.033360
[epoch17, step1237]: loss 0.032633
[epoch17, step1238]: loss 0.035664
[epoch17, step1239]: loss 0.034421
[epoch17, step1240]: loss 0.034629
[epoch17, step1241]: loss 0.033595
[epoch17, step1242]: loss 0.034034
[epoch17, step1243]: loss 0.034454
[epoch17, step1244]: loss 0.035384
[epoch17, step1245]: loss 0.032871
[epoch17, step1246]: loss 0.032707
[epoch17, step1247]: loss 0.035064
[epoch17, step1248]: loss 0.034515
[epoch17, step1249]: loss 0.034804
[epoch17, step1250]: loss 0.032566
[epoch17, step1251]: loss 0.035327
[epoch17, step1252]: loss 0.036290
[epoch17, step1253]: loss 0.036242
[epoch17, step1254]: loss 0.033232
[epoch17, step1255]: loss 0.032443
[epoch17, step1256]: loss 0.035974
[epoch17, step1257]: loss 0.034928
[epoch17, step1258]: loss 0.034284
[epoch17, step1259]: loss 0.033013
[epoch17, step1260]: loss 0.034394
[epoch17, step1261]: loss 0.034106
[epoch17, step1262]: loss 0.035412
[epoch17, step1263]: loss 0.033539
[epoch17, step1264]: loss 0.033113
[epoch17, step1265]: loss 0.034964
[epoch17, step1266]: loss 0.034091
[epoch17, step1267]: loss 0.034579
[epoch17, step1268]: loss 0.033112
[epoch17, step1269]: loss 0.034174
[epoch17, step1270]: loss 0.033880
[epoch17, step1271]: loss 0.035347
[epoch17, step1272]: loss 0.032500
[epoch17, step1273]: loss 0.032881
[epoch17, step1274]: loss 0.036478
[epoch17, step1275]: loss 0.034723
[epoch17, step1276]: loss 0.034070
[epoch17, step1277]: loss 0.032703
[epoch17, step1278]: loss 0.034788
[epoch17, step1279]: loss 0.034839
[epoch17, step1280]: loss 0.035357
[epoch17, step1281]: loss 0.032792
[epoch17, step1282]: loss 0.033059
[epoch17, step1283]: loss 0.035342
[epoch17, step1284]: loss 0.034112
[epoch17, step1285]: loss 0.034285
[epoch17, step1286]: loss 0.032420
[epoch17, step1287]: loss 0.036098
[epoch17, step1288]: loss 0.035641
[epoch17, step1289]: loss 0.037463
[epoch17, step1290]: loss 0.033013
[epoch17, step1291]: loss 0.032776
[epoch17, step1292]: loss 0.036828
[epoch17, step1293]: loss 0.034434
[epoch17, step1294]: loss 0.034745
[epoch17, step1295]: loss 0.033068
[epoch17, step1296]: loss 0.034367
[epoch17, step1297]: loss 0.035236
[epoch17, step1298]: loss 0.035807
[epoch17, step1299]: loss 0.032877
[epoch17, step1300]: loss 0.033275
[epoch17, step1301]: loss 0.035960
[epoch17, step1302]: loss 0.034358
[epoch17, step1303]: loss 0.034117
[epoch17, step1304]: loss 0.032195
[epoch17, step1305]: loss 0.034759
[epoch17, step1306]: loss 0.034483
[epoch17, step1307]: loss 0.035293
[epoch17, step1308]: loss 0.033700
[epoch17, step1309]: loss 0.032213
[epoch17, step1310]: loss 0.035339
[epoch17, step1311]: loss 0.034428
[epoch17, step1312]: loss 0.035826
[epoch17, step1313]: loss 0.033028
[epoch17, step1314]: loss 0.033720
[epoch17, step1315]: loss 0.034372
[epoch17, step1316]: loss 0.036962
[epoch17, step1317]: loss 0.032632
[epoch17, step1318]: loss 0.032765
[epoch17, step1319]: loss 0.035210
[epoch17, step1320]: loss 0.033833
[epoch17, step1321]: loss 0.034053
[epoch17, step1322]: loss 0.033391
[epoch17, step1323]: loss 0.034474
[epoch17, step1324]: loss 0.033910
[epoch17, step1325]: loss 0.035393
[epoch17, step1326]: loss 0.032773
[epoch17, step1327]: loss 0.032167
[epoch17, step1328]: loss 0.036498
[epoch17, step1329]: loss 0.033601
[epoch17, step1330]: loss 0.034604
[epoch17, step1331]: loss 0.032347
[epoch17, step1332]: loss 0.034248
[epoch17, step1333]: loss 0.034131
[epoch17, step1334]: loss 0.036266
[epoch17, step1335]: loss 0.034871
[epoch17, step1336]: loss 0.032385
[epoch17, step1337]: loss 0.035893
[epoch17, step1338]: loss 0.034132
[epoch17, step1339]: loss 0.034377
[epoch17, step1340]: loss 0.032596
[epoch17, step1341]: loss 0.034139
[epoch17, step1342]: loss 0.033669
[epoch17, step1343]: loss 0.035603
[epoch17, step1344]: loss 0.032797
[epoch17, step1345]: loss 0.032538
[epoch17, step1346]: loss 0.035648
[epoch17, step1347]: loss 0.034285
[epoch17, step1348]: loss 0.033763
[epoch17, step1349]: loss 0.033007
[epoch17, step1350]: loss 0.034375
[epoch17, step1351]: loss 0.033935
[epoch17, step1352]: loss 0.034935
[epoch17, step1353]: loss 0.032581
[epoch17, step1354]: loss 0.032301
[epoch17, step1355]: loss 0.036135
[epoch17, step1356]: loss 0.033852
[epoch17, step1357]: loss 0.033949
[epoch17, step1358]: loss 0.032211
[epoch17, step1359]: loss 0.033556
[epoch17, step1360]: loss 0.035217
[epoch17, step1361]: loss 0.035741
[epoch17, step1362]: loss 0.033198
[epoch17, step1363]: loss 0.033059
[epoch17, step1364]: loss 0.035456
[epoch17, step1365]: loss 0.034721
[epoch17, step1366]: loss 0.034841
[epoch17, step1367]: loss 0.032753
[epoch17, step1368]: loss 0.034834
[epoch17, step1369]: loss 0.034823
[epoch17, step1370]: loss 0.035479
[epoch17, step1371]: loss 0.033081
[epoch17, step1372]: loss 0.032216
[epoch17, step1373]: loss 0.035272
[epoch17, step1374]: loss 0.034475
[epoch17, step1375]: loss 0.035367
[epoch17, step1376]: loss 0.032299
[epoch17, step1377]: loss 0.034280
[epoch17, step1378]: loss 0.034148
[epoch17, step1379]: loss 0.035078
[epoch17, step1380]: loss 0.033582
[epoch17, step1381]: loss 0.032266
[epoch17, step1382]: loss 0.035627
[epoch17, step1383]: loss 0.033977
[epoch17, step1384]: loss 0.034191
[epoch17, step1385]: loss 0.031891
[epoch17, step1386]: loss 0.034362
[epoch17, step1387]: loss 0.035427
[epoch17, step1388]: loss 0.034383
[epoch17, step1389]: loss 0.032034
[epoch17, step1390]: loss 0.032732
[epoch17, step1391]: loss 0.035665
[epoch17, step1392]: loss 0.034627
[epoch17, step1393]: loss 0.034620
[epoch17, step1394]: loss 0.033525
[epoch17, step1395]: loss 0.034077
[epoch17, step1396]: loss 0.034249
[epoch17, step1397]: loss 0.034931
[epoch17, step1398]: loss 0.032456
[epoch17, step1399]: loss 0.033272
[epoch17, step1400]: loss 0.035925
[epoch17, step1401]: loss 0.034351
[epoch17, step1402]: loss 0.034009
[epoch17, step1403]: loss 0.032371
[epoch17, step1404]: loss 0.034434
[epoch17, step1405]: loss 0.033710
[epoch17, step1406]: loss 0.035937
[epoch17, step1407]: loss 0.034785
[epoch17, step1408]: loss 0.031827
[epoch17, step1409]: loss 0.035481
[epoch17, step1410]: loss 0.033621
[epoch17, step1411]: loss 0.033238
[epoch17, step1412]: loss 0.032443
[epoch17, step1413]: loss 0.034482
[epoch17, step1414]: loss 0.034025
[epoch17, step1415]: loss 0.035252
[epoch17, step1416]: loss 0.033026
[epoch17, step1417]: loss 0.033689
[epoch17, step1418]: loss 0.036398
[epoch17, step1419]: loss 0.034404
[epoch17, step1420]: loss 0.033933
[epoch17, step1421]: loss 0.032447
[epoch17, step1422]: loss 0.034075
[epoch17, step1423]: loss 0.033898
[epoch17, step1424]: loss 0.034855
[epoch17, step1425]: loss 0.032531
[epoch17, step1426]: loss 0.032622
[epoch17, step1427]: loss 0.037018
[epoch17, step1428]: loss 0.035887
[epoch17, step1429]: loss 0.033942
[epoch17, step1430]: loss 0.033304
[epoch17, step1431]: loss 0.034778
[epoch17, step1432]: loss 0.033952
[epoch17, step1433]: loss 0.035708
[epoch17, step1434]: loss 0.034247
[epoch17, step1435]: loss 0.033710
[epoch17, step1436]: loss 0.035764
[epoch17, step1437]: loss 0.034637
[epoch17, step1438]: loss 0.035090
[epoch17, step1439]: loss 0.032661
[epoch17, step1440]: loss 0.034262
[epoch17, step1441]: loss 0.035162
[epoch17, step1442]: loss 0.034987
[epoch17, step1443]: loss 0.032624
[epoch17, step1444]: loss 0.032425
[epoch17, step1445]: loss 0.035722
[epoch17, step1446]: loss 0.033813
[epoch17, step1447]: loss 0.035198
[epoch17, step1448]: loss 0.032332
[epoch17, step1449]: loss 0.033925
[epoch17, step1450]: loss 0.034423
[epoch17, step1451]: loss 0.035469
[epoch17, step1452]: loss 0.032513
[epoch17, step1453]: loss 0.033827
[epoch17, step1454]: loss 0.036251
[epoch17, step1455]: loss 0.034760
[epoch17, step1456]: loss 0.034098
[epoch17, step1457]: loss 0.032474
[epoch17, step1458]: loss 0.034339
[epoch17, step1459]: loss 0.034437
[epoch17, step1460]: loss 0.035228
[epoch17, step1461]: loss 0.032950
[epoch17, step1462]: loss 0.033305
[epoch17, step1463]: loss 0.035978
[epoch17, step1464]: loss 0.034165
[epoch17, step1465]: loss 0.033560
[epoch17, step1466]: loss 0.031936
[epoch17, step1467]: loss 0.033817
[epoch17, step1468]: loss 0.034286
[epoch17, step1469]: loss 0.035021
[epoch17, step1470]: loss 0.033096
[epoch17, step1471]: loss 0.032679
[epoch17, step1472]: loss 0.035684
[epoch17, step1473]: loss 0.033983
[epoch17, step1474]: loss 0.035204
[epoch17, step1475]: loss 0.031954
[epoch17, step1476]: loss 0.035639
[epoch17, step1477]: loss 0.034361
[epoch17, step1478]: loss 0.034886
[epoch17, step1479]: loss 0.032735
[epoch17, step1480]: loss 0.031996
[epoch17, step1481]: loss 0.035175
[epoch17, step1482]: loss 0.034106
[epoch17, step1483]: loss 0.033932
[epoch17, step1484]: loss 0.033369
[epoch17, step1485]: loss 0.034316
[epoch17, step1486]: loss 0.033647
[epoch17, step1487]: loss 0.035873
[epoch17, step1488]: loss 0.033075
[epoch17, step1489]: loss 0.032219
[epoch17, step1490]: loss 0.035608
[epoch17, step1491]: loss 0.034270
[epoch17, step1492]: loss 0.033712
[epoch17, step1493]: loss 0.032844
[epoch17, step1494]: loss 0.034598
[epoch17, step1495]: loss 0.034509
[epoch17, step1496]: loss 0.035624
[epoch17, step1497]: loss 0.033458
[epoch17, step1498]: loss 0.032853
[epoch17, step1499]: loss 0.034980
[epoch17, step1500]: loss 0.034579
[epoch17, step1501]: loss 0.033685
[epoch17, step1502]: loss 0.031669
[epoch17, step1503]: loss 0.033911
[epoch17, step1504]: loss 0.033906
[epoch17, step1505]: loss 0.035838
[epoch17, step1506]: loss 0.032273
[epoch17, step1507]: loss 0.032876
[epoch17, step1508]: loss 0.036462
[epoch17, step1509]: loss 0.033519
[epoch17, step1510]: loss 0.033826
[epoch17, step1511]: loss 0.033463
[epoch17, step1512]: loss 0.034407
[epoch17, step1513]: loss 0.033471
[epoch17, step1514]: loss 0.035022
[epoch17, step1515]: loss 0.033534
[epoch17, step1516]: loss 0.032135

[epoch17]: avg loss 0.031903

[epoch18, step1]: loss 0.030952
[epoch18, step2]: loss 0.035114
[epoch18, step3]: loss 0.035129
[epoch18, step4]: loss 0.033383
[epoch18, step5]: loss 0.033116
[epoch18, step6]: loss 0.035755
[epoch18, step7]: loss 0.033404
[epoch18, step8]: loss 0.035396
[epoch18, step9]: loss 0.032197
[epoch18, step10]: loss 0.033408
[epoch18, step11]: loss 0.035788
[epoch18, step12]: loss 0.034912
[epoch18, step13]: loss 0.032871
[epoch18, step14]: loss 0.032371
[epoch18, step15]: loss 0.035219
[epoch18, step16]: loss 0.034175
[epoch18, step17]: loss 0.036332
[epoch18, step18]: loss 0.033057
[epoch18, step19]: loss 0.033206
[epoch18, step20]: loss 0.035961
[epoch18, step21]: loss 0.034853
[epoch18, step22]: loss 0.032677
[epoch18, step23]: loss 0.033934
[epoch18, step24]: loss 0.035365
[epoch18, step25]: loss 0.032260
[epoch18, step26]: loss 0.035177
[epoch18, step27]: loss 0.031692
[epoch18, step28]: loss 0.034614
[epoch18, step29]: loss 0.035939
[epoch18, step30]: loss 0.037046
[epoch18, step31]: loss 0.032548
[epoch18, step32]: loss 0.033893
[epoch18, step33]: loss 0.036543
[epoch18, step34]: loss 0.033611
[epoch18, step35]: loss 0.036541
[epoch18, step36]: loss 0.033597
[epoch18, step37]: loss 0.033027
[epoch18, step38]: loss 0.036568
[epoch18, step39]: loss 0.035598
[epoch18, step40]: loss 0.032854
[epoch18, step41]: loss 0.032818
[epoch18, step42]: loss 0.035430
[epoch18, step43]: loss 0.032749
[epoch18, step44]: loss 0.036454
[epoch18, step45]: loss 0.032903
[epoch18, step46]: loss 0.034118
[epoch18, step47]: loss 0.035152
[epoch18, step48]: loss 0.035569
[epoch18, step49]: loss 0.032858
[epoch18, step50]: loss 0.033496
[epoch18, step51]: loss 0.035665
[epoch18, step52]: loss 0.033383
[epoch18, step53]: loss 0.036853
[epoch18, step54]: loss 0.031935
[epoch18, step55]: loss 0.033721
[epoch18, step56]: loss 0.036811
[epoch18, step57]: loss 0.035205
[epoch18, step58]: loss 0.033217
[epoch18, step59]: loss 0.033123
[epoch18, step60]: loss 0.035936
[epoch18, step61]: loss 0.033134
[epoch18, step62]: loss 0.035341
[epoch18, step63]: loss 0.032970
[epoch18, step64]: loss 0.032848
[epoch18, step65]: loss 0.035502
[epoch18, step66]: loss 0.035836
[epoch18, step67]: loss 0.033210
[epoch18, step68]: loss 0.032722
[epoch18, step69]: loss 0.036288
[epoch18, step70]: loss 0.032850
[epoch18, step71]: loss 0.035748
[epoch18, step72]: loss 0.032535
[epoch18, step73]: loss 0.033580
[epoch18, step74]: loss 0.034839
[epoch18, step75]: loss 0.035867
[epoch18, step76]: loss 0.033440
[epoch18, step77]: loss 0.033591
[epoch18, step78]: loss 0.036537
[epoch18, step79]: loss 0.032761
[epoch18, step80]: loss 0.036470
[epoch18, step81]: loss 0.032490
[epoch18, step82]: loss 0.033346
[epoch18, step83]: loss 0.035533
[epoch18, step84]: loss 0.035363
[epoch18, step85]: loss 0.033872
[epoch18, step86]: loss 0.032952
[epoch18, step87]: loss 0.037293
[epoch18, step88]: loss 0.033066
[epoch18, step89]: loss 0.035079
[epoch18, step90]: loss 0.034425
[epoch18, step91]: loss 0.032597
[epoch18, step92]: loss 0.035660
[epoch18, step93]: loss 0.036080
[epoch18, step94]: loss 0.032047
[epoch18, step95]: loss 0.032832
[epoch18, step96]: loss 0.035179
[epoch18, step97]: loss 0.033655
[epoch18, step98]: loss 0.036777
[epoch18, step99]: loss 0.033695
[epoch18, step100]: loss 0.032600
[epoch18, step101]: loss 0.036738
[epoch18, step102]: loss 0.035876
[epoch18, step103]: loss 0.033564
[epoch18, step104]: loss 0.033132
[epoch18, step105]: loss 0.035943
[epoch18, step106]: loss 0.032695
[epoch18, step107]: loss 0.035968
[epoch18, step108]: loss 0.032790
[epoch18, step109]: loss 0.032426
[epoch18, step110]: loss 0.036772
[epoch18, step111]: loss 0.035466
[epoch18, step112]: loss 0.032487
[epoch18, step113]: loss 0.034243
[epoch18, step114]: loss 0.035873
[epoch18, step115]: loss 0.032495
[epoch18, step116]: loss 0.037401
[epoch18, step117]: loss 0.032008
[epoch18, step118]: loss 0.034372
[epoch18, step119]: loss 0.036018
[epoch18, step120]: loss 0.035573
[epoch18, step121]: loss 0.032739
[epoch18, step122]: loss 0.032426
[epoch18, step123]: loss 0.035893
[epoch18, step124]: loss 0.033126
[epoch18, step125]: loss 0.035830
[epoch18, step126]: loss 0.032827
[epoch18, step127]: loss 0.032960
[epoch18, step128]: loss 0.035685
[epoch18, step129]: loss 0.035770
[epoch18, step130]: loss 0.033033
[epoch18, step131]: loss 0.032732
[epoch18, step132]: loss 0.035416
[epoch18, step133]: loss 0.033097
[epoch18, step134]: loss 0.035611
[epoch18, step135]: loss 0.032983
[epoch18, step136]: loss 0.035663
[epoch18, step137]: loss 0.036442
[epoch18, step138]: loss 0.035361
[epoch18, step139]: loss 0.032887
[epoch18, step140]: loss 0.033050
[epoch18, step141]: loss 0.036114
[epoch18, step142]: loss 0.032622
[epoch18, step143]: loss 0.035220
[epoch18, step144]: loss 0.033924
[epoch18, step145]: loss 0.032631
[epoch18, step146]: loss 0.035516
[epoch18, step147]: loss 0.037178
[epoch18, step148]: loss 0.032245
[epoch18, step149]: loss 0.032276
[epoch18, step150]: loss 0.034972
[epoch18, step151]: loss 0.032844
[epoch18, step152]: loss 0.035140
[epoch18, step153]: loss 0.032314
[epoch18, step154]: loss 0.032535
[epoch18, step155]: loss 0.035880
[epoch18, step156]: loss 0.034818
[epoch18, step157]: loss 0.032183
[epoch18, step158]: loss 0.033795
[epoch18, step159]: loss 0.036381
[epoch18, step160]: loss 0.032762
[epoch18, step161]: loss 0.035933
[epoch18, step162]: loss 0.033215
[epoch18, step163]: loss 0.032907
[epoch18, step164]: loss 0.036116
[epoch18, step165]: loss 0.035798
[epoch18, step166]: loss 0.032853
[epoch18, step167]: loss 0.032261
[epoch18, step168]: loss 0.036748
[epoch18, step169]: loss 0.032473
[epoch18, step170]: loss 0.035715
[epoch18, step171]: loss 0.033031
[epoch18, step172]: loss 0.032927
[epoch18, step173]: loss 0.036021
[epoch18, step174]: loss 0.035179
[epoch18, step175]: loss 0.033627
[epoch18, step176]: loss 0.032837
[epoch18, step177]: loss 0.035642
[epoch18, step178]: loss 0.033488
[epoch18, step179]: loss 0.035749
[epoch18, step180]: loss 0.032392
[epoch18, step181]: loss 0.033379
[epoch18, step182]: loss 0.036937
[epoch18, step183]: loss 0.035755
[epoch18, step184]: loss 0.034018
[epoch18, step185]: loss 0.032851
[epoch18, step186]: loss 0.035447
[epoch18, step187]: loss 0.032625
[epoch18, step188]: loss 0.035213
[epoch18, step189]: loss 0.032950
[epoch18, step190]: loss 0.033218
[epoch18, step191]: loss 0.035627
[epoch18, step192]: loss 0.035878
[epoch18, step193]: loss 0.031924
[epoch18, step194]: loss 0.031525
[epoch18, step195]: loss 0.035830
[epoch18, step196]: loss 0.033421
[epoch18, step197]: loss 0.035773
[epoch18, step198]: loss 0.031764
[epoch18, step199]: loss 0.033210
[epoch18, step200]: loss 0.036335
[epoch18, step201]: loss 0.035979
[epoch18, step202]: loss 0.032139
[epoch18, step203]: loss 0.033494
[epoch18, step204]: loss 0.036425
[epoch18, step205]: loss 0.032501
[epoch18, step206]: loss 0.036021
[epoch18, step207]: loss 0.032747
[epoch18, step208]: loss 0.033440
[epoch18, step209]: loss 0.036326
[epoch18, step210]: loss 0.037173
[epoch18, step211]: loss 0.033891
[epoch18, step212]: loss 0.032941
[epoch18, step213]: loss 0.036053
[epoch18, step214]: loss 0.033457
[epoch18, step215]: loss 0.035525
[epoch18, step216]: loss 0.033118
[epoch18, step217]: loss 0.034289
[epoch18, step218]: loss 0.036734
[epoch18, step219]: loss 0.035113
[epoch18, step220]: loss 0.033609
[epoch18, step221]: loss 0.033087
[epoch18, step222]: loss 0.035582
[epoch18, step223]: loss 0.033086
[epoch18, step224]: loss 0.035516
[epoch18, step225]: loss 0.032253
[epoch18, step226]: loss 0.032725
[epoch18, step227]: loss 0.034852
[epoch18, step228]: loss 0.035915
[epoch18, step229]: loss 0.031769
[epoch18, step230]: loss 0.033189
[epoch18, step231]: loss 0.036559
[epoch18, step232]: loss 0.032942
[epoch18, step233]: loss 0.035328
[epoch18, step234]: loss 0.032282
[epoch18, step235]: loss 0.033332
[epoch18, step236]: loss 0.035595
[epoch18, step237]: loss 0.035280
[epoch18, step238]: loss 0.033117
[epoch18, step239]: loss 0.032147
[epoch18, step240]: loss 0.035338
[epoch18, step241]: loss 0.033114
[epoch18, step242]: loss 0.035623
[epoch18, step243]: loss 0.034132
[epoch18, step244]: loss 0.032934
[epoch18, step245]: loss 0.035788
[epoch18, step246]: loss 0.035769
[epoch18, step247]: loss 0.034551
[epoch18, step248]: loss 0.032062
[epoch18, step249]: loss 0.035400
[epoch18, step250]: loss 0.033463
[epoch18, step251]: loss 0.035858
[epoch18, step252]: loss 0.033402
[epoch18, step253]: loss 0.032235
[epoch18, step254]: loss 0.035295
[epoch18, step255]: loss 0.035012
[epoch18, step256]: loss 0.032669
[epoch18, step257]: loss 0.032723
[epoch18, step258]: loss 0.036459
[epoch18, step259]: loss 0.033648
[epoch18, step260]: loss 0.035504
[epoch18, step261]: loss 0.033480
[epoch18, step262]: loss 0.034471
[epoch18, step263]: loss 0.036867
[epoch18, step264]: loss 0.035781
[epoch18, step265]: loss 0.032497
[epoch18, step266]: loss 0.032499
[epoch18, step267]: loss 0.036563
[epoch18, step268]: loss 0.033067
[epoch18, step269]: loss 0.035559
[epoch18, step270]: loss 0.033515
[epoch18, step271]: loss 0.032814
[epoch18, step272]: loss 0.035425
[epoch18, step273]: loss 0.035553
[epoch18, step274]: loss 0.033343
[epoch18, step275]: loss 0.032333
[epoch18, step276]: loss 0.036518
[epoch18, step277]: loss 0.033683
[epoch18, step278]: loss 0.035564
[epoch18, step279]: loss 0.032165
[epoch18, step280]: loss 0.033159
[epoch18, step281]: loss 0.035598
[epoch18, step282]: loss 0.036748
[epoch18, step283]: loss 0.032554
[epoch18, step284]: loss 0.032182
[epoch18, step285]: loss 0.037342
[epoch18, step286]: loss 0.033054
[epoch18, step287]: loss 0.036773
[epoch18, step288]: loss 0.032236
[epoch18, step289]: loss 0.033484
[epoch18, step290]: loss 0.035595
[epoch18, step291]: loss 0.035204
[epoch18, step292]: loss 0.032627
[epoch18, step293]: loss 0.032317
[epoch18, step294]: loss 0.035219
[epoch18, step295]: loss 0.033215
[epoch18, step296]: loss 0.037240
[epoch18, step297]: loss 0.032552
[epoch18, step298]: loss 0.033611
[epoch18, step299]: loss 0.035082
[epoch18, step300]: loss 0.036327
[epoch18, step301]: loss 0.033490
[epoch18, step302]: loss 0.033750
[epoch18, step303]: loss 0.036557
[epoch18, step304]: loss 0.033001
[epoch18, step305]: loss 0.034944
[epoch18, step306]: loss 0.033151
[epoch18, step307]: loss 0.032637
[epoch18, step308]: loss 0.036227
[epoch18, step309]: loss 0.035862
[epoch18, step310]: loss 0.032738
[epoch18, step311]: loss 0.033106
[epoch18, step312]: loss 0.036479
[epoch18, step313]: loss 0.033231
[epoch18, step314]: loss 0.035832
[epoch18, step315]: loss 0.033691
[epoch18, step316]: loss 0.033060
[epoch18, step317]: loss 0.036755
[epoch18, step318]: loss 0.035692
[epoch18, step319]: loss 0.032504
[epoch18, step320]: loss 0.031923
[epoch18, step321]: loss 0.034771
[epoch18, step322]: loss 0.032714
[epoch18, step323]: loss 0.034790
[epoch18, step324]: loss 0.034878
[epoch18, step325]: loss 0.033407
[epoch18, step326]: loss 0.035312
[epoch18, step327]: loss 0.034498
[epoch18, step328]: loss 0.033267
[epoch18, step329]: loss 0.032329
[epoch18, step330]: loss 0.034954
[epoch18, step331]: loss 0.033176
[epoch18, step332]: loss 0.035660
[epoch18, step333]: loss 0.032749
[epoch18, step334]: loss 0.033142
[epoch18, step335]: loss 0.036278
[epoch18, step336]: loss 0.035970
[epoch18, step337]: loss 0.033936
[epoch18, step338]: loss 0.032470
[epoch18, step339]: loss 0.036045
[epoch18, step340]: loss 0.033261
[epoch18, step341]: loss 0.034878
[epoch18, step342]: loss 0.031953
[epoch18, step343]: loss 0.033145
[epoch18, step344]: loss 0.035169
[epoch18, step345]: loss 0.034717
[epoch18, step346]: loss 0.032943
[epoch18, step347]: loss 0.033321
[epoch18, step348]: loss 0.036598
[epoch18, step349]: loss 0.034815
[epoch18, step350]: loss 0.036747
[epoch18, step351]: loss 0.031779
[epoch18, step352]: loss 0.032786
[epoch18, step353]: loss 0.036384
[epoch18, step354]: loss 0.034325
[epoch18, step355]: loss 0.032397
[epoch18, step356]: loss 0.034230
[epoch18, step357]: loss 0.035401
[epoch18, step358]: loss 0.032314
[epoch18, step359]: loss 0.037441
[epoch18, step360]: loss 0.031918
[epoch18, step361]: loss 0.032853
[epoch18, step362]: loss 0.036924
[epoch18, step363]: loss 0.034737
[epoch18, step364]: loss 0.032631
[epoch18, step365]: loss 0.032701
[epoch18, step366]: loss 0.036588
[epoch18, step367]: loss 0.033032
[epoch18, step368]: loss 0.036236
[epoch18, step369]: loss 0.032422
[epoch18, step370]: loss 0.034123
[epoch18, step371]: loss 0.036845
[epoch18, step372]: loss 0.034836
[epoch18, step373]: loss 0.032506
[epoch18, step374]: loss 0.032134
[epoch18, step375]: loss 0.036242
[epoch18, step376]: loss 0.032894
[epoch18, step377]: loss 0.035519
[epoch18, step378]: loss 0.032820
[epoch18, step379]: loss 0.033035
[epoch18, step380]: loss 0.036274
[epoch18, step381]: loss 0.035208
[epoch18, step382]: loss 0.033050
[epoch18, step383]: loss 0.032058
[epoch18, step384]: loss 0.035965
[epoch18, step385]: loss 0.032306
[epoch18, step386]: loss 0.035203
[epoch18, step387]: loss 0.032685
[epoch18, step388]: loss 0.034213
[epoch18, step389]: loss 0.035556
[epoch18, step390]: loss 0.037294
[epoch18, step391]: loss 0.032355
[epoch18, step392]: loss 0.033411
[epoch18, step393]: loss 0.035793
[epoch18, step394]: loss 0.032814
[epoch18, step395]: loss 0.035546
[epoch18, step396]: loss 0.032212
[epoch18, step397]: loss 0.032730
[epoch18, step398]: loss 0.035380
[epoch18, step399]: loss 0.035199
[epoch18, step400]: loss 0.032982
[epoch18, step401]: loss 0.031880
[epoch18, step402]: loss 0.035605
[epoch18, step403]: loss 0.032700
[epoch18, step404]: loss 0.035632
[epoch18, step405]: loss 0.032645
[epoch18, step406]: loss 0.033346
[epoch18, step407]: loss 0.035676
[epoch18, step408]: loss 0.035154
[epoch18, step409]: loss 0.034620
[epoch18, step410]: loss 0.033036
[epoch18, step411]: loss 0.036015
[epoch18, step412]: loss 0.034012
[epoch18, step413]: loss 0.036824
[epoch18, step414]: loss 0.034318
[epoch18, step415]: loss 0.033100
[epoch18, step416]: loss 0.036222
[epoch18, step417]: loss 0.035497
[epoch18, step418]: loss 0.033682
[epoch18, step419]: loss 0.032023
[epoch18, step420]: loss 0.035740
[epoch18, step421]: loss 0.032473
[epoch18, step422]: loss 0.035527
[epoch18, step423]: loss 0.032864
[epoch18, step424]: loss 0.032921
[epoch18, step425]: loss 0.035823
[epoch18, step426]: loss 0.036126
[epoch18, step427]: loss 0.033340
[epoch18, step428]: loss 0.032826
[epoch18, step429]: loss 0.036999
[epoch18, step430]: loss 0.033349
[epoch18, step431]: loss 0.035904
[epoch18, step432]: loss 0.032648
[epoch18, step433]: loss 0.033464
[epoch18, step434]: loss 0.035747
[epoch18, step435]: loss 0.035725
[epoch18, step436]: loss 0.032885
[epoch18, step437]: loss 0.033054
[epoch18, step438]: loss 0.035795
[epoch18, step439]: loss 0.033334
[epoch18, step440]: loss 0.035718
[epoch18, step441]: loss 0.032654
[epoch18, step442]: loss 0.032417
[epoch18, step443]: loss 0.036485
[epoch18, step444]: loss 0.034773
[epoch18, step445]: loss 0.032793
[epoch18, step446]: loss 0.033283
[epoch18, step447]: loss 0.036238
[epoch18, step448]: loss 0.033419
[epoch18, step449]: loss 0.035947
[epoch18, step450]: loss 0.033199
[epoch18, step451]: loss 0.032618
[epoch18, step452]: loss 0.035946
[epoch18, step453]: loss 0.035410
[epoch18, step454]: loss 0.032412
[epoch18, step455]: loss 0.033048
[epoch18, step456]: loss 0.035302
[epoch18, step457]: loss 0.033315
[epoch18, step458]: loss 0.035263
[epoch18, step459]: loss 0.033181
[epoch18, step460]: loss 0.032638
[epoch18, step461]: loss 0.036268
[epoch18, step462]: loss 0.034927
[epoch18, step463]: loss 0.033302
[epoch18, step464]: loss 0.032349
[epoch18, step465]: loss 0.036885
[epoch18, step466]: loss 0.032924
[epoch18, step467]: loss 0.034996
[epoch18, step468]: loss 0.032781
[epoch18, step469]: loss 0.032536
[epoch18, step470]: loss 0.035727
[epoch18, step471]: loss 0.035224
[epoch18, step472]: loss 0.033656
[epoch18, step473]: loss 0.032532
[epoch18, step474]: loss 0.034720
[epoch18, step475]: loss 0.033980
[epoch18, step476]: loss 0.036974
[epoch18, step477]: loss 0.032867
[epoch18, step478]: loss 0.032043
[epoch18, step479]: loss 0.035951
[epoch18, step480]: loss 0.034634
[epoch18, step481]: loss 0.032216
[epoch18, step482]: loss 0.031705
[epoch18, step483]: loss 0.035633
[epoch18, step484]: loss 0.033512
[epoch18, step485]: loss 0.035754
[epoch18, step486]: loss 0.032960
[epoch18, step487]: loss 0.032499
[epoch18, step488]: loss 0.036840
[epoch18, step489]: loss 0.035354
[epoch18, step490]: loss 0.033855
[epoch18, step491]: loss 0.033130
[epoch18, step492]: loss 0.036741
[epoch18, step493]: loss 0.033397
[epoch18, step494]: loss 0.034704
[epoch18, step495]: loss 0.034010
[epoch18, step496]: loss 0.033014
[epoch18, step497]: loss 0.035956
[epoch18, step498]: loss 0.035035
[epoch18, step499]: loss 0.032497
[epoch18, step500]: loss 0.032389
[epoch18, step501]: loss 0.035438
[epoch18, step502]: loss 0.032357
[epoch18, step503]: loss 0.036053
[epoch18, step504]: loss 0.033456
[epoch18, step505]: loss 0.032070
[epoch18, step506]: loss 0.036475
[epoch18, step507]: loss 0.036410
[epoch18, step508]: loss 0.033509
[epoch18, step509]: loss 0.032612
[epoch18, step510]: loss 0.036698
[epoch18, step511]: loss 0.033979
[epoch18, step512]: loss 0.035410
[epoch18, step513]: loss 0.032898
[epoch18, step514]: loss 0.032691
[epoch18, step515]: loss 0.035726
[epoch18, step516]: loss 0.035052
[epoch18, step517]: loss 0.032780
[epoch18, step518]: loss 0.032638
[epoch18, step519]: loss 0.035778
[epoch18, step520]: loss 0.032646
[epoch18, step521]: loss 0.035656
[epoch18, step522]: loss 0.032356
[epoch18, step523]: loss 0.032445
[epoch18, step524]: loss 0.036206
[epoch18, step525]: loss 0.036779
[epoch18, step526]: loss 0.033155
[epoch18, step527]: loss 0.032765
[epoch18, step528]: loss 0.037398
[epoch18, step529]: loss 0.033478
[epoch18, step530]: loss 0.035622
[epoch18, step531]: loss 0.032317
[epoch18, step532]: loss 0.033190
[epoch18, step533]: loss 0.036677
[epoch18, step534]: loss 0.034989
[epoch18, step535]: loss 0.034212
[epoch18, step536]: loss 0.032755
[epoch18, step537]: loss 0.035418
[epoch18, step538]: loss 0.033713
[epoch18, step539]: loss 0.035550
[epoch18, step540]: loss 0.033435
[epoch18, step541]: loss 0.032862
[epoch18, step542]: loss 0.035364
[epoch18, step543]: loss 0.034766
[epoch18, step544]: loss 0.032716
[epoch18, step545]: loss 0.032252
[epoch18, step546]: loss 0.036300
[epoch18, step547]: loss 0.032766
[epoch18, step548]: loss 0.036187
[epoch18, step549]: loss 0.033303
[epoch18, step550]: loss 0.032838
[epoch18, step551]: loss 0.036099
[epoch18, step552]: loss 0.035222
[epoch18, step553]: loss 0.034062
[epoch18, step554]: loss 0.032142
[epoch18, step555]: loss 0.035656
[epoch18, step556]: loss 0.032935
[epoch18, step557]: loss 0.035184
[epoch18, step558]: loss 0.032667
[epoch18, step559]: loss 0.032842
[epoch18, step560]: loss 0.035821
[epoch18, step561]: loss 0.034994
[epoch18, step562]: loss 0.032498
[epoch18, step563]: loss 0.032610
[epoch18, step564]: loss 0.035717
[epoch18, step565]: loss 0.029385
[epoch18, step566]: loss 0.040165
[epoch18, step567]: loss 0.029281
[epoch18, step568]: loss 0.028071
[epoch18, step569]: loss 0.024884
[epoch18, step570]: loss 0.034420
[epoch18, step571]: loss 0.026399
[epoch18, step572]: loss 0.026530
[epoch18, step573]: loss 0.031011
[epoch18, step574]: loss 0.029469
[epoch18, step575]: loss 0.022093
[epoch18, step576]: loss 0.022158
[epoch18, step577]: loss 0.026181
[epoch18, step578]: loss 0.019343
[epoch18, step579]: loss 0.029529
[epoch18, step580]: loss 0.019700
[epoch18, step581]: loss 0.027480
[epoch18, step582]: loss 0.025924
[epoch18, step583]: loss 0.022832
[epoch18, step584]: loss 0.024721
[epoch18, step585]: loss 0.025408
[epoch18, step586]: loss 0.021930
[epoch18, step587]: loss 0.027639
[epoch18, step588]: loss 0.022705
[epoch18, step589]: loss 0.022700
[epoch18, step590]: loss 0.027426
[epoch18, step591]: loss 0.020850
[epoch18, step592]: loss 0.025787
[epoch18, step593]: loss 0.021855
[epoch18, step594]: loss 0.025314
[epoch18, step595]: loss 0.026348
[epoch18, step596]: loss 0.022751
[epoch18, step597]: loss 0.024363
[epoch18, step598]: loss 0.027570
[epoch18, step599]: loss 0.024732
[epoch18, step600]: loss 0.026496
[epoch18, step601]: loss 0.019517
[epoch18, step602]: loss 0.022542
[epoch18, step603]: loss 0.026678
[epoch18, step604]: loss 0.027575
[epoch18, step605]: loss 0.026693
[epoch18, step606]: loss 0.025821
[epoch18, step607]: loss 0.027985
[epoch18, step608]: loss 0.026507
[epoch18, step609]: loss 0.027036
[epoch18, step610]: loss 0.026405
[epoch18, step611]: loss 0.026623
[epoch18, step612]: loss 0.025453
[epoch18, step613]: loss 0.020213
[epoch18, step614]: loss 0.025436
[epoch18, step615]: loss 0.027800
[epoch18, step616]: loss 0.024173
[epoch18, step617]: loss 0.023831
[epoch18, step618]: loss 0.025824
[epoch18, step619]: loss 0.026933
[epoch18, step620]: loss 0.024319
[epoch18, step621]: loss 0.026483
[epoch18, step622]: loss 0.020767
[epoch18, step623]: loss 0.024373
[epoch18, step624]: loss 0.026719
[epoch18, step625]: loss 0.026285
[epoch18, step626]: loss 0.028746
[epoch18, step627]: loss 0.023051
[epoch18, step628]: loss 0.025733
[epoch18, step629]: loss 0.020762
[epoch18, step630]: loss 0.023455
[epoch18, step631]: loss 0.031174
[epoch18, step632]: loss 0.023315
[epoch18, step633]: loss 0.024596
[epoch18, step634]: loss 0.027277
[epoch18, step635]: loss 0.025758
[epoch18, step636]: loss 0.020903
[epoch18, step637]: loss 0.027442
[epoch18, step638]: loss 0.026894
[epoch18, step639]: loss 0.022835
[epoch18, step640]: loss 0.029986
[epoch18, step641]: loss 0.030401
[epoch18, step642]: loss 0.025172
[epoch18, step643]: loss 0.025915
[epoch18, step644]: loss 0.026431
[epoch18, step645]: loss 0.023568
[epoch18, step646]: loss 0.026437
[epoch18, step647]: loss 0.023664
[epoch18, step648]: loss 0.023288
[epoch18, step649]: loss 0.028335
[epoch18, step650]: loss 0.022719
[epoch18, step651]: loss 0.026607
[epoch18, step652]: loss 0.027252
[epoch18, step653]: loss 0.028434
[epoch18, step654]: loss 0.023386
[epoch18, step655]: loss 0.024089
[epoch18, step656]: loss 0.021944
[epoch18, step657]: loss 0.027718
[epoch18, step658]: loss 0.025187
[epoch18, step659]: loss 0.027585
[epoch18, step660]: loss 0.024198
[epoch18, step661]: loss 0.027068
[epoch18, step662]: loss 0.024129
[epoch18, step663]: loss 0.021376
[epoch18, step664]: loss 0.025325
[epoch18, step665]: loss 0.028063
[epoch18, step666]: loss 0.027234
[epoch18, step667]: loss 0.026522
[epoch18, step668]: loss 0.022495
[epoch18, step669]: loss 0.026274
[epoch18, step670]: loss 0.027139
[epoch18, step671]: loss 0.021490
[epoch18, step672]: loss 0.024374
[epoch18, step673]: loss 0.022296
[epoch18, step674]: loss 0.021529
[epoch18, step675]: loss 0.020337
[epoch18, step676]: loss 0.024692
[epoch18, step677]: loss 0.025388
[epoch18, step678]: loss 0.023245
[epoch18, step679]: loss 0.023814
[epoch18, step680]: loss 0.030810
[epoch18, step681]: loss 0.022144
[epoch18, step682]: loss 0.026323
[epoch18, step683]: loss 0.025626
[epoch18, step684]: loss 0.025251
[epoch18, step685]: loss 0.024616
[epoch18, step686]: loss 0.027604
[epoch18, step687]: loss 0.027111
[epoch18, step688]: loss 0.023021
[epoch18, step689]: loss 0.024659
[epoch18, step690]: loss 0.025522
[epoch18, step691]: loss 0.024611
[epoch18, step692]: loss 0.022841
[epoch18, step693]: loss 0.027864
[epoch18, step694]: loss 0.022776
[epoch18, step695]: loss 0.026569
[epoch18, step696]: loss 0.026022
[epoch18, step697]: loss 0.027413
[epoch18, step698]: loss 0.025121
[epoch18, step699]: loss 0.023400
[epoch18, step700]: loss 0.021955
[epoch18, step701]: loss 0.025972
[epoch18, step702]: loss 0.021734
[epoch18, step703]: loss 0.023370
[epoch18, step704]: loss 0.025745
[epoch18, step705]: loss 0.024865
[epoch18, step706]: loss 0.023895
[epoch18, step707]: loss 0.024513
[epoch18, step708]: loss 0.026273
[epoch18, step709]: loss 0.027510
[epoch18, step710]: loss 0.024011
[epoch18, step711]: loss 0.023935
[epoch18, step712]: loss 0.027106
[epoch18, step713]: loss 0.026537
[epoch18, step714]: loss 0.021644
[epoch18, step715]: loss 0.023106
[epoch18, step716]: loss 0.026013
[epoch18, step717]: loss 0.023825
[epoch18, step718]: loss 0.025159
[epoch18, step719]: loss 0.033337
[epoch18, step720]: loss 0.025105
[epoch18, step721]: loss 0.023212
[epoch18, step722]: loss 0.031246
[epoch18, step723]: loss 0.026561
[epoch18, step724]: loss 0.023400
[epoch18, step725]: loss 0.028470
[epoch18, step726]: loss 0.022254
[epoch18, step727]: loss 0.024770
[epoch18, step728]: loss 0.026525
[epoch18, step729]: loss 0.021584
[epoch18, step730]: loss 0.022853
[epoch18, step731]: loss 0.026152
[epoch18, step732]: loss 0.025889
[epoch18, step733]: loss 0.024050
[epoch18, step734]: loss 0.022865
[epoch18, step735]: loss 0.027195
[epoch18, step736]: loss 0.025024
[epoch18, step737]: loss 0.026424
[epoch18, step738]: loss 0.020666
[epoch18, step739]: loss 0.025637
[epoch18, step740]: loss 0.022693
[epoch18, step741]: loss 0.025369
[epoch18, step742]: loss 0.021961
[epoch18, step743]: loss 0.023262
[epoch18, step744]: loss 0.024064
[epoch18, step745]: loss 0.024761
[epoch18, step746]: loss 0.025633
[epoch18, step747]: loss 0.027641
[epoch18, step748]: loss 0.026076
[epoch18, step749]: loss 0.026883
[epoch18, step750]: loss 0.027782
[epoch18, step751]: loss 0.021660
[epoch18, step752]: loss 0.025436
[epoch18, step753]: loss 0.025720
[epoch18, step754]: loss 0.022975
[epoch18, step755]: loss 0.026228
[epoch18, step756]: loss 0.023576
[epoch18, step757]: loss 0.020984
[epoch18, step758]: loss 0.025038
[epoch18, step759]: loss 0.023259
[epoch18, step760]: loss 0.024330
[epoch18, step761]: loss 0.026338
[epoch18, step762]: loss 0.021786
[epoch18, step763]: loss 0.025601
[epoch18, step764]: loss 0.024207
[epoch18, step765]: loss 0.026115
[epoch18, step766]: loss 0.025057
[epoch18, step767]: loss 0.026871
[epoch18, step768]: loss 0.021561
[epoch18, step769]: loss 0.026994
[epoch18, step770]: loss 0.026158
[epoch18, step771]: loss 0.023228
[epoch18, step772]: loss 0.029138
[epoch18, step773]: loss 0.026748
[epoch18, step774]: loss 0.023875
[epoch18, step775]: loss 0.021164
[epoch18, step776]: loss 0.026038
[epoch18, step777]: loss 0.022964
[epoch18, step778]: loss 0.028647
[epoch18, step779]: loss 0.024133
[epoch18, step780]: loss 0.020264
[epoch18, step781]: loss 0.024715
[epoch18, step782]: loss 0.022967
[epoch18, step783]: loss 0.019733
[epoch18, step784]: loss 0.020615
[epoch18, step785]: loss 0.021344
[epoch18, step786]: loss 0.024321
[epoch18, step787]: loss 0.023504
[epoch18, step788]: loss 0.025007
[epoch18, step789]: loss 0.022792
[epoch18, step790]: loss 0.023176
[epoch18, step791]: loss 0.027019
[epoch18, step792]: loss 0.025018
[epoch18, step793]: loss 0.027314
[epoch18, step794]: loss 0.020426
[epoch18, step795]: loss 0.025842
[epoch18, step796]: loss 0.027667
[epoch18, step797]: loss 0.028331
[epoch18, step798]: loss 0.027149
[epoch18, step799]: loss 0.025599
[epoch18, step800]: loss 0.021625
[epoch18, step801]: loss 0.022188
[epoch18, step802]: loss 0.023052
[epoch18, step803]: loss 0.026391
[epoch18, step804]: loss 0.027396
[epoch18, step805]: loss 0.028900
[epoch18, step806]: loss 0.021834
[epoch18, step807]: loss 0.020818
[epoch18, step808]: loss 0.023287
[epoch18, step809]: loss 0.023315
[epoch18, step810]: loss 0.025875
[epoch18, step811]: loss 0.026116
[epoch18, step812]: loss 0.024888
[epoch18, step813]: loss 0.024090
[epoch18, step814]: loss 0.025061
[epoch18, step815]: loss 0.024944
[epoch18, step816]: loss 0.024462
[epoch18, step817]: loss 0.024964
[epoch18, step818]: loss 0.022758
[epoch18, step819]: loss 0.020706
[epoch18, step820]: loss 0.023683
[epoch18, step821]: loss 0.022044
[epoch18, step822]: loss 0.031097
[epoch18, step823]: loss 0.023867
[epoch18, step824]: loss 0.027060
[epoch18, step825]: loss 0.025515
[epoch18, step826]: loss 0.024575
[epoch18, step827]: loss 0.027111
[epoch18, step828]: loss 0.029075
[epoch18, step829]: loss 0.026747
[epoch18, step830]: loss 0.022553
[epoch18, step831]: loss 0.026238
[epoch18, step832]: loss 0.021339
[epoch18, step833]: loss 0.028952
[epoch18, step834]: loss 0.025821
[epoch18, step835]: loss 0.020886
[epoch18, step836]: loss 0.026934
[epoch18, step837]: loss 0.025448
[epoch18, step838]: loss 0.026264
[epoch18, step839]: loss 0.028602
[epoch18, step840]: loss 0.020729
[epoch18, step841]: loss 0.024591
[epoch18, step842]: loss 0.027786
[epoch18, step843]: loss 0.025108
[epoch18, step844]: loss 0.025371
[epoch18, step845]: loss 0.021392
[epoch18, step846]: loss 0.025861
[epoch18, step847]: loss 0.027084
[epoch18, step848]: loss 0.025566
[epoch18, step849]: loss 0.025300
[epoch18, step850]: loss 0.023402
[epoch18, step851]: loss 0.024273
[epoch18, step852]: loss 0.023279
[epoch18, step853]: loss 0.029677
[epoch18, step854]: loss 0.022920
[epoch18, step855]: loss 0.027393
[epoch18, step856]: loss 0.022255
[epoch18, step857]: loss 0.026249
[epoch18, step858]: loss 0.024410
[epoch18, step859]: loss 0.023648
[epoch18, step860]: loss 0.022760
[epoch18, step861]: loss 0.023365
[epoch18, step862]: loss 0.023002
[epoch18, step863]: loss 0.020712
[epoch18, step864]: loss 0.026996
[epoch18, step865]: loss 0.023415
[epoch18, step866]: loss 0.025352
[epoch18, step867]: loss 0.026179
[epoch18, step868]: loss 0.027066
[epoch18, step869]: loss 0.023698
[epoch18, step870]: loss 0.031535
[epoch18, step871]: loss 0.022386
[epoch18, step872]: loss 0.025652
[epoch18, step873]: loss 0.025709
[epoch18, step874]: loss 0.023869
[epoch18, step875]: loss 0.024431
[epoch18, step876]: loss 0.024462
[epoch18, step877]: loss 0.019218
[epoch18, step878]: loss 0.023554
[epoch18, step879]: loss 0.027873
[epoch18, step880]: loss 0.025531
[epoch18, step881]: loss 0.022450
[epoch18, step882]: loss 0.024413
[epoch18, step883]: loss 0.024227
[epoch18, step884]: loss 0.026857
[epoch18, step885]: loss 0.026088
[epoch18, step886]: loss 0.026342
[epoch18, step887]: loss 0.024402
[epoch18, step888]: loss 0.024836
[epoch18, step889]: loss 0.023891
[epoch18, step890]: loss 0.023710
[epoch18, step891]: loss 0.025617
[epoch18, step892]: loss 0.021164
[epoch18, step893]: loss 0.024509
[epoch18, step894]: loss 0.024613
[epoch18, step895]: loss 0.022835
[epoch18, step896]: loss 0.022369
[epoch18, step897]: loss 0.024210
[epoch18, step898]: loss 0.025883
[epoch18, step899]: loss 0.028469
[epoch18, step900]: loss 0.027183
[epoch18, step901]: loss 0.025820
[epoch18, step902]: loss 0.024111
[epoch18, step903]: loss 0.024690
[epoch18, step904]: loss 0.028118
[epoch18, step905]: loss 0.027755
[epoch18, step906]: loss 0.022576
[epoch18, step907]: loss 0.023518
[epoch18, step908]: loss 0.022813
[epoch18, step909]: loss 0.025640
[epoch18, step910]: loss 0.023260
[epoch18, step911]: loss 0.025413
[epoch18, step912]: loss 0.023893
[epoch18, step913]: loss 0.024234
[epoch18, step914]: loss 0.030853
[epoch18, step915]: loss 0.024169
[epoch18, step916]: loss 0.023727
[epoch18, step917]: loss 0.025108
[epoch18, step918]: loss 0.028586
[epoch18, step919]: loss 0.024205
[epoch18, step920]: loss 0.027626
[epoch18, step921]: loss 0.024411
[epoch18, step922]: loss 0.023153
[epoch18, step923]: loss 0.023083
[epoch18, step924]: loss 0.021564
[epoch18, step925]: loss 0.025379
[epoch18, step926]: loss 0.026923
[epoch18, step927]: loss 0.025904
[epoch18, step928]: loss 0.024990
[epoch18, step929]: loss 0.027674
[epoch18, step930]: loss 0.025985
[epoch18, step931]: loss 0.027848
[epoch18, step932]: loss 0.021778
[epoch18, step933]: loss 0.028620
[epoch18, step934]: loss 0.022357
[epoch18, step935]: loss 0.022444
[epoch18, step936]: loss 0.022511
[epoch18, step937]: loss 0.027517
[epoch18, step938]: loss 0.025643
[epoch18, step939]: loss 0.020978
[epoch18, step940]: loss 0.023368
[epoch18, step941]: loss 0.026933
[epoch18, step942]: loss 0.025497
[epoch18, step943]: loss 0.023505
[epoch18, step944]: loss 0.028066
[epoch18, step945]: loss 0.020501
[epoch18, step946]: loss 0.025659
[epoch18, step947]: loss 0.028009
[epoch18, step948]: loss 0.019685
[epoch18, step949]: loss 0.022725
[epoch18, step950]: loss 0.026586
[epoch18, step951]: loss 0.028936
[epoch18, step952]: loss 0.025050
[epoch18, step953]: loss 0.027628
[epoch18, step954]: loss 0.022873
[epoch18, step955]: loss 0.037051
[epoch18, step956]: loss 0.052817
[epoch18, step957]: loss 0.047180
[epoch18, step958]: loss 0.044737
[epoch18, step959]: loss 0.049050
[epoch18, step960]: loss 0.045783
[epoch18, step961]: loss 0.046652
[epoch18, step962]: loss 0.045312
[epoch18, step963]: loss 0.043418
[epoch18, step964]: loss 0.043966
[epoch18, step965]: loss 0.045173
[epoch18, step966]: loss 0.042777
[epoch18, step967]: loss 0.041197
[epoch18, step968]: loss 0.043884
[epoch18, step969]: loss 0.043239
[epoch18, step970]: loss 0.042550
[epoch18, step971]: loss 0.042145
[epoch18, step972]: loss 0.042320
[epoch18, step973]: loss 0.041734
[epoch18, step974]: loss 0.043629
[epoch18, step975]: loss 0.040177
[epoch18, step976]: loss 0.038675
[epoch18, step977]: loss 0.042134
[epoch18, step978]: loss 0.040388
[epoch18, step979]: loss 0.039529
[epoch18, step980]: loss 0.037841
[epoch18, step981]: loss 0.038806
[epoch18, step982]: loss 0.039194
[epoch18, step983]: loss 0.041089
[epoch18, step984]: loss 0.037343
[epoch18, step985]: loss 0.037064
[epoch18, step986]: loss 0.041052
[epoch18, step987]: loss 0.039347
[epoch18, step988]: loss 0.039002
[epoch18, step989]: loss 0.038308
[epoch18, step990]: loss 0.038752
[epoch18, step991]: loss 0.039349
[epoch18, step992]: loss 0.039659
[epoch18, step993]: loss 0.037117
[epoch18, step994]: loss 0.036140
[epoch18, step995]: loss 0.040225
[epoch18, step996]: loss 0.038367
[epoch18, step997]: loss 0.037872
[epoch18, step998]: loss 0.037447
[epoch18, step999]: loss 0.038680
[epoch18, step1000]: loss 0.038749
[epoch18, step1001]: loss 0.039395
[epoch18, step1002]: loss 0.037062
[epoch18, step1003]: loss 0.036286
[epoch18, step1004]: loss 0.039924
[epoch18, step1005]: loss 0.037726
[epoch18, step1006]: loss 0.037693
[epoch18, step1007]: loss 0.036396
[epoch18, step1008]: loss 0.037847
[epoch18, step1009]: loss 0.038339
[epoch18, step1010]: loss 0.039789
[epoch18, step1011]: loss 0.036575
[epoch18, step1012]: loss 0.036626
[epoch18, step1013]: loss 0.039883
[epoch18, step1014]: loss 0.038861
[epoch18, step1015]: loss 0.040472
[epoch18, step1016]: loss 0.036112
[epoch18, step1017]: loss 0.037521
[epoch18, step1018]: loss 0.037893
[epoch18, step1019]: loss 0.039236
[epoch18, step1020]: loss 0.038708
[epoch18, step1021]: loss 0.035623
[epoch18, step1022]: loss 0.039287
[epoch18, step1023]: loss 0.037911
[epoch18, step1024]: loss 0.038377
[epoch18, step1025]: loss 0.036032
[epoch18, step1026]: loss 0.037080
[epoch18, step1027]: loss 0.037860
[epoch18, step1028]: loss 0.039008
[epoch18, step1029]: loss 0.036472
[epoch18, step1030]: loss 0.035436
[epoch18, step1031]: loss 0.038331
[epoch18, step1032]: loss 0.038280
[epoch18, step1033]: loss 0.037274
[epoch18, step1034]: loss 0.036016
[epoch18, step1035]: loss 0.036997
[epoch18, step1036]: loss 0.038102
[epoch18, step1037]: loss 0.038638
[epoch18, step1038]: loss 0.036173
[epoch18, step1039]: loss 0.036002
[epoch18, step1040]: loss 0.038662
[epoch18, step1041]: loss 0.037534
[epoch18, step1042]: loss 0.036779
[epoch18, step1043]: loss 0.035927
[epoch18, step1044]: loss 0.037688
[epoch18, step1045]: loss 0.038142
[epoch18, step1046]: loss 0.039028
[epoch18, step1047]: loss 0.036368
[epoch18, step1048]: loss 0.035435
[epoch18, step1049]: loss 0.039085
[epoch18, step1050]: loss 0.038145
[epoch18, step1051]: loss 0.037713
[epoch18, step1052]: loss 0.036285
[epoch18, step1053]: loss 0.037799
[epoch18, step1054]: loss 0.037769
[epoch18, step1055]: loss 0.038257
[epoch18, step1056]: loss 0.035450
[epoch18, step1057]: loss 0.036215
[epoch18, step1058]: loss 0.039779
[epoch18, step1059]: loss 0.038539
[epoch18, step1060]: loss 0.037504
[epoch18, step1061]: loss 0.035186
[epoch18, step1062]: loss 0.037859
[epoch18, step1063]: loss 0.037733
[epoch18, step1064]: loss 0.038661
[epoch18, step1065]: loss 0.036067
[epoch18, step1066]: loss 0.035133
[epoch18, step1067]: loss 0.039084
[epoch18, step1068]: loss 0.036359
[epoch18, step1069]: loss 0.036814
[epoch18, step1070]: loss 0.035679
[epoch18, step1071]: loss 0.037872
[epoch18, step1072]: loss 0.038390
[epoch18, step1073]: loss 0.038233
[epoch18, step1074]: loss 0.036082
[epoch18, step1075]: loss 0.035888
[epoch18, step1076]: loss 0.039067
[epoch18, step1077]: loss 0.037501
[epoch18, step1078]: loss 0.037175
[epoch18, step1079]: loss 0.036607
[epoch18, step1080]: loss 0.037321
[epoch18, step1081]: loss 0.037362
[epoch18, step1082]: loss 0.038439
[epoch18, step1083]: loss 0.036771
[epoch18, step1084]: loss 0.035773
[epoch18, step1085]: loss 0.038334
[epoch18, step1086]: loss 0.037139
[epoch18, step1087]: loss 0.037407
[epoch18, step1088]: loss 0.035400
[epoch18, step1089]: loss 0.037734
[epoch18, step1090]: loss 0.038036
[epoch18, step1091]: loss 0.038717
[epoch18, step1092]: loss 0.035777
[epoch18, step1093]: loss 0.035389
[epoch18, step1094]: loss 0.037947
[epoch18, step1095]: loss 0.036999
[epoch18, step1096]: loss 0.036623
[epoch18, step1097]: loss 0.035576
[epoch18, step1098]: loss 0.037028
[epoch18, step1099]: loss 0.036982
[epoch18, step1100]: loss 0.039084
[epoch18, step1101]: loss 0.036246
[epoch18, step1102]: loss 0.035331
[epoch18, step1103]: loss 0.038336
[epoch18, step1104]: loss 0.037238
[epoch18, step1105]: loss 0.037401
[epoch18, step1106]: loss 0.034653
[epoch18, step1107]: loss 0.037250
[epoch18, step1108]: loss 0.036963
[epoch18, step1109]: loss 0.038717
[epoch18, step1110]: loss 0.036588
[epoch18, step1111]: loss 0.035587
[epoch18, step1112]: loss 0.039359
[epoch18, step1113]: loss 0.037053
[epoch18, step1114]: loss 0.037409
[epoch18, step1115]: loss 0.035810
[epoch18, step1116]: loss 0.037223
[epoch18, step1117]: loss 0.037389
[epoch18, step1118]: loss 0.038234
[epoch18, step1119]: loss 0.035671
[epoch18, step1120]: loss 0.035253
[epoch18, step1121]: loss 0.038595
[epoch18, step1122]: loss 0.036806
[epoch18, step1123]: loss 0.036471
[epoch18, step1124]: loss 0.036155
[epoch18, step1125]: loss 0.037510
[epoch18, step1126]: loss 0.038181
[epoch18, step1127]: loss 0.038429
[epoch18, step1128]: loss 0.036275
[epoch18, step1129]: loss 0.035293
[epoch18, step1130]: loss 0.039467
[epoch18, step1131]: loss 0.037529
[epoch18, step1132]: loss 0.038042
[epoch18, step1133]: loss 0.035085
[epoch18, step1134]: loss 0.036879
[epoch18, step1135]: loss 0.038482
[epoch18, step1136]: loss 0.038821
[epoch18, step1137]: loss 0.035926
[epoch18, step1138]: loss 0.035541
[epoch18, step1139]: loss 0.038866
[epoch18, step1140]: loss 0.036921
[epoch18, step1141]: loss 0.036884
[epoch18, step1142]: loss 0.035339
[epoch18, step1143]: loss 0.036868
[epoch18, step1144]: loss 0.037690
[epoch18, step1145]: loss 0.037977
[epoch18, step1146]: loss 0.035627
[epoch18, step1147]: loss 0.036367
[epoch18, step1148]: loss 0.038898
[epoch18, step1149]: loss 0.037210
[epoch18, step1150]: loss 0.037117
[epoch18, step1151]: loss 0.035714
[epoch18, step1152]: loss 0.037828
[epoch18, step1153]: loss 0.036879
[epoch18, step1154]: loss 0.038622
[epoch18, step1155]: loss 0.036078
[epoch18, step1156]: loss 0.034649
[epoch18, step1157]: loss 0.038524
[epoch18, step1158]: loss 0.037389
[epoch18, step1159]: loss 0.037206
[epoch18, step1160]: loss 0.036128
[epoch18, step1161]: loss 0.037667
[epoch18, step1162]: loss 0.037329
[epoch18, step1163]: loss 0.037682
[epoch18, step1164]: loss 0.035835
[epoch18, step1165]: loss 0.036473
[epoch18, step1166]: loss 0.038681
[epoch18, step1167]: loss 0.036508
[epoch18, step1168]: loss 0.037502
[epoch18, step1169]: loss 0.035019
[epoch18, step1170]: loss 0.037336
[epoch18, step1171]: loss 0.037047
[epoch18, step1172]: loss 0.038319
[epoch18, step1173]: loss 0.036005
[epoch18, step1174]: loss 0.035598
[epoch18, step1175]: loss 0.038313
[epoch18, step1176]: loss 0.036676
[epoch18, step1177]: loss 0.037114
[epoch18, step1178]: loss 0.035423
[epoch18, step1179]: loss 0.036821
[epoch18, step1180]: loss 0.037456
[epoch18, step1181]: loss 0.038659
[epoch18, step1182]: loss 0.035292
[epoch18, step1183]: loss 0.035766
[epoch18, step1184]: loss 0.037869
[epoch18, step1185]: loss 0.037134
[epoch18, step1186]: loss 0.036331
[epoch18, step1187]: loss 0.034506
[epoch18, step1188]: loss 0.036612
[epoch18, step1189]: loss 0.036860
[epoch18, step1190]: loss 0.038102
[epoch18, step1191]: loss 0.036454
[epoch18, step1192]: loss 0.035251
[epoch18, step1193]: loss 0.038672
[epoch18, step1194]: loss 0.036896
[epoch18, step1195]: loss 0.035852
[epoch18, step1196]: loss 0.034661
[epoch18, step1197]: loss 0.037119
[epoch18, step1198]: loss 0.037129
[epoch18, step1199]: loss 0.037682
[epoch18, step1200]: loss 0.035439
[epoch18, step1201]: loss 0.035566
[epoch18, step1202]: loss 0.039393
[epoch18, step1203]: loss 0.037025
[epoch18, step1204]: loss 0.036327
[epoch18, step1205]: loss 0.034665
[epoch18, step1206]: loss 0.036418
[epoch18, step1207]: loss 0.037478
[epoch18, step1208]: loss 0.038233
[epoch18, step1209]: loss 0.034739
[epoch18, step1210]: loss 0.035682
[epoch18, step1211]: loss 0.037923
[epoch18, step1212]: loss 0.036799
[epoch18, step1213]: loss 0.036486
[epoch18, step1214]: loss 0.035335
[epoch18, step1215]: loss 0.037585
[epoch18, step1216]: loss 0.036644
[epoch18, step1217]: loss 0.039038
[epoch18, step1218]: loss 0.035563
[epoch18, step1219]: loss 0.035857
[epoch18, step1220]: loss 0.039074
[epoch18, step1221]: loss 0.036285
[epoch18, step1222]: loss 0.036854
[epoch18, step1223]: loss 0.034887
[epoch18, step1224]: loss 0.037351
[epoch18, step1225]: loss 0.037342
[epoch18, step1226]: loss 0.037988
[epoch18, step1227]: loss 0.035929
[epoch18, step1228]: loss 0.035175
[epoch18, step1229]: loss 0.038529
[epoch18, step1230]: loss 0.037661
[epoch18, step1231]: loss 0.036646
[epoch18, step1232]: loss 0.036566
[epoch18, step1233]: loss 0.037274
[epoch18, step1234]: loss 0.036922
[epoch18, step1235]: loss 0.039024
[epoch18, step1236]: loss 0.036099
[epoch18, step1237]: loss 0.034966
[epoch18, step1238]: loss 0.038124
[epoch18, step1239]: loss 0.037640
[epoch18, step1240]: loss 0.037241
[epoch18, step1241]: loss 0.034961
[epoch18, step1242]: loss 0.037064
[epoch18, step1243]: loss 0.037255
[epoch18, step1244]: loss 0.038256
[epoch18, step1245]: loss 0.036115
[epoch18, step1246]: loss 0.035455
[epoch18, step1247]: loss 0.037864
[epoch18, step1248]: loss 0.036964
[epoch18, step1249]: loss 0.037222
[epoch18, step1250]: loss 0.034978
[epoch18, step1251]: loss 0.037132
[epoch18, step1252]: loss 0.038108
[epoch18, step1253]: loss 0.038318
[epoch18, step1254]: loss 0.035823
[epoch18, step1255]: loss 0.035639
[epoch18, step1256]: loss 0.038871
[epoch18, step1257]: loss 0.037411
[epoch18, step1258]: loss 0.037214
[epoch18, step1259]: loss 0.034756
[epoch18, step1260]: loss 0.037181
[epoch18, step1261]: loss 0.037061
[epoch18, step1262]: loss 0.036916
[epoch18, step1263]: loss 0.036460
[epoch18, step1264]: loss 0.035174
[epoch18, step1265]: loss 0.037273
[epoch18, step1266]: loss 0.036949
[epoch18, step1267]: loss 0.037162
[epoch18, step1268]: loss 0.035310
[epoch18, step1269]: loss 0.036945
[epoch18, step1270]: loss 0.036478
[epoch18, step1271]: loss 0.038409
[epoch18, step1272]: loss 0.035892
[epoch18, step1273]: loss 0.034942
[epoch18, step1274]: loss 0.038173
[epoch18, step1275]: loss 0.037247
[epoch18, step1276]: loss 0.036581
[epoch18, step1277]: loss 0.035208
[epoch18, step1278]: loss 0.037362
[epoch18, step1279]: loss 0.037237
[epoch18, step1280]: loss 0.038592
[epoch18, step1281]: loss 0.035685
[epoch18, step1282]: loss 0.035489
[epoch18, step1283]: loss 0.037850
[epoch18, step1284]: loss 0.036728
[epoch18, step1285]: loss 0.037611
[epoch18, step1286]: loss 0.034423
[epoch18, step1287]: loss 0.037855
[epoch18, step1288]: loss 0.037919
[epoch18, step1289]: loss 0.038877
[epoch18, step1290]: loss 0.035888
[epoch18, step1291]: loss 0.034844
[epoch18, step1292]: loss 0.038904
[epoch18, step1293]: loss 0.036053
[epoch18, step1294]: loss 0.036690
[epoch18, step1295]: loss 0.035631
[epoch18, step1296]: loss 0.037043
[epoch18, step1297]: loss 0.036821
[epoch18, step1298]: loss 0.038456
[epoch18, step1299]: loss 0.035819
[epoch18, step1300]: loss 0.036096
[epoch18, step1301]: loss 0.037357
[epoch18, step1302]: loss 0.036930
[epoch18, step1303]: loss 0.037261
[epoch18, step1304]: loss 0.034378
[epoch18, step1305]: loss 0.037412
[epoch18, step1306]: loss 0.036992
[epoch18, step1307]: loss 0.037521
[epoch18, step1308]: loss 0.035967
[epoch18, step1309]: loss 0.034529
[epoch18, step1310]: loss 0.038200
[epoch18, step1311]: loss 0.035797
[epoch18, step1312]: loss 0.037376
[epoch18, step1313]: loss 0.035127
[epoch18, step1314]: loss 0.036863
[epoch18, step1315]: loss 0.036701
[epoch18, step1316]: loss 0.039596
[epoch18, step1317]: loss 0.035360
[epoch18, step1318]: loss 0.034472
[epoch18, step1319]: loss 0.038042
[epoch18, step1320]: loss 0.037110
[epoch18, step1321]: loss 0.037150
[epoch18, step1322]: loss 0.035032
[epoch18, step1323]: loss 0.037314
[epoch18, step1324]: loss 0.036683
[epoch18, step1325]: loss 0.037834
[epoch18, step1326]: loss 0.035526
[epoch18, step1327]: loss 0.035079
[epoch18, step1328]: loss 0.038434
[epoch18, step1329]: loss 0.036776
[epoch18, step1330]: loss 0.036838
[epoch18, step1331]: loss 0.034970
[epoch18, step1332]: loss 0.036715
[epoch18, step1333]: loss 0.036408
[epoch18, step1334]: loss 0.038228
[epoch18, step1335]: loss 0.036017
[epoch18, step1336]: loss 0.035673
[epoch18, step1337]: loss 0.037986
[epoch18, step1338]: loss 0.036453
[epoch18, step1339]: loss 0.037093
[epoch18, step1340]: loss 0.034589
[epoch18, step1341]: loss 0.037131
[epoch18, step1342]: loss 0.036990
[epoch18, step1343]: loss 0.037930
[epoch18, step1344]: loss 0.036488
[epoch18, step1345]: loss 0.034959
[epoch18, step1346]: loss 0.037693
[epoch18, step1347]: loss 0.037341
[epoch18, step1348]: loss 0.036218
[epoch18, step1349]: loss 0.035335
[epoch18, step1350]: loss 0.036986
[epoch18, step1351]: loss 0.036650
[epoch18, step1352]: loss 0.037297
[epoch18, step1353]: loss 0.035451
[epoch18, step1354]: loss 0.034936
[epoch18, step1355]: loss 0.038138
[epoch18, step1356]: loss 0.036382
[epoch18, step1357]: loss 0.036388
[epoch18, step1358]: loss 0.034975
[epoch18, step1359]: loss 0.036476
[epoch18, step1360]: loss 0.037237
[epoch18, step1361]: loss 0.038309
[epoch18, step1362]: loss 0.036166
[epoch18, step1363]: loss 0.035406
[epoch18, step1364]: loss 0.038333
[epoch18, step1365]: loss 0.036927
[epoch18, step1366]: loss 0.036492
[epoch18, step1367]: loss 0.034450
[epoch18, step1368]: loss 0.037917
[epoch18, step1369]: loss 0.036958
[epoch18, step1370]: loss 0.038109
[epoch18, step1371]: loss 0.035987
[epoch18, step1372]: loss 0.034885
[epoch18, step1373]: loss 0.038229
[epoch18, step1374]: loss 0.037539
[epoch18, step1375]: loss 0.037940
[epoch18, step1376]: loss 0.034985
[epoch18, step1377]: loss 0.036233
[epoch18, step1378]: loss 0.037449
[epoch18, step1379]: loss 0.037545
[epoch18, step1380]: loss 0.035877
[epoch18, step1381]: loss 0.034940
[epoch18, step1382]: loss 0.038464
[epoch18, step1383]: loss 0.036813
[epoch18, step1384]: loss 0.036522
[epoch18, step1385]: loss 0.034066
[epoch18, step1386]: loss 0.036978
[epoch18, step1387]: loss 0.037477
[epoch18, step1388]: loss 0.036869
[epoch18, step1389]: loss 0.034933
[epoch18, step1390]: loss 0.035228
[epoch18, step1391]: loss 0.037821
[epoch18, step1392]: loss 0.036872
[epoch18, step1393]: loss 0.037125
[epoch18, step1394]: loss 0.035123
[epoch18, step1395]: loss 0.037115
[epoch18, step1396]: loss 0.036372
[epoch18, step1397]: loss 0.037720
[epoch18, step1398]: loss 0.035714
[epoch18, step1399]: loss 0.035586
[epoch18, step1400]: loss 0.038515
[epoch18, step1401]: loss 0.036507
[epoch18, step1402]: loss 0.036581
[epoch18, step1403]: loss 0.033991
[epoch18, step1404]: loss 0.036423
[epoch18, step1405]: loss 0.036770
[epoch18, step1406]: loss 0.037562
[epoch18, step1407]: loss 0.036600
[epoch18, step1408]: loss 0.034560
[epoch18, step1409]: loss 0.037581
[epoch18, step1410]: loss 0.036576
[epoch18, step1411]: loss 0.035700
[epoch18, step1412]: loss 0.035117
[epoch18, step1413]: loss 0.036623
[epoch18, step1414]: loss 0.036728
[epoch18, step1415]: loss 0.037707
[epoch18, step1416]: loss 0.035521
[epoch18, step1417]: loss 0.035206
[epoch18, step1418]: loss 0.038352
[epoch18, step1419]: loss 0.037228
[epoch18, step1420]: loss 0.037226
[epoch18, step1421]: loss 0.035386
[epoch18, step1422]: loss 0.036950
[epoch18, step1423]: loss 0.036339
[epoch18, step1424]: loss 0.037994
[epoch18, step1425]: loss 0.034541
[epoch18, step1426]: loss 0.034754
[epoch18, step1427]: loss 0.038678
[epoch18, step1428]: loss 0.037340
[epoch18, step1429]: loss 0.036388
[epoch18, step1430]: loss 0.034728
[epoch18, step1431]: loss 0.036820
[epoch18, step1432]: loss 0.036615
[epoch18, step1433]: loss 0.037966
[epoch18, step1434]: loss 0.034855
[epoch18, step1435]: loss 0.035351
[epoch18, step1436]: loss 0.038205
[epoch18, step1437]: loss 0.037030
[epoch18, step1438]: loss 0.037437
[epoch18, step1439]: loss 0.034663
[epoch18, step1440]: loss 0.036624
[epoch18, step1441]: loss 0.037412
[epoch18, step1442]: loss 0.037268
[epoch18, step1443]: loss 0.035264
[epoch18, step1444]: loss 0.034195
[epoch18, step1445]: loss 0.038280
[epoch18, step1446]: loss 0.036998
[epoch18, step1447]: loss 0.037820
[epoch18, step1448]: loss 0.034865
[epoch18, step1449]: loss 0.036126
[epoch18, step1450]: loss 0.036920
[epoch18, step1451]: loss 0.037973
[epoch18, step1452]: loss 0.035307
[epoch18, step1453]: loss 0.036106
[epoch18, step1454]: loss 0.038727
[epoch18, step1455]: loss 0.037556
[epoch18, step1456]: loss 0.036259
[epoch18, step1457]: loss 0.035610
[epoch18, step1458]: loss 0.036883
[epoch18, step1459]: loss 0.036883
[epoch18, step1460]: loss 0.038591
[epoch18, step1461]: loss 0.036233
[epoch18, step1462]: loss 0.035893
[epoch18, step1463]: loss 0.038071
[epoch18, step1464]: loss 0.037393
[epoch18, step1465]: loss 0.036563
[epoch18, step1466]: loss 0.034309
[epoch18, step1467]: loss 0.036659
[epoch18, step1468]: loss 0.036472
[epoch18, step1469]: loss 0.037891
[epoch18, step1470]: loss 0.035496
[epoch18, step1471]: loss 0.034578
[epoch18, step1472]: loss 0.037920
[epoch18, step1473]: loss 0.036713
[epoch18, step1474]: loss 0.037169
[epoch18, step1475]: loss 0.034256
[epoch18, step1476]: loss 0.037314
[epoch18, step1477]: loss 0.036357
[epoch18, step1478]: loss 0.038122
[epoch18, step1479]: loss 0.035466
[epoch18, step1480]: loss 0.035088
[epoch18, step1481]: loss 0.036946
[epoch18, step1482]: loss 0.036658
[epoch18, step1483]: loss 0.037230
[epoch18, step1484]: loss 0.034869
[epoch18, step1485]: loss 0.036594
[epoch18, step1486]: loss 0.035825
[epoch18, step1487]: loss 0.037644
[epoch18, step1488]: loss 0.035432
[epoch18, step1489]: loss 0.034625
[epoch18, step1490]: loss 0.038285
[epoch18, step1491]: loss 0.036596
[epoch18, step1492]: loss 0.036262
[epoch18, step1493]: loss 0.034508
[epoch18, step1494]: loss 0.036653
[epoch18, step1495]: loss 0.036407
[epoch18, step1496]: loss 0.036925
[epoch18, step1497]: loss 0.035725
[epoch18, step1498]: loss 0.034883
[epoch18, step1499]: loss 0.037249
[epoch18, step1500]: loss 0.036853
[epoch18, step1501]: loss 0.036500
[epoch18, step1502]: loss 0.034507
[epoch18, step1503]: loss 0.036521
[epoch18, step1504]: loss 0.036231
[epoch18, step1505]: loss 0.038439
[epoch18, step1506]: loss 0.035000
[epoch18, step1507]: loss 0.035279
[epoch18, step1508]: loss 0.038778
[epoch18, step1509]: loss 0.036414
[epoch18, step1510]: loss 0.035659
[epoch18, step1511]: loss 0.035351
[epoch18, step1512]: loss 0.036695
[epoch18, step1513]: loss 0.035446
[epoch18, step1514]: loss 0.037978
[epoch18, step1515]: loss 0.036064
[epoch18, step1516]: loss 0.034714

[epoch18]: avg loss 0.032966

[epoch19, step1]: loss 0.031638
[epoch19, step2]: loss 0.038019
[epoch19, step3]: loss 0.038285
[epoch19, step4]: loss 0.034891
[epoch19, step5]: loss 0.035535
[epoch19, step6]: loss 0.038792
[epoch19, step7]: loss 0.036043
[epoch19, step8]: loss 0.038259
[epoch19, step9]: loss 0.034366
[epoch19, step10]: loss 0.036198
[epoch19, step11]: loss 0.038053
[epoch19, step12]: loss 0.037960
[epoch19, step13]: loss 0.035568
[epoch19, step14]: loss 0.034869
[epoch19, step15]: loss 0.037743
[epoch19, step16]: loss 0.035904
[epoch19, step17]: loss 0.038287
[epoch19, step18]: loss 0.035622
[epoch19, step19]: loss 0.035757
[epoch19, step20]: loss 0.038564
[epoch19, step21]: loss 0.037893
[epoch19, step22]: loss 0.034962
[epoch19, step23]: loss 0.034280
[epoch19, step24]: loss 0.038114
[epoch19, step25]: loss 0.035007
[epoch19, step26]: loss 0.037589
[epoch19, step27]: loss 0.034396
[epoch19, step28]: loss 0.035754
[epoch19, step29]: loss 0.038133
[epoch19, step30]: loss 0.038448
[epoch19, step31]: loss 0.034700
[epoch19, step32]: loss 0.035591
[epoch19, step33]: loss 0.038139
[epoch19, step34]: loss 0.036201
[epoch19, step35]: loss 0.038630
[epoch19, step36]: loss 0.034404
[epoch19, step37]: loss 0.035893
[epoch19, step38]: loss 0.037871
[epoch19, step39]: loss 0.037755
[epoch19, step40]: loss 0.035598
[epoch19, step41]: loss 0.034440
[epoch19, step42]: loss 0.038057
[epoch19, step43]: loss 0.036716
[epoch19, step44]: loss 0.038285
[epoch19, step45]: loss 0.034881
[epoch19, step46]: loss 0.035880
[epoch19, step47]: loss 0.037611
[epoch19, step48]: loss 0.037518
[epoch19, step49]: loss 0.033654
[epoch19, step50]: loss 0.034931
[epoch19, step51]: loss 0.037325
[epoch19, step52]: loss 0.035425
[epoch19, step53]: loss 0.038528
[epoch19, step54]: loss 0.034327
[epoch19, step55]: loss 0.035919
[epoch19, step56]: loss 0.038647
[epoch19, step57]: loss 0.038174
[epoch19, step58]: loss 0.035497
[epoch19, step59]: loss 0.033845
[epoch19, step60]: loss 0.038472
[epoch19, step61]: loss 0.035105
[epoch19, step62]: loss 0.037615
[epoch19, step63]: loss 0.034307
[epoch19, step64]: loss 0.035272
[epoch19, step65]: loss 0.038206
[epoch19, step66]: loss 0.037813
[epoch19, step67]: loss 0.035539
[epoch19, step68]: loss 0.034939
[epoch19, step69]: loss 0.037914
[epoch19, step70]: loss 0.035296
[epoch19, step71]: loss 0.038149
[epoch19, step72]: loss 0.035171
[epoch19, step73]: loss 0.035192
[epoch19, step74]: loss 0.038148
[epoch19, step75]: loss 0.037830
[epoch19, step76]: loss 0.035802
[epoch19, step77]: loss 0.035542
[epoch19, step78]: loss 0.038221
[epoch19, step79]: loss 0.034975
[epoch19, step80]: loss 0.039037
[epoch19, step81]: loss 0.034888
[epoch19, step82]: loss 0.035173
[epoch19, step83]: loss 0.037259
[epoch19, step84]: loss 0.038148
[epoch19, step85]: loss 0.036028
[epoch19, step86]: loss 0.035237
[epoch19, step87]: loss 0.038965
[epoch19, step88]: loss 0.034830
[epoch19, step89]: loss 0.037819
[epoch19, step90]: loss 0.035312
[epoch19, step91]: loss 0.035319
[epoch19, step92]: loss 0.038125
[epoch19, step93]: loss 0.038454
[epoch19, step94]: loss 0.035582
[epoch19, step95]: loss 0.035252
[epoch19, step96]: loss 0.038034
[epoch19, step97]: loss 0.036508
[epoch19, step98]: loss 0.037982
[epoch19, step99]: loss 0.035000
[epoch19, step100]: loss 0.034505
[epoch19, step101]: loss 0.038772
[epoch19, step102]: loss 0.037872
[epoch19, step103]: loss 0.035367
[epoch19, step104]: loss 0.034938
[epoch19, step105]: loss 0.038300
[epoch19, step106]: loss 0.036107
[epoch19, step107]: loss 0.038272
[epoch19, step108]: loss 0.035082
[epoch19, step109]: loss 0.035374
[epoch19, step110]: loss 0.038445
[epoch19, step111]: loss 0.038067
[epoch19, step112]: loss 0.035887
[epoch19, step113]: loss 0.035698
[epoch19, step114]: loss 0.037889
[epoch19, step115]: loss 0.035927
[epoch19, step116]: loss 0.038620
[epoch19, step117]: loss 0.034790
[epoch19, step118]: loss 0.036488
[epoch19, step119]: loss 0.038437
[epoch19, step120]: loss 0.037774
[epoch19, step121]: loss 0.035338
[epoch19, step122]: loss 0.035042
[epoch19, step123]: loss 0.038295
[epoch19, step124]: loss 0.035742
[epoch19, step125]: loss 0.038129
[epoch19, step126]: loss 0.034900
[epoch19, step127]: loss 0.035462
[epoch19, step128]: loss 0.037666
[epoch19, step129]: loss 0.037480
[epoch19, step130]: loss 0.035508
[epoch19, step131]: loss 0.034168
[epoch19, step132]: loss 0.038211
[epoch19, step133]: loss 0.035149
[epoch19, step134]: loss 0.037258
[epoch19, step135]: loss 0.035668
[epoch19, step136]: loss 0.036149
[epoch19, step137]: loss 0.037540
[epoch19, step138]: loss 0.037502
[epoch19, step139]: loss 0.035700
[epoch19, step140]: loss 0.035201
[epoch19, step141]: loss 0.038070
[epoch19, step142]: loss 0.035548
[epoch19, step143]: loss 0.037693
[epoch19, step144]: loss 0.035395
[epoch19, step145]: loss 0.035815
[epoch19, step146]: loss 0.038212
[epoch19, step147]: loss 0.039251
[epoch19, step148]: loss 0.035177
[epoch19, step149]: loss 0.034432
[epoch19, step150]: loss 0.037686
[epoch19, step151]: loss 0.035699
[epoch19, step152]: loss 0.038406
[epoch19, step153]: loss 0.034891
[epoch19, step154]: loss 0.035196
[epoch19, step155]: loss 0.038328
[epoch19, step156]: loss 0.037500
[epoch19, step157]: loss 0.035620
[epoch19, step158]: loss 0.035239
[epoch19, step159]: loss 0.038399
[epoch19, step160]: loss 0.035874
[epoch19, step161]: loss 0.038739
[epoch19, step162]: loss 0.035102
[epoch19, step163]: loss 0.035313
[epoch19, step164]: loss 0.038272
[epoch19, step165]: loss 0.037903
[epoch19, step166]: loss 0.035739
[epoch19, step167]: loss 0.034620
[epoch19, step168]: loss 0.038185
[epoch19, step169]: loss 0.035577
[epoch19, step170]: loss 0.038755
[epoch19, step171]: loss 0.035109
[epoch19, step172]: loss 0.035631
[epoch19, step173]: loss 0.038398
[epoch19, step174]: loss 0.037841
[epoch19, step175]: loss 0.036527
[epoch19, step176]: loss 0.035152
[epoch19, step177]: loss 0.038602
[epoch19, step178]: loss 0.035850
[epoch19, step179]: loss 0.037164
[epoch19, step180]: loss 0.035895
[epoch19, step181]: loss 0.035497
[epoch19, step182]: loss 0.038334
[epoch19, step183]: loss 0.038257
[epoch19, step184]: loss 0.036422
[epoch19, step185]: loss 0.035053
[epoch19, step186]: loss 0.037960
[epoch19, step187]: loss 0.035923
[epoch19, step188]: loss 0.037955
[epoch19, step189]: loss 0.035049
[epoch19, step190]: loss 0.034963
[epoch19, step191]: loss 0.037622
[epoch19, step192]: loss 0.039112
[epoch19, step193]: loss 0.034448
[epoch19, step194]: loss 0.034831
[epoch19, step195]: loss 0.038256
[epoch19, step196]: loss 0.036169
[epoch19, step197]: loss 0.038775
[epoch19, step198]: loss 0.034464
[epoch19, step199]: loss 0.035365
[epoch19, step200]: loss 0.039142
[epoch19, step201]: loss 0.039119
[epoch19, step202]: loss 0.035279
[epoch19, step203]: loss 0.035531
[epoch19, step204]: loss 0.039428
[epoch19, step205]: loss 0.035721
[epoch19, step206]: loss 0.037800
[epoch19, step207]: loss 0.034997
[epoch19, step208]: loss 0.035544
[epoch19, step209]: loss 0.038199
[epoch19, step210]: loss 0.038758
[epoch19, step211]: loss 0.036058
[epoch19, step212]: loss 0.035490
[epoch19, step213]: loss 0.037613
[epoch19, step214]: loss 0.034934
[epoch19, step215]: loss 0.038416
[epoch19, step216]: loss 0.035159
[epoch19, step217]: loss 0.034144
[epoch19, step218]: loss 0.038344
[epoch19, step219]: loss 0.037583
[epoch19, step220]: loss 0.035671
[epoch19, step221]: loss 0.035531
[epoch19, step222]: loss 0.037998
[epoch19, step223]: loss 0.036206
[epoch19, step224]: loss 0.038690
[epoch19, step225]: loss 0.035553
[epoch19, step226]: loss 0.034982
[epoch19, step227]: loss 0.037220
[epoch19, step228]: loss 0.038444
[epoch19, step229]: loss 0.034446
[epoch19, step230]: loss 0.035232
[epoch19, step231]: loss 0.038438
[epoch19, step232]: loss 0.035065
[epoch19, step233]: loss 0.037307
[epoch19, step234]: loss 0.034308
[epoch19, step235]: loss 0.035504
[epoch19, step236]: loss 0.037625
[epoch19, step237]: loss 0.037687
[epoch19, step238]: loss 0.035324
[epoch19, step239]: loss 0.034748
[epoch19, step240]: loss 0.037265
[epoch19, step241]: loss 0.036180
[epoch19, step242]: loss 0.038369
[epoch19, step243]: loss 0.035530
[epoch19, step244]: loss 0.035935
[epoch19, step245]: loss 0.039197
[epoch19, step246]: loss 0.038451
[epoch19, step247]: loss 0.035742
[epoch19, step248]: loss 0.034819
[epoch19, step249]: loss 0.037761
[epoch19, step250]: loss 0.035566
[epoch19, step251]: loss 0.038311
[epoch19, step252]: loss 0.036273
[epoch19, step253]: loss 0.034864
[epoch19, step254]: loss 0.037600
[epoch19, step255]: loss 0.038249
[epoch19, step256]: loss 0.035298
[epoch19, step257]: loss 0.035409
[epoch19, step258]: loss 0.039069
[epoch19, step259]: loss 0.036091
[epoch19, step260]: loss 0.038370
[epoch19, step261]: loss 0.036188
[epoch19, step262]: loss 0.036216
[epoch19, step263]: loss 0.038017
[epoch19, step264]: loss 0.037774
[epoch19, step265]: loss 0.035843
[epoch19, step266]: loss 0.035144
[epoch19, step267]: loss 0.037612
[epoch19, step268]: loss 0.035538
[epoch19, step269]: loss 0.038287
[epoch19, step270]: loss 0.034693
[epoch19, step271]: loss 0.035608
[epoch19, step272]: loss 0.038125
[epoch19, step273]: loss 0.037679
[epoch19, step274]: loss 0.036202
[epoch19, step275]: loss 0.034702
[epoch19, step276]: loss 0.037716
[epoch19, step277]: loss 0.036113
[epoch19, step278]: loss 0.038416
[epoch19, step279]: loss 0.034766
[epoch19, step280]: loss 0.035282
[epoch19, step281]: loss 0.038060
[epoch19, step282]: loss 0.038485
[epoch19, step283]: loss 0.034918
[epoch19, step284]: loss 0.034860
[epoch19, step285]: loss 0.038829
[epoch19, step286]: loss 0.034696
[epoch19, step287]: loss 0.038480
[epoch19, step288]: loss 0.034514
[epoch19, step289]: loss 0.036108
[epoch19, step290]: loss 0.038318
[epoch19, step291]: loss 0.037885
[epoch19, step292]: loss 0.034814
[epoch19, step293]: loss 0.034739
[epoch19, step294]: loss 0.037136
[epoch19, step295]: loss 0.034808
[epoch19, step296]: loss 0.038789
[epoch19, step297]: loss 0.034614
[epoch19, step298]: loss 0.035577
[epoch19, step299]: loss 0.037256
[epoch19, step300]: loss 0.037897
[epoch19, step301]: loss 0.036247
[epoch19, step302]: loss 0.036468
[epoch19, step303]: loss 0.039244
[epoch19, step304]: loss 0.035396
[epoch19, step305]: loss 0.037953
[epoch19, step306]: loss 0.035614
[epoch19, step307]: loss 0.034805
[epoch19, step308]: loss 0.038626
[epoch19, step309]: loss 0.038176
[epoch19, step310]: loss 0.035413
[epoch19, step311]: loss 0.035193
[epoch19, step312]: loss 0.037836
[epoch19, step313]: loss 0.035992
[epoch19, step314]: loss 0.038057
[epoch19, step315]: loss 0.035583
[epoch19, step316]: loss 0.034930
[epoch19, step317]: loss 0.038459
[epoch19, step318]: loss 0.037982
[epoch19, step319]: loss 0.035000
[epoch19, step320]: loss 0.034344
[epoch19, step321]: loss 0.037370
[epoch19, step322]: loss 0.035546
[epoch19, step323]: loss 0.037808
[epoch19, step324]: loss 0.035632
[epoch19, step325]: loss 0.035795
[epoch19, step326]: loss 0.037708
[epoch19, step327]: loss 0.037433
[epoch19, step328]: loss 0.035506
[epoch19, step329]: loss 0.034637
[epoch19, step330]: loss 0.037493
[epoch19, step331]: loss 0.035431
[epoch19, step332]: loss 0.037528
[epoch19, step333]: loss 0.034870
[epoch19, step334]: loss 0.035233
[epoch19, step335]: loss 0.038046
[epoch19, step336]: loss 0.039107
[epoch19, step337]: loss 0.035624
[epoch19, step338]: loss 0.034531
[epoch19, step339]: loss 0.037758
[epoch19, step340]: loss 0.036079
[epoch19, step341]: loss 0.038142
[epoch19, step342]: loss 0.034506
[epoch19, step343]: loss 0.035831
[epoch19, step344]: loss 0.037668
[epoch19, step345]: loss 0.037516
[epoch19, step346]: loss 0.035212
[epoch19, step347]: loss 0.034456
[epoch19, step348]: loss 0.038308
[epoch19, step349]: loss 0.035778
[epoch19, step350]: loss 0.037638
[epoch19, step351]: loss 0.034330
[epoch19, step352]: loss 0.035050
[epoch19, step353]: loss 0.037717
[epoch19, step354]: loss 0.036854
[epoch19, step355]: loss 0.034343
[epoch19, step356]: loss 0.035445
[epoch19, step357]: loss 0.037857
[epoch19, step358]: loss 0.034071
[epoch19, step359]: loss 0.038911
[epoch19, step360]: loss 0.033872
[epoch19, step361]: loss 0.034606
[epoch19, step362]: loss 0.038221
[epoch19, step363]: loss 0.037434
[epoch19, step364]: loss 0.035090
[epoch19, step365]: loss 0.034755
[epoch19, step366]: loss 0.038146
[epoch19, step367]: loss 0.035408
[epoch19, step368]: loss 0.037568
[epoch19, step369]: loss 0.034652
[epoch19, step370]: loss 0.035840
[epoch19, step371]: loss 0.038746
[epoch19, step372]: loss 0.037368
[epoch19, step373]: loss 0.035029
[epoch19, step374]: loss 0.034208
[epoch19, step375]: loss 0.038301
[epoch19, step376]: loss 0.035303
[epoch19, step377]: loss 0.038194
[epoch19, step378]: loss 0.035009
[epoch19, step379]: loss 0.035651
[epoch19, step380]: loss 0.038102
[epoch19, step381]: loss 0.037095
[epoch19, step382]: loss 0.035332
[epoch19, step383]: loss 0.033814
[epoch19, step384]: loss 0.037031
[epoch19, step385]: loss 0.035134
[epoch19, step386]: loss 0.037885
[epoch19, step387]: loss 0.034976
[epoch19, step388]: loss 0.035829
[epoch19, step389]: loss 0.037817
[epoch19, step390]: loss 0.038535
[epoch19, step391]: loss 0.034943
[epoch19, step392]: loss 0.035682
[epoch19, step393]: loss 0.037537
[epoch19, step394]: loss 0.035383
[epoch19, step395]: loss 0.037815
[epoch19, step396]: loss 0.034901
[epoch19, step397]: loss 0.034989
[epoch19, step398]: loss 0.038099
[epoch19, step399]: loss 0.037425
[epoch19, step400]: loss 0.034897
[epoch19, step401]: loss 0.034546
[epoch19, step402]: loss 0.037554
[epoch19, step403]: loss 0.035183
[epoch19, step404]: loss 0.038072
[epoch19, step405]: loss 0.035364
[epoch19, step406]: loss 0.035693
[epoch19, step407]: loss 0.037655
[epoch19, step408]: loss 0.038170
[epoch19, step409]: loss 0.036767
[epoch19, step410]: loss 0.035255
[epoch19, step411]: loss 0.037773
[epoch19, step412]: loss 0.034914
[epoch19, step413]: loss 0.037654
[epoch19, step414]: loss 0.034728
[epoch19, step415]: loss 0.035177
[epoch19, step416]: loss 0.037178
[epoch19, step417]: loss 0.037598
[epoch19, step418]: loss 0.035094
[epoch19, step419]: loss 0.034028
[epoch19, step420]: loss 0.037999
[epoch19, step421]: loss 0.035044
[epoch19, step422]: loss 0.037704
[epoch19, step423]: loss 0.034985
[epoch19, step424]: loss 0.035504
[epoch19, step425]: loss 0.038291
[epoch19, step426]: loss 0.038281
[epoch19, step427]: loss 0.035580
[epoch19, step428]: loss 0.034738
[epoch19, step429]: loss 0.038538
[epoch19, step430]: loss 0.035133
[epoch19, step431]: loss 0.038138
[epoch19, step432]: loss 0.034804
[epoch19, step433]: loss 0.036035
[epoch19, step434]: loss 0.037542
[epoch19, step435]: loss 0.037970
[epoch19, step436]: loss 0.034868
[epoch19, step437]: loss 0.034901
[epoch19, step438]: loss 0.038292
[epoch19, step439]: loss 0.035381
[epoch19, step440]: loss 0.037792
[epoch19, step441]: loss 0.035137
[epoch19, step442]: loss 0.035291
[epoch19, step443]: loss 0.038290
[epoch19, step444]: loss 0.037385
[epoch19, step445]: loss 0.035858
[epoch19, step446]: loss 0.035069
[epoch19, step447]: loss 0.038712
[epoch19, step448]: loss 0.035716
[epoch19, step449]: loss 0.037527
[epoch19, step450]: loss 0.034409
[epoch19, step451]: loss 0.034945
[epoch19, step452]: loss 0.036774
[epoch19, step453]: loss 0.037573
[epoch19, step454]: loss 0.035007
[epoch19, step455]: loss 0.034799
[epoch19, step456]: loss 0.036904
[epoch19, step457]: loss 0.035780
[epoch19, step458]: loss 0.037461
[epoch19, step459]: loss 0.035585
[epoch19, step460]: loss 0.035086
[epoch19, step461]: loss 0.038523
[epoch19, step462]: loss 0.037356
[epoch19, step463]: loss 0.035182
[epoch19, step464]: loss 0.034969
[epoch19, step465]: loss 0.039557
[epoch19, step466]: loss 0.035071
[epoch19, step467]: loss 0.037764
[epoch19, step468]: loss 0.035361
[epoch19, step469]: loss 0.035102
[epoch19, step470]: loss 0.038133
[epoch19, step471]: loss 0.037377
[epoch19, step472]: loss 0.035688
[epoch19, step473]: loss 0.034500
[epoch19, step474]: loss 0.037423
[epoch19, step475]: loss 0.035352
[epoch19, step476]: loss 0.038143
[epoch19, step477]: loss 0.034991
[epoch19, step478]: loss 0.034451
[epoch19, step479]: loss 0.037647
[epoch19, step480]: loss 0.036891
[epoch19, step481]: loss 0.034764
[epoch19, step482]: loss 0.034535
[epoch19, step483]: loss 0.037852
[epoch19, step484]: loss 0.035722
[epoch19, step485]: loss 0.038109
[epoch19, step486]: loss 0.035046
[epoch19, step487]: loss 0.034888
[epoch19, step488]: loss 0.038351
[epoch19, step489]: loss 0.037052
[epoch19, step490]: loss 0.036141
[epoch19, step491]: loss 0.035120
[epoch19, step492]: loss 0.037778
[epoch19, step493]: loss 0.035448
[epoch19, step494]: loss 0.037163
[epoch19, step495]: loss 0.036244
[epoch19, step496]: loss 0.035188
[epoch19, step497]: loss 0.037674
[epoch19, step498]: loss 0.037214
[epoch19, step499]: loss 0.035382
[epoch19, step500]: loss 0.034229
[epoch19, step501]: loss 0.037141
[epoch19, step502]: loss 0.034947
[epoch19, step503]: loss 0.037823
[epoch19, step504]: loss 0.034951
[epoch19, step505]: loss 0.034433
[epoch19, step506]: loss 0.038245
[epoch19, step507]: loss 0.038188
[epoch19, step508]: loss 0.035629
[epoch19, step509]: loss 0.034837
[epoch19, step510]: loss 0.037640
[epoch19, step511]: loss 0.035922
[epoch19, step512]: loss 0.038486
[epoch19, step513]: loss 0.035047
[epoch19, step514]: loss 0.035725
[epoch19, step515]: loss 0.038228
[epoch19, step516]: loss 0.038113
[epoch19, step517]: loss 0.035402
[epoch19, step518]: loss 0.035079
[epoch19, step519]: loss 0.037695
[epoch19, step520]: loss 0.034847
[epoch19, step521]: loss 0.037370
[epoch19, step522]: loss 0.034328
[epoch19, step523]: loss 0.035025
[epoch19, step524]: loss 0.036913
[epoch19, step525]: loss 0.037736
[epoch19, step526]: loss 0.035314
[epoch19, step527]: loss 0.034390
[epoch19, step528]: loss 0.037755
[epoch19, step529]: loss 0.035029
[epoch19, step530]: loss 0.037977
[epoch19, step531]: loss 0.034781
[epoch19, step532]: loss 0.034936
[epoch19, step533]: loss 0.038618
[epoch19, step534]: loss 0.037641
[epoch19, step535]: loss 0.035739
[epoch19, step536]: loss 0.034948
[epoch19, step537]: loss 0.037566
[epoch19, step538]: loss 0.035784
[epoch19, step539]: loss 0.038137
[epoch19, step540]: loss 0.034374
[epoch19, step541]: loss 0.034920
[epoch19, step542]: loss 0.038322
[epoch19, step543]: loss 0.037364
[epoch19, step544]: loss 0.035555
[epoch19, step545]: loss 0.034562
[epoch19, step546]: loss 0.038184
[epoch19, step547]: loss 0.035126
[epoch19, step548]: loss 0.037895
[epoch19, step549]: loss 0.035147
[epoch19, step550]: loss 0.035269
[epoch19, step551]: loss 0.037738
[epoch19, step552]: loss 0.036933
[epoch19, step553]: loss 0.035935
[epoch19, step554]: loss 0.035072
[epoch19, step555]: loss 0.037182
[epoch19, step556]: loss 0.035649
[epoch19, step557]: loss 0.038822
[epoch19, step558]: loss 0.035878
[epoch19, step559]: loss 0.034522
[epoch19, step560]: loss 0.038627
[epoch19, step561]: loss 0.037698
[epoch19, step562]: loss 0.035199
[epoch19, step563]: loss 0.029082
[epoch19, step564]: loss 0.030227
[epoch19, step565]: loss 0.027843
[epoch19, step566]: loss 0.037299
[epoch19, step567]: loss 0.027581
[epoch19, step568]: loss 0.026473
[epoch19, step569]: loss 0.024169
[epoch19, step570]: loss 0.032692
[epoch19, step571]: loss 0.028169
[epoch19, step572]: loss 0.026090
[epoch19, step573]: loss 0.029215
[epoch19, step574]: loss 0.027501
[epoch19, step575]: loss 0.021041
[epoch19, step576]: loss 0.021665
[epoch19, step577]: loss 0.025841
[epoch19, step578]: loss 0.019172
[epoch19, step579]: loss 0.028836
[epoch19, step580]: loss 0.020380
[epoch19, step581]: loss 0.025941
[epoch19, step582]: loss 0.025795
[epoch19, step583]: loss 0.022391
[epoch19, step584]: loss 0.023886
[epoch19, step585]: loss 0.026812
[epoch19, step586]: loss 0.022227
[epoch19, step587]: loss 0.028148
[epoch19, step588]: loss 0.023144
[epoch19, step589]: loss 0.023408
[epoch19, step590]: loss 0.028049
[epoch19, step591]: loss 0.020946
[epoch19, step592]: loss 0.026045
[epoch19, step593]: loss 0.022798
[epoch19, step594]: loss 0.026262
[epoch19, step595]: loss 0.026749
[epoch19, step596]: loss 0.022964
[epoch19, step597]: loss 0.025258
[epoch19, step598]: loss 0.026667
[epoch19, step599]: loss 0.025564
[epoch19, step600]: loss 0.027711
[epoch19, step601]: loss 0.019761
[epoch19, step602]: loss 0.022925
[epoch19, step603]: loss 0.026270
[epoch19, step604]: loss 0.026664
[epoch19, step605]: loss 0.025385
[epoch19, step606]: loss 0.024960
[epoch19, step607]: loss 0.028065
[epoch19, step608]: loss 0.025919
[epoch19, step609]: loss 0.027183
[epoch19, step610]: loss 0.025883
[epoch19, step611]: loss 0.026502
[epoch19, step612]: loss 0.026009
[epoch19, step613]: loss 0.019691
[epoch19, step614]: loss 0.025485
[epoch19, step615]: loss 0.028538
[epoch19, step616]: loss 0.024058
[epoch19, step617]: loss 0.023820
[epoch19, step618]: loss 0.025994
[epoch19, step619]: loss 0.026838
[epoch19, step620]: loss 0.024622
[epoch19, step621]: loss 0.026415
[epoch19, step622]: loss 0.020936
[epoch19, step623]: loss 0.024586
[epoch19, step624]: loss 0.026753
[epoch19, step625]: loss 0.026293
[epoch19, step626]: loss 0.028754
[epoch19, step627]: loss 0.023259
[epoch19, step628]: loss 0.026333
[epoch19, step629]: loss 0.020968
[epoch19, step630]: loss 0.023652
[epoch19, step631]: loss 0.031429
[epoch19, step632]: loss 0.023584
[epoch19, step633]: loss 0.024741
[epoch19, step634]: loss 0.027206
[epoch19, step635]: loss 0.025871
[epoch19, step636]: loss 0.021044
[epoch19, step637]: loss 0.027565
[epoch19, step638]: loss 0.027081
[epoch19, step639]: loss 0.023146
[epoch19, step640]: loss 0.029709
[epoch19, step641]: loss 0.030591
[epoch19, step642]: loss 0.025238
[epoch19, step643]: loss 0.026027
[epoch19, step644]: loss 0.026288
[epoch19, step645]: loss 0.023974
[epoch19, step646]: loss 0.026811
[epoch19, step647]: loss 0.023944
[epoch19, step648]: loss 0.023514
[epoch19, step649]: loss 0.028854
[epoch19, step650]: loss 0.022578
[epoch19, step651]: loss 0.026607
[epoch19, step652]: loss 0.027242
[epoch19, step653]: loss 0.028553
[epoch19, step654]: loss 0.023380
[epoch19, step655]: loss 0.024103
[epoch19, step656]: loss 0.021790
[epoch19, step657]: loss 0.028011
[epoch19, step658]: loss 0.025461
[epoch19, step659]: loss 0.027969
[epoch19, step660]: loss 0.024046
[epoch19, step661]: loss 0.026954
[epoch19, step662]: loss 0.023892
[epoch19, step663]: loss 0.021605
[epoch19, step664]: loss 0.025015
[epoch19, step665]: loss 0.028013
[epoch19, step666]: loss 0.027027
[epoch19, step667]: loss 0.026768
[epoch19, step668]: loss 0.022682
[epoch19, step669]: loss 0.026525
[epoch19, step670]: loss 0.027332
[epoch19, step671]: loss 0.021591
[epoch19, step672]: loss 0.024217
[epoch19, step673]: loss 0.022327
[epoch19, step674]: loss 0.021447
[epoch19, step675]: loss 0.020340
[epoch19, step676]: loss 0.024528
[epoch19, step677]: loss 0.025466
[epoch19, step678]: loss 0.023463
[epoch19, step679]: loss 0.024177
[epoch19, step680]: loss 0.030882
[epoch19, step681]: loss 0.022152
[epoch19, step682]: loss 0.026228
[epoch19, step683]: loss 0.025802
[epoch19, step684]: loss 0.025060
[epoch19, step685]: loss 0.024523
[epoch19, step686]: loss 0.027463
[epoch19, step687]: loss 0.026907
[epoch19, step688]: loss 0.023245
[epoch19, step689]: loss 0.024587
[epoch19, step690]: loss 0.025585
[epoch19, step691]: loss 0.024541
[epoch19, step692]: loss 0.022853
[epoch19, step693]: loss 0.027877
[epoch19, step694]: loss 0.023080
[epoch19, step695]: loss 0.026841
[epoch19, step696]: loss 0.025810
[epoch19, step697]: loss 0.027632
[epoch19, step698]: loss 0.025148
[epoch19, step699]: loss 0.023449
[epoch19, step700]: loss 0.021981
[epoch19, step701]: loss 0.026084
[epoch19, step702]: loss 0.021971
[epoch19, step703]: loss 0.023405
[epoch19, step704]: loss 0.025988
[epoch19, step705]: loss 0.024981
[epoch19, step706]: loss 0.024005
[epoch19, step707]: loss 0.024272
[epoch19, step708]: loss 0.026357
[epoch19, step709]: loss 0.027631
[epoch19, step710]: loss 0.024308
[epoch19, step711]: loss 0.024182
[epoch19, step712]: loss 0.027034
[epoch19, step713]: loss 0.026558
[epoch19, step714]: loss 0.021885
[epoch19, step715]: loss 0.023243
[epoch19, step716]: loss 0.026215
[epoch19, step717]: loss 0.023860
[epoch19, step718]: loss 0.025510
[epoch19, step719]: loss 0.033397
[epoch19, step720]: loss 0.025240
[epoch19, step721]: loss 0.023429
[epoch19, step722]: loss 0.031341
[epoch19, step723]: loss 0.026542
[epoch19, step724]: loss 0.023520
[epoch19, step725]: loss 0.028606
[epoch19, step726]: loss 0.022466
[epoch19, step727]: loss 0.024779
[epoch19, step728]: loss 0.026690
[epoch19, step729]: loss 0.021785
[epoch19, step730]: loss 0.023091
[epoch19, step731]: loss 0.026315
[epoch19, step732]: loss 0.025957
[epoch19, step733]: loss 0.024103
[epoch19, step734]: loss 0.023253
[epoch19, step735]: loss 0.027259
[epoch19, step736]: loss 0.025199
[epoch19, step737]: loss 0.026832
[epoch19, step738]: loss 0.020754
[epoch19, step739]: loss 0.025729
[epoch19, step740]: loss 0.022894
[epoch19, step741]: loss 0.025472
[epoch19, step742]: loss 0.022329
[epoch19, step743]: loss 0.023549
[epoch19, step744]: loss 0.024022
[epoch19, step745]: loss 0.024841
[epoch19, step746]: loss 0.025720
[epoch19, step747]: loss 0.027880
[epoch19, step748]: loss 0.026312
[epoch19, step749]: loss 0.026752
[epoch19, step750]: loss 0.028112
[epoch19, step751]: loss 0.022052
[epoch19, step752]: loss 0.025238
[epoch19, step753]: loss 0.025573
[epoch19, step754]: loss 0.023184
[epoch19, step755]: loss 0.026538
[epoch19, step756]: loss 0.023648
[epoch19, step757]: loss 0.021101
[epoch19, step758]: loss 0.025009
[epoch19, step759]: loss 0.023405
[epoch19, step760]: loss 0.024359
[epoch19, step761]: loss 0.026331
[epoch19, step762]: loss 0.021867
[epoch19, step763]: loss 0.025881
[epoch19, step764]: loss 0.024227
[epoch19, step765]: loss 0.026244
[epoch19, step766]: loss 0.024993
[epoch19, step767]: loss 0.027264
[epoch19, step768]: loss 0.021596
[epoch19, step769]: loss 0.027032
[epoch19, step770]: loss 0.026547
[epoch19, step771]: loss 0.023318
[epoch19, step772]: loss 0.029423
[epoch19, step773]: loss 0.026883
[epoch19, step774]: loss 0.024018
[epoch19, step775]: loss 0.021198
[epoch19, step776]: loss 0.026010
[epoch19, step777]: loss 0.023326
[epoch19, step778]: loss 0.028537
[epoch19, step779]: loss 0.024234
[epoch19, step780]: loss 0.020537
[epoch19, step781]: loss 0.024950
[epoch19, step782]: loss 0.023217
[epoch19, step783]: loss 0.019804
[epoch19, step784]: loss 0.020792
[epoch19, step785]: loss 0.021403
[epoch19, step786]: loss 0.024475
[epoch19, step787]: loss 0.023902
[epoch19, step788]: loss 0.024929
[epoch19, step789]: loss 0.023025
[epoch19, step790]: loss 0.023445
[epoch19, step791]: loss 0.027089
[epoch19, step792]: loss 0.025068
[epoch19, step793]: loss 0.027543
[epoch19, step794]: loss 0.020549
[epoch19, step795]: loss 0.025976
[epoch19, step796]: loss 0.027896
[epoch19, step797]: loss 0.028270
[epoch19, step798]: loss 0.027160
[epoch19, step799]: loss 0.025666
[epoch19, step800]: loss 0.022004
[epoch19, step801]: loss 0.022541
[epoch19, step802]: loss 0.023335
[epoch19, step803]: loss 0.026280
[epoch19, step804]: loss 0.027568
[epoch19, step805]: loss 0.028993
[epoch19, step806]: loss 0.022080
[epoch19, step807]: loss 0.021001
[epoch19, step808]: loss 0.023345
[epoch19, step809]: loss 0.023366
[epoch19, step810]: loss 0.026163
[epoch19, step811]: loss 0.026197
[epoch19, step812]: loss 0.024847
[epoch19, step813]: loss 0.023926
[epoch19, step814]: loss 0.025341
[epoch19, step815]: loss 0.024891
[epoch19, step816]: loss 0.024699
[epoch19, step817]: loss 0.025007
[epoch19, step818]: loss 0.022633
[epoch19, step819]: loss 0.020808
[epoch19, step820]: loss 0.023715
[epoch19, step821]: loss 0.022021
[epoch19, step822]: loss 0.031417
[epoch19, step823]: loss 0.024116
[epoch19, step824]: loss 0.027299
[epoch19, step825]: loss 0.025648
[epoch19, step826]: loss 0.024574
[epoch19, step827]: loss 0.027145
[epoch19, step828]: loss 0.028936
[epoch19, step829]: loss 0.026846
[epoch19, step830]: loss 0.022953
[epoch19, step831]: loss 0.026461
[epoch19, step832]: loss 0.021510
[epoch19, step833]: loss 0.028978
[epoch19, step834]: loss 0.025983
[epoch19, step835]: loss 0.021299
[epoch19, step836]: loss 0.027017
[epoch19, step837]: loss 0.025681
[epoch19, step838]: loss 0.026350
[epoch19, step839]: loss 0.028645
[epoch19, step840]: loss 0.020872
[epoch19, step841]: loss 0.024644
[epoch19, step842]: loss 0.027782
[epoch19, step843]: loss 0.025372
[epoch19, step844]: loss 0.025607
[epoch19, step845]: loss 0.021435
[epoch19, step846]: loss 0.026079
[epoch19, step847]: loss 0.027208
[epoch19, step848]: loss 0.025655
[epoch19, step849]: loss 0.025400
[epoch19, step850]: loss 0.023484
[epoch19, step851]: loss 0.024588
[epoch19, step852]: loss 0.023284
[epoch19, step853]: loss 0.029830
[epoch19, step854]: loss 0.022648
[epoch19, step855]: loss 0.027383
[epoch19, step856]: loss 0.022408
[epoch19, step857]: loss 0.026259
[epoch19, step858]: loss 0.024574
[epoch19, step859]: loss 0.023802
[epoch19, step860]: loss 0.022865
[epoch19, step861]: loss 0.023449
[epoch19, step862]: loss 0.023216
[epoch19, step863]: loss 0.020870
[epoch19, step864]: loss 0.026954
[epoch19, step865]: loss 0.023626
[epoch19, step866]: loss 0.025340
[epoch19, step867]: loss 0.026446
[epoch19, step868]: loss 0.027152
[epoch19, step869]: loss 0.023816
[epoch19, step870]: loss 0.031657
[epoch19, step871]: loss 0.022460
[epoch19, step872]: loss 0.025667
[epoch19, step873]: loss 0.025821
[epoch19, step874]: loss 0.023967
[epoch19, step875]: loss 0.024624
[epoch19, step876]: loss 0.024652
[epoch19, step877]: loss 0.019595
[epoch19, step878]: loss 0.023621
[epoch19, step879]: loss 0.028051
[epoch19, step880]: loss 0.025694
[epoch19, step881]: loss 0.022433
[epoch19, step882]: loss 0.024662
[epoch19, step883]: loss 0.024393
[epoch19, step884]: loss 0.026766
[epoch19, step885]: loss 0.026211
[epoch19, step886]: loss 0.026605
[epoch19, step887]: loss 0.024636
[epoch19, step888]: loss 0.025084
[epoch19, step889]: loss 0.023941
[epoch19, step890]: loss 0.023856
[epoch19, step891]: loss 0.025715
[epoch19, step892]: loss 0.021258
[epoch19, step893]: loss 0.024694
[epoch19, step894]: loss 0.024847
[epoch19, step895]: loss 0.022946
[epoch19, step896]: loss 0.022291
[epoch19, step897]: loss 0.024489
[epoch19, step898]: loss 0.025993
[epoch19, step899]: loss 0.028576
[epoch19, step900]: loss 0.027370
[epoch19, step901]: loss 0.025979
[epoch19, step902]: loss 0.024156
[epoch19, step903]: loss 0.025003
[epoch19, step904]: loss 0.028276
[epoch19, step905]: loss 0.027818
[epoch19, step906]: loss 0.022677
[epoch19, step907]: loss 0.023981
[epoch19, step908]: loss 0.022949
[epoch19, step909]: loss 0.026048
[epoch19, step910]: loss 0.023418
[epoch19, step911]: loss 0.025648
[epoch19, step912]: loss 0.023971
[epoch19, step913]: loss 0.024632
[epoch19, step914]: loss 0.031054
[epoch19, step915]: loss 0.024250
[epoch19, step916]: loss 0.023739
[epoch19, step917]: loss 0.025186
[epoch19, step918]: loss 0.028926
[epoch19, step919]: loss 0.024652
[epoch19, step920]: loss 0.027815
[epoch19, step921]: loss 0.024573
[epoch19, step922]: loss 0.023575
[epoch19, step923]: loss 0.023167
[epoch19, step924]: loss 0.021465
[epoch19, step925]: loss 0.025690
[epoch19, step926]: loss 0.026728
[epoch19, step927]: loss 0.026231
[epoch19, step928]: loss 0.025121
[epoch19, step929]: loss 0.027761
[epoch19, step930]: loss 0.026073
[epoch19, step931]: loss 0.028133
[epoch19, step932]: loss 0.022006
[epoch19, step933]: loss 0.028480
[epoch19, step934]: loss 0.022420
[epoch19, step935]: loss 0.022882
[epoch19, step936]: loss 0.023001
[epoch19, step937]: loss 0.027993
[epoch19, step938]: loss 0.025890
[epoch19, step939]: loss 0.021200
[epoch19, step940]: loss 0.023529
[epoch19, step941]: loss 0.026881
[epoch19, step942]: loss 0.025760
[epoch19, step943]: loss 0.023706
[epoch19, step944]: loss 0.028232
[epoch19, step945]: loss 0.020549
[epoch19, step946]: loss 0.025729
[epoch19, step947]: loss 0.028557
[epoch19, step948]: loss 0.019904
[epoch19, step949]: loss 0.022923
[epoch19, step950]: loss 0.026561
[epoch19, step951]: loss 0.029064
[epoch19, step952]: loss 0.025345
[epoch19, step953]: loss 0.027695
[epoch19, step954]: loss 0.022834
[epoch19, step955]: loss 0.037467
[epoch19, step956]: loss 0.052446
[epoch19, step957]: loss 0.045707
[epoch19, step958]: loss 0.042872
[epoch19, step959]: loss 0.045931
[epoch19, step960]: loss 0.042606
[epoch19, step961]: loss 0.043133
[epoch19, step962]: loss 0.041797
[epoch19, step963]: loss 0.041074
[epoch19, step964]: loss 0.041625
[epoch19, step965]: loss 0.042284
[epoch19, step966]: loss 0.040390
[epoch19, step967]: loss 0.039431
[epoch19, step968]: loss 0.041449
[epoch19, step969]: loss 0.040712
[epoch19, step970]: loss 0.040168
[epoch19, step971]: loss 0.039079
[epoch19, step972]: loss 0.040054
[epoch19, step973]: loss 0.039146
[epoch19, step974]: loss 0.041700
[epoch19, step975]: loss 0.038410
[epoch19, step976]: loss 0.037364
[epoch19, step977]: loss 0.041181
[epoch19, step978]: loss 0.039295
[epoch19, step979]: loss 0.038633
[epoch19, step980]: loss 0.037276
[epoch19, step981]: loss 0.038864
[epoch19, step982]: loss 0.039237
[epoch19, step983]: loss 0.040003
[epoch19, step984]: loss 0.036771
[epoch19, step985]: loss 0.036948
[epoch19, step986]: loss 0.040748
[epoch19, step987]: loss 0.038862
[epoch19, step988]: loss 0.038248
[epoch19, step989]: loss 0.037437
[epoch19, step990]: loss 0.037893
[epoch19, step991]: loss 0.038941
[epoch19, step992]: loss 0.039298
[epoch19, step993]: loss 0.036584
[epoch19, step994]: loss 0.035901
[epoch19, step995]: loss 0.039849
[epoch19, step996]: loss 0.038038
[epoch19, step997]: loss 0.037556
[epoch19, step998]: loss 0.037154
[epoch19, step999]: loss 0.038238
[epoch19, step1000]: loss 0.038519
[epoch19, step1001]: loss 0.039217
[epoch19, step1002]: loss 0.036766
[epoch19, step1003]: loss 0.036044
[epoch19, step1004]: loss 0.039671
[epoch19, step1005]: loss 0.037560
[epoch19, step1006]: loss 0.037499
[epoch19, step1007]: loss 0.036038
[epoch19, step1008]: loss 0.037534
[epoch19, step1009]: loss 0.038187
[epoch19, step1010]: loss 0.039451
[epoch19, step1011]: loss 0.036272
[epoch19, step1012]: loss 0.036368
[epoch19, step1013]: loss 0.039643
[epoch19, step1014]: loss 0.038797
[epoch19, step1015]: loss 0.037646
[epoch19, step1016]: loss 0.035952
[epoch19, step1017]: loss 0.037360
[epoch19, step1018]: loss 0.037869
[epoch19, step1019]: loss 0.039205
[epoch19, step1020]: loss 0.035855
[epoch19, step1021]: loss 0.035637
[epoch19, step1022]: loss 0.039292
[epoch19, step1023]: loss 0.037939
[epoch19, step1024]: loss 0.038053
[epoch19, step1025]: loss 0.035687
[epoch19, step1026]: loss 0.036934
[epoch19, step1027]: loss 0.037735
[epoch19, step1028]: loss 0.038716
[epoch19, step1029]: loss 0.035860
[epoch19, step1030]: loss 0.035278
[epoch19, step1031]: loss 0.038146
[epoch19, step1032]: loss 0.038199
[epoch19, step1033]: loss 0.036732
[epoch19, step1034]: loss 0.035747
[epoch19, step1035]: loss 0.036829
[epoch19, step1036]: loss 0.038076
[epoch19, step1037]: loss 0.038628
[epoch19, step1038]: loss 0.035752
[epoch19, step1039]: loss 0.036088
[epoch19, step1040]: loss 0.038788
[epoch19, step1041]: loss 0.037694
[epoch19, step1042]: loss 0.036459
[epoch19, step1043]: loss 0.035710
[epoch19, step1044]: loss 0.037448
[epoch19, step1045]: loss 0.038065
[epoch19, step1046]: loss 0.038821
[epoch19, step1047]: loss 0.036055
[epoch19, step1048]: loss 0.035365
[epoch19, step1049]: loss 0.039224
[epoch19, step1050]: loss 0.038026
[epoch19, step1051]: loss 0.037113
[epoch19, step1052]: loss 0.036239
[epoch19, step1053]: loss 0.037780
[epoch19, step1054]: loss 0.037843
[epoch19, step1055]: loss 0.038109
[epoch19, step1056]: loss 0.035311
[epoch19, step1057]: loss 0.036253
[epoch19, step1058]: loss 0.039827
[epoch19, step1059]: loss 0.038003
[epoch19, step1060]: loss 0.037187
[epoch19, step1061]: loss 0.035213
[epoch19, step1062]: loss 0.037747
[epoch19, step1063]: loss 0.037845
[epoch19, step1064]: loss 0.038649
[epoch19, step1065]: loss 0.035724
[epoch19, step1066]: loss 0.035234
[epoch19, step1067]: loss 0.039157
[epoch19, step1068]: loss 0.036501
[epoch19, step1069]: loss 0.036458
[epoch19, step1070]: loss 0.035681
[epoch19, step1071]: loss 0.037842
[epoch19, step1072]: loss 0.038490
[epoch19, step1073]: loss 0.038349
[epoch19, step1074]: loss 0.035770
[epoch19, step1075]: loss 0.035937
[epoch19, step1076]: loss 0.039113
[epoch19, step1077]: loss 0.037747
[epoch19, step1078]: loss 0.036823
[epoch19, step1079]: loss 0.036649
[epoch19, step1080]: loss 0.037454
[epoch19, step1081]: loss 0.037570
[epoch19, step1082]: loss 0.038439
[epoch19, step1083]: loss 0.036362
[epoch19, step1084]: loss 0.035916
[epoch19, step1085]: loss 0.038624
[epoch19, step1086]: loss 0.037465
[epoch19, step1087]: loss 0.037127
[epoch19, step1088]: loss 0.035572
[epoch19, step1089]: loss 0.037696
[epoch19, step1090]: loss 0.038273
[epoch19, step1091]: loss 0.038883
[epoch19, step1092]: loss 0.035680
[epoch19, step1093]: loss 0.035548
[epoch19, step1094]: loss 0.038170
[epoch19, step1095]: loss 0.037335
[epoch19, step1096]: loss 0.036531
[epoch19, step1097]: loss 0.035711
[epoch19, step1098]: loss 0.037235
[epoch19, step1099]: loss 0.037460
[epoch19, step1100]: loss 0.039184
[epoch19, step1101]: loss 0.036100
[epoch19, step1102]: loss 0.035672
[epoch19, step1103]: loss 0.038636
[epoch19, step1104]: loss 0.037554
[epoch19, step1105]: loss 0.037169
[epoch19, step1106]: loss 0.034830
[epoch19, step1107]: loss 0.037488
[epoch19, step1108]: loss 0.037426
[epoch19, step1109]: loss 0.038823
[epoch19, step1110]: loss 0.036338
[epoch19, step1111]: loss 0.035831
[epoch19, step1112]: loss 0.039431
[epoch19, step1113]: loss 0.037362
[epoch19, step1114]: loss 0.037217
[epoch19, step1115]: loss 0.035744
[epoch19, step1116]: loss 0.037506
[epoch19, step1117]: loss 0.037874
[epoch19, step1118]: loss 0.038618
[epoch19, step1119]: loss 0.035573
[epoch19, step1120]: loss 0.035577
[epoch19, step1121]: loss 0.039048
[epoch19, step1122]: loss 0.037230
[epoch19, step1123]: loss 0.036359
[epoch19, step1124]: loss 0.036300
[epoch19, step1125]: loss 0.037693
[epoch19, step1126]: loss 0.038733
[epoch19, step1127]: loss 0.038606
[epoch19, step1128]: loss 0.035931
[epoch19, step1129]: loss 0.035526
[epoch19, step1130]: loss 0.039596
[epoch19, step1131]: loss 0.038045
[epoch19, step1132]: loss 0.037313
[epoch19, step1133]: loss 0.035314
[epoch19, step1134]: loss 0.037195
[epoch19, step1135]: loss 0.038685
[epoch19, step1136]: loss 0.039258
[epoch19, step1137]: loss 0.035859
[epoch19, step1138]: loss 0.035860
[epoch19, step1139]: loss 0.039179
[epoch19, step1140]: loss 0.037016
[epoch19, step1141]: loss 0.036793
[epoch19, step1142]: loss 0.035507
[epoch19, step1143]: loss 0.036970
[epoch19, step1144]: loss 0.037992
[epoch19, step1145]: loss 0.038089
[epoch19, step1146]: loss 0.035484
[epoch19, step1147]: loss 0.036355
[epoch19, step1148]: loss 0.039229
[epoch19, step1149]: loss 0.037427
[epoch19, step1150]: loss 0.036660
[epoch19, step1151]: loss 0.035937
[epoch19, step1152]: loss 0.037848
[epoch19, step1153]: loss 0.037209
[epoch19, step1154]: loss 0.038992
[epoch19, step1155]: loss 0.035820
[epoch19, step1156]: loss 0.035081
[epoch19, step1157]: loss 0.038939
[epoch19, step1158]: loss 0.037910
[epoch19, step1159]: loss 0.037186
[epoch19, step1160]: loss 0.036383
[epoch19, step1161]: loss 0.037857
[epoch19, step1162]: loss 0.037727
[epoch19, step1163]: loss 0.037986
[epoch19, step1164]: loss 0.035615
[epoch19, step1165]: loss 0.036591
[epoch19, step1166]: loss 0.039130
[epoch19, step1167]: loss 0.036945
[epoch19, step1168]: loss 0.037003
[epoch19, step1169]: loss 0.035428
[epoch19, step1170]: loss 0.037438
[epoch19, step1171]: loss 0.037617
[epoch19, step1172]: loss 0.038719
[epoch19, step1173]: loss 0.035810
[epoch19, step1174]: loss 0.036099
[epoch19, step1175]: loss 0.038999
[epoch19, step1176]: loss 0.037342
[epoch19, step1177]: loss 0.037305
[epoch19, step1178]: loss 0.035775
[epoch19, step1179]: loss 0.037159
[epoch19, step1180]: loss 0.037949
[epoch19, step1181]: loss 0.039136
[epoch19, step1182]: loss 0.035132
[epoch19, step1183]: loss 0.036098
[epoch19, step1184]: loss 0.038627
[epoch19, step1185]: loss 0.037693
[epoch19, step1186]: loss 0.036215
[epoch19, step1187]: loss 0.034902
[epoch19, step1188]: loss 0.036785
[epoch19, step1189]: loss 0.037436
[epoch19, step1190]: loss 0.038243
[epoch19, step1191]: loss 0.036296
[epoch19, step1192]: loss 0.035691
[epoch19, step1193]: loss 0.038898
[epoch19, step1194]: loss 0.037462
[epoch19, step1195]: loss 0.035914
[epoch19, step1196]: loss 0.034942
[epoch19, step1197]: loss 0.037672
[epoch19, step1198]: loss 0.037803
[epoch19, step1199]: loss 0.038161
[epoch19, step1200]: loss 0.035452
[epoch19, step1201]: loss 0.036044
[epoch19, step1202]: loss 0.039856
[epoch19, step1203]: loss 0.037703
[epoch19, step1204]: loss 0.036268
[epoch19, step1205]: loss 0.035172
[epoch19, step1206]: loss 0.036935
[epoch19, step1207]: loss 0.037956
[epoch19, step1208]: loss 0.038752
[epoch19, step1209]: loss 0.034637
[epoch19, step1210]: loss 0.036163
[epoch19, step1211]: loss 0.038521
[epoch19, step1212]: loss 0.037387
[epoch19, step1213]: loss 0.036545
[epoch19, step1214]: loss 0.035760
[epoch19, step1215]: loss 0.037970
[epoch19, step1216]: loss 0.037429
[epoch19, step1217]: loss 0.039090
[epoch19, step1218]: loss 0.035349
[epoch19, step1219]: loss 0.036307
[epoch19, step1220]: loss 0.039303
[epoch19, step1221]: loss 0.036809
[epoch19, step1222]: loss 0.036980
[epoch19, step1223]: loss 0.035486
[epoch19, step1224]: loss 0.037755
[epoch19, step1225]: loss 0.037772
[epoch19, step1226]: loss 0.038301
[epoch19, step1227]: loss 0.035635
[epoch19, step1228]: loss 0.035340
[epoch19, step1229]: loss 0.038839
[epoch19, step1230]: loss 0.037799
[epoch19, step1231]: loss 0.036739
[epoch19, step1232]: loss 0.036544
[epoch19, step1233]: loss 0.037295
[epoch19, step1234]: loss 0.037564
[epoch19, step1235]: loss 0.039080
[epoch19, step1236]: loss 0.035910
[epoch19, step1237]: loss 0.035368
[epoch19, step1238]: loss 0.038498
[epoch19, step1239]: loss 0.038078
[epoch19, step1240]: loss 0.037164
[epoch19, step1241]: loss 0.035261
[epoch19, step1242]: loss 0.037356
[epoch19, step1243]: loss 0.037604
[epoch19, step1244]: loss 0.038823
[epoch19, step1245]: loss 0.035969
[epoch19, step1246]: loss 0.036021
[epoch19, step1247]: loss 0.038239
[epoch19, step1248]: loss 0.037746
[epoch19, step1249]: loss 0.037301
[epoch19, step1250]: loss 0.035529
[epoch19, step1251]: loss 0.037516
[epoch19, step1252]: loss 0.038644
[epoch19, step1253]: loss 0.038743
[epoch19, step1254]: loss 0.035744
[epoch19, step1255]: loss 0.035850
[epoch19, step1256]: loss 0.039408
[epoch19, step1257]: loss 0.037777
[epoch19, step1258]: loss 0.037013
[epoch19, step1259]: loss 0.035318
[epoch19, step1260]: loss 0.037488
[epoch19, step1261]: loss 0.037570
[epoch19, step1262]: loss 0.037531
[epoch19, step1263]: loss 0.036192
[epoch19, step1264]: loss 0.035667
[epoch19, step1265]: loss 0.037905
[epoch19, step1266]: loss 0.037540
[epoch19, step1267]: loss 0.036962
[epoch19, step1268]: loss 0.035772
[epoch19, step1269]: loss 0.037501
[epoch19, step1270]: loss 0.037196
[epoch19, step1271]: loss 0.038977
[epoch19, step1272]: loss 0.035787
[epoch19, step1273]: loss 0.035567
[epoch19, step1274]: loss 0.038816
[epoch19, step1275]: loss 0.038038
[epoch19, step1276]: loss 0.036564
[epoch19, step1277]: loss 0.035581
[epoch19, step1278]: loss 0.038008
[epoch19, step1279]: loss 0.037884
[epoch19, step1280]: loss 0.038861
[epoch19, step1281]: loss 0.035568
[epoch19, step1282]: loss 0.035538
[epoch19, step1283]: loss 0.038448
[epoch19, step1284]: loss 0.037163
[epoch19, step1285]: loss 0.037316
[epoch19, step1286]: loss 0.034946
[epoch19, step1287]: loss 0.038010
[epoch19, step1288]: loss 0.038461
[epoch19, step1289]: loss 0.039376
[epoch19, step1290]: loss 0.035780
[epoch19, step1291]: loss 0.035467
[epoch19, step1292]: loss 0.039367
[epoch19, step1293]: loss 0.036845
[epoch19, step1294]: loss 0.036788
[epoch19, step1295]: loss 0.035953
[epoch19, step1296]: loss 0.037580
[epoch19, step1297]: loss 0.037432
[epoch19, step1298]: loss 0.039125
[epoch19, step1299]: loss 0.035867
[epoch19, step1300]: loss 0.036366
[epoch19, step1301]: loss 0.038194
[epoch19, step1302]: loss 0.037639
[epoch19, step1303]: loss 0.037068
[epoch19, step1304]: loss 0.035072
[epoch19, step1305]: loss 0.037584
[epoch19, step1306]: loss 0.037512
[epoch19, step1307]: loss 0.038067
[epoch19, step1308]: loss 0.035823
[epoch19, step1309]: loss 0.035085
[epoch19, step1310]: loss 0.038889
[epoch19, step1311]: loss 0.036642
[epoch19, step1312]: loss 0.037490
[epoch19, step1313]: loss 0.035683
[epoch19, step1314]: loss 0.037372
[epoch19, step1315]: loss 0.037459
[epoch19, step1316]: loss 0.039916
[epoch19, step1317]: loss 0.035198
[epoch19, step1318]: loss 0.035381
[epoch19, step1319]: loss 0.038459
[epoch19, step1320]: loss 0.037771
[epoch19, step1321]: loss 0.037292
[epoch19, step1322]: loss 0.035315
[epoch19, step1323]: loss 0.037720
[epoch19, step1324]: loss 0.037379
[epoch19, step1325]: loss 0.038511
[epoch19, step1326]: loss 0.035473
[epoch19, step1327]: loss 0.035517
[epoch19, step1328]: loss 0.039009
[epoch19, step1329]: loss 0.037506
[epoch19, step1330]: loss 0.037053
[epoch19, step1331]: loss 0.035370
[epoch19, step1332]: loss 0.037339
[epoch19, step1333]: loss 0.036816
[epoch19, step1334]: loss 0.038921
[epoch19, step1335]: loss 0.036208
[epoch19, step1336]: loss 0.035621
[epoch19, step1337]: loss 0.038436
[epoch19, step1338]: loss 0.037365
[epoch19, step1339]: loss 0.037008
[epoch19, step1340]: loss 0.035196
[epoch19, step1341]: loss 0.037595
[epoch19, step1342]: loss 0.037546
[epoch19, step1343]: loss 0.038722
[epoch19, step1344]: loss 0.035821
[epoch19, step1345]: loss 0.035581
[epoch19, step1346]: loss 0.038579
[epoch19, step1347]: loss 0.038137
[epoch19, step1348]: loss 0.036374
[epoch19, step1349]: loss 0.035640
[epoch19, step1350]: loss 0.037306
[epoch19, step1351]: loss 0.037218
[epoch19, step1352]: loss 0.038000
[epoch19, step1353]: loss 0.035382
[epoch19, step1354]: loss 0.035416
[epoch19, step1355]: loss 0.039035
[epoch19, step1356]: loss 0.037105
[epoch19, step1357]: loss 0.036368
[epoch19, step1358]: loss 0.035275
[epoch19, step1359]: loss 0.036966
[epoch19, step1360]: loss 0.037784
[epoch19, step1361]: loss 0.038825
[epoch19, step1362]: loss 0.036170
[epoch19, step1363]: loss 0.036014
[epoch19, step1364]: loss 0.038793
[epoch19, step1365]: loss 0.037482
[epoch19, step1366]: loss 0.036682
[epoch19, step1367]: loss 0.034790
[epoch19, step1368]: loss 0.038091
[epoch19, step1369]: loss 0.037708
[epoch19, step1370]: loss 0.038399
[epoch19, step1371]: loss 0.035857
[epoch19, step1372]: loss 0.035459
[epoch19, step1373]: loss 0.038861
[epoch19, step1374]: loss 0.038185
[epoch19, step1375]: loss 0.037591
[epoch19, step1376]: loss 0.035285
[epoch19, step1377]: loss 0.036566
[epoch19, step1378]: loss 0.037798
[epoch19, step1379]: loss 0.038092
[epoch19, step1380]: loss 0.035890
[epoch19, step1381]: loss 0.035480
[epoch19, step1382]: loss 0.039099
[epoch19, step1383]: loss 0.037242
[epoch19, step1384]: loss 0.036676
[epoch19, step1385]: loss 0.034920
[epoch19, step1386]: loss 0.037512
[epoch19, step1387]: loss 0.038017
[epoch19, step1388]: loss 0.037680
[epoch19, step1389]: loss 0.034982
[epoch19, step1390]: loss 0.035690
[epoch19, step1391]: loss 0.038634
[epoch19, step1392]: loss 0.037241
[epoch19, step1393]: loss 0.037203
[epoch19, step1394]: loss 0.035822
[epoch19, step1395]: loss 0.037452
[epoch19, step1396]: loss 0.037331
[epoch19, step1397]: loss 0.038049
[epoch19, step1398]: loss 0.035509
[epoch19, step1399]: loss 0.036137
[epoch19, step1400]: loss 0.039207
[epoch19, step1401]: loss 0.037199
[epoch19, step1402]: loss 0.036712
[epoch19, step1403]: loss 0.034502
[epoch19, step1404]: loss 0.036749
[epoch19, step1405]: loss 0.037399
[epoch19, step1406]: loss 0.038194
[epoch19, step1407]: loss 0.036405
[epoch19, step1408]: loss 0.035171
[epoch19, step1409]: loss 0.038389
[epoch19, step1410]: loss 0.037423
[epoch19, step1411]: loss 0.035832
[epoch19, step1412]: loss 0.035410
[epoch19, step1413]: loss 0.037240
[epoch19, step1414]: loss 0.037172
[epoch19, step1415]: loss 0.038063
[epoch19, step1416]: loss 0.035581
[epoch19, step1417]: loss 0.035517
[epoch19, step1418]: loss 0.038582
[epoch19, step1419]: loss 0.037877
[epoch19, step1420]: loss 0.037260
[epoch19, step1421]: loss 0.035656
[epoch19, step1422]: loss 0.037357
[epoch19, step1423]: loss 0.037057
[epoch19, step1424]: loss 0.038441
[epoch19, step1425]: loss 0.034809
[epoch19, step1426]: loss 0.035244
[epoch19, step1427]: loss 0.039323
[epoch19, step1428]: loss 0.037979
[epoch19, step1429]: loss 0.036655
[epoch19, step1430]: loss 0.035076
[epoch19, step1431]: loss 0.037089
[epoch19, step1432]: loss 0.037038
[epoch19, step1433]: loss 0.038348
[epoch19, step1434]: loss 0.034837
[epoch19, step1435]: loss 0.036005
[epoch19, step1436]: loss 0.038923
[epoch19, step1437]: loss 0.037430
[epoch19, step1438]: loss 0.037397
[epoch19, step1439]: loss 0.035036
[epoch19, step1440]: loss 0.036983
[epoch19, step1441]: loss 0.037700
[epoch19, step1442]: loss 0.037536
[epoch19, step1443]: loss 0.035550
[epoch19, step1444]: loss 0.034600
[epoch19, step1445]: loss 0.038715
[epoch19, step1446]: loss 0.037354
[epoch19, step1447]: loss 0.037483
[epoch19, step1448]: loss 0.034746
[epoch19, step1449]: loss 0.036672
[epoch19, step1450]: loss 0.037265
[epoch19, step1451]: loss 0.038238
[epoch19, step1452]: loss 0.035274
[epoch19, step1453]: loss 0.036203
[epoch19, step1454]: loss 0.038827
[epoch19, step1455]: loss 0.037816
[epoch19, step1456]: loss 0.036115
[epoch19, step1457]: loss 0.035840
[epoch19, step1458]: loss 0.037302
[epoch19, step1459]: loss 0.037290
[epoch19, step1460]: loss 0.038746
[epoch19, step1461]: loss 0.035844
[epoch19, step1462]: loss 0.036332
[epoch19, step1463]: loss 0.038634
[epoch19, step1464]: loss 0.037557
[epoch19, step1465]: loss 0.036031
[epoch19, step1466]: loss 0.034491
[epoch19, step1467]: loss 0.036703
[epoch19, step1468]: loss 0.036898
[epoch19, step1469]: loss 0.037958
[epoch19, step1470]: loss 0.035375
[epoch19, step1471]: loss 0.035123
[epoch19, step1472]: loss 0.038552
[epoch19, step1473]: loss 0.037187
[epoch19, step1474]: loss 0.037077
[epoch19, step1475]: loss 0.034632
[epoch19, step1476]: loss 0.038124
[epoch19, step1477]: loss 0.036940
[epoch19, step1478]: loss 0.037843
[epoch19, step1479]: loss 0.035563
[epoch19, step1480]: loss 0.035764
[epoch19, step1481]: loss 0.037639
[epoch19, step1482]: loss 0.036775
[epoch19, step1483]: loss 0.036887
[epoch19, step1484]: loss 0.034910
[epoch19, step1485]: loss 0.036966
[epoch19, step1486]: loss 0.036113
[epoch19, step1487]: loss 0.037971
[epoch19, step1488]: loss 0.035310
[epoch19, step1489]: loss 0.035177
[epoch19, step1490]: loss 0.038471
[epoch19, step1491]: loss 0.037994
[epoch19, step1492]: loss 0.036909
[epoch19, step1493]: loss 0.035191
[epoch19, step1494]: loss 0.037639
[epoch19, step1495]: loss 0.037489
[epoch19, step1496]: loss 0.036978
[epoch19, step1497]: loss 0.035620
[epoch19, step1498]: loss 0.035332
[epoch19, step1499]: loss 0.037988
[epoch19, step1500]: loss 0.037351
[epoch19, step1501]: loss 0.036372
[epoch19, step1502]: loss 0.034550
[epoch19, step1503]: loss 0.036676
[epoch19, step1504]: loss 0.036961
[epoch19, step1505]: loss 0.038222
[epoch19, step1506]: loss 0.034804
[epoch19, step1507]: loss 0.035545
[epoch19, step1508]: loss 0.039304
[epoch19, step1509]: loss 0.036679
[epoch19, step1510]: loss 0.035424
[epoch19, step1511]: loss 0.035487
[epoch19, step1512]: loss 0.036991
[epoch19, step1513]: loss 0.036173
[epoch19, step1514]: loss 0.038136
[epoch19, step1515]: loss 0.035563
[epoch19, step1516]: loss 0.035149

[epoch19]: avg loss 0.033843

[epoch20, step1]: loss 0.029307
[epoch20, step2]: loss 0.038373
[epoch20, step3]: loss 0.037968
[epoch20, step4]: loss 0.035048
[epoch20, step5]: loss 0.035991
[epoch20, step6]: loss 0.038603
[epoch20, step7]: loss 0.037530
[epoch20, step8]: loss 0.039108
[epoch20, step9]: loss 0.035384
[epoch20, step10]: loss 0.036142
[epoch20, step11]: loss 0.038841
[epoch20, step12]: loss 0.037996
[epoch20, step13]: loss 0.035122
[epoch20, step14]: loss 0.035461
[epoch20, step15]: loss 0.038170
[epoch20, step16]: loss 0.036301
[epoch20, step17]: loss 0.038861
[epoch20, step18]: loss 0.035750
[epoch20, step19]: loss 0.036209
[epoch20, step20]: loss 0.039212
[epoch20, step21]: loss 0.038265
[epoch20, step22]: loss 0.034882
[epoch20, step23]: loss 0.034813
[epoch20, step24]: loss 0.038036
[epoch20, step25]: loss 0.035399
[epoch20, step26]: loss 0.037396
[epoch20, step27]: loss 0.034710
[epoch20, step28]: loss 0.036105
[epoch20, step29]: loss 0.038247
[epoch20, step30]: loss 0.038722
[epoch20, step31]: loss 0.035365
[epoch20, step32]: loss 0.036048
[epoch20, step33]: loss 0.039096
[epoch20, step34]: loss 0.036739
[epoch20, step35]: loss 0.038779
[epoch20, step36]: loss 0.035356
[epoch20, step37]: loss 0.036091
[epoch20, step38]: loss 0.038608
[epoch20, step39]: loss 0.037747
[epoch20, step40]: loss 0.035186
[epoch20, step41]: loss 0.035231
[epoch20, step42]: loss 0.038364
[epoch20, step43]: loss 0.035448
[epoch20, step44]: loss 0.039006
[epoch20, step45]: loss 0.035896
[epoch20, step46]: loss 0.036831
[epoch20, step47]: loss 0.038302
[epoch20, step48]: loss 0.037733
[epoch20, step49]: loss 0.033682
[epoch20, step50]: loss 0.035551
[epoch20, step51]: loss 0.038113
[epoch20, step52]: loss 0.036152
[epoch20, step53]: loss 0.038481
[epoch20, step54]: loss 0.034841
[epoch20, step55]: loss 0.036415
[epoch20, step56]: loss 0.039418
[epoch20, step57]: loss 0.038137
[epoch20, step58]: loss 0.035303
[epoch20, step59]: loss 0.034350
[epoch20, step60]: loss 0.038199
[epoch20, step61]: loss 0.035313
[epoch20, step62]: loss 0.037525
[epoch20, step63]: loss 0.034723
[epoch20, step64]: loss 0.035513
[epoch20, step65]: loss 0.038440
[epoch20, step66]: loss 0.038066
[epoch20, step67]: loss 0.035258
[epoch20, step68]: loss 0.035435
[epoch20, step69]: loss 0.038315
[epoch20, step70]: loss 0.035487
[epoch20, step71]: loss 0.037707
[epoch20, step72]: loss 0.034748
[epoch20, step73]: loss 0.035447
[epoch20, step74]: loss 0.038196
[epoch20, step75]: loss 0.038063
[epoch20, step76]: loss 0.035608
[epoch20, step77]: loss 0.035722
[epoch20, step78]: loss 0.038496
[epoch20, step79]: loss 0.035515
[epoch20, step80]: loss 0.039063
[epoch20, step81]: loss 0.034998
[epoch20, step82]: loss 0.035780
[epoch20, step83]: loss 0.037393
[epoch20, step84]: loss 0.038292
[epoch20, step85]: loss 0.035452
[epoch20, step86]: loss 0.035268
[epoch20, step87]: loss 0.039575
[epoch20, step88]: loss 0.034802
[epoch20, step89]: loss 0.038113
[epoch20, step90]: loss 0.035571
[epoch20, step91]: loss 0.035568
[epoch20, step92]: loss 0.037957
[epoch20, step93]: loss 0.038332
[epoch20, step94]: loss 0.034768
[epoch20, step95]: loss 0.036036
[epoch20, step96]: loss 0.038850
[epoch20, step97]: loss 0.036261
[epoch20, step98]: loss 0.038467
[epoch20, step99]: loss 0.035048
[epoch20, step100]: loss 0.034601
[epoch20, step101]: loss 0.039919
[epoch20, step102]: loss 0.038059
[epoch20, step103]: loss 0.035626
[epoch20, step104]: loss 0.036110
[epoch20, step105]: loss 0.039355
[epoch20, step106]: loss 0.035977
[epoch20, step107]: loss 0.038527
[epoch20, step108]: loss 0.035803
[epoch20, step109]: loss 0.035181
[epoch20, step110]: loss 0.039571
[epoch20, step111]: loss 0.038685
[epoch20, step112]: loss 0.035511
[epoch20, step113]: loss 0.036676
[epoch20, step114]: loss 0.039292
[epoch20, step115]: loss 0.036319
[epoch20, step116]: loss 0.038788
[epoch20, step117]: loss 0.035118
[epoch20, step118]: loss 0.036422
[epoch20, step119]: loss 0.038555
[epoch20, step120]: loss 0.038190
[epoch20, step121]: loss 0.035047
[epoch20, step122]: loss 0.035089
[epoch20, step123]: loss 0.039035
[epoch20, step124]: loss 0.036080
[epoch20, step125]: loss 0.038440
[epoch20, step126]: loss 0.035526
[epoch20, step127]: loss 0.035858
[epoch20, step128]: loss 0.038285
[epoch20, step129]: loss 0.037387
[epoch20, step130]: loss 0.035208
[epoch20, step131]: loss 0.034957
[epoch20, step132]: loss 0.038408
[epoch20, step133]: loss 0.035665
[epoch20, step134]: loss 0.037860
[epoch20, step135]: loss 0.035538
[epoch20, step136]: loss 0.036577
[epoch20, step137]: loss 0.038164
[epoch20, step138]: loss 0.038429
[epoch20, step139]: loss 0.035239
[epoch20, step140]: loss 0.035739
[epoch20, step141]: loss 0.038758
[epoch20, step142]: loss 0.035893
[epoch20, step143]: loss 0.037777
[epoch20, step144]: loss 0.035566
[epoch20, step145]: loss 0.035913
[epoch20, step146]: loss 0.038722
[epoch20, step147]: loss 0.038946
[epoch20, step148]: loss 0.035022
[epoch20, step149]: loss 0.034764
[epoch20, step150]: loss 0.037287
[epoch20, step151]: loss 0.035769
[epoch20, step152]: loss 0.037628
[epoch20, step153]: loss 0.035257
[epoch20, step154]: loss 0.035521
[epoch20, step155]: loss 0.038473
[epoch20, step156]: loss 0.038213
[epoch20, step157]: loss 0.035664
[epoch20, step158]: loss 0.035456
[epoch20, step159]: loss 0.038826
[epoch20, step160]: loss 0.036412
[epoch20, step161]: loss 0.038933
[epoch20, step162]: loss 0.035388
[epoch20, step163]: loss 0.035553
[epoch20, step164]: loss 0.039361
[epoch20, step165]: loss 0.038123
[epoch20, step166]: loss 0.035638
[epoch20, step167]: loss 0.034871
[epoch20, step168]: loss 0.038656
[epoch20, step169]: loss 0.035683
[epoch20, step170]: loss 0.038313
[epoch20, step171]: loss 0.035573
[epoch20, step172]: loss 0.036132
[epoch20, step173]: loss 0.038884
[epoch20, step174]: loss 0.037790
[epoch20, step175]: loss 0.036354
[epoch20, step176]: loss 0.035913
[epoch20, step177]: loss 0.038953
[epoch20, step178]: loss 0.036004
[epoch20, step179]: loss 0.037172
[epoch20, step180]: loss 0.035560
[epoch20, step181]: loss 0.035564
[epoch20, step182]: loss 0.038308
[epoch20, step183]: loss 0.038552
[epoch20, step184]: loss 0.036413
[epoch20, step185]: loss 0.035480
[epoch20, step186]: loss 0.037965
[epoch20, step187]: loss 0.035717
[epoch20, step188]: loss 0.037778
[epoch20, step189]: loss 0.035337
[epoch20, step190]: loss 0.035273
[epoch20, step191]: loss 0.038288
[epoch20, step192]: loss 0.038010
[epoch20, step193]: loss 0.033178
[epoch20, step194]: loss 0.034163
[epoch20, step195]: loss 0.037815
[epoch20, step196]: loss 0.036104
[epoch20, step197]: loss 0.038260
[epoch20, step198]: loss 0.034973
[epoch20, step199]: loss 0.036576
[epoch20, step200]: loss 0.040301
[epoch20, step201]: loss 0.039490
[epoch20, step202]: loss 0.035555
[epoch20, step203]: loss 0.035936
[epoch20, step204]: loss 0.039530
[epoch20, step205]: loss 0.035453
[epoch20, step206]: loss 0.038746
[epoch20, step207]: loss 0.036200
[epoch20, step208]: loss 0.036673
[epoch20, step209]: loss 0.040024
[epoch20, step210]: loss 0.039719
[epoch20, step211]: loss 0.036231
[epoch20, step212]: loss 0.036189
[epoch20, step213]: loss 0.038734
[epoch20, step214]: loss 0.036236
[epoch20, step215]: loss 0.038325
[epoch20, step216]: loss 0.035952
[epoch20, step217]: loss 0.035447
[epoch20, step218]: loss 0.038993
[epoch20, step219]: loss 0.038202
[epoch20, step220]: loss 0.036240
[epoch20, step221]: loss 0.036237
[epoch20, step222]: loss 0.038776
[epoch20, step223]: loss 0.036676
[epoch20, step224]: loss 0.038914
[epoch20, step225]: loss 0.035765
[epoch20, step226]: loss 0.036398
[epoch20, step227]: loss 0.038808
[epoch20, step228]: loss 0.039016
[epoch20, step229]: loss 0.034623
[epoch20, step230]: loss 0.036210
[epoch20, step231]: loss 0.039055
[epoch20, step232]: loss 0.036040
[epoch20, step233]: loss 0.037794
[epoch20, step234]: loss 0.035165
[epoch20, step235]: loss 0.036180
[epoch20, step236]: loss 0.039433
[epoch20, step237]: loss 0.038387
[epoch20, step238]: loss 0.035286
[epoch20, step239]: loss 0.035070
[epoch20, step240]: loss 0.038522
[epoch20, step241]: loss 0.037153
[epoch20, step242]: loss 0.037947
[epoch20, step243]: loss 0.036462
[epoch20, step244]: loss 0.036126
[epoch20, step245]: loss 0.038389
[epoch20, step246]: loss 0.038280
[epoch20, step247]: loss 0.036074
[epoch20, step248]: loss 0.035072
[epoch20, step249]: loss 0.038421
[epoch20, step250]: loss 0.036271
[epoch20, step251]: loss 0.038942
[epoch20, step252]: loss 0.035652
[epoch20, step253]: loss 0.035141
[epoch20, step254]: loss 0.037776
[epoch20, step255]: loss 0.038586
[epoch20, step256]: loss 0.035355
[epoch20, step257]: loss 0.034904
[epoch20, step258]: loss 0.038852
[epoch20, step259]: loss 0.036199
[epoch20, step260]: loss 0.037630
[epoch20, step261]: loss 0.036131
[epoch20, step262]: loss 0.036131
[epoch20, step263]: loss 0.037788
[epoch20, step264]: loss 0.037710
[epoch20, step265]: loss 0.035727
[epoch20, step266]: loss 0.035239
[epoch20, step267]: loss 0.038074
[epoch20, step268]: loss 0.036436
[epoch20, step269]: loss 0.038339
[epoch20, step270]: loss 0.034755
[epoch20, step271]: loss 0.035485
[epoch20, step272]: loss 0.038236
[epoch20, step273]: loss 0.037907
[epoch20, step274]: loss 0.035354
[epoch20, step275]: loss 0.035280
[epoch20, step276]: loss 0.038284
[epoch20, step277]: loss 0.036728
[epoch20, step278]: loss 0.038274
[epoch20, step279]: loss 0.034756
[epoch20, step280]: loss 0.035496
[epoch20, step281]: loss 0.038511
[epoch20, step282]: loss 0.038806
[epoch20, step283]: loss 0.035464
[epoch20, step284]: loss 0.035215
[epoch20, step285]: loss 0.039529
[epoch20, step286]: loss 0.035467
[epoch20, step287]: loss 0.038677
[epoch20, step288]: loss 0.034934
[epoch20, step289]: loss 0.036705
[epoch20, step290]: loss 0.038483
[epoch20, step291]: loss 0.038870
[epoch20, step292]: loss 0.034904
[epoch20, step293]: loss 0.035031
[epoch20, step294]: loss 0.037711
[epoch20, step295]: loss 0.035572
[epoch20, step296]: loss 0.038907
[epoch20, step297]: loss 0.034789
[epoch20, step298]: loss 0.036361
[epoch20, step299]: loss 0.037933
[epoch20, step300]: loss 0.038722
[epoch20, step301]: loss 0.035300
[epoch20, step302]: loss 0.035874
[epoch20, step303]: loss 0.038765
[epoch20, step304]: loss 0.036003
[epoch20, step305]: loss 0.037767
[epoch20, step306]: loss 0.035737
[epoch20, step307]: loss 0.035538
[epoch20, step308]: loss 0.039235
[epoch20, step309]: loss 0.038446
[epoch20, step310]: loss 0.035810
[epoch20, step311]: loss 0.035565
[epoch20, step312]: loss 0.038835
[epoch20, step313]: loss 0.036355
[epoch20, step314]: loss 0.038353
[epoch20, step315]: loss 0.036305
[epoch20, step316]: loss 0.035118
[epoch20, step317]: loss 0.038917
[epoch20, step318]: loss 0.038286
[epoch20, step319]: loss 0.035097
[epoch20, step320]: loss 0.034383
[epoch20, step321]: loss 0.038035
[epoch20, step322]: loss 0.035819
[epoch20, step323]: loss 0.037636
[epoch20, step324]: loss 0.035318
[epoch20, step325]: loss 0.035741
[epoch20, step326]: loss 0.038699
[epoch20, step327]: loss 0.037644
[epoch20, step328]: loss 0.035615
[epoch20, step329]: loss 0.035326
[epoch20, step330]: loss 0.038375
[epoch20, step331]: loss 0.036249
[epoch20, step332]: loss 0.037430
[epoch20, step333]: loss 0.034990
[epoch20, step334]: loss 0.035007
[epoch20, step335]: loss 0.038644
[epoch20, step336]: loss 0.039300
[epoch20, step337]: loss 0.035932
[epoch20, step338]: loss 0.034974
[epoch20, step339]: loss 0.037449
[epoch20, step340]: loss 0.036752
[epoch20, step341]: loss 0.038967
[epoch20, step342]: loss 0.034824
[epoch20, step343]: loss 0.035912
[epoch20, step344]: loss 0.038265
[epoch20, step345]: loss 0.038059
[epoch20, step346]: loss 0.034868
[epoch20, step347]: loss 0.035550
[epoch20, step348]: loss 0.038219
[epoch20, step349]: loss 0.036478
[epoch20, step350]: loss 0.037489
[epoch20, step351]: loss 0.034258
[epoch20, step352]: loss 0.035332
[epoch20, step353]: loss 0.038258
[epoch20, step354]: loss 0.036610
[epoch20, step355]: loss 0.034826
[epoch20, step356]: loss 0.035975
[epoch20, step357]: loss 0.038160
[epoch20, step358]: loss 0.034572
[epoch20, step359]: loss 0.040057
[epoch20, step360]: loss 0.033747
[epoch20, step361]: loss 0.035677
[epoch20, step362]: loss 0.039237
[epoch20, step363]: loss 0.037454
[epoch20, step364]: loss 0.035156
[epoch20, step365]: loss 0.034743
[epoch20, step366]: loss 0.038397
[epoch20, step367]: loss 0.035827
[epoch20, step368]: loss 0.038043
[epoch20, step369]: loss 0.034433
[epoch20, step370]: loss 0.035888
[epoch20, step371]: loss 0.038952
[epoch20, step372]: loss 0.037626
[epoch20, step373]: loss 0.034951
[epoch20, step374]: loss 0.034570
[epoch20, step375]: loss 0.039057
[epoch20, step376]: loss 0.035980
[epoch20, step377]: loss 0.038123
[epoch20, step378]: loss 0.035110
[epoch20, step379]: loss 0.036274
[epoch20, step380]: loss 0.039031
[epoch20, step381]: loss 0.037761
[epoch20, step382]: loss 0.035169
[epoch20, step383]: loss 0.034063
[epoch20, step384]: loss 0.037651
[epoch20, step385]: loss 0.035261
[epoch20, step386]: loss 0.038391
[epoch20, step387]: loss 0.035000
[epoch20, step388]: loss 0.036591
[epoch20, step389]: loss 0.038542
[epoch20, step390]: loss 0.038804
[epoch20, step391]: loss 0.035121
[epoch20, step392]: loss 0.035812
[epoch20, step393]: loss 0.037719
[epoch20, step394]: loss 0.035758
[epoch20, step395]: loss 0.037806
[epoch20, step396]: loss 0.035249
[epoch20, step397]: loss 0.035244
[epoch20, step398]: loss 0.038314
[epoch20, step399]: loss 0.037997
[epoch20, step400]: loss 0.035036
[epoch20, step401]: loss 0.034834
[epoch20, step402]: loss 0.037862
[epoch20, step403]: loss 0.036218
[epoch20, step404]: loss 0.038178
[epoch20, step405]: loss 0.035619
[epoch20, step406]: loss 0.036043
[epoch20, step407]: loss 0.037968
[epoch20, step408]: loss 0.038954
[epoch20, step409]: loss 0.036685
[epoch20, step410]: loss 0.035214
[epoch20, step411]: loss 0.038378
[epoch20, step412]: loss 0.035682
[epoch20, step413]: loss 0.037997
[epoch20, step414]: loss 0.035359
[epoch20, step415]: loss 0.036217
[epoch20, step416]: loss 0.037969
[epoch20, step417]: loss 0.038189
[epoch20, step418]: loss 0.035396
[epoch20, step419]: loss 0.034520
[epoch20, step420]: loss 0.038377
[epoch20, step421]: loss 0.035469
[epoch20, step422]: loss 0.037686
[epoch20, step423]: loss 0.035047
[epoch20, step424]: loss 0.035177
[epoch20, step425]: loss 0.038180
[epoch20, step426]: loss 0.038442
[epoch20, step427]: loss 0.035942
[epoch20, step428]: loss 0.035480
[epoch20, step429]: loss 0.039450
[epoch20, step430]: loss 0.035881
[epoch20, step431]: loss 0.038586
[epoch20, step432]: loss 0.034832
[epoch20, step433]: loss 0.036114
[epoch20, step434]: loss 0.038186
[epoch20, step435]: loss 0.038163
[epoch20, step436]: loss 0.034727
[epoch20, step437]: loss 0.035533
[epoch20, step438]: loss 0.038098
[epoch20, step439]: loss 0.036232
[epoch20, step440]: loss 0.038555
[epoch20, step441]: loss 0.035681
[epoch20, step442]: loss 0.035451
[epoch20, step443]: loss 0.039509
[epoch20, step444]: loss 0.038783
[epoch20, step445]: loss 0.035562
[epoch20, step446]: loss 0.036277
[epoch20, step447]: loss 0.040142
[epoch20, step448]: loss 0.036572
[epoch20, step449]: loss 0.037310
[epoch20, step450]: loss 0.034191
[epoch20, step451]: loss 0.035118
[epoch20, step452]: loss 0.036971
[epoch20, step453]: loss 0.038355
[epoch20, step454]: loss 0.034839
[epoch20, step455]: loss 0.035394
[epoch20, step456]: loss 0.036579
[epoch20, step457]: loss 0.036396
[epoch20, step458]: loss 0.037584
[epoch20, step459]: loss 0.035324
[epoch20, step460]: loss 0.035504
[epoch20, step461]: loss 0.039325
[epoch20, step462]: loss 0.037143
[epoch20, step463]: loss 0.035811
[epoch20, step464]: loss 0.034958
[epoch20, step465]: loss 0.039266
[epoch20, step466]: loss 0.035633
[epoch20, step467]: loss 0.037348
[epoch20, step468]: loss 0.035063
[epoch20, step469]: loss 0.035779
[epoch20, step470]: loss 0.039070
[epoch20, step471]: loss 0.037076
[epoch20, step472]: loss 0.035381
[epoch20, step473]: loss 0.034923
[epoch20, step474]: loss 0.037887
[epoch20, step475]: loss 0.036025
[epoch20, step476]: loss 0.038054
[epoch20, step477]: loss 0.035340
[epoch20, step478]: loss 0.034955
[epoch20, step479]: loss 0.038145
[epoch20, step480]: loss 0.037632
[epoch20, step481]: loss 0.034762
[epoch20, step482]: loss 0.034914
[epoch20, step483]: loss 0.038765
[epoch20, step484]: loss 0.036194
[epoch20, step485]: loss 0.038039
[epoch20, step486]: loss 0.035369
[epoch20, step487]: loss 0.034853
[epoch20, step488]: loss 0.038761
[epoch20, step489]: loss 0.037192
[epoch20, step490]: loss 0.035550
[epoch20, step491]: loss 0.035363
[epoch20, step492]: loss 0.037821
[epoch20, step493]: loss 0.035491
[epoch20, step494]: loss 0.037587
[epoch20, step495]: loss 0.036385
[epoch20, step496]: loss 0.035375
[epoch20, step497]: loss 0.038555
[epoch20, step498]: loss 0.037856
[epoch20, step499]: loss 0.035549
[epoch20, step500]: loss 0.034867
[epoch20, step501]: loss 0.037717
[epoch20, step502]: loss 0.035818
[epoch20, step503]: loss 0.038316
[epoch20, step504]: loss 0.035211
[epoch20, step505]: loss 0.035151
[epoch20, step506]: loss 0.038876
[epoch20, step507]: loss 0.038524
[epoch20, step508]: loss 0.036095
[epoch20, step509]: loss 0.035011
[epoch20, step510]: loss 0.038521
[epoch20, step511]: loss 0.036208
[epoch20, step512]: loss 0.038110
[epoch20, step513]: loss 0.034750
[epoch20, step514]: loss 0.035431
[epoch20, step515]: loss 0.038161
[epoch20, step516]: loss 0.038038
[epoch20, step517]: loss 0.035093
[epoch20, step518]: loss 0.035448
[epoch20, step519]: loss 0.038110
[epoch20, step520]: loss 0.034845
[epoch20, step521]: loss 0.037713
[epoch20, step522]: loss 0.034270
[epoch20, step523]: loss 0.034852
[epoch20, step524]: loss 0.038621
[epoch20, step525]: loss 0.038730
[epoch20, step526]: loss 0.035240
[epoch20, step527]: loss 0.035222
[epoch20, step528]: loss 0.039042
[epoch20, step529]: loss 0.035546
[epoch20, step530]: loss 0.038949
[epoch20, step531]: loss 0.035564
[epoch20, step532]: loss 0.034835
[epoch20, step533]: loss 0.039225
[epoch20, step534]: loss 0.038571
[epoch20, step535]: loss 0.036905
[epoch20, step536]: loss 0.035395
[epoch20, step537]: loss 0.037588
[epoch20, step538]: loss 0.036587
[epoch20, step539]: loss 0.038250
[epoch20, step540]: loss 0.034223
[epoch20, step541]: loss 0.034919
[epoch20, step542]: loss 0.038222
[epoch20, step543]: loss 0.037258
[epoch20, step544]: loss 0.035482
[epoch20, step545]: loss 0.034664
[epoch20, step546]: loss 0.038496
[epoch20, step547]: loss 0.035589
[epoch20, step548]: loss 0.038666
[epoch20, step549]: loss 0.035322
[epoch20, step550]: loss 0.035566
[epoch20, step551]: loss 0.037828
[epoch20, step552]: loss 0.037776
[epoch20, step553]: loss 0.035622
[epoch20, step554]: loss 0.034913
[epoch20, step555]: loss 0.037804
[epoch20, step556]: loss 0.035832
[epoch20, step557]: loss 0.037331
[epoch20, step558]: loss 0.034924
[epoch20, step559]: loss 0.034907
[epoch20, step560]: loss 0.038025
[epoch20, step561]: loss 0.037996
[epoch20, step562]: loss 0.035391
[epoch20, step563]: loss 0.028751
[epoch20, step564]: loss 0.030504
[epoch20, step565]: loss 0.028252
[epoch20, step566]: loss 0.036537
[epoch20, step567]: loss 0.027487
[epoch20, step568]: loss 0.026905
[epoch20, step569]: loss 0.024000
[epoch20, step570]: loss 0.033063
[epoch20, step571]: loss 0.028520
[epoch20, step572]: loss 0.026300
[epoch20, step573]: loss 0.030967
[epoch20, step574]: loss 0.028842
[epoch20, step575]: loss 0.021184
[epoch20, step576]: loss 0.022031
[epoch20, step577]: loss 0.027518
[epoch20, step578]: loss 0.019526
[epoch20, step579]: loss 0.029961
[epoch20, step580]: loss 0.020690
[epoch20, step581]: loss 0.026990
[epoch20, step582]: loss 0.026174
[epoch20, step583]: loss 0.022549
[epoch20, step584]: loss 0.024063
[epoch20, step585]: loss 0.027000
[epoch20, step586]: loss 0.022242
[epoch20, step587]: loss 0.028317
[epoch20, step588]: loss 0.023372
[epoch20, step589]: loss 0.023745
[epoch20, step590]: loss 0.028150
[epoch20, step591]: loss 0.021162
[epoch20, step592]: loss 0.026381
[epoch20, step593]: loss 0.022926
[epoch20, step594]: loss 0.026680
[epoch20, step595]: loss 0.027060
[epoch20, step596]: loss 0.022757
[epoch20, step597]: loss 0.025500
[epoch20, step598]: loss 0.026812
[epoch20, step599]: loss 0.025498
[epoch20, step600]: loss 0.027980
[epoch20, step601]: loss 0.019727
[epoch20, step602]: loss 0.023008
[epoch20, step603]: loss 0.026362
[epoch20, step604]: loss 0.026833
[epoch20, step605]: loss 0.025433
[epoch20, step606]: loss 0.025334
[epoch20, step607]: loss 0.028129
[epoch20, step608]: loss 0.026078
[epoch20, step609]: loss 0.027156
[epoch20, step610]: loss 0.025742
[epoch20, step611]: loss 0.026498
[epoch20, step612]: loss 0.026105
[epoch20, step613]: loss 0.019679
[epoch20, step614]: loss 0.025631
[epoch20, step615]: loss 0.028554
[epoch20, step616]: loss 0.024236
[epoch20, step617]: loss 0.023897
[epoch20, step618]: loss 0.026087
[epoch20, step619]: loss 0.027014
[epoch20, step620]: loss 0.024604
[epoch20, step621]: loss 0.026633
[epoch20, step622]: loss 0.020819
[epoch20, step623]: loss 0.024608
[epoch20, step624]: loss 0.026900
[epoch20, step625]: loss 0.026393
[epoch20, step626]: loss 0.028772
[epoch20, step627]: loss 0.023246
[epoch20, step628]: loss 0.026418
[epoch20, step629]: loss 0.020986
[epoch20, step630]: loss 0.023800
[epoch20, step631]: loss 0.031229
[epoch20, step632]: loss 0.023801
[epoch20, step633]: loss 0.024862
[epoch20, step634]: loss 0.027275
[epoch20, step635]: loss 0.025946
[epoch20, step636]: loss 0.020905
[epoch20, step637]: loss 0.027574
[epoch20, step638]: loss 0.027166
[epoch20, step639]: loss 0.023126
[epoch20, step640]: loss 0.030159
[epoch20, step641]: loss 0.030430
[epoch20, step642]: loss 0.025196
[epoch20, step643]: loss 0.025909
[epoch20, step644]: loss 0.026302
[epoch20, step645]: loss 0.023880
[epoch20, step646]: loss 0.026847
[epoch20, step647]: loss 0.023950
[epoch20, step648]: loss 0.023527
[epoch20, step649]: loss 0.028974
[epoch20, step650]: loss 0.022531
[epoch20, step651]: loss 0.026818
[epoch20, step652]: loss 0.027754
[epoch20, step653]: loss 0.028657
[epoch20, step654]: loss 0.023529
[epoch20, step655]: loss 0.024265
[epoch20, step656]: loss 0.021684
[epoch20, step657]: loss 0.027971
[epoch20, step658]: loss 0.025572
[epoch20, step659]: loss 0.027865
[epoch20, step660]: loss 0.024117
[epoch20, step661]: loss 0.027163
[epoch20, step662]: loss 0.023939
[epoch20, step663]: loss 0.021492
[epoch20, step664]: loss 0.025188
[epoch20, step665]: loss 0.028531
[epoch20, step666]: loss 0.027199
[epoch20, step667]: loss 0.026868
[epoch20, step668]: loss 0.022785
[epoch20, step669]: loss 0.026329
[epoch20, step670]: loss 0.027399
[epoch20, step671]: loss 0.021679
[epoch20, step672]: loss 0.024147
[epoch20, step673]: loss 0.022416
[epoch20, step674]: loss 0.021490
[epoch20, step675]: loss 0.020280
[epoch20, step676]: loss 0.024773
[epoch20, step677]: loss 0.025622
[epoch20, step678]: loss 0.023476
[epoch20, step679]: loss 0.024203
[epoch20, step680]: loss 0.031153
[epoch20, step681]: loss 0.022286
[epoch20, step682]: loss 0.026399
[epoch20, step683]: loss 0.025941
[epoch20, step684]: loss 0.025110
[epoch20, step685]: loss 0.024509
[epoch20, step686]: loss 0.027733
[epoch20, step687]: loss 0.027063
[epoch20, step688]: loss 0.023351
[epoch20, step689]: loss 0.024666
[epoch20, step690]: loss 0.025579
[epoch20, step691]: loss 0.024606
[epoch20, step692]: loss 0.022918
[epoch20, step693]: loss 0.027800
[epoch20, step694]: loss 0.023109
[epoch20, step695]: loss 0.026943
[epoch20, step696]: loss 0.026143
[epoch20, step697]: loss 0.027656
[epoch20, step698]: loss 0.025015
[epoch20, step699]: loss 0.023509
[epoch20, step700]: loss 0.022042
[epoch20, step701]: loss 0.026006
[epoch20, step702]: loss 0.021975
[epoch20, step703]: loss 0.023353
[epoch20, step704]: loss 0.026017
[epoch20, step705]: loss 0.024905
[epoch20, step706]: loss 0.024097
[epoch20, step707]: loss 0.024527
[epoch20, step708]: loss 0.026482
[epoch20, step709]: loss 0.027690
[epoch20, step710]: loss 0.024381
[epoch20, step711]: loss 0.024256
[epoch20, step712]: loss 0.026905
[epoch20, step713]: loss 0.026599
[epoch20, step714]: loss 0.021709
[epoch20, step715]: loss 0.023443
[epoch20, step716]: loss 0.026320
[epoch20, step717]: loss 0.023845
[epoch20, step718]: loss 0.025535
[epoch20, step719]: loss 0.033366
[epoch20, step720]: loss 0.025367
[epoch20, step721]: loss 0.023487
[epoch20, step722]: loss 0.031490
[epoch20, step723]: loss 0.026653
[epoch20, step724]: loss 0.023516
[epoch20, step725]: loss 0.028609
[epoch20, step726]: loss 0.022441
[epoch20, step727]: loss 0.024693
[epoch20, step728]: loss 0.026530
[epoch20, step729]: loss 0.021849
[epoch20, step730]: loss 0.022981
[epoch20, step731]: loss 0.026367
[epoch20, step732]: loss 0.025904
[epoch20, step733]: loss 0.024189
[epoch20, step734]: loss 0.023335
[epoch20, step735]: loss 0.027165
[epoch20, step736]: loss 0.025166
[epoch20, step737]: loss 0.026901
[epoch20, step738]: loss 0.020840
[epoch20, step739]: loss 0.025754
[epoch20, step740]: loss 0.023012
[epoch20, step741]: loss 0.025550
[epoch20, step742]: loss 0.022467
[epoch20, step743]: loss 0.023723
[epoch20, step744]: loss 0.024015
[epoch20, step745]: loss 0.024799
[epoch20, step746]: loss 0.025674
[epoch20, step747]: loss 0.027667
[epoch20, step748]: loss 0.026342
[epoch20, step749]: loss 0.026602
[epoch20, step750]: loss 0.028193
[epoch20, step751]: loss 0.022092
[epoch20, step752]: loss 0.025358
[epoch20, step753]: loss 0.025639
[epoch20, step754]: loss 0.023135
[epoch20, step755]: loss 0.026560
[epoch20, step756]: loss 0.023662
[epoch20, step757]: loss 0.021202
[epoch20, step758]: loss 0.025108
[epoch20, step759]: loss 0.023477
[epoch20, step760]: loss 0.024450
[epoch20, step761]: loss 0.026276
[epoch20, step762]: loss 0.021672
[epoch20, step763]: loss 0.025727
[epoch20, step764]: loss 0.024261
[epoch20, step765]: loss 0.026321
[epoch20, step766]: loss 0.025058
[epoch20, step767]: loss 0.027518
[epoch20, step768]: loss 0.021567
[epoch20, step769]: loss 0.027121
[epoch20, step770]: loss 0.026793
[epoch20, step771]: loss 0.023204
[epoch20, step772]: loss 0.029367
[epoch20, step773]: loss 0.026769
[epoch20, step774]: loss 0.024123
[epoch20, step775]: loss 0.021170
[epoch20, step776]: loss 0.026086
[epoch20, step777]: loss 0.023380
[epoch20, step778]: loss 0.028685
[epoch20, step779]: loss 0.024255
[epoch20, step780]: loss 0.020607
[epoch20, step781]: loss 0.024933
[epoch20, step782]: loss 0.023038
[epoch20, step783]: loss 0.019774
[epoch20, step784]: loss 0.020782
[epoch20, step785]: loss 0.021294
[epoch20, step786]: loss 0.024451
[epoch20, step787]: loss 0.023854
[epoch20, step788]: loss 0.024831
[epoch20, step789]: loss 0.023042
[epoch20, step790]: loss 0.023463
[epoch20, step791]: loss 0.027062
[epoch20, step792]: loss 0.025115
[epoch20, step793]: loss 0.027408
[epoch20, step794]: loss 0.020480
[epoch20, step795]: loss 0.026008
[epoch20, step796]: loss 0.027882
[epoch20, step797]: loss 0.028402
[epoch20, step798]: loss 0.027241
[epoch20, step799]: loss 0.025699
[epoch20, step800]: loss 0.021835
[epoch20, step801]: loss 0.022294
[epoch20, step802]: loss 0.023161
[epoch20, step803]: loss 0.026404
[epoch20, step804]: loss 0.027558
[epoch20, step805]: loss 0.029186
[epoch20, step806]: loss 0.021918
[epoch20, step807]: loss 0.020981
[epoch20, step808]: loss 0.023287
[epoch20, step809]: loss 0.023355
[epoch20, step810]: loss 0.026156
[epoch20, step811]: loss 0.026134
[epoch20, step812]: loss 0.024925
[epoch20, step813]: loss 0.024075
[epoch20, step814]: loss 0.025325
[epoch20, step815]: loss 0.025000
[epoch20, step816]: loss 0.024760
[epoch20, step817]: loss 0.025161
[epoch20, step818]: loss 0.022802
[epoch20, step819]: loss 0.020775
[epoch20, step820]: loss 0.023705
[epoch20, step821]: loss 0.022145
[epoch20, step822]: loss 0.031161
[epoch20, step823]: loss 0.024249
[epoch20, step824]: loss 0.027204
[epoch20, step825]: loss 0.025622
[epoch20, step826]: loss 0.024703
[epoch20, step827]: loss 0.026908
[epoch20, step828]: loss 0.028854
[epoch20, step829]: loss 0.026846
[epoch20, step830]: loss 0.022704
[epoch20, step831]: loss 0.026412
[epoch20, step832]: loss 0.021305
[epoch20, step833]: loss 0.029082
[epoch20, step834]: loss 0.026081
[epoch20, step835]: loss 0.021006
[epoch20, step836]: loss 0.027112
[epoch20, step837]: loss 0.025798
[epoch20, step838]: loss 0.026290
[epoch20, step839]: loss 0.028930
[epoch20, step840]: loss 0.020851
[epoch20, step841]: loss 0.024825
[epoch20, step842]: loss 0.027880
[epoch20, step843]: loss 0.025643
[epoch20, step844]: loss 0.025591
[epoch20, step845]: loss 0.021563
[epoch20, step846]: loss 0.026202
[epoch20, step847]: loss 0.027150
[epoch20, step848]: loss 0.025556
[epoch20, step849]: loss 0.025340
[epoch20, step850]: loss 0.023521
[epoch20, step851]: loss 0.024754
[epoch20, step852]: loss 0.023243
[epoch20, step853]: loss 0.030146
[epoch20, step854]: loss 0.022755
[epoch20, step855]: loss 0.027320
[epoch20, step856]: loss 0.022598
[epoch20, step857]: loss 0.026347
[epoch20, step858]: loss 0.024776
[epoch20, step859]: loss 0.023847
[epoch20, step860]: loss 0.023070
[epoch20, step861]: loss 0.023511
[epoch20, step862]: loss 0.023189
[epoch20, step863]: loss 0.020909
[epoch20, step864]: loss 0.026951
[epoch20, step865]: loss 0.023602
[epoch20, step866]: loss 0.025363
[epoch20, step867]: loss 0.026430
[epoch20, step868]: loss 0.027140
[epoch20, step869]: loss 0.023889
[epoch20, step870]: loss 0.031701
[epoch20, step871]: loss 0.022478
[epoch20, step872]: loss 0.025807
[epoch20, step873]: loss 0.025978
[epoch20, step874]: loss 0.023996
[epoch20, step875]: loss 0.024635
[epoch20, step876]: loss 0.024742
[epoch20, step877]: loss 0.019432
[epoch20, step878]: loss 0.023659
[epoch20, step879]: loss 0.028257
[epoch20, step880]: loss 0.025698
[epoch20, step881]: loss 0.022366
[epoch20, step882]: loss 0.024764
[epoch20, step883]: loss 0.024538
[epoch20, step884]: loss 0.026681
[epoch20, step885]: loss 0.026112
[epoch20, step886]: loss 0.026581
[epoch20, step887]: loss 0.024337
[epoch20, step888]: loss 0.024998
[epoch20, step889]: loss 0.024063
[epoch20, step890]: loss 0.024022
[epoch20, step891]: loss 0.025650
[epoch20, step892]: loss 0.021330
[epoch20, step893]: loss 0.024633
[epoch20, step894]: loss 0.024911
[epoch20, step895]: loss 0.023084
[epoch20, step896]: loss 0.022272
[epoch20, step897]: loss 0.024398
[epoch20, step898]: loss 0.026070
[epoch20, step899]: loss 0.028553
[epoch20, step900]: loss 0.027362
[epoch20, step901]: loss 0.026036
[epoch20, step902]: loss 0.024263
[epoch20, step903]: loss 0.024923
[epoch20, step904]: loss 0.028470
[epoch20, step905]: loss 0.027999
[epoch20, step906]: loss 0.022601
[epoch20, step907]: loss 0.023693
[epoch20, step908]: loss 0.022955
[epoch20, step909]: loss 0.026057
[epoch20, step910]: loss 0.023464
[epoch20, step911]: loss 0.025603
[epoch20, step912]: loss 0.023958
[epoch20, step913]: loss 0.024671
[epoch20, step914]: loss 0.030950
[epoch20, step915]: loss 0.024265
[epoch20, step916]: loss 0.023753
[epoch20, step917]: loss 0.025385
[epoch20, step918]: loss 0.028785
[epoch20, step919]: loss 0.024541
[epoch20, step920]: loss 0.027589
[epoch20, step921]: loss 0.024593
[epoch20, step922]: loss 0.023593
[epoch20, step923]: loss 0.023208
[epoch20, step924]: loss 0.021516
[epoch20, step925]: loss 0.025727
[epoch20, step926]: loss 0.026774
[epoch20, step927]: loss 0.026246
[epoch20, step928]: loss 0.025218
[epoch20, step929]: loss 0.027861
[epoch20, step930]: loss 0.026118
[epoch20, step931]: loss 0.028158
[epoch20, step932]: loss 0.022039
[epoch20, step933]: loss 0.028629
[epoch20, step934]: loss 0.022437
[epoch20, step935]: loss 0.022767
[epoch20, step936]: loss 0.023076
[epoch20, step937]: loss 0.027972
[epoch20, step938]: loss 0.025818
[epoch20, step939]: loss 0.021103
[epoch20, step940]: loss 0.023564
[epoch20, step941]: loss 0.026993
[epoch20, step942]: loss 0.025789
[epoch20, step943]: loss 0.023821
[epoch20, step944]: loss 0.028147
[epoch20, step945]: loss 0.020510
[epoch20, step946]: loss 0.025801
[epoch20, step947]: loss 0.028314
[epoch20, step948]: loss 0.019922
[epoch20, step949]: loss 0.022883
[epoch20, step950]: loss 0.026606
[epoch20, step951]: loss 0.029012
[epoch20, step952]: loss 0.025369
[epoch20, step953]: loss 0.027747
[epoch20, step954]: loss 0.022887
[epoch20, step955]: loss 0.036721
[epoch20, step956]: loss 0.051473
[epoch20, step957]: loss 0.044925
[epoch20, step958]: loss 0.042401
[epoch20, step959]: loss 0.046368
[epoch20, step960]: loss 0.043560
[epoch20, step961]: loss 0.043303
[epoch20, step962]: loss 0.040969
[epoch20, step963]: loss 0.040766
[epoch20, step964]: loss 0.041853
[epoch20, step965]: loss 0.042674
[epoch20, step966]: loss 0.040816
[epoch20, step967]: loss 0.040384
[epoch20, step968]: loss 0.042890
[epoch20, step969]: loss 0.041930
[epoch20, step970]: loss 0.040550
[epoch20, step971]: loss 0.039699
[epoch20, step972]: loss 0.040595
[epoch20, step973]: loss 0.039329
[epoch20, step974]: loss 0.041214
[epoch20, step975]: loss 0.038579
[epoch20, step976]: loss 0.037654
[epoch20, step977]: loss 0.041307
[epoch20, step978]: loss 0.039507
[epoch20, step979]: loss 0.039176
[epoch20, step980]: loss 0.037363
[epoch20, step981]: loss 0.039058
[epoch20, step982]: loss 0.039237
[epoch20, step983]: loss 0.040212
[epoch20, step984]: loss 0.036721
[epoch20, step985]: loss 0.037121
[epoch20, step986]: loss 0.040853
[epoch20, step987]: loss 0.039149
[epoch20, step988]: loss 0.038927
[epoch20, step989]: loss 0.037585
[epoch20, step990]: loss 0.038621
[epoch20, step991]: loss 0.039270
[epoch20, step992]: loss 0.039525
[epoch20, step993]: loss 0.037293
[epoch20, step994]: loss 0.036395
[epoch20, step995]: loss 0.040047
[epoch20, step996]: loss 0.038210
[epoch20, step997]: loss 0.038228
[epoch20, step998]: loss 0.037191
[epoch20, step999]: loss 0.038625
[epoch20, step1000]: loss 0.038785
[epoch20, step1001]: loss 0.039341
[epoch20, step1002]: loss 0.037022
[epoch20, step1003]: loss 0.036334
[epoch20, step1004]: loss 0.039748
[epoch20, step1005]: loss 0.037200
[epoch20, step1006]: loss 0.038198
[epoch20, step1007]: loss 0.035951
[epoch20, step1008]: loss 0.037811
[epoch20, step1009]: loss 0.038114
[epoch20, step1010]: loss 0.039559
[epoch20, step1011]: loss 0.036266
[epoch20, step1012]: loss 0.036339
[epoch20, step1013]: loss 0.040147
[epoch20, step1014]: loss 0.039465
[epoch20, step1015]: loss 0.038208
[epoch20, step1016]: loss 0.035509
[epoch20, step1017]: loss 0.038057
[epoch20, step1018]: loss 0.038093
[epoch20, step1019]: loss 0.039126
[epoch20, step1020]: loss 0.036111
[epoch20, step1021]: loss 0.035754
[epoch20, step1022]: loss 0.039305
[epoch20, step1023]: loss 0.037876
[epoch20, step1024]: loss 0.037957
[epoch20, step1025]: loss 0.035517
[epoch20, step1026]: loss 0.037560
[epoch20, step1027]: loss 0.037927
[epoch20, step1028]: loss 0.038735
[epoch20, step1029]: loss 0.036057
[epoch20, step1030]: loss 0.035562
[epoch20, step1031]: loss 0.038204
[epoch20, step1032]: loss 0.038064
[epoch20, step1033]: loss 0.036545
[epoch20, step1034]: loss 0.035558
[epoch20, step1035]: loss 0.036846
[epoch20, step1036]: loss 0.037983
[epoch20, step1037]: loss 0.038717
[epoch20, step1038]: loss 0.035815
[epoch20, step1039]: loss 0.035679
[epoch20, step1040]: loss 0.038348
[epoch20, step1041]: loss 0.037451
[epoch20, step1042]: loss 0.036477
[epoch20, step1043]: loss 0.035845
[epoch20, step1044]: loss 0.037630
[epoch20, step1045]: loss 0.038532
[epoch20, step1046]: loss 0.039387
[epoch20, step1047]: loss 0.035677
[epoch20, step1048]: loss 0.036268
[epoch20, step1049]: loss 0.039526
[epoch20, step1050]: loss 0.037980
[epoch20, step1051]: loss 0.037877
[epoch20, step1052]: loss 0.037458
[epoch20, step1053]: loss 0.038553
[epoch20, step1054]: loss 0.038130
[epoch20, step1055]: loss 0.038581
[epoch20, step1056]: loss 0.035652
[epoch20, step1057]: loss 0.036115
[epoch20, step1058]: loss 0.040231
[epoch20, step1059]: loss 0.038963
[epoch20, step1060]: loss 0.038056
[epoch20, step1061]: loss 0.035032
[epoch20, step1062]: loss 0.038079
[epoch20, step1063]: loss 0.038057
[epoch20, step1064]: loss 0.038169
[epoch20, step1065]: loss 0.036056
[epoch20, step1066]: loss 0.035226
[epoch20, step1067]: loss 0.038776
[epoch20, step1068]: loss 0.036462
[epoch20, step1069]: loss 0.036348
[epoch20, step1070]: loss 0.035102
[epoch20, step1071]: loss 0.037406
[epoch20, step1072]: loss 0.037986
[epoch20, step1073]: loss 0.037788
[epoch20, step1074]: loss 0.036306
[epoch20, step1075]: loss 0.035507
[epoch20, step1076]: loss 0.038437
[epoch20, step1077]: loss 0.037389
[epoch20, step1078]: loss 0.037024
[epoch20, step1079]: loss 0.035872
[epoch20, step1080]: loss 0.036962
[epoch20, step1081]: loss 0.037657
[epoch20, step1082]: loss 0.037508
[epoch20, step1083]: loss 0.035987
[epoch20, step1084]: loss 0.035539
[epoch20, step1085]: loss 0.037975
[epoch20, step1086]: loss 0.037104
[epoch20, step1087]: loss 0.036458
[epoch20, step1088]: loss 0.034979
[epoch20, step1089]: loss 0.037702
[epoch20, step1090]: loss 0.038013
[epoch20, step1091]: loss 0.038881
[epoch20, step1092]: loss 0.035776
[epoch20, step1093]: loss 0.036023
[epoch20, step1094]: loss 0.039469
[epoch20, step1095]: loss 0.037602
[epoch20, step1096]: loss 0.036249
[epoch20, step1097]: loss 0.035598
[epoch20, step1098]: loss 0.036914
[epoch20, step1099]: loss 0.036680
[epoch20, step1100]: loss 0.038419
[epoch20, step1101]: loss 0.035417
[epoch20, step1102]: loss 0.034870
[epoch20, step1103]: loss 0.038069
[epoch20, step1104]: loss 0.036455
[epoch20, step1105]: loss 0.037438
[epoch20, step1106]: loss 0.034378
[epoch20, step1107]: loss 0.037006
[epoch20, step1108]: loss 0.036414
[epoch20, step1109]: loss 0.038300
[epoch20, step1110]: loss 0.036472
[epoch20, step1111]: loss 0.035718
[epoch20, step1112]: loss 0.038914
[epoch20, step1113]: loss 0.037176
[epoch20, step1114]: loss 0.037593
[epoch20, step1115]: loss 0.035461
[epoch20, step1116]: loss 0.037540
[epoch20, step1117]: loss 0.037231
[epoch20, step1118]: loss 0.037844
[epoch20, step1119]: loss 0.035237
[epoch20, step1120]: loss 0.034978
[epoch20, step1121]: loss 0.038459
[epoch20, step1122]: loss 0.036427
[epoch20, step1123]: loss 0.035727
[epoch20, step1124]: loss 0.036079
[epoch20, step1125]: loss 0.037530
[epoch20, step1126]: loss 0.038743
[epoch20, step1127]: loss 0.038330
[epoch20, step1128]: loss 0.035517
[epoch20, step1129]: loss 0.035244
[epoch20, step1130]: loss 0.039430
[epoch20, step1131]: loss 0.037554
[epoch20, step1132]: loss 0.037646
[epoch20, step1133]: loss 0.034624
[epoch20, step1134]: loss 0.036686
[epoch20, step1135]: loss 0.037969
[epoch20, step1136]: loss 0.038634
[epoch20, step1137]: loss 0.035505
[epoch20, step1138]: loss 0.035685
[epoch20, step1139]: loss 0.038737
[epoch20, step1140]: loss 0.036401
[epoch20, step1141]: loss 0.036758
[epoch20, step1142]: loss 0.034894
[epoch20, step1143]: loss 0.036147
[epoch20, step1144]: loss 0.037463
[epoch20, step1145]: loss 0.037335
[epoch20, step1146]: loss 0.034698
[epoch20, step1147]: loss 0.035465
[epoch20, step1148]: loss 0.038527
[epoch20, step1149]: loss 0.036606
[epoch20, step1150]: loss 0.036427
[epoch20, step1151]: loss 0.035454
[epoch20, step1152]: loss 0.037400
[epoch20, step1153]: loss 0.036985
[epoch20, step1154]: loss 0.038355
[epoch20, step1155]: loss 0.035518
[epoch20, step1156]: loss 0.034611
[epoch20, step1157]: loss 0.038048
[epoch20, step1158]: loss 0.037608
[epoch20, step1159]: loss 0.036990
[epoch20, step1160]: loss 0.035284
[epoch20, step1161]: loss 0.036981
[epoch20, step1162]: loss 0.036787
[epoch20, step1163]: loss 0.037238
[epoch20, step1164]: loss 0.035203
[epoch20, step1165]: loss 0.036044
[epoch20, step1166]: loss 0.037984
[epoch20, step1167]: loss 0.035681
[epoch20, step1168]: loss 0.036559
[epoch20, step1169]: loss 0.034487
[epoch20, step1170]: loss 0.036478
[epoch20, step1171]: loss 0.037466
[epoch20, step1172]: loss 0.038111
[epoch20, step1173]: loss 0.035338
[epoch20, step1174]: loss 0.034989
[epoch20, step1175]: loss 0.038538
[epoch20, step1176]: loss 0.035936
[epoch20, step1177]: loss 0.037109
[epoch20, step1178]: loss 0.035241
[epoch20, step1179]: loss 0.036842
[epoch20, step1180]: loss 0.037419
[epoch20, step1181]: loss 0.038485
[epoch20, step1182]: loss 0.034530
[epoch20, step1183]: loss 0.035091
[epoch20, step1184]: loss 0.037401
[epoch20, step1185]: loss 0.036858
[epoch20, step1186]: loss 0.036029
[epoch20, step1187]: loss 0.034218
[epoch20, step1188]: loss 0.035966
[epoch20, step1189]: loss 0.036289
[epoch20, step1190]: loss 0.037562
[epoch20, step1191]: loss 0.035655
[epoch20, step1192]: loss 0.035067
[epoch20, step1193]: loss 0.037747
[epoch20, step1194]: loss 0.036582
[epoch20, step1195]: loss 0.035620
[epoch20, step1196]: loss 0.034045
[epoch20, step1197]: loss 0.036886
[epoch20, step1198]: loss 0.036996
[epoch20, step1199]: loss 0.037370
[epoch20, step1200]: loss 0.034538
[epoch20, step1201]: loss 0.035407
[epoch20, step1202]: loss 0.038949
[epoch20, step1203]: loss 0.036817
[epoch20, step1204]: loss 0.035664
[epoch20, step1205]: loss 0.034265
[epoch20, step1206]: loss 0.036106
[epoch20, step1207]: loss 0.036994
[epoch20, step1208]: loss 0.037735
[epoch20, step1209]: loss 0.034274
[epoch20, step1210]: loss 0.035204
[epoch20, step1211]: loss 0.038103
[epoch20, step1212]: loss 0.036388
[epoch20, step1213]: loss 0.035883
[epoch20, step1214]: loss 0.035151
[epoch20, step1215]: loss 0.037343
[epoch20, step1216]: loss 0.036565
[epoch20, step1217]: loss 0.037620
[epoch20, step1218]: loss 0.034444
[epoch20, step1219]: loss 0.035382
[epoch20, step1220]: loss 0.038611
[epoch20, step1221]: loss 0.036431
[epoch20, step1222]: loss 0.036362
[epoch20, step1223]: loss 0.035066
[epoch20, step1224]: loss 0.037544
[epoch20, step1225]: loss 0.036731
[epoch20, step1226]: loss 0.037663
[epoch20, step1227]: loss 0.034715
[epoch20, step1228]: loss 0.034694
[epoch20, step1229]: loss 0.037715
[epoch20, step1230]: loss 0.036806
[epoch20, step1231]: loss 0.036310
[epoch20, step1232]: loss 0.035149
[epoch20, step1233]: loss 0.036119
[epoch20, step1234]: loss 0.036279
[epoch20, step1235]: loss 0.038350
[epoch20, step1236]: loss 0.035360
[epoch20, step1237]: loss 0.034616
[epoch20, step1238]: loss 0.037820
[epoch20, step1239]: loss 0.036896
[epoch20, step1240]: loss 0.036739
[epoch20, step1241]: loss 0.033959
[epoch20, step1242]: loss 0.036280
[epoch20, step1243]: loss 0.037006
[epoch20, step1244]: loss 0.038380
[epoch20, step1245]: loss 0.035286
[epoch20, step1246]: loss 0.035680
[epoch20, step1247]: loss 0.037635
[epoch20, step1248]: loss 0.037246
[epoch20, step1249]: loss 0.036882
[epoch20, step1250]: loss 0.034838
[epoch20, step1251]: loss 0.037095
[epoch20, step1252]: loss 0.037871
[epoch20, step1253]: loss 0.038449
[epoch20, step1254]: loss 0.035585
[epoch20, step1255]: loss 0.035127
[epoch20, step1256]: loss 0.038277
[epoch20, step1257]: loss 0.036848
[epoch20, step1258]: loss 0.036246
[epoch20, step1259]: loss 0.034288
[epoch20, step1260]: loss 0.036386
[epoch20, step1261]: loss 0.036770
[epoch20, step1262]: loss 0.036786
[epoch20, step1263]: loss 0.035948
[epoch20, step1264]: loss 0.034870
[epoch20, step1265]: loss 0.037085
[epoch20, step1266]: loss 0.036265
[epoch20, step1267]: loss 0.035993
[epoch20, step1268]: loss 0.035488
[epoch20, step1269]: loss 0.036997
[epoch20, step1270]: loss 0.036287
[epoch20, step1271]: loss 0.038292
[epoch20, step1272]: loss 0.035308
[epoch20, step1273]: loss 0.034599
[epoch20, step1274]: loss 0.037821
[epoch20, step1275]: loss 0.036941
[epoch20, step1276]: loss 0.036058
[epoch20, step1277]: loss 0.034460
[epoch20, step1278]: loss 0.037039
[epoch20, step1279]: loss 0.036743
[epoch20, step1280]: loss 0.037821
[epoch20, step1281]: loss 0.034879
[epoch20, step1282]: loss 0.034563
[epoch20, step1283]: loss 0.037409
[epoch20, step1284]: loss 0.036565
[epoch20, step1285]: loss 0.037001
[epoch20, step1286]: loss 0.034488
[epoch20, step1287]: loss 0.037227
[epoch20, step1288]: loss 0.037313
[epoch20, step1289]: loss 0.038524
[epoch20, step1290]: loss 0.034861
[epoch20, step1291]: loss 0.034677
[epoch20, step1292]: loss 0.038757
[epoch20, step1293]: loss 0.036009
[epoch20, step1294]: loss 0.036613
[epoch20, step1295]: loss 0.035358
[epoch20, step1296]: loss 0.036619
[epoch20, step1297]: loss 0.036796
[epoch20, step1298]: loss 0.037962
[epoch20, step1299]: loss 0.035118
[epoch20, step1300]: loss 0.035434
[epoch20, step1301]: loss 0.037566
[epoch20, step1302]: loss 0.037064
[epoch20, step1303]: loss 0.036643
[epoch20, step1304]: loss 0.034460
[epoch20, step1305]: loss 0.036746
[epoch20, step1306]: loss 0.036527
[epoch20, step1307]: loss 0.037092
[epoch20, step1308]: loss 0.035220
[epoch20, step1309]: loss 0.034274
[epoch20, step1310]: loss 0.037758
[epoch20, step1311]: loss 0.035607
[epoch20, step1312]: loss 0.036892
[epoch20, step1313]: loss 0.034660
[epoch20, step1314]: loss 0.036095
[epoch20, step1315]: loss 0.036631
[epoch20, step1316]: loss 0.038899
[epoch20, step1317]: loss 0.033968
[epoch20, step1318]: loss 0.034473
[epoch20, step1319]: loss 0.037406
[epoch20, step1320]: loss 0.036512
[epoch20, step1321]: loss 0.036994
[epoch20, step1322]: loss 0.034766
[epoch20, step1323]: loss 0.036983
[epoch20, step1324]: loss 0.036503
[epoch20, step1325]: loss 0.037204
[epoch20, step1326]: loss 0.034749
[epoch20, step1327]: loss 0.034757
[epoch20, step1328]: loss 0.037972
[epoch20, step1329]: loss 0.036328
[epoch20, step1330]: loss 0.036575
[epoch20, step1331]: loss 0.034619
[epoch20, step1332]: loss 0.036163
[epoch20, step1333]: loss 0.036283
[epoch20, step1334]: loss 0.037823
[epoch20, step1335]: loss 0.035459
[epoch20, step1336]: loss 0.034914
[epoch20, step1337]: loss 0.037481
[epoch20, step1338]: loss 0.037113
[epoch20, step1339]: loss 0.037812
[epoch20, step1340]: loss 0.034302
[epoch20, step1341]: loss 0.036280
[epoch20, step1342]: loss 0.037173
[epoch20, step1343]: loss 0.037912
[epoch20, step1344]: loss 0.035366
[epoch20, step1345]: loss 0.034329
[epoch20, step1346]: loss 0.037391
[epoch20, step1347]: loss 0.036926
[epoch20, step1348]: loss 0.035942
[epoch20, step1349]: loss 0.034950
[epoch20, step1350]: loss 0.036978
[epoch20, step1351]: loss 0.036613
[epoch20, step1352]: loss 0.036409
[epoch20, step1353]: loss 0.035043
[epoch20, step1354]: loss 0.035142
[epoch20, step1355]: loss 0.037901
[epoch20, step1356]: loss 0.035886
[epoch20, step1357]: loss 0.036343
[epoch20, step1358]: loss 0.034282
[epoch20, step1359]: loss 0.035776
[epoch20, step1360]: loss 0.036779
[epoch20, step1361]: loss 0.037531
[epoch20, step1362]: loss 0.035382
[epoch20, step1363]: loss 0.034561
[epoch20, step1364]: loss 0.038395
[epoch20, step1365]: loss 0.036770
[epoch20, step1366]: loss 0.035911
[epoch20, step1367]: loss 0.034493
[epoch20, step1368]: loss 0.037663
[epoch20, step1369]: loss 0.036938
[epoch20, step1370]: loss 0.038401
[epoch20, step1371]: loss 0.036446
[epoch20, step1372]: loss 0.034601
[epoch20, step1373]: loss 0.037319
[epoch20, step1374]: loss 0.037359
[epoch20, step1375]: loss 0.037350
[epoch20, step1376]: loss 0.034578
[epoch20, step1377]: loss 0.036042
[epoch20, step1378]: loss 0.037361
[epoch20, step1379]: loss 0.037390
[epoch20, step1380]: loss 0.035110
[epoch20, step1381]: loss 0.034874
[epoch20, step1382]: loss 0.038367
[epoch20, step1383]: loss 0.036417
[epoch20, step1384]: loss 0.036561
[epoch20, step1385]: loss 0.033898
[epoch20, step1386]: loss 0.036882
[epoch20, step1387]: loss 0.037840
[epoch20, step1388]: loss 0.036617
[epoch20, step1389]: loss 0.034052
[epoch20, step1390]: loss 0.034270
[epoch20, step1391]: loss 0.037647
[epoch20, step1392]: loss 0.036514
[epoch20, step1393]: loss 0.036373
[epoch20, step1394]: loss 0.034317
[epoch20, step1395]: loss 0.036554
[epoch20, step1396]: loss 0.036247
[epoch20, step1397]: loss 0.037362
[epoch20, step1398]: loss 0.034565
[epoch20, step1399]: loss 0.034787
[epoch20, step1400]: loss 0.039017
[epoch20, step1401]: loss 0.037209
[epoch20, step1402]: loss 0.035990
[epoch20, step1403]: loss 0.034416
[epoch20, step1404]: loss 0.037515
[epoch20, step1405]: loss 0.036912
[epoch20, step1406]: loss 0.037777
[epoch20, step1407]: loss 0.036479
[epoch20, step1408]: loss 0.034469
[epoch20, step1409]: loss 0.037455
[epoch20, step1410]: loss 0.036861
[epoch20, step1411]: loss 0.035360
[epoch20, step1412]: loss 0.034287
[epoch20, step1413]: loss 0.037368
[epoch20, step1414]: loss 0.037018
[epoch20, step1415]: loss 0.037069
[epoch20, step1416]: loss 0.035675
[epoch20, step1417]: loss 0.035829
[epoch20, step1418]: loss 0.038058
[epoch20, step1419]: loss 0.036759
[epoch20, step1420]: loss 0.037084
[epoch20, step1421]: loss 0.035309
[epoch20, step1422]: loss 0.036017
[epoch20, step1423]: loss 0.036129
[epoch20, step1424]: loss 0.037653
[epoch20, step1425]: loss 0.034062
[epoch20, step1426]: loss 0.034545
[epoch20, step1427]: loss 0.038722
[epoch20, step1428]: loss 0.037160
[epoch20, step1429]: loss 0.036161
[epoch20, step1430]: loss 0.034163
[epoch20, step1431]: loss 0.036442
[epoch20, step1432]: loss 0.036351
[epoch20, step1433]: loss 0.037263
[epoch20, step1434]: loss 0.034241
[epoch20, step1435]: loss 0.035451
[epoch20, step1436]: loss 0.037964
[epoch20, step1437]: loss 0.036780
[epoch20, step1438]: loss 0.036378
[epoch20, step1439]: loss 0.034607
[epoch20, step1440]: loss 0.036512
[epoch20, step1441]: loss 0.036771
[epoch20, step1442]: loss 0.036756
[epoch20, step1443]: loss 0.035066
[epoch20, step1444]: loss 0.033675
[epoch20, step1445]: loss 0.037759
[epoch20, step1446]: loss 0.036760
[epoch20, step1447]: loss 0.036477
[epoch20, step1448]: loss 0.033637
[epoch20, step1449]: loss 0.035741
[epoch20, step1450]: loss 0.036772
[epoch20, step1451]: loss 0.037677
[epoch20, step1452]: loss 0.034605
[epoch20, step1453]: loss 0.035811
[epoch20, step1454]: loss 0.038785
[epoch20, step1455]: loss 0.037603
[epoch20, step1456]: loss 0.035730
[epoch20, step1457]: loss 0.035533
[epoch20, step1458]: loss 0.037363
[epoch20, step1459]: loss 0.036864
[epoch20, step1460]: loss 0.037808
[epoch20, step1461]: loss 0.035517
[epoch20, step1462]: loss 0.035002
[epoch20, step1463]: loss 0.037855
[epoch20, step1464]: loss 0.037528
[epoch20, step1465]: loss 0.035591
[epoch20, step1466]: loss 0.033448
[epoch20, step1467]: loss 0.036348
[epoch20, step1468]: loss 0.036873
[epoch20, step1469]: loss 0.037513
[epoch20, step1470]: loss 0.034801
[epoch20, step1471]: loss 0.034171
[epoch20, step1472]: loss 0.037899
[epoch20, step1473]: loss 0.036709
[epoch20, step1474]: loss 0.036494
[epoch20, step1475]: loss 0.034033
[epoch20, step1476]: loss 0.036974
[epoch20, step1477]: loss 0.036425
[epoch20, step1478]: loss 0.037578
[epoch20, step1479]: loss 0.034802
[epoch20, step1480]: loss 0.034808
[epoch20, step1481]: loss 0.036580
[epoch20, step1482]: loss 0.036100
[epoch20, step1483]: loss 0.036470
[epoch20, step1484]: loss 0.034256
[epoch20, step1485]: loss 0.036145
[epoch20, step1486]: loss 0.035231
[epoch20, step1487]: loss 0.037179
[epoch20, step1488]: loss 0.034521
[epoch20, step1489]: loss 0.034300
[epoch20, step1490]: loss 0.037669
[epoch20, step1491]: loss 0.037214
[epoch20, step1492]: loss 0.036231
[epoch20, step1493]: loss 0.034148
[epoch20, step1494]: loss 0.036886
[epoch20, step1495]: loss 0.036490
[epoch20, step1496]: loss 0.036198
[epoch20, step1497]: loss 0.034815
[epoch20, step1498]: loss 0.034468
[epoch20, step1499]: loss 0.036817
[epoch20, step1500]: loss 0.036674
[epoch20, step1501]: loss 0.036046
[epoch20, step1502]: loss 0.034101
[epoch20, step1503]: loss 0.036358
[epoch20, step1504]: loss 0.035921
[epoch20, step1505]: loss 0.037823
[epoch20, step1506]: loss 0.034098
[epoch20, step1507]: loss 0.035033
[epoch20, step1508]: loss 0.039083
[epoch20, step1509]: loss 0.035968
[epoch20, step1510]: loss 0.035020
[epoch20, step1511]: loss 0.035056
[epoch20, step1512]: loss 0.036452
[epoch20, step1513]: loss 0.035244
[epoch20, step1514]: loss 0.037405
[epoch20, step1515]: loss 0.034745
[epoch20, step1516]: loss 0.034524

[epoch20]: avg loss 0.033794

