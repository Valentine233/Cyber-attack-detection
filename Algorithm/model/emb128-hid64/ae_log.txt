[epoch1, step1]: loss 1231.163086
[epoch1, step2]: loss 1233.076660
[epoch1, step3]: loss 1215.959229
[epoch1, step4]: loss 1211.457520
[epoch1, step5]: loss 1204.836548
[epoch1, step6]: loss 1203.934814
[epoch1, step7]: loss 1214.596924
[epoch1, step8]: loss 1211.211548
[epoch1, step9]: loss 1206.491943
[epoch1, step10]: loss 1207.164917
[epoch1, step11]: loss 1186.185791
[epoch1, step12]: loss 1203.317139
[epoch1, step13]: loss 1198.867310
[epoch1, step14]: loss 1195.535400
[epoch1, step15]: loss 1202.190674
[epoch1, step16]: loss 1184.513794
[epoch1, step17]: loss 1189.030518
[epoch1, step18]: loss 1177.437012
[epoch1, step19]: loss 1185.221191
[epoch1, step20]: loss 1158.835205
[epoch1, step21]: loss 1142.279541
[epoch1, step22]: loss 1173.052246
[epoch1, step23]: loss 1172.496460
[epoch1, step24]: loss 1175.650146
[epoch1, step25]: loss 1174.434082
[epoch1, step26]: loss 1159.062622
[epoch1, step27]: loss 1163.778076
[epoch1, step28]: loss 1173.800537
[epoch1, step29]: loss 1164.979248
[epoch1, step30]: loss 1145.527954
[epoch1, step31]: loss 1157.830933
[epoch1, step32]: loss 1158.377563
[epoch1, step33]: loss 1150.693970
[epoch1, step34]: loss 1151.407837
[epoch1, step35]: loss 1129.908081
[epoch1, step36]: loss 1144.990234
[epoch1, step37]: loss 1155.214844
[epoch1, step38]: loss 1141.316162
[epoch1, step39]: loss 1140.795532
[epoch1, step40]: loss 1128.299927
[epoch1, step41]: loss 1132.599365
[epoch1, step42]: loss 1133.122070
[epoch1, step43]: loss 1109.159790
[epoch1, step44]: loss 1114.835205
[epoch1, step45]: loss 1130.048218
[epoch1, step46]: loss 1131.729492
[epoch1, step47]: loss 1117.366821
[epoch1, step48]: loss 1129.066040
[epoch1, step49]: loss 1125.952515
[epoch1, step50]: loss 1114.268677
[epoch1, step51]: loss 1118.698730
[epoch1, step52]: loss 1099.509033
[epoch1, step53]: loss 1104.737305
[epoch1, step54]: loss 1106.119141
[epoch1, step55]: loss 1109.774048
[epoch1, step56]: loss 1094.051758
[epoch1, step57]: loss 1107.593750
[epoch1, step58]: loss 1102.157471
[epoch1, step59]: loss 1085.695190
[epoch1, step60]: loss 1101.708618
[epoch1, step61]: loss 1077.880859
[epoch1, step62]: loss 1089.284912
[epoch1, step63]: loss 1092.491699
[epoch1, step64]: loss 1091.300293
[epoch1, step65]: loss 1077.837646
[epoch1, step66]: loss 1076.975830
[epoch1, step67]: loss 1083.339111
[epoch1, step68]: loss 1077.193115
[epoch1, step69]: loss 1082.940063
[epoch1, step70]: loss 1070.127563
[epoch1, step71]: loss 1077.325195
[epoch1, step72]: loss 1040.714355
[epoch1, step73]: loss 1071.088257
[epoch1, step74]: loss 1051.206909
[epoch1, step75]: loss 1058.011719
[epoch1, step76]: loss 1054.755005
[epoch1, step77]: loss 1054.969116
[epoch1, step78]: loss 1056.572632
[epoch1, step79]: loss 1051.323975
[epoch1, step80]: loss 1053.258789
[epoch1, step81]: loss 1038.979370
[epoch1, step82]: loss 1032.905762
[epoch1, step83]: loss 1048.948608
[epoch1, step84]: loss 1044.229126
[epoch1, step85]: loss 1033.794556
[epoch1, step86]: loss 1041.791382
[epoch1, step87]: loss 1030.244629
[epoch1, step88]: loss 1029.319580
[epoch1, step89]: loss 1029.105591
[epoch1, step90]: loss 1034.453857
[epoch1, step91]: loss 1021.335205
[epoch1, step92]: loss 1021.113342
[epoch1, step93]: loss 1022.601074
[epoch1, step94]: loss 1019.385315
[epoch1, step95]: loss 1015.336121
[epoch1, step96]: loss 1017.693298
[epoch1, step97]: loss 1018.761536
[epoch1, step98]: loss 1000.126831
[epoch1, step99]: loss 1001.552551
[epoch1, step100]: loss 1014.860352
[epoch1, step101]: loss 998.555176
[epoch1, step102]: loss 995.567322
[epoch1, step103]: loss 1001.135559
[epoch1, step104]: loss 1003.035706
[epoch1, step105]: loss 1006.198547
[epoch1, step106]: loss 989.165894
[epoch1, step107]: loss 989.054199
[epoch1, step108]: loss 979.449036
[epoch1, step109]: loss 978.859558
[epoch1, step110]: loss 984.812256
[epoch1, step111]: loss 972.270508
[epoch1, step112]: loss 972.780029
[epoch1, step113]: loss 974.852356
[epoch1, step114]: loss 969.084229
[epoch1, step115]: loss 960.062439
[epoch1, step116]: loss 963.218140
[epoch1, step117]: loss 963.281067
[epoch1, step118]: loss 951.097351
[epoch1, step119]: loss 955.601929
[epoch1, step120]: loss 953.975525
[epoch1, step121]: loss 961.225464
[epoch1, step122]: loss 934.033508
[epoch1, step123]: loss 943.387024
[epoch1, step124]: loss 946.090820
[epoch1, step125]: loss 939.842529
[epoch1, step126]: loss 939.208435
[epoch1, step127]: loss 930.626038
[epoch1, step128]: loss 930.944092
[epoch1, step129]: loss 928.439819
[epoch1, step130]: loss 925.908936
[epoch1, step131]: loss 921.096252
[epoch1, step132]: loss 921.817200
[epoch1, step133]: loss 911.167603
[epoch1, step134]: loss 909.867188
[epoch1, step135]: loss 903.090027
[epoch1, step136]: loss 886.254822
[epoch1, step137]: loss 889.261230
[epoch1, step138]: loss 887.908936
[epoch1, step139]: loss 900.567505
[epoch1, step140]: loss 898.048279
[epoch1, step141]: loss 895.572693
[epoch1, step142]: loss 882.795898
[epoch1, step143]: loss 892.095276
[epoch1, step144]: loss 879.167053
[epoch1, step145]: loss 880.776428
[epoch1, step146]: loss 885.949951
[epoch1, step147]: loss 878.959839
[epoch1, step148]: loss 867.818359
[epoch1, step149]: loss 844.082336
[epoch1, step150]: loss 873.732971
[epoch1, step151]: loss 867.150696
[epoch1, step152]: loss 868.493225
[epoch1, step153]: loss 866.215454
[epoch1, step154]: loss 847.689148
[epoch1, step155]: loss 836.568542
[epoch1, step156]: loss 842.412598
[epoch1, step157]: loss 831.705444
[epoch1, step158]: loss 844.048035
[epoch1, step159]: loss 854.803101
[epoch1, step160]: loss 832.329346
[epoch1, step161]: loss 830.878784
[epoch1, step162]: loss 845.866455
[epoch1, step163]: loss 809.333008
[epoch1, step164]: loss 816.077637
[epoch1, step165]: loss 841.085388
[epoch1, step166]: loss 814.427368
[epoch1, step167]: loss 804.393860
[epoch1, step168]: loss 837.025696
[epoch1, step169]: loss 791.122620
[epoch1, step170]: loss 800.150146
[epoch1, step171]: loss 801.711487
[epoch1, step172]: loss 789.207703
[epoch1, step173]: loss 790.725098
[epoch1, step174]: loss 802.689819
[epoch1, step175]: loss 789.880066
[epoch1, step176]: loss 798.066467
[epoch1, step177]: loss 765.590576
[epoch1, step178]: loss 778.180298
[epoch1, step179]: loss 799.467773
[epoch1, step180]: loss 756.971436
[epoch1, step181]: loss 796.259827
[epoch1, step182]: loss 757.592834
[epoch1, step183]: loss 760.586670
[epoch1, step184]: loss 770.183594
[epoch1, step185]: loss 750.482300
[epoch1, step186]: loss 745.096313
[epoch1, step187]: loss 767.767700
[epoch1, step188]: loss 729.291748
[epoch1, step189]: loss 736.844666
[epoch1, step190]: loss 747.120605
[epoch1, step191]: loss 711.486389
[epoch1, step192]: loss 723.073364
[epoch1, step193]: loss 735.286804
[epoch1, step194]: loss 745.682068
[epoch1, step195]: loss 715.336487
[epoch1, step196]: loss 727.734131
[epoch1, step197]: loss 700.472839
[epoch1, step198]: loss 712.077148
[epoch1, step199]: loss 693.364929
[epoch1, step200]: loss 719.598083
[epoch1, step201]: loss 707.498718
[epoch1, step202]: loss 680.165344
[epoch1, step203]: loss 685.338135
[epoch1, step204]: loss 670.817017
[epoch1, step205]: loss 662.848816
[epoch1, step206]: loss 662.243347
[epoch1, step207]: loss 651.773987
[epoch1, step208]: loss 662.519409
[epoch1, step209]: loss 671.943909
[epoch1, step210]: loss 653.881348
[epoch1, step211]: loss 684.129639
[epoch1, step212]: loss 673.020447
[epoch1, step213]: loss 667.416443
[epoch1, step214]: loss 638.500000
[epoch1, step215]: loss 654.826355
[epoch1, step216]: loss 612.518005
[epoch1, step217]: loss 637.929260
[epoch1, step218]: loss 665.192322
[epoch1, step219]: loss 617.151794
[epoch1, step220]: loss 648.658508
[epoch1, step221]: loss 616.369446
[epoch1, step222]: loss 627.650818
[epoch1, step223]: loss 623.460022
[epoch1, step224]: loss 597.875610
[epoch1, step225]: loss 608.477600
[epoch1, step226]: loss 587.593567
[epoch1, step227]: loss 598.697205
[epoch1, step228]: loss 589.349792
[epoch1, step229]: loss 577.734741
[epoch1, step230]: loss 585.127930
[epoch1, step231]: loss 621.812744
[epoch1, step232]: loss 570.163635
[epoch1, step233]: loss 609.277771
[epoch1, step234]: loss 588.289062
[epoch1, step235]: loss 574.184692
[epoch1, step236]: loss 558.113159
[epoch1, step237]: loss 592.375732
[epoch1, step238]: loss 556.242493
[epoch1, step239]: loss 529.551392
[epoch1, step240]: loss 583.270081
[epoch1, step241]: loss 575.300781
[epoch1, step242]: loss 566.103943
[epoch1, step243]: loss 553.168762
[epoch1, step244]: loss 559.932861
[epoch1, step245]: loss 537.433777
[epoch1, step246]: loss 563.255188
[epoch1, step247]: loss 534.269958
[epoch1, step248]: loss 538.977905
[epoch1, step249]: loss 519.558411
[epoch1, step250]: loss 548.814148
[epoch1, step251]: loss 526.694885
[epoch1, step252]: loss 486.879120
[epoch1, step253]: loss 548.821045
[epoch1, step254]: loss 533.628540
[epoch1, step255]: loss 507.332520
[epoch1, step256]: loss 489.164978
[epoch1, step257]: loss 524.302124
[epoch1, step258]: loss 458.991119
[epoch1, step259]: loss 492.588562
[epoch1, step260]: loss 492.885345
[epoch1, step261]: loss 511.905304
[epoch1, step262]: loss 477.630585
[epoch1, step263]: loss 532.874329
[epoch1, step264]: loss 505.058868
[epoch1, step265]: loss 469.068237
[epoch1, step266]: loss 509.150574
[epoch1, step267]: loss 449.349060
[epoch1, step268]: loss 475.450531
[epoch1, step269]: loss 498.336731
[epoch1, step270]: loss 460.076019
[epoch1, step271]: loss 452.959625
[epoch1, step272]: loss 549.273499
[epoch1, step273]: loss 452.877808
[epoch1, step274]: loss 447.690796
[epoch1, step275]: loss 407.936707
[epoch1, step276]: loss 429.411072
[epoch1, step277]: loss 441.238922
[epoch1, step278]: loss 445.275848
[epoch1, step279]: loss 447.042511
[epoch1, step280]: loss 473.415436
[epoch1, step281]: loss 402.145111
[epoch1, step282]: loss 407.194580
[epoch1, step283]: loss 386.414673
[epoch1, step284]: loss 390.403900
[epoch1, step285]: loss 390.620544
[epoch1, step286]: loss 438.961853
[epoch1, step287]: loss 426.477234
[epoch1, step288]: loss 448.477234
[epoch1, step289]: loss 459.769623
[epoch1, step290]: loss 409.736023
[epoch1, step291]: loss 397.284515
[epoch1, step292]: loss 391.187164
[epoch1, step293]: loss 378.768433
[epoch1, step294]: loss 371.915863
[epoch1, step295]: loss 443.376068
[epoch1, step296]: loss 384.875671
[epoch1, step297]: loss 411.406921
[epoch1, step298]: loss 337.136047
[epoch1, step299]: loss 374.078888
[epoch1, step300]: loss 429.449371
[epoch1, step301]: loss 338.806549
[epoch1, step302]: loss 433.628174
[epoch1, step303]: loss 358.397125
[epoch1, step304]: loss 371.205750
[epoch1, step305]: loss 348.301117
[epoch1, step306]: loss 353.882965
[epoch1, step307]: loss 360.905212
[epoch1, step308]: loss 332.937500
[epoch1, step309]: loss 384.425537
[epoch1, step310]: loss 377.309753
[epoch1, step311]: loss 371.612701
[epoch1, step312]: loss 370.344208
[epoch1, step313]: loss 283.718689
[epoch1, step314]: loss 315.864380
[epoch1, step315]: loss 359.232483
[epoch1, step316]: loss 312.313171
[epoch1, step317]: loss 357.496918
[epoch1, step318]: loss 308.207458
[epoch1, step319]: loss 367.433258
[epoch1, step320]: loss 350.426331
[epoch1, step321]: loss 259.096252
[epoch1, step322]: loss 294.431213
[epoch1, step323]: loss 346.431000
[epoch1, step324]: loss 290.425171
[epoch1, step325]: loss 263.201782
[epoch1, step326]: loss 267.268341
[epoch1, step327]: loss 269.585114
[epoch1, step328]: loss 332.324982
[epoch1, step329]: loss 355.566864
[epoch1, step330]: loss 259.699768
[epoch1, step331]: loss 332.740509
[epoch1, step332]: loss 326.803955
[epoch1, step333]: loss 273.136536
[epoch1, step334]: loss 382.074646
[epoch1, step335]: loss 272.295044
[epoch1, step336]: loss 235.539017
[epoch1, step337]: loss 378.612396
[epoch1, step338]: loss 218.084076
[epoch1, step339]: loss 359.228424
[epoch1, step340]: loss 361.997223
[epoch1, step341]: loss 269.388000
[epoch1, step342]: loss 288.269714
[epoch1, step343]: loss 318.803162
[epoch1, step344]: loss 225.671631
[epoch1, step345]: loss 287.332794
[epoch1, step346]: loss 257.801849
[epoch1, step347]: loss 287.661865
[epoch1, step348]: loss 251.901581
[epoch1, step349]: loss 317.230957
[epoch1, step350]: loss 275.549103
[epoch1, step351]: loss 357.539551
[epoch1, step352]: loss 311.419769
[epoch1, step353]: loss 212.435516
[epoch1, step354]: loss 252.463150
[epoch1, step355]: loss 328.132324
[epoch1, step356]: loss 194.480820
[epoch1, step357]: loss 203.286575
[epoch1, step358]: loss 268.935394
[epoch1, step359]: loss 295.185852
[epoch1, step360]: loss 260.330688
[epoch1, step361]: loss 267.967987
[epoch1, step362]: loss 258.335602
[epoch1, step363]: loss 253.198700
[epoch1, step364]: loss 227.904434
[epoch1, step365]: loss 346.034760
[epoch1, step366]: loss 239.770386
[epoch1, step367]: loss 220.170654
[epoch1, step368]: loss 308.943756
[epoch1, step369]: loss 232.353073
[epoch1, step370]: loss 226.219894
[epoch1, step371]: loss 279.412079
[epoch1, step372]: loss 224.930374
[epoch1, step373]: loss 245.124878
[epoch1, step374]: loss 244.519119
[epoch1, step375]: loss 180.006805
[epoch1, step376]: loss 211.906250
[epoch1, step377]: loss 250.609985
[epoch1, step378]: loss 213.077454
[epoch1, step379]: loss 296.486511
[epoch1, step380]: loss 207.814316
[epoch1, step381]: loss 301.588257
[epoch1, step382]: loss 173.762955
[epoch1, step383]: loss 251.321045
[epoch1, step384]: loss 223.058441
[epoch1, step385]: loss 260.050385
[epoch1, step386]: loss 225.501404
[epoch1, step387]: loss 194.193146
[epoch1, step388]: loss 265.225281
[epoch1, step389]: loss 298.905762
[epoch1, step390]: loss 214.779419
[epoch1, step391]: loss 226.667160
[epoch1, step392]: loss 220.146133
[epoch1, step393]: loss 256.217682
[epoch1, step394]: loss 184.282013
[epoch1, step395]: loss 174.574951
[epoch1, step396]: loss 125.982590
[epoch1, step397]: loss 192.800964
[epoch1, step398]: loss 217.337234
[epoch1, step399]: loss 185.138290
[epoch1, step400]: loss 207.835419
[epoch1, step401]: loss 148.419983
[epoch1, step402]: loss 108.183342
[epoch1, step403]: loss 231.336151
[epoch1, step404]: loss 173.454666
[epoch1, step405]: loss 210.782913
[epoch1, step406]: loss 121.498627
[epoch1, step407]: loss 227.790985
[epoch1, step408]: loss 147.773590
[epoch1, step409]: loss 179.075974
[epoch1, step410]: loss 182.921249
[epoch1, step411]: loss 201.960144
[epoch1, step412]: loss 203.571533
[epoch1, step413]: loss 131.914856
[epoch1, step414]: loss 134.563492
[epoch1, step415]: loss 315.032684
[epoch1, step416]: loss 157.854889
[epoch1, step417]: loss 260.866150
[epoch1, step418]: loss 157.285919
[epoch1, step419]: loss 150.129913
[epoch1, step420]: loss 275.093567
[epoch1, step421]: loss 213.049057
[epoch1, step422]: loss 126.816444
[epoch1, step423]: loss 189.871231
[epoch1, step424]: loss 237.692276
[epoch1, step425]: loss 168.125031
[epoch1, step426]: loss 210.777512
[epoch1, step427]: loss 187.351883
[epoch1, step428]: loss 168.152863
[epoch1, step429]: loss 193.556503
[epoch1, step430]: loss 148.244705
[epoch1, step431]: loss 164.152084
[epoch1, step432]: loss 123.856964
[epoch1, step433]: loss 175.662796
[epoch1, step434]: loss 114.299873
[epoch1, step435]: loss 136.538742
[epoch1, step436]: loss 307.065399
[epoch1, step437]: loss 213.336868
[epoch1, step438]: loss 92.901581
[epoch1, step439]: loss 194.405777
[epoch1, step440]: loss 134.462814
[epoch1, step441]: loss 184.893066
[epoch1, step442]: loss 175.733948
[epoch1, step443]: loss 200.695129
[epoch1, step444]: loss 184.630707
[epoch1, step445]: loss 222.567719
[epoch1, step446]: loss 152.006744
[epoch1, step447]: loss 65.134552
[epoch1, step448]: loss 289.515015
[epoch1, step449]: loss 184.825455
[epoch1, step450]: loss 215.202698
[epoch1, step451]: loss 84.438148
[epoch1, step452]: loss 172.642166
[epoch1, step453]: loss 171.977524
[epoch1, step454]: loss 174.638947
[epoch1, step455]: loss 103.461845
[epoch1, step456]: loss 188.401993
[epoch1, step457]: loss 161.824936
[epoch1, step458]: loss 195.047623
[epoch1, step459]: loss 188.868759
[epoch1, step460]: loss 239.578674
[epoch1, step461]: loss 137.323410
[epoch1, step462]: loss 122.431786
[epoch1, step463]: loss 61.518402
[epoch1, step464]: loss 182.134552
[epoch1, step465]: loss 118.903473
[epoch1, step466]: loss 80.295174
[epoch1, step467]: loss 190.664429
[epoch1, step468]: loss 189.272614
[epoch1, step469]: loss 236.278046
[epoch1, step470]: loss 162.262436
[epoch1, step471]: loss 178.811005
[epoch1, step472]: loss 159.446259
[epoch1, step473]: loss 156.833206
[epoch1, step474]: loss 224.785507
[epoch1, step475]: loss 177.043381
[epoch1, step476]: loss 145.905594
[epoch1, step477]: loss 136.719406
[epoch1, step478]: loss 93.383293
[epoch1, step479]: loss 135.418594
[epoch1, step480]: loss 159.706100
[epoch1, step481]: loss 211.743118
[epoch1, step482]: loss 216.731323
[epoch1, step483]: loss 93.779755
[epoch1, step484]: loss 221.300125
[epoch1, step485]: loss 159.375549
[epoch1, step486]: loss 95.959801
[epoch1, step487]: loss 112.763603
[epoch1, step488]: loss 73.447189
[epoch1, step489]: loss 173.594757
[epoch1, step490]: loss 229.666656
[epoch1, step491]: loss 118.805183
[epoch1, step492]: loss 184.619888
[epoch1, step493]: loss 117.666061
[epoch1, step494]: loss 193.651001
[epoch1, step495]: loss 116.322250
[epoch1, step496]: loss 273.727539
[epoch1, step497]: loss 149.187546
[epoch1, step498]: loss 89.853668
[epoch1, step499]: loss 132.731934
[epoch1, step500]: loss 50.692051
[epoch1, step501]: loss 71.952049
[epoch1, step502]: loss 198.083435
[epoch1, step503]: loss 169.939758
[epoch1, step504]: loss 87.095444
[epoch1, step505]: loss 197.344299
[epoch1, step506]: loss 125.682617
[epoch1, step507]: loss 85.599091
[epoch1, step508]: loss 129.286285
[epoch1, step509]: loss 122.140015
[epoch1, step510]: loss 161.584625
[epoch1, step511]: loss 171.636948
[epoch1, step512]: loss 85.973183
[epoch1, step513]: loss 227.799225
[epoch1, step514]: loss 91.992035
[epoch1, step515]: loss 107.946335
[epoch1, step516]: loss 83.749641
[epoch1, step517]: loss 73.731667
[epoch1, step518]: loss 238.303665
[epoch1, step519]: loss 105.729362
[epoch1, step520]: loss 139.810852
[epoch1, step521]: loss 140.281265
[epoch1, step522]: loss 120.397339
[epoch1, step523]: loss 124.959953
[epoch1, step524]: loss 104.164429
[epoch1, step525]: loss 206.153168
[epoch1, step526]: loss 165.923431
[epoch1, step527]: loss 81.350975
[epoch1, step528]: loss 112.156502
[epoch1, step529]: loss 125.155502
[epoch1, step530]: loss 142.199829
[epoch1, step531]: loss 46.027706
[epoch1, step532]: loss 102.805077
[epoch1, step533]: loss 174.911362
[epoch1, step534]: loss 125.532600
[epoch1, step535]: loss 145.799454
[epoch1, step536]: loss 135.825089
[epoch1, step537]: loss 239.775894
[epoch1, step538]: loss 143.657867
[epoch1, step539]: loss 124.553490
[epoch1, step540]: loss 159.829254
[epoch1, step541]: loss 60.376396
[epoch1, step542]: loss 42.299820
[epoch1, step543]: loss 135.856552
[epoch1, step544]: loss 207.954880
[epoch1, step545]: loss 145.856033
[epoch1, step546]: loss 119.922157
[epoch1, step547]: loss 116.302986
[epoch1, step548]: loss 116.051552
[epoch1, step549]: loss 218.052338
[epoch1, step550]: loss 58.474930
[epoch1, step551]: loss 181.822144
[epoch1, step552]: loss 187.560654
[epoch1, step553]: loss 233.929871
[epoch1, step554]: loss 111.785919
[epoch1, step555]: loss 121.854271
[epoch1, step556]: loss 132.646866
[epoch1, step557]: loss 77.197701
[epoch1, step558]: loss 131.535049
[epoch1, step559]: loss 96.300652
[epoch1, step560]: loss 117.695282
[epoch1, step561]: loss 115.396194
[epoch1, step562]: loss 97.417381
[epoch1, step563]: loss 63.241226
[epoch1, step564]: loss 123.734016
[epoch1, step565]: loss 154.917252
[epoch1, step566]: loss 115.473274
[epoch1, step567]: loss 147.469833
[epoch1, step568]: loss 142.919342
[epoch1, step569]: loss 100.725784
[epoch1, step570]: loss 112.194954
[epoch1, step571]: loss 86.675652
[epoch1, step572]: loss 74.444572
[epoch1, step573]: loss 128.001175
[epoch1, step574]: loss 76.031998
[epoch1, step575]: loss 45.689983
[epoch1, step576]: loss 172.093994
[epoch1, step577]: loss 134.633575
[epoch1, step578]: loss 102.733131
[epoch1, step579]: loss 162.185165
[epoch1, step580]: loss 123.142448
[epoch1, step581]: loss 81.165497
[epoch1, step582]: loss 138.285828
[epoch1, step583]: loss 157.148712
[epoch1, step584]: loss 123.678795
[epoch1, step585]: loss 142.627808
[epoch1, step586]: loss 107.188416
[epoch1, step587]: loss 107.061813
[epoch1, step588]: loss 34.807144
[epoch1, step589]: loss 102.611214
[epoch1, step590]: loss 160.018509
[epoch1, step591]: loss 89.762306
[epoch1, step592]: loss 195.663086
[epoch1, step593]: loss 99.213280
[epoch1, step594]: loss 69.935738
[epoch1, step595]: loss 93.602272
[epoch1, step596]: loss 129.353912
[epoch1, step597]: loss 149.054062
[epoch1, step598]: loss 121.432739
[epoch1, step599]: loss 113.642143
[epoch1, step600]: loss 127.000458
[epoch1, step601]: loss 141.549286
[epoch1, step602]: loss 185.538177
[epoch1, step603]: loss 130.365799
[epoch1, step604]: loss 58.415745
[epoch1, step605]: loss 81.273376
[epoch1, step606]: loss 19.735777
[epoch1, step607]: loss 122.417366
[epoch1, step608]: loss 139.064484
[epoch1, step609]: loss 48.588661
[epoch1, step610]: loss 126.973717
[epoch1, step611]: loss 94.805527
[epoch1, step612]: loss 81.494911
[epoch1, step613]: loss 98.627342
[epoch1, step614]: loss 81.902992
[epoch1, step615]: loss 61.813496
[epoch1, step616]: loss 32.746956
[epoch1, step617]: loss 86.794609
[epoch1, step618]: loss 219.111038
[epoch1, step619]: loss 118.881271
[epoch1, step620]: loss 63.793549
[epoch1, step621]: loss 107.539795
[epoch1, step622]: loss 44.834377
[epoch1, step623]: loss 62.400192
[epoch1, step624]: loss 104.026726
[epoch1, step625]: loss 51.684605
[epoch1, step626]: loss 124.295494
[epoch1, step627]: loss 48.251507
[epoch1, step628]: loss 41.070766
[epoch1, step629]: loss 88.576492
[epoch1, step630]: loss 140.198563
[epoch1, step631]: loss 159.908051
[epoch1, step632]: loss 92.638626
[epoch1, step633]: loss 90.701263
[epoch1, step634]: loss 116.296272
[epoch1, step635]: loss 85.493095
[epoch1, step636]: loss 161.824539
[epoch1, step637]: loss 125.295471
[epoch1, step638]: loss 134.450226
[epoch1, step639]: loss 90.329163
[epoch1, step640]: loss 57.235676
[epoch1, step641]: loss 187.142899
[epoch1, step642]: loss 107.171318
[epoch1, step643]: loss 69.020744
[epoch1, step644]: loss 151.084930
[epoch1, step645]: loss 150.815796
[epoch1, step646]: loss 184.064453
[epoch1, step647]: loss 125.341980
[epoch1, step648]: loss 136.917023
[epoch1, step649]: loss 66.078094
[epoch1, step650]: loss 223.289490
[epoch1, step651]: loss 80.677963
[epoch1, step652]: loss 168.121643
[epoch1, step653]: loss 150.594025
[epoch1, step654]: loss 64.640800
[epoch1, step655]: loss 92.175629
[epoch1, step656]: loss 106.327019
[epoch1, step657]: loss 91.525879
[epoch1, step658]: loss 66.088409
[epoch1, step659]: loss 81.530533
[epoch1, step660]: loss 117.507187
[epoch1, step661]: loss 97.168915
[epoch1, step662]: loss 93.286163
[epoch1, step663]: loss 123.659195
[epoch1, step664]: loss 80.784798
[epoch1, step665]: loss 97.645798
[epoch1, step666]: loss 106.843964
[epoch1, step667]: loss 119.736137
[epoch1, step668]: loss 80.228745
[epoch1, step669]: loss 42.349686
[epoch1, step670]: loss 82.594910
[epoch1, step671]: loss 86.771843
[epoch1, step672]: loss 91.837898
[epoch1, step673]: loss 151.255966
[epoch1, step674]: loss 100.329659
[epoch1, step675]: loss 151.818954
[epoch1, step676]: loss 59.869259
[epoch1, step677]: loss 120.292923
[epoch1, step678]: loss 121.918709
[epoch1, step679]: loss 105.607903
[epoch1, step680]: loss 91.067307
[epoch1, step681]: loss 91.062981
[epoch1, step682]: loss 34.110126
[epoch1, step683]: loss 139.955948
[epoch1, step684]: loss 110.945480
[epoch1, step685]: loss 97.319130
[epoch1, step686]: loss 61.098747
[epoch1, step687]: loss 78.408142
[epoch1, step688]: loss 122.905815
[epoch1, step689]: loss 139.441223
[epoch1, step690]: loss 104.993561
[epoch1, step691]: loss 112.553154
[epoch1, step692]: loss 112.180168
[epoch1, step693]: loss 127.691971
[epoch1, step694]: loss 39.783325
[epoch1, step695]: loss 148.149551
[epoch1, step696]: loss 103.021950
[epoch1, step697]: loss 88.632088
[epoch1, step698]: loss 71.592026
[epoch1, step699]: loss 30.277386
[epoch1, step700]: loss 48.939346
[epoch1, step701]: loss 99.000687
[epoch1, step702]: loss 139.193390
[epoch1, step703]: loss 109.313713
[epoch1, step704]: loss 102.885925
[epoch1, step705]: loss 52.333138
[epoch1, step706]: loss 124.813164
[epoch1, step707]: loss 151.283615
[epoch1, step708]: loss 152.388214
[epoch1, step709]: loss 59.631645
[epoch1, step710]: loss 102.231537
[epoch1, step711]: loss 127.465820
[epoch1, step712]: loss 96.602982
[epoch1, step713]: loss 104.587341
[epoch1, step714]: loss 141.013367
[epoch1, step715]: loss 77.508888
[epoch1, step716]: loss 108.023628
[epoch1, step717]: loss 102.484100
[epoch1, step718]: loss 88.705452
[epoch1, step719]: loss 58.873707
[epoch1, step720]: loss 111.020744
[epoch1, step721]: loss 108.425385
[epoch1, step722]: loss 117.095108
[epoch1, step723]: loss 93.874901
[epoch1, step724]: loss 122.850136
[epoch1, step725]: loss 80.386497
[epoch1, step726]: loss 120.567757
[epoch1, step727]: loss 83.292900
[epoch1, step728]: loss 101.592102
[epoch1, step729]: loss 50.615646
[epoch1, step730]: loss 120.864273
[epoch1, step731]: loss 92.355331
[epoch1, step732]: loss 71.738396
[epoch1, step733]: loss 75.634819
[epoch1, step734]: loss 113.561066
[epoch1, step735]: loss 77.223534
[epoch1, step736]: loss 50.446518
[epoch1, step737]: loss 44.166904
[epoch1, step738]: loss 95.334038
[epoch1, step739]: loss 102.750832
[epoch1, step740]: loss 109.159958
[epoch1, step741]: loss 71.444870
[epoch1, step742]: loss 91.599281
[epoch1, step743]: loss 100.961624
[epoch1, step744]: loss 57.245117
[epoch1, step745]: loss 101.506775
[epoch1, step746]: loss 81.086487
[epoch1, step747]: loss 86.321373
[epoch1, step748]: loss 56.407005
[epoch1, step749]: loss 83.039513
[epoch1, step750]: loss 84.451683
[epoch1, step751]: loss 146.970627
[epoch1, step752]: loss 106.594460
[epoch1, step753]: loss 101.966721
[epoch1, step754]: loss 58.353832
[epoch1, step755]: loss 70.775070
[epoch1, step756]: loss 60.860367
[epoch1, step757]: loss 155.337830
[epoch1, step758]: loss 155.227875
[epoch1, step759]: loss 67.729713
[epoch1, step760]: loss 108.473587
[epoch1, step761]: loss 115.224678
[epoch1, step762]: loss 110.820824
[epoch1, step763]: loss 77.257767
[epoch1, step764]: loss 94.752304
[epoch1, step765]: loss 74.583626
[epoch1, step766]: loss 65.533089
[epoch1, step767]: loss 103.285744
[epoch1, step768]: loss 94.988289
[epoch1, step769]: loss 127.261932
[epoch1, step770]: loss 76.759056
[epoch1, step771]: loss 121.013130
[epoch1, step772]: loss 79.963074
[epoch1, step773]: loss 104.574249
[epoch1, step774]: loss 70.253456
[epoch1, step775]: loss 74.974312
[epoch1, step776]: loss 36.614418
[epoch1, step777]: loss 64.418022
[epoch1, step778]: loss 74.332741
[epoch1, step779]: loss 136.186386
[epoch1, step780]: loss 100.539314
[epoch1, step781]: loss 49.265072
[epoch1, step782]: loss 69.825859
[epoch1, step783]: loss 25.453547
[epoch1, step784]: loss 65.575180
[epoch1, step785]: loss 72.465332
[epoch1, step786]: loss 30.657997
[epoch1, step787]: loss 48.626625
[epoch1, step788]: loss 89.504837
[epoch1, step789]: loss 67.550430
[epoch1, step790]: loss 74.895592
[epoch1, step791]: loss 61.155518
[epoch1, step792]: loss 37.236832
[epoch1, step793]: loss 58.886360
[epoch1, step794]: loss 97.537247
[epoch1, step795]: loss 136.486786
[epoch1, step796]: loss 79.538956
[epoch1, step797]: loss 53.545475
[epoch1, step798]: loss 54.377945
[epoch1, step799]: loss 98.864044
[epoch1, step800]: loss 100.413994
[epoch1, step801]: loss 67.837585
[epoch1, step802]: loss 61.503914
[epoch1, step803]: loss 85.283501
[epoch1, step804]: loss 110.241425
[epoch1, step805]: loss 55.929100
[epoch1, step806]: loss 89.673134
[epoch1, step807]: loss 72.279137
[epoch1, step808]: loss 61.501263
[epoch1, step809]: loss 103.536316
[epoch1, step810]: loss 107.046227
[epoch1, step811]: loss 37.942028
[epoch1, step812]: loss 54.504875
[epoch1, step813]: loss 40.096222
[epoch1, step814]: loss 99.297630
[epoch1, step815]: loss 131.239227
[epoch1, step816]: loss 25.423065
[epoch1, step817]: loss 56.669746
[epoch1, step818]: loss 43.771854
[epoch1, step819]: loss 80.793839
[epoch1, step820]: loss 78.074394
[epoch1, step821]: loss 67.545647
[epoch1, step822]: loss 63.694077
[epoch1, step823]: loss 78.233765
[epoch1, step824]: loss 167.535950
[epoch1, step825]: loss 117.286644
[epoch1, step826]: loss 26.206045
[epoch1, step827]: loss 60.472015
[epoch1, step828]: loss 76.516014
[epoch1, step829]: loss 39.715141
[epoch1, step830]: loss 49.491123
[epoch1, step831]: loss 71.690002
[epoch1, step832]: loss 46.423668
[epoch1, step833]: loss 73.621643
[epoch1, step834]: loss 31.730164
[epoch1, step835]: loss 90.277443
[epoch1, step836]: loss 82.048401
[epoch1, step837]: loss 87.516785
[epoch1, step838]: loss 73.358025
[epoch1, step839]: loss 72.266899
[epoch1, step840]: loss 80.978188
[epoch1, step841]: loss 58.718132
[epoch1, step842]: loss 72.510757
[epoch1, step843]: loss 41.032578
[epoch1, step844]: loss 73.362534
[epoch1, step845]: loss 93.500900
[epoch1, step846]: loss 79.219231
[epoch1, step847]: loss 72.852234
[epoch1, step848]: loss 53.680805
[epoch1, step849]: loss 53.128212
[epoch1, step850]: loss 102.903694
[epoch1, step851]: loss 71.162338
[epoch1, step852]: loss 139.912277
[epoch1, step853]: loss 96.705498
[epoch1, step854]: loss 51.252876
[epoch1, step855]: loss 61.435177
[epoch1, step856]: loss 84.486717
[epoch1, step857]: loss 101.660347
[epoch1, step858]: loss 76.167252
[epoch1, step859]: loss 53.575531
[epoch1, step860]: loss 69.347610
[epoch1, step861]: loss 101.516266
[epoch1, step862]: loss 58.572308
[epoch1, step863]: loss 119.455292
[epoch1, step864]: loss 74.590126
[epoch1, step865]: loss 132.339294
[epoch1, step866]: loss 93.587143
[epoch1, step867]: loss 76.593948
[epoch1, step868]: loss 67.342918
[epoch1, step869]: loss 52.060593
[epoch1, step870]: loss 84.623138
[epoch1, step871]: loss 38.034908
[epoch1, step872]: loss 56.054218
[epoch1, step873]: loss 83.326324
[epoch1, step874]: loss 95.146591
[epoch1, step875]: loss 27.710815
[epoch1, step876]: loss 25.708763
[epoch1, step877]: loss 99.689644
[epoch1, step878]: loss 121.519028
[epoch1, step879]: loss 54.748589
[epoch1, step880]: loss 95.097343
[epoch1, step881]: loss 79.357834
[epoch1, step882]: loss 112.959625
[epoch1, step883]: loss 77.692795
[epoch1, step884]: loss 86.916077
[epoch1, step885]: loss 61.322083
[epoch1, step886]: loss 62.814560
[epoch1, step887]: loss 126.815536
[epoch1, step888]: loss 35.052711
[epoch1, step889]: loss 70.196991
[epoch1, step890]: loss 84.075806
[epoch1, step891]: loss 105.817017
[epoch1, step892]: loss 64.012405
[epoch1, step893]: loss 66.279991
[epoch1, step894]: loss 139.104691
[epoch1, step895]: loss 79.135544
[epoch1, step896]: loss 90.500763
[epoch1, step897]: loss 65.851593
[epoch1, step898]: loss 66.183990
[epoch1, step899]: loss 48.928890
[epoch1, step900]: loss 30.545263
[epoch1, step901]: loss 105.821686
[epoch1, step902]: loss 112.747650
[epoch1, step903]: loss 66.676941
[epoch1, step904]: loss 64.683426
[epoch1, step905]: loss 97.185738
[epoch1, step906]: loss 71.676582
[epoch1, step907]: loss 120.105011
[epoch1, step908]: loss 64.650108
[epoch1, step909]: loss 72.921425
[epoch1, step910]: loss 79.559616
[epoch1, step911]: loss 61.085438
[epoch1, step912]: loss 42.064514
[epoch1, step913]: loss 40.516876
[epoch1, step914]: loss 45.866917
[epoch1, step915]: loss 73.578865
[epoch1, step916]: loss 97.857033
[epoch1, step917]: loss 88.790382
[epoch1, step918]: loss 62.757774
[epoch1, step919]: loss 87.439560
[epoch1, step920]: loss 85.582214
[epoch1, step921]: loss 75.067703
[epoch1, step922]: loss 94.851852
[epoch1, step923]: loss 123.372505
[epoch1, step924]: loss 62.114273
[epoch1, step925]: loss 115.734459
[epoch1, step926]: loss 88.863701
[epoch1, step927]: loss 111.987480
[epoch1, step928]: loss 55.797134
[epoch1, step929]: loss 50.629070
[epoch1, step930]: loss 42.900860
[epoch1, step931]: loss 54.817253
[epoch1, step932]: loss 73.888924
[epoch1, step933]: loss 111.649071
[epoch1, step934]: loss 46.102493
[epoch1, step935]: loss 68.099922
[epoch1, step936]: loss 15.857709
[epoch1, step937]: loss 60.894672
[epoch1, step938]: loss 82.432243
[epoch1, step939]: loss 86.773857
[epoch1, step940]: loss 71.982361
[epoch1, step941]: loss 54.836487
[epoch1, step942]: loss 85.208221
[epoch1, step943]: loss 54.610779
[epoch1, step944]: loss 79.728378
[epoch1, step945]: loss 125.066185
[epoch1, step946]: loss 97.638176
[epoch1, step947]: loss 75.940987
[epoch1, step948]: loss 74.564217
[epoch1, step949]: loss 94.235870
[epoch1, step950]: loss 73.284874
[epoch1, step951]: loss 92.623238
[epoch1, step952]: loss 50.381184
[epoch1, step953]: loss 30.575129
[epoch1, step954]: loss 117.114265
[epoch1, step955]: loss 111.290794
[epoch1, step956]: loss 27.875807
[epoch1, step957]: loss 91.161797
[epoch1, step958]: loss 149.668060
[epoch1, step959]: loss 69.435440
[epoch1, step960]: loss 58.930908
[epoch1, step961]: loss 35.066559
[epoch1, step962]: loss 58.422966
[epoch1, step963]: loss 38.526085
[epoch1, step964]: loss 72.821228
[epoch1, step965]: loss 48.829807
[epoch1, step966]: loss 38.522125
[epoch1, step967]: loss 86.855682
[epoch1, step968]: loss 58.540386
[epoch1, step969]: loss 51.662678
[epoch1, step970]: loss 75.708595
[epoch1, step971]: loss 148.773972
[epoch1, step972]: loss 76.485916
[epoch1, step973]: loss 57.672081
[epoch1, step974]: loss 31.437176
[epoch1, step975]: loss 62.306412
[epoch1, step976]: loss 66.355019
[epoch1, step977]: loss 138.457825
[epoch1, step978]: loss 83.616844
[epoch1, step979]: loss 135.318344
[epoch1, step980]: loss 39.617832
[epoch1, step981]: loss 111.639801
[epoch1, step982]: loss 95.831055
[epoch1, step983]: loss 62.221615
[epoch1, step984]: loss 102.441010
[epoch1, step985]: loss 110.216904
[epoch1, step986]: loss 91.704414
[epoch1, step987]: loss 55.669437
[epoch1, step988]: loss 90.003540
[epoch1, step989]: loss 93.413086
[epoch1, step990]: loss 62.715275
[epoch1, step991]: loss 50.979923
[epoch1, step992]: loss 51.324970
[epoch1, step993]: loss 88.655792
[epoch1, step994]: loss 101.321587
[epoch1, step995]: loss 38.382038
[epoch1, step996]: loss 56.808449
[epoch1, step997]: loss 32.683441
[epoch1, step998]: loss 45.102379
[epoch1, step999]: loss 63.529297
[epoch1, step1000]: loss 72.965561
[epoch1, step1001]: loss 31.992828
[epoch1, step1002]: loss 101.184853
[epoch1, step1003]: loss 75.086472
[epoch1, step1004]: loss 96.241623
[epoch1, step1005]: loss 136.820190
[epoch1, step1006]: loss 93.683075
[epoch1, step1007]: loss 53.582401
[epoch1, step1008]: loss 79.023125
[epoch1, step1009]: loss 133.866943
[epoch1, step1010]: loss 72.520699
[epoch1, step1011]: loss 50.282639
[epoch1, step1012]: loss 68.775482
[epoch1, step1013]: loss 94.131020
[epoch1, step1014]: loss 66.140755
[epoch1, step1015]: loss 104.153549
[epoch1, step1016]: loss 68.115074
[epoch1, step1017]: loss 68.217880
[epoch1, step1018]: loss 50.075802
[epoch1, step1019]: loss 78.683563
[epoch1, step1020]: loss 52.556969
[epoch1, step1021]: loss 42.949196
[epoch1, step1022]: loss 56.208961
[epoch1, step1023]: loss 69.174545
[epoch1, step1024]: loss 55.873634
[epoch1, step1025]: loss 53.704849
[epoch1, step1026]: loss 56.086987
[epoch1, step1027]: loss 92.773872
[epoch1, step1028]: loss 26.313560
[epoch1, step1029]: loss 69.999161
[epoch1, step1030]: loss 101.654190
[epoch1, step1031]: loss 17.458414
[epoch1, step1032]: loss 58.761868
[epoch1, step1033]: loss 48.036938
[epoch1, step1034]: loss 70.312965
[epoch1, step1035]: loss 43.239719
[epoch1, step1036]: loss 51.067047
[epoch1, step1037]: loss 55.041565
[epoch1, step1038]: loss 22.428061
[epoch1, step1039]: loss 102.475296
[epoch1, step1040]: loss 36.061436
[epoch1, step1041]: loss 41.940720
[epoch1, step1042]: loss 48.537010
[epoch1, step1043]: loss 114.760666
[epoch1, step1044]: loss 64.324501
[epoch1, step1045]: loss 65.516724
[epoch1, step1046]: loss 74.951286
[epoch1, step1047]: loss 86.506950
[epoch1, step1048]: loss 107.815750
[epoch1, step1049]: loss 68.003433
[epoch1, step1050]: loss 53.914528
[epoch1, step1051]: loss 58.747829
[epoch1, step1052]: loss 94.182343
[epoch1, step1053]: loss 57.512867
[epoch1, step1054]: loss 89.898018
[epoch1, step1055]: loss 88.802040
[epoch1, step1056]: loss 60.467571
[epoch1, step1057]: loss 71.264740
[epoch1, step1058]: loss 22.033237
[epoch1, step1059]: loss 70.902161
[epoch1, step1060]: loss 60.906677
[epoch1, step1061]: loss 14.584944
[epoch1, step1062]: loss 75.079460
[epoch1, step1063]: loss 76.715874
[epoch1, step1064]: loss 111.517883
[epoch1, step1065]: loss 65.233238
[epoch1, step1066]: loss 107.140945
[epoch1, step1067]: loss 113.697517
[epoch1, step1068]: loss 81.832024
[epoch1, step1069]: loss 33.181671
[epoch1, step1070]: loss 56.867325
[epoch1, step1071]: loss 41.166908
[epoch1, step1072]: loss 53.703587
[epoch1, step1073]: loss 64.152672
[epoch1, step1074]: loss 71.491463
[epoch1, step1075]: loss 86.836708
[epoch1, step1076]: loss 90.628815
[epoch1, step1077]: loss 94.516190
[epoch1, step1078]: loss 103.278671
[epoch1, step1079]: loss 61.626675
[epoch1, step1080]: loss 63.557499
[epoch1, step1081]: loss 60.499474
[epoch1, step1082]: loss 123.088905
[epoch1, step1083]: loss 60.187935
[epoch1, step1084]: loss 90.928360
[epoch1, step1085]: loss 74.646034
[epoch1, step1086]: loss 75.504471
[epoch1, step1087]: loss 41.757988
[epoch1, step1088]: loss 59.921947
[epoch1, step1089]: loss 94.874992
[epoch1, step1090]: loss 50.487320
[epoch1, step1091]: loss 85.076363
[epoch1, step1092]: loss 72.859436
[epoch1, step1093]: loss 52.735069
[epoch1, step1094]: loss 64.971313
[epoch1, step1095]: loss 108.422447
[epoch1, step1096]: loss 67.916473
[epoch1, step1097]: loss 49.880585
[epoch1, step1098]: loss 99.143524
[epoch1, step1099]: loss 32.338688
[epoch1, step1100]: loss 53.031853
[epoch1, step1101]: loss 118.517090
[epoch1, step1102]: loss 64.040222
[epoch1, step1103]: loss 81.500458
[epoch1, step1104]: loss 47.116375
[epoch1, step1105]: loss 39.751724
[epoch1, step1106]: loss 105.903816
[epoch1, step1107]: loss 112.040283
[epoch1, step1108]: loss 50.782707
[epoch1, step1109]: loss 83.209000
[epoch1, step1110]: loss 43.704746
[epoch1, step1111]: loss 57.970058
[epoch1, step1112]: loss 55.999294
[epoch1, step1113]: loss 36.834480
[epoch1, step1114]: loss 45.204144
[epoch1, step1115]: loss 58.098801
[epoch1, step1116]: loss 83.796593
[epoch1, step1117]: loss 38.706207
[epoch1, step1118]: loss 86.633064
[epoch1, step1119]: loss 69.287781
[epoch1, step1120]: loss 70.373383
[epoch1, step1121]: loss 91.276474
[epoch1, step1122]: loss 85.551483
[epoch1, step1123]: loss 45.138020
[epoch1, step1124]: loss 35.117401
[epoch1, step1125]: loss 93.705902
[epoch1, step1126]: loss 44.370255
[epoch1, step1127]: loss 37.588245
[epoch1, step1128]: loss 78.913490
[epoch1, step1129]: loss 52.446663
[epoch1, step1130]: loss 75.249191
[epoch1, step1131]: loss 79.806564
[epoch1, step1132]: loss 44.108528
[epoch1, step1133]: loss 77.621605
[epoch1, step1134]: loss 41.651913
[epoch1, step1135]: loss 43.997932
[epoch1, step1136]: loss 95.312012
[epoch1, step1137]: loss 48.452793
[epoch1, step1138]: loss 19.174637
[epoch1, step1139]: loss 51.775372
[epoch1, step1140]: loss 33.027580
[epoch1, step1141]: loss 76.561295
[epoch1, step1142]: loss 73.378395
[epoch1, step1143]: loss 118.610641
[epoch1, step1144]: loss 80.073151
[epoch1, step1145]: loss 53.686382
[epoch1, step1146]: loss 20.626482
[epoch1, step1147]: loss 50.861618
[epoch1, step1148]: loss 36.325672
[epoch1, step1149]: loss 48.444691
[epoch1, step1150]: loss 61.584518
[epoch1, step1151]: loss 37.971416
[epoch1, step1152]: loss 40.264645
[epoch1, step1153]: loss 72.964485
[epoch1, step1154]: loss 90.163948
[epoch1, step1155]: loss 55.067696
[epoch1, step1156]: loss 102.877167
[epoch1, step1157]: loss 31.656601
[epoch1, step1158]: loss 84.280830
[epoch1, step1159]: loss 45.571049
[epoch1, step1160]: loss 47.684399
[epoch1, step1161]: loss 10.983356
[epoch1, step1162]: loss 55.661621
[epoch1, step1163]: loss 86.104836
[epoch1, step1164]: loss 82.969116
[epoch1, step1165]: loss 42.556049
[epoch1, step1166]: loss 82.405586
[epoch1, step1167]: loss 34.453175
[epoch1, step1168]: loss 86.936638
[epoch1, step1169]: loss 72.164825
[epoch1, step1170]: loss 109.561714
[epoch1, step1171]: loss 83.547058
[epoch1, step1172]: loss 89.734612
[epoch1, step1173]: loss 69.869560
[epoch1, step1174]: loss 79.589684
[epoch1, step1175]: loss 82.420944
[epoch1, step1176]: loss 92.303596
[epoch1, step1177]: loss 57.494675
[epoch1, step1178]: loss 92.949348
[epoch1, step1179]: loss 59.281780
[epoch1, step1180]: loss 85.914970
[epoch1, step1181]: loss 100.864510
[epoch1, step1182]: loss 79.272934
[epoch1, step1183]: loss 51.494465
[epoch1, step1184]: loss 126.951706
[epoch1, step1185]: loss 41.500637
[epoch1, step1186]: loss 64.263008
[epoch1, step1187]: loss 55.198093
[epoch1, step1188]: loss 58.121159
[epoch1, step1189]: loss 53.176300
[epoch1, step1190]: loss 29.655174
[epoch1, step1191]: loss 84.600845
[epoch1, step1192]: loss 79.318428
[epoch1, step1193]: loss 58.763653
[epoch1, step1194]: loss 105.792419
[epoch1, step1195]: loss 73.536263
[epoch1, step1196]: loss 71.119461
[epoch1, step1197]: loss 41.560425
[epoch1, step1198]: loss 47.455276
[epoch1, step1199]: loss 42.516277
[epoch1, step1200]: loss 70.280716
[epoch1, step1201]: loss 107.407356
[epoch1, step1202]: loss 73.291504
[epoch1, step1203]: loss 47.747517
[epoch1, step1204]: loss 44.006321
[epoch1, step1205]: loss 47.123787
[epoch1, step1206]: loss 122.934204
[epoch1, step1207]: loss 96.310799
[epoch1, step1208]: loss 71.697838
[epoch1, step1209]: loss 80.803513
[epoch1, step1210]: loss 82.208328
[epoch1, step1211]: loss 109.108932
[epoch1, step1212]: loss 116.890900
[epoch1, step1213]: loss 54.170319
[epoch1, step1214]: loss 91.898796
[epoch1, step1215]: loss 116.577385
[epoch1, step1216]: loss 35.141472
[epoch1, step1217]: loss 127.581161
[epoch1, step1218]: loss 96.353081
[epoch1, step1219]: loss 48.331356
[epoch1, step1220]: loss 46.417992
[epoch1, step1221]: loss 24.654064
[epoch1, step1222]: loss 79.803284
[epoch1, step1223]: loss 52.782784
[epoch1, step1224]: loss 43.198982
[epoch1, step1225]: loss 78.117615
[epoch1, step1226]: loss 139.987137
[epoch1, step1227]: loss 38.136501
[epoch1, step1228]: loss 58.075012
[epoch1, step1229]: loss 58.577332
[epoch1, step1230]: loss 40.126915
[epoch1, step1231]: loss 65.529289
[epoch1, step1232]: loss 27.460945
[epoch1, step1233]: loss 77.707939
[epoch1, step1234]: loss 50.323254
[epoch1, step1235]: loss 17.635681
[epoch1, step1236]: loss 23.384098
[epoch1, step1237]: loss 56.840878
[epoch1, step1238]: loss 88.459702
[epoch1, step1239]: loss 54.909985
[epoch1, step1240]: loss 34.225147
[epoch1, step1241]: loss 34.036945
[epoch1, step1242]: loss 60.026829
[epoch1, step1243]: loss 56.318935
[epoch1, step1244]: loss 81.766312
[epoch1, step1245]: loss 104.624992
[epoch1, step1246]: loss 58.404358
[epoch1, step1247]: loss 53.047558
[epoch1, step1248]: loss 65.420189
[epoch1, step1249]: loss 47.143646
[epoch1, step1250]: loss 50.342293
[epoch1, step1251]: loss 53.932606
[epoch1, step1252]: loss 75.229027
[epoch1, step1253]: loss 63.468853
[epoch1, step1254]: loss 80.737785
[epoch1, step1255]: loss 65.439194
[epoch1, step1256]: loss 47.522141
[epoch1, step1257]: loss 66.354820
[epoch1, step1258]: loss 24.876450
[epoch1, step1259]: loss 35.280441
[epoch1, step1260]: loss 98.076057
[epoch1, step1261]: loss 134.146561
[epoch1, step1262]: loss 62.461681
[epoch1, step1263]: loss 54.890064
[epoch1, step1264]: loss 44.845905
[epoch1, step1265]: loss 31.003428
[epoch1, step1266]: loss 82.829224
[epoch1, step1267]: loss 81.933746
[epoch1, step1268]: loss 62.177731
[epoch1, step1269]: loss 60.117500
[epoch1, step1270]: loss 58.678173
[epoch1, step1271]: loss 27.684368
[epoch1, step1272]: loss 61.123840
[epoch1, step1273]: loss 62.938606
[epoch1, step1274]: loss 65.752274
[epoch1, step1275]: loss 63.198769
[epoch1, step1276]: loss 32.175491
[epoch1, step1277]: loss 84.585556
[epoch1, step1278]: loss 96.336411
[epoch1, step1279]: loss 76.609642
[epoch1, step1280]: loss 39.609333
[epoch1, step1281]: loss 25.922949
[epoch1, step1282]: loss 64.179070
[epoch1, step1283]: loss 46.820389
[epoch1, step1284]: loss 90.029366
[epoch1, step1285]: loss 95.084152
[epoch1, step1286]: loss 47.735298
[epoch1, step1287]: loss 32.255169
[epoch1, step1288]: loss 66.746208
[epoch1, step1289]: loss 73.256660
[epoch1, step1290]: loss 69.299377
[epoch1, step1291]: loss 36.797279
[epoch1, step1292]: loss 74.916763
[epoch1, step1293]: loss 51.520580
[epoch1, step1294]: loss 76.613556
[epoch1, step1295]: loss 33.512321
[epoch1, step1296]: loss 37.731853
[epoch1, step1297]: loss 46.222664
[epoch1, step1298]: loss 56.763859
[epoch1, step1299]: loss 49.086353
[epoch1, step1300]: loss 11.162628
[epoch1, step1301]: loss 45.630341
[epoch1, step1302]: loss 59.816437
[epoch1, step1303]: loss 91.987671
[epoch1, step1304]: loss 81.071617
[epoch1, step1305]: loss 85.810623
[epoch1, step1306]: loss 50.167137
[epoch1, step1307]: loss 50.528790
[epoch1, step1308]: loss 3.152507
[epoch1, step1309]: loss 48.731525
[epoch1, step1310]: loss 53.869167
[epoch1, step1311]: loss 87.138649
[epoch1, step1312]: loss 107.501335
[epoch1, step1313]: loss 68.211807
[epoch1, step1314]: loss 76.816780
[epoch1, step1315]: loss 16.471636
[epoch1, step1316]: loss 48.129902
[epoch1, step1317]: loss 109.699203
[epoch1, step1318]: loss 96.516571
[epoch1, step1319]: loss 80.307991
[epoch1, step1320]: loss 66.340302
[epoch1, step1321]: loss 94.777756
[epoch1, step1322]: loss 60.015434
[epoch1, step1323]: loss 63.588017
[epoch1, step1324]: loss 29.723520
[epoch1, step1325]: loss 115.293388
[epoch1, step1326]: loss 63.567245
[epoch1, step1327]: loss 85.665970
[epoch1, step1328]: loss 15.807165
[epoch1, step1329]: loss 62.731327
[epoch1, step1330]: loss 70.915123
[epoch1, step1331]: loss 103.828438
[epoch1, step1332]: loss 21.809502
[epoch1, step1333]: loss 61.989586
[epoch1, step1334]: loss 47.916641
[epoch1, step1335]: loss 25.528179
[epoch1, step1336]: loss 86.211227
[epoch1, step1337]: loss 70.655777
[epoch1, step1338]: loss 43.706436
[epoch1, step1339]: loss 46.066280
[epoch1, step1340]: loss 72.311913
[epoch1, step1341]: loss 96.296951
[epoch1, step1342]: loss 68.411613
[epoch1, step1343]: loss 28.980494
[epoch1, step1344]: loss 50.266033
[epoch1, step1345]: loss 83.269753
[epoch1, step1346]: loss 42.165565
[epoch1, step1347]: loss 92.747307
[epoch1, step1348]: loss 19.381104
[epoch1, step1349]: loss 109.010643
[epoch1, step1350]: loss 79.074516
[epoch1, step1351]: loss 19.095150
[epoch1, step1352]: loss 62.896156
[epoch1, step1353]: loss 29.317904
[epoch1, step1354]: loss 32.976929
[epoch1, step1355]: loss 46.134430
[epoch1, step1356]: loss 53.738655
[epoch1, step1357]: loss 59.044319
[epoch1, step1358]: loss 34.091213
[epoch1, step1359]: loss 66.012016
[epoch1, step1360]: loss 32.840485
[epoch1, step1361]: loss 64.771011
[epoch1, step1362]: loss 49.091835
[epoch1, step1363]: loss 35.550846
[epoch1, step1364]: loss 75.869484
[epoch1, step1365]: loss 54.175167
[epoch1, step1366]: loss 25.894428
[epoch1, step1367]: loss 39.902435
[epoch1, step1368]: loss 39.602303
[epoch1, step1369]: loss 60.291622
[epoch1, step1370]: loss 57.242348
[epoch1, step1371]: loss 47.590672
[epoch1, step1372]: loss 28.063929
[epoch1, step1373]: loss 21.530945
[epoch1, step1374]: loss 52.279991
[epoch1, step1375]: loss 79.819077
[epoch1, step1376]: loss 45.885052
[epoch1, step1377]: loss 34.896721
[epoch1, step1378]: loss 26.453325
[epoch1, step1379]: loss 36.526794
[epoch1, step1380]: loss 63.197716
[epoch1, step1381]: loss 80.852722
[epoch1, step1382]: loss 22.181597
[epoch1, step1383]: loss 63.205788
[epoch1, step1384]: loss 56.128078
[epoch1, step1385]: loss 42.338306
[epoch1, step1386]: loss 63.671818
[epoch1, step1387]: loss 49.334908
[epoch1, step1388]: loss 81.731445
[epoch1, step1389]: loss 29.970819
[epoch1, step1390]: loss 45.989410
[epoch1, step1391]: loss 18.324858
[epoch1, step1392]: loss 21.333719
[epoch1, step1393]: loss 60.692028
[epoch1, step1394]: loss 79.297050
[epoch1, step1395]: loss 42.040371
[epoch1, step1396]: loss 72.616730
[epoch1, step1397]: loss 47.411678
[epoch1, step1398]: loss 96.873322
[epoch1, step1399]: loss 113.717453
[epoch1, step1400]: loss 69.322441
[epoch1, step1401]: loss 58.110741
[epoch1, step1402]: loss 50.980301
[epoch1, step1403]: loss 98.364143
[epoch1, step1404]: loss 51.084419
[epoch1, step1405]: loss 30.006273
[epoch1, step1406]: loss 48.457108
[epoch1, step1407]: loss 129.188004
[epoch1, step1408]: loss 55.842834
[epoch1, step1409]: loss 38.337749
[epoch1, step1410]: loss 10.538477
[epoch1, step1411]: loss 48.046101
[epoch1, step1412]: loss 55.790691
[epoch1, step1413]: loss 35.573914
[epoch1, step1414]: loss 83.573700
[epoch1, step1415]: loss 50.615936
[epoch1, step1416]: loss 35.288311
[epoch1, step1417]: loss 74.638504
[epoch1, step1418]: loss 69.018196
[epoch1, step1419]: loss 73.541908
[epoch1, step1420]: loss 44.241894
[epoch1, step1421]: loss 24.851284
[epoch1, step1422]: loss 75.651909
[epoch1, step1423]: loss 22.546591
[epoch1, step1424]: loss 91.355507
[epoch1, step1425]: loss 60.615818
[epoch1, step1426]: loss 79.312485
[epoch1, step1427]: loss 95.385315
[epoch1, step1428]: loss 47.083328
[epoch1, step1429]: loss 39.827442
[epoch1, step1430]: loss 54.616055
[epoch1, step1431]: loss 70.801392
[epoch1, step1432]: loss 41.974174
[epoch1, step1433]: loss 75.585999
[epoch1, step1434]: loss 45.446648
[epoch1, step1435]: loss 56.650253
[epoch1, step1436]: loss 56.582809
[epoch1, step1437]: loss 74.547287
[epoch1, step1438]: loss 45.879887
[epoch1, step1439]: loss 81.611015
[epoch1, step1440]: loss 70.170067
[epoch1, step1441]: loss 65.572617
[epoch1, step1442]: loss 69.378113
[epoch1, step1443]: loss 64.398079
[epoch1, step1444]: loss 52.218082
[epoch1, step1445]: loss 41.989029
[epoch1, step1446]: loss 66.229485
[epoch1, step1447]: loss 87.093018
[epoch1, step1448]: loss 92.095695
[epoch1, step1449]: loss 27.613007
[epoch1, step1450]: loss 105.442314
[epoch1, step1451]: loss 50.801899
[epoch1, step1452]: loss 69.018303
[epoch1, step1453]: loss 61.687294
[epoch1, step1454]: loss 9.867922
[epoch1, step1455]: loss 53.000416
[epoch1, step1456]: loss 60.065685
[epoch1, step1457]: loss 52.398792
[epoch1, step1458]: loss 87.109947
[epoch1, step1459]: loss 107.342903
[epoch1, step1460]: loss 58.294640
[epoch1, step1461]: loss 74.118744
[epoch1, step1462]: loss 43.330124
[epoch1, step1463]: loss 50.707813
[epoch1, step1464]: loss 9.030462
[epoch1, step1465]: loss 95.807404
[epoch1, step1466]: loss 68.880539
[epoch1, step1467]: loss 5.500914
[epoch1, step1468]: loss 34.406467
[epoch1, step1469]: loss 80.843407
[epoch1, step1470]: loss 29.618114
[epoch1, step1471]: loss 77.489708
[epoch1, step1472]: loss 73.894516
[epoch1, step1473]: loss 22.237562
[epoch1, step1474]: loss 44.143295
[epoch1, step1475]: loss 59.638149
[epoch1, step1476]: loss 58.785919
[epoch1, step1477]: loss 47.398766
[epoch1, step1478]: loss 22.854254
[epoch1, step1479]: loss 108.335938
[epoch1, step1480]: loss 48.080353
[epoch1, step1481]: loss 75.162758
[epoch1, step1482]: loss 30.811380
[epoch1, step1483]: loss 65.939941
[epoch1, step1484]: loss 64.625938
[epoch1, step1485]: loss 65.009338
[epoch1, step1486]: loss 36.308117
[epoch1, step1487]: loss 48.251213
[epoch1, step1488]: loss 78.218002
[epoch1, step1489]: loss 20.981020
[epoch1, step1490]: loss 22.327444
[epoch1, step1491]: loss 62.302570
[epoch1, step1492]: loss 43.745991
[epoch1, step1493]: loss 73.891731
[epoch1, step1494]: loss 76.833206
[epoch1, step1495]: loss 27.294044
[epoch1, step1496]: loss 70.515945
[epoch1, step1497]: loss 37.596657
[epoch1, step1498]: loss 73.802956
[epoch1, step1499]: loss 31.283909
[epoch1, step1500]: loss 17.303701
[epoch1, step1501]: loss 41.369385
[epoch1, step1502]: loss 18.623104
[epoch1, step1503]: loss 61.813755
[epoch1, step1504]: loss 74.647995
[epoch1, step1505]: loss 63.430454
[epoch1, step1506]: loss 40.800655
[epoch1, step1507]: loss 96.346336
[epoch1, step1508]: loss 76.276672
[epoch1, step1509]: loss 54.137749
[epoch1, step1510]: loss 72.052414
[epoch1, step1511]: loss 68.849205
[epoch1, step1512]: loss 65.386070
[epoch1, step1513]: loss 59.175224
[epoch1, step1514]: loss 81.058014
[epoch1, step1515]: loss 65.987068
[epoch1, step1516]: loss 36.710987
[epoch1, step1517]: loss 25.596041
[epoch1, step1518]: loss 73.255241
[epoch1, step1519]: loss 52.021049
[epoch1, step1520]: loss 68.271065
[epoch1, step1521]: loss 5.342420
[epoch1, step1522]: loss 52.587158
[epoch1, step1523]: loss 96.254585
[epoch1, step1524]: loss 89.234627
[epoch1, step1525]: loss 14.992802
[epoch1, step1526]: loss 64.814751
[epoch1, step1527]: loss 119.451431
[epoch1, step1528]: loss 56.618874
[epoch1, step1529]: loss 82.676582
[epoch1, step1530]: loss 115.891159
[epoch1, step1531]: loss 63.438786
[epoch1, step1532]: loss 57.722984
[epoch1, step1533]: loss 73.947121
[epoch1, step1534]: loss 61.788452
[epoch1, step1535]: loss 86.506950
[epoch1, step1536]: loss 62.246170
[epoch1, step1537]: loss 58.698895
[epoch1, step1538]: loss 56.761917
[epoch1, step1539]: loss 19.506399
[epoch1, step1540]: loss 28.128805
[epoch1, step1541]: loss 37.618443
[epoch1, step1542]: loss 48.150940
[epoch1, step1543]: loss 39.379494
[epoch1, step1544]: loss 50.151779
[epoch1, step1545]: loss 82.511124
[epoch1, step1546]: loss 75.186424
[epoch1, step1547]: loss 76.067253
[epoch1, step1548]: loss 50.493877
[epoch1, step1549]: loss 102.600487
[epoch1, step1550]: loss 104.727409
[epoch1, step1551]: loss 55.601254
[epoch1, step1552]: loss 31.344019
[epoch1, step1553]: loss 21.082748
[epoch1, step1554]: loss 38.296669
[epoch1, step1555]: loss 41.360691
[epoch1, step1556]: loss 50.334602
[epoch1, step1557]: loss 69.931900
[epoch1, step1558]: loss 89.705772
[epoch1, step1559]: loss 26.231928
[epoch1, step1560]: loss 77.464149
[epoch1, step1561]: loss 50.691650
[epoch1, step1562]: loss 42.634632
[epoch1, step1563]: loss 23.794483
[epoch1, step1564]: loss 65.882500
[epoch1, step1565]: loss 27.518587
[epoch1, step1566]: loss 93.093437
[epoch1, step1567]: loss 27.165157
[epoch1, step1568]: loss 83.226151
[epoch1, step1569]: loss 77.160339
[epoch1, step1570]: loss 74.299156
[epoch1, step1571]: loss 59.713909
[epoch1, step1572]: loss 38.621628
[epoch1, step1573]: loss 74.081070
[epoch1, step1574]: loss 46.949867
[epoch1, step1575]: loss 59.377392
[epoch1, step1576]: loss 74.387131
[epoch1, step1577]: loss 17.205141
[epoch1, step1578]: loss 56.851830
[epoch1, step1579]: loss 80.669342
[epoch1, step1580]: loss 32.373985
[epoch1, step1581]: loss 90.642189
[epoch1, step1582]: loss 61.310768
[epoch1, step1583]: loss 32.107113
[epoch1, step1584]: loss 80.567223
[epoch1, step1585]: loss 21.161219
[epoch1, step1586]: loss 51.020031
[epoch1, step1587]: loss 74.033348
[epoch1, step1588]: loss 76.854019
[epoch1, step1589]: loss 25.353523
[epoch1, step1590]: loss 28.423906
[epoch1, step1591]: loss 93.791733
[epoch1, step1592]: loss 47.773426
[epoch1, step1593]: loss 85.696747
[epoch1, step1594]: loss 69.040863
[epoch1, step1595]: loss 32.036640
[epoch1, step1596]: loss 66.769058
[epoch1, step1597]: loss 46.165565
[epoch1, step1598]: loss 49.846931
[epoch1, step1599]: loss 38.918217
[epoch1, step1600]: loss 63.528477
[epoch1, step1601]: loss 64.524529
[epoch1, step1602]: loss 90.697083
[epoch1, step1603]: loss 95.409630
[epoch1, step1604]: loss 35.127167
[epoch1, step1605]: loss 69.784309
[epoch1, step1606]: loss 36.520538
[epoch1, step1607]: loss 67.070572
[epoch1, step1608]: loss 35.903740
[epoch1, step1609]: loss 28.943995
[epoch1, step1610]: loss 64.539833
[epoch1, step1611]: loss 79.073265
[epoch1, step1612]: loss 24.712706
[epoch1, step1613]: loss 48.349190
[epoch1, step1614]: loss 45.465355
[epoch1, step1615]: loss 51.044231
[epoch1, step1616]: loss 60.723763
[epoch1, step1617]: loss 59.190819
[epoch1, step1618]: loss 45.703861
[epoch1, step1619]: loss 49.989853
[epoch1, step1620]: loss 61.438705
[epoch1, step1621]: loss 61.298683
[epoch1, step1622]: loss 49.874805
[epoch1, step1623]: loss 31.790827
[epoch1, step1624]: loss 47.659061
[epoch1, step1625]: loss 59.855984
[epoch1, step1626]: loss 75.107834
[epoch1, step1627]: loss 35.392014
[epoch1, step1628]: loss 45.859047
[epoch1, step1629]: loss 47.563721
[epoch1, step1630]: loss 52.585701
[epoch1, step1631]: loss 76.420372
[epoch1, step1632]: loss 47.557350
[epoch1, step1633]: loss 63.589584
[epoch1, step1634]: loss 88.231544
[epoch1, step1635]: loss 68.231071
[epoch1, step1636]: loss 62.997097
[epoch1, step1637]: loss 61.964088
[epoch1, step1638]: loss 63.243645
[epoch1, step1639]: loss 69.791992
[epoch1, step1640]: loss 72.557800
[epoch1, step1641]: loss 65.998268
[epoch1, step1642]: loss 61.164848
[epoch1, step1643]: loss 53.551117
[epoch1, step1644]: loss 69.780472
[epoch1, step1645]: loss 50.894947
[epoch1, step1646]: loss 40.287521
[epoch1, step1647]: loss 94.013702
[epoch1, step1648]: loss 111.584595
[epoch1, step1649]: loss 42.943466
[epoch1, step1650]: loss 49.640537
[epoch1, step1651]: loss 33.265530
[epoch1, step1652]: loss 82.974129
[epoch1, step1653]: loss 54.334915
[epoch1, step1654]: loss 70.174576
[epoch1, step1655]: loss 81.299866
[epoch1, step1656]: loss 53.879810
[epoch1, step1657]: loss 46.926750
[epoch1, step1658]: loss 26.016956
[epoch1, step1659]: loss 101.667725
[epoch1, step1660]: loss 40.079288
[epoch1, step1661]: loss 48.417435
[epoch1, step1662]: loss 49.796989
[epoch1, step1663]: loss 59.805893
[epoch1, step1664]: loss 90.330536
[epoch1, step1665]: loss 38.320759
[epoch1, step1666]: loss 65.216408
[epoch1, step1667]: loss 66.746658
[epoch1, step1668]: loss 11.015450
[epoch1, step1669]: loss 77.606171
[epoch1, step1670]: loss 40.604317
[epoch1, step1671]: loss 98.030754
[epoch1, step1672]: loss 9.266424
[epoch1, step1673]: loss 85.003563
[epoch1, step1674]: loss 63.470497
[epoch1, step1675]: loss 30.802877
[epoch1, step1676]: loss 25.722437
[epoch1, step1677]: loss 98.949585
[epoch1, step1678]: loss 32.817436
[epoch1, step1679]: loss 121.860107
[epoch1, step1680]: loss 49.438229
[epoch1, step1681]: loss 44.421646
[epoch1, step1682]: loss 26.433886
[epoch1, step1683]: loss 50.748863
[epoch1, step1684]: loss 87.137833
[epoch1, step1685]: loss 60.647560
[epoch1, step1686]: loss 40.874397
[epoch1, step1687]: loss 49.388458
[epoch1, step1688]: loss 42.699329
[epoch1, step1689]: loss 60.892628
[epoch1, step1690]: loss 37.578007
[epoch1, step1691]: loss 60.102329
[epoch1, step1692]: loss 60.010834
[epoch1, step1693]: loss 37.929096
[epoch1, step1694]: loss 25.263721
[epoch1, step1695]: loss 74.590599
[epoch1, step1696]: loss 62.894745
[epoch1, step1697]: loss 44.138935
[epoch1, step1698]: loss 17.223469
[epoch1, step1699]: loss 25.552914
[epoch1, step1700]: loss 53.940125
[epoch1, step1701]: loss 64.144714
[epoch1, step1702]: loss 36.883419
[epoch1, step1703]: loss 106.601410
[epoch1, step1704]: loss 5.517810
[epoch1, step1705]: loss 29.482384
[epoch1, step1706]: loss 41.132561
[epoch1, step1707]: loss 56.565796
[epoch1, step1708]: loss 56.111767
[epoch1, step1709]: loss 48.776505
[epoch1, step1710]: loss 133.674469
[epoch1, step1711]: loss 34.824581
[epoch1, step1712]: loss 22.038733
[epoch1, step1713]: loss 94.965492
[epoch1, step1714]: loss 67.677170
[epoch1, step1715]: loss 60.720226
[epoch1, step1716]: loss 59.544250
[epoch1, step1717]: loss 50.447937
[epoch1, step1718]: loss 47.642780
[epoch1, step1719]: loss 57.051334
[epoch1, step1720]: loss 67.109619
[epoch1, step1721]: loss 60.441040
[epoch1, step1722]: loss 16.501919
[epoch1, step1723]: loss 60.695263
[epoch1, step1724]: loss 17.096241
[epoch1, step1725]: loss 15.396962
[epoch1, step1726]: loss 34.727379
[epoch1, step1727]: loss 10.427012
[epoch1, step1728]: loss 56.042000
[epoch1, step1729]: loss 32.446949
[epoch1, step1730]: loss 30.212063
[epoch1, step1731]: loss 56.753239
[epoch1, step1732]: loss 64.067612
[epoch1, step1733]: loss 21.695280
[epoch1, step1734]: loss 31.038622
[epoch1, step1735]: loss 55.911194
[epoch1, step1736]: loss 52.694462
[epoch1, step1737]: loss 74.918922
[epoch1, step1738]: loss 39.847557
[epoch1, step1739]: loss 27.988789
[epoch1, step1740]: loss 80.368629
[epoch1, step1741]: loss 37.577488
[epoch1, step1742]: loss 44.763008
[epoch1, step1743]: loss 16.136822
[epoch1, step1744]: loss 38.011250
[epoch1, step1745]: loss 42.129467
[epoch1, step1746]: loss 68.999023
[epoch1, step1747]: loss 31.065434
[epoch1, step1748]: loss 37.895279
[epoch1, step1749]: loss 60.876728
[epoch1, step1750]: loss 95.111237
[epoch1, step1751]: loss 65.771011
[epoch1, step1752]: loss 54.253593
[epoch1, step1753]: loss 48.871223
[epoch1, step1754]: loss 74.994217
[epoch1, step1755]: loss 50.592724
[epoch1, step1756]: loss 46.658440
[epoch1, step1757]: loss 71.390678
[epoch1, step1758]: loss 91.918701
[epoch1, step1759]: loss 39.789997
[epoch1, step1760]: loss 30.645678
[epoch1, step1761]: loss 71.867462
[epoch1, step1762]: loss 43.475948
[epoch1, step1763]: loss 48.814812
[epoch1, step1764]: loss 45.297943
[epoch1, step1765]: loss 45.196449
[epoch1, step1766]: loss 99.444183
[epoch1, step1767]: loss 54.496994
[epoch1, step1768]: loss 70.072670
[epoch1, step1769]: loss 43.148857
[epoch1, step1770]: loss 75.677574
[epoch1, step1771]: loss 46.140125
[epoch1, step1772]: loss 37.279221
[epoch1, step1773]: loss 45.216423
[epoch1, step1774]: loss 59.835045
[epoch1, step1775]: loss 56.047642
[epoch1, step1776]: loss 49.644253
[epoch1, step1777]: loss 30.117960
[epoch1, step1778]: loss 84.763985
[epoch1, step1779]: loss 58.654026
[epoch1, step1780]: loss 73.250786
[epoch1, step1781]: loss 51.768097
[epoch1, step1782]: loss 45.710999
[epoch1, step1783]: loss 74.018677
[epoch1, step1784]: loss 43.205437
[epoch1, step1785]: loss 40.567879
[epoch1, step1786]: loss 33.561951
[epoch1, step1787]: loss 44.246445
[epoch1, step1788]: loss 102.020699
[epoch1, step1789]: loss 33.918362
[epoch1, step1790]: loss 60.239021
[epoch1, step1791]: loss 38.416489
[epoch1, step1792]: loss 76.151581
[epoch1, step1793]: loss 45.773304
[epoch1, step1794]: loss 37.302757
[epoch1, step1795]: loss 34.220440
[epoch1, step1796]: loss 64.247154
[epoch1, step1797]: loss 57.206715
[epoch1, step1798]: loss 34.347496
[epoch1, step1799]: loss 95.473351
[epoch1, step1800]: loss 32.331966
[epoch1, step1801]: loss 31.628136
[epoch1, step1802]: loss 53.400314
[epoch1, step1803]: loss 92.663994
[epoch1, step1804]: loss 56.646000
[epoch1, step1805]: loss 108.729469
[epoch1, step1806]: loss 14.207614
[epoch1, step1807]: loss 62.787708
[epoch1, step1808]: loss 35.868782
[epoch1, step1809]: loss 27.064989
[epoch1, step1810]: loss 25.016190
[epoch1, step1811]: loss 42.785995
[epoch1, step1812]: loss 74.471611
[epoch1, step1813]: loss 47.390217
[epoch1, step1814]: loss 42.015984
[epoch1, step1815]: loss 115.989342
[epoch1, step1816]: loss 37.484283
[epoch1, step1817]: loss 84.041870
[epoch1, step1818]: loss 53.317944
[epoch1, step1819]: loss 73.940727
[epoch1, step1820]: loss 77.244667
[epoch1, step1821]: loss 66.536613
[epoch1, step1822]: loss 25.106970
[epoch1, step1823]: loss 97.499840
[epoch1, step1824]: loss 67.505257
[epoch1, step1825]: loss 42.900841
[epoch1, step1826]: loss 74.702522
[epoch1, step1827]: loss 88.825607
[epoch1, step1828]: loss 34.740082
[epoch1, step1829]: loss 96.786545
[epoch1, step1830]: loss 47.823563
[epoch1, step1831]: loss 36.292553
[epoch1, step1832]: loss 52.441433
[epoch1, step1833]: loss 58.153687
[epoch1, step1834]: loss 63.613777
[epoch1, step1835]: loss 51.215790
[epoch1, step1836]: loss 52.168556
[epoch1, step1837]: loss 84.682564
[epoch1, step1838]: loss 78.710114
[epoch1, step1839]: loss 37.394855
[epoch1, step1840]: loss 55.929893
[epoch1, step1841]: loss 61.595642
[epoch1, step1842]: loss 34.666607
[epoch1, step1843]: loss 103.568520
[epoch1, step1844]: loss 77.819466
[epoch1, step1845]: loss 40.487850
[epoch1, step1846]: loss 76.256241
[epoch1, step1847]: loss 16.283575
[epoch1, step1848]: loss 41.719170
[epoch1, step1849]: loss 35.045860
[epoch1, step1850]: loss 47.872730
[epoch1, step1851]: loss 41.868385
[epoch1, step1852]: loss 51.992977
[epoch1, step1853]: loss 45.159992
[epoch1, step1854]: loss 42.009445
[epoch1, step1855]: loss 6.478424
[epoch1, step1856]: loss 23.150887
[epoch1, step1857]: loss 37.557579
[epoch1, step1858]: loss 63.976517
[epoch1, step1859]: loss 9.630799
[epoch1, step1860]: loss 42.314831
[epoch1, step1861]: loss 19.601524
[epoch1, step1862]: loss 57.026440
[epoch1, step1863]: loss 77.117691
[epoch1, step1864]: loss 49.223007
[epoch1, step1865]: loss 70.171265
[epoch1, step1866]: loss 17.835211
[epoch1, step1867]: loss 46.017460
[epoch1, step1868]: loss 45.609283
[epoch1, step1869]: loss 54.379444
[epoch1, step1870]: loss 66.054733
[epoch1, step1871]: loss 73.890068
[epoch1, step1872]: loss 35.640114
[epoch1, step1873]: loss 32.730602
[epoch1, step1874]: loss 41.926964
[epoch1, step1875]: loss 39.247410
[epoch1, step1876]: loss 48.222275
[epoch1, step1877]: loss 71.528206
[epoch1, step1878]: loss 62.408760
[epoch1, step1879]: loss 77.928558
[epoch1, step1880]: loss 55.253212
[epoch1, step1881]: loss 55.082626
[epoch1, step1882]: loss 85.094376
[epoch1, step1883]: loss 88.854187
[epoch1, step1884]: loss 26.971970
[epoch1, step1885]: loss 44.151871
[epoch1, step1886]: loss 22.600019
[epoch1, step1887]: loss 26.383535
[epoch1, step1888]: loss 45.899654
[epoch1, step1889]: loss 66.313316
[epoch1, step1890]: loss 39.174957
[epoch1, step1891]: loss 58.404266
[epoch1, step1892]: loss 40.783371
[epoch1, step1893]: loss 72.079063
[epoch1, step1894]: loss 66.216484
[epoch1, step1895]: loss 46.305946
[epoch1, step1896]: loss 38.440166
[epoch1, step1897]: loss 56.116344
[epoch1, step1898]: loss 58.300186
[epoch1, step1899]: loss 32.961647
[epoch1, step1900]: loss 10.568250
[epoch1, step1901]: loss 64.502007
[epoch1, step1902]: loss 53.442032
[epoch1, step1903]: loss 62.409088
[epoch1, step1904]: loss 44.258835
[epoch1, step1905]: loss 53.359543
[epoch1, step1906]: loss 46.533936
[epoch1, step1907]: loss 53.465240
[epoch1, step1908]: loss 59.076469
[epoch1, step1909]: loss 37.730694
[epoch1, step1910]: loss 29.558310
[epoch1, step1911]: loss 75.313179
[epoch1, step1912]: loss 72.363846
[epoch1, step1913]: loss 67.109505
[epoch1, step1914]: loss 44.916824
[epoch1, step1915]: loss 66.738655
[epoch1, step1916]: loss 91.481392
[epoch1, step1917]: loss 67.132202
[epoch1, step1918]: loss 32.599659
[epoch1, step1919]: loss 66.907837
[epoch1, step1920]: loss 56.086250
[epoch1, step1921]: loss 57.771442
[epoch1, step1922]: loss 20.109032
[epoch1, step1923]: loss 44.741154
[epoch1, step1924]: loss 29.964607
[epoch1, step1925]: loss 60.029774
[epoch1, step1926]: loss 42.445736
[epoch1, step1927]: loss 47.040035
[epoch1, step1928]: loss 64.121178
[epoch1, step1929]: loss 77.589745
[epoch1, step1930]: loss 65.311363
[epoch1, step1931]: loss 49.430164
[epoch1, step1932]: loss 19.988604
[epoch1, step1933]: loss 42.886200
[epoch1, step1934]: loss 61.463913
[epoch1, step1935]: loss 55.800743
[epoch1, step1936]: loss 42.780941
[epoch1, step1937]: loss 65.083694
[epoch1, step1938]: loss 79.606064
[epoch1, step1939]: loss 50.510994
[epoch1, step1940]: loss 54.412415
[epoch1, step1941]: loss 71.524948
[epoch1, step1942]: loss 74.036926
[epoch1, step1943]: loss 26.486769
[epoch1, step1944]: loss 48.834118
[epoch1, step1945]: loss 25.642378
[epoch1, step1946]: loss 27.325693
[epoch1, step1947]: loss 50.420231
[epoch1, step1948]: loss 33.064400
[epoch1, step1949]: loss 48.314312
[epoch1, step1950]: loss 53.346855
[epoch1, step1951]: loss 22.894100
[epoch1, step1952]: loss 54.236553
[epoch1, step1953]: loss 9.512365
[epoch1, step1954]: loss 36.300392
[epoch1, step1955]: loss 42.644455
[epoch1, step1956]: loss 44.628086
[epoch1, step1957]: loss 41.532288
[epoch1, step1958]: loss 68.644997
[epoch1, step1959]: loss 51.054611
[epoch1, step1960]: loss 59.497368
[epoch1, step1961]: loss 64.090736
[epoch1, step1962]: loss 38.949272
[epoch1, step1963]: loss 30.381453
[epoch1, step1964]: loss 68.404320
[epoch1, step1965]: loss 77.560020
[epoch1, step1966]: loss 71.290428
[epoch1, step1967]: loss 38.669304
[epoch1, step1968]: loss 45.110939
[epoch1, step1969]: loss 59.095726
[epoch1, step1970]: loss 46.101467
[epoch1, step1971]: loss 58.254986
[epoch1, step1972]: loss 28.909220
[epoch1, step1973]: loss 62.027416
[epoch1, step1974]: loss 55.304836
[epoch1, step1975]: loss 30.338179
[epoch1, step1976]: loss 35.491432
[epoch1, step1977]: loss 53.374683
[epoch1, step1978]: loss 38.795177
[epoch1, step1979]: loss 45.046902
[epoch1, step1980]: loss 62.181690
[epoch1, step1981]: loss 50.465405
[epoch1, step1982]: loss 26.579784
[epoch1, step1983]: loss 58.691418
[epoch1, step1984]: loss 40.961094
[epoch1, step1985]: loss 30.594254
[epoch1, step1986]: loss 49.786842
[epoch1, step1987]: loss 30.463579
[epoch1, step1988]: loss 32.049805
[epoch1, step1989]: loss 20.683029
[epoch1, step1990]: loss 50.423218
[epoch1, step1991]: loss 22.037039
[epoch1, step1992]: loss 45.820568
[epoch1, step1993]: loss 69.308815
[epoch1, step1994]: loss 45.612194
[epoch1, step1995]: loss 45.647377
[epoch1, step1996]: loss 38.114449
[epoch1, step1997]: loss 86.148300
[epoch1, step1998]: loss 47.550339
[epoch1, step1999]: loss 63.709023
[epoch1, step2000]: loss 78.017426
[epoch1, step2001]: loss 52.028736
[epoch1, step2002]: loss 64.994446
[epoch1, step2003]: loss 50.753136
[epoch1, step2004]: loss 28.444881
[epoch1, step2005]: loss 42.492085
[epoch1, step2006]: loss 31.934340
[epoch1, step2007]: loss 54.326199
[epoch1, step2008]: loss 41.864014
[epoch1, step2009]: loss 27.542290
[epoch1, step2010]: loss 43.840630
[epoch1, step2011]: loss 46.688297
[epoch1, step2012]: loss 33.887527
[epoch1, step2013]: loss 58.083912
[epoch1, step2014]: loss 32.212906
[epoch1, step2015]: loss 32.031700
[epoch1, step2016]: loss 70.985550
[epoch1, step2017]: loss 20.564865
[epoch1, step2018]: loss 59.481251
[epoch1, step2019]: loss 33.333252
[epoch1, step2020]: loss 7.467811
[epoch1, step2021]: loss 27.279747
[epoch1, step2022]: loss 19.418468
[epoch1, step2023]: loss 30.196606
[epoch1, step2024]: loss 63.675777
[epoch1, step2025]: loss 25.377684
[epoch1, step2026]: loss 26.384995
[epoch1, step2027]: loss 39.473370
[epoch1, step2028]: loss 83.661949
[epoch1, step2029]: loss 71.188591
[epoch1, step2030]: loss 64.263824
[epoch1, step2031]: loss 49.874340
[epoch1, step2032]: loss 76.175743
[epoch1, step2033]: loss 69.056587
[epoch1, step2034]: loss 53.658951
[epoch1, step2035]: loss 47.278622
[epoch1, step2036]: loss 43.766827
[epoch1, step2037]: loss 66.358009
[epoch1, step2038]: loss 62.841965
[epoch1, step2039]: loss 41.104111
[epoch1, step2040]: loss 48.797787
[epoch1, step2041]: loss 34.765972
[epoch1, step2042]: loss 27.647068
[epoch1, step2043]: loss 74.063126
[epoch1, step2044]: loss 86.635185
[epoch1, step2045]: loss 73.981148
[epoch1, step2046]: loss 31.313519
[epoch1, step2047]: loss 67.183197
[epoch1, step2048]: loss 25.592533
[epoch1, step2049]: loss 56.308365
[epoch1, step2050]: loss 46.191895
[epoch1, step2051]: loss 67.710274
[epoch1, step2052]: loss 28.651163
[epoch1, step2053]: loss 72.260307
[epoch1, step2054]: loss 81.548653
[epoch1, step2055]: loss 65.910728
[epoch1, step2056]: loss 69.182434
[epoch1, step2057]: loss 58.786407
[epoch1, step2058]: loss 28.508295
[epoch1, step2059]: loss 71.580437
[epoch1, step2060]: loss 19.541353
[epoch1, step2061]: loss 78.014824
[epoch1, step2062]: loss 73.881348
[epoch1, step2063]: loss 45.510952
[epoch1, step2064]: loss 60.546246
[epoch1, step2065]: loss 63.517265
[epoch1, step2066]: loss 78.417862
[epoch1, step2067]: loss 50.956898
[epoch1, step2068]: loss 38.429359
[epoch1, step2069]: loss 30.302322
[epoch1, step2070]: loss 35.129021
[epoch1, step2071]: loss 39.074142
[epoch1, step2072]: loss 44.110023
[epoch1, step2073]: loss 45.046398
[epoch1, step2074]: loss 33.422607
[epoch1, step2075]: loss 52.708954
[epoch1, step2076]: loss 78.421455
[epoch1, step2077]: loss 55.639362
[epoch1, step2078]: loss 45.193523
[epoch1, step2079]: loss 34.374180
[epoch1, step2080]: loss 52.075123
[epoch1, step2081]: loss 85.951668
[epoch1, step2082]: loss 41.442642
[epoch1, step2083]: loss 47.391579
[epoch1, step2084]: loss 46.493847
[epoch1, step2085]: loss 48.095760
[epoch1, step2086]: loss 16.355864
[epoch1, step2087]: loss 17.492292
[epoch1, step2088]: loss 36.256218
[epoch1, step2089]: loss 59.707668
[epoch1, step2090]: loss 69.544334
[epoch1, step2091]: loss 48.664936
[epoch1, step2092]: loss 39.671955
[epoch1, step2093]: loss 38.587025
[epoch1, step2094]: loss 58.739040
[epoch1, step2095]: loss 60.790737
[epoch1, step2096]: loss 36.523605
[epoch1, step2097]: loss 54.501171
[epoch1, step2098]: loss 22.505285
[epoch1, step2099]: loss 64.822281
[epoch1, step2100]: loss 58.763943
[epoch1, step2101]: loss 77.696526
[epoch1, step2102]: loss 85.384506
[epoch1, step2103]: loss 60.698391
[epoch1, step2104]: loss 55.722305
[epoch1, step2105]: loss 44.466263
[epoch1, step2106]: loss 46.085831
[epoch1, step2107]: loss 74.442596
[epoch1, step2108]: loss 73.921349
[epoch1, step2109]: loss 51.105701
[epoch1, step2110]: loss 84.437500
[epoch1, step2111]: loss 35.613148
[epoch1, step2112]: loss 63.004349
[epoch1, step2113]: loss 37.525574
[epoch1, step2114]: loss 81.251183
[epoch1, step2115]: loss 52.768394
[epoch1, step2116]: loss 10.909075
[epoch1, step2117]: loss 47.682880
[epoch1, step2118]: loss 29.234262
[epoch1, step2119]: loss 64.147072
[epoch1, step2120]: loss 38.558823
[epoch1, step2121]: loss 57.468811
[epoch1, step2122]: loss 37.087555
[epoch1, step2123]: loss 42.172810
[epoch1, step2124]: loss 31.660479
[epoch1, step2125]: loss 71.925102
[epoch1, step2126]: loss 31.154367
[epoch1, step2127]: loss 13.603081
[epoch1, step2128]: loss 36.909016
[epoch1, step2129]: loss 38.984528
[epoch1, step2130]: loss 36.610706
[epoch1, step2131]: loss 29.601883
[epoch1, step2132]: loss 76.280563
[epoch1, step2133]: loss 43.869228
[epoch1, step2134]: loss 98.685074
[epoch1, step2135]: loss 75.267624
[epoch1, step2136]: loss 88.277794
[epoch1, step2137]: loss 32.998093
[epoch1, step2138]: loss 78.077927
[epoch1, step2139]: loss 32.542965
[epoch1, step2140]: loss 87.606102
[epoch1, step2141]: loss 29.940805
[epoch1, step2142]: loss 57.851295
[epoch1, step2143]: loss 64.673782
[epoch1, step2144]: loss 30.741629
[epoch1, step2145]: loss 62.346516
[epoch1, step2146]: loss 55.084209
[epoch1, step2147]: loss 48.027977
[epoch1, step2148]: loss 38.989807
[epoch1, step2149]: loss 54.029099
[epoch1, step2150]: loss 30.256310
[epoch1, step2151]: loss 54.050430
[epoch1, step2152]: loss 44.880283
[epoch1, step2153]: loss 31.217794
[epoch1, step2154]: loss 42.663586
[epoch1, step2155]: loss 39.211826
[epoch1, step2156]: loss 62.916729
[epoch1, step2157]: loss 28.376141
[epoch1, step2158]: loss 23.039351
[epoch1, step2159]: loss 43.997131
[epoch1, step2160]: loss 50.515640
[epoch1, step2161]: loss 45.988518
[epoch1, step2162]: loss 29.555719
[epoch1, step2163]: loss 75.086380
[epoch1, step2164]: loss 56.546860
[epoch1, step2165]: loss 43.902634
[epoch1, step2166]: loss 67.317688
[epoch1, step2167]: loss 37.597298
[epoch1, step2168]: loss 38.399204
[epoch1, step2169]: loss 50.194679
[epoch1, step2170]: loss 18.786589
[epoch1, step2171]: loss 59.853004
[epoch1, step2172]: loss 63.527416
[epoch1, step2173]: loss 40.354908
[epoch1, step2174]: loss 45.126064
[epoch1, step2175]: loss 58.219677
[epoch1, step2176]: loss 86.585869
[epoch1, step2177]: loss 41.821415
[epoch1, step2178]: loss 20.220663
[epoch1, step2179]: loss 40.868137
[epoch1, step2180]: loss 31.036476
[epoch1, step2181]: loss 51.756294
[epoch1, step2182]: loss 64.271416
[epoch1, step2183]: loss 60.582630
[epoch1, step2184]: loss 61.189209
[epoch1, step2185]: loss 41.443073
[epoch1, step2186]: loss 66.757683
[epoch1, step2187]: loss 66.457886
[epoch1, step2188]: loss 28.451601
[epoch1, step2189]: loss 33.295006
[epoch1, step2190]: loss 48.548042
[epoch1, step2191]: loss 66.228363
[epoch1, step2192]: loss 32.276043
[epoch1, step2193]: loss 78.569321
[epoch1, step2194]: loss 49.150970
[epoch1, step2195]: loss 34.953262
[epoch1, step2196]: loss 35.045238
[epoch1, step2197]: loss 8.137394
[epoch1, step2198]: loss 62.747887
[epoch1, step2199]: loss 58.293476
[epoch1, step2200]: loss 51.311447
[epoch1, step2201]: loss 56.725910
[epoch1, step2202]: loss 48.698421
[epoch1, step2203]: loss 59.884270
[epoch1, step2204]: loss 46.140915
[epoch1, step2205]: loss 98.493713
[epoch1, step2206]: loss 93.117134
[epoch1, step2207]: loss 59.695702
[epoch1, step2208]: loss 59.232891
[epoch1, step2209]: loss 49.831860
[epoch1, step2210]: loss 57.164227
[epoch1, step2211]: loss 20.070732
[epoch1, step2212]: loss 44.896336
[epoch1, step2213]: loss 20.207823
[epoch1, step2214]: loss 56.884991
[epoch1, step2215]: loss 63.839985
[epoch1, step2216]: loss 47.285721
[epoch1, step2217]: loss 45.839642
[epoch1, step2218]: loss 19.303627
[epoch1, step2219]: loss 27.384792
[epoch1, step2220]: loss 46.061260
[epoch1, step2221]: loss 38.937695
[epoch1, step2222]: loss 63.098820
[epoch1, step2223]: loss 10.824496
[epoch1, step2224]: loss 63.872139
[epoch1, step2225]: loss 50.169888
[epoch1, step2226]: loss 85.429855
[epoch1, step2227]: loss 38.845295
[epoch1, step2228]: loss 53.219997
[epoch1, step2229]: loss 75.372353
[epoch1, step2230]: loss 42.139328
[epoch1, step2231]: loss 66.803825
[epoch1, step2232]: loss 36.385628
[epoch1, step2233]: loss 54.727974
[epoch1, step2234]: loss 36.903996
[epoch1, step2235]: loss 55.248539
[epoch1, step2236]: loss 33.448154
[epoch1, step2237]: loss 76.314049
[epoch1, step2238]: loss 61.990208
[epoch1, step2239]: loss 57.639389
[epoch1, step2240]: loss 51.680275
[epoch1, step2241]: loss 41.306461
[epoch1, step2242]: loss 55.233780
[epoch1, step2243]: loss 30.509140
[epoch1, step2244]: loss 53.395920
[epoch1, step2245]: loss 51.392372
[epoch1, step2246]: loss 24.961451
[epoch1, step2247]: loss 29.451530
[epoch1, step2248]: loss 56.929897
[epoch1, step2249]: loss 73.651321
[epoch1, step2250]: loss 34.402519
[epoch1, step2251]: loss 65.087669
[epoch1, step2252]: loss 86.473213
[epoch1, step2253]: loss 19.781799
[epoch1, step2254]: loss 7.033734
[epoch1, step2255]: loss 25.267939
[epoch1, step2256]: loss 54.285187
[epoch1, step2257]: loss 37.989147
[epoch1, step2258]: loss 34.476902
[epoch1, step2259]: loss 58.587173
[epoch1, step2260]: loss 37.774193
[epoch1, step2261]: loss 32.818604
[epoch1, step2262]: loss 19.177608
[epoch1, step2263]: loss 44.335224
[epoch1, step2264]: loss 55.645988
[epoch1, step2265]: loss 24.232197
[epoch1, step2266]: loss 13.065498
[epoch1, step2267]: loss 60.868092
[epoch1, step2268]: loss 31.985678
[epoch1, step2269]: loss 24.157045
[epoch1, step2270]: loss 17.729759
[epoch1, step2271]: loss 45.908318
[epoch1, step2272]: loss 79.561485
[epoch1, step2273]: loss 14.614624
[epoch1, step2274]: loss 35.038677
[epoch1, step2275]: loss 47.450344
[epoch1, step2276]: loss 27.503490
[epoch1, step2277]: loss 31.820215
[epoch1, step2278]: loss 16.918255
[epoch1, step2279]: loss 39.497265
[epoch1, step2280]: loss 38.694344
[epoch1, step2281]: loss 12.857607
[epoch1, step2282]: loss 67.820702
[epoch1, step2283]: loss 11.041451
[epoch1, step2284]: loss 44.300404
[epoch1, step2285]: loss 24.411274
[epoch1, step2286]: loss 42.697117
[epoch1, step2287]: loss 25.965324
[epoch1, step2288]: loss 62.941868
[epoch1, step2289]: loss 41.957142
[epoch1, step2290]: loss 57.256222
[epoch1, step2291]: loss 38.418591
[epoch1, step2292]: loss 35.261044
[epoch1, step2293]: loss 81.203392
[epoch1, step2294]: loss 37.669029
[epoch1, step2295]: loss 25.118586
[epoch1, step2296]: loss 34.756691
[epoch1, step2297]: loss 76.103065
[epoch1, step2298]: loss 67.521408
[epoch1, step2299]: loss 65.334343
[epoch1, step2300]: loss 50.903671
[epoch1, step2301]: loss 62.943741
[epoch1, step2302]: loss 41.321877
[epoch1, step2303]: loss 42.003803
[epoch1, step2304]: loss 56.906830
[epoch1, step2305]: loss 35.871029
[epoch1, step2306]: loss 52.397137
[epoch1, step2307]: loss 30.728245
[epoch1, step2308]: loss 42.231880
[epoch1, step2309]: loss 30.678095
[epoch1, step2310]: loss 24.053205
[epoch1, step2311]: loss 46.604263
[epoch1, step2312]: loss 51.898125
[epoch1, step2313]: loss 30.409063
[epoch1, step2314]: loss 27.529028
[epoch1, step2315]: loss 38.665478
[epoch1, step2316]: loss 29.224236
[epoch1, step2317]: loss 42.398373
[epoch1, step2318]: loss 52.502075
[epoch1, step2319]: loss 58.496746
[epoch1, step2320]: loss 37.245220
[epoch1, step2321]: loss 33.116394
[epoch1, step2322]: loss 53.255230
[epoch1, step2323]: loss 48.884369
[epoch1, step2324]: loss 24.114443
[epoch1, step2325]: loss 41.472511
[epoch1, step2326]: loss 45.817783
[epoch1, step2327]: loss 12.903972
[epoch1, step2328]: loss 49.448116
[epoch1, step2329]: loss 98.563454
[epoch1, step2330]: loss 50.400837
[epoch1, step2331]: loss 69.123817
[epoch1, step2332]: loss 43.460644
[epoch1, step2333]: loss 58.223232
[epoch1, step2334]: loss 35.144699
[epoch1, step2335]: loss 34.657780
[epoch1, step2336]: loss 46.121593
[epoch1, step2337]: loss 19.262953
[epoch1, step2338]: loss 55.169369
[epoch1, step2339]: loss 45.038841
[epoch1, step2340]: loss 16.083918
[epoch1, step2341]: loss 73.155563
[epoch1, step2342]: loss 51.110874
[epoch1, step2343]: loss 9.247836
[epoch1, step2344]: loss 35.263416
[epoch1, step2345]: loss 12.414339
[epoch1, step2346]: loss 51.039711
[epoch1, step2347]: loss 43.046558
[epoch1, step2348]: loss 80.992554
[epoch1, step2349]: loss 72.881241
[epoch1, step2350]: loss 61.741810
[epoch1, step2351]: loss 17.773491
[epoch1, step2352]: loss 18.931295
[epoch1, step2353]: loss 34.453144
[epoch1, step2354]: loss 67.289589
[epoch1, step2355]: loss 21.525490
[epoch1, step2356]: loss 45.398392
[epoch1, step2357]: loss 35.140675
[epoch1, step2358]: loss 30.139219
[epoch1, step2359]: loss 80.547531
[epoch1, step2360]: loss 57.673439
[epoch1, step2361]: loss 35.759476
[epoch1, step2362]: loss 40.138897
[epoch1, step2363]: loss 32.659222
[epoch1, step2364]: loss 45.545719
[epoch1, step2365]: loss 35.341667
[epoch1, step2366]: loss 29.512266
[epoch1, step2367]: loss 19.770956
[epoch1, step2368]: loss 46.182209
[epoch1, step2369]: loss 47.775036
[epoch1, step2370]: loss 42.965408
[epoch1, step2371]: loss 50.689983
[epoch1, step2372]: loss 24.261036
[epoch1, step2373]: loss 36.630558
[epoch1, step2374]: loss 64.132828
[epoch1, step2375]: loss 21.796074
[epoch1, step2376]: loss 34.792477
[epoch1, step2377]: loss 34.997894
[epoch1, step2378]: loss 49.246323
[epoch1, step2379]: loss 51.679047
[epoch1, step2380]: loss 36.477730
[epoch1, step2381]: loss 41.187305
[epoch1, step2382]: loss 36.028458
[epoch1, step2383]: loss 42.570377
[epoch1, step2384]: loss 73.613068
[epoch1, step2385]: loss 32.357792
[epoch1, step2386]: loss 46.803638
[epoch1, step2387]: loss 43.626900
[epoch1, step2388]: loss 39.151890
[epoch1, step2389]: loss 61.186035
[epoch1, step2390]: loss 32.608849
[epoch1, step2391]: loss 45.589321
[epoch1, step2392]: loss 32.905418
[epoch1, step2393]: loss 31.581841
[epoch1, step2394]: loss 29.758425
[epoch1, step2395]: loss 33.751881
[epoch1, step2396]: loss 28.872009
[epoch1, step2397]: loss 53.645802
[epoch1, step2398]: loss 38.764305
[epoch1, step2399]: loss 34.242039
[epoch1, step2400]: loss 62.078285
[epoch1, step2401]: loss 60.508957
[epoch1, step2402]: loss 83.946045
[epoch1, step2403]: loss 67.803207
[epoch1, step2404]: loss 44.215759
[epoch1, step2405]: loss 27.183855
[epoch1, step2406]: loss 26.741112
[epoch1, step2407]: loss 31.272406
[epoch1, step2408]: loss 38.477898
[epoch1, step2409]: loss 69.362518
[epoch1, step2410]: loss 31.142609
[epoch1, step2411]: loss 56.744244
[epoch1, step2412]: loss 69.697899
[epoch1, step2413]: loss 27.605013
[epoch1, step2414]: loss 75.734352
[epoch1, step2415]: loss 39.344883
[epoch1, step2416]: loss 50.885765
[epoch1, step2417]: loss 41.132061
[epoch1, step2418]: loss 50.256828
[epoch1, step2419]: loss 50.747108
[epoch1, step2420]: loss 27.035357
[epoch1, step2421]: loss 44.122768
[epoch1, step2422]: loss 40.054382
[epoch1, step2423]: loss 37.260124
[epoch1, step2424]: loss 37.292969
[epoch1, step2425]: loss 59.254055
[epoch1, step2426]: loss 63.606033
[epoch1, step2427]: loss 22.477350
[epoch1, step2428]: loss 38.296684
[epoch1, step2429]: loss 18.226208
[epoch1, step2430]: loss 24.200048
[epoch1, step2431]: loss 27.043501
[epoch1, step2432]: loss 33.421604
[epoch1, step2433]: loss 68.547340
[epoch1, step2434]: loss 52.058743
[epoch1, step2435]: loss 28.309170
[epoch1, step2436]: loss 43.357761
[epoch1, step2437]: loss 31.623402
[epoch1, step2438]: loss 44.501839
[epoch1, step2439]: loss 47.808792
[epoch1, step2440]: loss 26.080412
[epoch1, step2441]: loss 26.510059
[epoch1, step2442]: loss 18.502697
[epoch1, step2443]: loss 47.287960
[epoch1, step2444]: loss 35.262383
[epoch1, step2445]: loss 41.832829
[epoch1, step2446]: loss 46.328571
[epoch1, step2447]: loss 59.662163
[epoch1, step2448]: loss 42.759003
[epoch1, step2449]: loss 26.238211
[epoch1, step2450]: loss 26.186029
[epoch1, step2451]: loss 56.983513
[epoch1, step2452]: loss 43.751686
[epoch1, step2453]: loss 66.947380
[epoch1, step2454]: loss 42.598576
[epoch1, step2455]: loss 66.395523
[epoch1, step2456]: loss 42.446606
[epoch1, step2457]: loss 11.952995
[epoch1, step2458]: loss 44.841824
[epoch1, step2459]: loss 56.118320
[epoch1, step2460]: loss 19.584185
[epoch1, step2461]: loss 19.453270
[epoch1, step2462]: loss 53.271603
[epoch1, step2463]: loss 45.400028
[epoch1, step2464]: loss 35.622566
[epoch1, step2465]: loss 15.934925
[epoch1, step2466]: loss 55.470367
[epoch1, step2467]: loss 30.502754
[epoch1, step2468]: loss 28.826927
[epoch1, step2469]: loss 42.806492
[epoch1, step2470]: loss 53.740650
[epoch1, step2471]: loss 101.011940
[epoch1, step2472]: loss 51.344501
[epoch1, step2473]: loss 49.377670
[epoch1, step2474]: loss 49.217396
[epoch1, step2475]: loss 33.437943
[epoch1, step2476]: loss 40.385475
[epoch1, step2477]: loss 23.192825
[epoch1, step2478]: loss 35.178970
[epoch1, step2479]: loss 46.273228
[epoch1, step2480]: loss 80.248604
[epoch1, step2481]: loss 59.748058
[epoch1, step2482]: loss 25.189814
[epoch1, step2483]: loss 53.825760
[epoch1, step2484]: loss 16.094387
[epoch1, step2485]: loss 35.928062
[epoch1, step2486]: loss 8.444176
[epoch1, step2487]: loss 24.502640
[epoch1, step2488]: loss 77.824524
[epoch1, step2489]: loss 54.953129
[epoch1, step2490]: loss 57.968540
[epoch1, step2491]: loss 33.650761
[epoch1, step2492]: loss 50.932907
[epoch1, step2493]: loss 33.682369
[epoch1, step2494]: loss 55.553860
[epoch1, step2495]: loss 34.909702
[epoch1, step2496]: loss 34.697800
[epoch1, step2497]: loss 53.633770
[epoch1, step2498]: loss 29.703827
[epoch1, step2499]: loss 30.752525
[epoch1, step2500]: loss 36.085014
[epoch1, step2501]: loss 20.054640
[epoch1, step2502]: loss 25.287481
[epoch1, step2503]: loss 20.170399
[epoch1, step2504]: loss 76.637550
[epoch1, step2505]: loss 27.948719
[epoch1, step2506]: loss 24.645275
[epoch1, step2507]: loss 41.246571
[epoch1, step2508]: loss 20.357607
[epoch1, step2509]: loss 53.326870
[epoch1, step2510]: loss 20.953295
[epoch1, step2511]: loss 48.110729
[epoch1, step2512]: loss 22.654976
[epoch1, step2513]: loss 30.481098
[epoch1, step2514]: loss 30.015598
[epoch1, step2515]: loss 45.895432
[epoch1, step2516]: loss 22.139668
[epoch1, step2517]: loss 19.165398
[epoch1, step2518]: loss 48.238197
[epoch1, step2519]: loss 22.239553
[epoch1, step2520]: loss 28.850046
[epoch1, step2521]: loss 57.356194
[epoch1, step2522]: loss 30.952049
[epoch1, step2523]: loss 18.459040
[epoch1, step2524]: loss 38.626724
[epoch1, step2525]: loss 53.465950
[epoch1, step2526]: loss 43.864487
[epoch1, step2527]: loss 39.947136
[epoch1, step2528]: loss 15.496221
[epoch1, step2529]: loss 38.106205
[epoch1, step2530]: loss 81.806160
[epoch1, step2531]: loss 33.018047
[epoch1, step2532]: loss 41.995365
[epoch1, step2533]: loss 52.930538
[epoch1, step2534]: loss 22.614868
[epoch1, step2535]: loss 21.037081
[epoch1, step2536]: loss 34.628803
[epoch1, step2537]: loss 36.725216
[epoch1, step2538]: loss 70.241241
[epoch1, step2539]: loss 15.499396
[epoch1, step2540]: loss 30.082726
[epoch1, step2541]: loss 28.442312
[epoch1, step2542]: loss 13.142252
[epoch1, step2543]: loss 25.718672
[epoch1, step2544]: loss 30.170218
[epoch1, step2545]: loss 29.564964
[epoch1, step2546]: loss 10.896041
[epoch1, step2547]: loss 32.191170
[epoch1, step2548]: loss 55.917053
[epoch1, step2549]: loss 25.694092
[epoch1, step2550]: loss 38.645317
[epoch1, step2551]: loss 36.141365
[epoch1, step2552]: loss 42.566620
[epoch1, step2553]: loss 63.716034
[epoch1, step2554]: loss 48.378483
[epoch1, step2555]: loss 27.561419
[epoch1, step2556]: loss 12.147797
[epoch1, step2557]: loss 27.644726
[epoch1, step2558]: loss 30.441038
[epoch1, step2559]: loss 16.880884
[epoch1, step2560]: loss 29.890472
[epoch1, step2561]: loss 28.834129
[epoch1, step2562]: loss 39.145203
[epoch1, step2563]: loss 53.183220
[epoch1, step2564]: loss 50.462173
[epoch1, step2565]: loss 47.556335
[epoch1, step2566]: loss 64.775131
[epoch1, step2567]: loss 37.751541
[epoch1, step2568]: loss 28.302908
[epoch1, step2569]: loss 37.616692
[epoch1, step2570]: loss 50.499550
[epoch1, step2571]: loss 23.509300
[epoch1, step2572]: loss 43.317287
[epoch1, step2573]: loss 23.641102
[epoch1, step2574]: loss 66.928955
[epoch1, step2575]: loss 59.255501
[epoch1, step2576]: loss 50.660244
[epoch1, step2577]: loss 13.017667
[epoch1, step2578]: loss 33.880333
[epoch1, step2579]: loss 67.299561
[epoch1, step2580]: loss 58.198666
[epoch1, step2581]: loss 46.405655
[epoch1, step2582]: loss 20.362764
[epoch1, step2583]: loss 14.827118
[epoch1, step2584]: loss 53.168812
[epoch1, step2585]: loss 49.203609
[epoch1, step2586]: loss 61.230709
[epoch1, step2587]: loss 22.020620
[epoch1, step2588]: loss 23.939386
[epoch1, step2589]: loss 24.716711
[epoch1, step2590]: loss 23.241995
[epoch1, step2591]: loss 15.587183
[epoch1, step2592]: loss 67.246223
[epoch1, step2593]: loss 50.391449
[epoch1, step2594]: loss 45.132328
[epoch1, step2595]: loss 80.515381
[epoch1, step2596]: loss 26.475332
[epoch1, step2597]: loss 77.046379
[epoch1, step2598]: loss 26.105532
[epoch1, step2599]: loss 31.154320
[epoch1, step2600]: loss 56.049725
[epoch1, step2601]: loss 49.842201
[epoch1, step2602]: loss 16.919151
[epoch1, step2603]: loss 55.245224
[epoch1, step2604]: loss 30.434538
[epoch1, step2605]: loss 19.740448
[epoch1, step2606]: loss 40.229794
[epoch1, step2607]: loss 27.650892
[epoch1, step2608]: loss 28.574673
[epoch1, step2609]: loss 32.369125
[epoch1, step2610]: loss 9.860170
[epoch1, step2611]: loss 44.417095
[epoch1, step2612]: loss 51.006474
[epoch1, step2613]: loss 5.396124
[epoch1, step2614]: loss 37.563999
[epoch1, step2615]: loss 53.429432
[epoch1, step2616]: loss 27.176842
[epoch1, step2617]: loss 23.989443
[epoch1, step2618]: loss 51.601860
[epoch1, step2619]: loss 34.820831
[epoch1, step2620]: loss 20.373137
[epoch1, step2621]: loss 16.308197
[epoch1, step2622]: loss 20.786238
[epoch1, step2623]: loss 52.341000
[epoch1, step2624]: loss 42.176926
[epoch1, step2625]: loss 29.948454
[epoch1, step2626]: loss 51.269276
[epoch1, step2627]: loss 35.913311
[epoch1, step2628]: loss 10.110251
[epoch1, step2629]: loss 36.876705
[epoch1, step2630]: loss 40.126186
[epoch1, step2631]: loss 42.925049
[epoch1, step2632]: loss 58.483604
[epoch1, step2633]: loss 24.707697
[epoch1, step2634]: loss 32.556747
[epoch1, step2635]: loss 38.458965
[epoch1, step2636]: loss 29.108789
[epoch1, step2637]: loss 55.068302
[epoch1, step2638]: loss 22.295031
[epoch1, step2639]: loss 40.175503
[epoch1, step2640]: loss 55.109295
[epoch1, step2641]: loss 43.430809
[epoch1, step2642]: loss 35.992836
[epoch1, step2643]: loss 49.229542
[epoch1, step2644]: loss 30.301771
[epoch1, step2645]: loss 29.613609
[epoch1, step2646]: loss 36.494427
[epoch1, step2647]: loss 41.450089
[epoch1, step2648]: loss 49.796970
[epoch1, step2649]: loss 54.259903
[epoch1, step2650]: loss 61.966331
[epoch1, step2651]: loss 39.714153
[epoch1, step2652]: loss 35.344498
[epoch1, step2653]: loss 60.341801
[epoch1, step2654]: loss 64.210579
[epoch1, step2655]: loss 70.372055
[epoch1, step2656]: loss 31.906546
[epoch1, step2657]: loss 22.450338
[epoch1, step2658]: loss 10.931547
[epoch1, step2659]: loss 60.524120
[epoch1, step2660]: loss 26.141472
[epoch1, step2661]: loss 5.931689
[epoch1, step2662]: loss 55.109035
[epoch1, step2663]: loss 31.781387
[epoch1, step2664]: loss 45.407040
[epoch1, step2665]: loss 49.106838
[epoch1, step2666]: loss 56.590878
[epoch1, step2667]: loss 19.480053
[epoch1, step2668]: loss 30.352007
[epoch1, step2669]: loss 24.870466
[epoch1, step2670]: loss 54.260151
[epoch1, step2671]: loss 47.211609
[epoch1, step2672]: loss 16.944855
[epoch1, step2673]: loss 33.191433
[epoch1, step2674]: loss 32.549854
[epoch1, step2675]: loss 30.152853
[epoch1, step2676]: loss 42.844532
[epoch1, step2677]: loss 58.865349
[epoch1, step2678]: loss 36.487144
[epoch1, step2679]: loss 36.825886
[epoch1, step2680]: loss 32.934818
[epoch1, step2681]: loss 45.009785
[epoch1, step2682]: loss 64.492188
[epoch1, step2683]: loss 34.441265
[epoch1, step2684]: loss 19.614363
[epoch1, step2685]: loss 51.093998
[epoch1, step2686]: loss 37.828030
[epoch1, step2687]: loss 10.045609
[epoch1, step2688]: loss 32.141998
[epoch1, step2689]: loss 34.949627
[epoch1, step2690]: loss 33.037979
[epoch1, step2691]: loss 24.991264
[epoch1, step2692]: loss 40.426399
[epoch1, step2693]: loss 49.777927
[epoch1, step2694]: loss 63.010803
[epoch1, step2695]: loss 49.129936
[epoch1, step2696]: loss 45.324280
[epoch1, step2697]: loss 63.132557
[epoch1, step2698]: loss 67.070572
[epoch1, step2699]: loss 19.962051
[epoch1, step2700]: loss 30.436363
[epoch1, step2701]: loss 33.920490
[epoch1, step2702]: loss 43.671013
[epoch1, step2703]: loss 38.848484
[epoch1, step2704]: loss 10.600630
[epoch1, step2705]: loss 74.563828
[epoch1, step2706]: loss 30.102859
[epoch1, step2707]: loss 50.732792
[epoch1, step2708]: loss 28.892988
[epoch1, step2709]: loss 33.471260
[epoch1, step2710]: loss 35.357201
[epoch1, step2711]: loss 44.328651
[epoch1, step2712]: loss 20.820221
[epoch1, step2713]: loss 15.497532
[epoch1, step2714]: loss 27.655460
[epoch1, step2715]: loss 54.464249
[epoch1, step2716]: loss 48.243473
[epoch1, step2717]: loss 87.825035
[epoch1, step2718]: loss 35.236462
[epoch1, step2719]: loss 25.412344
[epoch1, step2720]: loss 41.387802
[epoch1, step2721]: loss 48.301125
[epoch1, step2722]: loss 64.633286
[epoch1, step2723]: loss 30.632277
[epoch1, step2724]: loss 13.047633
[epoch1, step2725]: loss 30.554323
[epoch1, step2726]: loss 33.963100
[epoch1, step2727]: loss 56.460342
[epoch1, step2728]: loss 29.000502
[epoch1, step2729]: loss 41.214542
[epoch1, step2730]: loss 7.062724
[epoch1, step2731]: loss 35.211044
[epoch1, step2732]: loss 24.293440
[epoch1, step2733]: loss 63.148220
[epoch1, step2734]: loss 23.664984
[epoch1, step2735]: loss 35.595058
[epoch1, step2736]: loss 31.648165
[epoch1, step2737]: loss 39.296459
[epoch1, step2738]: loss 41.209385
[epoch1, step2739]: loss 18.016134
[epoch1, step2740]: loss 47.747929
[epoch1, step2741]: loss 43.325798
[epoch1, step2742]: loss 82.631325
[epoch1, step2743]: loss 49.337196
[epoch1, step2744]: loss 24.748934
[epoch1, step2745]: loss 49.194721
[epoch1, step2746]: loss 28.541119
[epoch1, step2747]: loss 17.099669
[epoch1, step2748]: loss 17.893261
[epoch1, step2749]: loss 31.090910
[epoch1, step2750]: loss 36.518532
[epoch1, step2751]: loss 39.384975
[epoch1, step2752]: loss 30.511597
[epoch1, step2753]: loss 43.961292
[epoch1, step2754]: loss 26.225136
[epoch1, step2755]: loss 29.215771
[epoch1, step2756]: loss 15.849195
[epoch1, step2757]: loss 61.166649
[epoch1, step2758]: loss 33.820049
[epoch1, step2759]: loss 42.237938
[epoch1, step2760]: loss 45.453522
[epoch1, step2761]: loss 47.755520
[epoch1, step2762]: loss 46.295059
[epoch1, step2763]: loss 35.545391
[epoch1, step2764]: loss 37.092960
[epoch1, step2765]: loss 7.499530
[epoch1, step2766]: loss 44.874138
[epoch1, step2767]: loss 47.887527
[epoch1, step2768]: loss 47.317776
[epoch1, step2769]: loss 27.084814
[epoch1, step2770]: loss 36.716354
[epoch1, step2771]: loss 50.171616
[epoch1, step2772]: loss 48.217609
[epoch1, step2773]: loss 53.845142
[epoch1, step2774]: loss 44.621037
[epoch1, step2775]: loss 31.828310
[epoch1, step2776]: loss 22.697495
[epoch1, step2777]: loss 52.784199
[epoch1, step2778]: loss 24.809959
[epoch1, step2779]: loss 11.779325
[epoch1, step2780]: loss 45.316437
[epoch1, step2781]: loss 30.785362
[epoch1, step2782]: loss 27.193483
[epoch1, step2783]: loss 35.733871
[epoch1, step2784]: loss 38.113991
[epoch1, step2785]: loss 36.985081
[epoch1, step2786]: loss 44.290146
[epoch1, step2787]: loss 9.612546
[epoch1, step2788]: loss 52.173897
[epoch1, step2789]: loss 38.997311
[epoch1, step2790]: loss 34.885773
[epoch1, step2791]: loss 36.601757
[epoch1, step2792]: loss 21.672901
[epoch1, step2793]: loss 24.663670
[epoch1, step2794]: loss 24.093622
[epoch1, step2795]: loss 32.605534
[epoch1, step2796]: loss 8.175633
[epoch1, step2797]: loss 64.004044
[epoch1, step2798]: loss 38.432949
[epoch1, step2799]: loss 28.163328
[epoch1, step2800]: loss 37.869915
[epoch1, step2801]: loss 20.610537
[epoch1, step2802]: loss 33.806084
[epoch1, step2803]: loss 28.101500
[epoch1, step2804]: loss 33.669666
[epoch1, step2805]: loss 72.774529
[epoch1, step2806]: loss 30.852230
[epoch1, step2807]: loss 53.143864
[epoch1, step2808]: loss 49.027023
[epoch1, step2809]: loss 39.022823
[epoch1, step2810]: loss 23.296804
[epoch1, step2811]: loss 15.342571
[epoch1, step2812]: loss 19.428143
[epoch1, step2813]: loss 22.601025
[epoch1, step2814]: loss 37.131191
[epoch1, step2815]: loss 38.138699
[epoch1, step2816]: loss 34.408344
[epoch1, step2817]: loss 41.767323
[epoch1, step2818]: loss 15.545498
[epoch1, step2819]: loss 43.579876
[epoch1, step2820]: loss 32.042248
[epoch1, step2821]: loss 18.968679
[epoch1, step2822]: loss 28.279099
[epoch1, step2823]: loss 62.200245
[epoch1, step2824]: loss 7.137084
[epoch1, step2825]: loss 38.988689
[epoch1, step2826]: loss 6.992748
[epoch1, step2827]: loss 22.904480
[epoch1, step2828]: loss 27.826988
[epoch1, step2829]: loss 24.856146
[epoch1, step2830]: loss 49.566570
[epoch1, step2831]: loss 21.833677
[epoch1, step2832]: loss 62.526344
[epoch1, step2833]: loss 45.285572
[epoch1, step2834]: loss 31.834330
[epoch1, step2835]: loss 13.438912
[epoch1, step2836]: loss 25.492804
[epoch1, step2837]: loss 44.762436
[epoch1, step2838]: loss 41.477798
[epoch1, step2839]: loss 35.507740
[epoch1, step2840]: loss 38.174755
[epoch1, step2841]: loss 37.815762
[epoch1, step2842]: loss 23.318810
[epoch1, step2843]: loss 62.701759
[epoch1, step2844]: loss 25.840593
[epoch1, step2845]: loss 32.103493
[epoch1, step2846]: loss 43.890274
[epoch1, step2847]: loss 30.624651
[epoch1, step2848]: loss 21.112728
[epoch1, step2849]: loss 38.805733
[epoch1, step2850]: loss 15.235827
[epoch1, step2851]: loss 18.209068
[epoch1, step2852]: loss 42.972332
[epoch1, step2853]: loss 27.925665
[epoch1, step2854]: loss 59.968159
[epoch1, step2855]: loss 18.629892
[epoch1, step2856]: loss 12.114209
[epoch1, step2857]: loss 55.561405
[epoch1, step2858]: loss 28.492979
[epoch1, step2859]: loss 32.317150
[epoch1, step2860]: loss 17.656616
[epoch1, step2861]: loss 49.494530
[epoch1, step2862]: loss 38.525696
[epoch1, step2863]: loss 13.278736
[epoch1, step2864]: loss 24.872589
[epoch1, step2865]: loss 50.753170
[epoch1, step2866]: loss 17.855400
[epoch1, step2867]: loss 49.863148
[epoch1, step2868]: loss 37.110542
[epoch1, step2869]: loss 18.403820
[epoch1, step2870]: loss 20.608463
[epoch1, step2871]: loss 43.558659
[epoch1, step2872]: loss 27.628134
[epoch1, step2873]: loss 43.078728
[epoch1, step2874]: loss 13.245346
[epoch1, step2875]: loss 41.908028
[epoch1, step2876]: loss 39.111790
[epoch1, step2877]: loss 51.153934
[epoch1, step2878]: loss 47.599445
[epoch1, step2879]: loss 30.722467
[epoch1, step2880]: loss 21.947325
[epoch1, step2881]: loss 14.630199
[epoch1, step2882]: loss 32.077702
[epoch1, step2883]: loss 36.243732
[epoch1, step2884]: loss 28.817236
[epoch1, step2885]: loss 74.342819
[epoch1, step2886]: loss 30.005621
[epoch1, step2887]: loss 18.298883
[epoch1, step2888]: loss 31.198854
[epoch1, step2889]: loss 30.381901
[epoch1, step2890]: loss 33.996464
[epoch1, step2891]: loss 40.739639
[epoch1, step2892]: loss 56.001827
[epoch1, step2893]: loss 36.393799
[epoch1, step2894]: loss 72.151596
[epoch1, step2895]: loss 18.151991
[epoch1, step2896]: loss 50.769779
[epoch1, step2897]: loss 22.533497
[epoch1, step2898]: loss 29.836636
[epoch1, step2899]: loss 16.287857
[epoch1, step2900]: loss 50.146557
[epoch1, step2901]: loss 40.866909
[epoch1, step2902]: loss 21.255003
[epoch1, step2903]: loss 29.195341
[epoch1, step2904]: loss 22.279612
[epoch1, step2905]: loss 26.624897
[epoch1, step2906]: loss 27.922155
[epoch1, step2907]: loss 47.450363
[epoch1, step2908]: loss 25.365631
[epoch1, step2909]: loss 32.350353
[epoch1, step2910]: loss 29.171398
[epoch1, step2911]: loss 39.437572
[epoch1, step2912]: loss 48.327686
[epoch1, step2913]: loss 77.924721
[epoch1, step2914]: loss 40.587044
[epoch1, step2915]: loss 38.573021
[epoch1, step2916]: loss 25.645027
[epoch1, step2917]: loss 39.965313
[epoch1, step2918]: loss 30.047567
[epoch1, step2919]: loss 19.958689
[epoch1, step2920]: loss 8.022254
[epoch1, step2921]: loss 41.508900
[epoch1, step2922]: loss 15.178350
[epoch1, step2923]: loss 41.626373
[epoch1, step2924]: loss 5.120090
[epoch1, step2925]: loss 16.991938
[epoch1, step2926]: loss 29.502300
[epoch1, step2927]: loss 29.219940
[epoch1, step2928]: loss 46.978874
[epoch1, step2929]: loss 58.063072
[epoch1, step2930]: loss 14.203232
[epoch1, step2931]: loss 64.205879
[epoch1, step2932]: loss 41.039398
[epoch1, step2933]: loss 59.647667
[epoch1, step2934]: loss 50.491184
[epoch1, step2935]: loss 42.186771
[epoch1, step2936]: loss 15.389270
[epoch1, step2937]: loss 30.485394
[epoch1, step2938]: loss 47.141754
[epoch1, step2939]: loss 41.041168
[epoch1, step2940]: loss 58.251099
[epoch1, step2941]: loss 70.894585
[epoch1, step2942]: loss 35.806396
[epoch1, step2943]: loss 27.229462
[epoch1, step2944]: loss 22.765049
[epoch1, step2945]: loss 36.727768
[epoch1, step2946]: loss 16.395134
[epoch1, step2947]: loss 16.635769
[epoch1, step2948]: loss 32.511330
[epoch1, step2949]: loss 58.716888
[epoch1, step2950]: loss 23.005117
[epoch1, step2951]: loss 56.794384
[epoch1, step2952]: loss 4.868872
[epoch1, step2953]: loss 26.142347
[epoch1, step2954]: loss 27.238880
[epoch1, step2955]: loss 35.694210
[epoch1, step2956]: loss 17.672323
[epoch1, step2957]: loss 26.718279
[epoch1, step2958]: loss 31.625904
[epoch1, step2959]: loss 28.426144
[epoch1, step2960]: loss 31.539087
[epoch1, step2961]: loss 44.342487
[epoch1, step2962]: loss 35.527702
[epoch1, step2963]: loss 34.282696
[epoch1, step2964]: loss 23.888609
[epoch1, step2965]: loss 41.451958
[epoch1, step2966]: loss 34.048267
[epoch1, step2967]: loss 42.349411
[epoch1, step2968]: loss 53.490749
[epoch1, step2969]: loss 34.054100
[epoch1, step2970]: loss 38.952560
[epoch1, step2971]: loss 37.405430
[epoch1, step2972]: loss 61.198151
[epoch1, step2973]: loss 32.918266
[epoch1, step2974]: loss 47.403568
[epoch1, step2975]: loss 12.157468
[epoch1, step2976]: loss 43.698647
[epoch1, step2977]: loss 31.880039
[epoch1, step2978]: loss 6.471488
[epoch1, step2979]: loss 49.776974
[epoch1, step2980]: loss 49.099228
[epoch1, step2981]: loss 16.659367
[epoch1, step2982]: loss 42.068741
[epoch1, step2983]: loss 15.827883
[epoch1, step2984]: loss 24.980400
[epoch1, step2985]: loss 49.428707
[epoch1, step2986]: loss 7.575423
[epoch1, step2987]: loss 33.823269
[epoch1, step2988]: loss 24.481462
[epoch1, step2989]: loss 11.822119
[epoch1, step2990]: loss 41.738102
[epoch1, step2991]: loss 17.821228
[epoch1, step2992]: loss 35.147652
[epoch1, step2993]: loss 48.644436
[epoch1, step2994]: loss 9.820667
[epoch1, step2995]: loss 39.130508
[epoch1, step2996]: loss 72.765793
[epoch1, step2997]: loss 25.293436
[epoch1, step2998]: loss 51.542042
[epoch1, step2999]: loss 28.297138
[epoch1, step3000]: loss 11.044942
[epoch1, step3001]: loss 50.620373
[epoch1, step3002]: loss 26.147581
[epoch1, step3003]: loss 29.910345
[epoch1, step3004]: loss 25.005793
[epoch1, step3005]: loss 51.982430
[epoch1, step3006]: loss 16.155663
[epoch1, step3007]: loss 35.494072
[epoch1, step3008]: loss 17.414454
[epoch1, step3009]: loss 21.440605
[epoch1, step3010]: loss 39.021671
[epoch1, step3011]: loss 6.035509
[epoch1, step3012]: loss 36.292809
[epoch1, step3013]: loss 36.860302
[epoch1, step3014]: loss 53.228603
[epoch1, step3015]: loss 42.102020
[epoch1, step3016]: loss 30.142920
[epoch1, step3017]: loss 37.419521
[epoch1, step3018]: loss 14.277780
[epoch1, step3019]: loss 20.104408
[epoch1, step3020]: loss 23.796743
[epoch1, step3021]: loss 15.935798
[epoch1, step3022]: loss 42.805260
[epoch1, step3023]: loss 37.447220
[epoch1, step3024]: loss 16.414141
[epoch1, step3025]: loss 24.510033
[epoch1, step3026]: loss 43.836281
[epoch1, step3027]: loss 49.640568
[epoch1, step3028]: loss 46.497768
[epoch1, step3029]: loss 16.712925
[epoch1, step3030]: loss 38.495819
[epoch1, step3031]: loss 26.421490
[epoch1, step3032]: loss 32.363014
[epoch1, step3033]: loss 30.903900
[epoch1, step3034]: loss 23.659540
[epoch1, step3035]: loss 39.810165
[epoch1, step3036]: loss 12.601871
[epoch1, step3037]: loss 36.575340
[epoch1, step3038]: loss 36.096790
[epoch1, step3039]: loss 27.733538
[epoch1, step3040]: loss 21.126165
[epoch1, step3041]: loss 35.262569
[epoch1, step3042]: loss 40.396599
[epoch1, step3043]: loss 18.495012
[epoch1, step3044]: loss 25.485949
[epoch1, step3045]: loss 25.429670
[epoch1, step3046]: loss 43.171329
[epoch1, step3047]: loss 32.091248
[epoch1, step3048]: loss 26.941673
[epoch1, step3049]: loss 41.367126
[epoch1, step3050]: loss 27.758450
[epoch1, step3051]: loss 22.626568
[epoch1, step3052]: loss 18.251804
[epoch1, step3053]: loss 50.487015
[epoch1, step3054]: loss 33.223251
[epoch1, step3055]: loss 32.635632
[epoch1, step3056]: loss 54.071365
[epoch1, step3057]: loss 39.225193
[epoch1, step3058]: loss 28.498280
[epoch1, step3059]: loss 35.893986
[epoch1, step3060]: loss 58.008560
[epoch1, step3061]: loss 36.083141
[epoch1, step3062]: loss 35.732220
[epoch1, step3063]: loss 15.101148
[epoch1, step3064]: loss 35.321400
[epoch1, step3065]: loss 37.856857
[epoch1, step3066]: loss 41.584770
[epoch1, step3067]: loss 39.873463
[epoch1, step3068]: loss 55.890259
[epoch1, step3069]: loss 24.595198
[epoch1, step3070]: loss 27.004583
[epoch1, step3071]: loss 44.121021
[epoch1, step3072]: loss 21.694016
[epoch1, step3073]: loss 39.430893
[epoch1, step3074]: loss 30.687454
[epoch1, step3075]: loss 38.652210
[epoch1, step3076]: loss 34.741669

[epoch1]: avg loss 34.741669

[epoch2, step1]: loss 56.339649
[epoch2, step2]: loss 7.704198
[epoch2, step3]: loss 35.730568
[epoch2, step4]: loss 55.568249
[epoch2, step5]: loss 54.601841
[epoch2, step6]: loss 12.369482
[epoch2, step7]: loss 79.044762
[epoch2, step8]: loss 45.526192
[epoch2, step9]: loss 23.327406
[epoch2, step10]: loss 71.682373
[epoch2, step11]: loss 35.612930
[epoch2, step12]: loss 13.413235
[epoch2, step13]: loss 16.608089
[epoch2, step14]: loss 6.075778
[epoch2, step15]: loss 20.178537
[epoch2, step16]: loss 35.617867
[epoch2, step17]: loss 23.853527
[epoch2, step18]: loss 56.301239
[epoch2, step19]: loss 25.297028
[epoch2, step20]: loss 48.241955
[epoch2, step21]: loss 13.312648
[epoch2, step22]: loss 28.776596
[epoch2, step23]: loss 41.250687
[epoch2, step24]: loss 4.891697
[epoch2, step25]: loss 19.913898
[epoch2, step26]: loss 42.103912
[epoch2, step27]: loss 28.332758
[epoch2, step28]: loss 28.418465
[epoch2, step29]: loss 31.707809
[epoch2, step30]: loss 49.554424
[epoch2, step31]: loss 40.307037
[epoch2, step32]: loss 8.690983
[epoch2, step33]: loss 41.817188
[epoch2, step34]: loss 20.333870
[epoch2, step35]: loss 27.268755
[epoch2, step36]: loss 24.910059
[epoch2, step37]: loss 30.653225
[epoch2, step38]: loss 21.364483
[epoch2, step39]: loss 35.978527
[epoch2, step40]: loss 43.627487
[epoch2, step41]: loss 12.324672
[epoch2, step42]: loss 17.899643
[epoch2, step43]: loss 33.586761
[epoch2, step44]: loss 44.499485
[epoch2, step45]: loss 92.496124
[epoch2, step46]: loss 25.308872
[epoch2, step47]: loss 49.792389
[epoch2, step48]: loss 39.171917
[epoch2, step49]: loss 27.307777
[epoch2, step50]: loss 24.798222
[epoch2, step51]: loss 23.125614
[epoch2, step52]: loss 38.494972
[epoch2, step53]: loss 23.321445
[epoch2, step54]: loss 8.922650
[epoch2, step55]: loss 26.958939
[epoch2, step56]: loss 62.497643
[epoch2, step57]: loss 45.292973
[epoch2, step58]: loss 30.645752
[epoch2, step59]: loss 29.093149
[epoch2, step60]: loss 43.484215
[epoch2, step61]: loss 16.791239
[epoch2, step62]: loss 50.138481
[epoch2, step63]: loss 39.426350
[epoch2, step64]: loss 53.137253
[epoch2, step65]: loss 32.036575
[epoch2, step66]: loss 14.190987
[epoch2, step67]: loss 24.499605
[epoch2, step68]: loss 40.664688
[epoch2, step69]: loss 23.711704
[epoch2, step70]: loss 35.444912
[epoch2, step71]: loss 33.424561
[epoch2, step72]: loss 33.869141
[epoch2, step73]: loss 25.499834
[epoch2, step74]: loss 26.710583
[epoch2, step75]: loss 49.708031
[epoch2, step76]: loss 14.798094
[epoch2, step77]: loss 12.439495
[epoch2, step78]: loss 40.007450
[epoch2, step79]: loss 32.391357
[epoch2, step80]: loss 14.293116
[epoch2, step81]: loss 13.714178
[epoch2, step82]: loss 32.648689
[epoch2, step83]: loss 37.021721
[epoch2, step84]: loss 25.927296
[epoch2, step85]: loss 21.821600
[epoch2, step86]: loss 15.478045
[epoch2, step87]: loss 62.700367
[epoch2, step88]: loss 26.452709
[epoch2, step89]: loss 27.402632
[epoch2, step90]: loss 82.089760
[epoch2, step91]: loss 29.406425
[epoch2, step92]: loss 35.708591
[epoch2, step93]: loss 21.743214
[epoch2, step94]: loss 23.301924
[epoch2, step95]: loss 24.993164
[epoch2, step96]: loss 39.998772
[epoch2, step97]: loss 36.356930
[epoch2, step98]: loss 36.092712
[epoch2, step99]: loss 41.674999
[epoch2, step100]: loss 42.289627
[epoch2, step101]: loss 39.221786
[epoch2, step102]: loss 51.410633
[epoch2, step103]: loss 42.529144
[epoch2, step104]: loss 17.047272
[epoch2, step105]: loss 15.410531
[epoch2, step106]: loss 73.351997
[epoch2, step107]: loss 15.291419
[epoch2, step108]: loss 37.659317
[epoch2, step109]: loss 48.337292
[epoch2, step110]: loss 38.545658
[epoch2, step111]: loss 30.164211
[epoch2, step112]: loss 46.435352
[epoch2, step113]: loss 52.615799
[epoch2, step114]: loss 15.444646
[epoch2, step115]: loss 28.765139
[epoch2, step116]: loss 64.453636
[epoch2, step117]: loss 11.292698
[epoch2, step118]: loss 42.248131
[epoch2, step119]: loss 42.670547
[epoch2, step120]: loss 59.525311
[epoch2, step121]: loss 32.451168
[epoch2, step122]: loss 33.652229
[epoch2, step123]: loss 15.725892
[epoch2, step124]: loss 55.322510
[epoch2, step125]: loss 29.075808
[epoch2, step126]: loss 16.631010
[epoch2, step127]: loss 29.603905
[epoch2, step128]: loss 38.909519
[epoch2, step129]: loss 61.238853
[epoch2, step130]: loss 9.857049
[epoch2, step131]: loss 26.203297
[epoch2, step132]: loss 34.092957
[epoch2, step133]: loss 46.403641
[epoch2, step134]: loss 29.565525
[epoch2, step135]: loss 31.476955
[epoch2, step136]: loss 28.195318
[epoch2, step137]: loss 68.334396
[epoch2, step138]: loss 31.640509
[epoch2, step139]: loss 47.235146
[epoch2, step140]: loss 25.198368
[epoch2, step141]: loss 14.843244
[epoch2, step142]: loss 20.244427
[epoch2, step143]: loss 36.303768
[epoch2, step144]: loss 33.142242
[epoch2, step145]: loss 19.837530
[epoch2, step146]: loss 34.219254
[epoch2, step147]: loss 29.395809
[epoch2, step148]: loss 21.504234
[epoch2, step149]: loss 39.679626
[epoch2, step150]: loss 16.450291
[epoch2, step151]: loss 4.959369
[epoch2, step152]: loss 21.002953
[epoch2, step153]: loss 28.020559
[epoch2, step154]: loss 28.927984
[epoch2, step155]: loss 13.729187
[epoch2, step156]: loss 18.650818
[epoch2, step157]: loss 48.463879
[epoch2, step158]: loss 13.389418
[epoch2, step159]: loss 27.443592
[epoch2, step160]: loss 17.412151
[epoch2, step161]: loss 54.220486
[epoch2, step162]: loss 39.122097
[epoch2, step163]: loss 34.681229
[epoch2, step164]: loss 25.383310
[epoch2, step165]: loss 31.188089
[epoch2, step166]: loss 27.738981
[epoch2, step167]: loss 27.354063
[epoch2, step168]: loss 29.919132
[epoch2, step169]: loss 44.184410
[epoch2, step170]: loss 49.029499
[epoch2, step171]: loss 23.823385
[epoch2, step172]: loss 60.648960
[epoch2, step173]: loss 34.969288
[epoch2, step174]: loss 41.831100
[epoch2, step175]: loss 65.192047
[epoch2, step176]: loss 50.949490
[epoch2, step177]: loss 26.346764
[epoch2, step178]: loss 34.536026
[epoch2, step179]: loss 16.231228
[epoch2, step180]: loss 41.029522
[epoch2, step181]: loss 36.631470
[epoch2, step182]: loss 29.873266
[epoch2, step183]: loss 87.680519
[epoch2, step184]: loss 24.147118
[epoch2, step185]: loss 30.546360
[epoch2, step186]: loss 26.595816
[epoch2, step187]: loss 37.174324
[epoch2, step188]: loss 33.568111
[epoch2, step189]: loss 11.968896
[epoch2, step190]: loss 13.281066
[epoch2, step191]: loss 32.215549
[epoch2, step192]: loss 43.501789
[epoch2, step193]: loss 29.163574
[epoch2, step194]: loss 36.423561
[epoch2, step195]: loss 28.128315
[epoch2, step196]: loss 53.094692
[epoch2, step197]: loss 25.795351
[epoch2, step198]: loss 33.397522
[epoch2, step199]: loss 18.984436
[epoch2, step200]: loss 35.616371
[epoch2, step201]: loss 19.657223
[epoch2, step202]: loss 14.920489
[epoch2, step203]: loss 10.991129
[epoch2, step204]: loss 19.336529
[epoch2, step205]: loss 33.165573
[epoch2, step206]: loss 42.051674
[epoch2, step207]: loss 14.538591
[epoch2, step208]: loss 32.380836
[epoch2, step209]: loss 6.909144
[epoch2, step210]: loss 16.574776
[epoch2, step211]: loss 31.813454
[epoch2, step212]: loss 31.705126
[epoch2, step213]: loss 48.344128
[epoch2, step214]: loss 10.525795
[epoch2, step215]: loss 37.151699
[epoch2, step216]: loss 33.671837
[epoch2, step217]: loss 24.976931
[epoch2, step218]: loss 32.604198
[epoch2, step219]: loss 40.244991
[epoch2, step220]: loss 28.921257
[epoch2, step221]: loss 18.988029
[epoch2, step222]: loss 15.090600
[epoch2, step223]: loss 28.797354
[epoch2, step224]: loss 13.499585
[epoch2, step225]: loss 29.655123
[epoch2, step226]: loss 52.228512
[epoch2, step227]: loss 36.717945
[epoch2, step228]: loss 56.254356
[epoch2, step229]: loss 24.791632
[epoch2, step230]: loss 33.310730
[epoch2, step231]: loss 28.541882
[epoch2, step232]: loss 28.420973
[epoch2, step233]: loss 14.189275
[epoch2, step234]: loss 35.216885
[epoch2, step235]: loss 7.363310
[epoch2, step236]: loss 22.765097
[epoch2, step237]: loss 4.839820
[epoch2, step238]: loss 28.542105
[epoch2, step239]: loss 38.883430
[epoch2, step240]: loss 20.055687
[epoch2, step241]: loss 46.398979
[epoch2, step242]: loss 50.400223
[epoch2, step243]: loss 37.527744
[epoch2, step244]: loss 9.331883
[epoch2, step245]: loss 14.309813
[epoch2, step246]: loss 45.902531
[epoch2, step247]: loss 13.497397
[epoch2, step248]: loss 26.070023
[epoch2, step249]: loss 28.541765
[epoch2, step250]: loss 38.329308
[epoch2, step251]: loss 12.755147
[epoch2, step252]: loss 52.684788
[epoch2, step253]: loss 35.654121
[epoch2, step254]: loss 60.100533
[epoch2, step255]: loss 38.665237
[epoch2, step256]: loss 50.359959
[epoch2, step257]: loss 16.031431
[epoch2, step258]: loss 16.288925
[epoch2, step259]: loss 16.020823
[epoch2, step260]: loss 22.660362
[epoch2, step261]: loss 39.052273
[epoch2, step262]: loss 24.470154
[epoch2, step263]: loss 38.904812
[epoch2, step264]: loss 18.984524
[epoch2, step265]: loss 18.121656
[epoch2, step266]: loss 26.523470
[epoch2, step267]: loss 37.809952
[epoch2, step268]: loss 38.680088
[epoch2, step269]: loss 24.643665
[epoch2, step270]: loss 8.711798
[epoch2, step271]: loss 20.090958
[epoch2, step272]: loss 30.882837
[epoch2, step273]: loss 18.540241
[epoch2, step274]: loss 34.959625
[epoch2, step275]: loss 63.871552
[epoch2, step276]: loss 34.308121
[epoch2, step277]: loss 31.706362
[epoch2, step278]: loss 23.832312
[epoch2, step279]: loss 25.947157
[epoch2, step280]: loss 9.963122
[epoch2, step281]: loss 8.307959
[epoch2, step282]: loss 22.221239
[epoch2, step283]: loss 20.335548
[epoch2, step284]: loss 21.457296
[epoch2, step285]: loss 29.000963
[epoch2, step286]: loss 33.465805
[epoch2, step287]: loss 27.087175
[epoch2, step288]: loss 33.249992
[epoch2, step289]: loss 23.991365
[epoch2, step290]: loss 28.477205
[epoch2, step291]: loss 38.081692
[epoch2, step292]: loss 26.128757
[epoch2, step293]: loss 32.886421
[epoch2, step294]: loss 50.300175
[epoch2, step295]: loss 24.696297
[epoch2, step296]: loss 43.787663
[epoch2, step297]: loss 3.389308
[epoch2, step298]: loss 28.661375
[epoch2, step299]: loss 13.110497
[epoch2, step300]: loss 35.666916
[epoch2, step301]: loss 43.166042
[epoch2, step302]: loss 30.190256
[epoch2, step303]: loss 14.162800
[epoch2, step304]: loss 25.218082
[epoch2, step305]: loss 35.053059
[epoch2, step306]: loss 32.701965
[epoch2, step307]: loss 37.651302
[epoch2, step308]: loss 42.783596
[epoch2, step309]: loss 57.727688
[epoch2, step310]: loss 4.029289
[epoch2, step311]: loss 27.643150
[epoch2, step312]: loss 15.039299
[epoch2, step313]: loss 29.374174
[epoch2, step314]: loss 35.080753
[epoch2, step315]: loss 15.773470
[epoch2, step316]: loss 29.471117
[epoch2, step317]: loss 16.817526
[epoch2, step318]: loss 53.517124
[epoch2, step319]: loss 78.046150
[epoch2, step320]: loss 13.386256
[epoch2, step321]: loss 20.656256
[epoch2, step322]: loss 14.287224
[epoch2, step323]: loss 34.921284
[epoch2, step324]: loss 25.755594
[epoch2, step325]: loss 38.914276
[epoch2, step326]: loss 25.054560
[epoch2, step327]: loss 29.175745
[epoch2, step328]: loss 29.639591
[epoch2, step329]: loss 21.006878
[epoch2, step330]: loss 27.186014
[epoch2, step331]: loss 24.412931
[epoch2, step332]: loss 20.009245
[epoch2, step333]: loss 45.331493
[epoch2, step334]: loss 48.158489
[epoch2, step335]: loss 19.586586
[epoch2, step336]: loss 21.621143
[epoch2, step337]: loss 54.035744
[epoch2, step338]: loss 24.524090
[epoch2, step339]: loss 33.109779
[epoch2, step340]: loss 21.120733
[epoch2, step341]: loss 27.663847
[epoch2, step342]: loss 45.963631
[epoch2, step343]: loss 29.488941
[epoch2, step344]: loss 40.507378
[epoch2, step345]: loss 39.379452
[epoch2, step346]: loss 12.220821
[epoch2, step347]: loss 19.656828
[epoch2, step348]: loss 36.956047
[epoch2, step349]: loss 25.521214
[epoch2, step350]: loss 55.931793
[epoch2, step351]: loss 39.456242
[epoch2, step352]: loss 9.378233
[epoch2, step353]: loss 23.746840
[epoch2, step354]: loss 30.986738
[epoch2, step355]: loss 19.285364
[epoch2, step356]: loss 29.673557
[epoch2, step357]: loss 21.348015
[epoch2, step358]: loss 30.401432
[epoch2, step359]: loss 13.922934
[epoch2, step360]: loss 32.498764
[epoch2, step361]: loss 27.661648
[epoch2, step362]: loss 26.818727
[epoch2, step363]: loss 16.975250
[epoch2, step364]: loss 29.975935
[epoch2, step365]: loss 31.903614
[epoch2, step366]: loss 10.370730
[epoch2, step367]: loss 44.595608
[epoch2, step368]: loss 41.963741
[epoch2, step369]: loss 38.491383
[epoch2, step370]: loss 30.954020
[epoch2, step371]: loss 49.261143
[epoch2, step372]: loss 37.306747
[epoch2, step373]: loss 17.827209
[epoch2, step374]: loss 13.818857
[epoch2, step375]: loss 18.550215
[epoch2, step376]: loss 13.656848
[epoch2, step377]: loss 18.449913
[epoch2, step378]: loss 19.646770
[epoch2, step379]: loss 8.942659
[epoch2, step380]: loss 23.493490
[epoch2, step381]: loss 24.769802
[epoch2, step382]: loss 15.169354
[epoch2, step383]: loss 16.958063
[epoch2, step384]: loss 20.977707
[epoch2, step385]: loss 7.908228
[epoch2, step386]: loss 31.685530
[epoch2, step387]: loss 17.591398
[epoch2, step388]: loss 33.612541
[epoch2, step389]: loss 17.679605
[epoch2, step390]: loss 13.323824
[epoch2, step391]: loss 23.922653
[epoch2, step392]: loss 48.462063
[epoch2, step393]: loss 26.696846
[epoch2, step394]: loss 44.957951
[epoch2, step395]: loss 23.026659
[epoch2, step396]: loss 42.428970
[epoch2, step397]: loss 7.181789
[epoch2, step398]: loss 16.425404
[epoch2, step399]: loss 52.338848
[epoch2, step400]: loss 20.757378
[epoch2, step401]: loss 34.933140
[epoch2, step402]: loss 27.114506
[epoch2, step403]: loss 20.098141
[epoch2, step404]: loss 38.076046
[epoch2, step405]: loss 46.262001
[epoch2, step406]: loss 24.335569
[epoch2, step407]: loss 8.949017
[epoch2, step408]: loss 49.174679
[epoch2, step409]: loss 18.247320
[epoch2, step410]: loss 20.725624
[epoch2, step411]: loss 17.714182
[epoch2, step412]: loss 19.980478
[epoch2, step413]: loss 23.136465
[epoch2, step414]: loss 13.422439
[epoch2, step415]: loss 22.319691
[epoch2, step416]: loss 19.451727
[epoch2, step417]: loss 21.347153
[epoch2, step418]: loss 28.090004
[epoch2, step419]: loss 40.305336
[epoch2, step420]: loss 15.784903
[epoch2, step421]: loss 33.492161
[epoch2, step422]: loss 35.342052
[epoch2, step423]: loss 18.451368
[epoch2, step424]: loss 14.529362
[epoch2, step425]: loss 11.158841
[epoch2, step426]: loss 20.374615
[epoch2, step427]: loss 18.913544
[epoch2, step428]: loss 6.461454
[epoch2, step429]: loss 23.551851
[epoch2, step430]: loss 22.341011
[epoch2, step431]: loss 38.688232
[epoch2, step432]: loss 35.382687
[epoch2, step433]: loss 15.289994
[epoch2, step434]: loss 36.939095
[epoch2, step435]: loss 9.934752
[epoch2, step436]: loss 33.323963
[epoch2, step437]: loss 18.274174
[epoch2, step438]: loss 29.712009
[epoch2, step439]: loss 8.856104
[epoch2, step440]: loss 46.388378
[epoch2, step441]: loss 12.729527
[epoch2, step442]: loss 38.843529
[epoch2, step443]: loss 38.224514
[epoch2, step444]: loss 25.059198
[epoch2, step445]: loss 14.488389
[epoch2, step446]: loss 17.877836
[epoch2, step447]: loss 31.735420
[epoch2, step448]: loss 33.986008
[epoch2, step449]: loss 15.697453
[epoch2, step450]: loss 16.795023
[epoch2, step451]: loss 10.786024
[epoch2, step452]: loss 42.176716
[epoch2, step453]: loss 17.192743
[epoch2, step454]: loss 51.303738
[epoch2, step455]: loss 18.963131
[epoch2, step456]: loss 14.312430
[epoch2, step457]: loss 26.174860
[epoch2, step458]: loss 19.807127
[epoch2, step459]: loss 32.333271
[epoch2, step460]: loss 15.614683
[epoch2, step461]: loss 30.299719
[epoch2, step462]: loss 16.788950
[epoch2, step463]: loss 7.534653
[epoch2, step464]: loss 12.186827
[epoch2, step465]: loss 22.218082
[epoch2, step466]: loss 12.926095
[epoch2, step467]: loss 31.983517
[epoch2, step468]: loss 14.087337
[epoch2, step469]: loss 18.382673
[epoch2, step470]: loss 24.647655
[epoch2, step471]: loss 31.452602
[epoch2, step472]: loss 24.348749
[epoch2, step473]: loss 53.417786
[epoch2, step474]: loss 47.106918
[epoch2, step475]: loss 17.770401
[epoch2, step476]: loss 30.047340
[epoch2, step477]: loss 9.194930
[epoch2, step478]: loss 15.050542
[epoch2, step479]: loss 10.951696
[epoch2, step480]: loss 35.057980
[epoch2, step481]: loss 28.596952
[epoch2, step482]: loss 13.789588
[epoch2, step483]: loss 12.325540
[epoch2, step484]: loss 30.464638
[epoch2, step485]: loss 29.671362
[epoch2, step486]: loss 23.974806
[epoch2, step487]: loss 25.720390
[epoch2, step488]: loss 25.416578
[epoch2, step489]: loss 27.120672
[epoch2, step490]: loss 24.541660
[epoch2, step491]: loss 20.298628
[epoch2, step492]: loss 15.777737
[epoch2, step493]: loss 38.060165
[epoch2, step494]: loss 20.371637
[epoch2, step495]: loss 20.942785
[epoch2, step496]: loss 19.348537
[epoch2, step497]: loss 27.018217
[epoch2, step498]: loss 28.903519
[epoch2, step499]: loss 24.037365
[epoch2, step500]: loss 17.946339
[epoch2, step501]: loss 21.458694
[epoch2, step502]: loss 11.635798
[epoch2, step503]: loss 28.319567
[epoch2, step504]: loss 33.944756
[epoch2, step505]: loss 27.261374
[epoch2, step506]: loss 13.662157
[epoch2, step507]: loss 28.850042
[epoch2, step508]: loss 44.988667
[epoch2, step509]: loss 32.284111
[epoch2, step510]: loss 35.654209
[epoch2, step511]: loss 51.226017
[epoch2, step512]: loss 21.583832
[epoch2, step513]: loss 16.669062
[epoch2, step514]: loss 10.850828
[epoch2, step515]: loss 20.988720
[epoch2, step516]: loss 22.221949
[epoch2, step517]: loss 44.804260
[epoch2, step518]: loss 29.161165
[epoch2, step519]: loss 17.014832
[epoch2, step520]: loss 10.991676
[epoch2, step521]: loss 30.451090
[epoch2, step522]: loss 13.817604
[epoch2, step523]: loss 5.037242
[epoch2, step524]: loss 23.545490
[epoch2, step525]: loss 24.942266
[epoch2, step526]: loss 26.469448
[epoch2, step527]: loss 35.167072
[epoch2, step528]: loss 18.878502
[epoch2, step529]: loss 21.308483
[epoch2, step530]: loss 49.936680
[epoch2, step531]: loss 9.090792
[epoch2, step532]: loss 45.722176
[epoch2, step533]: loss 20.025339
[epoch2, step534]: loss 22.499632
[epoch2, step535]: loss 10.913183
[epoch2, step536]: loss 14.857286
[epoch2, step537]: loss 31.368448
[epoch2, step538]: loss 26.228449
[epoch2, step539]: loss 17.079420
[epoch2, step540]: loss 7.290491
[epoch2, step541]: loss 24.709642
[epoch2, step542]: loss 9.216572
[epoch2, step543]: loss 30.200600
[epoch2, step544]: loss 17.447868
[epoch2, step545]: loss 45.238392
[epoch2, step546]: loss 24.619320
[epoch2, step547]: loss 18.610727
[epoch2, step548]: loss 16.889906
[epoch2, step549]: loss 21.302868
[epoch2, step550]: loss 39.730457
[epoch2, step551]: loss 38.156322
[epoch2, step552]: loss 15.722329
[epoch2, step553]: loss 41.703857
[epoch2, step554]: loss 30.481329
[epoch2, step555]: loss 12.849348
[epoch2, step556]: loss 11.136594
[epoch2, step557]: loss 13.164452
[epoch2, step558]: loss 29.335035
[epoch2, step559]: loss 37.974716
[epoch2, step560]: loss 19.434505
[epoch2, step561]: loss 17.546118
[epoch2, step562]: loss 11.697975
[epoch2, step563]: loss 16.408882
[epoch2, step564]: loss 10.044841
[epoch2, step565]: loss 33.033463
[epoch2, step566]: loss 12.002726
[epoch2, step567]: loss 45.879635
[epoch2, step568]: loss 33.388695
[epoch2, step569]: loss 39.645462
[epoch2, step570]: loss 19.124983
[epoch2, step571]: loss 15.273415
[epoch2, step572]: loss 15.005972
[epoch2, step573]: loss 36.484016
[epoch2, step574]: loss 35.488876
[epoch2, step575]: loss 25.053265
[epoch2, step576]: loss 46.485790
[epoch2, step577]: loss 17.869101
[epoch2, step578]: loss 26.480555
[epoch2, step579]: loss 24.434687
[epoch2, step580]: loss 11.485052
[epoch2, step581]: loss 64.980827
[epoch2, step582]: loss 8.279600
[epoch2, step583]: loss 35.977898
[epoch2, step584]: loss 15.686254
[epoch2, step585]: loss 26.505726
[epoch2, step586]: loss 9.378590
[epoch2, step587]: loss 32.638245
[epoch2, step588]: loss 37.717403
[epoch2, step589]: loss 11.544050
[epoch2, step590]: loss 46.573391
[epoch2, step591]: loss 13.813694
[epoch2, step592]: loss 33.821239
[epoch2, step593]: loss 44.629005
[epoch2, step594]: loss 11.306696
[epoch2, step595]: loss 22.905050
[epoch2, step596]: loss 27.385185
[epoch2, step597]: loss 40.154091
[epoch2, step598]: loss 28.378620
[epoch2, step599]: loss 53.437222
[epoch2, step600]: loss 44.733597
[epoch2, step601]: loss 24.867805
[epoch2, step602]: loss 15.016163
[epoch2, step603]: loss 44.872604
[epoch2, step604]: loss 16.379572
[epoch2, step605]: loss 21.593891
[epoch2, step606]: loss 28.923296
[epoch2, step607]: loss 25.718796
[epoch2, step608]: loss 40.630772
[epoch2, step609]: loss 21.952381
[epoch2, step610]: loss 7.080344
[epoch2, step611]: loss 55.796268
[epoch2, step612]: loss 12.470496
[epoch2, step613]: loss 16.216244
[epoch2, step614]: loss 8.111552
[epoch2, step615]: loss 15.406733
[epoch2, step616]: loss 23.435394
[epoch2, step617]: loss 20.852076
[epoch2, step618]: loss 17.647503
[epoch2, step619]: loss 30.740427
[epoch2, step620]: loss 20.223026
[epoch2, step621]: loss 38.000790
[epoch2, step622]: loss 4.469603
[epoch2, step623]: loss 26.063690
[epoch2, step624]: loss 23.862694
[epoch2, step625]: loss 45.522236
[epoch2, step626]: loss 31.252001
[epoch2, step627]: loss 12.960248
[epoch2, step628]: loss 21.062864
[epoch2, step629]: loss 13.388290
[epoch2, step630]: loss 20.778242
[epoch2, step631]: loss 16.077410
[epoch2, step632]: loss 24.437899
[epoch2, step633]: loss 24.721630
[epoch2, step634]: loss 17.122135
[epoch2, step635]: loss 31.833176
[epoch2, step636]: loss 8.038559
[epoch2, step637]: loss 26.910336
[epoch2, step638]: loss 12.179767
[epoch2, step639]: loss 18.907591
[epoch2, step640]: loss 26.931099
[epoch2, step641]: loss 13.369475
[epoch2, step642]: loss 18.436724
[epoch2, step643]: loss 23.434231
[epoch2, step644]: loss 26.390305
[epoch2, step645]: loss 29.545490
[epoch2, step646]: loss 24.460928
[epoch2, step647]: loss 23.118547
[epoch2, step648]: loss 12.774144
[epoch2, step649]: loss 12.697829
[epoch2, step650]: loss 39.295357
[epoch2, step651]: loss 8.938061
[epoch2, step652]: loss 26.980459
[epoch2, step653]: loss 18.750771
[epoch2, step654]: loss 9.850874
[epoch2, step655]: loss 18.319088
[epoch2, step656]: loss 15.001441
[epoch2, step657]: loss 22.115931
[epoch2, step658]: loss 5.508850
[epoch2, step659]: loss 26.768835
[epoch2, step660]: loss 36.504993
[epoch2, step661]: loss 32.393620
[epoch2, step662]: loss 22.013138
[epoch2, step663]: loss 25.844187
[epoch2, step664]: loss 22.136257
[epoch2, step665]: loss 43.547287
[epoch2, step666]: loss 5.471861
[epoch2, step667]: loss 10.180903
[epoch2, step668]: loss 36.252636
[epoch2, step669]: loss 19.027893
[epoch2, step670]: loss 12.570740
[epoch2, step671]: loss 34.670959
[epoch2, step672]: loss 31.369106
[epoch2, step673]: loss 11.590277
[epoch2, step674]: loss 11.826344
[epoch2, step675]: loss 12.694028
[epoch2, step676]: loss 37.394230
[epoch2, step677]: loss 37.138248
[epoch2, step678]: loss 55.587711
[epoch2, step679]: loss 12.201649
[epoch2, step680]: loss 40.331406
[epoch2, step681]: loss 8.052572
[epoch2, step682]: loss 15.744366
[epoch2, step683]: loss 24.366932
[epoch2, step684]: loss 22.971169
[epoch2, step685]: loss 19.630531
[epoch2, step686]: loss 27.704340
[epoch2, step687]: loss 5.389006
[epoch2, step688]: loss 14.967464
[epoch2, step689]: loss 59.945919
[epoch2, step690]: loss 9.642565
[epoch2, step691]: loss 30.587574
[epoch2, step692]: loss 4.398621
[epoch2, step693]: loss 14.943897
[epoch2, step694]: loss 18.444002
[epoch2, step695]: loss 18.768406
[epoch2, step696]: loss 17.378088
[epoch2, step697]: loss 22.947392
[epoch2, step698]: loss 33.351784
[epoch2, step699]: loss 31.831709
[epoch2, step700]: loss 19.219902
[epoch2, step701]: loss 51.683884
[epoch2, step702]: loss 20.203722
[epoch2, step703]: loss 23.287592
[epoch2, step704]: loss 10.651025
[epoch2, step705]: loss 33.017807
[epoch2, step706]: loss 23.524637
[epoch2, step707]: loss 26.546286
[epoch2, step708]: loss 30.139437
[epoch2, step709]: loss 28.054552
[epoch2, step710]: loss 15.116982
[epoch2, step711]: loss 10.415359
[epoch2, step712]: loss 5.503851
[epoch2, step713]: loss 24.389351
[epoch2, step714]: loss 31.529638
[epoch2, step715]: loss 17.437469
[epoch2, step716]: loss 26.133999
[epoch2, step717]: loss 62.359211
[epoch2, step718]: loss 19.188629
[epoch2, step719]: loss 29.186529
[epoch2, step720]: loss 22.691391
[epoch2, step721]: loss 27.854086
[epoch2, step722]: loss 45.719753
[epoch2, step723]: loss 38.809280
[epoch2, step724]: loss 16.250381
[epoch2, step725]: loss 25.080441
[epoch2, step726]: loss 30.752340
[epoch2, step727]: loss 15.038120
[epoch2, step728]: loss 23.254381
[epoch2, step729]: loss 92.520920
[epoch2, step730]: loss 29.982622
[epoch2, step731]: loss 12.420654
[epoch2, step732]: loss 25.231585
[epoch2, step733]: loss 22.466042
[epoch2, step734]: loss 37.149677
[epoch2, step735]: loss 13.265128
[epoch2, step736]: loss 38.770779
[epoch2, step737]: loss 27.310501
[epoch2, step738]: loss 31.330660
[epoch2, step739]: loss 16.332806
[epoch2, step740]: loss 46.629196
[epoch2, step741]: loss 30.698008
[epoch2, step742]: loss 17.890253
[epoch2, step743]: loss 9.025931
[epoch2, step744]: loss 22.279398
[epoch2, step745]: loss 14.022463
[epoch2, step746]: loss 17.394674
[epoch2, step747]: loss 36.386936
[epoch2, step748]: loss 8.281686
[epoch2, step749]: loss 28.564463
[epoch2, step750]: loss 17.419147
[epoch2, step751]: loss 15.866808
[epoch2, step752]: loss 21.956310
[epoch2, step753]: loss 23.261021
[epoch2, step754]: loss 9.187135
[epoch2, step755]: loss 22.968796
[epoch2, step756]: loss 15.500128
[epoch2, step757]: loss 19.183966
[epoch2, step758]: loss 16.789087
[epoch2, step759]: loss 25.250128
[epoch2, step760]: loss 39.681503
[epoch2, step761]: loss 20.445612
[epoch2, step762]: loss 30.137365
[epoch2, step763]: loss 13.914290
[epoch2, step764]: loss 14.180093
[epoch2, step765]: loss 33.064060
[epoch2, step766]: loss 29.505577
[epoch2, step767]: loss 11.300799
[epoch2, step768]: loss 14.070243
[epoch2, step769]: loss 12.572113
[epoch2, step770]: loss 26.058908
[epoch2, step771]: loss 57.930645
[epoch2, step772]: loss 17.627392
[epoch2, step773]: loss 33.687313
[epoch2, step774]: loss 29.915501
[epoch2, step775]: loss 13.396839
[epoch2, step776]: loss 21.385719
[epoch2, step777]: loss 10.709885
[epoch2, step778]: loss 14.732718
[epoch2, step779]: loss 8.323221
[epoch2, step780]: loss 37.746601
[epoch2, step781]: loss 20.485353
[epoch2, step782]: loss 32.925060
[epoch2, step783]: loss 25.602560
[epoch2, step784]: loss 20.882231
[epoch2, step785]: loss 15.777682
[epoch2, step786]: loss 30.281776
[epoch2, step787]: loss 9.077891
[epoch2, step788]: loss 7.447691
[epoch2, step789]: loss 25.351831
[epoch2, step790]: loss 24.280901
[epoch2, step791]: loss 22.738247
[epoch2, step792]: loss 11.189850
[epoch2, step793]: loss 12.925758
[epoch2, step794]: loss 11.972430
[epoch2, step795]: loss 31.093786
[epoch2, step796]: loss 30.026485
[epoch2, step797]: loss 13.510341
[epoch2, step798]: loss 33.641201
[epoch2, step799]: loss 6.799356
[epoch2, step800]: loss 22.644854
[epoch2, step801]: loss 25.847061
[epoch2, step802]: loss 36.584892
[epoch2, step803]: loss 23.153547
[epoch2, step804]: loss 50.418476
[epoch2, step805]: loss 36.516640
[epoch2, step806]: loss 33.512024
[epoch2, step807]: loss 34.113613
[epoch2, step808]: loss 33.855217
[epoch2, step809]: loss 29.232595
[epoch2, step810]: loss 21.671913
[epoch2, step811]: loss 43.067631
[epoch2, step812]: loss 24.531870
[epoch2, step813]: loss 32.101917
[epoch2, step814]: loss 23.013170
[epoch2, step815]: loss 34.583717
[epoch2, step816]: loss 34.785496
[epoch2, step817]: loss 17.198441
[epoch2, step818]: loss 28.444965
[epoch2, step819]: loss 14.005183
[epoch2, step820]: loss 36.233921
[epoch2, step821]: loss 17.646370
[epoch2, step822]: loss 25.573902
[epoch2, step823]: loss 40.836811
[epoch2, step824]: loss 6.113616
[epoch2, step825]: loss 25.101135
[epoch2, step826]: loss 16.755531
[epoch2, step827]: loss 28.751760
[epoch2, step828]: loss 4.562932
[epoch2, step829]: loss 32.274391
[epoch2, step830]: loss 33.291172
[epoch2, step831]: loss 21.384586
[epoch2, step832]: loss 33.525211
[epoch2, step833]: loss 25.880020
[epoch2, step834]: loss 22.162197
[epoch2, step835]: loss 21.451361
[epoch2, step836]: loss 13.689157
[epoch2, step837]: loss 26.699570
[epoch2, step838]: loss 13.797768
[epoch2, step839]: loss 24.499987
[epoch2, step840]: loss 18.080305
[epoch2, step841]: loss 70.088722
[epoch2, step842]: loss 36.486534
[epoch2, step843]: loss 15.674803
[epoch2, step844]: loss 7.252420
[epoch2, step845]: loss 17.860271
[epoch2, step846]: loss 25.484016
[epoch2, step847]: loss 28.700359
[epoch2, step848]: loss 8.542484
[epoch2, step849]: loss 28.277477
[epoch2, step850]: loss 9.960309
[epoch2, step851]: loss 8.601412
[epoch2, step852]: loss 10.878797
[epoch2, step853]: loss 9.682494
[epoch2, step854]: loss 21.277340
[epoch2, step855]: loss 8.945430
[epoch2, step856]: loss 5.308182
[epoch2, step857]: loss 7.579705
[epoch2, step858]: loss 14.281477
[epoch2, step859]: loss 10.483774
[epoch2, step860]: loss 27.597221
[epoch2, step861]: loss 19.182308
[epoch2, step862]: loss 34.006287
[epoch2, step863]: loss 9.414308
[epoch2, step864]: loss 20.496008
[epoch2, step865]: loss 17.380829
[epoch2, step866]: loss 28.472712
[epoch2, step867]: loss 10.104815
[epoch2, step868]: loss 14.829273
[epoch2, step869]: loss 61.235054
[epoch2, step870]: loss 13.488890
[epoch2, step871]: loss 30.167074
[epoch2, step872]: loss 32.129951
[epoch2, step873]: loss 25.346565
[epoch2, step874]: loss 7.830459
[epoch2, step875]: loss 10.314574
[epoch2, step876]: loss 15.152928
[epoch2, step877]: loss 13.932837
[epoch2, step878]: loss 57.139320
[epoch2, step879]: loss 20.938358
[epoch2, step880]: loss 9.659467
[epoch2, step881]: loss 16.324383
[epoch2, step882]: loss 46.418221
[epoch2, step883]: loss 51.090240
[epoch2, step884]: loss 22.227825
[epoch2, step885]: loss 11.005965
[epoch2, step886]: loss 22.466454
[epoch2, step887]: loss 6.921722
[epoch2, step888]: loss 11.885288
[epoch2, step889]: loss 26.829300
[epoch2, step890]: loss 10.804392
[epoch2, step891]: loss 33.630871
[epoch2, step892]: loss 8.091092
[epoch2, step893]: loss 13.172418
[epoch2, step894]: loss 27.922554
[epoch2, step895]: loss 7.592164
[epoch2, step896]: loss 23.848116
[epoch2, step897]: loss 19.905518
[epoch2, step898]: loss 21.954239
[epoch2, step899]: loss 46.446102
[epoch2, step900]: loss 28.957428
[epoch2, step901]: loss 27.966127
[epoch2, step902]: loss 39.919884
[epoch2, step903]: loss 30.208895
[epoch2, step904]: loss 9.085042
[epoch2, step905]: loss 27.444984
[epoch2, step906]: loss 14.529379
[epoch2, step907]: loss 26.517788
[epoch2, step908]: loss 25.796730
[epoch2, step909]: loss 31.992561
[epoch2, step910]: loss 9.456025
[epoch2, step911]: loss 9.611296
[epoch2, step912]: loss 8.765227
[epoch2, step913]: loss 11.386153
[epoch2, step914]: loss 15.039588
[epoch2, step915]: loss 20.851509
[epoch2, step916]: loss 34.053032
[epoch2, step917]: loss 17.708344
[epoch2, step918]: loss 9.341035
[epoch2, step919]: loss 37.718494
[epoch2, step920]: loss 22.144567
[epoch2, step921]: loss 7.872309
[epoch2, step922]: loss 33.539993
[epoch2, step923]: loss 13.194979
[epoch2, step924]: loss 9.619480
[epoch2, step925]: loss 12.021371
[epoch2, step926]: loss 27.010572
[epoch2, step927]: loss 24.914021
[epoch2, step928]: loss 15.646133
[epoch2, step929]: loss 23.207026
[epoch2, step930]: loss 30.143946
[epoch2, step931]: loss 14.509901
[epoch2, step932]: loss 14.278128
[epoch2, step933]: loss 28.672638
[epoch2, step934]: loss 39.557972
[epoch2, step935]: loss 30.134043
[epoch2, step936]: loss 14.168235
[epoch2, step937]: loss 10.679158
[epoch2, step938]: loss 21.712831
[epoch2, step939]: loss 16.196037
[epoch2, step940]: loss 22.432140
[epoch2, step941]: loss 21.221043
[epoch2, step942]: loss 29.594732
[epoch2, step943]: loss 9.219213
[epoch2, step944]: loss 33.302074
[epoch2, step945]: loss 13.855359
[epoch2, step946]: loss 12.732146
[epoch2, step947]: loss 28.570349
[epoch2, step948]: loss 39.247299
[epoch2, step949]: loss 26.454002
[epoch2, step950]: loss 6.177093
[epoch2, step951]: loss 30.699280
[epoch2, step952]: loss 25.511744
[epoch2, step953]: loss 19.278482
[epoch2, step954]: loss 34.129669
[epoch2, step955]: loss 33.744053
[epoch2, step956]: loss 42.857159
[epoch2, step957]: loss 12.852517
[epoch2, step958]: loss 29.959442
[epoch2, step959]: loss 10.239732
[epoch2, step960]: loss 35.417641
[epoch2, step961]: loss 11.976765
[epoch2, step962]: loss 14.303110
[epoch2, step963]: loss 22.599913
[epoch2, step964]: loss 32.146271
[epoch2, step965]: loss 36.897999
[epoch2, step966]: loss 17.382196
[epoch2, step967]: loss 23.568905
[epoch2, step968]: loss 45.111156
[epoch2, step969]: loss 18.255787
[epoch2, step970]: loss 15.628791
[epoch2, step971]: loss 18.223169
[epoch2, step972]: loss 25.524837
[epoch2, step973]: loss 8.494802
[epoch2, step974]: loss 26.850718
[epoch2, step975]: loss 26.440395
[epoch2, step976]: loss 43.273537
[epoch2, step977]: loss 37.999466
[epoch2, step978]: loss 15.156309
[epoch2, step979]: loss 22.201633
[epoch2, step980]: loss 13.340404
[epoch2, step981]: loss 24.983538
[epoch2, step982]: loss 25.363340
[epoch2, step983]: loss 34.068989
[epoch2, step984]: loss 11.514942
[epoch2, step985]: loss 17.796984
[epoch2, step986]: loss 14.951060
[epoch2, step987]: loss 15.858451
[epoch2, step988]: loss 18.885221
[epoch2, step989]: loss 19.124027
[epoch2, step990]: loss 9.348332
[epoch2, step991]: loss 12.242764
[epoch2, step992]: loss 13.067123
[epoch2, step993]: loss 38.665138
[epoch2, step994]: loss 10.016409
[epoch2, step995]: loss 19.891043
[epoch2, step996]: loss 19.614666
[epoch2, step997]: loss 23.281250
[epoch2, step998]: loss 20.024359
[epoch2, step999]: loss 36.825535
[epoch2, step1000]: loss 22.830463
[epoch2, step1001]: loss 34.703812
[epoch2, step1002]: loss 14.397273
[epoch2, step1003]: loss 13.876327
[epoch2, step1004]: loss 3.590218
[epoch2, step1005]: loss 41.795486
[epoch2, step1006]: loss 9.798431
[epoch2, step1007]: loss 17.572035
[epoch2, step1008]: loss 28.903538
[epoch2, step1009]: loss 33.639164
[epoch2, step1010]: loss 17.129452
[epoch2, step1011]: loss 24.641865
[epoch2, step1012]: loss 15.242633
[epoch2, step1013]: loss 20.820599
[epoch2, step1014]: loss 14.443807
[epoch2, step1015]: loss 12.145671
[epoch2, step1016]: loss 26.534288
[epoch2, step1017]: loss 28.325506
[epoch2, step1018]: loss 20.587160
[epoch2, step1019]: loss 24.163935
[epoch2, step1020]: loss 16.204882
[epoch2, step1021]: loss 30.080175
[epoch2, step1022]: loss 12.027432
[epoch2, step1023]: loss 18.732054
[epoch2, step1024]: loss 24.336613
[epoch2, step1025]: loss 5.221190
[epoch2, step1026]: loss 27.369442
[epoch2, step1027]: loss 20.651043
[epoch2, step1028]: loss 26.640202
[epoch2, step1029]: loss 17.776438
[epoch2, step1030]: loss 5.096013
[epoch2, step1031]: loss 28.982134
[epoch2, step1032]: loss 28.659126
[epoch2, step1033]: loss 31.820662
[epoch2, step1034]: loss 10.038788
[epoch2, step1035]: loss 25.090654
[epoch2, step1036]: loss 7.714156
[epoch2, step1037]: loss 14.600329
[epoch2, step1038]: loss 26.670233
[epoch2, step1039]: loss 4.925399
[epoch2, step1040]: loss 6.958498
[epoch2, step1041]: loss 12.264100
[epoch2, step1042]: loss 9.762828
[epoch2, step1043]: loss 17.297482
[epoch2, step1044]: loss 18.815454
[epoch2, step1045]: loss 25.145479
[epoch2, step1046]: loss 13.959120
[epoch2, step1047]: loss 25.703724
[epoch2, step1048]: loss 19.660990
[epoch2, step1049]: loss 8.376696
[epoch2, step1050]: loss 37.847240
[epoch2, step1051]: loss 34.414394
[epoch2, step1052]: loss 17.647943
[epoch2, step1053]: loss 4.811294
[epoch2, step1054]: loss 24.308672
[epoch2, step1055]: loss 12.379710
[epoch2, step1056]: loss 41.837425
[epoch2, step1057]: loss 20.124788
[epoch2, step1058]: loss 22.635042
[epoch2, step1059]: loss 30.605146
[epoch2, step1060]: loss 31.620529
[epoch2, step1061]: loss 17.896868
[epoch2, step1062]: loss 10.724326
[epoch2, step1063]: loss 20.874203
[epoch2, step1064]: loss 56.270348
[epoch2, step1065]: loss 17.962542
[epoch2, step1066]: loss 8.576729
[epoch2, step1067]: loss 20.814850
[epoch2, step1068]: loss 14.121143
[epoch2, step1069]: loss 19.369337
[epoch2, step1070]: loss 10.785953
[epoch2, step1071]: loss 25.437845
[epoch2, step1072]: loss 7.964902
[epoch2, step1073]: loss 24.109869
[epoch2, step1074]: loss 38.329048
[epoch2, step1075]: loss 9.145417
[epoch2, step1076]: loss 48.282047
[epoch2, step1077]: loss 21.687521
[epoch2, step1078]: loss 51.508282
[epoch2, step1079]: loss 6.629884
[epoch2, step1080]: loss 33.737045
[epoch2, step1081]: loss 4.679558
[epoch2, step1082]: loss 6.326774
[epoch2, step1083]: loss 17.435352
[epoch2, step1084]: loss 46.209709
[epoch2, step1085]: loss 4.128956
[epoch2, step1086]: loss 15.680703
[epoch2, step1087]: loss 26.453634
[epoch2, step1088]: loss 10.116773
[epoch2, step1089]: loss 21.333012
[epoch2, step1090]: loss 8.325555
[epoch2, step1091]: loss 20.685976
[epoch2, step1092]: loss 28.463724
[epoch2, step1093]: loss 12.960549
[epoch2, step1094]: loss 17.356558
[epoch2, step1095]: loss 10.091642
[epoch2, step1096]: loss 13.623408
[epoch2, step1097]: loss 37.231087
[epoch2, step1098]: loss 6.441324
[epoch2, step1099]: loss 8.924105
[epoch2, step1100]: loss 25.320501
[epoch2, step1101]: loss 52.892597
[epoch2, step1102]: loss 8.299800
[epoch2, step1103]: loss 33.981701
[epoch2, step1104]: loss 11.315072
[epoch2, step1105]: loss 14.889914
[epoch2, step1106]: loss 28.384445
[epoch2, step1107]: loss 30.798634
[epoch2, step1108]: loss 16.922470
[epoch2, step1109]: loss 30.742798
[epoch2, step1110]: loss 11.218976
[epoch2, step1111]: loss 32.730766
[epoch2, step1112]: loss 6.797599
[epoch2, step1113]: loss 26.651878
[epoch2, step1114]: loss 22.593929
[epoch2, step1115]: loss 6.308964
[epoch2, step1116]: loss 5.135676
[epoch2, step1117]: loss 14.293495
[epoch2, step1118]: loss 10.356440
[epoch2, step1119]: loss 16.625448
[epoch2, step1120]: loss 17.722094
[epoch2, step1121]: loss 21.241880
[epoch2, step1122]: loss 10.088415
[epoch2, step1123]: loss 10.245916
[epoch2, step1124]: loss 24.622955
[epoch2, step1125]: loss 15.301874
[epoch2, step1126]: loss 14.064606
[epoch2, step1127]: loss 18.657154
[epoch2, step1128]: loss 22.563679
[epoch2, step1129]: loss 30.927765
[epoch2, step1130]: loss 20.546663
[epoch2, step1131]: loss 25.775211
[epoch2, step1132]: loss 8.394622
[epoch2, step1133]: loss 15.759520
[epoch2, step1134]: loss 4.198288
[epoch2, step1135]: loss 13.222266
[epoch2, step1136]: loss 42.131943
[epoch2, step1137]: loss 20.204800
[epoch2, step1138]: loss 7.048498
[epoch2, step1139]: loss 22.908142
[epoch2, step1140]: loss 25.024376
[epoch2, step1141]: loss 37.060730
[epoch2, step1142]: loss 15.300630
[epoch2, step1143]: loss 19.864790
[epoch2, step1144]: loss 11.726878
[epoch2, step1145]: loss 21.993824
[epoch2, step1146]: loss 8.524860
[epoch2, step1147]: loss 33.013615
[epoch2, step1148]: loss 23.667353
[epoch2, step1149]: loss 5.902466
[epoch2, step1150]: loss 27.720621
[epoch2, step1151]: loss 18.840866
[epoch2, step1152]: loss 15.462452
[epoch2, step1153]: loss 20.056303
[epoch2, step1154]: loss 26.377853
[epoch2, step1155]: loss 5.124979
[epoch2, step1156]: loss 11.469978
[epoch2, step1157]: loss 12.717096
[epoch2, step1158]: loss 24.222069
[epoch2, step1159]: loss 7.106181
[epoch2, step1160]: loss 5.666266
[epoch2, step1161]: loss 37.956543
[epoch2, step1162]: loss 13.248805
[epoch2, step1163]: loss 29.461929
[epoch2, step1164]: loss 31.611677
[epoch2, step1165]: loss 28.709791
[epoch2, step1166]: loss 21.516937
[epoch2, step1167]: loss 31.480003
[epoch2, step1168]: loss 28.388721
[epoch2, step1169]: loss 10.194909
[epoch2, step1170]: loss 14.105861
[epoch2, step1171]: loss 10.189927
[epoch2, step1172]: loss 28.232454
[epoch2, step1173]: loss 28.531988
[epoch2, step1174]: loss 10.136975
[epoch2, step1175]: loss 22.818644
[epoch2, step1176]: loss 18.645435
[epoch2, step1177]: loss 6.411608
[epoch2, step1178]: loss 17.602644
[epoch2, step1179]: loss 33.646244
[epoch2, step1180]: loss 34.494797
[epoch2, step1181]: loss 22.875912
[epoch2, step1182]: loss 16.882864
[epoch2, step1183]: loss 6.555467
[epoch2, step1184]: loss 25.752405
[epoch2, step1185]: loss 17.024832
[epoch2, step1186]: loss 14.878799
[epoch2, step1187]: loss 17.465034
[epoch2, step1188]: loss 6.524754
[epoch2, step1189]: loss 20.219044
[epoch2, step1190]: loss 5.720546
[epoch2, step1191]: loss 28.195492
[epoch2, step1192]: loss 19.939831
[epoch2, step1193]: loss 26.606964
[epoch2, step1194]: loss 21.941174
[epoch2, step1195]: loss 19.028774
[epoch2, step1196]: loss 13.488682
[epoch2, step1197]: loss 8.360996
[epoch2, step1198]: loss 21.395691
[epoch2, step1199]: loss 15.436221
[epoch2, step1200]: loss 20.859858
[epoch2, step1201]: loss 32.066345
[epoch2, step1202]: loss 18.732470
[epoch2, step1203]: loss 9.687220
[epoch2, step1204]: loss 21.423149
[epoch2, step1205]: loss 14.531984
[epoch2, step1206]: loss 26.229118
[epoch2, step1207]: loss 49.856083
[epoch2, step1208]: loss 8.841168
[epoch2, step1209]: loss 12.515648
[epoch2, step1210]: loss 20.494743
[epoch2, step1211]: loss 16.573298
[epoch2, step1212]: loss 6.229844
[epoch2, step1213]: loss 8.318144
[epoch2, step1214]: loss 17.317284
[epoch2, step1215]: loss 16.329746
[epoch2, step1216]: loss 5.713893
[epoch2, step1217]: loss 26.757311
[epoch2, step1218]: loss 9.341561
[epoch2, step1219]: loss 5.917730
[epoch2, step1220]: loss 25.675983
[epoch2, step1221]: loss 22.062300
[epoch2, step1222]: loss 13.583104
[epoch2, step1223]: loss 4.639694
[epoch2, step1224]: loss 31.848408
[epoch2, step1225]: loss 19.349133
[epoch2, step1226]: loss 10.082110
[epoch2, step1227]: loss 9.517377
[epoch2, step1228]: loss 30.126888
[epoch2, step1229]: loss 32.711750
[epoch2, step1230]: loss 14.772152
[epoch2, step1231]: loss 12.452438
[epoch2, step1232]: loss 19.267300
[epoch2, step1233]: loss 11.610857
[epoch2, step1234]: loss 31.037203
[epoch2, step1235]: loss 33.478985
[epoch2, step1236]: loss 7.969425
[epoch2, step1237]: loss 12.391951
[epoch2, step1238]: loss 39.132023
[epoch2, step1239]: loss 13.638094
[epoch2, step1240]: loss 21.335705
[epoch2, step1241]: loss 46.555897
[epoch2, step1242]: loss 7.975665
[epoch2, step1243]: loss 8.791585
[epoch2, step1244]: loss 11.803988
[epoch2, step1245]: loss 17.103367
[epoch2, step1246]: loss 19.994122
[epoch2, step1247]: loss 27.911064
[epoch2, step1248]: loss 14.360303
[epoch2, step1249]: loss 15.425460
[epoch2, step1250]: loss 13.225769
[epoch2, step1251]: loss 9.254664
[epoch2, step1252]: loss 21.504774
[epoch2, step1253]: loss 27.213991
[epoch2, step1254]: loss 15.626277
[epoch2, step1255]: loss 19.518044
[epoch2, step1256]: loss 26.183386
[epoch2, step1257]: loss 8.712111
[epoch2, step1258]: loss 47.714600
[epoch2, step1259]: loss 20.906351
[epoch2, step1260]: loss 6.674998
[epoch2, step1261]: loss 12.564945
[epoch2, step1262]: loss 13.739960
[epoch2, step1263]: loss 18.291185
[epoch2, step1264]: loss 8.405096
[epoch2, step1265]: loss 21.959805
[epoch2, step1266]: loss 13.197317
[epoch2, step1267]: loss 14.236364
[epoch2, step1268]: loss 20.499426
[epoch2, step1269]: loss 26.376316
[epoch2, step1270]: loss 12.492947
[epoch2, step1271]: loss 6.541730
[epoch2, step1272]: loss 26.010128
[epoch2, step1273]: loss 9.755614
[epoch2, step1274]: loss 20.803991
[epoch2, step1275]: loss 8.327500
[epoch2, step1276]: loss 18.856133
[epoch2, step1277]: loss 5.190843
[epoch2, step1278]: loss 4.453336
[epoch2, step1279]: loss 3.569817
[epoch2, step1280]: loss 7.394729
[epoch2, step1281]: loss 28.952742
[epoch2, step1282]: loss 8.449340
[epoch2, step1283]: loss 10.987207
[epoch2, step1284]: loss 8.601721
[epoch2, step1285]: loss 27.666855
[epoch2, step1286]: loss 21.097115
[epoch2, step1287]: loss 8.051594
[epoch2, step1288]: loss 16.736591
[epoch2, step1289]: loss 21.392630
[epoch2, step1290]: loss 19.389200
[epoch2, step1291]: loss 19.951584
[epoch2, step1292]: loss 11.974174
[epoch2, step1293]: loss 3.312497
[epoch2, step1294]: loss 15.025396
[epoch2, step1295]: loss 27.702206
[epoch2, step1296]: loss 13.913188
[epoch2, step1297]: loss 25.854191
[epoch2, step1298]: loss 18.248337
[epoch2, step1299]: loss 39.896042
[epoch2, step1300]: loss 46.887142
[epoch2, step1301]: loss 16.328842
[epoch2, step1302]: loss 29.377201
[epoch2, step1303]: loss 37.175911
[epoch2, step1304]: loss 27.365679
[epoch2, step1305]: loss 13.354818
[epoch2, step1306]: loss 43.985466
[epoch2, step1307]: loss 10.407472
[epoch2, step1308]: loss 22.652985
[epoch2, step1309]: loss 9.998549
[epoch2, step1310]: loss 30.865658
[epoch2, step1311]: loss 36.239460
[epoch2, step1312]: loss 36.270290
[epoch2, step1313]: loss 31.259790
[epoch2, step1314]: loss 23.707487
[epoch2, step1315]: loss 18.173548
[epoch2, step1316]: loss 20.507692
[epoch2, step1317]: loss 22.169153
[epoch2, step1318]: loss 6.362334
[epoch2, step1319]: loss 10.755631
[epoch2, step1320]: loss 31.086134
[epoch2, step1321]: loss 28.936966
[epoch2, step1322]: loss 43.272873
[epoch2, step1323]: loss 7.267744
[epoch2, step1324]: loss 18.873749
[epoch2, step1325]: loss 22.453804
[epoch2, step1326]: loss 22.524073
[epoch2, step1327]: loss 24.749928
[epoch2, step1328]: loss 27.103382
[epoch2, step1329]: loss 15.294567
[epoch2, step1330]: loss 8.697167
[epoch2, step1331]: loss 10.488629
[epoch2, step1332]: loss 30.617134
[epoch2, step1333]: loss 16.716024
[epoch2, step1334]: loss 25.064741
[epoch2, step1335]: loss 18.296753
[epoch2, step1336]: loss 27.072823
[epoch2, step1337]: loss 11.189236
[epoch2, step1338]: loss 27.570175
[epoch2, step1339]: loss 19.994289
[epoch2, step1340]: loss 4.868424
[epoch2, step1341]: loss 6.925748
[epoch2, step1342]: loss 21.460932
[epoch2, step1343]: loss 29.603157
[epoch2, step1344]: loss 25.692209
[epoch2, step1345]: loss 29.918217
[epoch2, step1346]: loss 9.355651
[epoch2, step1347]: loss 10.431732
[epoch2, step1348]: loss 58.095963
[epoch2, step1349]: loss 23.910114
[epoch2, step1350]: loss 18.308491
[epoch2, step1351]: loss 21.654270
[epoch2, step1352]: loss 9.983328
[epoch2, step1353]: loss 7.761964
[epoch2, step1354]: loss 12.211040
[epoch2, step1355]: loss 8.605929
[epoch2, step1356]: loss 7.274997
[epoch2, step1357]: loss 31.957798
[epoch2, step1358]: loss 11.451336
[epoch2, step1359]: loss 6.289410
[epoch2, step1360]: loss 41.356861
[epoch2, step1361]: loss 53.449291
[epoch2, step1362]: loss 20.630093
[epoch2, step1363]: loss 9.193748
[epoch2, step1364]: loss 10.444495
[epoch2, step1365]: loss 11.353917
[epoch2, step1366]: loss 20.846607
[epoch2, step1367]: loss 7.983016
[epoch2, step1368]: loss 5.851356
[epoch2, step1369]: loss 12.062597
[epoch2, step1370]: loss 9.749265
[epoch2, step1371]: loss 24.224297
[epoch2, step1372]: loss 19.269157
[epoch2, step1373]: loss 28.986380
[epoch2, step1374]: loss 8.373148
[epoch2, step1375]: loss 20.431648
[epoch2, step1376]: loss 17.476757
[epoch2, step1377]: loss 11.543292
[epoch2, step1378]: loss 11.759446
[epoch2, step1379]: loss 32.823090
[epoch2, step1380]: loss 6.153353
[epoch2, step1381]: loss 24.952391
[epoch2, step1382]: loss 20.526192
[epoch2, step1383]: loss 23.344948
[epoch2, step1384]: loss 16.954214
[epoch2, step1385]: loss 11.747330
[epoch2, step1386]: loss 17.512171
[epoch2, step1387]: loss 19.616150
[epoch2, step1388]: loss 20.259304
[epoch2, step1389]: loss 18.464422
[epoch2, step1390]: loss 16.098866
[epoch2, step1391]: loss 10.460864
[epoch2, step1392]: loss 8.043047
[epoch2, step1393]: loss 16.841043
[epoch2, step1394]: loss 14.875873
[epoch2, step1395]: loss 17.862179
[epoch2, step1396]: loss 14.580489
[epoch2, step1397]: loss 11.808561
[epoch2, step1398]: loss 10.276690
[epoch2, step1399]: loss 7.175014
[epoch2, step1400]: loss 14.237591
[epoch2, step1401]: loss 11.567883
[epoch2, step1402]: loss 20.410425
[epoch2, step1403]: loss 16.619926
[epoch2, step1404]: loss 35.243294
[epoch2, step1405]: loss 13.580757
[epoch2, step1406]: loss 13.666326
[epoch2, step1407]: loss 15.853495
[epoch2, step1408]: loss 11.212254
[epoch2, step1409]: loss 10.090669
[epoch2, step1410]: loss 17.091331
[epoch2, step1411]: loss 12.338135
[epoch2, step1412]: loss 14.821678
[epoch2, step1413]: loss 14.082924
[epoch2, step1414]: loss 38.232979
[epoch2, step1415]: loss 8.343312
[epoch2, step1416]: loss 29.356392
[epoch2, step1417]: loss 56.756519
[epoch2, step1418]: loss 29.398540
[epoch2, step1419]: loss 20.391558
[epoch2, step1420]: loss 47.566460
[epoch2, step1421]: loss 12.548714
[epoch2, step1422]: loss 6.026525
[epoch2, step1423]: loss 20.383123
[epoch2, step1424]: loss 15.943909
[epoch2, step1425]: loss 19.651773
[epoch2, step1426]: loss 20.801165
[epoch2, step1427]: loss 42.674946
[epoch2, step1428]: loss 27.555573
[epoch2, step1429]: loss 13.246352
[epoch2, step1430]: loss 5.763913
[epoch2, step1431]: loss 8.329163
[epoch2, step1432]: loss 23.476431
[epoch2, step1433]: loss 6.533129
[epoch2, step1434]: loss 25.454596
[epoch2, step1435]: loss 8.842914
[epoch2, step1436]: loss 14.280909
[epoch2, step1437]: loss 28.410736
[epoch2, step1438]: loss 18.570606
[epoch2, step1439]: loss 16.890806
[epoch2, step1440]: loss 14.493093
[epoch2, step1441]: loss 31.727869
[epoch2, step1442]: loss 20.043291
[epoch2, step1443]: loss 21.768358
[epoch2, step1444]: loss 19.716671
[epoch2, step1445]: loss 14.444438
[epoch2, step1446]: loss 12.176057
[epoch2, step1447]: loss 31.932138
[epoch2, step1448]: loss 6.130681
[epoch2, step1449]: loss 19.255728
[epoch2, step1450]: loss 13.776105
[epoch2, step1451]: loss 16.141127
[epoch2, step1452]: loss 53.061169
[epoch2, step1453]: loss 27.546202
[epoch2, step1454]: loss 37.590187
[epoch2, step1455]: loss 40.578865
[epoch2, step1456]: loss 12.633983
[epoch2, step1457]: loss 30.507116
[epoch2, step1458]: loss 7.012080
[epoch2, step1459]: loss 7.090606
[epoch2, step1460]: loss 22.014486
[epoch2, step1461]: loss 25.728989
[epoch2, step1462]: loss 17.541826
[epoch2, step1463]: loss 29.194628
[epoch2, step1464]: loss 7.632646
[epoch2, step1465]: loss 8.753024
[epoch2, step1466]: loss 14.681975
[epoch2, step1467]: loss 15.752781
[epoch2, step1468]: loss 11.228267
[epoch2, step1469]: loss 24.408407
[epoch2, step1470]: loss 18.287306
[epoch2, step1471]: loss 6.460953
[epoch2, step1472]: loss 23.981052
[epoch2, step1473]: loss 19.017452
[epoch2, step1474]: loss 17.529480
[epoch2, step1475]: loss 21.588100
[epoch2, step1476]: loss 24.310938
[epoch2, step1477]: loss 16.716854
[epoch2, step1478]: loss 20.204105
[epoch2, step1479]: loss 10.633011
[epoch2, step1480]: loss 20.883801
[epoch2, step1481]: loss 13.742694
[epoch2, step1482]: loss 17.217360
[epoch2, step1483]: loss 10.322062
[epoch2, step1484]: loss 16.055210
[epoch2, step1485]: loss 13.625629
[epoch2, step1486]: loss 44.965473
[epoch2, step1487]: loss 16.337158
[epoch2, step1488]: loss 23.415462
[epoch2, step1489]: loss 7.943727
[epoch2, step1490]: loss 6.710260
[epoch2, step1491]: loss 7.457628
[epoch2, step1492]: loss 12.378508
[epoch2, step1493]: loss 23.632885
[epoch2, step1494]: loss 22.066263
[epoch2, step1495]: loss 6.325498
[epoch2, step1496]: loss 13.407492
[epoch2, step1497]: loss 25.923775
[epoch2, step1498]: loss 14.606667
[epoch2, step1499]: loss 27.851557
[epoch2, step1500]: loss 8.555373
[epoch2, step1501]: loss 11.729467
[epoch2, step1502]: loss 12.190548
[epoch2, step1503]: loss 11.344160
[epoch2, step1504]: loss 11.627281
[epoch2, step1505]: loss 7.887992
[epoch2, step1506]: loss 49.536175
[epoch2, step1507]: loss 6.339025
[epoch2, step1508]: loss 15.429905
[epoch2, step1509]: loss 5.774415
[epoch2, step1510]: loss 19.108498
[epoch2, step1511]: loss 7.617528
[epoch2, step1512]: loss 14.261489
[epoch2, step1513]: loss 4.789248
[epoch2, step1514]: loss 21.857197
[epoch2, step1515]: loss 24.602936
[epoch2, step1516]: loss 11.884819
[epoch2, step1517]: loss 22.663721
[epoch2, step1518]: loss 16.336954
[epoch2, step1519]: loss 8.738997
[epoch2, step1520]: loss 14.580631
[epoch2, step1521]: loss 16.009279
[epoch2, step1522]: loss 10.719920
[epoch2, step1523]: loss 14.224878
[epoch2, step1524]: loss 9.302911
[epoch2, step1525]: loss 21.594608
[epoch2, step1526]: loss 23.103188
[epoch2, step1527]: loss 10.554147
[epoch2, step1528]: loss 20.797726
[epoch2, step1529]: loss 25.758572
[epoch2, step1530]: loss 7.126603
[epoch2, step1531]: loss 15.887947
[epoch2, step1532]: loss 20.088091
[epoch2, step1533]: loss 17.066690
[epoch2, step1534]: loss 17.082327
[epoch2, step1535]: loss 12.026314
[epoch2, step1536]: loss 8.622677
[epoch2, step1537]: loss 10.262076
[epoch2, step1538]: loss 11.358820
[epoch2, step1539]: loss 12.058919
[epoch2, step1540]: loss 7.027536
[epoch2, step1541]: loss 16.847912
[epoch2, step1542]: loss 24.234745
[epoch2, step1543]: loss 17.638874
[epoch2, step1544]: loss 11.895193
[epoch2, step1545]: loss 17.112722
[epoch2, step1546]: loss 24.879187
[epoch2, step1547]: loss 45.781273
[epoch2, step1548]: loss 16.057985
[epoch2, step1549]: loss 54.311123
[epoch2, step1550]: loss 21.234324
[epoch2, step1551]: loss 15.635776
[epoch2, step1552]: loss 19.775560
[epoch2, step1553]: loss 24.673738
[epoch2, step1554]: loss 11.857301
[epoch2, step1555]: loss 18.633070
[epoch2, step1556]: loss 30.284746
[epoch2, step1557]: loss 10.017778
[epoch2, step1558]: loss 19.133682
[epoch2, step1559]: loss 20.770386
[epoch2, step1560]: loss 38.740303
[epoch2, step1561]: loss 10.759501
[epoch2, step1562]: loss 4.550330
[epoch2, step1563]: loss 19.345978
[epoch2, step1564]: loss 9.783284
[epoch2, step1565]: loss 13.427657
[epoch2, step1566]: loss 8.540070
[epoch2, step1567]: loss 32.342670
[epoch2, step1568]: loss 14.293823
[epoch2, step1569]: loss 22.108950
[epoch2, step1570]: loss 5.676023
[epoch2, step1571]: loss 46.738213
[epoch2, step1572]: loss 12.949302
[epoch2, step1573]: loss 23.903748
[epoch2, step1574]: loss 19.267267
[epoch2, step1575]: loss 29.052176
[epoch2, step1576]: loss 14.467836
[epoch2, step1577]: loss 26.645342
[epoch2, step1578]: loss 15.647799
[epoch2, step1579]: loss 8.265537
[epoch2, step1580]: loss 10.885509
[epoch2, step1581]: loss 5.520363
[epoch2, step1582]: loss 40.819660
[epoch2, step1583]: loss 17.816814
[epoch2, step1584]: loss 31.853765
[epoch2, step1585]: loss 3.184171
[epoch2, step1586]: loss 6.859869
[epoch2, step1587]: loss 24.583652
[epoch2, step1588]: loss 15.221384
[epoch2, step1589]: loss 10.898681
[epoch2, step1590]: loss 11.674015
[epoch2, step1591]: loss 20.383780
[epoch2, step1592]: loss 30.359856
[epoch2, step1593]: loss 20.994919
[epoch2, step1594]: loss 54.039162
[epoch2, step1595]: loss 30.613695
[epoch2, step1596]: loss 13.085575
[epoch2, step1597]: loss 8.654094
[epoch2, step1598]: loss 16.056602
[epoch2, step1599]: loss 32.340706
[epoch2, step1600]: loss 20.452490
[epoch2, step1601]: loss 25.549353
[epoch2, step1602]: loss 5.097432
[epoch2, step1603]: loss 8.092645
[epoch2, step1604]: loss 9.161415
[epoch2, step1605]: loss 11.212864
[epoch2, step1606]: loss 13.027298
[epoch2, step1607]: loss 15.643831
[epoch2, step1608]: loss 21.276564
[epoch2, step1609]: loss 11.746555
[epoch2, step1610]: loss 45.700661
[epoch2, step1611]: loss 15.937638
[epoch2, step1612]: loss 19.778559
[epoch2, step1613]: loss 15.977567
[epoch2, step1614]: loss 20.088020
[epoch2, step1615]: loss 33.729462
[epoch2, step1616]: loss 16.446894
[epoch2, step1617]: loss 14.494103
[epoch2, step1618]: loss 20.077065
[epoch2, step1619]: loss 16.985785
[epoch2, step1620]: loss 10.695141
[epoch2, step1621]: loss 12.221863
[epoch2, step1622]: loss 6.033926
[epoch2, step1623]: loss 26.736963
[epoch2, step1624]: loss 69.086906
[epoch2, step1625]: loss 13.610125
[epoch2, step1626]: loss 22.933565
[epoch2, step1627]: loss 45.650928
[epoch2, step1628]: loss 17.862074
[epoch2, step1629]: loss 17.456230
[epoch2, step1630]: loss 31.107763
[epoch2, step1631]: loss 69.428680
[epoch2, step1632]: loss 22.348190
[epoch2, step1633]: loss 16.950491
[epoch2, step1634]: loss 9.054087
[epoch2, step1635]: loss 3.425256
[epoch2, step1636]: loss 8.716155
[epoch2, step1637]: loss 25.019089
[epoch2, step1638]: loss 26.427462
[epoch2, step1639]: loss 11.463988
[epoch2, step1640]: loss 17.026114
[epoch2, step1641]: loss 14.910418
[epoch2, step1642]: loss 14.618989
[epoch2, step1643]: loss 14.595945
[epoch2, step1644]: loss 12.902836
[epoch2, step1645]: loss 17.040781
[epoch2, step1646]: loss 35.301868
[epoch2, step1647]: loss 30.499426
[epoch2, step1648]: loss 11.299331
[epoch2, step1649]: loss 14.862132
[epoch2, step1650]: loss 8.142509
[epoch2, step1651]: loss 42.388077
[epoch2, step1652]: loss 13.048726
[epoch2, step1653]: loss 7.806965
[epoch2, step1654]: loss 16.835199
[epoch2, step1655]: loss 23.336767
[epoch2, step1656]: loss 12.423007
[epoch2, step1657]: loss 24.232601
[epoch2, step1658]: loss 5.008981
[epoch2, step1659]: loss 11.926604
[epoch2, step1660]: loss 12.482989
[epoch2, step1661]: loss 10.859946
[epoch2, step1662]: loss 19.846519
[epoch2, step1663]: loss 15.128189
[epoch2, step1664]: loss 11.649008
[epoch2, step1665]: loss 35.048759
[epoch2, step1666]: loss 13.549373
[epoch2, step1667]: loss 8.998340
[epoch2, step1668]: loss 13.291897
[epoch2, step1669]: loss 13.501837
[epoch2, step1670]: loss 5.243943
[epoch2, step1671]: loss 19.278284
[epoch2, step1672]: loss 20.910812
[epoch2, step1673]: loss 25.032307
[epoch2, step1674]: loss 17.997694
[epoch2, step1675]: loss 13.364749
[epoch2, step1676]: loss 15.765768
[epoch2, step1677]: loss 19.236902
[epoch2, step1678]: loss 6.262057
[epoch2, step1679]: loss 21.008455
[epoch2, step1680]: loss 23.145676
[epoch2, step1681]: loss 20.662916
[epoch2, step1682]: loss 54.383411
[epoch2, step1683]: loss 26.291882
[epoch2, step1684]: loss 8.637223
[epoch2, step1685]: loss 5.560815
[epoch2, step1686]: loss 17.135233
[epoch2, step1687]: loss 9.723178
[epoch2, step1688]: loss 5.865199
[epoch2, step1689]: loss 14.985041
[epoch2, step1690]: loss 23.409925
[epoch2, step1691]: loss 19.853653
[epoch2, step1692]: loss 19.337378
[epoch2, step1693]: loss 24.577806
[epoch2, step1694]: loss 10.170197
[epoch2, step1695]: loss 11.872807
[epoch2, step1696]: loss 17.308750
[epoch2, step1697]: loss 22.892906
[epoch2, step1698]: loss 27.555735
[epoch2, step1699]: loss 13.243338
[epoch2, step1700]: loss 17.737782
[epoch2, step1701]: loss 11.650144
[epoch2, step1702]: loss 5.808465
[epoch2, step1703]: loss 14.408330
[epoch2, step1704]: loss 18.486153
[epoch2, step1705]: loss 14.141440
[epoch2, step1706]: loss 10.451645
[epoch2, step1707]: loss 13.296635
[epoch2, step1708]: loss 7.508035
[epoch2, step1709]: loss 18.050808
[epoch2, step1710]: loss 10.635229
[epoch2, step1711]: loss 10.983132
[epoch2, step1712]: loss 11.974483
[epoch2, step1713]: loss 6.430514
[epoch2, step1714]: loss 18.260557
[epoch2, step1715]: loss 31.846613
[epoch2, step1716]: loss 6.652057
[epoch2, step1717]: loss 6.925463
[epoch2, step1718]: loss 19.755888
[epoch2, step1719]: loss 11.616774
[epoch2, step1720]: loss 23.736515
[epoch2, step1721]: loss 16.513412
[epoch2, step1722]: loss 30.021299
[epoch2, step1723]: loss 25.776320
[epoch2, step1724]: loss 8.751047
[epoch2, step1725]: loss 11.649050
[epoch2, step1726]: loss 19.063023
[epoch2, step1727]: loss 13.900784
[epoch2, step1728]: loss 21.625259
[epoch2, step1729]: loss 13.643982
[epoch2, step1730]: loss 11.055198
[epoch2, step1731]: loss 13.193422
[epoch2, step1732]: loss 11.535387
[epoch2, step1733]: loss 12.046644
[epoch2, step1734]: loss 12.691993
[epoch2, step1735]: loss 22.479109
[epoch2, step1736]: loss 7.570000
[epoch2, step1737]: loss 33.470814
[epoch2, step1738]: loss 9.464839
[epoch2, step1739]: loss 16.480316
[epoch2, step1740]: loss 10.670388
[epoch2, step1741]: loss 27.787281
[epoch2, step1742]: loss 8.985022
[epoch2, step1743]: loss 13.456520
[epoch2, step1744]: loss 26.895010
[epoch2, step1745]: loss 14.388813
[epoch2, step1746]: loss 14.692752
[epoch2, step1747]: loss 9.711849
[epoch2, step1748]: loss 12.247990
[epoch2, step1749]: loss 14.633003
[epoch2, step1750]: loss 10.203106
[epoch2, step1751]: loss 12.045010
[epoch2, step1752]: loss 4.342877
[epoch2, step1753]: loss 20.523527
[epoch2, step1754]: loss 7.561738
[epoch2, step1755]: loss 16.905890
[epoch2, step1756]: loss 23.877863
[epoch2, step1757]: loss 21.297205
[epoch2, step1758]: loss 29.001228
[epoch2, step1759]: loss 25.475662
[epoch2, step1760]: loss 4.229670
[epoch2, step1761]: loss 24.577709
[epoch2, step1762]: loss 16.767609
[epoch2, step1763]: loss 47.687546
[epoch2, step1764]: loss 7.063476
[epoch2, step1765]: loss 12.705679
[epoch2, step1766]: loss 33.585751
[epoch2, step1767]: loss 32.153893
[epoch2, step1768]: loss 7.323946
[epoch2, step1769]: loss 23.051470
[epoch2, step1770]: loss 11.521575
[epoch2, step1771]: loss 25.354113
[epoch2, step1772]: loss 29.838749
[epoch2, step1773]: loss 23.176552
[epoch2, step1774]: loss 17.606659
[epoch2, step1775]: loss 14.421931
[epoch2, step1776]: loss 12.325294
[epoch2, step1777]: loss 12.563181
[epoch2, step1778]: loss 12.951791
[epoch2, step1779]: loss 31.658133
[epoch2, step1780]: loss 34.388691
[epoch2, step1781]: loss 10.453451
[epoch2, step1782]: loss 15.259486
[epoch2, step1783]: loss 5.529790
[epoch2, step1784]: loss 31.369068
[epoch2, step1785]: loss 28.775959
[epoch2, step1786]: loss 14.442162
[epoch2, step1787]: loss 18.207335
[epoch2, step1788]: loss 5.341222
[epoch2, step1789]: loss 19.421049
[epoch2, step1790]: loss 2.962362
[epoch2, step1791]: loss 5.984503
[epoch2, step1792]: loss 8.773265
[epoch2, step1793]: loss 3.740991
[epoch2, step1794]: loss 7.861532
[epoch2, step1795]: loss 25.268867
[epoch2, step1796]: loss 31.562361
[epoch2, step1797]: loss 26.661192
[epoch2, step1798]: loss 24.917362
[epoch2, step1799]: loss 20.520262
[epoch2, step1800]: loss 31.532694
[epoch2, step1801]: loss 7.668602
[epoch2, step1802]: loss 33.017914
[epoch2, step1803]: loss 15.526110
[epoch2, step1804]: loss 18.275826
[epoch2, step1805]: loss 22.667204
[epoch2, step1806]: loss 4.533521
[epoch2, step1807]: loss 13.914812
[epoch2, step1808]: loss 24.743687
[epoch2, step1809]: loss 7.750321
[epoch2, step1810]: loss 39.264030
[epoch2, step1811]: loss 6.590918
[epoch2, step1812]: loss 27.381222
[epoch2, step1813]: loss 11.951747
[epoch2, step1814]: loss 26.477573
[epoch2, step1815]: loss 14.573076
[epoch2, step1816]: loss 5.904268
[epoch2, step1817]: loss 13.190788
[epoch2, step1818]: loss 21.522642
[epoch2, step1819]: loss 8.615822
[epoch2, step1820]: loss 15.833992
[epoch2, step1821]: loss 16.892843
[epoch2, step1822]: loss 30.485657
[epoch2, step1823]: loss 20.187450
[epoch2, step1824]: loss 12.571672
[epoch2, step1825]: loss 16.687637
[epoch2, step1826]: loss 12.569938
[epoch2, step1827]: loss 9.289041
[epoch2, step1828]: loss 36.451111
[epoch2, step1829]: loss 24.793871
[epoch2, step1830]: loss 13.078805
[epoch2, step1831]: loss 25.743841
[epoch2, step1832]: loss 10.347176
[epoch2, step1833]: loss 8.446933
[epoch2, step1834]: loss 19.283760
[epoch2, step1835]: loss 14.374276
[epoch2, step1836]: loss 9.417306
[epoch2, step1837]: loss 17.609499
[epoch2, step1838]: loss 20.429853
[epoch2, step1839]: loss 12.402396
[epoch2, step1840]: loss 13.307381
[epoch2, step1841]: loss 32.200302
[epoch2, step1842]: loss 16.437738
[epoch2, step1843]: loss 21.433876
[epoch2, step1844]: loss 21.430120
[epoch2, step1845]: loss 16.853537
[epoch2, step1846]: loss 16.130604
[epoch2, step1847]: loss 8.982645
[epoch2, step1848]: loss 12.106442
[epoch2, step1849]: loss 9.642687
[epoch2, step1850]: loss 16.839588
[epoch2, step1851]: loss 10.529686
[epoch2, step1852]: loss 36.471294
[epoch2, step1853]: loss 26.760040
[epoch2, step1854]: loss 35.784599
[epoch2, step1855]: loss 9.962598
[epoch2, step1856]: loss 46.530842
[epoch2, step1857]: loss 10.249144
[epoch2, step1858]: loss 10.972584
[epoch2, step1859]: loss 11.303282
[epoch2, step1860]: loss 15.220399
[epoch2, step1861]: loss 9.155407
[epoch2, step1862]: loss 14.370605
[epoch2, step1863]: loss 4.539127
[epoch2, step1864]: loss 10.948636
[epoch2, step1865]: loss 9.215559
[epoch2, step1866]: loss 21.473492
[epoch2, step1867]: loss 12.934674
[epoch2, step1868]: loss 13.922892
[epoch2, step1869]: loss 27.653698
[epoch2, step1870]: loss 20.188208
[epoch2, step1871]: loss 31.258410
[epoch2, step1872]: loss 4.408004
[epoch2, step1873]: loss 8.507002
[epoch2, step1874]: loss 17.043346
[epoch2, step1875]: loss 16.882343
[epoch2, step1876]: loss 17.415859
[epoch2, step1877]: loss 16.085604
[epoch2, step1878]: loss 16.707685
[epoch2, step1879]: loss 7.148568
[epoch2, step1880]: loss 6.901520
[epoch2, step1881]: loss 9.712958
[epoch2, step1882]: loss 19.371864
[epoch2, step1883]: loss 13.971443
[epoch2, step1884]: loss 7.366086
[epoch2, step1885]: loss 27.031288
[epoch2, step1886]: loss 28.042891
[epoch2, step1887]: loss 26.293165
[epoch2, step1888]: loss 22.420712
[epoch2, step1889]: loss 7.175260
[epoch2, step1890]: loss 7.430487
[epoch2, step1891]: loss 8.058849
[epoch2, step1892]: loss 12.592788
[epoch2, step1893]: loss 12.561957
[epoch2, step1894]: loss 14.651840
[epoch2, step1895]: loss 22.647356
[epoch2, step1896]: loss 7.760544
[epoch2, step1897]: loss 8.766803
[epoch2, step1898]: loss 22.317759
[epoch2, step1899]: loss 13.864356
[epoch2, step1900]: loss 15.220093
[epoch2, step1901]: loss 4.963118
[epoch2, step1902]: loss 16.822460
[epoch2, step1903]: loss 14.718342
[epoch2, step1904]: loss 9.997269
[epoch2, step1905]: loss 14.369827
[epoch2, step1906]: loss 15.400432
[epoch2, step1907]: loss 17.549385
[epoch2, step1908]: loss 6.852989
[epoch2, step1909]: loss 24.551659
[epoch2, step1910]: loss 27.180857
[epoch2, step1911]: loss 18.694859
[epoch2, step1912]: loss 15.077920
[epoch2, step1913]: loss 32.458736
[epoch2, step1914]: loss 45.903297
[epoch2, step1915]: loss 5.132694
[epoch2, step1916]: loss 15.558947
[epoch2, step1917]: loss 10.573950
[epoch2, step1918]: loss 12.337008
[epoch2, step1919]: loss 12.324699
[epoch2, step1920]: loss 11.568645
[epoch2, step1921]: loss 16.836430
[epoch2, step1922]: loss 19.299040
[epoch2, step1923]: loss 14.894979
[epoch2, step1924]: loss 27.441521
[epoch2, step1925]: loss 6.900601
[epoch2, step1926]: loss 5.140709
[epoch2, step1927]: loss 20.675926
[epoch2, step1928]: loss 6.109991
[epoch2, step1929]: loss 14.134218
[epoch2, step1930]: loss 5.474963
[epoch2, step1931]: loss 10.922020
[epoch2, step1932]: loss 14.636817
[epoch2, step1933]: loss 12.822857
[epoch2, step1934]: loss 20.907368
[epoch2, step1935]: loss 7.855673
[epoch2, step1936]: loss 24.584717
[epoch2, step1937]: loss 8.190183
[epoch2, step1938]: loss 15.558744
[epoch2, step1939]: loss 23.559542
[epoch2, step1940]: loss 18.455971
[epoch2, step1941]: loss 31.857620
[epoch2, step1942]: loss 7.427436
[epoch2, step1943]: loss 12.438340
[epoch2, step1944]: loss 7.335168
[epoch2, step1945]: loss 17.255505
[epoch2, step1946]: loss 13.278597
[epoch2, step1947]: loss 18.167038
[epoch2, step1948]: loss 13.927468
[epoch2, step1949]: loss 10.923628
[epoch2, step1950]: loss 4.167555
[epoch2, step1951]: loss 25.204073
[epoch2, step1952]: loss 30.762280
[epoch2, step1953]: loss 37.217121
[epoch2, step1954]: loss 12.802978
[epoch2, step1955]: loss 14.803587
[epoch2, step1956]: loss 17.274836
[epoch2, step1957]: loss 7.105648
[epoch2, step1958]: loss 19.556526
[epoch2, step1959]: loss 23.376959
[epoch2, step1960]: loss 15.618123
[epoch2, step1961]: loss 6.117379
[epoch2, step1962]: loss 15.924338
[epoch2, step1963]: loss 32.657906
[epoch2, step1964]: loss 26.960220
[epoch2, step1965]: loss 37.645966
[epoch2, step1966]: loss 30.023592
[epoch2, step1967]: loss 56.693352
[epoch2, step1968]: loss 15.604519
[epoch2, step1969]: loss 16.780460
[epoch2, step1970]: loss 20.399458
[epoch2, step1971]: loss 36.373928
[epoch2, step1972]: loss 18.837521
[epoch2, step1973]: loss 15.918100
[epoch2, step1974]: loss 12.887188
[epoch2, step1975]: loss 10.764946
[epoch2, step1976]: loss 3.954681
[epoch2, step1977]: loss 6.598963
[epoch2, step1978]: loss 17.921398
[epoch2, step1979]: loss 41.813847
[epoch2, step1980]: loss 16.551266
[epoch2, step1981]: loss 23.399612
[epoch2, step1982]: loss 7.035725
[epoch2, step1983]: loss 11.647906
[epoch2, step1984]: loss 14.503999
[epoch2, step1985]: loss 6.271282
[epoch2, step1986]: loss 17.795078
[epoch2, step1987]: loss 16.702425
[epoch2, step1988]: loss 14.543983
[epoch2, step1989]: loss 11.598177
[epoch2, step1990]: loss 17.701817
[epoch2, step1991]: loss 5.565215
[epoch2, step1992]: loss 4.933333
[epoch2, step1993]: loss 23.960985
[epoch2, step1994]: loss 17.413965
[epoch2, step1995]: loss 19.340498
[epoch2, step1996]: loss 5.848382
[epoch2, step1997]: loss 3.622365
[epoch2, step1998]: loss 20.644365
[epoch2, step1999]: loss 9.489168
[epoch2, step2000]: loss 6.882511
[epoch2, step2001]: loss 10.354202
[epoch2, step2002]: loss 13.813166
[epoch2, step2003]: loss 24.102337
[epoch2, step2004]: loss 20.709789
[epoch2, step2005]: loss 12.517829
[epoch2, step2006]: loss 16.693937
[epoch2, step2007]: loss 16.071190
[epoch2, step2008]: loss 25.119368
[epoch2, step2009]: loss 11.696224
[epoch2, step2010]: loss 10.719259
[epoch2, step2011]: loss 21.230516
[epoch2, step2012]: loss 5.626510
[epoch2, step2013]: loss 14.814973
[epoch2, step2014]: loss 8.736309
[epoch2, step2015]: loss 21.750782
[epoch2, step2016]: loss 7.984562
[epoch2, step2017]: loss 21.970814
[epoch2, step2018]: loss 8.531260
[epoch2, step2019]: loss 41.492683
[epoch2, step2020]: loss 7.120736
[epoch2, step2021]: loss 46.217350
[epoch2, step2022]: loss 11.943165
[epoch2, step2023]: loss 5.250911
[epoch2, step2024]: loss 13.432431
[epoch2, step2025]: loss 34.535576
[epoch2, step2026]: loss 22.911345
[epoch2, step2027]: loss 14.211619
[epoch2, step2028]: loss 11.480151
[epoch2, step2029]: loss 18.262516
[epoch2, step2030]: loss 9.872559
[epoch2, step2031]: loss 29.407492
[epoch2, step2032]: loss 27.930126
[epoch2, step2033]: loss 16.915712
[epoch2, step2034]: loss 15.441131
[epoch2, step2035]: loss 8.239373
[epoch2, step2036]: loss 10.379121
[epoch2, step2037]: loss 55.469627
[epoch2, step2038]: loss 8.520057
[epoch2, step2039]: loss 11.984541
[epoch2, step2040]: loss 8.456081
[epoch2, step2041]: loss 48.111519
[epoch2, step2042]: loss 42.100742
[epoch2, step2043]: loss 8.462606
[epoch2, step2044]: loss 9.333639
[epoch2, step2045]: loss 9.736020
[epoch2, step2046]: loss 15.305416
[epoch2, step2047]: loss 19.216604
[epoch2, step2048]: loss 18.073582
[epoch2, step2049]: loss 9.933504
[epoch2, step2050]: loss 16.903946
[epoch2, step2051]: loss 6.630634
[epoch2, step2052]: loss 9.289260
[epoch2, step2053]: loss 24.947924
[epoch2, step2054]: loss 19.428066
[epoch2, step2055]: loss 5.132786
[epoch2, step2056]: loss 34.554337
[epoch2, step2057]: loss 22.786489
[epoch2, step2058]: loss 15.594198
[epoch2, step2059]: loss 3.245308
[epoch2, step2060]: loss 33.512405
[epoch2, step2061]: loss 6.957305
[epoch2, step2062]: loss 11.367640
[epoch2, step2063]: loss 25.328571
[epoch2, step2064]: loss 9.603175
[epoch2, step2065]: loss 5.284071
[epoch2, step2066]: loss 10.341544
[epoch2, step2067]: loss 9.917063
[epoch2, step2068]: loss 12.276766
[epoch2, step2069]: loss 22.521856
[epoch2, step2070]: loss 8.911046
[epoch2, step2071]: loss 5.270790
[epoch2, step2072]: loss 32.109634
[epoch2, step2073]: loss 7.500016
[epoch2, step2074]: loss 19.822496
[epoch2, step2075]: loss 4.777364
[epoch2, step2076]: loss 26.182583
[epoch2, step2077]: loss 6.073997
[epoch2, step2078]: loss 8.692186
[epoch2, step2079]: loss 18.116396
[epoch2, step2080]: loss 17.060770
[epoch2, step2081]: loss 10.463828
[epoch2, step2082]: loss 11.236730
[epoch2, step2083]: loss 16.975941
[epoch2, step2084]: loss 8.445475
[epoch2, step2085]: loss 23.144436
[epoch2, step2086]: loss 10.146648
[epoch2, step2087]: loss 10.232016
[epoch2, step2088]: loss 8.199741
[epoch2, step2089]: loss 30.210316
[epoch2, step2090]: loss 4.610746
[epoch2, step2091]: loss 9.745269
[epoch2, step2092]: loss 7.560191
[epoch2, step2093]: loss 20.375940
[epoch2, step2094]: loss 18.629709
[epoch2, step2095]: loss 17.231833
[epoch2, step2096]: loss 46.481770
[epoch2, step2097]: loss 31.747108
[epoch2, step2098]: loss 24.751442
[epoch2, step2099]: loss 11.180924
[epoch2, step2100]: loss 9.300350
[epoch2, step2101]: loss 19.164179
[epoch2, step2102]: loss 15.737828
[epoch2, step2103]: loss 20.027084
[epoch2, step2104]: loss 33.498363
[epoch2, step2105]: loss 47.237263
[epoch2, step2106]: loss 11.999623
[epoch2, step2107]: loss 25.757166
[epoch2, step2108]: loss 8.205910
[epoch2, step2109]: loss 34.986805
[epoch2, step2110]: loss 49.043606
[epoch2, step2111]: loss 20.671192
[epoch2, step2112]: loss 15.839337
[epoch2, step2113]: loss 16.298134
[epoch2, step2114]: loss 25.357700
[epoch2, step2115]: loss 4.689236
[epoch2, step2116]: loss 17.620279
[epoch2, step2117]: loss 19.511406
[epoch2, step2118]: loss 20.864010
[epoch2, step2119]: loss 7.885855
[epoch2, step2120]: loss 15.416127
[epoch2, step2121]: loss 6.732805
[epoch2, step2122]: loss 8.393080
[epoch2, step2123]: loss 5.107970
[epoch2, step2124]: loss 15.343576
[epoch2, step2125]: loss 26.626326
[epoch2, step2126]: loss 8.021995
[epoch2, step2127]: loss 17.096312
[epoch2, step2128]: loss 14.760719
[epoch2, step2129]: loss 3.204716
[epoch2, step2130]: loss 11.017187
[epoch2, step2131]: loss 14.237515
[epoch2, step2132]: loss 16.871737
[epoch2, step2133]: loss 25.712194
[epoch2, step2134]: loss 6.188044
[epoch2, step2135]: loss 9.281625
[epoch2, step2136]: loss 9.726832
[epoch2, step2137]: loss 11.368499
[epoch2, step2138]: loss 5.790665
[epoch2, step2139]: loss 16.954548
[epoch2, step2140]: loss 17.717728
[epoch2, step2141]: loss 10.841004
[epoch2, step2142]: loss 10.188011
[epoch2, step2143]: loss 9.916776
[epoch2, step2144]: loss 35.375458
[epoch2, step2145]: loss 13.465170
[epoch2, step2146]: loss 7.281242
[epoch2, step2147]: loss 36.615486
[epoch2, step2148]: loss 14.722376
[epoch2, step2149]: loss 48.654026
[epoch2, step2150]: loss 9.541685
[epoch2, step2151]: loss 10.859541
[epoch2, step2152]: loss 18.285631
[epoch2, step2153]: loss 36.356579
[epoch2, step2154]: loss 12.176493
[epoch2, step2155]: loss 21.848204
[epoch2, step2156]: loss 13.849986
[epoch2, step2157]: loss 10.828126
[epoch2, step2158]: loss 23.127735
[epoch2, step2159]: loss 29.513885
[epoch2, step2160]: loss 5.586244
[epoch2, step2161]: loss 8.053735
[epoch2, step2162]: loss 8.134306
[epoch2, step2163]: loss 13.502319
[epoch2, step2164]: loss 8.292568
[epoch2, step2165]: loss 8.727216
[epoch2, step2166]: loss 3.891742
[epoch2, step2167]: loss 3.356019
[epoch2, step2168]: loss 7.776845
[epoch2, step2169]: loss 8.447119
[epoch2, step2170]: loss 13.344519
[epoch2, step2171]: loss 6.366235
[epoch2, step2172]: loss 4.851491
[epoch2, step2173]: loss 19.842373
[epoch2, step2174]: loss 8.917002
[epoch2, step2175]: loss 9.707847
[epoch2, step2176]: loss 13.653645
[epoch2, step2177]: loss 6.662475
[epoch2, step2178]: loss 33.919189
[epoch2, step2179]: loss 11.760189
[epoch2, step2180]: loss 17.841208
[epoch2, step2181]: loss 17.808908
[epoch2, step2182]: loss 16.564791
[epoch2, step2183]: loss 25.392561
[epoch2, step2184]: loss 14.996255
[epoch2, step2185]: loss 14.458175
[epoch2, step2186]: loss 22.343996
[epoch2, step2187]: loss 23.667978
[epoch2, step2188]: loss 14.148561
[epoch2, step2189]: loss 18.850813
[epoch2, step2190]: loss 12.401368
[epoch2, step2191]: loss 25.006823
[epoch2, step2192]: loss 14.524475
[epoch2, step2193]: loss 24.878559
[epoch2, step2194]: loss 7.062315
[epoch2, step2195]: loss 10.728817
[epoch2, step2196]: loss 12.983623
[epoch2, step2197]: loss 11.760113
[epoch2, step2198]: loss 6.792832
[epoch2, step2199]: loss 5.402203
[epoch2, step2200]: loss 27.367548
[epoch2, step2201]: loss 15.963337
[epoch2, step2202]: loss 13.892314
[epoch2, step2203]: loss 9.660632
[epoch2, step2204]: loss 20.738779
[epoch2, step2205]: loss 10.145012
[epoch2, step2206]: loss 8.664134
[epoch2, step2207]: loss 24.482559
[epoch2, step2208]: loss 5.660262
[epoch2, step2209]: loss 6.417635
[epoch2, step2210]: loss 8.531689
[epoch2, step2211]: loss 25.098621
[epoch2, step2212]: loss 9.901794
[epoch2, step2213]: loss 7.264713
[epoch2, step2214]: loss 14.084867
[epoch2, step2215]: loss 6.759152
[epoch2, step2216]: loss 25.005285
[epoch2, step2217]: loss 8.075094
[epoch2, step2218]: loss 15.580929
[epoch2, step2219]: loss 8.503244
[epoch2, step2220]: loss 9.749978
[epoch2, step2221]: loss 3.532567
[epoch2, step2222]: loss 5.766074
[epoch2, step2223]: loss 8.870366
[epoch2, step2224]: loss 34.602692
[epoch2, step2225]: loss 18.719711
[epoch2, step2226]: loss 9.159347
[epoch2, step2227]: loss 20.041834
[epoch2, step2228]: loss 34.499043
[epoch2, step2229]: loss 25.794159
[epoch2, step2230]: loss 10.715468
[epoch2, step2231]: loss 20.559998
[epoch2, step2232]: loss 14.060747
[epoch2, step2233]: loss 21.968145
[epoch2, step2234]: loss 45.164650
[epoch2, step2235]: loss 19.018637
[epoch2, step2236]: loss 16.031300
[epoch2, step2237]: loss 7.696129
[epoch2, step2238]: loss 17.821390
[epoch2, step2239]: loss 32.317730
[epoch2, step2240]: loss 15.435926
[epoch2, step2241]: loss 22.675505
[epoch2, step2242]: loss 10.343623
[epoch2, step2243]: loss 12.854831
[epoch2, step2244]: loss 14.552794
[epoch2, step2245]: loss 16.864292
[epoch2, step2246]: loss 11.819187
[epoch2, step2247]: loss 22.875044
[epoch2, step2248]: loss 9.733334
[epoch2, step2249]: loss 23.207664
[epoch2, step2250]: loss 9.365452
[epoch2, step2251]: loss 15.575034
[epoch2, step2252]: loss 20.161392
[epoch2, step2253]: loss 4.638619
[epoch2, step2254]: loss 11.006351
[epoch2, step2255]: loss 26.585091
[epoch2, step2256]: loss 9.698394
[epoch2, step2257]: loss 6.285907
[epoch2, step2258]: loss 13.067234
[epoch2, step2259]: loss 24.677082
[epoch2, step2260]: loss 35.186985
[epoch2, step2261]: loss 21.389297
[epoch2, step2262]: loss 16.571392
[epoch2, step2263]: loss 8.932239
[epoch2, step2264]: loss 10.840394
[epoch2, step2265]: loss 24.933317
[epoch2, step2266]: loss 24.676920
[epoch2, step2267]: loss 12.246964
[epoch2, step2268]: loss 39.864815
[epoch2, step2269]: loss 6.846521
[epoch2, step2270]: loss 10.342089
[epoch2, step2271]: loss 15.585601
[epoch2, step2272]: loss 10.520758
[epoch2, step2273]: loss 23.250340
[epoch2, step2274]: loss 7.611039
[epoch2, step2275]: loss 17.767862
[epoch2, step2276]: loss 6.040423
[epoch2, step2277]: loss 46.576439
[epoch2, step2278]: loss 20.494261
[epoch2, step2279]: loss 27.165142
[epoch2, step2280]: loss 36.157089
[epoch2, step2281]: loss 21.087978
[epoch2, step2282]: loss 5.341613
[epoch2, step2283]: loss 21.186218
[epoch2, step2284]: loss 19.223324
[epoch2, step2285]: loss 18.059786
[epoch2, step2286]: loss 9.453848
[epoch2, step2287]: loss 14.113836
[epoch2, step2288]: loss 12.002933
[epoch2, step2289]: loss 9.169100
[epoch2, step2290]: loss 9.852576
[epoch2, step2291]: loss 23.755917
[epoch2, step2292]: loss 20.815163
[epoch2, step2293]: loss 22.254288
[epoch2, step2294]: loss 35.717022
[epoch2, step2295]: loss 52.164204
[epoch2, step2296]: loss 10.126711
[epoch2, step2297]: loss 14.792736
[epoch2, step2298]: loss 11.577065
[epoch2, step2299]: loss 20.151476
[epoch2, step2300]: loss 10.315178
[epoch2, step2301]: loss 33.939095
[epoch2, step2302]: loss 9.670732
[epoch2, step2303]: loss 21.762455
[epoch2, step2304]: loss 25.968288
[epoch2, step2305]: loss 16.502043
[epoch2, step2306]: loss 7.285998
[epoch2, step2307]: loss 5.680198
[epoch2, step2308]: loss 9.276901
[epoch2, step2309]: loss 26.596966
[epoch2, step2310]: loss 7.855802
[epoch2, step2311]: loss 33.849655
[epoch2, step2312]: loss 8.810662
[epoch2, step2313]: loss 8.265318
[epoch2, step2314]: loss 15.456470
[epoch2, step2315]: loss 17.248213
[epoch2, step2316]: loss 13.303142
[epoch2, step2317]: loss 20.874662
[epoch2, step2318]: loss 37.733318
[epoch2, step2319]: loss 27.750126
[epoch2, step2320]: loss 7.660717
[epoch2, step2321]: loss 18.761118
[epoch2, step2322]: loss 4.545197
[epoch2, step2323]: loss 16.972036
[epoch2, step2324]: loss 17.357769
[epoch2, step2325]: loss 24.614748
[epoch2, step2326]: loss 39.923176
[epoch2, step2327]: loss 13.632275
[epoch2, step2328]: loss 9.846128
[epoch2, step2329]: loss 21.061132
[epoch2, step2330]: loss 8.903228
[epoch2, step2331]: loss 33.136902
[epoch2, step2332]: loss 16.954725
[epoch2, step2333]: loss 9.659554
[epoch2, step2334]: loss 15.584256
[epoch2, step2335]: loss 9.220134
[epoch2, step2336]: loss 24.422539
[epoch2, step2337]: loss 35.320938
[epoch2, step2338]: loss 15.852002
[epoch2, step2339]: loss 25.580770
[epoch2, step2340]: loss 9.768273
[epoch2, step2341]: loss 4.165238
[epoch2, step2342]: loss 7.072315
[epoch2, step2343]: loss 16.938492
[epoch2, step2344]: loss 6.030179
[epoch2, step2345]: loss 28.182014
[epoch2, step2346]: loss 29.888975
[epoch2, step2347]: loss 8.314584
[epoch2, step2348]: loss 3.586058
[epoch2, step2349]: loss 14.727196
[epoch2, step2350]: loss 14.195434
[epoch2, step2351]: loss 19.624155
[epoch2, step2352]: loss 5.099735
[epoch2, step2353]: loss 23.244514
[epoch2, step2354]: loss 31.731693
[epoch2, step2355]: loss 34.454582
[epoch2, step2356]: loss 24.688078
[epoch2, step2357]: loss 14.152242
[epoch2, step2358]: loss 17.541155
[epoch2, step2359]: loss 18.149025
[epoch2, step2360]: loss 33.040527
[epoch2, step2361]: loss 20.117203
[epoch2, step2362]: loss 12.145259
[epoch2, step2363]: loss 18.309149
[epoch2, step2364]: loss 16.173103
[epoch2, step2365]: loss 15.345043
[epoch2, step2366]: loss 10.118455
[epoch2, step2367]: loss 12.831577
[epoch2, step2368]: loss 7.539462
[epoch2, step2369]: loss 32.945019
[epoch2, step2370]: loss 5.051126
[epoch2, step2371]: loss 9.943486
[epoch2, step2372]: loss 4.750132
[epoch2, step2373]: loss 33.428879
[epoch2, step2374]: loss 6.215005
[epoch2, step2375]: loss 8.722563
[epoch2, step2376]: loss 6.407994
[epoch2, step2377]: loss 5.939304
[epoch2, step2378]: loss 6.527257
[epoch2, step2379]: loss 8.976972
[epoch2, step2380]: loss 27.842331
[epoch2, step2381]: loss 11.745817
[epoch2, step2382]: loss 3.971220
[epoch2, step2383]: loss 14.300747
[epoch2, step2384]: loss 11.473404
[epoch2, step2385]: loss 16.235474
[epoch2, step2386]: loss 17.182570
[epoch2, step2387]: loss 10.785714
[epoch2, step2388]: loss 13.653748
[epoch2, step2389]: loss 6.889317
[epoch2, step2390]: loss 7.049386
[epoch2, step2391]: loss 5.290823
[epoch2, step2392]: loss 12.596965
[epoch2, step2393]: loss 29.690815
[epoch2, step2394]: loss 9.207898
[epoch2, step2395]: loss 31.699024
[epoch2, step2396]: loss 20.205566
[epoch2, step2397]: loss 22.396091
[epoch2, step2398]: loss 8.937620
[epoch2, step2399]: loss 38.075722
[epoch2, step2400]: loss 21.189346
[epoch2, step2401]: loss 14.616673
[epoch2, step2402]: loss 20.138859
[epoch2, step2403]: loss 26.187197
[epoch2, step2404]: loss 10.505532
[epoch2, step2405]: loss 19.655409
[epoch2, step2406]: loss 14.142580
[epoch2, step2407]: loss 14.592767
[epoch2, step2408]: loss 8.252132
[epoch2, step2409]: loss 23.562895
[epoch2, step2410]: loss 9.101385
[epoch2, step2411]: loss 9.342177
[epoch2, step2412]: loss 31.009186
[epoch2, step2413]: loss 9.380630
[epoch2, step2414]: loss 9.840294
[epoch2, step2415]: loss 9.176882
[epoch2, step2416]: loss 17.210878
[epoch2, step2417]: loss 13.848516
[epoch2, step2418]: loss 15.606403
[epoch2, step2419]: loss 24.800022
[epoch2, step2420]: loss 41.493576
[epoch2, step2421]: loss 19.028994
[epoch2, step2422]: loss 17.429943
[epoch2, step2423]: loss 12.533054
[epoch2, step2424]: loss 14.631804
[epoch2, step2425]: loss 16.296286
[epoch2, step2426]: loss 7.817353
[epoch2, step2427]: loss 4.171481
[epoch2, step2428]: loss 9.873491
[epoch2, step2429]: loss 14.735840
[epoch2, step2430]: loss 12.446841
[epoch2, step2431]: loss 36.306690
[epoch2, step2432]: loss 9.428204
[epoch2, step2433]: loss 43.606621
[epoch2, step2434]: loss 23.108940
[epoch2, step2435]: loss 19.515291
[epoch2, step2436]: loss 11.906502
[epoch2, step2437]: loss 4.781462
[epoch2, step2438]: loss 28.148281
[epoch2, step2439]: loss 20.336498
[epoch2, step2440]: loss 27.310242
[epoch2, step2441]: loss 12.858694
[epoch2, step2442]: loss 25.237097
[epoch2, step2443]: loss 30.977222
[epoch2, step2444]: loss 17.878990
[epoch2, step2445]: loss 17.984104
[epoch2, step2446]: loss 18.929691
[epoch2, step2447]: loss 8.319754
[epoch2, step2448]: loss 21.755129
[epoch2, step2449]: loss 46.015755
[epoch2, step2450]: loss 25.155369
[epoch2, step2451]: loss 21.050200
[epoch2, step2452]: loss 32.880638
[epoch2, step2453]: loss 11.108918
[epoch2, step2454]: loss 19.081816
[epoch2, step2455]: loss 31.469879
[epoch2, step2456]: loss 14.534591
[epoch2, step2457]: loss 17.924498
[epoch2, step2458]: loss 18.737265
[epoch2, step2459]: loss 7.413754
[epoch2, step2460]: loss 12.187980
[epoch2, step2461]: loss 12.562796
[epoch2, step2462]: loss 24.950760
[epoch2, step2463]: loss 14.962764
[epoch2, step2464]: loss 16.653772
[epoch2, step2465]: loss 23.114014
[epoch2, step2466]: loss 28.134155
[epoch2, step2467]: loss 16.709839
[epoch2, step2468]: loss 8.472665
[epoch2, step2469]: loss 10.513723
[epoch2, step2470]: loss 31.620564
[epoch2, step2471]: loss 5.127075
[epoch2, step2472]: loss 20.231182
[epoch2, step2473]: loss 23.996944
[epoch2, step2474]: loss 9.381496
[epoch2, step2475]: loss 4.747156
[epoch2, step2476]: loss 10.542130
[epoch2, step2477]: loss 8.005728
[epoch2, step2478]: loss 14.365211
[epoch2, step2479]: loss 31.593641
[epoch2, step2480]: loss 15.464138
[epoch2, step2481]: loss 15.542906
[epoch2, step2482]: loss 10.991597
[epoch2, step2483]: loss 10.417478
[epoch2, step2484]: loss 36.453117
[epoch2, step2485]: loss 19.430325
[epoch2, step2486]: loss 14.474153
[epoch2, step2487]: loss 10.506394
[epoch2, step2488]: loss 20.203949
[epoch2, step2489]: loss 4.891201
[epoch2, step2490]: loss 3.932347
[epoch2, step2491]: loss 14.124009
[epoch2, step2492]: loss 4.172455
[epoch2, step2493]: loss 18.137127
[epoch2, step2494]: loss 21.727322
[epoch2, step2495]: loss 4.700404
[epoch2, step2496]: loss 7.927178
[epoch2, step2497]: loss 10.490379
[epoch2, step2498]: loss 7.863400
[epoch2, step2499]: loss 22.564428
[epoch2, step2500]: loss 7.032827
[epoch2, step2501]: loss 32.887505
[epoch2, step2502]: loss 9.724084
[epoch2, step2503]: loss 15.550713
[epoch2, step2504]: loss 10.003229
[epoch2, step2505]: loss 6.920312
[epoch2, step2506]: loss 17.932659
[epoch2, step2507]: loss 13.040364
[epoch2, step2508]: loss 14.624210
[epoch2, step2509]: loss 24.675999
[epoch2, step2510]: loss 4.681255
[epoch2, step2511]: loss 6.954170
[epoch2, step2512]: loss 17.630037
[epoch2, step2513]: loss 11.012411
[epoch2, step2514]: loss 53.153622
[epoch2, step2515]: loss 23.433649
[epoch2, step2516]: loss 5.687824
[epoch2, step2517]: loss 15.621522
[epoch2, step2518]: loss 14.217939
[epoch2, step2519]: loss 26.813873
[epoch2, step2520]: loss 16.361153
[epoch2, step2521]: loss 6.637975
[epoch2, step2522]: loss 8.310156
[epoch2, step2523]: loss 12.753328
[epoch2, step2524]: loss 10.871946
[epoch2, step2525]: loss 21.217049
[epoch2, step2526]: loss 25.703129
[epoch2, step2527]: loss 5.653821
[epoch2, step2528]: loss 3.996020
[epoch2, step2529]: loss 9.005363
[epoch2, step2530]: loss 10.216241
[epoch2, step2531]: loss 38.508553
[epoch2, step2532]: loss 24.526499
[epoch2, step2533]: loss 9.975794
[epoch2, step2534]: loss 24.050217
[epoch2, step2535]: loss 21.009214
[epoch2, step2536]: loss 5.132931
[epoch2, step2537]: loss 12.478908
[epoch2, step2538]: loss 33.042442
[epoch2, step2539]: loss 11.140705
[epoch2, step2540]: loss 19.525032
[epoch2, step2541]: loss 16.453320
[epoch2, step2542]: loss 11.589556
[epoch2, step2543]: loss 3.591326
[epoch2, step2544]: loss 22.512077
[epoch2, step2545]: loss 15.870851
[epoch2, step2546]: loss 9.627354
[epoch2, step2547]: loss 9.657815
[epoch2, step2548]: loss 12.880673
[epoch2, step2549]: loss 21.305922
[epoch2, step2550]: loss 16.733955
[epoch2, step2551]: loss 5.003038
[epoch2, step2552]: loss 53.441689
[epoch2, step2553]: loss 30.118557
[epoch2, step2554]: loss 13.366845
[epoch2, step2555]: loss 12.043218
[epoch2, step2556]: loss 7.494779
[epoch2, step2557]: loss 19.829794
[epoch2, step2558]: loss 3.839774
[epoch2, step2559]: loss 14.596746
[epoch2, step2560]: loss 27.752716
[epoch2, step2561]: loss 5.492479
[epoch2, step2562]: loss 18.219252
[epoch2, step2563]: loss 7.648387
[epoch2, step2564]: loss 8.744559
[epoch2, step2565]: loss 38.106060
[epoch2, step2566]: loss 43.242981
[epoch2, step2567]: loss 4.738423
[epoch2, step2568]: loss 18.385094
[epoch2, step2569]: loss 46.780064
[epoch2, step2570]: loss 19.385475
[epoch2, step2571]: loss 28.876312
[epoch2, step2572]: loss 12.567100
[epoch2, step2573]: loss 40.525551
[epoch2, step2574]: loss 23.740889
[epoch2, step2575]: loss 6.867831
[epoch2, step2576]: loss 37.530247
[epoch2, step2577]: loss 5.889048
[epoch2, step2578]: loss 32.519310
[epoch2, step2579]: loss 7.202063
[epoch2, step2580]: loss 19.687975
[epoch2, step2581]: loss 24.755789
[epoch2, step2582]: loss 22.424719
[epoch2, step2583]: loss 31.121098
[epoch2, step2584]: loss 10.799562
[epoch2, step2585]: loss 17.406305
[epoch2, step2586]: loss 18.182753
[epoch2, step2587]: loss 9.490499
[epoch2, step2588]: loss 12.790584
[epoch2, step2589]: loss 16.155806
[epoch2, step2590]: loss 17.962366
[epoch2, step2591]: loss 30.292976
[epoch2, step2592]: loss 11.623446
[epoch2, step2593]: loss 3.643373
[epoch2, step2594]: loss 11.736677
[epoch2, step2595]: loss 8.195091
[epoch2, step2596]: loss 12.549797
[epoch2, step2597]: loss 14.917958
[epoch2, step2598]: loss 7.152108
[epoch2, step2599]: loss 4.539029
[epoch2, step2600]: loss 9.784893
[epoch2, step2601]: loss 7.158878
[epoch2, step2602]: loss 11.362674
[epoch2, step2603]: loss 5.666177
[epoch2, step2604]: loss 7.929524
[epoch2, step2605]: loss 11.215330
[epoch2, step2606]: loss 6.903768
[epoch2, step2607]: loss 9.728287
[epoch2, step2608]: loss 12.622828
[epoch2, step2609]: loss 16.437111
[epoch2, step2610]: loss 7.254796
[epoch2, step2611]: loss 9.058231
[epoch2, step2612]: loss 25.700453
[epoch2, step2613]: loss 3.189109
[epoch2, step2614]: loss 39.681141
[epoch2, step2615]: loss 19.878693
[epoch2, step2616]: loss 8.533464
[epoch2, step2617]: loss 11.201091
[epoch2, step2618]: loss 27.480217
[epoch2, step2619]: loss 9.229150
[epoch2, step2620]: loss 41.807438
[epoch2, step2621]: loss 15.645627
[epoch2, step2622]: loss 5.855907
[epoch2, step2623]: loss 10.174503
[epoch2, step2624]: loss 6.476108
[epoch2, step2625]: loss 5.257938
[epoch2, step2626]: loss 7.878962
[epoch2, step2627]: loss 10.284577
[epoch2, step2628]: loss 11.925793
[epoch2, step2629]: loss 24.306948
[epoch2, step2630]: loss 22.419609
[epoch2, step2631]: loss 23.742390
[epoch2, step2632]: loss 18.888256
[epoch2, step2633]: loss 8.092566
[epoch2, step2634]: loss 26.615751
[epoch2, step2635]: loss 7.159757
[epoch2, step2636]: loss 10.221813
[epoch2, step2637]: loss 17.585474
[epoch2, step2638]: loss 19.662590
[epoch2, step2639]: loss 31.783863
[epoch2, step2640]: loss 20.515299
[epoch2, step2641]: loss 40.151222
[epoch2, step2642]: loss 33.978664
[epoch2, step2643]: loss 9.787116
[epoch2, step2644]: loss 10.709649
[epoch2, step2645]: loss 14.152783
[epoch2, step2646]: loss 19.865040
[epoch2, step2647]: loss 26.555063
[epoch2, step2648]: loss 5.359556
[epoch2, step2649]: loss 17.288853
[epoch2, step2650]: loss 32.044525
[epoch2, step2651]: loss 9.814381
[epoch2, step2652]: loss 11.715666
[epoch2, step2653]: loss 10.229228
[epoch2, step2654]: loss 13.292237
[epoch2, step2655]: loss 7.130387
[epoch2, step2656]: loss 15.741939
[epoch2, step2657]: loss 10.036146
[epoch2, step2658]: loss 34.035957
[epoch2, step2659]: loss 5.663239
[epoch2, step2660]: loss 8.213330
[epoch2, step2661]: loss 19.535748
[epoch2, step2662]: loss 7.046521
[epoch2, step2663]: loss 9.413530
[epoch2, step2664]: loss 10.343660
[epoch2, step2665]: loss 10.712072
[epoch2, step2666]: loss 5.265719
[epoch2, step2667]: loss 9.545216
[epoch2, step2668]: loss 32.387627
[epoch2, step2669]: loss 10.822774
[epoch2, step2670]: loss 15.602090
[epoch2, step2671]: loss 12.141714
[epoch2, step2672]: loss 15.249092
[epoch2, step2673]: loss 9.200406
[epoch2, step2674]: loss 4.861906
[epoch2, step2675]: loss 37.143559
[epoch2, step2676]: loss 15.605781
[epoch2, step2677]: loss 8.002316
[epoch2, step2678]: loss 19.053217
[epoch2, step2679]: loss 8.200180
[epoch2, step2680]: loss 18.606207
[epoch2, step2681]: loss 14.277087
[epoch2, step2682]: loss 5.420650
[epoch2, step2683]: loss 31.085155
[epoch2, step2684]: loss 9.903198
[epoch2, step2685]: loss 14.977331
[epoch2, step2686]: loss 23.585938
[epoch2, step2687]: loss 12.131989
[epoch2, step2688]: loss 26.255056
[epoch2, step2689]: loss 9.098643
[epoch2, step2690]: loss 14.709745
[epoch2, step2691]: loss 21.212069
[epoch2, step2692]: loss 4.179605
[epoch2, step2693]: loss 7.725584
[epoch2, step2694]: loss 20.911808
[epoch2, step2695]: loss 11.254101
[epoch2, step2696]: loss 29.531199
[epoch2, step2697]: loss 8.137669
[epoch2, step2698]: loss 30.468067
[epoch2, step2699]: loss 17.772755
[epoch2, step2700]: loss 20.124205
[epoch2, step2701]: loss 11.648344
[epoch2, step2702]: loss 26.164665
[epoch2, step2703]: loss 15.155094
[epoch2, step2704]: loss 20.359484
[epoch2, step2705]: loss 11.509599
[epoch2, step2706]: loss 13.082330
[epoch2, step2707]: loss 24.271963
[epoch2, step2708]: loss 25.046860
[epoch2, step2709]: loss 15.298078
[epoch2, step2710]: loss 17.747252
[epoch2, step2711]: loss 9.306307
[epoch2, step2712]: loss 38.875324
[epoch2, step2713]: loss 27.029305
[epoch2, step2714]: loss 7.647294
[epoch2, step2715]: loss 7.523555
[epoch2, step2716]: loss 10.042981
[epoch2, step2717]: loss 17.433483
[epoch2, step2718]: loss 22.267429
[epoch2, step2719]: loss 3.958159
[epoch2, step2720]: loss 6.778454
[epoch2, step2721]: loss 12.149708
[epoch2, step2722]: loss 3.646864
[epoch2, step2723]: loss 24.979576
[epoch2, step2724]: loss 13.557254
[epoch2, step2725]: loss 26.432804
[epoch2, step2726]: loss 31.358538
[epoch2, step2727]: loss 9.453918
[epoch2, step2728]: loss 13.766607
[epoch2, step2729]: loss 8.965329
[epoch2, step2730]: loss 4.094543
[epoch2, step2731]: loss 3.598510
[epoch2, step2732]: loss 37.009907
[epoch2, step2733]: loss 18.204382
[epoch2, step2734]: loss 22.673944
[epoch2, step2735]: loss 19.472383
[epoch2, step2736]: loss 9.425373
[epoch2, step2737]: loss 3.498585
[epoch2, step2738]: loss 3.094426
[epoch2, step2739]: loss 5.222425
[epoch2, step2740]: loss 21.358797
[epoch2, step2741]: loss 13.462477
[epoch2, step2742]: loss 22.003395
[epoch2, step2743]: loss 20.550148
[epoch2, step2744]: loss 13.126047
[epoch2, step2745]: loss 22.435459
[epoch2, step2746]: loss 5.053329
[epoch2, step2747]: loss 10.594713
[epoch2, step2748]: loss 7.266320
[epoch2, step2749]: loss 13.945498
[epoch2, step2750]: loss 17.956745
[epoch2, step2751]: loss 15.193647
[epoch2, step2752]: loss 15.222553
[epoch2, step2753]: loss 4.229837
[epoch2, step2754]: loss 17.641140
[epoch2, step2755]: loss 18.968987
[epoch2, step2756]: loss 11.692413
[epoch2, step2757]: loss 21.360569
[epoch2, step2758]: loss 7.809942
[epoch2, step2759]: loss 5.628598
[epoch2, step2760]: loss 21.960091
[epoch2, step2761]: loss 15.311590
[epoch2, step2762]: loss 2.986176
[epoch2, step2763]: loss 14.000775
[epoch2, step2764]: loss 20.237383
[epoch2, step2765]: loss 10.358263
[epoch2, step2766]: loss 13.183774
[epoch2, step2767]: loss 18.825727
[epoch2, step2768]: loss 15.048120
[epoch2, step2769]: loss 11.768718
[epoch2, step2770]: loss 25.492258
[epoch2, step2771]: loss 11.557506
[epoch2, step2772]: loss 16.298809
[epoch2, step2773]: loss 18.108955
[epoch2, step2774]: loss 9.366056
[epoch2, step2775]: loss 13.794763
[epoch2, step2776]: loss 41.544952
[epoch2, step2777]: loss 8.023702
[epoch2, step2778]: loss 6.994853
[epoch2, step2779]: loss 8.800136
[epoch2, step2780]: loss 5.235556
[epoch2, step2781]: loss 28.516899
[epoch2, step2782]: loss 6.239202
[epoch2, step2783]: loss 10.857281
[epoch2, step2784]: loss 34.365803
[epoch2, step2785]: loss 34.093311
[epoch2, step2786]: loss 17.992340
[epoch2, step2787]: loss 6.845675
[epoch2, step2788]: loss 8.764489
[epoch2, step2789]: loss 12.354438
[epoch2, step2790]: loss 9.255048
[epoch2, step2791]: loss 23.854904
[epoch2, step2792]: loss 26.086809
[epoch2, step2793]: loss 42.567387
[epoch2, step2794]: loss 13.827322
[epoch2, step2795]: loss 36.661835
[epoch2, step2796]: loss 19.362061
[epoch2, step2797]: loss 4.235837
[epoch2, step2798]: loss 9.939196
[epoch2, step2799]: loss 8.515414
[epoch2, step2800]: loss 8.363010
[epoch2, step2801]: loss 10.258022
[epoch2, step2802]: loss 32.390381
[epoch2, step2803]: loss 12.902540
[epoch2, step2804]: loss 16.729031
[epoch2, step2805]: loss 21.155848
[epoch2, step2806]: loss 6.703166
[epoch2, step2807]: loss 26.857277
[epoch2, step2808]: loss 5.954759
[epoch2, step2809]: loss 18.782291
[epoch2, step2810]: loss 9.096154
[epoch2, step2811]: loss 7.804595
[epoch2, step2812]: loss 15.611873
[epoch2, step2813]: loss 7.196096
[epoch2, step2814]: loss 9.001506
[epoch2, step2815]: loss 13.141323
[epoch2, step2816]: loss 7.874565
[epoch2, step2817]: loss 12.294895
[epoch2, step2818]: loss 33.218300
[epoch2, step2819]: loss 31.673527
[epoch2, step2820]: loss 7.504875
[epoch2, step2821]: loss 19.249088
[epoch2, step2822]: loss 6.102258
[epoch2, step2823]: loss 20.489786
[epoch2, step2824]: loss 12.695177
[epoch2, step2825]: loss 29.782272
[epoch2, step2826]: loss 21.135279
[epoch2, step2827]: loss 21.995703
[epoch2, step2828]: loss 11.709304
[epoch2, step2829]: loss 21.204084
[epoch2, step2830]: loss 7.730130
[epoch2, step2831]: loss 11.253778
[epoch2, step2832]: loss 18.749731
[epoch2, step2833]: loss 30.515812
[epoch2, step2834]: loss 19.052036
[epoch2, step2835]: loss 23.754475
[epoch2, step2836]: loss 21.590326
[epoch2, step2837]: loss 3.288982
[epoch2, step2838]: loss 4.010735
[epoch2, step2839]: loss 23.475559
[epoch2, step2840]: loss 7.726964
[epoch2, step2841]: loss 14.764040
[epoch2, step2842]: loss 10.950092
[epoch2, step2843]: loss 31.550701
[epoch2, step2844]: loss 26.097929
[epoch2, step2845]: loss 9.277090
[epoch2, step2846]: loss 10.563428
[epoch2, step2847]: loss 20.061470
[epoch2, step2848]: loss 6.720020
[epoch2, step2849]: loss 8.163715
[epoch2, step2850]: loss 15.567822
[epoch2, step2851]: loss 21.153297
[epoch2, step2852]: loss 34.320194
[epoch2, step2853]: loss 8.770388
[epoch2, step2854]: loss 21.471468
[epoch2, step2855]: loss 25.739050
[epoch2, step2856]: loss 7.211435
[epoch2, step2857]: loss 28.318624
[epoch2, step2858]: loss 14.030431
[epoch2, step2859]: loss 23.534164
[epoch2, step2860]: loss 13.483968
[epoch2, step2861]: loss 8.622095
[epoch2, step2862]: loss 13.378910
[epoch2, step2863]: loss 9.341302
[epoch2, step2864]: loss 17.797071
[epoch2, step2865]: loss 6.063237
[epoch2, step2866]: loss 34.078403
[epoch2, step2867]: loss 10.641827
[epoch2, step2868]: loss 13.350386
[epoch2, step2869]: loss 18.164507
[epoch2, step2870]: loss 12.000921
[epoch2, step2871]: loss 11.973657
[epoch2, step2872]: loss 17.374027
[epoch2, step2873]: loss 6.286674
[epoch2, step2874]: loss 15.710500
[epoch2, step2875]: loss 15.701574
[epoch2, step2876]: loss 6.275906
[epoch2, step2877]: loss 6.894630
[epoch2, step2878]: loss 13.096119
[epoch2, step2879]: loss 28.885187
[epoch2, step2880]: loss 3.432449
[epoch2, step2881]: loss 5.176739
[epoch2, step2882]: loss 3.678826
[epoch2, step2883]: loss 6.449995
[epoch2, step2884]: loss 14.261377
[epoch2, step2885]: loss 11.220590
[epoch2, step2886]: loss 7.182821
[epoch2, step2887]: loss 16.224957
[epoch2, step2888]: loss 17.267969
[epoch2, step2889]: loss 9.307327
[epoch2, step2890]: loss 8.932633
[epoch2, step2891]: loss 12.523932
[epoch2, step2892]: loss 18.805969
[epoch2, step2893]: loss 10.177092
[epoch2, step2894]: loss 23.047554
[epoch2, step2895]: loss 13.697036
[epoch2, step2896]: loss 11.950765
[epoch2, step2897]: loss 10.770422
[epoch2, step2898]: loss 21.487368
[epoch2, step2899]: loss 53.780804
[epoch2, step2900]: loss 15.121969
[epoch2, step2901]: loss 18.613928
[epoch2, step2902]: loss 8.417344
[epoch2, step2903]: loss 9.335081
[epoch2, step2904]: loss 4.382320
[epoch2, step2905]: loss 13.366595
[epoch2, step2906]: loss 11.784297
[epoch2, step2907]: loss 4.479487
[epoch2, step2908]: loss 17.017965
[epoch2, step2909]: loss 29.115517
[epoch2, step2910]: loss 15.073528
[epoch2, step2911]: loss 12.796460
[epoch2, step2912]: loss 10.551379
[epoch2, step2913]: loss 20.374462
[epoch2, step2914]: loss 7.158788
[epoch2, step2915]: loss 7.747926
[epoch2, step2916]: loss 17.821178
[epoch2, step2917]: loss 27.382442
[epoch2, step2918]: loss 11.038528
[epoch2, step2919]: loss 40.760803
[epoch2, step2920]: loss 19.379448
[epoch2, step2921]: loss 5.319767
[epoch2, step2922]: loss 4.187366
[epoch2, step2923]: loss 11.079382
[epoch2, step2924]: loss 27.630714
[epoch2, step2925]: loss 14.519171
[epoch2, step2926]: loss 25.560583
[epoch2, step2927]: loss 14.254561
[epoch2, step2928]: loss 11.385491
[epoch2, step2929]: loss 22.934080
[epoch2, step2930]: loss 15.559205
[epoch2, step2931]: loss 21.604202
[epoch2, step2932]: loss 16.581984
[epoch2, step2933]: loss 28.203444
[epoch2, step2934]: loss 32.185944
[epoch2, step2935]: loss 14.137803
[epoch2, step2936]: loss 23.530052
[epoch2, step2937]: loss 12.058666
[epoch2, step2938]: loss 32.660011
[epoch2, step2939]: loss 16.720982
[epoch2, step2940]: loss 6.398749
[epoch2, step2941]: loss 8.485947
[epoch2, step2942]: loss 12.971229
[epoch2, step2943]: loss 23.838327
[epoch2, step2944]: loss 21.767603
[epoch2, step2945]: loss 37.488071
[epoch2, step2946]: loss 36.429607
[epoch2, step2947]: loss 16.313412
[epoch2, step2948]: loss 5.779204
[epoch2, step2949]: loss 16.707996
[epoch2, step2950]: loss 17.871819
[epoch2, step2951]: loss 12.992422
[epoch2, step2952]: loss 43.262402
[epoch2, step2953]: loss 51.524040
[epoch2, step2954]: loss 24.449003
[epoch2, step2955]: loss 7.608812
[epoch2, step2956]: loss 5.635514
[epoch2, step2957]: loss 10.816526
[epoch2, step2958]: loss 11.199441
[epoch2, step2959]: loss 11.702755
[epoch2, step2960]: loss 7.331864
[epoch2, step2961]: loss 19.855412
[epoch2, step2962]: loss 9.814585
[epoch2, step2963]: loss 19.719023
[epoch2, step2964]: loss 12.991073
[epoch2, step2965]: loss 12.022787
[epoch2, step2966]: loss 35.745022
[epoch2, step2967]: loss 9.239685
[epoch2, step2968]: loss 19.024185
[epoch2, step2969]: loss 19.202404
[epoch2, step2970]: loss 25.590103
[epoch2, step2971]: loss 13.810505
[epoch2, step2972]: loss 20.848551
[epoch2, step2973]: loss 5.979532
[epoch2, step2974]: loss 12.346063
[epoch2, step2975]: loss 10.963536
[epoch2, step2976]: loss 21.186819
[epoch2, step2977]: loss 19.413269
[epoch2, step2978]: loss 8.644785
[epoch2, step2979]: loss 5.963664
[epoch2, step2980]: loss 26.310785
[epoch2, step2981]: loss 9.486709
[epoch2, step2982]: loss 18.508837
[epoch2, step2983]: loss 8.751875
[epoch2, step2984]: loss 5.886533
[epoch2, step2985]: loss 9.273588
[epoch2, step2986]: loss 10.120100
[epoch2, step2987]: loss 4.293407
[epoch2, step2988]: loss 9.860788
[epoch2, step2989]: loss 21.330088
[epoch2, step2990]: loss 17.271275
[epoch2, step2991]: loss 30.161383
[epoch2, step2992]: loss 9.373674
[epoch2, step2993]: loss 5.373746
[epoch2, step2994]: loss 23.727875
[epoch2, step2995]: loss 10.442685
[epoch2, step2996]: loss 11.740843
[epoch2, step2997]: loss 21.145407
[epoch2, step2998]: loss 9.676948
[epoch2, step2999]: loss 21.071224
[epoch2, step3000]: loss 7.850773
[epoch2, step3001]: loss 19.005095
[epoch2, step3002]: loss 5.469854
[epoch2, step3003]: loss 5.385181
[epoch2, step3004]: loss 14.206161
[epoch2, step3005]: loss 10.820833
[epoch2, step3006]: loss 12.694334
[epoch2, step3007]: loss 11.103515
[epoch2, step3008]: loss 16.870651
[epoch2, step3009]: loss 7.687353
[epoch2, step3010]: loss 9.243433
[epoch2, step3011]: loss 12.999150
[epoch2, step3012]: loss 6.378303
[epoch2, step3013]: loss 3.969126
[epoch2, step3014]: loss 18.870049
[epoch2, step3015]: loss 9.014841
[epoch2, step3016]: loss 17.017115
[epoch2, step3017]: loss 35.835850
[epoch2, step3018]: loss 17.039234
[epoch2, step3019]: loss 14.192060
[epoch2, step3020]: loss 14.651667
[epoch2, step3021]: loss 43.518761
[epoch2, step3022]: loss 27.872517
[epoch2, step3023]: loss 11.591683
[epoch2, step3024]: loss 11.923760
[epoch2, step3025]: loss 16.363390
[epoch2, step3026]: loss 35.298119
[epoch2, step3027]: loss 5.637158
[epoch2, step3028]: loss 6.518466
[epoch2, step3029]: loss 15.045869
[epoch2, step3030]: loss 5.495146
[epoch2, step3031]: loss 7.192287
[epoch2, step3032]: loss 10.755344
[epoch2, step3033]: loss 5.221863
[epoch2, step3034]: loss 7.866630
[epoch2, step3035]: loss 12.791203
[epoch2, step3036]: loss 20.915941
[epoch2, step3037]: loss 33.283615
[epoch2, step3038]: loss 7.790924
[epoch2, step3039]: loss 6.024171
[epoch2, step3040]: loss 4.292150
[epoch2, step3041]: loss 9.816103
[epoch2, step3042]: loss 16.837524
[epoch2, step3043]: loss 6.580535
[epoch2, step3044]: loss 21.022524
[epoch2, step3045]: loss 10.153243
[epoch2, step3046]: loss 6.030227
[epoch2, step3047]: loss 7.085395
[epoch2, step3048]: loss 7.632659
[epoch2, step3049]: loss 5.820873
[epoch2, step3050]: loss 15.449959
[epoch2, step3051]: loss 24.562181
[epoch2, step3052]: loss 17.712870
[epoch2, step3053]: loss 13.351389
[epoch2, step3054]: loss 9.195416
[epoch2, step3055]: loss 26.698536
[epoch2, step3056]: loss 2.610496
[epoch2, step3057]: loss 40.662228
[epoch2, step3058]: loss 14.531904
[epoch2, step3059]: loss 14.921881
[epoch2, step3060]: loss 31.614454
[epoch2, step3061]: loss 11.691675
[epoch2, step3062]: loss 7.131827
[epoch2, step3063]: loss 6.340451
[epoch2, step3064]: loss 6.390548
[epoch2, step3065]: loss 8.394352
[epoch2, step3066]: loss 27.252583
[epoch2, step3067]: loss 10.633348
[epoch2, step3068]: loss 8.328164
[epoch2, step3069]: loss 10.048948
[epoch2, step3070]: loss 18.779148
[epoch2, step3071]: loss 4.612289
[epoch2, step3072]: loss 9.917392
[epoch2, step3073]: loss 11.913314
[epoch2, step3074]: loss 6.660082
[epoch2, step3075]: loss 8.623396
[epoch2, step3076]: loss 13.158161

[epoch2]: avg loss 13.158161

[epoch3, step1]: loss 16.068113
[epoch3, step2]: loss 22.255173
[epoch3, step3]: loss 10.299939
[epoch3, step4]: loss 20.013983
[epoch3, step5]: loss 15.077008
[epoch3, step6]: loss 19.520199
[epoch3, step7]: loss 7.644730
[epoch3, step8]: loss 6.608228
[epoch3, step9]: loss 6.076285
[epoch3, step10]: loss 7.599917
[epoch3, step11]: loss 7.940307
[epoch3, step12]: loss 14.106956
[epoch3, step13]: loss 3.120856
[epoch3, step14]: loss 11.980604
[epoch3, step15]: loss 20.435965
[epoch3, step16]: loss 5.914700
[epoch3, step17]: loss 20.444584
[epoch3, step18]: loss 6.794847
[epoch3, step19]: loss 18.778339
[epoch3, step20]: loss 6.233322
[epoch3, step21]: loss 19.545622
[epoch3, step22]: loss 20.006413
[epoch3, step23]: loss 17.447151
[epoch3, step24]: loss 20.086697
[epoch3, step25]: loss 3.614707
[epoch3, step26]: loss 13.519931
[epoch3, step27]: loss 29.712540
[epoch3, step28]: loss 6.745845
[epoch3, step29]: loss 7.037401
[epoch3, step30]: loss 22.200289
[epoch3, step31]: loss 34.179253
[epoch3, step32]: loss 8.653054
[epoch3, step33]: loss 45.735584
[epoch3, step34]: loss 38.129585
[epoch3, step35]: loss 8.226251
[epoch3, step36]: loss 5.907787
[epoch3, step37]: loss 36.077847
[epoch3, step38]: loss 9.187508
[epoch3, step39]: loss 33.915787
[epoch3, step40]: loss 4.985828
[epoch3, step41]: loss 12.189232
[epoch3, step42]: loss 8.686752
[epoch3, step43]: loss 30.298717
[epoch3, step44]: loss 23.315226
[epoch3, step45]: loss 40.043236
[epoch3, step46]: loss 40.781384
[epoch3, step47]: loss 24.131540
[epoch3, step48]: loss 12.368248
[epoch3, step49]: loss 22.203590
[epoch3, step50]: loss 5.933452
[epoch3, step51]: loss 5.788354
[epoch3, step52]: loss 34.182209
[epoch3, step53]: loss 9.963387
[epoch3, step54]: loss 10.336003
[epoch3, step55]: loss 22.904823
[epoch3, step56]: loss 14.543701
[epoch3, step57]: loss 14.522162
[epoch3, step58]: loss 3.338783
[epoch3, step59]: loss 7.398126
[epoch3, step60]: loss 24.063261
[epoch3, step61]: loss 22.065859
[epoch3, step62]: loss 3.151295
[epoch3, step63]: loss 13.222026
[epoch3, step64]: loss 15.671127
[epoch3, step65]: loss 5.885085
[epoch3, step66]: loss 25.089325
[epoch3, step67]: loss 32.909039
[epoch3, step68]: loss 3.884161
[epoch3, step69]: loss 14.097314
[epoch3, step70]: loss 9.338530
[epoch3, step71]: loss 4.542577
[epoch3, step72]: loss 9.655879
[epoch3, step73]: loss 12.581795
[epoch3, step74]: loss 13.747355
[epoch3, step75]: loss 13.861609
[epoch3, step76]: loss 7.650851
[epoch3, step77]: loss 2.602682
[epoch3, step78]: loss 9.493000
[epoch3, step79]: loss 14.430200
[epoch3, step80]: loss 3.767432
[epoch3, step81]: loss 12.996925
[epoch3, step82]: loss 33.426373
[epoch3, step83]: loss 31.355961
[epoch3, step84]: loss 12.167082
[epoch3, step85]: loss 24.693851
[epoch3, step86]: loss 31.011887
[epoch3, step87]: loss 9.527839
[epoch3, step88]: loss 12.496976
[epoch3, step89]: loss 9.652545
[epoch3, step90]: loss 6.150217
[epoch3, step91]: loss 19.153790
[epoch3, step92]: loss 9.230805
[epoch3, step93]: loss 6.138335
[epoch3, step94]: loss 6.090001
[epoch3, step95]: loss 12.688883
[epoch3, step96]: loss 7.700405
[epoch3, step97]: loss 28.834549
[epoch3, step98]: loss 5.056949
[epoch3, step99]: loss 6.917968
[epoch3, step100]: loss 12.792364
[epoch3, step101]: loss 16.936958
[epoch3, step102]: loss 37.837276
[epoch3, step103]: loss 8.942579
[epoch3, step104]: loss 9.982591
[epoch3, step105]: loss 34.041325
[epoch3, step106]: loss 15.963860
[epoch3, step107]: loss 20.606083
[epoch3, step108]: loss 6.660468
[epoch3, step109]: loss 3.450881
[epoch3, step110]: loss 17.077682
[epoch3, step111]: loss 19.146790
[epoch3, step112]: loss 8.251912
[epoch3, step113]: loss 5.982665
[epoch3, step114]: loss 17.567766
[epoch3, step115]: loss 4.079032
[epoch3, step116]: loss 9.778605
[epoch3, step117]: loss 5.541833
[epoch3, step118]: loss 20.710276
[epoch3, step119]: loss 17.968130
[epoch3, step120]: loss 13.772151
[epoch3, step121]: loss 11.426183
[epoch3, step122]: loss 24.468557
[epoch3, step123]: loss 9.608948
[epoch3, step124]: loss 13.916031
[epoch3, step125]: loss 20.772045
[epoch3, step126]: loss 10.404676
[epoch3, step127]: loss 8.333245
[epoch3, step128]: loss 11.354383
[epoch3, step129]: loss 13.045977
[epoch3, step130]: loss 10.372155
[epoch3, step131]: loss 23.593615
[epoch3, step132]: loss 8.076232
[epoch3, step133]: loss 23.086195
[epoch3, step134]: loss 7.358428
[epoch3, step135]: loss 16.061731
[epoch3, step136]: loss 12.892283
[epoch3, step137]: loss 14.930069
[epoch3, step138]: loss 39.485584
[epoch3, step139]: loss 12.683018
[epoch3, step140]: loss 14.582367
[epoch3, step141]: loss 5.302382
[epoch3, step142]: loss 3.396382
[epoch3, step143]: loss 6.074088
[epoch3, step144]: loss 7.213928
[epoch3, step145]: loss 28.790922
[epoch3, step146]: loss 5.752087
[epoch3, step147]: loss 6.346037
[epoch3, step148]: loss 19.437099
[epoch3, step149]: loss 9.529650
[epoch3, step150]: loss 27.381693
[epoch3, step151]: loss 21.339817
[epoch3, step152]: loss 8.109576
[epoch3, step153]: loss 5.210176
[epoch3, step154]: loss 6.840497
[epoch3, step155]: loss 21.031797
[epoch3, step156]: loss 3.775814
[epoch3, step157]: loss 16.697809
[epoch3, step158]: loss 28.368773
[epoch3, step159]: loss 15.328889
[epoch3, step160]: loss 34.777443
[epoch3, step161]: loss 9.766995
[epoch3, step162]: loss 39.481701
[epoch3, step163]: loss 12.823629
[epoch3, step164]: loss 11.552097
[epoch3, step165]: loss 8.007697
[epoch3, step166]: loss 2.684424
[epoch3, step167]: loss 36.710064
[epoch3, step168]: loss 12.946594
[epoch3, step169]: loss 8.175488
[epoch3, step170]: loss 7.274678
[epoch3, step171]: loss 12.111748
[epoch3, step172]: loss 12.400891
[epoch3, step173]: loss 10.756746
[epoch3, step174]: loss 15.255873
[epoch3, step175]: loss 11.241836
[epoch3, step176]: loss 7.356463
[epoch3, step177]: loss 13.698161
[epoch3, step178]: loss 8.666371
[epoch3, step179]: loss 2.753539
[epoch3, step180]: loss 4.944213
[epoch3, step181]: loss 15.525353
[epoch3, step182]: loss 46.545868
[epoch3, step183]: loss 16.802752
[epoch3, step184]: loss 15.520390
[epoch3, step185]: loss 14.385267
[epoch3, step186]: loss 17.869017
[epoch3, step187]: loss 7.246137
[epoch3, step188]: loss 17.846573
[epoch3, step189]: loss 4.129319
[epoch3, step190]: loss 27.546944
[epoch3, step191]: loss 23.103046
[epoch3, step192]: loss 26.937634
[epoch3, step193]: loss 4.377345
[epoch3, step194]: loss 11.739293
[epoch3, step195]: loss 6.647749
[epoch3, step196]: loss 7.050063
[epoch3, step197]: loss 5.469397
[epoch3, step198]: loss 11.854942
[epoch3, step199]: loss 8.918932
[epoch3, step200]: loss 5.806935
[epoch3, step201]: loss 6.178539
[epoch3, step202]: loss 15.127044
[epoch3, step203]: loss 17.791996
[epoch3, step204]: loss 20.861216
[epoch3, step205]: loss 5.175427
[epoch3, step206]: loss 8.551457
[epoch3, step207]: loss 4.881551
[epoch3, step208]: loss 28.146914
[epoch3, step209]: loss 16.515783
[epoch3, step210]: loss 7.436362
[epoch3, step211]: loss 25.560555
[epoch3, step212]: loss 12.040169
[epoch3, step213]: loss 13.816020
[epoch3, step214]: loss 7.824449
[epoch3, step215]: loss 3.623822
[epoch3, step216]: loss 40.806503
[epoch3, step217]: loss 4.171319
[epoch3, step218]: loss 24.247583
[epoch3, step219]: loss 27.093843
[epoch3, step220]: loss 14.876205
[epoch3, step221]: loss 19.265957
[epoch3, step222]: loss 8.626699
[epoch3, step223]: loss 6.482275
[epoch3, step224]: loss 23.706888
[epoch3, step225]: loss 21.575527
[epoch3, step226]: loss 4.523162
[epoch3, step227]: loss 8.315772
[epoch3, step228]: loss 13.697044
[epoch3, step229]: loss 14.887511
[epoch3, step230]: loss 4.032591
[epoch3, step231]: loss 5.985607
[epoch3, step232]: loss 5.180686
[epoch3, step233]: loss 20.795527
[epoch3, step234]: loss 11.461340
[epoch3, step235]: loss 16.203146
[epoch3, step236]: loss 8.282373
[epoch3, step237]: loss 7.653430
[epoch3, step238]: loss 5.053681
[epoch3, step239]: loss 15.179457
[epoch3, step240]: loss 28.002497
[epoch3, step241]: loss 8.951760
[epoch3, step242]: loss 17.025925
[epoch3, step243]: loss 5.090554
[epoch3, step244]: loss 17.216688
[epoch3, step245]: loss 4.371899
[epoch3, step246]: loss 16.542709
[epoch3, step247]: loss 10.959037
[epoch3, step248]: loss 5.611603
[epoch3, step249]: loss 6.888560
[epoch3, step250]: loss 14.026672
[epoch3, step251]: loss 4.590230
[epoch3, step252]: loss 15.454192
[epoch3, step253]: loss 11.574002
[epoch3, step254]: loss 10.138537
[epoch3, step255]: loss 14.992217
[epoch3, step256]: loss 7.842800
[epoch3, step257]: loss 20.356192
[epoch3, step258]: loss 13.180647
[epoch3, step259]: loss 7.324026
[epoch3, step260]: loss 7.375898
[epoch3, step261]: loss 43.657642
[epoch3, step262]: loss 14.227634
[epoch3, step263]: loss 8.749702
[epoch3, step264]: loss 6.331900
[epoch3, step265]: loss 7.985987
[epoch3, step266]: loss 5.336596
[epoch3, step267]: loss 10.239345
[epoch3, step268]: loss 9.045338
[epoch3, step269]: loss 6.340632
[epoch3, step270]: loss 26.142782
[epoch3, step271]: loss 6.810943
[epoch3, step272]: loss 6.960284
[epoch3, step273]: loss 4.825354
[epoch3, step274]: loss 9.883501
[epoch3, step275]: loss 9.903494
[epoch3, step276]: loss 22.372778
[epoch3, step277]: loss 16.510984
[epoch3, step278]: loss 14.578099
[epoch3, step279]: loss 29.738258
[epoch3, step280]: loss 5.264763
[epoch3, step281]: loss 18.979683
[epoch3, step282]: loss 8.503699
[epoch3, step283]: loss 25.967607
[epoch3, step284]: loss 14.880817
[epoch3, step285]: loss 13.334138
[epoch3, step286]: loss 15.395126
[epoch3, step287]: loss 12.329926
[epoch3, step288]: loss 21.989491
[epoch3, step289]: loss 15.066505
[epoch3, step290]: loss 33.949131
[epoch3, step291]: loss 17.066629
[epoch3, step292]: loss 9.860740
[epoch3, step293]: loss 13.764338
[epoch3, step294]: loss 4.976194
[epoch3, step295]: loss 11.146885
[epoch3, step296]: loss 31.394033
[epoch3, step297]: loss 31.623604
[epoch3, step298]: loss 19.221859
[epoch3, step299]: loss 5.522370
[epoch3, step300]: loss 9.227936
[epoch3, step301]: loss 6.315503
[epoch3, step302]: loss 7.240484
[epoch3, step303]: loss 24.649137
[epoch3, step304]: loss 6.674081
[epoch3, step305]: loss 3.372252
[epoch3, step306]: loss 6.321808
[epoch3, step307]: loss 16.402441
[epoch3, step308]: loss 6.426255
[epoch3, step309]: loss 7.986175
[epoch3, step310]: loss 9.908617
[epoch3, step311]: loss 8.550301
[epoch3, step312]: loss 16.899937
[epoch3, step313]: loss 25.791851
[epoch3, step314]: loss 11.034553
[epoch3, step315]: loss 7.875980
[epoch3, step316]: loss 15.067496
[epoch3, step317]: loss 6.913267
[epoch3, step318]: loss 11.058413
[epoch3, step319]: loss 5.393837
[epoch3, step320]: loss 16.398117
[epoch3, step321]: loss 20.145290
[epoch3, step322]: loss 8.836135
[epoch3, step323]: loss 29.796915
[epoch3, step324]: loss 15.503582
[epoch3, step325]: loss 8.980413
[epoch3, step326]: loss 19.400623
[epoch3, step327]: loss 6.462311
[epoch3, step328]: loss 12.000911
[epoch3, step329]: loss 18.976818
[epoch3, step330]: loss 10.660342
[epoch3, step331]: loss 11.825774
[epoch3, step332]: loss 8.694130
[epoch3, step333]: loss 22.664738
[epoch3, step334]: loss 13.054504
[epoch3, step335]: loss 20.686968
[epoch3, step336]: loss 14.109664
[epoch3, step337]: loss 14.034335
[epoch3, step338]: loss 13.887197
[epoch3, step339]: loss 6.144430
[epoch3, step340]: loss 8.759442
[epoch3, step341]: loss 12.933698
[epoch3, step342]: loss 5.575631
[epoch3, step343]: loss 8.796059
[epoch3, step344]: loss 5.557413
[epoch3, step345]: loss 16.849607
[epoch3, step346]: loss 17.349632
[epoch3, step347]: loss 7.141104
[epoch3, step348]: loss 13.592768
[epoch3, step349]: loss 5.406818
[epoch3, step350]: loss 5.873843
[epoch3, step351]: loss 21.888252
[epoch3, step352]: loss 8.786686
[epoch3, step353]: loss 12.121821
[epoch3, step354]: loss 35.348347
[epoch3, step355]: loss 34.243515
[epoch3, step356]: loss 21.464161
[epoch3, step357]: loss 8.629925
[epoch3, step358]: loss 5.002153
[epoch3, step359]: loss 23.124828
[epoch3, step360]: loss 17.182499
[epoch3, step361]: loss 17.493937
[epoch3, step362]: loss 4.364048
[epoch3, step363]: loss 5.149211
[epoch3, step364]: loss 25.660595
[epoch3, step365]: loss 20.156490
[epoch3, step366]: loss 8.617871
[epoch3, step367]: loss 8.636273
[epoch3, step368]: loss 4.622583
[epoch3, step369]: loss 4.311363
[epoch3, step370]: loss 6.709496
[epoch3, step371]: loss 15.314895
[epoch3, step372]: loss 30.191433
[epoch3, step373]: loss 15.220850
[epoch3, step374]: loss 23.531357
[epoch3, step375]: loss 6.307617
[epoch3, step376]: loss 9.993312
[epoch3, step377]: loss 16.672577
[epoch3, step378]: loss 13.464481
[epoch3, step379]: loss 11.011351
[epoch3, step380]: loss 11.645547
[epoch3, step381]: loss 13.711161
[epoch3, step382]: loss 8.460915
[epoch3, step383]: loss 24.198740
[epoch3, step384]: loss 13.805523
[epoch3, step385]: loss 6.462036
[epoch3, step386]: loss 13.754404
[epoch3, step387]: loss 10.375348
[epoch3, step388]: loss 21.891109
[epoch3, step389]: loss 8.143707
[epoch3, step390]: loss 6.055238
[epoch3, step391]: loss 14.287935
[epoch3, step392]: loss 29.126020
[epoch3, step393]: loss 10.247658
[epoch3, step394]: loss 9.810518
[epoch3, step395]: loss 17.001690
[epoch3, step396]: loss 6.478991
[epoch3, step397]: loss 11.194529
[epoch3, step398]: loss 32.264412
[epoch3, step399]: loss 6.182382
[epoch3, step400]: loss 9.093607
[epoch3, step401]: loss 35.637665
[epoch3, step402]: loss 10.036861
[epoch3, step403]: loss 27.338184
[epoch3, step404]: loss 17.690739
[epoch3, step405]: loss 25.175791
[epoch3, step406]: loss 16.045403
[epoch3, step407]: loss 7.889544
[epoch3, step408]: loss 8.979607
[epoch3, step409]: loss 7.707974
[epoch3, step410]: loss 19.072952
[epoch3, step411]: loss 29.497286
[epoch3, step412]: loss 10.724077
[epoch3, step413]: loss 7.556792
[epoch3, step414]: loss 5.894164
[epoch3, step415]: loss 14.976338
[epoch3, step416]: loss 5.214217
[epoch3, step417]: loss 21.764502
[epoch3, step418]: loss 28.501602
[epoch3, step419]: loss 30.598526
[epoch3, step420]: loss 18.909527
[epoch3, step421]: loss 4.904487
[epoch3, step422]: loss 8.191761
[epoch3, step423]: loss 13.627453
[epoch3, step424]: loss 15.691961
[epoch3, step425]: loss 2.704943
[epoch3, step426]: loss 23.939419
[epoch3, step427]: loss 8.932213
[epoch3, step428]: loss 13.531777
[epoch3, step429]: loss 4.126589
[epoch3, step430]: loss 5.648557
[epoch3, step431]: loss 8.621021
[epoch3, step432]: loss 43.514645
[epoch3, step433]: loss 7.076657
[epoch3, step434]: loss 6.374331
[epoch3, step435]: loss 6.598928
[epoch3, step436]: loss 13.541863
[epoch3, step437]: loss 13.659729
[epoch3, step438]: loss 5.991029
[epoch3, step439]: loss 20.377157
[epoch3, step440]: loss 8.244104
[epoch3, step441]: loss 11.112528
[epoch3, step442]: loss 26.198008
[epoch3, step443]: loss 26.665026
[epoch3, step444]: loss 41.099548
[epoch3, step445]: loss 6.019975
[epoch3, step446]: loss 10.322490
[epoch3, step447]: loss 24.279993
[epoch3, step448]: loss 11.194467
[epoch3, step449]: loss 5.789460
[epoch3, step450]: loss 16.707218
[epoch3, step451]: loss 8.266307
[epoch3, step452]: loss 13.151031
[epoch3, step453]: loss 11.920349
[epoch3, step454]: loss 5.323305
[epoch3, step455]: loss 4.088590
[epoch3, step456]: loss 19.490736
[epoch3, step457]: loss 7.331571
[epoch3, step458]: loss 14.403572
[epoch3, step459]: loss 9.844747
[epoch3, step460]: loss 8.820402
[epoch3, step461]: loss 6.570677
[epoch3, step462]: loss 9.831266
[epoch3, step463]: loss 15.818936
[epoch3, step464]: loss 15.022065
[epoch3, step465]: loss 10.603091
[epoch3, step466]: loss 26.175381
[epoch3, step467]: loss 15.577207
[epoch3, step468]: loss 7.881187
[epoch3, step469]: loss 9.252487
[epoch3, step470]: loss 31.145580
[epoch3, step471]: loss 8.824251
[epoch3, step472]: loss 11.604387
[epoch3, step473]: loss 13.531215
[epoch3, step474]: loss 17.117271
[epoch3, step475]: loss 17.278492
[epoch3, step476]: loss 8.334547
[epoch3, step477]: loss 6.135908
[epoch3, step478]: loss 22.938549
[epoch3, step479]: loss 18.564678
[epoch3, step480]: loss 10.269190
[epoch3, step481]: loss 18.689861
[epoch3, step482]: loss 26.498846
[epoch3, step483]: loss 18.917587
[epoch3, step484]: loss 7.171995
[epoch3, step485]: loss 19.057894
[epoch3, step486]: loss 16.337864
[epoch3, step487]: loss 17.764788
[epoch3, step488]: loss 19.095833
[epoch3, step489]: loss 5.691507
[epoch3, step490]: loss 11.432251
[epoch3, step491]: loss 10.245164
[epoch3, step492]: loss 40.708927
[epoch3, step493]: loss 15.330138
[epoch3, step494]: loss 26.739264
[epoch3, step495]: loss 5.590921
[epoch3, step496]: loss 4.984958
[epoch3, step497]: loss 5.790415
[epoch3, step498]: loss 7.241512
[epoch3, step499]: loss 19.281044
[epoch3, step500]: loss 7.131134
[epoch3, step501]: loss 25.670273
[epoch3, step502]: loss 37.901466
[epoch3, step503]: loss 6.609889
[epoch3, step504]: loss 11.293599
[epoch3, step505]: loss 15.264196
[epoch3, step506]: loss 30.500902
[epoch3, step507]: loss 2.833686
[epoch3, step508]: loss 7.864288
[epoch3, step509]: loss 18.036642
[epoch3, step510]: loss 8.046350
[epoch3, step511]: loss 17.669807
[epoch3, step512]: loss 5.880164
[epoch3, step513]: loss 5.263719
[epoch3, step514]: loss 11.772126
[epoch3, step515]: loss 20.382393
[epoch3, step516]: loss 4.980069
[epoch3, step517]: loss 6.508294
[epoch3, step518]: loss 7.988517
[epoch3, step519]: loss 29.657860
[epoch3, step520]: loss 7.942655
[epoch3, step521]: loss 7.657037
[epoch3, step522]: loss 20.641691
[epoch3, step523]: loss 5.937780
[epoch3, step524]: loss 18.157257
[epoch3, step525]: loss 20.348171
[epoch3, step526]: loss 33.542030
[epoch3, step527]: loss 6.519135
[epoch3, step528]: loss 11.925777
[epoch3, step529]: loss 11.352824
[epoch3, step530]: loss 24.319523
[epoch3, step531]: loss 20.367308
[epoch3, step532]: loss 10.235017
[epoch3, step533]: loss 25.112597
[epoch3, step534]: loss 14.960412
[epoch3, step535]: loss 27.389017
[epoch3, step536]: loss 14.782380
[epoch3, step537]: loss 3.744566
[epoch3, step538]: loss 12.974354
[epoch3, step539]: loss 17.806673
[epoch3, step540]: loss 14.395834
[epoch3, step541]: loss 9.832649
[epoch3, step542]: loss 5.264109
[epoch3, step543]: loss 15.588801
[epoch3, step544]: loss 6.696099
[epoch3, step545]: loss 8.762461
[epoch3, step546]: loss 9.350977
[epoch3, step547]: loss 14.193501
[epoch3, step548]: loss 4.722219
[epoch3, step549]: loss 19.215240
[epoch3, step550]: loss 9.342283
[epoch3, step551]: loss 30.083536
[epoch3, step552]: loss 5.095193
[epoch3, step553]: loss 3.927527
[epoch3, step554]: loss 8.933193
[epoch3, step555]: loss 6.061801
[epoch3, step556]: loss 10.040185
[epoch3, step557]: loss 27.009369
[epoch3, step558]: loss 17.341999
[epoch3, step559]: loss 14.776194
[epoch3, step560]: loss 17.317444
[epoch3, step561]: loss 8.166475
[epoch3, step562]: loss 13.160783
[epoch3, step563]: loss 6.698248
[epoch3, step564]: loss 6.039146
[epoch3, step565]: loss 6.685150
[epoch3, step566]: loss 3.524589
[epoch3, step567]: loss 7.119052
[epoch3, step568]: loss 4.602681
[epoch3, step569]: loss 9.095170
[epoch3, step570]: loss 21.080891
[epoch3, step571]: loss 22.639660
[epoch3, step572]: loss 36.640022
[epoch3, step573]: loss 8.653478
[epoch3, step574]: loss 19.079966
[epoch3, step575]: loss 12.903820
[epoch3, step576]: loss 22.217855
[epoch3, step577]: loss 5.826129
[epoch3, step578]: loss 7.508575
[epoch3, step579]: loss 6.441025
[epoch3, step580]: loss 14.168519
[epoch3, step581]: loss 4.339079
[epoch3, step582]: loss 21.038820
[epoch3, step583]: loss 5.823557
[epoch3, step584]: loss 14.165352
[epoch3, step585]: loss 5.530528
[epoch3, step586]: loss 6.353468
[epoch3, step587]: loss 9.964923
[epoch3, step588]: loss 14.192633
[epoch3, step589]: loss 24.248453
[epoch3, step590]: loss 13.521584
[epoch3, step591]: loss 9.353959
[epoch3, step592]: loss 39.849884
[epoch3, step593]: loss 18.661963
[epoch3, step594]: loss 9.515758
[epoch3, step595]: loss 8.464125
[epoch3, step596]: loss 6.684518
[epoch3, step597]: loss 12.846963
[epoch3, step598]: loss 25.085415
[epoch3, step599]: loss 7.444203
[epoch3, step600]: loss 11.107605
[epoch3, step601]: loss 33.785183
[epoch3, step602]: loss 18.473402
[epoch3, step603]: loss 6.773169
[epoch3, step604]: loss 9.230952
[epoch3, step605]: loss 33.506981
[epoch3, step606]: loss 5.921234
[epoch3, step607]: loss 7.925699
[epoch3, step608]: loss 15.772326
[epoch3, step609]: loss 12.133919
[epoch3, step610]: loss 8.099324
[epoch3, step611]: loss 6.834136
[epoch3, step612]: loss 11.834449
[epoch3, step613]: loss 12.919394
[epoch3, step614]: loss 25.328802
[epoch3, step615]: loss 4.421485
[epoch3, step616]: loss 26.035286
[epoch3, step617]: loss 7.806717
[epoch3, step618]: loss 5.645800
[epoch3, step619]: loss 25.025639
[epoch3, step620]: loss 12.804103
[epoch3, step621]: loss 16.426430
[epoch3, step622]: loss 11.276796
[epoch3, step623]: loss 23.760269
[epoch3, step624]: loss 17.000116
[epoch3, step625]: loss 10.312513
[epoch3, step626]: loss 3.957610
[epoch3, step627]: loss 19.479160
[epoch3, step628]: loss 4.405970
[epoch3, step629]: loss 17.833418
[epoch3, step630]: loss 11.286308
[epoch3, step631]: loss 4.323581
[epoch3, step632]: loss 14.302987
[epoch3, step633]: loss 11.389383
[epoch3, step634]: loss 7.316166
[epoch3, step635]: loss 15.239976
[epoch3, step636]: loss 9.690634
[epoch3, step637]: loss 4.676526
[epoch3, step638]: loss 5.911168
[epoch3, step639]: loss 21.885201
[epoch3, step640]: loss 16.435495
[epoch3, step641]: loss 16.537731
[epoch3, step642]: loss 15.797193
[epoch3, step643]: loss 14.864088
[epoch3, step644]: loss 8.261013
[epoch3, step645]: loss 19.766006
[epoch3, step646]: loss 17.032572
[epoch3, step647]: loss 9.683249
[epoch3, step648]: loss 12.793365
[epoch3, step649]: loss 4.363190
[epoch3, step650]: loss 14.856795
[epoch3, step651]: loss 10.541295
[epoch3, step652]: loss 5.861485
[epoch3, step653]: loss 5.017591
[epoch3, step654]: loss 8.728427
[epoch3, step655]: loss 22.570953
[epoch3, step656]: loss 19.646450
[epoch3, step657]: loss 6.919927
[epoch3, step658]: loss 6.401840
[epoch3, step659]: loss 20.288704
[epoch3, step660]: loss 7.324731
[epoch3, step661]: loss 16.156212
[epoch3, step662]: loss 17.196186
[epoch3, step663]: loss 2.389460
[epoch3, step664]: loss 31.363403
[epoch3, step665]: loss 8.536257
[epoch3, step666]: loss 22.419580
[epoch3, step667]: loss 24.993082
[epoch3, step668]: loss 19.303886
[epoch3, step669]: loss 6.887922
[epoch3, step670]: loss 23.675014
[epoch3, step671]: loss 7.218797
[epoch3, step672]: loss 8.235154
[epoch3, step673]: loss 9.143494
[epoch3, step674]: loss 21.734966
[epoch3, step675]: loss 5.869133
[epoch3, step676]: loss 26.624990
[epoch3, step677]: loss 17.815687
[epoch3, step678]: loss 5.994205
[epoch3, step679]: loss 11.933674
[epoch3, step680]: loss 5.776359
[epoch3, step681]: loss 5.848876
[epoch3, step682]: loss 10.476648
[epoch3, step683]: loss 7.153487
[epoch3, step684]: loss 4.902977
[epoch3, step685]: loss 7.079193
[epoch3, step686]: loss 22.185228
[epoch3, step687]: loss 11.993488
[epoch3, step688]: loss 8.244222
[epoch3, step689]: loss 7.680992
[epoch3, step690]: loss 17.060270
[epoch3, step691]: loss 5.071535
[epoch3, step692]: loss 5.369368
[epoch3, step693]: loss 5.324098
[epoch3, step694]: loss 16.849316
[epoch3, step695]: loss 11.430298
[epoch3, step696]: loss 21.456108
[epoch3, step697]: loss 13.859333
[epoch3, step698]: loss 28.268198
[epoch3, step699]: loss 18.121872
[epoch3, step700]: loss 6.475005
[epoch3, step701]: loss 40.708038
[epoch3, step702]: loss 7.071711
[epoch3, step703]: loss 16.155252
[epoch3, step704]: loss 30.947231
[epoch3, step705]: loss 26.000065
[epoch3, step706]: loss 7.468593
[epoch3, step707]: loss 7.835833
[epoch3, step708]: loss 27.877071
[epoch3, step709]: loss 7.968775
[epoch3, step710]: loss 13.369953
[epoch3, step711]: loss 12.649435
[epoch3, step712]: loss 11.141787
[epoch3, step713]: loss 6.709428
[epoch3, step714]: loss 7.048562
[epoch3, step715]: loss 6.323269
[epoch3, step716]: loss 23.606474
[epoch3, step717]: loss 5.938135
[epoch3, step718]: loss 6.360559
[epoch3, step719]: loss 20.617311
[epoch3, step720]: loss 5.923092
[epoch3, step721]: loss 8.659888
[epoch3, step722]: loss 2.896305
[epoch3, step723]: loss 19.226969
[epoch3, step724]: loss 16.148216
[epoch3, step725]: loss 5.074001
[epoch3, step726]: loss 7.462186
[epoch3, step727]: loss 23.944269
[epoch3, step728]: loss 7.565948
[epoch3, step729]: loss 7.483912
[epoch3, step730]: loss 12.246646
[epoch3, step731]: loss 24.692940
[epoch3, step732]: loss 23.195213
[epoch3, step733]: loss 26.524530
[epoch3, step734]: loss 31.827339
[epoch3, step735]: loss 16.123650
[epoch3, step736]: loss 3.451953
[epoch3, step737]: loss 23.004641
[epoch3, step738]: loss 6.731777
[epoch3, step739]: loss 16.142643
[epoch3, step740]: loss 12.266671
[epoch3, step741]: loss 9.240110
[epoch3, step742]: loss 16.830965
[epoch3, step743]: loss 11.245276
[epoch3, step744]: loss 9.063853
[epoch3, step745]: loss 7.058109
[epoch3, step746]: loss 25.626202
[epoch3, step747]: loss 13.873167
[epoch3, step748]: loss 4.030540
[epoch3, step749]: loss 7.003591
[epoch3, step750]: loss 7.190430
[epoch3, step751]: loss 12.694796
[epoch3, step752]: loss 13.337480
[epoch3, step753]: loss 13.685394
[epoch3, step754]: loss 9.547791
[epoch3, step755]: loss 17.365105
[epoch3, step756]: loss 37.726490
[epoch3, step757]: loss 35.331161
[epoch3, step758]: loss 9.028335
[epoch3, step759]: loss 3.942311
[epoch3, step760]: loss 18.498156
[epoch3, step761]: loss 19.070217
[epoch3, step762]: loss 22.768932
[epoch3, step763]: loss 5.970857
[epoch3, step764]: loss 7.686327
[epoch3, step765]: loss 26.266451
[epoch3, step766]: loss 7.253979
[epoch3, step767]: loss 4.518623
[epoch3, step768]: loss 3.162335
[epoch3, step769]: loss 3.849692
[epoch3, step770]: loss 8.569510
[epoch3, step771]: loss 13.969604
[epoch3, step772]: loss 19.876463
[epoch3, step773]: loss 27.152161
[epoch3, step774]: loss 13.759393
[epoch3, step775]: loss 16.230608
[epoch3, step776]: loss 5.143239
[epoch3, step777]: loss 39.860729
[epoch3, step778]: loss 4.610849
[epoch3, step779]: loss 4.440642
[epoch3, step780]: loss 10.537934
[epoch3, step781]: loss 4.435757
[epoch3, step782]: loss 18.529388
[epoch3, step783]: loss 7.074813
[epoch3, step784]: loss 14.151933
[epoch3, step785]: loss 6.662197
[epoch3, step786]: loss 19.233458
[epoch3, step787]: loss 6.009810
[epoch3, step788]: loss 4.642745
[epoch3, step789]: loss 16.916967
[epoch3, step790]: loss 3.548892
[epoch3, step791]: loss 31.107950
[epoch3, step792]: loss 17.667103
[epoch3, step793]: loss 7.050202
[epoch3, step794]: loss 4.511433
[epoch3, step795]: loss 4.938402
[epoch3, step796]: loss 5.816123
[epoch3, step797]: loss 8.395074
[epoch3, step798]: loss 11.667725
[epoch3, step799]: loss 8.687973
[epoch3, step800]: loss 4.557950
[epoch3, step801]: loss 25.106834
[epoch3, step802]: loss 12.059497
[epoch3, step803]: loss 18.139074
[epoch3, step804]: loss 5.828764
[epoch3, step805]: loss 6.417386
[epoch3, step806]: loss 4.843447
[epoch3, step807]: loss 10.434161
[epoch3, step808]: loss 4.582714
[epoch3, step809]: loss 10.124655
[epoch3, step810]: loss 10.340252
[epoch3, step811]: loss 14.705843
[epoch3, step812]: loss 9.652339
[epoch3, step813]: loss 4.989184
[epoch3, step814]: loss 16.307604
[epoch3, step815]: loss 20.435574
[epoch3, step816]: loss 15.889766
[epoch3, step817]: loss 13.599319
[epoch3, step818]: loss 35.609444
[epoch3, step819]: loss 5.147166
[epoch3, step820]: loss 14.648095
[epoch3, step821]: loss 14.727741
[epoch3, step822]: loss 14.497261
[epoch3, step823]: loss 15.430613
[epoch3, step824]: loss 16.092884
[epoch3, step825]: loss 8.692163
[epoch3, step826]: loss 10.765085
[epoch3, step827]: loss 7.989631
[epoch3, step828]: loss 19.405207
[epoch3, step829]: loss 22.520500
[epoch3, step830]: loss 28.614176
[epoch3, step831]: loss 15.362197
[epoch3, step832]: loss 14.946195
[epoch3, step833]: loss 26.024240
[epoch3, step834]: loss 15.242230
[epoch3, step835]: loss 5.905369
[epoch3, step836]: loss 33.446732
[epoch3, step837]: loss 6.339622
[epoch3, step838]: loss 16.297316
[epoch3, step839]: loss 6.557203
[epoch3, step840]: loss 10.160245
[epoch3, step841]: loss 24.360426
[epoch3, step842]: loss 27.707371
[epoch3, step843]: loss 13.616419
[epoch3, step844]: loss 9.118988
[epoch3, step845]: loss 11.720748
[epoch3, step846]: loss 3.307721
[epoch3, step847]: loss 9.879323
[epoch3, step848]: loss 23.229811
[epoch3, step849]: loss 18.384018
[epoch3, step850]: loss 24.061722
[epoch3, step851]: loss 13.078266
[epoch3, step852]: loss 17.520939
[epoch3, step853]: loss 6.365088
[epoch3, step854]: loss 10.994082
[epoch3, step855]: loss 11.153948
[epoch3, step856]: loss 39.951389
[epoch3, step857]: loss 13.069442
[epoch3, step858]: loss 6.968752
[epoch3, step859]: loss 48.904335
[epoch3, step860]: loss 36.485901
[epoch3, step861]: loss 7.197360
[epoch3, step862]: loss 22.053234
[epoch3, step863]: loss 16.533932
[epoch3, step864]: loss 17.382706
[epoch3, step865]: loss 9.181597
[epoch3, step866]: loss 12.642030
[epoch3, step867]: loss 22.119846
[epoch3, step868]: loss 5.397775
[epoch3, step869]: loss 33.146095
[epoch3, step870]: loss 14.612826
[epoch3, step871]: loss 18.992161
[epoch3, step872]: loss 10.048153
[epoch3, step873]: loss 19.068670
[epoch3, step874]: loss 43.843113
[epoch3, step875]: loss 13.827479
[epoch3, step876]: loss 13.549051
[epoch3, step877]: loss 7.960232
[epoch3, step878]: loss 8.261854
[epoch3, step879]: loss 10.707611
[epoch3, step880]: loss 15.596077
[epoch3, step881]: loss 10.753458
[epoch3, step882]: loss 8.186527
[epoch3, step883]: loss 9.749342
[epoch3, step884]: loss 3.163707
[epoch3, step885]: loss 17.571451
[epoch3, step886]: loss 17.335941
[epoch3, step887]: loss 23.077854
[epoch3, step888]: loss 25.769131
[epoch3, step889]: loss 14.578232
[epoch3, step890]: loss 3.430797
[epoch3, step891]: loss 13.120873
[epoch3, step892]: loss 9.712437
[epoch3, step893]: loss 14.453029
[epoch3, step894]: loss 8.724760
[epoch3, step895]: loss 5.401493
[epoch3, step896]: loss 15.590854
[epoch3, step897]: loss 10.616928
[epoch3, step898]: loss 7.117924
[epoch3, step899]: loss 24.466599
[epoch3, step900]: loss 19.918470
[epoch3, step901]: loss 6.666266
[epoch3, step902]: loss 6.746645
[epoch3, step903]: loss 9.992167
[epoch3, step904]: loss 19.645468
[epoch3, step905]: loss 10.880765
[epoch3, step906]: loss 8.589447
[epoch3, step907]: loss 11.065495
[epoch3, step908]: loss 32.923237
[epoch3, step909]: loss 12.849342
[epoch3, step910]: loss 6.845471
[epoch3, step911]: loss 6.937354
[epoch3, step912]: loss 9.725221
[epoch3, step913]: loss 2.931203
[epoch3, step914]: loss 11.232625
[epoch3, step915]: loss 7.345656
[epoch3, step916]: loss 32.294323
[epoch3, step917]: loss 17.599924
[epoch3, step918]: loss 10.123423
[epoch3, step919]: loss 41.961697
[epoch3, step920]: loss 10.054695
[epoch3, step921]: loss 17.695770
[epoch3, step922]: loss 10.079970
[epoch3, step923]: loss 19.769850
[epoch3, step924]: loss 30.340967
[epoch3, step925]: loss 3.163964
[epoch3, step926]: loss 9.774504
[epoch3, step927]: loss 2.651963
[epoch3, step928]: loss 11.012387
[epoch3, step929]: loss 7.422492
[epoch3, step930]: loss 5.903908
[epoch3, step931]: loss 7.402601
[epoch3, step932]: loss 4.555779
[epoch3, step933]: loss 4.207176
[epoch3, step934]: loss 20.165440
[epoch3, step935]: loss 4.117438
[epoch3, step936]: loss 8.249592
[epoch3, step937]: loss 5.704035
[epoch3, step938]: loss 16.759478
[epoch3, step939]: loss 6.810576
[epoch3, step940]: loss 9.838719
[epoch3, step941]: loss 4.572288
[epoch3, step942]: loss 16.471285
[epoch3, step943]: loss 24.300074
[epoch3, step944]: loss 13.309710
[epoch3, step945]: loss 5.634566
[epoch3, step946]: loss 8.124834
[epoch3, step947]: loss 6.103282
[epoch3, step948]: loss 16.093287
[epoch3, step949]: loss 3.858262
[epoch3, step950]: loss 11.798279
[epoch3, step951]: loss 4.186703
[epoch3, step952]: loss 5.550515
[epoch3, step953]: loss 10.991539
[epoch3, step954]: loss 27.647156
[epoch3, step955]: loss 11.656144
[epoch3, step956]: loss 26.072615
[epoch3, step957]: loss 6.754522
[epoch3, step958]: loss 32.458508
[epoch3, step959]: loss 13.736593
[epoch3, step960]: loss 5.097596
[epoch3, step961]: loss 8.028483
[epoch3, step962]: loss 12.949882
[epoch3, step963]: loss 16.040134
[epoch3, step964]: loss 16.714596
[epoch3, step965]: loss 3.337907
[epoch3, step966]: loss 3.653917
[epoch3, step967]: loss 3.870612
[epoch3, step968]: loss 22.164476
[epoch3, step969]: loss 5.490674
[epoch3, step970]: loss 4.847614
[epoch3, step971]: loss 13.660468
[epoch3, step972]: loss 8.426915
[epoch3, step973]: loss 7.548620
[epoch3, step974]: loss 12.862057
[epoch3, step975]: loss 6.890651
[epoch3, step976]: loss 3.445718
[epoch3, step977]: loss 12.505379
[epoch3, step978]: loss 31.358498
[epoch3, step979]: loss 13.613963
[epoch3, step980]: loss 5.913331
[epoch3, step981]: loss 6.969247
[epoch3, step982]: loss 14.298966
[epoch3, step983]: loss 12.820711
[epoch3, step984]: loss 2.682159
[epoch3, step985]: loss 21.170753
[epoch3, step986]: loss 6.318020
[epoch3, step987]: loss 24.123260
[epoch3, step988]: loss 5.118875
[epoch3, step989]: loss 6.648817
[epoch3, step990]: loss 3.273632
[epoch3, step991]: loss 7.388166
[epoch3, step992]: loss 14.756227
[epoch3, step993]: loss 11.477589
[epoch3, step994]: loss 8.357357
[epoch3, step995]: loss 8.403169
[epoch3, step996]: loss 5.091475
[epoch3, step997]: loss 8.894045
[epoch3, step998]: loss 24.648260
[epoch3, step999]: loss 11.946907
[epoch3, step1000]: loss 17.110592
[epoch3, step1001]: loss 17.832058
[epoch3, step1002]: loss 19.036982
[epoch3, step1003]: loss 5.095707
[epoch3, step1004]: loss 3.138657
[epoch3, step1005]: loss 4.081461
[epoch3, step1006]: loss 16.167532
[epoch3, step1007]: loss 16.482405
[epoch3, step1008]: loss 5.770513
[epoch3, step1009]: loss 17.847992
[epoch3, step1010]: loss 11.744963
[epoch3, step1011]: loss 16.039890
[epoch3, step1012]: loss 13.711957
[epoch3, step1013]: loss 16.030951
[epoch3, step1014]: loss 16.758015
[epoch3, step1015]: loss 23.056887
[epoch3, step1016]: loss 5.881656
[epoch3, step1017]: loss 14.392997
[epoch3, step1018]: loss 6.514933
[epoch3, step1019]: loss 9.058549
[epoch3, step1020]: loss 16.462044
[epoch3, step1021]: loss 15.482336
[epoch3, step1022]: loss 17.878618
[epoch3, step1023]: loss 17.824333
[epoch3, step1024]: loss 5.133898
[epoch3, step1025]: loss 6.420430
[epoch3, step1026]: loss 7.420436
[epoch3, step1027]: loss 18.639872
[epoch3, step1028]: loss 9.464116
[epoch3, step1029]: loss 8.523571
[epoch3, step1030]: loss 6.156473
[epoch3, step1031]: loss 17.013783
[epoch3, step1032]: loss 13.496038
[epoch3, step1033]: loss 6.296199
[epoch3, step1034]: loss 23.537395
[epoch3, step1035]: loss 7.403921
[epoch3, step1036]: loss 23.331501
[epoch3, step1037]: loss 7.141638
[epoch3, step1038]: loss 30.336506
[epoch3, step1039]: loss 16.621958
[epoch3, step1040]: loss 11.788444
[epoch3, step1041]: loss 5.920747
[epoch3, step1042]: loss 24.649372
[epoch3, step1043]: loss 16.888090
[epoch3, step1044]: loss 6.336040
[epoch3, step1045]: loss 3.535588
[epoch3, step1046]: loss 5.284021
[epoch3, step1047]: loss 6.432260
[epoch3, step1048]: loss 23.202274
[epoch3, step1049]: loss 14.326971
[epoch3, step1050]: loss 4.476958
[epoch3, step1051]: loss 7.591673
[epoch3, step1052]: loss 34.566612
[epoch3, step1053]: loss 13.934629
[epoch3, step1054]: loss 25.395588
[epoch3, step1055]: loss 9.251910
[epoch3, step1056]: loss 29.887012
[epoch3, step1057]: loss 6.568138
[epoch3, step1058]: loss 5.840743
[epoch3, step1059]: loss 5.585185
[epoch3, step1060]: loss 5.463734
[epoch3, step1061]: loss 16.807566
[epoch3, step1062]: loss 4.878050
[epoch3, step1063]: loss 12.822447
[epoch3, step1064]: loss 6.940485
[epoch3, step1065]: loss 7.230630
[epoch3, step1066]: loss 8.067396
[epoch3, step1067]: loss 12.564058
[epoch3, step1068]: loss 11.997672
[epoch3, step1069]: loss 28.208740
[epoch3, step1070]: loss 17.268799
[epoch3, step1071]: loss 27.924099
[epoch3, step1072]: loss 24.612038
[epoch3, step1073]: loss 22.857634
[epoch3, step1074]: loss 28.699917
[epoch3, step1075]: loss 4.470885
[epoch3, step1076]: loss 24.573990
[epoch3, step1077]: loss 6.877628
[epoch3, step1078]: loss 9.389917
[epoch3, step1079]: loss 4.576860
[epoch3, step1080]: loss 10.446564
[epoch3, step1081]: loss 21.463158
[epoch3, step1082]: loss 18.231453
[epoch3, step1083]: loss 20.178770
[epoch3, step1084]: loss 20.748306
[epoch3, step1085]: loss 27.740122
[epoch3, step1086]: loss 13.808883
[epoch3, step1087]: loss 6.575540
[epoch3, step1088]: loss 6.277101
[epoch3, step1089]: loss 13.308484
[epoch3, step1090]: loss 12.445771
[epoch3, step1091]: loss 8.216972
[epoch3, step1092]: loss 19.798311
[epoch3, step1093]: loss 28.291437
[epoch3, step1094]: loss 3.842821
[epoch3, step1095]: loss 14.140501
[epoch3, step1096]: loss 19.036736
[epoch3, step1097]: loss 1.837581
[epoch3, step1098]: loss 45.477837
[epoch3, step1099]: loss 8.280598
[epoch3, step1100]: loss 11.077594
[epoch3, step1101]: loss 5.407935
[epoch3, step1102]: loss 11.809290
[epoch3, step1103]: loss 22.251020
[epoch3, step1104]: loss 13.867308
[epoch3, step1105]: loss 21.283840
[epoch3, step1106]: loss 17.070829
[epoch3, step1107]: loss 4.960238
[epoch3, step1108]: loss 21.739441
[epoch3, step1109]: loss 41.612705
[epoch3, step1110]: loss 6.552586
[epoch3, step1111]: loss 18.220512
[epoch3, step1112]: loss 5.882849
[epoch3, step1113]: loss 4.913577
[epoch3, step1114]: loss 17.682198
[epoch3, step1115]: loss 16.587961
[epoch3, step1116]: loss 25.417233
[epoch3, step1117]: loss 4.311174
[epoch3, step1118]: loss 23.065668
[epoch3, step1119]: loss 4.916599
[epoch3, step1120]: loss 24.039194
[epoch3, step1121]: loss 3.917559
[epoch3, step1122]: loss 4.639989
[epoch3, step1123]: loss 23.523582
[epoch3, step1124]: loss 13.440557
[epoch3, step1125]: loss 6.148121
[epoch3, step1126]: loss 18.480988
[epoch3, step1127]: loss 6.508579
[epoch3, step1128]: loss 3.858187
[epoch3, step1129]: loss 8.833755
[epoch3, step1130]: loss 15.288101
[epoch3, step1131]: loss 44.881523
[epoch3, step1132]: loss 14.582726
[epoch3, step1133]: loss 3.106354
[epoch3, step1134]: loss 29.448229
[epoch3, step1135]: loss 8.179713
[epoch3, step1136]: loss 13.266347
[epoch3, step1137]: loss 4.450000
[epoch3, step1138]: loss 5.338653
[epoch3, step1139]: loss 6.726279
[epoch3, step1140]: loss 8.357739
[epoch3, step1141]: loss 9.165870
[epoch3, step1142]: loss 18.852242
[epoch3, step1143]: loss 8.010075
[epoch3, step1144]: loss 14.288633
[epoch3, step1145]: loss 4.246888
[epoch3, step1146]: loss 7.296820
[epoch3, step1147]: loss 8.754207
[epoch3, step1148]: loss 14.805721
[epoch3, step1149]: loss 12.554316
[epoch3, step1150]: loss 5.568120
[epoch3, step1151]: loss 7.696498
[epoch3, step1152]: loss 44.081596
[epoch3, step1153]: loss 19.678936
[epoch3, step1154]: loss 6.645986
[epoch3, step1155]: loss 15.745847
[epoch3, step1156]: loss 25.758907
[epoch3, step1157]: loss 4.308613
[epoch3, step1158]: loss 4.451921
[epoch3, step1159]: loss 16.063644
[epoch3, step1160]: loss 9.642553
[epoch3, step1161]: loss 3.704708
[epoch3, step1162]: loss 9.554651
[epoch3, step1163]: loss 3.868504
[epoch3, step1164]: loss 17.735603
[epoch3, step1165]: loss 5.219577
[epoch3, step1166]: loss 15.607113
[epoch3, step1167]: loss 17.928009
[epoch3, step1168]: loss 4.652511
[epoch3, step1169]: loss 13.432250
[epoch3, step1170]: loss 8.866192
[epoch3, step1171]: loss 14.481456
[epoch3, step1172]: loss 15.485727
[epoch3, step1173]: loss 6.586158
[epoch3, step1174]: loss 13.799806
[epoch3, step1175]: loss 13.540918
[epoch3, step1176]: loss 6.359142
[epoch3, step1177]: loss 3.334657
[epoch3, step1178]: loss 39.588764
[epoch3, step1179]: loss 10.635173
[epoch3, step1180]: loss 4.119698
[epoch3, step1181]: loss 15.210817
[epoch3, step1182]: loss 6.434809
[epoch3, step1183]: loss 12.163661
[epoch3, step1184]: loss 4.382515
[epoch3, step1185]: loss 4.682992
[epoch3, step1186]: loss 4.277306
[epoch3, step1187]: loss 15.937773
[epoch3, step1188]: loss 11.716246
[epoch3, step1189]: loss 24.646475
[epoch3, step1190]: loss 9.426461
[epoch3, step1191]: loss 6.701714
[epoch3, step1192]: loss 4.606025
[epoch3, step1193]: loss 7.466139
[epoch3, step1194]: loss 20.354788
[epoch3, step1195]: loss 8.935131
[epoch3, step1196]: loss 12.990570
[epoch3, step1197]: loss 17.290419
[epoch3, step1198]: loss 18.935900
[epoch3, step1199]: loss 19.449549
[epoch3, step1200]: loss 14.199043
[epoch3, step1201]: loss 19.763172
[epoch3, step1202]: loss 7.202599
[epoch3, step1203]: loss 25.207096
[epoch3, step1204]: loss 7.471904
[epoch3, step1205]: loss 10.926537
[epoch3, step1206]: loss 11.711805
[epoch3, step1207]: loss 6.823559
[epoch3, step1208]: loss 7.887626
[epoch3, step1209]: loss 14.462007
[epoch3, step1210]: loss 16.729509
[epoch3, step1211]: loss 27.665230
[epoch3, step1212]: loss 8.911791
[epoch3, step1213]: loss 15.701924
[epoch3, step1214]: loss 2.635868
[epoch3, step1215]: loss 14.232115
[epoch3, step1216]: loss 25.756790
[epoch3, step1217]: loss 6.473776
[epoch3, step1218]: loss 11.536339
[epoch3, step1219]: loss 8.870803
[epoch3, step1220]: loss 18.471077
[epoch3, step1221]: loss 1.972481
[epoch3, step1222]: loss 5.571438
[epoch3, step1223]: loss 13.238458
[epoch3, step1224]: loss 5.385562
[epoch3, step1225]: loss 27.126104
[epoch3, step1226]: loss 25.043619
[epoch3, step1227]: loss 16.962503
[epoch3, step1228]: loss 15.954515
[epoch3, step1229]: loss 12.857298
[epoch3, step1230]: loss 3.860054
[epoch3, step1231]: loss 8.167820
[epoch3, step1232]: loss 13.066842
[epoch3, step1233]: loss 4.681198
[epoch3, step1234]: loss 13.811134
[epoch3, step1235]: loss 11.483549
[epoch3, step1236]: loss 14.310869
[epoch3, step1237]: loss 8.570843
[epoch3, step1238]: loss 10.172704
[epoch3, step1239]: loss 15.210400
[epoch3, step1240]: loss 9.312997
[epoch3, step1241]: loss 18.888334
[epoch3, step1242]: loss 7.413671
[epoch3, step1243]: loss 14.515979
[epoch3, step1244]: loss 15.366967
[epoch3, step1245]: loss 9.229261
[epoch3, step1246]: loss 5.478634
[epoch3, step1247]: loss 19.354980
[epoch3, step1248]: loss 4.948627
[epoch3, step1249]: loss 6.092071
[epoch3, step1250]: loss 5.125047
[epoch3, step1251]: loss 4.711084
[epoch3, step1252]: loss 7.483483
[epoch3, step1253]: loss 5.281159
[epoch3, step1254]: loss 23.455618
[epoch3, step1255]: loss 18.779793
[epoch3, step1256]: loss 4.098598
[epoch3, step1257]: loss 6.671297
[epoch3, step1258]: loss 4.026225
[epoch3, step1259]: loss 11.114742
[epoch3, step1260]: loss 12.125270
[epoch3, step1261]: loss 9.576175
[epoch3, step1262]: loss 11.075128
[epoch3, step1263]: loss 18.887371
[epoch3, step1264]: loss 28.936581
[epoch3, step1265]: loss 5.146146
[epoch3, step1266]: loss 12.834246
[epoch3, step1267]: loss 8.839914
[epoch3, step1268]: loss 4.304181
[epoch3, step1269]: loss 5.454454
[epoch3, step1270]: loss 7.451268
[epoch3, step1271]: loss 6.142056
[epoch3, step1272]: loss 5.196878
[epoch3, step1273]: loss 7.121030
[epoch3, step1274]: loss 16.489908
[epoch3, step1275]: loss 5.876883
[epoch3, step1276]: loss 7.178871
[epoch3, step1277]: loss 8.503403
[epoch3, step1278]: loss 22.136177
[epoch3, step1279]: loss 13.810260
[epoch3, step1280]: loss 28.513330
[epoch3, step1281]: loss 26.733604
[epoch3, step1282]: loss 5.061590
[epoch3, step1283]: loss 16.612518
[epoch3, step1284]: loss 16.982147
[epoch3, step1285]: loss 4.432828
[epoch3, step1286]: loss 7.485042
[epoch3, step1287]: loss 15.248755
[epoch3, step1288]: loss 19.390387
[epoch3, step1289]: loss 5.980581
[epoch3, step1290]: loss 5.240043
[epoch3, step1291]: loss 5.389406
[epoch3, step1292]: loss 19.315619
[epoch3, step1293]: loss 13.030973
[epoch3, step1294]: loss 12.623030
[epoch3, step1295]: loss 7.477247
[epoch3, step1296]: loss 4.144833
[epoch3, step1297]: loss 17.936527
[epoch3, step1298]: loss 5.366215
[epoch3, step1299]: loss 12.123978
[epoch3, step1300]: loss 14.540716
[epoch3, step1301]: loss 14.923987
[epoch3, step1302]: loss 14.478289
[epoch3, step1303]: loss 11.239269
[epoch3, step1304]: loss 40.644863
[epoch3, step1305]: loss 4.839895
[epoch3, step1306]: loss 3.530237
[epoch3, step1307]: loss 9.148920
[epoch3, step1308]: loss 13.324756
[epoch3, step1309]: loss 5.206860
[epoch3, step1310]: loss 4.916398
[epoch3, step1311]: loss 5.356165
[epoch3, step1312]: loss 18.549149
[epoch3, step1313]: loss 28.912075
[epoch3, step1314]: loss 5.231205
[epoch3, step1315]: loss 21.982086
[epoch3, step1316]: loss 23.917114
[epoch3, step1317]: loss 4.897178
[epoch3, step1318]: loss 27.760227
[epoch3, step1319]: loss 9.359791
[epoch3, step1320]: loss 6.554631
[epoch3, step1321]: loss 20.145746
[epoch3, step1322]: loss 7.380715
[epoch3, step1323]: loss 26.874588
[epoch3, step1324]: loss 14.884725
[epoch3, step1325]: loss 12.452892
[epoch3, step1326]: loss 17.007534
[epoch3, step1327]: loss 6.376552
[epoch3, step1328]: loss 2.511407
[epoch3, step1329]: loss 20.259840
[epoch3, step1330]: loss 12.190611
[epoch3, step1331]: loss 4.563769
[epoch3, step1332]: loss 30.735294
[epoch3, step1333]: loss 7.348940
[epoch3, step1334]: loss 4.014699
[epoch3, step1335]: loss 3.591827
[epoch3, step1336]: loss 6.463947
[epoch3, step1337]: loss 24.479126
[epoch3, step1338]: loss 5.945463
[epoch3, step1339]: loss 5.228770
[epoch3, step1340]: loss 9.334922
[epoch3, step1341]: loss 11.225614
[epoch3, step1342]: loss 3.941612
[epoch3, step1343]: loss 21.527020
[epoch3, step1344]: loss 6.386254
[epoch3, step1345]: loss 4.402731
[epoch3, step1346]: loss 8.718840
[epoch3, step1347]: loss 16.268156
[epoch3, step1348]: loss 5.803759
[epoch3, step1349]: loss 5.658926
[epoch3, step1350]: loss 2.731396
[epoch3, step1351]: loss 13.647608
[epoch3, step1352]: loss 27.985773
[epoch3, step1353]: loss 3.585763
[epoch3, step1354]: loss 15.279447
[epoch3, step1355]: loss 5.056834
[epoch3, step1356]: loss 15.012650
[epoch3, step1357]: loss 6.713959
[epoch3, step1358]: loss 7.900820
[epoch3, step1359]: loss 18.329935
[epoch3, step1360]: loss 4.355741
[epoch3, step1361]: loss 4.157361
[epoch3, step1362]: loss 1.616068
[epoch3, step1363]: loss 7.501281
[epoch3, step1364]: loss 6.995171
[epoch3, step1365]: loss 9.613187
[epoch3, step1366]: loss 6.836378
[epoch3, step1367]: loss 21.393745
[epoch3, step1368]: loss 4.210778
[epoch3, step1369]: loss 8.613424
[epoch3, step1370]: loss 19.068171
[epoch3, step1371]: loss 14.502442
[epoch3, step1372]: loss 27.782410
[epoch3, step1373]: loss 5.366234
[epoch3, step1374]: loss 5.236530
[epoch3, step1375]: loss 14.673678
[epoch3, step1376]: loss 15.631404
[epoch3, step1377]: loss 4.467701
[epoch3, step1378]: loss 7.857254
[epoch3, step1379]: loss 5.200048
[epoch3, step1380]: loss 2.488766
[epoch3, step1381]: loss 23.223043
[epoch3, step1382]: loss 24.821764
[epoch3, step1383]: loss 16.596336
[epoch3, step1384]: loss 5.065671
[epoch3, step1385]: loss 21.049225
[epoch3, step1386]: loss 3.185761
[epoch3, step1387]: loss 5.056541
[epoch3, step1388]: loss 7.382491
[epoch3, step1389]: loss 7.626221
[epoch3, step1390]: loss 16.091095
[epoch3, step1391]: loss 15.329463
[epoch3, step1392]: loss 11.274943
[epoch3, step1393]: loss 2.901857
[epoch3, step1394]: loss 4.964117
[epoch3, step1395]: loss 3.322436
[epoch3, step1396]: loss 16.268625
[epoch3, step1397]: loss 9.833849
[epoch3, step1398]: loss 22.244585
[epoch3, step1399]: loss 4.654608
[epoch3, step1400]: loss 23.094175
[epoch3, step1401]: loss 9.235724
[epoch3, step1402]: loss 22.664917
[epoch3, step1403]: loss 12.718878
[epoch3, step1404]: loss 17.783789
[epoch3, step1405]: loss 12.687838
[epoch3, step1406]: loss 10.989460
[epoch3, step1407]: loss 19.531635
[epoch3, step1408]: loss 9.624930
[epoch3, step1409]: loss 8.696487
[epoch3, step1410]: loss 5.681760
[epoch3, step1411]: loss 18.096273
[epoch3, step1412]: loss 6.090509
[epoch3, step1413]: loss 5.574358
[epoch3, step1414]: loss 5.221290
[epoch3, step1415]: loss 3.968652
[epoch3, step1416]: loss 3.952690
[epoch3, step1417]: loss 6.101348
[epoch3, step1418]: loss 5.683117
[epoch3, step1419]: loss 2.975427
[epoch3, step1420]: loss 25.021681
[epoch3, step1421]: loss 11.248518
[epoch3, step1422]: loss 3.993422
[epoch3, step1423]: loss 19.289930
[epoch3, step1424]: loss 10.996718
[epoch3, step1425]: loss 19.232098
[epoch3, step1426]: loss 45.700958
[epoch3, step1427]: loss 17.583111
[epoch3, step1428]: loss 6.597726
[epoch3, step1429]: loss 10.600017
[epoch3, step1430]: loss 31.735537
[epoch3, step1431]: loss 20.615631
[epoch3, step1432]: loss 4.893969
[epoch3, step1433]: loss 13.640987
[epoch3, step1434]: loss 6.934000
[epoch3, step1435]: loss 6.234880
[epoch3, step1436]: loss 30.114370
[epoch3, step1437]: loss 8.283922
[epoch3, step1438]: loss 12.546808
[epoch3, step1439]: loss 4.850404
[epoch3, step1440]: loss 6.771539
[epoch3, step1441]: loss 6.576654
[epoch3, step1442]: loss 19.176275
[epoch3, step1443]: loss 6.894111
[epoch3, step1444]: loss 26.521049
[epoch3, step1445]: loss 12.500163
[epoch3, step1446]: loss 10.738800
[epoch3, step1447]: loss 17.312019
[epoch3, step1448]: loss 5.890928
[epoch3, step1449]: loss 5.755422
[epoch3, step1450]: loss 4.961998
[epoch3, step1451]: loss 10.218529
[epoch3, step1452]: loss 19.689951
[epoch3, step1453]: loss 2.317631
[epoch3, step1454]: loss 8.215463
[epoch3, step1455]: loss 21.223040
[epoch3, step1456]: loss 8.050168
[epoch3, step1457]: loss 12.318075
[epoch3, step1458]: loss 4.919151
[epoch3, step1459]: loss 5.975769
[epoch3, step1460]: loss 5.081204
[epoch3, step1461]: loss 17.256203
[epoch3, step1462]: loss 9.147131
[epoch3, step1463]: loss 4.445200
[epoch3, step1464]: loss 5.866211
[epoch3, step1465]: loss 6.491831
[epoch3, step1466]: loss 8.522492
[epoch3, step1467]: loss 17.025757
[epoch3, step1468]: loss 4.442120
[epoch3, step1469]: loss 13.394213
[epoch3, step1470]: loss 11.479392
[epoch3, step1471]: loss 33.694626
[epoch3, step1472]: loss 5.072113
[epoch3, step1473]: loss 27.581898
[epoch3, step1474]: loss 27.226721
[epoch3, step1475]: loss 10.627755
[epoch3, step1476]: loss 13.010547
[epoch3, step1477]: loss 14.356840
[epoch3, step1478]: loss 23.649614
[epoch3, step1479]: loss 13.970852
[epoch3, step1480]: loss 14.755649
[epoch3, step1481]: loss 4.234129
[epoch3, step1482]: loss 5.227869
[epoch3, step1483]: loss 7.389025
[epoch3, step1484]: loss 10.586620
[epoch3, step1485]: loss 4.494823
[epoch3, step1486]: loss 13.482338
[epoch3, step1487]: loss 12.633512
[epoch3, step1488]: loss 4.200439
[epoch3, step1489]: loss 14.824571
[epoch3, step1490]: loss 5.762074
[epoch3, step1491]: loss 7.193604
[epoch3, step1492]: loss 16.462124
[epoch3, step1493]: loss 5.175122
[epoch3, step1494]: loss 6.390203
[epoch3, step1495]: loss 6.501908
[epoch3, step1496]: loss 17.296644
[epoch3, step1497]: loss 2.820533
[epoch3, step1498]: loss 13.402026
[epoch3, step1499]: loss 15.155987
[epoch3, step1500]: loss 3.427896
[epoch3, step1501]: loss 3.083604
[epoch3, step1502]: loss 8.501042
[epoch3, step1503]: loss 6.820080
[epoch3, step1504]: loss 22.766876
[epoch3, step1505]: loss 5.582135
[epoch3, step1506]: loss 7.533477
[epoch3, step1507]: loss 18.999233
[epoch3, step1508]: loss 16.501118
[epoch3, step1509]: loss 23.524097
[epoch3, step1510]: loss 22.153637
[epoch3, step1511]: loss 5.894413
[epoch3, step1512]: loss 2.683722
[epoch3, step1513]: loss 37.854988
[epoch3, step1514]: loss 7.639859
[epoch3, step1515]: loss 3.043015
[epoch3, step1516]: loss 12.147989
[epoch3, step1517]: loss 5.072408
[epoch3, step1518]: loss 21.476341
[epoch3, step1519]: loss 3.827340
[epoch3, step1520]: loss 10.226020
[epoch3, step1521]: loss 4.639835
[epoch3, step1522]: loss 19.976496
[epoch3, step1523]: loss 2.589335
[epoch3, step1524]: loss 6.726109
[epoch3, step1525]: loss 5.598015
[epoch3, step1526]: loss 4.509995
[epoch3, step1527]: loss 12.959633
[epoch3, step1528]: loss 20.602465
[epoch3, step1529]: loss 5.470391
[epoch3, step1530]: loss 13.517802
[epoch3, step1531]: loss 20.018862
[epoch3, step1532]: loss 13.690569
[epoch3, step1533]: loss 13.897026
[epoch3, step1534]: loss 27.704502
[epoch3, step1535]: loss 5.510715
[epoch3, step1536]: loss 6.291182
[epoch3, step1537]: loss 24.781366
[epoch3, step1538]: loss 9.957581
[epoch3, step1539]: loss 23.132498
[epoch3, step1540]: loss 6.827489
[epoch3, step1541]: loss 7.623393
[epoch3, step1542]: loss 4.944634
[epoch3, step1543]: loss 6.937153
[epoch3, step1544]: loss 12.373303
[epoch3, step1545]: loss 10.192059
[epoch3, step1546]: loss 18.889029
[epoch3, step1547]: loss 3.950139
[epoch3, step1548]: loss 12.029307
[epoch3, step1549]: loss 14.356928
[epoch3, step1550]: loss 16.075649
[epoch3, step1551]: loss 17.246588
[epoch3, step1552]: loss 12.264746
[epoch3, step1553]: loss 13.380406
[epoch3, step1554]: loss 21.167152
[epoch3, step1555]: loss 33.140659
[epoch3, step1556]: loss 5.038785
[epoch3, step1557]: loss 4.775687
[epoch3, step1558]: loss 21.554993
[epoch3, step1559]: loss 11.008141
[epoch3, step1560]: loss 3.621325
[epoch3, step1561]: loss 2.560436
[epoch3, step1562]: loss 16.420555
[epoch3, step1563]: loss 5.103555
[epoch3, step1564]: loss 15.059172
[epoch3, step1565]: loss 15.344119
[epoch3, step1566]: loss 13.709926
[epoch3, step1567]: loss 18.771454
[epoch3, step1568]: loss 11.247458
[epoch3, step1569]: loss 4.211658
[epoch3, step1570]: loss 5.287270
[epoch3, step1571]: loss 3.697920
[epoch3, step1572]: loss 4.902811
[epoch3, step1573]: loss 22.560085
[epoch3, step1574]: loss 4.150286
[epoch3, step1575]: loss 17.232475
[epoch3, step1576]: loss 10.365055
[epoch3, step1577]: loss 4.346791
[epoch3, step1578]: loss 7.365004
[epoch3, step1579]: loss 23.992222
[epoch3, step1580]: loss 6.223674
[epoch3, step1581]: loss 29.290876
[epoch3, step1582]: loss 2.924712
[epoch3, step1583]: loss 5.859469
[epoch3, step1584]: loss 7.458326
[epoch3, step1585]: loss 19.413223
[epoch3, step1586]: loss 15.527190
[epoch3, step1587]: loss 5.257235
[epoch3, step1588]: loss 4.402158
[epoch3, step1589]: loss 4.362944
[epoch3, step1590]: loss 4.323806
[epoch3, step1591]: loss 4.651609
[epoch3, step1592]: loss 4.114269
[epoch3, step1593]: loss 16.776466
[epoch3, step1594]: loss 4.470963
[epoch3, step1595]: loss 5.022227
[epoch3, step1596]: loss 3.944176
[epoch3, step1597]: loss 7.252646
[epoch3, step1598]: loss 23.833460
[epoch3, step1599]: loss 7.006275
[epoch3, step1600]: loss 6.191556
[epoch3, step1601]: loss 7.858798
[epoch3, step1602]: loss 7.362244
[epoch3, step1603]: loss 7.114671
[epoch3, step1604]: loss 6.676483
[epoch3, step1605]: loss 23.515976
[epoch3, step1606]: loss 15.260264
[epoch3, step1607]: loss 7.923718
[epoch3, step1608]: loss 22.346426
[epoch3, step1609]: loss 15.349565
[epoch3, step1610]: loss 11.842941
[epoch3, step1611]: loss 12.164323
[epoch3, step1612]: loss 7.813623
[epoch3, step1613]: loss 4.147368
[epoch3, step1614]: loss 5.247302
[epoch3, step1615]: loss 2.820151
[epoch3, step1616]: loss 4.676928
[epoch3, step1617]: loss 21.280956
[epoch3, step1618]: loss 12.310415
[epoch3, step1619]: loss 11.080235
[epoch3, step1620]: loss 4.154393
[epoch3, step1621]: loss 10.787683
[epoch3, step1622]: loss 6.069177
[epoch3, step1623]: loss 4.555839
[epoch3, step1624]: loss 12.565403
[epoch3, step1625]: loss 6.699209
[epoch3, step1626]: loss 58.367069
[epoch3, step1627]: loss 5.232416
[epoch3, step1628]: loss 5.154638
[epoch3, step1629]: loss 32.543926
[epoch3, step1630]: loss 19.697422
[epoch3, step1631]: loss 33.558823
[epoch3, step1632]: loss 5.821710
[epoch3, step1633]: loss 5.470488
[epoch3, step1634]: loss 23.414495
[epoch3, step1635]: loss 6.537660
[epoch3, step1636]: loss 13.834733
[epoch3, step1637]: loss 16.605213
[epoch3, step1638]: loss 12.149789
[epoch3, step1639]: loss 20.267475
[epoch3, step1640]: loss 5.973384
[epoch3, step1641]: loss 5.885643
[epoch3, step1642]: loss 9.073750
[epoch3, step1643]: loss 11.394094
[epoch3, step1644]: loss 15.658248
[epoch3, step1645]: loss 4.879659
[epoch3, step1646]: loss 5.252462
[epoch3, step1647]: loss 4.562961
[epoch3, step1648]: loss 23.673250
[epoch3, step1649]: loss 7.294381
[epoch3, step1650]: loss 8.449789
[epoch3, step1651]: loss 9.386905
[epoch3, step1652]: loss 12.425799
[epoch3, step1653]: loss 8.868227
[epoch3, step1654]: loss 14.241684
[epoch3, step1655]: loss 9.894521
[epoch3, step1656]: loss 5.276404
[epoch3, step1657]: loss 12.502640
[epoch3, step1658]: loss 3.976260
[epoch3, step1659]: loss 5.246840
[epoch3, step1660]: loss 10.105696
[epoch3, step1661]: loss 15.090755
[epoch3, step1662]: loss 8.144675
[epoch3, step1663]: loss 4.858972
[epoch3, step1664]: loss 6.844261
[epoch3, step1665]: loss 11.569445
[epoch3, step1666]: loss 5.208053
[epoch3, step1667]: loss 13.939178
[epoch3, step1668]: loss 16.463760
[epoch3, step1669]: loss 9.885962
[epoch3, step1670]: loss 20.318501
[epoch3, step1671]: loss 4.709936
[epoch3, step1672]: loss 6.071635
[epoch3, step1673]: loss 6.300165
[epoch3, step1674]: loss 8.404455
[epoch3, step1675]: loss 16.159746
[epoch3, step1676]: loss 4.187630
[epoch3, step1677]: loss 19.342773
[epoch3, step1678]: loss 12.607183
[epoch3, step1679]: loss 6.162237
[epoch3, step1680]: loss 6.805618
[epoch3, step1681]: loss 6.245796
[epoch3, step1682]: loss 4.849815
[epoch3, step1683]: loss 6.234452
[epoch3, step1684]: loss 14.617237
[epoch3, step1685]: loss 6.460353
[epoch3, step1686]: loss 3.487822
[epoch3, step1687]: loss 4.339723
[epoch3, step1688]: loss 4.066643
[epoch3, step1689]: loss 7.862824
[epoch3, step1690]: loss 5.333426
[epoch3, step1691]: loss 4.743435
[epoch3, step1692]: loss 20.842699
[epoch3, step1693]: loss 2.985334
[epoch3, step1694]: loss 3.935455
[epoch3, step1695]: loss 3.920496
[epoch3, step1696]: loss 10.539204
[epoch3, step1697]: loss 11.461329
[epoch3, step1698]: loss 6.898529
[epoch3, step1699]: loss 17.731539
[epoch3, step1700]: loss 26.903580
[epoch3, step1701]: loss 3.773042
[epoch3, step1702]: loss 9.351375
[epoch3, step1703]: loss 8.353170
[epoch3, step1704]: loss 7.428076
[epoch3, step1705]: loss 13.670878
[epoch3, step1706]: loss 4.342587
[epoch3, step1707]: loss 4.385114
[epoch3, step1708]: loss 3.818231
[epoch3, step1709]: loss 7.991336
[epoch3, step1710]: loss 8.219868
[epoch3, step1711]: loss 3.642100
[epoch3, step1712]: loss 4.880676
[epoch3, step1713]: loss 3.471937
[epoch3, step1714]: loss 12.318388
[epoch3, step1715]: loss 18.158434
[epoch3, step1716]: loss 6.395053
[epoch3, step1717]: loss 6.578945
[epoch3, step1718]: loss 19.800575
[epoch3, step1719]: loss 29.352705
[epoch3, step1720]: loss 8.641379
[epoch3, step1721]: loss 22.349573
[epoch3, step1722]: loss 11.983266
[epoch3, step1723]: loss 14.501340
[epoch3, step1724]: loss 4.556213
[epoch3, step1725]: loss 10.681438
[epoch3, step1726]: loss 13.410328
[epoch3, step1727]: loss 13.550947
[epoch3, step1728]: loss 16.353466
[epoch3, step1729]: loss 8.568112
[epoch3, step1730]: loss 28.931955
[epoch3, step1731]: loss 7.966716
[epoch3, step1732]: loss 10.558694
[epoch3, step1733]: loss 31.236864
[epoch3, step1734]: loss 21.456526
[epoch3, step1735]: loss 19.889488
[epoch3, step1736]: loss 7.271332
[epoch3, step1737]: loss 18.789021
[epoch3, step1738]: loss 5.277925
[epoch3, step1739]: loss 19.862854
[epoch3, step1740]: loss 6.449814
[epoch3, step1741]: loss 16.818386
[epoch3, step1742]: loss 6.682572
[epoch3, step1743]: loss 5.657894
[epoch3, step1744]: loss 5.928848
[epoch3, step1745]: loss 5.618459
[epoch3, step1746]: loss 25.495029
[epoch3, step1747]: loss 11.033026
[epoch3, step1748]: loss 8.503177
[epoch3, step1749]: loss 8.537970
[epoch3, step1750]: loss 5.757376
[epoch3, step1751]: loss 9.457986
[epoch3, step1752]: loss 7.507328
[epoch3, step1753]: loss 6.490804
[epoch3, step1754]: loss 10.425119
[epoch3, step1755]: loss 5.987778
[epoch3, step1756]: loss 5.638049
[epoch3, step1757]: loss 20.512613
[epoch3, step1758]: loss 28.855927
[epoch3, step1759]: loss 4.136532
[epoch3, step1760]: loss 26.187941
[epoch3, step1761]: loss 40.232693
[epoch3, step1762]: loss 14.494064
[epoch3, step1763]: loss 6.275811
[epoch3, step1764]: loss 11.861557
[epoch3, step1765]: loss 14.458108
[epoch3, step1766]: loss 5.158857
[epoch3, step1767]: loss 7.072481
[epoch3, step1768]: loss 5.100836
[epoch3, step1769]: loss 5.271648
[epoch3, step1770]: loss 5.495563
[epoch3, step1771]: loss 5.561320
[epoch3, step1772]: loss 16.643236
[epoch3, step1773]: loss 14.023997
[epoch3, step1774]: loss 3.614482
[epoch3, step1775]: loss 4.359485
[epoch3, step1776]: loss 5.918444
[epoch3, step1777]: loss 16.545900
[epoch3, step1778]: loss 32.206661
[epoch3, step1779]: loss 20.377342
[epoch3, step1780]: loss 11.089212
[epoch3, step1781]: loss 17.874517
[epoch3, step1782]: loss 20.226377
[epoch3, step1783]: loss 12.986047
[epoch3, step1784]: loss 6.356424
[epoch3, step1785]: loss 28.076387
[epoch3, step1786]: loss 25.990866
[epoch3, step1787]: loss 3.814828
[epoch3, step1788]: loss 3.187067
[epoch3, step1789]: loss 5.710939
[epoch3, step1790]: loss 5.326390
[epoch3, step1791]: loss 7.429036
[epoch3, step1792]: loss 11.068470
[epoch3, step1793]: loss 18.635845
[epoch3, step1794]: loss 55.385220
[epoch3, step1795]: loss 16.400827
[epoch3, step1796]: loss 16.210909
[epoch3, step1797]: loss 15.849319
[epoch3, step1798]: loss 4.505458
[epoch3, step1799]: loss 7.668959
[epoch3, step1800]: loss 59.465847
[epoch3, step1801]: loss 13.714077
[epoch3, step1802]: loss 2.451239
[epoch3, step1803]: loss 4.961613
[epoch3, step1804]: loss 12.958557
[epoch3, step1805]: loss 4.021772
[epoch3, step1806]: loss 4.057768
[epoch3, step1807]: loss 4.864522
[epoch3, step1808]: loss 5.459101
[epoch3, step1809]: loss 14.591434
[epoch3, step1810]: loss 14.194095
[epoch3, step1811]: loss 4.496780
[epoch3, step1812]: loss 15.553095
[epoch3, step1813]: loss 26.737427
[epoch3, step1814]: loss 8.519939
[epoch3, step1815]: loss 5.192070
[epoch3, step1816]: loss 11.806513
[epoch3, step1817]: loss 7.722235
[epoch3, step1818]: loss 7.324844
[epoch3, step1819]: loss 4.303960
[epoch3, step1820]: loss 16.459517
[epoch3, step1821]: loss 4.878922
[epoch3, step1822]: loss 9.708577
[epoch3, step1823]: loss 22.236061
[epoch3, step1824]: loss 7.301881
[epoch3, step1825]: loss 21.835438
[epoch3, step1826]: loss 15.405208
[epoch3, step1827]: loss 16.067158
[epoch3, step1828]: loss 7.388978
[epoch3, step1829]: loss 16.156443
[epoch3, step1830]: loss 11.794958
[epoch3, step1831]: loss 20.103706
[epoch3, step1832]: loss 18.452171
[epoch3, step1833]: loss 31.984512
[epoch3, step1834]: loss 29.522701
[epoch3, step1835]: loss 22.981236
[epoch3, step1836]: loss 24.313086
[epoch3, step1837]: loss 5.296353
[epoch3, step1838]: loss 14.058288
[epoch3, step1839]: loss 5.585717
[epoch3, step1840]: loss 6.073612
[epoch3, step1841]: loss 5.493150
[epoch3, step1842]: loss 20.486288
[epoch3, step1843]: loss 13.835745
[epoch3, step1844]: loss 14.084237
[epoch3, step1845]: loss 6.216943
[epoch3, step1846]: loss 13.545519
[epoch3, step1847]: loss 6.228141
[epoch3, step1848]: loss 14.462893
[epoch3, step1849]: loss 4.754737
[epoch3, step1850]: loss 10.438487
[epoch3, step1851]: loss 4.900127
[epoch3, step1852]: loss 7.086683
[epoch3, step1853]: loss 41.849548
[epoch3, step1854]: loss 18.473194
[epoch3, step1855]: loss 6.695563
[epoch3, step1856]: loss 12.221116
[epoch3, step1857]: loss 20.963640
[epoch3, step1858]: loss 28.157396
[epoch3, step1859]: loss 6.955652
[epoch3, step1860]: loss 6.387413
[epoch3, step1861]: loss 6.139849
[epoch3, step1862]: loss 3.942095
[epoch3, step1863]: loss 24.442472
[epoch3, step1864]: loss 6.979238
[epoch3, step1865]: loss 8.777753
[epoch3, step1866]: loss 21.038729
[epoch3, step1867]: loss 19.736467
[epoch3, step1868]: loss 4.632146
[epoch3, step1869]: loss 3.924240
[epoch3, step1870]: loss 5.685905
[epoch3, step1871]: loss 5.797020
[epoch3, step1872]: loss 11.477924
[epoch3, step1873]: loss 15.494485
[epoch3, step1874]: loss 5.721181
[epoch3, step1875]: loss 2.496933
[epoch3, step1876]: loss 29.786325
[epoch3, step1877]: loss 26.865967
[epoch3, step1878]: loss 25.677122
[epoch3, step1879]: loss 11.031009
[epoch3, step1880]: loss 13.557930
[epoch3, step1881]: loss 5.784599
[epoch3, step1882]: loss 11.747399
[epoch3, step1883]: loss 22.655426
[epoch3, step1884]: loss 17.264458
[epoch3, step1885]: loss 6.598508
[epoch3, step1886]: loss 13.693265
[epoch3, step1887]: loss 5.930538
[epoch3, step1888]: loss 5.861722
[epoch3, step1889]: loss 23.733006
[epoch3, step1890]: loss 18.451248
[epoch3, step1891]: loss 34.382576
[epoch3, step1892]: loss 7.871682
[epoch3, step1893]: loss 7.118587
[epoch3, step1894]: loss 10.411349
[epoch3, step1895]: loss 14.340263
[epoch3, step1896]: loss 7.262651
[epoch3, step1897]: loss 6.364364
[epoch3, step1898]: loss 4.735713
[epoch3, step1899]: loss 22.895170
[epoch3, step1900]: loss 5.442505
[epoch3, step1901]: loss 4.319272
[epoch3, step1902]: loss 10.983802
[epoch3, step1903]: loss 11.460124
[epoch3, step1904]: loss 3.945977
[epoch3, step1905]: loss 31.615145
[epoch3, step1906]: loss 3.153986
[epoch3, step1907]: loss 7.743975
[epoch3, step1908]: loss 5.237098
[epoch3, step1909]: loss 15.018134
[epoch3, step1910]: loss 20.949108
[epoch3, step1911]: loss 3.347843
[epoch3, step1912]: loss 30.485315
[epoch3, step1913]: loss 15.838095
[epoch3, step1914]: loss 15.088200
[epoch3, step1915]: loss 4.076222
[epoch3, step1916]: loss 11.041162
[epoch3, step1917]: loss 5.243420
[epoch3, step1918]: loss 4.138055
[epoch3, step1919]: loss 8.134315
[epoch3, step1920]: loss 21.769674
[epoch3, step1921]: loss 19.849636
[epoch3, step1922]: loss 17.494686
[epoch3, step1923]: loss 3.273211
[epoch3, step1924]: loss 13.255480
[epoch3, step1925]: loss 15.527074
[epoch3, step1926]: loss 8.332032
[epoch3, step1927]: loss 10.835155
[epoch3, step1928]: loss 6.401387
[epoch3, step1929]: loss 5.241175
[epoch3, step1930]: loss 4.392241
[epoch3, step1931]: loss 13.775105
[epoch3, step1932]: loss 10.208666
[epoch3, step1933]: loss 20.469492
[epoch3, step1934]: loss 4.169733
[epoch3, step1935]: loss 16.244432
[epoch3, step1936]: loss 3.947842
[epoch3, step1937]: loss 6.782753
[epoch3, step1938]: loss 28.191578
[epoch3, step1939]: loss 22.099398
[epoch3, step1940]: loss 39.376446
[epoch3, step1941]: loss 16.919268
[epoch3, step1942]: loss 5.626326
[epoch3, step1943]: loss 3.986753
[epoch3, step1944]: loss 4.000986
[epoch3, step1945]: loss 3.692918
[epoch3, step1946]: loss 5.206395
[epoch3, step1947]: loss 17.225065
[epoch3, step1948]: loss 3.398977
[epoch3, step1949]: loss 28.948708
[epoch3, step1950]: loss 6.318699
[epoch3, step1951]: loss 6.484152
[epoch3, step1952]: loss 4.637205
[epoch3, step1953]: loss 21.343472
[epoch3, step1954]: loss 4.163018
[epoch3, step1955]: loss 11.296322
[epoch3, step1956]: loss 9.822115
[epoch3, step1957]: loss 5.717605
[epoch3, step1958]: loss 31.370173
[epoch3, step1959]: loss 22.720081
[epoch3, step1960]: loss 5.832657
[epoch3, step1961]: loss 5.969410
[epoch3, step1962]: loss 11.896278
[epoch3, step1963]: loss 12.541447
[epoch3, step1964]: loss 6.496517
[epoch3, step1965]: loss 9.529427
[epoch3, step1966]: loss 7.776846
[epoch3, step1967]: loss 8.216439
[epoch3, step1968]: loss 5.465398
[epoch3, step1969]: loss 2.301232
[epoch3, step1970]: loss 8.343013
[epoch3, step1971]: loss 10.632465
[epoch3, step1972]: loss 21.170765
[epoch3, step1973]: loss 4.526420
[epoch3, step1974]: loss 3.768046
[epoch3, step1975]: loss 9.962712
[epoch3, step1976]: loss 11.914890
[epoch3, step1977]: loss 11.803334
[epoch3, step1978]: loss 7.529465
[epoch3, step1979]: loss 15.448599
[epoch3, step1980]: loss 22.659359
[epoch3, step1981]: loss 27.716969
[epoch3, step1982]: loss 17.709595
[epoch3, step1983]: loss 14.988209
[epoch3, step1984]: loss 20.332699
[epoch3, step1985]: loss 4.955639
[epoch3, step1986]: loss 25.401184
[epoch3, step1987]: loss 11.199520
[epoch3, step1988]: loss 16.570564
[epoch3, step1989]: loss 17.794647
[epoch3, step1990]: loss 24.014299
[epoch3, step1991]: loss 5.722710
[epoch3, step1992]: loss 5.037162
[epoch3, step1993]: loss 5.602434
[epoch3, step1994]: loss 11.997962
[epoch3, step1995]: loss 9.572372
[epoch3, step1996]: loss 5.568305
[epoch3, step1997]: loss 14.653651
[epoch3, step1998]: loss 27.801296
[epoch3, step1999]: loss 12.223707
[epoch3, step2000]: loss 4.037846
[epoch3, step2001]: loss 13.073761
[epoch3, step2002]: loss 3.308623
[epoch3, step2003]: loss 11.374323
[epoch3, step2004]: loss 3.804732
[epoch3, step2005]: loss 4.585955
[epoch3, step2006]: loss 34.577049
[epoch3, step2007]: loss 4.655413
[epoch3, step2008]: loss 6.352372
[epoch3, step2009]: loss 3.447231
[epoch3, step2010]: loss 3.332794
[epoch3, step2011]: loss 13.546648
[epoch3, step2012]: loss 22.936953
[epoch3, step2013]: loss 10.810878
[epoch3, step2014]: loss 4.354946
[epoch3, step2015]: loss 4.773170
[epoch3, step2016]: loss 3.856759
[epoch3, step2017]: loss 5.868519
[epoch3, step2018]: loss 9.841573
[epoch3, step2019]: loss 4.907382
[epoch3, step2020]: loss 3.597737
[epoch3, step2021]: loss 6.246372
[epoch3, step2022]: loss 15.739187
[epoch3, step2023]: loss 6.660145
[epoch3, step2024]: loss 9.153127
[epoch3, step2025]: loss 18.144392
[epoch3, step2026]: loss 15.268124
[epoch3, step2027]: loss 5.938961
[epoch3, step2028]: loss 10.055759
[epoch3, step2029]: loss 5.521292
[epoch3, step2030]: loss 13.519175
[epoch3, step2031]: loss 4.887059
[epoch3, step2032]: loss 9.734637
[epoch3, step2033]: loss 4.905574
[epoch3, step2034]: loss 24.937771
[epoch3, step2035]: loss 4.029632
[epoch3, step2036]: loss 30.653324
[epoch3, step2037]: loss 6.345600
[epoch3, step2038]: loss 13.541950
[epoch3, step2039]: loss 5.977172
[epoch3, step2040]: loss 2.581017
[epoch3, step2041]: loss 8.527048
[epoch3, step2042]: loss 8.106709
[epoch3, step2043]: loss 3.761211
[epoch3, step2044]: loss 2.309440
[epoch3, step2045]: loss 5.237799
[epoch3, step2046]: loss 10.859426
[epoch3, step2047]: loss 34.010521
[epoch3, step2048]: loss 13.682591
[epoch3, step2049]: loss 27.801182
[epoch3, step2050]: loss 48.185162
[epoch3, step2051]: loss 4.494918
[epoch3, step2052]: loss 5.714924
[epoch3, step2053]: loss 11.865267
[epoch3, step2054]: loss 3.413752
[epoch3, step2055]: loss 4.305532
[epoch3, step2056]: loss 9.349010
[epoch3, step2057]: loss 4.500584
[epoch3, step2058]: loss 11.135995
[epoch3, step2059]: loss 17.524519
[epoch3, step2060]: loss 31.419720
[epoch3, step2061]: loss 6.693735
[epoch3, step2062]: loss 21.223503
[epoch3, step2063]: loss 6.206356
[epoch3, step2064]: loss 5.766039
[epoch3, step2065]: loss 4.946991
[epoch3, step2066]: loss 5.062049
[epoch3, step2067]: loss 7.576789
[epoch3, step2068]: loss 15.653776
[epoch3, step2069]: loss 5.149824
[epoch3, step2070]: loss 28.216816
[epoch3, step2071]: loss 26.027178
[epoch3, step2072]: loss 7.779630
[epoch3, step2073]: loss 4.841456
[epoch3, step2074]: loss 3.999372
[epoch3, step2075]: loss 12.963527
[epoch3, step2076]: loss 20.417526
[epoch3, step2077]: loss 4.100568
[epoch3, step2078]: loss 3.641190
[epoch3, step2079]: loss 4.189324
[epoch3, step2080]: loss 17.550907
[epoch3, step2081]: loss 10.368968
[epoch3, step2082]: loss 4.926411
[epoch3, step2083]: loss 11.601080
[epoch3, step2084]: loss 3.472524
[epoch3, step2085]: loss 16.860563
[epoch3, step2086]: loss 19.895264
[epoch3, step2087]: loss 42.601498
[epoch3, step2088]: loss 9.421060
[epoch3, step2089]: loss 19.361282
[epoch3, step2090]: loss 2.820944
[epoch3, step2091]: loss 4.408795
[epoch3, step2092]: loss 4.819980
[epoch3, step2093]: loss 29.366859
[epoch3, step2094]: loss 9.700710
[epoch3, step2095]: loss 19.875038
[epoch3, step2096]: loss 12.562856
[epoch3, step2097]: loss 4.272692
[epoch3, step2098]: loss 12.145318
[epoch3, step2099]: loss 4.304493
[epoch3, step2100]: loss 21.127033
[epoch3, step2101]: loss 6.387517
[epoch3, step2102]: loss 28.073118
[epoch3, step2103]: loss 3.223643
[epoch3, step2104]: loss 5.404374
[epoch3, step2105]: loss 12.895317
[epoch3, step2106]: loss 20.764208
[epoch3, step2107]: loss 33.183228
[epoch3, step2108]: loss 32.867199
[epoch3, step2109]: loss 5.872634
[epoch3, step2110]: loss 31.789982
[epoch3, step2111]: loss 12.456281
[epoch3, step2112]: loss 5.064340
[epoch3, step2113]: loss 11.200769
[epoch3, step2114]: loss 15.936841
[epoch3, step2115]: loss 2.922309
[epoch3, step2116]: loss 5.253251
[epoch3, step2117]: loss 6.152619
[epoch3, step2118]: loss 2.519146
[epoch3, step2119]: loss 12.883914
[epoch3, step2120]: loss 14.482716
[epoch3, step2121]: loss 14.719323
[epoch3, step2122]: loss 13.591574
[epoch3, step2123]: loss 3.743619
[epoch3, step2124]: loss 15.849871
[epoch3, step2125]: loss 14.671812
[epoch3, step2126]: loss 3.800103
[epoch3, step2127]: loss 5.414525
[epoch3, step2128]: loss 14.468296
[epoch3, step2129]: loss 6.022734
[epoch3, step2130]: loss 24.925570
[epoch3, step2131]: loss 13.049178
[epoch3, step2132]: loss 3.691513
[epoch3, step2133]: loss 12.400802
[epoch3, step2134]: loss 4.728099
[epoch3, step2135]: loss 3.733040
[epoch3, step2136]: loss 18.795607
[epoch3, step2137]: loss 4.092272
[epoch3, step2138]: loss 4.093135
[epoch3, step2139]: loss 4.703914
[epoch3, step2140]: loss 5.527528
[epoch3, step2141]: loss 2.559948
[epoch3, step2142]: loss 7.491481
[epoch3, step2143]: loss 19.223333
[epoch3, step2144]: loss 18.336258
[epoch3, step2145]: loss 3.357652
[epoch3, step2146]: loss 10.675817
[epoch3, step2147]: loss 4.035429
[epoch3, step2148]: loss 5.583139
[epoch3, step2149]: loss 16.180258
[epoch3, step2150]: loss 6.865446
[epoch3, step2151]: loss 6.019977
[epoch3, step2152]: loss 16.816221
[epoch3, step2153]: loss 4.739669
[epoch3, step2154]: loss 3.017448
[epoch3, step2155]: loss 11.453307
[epoch3, step2156]: loss 4.171215
[epoch3, step2157]: loss 6.578823
[epoch3, step2158]: loss 20.523483
[epoch3, step2159]: loss 26.669369
[epoch3, step2160]: loss 7.857586
[epoch3, step2161]: loss 9.227015
[epoch3, step2162]: loss 21.661167
[epoch3, step2163]: loss 5.517654
[epoch3, step2164]: loss 1.672482
[epoch3, step2165]: loss 4.456684
[epoch3, step2166]: loss 2.824949
[epoch3, step2167]: loss 14.290260
[epoch3, step2168]: loss 4.453218
[epoch3, step2169]: loss 3.318641
[epoch3, step2170]: loss 6.273132
[epoch3, step2171]: loss 14.412844
[epoch3, step2172]: loss 3.063798
[epoch3, step2173]: loss 4.165548
[epoch3, step2174]: loss 19.943357
[epoch3, step2175]: loss 3.838800
[epoch3, step2176]: loss 18.285725
[epoch3, step2177]: loss 5.487109
[epoch3, step2178]: loss 24.582487
[epoch3, step2179]: loss 7.749899
[epoch3, step2180]: loss 21.703791
[epoch3, step2181]: loss 15.862764
[epoch3, step2182]: loss 18.874563
[epoch3, step2183]: loss 4.166238
[epoch3, step2184]: loss 4.267055
[epoch3, step2185]: loss 19.411629
[epoch3, step2186]: loss 13.251005
[epoch3, step2187]: loss 21.977503
[epoch3, step2188]: loss 17.595585
[epoch3, step2189]: loss 5.071915
[epoch3, step2190]: loss 11.344420
[epoch3, step2191]: loss 10.817747
[epoch3, step2192]: loss 14.731679
[epoch3, step2193]: loss 11.624442
[epoch3, step2194]: loss 6.019649
[epoch3, step2195]: loss 19.035801
[epoch3, step2196]: loss 11.464686
[epoch3, step2197]: loss 5.988153
[epoch3, step2198]: loss 3.911905
[epoch3, step2199]: loss 4.583272
[epoch3, step2200]: loss 12.090117
[epoch3, step2201]: loss 14.466125
[epoch3, step2202]: loss 8.316682
[epoch3, step2203]: loss 19.174240
[epoch3, step2204]: loss 5.846255
[epoch3, step2205]: loss 3.558592
[epoch3, step2206]: loss 4.347064
[epoch3, step2207]: loss 5.584085
[epoch3, step2208]: loss 33.777870
[epoch3, step2209]: loss 8.599744
[epoch3, step2210]: loss 3.598647
[epoch3, step2211]: loss 6.858076
[epoch3, step2212]: loss 10.624316
[epoch3, step2213]: loss 18.867041
[epoch3, step2214]: loss 5.441151
[epoch3, step2215]: loss 11.368505
[epoch3, step2216]: loss 15.604827
[epoch3, step2217]: loss 4.704054
[epoch3, step2218]: loss 18.165842
[epoch3, step2219]: loss 16.129795
[epoch3, step2220]: loss 19.898582
[epoch3, step2221]: loss 10.008627
[epoch3, step2222]: loss 22.030254
[epoch3, step2223]: loss 6.436969
[epoch3, step2224]: loss 14.569944
[epoch3, step2225]: loss 10.655884
[epoch3, step2226]: loss 13.416426
[epoch3, step2227]: loss 2.185776
[epoch3, step2228]: loss 4.856791
[epoch3, step2229]: loss 4.468453
[epoch3, step2230]: loss 19.697390
[epoch3, step2231]: loss 7.030987
[epoch3, step2232]: loss 3.966606
[epoch3, step2233]: loss 12.998769
[epoch3, step2234]: loss 29.172266
[epoch3, step2235]: loss 3.648788
[epoch3, step2236]: loss 5.022665
[epoch3, step2237]: loss 7.260897
[epoch3, step2238]: loss 14.615880
[epoch3, step2239]: loss 25.928307
[epoch3, step2240]: loss 6.097505
[epoch3, step2241]: loss 18.025141
[epoch3, step2242]: loss 3.847297
[epoch3, step2243]: loss 21.346136
[epoch3, step2244]: loss 13.347283
[epoch3, step2245]: loss 21.082714
[epoch3, step2246]: loss 23.427197
[epoch3, step2247]: loss 17.119253
[epoch3, step2248]: loss 10.362758
[epoch3, step2249]: loss 11.977679
[epoch3, step2250]: loss 4.693640
[epoch3, step2251]: loss 9.403971
[epoch3, step2252]: loss 19.343313
[epoch3, step2253]: loss 11.080435
[epoch3, step2254]: loss 32.136963
[epoch3, step2255]: loss 3.444907
[epoch3, step2256]: loss 10.166731
[epoch3, step2257]: loss 12.217257
[epoch3, step2258]: loss 20.645176
[epoch3, step2259]: loss 10.430518
[epoch3, step2260]: loss 11.860333
[epoch3, step2261]: loss 13.578375
[epoch3, step2262]: loss 4.147387
[epoch3, step2263]: loss 14.651199
[epoch3, step2264]: loss 35.457611
[epoch3, step2265]: loss 6.918252
[epoch3, step2266]: loss 2.234919
[epoch3, step2267]: loss 17.620951
[epoch3, step2268]: loss 5.040811
[epoch3, step2269]: loss 8.836257
[epoch3, step2270]: loss 6.606994
[epoch3, step2271]: loss 17.944830
[epoch3, step2272]: loss 4.263318
[epoch3, step2273]: loss 5.203182
[epoch3, step2274]: loss 14.314853
[epoch3, step2275]: loss 17.812757
[epoch3, step2276]: loss 12.280681
[epoch3, step2277]: loss 3.891886
[epoch3, step2278]: loss 7.157291
[epoch3, step2279]: loss 21.912502
[epoch3, step2280]: loss 6.791209
[epoch3, step2281]: loss 4.875803
[epoch3, step2282]: loss 19.391994
[epoch3, step2283]: loss 7.462389
[epoch3, step2284]: loss 11.763328
[epoch3, step2285]: loss 4.197322
[epoch3, step2286]: loss 6.662525
[epoch3, step2287]: loss 5.895106
[epoch3, step2288]: loss 17.747292
[epoch3, step2289]: loss 23.390345
[epoch3, step2290]: loss 7.788873
[epoch3, step2291]: loss 13.101857
[epoch3, step2292]: loss 3.543083
[epoch3, step2293]: loss 12.068578
[epoch3, step2294]: loss 3.235769
[epoch3, step2295]: loss 17.472834
[epoch3, step2296]: loss 4.770738
[epoch3, step2297]: loss 4.866100
[epoch3, step2298]: loss 9.494450
[epoch3, step2299]: loss 11.841393
[epoch3, step2300]: loss 6.634552
[epoch3, step2301]: loss 2.768268
[epoch3, step2302]: loss 12.266609
[epoch3, step2303]: loss 4.532084
[epoch3, step2304]: loss 34.016563
[epoch3, step2305]: loss 4.984208
[epoch3, step2306]: loss 17.721951
[epoch3, step2307]: loss 3.633143
[epoch3, step2308]: loss 5.086156
[epoch3, step2309]: loss 27.953896
[epoch3, step2310]: loss 32.709259
[epoch3, step2311]: loss 11.254800
[epoch3, step2312]: loss 5.927480
[epoch3, step2313]: loss 12.740509
[epoch3, step2314]: loss 12.452437
[epoch3, step2315]: loss 4.119984
[epoch3, step2316]: loss 12.778726
[epoch3, step2317]: loss 3.970199
[epoch3, step2318]: loss 25.491503
[epoch3, step2319]: loss 9.990459
[epoch3, step2320]: loss 4.920996
[epoch3, step2321]: loss 5.921450
[epoch3, step2322]: loss 4.154732
[epoch3, step2323]: loss 6.983444
[epoch3, step2324]: loss 6.368981
[epoch3, step2325]: loss 3.387672
[epoch3, step2326]: loss 4.592617
[epoch3, step2327]: loss 17.764198
[epoch3, step2328]: loss 7.078737
[epoch3, step2329]: loss 11.931732
[epoch3, step2330]: loss 14.222819
[epoch3, step2331]: loss 3.445055
[epoch3, step2332]: loss 19.995243
[epoch3, step2333]: loss 5.682381
[epoch3, step2334]: loss 14.640049
[epoch3, step2335]: loss 33.709759
[epoch3, step2336]: loss 19.398399
[epoch3, step2337]: loss 9.752556
[epoch3, step2338]: loss 14.533134
[epoch3, step2339]: loss 3.611662
[epoch3, step2340]: loss 7.649916
[epoch3, step2341]: loss 9.974636
[epoch3, step2342]: loss 14.288631
[epoch3, step2343]: loss 5.980398
[epoch3, step2344]: loss 17.449495
[epoch3, step2345]: loss 12.757524
[epoch3, step2346]: loss 21.956659
[epoch3, step2347]: loss 10.215856
[epoch3, step2348]: loss 14.074515
[epoch3, step2349]: loss 9.013815
[epoch3, step2350]: loss 4.028534
[epoch3, step2351]: loss 19.850748
[epoch3, step2352]: loss 7.460314
[epoch3, step2353]: loss 6.202164
[epoch3, step2354]: loss 39.304077
[epoch3, step2355]: loss 24.034576
[epoch3, step2356]: loss 12.090930
[epoch3, step2357]: loss 14.044066
[epoch3, step2358]: loss 14.672728
[epoch3, step2359]: loss 10.069536
[epoch3, step2360]: loss 16.953306
[epoch3, step2361]: loss 4.659834
[epoch3, step2362]: loss 12.259795
[epoch3, step2363]: loss 18.919569
[epoch3, step2364]: loss 6.133728
[epoch3, step2365]: loss 8.520686
[epoch3, step2366]: loss 13.538424
[epoch3, step2367]: loss 11.344930
[epoch3, step2368]: loss 13.767510
[epoch3, step2369]: loss 23.995335
[epoch3, step2370]: loss 6.818442
[epoch3, step2371]: loss 23.029238
[epoch3, step2372]: loss 5.837412
[epoch3, step2373]: loss 13.408257
[epoch3, step2374]: loss 17.368525
[epoch3, step2375]: loss 13.048988
[epoch3, step2376]: loss 14.978728
[epoch3, step2377]: loss 17.433758
[epoch3, step2378]: loss 24.029251
[epoch3, step2379]: loss 6.998100
[epoch3, step2380]: loss 33.135921
[epoch3, step2381]: loss 5.717725
[epoch3, step2382]: loss 13.611496
[epoch3, step2383]: loss 7.286106
[epoch3, step2384]: loss 10.934258
[epoch3, step2385]: loss 10.615748
[epoch3, step2386]: loss 7.787965
[epoch3, step2387]: loss 31.688715
[epoch3, step2388]: loss 3.638370
[epoch3, step2389]: loss 24.424471
[epoch3, step2390]: loss 2.941289
[epoch3, step2391]: loss 3.285758
[epoch3, step2392]: loss 3.557318
[epoch3, step2393]: loss 5.737900
[epoch3, step2394]: loss 5.040618
[epoch3, step2395]: loss 11.059120
[epoch3, step2396]: loss 3.862368
[epoch3, step2397]: loss 5.906414
[epoch3, step2398]: loss 11.533846
[epoch3, step2399]: loss 3.292508
[epoch3, step2400]: loss 6.986986
[epoch3, step2401]: loss 24.109777
[epoch3, step2402]: loss 14.971858
[epoch3, step2403]: loss 4.186966
[epoch3, step2404]: loss 7.455991
[epoch3, step2405]: loss 12.504252
[epoch3, step2406]: loss 13.525457
[epoch3, step2407]: loss 7.248596
[epoch3, step2408]: loss 22.475658
[epoch3, step2409]: loss 3.459877
[epoch3, step2410]: loss 10.882571
[epoch3, step2411]: loss 17.088001
[epoch3, step2412]: loss 6.650810
[epoch3, step2413]: loss 5.146201
[epoch3, step2414]: loss 3.769428
[epoch3, step2415]: loss 14.411640
[epoch3, step2416]: loss 30.079260
[epoch3, step2417]: loss 5.681574
[epoch3, step2418]: loss 9.594579
[epoch3, step2419]: loss 3.688646
[epoch3, step2420]: loss 5.830006
[epoch3, step2421]: loss 5.287575
[epoch3, step2422]: loss 18.242130
[epoch3, step2423]: loss 5.011132
[epoch3, step2424]: loss 5.966772
[epoch3, step2425]: loss 13.910430
[epoch3, step2426]: loss 4.618527
[epoch3, step2427]: loss 7.250411
[epoch3, step2428]: loss 3.949223
[epoch3, step2429]: loss 4.358768
[epoch3, step2430]: loss 14.023893
[epoch3, step2431]: loss 13.455352
[epoch3, step2432]: loss 21.199390
[epoch3, step2433]: loss 13.557193
[epoch3, step2434]: loss 5.976423
[epoch3, step2435]: loss 2.551956
[epoch3, step2436]: loss 22.054695
[epoch3, step2437]: loss 20.254890
[epoch3, step2438]: loss 20.405857
[epoch3, step2439]: loss 4.511173
[epoch3, step2440]: loss 12.847228
[epoch3, step2441]: loss 6.413350
[epoch3, step2442]: loss 21.233873
[epoch3, step2443]: loss 15.408174
[epoch3, step2444]: loss 3.408067
[epoch3, step2445]: loss 26.164268
[epoch3, step2446]: loss 12.259982
[epoch3, step2447]: loss 6.862951
[epoch3, step2448]: loss 5.249330
[epoch3, step2449]: loss 13.292294
[epoch3, step2450]: loss 3.247760
[epoch3, step2451]: loss 6.199327
[epoch3, step2452]: loss 6.538532
[epoch3, step2453]: loss 7.402207
[epoch3, step2454]: loss 11.071889
[epoch3, step2455]: loss 11.530085
[epoch3, step2456]: loss 2.984292
[epoch3, step2457]: loss 3.432477
[epoch3, step2458]: loss 8.693397
[epoch3, step2459]: loss 19.621174
[epoch3, step2460]: loss 3.602222
[epoch3, step2461]: loss 5.671606
[epoch3, step2462]: loss 16.126686
[epoch3, step2463]: loss 5.697550
[epoch3, step2464]: loss 34.159355
[epoch3, step2465]: loss 3.717623
[epoch3, step2466]: loss 16.330431
[epoch3, step2467]: loss 20.144224
[epoch3, step2468]: loss 18.188189
[epoch3, step2469]: loss 4.602078
[epoch3, step2470]: loss 4.086264
[epoch3, step2471]: loss 5.847252
[epoch3, step2472]: loss 5.609450
[epoch3, step2473]: loss 4.202431
[epoch3, step2474]: loss 6.704024
[epoch3, step2475]: loss 11.597984
[epoch3, step2476]: loss 4.317701
[epoch3, step2477]: loss 31.513397
[epoch3, step2478]: loss 3.897193
[epoch3, step2479]: loss 12.293456
[epoch3, step2480]: loss 2.449948
[epoch3, step2481]: loss 3.448022
[epoch3, step2482]: loss 25.323343
[epoch3, step2483]: loss 5.418957
[epoch3, step2484]: loss 18.819626
[epoch3, step2485]: loss 4.129639
[epoch3, step2486]: loss 3.763219
[epoch3, step2487]: loss 4.025892
[epoch3, step2488]: loss 5.636893
[epoch3, step2489]: loss 20.589743
[epoch3, step2490]: loss 2.280212
[epoch3, step2491]: loss 13.211850
[epoch3, step2492]: loss 8.992874
[epoch3, step2493]: loss 10.786845
[epoch3, step2494]: loss 14.611262
[epoch3, step2495]: loss 5.053885
[epoch3, step2496]: loss 4.488135
[epoch3, step2497]: loss 13.023377
[epoch3, step2498]: loss 27.707750
[epoch3, step2499]: loss 12.154680
[epoch3, step2500]: loss 4.313650
[epoch3, step2501]: loss 13.442083
[epoch3, step2502]: loss 14.120194
[epoch3, step2503]: loss 14.929271
[epoch3, step2504]: loss 25.842421
[epoch3, step2505]: loss 25.123852
[epoch3, step2506]: loss 28.652504
[epoch3, step2507]: loss 11.101005
[epoch3, step2508]: loss 3.833748
[epoch3, step2509]: loss 18.747839
[epoch3, step2510]: loss 12.207383
[epoch3, step2511]: loss 10.146997
[epoch3, step2512]: loss 4.885501
[epoch3, step2513]: loss 25.209362
[epoch3, step2514]: loss 2.343006
[epoch3, step2515]: loss 4.259794
[epoch3, step2516]: loss 5.292454
[epoch3, step2517]: loss 3.785261
[epoch3, step2518]: loss 4.473987
[epoch3, step2519]: loss 5.073736
[epoch3, step2520]: loss 4.954722
[epoch3, step2521]: loss 2.828421
[epoch3, step2522]: loss 3.791121
[epoch3, step2523]: loss 3.007697
[epoch3, step2524]: loss 4.819036
[epoch3, step2525]: loss 3.258910
[epoch3, step2526]: loss 3.121197
[epoch3, step2527]: loss 5.167791
[epoch3, step2528]: loss 32.781418
[epoch3, step2529]: loss 7.159880
[epoch3, step2530]: loss 7.034583
[epoch3, step2531]: loss 6.195567
[epoch3, step2532]: loss 14.813266
[epoch3, step2533]: loss 4.022999
[epoch3, step2534]: loss 14.915501
[epoch3, step2535]: loss 7.462657
[epoch3, step2536]: loss 2.985283
[epoch3, step2537]: loss 9.877896
[epoch3, step2538]: loss 4.442997
[epoch3, step2539]: loss 3.960159
[epoch3, step2540]: loss 2.472251
[epoch3, step2541]: loss 3.937454
[epoch3, step2542]: loss 8.230896
[epoch3, step2543]: loss 4.069096
[epoch3, step2544]: loss 11.319534
[epoch3, step2545]: loss 4.972093
[epoch3, step2546]: loss 5.521254
[epoch3, step2547]: loss 8.257592
[epoch3, step2548]: loss 3.869720
[epoch3, step2549]: loss 14.466141
[epoch3, step2550]: loss 13.932284
[epoch3, step2551]: loss 11.248557
[epoch3, step2552]: loss 4.300487
[epoch3, step2553]: loss 29.796801
[epoch3, step2554]: loss 12.096184
[epoch3, step2555]: loss 13.275781
[epoch3, step2556]: loss 27.271536
[epoch3, step2557]: loss 5.898837
[epoch3, step2558]: loss 5.204482
[epoch3, step2559]: loss 10.507688
[epoch3, step2560]: loss 6.351738
[epoch3, step2561]: loss 6.612692
[epoch3, step2562]: loss 3.270689
[epoch3, step2563]: loss 4.541631
[epoch3, step2564]: loss 8.584675
[epoch3, step2565]: loss 8.781182
[epoch3, step2566]: loss 5.027953
[epoch3, step2567]: loss 21.812031
[epoch3, step2568]: loss 20.447544
[epoch3, step2569]: loss 4.003768
[epoch3, step2570]: loss 11.596241
[epoch3, step2571]: loss 3.298831
[epoch3, step2572]: loss 7.973396
[epoch3, step2573]: loss 5.275103
[epoch3, step2574]: loss 4.560314
[epoch3, step2575]: loss 6.629902
[epoch3, step2576]: loss 3.656519
[epoch3, step2577]: loss 4.285724
[epoch3, step2578]: loss 3.991669
[epoch3, step2579]: loss 3.707922
[epoch3, step2580]: loss 4.398493
[epoch3, step2581]: loss 6.363170
[epoch3, step2582]: loss 3.379498
[epoch3, step2583]: loss 4.755708
[epoch3, step2584]: loss 4.776285
[epoch3, step2585]: loss 7.033647
[epoch3, step2586]: loss 10.755462
[epoch3, step2587]: loss 12.092564
[epoch3, step2588]: loss 6.069245
[epoch3, step2589]: loss 6.578338
[epoch3, step2590]: loss 5.661141
[epoch3, step2591]: loss 34.704117
[epoch3, step2592]: loss 29.004902
[epoch3, step2593]: loss 23.138622
[epoch3, step2594]: loss 5.395973
[epoch3, step2595]: loss 5.773463
[epoch3, step2596]: loss 11.211823
[epoch3, step2597]: loss 4.060976
[epoch3, step2598]: loss 5.034018
[epoch3, step2599]: loss 15.429550
[epoch3, step2600]: loss 4.075588
[epoch3, step2601]: loss 17.295387
[epoch3, step2602]: loss 11.149861
[epoch3, step2603]: loss 4.840766
[epoch3, step2604]: loss 11.846406
[epoch3, step2605]: loss 7.527981
[epoch3, step2606]: loss 15.223175
[epoch3, step2607]: loss 6.913670
[epoch3, step2608]: loss 14.294519
[epoch3, step2609]: loss 9.498689
[epoch3, step2610]: loss 3.068255
[epoch3, step2611]: loss 3.821172
[epoch3, step2612]: loss 4.227141
[epoch3, step2613]: loss 14.339502
[epoch3, step2614]: loss 5.539344
[epoch3, step2615]: loss 12.460284
[epoch3, step2616]: loss 6.047340
[epoch3, step2617]: loss 4.747293
[epoch3, step2618]: loss 13.017166
[epoch3, step2619]: loss 4.575128
[epoch3, step2620]: loss 8.992552
[epoch3, step2621]: loss 3.895276
[epoch3, step2622]: loss 14.265287
[epoch3, step2623]: loss 32.273232
[epoch3, step2624]: loss 13.686134
[epoch3, step2625]: loss 14.451622
[epoch3, step2626]: loss 17.668085
[epoch3, step2627]: loss 4.563903
[epoch3, step2628]: loss 19.535021
[epoch3, step2629]: loss 10.928029
[epoch3, step2630]: loss 11.812748
[epoch3, step2631]: loss 4.444381
[epoch3, step2632]: loss 21.892847
[epoch3, step2633]: loss 5.173117
[epoch3, step2634]: loss 8.582292
[epoch3, step2635]: loss 5.010941
[epoch3, step2636]: loss 3.924974
[epoch3, step2637]: loss 7.645900
[epoch3, step2638]: loss 8.718071
[epoch3, step2639]: loss 5.498280
[epoch3, step2640]: loss 4.879732
[epoch3, step2641]: loss 6.216691
[epoch3, step2642]: loss 14.364413
[epoch3, step2643]: loss 4.668342
[epoch3, step2644]: loss 13.449207
[epoch3, step2645]: loss 13.876859
[epoch3, step2646]: loss 6.191058
[epoch3, step2647]: loss 4.007096
[epoch3, step2648]: loss 9.593054
[epoch3, step2649]: loss 4.420081
[epoch3, step2650]: loss 3.226005
[epoch3, step2651]: loss 6.033747
[epoch3, step2652]: loss 5.561306
[epoch3, step2653]: loss 6.564666
[epoch3, step2654]: loss 32.452824
[epoch3, step2655]: loss 6.294109
[epoch3, step2656]: loss 33.161373
[epoch3, step2657]: loss 15.241801
[epoch3, step2658]: loss 4.761564
[epoch3, step2659]: loss 7.614780
[epoch3, step2660]: loss 18.209303
[epoch3, step2661]: loss 11.777678
[epoch3, step2662]: loss 25.284678
[epoch3, step2663]: loss 15.662917
[epoch3, step2664]: loss 5.132336
[epoch3, step2665]: loss 27.502405
[epoch3, step2666]: loss 7.340199
[epoch3, step2667]: loss 19.490032
[epoch3, step2668]: loss 4.561821
[epoch3, step2669]: loss 6.808720
[epoch3, step2670]: loss 3.561518
[epoch3, step2671]: loss 5.769616
[epoch3, step2672]: loss 10.580167
[epoch3, step2673]: loss 18.282398
[epoch3, step2674]: loss 32.228306
[epoch3, step2675]: loss 20.448284
[epoch3, step2676]: loss 5.937298
[epoch3, step2677]: loss 4.042361
[epoch3, step2678]: loss 7.186141
[epoch3, step2679]: loss 3.856445
[epoch3, step2680]: loss 6.379578
[epoch3, step2681]: loss 4.503956
[epoch3, step2682]: loss 3.681831
[epoch3, step2683]: loss 5.503897
[epoch3, step2684]: loss 8.590018
[epoch3, step2685]: loss 5.276115
[epoch3, step2686]: loss 7.151493
[epoch3, step2687]: loss 5.582911
[epoch3, step2688]: loss 10.940372
[epoch3, step2689]: loss 2.112064
[epoch3, step2690]: loss 8.593953
[epoch3, step2691]: loss 26.104012
[epoch3, step2692]: loss 31.836672
[epoch3, step2693]: loss 10.637068
[epoch3, step2694]: loss 11.552857
[epoch3, step2695]: loss 10.747189
[epoch3, step2696]: loss 3.396924
[epoch3, step2697]: loss 3.100978
[epoch3, step2698]: loss 6.612236
[epoch3, step2699]: loss 7.881366
[epoch3, step2700]: loss 9.426528
[epoch3, step2701]: loss 20.185740
[epoch3, step2702]: loss 3.813392
[epoch3, step2703]: loss 15.846128
[epoch3, step2704]: loss 7.133845
[epoch3, step2705]: loss 3.756373
[epoch3, step2706]: loss 3.524059
[epoch3, step2707]: loss 3.157144
[epoch3, step2708]: loss 24.720106
[epoch3, step2709]: loss 12.133684
[epoch3, step2710]: loss 14.601241
[epoch3, step2711]: loss 23.913401
[epoch3, step2712]: loss 6.976687
[epoch3, step2713]: loss 7.425251
[epoch3, step2714]: loss 12.443403
[epoch3, step2715]: loss 2.750087
[epoch3, step2716]: loss 11.067879
[epoch3, step2717]: loss 7.160430
[epoch3, step2718]: loss 3.023517
[epoch3, step2719]: loss 29.577541
[epoch3, step2720]: loss 5.428671
[epoch3, step2721]: loss 13.521258
[epoch3, step2722]: loss 30.847172
[epoch3, step2723]: loss 5.123175
[epoch3, step2724]: loss 7.434833
[epoch3, step2725]: loss 13.129716
[epoch3, step2726]: loss 5.058444
[epoch3, step2727]: loss 11.309025
[epoch3, step2728]: loss 11.797745
[epoch3, step2729]: loss 29.408022
[epoch3, step2730]: loss 4.273981
[epoch3, step2731]: loss 3.841501
[epoch3, step2732]: loss 11.878851
[epoch3, step2733]: loss 13.740897
[epoch3, step2734]: loss 6.017318
[epoch3, step2735]: loss 12.221152
[epoch3, step2736]: loss 21.595812
[epoch3, step2737]: loss 5.012830
[epoch3, step2738]: loss 14.005591
[epoch3, step2739]: loss 4.979365
[epoch3, step2740]: loss 6.529420
[epoch3, step2741]: loss 39.790512
[epoch3, step2742]: loss 4.433998
[epoch3, step2743]: loss 5.189084
[epoch3, step2744]: loss 5.188589
[epoch3, step2745]: loss 9.336040
[epoch3, step2746]: loss 2.753835
[epoch3, step2747]: loss 15.094234
[epoch3, step2748]: loss 15.418426
[epoch3, step2749]: loss 5.521461
[epoch3, step2750]: loss 4.031348
[epoch3, step2751]: loss 2.446810
[epoch3, step2752]: loss 12.842196
[epoch3, step2753]: loss 10.170568
[epoch3, step2754]: loss 7.619345
[epoch3, step2755]: loss 10.279410
[epoch3, step2756]: loss 3.557711
[epoch3, step2757]: loss 17.847040
[epoch3, step2758]: loss 30.362118
[epoch3, step2759]: loss 11.768728
[epoch3, step2760]: loss 10.168870
[epoch3, step2761]: loss 2.713460
[epoch3, step2762]: loss 11.420568
[epoch3, step2763]: loss 14.806188
[epoch3, step2764]: loss 6.271685
[epoch3, step2765]: loss 15.031126
[epoch3, step2766]: loss 24.987165
[epoch3, step2767]: loss 18.698257
[epoch3, step2768]: loss 23.140387
[epoch3, step2769]: loss 21.287785
[epoch3, step2770]: loss 13.338565
[epoch3, step2771]: loss 5.748211
[epoch3, step2772]: loss 13.684684
[epoch3, step2773]: loss 5.670575
[epoch3, step2774]: loss 10.517240
[epoch3, step2775]: loss 20.038734
[epoch3, step2776]: loss 3.796003
[epoch3, step2777]: loss 6.075682
[epoch3, step2778]: loss 13.096910
[epoch3, step2779]: loss 12.298535
[epoch3, step2780]: loss 12.627963
[epoch3, step2781]: loss 3.618078
[epoch3, step2782]: loss 2.226657
[epoch3, step2783]: loss 6.355874
[epoch3, step2784]: loss 5.507318
[epoch3, step2785]: loss 9.451538
[epoch3, step2786]: loss 4.803939
[epoch3, step2787]: loss 7.119250
[epoch3, step2788]: loss 11.576086
[epoch3, step2789]: loss 3.649826
[epoch3, step2790]: loss 5.847208
[epoch3, step2791]: loss 4.330050
[epoch3, step2792]: loss 4.732636
[epoch3, step2793]: loss 24.201794
[epoch3, step2794]: loss 15.386923
[epoch3, step2795]: loss 12.992903
[epoch3, step2796]: loss 13.676214
[epoch3, step2797]: loss 5.848466
[epoch3, step2798]: loss 14.247731
[epoch3, step2799]: loss 8.555148
[epoch3, step2800]: loss 8.838254
[epoch3, step2801]: loss 3.485817
[epoch3, step2802]: loss 24.753195
[epoch3, step2803]: loss 19.619944
[epoch3, step2804]: loss 5.004894
[epoch3, step2805]: loss 3.901983
[epoch3, step2806]: loss 3.588652
[epoch3, step2807]: loss 3.325537
[epoch3, step2808]: loss 3.459714
[epoch3, step2809]: loss 6.810850
[epoch3, step2810]: loss 11.879559
[epoch3, step2811]: loss 5.245195
[epoch3, step2812]: loss 11.301352
[epoch3, step2813]: loss 7.049608
[epoch3, step2814]: loss 4.193948
[epoch3, step2815]: loss 7.156112
[epoch3, step2816]: loss 3.749823
[epoch3, step2817]: loss 38.295036
[epoch3, step2818]: loss 10.982332
[epoch3, step2819]: loss 2.664490
[epoch3, step2820]: loss 9.385839
[epoch3, step2821]: loss 4.548952
[epoch3, step2822]: loss 29.152948
[epoch3, step2823]: loss 20.950012
[epoch3, step2824]: loss 13.202600
[epoch3, step2825]: loss 6.677021
[epoch3, step2826]: loss 16.659967
[epoch3, step2827]: loss 6.491866
[epoch3, step2828]: loss 8.316528
[epoch3, step2829]: loss 1.958902
[epoch3, step2830]: loss 7.732870
[epoch3, step2831]: loss 16.137718
[epoch3, step2832]: loss 18.136141
[epoch3, step2833]: loss 22.054140
[epoch3, step2834]: loss 3.056972
[epoch3, step2835]: loss 6.676757
[epoch3, step2836]: loss 5.086988
[epoch3, step2837]: loss 5.576990
[epoch3, step2838]: loss 7.086525
[epoch3, step2839]: loss 19.833508
[epoch3, step2840]: loss 24.536331
[epoch3, step2841]: loss 10.471016
[epoch3, step2842]: loss 12.444201
[epoch3, step2843]: loss 30.460047
[epoch3, step2844]: loss 9.706191
[epoch3, step2845]: loss 3.983165
[epoch3, step2846]: loss 7.618719
[epoch3, step2847]: loss 16.830761
[epoch3, step2848]: loss 3.920914
[epoch3, step2849]: loss 3.000155
[epoch3, step2850]: loss 14.369502
[epoch3, step2851]: loss 32.985085
[epoch3, step2852]: loss 2.921154
[epoch3, step2853]: loss 3.765955
[epoch3, step2854]: loss 20.160582
[epoch3, step2855]: loss 5.728077
[epoch3, step2856]: loss 11.955294
[epoch3, step2857]: loss 5.182656
[epoch3, step2858]: loss 6.367862
[epoch3, step2859]: loss 13.815457
[epoch3, step2860]: loss 2.967702
[epoch3, step2861]: loss 3.803469
[epoch3, step2862]: loss 5.091125
[epoch3, step2863]: loss 5.155921
[epoch3, step2864]: loss 12.163834
[epoch3, step2865]: loss 35.417252
[epoch3, step2866]: loss 4.202785
[epoch3, step2867]: loss 7.642569
[epoch3, step2868]: loss 5.751151
[epoch3, step2869]: loss 13.601821
[epoch3, step2870]: loss 4.395085
[epoch3, step2871]: loss 6.698590
[epoch3, step2872]: loss 4.659228
[epoch3, step2873]: loss 7.772501
[epoch3, step2874]: loss 42.666756
[epoch3, step2875]: loss 22.387718
[epoch3, step2876]: loss 17.835434
[epoch3, step2877]: loss 4.932429
[epoch3, step2878]: loss 16.528408
[epoch3, step2879]: loss 16.756929
[epoch3, step2880]: loss 3.813078
[epoch3, step2881]: loss 3.059428
[epoch3, step2882]: loss 18.700335
[epoch3, step2883]: loss 11.351591
[epoch3, step2884]: loss 2.236341
[epoch3, step2885]: loss 24.090288
[epoch3, step2886]: loss 8.988952
[epoch3, step2887]: loss 7.646702
[epoch3, step2888]: loss 4.950231
[epoch3, step2889]: loss 14.645002
[epoch3, step2890]: loss 8.582015
[epoch3, step2891]: loss 5.143024
[epoch3, step2892]: loss 29.590086
[epoch3, step2893]: loss 18.467028
[epoch3, step2894]: loss 5.710687
[epoch3, step2895]: loss 5.600175
[epoch3, step2896]: loss 4.269617
[epoch3, step2897]: loss 4.699468
[epoch3, step2898]: loss 11.418541
[epoch3, step2899]: loss 4.951798
[epoch3, step2900]: loss 13.766829
[epoch3, step2901]: loss 13.300066
[epoch3, step2902]: loss 9.780960
[epoch3, step2903]: loss 4.754119
[epoch3, step2904]: loss 13.932409
[epoch3, step2905]: loss 5.555129
[epoch3, step2906]: loss 14.835005
[epoch3, step2907]: loss 7.963838
[epoch3, step2908]: loss 19.999659
[epoch3, step2909]: loss 11.977777
[epoch3, step2910]: loss 20.582798
[epoch3, step2911]: loss 16.477367
[epoch3, step2912]: loss 10.895025
[epoch3, step2913]: loss 4.829035
[epoch3, step2914]: loss 10.612158
[epoch3, step2915]: loss 4.064684
[epoch3, step2916]: loss 13.858467
[epoch3, step2917]: loss 4.239338
[epoch3, step2918]: loss 14.474900
[epoch3, step2919]: loss 31.049871
[epoch3, step2920]: loss 2.839813
[epoch3, step2921]: loss 28.520111
[epoch3, step2922]: loss 4.920612
[epoch3, step2923]: loss 4.616968
[epoch3, step2924]: loss 2.647156
[epoch3, step2925]: loss 6.829920
[epoch3, step2926]: loss 8.163660
[epoch3, step2927]: loss 19.341761
[epoch3, step2928]: loss 9.324233
[epoch3, step2929]: loss 5.374878
[epoch3, step2930]: loss 13.406027
[epoch3, step2931]: loss 2.664557
[epoch3, step2932]: loss 2.412041
[epoch3, step2933]: loss 3.140703
[epoch3, step2934]: loss 13.879947
[epoch3, step2935]: loss 14.315564
[epoch3, step2936]: loss 5.497152
[epoch3, step2937]: loss 12.884905
[epoch3, step2938]: loss 5.587958
[epoch3, step2939]: loss 11.118638
[epoch3, step2940]: loss 18.544119
[epoch3, step2941]: loss 3.869779
[epoch3, step2942]: loss 5.553757
[epoch3, step2943]: loss 3.774448
[epoch3, step2944]: loss 5.525883
[epoch3, step2945]: loss 7.851094
[epoch3, step2946]: loss 15.498005
[epoch3, step2947]: loss 11.259531
[epoch3, step2948]: loss 16.924608
[epoch3, step2949]: loss 12.621870
[epoch3, step2950]: loss 4.685503
[epoch3, step2951]: loss 30.256306
[epoch3, step2952]: loss 10.987368
[epoch3, step2953]: loss 4.612697
[epoch3, step2954]: loss 9.771454
[epoch3, step2955]: loss 21.138147
[epoch3, step2956]: loss 12.385794
[epoch3, step2957]: loss 14.506301
[epoch3, step2958]: loss 25.973581
[epoch3, step2959]: loss 11.970770
[epoch3, step2960]: loss 4.127476
[epoch3, step2961]: loss 19.120762
[epoch3, step2962]: loss 20.274273
[epoch3, step2963]: loss 6.392106
[epoch3, step2964]: loss 5.131946
[epoch3, step2965]: loss 18.790751
[epoch3, step2966]: loss 3.243890
[epoch3, step2967]: loss 30.768467
[epoch3, step2968]: loss 5.268072
[epoch3, step2969]: loss 16.475126
[epoch3, step2970]: loss 8.094739
[epoch3, step2971]: loss 15.084635
[epoch3, step2972]: loss 3.563696
[epoch3, step2973]: loss 16.414524
[epoch3, step2974]: loss 15.642336
[epoch3, step2975]: loss 8.854619
[epoch3, step2976]: loss 2.360119
[epoch3, step2977]: loss 4.858037
[epoch3, step2978]: loss 16.529181
[epoch3, step2979]: loss 3.667243
[epoch3, step2980]: loss 18.677425
[epoch3, step2981]: loss 5.929898
[epoch3, step2982]: loss 6.141644
[epoch3, step2983]: loss 20.287155
[epoch3, step2984]: loss 17.229298
[epoch3, step2985]: loss 4.086681
[epoch3, step2986]: loss 12.674478
[epoch3, step2987]: loss 3.959425
[epoch3, step2988]: loss 3.263390
[epoch3, step2989]: loss 25.916830
[epoch3, step2990]: loss 7.126367
[epoch3, step2991]: loss 5.295524
[epoch3, step2992]: loss 7.390360
[epoch3, step2993]: loss 5.848971
[epoch3, step2994]: loss 12.713727
[epoch3, step2995]: loss 3.389425
[epoch3, step2996]: loss 21.036211
[epoch3, step2997]: loss 3.852482
[epoch3, step2998]: loss 3.525733
[epoch3, step2999]: loss 13.639359
[epoch3, step3000]: loss 17.113815
[epoch3, step3001]: loss 22.090508
[epoch3, step3002]: loss 16.827951
[epoch3, step3003]: loss 22.500715
[epoch3, step3004]: loss 4.060907
[epoch3, step3005]: loss 12.681876
[epoch3, step3006]: loss 4.455266
[epoch3, step3007]: loss 24.780699
[epoch3, step3008]: loss 17.770987
[epoch3, step3009]: loss 21.422897
[epoch3, step3010]: loss 4.651403
[epoch3, step3011]: loss 14.357696
[epoch3, step3012]: loss 6.192145
[epoch3, step3013]: loss 4.863610
[epoch3, step3014]: loss 5.836622
[epoch3, step3015]: loss 12.409145
[epoch3, step3016]: loss 4.894363
[epoch3, step3017]: loss 23.392040
[epoch3, step3018]: loss 10.525776
[epoch3, step3019]: loss 15.463659
[epoch3, step3020]: loss 12.640115
[epoch3, step3021]: loss 4.248479
[epoch3, step3022]: loss 12.536632
[epoch3, step3023]: loss 4.473493
[epoch3, step3024]: loss 5.758407
[epoch3, step3025]: loss 4.235066
[epoch3, step3026]: loss 3.626599
[epoch3, step3027]: loss 7.510150
[epoch3, step3028]: loss 13.032813
[epoch3, step3029]: loss 19.230551
[epoch3, step3030]: loss 13.436007
[epoch3, step3031]: loss 17.484486
[epoch3, step3032]: loss 33.551197
[epoch3, step3033]: loss 19.268867
[epoch3, step3034]: loss 3.552938
[epoch3, step3035]: loss 4.757259
[epoch3, step3036]: loss 7.268606
[epoch3, step3037]: loss 14.658012
[epoch3, step3038]: loss 12.791565
[epoch3, step3039]: loss 1.844685
[epoch3, step3040]: loss 4.165262
[epoch3, step3041]: loss 9.188649
[epoch3, step3042]: loss 5.318021
[epoch3, step3043]: loss 5.903131
[epoch3, step3044]: loss 2.740177
[epoch3, step3045]: loss 8.423267
[epoch3, step3046]: loss 19.453253
[epoch3, step3047]: loss 4.786606
[epoch3, step3048]: loss 11.778660
[epoch3, step3049]: loss 5.473813
[epoch3, step3050]: loss 13.226278
[epoch3, step3051]: loss 4.579710
[epoch3, step3052]: loss 3.993098
[epoch3, step3053]: loss 2.779495
[epoch3, step3054]: loss 4.951118
[epoch3, step3055]: loss 25.127750
[epoch3, step3056]: loss 14.570400
[epoch3, step3057]: loss 7.117472
[epoch3, step3058]: loss 3.955459
[epoch3, step3059]: loss 4.359236
[epoch3, step3060]: loss 11.556803
[epoch3, step3061]: loss 22.348204
[epoch3, step3062]: loss 5.016407
[epoch3, step3063]: loss 15.885221
[epoch3, step3064]: loss 11.343249
[epoch3, step3065]: loss 5.180102
[epoch3, step3066]: loss 5.620130
[epoch3, step3067]: loss 20.284277
[epoch3, step3068]: loss 4.306364
[epoch3, step3069]: loss 3.929732
[epoch3, step3070]: loss 14.988528
[epoch3, step3071]: loss 8.489138
[epoch3, step3072]: loss 9.065232
[epoch3, step3073]: loss 3.685987
[epoch3, step3074]: loss 4.730324
[epoch3, step3075]: loss 23.348690
[epoch3, step3076]: loss 11.370332

[epoch3]: avg loss 11.370332

[epoch4, step1]: loss 10.086816
[epoch4, step2]: loss 18.417519
[epoch4, step3]: loss 13.640150
[epoch4, step4]: loss 13.495652
[epoch4, step5]: loss 11.134893
[epoch4, step6]: loss 5.712276
[epoch4, step7]: loss 21.341599
[epoch4, step8]: loss 18.135813
[epoch4, step9]: loss 9.790624
[epoch4, step10]: loss 4.635031
[epoch4, step11]: loss 16.656225
[epoch4, step12]: loss 3.831983
[epoch4, step13]: loss 18.034473
[epoch4, step14]: loss 9.818540
[epoch4, step15]: loss 5.458252
[epoch4, step16]: loss 3.853556
[epoch4, step17]: loss 4.397655
[epoch4, step18]: loss 7.138061
[epoch4, step19]: loss 4.474195
[epoch4, step20]: loss 3.016423
[epoch4, step21]: loss 21.052795
[epoch4, step22]: loss 20.755301
[epoch4, step23]: loss 14.881675
[epoch4, step24]: loss 4.039508
[epoch4, step25]: loss 5.190454
[epoch4, step26]: loss 24.162859
[epoch4, step27]: loss 6.661517
[epoch4, step28]: loss 3.662952
[epoch4, step29]: loss 3.552513
[epoch4, step30]: loss 7.060514
[epoch4, step31]: loss 13.436969
[epoch4, step32]: loss 20.647118
[epoch4, step33]: loss 7.824550
[epoch4, step34]: loss 4.466096
[epoch4, step35]: loss 12.809317
[epoch4, step36]: loss 8.295465
[epoch4, step37]: loss 3.203357
[epoch4, step38]: loss 4.200704
[epoch4, step39]: loss 6.205916
[epoch4, step40]: loss 6.232305
[epoch4, step41]: loss 3.306313
[epoch4, step42]: loss 23.975760
[epoch4, step43]: loss 11.684995
[epoch4, step44]: loss 4.467293
[epoch4, step45]: loss 8.312511
[epoch4, step46]: loss 10.399380
[epoch4, step47]: loss 8.225669
[epoch4, step48]: loss 5.304145
[epoch4, step49]: loss 3.164839
[epoch4, step50]: loss 3.610178
[epoch4, step51]: loss 16.126255
[epoch4, step52]: loss 3.127891
[epoch4, step53]: loss 2.700230
[epoch4, step54]: loss 11.160254
[epoch4, step55]: loss 3.328106
[epoch4, step56]: loss 4.257463
[epoch4, step57]: loss 5.715963
[epoch4, step58]: loss 11.785643
[epoch4, step59]: loss 20.971930
[epoch4, step60]: loss 24.002089
[epoch4, step61]: loss 4.294597
[epoch4, step62]: loss 8.363825
[epoch4, step63]: loss 17.713892
[epoch4, step64]: loss 5.543151
[epoch4, step65]: loss 34.249096
[epoch4, step66]: loss 23.023268
[epoch4, step67]: loss 13.093604
[epoch4, step68]: loss 31.522684
[epoch4, step69]: loss 7.031102
[epoch4, step70]: loss 50.060032
[epoch4, step71]: loss 4.968474
[epoch4, step72]: loss 21.425505
[epoch4, step73]: loss 6.883527
[epoch4, step74]: loss 4.490018
[epoch4, step75]: loss 11.717793
[epoch4, step76]: loss 18.944771
[epoch4, step77]: loss 14.749218
[epoch4, step78]: loss 13.729345
[epoch4, step79]: loss 13.945541
[epoch4, step80]: loss 7.147154
[epoch4, step81]: loss 12.426774
[epoch4, step82]: loss 11.063716
[epoch4, step83]: loss 6.564201
[epoch4, step84]: loss 3.769797
[epoch4, step85]: loss 10.288341
[epoch4, step86]: loss 30.736828
[epoch4, step87]: loss 1.807480
[epoch4, step88]: loss 4.724667
[epoch4, step89]: loss 1.299260
[epoch4, step90]: loss 13.616961
[epoch4, step91]: loss 11.219639
[epoch4, step92]: loss 4.370584
[epoch4, step93]: loss 20.392942
[epoch4, step94]: loss 19.916542
[epoch4, step95]: loss 12.550659
[epoch4, step96]: loss 5.187189
[epoch4, step97]: loss 27.615179
[epoch4, step98]: loss 3.155820
[epoch4, step99]: loss 4.555453
[epoch4, step100]: loss 6.626590
[epoch4, step101]: loss 13.084897
[epoch4, step102]: loss 4.421464
[epoch4, step103]: loss 11.408434
[epoch4, step104]: loss 4.170564
[epoch4, step105]: loss 3.239573
[epoch4, step106]: loss 5.527621
[epoch4, step107]: loss 13.652073
[epoch4, step108]: loss 6.521398
[epoch4, step109]: loss 11.592851
[epoch4, step110]: loss 7.093905
[epoch4, step111]: loss 10.616607
[epoch4, step112]: loss 14.712475
[epoch4, step113]: loss 3.417842
[epoch4, step114]: loss 4.829337
[epoch4, step115]: loss 9.221302
[epoch4, step116]: loss 13.492185
[epoch4, step117]: loss 6.428349
[epoch4, step118]: loss 4.982331
[epoch4, step119]: loss 4.617866
[epoch4, step120]: loss 3.934593
[epoch4, step121]: loss 18.518169
[epoch4, step122]: loss 7.865578
[epoch4, step123]: loss 5.069164
[epoch4, step124]: loss 2.265057
[epoch4, step125]: loss 12.896320
[epoch4, step126]: loss 10.311563
[epoch4, step127]: loss 5.232961
[epoch4, step128]: loss 12.536346
[epoch4, step129]: loss 19.014692
[epoch4, step130]: loss 4.406004
[epoch4, step131]: loss 4.800735
[epoch4, step132]: loss 43.112518
[epoch4, step133]: loss 7.220888
[epoch4, step134]: loss 7.503988
[epoch4, step135]: loss 29.126928
[epoch4, step136]: loss 22.239567
[epoch4, step137]: loss 1.930852
[epoch4, step138]: loss 5.464942
[epoch4, step139]: loss 2.818169
[epoch4, step140]: loss 5.199637
[epoch4, step141]: loss 4.666088
[epoch4, step142]: loss 5.482808
[epoch4, step143]: loss 5.881246
[epoch4, step144]: loss 12.945673
[epoch4, step145]: loss 3.833863
[epoch4, step146]: loss 13.612697
[epoch4, step147]: loss 7.796531
[epoch4, step148]: loss 3.384320
[epoch4, step149]: loss 11.119395
[epoch4, step150]: loss 12.868345
[epoch4, step151]: loss 3.246552
[epoch4, step152]: loss 12.356489
[epoch4, step153]: loss 3.213770
[epoch4, step154]: loss 3.934813
[epoch4, step155]: loss 17.246897
[epoch4, step156]: loss 10.267192
[epoch4, step157]: loss 3.273734
[epoch4, step158]: loss 6.205776
[epoch4, step159]: loss 42.897644
[epoch4, step160]: loss 1.920295
[epoch4, step161]: loss 6.515212
[epoch4, step162]: loss 16.487825
[epoch4, step163]: loss 11.684285
[epoch4, step164]: loss 14.096198
[epoch4, step165]: loss 6.601329
[epoch4, step166]: loss 4.840997
[epoch4, step167]: loss 27.028837
[epoch4, step168]: loss 7.675453
[epoch4, step169]: loss 15.073558
[epoch4, step170]: loss 10.117208
[epoch4, step171]: loss 1.971012
[epoch4, step172]: loss 4.681211
[epoch4, step173]: loss 10.360929
[epoch4, step174]: loss 8.931066
[epoch4, step175]: loss 14.482398
[epoch4, step176]: loss 12.548495
[epoch4, step177]: loss 5.211453
[epoch4, step178]: loss 13.121951
[epoch4, step179]: loss 20.277981
[epoch4, step180]: loss 4.058959
[epoch4, step181]: loss 30.942715
[epoch4, step182]: loss 12.008336
[epoch4, step183]: loss 3.668609
[epoch4, step184]: loss 11.593452
[epoch4, step185]: loss 11.051923
[epoch4, step186]: loss 13.004178
[epoch4, step187]: loss 14.193625
[epoch4, step188]: loss 3.447333
[epoch4, step189]: loss 12.219228
[epoch4, step190]: loss 4.694645
[epoch4, step191]: loss 5.577462
[epoch4, step192]: loss 3.138310
[epoch4, step193]: loss 17.604836
[epoch4, step194]: loss 3.089013
[epoch4, step195]: loss 11.556492
[epoch4, step196]: loss 2.471442
[epoch4, step197]: loss 11.563945
[epoch4, step198]: loss 13.887634
[epoch4, step199]: loss 8.210562
[epoch4, step200]: loss 3.127074
[epoch4, step201]: loss 16.107845
[epoch4, step202]: loss 2.033903
[epoch4, step203]: loss 5.608592
[epoch4, step204]: loss 11.595926
[epoch4, step205]: loss 12.372806
[epoch4, step206]: loss 14.282881
[epoch4, step207]: loss 7.527147
[epoch4, step208]: loss 2.808017
[epoch4, step209]: loss 3.481714
[epoch4, step210]: loss 34.900650
[epoch4, step211]: loss 5.067658
[epoch4, step212]: loss 17.535128
[epoch4, step213]: loss 9.730295
[epoch4, step214]: loss 11.446863
[epoch4, step215]: loss 31.128448
[epoch4, step216]: loss 5.621558
[epoch4, step217]: loss 3.573883
[epoch4, step218]: loss 8.808349
[epoch4, step219]: loss 25.055166
[epoch4, step220]: loss 13.235608
[epoch4, step221]: loss 4.056448
[epoch4, step222]: loss 21.477978
[epoch4, step223]: loss 7.303451
[epoch4, step224]: loss 3.194988
[epoch4, step225]: loss 5.000805
[epoch4, step226]: loss 4.815162
[epoch4, step227]: loss 13.095279
[epoch4, step228]: loss 4.880161
[epoch4, step229]: loss 2.556112
[epoch4, step230]: loss 5.133116
[epoch4, step231]: loss 10.082788
[epoch4, step232]: loss 30.027378
[epoch4, step233]: loss 6.925540
[epoch4, step234]: loss 9.604939
[epoch4, step235]: loss 2.781704
[epoch4, step236]: loss 15.104409
[epoch4, step237]: loss 3.733143
[epoch4, step238]: loss 18.496721
[epoch4, step239]: loss 12.403988
[epoch4, step240]: loss 28.460426
[epoch4, step241]: loss 9.045816
[epoch4, step242]: loss 8.561497
[epoch4, step243]: loss 2.986980
[epoch4, step244]: loss 2.994504
[epoch4, step245]: loss 11.987865
[epoch4, step246]: loss 16.084816
[epoch4, step247]: loss 6.214524
[epoch4, step248]: loss 3.413895
[epoch4, step249]: loss 4.607014
[epoch4, step250]: loss 34.278564
[epoch4, step251]: loss 12.093731
[epoch4, step252]: loss 40.658325
[epoch4, step253]: loss 2.814003
[epoch4, step254]: loss 3.481821
[epoch4, step255]: loss 13.119945
[epoch4, step256]: loss 10.918652
[epoch4, step257]: loss 15.533073
[epoch4, step258]: loss 12.282214
[epoch4, step259]: loss 17.383816
[epoch4, step260]: loss 5.282346
[epoch4, step261]: loss 9.534774
[epoch4, step262]: loss 3.031918
[epoch4, step263]: loss 6.213916
[epoch4, step264]: loss 3.468300
[epoch4, step265]: loss 23.063730
[epoch4, step266]: loss 24.132786
[epoch4, step267]: loss 14.355108
[epoch4, step268]: loss 2.963804
[epoch4, step269]: loss 12.189611
[epoch4, step270]: loss 12.015292
[epoch4, step271]: loss 5.012506
[epoch4, step272]: loss 11.512591
[epoch4, step273]: loss 4.157352
[epoch4, step274]: loss 4.630154
[epoch4, step275]: loss 18.719683
[epoch4, step276]: loss 15.664531
[epoch4, step277]: loss 17.367632
[epoch4, step278]: loss 2.585810
[epoch4, step279]: loss 4.313566
[epoch4, step280]: loss 37.666550
[epoch4, step281]: loss 3.294811
[epoch4, step282]: loss 12.460674
[epoch4, step283]: loss 19.115442
[epoch4, step284]: loss 5.790420
[epoch4, step285]: loss 19.526026
[epoch4, step286]: loss 5.930866
[epoch4, step287]: loss 7.302267
[epoch4, step288]: loss 11.320583
[epoch4, step289]: loss 21.446066
[epoch4, step290]: loss 2.747775
[epoch4, step291]: loss 4.119133
[epoch4, step292]: loss 19.328777
[epoch4, step293]: loss 2.122144
[epoch4, step294]: loss 4.149406
[epoch4, step295]: loss 6.237500
[epoch4, step296]: loss 12.098463
[epoch4, step297]: loss 17.752083
[epoch4, step298]: loss 9.705528
[epoch4, step299]: loss 16.726938
[epoch4, step300]: loss 3.251631
[epoch4, step301]: loss 10.569527
[epoch4, step302]: loss 4.197427
[epoch4, step303]: loss 11.398972
[epoch4, step304]: loss 18.939014
[epoch4, step305]: loss 7.070978
[epoch4, step306]: loss 9.887749
[epoch4, step307]: loss 4.857225
[epoch4, step308]: loss 4.789326
[epoch4, step309]: loss 3.011720
[epoch4, step310]: loss 14.381188
[epoch4, step311]: loss 12.578620
[epoch4, step312]: loss 4.631311
[epoch4, step313]: loss 8.351460
[epoch4, step314]: loss 14.645042
[epoch4, step315]: loss 4.734870
[epoch4, step316]: loss 6.719537
[epoch4, step317]: loss 8.675686
[epoch4, step318]: loss 8.605829
[epoch4, step319]: loss 6.909172
[epoch4, step320]: loss 3.004775
[epoch4, step321]: loss 19.410494
[epoch4, step322]: loss 11.023282
[epoch4, step323]: loss 10.864900
[epoch4, step324]: loss 8.082909
[epoch4, step325]: loss 4.105478
[epoch4, step326]: loss 17.049788
[epoch4, step327]: loss 5.527826
[epoch4, step328]: loss 13.110150
[epoch4, step329]: loss 12.068529
[epoch4, step330]: loss 3.507050
[epoch4, step331]: loss 9.391368
[epoch4, step332]: loss 7.249165
[epoch4, step333]: loss 14.478973
[epoch4, step334]: loss 2.995543
[epoch4, step335]: loss 2.955959
[epoch4, step336]: loss 15.231703
[epoch4, step337]: loss 11.899754
[epoch4, step338]: loss 5.100564
[epoch4, step339]: loss 6.138484
[epoch4, step340]: loss 4.543480
[epoch4, step341]: loss 12.749449
[epoch4, step342]: loss 8.856767
[epoch4, step343]: loss 10.085537
[epoch4, step344]: loss 8.980131
[epoch4, step345]: loss 3.404746
[epoch4, step346]: loss 9.674466
[epoch4, step347]: loss 18.182976
[epoch4, step348]: loss 8.227116
[epoch4, step349]: loss 9.194687
[epoch4, step350]: loss 31.415257
[epoch4, step351]: loss 19.311460
[epoch4, step352]: loss 26.342484
[epoch4, step353]: loss 12.863291
[epoch4, step354]: loss 12.495335
[epoch4, step355]: loss 7.422118
[epoch4, step356]: loss 11.091359
[epoch4, step357]: loss 4.097163
[epoch4, step358]: loss 28.404293
[epoch4, step359]: loss 2.911657
[epoch4, step360]: loss 4.184034
[epoch4, step361]: loss 20.518757
[epoch4, step362]: loss 8.221928
[epoch4, step363]: loss 12.139617
[epoch4, step364]: loss 10.231256
[epoch4, step365]: loss 2.928633
[epoch4, step366]: loss 16.097284
[epoch4, step367]: loss 2.996285
[epoch4, step368]: loss 2.504922
[epoch4, step369]: loss 4.249000
[epoch4, step370]: loss 5.789961
[epoch4, step371]: loss 4.523036
[epoch4, step372]: loss 5.831460
[epoch4, step373]: loss 2.749191
[epoch4, step374]: loss 4.775088
[epoch4, step375]: loss 4.141524
[epoch4, step376]: loss 8.440945
[epoch4, step377]: loss 17.853003
[epoch4, step378]: loss 22.361130
[epoch4, step379]: loss 5.727698
[epoch4, step380]: loss 10.964198
[epoch4, step381]: loss 14.790036
[epoch4, step382]: loss 13.018744
[epoch4, step383]: loss 7.951319
[epoch4, step384]: loss 4.217603
[epoch4, step385]: loss 5.143278
[epoch4, step386]: loss 3.955554
[epoch4, step387]: loss 11.862461
[epoch4, step388]: loss 5.591849
[epoch4, step389]: loss 14.629136
[epoch4, step390]: loss 4.574138
[epoch4, step391]: loss 2.143406
[epoch4, step392]: loss 18.130016
[epoch4, step393]: loss 14.677581
[epoch4, step394]: loss 4.163413
[epoch4, step395]: loss 4.263606
[epoch4, step396]: loss 19.637379
[epoch4, step397]: loss 3.986511
[epoch4, step398]: loss 2.688556
[epoch4, step399]: loss 3.226386
[epoch4, step400]: loss 11.953206
[epoch4, step401]: loss 17.668947
[epoch4, step402]: loss 5.385617
[epoch4, step403]: loss 11.657744
[epoch4, step404]: loss 17.078415
[epoch4, step405]: loss 2.633249
[epoch4, step406]: loss 4.410568
[epoch4, step407]: loss 4.849380
[epoch4, step408]: loss 11.339811
[epoch4, step409]: loss 9.109829
[epoch4, step410]: loss 25.798824
[epoch4, step411]: loss 4.731473
[epoch4, step412]: loss 4.691492
[epoch4, step413]: loss 6.366430
[epoch4, step414]: loss 10.797622
[epoch4, step415]: loss 13.188277
[epoch4, step416]: loss 10.252801
[epoch4, step417]: loss 2.813025
[epoch4, step418]: loss 5.584375
[epoch4, step419]: loss 5.456144
[epoch4, step420]: loss 14.151048
[epoch4, step421]: loss 3.577956
[epoch4, step422]: loss 3.395420
[epoch4, step423]: loss 5.866735
[epoch4, step424]: loss 24.132029
[epoch4, step425]: loss 5.314938
[epoch4, step426]: loss 41.117905
[epoch4, step427]: loss 2.831881
[epoch4, step428]: loss 20.896975
[epoch4, step429]: loss 17.503801
[epoch4, step430]: loss 3.582343
[epoch4, step431]: loss 4.686105
[epoch4, step432]: loss 3.438426
[epoch4, step433]: loss 3.226879
[epoch4, step434]: loss 4.476745
[epoch4, step435]: loss 14.070865
[epoch4, step436]: loss 25.412323
[epoch4, step437]: loss 3.120967
[epoch4, step438]: loss 22.347876
[epoch4, step439]: loss 25.760687
[epoch4, step440]: loss 5.477062
[epoch4, step441]: loss 4.910947
[epoch4, step442]: loss 13.754354
[epoch4, step443]: loss 4.545772
[epoch4, step444]: loss 20.302071
[epoch4, step445]: loss 3.076069
[epoch4, step446]: loss 5.751997
[epoch4, step447]: loss 18.375929
[epoch4, step448]: loss 14.839916
[epoch4, step449]: loss 14.757162
[epoch4, step450]: loss 12.811072
[epoch4, step451]: loss 4.334530
[epoch4, step452]: loss 3.507059
[epoch4, step453]: loss 11.684442
[epoch4, step454]: loss 25.394104
[epoch4, step455]: loss 11.081155
[epoch4, step456]: loss 3.913538
[epoch4, step457]: loss 18.416874
[epoch4, step458]: loss 5.629272
[epoch4, step459]: loss 2.672451
[epoch4, step460]: loss 11.051310
[epoch4, step461]: loss 14.325379
[epoch4, step462]: loss 12.703321
[epoch4, step463]: loss 11.363214
[epoch4, step464]: loss 25.489386
[epoch4, step465]: loss 10.024168
[epoch4, step466]: loss 2.982623
[epoch4, step467]: loss 18.142134
[epoch4, step468]: loss 3.848697
[epoch4, step469]: loss 7.819366
[epoch4, step470]: loss 15.839139
[epoch4, step471]: loss 16.883684
[epoch4, step472]: loss 14.641372
[epoch4, step473]: loss 10.927401
[epoch4, step474]: loss 7.141535
[epoch4, step475]: loss 7.829706
[epoch4, step476]: loss 5.069292
[epoch4, step477]: loss 6.162058
[epoch4, step478]: loss 24.804592
[epoch4, step479]: loss 2.622740
[epoch4, step480]: loss 12.765696
[epoch4, step481]: loss 3.886650
[epoch4, step482]: loss 5.224429
[epoch4, step483]: loss 11.165427
[epoch4, step484]: loss 39.762951
[epoch4, step485]: loss 20.538757
[epoch4, step486]: loss 25.544342
[epoch4, step487]: loss 3.987231
[epoch4, step488]: loss 15.920156
[epoch4, step489]: loss 9.328554
[epoch4, step490]: loss 4.459565
[epoch4, step491]: loss 12.580081
[epoch4, step492]: loss 8.982459
[epoch4, step493]: loss 12.759121
[epoch4, step494]: loss 5.874639
[epoch4, step495]: loss 4.535810
[epoch4, step496]: loss 9.193348
[epoch4, step497]: loss 4.224994
[epoch4, step498]: loss 18.039736
[epoch4, step499]: loss 23.901541
[epoch4, step500]: loss 22.739967
[epoch4, step501]: loss 3.159388
[epoch4, step502]: loss 4.263173
[epoch4, step503]: loss 5.642893
[epoch4, step504]: loss 26.053862
[epoch4, step505]: loss 3.372292
[epoch4, step506]: loss 16.983932
[epoch4, step507]: loss 20.776585
[epoch4, step508]: loss 6.066562
[epoch4, step509]: loss 3.420564
[epoch4, step510]: loss 13.092766
[epoch4, step511]: loss 24.205532
[epoch4, step512]: loss 2.671890
[epoch4, step513]: loss 4.769996
[epoch4, step514]: loss 25.552402
[epoch4, step515]: loss 4.348629
[epoch4, step516]: loss 24.109051
[epoch4, step517]: loss 31.308578
[epoch4, step518]: loss 13.228021
[epoch4, step519]: loss 24.388809
[epoch4, step520]: loss 6.234755
[epoch4, step521]: loss 7.682763
[epoch4, step522]: loss 37.998703
[epoch4, step523]: loss 3.008048
[epoch4, step524]: loss 7.184259
[epoch4, step525]: loss 20.301855
[epoch4, step526]: loss 19.287609
[epoch4, step527]: loss 12.434314
[epoch4, step528]: loss 21.102373
[epoch4, step529]: loss 11.370688
[epoch4, step530]: loss 13.932468
[epoch4, step531]: loss 45.511089
[epoch4, step532]: loss 9.682682
[epoch4, step533]: loss 2.872896
[epoch4, step534]: loss 8.501035
[epoch4, step535]: loss 4.202217
[epoch4, step536]: loss 15.815981
[epoch4, step537]: loss 4.134531
[epoch4, step538]: loss 3.462880
[epoch4, step539]: loss 5.771663
[epoch4, step540]: loss 6.761653
[epoch4, step541]: loss 13.411213
[epoch4, step542]: loss 11.654861
[epoch4, step543]: loss 7.251088
[epoch4, step544]: loss 6.618669
[epoch4, step545]: loss 4.439074
[epoch4, step546]: loss 3.998755
[epoch4, step547]: loss 17.749763
[epoch4, step548]: loss 2.893015
[epoch4, step549]: loss 11.164143
[epoch4, step550]: loss 33.553825
[epoch4, step551]: loss 12.073862
[epoch4, step552]: loss 10.638932
[epoch4, step553]: loss 21.340897
[epoch4, step554]: loss 4.769727
[epoch4, step555]: loss 28.072622
[epoch4, step556]: loss 22.946718
[epoch4, step557]: loss 10.204224
[epoch4, step558]: loss 11.922260
[epoch4, step559]: loss 15.223921
[epoch4, step560]: loss 3.919343
[epoch4, step561]: loss 4.319242
[epoch4, step562]: loss 10.989498
[epoch4, step563]: loss 5.243125
[epoch4, step564]: loss 10.142148
[epoch4, step565]: loss 15.028871
[epoch4, step566]: loss 17.293053
[epoch4, step567]: loss 12.843737
[epoch4, step568]: loss 9.529639
[epoch4, step569]: loss 19.506998
[epoch4, step570]: loss 8.487823
[epoch4, step571]: loss 4.796938
[epoch4, step572]: loss 12.796029
[epoch4, step573]: loss 2.721611
[epoch4, step574]: loss 3.129900
[epoch4, step575]: loss 6.720819
[epoch4, step576]: loss 15.436877
[epoch4, step577]: loss 7.445213
[epoch4, step578]: loss 2.387872
[epoch4, step579]: loss 14.703331
[epoch4, step580]: loss 10.219277
[epoch4, step581]: loss 24.325645
[epoch4, step582]: loss 9.605824
[epoch4, step583]: loss 4.650592
[epoch4, step584]: loss 3.737580
[epoch4, step585]: loss 10.208322
[epoch4, step586]: loss 25.639051
[epoch4, step587]: loss 37.367954
[epoch4, step588]: loss 4.221157
[epoch4, step589]: loss 3.252461
[epoch4, step590]: loss 10.986214
[epoch4, step591]: loss 3.720173
[epoch4, step592]: loss 7.244481
[epoch4, step593]: loss 8.136829
[epoch4, step594]: loss 3.617322
[epoch4, step595]: loss 5.539876
[epoch4, step596]: loss 3.992516
[epoch4, step597]: loss 14.228595
[epoch4, step598]: loss 9.187575
[epoch4, step599]: loss 7.042036
[epoch4, step600]: loss 4.257061
[epoch4, step601]: loss 20.074909
[epoch4, step602]: loss 9.444572
[epoch4, step603]: loss 6.662123
[epoch4, step604]: loss 2.601442
[epoch4, step605]: loss 4.949094
[epoch4, step606]: loss 3.013014
[epoch4, step607]: loss 7.779990
[epoch4, step608]: loss 5.220066
[epoch4, step609]: loss 3.648304
[epoch4, step610]: loss 16.664139
[epoch4, step611]: loss 32.536171
[epoch4, step612]: loss 3.709479
[epoch4, step613]: loss 13.829219
[epoch4, step614]: loss 5.790421
[epoch4, step615]: loss 25.852890
[epoch4, step616]: loss 10.143745
[epoch4, step617]: loss 6.038464
[epoch4, step618]: loss 6.839140
[epoch4, step619]: loss 10.865944
[epoch4, step620]: loss 4.749049
[epoch4, step621]: loss 27.985878
[epoch4, step622]: loss 4.357666
[epoch4, step623]: loss 5.201609
[epoch4, step624]: loss 21.203218
[epoch4, step625]: loss 25.930105
[epoch4, step626]: loss 15.247070
[epoch4, step627]: loss 4.912483
[epoch4, step628]: loss 3.688010
[epoch4, step629]: loss 10.084208
[epoch4, step630]: loss 10.054181
[epoch4, step631]: loss 3.435464
[epoch4, step632]: loss 8.772738
[epoch4, step633]: loss 9.327308
[epoch4, step634]: loss 3.989001
[epoch4, step635]: loss 3.370208
[epoch4, step636]: loss 26.885630
[epoch4, step637]: loss 4.347375
[epoch4, step638]: loss 9.404925
[epoch4, step639]: loss 15.743940
[epoch4, step640]: loss 4.913694
[epoch4, step641]: loss 9.080816
[epoch4, step642]: loss 5.413589
[epoch4, step643]: loss 19.516094
[epoch4, step644]: loss 4.778194
[epoch4, step645]: loss 15.403110
[epoch4, step646]: loss 9.524354
[epoch4, step647]: loss 10.725821
[epoch4, step648]: loss 7.362389
[epoch4, step649]: loss 12.840629
[epoch4, step650]: loss 4.578696
[epoch4, step651]: loss 4.413183
[epoch4, step652]: loss 12.522869
[epoch4, step653]: loss 4.407998
[epoch4, step654]: loss 5.662276
[epoch4, step655]: loss 2.790025
[epoch4, step656]: loss 6.888775
[epoch4, step657]: loss 15.022640
[epoch4, step658]: loss 5.132780
[epoch4, step659]: loss 6.256088
[epoch4, step660]: loss 2.626454
[epoch4, step661]: loss 23.391249
[epoch4, step662]: loss 13.592649
[epoch4, step663]: loss 4.760083
[epoch4, step664]: loss 3.624663
[epoch4, step665]: loss 12.816735
[epoch4, step666]: loss 3.071414
[epoch4, step667]: loss 12.075287
[epoch4, step668]: loss 4.256691
[epoch4, step669]: loss 2.420115
[epoch4, step670]: loss 6.517941
[epoch4, step671]: loss 13.949506
[epoch4, step672]: loss 10.435743
[epoch4, step673]: loss 25.846684
[epoch4, step674]: loss 3.683906
[epoch4, step675]: loss 15.370028
[epoch4, step676]: loss 17.443161
[epoch4, step677]: loss 8.873592
[epoch4, step678]: loss 12.205935
[epoch4, step679]: loss 3.800948
[epoch4, step680]: loss 35.572044
[epoch4, step681]: loss 10.792630
[epoch4, step682]: loss 18.144499
[epoch4, step683]: loss 36.507198
[epoch4, step684]: loss 3.419135
[epoch4, step685]: loss 3.130197
[epoch4, step686]: loss 3.124328
[epoch4, step687]: loss 35.301617
[epoch4, step688]: loss 5.335400
[epoch4, step689]: loss 2.537405
[epoch4, step690]: loss 12.296790
[epoch4, step691]: loss 10.469937
[epoch4, step692]: loss 19.873940
[epoch4, step693]: loss 15.225128
[epoch4, step694]: loss 20.292856
[epoch4, step695]: loss 23.043941
[epoch4, step696]: loss 4.157979
[epoch4, step697]: loss 4.157450
[epoch4, step698]: loss 9.016511
[epoch4, step699]: loss 14.336799
[epoch4, step700]: loss 8.380963
[epoch4, step701]: loss 3.891539
[epoch4, step702]: loss 13.316084
[epoch4, step703]: loss 11.760909
[epoch4, step704]: loss 13.539454
[epoch4, step705]: loss 3.669437
[epoch4, step706]: loss 24.036840
[epoch4, step707]: loss 4.655237
[epoch4, step708]: loss 11.162580
[epoch4, step709]: loss 19.071552
[epoch4, step710]: loss 2.900866
[epoch4, step711]: loss 18.691862
[epoch4, step712]: loss 1.851025
[epoch4, step713]: loss 9.920932
[epoch4, step714]: loss 3.691434
[epoch4, step715]: loss 3.028553
[epoch4, step716]: loss 10.889526
[epoch4, step717]: loss 24.914169
[epoch4, step718]: loss 21.974066
[epoch4, step719]: loss 4.109880
[epoch4, step720]: loss 22.768490
[epoch4, step721]: loss 21.075918
[epoch4, step722]: loss 26.819452
[epoch4, step723]: loss 5.572155
[epoch4, step724]: loss 3.015998
[epoch4, step725]: loss 4.630618
[epoch4, step726]: loss 2.075534
[epoch4, step727]: loss 6.382835
[epoch4, step728]: loss 6.507355
[epoch4, step729]: loss 9.017769
[epoch4, step730]: loss 7.481681
[epoch4, step731]: loss 6.782186
[epoch4, step732]: loss 5.193423
[epoch4, step733]: loss 23.219919
[epoch4, step734]: loss 4.753744
[epoch4, step735]: loss 27.290680
[epoch4, step736]: loss 4.730985
[epoch4, step737]: loss 12.732887
[epoch4, step738]: loss 3.113534
[epoch4, step739]: loss 8.481304
[epoch4, step740]: loss 7.538278
[epoch4, step741]: loss 22.843971
[epoch4, step742]: loss 5.993288
[epoch4, step743]: loss 11.065071
[epoch4, step744]: loss 37.585922
[epoch4, step745]: loss 4.239529
[epoch4, step746]: loss 3.357145
[epoch4, step747]: loss 12.080214
[epoch4, step748]: loss 9.583304
[epoch4, step749]: loss 2.743673
[epoch4, step750]: loss 3.798759
[epoch4, step751]: loss 13.827985
[epoch4, step752]: loss 19.868950
[epoch4, step753]: loss 5.119489
[epoch4, step754]: loss 20.924959
[epoch4, step755]: loss 5.572532
[epoch4, step756]: loss 10.216207
[epoch4, step757]: loss 13.982278
[epoch4, step758]: loss 20.032825
[epoch4, step759]: loss 7.883168
[epoch4, step760]: loss 2.234842
[epoch4, step761]: loss 15.124775
[epoch4, step762]: loss 5.566598
[epoch4, step763]: loss 16.597532
[epoch4, step764]: loss 11.086863
[epoch4, step765]: loss 4.904261
[epoch4, step766]: loss 9.828764
[epoch4, step767]: loss 10.532290
[epoch4, step768]: loss 4.405599
[epoch4, step769]: loss 9.379833
[epoch4, step770]: loss 22.411562
[epoch4, step771]: loss 10.716801
[epoch4, step772]: loss 7.392119
[epoch4, step773]: loss 10.144575
[epoch4, step774]: loss 5.918479
[epoch4, step775]: loss 4.519093
[epoch4, step776]: loss 3.903433
[epoch4, step777]: loss 4.612193
[epoch4, step778]: loss 22.150164
[epoch4, step779]: loss 29.836241
[epoch4, step780]: loss 21.393316
[epoch4, step781]: loss 2.753951
[epoch4, step782]: loss 19.900463
[epoch4, step783]: loss 2.800200
[epoch4, step784]: loss 19.450190
[epoch4, step785]: loss 3.531053
[epoch4, step786]: loss 29.628363
[epoch4, step787]: loss 3.518635
[epoch4, step788]: loss 5.477946
[epoch4, step789]: loss 13.895138
[epoch4, step790]: loss 4.498260
[epoch4, step791]: loss 4.463644
[epoch4, step792]: loss 2.819222
[epoch4, step793]: loss 12.972499
[epoch4, step794]: loss 3.416994
[epoch4, step795]: loss 23.163605
[epoch4, step796]: loss 15.833119
[epoch4, step797]: loss 3.915717
[epoch4, step798]: loss 2.654792
[epoch4, step799]: loss 13.611341
[epoch4, step800]: loss 2.537854
[epoch4, step801]: loss 2.394044
[epoch4, step802]: loss 2.990503
[epoch4, step803]: loss 4.609301
[epoch4, step804]: loss 9.111700
[epoch4, step805]: loss 24.667925
[epoch4, step806]: loss 10.841801
[epoch4, step807]: loss 9.028874
[epoch4, step808]: loss 2.004922
[epoch4, step809]: loss 15.112570
[epoch4, step810]: loss 21.028788
[epoch4, step811]: loss 2.380221
[epoch4, step812]: loss 5.751553
[epoch4, step813]: loss 7.990355
[epoch4, step814]: loss 4.024922
[epoch4, step815]: loss 15.700788
[epoch4, step816]: loss 3.018838
[epoch4, step817]: loss 4.847444
[epoch4, step818]: loss 9.527418
[epoch4, step819]: loss 14.283090
[epoch4, step820]: loss 8.241124
[epoch4, step821]: loss 4.220884
[epoch4, step822]: loss 5.108641
[epoch4, step823]: loss 31.683136
[epoch4, step824]: loss 4.742989
[epoch4, step825]: loss 20.725937
[epoch4, step826]: loss 28.215250
[epoch4, step827]: loss 17.335087
[epoch4, step828]: loss 28.208229
[epoch4, step829]: loss 6.961124
[epoch4, step830]: loss 3.710235
[epoch4, step831]: loss 14.484768
[epoch4, step832]: loss 39.836506
[epoch4, step833]: loss 4.256656
[epoch4, step834]: loss 34.226810
[epoch4, step835]: loss 4.864165
[epoch4, step836]: loss 10.877324
[epoch4, step837]: loss 3.152627
[epoch4, step838]: loss 3.452336
[epoch4, step839]: loss 4.989094
[epoch4, step840]: loss 16.357697
[epoch4, step841]: loss 20.432444
[epoch4, step842]: loss 30.430811
[epoch4, step843]: loss 10.268510
[epoch4, step844]: loss 2.771497
[epoch4, step845]: loss 5.948207
[epoch4, step846]: loss 2.578708
[epoch4, step847]: loss 2.821898
[epoch4, step848]: loss 4.579000
[epoch4, step849]: loss 4.464436
[epoch4, step850]: loss 3.605988
[epoch4, step851]: loss 29.841328
[epoch4, step852]: loss 19.984318
[epoch4, step853]: loss 3.370955
[epoch4, step854]: loss 19.525238
[epoch4, step855]: loss 3.044694
[epoch4, step856]: loss 11.110300
[epoch4, step857]: loss 36.222988
[epoch4, step858]: loss 4.113046
[epoch4, step859]: loss 12.519914
[epoch4, step860]: loss 4.956816
[epoch4, step861]: loss 10.798910
[epoch4, step862]: loss 10.032026
[epoch4, step863]: loss 5.934329
[epoch4, step864]: loss 5.362195
[epoch4, step865]: loss 3.902979
[epoch4, step866]: loss 14.849214
[epoch4, step867]: loss 8.437071
[epoch4, step868]: loss 7.153402
[epoch4, step869]: loss 3.729916
[epoch4, step870]: loss 6.296094
[epoch4, step871]: loss 3.380681
[epoch4, step872]: loss 14.269783
[epoch4, step873]: loss 10.053416
[epoch4, step874]: loss 13.888318
[epoch4, step875]: loss 18.504927
[epoch4, step876]: loss 21.727467
[epoch4, step877]: loss 3.658669
[epoch4, step878]: loss 14.239558
[epoch4, step879]: loss 13.860860
[epoch4, step880]: loss 5.656184
[epoch4, step881]: loss 12.301714
[epoch4, step882]: loss 7.149531
[epoch4, step883]: loss 5.864972
[epoch4, step884]: loss 5.775299
[epoch4, step885]: loss 15.863868
[epoch4, step886]: loss 3.049182
[epoch4, step887]: loss 3.238608
[epoch4, step888]: loss 8.179236
[epoch4, step889]: loss 1.927979
[epoch4, step890]: loss 11.666137
[epoch4, step891]: loss 4.272486
[epoch4, step892]: loss 4.154856
[epoch4, step893]: loss 22.366365
[epoch4, step894]: loss 2.718118
[epoch4, step895]: loss 22.750122
[epoch4, step896]: loss 7.965805
[epoch4, step897]: loss 18.820303
[epoch4, step898]: loss 11.899809
[epoch4, step899]: loss 17.250711
[epoch4, step900]: loss 3.290950
[epoch4, step901]: loss 12.795557
[epoch4, step902]: loss 4.856585
[epoch4, step903]: loss 6.674778
[epoch4, step904]: loss 3.709469
[epoch4, step905]: loss 13.641665
[epoch4, step906]: loss 5.018402
[epoch4, step907]: loss 11.482625
[epoch4, step908]: loss 16.979698
[epoch4, step909]: loss 5.428048
[epoch4, step910]: loss 18.052141
[epoch4, step911]: loss 10.037733
[epoch4, step912]: loss 14.499725
[epoch4, step913]: loss 3.561780
[epoch4, step914]: loss 11.310621
[epoch4, step915]: loss 4.024031
[epoch4, step916]: loss 13.233430
[epoch4, step917]: loss 2.479147
[epoch4, step918]: loss 4.867129
[epoch4, step919]: loss 6.476790
[epoch4, step920]: loss 6.091649
[epoch4, step921]: loss 23.068222
[epoch4, step922]: loss 10.652361
[epoch4, step923]: loss 23.384726
[epoch4, step924]: loss 2.357865
[epoch4, step925]: loss 3.720523
[epoch4, step926]: loss 3.134698
[epoch4, step927]: loss 3.266156
[epoch4, step928]: loss 15.301211
[epoch4, step929]: loss 13.009878
[epoch4, step930]: loss 5.256754
[epoch4, step931]: loss 11.093477
[epoch4, step932]: loss 8.917604
[epoch4, step933]: loss 6.367477
[epoch4, step934]: loss 4.553763
[epoch4, step935]: loss 24.512051
[epoch4, step936]: loss 3.591580
[epoch4, step937]: loss 3.905534
[epoch4, step938]: loss 6.297351
[epoch4, step939]: loss 20.013870
[epoch4, step940]: loss 8.827130
[epoch4, step941]: loss 3.897881
[epoch4, step942]: loss 5.242315
[epoch4, step943]: loss 15.445666
[epoch4, step944]: loss 6.135493
[epoch4, step945]: loss 15.192301
[epoch4, step946]: loss 2.176363
[epoch4, step947]: loss 3.626858
[epoch4, step948]: loss 6.153946
[epoch4, step949]: loss 15.056730
[epoch4, step950]: loss 16.025932
[epoch4, step951]: loss 3.062738
[epoch4, step952]: loss 4.408245
[epoch4, step953]: loss 3.632241
[epoch4, step954]: loss 15.080984
[epoch4, step955]: loss 19.660906
[epoch4, step956]: loss 2.412021
[epoch4, step957]: loss 13.525918
[epoch4, step958]: loss 10.189024
[epoch4, step959]: loss 3.501482
[epoch4, step960]: loss 7.517763
[epoch4, step961]: loss 6.818159
[epoch4, step962]: loss 13.889196
[epoch4, step963]: loss 2.350740
[epoch4, step964]: loss 9.872910
[epoch4, step965]: loss 3.924678
[epoch4, step966]: loss 6.544216
[epoch4, step967]: loss 22.088638
[epoch4, step968]: loss 7.363608
[epoch4, step969]: loss 9.202250
[epoch4, step970]: loss 9.603690
[epoch4, step971]: loss 25.406248
[epoch4, step972]: loss 8.601078
[epoch4, step973]: loss 3.629376
[epoch4, step974]: loss 3.253394
[epoch4, step975]: loss 23.977798
[epoch4, step976]: loss 12.047863
[epoch4, step977]: loss 22.064047
[epoch4, step978]: loss 18.213448
[epoch4, step979]: loss 5.657318
[epoch4, step980]: loss 6.499093
[epoch4, step981]: loss 12.890803
[epoch4, step982]: loss 3.555370
[epoch4, step983]: loss 3.644564
[epoch4, step984]: loss 3.552757
[epoch4, step985]: loss 6.274816
[epoch4, step986]: loss 31.182388
[epoch4, step987]: loss 23.424681
[epoch4, step988]: loss 8.826567
[epoch4, step989]: loss 3.849687
[epoch4, step990]: loss 6.246892
[epoch4, step991]: loss 11.725636
[epoch4, step992]: loss 22.937775
[epoch4, step993]: loss 16.419727
[epoch4, step994]: loss 4.447361
[epoch4, step995]: loss 2.910250
[epoch4, step996]: loss 9.436291
[epoch4, step997]: loss 3.156494
[epoch4, step998]: loss 11.170607
[epoch4, step999]: loss 12.475308
[epoch4, step1000]: loss 4.842638
[epoch4, step1001]: loss 3.714128
[epoch4, step1002]: loss 14.408780
[epoch4, step1003]: loss 4.260754
[epoch4, step1004]: loss 24.009487
[epoch4, step1005]: loss 20.237968
[epoch4, step1006]: loss 8.152136
[epoch4, step1007]: loss 4.832484
[epoch4, step1008]: loss 9.154802
[epoch4, step1009]: loss 9.666336
[epoch4, step1010]: loss 6.808824
[epoch4, step1011]: loss 2.462984
[epoch4, step1012]: loss 3.565311
[epoch4, step1013]: loss 10.962543
[epoch4, step1014]: loss 2.519633
[epoch4, step1015]: loss 2.680054
[epoch4, step1016]: loss 18.851395
[epoch4, step1017]: loss 5.173138
[epoch4, step1018]: loss 31.292336
[epoch4, step1019]: loss 13.580203
[epoch4, step1020]: loss 18.820162
[epoch4, step1021]: loss 20.575979
[epoch4, step1022]: loss 2.682743
[epoch4, step1023]: loss 10.818378
[epoch4, step1024]: loss 2.773132
[epoch4, step1025]: loss 19.842030
[epoch4, step1026]: loss 8.717725
[epoch4, step1027]: loss 3.826096
[epoch4, step1028]: loss 9.294684
[epoch4, step1029]: loss 12.357916
[epoch4, step1030]: loss 9.223502
[epoch4, step1031]: loss 18.980055
[epoch4, step1032]: loss 18.525146
[epoch4, step1033]: loss 8.456170
[epoch4, step1034]: loss 2.766599
[epoch4, step1035]: loss 2.947814
[epoch4, step1036]: loss 20.693060
[epoch4, step1037]: loss 6.824543
[epoch4, step1038]: loss 20.622793
[epoch4, step1039]: loss 5.279534
[epoch4, step1040]: loss 4.422857
[epoch4, step1041]: loss 4.407114
[epoch4, step1042]: loss 3.456800
[epoch4, step1043]: loss 8.628392
[epoch4, step1044]: loss 4.522030
[epoch4, step1045]: loss 2.450340
[epoch4, step1046]: loss 5.232625
[epoch4, step1047]: loss 15.556561
[epoch4, step1048]: loss 33.473351
[epoch4, step1049]: loss 9.269519
[epoch4, step1050]: loss 2.615065
[epoch4, step1051]: loss 13.354143
[epoch4, step1052]: loss 9.675756
[epoch4, step1053]: loss 19.079144
[epoch4, step1054]: loss 6.161913
[epoch4, step1055]: loss 22.712576
[epoch4, step1056]: loss 3.711099
[epoch4, step1057]: loss 16.132481
[epoch4, step1058]: loss 5.266703
[epoch4, step1059]: loss 5.144323
[epoch4, step1060]: loss 3.161135
[epoch4, step1061]: loss 3.756045
[epoch4, step1062]: loss 5.123563
[epoch4, step1063]: loss 4.237708
[epoch4, step1064]: loss 2.551591
[epoch4, step1065]: loss 5.174889
[epoch4, step1066]: loss 5.358621
[epoch4, step1067]: loss 21.567293
[epoch4, step1068]: loss 3.935449
[epoch4, step1069]: loss 18.961554
[epoch4, step1070]: loss 4.288729
[epoch4, step1071]: loss 13.819965
[epoch4, step1072]: loss 11.249330
[epoch4, step1073]: loss 3.391248
[epoch4, step1074]: loss 4.993888
[epoch4, step1075]: loss 42.870758
[epoch4, step1076]: loss 4.292612
[epoch4, step1077]: loss 1.774897
[epoch4, step1078]: loss 3.344939
[epoch4, step1079]: loss 9.335328
[epoch4, step1080]: loss 5.134964
[epoch4, step1081]: loss 5.695817
[epoch4, step1082]: loss 15.003450
[epoch4, step1083]: loss 3.778792
[epoch4, step1084]: loss 2.124337
[epoch4, step1085]: loss 2.777386
[epoch4, step1086]: loss 4.749000
[epoch4, step1087]: loss 3.380104
[epoch4, step1088]: loss 21.947470
[epoch4, step1089]: loss 25.050489
[epoch4, step1090]: loss 8.218092
[epoch4, step1091]: loss 21.379419
[epoch4, step1092]: loss 2.527413
[epoch4, step1093]: loss 8.491046
[epoch4, step1094]: loss 23.224573
[epoch4, step1095]: loss 2.864030
[epoch4, step1096]: loss 7.608096
[epoch4, step1097]: loss 12.316596
[epoch4, step1098]: loss 3.253535
[epoch4, step1099]: loss 20.601936
[epoch4, step1100]: loss 4.866454
[epoch4, step1101]: loss 12.941426
[epoch4, step1102]: loss 5.802584
[epoch4, step1103]: loss 2.383213
[epoch4, step1104]: loss 10.475443
[epoch4, step1105]: loss 4.210293
[epoch4, step1106]: loss 17.312775
[epoch4, step1107]: loss 6.763090
[epoch4, step1108]: loss 20.364513
[epoch4, step1109]: loss 5.861714
[epoch4, step1110]: loss 5.211777
[epoch4, step1111]: loss 10.910714
[epoch4, step1112]: loss 4.622406
[epoch4, step1113]: loss 3.004167
[epoch4, step1114]: loss 4.672831
[epoch4, step1115]: loss 36.362144
[epoch4, step1116]: loss 3.215723
[epoch4, step1117]: loss 7.250159
[epoch4, step1118]: loss 4.641624
[epoch4, step1119]: loss 4.654768
[epoch4, step1120]: loss 3.107689
[epoch4, step1121]: loss 4.587206
[epoch4, step1122]: loss 2.444457
[epoch4, step1123]: loss 2.444049
[epoch4, step1124]: loss 15.159642
[epoch4, step1125]: loss 23.676355
[epoch4, step1126]: loss 15.316169
[epoch4, step1127]: loss 5.451885
[epoch4, step1128]: loss 20.879808
[epoch4, step1129]: loss 1.924607
[epoch4, step1130]: loss 2.799282
[epoch4, step1131]: loss 6.243959
[epoch4, step1132]: loss 3.964534
[epoch4, step1133]: loss 24.635241
[epoch4, step1134]: loss 9.254311
[epoch4, step1135]: loss 2.892359
[epoch4, step1136]: loss 2.358538
[epoch4, step1137]: loss 2.524300
[epoch4, step1138]: loss 3.570497
[epoch4, step1139]: loss 11.032862
[epoch4, step1140]: loss 5.711263
[epoch4, step1141]: loss 18.846201
[epoch4, step1142]: loss 26.565517
[epoch4, step1143]: loss 4.639030
[epoch4, step1144]: loss 4.310597
[epoch4, step1145]: loss 4.126938
[epoch4, step1146]: loss 14.012885
[epoch4, step1147]: loss 4.538240
[epoch4, step1148]: loss 4.367879
[epoch4, step1149]: loss 22.923445
[epoch4, step1150]: loss 4.226096
[epoch4, step1151]: loss 13.527989
[epoch4, step1152]: loss 12.484704
[epoch4, step1153]: loss 5.265099
[epoch4, step1154]: loss 2.641560
[epoch4, step1155]: loss 6.438842
[epoch4, step1156]: loss 3.857271
[epoch4, step1157]: loss 2.749206
[epoch4, step1158]: loss 3.668689
[epoch4, step1159]: loss 3.422529
[epoch4, step1160]: loss 20.212950
[epoch4, step1161]: loss 11.849730
[epoch4, step1162]: loss 5.312244
[epoch4, step1163]: loss 10.405193
[epoch4, step1164]: loss 5.832742
[epoch4, step1165]: loss 3.326563
[epoch4, step1166]: loss 23.995747
[epoch4, step1167]: loss 15.436515
[epoch4, step1168]: loss 23.705446
[epoch4, step1169]: loss 21.254389
[epoch4, step1170]: loss 7.945971
[epoch4, step1171]: loss 12.644557
[epoch4, step1172]: loss 11.685061
[epoch4, step1173]: loss 4.051263
[epoch4, step1174]: loss 13.075188
[epoch4, step1175]: loss 4.301645
[epoch4, step1176]: loss 12.169494
[epoch4, step1177]: loss 8.988077
[epoch4, step1178]: loss 16.396782
[epoch4, step1179]: loss 4.675433
[epoch4, step1180]: loss 11.304588
[epoch4, step1181]: loss 3.926842
[epoch4, step1182]: loss 5.281106
[epoch4, step1183]: loss 10.433777
[epoch4, step1184]: loss 1.541397
[epoch4, step1185]: loss 20.852680
[epoch4, step1186]: loss 23.257156
[epoch4, step1187]: loss 16.600872
[epoch4, step1188]: loss 11.386844
[epoch4, step1189]: loss 10.022913
[epoch4, step1190]: loss 11.457105
[epoch4, step1191]: loss 3.050860
[epoch4, step1192]: loss 3.123010
[epoch4, step1193]: loss 21.607294
[epoch4, step1194]: loss 11.549797
[epoch4, step1195]: loss 7.912179
[epoch4, step1196]: loss 18.739407
[epoch4, step1197]: loss 13.216889
[epoch4, step1198]: loss 9.797301
[epoch4, step1199]: loss 1.966651
[epoch4, step1200]: loss 2.920141
[epoch4, step1201]: loss 29.836000
[epoch4, step1202]: loss 2.915999
[epoch4, step1203]: loss 2.607386
[epoch4, step1204]: loss 4.004126
[epoch4, step1205]: loss 11.460799
[epoch4, step1206]: loss 11.103240
[epoch4, step1207]: loss 16.516306
[epoch4, step1208]: loss 4.900517
[epoch4, step1209]: loss 2.347113
[epoch4, step1210]: loss 5.293235
[epoch4, step1211]: loss 3.203978
[epoch4, step1212]: loss 21.770330
[epoch4, step1213]: loss 7.926947
[epoch4, step1214]: loss 10.590059
[epoch4, step1215]: loss 28.815527
[epoch4, step1216]: loss 4.307391
[epoch4, step1217]: loss 5.821605
[epoch4, step1218]: loss 3.488885
[epoch4, step1219]: loss 10.903533
[epoch4, step1220]: loss 2.877613
[epoch4, step1221]: loss 2.856415
[epoch4, step1222]: loss 9.448620
[epoch4, step1223]: loss 7.558967
[epoch4, step1224]: loss 20.223150
[epoch4, step1225]: loss 8.951243
[epoch4, step1226]: loss 2.541869
[epoch4, step1227]: loss 6.168278
[epoch4, step1228]: loss 23.996122
[epoch4, step1229]: loss 3.679808
[epoch4, step1230]: loss 10.573943
[epoch4, step1231]: loss 5.168398
[epoch4, step1232]: loss 2.284502
[epoch4, step1233]: loss 3.244178
[epoch4, step1234]: loss 6.025865
[epoch4, step1235]: loss 5.575152
[epoch4, step1236]: loss 2.361887
[epoch4, step1237]: loss 4.181263
[epoch4, step1238]: loss 8.619449
[epoch4, step1239]: loss 24.016369
[epoch4, step1240]: loss 9.374103
[epoch4, step1241]: loss 9.955823
[epoch4, step1242]: loss 2.888351
[epoch4, step1243]: loss 2.765854
[epoch4, step1244]: loss 2.705273
[epoch4, step1245]: loss 5.121787
[epoch4, step1246]: loss 3.020678
[epoch4, step1247]: loss 5.964584
[epoch4, step1248]: loss 10.209578
[epoch4, step1249]: loss 3.332765
[epoch4, step1250]: loss 3.241191
[epoch4, step1251]: loss 2.536180
[epoch4, step1252]: loss 13.695247
[epoch4, step1253]: loss 12.494608
[epoch4, step1254]: loss 3.045977
[epoch4, step1255]: loss 8.637716
[epoch4, step1256]: loss 9.689702
[epoch4, step1257]: loss 4.737489
[epoch4, step1258]: loss 11.359175
[epoch4, step1259]: loss 10.175389
[epoch4, step1260]: loss 5.661034
[epoch4, step1261]: loss 3.064416
[epoch4, step1262]: loss 3.499417
[epoch4, step1263]: loss 8.793767
[epoch4, step1264]: loss 9.700971
[epoch4, step1265]: loss 10.544906
[epoch4, step1266]: loss 7.254363
[epoch4, step1267]: loss 14.980119
[epoch4, step1268]: loss 14.846938
[epoch4, step1269]: loss 2.829463
[epoch4, step1270]: loss 3.744051
[epoch4, step1271]: loss 28.957947
[epoch4, step1272]: loss 8.234898
[epoch4, step1273]: loss 3.508306
[epoch4, step1274]: loss 18.225208
[epoch4, step1275]: loss 11.436120
[epoch4, step1276]: loss 22.347872
[epoch4, step1277]: loss 12.434500
[epoch4, step1278]: loss 9.973068
[epoch4, step1279]: loss 13.385296
[epoch4, step1280]: loss 37.702755
[epoch4, step1281]: loss 18.175276
[epoch4, step1282]: loss 8.224315
[epoch4, step1283]: loss 13.634192
[epoch4, step1284]: loss 8.200511
[epoch4, step1285]: loss 3.858135
[epoch4, step1286]: loss 4.756044
[epoch4, step1287]: loss 22.361816
[epoch4, step1288]: loss 5.537807
[epoch4, step1289]: loss 24.501575
[epoch4, step1290]: loss 3.088221
[epoch4, step1291]: loss 10.147350
[epoch4, step1292]: loss 28.730770
[epoch4, step1293]: loss 9.503186
[epoch4, step1294]: loss 2.543450
[epoch4, step1295]: loss 11.771279
[epoch4, step1296]: loss 3.076812
[epoch4, step1297]: loss 11.715447
[epoch4, step1298]: loss 4.716080
[epoch4, step1299]: loss 8.283610
[epoch4, step1300]: loss 5.885138
[epoch4, step1301]: loss 2.635261
[epoch4, step1302]: loss 12.223192
[epoch4, step1303]: loss 4.577206
[epoch4, step1304]: loss 2.725057
[epoch4, step1305]: loss 9.511743
[epoch4, step1306]: loss 12.791473
[epoch4, step1307]: loss 2.431828
[epoch4, step1308]: loss 2.983755
[epoch4, step1309]: loss 15.431142
[epoch4, step1310]: loss 14.250353
[epoch4, step1311]: loss 8.942655
[epoch4, step1312]: loss 2.321883
[epoch4, step1313]: loss 16.928087
[epoch4, step1314]: loss 17.529573
[epoch4, step1315]: loss 14.150534
[epoch4, step1316]: loss 4.945135
[epoch4, step1317]: loss 2.193561
[epoch4, step1318]: loss 10.831767
[epoch4, step1319]: loss 5.399859
[epoch4, step1320]: loss 3.762219
[epoch4, step1321]: loss 7.242877
[epoch4, step1322]: loss 8.992823
[epoch4, step1323]: loss 12.638840
[epoch4, step1324]: loss 13.475839
[epoch4, step1325]: loss 14.543231
[epoch4, step1326]: loss 11.186394
[epoch4, step1327]: loss 15.378481
[epoch4, step1328]: loss 4.005832
[epoch4, step1329]: loss 7.487843
[epoch4, step1330]: loss 3.163878
[epoch4, step1331]: loss 8.174202
[epoch4, step1332]: loss 2.442669
[epoch4, step1333]: loss 11.792521
[epoch4, step1334]: loss 3.728245
[epoch4, step1335]: loss 2.732091
[epoch4, step1336]: loss 11.706697
[epoch4, step1337]: loss 2.905402
[epoch4, step1338]: loss 4.914666
[epoch4, step1339]: loss 2.702777
[epoch4, step1340]: loss 2.153985
[epoch4, step1341]: loss 3.068599
[epoch4, step1342]: loss 5.437682
[epoch4, step1343]: loss 3.037148
[epoch4, step1344]: loss 3.542520
[epoch4, step1345]: loss 14.558157
[epoch4, step1346]: loss 16.435690
[epoch4, step1347]: loss 3.588867
[epoch4, step1348]: loss 12.559112
[epoch4, step1349]: loss 8.511891
[epoch4, step1350]: loss 18.400768
[epoch4, step1351]: loss 41.670246
[epoch4, step1352]: loss 18.072195
[epoch4, step1353]: loss 14.281718
[epoch4, step1354]: loss 8.362248
[epoch4, step1355]: loss 31.241436
[epoch4, step1356]: loss 26.415512
[epoch4, step1357]: loss 3.143946
[epoch4, step1358]: loss 6.362950
[epoch4, step1359]: loss 4.062521
[epoch4, step1360]: loss 5.213704
[epoch4, step1361]: loss 32.659721
[epoch4, step1362]: loss 17.005646
[epoch4, step1363]: loss 12.426442
[epoch4, step1364]: loss 4.470528
[epoch4, step1365]: loss 3.477050
[epoch4, step1366]: loss 6.578902
[epoch4, step1367]: loss 17.860956
[epoch4, step1368]: loss 2.241894
[epoch4, step1369]: loss 4.705705
[epoch4, step1370]: loss 10.730412
[epoch4, step1371]: loss 21.688341
[epoch4, step1372]: loss 3.602983
[epoch4, step1373]: loss 2.755218
[epoch4, step1374]: loss 12.251455
[epoch4, step1375]: loss 11.459030
[epoch4, step1376]: loss 7.605842
[epoch4, step1377]: loss 11.990523
[epoch4, step1378]: loss 14.817020
[epoch4, step1379]: loss 15.810942
[epoch4, step1380]: loss 9.172949
[epoch4, step1381]: loss 4.401575
[epoch4, step1382]: loss 8.626254
[epoch4, step1383]: loss 9.593080
[epoch4, step1384]: loss 9.206489
[epoch4, step1385]: loss 18.973146
[epoch4, step1386]: loss 2.624622
[epoch4, step1387]: loss 21.739372
[epoch4, step1388]: loss 40.777603
[epoch4, step1389]: loss 4.835025
[epoch4, step1390]: loss 10.333173
[epoch4, step1391]: loss 9.832141
[epoch4, step1392]: loss 3.469434
[epoch4, step1393]: loss 8.026591
[epoch4, step1394]: loss 2.401014
[epoch4, step1395]: loss 5.862925
[epoch4, step1396]: loss 4.066422
[epoch4, step1397]: loss 4.381392
[epoch4, step1398]: loss 7.293114
[epoch4, step1399]: loss 3.153685
[epoch4, step1400]: loss 17.029524
[epoch4, step1401]: loss 17.448502
[epoch4, step1402]: loss 32.212051
[epoch4, step1403]: loss 8.748854
[epoch4, step1404]: loss 9.701935
[epoch4, step1405]: loss 10.834129
[epoch4, step1406]: loss 14.224947
[epoch4, step1407]: loss 3.974500
[epoch4, step1408]: loss 3.212181
[epoch4, step1409]: loss 12.879568
[epoch4, step1410]: loss 2.830110
[epoch4, step1411]: loss 14.307389
[epoch4, step1412]: loss 4.581837
[epoch4, step1413]: loss 4.128695
[epoch4, step1414]: loss 5.004254
[epoch4, step1415]: loss 12.775682
[epoch4, step1416]: loss 13.772280
[epoch4, step1417]: loss 16.508739
[epoch4, step1418]: loss 3.953936
[epoch4, step1419]: loss 16.875397
[epoch4, step1420]: loss 3.654582
[epoch4, step1421]: loss 18.943447
[epoch4, step1422]: loss 10.429807
[epoch4, step1423]: loss 3.506237
[epoch4, step1424]: loss 3.737485
[epoch4, step1425]: loss 3.360079
[epoch4, step1426]: loss 5.983934
[epoch4, step1427]: loss 17.346191
[epoch4, step1428]: loss 16.842222
[epoch4, step1429]: loss 11.093095
[epoch4, step1430]: loss 10.301229
[epoch4, step1431]: loss 33.109673
[epoch4, step1432]: loss 3.451811
[epoch4, step1433]: loss 5.657013
[epoch4, step1434]: loss 5.256534
[epoch4, step1435]: loss 23.980543
[epoch4, step1436]: loss 3.297501
[epoch4, step1437]: loss 8.992968
[epoch4, step1438]: loss 2.747994
[epoch4, step1439]: loss 5.744905
[epoch4, step1440]: loss 18.484745
[epoch4, step1441]: loss 11.001216
[epoch4, step1442]: loss 4.967821
[epoch4, step1443]: loss 4.498329
[epoch4, step1444]: loss 4.349023
[epoch4, step1445]: loss 4.620190
[epoch4, step1446]: loss 2.685458
[epoch4, step1447]: loss 13.500558
[epoch4, step1448]: loss 3.825161
[epoch4, step1449]: loss 7.368841
[epoch4, step1450]: loss 4.207162
[epoch4, step1451]: loss 10.014065
[epoch4, step1452]: loss 14.956808
[epoch4, step1453]: loss 4.532321
[epoch4, step1454]: loss 5.830272
[epoch4, step1455]: loss 2.743653
[epoch4, step1456]: loss 16.491734
[epoch4, step1457]: loss 21.735325
[epoch4, step1458]: loss 4.076647
[epoch4, step1459]: loss 10.332681
[epoch4, step1460]: loss 14.661683
[epoch4, step1461]: loss 2.363042
[epoch4, step1462]: loss 4.398351
[epoch4, step1463]: loss 2.972117
[epoch4, step1464]: loss 10.694871
[epoch4, step1465]: loss 34.018665
[epoch4, step1466]: loss 18.384464
[epoch4, step1467]: loss 3.606724
[epoch4, step1468]: loss 12.868690
[epoch4, step1469]: loss 2.140289
[epoch4, step1470]: loss 10.440582
[epoch4, step1471]: loss 2.503907
[epoch4, step1472]: loss 5.537730
[epoch4, step1473]: loss 10.600245
[epoch4, step1474]: loss 5.696747
[epoch4, step1475]: loss 2.229103
[epoch4, step1476]: loss 26.029305
[epoch4, step1477]: loss 5.618832
[epoch4, step1478]: loss 3.895982
[epoch4, step1479]: loss 4.045767
[epoch4, step1480]: loss 2.560226
[epoch4, step1481]: loss 5.966720
[epoch4, step1482]: loss 4.857425
[epoch4, step1483]: loss 2.092253
[epoch4, step1484]: loss 11.179885
[epoch4, step1485]: loss 1.774764
[epoch4, step1486]: loss 5.342168
[epoch4, step1487]: loss 2.507652
[epoch4, step1488]: loss 22.047029
[epoch4, step1489]: loss 28.788105
[epoch4, step1490]: loss 5.712388
[epoch4, step1491]: loss 4.193380
[epoch4, step1492]: loss 18.618658
[epoch4, step1493]: loss 3.844009
[epoch4, step1494]: loss 10.797619
[epoch4, step1495]: loss 3.508889
[epoch4, step1496]: loss 18.443855
[epoch4, step1497]: loss 14.187233
[epoch4, step1498]: loss 1.276271
[epoch4, step1499]: loss 12.880372
[epoch4, step1500]: loss 5.381135
[epoch4, step1501]: loss 2.788017
[epoch4, step1502]: loss 3.349326
[epoch4, step1503]: loss 12.894779
[epoch4, step1504]: loss 27.935646
[epoch4, step1505]: loss 11.794228
[epoch4, step1506]: loss 3.494057
[epoch4, step1507]: loss 10.291653
[epoch4, step1508]: loss 4.524201
[epoch4, step1509]: loss 2.220762
[epoch4, step1510]: loss 4.498560
[epoch4, step1511]: loss 31.734314
[epoch4, step1512]: loss 31.293453
[epoch4, step1513]: loss 14.463383
[epoch4, step1514]: loss 15.105662
[epoch4, step1515]: loss 3.870763
[epoch4, step1516]: loss 5.324469
[epoch4, step1517]: loss 7.171533
[epoch4, step1518]: loss 22.982153
[epoch4, step1519]: loss 4.946333
[epoch4, step1520]: loss 11.356437
[epoch4, step1521]: loss 12.272614
[epoch4, step1522]: loss 20.036270
[epoch4, step1523]: loss 20.125937
[epoch4, step1524]: loss 9.556697
[epoch4, step1525]: loss 2.588893
[epoch4, step1526]: loss 4.933710
[epoch4, step1527]: loss 13.573454
[epoch4, step1528]: loss 2.720697
[epoch4, step1529]: loss 1.451366
[epoch4, step1530]: loss 25.154757
[epoch4, step1531]: loss 12.120898
[epoch4, step1532]: loss 7.986114
[epoch4, step1533]: loss 5.708961
[epoch4, step1534]: loss 11.205194
[epoch4, step1535]: loss 2.726754
[epoch4, step1536]: loss 2.853732
[epoch4, step1537]: loss 17.015583
[epoch4, step1538]: loss 21.051998
[epoch4, step1539]: loss 21.275166
[epoch4, step1540]: loss 11.868123
[epoch4, step1541]: loss 5.416783
[epoch4, step1542]: loss 16.624918
[epoch4, step1543]: loss 12.226554
[epoch4, step1544]: loss 27.299183
[epoch4, step1545]: loss 22.566277
[epoch4, step1546]: loss 11.594821
[epoch4, step1547]: loss 7.122119
[epoch4, step1548]: loss 2.896223
[epoch4, step1549]: loss 30.684406
[epoch4, step1550]: loss 3.968617
[epoch4, step1551]: loss 3.436750
[epoch4, step1552]: loss 23.306860
[epoch4, step1553]: loss 10.539449
[epoch4, step1554]: loss 8.035165
[epoch4, step1555]: loss 3.353912
[epoch4, step1556]: loss 2.509589
[epoch4, step1557]: loss 20.027323
[epoch4, step1558]: loss 13.803593
[epoch4, step1559]: loss 29.596699
[epoch4, step1560]: loss 10.557446
[epoch4, step1561]: loss 10.282447
[epoch4, step1562]: loss 4.599530
[epoch4, step1563]: loss 3.549931
[epoch4, step1564]: loss 4.534095
[epoch4, step1565]: loss 33.822487
[epoch4, step1566]: loss 4.182890
[epoch4, step1567]: loss 4.891264
[epoch4, step1568]: loss 14.871489
[epoch4, step1569]: loss 10.470395
[epoch4, step1570]: loss 3.188742
[epoch4, step1571]: loss 10.602241
[epoch4, step1572]: loss 4.186337
[epoch4, step1573]: loss 12.090019
[epoch4, step1574]: loss 2.188254
[epoch4, step1575]: loss 24.124556
[epoch4, step1576]: loss 3.173059
[epoch4, step1577]: loss 4.572879
[epoch4, step1578]: loss 7.657245
[epoch4, step1579]: loss 26.058451
[epoch4, step1580]: loss 13.281484
[epoch4, step1581]: loss 14.043046
[epoch4, step1582]: loss 3.216027
[epoch4, step1583]: loss 8.699366
[epoch4, step1584]: loss 12.827722
[epoch4, step1585]: loss 18.229151
[epoch4, step1586]: loss 2.438912
[epoch4, step1587]: loss 4.011163
[epoch4, step1588]: loss 3.292610
[epoch4, step1589]: loss 10.366185
[epoch4, step1590]: loss 4.033107
[epoch4, step1591]: loss 14.981543
[epoch4, step1592]: loss 9.876194
[epoch4, step1593]: loss 3.868621
[epoch4, step1594]: loss 29.823402
[epoch4, step1595]: loss 6.348707
[epoch4, step1596]: loss 3.401762
[epoch4, step1597]: loss 12.890049
[epoch4, step1598]: loss 1.511091
[epoch4, step1599]: loss 5.540707
[epoch4, step1600]: loss 11.887256
[epoch4, step1601]: loss 17.538313
[epoch4, step1602]: loss 8.145780
[epoch4, step1603]: loss 10.080383
[epoch4, step1604]: loss 3.331214
[epoch4, step1605]: loss 2.544665
[epoch4, step1606]: loss 24.567486
[epoch4, step1607]: loss 7.790218
[epoch4, step1608]: loss 5.834434
[epoch4, step1609]: loss 3.823266
[epoch4, step1610]: loss 7.454362
[epoch4, step1611]: loss 5.401415
[epoch4, step1612]: loss 10.363644
[epoch4, step1613]: loss 2.758610
[epoch4, step1614]: loss 6.549725
[epoch4, step1615]: loss 2.611195
[epoch4, step1616]: loss 22.141527
[epoch4, step1617]: loss 6.968291
[epoch4, step1618]: loss 8.943481
[epoch4, step1619]: loss 3.017476
[epoch4, step1620]: loss 3.238438
[epoch4, step1621]: loss 3.896879
[epoch4, step1622]: loss 4.070785
[epoch4, step1623]: loss 16.274590
[epoch4, step1624]: loss 26.047068
[epoch4, step1625]: loss 3.302012
[epoch4, step1626]: loss 8.698568
[epoch4, step1627]: loss 10.644938
[epoch4, step1628]: loss 13.111792
[epoch4, step1629]: loss 1.822416
[epoch4, step1630]: loss 11.032078
[epoch4, step1631]: loss 2.259429
[epoch4, step1632]: loss 13.741862
[epoch4, step1633]: loss 7.134879
[epoch4, step1634]: loss 5.318616
[epoch4, step1635]: loss 4.863422
[epoch4, step1636]: loss 3.564288
[epoch4, step1637]: loss 6.599432
[epoch4, step1638]: loss 5.307708
[epoch4, step1639]: loss 13.588786
[epoch4, step1640]: loss 27.423504
[epoch4, step1641]: loss 4.811852
[epoch4, step1642]: loss 10.341555
[epoch4, step1643]: loss 16.154253
[epoch4, step1644]: loss 3.399926
[epoch4, step1645]: loss 3.176822
[epoch4, step1646]: loss 3.819016
[epoch4, step1647]: loss 11.115682
[epoch4, step1648]: loss 2.620043
[epoch4, step1649]: loss 5.809214
[epoch4, step1650]: loss 20.447557
[epoch4, step1651]: loss 19.635036
[epoch4, step1652]: loss 5.843681
[epoch4, step1653]: loss 4.143990
[epoch4, step1654]: loss 4.697779
[epoch4, step1655]: loss 9.764787
[epoch4, step1656]: loss 3.885727
[epoch4, step1657]: loss 3.843452
[epoch4, step1658]: loss 6.673065
[epoch4, step1659]: loss 3.744177
[epoch4, step1660]: loss 19.139275
[epoch4, step1661]: loss 3.726187
[epoch4, step1662]: loss 2.783394
[epoch4, step1663]: loss 10.993816
[epoch4, step1664]: loss 5.887281
[epoch4, step1665]: loss 9.382880
[epoch4, step1666]: loss 25.838963
[epoch4, step1667]: loss 16.494755
[epoch4, step1668]: loss 13.734538
[epoch4, step1669]: loss 7.589633
[epoch4, step1670]: loss 2.705695
[epoch4, step1671]: loss 1.928227
[epoch4, step1672]: loss 14.843396
[epoch4, step1673]: loss 3.882317
[epoch4, step1674]: loss 6.074807
[epoch4, step1675]: loss 8.987868
[epoch4, step1676]: loss 10.949677
[epoch4, step1677]: loss 11.655609
[epoch4, step1678]: loss 11.232398
[epoch4, step1679]: loss 23.714205
[epoch4, step1680]: loss 2.249616
[epoch4, step1681]: loss 22.070650
[epoch4, step1682]: loss 4.381246
[epoch4, step1683]: loss 14.951919
[epoch4, step1684]: loss 7.866917
[epoch4, step1685]: loss 15.967314
[epoch4, step1686]: loss 4.912698
[epoch4, step1687]: loss 3.522893
[epoch4, step1688]: loss 11.189182
[epoch4, step1689]: loss 5.236944
[epoch4, step1690]: loss 3.210579
[epoch4, step1691]: loss 3.625237
[epoch4, step1692]: loss 3.096422
[epoch4, step1693]: loss 3.348210
[epoch4, step1694]: loss 4.009767
[epoch4, step1695]: loss 4.478539
[epoch4, step1696]: loss 4.394763
[epoch4, step1697]: loss 3.751080
[epoch4, step1698]: loss 2.258620
[epoch4, step1699]: loss 5.064613
[epoch4, step1700]: loss 4.009511
[epoch4, step1701]: loss 7.296087
[epoch4, step1702]: loss 3.246619
[epoch4, step1703]: loss 9.389854
[epoch4, step1704]: loss 6.063540
[epoch4, step1705]: loss 10.770258
[epoch4, step1706]: loss 14.253866
[epoch4, step1707]: loss 17.146107
[epoch4, step1708]: loss 10.362433
[epoch4, step1709]: loss 10.155431
[epoch4, step1710]: loss 1.964438
[epoch4, step1711]: loss 3.522548
[epoch4, step1712]: loss 28.679768
[epoch4, step1713]: loss 4.685524
[epoch4, step1714]: loss 5.951950
[epoch4, step1715]: loss 23.221861
[epoch4, step1716]: loss 36.420418
[epoch4, step1717]: loss 9.911247
[epoch4, step1718]: loss 3.078683
[epoch4, step1719]: loss 20.243872
[epoch4, step1720]: loss 22.013279
[epoch4, step1721]: loss 5.246655
[epoch4, step1722]: loss 6.953460
[epoch4, step1723]: loss 12.037327
[epoch4, step1724]: loss 20.018190
[epoch4, step1725]: loss 6.787313
[epoch4, step1726]: loss 26.781029
[epoch4, step1727]: loss 10.154121
[epoch4, step1728]: loss 19.150177
[epoch4, step1729]: loss 4.271716
[epoch4, step1730]: loss 5.878192
[epoch4, step1731]: loss 4.276264
[epoch4, step1732]: loss 15.251401
[epoch4, step1733]: loss 2.451526
[epoch4, step1734]: loss 1.823425
[epoch4, step1735]: loss 13.211162
[epoch4, step1736]: loss 2.809203
[epoch4, step1737]: loss 6.755457
[epoch4, step1738]: loss 46.400108
[epoch4, step1739]: loss 2.520890
[epoch4, step1740]: loss 3.588404
[epoch4, step1741]: loss 3.991465
[epoch4, step1742]: loss 4.447599
[epoch4, step1743]: loss 8.647839
[epoch4, step1744]: loss 14.186419
[epoch4, step1745]: loss 11.302578
[epoch4, step1746]: loss 19.427383
[epoch4, step1747]: loss 31.337320
[epoch4, step1748]: loss 2.459663
[epoch4, step1749]: loss 16.099859
[epoch4, step1750]: loss 4.149163
[epoch4, step1751]: loss 11.407953
[epoch4, step1752]: loss 3.778293
[epoch4, step1753]: loss 10.560535
[epoch4, step1754]: loss 3.144078
[epoch4, step1755]: loss 4.632680
[epoch4, step1756]: loss 5.720192
[epoch4, step1757]: loss 11.845221
[epoch4, step1758]: loss 15.562167
[epoch4, step1759]: loss 21.578081
[epoch4, step1760]: loss 6.047321
[epoch4, step1761]: loss 6.235239
[epoch4, step1762]: loss 24.774199
[epoch4, step1763]: loss 11.466263
[epoch4, step1764]: loss 10.795880
[epoch4, step1765]: loss 30.035219
[epoch4, step1766]: loss 3.771837
[epoch4, step1767]: loss 6.636308
[epoch4, step1768]: loss 1.547219
[epoch4, step1769]: loss 3.035413
[epoch4, step1770]: loss 4.893724
[epoch4, step1771]: loss 8.896728
[epoch4, step1772]: loss 2.301905
[epoch4, step1773]: loss 4.804594
[epoch4, step1774]: loss 17.428785
[epoch4, step1775]: loss 22.740353
[epoch4, step1776]: loss 12.839797
[epoch4, step1777]: loss 20.008741
[epoch4, step1778]: loss 3.380482
[epoch4, step1779]: loss 11.834628
[epoch4, step1780]: loss 3.046752
[epoch4, step1781]: loss 18.026794
[epoch4, step1782]: loss 16.266218
[epoch4, step1783]: loss 14.431391
[epoch4, step1784]: loss 7.040635
[epoch4, step1785]: loss 6.812331
[epoch4, step1786]: loss 7.795998
[epoch4, step1787]: loss 23.679607
[epoch4, step1788]: loss 6.475208
[epoch4, step1789]: loss 10.639634
[epoch4, step1790]: loss 22.624722
[epoch4, step1791]: loss 14.303438
[epoch4, step1792]: loss 4.714880
[epoch4, step1793]: loss 10.210933
[epoch4, step1794]: loss 5.309471
[epoch4, step1795]: loss 8.944452
[epoch4, step1796]: loss 2.544703
[epoch4, step1797]: loss 10.084437
[epoch4, step1798]: loss 11.165450
[epoch4, step1799]: loss 3.161222
[epoch4, step1800]: loss 14.957270
[epoch4, step1801]: loss 2.550658
[epoch4, step1802]: loss 9.467629
[epoch4, step1803]: loss 9.998282
[epoch4, step1804]: loss 15.718764
[epoch4, step1805]: loss 10.857998
[epoch4, step1806]: loss 31.795036
[epoch4, step1807]: loss 10.339031
[epoch4, step1808]: loss 5.141006
[epoch4, step1809]: loss 13.516221
[epoch4, step1810]: loss 2.424753
[epoch4, step1811]: loss 15.163863
[epoch4, step1812]: loss 12.360465
[epoch4, step1813]: loss 4.138092
[epoch4, step1814]: loss 16.505638
[epoch4, step1815]: loss 10.273640
[epoch4, step1816]: loss 12.137776
[epoch4, step1817]: loss 23.212112
[epoch4, step1818]: loss 10.544149
[epoch4, step1819]: loss 17.272331
[epoch4, step1820]: loss 5.568224
[epoch4, step1821]: loss 3.746774
[epoch4, step1822]: loss 12.330210
[epoch4, step1823]: loss 2.804406
[epoch4, step1824]: loss 2.930415
[epoch4, step1825]: loss 15.760109
[epoch4, step1826]: loss 4.582951
[epoch4, step1827]: loss 16.378510
[epoch4, step1828]: loss 12.887712
[epoch4, step1829]: loss 10.482849
[epoch4, step1830]: loss 3.116518
[epoch4, step1831]: loss 3.865052
[epoch4, step1832]: loss 11.274926
[epoch4, step1833]: loss 5.338025
[epoch4, step1834]: loss 6.362844
[epoch4, step1835]: loss 24.728237
[epoch4, step1836]: loss 3.987677
[epoch4, step1837]: loss 4.504549
[epoch4, step1838]: loss 3.555984
[epoch4, step1839]: loss 1.879843
[epoch4, step1840]: loss 28.576096
[epoch4, step1841]: loss 2.998571
[epoch4, step1842]: loss 2.769936
[epoch4, step1843]: loss 11.945730
[epoch4, step1844]: loss 27.215879
[epoch4, step1845]: loss 6.533700
[epoch4, step1846]: loss 16.377331
[epoch4, step1847]: loss 6.351852
[epoch4, step1848]: loss 13.224036
[epoch4, step1849]: loss 10.823268
[epoch4, step1850]: loss 3.150391
[epoch4, step1851]: loss 12.279189
[epoch4, step1852]: loss 9.241673
[epoch4, step1853]: loss 6.292315
[epoch4, step1854]: loss 5.520804
[epoch4, step1855]: loss 3.706239
[epoch4, step1856]: loss 4.768961
[epoch4, step1857]: loss 2.139812
[epoch4, step1858]: loss 5.634613
[epoch4, step1859]: loss 6.730945
[epoch4, step1860]: loss 2.162118
[epoch4, step1861]: loss 10.840701
[epoch4, step1862]: loss 8.177092
[epoch4, step1863]: loss 23.815237
[epoch4, step1864]: loss 8.418791
[epoch4, step1865]: loss 2.792853
[epoch4, step1866]: loss 24.059093
[epoch4, step1867]: loss 11.445004
[epoch4, step1868]: loss 10.929919
[epoch4, step1869]: loss 20.827002
[epoch4, step1870]: loss 4.926650
[epoch4, step1871]: loss 2.158107
[epoch4, step1872]: loss 4.464820
[epoch4, step1873]: loss 4.756395
[epoch4, step1874]: loss 2.571795
[epoch4, step1875]: loss 20.461170
[epoch4, step1876]: loss 3.083341
[epoch4, step1877]: loss 3.299936
[epoch4, step1878]: loss 5.233207
[epoch4, step1879]: loss 7.382575
[epoch4, step1880]: loss 11.839726
[epoch4, step1881]: loss 16.220118
[epoch4, step1882]: loss 20.481373
[epoch4, step1883]: loss 12.347372
[epoch4, step1884]: loss 2.496418
[epoch4, step1885]: loss 4.190873
[epoch4, step1886]: loss 2.578579
[epoch4, step1887]: loss 27.606153
[epoch4, step1888]: loss 10.049026
[epoch4, step1889]: loss 16.139744
[epoch4, step1890]: loss 12.709458
[epoch4, step1891]: loss 9.413448
[epoch4, step1892]: loss 4.632290
[epoch4, step1893]: loss 4.357471
[epoch4, step1894]: loss 4.237741
[epoch4, step1895]: loss 2.418130
[epoch4, step1896]: loss 8.168600
[epoch4, step1897]: loss 4.920722
[epoch4, step1898]: loss 10.574291
[epoch4, step1899]: loss 13.495018
[epoch4, step1900]: loss 5.457823
[epoch4, step1901]: loss 19.429590
[epoch4, step1902]: loss 20.526793
[epoch4, step1903]: loss 22.053303
[epoch4, step1904]: loss 4.846190
[epoch4, step1905]: loss 3.559268
[epoch4, step1906]: loss 20.064608
[epoch4, step1907]: loss 2.858353
[epoch4, step1908]: loss 29.631655
[epoch4, step1909]: loss 8.806705
[epoch4, step1910]: loss 4.385237
[epoch4, step1911]: loss 1.722267
[epoch4, step1912]: loss 18.155073
[epoch4, step1913]: loss 11.157118
[epoch4, step1914]: loss 10.035475
[epoch4, step1915]: loss 3.824545
[epoch4, step1916]: loss 22.149199
[epoch4, step1917]: loss 11.737730
[epoch4, step1918]: loss 17.488947
[epoch4, step1919]: loss 2.652869
[epoch4, step1920]: loss 16.224985
[epoch4, step1921]: loss 3.458386
[epoch4, step1922]: loss 10.010932
[epoch4, step1923]: loss 3.041930
[epoch4, step1924]: loss 4.555933
[epoch4, step1925]: loss 3.007717
[epoch4, step1926]: loss 2.328763
[epoch4, step1927]: loss 23.672689
[epoch4, step1928]: loss 8.736544
[epoch4, step1929]: loss 4.142394
[epoch4, step1930]: loss 11.189810
[epoch4, step1931]: loss 18.205431
[epoch4, step1932]: loss 3.487874
[epoch4, step1933]: loss 18.674168
[epoch4, step1934]: loss 3.898003
[epoch4, step1935]: loss 17.444691
[epoch4, step1936]: loss 3.368962
[epoch4, step1937]: loss 1.917972
[epoch4, step1938]: loss 4.308883
[epoch4, step1939]: loss 32.354126
[epoch4, step1940]: loss 9.290860
[epoch4, step1941]: loss 4.362898
[epoch4, step1942]: loss 22.546646
[epoch4, step1943]: loss 18.041836
[epoch4, step1944]: loss 5.489054
[epoch4, step1945]: loss 20.313900
[epoch4, step1946]: loss 1.689380
[epoch4, step1947]: loss 10.872751
[epoch4, step1948]: loss 3.564976
[epoch4, step1949]: loss 22.691923
[epoch4, step1950]: loss 20.429697
[epoch4, step1951]: loss 2.554066
[epoch4, step1952]: loss 5.390982
[epoch4, step1953]: loss 13.587683
[epoch4, step1954]: loss 3.506926
[epoch4, step1955]: loss 5.987901
[epoch4, step1956]: loss 17.436785
[epoch4, step1957]: loss 2.634549
[epoch4, step1958]: loss 15.763612
[epoch4, step1959]: loss 2.411709
[epoch4, step1960]: loss 24.962643
[epoch4, step1961]: loss 9.112852
[epoch4, step1962]: loss 10.851242
[epoch4, step1963]: loss 2.345734
[epoch4, step1964]: loss 20.499199
[epoch4, step1965]: loss 2.738267
[epoch4, step1966]: loss 10.103492
[epoch4, step1967]: loss 5.884739
[epoch4, step1968]: loss 3.119108
[epoch4, step1969]: loss 9.934665
[epoch4, step1970]: loss 2.221044
[epoch4, step1971]: loss 5.489557
[epoch4, step1972]: loss 14.538681
[epoch4, step1973]: loss 2.929059
[epoch4, step1974]: loss 4.467596
[epoch4, step1975]: loss 43.951920
[epoch4, step1976]: loss 1.902833
[epoch4, step1977]: loss 6.294830
[epoch4, step1978]: loss 16.587450
[epoch4, step1979]: loss 8.662307
[epoch4, step1980]: loss 2.975100
[epoch4, step1981]: loss 3.357208
[epoch4, step1982]: loss 15.439869
[epoch4, step1983]: loss 3.514272
[epoch4, step1984]: loss 10.214858
[epoch4, step1985]: loss 16.194128
[epoch4, step1986]: loss 18.880325
[epoch4, step1987]: loss 10.743267
[epoch4, step1988]: loss 19.122610
[epoch4, step1989]: loss 1.994025
[epoch4, step1990]: loss 6.316517
[epoch4, step1991]: loss 16.484825
[epoch4, step1992]: loss 11.464504
[epoch4, step1993]: loss 18.645451
[epoch4, step1994]: loss 18.936991
[epoch4, step1995]: loss 4.569364
[epoch4, step1996]: loss 2.608178
[epoch4, step1997]: loss 4.216383
[epoch4, step1998]: loss 6.986813
[epoch4, step1999]: loss 12.268141
[epoch4, step2000]: loss 2.993245
[epoch4, step2001]: loss 22.523148
[epoch4, step2002]: loss 2.742050
[epoch4, step2003]: loss 6.106379
[epoch4, step2004]: loss 4.682956
[epoch4, step2005]: loss 9.151879
[epoch4, step2006]: loss 2.071002
[epoch4, step2007]: loss 1.877207
[epoch4, step2008]: loss 8.255439
[epoch4, step2009]: loss 13.247012
[epoch4, step2010]: loss 14.971301
[epoch4, step2011]: loss 23.748314
[epoch4, step2012]: loss 3.839567
[epoch4, step2013]: loss 3.242288
[epoch4, step2014]: loss 2.851355
[epoch4, step2015]: loss 14.743842
[epoch4, step2016]: loss 48.993767
[epoch4, step2017]: loss 5.321404
[epoch4, step2018]: loss 2.774678
[epoch4, step2019]: loss 3.457541
[epoch4, step2020]: loss 9.610752
[epoch4, step2021]: loss 7.020141
[epoch4, step2022]: loss 3.093617
[epoch4, step2023]: loss 14.907275
[epoch4, step2024]: loss 2.549472
[epoch4, step2025]: loss 3.422636
[epoch4, step2026]: loss 9.742777
[epoch4, step2027]: loss 6.206530
[epoch4, step2028]: loss 3.191784
[epoch4, step2029]: loss 2.692710
[epoch4, step2030]: loss 1.863246
[epoch4, step2031]: loss 24.754128
[epoch4, step2032]: loss 5.639427
[epoch4, step2033]: loss 13.964558
[epoch4, step2034]: loss 18.721323
[epoch4, step2035]: loss 3.547881
[epoch4, step2036]: loss 16.847376
[epoch4, step2037]: loss 17.831961
[epoch4, step2038]: loss 7.771697
[epoch4, step2039]: loss 10.614439
[epoch4, step2040]: loss 17.177940
[epoch4, step2041]: loss 8.474648
[epoch4, step2042]: loss 2.926679
[epoch4, step2043]: loss 13.603124
[epoch4, step2044]: loss 11.457948
[epoch4, step2045]: loss 3.941054
[epoch4, step2046]: loss 2.252996
[epoch4, step2047]: loss 11.917799
[epoch4, step2048]: loss 3.747825
[epoch4, step2049]: loss 3.010105
[epoch4, step2050]: loss 1.648280
[epoch4, step2051]: loss 10.325539
[epoch4, step2052]: loss 2.398913
[epoch4, step2053]: loss 15.100728
[epoch4, step2054]: loss 5.617455
[epoch4, step2055]: loss 10.218387
[epoch4, step2056]: loss 15.373619
[epoch4, step2057]: loss 3.248655
[epoch4, step2058]: loss 10.460889
[epoch4, step2059]: loss 2.850285
[epoch4, step2060]: loss 8.818275
[epoch4, step2061]: loss 18.136463
[epoch4, step2062]: loss 14.174083
[epoch4, step2063]: loss 2.089803
[epoch4, step2064]: loss 4.156681
[epoch4, step2065]: loss 11.914921
[epoch4, step2066]: loss 3.646034
[epoch4, step2067]: loss 6.117615
[epoch4, step2068]: loss 11.189112
[epoch4, step2069]: loss 5.428421
[epoch4, step2070]: loss 16.870121
[epoch4, step2071]: loss 12.092154
[epoch4, step2072]: loss 10.524618
[epoch4, step2073]: loss 3.262441
[epoch4, step2074]: loss 13.646383
[epoch4, step2075]: loss 1.946643
[epoch4, step2076]: loss 14.717187
[epoch4, step2077]: loss 4.832257
[epoch4, step2078]: loss 28.973440
[epoch4, step2079]: loss 11.428258
[epoch4, step2080]: loss 12.421289
[epoch4, step2081]: loss 6.375179
[epoch4, step2082]: loss 1.795617
[epoch4, step2083]: loss 10.506621
[epoch4, step2084]: loss 7.320211
[epoch4, step2085]: loss 12.774723
[epoch4, step2086]: loss 11.073937
[epoch4, step2087]: loss 15.249809
[epoch4, step2088]: loss 17.167290
[epoch4, step2089]: loss 2.686074
[epoch4, step2090]: loss 2.582765
[epoch4, step2091]: loss 3.400445
[epoch4, step2092]: loss 7.541715
[epoch4, step2093]: loss 1.384212
[epoch4, step2094]: loss 21.506382
[epoch4, step2095]: loss 18.916359
[epoch4, step2096]: loss 25.264511
[epoch4, step2097]: loss 30.445908
[epoch4, step2098]: loss 8.833547
[epoch4, step2099]: loss 2.364486
[epoch4, step2100]: loss 9.779569
[epoch4, step2101]: loss 21.283092
[epoch4, step2102]: loss 2.234051
[epoch4, step2103]: loss 12.128468
[epoch4, step2104]: loss 12.662884
[epoch4, step2105]: loss 3.988642
[epoch4, step2106]: loss 10.863726
[epoch4, step2107]: loss 2.732814
[epoch4, step2108]: loss 17.474314
[epoch4, step2109]: loss 19.433714
[epoch4, step2110]: loss 3.366261
[epoch4, step2111]: loss 3.156167
[epoch4, step2112]: loss 14.112377
[epoch4, step2113]: loss 1.788476
[epoch4, step2114]: loss 30.406345
[epoch4, step2115]: loss 3.291250
[epoch4, step2116]: loss 2.324593
[epoch4, step2117]: loss 2.284458
[epoch4, step2118]: loss 2.932386
[epoch4, step2119]: loss 11.882631
[epoch4, step2120]: loss 18.093178
[epoch4, step2121]: loss 24.274641
[epoch4, step2122]: loss 16.084558
[epoch4, step2123]: loss 7.054372
[epoch4, step2124]: loss 3.117756
[epoch4, step2125]: loss 2.206418
[epoch4, step2126]: loss 3.922207
[epoch4, step2127]: loss 5.260842
[epoch4, step2128]: loss 26.947760
[epoch4, step2129]: loss 10.798565
[epoch4, step2130]: loss 2.915101
[epoch4, step2131]: loss 17.914598
[epoch4, step2132]: loss 10.734053
[epoch4, step2133]: loss 12.698355
[epoch4, step2134]: loss 1.688377
[epoch4, step2135]: loss 12.332303
[epoch4, step2136]: loss 2.881712
[epoch4, step2137]: loss 10.697864
[epoch4, step2138]: loss 15.546996
[epoch4, step2139]: loss 7.692445
[epoch4, step2140]: loss 5.690515
[epoch4, step2141]: loss 14.934609
[epoch4, step2142]: loss 5.627005
[epoch4, step2143]: loss 10.821993
[epoch4, step2144]: loss 3.911666
[epoch4, step2145]: loss 19.283157
[epoch4, step2146]: loss 3.435939
[epoch4, step2147]: loss 8.901497
[epoch4, step2148]: loss 13.018602
[epoch4, step2149]: loss 2.780935
[epoch4, step2150]: loss 10.382119
[epoch4, step2151]: loss 5.282634
[epoch4, step2152]: loss 5.130534
[epoch4, step2153]: loss 3.232715
[epoch4, step2154]: loss 34.528770
[epoch4, step2155]: loss 9.278399
[epoch4, step2156]: loss 15.355581
[epoch4, step2157]: loss 5.169462
[epoch4, step2158]: loss 17.109331
[epoch4, step2159]: loss 3.022318
[epoch4, step2160]: loss 6.129919
[epoch4, step2161]: loss 21.988197
[epoch4, step2162]: loss 8.940570
[epoch4, step2163]: loss 10.313742
[epoch4, step2164]: loss 4.631170
[epoch4, step2165]: loss 7.776947
[epoch4, step2166]: loss 10.186691
[epoch4, step2167]: loss 17.285076
[epoch4, step2168]: loss 16.900602
[epoch4, step2169]: loss 2.683160
[epoch4, step2170]: loss 4.071136
[epoch4, step2171]: loss 37.537392
[epoch4, step2172]: loss 9.171989
[epoch4, step2173]: loss 5.646117
[epoch4, step2174]: loss 15.865815
[epoch4, step2175]: loss 4.561618
[epoch4, step2176]: loss 7.664154
[epoch4, step2177]: loss 20.932442
[epoch4, step2178]: loss 20.678120
[epoch4, step2179]: loss 4.798479
[epoch4, step2180]: loss 2.360006
[epoch4, step2181]: loss 10.774717
[epoch4, step2182]: loss 4.628575
[epoch4, step2183]: loss 5.099969
[epoch4, step2184]: loss 2.464498
[epoch4, step2185]: loss 7.054238
[epoch4, step2186]: loss 18.146362
[epoch4, step2187]: loss 3.120308
[epoch4, step2188]: loss 10.578244
[epoch4, step2189]: loss 9.400194
[epoch4, step2190]: loss 23.712708
[epoch4, step2191]: loss 28.113310
[epoch4, step2192]: loss 13.012639
[epoch4, step2193]: loss 3.355896
[epoch4, step2194]: loss 11.962385
[epoch4, step2195]: loss 3.397070
[epoch4, step2196]: loss 9.676127
[epoch4, step2197]: loss 6.063198
[epoch4, step2198]: loss 2.497851
[epoch4, step2199]: loss 14.897871
[epoch4, step2200]: loss 19.088720
[epoch4, step2201]: loss 10.208441
[epoch4, step2202]: loss 3.665772
[epoch4, step2203]: loss 22.223143
[epoch4, step2204]: loss 2.208397
[epoch4, step2205]: loss 4.711370
[epoch4, step2206]: loss 24.032084
[epoch4, step2207]: loss 9.052136
[epoch4, step2208]: loss 8.683112
[epoch4, step2209]: loss 25.924248
[epoch4, step2210]: loss 3.570980
[epoch4, step2211]: loss 4.702134
[epoch4, step2212]: loss 5.190294
[epoch4, step2213]: loss 4.911869
[epoch4, step2214]: loss 20.862144
[epoch4, step2215]: loss 4.761704
[epoch4, step2216]: loss 4.731523
[epoch4, step2217]: loss 14.129115
[epoch4, step2218]: loss 12.269511
[epoch4, step2219]: loss 2.206695
[epoch4, step2220]: loss 17.176485
[epoch4, step2221]: loss 17.922127
[epoch4, step2222]: loss 2.730887
[epoch4, step2223]: loss 2.950420
[epoch4, step2224]: loss 4.018652
[epoch4, step2225]: loss 5.278858
[epoch4, step2226]: loss 6.269248
[epoch4, step2227]: loss 6.584129
[epoch4, step2228]: loss 1.992452
[epoch4, step2229]: loss 4.491151
[epoch4, step2230]: loss 15.823215
[epoch4, step2231]: loss 20.337875
[epoch4, step2232]: loss 11.315413
[epoch4, step2233]: loss 4.676637
[epoch4, step2234]: loss 3.534254
[epoch4, step2235]: loss 2.449738
[epoch4, step2236]: loss 16.771038
[epoch4, step2237]: loss 20.035730
[epoch4, step2238]: loss 1.935143
[epoch4, step2239]: loss 2.196926
[epoch4, step2240]: loss 2.760241
[epoch4, step2241]: loss 18.662117
[epoch4, step2242]: loss 9.659701
[epoch4, step2243]: loss 3.405283
[epoch4, step2244]: loss 22.170824
[epoch4, step2245]: loss 9.013937
[epoch4, step2246]: loss 2.163048
[epoch4, step2247]: loss 7.856258
[epoch4, step2248]: loss 12.756582
[epoch4, step2249]: loss 3.073326
[epoch4, step2250]: loss 4.538449
[epoch4, step2251]: loss 12.723147
[epoch4, step2252]: loss 9.020010
[epoch4, step2253]: loss 2.434815
[epoch4, step2254]: loss 1.906382
[epoch4, step2255]: loss 4.770439
[epoch4, step2256]: loss 2.518109
[epoch4, step2257]: loss 18.264832
[epoch4, step2258]: loss 16.040323
[epoch4, step2259]: loss 5.338186
[epoch4, step2260]: loss 10.843498
[epoch4, step2261]: loss 3.807479
[epoch4, step2262]: loss 4.513453
[epoch4, step2263]: loss 3.104370
[epoch4, step2264]: loss 1.893618
[epoch4, step2265]: loss 13.106339
[epoch4, step2266]: loss 3.915904
[epoch4, step2267]: loss 14.918566
[epoch4, step2268]: loss 11.367393
[epoch4, step2269]: loss 5.102120
[epoch4, step2270]: loss 4.991559
[epoch4, step2271]: loss 19.015457
[epoch4, step2272]: loss 18.542294
[epoch4, step2273]: loss 6.133804
[epoch4, step2274]: loss 2.954588
[epoch4, step2275]: loss 11.303869
[epoch4, step2276]: loss 2.366268
[epoch4, step2277]: loss 2.745465
[epoch4, step2278]: loss 1.913933
[epoch4, step2279]: loss 13.140011
[epoch4, step2280]: loss 2.640958
[epoch4, step2281]: loss 5.383163
[epoch4, step2282]: loss 8.341197
[epoch4, step2283]: loss 3.625895
[epoch4, step2284]: loss 29.085417
[epoch4, step2285]: loss 3.937378
[epoch4, step2286]: loss 2.195651
[epoch4, step2287]: loss 10.162779
[epoch4, step2288]: loss 20.097616
[epoch4, step2289]: loss 10.312197
[epoch4, step2290]: loss 5.282343
[epoch4, step2291]: loss 29.955072
[epoch4, step2292]: loss 16.919165
[epoch4, step2293]: loss 4.399726
[epoch4, step2294]: loss 21.962399
[epoch4, step2295]: loss 14.064920
[epoch4, step2296]: loss 1.767964
[epoch4, step2297]: loss 2.132347
[epoch4, step2298]: loss 5.881302
[epoch4, step2299]: loss 3.399939
[epoch4, step2300]: loss 4.548539
[epoch4, step2301]: loss 14.860331
[epoch4, step2302]: loss 10.211158
[epoch4, step2303]: loss 41.693432
[epoch4, step2304]: loss 5.451541
[epoch4, step2305]: loss 12.644297
[epoch4, step2306]: loss 4.796561
[epoch4, step2307]: loss 2.653572
[epoch4, step2308]: loss 11.471991
[epoch4, step2309]: loss 4.652040
[epoch4, step2310]: loss 3.180889
[epoch4, step2311]: loss 8.826673
[epoch4, step2312]: loss 11.940083
[epoch4, step2313]: loss 10.146276
[epoch4, step2314]: loss 2.707669
[epoch4, step2315]: loss 37.452835
[epoch4, step2316]: loss 11.191548
[epoch4, step2317]: loss 6.489419
[epoch4, step2318]: loss 12.182462
[epoch4, step2319]: loss 8.022812
[epoch4, step2320]: loss 2.616985
[epoch4, step2321]: loss 2.823425
[epoch4, step2322]: loss 14.578790
[epoch4, step2323]: loss 6.931498
[epoch4, step2324]: loss 15.836926
[epoch4, step2325]: loss 4.151388
[epoch4, step2326]: loss 2.235069
[epoch4, step2327]: loss 12.375947
[epoch4, step2328]: loss 15.798178
[epoch4, step2329]: loss 24.598122
[epoch4, step2330]: loss 4.338799
[epoch4, step2331]: loss 9.069778
[epoch4, step2332]: loss 9.300304
[epoch4, step2333]: loss 22.591688
[epoch4, step2334]: loss 2.260471
[epoch4, step2335]: loss 16.008720
[epoch4, step2336]: loss 7.397479
[epoch4, step2337]: loss 3.700444
[epoch4, step2338]: loss 10.389015
[epoch4, step2339]: loss 3.616098
[epoch4, step2340]: loss 4.735013
[epoch4, step2341]: loss 2.701205
[epoch4, step2342]: loss 3.914936
[epoch4, step2343]: loss 10.487237
[epoch4, step2344]: loss 2.341267
[epoch4, step2345]: loss 2.670250
[epoch4, step2346]: loss 4.750400
[epoch4, step2347]: loss 2.312679
[epoch4, step2348]: loss 12.723957
[epoch4, step2349]: loss 17.452002
[epoch4, step2350]: loss 1.878657
[epoch4, step2351]: loss 9.583910
[epoch4, step2352]: loss 2.077153
[epoch4, step2353]: loss 2.299510
[epoch4, step2354]: loss 4.600958
[epoch4, step2355]: loss 18.775507
[epoch4, step2356]: loss 3.260086
[epoch4, step2357]: loss 2.737397
[epoch4, step2358]: loss 12.125845
[epoch4, step2359]: loss 2.047102
[epoch4, step2360]: loss 3.551996
[epoch4, step2361]: loss 29.490574
[epoch4, step2362]: loss 10.750627
[epoch4, step2363]: loss 22.036896
[epoch4, step2364]: loss 26.854269
[epoch4, step2365]: loss 2.116477
[epoch4, step2366]: loss 4.959091
[epoch4, step2367]: loss 2.289428
[epoch4, step2368]: loss 8.408826
[epoch4, step2369]: loss 18.602541
[epoch4, step2370]: loss 6.446823
[epoch4, step2371]: loss 14.864365
[epoch4, step2372]: loss 4.840788
[epoch4, step2373]: loss 19.754330
[epoch4, step2374]: loss 3.026657
[epoch4, step2375]: loss 12.858740
[epoch4, step2376]: loss 8.181210
[epoch4, step2377]: loss 26.162909
[epoch4, step2378]: loss 5.457676
[epoch4, step2379]: loss 5.321554
[epoch4, step2380]: loss 11.828308
[epoch4, step2381]: loss 6.031331
[epoch4, step2382]: loss 5.141235
[epoch4, step2383]: loss 7.238772
[epoch4, step2384]: loss 11.884932
[epoch4, step2385]: loss 4.208631
[epoch4, step2386]: loss 23.597918
[epoch4, step2387]: loss 17.574224
[epoch4, step2388]: loss 2.825657
[epoch4, step2389]: loss 3.631421
[epoch4, step2390]: loss 29.225792
[epoch4, step2391]: loss 3.826874
[epoch4, step2392]: loss 35.716862
[epoch4, step2393]: loss 2.279622
[epoch4, step2394]: loss 11.497662
[epoch4, step2395]: loss 1.683946
[epoch4, step2396]: loss 2.920447
[epoch4, step2397]: loss 4.698442
[epoch4, step2398]: loss 39.037582
[epoch4, step2399]: loss 3.336640
[epoch4, step2400]: loss 21.725103
[epoch4, step2401]: loss 12.515462
[epoch4, step2402]: loss 2.049639
[epoch4, step2403]: loss 8.686237
[epoch4, step2404]: loss 12.088031
[epoch4, step2405]: loss 12.223952
[epoch4, step2406]: loss 17.524752
[epoch4, step2407]: loss 5.206959
[epoch4, step2408]: loss 21.924557
[epoch4, step2409]: loss 28.353674
[epoch4, step2410]: loss 3.689427
[epoch4, step2411]: loss 4.979926
[epoch4, step2412]: loss 21.904909
[epoch4, step2413]: loss 2.868744
[epoch4, step2414]: loss 2.333220
[epoch4, step2415]: loss 8.225976
[epoch4, step2416]: loss 5.231040
[epoch4, step2417]: loss 13.908371
[epoch4, step2418]: loss 2.744445
[epoch4, step2419]: loss 2.653131
[epoch4, step2420]: loss 7.847968
[epoch4, step2421]: loss 10.128794
[epoch4, step2422]: loss 3.113582
[epoch4, step2423]: loss 3.055806
[epoch4, step2424]: loss 3.146604
[epoch4, step2425]: loss 7.164797
[epoch4, step2426]: loss 3.694636
[epoch4, step2427]: loss 3.946469
[epoch4, step2428]: loss 4.389488
[epoch4, step2429]: loss 3.722540
[epoch4, step2430]: loss 4.208410
[epoch4, step2431]: loss 2.559782
[epoch4, step2432]: loss 24.799114
[epoch4, step2433]: loss 11.277932
[epoch4, step2434]: loss 4.717493
[epoch4, step2435]: loss 1.688956
[epoch4, step2436]: loss 14.642106
[epoch4, step2437]: loss 2.401675
[epoch4, step2438]: loss 14.268157
[epoch4, step2439]: loss 10.663763
[epoch4, step2440]: loss 10.664167
[epoch4, step2441]: loss 2.491879
[epoch4, step2442]: loss 3.144647
[epoch4, step2443]: loss 3.646624
[epoch4, step2444]: loss 28.744345
[epoch4, step2445]: loss 21.110939
[epoch4, step2446]: loss 17.294458
[epoch4, step2447]: loss 13.284662
[epoch4, step2448]: loss 3.669477
[epoch4, step2449]: loss 5.045587
[epoch4, step2450]: loss 2.123641
[epoch4, step2451]: loss 2.022623
[epoch4, step2452]: loss 15.316628
[epoch4, step2453]: loss 17.371094
[epoch4, step2454]: loss 4.677256
[epoch4, step2455]: loss 10.574526
[epoch4, step2456]: loss 29.046682
[epoch4, step2457]: loss 2.415524
[epoch4, step2458]: loss 19.273794
[epoch4, step2459]: loss 2.151936
[epoch4, step2460]: loss 20.677258
[epoch4, step2461]: loss 12.904567
[epoch4, step2462]: loss 4.011260
[epoch4, step2463]: loss 10.863247
[epoch4, step2464]: loss 5.952757
[epoch4, step2465]: loss 13.609865
[epoch4, step2466]: loss 18.776262
[epoch4, step2467]: loss 1.760638
[epoch4, step2468]: loss 26.782814
[epoch4, step2469]: loss 5.815352
[epoch4, step2470]: loss 6.254455
[epoch4, step2471]: loss 16.530958
[epoch4, step2472]: loss 11.902705
[epoch4, step2473]: loss 2.210458
[epoch4, step2474]: loss 9.201537
[epoch4, step2475]: loss 13.087446
[epoch4, step2476]: loss 12.831141
[epoch4, step2477]: loss 5.691932
[epoch4, step2478]: loss 4.128437
[epoch4, step2479]: loss 15.715560
[epoch4, step2480]: loss 3.860434
[epoch4, step2481]: loss 2.625612
[epoch4, step2482]: loss 3.104879
[epoch4, step2483]: loss 7.520430
[epoch4, step2484]: loss 11.450864
[epoch4, step2485]: loss 6.845387
[epoch4, step2486]: loss 2.464833
[epoch4, step2487]: loss 29.604565
[epoch4, step2488]: loss 10.214890
[epoch4, step2489]: loss 28.244305
[epoch4, step2490]: loss 10.206612
[epoch4, step2491]: loss 13.620192
[epoch4, step2492]: loss 3.713992
[epoch4, step2493]: loss 10.352957
[epoch4, step2494]: loss 2.757067
[epoch4, step2495]: loss 13.879243
[epoch4, step2496]: loss 2.145878
[epoch4, step2497]: loss 4.039653
[epoch4, step2498]: loss 7.107807
[epoch4, step2499]: loss 13.730925
[epoch4, step2500]: loss 4.058916
[epoch4, step2501]: loss 2.501342
[epoch4, step2502]: loss 4.333123
[epoch4, step2503]: loss 19.446325
[epoch4, step2504]: loss 12.593336
[epoch4, step2505]: loss 9.145635
[epoch4, step2506]: loss 2.732114
[epoch4, step2507]: loss 7.095714
[epoch4, step2508]: loss 3.421577
[epoch4, step2509]: loss 11.780756
[epoch4, step2510]: loss 9.305662
[epoch4, step2511]: loss 2.004889
[epoch4, step2512]: loss 3.926180
[epoch4, step2513]: loss 41.206722
[epoch4, step2514]: loss 3.997107
[epoch4, step2515]: loss 7.470399
[epoch4, step2516]: loss 3.339617
[epoch4, step2517]: loss 7.402711
[epoch4, step2518]: loss 1.980903
[epoch4, step2519]: loss 17.813663
[epoch4, step2520]: loss 2.894055
[epoch4, step2521]: loss 7.073085
[epoch4, step2522]: loss 20.030123
[epoch4, step2523]: loss 5.454574
[epoch4, step2524]: loss 5.401139
[epoch4, step2525]: loss 17.159393
[epoch4, step2526]: loss 14.134383
[epoch4, step2527]: loss 3.676781
[epoch4, step2528]: loss 7.614770
[epoch4, step2529]: loss 4.186056
[epoch4, step2530]: loss 5.244718
[epoch4, step2531]: loss 3.065015
[epoch4, step2532]: loss 5.682768
[epoch4, step2533]: loss 4.523983
[epoch4, step2534]: loss 6.642386
[epoch4, step2535]: loss 5.200948
[epoch4, step2536]: loss 2.423235
[epoch4, step2537]: loss 9.891351
[epoch4, step2538]: loss 21.886234
[epoch4, step2539]: loss 10.561295
[epoch4, step2540]: loss 5.160169
[epoch4, step2541]: loss 19.743048
[epoch4, step2542]: loss 4.441306
[epoch4, step2543]: loss 4.988836
[epoch4, step2544]: loss 28.905560
[epoch4, step2545]: loss 7.427911
[epoch4, step2546]: loss 3.240050
[epoch4, step2547]: loss 14.813131
[epoch4, step2548]: loss 26.547758
[epoch4, step2549]: loss 3.304394
[epoch4, step2550]: loss 21.009808
[epoch4, step2551]: loss 19.943245
[epoch4, step2552]: loss 2.252369
[epoch4, step2553]: loss 39.677029
[epoch4, step2554]: loss 2.474775
[epoch4, step2555]: loss 3.412798
[epoch4, step2556]: loss 10.630941
[epoch4, step2557]: loss 2.362704
[epoch4, step2558]: loss 28.799488
[epoch4, step2559]: loss 3.901940
[epoch4, step2560]: loss 5.070463
[epoch4, step2561]: loss 2.775244
[epoch4, step2562]: loss 3.512514
[epoch4, step2563]: loss 11.011097
[epoch4, step2564]: loss 2.358440
[epoch4, step2565]: loss 2.020308
[epoch4, step2566]: loss 2.816591
[epoch4, step2567]: loss 7.186683
[epoch4, step2568]: loss 9.927082
[epoch4, step2569]: loss 23.155005
[epoch4, step2570]: loss 16.811682
[epoch4, step2571]: loss 1.780034
[epoch4, step2572]: loss 28.961933
[epoch4, step2573]: loss 6.816637
[epoch4, step2574]: loss 8.714014
[epoch4, step2575]: loss 31.964407
[epoch4, step2576]: loss 12.741423
[epoch4, step2577]: loss 2.645983
[epoch4, step2578]: loss 19.489338
[epoch4, step2579]: loss 3.603620
[epoch4, step2580]: loss 2.841906
[epoch4, step2581]: loss 11.305177
[epoch4, step2582]: loss 18.777426
[epoch4, step2583]: loss 4.820429
[epoch4, step2584]: loss 25.493299
[epoch4, step2585]: loss 9.407517
[epoch4, step2586]: loss 10.910015
[epoch4, step2587]: loss 15.211165
[epoch4, step2588]: loss 2.276865
[epoch4, step2589]: loss 1.895969
[epoch4, step2590]: loss 2.536031
[epoch4, step2591]: loss 2.019612
[epoch4, step2592]: loss 3.811330
[epoch4, step2593]: loss 3.054365
[epoch4, step2594]: loss 2.712703
[epoch4, step2595]: loss 1.853489
[epoch4, step2596]: loss 7.331234
[epoch4, step2597]: loss 21.485479
[epoch4, step2598]: loss 12.552130
[epoch4, step2599]: loss 13.257459
[epoch4, step2600]: loss 11.756749
[epoch4, step2601]: loss 9.277805
[epoch4, step2602]: loss 12.041894
[epoch4, step2603]: loss 6.421000
[epoch4, step2604]: loss 2.847727
[epoch4, step2605]: loss 15.172023
[epoch4, step2606]: loss 10.706553
[epoch4, step2607]: loss 5.044426
[epoch4, step2608]: loss 6.979873
[epoch4, step2609]: loss 8.813972
[epoch4, step2610]: loss 10.208615
[epoch4, step2611]: loss 13.079604
[epoch4, step2612]: loss 2.147066
[epoch4, step2613]: loss 11.564052
[epoch4, step2614]: loss 5.064977
[epoch4, step2615]: loss 3.667666
[epoch4, step2616]: loss 18.501070
[epoch4, step2617]: loss 9.110865
[epoch4, step2618]: loss 9.510172
[epoch4, step2619]: loss 6.460242
[epoch4, step2620]: loss 23.256342
[epoch4, step2621]: loss 28.533142
[epoch4, step2622]: loss 22.516918
[epoch4, step2623]: loss 2.499253
[epoch4, step2624]: loss 9.915154
[epoch4, step2625]: loss 11.088943
[epoch4, step2626]: loss 3.182369
[epoch4, step2627]: loss 2.796436
[epoch4, step2628]: loss 9.684120
[epoch4, step2629]: loss 10.753356
[epoch4, step2630]: loss 13.945933
[epoch4, step2631]: loss 4.987166
[epoch4, step2632]: loss 1.907599
[epoch4, step2633]: loss 2.031959
[epoch4, step2634]: loss 2.355520
[epoch4, step2635]: loss 12.517561
[epoch4, step2636]: loss 18.066347
[epoch4, step2637]: loss 13.274987
[epoch4, step2638]: loss 10.502362
[epoch4, step2639]: loss 28.718019
[epoch4, step2640]: loss 20.756754
[epoch4, step2641]: loss 16.586845
[epoch4, step2642]: loss 5.106607
[epoch4, step2643]: loss 3.484781
[epoch4, step2644]: loss 1.977137
[epoch4, step2645]: loss 2.604743
[epoch4, step2646]: loss 3.082195
[epoch4, step2647]: loss 1.659258
[epoch4, step2648]: loss 16.617405
[epoch4, step2649]: loss 2.484305
[epoch4, step2650]: loss 9.839797
[epoch4, step2651]: loss 9.398955
[epoch4, step2652]: loss 12.809843
[epoch4, step2653]: loss 10.500309
[epoch4, step2654]: loss 20.278727
[epoch4, step2655]: loss 5.662786
[epoch4, step2656]: loss 4.915796
[epoch4, step2657]: loss 2.033723
[epoch4, step2658]: loss 1.550179
[epoch4, step2659]: loss 9.838625
[epoch4, step2660]: loss 26.725233
[epoch4, step2661]: loss 3.671296
[epoch4, step2662]: loss 5.477835
[epoch4, step2663]: loss 19.307726
[epoch4, step2664]: loss 3.775956
[epoch4, step2665]: loss 4.683048
[epoch4, step2666]: loss 2.150685
[epoch4, step2667]: loss 9.358746
[epoch4, step2668]: loss 2.185613
[epoch4, step2669]: loss 31.200459
[epoch4, step2670]: loss 19.182135
[epoch4, step2671]: loss 14.288327
[epoch4, step2672]: loss 13.028558
[epoch4, step2673]: loss 4.334920
[epoch4, step2674]: loss 12.127382
[epoch4, step2675]: loss 3.568581
[epoch4, step2676]: loss 2.589855
[epoch4, step2677]: loss 4.623688
[epoch4, step2678]: loss 3.211409
[epoch4, step2679]: loss 7.964614
[epoch4, step2680]: loss 8.758050
[epoch4, step2681]: loss 20.653868
[epoch4, step2682]: loss 2.114671
[epoch4, step2683]: loss 4.579957
[epoch4, step2684]: loss 3.952652
[epoch4, step2685]: loss 2.684007
[epoch4, step2686]: loss 21.249804
[epoch4, step2687]: loss 16.845125
[epoch4, step2688]: loss 18.377472
[epoch4, step2689]: loss 10.070736
[epoch4, step2690]: loss 16.854996
[epoch4, step2691]: loss 3.249765
[epoch4, step2692]: loss 4.166913
[epoch4, step2693]: loss 2.951525
[epoch4, step2694]: loss 4.163529
[epoch4, step2695]: loss 16.356474
[epoch4, step2696]: loss 18.202898
[epoch4, step2697]: loss 12.695044
[epoch4, step2698]: loss 18.186707
[epoch4, step2699]: loss 2.448269
[epoch4, step2700]: loss 3.587548
[epoch4, step2701]: loss 10.972048
[epoch4, step2702]: loss 11.656593
[epoch4, step2703]: loss 9.543894
[epoch4, step2704]: loss 3.258682
[epoch4, step2705]: loss 3.565688
[epoch4, step2706]: loss 2.286782
[epoch4, step2707]: loss 8.084270
[epoch4, step2708]: loss 20.649710
[epoch4, step2709]: loss 15.090753
[epoch4, step2710]: loss 3.355548
[epoch4, step2711]: loss 10.343204
[epoch4, step2712]: loss 9.609980
[epoch4, step2713]: loss 22.523054
[epoch4, step2714]: loss 1.858606
[epoch4, step2715]: loss 4.114371
[epoch4, step2716]: loss 2.438319
[epoch4, step2717]: loss 1.879934
[epoch4, step2718]: loss 4.822892
[epoch4, step2719]: loss 11.878971
[epoch4, step2720]: loss 37.820072
[epoch4, step2721]: loss 4.931935
[epoch4, step2722]: loss 5.063176
[epoch4, step2723]: loss 6.058612
[epoch4, step2724]: loss 29.465906
[epoch4, step2725]: loss 3.223926
[epoch4, step2726]: loss 9.265931
[epoch4, step2727]: loss 3.084681
[epoch4, step2728]: loss 6.475590
[epoch4, step2729]: loss 14.803588
[epoch4, step2730]: loss 26.689207
[epoch4, step2731]: loss 22.780796
[epoch4, step2732]: loss 4.333743
[epoch4, step2733]: loss 18.195621
[epoch4, step2734]: loss 4.706424
[epoch4, step2735]: loss 2.261328
[epoch4, step2736]: loss 21.710924
[epoch4, step2737]: loss 10.000428
[epoch4, step2738]: loss 4.237238
[epoch4, step2739]: loss 9.599034
[epoch4, step2740]: loss 13.477568
[epoch4, step2741]: loss 5.472587
[epoch4, step2742]: loss 11.554481
[epoch4, step2743]: loss 1.685928
[epoch4, step2744]: loss 1.546674
[epoch4, step2745]: loss 9.405385
[epoch4, step2746]: loss 4.083599
[epoch4, step2747]: loss 10.163873
[epoch4, step2748]: loss 4.648915
[epoch4, step2749]: loss 27.370354
[epoch4, step2750]: loss 8.823503
[epoch4, step2751]: loss 2.083995
[epoch4, step2752]: loss 13.257808
[epoch4, step2753]: loss 2.167508
[epoch4, step2754]: loss 3.071569
[epoch4, step2755]: loss 18.287901
[epoch4, step2756]: loss 9.359143
[epoch4, step2757]: loss 20.973423
[epoch4, step2758]: loss 4.890835
[epoch4, step2759]: loss 31.816305
[epoch4, step2760]: loss 10.277986
[epoch4, step2761]: loss 22.923803
[epoch4, step2762]: loss 2.527345
[epoch4, step2763]: loss 2.059652
[epoch4, step2764]: loss 18.457159
[epoch4, step2765]: loss 8.373945
[epoch4, step2766]: loss 11.005545
[epoch4, step2767]: loss 8.453680
[epoch4, step2768]: loss 15.279862
[epoch4, step2769]: loss 19.716921
[epoch4, step2770]: loss 3.702684
[epoch4, step2771]: loss 3.547677
[epoch4, step2772]: loss 8.874257
[epoch4, step2773]: loss 5.731459
[epoch4, step2774]: loss 9.143992
[epoch4, step2775]: loss 1.962763
[epoch4, step2776]: loss 1.978966
[epoch4, step2777]: loss 3.434168
[epoch4, step2778]: loss 11.286340
[epoch4, step2779]: loss 4.439783
[epoch4, step2780]: loss 24.601192
[epoch4, step2781]: loss 3.936454
[epoch4, step2782]: loss 10.612340
[epoch4, step2783]: loss 15.117182
[epoch4, step2784]: loss 10.768896
[epoch4, step2785]: loss 2.304192
[epoch4, step2786]: loss 3.647338
[epoch4, step2787]: loss 10.682935
[epoch4, step2788]: loss 10.957327
[epoch4, step2789]: loss 17.076920
[epoch4, step2790]: loss 4.475815
[epoch4, step2791]: loss 9.292945
[epoch4, step2792]: loss 9.812386
[epoch4, step2793]: loss 3.010777
[epoch4, step2794]: loss 3.009762
[epoch4, step2795]: loss 2.083055
[epoch4, step2796]: loss 10.451748
[epoch4, step2797]: loss 2.179593
[epoch4, step2798]: loss 7.643468
[epoch4, step2799]: loss 3.701287
[epoch4, step2800]: loss 11.784434
[epoch4, step2801]: loss 1.802475
[epoch4, step2802]: loss 1.427641
[epoch4, step2803]: loss 3.056304
[epoch4, step2804]: loss 1.787484
[epoch4, step2805]: loss 15.426010
[epoch4, step2806]: loss 3.683165
[epoch4, step2807]: loss 6.039936
[epoch4, step2808]: loss 27.815189
[epoch4, step2809]: loss 10.663580
[epoch4, step2810]: loss 3.060189
[epoch4, step2811]: loss 2.349069
[epoch4, step2812]: loss 3.250241
[epoch4, step2813]: loss 5.365911
[epoch4, step2814]: loss 9.686653
[epoch4, step2815]: loss 15.313080
[epoch4, step2816]: loss 11.022653
[epoch4, step2817]: loss 3.234681
[epoch4, step2818]: loss 13.895691
[epoch4, step2819]: loss 1.726092
[epoch4, step2820]: loss 17.045107
[epoch4, step2821]: loss 11.252486
[epoch4, step2822]: loss 5.658161
[epoch4, step2823]: loss 3.128732
[epoch4, step2824]: loss 7.785271
[epoch4, step2825]: loss 6.502616
[epoch4, step2826]: loss 2.444347
[epoch4, step2827]: loss 4.100347
[epoch4, step2828]: loss 12.805416
[epoch4, step2829]: loss 3.131266
[epoch4, step2830]: loss 4.079134
[epoch4, step2831]: loss 9.915108
[epoch4, step2832]: loss 1.732824
[epoch4, step2833]: loss 24.439291
[epoch4, step2834]: loss 4.630349
[epoch4, step2835]: loss 3.535910
[epoch4, step2836]: loss 7.746586
[epoch4, step2837]: loss 3.636312
[epoch4, step2838]: loss 14.654641
[epoch4, step2839]: loss 10.253135
[epoch4, step2840]: loss 6.811202
[epoch4, step2841]: loss 3.918659
[epoch4, step2842]: loss 2.547077
[epoch4, step2843]: loss 10.128425
[epoch4, step2844]: loss 7.702137
[epoch4, step2845]: loss 23.526249
[epoch4, step2846]: loss 1.676157
[epoch4, step2847]: loss 8.399823
[epoch4, step2848]: loss 2.894198
[epoch4, step2849]: loss 2.566463
[epoch4, step2850]: loss 4.695206
[epoch4, step2851]: loss 18.287653
[epoch4, step2852]: loss 33.072693
[epoch4, step2853]: loss 2.004477
[epoch4, step2854]: loss 11.283423
[epoch4, step2855]: loss 11.776896
[epoch4, step2856]: loss 23.386543
[epoch4, step2857]: loss 4.389564
[epoch4, step2858]: loss 12.845517
[epoch4, step2859]: loss 15.822322
[epoch4, step2860]: loss 7.843717
[epoch4, step2861]: loss 2.465661
[epoch4, step2862]: loss 9.905263
[epoch4, step2863]: loss 9.292078
[epoch4, step2864]: loss 3.634363
[epoch4, step2865]: loss 2.210047
[epoch4, step2866]: loss 3.186974
[epoch4, step2867]: loss 1.669792
[epoch4, step2868]: loss 2.464547
[epoch4, step2869]: loss 17.597950
[epoch4, step2870]: loss 3.870770
[epoch4, step2871]: loss 1.659990
[epoch4, step2872]: loss 2.261815
[epoch4, step2873]: loss 23.213034
[epoch4, step2874]: loss 10.295135
[epoch4, step2875]: loss 2.773663
[epoch4, step2876]: loss 3.947330
[epoch4, step2877]: loss 6.497349
[epoch4, step2878]: loss 2.194602
[epoch4, step2879]: loss 3.626090
[epoch4, step2880]: loss 24.130520
[epoch4, step2881]: loss 7.532295
[epoch4, step2882]: loss 11.386757
[epoch4, step2883]: loss 1.719975
[epoch4, step2884]: loss 3.402475
[epoch4, step2885]: loss 3.921468
[epoch4, step2886]: loss 5.361250
[epoch4, step2887]: loss 3.618893
[epoch4, step2888]: loss 3.309469
[epoch4, step2889]: loss 3.002502
[epoch4, step2890]: loss 6.202317
[epoch4, step2891]: loss 5.427374
[epoch4, step2892]: loss 2.206839
[epoch4, step2893]: loss 4.608173
[epoch4, step2894]: loss 9.634666
[epoch4, step2895]: loss 2.849549
[epoch4, step2896]: loss 9.318365
[epoch4, step2897]: loss 16.027782
[epoch4, step2898]: loss 3.102870
[epoch4, step2899]: loss 20.970116
[epoch4, step2900]: loss 4.285501
[epoch4, step2901]: loss 2.715415
[epoch4, step2902]: loss 6.226611
[epoch4, step2903]: loss 1.301252
[epoch4, step2904]: loss 10.442488
[epoch4, step2905]: loss 3.029148
[epoch4, step2906]: loss 2.511732
[epoch4, step2907]: loss 2.144248
[epoch4, step2908]: loss 2.671778
[epoch4, step2909]: loss 2.700975
[epoch4, step2910]: loss 2.874648
[epoch4, step2911]: loss 2.583573
[epoch4, step2912]: loss 21.905825
[epoch4, step2913]: loss 9.449549
[epoch4, step2914]: loss 3.574854
[epoch4, step2915]: loss 9.693898
[epoch4, step2916]: loss 21.295460
[epoch4, step2917]: loss 3.869886
[epoch4, step2918]: loss 3.958791
[epoch4, step2919]: loss 9.167521
[epoch4, step2920]: loss 22.373146
[epoch4, step2921]: loss 12.884998
[epoch4, step2922]: loss 2.605354
[epoch4, step2923]: loss 13.837963
[epoch4, step2924]: loss 11.058712
[epoch4, step2925]: loss 17.608986
[epoch4, step2926]: loss 3.359801
[epoch4, step2927]: loss 18.472651
[epoch4, step2928]: loss 2.067187
[epoch4, step2929]: loss 4.057500
[epoch4, step2930]: loss 11.929954
[epoch4, step2931]: loss 2.368630
[epoch4, step2932]: loss 1.844574
[epoch4, step2933]: loss 3.218877
[epoch4, step2934]: loss 1.878972
[epoch4, step2935]: loss 27.211897
[epoch4, step2936]: loss 2.182332
[epoch4, step2937]: loss 2.631137
[epoch4, step2938]: loss 1.381520
[epoch4, step2939]: loss 2.517342
[epoch4, step2940]: loss 5.444435
[epoch4, step2941]: loss 24.822800
[epoch4, step2942]: loss 12.530537
[epoch4, step2943]: loss 5.228270
[epoch4, step2944]: loss 4.454714
[epoch4, step2945]: loss 9.686011
[epoch4, step2946]: loss 15.244201
[epoch4, step2947]: loss 16.714952
[epoch4, step2948]: loss 8.935040
[epoch4, step2949]: loss 9.690199
[epoch4, step2950]: loss 3.258162
[epoch4, step2951]: loss 17.986624
[epoch4, step2952]: loss 2.792950
[epoch4, step2953]: loss 2.384510
[epoch4, step2954]: loss 12.339482
[epoch4, step2955]: loss 9.087175
[epoch4, step2956]: loss 3.716654
[epoch4, step2957]: loss 15.507365
[epoch4, step2958]: loss 2.385486
[epoch4, step2959]: loss 9.334745
[epoch4, step2960]: loss 1.835681
[epoch4, step2961]: loss 28.533194
[epoch4, step2962]: loss 11.662746
[epoch4, step2963]: loss 4.252147
[epoch4, step2964]: loss 10.823449
[epoch4, step2965]: loss 1.780008
[epoch4, step2966]: loss 2.146783
[epoch4, step2967]: loss 13.888999
[epoch4, step2968]: loss 6.925981
[epoch4, step2969]: loss 3.439863
[epoch4, step2970]: loss 15.368468
[epoch4, step2971]: loss 2.080071
[epoch4, step2972]: loss 5.558877
[epoch4, step2973]: loss 4.335340
[epoch4, step2974]: loss 3.081105
[epoch4, step2975]: loss 1.784975
[epoch4, step2976]: loss 11.708349
[epoch4, step2977]: loss 4.170038
[epoch4, step2978]: loss 6.604766
[epoch4, step2979]: loss 2.088713
[epoch4, step2980]: loss 15.333141
[epoch4, step2981]: loss 20.974880
[epoch4, step2982]: loss 3.070530
[epoch4, step2983]: loss 2.621458
[epoch4, step2984]: loss 29.308155
[epoch4, step2985]: loss 7.442910
[epoch4, step2986]: loss 3.521496
[epoch4, step2987]: loss 6.390988
[epoch4, step2988]: loss 4.929867
[epoch4, step2989]: loss 2.245424
[epoch4, step2990]: loss 2.862190
[epoch4, step2991]: loss 4.937428
[epoch4, step2992]: loss 3.772864
[epoch4, step2993]: loss 3.016237
[epoch4, step2994]: loss 2.784061
[epoch4, step2995]: loss 12.324636
[epoch4, step2996]: loss 1.919869
[epoch4, step2997]: loss 2.129031
[epoch4, step2998]: loss 4.127583
[epoch4, step2999]: loss 10.116484
[epoch4, step3000]: loss 2.619685
[epoch4, step3001]: loss 6.732423
[epoch4, step3002]: loss 4.789467
[epoch4, step3003]: loss 6.935274
[epoch4, step3004]: loss 7.592498
[epoch4, step3005]: loss 14.942698
[epoch4, step3006]: loss 10.283385
[epoch4, step3007]: loss 3.219590
[epoch4, step3008]: loss 4.194144
[epoch4, step3009]: loss 2.689168
[epoch4, step3010]: loss 3.669447
[epoch4, step3011]: loss 8.873536
[epoch4, step3012]: loss 3.174738
[epoch4, step3013]: loss 9.199241
[epoch4, step3014]: loss 3.754761
[epoch4, step3015]: loss 12.585537
[epoch4, step3016]: loss 3.916598
[epoch4, step3017]: loss 11.840526
[epoch4, step3018]: loss 8.371037
[epoch4, step3019]: loss 1.669520
[epoch4, step3020]: loss 2.131964
[epoch4, step3021]: loss 7.029653
[epoch4, step3022]: loss 3.097493
[epoch4, step3023]: loss 16.685907
[epoch4, step3024]: loss 3.522153
[epoch4, step3025]: loss 15.203930
[epoch4, step3026]: loss 9.356920
[epoch4, step3027]: loss 8.900721
[epoch4, step3028]: loss 2.998760
[epoch4, step3029]: loss 2.901602
[epoch4, step3030]: loss 13.725244
[epoch4, step3031]: loss 2.256725
[epoch4, step3032]: loss 6.050736
[epoch4, step3033]: loss 1.880676
[epoch4, step3034]: loss 7.344972
[epoch4, step3035]: loss 13.399857
[epoch4, step3036]: loss 18.229609
[epoch4, step3037]: loss 14.829337
[epoch4, step3038]: loss 23.427582
[epoch4, step3039]: loss 1.719966
[epoch4, step3040]: loss 1.837442
[epoch4, step3041]: loss 31.458740
[epoch4, step3042]: loss 12.466166
[epoch4, step3043]: loss 2.373013
[epoch4, step3044]: loss 6.869275
[epoch4, step3045]: loss 2.800569
[epoch4, step3046]: loss 3.590109
[epoch4, step3047]: loss 3.414217
[epoch4, step3048]: loss 4.792397
[epoch4, step3049]: loss 9.853878
[epoch4, step3050]: loss 14.410505
[epoch4, step3051]: loss 26.520588
[epoch4, step3052]: loss 3.766203
[epoch4, step3053]: loss 6.186535
[epoch4, step3054]: loss 24.152079
[epoch4, step3055]: loss 2.170888
[epoch4, step3056]: loss 4.872864
[epoch4, step3057]: loss 3.504287
[epoch4, step3058]: loss 3.545485
[epoch4, step3059]: loss 2.245501
[epoch4, step3060]: loss 13.182309
[epoch4, step3061]: loss 3.341402
[epoch4, step3062]: loss 17.289244
[epoch4, step3063]: loss 3.909811
[epoch4, step3064]: loss 6.469426
[epoch4, step3065]: loss 3.120007
[epoch4, step3066]: loss 12.329333
[epoch4, step3067]: loss 16.646397
[epoch4, step3068]: loss 8.141048
[epoch4, step3069]: loss 3.211551
[epoch4, step3070]: loss 12.228316
[epoch4, step3071]: loss 4.315456
[epoch4, step3072]: loss 2.258370
[epoch4, step3073]: loss 4.919614
[epoch4, step3074]: loss 25.705566
[epoch4, step3075]: loss 19.839455
[epoch4, step3076]: loss 2.971316

[epoch4]: avg loss 2.971316

[epoch5, step1]: loss 3.517247
[epoch5, step2]: loss 17.763214
[epoch5, step3]: loss 2.797498
[epoch5, step4]: loss 3.800101
[epoch5, step5]: loss 4.069234
[epoch5, step6]: loss 2.219916
[epoch5, step7]: loss 11.130707
[epoch5, step8]: loss 2.113216
[epoch5, step9]: loss 4.200110
[epoch5, step10]: loss 2.070928
[epoch5, step11]: loss 9.799904
[epoch5, step12]: loss 3.379932
[epoch5, step13]: loss 5.719194
[epoch5, step14]: loss 18.824013
[epoch5, step15]: loss 17.173948
[epoch5, step16]: loss 2.066144
[epoch5, step17]: loss 7.199370
[epoch5, step18]: loss 6.182791
[epoch5, step19]: loss 12.849538
[epoch5, step20]: loss 10.779892
[epoch5, step21]: loss 3.119070
[epoch5, step22]: loss 1.868091
[epoch5, step23]: loss 2.732131
[epoch5, step24]: loss 3.433664
[epoch5, step25]: loss 2.388427
[epoch5, step26]: loss 4.202405
[epoch5, step27]: loss 3.670681
[epoch5, step28]: loss 20.410654
[epoch5, step29]: loss 2.198583
[epoch5, step30]: loss 8.003050
[epoch5, step31]: loss 5.963145
[epoch5, step32]: loss 8.734605
[epoch5, step33]: loss 3.839520
[epoch5, step34]: loss 2.277624
[epoch5, step35]: loss 12.366511
[epoch5, step36]: loss 1.602879
[epoch5, step37]: loss 2.820993
[epoch5, step38]: loss 13.588603
[epoch5, step39]: loss 22.092476
[epoch5, step40]: loss 3.632190
[epoch5, step41]: loss 3.291052
[epoch5, step42]: loss 3.767254
[epoch5, step43]: loss 6.430080
[epoch5, step44]: loss 3.552274
[epoch5, step45]: loss 5.824367
[epoch5, step46]: loss 6.974075
[epoch5, step47]: loss 9.886349
[epoch5, step48]: loss 2.296187
[epoch5, step49]: loss 2.426625
[epoch5, step50]: loss 13.888849
[epoch5, step51]: loss 1.480891
[epoch5, step52]: loss 4.429566
[epoch5, step53]: loss 13.961178
[epoch5, step54]: loss 1.977544
[epoch5, step55]: loss 2.268441
[epoch5, step56]: loss 25.792601
[epoch5, step57]: loss 3.456556
[epoch5, step58]: loss 7.986838
[epoch5, step59]: loss 28.544210
[epoch5, step60]: loss 10.009026
[epoch5, step61]: loss 7.873194
[epoch5, step62]: loss 12.015244
[epoch5, step63]: loss 5.204219
[epoch5, step64]: loss 9.815252
[epoch5, step65]: loss 17.946304
[epoch5, step66]: loss 5.527602
[epoch5, step67]: loss 2.752226
[epoch5, step68]: loss 2.892839
[epoch5, step69]: loss 4.608587
[epoch5, step70]: loss 31.070456
[epoch5, step71]: loss 3.354088
[epoch5, step72]: loss 8.911460
[epoch5, step73]: loss 2.372384
[epoch5, step74]: loss 7.936712
[epoch5, step75]: loss 3.481833
[epoch5, step76]: loss 3.103365
[epoch5, step77]: loss 11.008657
[epoch5, step78]: loss 1.727442
[epoch5, step79]: loss 27.606703
[epoch5, step80]: loss 19.385715
[epoch5, step81]: loss 2.354033
[epoch5, step82]: loss 2.217348
[epoch5, step83]: loss 17.069193
[epoch5, step84]: loss 1.720222
[epoch5, step85]: loss 4.835696
[epoch5, step86]: loss 5.406092
[epoch5, step87]: loss 1.966794
[epoch5, step88]: loss 2.728591
[epoch5, step89]: loss 1.933580
[epoch5, step90]: loss 4.481169
[epoch5, step91]: loss 2.021315
[epoch5, step92]: loss 23.725962
[epoch5, step93]: loss 13.982372
[epoch5, step94]: loss 11.268306
[epoch5, step95]: loss 8.215198
[epoch5, step96]: loss 6.382616
[epoch5, step97]: loss 11.023744
[epoch5, step98]: loss 25.902243
[epoch5, step99]: loss 10.921142
[epoch5, step100]: loss 9.313522
[epoch5, step101]: loss 10.247669
[epoch5, step102]: loss 10.829371
[epoch5, step103]: loss 8.719949
[epoch5, step104]: loss 7.668884
[epoch5, step105]: loss 2.231639
[epoch5, step106]: loss 4.619729
[epoch5, step107]: loss 25.044559
[epoch5, step108]: loss 2.981062
[epoch5, step109]: loss 21.761377
[epoch5, step110]: loss 1.607926
[epoch5, step111]: loss 7.657402
[epoch5, step112]: loss 9.551091
[epoch5, step113]: loss 4.927904
[epoch5, step114]: loss 3.558403
[epoch5, step115]: loss 1.832682
[epoch5, step116]: loss 1.732450
[epoch5, step117]: loss 7.692583
[epoch5, step118]: loss 12.763272
[epoch5, step119]: loss 13.153973
[epoch5, step120]: loss 6.215599
[epoch5, step121]: loss 21.146551
[epoch5, step122]: loss 3.712282
[epoch5, step123]: loss 2.334850
[epoch5, step124]: loss 5.691929
[epoch5, step125]: loss 9.752717
[epoch5, step126]: loss 19.915339
[epoch5, step127]: loss 3.571128
[epoch5, step128]: loss 8.532764
[epoch5, step129]: loss 11.311596
[epoch5, step130]: loss 10.094383
[epoch5, step131]: loss 3.059420
[epoch5, step132]: loss 2.160664
[epoch5, step133]: loss 17.087702
[epoch5, step134]: loss 2.819220
[epoch5, step135]: loss 2.773837
[epoch5, step136]: loss 19.415121
[epoch5, step137]: loss 4.895841
[epoch5, step138]: loss 16.199377
[epoch5, step139]: loss 6.497398
[epoch5, step140]: loss 2.830918
[epoch5, step141]: loss 7.112081
[epoch5, step142]: loss 6.513858
[epoch5, step143]: loss 11.495784
[epoch5, step144]: loss 3.351572
[epoch5, step145]: loss 12.097876
[epoch5, step146]: loss 4.417060
[epoch5, step147]: loss 3.679626
[epoch5, step148]: loss 6.664048
[epoch5, step149]: loss 21.289459
[epoch5, step150]: loss 8.497325
[epoch5, step151]: loss 15.990381
[epoch5, step152]: loss 19.975674
[epoch5, step153]: loss 2.197156
[epoch5, step154]: loss 17.729910
[epoch5, step155]: loss 2.964530
[epoch5, step156]: loss 2.298496
[epoch5, step157]: loss 3.875618
[epoch5, step158]: loss 11.179853
[epoch5, step159]: loss 3.648071
[epoch5, step160]: loss 7.525466
[epoch5, step161]: loss 4.268862
[epoch5, step162]: loss 14.294937
[epoch5, step163]: loss 1.726703
[epoch5, step164]: loss 22.615971
[epoch5, step165]: loss 5.802601
[epoch5, step166]: loss 18.111189
[epoch5, step167]: loss 5.677560
[epoch5, step168]: loss 3.629040
[epoch5, step169]: loss 9.982378
[epoch5, step170]: loss 12.328120
[epoch5, step171]: loss 3.197447
[epoch5, step172]: loss 6.940156
[epoch5, step173]: loss 6.116537
[epoch5, step174]: loss 9.760048
[epoch5, step175]: loss 30.777851
[epoch5, step176]: loss 4.569449
[epoch5, step177]: loss 20.114574
[epoch5, step178]: loss 8.306087
[epoch5, step179]: loss 12.389215
[epoch5, step180]: loss 1.828024
[epoch5, step181]: loss 2.620262
[epoch5, step182]: loss 10.653196
[epoch5, step183]: loss 3.476587
[epoch5, step184]: loss 3.052000
[epoch5, step185]: loss 1.701438
[epoch5, step186]: loss 16.741211
[epoch5, step187]: loss 13.210559
[epoch5, step188]: loss 4.018517
[epoch5, step189]: loss 3.051679
[epoch5, step190]: loss 3.982917
[epoch5, step191]: loss 2.055791
[epoch5, step192]: loss 4.172570
[epoch5, step193]: loss 2.619324
[epoch5, step194]: loss 9.427404
[epoch5, step195]: loss 5.227982
[epoch5, step196]: loss 9.068199
[epoch5, step197]: loss 2.088201
[epoch5, step198]: loss 21.838512
[epoch5, step199]: loss 12.823465
[epoch5, step200]: loss 2.206866
[epoch5, step201]: loss 21.510063
[epoch5, step202]: loss 7.015180
[epoch5, step203]: loss 3.246518
[epoch5, step204]: loss 18.082279
[epoch5, step205]: loss 2.487655
[epoch5, step206]: loss 4.477853
[epoch5, step207]: loss 4.327431
[epoch5, step208]: loss 1.736437
[epoch5, step209]: loss 4.480413
[epoch5, step210]: loss 46.056450
[epoch5, step211]: loss 5.387108
[epoch5, step212]: loss 7.412768
[epoch5, step213]: loss 3.024364
[epoch5, step214]: loss 12.395359
[epoch5, step215]: loss 9.247743
[epoch5, step216]: loss 2.927625
[epoch5, step217]: loss 8.520624
[epoch5, step218]: loss 1.649723
[epoch5, step219]: loss 2.661870
[epoch5, step220]: loss 4.181307
[epoch5, step221]: loss 17.507458
[epoch5, step222]: loss 5.070094
[epoch5, step223]: loss 4.469533
[epoch5, step224]: loss 2.642061
[epoch5, step225]: loss 2.008739
[epoch5, step226]: loss 20.159281
[epoch5, step227]: loss 3.421961
[epoch5, step228]: loss 28.417767
[epoch5, step229]: loss 1.796688
[epoch5, step230]: loss 4.206824
[epoch5, step231]: loss 4.433759
[epoch5, step232]: loss 33.990620
[epoch5, step233]: loss 14.071507
[epoch5, step234]: loss 11.324838
[epoch5, step235]: loss 2.071751
[epoch5, step236]: loss 5.513306
[epoch5, step237]: loss 13.866297
[epoch5, step238]: loss 3.370072
[epoch5, step239]: loss 11.647498
[epoch5, step240]: loss 2.898485
[epoch5, step241]: loss 16.347116
[epoch5, step242]: loss 17.004303
[epoch5, step243]: loss 27.621033
[epoch5, step244]: loss 3.581198
[epoch5, step245]: loss 12.750337
[epoch5, step246]: loss 10.290190
[epoch5, step247]: loss 13.046541
[epoch5, step248]: loss 13.335407
[epoch5, step249]: loss 24.997169
[epoch5, step250]: loss 19.834637
[epoch5, step251]: loss 3.641581
[epoch5, step252]: loss 7.330720
[epoch5, step253]: loss 5.837390
[epoch5, step254]: loss 3.871255
[epoch5, step255]: loss 20.498970
[epoch5, step256]: loss 1.484495
[epoch5, step257]: loss 1.379672
[epoch5, step258]: loss 3.886549
[epoch5, step259]: loss 2.577147
[epoch5, step260]: loss 2.826418
[epoch5, step261]: loss 15.596063
[epoch5, step262]: loss 8.166563
[epoch5, step263]: loss 18.866062
[epoch5, step264]: loss 3.900391
[epoch5, step265]: loss 10.241064
[epoch5, step266]: loss 21.605448
[epoch5, step267]: loss 4.377293
[epoch5, step268]: loss 10.517261
[epoch5, step269]: loss 12.692919
[epoch5, step270]: loss 8.444886
[epoch5, step271]: loss 2.454255
[epoch5, step272]: loss 3.069943
[epoch5, step273]: loss 2.055832
[epoch5, step274]: loss 5.711621
[epoch5, step275]: loss 1.654927
[epoch5, step276]: loss 28.725395
[epoch5, step277]: loss 13.585261
[epoch5, step278]: loss 13.207462
[epoch5, step279]: loss 3.712241
[epoch5, step280]: loss 2.550768
[epoch5, step281]: loss 6.779608
[epoch5, step282]: loss 38.825504
[epoch5, step283]: loss 19.150911
[epoch5, step284]: loss 18.752222
[epoch5, step285]: loss 5.580837
[epoch5, step286]: loss 9.489637
[epoch5, step287]: loss 2.822493
[epoch5, step288]: loss 8.309877
[epoch5, step289]: loss 7.591576
[epoch5, step290]: loss 6.212691
[epoch5, step291]: loss 17.796621
[epoch5, step292]: loss 3.898628
[epoch5, step293]: loss 16.045143
[epoch5, step294]: loss 3.304497
[epoch5, step295]: loss 5.982151
[epoch5, step296]: loss 5.483224
[epoch5, step297]: loss 1.641566
[epoch5, step298]: loss 14.832333
[epoch5, step299]: loss 10.721535
[epoch5, step300]: loss 8.602950
[epoch5, step301]: loss 6.607558
[epoch5, step302]: loss 7.893599
[epoch5, step303]: loss 5.602551
[epoch5, step304]: loss 13.803688
[epoch5, step305]: loss 10.833205
[epoch5, step306]: loss 17.936630
[epoch5, step307]: loss 9.052320
[epoch5, step308]: loss 3.675747
[epoch5, step309]: loss 2.073527
[epoch5, step310]: loss 9.236388
[epoch5, step311]: loss 8.302869
[epoch5, step312]: loss 2.850512
[epoch5, step313]: loss 8.414483
[epoch5, step314]: loss 16.056925
[epoch5, step315]: loss 9.329336
[epoch5, step316]: loss 11.219232
[epoch5, step317]: loss 9.604126
[epoch5, step318]: loss 4.128477
[epoch5, step319]: loss 4.244431
[epoch5, step320]: loss 2.591847
[epoch5, step321]: loss 6.431853
[epoch5, step322]: loss 31.519033
[epoch5, step323]: loss 26.749969
[epoch5, step324]: loss 3.887648
[epoch5, step325]: loss 8.112162
[epoch5, step326]: loss 2.179383
[epoch5, step327]: loss 2.785492
[epoch5, step328]: loss 1.645656
[epoch5, step329]: loss 3.097422
[epoch5, step330]: loss 22.384901
[epoch5, step331]: loss 16.536150
[epoch5, step332]: loss 1.690336
[epoch5, step333]: loss 10.623096
[epoch5, step334]: loss 12.768021
[epoch5, step335]: loss 10.208035
[epoch5, step336]: loss 3.073297
[epoch5, step337]: loss 16.415373
[epoch5, step338]: loss 1.929114
[epoch5, step339]: loss 22.023565
[epoch5, step340]: loss 30.699043
[epoch5, step341]: loss 2.075482
[epoch5, step342]: loss 7.609470
[epoch5, step343]: loss 3.206180
[epoch5, step344]: loss 23.201296
[epoch5, step345]: loss 2.322155
[epoch5, step346]: loss 8.716018
[epoch5, step347]: loss 6.224236
[epoch5, step348]: loss 10.038238
[epoch5, step349]: loss 11.290735
[epoch5, step350]: loss 12.069615
[epoch5, step351]: loss 1.540433
[epoch5, step352]: loss 2.606754
[epoch5, step353]: loss 10.424563
[epoch5, step354]: loss 17.360340
[epoch5, step355]: loss 30.402271
[epoch5, step356]: loss 1.862115
[epoch5, step357]: loss 12.520000
[epoch5, step358]: loss 6.463033
[epoch5, step359]: loss 3.067147
[epoch5, step360]: loss 9.125918
[epoch5, step361]: loss 7.222008
[epoch5, step362]: loss 30.493818
[epoch5, step363]: loss 9.191020
[epoch5, step364]: loss 18.323589
[epoch5, step365]: loss 4.114629
[epoch5, step366]: loss 10.770668
[epoch5, step367]: loss 2.138978
[epoch5, step368]: loss 3.079919
[epoch5, step369]: loss 2.532549
[epoch5, step370]: loss 4.276381
[epoch5, step371]: loss 1.446211
[epoch5, step372]: loss 8.782996
[epoch5, step373]: loss 1.688626
[epoch5, step374]: loss 10.039021
[epoch5, step375]: loss 1.696147
[epoch5, step376]: loss 12.399492
[epoch5, step377]: loss 4.852419
[epoch5, step378]: loss 10.842061
[epoch5, step379]: loss 3.972960
[epoch5, step380]: loss 4.139791
[epoch5, step381]: loss 26.344355
[epoch5, step382]: loss 11.532752
[epoch5, step383]: loss 9.498349
[epoch5, step384]: loss 21.339178
[epoch5, step385]: loss 3.648720
[epoch5, step386]: loss 16.705282
[epoch5, step387]: loss 20.181124
[epoch5, step388]: loss 17.497246
[epoch5, step389]: loss 4.591520
[epoch5, step390]: loss 2.032368
[epoch5, step391]: loss 1.895441
[epoch5, step392]: loss 1.962567
[epoch5, step393]: loss 20.212389
[epoch5, step394]: loss 13.584769
[epoch5, step395]: loss 3.653958
[epoch5, step396]: loss 9.743645
[epoch5, step397]: loss 6.297421
[epoch5, step398]: loss 11.370474
[epoch5, step399]: loss 8.636740
[epoch5, step400]: loss 8.779102
[epoch5, step401]: loss 3.443220
[epoch5, step402]: loss 5.223733
[epoch5, step403]: loss 5.412021
[epoch5, step404]: loss 4.906943
[epoch5, step405]: loss 14.699230
[epoch5, step406]: loss 1.565448
[epoch5, step407]: loss 14.127808
[epoch5, step408]: loss 2.314009
[epoch5, step409]: loss 18.020044
[epoch5, step410]: loss 38.042191
[epoch5, step411]: loss 3.196334
[epoch5, step412]: loss 1.666503
[epoch5, step413]: loss 8.630877
[epoch5, step414]: loss 31.626736
[epoch5, step415]: loss 4.831964
[epoch5, step416]: loss 25.200350
[epoch5, step417]: loss 2.696660
[epoch5, step418]: loss 13.054509
[epoch5, step419]: loss 2.251071
[epoch5, step420]: loss 2.241585
[epoch5, step421]: loss 11.539515
[epoch5, step422]: loss 3.660739
[epoch5, step423]: loss 12.265800
[epoch5, step424]: loss 16.229652
[epoch5, step425]: loss 12.483602
[epoch5, step426]: loss 11.354230
[epoch5, step427]: loss 2.202505
[epoch5, step428]: loss 9.680383
[epoch5, step429]: loss 9.728551
[epoch5, step430]: loss 3.705746
[epoch5, step431]: loss 10.526155
[epoch5, step432]: loss 4.729600
[epoch5, step433]: loss 2.338453
[epoch5, step434]: loss 1.589542
[epoch5, step435]: loss 13.875154
[epoch5, step436]: loss 10.364549
[epoch5, step437]: loss 8.491442
[epoch5, step438]: loss 21.170389
[epoch5, step439]: loss 31.590961
[epoch5, step440]: loss 3.507976
[epoch5, step441]: loss 2.867932
[epoch5, step442]: loss 1.612682
[epoch5, step443]: loss 2.890602
[epoch5, step444]: loss 3.336447
[epoch5, step445]: loss 8.586905
[epoch5, step446]: loss 10.605007
[epoch5, step447]: loss 3.096166
[epoch5, step448]: loss 3.482573
[epoch5, step449]: loss 13.154122
[epoch5, step450]: loss 14.544176
[epoch5, step451]: loss 4.272339
[epoch5, step452]: loss 5.005302
[epoch5, step453]: loss 10.672988
[epoch5, step454]: loss 2.333277
[epoch5, step455]: loss 1.937867
[epoch5, step456]: loss 14.999716
[epoch5, step457]: loss 11.607017
[epoch5, step458]: loss 1.437665
[epoch5, step459]: loss 3.849863
[epoch5, step460]: loss 2.438555
[epoch5, step461]: loss 17.138926
[epoch5, step462]: loss 1.923825
[epoch5, step463]: loss 2.778372
[epoch5, step464]: loss 8.641576
[epoch5, step465]: loss 6.361905
[epoch5, step466]: loss 18.477766
[epoch5, step467]: loss 26.926687
[epoch5, step468]: loss 8.806769
[epoch5, step469]: loss 12.154749
[epoch5, step470]: loss 4.483296
[epoch5, step471]: loss 4.217514
[epoch5, step472]: loss 3.798340
[epoch5, step473]: loss 4.401231
[epoch5, step474]: loss 5.810616
[epoch5, step475]: loss 11.886535
[epoch5, step476]: loss 2.459748
[epoch5, step477]: loss 1.767386
[epoch5, step478]: loss 4.328274
[epoch5, step479]: loss 20.674192
[epoch5, step480]: loss 3.675446
[epoch5, step481]: loss 3.145632
[epoch5, step482]: loss 6.409072
[epoch5, step483]: loss 1.672604
[epoch5, step484]: loss 2.240551
[epoch5, step485]: loss 22.924000
[epoch5, step486]: loss 11.132109
[epoch5, step487]: loss 18.521029
[epoch5, step488]: loss 8.736641
[epoch5, step489]: loss 12.342385
[epoch5, step490]: loss 16.131668
[epoch5, step491]: loss 23.530134
[epoch5, step492]: loss 17.600361
[epoch5, step493]: loss 1.480084
[epoch5, step494]: loss 2.107244
[epoch5, step495]: loss 5.857366
[epoch5, step496]: loss 13.947737
[epoch5, step497]: loss 6.661014
[epoch5, step498]: loss 6.054328
[epoch5, step499]: loss 2.197838
[epoch5, step500]: loss 20.584099
[epoch5, step501]: loss 2.072480
[epoch5, step502]: loss 3.234591
[epoch5, step503]: loss 3.677967
[epoch5, step504]: loss 23.289043
[epoch5, step505]: loss 13.103158
[epoch5, step506]: loss 3.123265
[epoch5, step507]: loss 4.144014
[epoch5, step508]: loss 3.239297
[epoch5, step509]: loss 4.199482
[epoch5, step510]: loss 5.234396
[epoch5, step511]: loss 2.304131
[epoch5, step512]: loss 11.557562
[epoch5, step513]: loss 3.611641
[epoch5, step514]: loss 5.806463
[epoch5, step515]: loss 4.717251
[epoch5, step516]: loss 6.024921
[epoch5, step517]: loss 3.012408
[epoch5, step518]: loss 35.482590
[epoch5, step519]: loss 15.937849
[epoch5, step520]: loss 36.975842
[epoch5, step521]: loss 3.054142
[epoch5, step522]: loss 3.058758
[epoch5, step523]: loss 10.062677
[epoch5, step524]: loss 21.411739
[epoch5, step525]: loss 11.392410
[epoch5, step526]: loss 21.056910
[epoch5, step527]: loss 2.383220
[epoch5, step528]: loss 11.567409
[epoch5, step529]: loss 10.190946
[epoch5, step530]: loss 1.543975
[epoch5, step531]: loss 13.718858
[epoch5, step532]: loss 10.988099
[epoch5, step533]: loss 16.829704
[epoch5, step534]: loss 16.554861
[epoch5, step535]: loss 29.465128
[epoch5, step536]: loss 7.333613
[epoch5, step537]: loss 1.653307
[epoch5, step538]: loss 26.024021
[epoch5, step539]: loss 1.854766
[epoch5, step540]: loss 14.053183
[epoch5, step541]: loss 2.578785
[epoch5, step542]: loss 11.551908
[epoch5, step543]: loss 10.183189
[epoch5, step544]: loss 1.218933
[epoch5, step545]: loss 21.714340
[epoch5, step546]: loss 3.027565
[epoch5, step547]: loss 5.056962
[epoch5, step548]: loss 8.776671
[epoch5, step549]: loss 3.127659
[epoch5, step550]: loss 12.656668
[epoch5, step551]: loss 2.211772
[epoch5, step552]: loss 1.676082
[epoch5, step553]: loss 6.530380
[epoch5, step554]: loss 19.038599
[epoch5, step555]: loss 3.177066
[epoch5, step556]: loss 25.342434
[epoch5, step557]: loss 3.911028
[epoch5, step558]: loss 1.838871
[epoch5, step559]: loss 5.973636
[epoch5, step560]: loss 1.941518
[epoch5, step561]: loss 11.987749
[epoch5, step562]: loss 5.094028
[epoch5, step563]: loss 16.432556
[epoch5, step564]: loss 9.081315
[epoch5, step565]: loss 2.825792
[epoch5, step566]: loss 9.562676
[epoch5, step567]: loss 1.958652
[epoch5, step568]: loss 1.790428
[epoch5, step569]: loss 19.902988
[epoch5, step570]: loss 1.656040
[epoch5, step571]: loss 11.390560
[epoch5, step572]: loss 1.481315
[epoch5, step573]: loss 12.259923
[epoch5, step574]: loss 2.416933
[epoch5, step575]: loss 9.495092
[epoch5, step576]: loss 4.692601
[epoch5, step577]: loss 10.176105
[epoch5, step578]: loss 3.520566
[epoch5, step579]: loss 5.155898
[epoch5, step580]: loss 5.070698
[epoch5, step581]: loss 2.849697
[epoch5, step582]: loss 2.858326
[epoch5, step583]: loss 9.854474
[epoch5, step584]: loss 18.950123
[epoch5, step585]: loss 13.957105
[epoch5, step586]: loss 12.263657
[epoch5, step587]: loss 7.435248
[epoch5, step588]: loss 19.046667
[epoch5, step589]: loss 16.129974
[epoch5, step590]: loss 2.935185
[epoch5, step591]: loss 4.013838
[epoch5, step592]: loss 2.321235
[epoch5, step593]: loss 3.444099
[epoch5, step594]: loss 12.654505
[epoch5, step595]: loss 23.683662
[epoch5, step596]: loss 5.071959
[epoch5, step597]: loss 11.913310
[epoch5, step598]: loss 11.117409
[epoch5, step599]: loss 22.703129
[epoch5, step600]: loss 22.090073
[epoch5, step601]: loss 17.719805
[epoch5, step602]: loss 8.312939
[epoch5, step603]: loss 1.812152
[epoch5, step604]: loss 9.486264
[epoch5, step605]: loss 1.574975
[epoch5, step606]: loss 3.049702
[epoch5, step607]: loss 14.456362
[epoch5, step608]: loss 12.145934
[epoch5, step609]: loss 7.003077
[epoch5, step610]: loss 3.523443
[epoch5, step611]: loss 2.093751
[epoch5, step612]: loss 10.568985
[epoch5, step613]: loss 21.385916
[epoch5, step614]: loss 2.473117
[epoch5, step615]: loss 21.700369
[epoch5, step616]: loss 18.215130
[epoch5, step617]: loss 6.484198
[epoch5, step618]: loss 20.241096
[epoch5, step619]: loss 16.250412
[epoch5, step620]: loss 2.184988
[epoch5, step621]: loss 7.137306
[epoch5, step622]: loss 16.063808
[epoch5, step623]: loss 8.580824
[epoch5, step624]: loss 5.270275
[epoch5, step625]: loss 2.719595
[epoch5, step626]: loss 37.505363
[epoch5, step627]: loss 2.571796
[epoch5, step628]: loss 7.171748
[epoch5, step629]: loss 15.289886
[epoch5, step630]: loss 3.462823
[epoch5, step631]: loss 9.190651
[epoch5, step632]: loss 2.298993
[epoch5, step633]: loss 2.992430
[epoch5, step634]: loss 19.433750
[epoch5, step635]: loss 6.059004
[epoch5, step636]: loss 9.361199
[epoch5, step637]: loss 16.352371
[epoch5, step638]: loss 2.486112
[epoch5, step639]: loss 8.694128
[epoch5, step640]: loss 1.910478
[epoch5, step641]: loss 1.999292
[epoch5, step642]: loss 6.511155
[epoch5, step643]: loss 4.033523
[epoch5, step644]: loss 11.632300
[epoch5, step645]: loss 18.403387
[epoch5, step646]: loss 4.850223
[epoch5, step647]: loss 3.836231
[epoch5, step648]: loss 13.647922
[epoch5, step649]: loss 43.950447
[epoch5, step650]: loss 19.461462
[epoch5, step651]: loss 10.336095
[epoch5, step652]: loss 1.692349
[epoch5, step653]: loss 21.987997
[epoch5, step654]: loss 2.356927
[epoch5, step655]: loss 1.986906
[epoch5, step656]: loss 1.639097
[epoch5, step657]: loss 1.701585
[epoch5, step658]: loss 2.574065
[epoch5, step659]: loss 22.763552
[epoch5, step660]: loss 23.901960
[epoch5, step661]: loss 10.655697
[epoch5, step662]: loss 2.135485
[epoch5, step663]: loss 11.416244
[epoch5, step664]: loss 10.248174
[epoch5, step665]: loss 9.035158
[epoch5, step666]: loss 7.106879
[epoch5, step667]: loss 1.998093
[epoch5, step668]: loss 5.867093
[epoch5, step669]: loss 3.965855
[epoch5, step670]: loss 3.191121
[epoch5, step671]: loss 11.017053
[epoch5, step672]: loss 3.380216
[epoch5, step673]: loss 2.259879
[epoch5, step674]: loss 17.068316
[epoch5, step675]: loss 16.003273
[epoch5, step676]: loss 3.216631
[epoch5, step677]: loss 11.278620
[epoch5, step678]: loss 2.267734
[epoch5, step679]: loss 7.356708
[epoch5, step680]: loss 2.941043
[epoch5, step681]: loss 3.542922
[epoch5, step682]: loss 3.850549
[epoch5, step683]: loss 6.795148
[epoch5, step684]: loss 8.650689
[epoch5, step685]: loss 3.487025
[epoch5, step686]: loss 1.247771
[epoch5, step687]: loss 17.566748
[epoch5, step688]: loss 11.143242
[epoch5, step689]: loss 5.870410
[epoch5, step690]: loss 3.997887
[epoch5, step691]: loss 4.554572
[epoch5, step692]: loss 8.332809
[epoch5, step693]: loss 2.551576
[epoch5, step694]: loss 10.121840
[epoch5, step695]: loss 2.573930
[epoch5, step696]: loss 11.430922
[epoch5, step697]: loss 21.790697
[epoch5, step698]: loss 10.469910
[epoch5, step699]: loss 1.380835
[epoch5, step700]: loss 19.357443
[epoch5, step701]: loss 12.391994
[epoch5, step702]: loss 7.083005
[epoch5, step703]: loss 7.040908
[epoch5, step704]: loss 22.456802
[epoch5, step705]: loss 3.477265
[epoch5, step706]: loss 2.415653
[epoch5, step707]: loss 1.457286
[epoch5, step708]: loss 5.212037
[epoch5, step709]: loss 9.349751
[epoch5, step710]: loss 5.614234
[epoch5, step711]: loss 3.626270
[epoch5, step712]: loss 1.167734
[epoch5, step713]: loss 3.370318
[epoch5, step714]: loss 3.699572
[epoch5, step715]: loss 1.594567
[epoch5, step716]: loss 9.081574
[epoch5, step717]: loss 1.692316
[epoch5, step718]: loss 3.461359
[epoch5, step719]: loss 6.284006
[epoch5, step720]: loss 15.764772
[epoch5, step721]: loss 24.185770
[epoch5, step722]: loss 15.416644
[epoch5, step723]: loss 11.398999
[epoch5, step724]: loss 2.258164
[epoch5, step725]: loss 12.185338
[epoch5, step726]: loss 11.755222
[epoch5, step727]: loss 9.723214
[epoch5, step728]: loss 9.757344
[epoch5, step729]: loss 10.064940
[epoch5, step730]: loss 10.761358
[epoch5, step731]: loss 2.815451
[epoch5, step732]: loss 1.469464
[epoch5, step733]: loss 4.448974
[epoch5, step734]: loss 1.827045
[epoch5, step735]: loss 1.524035
[epoch5, step736]: loss 2.244884
[epoch5, step737]: loss 11.404683
[epoch5, step738]: loss 17.154245
[epoch5, step739]: loss 8.657346
[epoch5, step740]: loss 14.280991
[epoch5, step741]: loss 4.156387
[epoch5, step742]: loss 9.940492
[epoch5, step743]: loss 0.995718
[epoch5, step744]: loss 3.281095
[epoch5, step745]: loss 2.478029
[epoch5, step746]: loss 4.304399
[epoch5, step747]: loss 4.737527
[epoch5, step748]: loss 24.093407
[epoch5, step749]: loss 2.397537
[epoch5, step750]: loss 14.603635
[epoch5, step751]: loss 1.941029
[epoch5, step752]: loss 5.610701
[epoch5, step753]: loss 17.472452
[epoch5, step754]: loss 2.118752
[epoch5, step755]: loss 1.368506
[epoch5, step756]: loss 25.258955
[epoch5, step757]: loss 2.227714
[epoch5, step758]: loss 2.336791
[epoch5, step759]: loss 3.413917
[epoch5, step760]: loss 6.486002
[epoch5, step761]: loss 6.064521
[epoch5, step762]: loss 2.783717
[epoch5, step763]: loss 4.319712
[epoch5, step764]: loss 2.214983
[epoch5, step765]: loss 15.615829
[epoch5, step766]: loss 12.840997
[epoch5, step767]: loss 9.683787
[epoch5, step768]: loss 2.521997
[epoch5, step769]: loss 19.741941
[epoch5, step770]: loss 5.584396
[epoch5, step771]: loss 17.725210
[epoch5, step772]: loss 8.185544
[epoch5, step773]: loss 2.993303
[epoch5, step774]: loss 14.544051
[epoch5, step775]: loss 3.559020
[epoch5, step776]: loss 3.040281
[epoch5, step777]: loss 5.447793
[epoch5, step778]: loss 1.980734
[epoch5, step779]: loss 7.922823
[epoch5, step780]: loss 8.558330
[epoch5, step781]: loss 17.185186
[epoch5, step782]: loss 2.109002
[epoch5, step783]: loss 1.876460
[epoch5, step784]: loss 7.997347
[epoch5, step785]: loss 1.483087
[epoch5, step786]: loss 2.748264
[epoch5, step787]: loss 2.990764
[epoch5, step788]: loss 20.168024
[epoch5, step789]: loss 2.741949
[epoch5, step790]: loss 2.402464
[epoch5, step791]: loss 24.440649
[epoch5, step792]: loss 3.642386
[epoch5, step793]: loss 2.561750
[epoch5, step794]: loss 3.733072
[epoch5, step795]: loss 11.038038
[epoch5, step796]: loss 15.406576
[epoch5, step797]: loss 2.495204
[epoch5, step798]: loss 2.620661
[epoch5, step799]: loss 4.485831
[epoch5, step800]: loss 4.528401
[epoch5, step801]: loss 3.818480
[epoch5, step802]: loss 4.289495
[epoch5, step803]: loss 4.512896
[epoch5, step804]: loss 16.933350
[epoch5, step805]: loss 2.669141
[epoch5, step806]: loss 1.742034
[epoch5, step807]: loss 2.902264
[epoch5, step808]: loss 1.817388
[epoch5, step809]: loss 1.762676
[epoch5, step810]: loss 2.273859
[epoch5, step811]: loss 3.733004
[epoch5, step812]: loss 4.498503
[epoch5, step813]: loss 6.687094
[epoch5, step814]: loss 1.860514
[epoch5, step815]: loss 7.182117
[epoch5, step816]: loss 9.307677
[epoch5, step817]: loss 8.369350
[epoch5, step818]: loss 5.723639
[epoch5, step819]: loss 12.231293
[epoch5, step820]: loss 6.228816
[epoch5, step821]: loss 12.122274
[epoch5, step822]: loss 1.753635
[epoch5, step823]: loss 3.547503
[epoch5, step824]: loss 3.784823
[epoch5, step825]: loss 3.825166
[epoch5, step826]: loss 7.569227
[epoch5, step827]: loss 5.759636
[epoch5, step828]: loss 9.121705
[epoch5, step829]: loss 14.045850
[epoch5, step830]: loss 7.803771
[epoch5, step831]: loss 3.265962
[epoch5, step832]: loss 5.515724
[epoch5, step833]: loss 15.457250
[epoch5, step834]: loss 9.809905
[epoch5, step835]: loss 1.831960
[epoch5, step836]: loss 5.097493
[epoch5, step837]: loss 7.130394
[epoch5, step838]: loss 1.530191
[epoch5, step839]: loss 11.022776
[epoch5, step840]: loss 2.993571
[epoch5, step841]: loss 10.480267
[epoch5, step842]: loss 10.661848
[epoch5, step843]: loss 18.578098
[epoch5, step844]: loss 10.617334
[epoch5, step845]: loss 11.961446
[epoch5, step846]: loss 18.442814
[epoch5, step847]: loss 23.203428
[epoch5, step848]: loss 10.514662
[epoch5, step849]: loss 14.132675
[epoch5, step850]: loss 4.323257
[epoch5, step851]: loss 8.906617
[epoch5, step852]: loss 8.984194
[epoch5, step853]: loss 12.336325
[epoch5, step854]: loss 2.747193
[epoch5, step855]: loss 1.981246
[epoch5, step856]: loss 8.538738
[epoch5, step857]: loss 3.907723
[epoch5, step858]: loss 16.906715
[epoch5, step859]: loss 6.813364
[epoch5, step860]: loss 27.484266
[epoch5, step861]: loss 18.214556
[epoch5, step862]: loss 1.839946
[epoch5, step863]: loss 8.951819
[epoch5, step864]: loss 2.869431
[epoch5, step865]: loss 1.247107
[epoch5, step866]: loss 1.926273
[epoch5, step867]: loss 4.694028
[epoch5, step868]: loss 3.283303
[epoch5, step869]: loss 3.986088
[epoch5, step870]: loss 14.033706
[epoch5, step871]: loss 11.889152
[epoch5, step872]: loss 22.011042
[epoch5, step873]: loss 15.290526
[epoch5, step874]: loss 2.805849
[epoch5, step875]: loss 8.252581
[epoch5, step876]: loss 21.432779
[epoch5, step877]: loss 10.129062
[epoch5, step878]: loss 9.294730
[epoch5, step879]: loss 1.423757
[epoch5, step880]: loss 10.742435
[epoch5, step881]: loss 7.107540
[epoch5, step882]: loss 9.682614
[epoch5, step883]: loss 14.000764
[epoch5, step884]: loss 1.702125
[epoch5, step885]: loss 11.474615
[epoch5, step886]: loss 1.185687
[epoch5, step887]: loss 2.303026
[epoch5, step888]: loss 11.471121
[epoch5, step889]: loss 4.316378
[epoch5, step890]: loss 3.484229
[epoch5, step891]: loss 3.568747
[epoch5, step892]: loss 4.423370
[epoch5, step893]: loss 1.972305
[epoch5, step894]: loss 7.817501
[epoch5, step895]: loss 17.108463
[epoch5, step896]: loss 1.884759
[epoch5, step897]: loss 13.284200
[epoch5, step898]: loss 11.234186
[epoch5, step899]: loss 12.468266
[epoch5, step900]: loss 8.990041
[epoch5, step901]: loss 3.523755
[epoch5, step902]: loss 22.972139
[epoch5, step903]: loss 2.255128
[epoch5, step904]: loss 11.786147
[epoch5, step905]: loss 5.910624
[epoch5, step906]: loss 37.571480
[epoch5, step907]: loss 9.032290
[epoch5, step908]: loss 2.952223
[epoch5, step909]: loss 9.716101
[epoch5, step910]: loss 20.826437
[epoch5, step911]: loss 1.304680
[epoch5, step912]: loss 26.981646
[epoch5, step913]: loss 2.753882
[epoch5, step914]: loss 2.094901
[epoch5, step915]: loss 21.970350
[epoch5, step916]: loss 6.071223
[epoch5, step917]: loss 8.924265
[epoch5, step918]: loss 21.579414
[epoch5, step919]: loss 11.109107
[epoch5, step920]: loss 21.872566
[epoch5, step921]: loss 4.938116
[epoch5, step922]: loss 3.535922
[epoch5, step923]: loss 10.667368
[epoch5, step924]: loss 5.411227
[epoch5, step925]: loss 6.572811
[epoch5, step926]: loss 3.973866
[epoch5, step927]: loss 6.099570
[epoch5, step928]: loss 13.265343
[epoch5, step929]: loss 19.943924
[epoch5, step930]: loss 1.653871
[epoch5, step931]: loss 16.000275
[epoch5, step932]: loss 9.844497
[epoch5, step933]: loss 18.119625
[epoch5, step934]: loss 1.306215
[epoch5, step935]: loss 1.697260
[epoch5, step936]: loss 3.123250
[epoch5, step937]: loss 9.048441
[epoch5, step938]: loss 6.560895
[epoch5, step939]: loss 5.099423
[epoch5, step940]: loss 3.732597
[epoch5, step941]: loss 2.569132
[epoch5, step942]: loss 1.637457
[epoch5, step943]: loss 3.059081
[epoch5, step944]: loss 2.627145
[epoch5, step945]: loss 2.745565
[epoch5, step946]: loss 3.464636
[epoch5, step947]: loss 7.630832
[epoch5, step948]: loss 11.093362
[epoch5, step949]: loss 23.131111
[epoch5, step950]: loss 3.101108
[epoch5, step951]: loss 9.112698
[epoch5, step952]: loss 1.577199
[epoch5, step953]: loss 2.141925
[epoch5, step954]: loss 4.399035
[epoch5, step955]: loss 2.965955
[epoch5, step956]: loss 1.712562
[epoch5, step957]: loss 1.496795
[epoch5, step958]: loss 3.207764
[epoch5, step959]: loss 2.232956
[epoch5, step960]: loss 11.434744
[epoch5, step961]: loss 1.933393
[epoch5, step962]: loss 2.865892
[epoch5, step963]: loss 3.637614
[epoch5, step964]: loss 9.205063
[epoch5, step965]: loss 3.412641
[epoch5, step966]: loss 2.456378
[epoch5, step967]: loss 2.263428
[epoch5, step968]: loss 3.284740
[epoch5, step969]: loss 3.095403
[epoch5, step970]: loss 8.579647
[epoch5, step971]: loss 24.534033
[epoch5, step972]: loss 1.807218
[epoch5, step973]: loss 18.244019
[epoch5, step974]: loss 18.382357
[epoch5, step975]: loss 3.311491
[epoch5, step976]: loss 15.717563
[epoch5, step977]: loss 7.155535
[epoch5, step978]: loss 9.796341
[epoch5, step979]: loss 28.171749
[epoch5, step980]: loss 1.771392
[epoch5, step981]: loss 6.867119
[epoch5, step982]: loss 17.268297
[epoch5, step983]: loss 10.267634
[epoch5, step984]: loss 12.473522
[epoch5, step985]: loss 8.513558
[epoch5, step986]: loss 10.392364
[epoch5, step987]: loss 11.753834
[epoch5, step988]: loss 3.264615
[epoch5, step989]: loss 10.328680
[epoch5, step990]: loss 19.849024
[epoch5, step991]: loss 22.797331
[epoch5, step992]: loss 3.128405
[epoch5, step993]: loss 12.253985
[epoch5, step994]: loss 5.228212
[epoch5, step995]: loss 6.100565
[epoch5, step996]: loss 2.902430
[epoch5, step997]: loss 15.458320
[epoch5, step998]: loss 2.534867
[epoch5, step999]: loss 4.109580
[epoch5, step1000]: loss 3.714044
[epoch5, step1001]: loss 3.811471
[epoch5, step1002]: loss 27.113201
[epoch5, step1003]: loss 18.064985
[epoch5, step1004]: loss 14.036386
[epoch5, step1005]: loss 10.622231
[epoch5, step1006]: loss 2.625716
[epoch5, step1007]: loss 16.119097
[epoch5, step1008]: loss 10.865374
[epoch5, step1009]: loss 3.099720
[epoch5, step1010]: loss 6.929316
[epoch5, step1011]: loss 13.435334
[epoch5, step1012]: loss 2.552215
[epoch5, step1013]: loss 3.517980
[epoch5, step1014]: loss 2.518706
[epoch5, step1015]: loss 2.581594
[epoch5, step1016]: loss 3.194844
[epoch5, step1017]: loss 11.448105
[epoch5, step1018]: loss 1.601554
[epoch5, step1019]: loss 1.517715
[epoch5, step1020]: loss 2.020990
[epoch5, step1021]: loss 19.174452
[epoch5, step1022]: loss 3.898159
[epoch5, step1023]: loss 1.781709
[epoch5, step1024]: loss 5.742508
[epoch5, step1025]: loss 1.482744
[epoch5, step1026]: loss 5.038955
[epoch5, step1027]: loss 1.650613
[epoch5, step1028]: loss 5.119108
[epoch5, step1029]: loss 2.085218
[epoch5, step1030]: loss 1.233913
[epoch5, step1031]: loss 11.732224
[epoch5, step1032]: loss 25.131895
[epoch5, step1033]: loss 10.131924
[epoch5, step1034]: loss 9.344060
[epoch5, step1035]: loss 1.988725
[epoch5, step1036]: loss 1.990028
[epoch5, step1037]: loss 3.700522
[epoch5, step1038]: loss 2.968826
[epoch5, step1039]: loss 2.409080
[epoch5, step1040]: loss 6.167478
[epoch5, step1041]: loss 8.884330
[epoch5, step1042]: loss 11.003816
[epoch5, step1043]: loss 17.379055
[epoch5, step1044]: loss 10.525572
[epoch5, step1045]: loss 16.143402
[epoch5, step1046]: loss 11.357747
[epoch5, step1047]: loss 9.829638
[epoch5, step1048]: loss 9.510180
[epoch5, step1049]: loss 15.289820
[epoch5, step1050]: loss 15.391797
[epoch5, step1051]: loss 40.983574
[epoch5, step1052]: loss 3.869059
[epoch5, step1053]: loss 1.673185
[epoch5, step1054]: loss 7.363722
[epoch5, step1055]: loss 4.501730
[epoch5, step1056]: loss 9.589727
[epoch5, step1057]: loss 10.750724
[epoch5, step1058]: loss 10.603994
[epoch5, step1059]: loss 3.792141
[epoch5, step1060]: loss 5.648401
[epoch5, step1061]: loss 4.608565
[epoch5, step1062]: loss 18.009804
[epoch5, step1063]: loss 11.123356
[epoch5, step1064]: loss 2.651767
[epoch5, step1065]: loss 1.449070
[epoch5, step1066]: loss 2.668870
[epoch5, step1067]: loss 2.172680
[epoch5, step1068]: loss 26.093748
[epoch5, step1069]: loss 8.905250
[epoch5, step1070]: loss 9.875916
[epoch5, step1071]: loss 3.313444
[epoch5, step1072]: loss 22.759481
[epoch5, step1073]: loss 6.062536
[epoch5, step1074]: loss 14.068347
[epoch5, step1075]: loss 3.688786
[epoch5, step1076]: loss 1.319104
[epoch5, step1077]: loss 25.949051
[epoch5, step1078]: loss 5.097154
[epoch5, step1079]: loss 5.778303
[epoch5, step1080]: loss 9.245384
[epoch5, step1081]: loss 26.923391
[epoch5, step1082]: loss 12.005208
[epoch5, step1083]: loss 11.508621
[epoch5, step1084]: loss 28.165243
[epoch5, step1085]: loss 3.670093
[epoch5, step1086]: loss 7.840539
[epoch5, step1087]: loss 1.726005
[epoch5, step1088]: loss 2.285596
[epoch5, step1089]: loss 15.273640
[epoch5, step1090]: loss 5.358299
[epoch5, step1091]: loss 9.055948
[epoch5, step1092]: loss 1.838236
[epoch5, step1093]: loss 10.862955
[epoch5, step1094]: loss 1.401985
[epoch5, step1095]: loss 25.302563
[epoch5, step1096]: loss 5.636020
[epoch5, step1097]: loss 15.643473
[epoch5, step1098]: loss 4.740520
[epoch5, step1099]: loss 21.978477
[epoch5, step1100]: loss 11.546922
[epoch5, step1101]: loss 10.643455
[epoch5, step1102]: loss 29.056271
[epoch5, step1103]: loss 17.902534
[epoch5, step1104]: loss 7.741028
[epoch5, step1105]: loss 4.793057
[epoch5, step1106]: loss 2.470804
[epoch5, step1107]: loss 2.019318
[epoch5, step1108]: loss 3.250806
[epoch5, step1109]: loss 14.864356
[epoch5, step1110]: loss 5.673638
[epoch5, step1111]: loss 3.380907
[epoch5, step1112]: loss 10.639433
[epoch5, step1113]: loss 1.627469
[epoch5, step1114]: loss 13.374249
[epoch5, step1115]: loss 1.780470
[epoch5, step1116]: loss 3.444038
[epoch5, step1117]: loss 3.768308
[epoch5, step1118]: loss 4.287976
[epoch5, step1119]: loss 13.726149
[epoch5, step1120]: loss 2.289994
[epoch5, step1121]: loss 15.396318
[epoch5, step1122]: loss 1.455269
[epoch5, step1123]: loss 1.321741
[epoch5, step1124]: loss 4.885021
[epoch5, step1125]: loss 13.148034
[epoch5, step1126]: loss 15.599920
[epoch5, step1127]: loss 3.725808
[epoch5, step1128]: loss 10.555914
[epoch5, step1129]: loss 17.568174
[epoch5, step1130]: loss 8.053114
[epoch5, step1131]: loss 8.563869
[epoch5, step1132]: loss 3.672280
[epoch5, step1133]: loss 16.884050
[epoch5, step1134]: loss 3.394470
[epoch5, step1135]: loss 2.751987
[epoch5, step1136]: loss 8.303789
[epoch5, step1137]: loss 4.574188
[epoch5, step1138]: loss 2.793251
[epoch5, step1139]: loss 2.843833
[epoch5, step1140]: loss 9.215784
[epoch5, step1141]: loss 2.916494
[epoch5, step1142]: loss 2.264379
[epoch5, step1143]: loss 11.800179
[epoch5, step1144]: loss 15.924060
[epoch5, step1145]: loss 4.081264
[epoch5, step1146]: loss 3.798514
[epoch5, step1147]: loss 3.479939
[epoch5, step1148]: loss 3.345547
[epoch5, step1149]: loss 1.194006
[epoch5, step1150]: loss 5.795041
[epoch5, step1151]: loss 4.184279
[epoch5, step1152]: loss 2.857717
[epoch5, step1153]: loss 7.767375
[epoch5, step1154]: loss 2.812402
[epoch5, step1155]: loss 5.437986
[epoch5, step1156]: loss 1.706663
[epoch5, step1157]: loss 4.136878
[epoch5, step1158]: loss 21.872652
[epoch5, step1159]: loss 4.704807
[epoch5, step1160]: loss 8.628948
[epoch5, step1161]: loss 18.827101
[epoch5, step1162]: loss 5.142207
[epoch5, step1163]: loss 7.171664
[epoch5, step1164]: loss 2.126031
[epoch5, step1165]: loss 3.162232
[epoch5, step1166]: loss 2.003217
[epoch5, step1167]: loss 6.673098
[epoch5, step1168]: loss 5.089839
[epoch5, step1169]: loss 36.569370
[epoch5, step1170]: loss 26.457329
[epoch5, step1171]: loss 11.370830
[epoch5, step1172]: loss 2.005985
[epoch5, step1173]: loss 16.838617
[epoch5, step1174]: loss 10.542884
[epoch5, step1175]: loss 10.506741
[epoch5, step1176]: loss 9.401249
[epoch5, step1177]: loss 15.340530
[epoch5, step1178]: loss 10.120660
[epoch5, step1179]: loss 3.509174
[epoch5, step1180]: loss 7.638120
[epoch5, step1181]: loss 12.477951
[epoch5, step1182]: loss 12.984240
[epoch5, step1183]: loss 16.587673
[epoch5, step1184]: loss 10.649368
[epoch5, step1185]: loss 4.455921
[epoch5, step1186]: loss 1.812597
[epoch5, step1187]: loss 2.180153
[epoch5, step1188]: loss 13.391054
[epoch5, step1189]: loss 8.968801
[epoch5, step1190]: loss 26.797438
[epoch5, step1191]: loss 27.634287
[epoch5, step1192]: loss 2.895619
[epoch5, step1193]: loss 15.795531
[epoch5, step1194]: loss 2.061312
[epoch5, step1195]: loss 3.744555
[epoch5, step1196]: loss 11.557531
[epoch5, step1197]: loss 16.184994
[epoch5, step1198]: loss 8.251957
[epoch5, step1199]: loss 15.430718
[epoch5, step1200]: loss 10.655560
[epoch5, step1201]: loss 4.131206
[epoch5, step1202]: loss 16.651829
[epoch5, step1203]: loss 3.898210
[epoch5, step1204]: loss 17.490147
[epoch5, step1205]: loss 5.206558
[epoch5, step1206]: loss 1.421386
[epoch5, step1207]: loss 8.226099
[epoch5, step1208]: loss 2.004958
[epoch5, step1209]: loss 12.064789
[epoch5, step1210]: loss 10.856751
[epoch5, step1211]: loss 16.909277
[epoch5, step1212]: loss 17.313025
[epoch5, step1213]: loss 1.887815
[epoch5, step1214]: loss 1.660770
[epoch5, step1215]: loss 4.115862
[epoch5, step1216]: loss 4.029829
[epoch5, step1217]: loss 5.097126
[epoch5, step1218]: loss 5.374535
[epoch5, step1219]: loss 5.327541
[epoch5, step1220]: loss 13.329212
[epoch5, step1221]: loss 3.211798
[epoch5, step1222]: loss 19.022493
[epoch5, step1223]: loss 4.103396
[epoch5, step1224]: loss 9.020679
[epoch5, step1225]: loss 21.876501
[epoch5, step1226]: loss 2.907901
[epoch5, step1227]: loss 9.131339
[epoch5, step1228]: loss 11.662675
[epoch5, step1229]: loss 8.676919
[epoch5, step1230]: loss 15.922696
[epoch5, step1231]: loss 32.704762
[epoch5, step1232]: loss 2.808479
[epoch5, step1233]: loss 5.609028
[epoch5, step1234]: loss 13.812860
[epoch5, step1235]: loss 2.199015
[epoch5, step1236]: loss 1.930783
[epoch5, step1237]: loss 1.812768
[epoch5, step1238]: loss 10.941084
[epoch5, step1239]: loss 12.256807
[epoch5, step1240]: loss 8.738644
[epoch5, step1241]: loss 3.925436
[epoch5, step1242]: loss 7.513363
[epoch5, step1243]: loss 3.051944
[epoch5, step1244]: loss 18.783733
[epoch5, step1245]: loss 8.807823
[epoch5, step1246]: loss 17.672512
[epoch5, step1247]: loss 2.624329
[epoch5, step1248]: loss 30.481884
[epoch5, step1249]: loss 33.478973
[epoch5, step1250]: loss 24.995476
[epoch5, step1251]: loss 7.494249
[epoch5, step1252]: loss 19.978052
[epoch5, step1253]: loss 1.976554
[epoch5, step1254]: loss 4.157897
[epoch5, step1255]: loss 1.974183
[epoch5, step1256]: loss 27.954870
[epoch5, step1257]: loss 5.415172
[epoch5, step1258]: loss 16.136631
[epoch5, step1259]: loss 17.886923
[epoch5, step1260]: loss 2.871595
[epoch5, step1261]: loss 17.460827
[epoch5, step1262]: loss 4.947224
[epoch5, step1263]: loss 4.443157
[epoch5, step1264]: loss 4.835384
[epoch5, step1265]: loss 16.101240
[epoch5, step1266]: loss 2.027824
[epoch5, step1267]: loss 9.827971
[epoch5, step1268]: loss 16.111013
[epoch5, step1269]: loss 2.467777
[epoch5, step1270]: loss 3.793065
[epoch5, step1271]: loss 19.750551
[epoch5, step1272]: loss 5.196289
[epoch5, step1273]: loss 4.892528
[epoch5, step1274]: loss 2.466606
[epoch5, step1275]: loss 2.788614
[epoch5, step1276]: loss 3.351472
[epoch5, step1277]: loss 2.595476
[epoch5, step1278]: loss 19.011822
[epoch5, step1279]: loss 12.858036
[epoch5, step1280]: loss 13.400834
[epoch5, step1281]: loss 7.241940
[epoch5, step1282]: loss 12.002700
[epoch5, step1283]: loss 2.751901
[epoch5, step1284]: loss 13.940418
[epoch5, step1285]: loss 21.398960
[epoch5, step1286]: loss 6.117455
[epoch5, step1287]: loss 2.341264
[epoch5, step1288]: loss 5.821398
[epoch5, step1289]: loss 7.097982
[epoch5, step1290]: loss 18.973545
[epoch5, step1291]: loss 20.026165
[epoch5, step1292]: loss 14.118448
[epoch5, step1293]: loss 7.636339
[epoch5, step1294]: loss 8.873497
[epoch5, step1295]: loss 8.365391
[epoch5, step1296]: loss 11.568429
[epoch5, step1297]: loss 19.450214
[epoch5, step1298]: loss 8.732452
[epoch5, step1299]: loss 3.041110
[epoch5, step1300]: loss 20.424765
[epoch5, step1301]: loss 20.824242
[epoch5, step1302]: loss 2.052835
[epoch5, step1303]: loss 5.995787
[epoch5, step1304]: loss 18.485035
[epoch5, step1305]: loss 19.947613
[epoch5, step1306]: loss 11.907436
[epoch5, step1307]: loss 4.493120
[epoch5, step1308]: loss 2.007787
[epoch5, step1309]: loss 2.385233
[epoch5, step1310]: loss 4.081750
[epoch5, step1311]: loss 26.211201
[epoch5, step1312]: loss 1.850247
[epoch5, step1313]: loss 4.202408
[epoch5, step1314]: loss 10.646661
[epoch5, step1315]: loss 37.484688
[epoch5, step1316]: loss 3.197249
[epoch5, step1317]: loss 1.345515
[epoch5, step1318]: loss 2.216943
[epoch5, step1319]: loss 7.600197
[epoch5, step1320]: loss 2.854930
[epoch5, step1321]: loss 1.344219
[epoch5, step1322]: loss 2.693634
[epoch5, step1323]: loss 6.124964
[epoch5, step1324]: loss 1.588224
[epoch5, step1325]: loss 1.781200
[epoch5, step1326]: loss 5.334971
[epoch5, step1327]: loss 11.604123
[epoch5, step1328]: loss 1.445640
[epoch5, step1329]: loss 1.631886
[epoch5, step1330]: loss 10.723099
[epoch5, step1331]: loss 8.986128
[epoch5, step1332]: loss 8.466928
[epoch5, step1333]: loss 7.801158
[epoch5, step1334]: loss 11.160107
[epoch5, step1335]: loss 1.719202
[epoch5, step1336]: loss 3.356759
[epoch5, step1337]: loss 42.583279
[epoch5, step1338]: loss 10.724111
[epoch5, step1339]: loss 8.556646
[epoch5, step1340]: loss 23.017824
[epoch5, step1341]: loss 7.900635
[epoch5, step1342]: loss 8.290487
[epoch5, step1343]: loss 4.783658
[epoch5, step1344]: loss 2.108788
[epoch5, step1345]: loss 5.176704
[epoch5, step1346]: loss 2.936482
[epoch5, step1347]: loss 16.655523
[epoch5, step1348]: loss 19.658495
[epoch5, step1349]: loss 4.051033
[epoch5, step1350]: loss 4.936930
[epoch5, step1351]: loss 8.613868
[epoch5, step1352]: loss 1.878398
[epoch5, step1353]: loss 6.750113
[epoch5, step1354]: loss 2.353572
[epoch5, step1355]: loss 8.494878
[epoch5, step1356]: loss 8.831777
[epoch5, step1357]: loss 33.968948
[epoch5, step1358]: loss 1.914921
[epoch5, step1359]: loss 2.634942
[epoch5, step1360]: loss 7.759126
[epoch5, step1361]: loss 2.901378
[epoch5, step1362]: loss 3.156419
[epoch5, step1363]: loss 5.405514
[epoch5, step1364]: loss 2.288816
[epoch5, step1365]: loss 28.291565
[epoch5, step1366]: loss 17.623339
[epoch5, step1367]: loss 17.844599
[epoch5, step1368]: loss 9.147404
[epoch5, step1369]: loss 3.980982
[epoch5, step1370]: loss 9.998471
[epoch5, step1371]: loss 13.624737
[epoch5, step1372]: loss 11.381000
[epoch5, step1373]: loss 12.235361
[epoch5, step1374]: loss 4.292841
[epoch5, step1375]: loss 26.278795
[epoch5, step1376]: loss 2.494722
[epoch5, step1377]: loss 2.219791
[epoch5, step1378]: loss 1.852800
[epoch5, step1379]: loss 3.324076
[epoch5, step1380]: loss 22.096130
[epoch5, step1381]: loss 2.092760
[epoch5, step1382]: loss 5.450522
[epoch5, step1383]: loss 2.315525
[epoch5, step1384]: loss 2.864877
[epoch5, step1385]: loss 2.760266
[epoch5, step1386]: loss 6.620631
[epoch5, step1387]: loss 11.456128
[epoch5, step1388]: loss 4.299363
[epoch5, step1389]: loss 9.587973
[epoch5, step1390]: loss 14.083615
[epoch5, step1391]: loss 19.189865
[epoch5, step1392]: loss 8.242698
[epoch5, step1393]: loss 2.781245
[epoch5, step1394]: loss 17.522650
[epoch5, step1395]: loss 2.796458
[epoch5, step1396]: loss 33.335148
[epoch5, step1397]: loss 3.754549
[epoch5, step1398]: loss 17.501255
[epoch5, step1399]: loss 4.465864
[epoch5, step1400]: loss 1.252078
[epoch5, step1401]: loss 2.147258
[epoch5, step1402]: loss 3.574754
[epoch5, step1403]: loss 4.126908
[epoch5, step1404]: loss 6.513345
[epoch5, step1405]: loss 10.824942
[epoch5, step1406]: loss 5.527224
[epoch5, step1407]: loss 2.036901
[epoch5, step1408]: loss 1.647130
[epoch5, step1409]: loss 10.616249
[epoch5, step1410]: loss 15.424967
[epoch5, step1411]: loss 38.329910
[epoch5, step1412]: loss 4.118718
[epoch5, step1413]: loss 1.493628
[epoch5, step1414]: loss 6.178296
[epoch5, step1415]: loss 1.387069
[epoch5, step1416]: loss 3.067564
[epoch5, step1417]: loss 5.959555
[epoch5, step1418]: loss 6.728303
[epoch5, step1419]: loss 27.046816
[epoch5, step1420]: loss 8.320532
[epoch5, step1421]: loss 22.423368
[epoch5, step1422]: loss 8.030804
[epoch5, step1423]: loss 10.404654
[epoch5, step1424]: loss 2.567320
[epoch5, step1425]: loss 5.127189
[epoch5, step1426]: loss 1.657570
[epoch5, step1427]: loss 24.250954
[epoch5, step1428]: loss 1.638404
[epoch5, step1429]: loss 14.043147
[epoch5, step1430]: loss 12.252408
[epoch5, step1431]: loss 6.096955
[epoch5, step1432]: loss 3.241465
[epoch5, step1433]: loss 2.809067
[epoch5, step1434]: loss 10.993990
[epoch5, step1435]: loss 7.973765
[epoch5, step1436]: loss 8.603272
[epoch5, step1437]: loss 3.478117
[epoch5, step1438]: loss 2.682745
[epoch5, step1439]: loss 1.515742
[epoch5, step1440]: loss 7.620740
[epoch5, step1441]: loss 2.539101
[epoch5, step1442]: loss 10.243965
[epoch5, step1443]: loss 20.775919
[epoch5, step1444]: loss 20.496078
[epoch5, step1445]: loss 10.563414
[epoch5, step1446]: loss 6.318305
[epoch5, step1447]: loss 1.582464
[epoch5, step1448]: loss 11.946004
[epoch5, step1449]: loss 2.872831
[epoch5, step1450]: loss 6.444850
[epoch5, step1451]: loss 7.492182
[epoch5, step1452]: loss 1.953023
[epoch5, step1453]: loss 2.621186
[epoch5, step1454]: loss 3.407193
[epoch5, step1455]: loss 3.246455
[epoch5, step1456]: loss 1.964865
[epoch5, step1457]: loss 10.955171
[epoch5, step1458]: loss 4.213630
[epoch5, step1459]: loss 5.265991
[epoch5, step1460]: loss 3.483474
[epoch5, step1461]: loss 4.364435
[epoch5, step1462]: loss 7.597728
[epoch5, step1463]: loss 1.689019
[epoch5, step1464]: loss 9.451635
[epoch5, step1465]: loss 0.954786
[epoch5, step1466]: loss 28.808371
[epoch5, step1467]: loss 1.852076
[epoch5, step1468]: loss 4.721966
[epoch5, step1469]: loss 9.187330
[epoch5, step1470]: loss 9.377899
[epoch5, step1471]: loss 3.332756
[epoch5, step1472]: loss 2.682137
[epoch5, step1473]: loss 7.968118
[epoch5, step1474]: loss 22.461782
[epoch5, step1475]: loss 3.003987
[epoch5, step1476]: loss 15.562088
[epoch5, step1477]: loss 6.764064
[epoch5, step1478]: loss 1.580039
[epoch5, step1479]: loss 16.875954
[epoch5, step1480]: loss 10.720177
[epoch5, step1481]: loss 28.216372
[epoch5, step1482]: loss 11.380294
[epoch5, step1483]: loss 1.699949
[epoch5, step1484]: loss 8.368433
[epoch5, step1485]: loss 4.292026
[epoch5, step1486]: loss 7.719215
[epoch5, step1487]: loss 4.777407
[epoch5, step1488]: loss 9.129288
[epoch5, step1489]: loss 2.676213
[epoch5, step1490]: loss 21.441086
[epoch5, step1491]: loss 11.784615
[epoch5, step1492]: loss 14.414692
[epoch5, step1493]: loss 5.048031
[epoch5, step1494]: loss 2.865223
[epoch5, step1495]: loss 12.950741
[epoch5, step1496]: loss 1.579399
[epoch5, step1497]: loss 10.347842
[epoch5, step1498]: loss 1.823234
[epoch5, step1499]: loss 8.574751
[epoch5, step1500]: loss 29.787764
[epoch5, step1501]: loss 4.941214
[epoch5, step1502]: loss 1.741508
[epoch5, step1503]: loss 18.956688
[epoch5, step1504]: loss 6.471834
[epoch5, step1505]: loss 4.654414
[epoch5, step1506]: loss 4.768722
[epoch5, step1507]: loss 8.870019
[epoch5, step1508]: loss 7.479721
[epoch5, step1509]: loss 17.709478
[epoch5, step1510]: loss 15.211928
[epoch5, step1511]: loss 1.274036
[epoch5, step1512]: loss 19.206516
[epoch5, step1513]: loss 2.722022
[epoch5, step1514]: loss 21.621504
[epoch5, step1515]: loss 4.587942
[epoch5, step1516]: loss 22.703270
[epoch5, step1517]: loss 2.285227
[epoch5, step1518]: loss 17.707272
[epoch5, step1519]: loss 19.734356
[epoch5, step1520]: loss 15.057844
[epoch5, step1521]: loss 3.960738
[epoch5, step1522]: loss 2.431705
[epoch5, step1523]: loss 1.739817
[epoch5, step1524]: loss 16.193554
[epoch5, step1525]: loss 30.377348
[epoch5, step1526]: loss 2.625910
[epoch5, step1527]: loss 11.700048
[epoch5, step1528]: loss 3.569489
[epoch5, step1529]: loss 8.928721
[epoch5, step1530]: loss 7.396251
[epoch5, step1531]: loss 12.761774
[epoch5, step1532]: loss 3.403218
[epoch5, step1533]: loss 4.816529
[epoch5, step1534]: loss 4.255566
[epoch5, step1535]: loss 2.263376
[epoch5, step1536]: loss 2.884865
[epoch5, step1537]: loss 7.620135
[epoch5, step1538]: loss 16.955172
[epoch5, step1539]: loss 5.158538
[epoch5, step1540]: loss 10.997927
[epoch5, step1541]: loss 7.309115
[epoch5, step1542]: loss 1.883644
[epoch5, step1543]: loss 1.601881
[epoch5, step1544]: loss 9.138302
[epoch5, step1545]: loss 10.315980
[epoch5, step1546]: loss 7.250593
[epoch5, step1547]: loss 1.617445
[epoch5, step1548]: loss 8.741338
[epoch5, step1549]: loss 1.438266
[epoch5, step1550]: loss 7.424998
[epoch5, step1551]: loss 8.117473
[epoch5, step1552]: loss 2.565547
[epoch5, step1553]: loss 4.422534
[epoch5, step1554]: loss 3.030456
[epoch5, step1555]: loss 3.661018
[epoch5, step1556]: loss 10.422976
[epoch5, step1557]: loss 26.978994
[epoch5, step1558]: loss 7.454035
[epoch5, step1559]: loss 8.847602
[epoch5, step1560]: loss 1.414970
[epoch5, step1561]: loss 10.465307
[epoch5, step1562]: loss 13.554235
[epoch5, step1563]: loss 3.225353
[epoch5, step1564]: loss 6.849990
[epoch5, step1565]: loss 27.642704
[epoch5, step1566]: loss 2.461660
[epoch5, step1567]: loss 13.909118
[epoch5, step1568]: loss 10.732493
[epoch5, step1569]: loss 5.995619
[epoch5, step1570]: loss 8.961432
[epoch5, step1571]: loss 20.417496
[epoch5, step1572]: loss 10.541466
[epoch5, step1573]: loss 15.361547
[epoch5, step1574]: loss 1.604251
[epoch5, step1575]: loss 11.085499
[epoch5, step1576]: loss 2.225010
[epoch5, step1577]: loss 3.623305
[epoch5, step1578]: loss 22.727283
[epoch5, step1579]: loss 3.602495
[epoch5, step1580]: loss 30.953936
[epoch5, step1581]: loss 23.777678
[epoch5, step1582]: loss 2.473081
[epoch5, step1583]: loss 1.673933
[epoch5, step1584]: loss 1.260396
[epoch5, step1585]: loss 13.534068
[epoch5, step1586]: loss 4.717776
[epoch5, step1587]: loss 18.534298
[epoch5, step1588]: loss 1.468489
[epoch5, step1589]: loss 2.807782
[epoch5, step1590]: loss 3.416288
[epoch5, step1591]: loss 3.467699
[epoch5, step1592]: loss 2.804913
[epoch5, step1593]: loss 2.994024
[epoch5, step1594]: loss 1.494138
[epoch5, step1595]: loss 13.439352
[epoch5, step1596]: loss 1.490034
[epoch5, step1597]: loss 8.170859
[epoch5, step1598]: loss 3.970850
[epoch5, step1599]: loss 19.848890
[epoch5, step1600]: loss 9.371760
[epoch5, step1601]: loss 13.121846
[epoch5, step1602]: loss 7.615474
[epoch5, step1603]: loss 1.937922
[epoch5, step1604]: loss 8.668591
[epoch5, step1605]: loss 21.883041
[epoch5, step1606]: loss 5.894133
[epoch5, step1607]: loss 4.444640
[epoch5, step1608]: loss 3.443570
[epoch5, step1609]: loss 12.883410
[epoch5, step1610]: loss 1.857299
[epoch5, step1611]: loss 4.890449
[epoch5, step1612]: loss 13.759025
[epoch5, step1613]: loss 2.382010
[epoch5, step1614]: loss 2.476056
[epoch5, step1615]: loss 3.809429
[epoch5, step1616]: loss 5.727073
[epoch5, step1617]: loss 4.940551
[epoch5, step1618]: loss 3.067867
[epoch5, step1619]: loss 19.589899
[epoch5, step1620]: loss 8.708733
[epoch5, step1621]: loss 9.032362
[epoch5, step1622]: loss 12.806128
[epoch5, step1623]: loss 5.016037
[epoch5, step1624]: loss 7.086852
[epoch5, step1625]: loss 9.536393
[epoch5, step1626]: loss 3.822204
[epoch5, step1627]: loss 3.181506
[epoch5, step1628]: loss 3.900191
[epoch5, step1629]: loss 3.780604
[epoch5, step1630]: loss 4.471199
[epoch5, step1631]: loss 6.181808
[epoch5, step1632]: loss 2.851032
[epoch5, step1633]: loss 8.261397
[epoch5, step1634]: loss 15.630880
[epoch5, step1635]: loss 25.924147
[epoch5, step1636]: loss 2.218153
[epoch5, step1637]: loss 12.561545
[epoch5, step1638]: loss 9.719068
[epoch5, step1639]: loss 3.304550
[epoch5, step1640]: loss 3.798928
[epoch5, step1641]: loss 3.486978
[epoch5, step1642]: loss 2.239404
[epoch5, step1643]: loss 4.114269
[epoch5, step1644]: loss 4.050699
[epoch5, step1645]: loss 15.078396
[epoch5, step1646]: loss 4.566421
[epoch5, step1647]: loss 13.205917
[epoch5, step1648]: loss 22.743660
[epoch5, step1649]: loss 1.506382
[epoch5, step1650]: loss 1.640850
[epoch5, step1651]: loss 13.262357
[epoch5, step1652]: loss 13.717257
[epoch5, step1653]: loss 23.466375
[epoch5, step1654]: loss 2.641128
[epoch5, step1655]: loss 3.718565
[epoch5, step1656]: loss 8.107527
[epoch5, step1657]: loss 17.902340
[epoch5, step1658]: loss 7.186168
[epoch5, step1659]: loss 5.352251
[epoch5, step1660]: loss 23.962486
[epoch5, step1661]: loss 3.176147
[epoch5, step1662]: loss 11.637565
[epoch5, step1663]: loss 3.023951
[epoch5, step1664]: loss 7.688896
[epoch5, step1665]: loss 4.472798
[epoch5, step1666]: loss 6.442809
[epoch5, step1667]: loss 24.150505
[epoch5, step1668]: loss 3.779179
[epoch5, step1669]: loss 24.011772
[epoch5, step1670]: loss 10.043904
[epoch5, step1671]: loss 16.532316
[epoch5, step1672]: loss 23.319422
[epoch5, step1673]: loss 9.144133
[epoch5, step1674]: loss 13.210972
[epoch5, step1675]: loss 8.655591
[epoch5, step1676]: loss 10.225398
[epoch5, step1677]: loss 8.903300
[epoch5, step1678]: loss 17.445230
[epoch5, step1679]: loss 8.713929
[epoch5, step1680]: loss 2.373469
[epoch5, step1681]: loss 4.748651
[epoch5, step1682]: loss 3.367571
[epoch5, step1683]: loss 2.082912
[epoch5, step1684]: loss 4.682275
[epoch5, step1685]: loss 1.246466
[epoch5, step1686]: loss 3.313580
[epoch5, step1687]: loss 23.326021
[epoch5, step1688]: loss 1.813899
[epoch5, step1689]: loss 11.831269
[epoch5, step1690]: loss 4.412927
[epoch5, step1691]: loss 22.370461
[epoch5, step1692]: loss 15.276933
[epoch5, step1693]: loss 2.065427
[epoch5, step1694]: loss 1.310997
[epoch5, step1695]: loss 34.010742
[epoch5, step1696]: loss 3.354735
[epoch5, step1697]: loss 1.421650
[epoch5, step1698]: loss 1.743288
[epoch5, step1699]: loss 3.696076
[epoch5, step1700]: loss 8.278375
[epoch5, step1701]: loss 2.754546
[epoch5, step1702]: loss 1.861694
[epoch5, step1703]: loss 20.350185
[epoch5, step1704]: loss 22.656679
[epoch5, step1705]: loss 4.013357
[epoch5, step1706]: loss 5.164897
[epoch5, step1707]: loss 2.650906
[epoch5, step1708]: loss 3.023576
[epoch5, step1709]: loss 27.101961
[epoch5, step1710]: loss 6.574676
[epoch5, step1711]: loss 8.144781
[epoch5, step1712]: loss 1.549750
[epoch5, step1713]: loss 23.600145
[epoch5, step1714]: loss 10.692448
[epoch5, step1715]: loss 9.015958
[epoch5, step1716]: loss 17.309778
[epoch5, step1717]: loss 21.802973
[epoch5, step1718]: loss 12.603865
[epoch5, step1719]: loss 10.401516
[epoch5, step1720]: loss 3.773426
[epoch5, step1721]: loss 3.081309
[epoch5, step1722]: loss 13.827388
[epoch5, step1723]: loss 11.286183
[epoch5, step1724]: loss 13.922623
[epoch5, step1725]: loss 13.314230
[epoch5, step1726]: loss 2.847769
[epoch5, step1727]: loss 1.633939
[epoch5, step1728]: loss 3.997012
[epoch5, step1729]: loss 17.984030
[epoch5, step1730]: loss 9.276399
[epoch5, step1731]: loss 1.785535
[epoch5, step1732]: loss 1.949169
[epoch5, step1733]: loss 27.689533
[epoch5, step1734]: loss 9.004475
[epoch5, step1735]: loss 9.001938
[epoch5, step1736]: loss 8.300712
[epoch5, step1737]: loss 4.692318
[epoch5, step1738]: loss 2.416167
[epoch5, step1739]: loss 18.366089
[epoch5, step1740]: loss 16.217936
[epoch5, step1741]: loss 9.267097
[epoch5, step1742]: loss 15.281932
[epoch5, step1743]: loss 1.821079
[epoch5, step1744]: loss 12.712120
[epoch5, step1745]: loss 1.842014
[epoch5, step1746]: loss 2.208325
[epoch5, step1747]: loss 14.791282
[epoch5, step1748]: loss 3.405500
[epoch5, step1749]: loss 6.261641
[epoch5, step1750]: loss 23.045364
[epoch5, step1751]: loss 7.452425
[epoch5, step1752]: loss 7.669600
[epoch5, step1753]: loss 18.598347
[epoch5, step1754]: loss 4.152015
[epoch5, step1755]: loss 27.455873
[epoch5, step1756]: loss 1.519331
[epoch5, step1757]: loss 2.087404
[epoch5, step1758]: loss 20.480457
[epoch5, step1759]: loss 3.206097
[epoch5, step1760]: loss 2.124296
[epoch5, step1761]: loss 24.533829
[epoch5, step1762]: loss 1.613996
[epoch5, step1763]: loss 10.521411
[epoch5, step1764]: loss 9.626527
[epoch5, step1765]: loss 24.279348
[epoch5, step1766]: loss 17.278936
[epoch5, step1767]: loss 2.509675
[epoch5, step1768]: loss 5.529793
[epoch5, step1769]: loss 1.104874
[epoch5, step1770]: loss 14.447071
[epoch5, step1771]: loss 7.084045
[epoch5, step1772]: loss 2.634325
[epoch5, step1773]: loss 7.305060
[epoch5, step1774]: loss 1.394852
[epoch5, step1775]: loss 5.632939
[epoch5, step1776]: loss 1.674835
[epoch5, step1777]: loss 23.839289
[epoch5, step1778]: loss 1.212799
[epoch5, step1779]: loss 13.119113
[epoch5, step1780]: loss 4.121598
[epoch5, step1781]: loss 8.916544
[epoch5, step1782]: loss 1.269715
[epoch5, step1783]: loss 8.123604
[epoch5, step1784]: loss 9.823392
[epoch5, step1785]: loss 6.877038
[epoch5, step1786]: loss 17.975731
[epoch5, step1787]: loss 3.108076
[epoch5, step1788]: loss 15.243462
[epoch5, step1789]: loss 25.486343
[epoch5, step1790]: loss 8.626249
[epoch5, step1791]: loss 26.318848
[epoch5, step1792]: loss 9.576205
[epoch5, step1793]: loss 2.782410
[epoch5, step1794]: loss 1.880409
[epoch5, step1795]: loss 7.056507
[epoch5, step1796]: loss 9.525164
[epoch5, step1797]: loss 15.388950
[epoch5, step1798]: loss 4.037400
[epoch5, step1799]: loss 3.679811
[epoch5, step1800]: loss 11.937349
[epoch5, step1801]: loss 1.661283
[epoch5, step1802]: loss 4.219365
[epoch5, step1803]: loss 2.510337
[epoch5, step1804]: loss 9.807955
[epoch5, step1805]: loss 10.707967
[epoch5, step1806]: loss 14.815277
[epoch5, step1807]: loss 3.257397
[epoch5, step1808]: loss 34.119606
[epoch5, step1809]: loss 1.445868
[epoch5, step1810]: loss 14.696944
[epoch5, step1811]: loss 1.666326
[epoch5, step1812]: loss 16.382051
[epoch5, step1813]: loss 2.349058
[epoch5, step1814]: loss 2.564504
[epoch5, step1815]: loss 6.216913
[epoch5, step1816]: loss 9.239755
[epoch5, step1817]: loss 3.055149
[epoch5, step1818]: loss 2.137295
[epoch5, step1819]: loss 8.251044
[epoch5, step1820]: loss 9.749701
[epoch5, step1821]: loss 9.710800
[epoch5, step1822]: loss 3.364729
[epoch5, step1823]: loss 1.767452
[epoch5, step1824]: loss 3.292980
[epoch5, step1825]: loss 3.724586
[epoch5, step1826]: loss 10.221961
[epoch5, step1827]: loss 2.484186
[epoch5, step1828]: loss 1.671072
[epoch5, step1829]: loss 1.574047
[epoch5, step1830]: loss 1.471280
[epoch5, step1831]: loss 3.376527
[epoch5, step1832]: loss 10.272243
[epoch5, step1833]: loss 2.519960
[epoch5, step1834]: loss 4.534951
[epoch5, step1835]: loss 16.992989
[epoch5, step1836]: loss 2.797987
[epoch5, step1837]: loss 13.717912
[epoch5, step1838]: loss 1.705284
[epoch5, step1839]: loss 16.966433
[epoch5, step1840]: loss 22.553091
[epoch5, step1841]: loss 3.282200
[epoch5, step1842]: loss 4.852710
[epoch5, step1843]: loss 15.533470
[epoch5, step1844]: loss 18.863556
[epoch5, step1845]: loss 2.416910
[epoch5, step1846]: loss 8.806374
[epoch5, step1847]: loss 11.883529
[epoch5, step1848]: loss 16.444653
[epoch5, step1849]: loss 3.605650
[epoch5, step1850]: loss 1.471900
[epoch5, step1851]: loss 2.404036
[epoch5, step1852]: loss 8.711001
[epoch5, step1853]: loss 2.746497
[epoch5, step1854]: loss 8.415441
[epoch5, step1855]: loss 3.212743
[epoch5, step1856]: loss 2.322538
[epoch5, step1857]: loss 13.577582
[epoch5, step1858]: loss 11.888236
[epoch5, step1859]: loss 24.415995
[epoch5, step1860]: loss 19.718960
[epoch5, step1861]: loss 10.519756
[epoch5, step1862]: loss 10.262914
[epoch5, step1863]: loss 21.189169
[epoch5, step1864]: loss 4.859347
[epoch5, step1865]: loss 1.528610
[epoch5, step1866]: loss 15.829638
[epoch5, step1867]: loss 11.420196
[epoch5, step1868]: loss 10.562934
[epoch5, step1869]: loss 3.494209
[epoch5, step1870]: loss 5.605511
[epoch5, step1871]: loss 1.778406
[epoch5, step1872]: loss 19.535931
[epoch5, step1873]: loss 1.807332
[epoch5, step1874]: loss 2.973097
[epoch5, step1875]: loss 6.580790
[epoch5, step1876]: loss 1.824707
[epoch5, step1877]: loss 3.225901
[epoch5, step1878]: loss 11.508762
[epoch5, step1879]: loss 4.222527
[epoch5, step1880]: loss 14.089195
[epoch5, step1881]: loss 16.415068
[epoch5, step1882]: loss 2.488813
[epoch5, step1883]: loss 16.532381
[epoch5, step1884]: loss 4.295475
[epoch5, step1885]: loss 7.253543
[epoch5, step1886]: loss 3.266058
[epoch5, step1887]: loss 3.093506
[epoch5, step1888]: loss 9.156115
[epoch5, step1889]: loss 1.393291
[epoch5, step1890]: loss 1.551000
[epoch5, step1891]: loss 8.773721
[epoch5, step1892]: loss 6.965467
[epoch5, step1893]: loss 1.926292
[epoch5, step1894]: loss 8.461551
[epoch5, step1895]: loss 11.171235
[epoch5, step1896]: loss 4.009575
[epoch5, step1897]: loss 2.757127
[epoch5, step1898]: loss 19.901064
[epoch5, step1899]: loss 12.312774
[epoch5, step1900]: loss 3.693657
[epoch5, step1901]: loss 15.224648
[epoch5, step1902]: loss 24.007568
[epoch5, step1903]: loss 1.201876
[epoch5, step1904]: loss 17.728556
[epoch5, step1905]: loss 4.609208
[epoch5, step1906]: loss 7.951645
[epoch5, step1907]: loss 15.449706
[epoch5, step1908]: loss 11.043642
[epoch5, step1909]: loss 2.317488
[epoch5, step1910]: loss 12.391018
[epoch5, step1911]: loss 4.321303
[epoch5, step1912]: loss 1.630344
[epoch5, step1913]: loss 27.915493
[epoch5, step1914]: loss 21.700937
[epoch5, step1915]: loss 3.504711
[epoch5, step1916]: loss 2.184964
[epoch5, step1917]: loss 17.015905
[epoch5, step1918]: loss 2.570559
[epoch5, step1919]: loss 3.097291
[epoch5, step1920]: loss 1.084821
[epoch5, step1921]: loss 3.319878
[epoch5, step1922]: loss 2.923856
[epoch5, step1923]: loss 1.436016
[epoch5, step1924]: loss 4.718796
[epoch5, step1925]: loss 11.645794
[epoch5, step1926]: loss 3.926808
[epoch5, step1927]: loss 13.023680
[epoch5, step1928]: loss 8.543959
[epoch5, step1929]: loss 43.464096
[epoch5, step1930]: loss 3.019453
[epoch5, step1931]: loss 3.240990
[epoch5, step1932]: loss 2.244074
[epoch5, step1933]: loss 1.969983
[epoch5, step1934]: loss 2.507461
[epoch5, step1935]: loss 11.636477
[epoch5, step1936]: loss 18.853254
[epoch5, step1937]: loss 1.995729
[epoch5, step1938]: loss 2.985579
[epoch5, step1939]: loss 21.365988
[epoch5, step1940]: loss 2.919811
[epoch5, step1941]: loss 50.124355
[epoch5, step1942]: loss 9.713765
[epoch5, step1943]: loss 16.226912
[epoch5, step1944]: loss 4.994550
[epoch5, step1945]: loss 10.723652
[epoch5, step1946]: loss 1.393266
[epoch5, step1947]: loss 6.994407
[epoch5, step1948]: loss 13.771669
[epoch5, step1949]: loss 12.474567
[epoch5, step1950]: loss 14.749905
[epoch5, step1951]: loss 23.005978
[epoch5, step1952]: loss 15.370360
[epoch5, step1953]: loss 5.591140
[epoch5, step1954]: loss 3.116707
[epoch5, step1955]: loss 3.133769
[epoch5, step1956]: loss 3.370424
[epoch5, step1957]: loss 10.339199
[epoch5, step1958]: loss 13.368689
[epoch5, step1959]: loss 9.549505
[epoch5, step1960]: loss 21.421846
[epoch5, step1961]: loss 16.821617
[epoch5, step1962]: loss 3.296608
[epoch5, step1963]: loss 2.048962
[epoch5, step1964]: loss 22.531170
[epoch5, step1965]: loss 3.645531
[epoch5, step1966]: loss 3.617257
[epoch5, step1967]: loss 2.959312
[epoch5, step1968]: loss 6.573384
[epoch5, step1969]: loss 15.624698
[epoch5, step1970]: loss 3.796737
[epoch5, step1971]: loss 4.115804
[epoch5, step1972]: loss 2.619927
[epoch5, step1973]: loss 10.515612
[epoch5, step1974]: loss 2.460581
[epoch5, step1975]: loss 23.251587
[epoch5, step1976]: loss 9.905725
[epoch5, step1977]: loss 10.562440
[epoch5, step1978]: loss 1.443791
[epoch5, step1979]: loss 6.791174
[epoch5, step1980]: loss 2.842159
[epoch5, step1981]: loss 2.527359
[epoch5, step1982]: loss 3.738234
[epoch5, step1983]: loss 9.355006
[epoch5, step1984]: loss 4.174125
[epoch5, step1985]: loss 15.711596
[epoch5, step1986]: loss 12.091311
[epoch5, step1987]: loss 1.696609
[epoch5, step1988]: loss 14.912956
[epoch5, step1989]: loss 23.500425
[epoch5, step1990]: loss 3.363828
[epoch5, step1991]: loss 2.689389
[epoch5, step1992]: loss 4.924600
[epoch5, step1993]: loss 2.341130
[epoch5, step1994]: loss 1.327983
[epoch5, step1995]: loss 17.042192
[epoch5, step1996]: loss 12.546944
[epoch5, step1997]: loss 3.291540
[epoch5, step1998]: loss 9.583836
[epoch5, step1999]: loss 2.085409
[epoch5, step2000]: loss 3.789721
[epoch5, step2001]: loss 2.375341
[epoch5, step2002]: loss 20.723194
[epoch5, step2003]: loss 4.370819
[epoch5, step2004]: loss 2.469048
[epoch5, step2005]: loss 10.066144
[epoch5, step2006]: loss 1.982956
[epoch5, step2007]: loss 7.512412
[epoch5, step2008]: loss 15.700958
[epoch5, step2009]: loss 9.825756
[epoch5, step2010]: loss 1.695480
[epoch5, step2011]: loss 2.682473
[epoch5, step2012]: loss 4.096584
[epoch5, step2013]: loss 1.488952
[epoch5, step2014]: loss 3.268872
[epoch5, step2015]: loss 7.226214
[epoch5, step2016]: loss 20.787077
[epoch5, step2017]: loss 13.818405
[epoch5, step2018]: loss 7.146643
[epoch5, step2019]: loss 2.020216
[epoch5, step2020]: loss 10.327012
[epoch5, step2021]: loss 14.710705
[epoch5, step2022]: loss 4.311346
[epoch5, step2023]: loss 2.731049
[epoch5, step2024]: loss 2.443007
[epoch5, step2025]: loss 0.983316
[epoch5, step2026]: loss 2.384004
[epoch5, step2027]: loss 4.422050
[epoch5, step2028]: loss 1.286080
[epoch5, step2029]: loss 46.097099
[epoch5, step2030]: loss 11.967482
[epoch5, step2031]: loss 3.800951
[epoch5, step2032]: loss 6.825437
[epoch5, step2033]: loss 8.764278
[epoch5, step2034]: loss 17.379959
[epoch5, step2035]: loss 3.045581
[epoch5, step2036]: loss 9.564427
[epoch5, step2037]: loss 3.699419
[epoch5, step2038]: loss 3.317411
[epoch5, step2039]: loss 20.988281
[epoch5, step2040]: loss 4.354068
[epoch5, step2041]: loss 11.260888
[epoch5, step2042]: loss 13.177794
[epoch5, step2043]: loss 9.711288
[epoch5, step2044]: loss 3.772930
[epoch5, step2045]: loss 2.489408
[epoch5, step2046]: loss 19.862116
[epoch5, step2047]: loss 3.206260
[epoch5, step2048]: loss 3.350724
[epoch5, step2049]: loss 2.083666
[epoch5, step2050]: loss 2.616321
[epoch5, step2051]: loss 6.597869
[epoch5, step2052]: loss 18.965570
[epoch5, step2053]: loss 20.518896
[epoch5, step2054]: loss 7.313785
[epoch5, step2055]: loss 5.317988
[epoch5, step2056]: loss 4.190396
[epoch5, step2057]: loss 8.075722
[epoch5, step2058]: loss 1.758166
[epoch5, step2059]: loss 4.217892
[epoch5, step2060]: loss 6.014129
[epoch5, step2061]: loss 10.314009
[epoch5, step2062]: loss 1.227842
[epoch5, step2063]: loss 4.342133
[epoch5, step2064]: loss 9.688769
[epoch5, step2065]: loss 3.259884
[epoch5, step2066]: loss 15.538165
[epoch5, step2067]: loss 5.516290
[epoch5, step2068]: loss 2.684680
[epoch5, step2069]: loss 3.507967
[epoch5, step2070]: loss 3.773757
[epoch5, step2071]: loss 1.322178
[epoch5, step2072]: loss 10.439981
[epoch5, step2073]: loss 17.321465
[epoch5, step2074]: loss 5.945658
[epoch5, step2075]: loss 7.872207
[epoch5, step2076]: loss 8.334485
[epoch5, step2077]: loss 13.296855
[epoch5, step2078]: loss 9.992128
[epoch5, step2079]: loss 18.994164
[epoch5, step2080]: loss 1.787100
[epoch5, step2081]: loss 31.261124
[epoch5, step2082]: loss 12.090177
[epoch5, step2083]: loss 11.216051
[epoch5, step2084]: loss 1.222563
[epoch5, step2085]: loss 13.411982
[epoch5, step2086]: loss 2.571075
[epoch5, step2087]: loss 4.591463
[epoch5, step2088]: loss 11.211843
[epoch5, step2089]: loss 5.444960
[epoch5, step2090]: loss 19.232082
[epoch5, step2091]: loss 1.259894
[epoch5, step2092]: loss 8.212028
[epoch5, step2093]: loss 7.565645
[epoch5, step2094]: loss 2.316967
[epoch5, step2095]: loss 8.648817
[epoch5, step2096]: loss 9.616371
[epoch5, step2097]: loss 1.518662
[epoch5, step2098]: loss 7.914670
[epoch5, step2099]: loss 28.330891
[epoch5, step2100]: loss 3.433516
[epoch5, step2101]: loss 9.580348
[epoch5, step2102]: loss 2.044661
[epoch5, step2103]: loss 2.482188
[epoch5, step2104]: loss 4.010355
[epoch5, step2105]: loss 6.498987
[epoch5, step2106]: loss 11.547636
[epoch5, step2107]: loss 4.138093
[epoch5, step2108]: loss 12.399480
[epoch5, step2109]: loss 2.654243
[epoch5, step2110]: loss 2.448312
[epoch5, step2111]: loss 3.142631
[epoch5, step2112]: loss 11.373764
[epoch5, step2113]: loss 2.012598
[epoch5, step2114]: loss 14.251359
[epoch5, step2115]: loss 2.308408
[epoch5, step2116]: loss 34.497421
[epoch5, step2117]: loss 3.184280
[epoch5, step2118]: loss 4.270075
[epoch5, step2119]: loss 10.672478
[epoch5, step2120]: loss 10.498659
[epoch5, step2121]: loss 5.382070
[epoch5, step2122]: loss 7.280885
[epoch5, step2123]: loss 19.446695
[epoch5, step2124]: loss 2.194049
[epoch5, step2125]: loss 1.427244
[epoch5, step2126]: loss 6.110767
[epoch5, step2127]: loss 4.063053
[epoch5, step2128]: loss 3.166816
[epoch5, step2129]: loss 4.276013
[epoch5, step2130]: loss 11.369294
[epoch5, step2131]: loss 1.653004
[epoch5, step2132]: loss 8.768822
[epoch5, step2133]: loss 7.324539
[epoch5, step2134]: loss 1.186310
[epoch5, step2135]: loss 13.628192
[epoch5, step2136]: loss 7.220038
[epoch5, step2137]: loss 11.384604
[epoch5, step2138]: loss 2.839531
[epoch5, step2139]: loss 9.133682
[epoch5, step2140]: loss 8.268133
[epoch5, step2141]: loss 5.529737
[epoch5, step2142]: loss 6.463071
[epoch5, step2143]: loss 1.975418
[epoch5, step2144]: loss 13.437595
[epoch5, step2145]: loss 5.788011
[epoch5, step2146]: loss 3.987966
[epoch5, step2147]: loss 26.768528
[epoch5, step2148]: loss 5.887322
[epoch5, step2149]: loss 25.120987
[epoch5, step2150]: loss 1.338179
[epoch5, step2151]: loss 1.089491
[epoch5, step2152]: loss 3.247513
[epoch5, step2153]: loss 1.249402
[epoch5, step2154]: loss 18.418512
[epoch5, step2155]: loss 7.700682
[epoch5, step2156]: loss 8.050009
[epoch5, step2157]: loss 2.186009
[epoch5, step2158]: loss 2.621649
[epoch5, step2159]: loss 12.249792
[epoch5, step2160]: loss 17.900389
[epoch5, step2161]: loss 17.544065
[epoch5, step2162]: loss 1.440191
[epoch5, step2163]: loss 11.394439
[epoch5, step2164]: loss 1.947392
[epoch5, step2165]: loss 18.431713
[epoch5, step2166]: loss 2.643229
[epoch5, step2167]: loss 3.104552
[epoch5, step2168]: loss 3.920015
[epoch5, step2169]: loss 13.826661
[epoch5, step2170]: loss 2.647392
[epoch5, step2171]: loss 18.149345
[epoch5, step2172]: loss 4.441284
[epoch5, step2173]: loss 27.583937
[epoch5, step2174]: loss 3.284486
[epoch5, step2175]: loss 28.192236
[epoch5, step2176]: loss 2.721453
[epoch5, step2177]: loss 10.789758
[epoch5, step2178]: loss 13.880993
[epoch5, step2179]: loss 1.614137
[epoch5, step2180]: loss 1.433962
[epoch5, step2181]: loss 2.073303
[epoch5, step2182]: loss 1.452039
[epoch5, step2183]: loss 6.595121
[epoch5, step2184]: loss 4.201659
[epoch5, step2185]: loss 2.990021
[epoch5, step2186]: loss 2.158739
[epoch5, step2187]: loss 18.405689
[epoch5, step2188]: loss 1.529578
[epoch5, step2189]: loss 5.662872
[epoch5, step2190]: loss 1.121371
[epoch5, step2191]: loss 8.638066
[epoch5, step2192]: loss 2.390551
[epoch5, step2193]: loss 8.923034
[epoch5, step2194]: loss 1.418459
[epoch5, step2195]: loss 4.388577
[epoch5, step2196]: loss 20.089193
[epoch5, step2197]: loss 1.556021
[epoch5, step2198]: loss 11.457415
[epoch5, step2199]: loss 15.122177
[epoch5, step2200]: loss 8.328890
[epoch5, step2201]: loss 3.998320
[epoch5, step2202]: loss 12.413996
[epoch5, step2203]: loss 4.731567
[epoch5, step2204]: loss 10.065012
[epoch5, step2205]: loss 11.973613
[epoch5, step2206]: loss 9.217374
[epoch5, step2207]: loss 8.137584
[epoch5, step2208]: loss 9.991508
[epoch5, step2209]: loss 11.794542
[epoch5, step2210]: loss 4.026811
[epoch5, step2211]: loss 12.456814
[epoch5, step2212]: loss 5.217183
[epoch5, step2213]: loss 35.362167
[epoch5, step2214]: loss 8.057236
[epoch5, step2215]: loss 3.249823
[epoch5, step2216]: loss 2.371100
[epoch5, step2217]: loss 3.390490
[epoch5, step2218]: loss 1.448722
[epoch5, step2219]: loss 15.031043
[epoch5, step2220]: loss 57.525097
[epoch5, step2221]: loss 17.024141
[epoch5, step2222]: loss 10.355917
[epoch5, step2223]: loss 1.686992
[epoch5, step2224]: loss 9.364018
[epoch5, step2225]: loss 31.497816
[epoch5, step2226]: loss 5.225811
[epoch5, step2227]: loss 3.774817
[epoch5, step2228]: loss 11.006181
[epoch5, step2229]: loss 6.299443
[epoch5, step2230]: loss 2.599393
[epoch5, step2231]: loss 27.221888
[epoch5, step2232]: loss 8.430680
[epoch5, step2233]: loss 15.498532
[epoch5, step2234]: loss 11.163876
[epoch5, step2235]: loss 2.396243
[epoch5, step2236]: loss 1.819311
[epoch5, step2237]: loss 1.738355
[epoch5, step2238]: loss 14.032165
[epoch5, step2239]: loss 34.450874
[epoch5, step2240]: loss 1.839498
[epoch5, step2241]: loss 19.681610
[epoch5, step2242]: loss 23.384871
[epoch5, step2243]: loss 6.286828
[epoch5, step2244]: loss 16.264082
[epoch5, step2245]: loss 8.241676
[epoch5, step2246]: loss 22.758015
[epoch5, step2247]: loss 7.944497
[epoch5, step2248]: loss 13.521477
[epoch5, step2249]: loss 9.123150
[epoch5, step2250]: loss 1.887664
[epoch5, step2251]: loss 11.776016
[epoch5, step2252]: loss 2.122536
[epoch5, step2253]: loss 2.417967
[epoch5, step2254]: loss 7.426926
[epoch5, step2255]: loss 3.950088
[epoch5, step2256]: loss 2.032756
[epoch5, step2257]: loss 2.833252
[epoch5, step2258]: loss 2.160973
[epoch5, step2259]: loss 7.183442
[epoch5, step2260]: loss 18.182474
[epoch5, step2261]: loss 10.318959
[epoch5, step2262]: loss 2.644881
[epoch5, step2263]: loss 18.366245
[epoch5, step2264]: loss 4.165107
[epoch5, step2265]: loss 13.401686
[epoch5, step2266]: loss 1.951078
[epoch5, step2267]: loss 1.577493
[epoch5, step2268]: loss 3.538204
[epoch5, step2269]: loss 8.656118
[epoch5, step2270]: loss 2.243700
[epoch5, step2271]: loss 2.655339
[epoch5, step2272]: loss 1.244125
[epoch5, step2273]: loss 10.304089
[epoch5, step2274]: loss 2.483062
[epoch5, step2275]: loss 1.190617
[epoch5, step2276]: loss 16.726843
[epoch5, step2277]: loss 4.179580
[epoch5, step2278]: loss 8.771044
[epoch5, step2279]: loss 7.344655
[epoch5, step2280]: loss 3.346765
[epoch5, step2281]: loss 9.060261
[epoch5, step2282]: loss 3.543466
[epoch5, step2283]: loss 1.230132
[epoch5, step2284]: loss 8.925773
[epoch5, step2285]: loss 15.020712
[epoch5, step2286]: loss 1.312858
[epoch5, step2287]: loss 7.891815
[epoch5, step2288]: loss 2.823102
[epoch5, step2289]: loss 10.486968
[epoch5, step2290]: loss 11.860057
[epoch5, step2291]: loss 1.980862
[epoch5, step2292]: loss 5.233012
[epoch5, step2293]: loss 5.845445
[epoch5, step2294]: loss 1.730420
[epoch5, step2295]: loss 2.600893
[epoch5, step2296]: loss 7.125642
[epoch5, step2297]: loss 15.220489
[epoch5, step2298]: loss 2.272486
[epoch5, step2299]: loss 23.851093
[epoch5, step2300]: loss 4.635185
[epoch5, step2301]: loss 8.394709
[epoch5, step2302]: loss 3.744644
[epoch5, step2303]: loss 2.614797
[epoch5, step2304]: loss 5.370831
[epoch5, step2305]: loss 9.537340
[epoch5, step2306]: loss 8.762768
[epoch5, step2307]: loss 17.617266
[epoch5, step2308]: loss 19.543180
[epoch5, step2309]: loss 1.847384
[epoch5, step2310]: loss 3.264109
[epoch5, step2311]: loss 1.357183
[epoch5, step2312]: loss 3.705730
[epoch5, step2313]: loss 8.062243
[epoch5, step2314]: loss 21.022823
[epoch5, step2315]: loss 2.645879
[epoch5, step2316]: loss 5.235025
[epoch5, step2317]: loss 3.977246
[epoch5, step2318]: loss 16.774837
[epoch5, step2319]: loss 1.981211
[epoch5, step2320]: loss 0.959633
[epoch5, step2321]: loss 9.904057
[epoch5, step2322]: loss 10.313260
[epoch5, step2323]: loss 9.789858
[epoch5, step2324]: loss 4.136113
[epoch5, step2325]: loss 1.846534
[epoch5, step2326]: loss 1.529615
[epoch5, step2327]: loss 7.408064
[epoch5, step2328]: loss 1.727553
[epoch5, step2329]: loss 2.555585
[epoch5, step2330]: loss 9.112429
[epoch5, step2331]: loss 3.030319
[epoch5, step2332]: loss 10.925107
[epoch5, step2333]: loss 1.585109
[epoch5, step2334]: loss 22.168447
[epoch5, step2335]: loss 23.415655
[epoch5, step2336]: loss 25.815622
[epoch5, step2337]: loss 11.952046
[epoch5, step2338]: loss 28.192764
[epoch5, step2339]: loss 4.113046
[epoch5, step2340]: loss 3.617005
[epoch5, step2341]: loss 1.684481
[epoch5, step2342]: loss 1.480337
[epoch5, step2343]: loss 31.547077
[epoch5, step2344]: loss 7.970964
[epoch5, step2345]: loss 18.975946
[epoch5, step2346]: loss 1.004359
[epoch5, step2347]: loss 9.602714
[epoch5, step2348]: loss 7.361434
[epoch5, step2349]: loss 10.689580
[epoch5, step2350]: loss 10.352478
[epoch5, step2351]: loss 3.189904
[epoch5, step2352]: loss 1.574636
[epoch5, step2353]: loss 2.268215
[epoch5, step2354]: loss 10.672516
[epoch5, step2355]: loss 16.650576
[epoch5, step2356]: loss 3.182453
[epoch5, step2357]: loss 1.569228
[epoch5, step2358]: loss 1.722341
[epoch5, step2359]: loss 2.048916
[epoch5, step2360]: loss 9.893211
[epoch5, step2361]: loss 2.675991
[epoch5, step2362]: loss 5.082144
[epoch5, step2363]: loss 1.916250
[epoch5, step2364]: loss 1.282633
[epoch5, step2365]: loss 1.323149
[epoch5, step2366]: loss 19.921873
[epoch5, step2367]: loss 1.722408
[epoch5, step2368]: loss 19.936188
[epoch5, step2369]: loss 1.814299
[epoch5, step2370]: loss 9.309405
[epoch5, step2371]: loss 7.379228
[epoch5, step2372]: loss 2.056490
[epoch5, step2373]: loss 16.074553
[epoch5, step2374]: loss 10.298773
[epoch5, step2375]: loss 1.348157
[epoch5, step2376]: loss 3.806596
[epoch5, step2377]: loss 7.516085
[epoch5, step2378]: loss 1.619744
[epoch5, step2379]: loss 9.729601
[epoch5, step2380]: loss 17.034811
[epoch5, step2381]: loss 7.205065
[epoch5, step2382]: loss 1.912079
[epoch5, step2383]: loss 1.504170
[epoch5, step2384]: loss 10.222559
[epoch5, step2385]: loss 2.045393
[epoch5, step2386]: loss 5.352436
[epoch5, step2387]: loss 18.271093
[epoch5, step2388]: loss 2.549457
[epoch5, step2389]: loss 8.655790
[epoch5, step2390]: loss 23.274574
[epoch5, step2391]: loss 5.527040
[epoch5, step2392]: loss 15.935547
[epoch5, step2393]: loss 4.639318
[epoch5, step2394]: loss 20.786240
[epoch5, step2395]: loss 1.221395
[epoch5, step2396]: loss 12.331670
[epoch5, step2397]: loss 6.268602
[epoch5, step2398]: loss 2.875878
[epoch5, step2399]: loss 13.091061
[epoch5, step2400]: loss 2.461627
[epoch5, step2401]: loss 21.166094
[epoch5, step2402]: loss 11.368997
[epoch5, step2403]: loss 8.804121
[epoch5, step2404]: loss 6.032578
[epoch5, step2405]: loss 6.710026
[epoch5, step2406]: loss 2.039790
[epoch5, step2407]: loss 3.079107
[epoch5, step2408]: loss 16.059910
[epoch5, step2409]: loss 11.160667
[epoch5, step2410]: loss 10.711675
[epoch5, step2411]: loss 2.331802
[epoch5, step2412]: loss 1.644002
[epoch5, step2413]: loss 3.944298
[epoch5, step2414]: loss 3.469436
[epoch5, step2415]: loss 16.429523
[epoch5, step2416]: loss 1.202594
[epoch5, step2417]: loss 1.250668
[epoch5, step2418]: loss 10.287704
[epoch5, step2419]: loss 11.405497
[epoch5, step2420]: loss 2.990147
[epoch5, step2421]: loss 1.181747
[epoch5, step2422]: loss 14.276247
[epoch5, step2423]: loss 1.799923
[epoch5, step2424]: loss 7.697267
[epoch5, step2425]: loss 2.278152
[epoch5, step2426]: loss 6.411248
[epoch5, step2427]: loss 6.256090
[epoch5, step2428]: loss 3.084643
[epoch5, step2429]: loss 5.761670
[epoch5, step2430]: loss 6.487659
[epoch5, step2431]: loss 6.156449
[epoch5, step2432]: loss 3.373155
[epoch5, step2433]: loss 1.671803
[epoch5, step2434]: loss 12.413752
[epoch5, step2435]: loss 19.547396
[epoch5, step2436]: loss 4.233046
[epoch5, step2437]: loss 7.126712
[epoch5, step2438]: loss 5.428990
[epoch5, step2439]: loss 16.181362
[epoch5, step2440]: loss 17.642622
[epoch5, step2441]: loss 16.083731
[epoch5, step2442]: loss 4.517649
[epoch5, step2443]: loss 3.166755
[epoch5, step2444]: loss 6.864249
[epoch5, step2445]: loss 5.977327
[epoch5, step2446]: loss 16.156834
[epoch5, step2447]: loss 7.072859
[epoch5, step2448]: loss 12.373625
[epoch5, step2449]: loss 5.599673
[epoch5, step2450]: loss 2.705100
[epoch5, step2451]: loss 2.040273
[epoch5, step2452]: loss 23.822985
[epoch5, step2453]: loss 11.031219
[epoch5, step2454]: loss 8.205714
[epoch5, step2455]: loss 6.510802
[epoch5, step2456]: loss 1.168766
[epoch5, step2457]: loss 9.007551
[epoch5, step2458]: loss 1.848333
[epoch5, step2459]: loss 4.210211
[epoch5, step2460]: loss 15.970989
[epoch5, step2461]: loss 1.217451
[epoch5, step2462]: loss 11.947577
[epoch5, step2463]: loss 3.884141
[epoch5, step2464]: loss 2.842921
[epoch5, step2465]: loss 8.291793
[epoch5, step2466]: loss 18.688562
[epoch5, step2467]: loss 3.762921
[epoch5, step2468]: loss 3.545751
[epoch5, step2469]: loss 6.637085
[epoch5, step2470]: loss 12.121519
[epoch5, step2471]: loss 5.861222
[epoch5, step2472]: loss 10.869482
[epoch5, step2473]: loss 7.622663
[epoch5, step2474]: loss 4.490008
[epoch5, step2475]: loss 4.334087
[epoch5, step2476]: loss 12.349980
[epoch5, step2477]: loss 23.403496
[epoch5, step2478]: loss 7.553689
[epoch5, step2479]: loss 21.493174
[epoch5, step2480]: loss 3.512345
[epoch5, step2481]: loss 5.078595
[epoch5, step2482]: loss 2.706603
[epoch5, step2483]: loss 6.373323
[epoch5, step2484]: loss 2.278080
[epoch5, step2485]: loss 4.093901
[epoch5, step2486]: loss 13.862779
[epoch5, step2487]: loss 7.658670
[epoch5, step2488]: loss 11.562892
[epoch5, step2489]: loss 8.619144
[epoch5, step2490]: loss 16.408381
[epoch5, step2491]: loss 15.115368
[epoch5, step2492]: loss 1.731396
[epoch5, step2493]: loss 1.654569
[epoch5, step2494]: loss 7.235378
[epoch5, step2495]: loss 5.670202
[epoch5, step2496]: loss 2.965173
[epoch5, step2497]: loss 3.871567
[epoch5, step2498]: loss 3.605128
[epoch5, step2499]: loss 11.245772
[epoch5, step2500]: loss 3.235156
[epoch5, step2501]: loss 4.922716
[epoch5, step2502]: loss 1.460264
[epoch5, step2503]: loss 12.164886
[epoch5, step2504]: loss 3.836351
[epoch5, step2505]: loss 13.688470
[epoch5, step2506]: loss 2.057472
[epoch5, step2507]: loss 10.625406
[epoch5, step2508]: loss 6.925515
[epoch5, step2509]: loss 6.896906
[epoch5, step2510]: loss 2.115602
[epoch5, step2511]: loss 5.425681
[epoch5, step2512]: loss 11.797353
[epoch5, step2513]: loss 6.261693
[epoch5, step2514]: loss 18.672796
[epoch5, step2515]: loss 2.819661
[epoch5, step2516]: loss 10.685776
[epoch5, step2517]: loss 3.129983
[epoch5, step2518]: loss 22.423679
[epoch5, step2519]: loss 4.059275
[epoch5, step2520]: loss 5.014511
[epoch5, step2521]: loss 12.499440
[epoch5, step2522]: loss 19.216646
[epoch5, step2523]: loss 6.792458
[epoch5, step2524]: loss 8.964655
[epoch5, step2525]: loss 9.165647
[epoch5, step2526]: loss 20.900080
[epoch5, step2527]: loss 25.485859
[epoch5, step2528]: loss 4.275406
[epoch5, step2529]: loss 6.516281
[epoch5, step2530]: loss 2.916764
[epoch5, step2531]: loss 3.121428
[epoch5, step2532]: loss 8.609422
[epoch5, step2533]: loss 20.110199
[epoch5, step2534]: loss 8.200318
[epoch5, step2535]: loss 4.883446
[epoch5, step2536]: loss 12.114088
[epoch5, step2537]: loss 20.080095
[epoch5, step2538]: loss 4.028165
[epoch5, step2539]: loss 13.194570
[epoch5, step2540]: loss 1.813779
[epoch5, step2541]: loss 16.427244
[epoch5, step2542]: loss 2.991716
[epoch5, step2543]: loss 14.702584
[epoch5, step2544]: loss 16.587938
[epoch5, step2545]: loss 10.432196
[epoch5, step2546]: loss 6.676167
[epoch5, step2547]: loss 11.595336
[epoch5, step2548]: loss 7.663671
[epoch5, step2549]: loss 5.424758
[epoch5, step2550]: loss 1.693313
[epoch5, step2551]: loss 15.502037
[epoch5, step2552]: loss 4.704955
[epoch5, step2553]: loss 3.009431
[epoch5, step2554]: loss 12.989460
[epoch5, step2555]: loss 5.074299
[epoch5, step2556]: loss 1.506587
[epoch5, step2557]: loss 3.318369
[epoch5, step2558]: loss 9.421000
[epoch5, step2559]: loss 11.450994
[epoch5, step2560]: loss 2.441372
[epoch5, step2561]: loss 1.055059
[epoch5, step2562]: loss 1.096590
[epoch5, step2563]: loss 2.264695
[epoch5, step2564]: loss 1.167300
[epoch5, step2565]: loss 12.861761
[epoch5, step2566]: loss 16.732935
[epoch5, step2567]: loss 2.182799
[epoch5, step2568]: loss 2.789681
[epoch5, step2569]: loss 20.209288
[epoch5, step2570]: loss 15.349804
[epoch5, step2571]: loss 1.342499
[epoch5, step2572]: loss 14.022825
[epoch5, step2573]: loss 4.490590
[epoch5, step2574]: loss 13.754414
[epoch5, step2575]: loss 3.041648
[epoch5, step2576]: loss 14.797508
[epoch5, step2577]: loss 20.593636
[epoch5, step2578]: loss 2.336174
[epoch5, step2579]: loss 2.496876
[epoch5, step2580]: loss 1.699853
[epoch5, step2581]: loss 15.633993
[epoch5, step2582]: loss 4.948225
[epoch5, step2583]: loss 11.436744
[epoch5, step2584]: loss 6.198564
[epoch5, step2585]: loss 3.804934
[epoch5, step2586]: loss 5.081305
[epoch5, step2587]: loss 3.350874
[epoch5, step2588]: loss 1.746721
[epoch5, step2589]: loss 4.397542
[epoch5, step2590]: loss 1.887503
[epoch5, step2591]: loss 10.157472
[epoch5, step2592]: loss 2.467108
[epoch5, step2593]: loss 11.353099
[epoch5, step2594]: loss 9.430389
[epoch5, step2595]: loss 2.158680
[epoch5, step2596]: loss 13.126118
[epoch5, step2597]: loss 1.586802
[epoch5, step2598]: loss 3.737479
[epoch5, step2599]: loss 26.832687
[epoch5, step2600]: loss 8.851088
[epoch5, step2601]: loss 6.967274
[epoch5, step2602]: loss 1.442874
[epoch5, step2603]: loss 9.614141
[epoch5, step2604]: loss 8.152547
[epoch5, step2605]: loss 31.130028
[epoch5, step2606]: loss 7.108263
[epoch5, step2607]: loss 9.892497
[epoch5, step2608]: loss 15.262635
[epoch5, step2609]: loss 15.416765
[epoch5, step2610]: loss 6.518433
[epoch5, step2611]: loss 2.235213
[epoch5, step2612]: loss 1.643457
[epoch5, step2613]: loss 19.374454
[epoch5, step2614]: loss 2.377337
[epoch5, step2615]: loss 2.711440
[epoch5, step2616]: loss 7.158139
[epoch5, step2617]: loss 16.381727
[epoch5, step2618]: loss 13.156270
[epoch5, step2619]: loss 2.293130
[epoch5, step2620]: loss 2.768135
[epoch5, step2621]: loss 16.190876
[epoch5, step2622]: loss 3.808054
[epoch5, step2623]: loss 10.357428
[epoch5, step2624]: loss 2.790401
[epoch5, step2625]: loss 1.428123
[epoch5, step2626]: loss 2.376666
[epoch5, step2627]: loss 1.812137
[epoch5, step2628]: loss 6.500364
[epoch5, step2629]: loss 15.069147
[epoch5, step2630]: loss 9.976029
[epoch5, step2631]: loss 2.492223
[epoch5, step2632]: loss 7.510075
[epoch5, step2633]: loss 11.526571
[epoch5, step2634]: loss 3.860409
[epoch5, step2635]: loss 10.673990
[epoch5, step2636]: loss 12.908837
[epoch5, step2637]: loss 3.032681
[epoch5, step2638]: loss 9.599046
[epoch5, step2639]: loss 3.764645
[epoch5, step2640]: loss 3.535156
[epoch5, step2641]: loss 13.162694
[epoch5, step2642]: loss 2.671585
[epoch5, step2643]: loss 3.063404
[epoch5, step2644]: loss 1.621877
[epoch5, step2645]: loss 16.192286
[epoch5, step2646]: loss 17.811903
[epoch5, step2647]: loss 7.896547
[epoch5, step2648]: loss 12.344790
[epoch5, step2649]: loss 2.872925
[epoch5, step2650]: loss 2.353494
[epoch5, step2651]: loss 3.252453
[epoch5, step2652]: loss 2.917714
[epoch5, step2653]: loss 27.616161
[epoch5, step2654]: loss 15.701416
[epoch5, step2655]: loss 3.196094
[epoch5, step2656]: loss 9.110110
[epoch5, step2657]: loss 2.087530
[epoch5, step2658]: loss 5.778611
[epoch5, step2659]: loss 3.750810
[epoch5, step2660]: loss 14.334853
[epoch5, step2661]: loss 4.489086
[epoch5, step2662]: loss 2.453036
[epoch5, step2663]: loss 1.842788
[epoch5, step2664]: loss 8.331851
[epoch5, step2665]: loss 15.049204
[epoch5, step2666]: loss 18.919489
[epoch5, step2667]: loss 1.612537
[epoch5, step2668]: loss 18.249987
[epoch5, step2669]: loss 2.831631
[epoch5, step2670]: loss 3.214854
[epoch5, step2671]: loss 10.422121
[epoch5, step2672]: loss 4.021470
[epoch5, step2673]: loss 19.859268
[epoch5, step2674]: loss 3.997062
[epoch5, step2675]: loss 6.342648
[epoch5, step2676]: loss 2.323625
[epoch5, step2677]: loss 2.007007
[epoch5, step2678]: loss 13.728467
[epoch5, step2679]: loss 4.769055
[epoch5, step2680]: loss 4.169836
[epoch5, step2681]: loss 29.314661
[epoch5, step2682]: loss 2.997749
[epoch5, step2683]: loss 13.031189
[epoch5, step2684]: loss 3.284724
[epoch5, step2685]: loss 16.118849
[epoch5, step2686]: loss 8.103505
[epoch5, step2687]: loss 1.749459
[epoch5, step2688]: loss 30.632927
[epoch5, step2689]: loss 7.238165
[epoch5, step2690]: loss 8.684184
[epoch5, step2691]: loss 1.537239
[epoch5, step2692]: loss 9.548704
[epoch5, step2693]: loss 14.549075
[epoch5, step2694]: loss 1.750064
[epoch5, step2695]: loss 9.178255
[epoch5, step2696]: loss 7.633489
[epoch5, step2697]: loss 2.858797
[epoch5, step2698]: loss 16.305792
[epoch5, step2699]: loss 3.133144
[epoch5, step2700]: loss 16.662378
[epoch5, step2701]: loss 25.620586
[epoch5, step2702]: loss 4.370636
[epoch5, step2703]: loss 1.608233
[epoch5, step2704]: loss 1.369633
[epoch5, step2705]: loss 2.663627
[epoch5, step2706]: loss 3.538104
[epoch5, step2707]: loss 4.513862
[epoch5, step2708]: loss 3.651105
[epoch5, step2709]: loss 7.418109
[epoch5, step2710]: loss 1.428079
[epoch5, step2711]: loss 6.735351
[epoch5, step2712]: loss 8.433316
[epoch5, step2713]: loss 1.631531
[epoch5, step2714]: loss 9.500973
[epoch5, step2715]: loss 14.559747
[epoch5, step2716]: loss 3.970484
[epoch5, step2717]: loss 7.993901
[epoch5, step2718]: loss 9.996861
[epoch5, step2719]: loss 8.792000
[epoch5, step2720]: loss 2.825633
[epoch5, step2721]: loss 5.218899
[epoch5, step2722]: loss 11.610998
[epoch5, step2723]: loss 7.951144
[epoch5, step2724]: loss 2.596600
[epoch5, step2725]: loss 3.626561
[epoch5, step2726]: loss 25.490084
[epoch5, step2727]: loss 19.426735
[epoch5, step2728]: loss 14.386015
[epoch5, step2729]: loss 4.731105
[epoch5, step2730]: loss 21.219158
[epoch5, step2731]: loss 2.085570
[epoch5, step2732]: loss 1.590883
[epoch5, step2733]: loss 3.592556
[epoch5, step2734]: loss 2.650921
[epoch5, step2735]: loss 14.799688
[epoch5, step2736]: loss 9.734199
[epoch5, step2737]: loss 1.876751
[epoch5, step2738]: loss 8.264848
[epoch5, step2739]: loss 11.176994
[epoch5, step2740]: loss 11.239655
[epoch5, step2741]: loss 9.574687
[epoch5, step2742]: loss 12.648415
[epoch5, step2743]: loss 7.629815
[epoch5, step2744]: loss 20.543839
[epoch5, step2745]: loss 9.511350
[epoch5, step2746]: loss 25.334906
[epoch5, step2747]: loss 20.625671
[epoch5, step2748]: loss 7.712579
[epoch5, step2749]: loss 2.529574
[epoch5, step2750]: loss 22.596781
[epoch5, step2751]: loss 24.580645
[epoch5, step2752]: loss 12.747590
[epoch5, step2753]: loss 2.735409
[epoch5, step2754]: loss 9.317752
[epoch5, step2755]: loss 3.043269
[epoch5, step2756]: loss 25.145203
[epoch5, step2757]: loss 6.564015
[epoch5, step2758]: loss 8.836969
[epoch5, step2759]: loss 2.056818
[epoch5, step2760]: loss 26.007195
[epoch5, step2761]: loss 15.251396
[epoch5, step2762]: loss 4.361073
[epoch5, step2763]: loss 10.788837
[epoch5, step2764]: loss 12.202925
[epoch5, step2765]: loss 1.873374
[epoch5, step2766]: loss 15.233856
[epoch5, step2767]: loss 12.279767
[epoch5, step2768]: loss 4.517056
[epoch5, step2769]: loss 3.393231
[epoch5, step2770]: loss 5.211835
[epoch5, step2771]: loss 9.822551
[epoch5, step2772]: loss 0.898020
[epoch5, step2773]: loss 2.340711
[epoch5, step2774]: loss 3.489752
[epoch5, step2775]: loss 2.831447
[epoch5, step2776]: loss 17.318615
[epoch5, step2777]: loss 6.518751
[epoch5, step2778]: loss 6.622674
[epoch5, step2779]: loss 2.319142
[epoch5, step2780]: loss 8.489814
[epoch5, step2781]: loss 7.689645
[epoch5, step2782]: loss 8.461364
[epoch5, step2783]: loss 2.733421
[epoch5, step2784]: loss 1.615906
[epoch5, step2785]: loss 9.896498
[epoch5, step2786]: loss 5.779491
[epoch5, step2787]: loss 6.843098
[epoch5, step2788]: loss 18.517496
[epoch5, step2789]: loss 7.869262
[epoch5, step2790]: loss 2.098045
[epoch5, step2791]: loss 2.558564
[epoch5, step2792]: loss 3.574260
[epoch5, step2793]: loss 3.243197
[epoch5, step2794]: loss 1.868898
[epoch5, step2795]: loss 9.694645
[epoch5, step2796]: loss 14.935629
[epoch5, step2797]: loss 4.664405
[epoch5, step2798]: loss 13.294826
[epoch5, step2799]: loss 1.515193
[epoch5, step2800]: loss 14.906223
[epoch5, step2801]: loss 18.482338
[epoch5, step2802]: loss 11.491490
[epoch5, step2803]: loss 1.864183
[epoch5, step2804]: loss 2.324571
[epoch5, step2805]: loss 3.323016
[epoch5, step2806]: loss 12.645824
[epoch5, step2807]: loss 2.635847
[epoch5, step2808]: loss 17.235609
[epoch5, step2809]: loss 2.181793
[epoch5, step2810]: loss 1.825992
[epoch5, step2811]: loss 1.354603
[epoch5, step2812]: loss 10.126511
[epoch5, step2813]: loss 3.237307
[epoch5, step2814]: loss 5.414896
[epoch5, step2815]: loss 19.489771
[epoch5, step2816]: loss 7.700601
[epoch5, step2817]: loss 5.491162
[epoch5, step2818]: loss 4.547462
[epoch5, step2819]: loss 11.379923
[epoch5, step2820]: loss 6.197345
[epoch5, step2821]: loss 1.688563
[epoch5, step2822]: loss 9.440469
[epoch5, step2823]: loss 10.085832
[epoch5, step2824]: loss 20.152300
[epoch5, step2825]: loss 13.356144
[epoch5, step2826]: loss 15.067276
[epoch5, step2827]: loss 20.612898
[epoch5, step2828]: loss 1.820549
[epoch5, step2829]: loss 9.948853
[epoch5, step2830]: loss 4.862377
[epoch5, step2831]: loss 1.244778
[epoch5, step2832]: loss 10.743770
[epoch5, step2833]: loss 2.219198
[epoch5, step2834]: loss 8.576599
[epoch5, step2835]: loss 3.058261
[epoch5, step2836]: loss 4.715044
[epoch5, step2837]: loss 5.628929
[epoch5, step2838]: loss 1.476042
[epoch5, step2839]: loss 14.478385
[epoch5, step2840]: loss 2.804205
[epoch5, step2841]: loss 2.084883
[epoch5, step2842]: loss 17.498718
[epoch5, step2843]: loss 1.476108
[epoch5, step2844]: loss 6.737950
[epoch5, step2845]: loss 3.276000
[epoch5, step2846]: loss 15.812655
[epoch5, step2847]: loss 7.767434
[epoch5, step2848]: loss 2.419580
[epoch5, step2849]: loss 11.670343
[epoch5, step2850]: loss 6.601902
[epoch5, step2851]: loss 7.365222
[epoch5, step2852]: loss 8.685412
[epoch5, step2853]: loss 10.231361
[epoch5, step2854]: loss 12.828459
[epoch5, step2855]: loss 8.734368
[epoch5, step2856]: loss 3.029634
[epoch5, step2857]: loss 3.846054
[epoch5, step2858]: loss 2.860738
[epoch5, step2859]: loss 5.411162
[epoch5, step2860]: loss 7.574259
[epoch5, step2861]: loss 8.356737
[epoch5, step2862]: loss 12.542348
[epoch5, step2863]: loss 24.915951
[epoch5, step2864]: loss 14.782886
[epoch5, step2865]: loss 15.911057
[epoch5, step2866]: loss 8.126148
[epoch5, step2867]: loss 14.796040
[epoch5, step2868]: loss 2.348065
[epoch5, step2869]: loss 3.358507
[epoch5, step2870]: loss 4.541122
[epoch5, step2871]: loss 7.706803
[epoch5, step2872]: loss 11.577672
[epoch5, step2873]: loss 3.979084
[epoch5, step2874]: loss 4.259992
[epoch5, step2875]: loss 14.307916
[epoch5, step2876]: loss 1.824168
[epoch5, step2877]: loss 12.807601
[epoch5, step2878]: loss 5.479879
[epoch5, step2879]: loss 4.417242
[epoch5, step2880]: loss 2.697802
[epoch5, step2881]: loss 1.718219
[epoch5, step2882]: loss 1.771977
[epoch5, step2883]: loss 8.251664
[epoch5, step2884]: loss 9.243408
[epoch5, step2885]: loss 4.820346
[epoch5, step2886]: loss 2.862060
[epoch5, step2887]: loss 13.370119
[epoch5, step2888]: loss 1.499575
[epoch5, step2889]: loss 2.674674
[epoch5, step2890]: loss 9.458817
[epoch5, step2891]: loss 16.095591
[epoch5, step2892]: loss 2.281876
[epoch5, step2893]: loss 22.161421
[epoch5, step2894]: loss 12.725794
[epoch5, step2895]: loss 7.579530
[epoch5, step2896]: loss 20.251034
[epoch5, step2897]: loss 3.346107
[epoch5, step2898]: loss 23.943138
[epoch5, step2899]: loss 9.015356
[epoch5, step2900]: loss 9.303546
[epoch5, step2901]: loss 12.203938
[epoch5, step2902]: loss 3.507172
[epoch5, step2903]: loss 6.336637
[epoch5, step2904]: loss 1.372872
[epoch5, step2905]: loss 10.163882
[epoch5, step2906]: loss 3.410003
[epoch5, step2907]: loss 2.902161
[epoch5, step2908]: loss 4.094329
[epoch5, step2909]: loss 1.555296
[epoch5, step2910]: loss 14.258254
[epoch5, step2911]: loss 2.245069
[epoch5, step2912]: loss 9.029840
[epoch5, step2913]: loss 23.252853
[epoch5, step2914]: loss 4.676185
[epoch5, step2915]: loss 1.985409
[epoch5, step2916]: loss 10.146874
[epoch5, step2917]: loss 7.965149
[epoch5, step2918]: loss 7.026242
[epoch5, step2919]: loss 18.362270
[epoch5, step2920]: loss 9.171191
[epoch5, step2921]: loss 18.201994
[epoch5, step2922]: loss 10.283918
[epoch5, step2923]: loss 7.823433
[epoch5, step2924]: loss 11.423213
[epoch5, step2925]: loss 6.760991
[epoch5, step2926]: loss 19.243147
[epoch5, step2927]: loss 8.435298
[epoch5, step2928]: loss 1.536668
[epoch5, step2929]: loss 15.124141
[epoch5, step2930]: loss 2.440924
[epoch5, step2931]: loss 7.584297
[epoch5, step2932]: loss 23.832922
[epoch5, step2933]: loss 3.102316
[epoch5, step2934]: loss 2.528998
[epoch5, step2935]: loss 4.071874
[epoch5, step2936]: loss 2.040163
[epoch5, step2937]: loss 7.617811
[epoch5, step2938]: loss 3.523256
[epoch5, step2939]: loss 2.074919
[epoch5, step2940]: loss 10.741995
[epoch5, step2941]: loss 3.657708
[epoch5, step2942]: loss 3.715939
[epoch5, step2943]: loss 1.715074
[epoch5, step2944]: loss 8.414129
[epoch5, step2945]: loss 17.157024
[epoch5, step2946]: loss 1.215537
[epoch5, step2947]: loss 7.443960
[epoch5, step2948]: loss 3.317000
[epoch5, step2949]: loss 4.287601
[epoch5, step2950]: loss 16.884945
[epoch5, step2951]: loss 1.264533
[epoch5, step2952]: loss 2.104057
[epoch5, step2953]: loss 16.666193
[epoch5, step2954]: loss 2.302980
[epoch5, step2955]: loss 3.275551
[epoch5, step2956]: loss 10.007115
[epoch5, step2957]: loss 2.444443
[epoch5, step2958]: loss 7.915421
[epoch5, step2959]: loss 10.498925
[epoch5, step2960]: loss 5.400498
[epoch5, step2961]: loss 7.421303
[epoch5, step2962]: loss 13.015498
[epoch5, step2963]: loss 1.433988
[epoch5, step2964]: loss 9.978629
[epoch5, step2965]: loss 3.885585
[epoch5, step2966]: loss 8.089854
[epoch5, step2967]: loss 2.190527
[epoch5, step2968]: loss 9.167896
[epoch5, step2969]: loss 8.696359
[epoch5, step2970]: loss 2.303372
[epoch5, step2971]: loss 1.048317
[epoch5, step2972]: loss 1.445004
[epoch5, step2973]: loss 6.332856
[epoch5, step2974]: loss 3.699092
[epoch5, step2975]: loss 12.783251
[epoch5, step2976]: loss 7.616404
[epoch5, step2977]: loss 15.185790
[epoch5, step2978]: loss 18.292498
[epoch5, step2979]: loss 4.464437
[epoch5, step2980]: loss 3.748176
[epoch5, step2981]: loss 1.683007
[epoch5, step2982]: loss 10.536749
[epoch5, step2983]: loss 22.215176
[epoch5, step2984]: loss 1.566799
[epoch5, step2985]: loss 10.291735
[epoch5, step2986]: loss 2.604168
[epoch5, step2987]: loss 9.580781
[epoch5, step2988]: loss 2.288641
[epoch5, step2989]: loss 12.413653
[epoch5, step2990]: loss 13.626809
[epoch5, step2991]: loss 15.435949
[epoch5, step2992]: loss 4.016267
[epoch5, step2993]: loss 7.626904
[epoch5, step2994]: loss 1.324895
[epoch5, step2995]: loss 11.146895
[epoch5, step2996]: loss 1.346154
[epoch5, step2997]: loss 0.986579
[epoch5, step2998]: loss 7.465826
[epoch5, step2999]: loss 13.379643
[epoch5, step3000]: loss 3.054548
[epoch5, step3001]: loss 12.310454
[epoch5, step3002]: loss 14.389790
[epoch5, step3003]: loss 2.637002
[epoch5, step3004]: loss 2.006546
[epoch5, step3005]: loss 19.416212
[epoch5, step3006]: loss 1.983432
[epoch5, step3007]: loss 5.404281
[epoch5, step3008]: loss 4.842155
[epoch5, step3009]: loss 2.021927
[epoch5, step3010]: loss 4.353406
[epoch5, step3011]: loss 3.238096
[epoch5, step3012]: loss 7.400584
[epoch5, step3013]: loss 10.873976
[epoch5, step3014]: loss 6.197603
[epoch5, step3015]: loss 12.359606
[epoch5, step3016]: loss 9.104937
[epoch5, step3017]: loss 25.280396
[epoch5, step3018]: loss 1.358847
[epoch5, step3019]: loss 26.751684
[epoch5, step3020]: loss 14.854108
[epoch5, step3021]: loss 11.285295
[epoch5, step3022]: loss 3.178234
[epoch5, step3023]: loss 7.500268
[epoch5, step3024]: loss 7.236574
[epoch5, step3025]: loss 3.113672
[epoch5, step3026]: loss 2.188498
[epoch5, step3027]: loss 12.642946
[epoch5, step3028]: loss 3.204264
[epoch5, step3029]: loss 9.071157
[epoch5, step3030]: loss 13.436129
[epoch5, step3031]: loss 10.827810
[epoch5, step3032]: loss 24.854242
[epoch5, step3033]: loss 4.017092
[epoch5, step3034]: loss 16.865627
[epoch5, step3035]: loss 13.357893
[epoch5, step3036]: loss 12.466073
[epoch5, step3037]: loss 2.899338
[epoch5, step3038]: loss 9.465564
[epoch5, step3039]: loss 1.482956
[epoch5, step3040]: loss 15.943233
[epoch5, step3041]: loss 2.658848
[epoch5, step3042]: loss 9.801761
[epoch5, step3043]: loss 14.194815
[epoch5, step3044]: loss 1.955819
[epoch5, step3045]: loss 1.864008
[epoch5, step3046]: loss 5.775310
[epoch5, step3047]: loss 6.877805
[epoch5, step3048]: loss 12.921700
[epoch5, step3049]: loss 1.604265
[epoch5, step3050]: loss 11.533125
[epoch5, step3051]: loss 3.400373
[epoch5, step3052]: loss 10.916697
[epoch5, step3053]: loss 4.362620
[epoch5, step3054]: loss 3.233492
[epoch5, step3055]: loss 2.713013
[epoch5, step3056]: loss 3.198055
[epoch5, step3057]: loss 3.548629
[epoch5, step3058]: loss 4.918203
[epoch5, step3059]: loss 5.499214
[epoch5, step3060]: loss 1.180624
[epoch5, step3061]: loss 1.045795
[epoch5, step3062]: loss 4.664875
[epoch5, step3063]: loss 1.436710
[epoch5, step3064]: loss 2.924315
[epoch5, step3065]: loss 5.629867
[epoch5, step3066]: loss 22.974230
[epoch5, step3067]: loss 1.556813
[epoch5, step3068]: loss 2.323898
[epoch5, step3069]: loss 1.868131
[epoch5, step3070]: loss 20.536530
[epoch5, step3071]: loss 1.315422
[epoch5, step3072]: loss 1.807341
[epoch5, step3073]: loss 2.390004
[epoch5, step3074]: loss 3.688053
[epoch5, step3075]: loss 8.058730
[epoch5, step3076]: loss 7.930326

[epoch5]: avg loss 7.930326

[epoch6, step1]: loss 5.690353
[epoch6, step2]: loss 23.850941
[epoch6, step3]: loss 3.193482
[epoch6, step4]: loss 8.015551
[epoch6, step5]: loss 8.048553
[epoch6, step6]: loss 13.782864
[epoch6, step7]: loss 20.355377
[epoch6, step8]: loss 4.221792
[epoch6, step9]: loss 4.565798
[epoch6, step10]: loss 14.808771
[epoch6, step11]: loss 16.123810
[epoch6, step12]: loss 4.402112
[epoch6, step13]: loss 6.414398
[epoch6, step14]: loss 2.897616
[epoch6, step15]: loss 1.991188
[epoch6, step16]: loss 4.012352
[epoch6, step17]: loss 3.926126
[epoch6, step18]: loss 13.381061
[epoch6, step19]: loss 13.816361
[epoch6, step20]: loss 9.301731
[epoch6, step21]: loss 20.624840
[epoch6, step22]: loss 23.594465
[epoch6, step23]: loss 20.893421
[epoch6, step24]: loss 12.881103
[epoch6, step25]: loss 2.451910
[epoch6, step26]: loss 7.119421
[epoch6, step27]: loss 13.616757
[epoch6, step28]: loss 3.583811
[epoch6, step29]: loss 2.980314
[epoch6, step30]: loss 4.618455
[epoch6, step31]: loss 8.207804
[epoch6, step32]: loss 4.678643
[epoch6, step33]: loss 2.525757
[epoch6, step34]: loss 21.072926
[epoch6, step35]: loss 5.829008
[epoch6, step36]: loss 1.285021
[epoch6, step37]: loss 6.852733
[epoch6, step38]: loss 3.553631
[epoch6, step39]: loss 22.500351
[epoch6, step40]: loss 19.414610
[epoch6, step41]: loss 15.116300
[epoch6, step42]: loss 2.698549
[epoch6, step43]: loss 20.490555
[epoch6, step44]: loss 2.287198
[epoch6, step45]: loss 25.705259
[epoch6, step46]: loss 3.114973
[epoch6, step47]: loss 7.044062
[epoch6, step48]: loss 2.296474
[epoch6, step49]: loss 3.568827
[epoch6, step50]: loss 6.287280
[epoch6, step51]: loss 2.650197
[epoch6, step52]: loss 9.524716
[epoch6, step53]: loss 8.444230
[epoch6, step54]: loss 1.440709
[epoch6, step55]: loss 7.890669
[epoch6, step56]: loss 1.798387
[epoch6, step57]: loss 1.499630
[epoch6, step58]: loss 3.824568
[epoch6, step59]: loss 8.805897
[epoch6, step60]: loss 1.910360
[epoch6, step61]: loss 13.506226
[epoch6, step62]: loss 1.305004
[epoch6, step63]: loss 13.196127
[epoch6, step64]: loss 9.385130
[epoch6, step65]: loss 6.557604
[epoch6, step66]: loss 7.594720
[epoch6, step67]: loss 5.097054
[epoch6, step68]: loss 2.414448
[epoch6, step69]: loss 2.481681
[epoch6, step70]: loss 8.895011
[epoch6, step71]: loss 8.060532
[epoch6, step72]: loss 1.602886
[epoch6, step73]: loss 26.039000
[epoch6, step74]: loss 7.889238
[epoch6, step75]: loss 2.546598
[epoch6, step76]: loss 3.026829
[epoch6, step77]: loss 2.331083
[epoch6, step78]: loss 10.342308
[epoch6, step79]: loss 6.378829
[epoch6, step80]: loss 7.185858
[epoch6, step81]: loss 4.119291
[epoch6, step82]: loss 8.302654
[epoch6, step83]: loss 17.865267
[epoch6, step84]: loss 10.776932
[epoch6, step85]: loss 1.272109
[epoch6, step86]: loss 1.804302
[epoch6, step87]: loss 26.785212
[epoch6, step88]: loss 6.300053
[epoch6, step89]: loss 6.564215
[epoch6, step90]: loss 9.417367
[epoch6, step91]: loss 2.585089
[epoch6, step92]: loss 10.500157
[epoch6, step93]: loss 2.587540
[epoch6, step94]: loss 1.714621
[epoch6, step95]: loss 10.973994
[epoch6, step96]: loss 7.868428
[epoch6, step97]: loss 2.541605
[epoch6, step98]: loss 14.918853
[epoch6, step99]: loss 3.371850
[epoch6, step100]: loss 11.078082
[epoch6, step101]: loss 13.572510
[epoch6, step102]: loss 2.822415
[epoch6, step103]: loss 7.655953
[epoch6, step104]: loss 4.232206
[epoch6, step105]: loss 4.122623
[epoch6, step106]: loss 5.605314
[epoch6, step107]: loss 31.941360
[epoch6, step108]: loss 1.918619
[epoch6, step109]: loss 1.662693
[epoch6, step110]: loss 8.238449
[epoch6, step111]: loss 1.443072
[epoch6, step112]: loss 6.803031
[epoch6, step113]: loss 10.063816
[epoch6, step114]: loss 4.834207
[epoch6, step115]: loss 18.669815
[epoch6, step116]: loss 6.785075
[epoch6, step117]: loss 4.391636
[epoch6, step118]: loss 2.418542
[epoch6, step119]: loss 20.336687
[epoch6, step120]: loss 8.691519
[epoch6, step121]: loss 1.415235
[epoch6, step122]: loss 3.148596
[epoch6, step123]: loss 27.407221
[epoch6, step124]: loss 4.532055
[epoch6, step125]: loss 8.591697
[epoch6, step126]: loss 9.395934
[epoch6, step127]: loss 1.259981
[epoch6, step128]: loss 3.104462
[epoch6, step129]: loss 7.712328
[epoch6, step130]: loss 8.678225
[epoch6, step131]: loss 1.936026
[epoch6, step132]: loss 3.455181
[epoch6, step133]: loss 5.449346
[epoch6, step134]: loss 3.116275
[epoch6, step135]: loss 1.824949
[epoch6, step136]: loss 9.205043
[epoch6, step137]: loss 1.647366
[epoch6, step138]: loss 10.058686
[epoch6, step139]: loss 25.092653
[epoch6, step140]: loss 8.456187
[epoch6, step141]: loss 19.684004
[epoch6, step142]: loss 7.122708
[epoch6, step143]: loss 2.197367
[epoch6, step144]: loss 4.333665
[epoch6, step145]: loss 10.227710
[epoch6, step146]: loss 2.181029
[epoch6, step147]: loss 9.262569
[epoch6, step148]: loss 3.130667
[epoch6, step149]: loss 21.848310
[epoch6, step150]: loss 4.559497
[epoch6, step151]: loss 1.857525
[epoch6, step152]: loss 4.767921
[epoch6, step153]: loss 9.147787
[epoch6, step154]: loss 2.038155
[epoch6, step155]: loss 11.070584
[epoch6, step156]: loss 12.299626
[epoch6, step157]: loss 10.479393
[epoch6, step158]: loss 16.490793
[epoch6, step159]: loss 2.751471
[epoch6, step160]: loss 2.926645
[epoch6, step161]: loss 27.050323
[epoch6, step162]: loss 12.169862
[epoch6, step163]: loss 7.481967
[epoch6, step164]: loss 9.668897
[epoch6, step165]: loss 1.423863
[epoch6, step166]: loss 2.248917
[epoch6, step167]: loss 5.808337
[epoch6, step168]: loss 3.311362
[epoch6, step169]: loss 2.338995
[epoch6, step170]: loss 6.189448
[epoch6, step171]: loss 5.225379
[epoch6, step172]: loss 8.508038
[epoch6, step173]: loss 1.374703
[epoch6, step174]: loss 4.481262
[epoch6, step175]: loss 7.552463
[epoch6, step176]: loss 2.497072
[epoch6, step177]: loss 24.287800
[epoch6, step178]: loss 9.819329
[epoch6, step179]: loss 13.084871
[epoch6, step180]: loss 20.101185
[epoch6, step181]: loss 2.673608
[epoch6, step182]: loss 3.243681
[epoch6, step183]: loss 7.896034
[epoch6, step184]: loss 3.716384
[epoch6, step185]: loss 4.227168
[epoch6, step186]: loss 13.554206
[epoch6, step187]: loss 14.320992
[epoch6, step188]: loss 20.289843
[epoch6, step189]: loss 3.909114
[epoch6, step190]: loss 7.087194
[epoch6, step191]: loss 6.203387
[epoch6, step192]: loss 45.288700
[epoch6, step193]: loss 11.318798
[epoch6, step194]: loss 3.487180
[epoch6, step195]: loss 17.635170
[epoch6, step196]: loss 9.742951
[epoch6, step197]: loss 12.818779
[epoch6, step198]: loss 4.987788
[epoch6, step199]: loss 2.341982
[epoch6, step200]: loss 1.490779
[epoch6, step201]: loss 21.308123
[epoch6, step202]: loss 4.728707
[epoch6, step203]: loss 9.941140
[epoch6, step204]: loss 25.928568
[epoch6, step205]: loss 9.772871
[epoch6, step206]: loss 11.096583
[epoch6, step207]: loss 1.452420
[epoch6, step208]: loss 11.734811
[epoch6, step209]: loss 18.780518
[epoch6, step210]: loss 4.296755
[epoch6, step211]: loss 6.359221
[epoch6, step212]: loss 2.097934
[epoch6, step213]: loss 2.425945
[epoch6, step214]: loss 1.183292
[epoch6, step215]: loss 1.564369
[epoch6, step216]: loss 13.513259
[epoch6, step217]: loss 17.805223
[epoch6, step218]: loss 11.350760
[epoch6, step219]: loss 10.648261
[epoch6, step220]: loss 2.510730
[epoch6, step221]: loss 23.451603
[epoch6, step222]: loss 1.355209
[epoch6, step223]: loss 12.621496
[epoch6, step224]: loss 7.970755
[epoch6, step225]: loss 4.423637
[epoch6, step226]: loss 3.491639
[epoch6, step227]: loss 7.194501
[epoch6, step228]: loss 3.222417
[epoch6, step229]: loss 1.753988
[epoch6, step230]: loss 10.175789
[epoch6, step231]: loss 1.697787
[epoch6, step232]: loss 2.216088
[epoch6, step233]: loss 7.688752
[epoch6, step234]: loss 2.268001
[epoch6, step235]: loss 7.909646
[epoch6, step236]: loss 2.210787
[epoch6, step237]: loss 8.377932
[epoch6, step238]: loss 7.308535
[epoch6, step239]: loss 15.643881
[epoch6, step240]: loss 4.264601
[epoch6, step241]: loss 2.308944
[epoch6, step242]: loss 5.593453
[epoch6, step243]: loss 3.446047
[epoch6, step244]: loss 17.914230
[epoch6, step245]: loss 1.755111
[epoch6, step246]: loss 9.783000
[epoch6, step247]: loss 2.526818
[epoch6, step248]: loss 3.082633
[epoch6, step249]: loss 2.561134
[epoch6, step250]: loss 4.175681
[epoch6, step251]: loss 7.791890
[epoch6, step252]: loss 1.920955
[epoch6, step253]: loss 6.221383
[epoch6, step254]: loss 8.443161
[epoch6, step255]: loss 2.235960
[epoch6, step256]: loss 2.879447
[epoch6, step257]: loss 11.190166
[epoch6, step258]: loss 16.275661
[epoch6, step259]: loss 8.587426
[epoch6, step260]: loss 6.049145
[epoch6, step261]: loss 6.412474
[epoch6, step262]: loss 10.713103
[epoch6, step263]: loss 3.448293
[epoch6, step264]: loss 21.130892
[epoch6, step265]: loss 14.446929
[epoch6, step266]: loss 3.122457
[epoch6, step267]: loss 2.952091
[epoch6, step268]: loss 3.324161
[epoch6, step269]: loss 10.289967
[epoch6, step270]: loss 28.472271
[epoch6, step271]: loss 14.510341
[epoch6, step272]: loss 2.184571
[epoch6, step273]: loss 9.008158
[epoch6, step274]: loss 38.538670
[epoch6, step275]: loss 2.048732
[epoch6, step276]: loss 3.083489
[epoch6, step277]: loss 12.293552
[epoch6, step278]: loss 2.875064
[epoch6, step279]: loss 5.164348
[epoch6, step280]: loss 14.157043
[epoch6, step281]: loss 19.019701
[epoch6, step282]: loss 2.138899
[epoch6, step283]: loss 8.718589
[epoch6, step284]: loss 7.131773
[epoch6, step285]: loss 1.386516
[epoch6, step286]: loss 1.524276
[epoch6, step287]: loss 1.948841
[epoch6, step288]: loss 7.743759
[epoch6, step289]: loss 9.934217
[epoch6, step290]: loss 2.889254
[epoch6, step291]: loss 10.119822
[epoch6, step292]: loss 3.297151
[epoch6, step293]: loss 2.525358
[epoch6, step294]: loss 1.356815
[epoch6, step295]: loss 10.003710
[epoch6, step296]: loss 18.496962
[epoch6, step297]: loss 1.131927
[epoch6, step298]: loss 6.117527
[epoch6, step299]: loss 2.673854
[epoch6, step300]: loss 3.358069
[epoch6, step301]: loss 14.823697
[epoch6, step302]: loss 15.154929
[epoch6, step303]: loss 3.462565
[epoch6, step304]: loss 19.115934
[epoch6, step305]: loss 9.915388
[epoch6, step306]: loss 8.165615
[epoch6, step307]: loss 2.427864
[epoch6, step308]: loss 2.119369
[epoch6, step309]: loss 2.560173
[epoch6, step310]: loss 2.284227
[epoch6, step311]: loss 2.040758
[epoch6, step312]: loss 2.669982
[epoch6, step313]: loss 9.930449
[epoch6, step314]: loss 2.615174
[epoch6, step315]: loss 19.406120
[epoch6, step316]: loss 4.055791
[epoch6, step317]: loss 1.390998
[epoch6, step318]: loss 10.455384
[epoch6, step319]: loss 4.312398
[epoch6, step320]: loss 2.456416
[epoch6, step321]: loss 1.398834
[epoch6, step322]: loss 2.477614
[epoch6, step323]: loss 5.838049
[epoch6, step324]: loss 3.768439
[epoch6, step325]: loss 10.958309
[epoch6, step326]: loss 11.753426
[epoch6, step327]: loss 2.463411
[epoch6, step328]: loss 5.890723
[epoch6, step329]: loss 1.037294
[epoch6, step330]: loss 4.499087
[epoch6, step331]: loss 7.872930
[epoch6, step332]: loss 11.268834
[epoch6, step333]: loss 0.941961
[epoch6, step334]: loss 7.713063
[epoch6, step335]: loss 2.723697
[epoch6, step336]: loss 11.044805
[epoch6, step337]: loss 7.689763
[epoch6, step338]: loss 6.663287
[epoch6, step339]: loss 10.733794
[epoch6, step340]: loss 8.400374
[epoch6, step341]: loss 2.655614
[epoch6, step342]: loss 15.509987
[epoch6, step343]: loss 3.030422
[epoch6, step344]: loss 17.549583
[epoch6, step345]: loss 1.203599
[epoch6, step346]: loss 3.435438
[epoch6, step347]: loss 3.624034
[epoch6, step348]: loss 1.230278
[epoch6, step349]: loss 8.652766
[epoch6, step350]: loss 6.556450
[epoch6, step351]: loss 3.031745
[epoch6, step352]: loss 15.115443
[epoch6, step353]: loss 14.356623
[epoch6, step354]: loss 6.963291
[epoch6, step355]: loss 17.340853
[epoch6, step356]: loss 3.702131
[epoch6, step357]: loss 1.589177
[epoch6, step358]: loss 5.873994
[epoch6, step359]: loss 1.493494
[epoch6, step360]: loss 2.168345
[epoch6, step361]: loss 6.118581
[epoch6, step362]: loss 46.846394
[epoch6, step363]: loss 6.927623
[epoch6, step364]: loss 1.711852
[epoch6, step365]: loss 10.906741
[epoch6, step366]: loss 3.635776
[epoch6, step367]: loss 1.361809
[epoch6, step368]: loss 2.801522
[epoch6, step369]: loss 7.002171
[epoch6, step370]: loss 3.062473
[epoch6, step371]: loss 8.730373
[epoch6, step372]: loss 1.743271
[epoch6, step373]: loss 1.788067
[epoch6, step374]: loss 7.003385
[epoch6, step375]: loss 9.876948
[epoch6, step376]: loss 11.041420
[epoch6, step377]: loss 1.594401
[epoch6, step378]: loss 3.217171
[epoch6, step379]: loss 10.069468
[epoch6, step380]: loss 13.612404
[epoch6, step381]: loss 14.035018
[epoch6, step382]: loss 1.547899
[epoch6, step383]: loss 9.791251
[epoch6, step384]: loss 2.461248
[epoch6, step385]: loss 9.408922
[epoch6, step386]: loss 10.444626
[epoch6, step387]: loss 23.620707
[epoch6, step388]: loss 10.649221
[epoch6, step389]: loss 5.400918
[epoch6, step390]: loss 15.802217
[epoch6, step391]: loss 15.354838
[epoch6, step392]: loss 15.194826
[epoch6, step393]: loss 2.191633
[epoch6, step394]: loss 14.098698
[epoch6, step395]: loss 3.582330
[epoch6, step396]: loss 1.813115
[epoch6, step397]: loss 8.966385
[epoch6, step398]: loss 20.405418
[epoch6, step399]: loss 1.589037
[epoch6, step400]: loss 1.721262
[epoch6, step401]: loss 2.110311
[epoch6, step402]: loss 12.258608
[epoch6, step403]: loss 6.695418
[epoch6, step404]: loss 8.335484
[epoch6, step405]: loss 2.750595
[epoch6, step406]: loss 4.110882
[epoch6, step407]: loss 1.649325
[epoch6, step408]: loss 8.484508
[epoch6, step409]: loss 2.998618
[epoch6, step410]: loss 2.766035
[epoch6, step411]: loss 6.648787
[epoch6, step412]: loss 8.697319
[epoch6, step413]: loss 8.103518
[epoch6, step414]: loss 9.175870
[epoch6, step415]: loss 8.547336
[epoch6, step416]: loss 2.891118
[epoch6, step417]: loss 13.971749
[epoch6, step418]: loss 2.360240
[epoch6, step419]: loss 7.183496
[epoch6, step420]: loss 1.967561
[epoch6, step421]: loss 2.375968
[epoch6, step422]: loss 8.060348
[epoch6, step423]: loss 5.861892
[epoch6, step424]: loss 18.042027
[epoch6, step425]: loss 8.490187
[epoch6, step426]: loss 4.334095
[epoch6, step427]: loss 1.252301
[epoch6, step428]: loss 10.666492
[epoch6, step429]: loss 15.243664
[epoch6, step430]: loss 1.203157
[epoch6, step431]: loss 4.707606
[epoch6, step432]: loss 4.084619
[epoch6, step433]: loss 13.550244
[epoch6, step434]: loss 16.008421
[epoch6, step435]: loss 18.171843
[epoch6, step436]: loss 13.854881
[epoch6, step437]: loss 19.496967
[epoch6, step438]: loss 2.637852
[epoch6, step439]: loss 8.873985
[epoch6, step440]: loss 7.766328
[epoch6, step441]: loss 11.120505
[epoch6, step442]: loss 3.963983
[epoch6, step443]: loss 6.264341
[epoch6, step444]: loss 2.667404
[epoch6, step445]: loss 14.116564
[epoch6, step446]: loss 12.102925
[epoch6, step447]: loss 5.462276
[epoch6, step448]: loss 7.219925
[epoch6, step449]: loss 2.157493
[epoch6, step450]: loss 1.408980
[epoch6, step451]: loss 1.827893
[epoch6, step452]: loss 10.665699
[epoch6, step453]: loss 14.433799
[epoch6, step454]: loss 9.199619
[epoch6, step455]: loss 8.301809
[epoch6, step456]: loss 2.862451
[epoch6, step457]: loss 1.556144
[epoch6, step458]: loss 7.834893
[epoch6, step459]: loss 1.574729
[epoch6, step460]: loss 14.200181
[epoch6, step461]: loss 26.598251
[epoch6, step462]: loss 15.645821
[epoch6, step463]: loss 2.981300
[epoch6, step464]: loss 14.434376
[epoch6, step465]: loss 18.784348
[epoch6, step466]: loss 1.979278
[epoch6, step467]: loss 8.401713
[epoch6, step468]: loss 4.795310
[epoch6, step469]: loss 2.239507
[epoch6, step470]: loss 2.482160
[epoch6, step471]: loss 3.038164
[epoch6, step472]: loss 9.862730
[epoch6, step473]: loss 2.390477
[epoch6, step474]: loss 2.817309
[epoch6, step475]: loss 28.579350
[epoch6, step476]: loss 2.828043
[epoch6, step477]: loss 9.268358
[epoch6, step478]: loss 1.628196
[epoch6, step479]: loss 8.402426
[epoch6, step480]: loss 2.494587
[epoch6, step481]: loss 2.288697
[epoch6, step482]: loss 17.641632
[epoch6, step483]: loss 19.484974
[epoch6, step484]: loss 14.849540
[epoch6, step485]: loss 9.150646
[epoch6, step486]: loss 18.378084
[epoch6, step487]: loss 6.894697
[epoch6, step488]: loss 25.963150
[epoch6, step489]: loss 7.148171
[epoch6, step490]: loss 3.613078
[epoch6, step491]: loss 3.318607
[epoch6, step492]: loss 2.418819
[epoch6, step493]: loss 4.008156
[epoch6, step494]: loss 3.344941
[epoch6, step495]: loss 3.197112
[epoch6, step496]: loss 1.573127
[epoch6, step497]: loss 2.409616
[epoch6, step498]: loss 2.446124
[epoch6, step499]: loss 1.645185
[epoch6, step500]: loss 9.316635
[epoch6, step501]: loss 9.436414
[epoch6, step502]: loss 17.263109
[epoch6, step503]: loss 3.231062
[epoch6, step504]: loss 5.198748
[epoch6, step505]: loss 7.464678
[epoch6, step506]: loss 13.536950
[epoch6, step507]: loss 2.374905
[epoch6, step508]: loss 4.192496
[epoch6, step509]: loss 1.417826
[epoch6, step510]: loss 8.245435
[epoch6, step511]: loss 14.539569
[epoch6, step512]: loss 4.262985
[epoch6, step513]: loss 1.743616
[epoch6, step514]: loss 5.087353
[epoch6, step515]: loss 13.407466
[epoch6, step516]: loss 6.235340
[epoch6, step517]: loss 6.400446
[epoch6, step518]: loss 4.307322
[epoch6, step519]: loss 30.088346
[epoch6, step520]: loss 17.510984
[epoch6, step521]: loss 10.646183
[epoch6, step522]: loss 12.500785
[epoch6, step523]: loss 1.393874
[epoch6, step524]: loss 1.070015
[epoch6, step525]: loss 1.741480
[epoch6, step526]: loss 29.207907
[epoch6, step527]: loss 2.008582
[epoch6, step528]: loss 17.630871
[epoch6, step529]: loss 9.956348
[epoch6, step530]: loss 2.340641
[epoch6, step531]: loss 4.109316
[epoch6, step532]: loss 9.800647
[epoch6, step533]: loss 12.584094
[epoch6, step534]: loss 2.585232
[epoch6, step535]: loss 10.818028
[epoch6, step536]: loss 6.085589
[epoch6, step537]: loss 1.628407
[epoch6, step538]: loss 1.048739
[epoch6, step539]: loss 5.710494
[epoch6, step540]: loss 12.346265
[epoch6, step541]: loss 12.120463
[epoch6, step542]: loss 1.298215
[epoch6, step543]: loss 19.432026
[epoch6, step544]: loss 8.766044
[epoch6, step545]: loss 23.420597
[epoch6, step546]: loss 12.478483
[epoch6, step547]: loss 9.616560
[epoch6, step548]: loss 6.287068
[epoch6, step549]: loss 15.386780
[epoch6, step550]: loss 5.350027
[epoch6, step551]: loss 10.720346
[epoch6, step552]: loss 8.102419
[epoch6, step553]: loss 9.038828
[epoch6, step554]: loss 10.008152
[epoch6, step555]: loss 4.339413
[epoch6, step556]: loss 7.514779
[epoch6, step557]: loss 3.386865
[epoch6, step558]: loss 10.814415
[epoch6, step559]: loss 3.213907
[epoch6, step560]: loss 9.791930
[epoch6, step561]: loss 2.226303
[epoch6, step562]: loss 2.160599
[epoch6, step563]: loss 5.586317
[epoch6, step564]: loss 3.838454
[epoch6, step565]: loss 17.567032
[epoch6, step566]: loss 2.348096
[epoch6, step567]: loss 2.254766
[epoch6, step568]: loss 24.315506
[epoch6, step569]: loss 8.910465
[epoch6, step570]: loss 9.427904
[epoch6, step571]: loss 2.345583
[epoch6, step572]: loss 12.507859
[epoch6, step573]: loss 10.050469
[epoch6, step574]: loss 5.204147
[epoch6, step575]: loss 1.096326
[epoch6, step576]: loss 3.659547
[epoch6, step577]: loss 8.071630
[epoch6, step578]: loss 4.477323
[epoch6, step579]: loss 8.010656
[epoch6, step580]: loss 3.769792
[epoch6, step581]: loss 12.887248
[epoch6, step582]: loss 10.075569
[epoch6, step583]: loss 2.328391
[epoch6, step584]: loss 10.051690
[epoch6, step585]: loss 23.890060
[epoch6, step586]: loss 9.240793
[epoch6, step587]: loss 2.109444
[epoch6, step588]: loss 9.150130
[epoch6, step589]: loss 10.123365
[epoch6, step590]: loss 16.018925
[epoch6, step591]: loss 16.570616
[epoch6, step592]: loss 3.244728
[epoch6, step593]: loss 2.203758
[epoch6, step594]: loss 15.145274
[epoch6, step595]: loss 27.173628
[epoch6, step596]: loss 19.089939
[epoch6, step597]: loss 13.507236
[epoch6, step598]: loss 20.170191
[epoch6, step599]: loss 2.200017
[epoch6, step600]: loss 4.285347
[epoch6, step601]: loss 6.700084
[epoch6, step602]: loss 3.661360
[epoch6, step603]: loss 7.044386
[epoch6, step604]: loss 2.921313
[epoch6, step605]: loss 3.111042
[epoch6, step606]: loss 5.161612
[epoch6, step607]: loss 9.229394
[epoch6, step608]: loss 2.103259
[epoch6, step609]: loss 4.107416
[epoch6, step610]: loss 3.157945
[epoch6, step611]: loss 9.255873
[epoch6, step612]: loss 4.007309
[epoch6, step613]: loss 7.383751
[epoch6, step614]: loss 4.866086
[epoch6, step615]: loss 20.555906
[epoch6, step616]: loss 4.876202
[epoch6, step617]: loss 9.196281
[epoch6, step618]: loss 1.979231
[epoch6, step619]: loss 2.967134
[epoch6, step620]: loss 11.096087
[epoch6, step621]: loss 1.620167
[epoch6, step622]: loss 10.358042
[epoch6, step623]: loss 25.366993
[epoch6, step624]: loss 6.176639
[epoch6, step625]: loss 4.857373
[epoch6, step626]: loss 7.676234
[epoch6, step627]: loss 2.240751
[epoch6, step628]: loss 5.679933
[epoch6, step629]: loss 19.021303
[epoch6, step630]: loss 1.304196
[epoch6, step631]: loss 7.623844
[epoch6, step632]: loss 9.284352
[epoch6, step633]: loss 3.230353
[epoch6, step634]: loss 7.496043
[epoch6, step635]: loss 2.259262
[epoch6, step636]: loss 2.587407
[epoch6, step637]: loss 7.303610
[epoch6, step638]: loss 2.058842
[epoch6, step639]: loss 6.237628
[epoch6, step640]: loss 2.098043
[epoch6, step641]: loss 1.309552
[epoch6, step642]: loss 8.443345
[epoch6, step643]: loss 23.936750
[epoch6, step644]: loss 2.019123
[epoch6, step645]: loss 6.343690
[epoch6, step646]: loss 9.020535
[epoch6, step647]: loss 2.419461
[epoch6, step648]: loss 1.592445
[epoch6, step649]: loss 6.007275
[epoch6, step650]: loss 5.272675
[epoch6, step651]: loss 5.715321
[epoch6, step652]: loss 13.107209
[epoch6, step653]: loss 1.249872
[epoch6, step654]: loss 17.375477
[epoch6, step655]: loss 3.044824
[epoch6, step656]: loss 25.221466
[epoch6, step657]: loss 1.773570
[epoch6, step658]: loss 3.056654
[epoch6, step659]: loss 10.097258
[epoch6, step660]: loss 29.914587
[epoch6, step661]: loss 2.318197
[epoch6, step662]: loss 12.664710
[epoch6, step663]: loss 7.635499
[epoch6, step664]: loss 5.150032
[epoch6, step665]: loss 42.530945
[epoch6, step666]: loss 10.599133
[epoch6, step667]: loss 27.116089
[epoch6, step668]: loss 5.290102
[epoch6, step669]: loss 6.033824
[epoch6, step670]: loss 6.018137
[epoch6, step671]: loss 33.979595
[epoch6, step672]: loss 11.425498
[epoch6, step673]: loss 10.814452
[epoch6, step674]: loss 17.445801
[epoch6, step675]: loss 1.321224
[epoch6, step676]: loss 1.566578
[epoch6, step677]: loss 1.919606
[epoch6, step678]: loss 3.554071
[epoch6, step679]: loss 0.883817
[epoch6, step680]: loss 2.209521
[epoch6, step681]: loss 8.750218
[epoch6, step682]: loss 2.050111
[epoch6, step683]: loss 19.837048
[epoch6, step684]: loss 15.789376
[epoch6, step685]: loss 3.524817
[epoch6, step686]: loss 3.088550
[epoch6, step687]: loss 4.029699
[epoch6, step688]: loss 14.708832
[epoch6, step689]: loss 2.221492
[epoch6, step690]: loss 1.889116
[epoch6, step691]: loss 2.809856
[epoch6, step692]: loss 4.960540
[epoch6, step693]: loss 1.929114
[epoch6, step694]: loss 9.073423
[epoch6, step695]: loss 7.412457
[epoch6, step696]: loss 15.154071
[epoch6, step697]: loss 2.317488
[epoch6, step698]: loss 6.296162
[epoch6, step699]: loss 17.955305
[epoch6, step700]: loss 2.366001
[epoch6, step701]: loss 18.522095
[epoch6, step702]: loss 15.621640
[epoch6, step703]: loss 3.093536
[epoch6, step704]: loss 9.562847
[epoch6, step705]: loss 1.990435
[epoch6, step706]: loss 2.765098
[epoch6, step707]: loss 8.604436
[epoch6, step708]: loss 28.405996
[epoch6, step709]: loss 7.440099
[epoch6, step710]: loss 7.884355
[epoch6, step711]: loss 16.874701
[epoch6, step712]: loss 7.161686
[epoch6, step713]: loss 11.111898
[epoch6, step714]: loss 14.069659
[epoch6, step715]: loss 8.403646
[epoch6, step716]: loss 7.918023
[epoch6, step717]: loss 1.990501
[epoch6, step718]: loss 3.435823
[epoch6, step719]: loss 17.143757
[epoch6, step720]: loss 4.059312
[epoch6, step721]: loss 1.153607
[epoch6, step722]: loss 5.654197
[epoch6, step723]: loss 8.702345
[epoch6, step724]: loss 1.933113
[epoch6, step725]: loss 7.560529
[epoch6, step726]: loss 1.403205
[epoch6, step727]: loss 5.995189
[epoch6, step728]: loss 2.677427
[epoch6, step729]: loss 4.905383
[epoch6, step730]: loss 22.952713
[epoch6, step731]: loss 1.888615
[epoch6, step732]: loss 2.166675
[epoch6, step733]: loss 2.196379
[epoch6, step734]: loss 1.817741
[epoch6, step735]: loss 9.066092
[epoch6, step736]: loss 10.482005
[epoch6, step737]: loss 2.854446
[epoch6, step738]: loss 11.029154
[epoch6, step739]: loss 11.070426
[epoch6, step740]: loss 7.265429
[epoch6, step741]: loss 1.639753
[epoch6, step742]: loss 2.556122
[epoch6, step743]: loss 12.677054
[epoch6, step744]: loss 3.645096
[epoch6, step745]: loss 6.626266
[epoch6, step746]: loss 18.551161
[epoch6, step747]: loss 1.366188
[epoch6, step748]: loss 28.063641
[epoch6, step749]: loss 2.589662
[epoch6, step750]: loss 4.359717
[epoch6, step751]: loss 6.504159
[epoch6, step752]: loss 3.935755
[epoch6, step753]: loss 9.216257
[epoch6, step754]: loss 9.284534
[epoch6, step755]: loss 4.405708
[epoch6, step756]: loss 18.000063
[epoch6, step757]: loss 4.125395
[epoch6, step758]: loss 9.247522
[epoch6, step759]: loss 2.068090
[epoch6, step760]: loss 11.970429
[epoch6, step761]: loss 1.896163
[epoch6, step762]: loss 15.340625
[epoch6, step763]: loss 3.966307
[epoch6, step764]: loss 1.168900
[epoch6, step765]: loss 15.741687
[epoch6, step766]: loss 11.672231
[epoch6, step767]: loss 2.855179
[epoch6, step768]: loss 18.935066
[epoch6, step769]: loss 4.335066
[epoch6, step770]: loss 3.005275
[epoch6, step771]: loss 2.155976
[epoch6, step772]: loss 2.951433
[epoch6, step773]: loss 4.506724
[epoch6, step774]: loss 1.317619
[epoch6, step775]: loss 1.611960
[epoch6, step776]: loss 10.283689
[epoch6, step777]: loss 11.059940
[epoch6, step778]: loss 21.010210
[epoch6, step779]: loss 9.247001
[epoch6, step780]: loss 18.574141
[epoch6, step781]: loss 11.637068
[epoch6, step782]: loss 3.996221
[epoch6, step783]: loss 3.749545
[epoch6, step784]: loss 5.631942
[epoch6, step785]: loss 1.492680
[epoch6, step786]: loss 8.859703
[epoch6, step787]: loss 4.689726
[epoch6, step788]: loss 2.319335
[epoch6, step789]: loss 8.459319
[epoch6, step790]: loss 37.112320
[epoch6, step791]: loss 3.521606
[epoch6, step792]: loss 10.433513
[epoch6, step793]: loss 8.402032
[epoch6, step794]: loss 11.956711
[epoch6, step795]: loss 17.373222
[epoch6, step796]: loss 6.356806
[epoch6, step797]: loss 2.997482
[epoch6, step798]: loss 4.280463
[epoch6, step799]: loss 4.833367
[epoch6, step800]: loss 6.590873
[epoch6, step801]: loss 22.335762
[epoch6, step802]: loss 3.358456
[epoch6, step803]: loss 5.367536
[epoch6, step804]: loss 12.768273
[epoch6, step805]: loss 8.349810
[epoch6, step806]: loss 4.189631
[epoch6, step807]: loss 1.099361
[epoch6, step808]: loss 1.148125
[epoch6, step809]: loss 13.438039
[epoch6, step810]: loss 2.309956
[epoch6, step811]: loss 20.635077
[epoch6, step812]: loss 11.338457
[epoch6, step813]: loss 1.120322
[epoch6, step814]: loss 9.188872
[epoch6, step815]: loss 4.732610
[epoch6, step816]: loss 18.708500
[epoch6, step817]: loss 28.158833
[epoch6, step818]: loss 2.885631
[epoch6, step819]: loss 2.843079
[epoch6, step820]: loss 11.221415
[epoch6, step821]: loss 1.773175
[epoch6, step822]: loss 11.093465
[epoch6, step823]: loss 7.346511
[epoch6, step824]: loss 17.448561
[epoch6, step825]: loss 6.417345
[epoch6, step826]: loss 4.324864
[epoch6, step827]: loss 3.398284
[epoch6, step828]: loss 7.603728
[epoch6, step829]: loss 7.463553
[epoch6, step830]: loss 4.759913
[epoch6, step831]: loss 27.498960
[epoch6, step832]: loss 4.436519
[epoch6, step833]: loss 3.409478
[epoch6, step834]: loss 1.508553
[epoch6, step835]: loss 22.244034
[epoch6, step836]: loss 10.912677
[epoch6, step837]: loss 24.050623
[epoch6, step838]: loss 19.370646
[epoch6, step839]: loss 6.949397
[epoch6, step840]: loss 19.282982
[epoch6, step841]: loss 7.566475
[epoch6, step842]: loss 23.116467
[epoch6, step843]: loss 9.143553
[epoch6, step844]: loss 7.450175
[epoch6, step845]: loss 1.765375
[epoch6, step846]: loss 1.689641
[epoch6, step847]: loss 13.193281
[epoch6, step848]: loss 2.318129
[epoch6, step849]: loss 15.883772
[epoch6, step850]: loss 3.578275
[epoch6, step851]: loss 11.031369
[epoch6, step852]: loss 3.858122
[epoch6, step853]: loss 3.791933
[epoch6, step854]: loss 16.270555
[epoch6, step855]: loss 6.121551
[epoch6, step856]: loss 1.617002
[epoch6, step857]: loss 2.159794
[epoch6, step858]: loss 13.620919
[epoch6, step859]: loss 2.551112
[epoch6, step860]: loss 1.094224
[epoch6, step861]: loss 1.985741
[epoch6, step862]: loss 15.285233
[epoch6, step863]: loss 12.891917
[epoch6, step864]: loss 14.744951
[epoch6, step865]: loss 18.549305
[epoch6, step866]: loss 3.950266
[epoch6, step867]: loss 9.777959
[epoch6, step868]: loss 23.644608
[epoch6, step869]: loss 15.009666
[epoch6, step870]: loss 10.016582
[epoch6, step871]: loss 7.780051
[epoch6, step872]: loss 10.237638
[epoch6, step873]: loss 9.400032
[epoch6, step874]: loss 1.065702
[epoch6, step875]: loss 9.219584
[epoch6, step876]: loss 7.372071
[epoch6, step877]: loss 3.964789
[epoch6, step878]: loss 3.479356
[epoch6, step879]: loss 3.702703
[epoch6, step880]: loss 3.326364
[epoch6, step881]: loss 1.156524
[epoch6, step882]: loss 12.231650
[epoch6, step883]: loss 1.042232
[epoch6, step884]: loss 11.948230
[epoch6, step885]: loss 1.244193
[epoch6, step886]: loss 1.859953
[epoch6, step887]: loss 6.613241
[epoch6, step888]: loss 1.268773
[epoch6, step889]: loss 26.326933
[epoch6, step890]: loss 20.111263
[epoch6, step891]: loss 9.144050
[epoch6, step892]: loss 1.129956
[epoch6, step893]: loss 9.476918
[epoch6, step894]: loss 2.882185
[epoch6, step895]: loss 11.102436
[epoch6, step896]: loss 2.067964
[epoch6, step897]: loss 1.721419
[epoch6, step898]: loss 2.112539
[epoch6, step899]: loss 1.400509
[epoch6, step900]: loss 15.221563
[epoch6, step901]: loss 12.385503
[epoch6, step902]: loss 20.295425
[epoch6, step903]: loss 9.486380
[epoch6, step904]: loss 9.346094
[epoch6, step905]: loss 14.466925
[epoch6, step906]: loss 10.016212
[epoch6, step907]: loss 2.677492
[epoch6, step908]: loss 14.924088
[epoch6, step909]: loss 8.081895
[epoch6, step910]: loss 15.230293
[epoch6, step911]: loss 4.383344
[epoch6, step912]: loss 6.371981
[epoch6, step913]: loss 1.769029
[epoch6, step914]: loss 8.928720
[epoch6, step915]: loss 8.689977
[epoch6, step916]: loss 22.356089
[epoch6, step917]: loss 19.896351
[epoch6, step918]: loss 16.797108
[epoch6, step919]: loss 14.400324
[epoch6, step920]: loss 13.239265
[epoch6, step921]: loss 2.300629
[epoch6, step922]: loss 6.509725
[epoch6, step923]: loss 1.879309
[epoch6, step924]: loss 7.387590
[epoch6, step925]: loss 7.826107
[epoch6, step926]: loss 8.120567
[epoch6, step927]: loss 2.671391
[epoch6, step928]: loss 14.346482
[epoch6, step929]: loss 18.391823
[epoch6, step930]: loss 17.021349
[epoch6, step931]: loss 3.474199
[epoch6, step932]: loss 2.321683
[epoch6, step933]: loss 8.435145
[epoch6, step934]: loss 12.831831
[epoch6, step935]: loss 7.830414
[epoch6, step936]: loss 8.510399
[epoch6, step937]: loss 3.095695
[epoch6, step938]: loss 8.012774
[epoch6, step939]: loss 8.369350
[epoch6, step940]: loss 8.057070
[epoch6, step941]: loss 29.853376
[epoch6, step942]: loss 8.274354
[epoch6, step943]: loss 13.044417
[epoch6, step944]: loss 7.472395
[epoch6, step945]: loss 1.587889
[epoch6, step946]: loss 11.417602
[epoch6, step947]: loss 17.946638
[epoch6, step948]: loss 1.409283
[epoch6, step949]: loss 1.596880
[epoch6, step950]: loss 2.418332
[epoch6, step951]: loss 1.823754
[epoch6, step952]: loss 2.619627
[epoch6, step953]: loss 16.677176
[epoch6, step954]: loss 24.686232
[epoch6, step955]: loss 17.972898
[epoch6, step956]: loss 7.840653
[epoch6, step957]: loss 4.326916
[epoch6, step958]: loss 41.720890
[epoch6, step959]: loss 7.919930
[epoch6, step960]: loss 1.782678
[epoch6, step961]: loss 9.736798
[epoch6, step962]: loss 1.673332
[epoch6, step963]: loss 2.726089
[epoch6, step964]: loss 9.857656
[epoch6, step965]: loss 2.057443
[epoch6, step966]: loss 13.919472
[epoch6, step967]: loss 16.043903
[epoch6, step968]: loss 20.793364
[epoch6, step969]: loss 7.958493
[epoch6, step970]: loss 2.753998
[epoch6, step971]: loss 2.406283
[epoch6, step972]: loss 3.343715
[epoch6, step973]: loss 19.869802
[epoch6, step974]: loss 25.351349
[epoch6, step975]: loss 18.819338
[epoch6, step976]: loss 10.152362
[epoch6, step977]: loss 7.554409
[epoch6, step978]: loss 2.741537
[epoch6, step979]: loss 10.897358
[epoch6, step980]: loss 7.685858
[epoch6, step981]: loss 1.440788
[epoch6, step982]: loss 3.387837
[epoch6, step983]: loss 2.265754
[epoch6, step984]: loss 18.449318
[epoch6, step985]: loss 21.042957
[epoch6, step986]: loss 13.654990
[epoch6, step987]: loss 7.362921
[epoch6, step988]: loss 1.890843
[epoch6, step989]: loss 1.029714
[epoch6, step990]: loss 2.082394
[epoch6, step991]: loss 4.316912
[epoch6, step992]: loss 6.949118
[epoch6, step993]: loss 1.099608
[epoch6, step994]: loss 19.279564
[epoch6, step995]: loss 3.258589
[epoch6, step996]: loss 20.055105
[epoch6, step997]: loss 19.996126
[epoch6, step998]: loss 7.814836
[epoch6, step999]: loss 1.001830
[epoch6, step1000]: loss 30.482555
[epoch6, step1001]: loss 5.393045
[epoch6, step1002]: loss 2.447379
[epoch6, step1003]: loss 9.591702
[epoch6, step1004]: loss 4.869113
[epoch6, step1005]: loss 14.124284
[epoch6, step1006]: loss 2.463499
[epoch6, step1007]: loss 4.951710
[epoch6, step1008]: loss 4.623522
[epoch6, step1009]: loss 12.203900
[epoch6, step1010]: loss 2.347619
[epoch6, step1011]: loss 8.511978
[epoch6, step1012]: loss 6.339146
[epoch6, step1013]: loss 16.767199
[epoch6, step1014]: loss 14.287143
[epoch6, step1015]: loss 21.038479
[epoch6, step1016]: loss 2.754563
[epoch6, step1017]: loss 6.344051
[epoch6, step1018]: loss 1.003599
[epoch6, step1019]: loss 9.570128
[epoch6, step1020]: loss 3.650618
[epoch6, step1021]: loss 12.894250
[epoch6, step1022]: loss 2.015460
[epoch6, step1023]: loss 7.880737
[epoch6, step1024]: loss 2.434520
[epoch6, step1025]: loss 14.822324
[epoch6, step1026]: loss 4.533527
[epoch6, step1027]: loss 2.233016
[epoch6, step1028]: loss 1.905836
[epoch6, step1029]: loss 0.890677
[epoch6, step1030]: loss 11.169752
[epoch6, step1031]: loss 17.350912
[epoch6, step1032]: loss 16.353182
[epoch6, step1033]: loss 13.884741
[epoch6, step1034]: loss 4.071686
[epoch6, step1035]: loss 2.341485
[epoch6, step1036]: loss 2.816863
[epoch6, step1037]: loss 5.274990
[epoch6, step1038]: loss 15.546196
[epoch6, step1039]: loss 2.783215
[epoch6, step1040]: loss 3.213267
[epoch6, step1041]: loss 6.427608
[epoch6, step1042]: loss 5.332497
[epoch6, step1043]: loss 4.228442
[epoch6, step1044]: loss 2.058397
[epoch6, step1045]: loss 2.574168
[epoch6, step1046]: loss 11.851313
[epoch6, step1047]: loss 14.957718
[epoch6, step1048]: loss 2.492894
[epoch6, step1049]: loss 2.057225
[epoch6, step1050]: loss 1.982377
[epoch6, step1051]: loss 2.932914
[epoch6, step1052]: loss 30.439508
[epoch6, step1053]: loss 1.333681
[epoch6, step1054]: loss 14.473063
[epoch6, step1055]: loss 3.577243
[epoch6, step1056]: loss 14.871454
[epoch6, step1057]: loss 1.230550
[epoch6, step1058]: loss 7.560809
[epoch6, step1059]: loss 15.999612
[epoch6, step1060]: loss 2.764365
[epoch6, step1061]: loss 1.225609
[epoch6, step1062]: loss 8.990932
[epoch6, step1063]: loss 6.647122
[epoch6, step1064]: loss 8.714298
[epoch6, step1065]: loss 2.987837
[epoch6, step1066]: loss 2.612240
[epoch6, step1067]: loss 8.013453
[epoch6, step1068]: loss 6.366373
[epoch6, step1069]: loss 9.091098
[epoch6, step1070]: loss 14.639132
[epoch6, step1071]: loss 12.784949
[epoch6, step1072]: loss 2.079115
[epoch6, step1073]: loss 3.084289
[epoch6, step1074]: loss 7.969228
[epoch6, step1075]: loss 9.960596
[epoch6, step1076]: loss 1.365506
[epoch6, step1077]: loss 1.560698
[epoch6, step1078]: loss 7.908126
[epoch6, step1079]: loss 13.831971
[epoch6, step1080]: loss 6.189609
[epoch6, step1081]: loss 1.879577
[epoch6, step1082]: loss 7.119754
[epoch6, step1083]: loss 30.668013
[epoch6, step1084]: loss 3.051185
[epoch6, step1085]: loss 8.828543
[epoch6, step1086]: loss 1.242236
[epoch6, step1087]: loss 4.600653
[epoch6, step1088]: loss 2.228911
[epoch6, step1089]: loss 30.774549
[epoch6, step1090]: loss 11.029899
[epoch6, step1091]: loss 8.787574
[epoch6, step1092]: loss 11.443859
[epoch6, step1093]: loss 1.891059
[epoch6, step1094]: loss 12.150341
[epoch6, step1095]: loss 11.973464
[epoch6, step1096]: loss 3.380548
[epoch6, step1097]: loss 6.220129
[epoch6, step1098]: loss 1.326862
[epoch6, step1099]: loss 2.718710
[epoch6, step1100]: loss 1.591108
[epoch6, step1101]: loss 13.507089
[epoch6, step1102]: loss 10.060796
[epoch6, step1103]: loss 4.647074
[epoch6, step1104]: loss 2.857327
[epoch6, step1105]: loss 0.728012
[epoch6, step1106]: loss 2.506370
[epoch6, step1107]: loss 11.716600
[epoch6, step1108]: loss 13.551888
[epoch6, step1109]: loss 2.649188
[epoch6, step1110]: loss 23.009153
[epoch6, step1111]: loss 7.855911
[epoch6, step1112]: loss 4.138458
[epoch6, step1113]: loss 8.938078
[epoch6, step1114]: loss 6.193734
[epoch6, step1115]: loss 16.927996
[epoch6, step1116]: loss 1.644036
[epoch6, step1117]: loss 1.262493
[epoch6, step1118]: loss 10.493940
[epoch6, step1119]: loss 3.925086
[epoch6, step1120]: loss 14.822409
[epoch6, step1121]: loss 7.955565
[epoch6, step1122]: loss 16.568363
[epoch6, step1123]: loss 3.615106
[epoch6, step1124]: loss 6.604594
[epoch6, step1125]: loss 1.108151
[epoch6, step1126]: loss 14.800031
[epoch6, step1127]: loss 9.430429
[epoch6, step1128]: loss 14.966128
[epoch6, step1129]: loss 2.543090
[epoch6, step1130]: loss 7.858763
[epoch6, step1131]: loss 7.909009
[epoch6, step1132]: loss 8.172499
[epoch6, step1133]: loss 3.602188
[epoch6, step1134]: loss 7.414406
[epoch6, step1135]: loss 1.924101
[epoch6, step1136]: loss 3.753714
[epoch6, step1137]: loss 2.074269
[epoch6, step1138]: loss 1.556535
[epoch6, step1139]: loss 1.506741
[epoch6, step1140]: loss 1.637661
[epoch6, step1141]: loss 6.926284
[epoch6, step1142]: loss 1.133411
[epoch6, step1143]: loss 2.644899
[epoch6, step1144]: loss 1.550596
[epoch6, step1145]: loss 2.218382
[epoch6, step1146]: loss 3.397165
[epoch6, step1147]: loss 1.196736
[epoch6, step1148]: loss 18.904335
[epoch6, step1149]: loss 19.141676
[epoch6, step1150]: loss 3.101679
[epoch6, step1151]: loss 8.658366
[epoch6, step1152]: loss 2.775132
[epoch6, step1153]: loss 9.738521
[epoch6, step1154]: loss 2.527710
[epoch6, step1155]: loss 4.512219
[epoch6, step1156]: loss 19.004662
[epoch6, step1157]: loss 29.730621
[epoch6, step1158]: loss 6.576652
[epoch6, step1159]: loss 3.254350
[epoch6, step1160]: loss 5.354505
[epoch6, step1161]: loss 8.097607
[epoch6, step1162]: loss 15.440989
[epoch6, step1163]: loss 21.567791
[epoch6, step1164]: loss 4.054661
[epoch6, step1165]: loss 2.184072
[epoch6, step1166]: loss 1.085938
[epoch6, step1167]: loss 10.721973
[epoch6, step1168]: loss 19.669039
[epoch6, step1169]: loss 12.616497
[epoch6, step1170]: loss 14.732759
[epoch6, step1171]: loss 11.522337
[epoch6, step1172]: loss 2.431493
[epoch6, step1173]: loss 1.581767
[epoch6, step1174]: loss 1.576684
[epoch6, step1175]: loss 1.685925
[epoch6, step1176]: loss 11.086720
[epoch6, step1177]: loss 1.957762
[epoch6, step1178]: loss 3.404527
[epoch6, step1179]: loss 7.973712
[epoch6, step1180]: loss 5.235409
[epoch6, step1181]: loss 28.021059
[epoch6, step1182]: loss 1.883744
[epoch6, step1183]: loss 1.205352
[epoch6, step1184]: loss 2.322330
[epoch6, step1185]: loss 15.741699
[epoch6, step1186]: loss 1.283165
[epoch6, step1187]: loss 4.061194
[epoch6, step1188]: loss 3.183669
[epoch6, step1189]: loss 1.000538
[epoch6, step1190]: loss 3.482157
[epoch6, step1191]: loss 9.387727
[epoch6, step1192]: loss 2.694065
[epoch6, step1193]: loss 14.181952
[epoch6, step1194]: loss 12.223607
[epoch6, step1195]: loss 17.906347
[epoch6, step1196]: loss 6.144081
[epoch6, step1197]: loss 2.157640
[epoch6, step1198]: loss 44.652622
[epoch6, step1199]: loss 13.178536
[epoch6, step1200]: loss 13.674941
[epoch6, step1201]: loss 1.321653
[epoch6, step1202]: loss 7.650958
[epoch6, step1203]: loss 3.937496
[epoch6, step1204]: loss 2.656818
[epoch6, step1205]: loss 10.790090
[epoch6, step1206]: loss 4.241416
[epoch6, step1207]: loss 4.440873
[epoch6, step1208]: loss 9.612819
[epoch6, step1209]: loss 2.176999
[epoch6, step1210]: loss 1.382940
[epoch6, step1211]: loss 15.409974
[epoch6, step1212]: loss 2.185255
[epoch6, step1213]: loss 2.855626
[epoch6, step1214]: loss 10.478819
[epoch6, step1215]: loss 7.199063
[epoch6, step1216]: loss 3.278663
[epoch6, step1217]: loss 4.815443
[epoch6, step1218]: loss 21.826460
[epoch6, step1219]: loss 8.125331
[epoch6, step1220]: loss 3.121474
[epoch6, step1221]: loss 1.870155
[epoch6, step1222]: loss 1.842523
[epoch6, step1223]: loss 1.338498
[epoch6, step1224]: loss 2.510433
[epoch6, step1225]: loss 2.029220
[epoch6, step1226]: loss 8.145438
[epoch6, step1227]: loss 1.379722
[epoch6, step1228]: loss 1.522828
[epoch6, step1229]: loss 2.279410
[epoch6, step1230]: loss 8.240623
[epoch6, step1231]: loss 1.636908
[epoch6, step1232]: loss 18.254284
[epoch6, step1233]: loss 21.464806
[epoch6, step1234]: loss 18.964582
[epoch6, step1235]: loss 0.898581
[epoch6, step1236]: loss 1.915287
[epoch6, step1237]: loss 5.901165
[epoch6, step1238]: loss 8.034493
[epoch6, step1239]: loss 7.565149
[epoch6, step1240]: loss 3.110564
[epoch6, step1241]: loss 15.515438
[epoch6, step1242]: loss 16.517912
[epoch6, step1243]: loss 2.292720
[epoch6, step1244]: loss 1.623099
[epoch6, step1245]: loss 3.953317
[epoch6, step1246]: loss 8.076417
[epoch6, step1247]: loss 1.386607
[epoch6, step1248]: loss 5.929610
[epoch6, step1249]: loss 13.142619
[epoch6, step1250]: loss 2.175520
[epoch6, step1251]: loss 19.614019
[epoch6, step1252]: loss 10.021098
[epoch6, step1253]: loss 6.429245
[epoch6, step1254]: loss 6.845968
[epoch6, step1255]: loss 1.046812
[epoch6, step1256]: loss 2.189811
[epoch6, step1257]: loss 3.767394
[epoch6, step1258]: loss 6.932272
[epoch6, step1259]: loss 2.097553
[epoch6, step1260]: loss 1.620328
[epoch6, step1261]: loss 1.817417
[epoch6, step1262]: loss 3.157505
[epoch6, step1263]: loss 2.306163
[epoch6, step1264]: loss 2.955194
[epoch6, step1265]: loss 8.991611
[epoch6, step1266]: loss 3.418059
[epoch6, step1267]: loss 12.039663
[epoch6, step1268]: loss 1.161506
[epoch6, step1269]: loss 3.661712
[epoch6, step1270]: loss 5.762187
[epoch6, step1271]: loss 2.004045
[epoch6, step1272]: loss 11.717211
[epoch6, step1273]: loss 12.129088
[epoch6, step1274]: loss 2.183975
[epoch6, step1275]: loss 4.801213
[epoch6, step1276]: loss 17.230751
[epoch6, step1277]: loss 8.388363
[epoch6, step1278]: loss 19.676426
[epoch6, step1279]: loss 1.921901
[epoch6, step1280]: loss 3.362797
[epoch6, step1281]: loss 3.824314
[epoch6, step1282]: loss 2.085286
[epoch6, step1283]: loss 1.579369
[epoch6, step1284]: loss 12.942943
[epoch6, step1285]: loss 1.865500
[epoch6, step1286]: loss 14.051660
[epoch6, step1287]: loss 20.203756
[epoch6, step1288]: loss 1.298769
[epoch6, step1289]: loss 7.606817
[epoch6, step1290]: loss 3.279263
[epoch6, step1291]: loss 2.248614
[epoch6, step1292]: loss 4.318495
[epoch6, step1293]: loss 7.550611
[epoch6, step1294]: loss 2.543705
[epoch6, step1295]: loss 3.889207
[epoch6, step1296]: loss 7.465362
[epoch6, step1297]: loss 15.991286
[epoch6, step1298]: loss 5.157753
[epoch6, step1299]: loss 16.605030
[epoch6, step1300]: loss 2.675607
[epoch6, step1301]: loss 3.222069
[epoch6, step1302]: loss 1.276886
[epoch6, step1303]: loss 12.501634
[epoch6, step1304]: loss 3.274659
[epoch6, step1305]: loss 10.047270
[epoch6, step1306]: loss 1.987452
[epoch6, step1307]: loss 1.486070
[epoch6, step1308]: loss 1.853391
[epoch6, step1309]: loss 5.587407
[epoch6, step1310]: loss 2.408927
[epoch6, step1311]: loss 9.289706
[epoch6, step1312]: loss 2.790707
[epoch6, step1313]: loss 3.308190
[epoch6, step1314]: loss 2.229105
[epoch6, step1315]: loss 17.994917
[epoch6, step1316]: loss 1.366994
[epoch6, step1317]: loss 16.345695
[epoch6, step1318]: loss 10.926932
[epoch6, step1319]: loss 20.469610
[epoch6, step1320]: loss 2.913736
[epoch6, step1321]: loss 14.618003
[epoch6, step1322]: loss 3.320236
[epoch6, step1323]: loss 0.984564
[epoch6, step1324]: loss 4.401747
[epoch6, step1325]: loss 17.762146
[epoch6, step1326]: loss 1.501598
[epoch6, step1327]: loss 2.346095
[epoch6, step1328]: loss 8.620040
[epoch6, step1329]: loss 10.949067
[epoch6, step1330]: loss 1.488178
[epoch6, step1331]: loss 29.037270
[epoch6, step1332]: loss 2.749367
[epoch6, step1333]: loss 10.737863
[epoch6, step1334]: loss 1.645117
[epoch6, step1335]: loss 13.601111
[epoch6, step1336]: loss 1.228804
[epoch6, step1337]: loss 25.259071
[epoch6, step1338]: loss 7.235576
[epoch6, step1339]: loss 1.119582
[epoch6, step1340]: loss 3.508490
[epoch6, step1341]: loss 4.660851
[epoch6, step1342]: loss 2.101301
[epoch6, step1343]: loss 1.032463
[epoch6, step1344]: loss 15.927000
[epoch6, step1345]: loss 1.301208
[epoch6, step1346]: loss 1.423475
[epoch6, step1347]: loss 2.107103
[epoch6, step1348]: loss 2.983935
[epoch6, step1349]: loss 20.209040
[epoch6, step1350]: loss 4.349889
[epoch6, step1351]: loss 15.667664
[epoch6, step1352]: loss 4.459690
[epoch6, step1353]: loss 2.561483
[epoch6, step1354]: loss 3.553517
[epoch6, step1355]: loss 5.691093
[epoch6, step1356]: loss 9.193254
[epoch6, step1357]: loss 39.641457
[epoch6, step1358]: loss 21.695440
[epoch6, step1359]: loss 1.222577
[epoch6, step1360]: loss 6.248358
[epoch6, step1361]: loss 1.513253
[epoch6, step1362]: loss 4.822958
[epoch6, step1363]: loss 18.710312
[epoch6, step1364]: loss 3.341570
[epoch6, step1365]: loss 16.769497
[epoch6, step1366]: loss 2.906746
[epoch6, step1367]: loss 17.460962
[epoch6, step1368]: loss 10.797483
[epoch6, step1369]: loss 9.822850
[epoch6, step1370]: loss 3.473676
[epoch6, step1371]: loss 5.764597
[epoch6, step1372]: loss 9.138703
[epoch6, step1373]: loss 1.362742
[epoch6, step1374]: loss 6.592742
[epoch6, step1375]: loss 1.763256
[epoch6, step1376]: loss 5.228300
[epoch6, step1377]: loss 5.763678
[epoch6, step1378]: loss 1.364572
[epoch6, step1379]: loss 7.254130
[epoch6, step1380]: loss 3.829992
[epoch6, step1381]: loss 4.359920
[epoch6, step1382]: loss 11.041285
[epoch6, step1383]: loss 2.563720
[epoch6, step1384]: loss 8.292360
[epoch6, step1385]: loss 11.178166
[epoch6, step1386]: loss 7.204209
[epoch6, step1387]: loss 7.027998
[epoch6, step1388]: loss 2.825871
[epoch6, step1389]: loss 28.385719
[epoch6, step1390]: loss 3.926919
[epoch6, step1391]: loss 2.093894
[epoch6, step1392]: loss 7.130468
[epoch6, step1393]: loss 7.129578
[epoch6, step1394]: loss 8.908624
[epoch6, step1395]: loss 9.306252
[epoch6, step1396]: loss 2.855067
[epoch6, step1397]: loss 21.875883
[epoch6, step1398]: loss 18.021046
[epoch6, step1399]: loss 2.707041
[epoch6, step1400]: loss 3.039398
[epoch6, step1401]: loss 11.553007
[epoch6, step1402]: loss 16.223639
[epoch6, step1403]: loss 2.425340
[epoch6, step1404]: loss 3.853453
[epoch6, step1405]: loss 11.049866
[epoch6, step1406]: loss 15.922387
[epoch6, step1407]: loss 3.377895
[epoch6, step1408]: loss 2.620579
[epoch6, step1409]: loss 5.242317
[epoch6, step1410]: loss 1.174888
[epoch6, step1411]: loss 16.854605
[epoch6, step1412]: loss 9.174359
[epoch6, step1413]: loss 4.859120
[epoch6, step1414]: loss 21.369507
[epoch6, step1415]: loss 6.519224
[epoch6, step1416]: loss 11.668296
[epoch6, step1417]: loss 2.296754
[epoch6, step1418]: loss 1.633829
[epoch6, step1419]: loss 2.296444
[epoch6, step1420]: loss 9.843114
[epoch6, step1421]: loss 14.868638
[epoch6, step1422]: loss 4.678653
[epoch6, step1423]: loss 14.645307
[epoch6, step1424]: loss 19.420843
[epoch6, step1425]: loss 2.913908
[epoch6, step1426]: loss 7.668429
[epoch6, step1427]: loss 1.186540
[epoch6, step1428]: loss 1.707126
[epoch6, step1429]: loss 7.434595
[epoch6, step1430]: loss 8.071548
[epoch6, step1431]: loss 8.720160
[epoch6, step1432]: loss 8.743457
[epoch6, step1433]: loss 9.673513
[epoch6, step1434]: loss 12.804416
[epoch6, step1435]: loss 7.360947
[epoch6, step1436]: loss 2.323712
[epoch6, step1437]: loss 2.139923
[epoch6, step1438]: loss 3.419959
[epoch6, step1439]: loss 13.869278
[epoch6, step1440]: loss 4.539719
[epoch6, step1441]: loss 32.110214
[epoch6, step1442]: loss 3.144033
[epoch6, step1443]: loss 2.866019
[epoch6, step1444]: loss 16.325508
[epoch6, step1445]: loss 11.678612
[epoch6, step1446]: loss 10.156052
[epoch6, step1447]: loss 2.618872
[epoch6, step1448]: loss 8.452450
[epoch6, step1449]: loss 2.655405
[epoch6, step1450]: loss 2.287887
[epoch6, step1451]: loss 1.387333
[epoch6, step1452]: loss 7.728427
[epoch6, step1453]: loss 2.303066
[epoch6, step1454]: loss 21.782932
[epoch6, step1455]: loss 1.776076
[epoch6, step1456]: loss 14.518161
[epoch6, step1457]: loss 2.584395
[epoch6, step1458]: loss 15.138897
[epoch6, step1459]: loss 3.843302
[epoch6, step1460]: loss 3.134972
[epoch6, step1461]: loss 1.607422
[epoch6, step1462]: loss 2.368086
[epoch6, step1463]: loss 14.356413
[epoch6, step1464]: loss 2.491740
[epoch6, step1465]: loss 4.146314
[epoch6, step1466]: loss 4.210522
[epoch6, step1467]: loss 3.424964
[epoch6, step1468]: loss 8.970864
[epoch6, step1469]: loss 19.326385
[epoch6, step1470]: loss 2.325418
[epoch6, step1471]: loss 27.567636
[epoch6, step1472]: loss 10.251075
[epoch6, step1473]: loss 7.818713
[epoch6, step1474]: loss 4.791446
[epoch6, step1475]: loss 10.766638
[epoch6, step1476]: loss 2.431231
[epoch6, step1477]: loss 7.023211
[epoch6, step1478]: loss 2.343693
[epoch6, step1479]: loss 11.236971
[epoch6, step1480]: loss 2.347508
[epoch6, step1481]: loss 10.319556
[epoch6, step1482]: loss 8.350322
[epoch6, step1483]: loss 2.136281
[epoch6, step1484]: loss 1.187304
[epoch6, step1485]: loss 2.461320
[epoch6, step1486]: loss 5.213570
[epoch6, step1487]: loss 2.690563
[epoch6, step1488]: loss 7.436866
[epoch6, step1489]: loss 8.054632
[epoch6, step1490]: loss 3.862820
[epoch6, step1491]: loss 3.001524
[epoch6, step1492]: loss 4.056392
[epoch6, step1493]: loss 8.045500
[epoch6, step1494]: loss 4.834743
[epoch6, step1495]: loss 1.857325
[epoch6, step1496]: loss 12.272068
[epoch6, step1497]: loss 3.021333
[epoch6, step1498]: loss 10.417233
[epoch6, step1499]: loss 3.669473
[epoch6, step1500]: loss 2.235080
[epoch6, step1501]: loss 1.307791
[epoch6, step1502]: loss 4.139276
[epoch6, step1503]: loss 6.985544
[epoch6, step1504]: loss 2.139218
[epoch6, step1505]: loss 4.172904
[epoch6, step1506]: loss 11.909506
[epoch6, step1507]: loss 24.337366
[epoch6, step1508]: loss 1.236253
[epoch6, step1509]: loss 12.255845
[epoch6, step1510]: loss 2.561107
[epoch6, step1511]: loss 7.610828
[epoch6, step1512]: loss 7.633558
[epoch6, step1513]: loss 12.459033
[epoch6, step1514]: loss 5.283494
[epoch6, step1515]: loss 34.210457
[epoch6, step1516]: loss 7.934020
[epoch6, step1517]: loss 13.434105
[epoch6, step1518]: loss 3.219532
[epoch6, step1519]: loss 3.667573
[epoch6, step1520]: loss 5.851311
[epoch6, step1521]: loss 1.892380
[epoch6, step1522]: loss 2.271534
[epoch6, step1523]: loss 3.943573
[epoch6, step1524]: loss 22.631702
[epoch6, step1525]: loss 1.706897
[epoch6, step1526]: loss 3.371884
[epoch6, step1527]: loss 15.233212
[epoch6, step1528]: loss 12.083454
[epoch6, step1529]: loss 15.518408
[epoch6, step1530]: loss 17.385031
[epoch6, step1531]: loss 11.416945
[epoch6, step1532]: loss 3.549228
[epoch6, step1533]: loss 18.978720
[epoch6, step1534]: loss 8.088123
[epoch6, step1535]: loss 3.267610
[epoch6, step1536]: loss 7.200183
[epoch6, step1537]: loss 3.654794
[epoch6, step1538]: loss 2.211439
[epoch6, step1539]: loss 1.941509
[epoch6, step1540]: loss 2.809345
[epoch6, step1541]: loss 2.079153
[epoch6, step1542]: loss 1.569277
[epoch6, step1543]: loss 1.839406
[epoch6, step1544]: loss 4.614391
[epoch6, step1545]: loss 9.124106
[epoch6, step1546]: loss 14.877810
[epoch6, step1547]: loss 1.910631
[epoch6, step1548]: loss 7.136434
[epoch6, step1549]: loss 19.700382
[epoch6, step1550]: loss 2.918624
[epoch6, step1551]: loss 9.116878
[epoch6, step1552]: loss 7.947432
[epoch6, step1553]: loss 9.364902
[epoch6, step1554]: loss 3.363142
[epoch6, step1555]: loss 7.508209
[epoch6, step1556]: loss 2.568872
[epoch6, step1557]: loss 8.230071
[epoch6, step1558]: loss 8.853303
[epoch6, step1559]: loss 6.570573
[epoch6, step1560]: loss 2.343206
[epoch6, step1561]: loss 3.263930
[epoch6, step1562]: loss 9.369606
[epoch6, step1563]: loss 2.993009
[epoch6, step1564]: loss 22.791647
[epoch6, step1565]: loss 1.455263
[epoch6, step1566]: loss 1.464763
[epoch6, step1567]: loss 3.743376
[epoch6, step1568]: loss 7.591326
[epoch6, step1569]: loss 9.225161
[epoch6, step1570]: loss 2.876109
[epoch6, step1571]: loss 33.985394
[epoch6, step1572]: loss 15.052646
[epoch6, step1573]: loss 15.880685
[epoch6, step1574]: loss 22.567045
[epoch6, step1575]: loss 20.199286
[epoch6, step1576]: loss 10.832626
[epoch6, step1577]: loss 3.070947
[epoch6, step1578]: loss 8.763562
[epoch6, step1579]: loss 2.103617
[epoch6, step1580]: loss 1.837641
[epoch6, step1581]: loss 11.660698
[epoch6, step1582]: loss 6.905523
[epoch6, step1583]: loss 3.836262
[epoch6, step1584]: loss 2.492529
[epoch6, step1585]: loss 3.427216
[epoch6, step1586]: loss 8.395065
[epoch6, step1587]: loss 4.985230
[epoch6, step1588]: loss 4.282384
[epoch6, step1589]: loss 8.771045
[epoch6, step1590]: loss 15.804233
[epoch6, step1591]: loss 5.881959
[epoch6, step1592]: loss 6.583615
[epoch6, step1593]: loss 2.319695
[epoch6, step1594]: loss 12.430387
[epoch6, step1595]: loss 13.519213
[epoch6, step1596]: loss 3.265114
[epoch6, step1597]: loss 16.479189
[epoch6, step1598]: loss 1.496008
[epoch6, step1599]: loss 4.037030
[epoch6, step1600]: loss 7.106916
[epoch6, step1601]: loss 2.482334
[epoch6, step1602]: loss 19.176458
[epoch6, step1603]: loss 15.091488
[epoch6, step1604]: loss 1.838951
[epoch6, step1605]: loss 1.172350
[epoch6, step1606]: loss 3.457065
[epoch6, step1607]: loss 22.186607
[epoch6, step1608]: loss 22.565187
[epoch6, step1609]: loss 2.131356
[epoch6, step1610]: loss 10.482873
[epoch6, step1611]: loss 6.782089
[epoch6, step1612]: loss 14.231144
[epoch6, step1613]: loss 6.584013
[epoch6, step1614]: loss 8.355168
[epoch6, step1615]: loss 4.518748
[epoch6, step1616]: loss 1.137192
[epoch6, step1617]: loss 25.273741
[epoch6, step1618]: loss 1.879713
[epoch6, step1619]: loss 11.114312
[epoch6, step1620]: loss 6.372544
[epoch6, step1621]: loss 6.760572
[epoch6, step1622]: loss 16.563614
[epoch6, step1623]: loss 12.028882
[epoch6, step1624]: loss 2.562129
[epoch6, step1625]: loss 8.136533
[epoch6, step1626]: loss 6.657368
[epoch6, step1627]: loss 1.609698
[epoch6, step1628]: loss 2.348049
[epoch6, step1629]: loss 20.302868
[epoch6, step1630]: loss 7.477096
[epoch6, step1631]: loss 2.091345
[epoch6, step1632]: loss 15.981212
[epoch6, step1633]: loss 9.002658
[epoch6, step1634]: loss 1.671192
[epoch6, step1635]: loss 12.367371
[epoch6, step1636]: loss 2.289128
[epoch6, step1637]: loss 2.290924
[epoch6, step1638]: loss 3.757916
[epoch6, step1639]: loss 4.864915
[epoch6, step1640]: loss 1.781563
[epoch6, step1641]: loss 6.678222
[epoch6, step1642]: loss 1.427213
[epoch6, step1643]: loss 11.915223
[epoch6, step1644]: loss 6.870171
[epoch6, step1645]: loss 1.398506
[epoch6, step1646]: loss 1.621806
[epoch6, step1647]: loss 2.478016
[epoch6, step1648]: loss 3.153435
[epoch6, step1649]: loss 1.544765
[epoch6, step1650]: loss 10.641993
[epoch6, step1651]: loss 4.980889
[epoch6, step1652]: loss 2.200025
[epoch6, step1653]: loss 1.211674
[epoch6, step1654]: loss 10.170073
[epoch6, step1655]: loss 3.089852
[epoch6, step1656]: loss 3.055940
[epoch6, step1657]: loss 9.299067
[epoch6, step1658]: loss 2.146564
[epoch6, step1659]: loss 3.173537
[epoch6, step1660]: loss 1.654452
[epoch6, step1661]: loss 3.092709
[epoch6, step1662]: loss 1.225929
[epoch6, step1663]: loss 3.224309
[epoch6, step1664]: loss 4.247940
[epoch6, step1665]: loss 1.992309
[epoch6, step1666]: loss 2.189265
[epoch6, step1667]: loss 2.589739
[epoch6, step1668]: loss 1.400471
[epoch6, step1669]: loss 7.967267
[epoch6, step1670]: loss 3.941610
[epoch6, step1671]: loss 1.379101
[epoch6, step1672]: loss 9.738000
[epoch6, step1673]: loss 30.660484
[epoch6, step1674]: loss 4.575909
[epoch6, step1675]: loss 3.443116
[epoch6, step1676]: loss 11.709127
[epoch6, step1677]: loss 19.693487
[epoch6, step1678]: loss 3.381774
[epoch6, step1679]: loss 8.704404
[epoch6, step1680]: loss 9.208242
[epoch6, step1681]: loss 6.161918
[epoch6, step1682]: loss 14.464562
[epoch6, step1683]: loss 4.107979
[epoch6, step1684]: loss 3.576693
[epoch6, step1685]: loss 3.107479
[epoch6, step1686]: loss 5.987333
[epoch6, step1687]: loss 13.722436
[epoch6, step1688]: loss 12.993091
[epoch6, step1689]: loss 8.112358
[epoch6, step1690]: loss 1.399755
[epoch6, step1691]: loss 2.005722
[epoch6, step1692]: loss 2.070000
[epoch6, step1693]: loss 11.546206
[epoch6, step1694]: loss 8.084745
[epoch6, step1695]: loss 3.606412
[epoch6, step1696]: loss 3.087307
[epoch6, step1697]: loss 4.864561
[epoch6, step1698]: loss 13.345510
[epoch6, step1699]: loss 6.475121
[epoch6, step1700]: loss 16.151365
[epoch6, step1701]: loss 1.532185
[epoch6, step1702]: loss 2.540348
[epoch6, step1703]: loss 8.241215
[epoch6, step1704]: loss 5.310328
[epoch6, step1705]: loss 13.683236
[epoch6, step1706]: loss 4.485214
[epoch6, step1707]: loss 6.787460
[epoch6, step1708]: loss 6.392352
[epoch6, step1709]: loss 12.511425
[epoch6, step1710]: loss 4.426327
[epoch6, step1711]: loss 3.629397
[epoch6, step1712]: loss 6.906468
[epoch6, step1713]: loss 1.705442
[epoch6, step1714]: loss 1.558738
[epoch6, step1715]: loss 1.919456
[epoch6, step1716]: loss 2.203739
[epoch6, step1717]: loss 3.029375
[epoch6, step1718]: loss 11.563052
[epoch6, step1719]: loss 10.043873
[epoch6, step1720]: loss 1.235560
[epoch6, step1721]: loss 6.596488
[epoch6, step1722]: loss 6.365022
[epoch6, step1723]: loss 2.890348
[epoch6, step1724]: loss 2.929865
[epoch6, step1725]: loss 10.245571
[epoch6, step1726]: loss 1.287465
[epoch6, step1727]: loss 5.063145
[epoch6, step1728]: loss 7.870514
[epoch6, step1729]: loss 2.174886
[epoch6, step1730]: loss 6.286313
[epoch6, step1731]: loss 6.829040
[epoch6, step1732]: loss 7.317224
[epoch6, step1733]: loss 1.613706
[epoch6, step1734]: loss 16.851961
[epoch6, step1735]: loss 13.049624
[epoch6, step1736]: loss 2.260441
[epoch6, step1737]: loss 2.575797
[epoch6, step1738]: loss 7.424323
[epoch6, step1739]: loss 9.482018
[epoch6, step1740]: loss 6.812212
[epoch6, step1741]: loss 7.985479
[epoch6, step1742]: loss 2.469265
[epoch6, step1743]: loss 6.399205
[epoch6, step1744]: loss 18.467148
[epoch6, step1745]: loss 3.783409
[epoch6, step1746]: loss 9.356277
[epoch6, step1747]: loss 7.228791
[epoch6, step1748]: loss 6.599739
[epoch6, step1749]: loss 3.485222
[epoch6, step1750]: loss 4.832431
[epoch6, step1751]: loss 16.643562
[epoch6, step1752]: loss 1.334210
[epoch6, step1753]: loss 2.367442
[epoch6, step1754]: loss 7.665156
[epoch6, step1755]: loss 7.006373
[epoch6, step1756]: loss 2.786572
[epoch6, step1757]: loss 17.343670
[epoch6, step1758]: loss 3.506202
[epoch6, step1759]: loss 19.869978
[epoch6, step1760]: loss 18.717613
[epoch6, step1761]: loss 2.498870
[epoch6, step1762]: loss 2.302704
[epoch6, step1763]: loss 1.130732
[epoch6, step1764]: loss 3.164782
[epoch6, step1765]: loss 4.059772
[epoch6, step1766]: loss 10.645848
[epoch6, step1767]: loss 17.749023
[epoch6, step1768]: loss 3.968678
[epoch6, step1769]: loss 2.831986
[epoch6, step1770]: loss 6.736845
[epoch6, step1771]: loss 3.827426
[epoch6, step1772]: loss 4.269394
[epoch6, step1773]: loss 4.510132
[epoch6, step1774]: loss 26.090244
[epoch6, step1775]: loss 1.930240
[epoch6, step1776]: loss 1.449385
[epoch6, step1777]: loss 2.430750
[epoch6, step1778]: loss 3.126221
[epoch6, step1779]: loss 7.788769
[epoch6, step1780]: loss 14.560760
[epoch6, step1781]: loss 5.535887
[epoch6, step1782]: loss 3.959599
[epoch6, step1783]: loss 1.796539
[epoch6, step1784]: loss 2.369973
[epoch6, step1785]: loss 1.118462
[epoch6, step1786]: loss 4.940764
[epoch6, step1787]: loss 13.884469
[epoch6, step1788]: loss 3.575680
[epoch6, step1789]: loss 6.682294
[epoch6, step1790]: loss 3.591741
[epoch6, step1791]: loss 15.146620
[epoch6, step1792]: loss 5.485369
[epoch6, step1793]: loss 4.974157
[epoch6, step1794]: loss 3.995911
[epoch6, step1795]: loss 7.377640
[epoch6, step1796]: loss 6.587082
[epoch6, step1797]: loss 3.464892
[epoch6, step1798]: loss 8.082283
[epoch6, step1799]: loss 15.874604
[epoch6, step1800]: loss 1.378581
[epoch6, step1801]: loss 7.241976
[epoch6, step1802]: loss 1.708340
[epoch6, step1803]: loss 3.673333
[epoch6, step1804]: loss 20.109913
[epoch6, step1805]: loss 2.419196
[epoch6, step1806]: loss 1.485039
[epoch6, step1807]: loss 6.871385
[epoch6, step1808]: loss 1.958331
[epoch6, step1809]: loss 9.752922
[epoch6, step1810]: loss 4.559848
[epoch6, step1811]: loss 3.931053
[epoch6, step1812]: loss 8.922967
[epoch6, step1813]: loss 6.827008
[epoch6, step1814]: loss 10.591657
[epoch6, step1815]: loss 13.769344
[epoch6, step1816]: loss 4.331010
[epoch6, step1817]: loss 2.241377
[epoch6, step1818]: loss 4.234164
[epoch6, step1819]: loss 17.023849
[epoch6, step1820]: loss 1.732369
[epoch6, step1821]: loss 10.728765
[epoch6, step1822]: loss 1.056359
[epoch6, step1823]: loss 17.925915
[epoch6, step1824]: loss 9.129882
[epoch6, step1825]: loss 4.179987
[epoch6, step1826]: loss 3.102126
[epoch6, step1827]: loss 13.507666
[epoch6, step1828]: loss 4.642154
[epoch6, step1829]: loss 9.683405
[epoch6, step1830]: loss 3.031003
[epoch6, step1831]: loss 6.444751
[epoch6, step1832]: loss 2.302979
[epoch6, step1833]: loss 4.368504
[epoch6, step1834]: loss 8.549523
[epoch6, step1835]: loss 2.272705
[epoch6, step1836]: loss 16.106596
[epoch6, step1837]: loss 15.108828
[epoch6, step1838]: loss 12.641689
[epoch6, step1839]: loss 6.762585
[epoch6, step1840]: loss 2.211049
[epoch6, step1841]: loss 9.536729
[epoch6, step1842]: loss 11.351734
[epoch6, step1843]: loss 1.382896
[epoch6, step1844]: loss 6.126481
[epoch6, step1845]: loss 26.584309
[epoch6, step1846]: loss 15.345574
[epoch6, step1847]: loss 3.295697
[epoch6, step1848]: loss 8.217695
[epoch6, step1849]: loss 1.220925
[epoch6, step1850]: loss 2.785517
[epoch6, step1851]: loss 6.530885
[epoch6, step1852]: loss 2.109492
[epoch6, step1853]: loss 3.667011
[epoch6, step1854]: loss 6.119958
[epoch6, step1855]: loss 28.491169
[epoch6, step1856]: loss 1.640797
[epoch6, step1857]: loss 15.613806
[epoch6, step1858]: loss 18.291332
[epoch6, step1859]: loss 14.813767
[epoch6, step1860]: loss 2.510072
[epoch6, step1861]: loss 9.232938
[epoch6, step1862]: loss 1.785495
[epoch6, step1863]: loss 3.828269
[epoch6, step1864]: loss 8.602162
[epoch6, step1865]: loss 2.264606
[epoch6, step1866]: loss 2.525340
[epoch6, step1867]: loss 5.551937
[epoch6, step1868]: loss 6.242906
[epoch6, step1869]: loss 8.792583
[epoch6, step1870]: loss 2.880549
[epoch6, step1871]: loss 18.282026
[epoch6, step1872]: loss 2.281667
[epoch6, step1873]: loss 2.150350
[epoch6, step1874]: loss 5.182897
[epoch6, step1875]: loss 20.314440
[epoch6, step1876]: loss 2.178769
[epoch6, step1877]: loss 12.811687
[epoch6, step1878]: loss 6.161057
[epoch6, step1879]: loss 3.419341
[epoch6, step1880]: loss 2.528253
[epoch6, step1881]: loss 13.471681
[epoch6, step1882]: loss 9.293245
[epoch6, step1883]: loss 7.116500
[epoch6, step1884]: loss 24.425024
[epoch6, step1885]: loss 3.095601
[epoch6, step1886]: loss 9.067648
[epoch6, step1887]: loss 14.492229
[epoch6, step1888]: loss 14.079176
[epoch6, step1889]: loss 3.521515
[epoch6, step1890]: loss 3.459465
[epoch6, step1891]: loss 6.421496
[epoch6, step1892]: loss 7.064271
[epoch6, step1893]: loss 2.749743
[epoch6, step1894]: loss 37.308548
[epoch6, step1895]: loss 14.076700
[epoch6, step1896]: loss 11.832224
[epoch6, step1897]: loss 8.084807
[epoch6, step1898]: loss 2.183803
[epoch6, step1899]: loss 9.504845
[epoch6, step1900]: loss 1.612019
[epoch6, step1901]: loss 1.883492
[epoch6, step1902]: loss 5.255735
[epoch6, step1903]: loss 2.477044
[epoch6, step1904]: loss 18.041645
[epoch6, step1905]: loss 4.029732
[epoch6, step1906]: loss 6.538906
[epoch6, step1907]: loss 1.460104
[epoch6, step1908]: loss 5.920535
[epoch6, step1909]: loss 4.133466
[epoch6, step1910]: loss 1.824394
[epoch6, step1911]: loss 16.096512
[epoch6, step1912]: loss 6.746735
[epoch6, step1913]: loss 12.212896
[epoch6, step1914]: loss 2.013673
[epoch6, step1915]: loss 4.175574
[epoch6, step1916]: loss 12.451266
[epoch6, step1917]: loss 11.221372
[epoch6, step1918]: loss 11.460711
[epoch6, step1919]: loss 6.133344
[epoch6, step1920]: loss 15.780588
[epoch6, step1921]: loss 23.052113
[epoch6, step1922]: loss 1.859431
[epoch6, step1923]: loss 4.844066
[epoch6, step1924]: loss 10.080812
[epoch6, step1925]: loss 15.336279
[epoch6, step1926]: loss 1.486599
[epoch6, step1927]: loss 1.239357
[epoch6, step1928]: loss 14.308952
[epoch6, step1929]: loss 1.114807
[epoch6, step1930]: loss 11.837834
[epoch6, step1931]: loss 10.143289
[epoch6, step1932]: loss 2.613959
[epoch6, step1933]: loss 2.396517
[epoch6, step1934]: loss 12.288070
[epoch6, step1935]: loss 1.021895
[epoch6, step1936]: loss 14.967196
[epoch6, step1937]: loss 1.532308
[epoch6, step1938]: loss 3.746234
[epoch6, step1939]: loss 3.753618
[epoch6, step1940]: loss 1.750283
[epoch6, step1941]: loss 7.434314
[epoch6, step1942]: loss 17.864906
[epoch6, step1943]: loss 5.267395
[epoch6, step1944]: loss 12.247615
[epoch6, step1945]: loss 2.973735
[epoch6, step1946]: loss 2.531952
[epoch6, step1947]: loss 2.340894
[epoch6, step1948]: loss 3.528382
[epoch6, step1949]: loss 16.957674
[epoch6, step1950]: loss 1.327947
[epoch6, step1951]: loss 8.108836
[epoch6, step1952]: loss 4.036456
[epoch6, step1953]: loss 14.087636
[epoch6, step1954]: loss 13.471534
[epoch6, step1955]: loss 10.554722
[epoch6, step1956]: loss 6.826704
[epoch6, step1957]: loss 1.951048
[epoch6, step1958]: loss 9.304944
[epoch6, step1959]: loss 7.375685
[epoch6, step1960]: loss 1.488580
[epoch6, step1961]: loss 2.961343
[epoch6, step1962]: loss 1.859132
[epoch6, step1963]: loss 1.680340
[epoch6, step1964]: loss 9.961292
[epoch6, step1965]: loss 15.336672
[epoch6, step1966]: loss 14.697394
[epoch6, step1967]: loss 4.713593
[epoch6, step1968]: loss 2.884794
[epoch6, step1969]: loss 11.958907
[epoch6, step1970]: loss 16.827274
[epoch6, step1971]: loss 14.746248
[epoch6, step1972]: loss 1.881849
[epoch6, step1973]: loss 16.197971
[epoch6, step1974]: loss 2.693008
[epoch6, step1975]: loss 8.386910
[epoch6, step1976]: loss 8.155620
[epoch6, step1977]: loss 5.867619
[epoch6, step1978]: loss 25.596176
[epoch6, step1979]: loss 7.109696
[epoch6, step1980]: loss 3.440587
[epoch6, step1981]: loss 12.357521
[epoch6, step1982]: loss 8.155229
[epoch6, step1983]: loss 7.861427
[epoch6, step1984]: loss 10.371123
[epoch6, step1985]: loss 11.113746
[epoch6, step1986]: loss 1.678629
[epoch6, step1987]: loss 2.860504
[epoch6, step1988]: loss 0.969677
[epoch6, step1989]: loss 11.190469
[epoch6, step1990]: loss 4.501108
[epoch6, step1991]: loss 2.360684
[epoch6, step1992]: loss 18.415953
[epoch6, step1993]: loss 6.572482
[epoch6, step1994]: loss 4.048872
[epoch6, step1995]: loss 1.881359
[epoch6, step1996]: loss 5.469990
[epoch6, step1997]: loss 1.434730
[epoch6, step1998]: loss 10.297733
[epoch6, step1999]: loss 15.850665
[epoch6, step2000]: loss 8.905169
[epoch6, step2001]: loss 3.887810
[epoch6, step2002]: loss 2.257429
[epoch6, step2003]: loss 1.331459
[epoch6, step2004]: loss 13.961782
[epoch6, step2005]: loss 10.634128
[epoch6, step2006]: loss 23.189558
[epoch6, step2007]: loss 2.403963
[epoch6, step2008]: loss 2.230668
[epoch6, step2009]: loss 1.705406
[epoch6, step2010]: loss 12.687665
[epoch6, step2011]: loss 2.027045
[epoch6, step2012]: loss 3.491150
[epoch6, step2013]: loss 2.177269
[epoch6, step2014]: loss 4.959429
[epoch6, step2015]: loss 14.430397
[epoch6, step2016]: loss 6.525373
[epoch6, step2017]: loss 7.549685
[epoch6, step2018]: loss 11.983264
[epoch6, step2019]: loss 6.718529
[epoch6, step2020]: loss 8.626280
[epoch6, step2021]: loss 2.932986
[epoch6, step2022]: loss 22.755110
[epoch6, step2023]: loss 2.896443
[epoch6, step2024]: loss 1.593107
[epoch6, step2025]: loss 1.664783
[epoch6, step2026]: loss 5.356323
[epoch6, step2027]: loss 2.346128
[epoch6, step2028]: loss 14.078413
[epoch6, step2029]: loss 19.607706
[epoch6, step2030]: loss 3.913639
[epoch6, step2031]: loss 15.073686
[epoch6, step2032]: loss 3.062570
[epoch6, step2033]: loss 17.310980
[epoch6, step2034]: loss 1.287490
[epoch6, step2035]: loss 3.453613
[epoch6, step2036]: loss 14.626845
[epoch6, step2037]: loss 10.359498
[epoch6, step2038]: loss 12.408002
[epoch6, step2039]: loss 3.343125
[epoch6, step2040]: loss 8.228518
[epoch6, step2041]: loss 1.904106
[epoch6, step2042]: loss 3.373471
[epoch6, step2043]: loss 1.715902
[epoch6, step2044]: loss 8.471872
[epoch6, step2045]: loss 2.941018
[epoch6, step2046]: loss 1.472712
[epoch6, step2047]: loss 1.861062
[epoch6, step2048]: loss 6.984276
[epoch6, step2049]: loss 1.457944
[epoch6, step2050]: loss 2.832127
[epoch6, step2051]: loss 9.210344
[epoch6, step2052]: loss 5.466500
[epoch6, step2053]: loss 1.305838
[epoch6, step2054]: loss 7.263902
[epoch6, step2055]: loss 20.540493
[epoch6, step2056]: loss 2.687186
[epoch6, step2057]: loss 2.656227
[epoch6, step2058]: loss 16.551153
[epoch6, step2059]: loss 3.631517
[epoch6, step2060]: loss 14.072962
[epoch6, step2061]: loss 1.096667
[epoch6, step2062]: loss 3.281236
[epoch6, step2063]: loss 19.794811
[epoch6, step2064]: loss 1.753815
[epoch6, step2065]: loss 7.175659
[epoch6, step2066]: loss 12.957664
[epoch6, step2067]: loss 9.530465
[epoch6, step2068]: loss 1.403450
[epoch6, step2069]: loss 1.846037
[epoch6, step2070]: loss 18.127132
[epoch6, step2071]: loss 7.196866
[epoch6, step2072]: loss 7.759933
[epoch6, step2073]: loss 8.015479
[epoch6, step2074]: loss 13.701166
[epoch6, step2075]: loss 1.850860
[epoch6, step2076]: loss 30.030991
[epoch6, step2077]: loss 3.249181
[epoch6, step2078]: loss 12.486057
[epoch6, step2079]: loss 12.715109
[epoch6, step2080]: loss 1.821552
[epoch6, step2081]: loss 2.346802
[epoch6, step2082]: loss 7.410429
[epoch6, step2083]: loss 13.905921
[epoch6, step2084]: loss 17.518723
[epoch6, step2085]: loss 19.379538
[epoch6, step2086]: loss 1.107614
[epoch6, step2087]: loss 15.400632
[epoch6, step2088]: loss 6.021997
[epoch6, step2089]: loss 12.473297
[epoch6, step2090]: loss 2.725861
[epoch6, step2091]: loss 2.759053
[epoch6, step2092]: loss 5.925347
[epoch6, step2093]: loss 1.328875
[epoch6, step2094]: loss 5.101879
[epoch6, step2095]: loss 9.409582
[epoch6, step2096]: loss 19.119799
[epoch6, step2097]: loss 2.387806
[epoch6, step2098]: loss 3.430231
[epoch6, step2099]: loss 15.753186
[epoch6, step2100]: loss 2.387246
[epoch6, step2101]: loss 5.642807
[epoch6, step2102]: loss 1.222146
[epoch6, step2103]: loss 9.740867
[epoch6, step2104]: loss 32.045170
[epoch6, step2105]: loss 1.815262
[epoch6, step2106]: loss 6.856746
[epoch6, step2107]: loss 7.337677
[epoch6, step2108]: loss 9.978684
[epoch6, step2109]: loss 11.981379
[epoch6, step2110]: loss 10.939436
[epoch6, step2111]: loss 14.678550
[epoch6, step2112]: loss 1.341778
[epoch6, step2113]: loss 12.510098
[epoch6, step2114]: loss 16.384521
[epoch6, step2115]: loss 2.151472
[epoch6, step2116]: loss 2.449095
[epoch6, step2117]: loss 14.159718
[epoch6, step2118]: loss 3.047173
[epoch6, step2119]: loss 8.015254
[epoch6, step2120]: loss 3.860265
[epoch6, step2121]: loss 1.559940
[epoch6, step2122]: loss 35.276718
[epoch6, step2123]: loss 2.938013
[epoch6, step2124]: loss 1.171656
[epoch6, step2125]: loss 5.886342
[epoch6, step2126]: loss 2.285053
[epoch6, step2127]: loss 1.626386
[epoch6, step2128]: loss 1.387741
[epoch6, step2129]: loss 6.407892
[epoch6, step2130]: loss 2.435906
[epoch6, step2131]: loss 1.811231
[epoch6, step2132]: loss 1.895282
[epoch6, step2133]: loss 10.379295
[epoch6, step2134]: loss 3.462029
[epoch6, step2135]: loss 8.386589
[epoch6, step2136]: loss 1.676416
[epoch6, step2137]: loss 2.219909
[epoch6, step2138]: loss 2.972426
[epoch6, step2139]: loss 3.076060
[epoch6, step2140]: loss 8.796755
[epoch6, step2141]: loss 12.865587
[epoch6, step2142]: loss 2.893918
[epoch6, step2143]: loss 11.361515
[epoch6, step2144]: loss 10.760847
[epoch6, step2145]: loss 2.750676
[epoch6, step2146]: loss 1.264671
[epoch6, step2147]: loss 4.162076
[epoch6, step2148]: loss 8.465470
[epoch6, step2149]: loss 6.369806
[epoch6, step2150]: loss 3.892154
[epoch6, step2151]: loss 4.491662
[epoch6, step2152]: loss 2.352426
[epoch6, step2153]: loss 1.977890
[epoch6, step2154]: loss 1.191396
[epoch6, step2155]: loss 4.438271
[epoch6, step2156]: loss 11.909202
[epoch6, step2157]: loss 2.612453
[epoch6, step2158]: loss 7.227807
[epoch6, step2159]: loss 10.188609
[epoch6, step2160]: loss 2.439420
[epoch6, step2161]: loss 20.918344
[epoch6, step2162]: loss 1.292980
[epoch6, step2163]: loss 10.954299
[epoch6, step2164]: loss 1.567257
[epoch6, step2165]: loss 2.705900
[epoch6, step2166]: loss 23.130178
[epoch6, step2167]: loss 26.722607
[epoch6, step2168]: loss 6.543339
[epoch6, step2169]: loss 1.646861
[epoch6, step2170]: loss 1.875486
[epoch6, step2171]: loss 2.744040
[epoch6, step2172]: loss 13.877245
[epoch6, step2173]: loss 10.075022
[epoch6, step2174]: loss 2.073950
[epoch6, step2175]: loss 2.723176
[epoch6, step2176]: loss 13.995882
[epoch6, step2177]: loss 2.869146
[epoch6, step2178]: loss 6.344434
[epoch6, step2179]: loss 11.595778
[epoch6, step2180]: loss 5.637840
[epoch6, step2181]: loss 2.911444
[epoch6, step2182]: loss 6.880671
[epoch6, step2183]: loss 1.435212
[epoch6, step2184]: loss 9.398199
[epoch6, step2185]: loss 8.332503
[epoch6, step2186]: loss 1.347881
[epoch6, step2187]: loss 2.065728
[epoch6, step2188]: loss 2.761037
[epoch6, step2189]: loss 10.481606
[epoch6, step2190]: loss 14.405991
[epoch6, step2191]: loss 5.243584
[epoch6, step2192]: loss 6.202467
[epoch6, step2193]: loss 12.776668
[epoch6, step2194]: loss 3.949929
[epoch6, step2195]: loss 9.058849
[epoch6, step2196]: loss 16.893312
[epoch6, step2197]: loss 5.301741
[epoch6, step2198]: loss 4.067358
[epoch6, step2199]: loss 1.899591
[epoch6, step2200]: loss 2.005422
[epoch6, step2201]: loss 6.146590
[epoch6, step2202]: loss 2.445617
[epoch6, step2203]: loss 11.221521
[epoch6, step2204]: loss 4.159828
[epoch6, step2205]: loss 2.557637
[epoch6, step2206]: loss 1.175003
[epoch6, step2207]: loss 2.400843
[epoch6, step2208]: loss 9.791017
[epoch6, step2209]: loss 3.828629
[epoch6, step2210]: loss 6.072616
[epoch6, step2211]: loss 21.026037
[epoch6, step2212]: loss 7.852175
[epoch6, step2213]: loss 9.642191
[epoch6, step2214]: loss 11.485481
[epoch6, step2215]: loss 2.425089
[epoch6, step2216]: loss 2.149674
[epoch6, step2217]: loss 5.249422
[epoch6, step2218]: loss 7.450143
[epoch6, step2219]: loss 12.982752
[epoch6, step2220]: loss 21.049608
[epoch6, step2221]: loss 14.071748
[epoch6, step2222]: loss 11.350678
[epoch6, step2223]: loss 7.838089
[epoch6, step2224]: loss 13.367351
[epoch6, step2225]: loss 6.277899
[epoch6, step2226]: loss 1.376507
[epoch6, step2227]: loss 1.782383
[epoch6, step2228]: loss 2.409618
[epoch6, step2229]: loss 2.183836
[epoch6, step2230]: loss 2.780260
[epoch6, step2231]: loss 16.977503
[epoch6, step2232]: loss 1.968149
[epoch6, step2233]: loss 7.293605
[epoch6, step2234]: loss 1.730140
[epoch6, step2235]: loss 2.185925
[epoch6, step2236]: loss 1.246058
[epoch6, step2237]: loss 1.012849
[epoch6, step2238]: loss 15.271005
[epoch6, step2239]: loss 1.817166
[epoch6, step2240]: loss 1.310358
[epoch6, step2241]: loss 3.524775
[epoch6, step2242]: loss 1.617346
[epoch6, step2243]: loss 3.935507
[epoch6, step2244]: loss 11.639415
[epoch6, step2245]: loss 1.614752
[epoch6, step2246]: loss 16.619947
[epoch6, step2247]: loss 8.249364
[epoch6, step2248]: loss 2.799936
[epoch6, step2249]: loss 15.086542
[epoch6, step2250]: loss 3.507706
[epoch6, step2251]: loss 2.290442
[epoch6, step2252]: loss 14.737926
[epoch6, step2253]: loss 24.806932
[epoch6, step2254]: loss 18.662172
[epoch6, step2255]: loss 1.018560
[epoch6, step2256]: loss 3.524308
[epoch6, step2257]: loss 1.655459
[epoch6, step2258]: loss 4.906954
[epoch6, step2259]: loss 9.152855
[epoch6, step2260]: loss 22.652143
[epoch6, step2261]: loss 3.481776
[epoch6, step2262]: loss 4.273683
[epoch6, step2263]: loss 1.093465
[epoch6, step2264]: loss 1.338320
[epoch6, step2265]: loss 19.043900
[epoch6, step2266]: loss 1.136280
[epoch6, step2267]: loss 3.259225
[epoch6, step2268]: loss 2.649909
[epoch6, step2269]: loss 9.360788
[epoch6, step2270]: loss 1.856564
[epoch6, step2271]: loss 10.158091
[epoch6, step2272]: loss 4.135317
[epoch6, step2273]: loss 2.631516
[epoch6, step2274]: loss 14.948324
[epoch6, step2275]: loss 23.106356
[epoch6, step2276]: loss 18.954971
[epoch6, step2277]: loss 2.113378
[epoch6, step2278]: loss 7.425490
[epoch6, step2279]: loss 7.294489
[epoch6, step2280]: loss 6.619885
[epoch6, step2281]: loss 7.664515
[epoch6, step2282]: loss 1.280660
[epoch6, step2283]: loss 3.561034
[epoch6, step2284]: loss 10.550776
[epoch6, step2285]: loss 1.953264
[epoch6, step2286]: loss 9.686413
[epoch6, step2287]: loss 5.663053
[epoch6, step2288]: loss 2.381835
[epoch6, step2289]: loss 2.578261
[epoch6, step2290]: loss 1.383051
[epoch6, step2291]: loss 9.393312
[epoch6, step2292]: loss 10.501152
[epoch6, step2293]: loss 11.296415
[epoch6, step2294]: loss 4.745208
[epoch6, step2295]: loss 6.317286
[epoch6, step2296]: loss 3.776650
[epoch6, step2297]: loss 1.837258
[epoch6, step2298]: loss 3.672025
[epoch6, step2299]: loss 8.215874
[epoch6, step2300]: loss 2.365785
[epoch6, step2301]: loss 2.810833
[epoch6, step2302]: loss 5.117646
[epoch6, step2303]: loss 14.649549
[epoch6, step2304]: loss 13.776931
[epoch6, step2305]: loss 23.229143
[epoch6, step2306]: loss 4.083529
[epoch6, step2307]: loss 8.781089
[epoch6, step2308]: loss 1.928737
[epoch6, step2309]: loss 12.673960
[epoch6, step2310]: loss 1.597759
[epoch6, step2311]: loss 8.995302
[epoch6, step2312]: loss 1.443804
[epoch6, step2313]: loss 8.395514
[epoch6, step2314]: loss 2.365095
[epoch6, step2315]: loss 2.435955
[epoch6, step2316]: loss 4.811996
[epoch6, step2317]: loss 1.568247
[epoch6, step2318]: loss 4.320927
[epoch6, step2319]: loss 8.008190
[epoch6, step2320]: loss 2.875141
[epoch6, step2321]: loss 3.836968
[epoch6, step2322]: loss 7.393904
[epoch6, step2323]: loss 6.688997
[epoch6, step2324]: loss 20.774750
[epoch6, step2325]: loss 8.938787
[epoch6, step2326]: loss 19.497826
[epoch6, step2327]: loss 9.100270
[epoch6, step2328]: loss 3.391079
[epoch6, step2329]: loss 11.094131
[epoch6, step2330]: loss 9.522543
[epoch6, step2331]: loss 5.819876
[epoch6, step2332]: loss 5.534793
[epoch6, step2333]: loss 9.974515
[epoch6, step2334]: loss 1.152725
[epoch6, step2335]: loss 2.127091
[epoch6, step2336]: loss 2.887591
[epoch6, step2337]: loss 7.774247
[epoch6, step2338]: loss 8.174994
[epoch6, step2339]: loss 7.073409
[epoch6, step2340]: loss 16.034914
[epoch6, step2341]: loss 6.815664
[epoch6, step2342]: loss 1.567991
[epoch6, step2343]: loss 4.665354
[epoch6, step2344]: loss 19.011311
[epoch6, step2345]: loss 22.624554
[epoch6, step2346]: loss 13.623467
[epoch6, step2347]: loss 8.928051
[epoch6, step2348]: loss 16.721230
[epoch6, step2349]: loss 2.329515
[epoch6, step2350]: loss 9.281311
[epoch6, step2351]: loss 2.662649
[epoch6, step2352]: loss 4.469064
[epoch6, step2353]: loss 6.512444
[epoch6, step2354]: loss 35.164268
[epoch6, step2355]: loss 4.250182
[epoch6, step2356]: loss 1.826075
[epoch6, step2357]: loss 2.090512
[epoch6, step2358]: loss 0.853373
[epoch6, step2359]: loss 13.421553
[epoch6, step2360]: loss 2.476178
[epoch6, step2361]: loss 13.877098
[epoch6, step2362]: loss 8.473598
[epoch6, step2363]: loss 7.419556
[epoch6, step2364]: loss 5.394557
[epoch6, step2365]: loss 3.719768
[epoch6, step2366]: loss 14.187609
[epoch6, step2367]: loss 7.220337
[epoch6, step2368]: loss 5.016953
[epoch6, step2369]: loss 16.719328
[epoch6, step2370]: loss 9.132422
[epoch6, step2371]: loss 1.149617
[epoch6, step2372]: loss 4.194289
[epoch6, step2373]: loss 16.124264
[epoch6, step2374]: loss 1.781587
[epoch6, step2375]: loss 2.113561
[epoch6, step2376]: loss 2.119931
[epoch6, step2377]: loss 3.944886
[epoch6, step2378]: loss 6.396582
[epoch6, step2379]: loss 1.777898
[epoch6, step2380]: loss 19.870314
[epoch6, step2381]: loss 1.711121
[epoch6, step2382]: loss 2.340545
[epoch6, step2383]: loss 3.772750
[epoch6, step2384]: loss 8.758133
[epoch6, step2385]: loss 2.037318
[epoch6, step2386]: loss 1.422544
[epoch6, step2387]: loss 6.580569
[epoch6, step2388]: loss 1.674662
[epoch6, step2389]: loss 6.749816
[epoch6, step2390]: loss 3.356202
[epoch6, step2391]: loss 2.973455
[epoch6, step2392]: loss 1.094245
[epoch6, step2393]: loss 4.506151
[epoch6, step2394]: loss 4.086242
[epoch6, step2395]: loss 4.259385
[epoch6, step2396]: loss 8.608887
[epoch6, step2397]: loss 14.114676
[epoch6, step2398]: loss 4.780034
[epoch6, step2399]: loss 8.190403
[epoch6, step2400]: loss 2.456472
[epoch6, step2401]: loss 8.265105
[epoch6, step2402]: loss 2.967181
[epoch6, step2403]: loss 15.373248
[epoch6, step2404]: loss 16.758247
[epoch6, step2405]: loss 1.971929
[epoch6, step2406]: loss 1.048096
[epoch6, step2407]: loss 16.144241
[epoch6, step2408]: loss 2.600327
[epoch6, step2409]: loss 2.937096
[epoch6, step2410]: loss 15.766266
[epoch6, step2411]: loss 5.152697
[epoch6, step2412]: loss 2.724221
[epoch6, step2413]: loss 5.685483
[epoch6, step2414]: loss 2.221061
[epoch6, step2415]: loss 12.381019
[epoch6, step2416]: loss 5.227993
[epoch6, step2417]: loss 14.364026
[epoch6, step2418]: loss 11.661326
[epoch6, step2419]: loss 24.865362
[epoch6, step2420]: loss 1.777884
[epoch6, step2421]: loss 1.777021
[epoch6, step2422]: loss 2.832275
[epoch6, step2423]: loss 2.104065
[epoch6, step2424]: loss 18.348404
[epoch6, step2425]: loss 3.007305
[epoch6, step2426]: loss 2.348335
[epoch6, step2427]: loss 3.862510
[epoch6, step2428]: loss 9.126786
[epoch6, step2429]: loss 16.365801
[epoch6, step2430]: loss 7.221253
[epoch6, step2431]: loss 2.120230
[epoch6, step2432]: loss 4.327184
[epoch6, step2433]: loss 8.231155
[epoch6, step2434]: loss 2.065349
[epoch6, step2435]: loss 40.504562
[epoch6, step2436]: loss 7.420734
[epoch6, step2437]: loss 2.837066
[epoch6, step2438]: loss 1.369828
[epoch6, step2439]: loss 11.677065
[epoch6, step2440]: loss 15.282959
[epoch6, step2441]: loss 9.536926
[epoch6, step2442]: loss 1.904547
[epoch6, step2443]: loss 3.415252
[epoch6, step2444]: loss 2.315063
[epoch6, step2445]: loss 2.391453
[epoch6, step2446]: loss 11.091830
[epoch6, step2447]: loss 2.366937
[epoch6, step2448]: loss 2.622351
[epoch6, step2449]: loss 2.138650
[epoch6, step2450]: loss 15.801840
[epoch6, step2451]: loss 2.102493
[epoch6, step2452]: loss 1.371517
[epoch6, step2453]: loss 1.334739
[epoch6, step2454]: loss 3.438386
[epoch6, step2455]: loss 21.646318
[epoch6, step2456]: loss 1.767098
[epoch6, step2457]: loss 2.541002
[epoch6, step2458]: loss 5.150616
[epoch6, step2459]: loss 10.295794
[epoch6, step2460]: loss 7.838917
[epoch6, step2461]: loss 3.933078
[epoch6, step2462]: loss 1.811102
[epoch6, step2463]: loss 19.063169
[epoch6, step2464]: loss 1.265214
[epoch6, step2465]: loss 1.125027
[epoch6, step2466]: loss 1.658731
[epoch6, step2467]: loss 6.865018
[epoch6, step2468]: loss 9.513646
[epoch6, step2469]: loss 2.282994
[epoch6, step2470]: loss 2.303234
[epoch6, step2471]: loss 17.960363
[epoch6, step2472]: loss 24.413391
[epoch6, step2473]: loss 1.735739
[epoch6, step2474]: loss 11.671775
[epoch6, step2475]: loss 1.261404
[epoch6, step2476]: loss 7.351598
[epoch6, step2477]: loss 1.836386
[epoch6, step2478]: loss 1.815704
[epoch6, step2479]: loss 11.507158
[epoch6, step2480]: loss 14.147791
[epoch6, step2481]: loss 8.750442
[epoch6, step2482]: loss 18.928656
[epoch6, step2483]: loss 8.120686
[epoch6, step2484]: loss 2.695149
[epoch6, step2485]: loss 1.004393
[epoch6, step2486]: loss 17.946949
[epoch6, step2487]: loss 9.978868
[epoch6, step2488]: loss 1.306522
[epoch6, step2489]: loss 5.203473
[epoch6, step2490]: loss 1.704564
[epoch6, step2491]: loss 23.949677
[epoch6, step2492]: loss 10.377920
[epoch6, step2493]: loss 3.252460
[epoch6, step2494]: loss 3.031158
[epoch6, step2495]: loss 2.466195
[epoch6, step2496]: loss 1.994217
[epoch6, step2497]: loss 2.321813
[epoch6, step2498]: loss 1.423304
[epoch6, step2499]: loss 21.595634
[epoch6, step2500]: loss 2.371534
[epoch6, step2501]: loss 16.898258
[epoch6, step2502]: loss 10.911183
[epoch6, step2503]: loss 7.639071
[epoch6, step2504]: loss 3.494765
[epoch6, step2505]: loss 9.829443
[epoch6, step2506]: loss 1.808806
[epoch6, step2507]: loss 1.402173
[epoch6, step2508]: loss 18.029242
[epoch6, step2509]: loss 3.999625
[epoch6, step2510]: loss 6.734599
[epoch6, step2511]: loss 8.624106
[epoch6, step2512]: loss 1.895224
[epoch6, step2513]: loss 4.037916
[epoch6, step2514]: loss 17.327181
[epoch6, step2515]: loss 0.913799
[epoch6, step2516]: loss 3.559685
[epoch6, step2517]: loss 6.912101
[epoch6, step2518]: loss 17.407881
[epoch6, step2519]: loss 8.143149
[epoch6, step2520]: loss 21.692320
[epoch6, step2521]: loss 1.883442
[epoch6, step2522]: loss 2.632037
[epoch6, step2523]: loss 1.982104
[epoch6, step2524]: loss 7.394866
[epoch6, step2525]: loss 3.117883
[epoch6, step2526]: loss 8.344437
[epoch6, step2527]: loss 7.746286
[epoch6, step2528]: loss 2.608287
[epoch6, step2529]: loss 3.307704
[epoch6, step2530]: loss 12.917027
[epoch6, step2531]: loss 5.957639
[epoch6, step2532]: loss 8.957649
[epoch6, step2533]: loss 2.204804
[epoch6, step2534]: loss 8.779707
[epoch6, step2535]: loss 8.663471
[epoch6, step2536]: loss 7.657153
[epoch6, step2537]: loss 12.196349
[epoch6, step2538]: loss 1.373616
[epoch6, step2539]: loss 7.379173
[epoch6, step2540]: loss 1.934250
[epoch6, step2541]: loss 8.244328
[epoch6, step2542]: loss 8.756690
[epoch6, step2543]: loss 38.225777
[epoch6, step2544]: loss 21.077143
[epoch6, step2545]: loss 10.130131
[epoch6, step2546]: loss 2.409337
[epoch6, step2547]: loss 8.247103
[epoch6, step2548]: loss 14.080404
[epoch6, step2549]: loss 2.301148
[epoch6, step2550]: loss 11.617392
[epoch6, step2551]: loss 9.417065
[epoch6, step2552]: loss 1.456110
[epoch6, step2553]: loss 1.095125
[epoch6, step2554]: loss 1.354581
[epoch6, step2555]: loss 16.737682
[epoch6, step2556]: loss 2.701855
[epoch6, step2557]: loss 12.832001
[epoch6, step2558]: loss 5.043661
[epoch6, step2559]: loss 2.297640
[epoch6, step2560]: loss 23.337574
[epoch6, step2561]: loss 2.262479
[epoch6, step2562]: loss 1.594638
[epoch6, step2563]: loss 27.841694
[epoch6, step2564]: loss 13.254497
[epoch6, step2565]: loss 2.448171
[epoch6, step2566]: loss 3.980909
[epoch6, step2567]: loss 9.709666
[epoch6, step2568]: loss 2.254749
[epoch6, step2569]: loss 18.554800
[epoch6, step2570]: loss 4.193764
[epoch6, step2571]: loss 1.981392
[epoch6, step2572]: loss 11.013523
[epoch6, step2573]: loss 24.552559
[epoch6, step2574]: loss 0.822476
[epoch6, step2575]: loss 12.425245
[epoch6, step2576]: loss 9.915264
[epoch6, step2577]: loss 2.740188
[epoch6, step2578]: loss 10.202244
[epoch6, step2579]: loss 1.151766
[epoch6, step2580]: loss 11.021051
[epoch6, step2581]: loss 1.114060
[epoch6, step2582]: loss 1.873578
[epoch6, step2583]: loss 2.448108
[epoch6, step2584]: loss 6.000116
[epoch6, step2585]: loss 8.878983
[epoch6, step2586]: loss 1.307802
[epoch6, step2587]: loss 19.126486
[epoch6, step2588]: loss 18.296412
[epoch6, step2589]: loss 3.356363
[epoch6, step2590]: loss 1.327386
[epoch6, step2591]: loss 4.907223
[epoch6, step2592]: loss 6.415082
[epoch6, step2593]: loss 3.663959
[epoch6, step2594]: loss 2.049722
[epoch6, step2595]: loss 9.826702
[epoch6, step2596]: loss 3.480699
[epoch6, step2597]: loss 12.089443
[epoch6, step2598]: loss 3.485147
[epoch6, step2599]: loss 1.919337
[epoch6, step2600]: loss 2.369586
[epoch6, step2601]: loss 1.890240
[epoch6, step2602]: loss 5.633167
[epoch6, step2603]: loss 14.297586
[epoch6, step2604]: loss 6.466362
[epoch6, step2605]: loss 19.805174
[epoch6, step2606]: loss 8.144831
[epoch6, step2607]: loss 3.918902
[epoch6, step2608]: loss 2.556128
[epoch6, step2609]: loss 2.945686
[epoch6, step2610]: loss 2.517362
[epoch6, step2611]: loss 2.710516
[epoch6, step2612]: loss 16.691095
[epoch6, step2613]: loss 18.790545
[epoch6, step2614]: loss 13.223110
[epoch6, step2615]: loss 2.227954
[epoch6, step2616]: loss 14.971928
[epoch6, step2617]: loss 2.534177
[epoch6, step2618]: loss 18.285702
[epoch6, step2619]: loss 9.262481
[epoch6, step2620]: loss 7.829755
[epoch6, step2621]: loss 0.951795
[epoch6, step2622]: loss 10.307651
[epoch6, step2623]: loss 18.402674
[epoch6, step2624]: loss 1.663291
[epoch6, step2625]: loss 17.543909
[epoch6, step2626]: loss 19.668041
[epoch6, step2627]: loss 6.154745
[epoch6, step2628]: loss 16.173643
[epoch6, step2629]: loss 1.425122
[epoch6, step2630]: loss 2.271438
[epoch6, step2631]: loss 9.648957
[epoch6, step2632]: loss 5.600717
[epoch6, step2633]: loss 26.934855
[epoch6, step2634]: loss 6.656398
[epoch6, step2635]: loss 2.739332
[epoch6, step2636]: loss 2.048615
[epoch6, step2637]: loss 13.427372
[epoch6, step2638]: loss 3.055863
[epoch6, step2639]: loss 4.024241
[epoch6, step2640]: loss 5.438149
[epoch6, step2641]: loss 13.547770
[epoch6, step2642]: loss 2.085946
[epoch6, step2643]: loss 2.013966
[epoch6, step2644]: loss 2.507196
[epoch6, step2645]: loss 13.390783
[epoch6, step2646]: loss 20.342333
[epoch6, step2647]: loss 2.236414
[epoch6, step2648]: loss 1.826545
[epoch6, step2649]: loss 4.248181
[epoch6, step2650]: loss 6.148277
[epoch6, step2651]: loss 2.079499
[epoch6, step2652]: loss 1.214318
[epoch6, step2653]: loss 6.170676
[epoch6, step2654]: loss 13.700182
[epoch6, step2655]: loss 1.891276
[epoch6, step2656]: loss 8.708557
[epoch6, step2657]: loss 6.603687
[epoch6, step2658]: loss 2.162160
[epoch6, step2659]: loss 6.188850
[epoch6, step2660]: loss 1.049258
[epoch6, step2661]: loss 10.360985
[epoch6, step2662]: loss 10.525395
[epoch6, step2663]: loss 4.083537
[epoch6, step2664]: loss 16.242418
[epoch6, step2665]: loss 2.155765
[epoch6, step2666]: loss 6.371240
[epoch6, step2667]: loss 21.832653
[epoch6, step2668]: loss 6.775065
[epoch6, step2669]: loss 1.325251
[epoch6, step2670]: loss 14.825793
[epoch6, step2671]: loss 1.946346
[epoch6, step2672]: loss 4.560030
[epoch6, step2673]: loss 1.574397
[epoch6, step2674]: loss 1.279951
[epoch6, step2675]: loss 3.616178
[epoch6, step2676]: loss 7.714081
[epoch6, step2677]: loss 11.283514
[epoch6, step2678]: loss 6.926151
[epoch6, step2679]: loss 2.152224
[epoch6, step2680]: loss 7.589141
[epoch6, step2681]: loss 2.289634
[epoch6, step2682]: loss 2.138753
[epoch6, step2683]: loss 6.532362
[epoch6, step2684]: loss 1.154878
[epoch6, step2685]: loss 1.454903
[epoch6, step2686]: loss 7.356360
[epoch6, step2687]: loss 7.540597
[epoch6, step2688]: loss 8.533240
[epoch6, step2689]: loss 3.035347
[epoch6, step2690]: loss 3.185758
[epoch6, step2691]: loss 3.316722
[epoch6, step2692]: loss 7.101666
[epoch6, step2693]: loss 3.526479
[epoch6, step2694]: loss 0.897647
[epoch6, step2695]: loss 26.947083
[epoch6, step2696]: loss 1.721322
[epoch6, step2697]: loss 1.564616
[epoch6, step2698]: loss 1.582408
[epoch6, step2699]: loss 10.707952
[epoch6, step2700]: loss 9.892271
[epoch6, step2701]: loss 6.327011
[epoch6, step2702]: loss 2.161951
[epoch6, step2703]: loss 5.940656
[epoch6, step2704]: loss 3.106340
[epoch6, step2705]: loss 3.538849
[epoch6, step2706]: loss 1.881040
[epoch6, step2707]: loss 2.001107
[epoch6, step2708]: loss 4.226944
[epoch6, step2709]: loss 18.415632
[epoch6, step2710]: loss 6.402024
[epoch6, step2711]: loss 8.880385
[epoch6, step2712]: loss 7.706792
[epoch6, step2713]: loss 17.310608
[epoch6, step2714]: loss 2.564672
[epoch6, step2715]: loss 10.569592
[epoch6, step2716]: loss 6.376134
[epoch6, step2717]: loss 1.324046
[epoch6, step2718]: loss 1.010724
[epoch6, step2719]: loss 2.280539
[epoch6, step2720]: loss 6.514897
[epoch6, step2721]: loss 10.757401
[epoch6, step2722]: loss 9.508061
[epoch6, step2723]: loss 2.270737
[epoch6, step2724]: loss 9.572781
[epoch6, step2725]: loss 1.641972
[epoch6, step2726]: loss 1.803493
[epoch6, step2727]: loss 16.582146
[epoch6, step2728]: loss 6.352308
[epoch6, step2729]: loss 2.936842
[epoch6, step2730]: loss 4.572274
[epoch6, step2731]: loss 4.748890
[epoch6, step2732]: loss 2.646943
[epoch6, step2733]: loss 8.130814
[epoch6, step2734]: loss 1.433009
[epoch6, step2735]: loss 20.784416
[epoch6, step2736]: loss 1.221035
[epoch6, step2737]: loss 1.692820
[epoch6, step2738]: loss 6.019456
[epoch6, step2739]: loss 14.819606
[epoch6, step2740]: loss 1.388325
[epoch6, step2741]: loss 14.108434
[epoch6, step2742]: loss 8.478965
[epoch6, step2743]: loss 17.462746
[epoch6, step2744]: loss 7.172234
[epoch6, step2745]: loss 20.658995
[epoch6, step2746]: loss 1.292885
[epoch6, step2747]: loss 14.338640
[epoch6, step2748]: loss 6.846350
[epoch6, step2749]: loss 15.453512
[epoch6, step2750]: loss 29.287289
[epoch6, step2751]: loss 2.467673
[epoch6, step2752]: loss 3.200660
[epoch6, step2753]: loss 12.839644
[epoch6, step2754]: loss 16.217983
[epoch6, step2755]: loss 6.481765
[epoch6, step2756]: loss 12.154521
[epoch6, step2757]: loss 4.769216
[epoch6, step2758]: loss 11.984527
[epoch6, step2759]: loss 6.418892
[epoch6, step2760]: loss 8.303375
[epoch6, step2761]: loss 13.441462
[epoch6, step2762]: loss 7.131487
[epoch6, step2763]: loss 10.983976
[epoch6, step2764]: loss 1.653772
[epoch6, step2765]: loss 6.862577
[epoch6, step2766]: loss 10.423330
[epoch6, step2767]: loss 15.033272
[epoch6, step2768]: loss 7.625252
[epoch6, step2769]: loss 1.982585
[epoch6, step2770]: loss 8.282194
[epoch6, step2771]: loss 33.519062
[epoch6, step2772]: loss 1.829105
[epoch6, step2773]: loss 13.657886
[epoch6, step2774]: loss 2.927595
[epoch6, step2775]: loss 5.850019
[epoch6, step2776]: loss 9.332277
[epoch6, step2777]: loss 15.775625
[epoch6, step2778]: loss 2.701675
[epoch6, step2779]: loss 15.106931
[epoch6, step2780]: loss 19.472336
[epoch6, step2781]: loss 1.127598
[epoch6, step2782]: loss 18.704994
[epoch6, step2783]: loss 2.598562
[epoch6, step2784]: loss 2.847613
[epoch6, step2785]: loss 1.358221
[epoch6, step2786]: loss 6.951504
[epoch6, step2787]: loss 12.226045
[epoch6, step2788]: loss 7.115537
[epoch6, step2789]: loss 1.442215
[epoch6, step2790]: loss 1.237700
[epoch6, step2791]: loss 7.988107
[epoch6, step2792]: loss 13.323684
[epoch6, step2793]: loss 2.507065
[epoch6, step2794]: loss 19.828310
[epoch6, step2795]: loss 11.923684
[epoch6, step2796]: loss 6.456708
[epoch6, step2797]: loss 8.856766
[epoch6, step2798]: loss 2.107473
[epoch6, step2799]: loss 7.305254
[epoch6, step2800]: loss 3.939996
[epoch6, step2801]: loss 15.554421
[epoch6, step2802]: loss 1.604269
[epoch6, step2803]: loss 12.678019
[epoch6, step2804]: loss 2.393613
[epoch6, step2805]: loss 8.694469
[epoch6, step2806]: loss 18.604530
[epoch6, step2807]: loss 1.597604
[epoch6, step2808]: loss 3.653924
[epoch6, step2809]: loss 0.886612
[epoch6, step2810]: loss 1.909466
[epoch6, step2811]: loss 4.483352
[epoch6, step2812]: loss 13.164071
[epoch6, step2813]: loss 2.645416
[epoch6, step2814]: loss 17.862226
[epoch6, step2815]: loss 13.172774
[epoch6, step2816]: loss 8.233621
[epoch6, step2817]: loss 3.398048
[epoch6, step2818]: loss 13.868439
[epoch6, step2819]: loss 7.327236
[epoch6, step2820]: loss 3.522225
[epoch6, step2821]: loss 0.972240
[epoch6, step2822]: loss 14.004936
[epoch6, step2823]: loss 8.516948
[epoch6, step2824]: loss 10.143828
[epoch6, step2825]: loss 0.944692
[epoch6, step2826]: loss 3.979531
[epoch6, step2827]: loss 3.699975
[epoch6, step2828]: loss 3.444346
[epoch6, step2829]: loss 17.249380
[epoch6, step2830]: loss 14.167774
[epoch6, step2831]: loss 18.463032
[epoch6, step2832]: loss 1.839202
[epoch6, step2833]: loss 5.598055
[epoch6, step2834]: loss 6.783641
[epoch6, step2835]: loss 6.396400
[epoch6, step2836]: loss 7.353079
[epoch6, step2837]: loss 8.786933
[epoch6, step2838]: loss 13.706788
[epoch6, step2839]: loss 14.283068
[epoch6, step2840]: loss 5.975437
[epoch6, step2841]: loss 1.393357
[epoch6, step2842]: loss 16.635338
[epoch6, step2843]: loss 16.849882
[epoch6, step2844]: loss 8.336952
[epoch6, step2845]: loss 2.457067
[epoch6, step2846]: loss 7.270201
[epoch6, step2847]: loss 1.462813
[epoch6, step2848]: loss 1.363558
[epoch6, step2849]: loss 1.742002
[epoch6, step2850]: loss 3.147862
[epoch6, step2851]: loss 11.854583
[epoch6, step2852]: loss 9.114625
[epoch6, step2853]: loss 23.021891
[epoch6, step2854]: loss 17.351721
[epoch6, step2855]: loss 8.005396
[epoch6, step2856]: loss 5.293416
[epoch6, step2857]: loss 2.990675
[epoch6, step2858]: loss 5.732177
[epoch6, step2859]: loss 3.101976
[epoch6, step2860]: loss 4.399260
[epoch6, step2861]: loss 4.999499
[epoch6, step2862]: loss 7.246825
[epoch6, step2863]: loss 1.434541
[epoch6, step2864]: loss 5.795761
[epoch6, step2865]: loss 2.417706
[epoch6, step2866]: loss 3.630114
[epoch6, step2867]: loss 8.949933
[epoch6, step2868]: loss 1.268497
[epoch6, step2869]: loss 10.263096
[epoch6, step2870]: loss 3.199348
[epoch6, step2871]: loss 12.046290
[epoch6, step2872]: loss 20.670946
[epoch6, step2873]: loss 1.077770
[epoch6, step2874]: loss 2.056643
[epoch6, step2875]: loss 40.048038
[epoch6, step2876]: loss 2.467288
[epoch6, step2877]: loss 5.900320
[epoch6, step2878]: loss 11.133209
[epoch6, step2879]: loss 11.552312
[epoch6, step2880]: loss 1.166745
[epoch6, step2881]: loss 7.389052
[epoch6, step2882]: loss 2.421088
[epoch6, step2883]: loss 6.469231
[epoch6, step2884]: loss 9.308811
[epoch6, step2885]: loss 7.422227
[epoch6, step2886]: loss 4.272176
[epoch6, step2887]: loss 1.901597
[epoch6, step2888]: loss 19.352722
[epoch6, step2889]: loss 7.004898
[epoch6, step2890]: loss 3.509071
[epoch6, step2891]: loss 8.728207
[epoch6, step2892]: loss 8.368669
[epoch6, step2893]: loss 3.221460
[epoch6, step2894]: loss 18.432074
[epoch6, step2895]: loss 1.034214
[epoch6, step2896]: loss 1.742711
[epoch6, step2897]: loss 3.488016
[epoch6, step2898]: loss 4.336078
[epoch6, step2899]: loss 20.072123
[epoch6, step2900]: loss 8.006460
[epoch6, step2901]: loss 11.222930
[epoch6, step2902]: loss 4.152544
[epoch6, step2903]: loss 18.776850
[epoch6, step2904]: loss 5.066458
[epoch6, step2905]: loss 10.055364
[epoch6, step2906]: loss 14.336691
[epoch6, step2907]: loss 3.953928
[epoch6, step2908]: loss 12.988054
[epoch6, step2909]: loss 3.189664
[epoch6, step2910]: loss 2.712022
[epoch6, step2911]: loss 11.827021
[epoch6, step2912]: loss 2.510633
[epoch6, step2913]: loss 11.849946
[epoch6, step2914]: loss 9.248996
[epoch6, step2915]: loss 7.734210
[epoch6, step2916]: loss 1.195744
[epoch6, step2917]: loss 16.037289
[epoch6, step2918]: loss 5.368935
[epoch6, step2919]: loss 3.004235
[epoch6, step2920]: loss 14.435429
[epoch6, step2921]: loss 5.814594
[epoch6, step2922]: loss 15.256514
[epoch6, step2923]: loss 5.955689
[epoch6, step2924]: loss 1.343497
[epoch6, step2925]: loss 9.446366
[epoch6, step2926]: loss 18.757109
[epoch6, step2927]: loss 5.639253
[epoch6, step2928]: loss 1.318597
[epoch6, step2929]: loss 2.044446
[epoch6, step2930]: loss 6.671572
[epoch6, step2931]: loss 5.625843
[epoch6, step2932]: loss 1.263103
[epoch6, step2933]: loss 4.332164
[epoch6, step2934]: loss 8.213446
[epoch6, step2935]: loss 2.248644
[epoch6, step2936]: loss 6.744132
[epoch6, step2937]: loss 1.863409
[epoch6, step2938]: loss 6.169084
[epoch6, step2939]: loss 1.847880
[epoch6, step2940]: loss 4.235065
[epoch6, step2941]: loss 5.657753
[epoch6, step2942]: loss 3.838717
[epoch6, step2943]: loss 5.789630
[epoch6, step2944]: loss 17.747229
[epoch6, step2945]: loss 2.004984
[epoch6, step2946]: loss 12.027310
[epoch6, step2947]: loss 1.679388
[epoch6, step2948]: loss 3.624621
[epoch6, step2949]: loss 3.292744
[epoch6, step2950]: loss 26.356989
[epoch6, step2951]: loss 12.831934
[epoch6, step2952]: loss 6.691138
[epoch6, step2953]: loss 1.542842
[epoch6, step2954]: loss 4.023076
[epoch6, step2955]: loss 1.261659
[epoch6, step2956]: loss 5.986332
[epoch6, step2957]: loss 3.248810
[epoch6, step2958]: loss 3.737843
[epoch6, step2959]: loss 1.183542
[epoch6, step2960]: loss 14.112661
[epoch6, step2961]: loss 5.800622
[epoch6, step2962]: loss 5.649041
[epoch6, step2963]: loss 1.591375
[epoch6, step2964]: loss 12.897748
[epoch6, step2965]: loss 3.115459
[epoch6, step2966]: loss 14.117392
[epoch6, step2967]: loss 1.930207
[epoch6, step2968]: loss 2.025150
[epoch6, step2969]: loss 5.120282
[epoch6, step2970]: loss 9.808325
[epoch6, step2971]: loss 14.427392
[epoch6, step2972]: loss 10.375279
[epoch6, step2973]: loss 30.447809
[epoch6, step2974]: loss 16.760992
[epoch6, step2975]: loss 21.366081
[epoch6, step2976]: loss 5.288332
[epoch6, step2977]: loss 15.058443
[epoch6, step2978]: loss 16.635073
[epoch6, step2979]: loss 15.365967
[epoch6, step2980]: loss 1.315540
[epoch6, step2981]: loss 2.662607
[epoch6, step2982]: loss 1.969598
[epoch6, step2983]: loss 6.152635
[epoch6, step2984]: loss 8.202980
[epoch6, step2985]: loss 9.756704
[epoch6, step2986]: loss 7.761794
[epoch6, step2987]: loss 8.411803
[epoch6, step2988]: loss 1.594491
[epoch6, step2989]: loss 8.557960
[epoch6, step2990]: loss 1.324123
[epoch6, step2991]: loss 8.896494
[epoch6, step2992]: loss 6.772086
[epoch6, step2993]: loss 1.465390
[epoch6, step2994]: loss 6.578832
[epoch6, step2995]: loss 19.745665
[epoch6, step2996]: loss 6.473151
[epoch6, step2997]: loss 9.144591
[epoch6, step2998]: loss 2.793711
[epoch6, step2999]: loss 2.004978
[epoch6, step3000]: loss 8.858412
[epoch6, step3001]: loss 12.586541
[epoch6, step3002]: loss 6.076373
[epoch6, step3003]: loss 10.618711
[epoch6, step3004]: loss 1.380838
[epoch6, step3005]: loss 2.515969
[epoch6, step3006]: loss 6.704138
[epoch6, step3007]: loss 6.037717
[epoch6, step3008]: loss 1.401623
[epoch6, step3009]: loss 16.265566
[epoch6, step3010]: loss 9.531577
[epoch6, step3011]: loss 1.658718
[epoch6, step3012]: loss 1.825326
[epoch6, step3013]: loss 2.817386
[epoch6, step3014]: loss 33.561951
[epoch6, step3015]: loss 1.334778
[epoch6, step3016]: loss 7.569947
[epoch6, step3017]: loss 6.389966
[epoch6, step3018]: loss 9.163207
[epoch6, step3019]: loss 10.729921
[epoch6, step3020]: loss 2.156976
[epoch6, step3021]: loss 17.168318
[epoch6, step3022]: loss 1.020732
[epoch6, step3023]: loss 3.738080
[epoch6, step3024]: loss 2.033140
[epoch6, step3025]: loss 5.646824
[epoch6, step3026]: loss 1.174464
[epoch6, step3027]: loss 3.794901
[epoch6, step3028]: loss 5.460238
[epoch6, step3029]: loss 4.050405
[epoch6, step3030]: loss 1.452135
[epoch6, step3031]: loss 15.246624
[epoch6, step3032]: loss 2.241226
[epoch6, step3033]: loss 5.374933
[epoch6, step3034]: loss 3.270020
[epoch6, step3035]: loss 1.071482
[epoch6, step3036]: loss 1.465551
[epoch6, step3037]: loss 10.376482
[epoch6, step3038]: loss 1.048050
[epoch6, step3039]: loss 1.507538
[epoch6, step3040]: loss 15.825806
[epoch6, step3041]: loss 6.452162
[epoch6, step3042]: loss 13.353020
[epoch6, step3043]: loss 2.184088
[epoch6, step3044]: loss 2.943853
[epoch6, step3045]: loss 18.050081
[epoch6, step3046]: loss 1.334743
[epoch6, step3047]: loss 2.335455
[epoch6, step3048]: loss 10.100746
[epoch6, step3049]: loss 2.208173
[epoch6, step3050]: loss 3.061135
[epoch6, step3051]: loss 1.662423
[epoch6, step3052]: loss 12.811426
[epoch6, step3053]: loss 6.704937
[epoch6, step3054]: loss 1.814586
[epoch6, step3055]: loss 10.315841
[epoch6, step3056]: loss 2.505462
[epoch6, step3057]: loss 1.879560
[epoch6, step3058]: loss 9.695682
[epoch6, step3059]: loss 2.663095
[epoch6, step3060]: loss 6.105807
[epoch6, step3061]: loss 2.932243
[epoch6, step3062]: loss 3.479419
[epoch6, step3063]: loss 5.741086
[epoch6, step3064]: loss 1.482366
[epoch6, step3065]: loss 8.685325
[epoch6, step3066]: loss 11.034652
[epoch6, step3067]: loss 2.908581
[epoch6, step3068]: loss 17.721039
[epoch6, step3069]: loss 8.800795
[epoch6, step3070]: loss 4.110360
[epoch6, step3071]: loss 17.503035
[epoch6, step3072]: loss 1.889164
[epoch6, step3073]: loss 9.656628
[epoch6, step3074]: loss 3.291860
[epoch6, step3075]: loss 3.462990
[epoch6, step3076]: loss 11.082226

[epoch6]: avg loss 11.082226

[epoch7, step1]: loss 4.612031
[epoch7, step2]: loss 1.150564
[epoch7, step3]: loss 7.364937
[epoch7, step4]: loss 5.222495
[epoch7, step5]: loss 0.993871
[epoch7, step6]: loss 8.620628
[epoch7, step7]: loss 2.539340
[epoch7, step8]: loss 5.687957
[epoch7, step9]: loss 2.794946
[epoch7, step10]: loss 9.161838
[epoch7, step11]: loss 1.191255
[epoch7, step12]: loss 2.333478
[epoch7, step13]: loss 17.978041
[epoch7, step14]: loss 1.301070
[epoch7, step15]: loss 8.377001
[epoch7, step16]: loss 3.551093
[epoch7, step17]: loss 11.535664
[epoch7, step18]: loss 6.265678
[epoch7, step19]: loss 1.886463
[epoch7, step20]: loss 7.339666
[epoch7, step21]: loss 6.724224
[epoch7, step22]: loss 15.039178
[epoch7, step23]: loss 5.697145
[epoch7, step24]: loss 5.691500
[epoch7, step25]: loss 9.353351
[epoch7, step26]: loss 2.110960
[epoch7, step27]: loss 8.158408
[epoch7, step28]: loss 14.527552
[epoch7, step29]: loss 1.969254
[epoch7, step30]: loss 4.100218
[epoch7, step31]: loss 5.267606
[epoch7, step32]: loss 27.730558
[epoch7, step33]: loss 14.757881
[epoch7, step34]: loss 2.502378
[epoch7, step35]: loss 7.018517
[epoch7, step36]: loss 15.596847
[epoch7, step37]: loss 14.146390
[epoch7, step38]: loss 5.081856
[epoch7, step39]: loss 3.967794
[epoch7, step40]: loss 11.753497
[epoch7, step41]: loss 2.404039
[epoch7, step42]: loss 6.533251
[epoch7, step43]: loss 12.298347
[epoch7, step44]: loss 2.186275
[epoch7, step45]: loss 3.443423
[epoch7, step46]: loss 1.372300
[epoch7, step47]: loss 3.591214
[epoch7, step48]: loss 19.564070
[epoch7, step49]: loss 11.308665
[epoch7, step50]: loss 8.925940
[epoch7, step51]: loss 8.783457
[epoch7, step52]: loss 1.525635
[epoch7, step53]: loss 4.672781
[epoch7, step54]: loss 13.346715
[epoch7, step55]: loss 5.262768
[epoch7, step56]: loss 10.722755
[epoch7, step57]: loss 8.009879
[epoch7, step58]: loss 2.472141
[epoch7, step59]: loss 1.835448
[epoch7, step60]: loss 2.494619
[epoch7, step61]: loss 3.209409
[epoch7, step62]: loss 29.518234
[epoch7, step63]: loss 2.349440
[epoch7, step64]: loss 6.924834
[epoch7, step65]: loss 8.500018
[epoch7, step66]: loss 3.500121
[epoch7, step67]: loss 1.105885
[epoch7, step68]: loss 6.432993
[epoch7, step69]: loss 1.455831
[epoch7, step70]: loss 5.548633
[epoch7, step71]: loss 13.525223
[epoch7, step72]: loss 2.571338
[epoch7, step73]: loss 12.815576
[epoch7, step74]: loss 11.430549
[epoch7, step75]: loss 5.914831
[epoch7, step76]: loss 1.934541
[epoch7, step77]: loss 5.987204
[epoch7, step78]: loss 6.379844
[epoch7, step79]: loss 4.449395
[epoch7, step80]: loss 2.245357
[epoch7, step81]: loss 6.701569
[epoch7, step82]: loss 1.608686
[epoch7, step83]: loss 1.427595
[epoch7, step84]: loss 3.599892
[epoch7, step85]: loss 11.953788
[epoch7, step86]: loss 7.934069
[epoch7, step87]: loss 2.303700
[epoch7, step88]: loss 13.545563
[epoch7, step89]: loss 7.817334
[epoch7, step90]: loss 15.038156
[epoch7, step91]: loss 1.581002
[epoch7, step92]: loss 1.928573
[epoch7, step93]: loss 3.058765
[epoch7, step94]: loss 2.456140
[epoch7, step95]: loss 5.185984
[epoch7, step96]: loss 6.548204
[epoch7, step97]: loss 3.563444
[epoch7, step98]: loss 6.892532
[epoch7, step99]: loss 2.938680
[epoch7, step100]: loss 8.795515
[epoch7, step101]: loss 11.144576
[epoch7, step102]: loss 3.096177
[epoch7, step103]: loss 3.028263
[epoch7, step104]: loss 1.157655
[epoch7, step105]: loss 2.768940
[epoch7, step106]: loss 7.200509
[epoch7, step107]: loss 17.410477
[epoch7, step108]: loss 9.574403
[epoch7, step109]: loss 2.194046
[epoch7, step110]: loss 10.388803
[epoch7, step111]: loss 2.591605
[epoch7, step112]: loss 11.276484
[epoch7, step113]: loss 16.484409
[epoch7, step114]: loss 2.540011
[epoch7, step115]: loss 1.494687
[epoch7, step116]: loss 24.154621
[epoch7, step117]: loss 1.146048
[epoch7, step118]: loss 4.395969
[epoch7, step119]: loss 8.617126
[epoch7, step120]: loss 4.090635
[epoch7, step121]: loss 3.030049
[epoch7, step122]: loss 14.549336
[epoch7, step123]: loss 3.720780
[epoch7, step124]: loss 7.963810
[epoch7, step125]: loss 13.866028
[epoch7, step126]: loss 2.522737
[epoch7, step127]: loss 2.170037
[epoch7, step128]: loss 2.920420
[epoch7, step129]: loss 2.889819
[epoch7, step130]: loss 3.049703
[epoch7, step131]: loss 6.377873
[epoch7, step132]: loss 10.023675
[epoch7, step133]: loss 1.821541
[epoch7, step134]: loss 4.036370
[epoch7, step135]: loss 10.752364
[epoch7, step136]: loss 1.605103
[epoch7, step137]: loss 14.979977
[epoch7, step138]: loss 2.271482
[epoch7, step139]: loss 1.115934
[epoch7, step140]: loss 8.639046
[epoch7, step141]: loss 2.426012
[epoch7, step142]: loss 13.952656
[epoch7, step143]: loss 2.269329
[epoch7, step144]: loss 4.412833
[epoch7, step145]: loss 7.685030
[epoch7, step146]: loss 18.501335
[epoch7, step147]: loss 5.222256
[epoch7, step148]: loss 2.770127
[epoch7, step149]: loss 12.407755
[epoch7, step150]: loss 2.868472
[epoch7, step151]: loss 3.175876
[epoch7, step152]: loss 6.198166
[epoch7, step153]: loss 5.655042
[epoch7, step154]: loss 2.708584
[epoch7, step155]: loss 20.212849
[epoch7, step156]: loss 3.427039
[epoch7, step157]: loss 4.455734
[epoch7, step158]: loss 4.992071
[epoch7, step159]: loss 9.063304
[epoch7, step160]: loss 10.382161
[epoch7, step161]: loss 5.881691
[epoch7, step162]: loss 1.538845
[epoch7, step163]: loss 3.344306
[epoch7, step164]: loss 8.727668
[epoch7, step165]: loss 18.280581
[epoch7, step166]: loss 16.286478
[epoch7, step167]: loss 1.801741
[epoch7, step168]: loss 7.904843
[epoch7, step169]: loss 8.640102
[epoch7, step170]: loss 1.141765
[epoch7, step171]: loss 16.222240
[epoch7, step172]: loss 1.449643
[epoch7, step173]: loss 3.224804
[epoch7, step174]: loss 6.013695
[epoch7, step175]: loss 1.586646
[epoch7, step176]: loss 10.952003
[epoch7, step177]: loss 8.292471
[epoch7, step178]: loss 9.010159
[epoch7, step179]: loss 15.304852
[epoch7, step180]: loss 21.443266
[epoch7, step181]: loss 4.268374
[epoch7, step182]: loss 3.386086
[epoch7, step183]: loss 7.629554
[epoch7, step184]: loss 2.130001
[epoch7, step185]: loss 1.810805
[epoch7, step186]: loss 1.360470
[epoch7, step187]: loss 2.821609
[epoch7, step188]: loss 11.728284
[epoch7, step189]: loss 7.914678
[epoch7, step190]: loss 2.782748
[epoch7, step191]: loss 5.758331
[epoch7, step192]: loss 10.374347
[epoch7, step193]: loss 5.598051
[epoch7, step194]: loss 2.219533
[epoch7, step195]: loss 9.926276
[epoch7, step196]: loss 13.757050
[epoch7, step197]: loss 5.720116
[epoch7, step198]: loss 11.027121
[epoch7, step199]: loss 2.024190
[epoch7, step200]: loss 12.786368
[epoch7, step201]: loss 10.511833
[epoch7, step202]: loss 7.788332
[epoch7, step203]: loss 4.340820
[epoch7, step204]: loss 14.448051
[epoch7, step205]: loss 6.027028
[epoch7, step206]: loss 9.176890
[epoch7, step207]: loss 12.571362
[epoch7, step208]: loss 9.357697
[epoch7, step209]: loss 6.814400
[epoch7, step210]: loss 2.418205
[epoch7, step211]: loss 6.214126
[epoch7, step212]: loss 2.270393
[epoch7, step213]: loss 8.544533
[epoch7, step214]: loss 13.890345
[epoch7, step215]: loss 7.948788
[epoch7, step216]: loss 14.384748
[epoch7, step217]: loss 1.370336
[epoch7, step218]: loss 1.523167
[epoch7, step219]: loss 9.763606
[epoch7, step220]: loss 8.359834
[epoch7, step221]: loss 5.810694
[epoch7, step222]: loss 18.756199
[epoch7, step223]: loss 1.047827
[epoch7, step224]: loss 4.825161
[epoch7, step225]: loss 6.997948
[epoch7, step226]: loss 7.012146
[epoch7, step227]: loss 1.411810
[epoch7, step228]: loss 12.973182
[epoch7, step229]: loss 1.628833
[epoch7, step230]: loss 1.798884
[epoch7, step231]: loss 6.731945
[epoch7, step232]: loss 5.358701
[epoch7, step233]: loss 2.528914
[epoch7, step234]: loss 4.687234
[epoch7, step235]: loss 2.929810
[epoch7, step236]: loss 6.014077
[epoch7, step237]: loss 6.611979
[epoch7, step238]: loss 2.629890
[epoch7, step239]: loss 8.706466
[epoch7, step240]: loss 2.237124
[epoch7, step241]: loss 8.297269
[epoch7, step242]: loss 6.300165
[epoch7, step243]: loss 9.540107
[epoch7, step244]: loss 8.333446
[epoch7, step245]: loss 5.140662
[epoch7, step246]: loss 13.909690
[epoch7, step247]: loss 1.514956
[epoch7, step248]: loss 11.313342
[epoch7, step249]: loss 17.164492
[epoch7, step250]: loss 1.667004
[epoch7, step251]: loss 1.914332
[epoch7, step252]: loss 14.036441
[epoch7, step253]: loss 8.729807
[epoch7, step254]: loss 1.358182
[epoch7, step255]: loss 1.779141
[epoch7, step256]: loss 43.174870
[epoch7, step257]: loss 2.709511
[epoch7, step258]: loss 1.153053
[epoch7, step259]: loss 2.262015
[epoch7, step260]: loss 6.557405
[epoch7, step261]: loss 10.934335
[epoch7, step262]: loss 1.114288
[epoch7, step263]: loss 1.545033
[epoch7, step264]: loss 2.349682
[epoch7, step265]: loss 1.638030
[epoch7, step266]: loss 11.124061
[epoch7, step267]: loss 16.259092
[epoch7, step268]: loss 1.346537
[epoch7, step269]: loss 1.944664
[epoch7, step270]: loss 15.598639
[epoch7, step271]: loss 25.781740
[epoch7, step272]: loss 23.060371
[epoch7, step273]: loss 1.708688
[epoch7, step274]: loss 3.081550
[epoch7, step275]: loss 12.919147
[epoch7, step276]: loss 9.006996
[epoch7, step277]: loss 9.032983
[epoch7, step278]: loss 8.758673
[epoch7, step279]: loss 1.823391
[epoch7, step280]: loss 5.972394
[epoch7, step281]: loss 4.768389
[epoch7, step282]: loss 3.489146
[epoch7, step283]: loss 1.886286
[epoch7, step284]: loss 17.773226
[epoch7, step285]: loss 10.289297
[epoch7, step286]: loss 1.186634
[epoch7, step287]: loss 3.256082
[epoch7, step288]: loss 2.513438
[epoch7, step289]: loss 5.473179
[epoch7, step290]: loss 1.138071
[epoch7, step291]: loss 2.607540
[epoch7, step292]: loss 13.883281
[epoch7, step293]: loss 5.934435
[epoch7, step294]: loss 1.716924
[epoch7, step295]: loss 1.579605
[epoch7, step296]: loss 4.943460
[epoch7, step297]: loss 18.358376
[epoch7, step298]: loss 16.351822
[epoch7, step299]: loss 13.061318
[epoch7, step300]: loss 5.776951
[epoch7, step301]: loss 7.073697
[epoch7, step302]: loss 10.961294
[epoch7, step303]: loss 25.193577
[epoch7, step304]: loss 8.043652
[epoch7, step305]: loss 6.058345
[epoch7, step306]: loss 2.142457
[epoch7, step307]: loss 1.557075
[epoch7, step308]: loss 6.385875
[epoch7, step309]: loss 5.865859
[epoch7, step310]: loss 4.522604
[epoch7, step311]: loss 2.228072
[epoch7, step312]: loss 12.767354
[epoch7, step313]: loss 14.676126
[epoch7, step314]: loss 4.440339
[epoch7, step315]: loss 10.393020
[epoch7, step316]: loss 5.752418
[epoch7, step317]: loss 2.480320
[epoch7, step318]: loss 6.303188
[epoch7, step319]: loss 7.722147
[epoch7, step320]: loss 18.451429
[epoch7, step321]: loss 2.193574
[epoch7, step322]: loss 2.588947
[epoch7, step323]: loss 1.603232
[epoch7, step324]: loss 2.137584
[epoch7, step325]: loss 7.569860
[epoch7, step326]: loss 2.787372
[epoch7, step327]: loss 15.846422
[epoch7, step328]: loss 7.682086
[epoch7, step329]: loss 1.803682
[epoch7, step330]: loss 8.037477
[epoch7, step331]: loss 1.217595
[epoch7, step332]: loss 2.083550
[epoch7, step333]: loss 1.594836
[epoch7, step334]: loss 1.482099
[epoch7, step335]: loss 5.894894
[epoch7, step336]: loss 10.777400
[epoch7, step337]: loss 1.357241
[epoch7, step338]: loss 5.682288
[epoch7, step339]: loss 2.299245
[epoch7, step340]: loss 4.932399
[epoch7, step341]: loss 6.578922
[epoch7, step342]: loss 10.228008
[epoch7, step343]: loss 8.985618
[epoch7, step344]: loss 0.973192
[epoch7, step345]: loss 3.931733
[epoch7, step346]: loss 1.749663
[epoch7, step347]: loss 5.204901
[epoch7, step348]: loss 9.745276
[epoch7, step349]: loss 4.551685
[epoch7, step350]: loss 19.894562
[epoch7, step351]: loss 18.958199
[epoch7, step352]: loss 1.586537
[epoch7, step353]: loss 3.385941
[epoch7, step354]: loss 1.160480
[epoch7, step355]: loss 2.835814
[epoch7, step356]: loss 3.767471
[epoch7, step357]: loss 9.115375
[epoch7, step358]: loss 3.654457
[epoch7, step359]: loss 5.027634
[epoch7, step360]: loss 4.478796
[epoch7, step361]: loss 1.896092
[epoch7, step362]: loss 12.661738
[epoch7, step363]: loss 7.524873
[epoch7, step364]: loss 14.071059
[epoch7, step365]: loss 13.793557
[epoch7, step366]: loss 2.280424
[epoch7, step367]: loss 6.020842
[epoch7, step368]: loss 2.676810
[epoch7, step369]: loss 8.059869
[epoch7, step370]: loss 1.421382
[epoch7, step371]: loss 2.229603
[epoch7, step372]: loss 1.048742
[epoch7, step373]: loss 2.134276
[epoch7, step374]: loss 11.661767
[epoch7, step375]: loss 3.057901
[epoch7, step376]: loss 12.811929
[epoch7, step377]: loss 1.355243
[epoch7, step378]: loss 1.264393
[epoch7, step379]: loss 2.765382
[epoch7, step380]: loss 8.827455
[epoch7, step381]: loss 8.715238
[epoch7, step382]: loss 6.240380
[epoch7, step383]: loss 8.261916
[epoch7, step384]: loss 2.340111
[epoch7, step385]: loss 1.473937
[epoch7, step386]: loss 3.167521
[epoch7, step387]: loss 13.825731
[epoch7, step388]: loss 2.718687
[epoch7, step389]: loss 2.444502
[epoch7, step390]: loss 4.857759
[epoch7, step391]: loss 1.264293
[epoch7, step392]: loss 1.333269
[epoch7, step393]: loss 6.629926
[epoch7, step394]: loss 6.691451
[epoch7, step395]: loss 1.781104
[epoch7, step396]: loss 2.979647
[epoch7, step397]: loss 14.536803
[epoch7, step398]: loss 11.918151
[epoch7, step399]: loss 21.110022
[epoch7, step400]: loss 7.601313
[epoch7, step401]: loss 9.545436
[epoch7, step402]: loss 6.362990
[epoch7, step403]: loss 9.541699
[epoch7, step404]: loss 12.022981
[epoch7, step405]: loss 2.459016
[epoch7, step406]: loss 3.285336
[epoch7, step407]: loss 15.203104
[epoch7, step408]: loss 10.155705
[epoch7, step409]: loss 3.047640
[epoch7, step410]: loss 6.264995
[epoch7, step411]: loss 2.232610
[epoch7, step412]: loss 11.359810
[epoch7, step413]: loss 1.723864
[epoch7, step414]: loss 1.929735
[epoch7, step415]: loss 9.063633
[epoch7, step416]: loss 2.343270
[epoch7, step417]: loss 2.201319
[epoch7, step418]: loss 2.796626
[epoch7, step419]: loss 2.415055
[epoch7, step420]: loss 2.615836
[epoch7, step421]: loss 2.841025
[epoch7, step422]: loss 1.641966
[epoch7, step423]: loss 1.447190
[epoch7, step424]: loss 1.347939
[epoch7, step425]: loss 9.351213
[epoch7, step426]: loss 1.826497
[epoch7, step427]: loss 20.858496
[epoch7, step428]: loss 16.237326
[epoch7, step429]: loss 5.767239
[epoch7, step430]: loss 2.892462
[epoch7, step431]: loss 7.340395
[epoch7, step432]: loss 4.116321
[epoch7, step433]: loss 6.807320
[epoch7, step434]: loss 2.242823
[epoch7, step435]: loss 1.574420
[epoch7, step436]: loss 2.734385
[epoch7, step437]: loss 9.201712
[epoch7, step438]: loss 1.932210
[epoch7, step439]: loss 6.006067
[epoch7, step440]: loss 12.163445
[epoch7, step441]: loss 2.918306
[epoch7, step442]: loss 4.270241
[epoch7, step443]: loss 3.879682
[epoch7, step444]: loss 17.817595
[epoch7, step445]: loss 2.623917
[epoch7, step446]: loss 7.226779
[epoch7, step447]: loss 5.549989
[epoch7, step448]: loss 1.688074
[epoch7, step449]: loss 1.142081
[epoch7, step450]: loss 1.928858
[epoch7, step451]: loss 6.434689
[epoch7, step452]: loss 2.064562
[epoch7, step453]: loss 3.080078
[epoch7, step454]: loss 1.216092
[epoch7, step455]: loss 11.963006
[epoch7, step456]: loss 5.953035
[epoch7, step457]: loss 1.354192
[epoch7, step458]: loss 9.048414
[epoch7, step459]: loss 2.409650
[epoch7, step460]: loss 8.382156
[epoch7, step461]: loss 5.629507
[epoch7, step462]: loss 10.522802
[epoch7, step463]: loss 5.062541
[epoch7, step464]: loss 2.702862
[epoch7, step465]: loss 13.775756
[epoch7, step466]: loss 6.278603
[epoch7, step467]: loss 47.671043
[epoch7, step468]: loss 2.382249
[epoch7, step469]: loss 2.253845
[epoch7, step470]: loss 1.623459
[epoch7, step471]: loss 2.199207
[epoch7, step472]: loss 2.844905
[epoch7, step473]: loss 13.138794
[epoch7, step474]: loss 15.824056
[epoch7, step475]: loss 1.762014
[epoch7, step476]: loss 26.400362
[epoch7, step477]: loss 14.123719
[epoch7, step478]: loss 1.798563
[epoch7, step479]: loss 6.861234
[epoch7, step480]: loss 27.336113
[epoch7, step481]: loss 12.683281
[epoch7, step482]: loss 2.854788
[epoch7, step483]: loss 6.419679
[epoch7, step484]: loss 2.022628
[epoch7, step485]: loss 3.495302
[epoch7, step486]: loss 6.020885
[epoch7, step487]: loss 20.563147
[epoch7, step488]: loss 11.603068
[epoch7, step489]: loss 7.518861
[epoch7, step490]: loss 8.139694
[epoch7, step491]: loss 2.690319
[epoch7, step492]: loss 19.887970
[epoch7, step493]: loss 1.847266
[epoch7, step494]: loss 3.129576
[epoch7, step495]: loss 2.266418
[epoch7, step496]: loss 1.939049
[epoch7, step497]: loss 9.152208
[epoch7, step498]: loss 5.771409
[epoch7, step499]: loss 2.999016
[epoch7, step500]: loss 1.617350
[epoch7, step501]: loss 3.770591
[epoch7, step502]: loss 2.255441
[epoch7, step503]: loss 1.692154
[epoch7, step504]: loss 1.457919
[epoch7, step505]: loss 7.947748
[epoch7, step506]: loss 15.559509
[epoch7, step507]: loss 1.457790
[epoch7, step508]: loss 10.008040
[epoch7, step509]: loss 25.012539
[epoch7, step510]: loss 17.473164
[epoch7, step511]: loss 7.695567
[epoch7, step512]: loss 12.638762
[epoch7, step513]: loss 3.481229
[epoch7, step514]: loss 3.288723
[epoch7, step515]: loss 9.484913
[epoch7, step516]: loss 6.423126
[epoch7, step517]: loss 13.517462
[epoch7, step518]: loss 1.899414
[epoch7, step519]: loss 13.520569
[epoch7, step520]: loss 7.064677
[epoch7, step521]: loss 17.838358
[epoch7, step522]: loss 16.758759
[epoch7, step523]: loss 16.637604
[epoch7, step524]: loss 3.400742
[epoch7, step525]: loss 5.188229
[epoch7, step526]: loss 5.705009
[epoch7, step527]: loss 18.388493
[epoch7, step528]: loss 3.677259
[epoch7, step529]: loss 5.831694
[epoch7, step530]: loss 2.025100
[epoch7, step531]: loss 2.087314
[epoch7, step532]: loss 17.531696
[epoch7, step533]: loss 2.043862
[epoch7, step534]: loss 19.822821
[epoch7, step535]: loss 12.149275
[epoch7, step536]: loss 2.443465
[epoch7, step537]: loss 3.433810
[epoch7, step538]: loss 11.953418
[epoch7, step539]: loss 8.357368
[epoch7, step540]: loss 5.602438
[epoch7, step541]: loss 2.487672
[epoch7, step542]: loss 3.088568
[epoch7, step543]: loss 3.704608
[epoch7, step544]: loss 5.268198
[epoch7, step545]: loss 2.495602
[epoch7, step546]: loss 2.264078
[epoch7, step547]: loss 3.341998
[epoch7, step548]: loss 12.291389
[epoch7, step549]: loss 2.157170
[epoch7, step550]: loss 1.687296
[epoch7, step551]: loss 3.411114
[epoch7, step552]: loss 2.392174
[epoch7, step553]: loss 1.246085
[epoch7, step554]: loss 1.449109
[epoch7, step555]: loss 9.484488
[epoch7, step556]: loss 1.020780
[epoch7, step557]: loss 6.819766
[epoch7, step558]: loss 7.033243
[epoch7, step559]: loss 2.709991
[epoch7, step560]: loss 15.076863
[epoch7, step561]: loss 13.032392
[epoch7, step562]: loss 11.833333
[epoch7, step563]: loss 5.856503
[epoch7, step564]: loss 1.812923
[epoch7, step565]: loss 16.916967
[epoch7, step566]: loss 2.493269
[epoch7, step567]: loss 1.981053
[epoch7, step568]: loss 2.787265
[epoch7, step569]: loss 1.520680
[epoch7, step570]: loss 1.629672
[epoch7, step571]: loss 4.631100
[epoch7, step572]: loss 1.608217
[epoch7, step573]: loss 0.972283
[epoch7, step574]: loss 2.054951
[epoch7, step575]: loss 8.286373
[epoch7, step576]: loss 6.208684
[epoch7, step577]: loss 14.075396
[epoch7, step578]: loss 1.409885
[epoch7, step579]: loss 14.925387
[epoch7, step580]: loss 3.867096
[epoch7, step581]: loss 4.618979
[epoch7, step582]: loss 13.169389
[epoch7, step583]: loss 3.269215
[epoch7, step584]: loss 13.519034
[epoch7, step585]: loss 1.203617
[epoch7, step586]: loss 27.368591
[epoch7, step587]: loss 6.400289
[epoch7, step588]: loss 1.525238
[epoch7, step589]: loss 2.112499
[epoch7, step590]: loss 3.273756
[epoch7, step591]: loss 9.819708
[epoch7, step592]: loss 1.533103
[epoch7, step593]: loss 4.516211
[epoch7, step594]: loss 3.067713
[epoch7, step595]: loss 2.879383
[epoch7, step596]: loss 1.317046
[epoch7, step597]: loss 6.125937
[epoch7, step598]: loss 1.730534
[epoch7, step599]: loss 16.281244
[epoch7, step600]: loss 2.080939
[epoch7, step601]: loss 6.329616
[epoch7, step602]: loss 6.299242
[epoch7, step603]: loss 5.018882
[epoch7, step604]: loss 1.734421
[epoch7, step605]: loss 2.323760
[epoch7, step606]: loss 9.551744
[epoch7, step607]: loss 18.496815
[epoch7, step608]: loss 11.162488
[epoch7, step609]: loss 2.645134
[epoch7, step610]: loss 18.256828
[epoch7, step611]: loss 6.635537
[epoch7, step612]: loss 2.830706
[epoch7, step613]: loss 6.009386
[epoch7, step614]: loss 1.007572
[epoch7, step615]: loss 5.290902
[epoch7, step616]: loss 2.194659
[epoch7, step617]: loss 11.055449
[epoch7, step618]: loss 8.496748
[epoch7, step619]: loss 14.650053
[epoch7, step620]: loss 23.668674
[epoch7, step621]: loss 10.996360
[epoch7, step622]: loss 4.684282
[epoch7, step623]: loss 3.389510
[epoch7, step624]: loss 8.415417
[epoch7, step625]: loss 14.870914
[epoch7, step626]: loss 3.313911
[epoch7, step627]: loss 9.174666
[epoch7, step628]: loss 5.454560
[epoch7, step629]: loss 11.777175
[epoch7, step630]: loss 13.885425
[epoch7, step631]: loss 1.851809
[epoch7, step632]: loss 3.592916
[epoch7, step633]: loss 5.380542
[epoch7, step634]: loss 5.943082
[epoch7, step635]: loss 14.631361
[epoch7, step636]: loss 12.384088
[epoch7, step637]: loss 12.748741
[epoch7, step638]: loss 2.365748
[epoch7, step639]: loss 2.020461
[epoch7, step640]: loss 2.138907
[epoch7, step641]: loss 26.048208
[epoch7, step642]: loss 2.877567
[epoch7, step643]: loss 15.831543
[epoch7, step644]: loss 9.963990
[epoch7, step645]: loss 3.046086
[epoch7, step646]: loss 5.429115
[epoch7, step647]: loss 1.253235
[epoch7, step648]: loss 13.844321
[epoch7, step649]: loss 5.104750
[epoch7, step650]: loss 5.892216
[epoch7, step651]: loss 14.929349
[epoch7, step652]: loss 1.519977
[epoch7, step653]: loss 2.393314
[epoch7, step654]: loss 1.965391
[epoch7, step655]: loss 2.154037
[epoch7, step656]: loss 1.659014
[epoch7, step657]: loss 2.416135
[epoch7, step658]: loss 1.937135
[epoch7, step659]: loss 2.690485
[epoch7, step660]: loss 5.017869
[epoch7, step661]: loss 10.571373
[epoch7, step662]: loss 1.873765
[epoch7, step663]: loss 1.550594
[epoch7, step664]: loss 10.074409
[epoch7, step665]: loss 14.548533
[epoch7, step666]: loss 21.902554
[epoch7, step667]: loss 20.826326
[epoch7, step668]: loss 2.799595
[epoch7, step669]: loss 10.511854
[epoch7, step670]: loss 6.601948
[epoch7, step671]: loss 1.344862
[epoch7, step672]: loss 1.654747
[epoch7, step673]: loss 12.073421
[epoch7, step674]: loss 2.960821
[epoch7, step675]: loss 10.144127
[epoch7, step676]: loss 2.041784
[epoch7, step677]: loss 7.010864
[epoch7, step678]: loss 25.216585
[epoch7, step679]: loss 4.286654
[epoch7, step680]: loss 18.408659
[epoch7, step681]: loss 6.898880
[epoch7, step682]: loss 1.739032
[epoch7, step683]: loss 2.123231
[epoch7, step684]: loss 5.661995
[epoch7, step685]: loss 1.548557
[epoch7, step686]: loss 2.547430
[epoch7, step687]: loss 2.312331
[epoch7, step688]: loss 10.540122
[epoch7, step689]: loss 1.230162
[epoch7, step690]: loss 9.832840
[epoch7, step691]: loss 2.098365
[epoch7, step692]: loss 4.282219
[epoch7, step693]: loss 14.152905
[epoch7, step694]: loss 8.432544
[epoch7, step695]: loss 1.855359
[epoch7, step696]: loss 4.174245
[epoch7, step697]: loss 6.493859
[epoch7, step698]: loss 6.279096
[epoch7, step699]: loss 13.894341
[epoch7, step700]: loss 1.952845
[epoch7, step701]: loss 16.025158
[epoch7, step702]: loss 15.484885
[epoch7, step703]: loss 10.565832
[epoch7, step704]: loss 23.131611
[epoch7, step705]: loss 14.272997
[epoch7, step706]: loss 0.998472
[epoch7, step707]: loss 1.166345
[epoch7, step708]: loss 2.439607
[epoch7, step709]: loss 15.213847
[epoch7, step710]: loss 25.734518
[epoch7, step711]: loss 1.450117
[epoch7, step712]: loss 22.905313
[epoch7, step713]: loss 2.873665
[epoch7, step714]: loss 14.379261
[epoch7, step715]: loss 16.205799
[epoch7, step716]: loss 6.096321
[epoch7, step717]: loss 1.905422
[epoch7, step718]: loss 11.187272
[epoch7, step719]: loss 13.464735
[epoch7, step720]: loss 1.501460
[epoch7, step721]: loss 2.917031
[epoch7, step722]: loss 8.973053
[epoch7, step723]: loss 2.916898
[epoch7, step724]: loss 10.278848
[epoch7, step725]: loss 1.569283
[epoch7, step726]: loss 3.196363
[epoch7, step727]: loss 23.825748
[epoch7, step728]: loss 3.975712
[epoch7, step729]: loss 2.611746
[epoch7, step730]: loss 3.824336
[epoch7, step731]: loss 1.194066
[epoch7, step732]: loss 10.358752
[epoch7, step733]: loss 2.796666
[epoch7, step734]: loss 5.686661
[epoch7, step735]: loss 9.923265
[epoch7, step736]: loss 2.894891
[epoch7, step737]: loss 1.244816
[epoch7, step738]: loss 2.624851
[epoch7, step739]: loss 1.223800
[epoch7, step740]: loss 1.570854
[epoch7, step741]: loss 2.273917
[epoch7, step742]: loss 3.038004
[epoch7, step743]: loss 10.327181
[epoch7, step744]: loss 1.549316
[epoch7, step745]: loss 9.701313
[epoch7, step746]: loss 12.705924
[epoch7, step747]: loss 2.239732
[epoch7, step748]: loss 1.552921
[epoch7, step749]: loss 12.731186
[epoch7, step750]: loss 1.389648
[epoch7, step751]: loss 6.793521
[epoch7, step752]: loss 11.097393
[epoch7, step753]: loss 13.138472
[epoch7, step754]: loss 1.396068
[epoch7, step755]: loss 10.044885
[epoch7, step756]: loss 0.933493
[epoch7, step757]: loss 9.108644
[epoch7, step758]: loss 1.869536
[epoch7, step759]: loss 2.629027
[epoch7, step760]: loss 2.454032
[epoch7, step761]: loss 11.112795
[epoch7, step762]: loss 2.260913
[epoch7, step763]: loss 6.922872
[epoch7, step764]: loss 4.321945
[epoch7, step765]: loss 6.565908
[epoch7, step766]: loss 12.509946
[epoch7, step767]: loss 2.753129
[epoch7, step768]: loss 17.878368
[epoch7, step769]: loss 4.942531
[epoch7, step770]: loss 12.415547
[epoch7, step771]: loss 4.209874
[epoch7, step772]: loss 1.534567
[epoch7, step773]: loss 11.556211
[epoch7, step774]: loss 5.469361
[epoch7, step775]: loss 4.965795
[epoch7, step776]: loss 3.557847
[epoch7, step777]: loss 1.839287
[epoch7, step778]: loss 14.096827
[epoch7, step779]: loss 1.490532
[epoch7, step780]: loss 5.828512
[epoch7, step781]: loss 21.241623
[epoch7, step782]: loss 1.491086
[epoch7, step783]: loss 2.436188
[epoch7, step784]: loss 23.129669
[epoch7, step785]: loss 14.183557
[epoch7, step786]: loss 3.212908
[epoch7, step787]: loss 1.267975
[epoch7, step788]: loss 10.021761
[epoch7, step789]: loss 2.849637
[epoch7, step790]: loss 4.900123
[epoch7, step791]: loss 3.779435
[epoch7, step792]: loss 4.372253
[epoch7, step793]: loss 17.862173
[epoch7, step794]: loss 17.546717
[epoch7, step795]: loss 17.823290
[epoch7, step796]: loss 12.597582
[epoch7, step797]: loss 3.125393
[epoch7, step798]: loss 2.065073
[epoch7, step799]: loss 6.888631
[epoch7, step800]: loss 29.232178
[epoch7, step801]: loss 9.318631
[epoch7, step802]: loss 5.740217
[epoch7, step803]: loss 1.500618
[epoch7, step804]: loss 1.202705
[epoch7, step805]: loss 4.306340
[epoch7, step806]: loss 3.787046
[epoch7, step807]: loss 1.472547
[epoch7, step808]: loss 15.658133
[epoch7, step809]: loss 1.327099
[epoch7, step810]: loss 1.237382
[epoch7, step811]: loss 2.820988
[epoch7, step812]: loss 5.848888
[epoch7, step813]: loss 0.724424
[epoch7, step814]: loss 13.974546
[epoch7, step815]: loss 11.667332
[epoch7, step816]: loss 1.634887
[epoch7, step817]: loss 3.642331
[epoch7, step818]: loss 1.355248
[epoch7, step819]: loss 8.089347
[epoch7, step820]: loss 30.237534
[epoch7, step821]: loss 5.881152
[epoch7, step822]: loss 3.291488
[epoch7, step823]: loss 1.830814
[epoch7, step824]: loss 2.019498
[epoch7, step825]: loss 1.226812
[epoch7, step826]: loss 7.118130
[epoch7, step827]: loss 0.861052
[epoch7, step828]: loss 3.883438
[epoch7, step829]: loss 1.897027
[epoch7, step830]: loss 1.976463
[epoch7, step831]: loss 10.250294
[epoch7, step832]: loss 2.761754
[epoch7, step833]: loss 3.111068
[epoch7, step834]: loss 8.573966
[epoch7, step835]: loss 1.447430
[epoch7, step836]: loss 5.376126
[epoch7, step837]: loss 1.537279
[epoch7, step838]: loss 3.937860
[epoch7, step839]: loss 7.744206
[epoch7, step840]: loss 5.422861
[epoch7, step841]: loss 6.242555
[epoch7, step842]: loss 2.833837
[epoch7, step843]: loss 2.438044
[epoch7, step844]: loss 2.201474
[epoch7, step845]: loss 5.589224
[epoch7, step846]: loss 16.721350
[epoch7, step847]: loss 11.067543
[epoch7, step848]: loss 12.157835
[epoch7, step849]: loss 3.613589
[epoch7, step850]: loss 17.708902
[epoch7, step851]: loss 1.062209
[epoch7, step852]: loss 14.587362
[epoch7, step853]: loss 6.234611
[epoch7, step854]: loss 16.797367
[epoch7, step855]: loss 1.751152
[epoch7, step856]: loss 2.454527
[epoch7, step857]: loss 5.326364
[epoch7, step858]: loss 2.849619
[epoch7, step859]: loss 2.480621
[epoch7, step860]: loss 1.902312
[epoch7, step861]: loss 2.210646
[epoch7, step862]: loss 11.638096
[epoch7, step863]: loss 2.598326
[epoch7, step864]: loss 2.382021
[epoch7, step865]: loss 1.689578
[epoch7, step866]: loss 1.355967
[epoch7, step867]: loss 3.458398
[epoch7, step868]: loss 5.468529
[epoch7, step869]: loss 5.830601
[epoch7, step870]: loss 2.825425
[epoch7, step871]: loss 7.366937
[epoch7, step872]: loss 1.174893
[epoch7, step873]: loss 2.591254
[epoch7, step874]: loss 6.927722
[epoch7, step875]: loss 2.043265
[epoch7, step876]: loss 2.601218
[epoch7, step877]: loss 3.277557
[epoch7, step878]: loss 1.264353
[epoch7, step879]: loss 1.746746
[epoch7, step880]: loss 2.139705
[epoch7, step881]: loss 2.742547
[epoch7, step882]: loss 4.572725
[epoch7, step883]: loss 12.757985
[epoch7, step884]: loss 6.123262
[epoch7, step885]: loss 6.940801
[epoch7, step886]: loss 5.225911
[epoch7, step887]: loss 11.421475
[epoch7, step888]: loss 7.992221
[epoch7, step889]: loss 9.486609
[epoch7, step890]: loss 2.652087
[epoch7, step891]: loss 2.504650
[epoch7, step892]: loss 17.889364
[epoch7, step893]: loss 2.001064
[epoch7, step894]: loss 0.998395
[epoch7, step895]: loss 14.743057
[epoch7, step896]: loss 1.670302
[epoch7, step897]: loss 12.828393
[epoch7, step898]: loss 4.063601
[epoch7, step899]: loss 5.019070
[epoch7, step900]: loss 8.300285
[epoch7, step901]: loss 4.896627
[epoch7, step902]: loss 1.664756
[epoch7, step903]: loss 2.203538
[epoch7, step904]: loss 2.850039
[epoch7, step905]: loss 3.163428
[epoch7, step906]: loss 10.564104
[epoch7, step907]: loss 2.476888
[epoch7, step908]: loss 1.897821
[epoch7, step909]: loss 9.227216
[epoch7, step910]: loss 6.757659
[epoch7, step911]: loss 4.292155
[epoch7, step912]: loss 9.851274
[epoch7, step913]: loss 10.201864
[epoch7, step914]: loss 7.033381
[epoch7, step915]: loss 5.207381
[epoch7, step916]: loss 1.595112
[epoch7, step917]: loss 10.632033
[epoch7, step918]: loss 7.806965
[epoch7, step919]: loss 1.551055
[epoch7, step920]: loss 23.217505
[epoch7, step921]: loss 6.614890
[epoch7, step922]: loss 11.165650
[epoch7, step923]: loss 3.646366
[epoch7, step924]: loss 10.692957
[epoch7, step925]: loss 22.860298
[epoch7, step926]: loss 1.717105
[epoch7, step927]: loss 9.114738
[epoch7, step928]: loss 11.226146
[epoch7, step929]: loss 4.793068
[epoch7, step930]: loss 7.557930
[epoch7, step931]: loss 7.667180
[epoch7, step932]: loss 3.226119
[epoch7, step933]: loss 1.294427
[epoch7, step934]: loss 3.063669
[epoch7, step935]: loss 2.627523
[epoch7, step936]: loss 5.179991
[epoch7, step937]: loss 9.679679
[epoch7, step938]: loss 8.922603
[epoch7, step939]: loss 12.561195
[epoch7, step940]: loss 5.962753
[epoch7, step941]: loss 1.471945
[epoch7, step942]: loss 2.504442
[epoch7, step943]: loss 13.036210
[epoch7, step944]: loss 1.622747
[epoch7, step945]: loss 6.452560
[epoch7, step946]: loss 1.458820
[epoch7, step947]: loss 14.027981
[epoch7, step948]: loss 3.780517
[epoch7, step949]: loss 16.469152
[epoch7, step950]: loss 1.494810
[epoch7, step951]: loss 1.661616
[epoch7, step952]: loss 1.976489
[epoch7, step953]: loss 5.728963
[epoch7, step954]: loss 1.104360
[epoch7, step955]: loss 4.420548
[epoch7, step956]: loss 25.721466
[epoch7, step957]: loss 2.296755
[epoch7, step958]: loss 2.667283
[epoch7, step959]: loss 4.409891
[epoch7, step960]: loss 13.553018
[epoch7, step961]: loss 17.635101
[epoch7, step962]: loss 9.627983
[epoch7, step963]: loss 1.830503
[epoch7, step964]: loss 1.955623
[epoch7, step965]: loss 3.836364
[epoch7, step966]: loss 12.454247
[epoch7, step967]: loss 1.437803
[epoch7, step968]: loss 8.073171
[epoch7, step969]: loss 17.016058
[epoch7, step970]: loss 6.618653
[epoch7, step971]: loss 5.467975
[epoch7, step972]: loss 10.138785
[epoch7, step973]: loss 17.352745
[epoch7, step974]: loss 2.245412
[epoch7, step975]: loss 2.682462
[epoch7, step976]: loss 6.389628
[epoch7, step977]: loss 8.218505
[epoch7, step978]: loss 2.152620
[epoch7, step979]: loss 3.669386
[epoch7, step980]: loss 26.924610
[epoch7, step981]: loss 4.913863
[epoch7, step982]: loss 2.731545
[epoch7, step983]: loss 6.083140
[epoch7, step984]: loss 3.385928
[epoch7, step985]: loss 2.424221
[epoch7, step986]: loss 1.145837
[epoch7, step987]: loss 10.257261
[epoch7, step988]: loss 9.486320
[epoch7, step989]: loss 2.258755
[epoch7, step990]: loss 7.807956
[epoch7, step991]: loss 2.363962
[epoch7, step992]: loss 2.058496
[epoch7, step993]: loss 10.847423
[epoch7, step994]: loss 10.292230
[epoch7, step995]: loss 3.849746
[epoch7, step996]: loss 1.331721
[epoch7, step997]: loss 3.270405
[epoch7, step998]: loss 5.034580
[epoch7, step999]: loss 10.986188
[epoch7, step1000]: loss 15.646446
[epoch7, step1001]: loss 1.868372
[epoch7, step1002]: loss 1.072579
[epoch7, step1003]: loss 3.315785
[epoch7, step1004]: loss 2.976009
[epoch7, step1005]: loss 11.315674
[epoch7, step1006]: loss 1.026611
[epoch7, step1007]: loss 6.251807
[epoch7, step1008]: loss 5.841724
[epoch7, step1009]: loss 6.057315
[epoch7, step1010]: loss 6.561917
[epoch7, step1011]: loss 12.838076
[epoch7, step1012]: loss 10.718644
[epoch7, step1013]: loss 9.713331
[epoch7, step1014]: loss 3.067400
[epoch7, step1015]: loss 3.088741
[epoch7, step1016]: loss 13.106984
[epoch7, step1017]: loss 13.107340
[epoch7, step1018]: loss 16.334509
[epoch7, step1019]: loss 22.990391
[epoch7, step1020]: loss 8.273126
[epoch7, step1021]: loss 4.712574
[epoch7, step1022]: loss 1.657735
[epoch7, step1023]: loss 1.318772
[epoch7, step1024]: loss 1.804621
[epoch7, step1025]: loss 8.552173
[epoch7, step1026]: loss 3.915698
[epoch7, step1027]: loss 2.030613
[epoch7, step1028]: loss 6.962514
[epoch7, step1029]: loss 3.315939
[epoch7, step1030]: loss 8.081241
[epoch7, step1031]: loss 9.526563
[epoch7, step1032]: loss 21.427277
[epoch7, step1033]: loss 10.369538
[epoch7, step1034]: loss 1.581774
[epoch7, step1035]: loss 3.696251
[epoch7, step1036]: loss 3.360084
[epoch7, step1037]: loss 0.862680
[epoch7, step1038]: loss 9.405397
[epoch7, step1039]: loss 1.788137
[epoch7, step1040]: loss 7.582942
[epoch7, step1041]: loss 11.157626
[epoch7, step1042]: loss 2.796289
[epoch7, step1043]: loss 2.414695
[epoch7, step1044]: loss 1.927720
[epoch7, step1045]: loss 2.528634
[epoch7, step1046]: loss 9.635220
[epoch7, step1047]: loss 14.674620
[epoch7, step1048]: loss 8.970471
[epoch7, step1049]: loss 1.120750
[epoch7, step1050]: loss 6.672977
[epoch7, step1051]: loss 2.294895
[epoch7, step1052]: loss 13.391118
[epoch7, step1053]: loss 1.912304
[epoch7, step1054]: loss 2.325136
[epoch7, step1055]: loss 4.185356
[epoch7, step1056]: loss 3.596858
[epoch7, step1057]: loss 7.918573
[epoch7, step1058]: loss 3.388224
[epoch7, step1059]: loss 2.416502
[epoch7, step1060]: loss 1.850746
[epoch7, step1061]: loss 2.340277
[epoch7, step1062]: loss 10.514292
[epoch7, step1063]: loss 3.198329
[epoch7, step1064]: loss 7.514478
[epoch7, step1065]: loss 5.061066
[epoch7, step1066]: loss 20.711016
[epoch7, step1067]: loss 2.341457
[epoch7, step1068]: loss 1.496755
[epoch7, step1069]: loss 3.353116
[epoch7, step1070]: loss 3.122926
[epoch7, step1071]: loss 1.878898
[epoch7, step1072]: loss 1.845419
[epoch7, step1073]: loss 5.683527
[epoch7, step1074]: loss 11.055016
[epoch7, step1075]: loss 4.850561
[epoch7, step1076]: loss 6.525411
[epoch7, step1077]: loss 2.062212
[epoch7, step1078]: loss 1.863013
[epoch7, step1079]: loss 24.303839
[epoch7, step1080]: loss 4.400124
[epoch7, step1081]: loss 1.803777
[epoch7, step1082]: loss 20.136574
[epoch7, step1083]: loss 11.982224
[epoch7, step1084]: loss 10.518724
[epoch7, step1085]: loss 13.725061
[epoch7, step1086]: loss 1.758899
[epoch7, step1087]: loss 5.264184
[epoch7, step1088]: loss 13.252543
[epoch7, step1089]: loss 29.425163
[epoch7, step1090]: loss 1.417342
[epoch7, step1091]: loss 2.969350
[epoch7, step1092]: loss 1.935316
[epoch7, step1093]: loss 2.311195
[epoch7, step1094]: loss 17.579441
[epoch7, step1095]: loss 5.723918
[epoch7, step1096]: loss 8.221218
[epoch7, step1097]: loss 1.775762
[epoch7, step1098]: loss 1.472227
[epoch7, step1099]: loss 1.435029
[epoch7, step1100]: loss 1.580668
[epoch7, step1101]: loss 5.548037
[epoch7, step1102]: loss 2.093023
[epoch7, step1103]: loss 6.656105
[epoch7, step1104]: loss 11.802116
[epoch7, step1105]: loss 1.958972
[epoch7, step1106]: loss 2.397344
[epoch7, step1107]: loss 5.797842
[epoch7, step1108]: loss 6.566799
[epoch7, step1109]: loss 21.247610
[epoch7, step1110]: loss 2.152011
[epoch7, step1111]: loss 1.134760
[epoch7, step1112]: loss 9.570079
[epoch7, step1113]: loss 4.703528
[epoch7, step1114]: loss 1.463442
[epoch7, step1115]: loss 2.672233
[epoch7, step1116]: loss 14.408765
[epoch7, step1117]: loss 1.336000
[epoch7, step1118]: loss 2.114673
[epoch7, step1119]: loss 3.165673
[epoch7, step1120]: loss 1.908791
[epoch7, step1121]: loss 1.863287
[epoch7, step1122]: loss 0.965158
[epoch7, step1123]: loss 1.412320
[epoch7, step1124]: loss 7.987497
[epoch7, step1125]: loss 1.287039
[epoch7, step1126]: loss 17.113533
[epoch7, step1127]: loss 4.978993
[epoch7, step1128]: loss 17.333921
[epoch7, step1129]: loss 9.092047
[epoch7, step1130]: loss 3.180335
[epoch7, step1131]: loss 2.078105
[epoch7, step1132]: loss 12.351977
[epoch7, step1133]: loss 15.106115
[epoch7, step1134]: loss 4.262913
[epoch7, step1135]: loss 1.043933
[epoch7, step1136]: loss 5.521509
[epoch7, step1137]: loss 2.065752
[epoch7, step1138]: loss 12.932344
[epoch7, step1139]: loss 6.263627
[epoch7, step1140]: loss 2.101195
[epoch7, step1141]: loss 4.730817
[epoch7, step1142]: loss 4.732766
[epoch7, step1143]: loss 5.862794
[epoch7, step1144]: loss 12.333318
[epoch7, step1145]: loss 1.855277
[epoch7, step1146]: loss 1.012061
[epoch7, step1147]: loss 3.001621
[epoch7, step1148]: loss 13.695518
[epoch7, step1149]: loss 4.915015
[epoch7, step1150]: loss 18.112007
[epoch7, step1151]: loss 2.715189
[epoch7, step1152]: loss 1.475846
[epoch7, step1153]: loss 18.166639
[epoch7, step1154]: loss 10.417439
[epoch7, step1155]: loss 11.384933
[epoch7, step1156]: loss 1.579540
[epoch7, step1157]: loss 2.583718
[epoch7, step1158]: loss 18.741060
[epoch7, step1159]: loss 2.230220
[epoch7, step1160]: loss 9.301118
[epoch7, step1161]: loss 16.476704
[epoch7, step1162]: loss 12.811621
[epoch7, step1163]: loss 2.092550
[epoch7, step1164]: loss 5.084413
[epoch7, step1165]: loss 2.028389
[epoch7, step1166]: loss 5.623664
[epoch7, step1167]: loss 1.518461
[epoch7, step1168]: loss 10.742476
[epoch7, step1169]: loss 1.177292
[epoch7, step1170]: loss 15.192385
[epoch7, step1171]: loss 17.306021
[epoch7, step1172]: loss 2.204561
[epoch7, step1173]: loss 5.144469
[epoch7, step1174]: loss 4.772450
[epoch7, step1175]: loss 21.770386
[epoch7, step1176]: loss 6.879757
[epoch7, step1177]: loss 2.918193
[epoch7, step1178]: loss 2.356850
[epoch7, step1179]: loss 4.526703
[epoch7, step1180]: loss 24.719912
[epoch7, step1181]: loss 1.791589
[epoch7, step1182]: loss 1.863486
[epoch7, step1183]: loss 6.540661
[epoch7, step1184]: loss 3.225428
[epoch7, step1185]: loss 17.273914
[epoch7, step1186]: loss 2.183842
[epoch7, step1187]: loss 5.390992
[epoch7, step1188]: loss 17.706882
[epoch7, step1189]: loss 5.577684
[epoch7, step1190]: loss 2.602938
[epoch7, step1191]: loss 29.501259
[epoch7, step1192]: loss 1.759148
[epoch7, step1193]: loss 4.167755
[epoch7, step1194]: loss 20.504028
[epoch7, step1195]: loss 2.965870
[epoch7, step1196]: loss 11.800278
[epoch7, step1197]: loss 2.113540
[epoch7, step1198]: loss 6.497047
[epoch7, step1199]: loss 7.189501
[epoch7, step1200]: loss 5.388849
[epoch7, step1201]: loss 7.243381
[epoch7, step1202]: loss 5.553618
[epoch7, step1203]: loss 14.756528
[epoch7, step1204]: loss 8.820032
[epoch7, step1205]: loss 2.526279
[epoch7, step1206]: loss 1.401980
[epoch7, step1207]: loss 1.303972
[epoch7, step1208]: loss 1.454270
[epoch7, step1209]: loss 2.063442
[epoch7, step1210]: loss 1.412994
[epoch7, step1211]: loss 3.195222
[epoch7, step1212]: loss 8.611906
[epoch7, step1213]: loss 1.713142
[epoch7, step1214]: loss 13.910419
[epoch7, step1215]: loss 25.995449
[epoch7, step1216]: loss 10.715981
[epoch7, step1217]: loss 1.937518
[epoch7, step1218]: loss 6.472658
[epoch7, step1219]: loss 4.110126
[epoch7, step1220]: loss 2.729678
[epoch7, step1221]: loss 11.390408
[epoch7, step1222]: loss 9.054655
[epoch7, step1223]: loss 4.010203
[epoch7, step1224]: loss 8.217757
[epoch7, step1225]: loss 3.751314
[epoch7, step1226]: loss 1.036549
[epoch7, step1227]: loss 10.462641
[epoch7, step1228]: loss 6.027590
[epoch7, step1229]: loss 16.545561
[epoch7, step1230]: loss 16.289665
[epoch7, step1231]: loss 1.936984
[epoch7, step1232]: loss 2.227262
[epoch7, step1233]: loss 5.140623
[epoch7, step1234]: loss 3.114534
[epoch7, step1235]: loss 1.287635
[epoch7, step1236]: loss 1.548146
[epoch7, step1237]: loss 8.419712
[epoch7, step1238]: loss 14.582726
[epoch7, step1239]: loss 3.509051
[epoch7, step1240]: loss 20.771660
[epoch7, step1241]: loss 11.974379
[epoch7, step1242]: loss 17.717953
[epoch7, step1243]: loss 1.926551
[epoch7, step1244]: loss 2.825326
[epoch7, step1245]: loss 16.580688
[epoch7, step1246]: loss 9.287587
[epoch7, step1247]: loss 2.861186
[epoch7, step1248]: loss 7.955207
[epoch7, step1249]: loss 13.118207
[epoch7, step1250]: loss 0.899812
[epoch7, step1251]: loss 5.311017
[epoch7, step1252]: loss 2.001502
[epoch7, step1253]: loss 2.231489
[epoch7, step1254]: loss 3.516734
[epoch7, step1255]: loss 6.511989
[epoch7, step1256]: loss 12.771834
[epoch7, step1257]: loss 10.694264
[epoch7, step1258]: loss 1.715307
[epoch7, step1259]: loss 5.619914
[epoch7, step1260]: loss 25.755451
[epoch7, step1261]: loss 7.796266
[epoch7, step1262]: loss 4.816652
[epoch7, step1263]: loss 15.262899
[epoch7, step1264]: loss 6.965276
[epoch7, step1265]: loss 6.512739
[epoch7, step1266]: loss 1.714612
[epoch7, step1267]: loss 7.958757
[epoch7, step1268]: loss 1.782916
[epoch7, step1269]: loss 4.409764
[epoch7, step1270]: loss 19.176552
[epoch7, step1271]: loss 3.643789
[epoch7, step1272]: loss 1.810388
[epoch7, step1273]: loss 2.813373
[epoch7, step1274]: loss 17.244726
[epoch7, step1275]: loss 4.313650
[epoch7, step1276]: loss 2.705283
[epoch7, step1277]: loss 4.780159
[epoch7, step1278]: loss 9.104335
[epoch7, step1279]: loss 1.951648
[epoch7, step1280]: loss 4.742472
[epoch7, step1281]: loss 2.225173
[epoch7, step1282]: loss 11.902604
[epoch7, step1283]: loss 1.575704
[epoch7, step1284]: loss 20.959040
[epoch7, step1285]: loss 5.999694
[epoch7, step1286]: loss 8.600652
[epoch7, step1287]: loss 1.670487
[epoch7, step1288]: loss 4.199084
[epoch7, step1289]: loss 1.107575
[epoch7, step1290]: loss 4.707336
[epoch7, step1291]: loss 18.531603
[epoch7, step1292]: loss 3.085092
[epoch7, step1293]: loss 11.456285
[epoch7, step1294]: loss 8.405217
[epoch7, step1295]: loss 8.772221
[epoch7, step1296]: loss 10.405854
[epoch7, step1297]: loss 20.890627
[epoch7, step1298]: loss 11.364933
[epoch7, step1299]: loss 1.002343
[epoch7, step1300]: loss 3.300887
[epoch7, step1301]: loss 2.474477
[epoch7, step1302]: loss 1.266006
[epoch7, step1303]: loss 21.027287
[epoch7, step1304]: loss 2.010835
[epoch7, step1305]: loss 26.719728
[epoch7, step1306]: loss 2.063145
[epoch7, step1307]: loss 1.945029
[epoch7, step1308]: loss 1.957653
[epoch7, step1309]: loss 3.124070
[epoch7, step1310]: loss 5.414659
[epoch7, step1311]: loss 1.715552
[epoch7, step1312]: loss 5.996488
[epoch7, step1313]: loss 5.776992
[epoch7, step1314]: loss 5.672101
[epoch7, step1315]: loss 15.051885
[epoch7, step1316]: loss 1.623479
[epoch7, step1317]: loss 1.090484
[epoch7, step1318]: loss 14.720229
[epoch7, step1319]: loss 10.115407
[epoch7, step1320]: loss 2.700169
[epoch7, step1321]: loss 3.754787
[epoch7, step1322]: loss 17.041410
[epoch7, step1323]: loss 4.757797
[epoch7, step1324]: loss 4.427697
[epoch7, step1325]: loss 11.050584
[epoch7, step1326]: loss 1.238785
[epoch7, step1327]: loss 8.954463
[epoch7, step1328]: loss 5.618906
[epoch7, step1329]: loss 1.732938
[epoch7, step1330]: loss 8.684951
[epoch7, step1331]: loss 1.456351
[epoch7, step1332]: loss 12.493004
[epoch7, step1333]: loss 1.886213
[epoch7, step1334]: loss 1.416522
[epoch7, step1335]: loss 2.723451
[epoch7, step1336]: loss 11.416242
[epoch7, step1337]: loss 2.209219
[epoch7, step1338]: loss 2.462827
[epoch7, step1339]: loss 12.636824
[epoch7, step1340]: loss 22.603201
[epoch7, step1341]: loss 2.603699
[epoch7, step1342]: loss 5.637595
[epoch7, step1343]: loss 17.249838
[epoch7, step1344]: loss 4.712751
[epoch7, step1345]: loss 6.592619
[epoch7, step1346]: loss 1.618602
[epoch7, step1347]: loss 10.765260
[epoch7, step1348]: loss 1.914639
[epoch7, step1349]: loss 11.820707
[epoch7, step1350]: loss 33.060711
[epoch7, step1351]: loss 3.428916
[epoch7, step1352]: loss 10.259940
[epoch7, step1353]: loss 1.366303
[epoch7, step1354]: loss 6.033072
[epoch7, step1355]: loss 14.242292
[epoch7, step1356]: loss 1.233484
[epoch7, step1357]: loss 6.225874
[epoch7, step1358]: loss 13.737974
[epoch7, step1359]: loss 2.369041
[epoch7, step1360]: loss 8.937807
[epoch7, step1361]: loss 2.708111
[epoch7, step1362]: loss 13.668185
[epoch7, step1363]: loss 0.768498
[epoch7, step1364]: loss 1.246387
[epoch7, step1365]: loss 1.601356
[epoch7, step1366]: loss 4.092492
[epoch7, step1367]: loss 3.596818
[epoch7, step1368]: loss 8.187804
[epoch7, step1369]: loss 13.484678
[epoch7, step1370]: loss 16.525267
[epoch7, step1371]: loss 14.632876
[epoch7, step1372]: loss 14.280350
[epoch7, step1373]: loss 1.369663
[epoch7, step1374]: loss 1.170706
[epoch7, step1375]: loss 10.974430
[epoch7, step1376]: loss 10.057228
[epoch7, step1377]: loss 2.261519
[epoch7, step1378]: loss 12.139701
[epoch7, step1379]: loss 4.024412
[epoch7, step1380]: loss 1.505198
[epoch7, step1381]: loss 7.932171
[epoch7, step1382]: loss 25.941833
[epoch7, step1383]: loss 11.052894
[epoch7, step1384]: loss 3.427990
[epoch7, step1385]: loss 1.371659
[epoch7, step1386]: loss 0.879017
[epoch7, step1387]: loss 2.587705
[epoch7, step1388]: loss 2.716331
[epoch7, step1389]: loss 13.690718
[epoch7, step1390]: loss 8.646349
[epoch7, step1391]: loss 2.004457
[epoch7, step1392]: loss 19.561205
[epoch7, step1393]: loss 18.514708
[epoch7, step1394]: loss 10.426386
[epoch7, step1395]: loss 1.539834
[epoch7, step1396]: loss 21.035847
[epoch7, step1397]: loss 2.407923
[epoch7, step1398]: loss 7.991277
[epoch7, step1399]: loss 1.529664
[epoch7, step1400]: loss 4.905439
[epoch7, step1401]: loss 9.220237
[epoch7, step1402]: loss 5.716085
[epoch7, step1403]: loss 2.694033
[epoch7, step1404]: loss 1.577251
[epoch7, step1405]: loss 15.402544
[epoch7, step1406]: loss 14.639240
[epoch7, step1407]: loss 14.861230
[epoch7, step1408]: loss 9.290342
[epoch7, step1409]: loss 10.030790
[epoch7, step1410]: loss 13.076233
[epoch7, step1411]: loss 10.654105
[epoch7, step1412]: loss 1.945805
[epoch7, step1413]: loss 9.185359
[epoch7, step1414]: loss 2.177156
[epoch7, step1415]: loss 1.935454
[epoch7, step1416]: loss 3.467734
[epoch7, step1417]: loss 13.140416
[epoch7, step1418]: loss 1.474264
[epoch7, step1419]: loss 5.779902
[epoch7, step1420]: loss 4.166285
[epoch7, step1421]: loss 7.600132
[epoch7, step1422]: loss 2.715322
[epoch7, step1423]: loss 7.167328
[epoch7, step1424]: loss 4.364932
[epoch7, step1425]: loss 2.122895
[epoch7, step1426]: loss 3.430680
[epoch7, step1427]: loss 2.691808
[epoch7, step1428]: loss 1.888916
[epoch7, step1429]: loss 1.724698
[epoch7, step1430]: loss 1.418261
[epoch7, step1431]: loss 11.842696
[epoch7, step1432]: loss 3.608941
[epoch7, step1433]: loss 10.426216
[epoch7, step1434]: loss 5.660738
[epoch7, step1435]: loss 1.790442
[epoch7, step1436]: loss 13.025592
[epoch7, step1437]: loss 14.890736
[epoch7, step1438]: loss 16.462271
[epoch7, step1439]: loss 2.769553
[epoch7, step1440]: loss 11.687695
[epoch7, step1441]: loss 1.445231
[epoch7, step1442]: loss 2.844615
[epoch7, step1443]: loss 1.080016
[epoch7, step1444]: loss 3.690988
[epoch7, step1445]: loss 1.675997
[epoch7, step1446]: loss 12.299118
[epoch7, step1447]: loss 16.237608
[epoch7, step1448]: loss 1.533479
[epoch7, step1449]: loss 12.688141
[epoch7, step1450]: loss 18.430490
[epoch7, step1451]: loss 8.514933
[epoch7, step1452]: loss 4.945567
[epoch7, step1453]: loss 3.164825
[epoch7, step1454]: loss 1.600564
[epoch7, step1455]: loss 13.391232
[epoch7, step1456]: loss 3.833162
[epoch7, step1457]: loss 1.217507
[epoch7, step1458]: loss 2.549933
[epoch7, step1459]: loss 10.305166
[epoch7, step1460]: loss 4.431924
[epoch7, step1461]: loss 3.524252
[epoch7, step1462]: loss 3.660296
[epoch7, step1463]: loss 6.003173
[epoch7, step1464]: loss 2.390920
[epoch7, step1465]: loss 2.234853
[epoch7, step1466]: loss 8.247721
[epoch7, step1467]: loss 9.292521
[epoch7, step1468]: loss 11.558369
[epoch7, step1469]: loss 6.216564
[epoch7, step1470]: loss 5.519559
[epoch7, step1471]: loss 1.728008
[epoch7, step1472]: loss 1.748655
[epoch7, step1473]: loss 6.024377
[epoch7, step1474]: loss 6.172729
[epoch7, step1475]: loss 2.681743
[epoch7, step1476]: loss 1.839200
[epoch7, step1477]: loss 4.663597
[epoch7, step1478]: loss 13.120909
[epoch7, step1479]: loss 1.745360
[epoch7, step1480]: loss 1.443551
[epoch7, step1481]: loss 2.379567
[epoch7, step1482]: loss 13.947884
[epoch7, step1483]: loss 7.405714
[epoch7, step1484]: loss 29.778336
[epoch7, step1485]: loss 4.190370
[epoch7, step1486]: loss 2.633739
[epoch7, step1487]: loss 16.505922
[epoch7, step1488]: loss 29.427717
[epoch7, step1489]: loss 0.993123
[epoch7, step1490]: loss 2.066626
[epoch7, step1491]: loss 2.215718
[epoch7, step1492]: loss 5.038903
[epoch7, step1493]: loss 1.825191
[epoch7, step1494]: loss 4.425159
[epoch7, step1495]: loss 1.408968
[epoch7, step1496]: loss 9.419990
[epoch7, step1497]: loss 3.733797
[epoch7, step1498]: loss 9.677271
[epoch7, step1499]: loss 3.511988
[epoch7, step1500]: loss 10.389605
[epoch7, step1501]: loss 1.750410
[epoch7, step1502]: loss 2.042136
[epoch7, step1503]: loss 11.051118
[epoch7, step1504]: loss 5.561865
[epoch7, step1505]: loss 1.992629
[epoch7, step1506]: loss 13.798403
[epoch7, step1507]: loss 9.705235
[epoch7, step1508]: loss 2.177252
[epoch7, step1509]: loss 11.389722
[epoch7, step1510]: loss 4.273024
[epoch7, step1511]: loss 1.522787
[epoch7, step1512]: loss 2.769283
[epoch7, step1513]: loss 6.047622
[epoch7, step1514]: loss 2.024809
[epoch7, step1515]: loss 9.155114
[epoch7, step1516]: loss 12.649637
[epoch7, step1517]: loss 4.045925
[epoch7, step1518]: loss 12.543663
[epoch7, step1519]: loss 10.484711
[epoch7, step1520]: loss 4.087977
[epoch7, step1521]: loss 14.301880
[epoch7, step1522]: loss 7.635386
[epoch7, step1523]: loss 2.043686
[epoch7, step1524]: loss 2.272271
[epoch7, step1525]: loss 9.417313
[epoch7, step1526]: loss 1.075786
[epoch7, step1527]: loss 4.341317
[epoch7, step1528]: loss 6.719902
[epoch7, step1529]: loss 14.013335
[epoch7, step1530]: loss 7.671457
[epoch7, step1531]: loss 2.700174
[epoch7, step1532]: loss 12.607236
[epoch7, step1533]: loss 8.099457
[epoch7, step1534]: loss 4.170626
[epoch7, step1535]: loss 2.210494
[epoch7, step1536]: loss 2.362564
[epoch7, step1537]: loss 2.127186
[epoch7, step1538]: loss 2.282763
[epoch7, step1539]: loss 1.518149
[epoch7, step1540]: loss 2.566232
[epoch7, step1541]: loss 1.532568
[epoch7, step1542]: loss 3.029023
[epoch7, step1543]: loss 2.057699
[epoch7, step1544]: loss 3.640174
[epoch7, step1545]: loss 11.861156
[epoch7, step1546]: loss 1.304652
[epoch7, step1547]: loss 4.834918
[epoch7, step1548]: loss 7.551572
[epoch7, step1549]: loss 5.829466
[epoch7, step1550]: loss 4.484658
[epoch7, step1551]: loss 7.110419
[epoch7, step1552]: loss 20.956968
[epoch7, step1553]: loss 3.551712
[epoch7, step1554]: loss 10.729834
[epoch7, step1555]: loss 3.778117
[epoch7, step1556]: loss 6.613464
[epoch7, step1557]: loss 2.266978
[epoch7, step1558]: loss 21.772219
[epoch7, step1559]: loss 7.661079
[epoch7, step1560]: loss 3.665788
[epoch7, step1561]: loss 5.454460
[epoch7, step1562]: loss 4.505784
[epoch7, step1563]: loss 12.920819
[epoch7, step1564]: loss 1.826014
[epoch7, step1565]: loss 22.187103
[epoch7, step1566]: loss 9.779655
[epoch7, step1567]: loss 15.001327
[epoch7, step1568]: loss 2.051066
[epoch7, step1569]: loss 15.913167
[epoch7, step1570]: loss 1.389833
[epoch7, step1571]: loss 7.144319
[epoch7, step1572]: loss 2.573672
[epoch7, step1573]: loss 3.260018
[epoch7, step1574]: loss 3.721530
[epoch7, step1575]: loss 1.212174
[epoch7, step1576]: loss 1.524410
[epoch7, step1577]: loss 6.659827
[epoch7, step1578]: loss 2.346959
[epoch7, step1579]: loss 2.826658
[epoch7, step1580]: loss 10.530207
[epoch7, step1581]: loss 1.917641
[epoch7, step1582]: loss 18.584812
[epoch7, step1583]: loss 23.571123
[epoch7, step1584]: loss 2.779914
[epoch7, step1585]: loss 1.158565
[epoch7, step1586]: loss 1.511958
[epoch7, step1587]: loss 2.126434
[epoch7, step1588]: loss 8.728621
[epoch7, step1589]: loss 4.166269
[epoch7, step1590]: loss 1.791368
[epoch7, step1591]: loss 2.838244
[epoch7, step1592]: loss 14.398374
[epoch7, step1593]: loss 21.222792
[epoch7, step1594]: loss 3.257643
[epoch7, step1595]: loss 17.732864
[epoch7, step1596]: loss 14.890588
[epoch7, step1597]: loss 9.793367
[epoch7, step1598]: loss 13.312409
[epoch7, step1599]: loss 1.385743
[epoch7, step1600]: loss 9.735609
[epoch7, step1601]: loss 2.247765
[epoch7, step1602]: loss 3.295557
[epoch7, step1603]: loss 5.289268
[epoch7, step1604]: loss 5.980595
[epoch7, step1605]: loss 8.253425
[epoch7, step1606]: loss 31.533871
[epoch7, step1607]: loss 2.768374
[epoch7, step1608]: loss 2.301143
[epoch7, step1609]: loss 5.444429
[epoch7, step1610]: loss 8.419651
[epoch7, step1611]: loss 2.287004
[epoch7, step1612]: loss 2.023098
[epoch7, step1613]: loss 15.673339
[epoch7, step1614]: loss 3.270397
[epoch7, step1615]: loss 1.569494
[epoch7, step1616]: loss 2.596607
[epoch7, step1617]: loss 2.228174
[epoch7, step1618]: loss 10.271375
[epoch7, step1619]: loss 6.922517
[epoch7, step1620]: loss 9.343062
[epoch7, step1621]: loss 1.469025
[epoch7, step1622]: loss 2.498159
[epoch7, step1623]: loss 15.093882
[epoch7, step1624]: loss 2.193912
[epoch7, step1625]: loss 1.116163
[epoch7, step1626]: loss 1.702911
[epoch7, step1627]: loss 5.182114
[epoch7, step1628]: loss 5.578290
[epoch7, step1629]: loss 19.896942
[epoch7, step1630]: loss 4.418960
[epoch7, step1631]: loss 6.023504
[epoch7, step1632]: loss 2.177901
[epoch7, step1633]: loss 6.279884
[epoch7, step1634]: loss 13.599517
[epoch7, step1635]: loss 7.208375
[epoch7, step1636]: loss 6.413628
[epoch7, step1637]: loss 30.683601
[epoch7, step1638]: loss 5.284782
[epoch7, step1639]: loss 4.250758
[epoch7, step1640]: loss 3.713187
[epoch7, step1641]: loss 1.763613
[epoch7, step1642]: loss 1.787864
[epoch7, step1643]: loss 3.909314
[epoch7, step1644]: loss 3.151001
[epoch7, step1645]: loss 21.116356
[epoch7, step1646]: loss 7.740385
[epoch7, step1647]: loss 1.901340
[epoch7, step1648]: loss 1.320351
[epoch7, step1649]: loss 13.261275
[epoch7, step1650]: loss 1.977756
[epoch7, step1651]: loss 2.105886
[epoch7, step1652]: loss 22.282669
[epoch7, step1653]: loss 4.669604
[epoch7, step1654]: loss 5.479056
[epoch7, step1655]: loss 5.320609
[epoch7, step1656]: loss 6.087298
[epoch7, step1657]: loss 14.004612
[epoch7, step1658]: loss 4.594529
[epoch7, step1659]: loss 7.221120
[epoch7, step1660]: loss 20.704367
[epoch7, step1661]: loss 1.164800
[epoch7, step1662]: loss 9.431069
[epoch7, step1663]: loss 12.263339
[epoch7, step1664]: loss 1.386656
[epoch7, step1665]: loss 3.243367
[epoch7, step1666]: loss 5.626579
[epoch7, step1667]: loss 3.483309
[epoch7, step1668]: loss 4.937234
[epoch7, step1669]: loss 15.117446
[epoch7, step1670]: loss 6.138517
[epoch7, step1671]: loss 6.160804
[epoch7, step1672]: loss 3.394422
[epoch7, step1673]: loss 9.853283
[epoch7, step1674]: loss 6.150790
[epoch7, step1675]: loss 4.456807
[epoch7, step1676]: loss 3.111748
[epoch7, step1677]: loss 1.547268
[epoch7, step1678]: loss 10.982721
[epoch7, step1679]: loss 8.903296
[epoch7, step1680]: loss 9.766101
[epoch7, step1681]: loss 1.377268
[epoch7, step1682]: loss 1.697375
[epoch7, step1683]: loss 18.001703
[epoch7, step1684]: loss 7.726427
[epoch7, step1685]: loss 4.831655
[epoch7, step1686]: loss 14.319107
[epoch7, step1687]: loss 2.470309
[epoch7, step1688]: loss 2.637483
[epoch7, step1689]: loss 1.313242
[epoch7, step1690]: loss 5.307374
[epoch7, step1691]: loss 9.931761
[epoch7, step1692]: loss 16.835369
[epoch7, step1693]: loss 9.862647
[epoch7, step1694]: loss 1.169394
[epoch7, step1695]: loss 14.715255
[epoch7, step1696]: loss 8.514675
[epoch7, step1697]: loss 1.636855
[epoch7, step1698]: loss 4.119907
[epoch7, step1699]: loss 2.407085
[epoch7, step1700]: loss 1.107325
[epoch7, step1701]: loss 16.011896
[epoch7, step1702]: loss 2.352453
[epoch7, step1703]: loss 11.569340
[epoch7, step1704]: loss 9.972862
[epoch7, step1705]: loss 10.941782
[epoch7, step1706]: loss 17.696661
[epoch7, step1707]: loss 5.441640
[epoch7, step1708]: loss 1.209605
[epoch7, step1709]: loss 5.956239
[epoch7, step1710]: loss 4.554257
[epoch7, step1711]: loss 9.362399
[epoch7, step1712]: loss 3.137144
[epoch7, step1713]: loss 1.480108
[epoch7, step1714]: loss 5.190070
[epoch7, step1715]: loss 10.067268
[epoch7, step1716]: loss 2.016013
[epoch7, step1717]: loss 2.712077
[epoch7, step1718]: loss 2.958039
[epoch7, step1719]: loss 6.923565
[epoch7, step1720]: loss 1.761395
[epoch7, step1721]: loss 16.933586
[epoch7, step1722]: loss 3.445114
[epoch7, step1723]: loss 2.259097
[epoch7, step1724]: loss 1.213797
[epoch7, step1725]: loss 4.611829
[epoch7, step1726]: loss 7.848189
[epoch7, step1727]: loss 17.504818
[epoch7, step1728]: loss 18.556520
[epoch7, step1729]: loss 18.351295
[epoch7, step1730]: loss 2.520512
[epoch7, step1731]: loss 12.330777
[epoch7, step1732]: loss 1.203376
[epoch7, step1733]: loss 2.850135
[epoch7, step1734]: loss 13.573601
[epoch7, step1735]: loss 4.205596
[epoch7, step1736]: loss 1.535169
[epoch7, step1737]: loss 5.985940
[epoch7, step1738]: loss 6.912125
[epoch7, step1739]: loss 13.979120
[epoch7, step1740]: loss 2.685676
[epoch7, step1741]: loss 20.207468
[epoch7, step1742]: loss 3.763180
[epoch7, step1743]: loss 13.939500
[epoch7, step1744]: loss 10.221678
[epoch7, step1745]: loss 3.141169
[epoch7, step1746]: loss 5.550998
[epoch7, step1747]: loss 8.640457
[epoch7, step1748]: loss 5.722321
[epoch7, step1749]: loss 2.273350
[epoch7, step1750]: loss 9.337976
[epoch7, step1751]: loss 1.687236
[epoch7, step1752]: loss 7.201473
[epoch7, step1753]: loss 14.271992
[epoch7, step1754]: loss 2.792149
[epoch7, step1755]: loss 1.846479
[epoch7, step1756]: loss 11.773707
[epoch7, step1757]: loss 1.688178
[epoch7, step1758]: loss 18.320990
[epoch7, step1759]: loss 11.493366
[epoch7, step1760]: loss 4.587941
[epoch7, step1761]: loss 1.900425
[epoch7, step1762]: loss 1.926927
[epoch7, step1763]: loss 1.467376
[epoch7, step1764]: loss 2.434071
[epoch7, step1765]: loss 5.954399
[epoch7, step1766]: loss 2.295484
[epoch7, step1767]: loss 20.205536
[epoch7, step1768]: loss 8.678507
[epoch7, step1769]: loss 15.963032
[epoch7, step1770]: loss 8.113832
[epoch7, step1771]: loss 2.449727
[epoch7, step1772]: loss 25.650841
[epoch7, step1773]: loss 3.628921
[epoch7, step1774]: loss 6.252566
[epoch7, step1775]: loss 1.516624
[epoch7, step1776]: loss 1.102978
[epoch7, step1777]: loss 9.991134
[epoch7, step1778]: loss 7.024970
[epoch7, step1779]: loss 3.534048
[epoch7, step1780]: loss 4.640996
[epoch7, step1781]: loss 2.116497
[epoch7, step1782]: loss 10.068326
[epoch7, step1783]: loss 9.892550
[epoch7, step1784]: loss 2.007078
[epoch7, step1785]: loss 18.329788
[epoch7, step1786]: loss 2.515214
[epoch7, step1787]: loss 1.496181
[epoch7, step1788]: loss 6.846285
[epoch7, step1789]: loss 1.548432
[epoch7, step1790]: loss 1.307002
[epoch7, step1791]: loss 24.341375
[epoch7, step1792]: loss 6.642442
[epoch7, step1793]: loss 20.297384
[epoch7, step1794]: loss 8.090755
[epoch7, step1795]: loss 9.950734
[epoch7, step1796]: loss 10.391955
[epoch7, step1797]: loss 17.339603
[epoch7, step1798]: loss 32.038353
[epoch7, step1799]: loss 7.405168
[epoch7, step1800]: loss 22.184032
[epoch7, step1801]: loss 3.092022
[epoch7, step1802]: loss 4.883143
[epoch7, step1803]: loss 7.427751
[epoch7, step1804]: loss 1.254277
[epoch7, step1805]: loss 1.305987
[epoch7, step1806]: loss 1.777550
[epoch7, step1807]: loss 1.873978
[epoch7, step1808]: loss 1.964814
[epoch7, step1809]: loss 12.485976
[epoch7, step1810]: loss 9.219726
[epoch7, step1811]: loss 4.155923
[epoch7, step1812]: loss 10.043956
[epoch7, step1813]: loss 6.690120
[epoch7, step1814]: loss 9.161468
[epoch7, step1815]: loss 17.069210
[epoch7, step1816]: loss 9.588569
[epoch7, step1817]: loss 7.157807
[epoch7, step1818]: loss 2.446214
[epoch7, step1819]: loss 9.041838
[epoch7, step1820]: loss 9.912151
[epoch7, step1821]: loss 1.512631
[epoch7, step1822]: loss 10.293390
[epoch7, step1823]: loss 1.837188
[epoch7, step1824]: loss 5.082028
[epoch7, step1825]: loss 6.137919
[epoch7, step1826]: loss 5.556904
[epoch7, step1827]: loss 12.258677
[epoch7, step1828]: loss 8.459682
[epoch7, step1829]: loss 4.399886
[epoch7, step1830]: loss 15.064227
[epoch7, step1831]: loss 6.257318
[epoch7, step1832]: loss 10.983142
[epoch7, step1833]: loss 10.569436
[epoch7, step1834]: loss 9.850061
[epoch7, step1835]: loss 3.662846
[epoch7, step1836]: loss 2.775104
[epoch7, step1837]: loss 1.723498
[epoch7, step1838]: loss 1.994787
[epoch7, step1839]: loss 1.831390
[epoch7, step1840]: loss 1.404750
[epoch7, step1841]: loss 1.544921
[epoch7, step1842]: loss 12.839261
[epoch7, step1843]: loss 1.754038
[epoch7, step1844]: loss 1.282389
[epoch7, step1845]: loss 2.974788
[epoch7, step1846]: loss 22.566923
[epoch7, step1847]: loss 4.682395
[epoch7, step1848]: loss 13.956208
[epoch7, step1849]: loss 29.391462
[epoch7, step1850]: loss 5.389819
[epoch7, step1851]: loss 2.911221
[epoch7, step1852]: loss 10.668294
[epoch7, step1853]: loss 1.446787
[epoch7, step1854]: loss 1.286736
[epoch7, step1855]: loss 0.900245
[epoch7, step1856]: loss 11.969795
[epoch7, step1857]: loss 22.313587
[epoch7, step1858]: loss 12.019692
[epoch7, step1859]: loss 1.542417
[epoch7, step1860]: loss 2.175619
[epoch7, step1861]: loss 8.812284
[epoch7, step1862]: loss 1.972431
[epoch7, step1863]: loss 2.498796
[epoch7, step1864]: loss 8.172780
[epoch7, step1865]: loss 3.832206
[epoch7, step1866]: loss 2.003454
[epoch7, step1867]: loss 4.759606
[epoch7, step1868]: loss 1.520063
[epoch7, step1869]: loss 3.635181
[epoch7, step1870]: loss 1.505933
[epoch7, step1871]: loss 9.088689
[epoch7, step1872]: loss 1.856102
[epoch7, step1873]: loss 5.806830
[epoch7, step1874]: loss 2.048503
[epoch7, step1875]: loss 2.404438
[epoch7, step1876]: loss 2.297954
[epoch7, step1877]: loss 5.219897
[epoch7, step1878]: loss 14.861837
[epoch7, step1879]: loss 1.992010
[epoch7, step1880]: loss 3.389358
[epoch7, step1881]: loss 1.798751
[epoch7, step1882]: loss 8.014215
[epoch7, step1883]: loss 1.364499
[epoch7, step1884]: loss 5.613731
[epoch7, step1885]: loss 1.589010
[epoch7, step1886]: loss 3.018578
[epoch7, step1887]: loss 2.959748
[epoch7, step1888]: loss 1.691740
[epoch7, step1889]: loss 1.986798
[epoch7, step1890]: loss 2.981590
[epoch7, step1891]: loss 2.123002
[epoch7, step1892]: loss 1.584979
[epoch7, step1893]: loss 5.587543
[epoch7, step1894]: loss 4.098625
[epoch7, step1895]: loss 2.882051
[epoch7, step1896]: loss 12.858565
[epoch7, step1897]: loss 21.890762
[epoch7, step1898]: loss 3.159106
[epoch7, step1899]: loss 2.912801
[epoch7, step1900]: loss 14.649552
[epoch7, step1901]: loss 2.209946
[epoch7, step1902]: loss 21.013475
[epoch7, step1903]: loss 1.454114
[epoch7, step1904]: loss 4.145504
[epoch7, step1905]: loss 2.661214
[epoch7, step1906]: loss 15.623028
[epoch7, step1907]: loss 7.628149
[epoch7, step1908]: loss 13.557375
[epoch7, step1909]: loss 2.063415
[epoch7, step1910]: loss 2.722649
[epoch7, step1911]: loss 1.726273
[epoch7, step1912]: loss 2.308413
[epoch7, step1913]: loss 4.637835
[epoch7, step1914]: loss 2.233124
[epoch7, step1915]: loss 4.849533
[epoch7, step1916]: loss 1.274675
[epoch7, step1917]: loss 1.294167
[epoch7, step1918]: loss 5.690975
[epoch7, step1919]: loss 19.357956
[epoch7, step1920]: loss 4.484660
[epoch7, step1921]: loss 2.153302
[epoch7, step1922]: loss 1.829764
[epoch7, step1923]: loss 9.204885
[epoch7, step1924]: loss 4.194404
[epoch7, step1925]: loss 14.121805
[epoch7, step1926]: loss 2.231410
[epoch7, step1927]: loss 1.163976
[epoch7, step1928]: loss 7.943337
[epoch7, step1929]: loss 1.931337
[epoch7, step1930]: loss 1.713712
[epoch7, step1931]: loss 2.464498
[epoch7, step1932]: loss 13.963169
[epoch7, step1933]: loss 4.033688
[epoch7, step1934]: loss 13.930315
[epoch7, step1935]: loss 1.880064
[epoch7, step1936]: loss 1.346849
[epoch7, step1937]: loss 2.455938
[epoch7, step1938]: loss 5.910493
[epoch7, step1939]: loss 1.177738
[epoch7, step1940]: loss 4.620918
[epoch7, step1941]: loss 1.165918
[epoch7, step1942]: loss 5.670256
[epoch7, step1943]: loss 8.443673
[epoch7, step1944]: loss 3.395016
[epoch7, step1945]: loss 4.739023
[epoch7, step1946]: loss 10.200863
[epoch7, step1947]: loss 5.354071
[epoch7, step1948]: loss 1.221696
[epoch7, step1949]: loss 11.721498
[epoch7, step1950]: loss 1.184933
[epoch7, step1951]: loss 8.575620
[epoch7, step1952]: loss 3.198288
[epoch7, step1953]: loss 1.804117
[epoch7, step1954]: loss 1.909950
[epoch7, step1955]: loss 9.091434
[epoch7, step1956]: loss 6.726671
[epoch7, step1957]: loss 15.086922
[epoch7, step1958]: loss 16.248455
[epoch7, step1959]: loss 2.762909
[epoch7, step1960]: loss 2.157301
[epoch7, step1961]: loss 1.564715
[epoch7, step1962]: loss 12.573153
[epoch7, step1963]: loss 1.183209
[epoch7, step1964]: loss 12.176688
[epoch7, step1965]: loss 2.155659
[epoch7, step1966]: loss 5.532253
[epoch7, step1967]: loss 4.983058
[epoch7, step1968]: loss 7.421209
[epoch7, step1969]: loss 4.223140
[epoch7, step1970]: loss 21.775410
[epoch7, step1971]: loss 1.033339
[epoch7, step1972]: loss 5.322690
[epoch7, step1973]: loss 4.535206
[epoch7, step1974]: loss 12.239599
[epoch7, step1975]: loss 3.342257
[epoch7, step1976]: loss 3.155981
[epoch7, step1977]: loss 19.548342
[epoch7, step1978]: loss 12.211264
[epoch7, step1979]: loss 13.269116
[epoch7, step1980]: loss 5.170681
[epoch7, step1981]: loss 2.213088
[epoch7, step1982]: loss 1.534999
[epoch7, step1983]: loss 3.012322
[epoch7, step1984]: loss 1.178522
[epoch7, step1985]: loss 10.074951
[epoch7, step1986]: loss 1.825731
[epoch7, step1987]: loss 13.677168
[epoch7, step1988]: loss 1.112993
[epoch7, step1989]: loss 8.334311
[epoch7, step1990]: loss 1.596760
[epoch7, step1991]: loss 1.785429
[epoch7, step1992]: loss 1.953419
[epoch7, step1993]: loss 1.771165
[epoch7, step1994]: loss 12.323037
[epoch7, step1995]: loss 24.029715
[epoch7, step1996]: loss 1.373498
[epoch7, step1997]: loss 3.980161
[epoch7, step1998]: loss 12.386847
[epoch7, step1999]: loss 10.405781
[epoch7, step2000]: loss 1.836135
[epoch7, step2001]: loss 8.240813
[epoch7, step2002]: loss 7.314745
[epoch7, step2003]: loss 1.339328
[epoch7, step2004]: loss 2.062992
[epoch7, step2005]: loss 10.905663
[epoch7, step2006]: loss 10.633244
[epoch7, step2007]: loss 5.575925
[epoch7, step2008]: loss 8.320071
[epoch7, step2009]: loss 14.874159
[epoch7, step2010]: loss 3.120215
[epoch7, step2011]: loss 19.429840
[epoch7, step2012]: loss 1.576966
[epoch7, step2013]: loss 7.688858
[epoch7, step2014]: loss 6.333497
[epoch7, step2015]: loss 9.421315
[epoch7, step2016]: loss 16.177195
[epoch7, step2017]: loss 7.460639
[epoch7, step2018]: loss 8.174501
[epoch7, step2019]: loss 3.253165
[epoch7, step2020]: loss 2.434262
[epoch7, step2021]: loss 17.089237
[epoch7, step2022]: loss 13.580089
[epoch7, step2023]: loss 1.534111
[epoch7, step2024]: loss 9.498093
[epoch7, step2025]: loss 1.078301
[epoch7, step2026]: loss 2.674632
[epoch7, step2027]: loss 4.917016
[epoch7, step2028]: loss 2.203862
[epoch7, step2029]: loss 2.248900
[epoch7, step2030]: loss 1.754785
[epoch7, step2031]: loss 14.055321
[epoch7, step2032]: loss 5.363090
[epoch7, step2033]: loss 9.289574
[epoch7, step2034]: loss 2.922414
[epoch7, step2035]: loss 1.615455
[epoch7, step2036]: loss 1.709234
[epoch7, step2037]: loss 4.523931
[epoch7, step2038]: loss 12.801284
[epoch7, step2039]: loss 11.807256
[epoch7, step2040]: loss 8.721332
[epoch7, step2041]: loss 1.179635
[epoch7, step2042]: loss 5.073739
[epoch7, step2043]: loss 1.743858
[epoch7, step2044]: loss 2.367096
[epoch7, step2045]: loss 15.466682
[epoch7, step2046]: loss 8.948284
[epoch7, step2047]: loss 1.860705
[epoch7, step2048]: loss 2.116718
[epoch7, step2049]: loss 4.360309
[epoch7, step2050]: loss 4.320472
[epoch7, step2051]: loss 5.281250
[epoch7, step2052]: loss 5.254635
[epoch7, step2053]: loss 2.425760
[epoch7, step2054]: loss 6.405162
[epoch7, step2055]: loss 16.784004
[epoch7, step2056]: loss 22.050629
[epoch7, step2057]: loss 4.396977
[epoch7, step2058]: loss 16.498041
[epoch7, step2059]: loss 2.195684
[epoch7, step2060]: loss 17.209715
[epoch7, step2061]: loss 18.845518
[epoch7, step2062]: loss 1.464555
[epoch7, step2063]: loss 3.275463
[epoch7, step2064]: loss 11.548320
[epoch7, step2065]: loss 1.464376
[epoch7, step2066]: loss 1.604094
[epoch7, step2067]: loss 5.168671
[epoch7, step2068]: loss 8.084490
[epoch7, step2069]: loss 2.051317
[epoch7, step2070]: loss 13.392401
[epoch7, step2071]: loss 2.706029
[epoch7, step2072]: loss 6.788470
[epoch7, step2073]: loss 1.358060
[epoch7, step2074]: loss 2.537462
[epoch7, step2075]: loss 2.698385
[epoch7, step2076]: loss 13.290694
[epoch7, step2077]: loss 9.378934
[epoch7, step2078]: loss 16.936142
[epoch7, step2079]: loss 2.713842
[epoch7, step2080]: loss 8.360751
[epoch7, step2081]: loss 3.692623
[epoch7, step2082]: loss 1.010232
[epoch7, step2083]: loss 2.125990
[epoch7, step2084]: loss 1.564593
[epoch7, step2085]: loss 15.429440
[epoch7, step2086]: loss 1.649657
[epoch7, step2087]: loss 10.194502
[epoch7, step2088]: loss 7.709358
[epoch7, step2089]: loss 3.093767
[epoch7, step2090]: loss 8.811028
[epoch7, step2091]: loss 5.270483
[epoch7, step2092]: loss 3.835470
[epoch7, step2093]: loss 4.434356
[epoch7, step2094]: loss 2.528341
[epoch7, step2095]: loss 1.799853
[epoch7, step2096]: loss 7.758773
[epoch7, step2097]: loss 3.763755
[epoch7, step2098]: loss 3.975602
[epoch7, step2099]: loss 6.862348
[epoch7, step2100]: loss 8.653069
[epoch7, step2101]: loss 4.455160
[epoch7, step2102]: loss 1.246043
[epoch7, step2103]: loss 2.590771
[epoch7, step2104]: loss 5.197348
[epoch7, step2105]: loss 1.473568
[epoch7, step2106]: loss 2.871638
[epoch7, step2107]: loss 7.680231
[epoch7, step2108]: loss 2.482895
[epoch7, step2109]: loss 1.431692
[epoch7, step2110]: loss 5.257402
[epoch7, step2111]: loss 3.401915
[epoch7, step2112]: loss 9.314481
[epoch7, step2113]: loss 25.382215
[epoch7, step2114]: loss 2.670478
[epoch7, step2115]: loss 2.749913
[epoch7, step2116]: loss 2.136736
[epoch7, step2117]: loss 5.977255
[epoch7, step2118]: loss 4.947202
[epoch7, step2119]: loss 8.996474
[epoch7, step2120]: loss 1.047700
[epoch7, step2121]: loss 9.312933
[epoch7, step2122]: loss 15.934480
[epoch7, step2123]: loss 10.658230
[epoch7, step2124]: loss 5.894365
[epoch7, step2125]: loss 20.479734
[epoch7, step2126]: loss 1.304885
[epoch7, step2127]: loss 9.987363
[epoch7, step2128]: loss 1.216272
[epoch7, step2129]: loss 25.918573
[epoch7, step2130]: loss 12.983438
[epoch7, step2131]: loss 6.375189
[epoch7, step2132]: loss 23.467796
[epoch7, step2133]: loss 0.968862
[epoch7, step2134]: loss 9.390256
[epoch7, step2135]: loss 1.616640
[epoch7, step2136]: loss 11.939753
[epoch7, step2137]: loss 22.928646
[epoch7, step2138]: loss 3.513482
[epoch7, step2139]: loss 11.367030
[epoch7, step2140]: loss 13.172305
[epoch7, step2141]: loss 1.183933
[epoch7, step2142]: loss 17.841688
[epoch7, step2143]: loss 2.538885
[epoch7, step2144]: loss 5.687088
[epoch7, step2145]: loss 15.362947
[epoch7, step2146]: loss 2.099195
[epoch7, step2147]: loss 10.490611
[epoch7, step2148]: loss 9.127812
[epoch7, step2149]: loss 2.651955
[epoch7, step2150]: loss 4.764513
[epoch7, step2151]: loss 19.046444
[epoch7, step2152]: loss 7.900309
[epoch7, step2153]: loss 1.759259
[epoch7, step2154]: loss 1.807050
[epoch7, step2155]: loss 11.006728
[epoch7, step2156]: loss 7.390293
[epoch7, step2157]: loss 14.338268
[epoch7, step2158]: loss 5.807217
[epoch7, step2159]: loss 11.002780
[epoch7, step2160]: loss 1.066294
[epoch7, step2161]: loss 10.385753
[epoch7, step2162]: loss 24.763027
[epoch7, step2163]: loss 6.756895
[epoch7, step2164]: loss 21.793564
[epoch7, step2165]: loss 5.888383
[epoch7, step2166]: loss 2.101801
[epoch7, step2167]: loss 2.785291
[epoch7, step2168]: loss 6.252223
[epoch7, step2169]: loss 1.813368
[epoch7, step2170]: loss 9.339038
[epoch7, step2171]: loss 11.871967
[epoch7, step2172]: loss 2.147125
[epoch7, step2173]: loss 10.574414
[epoch7, step2174]: loss 8.519363
[epoch7, step2175]: loss 1.522584
[epoch7, step2176]: loss 5.330392
[epoch7, step2177]: loss 20.839573
[epoch7, step2178]: loss 4.875480
[epoch7, step2179]: loss 4.106183
[epoch7, step2180]: loss 1.761819
[epoch7, step2181]: loss 5.241492
[epoch7, step2182]: loss 1.519821
[epoch7, step2183]: loss 17.375084
[epoch7, step2184]: loss 3.201250
[epoch7, step2185]: loss 11.075563
[epoch7, step2186]: loss 1.681327
[epoch7, step2187]: loss 4.109262
[epoch7, step2188]: loss 12.721231
[epoch7, step2189]: loss 1.654720
[epoch7, step2190]: loss 5.112245
[epoch7, step2191]: loss 4.519441
[epoch7, step2192]: loss 9.823414
[epoch7, step2193]: loss 16.812798
[epoch7, step2194]: loss 29.231190
[epoch7, step2195]: loss 15.450439
[epoch7, step2196]: loss 2.852405
[epoch7, step2197]: loss 2.648001
[epoch7, step2198]: loss 9.875947
[epoch7, step2199]: loss 5.972965
[epoch7, step2200]: loss 1.776039
[epoch7, step2201]: loss 8.034929
[epoch7, step2202]: loss 2.770155
[epoch7, step2203]: loss 8.273816
[epoch7, step2204]: loss 6.874830
[epoch7, step2205]: loss 3.343707
[epoch7, step2206]: loss 13.123638
[epoch7, step2207]: loss 4.535339
[epoch7, step2208]: loss 1.601640
[epoch7, step2209]: loss 1.239604
[epoch7, step2210]: loss 3.418545
[epoch7, step2211]: loss 1.431579
[epoch7, step2212]: loss 1.661831
[epoch7, step2213]: loss 6.310822
[epoch7, step2214]: loss 13.120386
[epoch7, step2215]: loss 8.125759
[epoch7, step2216]: loss 1.601060
[epoch7, step2217]: loss 1.780648
[epoch7, step2218]: loss 37.540184
[epoch7, step2219]: loss 3.093524
[epoch7, step2220]: loss 1.686739
[epoch7, step2221]: loss 0.786612
[epoch7, step2222]: loss 1.644303
[epoch7, step2223]: loss 8.285242
[epoch7, step2224]: loss 4.285655
[epoch7, step2225]: loss 5.948160
[epoch7, step2226]: loss 14.060688
[epoch7, step2227]: loss 9.559069
[epoch7, step2228]: loss 1.413934
[epoch7, step2229]: loss 21.349432
[epoch7, step2230]: loss 4.219545
[epoch7, step2231]: loss 2.235502
[epoch7, step2232]: loss 5.155366
[epoch7, step2233]: loss 6.967927
[epoch7, step2234]: loss 13.581762
[epoch7, step2235]: loss 1.161721
[epoch7, step2236]: loss 5.169487
[epoch7, step2237]: loss 11.182390
[epoch7, step2238]: loss 12.234700
[epoch7, step2239]: loss 4.917074
[epoch7, step2240]: loss 2.350365
[epoch7, step2241]: loss 1.311228
[epoch7, step2242]: loss 0.753396
[epoch7, step2243]: loss 9.211703
[epoch7, step2244]: loss 11.996226
[epoch7, step2245]: loss 3.981022
[epoch7, step2246]: loss 1.871558
[epoch7, step2247]: loss 10.973566
[epoch7, step2248]: loss 1.484326
[epoch7, step2249]: loss 4.096701
[epoch7, step2250]: loss 11.875335
[epoch7, step2251]: loss 1.174905
[epoch7, step2252]: loss 3.859243
[epoch7, step2253]: loss 16.184057
[epoch7, step2254]: loss 3.213007
[epoch7, step2255]: loss 12.638345
[epoch7, step2256]: loss 2.356608
[epoch7, step2257]: loss 15.968359
[epoch7, step2258]: loss 6.249566
[epoch7, step2259]: loss 15.172737
[epoch7, step2260]: loss 2.041013
[epoch7, step2261]: loss 9.144623
[epoch7, step2262]: loss 3.936356
[epoch7, step2263]: loss 5.901374
[epoch7, step2264]: loss 1.128807
[epoch7, step2265]: loss 17.484476
[epoch7, step2266]: loss 5.631128
[epoch7, step2267]: loss 13.373073
[epoch7, step2268]: loss 6.292257
[epoch7, step2269]: loss 21.179213
[epoch7, step2270]: loss 14.635247
[epoch7, step2271]: loss 0.840509
[epoch7, step2272]: loss 8.202427
[epoch7, step2273]: loss 2.254234
[epoch7, step2274]: loss 9.587996
[epoch7, step2275]: loss 11.626721
[epoch7, step2276]: loss 14.607289
[epoch7, step2277]: loss 10.944591
[epoch7, step2278]: loss 2.280188
[epoch7, step2279]: loss 2.008859
[epoch7, step2280]: loss 2.702396
[epoch7, step2281]: loss 2.109335
[epoch7, step2282]: loss 1.750767
[epoch7, step2283]: loss 11.304877
[epoch7, step2284]: loss 2.482201
[epoch7, step2285]: loss 8.018324
[epoch7, step2286]: loss 1.223877
[epoch7, step2287]: loss 12.792273
[epoch7, step2288]: loss 17.544523
[epoch7, step2289]: loss 21.565134
[epoch7, step2290]: loss 2.302285
[epoch7, step2291]: loss 4.192221
[epoch7, step2292]: loss 3.814777
[epoch7, step2293]: loss 1.940085
[epoch7, step2294]: loss 2.915944
[epoch7, step2295]: loss 10.928531
[epoch7, step2296]: loss 2.010085
[epoch7, step2297]: loss 15.271491
[epoch7, step2298]: loss 2.398244
[epoch7, step2299]: loss 8.350063
[epoch7, step2300]: loss 4.471877
[epoch7, step2301]: loss 9.191588
[epoch7, step2302]: loss 8.338557
[epoch7, step2303]: loss 17.971279
[epoch7, step2304]: loss 0.960965
[epoch7, step2305]: loss 8.093581
[epoch7, step2306]: loss 6.629192
[epoch7, step2307]: loss 18.632015
[epoch7, step2308]: loss 20.644432
[epoch7, step2309]: loss 16.971363
[epoch7, step2310]: loss 4.471120
[epoch7, step2311]: loss 7.691015
[epoch7, step2312]: loss 1.962180
[epoch7, step2313]: loss 2.943113
[epoch7, step2314]: loss 11.378847
[epoch7, step2315]: loss 1.738157
[epoch7, step2316]: loss 5.914071
[epoch7, step2317]: loss 2.721100
[epoch7, step2318]: loss 2.216215
[epoch7, step2319]: loss 2.112365
[epoch7, step2320]: loss 3.306534
[epoch7, step2321]: loss 4.425925
[epoch7, step2322]: loss 14.477759
[epoch7, step2323]: loss 7.356153
[epoch7, step2324]: loss 1.572111
[epoch7, step2325]: loss 2.118028
[epoch7, step2326]: loss 5.222395
[epoch7, step2327]: loss 10.669042
[epoch7, step2328]: loss 1.409251
[epoch7, step2329]: loss 4.776039
[epoch7, step2330]: loss 2.784989
[epoch7, step2331]: loss 1.481031
[epoch7, step2332]: loss 19.989866
[epoch7, step2333]: loss 8.197507
[epoch7, step2334]: loss 2.449556
[epoch7, step2335]: loss 3.652101
[epoch7, step2336]: loss 1.268290
[epoch7, step2337]: loss 15.617419
[epoch7, step2338]: loss 1.218762
[epoch7, step2339]: loss 2.774447
[epoch7, step2340]: loss 3.293712
[epoch7, step2341]: loss 4.588697
[epoch7, step2342]: loss 8.870427
[epoch7, step2343]: loss 1.722748
[epoch7, step2344]: loss 10.648068
[epoch7, step2345]: loss 2.484111
[epoch7, step2346]: loss 7.005624
[epoch7, step2347]: loss 18.619461
[epoch7, step2348]: loss 4.191752
[epoch7, step2349]: loss 2.469184
[epoch7, step2350]: loss 5.273367
[epoch7, step2351]: loss 1.341417
[epoch7, step2352]: loss 1.158245
[epoch7, step2353]: loss 9.813161
[epoch7, step2354]: loss 1.279487
[epoch7, step2355]: loss 1.226148
[epoch7, step2356]: loss 13.759706
[epoch7, step2357]: loss 3.354863
[epoch7, step2358]: loss 19.598574
[epoch7, step2359]: loss 19.427500
[epoch7, step2360]: loss 4.447579
[epoch7, step2361]: loss 2.960254
[epoch7, step2362]: loss 1.949708
[epoch7, step2363]: loss 1.300220
[epoch7, step2364]: loss 22.426449
[epoch7, step2365]: loss 1.199088
[epoch7, step2366]: loss 6.994586
[epoch7, step2367]: loss 7.749072
[epoch7, step2368]: loss 17.963068
[epoch7, step2369]: loss 4.983832
[epoch7, step2370]: loss 1.268299
[epoch7, step2371]: loss 1.481153
[epoch7, step2372]: loss 2.283276
[epoch7, step2373]: loss 10.227280
[epoch7, step2374]: loss 16.453638
[epoch7, step2375]: loss 15.478761
[epoch7, step2376]: loss 13.227359
[epoch7, step2377]: loss 14.482334
[epoch7, step2378]: loss 25.348011
[epoch7, step2379]: loss 1.629852
[epoch7, step2380]: loss 22.534973
[epoch7, step2381]: loss 1.832978
[epoch7, step2382]: loss 3.692712
[epoch7, step2383]: loss 8.136401
[epoch7, step2384]: loss 2.750509
[epoch7, step2385]: loss 2.654337
[epoch7, step2386]: loss 20.346123
[epoch7, step2387]: loss 1.007982
[epoch7, step2388]: loss 0.966358
[epoch7, step2389]: loss 1.827411
[epoch7, step2390]: loss 9.491632
[epoch7, step2391]: loss 10.290867
[epoch7, step2392]: loss 12.133026
[epoch7, step2393]: loss 15.423987
[epoch7, step2394]: loss 10.285074
[epoch7, step2395]: loss 11.965905
[epoch7, step2396]: loss 3.262271
[epoch7, step2397]: loss 6.568088
[epoch7, step2398]: loss 1.834476
[epoch7, step2399]: loss 3.319008
[epoch7, step2400]: loss 1.477057
[epoch7, step2401]: loss 2.799608
[epoch7, step2402]: loss 1.372294
[epoch7, step2403]: loss 1.382107
[epoch7, step2404]: loss 6.493598
[epoch7, step2405]: loss 1.835970
[epoch7, step2406]: loss 3.973495
[epoch7, step2407]: loss 1.612390
[epoch7, step2408]: loss 5.495221
[epoch7, step2409]: loss 2.605285
[epoch7, step2410]: loss 2.324998
[epoch7, step2411]: loss 8.975063
[epoch7, step2412]: loss 5.600741
[epoch7, step2413]: loss 8.102301
[epoch7, step2414]: loss 1.701396
[epoch7, step2415]: loss 1.601187
[epoch7, step2416]: loss 1.221690
[epoch7, step2417]: loss 4.536486
[epoch7, step2418]: loss 2.058164
[epoch7, step2419]: loss 1.904509
[epoch7, step2420]: loss 15.366319
[epoch7, step2421]: loss 14.081862
[epoch7, step2422]: loss 3.430419
[epoch7, step2423]: loss 2.226688
[epoch7, step2424]: loss 2.063789
[epoch7, step2425]: loss 1.851003
[epoch7, step2426]: loss 5.817948
[epoch7, step2427]: loss 10.947867
[epoch7, step2428]: loss 14.081242
[epoch7, step2429]: loss 1.395971
[epoch7, step2430]: loss 10.483413
[epoch7, step2431]: loss 6.753273
[epoch7, step2432]: loss 3.541445
[epoch7, step2433]: loss 1.867375
[epoch7, step2434]: loss 9.946317
[epoch7, step2435]: loss 16.310278
[epoch7, step2436]: loss 1.003428
[epoch7, step2437]: loss 2.260371
[epoch7, step2438]: loss 7.288175
[epoch7, step2439]: loss 14.608700
[epoch7, step2440]: loss 10.335579
[epoch7, step2441]: loss 9.050910
[epoch7, step2442]: loss 3.028158
[epoch7, step2443]: loss 4.793122
[epoch7, step2444]: loss 1.889704
[epoch7, step2445]: loss 2.631797
[epoch7, step2446]: loss 1.992761
[epoch7, step2447]: loss 1.878495
[epoch7, step2448]: loss 8.411687
[epoch7, step2449]: loss 8.573249
[epoch7, step2450]: loss 8.802894
[epoch7, step2451]: loss 5.164918
[epoch7, step2452]: loss 2.045007
[epoch7, step2453]: loss 6.140887
[epoch7, step2454]: loss 1.258047
[epoch7, step2455]: loss 4.813712
[epoch7, step2456]: loss 1.944511
[epoch7, step2457]: loss 15.168678
[epoch7, step2458]: loss 4.091410
[epoch7, step2459]: loss 15.607494
[epoch7, step2460]: loss 1.800921
[epoch7, step2461]: loss 1.608797
[epoch7, step2462]: loss 12.117569
[epoch7, step2463]: loss 8.791771
[epoch7, step2464]: loss 14.631635
[epoch7, step2465]: loss 1.053204
[epoch7, step2466]: loss 1.501321
[epoch7, step2467]: loss 1.163444
[epoch7, step2468]: loss 2.502804
[epoch7, step2469]: loss 18.532253
[epoch7, step2470]: loss 14.319880
[epoch7, step2471]: loss 2.182192
[epoch7, step2472]: loss 2.199001
[epoch7, step2473]: loss 2.008581
[epoch7, step2474]: loss 5.975126
[epoch7, step2475]: loss 8.426542
[epoch7, step2476]: loss 4.370228
[epoch7, step2477]: loss 15.666240
[epoch7, step2478]: loss 4.285512
[epoch7, step2479]: loss 5.028878
[epoch7, step2480]: loss 12.560549
[epoch7, step2481]: loss 2.651259
[epoch7, step2482]: loss 15.950490
[epoch7, step2483]: loss 9.410585
[epoch7, step2484]: loss 2.253447
[epoch7, step2485]: loss 4.011415
[epoch7, step2486]: loss 26.747845
[epoch7, step2487]: loss 6.915939
[epoch7, step2488]: loss 18.869898
[epoch7, step2489]: loss 3.102124
[epoch7, step2490]: loss 1.524001
[epoch7, step2491]: loss 1.397452
[epoch7, step2492]: loss 6.252199
[epoch7, step2493]: loss 1.872844
[epoch7, step2494]: loss 4.703436
[epoch7, step2495]: loss 11.992966
[epoch7, step2496]: loss 3.094416
[epoch7, step2497]: loss 2.577649
[epoch7, step2498]: loss 1.680845
[epoch7, step2499]: loss 5.083081
[epoch7, step2500]: loss 4.370430
[epoch7, step2501]: loss 35.148483
[epoch7, step2502]: loss 1.068190
[epoch7, step2503]: loss 7.191888
[epoch7, step2504]: loss 11.468527
[epoch7, step2505]: loss 11.118141
[epoch7, step2506]: loss 16.740992
[epoch7, step2507]: loss 2.455692
[epoch7, step2508]: loss 2.063980
[epoch7, step2509]: loss 2.970886
[epoch7, step2510]: loss 1.943460
[epoch7, step2511]: loss 4.528118
[epoch7, step2512]: loss 1.823384
[epoch7, step2513]: loss 2.085746
[epoch7, step2514]: loss 2.512866
[epoch7, step2515]: loss 2.447819
[epoch7, step2516]: loss 2.174471
[epoch7, step2517]: loss 5.071571
[epoch7, step2518]: loss 2.003342
[epoch7, step2519]: loss 1.176832
[epoch7, step2520]: loss 2.609350
[epoch7, step2521]: loss 5.437331
[epoch7, step2522]: loss 4.637400
[epoch7, step2523]: loss 13.361623
[epoch7, step2524]: loss 2.499422
[epoch7, step2525]: loss 8.227408
[epoch7, step2526]: loss 3.198027
[epoch7, step2527]: loss 2.396913
[epoch7, step2528]: loss 4.038464
[epoch7, step2529]: loss 5.058450
[epoch7, step2530]: loss 4.469003
[epoch7, step2531]: loss 42.875107
[epoch7, step2532]: loss 8.978297
[epoch7, step2533]: loss 7.678123
[epoch7, step2534]: loss 1.382244
[epoch7, step2535]: loss 5.517575
[epoch7, step2536]: loss 14.550076
[epoch7, step2537]: loss 1.946742
[epoch7, step2538]: loss 13.868861
[epoch7, step2539]: loss 7.737066
[epoch7, step2540]: loss 11.114835
[epoch7, step2541]: loss 1.640937
[epoch7, step2542]: loss 4.430635
[epoch7, step2543]: loss 4.774804
[epoch7, step2544]: loss 1.561401
[epoch7, step2545]: loss 5.625120
[epoch7, step2546]: loss 7.349825
[epoch7, step2547]: loss 13.728230
[epoch7, step2548]: loss 2.901440
[epoch7, step2549]: loss 1.836484
[epoch7, step2550]: loss 7.351672
[epoch7, step2551]: loss 14.599622
[epoch7, step2552]: loss 4.258008
[epoch7, step2553]: loss 2.520586
[epoch7, step2554]: loss 5.118349
[epoch7, step2555]: loss 1.453608
[epoch7, step2556]: loss 7.957624
[epoch7, step2557]: loss 9.972006
[epoch7, step2558]: loss 9.918219
[epoch7, step2559]: loss 2.657233
[epoch7, step2560]: loss 4.334522
[epoch7, step2561]: loss 12.505768
[epoch7, step2562]: loss 5.818779
[epoch7, step2563]: loss 5.268563
[epoch7, step2564]: loss 3.690282
[epoch7, step2565]: loss 1.923693
[epoch7, step2566]: loss 3.849662
[epoch7, step2567]: loss 1.170805
[epoch7, step2568]: loss 8.949081
[epoch7, step2569]: loss 4.697324
[epoch7, step2570]: loss 8.181974
[epoch7, step2571]: loss 1.953470
[epoch7, step2572]: loss 12.549688
[epoch7, step2573]: loss 13.918614
[epoch7, step2574]: loss 1.758945
[epoch7, step2575]: loss 2.548372
[epoch7, step2576]: loss 5.013133
[epoch7, step2577]: loss 8.193871
[epoch7, step2578]: loss 9.280850
[epoch7, step2579]: loss 4.118402
[epoch7, step2580]: loss 8.184254
[epoch7, step2581]: loss 2.308653
[epoch7, step2582]: loss 4.578499
[epoch7, step2583]: loss 3.190475
[epoch7, step2584]: loss 6.497423
[epoch7, step2585]: loss 2.983809
[epoch7, step2586]: loss 3.000494
[epoch7, step2587]: loss 0.808028
[epoch7, step2588]: loss 4.164779
[epoch7, step2589]: loss 2.343827
[epoch7, step2590]: loss 1.790917
[epoch7, step2591]: loss 4.809838
[epoch7, step2592]: loss 8.267951
[epoch7, step2593]: loss 3.916303
[epoch7, step2594]: loss 3.431245
[epoch7, step2595]: loss 1.238063
[epoch7, step2596]: loss 6.592810
[epoch7, step2597]: loss 13.543398
[epoch7, step2598]: loss 14.671675
[epoch7, step2599]: loss 1.220260
[epoch7, step2600]: loss 1.871647
[epoch7, step2601]: loss 3.575619
[epoch7, step2602]: loss 3.637883
[epoch7, step2603]: loss 21.387121
[epoch7, step2604]: loss 1.344258
[epoch7, step2605]: loss 2.076196
[epoch7, step2606]: loss 9.981051
[epoch7, step2607]: loss 10.282073
[epoch7, step2608]: loss 2.258605
[epoch7, step2609]: loss 1.118852
[epoch7, step2610]: loss 1.843414
[epoch7, step2611]: loss 1.196878
[epoch7, step2612]: loss 4.650601
[epoch7, step2613]: loss 0.933043
[epoch7, step2614]: loss 12.208918
[epoch7, step2615]: loss 15.698895
[epoch7, step2616]: loss 15.384904
[epoch7, step2617]: loss 14.656844
[epoch7, step2618]: loss 3.326971
[epoch7, step2619]: loss 1.411888
[epoch7, step2620]: loss 13.431187
[epoch7, step2621]: loss 9.537320
[epoch7, step2622]: loss 2.394992
[epoch7, step2623]: loss 5.250648
[epoch7, step2624]: loss 1.927836
[epoch7, step2625]: loss 4.871146
[epoch7, step2626]: loss 1.746502
[epoch7, step2627]: loss 2.486000
[epoch7, step2628]: loss 11.942426
[epoch7, step2629]: loss 2.646546
[epoch7, step2630]: loss 2.546100
[epoch7, step2631]: loss 12.934740
[epoch7, step2632]: loss 2.705492
[epoch7, step2633]: loss 5.973511
[epoch7, step2634]: loss 6.196545
[epoch7, step2635]: loss 5.481175
[epoch7, step2636]: loss 1.046961
[epoch7, step2637]: loss 2.260587
[epoch7, step2638]: loss 12.896279
[epoch7, step2639]: loss 11.940195
[epoch7, step2640]: loss 11.605182
[epoch7, step2641]: loss 18.486984
[epoch7, step2642]: loss 8.447681
[epoch7, step2643]: loss 2.863054
[epoch7, step2644]: loss 1.769550
[epoch7, step2645]: loss 1.779260
[epoch7, step2646]: loss 4.182665
[epoch7, step2647]: loss 15.994562
[epoch7, step2648]: loss 14.180685
[epoch7, step2649]: loss 1.886807
[epoch7, step2650]: loss 1.480723
[epoch7, step2651]: loss 4.635808
[epoch7, step2652]: loss 1.402931
[epoch7, step2653]: loss 1.695322
[epoch7, step2654]: loss 2.037300
[epoch7, step2655]: loss 6.263491
[epoch7, step2656]: loss 21.669584
[epoch7, step2657]: loss 12.911709
[epoch7, step2658]: loss 1.172159
[epoch7, step2659]: loss 1.680163
[epoch7, step2660]: loss 1.802931
[epoch7, step2661]: loss 5.769125
[epoch7, step2662]: loss 2.436444
[epoch7, step2663]: loss 1.653914
[epoch7, step2664]: loss 2.023087
[epoch7, step2665]: loss 3.649253
[epoch7, step2666]: loss 6.667080
[epoch7, step2667]: loss 7.920739
[epoch7, step2668]: loss 14.629416
[epoch7, step2669]: loss 1.058312
[epoch7, step2670]: loss 13.693060
[epoch7, step2671]: loss 14.418637
[epoch7, step2672]: loss 7.489139
[epoch7, step2673]: loss 1.761020
[epoch7, step2674]: loss 15.936698
[epoch7, step2675]: loss 11.641794
[epoch7, step2676]: loss 5.729361
[epoch7, step2677]: loss 7.369988
[epoch7, step2678]: loss 11.289639
[epoch7, step2679]: loss 1.473833
[epoch7, step2680]: loss 4.928181
[epoch7, step2681]: loss 2.483242
[epoch7, step2682]: loss 1.942458
[epoch7, step2683]: loss 7.155554
[epoch7, step2684]: loss 15.070971
[epoch7, step2685]: loss 1.359966
[epoch7, step2686]: loss 5.459729
[epoch7, step2687]: loss 14.491272
[epoch7, step2688]: loss 6.576466
[epoch7, step2689]: loss 22.866953
[epoch7, step2690]: loss 13.372301
[epoch7, step2691]: loss 4.439837
[epoch7, step2692]: loss 2.951429
[epoch7, step2693]: loss 18.174145
[epoch7, step2694]: loss 12.282688
[epoch7, step2695]: loss 1.091323
[epoch7, step2696]: loss 1.102018
[epoch7, step2697]: loss 8.122950
[epoch7, step2698]: loss 11.032760
[epoch7, step2699]: loss 1.673538
[epoch7, step2700]: loss 1.640954
[epoch7, step2701]: loss 2.505471
[epoch7, step2702]: loss 1.901656
[epoch7, step2703]: loss 2.399019
[epoch7, step2704]: loss 29.393373
[epoch7, step2705]: loss 14.558589
[epoch7, step2706]: loss 1.777489
[epoch7, step2707]: loss 3.706537
[epoch7, step2708]: loss 10.993437
[epoch7, step2709]: loss 1.128571
[epoch7, step2710]: loss 2.193313
[epoch7, step2711]: loss 2.974280
[epoch7, step2712]: loss 1.789991
[epoch7, step2713]: loss 4.772471
[epoch7, step2714]: loss 6.082018
[epoch7, step2715]: loss 2.809080
[epoch7, step2716]: loss 12.537436
[epoch7, step2717]: loss 1.426295
[epoch7, step2718]: loss 1.475761
[epoch7, step2719]: loss 1.256791
[epoch7, step2720]: loss 11.931377
[epoch7, step2721]: loss 1.768919
[epoch7, step2722]: loss 13.414038
[epoch7, step2723]: loss 12.461843
[epoch7, step2724]: loss 2.340596
[epoch7, step2725]: loss 3.210658
[epoch7, step2726]: loss 2.712437
[epoch7, step2727]: loss 4.482675
[epoch7, step2728]: loss 8.802154
[epoch7, step2729]: loss 9.317139
[epoch7, step2730]: loss 24.674627
[epoch7, step2731]: loss 1.229629
[epoch7, step2732]: loss 2.849219
[epoch7, step2733]: loss 1.508323
[epoch7, step2734]: loss 3.292422
[epoch7, step2735]: loss 24.133303
[epoch7, step2736]: loss 1.593893
[epoch7, step2737]: loss 1.282777
[epoch7, step2738]: loss 3.223403
[epoch7, step2739]: loss 5.597367
[epoch7, step2740]: loss 20.727478
[epoch7, step2741]: loss 9.969929
[epoch7, step2742]: loss 5.311237
[epoch7, step2743]: loss 6.982746
[epoch7, step2744]: loss 3.405863
[epoch7, step2745]: loss 8.138000
[epoch7, step2746]: loss 1.179686
[epoch7, step2747]: loss 4.426840
[epoch7, step2748]: loss 1.705228
[epoch7, step2749]: loss 11.371167
[epoch7, step2750]: loss 0.980634
[epoch7, step2751]: loss 6.311698
[epoch7, step2752]: loss 7.578956
[epoch7, step2753]: loss 2.904243
[epoch7, step2754]: loss 3.080484
[epoch7, step2755]: loss 11.520004
[epoch7, step2756]: loss 4.635231
[epoch7, step2757]: loss 15.942808
[epoch7, step2758]: loss 7.735463
[epoch7, step2759]: loss 1.322312
[epoch7, step2760]: loss 1.076939
[epoch7, step2761]: loss 2.300064
[epoch7, step2762]: loss 3.696953
[epoch7, step2763]: loss 1.628666
[epoch7, step2764]: loss 17.036501
[epoch7, step2765]: loss 3.392891
[epoch7, step2766]: loss 4.541625
[epoch7, step2767]: loss 1.151760
[epoch7, step2768]: loss 1.668826
[epoch7, step2769]: loss 7.913329
[epoch7, step2770]: loss 5.907109
[epoch7, step2771]: loss 16.010170
[epoch7, step2772]: loss 1.830339
[epoch7, step2773]: loss 7.859231
[epoch7, step2774]: loss 4.456661
[epoch7, step2775]: loss 5.170818
[epoch7, step2776]: loss 8.841517
[epoch7, step2777]: loss 5.174953
[epoch7, step2778]: loss 5.588682
[epoch7, step2779]: loss 2.004681
[epoch7, step2780]: loss 8.015161
[epoch7, step2781]: loss 2.594281
[epoch7, step2782]: loss 19.369610
[epoch7, step2783]: loss 4.024958
[epoch7, step2784]: loss 1.761585
[epoch7, step2785]: loss 2.497518
[epoch7, step2786]: loss 5.163060
[epoch7, step2787]: loss 1.661125
[epoch7, step2788]: loss 5.686320
[epoch7, step2789]: loss 1.651316
[epoch7, step2790]: loss 3.467769
[epoch7, step2791]: loss 7.868845
[epoch7, step2792]: loss 3.179803
[epoch7, step2793]: loss 1.539011
[epoch7, step2794]: loss 5.141547
[epoch7, step2795]: loss 2.028204
[epoch7, step2796]: loss 13.482800
[epoch7, step2797]: loss 17.255508
[epoch7, step2798]: loss 1.888371
[epoch7, step2799]: loss 18.014729
[epoch7, step2800]: loss 8.004401
[epoch7, step2801]: loss 1.872691
[epoch7, step2802]: loss 3.018330
[epoch7, step2803]: loss 1.675933
[epoch7, step2804]: loss 1.116669
[epoch7, step2805]: loss 1.235957
[epoch7, step2806]: loss 3.145465
[epoch7, step2807]: loss 8.310689
[epoch7, step2808]: loss 0.997594
[epoch7, step2809]: loss 12.384074
[epoch7, step2810]: loss 4.587211
[epoch7, step2811]: loss 0.858349
[epoch7, step2812]: loss 4.253250
[epoch7, step2813]: loss 0.964679
[epoch7, step2814]: loss 2.001738
[epoch7, step2815]: loss 26.676916
[epoch7, step2816]: loss 9.319526
[epoch7, step2817]: loss 14.203004
[epoch7, step2818]: loss 1.176857
[epoch7, step2819]: loss 6.702275
[epoch7, step2820]: loss 1.409287
[epoch7, step2821]: loss 1.691345
[epoch7, step2822]: loss 4.927024
[epoch7, step2823]: loss 25.522163
[epoch7, step2824]: loss 14.631183
[epoch7, step2825]: loss 6.992308
[epoch7, step2826]: loss 3.452853
[epoch7, step2827]: loss 13.627316
[epoch7, step2828]: loss 11.381083
[epoch7, step2829]: loss 15.137252
[epoch7, step2830]: loss 1.628472
[epoch7, step2831]: loss 2.301854
[epoch7, step2832]: loss 1.586369
[epoch7, step2833]: loss 6.604247
[epoch7, step2834]: loss 2.414785
[epoch7, step2835]: loss 2.974224
[epoch7, step2836]: loss 9.806357
[epoch7, step2837]: loss 19.756870
[epoch7, step2838]: loss 18.089970
[epoch7, step2839]: loss 1.524865
[epoch7, step2840]: loss 45.179295
[epoch7, step2841]: loss 1.147196
[epoch7, step2842]: loss 1.612286
[epoch7, step2843]: loss 16.810728
[epoch7, step2844]: loss 1.974113
[epoch7, step2845]: loss 3.085221
[epoch7, step2846]: loss 11.176618
[epoch7, step2847]: loss 5.035119
[epoch7, step2848]: loss 1.170194
[epoch7, step2849]: loss 7.201236
[epoch7, step2850]: loss 1.572652
[epoch7, step2851]: loss 1.372248
[epoch7, step2852]: loss 1.423865
[epoch7, step2853]: loss 11.767874
[epoch7, step2854]: loss 2.995046
[epoch7, step2855]: loss 11.018392
[epoch7, step2856]: loss 1.451115
[epoch7, step2857]: loss 1.433954
[epoch7, step2858]: loss 4.183827
[epoch7, step2859]: loss 12.370938
[epoch7, step2860]: loss 4.395125
[epoch7, step2861]: loss 7.226367
[epoch7, step2862]: loss 7.950693
[epoch7, step2863]: loss 0.891616
[epoch7, step2864]: loss 2.061174
[epoch7, step2865]: loss 4.748518
[epoch7, step2866]: loss 5.568552
[epoch7, step2867]: loss 12.607824
[epoch7, step2868]: loss 2.106454
[epoch7, step2869]: loss 2.418155
[epoch7, step2870]: loss 2.443029
[epoch7, step2871]: loss 4.371109
[epoch7, step2872]: loss 8.481969
[epoch7, step2873]: loss 6.176882
[epoch7, step2874]: loss 7.972626
[epoch7, step2875]: loss 2.476171
[epoch7, step2876]: loss 3.571318
[epoch7, step2877]: loss 4.532940
[epoch7, step2878]: loss 1.732106
[epoch7, step2879]: loss 1.424887
[epoch7, step2880]: loss 2.182967
[epoch7, step2881]: loss 1.094602
[epoch7, step2882]: loss 2.907276
[epoch7, step2883]: loss 6.509159
[epoch7, step2884]: loss 12.858795
[epoch7, step2885]: loss 11.110835
[epoch7, step2886]: loss 14.406791
[epoch7, step2887]: loss 3.804697
[epoch7, step2888]: loss 4.674008
[epoch7, step2889]: loss 2.134381
[epoch7, step2890]: loss 1.236952
[epoch7, step2891]: loss 10.789885
[epoch7, step2892]: loss 4.756825
[epoch7, step2893]: loss 27.370798
[epoch7, step2894]: loss 2.315892
[epoch7, step2895]: loss 1.296079
[epoch7, step2896]: loss 4.556491
[epoch7, step2897]: loss 13.054914
[epoch7, step2898]: loss 10.463449
[epoch7, step2899]: loss 1.588241
[epoch7, step2900]: loss 0.985472
[epoch7, step2901]: loss 1.952920
[epoch7, step2902]: loss 5.130641
[epoch7, step2903]: loss 5.483945
[epoch7, step2904]: loss 5.870677
[epoch7, step2905]: loss 1.265484
[epoch7, step2906]: loss 18.339296
[epoch7, step2907]: loss 5.675759
[epoch7, step2908]: loss 21.182535
[epoch7, step2909]: loss 1.713899
[epoch7, step2910]: loss 2.311074
[epoch7, step2911]: loss 2.874811
[epoch7, step2912]: loss 1.868500
[epoch7, step2913]: loss 1.140584
[epoch7, step2914]: loss 1.247924
[epoch7, step2915]: loss 3.388896
[epoch7, step2916]: loss 17.967882
[epoch7, step2917]: loss 4.912919
[epoch7, step2918]: loss 2.297785
[epoch7, step2919]: loss 10.385756
[epoch7, step2920]: loss 2.563930
[epoch7, step2921]: loss 12.021605
[epoch7, step2922]: loss 1.880145
[epoch7, step2923]: loss 0.873120
[epoch7, step2924]: loss 13.059017
[epoch7, step2925]: loss 7.491973
[epoch7, step2926]: loss 7.494660
[epoch7, step2927]: loss 1.323938
[epoch7, step2928]: loss 2.157646
[epoch7, step2929]: loss 4.411442
[epoch7, step2930]: loss 7.502489
[epoch7, step2931]: loss 0.979070
[epoch7, step2932]: loss 2.890289
[epoch7, step2933]: loss 2.723639
[epoch7, step2934]: loss 2.114819
[epoch7, step2935]: loss 7.835592
[epoch7, step2936]: loss 20.001249
[epoch7, step2937]: loss 7.070052
[epoch7, step2938]: loss 7.278048
[epoch7, step2939]: loss 4.878362
[epoch7, step2940]: loss 1.088946
[epoch7, step2941]: loss 19.429461
[epoch7, step2942]: loss 13.011780
[epoch7, step2943]: loss 4.971941
[epoch7, step2944]: loss 2.721441
[epoch7, step2945]: loss 15.385875
[epoch7, step2946]: loss 2.624479
[epoch7, step2947]: loss 4.509747
[epoch7, step2948]: loss 1.493667
[epoch7, step2949]: loss 2.522254
[epoch7, step2950]: loss 7.775477
[epoch7, step2951]: loss 1.684857
[epoch7, step2952]: loss 4.257695
[epoch7, step2953]: loss 1.479034
[epoch7, step2954]: loss 4.725563
[epoch7, step2955]: loss 13.091522
[epoch7, step2956]: loss 1.948604
[epoch7, step2957]: loss 2.635794
[epoch7, step2958]: loss 8.322167
[epoch7, step2959]: loss 10.858604
[epoch7, step2960]: loss 2.244279
[epoch7, step2961]: loss 5.911461
[epoch7, step2962]: loss 2.894951
[epoch7, step2963]: loss 1.419739
[epoch7, step2964]: loss 2.109720
[epoch7, step2965]: loss 20.279886
[epoch7, step2966]: loss 17.694805
[epoch7, step2967]: loss 5.049422
[epoch7, step2968]: loss 8.099888
[epoch7, step2969]: loss 6.567142
[epoch7, step2970]: loss 14.375506
[epoch7, step2971]: loss 20.079840
[epoch7, step2972]: loss 5.575767
[epoch7, step2973]: loss 11.225122
[epoch7, step2974]: loss 3.451970
[epoch7, step2975]: loss 17.596540
[epoch7, step2976]: loss 1.854343
[epoch7, step2977]: loss 3.563992
[epoch7, step2978]: loss 3.988178
[epoch7, step2979]: loss 7.314629
[epoch7, step2980]: loss 7.400617
[epoch7, step2981]: loss 1.277889
[epoch7, step2982]: loss 1.085974
[epoch7, step2983]: loss 1.649881
[epoch7, step2984]: loss 12.482759
[epoch7, step2985]: loss 14.900009
[epoch7, step2986]: loss 1.050887
[epoch7, step2987]: loss 0.953632
[epoch7, step2988]: loss 1.409795
[epoch7, step2989]: loss 2.358200
[epoch7, step2990]: loss 5.109787
[epoch7, step2991]: loss 10.011503
[epoch7, step2992]: loss 1.331586
[epoch7, step2993]: loss 3.052583
[epoch7, step2994]: loss 5.524834
[epoch7, step2995]: loss 9.930487
[epoch7, step2996]: loss 13.324727
[epoch7, step2997]: loss 1.331329
[epoch7, step2998]: loss 11.817512
[epoch7, step2999]: loss 17.927258
[epoch7, step3000]: loss 14.114860
[epoch7, step3001]: loss 1.494233
[epoch7, step3002]: loss 1.894550
[epoch7, step3003]: loss 1.765816
[epoch7, step3004]: loss 4.615415
[epoch7, step3005]: loss 2.933604
[epoch7, step3006]: loss 9.523586
[epoch7, step3007]: loss 4.464505
[epoch7, step3008]: loss 1.701757
[epoch7, step3009]: loss 22.898623
[epoch7, step3010]: loss 1.524478
[epoch7, step3011]: loss 3.148671
[epoch7, step3012]: loss 5.478700
[epoch7, step3013]: loss 14.380468
[epoch7, step3014]: loss 14.342616
[epoch7, step3015]: loss 8.112152
[epoch7, step3016]: loss 3.923491
[epoch7, step3017]: loss 1.493734
[epoch7, step3018]: loss 4.881452
[epoch7, step3019]: loss 2.994947
[epoch7, step3020]: loss 1.897094
[epoch7, step3021]: loss 11.476493
[epoch7, step3022]: loss 1.224734
[epoch7, step3023]: loss 9.719355
[epoch7, step3024]: loss 8.411385
[epoch7, step3025]: loss 23.058979
[epoch7, step3026]: loss 1.697081
[epoch7, step3027]: loss 9.208936
[epoch7, step3028]: loss 3.158713
[epoch7, step3029]: loss 1.494140
[epoch7, step3030]: loss 2.310996
[epoch7, step3031]: loss 7.681061
[epoch7, step3032]: loss 1.420816
[epoch7, step3033]: loss 9.747820
[epoch7, step3034]: loss 4.701290
[epoch7, step3035]: loss 8.645785
[epoch7, step3036]: loss 5.638411
[epoch7, step3037]: loss 1.828665
[epoch7, step3038]: loss 14.496891
[epoch7, step3039]: loss 9.718986
[epoch7, step3040]: loss 1.787133
[epoch7, step3041]: loss 2.554049
[epoch7, step3042]: loss 8.046829
[epoch7, step3043]: loss 5.724981
[epoch7, step3044]: loss 11.048455
[epoch7, step3045]: loss 7.885441
[epoch7, step3046]: loss 1.704095
[epoch7, step3047]: loss 1.872185
[epoch7, step3048]: loss 1.779530
[epoch7, step3049]: loss 3.310227
[epoch7, step3050]: loss 4.938774
[epoch7, step3051]: loss 17.103125
[epoch7, step3052]: loss 5.828129
[epoch7, step3053]: loss 7.969360
[epoch7, step3054]: loss 1.703696
[epoch7, step3055]: loss 1.051019
[epoch7, step3056]: loss 1.326966
[epoch7, step3057]: loss 2.649629
[epoch7, step3058]: loss 1.485117
[epoch7, step3059]: loss 1.784995
[epoch7, step3060]: loss 4.778615
[epoch7, step3061]: loss 2.831704
[epoch7, step3062]: loss 16.730007
[epoch7, step3063]: loss 1.943563
[epoch7, step3064]: loss 4.848993
[epoch7, step3065]: loss 12.445246
[epoch7, step3066]: loss 6.126147
[epoch7, step3067]: loss 9.434019
[epoch7, step3068]: loss 16.722698
[epoch7, step3069]: loss 4.880861
[epoch7, step3070]: loss 8.851751
[epoch7, step3071]: loss 1.050474
[epoch7, step3072]: loss 3.313321
[epoch7, step3073]: loss 14.131866
[epoch7, step3074]: loss 14.153811
[epoch7, step3075]: loss 12.495090
[epoch7, step3076]: loss 7.075587

[epoch7]: avg loss 7.075587

[epoch8, step1]: loss 1.188529
[epoch8, step2]: loss 14.178831
[epoch8, step3]: loss 1.306895
[epoch8, step4]: loss 9.980444
[epoch8, step5]: loss 2.085710
[epoch8, step6]: loss 8.317941
[epoch8, step7]: loss 5.021741
[epoch8, step8]: loss 1.394215
[epoch8, step9]: loss 1.898430
[epoch8, step10]: loss 3.187712
[epoch8, step11]: loss 18.459829
[epoch8, step12]: loss 4.215150
[epoch8, step13]: loss 5.212253
[epoch8, step14]: loss 3.715008
[epoch8, step15]: loss 8.272276
[epoch8, step16]: loss 15.219109
[epoch8, step17]: loss 2.538881
[epoch8, step18]: loss 4.681983
[epoch8, step19]: loss 1.649056
[epoch8, step20]: loss 3.780751
[epoch8, step21]: loss 14.785657
[epoch8, step22]: loss 7.211456
[epoch8, step23]: loss 12.674650
[epoch8, step24]: loss 14.551848
[epoch8, step25]: loss 2.316014
[epoch8, step26]: loss 10.587633
[epoch8, step27]: loss 10.760367
[epoch8, step28]: loss 1.864755
[epoch8, step29]: loss 17.646233
[epoch8, step30]: loss 3.885303
[epoch8, step31]: loss 1.936367
[epoch8, step32]: loss 2.882009
[epoch8, step33]: loss 1.777498
[epoch8, step34]: loss 1.766135
[epoch8, step35]: loss 1.592544
[epoch8, step36]: loss 1.573646
[epoch8, step37]: loss 1.621647
[epoch8, step38]: loss 9.674160
[epoch8, step39]: loss 1.637555
[epoch8, step40]: loss 22.335554
[epoch8, step41]: loss 9.889340
[epoch8, step42]: loss 8.670369
[epoch8, step43]: loss 3.877456
[epoch8, step44]: loss 18.017300
[epoch8, step45]: loss 2.613481
[epoch8, step46]: loss 1.556648
[epoch8, step47]: loss 2.584506
[epoch8, step48]: loss 2.521726
[epoch8, step49]: loss 9.561132
[epoch8, step50]: loss 1.191934
[epoch8, step51]: loss 2.456161
[epoch8, step52]: loss 10.774962
[epoch8, step53]: loss 21.012991
[epoch8, step54]: loss 18.329311
[epoch8, step55]: loss 1.258821
[epoch8, step56]: loss 2.277995
[epoch8, step57]: loss 1.826450
[epoch8, step58]: loss 6.265982
[epoch8, step59]: loss 27.180099
[epoch8, step60]: loss 3.248551
[epoch8, step61]: loss 9.741317
[epoch8, step62]: loss 6.987342
[epoch8, step63]: loss 4.470636
[epoch8, step64]: loss 7.709979
[epoch8, step65]: loss 3.853789
[epoch8, step66]: loss 4.290413
[epoch8, step67]: loss 19.839283
[epoch8, step68]: loss 5.342513
[epoch8, step69]: loss 2.662170
[epoch8, step70]: loss 2.073519
[epoch8, step71]: loss 2.262850
[epoch8, step72]: loss 2.138160
[epoch8, step73]: loss 1.926575
[epoch8, step74]: loss 1.819752
[epoch8, step75]: loss 1.310727
[epoch8, step76]: loss 1.408628
[epoch8, step77]: loss 3.768334
[epoch8, step78]: loss 1.397919
[epoch8, step79]: loss 0.867205
[epoch8, step80]: loss 5.859299
[epoch8, step81]: loss 11.982491
[epoch8, step82]: loss 6.697050
[epoch8, step83]: loss 3.800782
[epoch8, step84]: loss 1.329857
[epoch8, step85]: loss 16.349733
[epoch8, step86]: loss 1.663089
[epoch8, step87]: loss 2.154264
[epoch8, step88]: loss 2.527243
[epoch8, step89]: loss 1.882664
[epoch8, step90]: loss 14.688000
[epoch8, step91]: loss 5.089988
[epoch8, step92]: loss 2.188085
[epoch8, step93]: loss 14.805174
[epoch8, step94]: loss 9.408125
[epoch8, step95]: loss 7.504225
[epoch8, step96]: loss 1.194088
[epoch8, step97]: loss 22.458588
[epoch8, step98]: loss 13.754159
[epoch8, step99]: loss 4.107265
[epoch8, step100]: loss 8.627083
[epoch8, step101]: loss 14.735797
[epoch8, step102]: loss 1.728540
[epoch8, step103]: loss 0.915489
[epoch8, step104]: loss 8.599925
[epoch8, step105]: loss 4.968109
[epoch8, step106]: loss 2.382142
[epoch8, step107]: loss 2.693461
[epoch8, step108]: loss 3.381043
[epoch8, step109]: loss 3.185756
[epoch8, step110]: loss 0.820562
[epoch8, step111]: loss 3.343566
[epoch8, step112]: loss 2.553609
[epoch8, step113]: loss 3.821097
[epoch8, step114]: loss 15.944201
[epoch8, step115]: loss 20.958208
[epoch8, step116]: loss 1.415024
[epoch8, step117]: loss 1.899720
[epoch8, step118]: loss 5.474013
[epoch8, step119]: loss 14.533678
[epoch8, step120]: loss 8.212280
[epoch8, step121]: loss 11.051306
[epoch8, step122]: loss 7.241590
[epoch8, step123]: loss 1.862958
[epoch8, step124]: loss 5.507046
[epoch8, step125]: loss 1.139285
[epoch8, step126]: loss 11.594250
[epoch8, step127]: loss 5.360435
[epoch8, step128]: loss 2.470546
[epoch8, step129]: loss 2.073322
[epoch8, step130]: loss 8.661650
[epoch8, step131]: loss 1.608219
[epoch8, step132]: loss 9.424608
[epoch8, step133]: loss 13.837470
[epoch8, step134]: loss 23.007746
[epoch8, step135]: loss 2.465458
[epoch8, step136]: loss 15.931158
[epoch8, step137]: loss 9.560303
[epoch8, step138]: loss 2.594002
[epoch8, step139]: loss 2.974339
[epoch8, step140]: loss 1.744894
[epoch8, step141]: loss 8.922876
[epoch8, step142]: loss 7.024340
[epoch8, step143]: loss 2.140439
[epoch8, step144]: loss 17.487406
[epoch8, step145]: loss 1.871954
[epoch8, step146]: loss 1.435185
[epoch8, step147]: loss 4.057055
[epoch8, step148]: loss 3.639115
[epoch8, step149]: loss 13.031014
[epoch8, step150]: loss 11.056669
[epoch8, step151]: loss 12.470801
[epoch8, step152]: loss 1.713068
[epoch8, step153]: loss 9.641823
[epoch8, step154]: loss 8.088109
[epoch8, step155]: loss 2.339342
[epoch8, step156]: loss 9.283899
[epoch8, step157]: loss 1.209860
[epoch8, step158]: loss 1.930190
[epoch8, step159]: loss 1.424439
[epoch8, step160]: loss 2.267301
[epoch8, step161]: loss 11.138425
[epoch8, step162]: loss 4.969498
[epoch8, step163]: loss 2.663797
[epoch8, step164]: loss 4.793600
[epoch8, step165]: loss 7.621470
[epoch8, step166]: loss 1.056063
[epoch8, step167]: loss 2.486980
[epoch8, step168]: loss 7.311603
[epoch8, step169]: loss 4.736703
[epoch8, step170]: loss 2.494928
[epoch8, step171]: loss 8.676768
[epoch8, step172]: loss 7.796744
[epoch8, step173]: loss 2.190272
[epoch8, step174]: loss 1.592853
[epoch8, step175]: loss 2.452733
[epoch8, step176]: loss 5.436804
[epoch8, step177]: loss 1.250389
[epoch8, step178]: loss 6.532669
[epoch8, step179]: loss 11.124648
[epoch8, step180]: loss 1.717166
[epoch8, step181]: loss 22.002853
[epoch8, step182]: loss 4.475054
[epoch8, step183]: loss 3.023771
[epoch8, step184]: loss 10.325785
[epoch8, step185]: loss 13.103418
[epoch8, step186]: loss 9.103488
[epoch8, step187]: loss 1.941830
[epoch8, step188]: loss 1.167944
[epoch8, step189]: loss 1.533617
[epoch8, step190]: loss 1.618981
[epoch8, step191]: loss 14.986587
[epoch8, step192]: loss 2.133442
[epoch8, step193]: loss 6.693387
[epoch8, step194]: loss 5.338091
[epoch8, step195]: loss 1.685804
[epoch8, step196]: loss 2.907787
[epoch8, step197]: loss 3.093947
[epoch8, step198]: loss 7.195622
[epoch8, step199]: loss 7.840786
[epoch8, step200]: loss 4.346282
[epoch8, step201]: loss 5.732564
[epoch8, step202]: loss 5.865790
[epoch8, step203]: loss 3.535408
[epoch8, step204]: loss 9.412553
[epoch8, step205]: loss 10.076084
[epoch8, step206]: loss 4.651680
[epoch8, step207]: loss 14.954372
[epoch8, step208]: loss 7.650249
[epoch8, step209]: loss 5.278687
[epoch8, step210]: loss 2.019180
[epoch8, step211]: loss 9.509531
[epoch8, step212]: loss 7.926715
[epoch8, step213]: loss 1.182696
[epoch8, step214]: loss 4.200722
[epoch8, step215]: loss 1.834325
[epoch8, step216]: loss 4.150701
[epoch8, step217]: loss 8.536770
[epoch8, step218]: loss 1.344011
[epoch8, step219]: loss 2.195503
[epoch8, step220]: loss 1.341731
[epoch8, step221]: loss 7.768910
[epoch8, step222]: loss 11.801486
[epoch8, step223]: loss 1.154705
[epoch8, step224]: loss 7.059523
[epoch8, step225]: loss 23.166641
[epoch8, step226]: loss 1.463639
[epoch8, step227]: loss 3.795456
[epoch8, step228]: loss 2.068108
[epoch8, step229]: loss 2.017311
[epoch8, step230]: loss 5.670133
[epoch8, step231]: loss 1.576544
[epoch8, step232]: loss 5.849592
[epoch8, step233]: loss 1.472141
[epoch8, step234]: loss 1.145838
[epoch8, step235]: loss 2.075220
[epoch8, step236]: loss 0.832704
[epoch8, step237]: loss 12.072211
[epoch8, step238]: loss 15.871736
[epoch8, step239]: loss 2.700989
[epoch8, step240]: loss 10.751575
[epoch8, step241]: loss 11.345029
[epoch8, step242]: loss 1.569457
[epoch8, step243]: loss 1.248447
[epoch8, step244]: loss 13.646638
[epoch8, step245]: loss 7.356820
[epoch8, step246]: loss 11.661619
[epoch8, step247]: loss 4.932292
[epoch8, step248]: loss 11.788524
[epoch8, step249]: loss 12.600595
[epoch8, step250]: loss 33.783535
[epoch8, step251]: loss 1.592037
[epoch8, step252]: loss 1.622452
[epoch8, step253]: loss 3.931489
[epoch8, step254]: loss 2.493025
[epoch8, step255]: loss 5.653369
[epoch8, step256]: loss 3.492500
[epoch8, step257]: loss 2.220989
[epoch8, step258]: loss 7.766067
[epoch8, step259]: loss 17.311415
[epoch8, step260]: loss 7.454357
[epoch8, step261]: loss 4.286687
[epoch8, step262]: loss 3.755737
[epoch8, step263]: loss 1.925362
[epoch8, step264]: loss 6.755892
[epoch8, step265]: loss 13.071786
[epoch8, step266]: loss 7.447658
[epoch8, step267]: loss 12.646867
[epoch8, step268]: loss 2.784346
[epoch8, step269]: loss 21.216908
[epoch8, step270]: loss 1.695310
[epoch8, step271]: loss 5.126851
[epoch8, step272]: loss 1.673439
[epoch8, step273]: loss 3.416458
[epoch8, step274]: loss 2.903765
[epoch8, step275]: loss 1.081980
[epoch8, step276]: loss 1.923032
[epoch8, step277]: loss 5.145895
[epoch8, step278]: loss 14.179923
[epoch8, step279]: loss 4.962057
[epoch8, step280]: loss 4.347192
[epoch8, step281]: loss 7.599517
[epoch8, step282]: loss 5.414052
[epoch8, step283]: loss 1.586856
[epoch8, step284]: loss 12.371873
[epoch8, step285]: loss 9.580390
[epoch8, step286]: loss 12.295828
[epoch8, step287]: loss 1.664093
[epoch8, step288]: loss 2.459571
[epoch8, step289]: loss 1.586289
[epoch8, step290]: loss 2.111782
[epoch8, step291]: loss 11.644852
[epoch8, step292]: loss 2.632364
[epoch8, step293]: loss 4.480201
[epoch8, step294]: loss 6.444722
[epoch8, step295]: loss 1.711232
[epoch8, step296]: loss 4.356587
[epoch8, step297]: loss 2.136881
[epoch8, step298]: loss 2.056575
[epoch8, step299]: loss 13.987749
[epoch8, step300]: loss 2.207099
[epoch8, step301]: loss 5.107475
[epoch8, step302]: loss 1.808595
[epoch8, step303]: loss 11.683720
[epoch8, step304]: loss 2.692208
[epoch8, step305]: loss 2.350532
[epoch8, step306]: loss 3.470608
[epoch8, step307]: loss 1.212848
[epoch8, step308]: loss 5.614360
[epoch8, step309]: loss 1.343005
[epoch8, step310]: loss 4.309945
[epoch8, step311]: loss 4.785898
[epoch8, step312]: loss 2.489938
[epoch8, step313]: loss 12.036101
[epoch8, step314]: loss 14.145929
[epoch8, step315]: loss 13.360065
[epoch8, step316]: loss 7.595956
[epoch8, step317]: loss 3.571549
[epoch8, step318]: loss 1.638024
[epoch8, step319]: loss 3.094974
[epoch8, step320]: loss 4.347588
[epoch8, step321]: loss 8.870167
[epoch8, step322]: loss 2.035071
[epoch8, step323]: loss 5.077984
[epoch8, step324]: loss 10.399434
[epoch8, step325]: loss 1.777585
[epoch8, step326]: loss 9.214432
[epoch8, step327]: loss 15.714304
[epoch8, step328]: loss 4.682467
[epoch8, step329]: loss 15.183702
[epoch8, step330]: loss 1.586773
[epoch8, step331]: loss 2.566784
[epoch8, step332]: loss 3.317609
[epoch8, step333]: loss 2.385196
[epoch8, step334]: loss 6.813994
[epoch8, step335]: loss 10.502119
[epoch8, step336]: loss 10.356794
[epoch8, step337]: loss 12.463175
[epoch8, step338]: loss 8.374306
[epoch8, step339]: loss 0.866743
[epoch8, step340]: loss 1.650770
[epoch8, step341]: loss 8.171464
[epoch8, step342]: loss 7.939618
[epoch8, step343]: loss 2.424691
[epoch8, step344]: loss 1.739787
[epoch8, step345]: loss 4.059005
[epoch8, step346]: loss 1.750650
[epoch8, step347]: loss 9.355846
[epoch8, step348]: loss 10.263276
[epoch8, step349]: loss 2.100289
[epoch8, step350]: loss 1.977562
[epoch8, step351]: loss 5.078431
[epoch8, step352]: loss 16.746895
[epoch8, step353]: loss 2.813044
[epoch8, step354]: loss 2.201613
[epoch8, step355]: loss 4.603225
[epoch8, step356]: loss 9.471037
[epoch8, step357]: loss 12.585123
[epoch8, step358]: loss 2.866469
[epoch8, step359]: loss 1.475921
[epoch8, step360]: loss 5.254009
[epoch8, step361]: loss 14.286744
[epoch8, step362]: loss 1.465984
[epoch8, step363]: loss 1.984797
[epoch8, step364]: loss 27.282869
[epoch8, step365]: loss 2.341051
[epoch8, step366]: loss 17.771687
[epoch8, step367]: loss 1.814291
[epoch8, step368]: loss 12.015438
[epoch8, step369]: loss 6.907422
[epoch8, step370]: loss 4.899652
[epoch8, step371]: loss 11.148981
[epoch8, step372]: loss 8.760746
[epoch8, step373]: loss 1.928137
[epoch8, step374]: loss 3.711112
[epoch8, step375]: loss 5.850690
[epoch8, step376]: loss 1.960919
[epoch8, step377]: loss 4.637613
[epoch8, step378]: loss 12.007920
[epoch8, step379]: loss 7.368711
[epoch8, step380]: loss 8.446852
[epoch8, step381]: loss 11.857254
[epoch8, step382]: loss 2.072902
[epoch8, step383]: loss 7.764433
[epoch8, step384]: loss 19.182613
[epoch8, step385]: loss 4.429609
[epoch8, step386]: loss 2.866447
[epoch8, step387]: loss 1.259301
[epoch8, step388]: loss 9.031322
[epoch8, step389]: loss 1.776017
[epoch8, step390]: loss 0.812307
[epoch8, step391]: loss 1.476921
[epoch8, step392]: loss 16.519472
[epoch8, step393]: loss 12.931754
[epoch8, step394]: loss 4.306104
[epoch8, step395]: loss 2.929234
[epoch8, step396]: loss 21.058075
[epoch8, step397]: loss 4.071901
[epoch8, step398]: loss 3.932231
[epoch8, step399]: loss 11.475719
[epoch8, step400]: loss 7.816231
[epoch8, step401]: loss 5.823510
[epoch8, step402]: loss 11.005408
[epoch8, step403]: loss 1.666079
[epoch8, step404]: loss 5.057000
[epoch8, step405]: loss 2.361471
[epoch8, step406]: loss 4.461223
[epoch8, step407]: loss 21.678919
[epoch8, step408]: loss 3.087850
[epoch8, step409]: loss 11.568120
[epoch8, step410]: loss 4.574955
[epoch8, step411]: loss 11.245888
[epoch8, step412]: loss 1.666191
[epoch8, step413]: loss 1.695337
[epoch8, step414]: loss 3.037560
[epoch8, step415]: loss 4.335698
[epoch8, step416]: loss 1.303824
[epoch8, step417]: loss 4.904349
[epoch8, step418]: loss 4.281330
[epoch8, step419]: loss 11.701537
[epoch8, step420]: loss 1.859134
[epoch8, step421]: loss 6.148950
[epoch8, step422]: loss 1.228101
[epoch8, step423]: loss 5.546486
[epoch8, step424]: loss 4.127812
[epoch8, step425]: loss 4.403646
[epoch8, step426]: loss 9.167959
[epoch8, step427]: loss 22.786087
[epoch8, step428]: loss 1.358321
[epoch8, step429]: loss 11.556143
[epoch8, step430]: loss 2.547133
[epoch8, step431]: loss 5.077197
[epoch8, step432]: loss 6.181883
[epoch8, step433]: loss 21.172073
[epoch8, step434]: loss 4.272406
[epoch8, step435]: loss 6.644568
[epoch8, step436]: loss 10.732188
[epoch8, step437]: loss 7.699652
[epoch8, step438]: loss 10.793223
[epoch8, step439]: loss 3.586994
[epoch8, step440]: loss 2.748974
[epoch8, step441]: loss 7.785355
[epoch8, step442]: loss 29.980614
[epoch8, step443]: loss 1.970094
[epoch8, step444]: loss 4.068560
[epoch8, step445]: loss 14.319192
[epoch8, step446]: loss 14.790442
[epoch8, step447]: loss 6.665339
[epoch8, step448]: loss 10.374049
[epoch8, step449]: loss 10.195643
[epoch8, step450]: loss 10.591435
[epoch8, step451]: loss 1.336844
[epoch8, step452]: loss 1.621292
[epoch8, step453]: loss 2.172930
[epoch8, step454]: loss 8.758537
[epoch8, step455]: loss 11.233750
[epoch8, step456]: loss 1.265290
[epoch8, step457]: loss 24.444046
[epoch8, step458]: loss 8.586623
[epoch8, step459]: loss 15.464935
[epoch8, step460]: loss 2.726948
[epoch8, step461]: loss 2.948488
[epoch8, step462]: loss 2.619780
[epoch8, step463]: loss 6.123732
[epoch8, step464]: loss 4.257179
[epoch8, step465]: loss 1.081136
[epoch8, step466]: loss 2.145992
[epoch8, step467]: loss 5.451731
[epoch8, step468]: loss 7.416565
[epoch8, step469]: loss 16.113935
[epoch8, step470]: loss 4.577319
[epoch8, step471]: loss 2.514646
[epoch8, step472]: loss 5.445136
[epoch8, step473]: loss 1.739883
[epoch8, step474]: loss 7.989883
[epoch8, step475]: loss 2.181491
[epoch8, step476]: loss 10.357636
[epoch8, step477]: loss 4.101853
[epoch8, step478]: loss 14.494785
[epoch8, step479]: loss 7.934683
[epoch8, step480]: loss 5.664862
[epoch8, step481]: loss 1.031902
[epoch8, step482]: loss 5.626569
[epoch8, step483]: loss 15.258179
[epoch8, step484]: loss 1.216735
[epoch8, step485]: loss 16.745918
[epoch8, step486]: loss 1.018028
[epoch8, step487]: loss 2.089900
[epoch8, step488]: loss 4.408621
[epoch8, step489]: loss 1.997692
[epoch8, step490]: loss 1.629853
[epoch8, step491]: loss 8.866278
[epoch8, step492]: loss 1.259921
[epoch8, step493]: loss 7.682523
[epoch8, step494]: loss 4.662199
[epoch8, step495]: loss 10.841427
[epoch8, step496]: loss 3.401148
[epoch8, step497]: loss 4.372353
[epoch8, step498]: loss 4.681282
[epoch8, step499]: loss 15.684261
[epoch8, step500]: loss 4.089242
[epoch8, step501]: loss 15.546250
[epoch8, step502]: loss 4.877624
[epoch8, step503]: loss 1.796083
[epoch8, step504]: loss 4.576871
[epoch8, step505]: loss 12.569906
[epoch8, step506]: loss 4.298151
[epoch8, step507]: loss 3.971768
[epoch8, step508]: loss 1.193575
[epoch8, step509]: loss 1.502971
[epoch8, step510]: loss 1.633922
[epoch8, step511]: loss 14.263496
[epoch8, step512]: loss 1.366627
[epoch8, step513]: loss 12.073892
[epoch8, step514]: loss 3.060863
[epoch8, step515]: loss 23.809847
[epoch8, step516]: loss 14.710332
[epoch8, step517]: loss 9.899174
[epoch8, step518]: loss 16.224863
[epoch8, step519]: loss 1.640342
[epoch8, step520]: loss 12.359591
[epoch8, step521]: loss 14.187610
[epoch8, step522]: loss 2.524404
[epoch8, step523]: loss 1.289688
[epoch8, step524]: loss 5.390480
[epoch8, step525]: loss 4.588742
[epoch8, step526]: loss 7.348790
[epoch8, step527]: loss 4.502164
[epoch8, step528]: loss 1.906673
[epoch8, step529]: loss 2.947579
[epoch8, step530]: loss 1.552714
[epoch8, step531]: loss 3.776642
[epoch8, step532]: loss 10.252123
[epoch8, step533]: loss 2.456045
[epoch8, step534]: loss 1.059474
[epoch8, step535]: loss 2.720278
[epoch8, step536]: loss 1.776788
[epoch8, step537]: loss 2.312177
[epoch8, step538]: loss 4.306948
[epoch8, step539]: loss 5.862026
[epoch8, step540]: loss 2.397665
[epoch8, step541]: loss 7.396657
[epoch8, step542]: loss 2.979739
[epoch8, step543]: loss 1.943833
[epoch8, step544]: loss 7.089029
[epoch8, step545]: loss 9.109454
[epoch8, step546]: loss 8.090415
[epoch8, step547]: loss 8.827111
[epoch8, step548]: loss 1.154037
[epoch8, step549]: loss 1.689447
[epoch8, step550]: loss 1.545663
[epoch8, step551]: loss 4.282386
[epoch8, step552]: loss 1.297940
[epoch8, step553]: loss 2.342966
[epoch8, step554]: loss 10.499696
[epoch8, step555]: loss 14.181745
[epoch8, step556]: loss 8.148844
[epoch8, step557]: loss 4.410372
[epoch8, step558]: loss 1.713729
[epoch8, step559]: loss 3.085750
[epoch8, step560]: loss 8.378618
[epoch8, step561]: loss 1.309776
[epoch8, step562]: loss 1.630014
[epoch8, step563]: loss 2.180525
[epoch8, step564]: loss 0.957190
[epoch8, step565]: loss 2.600841
[epoch8, step566]: loss 5.707638
[epoch8, step567]: loss 7.468653
[epoch8, step568]: loss 12.407557
[epoch8, step569]: loss 1.368284
[epoch8, step570]: loss 6.689883
[epoch8, step571]: loss 1.666929
[epoch8, step572]: loss 2.567356
[epoch8, step573]: loss 19.769543
[epoch8, step574]: loss 8.884846
[epoch8, step575]: loss 2.229068
[epoch8, step576]: loss 0.983478
[epoch8, step577]: loss 4.062037
[epoch8, step578]: loss 1.377130
[epoch8, step579]: loss 13.613782
[epoch8, step580]: loss 9.161947
[epoch8, step581]: loss 4.614733
[epoch8, step582]: loss 2.078138
[epoch8, step583]: loss 9.352900
[epoch8, step584]: loss 4.180247
[epoch8, step585]: loss 6.372681
[epoch8, step586]: loss 2.911768
[epoch8, step587]: loss 4.156797
[epoch8, step588]: loss 0.892368
[epoch8, step589]: loss 20.687990
[epoch8, step590]: loss 5.936357
[epoch8, step591]: loss 4.536622
[epoch8, step592]: loss 1.558216
[epoch8, step593]: loss 7.913480
[epoch8, step594]: loss 4.576357
[epoch8, step595]: loss 16.643194
[epoch8, step596]: loss 9.974643
[epoch8, step597]: loss 23.339920
[epoch8, step598]: loss 2.232049
[epoch8, step599]: loss 5.648179
[epoch8, step600]: loss 8.714123
[epoch8, step601]: loss 7.908949
[epoch8, step602]: loss 1.921914
[epoch8, step603]: loss 1.123065
[epoch8, step604]: loss 1.148341
[epoch8, step605]: loss 23.148310
[epoch8, step606]: loss 2.432667
[epoch8, step607]: loss 1.963991
[epoch8, step608]: loss 5.306923
[epoch8, step609]: loss 1.617016
[epoch8, step610]: loss 5.626219
[epoch8, step611]: loss 2.920503
[epoch8, step612]: loss 1.874549
[epoch8, step613]: loss 1.672200
[epoch8, step614]: loss 3.943679
[epoch8, step615]: loss 8.007177
[epoch8, step616]: loss 11.073497
[epoch8, step617]: loss 3.883522
[epoch8, step618]: loss 1.987320
[epoch8, step619]: loss 1.624561
[epoch8, step620]: loss 18.232384
[epoch8, step621]: loss 3.334236
[epoch8, step622]: loss 5.275308
[epoch8, step623]: loss 1.592985
[epoch8, step624]: loss 22.056381
[epoch8, step625]: loss 7.833367
[epoch8, step626]: loss 28.684233
[epoch8, step627]: loss 2.470512
[epoch8, step628]: loss 2.238133
[epoch8, step629]: loss 14.497456
[epoch8, step630]: loss 1.518951
[epoch8, step631]: loss 5.183750
[epoch8, step632]: loss 4.428516
[epoch8, step633]: loss 12.257878
[epoch8, step634]: loss 3.049220
[epoch8, step635]: loss 3.247084
[epoch8, step636]: loss 1.230868
[epoch8, step637]: loss 9.417590
[epoch8, step638]: loss 5.028841
[epoch8, step639]: loss 3.961564
[epoch8, step640]: loss 15.394229
[epoch8, step641]: loss 1.595584
[epoch8, step642]: loss 15.736208
[epoch8, step643]: loss 4.610351
[epoch8, step644]: loss 4.689417
[epoch8, step645]: loss 1.955199
[epoch8, step646]: loss 3.772282
[epoch8, step647]: loss 3.728633
[epoch8, step648]: loss 15.271965
[epoch8, step649]: loss 12.068746
[epoch8, step650]: loss 3.615953
[epoch8, step651]: loss 1.565472
[epoch8, step652]: loss 7.088891
[epoch8, step653]: loss 2.546933
[epoch8, step654]: loss 10.903916
[epoch8, step655]: loss 13.586752
[epoch8, step656]: loss 4.803937
[epoch8, step657]: loss 12.349396
[epoch8, step658]: loss 4.957676
[epoch8, step659]: loss 3.336288
[epoch8, step660]: loss 1.232289
[epoch8, step661]: loss 14.148572
[epoch8, step662]: loss 2.153118
[epoch8, step663]: loss 14.622929
[epoch8, step664]: loss 4.741609
[epoch8, step665]: loss 15.213585
[epoch8, step666]: loss 5.913199
[epoch8, step667]: loss 3.373189
[epoch8, step668]: loss 1.498644
[epoch8, step669]: loss 1.477383
[epoch8, step670]: loss 1.105403
[epoch8, step671]: loss 1.858599
[epoch8, step672]: loss 1.965831
[epoch8, step673]: loss 13.622018
[epoch8, step674]: loss 1.412463
[epoch8, step675]: loss 5.357432
[epoch8, step676]: loss 6.204114
[epoch8, step677]: loss 5.137269
[epoch8, step678]: loss 3.261050
[epoch8, step679]: loss 1.394839
[epoch8, step680]: loss 9.405231
[epoch8, step681]: loss 6.965456
[epoch8, step682]: loss 1.719935
[epoch8, step683]: loss 10.861191
[epoch8, step684]: loss 1.983961
[epoch8, step685]: loss 2.392202
[epoch8, step686]: loss 16.254793
[epoch8, step687]: loss 15.038578
[epoch8, step688]: loss 12.369909
[epoch8, step689]: loss 3.847163
[epoch8, step690]: loss 17.327579
[epoch8, step691]: loss 4.950463
[epoch8, step692]: loss 1.751986
[epoch8, step693]: loss 3.154926
[epoch8, step694]: loss 2.595931
[epoch8, step695]: loss 4.210319
[epoch8, step696]: loss 15.242062
[epoch8, step697]: loss 1.396519
[epoch8, step698]: loss 0.973712
[epoch8, step699]: loss 1.497378
[epoch8, step700]: loss 29.473320
[epoch8, step701]: loss 3.769197
[epoch8, step702]: loss 3.866821
[epoch8, step703]: loss 4.164899
[epoch8, step704]: loss 14.683008
[epoch8, step705]: loss 12.608624
[epoch8, step706]: loss 9.437080
[epoch8, step707]: loss 5.516914
[epoch8, step708]: loss 8.621887
[epoch8, step709]: loss 1.140070
[epoch8, step710]: loss 7.708496
[epoch8, step711]: loss 2.563274
[epoch8, step712]: loss 1.854025
[epoch8, step713]: loss 3.156305
[epoch8, step714]: loss 1.600995
[epoch8, step715]: loss 0.999446
[epoch8, step716]: loss 9.175387
[epoch8, step717]: loss 7.019504
[epoch8, step718]: loss 6.240708
[epoch8, step719]: loss 4.411926
[epoch8, step720]: loss 1.245884
[epoch8, step721]: loss 24.587225
[epoch8, step722]: loss 2.384437
[epoch8, step723]: loss 5.785789
[epoch8, step724]: loss 13.165856
[epoch8, step725]: loss 3.213879
[epoch8, step726]: loss 2.126325
[epoch8, step727]: loss 2.364131
[epoch8, step728]: loss 1.840524
[epoch8, step729]: loss 4.715774
[epoch8, step730]: loss 11.917752
[epoch8, step731]: loss 1.441017
[epoch8, step732]: loss 1.051630
[epoch8, step733]: loss 13.934113
[epoch8, step734]: loss 4.216353
[epoch8, step735]: loss 1.779029
[epoch8, step736]: loss 3.923623
[epoch8, step737]: loss 5.968299
[epoch8, step738]: loss 6.560113
[epoch8, step739]: loss 1.653887
[epoch8, step740]: loss 4.027974
[epoch8, step741]: loss 2.209559
[epoch8, step742]: loss 8.162665
[epoch8, step743]: loss 5.755943
[epoch8, step744]: loss 9.882186
[epoch8, step745]: loss 10.107519
[epoch8, step746]: loss 12.772219
[epoch8, step747]: loss 0.826748
[epoch8, step748]: loss 4.556443
[epoch8, step749]: loss 2.047143
[epoch8, step750]: loss 5.305287
[epoch8, step751]: loss 5.746119
[epoch8, step752]: loss 2.078009
[epoch8, step753]: loss 9.388647
[epoch8, step754]: loss 2.012005
[epoch8, step755]: loss 7.559054
[epoch8, step756]: loss 12.636489
[epoch8, step757]: loss 5.627816
[epoch8, step758]: loss 5.633266
[epoch8, step759]: loss 2.278058
[epoch8, step760]: loss 7.154121
[epoch8, step761]: loss 5.973602
[epoch8, step762]: loss 5.866053
[epoch8, step763]: loss 6.066599
[epoch8, step764]: loss 2.081847
[epoch8, step765]: loss 10.988294
[epoch8, step766]: loss 13.065661
[epoch8, step767]: loss 22.412395
[epoch8, step768]: loss 1.635930
[epoch8, step769]: loss 1.631541
[epoch8, step770]: loss 1.915248
[epoch8, step771]: loss 2.643133
[epoch8, step772]: loss 2.043971
[epoch8, step773]: loss 1.378813
[epoch8, step774]: loss 5.616364
[epoch8, step775]: loss 11.153688
[epoch8, step776]: loss 2.995469
[epoch8, step777]: loss 2.007587
[epoch8, step778]: loss 22.739937
[epoch8, step779]: loss 2.283981
[epoch8, step780]: loss 28.041822
[epoch8, step781]: loss 1.559176
[epoch8, step782]: loss 5.497078
[epoch8, step783]: loss 2.734681
[epoch8, step784]: loss 27.290976
[epoch8, step785]: loss 8.544279
[epoch8, step786]: loss 10.300797
[epoch8, step787]: loss 4.008452
[epoch8, step788]: loss 1.016853
[epoch8, step789]: loss 2.358503
[epoch8, step790]: loss 5.021091
[epoch8, step791]: loss 1.784968
[epoch8, step792]: loss 1.508966
[epoch8, step793]: loss 2.197411
[epoch8, step794]: loss 5.127720
[epoch8, step795]: loss 1.032108
[epoch8, step796]: loss 8.508614
[epoch8, step797]: loss 2.346473
[epoch8, step798]: loss 21.574219
[epoch8, step799]: loss 5.383506
[epoch8, step800]: loss 4.189092
[epoch8, step801]: loss 9.970049
[epoch8, step802]: loss 7.228421
[epoch8, step803]: loss 6.738616
[epoch8, step804]: loss 1.190256
[epoch8, step805]: loss 1.713058
[epoch8, step806]: loss 1.741945
[epoch8, step807]: loss 2.442101
[epoch8, step808]: loss 2.098962
[epoch8, step809]: loss 1.426503
[epoch8, step810]: loss 3.321943
[epoch8, step811]: loss 4.144267
[epoch8, step812]: loss 1.405140
[epoch8, step813]: loss 1.963378
[epoch8, step814]: loss 1.350260
[epoch8, step815]: loss 1.585465
[epoch8, step816]: loss 1.084026
[epoch8, step817]: loss 1.704000
[epoch8, step818]: loss 1.404757
[epoch8, step819]: loss 8.530408
[epoch8, step820]: loss 13.804974
[epoch8, step821]: loss 1.876023
[epoch8, step822]: loss 7.377171
[epoch8, step823]: loss 13.156076
[epoch8, step824]: loss 1.411376
[epoch8, step825]: loss 11.122118
[epoch8, step826]: loss 1.983160
[epoch8, step827]: loss 1.367441
[epoch8, step828]: loss 5.107272
[epoch8, step829]: loss 4.103724
[epoch8, step830]: loss 2.071275
[epoch8, step831]: loss 2.381107
[epoch8, step832]: loss 4.873377
[epoch8, step833]: loss 1.701333
[epoch8, step834]: loss 1.463918
[epoch8, step835]: loss 2.609414
[epoch8, step836]: loss 11.790475
[epoch8, step837]: loss 11.629045
[epoch8, step838]: loss 10.306809
[epoch8, step839]: loss 2.319821
[epoch8, step840]: loss 4.762908
[epoch8, step841]: loss 1.985826
[epoch8, step842]: loss 2.153555
[epoch8, step843]: loss 3.420239
[epoch8, step844]: loss 8.566098
[epoch8, step845]: loss 1.251702
[epoch8, step846]: loss 1.259970
[epoch8, step847]: loss 4.651098
[epoch8, step848]: loss 0.784235
[epoch8, step849]: loss 2.801407
[epoch8, step850]: loss 2.642323
[epoch8, step851]: loss 3.441701
[epoch8, step852]: loss 4.767184
[epoch8, step853]: loss 8.184353
[epoch8, step854]: loss 7.089571
[epoch8, step855]: loss 11.283897
[epoch8, step856]: loss 4.790461
[epoch8, step857]: loss 1.801796
[epoch8, step858]: loss 2.414662
[epoch8, step859]: loss 1.997939
[epoch8, step860]: loss 10.536532
[epoch8, step861]: loss 2.663403
[epoch8, step862]: loss 16.611897
[epoch8, step863]: loss 5.374099
[epoch8, step864]: loss 4.418650
[epoch8, step865]: loss 8.788902
[epoch8, step866]: loss 1.556803
[epoch8, step867]: loss 22.434309
[epoch8, step868]: loss 22.343676
[epoch8, step869]: loss 3.777475
[epoch8, step870]: loss 4.786820
[epoch8, step871]: loss 2.290528
[epoch8, step872]: loss 20.751337
[epoch8, step873]: loss 2.135277
[epoch8, step874]: loss 1.810091
[epoch8, step875]: loss 4.226276
[epoch8, step876]: loss 21.763147
[epoch8, step877]: loss 3.901995
[epoch8, step878]: loss 2.100234
[epoch8, step879]: loss 5.016039
[epoch8, step880]: loss 14.059585
[epoch8, step881]: loss 20.863087
[epoch8, step882]: loss 3.246522
[epoch8, step883]: loss 13.771499
[epoch8, step884]: loss 5.766554
[epoch8, step885]: loss 2.252859
[epoch8, step886]: loss 5.451421
[epoch8, step887]: loss 2.320896
[epoch8, step888]: loss 4.364136
[epoch8, step889]: loss 3.918483
[epoch8, step890]: loss 20.201168
[epoch8, step891]: loss 2.621729
[epoch8, step892]: loss 2.644707
[epoch8, step893]: loss 3.543089
[epoch8, step894]: loss 15.512339
[epoch8, step895]: loss 13.404539
[epoch8, step896]: loss 8.919678
[epoch8, step897]: loss 26.181112
[epoch8, step898]: loss 15.057352
[epoch8, step899]: loss 1.041920
[epoch8, step900]: loss 2.787344
[epoch8, step901]: loss 7.552734
[epoch8, step902]: loss 2.097107
[epoch8, step903]: loss 5.431633
[epoch8, step904]: loss 2.234393
[epoch8, step905]: loss 3.690312
[epoch8, step906]: loss 5.450024
[epoch8, step907]: loss 1.467463
[epoch8, step908]: loss 2.361646
[epoch8, step909]: loss 1.090139
[epoch8, step910]: loss 2.250772
[epoch8, step911]: loss 1.007918
[epoch8, step912]: loss 1.734140
[epoch8, step913]: loss 2.027719
[epoch8, step914]: loss 19.855097
[epoch8, step915]: loss 2.019675
[epoch8, step916]: loss 5.298048
[epoch8, step917]: loss 1.568027
[epoch8, step918]: loss 11.444600
[epoch8, step919]: loss 1.943332
[epoch8, step920]: loss 2.054826
[epoch8, step921]: loss 3.146337
[epoch8, step922]: loss 1.518998
[epoch8, step923]: loss 1.814148
[epoch8, step924]: loss 28.500038
[epoch8, step925]: loss 3.898117
[epoch8, step926]: loss 3.648858
[epoch8, step927]: loss 1.346102
[epoch8, step928]: loss 3.998531
[epoch8, step929]: loss 1.203881
[epoch8, step930]: loss 1.432852
[epoch8, step931]: loss 3.023152
[epoch8, step932]: loss 1.696402
[epoch8, step933]: loss 7.717413
[epoch8, step934]: loss 2.963367
[epoch8, step935]: loss 2.307833
[epoch8, step936]: loss 6.238602
[epoch8, step937]: loss 10.167274
[epoch8, step938]: loss 1.850347
[epoch8, step939]: loss 1.567232
[epoch8, step940]: loss 15.405179
[epoch8, step941]: loss 12.990128
[epoch8, step942]: loss 3.719414
[epoch8, step943]: loss 2.833055
[epoch8, step944]: loss 7.641047
[epoch8, step945]: loss 2.236825
[epoch8, step946]: loss 1.863310
[epoch8, step947]: loss 2.119156
[epoch8, step948]: loss 2.128935
[epoch8, step949]: loss 26.059824
[epoch8, step950]: loss 1.703490
[epoch8, step951]: loss 11.336028
[epoch8, step952]: loss 8.878398
[epoch8, step953]: loss 7.359416
[epoch8, step954]: loss 2.786925
[epoch8, step955]: loss 7.998681
[epoch8, step956]: loss 5.236020
[epoch8, step957]: loss 2.611661
[epoch8, step958]: loss 0.915463
[epoch8, step959]: loss 11.174318
[epoch8, step960]: loss 1.966144
[epoch8, step961]: loss 9.244187
[epoch8, step962]: loss 8.405426
[epoch8, step963]: loss 5.760962
[epoch8, step964]: loss 7.338077
[epoch8, step965]: loss 2.665631
[epoch8, step966]: loss 2.627141
[epoch8, step967]: loss 7.350505
[epoch8, step968]: loss 1.645540
[epoch8, step969]: loss 4.522331
[epoch8, step970]: loss 1.052959
[epoch8, step971]: loss 6.826518
[epoch8, step972]: loss 10.934358
[epoch8, step973]: loss 3.153190
[epoch8, step974]: loss 3.500054
[epoch8, step975]: loss 13.327890
[epoch8, step976]: loss 16.128248
[epoch8, step977]: loss 2.441738
[epoch8, step978]: loss 3.241848
[epoch8, step979]: loss 10.263234
[epoch8, step980]: loss 2.023775
[epoch8, step981]: loss 4.072723
[epoch8, step982]: loss 12.142828
[epoch8, step983]: loss 5.147373
[epoch8, step984]: loss 5.581248
[epoch8, step985]: loss 5.349089
[epoch8, step986]: loss 3.186995
[epoch8, step987]: loss 8.428334
[epoch8, step988]: loss 1.506850
[epoch8, step989]: loss 2.826248
[epoch8, step990]: loss 2.697556
[epoch8, step991]: loss 6.047457
[epoch8, step992]: loss 1.528154
[epoch8, step993]: loss 2.403892
[epoch8, step994]: loss 10.710757
[epoch8, step995]: loss 6.170904
[epoch8, step996]: loss 4.398218
[epoch8, step997]: loss 4.530545
[epoch8, step998]: loss 9.842417
[epoch8, step999]: loss 2.003773
[epoch8, step1000]: loss 1.400328
[epoch8, step1001]: loss 4.142562
[epoch8, step1002]: loss 3.531125
[epoch8, step1003]: loss 3.876829
[epoch8, step1004]: loss 3.101019
[epoch8, step1005]: loss 9.026738
[epoch8, step1006]: loss 8.918258
[epoch8, step1007]: loss 1.946036
[epoch8, step1008]: loss 9.019619
[epoch8, step1009]: loss 3.166697
[epoch8, step1010]: loss 3.273692
[epoch8, step1011]: loss 1.592943
[epoch8, step1012]: loss 4.265394
[epoch8, step1013]: loss 2.445331
[epoch8, step1014]: loss 1.998166
[epoch8, step1015]: loss 2.068818
[epoch8, step1016]: loss 2.387500
[epoch8, step1017]: loss 2.043884
[epoch8, step1018]: loss 2.253392
[epoch8, step1019]: loss 20.810986
[epoch8, step1020]: loss 10.529809
[epoch8, step1021]: loss 2.149169
[epoch8, step1022]: loss 1.358674
[epoch8, step1023]: loss 7.358503
[epoch8, step1024]: loss 13.235937
[epoch8, step1025]: loss 15.299367
[epoch8, step1026]: loss 3.607903
[epoch8, step1027]: loss 15.191444
[epoch8, step1028]: loss 8.601281
[epoch8, step1029]: loss 2.333673
[epoch8, step1030]: loss 1.681552
[epoch8, step1031]: loss 12.832895
[epoch8, step1032]: loss 2.262230
[epoch8, step1033]: loss 2.533442
[epoch8, step1034]: loss 2.603701
[epoch8, step1035]: loss 3.945657
[epoch8, step1036]: loss 7.988655
[epoch8, step1037]: loss 1.792562
[epoch8, step1038]: loss 2.659138
[epoch8, step1039]: loss 7.267183
[epoch8, step1040]: loss 2.438792
[epoch8, step1041]: loss 2.400925
[epoch8, step1042]: loss 1.709402
[epoch8, step1043]: loss 14.170359
[epoch8, step1044]: loss 1.199023
[epoch8, step1045]: loss 9.741488
[epoch8, step1046]: loss 7.466667
[epoch8, step1047]: loss 4.469542
[epoch8, step1048]: loss 1.910216
[epoch8, step1049]: loss 9.596333
[epoch8, step1050]: loss 2.305309
[epoch8, step1051]: loss 10.842804
[epoch8, step1052]: loss 10.458544
[epoch8, step1053]: loss 2.738762
[epoch8, step1054]: loss 1.909565
[epoch8, step1055]: loss 1.990688
[epoch8, step1056]: loss 4.702115
[epoch8, step1057]: loss 0.953383
[epoch8, step1058]: loss 2.374479
[epoch8, step1059]: loss 6.221187
[epoch8, step1060]: loss 13.715499
[epoch8, step1061]: loss 9.363339
[epoch8, step1062]: loss 1.894555
[epoch8, step1063]: loss 2.230573
[epoch8, step1064]: loss 1.589371
[epoch8, step1065]: loss 1.627468
[epoch8, step1066]: loss 1.367564
[epoch8, step1067]: loss 17.182297
[epoch8, step1068]: loss 1.448851
[epoch8, step1069]: loss 5.036882
[epoch8, step1070]: loss 1.097723
[epoch8, step1071]: loss 2.510591
[epoch8, step1072]: loss 3.969883
[epoch8, step1073]: loss 1.967083
[epoch8, step1074]: loss 2.297061
[epoch8, step1075]: loss 16.108568
[epoch8, step1076]: loss 13.408510
[epoch8, step1077]: loss 1.466718
[epoch8, step1078]: loss 3.260476
[epoch8, step1079]: loss 14.172513
[epoch8, step1080]: loss 2.534910
[epoch8, step1081]: loss 5.611822
[epoch8, step1082]: loss 6.005907
[epoch8, step1083]: loss 1.075909
[epoch8, step1084]: loss 9.561502
[epoch8, step1085]: loss 4.342659
[epoch8, step1086]: loss 1.246186
[epoch8, step1087]: loss 0.927495
[epoch8, step1088]: loss 2.784211
[epoch8, step1089]: loss 2.958078
[epoch8, step1090]: loss 2.706398
[epoch8, step1091]: loss 11.715734
[epoch8, step1092]: loss 6.591236
[epoch8, step1093]: loss 5.636082
[epoch8, step1094]: loss 11.467826
[epoch8, step1095]: loss 1.756588
[epoch8, step1096]: loss 1.842902
[epoch8, step1097]: loss 13.672009
[epoch8, step1098]: loss 1.911380
[epoch8, step1099]: loss 3.053764
[epoch8, step1100]: loss 4.740742
[epoch8, step1101]: loss 1.487903
[epoch8, step1102]: loss 2.353786
[epoch8, step1103]: loss 9.341309
[epoch8, step1104]: loss 2.075379
[epoch8, step1105]: loss 9.302567
[epoch8, step1106]: loss 8.629864
[epoch8, step1107]: loss 15.438342
[epoch8, step1108]: loss 20.235592
[epoch8, step1109]: loss 9.413214
[epoch8, step1110]: loss 2.372313
[epoch8, step1111]: loss 1.748291
[epoch8, step1112]: loss 10.220691
[epoch8, step1113]: loss 37.837486
[epoch8, step1114]: loss 5.340174
[epoch8, step1115]: loss 3.847284
[epoch8, step1116]: loss 6.969129
[epoch8, step1117]: loss 6.737942
[epoch8, step1118]: loss 3.504819
[epoch8, step1119]: loss 1.149958
[epoch8, step1120]: loss 6.090942
[epoch8, step1121]: loss 1.979344
[epoch8, step1122]: loss 4.765814
[epoch8, step1123]: loss 6.421154
[epoch8, step1124]: loss 12.816782
[epoch8, step1125]: loss 9.869586
[epoch8, step1126]: loss 5.007740
[epoch8, step1127]: loss 13.458191
[epoch8, step1128]: loss 2.610316
[epoch8, step1129]: loss 1.727844
[epoch8, step1130]: loss 1.920189
[epoch8, step1131]: loss 10.319197
[epoch8, step1132]: loss 1.867484
[epoch8, step1133]: loss 7.067509
[epoch8, step1134]: loss 6.191754
[epoch8, step1135]: loss 9.679885
[epoch8, step1136]: loss 12.736450
[epoch8, step1137]: loss 6.095450
[epoch8, step1138]: loss 12.308955
[epoch8, step1139]: loss 10.069838
[epoch8, step1140]: loss 5.186247
[epoch8, step1141]: loss 1.124566
[epoch8, step1142]: loss 1.129499
[epoch8, step1143]: loss 2.495544
[epoch8, step1144]: loss 2.389545
[epoch8, step1145]: loss 3.824662
[epoch8, step1146]: loss 10.260789
[epoch8, step1147]: loss 3.828078
[epoch8, step1148]: loss 1.233198
[epoch8, step1149]: loss 1.623400
[epoch8, step1150]: loss 3.422368
[epoch8, step1151]: loss 2.637119
[epoch8, step1152]: loss 1.225501
[epoch8, step1153]: loss 10.576283
[epoch8, step1154]: loss 1.345829
[epoch8, step1155]: loss 2.716387
[epoch8, step1156]: loss 14.628673
[epoch8, step1157]: loss 1.540982
[epoch8, step1158]: loss 2.630764
[epoch8, step1159]: loss 4.039259
[epoch8, step1160]: loss 9.765821
[epoch8, step1161]: loss 9.434743
[epoch8, step1162]: loss 15.032676
[epoch8, step1163]: loss 1.018538
[epoch8, step1164]: loss 1.699833
[epoch8, step1165]: loss 2.548348
[epoch8, step1166]: loss 0.925497
[epoch8, step1167]: loss 12.008492
[epoch8, step1168]: loss 7.144611
[epoch8, step1169]: loss 1.049150
[epoch8, step1170]: loss 1.821595
[epoch8, step1171]: loss 1.960446
[epoch8, step1172]: loss 16.459949
[epoch8, step1173]: loss 12.927279
[epoch8, step1174]: loss 1.840250
[epoch8, step1175]: loss 1.435764
[epoch8, step1176]: loss 9.728064
[epoch8, step1177]: loss 1.513131
[epoch8, step1178]: loss 6.806204
[epoch8, step1179]: loss 3.173038
[epoch8, step1180]: loss 1.938245
[epoch8, step1181]: loss 4.460417
[epoch8, step1182]: loss 9.239657
[epoch8, step1183]: loss 0.863503
[epoch8, step1184]: loss 1.480422
[epoch8, step1185]: loss 12.585461
[epoch8, step1186]: loss 1.198466
[epoch8, step1187]: loss 6.725077
[epoch8, step1188]: loss 7.688736
[epoch8, step1189]: loss 12.573082
[epoch8, step1190]: loss 13.571085
[epoch8, step1191]: loss 1.934840
[epoch8, step1192]: loss 8.162063
[epoch8, step1193]: loss 11.257571
[epoch8, step1194]: loss 1.362255
[epoch8, step1195]: loss 4.768713
[epoch8, step1196]: loss 6.337470
[epoch8, step1197]: loss 5.873338
[epoch8, step1198]: loss 7.614969
[epoch8, step1199]: loss 2.060665
[epoch8, step1200]: loss 1.824952
[epoch8, step1201]: loss 12.164700
[epoch8, step1202]: loss 3.862377
[epoch8, step1203]: loss 3.935467
[epoch8, step1204]: loss 7.860070
[epoch8, step1205]: loss 1.002814
[epoch8, step1206]: loss 8.362761
[epoch8, step1207]: loss 4.881950
[epoch8, step1208]: loss 12.477649
[epoch8, step1209]: loss 2.761370
[epoch8, step1210]: loss 6.311669
[epoch8, step1211]: loss 11.692827
[epoch8, step1212]: loss 17.765825
[epoch8, step1213]: loss 3.349299
[epoch8, step1214]: loss 16.146936
[epoch8, step1215]: loss 1.181769
[epoch8, step1216]: loss 4.229371
[epoch8, step1217]: loss 3.645013
[epoch8, step1218]: loss 13.256200
[epoch8, step1219]: loss 20.968716
[epoch8, step1220]: loss 1.219520
[epoch8, step1221]: loss 2.564499
[epoch8, step1222]: loss 1.622044
[epoch8, step1223]: loss 1.092039
[epoch8, step1224]: loss 2.627583
[epoch8, step1225]: loss 0.866911
[epoch8, step1226]: loss 11.720159
[epoch8, step1227]: loss 2.382588
[epoch8, step1228]: loss 2.096837
[epoch8, step1229]: loss 5.270811
[epoch8, step1230]: loss 4.410523
[epoch8, step1231]: loss 3.060211
[epoch8, step1232]: loss 3.759919
[epoch8, step1233]: loss 10.287526
[epoch8, step1234]: loss 10.146147
[epoch8, step1235]: loss 7.666780
[epoch8, step1236]: loss 1.701552
[epoch8, step1237]: loss 12.513878
[epoch8, step1238]: loss 3.756727
[epoch8, step1239]: loss 14.061226
[epoch8, step1240]: loss 1.483031
[epoch8, step1241]: loss 1.861351
[epoch8, step1242]: loss 1.746000
[epoch8, step1243]: loss 3.656851
[epoch8, step1244]: loss 11.598015
[epoch8, step1245]: loss 1.243267
[epoch8, step1246]: loss 7.011908
[epoch8, step1247]: loss 1.547085
[epoch8, step1248]: loss 4.332656
[epoch8, step1249]: loss 5.060345
[epoch8, step1250]: loss 1.262314
[epoch8, step1251]: loss 3.067562
[epoch8, step1252]: loss 1.002449
[epoch8, step1253]: loss 3.532979
[epoch8, step1254]: loss 13.028957
[epoch8, step1255]: loss 2.917949
[epoch8, step1256]: loss 1.889960
[epoch8, step1257]: loss 8.748364
[epoch8, step1258]: loss 1.299328
[epoch8, step1259]: loss 9.382868
[epoch8, step1260]: loss 29.209023
[epoch8, step1261]: loss 10.341528
[epoch8, step1262]: loss 1.902144
[epoch8, step1263]: loss 1.404004
[epoch8, step1264]: loss 1.165640
[epoch8, step1265]: loss 19.005560
[epoch8, step1266]: loss 3.849097
[epoch8, step1267]: loss 8.740932
[epoch8, step1268]: loss 22.417458
[epoch8, step1269]: loss 1.325273
[epoch8, step1270]: loss 1.706720
[epoch8, step1271]: loss 21.303444
[epoch8, step1272]: loss 1.880389
[epoch8, step1273]: loss 2.020219
[epoch8, step1274]: loss 3.803565
[epoch8, step1275]: loss 0.980912
[epoch8, step1276]: loss 1.000466
[epoch8, step1277]: loss 4.160524
[epoch8, step1278]: loss 3.723326
[epoch8, step1279]: loss 3.904802
[epoch8, step1280]: loss 3.874131
[epoch8, step1281]: loss 1.149315
[epoch8, step1282]: loss 1.809634
[epoch8, step1283]: loss 4.259188
[epoch8, step1284]: loss 1.252794
[epoch8, step1285]: loss 10.694301
[epoch8, step1286]: loss 3.809003
[epoch8, step1287]: loss 1.965427
[epoch8, step1288]: loss 16.688286
[epoch8, step1289]: loss 3.432861
[epoch8, step1290]: loss 2.189289
[epoch8, step1291]: loss 7.725614
[epoch8, step1292]: loss 13.247180
[epoch8, step1293]: loss 10.951748
[epoch8, step1294]: loss 18.086641
[epoch8, step1295]: loss 2.483876
[epoch8, step1296]: loss 1.473315
[epoch8, step1297]: loss 1.248626
[epoch8, step1298]: loss 2.738710
[epoch8, step1299]: loss 1.803528
[epoch8, step1300]: loss 5.330872
[epoch8, step1301]: loss 4.222375
[epoch8, step1302]: loss 3.085293
[epoch8, step1303]: loss 23.116884
[epoch8, step1304]: loss 8.428365
[epoch8, step1305]: loss 1.462733
[epoch8, step1306]: loss 1.468869
[epoch8, step1307]: loss 12.616755
[epoch8, step1308]: loss 1.861493
[epoch8, step1309]: loss 8.874042
[epoch8, step1310]: loss 1.616365
[epoch8, step1311]: loss 1.951549
[epoch8, step1312]: loss 25.939632
[epoch8, step1313]: loss 9.426071
[epoch8, step1314]: loss 11.971616
[epoch8, step1315]: loss 0.968088
[epoch8, step1316]: loss 2.700423
[epoch8, step1317]: loss 11.047717
[epoch8, step1318]: loss 15.823072
[epoch8, step1319]: loss 5.504733
[epoch8, step1320]: loss 8.925475
[epoch8, step1321]: loss 7.350139
[epoch8, step1322]: loss 17.869678
[epoch8, step1323]: loss 10.726377
[epoch8, step1324]: loss 1.702216
[epoch8, step1325]: loss 5.898106
[epoch8, step1326]: loss 10.557617
[epoch8, step1327]: loss 4.838687
[epoch8, step1328]: loss 1.643022
[epoch8, step1329]: loss 6.014566
[epoch8, step1330]: loss 14.958138
[epoch8, step1331]: loss 2.578717
[epoch8, step1332]: loss 1.605926
[epoch8, step1333]: loss 15.491959
[epoch8, step1334]: loss 10.336926
[epoch8, step1335]: loss 14.599520
[epoch8, step1336]: loss 4.956558
[epoch8, step1337]: loss 4.933159
[epoch8, step1338]: loss 3.354892
[epoch8, step1339]: loss 1.440851
[epoch8, step1340]: loss 1.209344
[epoch8, step1341]: loss 21.352919
[epoch8, step1342]: loss 1.790406
[epoch8, step1343]: loss 3.987746
[epoch8, step1344]: loss 11.348899
[epoch8, step1345]: loss 2.187417
[epoch8, step1346]: loss 4.851476
[epoch8, step1347]: loss 1.809979
[epoch8, step1348]: loss 6.107038
[epoch8, step1349]: loss 1.925055
[epoch8, step1350]: loss 4.995625
[epoch8, step1351]: loss 4.976955
[epoch8, step1352]: loss 2.784960
[epoch8, step1353]: loss 1.384321
[epoch8, step1354]: loss 1.498700
[epoch8, step1355]: loss 6.080122
[epoch8, step1356]: loss 1.104917
[epoch8, step1357]: loss 1.552824
[epoch8, step1358]: loss 4.101087
[epoch8, step1359]: loss 11.744851
[epoch8, step1360]: loss 1.860113
[epoch8, step1361]: loss 10.500425
[epoch8, step1362]: loss 3.948575
[epoch8, step1363]: loss 8.247886
[epoch8, step1364]: loss 1.707334
[epoch8, step1365]: loss 13.460695
[epoch8, step1366]: loss 11.645804
[epoch8, step1367]: loss 1.429115
[epoch8, step1368]: loss 8.125429
[epoch8, step1369]: loss 11.266849
[epoch8, step1370]: loss 15.003568
[epoch8, step1371]: loss 1.654878
[epoch8, step1372]: loss 5.151966
[epoch8, step1373]: loss 1.372697
[epoch8, step1374]: loss 3.528551
[epoch8, step1375]: loss 2.703517
[epoch8, step1376]: loss 30.373589
[epoch8, step1377]: loss 1.641343
[epoch8, step1378]: loss 3.731576
[epoch8, step1379]: loss 3.269469
[epoch8, step1380]: loss 9.538904
[epoch8, step1381]: loss 7.046469
[epoch8, step1382]: loss 10.213881
[epoch8, step1383]: loss 5.433157
[epoch8, step1384]: loss 4.281507
[epoch8, step1385]: loss 1.481289
[epoch8, step1386]: loss 10.519693
[epoch8, step1387]: loss 18.503967
[epoch8, step1388]: loss 0.939058
[epoch8, step1389]: loss 2.506724
[epoch8, step1390]: loss 6.228340
[epoch8, step1391]: loss 1.806906
[epoch8, step1392]: loss 2.249368
[epoch8, step1393]: loss 9.678938
[epoch8, step1394]: loss 3.920285
[epoch8, step1395]: loss 3.578895
[epoch8, step1396]: loss 10.038710
[epoch8, step1397]: loss 5.164290
[epoch8, step1398]: loss 5.632957
[epoch8, step1399]: loss 15.219564
[epoch8, step1400]: loss 1.990034
[epoch8, step1401]: loss 10.182110
[epoch8, step1402]: loss 1.733180
[epoch8, step1403]: loss 17.183880
[epoch8, step1404]: loss 1.522424
[epoch8, step1405]: loss 1.444224
[epoch8, step1406]: loss 4.790753
[epoch8, step1407]: loss 3.080899
[epoch8, step1408]: loss 3.546909
[epoch8, step1409]: loss 4.165153
[epoch8, step1410]: loss 2.049740
[epoch8, step1411]: loss 4.872875
[epoch8, step1412]: loss 12.748440
[epoch8, step1413]: loss 2.131959
[epoch8, step1414]: loss 3.931792
[epoch8, step1415]: loss 2.492334
[epoch8, step1416]: loss 12.027205
[epoch8, step1417]: loss 2.176256
[epoch8, step1418]: loss 1.099377
[epoch8, step1419]: loss 4.706523
[epoch8, step1420]: loss 2.093736
[epoch8, step1421]: loss 18.362429
[epoch8, step1422]: loss 18.142010
[epoch8, step1423]: loss 5.120575
[epoch8, step1424]: loss 2.611307
[epoch8, step1425]: loss 29.708122
[epoch8, step1426]: loss 6.515200
[epoch8, step1427]: loss 11.816401
[epoch8, step1428]: loss 20.069483
[epoch8, step1429]: loss 4.750258
[epoch8, step1430]: loss 7.173066
[epoch8, step1431]: loss 1.768464
[epoch8, step1432]: loss 2.333212
[epoch8, step1433]: loss 8.961518
[epoch8, step1434]: loss 1.929199
[epoch8, step1435]: loss 3.763806
[epoch8, step1436]: loss 1.097210
[epoch8, step1437]: loss 1.797836
[epoch8, step1438]: loss 23.643730
[epoch8, step1439]: loss 5.055507
[epoch8, step1440]: loss 2.288606
[epoch8, step1441]: loss 0.959386
[epoch8, step1442]: loss 14.020195
[epoch8, step1443]: loss 4.757708
[epoch8, step1444]: loss 12.725824
[epoch8, step1445]: loss 10.441769
[epoch8, step1446]: loss 9.583811
[epoch8, step1447]: loss 6.220218
[epoch8, step1448]: loss 1.579539
[epoch8, step1449]: loss 2.904818
[epoch8, step1450]: loss 5.298875
[epoch8, step1451]: loss 16.160854
[epoch8, step1452]: loss 12.824542
[epoch8, step1453]: loss 17.778076
[epoch8, step1454]: loss 1.576569
[epoch8, step1455]: loss 9.166788
[epoch8, step1456]: loss 12.425017
[epoch8, step1457]: loss 6.407326
[epoch8, step1458]: loss 1.558084
[epoch8, step1459]: loss 7.290788
[epoch8, step1460]: loss 6.174000
[epoch8, step1461]: loss 0.940079
[epoch8, step1462]: loss 1.821747
[epoch8, step1463]: loss 4.517644
[epoch8, step1464]: loss 1.291088
[epoch8, step1465]: loss 3.784509
[epoch8, step1466]: loss 1.685086
[epoch8, step1467]: loss 0.829763
[epoch8, step1468]: loss 1.531845
[epoch8, step1469]: loss 1.372648
[epoch8, step1470]: loss 13.350189
[epoch8, step1471]: loss 11.820049
[epoch8, step1472]: loss 3.105895
[epoch8, step1473]: loss 4.700918
[epoch8, step1474]: loss 9.858623
[epoch8, step1475]: loss 2.191677
[epoch8, step1476]: loss 2.014430
[epoch8, step1477]: loss 8.333734
[epoch8, step1478]: loss 10.452438
[epoch8, step1479]: loss 1.218633
[epoch8, step1480]: loss 1.410674
[epoch8, step1481]: loss 1.744172
[epoch8, step1482]: loss 1.669699
[epoch8, step1483]: loss 1.460142
[epoch8, step1484]: loss 1.492034
[epoch8, step1485]: loss 0.814798
[epoch8, step1486]: loss 1.650501
[epoch8, step1487]: loss 9.975858
[epoch8, step1488]: loss 2.211573
[epoch8, step1489]: loss 1.550274
[epoch8, step1490]: loss 8.806886
[epoch8, step1491]: loss 1.307862
[epoch8, step1492]: loss 3.612740
[epoch8, step1493]: loss 4.632015
[epoch8, step1494]: loss 6.199070
[epoch8, step1495]: loss 1.496614
[epoch8, step1496]: loss 2.292462
[epoch8, step1497]: loss 1.552724
[epoch8, step1498]: loss 2.064999
[epoch8, step1499]: loss 7.966332
[epoch8, step1500]: loss 7.858051
[epoch8, step1501]: loss 2.790104
[epoch8, step1502]: loss 5.176102
[epoch8, step1503]: loss 5.216243
[epoch8, step1504]: loss 2.914013
[epoch8, step1505]: loss 4.905945
[epoch8, step1506]: loss 1.890536
[epoch8, step1507]: loss 4.988914
[epoch8, step1508]: loss 0.675757
[epoch8, step1509]: loss 10.961528
[epoch8, step1510]: loss 2.012874
[epoch8, step1511]: loss 10.969379
[epoch8, step1512]: loss 3.870240
[epoch8, step1513]: loss 7.119705
[epoch8, step1514]: loss 11.172542
[epoch8, step1515]: loss 1.641916
[epoch8, step1516]: loss 7.266318
[epoch8, step1517]: loss 12.238207
[epoch8, step1518]: loss 1.486944
[epoch8, step1519]: loss 2.335327
[epoch8, step1520]: loss 12.685485
[epoch8, step1521]: loss 8.188285
[epoch8, step1522]: loss 1.844042
[epoch8, step1523]: loss 10.666872
[epoch8, step1524]: loss 12.313696
[epoch8, step1525]: loss 23.157526
[epoch8, step1526]: loss 17.706280
[epoch8, step1527]: loss 5.097887
[epoch8, step1528]: loss 4.788307
[epoch8, step1529]: loss 2.049281
[epoch8, step1530]: loss 8.930346
[epoch8, step1531]: loss 3.249842
[epoch8, step1532]: loss 7.151759
[epoch8, step1533]: loss 1.189863
[epoch8, step1534]: loss 11.107454
[epoch8, step1535]: loss 10.431961
[epoch8, step1536]: loss 1.272275
[epoch8, step1537]: loss 17.148710
[epoch8, step1538]: loss 2.718613
[epoch8, step1539]: loss 2.486710
[epoch8, step1540]: loss 1.158864
[epoch8, step1541]: loss 1.577972
[epoch8, step1542]: loss 11.504939
[epoch8, step1543]: loss 3.991000
[epoch8, step1544]: loss 1.716076
[epoch8, step1545]: loss 10.931819
[epoch8, step1546]: loss 2.450459
[epoch8, step1547]: loss 3.694617
[epoch8, step1548]: loss 2.782872
[epoch8, step1549]: loss 7.340453
[epoch8, step1550]: loss 4.900412
[epoch8, step1551]: loss 3.951773
[epoch8, step1552]: loss 11.744932
[epoch8, step1553]: loss 3.212167
[epoch8, step1554]: loss 1.857404
[epoch8, step1555]: loss 1.720107
[epoch8, step1556]: loss 1.386436
[epoch8, step1557]: loss 1.497224
[epoch8, step1558]: loss 4.280598
[epoch8, step1559]: loss 1.476828
[epoch8, step1560]: loss 11.681884
[epoch8, step1561]: loss 9.278041
[epoch8, step1562]: loss 2.264425
[epoch8, step1563]: loss 11.813710
[epoch8, step1564]: loss 1.437769
[epoch8, step1565]: loss 18.612530
[epoch8, step1566]: loss 2.871796
[epoch8, step1567]: loss 8.271099
[epoch8, step1568]: loss 18.106153
[epoch8, step1569]: loss 4.264512
[epoch8, step1570]: loss 1.979892
[epoch8, step1571]: loss 17.482470
[epoch8, step1572]: loss 2.015277
[epoch8, step1573]: loss 1.304992
[epoch8, step1574]: loss 20.311110
[epoch8, step1575]: loss 1.683703
[epoch8, step1576]: loss 2.117509
[epoch8, step1577]: loss 1.095910
[epoch8, step1578]: loss 8.470157
[epoch8, step1579]: loss 1.388567
[epoch8, step1580]: loss 8.894455
[epoch8, step1581]: loss 2.351408
[epoch8, step1582]: loss 11.522863
[epoch8, step1583]: loss 3.384868
[epoch8, step1584]: loss 2.401920
[epoch8, step1585]: loss 1.770892
[epoch8, step1586]: loss 10.915233
[epoch8, step1587]: loss 2.633955
[epoch8, step1588]: loss 7.898863
[epoch8, step1589]: loss 4.514280
[epoch8, step1590]: loss 1.432626
[epoch8, step1591]: loss 1.324080
[epoch8, step1592]: loss 2.303479
[epoch8, step1593]: loss 11.802098
[epoch8, step1594]: loss 6.730952
[epoch8, step1595]: loss 9.267733
[epoch8, step1596]: loss 2.902138
[epoch8, step1597]: loss 8.159811
[epoch8, step1598]: loss 7.179009
[epoch8, step1599]: loss 1.772186
[epoch8, step1600]: loss 1.911288
[epoch8, step1601]: loss 9.394934
[epoch8, step1602]: loss 2.080065
[epoch8, step1603]: loss 5.144889
[epoch8, step1604]: loss 11.914905
[epoch8, step1605]: loss 3.233699
[epoch8, step1606]: loss 7.226840
[epoch8, step1607]: loss 9.110423
[epoch8, step1608]: loss 4.397029
[epoch8, step1609]: loss 2.152616
[epoch8, step1610]: loss 3.437743
[epoch8, step1611]: loss 1.103323
[epoch8, step1612]: loss 2.359961
[epoch8, step1613]: loss 3.084408
[epoch8, step1614]: loss 1.691864
[epoch8, step1615]: loss 3.737648
[epoch8, step1616]: loss 2.954776
[epoch8, step1617]: loss 1.780284
[epoch8, step1618]: loss 2.296820
[epoch8, step1619]: loss 1.191902
[epoch8, step1620]: loss 13.214793
[epoch8, step1621]: loss 9.182490
[epoch8, step1622]: loss 2.790849
[epoch8, step1623]: loss 9.920641
[epoch8, step1624]: loss 1.649286
[epoch8, step1625]: loss 3.762327
[epoch8, step1626]: loss 13.453518
[epoch8, step1627]: loss 12.846802
[epoch8, step1628]: loss 4.210830
[epoch8, step1629]: loss 6.765628
[epoch8, step1630]: loss 6.135414
[epoch8, step1631]: loss 9.168966
[epoch8, step1632]: loss 1.872013
[epoch8, step1633]: loss 1.124991
[epoch8, step1634]: loss 1.890488
[epoch8, step1635]: loss 9.772076
[epoch8, step1636]: loss 6.065864
[epoch8, step1637]: loss 1.794346
[epoch8, step1638]: loss 6.756757
[epoch8, step1639]: loss 13.397173
[epoch8, step1640]: loss 15.285653
[epoch8, step1641]: loss 9.667610
[epoch8, step1642]: loss 3.841720
[epoch8, step1643]: loss 11.492352
[epoch8, step1644]: loss 11.994012
[epoch8, step1645]: loss 2.601641
[epoch8, step1646]: loss 7.812767
[epoch8, step1647]: loss 3.286558
[epoch8, step1648]: loss 1.776005
[epoch8, step1649]: loss 11.436559
[epoch8, step1650]: loss 1.482338
[epoch8, step1651]: loss 1.835757
[epoch8, step1652]: loss 1.801312
[epoch8, step1653]: loss 10.798270
[epoch8, step1654]: loss 13.950573
[epoch8, step1655]: loss 2.699385
[epoch8, step1656]: loss 5.994765
[epoch8, step1657]: loss 3.700664
[epoch8, step1658]: loss 11.893890
[epoch8, step1659]: loss 1.565334
[epoch8, step1660]: loss 15.725464
[epoch8, step1661]: loss 7.678592
[epoch8, step1662]: loss 1.919173
[epoch8, step1663]: loss 7.163116
[epoch8, step1664]: loss 3.346906
[epoch8, step1665]: loss 1.148746
[epoch8, step1666]: loss 4.362987
[epoch8, step1667]: loss 1.472214
[epoch8, step1668]: loss 1.703725
[epoch8, step1669]: loss 4.334058
[epoch8, step1670]: loss 1.187371
[epoch8, step1671]: loss 9.233521
[epoch8, step1672]: loss 8.786415
[epoch8, step1673]: loss 2.147863
[epoch8, step1674]: loss 4.265385
[epoch8, step1675]: loss 1.219264
[epoch8, step1676]: loss 13.200918
[epoch8, step1677]: loss 13.229984
[epoch8, step1678]: loss 1.378414
[epoch8, step1679]: loss 1.264976
[epoch8, step1680]: loss 16.324278
[epoch8, step1681]: loss 1.259083
[epoch8, step1682]: loss 1.460579
[epoch8, step1683]: loss 2.712756
[epoch8, step1684]: loss 22.011766
[epoch8, step1685]: loss 2.434408
[epoch8, step1686]: loss 7.577456
[epoch8, step1687]: loss 1.871800
[epoch8, step1688]: loss 4.673506
[epoch8, step1689]: loss 4.093537
[epoch8, step1690]: loss 9.709715
[epoch8, step1691]: loss 2.426931
[epoch8, step1692]: loss 10.056404
[epoch8, step1693]: loss 11.206746
[epoch8, step1694]: loss 5.393093
[epoch8, step1695]: loss 5.168236
[epoch8, step1696]: loss 8.544840
[epoch8, step1697]: loss 2.619220
[epoch8, step1698]: loss 4.042758
[epoch8, step1699]: loss 2.449615
[epoch8, step1700]: loss 12.121039
[epoch8, step1701]: loss 2.168804
[epoch8, step1702]: loss 6.262778
[epoch8, step1703]: loss 2.484416
[epoch8, step1704]: loss 3.972125
[epoch8, step1705]: loss 1.365855
[epoch8, step1706]: loss 4.094556
[epoch8, step1707]: loss 1.777154
[epoch8, step1708]: loss 12.037165
[epoch8, step1709]: loss 6.043239
[epoch8, step1710]: loss 2.113478
[epoch8, step1711]: loss 2.558022
[epoch8, step1712]: loss 2.258584
[epoch8, step1713]: loss 2.160202
[epoch8, step1714]: loss 5.478513
[epoch8, step1715]: loss 3.486401
[epoch8, step1716]: loss 7.911894
[epoch8, step1717]: loss 8.609849
[epoch8, step1718]: loss 5.220268
[epoch8, step1719]: loss 22.065052
[epoch8, step1720]: loss 1.346829
[epoch8, step1721]: loss 1.205546
[epoch8, step1722]: loss 3.618400
[epoch8, step1723]: loss 5.338017
[epoch8, step1724]: loss 27.150648
[epoch8, step1725]: loss 5.384044
[epoch8, step1726]: loss 8.389323
[epoch8, step1727]: loss 1.902598
[epoch8, step1728]: loss 10.355978
[epoch8, step1729]: loss 1.128207
[epoch8, step1730]: loss 15.129310
[epoch8, step1731]: loss 1.101594
[epoch8, step1732]: loss 2.302752
[epoch8, step1733]: loss 2.050216
[epoch8, step1734]: loss 2.116442
[epoch8, step1735]: loss 6.832284
[epoch8, step1736]: loss 16.077618
[epoch8, step1737]: loss 3.510870
[epoch8, step1738]: loss 1.600033
[epoch8, step1739]: loss 3.465080
[epoch8, step1740]: loss 1.067753
[epoch8, step1741]: loss 1.643799
[epoch8, step1742]: loss 1.260942
[epoch8, step1743]: loss 1.200412
[epoch8, step1744]: loss 5.815375
[epoch8, step1745]: loss 2.486798
[epoch8, step1746]: loss 5.199481
[epoch8, step1747]: loss 1.967643
[epoch8, step1748]: loss 11.130112
[epoch8, step1749]: loss 6.117594
[epoch8, step1750]: loss 5.025194
[epoch8, step1751]: loss 6.733168
[epoch8, step1752]: loss 27.194834
[epoch8, step1753]: loss 8.848821
[epoch8, step1754]: loss 11.835779
[epoch8, step1755]: loss 3.313990
[epoch8, step1756]: loss 23.920092
[epoch8, step1757]: loss 9.454659
[epoch8, step1758]: loss 1.267973
[epoch8, step1759]: loss 10.510197
[epoch8, step1760]: loss 7.770258
[epoch8, step1761]: loss 4.311459
[epoch8, step1762]: loss 1.454836
[epoch8, step1763]: loss 6.109921
[epoch8, step1764]: loss 3.360645
[epoch8, step1765]: loss 11.005763
[epoch8, step1766]: loss 13.055841
[epoch8, step1767]: loss 1.463154
[epoch8, step1768]: loss 5.468946
[epoch8, step1769]: loss 10.753539
[epoch8, step1770]: loss 11.426389
[epoch8, step1771]: loss 11.946672
[epoch8, step1772]: loss 1.177840
[epoch8, step1773]: loss 16.898426
[epoch8, step1774]: loss 1.198580
[epoch8, step1775]: loss 1.636057
[epoch8, step1776]: loss 2.428442
[epoch8, step1777]: loss 1.655672
[epoch8, step1778]: loss 2.735346
[epoch8, step1779]: loss 11.834197
[epoch8, step1780]: loss 15.088819
[epoch8, step1781]: loss 1.373335
[epoch8, step1782]: loss 7.558699
[epoch8, step1783]: loss 4.976169
[epoch8, step1784]: loss 5.670808
[epoch8, step1785]: loss 4.480879
[epoch8, step1786]: loss 2.772269
[epoch8, step1787]: loss 8.777744
[epoch8, step1788]: loss 4.071674
[epoch8, step1789]: loss 5.347576
[epoch8, step1790]: loss 13.314084
[epoch8, step1791]: loss 12.999619
[epoch8, step1792]: loss 13.633255
[epoch8, step1793]: loss 3.651840
[epoch8, step1794]: loss 3.143874
[epoch8, step1795]: loss 2.930850
[epoch8, step1796]: loss 1.321190
[epoch8, step1797]: loss 1.239619
[epoch8, step1798]: loss 10.666447
[epoch8, step1799]: loss 4.567043
[epoch8, step1800]: loss 4.916502
[epoch8, step1801]: loss 11.805041
[epoch8, step1802]: loss 12.154592
[epoch8, step1803]: loss 3.923741
[epoch8, step1804]: loss 1.174036
[epoch8, step1805]: loss 9.834851
[epoch8, step1806]: loss 1.501005
[epoch8, step1807]: loss 1.501670
[epoch8, step1808]: loss 4.849491
[epoch8, step1809]: loss 9.381167
[epoch8, step1810]: loss 5.705198
[epoch8, step1811]: loss 12.728122
[epoch8, step1812]: loss 1.033952
[epoch8, step1813]: loss 11.991181
[epoch8, step1814]: loss 4.257169
[epoch8, step1815]: loss 7.245792
[epoch8, step1816]: loss 2.792573
[epoch8, step1817]: loss 2.260857
[epoch8, step1818]: loss 3.525092
[epoch8, step1819]: loss 16.522362
[epoch8, step1820]: loss 1.983436
[epoch8, step1821]: loss 2.573592
[epoch8, step1822]: loss 22.795147
[epoch8, step1823]: loss 11.231311
[epoch8, step1824]: loss 4.945382
[epoch8, step1825]: loss 10.356940
[epoch8, step1826]: loss 3.003485
[epoch8, step1827]: loss 1.606335
[epoch8, step1828]: loss 7.098662
[epoch8, step1829]: loss 1.303070
[epoch8, step1830]: loss 2.730008
[epoch8, step1831]: loss 9.966253
[epoch8, step1832]: loss 11.764375
[epoch8, step1833]: loss 5.941677
[epoch8, step1834]: loss 10.682448
[epoch8, step1835]: loss 12.675357
[epoch8, step1836]: loss 11.554336
[epoch8, step1837]: loss 15.168507
[epoch8, step1838]: loss 10.049892
[epoch8, step1839]: loss 2.008025
[epoch8, step1840]: loss 1.511254
[epoch8, step1841]: loss 2.104190
[epoch8, step1842]: loss 2.665190
[epoch8, step1843]: loss 6.221002
[epoch8, step1844]: loss 11.429124
[epoch8, step1845]: loss 1.919980
[epoch8, step1846]: loss 3.651898
[epoch8, step1847]: loss 9.886320
[epoch8, step1848]: loss 1.403249
[epoch8, step1849]: loss 4.839898
[epoch8, step1850]: loss 1.463282
[epoch8, step1851]: loss 20.106277
[epoch8, step1852]: loss 2.105089
[epoch8, step1853]: loss 4.512849
[epoch8, step1854]: loss 13.524854
[epoch8, step1855]: loss 1.985681
[epoch8, step1856]: loss 2.971632
[epoch8, step1857]: loss 8.181609
[epoch8, step1858]: loss 1.599271
[epoch8, step1859]: loss 1.717732
[epoch8, step1860]: loss 15.527095
[epoch8, step1861]: loss 4.287213
[epoch8, step1862]: loss 3.427392
[epoch8, step1863]: loss 12.054179
[epoch8, step1864]: loss 2.948320
[epoch8, step1865]: loss 2.338334
[epoch8, step1866]: loss 10.704573
[epoch8, step1867]: loss 1.336726
[epoch8, step1868]: loss 14.050033
[epoch8, step1869]: loss 3.086720
[epoch8, step1870]: loss 4.030352
[epoch8, step1871]: loss 11.172498
[epoch8, step1872]: loss 1.923182
[epoch8, step1873]: loss 10.157402
[epoch8, step1874]: loss 10.031305
[epoch8, step1875]: loss 9.089904
[epoch8, step1876]: loss 8.537128
[epoch8, step1877]: loss 6.645099
[epoch8, step1878]: loss 11.183565
[epoch8, step1879]: loss 13.980190
[epoch8, step1880]: loss 2.141037
[epoch8, step1881]: loss 4.993730
[epoch8, step1882]: loss 2.700490
[epoch8, step1883]: loss 0.825368
[epoch8, step1884]: loss 1.573126
[epoch8, step1885]: loss 17.306917
[epoch8, step1886]: loss 16.620432
[epoch8, step1887]: loss 13.182283
[epoch8, step1888]: loss 4.715604
[epoch8, step1889]: loss 13.994747
[epoch8, step1890]: loss 5.867768
[epoch8, step1891]: loss 1.798875
[epoch8, step1892]: loss 5.749447
[epoch8, step1893]: loss 1.683591
[epoch8, step1894]: loss 14.745319
[epoch8, step1895]: loss 4.548344
[epoch8, step1896]: loss 1.207460
[epoch8, step1897]: loss 1.457196
[epoch8, step1898]: loss 8.994475
[epoch8, step1899]: loss 2.303594
[epoch8, step1900]: loss 1.311590
[epoch8, step1901]: loss 6.818403
[epoch8, step1902]: loss 13.845998
[epoch8, step1903]: loss 2.566653
[epoch8, step1904]: loss 5.329126
[epoch8, step1905]: loss 9.247738
[epoch8, step1906]: loss 9.270967
[epoch8, step1907]: loss 5.708078
[epoch8, step1908]: loss 6.352323
[epoch8, step1909]: loss 1.901522
[epoch8, step1910]: loss 4.267607
[epoch8, step1911]: loss 1.236518
[epoch8, step1912]: loss 1.408247
[epoch8, step1913]: loss 18.894630
[epoch8, step1914]: loss 2.842075
[epoch8, step1915]: loss 9.142703
[epoch8, step1916]: loss 19.419769
[epoch8, step1917]: loss 1.894615
[epoch8, step1918]: loss 10.103747
[epoch8, step1919]: loss 14.081779
[epoch8, step1920]: loss 4.446712
[epoch8, step1921]: loss 2.066100
[epoch8, step1922]: loss 2.638973
[epoch8, step1923]: loss 11.162695
[epoch8, step1924]: loss 1.760682
[epoch8, step1925]: loss 18.031286
[epoch8, step1926]: loss 1.432622
[epoch8, step1927]: loss 13.411942
[epoch8, step1928]: loss 1.350199
[epoch8, step1929]: loss 1.719113
[epoch8, step1930]: loss 1.907703
[epoch8, step1931]: loss 2.041190
[epoch8, step1932]: loss 16.242357
[epoch8, step1933]: loss 1.885393
[epoch8, step1934]: loss 4.623594
[epoch8, step1935]: loss 3.815443
[epoch8, step1936]: loss 1.704520
[epoch8, step1937]: loss 1.722388
[epoch8, step1938]: loss 1.442430
[epoch8, step1939]: loss 1.667297
[epoch8, step1940]: loss 1.610503
[epoch8, step1941]: loss 3.493989
[epoch8, step1942]: loss 12.733283
[epoch8, step1943]: loss 15.125436
[epoch8, step1944]: loss 5.553945
[epoch8, step1945]: loss 1.646638
[epoch8, step1946]: loss 10.259522
[epoch8, step1947]: loss 2.819373
[epoch8, step1948]: loss 4.916371
[epoch8, step1949]: loss 2.827009
[epoch8, step1950]: loss 4.074229
[epoch8, step1951]: loss 1.178525
[epoch8, step1952]: loss 0.955578
[epoch8, step1953]: loss 1.752845
[epoch8, step1954]: loss 3.728320
[epoch8, step1955]: loss 1.941028
[epoch8, step1956]: loss 3.664715
[epoch8, step1957]: loss 4.979647
[epoch8, step1958]: loss 2.666636
[epoch8, step1959]: loss 35.972027
[epoch8, step1960]: loss 3.319849
[epoch8, step1961]: loss 6.068576
[epoch8, step1962]: loss 3.672739
[epoch8, step1963]: loss 6.172913
[epoch8, step1964]: loss 3.509376
[epoch8, step1965]: loss 8.554186
[epoch8, step1966]: loss 11.705546
[epoch8, step1967]: loss 2.773219
[epoch8, step1968]: loss 3.702166
[epoch8, step1969]: loss 1.754070
[epoch8, step1970]: loss 6.276148
[epoch8, step1971]: loss 1.221017
[epoch8, step1972]: loss 2.046733
[epoch8, step1973]: loss 6.743986
[epoch8, step1974]: loss 3.642122
[epoch8, step1975]: loss 4.705496
[epoch8, step1976]: loss 3.912771
[epoch8, step1977]: loss 8.029362
[epoch8, step1978]: loss 3.304408
[epoch8, step1979]: loss 11.983156
[epoch8, step1980]: loss 4.827606
[epoch8, step1981]: loss 2.316747
[epoch8, step1982]: loss 7.228108
[epoch8, step1983]: loss 9.100929
[epoch8, step1984]: loss 6.409895
[epoch8, step1985]: loss 2.214205
[epoch8, step1986]: loss 4.817488
[epoch8, step1987]: loss 1.587405
[epoch8, step1988]: loss 3.076144
[epoch8, step1989]: loss 10.731774
[epoch8, step1990]: loss 3.762202
[epoch8, step1991]: loss 23.404537
[epoch8, step1992]: loss 17.822315
[epoch8, step1993]: loss 1.608961
[epoch8, step1994]: loss 6.433691
[epoch8, step1995]: loss 1.744182
[epoch8, step1996]: loss 1.134339
[epoch8, step1997]: loss 12.506899
[epoch8, step1998]: loss 4.290133
[epoch8, step1999]: loss 0.977897
[epoch8, step2000]: loss 3.537496
[epoch8, step2001]: loss 1.605654
[epoch8, step2002]: loss 2.347949
[epoch8, step2003]: loss 2.866406
[epoch8, step2004]: loss 5.845619
[epoch8, step2005]: loss 3.305521
[epoch8, step2006]: loss 1.275618
[epoch8, step2007]: loss 9.485175
[epoch8, step2008]: loss 2.515927
[epoch8, step2009]: loss 1.357284
[epoch8, step2010]: loss 1.245557
[epoch8, step2011]: loss 16.142113
[epoch8, step2012]: loss 3.126489
[epoch8, step2013]: loss 1.325845
[epoch8, step2014]: loss 4.142171
[epoch8, step2015]: loss 1.322021
[epoch8, step2016]: loss 3.174889
[epoch8, step2017]: loss 1.599127
[epoch8, step2018]: loss 1.825840
[epoch8, step2019]: loss 2.044939
[epoch8, step2020]: loss 31.619358
[epoch8, step2021]: loss 3.329301
[epoch8, step2022]: loss 4.975661
[epoch8, step2023]: loss 11.302900
[epoch8, step2024]: loss 1.237725
[epoch8, step2025]: loss 1.524277
[epoch8, step2026]: loss 1.359126
[epoch8, step2027]: loss 5.171746
[epoch8, step2028]: loss 13.799409
[epoch8, step2029]: loss 1.254855
[epoch8, step2030]: loss 10.991960
[epoch8, step2031]: loss 3.581085
[epoch8, step2032]: loss 2.585822
[epoch8, step2033]: loss 5.641481
[epoch8, step2034]: loss 2.537858
[epoch8, step2035]: loss 1.046947
[epoch8, step2036]: loss 4.249359
[epoch8, step2037]: loss 10.867591
[epoch8, step2038]: loss 8.268104
[epoch8, step2039]: loss 5.361792
[epoch8, step2040]: loss 4.144719
[epoch8, step2041]: loss 1.289869
[epoch8, step2042]: loss 2.357710
[epoch8, step2043]: loss 3.000631
[epoch8, step2044]: loss 4.104719
[epoch8, step2045]: loss 3.852568
[epoch8, step2046]: loss 4.886925
[epoch8, step2047]: loss 5.454589
[epoch8, step2048]: loss 5.497119
[epoch8, step2049]: loss 1.459418
[epoch8, step2050]: loss 1.254989
[epoch8, step2051]: loss 10.113407
[epoch8, step2052]: loss 8.495148
[epoch8, step2053]: loss 5.210222
[epoch8, step2054]: loss 1.116167
[epoch8, step2055]: loss 1.477268
[epoch8, step2056]: loss 1.210847
[epoch8, step2057]: loss 3.366707
[epoch8, step2058]: loss 9.894484
[epoch8, step2059]: loss 6.419287
[epoch8, step2060]: loss 3.265396
[epoch8, step2061]: loss 3.539553
[epoch8, step2062]: loss 1.103386
[epoch8, step2063]: loss 4.770226
[epoch8, step2064]: loss 1.420301
[epoch8, step2065]: loss 4.241963
[epoch8, step2066]: loss 1.128626
[epoch8, step2067]: loss 1.782879
[epoch8, step2068]: loss 19.052301
[epoch8, step2069]: loss 12.567322
[epoch8, step2070]: loss 10.681213
[epoch8, step2071]: loss 1.459381
[epoch8, step2072]: loss 1.413011
[epoch8, step2073]: loss 15.608081
[epoch8, step2074]: loss 1.384779
[epoch8, step2075]: loss 1.870509
[epoch8, step2076]: loss 1.283397
[epoch8, step2077]: loss 1.639649
[epoch8, step2078]: loss 5.177443
[epoch8, step2079]: loss 1.608467
[epoch8, step2080]: loss 6.241079
[epoch8, step2081]: loss 1.653119
[epoch8, step2082]: loss 4.735289
[epoch8, step2083]: loss 4.912719
[epoch8, step2084]: loss 2.353935
[epoch8, step2085]: loss 1.084229
[epoch8, step2086]: loss 1.946702
[epoch8, step2087]: loss 1.432979
[epoch8, step2088]: loss 3.620908
[epoch8, step2089]: loss 1.954395
[epoch8, step2090]: loss 14.811358
[epoch8, step2091]: loss 15.239444
[epoch8, step2092]: loss 11.311252
[epoch8, step2093]: loss 1.515828
[epoch8, step2094]: loss 3.127900
[epoch8, step2095]: loss 1.202196
[epoch8, step2096]: loss 2.600645
[epoch8, step2097]: loss 9.980639
[epoch8, step2098]: loss 6.879487
[epoch8, step2099]: loss 1.195694
[epoch8, step2100]: loss 2.076952
[epoch8, step2101]: loss 0.966320
[epoch8, step2102]: loss 1.892994
[epoch8, step2103]: loss 1.221284
[epoch8, step2104]: loss 1.213114
[epoch8, step2105]: loss 1.610783
[epoch8, step2106]: loss 1.666216
[epoch8, step2107]: loss 2.038028
[epoch8, step2108]: loss 14.401823
[epoch8, step2109]: loss 0.935046
[epoch8, step2110]: loss 13.778643
[epoch8, step2111]: loss 2.671604
[epoch8, step2112]: loss 7.537118
[epoch8, step2113]: loss 2.120377
[epoch8, step2114]: loss 11.825747
[epoch8, step2115]: loss 9.880747
[epoch8, step2116]: loss 13.576431
[epoch8, step2117]: loss 1.802395
[epoch8, step2118]: loss 11.514736
[epoch8, step2119]: loss 1.638628
[epoch8, step2120]: loss 2.509598
[epoch8, step2121]: loss 1.609087
[epoch8, step2122]: loss 1.433141
[epoch8, step2123]: loss 10.466413
[epoch8, step2124]: loss 8.208717
[epoch8, step2125]: loss 2.053151
[epoch8, step2126]: loss 11.454915
[epoch8, step2127]: loss 1.883812
[epoch8, step2128]: loss 5.996769
[epoch8, step2129]: loss 3.805063
[epoch8, step2130]: loss 2.027266
[epoch8, step2131]: loss 1.568844
[epoch8, step2132]: loss 10.085317
[epoch8, step2133]: loss 8.912906
[epoch8, step2134]: loss 3.768627
[epoch8, step2135]: loss 21.047754
[epoch8, step2136]: loss 1.746627
[epoch8, step2137]: loss 9.039055
[epoch8, step2138]: loss 1.884499
[epoch8, step2139]: loss 3.139027
[epoch8, step2140]: loss 1.723352
[epoch8, step2141]: loss 14.805223
[epoch8, step2142]: loss 6.871732
[epoch8, step2143]: loss 1.900592
[epoch8, step2144]: loss 5.807848
[epoch8, step2145]: loss 2.092181
[epoch8, step2146]: loss 17.959705
[epoch8, step2147]: loss 2.267410
[epoch8, step2148]: loss 12.997931
[epoch8, step2149]: loss 3.602602
[epoch8, step2150]: loss 17.168373
[epoch8, step2151]: loss 1.396381
[epoch8, step2152]: loss 1.695876
[epoch8, step2153]: loss 2.033129
[epoch8, step2154]: loss 5.645075
[epoch8, step2155]: loss 18.041693
[epoch8, step2156]: loss 8.589518
[epoch8, step2157]: loss 2.078924
[epoch8, step2158]: loss 15.163698
[epoch8, step2159]: loss 10.325406
[epoch8, step2160]: loss 1.436829
[epoch8, step2161]: loss 9.153728
[epoch8, step2162]: loss 2.722059
[epoch8, step2163]: loss 3.544527
[epoch8, step2164]: loss 1.408703
[epoch8, step2165]: loss 11.326683
[epoch8, step2166]: loss 3.999829
[epoch8, step2167]: loss 3.992463
[epoch8, step2168]: loss 3.686733
[epoch8, step2169]: loss 11.929628
[epoch8, step2170]: loss 11.039167
[epoch8, step2171]: loss 13.260985
[epoch8, step2172]: loss 4.960356
[epoch8, step2173]: loss 3.758746
[epoch8, step2174]: loss 4.653697
[epoch8, step2175]: loss 13.729856
[epoch8, step2176]: loss 17.716345
[epoch8, step2177]: loss 4.368836
[epoch8, step2178]: loss 8.415993
[epoch8, step2179]: loss 12.829747
[epoch8, step2180]: loss 2.673913
[epoch8, step2181]: loss 14.126796
[epoch8, step2182]: loss 38.117386
[epoch8, step2183]: loss 1.840617
[epoch8, step2184]: loss 1.606751
[epoch8, step2185]: loss 21.345118
[epoch8, step2186]: loss 9.785214
[epoch8, step2187]: loss 3.762999
[epoch8, step2188]: loss 16.804482
[epoch8, step2189]: loss 9.189266
[epoch8, step2190]: loss 3.304763
[epoch8, step2191]: loss 1.381713
[epoch8, step2192]: loss 13.005726
[epoch8, step2193]: loss 9.734252
[epoch8, step2194]: loss 7.200598
[epoch8, step2195]: loss 7.551486
[epoch8, step2196]: loss 7.718049
[epoch8, step2197]: loss 1.376464
[epoch8, step2198]: loss 2.014507
[epoch8, step2199]: loss 1.686658
[epoch8, step2200]: loss 2.618407
[epoch8, step2201]: loss 14.877149
[epoch8, step2202]: loss 10.273090
[epoch8, step2203]: loss 1.251449
[epoch8, step2204]: loss 1.411639
[epoch8, step2205]: loss 1.077223
[epoch8, step2206]: loss 9.357361
[epoch8, step2207]: loss 14.771977
[epoch8, step2208]: loss 2.312746
[epoch8, step2209]: loss 1.527611
[epoch8, step2210]: loss 1.092042
[epoch8, step2211]: loss 1.405753
[epoch8, step2212]: loss 3.732201
[epoch8, step2213]: loss 3.355464
[epoch8, step2214]: loss 3.414533
[epoch8, step2215]: loss 8.555367
[epoch8, step2216]: loss 11.403367
[epoch8, step2217]: loss 5.339374
[epoch8, step2218]: loss 17.559130
[epoch8, step2219]: loss 1.040533
[epoch8, step2220]: loss 1.012641
[epoch8, step2221]: loss 1.043527
[epoch8, step2222]: loss 12.510276
[epoch8, step2223]: loss 3.791316
[epoch8, step2224]: loss 2.324961
[epoch8, step2225]: loss 1.428418
[epoch8, step2226]: loss 1.563898
[epoch8, step2227]: loss 1.656868
[epoch8, step2228]: loss 13.372503
[epoch8, step2229]: loss 12.306838
[epoch8, step2230]: loss 1.632112
[epoch8, step2231]: loss 1.397368
[epoch8, step2232]: loss 1.597021
[epoch8, step2233]: loss 12.600262
[epoch8, step2234]: loss 1.668391
[epoch8, step2235]: loss 1.327345
[epoch8, step2236]: loss 1.604628
[epoch8, step2237]: loss 2.259341
[epoch8, step2238]: loss 11.193066
[epoch8, step2239]: loss 5.191522
[epoch8, step2240]: loss 20.781216
[epoch8, step2241]: loss 9.156499
[epoch8, step2242]: loss 5.503082
[epoch8, step2243]: loss 12.268476
[epoch8, step2244]: loss 1.367187
[epoch8, step2245]: loss 3.539739
[epoch8, step2246]: loss 1.987068
[epoch8, step2247]: loss 7.031109
[epoch8, step2248]: loss 1.494680
[epoch8, step2249]: loss 21.321304
[epoch8, step2250]: loss 1.636319
[epoch8, step2251]: loss 9.526619
[epoch8, step2252]: loss 7.875540
[epoch8, step2253]: loss 10.683277
[epoch8, step2254]: loss 14.773561
[epoch8, step2255]: loss 1.857395
[epoch8, step2256]: loss 11.498364
[epoch8, step2257]: loss 11.263910
[epoch8, step2258]: loss 10.031902
[epoch8, step2259]: loss 12.112955
[epoch8, step2260]: loss 1.054179
[epoch8, step2261]: loss 2.239584
[epoch8, step2262]: loss 1.924465
[epoch8, step2263]: loss 1.156768
[epoch8, step2264]: loss 1.150110
[epoch8, step2265]: loss 2.099897
[epoch8, step2266]: loss 8.237821
[epoch8, step2267]: loss 2.706136
[epoch8, step2268]: loss 2.953665
[epoch8, step2269]: loss 3.037440
[epoch8, step2270]: loss 5.115713
[epoch8, step2271]: loss 8.483210
[epoch8, step2272]: loss 9.803383
[epoch8, step2273]: loss 13.250366
[epoch8, step2274]: loss 1.996485
[epoch8, step2275]: loss 1.631841
[epoch8, step2276]: loss 6.131068
[epoch8, step2277]: loss 7.768663
[epoch8, step2278]: loss 11.853400
[epoch8, step2279]: loss 2.022964
[epoch8, step2280]: loss 1.466732
[epoch8, step2281]: loss 1.587182
[epoch8, step2282]: loss 1.690329
[epoch8, step2283]: loss 8.639574
[epoch8, step2284]: loss 2.061726
[epoch8, step2285]: loss 5.765285
[epoch8, step2286]: loss 2.841905
[epoch8, step2287]: loss 11.962959
[epoch8, step2288]: loss 15.578638
[epoch8, step2289]: loss 5.919671
[epoch8, step2290]: loss 4.445673
[epoch8, step2291]: loss 1.750072
[epoch8, step2292]: loss 1.541732
[epoch8, step2293]: loss 35.783089
[epoch8, step2294]: loss 2.765607
[epoch8, step2295]: loss 5.798354
[epoch8, step2296]: loss 18.068819
[epoch8, step2297]: loss 13.504138
[epoch8, step2298]: loss 8.248447
[epoch8, step2299]: loss 1.708282
[epoch8, step2300]: loss 18.711477
[epoch8, step2301]: loss 1.369302
[epoch8, step2302]: loss 1.184001
[epoch8, step2303]: loss 6.708065
[epoch8, step2304]: loss 1.280425
[epoch8, step2305]: loss 10.441811
[epoch8, step2306]: loss 3.914465
[epoch8, step2307]: loss 5.433974
[epoch8, step2308]: loss 4.165120
[epoch8, step2309]: loss 33.003712
[epoch8, step2310]: loss 1.188576
[epoch8, step2311]: loss 2.588110
[epoch8, step2312]: loss 9.048895
[epoch8, step2313]: loss 1.097395
[epoch8, step2314]: loss 1.048406
[epoch8, step2315]: loss 1.494362
[epoch8, step2316]: loss 3.432879
[epoch8, step2317]: loss 11.851580
[epoch8, step2318]: loss 8.267061
[epoch8, step2319]: loss 12.380614
[epoch8, step2320]: loss 2.327427
[epoch8, step2321]: loss 10.569435
[epoch8, step2322]: loss 1.487783
[epoch8, step2323]: loss 1.683953
[epoch8, step2324]: loss 3.841764
[epoch8, step2325]: loss 1.346845
[epoch8, step2326]: loss 11.672813
[epoch8, step2327]: loss 2.227386
[epoch8, step2328]: loss 16.976933
[epoch8, step2329]: loss 8.407963
[epoch8, step2330]: loss 20.698183
[epoch8, step2331]: loss 14.561707
[epoch8, step2332]: loss 1.049770
[epoch8, step2333]: loss 0.948323
[epoch8, step2334]: loss 0.922157
[epoch8, step2335]: loss 1.451767
[epoch8, step2336]: loss 8.393496
[epoch8, step2337]: loss 1.455055
[epoch8, step2338]: loss 1.383735
[epoch8, step2339]: loss 3.508318
[epoch8, step2340]: loss 1.557857
[epoch8, step2341]: loss 1.432843
[epoch8, step2342]: loss 2.119422
[epoch8, step2343]: loss 2.475960
[epoch8, step2344]: loss 7.174548
[epoch8, step2345]: loss 1.783074
[epoch8, step2346]: loss 8.801814
[epoch8, step2347]: loss 3.568448
[epoch8, step2348]: loss 4.757040
[epoch8, step2349]: loss 11.909251
[epoch8, step2350]: loss 2.319334
[epoch8, step2351]: loss 9.385943
[epoch8, step2352]: loss 1.573476
[epoch8, step2353]: loss 7.491525
[epoch8, step2354]: loss 1.860276
[epoch8, step2355]: loss 1.286803
[epoch8, step2356]: loss 4.348027
[epoch8, step2357]: loss 19.750198
[epoch8, step2358]: loss 23.674295
[epoch8, step2359]: loss 9.203189
[epoch8, step2360]: loss 9.838655
[epoch8, step2361]: loss 12.272744
[epoch8, step2362]: loss 7.520299
[epoch8, step2363]: loss 24.554071
[epoch8, step2364]: loss 20.752258
[epoch8, step2365]: loss 10.113988
[epoch8, step2366]: loss 17.283993
[epoch8, step2367]: loss 3.594747
[epoch8, step2368]: loss 2.891347
[epoch8, step2369]: loss 0.921249
[epoch8, step2370]: loss 1.485937
[epoch8, step2371]: loss 3.764885
[epoch8, step2372]: loss 5.052719
[epoch8, step2373]: loss 7.726658
[epoch8, step2374]: loss 14.000027
[epoch8, step2375]: loss 5.696342
[epoch8, step2376]: loss 0.967153
[epoch8, step2377]: loss 0.979941
[epoch8, step2378]: loss 4.999374
[epoch8, step2379]: loss 24.794945
[epoch8, step2380]: loss 5.557189
[epoch8, step2381]: loss 1.615833
[epoch8, step2382]: loss 2.396266
[epoch8, step2383]: loss 5.770857
[epoch8, step2384]: loss 1.064770
[epoch8, step2385]: loss 1.310130
[epoch8, step2386]: loss 16.571646
[epoch8, step2387]: loss 15.760461
[epoch8, step2388]: loss 1.685465
[epoch8, step2389]: loss 2.871581
[epoch8, step2390]: loss 1.698398
[epoch8, step2391]: loss 1.518922
[epoch8, step2392]: loss 0.995272
[epoch8, step2393]: loss 1.490340
[epoch8, step2394]: loss 1.605628
[epoch8, step2395]: loss 5.234517
[epoch8, step2396]: loss 1.277263
[epoch8, step2397]: loss 3.914382
[epoch8, step2398]: loss 1.872937
[epoch8, step2399]: loss 1.699463
[epoch8, step2400]: loss 6.488983
[epoch8, step2401]: loss 1.642316
[epoch8, step2402]: loss 12.409428
[epoch8, step2403]: loss 4.468848
[epoch8, step2404]: loss 20.553116
[epoch8, step2405]: loss 10.529444
[epoch8, step2406]: loss 7.828094
[epoch8, step2407]: loss 1.767904
[epoch8, step2408]: loss 31.339605
[epoch8, step2409]: loss 1.432322
[epoch8, step2410]: loss 7.130826
[epoch8, step2411]: loss 10.686823
[epoch8, step2412]: loss 1.633402
[epoch8, step2413]: loss 1.873992
[epoch8, step2414]: loss 5.663235
[epoch8, step2415]: loss 13.508621
[epoch8, step2416]: loss 1.367667
[epoch8, step2417]: loss 19.915791
[epoch8, step2418]: loss 3.104499
[epoch8, step2419]: loss 12.180548
[epoch8, step2420]: loss 1.490369
[epoch8, step2421]: loss 5.204846
[epoch8, step2422]: loss 19.900383
[epoch8, step2423]: loss 6.567954
[epoch8, step2424]: loss 2.816761
[epoch8, step2425]: loss 1.842280
[epoch8, step2426]: loss 2.486420
[epoch8, step2427]: loss 0.932755
[epoch8, step2428]: loss 1.901180
[epoch8, step2429]: loss 6.127049
[epoch8, step2430]: loss 12.264821
[epoch8, step2431]: loss 8.218291
[epoch8, step2432]: loss 1.421103
[epoch8, step2433]: loss 0.907010
[epoch8, step2434]: loss 14.794091
[epoch8, step2435]: loss 4.806257
[epoch8, step2436]: loss 0.855384
[epoch8, step2437]: loss 1.834121
[epoch8, step2438]: loss 1.643695
[epoch8, step2439]: loss 1.165889
[epoch8, step2440]: loss 18.259813
[epoch8, step2441]: loss 4.695526
[epoch8, step2442]: loss 4.356811
[epoch8, step2443]: loss 1.740370
[epoch8, step2444]: loss 1.170866
[epoch8, step2445]: loss 3.872858
[epoch8, step2446]: loss 3.665405
[epoch8, step2447]: loss 1.511224
[epoch8, step2448]: loss 4.374148
[epoch8, step2449]: loss 12.306950
[epoch8, step2450]: loss 2.175951
[epoch8, step2451]: loss 1.990146
[epoch8, step2452]: loss 1.572181
[epoch8, step2453]: loss 1.401512
[epoch8, step2454]: loss 9.878180
[epoch8, step2455]: loss 1.603258
[epoch8, step2456]: loss 1.390089
[epoch8, step2457]: loss 2.915468
[epoch8, step2458]: loss 1.628494
[epoch8, step2459]: loss 11.051764
[epoch8, step2460]: loss 10.929082
[epoch8, step2461]: loss 5.072662
[epoch8, step2462]: loss 17.080044
[epoch8, step2463]: loss 26.773714
[epoch8, step2464]: loss 1.350147
[epoch8, step2465]: loss 9.907104
[epoch8, step2466]: loss 6.615990
[epoch8, step2467]: loss 15.122165
[epoch8, step2468]: loss 2.727599
[epoch8, step2469]: loss 1.048425
[epoch8, step2470]: loss 19.299332
[epoch8, step2471]: loss 1.380110
[epoch8, step2472]: loss 2.020485
[epoch8, step2473]: loss 1.304566
[epoch8, step2474]: loss 3.900207
[epoch8, step2475]: loss 25.923347
[epoch8, step2476]: loss 3.848093
[epoch8, step2477]: loss 3.601666
[epoch8, step2478]: loss 2.067027
[epoch8, step2479]: loss 14.964210
[epoch8, step2480]: loss 13.849642
[epoch8, step2481]: loss 3.173113
[epoch8, step2482]: loss 1.309033
[epoch8, step2483]: loss 3.345995
[epoch8, step2484]: loss 13.273112
[epoch8, step2485]: loss 2.023164
[epoch8, step2486]: loss 2.878508
[epoch8, step2487]: loss 2.257080
[epoch8, step2488]: loss 1.981824
[epoch8, step2489]: loss 12.489429
[epoch8, step2490]: loss 3.926422
[epoch8, step2491]: loss 1.008664
[epoch8, step2492]: loss 1.845314
[epoch8, step2493]: loss 3.924742
[epoch8, step2494]: loss 10.143406
[epoch8, step2495]: loss 1.299877
[epoch8, step2496]: loss 2.102716
[epoch8, step2497]: loss 3.639919
[epoch8, step2498]: loss 3.985239
[epoch8, step2499]: loss 12.630105
[epoch8, step2500]: loss 1.722031
[epoch8, step2501]: loss 2.984468
[epoch8, step2502]: loss 4.359797
[epoch8, step2503]: loss 1.216417
[epoch8, step2504]: loss 2.241025
[epoch8, step2505]: loss 1.821671
[epoch8, step2506]: loss 1.842335
[epoch8, step2507]: loss 1.286780
[epoch8, step2508]: loss 3.619399
[epoch8, step2509]: loss 5.047864
[epoch8, step2510]: loss 1.048055
[epoch8, step2511]: loss 1.433349
[epoch8, step2512]: loss 11.117414
[epoch8, step2513]: loss 1.858691
[epoch8, step2514]: loss 1.221709
[epoch8, step2515]: loss 1.990627
[epoch8, step2516]: loss 5.060560
[epoch8, step2517]: loss 4.586865
[epoch8, step2518]: loss 6.545860
[epoch8, step2519]: loss 2.834213
[epoch8, step2520]: loss 5.843502
[epoch8, step2521]: loss 1.590362
[epoch8, step2522]: loss 4.865260
[epoch8, step2523]: loss 2.988002
[epoch8, step2524]: loss 5.769568
[epoch8, step2525]: loss 2.938857
[epoch8, step2526]: loss 2.592787
[epoch8, step2527]: loss 3.052114
[epoch8, step2528]: loss 8.734184
[epoch8, step2529]: loss 11.393848
[epoch8, step2530]: loss 2.114258
[epoch8, step2531]: loss 1.967536
[epoch8, step2532]: loss 1.350245
[epoch8, step2533]: loss 18.131344
[epoch8, step2534]: loss 3.528147
[epoch8, step2535]: loss 3.433962
[epoch8, step2536]: loss 3.076500
[epoch8, step2537]: loss 2.165273
[epoch8, step2538]: loss 1.529387
[epoch8, step2539]: loss 1.334414
[epoch8, step2540]: loss 2.403775
[epoch8, step2541]: loss 4.900128
[epoch8, step2542]: loss 1.984362
[epoch8, step2543]: loss 4.630267
[epoch8, step2544]: loss 1.044413
[epoch8, step2545]: loss 2.832546
[epoch8, step2546]: loss 10.185555
[epoch8, step2547]: loss 2.385294
[epoch8, step2548]: loss 11.224032
[epoch8, step2549]: loss 10.573827
[epoch8, step2550]: loss 12.168679
[epoch8, step2551]: loss 1.335922
[epoch8, step2552]: loss 2.478012
[epoch8, step2553]: loss 1.334093
[epoch8, step2554]: loss 1.098100
[epoch8, step2555]: loss 7.742022
[epoch8, step2556]: loss 17.627951
[epoch8, step2557]: loss 0.958477
[epoch8, step2558]: loss 18.973372
[epoch8, step2559]: loss 6.037922
[epoch8, step2560]: loss 15.100316
[epoch8, step2561]: loss 1.070001
[epoch8, step2562]: loss 11.624535
[epoch8, step2563]: loss 11.686285
[epoch8, step2564]: loss 2.643249
[epoch8, step2565]: loss 2.432350
[epoch8, step2566]: loss 10.574758
[epoch8, step2567]: loss 1.229037
[epoch8, step2568]: loss 5.006570
[epoch8, step2569]: loss 7.586473
[epoch8, step2570]: loss 14.115413
[epoch8, step2571]: loss 3.387834
[epoch8, step2572]: loss 9.195771
[epoch8, step2573]: loss 7.452739
[epoch8, step2574]: loss 5.554616
[epoch8, step2575]: loss 12.291781
[epoch8, step2576]: loss 2.490796
[epoch8, step2577]: loss 1.318030
[epoch8, step2578]: loss 1.261101
[epoch8, step2579]: loss 1.840470
[epoch8, step2580]: loss 3.107404
[epoch8, step2581]: loss 3.639970
[epoch8, step2582]: loss 3.144320
[epoch8, step2583]: loss 1.165169
[epoch8, step2584]: loss 1.873140
[epoch8, step2585]: loss 1.075230
[epoch8, step2586]: loss 6.996369
[epoch8, step2587]: loss 6.352919
[epoch8, step2588]: loss 3.595763
[epoch8, step2589]: loss 8.292356
[epoch8, step2590]: loss 4.536389
[epoch8, step2591]: loss 13.060958
[epoch8, step2592]: loss 11.470599
[epoch8, step2593]: loss 1.258196
[epoch8, step2594]: loss 10.164225
[epoch8, step2595]: loss 5.822165
[epoch8, step2596]: loss 6.054511
[epoch8, step2597]: loss 4.127837
[epoch8, step2598]: loss 1.239593
[epoch8, step2599]: loss 14.378360
[epoch8, step2600]: loss 11.613015
[epoch8, step2601]: loss 11.307441
[epoch8, step2602]: loss 0.985929
[epoch8, step2603]: loss 2.078418
[epoch8, step2604]: loss 9.797564
[epoch8, step2605]: loss 6.969116
[epoch8, step2606]: loss 12.712922
[epoch8, step2607]: loss 25.058325
[epoch8, step2608]: loss 1.369895
[epoch8, step2609]: loss 1.008133
[epoch8, step2610]: loss 2.822968
[epoch8, step2611]: loss 1.843615
[epoch8, step2612]: loss 7.557012
[epoch8, step2613]: loss 19.664141
[epoch8, step2614]: loss 9.032467
[epoch8, step2615]: loss 4.312879
[epoch8, step2616]: loss 1.602635
[epoch8, step2617]: loss 1.578449
[epoch8, step2618]: loss 1.808343
[epoch8, step2619]: loss 2.174233
[epoch8, step2620]: loss 3.192774
[epoch8, step2621]: loss 11.633194
[epoch8, step2622]: loss 11.905110
[epoch8, step2623]: loss 10.934795
[epoch8, step2624]: loss 3.858401
[epoch8, step2625]: loss 5.548769
[epoch8, step2626]: loss 1.791258
[epoch8, step2627]: loss 2.840958
[epoch8, step2628]: loss 10.012886
[epoch8, step2629]: loss 2.263530
[epoch8, step2630]: loss 4.849895
[epoch8, step2631]: loss 13.014089
[epoch8, step2632]: loss 13.566578
[epoch8, step2633]: loss 2.207202
[epoch8, step2634]: loss 1.043487
[epoch8, step2635]: loss 25.288774
[epoch8, step2636]: loss 0.848600
[epoch8, step2637]: loss 12.038953
[epoch8, step2638]: loss 9.636909
[epoch8, step2639]: loss 3.549072
[epoch8, step2640]: loss 23.841951
[epoch8, step2641]: loss 3.552473
[epoch8, step2642]: loss 3.422699
[epoch8, step2643]: loss 4.384829
[epoch8, step2644]: loss 1.799464
[epoch8, step2645]: loss 10.548310
[epoch8, step2646]: loss 1.321257
[epoch8, step2647]: loss 2.894022
[epoch8, step2648]: loss 1.570956
[epoch8, step2649]: loss 1.449618
[epoch8, step2650]: loss 2.256908
[epoch8, step2651]: loss 1.686465
[epoch8, step2652]: loss 2.294964
[epoch8, step2653]: loss 10.411885
[epoch8, step2654]: loss 1.146649
[epoch8, step2655]: loss 12.824141
[epoch8, step2656]: loss 26.900673
[epoch8, step2657]: loss 3.872996
[epoch8, step2658]: loss 1.276117
[epoch8, step2659]: loss 3.013701
[epoch8, step2660]: loss 6.722791
[epoch8, step2661]: loss 1.129026
[epoch8, step2662]: loss 7.040639
[epoch8, step2663]: loss 2.156388
[epoch8, step2664]: loss 2.029154
[epoch8, step2665]: loss 1.146365
[epoch8, step2666]: loss 2.430244
[epoch8, step2667]: loss 1.302825
[epoch8, step2668]: loss 3.062861
[epoch8, step2669]: loss 2.053755
[epoch8, step2670]: loss 3.239637
[epoch8, step2671]: loss 4.018111
[epoch8, step2672]: loss 2.181710
[epoch8, step2673]: loss 1.968668
[epoch8, step2674]: loss 1.371742
[epoch8, step2675]: loss 2.336603
[epoch8, step2676]: loss 1.288239
[epoch8, step2677]: loss 9.133505
[epoch8, step2678]: loss 5.736064
[epoch8, step2679]: loss 2.674100
[epoch8, step2680]: loss 11.924175
[epoch8, step2681]: loss 3.208954
[epoch8, step2682]: loss 1.884169
[epoch8, step2683]: loss 2.429805
[epoch8, step2684]: loss 11.025636
[epoch8, step2685]: loss 13.974723
[epoch8, step2686]: loss 19.817806
[epoch8, step2687]: loss 3.764175
[epoch8, step2688]: loss 1.435724
[epoch8, step2689]: loss 2.031126
[epoch8, step2690]: loss 1.707399
[epoch8, step2691]: loss 1.433410
[epoch8, step2692]: loss 1.123344
[epoch8, step2693]: loss 15.519460
[epoch8, step2694]: loss 1.496746
[epoch8, step2695]: loss 13.208117
[epoch8, step2696]: loss 10.679455
[epoch8, step2697]: loss 4.423341
[epoch8, step2698]: loss 7.643943
[epoch8, step2699]: loss 1.312827
[epoch8, step2700]: loss 4.004612
[epoch8, step2701]: loss 1.690459
[epoch8, step2702]: loss 10.286548
[epoch8, step2703]: loss 1.257845
[epoch8, step2704]: loss 3.654694
[epoch8, step2705]: loss 4.733762
[epoch8, step2706]: loss 9.840779
[epoch8, step2707]: loss 17.669611
[epoch8, step2708]: loss 14.125487
[epoch8, step2709]: loss 9.572826
[epoch8, step2710]: loss 16.559940
[epoch8, step2711]: loss 4.744050
[epoch8, step2712]: loss 1.607720
[epoch8, step2713]: loss 0.812356
[epoch8, step2714]: loss 5.564333
[epoch8, step2715]: loss 8.841235
[epoch8, step2716]: loss 14.125069
[epoch8, step2717]: loss 2.996119
[epoch8, step2718]: loss 2.268446
[epoch8, step2719]: loss 1.593154
[epoch8, step2720]: loss 2.527053
[epoch8, step2721]: loss 2.419842
[epoch8, step2722]: loss 12.060224
[epoch8, step2723]: loss 1.284246
[epoch8, step2724]: loss 21.432648
[epoch8, step2725]: loss 15.191361
[epoch8, step2726]: loss 1.676260
[epoch8, step2727]: loss 2.648763
[epoch8, step2728]: loss 8.852051
[epoch8, step2729]: loss 5.750298
[epoch8, step2730]: loss 13.207783
[epoch8, step2731]: loss 1.622283
[epoch8, step2732]: loss 2.673803
[epoch8, step2733]: loss 2.323800
[epoch8, step2734]: loss 3.145926
[epoch8, step2735]: loss 2.718240
[epoch8, step2736]: loss 2.501302
[epoch8, step2737]: loss 13.939022
[epoch8, step2738]: loss 2.005751
[epoch8, step2739]: loss 1.611225
[epoch8, step2740]: loss 2.922669
[epoch8, step2741]: loss 4.450551
[epoch8, step2742]: loss 4.010205
[epoch8, step2743]: loss 2.149888
[epoch8, step2744]: loss 19.536325
[epoch8, step2745]: loss 1.984194
[epoch8, step2746]: loss 22.313313
[epoch8, step2747]: loss 6.513929
[epoch8, step2748]: loss 2.920792
[epoch8, step2749]: loss 11.213109
[epoch8, step2750]: loss 16.064392
[epoch8, step2751]: loss 2.391335
[epoch8, step2752]: loss 2.198139
[epoch8, step2753]: loss 1.044908
[epoch8, step2754]: loss 21.269018
[epoch8, step2755]: loss 11.201860
[epoch8, step2756]: loss 1.060049
[epoch8, step2757]: loss 11.139490
[epoch8, step2758]: loss 6.269723
[epoch8, step2759]: loss 12.035296
[epoch8, step2760]: loss 2.713194
[epoch8, step2761]: loss 11.852524
[epoch8, step2762]: loss 2.295161
[epoch8, step2763]: loss 2.141951
[epoch8, step2764]: loss 5.782256
[epoch8, step2765]: loss 1.346089
[epoch8, step2766]: loss 6.543407
[epoch8, step2767]: loss 4.824526
[epoch8, step2768]: loss 1.191382
[epoch8, step2769]: loss 1.434630
[epoch8, step2770]: loss 1.494074
[epoch8, step2771]: loss 2.502539
[epoch8, step2772]: loss 4.147426
[epoch8, step2773]: loss 14.540711
[epoch8, step2774]: loss 1.547508
[epoch8, step2775]: loss 3.414264
[epoch8, step2776]: loss 3.643529
[epoch8, step2777]: loss 2.257506
[epoch8, step2778]: loss 2.892292
[epoch8, step2779]: loss 19.716288
[epoch8, step2780]: loss 13.955972
[epoch8, step2781]: loss 20.756989
[epoch8, step2782]: loss 1.848705
[epoch8, step2783]: loss 7.134993
[epoch8, step2784]: loss 9.017803
[epoch8, step2785]: loss 3.135650
[epoch8, step2786]: loss 2.285742
[epoch8, step2787]: loss 1.018099
[epoch8, step2788]: loss 1.157545
[epoch8, step2789]: loss 1.217173
[epoch8, step2790]: loss 1.217943
[epoch8, step2791]: loss 8.526021
[epoch8, step2792]: loss 1.829523
[epoch8, step2793]: loss 1.656194
[epoch8, step2794]: loss 7.695250
[epoch8, step2795]: loss 2.083560
[epoch8, step2796]: loss 6.771369
[epoch8, step2797]: loss 1.857404
[epoch8, step2798]: loss 15.730512
[epoch8, step2799]: loss 2.744946
[epoch8, step2800]: loss 13.388563
[epoch8, step2801]: loss 4.062093
[epoch8, step2802]: loss 6.222819
[epoch8, step2803]: loss 3.424040
[epoch8, step2804]: loss 0.951821
[epoch8, step2805]: loss 15.905072
[epoch8, step2806]: loss 1.581320
[epoch8, step2807]: loss 5.579355
[epoch8, step2808]: loss 11.136065
[epoch8, step2809]: loss 1.266925
[epoch8, step2810]: loss 1.575073
[epoch8, step2811]: loss 2.164701
[epoch8, step2812]: loss 1.468225
[epoch8, step2813]: loss 1.570529
[epoch8, step2814]: loss 1.802844
[epoch8, step2815]: loss 6.929189
[epoch8, step2816]: loss 1.156075
[epoch8, step2817]: loss 4.811554
[epoch8, step2818]: loss 16.648907
[epoch8, step2819]: loss 1.614657
[epoch8, step2820]: loss 1.472302
[epoch8, step2821]: loss 13.269648
[epoch8, step2822]: loss 1.340077
[epoch8, step2823]: loss 1.260348
[epoch8, step2824]: loss 1.407094
[epoch8, step2825]: loss 3.050293
[epoch8, step2826]: loss 6.210584
[epoch8, step2827]: loss 5.142176
[epoch8, step2828]: loss 3.058094
[epoch8, step2829]: loss 1.748532
[epoch8, step2830]: loss 1.846851
[epoch8, step2831]: loss 2.874644
[epoch8, step2832]: loss 1.213035
[epoch8, step2833]: loss 1.124202
[epoch8, step2834]: loss 13.137987
[epoch8, step2835]: loss 2.606705
[epoch8, step2836]: loss 1.723063
[epoch8, step2837]: loss 1.458078
[epoch8, step2838]: loss 0.983784
[epoch8, step2839]: loss 20.499149
[epoch8, step2840]: loss 12.822145
[epoch8, step2841]: loss 8.929870
[epoch8, step2842]: loss 8.935922
[epoch8, step2843]: loss 17.133030
[epoch8, step2844]: loss 20.742743
[epoch8, step2845]: loss 14.321330
[epoch8, step2846]: loss 4.226778
[epoch8, step2847]: loss 14.684008
[epoch8, step2848]: loss 2.528495
[epoch8, step2849]: loss 6.875924
[epoch8, step2850]: loss 3.339532
[epoch8, step2851]: loss 3.759243
[epoch8, step2852]: loss 12.455338
[epoch8, step2853]: loss 1.700583
[epoch8, step2854]: loss 1.930895
[epoch8, step2855]: loss 1.839120
[epoch8, step2856]: loss 3.664311
[epoch8, step2857]: loss 1.819499
[epoch8, step2858]: loss 6.524295
[epoch8, step2859]: loss 5.372951
[epoch8, step2860]: loss 3.663427
[epoch8, step2861]: loss 1.486032
[epoch8, step2862]: loss 20.208670
[epoch8, step2863]: loss 11.570182
[epoch8, step2864]: loss 9.100910
[epoch8, step2865]: loss 15.600266
[epoch8, step2866]: loss 2.040680
[epoch8, step2867]: loss 1.991672
[epoch8, step2868]: loss 25.689753
[epoch8, step2869]: loss 2.567402
[epoch8, step2870]: loss 2.936922
[epoch8, step2871]: loss 10.265002
[epoch8, step2872]: loss 16.404869
[epoch8, step2873]: loss 2.691545
[epoch8, step2874]: loss 1.458865
[epoch8, step2875]: loss 4.415162
[epoch8, step2876]: loss 11.622867
[epoch8, step2877]: loss 4.369059
[epoch8, step2878]: loss 8.318335
[epoch8, step2879]: loss 1.031661
[epoch8, step2880]: loss 1.409062
[epoch8, step2881]: loss 12.682176
[epoch8, step2882]: loss 21.151773
[epoch8, step2883]: loss 1.647106
[epoch8, step2884]: loss 2.402229
[epoch8, step2885]: loss 1.486948
[epoch8, step2886]: loss 16.467630
[epoch8, step2887]: loss 2.170774
[epoch8, step2888]: loss 9.725121
[epoch8, step2889]: loss 9.070276
[epoch8, step2890]: loss 2.640853
[epoch8, step2891]: loss 16.263357
[epoch8, step2892]: loss 1.886190
[epoch8, step2893]: loss 13.581528
[epoch8, step2894]: loss 1.035685
[epoch8, step2895]: loss 0.869584
[epoch8, step2896]: loss 1.402673
[epoch8, step2897]: loss 4.145751
[epoch8, step2898]: loss 1.676481
[epoch8, step2899]: loss 9.660561
[epoch8, step2900]: loss 3.991770
[epoch8, step2901]: loss 12.111338
[epoch8, step2902]: loss 3.661731
[epoch8, step2903]: loss 1.234035
[epoch8, step2904]: loss 3.454590
[epoch8, step2905]: loss 1.527651
[epoch8, step2906]: loss 1.005165
[epoch8, step2907]: loss 1.760195
[epoch8, step2908]: loss 1.492527
[epoch8, step2909]: loss 2.153188
[epoch8, step2910]: loss 8.487409
[epoch8, step2911]: loss 9.287519
[epoch8, step2912]: loss 1.257012
[epoch8, step2913]: loss 15.094407
[epoch8, step2914]: loss 1.390948
[epoch8, step2915]: loss 3.242093
[epoch8, step2916]: loss 12.306040
[epoch8, step2917]: loss 19.742289
[epoch8, step2918]: loss 2.829075
[epoch8, step2919]: loss 1.215849
[epoch8, step2920]: loss 12.440934
[epoch8, step2921]: loss 4.739079
[epoch8, step2922]: loss 5.301542
[epoch8, step2923]: loss 1.711871
[epoch8, step2924]: loss 1.334655
[epoch8, step2925]: loss 4.056596
[epoch8, step2926]: loss 1.670334
[epoch8, step2927]: loss 4.526818
[epoch8, step2928]: loss 8.956274
[epoch8, step2929]: loss 1.087314
[epoch8, step2930]: loss 1.842152
[epoch8, step2931]: loss 1.268126
[epoch8, step2932]: loss 2.820700
[epoch8, step2933]: loss 3.240329
[epoch8, step2934]: loss 4.351058
[epoch8, step2935]: loss 3.420218
[epoch8, step2936]: loss 3.806894
[epoch8, step2937]: loss 1.857646
[epoch8, step2938]: loss 3.965048
[epoch8, step2939]: loss 10.726106
[epoch8, step2940]: loss 1.007393
[epoch8, step2941]: loss 2.802567
[epoch8, step2942]: loss 12.349207
[epoch8, step2943]: loss 5.019316
[epoch8, step2944]: loss 1.652752
[epoch8, step2945]: loss 5.159167
[epoch8, step2946]: loss 8.782601
[epoch8, step2947]: loss 3.659530
[epoch8, step2948]: loss 1.967440
[epoch8, step2949]: loss 2.299767
[epoch8, step2950]: loss 2.243447
[epoch8, step2951]: loss 7.698361
[epoch8, step2952]: loss 2.295416
[epoch8, step2953]: loss 1.544713
[epoch8, step2954]: loss 8.881912
[epoch8, step2955]: loss 9.467577
[epoch8, step2956]: loss 14.037565
[epoch8, step2957]: loss 7.432895
[epoch8, step2958]: loss 15.028377
[epoch8, step2959]: loss 1.898645
[epoch8, step2960]: loss 2.516985
[epoch8, step2961]: loss 16.431543
[epoch8, step2962]: loss 0.872147
[epoch8, step2963]: loss 1.700881
[epoch8, step2964]: loss 1.971785
[epoch8, step2965]: loss 1.365265
[epoch8, step2966]: loss 3.655609
[epoch8, step2967]: loss 2.023522
[epoch8, step2968]: loss 4.822660
[epoch8, step2969]: loss 19.432426
[epoch8, step2970]: loss 9.810455
[epoch8, step2971]: loss 11.490749
[epoch8, step2972]: loss 7.625822
[epoch8, step2973]: loss 2.525003
[epoch8, step2974]: loss 9.781817
[epoch8, step2975]: loss 1.087763
[epoch8, step2976]: loss 8.166792
[epoch8, step2977]: loss 1.190785
[epoch8, step2978]: loss 9.480070
[epoch8, step2979]: loss 3.404054
[epoch8, step2980]: loss 2.354932
[epoch8, step2981]: loss 5.288093
[epoch8, step2982]: loss 6.168352
[epoch8, step2983]: loss 4.205029
[epoch8, step2984]: loss 1.888370
[epoch8, step2985]: loss 3.212163
[epoch8, step2986]: loss 5.089542
[epoch8, step2987]: loss 5.625545
[epoch8, step2988]: loss 11.133677
[epoch8, step2989]: loss 16.223810
[epoch8, step2990]: loss 1.163414
[epoch8, step2991]: loss 7.821970
[epoch8, step2992]: loss 12.935315
[epoch8, step2993]: loss 3.257472
[epoch8, step2994]: loss 1.508081
[epoch8, step2995]: loss 2.206174
[epoch8, step2996]: loss 7.929984
[epoch8, step2997]: loss 3.979013
[epoch8, step2998]: loss 9.368093
[epoch8, step2999]: loss 1.521344
[epoch8, step3000]: loss 12.087518
[epoch8, step3001]: loss 11.995731
[epoch8, step3002]: loss 9.245785
[epoch8, step3003]: loss 2.831371
[epoch8, step3004]: loss 1.027707
[epoch8, step3005]: loss 1.812949
[epoch8, step3006]: loss 5.872352
[epoch8, step3007]: loss 2.009147
[epoch8, step3008]: loss 1.173641
[epoch8, step3009]: loss 5.774939
[epoch8, step3010]: loss 1.272861
[epoch8, step3011]: loss 1.219641
[epoch8, step3012]: loss 4.953670
[epoch8, step3013]: loss 2.087054
[epoch8, step3014]: loss 1.512266
[epoch8, step3015]: loss 2.502729
[epoch8, step3016]: loss 11.992727
[epoch8, step3017]: loss 3.538991
[epoch8, step3018]: loss 1.321082
[epoch8, step3019]: loss 1.833019
[epoch8, step3020]: loss 4.313784
[epoch8, step3021]: loss 1.119175
[epoch8, step3022]: loss 7.234753
[epoch8, step3023]: loss 4.234436
[epoch8, step3024]: loss 2.236398
[epoch8, step3025]: loss 7.927624
[epoch8, step3026]: loss 13.001066
[epoch8, step3027]: loss 2.488424
[epoch8, step3028]: loss 7.421969
[epoch8, step3029]: loss 2.458008
[epoch8, step3030]: loss 1.890618
[epoch8, step3031]: loss 3.916389
[epoch8, step3032]: loss 1.044058
[epoch8, step3033]: loss 1.799538
[epoch8, step3034]: loss 9.145614
[epoch8, step3035]: loss 6.636319
[epoch8, step3036]: loss 1.278943
[epoch8, step3037]: loss 14.415560
[epoch8, step3038]: loss 1.924532
[epoch8, step3039]: loss 7.481639
[epoch8, step3040]: loss 3.179908
[epoch8, step3041]: loss 9.991363
[epoch8, step3042]: loss 1.020221
[epoch8, step3043]: loss 6.720398
[epoch8, step3044]: loss 18.680964
[epoch8, step3045]: loss 1.921565
[epoch8, step3046]: loss 1.223907
[epoch8, step3047]: loss 1.343901
[epoch8, step3048]: loss 12.356414
[epoch8, step3049]: loss 0.963146
[epoch8, step3050]: loss 1.696720
[epoch8, step3051]: loss 2.183124
[epoch8, step3052]: loss 1.642705
[epoch8, step3053]: loss 7.481454
[epoch8, step3054]: loss 11.899604
[epoch8, step3055]: loss 3.486928
[epoch8, step3056]: loss 3.481698
[epoch8, step3057]: loss 8.353060
[epoch8, step3058]: loss 1.307481
[epoch8, step3059]: loss 12.680610
[epoch8, step3060]: loss 1.451862
[epoch8, step3061]: loss 2.147223
[epoch8, step3062]: loss 9.556713
[epoch8, step3063]: loss 8.316252
[epoch8, step3064]: loss 4.022661
[epoch8, step3065]: loss 4.579258
[epoch8, step3066]: loss 1.021662
[epoch8, step3067]: loss 13.630868
[epoch8, step3068]: loss 8.825511
[epoch8, step3069]: loss 6.463083
[epoch8, step3070]: loss 14.590509
[epoch8, step3071]: loss 1.815829
[epoch8, step3072]: loss 4.569990
[epoch8, step3073]: loss 11.375916
[epoch8, step3074]: loss 2.099471
[epoch8, step3075]: loss 4.610936
[epoch8, step3076]: loss 1.031847

[epoch8]: avg loss 1.031847

[epoch9, step1]: loss 10.766528
[epoch9, step2]: loss 1.369957
[epoch9, step3]: loss 11.286437
[epoch9, step4]: loss 11.248294
[epoch9, step5]: loss 2.896585
[epoch9, step6]: loss 12.683879
[epoch9, step7]: loss 3.616631
[epoch9, step8]: loss 2.182913
[epoch9, step9]: loss 3.311657
[epoch9, step10]: loss 15.895933
[epoch9, step11]: loss 7.944675
[epoch9, step12]: loss 4.447140
[epoch9, step13]: loss 2.153059
[epoch9, step14]: loss 1.144765
[epoch9, step15]: loss 1.744412
[epoch9, step16]: loss 4.241946
[epoch9, step17]: loss 2.076529
[epoch9, step18]: loss 1.387688
[epoch9, step19]: loss 2.785811
[epoch9, step20]: loss 14.577600
[epoch9, step21]: loss 1.150414
[epoch9, step22]: loss 13.982049
[epoch9, step23]: loss 4.670606
[epoch9, step24]: loss 2.692092
[epoch9, step25]: loss 1.258741
[epoch9, step26]: loss 2.211872
[epoch9, step27]: loss 2.847582
[epoch9, step28]: loss 7.178985
[epoch9, step29]: loss 11.069948
[epoch9, step30]: loss 15.007591
[epoch9, step31]: loss 3.825715
[epoch9, step32]: loss 1.557498
[epoch9, step33]: loss 10.371511
[epoch9, step34]: loss 12.735118
[epoch9, step35]: loss 2.008474
[epoch9, step36]: loss 2.079612
[epoch9, step37]: loss 17.270405
[epoch9, step38]: loss 1.577056
[epoch9, step39]: loss 22.474710
[epoch9, step40]: loss 2.111002
[epoch9, step41]: loss 10.842970
[epoch9, step42]: loss 1.118195
[epoch9, step43]: loss 3.436082
[epoch9, step44]: loss 2.257968
[epoch9, step45]: loss 1.060084
[epoch9, step46]: loss 2.254459
[epoch9, step47]: loss 2.531730
[epoch9, step48]: loss 1.307165
[epoch9, step49]: loss 8.674701
[epoch9, step50]: loss 3.836322
[epoch9, step51]: loss 2.379879
[epoch9, step52]: loss 15.219435
[epoch9, step53]: loss 10.881944
[epoch9, step54]: loss 12.430071
[epoch9, step55]: loss 1.318109
[epoch9, step56]: loss 1.552300
[epoch9, step57]: loss 1.199367
[epoch9, step58]: loss 16.285200
[epoch9, step59]: loss 2.898472
[epoch9, step60]: loss 10.990704
[epoch9, step61]: loss 3.129051
[epoch9, step62]: loss 1.182282
[epoch9, step63]: loss 2.138755
[epoch9, step64]: loss 1.503515
[epoch9, step65]: loss 1.346413
[epoch9, step66]: loss 4.391735
[epoch9, step67]: loss 8.772952
[epoch9, step68]: loss 4.223364
[epoch9, step69]: loss 9.098488
[epoch9, step70]: loss 7.487495
[epoch9, step71]: loss 6.341568
[epoch9, step72]: loss 4.843781
[epoch9, step73]: loss 3.508229
[epoch9, step74]: loss 22.647991
[epoch9, step75]: loss 14.577791
[epoch9, step76]: loss 1.636286
[epoch9, step77]: loss 1.395933
[epoch9, step78]: loss 6.287446
[epoch9, step79]: loss 2.394428
[epoch9, step80]: loss 1.510135
[epoch9, step81]: loss 4.130866
[epoch9, step82]: loss 1.409023
[epoch9, step83]: loss 1.467315
[epoch9, step84]: loss 13.601756
[epoch9, step85]: loss 33.203842
[epoch9, step86]: loss 8.128213
[epoch9, step87]: loss 1.104388
[epoch9, step88]: loss 4.836257
[epoch9, step89]: loss 7.536264
[epoch9, step90]: loss 12.109151
[epoch9, step91]: loss 2.329314
[epoch9, step92]: loss 2.385750
[epoch9, step93]: loss 1.355891
[epoch9, step94]: loss 12.682076
[epoch9, step95]: loss 14.295473
[epoch9, step96]: loss 3.585447
[epoch9, step97]: loss 1.207003
[epoch9, step98]: loss 1.410338
[epoch9, step99]: loss 3.817189
[epoch9, step100]: loss 1.240094
[epoch9, step101]: loss 4.270577
[epoch9, step102]: loss 3.366197
[epoch9, step103]: loss 1.190328
[epoch9, step104]: loss 4.955683
[epoch9, step105]: loss 1.538895
[epoch9, step106]: loss 3.551414
[epoch9, step107]: loss 1.452314
[epoch9, step108]: loss 6.290711
[epoch9, step109]: loss 3.752714
[epoch9, step110]: loss 1.617517
[epoch9, step111]: loss 3.087670
[epoch9, step112]: loss 8.228618
[epoch9, step113]: loss 1.086633
[epoch9, step114]: loss 10.580389
[epoch9, step115]: loss 1.887921
[epoch9, step116]: loss 1.399381
[epoch9, step117]: loss 9.576389
[epoch9, step118]: loss 1.143779
[epoch9, step119]: loss 2.367123
[epoch9, step120]: loss 3.943979
[epoch9, step121]: loss 16.886087
[epoch9, step122]: loss 7.646017
[epoch9, step123]: loss 5.530102
[epoch9, step124]: loss 18.264683
[epoch9, step125]: loss 2.069919
[epoch9, step126]: loss 20.908758
[epoch9, step127]: loss 3.354485
[epoch9, step128]: loss 1.896577
[epoch9, step129]: loss 3.133269
[epoch9, step130]: loss 13.193318
[epoch9, step131]: loss 1.142399
[epoch9, step132]: loss 1.740418
[epoch9, step133]: loss 2.414994
[epoch9, step134]: loss 4.763535
[epoch9, step135]: loss 4.809456
[epoch9, step136]: loss 1.576653
[epoch9, step137]: loss 12.292974
[epoch9, step138]: loss 11.274744
[epoch9, step139]: loss 2.227509
[epoch9, step140]: loss 2.124342
[epoch9, step141]: loss 3.825720
[epoch9, step142]: loss 17.955673
[epoch9, step143]: loss 12.786777
[epoch9, step144]: loss 10.084515
[epoch9, step145]: loss 12.695567
[epoch9, step146]: loss 4.340406
[epoch9, step147]: loss 1.107034
[epoch9, step148]: loss 9.538862
[epoch9, step149]: loss 14.543725
[epoch9, step150]: loss 15.165702
[epoch9, step151]: loss 14.100061
[epoch9, step152]: loss 5.599623
[epoch9, step153]: loss 10.187332
[epoch9, step154]: loss 1.420713
[epoch9, step155]: loss 8.272539
[epoch9, step156]: loss 1.171404
[epoch9, step157]: loss 4.731150
[epoch9, step158]: loss 2.743328
[epoch9, step159]: loss 12.374479
[epoch9, step160]: loss 11.032385
[epoch9, step161]: loss 1.230360
[epoch9, step162]: loss 17.809555
[epoch9, step163]: loss 1.615849
[epoch9, step164]: loss 3.623937
[epoch9, step165]: loss 1.571620
[epoch9, step166]: loss 0.973757
[epoch9, step167]: loss 5.086703
[epoch9, step168]: loss 10.307940
[epoch9, step169]: loss 7.530528
[epoch9, step170]: loss 8.416378
[epoch9, step171]: loss 16.850010
[epoch9, step172]: loss 1.126306
[epoch9, step173]: loss 4.208592
[epoch9, step174]: loss 9.738691
[epoch9, step175]: loss 11.905869
[epoch9, step176]: loss 14.177535
[epoch9, step177]: loss 1.521415
[epoch9, step178]: loss 0.941959
[epoch9, step179]: loss 0.994003
[epoch9, step180]: loss 1.943268
[epoch9, step181]: loss 3.639587
[epoch9, step182]: loss 2.358480
[epoch9, step183]: loss 1.335471
[epoch9, step184]: loss 1.940733
[epoch9, step185]: loss 5.867764
[epoch9, step186]: loss 1.972288
[epoch9, step187]: loss 1.405735
[epoch9, step188]: loss 1.369092
[epoch9, step189]: loss 7.321804
[epoch9, step190]: loss 2.009361
[epoch9, step191]: loss 3.537513
[epoch9, step192]: loss 1.228985
[epoch9, step193]: loss 1.147401
[epoch9, step194]: loss 4.695870
[epoch9, step195]: loss 1.919017
[epoch9, step196]: loss 27.750475
[epoch9, step197]: loss 1.563511
[epoch9, step198]: loss 9.853172
[epoch9, step199]: loss 4.528064
[epoch9, step200]: loss 3.182878
[epoch9, step201]: loss 5.365457
[epoch9, step202]: loss 5.447072
[epoch9, step203]: loss 2.057547
[epoch9, step204]: loss 8.943778
[epoch9, step205]: loss 4.213500
[epoch9, step206]: loss 1.141318
[epoch9, step207]: loss 3.978809
[epoch9, step208]: loss 2.353862
[epoch9, step209]: loss 5.201174
[epoch9, step210]: loss 8.841676
[epoch9, step211]: loss 2.999394
[epoch9, step212]: loss 3.204651
[epoch9, step213]: loss 8.650561
[epoch9, step214]: loss 6.123411
[epoch9, step215]: loss 5.129810
[epoch9, step216]: loss 3.303714
[epoch9, step217]: loss 3.517434
[epoch9, step218]: loss 2.163657
[epoch9, step219]: loss 2.200011
[epoch9, step220]: loss 5.049983
[epoch9, step221]: loss 1.409219
[epoch9, step222]: loss 1.453303
[epoch9, step223]: loss 8.287578
[epoch9, step224]: loss 1.032028
[epoch9, step225]: loss 1.389736
[epoch9, step226]: loss 1.318171
[epoch9, step227]: loss 13.241536
[epoch9, step228]: loss 1.954910
[epoch9, step229]: loss 2.131638
[epoch9, step230]: loss 1.910772
[epoch9, step231]: loss 12.227238
[epoch9, step232]: loss 3.055468
[epoch9, step233]: loss 2.604750
[epoch9, step234]: loss 3.021401
[epoch9, step235]: loss 2.611713
[epoch9, step236]: loss 4.548072
[epoch9, step237]: loss 2.940920
[epoch9, step238]: loss 3.510261
[epoch9, step239]: loss 3.347553
[epoch9, step240]: loss 3.606681
[epoch9, step241]: loss 12.887893
[epoch9, step242]: loss 2.060602
[epoch9, step243]: loss 10.858141
[epoch9, step244]: loss 18.276035
[epoch9, step245]: loss 1.806308
[epoch9, step246]: loss 12.660292
[epoch9, step247]: loss 1.212997
[epoch9, step248]: loss 31.739058
[epoch9, step249]: loss 1.742785
[epoch9, step250]: loss 3.375571
[epoch9, step251]: loss 1.875934
[epoch9, step252]: loss 3.413423
[epoch9, step253]: loss 13.367281
[epoch9, step254]: loss 4.282558
[epoch9, step255]: loss 6.470166
[epoch9, step256]: loss 12.683224
[epoch9, step257]: loss 1.614431
[epoch9, step258]: loss 2.368089
[epoch9, step259]: loss 1.360491
[epoch9, step260]: loss 17.114300
[epoch9, step261]: loss 5.103664
[epoch9, step262]: loss 12.673439
[epoch9, step263]: loss 2.339746
[epoch9, step264]: loss 3.343215
[epoch9, step265]: loss 11.960037
[epoch9, step266]: loss 1.730394
[epoch9, step267]: loss 2.233258
[epoch9, step268]: loss 1.515085
[epoch9, step269]: loss 11.354630
[epoch9, step270]: loss 1.914998
[epoch9, step271]: loss 2.515650
[epoch9, step272]: loss 2.985707
[epoch9, step273]: loss 9.828588
[epoch9, step274]: loss 1.800338
[epoch9, step275]: loss 9.599483
[epoch9, step276]: loss 1.671826
[epoch9, step277]: loss 1.140478
[epoch9, step278]: loss 2.235815
[epoch9, step279]: loss 1.405151
[epoch9, step280]: loss 11.854223
[epoch9, step281]: loss 1.518695
[epoch9, step282]: loss 11.466706
[epoch9, step283]: loss 4.576129
[epoch9, step284]: loss 9.039379
[epoch9, step285]: loss 0.902976
[epoch9, step286]: loss 1.875533
[epoch9, step287]: loss 1.125130
[epoch9, step288]: loss 2.024571
[epoch9, step289]: loss 2.257586
[epoch9, step290]: loss 16.005129
[epoch9, step291]: loss 1.604052
[epoch9, step292]: loss 12.291739
[epoch9, step293]: loss 9.502164
[epoch9, step294]: loss 2.666536
[epoch9, step295]: loss 8.113706
[epoch9, step296]: loss 6.520929
[epoch9, step297]: loss 6.756789
[epoch9, step298]: loss 12.004874
[epoch9, step299]: loss 7.105831
[epoch9, step300]: loss 19.441496
[epoch9, step301]: loss 1.748823
[epoch9, step302]: loss 2.746874
[epoch9, step303]: loss 1.559105
[epoch9, step304]: loss 10.719864
[epoch9, step305]: loss 3.139227
[epoch9, step306]: loss 1.181206
[epoch9, step307]: loss 2.337550
[epoch9, step308]: loss 1.583489
[epoch9, step309]: loss 2.935520
[epoch9, step310]: loss 0.872566
[epoch9, step311]: loss 1.637766
[epoch9, step312]: loss 1.183155
[epoch9, step313]: loss 10.158158
[epoch9, step314]: loss 6.104362
[epoch9, step315]: loss 8.136511
[epoch9, step316]: loss 1.476176
[epoch9, step317]: loss 13.017561
[epoch9, step318]: loss 3.989466
[epoch9, step319]: loss 1.961879
[epoch9, step320]: loss 1.949922
[epoch9, step321]: loss 11.413931
[epoch9, step322]: loss 15.746695
[epoch9, step323]: loss 5.122175
[epoch9, step324]: loss 0.859725
[epoch9, step325]: loss 1.370982
[epoch9, step326]: loss 4.258615
[epoch9, step327]: loss 7.319322
[epoch9, step328]: loss 6.146562
[epoch9, step329]: loss 1.182078
[epoch9, step330]: loss 1.869265
[epoch9, step331]: loss 2.871298
[epoch9, step332]: loss 12.550646
[epoch9, step333]: loss 2.453184
[epoch9, step334]: loss 10.702643
[epoch9, step335]: loss 0.965190
[epoch9, step336]: loss 8.981229
[epoch9, step337]: loss 1.075903
[epoch9, step338]: loss 1.634230
[epoch9, step339]: loss 4.751777
[epoch9, step340]: loss 6.181601
[epoch9, step341]: loss 4.970156
[epoch9, step342]: loss 2.308263
[epoch9, step343]: loss 1.706524
[epoch9, step344]: loss 1.071276
[epoch9, step345]: loss 1.365198
[epoch9, step346]: loss 3.067583
[epoch9, step347]: loss 1.735676
[epoch9, step348]: loss 13.348190
[epoch9, step349]: loss 9.366901
[epoch9, step350]: loss 11.823722
[epoch9, step351]: loss 28.444448
[epoch9, step352]: loss 0.983190
[epoch9, step353]: loss 2.629928
[epoch9, step354]: loss 3.055440
[epoch9, step355]: loss 0.923942
[epoch9, step356]: loss 1.441964
[epoch9, step357]: loss 4.781641
[epoch9, step358]: loss 9.420847
[epoch9, step359]: loss 7.902747
[epoch9, step360]: loss 11.020491
[epoch9, step361]: loss 2.215121
[epoch9, step362]: loss 12.646182
[epoch9, step363]: loss 6.292410
[epoch9, step364]: loss 3.273817
[epoch9, step365]: loss 7.777431
[epoch9, step366]: loss 20.225550
[epoch9, step367]: loss 2.799398
[epoch9, step368]: loss 15.481071
[epoch9, step369]: loss 11.118332
[epoch9, step370]: loss 2.056496
[epoch9, step371]: loss 0.966117
[epoch9, step372]: loss 1.596612
[epoch9, step373]: loss 1.996942
[epoch9, step374]: loss 19.482685
[epoch9, step375]: loss 7.495934
[epoch9, step376]: loss 10.918933
[epoch9, step377]: loss 0.977102
[epoch9, step378]: loss 3.348523
[epoch9, step379]: loss 2.350781
[epoch9, step380]: loss 1.697910
[epoch9, step381]: loss 3.513991
[epoch9, step382]: loss 2.173879
[epoch9, step383]: loss 4.339730
[epoch9, step384]: loss 4.707271
[epoch9, step385]: loss 2.068821
[epoch9, step386]: loss 16.253220
[epoch9, step387]: loss 14.941205
[epoch9, step388]: loss 11.380933
[epoch9, step389]: loss 1.184873
[epoch9, step390]: loss 1.715471
[epoch9, step391]: loss 26.500603
[epoch9, step392]: loss 16.188431
[epoch9, step393]: loss 10.607743
[epoch9, step394]: loss 8.515676
[epoch9, step395]: loss 1.350738
[epoch9, step396]: loss 1.969389
[epoch9, step397]: loss 11.372365
[epoch9, step398]: loss 16.653032
[epoch9, step399]: loss 2.381306
[epoch9, step400]: loss 2.270147
[epoch9, step401]: loss 1.479949
[epoch9, step402]: loss 0.952870
[epoch9, step403]: loss 9.731690
[epoch9, step404]: loss 5.179172
[epoch9, step405]: loss 0.955234
[epoch9, step406]: loss 1.282100
[epoch9, step407]: loss 9.312715
[epoch9, step408]: loss 4.597175
[epoch9, step409]: loss 4.396128
[epoch9, step410]: loss 3.667945
[epoch9, step411]: loss 1.029417
[epoch9, step412]: loss 3.211330
[epoch9, step413]: loss 1.283487
[epoch9, step414]: loss 18.082954
[epoch9, step415]: loss 9.654114
[epoch9, step416]: loss 4.565114
[epoch9, step417]: loss 8.635064
[epoch9, step418]: loss 2.053836
[epoch9, step419]: loss 14.149737
[epoch9, step420]: loss 1.574894
[epoch9, step421]: loss 1.829033
[epoch9, step422]: loss 9.610285
[epoch9, step423]: loss 1.505455
[epoch9, step424]: loss 1.472156
[epoch9, step425]: loss 9.059017
[epoch9, step426]: loss 7.288128
[epoch9, step427]: loss 1.306951
[epoch9, step428]: loss 15.764529
[epoch9, step429]: loss 1.751662
[epoch9, step430]: loss 1.425171
[epoch9, step431]: loss 2.054117
[epoch9, step432]: loss 11.246335
[epoch9, step433]: loss 0.798037
[epoch9, step434]: loss 6.467355
[epoch9, step435]: loss 1.720395
[epoch9, step436]: loss 9.964829
[epoch9, step437]: loss 1.687550
[epoch9, step438]: loss 10.338381
[epoch9, step439]: loss 7.075477
[epoch9, step440]: loss 3.404143
[epoch9, step441]: loss 1.226903
[epoch9, step442]: loss 1.532389
[epoch9, step443]: loss 1.376801
[epoch9, step444]: loss 7.153112
[epoch9, step445]: loss 1.649706
[epoch9, step446]: loss 1.683151
[epoch9, step447]: loss 1.200700
[epoch9, step448]: loss 1.253207
[epoch9, step449]: loss 3.067025
[epoch9, step450]: loss 13.745141
[epoch9, step451]: loss 4.708250
[epoch9, step452]: loss 3.292042
[epoch9, step453]: loss 2.159625
[epoch9, step454]: loss 7.280303
[epoch9, step455]: loss 1.668661
[epoch9, step456]: loss 2.357475
[epoch9, step457]: loss 0.861167
[epoch9, step458]: loss 1.684587
[epoch9, step459]: loss 3.371143
[epoch9, step460]: loss 0.931490
[epoch9, step461]: loss 4.791430
[epoch9, step462]: loss 2.878041
[epoch9, step463]: loss 15.489536
[epoch9, step464]: loss 1.413940
[epoch9, step465]: loss 2.420282
[epoch9, step466]: loss 2.827715
[epoch9, step467]: loss 3.476574
[epoch9, step468]: loss 1.873864
[epoch9, step469]: loss 4.907782
[epoch9, step470]: loss 1.188168
[epoch9, step471]: loss 12.296988
[epoch9, step472]: loss 1.443990
[epoch9, step473]: loss 2.741167
[epoch9, step474]: loss 2.918763
[epoch9, step475]: loss 1.893914
[epoch9, step476]: loss 6.710722
[epoch9, step477]: loss 3.352355
[epoch9, step478]: loss 16.173328
[epoch9, step479]: loss 1.182435
[epoch9, step480]: loss 5.044164
[epoch9, step481]: loss 3.583249
[epoch9, step482]: loss 1.323751
[epoch9, step483]: loss 1.939861
[epoch9, step484]: loss 3.403730
[epoch9, step485]: loss 9.058466
[epoch9, step486]: loss 4.465140
[epoch9, step487]: loss 6.559063
[epoch9, step488]: loss 3.615421
[epoch9, step489]: loss 1.218792
[epoch9, step490]: loss 1.199016
[epoch9, step491]: loss 6.501037
[epoch9, step492]: loss 0.637856
[epoch9, step493]: loss 4.696413
[epoch9, step494]: loss 11.571067
[epoch9, step495]: loss 2.957170
[epoch9, step496]: loss 2.140465
[epoch9, step497]: loss 1.213665
[epoch9, step498]: loss 2.769294
[epoch9, step499]: loss 7.164166
[epoch9, step500]: loss 10.480916
[epoch9, step501]: loss 1.039859
[epoch9, step502]: loss 3.041890
[epoch9, step503]: loss 3.108628
[epoch9, step504]: loss 2.178151
[epoch9, step505]: loss 3.512761
[epoch9, step506]: loss 9.793580
[epoch9, step507]: loss 1.148636
[epoch9, step508]: loss 1.846848
[epoch9, step509]: loss 2.274194
[epoch9, step510]: loss 12.125969
[epoch9, step511]: loss 2.598688
[epoch9, step512]: loss 2.449344
[epoch9, step513]: loss 1.304400
[epoch9, step514]: loss 7.931781
[epoch9, step515]: loss 1.305144
[epoch9, step516]: loss 4.555299
[epoch9, step517]: loss 3.864350
[epoch9, step518]: loss 12.145086
[epoch9, step519]: loss 3.306620
[epoch9, step520]: loss 2.972492
[epoch9, step521]: loss 13.823864
[epoch9, step522]: loss 1.639410
[epoch9, step523]: loss 5.634411
[epoch9, step524]: loss 17.042290
[epoch9, step525]: loss 15.196432
[epoch9, step526]: loss 20.403557
[epoch9, step527]: loss 1.196194
[epoch9, step528]: loss 24.017000
[epoch9, step529]: loss 14.371060
[epoch9, step530]: loss 1.722519
[epoch9, step531]: loss 1.382906
[epoch9, step532]: loss 3.880252
[epoch9, step533]: loss 2.067183
[epoch9, step534]: loss 1.653960
[epoch9, step535]: loss 1.883864
[epoch9, step536]: loss 1.499553
[epoch9, step537]: loss 2.646254
[epoch9, step538]: loss 9.961718
[epoch9, step539]: loss 2.339368
[epoch9, step540]: loss 1.111237
[epoch9, step541]: loss 3.088436
[epoch9, step542]: loss 3.577016
[epoch9, step543]: loss 10.800765
[epoch9, step544]: loss 1.573065
[epoch9, step545]: loss 4.446382
[epoch9, step546]: loss 1.503412
[epoch9, step547]: loss 3.371210
[epoch9, step548]: loss 11.355494
[epoch9, step549]: loss 9.129166
[epoch9, step550]: loss 12.306053
[epoch9, step551]: loss 3.239345
[epoch9, step552]: loss 1.619745
[epoch9, step553]: loss 1.343427
[epoch9, step554]: loss 3.619612
[epoch9, step555]: loss 3.116884
[epoch9, step556]: loss 7.041105
[epoch9, step557]: loss 3.728944
[epoch9, step558]: loss 20.051931
[epoch9, step559]: loss 1.927532
[epoch9, step560]: loss 2.843632
[epoch9, step561]: loss 1.367153
[epoch9, step562]: loss 5.411754
[epoch9, step563]: loss 1.207212
[epoch9, step564]: loss 2.663466
[epoch9, step565]: loss 3.370909
[epoch9, step566]: loss 3.326049
[epoch9, step567]: loss 2.193275
[epoch9, step568]: loss 1.872681
[epoch9, step569]: loss 6.949390
[epoch9, step570]: loss 10.905437
[epoch9, step571]: loss 2.633131
[epoch9, step572]: loss 1.847135
[epoch9, step573]: loss 11.479125
[epoch9, step574]: loss 1.895157
[epoch9, step575]: loss 3.087792
[epoch9, step576]: loss 12.536807
[epoch9, step577]: loss 2.039667
[epoch9, step578]: loss 3.695907
[epoch9, step579]: loss 1.452389
[epoch9, step580]: loss 1.346982
[epoch9, step581]: loss 10.724649
[epoch9, step582]: loss 1.499637
[epoch9, step583]: loss 2.749317
[epoch9, step584]: loss 3.225272
[epoch9, step585]: loss 1.312348
[epoch9, step586]: loss 1.036600
[epoch9, step587]: loss 29.909229
[epoch9, step588]: loss 1.220824
[epoch9, step589]: loss 15.214584
[epoch9, step590]: loss 6.170012
[epoch9, step591]: loss 17.808903
[epoch9, step592]: loss 2.712935
[epoch9, step593]: loss 11.613010
[epoch9, step594]: loss 13.627741
[epoch9, step595]: loss 5.506146
[epoch9, step596]: loss 3.181587
[epoch9, step597]: loss 1.370197
[epoch9, step598]: loss 9.102654
[epoch9, step599]: loss 1.059459
[epoch9, step600]: loss 3.509805
[epoch9, step601]: loss 9.481093
[epoch9, step602]: loss 2.069406
[epoch9, step603]: loss 3.538651
[epoch9, step604]: loss 4.020963
[epoch9, step605]: loss 2.161127
[epoch9, step606]: loss 4.704225
[epoch9, step607]: loss 10.376654
[epoch9, step608]: loss 0.849011
[epoch9, step609]: loss 1.473192
[epoch9, step610]: loss 5.520923
[epoch9, step611]: loss 4.243528
[epoch9, step612]: loss 0.921885
[epoch9, step613]: loss 1.775168
[epoch9, step614]: loss 0.871855
[epoch9, step615]: loss 4.593455
[epoch9, step616]: loss 9.906415
[epoch9, step617]: loss 3.522035
[epoch9, step618]: loss 0.949462
[epoch9, step619]: loss 4.702832
[epoch9, step620]: loss 12.776282
[epoch9, step621]: loss 1.637901
[epoch9, step622]: loss 11.722034
[epoch9, step623]: loss 2.376889
[epoch9, step624]: loss 5.012544
[epoch9, step625]: loss 2.419741
[epoch9, step626]: loss 10.266514
[epoch9, step627]: loss 9.652584
[epoch9, step628]: loss 9.361898
[epoch9, step629]: loss 0.919140
[epoch9, step630]: loss 3.281915
[epoch9, step631]: loss 1.802933
[epoch9, step632]: loss 14.589933
[epoch9, step633]: loss 7.296719
[epoch9, step634]: loss 1.866110
[epoch9, step635]: loss 11.130771
[epoch9, step636]: loss 8.566661
[epoch9, step637]: loss 11.027335
[epoch9, step638]: loss 4.757985
[epoch9, step639]: loss 2.309745
[epoch9, step640]: loss 6.660006
[epoch9, step641]: loss 17.317511
[epoch9, step642]: loss 2.431222
[epoch9, step643]: loss 7.262514
[epoch9, step644]: loss 2.268209
[epoch9, step645]: loss 1.735649
[epoch9, step646]: loss 7.422587
[epoch9, step647]: loss 2.252756
[epoch9, step648]: loss 1.462613
[epoch9, step649]: loss 17.140100
[epoch9, step650]: loss 4.899142
[epoch9, step651]: loss 10.195124
[epoch9, step652]: loss 2.257721
[epoch9, step653]: loss 6.085705
[epoch9, step654]: loss 1.342446
[epoch9, step655]: loss 3.570550
[epoch9, step656]: loss 1.318057
[epoch9, step657]: loss 5.718341
[epoch9, step658]: loss 9.469445
[epoch9, step659]: loss 1.212154
[epoch9, step660]: loss 8.496236
[epoch9, step661]: loss 1.286671
[epoch9, step662]: loss 10.439167
[epoch9, step663]: loss 2.553182
[epoch9, step664]: loss 1.313307
[epoch9, step665]: loss 8.467292
[epoch9, step666]: loss 1.296020
[epoch9, step667]: loss 2.156014
[epoch9, step668]: loss 8.380618
[epoch9, step669]: loss 2.968221
[epoch9, step670]: loss 4.868253
[epoch9, step671]: loss 1.247773
[epoch9, step672]: loss 3.420742
[epoch9, step673]: loss 7.190338
[epoch9, step674]: loss 2.363302
[epoch9, step675]: loss 1.859060
[epoch9, step676]: loss 1.732153
[epoch9, step677]: loss 4.157743
[epoch9, step678]: loss 1.619329
[epoch9, step679]: loss 10.342423
[epoch9, step680]: loss 1.911380
[epoch9, step681]: loss 5.492272
[epoch9, step682]: loss 7.011295
[epoch9, step683]: loss 3.611468
[epoch9, step684]: loss 10.142243
[epoch9, step685]: loss 8.979472
[epoch9, step686]: loss 18.826000
[epoch9, step687]: loss 2.168642
[epoch9, step688]: loss 1.471491
[epoch9, step689]: loss 3.708399
[epoch9, step690]: loss 24.430044
[epoch9, step691]: loss 6.679649
[epoch9, step692]: loss 10.719848
[epoch9, step693]: loss 4.162029
[epoch9, step694]: loss 4.488753
[epoch9, step695]: loss 2.049461
[epoch9, step696]: loss 4.870307
[epoch9, step697]: loss 4.159481
[epoch9, step698]: loss 4.751428
[epoch9, step699]: loss 3.133278
[epoch9, step700]: loss 21.734112
[epoch9, step701]: loss 1.540548
[epoch9, step702]: loss 7.065410
[epoch9, step703]: loss 17.250481
[epoch9, step704]: loss 2.414739
[epoch9, step705]: loss 6.928038
[epoch9, step706]: loss 4.406050
[epoch9, step707]: loss 1.188761
[epoch9, step708]: loss 1.260734
[epoch9, step709]: loss 9.176497
[epoch9, step710]: loss 9.505664
[epoch9, step711]: loss 11.769408
[epoch9, step712]: loss 16.581699
[epoch9, step713]: loss 1.312570
[epoch9, step714]: loss 10.507427
[epoch9, step715]: loss 21.108200
[epoch9, step716]: loss 0.843142
[epoch9, step717]: loss 1.828915
[epoch9, step718]: loss 1.353967
[epoch9, step719]: loss 1.304461
[epoch9, step720]: loss 5.633940
[epoch9, step721]: loss 2.107402
[epoch9, step722]: loss 2.457040
[epoch9, step723]: loss 27.006010
[epoch9, step724]: loss 1.352226
[epoch9, step725]: loss 1.331276
[epoch9, step726]: loss 1.128000
[epoch9, step727]: loss 1.330585
[epoch9, step728]: loss 6.455788
[epoch9, step729]: loss 0.994260
[epoch9, step730]: loss 2.135492
[epoch9, step731]: loss 13.441177
[epoch9, step732]: loss 5.102772
[epoch9, step733]: loss 2.008137
[epoch9, step734]: loss 1.299607
[epoch9, step735]: loss 15.115782
[epoch9, step736]: loss 0.928662
[epoch9, step737]: loss 2.905092
[epoch9, step738]: loss 1.335230
[epoch9, step739]: loss 1.510126
[epoch9, step740]: loss 1.080373
[epoch9, step741]: loss 6.865295
[epoch9, step742]: loss 3.974311
[epoch9, step743]: loss 2.769826
[epoch9, step744]: loss 11.397063
[epoch9, step745]: loss 3.378477
[epoch9, step746]: loss 1.521322
[epoch9, step747]: loss 19.664682
[epoch9, step748]: loss 3.921358
[epoch9, step749]: loss 2.719223
[epoch9, step750]: loss 5.158728
[epoch9, step751]: loss 3.222985
[epoch9, step752]: loss 2.851023
[epoch9, step753]: loss 16.168829
[epoch9, step754]: loss 23.713062
[epoch9, step755]: loss 1.751709
[epoch9, step756]: loss 3.740199
[epoch9, step757]: loss 10.929537
[epoch9, step758]: loss 1.792930
[epoch9, step759]: loss 1.504952
[epoch9, step760]: loss 7.831017
[epoch9, step761]: loss 15.319739
[epoch9, step762]: loss 17.862839
[epoch9, step763]: loss 2.719031
[epoch9, step764]: loss 8.573255
[epoch9, step765]: loss 11.398716
[epoch9, step766]: loss 1.755576
[epoch9, step767]: loss 10.981686
[epoch9, step768]: loss 10.527402
[epoch9, step769]: loss 2.962534
[epoch9, step770]: loss 1.812564
[epoch9, step771]: loss 5.755857
[epoch9, step772]: loss 4.974855
[epoch9, step773]: loss 1.398942
[epoch9, step774]: loss 1.745757
[epoch9, step775]: loss 2.413781
[epoch9, step776]: loss 1.146648
[epoch9, step777]: loss 8.302753
[epoch9, step778]: loss 1.526372
[epoch9, step779]: loss 1.324140
[epoch9, step780]: loss 2.129244
[epoch9, step781]: loss 2.849249
[epoch9, step782]: loss 1.704174
[epoch9, step783]: loss 1.648730
[epoch9, step784]: loss 6.892169
[epoch9, step785]: loss 3.570014
[epoch9, step786]: loss 2.530612
[epoch9, step787]: loss 1.268440
[epoch9, step788]: loss 1.081193
[epoch9, step789]: loss 15.333413
[epoch9, step790]: loss 1.730376
[epoch9, step791]: loss 1.738442
[epoch9, step792]: loss 2.136944
[epoch9, step793]: loss 3.085616
[epoch9, step794]: loss 1.201603
[epoch9, step795]: loss 1.126522
[epoch9, step796]: loss 1.406310
[epoch9, step797]: loss 3.681237
[epoch9, step798]: loss 1.711315
[epoch9, step799]: loss 2.231438
[epoch9, step800]: loss 1.187825
[epoch9, step801]: loss 10.099090
[epoch9, step802]: loss 2.180963
[epoch9, step803]: loss 2.944632
[epoch9, step804]: loss 1.053461
[epoch9, step805]: loss 8.053295
[epoch9, step806]: loss 3.928498
[epoch9, step807]: loss 31.532007
[epoch9, step808]: loss 1.758042
[epoch9, step809]: loss 1.212727
[epoch9, step810]: loss 10.037271
[epoch9, step811]: loss 1.588786
[epoch9, step812]: loss 12.792439
[epoch9, step813]: loss 10.975226
[epoch9, step814]: loss 10.927266
[epoch9, step815]: loss 1.037117
[epoch9, step816]: loss 8.405161
[epoch9, step817]: loss 6.814524
[epoch9, step818]: loss 3.520966
[epoch9, step819]: loss 2.672015
[epoch9, step820]: loss 14.266641
[epoch9, step821]: loss 2.202281
[epoch9, step822]: loss 10.340029
[epoch9, step823]: loss 3.932769
[epoch9, step824]: loss 2.771452
[epoch9, step825]: loss 1.244390
[epoch9, step826]: loss 0.884611
[epoch9, step827]: loss 3.580970
[epoch9, step828]: loss 5.137078
[epoch9, step829]: loss 14.297158
[epoch9, step830]: loss 13.204117
[epoch9, step831]: loss 3.773416
[epoch9, step832]: loss 10.721264
[epoch9, step833]: loss 5.043022
[epoch9, step834]: loss 3.418873
[epoch9, step835]: loss 2.885972
[epoch9, step836]: loss 7.420169
[epoch9, step837]: loss 1.325318
[epoch9, step838]: loss 1.694792
[epoch9, step839]: loss 0.679306
[epoch9, step840]: loss 8.403403
[epoch9, step841]: loss 17.697559
[epoch9, step842]: loss 12.363851
[epoch9, step843]: loss 1.110894
[epoch9, step844]: loss 5.489114
[epoch9, step845]: loss 3.245718
[epoch9, step846]: loss 4.327790
[epoch9, step847]: loss 1.939373
[epoch9, step848]: loss 27.637173
[epoch9, step849]: loss 1.671430
[epoch9, step850]: loss 1.113856
[epoch9, step851]: loss 18.371685
[epoch9, step852]: loss 1.089710
[epoch9, step853]: loss 12.491180
[epoch9, step854]: loss 1.825752
[epoch9, step855]: loss 7.100393
[epoch9, step856]: loss 2.077468
[epoch9, step857]: loss 1.852540
[epoch9, step858]: loss 6.561621
[epoch9, step859]: loss 1.378884
[epoch9, step860]: loss 3.051344
[epoch9, step861]: loss 2.657436
[epoch9, step862]: loss 2.155494
[epoch9, step863]: loss 8.183697
[epoch9, step864]: loss 24.502850
[epoch9, step865]: loss 2.611963
[epoch9, step866]: loss 25.353827
[epoch9, step867]: loss 16.028816
[epoch9, step868]: loss 2.123239
[epoch9, step869]: loss 3.336797
[epoch9, step870]: loss 1.237594
[epoch9, step871]: loss 3.892038
[epoch9, step872]: loss 2.028913
[epoch9, step873]: loss 10.244507
[epoch9, step874]: loss 17.155436
[epoch9, step875]: loss 1.486106
[epoch9, step876]: loss 1.423558
[epoch9, step877]: loss 2.083472
[epoch9, step878]: loss 10.391693
[epoch9, step879]: loss 11.546131
[epoch9, step880]: loss 2.080756
[epoch9, step881]: loss 9.591833
[epoch9, step882]: loss 1.917435
[epoch9, step883]: loss 1.496205
[epoch9, step884]: loss 7.009731
[epoch9, step885]: loss 4.349853
[epoch9, step886]: loss 15.022619
[epoch9, step887]: loss 13.947762
[epoch9, step888]: loss 1.783471
[epoch9, step889]: loss 5.300040
[epoch9, step890]: loss 3.499721
[epoch9, step891]: loss 2.104112
[epoch9, step892]: loss 1.654048
[epoch9, step893]: loss 1.901882
[epoch9, step894]: loss 1.186399
[epoch9, step895]: loss 1.943629
[epoch9, step896]: loss 1.189974
[epoch9, step897]: loss 1.075859
[epoch9, step898]: loss 2.077251
[epoch9, step899]: loss 2.876455
[epoch9, step900]: loss 1.396589
[epoch9, step901]: loss 1.885478
[epoch9, step902]: loss 12.337011
[epoch9, step903]: loss 15.964901
[epoch9, step904]: loss 7.694095
[epoch9, step905]: loss 4.724765
[epoch9, step906]: loss 9.435521
[epoch9, step907]: loss 3.019903
[epoch9, step908]: loss 1.491748
[epoch9, step909]: loss 11.118859
[epoch9, step910]: loss 11.759824
[epoch9, step911]: loss 2.858505
[epoch9, step912]: loss 1.505526
[epoch9, step913]: loss 10.063773
[epoch9, step914]: loss 4.119938
[epoch9, step915]: loss 8.066177
[epoch9, step916]: loss 8.174137
[epoch9, step917]: loss 7.605504
[epoch9, step918]: loss 7.190034
[epoch9, step919]: loss 11.606094
[epoch9, step920]: loss 3.059367
[epoch9, step921]: loss 3.181432
[epoch9, step922]: loss 8.067010
[epoch9, step923]: loss 10.833911
[epoch9, step924]: loss 1.216410
[epoch9, step925]: loss 1.747235
[epoch9, step926]: loss 1.235372
[epoch9, step927]: loss 2.305612
[epoch9, step928]: loss 17.884871
[epoch9, step929]: loss 14.207493
[epoch9, step930]: loss 12.695362
[epoch9, step931]: loss 2.713984
[epoch9, step932]: loss 0.972424
[epoch9, step933]: loss 2.339968
[epoch9, step934]: loss 15.690619
[epoch9, step935]: loss 4.399365
[epoch9, step936]: loss 1.210545
[epoch9, step937]: loss 0.945972
[epoch9, step938]: loss 6.950634
[epoch9, step939]: loss 2.980716
[epoch9, step940]: loss 7.554262
[epoch9, step941]: loss 1.760755
[epoch9, step942]: loss 1.554244
[epoch9, step943]: loss 3.591075
[epoch9, step944]: loss 0.882850
[epoch9, step945]: loss 20.137444
[epoch9, step946]: loss 1.259408
[epoch9, step947]: loss 1.901977
[epoch9, step948]: loss 9.398631
[epoch9, step949]: loss 1.594239
[epoch9, step950]: loss 1.963981
[epoch9, step951]: loss 14.101760
[epoch9, step952]: loss 1.211687
[epoch9, step953]: loss 2.275919
[epoch9, step954]: loss 15.134129
[epoch9, step955]: loss 1.376774
[epoch9, step956]: loss 11.551183
[epoch9, step957]: loss 2.894219
[epoch9, step958]: loss 1.372374
[epoch9, step959]: loss 1.478433
[epoch9, step960]: loss 2.779052
[epoch9, step961]: loss 1.218975
[epoch9, step962]: loss 10.381350
[epoch9, step963]: loss 1.579091
[epoch9, step964]: loss 2.045298
[epoch9, step965]: loss 11.419584
[epoch9, step966]: loss 5.183603
[epoch9, step967]: loss 2.480970
[epoch9, step968]: loss 3.460068
[epoch9, step969]: loss 1.903413
[epoch9, step970]: loss 1.200410
[epoch9, step971]: loss 13.189042
[epoch9, step972]: loss 1.397941
[epoch9, step973]: loss 1.614394
[epoch9, step974]: loss 1.766659
[epoch9, step975]: loss 8.404900
[epoch9, step976]: loss 4.229665
[epoch9, step977]: loss 1.375804
[epoch9, step978]: loss 1.672902
[epoch9, step979]: loss 9.177301
[epoch9, step980]: loss 3.997361
[epoch9, step981]: loss 14.984540
[epoch9, step982]: loss 0.982636
[epoch9, step983]: loss 0.971041
[epoch9, step984]: loss 7.397320
[epoch9, step985]: loss 11.681857
[epoch9, step986]: loss 1.822391
[epoch9, step987]: loss 4.190007
[epoch9, step988]: loss 2.358536
[epoch9, step989]: loss 4.350985
[epoch9, step990]: loss 3.965314
[epoch9, step991]: loss 1.187708
[epoch9, step992]: loss 3.419633
[epoch9, step993]: loss 3.106287
[epoch9, step994]: loss 2.408539
[epoch9, step995]: loss 3.072963
[epoch9, step996]: loss 1.151476
[epoch9, step997]: loss 8.938677
[epoch9, step998]: loss 2.132842
[epoch9, step999]: loss 4.423661
[epoch9, step1000]: loss 4.905419
[epoch9, step1001]: loss 1.484730
[epoch9, step1002]: loss 1.732245
[epoch9, step1003]: loss 1.046101
[epoch9, step1004]: loss 2.910688
[epoch9, step1005]: loss 14.092932
[epoch9, step1006]: loss 13.710391
[epoch9, step1007]: loss 2.966154
[epoch9, step1008]: loss 6.367111
[epoch9, step1009]: loss 2.250543
[epoch9, step1010]: loss 0.787847
[epoch9, step1011]: loss 1.119364
[epoch9, step1012]: loss 4.163050
[epoch9, step1013]: loss 1.301008
[epoch9, step1014]: loss 1.296730
[epoch9, step1015]: loss 12.649271
[epoch9, step1016]: loss 21.154604
[epoch9, step1017]: loss 7.706228
[epoch9, step1018]: loss 16.491457
[epoch9, step1019]: loss 18.815641
[epoch9, step1020]: loss 1.877595
[epoch9, step1021]: loss 8.135304
[epoch9, step1022]: loss 4.212044
[epoch9, step1023]: loss 3.129039
[epoch9, step1024]: loss 1.260619
[epoch9, step1025]: loss 15.792951
[epoch9, step1026]: loss 12.552679
[epoch9, step1027]: loss 1.177432
[epoch9, step1028]: loss 11.406980
[epoch9, step1029]: loss 12.425343
[epoch9, step1030]: loss 11.696889
[epoch9, step1031]: loss 8.143059
[epoch9, step1032]: loss 7.785812
[epoch9, step1033]: loss 3.261248
[epoch9, step1034]: loss 2.191704
[epoch9, step1035]: loss 2.467021
[epoch9, step1036]: loss 1.107991
[epoch9, step1037]: loss 2.925008
[epoch9, step1038]: loss 3.268783
[epoch9, step1039]: loss 47.875519
[epoch9, step1040]: loss 8.773725
[epoch9, step1041]: loss 1.632264
[epoch9, step1042]: loss 1.479008
[epoch9, step1043]: loss 1.277351
[epoch9, step1044]: loss 11.049280
[epoch9, step1045]: loss 13.388933
[epoch9, step1046]: loss 1.950251
[epoch9, step1047]: loss 7.737825
[epoch9, step1048]: loss 1.606327
[epoch9, step1049]: loss 1.818605
[epoch9, step1050]: loss 22.160875
[epoch9, step1051]: loss 15.038287
[epoch9, step1052]: loss 2.259676
[epoch9, step1053]: loss 2.744750
[epoch9, step1054]: loss 1.136878
[epoch9, step1055]: loss 1.279785
[epoch9, step1056]: loss 1.402726
[epoch9, step1057]: loss 2.817560
[epoch9, step1058]: loss 2.591474
[epoch9, step1059]: loss 3.056716
[epoch9, step1060]: loss 4.361841
[epoch9, step1061]: loss 1.500628
[epoch9, step1062]: loss 1.949664
[epoch9, step1063]: loss 10.508762
[epoch9, step1064]: loss 1.806086
[epoch9, step1065]: loss 3.843123
[epoch9, step1066]: loss 15.304184
[epoch9, step1067]: loss 1.870496
[epoch9, step1068]: loss 10.182093
[epoch9, step1069]: loss 1.999483
[epoch9, step1070]: loss 3.373295
[epoch9, step1071]: loss 0.880612
[epoch9, step1072]: loss 2.925894
[epoch9, step1073]: loss 7.026065
[epoch9, step1074]: loss 6.942730
[epoch9, step1075]: loss 3.252164
[epoch9, step1076]: loss 11.235014
[epoch9, step1077]: loss 13.690225
[epoch9, step1078]: loss 2.151736
[epoch9, step1079]: loss 15.022773
[epoch9, step1080]: loss 2.492513
[epoch9, step1081]: loss 2.304696
[epoch9, step1082]: loss 1.211258
[epoch9, step1083]: loss 0.846023
[epoch9, step1084]: loss 14.796712
[epoch9, step1085]: loss 5.910814
[epoch9, step1086]: loss 1.200073
[epoch9, step1087]: loss 5.495394
[epoch9, step1088]: loss 4.519902
[epoch9, step1089]: loss 13.447763
[epoch9, step1090]: loss 9.705659
[epoch9, step1091]: loss 1.352685
[epoch9, step1092]: loss 5.044291
[epoch9, step1093]: loss 5.296488
[epoch9, step1094]: loss 2.521566
[epoch9, step1095]: loss 9.454270
[epoch9, step1096]: loss 1.230244
[epoch9, step1097]: loss 0.966554
[epoch9, step1098]: loss 1.163997
[epoch9, step1099]: loss 2.784355
[epoch9, step1100]: loss 10.426792
[epoch9, step1101]: loss 1.840037
[epoch9, step1102]: loss 3.610460
[epoch9, step1103]: loss 4.427999
[epoch9, step1104]: loss 4.479319
[epoch9, step1105]: loss 11.058410
[epoch9, step1106]: loss 1.867180
[epoch9, step1107]: loss 3.597178
[epoch9, step1108]: loss 1.596815
[epoch9, step1109]: loss 12.731744
[epoch9, step1110]: loss 0.951451
[epoch9, step1111]: loss 1.699646
[epoch9, step1112]: loss 1.937010
[epoch9, step1113]: loss 19.522163
[epoch9, step1114]: loss 13.065502
[epoch9, step1115]: loss 2.316470
[epoch9, step1116]: loss 1.113523
[epoch9, step1117]: loss 12.317806
[epoch9, step1118]: loss 1.653318
[epoch9, step1119]: loss 1.698910
[epoch9, step1120]: loss 4.865102
[epoch9, step1121]: loss 0.919044
[epoch9, step1122]: loss 0.920571
[epoch9, step1123]: loss 2.485090
[epoch9, step1124]: loss 8.874686
[epoch9, step1125]: loss 3.427771
[epoch9, step1126]: loss 13.403465
[epoch9, step1127]: loss 1.788103
[epoch9, step1128]: loss 1.139015
[epoch9, step1129]: loss 1.701649
[epoch9, step1130]: loss 8.102993
[epoch9, step1131]: loss 6.177940
[epoch9, step1132]: loss 1.368994
[epoch9, step1133]: loss 1.877363
[epoch9, step1134]: loss 1.794276
[epoch9, step1135]: loss 1.606694
[epoch9, step1136]: loss 2.495557
[epoch9, step1137]: loss 1.330274
[epoch9, step1138]: loss 5.911333
[epoch9, step1139]: loss 2.455223
[epoch9, step1140]: loss 9.274588
[epoch9, step1141]: loss 2.851714
[epoch9, step1142]: loss 4.350144
[epoch9, step1143]: loss 2.139009
[epoch9, step1144]: loss 10.726347
[epoch9, step1145]: loss 0.829891
[epoch9, step1146]: loss 1.264769
[epoch9, step1147]: loss 10.554781
[epoch9, step1148]: loss 1.011160
[epoch9, step1149]: loss 3.453680
[epoch9, step1150]: loss 2.086190
[epoch9, step1151]: loss 0.977601
[epoch9, step1152]: loss 6.414054
[epoch9, step1153]: loss 6.598603
[epoch9, step1154]: loss 8.903738
[epoch9, step1155]: loss 1.555380
[epoch9, step1156]: loss 1.745052
[epoch9, step1157]: loss 4.721133
[epoch9, step1158]: loss 1.447248
[epoch9, step1159]: loss 3.001014
[epoch9, step1160]: loss 3.467649
[epoch9, step1161]: loss 3.923649
[epoch9, step1162]: loss 2.063548
[epoch9, step1163]: loss 2.356074
[epoch9, step1164]: loss 5.958521
[epoch9, step1165]: loss 6.640501
[epoch9, step1166]: loss 16.199471
[epoch9, step1167]: loss 1.674927
[epoch9, step1168]: loss 4.119477
[epoch9, step1169]: loss 1.429381
[epoch9, step1170]: loss 2.016197
[epoch9, step1171]: loss 2.047423
[epoch9, step1172]: loss 1.349193
[epoch9, step1173]: loss 7.597254
[epoch9, step1174]: loss 3.232840
[epoch9, step1175]: loss 2.006940
[epoch9, step1176]: loss 8.184691
[epoch9, step1177]: loss 1.306249
[epoch9, step1178]: loss 1.414614
[epoch9, step1179]: loss 1.736055
[epoch9, step1180]: loss 6.136507
[epoch9, step1181]: loss 12.089403
[epoch9, step1182]: loss 12.840419
[epoch9, step1183]: loss 6.421371
[epoch9, step1184]: loss 18.412315
[epoch9, step1185]: loss 10.745294
[epoch9, step1186]: loss 3.472453
[epoch9, step1187]: loss 1.606236
[epoch9, step1188]: loss 1.356488
[epoch9, step1189]: loss 2.111540
[epoch9, step1190]: loss 4.130972
[epoch9, step1191]: loss 13.830528
[epoch9, step1192]: loss 9.431975
[epoch9, step1193]: loss 1.505730
[epoch9, step1194]: loss 1.685611
[epoch9, step1195]: loss 8.166694
[epoch9, step1196]: loss 6.522481
[epoch9, step1197]: loss 1.447984
[epoch9, step1198]: loss 9.680494
[epoch9, step1199]: loss 3.706788
[epoch9, step1200]: loss 2.654638
[epoch9, step1201]: loss 2.805203
[epoch9, step1202]: loss 10.704815
[epoch9, step1203]: loss 1.424613
[epoch9, step1204]: loss 1.143995
[epoch9, step1205]: loss 3.358469
[epoch9, step1206]: loss 2.263834
[epoch9, step1207]: loss 3.725390
[epoch9, step1208]: loss 7.665487
[epoch9, step1209]: loss 1.028097
[epoch9, step1210]: loss 2.941703
[epoch9, step1211]: loss 5.573513
[epoch9, step1212]: loss 2.553365
[epoch9, step1213]: loss 14.082567
[epoch9, step1214]: loss 1.191629
[epoch9, step1215]: loss 1.593355
[epoch9, step1216]: loss 11.063392
[epoch9, step1217]: loss 1.495471
[epoch9, step1218]: loss 2.718635
[epoch9, step1219]: loss 1.344071
[epoch9, step1220]: loss 2.146292
[epoch9, step1221]: loss 15.130576
[epoch9, step1222]: loss 1.244479
[epoch9, step1223]: loss 1.572804
[epoch9, step1224]: loss 3.247611
[epoch9, step1225]: loss 10.331987
[epoch9, step1226]: loss 2.524418
[epoch9, step1227]: loss 21.093048
[epoch9, step1228]: loss 21.167124
[epoch9, step1229]: loss 16.473055
[epoch9, step1230]: loss 6.207537
[epoch9, step1231]: loss 12.957465
[epoch9, step1232]: loss 2.280979
[epoch9, step1233]: loss 12.086856
[epoch9, step1234]: loss 9.859630
[epoch9, step1235]: loss 1.680206
[epoch9, step1236]: loss 1.927419
[epoch9, step1237]: loss 10.358095
[epoch9, step1238]: loss 2.168332
[epoch9, step1239]: loss 25.220327
[epoch9, step1240]: loss 4.868706
[epoch9, step1241]: loss 3.639756
[epoch9, step1242]: loss 1.759493
[epoch9, step1243]: loss 5.089985
[epoch9, step1244]: loss 7.888879
[epoch9, step1245]: loss 9.669219
[epoch9, step1246]: loss 11.648457
[epoch9, step1247]: loss 1.572214
[epoch9, step1248]: loss 2.780563
[epoch9, step1249]: loss 15.401441
[epoch9, step1250]: loss 1.990536
[epoch9, step1251]: loss 1.165091
[epoch9, step1252]: loss 1.444263
[epoch9, step1253]: loss 4.353800
[epoch9, step1254]: loss 3.803658
[epoch9, step1255]: loss 13.293986
[epoch9, step1256]: loss 6.660936
[epoch9, step1257]: loss 3.116173
[epoch9, step1258]: loss 2.959918
[epoch9, step1259]: loss 1.589854
[epoch9, step1260]: loss 18.370279
[epoch9, step1261]: loss 8.228574
[epoch9, step1262]: loss 17.171227
[epoch9, step1263]: loss 18.896938
[epoch9, step1264]: loss 5.166413
[epoch9, step1265]: loss 6.098442
[epoch9, step1266]: loss 2.521634
[epoch9, step1267]: loss 2.963665
[epoch9, step1268]: loss 5.153988
[epoch9, step1269]: loss 3.474815
[epoch9, step1270]: loss 1.352373
[epoch9, step1271]: loss 2.471051
[epoch9, step1272]: loss 15.968545
[epoch9, step1273]: loss 3.036254
[epoch9, step1274]: loss 1.658071
[epoch9, step1275]: loss 0.932638
[epoch9, step1276]: loss 9.173262
[epoch9, step1277]: loss 12.683743
[epoch9, step1278]: loss 8.909800
[epoch9, step1279]: loss 10.585293
[epoch9, step1280]: loss 1.041672
[epoch9, step1281]: loss 1.773331
[epoch9, step1282]: loss 2.816900
[epoch9, step1283]: loss 1.707895
[epoch9, step1284]: loss 1.361542
[epoch9, step1285]: loss 0.971189
[epoch9, step1286]: loss 2.923017
[epoch9, step1287]: loss 6.324910
[epoch9, step1288]: loss 8.887506
[epoch9, step1289]: loss 8.452932
[epoch9, step1290]: loss 2.949336
[epoch9, step1291]: loss 11.705210
[epoch9, step1292]: loss 1.878524
[epoch9, step1293]: loss 1.040509
[epoch9, step1294]: loss 1.654458
[epoch9, step1295]: loss 1.713279
[epoch9, step1296]: loss 1.345987
[epoch9, step1297]: loss 12.593603
[epoch9, step1298]: loss 25.031813
[epoch9, step1299]: loss 0.861256
[epoch9, step1300]: loss 1.992648
[epoch9, step1301]: loss 7.279183
[epoch9, step1302]: loss 8.829981
[epoch9, step1303]: loss 4.201807
[epoch9, step1304]: loss 5.939147
[epoch9, step1305]: loss 1.148920
[epoch9, step1306]: loss 1.354076
[epoch9, step1307]: loss 23.682894
[epoch9, step1308]: loss 5.748605
[epoch9, step1309]: loss 1.910002
[epoch9, step1310]: loss 1.973927
[epoch9, step1311]: loss 1.437771
[epoch9, step1312]: loss 6.148631
[epoch9, step1313]: loss 7.334181
[epoch9, step1314]: loss 9.357303
[epoch9, step1315]: loss 1.059049
[epoch9, step1316]: loss 5.285261
[epoch9, step1317]: loss 6.221529
[epoch9, step1318]: loss 3.009192
[epoch9, step1319]: loss 1.119912
[epoch9, step1320]: loss 3.259501
[epoch9, step1321]: loss 9.618917
[epoch9, step1322]: loss 1.687474
[epoch9, step1323]: loss 0.807671
[epoch9, step1324]: loss 1.583417
[epoch9, step1325]: loss 19.403109
[epoch9, step1326]: loss 14.401570
[epoch9, step1327]: loss 11.084711
[epoch9, step1328]: loss 3.739905
[epoch9, step1329]: loss 1.987396
[epoch9, step1330]: loss 1.312691
[epoch9, step1331]: loss 1.079296
[epoch9, step1332]: loss 3.048424
[epoch9, step1333]: loss 12.979915
[epoch9, step1334]: loss 8.802675
[epoch9, step1335]: loss 2.228320
[epoch9, step1336]: loss 8.880104
[epoch9, step1337]: loss 1.395691
[epoch9, step1338]: loss 2.720364
[epoch9, step1339]: loss 1.456258
[epoch9, step1340]: loss 4.569366
[epoch9, step1341]: loss 1.147124
[epoch9, step1342]: loss 12.502429
[epoch9, step1343]: loss 0.963737
[epoch9, step1344]: loss 1.753986
[epoch9, step1345]: loss 9.067753
[epoch9, step1346]: loss 12.684448
[epoch9, step1347]: loss 1.543188
[epoch9, step1348]: loss 6.481894
[epoch9, step1349]: loss 5.877294
[epoch9, step1350]: loss 13.787127
[epoch9, step1351]: loss 2.684454
[epoch9, step1352]: loss 1.902041
[epoch9, step1353]: loss 20.775162
[epoch9, step1354]: loss 0.930392
[epoch9, step1355]: loss 1.241279
[epoch9, step1356]: loss 1.759569
[epoch9, step1357]: loss 1.357850
[epoch9, step1358]: loss 2.960337
[epoch9, step1359]: loss 7.282888
[epoch9, step1360]: loss 1.439550
[epoch9, step1361]: loss 1.236294
[epoch9, step1362]: loss 8.069323
[epoch9, step1363]: loss 4.855908
[epoch9, step1364]: loss 8.953222
[epoch9, step1365]: loss 1.342629
[epoch9, step1366]: loss 18.541311
[epoch9, step1367]: loss 4.067892
[epoch9, step1368]: loss 9.879753
[epoch9, step1369]: loss 3.014595
[epoch9, step1370]: loss 0.717457
[epoch9, step1371]: loss 1.616525
[epoch9, step1372]: loss 1.306979
[epoch9, step1373]: loss 2.722707
[epoch9, step1374]: loss 11.298950
[epoch9, step1375]: loss 9.881366
[epoch9, step1376]: loss 1.170039
[epoch9, step1377]: loss 1.959277
[epoch9, step1378]: loss 8.279256
[epoch9, step1379]: loss 10.622607
[epoch9, step1380]: loss 1.279112
[epoch9, step1381]: loss 1.358760
[epoch9, step1382]: loss 1.150557
[epoch9, step1383]: loss 12.473916
[epoch9, step1384]: loss 2.201073
[epoch9, step1385]: loss 1.545627
[epoch9, step1386]: loss 4.445423
[epoch9, step1387]: loss 1.578295
[epoch9, step1388]: loss 1.262174
[epoch9, step1389]: loss 2.089169
[epoch9, step1390]: loss 4.480339
[epoch9, step1391]: loss 3.039461
[epoch9, step1392]: loss 26.199841
[epoch9, step1393]: loss 1.975247
[epoch9, step1394]: loss 5.194361
[epoch9, step1395]: loss 2.897990
[epoch9, step1396]: loss 8.015495
[epoch9, step1397]: loss 2.690266
[epoch9, step1398]: loss 0.772942
[epoch9, step1399]: loss 15.602544
[epoch9, step1400]: loss 6.799439
[epoch9, step1401]: loss 0.918124
[epoch9, step1402]: loss 4.971912
[epoch9, step1403]: loss 2.721030
[epoch9, step1404]: loss 1.801377
[epoch9, step1405]: loss 1.098441
[epoch9, step1406]: loss 1.235654
[epoch9, step1407]: loss 1.170184
[epoch9, step1408]: loss 1.654799
[epoch9, step1409]: loss 16.859148
[epoch9, step1410]: loss 3.859485
[epoch9, step1411]: loss 14.589631
[epoch9, step1412]: loss 12.537209
[epoch9, step1413]: loss 2.517346
[epoch9, step1414]: loss 1.206894
[epoch9, step1415]: loss 1.163684
[epoch9, step1416]: loss 2.930354
[epoch9, step1417]: loss 2.691814
[epoch9, step1418]: loss 2.949353
[epoch9, step1419]: loss 4.433741
[epoch9, step1420]: loss 4.860796
[epoch9, step1421]: loss 2.765296
[epoch9, step1422]: loss 20.404303
[epoch9, step1423]: loss 1.408105
[epoch9, step1424]: loss 7.766577
[epoch9, step1425]: loss 11.936604
[epoch9, step1426]: loss 3.922364
[epoch9, step1427]: loss 8.952605
[epoch9, step1428]: loss 0.801921
[epoch9, step1429]: loss 1.834909
[epoch9, step1430]: loss 0.985660
[epoch9, step1431]: loss 12.046047
[epoch9, step1432]: loss 2.262779
[epoch9, step1433]: loss 4.506494
[epoch9, step1434]: loss 2.045150
[epoch9, step1435]: loss 4.014441
[epoch9, step1436]: loss 1.703512
[epoch9, step1437]: loss 15.547223
[epoch9, step1438]: loss 10.090846
[epoch9, step1439]: loss 1.703407
[epoch9, step1440]: loss 4.233660
[epoch9, step1441]: loss 1.361078
[epoch9, step1442]: loss 12.259653
[epoch9, step1443]: loss 24.275642
[epoch9, step1444]: loss 5.104925
[epoch9, step1445]: loss 1.509666
[epoch9, step1446]: loss 8.763577
[epoch9, step1447]: loss 1.089908
[epoch9, step1448]: loss 5.345451
[epoch9, step1449]: loss 15.959247
[epoch9, step1450]: loss 3.052187
[epoch9, step1451]: loss 8.223951
[epoch9, step1452]: loss 2.288545
[epoch9, step1453]: loss 8.293715
[epoch9, step1454]: loss 4.691350
[epoch9, step1455]: loss 1.039828
[epoch9, step1456]: loss 0.904204
[epoch9, step1457]: loss 1.147169
[epoch9, step1458]: loss 3.593902
[epoch9, step1459]: loss 16.819002
[epoch9, step1460]: loss 3.356372
[epoch9, step1461]: loss 1.695228
[epoch9, step1462]: loss 4.396280
[epoch9, step1463]: loss 3.192980
[epoch9, step1464]: loss 1.306102
[epoch9, step1465]: loss 1.195807
[epoch9, step1466]: loss 2.595995
[epoch9, step1467]: loss 1.132443
[epoch9, step1468]: loss 15.124536
[epoch9, step1469]: loss 5.323739
[epoch9, step1470]: loss 1.978179
[epoch9, step1471]: loss 1.572161
[epoch9, step1472]: loss 15.071308
[epoch9, step1473]: loss 1.035567
[epoch9, step1474]: loss 10.035412
[epoch9, step1475]: loss 13.581028
[epoch9, step1476]: loss 1.286884
[epoch9, step1477]: loss 3.772545
[epoch9, step1478]: loss 2.191335
[epoch9, step1479]: loss 11.254156
[epoch9, step1480]: loss 3.124526
[epoch9, step1481]: loss 0.956388
[epoch9, step1482]: loss 1.332547
[epoch9, step1483]: loss 4.163167
[epoch9, step1484]: loss 2.615008
[epoch9, step1485]: loss 10.537263
[epoch9, step1486]: loss 3.592736
[epoch9, step1487]: loss 3.795695
[epoch9, step1488]: loss 24.024206
[epoch9, step1489]: loss 3.224539
[epoch9, step1490]: loss 24.389755
[epoch9, step1491]: loss 3.854053
[epoch9, step1492]: loss 1.397819
[epoch9, step1493]: loss 0.941667
[epoch9, step1494]: loss 2.449554
[epoch9, step1495]: loss 6.968566
[epoch9, step1496]: loss 1.256951
[epoch9, step1497]: loss 2.309099
[epoch9, step1498]: loss 1.854158
[epoch9, step1499]: loss 7.540355
[epoch9, step1500]: loss 18.186180
[epoch9, step1501]: loss 9.141033
[epoch9, step1502]: loss 6.335527
[epoch9, step1503]: loss 9.124249
[epoch9, step1504]: loss 5.459847
[epoch9, step1505]: loss 1.271380
[epoch9, step1506]: loss 3.707376
[epoch9, step1507]: loss 4.387570
[epoch9, step1508]: loss 6.086762
[epoch9, step1509]: loss 1.134217
[epoch9, step1510]: loss 7.193026
[epoch9, step1511]: loss 1.761057
[epoch9, step1512]: loss 1.392559
[epoch9, step1513]: loss 4.266675
[epoch9, step1514]: loss 6.363685
[epoch9, step1515]: loss 14.281081
[epoch9, step1516]: loss 10.094612
[epoch9, step1517]: loss 6.921755
[epoch9, step1518]: loss 5.406311
[epoch9, step1519]: loss 9.360832
[epoch9, step1520]: loss 2.607966
[epoch9, step1521]: loss 12.551894
[epoch9, step1522]: loss 2.533593
[epoch9, step1523]: loss 1.978708
[epoch9, step1524]: loss 3.112102
[epoch9, step1525]: loss 0.995177
[epoch9, step1526]: loss 2.840582
[epoch9, step1527]: loss 9.201310
[epoch9, step1528]: loss 8.436796
[epoch9, step1529]: loss 3.608365
[epoch9, step1530]: loss 3.293528
[epoch9, step1531]: loss 2.661224
[epoch9, step1532]: loss 12.405292
[epoch9, step1533]: loss 2.386110
[epoch9, step1534]: loss 9.622988
[epoch9, step1535]: loss 2.271781
[epoch9, step1536]: loss 1.749740
[epoch9, step1537]: loss 8.222344
[epoch9, step1538]: loss 1.891411
[epoch9, step1539]: loss 9.724517
[epoch9, step1540]: loss 1.544165
[epoch9, step1541]: loss 14.263416
[epoch9, step1542]: loss 1.485524
[epoch9, step1543]: loss 0.937614
[epoch9, step1544]: loss 4.953067
[epoch9, step1545]: loss 1.722607
[epoch9, step1546]: loss 5.129818
[epoch9, step1547]: loss 2.066550
[epoch9, step1548]: loss 2.602634
[epoch9, step1549]: loss 2.411942
[epoch9, step1550]: loss 15.690861
[epoch9, step1551]: loss 13.151666
[epoch9, step1552]: loss 10.366389
[epoch9, step1553]: loss 3.595844
[epoch9, step1554]: loss 14.808948
[epoch9, step1555]: loss 8.282697
[epoch9, step1556]: loss 2.663347
[epoch9, step1557]: loss 10.995880
[epoch9, step1558]: loss 3.302100
[epoch9, step1559]: loss 1.484390
[epoch9, step1560]: loss 8.716389
[epoch9, step1561]: loss 1.723186
[epoch9, step1562]: loss 16.375217
[epoch9, step1563]: loss 5.211844
[epoch9, step1564]: loss 4.104952
[epoch9, step1565]: loss 8.726873
[epoch9, step1566]: loss 8.949264
[epoch9, step1567]: loss 3.537936
[epoch9, step1568]: loss 9.401592
[epoch9, step1569]: loss 1.642299
[epoch9, step1570]: loss 0.974391
[epoch9, step1571]: loss 1.721746
[epoch9, step1572]: loss 9.199585
[epoch9, step1573]: loss 34.354836
[epoch9, step1574]: loss 4.893829
[epoch9, step1575]: loss 4.352660
[epoch9, step1576]: loss 2.730342
[epoch9, step1577]: loss 1.301089
[epoch9, step1578]: loss 2.203475
[epoch9, step1579]: loss 17.299543
[epoch9, step1580]: loss 11.988694
[epoch9, step1581]: loss 1.158209
[epoch9, step1582]: loss 1.484524
[epoch9, step1583]: loss 11.522333
[epoch9, step1584]: loss 2.254579
[epoch9, step1585]: loss 5.866640
[epoch9, step1586]: loss 1.255089
[epoch9, step1587]: loss 1.479872
[epoch9, step1588]: loss 3.525517
[epoch9, step1589]: loss 7.908020
[epoch9, step1590]: loss 1.862265
[epoch9, step1591]: loss 9.825728
[epoch9, step1592]: loss 10.663059
[epoch9, step1593]: loss 2.933088
[epoch9, step1594]: loss 15.821685
[epoch9, step1595]: loss 7.738283
[epoch9, step1596]: loss 1.871508
[epoch9, step1597]: loss 1.348117
[epoch9, step1598]: loss 10.404131
[epoch9, step1599]: loss 5.187757
[epoch9, step1600]: loss 2.744051
[epoch9, step1601]: loss 4.232399
[epoch9, step1602]: loss 15.488293
[epoch9, step1603]: loss 1.634144
[epoch9, step1604]: loss 1.089744
[epoch9, step1605]: loss 1.010369
[epoch9, step1606]: loss 3.331422
[epoch9, step1607]: loss 9.869267
[epoch9, step1608]: loss 16.742872
[epoch9, step1609]: loss 1.622266
[epoch9, step1610]: loss 8.803656
[epoch9, step1611]: loss 3.166242
[epoch9, step1612]: loss 2.597267
[epoch9, step1613]: loss 5.568963
[epoch9, step1614]: loss 1.051581
[epoch9, step1615]: loss 9.298698
[epoch9, step1616]: loss 0.982027
[epoch9, step1617]: loss 4.851733
[epoch9, step1618]: loss 2.091732
[epoch9, step1619]: loss 18.560801
[epoch9, step1620]: loss 5.507418
[epoch9, step1621]: loss 1.411528
[epoch9, step1622]: loss 1.277177
[epoch9, step1623]: loss 5.965862
[epoch9, step1624]: loss 11.317374
[epoch9, step1625]: loss 7.876021
[epoch9, step1626]: loss 2.184254
[epoch9, step1627]: loss 23.820259
[epoch9, step1628]: loss 11.218971
[epoch9, step1629]: loss 1.391596
[epoch9, step1630]: loss 7.170537
[epoch9, step1631]: loss 1.875547
[epoch9, step1632]: loss 4.222938
[epoch9, step1633]: loss 2.860876
[epoch9, step1634]: loss 8.955030
[epoch9, step1635]: loss 1.919016
[epoch9, step1636]: loss 1.994009
[epoch9, step1637]: loss 2.141262
[epoch9, step1638]: loss 12.707489
[epoch9, step1639]: loss 0.954263
[epoch9, step1640]: loss 10.251901
[epoch9, step1641]: loss 7.307668
[epoch9, step1642]: loss 1.052056
[epoch9, step1643]: loss 1.359585
[epoch9, step1644]: loss 1.796169
[epoch9, step1645]: loss 2.439009
[epoch9, step1646]: loss 12.847643
[epoch9, step1647]: loss 10.726192
[epoch9, step1648]: loss 7.904786
[epoch9, step1649]: loss 4.166187
[epoch9, step1650]: loss 14.974572
[epoch9, step1651]: loss 1.469931
[epoch9, step1652]: loss 1.205518
[epoch9, step1653]: loss 7.950246
[epoch9, step1654]: loss 9.258991
[epoch9, step1655]: loss 1.562775
[epoch9, step1656]: loss 1.111815
[epoch9, step1657]: loss 19.075764
[epoch9, step1658]: loss 5.503787
[epoch9, step1659]: loss 11.273995
[epoch9, step1660]: loss 1.924542
[epoch9, step1661]: loss 2.273254
[epoch9, step1662]: loss 10.681885
[epoch9, step1663]: loss 2.117092
[epoch9, step1664]: loss 14.609042
[epoch9, step1665]: loss 1.555766
[epoch9, step1666]: loss 1.036942
[epoch9, step1667]: loss 1.804407
[epoch9, step1668]: loss 4.332760
[epoch9, step1669]: loss 2.696771
[epoch9, step1670]: loss 1.347021
[epoch9, step1671]: loss 1.440073
[epoch9, step1672]: loss 1.941366
[epoch9, step1673]: loss 1.926063
[epoch9, step1674]: loss 1.630967
[epoch9, step1675]: loss 4.532459
[epoch9, step1676]: loss 1.030647
[epoch9, step1677]: loss 13.636040
[epoch9, step1678]: loss 1.658183
[epoch9, step1679]: loss 3.958175
[epoch9, step1680]: loss 13.635118
[epoch9, step1681]: loss 6.829890
[epoch9, step1682]: loss 8.419967
[epoch9, step1683]: loss 1.684410
[epoch9, step1684]: loss 1.984523
[epoch9, step1685]: loss 1.386039
[epoch9, step1686]: loss 2.637354
[epoch9, step1687]: loss 0.879248
[epoch9, step1688]: loss 10.254539
[epoch9, step1689]: loss 0.837373
[epoch9, step1690]: loss 1.439356
[epoch9, step1691]: loss 1.416180
[epoch9, step1692]: loss 0.844437
[epoch9, step1693]: loss 5.210055
[epoch9, step1694]: loss 3.064030
[epoch9, step1695]: loss 14.201843
[epoch9, step1696]: loss 10.516154
[epoch9, step1697]: loss 10.758657
[epoch9, step1698]: loss 8.161012
[epoch9, step1699]: loss 2.835471
[epoch9, step1700]: loss 9.389866
[epoch9, step1701]: loss 6.783439
[epoch9, step1702]: loss 16.562115
[epoch9, step1703]: loss 1.087519
[epoch9, step1704]: loss 1.167229
[epoch9, step1705]: loss 9.462506
[epoch9, step1706]: loss 3.039606
[epoch9, step1707]: loss 9.258693
[epoch9, step1708]: loss 10.443984
[epoch9, step1709]: loss 7.510725
[epoch9, step1710]: loss 10.308086
[epoch9, step1711]: loss 12.667513
[epoch9, step1712]: loss 2.063703
[epoch9, step1713]: loss 5.884164
[epoch9, step1714]: loss 6.081164
[epoch9, step1715]: loss 2.297426
[epoch9, step1716]: loss 7.144933
[epoch9, step1717]: loss 1.009957
[epoch9, step1718]: loss 1.468718
[epoch9, step1719]: loss 2.241166
[epoch9, step1720]: loss 1.424492
[epoch9, step1721]: loss 4.125166
[epoch9, step1722]: loss 11.645354
[epoch9, step1723]: loss 3.206475
[epoch9, step1724]: loss 6.885788
[epoch9, step1725]: loss 6.395684
[epoch9, step1726]: loss 1.217104
[epoch9, step1727]: loss 1.839474
[epoch9, step1728]: loss 7.578618
[epoch9, step1729]: loss 2.757653
[epoch9, step1730]: loss 9.528371
[epoch9, step1731]: loss 28.976839
[epoch9, step1732]: loss 1.409470
[epoch9, step1733]: loss 1.436688
[epoch9, step1734]: loss 2.436500
[epoch9, step1735]: loss 1.731098
[epoch9, step1736]: loss 1.304889
[epoch9, step1737]: loss 1.872100
[epoch9, step1738]: loss 11.815477
[epoch9, step1739]: loss 2.255699
[epoch9, step1740]: loss 1.620120
[epoch9, step1741]: loss 12.754722
[epoch9, step1742]: loss 14.456436
[epoch9, step1743]: loss 2.531418
[epoch9, step1744]: loss 5.056157
[epoch9, step1745]: loss 5.046881
[epoch9, step1746]: loss 1.994983
[epoch9, step1747]: loss 1.465876
[epoch9, step1748]: loss 3.513962
[epoch9, step1749]: loss 1.096120
[epoch9, step1750]: loss 8.492473
[epoch9, step1751]: loss 2.054656
[epoch9, step1752]: loss 1.762998
[epoch9, step1753]: loss 1.250362
[epoch9, step1754]: loss 1.332388
[epoch9, step1755]: loss 1.777002
[epoch9, step1756]: loss 1.330754
[epoch9, step1757]: loss 1.740853
[epoch9, step1758]: loss 1.501888
[epoch9, step1759]: loss 3.317028
[epoch9, step1760]: loss 8.037970
[epoch9, step1761]: loss 1.005302
[epoch9, step1762]: loss 3.628863
[epoch9, step1763]: loss 6.844835
[epoch9, step1764]: loss 0.989142
[epoch9, step1765]: loss 13.313169
[epoch9, step1766]: loss 3.445294
[epoch9, step1767]: loss 1.551634
[epoch9, step1768]: loss 9.584260
[epoch9, step1769]: loss 4.437316
[epoch9, step1770]: loss 7.653821
[epoch9, step1771]: loss 1.446681
[epoch9, step1772]: loss 9.159559
[epoch9, step1773]: loss 1.179185
[epoch9, step1774]: loss 1.174211
[epoch9, step1775]: loss 2.661605
[epoch9, step1776]: loss 6.068007
[epoch9, step1777]: loss 3.455296
[epoch9, step1778]: loss 0.921705
[epoch9, step1779]: loss 6.038534
[epoch9, step1780]: loss 1.350166
[epoch9, step1781]: loss 1.480769
[epoch9, step1782]: loss 4.185426
[epoch9, step1783]: loss 5.412506
[epoch9, step1784]: loss 3.264521
[epoch9, step1785]: loss 1.934162
[epoch9, step1786]: loss 8.914186
[epoch9, step1787]: loss 2.388698
[epoch9, step1788]: loss 9.812715
[epoch9, step1789]: loss 3.864615
[epoch9, step1790]: loss 1.407509
[epoch9, step1791]: loss 23.216703
[epoch9, step1792]: loss 13.246822
[epoch9, step1793]: loss 12.055258
[epoch9, step1794]: loss 2.580379
[epoch9, step1795]: loss 3.732132
[epoch9, step1796]: loss 11.952389
[epoch9, step1797]: loss 7.601863
[epoch9, step1798]: loss 1.246038
[epoch9, step1799]: loss 2.225026
[epoch9, step1800]: loss 2.037166
[epoch9, step1801]: loss 1.100125
[epoch9, step1802]: loss 8.470590
[epoch9, step1803]: loss 3.987488
[epoch9, step1804]: loss 13.220495
[epoch9, step1805]: loss 6.504092
[epoch9, step1806]: loss 9.038102
[epoch9, step1807]: loss 2.659597
[epoch9, step1808]: loss 7.849325
[epoch9, step1809]: loss 11.409760
[epoch9, step1810]: loss 3.688946
[epoch9, step1811]: loss 1.157795
[epoch9, step1812]: loss 14.420067
[epoch9, step1813]: loss 2.176403
[epoch9, step1814]: loss 14.588577
[epoch9, step1815]: loss 2.708880
[epoch9, step1816]: loss 1.576439
[epoch9, step1817]: loss 9.066652
[epoch9, step1818]: loss 1.656464
[epoch9, step1819]: loss 3.732771
[epoch9, step1820]: loss 12.500685
[epoch9, step1821]: loss 6.393032
[epoch9, step1822]: loss 0.840769
[epoch9, step1823]: loss 1.858282
[epoch9, step1824]: loss 3.864951
[epoch9, step1825]: loss 13.193615
[epoch9, step1826]: loss 10.694438
[epoch9, step1827]: loss 1.295905
[epoch9, step1828]: loss 3.435963
[epoch9, step1829]: loss 1.930560
[epoch9, step1830]: loss 3.579212
[epoch9, step1831]: loss 4.646270
[epoch9, step1832]: loss 9.978700
[epoch9, step1833]: loss 1.583375
[epoch9, step1834]: loss 4.328525
[epoch9, step1835]: loss 1.247207
[epoch9, step1836]: loss 4.333849
[epoch9, step1837]: loss 21.477629
[epoch9, step1838]: loss 1.417910
[epoch9, step1839]: loss 1.353053
[epoch9, step1840]: loss 4.550896
[epoch9, step1841]: loss 1.272057
[epoch9, step1842]: loss 1.432807
[epoch9, step1843]: loss 5.818509
[epoch9, step1844]: loss 3.025824
[epoch9, step1845]: loss 24.160738
[epoch9, step1846]: loss 1.459330
[epoch9, step1847]: loss 1.843338
[epoch9, step1848]: loss 1.899429
[epoch9, step1849]: loss 1.210036
[epoch9, step1850]: loss 1.892402
[epoch9, step1851]: loss 7.365768
[epoch9, step1852]: loss 8.598837
[epoch9, step1853]: loss 11.644556
[epoch9, step1854]: loss 2.140886
[epoch9, step1855]: loss 2.607034
[epoch9, step1856]: loss 8.166118
[epoch9, step1857]: loss 7.301377
[epoch9, step1858]: loss 1.655954
[epoch9, step1859]: loss 2.804083
[epoch9, step1860]: loss 10.250299
[epoch9, step1861]: loss 5.397164
[epoch9, step1862]: loss 1.694227
[epoch9, step1863]: loss 1.707411
[epoch9, step1864]: loss 2.855534
[epoch9, step1865]: loss 3.031816
[epoch9, step1866]: loss 24.640463
[epoch9, step1867]: loss 2.707064
[epoch9, step1868]: loss 3.941963
[epoch9, step1869]: loss 4.603382
[epoch9, step1870]: loss 16.238764
[epoch9, step1871]: loss 1.177661
[epoch9, step1872]: loss 3.666746
[epoch9, step1873]: loss 7.344555
[epoch9, step1874]: loss 0.673364
[epoch9, step1875]: loss 4.388197
[epoch9, step1876]: loss 3.914604
[epoch9, step1877]: loss 1.940527
[epoch9, step1878]: loss 1.710778
[epoch9, step1879]: loss 3.023496
[epoch9, step1880]: loss 4.157207
[epoch9, step1881]: loss 3.926862
[epoch9, step1882]: loss 1.562470
[epoch9, step1883]: loss 12.679949
[epoch9, step1884]: loss 4.069774
[epoch9, step1885]: loss 2.777926
[epoch9, step1886]: loss 4.264931
[epoch9, step1887]: loss 1.373262
[epoch9, step1888]: loss 0.646349
[epoch9, step1889]: loss 1.375074
[epoch9, step1890]: loss 3.119226
[epoch9, step1891]: loss 22.909357
[epoch9, step1892]: loss 1.800414
[epoch9, step1893]: loss 14.044519
[epoch9, step1894]: loss 1.355670
[epoch9, step1895]: loss 1.572129
[epoch9, step1896]: loss 6.160073
[epoch9, step1897]: loss 2.601426
[epoch9, step1898]: loss 10.354076
[epoch9, step1899]: loss 2.206335
[epoch9, step1900]: loss 1.338652
[epoch9, step1901]: loss 1.424476
[epoch9, step1902]: loss 21.325354
[epoch9, step1903]: loss 15.157222
[epoch9, step1904]: loss 3.275833
[epoch9, step1905]: loss 1.635064
[epoch9, step1906]: loss 1.682303
[epoch9, step1907]: loss 5.477330
[epoch9, step1908]: loss 2.880372
[epoch9, step1909]: loss 0.795579
[epoch9, step1910]: loss 5.249803
[epoch9, step1911]: loss 3.667046
[epoch9, step1912]: loss 2.065070
[epoch9, step1913]: loss 4.459566
[epoch9, step1914]: loss 9.945147
[epoch9, step1915]: loss 1.222354
[epoch9, step1916]: loss 1.561115
[epoch9, step1917]: loss 6.361853
[epoch9, step1918]: loss 1.449686
[epoch9, step1919]: loss 11.273755
[epoch9, step1920]: loss 2.937274
[epoch9, step1921]: loss 1.676562
[epoch9, step1922]: loss 1.129910
[epoch9, step1923]: loss 1.873557
[epoch9, step1924]: loss 1.780951
[epoch9, step1925]: loss 3.458970
[epoch9, step1926]: loss 2.414736
[epoch9, step1927]: loss 3.236094
[epoch9, step1928]: loss 1.722461
[epoch9, step1929]: loss 2.693409
[epoch9, step1930]: loss 7.311447
[epoch9, step1931]: loss 11.391345
[epoch9, step1932]: loss 11.224218
[epoch9, step1933]: loss 0.898250
[epoch9, step1934]: loss 1.400465
[epoch9, step1935]: loss 2.154909
[epoch9, step1936]: loss 10.199420
[epoch9, step1937]: loss 1.657434
[epoch9, step1938]: loss 9.234669
[epoch9, step1939]: loss 4.783926
[epoch9, step1940]: loss 11.448194
[epoch9, step1941]: loss 1.475325
[epoch9, step1942]: loss 3.476643
[epoch9, step1943]: loss 1.528159
[epoch9, step1944]: loss 3.385666
[epoch9, step1945]: loss 8.572708
[epoch9, step1946]: loss 2.343328
[epoch9, step1947]: loss 16.722691
[epoch9, step1948]: loss 1.989625
[epoch9, step1949]: loss 1.306257
[epoch9, step1950]: loss 1.095819
[epoch9, step1951]: loss 3.489933
[epoch9, step1952]: loss 15.622690
[epoch9, step1953]: loss 2.394386
[epoch9, step1954]: loss 2.127757
[epoch9, step1955]: loss 1.365476
[epoch9, step1956]: loss 1.764499
[epoch9, step1957]: loss 1.776466
[epoch9, step1958]: loss 2.356856
[epoch9, step1959]: loss 1.699320
[epoch9, step1960]: loss 7.193996
[epoch9, step1961]: loss 2.124016
[epoch9, step1962]: loss 2.082541
[epoch9, step1963]: loss 2.079020
[epoch9, step1964]: loss 0.737654
[epoch9, step1965]: loss 12.264853
[epoch9, step1966]: loss 14.090993
[epoch9, step1967]: loss 17.897003
[epoch9, step1968]: loss 8.775105
[epoch9, step1969]: loss 1.770780
[epoch9, step1970]: loss 2.826135
[epoch9, step1971]: loss 1.812108
[epoch9, step1972]: loss 1.466029
[epoch9, step1973]: loss 16.175804
[epoch9, step1974]: loss 7.489192
[epoch9, step1975]: loss 3.093140
[epoch9, step1976]: loss 8.637129
[epoch9, step1977]: loss 1.598779
[epoch9, step1978]: loss 12.232540
[epoch9, step1979]: loss 6.906803
[epoch9, step1980]: loss 1.243075
[epoch9, step1981]: loss 4.173833
[epoch9, step1982]: loss 3.057657
[epoch9, step1983]: loss 12.549988
[epoch9, step1984]: loss 2.713184
[epoch9, step1985]: loss 2.747659
[epoch9, step1986]: loss 7.738831
[epoch9, step1987]: loss 10.206553
[epoch9, step1988]: loss 2.043892
[epoch9, step1989]: loss 4.199071
[epoch9, step1990]: loss 1.366502
[epoch9, step1991]: loss 5.230114
[epoch9, step1992]: loss 1.948169
[epoch9, step1993]: loss 15.626357
[epoch9, step1994]: loss 12.256636
[epoch9, step1995]: loss 1.461299
[epoch9, step1996]: loss 1.123027
[epoch9, step1997]: loss 11.700178
[epoch9, step1998]: loss 1.282807
[epoch9, step1999]: loss 11.980583
[epoch9, step2000]: loss 11.758370
[epoch9, step2001]: loss 15.224465
[epoch9, step2002]: loss 1.481973
[epoch9, step2003]: loss 3.127395
[epoch9, step2004]: loss 1.940936
[epoch9, step2005]: loss 1.859211
[epoch9, step2006]: loss 2.330171
[epoch9, step2007]: loss 2.708332
[epoch9, step2008]: loss 4.831337
[epoch9, step2009]: loss 1.675717
[epoch9, step2010]: loss 1.244912
[epoch9, step2011]: loss 1.288352
[epoch9, step2012]: loss 2.210115
[epoch9, step2013]: loss 2.014915
[epoch9, step2014]: loss 2.588396
[epoch9, step2015]: loss 1.116945
[epoch9, step2016]: loss 1.204492
[epoch9, step2017]: loss 1.992010
[epoch9, step2018]: loss 11.048485
[epoch9, step2019]: loss 11.704535
[epoch9, step2020]: loss 1.544544
[epoch9, step2021]: loss 2.637935
[epoch9, step2022]: loss 7.944448
[epoch9, step2023]: loss 1.833996
[epoch9, step2024]: loss 2.379250
[epoch9, step2025]: loss 2.039140
[epoch9, step2026]: loss 11.582529
[epoch9, step2027]: loss 1.050902
[epoch9, step2028]: loss 1.092015
[epoch9, step2029]: loss 21.543015
[epoch9, step2030]: loss 2.489670
[epoch9, step2031]: loss 1.816334
[epoch9, step2032]: loss 9.674477
[epoch9, step2033]: loss 0.915015
[epoch9, step2034]: loss 21.513863
[epoch9, step2035]: loss 1.402852
[epoch9, step2036]: loss 9.522440
[epoch9, step2037]: loss 6.727256
[epoch9, step2038]: loss 9.155221
[epoch9, step2039]: loss 1.073233
[epoch9, step2040]: loss 1.275031
[epoch9, step2041]: loss 6.183539
[epoch9, step2042]: loss 11.718787
[epoch9, step2043]: loss 4.051675
[epoch9, step2044]: loss 6.044466
[epoch9, step2045]: loss 2.746594
[epoch9, step2046]: loss 1.487321
[epoch9, step2047]: loss 1.994760
[epoch9, step2048]: loss 11.627046
[epoch9, step2049]: loss 1.771215
[epoch9, step2050]: loss 2.036198
[epoch9, step2051]: loss 21.351545
[epoch9, step2052]: loss 1.936110
[epoch9, step2053]: loss 8.568481
[epoch9, step2054]: loss 4.161938
[epoch9, step2055]: loss 9.868168
[epoch9, step2056]: loss 5.055296
[epoch9, step2057]: loss 7.749009
[epoch9, step2058]: loss 2.589727
[epoch9, step2059]: loss 3.722361
[epoch9, step2060]: loss 8.834964
[epoch9, step2061]: loss 1.371196
[epoch9, step2062]: loss 3.398309
[epoch9, step2063]: loss 1.690305
[epoch9, step2064]: loss 9.948284
[epoch9, step2065]: loss 1.575868
[epoch9, step2066]: loss 1.769595
[epoch9, step2067]: loss 1.047309
[epoch9, step2068]: loss 11.449946
[epoch9, step2069]: loss 11.789072
[epoch9, step2070]: loss 1.818296
[epoch9, step2071]: loss 3.906448
[epoch9, step2072]: loss 3.216679
[epoch9, step2073]: loss 2.882663
[epoch9, step2074]: loss 10.168385
[epoch9, step2075]: loss 1.049627
[epoch9, step2076]: loss 2.393851
[epoch9, step2077]: loss 5.189516
[epoch9, step2078]: loss 1.303631
[epoch9, step2079]: loss 3.013675
[epoch9, step2080]: loss 1.872654
[epoch9, step2081]: loss 9.118128
[epoch9, step2082]: loss 11.479752
[epoch9, step2083]: loss 3.859247
[epoch9, step2084]: loss 2.130677
[epoch9, step2085]: loss 1.299631
[epoch9, step2086]: loss 4.132370
[epoch9, step2087]: loss 7.572728
[epoch9, step2088]: loss 13.952760
[epoch9, step2089]: loss 5.926324
[epoch9, step2090]: loss 14.398709
[epoch9, step2091]: loss 9.612864
[epoch9, step2092]: loss 3.068533
[epoch9, step2093]: loss 2.407879
[epoch9, step2094]: loss 8.734509
[epoch9, step2095]: loss 2.395238
[epoch9, step2096]: loss 1.687899
[epoch9, step2097]: loss 6.354765
[epoch9, step2098]: loss 0.877611
[epoch9, step2099]: loss 2.593146
[epoch9, step2100]: loss 1.885615
[epoch9, step2101]: loss 5.966244
[epoch9, step2102]: loss 9.873648
[epoch9, step2103]: loss 2.543193
[epoch9, step2104]: loss 1.333772
[epoch9, step2105]: loss 1.820716
[epoch9, step2106]: loss 1.576892
[epoch9, step2107]: loss 8.590954
[epoch9, step2108]: loss 10.442865
[epoch9, step2109]: loss 1.817751
[epoch9, step2110]: loss 6.451587
[epoch9, step2111]: loss 13.195602
[epoch9, step2112]: loss 7.106545
[epoch9, step2113]: loss 5.694348
[epoch9, step2114]: loss 4.657231
[epoch9, step2115]: loss 1.481462
[epoch9, step2116]: loss 3.878507
[epoch9, step2117]: loss 3.099668
[epoch9, step2118]: loss 5.444322
[epoch9, step2119]: loss 1.190754
[epoch9, step2120]: loss 3.669918
[epoch9, step2121]: loss 14.782575
[epoch9, step2122]: loss 1.354013
[epoch9, step2123]: loss 3.578926
[epoch9, step2124]: loss 7.506694
[epoch9, step2125]: loss 4.347252
[epoch9, step2126]: loss 13.435840
[epoch9, step2127]: loss 8.834732
[epoch9, step2128]: loss 23.816601
[epoch9, step2129]: loss 0.932485
[epoch9, step2130]: loss 2.153899
[epoch9, step2131]: loss 1.857341
[epoch9, step2132]: loss 1.098131
[epoch9, step2133]: loss 11.457309
[epoch9, step2134]: loss 14.454643
[epoch9, step2135]: loss 1.337166
[epoch9, step2136]: loss 5.590990
[epoch9, step2137]: loss 18.418489
[epoch9, step2138]: loss 1.591813
[epoch9, step2139]: loss 1.337530
[epoch9, step2140]: loss 11.567123
[epoch9, step2141]: loss 3.604043
[epoch9, step2142]: loss 1.494226
[epoch9, step2143]: loss 2.468431
[epoch9, step2144]: loss 1.852119
[epoch9, step2145]: loss 2.514307
[epoch9, step2146]: loss 1.634131
[epoch9, step2147]: loss 12.285621
[epoch9, step2148]: loss 20.452314
[epoch9, step2149]: loss 2.618814
[epoch9, step2150]: loss 1.243838
[epoch9, step2151]: loss 2.923879
[epoch9, step2152]: loss 5.834262
[epoch9, step2153]: loss 10.356270
[epoch9, step2154]: loss 2.469873
[epoch9, step2155]: loss 1.603099
[epoch9, step2156]: loss 2.542558
[epoch9, step2157]: loss 1.951385
[epoch9, step2158]: loss 15.019096
[epoch9, step2159]: loss 1.239191
[epoch9, step2160]: loss 1.294538
[epoch9, step2161]: loss 13.038844
[epoch9, step2162]: loss 2.127399
[epoch9, step2163]: loss 16.083305
[epoch9, step2164]: loss 10.910480
[epoch9, step2165]: loss 7.206155
[epoch9, step2166]: loss 2.758441
[epoch9, step2167]: loss 1.291065
[epoch9, step2168]: loss 1.671969
[epoch9, step2169]: loss 5.046263
[epoch9, step2170]: loss 9.987794
[epoch9, step2171]: loss 2.419005
[epoch9, step2172]: loss 10.425040
[epoch9, step2173]: loss 2.186853
[epoch9, step2174]: loss 1.920856
[epoch9, step2175]: loss 7.064664
[epoch9, step2176]: loss 3.323002
[epoch9, step2177]: loss 4.281071
[epoch9, step2178]: loss 4.513428
[epoch9, step2179]: loss 1.427173
[epoch9, step2180]: loss 8.386673
[epoch9, step2181]: loss 2.274625
[epoch9, step2182]: loss 4.927125
[epoch9, step2183]: loss 5.181404
[epoch9, step2184]: loss 3.955177
[epoch9, step2185]: loss 1.381039
[epoch9, step2186]: loss 11.518929
[epoch9, step2187]: loss 4.550723
[epoch9, step2188]: loss 2.879102
[epoch9, step2189]: loss 3.496490
[epoch9, step2190]: loss 15.813270
[epoch9, step2191]: loss 3.319859
[epoch9, step2192]: loss 2.285083
[epoch9, step2193]: loss 5.469543
[epoch9, step2194]: loss 9.820446
[epoch9, step2195]: loss 1.113490
[epoch9, step2196]: loss 2.236853
[epoch9, step2197]: loss 6.223328
[epoch9, step2198]: loss 16.353027
[epoch9, step2199]: loss 1.060918
[epoch9, step2200]: loss 1.421177
[epoch9, step2201]: loss 11.295190
[epoch9, step2202]: loss 8.792763
[epoch9, step2203]: loss 24.311371
[epoch9, step2204]: loss 2.316823
[epoch9, step2205]: loss 2.599922
[epoch9, step2206]: loss 11.576299
[epoch9, step2207]: loss 3.007318
[epoch9, step2208]: loss 0.963322
[epoch9, step2209]: loss 1.439220
[epoch9, step2210]: loss 11.777768
[epoch9, step2211]: loss 1.445472
[epoch9, step2212]: loss 5.337040
[epoch9, step2213]: loss 3.244055
[epoch9, step2214]: loss 1.478102
[epoch9, step2215]: loss 1.394666
[epoch9, step2216]: loss 12.417211
[epoch9, step2217]: loss 2.316095
[epoch9, step2218]: loss 8.190804
[epoch9, step2219]: loss 1.741115
[epoch9, step2220]: loss 4.927641
[epoch9, step2221]: loss 1.247642
[epoch9, step2222]: loss 5.190434
[epoch9, step2223]: loss 2.285018
[epoch9, step2224]: loss 12.043285
[epoch9, step2225]: loss 1.638547
[epoch9, step2226]: loss 2.829594
[epoch9, step2227]: loss 2.932219
[epoch9, step2228]: loss 1.188260
[epoch9, step2229]: loss 2.199576
[epoch9, step2230]: loss 11.860652
[epoch9, step2231]: loss 7.834881
[epoch9, step2232]: loss 1.480227
[epoch9, step2233]: loss 11.953162
[epoch9, step2234]: loss 1.631591
[epoch9, step2235]: loss 3.010193
[epoch9, step2236]: loss 2.035795
[epoch9, step2237]: loss 2.185580
[epoch9, step2238]: loss 1.234652
[epoch9, step2239]: loss 16.039211
[epoch9, step2240]: loss 1.083619
[epoch9, step2241]: loss 4.013741
[epoch9, step2242]: loss 9.644240
[epoch9, step2243]: loss 2.375794
[epoch9, step2244]: loss 4.955847
[epoch9, step2245]: loss 2.159149
[epoch9, step2246]: loss 4.634731
[epoch9, step2247]: loss 7.096572
[epoch9, step2248]: loss 22.006187
[epoch9, step2249]: loss 2.076723
[epoch9, step2250]: loss 12.665874
[epoch9, step2251]: loss 13.691741
[epoch9, step2252]: loss 15.272092
[epoch9, step2253]: loss 0.973670
[epoch9, step2254]: loss 21.737276
[epoch9, step2255]: loss 17.970316
[epoch9, step2256]: loss 2.174882
[epoch9, step2257]: loss 12.625076
[epoch9, step2258]: loss 1.459507
[epoch9, step2259]: loss 2.851256
[epoch9, step2260]: loss 1.243213
[epoch9, step2261]: loss 5.657047
[epoch9, step2262]: loss 1.292879
[epoch9, step2263]: loss 7.442976
[epoch9, step2264]: loss 5.183311
[epoch9, step2265]: loss 9.852589
[epoch9, step2266]: loss 13.586979
[epoch9, step2267]: loss 2.104121
[epoch9, step2268]: loss 11.135568
[epoch9, step2269]: loss 2.636703
[epoch9, step2270]: loss 2.367637
[epoch9, step2271]: loss 10.341254
[epoch9, step2272]: loss 2.444400
[epoch9, step2273]: loss 1.659424
[epoch9, step2274]: loss 13.623768
[epoch9, step2275]: loss 1.366330
[epoch9, step2276]: loss 2.977580
[epoch9, step2277]: loss 3.764015
[epoch9, step2278]: loss 10.018367
[epoch9, step2279]: loss 8.179158
[epoch9, step2280]: loss 4.722323
[epoch9, step2281]: loss 9.684834
[epoch9, step2282]: loss 2.959223
[epoch9, step2283]: loss 1.019568
[epoch9, step2284]: loss 16.140570
[epoch9, step2285]: loss 3.572988
[epoch9, step2286]: loss 4.838242
[epoch9, step2287]: loss 1.580850
[epoch9, step2288]: loss 13.360950
[epoch9, step2289]: loss 1.665409
[epoch9, step2290]: loss 7.958114
[epoch9, step2291]: loss 3.751669
[epoch9, step2292]: loss 7.525765
[epoch9, step2293]: loss 1.691253
[epoch9, step2294]: loss 7.987275
[epoch9, step2295]: loss 15.563866
[epoch9, step2296]: loss 1.343473
[epoch9, step2297]: loss 11.257676
[epoch9, step2298]: loss 1.341225
[epoch9, step2299]: loss 1.601847
[epoch9, step2300]: loss 11.847079
[epoch9, step2301]: loss 20.145416
[epoch9, step2302]: loss 1.573552
[epoch9, step2303]: loss 3.872243
[epoch9, step2304]: loss 9.701465
[epoch9, step2305]: loss 2.683836
[epoch9, step2306]: loss 5.336548
[epoch9, step2307]: loss 0.960162
[epoch9, step2308]: loss 2.720840
[epoch9, step2309]: loss 1.921710
[epoch9, step2310]: loss 2.546861
[epoch9, step2311]: loss 1.446478
[epoch9, step2312]: loss 3.515190
[epoch9, step2313]: loss 6.500122
[epoch9, step2314]: loss 33.935551
[epoch9, step2315]: loss 0.973757
[epoch9, step2316]: loss 14.780457
[epoch9, step2317]: loss 1.161292
[epoch9, step2318]: loss 1.027791
[epoch9, step2319]: loss 24.991001
[epoch9, step2320]: loss 14.599185
[epoch9, step2321]: loss 14.859968
[epoch9, step2322]: loss 3.288369
[epoch9, step2323]: loss 6.530233
[epoch9, step2324]: loss 1.510806
[epoch9, step2325]: loss 2.507921
[epoch9, step2326]: loss 3.017344
[epoch9, step2327]: loss 1.475408
[epoch9, step2328]: loss 1.168387
[epoch9, step2329]: loss 1.923325
[epoch9, step2330]: loss 2.179327
[epoch9, step2331]: loss 11.446396
[epoch9, step2332]: loss 6.431159
[epoch9, step2333]: loss 3.614568
[epoch9, step2334]: loss 1.835953
[epoch9, step2335]: loss 1.606220
[epoch9, step2336]: loss 11.733293
[epoch9, step2337]: loss 5.427815
[epoch9, step2338]: loss 0.897161
[epoch9, step2339]: loss 3.228683
[epoch9, step2340]: loss 2.843956
[epoch9, step2341]: loss 2.591432
[epoch9, step2342]: loss 25.072002
[epoch9, step2343]: loss 1.962265
[epoch9, step2344]: loss 9.222632
[epoch9, step2345]: loss 2.820524
[epoch9, step2346]: loss 3.913753
[epoch9, step2347]: loss 1.189831
[epoch9, step2348]: loss 4.975171
[epoch9, step2349]: loss 13.232486
[epoch9, step2350]: loss 2.327658
[epoch9, step2351]: loss 14.320737
[epoch9, step2352]: loss 6.823329
[epoch9, step2353]: loss 11.046113
[epoch9, step2354]: loss 23.563414
[epoch9, step2355]: loss 4.963689
[epoch9, step2356]: loss 2.405692
[epoch9, step2357]: loss 6.493880
[epoch9, step2358]: loss 1.459671
[epoch9, step2359]: loss 1.003131
[epoch9, step2360]: loss 1.351233
[epoch9, step2361]: loss 1.508153
[epoch9, step2362]: loss 1.216892
[epoch9, step2363]: loss 1.779955
[epoch9, step2364]: loss 9.487679
[epoch9, step2365]: loss 1.103233
[epoch9, step2366]: loss 11.596320
[epoch9, step2367]: loss 26.401941
[epoch9, step2368]: loss 1.662979
[epoch9, step2369]: loss 1.779310
[epoch9, step2370]: loss 9.790201
[epoch9, step2371]: loss 12.969743
[epoch9, step2372]: loss 22.088951
[epoch9, step2373]: loss 14.659967
[epoch9, step2374]: loss 6.053431
[epoch9, step2375]: loss 3.224825
[epoch9, step2376]: loss 3.686492
[epoch9, step2377]: loss 1.861723
[epoch9, step2378]: loss 4.015927
[epoch9, step2379]: loss 14.477651
[epoch9, step2380]: loss 1.193913
[epoch9, step2381]: loss 5.201998
[epoch9, step2382]: loss 4.190392
[epoch9, step2383]: loss 1.288634
[epoch9, step2384]: loss 1.172614
[epoch9, step2385]: loss 2.448698
[epoch9, step2386]: loss 0.947731
[epoch9, step2387]: loss 1.400424
[epoch9, step2388]: loss 1.664135
[epoch9, step2389]: loss 0.974834
[epoch9, step2390]: loss 4.855701
[epoch9, step2391]: loss 2.795074
[epoch9, step2392]: loss 1.358608
[epoch9, step2393]: loss 8.526213
[epoch9, step2394]: loss 9.772536
[epoch9, step2395]: loss 1.283597
[epoch9, step2396]: loss 1.790489
[epoch9, step2397]: loss 10.617855
[epoch9, step2398]: loss 1.187342
[epoch9, step2399]: loss 6.182422
[epoch9, step2400]: loss 1.871848
[epoch9, step2401]: loss 1.320842
[epoch9, step2402]: loss 4.824176
[epoch9, step2403]: loss 13.223557
[epoch9, step2404]: loss 3.874985
[epoch9, step2405]: loss 0.567089
[epoch9, step2406]: loss 2.900970
[epoch9, step2407]: loss 4.498939
[epoch9, step2408]: loss 11.824985
[epoch9, step2409]: loss 2.960748
[epoch9, step2410]: loss 15.368882
[epoch9, step2411]: loss 11.810162
[epoch9, step2412]: loss 1.607506
[epoch9, step2413]: loss 2.265931
[epoch9, step2414]: loss 1.481453
[epoch9, step2415]: loss 1.437186
[epoch9, step2416]: loss 12.272158
[epoch9, step2417]: loss 1.584909
[epoch9, step2418]: loss 11.833298
[epoch9, step2419]: loss 0.912763
[epoch9, step2420]: loss 3.142316
[epoch9, step2421]: loss 5.172911
[epoch9, step2422]: loss 3.009701
[epoch9, step2423]: loss 9.387131
[epoch9, step2424]: loss 9.555930
[epoch9, step2425]: loss 0.845317
[epoch9, step2426]: loss 8.910863
[epoch9, step2427]: loss 9.719322
[epoch9, step2428]: loss 10.342803
[epoch9, step2429]: loss 9.389316
[epoch9, step2430]: loss 1.420348
[epoch9, step2431]: loss 4.050704
[epoch9, step2432]: loss 0.878373
[epoch9, step2433]: loss 14.527425
[epoch9, step2434]: loss 2.571497
[epoch9, step2435]: loss 4.238579
[epoch9, step2436]: loss 1.079971
[epoch9, step2437]: loss 2.097211
[epoch9, step2438]: loss 1.091075
[epoch9, step2439]: loss 6.234632
[epoch9, step2440]: loss 9.824353
[epoch9, step2441]: loss 3.820107
[epoch9, step2442]: loss 0.858403
[epoch9, step2443]: loss 9.913623
[epoch9, step2444]: loss 1.179903
[epoch9, step2445]: loss 4.406572
[epoch9, step2446]: loss 1.699037
[epoch9, step2447]: loss 18.415283
[epoch9, step2448]: loss 4.516293
[epoch9, step2449]: loss 2.325537
[epoch9, step2450]: loss 1.191476
[epoch9, step2451]: loss 1.782571
[epoch9, step2452]: loss 2.767951
[epoch9, step2453]: loss 4.391996
[epoch9, step2454]: loss 1.230744
[epoch9, step2455]: loss 1.402281
[epoch9, step2456]: loss 2.078207
[epoch9, step2457]: loss 3.121343
[epoch9, step2458]: loss 9.943822
[epoch9, step2459]: loss 3.246128
[epoch9, step2460]: loss 1.200227
[epoch9, step2461]: loss 9.315730
[epoch9, step2462]: loss 9.245034
[epoch9, step2463]: loss 1.265315
[epoch9, step2464]: loss 1.049556
[epoch9, step2465]: loss 2.221292
[epoch9, step2466]: loss 3.011205
[epoch9, step2467]: loss 2.780354
[epoch9, step2468]: loss 8.435654
[epoch9, step2469]: loss 1.237680
[epoch9, step2470]: loss 2.849659
[epoch9, step2471]: loss 2.585010
[epoch9, step2472]: loss 1.786664
[epoch9, step2473]: loss 7.836363
[epoch9, step2474]: loss 2.190168
[epoch9, step2475]: loss 0.889771
[epoch9, step2476]: loss 11.317365
[epoch9, step2477]: loss 4.369538
[epoch9, step2478]: loss 18.682884
[epoch9, step2479]: loss 4.996930
[epoch9, step2480]: loss 15.318715
[epoch9, step2481]: loss 8.060595
[epoch9, step2482]: loss 8.407631
[epoch9, step2483]: loss 1.798807
[epoch9, step2484]: loss 2.448952
[epoch9, step2485]: loss 2.914470
[epoch9, step2486]: loss 2.966878
[epoch9, step2487]: loss 3.979315
[epoch9, step2488]: loss 1.312689
[epoch9, step2489]: loss 2.167922
[epoch9, step2490]: loss 5.274039
[epoch9, step2491]: loss 2.255657
[epoch9, step2492]: loss 9.119674
[epoch9, step2493]: loss 2.029445
[epoch9, step2494]: loss 16.311480
[epoch9, step2495]: loss 5.021954
[epoch9, step2496]: loss 2.528729
[epoch9, step2497]: loss 0.939131
[epoch9, step2498]: loss 1.209195
[epoch9, step2499]: loss 2.164700
[epoch9, step2500]: loss 1.601967
[epoch9, step2501]: loss 1.297831
[epoch9, step2502]: loss 1.615119
[epoch9, step2503]: loss 2.268034
[epoch9, step2504]: loss 1.317925
[epoch9, step2505]: loss 1.692693
[epoch9, step2506]: loss 3.862179
[epoch9, step2507]: loss 6.783246
[epoch9, step2508]: loss 4.596774
[epoch9, step2509]: loss 1.437518
[epoch9, step2510]: loss 16.867702
[epoch9, step2511]: loss 8.839942
[epoch9, step2512]: loss 6.958215
[epoch9, step2513]: loss 1.650646
[epoch9, step2514]: loss 1.229211
[epoch9, step2515]: loss 1.706810
[epoch9, step2516]: loss 20.037016
[epoch9, step2517]: loss 13.694499
[epoch9, step2518]: loss 1.985019
[epoch9, step2519]: loss 6.964736
[epoch9, step2520]: loss 5.919689
[epoch9, step2521]: loss 2.924873
[epoch9, step2522]: loss 27.815483
[epoch9, step2523]: loss 11.161928
[epoch9, step2524]: loss 13.273710
[epoch9, step2525]: loss 2.782222
[epoch9, step2526]: loss 0.948848
[epoch9, step2527]: loss 1.576727
[epoch9, step2528]: loss 1.546863
[epoch9, step2529]: loss 1.095486
[epoch9, step2530]: loss 2.651958
[epoch9, step2531]: loss 13.428062
[epoch9, step2532]: loss 1.639682
[epoch9, step2533]: loss 10.932046
[epoch9, step2534]: loss 5.546230
[epoch9, step2535]: loss 10.836413
[epoch9, step2536]: loss 7.670373
[epoch9, step2537]: loss 1.280741
[epoch9, step2538]: loss 4.444309
[epoch9, step2539]: loss 2.327929
[epoch9, step2540]: loss 2.115124
[epoch9, step2541]: loss 9.108960
[epoch9, step2542]: loss 25.959988
[epoch9, step2543]: loss 11.593329
[epoch9, step2544]: loss 1.529669
[epoch9, step2545]: loss 1.698428
[epoch9, step2546]: loss 1.157233
[epoch9, step2547]: loss 6.444070
[epoch9, step2548]: loss 4.614719
[epoch9, step2549]: loss 9.594087
[epoch9, step2550]: loss 3.433277
[epoch9, step2551]: loss 7.100051
[epoch9, step2552]: loss 1.826741
[epoch9, step2553]: loss 4.690184
[epoch9, step2554]: loss 2.462142
[epoch9, step2555]: loss 12.275412
[epoch9, step2556]: loss 1.749383
[epoch9, step2557]: loss 7.756373
[epoch9, step2558]: loss 2.105606
[epoch9, step2559]: loss 7.635899
[epoch9, step2560]: loss 1.856079
[epoch9, step2561]: loss 10.799811
[epoch9, step2562]: loss 1.269483
[epoch9, step2563]: loss 17.764038
[epoch9, step2564]: loss 1.758980
[epoch9, step2565]: loss 2.649712
[epoch9, step2566]: loss 1.395994
[epoch9, step2567]: loss 8.300694
[epoch9, step2568]: loss 2.809007
[epoch9, step2569]: loss 12.620122
[epoch9, step2570]: loss 3.841431
[epoch9, step2571]: loss 7.538606
[epoch9, step2572]: loss 1.851114
[epoch9, step2573]: loss 1.190538
[epoch9, step2574]: loss 1.468033
[epoch9, step2575]: loss 9.617226
[epoch9, step2576]: loss 2.373498
[epoch9, step2577]: loss 3.239078
[epoch9, step2578]: loss 3.973564
[epoch9, step2579]: loss 6.091315
[epoch9, step2580]: loss 6.363846
[epoch9, step2581]: loss 2.045125
[epoch9, step2582]: loss 1.957463
[epoch9, step2583]: loss 4.698547
[epoch9, step2584]: loss 8.792219
[epoch9, step2585]: loss 8.911843
[epoch9, step2586]: loss 1.080626
[epoch9, step2587]: loss 7.845197
[epoch9, step2588]: loss 6.048774
[epoch9, step2589]: loss 1.634917
[epoch9, step2590]: loss 1.444680
[epoch9, step2591]: loss 2.436006
[epoch9, step2592]: loss 15.754435
[epoch9, step2593]: loss 2.096002
[epoch9, step2594]: loss 13.528253
[epoch9, step2595]: loss 1.621437
[epoch9, step2596]: loss 2.278322
[epoch9, step2597]: loss 4.146282
[epoch9, step2598]: loss 22.043341
[epoch9, step2599]: loss 1.045012
[epoch9, step2600]: loss 2.219851
[epoch9, step2601]: loss 3.282787
[epoch9, step2602]: loss 13.881467
[epoch9, step2603]: loss 1.423740
[epoch9, step2604]: loss 3.055134
[epoch9, step2605]: loss 47.755608
[epoch9, step2606]: loss 1.220176
[epoch9, step2607]: loss 13.855745
[epoch9, step2608]: loss 5.093094
[epoch9, step2609]: loss 4.304606
[epoch9, step2610]: loss 2.416131
[epoch9, step2611]: loss 8.557667
[epoch9, step2612]: loss 2.321993
[epoch9, step2613]: loss 2.068134
[epoch9, step2614]: loss 1.520452
[epoch9, step2615]: loss 0.934613
[epoch9, step2616]: loss 1.354909
[epoch9, step2617]: loss 13.330760
[epoch9, step2618]: loss 2.880032
[epoch9, step2619]: loss 1.887036
[epoch9, step2620]: loss 2.696611
[epoch9, step2621]: loss 1.552747
[epoch9, step2622]: loss 1.478088
[epoch9, step2623]: loss 2.128040
[epoch9, step2624]: loss 3.004740
[epoch9, step2625]: loss 2.081130
[epoch9, step2626]: loss 7.049651
[epoch9, step2627]: loss 7.611557
[epoch9, step2628]: loss 6.262712
[epoch9, step2629]: loss 11.517473
[epoch9, step2630]: loss 11.342387
[epoch9, step2631]: loss 3.533327
[epoch9, step2632]: loss 10.990667
[epoch9, step2633]: loss 5.338721
[epoch9, step2634]: loss 6.123046
[epoch9, step2635]: loss 3.226315
[epoch9, step2636]: loss 11.286785
[epoch9, step2637]: loss 9.876399
[epoch9, step2638]: loss 10.791410
[epoch9, step2639]: loss 10.383218
[epoch9, step2640]: loss 7.680685
[epoch9, step2641]: loss 10.371876
[epoch9, step2642]: loss 1.388438
[epoch9, step2643]: loss 1.434585
[epoch9, step2644]: loss 1.377365
[epoch9, step2645]: loss 1.408830
[epoch9, step2646]: loss 0.971083
[epoch9, step2647]: loss 6.066921
[epoch9, step2648]: loss 3.116157
[epoch9, step2649]: loss 7.782421
[epoch9, step2650]: loss 4.564232
[epoch9, step2651]: loss 9.096745
[epoch9, step2652]: loss 1.690921
[epoch9, step2653]: loss 0.829403
[epoch9, step2654]: loss 9.125010
[epoch9, step2655]: loss 1.720463
[epoch9, step2656]: loss 1.410680
[epoch9, step2657]: loss 10.632721
[epoch9, step2658]: loss 2.335164
[epoch9, step2659]: loss 1.606574
[epoch9, step2660]: loss 9.015968
[epoch9, step2661]: loss 16.351496
[epoch9, step2662]: loss 1.917999
[epoch9, step2663]: loss 14.981677
[epoch9, step2664]: loss 11.841924
[epoch9, step2665]: loss 2.746572
[epoch9, step2666]: loss 2.685137
[epoch9, step2667]: loss 3.460614
[epoch9, step2668]: loss 1.663160
[epoch9, step2669]: loss 1.181477
[epoch9, step2670]: loss 6.458972
[epoch9, step2671]: loss 3.175709
[epoch9, step2672]: loss 7.800928
[epoch9, step2673]: loss 4.565914
[epoch9, step2674]: loss 1.052473
[epoch9, step2675]: loss 2.273947
[epoch9, step2676]: loss 1.203818
[epoch9, step2677]: loss 1.979271
[epoch9, step2678]: loss 4.201502
[epoch9, step2679]: loss 9.292907
[epoch9, step2680]: loss 9.771851
[epoch9, step2681]: loss 7.444796
[epoch9, step2682]: loss 1.666725
[epoch9, step2683]: loss 2.960090
[epoch9, step2684]: loss 10.041944
[epoch9, step2685]: loss 1.643739
[epoch9, step2686]: loss 4.153395
[epoch9, step2687]: loss 3.544666
[epoch9, step2688]: loss 1.954758
[epoch9, step2689]: loss 1.013613
[epoch9, step2690]: loss 1.535015
[epoch9, step2691]: loss 1.399304
[epoch9, step2692]: loss 1.977143
[epoch9, step2693]: loss 1.101419
[epoch9, step2694]: loss 1.279854
[epoch9, step2695]: loss 3.001086
[epoch9, step2696]: loss 3.771204
[epoch9, step2697]: loss 6.715496
[epoch9, step2698]: loss 5.020303
[epoch9, step2699]: loss 1.237526
[epoch9, step2700]: loss 2.233351
[epoch9, step2701]: loss 4.035383
[epoch9, step2702]: loss 1.441405
[epoch9, step2703]: loss 4.875160
[epoch9, step2704]: loss 2.009704
[epoch9, step2705]: loss 13.649151
[epoch9, step2706]: loss 2.120401
[epoch9, step2707]: loss 19.840477
[epoch9, step2708]: loss 8.208827
[epoch9, step2709]: loss 1.625079
[epoch9, step2710]: loss 1.092377
[epoch9, step2711]: loss 0.714903
[epoch9, step2712]: loss 16.525816
[epoch9, step2713]: loss 5.091467
[epoch9, step2714]: loss 1.369455
[epoch9, step2715]: loss 0.774090
[epoch9, step2716]: loss 2.055120
[epoch9, step2717]: loss 5.202350
[epoch9, step2718]: loss 9.289197
[epoch9, step2719]: loss 1.091438
[epoch9, step2720]: loss 0.838690
[epoch9, step2721]: loss 9.944501
[epoch9, step2722]: loss 5.708880
[epoch9, step2723]: loss 13.482184
[epoch9, step2724]: loss 5.345229
[epoch9, step2725]: loss 2.876776
[epoch9, step2726]: loss 0.866970
[epoch9, step2727]: loss 3.505974
[epoch9, step2728]: loss 4.181530
[epoch9, step2729]: loss 12.479089
[epoch9, step2730]: loss 1.773824
[epoch9, step2731]: loss 1.299213
[epoch9, step2732]: loss 1.800531
[epoch9, step2733]: loss 7.492333
[epoch9, step2734]: loss 7.384167
[epoch9, step2735]: loss 1.328696
[epoch9, step2736]: loss 3.934583
[epoch9, step2737]: loss 12.563741
[epoch9, step2738]: loss 1.765386
[epoch9, step2739]: loss 8.250206
[epoch9, step2740]: loss 2.646874
[epoch9, step2741]: loss 3.558034
[epoch9, step2742]: loss 0.831164
[epoch9, step2743]: loss 1.617846
[epoch9, step2744]: loss 1.671234
[epoch9, step2745]: loss 1.181266
[epoch9, step2746]: loss 0.968275
[epoch9, step2747]: loss 1.012716
[epoch9, step2748]: loss 5.774767
[epoch9, step2749]: loss 1.874539
[epoch9, step2750]: loss 15.648823
[epoch9, step2751]: loss 1.084241
[epoch9, step2752]: loss 21.639904
[epoch9, step2753]: loss 1.338106
[epoch9, step2754]: loss 17.313885
[epoch9, step2755]: loss 2.890121
[epoch9, step2756]: loss 1.352278
[epoch9, step2757]: loss 16.075388
[epoch9, step2758]: loss 1.655344
[epoch9, step2759]: loss 2.374310
[epoch9, step2760]: loss 1.184879
[epoch9, step2761]: loss 9.294828
[epoch9, step2762]: loss 0.997801
[epoch9, step2763]: loss 9.144272
[epoch9, step2764]: loss 11.075551
[epoch9, step2765]: loss 1.673774
[epoch9, step2766]: loss 13.931152
[epoch9, step2767]: loss 10.529374
[epoch9, step2768]: loss 1.930215
[epoch9, step2769]: loss 1.090761
[epoch9, step2770]: loss 2.177712
[epoch9, step2771]: loss 12.493731
[epoch9, step2772]: loss 1.990036
[epoch9, step2773]: loss 1.853966
[epoch9, step2774]: loss 1.174905
[epoch9, step2775]: loss 1.321808
[epoch9, step2776]: loss 7.918850
[epoch9, step2777]: loss 1.697203
[epoch9, step2778]: loss 20.650103
[epoch9, step2779]: loss 0.814642
[epoch9, step2780]: loss 9.857415
[epoch9, step2781]: loss 9.825316
[epoch9, step2782]: loss 1.032787
[epoch9, step2783]: loss 5.626406
[epoch9, step2784]: loss 1.407318
[epoch9, step2785]: loss 0.906939
[epoch9, step2786]: loss 11.977980
[epoch9, step2787]: loss 8.836729
[epoch9, step2788]: loss 1.159906
[epoch9, step2789]: loss 1.186247
[epoch9, step2790]: loss 1.101880
[epoch9, step2791]: loss 1.985108
[epoch9, step2792]: loss 1.362842
[epoch9, step2793]: loss 0.982746
[epoch9, step2794]: loss 3.310987
[epoch9, step2795]: loss 2.634421
[epoch9, step2796]: loss 7.361907
[epoch9, step2797]: loss 3.118398
[epoch9, step2798]: loss 2.314468
[epoch9, step2799]: loss 2.039429
[epoch9, step2800]: loss 2.978741
[epoch9, step2801]: loss 1.592107
[epoch9, step2802]: loss 4.127353
[epoch9, step2803]: loss 2.996134
[epoch9, step2804]: loss 9.488241
[epoch9, step2805]: loss 6.770941
[epoch9, step2806]: loss 3.325324
[epoch9, step2807]: loss 1.995588
[epoch9, step2808]: loss 7.105877
[epoch9, step2809]: loss 9.561969
[epoch9, step2810]: loss 1.833797
[epoch9, step2811]: loss 12.711087
[epoch9, step2812]: loss 8.343699
[epoch9, step2813]: loss 0.999084
[epoch9, step2814]: loss 6.746596
[epoch9, step2815]: loss 1.157356
[epoch9, step2816]: loss 1.056217
[epoch9, step2817]: loss 2.589120
[epoch9, step2818]: loss 2.063962
[epoch9, step2819]: loss 15.346414
[epoch9, step2820]: loss 6.365330
[epoch9, step2821]: loss 7.779018
[epoch9, step2822]: loss 2.965081
[epoch9, step2823]: loss 2.447433
[epoch9, step2824]: loss 19.014858
[epoch9, step2825]: loss 22.363998
[epoch9, step2826]: loss 1.985227
[epoch9, step2827]: loss 9.674474
[epoch9, step2828]: loss 9.747343
[epoch9, step2829]: loss 11.471466
[epoch9, step2830]: loss 1.538514
[epoch9, step2831]: loss 1.105793
[epoch9, step2832]: loss 2.511019
[epoch9, step2833]: loss 1.736078
[epoch9, step2834]: loss 3.106004
[epoch9, step2835]: loss 1.744605
[epoch9, step2836]: loss 14.855368
[epoch9, step2837]: loss 1.986243
[epoch9, step2838]: loss 1.374160
[epoch9, step2839]: loss 10.063582
[epoch9, step2840]: loss 1.522695
[epoch9, step2841]: loss 1.841075
[epoch9, step2842]: loss 12.460799
[epoch9, step2843]: loss 19.631205
[epoch9, step2844]: loss 12.309076
[epoch9, step2845]: loss 2.184269
[epoch9, step2846]: loss 2.560051
[epoch9, step2847]: loss 2.309146
[epoch9, step2848]: loss 2.599289
[epoch9, step2849]: loss 12.186764
[epoch9, step2850]: loss 4.235875
[epoch9, step2851]: loss 1.281282
[epoch9, step2852]: loss 1.256546
[epoch9, step2853]: loss 5.137185
[epoch9, step2854]: loss 1.124291
[epoch9, step2855]: loss 1.786262
[epoch9, step2856]: loss 2.128408
[epoch9, step2857]: loss 7.279934
[epoch9, step2858]: loss 3.708397
[epoch9, step2859]: loss 2.411541
[epoch9, step2860]: loss 3.445749
[epoch9, step2861]: loss 2.508201
[epoch9, step2862]: loss 1.717947
[epoch9, step2863]: loss 10.384209
[epoch9, step2864]: loss 3.876833
[epoch9, step2865]: loss 3.559990
[epoch9, step2866]: loss 1.345542
[epoch9, step2867]: loss 0.993157
[epoch9, step2868]: loss 2.933155
[epoch9, step2869]: loss 4.995260
[epoch9, step2870]: loss 1.937938
[epoch9, step2871]: loss 1.202377
[epoch9, step2872]: loss 1.533281
[epoch9, step2873]: loss 14.002827
[epoch9, step2874]: loss 1.310278
[epoch9, step2875]: loss 10.977981
[epoch9, step2876]: loss 11.102564
[epoch9, step2877]: loss 3.529931
[epoch9, step2878]: loss 10.431706
[epoch9, step2879]: loss 3.006186
[epoch9, step2880]: loss 1.198421
[epoch9, step2881]: loss 3.440059
[epoch9, step2882]: loss 21.324110
[epoch9, step2883]: loss 1.744361
[epoch9, step2884]: loss 2.053074
[epoch9, step2885]: loss 1.638390
[epoch9, step2886]: loss 1.691546
[epoch9, step2887]: loss 1.786052
[epoch9, step2888]: loss 4.759206
[epoch9, step2889]: loss 13.053333
[epoch9, step2890]: loss 3.757811
[epoch9, step2891]: loss 2.052402
[epoch9, step2892]: loss 0.995833
[epoch9, step2893]: loss 1.004378
[epoch9, step2894]: loss 7.622913
[epoch9, step2895]: loss 9.153350
[epoch9, step2896]: loss 1.206793
[epoch9, step2897]: loss 4.773868
[epoch9, step2898]: loss 9.341232
[epoch9, step2899]: loss 6.105235
[epoch9, step2900]: loss 2.667167
[epoch9, step2901]: loss 2.780503
[epoch9, step2902]: loss 1.030399
[epoch9, step2903]: loss 1.670936
[epoch9, step2904]: loss 4.405589
[epoch9, step2905]: loss 1.964248
[epoch9, step2906]: loss 4.916901
[epoch9, step2907]: loss 2.016362
[epoch9, step2908]: loss 7.959169
[epoch9, step2909]: loss 14.251827
[epoch9, step2910]: loss 21.675304
[epoch9, step2911]: loss 2.646925
[epoch9, step2912]: loss 8.533173
[epoch9, step2913]: loss 1.856469
[epoch9, step2914]: loss 4.695621
[epoch9, step2915]: loss 1.255352
[epoch9, step2916]: loss 15.172869
[epoch9, step2917]: loss 12.464121
[epoch9, step2918]: loss 6.413477
[epoch9, step2919]: loss 1.221190
[epoch9, step2920]: loss 2.619954
[epoch9, step2921]: loss 4.231456
[epoch9, step2922]: loss 1.735482
[epoch9, step2923]: loss 4.706899
[epoch9, step2924]: loss 7.074870
[epoch9, step2925]: loss 19.238852
[epoch9, step2926]: loss 2.128661
[epoch9, step2927]: loss 1.377995
[epoch9, step2928]: loss 1.131527
[epoch9, step2929]: loss 16.948149
[epoch9, step2930]: loss 14.866489
[epoch9, step2931]: loss 1.377874
[epoch9, step2932]: loss 5.674604
[epoch9, step2933]: loss 8.856400
[epoch9, step2934]: loss 1.663304
[epoch9, step2935]: loss 5.569970
[epoch9, step2936]: loss 2.566062
[epoch9, step2937]: loss 3.125959
[epoch9, step2938]: loss 1.193581
[epoch9, step2939]: loss 5.459041
[epoch9, step2940]: loss 2.624256
[epoch9, step2941]: loss 11.732772
[epoch9, step2942]: loss 5.106818
[epoch9, step2943]: loss 1.546900
[epoch9, step2944]: loss 2.035455
[epoch9, step2945]: loss 9.800599
[epoch9, step2946]: loss 13.072604
[epoch9, step2947]: loss 0.825933
[epoch9, step2948]: loss 2.504501
[epoch9, step2949]: loss 15.962227
[epoch9, step2950]: loss 5.674679
[epoch9, step2951]: loss 2.029358
[epoch9, step2952]: loss 2.519311
[epoch9, step2953]: loss 0.977283
[epoch9, step2954]: loss 2.162318
[epoch9, step2955]: loss 10.218773
[epoch9, step2956]: loss 3.286994
[epoch9, step2957]: loss 7.825611
[epoch9, step2958]: loss 3.834176
[epoch9, step2959]: loss 8.962131
[epoch9, step2960]: loss 1.011387
[epoch9, step2961]: loss 12.489631
[epoch9, step2962]: loss 11.050656
[epoch9, step2963]: loss 3.625432
[epoch9, step2964]: loss 1.729711
[epoch9, step2965]: loss 6.806319
[epoch9, step2966]: loss 2.174788
[epoch9, step2967]: loss 7.523269
[epoch9, step2968]: loss 9.444484
[epoch9, step2969]: loss 11.349645
[epoch9, step2970]: loss 1.446923
[epoch9, step2971]: loss 1.904613
[epoch9, step2972]: loss 1.153368
[epoch9, step2973]: loss 13.955912
[epoch9, step2974]: loss 4.888906
[epoch9, step2975]: loss 3.288867
[epoch9, step2976]: loss 3.516103
[epoch9, step2977]: loss 7.360430
[epoch9, step2978]: loss 15.089828
[epoch9, step2979]: loss 13.261289
[epoch9, step2980]: loss 0.797348
[epoch9, step2981]: loss 2.060088
[epoch9, step2982]: loss 11.214846
[epoch9, step2983]: loss 1.307713
[epoch9, step2984]: loss 1.343743
[epoch9, step2985]: loss 10.937678
[epoch9, step2986]: loss 19.236744
[epoch9, step2987]: loss 4.764644
[epoch9, step2988]: loss 8.712807
[epoch9, step2989]: loss 13.229999
[epoch9, step2990]: loss 5.420007
[epoch9, step2991]: loss 11.318843
[epoch9, step2992]: loss 1.110247
[epoch9, step2993]: loss 0.775545
[epoch9, step2994]: loss 25.489368
[epoch9, step2995]: loss 9.105912
[epoch9, step2996]: loss 9.375830
[epoch9, step2997]: loss 1.118376
[epoch9, step2998]: loss 9.165236
[epoch9, step2999]: loss 12.010468
[epoch9, step3000]: loss 1.701914
[epoch9, step3001]: loss 2.257496
[epoch9, step3002]: loss 3.613957
[epoch9, step3003]: loss 3.806005
[epoch9, step3004]: loss 3.584439
[epoch9, step3005]: loss 3.303756
[epoch9, step3006]: loss 15.823483
[epoch9, step3007]: loss 12.601796
[epoch9, step3008]: loss 1.970400
[epoch9, step3009]: loss 11.726100
[epoch9, step3010]: loss 2.372870
[epoch9, step3011]: loss 4.424073
[epoch9, step3012]: loss 1.576422
[epoch9, step3013]: loss 1.768264
[epoch9, step3014]: loss 12.371225
[epoch9, step3015]: loss 1.796303
[epoch9, step3016]: loss 2.809382
[epoch9, step3017]: loss 1.281318
[epoch9, step3018]: loss 2.597738
[epoch9, step3019]: loss 5.403497
[epoch9, step3020]: loss 8.958084
[epoch9, step3021]: loss 4.368999
[epoch9, step3022]: loss 1.905043
[epoch9, step3023]: loss 12.337967
[epoch9, step3024]: loss 18.996502
[epoch9, step3025]: loss 15.033514
[epoch9, step3026]: loss 11.196875
[epoch9, step3027]: loss 0.893910
[epoch9, step3028]: loss 2.442451
[epoch9, step3029]: loss 1.234899
[epoch9, step3030]: loss 8.035031
[epoch9, step3031]: loss 11.083412
[epoch9, step3032]: loss 2.001870
[epoch9, step3033]: loss 12.318900
[epoch9, step3034]: loss 1.561673
[epoch9, step3035]: loss 1.573795
[epoch9, step3036]: loss 2.703138
[epoch9, step3037]: loss 1.561835
[epoch9, step3038]: loss 3.221833
[epoch9, step3039]: loss 11.120435
[epoch9, step3040]: loss 1.006581
[epoch9, step3041]: loss 2.288013
[epoch9, step3042]: loss 6.402230
[epoch9, step3043]: loss 1.574211
[epoch9, step3044]: loss 3.938467
[epoch9, step3045]: loss 9.770292
[epoch9, step3046]: loss 9.139853
[epoch9, step3047]: loss 2.476098
[epoch9, step3048]: loss 11.064613
[epoch9, step3049]: loss 1.685993
[epoch9, step3050]: loss 0.949327
[epoch9, step3051]: loss 5.248833
[epoch9, step3052]: loss 1.024696
[epoch9, step3053]: loss 2.886974
[epoch9, step3054]: loss 2.756739
[epoch9, step3055]: loss 11.197683
[epoch9, step3056]: loss 13.976622
[epoch9, step3057]: loss 7.532150
[epoch9, step3058]: loss 1.267401
[epoch9, step3059]: loss 2.217867
[epoch9, step3060]: loss 6.764820
[epoch9, step3061]: loss 1.330293
[epoch9, step3062]: loss 14.802691
[epoch9, step3063]: loss 3.428409
[epoch9, step3064]: loss 27.310204
[epoch9, step3065]: loss 13.488550
[epoch9, step3066]: loss 1.091623
[epoch9, step3067]: loss 7.882083
[epoch9, step3068]: loss 3.937494
[epoch9, step3069]: loss 13.141747
[epoch9, step3070]: loss 1.908349
[epoch9, step3071]: loss 5.944853
[epoch9, step3072]: loss 8.564272
[epoch9, step3073]: loss 1.757638
[epoch9, step3074]: loss 6.377352
[epoch9, step3075]: loss 3.352325
[epoch9, step3076]: loss 2.047000

[epoch9]: avg loss 2.047000

[epoch10, step1]: loss 1.602169
[epoch10, step2]: loss 12.731892
[epoch10, step3]: loss 3.749723
[epoch10, step4]: loss 4.437986
[epoch10, step5]: loss 5.366129
[epoch10, step6]: loss 9.593443
[epoch10, step7]: loss 2.101471
[epoch10, step8]: loss 1.675851
[epoch10, step9]: loss 2.134708
[epoch10, step10]: loss 1.767900
[epoch10, step11]: loss 1.059942
[epoch10, step12]: loss 0.870691
[epoch10, step13]: loss 11.850045
[epoch10, step14]: loss 1.613068
[epoch10, step15]: loss 1.477423
[epoch10, step16]: loss 3.075652
[epoch10, step17]: loss 1.422233
[epoch10, step18]: loss 4.568993
[epoch10, step19]: loss 9.549513
[epoch10, step20]: loss 9.565580
[epoch10, step21]: loss 1.801825
[epoch10, step22]: loss 4.730661
[epoch10, step23]: loss 2.453201
[epoch10, step24]: loss 3.376575
[epoch10, step25]: loss 3.121766
[epoch10, step26]: loss 0.991553
[epoch10, step27]: loss 1.916196
[epoch10, step28]: loss 9.979775
[epoch10, step29]: loss 1.521362
[epoch10, step30]: loss 6.716166
[epoch10, step31]: loss 4.565755
[epoch10, step32]: loss 1.935842
[epoch10, step33]: loss 3.288855
[epoch10, step34]: loss 1.567352
[epoch10, step35]: loss 3.233390
[epoch10, step36]: loss 7.659192
[epoch10, step37]: loss 1.903731
[epoch10, step38]: loss 4.688541
[epoch10, step39]: loss 12.469251
[epoch10, step40]: loss 2.308598
[epoch10, step41]: loss 0.832165
[epoch10, step42]: loss 0.780020
[epoch10, step43]: loss 7.422635
[epoch10, step44]: loss 2.694108
[epoch10, step45]: loss 1.405351
[epoch10, step46]: loss 1.371667
[epoch10, step47]: loss 3.665401
[epoch10, step48]: loss 15.355322
[epoch10, step49]: loss 1.315990
[epoch10, step50]: loss 9.197555
[epoch10, step51]: loss 1.240246
[epoch10, step52]: loss 5.020852
[epoch10, step53]: loss 8.247859
[epoch10, step54]: loss 0.828020
[epoch10, step55]: loss 12.221795
[epoch10, step56]: loss 11.099891
[epoch10, step57]: loss 9.579484
[epoch10, step58]: loss 1.870752
[epoch10, step59]: loss 2.033704
[epoch10, step60]: loss 12.806050
[epoch10, step61]: loss 7.620770
[epoch10, step62]: loss 1.864124
[epoch10, step63]: loss 1.602127
[epoch10, step64]: loss 6.280470
[epoch10, step65]: loss 23.270613
[epoch10, step66]: loss 11.078278
[epoch10, step67]: loss 2.454645
[epoch10, step68]: loss 16.912128
[epoch10, step69]: loss 10.586273
[epoch10, step70]: loss 12.282238
[epoch10, step71]: loss 2.852884
[epoch10, step72]: loss 3.259233
[epoch10, step73]: loss 19.674526
[epoch10, step74]: loss 14.785140
[epoch10, step75]: loss 4.267472
[epoch10, step76]: loss 2.676330
[epoch10, step77]: loss 1.729927
[epoch10, step78]: loss 1.205656
[epoch10, step79]: loss 8.442136
[epoch10, step80]: loss 11.807981
[epoch10, step81]: loss 1.961217
[epoch10, step82]: loss 2.331747
[epoch10, step83]: loss 0.852695
[epoch10, step84]: loss 4.906963
[epoch10, step85]: loss 9.571038
[epoch10, step86]: loss 1.894608
[epoch10, step87]: loss 34.525925
[epoch10, step88]: loss 10.423379
[epoch10, step89]: loss 7.510242
[epoch10, step90]: loss 1.113944
[epoch10, step91]: loss 1.849756
[epoch10, step92]: loss 2.155305
[epoch10, step93]: loss 3.140337
[epoch10, step94]: loss 0.894446
[epoch10, step95]: loss 6.326836
[epoch10, step96]: loss 1.464054
[epoch10, step97]: loss 8.609425
[epoch10, step98]: loss 1.090457
[epoch10, step99]: loss 6.627984
[epoch10, step100]: loss 16.515270
[epoch10, step101]: loss 2.744792
[epoch10, step102]: loss 1.387240
[epoch10, step103]: loss 1.701256
[epoch10, step104]: loss 1.753660
[epoch10, step105]: loss 11.886488
[epoch10, step106]: loss 1.296228
[epoch10, step107]: loss 2.721007
[epoch10, step108]: loss 7.821478
[epoch10, step109]: loss 1.222867
[epoch10, step110]: loss 10.819593
[epoch10, step111]: loss 1.311364
[epoch10, step112]: loss 2.021320
[epoch10, step113]: loss 1.623432
[epoch10, step114]: loss 1.364014
[epoch10, step115]: loss 1.365927
[epoch10, step116]: loss 2.668307
[epoch10, step117]: loss 1.956454
[epoch10, step118]: loss 1.186988
[epoch10, step119]: loss 1.412897
[epoch10, step120]: loss 2.755805
[epoch10, step121]: loss 1.557748
[epoch10, step122]: loss 1.277662
[epoch10, step123]: loss 9.367916
[epoch10, step124]: loss 7.410131
[epoch10, step125]: loss 1.163073
[epoch10, step126]: loss 2.662134
[epoch10, step127]: loss 7.204062
[epoch10, step128]: loss 1.386381
[epoch10, step129]: loss 2.677363
[epoch10, step130]: loss 2.379784
[epoch10, step131]: loss 12.284651
[epoch10, step132]: loss 2.797427
[epoch10, step133]: loss 9.661699
[epoch10, step134]: loss 3.282941
[epoch10, step135]: loss 14.159325
[epoch10, step136]: loss 10.639354
[epoch10, step137]: loss 1.645480
[epoch10, step138]: loss 4.231525
[epoch10, step139]: loss 15.562456
[epoch10, step140]: loss 6.193444
[epoch10, step141]: loss 2.152488
[epoch10, step142]: loss 10.700951
[epoch10, step143]: loss 11.652263
[epoch10, step144]: loss 6.126068
[epoch10, step145]: loss 1.352101
[epoch10, step146]: loss 1.249285
[epoch10, step147]: loss 1.572507
[epoch10, step148]: loss 11.517622
[epoch10, step149]: loss 1.768929
[epoch10, step150]: loss 1.650564
[epoch10, step151]: loss 11.436730
[epoch10, step152]: loss 1.538488
[epoch10, step153]: loss 2.904943
[epoch10, step154]: loss 13.578059
[epoch10, step155]: loss 11.840315
[epoch10, step156]: loss 4.948188
[epoch10, step157]: loss 6.399546
[epoch10, step158]: loss 1.146463
[epoch10, step159]: loss 2.362452
[epoch10, step160]: loss 13.393368
[epoch10, step161]: loss 1.980065
[epoch10, step162]: loss 1.405264
[epoch10, step163]: loss 8.132343
[epoch10, step164]: loss 1.587501
[epoch10, step165]: loss 1.278630
[epoch10, step166]: loss 5.676458
[epoch10, step167]: loss 2.542981
[epoch10, step168]: loss 4.237917
[epoch10, step169]: loss 1.445969
[epoch10, step170]: loss 1.883448
[epoch10, step171]: loss 14.164684
[epoch10, step172]: loss 5.951875
[epoch10, step173]: loss 8.266838
[epoch10, step174]: loss 1.700444
[epoch10, step175]: loss 8.315191
[epoch10, step176]: loss 1.243565
[epoch10, step177]: loss 2.642596
[epoch10, step178]: loss 9.310905
[epoch10, step179]: loss 8.262781
[epoch10, step180]: loss 6.405712
[epoch10, step181]: loss 1.922272
[epoch10, step182]: loss 9.273663
[epoch10, step183]: loss 7.957866
[epoch10, step184]: loss 3.629130
[epoch10, step185]: loss 14.753346
[epoch10, step186]: loss 8.335248
[epoch10, step187]: loss 2.126800
[epoch10, step188]: loss 8.025189
[epoch10, step189]: loss 4.541307
[epoch10, step190]: loss 2.735023
[epoch10, step191]: loss 11.904928
[epoch10, step192]: loss 3.468779
[epoch10, step193]: loss 1.397395
[epoch10, step194]: loss 14.393516
[epoch10, step195]: loss 0.901777
[epoch10, step196]: loss 3.738045
[epoch10, step197]: loss 2.538126
[epoch10, step198]: loss 1.383943
[epoch10, step199]: loss 2.956995
[epoch10, step200]: loss 29.052330
[epoch10, step201]: loss 1.077044
[epoch10, step202]: loss 1.261753
[epoch10, step203]: loss 1.425438
[epoch10, step204]: loss 4.558116
[epoch10, step205]: loss 6.460607
[epoch10, step206]: loss 2.168145
[epoch10, step207]: loss 6.473123
[epoch10, step208]: loss 8.938248
[epoch10, step209]: loss 1.900761
[epoch10, step210]: loss 1.833266
[epoch10, step211]: loss 14.060351
[epoch10, step212]: loss 1.504687
[epoch10, step213]: loss 4.004069
[epoch10, step214]: loss 1.071324
[epoch10, step215]: loss 10.680813
[epoch10, step216]: loss 1.801277
[epoch10, step217]: loss 3.094625
[epoch10, step218]: loss 10.139714
[epoch10, step219]: loss 9.923586
[epoch10, step220]: loss 2.414284
[epoch10, step221]: loss 3.397075
[epoch10, step222]: loss 1.042441
[epoch10, step223]: loss 1.315834
[epoch10, step224]: loss 7.443799
[epoch10, step225]: loss 2.523280
[epoch10, step226]: loss 8.924784
[epoch10, step227]: loss 13.231981
[epoch10, step228]: loss 3.604509
[epoch10, step229]: loss 1.035205
[epoch10, step230]: loss 2.023613
[epoch10, step231]: loss 1.244107
[epoch10, step232]: loss 1.609517
[epoch10, step233]: loss 1.225372
[epoch10, step234]: loss 4.047785
[epoch10, step235]: loss 1.965562
[epoch10, step236]: loss 3.299047
[epoch10, step237]: loss 10.636488
[epoch10, step238]: loss 1.693642
[epoch10, step239]: loss 1.101535
[epoch10, step240]: loss 1.364094
[epoch10, step241]: loss 3.294874
[epoch10, step242]: loss 2.526082
[epoch10, step243]: loss 4.850965
[epoch10, step244]: loss 11.650241
[epoch10, step245]: loss 9.862809
[epoch10, step246]: loss 1.094175
[epoch10, step247]: loss 3.918051
[epoch10, step248]: loss 2.623240
[epoch10, step249]: loss 1.198618
[epoch10, step250]: loss 1.598850
[epoch10, step251]: loss 1.391174
[epoch10, step252]: loss 2.695082
[epoch10, step253]: loss 1.029970
[epoch10, step254]: loss 1.210612
[epoch10, step255]: loss 0.947273
[epoch10, step256]: loss 4.599898
[epoch10, step257]: loss 1.505094
[epoch10, step258]: loss 15.423925
[epoch10, step259]: loss 7.917904
[epoch10, step260]: loss 1.232531
[epoch10, step261]: loss 2.268570
[epoch10, step262]: loss 0.991051
[epoch10, step263]: loss 8.485995
[epoch10, step264]: loss 1.428176
[epoch10, step265]: loss 3.269160
[epoch10, step266]: loss 0.994725
[epoch10, step267]: loss 1.494905
[epoch10, step268]: loss 2.086231
[epoch10, step269]: loss 3.570459
[epoch10, step270]: loss 4.925907
[epoch10, step271]: loss 2.422563
[epoch10, step272]: loss 1.732337
[epoch10, step273]: loss 4.057444
[epoch10, step274]: loss 2.140396
[epoch10, step275]: loss 3.192949
[epoch10, step276]: loss 3.613416
[epoch10, step277]: loss 7.256659
[epoch10, step278]: loss 2.979066
[epoch10, step279]: loss 1.089672
[epoch10, step280]: loss 12.918990
[epoch10, step281]: loss 7.693981
[epoch10, step282]: loss 10.212432
[epoch10, step283]: loss 15.123042
[epoch10, step284]: loss 1.600710
[epoch10, step285]: loss 1.436492
[epoch10, step286]: loss 10.592849
[epoch10, step287]: loss 1.145821
[epoch10, step288]: loss 9.490408
[epoch10, step289]: loss 8.357646
[epoch10, step290]: loss 13.905230
[epoch10, step291]: loss 1.329213
[epoch10, step292]: loss 2.494439
[epoch10, step293]: loss 1.639348
[epoch10, step294]: loss 4.980135
[epoch10, step295]: loss 4.190988
[epoch10, step296]: loss 9.635237
[epoch10, step297]: loss 4.186320
[epoch10, step298]: loss 2.381289
[epoch10, step299]: loss 0.795301
[epoch10, step300]: loss 8.951846
[epoch10, step301]: loss 9.067327
[epoch10, step302]: loss 1.137738
[epoch10, step303]: loss 1.480060
[epoch10, step304]: loss 4.121850
[epoch10, step305]: loss 2.249114
[epoch10, step306]: loss 7.691463
[epoch10, step307]: loss 1.502115
[epoch10, step308]: loss 3.029818
[epoch10, step309]: loss 6.120352
[epoch10, step310]: loss 1.411853
[epoch10, step311]: loss 3.274372
[epoch10, step312]: loss 3.013976
[epoch10, step313]: loss 7.076520
[epoch10, step314]: loss 11.111626
[epoch10, step315]: loss 3.063161
[epoch10, step316]: loss 14.173278
[epoch10, step317]: loss 1.291344
[epoch10, step318]: loss 6.568990
[epoch10, step319]: loss 2.002063
[epoch10, step320]: loss 4.183414
[epoch10, step321]: loss 1.234617
[epoch10, step322]: loss 5.154087
[epoch10, step323]: loss 9.694514
[epoch10, step324]: loss 13.447468
[epoch10, step325]: loss 9.492332
[epoch10, step326]: loss 1.975344
[epoch10, step327]: loss 7.687798
[epoch10, step328]: loss 2.242426
[epoch10, step329]: loss 3.007670
[epoch10, step330]: loss 3.740612
[epoch10, step331]: loss 7.542478
[epoch10, step332]: loss 1.823135
[epoch10, step333]: loss 3.691476
[epoch10, step334]: loss 11.033961
[epoch10, step335]: loss 7.948810
[epoch10, step336]: loss 1.476623
[epoch10, step337]: loss 1.426774
[epoch10, step338]: loss 12.907483
[epoch10, step339]: loss 25.657799
[epoch10, step340]: loss 1.493191
[epoch10, step341]: loss 1.973594
[epoch10, step342]: loss 2.449722
[epoch10, step343]: loss 11.287112
[epoch10, step344]: loss 15.426701
[epoch10, step345]: loss 17.802767
[epoch10, step346]: loss 17.096462
[epoch10, step347]: loss 1.636620
[epoch10, step348]: loss 6.494378
[epoch10, step349]: loss 1.250342
[epoch10, step350]: loss 4.613761
[epoch10, step351]: loss 11.413893
[epoch10, step352]: loss 16.972712
[epoch10, step353]: loss 1.412063
[epoch10, step354]: loss 10.771175
[epoch10, step355]: loss 5.784867
[epoch10, step356]: loss 6.822401
[epoch10, step357]: loss 1.747134
[epoch10, step358]: loss 0.971496
[epoch10, step359]: loss 11.215578
[epoch10, step360]: loss 1.621562
[epoch10, step361]: loss 1.951980
[epoch10, step362]: loss 1.809818
[epoch10, step363]: loss 7.475873
[epoch10, step364]: loss 10.894598
[epoch10, step365]: loss 23.174540
[epoch10, step366]: loss 1.504374
[epoch10, step367]: loss 4.607733
[epoch10, step368]: loss 2.561994
[epoch10, step369]: loss 1.563066
[epoch10, step370]: loss 5.617807
[epoch10, step371]: loss 3.172615
[epoch10, step372]: loss 4.165184
[epoch10, step373]: loss 28.208021
[epoch10, step374]: loss 9.939304
[epoch10, step375]: loss 1.001190
[epoch10, step376]: loss 12.206143
[epoch10, step377]: loss 2.175692
[epoch10, step378]: loss 0.967294
[epoch10, step379]: loss 2.127377
[epoch10, step380]: loss 1.548831
[epoch10, step381]: loss 10.857955
[epoch10, step382]: loss 26.185068
[epoch10, step383]: loss 1.410493
[epoch10, step384]: loss 3.623430
[epoch10, step385]: loss 3.457653
[epoch10, step386]: loss 1.167411
[epoch10, step387]: loss 1.404339
[epoch10, step388]: loss 8.532232
[epoch10, step389]: loss 1.130129
[epoch10, step390]: loss 1.469669
[epoch10, step391]: loss 1.071028
[epoch10, step392]: loss 1.825859
[epoch10, step393]: loss 1.174717
[epoch10, step394]: loss 1.463679
[epoch10, step395]: loss 1.234233
[epoch10, step396]: loss 9.654820
[epoch10, step397]: loss 3.577224
[epoch10, step398]: loss 20.561049
[epoch10, step399]: loss 1.199279
[epoch10, step400]: loss 9.933954
[epoch10, step401]: loss 15.321768
[epoch10, step402]: loss 3.269506
[epoch10, step403]: loss 5.227825
[epoch10, step404]: loss 3.121238
[epoch10, step405]: loss 10.478888
[epoch10, step406]: loss 1.427967
[epoch10, step407]: loss 8.542974
[epoch10, step408]: loss 2.401345
[epoch10, step409]: loss 4.393775
[epoch10, step410]: loss 1.464727
[epoch10, step411]: loss 0.861560
[epoch10, step412]: loss 21.304583
[epoch10, step413]: loss 2.016680
[epoch10, step414]: loss 8.484716
[epoch10, step415]: loss 35.597054
[epoch10, step416]: loss 0.944070
[epoch10, step417]: loss 16.012335
[epoch10, step418]: loss 10.337570
[epoch10, step419]: loss 4.033159
[epoch10, step420]: loss 1.391263
[epoch10, step421]: loss 8.862677
[epoch10, step422]: loss 1.335410
[epoch10, step423]: loss 12.030649
[epoch10, step424]: loss 1.485815
[epoch10, step425]: loss 4.029766
[epoch10, step426]: loss 1.226850
[epoch10, step427]: loss 1.566654
[epoch10, step428]: loss 3.725737
[epoch10, step429]: loss 4.105847
[epoch10, step430]: loss 1.735495
[epoch10, step431]: loss 1.475819
[epoch10, step432]: loss 1.790117
[epoch10, step433]: loss 11.096230
[epoch10, step434]: loss 5.071655
[epoch10, step435]: loss 5.520329
[epoch10, step436]: loss 2.681158
[epoch10, step437]: loss 2.049880
[epoch10, step438]: loss 1.096432
[epoch10, step439]: loss 1.437675
[epoch10, step440]: loss 8.615008
[epoch10, step441]: loss 1.233131
[epoch10, step442]: loss 4.939937
[epoch10, step443]: loss 2.345697
[epoch10, step444]: loss 19.539032
[epoch10, step445]: loss 1.310459
[epoch10, step446]: loss 1.604677
[epoch10, step447]: loss 12.223021
[epoch10, step448]: loss 12.162563
[epoch10, step449]: loss 1.739406
[epoch10, step450]: loss 1.497267
[epoch10, step451]: loss 1.867855
[epoch10, step452]: loss 2.198655
[epoch10, step453]: loss 12.887450
[epoch10, step454]: loss 3.053287
[epoch10, step455]: loss 7.736296
[epoch10, step456]: loss 1.501077
[epoch10, step457]: loss 1.584209
[epoch10, step458]: loss 8.772716
[epoch10, step459]: loss 6.140845
[epoch10, step460]: loss 4.706440
[epoch10, step461]: loss 9.943027
[epoch10, step462]: loss 9.527051
[epoch10, step463]: loss 7.292799
[epoch10, step464]: loss 3.982861
[epoch10, step465]: loss 3.197762
[epoch10, step466]: loss 1.189492
[epoch10, step467]: loss 1.812730
[epoch10, step468]: loss 1.568547
[epoch10, step469]: loss 0.845445
[epoch10, step470]: loss 1.272891
[epoch10, step471]: loss 5.247084
[epoch10, step472]: loss 7.434732
[epoch10, step473]: loss 10.961941
[epoch10, step474]: loss 1.443226
[epoch10, step475]: loss 3.401441
[epoch10, step476]: loss 9.321142
[epoch10, step477]: loss 20.813171
[epoch10, step478]: loss 6.677958
[epoch10, step479]: loss 1.945966
[epoch10, step480]: loss 1.048968
[epoch10, step481]: loss 13.301174
[epoch10, step482]: loss 12.229136
[epoch10, step483]: loss 3.132960
[epoch10, step484]: loss 1.560241
[epoch10, step485]: loss 5.250840
[epoch10, step486]: loss 5.975964
[epoch10, step487]: loss 6.586711
[epoch10, step488]: loss 10.881582
[epoch10, step489]: loss 1.499892
[epoch10, step490]: loss 1.189241
[epoch10, step491]: loss 4.367118
[epoch10, step492]: loss 9.215547
[epoch10, step493]: loss 8.263154
[epoch10, step494]: loss 1.298618
[epoch10, step495]: loss 1.355569
[epoch10, step496]: loss 2.732087
[epoch10, step497]: loss 0.972360
[epoch10, step498]: loss 1.083095
[epoch10, step499]: loss 2.432191
[epoch10, step500]: loss 2.602119
[epoch10, step501]: loss 18.028389
[epoch10, step502]: loss 1.247235
[epoch10, step503]: loss 9.605064
[epoch10, step504]: loss 16.058483
[epoch10, step505]: loss 1.636897
[epoch10, step506]: loss 10.600262
[epoch10, step507]: loss 3.632941
[epoch10, step508]: loss 1.721384
[epoch10, step509]: loss 1.049949
[epoch10, step510]: loss 9.612501
[epoch10, step511]: loss 5.032397
[epoch10, step512]: loss 1.816350
[epoch10, step513]: loss 19.296360
[epoch10, step514]: loss 2.513075
[epoch10, step515]: loss 7.944171
[epoch10, step516]: loss 2.157843
[epoch10, step517]: loss 7.584019
[epoch10, step518]: loss 8.861345
[epoch10, step519]: loss 1.947848
[epoch10, step520]: loss 2.456313
[epoch10, step521]: loss 22.056316
[epoch10, step522]: loss 1.590754
[epoch10, step523]: loss 3.001001
[epoch10, step524]: loss 22.942030
[epoch10, step525]: loss 2.101154
[epoch10, step526]: loss 1.342812
[epoch10, step527]: loss 10.828100
[epoch10, step528]: loss 12.471853
[epoch10, step529]: loss 9.868853
[epoch10, step530]: loss 3.170966
[epoch10, step531]: loss 10.276816
[epoch10, step532]: loss 4.465385
[epoch10, step533]: loss 1.264121
[epoch10, step534]: loss 4.926109
[epoch10, step535]: loss 0.786845
[epoch10, step536]: loss 0.946933
[epoch10, step537]: loss 1.325712
[epoch10, step538]: loss 8.958992
[epoch10, step539]: loss 1.682551
[epoch10, step540]: loss 3.800645
[epoch10, step541]: loss 9.209562
[epoch10, step542]: loss 1.682122
[epoch10, step543]: loss 6.143925
[epoch10, step544]: loss 4.394063
[epoch10, step545]: loss 1.132649
[epoch10, step546]: loss 2.409270
[epoch10, step547]: loss 1.250059
[epoch10, step548]: loss 1.490725
[epoch10, step549]: loss 6.480054
[epoch10, step550]: loss 11.061224
[epoch10, step551]: loss 7.469459
[epoch10, step552]: loss 1.378669
[epoch10, step553]: loss 20.107632
[epoch10, step554]: loss 0.898243
[epoch10, step555]: loss 12.662503
[epoch10, step556]: loss 2.597807
[epoch10, step557]: loss 0.992070
[epoch10, step558]: loss 2.446785
[epoch10, step559]: loss 1.364499
[epoch10, step560]: loss 28.980652
[epoch10, step561]: loss 1.494722
[epoch10, step562]: loss 0.993248
[epoch10, step563]: loss 5.330004
[epoch10, step564]: loss 1.552941
[epoch10, step565]: loss 19.546801
[epoch10, step566]: loss 7.462791
[epoch10, step567]: loss 23.408024
[epoch10, step568]: loss 2.209054
[epoch10, step569]: loss 0.834551
[epoch10, step570]: loss 1.222047
[epoch10, step571]: loss 11.666217
[epoch10, step572]: loss 3.662246
[epoch10, step573]: loss 8.790824
[epoch10, step574]: loss 5.473608
[epoch10, step575]: loss 10.689801
[epoch10, step576]: loss 2.822675
[epoch10, step577]: loss 2.480571
[epoch10, step578]: loss 1.378564
[epoch10, step579]: loss 1.913816
[epoch10, step580]: loss 18.495865
[epoch10, step581]: loss 2.419681
[epoch10, step582]: loss 1.243068
[epoch10, step583]: loss 6.598595
[epoch10, step584]: loss 12.222768
[epoch10, step585]: loss 3.628976
[epoch10, step586]: loss 16.743593
[epoch10, step587]: loss 14.879181
[epoch10, step588]: loss 6.773442
[epoch10, step589]: loss 12.771432
[epoch10, step590]: loss 1.294108
[epoch10, step591]: loss 3.393911
[epoch10, step592]: loss 3.171439
[epoch10, step593]: loss 1.009538
[epoch10, step594]: loss 5.951572
[epoch10, step595]: loss 1.303603
[epoch10, step596]: loss 10.981091
[epoch10, step597]: loss 1.310985
[epoch10, step598]: loss 4.194031
[epoch10, step599]: loss 10.600336
[epoch10, step600]: loss 16.912106
[epoch10, step601]: loss 10.412237
[epoch10, step602]: loss 11.575748
[epoch10, step603]: loss 9.737794
[epoch10, step604]: loss 6.850674
[epoch10, step605]: loss 7.132461
[epoch10, step606]: loss 17.439428
[epoch10, step607]: loss 6.966919
[epoch10, step608]: loss 3.791657
[epoch10, step609]: loss 13.538141
[epoch10, step610]: loss 1.282134
[epoch10, step611]: loss 2.188406
[epoch10, step612]: loss 1.106158
[epoch10, step613]: loss 2.270027
[epoch10, step614]: loss 2.404547
[epoch10, step615]: loss 11.013767
[epoch10, step616]: loss 1.106441
[epoch10, step617]: loss 2.767121
[epoch10, step618]: loss 1.440623
[epoch10, step619]: loss 1.347945
[epoch10, step620]: loss 8.695412
[epoch10, step621]: loss 8.459722
[epoch10, step622]: loss 10.282775
[epoch10, step623]: loss 9.736361
[epoch10, step624]: loss 3.544785
[epoch10, step625]: loss 1.652683
[epoch10, step626]: loss 2.570661
[epoch10, step627]: loss 10.513744
[epoch10, step628]: loss 2.572213
[epoch10, step629]: loss 2.555777
[epoch10, step630]: loss 9.541592
[epoch10, step631]: loss 2.024296
[epoch10, step632]: loss 4.764513
[epoch10, step633]: loss 1.746089
[epoch10, step634]: loss 1.127999
[epoch10, step635]: loss 11.442619
[epoch10, step636]: loss 3.380866
[epoch10, step637]: loss 2.351656
[epoch10, step638]: loss 1.973503
[epoch10, step639]: loss 1.869798
[epoch10, step640]: loss 2.470403
[epoch10, step641]: loss 1.617842
[epoch10, step642]: loss 8.343399
[epoch10, step643]: loss 1.204269
[epoch10, step644]: loss 3.956227
[epoch10, step645]: loss 11.024958
[epoch10, step646]: loss 10.910057
[epoch10, step647]: loss 11.466236
[epoch10, step648]: loss 3.110199
[epoch10, step649]: loss 3.702961
[epoch10, step650]: loss 1.306435
[epoch10, step651]: loss 1.554247
[epoch10, step652]: loss 1.848682
[epoch10, step653]: loss 1.801427
[epoch10, step654]: loss 7.690116
[epoch10, step655]: loss 1.613400
[epoch10, step656]: loss 1.417358
[epoch10, step657]: loss 24.504128
[epoch10, step658]: loss 1.041492
[epoch10, step659]: loss 1.188137
[epoch10, step660]: loss 7.057351
[epoch10, step661]: loss 1.459294
[epoch10, step662]: loss 1.084857
[epoch10, step663]: loss 1.352196
[epoch10, step664]: loss 1.661212
[epoch10, step665]: loss 2.619808
[epoch10, step666]: loss 2.359469
[epoch10, step667]: loss 7.075854
[epoch10, step668]: loss 3.402335
[epoch10, step669]: loss 6.391920
[epoch10, step670]: loss 1.841195
[epoch10, step671]: loss 1.946259
[epoch10, step672]: loss 1.757187
[epoch10, step673]: loss 10.804053
[epoch10, step674]: loss 1.878730
[epoch10, step675]: loss 7.572959
[epoch10, step676]: loss 1.411408
[epoch10, step677]: loss 1.723694
[epoch10, step678]: loss 6.731834
[epoch10, step679]: loss 2.410479
[epoch10, step680]: loss 6.860766
[epoch10, step681]: loss 20.508085
[epoch10, step682]: loss 1.150678
[epoch10, step683]: loss 1.765757
[epoch10, step684]: loss 6.288017
[epoch10, step685]: loss 3.213033
[epoch10, step686]: loss 3.472473
[epoch10, step687]: loss 22.870758
[epoch10, step688]: loss 1.600178
[epoch10, step689]: loss 1.114044
[epoch10, step690]: loss 2.318391
[epoch10, step691]: loss 1.990635
[epoch10, step692]: loss 2.109357
[epoch10, step693]: loss 2.808042
[epoch10, step694]: loss 8.294433
[epoch10, step695]: loss 2.169141
[epoch10, step696]: loss 10.303790
[epoch10, step697]: loss 3.624106
[epoch10, step698]: loss 2.903077
[epoch10, step699]: loss 0.791622
[epoch10, step700]: loss 1.519710
[epoch10, step701]: loss 16.680740
[epoch10, step702]: loss 1.615954
[epoch10, step703]: loss 9.360641
[epoch10, step704]: loss 1.066473
[epoch10, step705]: loss 2.846571
[epoch10, step706]: loss 7.552772
[epoch10, step707]: loss 6.186130
[epoch10, step708]: loss 17.349936
[epoch10, step709]: loss 2.373514
[epoch10, step710]: loss 1.217314
[epoch10, step711]: loss 1.913506
[epoch10, step712]: loss 14.041696
[epoch10, step713]: loss 6.140224
[epoch10, step714]: loss 2.400308
[epoch10, step715]: loss 1.147851
[epoch10, step716]: loss 1.172912
[epoch10, step717]: loss 0.956003
[epoch10, step718]: loss 24.091000
[epoch10, step719]: loss 25.246078
[epoch10, step720]: loss 10.211870
[epoch10, step721]: loss 11.996839
[epoch10, step722]: loss 18.300680
[epoch10, step723]: loss 3.142169
[epoch10, step724]: loss 8.423161
[epoch10, step725]: loss 4.097298
[epoch10, step726]: loss 2.115586
[epoch10, step727]: loss 0.974803
[epoch10, step728]: loss 18.463385
[epoch10, step729]: loss 1.443062
[epoch10, step730]: loss 2.117526
[epoch10, step731]: loss 1.284534
[epoch10, step732]: loss 1.134884
[epoch10, step733]: loss 3.787434
[epoch10, step734]: loss 1.251471
[epoch10, step735]: loss 17.453001
[epoch10, step736]: loss 11.167624
[epoch10, step737]: loss 1.188097
[epoch10, step738]: loss 3.027876
[epoch10, step739]: loss 1.950387
[epoch10, step740]: loss 4.649360
[epoch10, step741]: loss 11.854112
[epoch10, step742]: loss 1.831695
[epoch10, step743]: loss 2.023875
[epoch10, step744]: loss 2.278450
[epoch10, step745]: loss 1.307158
[epoch10, step746]: loss 11.649287
[epoch10, step747]: loss 4.869835
[epoch10, step748]: loss 2.224382
[epoch10, step749]: loss 10.063042
[epoch10, step750]: loss 1.107608
[epoch10, step751]: loss 13.599830
[epoch10, step752]: loss 2.753557
[epoch10, step753]: loss 1.648572
[epoch10, step754]: loss 26.497372
[epoch10, step755]: loss 3.515005
[epoch10, step756]: loss 4.046833
[epoch10, step757]: loss 1.557043
[epoch10, step758]: loss 1.359823
[epoch10, step759]: loss 12.160553
[epoch10, step760]: loss 10.875148
[epoch10, step761]: loss 1.584795
[epoch10, step762]: loss 2.185238
[epoch10, step763]: loss 2.033159
[epoch10, step764]: loss 2.257946
[epoch10, step765]: loss 1.097932
[epoch10, step766]: loss 2.699790
[epoch10, step767]: loss 6.854162
[epoch10, step768]: loss 1.949031
[epoch10, step769]: loss 8.214819
[epoch10, step770]: loss 12.049614
[epoch10, step771]: loss 5.579123
[epoch10, step772]: loss 2.389145
[epoch10, step773]: loss 4.112440
[epoch10, step774]: loss 10.867662
[epoch10, step775]: loss 4.155672
[epoch10, step776]: loss 20.260818
[epoch10, step777]: loss 1.325381
[epoch10, step778]: loss 0.883868
[epoch10, step779]: loss 10.131636
[epoch10, step780]: loss 1.250184
[epoch10, step781]: loss 2.803614
[epoch10, step782]: loss 4.288902
[epoch10, step783]: loss 1.935541
[epoch10, step784]: loss 2.183275
[epoch10, step785]: loss 11.017416
[epoch10, step786]: loss 4.398017
[epoch10, step787]: loss 1.143439
[epoch10, step788]: loss 4.586476
[epoch10, step789]: loss 3.747703
[epoch10, step790]: loss 2.441618
[epoch10, step791]: loss 2.925209
[epoch10, step792]: loss 1.323712
[epoch10, step793]: loss 3.836031
[epoch10, step794]: loss 3.696835
[epoch10, step795]: loss 2.175922
[epoch10, step796]: loss 2.376682
[epoch10, step797]: loss 3.734863
[epoch10, step798]: loss 1.703413
[epoch10, step799]: loss 15.890533
[epoch10, step800]: loss 1.919573
[epoch10, step801]: loss 2.076654
[epoch10, step802]: loss 4.275068
[epoch10, step803]: loss 1.580713
[epoch10, step804]: loss 9.106138
[epoch10, step805]: loss 1.090796
[epoch10, step806]: loss 1.591608
[epoch10, step807]: loss 7.678020
[epoch10, step808]: loss 7.740811
[epoch10, step809]: loss 1.343719
[epoch10, step810]: loss 0.877980
[epoch10, step811]: loss 14.393624
[epoch10, step812]: loss 2.124041
[epoch10, step813]: loss 17.112398
[epoch10, step814]: loss 1.644052
[epoch10, step815]: loss 1.794252
[epoch10, step816]: loss 1.285281
[epoch10, step817]: loss 1.489830
[epoch10, step818]: loss 1.791732
[epoch10, step819]: loss 1.383090
[epoch10, step820]: loss 8.952616
[epoch10, step821]: loss 2.831880
[epoch10, step822]: loss 8.995246
[epoch10, step823]: loss 6.643640
[epoch10, step824]: loss 10.624335
[epoch10, step825]: loss 1.696732
[epoch10, step826]: loss 1.964537
[epoch10, step827]: loss 2.338655
[epoch10, step828]: loss 3.255776
[epoch10, step829]: loss 3.853288
[epoch10, step830]: loss 2.526898
[epoch10, step831]: loss 1.102241
[epoch10, step832]: loss 12.346626
[epoch10, step833]: loss 2.301541
[epoch10, step834]: loss 3.048595
[epoch10, step835]: loss 1.182320
[epoch10, step836]: loss 1.596380
[epoch10, step837]: loss 27.269806
[epoch10, step838]: loss 3.042831
[epoch10, step839]: loss 2.150405
[epoch10, step840]: loss 3.503213
[epoch10, step841]: loss 1.665970
[epoch10, step842]: loss 2.413256
[epoch10, step843]: loss 1.424559
[epoch10, step844]: loss 1.715561
[epoch10, step845]: loss 3.109436
[epoch10, step846]: loss 2.614489
[epoch10, step847]: loss 12.712677
[epoch10, step848]: loss 3.656604
[epoch10, step849]: loss 3.253205
[epoch10, step850]: loss 14.473831
[epoch10, step851]: loss 2.082925
[epoch10, step852]: loss 11.826190
[epoch10, step853]: loss 8.774363
[epoch10, step854]: loss 1.747668
[epoch10, step855]: loss 1.293105
[epoch10, step856]: loss 8.640859
[epoch10, step857]: loss 13.573176
[epoch10, step858]: loss 1.216696
[epoch10, step859]: loss 1.768142
[epoch10, step860]: loss 1.835322
[epoch10, step861]: loss 1.465479
[epoch10, step862]: loss 11.889933
[epoch10, step863]: loss 9.472972
[epoch10, step864]: loss 8.745728
[epoch10, step865]: loss 26.504707
[epoch10, step866]: loss 1.801479
[epoch10, step867]: loss 7.425496
[epoch10, step868]: loss 3.576176
[epoch10, step869]: loss 8.873688
[epoch10, step870]: loss 0.757238
[epoch10, step871]: loss 10.863280
[epoch10, step872]: loss 3.894984
[epoch10, step873]: loss 14.137032
[epoch10, step874]: loss 1.197289
[epoch10, step875]: loss 26.952518
[epoch10, step876]: loss 20.279308
[epoch10, step877]: loss 6.550654
[epoch10, step878]: loss 8.399750
[epoch10, step879]: loss 24.469852
[epoch10, step880]: loss 5.907469
[epoch10, step881]: loss 14.200091
[epoch10, step882]: loss 2.896348
[epoch10, step883]: loss 0.954729
[epoch10, step884]: loss 1.269611
[epoch10, step885]: loss 1.573910
[epoch10, step886]: loss 2.752020
[epoch10, step887]: loss 1.243021
[epoch10, step888]: loss 2.437134
[epoch10, step889]: loss 1.429761
[epoch10, step890]: loss 12.237975
[epoch10, step891]: loss 1.172466
[epoch10, step892]: loss 2.305452
[epoch10, step893]: loss 6.560169
[epoch10, step894]: loss 1.381623
[epoch10, step895]: loss 1.042481
[epoch10, step896]: loss 1.532993
[epoch10, step897]: loss 1.114861
[epoch10, step898]: loss 1.889627
[epoch10, step899]: loss 17.517092
[epoch10, step900]: loss 1.499388
[epoch10, step901]: loss 9.814662
[epoch10, step902]: loss 8.596243
[epoch10, step903]: loss 1.335783
[epoch10, step904]: loss 13.787352
[epoch10, step905]: loss 1.643962
[epoch10, step906]: loss 7.795197
[epoch10, step907]: loss 21.148884
[epoch10, step908]: loss 1.344196
[epoch10, step909]: loss 3.813153
[epoch10, step910]: loss 1.256858
[epoch10, step911]: loss 1.914477
[epoch10, step912]: loss 0.811316
[epoch10, step913]: loss 18.140139
[epoch10, step914]: loss 5.834719
[epoch10, step915]: loss 1.503742
[epoch10, step916]: loss 3.105403
[epoch10, step917]: loss 1.969078
[epoch10, step918]: loss 1.436161
[epoch10, step919]: loss 24.341093
[epoch10, step920]: loss 1.599745
[epoch10, step921]: loss 1.993241
[epoch10, step922]: loss 4.332101
[epoch10, step923]: loss 2.911335
[epoch10, step924]: loss 8.744550
[epoch10, step925]: loss 9.078651
[epoch10, step926]: loss 0.967100
[epoch10, step927]: loss 1.616887
[epoch10, step928]: loss 15.148605
[epoch10, step929]: loss 1.154893
[epoch10, step930]: loss 1.713170
[epoch10, step931]: loss 1.204152
[epoch10, step932]: loss 1.604972
[epoch10, step933]: loss 9.887202
[epoch10, step934]: loss 1.864642
[epoch10, step935]: loss 1.341509
[epoch10, step936]: loss 3.291603
[epoch10, step937]: loss 1.632727
[epoch10, step938]: loss 3.271912
[epoch10, step939]: loss 1.474553
[epoch10, step940]: loss 1.676616
[epoch10, step941]: loss 1.581654
[epoch10, step942]: loss 1.183597
[epoch10, step943]: loss 0.970376
[epoch10, step944]: loss 2.950730
[epoch10, step945]: loss 6.097015
[epoch10, step946]: loss 2.664345
[epoch10, step947]: loss 1.960448
[epoch10, step948]: loss 10.655561
[epoch10, step949]: loss 0.892435
[epoch10, step950]: loss 3.029635
[epoch10, step951]: loss 1.649131
[epoch10, step952]: loss 1.867472
[epoch10, step953]: loss 13.092978
[epoch10, step954]: loss 2.173364
[epoch10, step955]: loss 6.333018
[epoch10, step956]: loss 3.556098
[epoch10, step957]: loss 1.678129
[epoch10, step958]: loss 1.145391
[epoch10, step959]: loss 1.555246
[epoch10, step960]: loss 2.188907
[epoch10, step961]: loss 1.016129
[epoch10, step962]: loss 1.153636
[epoch10, step963]: loss 1.035045
[epoch10, step964]: loss 3.486469
[epoch10, step965]: loss 1.484045
[epoch10, step966]: loss 1.335432
[epoch10, step967]: loss 1.852339
[epoch10, step968]: loss 5.500023
[epoch10, step969]: loss 1.423759
[epoch10, step970]: loss 3.538027
[epoch10, step971]: loss 1.204051
[epoch10, step972]: loss 6.561322
[epoch10, step973]: loss 1.309754
[epoch10, step974]: loss 0.959359
[epoch10, step975]: loss 1.332837
[epoch10, step976]: loss 11.220172
[epoch10, step977]: loss 11.958317
[epoch10, step978]: loss 8.423851
[epoch10, step979]: loss 3.463681
[epoch10, step980]: loss 4.765862
[epoch10, step981]: loss 2.872437
[epoch10, step982]: loss 10.874892
[epoch10, step983]: loss 1.490579
[epoch10, step984]: loss 1.737099
[epoch10, step985]: loss 5.077578
[epoch10, step986]: loss 19.318195
[epoch10, step987]: loss 1.109153
[epoch10, step988]: loss 9.680700
[epoch10, step989]: loss 4.879604
[epoch10, step990]: loss 7.733886
[epoch10, step991]: loss 2.401095
[epoch10, step992]: loss 0.969253
[epoch10, step993]: loss 1.993771
[epoch10, step994]: loss 10.911494
[epoch10, step995]: loss 8.592518
[epoch10, step996]: loss 10.727430
[epoch10, step997]: loss 7.270883
[epoch10, step998]: loss 4.746145
[epoch10, step999]: loss 10.587625
[epoch10, step1000]: loss 1.043052
[epoch10, step1001]: loss 12.487322
[epoch10, step1002]: loss 1.316041
[epoch10, step1003]: loss 10.561152
[epoch10, step1004]: loss 1.220649
[epoch10, step1005]: loss 5.118182
[epoch10, step1006]: loss 3.323510
[epoch10, step1007]: loss 8.083368
[epoch10, step1008]: loss 1.798923
[epoch10, step1009]: loss 1.959607
[epoch10, step1010]: loss 2.486409
[epoch10, step1011]: loss 5.237809
[epoch10, step1012]: loss 1.781057
[epoch10, step1013]: loss 26.825098
[epoch10, step1014]: loss 6.873696
[epoch10, step1015]: loss 19.316088
[epoch10, step1016]: loss 1.268371
[epoch10, step1017]: loss 3.048845
[epoch10, step1018]: loss 2.334265
[epoch10, step1019]: loss 1.763642
[epoch10, step1020]: loss 5.563232
[epoch10, step1021]: loss 1.325313
[epoch10, step1022]: loss 15.818040
[epoch10, step1023]: loss 5.154664
[epoch10, step1024]: loss 1.927107
[epoch10, step1025]: loss 10.983197
[epoch10, step1026]: loss 2.215179
[epoch10, step1027]: loss 6.249798
[epoch10, step1028]: loss 2.259555
[epoch10, step1029]: loss 7.132053
[epoch10, step1030]: loss 2.810255
[epoch10, step1031]: loss 2.747328
[epoch10, step1032]: loss 6.384357
[epoch10, step1033]: loss 1.239989
[epoch10, step1034]: loss 1.576956
[epoch10, step1035]: loss 2.588124
[epoch10, step1036]: loss 5.114474
[epoch10, step1037]: loss 12.761497
[epoch10, step1038]: loss 1.374889
[epoch10, step1039]: loss 2.451129
[epoch10, step1040]: loss 1.681208
[epoch10, step1041]: loss 2.432450
[epoch10, step1042]: loss 6.113026
[epoch10, step1043]: loss 10.334949
[epoch10, step1044]: loss 1.974146
[epoch10, step1045]: loss 12.791981
[epoch10, step1046]: loss 2.614849
[epoch10, step1047]: loss 5.468235
[epoch10, step1048]: loss 8.635799
[epoch10, step1049]: loss 6.005906
[epoch10, step1050]: loss 2.732291
[epoch10, step1051]: loss 1.650254
[epoch10, step1052]: loss 1.045206
[epoch10, step1053]: loss 1.725187
[epoch10, step1054]: loss 0.707629
[epoch10, step1055]: loss 2.772660
[epoch10, step1056]: loss 1.559729
[epoch10, step1057]: loss 9.480235
[epoch10, step1058]: loss 19.936916
[epoch10, step1059]: loss 1.481620
[epoch10, step1060]: loss 0.713148
[epoch10, step1061]: loss 2.171004
[epoch10, step1062]: loss 1.292423
[epoch10, step1063]: loss 1.192794
[epoch10, step1064]: loss 2.540235
[epoch10, step1065]: loss 2.163047
[epoch10, step1066]: loss 1.746388
[epoch10, step1067]: loss 4.390018
[epoch10, step1068]: loss 1.460604
[epoch10, step1069]: loss 3.731407
[epoch10, step1070]: loss 2.383334
[epoch10, step1071]: loss 1.618962
[epoch10, step1072]: loss 1.775309
[epoch10, step1073]: loss 1.284510
[epoch10, step1074]: loss 8.000546
[epoch10, step1075]: loss 1.626600
[epoch10, step1076]: loss 1.451705
[epoch10, step1077]: loss 0.976995
[epoch10, step1078]: loss 1.632484
[epoch10, step1079]: loss 0.957485
[epoch10, step1080]: loss 1.012505
[epoch10, step1081]: loss 14.863726
[epoch10, step1082]: loss 1.835694
[epoch10, step1083]: loss 1.343891
[epoch10, step1084]: loss 6.083014
[epoch10, step1085]: loss 13.046121
[epoch10, step1086]: loss 9.825283
[epoch10, step1087]: loss 1.330710
[epoch10, step1088]: loss 14.478421
[epoch10, step1089]: loss 7.378668
[epoch10, step1090]: loss 1.471442
[epoch10, step1091]: loss 0.921654
[epoch10, step1092]: loss 2.404308
[epoch10, step1093]: loss 1.337292
[epoch10, step1094]: loss 16.207392
[epoch10, step1095]: loss 11.746696
[epoch10, step1096]: loss 3.589487
[epoch10, step1097]: loss 15.177000
[epoch10, step1098]: loss 3.207340
[epoch10, step1099]: loss 1.408225
[epoch10, step1100]: loss 1.495172
[epoch10, step1101]: loss 8.386839
[epoch10, step1102]: loss 11.680271
[epoch10, step1103]: loss 5.778309
[epoch10, step1104]: loss 1.376302
[epoch10, step1105]: loss 8.323477
[epoch10, step1106]: loss 11.317852
[epoch10, step1107]: loss 1.240369
[epoch10, step1108]: loss 1.237541
[epoch10, step1109]: loss 1.344388
[epoch10, step1110]: loss 1.328031
[epoch10, step1111]: loss 1.839002
[epoch10, step1112]: loss 1.010065
[epoch10, step1113]: loss 1.017177
[epoch10, step1114]: loss 6.301575
[epoch10, step1115]: loss 2.186691
[epoch10, step1116]: loss 10.693586
[epoch10, step1117]: loss 1.164535
[epoch10, step1118]: loss 1.898694
[epoch10, step1119]: loss 4.498699
[epoch10, step1120]: loss 0.986760
[epoch10, step1121]: loss 1.216799
[epoch10, step1122]: loss 1.155957
[epoch10, step1123]: loss 6.183154
[epoch10, step1124]: loss 2.700518
[epoch10, step1125]: loss 7.040726
[epoch10, step1126]: loss 2.093631
[epoch10, step1127]: loss 7.554215
[epoch10, step1128]: loss 10.927258
[epoch10, step1129]: loss 12.446856
[epoch10, step1130]: loss 5.199018
[epoch10, step1131]: loss 2.168712
[epoch10, step1132]: loss 1.772077
[epoch10, step1133]: loss 18.978069
[epoch10, step1134]: loss 2.057509
[epoch10, step1135]: loss 5.559174
[epoch10, step1136]: loss 6.143799
[epoch10, step1137]: loss 1.778082
[epoch10, step1138]: loss 1.861060
[epoch10, step1139]: loss 2.850692
[epoch10, step1140]: loss 2.465544
[epoch10, step1141]: loss 10.615965
[epoch10, step1142]: loss 4.404906
[epoch10, step1143]: loss 1.639132
[epoch10, step1144]: loss 7.438440
[epoch10, step1145]: loss 22.187077
[epoch10, step1146]: loss 3.138609
[epoch10, step1147]: loss 1.221628
[epoch10, step1148]: loss 6.064834
[epoch10, step1149]: loss 1.605222
[epoch10, step1150]: loss 1.078089
[epoch10, step1151]: loss 1.041320
[epoch10, step1152]: loss 0.700242
[epoch10, step1153]: loss 4.663625
[epoch10, step1154]: loss 3.196442
[epoch10, step1155]: loss 5.317731
[epoch10, step1156]: loss 13.868356
[epoch10, step1157]: loss 4.531881
[epoch10, step1158]: loss 10.525230
[epoch10, step1159]: loss 11.765937
[epoch10, step1160]: loss 2.900273
[epoch10, step1161]: loss 4.055065
[epoch10, step1162]: loss 11.919492
[epoch10, step1163]: loss 2.689551
[epoch10, step1164]: loss 0.986576
[epoch10, step1165]: loss 8.594065
[epoch10, step1166]: loss 8.219945
[epoch10, step1167]: loss 11.058352
[epoch10, step1168]: loss 5.347987
[epoch10, step1169]: loss 10.407598
[epoch10, step1170]: loss 5.504651
[epoch10, step1171]: loss 4.285657
[epoch10, step1172]: loss 1.759005
[epoch10, step1173]: loss 1.355964
[epoch10, step1174]: loss 1.811457
[epoch10, step1175]: loss 1.926443
[epoch10, step1176]: loss 14.675867
[epoch10, step1177]: loss 1.861346
[epoch10, step1178]: loss 3.138632
[epoch10, step1179]: loss 18.868567
[epoch10, step1180]: loss 3.917297
[epoch10, step1181]: loss 1.683627
[epoch10, step1182]: loss 0.835224
[epoch10, step1183]: loss 0.977478
[epoch10, step1184]: loss 0.996135
[epoch10, step1185]: loss 1.462584
[epoch10, step1186]: loss 2.445819
[epoch10, step1187]: loss 1.897006
[epoch10, step1188]: loss 2.262020
[epoch10, step1189]: loss 6.133352
[epoch10, step1190]: loss 11.159904
[epoch10, step1191]: loss 8.891582
[epoch10, step1192]: loss 1.729661
[epoch10, step1193]: loss 2.418302
[epoch10, step1194]: loss 1.444137
[epoch10, step1195]: loss 4.222058
[epoch10, step1196]: loss 17.543440
[epoch10, step1197]: loss 13.698437
[epoch10, step1198]: loss 3.756319
[epoch10, step1199]: loss 4.838830
[epoch10, step1200]: loss 1.629117
[epoch10, step1201]: loss 9.408661
[epoch10, step1202]: loss 2.301205
[epoch10, step1203]: loss 1.147516
[epoch10, step1204]: loss 12.217774
[epoch10, step1205]: loss 11.772807
[epoch10, step1206]: loss 3.057709
[epoch10, step1207]: loss 1.088313
[epoch10, step1208]: loss 10.442687
[epoch10, step1209]: loss 2.867000
[epoch10, step1210]: loss 2.457774
[epoch10, step1211]: loss 11.426778
[epoch10, step1212]: loss 1.228902
[epoch10, step1213]: loss 1.346002
[epoch10, step1214]: loss 2.011312
[epoch10, step1215]: loss 11.943519
[epoch10, step1216]: loss 14.028791
[epoch10, step1217]: loss 1.713233
[epoch10, step1218]: loss 4.074413
[epoch10, step1219]: loss 2.250460
[epoch10, step1220]: loss 8.130299
[epoch10, step1221]: loss 0.894496
[epoch10, step1222]: loss 11.071102
[epoch10, step1223]: loss 8.202783
[epoch10, step1224]: loss 1.272160
[epoch10, step1225]: loss 1.357814
[epoch10, step1226]: loss 12.848812
[epoch10, step1227]: loss 1.524199
[epoch10, step1228]: loss 1.555971
[epoch10, step1229]: loss 9.675481
[epoch10, step1230]: loss 0.768272
[epoch10, step1231]: loss 5.806012
[epoch10, step1232]: loss 13.017623
[epoch10, step1233]: loss 21.555826
[epoch10, step1234]: loss 2.208331
[epoch10, step1235]: loss 1.376842
[epoch10, step1236]: loss 2.473289
[epoch10, step1237]: loss 8.375019
[epoch10, step1238]: loss 10.223741
[epoch10, step1239]: loss 11.771042
[epoch10, step1240]: loss 1.345185
[epoch10, step1241]: loss 12.073902
[epoch10, step1242]: loss 8.633449
[epoch10, step1243]: loss 1.128152
[epoch10, step1244]: loss 0.926072
[epoch10, step1245]: loss 1.061033
[epoch10, step1246]: loss 9.299015
[epoch10, step1247]: loss 4.606561
[epoch10, step1248]: loss 11.142423
[epoch10, step1249]: loss 2.536435
[epoch10, step1250]: loss 10.009254
[epoch10, step1251]: loss 5.977469
[epoch10, step1252]: loss 2.947325
[epoch10, step1253]: loss 26.101797
[epoch10, step1254]: loss 3.678019
[epoch10, step1255]: loss 5.387823
[epoch10, step1256]: loss 1.896067
[epoch10, step1257]: loss 1.288349
[epoch10, step1258]: loss 1.062103
[epoch10, step1259]: loss 2.516287
[epoch10, step1260]: loss 2.185542
[epoch10, step1261]: loss 2.399088
[epoch10, step1262]: loss 9.520883
[epoch10, step1263]: loss 3.538091
[epoch10, step1264]: loss 1.673325
[epoch10, step1265]: loss 1.630541
[epoch10, step1266]: loss 1.932692
[epoch10, step1267]: loss 6.825952
[epoch10, step1268]: loss 1.318349
[epoch10, step1269]: loss 1.596906
[epoch10, step1270]: loss 1.392936
[epoch10, step1271]: loss 0.900636
[epoch10, step1272]: loss 1.353049
[epoch10, step1273]: loss 1.100689
[epoch10, step1274]: loss 7.824586
[epoch10, step1275]: loss 12.848651
[epoch10, step1276]: loss 0.900239
[epoch10, step1277]: loss 2.531950
[epoch10, step1278]: loss 4.829866
[epoch10, step1279]: loss 7.129884
[epoch10, step1280]: loss 10.346419
[epoch10, step1281]: loss 2.895431
[epoch10, step1282]: loss 1.066340
[epoch10, step1283]: loss 2.846605
[epoch10, step1284]: loss 2.367344
[epoch10, step1285]: loss 1.118815
[epoch10, step1286]: loss 15.966778
[epoch10, step1287]: loss 3.573582
[epoch10, step1288]: loss 12.237581
[epoch10, step1289]: loss 10.059264
[epoch10, step1290]: loss 12.382599
[epoch10, step1291]: loss 1.210946
[epoch10, step1292]: loss 1.188657
[epoch10, step1293]: loss 1.605530
[epoch10, step1294]: loss 9.878400
[epoch10, step1295]: loss 2.210270
[epoch10, step1296]: loss 2.610399
[epoch10, step1297]: loss 6.383151
[epoch10, step1298]: loss 2.240421
[epoch10, step1299]: loss 2.909116
[epoch10, step1300]: loss 0.943677
[epoch10, step1301]: loss 1.478289
[epoch10, step1302]: loss 16.634657
[epoch10, step1303]: loss 10.853565
[epoch10, step1304]: loss 3.319983
[epoch10, step1305]: loss 2.196418
[epoch10, step1306]: loss 7.363463
[epoch10, step1307]: loss 1.519991
[epoch10, step1308]: loss 0.981153
[epoch10, step1309]: loss 13.389441
[epoch10, step1310]: loss 13.793174
[epoch10, step1311]: loss 3.686961
[epoch10, step1312]: loss 1.267941
[epoch10, step1313]: loss 1.573908
[epoch10, step1314]: loss 1.981408
[epoch10, step1315]: loss 1.268976
[epoch10, step1316]: loss 0.994509
[epoch10, step1317]: loss 7.055679
[epoch10, step1318]: loss 9.222321
[epoch10, step1319]: loss 1.664558
[epoch10, step1320]: loss 2.785446
[epoch10, step1321]: loss 2.515638
[epoch10, step1322]: loss 1.924802
[epoch10, step1323]: loss 1.687197
[epoch10, step1324]: loss 1.470914
[epoch10, step1325]: loss 6.779060
[epoch10, step1326]: loss 3.626663
[epoch10, step1327]: loss 1.303750
[epoch10, step1328]: loss 10.215105
[epoch10, step1329]: loss 4.204969
[epoch10, step1330]: loss 1.637002
[epoch10, step1331]: loss 7.499684
[epoch10, step1332]: loss 5.607203
[epoch10, step1333]: loss 10.072633
[epoch10, step1334]: loss 1.161109
[epoch10, step1335]: loss 2.904049
[epoch10, step1336]: loss 10.833136
[epoch10, step1337]: loss 4.773499
[epoch10, step1338]: loss 6.246245
[epoch10, step1339]: loss 1.826999
[epoch10, step1340]: loss 10.298139
[epoch10, step1341]: loss 8.303597
[epoch10, step1342]: loss 4.724495
[epoch10, step1343]: loss 4.581338
[epoch10, step1344]: loss 3.446679
[epoch10, step1345]: loss 0.985041
[epoch10, step1346]: loss 1.312374
[epoch10, step1347]: loss 2.434077
[epoch10, step1348]: loss 3.011299
[epoch10, step1349]: loss 1.494021
[epoch10, step1350]: loss 7.073327
[epoch10, step1351]: loss 9.023303
[epoch10, step1352]: loss 2.431756
[epoch10, step1353]: loss 1.703699
[epoch10, step1354]: loss 1.336634
[epoch10, step1355]: loss 4.050276
[epoch10, step1356]: loss 16.330095
[epoch10, step1357]: loss 1.800217
[epoch10, step1358]: loss 2.258338
[epoch10, step1359]: loss 1.503347
[epoch10, step1360]: loss 2.651238
[epoch10, step1361]: loss 1.837807
[epoch10, step1362]: loss 4.359373
[epoch10, step1363]: loss 1.996216
[epoch10, step1364]: loss 8.573975
[epoch10, step1365]: loss 5.764882
[epoch10, step1366]: loss 1.223845
[epoch10, step1367]: loss 8.074026
[epoch10, step1368]: loss 0.994623
[epoch10, step1369]: loss 0.837478
[epoch10, step1370]: loss 1.387251
[epoch10, step1371]: loss 2.445574
[epoch10, step1372]: loss 2.768009
[epoch10, step1373]: loss 1.539161
[epoch10, step1374]: loss 4.974286
[epoch10, step1375]: loss 1.359827
[epoch10, step1376]: loss 22.186066
[epoch10, step1377]: loss 6.728812
[epoch10, step1378]: loss 2.960302
[epoch10, step1379]: loss 6.580518
[epoch10, step1380]: loss 7.101589
[epoch10, step1381]: loss 0.893130
[epoch10, step1382]: loss 1.336064
[epoch10, step1383]: loss 3.318333
[epoch10, step1384]: loss 1.715969
[epoch10, step1385]: loss 7.458515
[epoch10, step1386]: loss 3.296580
[epoch10, step1387]: loss 1.166647
[epoch10, step1388]: loss 1.237769
[epoch10, step1389]: loss 2.195397
[epoch10, step1390]: loss 6.486574
[epoch10, step1391]: loss 1.537429
[epoch10, step1392]: loss 2.611815
[epoch10, step1393]: loss 1.886404
[epoch10, step1394]: loss 1.535056
[epoch10, step1395]: loss 2.854780
[epoch10, step1396]: loss 1.756705
[epoch10, step1397]: loss 13.754207
[epoch10, step1398]: loss 1.405909
[epoch10, step1399]: loss 1.399660
[epoch10, step1400]: loss 13.049961
[epoch10, step1401]: loss 1.230115
[epoch10, step1402]: loss 1.051747
[epoch10, step1403]: loss 1.169830
[epoch10, step1404]: loss 13.336082
[epoch10, step1405]: loss 1.536543
[epoch10, step1406]: loss 1.440660
[epoch10, step1407]: loss 22.256889
[epoch10, step1408]: loss 3.551039
[epoch10, step1409]: loss 14.623109
[epoch10, step1410]: loss 2.160537
[epoch10, step1411]: loss 8.374941
[epoch10, step1412]: loss 4.783543
[epoch10, step1413]: loss 1.347386
[epoch10, step1414]: loss 1.595483
[epoch10, step1415]: loss 5.030314
[epoch10, step1416]: loss 5.878633
[epoch10, step1417]: loss 9.809578
[epoch10, step1418]: loss 8.833933
[epoch10, step1419]: loss 3.705172
[epoch10, step1420]: loss 3.254455
[epoch10, step1421]: loss 1.793743
[epoch10, step1422]: loss 10.107803
[epoch10, step1423]: loss 14.223888
[epoch10, step1424]: loss 1.445896
[epoch10, step1425]: loss 1.093447
[epoch10, step1426]: loss 3.418106
[epoch10, step1427]: loss 2.462836
[epoch10, step1428]: loss 4.670788
[epoch10, step1429]: loss 4.378346
[epoch10, step1430]: loss 10.597179
[epoch10, step1431]: loss 2.633469
[epoch10, step1432]: loss 1.756031
[epoch10, step1433]: loss 11.854424
[epoch10, step1434]: loss 3.545039
[epoch10, step1435]: loss 1.379102
[epoch10, step1436]: loss 3.595420
[epoch10, step1437]: loss 8.470245
[epoch10, step1438]: loss 1.506986
[epoch10, step1439]: loss 0.865035
[epoch10, step1440]: loss 0.962166
[epoch10, step1441]: loss 1.128913
[epoch10, step1442]: loss 5.993943
[epoch10, step1443]: loss 1.389290
[epoch10, step1444]: loss 0.977482
[epoch10, step1445]: loss 6.184309
[epoch10, step1446]: loss 4.332171
[epoch10, step1447]: loss 4.108366
[epoch10, step1448]: loss 1.437598
[epoch10, step1449]: loss 2.437991
[epoch10, step1450]: loss 19.751410
[epoch10, step1451]: loss 2.795150
[epoch10, step1452]: loss 0.995057
[epoch10, step1453]: loss 3.104304
[epoch10, step1454]: loss 2.567438
[epoch10, step1455]: loss 1.078991
[epoch10, step1456]: loss 2.533812
[epoch10, step1457]: loss 2.589667
[epoch10, step1458]: loss 11.168379
[epoch10, step1459]: loss 9.740875
[epoch10, step1460]: loss 1.345043
[epoch10, step1461]: loss 1.747222
[epoch10, step1462]: loss 1.537632
[epoch10, step1463]: loss 1.584439
[epoch10, step1464]: loss 1.465301
[epoch10, step1465]: loss 1.493930
[epoch10, step1466]: loss 5.135901
[epoch10, step1467]: loss 1.004354
[epoch10, step1468]: loss 1.098940
[epoch10, step1469]: loss 1.157520
[epoch10, step1470]: loss 0.804647
[epoch10, step1471]: loss 7.170978
[epoch10, step1472]: loss 0.939180
[epoch10, step1473]: loss 2.094539
[epoch10, step1474]: loss 10.583883
[epoch10, step1475]: loss 2.570637
[epoch10, step1476]: loss 1.630698
[epoch10, step1477]: loss 4.425941
[epoch10, step1478]: loss 0.805856
[epoch10, step1479]: loss 26.471815
[epoch10, step1480]: loss 1.299326
[epoch10, step1481]: loss 22.665573
[epoch10, step1482]: loss 5.988483
[epoch10, step1483]: loss 1.335558
[epoch10, step1484]: loss 1.280041
[epoch10, step1485]: loss 1.509351
[epoch10, step1486]: loss 1.451052
[epoch10, step1487]: loss 12.229892
[epoch10, step1488]: loss 1.887212
[epoch10, step1489]: loss 2.144258
[epoch10, step1490]: loss 1.111478
[epoch10, step1491]: loss 1.381837
[epoch10, step1492]: loss 3.338703
[epoch10, step1493]: loss 1.882652
[epoch10, step1494]: loss 2.604634
[epoch10, step1495]: loss 2.230996
[epoch10, step1496]: loss 1.558128
[epoch10, step1497]: loss 13.940708
[epoch10, step1498]: loss 1.672633
[epoch10, step1499]: loss 1.875419
[epoch10, step1500]: loss 11.462106
[epoch10, step1501]: loss 1.054853
[epoch10, step1502]: loss 1.934731
[epoch10, step1503]: loss 0.872341
[epoch10, step1504]: loss 1.464174
[epoch10, step1505]: loss 8.544711
[epoch10, step1506]: loss 20.229076
[epoch10, step1507]: loss 1.920954
[epoch10, step1508]: loss 21.930037
[epoch10, step1509]: loss 1.020950
[epoch10, step1510]: loss 2.734441
[epoch10, step1511]: loss 10.054809
[epoch10, step1512]: loss 1.973892
[epoch10, step1513]: loss 1.704195
[epoch10, step1514]: loss 4.769018
[epoch10, step1515]: loss 1.337135
[epoch10, step1516]: loss 3.040450
[epoch10, step1517]: loss 10.359764
[epoch10, step1518]: loss 1.671368
[epoch10, step1519]: loss 5.056295
[epoch10, step1520]: loss 1.350577
[epoch10, step1521]: loss 1.978997
[epoch10, step1522]: loss 1.806528
[epoch10, step1523]: loss 1.003066
[epoch10, step1524]: loss 1.150285
[epoch10, step1525]: loss 1.456317
[epoch10, step1526]: loss 1.961988
[epoch10, step1527]: loss 10.443551
[epoch10, step1528]: loss 0.807990
[epoch10, step1529]: loss 8.532366
[epoch10, step1530]: loss 1.355875
[epoch10, step1531]: loss 6.116707
[epoch10, step1532]: loss 10.348334
[epoch10, step1533]: loss 10.636343
[epoch10, step1534]: loss 14.491798
[epoch10, step1535]: loss 0.744506
[epoch10, step1536]: loss 1.767924
[epoch10, step1537]: loss 11.599053
[epoch10, step1538]: loss 11.446815
[epoch10, step1539]: loss 3.187745
[epoch10, step1540]: loss 5.563249
[epoch10, step1541]: loss 3.528034
[epoch10, step1542]: loss 13.197074
[epoch10, step1543]: loss 9.293762
[epoch10, step1544]: loss 14.399754
[epoch10, step1545]: loss 10.202867
[epoch10, step1546]: loss 2.902630
[epoch10, step1547]: loss 13.279315
[epoch10, step1548]: loss 13.768888
[epoch10, step1549]: loss 3.511700
[epoch10, step1550]: loss 0.929969
[epoch10, step1551]: loss 7.637343
[epoch10, step1552]: loss 1.152387
[epoch10, step1553]: loss 10.362865
[epoch10, step1554]: loss 3.659907
[epoch10, step1555]: loss 3.173782
[epoch10, step1556]: loss 4.880819
[epoch10, step1557]: loss 0.930053
[epoch10, step1558]: loss 8.155999
[epoch10, step1559]: loss 14.384568
[epoch10, step1560]: loss 1.560243
[epoch10, step1561]: loss 10.346207
[epoch10, step1562]: loss 2.049003
[epoch10, step1563]: loss 8.255593
[epoch10, step1564]: loss 3.932923
[epoch10, step1565]: loss 16.865202
[epoch10, step1566]: loss 17.297258
[epoch10, step1567]: loss 3.102852
[epoch10, step1568]: loss 0.876991
[epoch10, step1569]: loss 5.698324
[epoch10, step1570]: loss 1.017482
[epoch10, step1571]: loss 1.846164
[epoch10, step1572]: loss 1.859943
[epoch10, step1573]: loss 17.292465
[epoch10, step1574]: loss 7.661955
[epoch10, step1575]: loss 10.772323
[epoch10, step1576]: loss 0.948551
[epoch10, step1577]: loss 2.009291
[epoch10, step1578]: loss 2.231269
[epoch10, step1579]: loss 1.280606
[epoch10, step1580]: loss 17.042068
[epoch10, step1581]: loss 8.590957
[epoch10, step1582]: loss 7.586784
[epoch10, step1583]: loss 4.866123
[epoch10, step1584]: loss 1.208635
[epoch10, step1585]: loss 1.837664
[epoch10, step1586]: loss 7.926823
[epoch10, step1587]: loss 8.466629
[epoch10, step1588]: loss 1.343771
[epoch10, step1589]: loss 1.854453
[epoch10, step1590]: loss 2.198143
[epoch10, step1591]: loss 1.266467
[epoch10, step1592]: loss 2.490487
[epoch10, step1593]: loss 7.041121
[epoch10, step1594]: loss 0.941492
[epoch10, step1595]: loss 25.020041
[epoch10, step1596]: loss 1.431869
[epoch10, step1597]: loss 2.096476
[epoch10, step1598]: loss 1.561318
[epoch10, step1599]: loss 16.415213
[epoch10, step1600]: loss 1.947926
[epoch10, step1601]: loss 2.164942
[epoch10, step1602]: loss 1.144327
[epoch10, step1603]: loss 11.199320
[epoch10, step1604]: loss 1.332694
[epoch10, step1605]: loss 0.941910
[epoch10, step1606]: loss 10.658706
[epoch10, step1607]: loss 2.426488
[epoch10, step1608]: loss 1.539683
[epoch10, step1609]: loss 11.702510
[epoch10, step1610]: loss 3.849965
[epoch10, step1611]: loss 3.672587
[epoch10, step1612]: loss 4.283241
[epoch10, step1613]: loss 6.855521
[epoch10, step1614]: loss 5.397185
[epoch10, step1615]: loss 8.579631
[epoch10, step1616]: loss 0.919760
[epoch10, step1617]: loss 7.155283
[epoch10, step1618]: loss 10.809490
[epoch10, step1619]: loss 1.397248
[epoch10, step1620]: loss 6.117595
[epoch10, step1621]: loss 5.112366
[epoch10, step1622]: loss 5.645668
[epoch10, step1623]: loss 1.217611
[epoch10, step1624]: loss 22.637600
[epoch10, step1625]: loss 2.185984
[epoch10, step1626]: loss 16.480400
[epoch10, step1627]: loss 20.108778
[epoch10, step1628]: loss 1.475062
[epoch10, step1629]: loss 3.368098
[epoch10, step1630]: loss 2.238225
[epoch10, step1631]: loss 1.597084
[epoch10, step1632]: loss 3.283698
[epoch10, step1633]: loss 5.601403
[epoch10, step1634]: loss 9.780168
[epoch10, step1635]: loss 2.554787
[epoch10, step1636]: loss 9.538357
[epoch10, step1637]: loss 11.266198
[epoch10, step1638]: loss 3.297130
[epoch10, step1639]: loss 2.883275
[epoch10, step1640]: loss 1.315071
[epoch10, step1641]: loss 8.543528
[epoch10, step1642]: loss 0.983741
[epoch10, step1643]: loss 3.680938
[epoch10, step1644]: loss 2.671122
[epoch10, step1645]: loss 1.993032
[epoch10, step1646]: loss 1.484149
[epoch10, step1647]: loss 6.006158
[epoch10, step1648]: loss 2.623099
[epoch10, step1649]: loss 7.452514
[epoch10, step1650]: loss 2.060325
[epoch10, step1651]: loss 4.440241
[epoch10, step1652]: loss 1.059458
[epoch10, step1653]: loss 4.169606
[epoch10, step1654]: loss 7.494738
[epoch10, step1655]: loss 5.545291
[epoch10, step1656]: loss 10.447420
[epoch10, step1657]: loss 2.046111
[epoch10, step1658]: loss 2.021738
[epoch10, step1659]: loss 1.647365
[epoch10, step1660]: loss 8.147873
[epoch10, step1661]: loss 3.093429
[epoch10, step1662]: loss 1.455043
[epoch10, step1663]: loss 4.314324
[epoch10, step1664]: loss 4.549764
[epoch10, step1665]: loss 1.389748
[epoch10, step1666]: loss 1.798698
[epoch10, step1667]: loss 14.833391
[epoch10, step1668]: loss 8.693767
[epoch10, step1669]: loss 9.010990
[epoch10, step1670]: loss 1.443588
[epoch10, step1671]: loss 1.370216
[epoch10, step1672]: loss 3.213264
[epoch10, step1673]: loss 17.474445
[epoch10, step1674]: loss 3.445544
[epoch10, step1675]: loss 1.278156
[epoch10, step1676]: loss 5.233229
[epoch10, step1677]: loss 3.748436
[epoch10, step1678]: loss 2.724059
[epoch10, step1679]: loss 5.732102
[epoch10, step1680]: loss 1.245731
[epoch10, step1681]: loss 1.945727
[epoch10, step1682]: loss 2.469658
[epoch10, step1683]: loss 5.672709
[epoch10, step1684]: loss 4.967872
[epoch10, step1685]: loss 1.236368
[epoch10, step1686]: loss 7.251717
[epoch10, step1687]: loss 1.497357
[epoch10, step1688]: loss 5.781383
[epoch10, step1689]: loss 1.284639
[epoch10, step1690]: loss 14.149514
[epoch10, step1691]: loss 1.760042
[epoch10, step1692]: loss 12.441427
[epoch10, step1693]: loss 10.409121
[epoch10, step1694]: loss 1.331125
[epoch10, step1695]: loss 0.917067
[epoch10, step1696]: loss 1.412406
[epoch10, step1697]: loss 3.163666
[epoch10, step1698]: loss 1.834422
[epoch10, step1699]: loss 5.837645
[epoch10, step1700]: loss 3.911030
[epoch10, step1701]: loss 10.631524
[epoch10, step1702]: loss 7.356666
[epoch10, step1703]: loss 4.723767
[epoch10, step1704]: loss 9.132663
[epoch10, step1705]: loss 8.454815
[epoch10, step1706]: loss 4.767839
[epoch10, step1707]: loss 1.306904
[epoch10, step1708]: loss 4.233951
[epoch10, step1709]: loss 10.540662
[epoch10, step1710]: loss 4.148949
[epoch10, step1711]: loss 3.795308
[epoch10, step1712]: loss 2.539253
[epoch10, step1713]: loss 1.176957
[epoch10, step1714]: loss 1.491645
[epoch10, step1715]: loss 11.415123
[epoch10, step1716]: loss 10.111685
[epoch10, step1717]: loss 1.492443
[epoch10, step1718]: loss 12.938412
[epoch10, step1719]: loss 1.013848
[epoch10, step1720]: loss 12.768870
[epoch10, step1721]: loss 3.380115
[epoch10, step1722]: loss 11.451524
[epoch10, step1723]: loss 17.674877
[epoch10, step1724]: loss 14.384831
[epoch10, step1725]: loss 2.964378
[epoch10, step1726]: loss 2.824814
[epoch10, step1727]: loss 9.227477
[epoch10, step1728]: loss 3.168051
[epoch10, step1729]: loss 1.338591
[epoch10, step1730]: loss 3.307895
[epoch10, step1731]: loss 1.284375
[epoch10, step1732]: loss 1.787813
[epoch10, step1733]: loss 1.410509
[epoch10, step1734]: loss 7.035525
[epoch10, step1735]: loss 1.701988
[epoch10, step1736]: loss 9.141450
[epoch10, step1737]: loss 9.927067
[epoch10, step1738]: loss 1.599797
[epoch10, step1739]: loss 1.474819
[epoch10, step1740]: loss 15.437227
[epoch10, step1741]: loss 19.386982
[epoch10, step1742]: loss 1.117327
[epoch10, step1743]: loss 1.622781
[epoch10, step1744]: loss 2.008590
[epoch10, step1745]: loss 3.057501
[epoch10, step1746]: loss 4.038074
[epoch10, step1747]: loss 9.755029
[epoch10, step1748]: loss 1.299798
[epoch10, step1749]: loss 9.789162
[epoch10, step1750]: loss 1.662448
[epoch10, step1751]: loss 1.806971
[epoch10, step1752]: loss 2.584452
[epoch10, step1753]: loss 1.089910
[epoch10, step1754]: loss 4.987950
[epoch10, step1755]: loss 11.799891
[epoch10, step1756]: loss 4.262529
[epoch10, step1757]: loss 18.744631
[epoch10, step1758]: loss 1.611341
[epoch10, step1759]: loss 0.989622
[epoch10, step1760]: loss 2.875711
[epoch10, step1761]: loss 8.623015
[epoch10, step1762]: loss 1.848796
[epoch10, step1763]: loss 1.894563
[epoch10, step1764]: loss 21.177582
[epoch10, step1765]: loss 4.479981
[epoch10, step1766]: loss 1.823502
[epoch10, step1767]: loss 15.779378
[epoch10, step1768]: loss 20.067987
[epoch10, step1769]: loss 2.742551
[epoch10, step1770]: loss 9.028971
[epoch10, step1771]: loss 5.246779
[epoch10, step1772]: loss 10.219272
[epoch10, step1773]: loss 0.766199
[epoch10, step1774]: loss 3.499608
[epoch10, step1775]: loss 2.094971
[epoch10, step1776]: loss 1.279463
[epoch10, step1777]: loss 2.483005
[epoch10, step1778]: loss 0.912067
[epoch10, step1779]: loss 1.841242
[epoch10, step1780]: loss 5.142695
[epoch10, step1781]: loss 2.432066
[epoch10, step1782]: loss 3.257326
[epoch10, step1783]: loss 1.576832
[epoch10, step1784]: loss 11.599589
[epoch10, step1785]: loss 1.166766
[epoch10, step1786]: loss 8.043929
[epoch10, step1787]: loss 1.261605
[epoch10, step1788]: loss 1.286528
[epoch10, step1789]: loss 0.856817
[epoch10, step1790]: loss 2.122418
[epoch10, step1791]: loss 8.506027
[epoch10, step1792]: loss 1.682065
[epoch10, step1793]: loss 2.699675
[epoch10, step1794]: loss 4.815295
[epoch10, step1795]: loss 2.239033
[epoch10, step1796]: loss 1.635547
[epoch10, step1797]: loss 16.214005
[epoch10, step1798]: loss 1.203439
[epoch10, step1799]: loss 10.953010
[epoch10, step1800]: loss 1.946700
[epoch10, step1801]: loss 4.112606
[epoch10, step1802]: loss 6.112490
[epoch10, step1803]: loss 14.534604
[epoch10, step1804]: loss 3.596214
[epoch10, step1805]: loss 1.659202
[epoch10, step1806]: loss 1.281320
[epoch10, step1807]: loss 14.569154
[epoch10, step1808]: loss 1.071903
[epoch10, step1809]: loss 14.405857
[epoch10, step1810]: loss 3.220116
[epoch10, step1811]: loss 16.940271
[epoch10, step1812]: loss 1.283852
[epoch10, step1813]: loss 1.084593
[epoch10, step1814]: loss 15.256449
[epoch10, step1815]: loss 3.719477
[epoch10, step1816]: loss 3.020567
[epoch10, step1817]: loss 11.017058
[epoch10, step1818]: loss 1.489964
[epoch10, step1819]: loss 2.145895
[epoch10, step1820]: loss 1.213890
[epoch10, step1821]: loss 11.231541
[epoch10, step1822]: loss 2.298666
[epoch10, step1823]: loss 3.045594
[epoch10, step1824]: loss 3.783988
[epoch10, step1825]: loss 2.039503
[epoch10, step1826]: loss 1.604918
[epoch10, step1827]: loss 9.492916
[epoch10, step1828]: loss 2.080932
[epoch10, step1829]: loss 1.212061
[epoch10, step1830]: loss 1.518958
[epoch10, step1831]: loss 3.327291
[epoch10, step1832]: loss 15.684451
[epoch10, step1833]: loss 1.894481
[epoch10, step1834]: loss 6.918796
[epoch10, step1835]: loss 1.520144
[epoch10, step1836]: loss 0.998500
[epoch10, step1837]: loss 8.704954
[epoch10, step1838]: loss 10.326906
[epoch10, step1839]: loss 4.790390
[epoch10, step1840]: loss 3.288109
[epoch10, step1841]: loss 3.383351
[epoch10, step1842]: loss 1.309678
[epoch10, step1843]: loss 1.950085
[epoch10, step1844]: loss 2.120556
[epoch10, step1845]: loss 3.125984
[epoch10, step1846]: loss 1.151213
[epoch10, step1847]: loss 1.878437
[epoch10, step1848]: loss 10.418974
[epoch10, step1849]: loss 3.426251
[epoch10, step1850]: loss 3.272392
[epoch10, step1851]: loss 1.010685
[epoch10, step1852]: loss 1.540632
[epoch10, step1853]: loss 0.963223
[epoch10, step1854]: loss 4.236316
[epoch10, step1855]: loss 1.197189
[epoch10, step1856]: loss 6.424019
[epoch10, step1857]: loss 1.387254
[epoch10, step1858]: loss 13.953891
[epoch10, step1859]: loss 6.501874
[epoch10, step1860]: loss 16.495710
[epoch10, step1861]: loss 2.412698
[epoch10, step1862]: loss 1.125794
[epoch10, step1863]: loss 4.304634
[epoch10, step1864]: loss 0.888079
[epoch10, step1865]: loss 2.282209
[epoch10, step1866]: loss 4.417246
[epoch10, step1867]: loss 5.544157
[epoch10, step1868]: loss 2.872277
[epoch10, step1869]: loss 2.480789
[epoch10, step1870]: loss 9.057015
[epoch10, step1871]: loss 2.773073
[epoch10, step1872]: loss 2.571522
[epoch10, step1873]: loss 9.190962
[epoch10, step1874]: loss 1.262622
[epoch10, step1875]: loss 11.231642
[epoch10, step1876]: loss 1.989496
[epoch10, step1877]: loss 2.819965
[epoch10, step1878]: loss 7.538156
[epoch10, step1879]: loss 1.944546
[epoch10, step1880]: loss 7.046557
[epoch10, step1881]: loss 18.440985
[epoch10, step1882]: loss 1.138876
[epoch10, step1883]: loss 1.157503
[epoch10, step1884]: loss 1.665409
[epoch10, step1885]: loss 1.342880
[epoch10, step1886]: loss 2.537335
[epoch10, step1887]: loss 8.967451
[epoch10, step1888]: loss 14.561119
[epoch10, step1889]: loss 5.311896
[epoch10, step1890]: loss 1.627349
[epoch10, step1891]: loss 7.456870
[epoch10, step1892]: loss 1.374546
[epoch10, step1893]: loss 4.001863
[epoch10, step1894]: loss 9.092936
[epoch10, step1895]: loss 12.699679
[epoch10, step1896]: loss 2.386187
[epoch10, step1897]: loss 9.499206
[epoch10, step1898]: loss 1.557924
[epoch10, step1899]: loss 2.015029
[epoch10, step1900]: loss 1.114996
[epoch10, step1901]: loss 11.318209
[epoch10, step1902]: loss 1.488607
[epoch10, step1903]: loss 2.787998
[epoch10, step1904]: loss 21.690210
[epoch10, step1905]: loss 1.748524
[epoch10, step1906]: loss 1.756527
[epoch10, step1907]: loss 2.027065
[epoch10, step1908]: loss 11.868587
[epoch10, step1909]: loss 2.012986
[epoch10, step1910]: loss 13.275425
[epoch10, step1911]: loss 9.733683
[epoch10, step1912]: loss 26.264297
[epoch10, step1913]: loss 5.925754
[epoch10, step1914]: loss 0.868503
[epoch10, step1915]: loss 3.034227
[epoch10, step1916]: loss 3.352936
[epoch10, step1917]: loss 1.653316
[epoch10, step1918]: loss 13.165798
[epoch10, step1919]: loss 1.378601
[epoch10, step1920]: loss 5.004889
[epoch10, step1921]: loss 1.497959
[epoch10, step1922]: loss 2.054443
[epoch10, step1923]: loss 1.727893
[epoch10, step1924]: loss 8.688397
[epoch10, step1925]: loss 1.486643
[epoch10, step1926]: loss 2.142841
[epoch10, step1927]: loss 1.672399
[epoch10, step1928]: loss 5.873091
[epoch10, step1929]: loss 17.537991
[epoch10, step1930]: loss 2.674959
[epoch10, step1931]: loss 1.447481
[epoch10, step1932]: loss 2.827048
[epoch10, step1933]: loss 3.427506
[epoch10, step1934]: loss 8.249143
[epoch10, step1935]: loss 11.004267
[epoch10, step1936]: loss 1.714455
[epoch10, step1937]: loss 1.541323
[epoch10, step1938]: loss 1.317708
[epoch10, step1939]: loss 10.522292
[epoch10, step1940]: loss 1.292650
[epoch10, step1941]: loss 2.204489
[epoch10, step1942]: loss 9.913095
[epoch10, step1943]: loss 2.398267
[epoch10, step1944]: loss 4.508847
[epoch10, step1945]: loss 2.127961
[epoch10, step1946]: loss 4.285765
[epoch10, step1947]: loss 7.189505
[epoch10, step1948]: loss 1.131146
[epoch10, step1949]: loss 4.267363
[epoch10, step1950]: loss 10.034974
[epoch10, step1951]: loss 2.213386
[epoch10, step1952]: loss 3.702436
[epoch10, step1953]: loss 9.897622
[epoch10, step1954]: loss 7.551583
[epoch10, step1955]: loss 1.222024
[epoch10, step1956]: loss 2.223625
[epoch10, step1957]: loss 1.718080
[epoch10, step1958]: loss 1.215528
[epoch10, step1959]: loss 7.032835
[epoch10, step1960]: loss 12.062492
[epoch10, step1961]: loss 9.771286
[epoch10, step1962]: loss 1.397485
[epoch10, step1963]: loss 1.296158
[epoch10, step1964]: loss 9.644956
[epoch10, step1965]: loss 9.895679
[epoch10, step1966]: loss 2.842596
[epoch10, step1967]: loss 2.466849
[epoch10, step1968]: loss 11.208634
[epoch10, step1969]: loss 0.886306
[epoch10, step1970]: loss 10.129348
[epoch10, step1971]: loss 4.320365
[epoch10, step1972]: loss 7.238008
[epoch10, step1973]: loss 3.389924
[epoch10, step1974]: loss 10.800042
[epoch10, step1975]: loss 1.236527
[epoch10, step1976]: loss 1.839934
[epoch10, step1977]: loss 11.279504
[epoch10, step1978]: loss 2.047612
[epoch10, step1979]: loss 7.328548
[epoch10, step1980]: loss 6.708366
[epoch10, step1981]: loss 8.971569
[epoch10, step1982]: loss 2.732249
[epoch10, step1983]: loss 23.542847
[epoch10, step1984]: loss 0.909485
[epoch10, step1985]: loss 2.965573
[epoch10, step1986]: loss 16.104174
[epoch10, step1987]: loss 1.078999
[epoch10, step1988]: loss 1.202309
[epoch10, step1989]: loss 1.083871
[epoch10, step1990]: loss 1.855378
[epoch10, step1991]: loss 1.800848
[epoch10, step1992]: loss 11.438227
[epoch10, step1993]: loss 10.463118
[epoch10, step1994]: loss 2.131011
[epoch10, step1995]: loss 1.266688
[epoch10, step1996]: loss 8.032269
[epoch10, step1997]: loss 0.832617
[epoch10, step1998]: loss 2.283783
[epoch10, step1999]: loss 7.638115
[epoch10, step2000]: loss 1.037969
[epoch10, step2001]: loss 2.578110
[epoch10, step2002]: loss 4.116094
[epoch10, step2003]: loss 2.204619
[epoch10, step2004]: loss 8.465275
[epoch10, step2005]: loss 2.052029
[epoch10, step2006]: loss 2.014429
[epoch10, step2007]: loss 8.491877
[epoch10, step2008]: loss 10.605708
[epoch10, step2009]: loss 4.063755
[epoch10, step2010]: loss 4.756062
[epoch10, step2011]: loss 17.647377
[epoch10, step2012]: loss 1.625924
[epoch10, step2013]: loss 3.582586
[epoch10, step2014]: loss 3.410348
[epoch10, step2015]: loss 1.857726
[epoch10, step2016]: loss 2.200610
[epoch10, step2017]: loss 3.483214
[epoch10, step2018]: loss 1.610105
[epoch10, step2019]: loss 1.244088
[epoch10, step2020]: loss 21.844774
[epoch10, step2021]: loss 2.024825
[epoch10, step2022]: loss 1.078070
[epoch10, step2023]: loss 1.104744
[epoch10, step2024]: loss 1.685495
[epoch10, step2025]: loss 1.548052
[epoch10, step2026]: loss 1.223495
[epoch10, step2027]: loss 7.829590
[epoch10, step2028]: loss 10.882606
[epoch10, step2029]: loss 15.974825
[epoch10, step2030]: loss 11.752868
[epoch10, step2031]: loss 3.330093
[epoch10, step2032]: loss 11.639292
[epoch10, step2033]: loss 20.517191
[epoch10, step2034]: loss 3.497972
[epoch10, step2035]: loss 5.288379
[epoch10, step2036]: loss 3.084220
[epoch10, step2037]: loss 2.709960
[epoch10, step2038]: loss 4.161478
[epoch10, step2039]: loss 1.787123
[epoch10, step2040]: loss 4.346743
[epoch10, step2041]: loss 1.841485
[epoch10, step2042]: loss 10.547403
[epoch10, step2043]: loss 1.941048
[epoch10, step2044]: loss 1.819455
[epoch10, step2045]: loss 13.600533
[epoch10, step2046]: loss 1.199204
[epoch10, step2047]: loss 7.507391
[epoch10, step2048]: loss 7.909154
[epoch10, step2049]: loss 5.806357
[epoch10, step2050]: loss 10.308141
[epoch10, step2051]: loss 3.701204
[epoch10, step2052]: loss 2.649992
[epoch10, step2053]: loss 2.164307
[epoch10, step2054]: loss 11.322076
[epoch10, step2055]: loss 1.029082
[epoch10, step2056]: loss 3.579437
[epoch10, step2057]: loss 3.650913
[epoch10, step2058]: loss 2.822024
[epoch10, step2059]: loss 9.618489
[epoch10, step2060]: loss 9.605358
[epoch10, step2061]: loss 3.359145
[epoch10, step2062]: loss 2.845829
[epoch10, step2063]: loss 4.918391
[epoch10, step2064]: loss 0.843515
[epoch10, step2065]: loss 2.128393
[epoch10, step2066]: loss 4.888066
[epoch10, step2067]: loss 20.111765
[epoch10, step2068]: loss 11.253722
[epoch10, step2069]: loss 1.333215
[epoch10, step2070]: loss 8.685874
[epoch10, step2071]: loss 1.482603
[epoch10, step2072]: loss 4.212898
[epoch10, step2073]: loss 1.119636
[epoch10, step2074]: loss 2.678822
[epoch10, step2075]: loss 2.144975
[epoch10, step2076]: loss 7.619798
[epoch10, step2077]: loss 21.965641
[epoch10, step2078]: loss 3.485725
[epoch10, step2079]: loss 16.126957
[epoch10, step2080]: loss 2.268280
[epoch10, step2081]: loss 1.496312
[epoch10, step2082]: loss 2.368357
[epoch10, step2083]: loss 11.724804
[epoch10, step2084]: loss 1.127480
[epoch10, step2085]: loss 3.837989
[epoch10, step2086]: loss 4.805265
[epoch10, step2087]: loss 1.912199
[epoch10, step2088]: loss 1.709497
[epoch10, step2089]: loss 3.374931
[epoch10, step2090]: loss 1.901163
[epoch10, step2091]: loss 2.135552
[epoch10, step2092]: loss 3.776976
[epoch10, step2093]: loss 1.218180
[epoch10, step2094]: loss 2.232247
[epoch10, step2095]: loss 2.332944
[epoch10, step2096]: loss 1.491247
[epoch10, step2097]: loss 1.235652
[epoch10, step2098]: loss 1.387983
[epoch10, step2099]: loss 1.969091
[epoch10, step2100]: loss 8.991941
[epoch10, step2101]: loss 2.480877
[epoch10, step2102]: loss 3.088515
[epoch10, step2103]: loss 16.662809
[epoch10, step2104]: loss 3.474224
[epoch10, step2105]: loss 14.647619
[epoch10, step2106]: loss 11.219999
[epoch10, step2107]: loss 1.681788
[epoch10, step2108]: loss 4.032212
[epoch10, step2109]: loss 9.641386
[epoch10, step2110]: loss 1.550183
[epoch10, step2111]: loss 2.246340
[epoch10, step2112]: loss 1.360252
[epoch10, step2113]: loss 1.790063
[epoch10, step2114]: loss 0.911286
[epoch10, step2115]: loss 2.483885
[epoch10, step2116]: loss 1.207790
[epoch10, step2117]: loss 1.055384
[epoch10, step2118]: loss 2.335277
[epoch10, step2119]: loss 0.867484
[epoch10, step2120]: loss 17.764254
[epoch10, step2121]: loss 1.400161
[epoch10, step2122]: loss 0.903390
[epoch10, step2123]: loss 1.863516
[epoch10, step2124]: loss 1.380775
[epoch10, step2125]: loss 1.103747
[epoch10, step2126]: loss 0.973948
[epoch10, step2127]: loss 3.311196
[epoch10, step2128]: loss 1.823731
[epoch10, step2129]: loss 1.030703
[epoch10, step2130]: loss 1.230073
[epoch10, step2131]: loss 2.819214
[epoch10, step2132]: loss 0.891205
[epoch10, step2133]: loss 9.402143
[epoch10, step2134]: loss 1.745176
[epoch10, step2135]: loss 1.967836
[epoch10, step2136]: loss 13.454834
[epoch10, step2137]: loss 8.961544
[epoch10, step2138]: loss 3.930517
[epoch10, step2139]: loss 0.831248
[epoch10, step2140]: loss 9.645801
[epoch10, step2141]: loss 7.631755
[epoch10, step2142]: loss 1.473104
[epoch10, step2143]: loss 0.931391
[epoch10, step2144]: loss 2.574317
[epoch10, step2145]: loss 14.969543
[epoch10, step2146]: loss 8.287745
[epoch10, step2147]: loss 1.348755
[epoch10, step2148]: loss 4.220577
[epoch10, step2149]: loss 1.023531
[epoch10, step2150]: loss 1.386016
[epoch10, step2151]: loss 5.055843
[epoch10, step2152]: loss 1.683663
[epoch10, step2153]: loss 1.459731
[epoch10, step2154]: loss 1.951291
[epoch10, step2155]: loss 2.063955
[epoch10, step2156]: loss 12.123383
[epoch10, step2157]: loss 3.262636
[epoch10, step2158]: loss 3.081363
[epoch10, step2159]: loss 1.022179
[epoch10, step2160]: loss 1.765144
[epoch10, step2161]: loss 12.338765
[epoch10, step2162]: loss 4.548807
[epoch10, step2163]: loss 1.847535
[epoch10, step2164]: loss 8.945653
[epoch10, step2165]: loss 1.307389
[epoch10, step2166]: loss 1.184643
[epoch10, step2167]: loss 2.051458
[epoch10, step2168]: loss 1.080707
[epoch10, step2169]: loss 1.321187
[epoch10, step2170]: loss 3.691241
[epoch10, step2171]: loss 1.532854
[epoch10, step2172]: loss 8.888160
[epoch10, step2173]: loss 1.161643
[epoch10, step2174]: loss 1.850846
[epoch10, step2175]: loss 1.485827
[epoch10, step2176]: loss 5.552027
[epoch10, step2177]: loss 1.375759
[epoch10, step2178]: loss 2.101597
[epoch10, step2179]: loss 1.028371
[epoch10, step2180]: loss 2.200813
[epoch10, step2181]: loss 4.941361
[epoch10, step2182]: loss 5.556638
[epoch10, step2183]: loss 1.266301
[epoch10, step2184]: loss 1.386091
[epoch10, step2185]: loss 1.715736
[epoch10, step2186]: loss 2.549279
[epoch10, step2187]: loss 1.952288
[epoch10, step2188]: loss 8.511797
[epoch10, step2189]: loss 1.423703
[epoch10, step2190]: loss 1.685601
[epoch10, step2191]: loss 1.025562
[epoch10, step2192]: loss 1.559637
[epoch10, step2193]: loss 1.158029
[epoch10, step2194]: loss 10.285318
[epoch10, step2195]: loss 1.752005
[epoch10, step2196]: loss 1.096738
[epoch10, step2197]: loss 1.604448
[epoch10, step2198]: loss 3.957783
[epoch10, step2199]: loss 1.653591
[epoch10, step2200]: loss 1.734185
[epoch10, step2201]: loss 1.798754
[epoch10, step2202]: loss 5.152418
[epoch10, step2203]: loss 3.890272
[epoch10, step2204]: loss 2.124410
[epoch10, step2205]: loss 2.953643
[epoch10, step2206]: loss 6.051399
[epoch10, step2207]: loss 2.226590
[epoch10, step2208]: loss 3.525623
[epoch10, step2209]: loss 0.994798
[epoch10, step2210]: loss 2.938992
[epoch10, step2211]: loss 1.943780
[epoch10, step2212]: loss 9.995053
[epoch10, step2213]: loss 1.130378
[epoch10, step2214]: loss 1.171138
[epoch10, step2215]: loss 1.843598
[epoch10, step2216]: loss 2.328466
[epoch10, step2217]: loss 1.063000
[epoch10, step2218]: loss 14.161198
[epoch10, step2219]: loss 7.842903
[epoch10, step2220]: loss 1.121967
[epoch10, step2221]: loss 2.315058
[epoch10, step2222]: loss 5.246761
[epoch10, step2223]: loss 2.159984
[epoch10, step2224]: loss 10.091705
[epoch10, step2225]: loss 1.720986
[epoch10, step2226]: loss 2.027831
[epoch10, step2227]: loss 1.966438
[epoch10, step2228]: loss 3.851694
[epoch10, step2229]: loss 21.849054
[epoch10, step2230]: loss 3.534255
[epoch10, step2231]: loss 1.167014
[epoch10, step2232]: loss 3.350876
[epoch10, step2233]: loss 13.571918
[epoch10, step2234]: loss 4.781343
[epoch10, step2235]: loss 1.473956
[epoch10, step2236]: loss 6.810865
[epoch10, step2237]: loss 1.743630
[epoch10, step2238]: loss 11.594166
[epoch10, step2239]: loss 14.347226
[epoch10, step2240]: loss 1.938485
[epoch10, step2241]: loss 10.226522
[epoch10, step2242]: loss 1.488835
[epoch10, step2243]: loss 1.529660
[epoch10, step2244]: loss 1.057072
[epoch10, step2245]: loss 3.278918
[epoch10, step2246]: loss 8.951443
[epoch10, step2247]: loss 3.145004
[epoch10, step2248]: loss 9.769837
[epoch10, step2249]: loss 2.001563
[epoch10, step2250]: loss 19.566502
[epoch10, step2251]: loss 9.256969
[epoch10, step2252]: loss 1.641537
[epoch10, step2253]: loss 2.429199
[epoch10, step2254]: loss 15.461698
[epoch10, step2255]: loss 10.532124
[epoch10, step2256]: loss 2.483172
[epoch10, step2257]: loss 0.961660
[epoch10, step2258]: loss 21.207617
[epoch10, step2259]: loss 1.493752
[epoch10, step2260]: loss 1.212549
[epoch10, step2261]: loss 1.209654
[epoch10, step2262]: loss 1.061504
[epoch10, step2263]: loss 1.250788
[epoch10, step2264]: loss 2.429778
[epoch10, step2265]: loss 12.779543
[epoch10, step2266]: loss 2.955181
[epoch10, step2267]: loss 1.642528
[epoch10, step2268]: loss 5.636557
[epoch10, step2269]: loss 2.136206
[epoch10, step2270]: loss 12.606161
[epoch10, step2271]: loss 2.031926
[epoch10, step2272]: loss 1.733851
[epoch10, step2273]: loss 13.325771
[epoch10, step2274]: loss 1.594820
[epoch10, step2275]: loss 6.555080
[epoch10, step2276]: loss 1.305023
[epoch10, step2277]: loss 22.002850
[epoch10, step2278]: loss 3.941598
[epoch10, step2279]: loss 1.460670
[epoch10, step2280]: loss 4.231903
[epoch10, step2281]: loss 1.754628
[epoch10, step2282]: loss 12.127045
[epoch10, step2283]: loss 11.164491
[epoch10, step2284]: loss 4.075448
[epoch10, step2285]: loss 18.820580
[epoch10, step2286]: loss 1.687435
[epoch10, step2287]: loss 16.676462
[epoch10, step2288]: loss 6.051251
[epoch10, step2289]: loss 11.432808
[epoch10, step2290]: loss 1.397052
[epoch10, step2291]: loss 2.643412
[epoch10, step2292]: loss 2.144308
[epoch10, step2293]: loss 1.546522
[epoch10, step2294]: loss 3.942221
[epoch10, step2295]: loss 9.520128
[epoch10, step2296]: loss 4.165720
[epoch10, step2297]: loss 17.380566
[epoch10, step2298]: loss 1.127318
[epoch10, step2299]: loss 5.572820
[epoch10, step2300]: loss 0.953009
[epoch10, step2301]: loss 4.652760
[epoch10, step2302]: loss 9.374600
[epoch10, step2303]: loss 15.247001
[epoch10, step2304]: loss 4.424191
[epoch10, step2305]: loss 1.531882
[epoch10, step2306]: loss 9.860390
[epoch10, step2307]: loss 7.867608
[epoch10, step2308]: loss 0.834300
[epoch10, step2309]: loss 1.112842
[epoch10, step2310]: loss 13.750374
[epoch10, step2311]: loss 1.202466
[epoch10, step2312]: loss 9.122245
[epoch10, step2313]: loss 0.860222
[epoch10, step2314]: loss 16.308567
[epoch10, step2315]: loss 1.274583
[epoch10, step2316]: loss 14.127241
[epoch10, step2317]: loss 3.525889
[epoch10, step2318]: loss 10.306038
[epoch10, step2319]: loss 2.165747
[epoch10, step2320]: loss 1.277589
[epoch10, step2321]: loss 9.135012
[epoch10, step2322]: loss 5.098768
[epoch10, step2323]: loss 9.693172
[epoch10, step2324]: loss 2.258868
[epoch10, step2325]: loss 1.297362
[epoch10, step2326]: loss 4.234719
[epoch10, step2327]: loss 4.219015
[epoch10, step2328]: loss 1.039833
[epoch10, step2329]: loss 7.120830
[epoch10, step2330]: loss 1.106565
[epoch10, step2331]: loss 3.814039
[epoch10, step2332]: loss 11.030357
[epoch10, step2333]: loss 1.177469
[epoch10, step2334]: loss 1.966663
[epoch10, step2335]: loss 7.363380
[epoch10, step2336]: loss 1.973562
[epoch10, step2337]: loss 10.613475
[epoch10, step2338]: loss 1.743398
[epoch10, step2339]: loss 1.462450
[epoch10, step2340]: loss 0.979593
[epoch10, step2341]: loss 3.269307
[epoch10, step2342]: loss 5.475710
[epoch10, step2343]: loss 0.918956
[epoch10, step2344]: loss 9.428012
[epoch10, step2345]: loss 11.035831
[epoch10, step2346]: loss 2.670140
[epoch10, step2347]: loss 15.405678
[epoch10, step2348]: loss 7.924629
[epoch10, step2349]: loss 1.286552
[epoch10, step2350]: loss 4.048555
[epoch10, step2351]: loss 3.486172
[epoch10, step2352]: loss 2.895200
[epoch10, step2353]: loss 2.486331
[epoch10, step2354]: loss 19.184669
[epoch10, step2355]: loss 10.025932
[epoch10, step2356]: loss 2.395071
[epoch10, step2357]: loss 1.298876
[epoch10, step2358]: loss 2.278267
[epoch10, step2359]: loss 7.021374
[epoch10, step2360]: loss 2.170601
[epoch10, step2361]: loss 7.264149
[epoch10, step2362]: loss 10.471454
[epoch10, step2363]: loss 1.976067
[epoch10, step2364]: loss 5.750842
[epoch10, step2365]: loss 7.294863
[epoch10, step2366]: loss 1.626882
[epoch10, step2367]: loss 4.225441
[epoch10, step2368]: loss 11.437827
[epoch10, step2369]: loss 2.214486
[epoch10, step2370]: loss 2.550744
[epoch10, step2371]: loss 2.560977
[epoch10, step2372]: loss 1.164137
[epoch10, step2373]: loss 11.487770
[epoch10, step2374]: loss 1.339895
[epoch10, step2375]: loss 1.037781
[epoch10, step2376]: loss 0.999524
[epoch10, step2377]: loss 1.207821
[epoch10, step2378]: loss 6.115873
[epoch10, step2379]: loss 8.767361
[epoch10, step2380]: loss 1.642781
[epoch10, step2381]: loss 12.648757
[epoch10, step2382]: loss 3.995713
[epoch10, step2383]: loss 2.300025
[epoch10, step2384]: loss 1.681655
[epoch10, step2385]: loss 1.992742
[epoch10, step2386]: loss 1.726805
[epoch10, step2387]: loss 18.580126
[epoch10, step2388]: loss 1.071218
[epoch10, step2389]: loss 1.181335
[epoch10, step2390]: loss 20.766144
[epoch10, step2391]: loss 2.204320
[epoch10, step2392]: loss 1.015982
[epoch10, step2393]: loss 4.362205
[epoch10, step2394]: loss 4.198229
[epoch10, step2395]: loss 1.027658
[epoch10, step2396]: loss 10.429368
[epoch10, step2397]: loss 19.541636
[epoch10, step2398]: loss 3.365718
[epoch10, step2399]: loss 2.687324
[epoch10, step2400]: loss 1.226841
[epoch10, step2401]: loss 1.338627
[epoch10, step2402]: loss 0.934489
[epoch10, step2403]: loss 3.804770
[epoch10, step2404]: loss 2.833455
[epoch10, step2405]: loss 1.300140
[epoch10, step2406]: loss 0.844687
[epoch10, step2407]: loss 2.029308
[epoch10, step2408]: loss 3.324645
[epoch10, step2409]: loss 2.660810
[epoch10, step2410]: loss 2.757713
[epoch10, step2411]: loss 1.136970
[epoch10, step2412]: loss 7.834198
[epoch10, step2413]: loss 13.515434
[epoch10, step2414]: loss 0.799646
[epoch10, step2415]: loss 3.635266
[epoch10, step2416]: loss 3.622108
[epoch10, step2417]: loss 1.025271
[epoch10, step2418]: loss 10.205215
[epoch10, step2419]: loss 9.765129
[epoch10, step2420]: loss 1.245510
[epoch10, step2421]: loss 1.073546
[epoch10, step2422]: loss 17.072567
[epoch10, step2423]: loss 1.512636
[epoch10, step2424]: loss 5.158426
[epoch10, step2425]: loss 8.239445
[epoch10, step2426]: loss 3.263882
[epoch10, step2427]: loss 1.142094
[epoch10, step2428]: loss 1.657818
[epoch10, step2429]: loss 1.048854
[epoch10, step2430]: loss 8.694724
[epoch10, step2431]: loss 4.902100
[epoch10, step2432]: loss 0.776775
[epoch10, step2433]: loss 2.279436
[epoch10, step2434]: loss 9.854714
[epoch10, step2435]: loss 7.422695
[epoch10, step2436]: loss 3.028826
[epoch10, step2437]: loss 2.105564
[epoch10, step2438]: loss 2.769813
[epoch10, step2439]: loss 18.623817
[epoch10, step2440]: loss 9.678720
[epoch10, step2441]: loss 12.024987
[epoch10, step2442]: loss 11.593970
[epoch10, step2443]: loss 3.088614
[epoch10, step2444]: loss 8.328207
[epoch10, step2445]: loss 3.697646
[epoch10, step2446]: loss 9.722366
[epoch10, step2447]: loss 5.618432
[epoch10, step2448]: loss 4.506377
[epoch10, step2449]: loss 1.505034
[epoch10, step2450]: loss 6.859735
[epoch10, step2451]: loss 4.552816
[epoch10, step2452]: loss 13.596154
[epoch10, step2453]: loss 6.230056
[epoch10, step2454]: loss 1.603894
[epoch10, step2455]: loss 1.087477
[epoch10, step2456]: loss 2.203732
[epoch10, step2457]: loss 9.448553
[epoch10, step2458]: loss 4.525378
[epoch10, step2459]: loss 1.672454
[epoch10, step2460]: loss 1.680713
[epoch10, step2461]: loss 1.847741
[epoch10, step2462]: loss 2.485807
[epoch10, step2463]: loss 12.204618
[epoch10, step2464]: loss 9.362123
[epoch10, step2465]: loss 2.358567
[epoch10, step2466]: loss 9.394933
[epoch10, step2467]: loss 9.646518
[epoch10, step2468]: loss 8.947261
[epoch10, step2469]: loss 5.386142
[epoch10, step2470]: loss 6.385782
[epoch10, step2471]: loss 15.714035
[epoch10, step2472]: loss 14.035592
[epoch10, step2473]: loss 13.572394
[epoch10, step2474]: loss 1.302099
[epoch10, step2475]: loss 2.777695
[epoch10, step2476]: loss 2.384763
[epoch10, step2477]: loss 7.184416
[epoch10, step2478]: loss 2.009850
[epoch10, step2479]: loss 8.856530
[epoch10, step2480]: loss 1.882231
[epoch10, step2481]: loss 2.038393
[epoch10, step2482]: loss 0.777028
[epoch10, step2483]: loss 4.411782
[epoch10, step2484]: loss 13.235099
[epoch10, step2485]: loss 1.350335
[epoch10, step2486]: loss 0.899281
[epoch10, step2487]: loss 4.567020
[epoch10, step2488]: loss 18.030041
[epoch10, step2489]: loss 7.417749
[epoch10, step2490]: loss 4.576072
[epoch10, step2491]: loss 17.730366
[epoch10, step2492]: loss 5.838073
[epoch10, step2493]: loss 1.515337
[epoch10, step2494]: loss 1.499868
[epoch10, step2495]: loss 5.989574
[epoch10, step2496]: loss 1.462456
[epoch10, step2497]: loss 6.013626
[epoch10, step2498]: loss 1.253714
[epoch10, step2499]: loss 1.160220
[epoch10, step2500]: loss 2.594425
[epoch10, step2501]: loss 24.276201
[epoch10, step2502]: loss 0.696727
[epoch10, step2503]: loss 0.625757
[epoch10, step2504]: loss 1.780192
[epoch10, step2505]: loss 1.678065
[epoch10, step2506]: loss 1.788360
[epoch10, step2507]: loss 1.277828
[epoch10, step2508]: loss 0.944003
[epoch10, step2509]: loss 3.199953
[epoch10, step2510]: loss 1.614071
[epoch10, step2511]: loss 4.495180
[epoch10, step2512]: loss 11.470513
[epoch10, step2513]: loss 8.248133
[epoch10, step2514]: loss 33.012840
[epoch10, step2515]: loss 1.637754
[epoch10, step2516]: loss 2.528624
[epoch10, step2517]: loss 13.119902
[epoch10, step2518]: loss 0.941846
[epoch10, step2519]: loss 2.360243
[epoch10, step2520]: loss 1.781795
[epoch10, step2521]: loss 5.682764
[epoch10, step2522]: loss 10.036739
[epoch10, step2523]: loss 1.399791
[epoch10, step2524]: loss 1.536770
[epoch10, step2525]: loss 1.585350
[epoch10, step2526]: loss 1.278650
[epoch10, step2527]: loss 1.480821
[epoch10, step2528]: loss 0.843861
[epoch10, step2529]: loss 1.684378
[epoch10, step2530]: loss 1.075003
[epoch10, step2531]: loss 7.551885
[epoch10, step2532]: loss 10.983299
[epoch10, step2533]: loss 2.492441
[epoch10, step2534]: loss 2.517911
[epoch10, step2535]: loss 1.878927
[epoch10, step2536]: loss 2.307249
[epoch10, step2537]: loss 1.197845
[epoch10, step2538]: loss 5.689224
[epoch10, step2539]: loss 1.583125
[epoch10, step2540]: loss 2.190087
[epoch10, step2541]: loss 1.208612
[epoch10, step2542]: loss 3.449441
[epoch10, step2543]: loss 4.452365
[epoch10, step2544]: loss 1.259441
[epoch10, step2545]: loss 12.740048
[epoch10, step2546]: loss 0.851126
[epoch10, step2547]: loss 0.965238
[epoch10, step2548]: loss 10.537305
[epoch10, step2549]: loss 1.616368
[epoch10, step2550]: loss 13.303691
[epoch10, step2551]: loss 1.822034
[epoch10, step2552]: loss 9.249302
[epoch10, step2553]: loss 5.291673
[epoch10, step2554]: loss 1.969812
[epoch10, step2555]: loss 9.711728
[epoch10, step2556]: loss 8.357602
[epoch10, step2557]: loss 16.594442
[epoch10, step2558]: loss 9.873834
[epoch10, step2559]: loss 1.077350
[epoch10, step2560]: loss 1.504178
[epoch10, step2561]: loss 13.839538
[epoch10, step2562]: loss 1.310623
[epoch10, step2563]: loss 16.079359
[epoch10, step2564]: loss 2.100544
[epoch10, step2565]: loss 1.340905
[epoch10, step2566]: loss 2.809595
[epoch10, step2567]: loss 2.301382
[epoch10, step2568]: loss 9.259733
[epoch10, step2569]: loss 4.126347
[epoch10, step2570]: loss 2.519427
[epoch10, step2571]: loss 0.870792
[epoch10, step2572]: loss 2.864680
[epoch10, step2573]: loss 1.255789
[epoch10, step2574]: loss 1.744756
[epoch10, step2575]: loss 4.498727
[epoch10, step2576]: loss 1.295148
[epoch10, step2577]: loss 32.990208
[epoch10, step2578]: loss 7.410273
[epoch10, step2579]: loss 3.850773
[epoch10, step2580]: loss 8.682075
[epoch10, step2581]: loss 0.949934
[epoch10, step2582]: loss 10.155410
[epoch10, step2583]: loss 1.130806
[epoch10, step2584]: loss 6.600622
[epoch10, step2585]: loss 1.295582
[epoch10, step2586]: loss 2.071250
[epoch10, step2587]: loss 1.004095
[epoch10, step2588]: loss 8.061256
[epoch10, step2589]: loss 2.292544
[epoch10, step2590]: loss 8.671762
[epoch10, step2591]: loss 1.043976
[epoch10, step2592]: loss 2.196842
[epoch10, step2593]: loss 7.508620
[epoch10, step2594]: loss 2.788977
[epoch10, step2595]: loss 1.920548
[epoch10, step2596]: loss 2.100506
[epoch10, step2597]: loss 1.643640
[epoch10, step2598]: loss 8.696697
[epoch10, step2599]: loss 9.058013
[epoch10, step2600]: loss 24.052149
[epoch10, step2601]: loss 0.964259
[epoch10, step2602]: loss 19.223482
[epoch10, step2603]: loss 1.142194
[epoch10, step2604]: loss 13.479342
[epoch10, step2605]: loss 0.794421
[epoch10, step2606]: loss 4.319971
[epoch10, step2607]: loss 10.525082
[epoch10, step2608]: loss 0.980818
[epoch10, step2609]: loss 10.659217
[epoch10, step2610]: loss 4.604308
[epoch10, step2611]: loss 6.749721
[epoch10, step2612]: loss 0.875294
[epoch10, step2613]: loss 1.911721
[epoch10, step2614]: loss 10.787817
[epoch10, step2615]: loss 2.640407
[epoch10, step2616]: loss 2.244056
[epoch10, step2617]: loss 2.019639
[epoch10, step2618]: loss 1.112386
[epoch10, step2619]: loss 0.953677
[epoch10, step2620]: loss 1.053795
[epoch10, step2621]: loss 1.266349
[epoch10, step2622]: loss 14.668016
[epoch10, step2623]: loss 1.248052
[epoch10, step2624]: loss 24.053963
[epoch10, step2625]: loss 0.943634
[epoch10, step2626]: loss 1.679633
[epoch10, step2627]: loss 1.072796
[epoch10, step2628]: loss 1.115256
[epoch10, step2629]: loss 9.968527
[epoch10, step2630]: loss 5.071414
[epoch10, step2631]: loss 15.587468
[epoch10, step2632]: loss 4.970017
[epoch10, step2633]: loss 1.171170
[epoch10, step2634]: loss 1.670431
[epoch10, step2635]: loss 4.383964
[epoch10, step2636]: loss 1.185662
[epoch10, step2637]: loss 3.100628
[epoch10, step2638]: loss 1.007938
[epoch10, step2639]: loss 7.394351
[epoch10, step2640]: loss 1.270791
[epoch10, step2641]: loss 8.518020
[epoch10, step2642]: loss 3.341083
[epoch10, step2643]: loss 1.290385
[epoch10, step2644]: loss 0.570875
[epoch10, step2645]: loss 1.071801
[epoch10, step2646]: loss 1.215426
[epoch10, step2647]: loss 2.306888
[epoch10, step2648]: loss 13.927956
[epoch10, step2649]: loss 3.406228
[epoch10, step2650]: loss 4.617191
[epoch10, step2651]: loss 18.829508
[epoch10, step2652]: loss 8.220902
[epoch10, step2653]: loss 3.499510
[epoch10, step2654]: loss 9.733638
[epoch10, step2655]: loss 3.115414
[epoch10, step2656]: loss 1.473159
[epoch10, step2657]: loss 1.358569
[epoch10, step2658]: loss 9.470032
[epoch10, step2659]: loss 5.891958
[epoch10, step2660]: loss 4.208857
[epoch10, step2661]: loss 5.492597
[epoch10, step2662]: loss 3.798034
[epoch10, step2663]: loss 3.508456
[epoch10, step2664]: loss 2.176006
[epoch10, step2665]: loss 1.089595
[epoch10, step2666]: loss 3.215292
[epoch10, step2667]: loss 13.195436
[epoch10, step2668]: loss 0.749891
[epoch10, step2669]: loss 3.341886
[epoch10, step2670]: loss 2.776011
[epoch10, step2671]: loss 1.244768
[epoch10, step2672]: loss 6.974831
[epoch10, step2673]: loss 1.225815
[epoch10, step2674]: loss 3.963603
[epoch10, step2675]: loss 1.309496
[epoch10, step2676]: loss 28.317261
[epoch10, step2677]: loss 10.168820
[epoch10, step2678]: loss 1.046070
[epoch10, step2679]: loss 1.220341
[epoch10, step2680]: loss 2.116310
[epoch10, step2681]: loss 0.850972
[epoch10, step2682]: loss 1.350123
[epoch10, step2683]: loss 1.850225
[epoch10, step2684]: loss 0.750724
[epoch10, step2685]: loss 2.730233
[epoch10, step2686]: loss 2.212501
[epoch10, step2687]: loss 1.939830
[epoch10, step2688]: loss 1.155552
[epoch10, step2689]: loss 1.234128
[epoch10, step2690]: loss 1.560878
[epoch10, step2691]: loss 5.744984
[epoch10, step2692]: loss 2.871207
[epoch10, step2693]: loss 6.444108
[epoch10, step2694]: loss 12.942390
[epoch10, step2695]: loss 2.006608
[epoch10, step2696]: loss 13.198188
[epoch10, step2697]: loss 0.858849
[epoch10, step2698]: loss 11.048574
[epoch10, step2699]: loss 12.238977
[epoch10, step2700]: loss 1.904063
[epoch10, step2701]: loss 2.206417
[epoch10, step2702]: loss 2.832378
[epoch10, step2703]: loss 2.099663
[epoch10, step2704]: loss 2.268366
[epoch10, step2705]: loss 8.011486
[epoch10, step2706]: loss 1.440496
[epoch10, step2707]: loss 1.210399
[epoch10, step2708]: loss 3.884547
[epoch10, step2709]: loss 12.664763
[epoch10, step2710]: loss 1.058818
[epoch10, step2711]: loss 2.384181
[epoch10, step2712]: loss 2.245059
[epoch10, step2713]: loss 1.021003
[epoch10, step2714]: loss 4.758327
[epoch10, step2715]: loss 2.238638
[epoch10, step2716]: loss 1.264606
[epoch10, step2717]: loss 1.355593
[epoch10, step2718]: loss 1.100096
[epoch10, step2719]: loss 10.094417
[epoch10, step2720]: loss 1.618002
[epoch10, step2721]: loss 3.873332
[epoch10, step2722]: loss 10.330472
[epoch10, step2723]: loss 0.971247
[epoch10, step2724]: loss 1.561581
[epoch10, step2725]: loss 8.960047
[epoch10, step2726]: loss 21.247801
[epoch10, step2727]: loss 13.709249
[epoch10, step2728]: loss 9.928986
[epoch10, step2729]: loss 0.815486
[epoch10, step2730]: loss 0.913904
[epoch10, step2731]: loss 1.444838
[epoch10, step2732]: loss 1.092168
[epoch10, step2733]: loss 4.864679
[epoch10, step2734]: loss 0.904337
[epoch10, step2735]: loss 15.480744
[epoch10, step2736]: loss 0.869855
[epoch10, step2737]: loss 10.585730
[epoch10, step2738]: loss 5.218517
[epoch10, step2739]: loss 3.144763
[epoch10, step2740]: loss 9.186285
[epoch10, step2741]: loss 1.294029
[epoch10, step2742]: loss 5.550810
[epoch10, step2743]: loss 8.002036
[epoch10, step2744]: loss 2.110152
[epoch10, step2745]: loss 2.021074
[epoch10, step2746]: loss 1.304904
[epoch10, step2747]: loss 21.490175
[epoch10, step2748]: loss 1.702011
[epoch10, step2749]: loss 1.974712
[epoch10, step2750]: loss 3.738340
[epoch10, step2751]: loss 6.315858
[epoch10, step2752]: loss 10.132560
[epoch10, step2753]: loss 9.524420
[epoch10, step2754]: loss 2.405320
[epoch10, step2755]: loss 2.079138
[epoch10, step2756]: loss 5.547143
[epoch10, step2757]: loss 19.227507
[epoch10, step2758]: loss 1.549180
[epoch10, step2759]: loss 24.627878
[epoch10, step2760]: loss 10.302097
[epoch10, step2761]: loss 1.059131
[epoch10, step2762]: loss 2.740817
[epoch10, step2763]: loss 1.471496
[epoch10, step2764]: loss 10.067413
[epoch10, step2765]: loss 5.272976
[epoch10, step2766]: loss 3.733796
[epoch10, step2767]: loss 2.155050
[epoch10, step2768]: loss 1.691359
[epoch10, step2769]: loss 1.210398
[epoch10, step2770]: loss 10.161182
[epoch10, step2771]: loss 15.939281
[epoch10, step2772]: loss 1.116844
[epoch10, step2773]: loss 1.309282
[epoch10, step2774]: loss 1.382359
[epoch10, step2775]: loss 4.904342
[epoch10, step2776]: loss 11.869284
[epoch10, step2777]: loss 11.627743
[epoch10, step2778]: loss 13.559014
[epoch10, step2779]: loss 2.305152
[epoch10, step2780]: loss 3.256067
[epoch10, step2781]: loss 2.112499
[epoch10, step2782]: loss 3.408073
[epoch10, step2783]: loss 1.044952
[epoch10, step2784]: loss 1.122753
[epoch10, step2785]: loss 0.624352
[epoch10, step2786]: loss 2.068310
[epoch10, step2787]: loss 1.117690
[epoch10, step2788]: loss 2.143109
[epoch10, step2789]: loss 3.255982
[epoch10, step2790]: loss 1.231479
[epoch10, step2791]: loss 0.850119
[epoch10, step2792]: loss 4.791330
[epoch10, step2793]: loss 13.475206
[epoch10, step2794]: loss 1.433519
[epoch10, step2795]: loss 5.985926
[epoch10, step2796]: loss 10.423551
[epoch10, step2797]: loss 1.810345
[epoch10, step2798]: loss 7.561879
[epoch10, step2799]: loss 13.739902
[epoch10, step2800]: loss 7.025033
[epoch10, step2801]: loss 0.913494
[epoch10, step2802]: loss 9.258128
[epoch10, step2803]: loss 2.380186
[epoch10, step2804]: loss 14.287599
[epoch10, step2805]: loss 10.134466
[epoch10, step2806]: loss 1.842560
[epoch10, step2807]: loss 2.537055
[epoch10, step2808]: loss 1.166896
[epoch10, step2809]: loss 3.282437
[epoch10, step2810]: loss 3.648438
[epoch10, step2811]: loss 1.585742
[epoch10, step2812]: loss 12.504450
[epoch10, step2813]: loss 1.843752
[epoch10, step2814]: loss 1.900519
[epoch10, step2815]: loss 10.620360
[epoch10, step2816]: loss 1.421720
[epoch10, step2817]: loss 21.793491
[epoch10, step2818]: loss 1.481506
[epoch10, step2819]: loss 5.072664
[epoch10, step2820]: loss 5.201923
[epoch10, step2821]: loss 3.752793
[epoch10, step2822]: loss 1.076699
[epoch10, step2823]: loss 4.265927
[epoch10, step2824]: loss 12.428967
[epoch10, step2825]: loss 1.012007
[epoch10, step2826]: loss 13.432656
[epoch10, step2827]: loss 11.587740
[epoch10, step2828]: loss 1.684601
[epoch10, step2829]: loss 8.650651
[epoch10, step2830]: loss 2.321715
[epoch10, step2831]: loss 7.995835
[epoch10, step2832]: loss 10.008868
[epoch10, step2833]: loss 1.032572
[epoch10, step2834]: loss 12.101221
[epoch10, step2835]: loss 3.314726
[epoch10, step2836]: loss 0.964597
[epoch10, step2837]: loss 1.155775
[epoch10, step2838]: loss 3.431885
[epoch10, step2839]: loss 2.015357
[epoch10, step2840]: loss 1.154127
[epoch10, step2841]: loss 6.842615
[epoch10, step2842]: loss 2.377879
[epoch10, step2843]: loss 10.232067
[epoch10, step2844]: loss 4.853159
[epoch10, step2845]: loss 9.233240
[epoch10, step2846]: loss 9.965207
[epoch10, step2847]: loss 11.100437
[epoch10, step2848]: loss 0.776545
[epoch10, step2849]: loss 1.657605
[epoch10, step2850]: loss 1.331737
[epoch10, step2851]: loss 8.646291
[epoch10, step2852]: loss 10.362729
[epoch10, step2853]: loss 1.288150
[epoch10, step2854]: loss 0.939427
[epoch10, step2855]: loss 7.491556
[epoch10, step2856]: loss 2.641374
[epoch10, step2857]: loss 1.879941
[epoch10, step2858]: loss 1.701030
[epoch10, step2859]: loss 7.710731
[epoch10, step2860]: loss 5.117585
[epoch10, step2861]: loss 1.222551
[epoch10, step2862]: loss 2.069456
[epoch10, step2863]: loss 1.373035
[epoch10, step2864]: loss 8.985880
[epoch10, step2865]: loss 3.007403
[epoch10, step2866]: loss 20.552660
[epoch10, step2867]: loss 11.025777
[epoch10, step2868]: loss 9.867648
[epoch10, step2869]: loss 1.050399
[epoch10, step2870]: loss 10.199612
[epoch10, step2871]: loss 1.819904
[epoch10, step2872]: loss 9.689480
[epoch10, step2873]: loss 12.400917
[epoch10, step2874]: loss 1.905295
[epoch10, step2875]: loss 3.998046
[epoch10, step2876]: loss 2.147489
[epoch10, step2877]: loss 1.535264
[epoch10, step2878]: loss 5.099145
[epoch10, step2879]: loss 6.803992
[epoch10, step2880]: loss 1.603593
[epoch10, step2881]: loss 8.160871
[epoch10, step2882]: loss 2.098633
[epoch10, step2883]: loss 1.085384
[epoch10, step2884]: loss 0.750778
[epoch10, step2885]: loss 10.027776
[epoch10, step2886]: loss 16.899292
[epoch10, step2887]: loss 1.461462
[epoch10, step2888]: loss 6.931590
[epoch10, step2889]: loss 9.554375
[epoch10, step2890]: loss 1.452620
[epoch10, step2891]: loss 13.842507
[epoch10, step2892]: loss 6.878368
[epoch10, step2893]: loss 0.788984
[epoch10, step2894]: loss 4.198953
[epoch10, step2895]: loss 1.103229
[epoch10, step2896]: loss 1.854111
[epoch10, step2897]: loss 1.526794
[epoch10, step2898]: loss 1.281726
[epoch10, step2899]: loss 5.107121
[epoch10, step2900]: loss 6.562044
[epoch10, step2901]: loss 2.747659
[epoch10, step2902]: loss 9.544208
[epoch10, step2903]: loss 1.212739
[epoch10, step2904]: loss 22.881813
[epoch10, step2905]: loss 0.957843
[epoch10, step2906]: loss 1.529885
[epoch10, step2907]: loss 14.027825
[epoch10, step2908]: loss 1.385790
[epoch10, step2909]: loss 8.335517
[epoch10, step2910]: loss 16.889862
[epoch10, step2911]: loss 1.395301
[epoch10, step2912]: loss 8.452819
[epoch10, step2913]: loss 10.353545
[epoch10, step2914]: loss 1.299825
[epoch10, step2915]: loss 12.665578
[epoch10, step2916]: loss 15.866666
[epoch10, step2917]: loss 1.159800
[epoch10, step2918]: loss 4.111640
[epoch10, step2919]: loss 14.759975
[epoch10, step2920]: loss 5.052925
[epoch10, step2921]: loss 1.303393
[epoch10, step2922]: loss 8.787214
[epoch10, step2923]: loss 18.169100
[epoch10, step2924]: loss 2.453514
[epoch10, step2925]: loss 1.382890
[epoch10, step2926]: loss 0.957580
[epoch10, step2927]: loss 16.515335
[epoch10, step2928]: loss 4.882505
[epoch10, step2929]: loss 2.821084
[epoch10, step2930]: loss 10.060958
[epoch10, step2931]: loss 10.292738
[epoch10, step2932]: loss 1.175561
[epoch10, step2933]: loss 1.859123
[epoch10, step2934]: loss 3.390598
[epoch10, step2935]: loss 9.346500
[epoch10, step2936]: loss 5.158462
[epoch10, step2937]: loss 8.565483
[epoch10, step2938]: loss 11.920595
[epoch10, step2939]: loss 4.090780
[epoch10, step2940]: loss 18.447792
[epoch10, step2941]: loss 6.132248
[epoch10, step2942]: loss 1.377791
[epoch10, step2943]: loss 2.414376
[epoch10, step2944]: loss 2.414702
[epoch10, step2945]: loss 10.996635
[epoch10, step2946]: loss 3.182288
[epoch10, step2947]: loss 8.721013
[epoch10, step2948]: loss 1.726266
[epoch10, step2949]: loss 1.749883
[epoch10, step2950]: loss 1.478449
[epoch10, step2951]: loss 4.693591
[epoch10, step2952]: loss 3.194327
[epoch10, step2953]: loss 9.905041
[epoch10, step2954]: loss 1.706570
[epoch10, step2955]: loss 1.321540
[epoch10, step2956]: loss 2.135630
[epoch10, step2957]: loss 2.012358
[epoch10, step2958]: loss 0.880746
[epoch10, step2959]: loss 1.991222
[epoch10, step2960]: loss 1.076957
[epoch10, step2961]: loss 2.284220
[epoch10, step2962]: loss 1.039970
[epoch10, step2963]: loss 13.655059
[epoch10, step2964]: loss 12.073411
[epoch10, step2965]: loss 5.489975
[epoch10, step2966]: loss 1.243012
[epoch10, step2967]: loss 6.539558
[epoch10, step2968]: loss 11.643128
[epoch10, step2969]: loss 1.622271
[epoch10, step2970]: loss 13.533431
[epoch10, step2971]: loss 1.025833
[epoch10, step2972]: loss 2.405496
[epoch10, step2973]: loss 0.918846
[epoch10, step2974]: loss 0.887295
[epoch10, step2975]: loss 8.273250
[epoch10, step2976]: loss 0.999568
[epoch10, step2977]: loss 2.285292
[epoch10, step2978]: loss 1.166491
[epoch10, step2979]: loss 1.921852
[epoch10, step2980]: loss 1.257441
[epoch10, step2981]: loss 1.612684
[epoch10, step2982]: loss 1.912455
[epoch10, step2983]: loss 1.643433
[epoch10, step2984]: loss 1.800572
[epoch10, step2985]: loss 0.954322
[epoch10, step2986]: loss 1.363026
[epoch10, step2987]: loss 2.785931
[epoch10, step2988]: loss 1.508959
[epoch10, step2989]: loss 6.343663
[epoch10, step2990]: loss 2.576290
[epoch10, step2991]: loss 6.186010
[epoch10, step2992]: loss 2.125270
[epoch10, step2993]: loss 1.755647
[epoch10, step2994]: loss 9.579420
[epoch10, step2995]: loss 1.236388
[epoch10, step2996]: loss 3.091986
[epoch10, step2997]: loss 0.900319
[epoch10, step2998]: loss 18.125746
[epoch10, step2999]: loss 9.880670
[epoch10, step3000]: loss 1.798232
[epoch10, step3001]: loss 1.254276
[epoch10, step3002]: loss 2.070185
[epoch10, step3003]: loss 2.335912
[epoch10, step3004]: loss 2.385492
[epoch10, step3005]: loss 1.409283
[epoch10, step3006]: loss 7.859400
[epoch10, step3007]: loss 3.125013
[epoch10, step3008]: loss 1.504575
[epoch10, step3009]: loss 11.095414
[epoch10, step3010]: loss 1.795510
[epoch10, step3011]: loss 4.943006
[epoch10, step3012]: loss 1.414429
[epoch10, step3013]: loss 6.047934
[epoch10, step3014]: loss 15.944608
[epoch10, step3015]: loss 2.635836
[epoch10, step3016]: loss 6.094662
[epoch10, step3017]: loss 1.728707
[epoch10, step3018]: loss 1.616472
[epoch10, step3019]: loss 6.198678
[epoch10, step3020]: loss 4.886288
[epoch10, step3021]: loss 6.425214
[epoch10, step3022]: loss 1.357397
[epoch10, step3023]: loss 2.206123
[epoch10, step3024]: loss 1.722304
[epoch10, step3025]: loss 4.789479
[epoch10, step3026]: loss 2.350667
[epoch10, step3027]: loss 2.092091
[epoch10, step3028]: loss 5.081770
[epoch10, step3029]: loss 4.899514
[epoch10, step3030]: loss 5.277352
[epoch10, step3031]: loss 11.323814
[epoch10, step3032]: loss 2.450042
[epoch10, step3033]: loss 1.523168
[epoch10, step3034]: loss 12.809319
[epoch10, step3035]: loss 16.722166
[epoch10, step3036]: loss 1.217269
[epoch10, step3037]: loss 1.515357
[epoch10, step3038]: loss 4.566855
[epoch10, step3039]: loss 3.265202
[epoch10, step3040]: loss 8.037846
[epoch10, step3041]: loss 14.953192
[epoch10, step3042]: loss 1.672694
[epoch10, step3043]: loss 1.255057
[epoch10, step3044]: loss 3.548724
[epoch10, step3045]: loss 17.321934
[epoch10, step3046]: loss 1.094034
[epoch10, step3047]: loss 12.523232
[epoch10, step3048]: loss 14.455201
[epoch10, step3049]: loss 0.719862
[epoch10, step3050]: loss 12.210474
[epoch10, step3051]: loss 12.962949
[epoch10, step3052]: loss 6.540951
[epoch10, step3053]: loss 1.332991
[epoch10, step3054]: loss 1.137088
[epoch10, step3055]: loss 2.932540
[epoch10, step3056]: loss 2.482924
[epoch10, step3057]: loss 2.975009
[epoch10, step3058]: loss 13.931489
[epoch10, step3059]: loss 3.735993
[epoch10, step3060]: loss 2.517711
[epoch10, step3061]: loss 12.953697
[epoch10, step3062]: loss 2.662337
[epoch10, step3063]: loss 2.389544
[epoch10, step3064]: loss 2.481746
[epoch10, step3065]: loss 2.434070
[epoch10, step3066]: loss 1.328746
[epoch10, step3067]: loss 5.542065
[epoch10, step3068]: loss 5.904540
[epoch10, step3069]: loss 7.717778
[epoch10, step3070]: loss 1.201995
[epoch10, step3071]: loss 3.700300
[epoch10, step3072]: loss 11.346882
[epoch10, step3073]: loss 2.193740
[epoch10, step3074]: loss 1.434154
[epoch10, step3075]: loss 5.321934
[epoch10, step3076]: loss 3.295793

[epoch10]: avg loss 3.295793

[epoch11, step1]: loss 1.547637
[epoch11, step2]: loss 0.989328
[epoch11, step3]: loss 6.245643
[epoch11, step4]: loss 1.052768
[epoch11, step5]: loss 1.001777
[epoch11, step6]: loss 1.536595
[epoch11, step7]: loss 17.437757
[epoch11, step8]: loss 1.174484
[epoch11, step9]: loss 10.083085
[epoch11, step10]: loss 1.164410
[epoch11, step11]: loss 1.865079
[epoch11, step12]: loss 1.424690
[epoch11, step13]: loss 1.485613
[epoch11, step14]: loss 2.442875
[epoch11, step15]: loss 12.620304
[epoch11, step16]: loss 12.528339
[epoch11, step17]: loss 1.493015
[epoch11, step18]: loss 11.115479
[epoch11, step19]: loss 1.067725
[epoch11, step20]: loss 3.013479
[epoch11, step21]: loss 4.273657
[epoch11, step22]: loss 1.728877
[epoch11, step23]: loss 0.948315
[epoch11, step24]: loss 2.820614
[epoch11, step25]: loss 5.755428
[epoch11, step26]: loss 2.129369
[epoch11, step27]: loss 1.099542
[epoch11, step28]: loss 3.045528
[epoch11, step29]: loss 8.549625
[epoch11, step30]: loss 3.065171
[epoch11, step31]: loss 0.998249
[epoch11, step32]: loss 2.436224
[epoch11, step33]: loss 11.379217
[epoch11, step34]: loss 5.250784
[epoch11, step35]: loss 14.911833
[epoch11, step36]: loss 8.007520
[epoch11, step37]: loss 6.728073
[epoch11, step38]: loss 2.282552
[epoch11, step39]: loss 8.198177
[epoch11, step40]: loss 10.027999
[epoch11, step41]: loss 3.829848
[epoch11, step42]: loss 2.254472
[epoch11, step43]: loss 1.301933
[epoch11, step44]: loss 3.646324
[epoch11, step45]: loss 17.018616
[epoch11, step46]: loss 1.628681
[epoch11, step47]: loss 1.567892
[epoch11, step48]: loss 1.736126
[epoch11, step49]: loss 0.961803
[epoch11, step50]: loss 1.287065
[epoch11, step51]: loss 1.310968
[epoch11, step52]: loss 1.327377
[epoch11, step53]: loss 2.655221
[epoch11, step54]: loss 1.897755
[epoch11, step55]: loss 2.799801
[epoch11, step56]: loss 2.838867
[epoch11, step57]: loss 2.763805
[epoch11, step58]: loss 3.115506
[epoch11, step59]: loss 0.903330
[epoch11, step60]: loss 3.829659
[epoch11, step61]: loss 6.791629
[epoch11, step62]: loss 0.976599
[epoch11, step63]: loss 1.203213
[epoch11, step64]: loss 2.385300
[epoch11, step65]: loss 0.780304
[epoch11, step66]: loss 3.315873
[epoch11, step67]: loss 1.413717
[epoch11, step68]: loss 15.300182
[epoch11, step69]: loss 1.428914
[epoch11, step70]: loss 5.036385
[epoch11, step71]: loss 1.453315
[epoch11, step72]: loss 2.390745
[epoch11, step73]: loss 13.076941
[epoch11, step74]: loss 7.777173
[epoch11, step75]: loss 2.085997
[epoch11, step76]: loss 12.479220
[epoch11, step77]: loss 12.172855
[epoch11, step78]: loss 1.207679
[epoch11, step79]: loss 1.369343
[epoch11, step80]: loss 7.429428
[epoch11, step81]: loss 1.817388
[epoch11, step82]: loss 0.783804
[epoch11, step83]: loss 1.669398
[epoch11, step84]: loss 5.507281
[epoch11, step85]: loss 13.965113
[epoch11, step86]: loss 1.485944
[epoch11, step87]: loss 13.053624
[epoch11, step88]: loss 13.308318
[epoch11, step89]: loss 1.819686
[epoch11, step90]: loss 16.370417
[epoch11, step91]: loss 2.028512
[epoch11, step92]: loss 4.036600
[epoch11, step93]: loss 11.213597
[epoch11, step94]: loss 2.542176
[epoch11, step95]: loss 1.584170
[epoch11, step96]: loss 8.581347
[epoch11, step97]: loss 0.648965
[epoch11, step98]: loss 1.223369
[epoch11, step99]: loss 1.935213
[epoch11, step100]: loss 0.916271
[epoch11, step101]: loss 2.482905
[epoch11, step102]: loss 2.164741
[epoch11, step103]: loss 10.552565
[epoch11, step104]: loss 1.864705
[epoch11, step105]: loss 1.029498
[epoch11, step106]: loss 4.102096
[epoch11, step107]: loss 0.879033
[epoch11, step108]: loss 4.222450
[epoch11, step109]: loss 1.218932
[epoch11, step110]: loss 5.401747
[epoch11, step111]: loss 7.256514
[epoch11, step112]: loss 1.270505
[epoch11, step113]: loss 1.821704
[epoch11, step114]: loss 3.095783
[epoch11, step115]: loss 3.880299
[epoch11, step116]: loss 2.186887
[epoch11, step117]: loss 2.909878
[epoch11, step118]: loss 6.699016
[epoch11, step119]: loss 1.896368
[epoch11, step120]: loss 1.542428
[epoch11, step121]: loss 14.064011
[epoch11, step122]: loss 2.805348
[epoch11, step123]: loss 1.271699
[epoch11, step124]: loss 1.030006
[epoch11, step125]: loss 9.406611
[epoch11, step126]: loss 9.213573
[epoch11, step127]: loss 10.317009
[epoch11, step128]: loss 0.931976
[epoch11, step129]: loss 1.222112
[epoch11, step130]: loss 7.626115
[epoch11, step131]: loss 8.139743
[epoch11, step132]: loss 9.047983
[epoch11, step133]: loss 9.010050
[epoch11, step134]: loss 1.198173
[epoch11, step135]: loss 14.195014
[epoch11, step136]: loss 1.237698
[epoch11, step137]: loss 1.119259
[epoch11, step138]: loss 1.682318
[epoch11, step139]: loss 3.163996
[epoch11, step140]: loss 1.115153
[epoch11, step141]: loss 3.903576
[epoch11, step142]: loss 3.865661
[epoch11, step143]: loss 11.668463
[epoch11, step144]: loss 4.364752
[epoch11, step145]: loss 0.864963
[epoch11, step146]: loss 4.844563
[epoch11, step147]: loss 1.102132
[epoch11, step148]: loss 2.229564
[epoch11, step149]: loss 1.422946
[epoch11, step150]: loss 1.246607
[epoch11, step151]: loss 1.259743
[epoch11, step152]: loss 9.483504
[epoch11, step153]: loss 2.458865
[epoch11, step154]: loss 5.973785
[epoch11, step155]: loss 0.996384
[epoch11, step156]: loss 1.345092
[epoch11, step157]: loss 2.312353
[epoch11, step158]: loss 2.810218
[epoch11, step159]: loss 3.295249
[epoch11, step160]: loss 1.739368
[epoch11, step161]: loss 11.952826
[epoch11, step162]: loss 1.517442
[epoch11, step163]: loss 2.185598
[epoch11, step164]: loss 18.979647
[epoch11, step165]: loss 1.287653
[epoch11, step166]: loss 1.559597
[epoch11, step167]: loss 10.534064
[epoch11, step168]: loss 4.719948
[epoch11, step169]: loss 1.106475
[epoch11, step170]: loss 1.227888
[epoch11, step171]: loss 0.581759
[epoch11, step172]: loss 1.872237
[epoch11, step173]: loss 9.389583
[epoch11, step174]: loss 3.010443
[epoch11, step175]: loss 1.044363
[epoch11, step176]: loss 2.202274
[epoch11, step177]: loss 1.318610
[epoch11, step178]: loss 1.176886
[epoch11, step179]: loss 1.196841
[epoch11, step180]: loss 16.136616
[epoch11, step181]: loss 12.772398
[epoch11, step182]: loss 7.834448
[epoch11, step183]: loss 7.045220
[epoch11, step184]: loss 1.429089
[epoch11, step185]: loss 2.040199
[epoch11, step186]: loss 3.536033
[epoch11, step187]: loss 22.707684
[epoch11, step188]: loss 1.795158
[epoch11, step189]: loss 2.924637
[epoch11, step190]: loss 1.347433
[epoch11, step191]: loss 4.260207
[epoch11, step192]: loss 2.588273
[epoch11, step193]: loss 1.102033
[epoch11, step194]: loss 24.897530
[epoch11, step195]: loss 1.113219
[epoch11, step196]: loss 6.217462
[epoch11, step197]: loss 1.409545
[epoch11, step198]: loss 6.927074
[epoch11, step199]: loss 2.119694
[epoch11, step200]: loss 16.873146
[epoch11, step201]: loss 12.360078
[epoch11, step202]: loss 13.374418
[epoch11, step203]: loss 2.935664
[epoch11, step204]: loss 8.527528
[epoch11, step205]: loss 8.399043
[epoch11, step206]: loss 9.530794
[epoch11, step207]: loss 8.181222
[epoch11, step208]: loss 12.391109
[epoch11, step209]: loss 7.066496
[epoch11, step210]: loss 5.308672
[epoch11, step211]: loss 9.369377
[epoch11, step212]: loss 0.912963
[epoch11, step213]: loss 2.164952
[epoch11, step214]: loss 12.234825
[epoch11, step215]: loss 0.788212
[epoch11, step216]: loss 2.682399
[epoch11, step217]: loss 7.183328
[epoch11, step218]: loss 9.094363
[epoch11, step219]: loss 2.054430
[epoch11, step220]: loss 8.138096
[epoch11, step221]: loss 1.116663
[epoch11, step222]: loss 1.031501
[epoch11, step223]: loss 1.428507
[epoch11, step224]: loss 7.731542
[epoch11, step225]: loss 1.961399
[epoch11, step226]: loss 2.148131
[epoch11, step227]: loss 2.554871
[epoch11, step228]: loss 7.570280
[epoch11, step229]: loss 14.329405
[epoch11, step230]: loss 2.030872
[epoch11, step231]: loss 7.480723
[epoch11, step232]: loss 1.788528
[epoch11, step233]: loss 1.585410
[epoch11, step234]: loss 10.746647
[epoch11, step235]: loss 7.640237
[epoch11, step236]: loss 0.943053
[epoch11, step237]: loss 1.250719
[epoch11, step238]: loss 2.122729
[epoch11, step239]: loss 1.082462
[epoch11, step240]: loss 6.916117
[epoch11, step241]: loss 2.958731
[epoch11, step242]: loss 8.529662
[epoch11, step243]: loss 11.677566
[epoch11, step244]: loss 1.205504
[epoch11, step245]: loss 1.148035
[epoch11, step246]: loss 1.468120
[epoch11, step247]: loss 1.475479
[epoch11, step248]: loss 3.134693
[epoch11, step249]: loss 13.877803
[epoch11, step250]: loss 1.145922
[epoch11, step251]: loss 5.637777
[epoch11, step252]: loss 1.986801
[epoch11, step253]: loss 1.767324
[epoch11, step254]: loss 0.899992
[epoch11, step255]: loss 10.222931
[epoch11, step256]: loss 1.383259
[epoch11, step257]: loss 0.900232
[epoch11, step258]: loss 9.903894
[epoch11, step259]: loss 2.138074
[epoch11, step260]: loss 3.313946
[epoch11, step261]: loss 4.479702
[epoch11, step262]: loss 0.931165
[epoch11, step263]: loss 1.442919
[epoch11, step264]: loss 1.215319
[epoch11, step265]: loss 2.909894
[epoch11, step266]: loss 1.309862
[epoch11, step267]: loss 9.866843
[epoch11, step268]: loss 1.552546
[epoch11, step269]: loss 2.424187
[epoch11, step270]: loss 0.843637
[epoch11, step271]: loss 0.899688
[epoch11, step272]: loss 1.172027
[epoch11, step273]: loss 1.878237
[epoch11, step274]: loss 1.093767
[epoch11, step275]: loss 1.282808
[epoch11, step276]: loss 2.021569
[epoch11, step277]: loss 17.267256
[epoch11, step278]: loss 1.896075
[epoch11, step279]: loss 1.209589
[epoch11, step280]: loss 1.505744
[epoch11, step281]: loss 4.373513
[epoch11, step282]: loss 1.130488
[epoch11, step283]: loss 1.584555
[epoch11, step284]: loss 9.073861
[epoch11, step285]: loss 8.464942
[epoch11, step286]: loss 1.041094
[epoch11, step287]: loss 4.285548
[epoch11, step288]: loss 1.925935
[epoch11, step289]: loss 1.725789
[epoch11, step290]: loss 9.863621
[epoch11, step291]: loss 1.422769
[epoch11, step292]: loss 0.863747
[epoch11, step293]: loss 8.836237
[epoch11, step294]: loss 19.148029
[epoch11, step295]: loss 4.000889
[epoch11, step296]: loss 23.114578
[epoch11, step297]: loss 4.409989
[epoch11, step298]: loss 26.011486
[epoch11, step299]: loss 1.459272
[epoch11, step300]: loss 2.089535
[epoch11, step301]: loss 1.622218
[epoch11, step302]: loss 1.539603
[epoch11, step303]: loss 3.053097
[epoch11, step304]: loss 0.949946
[epoch11, step305]: loss 5.230601
[epoch11, step306]: loss 25.346100
[epoch11, step307]: loss 8.326981
[epoch11, step308]: loss 1.997065
[epoch11, step309]: loss 8.348866
[epoch11, step310]: loss 7.256850
[epoch11, step311]: loss 1.500514
[epoch11, step312]: loss 1.407252
[epoch11, step313]: loss 3.856271
[epoch11, step314]: loss 2.627015
[epoch11, step315]: loss 2.457042
[epoch11, step316]: loss 1.059946
[epoch11, step317]: loss 2.211438
[epoch11, step318]: loss 2.007964
[epoch11, step319]: loss 2.094843
[epoch11, step320]: loss 11.099733
[epoch11, step321]: loss 2.068673
[epoch11, step322]: loss 12.385482
[epoch11, step323]: loss 0.636400
[epoch11, step324]: loss 1.830533
[epoch11, step325]: loss 1.027910
[epoch11, step326]: loss 1.806554
[epoch11, step327]: loss 7.638742
[epoch11, step328]: loss 10.173101
[epoch11, step329]: loss 7.964962
[epoch11, step330]: loss 9.578516
[epoch11, step331]: loss 4.097559
[epoch11, step332]: loss 2.517691
[epoch11, step333]: loss 10.303082
[epoch11, step334]: loss 2.112654
[epoch11, step335]: loss 1.198174
[epoch11, step336]: loss 0.802887
[epoch11, step337]: loss 5.616337
[epoch11, step338]: loss 3.000523
[epoch11, step339]: loss 9.694686
[epoch11, step340]: loss 8.709624
[epoch11, step341]: loss 6.292719
[epoch11, step342]: loss 1.335881
[epoch11, step343]: loss 1.168159
[epoch11, step344]: loss 1.550737
[epoch11, step345]: loss 1.509593
[epoch11, step346]: loss 2.374451
[epoch11, step347]: loss 2.577817
[epoch11, step348]: loss 1.742980
[epoch11, step349]: loss 7.299483
[epoch11, step350]: loss 0.897904
[epoch11, step351]: loss 3.087022
[epoch11, step352]: loss 4.686399
[epoch11, step353]: loss 9.453731
[epoch11, step354]: loss 13.666803
[epoch11, step355]: loss 1.262152
[epoch11, step356]: loss 1.911632
[epoch11, step357]: loss 6.100799
[epoch11, step358]: loss 5.931479
[epoch11, step359]: loss 0.995635
[epoch11, step360]: loss 1.962086
[epoch11, step361]: loss 4.727110
[epoch11, step362]: loss 1.200765
[epoch11, step363]: loss 1.066690
[epoch11, step364]: loss 9.387422
[epoch11, step365]: loss 3.340361
[epoch11, step366]: loss 10.858946
[epoch11, step367]: loss 14.148536
[epoch11, step368]: loss 13.393469
[epoch11, step369]: loss 2.671587
[epoch11, step370]: loss 13.718654
[epoch11, step371]: loss 2.582717
[epoch11, step372]: loss 10.648746
[epoch11, step373]: loss 2.633230
[epoch11, step374]: loss 1.894477
[epoch11, step375]: loss 4.095661
[epoch11, step376]: loss 12.753130
[epoch11, step377]: loss 4.419332
[epoch11, step378]: loss 18.579628
[epoch11, step379]: loss 10.068741
[epoch11, step380]: loss 2.141512
[epoch11, step381]: loss 2.898274
[epoch11, step382]: loss 12.091990
[epoch11, step383]: loss 1.306028
[epoch11, step384]: loss 0.959697
[epoch11, step385]: loss 6.782242
[epoch11, step386]: loss 1.019671
[epoch11, step387]: loss 7.868062
[epoch11, step388]: loss 5.231110
[epoch11, step389]: loss 1.470185
[epoch11, step390]: loss 3.180246
[epoch11, step391]: loss 10.590045
[epoch11, step392]: loss 0.769812
[epoch11, step393]: loss 9.138210
[epoch11, step394]: loss 8.455467
[epoch11, step395]: loss 2.116060
[epoch11, step396]: loss 25.880619
[epoch11, step397]: loss 5.200470
[epoch11, step398]: loss 1.624946
[epoch11, step399]: loss 2.053874
[epoch11, step400]: loss 15.355205
[epoch11, step401]: loss 1.382540
[epoch11, step402]: loss 1.454552
[epoch11, step403]: loss 23.527676
[epoch11, step404]: loss 2.933926
[epoch11, step405]: loss 1.142944
[epoch11, step406]: loss 1.481240
[epoch11, step407]: loss 3.331631
[epoch11, step408]: loss 4.317049
[epoch11, step409]: loss 1.239854
[epoch11, step410]: loss 1.095065
[epoch11, step411]: loss 1.042748
[epoch11, step412]: loss 1.287608
[epoch11, step413]: loss 1.661162
[epoch11, step414]: loss 4.011588
[epoch11, step415]: loss 3.346133
[epoch11, step416]: loss 1.185391
[epoch11, step417]: loss 1.147964
[epoch11, step418]: loss 1.216635
[epoch11, step419]: loss 5.381859
[epoch11, step420]: loss 1.150724
[epoch11, step421]: loss 5.742336
[epoch11, step422]: loss 10.641393
[epoch11, step423]: loss 0.773381
[epoch11, step424]: loss 5.519808
[epoch11, step425]: loss 1.475348
[epoch11, step426]: loss 0.832519
[epoch11, step427]: loss 6.368172
[epoch11, step428]: loss 10.735520
[epoch11, step429]: loss 1.788610
[epoch11, step430]: loss 2.373642
[epoch11, step431]: loss 4.093285
[epoch11, step432]: loss 32.887730
[epoch11, step433]: loss 1.445631
[epoch11, step434]: loss 12.444305
[epoch11, step435]: loss 0.867634
[epoch11, step436]: loss 1.310465
[epoch11, step437]: loss 12.583873
[epoch11, step438]: loss 5.048626
[epoch11, step439]: loss 1.580691
[epoch11, step440]: loss 1.578188
[epoch11, step441]: loss 9.385522
[epoch11, step442]: loss 2.677011
[epoch11, step443]: loss 8.682112
[epoch11, step444]: loss 5.665982
[epoch11, step445]: loss 1.306902
[epoch11, step446]: loss 3.160082
[epoch11, step447]: loss 1.982876
[epoch11, step448]: loss 14.253025
[epoch11, step449]: loss 6.167860
[epoch11, step450]: loss 1.106722
[epoch11, step451]: loss 7.722628
[epoch11, step452]: loss 2.075601
[epoch11, step453]: loss 13.100698
[epoch11, step454]: loss 1.884565
[epoch11, step455]: loss 1.745670
[epoch11, step456]: loss 10.479581
[epoch11, step457]: loss 4.531425
[epoch11, step458]: loss 3.154023
[epoch11, step459]: loss 1.058864
[epoch11, step460]: loss 5.011840
[epoch11, step461]: loss 2.392738
[epoch11, step462]: loss 4.732438
[epoch11, step463]: loss 4.788055
[epoch11, step464]: loss 2.174494
[epoch11, step465]: loss 1.760869
[epoch11, step466]: loss 2.555704
[epoch11, step467]: loss 6.513839
[epoch11, step468]: loss 0.989763
[epoch11, step469]: loss 17.989399
[epoch11, step470]: loss 3.354458
[epoch11, step471]: loss 1.860820
[epoch11, step472]: loss 10.959027
[epoch11, step473]: loss 1.326829
[epoch11, step474]: loss 1.631566
[epoch11, step475]: loss 18.296297
[epoch11, step476]: loss 2.957787
[epoch11, step477]: loss 2.025888
[epoch11, step478]: loss 0.652872
[epoch11, step479]: loss 2.326122
[epoch11, step480]: loss 9.059892
[epoch11, step481]: loss 7.940337
[epoch11, step482]: loss 2.439642
[epoch11, step483]: loss 3.374753
[epoch11, step484]: loss 9.359931
[epoch11, step485]: loss 1.740963
[epoch11, step486]: loss 2.321953
[epoch11, step487]: loss 6.711075
[epoch11, step488]: loss 17.742353
[epoch11, step489]: loss 1.097538
[epoch11, step490]: loss 8.880898
[epoch11, step491]: loss 3.174624
[epoch11, step492]: loss 22.436308
[epoch11, step493]: loss 9.563530
[epoch11, step494]: loss 8.057229
[epoch11, step495]: loss 13.757558
[epoch11, step496]: loss 2.214441
[epoch11, step497]: loss 1.453957
[epoch11, step498]: loss 2.591422
[epoch11, step499]: loss 15.039058
[epoch11, step500]: loss 0.899711
[epoch11, step501]: loss 1.251246
[epoch11, step502]: loss 13.875891
[epoch11, step503]: loss 11.659552
[epoch11, step504]: loss 0.984727
[epoch11, step505]: loss 5.174894
[epoch11, step506]: loss 1.582836
[epoch11, step507]: loss 1.084108
[epoch11, step508]: loss 16.387800
[epoch11, step509]: loss 1.732335
[epoch11, step510]: loss 4.641429
[epoch11, step511]: loss 3.050491
[epoch11, step512]: loss 1.965276
[epoch11, step513]: loss 2.217870
[epoch11, step514]: loss 9.364805
[epoch11, step515]: loss 2.835393
[epoch11, step516]: loss 2.493594
[epoch11, step517]: loss 6.221495
[epoch11, step518]: loss 2.920993
[epoch11, step519]: loss 3.137135
[epoch11, step520]: loss 9.407357
[epoch11, step521]: loss 11.402048
[epoch11, step522]: loss 14.583707
[epoch11, step523]: loss 4.419412
[epoch11, step524]: loss 7.256103
[epoch11, step525]: loss 3.549825
[epoch11, step526]: loss 12.602394
[epoch11, step527]: loss 9.789248
[epoch11, step528]: loss 2.009199
[epoch11, step529]: loss 5.757555
[epoch11, step530]: loss 1.201358
[epoch11, step531]: loss 0.937325
[epoch11, step532]: loss 5.583486
[epoch11, step533]: loss 19.945734
[epoch11, step534]: loss 8.031957
[epoch11, step535]: loss 2.641775
[epoch11, step536]: loss 4.541722
[epoch11, step537]: loss 6.896310
[epoch11, step538]: loss 4.488949
[epoch11, step539]: loss 0.797907
[epoch11, step540]: loss 4.875260
[epoch11, step541]: loss 2.248107
[epoch11, step542]: loss 14.757421
[epoch11, step543]: loss 3.301852
[epoch11, step544]: loss 0.675030
[epoch11, step545]: loss 2.117616
[epoch11, step546]: loss 10.922534
[epoch11, step547]: loss 6.190579
[epoch11, step548]: loss 1.232464
[epoch11, step549]: loss 16.994452
[epoch11, step550]: loss 0.675307
[epoch11, step551]: loss 4.972080
[epoch11, step552]: loss 2.559602
[epoch11, step553]: loss 0.835565
[epoch11, step554]: loss 2.579390
[epoch11, step555]: loss 1.060833
[epoch11, step556]: loss 2.462950
[epoch11, step557]: loss 17.831615
[epoch11, step558]: loss 1.575772
[epoch11, step559]: loss 12.175303
[epoch11, step560]: loss 2.308306
[epoch11, step561]: loss 1.469573
[epoch11, step562]: loss 0.780140
[epoch11, step563]: loss 17.889872
[epoch11, step564]: loss 2.030942
[epoch11, step565]: loss 1.963591
[epoch11, step566]: loss 0.603420
[epoch11, step567]: loss 0.726804
[epoch11, step568]: loss 7.210241
[epoch11, step569]: loss 10.554825
[epoch11, step570]: loss 1.196423
[epoch11, step571]: loss 3.814088
[epoch11, step572]: loss 1.435528
[epoch11, step573]: loss 8.731468
[epoch11, step574]: loss 1.054454
[epoch11, step575]: loss 19.887491
[epoch11, step576]: loss 4.998395
[epoch11, step577]: loss 0.821563
[epoch11, step578]: loss 1.988859
[epoch11, step579]: loss 1.690974
[epoch11, step580]: loss 7.872563
[epoch11, step581]: loss 8.372082
[epoch11, step582]: loss 2.008581
[epoch11, step583]: loss 10.026896
[epoch11, step584]: loss 5.219701
[epoch11, step585]: loss 6.353179
[epoch11, step586]: loss 15.854943
[epoch11, step587]: loss 4.692275
[epoch11, step588]: loss 1.074786
[epoch11, step589]: loss 8.723959
[epoch11, step590]: loss 10.459144
[epoch11, step591]: loss 2.182055
[epoch11, step592]: loss 3.023642
[epoch11, step593]: loss 1.110228
[epoch11, step594]: loss 1.293383
[epoch11, step595]: loss 1.262825
[epoch11, step596]: loss 1.712710
[epoch11, step597]: loss 1.099416
[epoch11, step598]: loss 17.881987
[epoch11, step599]: loss 11.622073
[epoch11, step600]: loss 7.587549
[epoch11, step601]: loss 3.162470
[epoch11, step602]: loss 1.883242
[epoch11, step603]: loss 2.464303
[epoch11, step604]: loss 1.170986
[epoch11, step605]: loss 1.294250
[epoch11, step606]: loss 1.578558
[epoch11, step607]: loss 1.332542
[epoch11, step608]: loss 1.929135
[epoch11, step609]: loss 1.821502
[epoch11, step610]: loss 1.769661
[epoch11, step611]: loss 2.359707
[epoch11, step612]: loss 6.171154
[epoch11, step613]: loss 1.155597
[epoch11, step614]: loss 4.252870
[epoch11, step615]: loss 1.131469
[epoch11, step616]: loss 1.445221
[epoch11, step617]: loss 2.999713
[epoch11, step618]: loss 1.845268
[epoch11, step619]: loss 5.505162
[epoch11, step620]: loss 10.651526
[epoch11, step621]: loss 3.080955
[epoch11, step622]: loss 1.776564
[epoch11, step623]: loss 1.912225
[epoch11, step624]: loss 1.511739
[epoch11, step625]: loss 2.368825
[epoch11, step626]: loss 2.338129
[epoch11, step627]: loss 21.889950
[epoch11, step628]: loss 1.651787
[epoch11, step629]: loss 1.512260
[epoch11, step630]: loss 2.567023
[epoch11, step631]: loss 1.087961
[epoch11, step632]: loss 2.182130
[epoch11, step633]: loss 2.653677
[epoch11, step634]: loss 1.612208
[epoch11, step635]: loss 1.172032
[epoch11, step636]: loss 3.625973
[epoch11, step637]: loss 1.010444
[epoch11, step638]: loss 9.335497
[epoch11, step639]: loss 3.149962
[epoch11, step640]: loss 3.470456
[epoch11, step641]: loss 2.668346
[epoch11, step642]: loss 1.221693
[epoch11, step643]: loss 0.996230
[epoch11, step644]: loss 2.050290
[epoch11, step645]: loss 7.357348
[epoch11, step646]: loss 19.455242
[epoch11, step647]: loss 1.229838
[epoch11, step648]: loss 9.618989
[epoch11, step649]: loss 1.626477
[epoch11, step650]: loss 8.853086
[epoch11, step651]: loss 1.717734
[epoch11, step652]: loss 1.157277
[epoch11, step653]: loss 2.026742
[epoch11, step654]: loss 2.622868
[epoch11, step655]: loss 1.648120
[epoch11, step656]: loss 1.895299
[epoch11, step657]: loss 1.727855
[epoch11, step658]: loss 9.845805
[epoch11, step659]: loss 21.809118
[epoch11, step660]: loss 1.679639
[epoch11, step661]: loss 4.024589
[epoch11, step662]: loss 4.877486
[epoch11, step663]: loss 0.763166
[epoch11, step664]: loss 1.625529
[epoch11, step665]: loss 3.020496
[epoch11, step666]: loss 5.923517
[epoch11, step667]: loss 13.192312
[epoch11, step668]: loss 2.683714
[epoch11, step669]: loss 15.216160
[epoch11, step670]: loss 1.337644
[epoch11, step671]: loss 3.500123
[epoch11, step672]: loss 9.717464
[epoch11, step673]: loss 1.866998
[epoch11, step674]: loss 9.496341
[epoch11, step675]: loss 1.307444
[epoch11, step676]: loss 1.045807
[epoch11, step677]: loss 1.866890
[epoch11, step678]: loss 6.557817
[epoch11, step679]: loss 9.009173
[epoch11, step680]: loss 9.587959
[epoch11, step681]: loss 1.466562
[epoch11, step682]: loss 3.412452
[epoch11, step683]: loss 7.681491
[epoch11, step684]: loss 1.547973
[epoch11, step685]: loss 2.922215
[epoch11, step686]: loss 3.013694
[epoch11, step687]: loss 2.593101
[epoch11, step688]: loss 2.201555
[epoch11, step689]: loss 4.874262
[epoch11, step690]: loss 6.928658
[epoch11, step691]: loss 1.931788
[epoch11, step692]: loss 1.045268
[epoch11, step693]: loss 3.685802
[epoch11, step694]: loss 1.876072
[epoch11, step695]: loss 1.376258
[epoch11, step696]: loss 1.200760
[epoch11, step697]: loss 9.171046
[epoch11, step698]: loss 14.261074
[epoch11, step699]: loss 2.277369
[epoch11, step700]: loss 11.907528
[epoch11, step701]: loss 14.553644
[epoch11, step702]: loss 1.368226
[epoch11, step703]: loss 7.796077
[epoch11, step704]: loss 13.318361
[epoch11, step705]: loss 1.221391
[epoch11, step706]: loss 2.193119
[epoch11, step707]: loss 0.814035
[epoch11, step708]: loss 1.188493
[epoch11, step709]: loss 2.681599
[epoch11, step710]: loss 1.634603
[epoch11, step711]: loss 5.715976
[epoch11, step712]: loss 1.269433
[epoch11, step713]: loss 2.071269
[epoch11, step714]: loss 19.938818
[epoch11, step715]: loss 1.977725
[epoch11, step716]: loss 1.703943
[epoch11, step717]: loss 1.274493
[epoch11, step718]: loss 2.253031
[epoch11, step719]: loss 3.871182
[epoch11, step720]: loss 0.804578
[epoch11, step721]: loss 2.867657
[epoch11, step722]: loss 1.855622
[epoch11, step723]: loss 1.993085
[epoch11, step724]: loss 1.040744
[epoch11, step725]: loss 1.003800
[epoch11, step726]: loss 0.885467
[epoch11, step727]: loss 3.554893
[epoch11, step728]: loss 9.547919
[epoch11, step729]: loss 1.994797
[epoch11, step730]: loss 2.171882
[epoch11, step731]: loss 1.724585
[epoch11, step732]: loss 19.661087
[epoch11, step733]: loss 4.641135
[epoch11, step734]: loss 5.581608
[epoch11, step735]: loss 20.911905
[epoch11, step736]: loss 3.509489
[epoch11, step737]: loss 0.934604
[epoch11, step738]: loss 3.734117
[epoch11, step739]: loss 1.111152
[epoch11, step740]: loss 5.824750
[epoch11, step741]: loss 5.326850
[epoch11, step742]: loss 2.813224
[epoch11, step743]: loss 3.847858
[epoch11, step744]: loss 1.914127
[epoch11, step745]: loss 14.419963
[epoch11, step746]: loss 6.464523
[epoch11, step747]: loss 1.626307
[epoch11, step748]: loss 0.937391
[epoch11, step749]: loss 1.179237
[epoch11, step750]: loss 12.144187
[epoch11, step751]: loss 5.705374
[epoch11, step752]: loss 9.617160
[epoch11, step753]: loss 6.025848
[epoch11, step754]: loss 17.632423
[epoch11, step755]: loss 10.761478
[epoch11, step756]: loss 11.284514
[epoch11, step757]: loss 13.990090
[epoch11, step758]: loss 2.762923
[epoch11, step759]: loss 1.312679
[epoch11, step760]: loss 2.304370
[epoch11, step761]: loss 1.215490
[epoch11, step762]: loss 10.689384
[epoch11, step763]: loss 1.991030
[epoch11, step764]: loss 1.077451
[epoch11, step765]: loss 2.146411
[epoch11, step766]: loss 1.909607
[epoch11, step767]: loss 1.174219
[epoch11, step768]: loss 9.987563
[epoch11, step769]: loss 10.708901
[epoch11, step770]: loss 11.300543
[epoch11, step771]: loss 1.619182
[epoch11, step772]: loss 4.978004
[epoch11, step773]: loss 8.028799
[epoch11, step774]: loss 19.352646
[epoch11, step775]: loss 1.434345
[epoch11, step776]: loss 9.661836
[epoch11, step777]: loss 16.359934
[epoch11, step778]: loss 3.356828
[epoch11, step779]: loss 1.046017
[epoch11, step780]: loss 1.684007
[epoch11, step781]: loss 8.200875
[epoch11, step782]: loss 1.668175
[epoch11, step783]: loss 1.900034
[epoch11, step784]: loss 5.811064
[epoch11, step785]: loss 2.029466
[epoch11, step786]: loss 9.451328
[epoch11, step787]: loss 9.613014
[epoch11, step788]: loss 6.099489
[epoch11, step789]: loss 1.223065
[epoch11, step790]: loss 1.216133
[epoch11, step791]: loss 2.496887
[epoch11, step792]: loss 1.240628
[epoch11, step793]: loss 18.301651
[epoch11, step794]: loss 2.814711
[epoch11, step795]: loss 1.346807
[epoch11, step796]: loss 1.739007
[epoch11, step797]: loss 14.643334
[epoch11, step798]: loss 1.388393
[epoch11, step799]: loss 0.811715
[epoch11, step800]: loss 1.484076
[epoch11, step801]: loss 1.932159
[epoch11, step802]: loss 9.847279
[epoch11, step803]: loss 13.547750
[epoch11, step804]: loss 18.034077
[epoch11, step805]: loss 1.092682
[epoch11, step806]: loss 1.635178
[epoch11, step807]: loss 13.753861
[epoch11, step808]: loss 18.043188
[epoch11, step809]: loss 0.876719
[epoch11, step810]: loss 1.516089
[epoch11, step811]: loss 2.290452
[epoch11, step812]: loss 3.376289
[epoch11, step813]: loss 2.132336
[epoch11, step814]: loss 3.238299
[epoch11, step815]: loss 1.055723
[epoch11, step816]: loss 1.290550
[epoch11, step817]: loss 4.387933
[epoch11, step818]: loss 1.132948
[epoch11, step819]: loss 1.234431
[epoch11, step820]: loss 3.325495
[epoch11, step821]: loss 4.271358
[epoch11, step822]: loss 1.332450
[epoch11, step823]: loss 10.227272
[epoch11, step824]: loss 15.806230
[epoch11, step825]: loss 1.326758
[epoch11, step826]: loss 1.402898
[epoch11, step827]: loss 6.141742
[epoch11, step828]: loss 8.738942
[epoch11, step829]: loss 1.201712
[epoch11, step830]: loss 4.246523
[epoch11, step831]: loss 9.323821
[epoch11, step832]: loss 0.803194
[epoch11, step833]: loss 2.745797
[epoch11, step834]: loss 2.281579
[epoch11, step835]: loss 1.490884
[epoch11, step836]: loss 0.867491
[epoch11, step837]: loss 2.563099
[epoch11, step838]: loss 5.575010
[epoch11, step839]: loss 1.111399
[epoch11, step840]: loss 3.220139
[epoch11, step841]: loss 1.562733
[epoch11, step842]: loss 3.907530
[epoch11, step843]: loss 1.318981
[epoch11, step844]: loss 1.214409
[epoch11, step845]: loss 5.716389
[epoch11, step846]: loss 1.375451
[epoch11, step847]: loss 15.730344
[epoch11, step848]: loss 1.031893
[epoch11, step849]: loss 0.496753
[epoch11, step850]: loss 1.082630
[epoch11, step851]: loss 1.648070
[epoch11, step852]: loss 12.792068
[epoch11, step853]: loss 1.373838
[epoch11, step854]: loss 2.439096
[epoch11, step855]: loss 1.415387
[epoch11, step856]: loss 2.133384
[epoch11, step857]: loss 2.325905
[epoch11, step858]: loss 2.041975
[epoch11, step859]: loss 0.929175
[epoch11, step860]: loss 4.158921
[epoch11, step861]: loss 1.783854
[epoch11, step862]: loss 16.414957
[epoch11, step863]: loss 3.292322
[epoch11, step864]: loss 1.815248
[epoch11, step865]: loss 2.368652
[epoch11, step866]: loss 1.475805
[epoch11, step867]: loss 8.227393
[epoch11, step868]: loss 3.107237
[epoch11, step869]: loss 1.669366
[epoch11, step870]: loss 2.298356
[epoch11, step871]: loss 3.119429
[epoch11, step872]: loss 18.222082
[epoch11, step873]: loss 1.111734
[epoch11, step874]: loss 1.149824
[epoch11, step875]: loss 1.459538
[epoch11, step876]: loss 14.051281
[epoch11, step877]: loss 3.413471
[epoch11, step878]: loss 2.521707
[epoch11, step879]: loss 8.105212
[epoch11, step880]: loss 5.599348
[epoch11, step881]: loss 1.296194
[epoch11, step882]: loss 9.740976
[epoch11, step883]: loss 9.558195
[epoch11, step884]: loss 1.279696
[epoch11, step885]: loss 0.813861
[epoch11, step886]: loss 1.404315
[epoch11, step887]: loss 1.608917
[epoch11, step888]: loss 2.706450
[epoch11, step889]: loss 7.635715
[epoch11, step890]: loss 3.217556
[epoch11, step891]: loss 9.560900
[epoch11, step892]: loss 1.432558
[epoch11, step893]: loss 2.182736
[epoch11, step894]: loss 1.966597
[epoch11, step895]: loss 1.867279
[epoch11, step896]: loss 1.448240
[epoch11, step897]: loss 1.994649
[epoch11, step898]: loss 1.445261
[epoch11, step899]: loss 9.274546
[epoch11, step900]: loss 15.162428
[epoch11, step901]: loss 15.660232
[epoch11, step902]: loss 1.126383
[epoch11, step903]: loss 0.849311
[epoch11, step904]: loss 2.149745
[epoch11, step905]: loss 15.145079
[epoch11, step906]: loss 1.502030
[epoch11, step907]: loss 1.774367
[epoch11, step908]: loss 4.263254
[epoch11, step909]: loss 1.865772
[epoch11, step910]: loss 3.156883
[epoch11, step911]: loss 9.990520
[epoch11, step912]: loss 0.672808
[epoch11, step913]: loss 0.805969
[epoch11, step914]: loss 11.253980
[epoch11, step915]: loss 1.538951
[epoch11, step916]: loss 1.174546
[epoch11, step917]: loss 4.229181
[epoch11, step918]: loss 1.929448
[epoch11, step919]: loss 1.309345
[epoch11, step920]: loss 3.773191
[epoch11, step921]: loss 2.645605
[epoch11, step922]: loss 2.108509
[epoch11, step923]: loss 5.087196
[epoch11, step924]: loss 1.576733
[epoch11, step925]: loss 10.931553
[epoch11, step926]: loss 6.003965
[epoch11, step927]: loss 9.125847
[epoch11, step928]: loss 2.039850
[epoch11, step929]: loss 4.530260
[epoch11, step930]: loss 3.200954
[epoch11, step931]: loss 10.226394
[epoch11, step932]: loss 15.488235
[epoch11, step933]: loss 9.630900
[epoch11, step934]: loss 8.913511
[epoch11, step935]: loss 1.596963
[epoch11, step936]: loss 0.980943
[epoch11, step937]: loss 11.348892
[epoch11, step938]: loss 10.874841
[epoch11, step939]: loss 1.178218
[epoch11, step940]: loss 9.531051
[epoch11, step941]: loss 1.163236
[epoch11, step942]: loss 1.662819
[epoch11, step943]: loss 0.753914
[epoch11, step944]: loss 1.633101
[epoch11, step945]: loss 9.349709
[epoch11, step946]: loss 1.397537
[epoch11, step947]: loss 6.884622
[epoch11, step948]: loss 3.971082
[epoch11, step949]: loss 0.742242
[epoch11, step950]: loss 1.611225
[epoch11, step951]: loss 4.075257
[epoch11, step952]: loss 0.810098
[epoch11, step953]: loss 5.403026
[epoch11, step954]: loss 1.746810
[epoch11, step955]: loss 9.445446
[epoch11, step956]: loss 1.956503
[epoch11, step957]: loss 9.664423
[epoch11, step958]: loss 12.469550
[epoch11, step959]: loss 3.883739
[epoch11, step960]: loss 4.018848
[epoch11, step961]: loss 1.324718
[epoch11, step962]: loss 9.455903
[epoch11, step963]: loss 2.312476
[epoch11, step964]: loss 13.282027
[epoch11, step965]: loss 0.970744
[epoch11, step966]: loss 1.535224
[epoch11, step967]: loss 4.029568
[epoch11, step968]: loss 1.617407
[epoch11, step969]: loss 2.128601
[epoch11, step970]: loss 10.863390
[epoch11, step971]: loss 3.259387
[epoch11, step972]: loss 7.872201
[epoch11, step973]: loss 1.153011
[epoch11, step974]: loss 8.271893
[epoch11, step975]: loss 9.785767
[epoch11, step976]: loss 11.244801
[epoch11, step977]: loss 0.817170
[epoch11, step978]: loss 1.719451
[epoch11, step979]: loss 1.590171
[epoch11, step980]: loss 12.451756
[epoch11, step981]: loss 13.648898
[epoch11, step982]: loss 17.286394
[epoch11, step983]: loss 1.475173
[epoch11, step984]: loss 3.323830
[epoch11, step985]: loss 13.607595
[epoch11, step986]: loss 10.028653
[epoch11, step987]: loss 2.007005
[epoch11, step988]: loss 11.163787
[epoch11, step989]: loss 3.569295
[epoch11, step990]: loss 2.467932
[epoch11, step991]: loss 1.595580
[epoch11, step992]: loss 1.271188
[epoch11, step993]: loss 4.218454
[epoch11, step994]: loss 2.325310
[epoch11, step995]: loss 9.901587
[epoch11, step996]: loss 12.498486
[epoch11, step997]: loss 1.790720
[epoch11, step998]: loss 0.995400
[epoch11, step999]: loss 4.658123
[epoch11, step1000]: loss 1.229416
[epoch11, step1001]: loss 1.029345
[epoch11, step1002]: loss 0.805739
[epoch11, step1003]: loss 1.534521
[epoch11, step1004]: loss 3.031089
[epoch11, step1005]: loss 9.329506
[epoch11, step1006]: loss 8.667709
[epoch11, step1007]: loss 1.550648
[epoch11, step1008]: loss 2.394242
[epoch11, step1009]: loss 1.052066
[epoch11, step1010]: loss 1.338744
[epoch11, step1011]: loss 20.283150
[epoch11, step1012]: loss 2.354631
[epoch11, step1013]: loss 6.238949
[epoch11, step1014]: loss 10.261768
[epoch11, step1015]: loss 5.493260
[epoch11, step1016]: loss 0.685322
[epoch11, step1017]: loss 15.285597
[epoch11, step1018]: loss 2.146255
[epoch11, step1019]: loss 1.126930
[epoch11, step1020]: loss 2.717044
[epoch11, step1021]: loss 2.077808
[epoch11, step1022]: loss 2.788070
[epoch11, step1023]: loss 2.365322
[epoch11, step1024]: loss 21.020254
[epoch11, step1025]: loss 2.037196
[epoch11, step1026]: loss 9.589882
[epoch11, step1027]: loss 6.698107
[epoch11, step1028]: loss 13.473827
[epoch11, step1029]: loss 0.720565
[epoch11, step1030]: loss 0.882243
[epoch11, step1031]: loss 6.273555
[epoch11, step1032]: loss 1.483032
[epoch11, step1033]: loss 6.032479
[epoch11, step1034]: loss 0.869708
[epoch11, step1035]: loss 2.337941
[epoch11, step1036]: loss 1.271542
[epoch11, step1037]: loss 1.818905
[epoch11, step1038]: loss 1.378236
[epoch11, step1039]: loss 1.774927
[epoch11, step1040]: loss 3.324113
[epoch11, step1041]: loss 10.960005
[epoch11, step1042]: loss 1.911098
[epoch11, step1043]: loss 2.769293
[epoch11, step1044]: loss 1.984060
[epoch11, step1045]: loss 23.546219
[epoch11, step1046]: loss 14.496457
[epoch11, step1047]: loss 4.167116
[epoch11, step1048]: loss 1.467769
[epoch11, step1049]: loss 5.492170
[epoch11, step1050]: loss 2.672857
[epoch11, step1051]: loss 8.886419
[epoch11, step1052]: loss 1.960496
[epoch11, step1053]: loss 10.050030
[epoch11, step1054]: loss 1.012656
[epoch11, step1055]: loss 7.033741
[epoch11, step1056]: loss 3.616044
[epoch11, step1057]: loss 2.927769
[epoch11, step1058]: loss 1.804142
[epoch11, step1059]: loss 1.880130
[epoch11, step1060]: loss 2.540830
[epoch11, step1061]: loss 5.305229
[epoch11, step1062]: loss 7.230552
[epoch11, step1063]: loss 2.158366
[epoch11, step1064]: loss 1.243446
[epoch11, step1065]: loss 1.266900
[epoch11, step1066]: loss 3.529541
[epoch11, step1067]: loss 0.979940
[epoch11, step1068]: loss 2.333751
[epoch11, step1069]: loss 7.779740
[epoch11, step1070]: loss 15.030015
[epoch11, step1071]: loss 6.424620
[epoch11, step1072]: loss 4.661940
[epoch11, step1073]: loss 12.357656
[epoch11, step1074]: loss 10.185242
[epoch11, step1075]: loss 13.146029
[epoch11, step1076]: loss 1.262283
[epoch11, step1077]: loss 16.762766
[epoch11, step1078]: loss 6.475141
[epoch11, step1079]: loss 2.744788
[epoch11, step1080]: loss 1.147214
[epoch11, step1081]: loss 5.903368
[epoch11, step1082]: loss 15.097964
[epoch11, step1083]: loss 9.795017
[epoch11, step1084]: loss 1.498759
[epoch11, step1085]: loss 3.640474
[epoch11, step1086]: loss 1.427109
[epoch11, step1087]: loss 1.410753
[epoch11, step1088]: loss 0.828564
[epoch11, step1089]: loss 23.015163
[epoch11, step1090]: loss 1.755505
[epoch11, step1091]: loss 3.313683
[epoch11, step1092]: loss 3.024675
[epoch11, step1093]: loss 3.333490
[epoch11, step1094]: loss 2.609391
[epoch11, step1095]: loss 1.100007
[epoch11, step1096]: loss 2.006995
[epoch11, step1097]: loss 6.010023
[epoch11, step1098]: loss 9.781137
[epoch11, step1099]: loss 1.180901
[epoch11, step1100]: loss 1.508295
[epoch11, step1101]: loss 1.030980
[epoch11, step1102]: loss 15.874513
[epoch11, step1103]: loss 9.602357
[epoch11, step1104]: loss 1.819187
[epoch11, step1105]: loss 10.749251
[epoch11, step1106]: loss 1.947206
[epoch11, step1107]: loss 1.269381
[epoch11, step1108]: loss 1.325298
[epoch11, step1109]: loss 3.363179
[epoch11, step1110]: loss 2.064037
[epoch11, step1111]: loss 1.871089
[epoch11, step1112]: loss 2.480574
[epoch11, step1113]: loss 8.639402
[epoch11, step1114]: loss 19.831278
[epoch11, step1115]: loss 1.048635
[epoch11, step1116]: loss 7.852386
[epoch11, step1117]: loss 5.715399
[epoch11, step1118]: loss 2.329745
[epoch11, step1119]: loss 0.984430
[epoch11, step1120]: loss 1.887589
[epoch11, step1121]: loss 2.678183
[epoch11, step1122]: loss 2.210095
[epoch11, step1123]: loss 1.205706
[epoch11, step1124]: loss 9.012583
[epoch11, step1125]: loss 14.253377
[epoch11, step1126]: loss 1.389263
[epoch11, step1127]: loss 3.804430
[epoch11, step1128]: loss 1.300151
[epoch11, step1129]: loss 4.603133
[epoch11, step1130]: loss 1.163659
[epoch11, step1131]: loss 2.892518
[epoch11, step1132]: loss 0.951485
[epoch11, step1133]: loss 2.079375
[epoch11, step1134]: loss 0.957258
[epoch11, step1135]: loss 1.398165
[epoch11, step1136]: loss 3.007953
[epoch11, step1137]: loss 2.763260
[epoch11, step1138]: loss 6.634711
[epoch11, step1139]: loss 11.902216
[epoch11, step1140]: loss 8.277792
[epoch11, step1141]: loss 2.819310
[epoch11, step1142]: loss 1.796351
[epoch11, step1143]: loss 5.667918
[epoch11, step1144]: loss 12.918002
[epoch11, step1145]: loss 14.945468
[epoch11, step1146]: loss 10.938217
[epoch11, step1147]: loss 1.312351
[epoch11, step1148]: loss 0.689973
[epoch11, step1149]: loss 8.682913
[epoch11, step1150]: loss 2.717564
[epoch11, step1151]: loss 2.363047
[epoch11, step1152]: loss 12.882830
[epoch11, step1153]: loss 1.363930
[epoch11, step1154]: loss 1.786964
[epoch11, step1155]: loss 2.387986
[epoch11, step1156]: loss 20.977491
[epoch11, step1157]: loss 1.734783
[epoch11, step1158]: loss 4.921351
[epoch11, step1159]: loss 1.119546
[epoch11, step1160]: loss 1.156486
[epoch11, step1161]: loss 2.954762
[epoch11, step1162]: loss 1.421977
[epoch11, step1163]: loss 5.426669
[epoch11, step1164]: loss 5.700621
[epoch11, step1165]: loss 5.683353
[epoch11, step1166]: loss 1.112868
[epoch11, step1167]: loss 4.453569
[epoch11, step1168]: loss 8.105059
[epoch11, step1169]: loss 3.336528
[epoch11, step1170]: loss 6.399035
[epoch11, step1171]: loss 1.162964
[epoch11, step1172]: loss 5.475489
[epoch11, step1173]: loss 9.592816
[epoch11, step1174]: loss 8.872675
[epoch11, step1175]: loss 0.855557
[epoch11, step1176]: loss 1.809361
[epoch11, step1177]: loss 5.315192
[epoch11, step1178]: loss 3.268905
[epoch11, step1179]: loss 9.717406
[epoch11, step1180]: loss 2.480232
[epoch11, step1181]: loss 9.450931
[epoch11, step1182]: loss 15.138166
[epoch11, step1183]: loss 1.255714
[epoch11, step1184]: loss 5.919727
[epoch11, step1185]: loss 9.402120
[epoch11, step1186]: loss 1.143042
[epoch11, step1187]: loss 7.694126
[epoch11, step1188]: loss 7.472402
[epoch11, step1189]: loss 1.304166
[epoch11, step1190]: loss 1.289227
[epoch11, step1191]: loss 3.708723
[epoch11, step1192]: loss 16.618372
[epoch11, step1193]: loss 8.577161
[epoch11, step1194]: loss 1.351700
[epoch11, step1195]: loss 1.524426
[epoch11, step1196]: loss 1.919014
[epoch11, step1197]: loss 1.994877
[epoch11, step1198]: loss 2.091276
[epoch11, step1199]: loss 7.221189
[epoch11, step1200]: loss 5.841113
[epoch11, step1201]: loss 9.115135
[epoch11, step1202]: loss 6.834639
[epoch11, step1203]: loss 5.160690
[epoch11, step1204]: loss 11.914823
[epoch11, step1205]: loss 26.379198
[epoch11, step1206]: loss 7.468175
[epoch11, step1207]: loss 1.359606
[epoch11, step1208]: loss 9.800260
[epoch11, step1209]: loss 0.929354
[epoch11, step1210]: loss 3.460698
[epoch11, step1211]: loss 2.119606
[epoch11, step1212]: loss 2.096201
[epoch11, step1213]: loss 10.115713
[epoch11, step1214]: loss 4.863715
[epoch11, step1215]: loss 3.717278
[epoch11, step1216]: loss 4.248460
[epoch11, step1217]: loss 8.751554
[epoch11, step1218]: loss 3.666071
[epoch11, step1219]: loss 1.691495
[epoch11, step1220]: loss 9.740190
[epoch11, step1221]: loss 1.246430
[epoch11, step1222]: loss 3.951399
[epoch11, step1223]: loss 1.263215
[epoch11, step1224]: loss 1.146211
[epoch11, step1225]: loss 1.072853
[epoch11, step1226]: loss 13.428873
[epoch11, step1227]: loss 3.190542
[epoch11, step1228]: loss 1.253536
[epoch11, step1229]: loss 0.950554
[epoch11, step1230]: loss 0.717410
[epoch11, step1231]: loss 0.993207
[epoch11, step1232]: loss 8.027613
[epoch11, step1233]: loss 2.318146
[epoch11, step1234]: loss 3.408765
[epoch11, step1235]: loss 4.840416
[epoch11, step1236]: loss 1.403883
[epoch11, step1237]: loss 8.631968
[epoch11, step1238]: loss 1.728984
[epoch11, step1239]: loss 2.116969
[epoch11, step1240]: loss 1.041360
[epoch11, step1241]: loss 0.964721
[epoch11, step1242]: loss 4.362329
[epoch11, step1243]: loss 2.551399
[epoch11, step1244]: loss 1.272771
[epoch11, step1245]: loss 3.063155
[epoch11, step1246]: loss 19.477961
[epoch11, step1247]: loss 0.886011
[epoch11, step1248]: loss 2.002151
[epoch11, step1249]: loss 1.060983
[epoch11, step1250]: loss 2.786349
[epoch11, step1251]: loss 1.399459
[epoch11, step1252]: loss 2.045530
[epoch11, step1253]: loss 2.205841
[epoch11, step1254]: loss 1.014575
[epoch11, step1255]: loss 11.134295
[epoch11, step1256]: loss 11.375239
[epoch11, step1257]: loss 3.188875
[epoch11, step1258]: loss 1.928535
[epoch11, step1259]: loss 2.297610
[epoch11, step1260]: loss 6.085553
[epoch11, step1261]: loss 1.051798
[epoch11, step1262]: loss 11.748811
[epoch11, step1263]: loss 3.336729
[epoch11, step1264]: loss 1.377352
[epoch11, step1265]: loss 0.818679
[epoch11, step1266]: loss 3.638863
[epoch11, step1267]: loss 4.746753
[epoch11, step1268]: loss 4.893332
[epoch11, step1269]: loss 1.227222
[epoch11, step1270]: loss 1.724488
[epoch11, step1271]: loss 5.335328
[epoch11, step1272]: loss 2.525051
[epoch11, step1273]: loss 2.034117
[epoch11, step1274]: loss 1.678790
[epoch11, step1275]: loss 6.232524
[epoch11, step1276]: loss 2.057474
[epoch11, step1277]: loss 3.434495
[epoch11, step1278]: loss 1.548032
[epoch11, step1279]: loss 1.154240
[epoch11, step1280]: loss 2.310915
[epoch11, step1281]: loss 0.766084
[epoch11, step1282]: loss 1.583906
[epoch11, step1283]: loss 2.182236
[epoch11, step1284]: loss 17.213387
[epoch11, step1285]: loss 12.067154
[epoch11, step1286]: loss 2.532095
[epoch11, step1287]: loss 9.254274
[epoch11, step1288]: loss 10.903575
[epoch11, step1289]: loss 8.328155
[epoch11, step1290]: loss 4.504537
[epoch11, step1291]: loss 1.591928
[epoch11, step1292]: loss 3.101062
[epoch11, step1293]: loss 1.450059
[epoch11, step1294]: loss 3.940834
[epoch11, step1295]: loss 17.396305
[epoch11, step1296]: loss 0.872634
[epoch11, step1297]: loss 3.701322
[epoch11, step1298]: loss 3.839588
[epoch11, step1299]: loss 8.987789
[epoch11, step1300]: loss 2.554160
[epoch11, step1301]: loss 0.886577
[epoch11, step1302]: loss 1.760797
[epoch11, step1303]: loss 3.910248
[epoch11, step1304]: loss 15.529956
[epoch11, step1305]: loss 2.224375
[epoch11, step1306]: loss 2.245451
[epoch11, step1307]: loss 0.930841
[epoch11, step1308]: loss 2.321476
[epoch11, step1309]: loss 9.314258
[epoch11, step1310]: loss 1.010810
[epoch11, step1311]: loss 16.441181
[epoch11, step1312]: loss 3.267298
[epoch11, step1313]: loss 5.779155
[epoch11, step1314]: loss 1.405655
[epoch11, step1315]: loss 10.368676
[epoch11, step1316]: loss 1.208834
[epoch11, step1317]: loss 3.567352
[epoch11, step1318]: loss 6.396536
[epoch11, step1319]: loss 5.930945
[epoch11, step1320]: loss 1.630478
[epoch11, step1321]: loss 4.228630
[epoch11, step1322]: loss 1.381626
[epoch11, step1323]: loss 1.861347
[epoch11, step1324]: loss 5.320302
[epoch11, step1325]: loss 4.349385
[epoch11, step1326]: loss 0.848243
[epoch11, step1327]: loss 15.993751
[epoch11, step1328]: loss 2.298748
[epoch11, step1329]: loss 0.891236
[epoch11, step1330]: loss 2.373631
[epoch11, step1331]: loss 0.673319
[epoch11, step1332]: loss 2.296697
[epoch11, step1333]: loss 2.513718
[epoch11, step1334]: loss 9.528120
[epoch11, step1335]: loss 1.239723
[epoch11, step1336]: loss 1.056735
[epoch11, step1337]: loss 12.851639
[epoch11, step1338]: loss 2.358055
[epoch11, step1339]: loss 3.414891
[epoch11, step1340]: loss 11.058215
[epoch11, step1341]: loss 1.649903
[epoch11, step1342]: loss 6.476238
[epoch11, step1343]: loss 0.587559
[epoch11, step1344]: loss 3.147961
[epoch11, step1345]: loss 9.411350
[epoch11, step1346]: loss 9.584282
[epoch11, step1347]: loss 0.979164
[epoch11, step1348]: loss 3.917940
[epoch11, step1349]: loss 8.440320
[epoch11, step1350]: loss 2.081754
[epoch11, step1351]: loss 1.533564
[epoch11, step1352]: loss 6.487874
[epoch11, step1353]: loss 11.404175
[epoch11, step1354]: loss 0.929298
[epoch11, step1355]: loss 5.249688
[epoch11, step1356]: loss 1.405200
[epoch11, step1357]: loss 8.246482
[epoch11, step1358]: loss 1.439168
[epoch11, step1359]: loss 6.247221
[epoch11, step1360]: loss 6.480890
[epoch11, step1361]: loss 1.345596
[epoch11, step1362]: loss 7.071764
[epoch11, step1363]: loss 10.042878
[epoch11, step1364]: loss 1.956925
[epoch11, step1365]: loss 1.110616
[epoch11, step1366]: loss 8.047614
[epoch11, step1367]: loss 2.624951
[epoch11, step1368]: loss 1.029517
[epoch11, step1369]: loss 1.052134
[epoch11, step1370]: loss 1.392482
[epoch11, step1371]: loss 4.062720
[epoch11, step1372]: loss 2.051143
[epoch11, step1373]: loss 1.862058
[epoch11, step1374]: loss 1.753447
[epoch11, step1375]: loss 2.072614
[epoch11, step1376]: loss 1.919860
[epoch11, step1377]: loss 4.365526
[epoch11, step1378]: loss 1.805442
[epoch11, step1379]: loss 13.724003
[epoch11, step1380]: loss 10.344755
[epoch11, step1381]: loss 2.060416
[epoch11, step1382]: loss 4.755266
[epoch11, step1383]: loss 1.497959
[epoch11, step1384]: loss 1.783340
[epoch11, step1385]: loss 1.168464
[epoch11, step1386]: loss 1.093789
[epoch11, step1387]: loss 2.035029
[epoch11, step1388]: loss 6.837969
[epoch11, step1389]: loss 2.469391
[epoch11, step1390]: loss 2.472224
[epoch11, step1391]: loss 2.658730
[epoch11, step1392]: loss 1.610568
[epoch11, step1393]: loss 9.435207
[epoch11, step1394]: loss 4.504319
[epoch11, step1395]: loss 3.236202
[epoch11, step1396]: loss 1.405769
[epoch11, step1397]: loss 1.646392
[epoch11, step1398]: loss 4.013953
[epoch11, step1399]: loss 9.220242
[epoch11, step1400]: loss 1.764611
[epoch11, step1401]: loss 4.051658
[epoch11, step1402]: loss 1.942306
[epoch11, step1403]: loss 0.963251
[epoch11, step1404]: loss 0.868229
[epoch11, step1405]: loss 0.780832
[epoch11, step1406]: loss 1.384294
[epoch11, step1407]: loss 1.833171
[epoch11, step1408]: loss 8.564005
[epoch11, step1409]: loss 17.793541
[epoch11, step1410]: loss 1.225366
[epoch11, step1411]: loss 1.604187
[epoch11, step1412]: loss 2.215536
[epoch11, step1413]: loss 30.013147
[epoch11, step1414]: loss 8.660769
[epoch11, step1415]: loss 3.438393
[epoch11, step1416]: loss 5.974984
[epoch11, step1417]: loss 3.000953
[epoch11, step1418]: loss 7.697371
[epoch11, step1419]: loss 2.741267
[epoch11, step1420]: loss 1.354815
[epoch11, step1421]: loss 1.196824
[epoch11, step1422]: loss 10.115408
[epoch11, step1423]: loss 5.074197
[epoch11, step1424]: loss 2.958750
[epoch11, step1425]: loss 18.956181
[epoch11, step1426]: loss 8.754045
[epoch11, step1427]: loss 3.641799
[epoch11, step1428]: loss 11.667180
[epoch11, step1429]: loss 3.223142
[epoch11, step1430]: loss 1.127960
[epoch11, step1431]: loss 9.263910
[epoch11, step1432]: loss 0.838353
[epoch11, step1433]: loss 2.546245
[epoch11, step1434]: loss 1.786190
[epoch11, step1435]: loss 6.260718
[epoch11, step1436]: loss 0.988267
[epoch11, step1437]: loss 2.664910
[epoch11, step1438]: loss 7.110796
[epoch11, step1439]: loss 1.488434
[epoch11, step1440]: loss 1.215292
[epoch11, step1441]: loss 1.298957
[epoch11, step1442]: loss 1.371266
[epoch11, step1443]: loss 1.233000
[epoch11, step1444]: loss 1.006257
[epoch11, step1445]: loss 9.315145
[epoch11, step1446]: loss 1.149279
[epoch11, step1447]: loss 0.904129
[epoch11, step1448]: loss 0.850360
[epoch11, step1449]: loss 5.337698
[epoch11, step1450]: loss 0.592393
[epoch11, step1451]: loss 18.609472
[epoch11, step1452]: loss 7.575887
[epoch11, step1453]: loss 5.909727
[epoch11, step1454]: loss 9.930357
[epoch11, step1455]: loss 8.674973
[epoch11, step1456]: loss 1.701901
[epoch11, step1457]: loss 2.253930
[epoch11, step1458]: loss 1.321079
[epoch11, step1459]: loss 4.940644
[epoch11, step1460]: loss 1.051304
[epoch11, step1461]: loss 1.456534
[epoch11, step1462]: loss 2.709986
[epoch11, step1463]: loss 12.788710
[epoch11, step1464]: loss 0.879871
[epoch11, step1465]: loss 8.250497
[epoch11, step1466]: loss 1.129133
[epoch11, step1467]: loss 1.031733
[epoch11, step1468]: loss 1.135127
[epoch11, step1469]: loss 3.889161
[epoch11, step1470]: loss 15.909312
[epoch11, step1471]: loss 3.187637
[epoch11, step1472]: loss 4.323525
[epoch11, step1473]: loss 3.594597
[epoch11, step1474]: loss 1.421706
[epoch11, step1475]: loss 1.709424
[epoch11, step1476]: loss 2.700665
[epoch11, step1477]: loss 3.162466
[epoch11, step1478]: loss 4.262145
[epoch11, step1479]: loss 1.463720
[epoch11, step1480]: loss 13.202306
[epoch11, step1481]: loss 5.360013
[epoch11, step1482]: loss 13.034348
[epoch11, step1483]: loss 1.383361
[epoch11, step1484]: loss 3.620647
[epoch11, step1485]: loss 7.418044
[epoch11, step1486]: loss 13.063261
[epoch11, step1487]: loss 9.313988
[epoch11, step1488]: loss 9.860085
[epoch11, step1489]: loss 1.012368
[epoch11, step1490]: loss 1.232927
[epoch11, step1491]: loss 0.765076
[epoch11, step1492]: loss 1.334550
[epoch11, step1493]: loss 1.222205
[epoch11, step1494]: loss 1.723148
[epoch11, step1495]: loss 20.764408
[epoch11, step1496]: loss 9.891458
[epoch11, step1497]: loss 7.389148
[epoch11, step1498]: loss 6.667505
[epoch11, step1499]: loss 3.852560
[epoch11, step1500]: loss 1.206896
[epoch11, step1501]: loss 0.836611
[epoch11, step1502]: loss 1.507864
[epoch11, step1503]: loss 19.542196
[epoch11, step1504]: loss 11.521256
[epoch11, step1505]: loss 2.089606
[epoch11, step1506]: loss 1.316170
[epoch11, step1507]: loss 2.094513
[epoch11, step1508]: loss 1.068891
[epoch11, step1509]: loss 11.596991
[epoch11, step1510]: loss 12.946671
[epoch11, step1511]: loss 5.663443
[epoch11, step1512]: loss 2.184246
[epoch11, step1513]: loss 1.093147
[epoch11, step1514]: loss 13.011487
[epoch11, step1515]: loss 0.888137
[epoch11, step1516]: loss 8.486488
[epoch11, step1517]: loss 1.811353
[epoch11, step1518]: loss 2.947302
[epoch11, step1519]: loss 11.502400
[epoch11, step1520]: loss 2.544263
[epoch11, step1521]: loss 1.952332
[epoch11, step1522]: loss 9.627251
[epoch11, step1523]: loss 2.244026
[epoch11, step1524]: loss 6.521726
[epoch11, step1525]: loss 2.452132
[epoch11, step1526]: loss 0.960818
[epoch11, step1527]: loss 7.698020
[epoch11, step1528]: loss 11.301644
[epoch11, step1529]: loss 17.733332
[epoch11, step1530]: loss 2.226744
[epoch11, step1531]: loss 1.575177
[epoch11, step1532]: loss 1.809374
[epoch11, step1533]: loss 18.356312
[epoch11, step1534]: loss 17.661306
[epoch11, step1535]: loss 1.312654
[epoch11, step1536]: loss 1.779861
[epoch11, step1537]: loss 12.333060
[epoch11, step1538]: loss 1.280972
[epoch11, step1539]: loss 1.509920
[epoch11, step1540]: loss 0.992662
[epoch11, step1541]: loss 2.372695
[epoch11, step1542]: loss 2.403712
[epoch11, step1543]: loss 5.500604
[epoch11, step1544]: loss 2.393652
[epoch11, step1545]: loss 12.594634
[epoch11, step1546]: loss 2.081226
[epoch11, step1547]: loss 0.959249
[epoch11, step1548]: loss 4.733053
[epoch11, step1549]: loss 1.956871
[epoch11, step1550]: loss 3.690435
[epoch11, step1551]: loss 7.421942
[epoch11, step1552]: loss 8.091512
[epoch11, step1553]: loss 17.382338
[epoch11, step1554]: loss 8.408629
[epoch11, step1555]: loss 10.107874
[epoch11, step1556]: loss 5.024171
[epoch11, step1557]: loss 2.187129
[epoch11, step1558]: loss 18.528181
[epoch11, step1559]: loss 5.173246
[epoch11, step1560]: loss 3.073397
[epoch11, step1561]: loss 0.829414
[epoch11, step1562]: loss 18.200382
[epoch11, step1563]: loss 6.645281
[epoch11, step1564]: loss 0.618456
[epoch11, step1565]: loss 1.749277
[epoch11, step1566]: loss 1.295766
[epoch11, step1567]: loss 1.313490
[epoch11, step1568]: loss 7.592320
[epoch11, step1569]: loss 5.963430
[epoch11, step1570]: loss 3.157398
[epoch11, step1571]: loss 10.324751
[epoch11, step1572]: loss 1.194810
[epoch11, step1573]: loss 1.552143
[epoch11, step1574]: loss 2.627935
[epoch11, step1575]: loss 17.146130
[epoch11, step1576]: loss 15.765158
[epoch11, step1577]: loss 1.306050
[epoch11, step1578]: loss 2.726186
[epoch11, step1579]: loss 10.749136
[epoch11, step1580]: loss 8.894190
[epoch11, step1581]: loss 1.524103
[epoch11, step1582]: loss 1.514273
[epoch11, step1583]: loss 3.454494
[epoch11, step1584]: loss 1.885790
[epoch11, step1585]: loss 15.662307
[epoch11, step1586]: loss 0.870669
[epoch11, step1587]: loss 20.508898
[epoch11, step1588]: loss 3.705867
[epoch11, step1589]: loss 2.047804
[epoch11, step1590]: loss 1.517493
[epoch11, step1591]: loss 1.524758
[epoch11, step1592]: loss 1.720893
[epoch11, step1593]: loss 1.598414
[epoch11, step1594]: loss 10.386373
[epoch11, step1595]: loss 1.105464
[epoch11, step1596]: loss 7.977363
[epoch11, step1597]: loss 14.182004
[epoch11, step1598]: loss 1.911116
[epoch11, step1599]: loss 8.215120
[epoch11, step1600]: loss 11.588939
[epoch11, step1601]: loss 21.648214
[epoch11, step1602]: loss 2.032745
[epoch11, step1603]: loss 1.914335
[epoch11, step1604]: loss 2.554080
[epoch11, step1605]: loss 10.203282
[epoch11, step1606]: loss 5.825291
[epoch11, step1607]: loss 3.362942
[epoch11, step1608]: loss 2.983394
[epoch11, step1609]: loss 12.573746
[epoch11, step1610]: loss 1.383093
[epoch11, step1611]: loss 1.147007
[epoch11, step1612]: loss 9.782790
[epoch11, step1613]: loss 17.528284
[epoch11, step1614]: loss 21.250423
[epoch11, step1615]: loss 6.643618
[epoch11, step1616]: loss 8.710254
[epoch11, step1617]: loss 18.614445
[epoch11, step1618]: loss 6.074746
[epoch11, step1619]: loss 2.010432
[epoch11, step1620]: loss 1.537835
[epoch11, step1621]: loss 2.699047
[epoch11, step1622]: loss 1.691211
[epoch11, step1623]: loss 1.444939
[epoch11, step1624]: loss 9.159227
[epoch11, step1625]: loss 9.932958
[epoch11, step1626]: loss 1.647553
[epoch11, step1627]: loss 2.528533
[epoch11, step1628]: loss 2.076568
[epoch11, step1629]: loss 2.775567
[epoch11, step1630]: loss 12.490679
[epoch11, step1631]: loss 5.312431
[epoch11, step1632]: loss 0.671860
[epoch11, step1633]: loss 9.871179
[epoch11, step1634]: loss 2.101584
[epoch11, step1635]: loss 1.278418
[epoch11, step1636]: loss 3.493892
[epoch11, step1637]: loss 1.190588
[epoch11, step1638]: loss 8.074671
[epoch11, step1639]: loss 3.743355
[epoch11, step1640]: loss 1.878364
[epoch11, step1641]: loss 7.650866
[epoch11, step1642]: loss 12.920892
[epoch11, step1643]: loss 1.707547
[epoch11, step1644]: loss 23.140053
[epoch11, step1645]: loss 1.551028
[epoch11, step1646]: loss 12.772720
[epoch11, step1647]: loss 8.227395
[epoch11, step1648]: loss 2.821284
[epoch11, step1649]: loss 1.334560
[epoch11, step1650]: loss 1.756184
[epoch11, step1651]: loss 9.647867
[epoch11, step1652]: loss 1.987715
[epoch11, step1653]: loss 0.776417
[epoch11, step1654]: loss 8.198380
[epoch11, step1655]: loss 1.869008
[epoch11, step1656]: loss 0.979380
[epoch11, step1657]: loss 1.154004
[epoch11, step1658]: loss 2.899847
[epoch11, step1659]: loss 4.675167
[epoch11, step1660]: loss 1.070162
[epoch11, step1661]: loss 8.241216
[epoch11, step1662]: loss 7.949998
[epoch11, step1663]: loss 9.551947
[epoch11, step1664]: loss 8.059603
[epoch11, step1665]: loss 2.384662
[epoch11, step1666]: loss 7.674901
[epoch11, step1667]: loss 1.539461
[epoch11, step1668]: loss 30.507504
[epoch11, step1669]: loss 1.345767
[epoch11, step1670]: loss 5.682273
[epoch11, step1671]: loss 3.204193
[epoch11, step1672]: loss 15.007257
[epoch11, step1673]: loss 0.972028
[epoch11, step1674]: loss 2.283358
[epoch11, step1675]: loss 1.974652
[epoch11, step1676]: loss 7.950829
[epoch11, step1677]: loss 3.132767
[epoch11, step1678]: loss 1.256047
[epoch11, step1679]: loss 7.955812
[epoch11, step1680]: loss 1.561434
[epoch11, step1681]: loss 1.460975
[epoch11, step1682]: loss 9.595375
[epoch11, step1683]: loss 2.491430
[epoch11, step1684]: loss 10.203126
[epoch11, step1685]: loss 1.075813
[epoch11, step1686]: loss 2.613564
[epoch11, step1687]: loss 3.558052
[epoch11, step1688]: loss 2.054547
[epoch11, step1689]: loss 0.945077
[epoch11, step1690]: loss 1.226945
[epoch11, step1691]: loss 7.784698
[epoch11, step1692]: loss 4.249596
[epoch11, step1693]: loss 5.550363
[epoch11, step1694]: loss 1.825374
[epoch11, step1695]: loss 1.597422
[epoch11, step1696]: loss 2.190680
[epoch11, step1697]: loss 1.090790
[epoch11, step1698]: loss 1.930081
[epoch11, step1699]: loss 9.135975
[epoch11, step1700]: loss 1.307903
[epoch11, step1701]: loss 4.075881
[epoch11, step1702]: loss 2.451169
[epoch11, step1703]: loss 9.832282
[epoch11, step1704]: loss 10.819679
[epoch11, step1705]: loss 15.965146
[epoch11, step1706]: loss 4.699914
[epoch11, step1707]: loss 17.037939
[epoch11, step1708]: loss 11.300120
[epoch11, step1709]: loss 1.725684
[epoch11, step1710]: loss 3.104155
[epoch11, step1711]: loss 3.574836
[epoch11, step1712]: loss 1.130057
[epoch11, step1713]: loss 2.151357
[epoch11, step1714]: loss 3.681902
[epoch11, step1715]: loss 13.526857
[epoch11, step1716]: loss 5.997875
[epoch11, step1717]: loss 10.217020
[epoch11, step1718]: loss 1.008189
[epoch11, step1719]: loss 1.279413
[epoch11, step1720]: loss 4.570149
[epoch11, step1721]: loss 0.900544
[epoch11, step1722]: loss 1.080302
[epoch11, step1723]: loss 2.795598
[epoch11, step1724]: loss 1.603914
[epoch11, step1725]: loss 15.763966
[epoch11, step1726]: loss 1.605766
[epoch11, step1727]: loss 1.129423
[epoch11, step1728]: loss 5.371241
[epoch11, step1729]: loss 23.538723
[epoch11, step1730]: loss 2.357693
[epoch11, step1731]: loss 9.507987
[epoch11, step1732]: loss 3.414574
[epoch11, step1733]: loss 2.629827
[epoch11, step1734]: loss 2.150341
[epoch11, step1735]: loss 0.953496
[epoch11, step1736]: loss 1.595775
[epoch11, step1737]: loss 4.314479
[epoch11, step1738]: loss 1.639167
[epoch11, step1739]: loss 4.050480
[epoch11, step1740]: loss 1.561361
[epoch11, step1741]: loss 0.826851
[epoch11, step1742]: loss 0.825196
[epoch11, step1743]: loss 6.799863
[epoch11, step1744]: loss 3.578905
[epoch11, step1745]: loss 2.171877
[epoch11, step1746]: loss 9.690548
[epoch11, step1747]: loss 0.789044
[epoch11, step1748]: loss 1.082627
[epoch11, step1749]: loss 9.321498
[epoch11, step1750]: loss 2.950573
[epoch11, step1751]: loss 0.995815
[epoch11, step1752]: loss 8.326337
[epoch11, step1753]: loss 1.783432
[epoch11, step1754]: loss 1.957728
[epoch11, step1755]: loss 1.780626
[epoch11, step1756]: loss 9.760100
[epoch11, step1757]: loss 0.890572
[epoch11, step1758]: loss 2.618433
[epoch11, step1759]: loss 9.759060
[epoch11, step1760]: loss 1.293247
[epoch11, step1761]: loss 9.277196
[epoch11, step1762]: loss 1.521947
[epoch11, step1763]: loss 2.501707
[epoch11, step1764]: loss 6.700585
[epoch11, step1765]: loss 2.440596
[epoch11, step1766]: loss 0.803597
[epoch11, step1767]: loss 1.146463
[epoch11, step1768]: loss 6.623231
[epoch11, step1769]: loss 1.834163
[epoch11, step1770]: loss 1.090470
[epoch11, step1771]: loss 11.733288
[epoch11, step1772]: loss 3.008124
[epoch11, step1773]: loss 1.892292
[epoch11, step1774]: loss 12.280715
[epoch11, step1775]: loss 3.696330
[epoch11, step1776]: loss 1.904832
[epoch11, step1777]: loss 0.751163
[epoch11, step1778]: loss 10.851650
[epoch11, step1779]: loss 2.310980
[epoch11, step1780]: loss 2.188762
[epoch11, step1781]: loss 4.427947
[epoch11, step1782]: loss 18.849031
[epoch11, step1783]: loss 0.697624
[epoch11, step1784]: loss 1.324355
[epoch11, step1785]: loss 1.379777
[epoch11, step1786]: loss 2.498096
[epoch11, step1787]: loss 3.343460
[epoch11, step1788]: loss 8.866240
[epoch11, step1789]: loss 20.973841
[epoch11, step1790]: loss 1.342048
[epoch11, step1791]: loss 9.165692
[epoch11, step1792]: loss 0.985315
[epoch11, step1793]: loss 7.644164
[epoch11, step1794]: loss 0.849719
[epoch11, step1795]: loss 1.696876
[epoch11, step1796]: loss 3.702284
[epoch11, step1797]: loss 1.288733
[epoch11, step1798]: loss 1.450823
[epoch11, step1799]: loss 1.414110
[epoch11, step1800]: loss 6.892455
[epoch11, step1801]: loss 1.625463
[epoch11, step1802]: loss 12.607598
[epoch11, step1803]: loss 1.729861
[epoch11, step1804]: loss 6.671968
[epoch11, step1805]: loss 11.512776
[epoch11, step1806]: loss 2.996773
[epoch11, step1807]: loss 2.712421
[epoch11, step1808]: loss 1.448762
[epoch11, step1809]: loss 1.289484
[epoch11, step1810]: loss 15.441553
[epoch11, step1811]: loss 1.611365
[epoch11, step1812]: loss 1.279786
[epoch11, step1813]: loss 3.177067
[epoch11, step1814]: loss 1.037762
[epoch11, step1815]: loss 6.187422
[epoch11, step1816]: loss 2.842950
[epoch11, step1817]: loss 0.917753
[epoch11, step1818]: loss 0.642936
[epoch11, step1819]: loss 1.210396
[epoch11, step1820]: loss 4.137031
[epoch11, step1821]: loss 1.473167
[epoch11, step1822]: loss 5.798009
[epoch11, step1823]: loss 2.359440
[epoch11, step1824]: loss 3.562189
[epoch11, step1825]: loss 5.795405
[epoch11, step1826]: loss 10.531145
[epoch11, step1827]: loss 1.295872
[epoch11, step1828]: loss 27.787874
[epoch11, step1829]: loss 9.224120
[epoch11, step1830]: loss 7.149433
[epoch11, step1831]: loss 5.252994
[epoch11, step1832]: loss 11.374109
[epoch11, step1833]: loss 10.895378
[epoch11, step1834]: loss 1.670300
[epoch11, step1835]: loss 3.635177
[epoch11, step1836]: loss 2.095258
[epoch11, step1837]: loss 1.277666
[epoch11, step1838]: loss 1.167855
[epoch11, step1839]: loss 1.187967
[epoch11, step1840]: loss 11.544406
[epoch11, step1841]: loss 3.505681
[epoch11, step1842]: loss 7.160831
[epoch11, step1843]: loss 1.971146
[epoch11, step1844]: loss 5.165236
[epoch11, step1845]: loss 1.344204
[epoch11, step1846]: loss 3.027355
[epoch11, step1847]: loss 10.920681
[epoch11, step1848]: loss 1.957457
[epoch11, step1849]: loss 0.949561
[epoch11, step1850]: loss 6.358545
[epoch11, step1851]: loss 4.244594
[epoch11, step1852]: loss 2.030643
[epoch11, step1853]: loss 1.000687
[epoch11, step1854]: loss 1.105576
[epoch11, step1855]: loss 0.971679
[epoch11, step1856]: loss 2.454527
[epoch11, step1857]: loss 16.427620
[epoch11, step1858]: loss 1.219478
[epoch11, step1859]: loss 2.267691
[epoch11, step1860]: loss 0.929133
[epoch11, step1861]: loss 2.020387
[epoch11, step1862]: loss 0.767861
[epoch11, step1863]: loss 15.587448
[epoch11, step1864]: loss 1.570344
[epoch11, step1865]: loss 14.021906
[epoch11, step1866]: loss 1.048332
[epoch11, step1867]: loss 2.837147
[epoch11, step1868]: loss 1.310844
[epoch11, step1869]: loss 1.178075
[epoch11, step1870]: loss 10.249032
[epoch11, step1871]: loss 3.528908
[epoch11, step1872]: loss 13.177322
[epoch11, step1873]: loss 13.786567
[epoch11, step1874]: loss 9.647700
[epoch11, step1875]: loss 2.529803
[epoch11, step1876]: loss 3.916036
[epoch11, step1877]: loss 11.486544
[epoch11, step1878]: loss 14.803010
[epoch11, step1879]: loss 1.730270
[epoch11, step1880]: loss 3.238285
[epoch11, step1881]: loss 1.666038
[epoch11, step1882]: loss 7.753316
[epoch11, step1883]: loss 1.054832
[epoch11, step1884]: loss 1.448021
[epoch11, step1885]: loss 1.073364
[epoch11, step1886]: loss 3.023112
[epoch11, step1887]: loss 3.136008
[epoch11, step1888]: loss 1.254592
[epoch11, step1889]: loss 1.590274
[epoch11, step1890]: loss 2.357766
[epoch11, step1891]: loss 5.405114
[epoch11, step1892]: loss 3.054282
[epoch11, step1893]: loss 1.053553
[epoch11, step1894]: loss 3.033933
[epoch11, step1895]: loss 1.472271
[epoch11, step1896]: loss 13.576815
[epoch11, step1897]: loss 3.577923
[epoch11, step1898]: loss 2.481171
[epoch11, step1899]: loss 12.955594
[epoch11, step1900]: loss 1.141278
[epoch11, step1901]: loss 8.577436
[epoch11, step1902]: loss 2.190631
[epoch11, step1903]: loss 1.902985
[epoch11, step1904]: loss 2.691730
[epoch11, step1905]: loss 9.517304
[epoch11, step1906]: loss 1.415161
[epoch11, step1907]: loss 12.783093
[epoch11, step1908]: loss 1.844397
[epoch11, step1909]: loss 2.383878
[epoch11, step1910]: loss 7.727455
[epoch11, step1911]: loss 1.383287
[epoch11, step1912]: loss 1.801818
[epoch11, step1913]: loss 0.932221
[epoch11, step1914]: loss 1.471069
[epoch11, step1915]: loss 6.956779
[epoch11, step1916]: loss 5.908243
[epoch11, step1917]: loss 1.177453
[epoch11, step1918]: loss 2.133483
[epoch11, step1919]: loss 7.410567
[epoch11, step1920]: loss 2.154975
[epoch11, step1921]: loss 1.099941
[epoch11, step1922]: loss 1.133237
[epoch11, step1923]: loss 0.940514
[epoch11, step1924]: loss 1.480368
[epoch11, step1925]: loss 1.056143
[epoch11, step1926]: loss 1.039891
[epoch11, step1927]: loss 1.150098
[epoch11, step1928]: loss 14.733671
[epoch11, step1929]: loss 10.445295
[epoch11, step1930]: loss 1.193663
[epoch11, step1931]: loss 8.452553
[epoch11, step1932]: loss 2.761519
[epoch11, step1933]: loss 1.480133
[epoch11, step1934]: loss 2.046337
[epoch11, step1935]: loss 2.444771
[epoch11, step1936]: loss 3.449995
[epoch11, step1937]: loss 0.942648
[epoch11, step1938]: loss 1.498833
[epoch11, step1939]: loss 8.534737
[epoch11, step1940]: loss 4.165796
[epoch11, step1941]: loss 17.925213
[epoch11, step1942]: loss 2.070342
[epoch11, step1943]: loss 0.797902
[epoch11, step1944]: loss 1.881761
[epoch11, step1945]: loss 9.241879
[epoch11, step1946]: loss 2.519493
[epoch11, step1947]: loss 5.208033
[epoch11, step1948]: loss 9.104238
[epoch11, step1949]: loss 2.250529
[epoch11, step1950]: loss 8.968280
[epoch11, step1951]: loss 5.904118
[epoch11, step1952]: loss 9.315152
[epoch11, step1953]: loss 11.352031
[epoch11, step1954]: loss 6.320761
[epoch11, step1955]: loss 15.006371
[epoch11, step1956]: loss 1.380550
[epoch11, step1957]: loss 0.912509
[epoch11, step1958]: loss 13.557142
[epoch11, step1959]: loss 1.908773
[epoch11, step1960]: loss 0.842818
[epoch11, step1961]: loss 5.153904
[epoch11, step1962]: loss 6.763649
[epoch11, step1963]: loss 1.126101
[epoch11, step1964]: loss 6.718287
[epoch11, step1965]: loss 2.471161
[epoch11, step1966]: loss 1.129229
[epoch11, step1967]: loss 7.747038
[epoch11, step1968]: loss 2.802600
[epoch11, step1969]: loss 1.381163
[epoch11, step1970]: loss 9.396235
[epoch11, step1971]: loss 19.455322
[epoch11, step1972]: loss 2.738444
[epoch11, step1973]: loss 1.784264
[epoch11, step1974]: loss 2.127327
[epoch11, step1975]: loss 4.677670
[epoch11, step1976]: loss 3.862849
[epoch11, step1977]: loss 10.554103
[epoch11, step1978]: loss 1.161513
[epoch11, step1979]: loss 0.861700
[epoch11, step1980]: loss 10.754738
[epoch11, step1981]: loss 0.983879
[epoch11, step1982]: loss 8.619158
[epoch11, step1983]: loss 3.759856
[epoch11, step1984]: loss 0.781186
[epoch11, step1985]: loss 4.672026
[epoch11, step1986]: loss 0.964435
[epoch11, step1987]: loss 10.712821
[epoch11, step1988]: loss 1.502806
[epoch11, step1989]: loss 3.467080
[epoch11, step1990]: loss 12.005171
[epoch11, step1991]: loss 6.020838
[epoch11, step1992]: loss 2.623084
[epoch11, step1993]: loss 4.166411
[epoch11, step1994]: loss 11.835229
[epoch11, step1995]: loss 1.893301
[epoch11, step1996]: loss 22.652431
[epoch11, step1997]: loss 12.038119
[epoch11, step1998]: loss 1.261376
[epoch11, step1999]: loss 7.786524
[epoch11, step2000]: loss 1.400856
[epoch11, step2001]: loss 1.420846
[epoch11, step2002]: loss 11.799894
[epoch11, step2003]: loss 6.747410
[epoch11, step2004]: loss 11.253525
[epoch11, step2005]: loss 1.213457
[epoch11, step2006]: loss 2.682663
[epoch11, step2007]: loss 12.198677
[epoch11, step2008]: loss 24.933853
[epoch11, step2009]: loss 4.512414
[epoch11, step2010]: loss 0.895895
[epoch11, step2011]: loss 9.029551
[epoch11, step2012]: loss 3.348570
[epoch11, step2013]: loss 0.899767
[epoch11, step2014]: loss 1.919562
[epoch11, step2015]: loss 10.528456
[epoch11, step2016]: loss 5.928326
[epoch11, step2017]: loss 10.078722
[epoch11, step2018]: loss 1.372893
[epoch11, step2019]: loss 7.927075
[epoch11, step2020]: loss 1.901024
[epoch11, step2021]: loss 1.228551
[epoch11, step2022]: loss 11.129056
[epoch11, step2023]: loss 1.734957
[epoch11, step2024]: loss 1.058848
[epoch11, step2025]: loss 1.147560
[epoch11, step2026]: loss 1.005334
[epoch11, step2027]: loss 7.495772
[epoch11, step2028]: loss 15.222481
[epoch11, step2029]: loss 0.969515
[epoch11, step2030]: loss 6.822887
[epoch11, step2031]: loss 1.451239
[epoch11, step2032]: loss 0.655036
[epoch11, step2033]: loss 12.726475
[epoch11, step2034]: loss 1.792703
[epoch11, step2035]: loss 4.410714
[epoch11, step2036]: loss 5.411028
[epoch11, step2037]: loss 0.868775
[epoch11, step2038]: loss 1.625804
[epoch11, step2039]: loss 1.031254
[epoch11, step2040]: loss 3.191729
[epoch11, step2041]: loss 2.176484
[epoch11, step2042]: loss 0.987531
[epoch11, step2043]: loss 5.101714
[epoch11, step2044]: loss 3.512784
[epoch11, step2045]: loss 0.886027
[epoch11, step2046]: loss 4.347377
[epoch11, step2047]: loss 12.498459
[epoch11, step2048]: loss 7.342393
[epoch11, step2049]: loss 1.033472
[epoch11, step2050]: loss 1.141029
[epoch11, step2051]: loss 0.675256
[epoch11, step2052]: loss 1.202991
[epoch11, step2053]: loss 1.809775
[epoch11, step2054]: loss 1.546912
[epoch11, step2055]: loss 1.087517
[epoch11, step2056]: loss 2.020121
[epoch11, step2057]: loss 1.199068
[epoch11, step2058]: loss 3.294317
[epoch11, step2059]: loss 1.735235
[epoch11, step2060]: loss 4.111473
[epoch11, step2061]: loss 23.716812
[epoch11, step2062]: loss 8.536880
[epoch11, step2063]: loss 1.576241
[epoch11, step2064]: loss 3.492151
[epoch11, step2065]: loss 5.802336
[epoch11, step2066]: loss 7.785383
[epoch11, step2067]: loss 2.172610
[epoch11, step2068]: loss 3.502709
[epoch11, step2069]: loss 8.481918
[epoch11, step2070]: loss 1.499988
[epoch11, step2071]: loss 2.007556
[epoch11, step2072]: loss 5.342337
[epoch11, step2073]: loss 14.291438
[epoch11, step2074]: loss 1.678416
[epoch11, step2075]: loss 2.198442
[epoch11, step2076]: loss 2.096572
[epoch11, step2077]: loss 1.155962
[epoch11, step2078]: loss 1.068950
[epoch11, step2079]: loss 9.330129
[epoch11, step2080]: loss 3.643735
[epoch11, step2081]: loss 13.615382
[epoch11, step2082]: loss 11.144144
[epoch11, step2083]: loss 2.937491
[epoch11, step2084]: loss 9.561840
[epoch11, step2085]: loss 1.435962
[epoch11, step2086]: loss 7.875870
[epoch11, step2087]: loss 0.833524
[epoch11, step2088]: loss 9.346762
[epoch11, step2089]: loss 1.739760
[epoch11, step2090]: loss 0.976981
[epoch11, step2091]: loss 0.979192
[epoch11, step2092]: loss 1.557363
[epoch11, step2093]: loss 1.522922
[epoch11, step2094]: loss 0.808853
[epoch11, step2095]: loss 3.078856
[epoch11, step2096]: loss 4.587832
[epoch11, step2097]: loss 4.780621
[epoch11, step2098]: loss 1.283338
[epoch11, step2099]: loss 5.879002
[epoch11, step2100]: loss 5.140794
[epoch11, step2101]: loss 2.090889
[epoch11, step2102]: loss 2.722071
[epoch11, step2103]: loss 1.436916
[epoch11, step2104]: loss 1.879204
[epoch11, step2105]: loss 2.572790
[epoch11, step2106]: loss 6.503372
[epoch11, step2107]: loss 1.481801
[epoch11, step2108]: loss 7.558389
[epoch11, step2109]: loss 10.304522
[epoch11, step2110]: loss 1.051221
[epoch11, step2111]: loss 3.448710
[epoch11, step2112]: loss 2.043419
[epoch11, step2113]: loss 1.583624
[epoch11, step2114]: loss 0.917217
[epoch11, step2115]: loss 1.937839
[epoch11, step2116]: loss 0.713491
[epoch11, step2117]: loss 1.431568
[epoch11, step2118]: loss 7.235533
[epoch11, step2119]: loss 10.527981
[epoch11, step2120]: loss 1.464276
[epoch11, step2121]: loss 6.241384
[epoch11, step2122]: loss 9.455157
[epoch11, step2123]: loss 10.653597
[epoch11, step2124]: loss 1.437595
[epoch11, step2125]: loss 3.894153
[epoch11, step2126]: loss 1.947424
[epoch11, step2127]: loss 2.139331
[epoch11, step2128]: loss 6.797164
[epoch11, step2129]: loss 1.531862
[epoch11, step2130]: loss 4.139567
[epoch11, step2131]: loss 7.527723
[epoch11, step2132]: loss 1.548748
[epoch11, step2133]: loss 2.610435
[epoch11, step2134]: loss 1.178849
[epoch11, step2135]: loss 1.049837
[epoch11, step2136]: loss 7.727265
[epoch11, step2137]: loss 11.043160
[epoch11, step2138]: loss 0.851442
[epoch11, step2139]: loss 3.639515
[epoch11, step2140]: loss 4.254587
[epoch11, step2141]: loss 1.591658
[epoch11, step2142]: loss 26.585356
[epoch11, step2143]: loss 14.110035
[epoch11, step2144]: loss 5.599403
[epoch11, step2145]: loss 2.383958
[epoch11, step2146]: loss 9.112800
[epoch11, step2147]: loss 10.898883
[epoch11, step2148]: loss 6.543768
[epoch11, step2149]: loss 3.575412
[epoch11, step2150]: loss 3.601295
[epoch11, step2151]: loss 2.491215
[epoch11, step2152]: loss 4.159825
[epoch11, step2153]: loss 1.217357
[epoch11, step2154]: loss 1.980823
[epoch11, step2155]: loss 11.066398
[epoch11, step2156]: loss 1.025210
[epoch11, step2157]: loss 1.898882
[epoch11, step2158]: loss 1.466986
[epoch11, step2159]: loss 1.679401
[epoch11, step2160]: loss 2.274108
[epoch11, step2161]: loss 1.479231
[epoch11, step2162]: loss 2.836803
[epoch11, step2163]: loss 1.926765
[epoch11, step2164]: loss 10.608806
[epoch11, step2165]: loss 11.559333
[epoch11, step2166]: loss 8.922857
[epoch11, step2167]: loss 16.497269
[epoch11, step2168]: loss 11.048173
[epoch11, step2169]: loss 2.288458
[epoch11, step2170]: loss 0.957829
[epoch11, step2171]: loss 14.462183
[epoch11, step2172]: loss 6.900438
[epoch11, step2173]: loss 1.885980
[epoch11, step2174]: loss 3.026631
[epoch11, step2175]: loss 2.747411
[epoch11, step2176]: loss 0.851387
[epoch11, step2177]: loss 12.483136
[epoch11, step2178]: loss 1.236898
[epoch11, step2179]: loss 0.739817
[epoch11, step2180]: loss 1.224405
[epoch11, step2181]: loss 8.439453
[epoch11, step2182]: loss 2.414607
[epoch11, step2183]: loss 2.031790
[epoch11, step2184]: loss 1.049805
[epoch11, step2185]: loss 22.376278
[epoch11, step2186]: loss 0.890611
[epoch11, step2187]: loss 2.507861
[epoch11, step2188]: loss 4.724956
[epoch11, step2189]: loss 1.101858
[epoch11, step2190]: loss 9.483900
[epoch11, step2191]: loss 4.781636
[epoch11, step2192]: loss 3.516068
[epoch11, step2193]: loss 1.198572
[epoch11, step2194]: loss 2.163193
[epoch11, step2195]: loss 1.105943
[epoch11, step2196]: loss 1.507979
[epoch11, step2197]: loss 1.706296
[epoch11, step2198]: loss 9.568568
[epoch11, step2199]: loss 2.170452
[epoch11, step2200]: loss 1.187336
[epoch11, step2201]: loss 4.757692
[epoch11, step2202]: loss 0.915465
[epoch11, step2203]: loss 1.127080
[epoch11, step2204]: loss 17.879990
[epoch11, step2205]: loss 2.566191
[epoch11, step2206]: loss 5.114175
[epoch11, step2207]: loss 1.129776
[epoch11, step2208]: loss 12.811771
[epoch11, step2209]: loss 1.009895
[epoch11, step2210]: loss 1.834695
[epoch11, step2211]: loss 6.797176
[epoch11, step2212]: loss 3.300264
[epoch11, step2213]: loss 1.856337
[epoch11, step2214]: loss 0.825599
[epoch11, step2215]: loss 2.952355
[epoch11, step2216]: loss 1.510194
[epoch11, step2217]: loss 2.152317
[epoch11, step2218]: loss 9.580019
[epoch11, step2219]: loss 1.087802
[epoch11, step2220]: loss 12.340715
[epoch11, step2221]: loss 1.794366
[epoch11, step2222]: loss 1.618556
[epoch11, step2223]: loss 1.962224
[epoch11, step2224]: loss 1.104161
[epoch11, step2225]: loss 12.383123
[epoch11, step2226]: loss 10.651089
[epoch11, step2227]: loss 8.155664
[epoch11, step2228]: loss 0.795375
[epoch11, step2229]: loss 15.567213
[epoch11, step2230]: loss 1.122510
[epoch11, step2231]: loss 2.205818
[epoch11, step2232]: loss 3.240372
[epoch11, step2233]: loss 1.402771
[epoch11, step2234]: loss 5.541471
[epoch11, step2235]: loss 1.534179
[epoch11, step2236]: loss 0.954100
[epoch11, step2237]: loss 11.238055
[epoch11, step2238]: loss 3.172315
[epoch11, step2239]: loss 10.282804
[epoch11, step2240]: loss 1.903117
[epoch11, step2241]: loss 1.014576
[epoch11, step2242]: loss 2.821338
[epoch11, step2243]: loss 2.327785
[epoch11, step2244]: loss 0.719487
[epoch11, step2245]: loss 10.336426
[epoch11, step2246]: loss 10.755626
[epoch11, step2247]: loss 1.143390
[epoch11, step2248]: loss 12.287516
[epoch11, step2249]: loss 2.394343
[epoch11, step2250]: loss 11.804313
[epoch11, step2251]: loss 1.243891
[epoch11, step2252]: loss 11.405087
[epoch11, step2253]: loss 9.113246
[epoch11, step2254]: loss 1.291090
[epoch11, step2255]: loss 5.805138
[epoch11, step2256]: loss 0.867650
[epoch11, step2257]: loss 1.694677
[epoch11, step2258]: loss 2.490489
[epoch11, step2259]: loss 12.057773
[epoch11, step2260]: loss 1.133346
[epoch11, step2261]: loss 0.754816
[epoch11, step2262]: loss 1.558261
[epoch11, step2263]: loss 5.402507
[epoch11, step2264]: loss 1.427567
[epoch11, step2265]: loss 15.654296
[epoch11, step2266]: loss 1.271682
[epoch11, step2267]: loss 12.768232
[epoch11, step2268]: loss 1.799595
[epoch11, step2269]: loss 1.543874
[epoch11, step2270]: loss 8.443283
[epoch11, step2271]: loss 1.845940
[epoch11, step2272]: loss 0.899788
[epoch11, step2273]: loss 0.747335
[epoch11, step2274]: loss 8.408111
[epoch11, step2275]: loss 5.496028
[epoch11, step2276]: loss 10.937929
[epoch11, step2277]: loss 12.393569
[epoch11, step2278]: loss 7.827318
[epoch11, step2279]: loss 3.525692
[epoch11, step2280]: loss 1.772845
[epoch11, step2281]: loss 1.633683
[epoch11, step2282]: loss 1.422000
[epoch11, step2283]: loss 1.032730
[epoch11, step2284]: loss 1.236221
[epoch11, step2285]: loss 3.511567
[epoch11, step2286]: loss 0.720058
[epoch11, step2287]: loss 1.939625
[epoch11, step2288]: loss 5.984758
[epoch11, step2289]: loss 1.410443
[epoch11, step2290]: loss 13.670534
[epoch11, step2291]: loss 16.015728
[epoch11, step2292]: loss 8.303769
[epoch11, step2293]: loss 1.044252
[epoch11, step2294]: loss 1.731365
[epoch11, step2295]: loss 9.896911
[epoch11, step2296]: loss 1.173452
[epoch11, step2297]: loss 1.629016
[epoch11, step2298]: loss 1.787296
[epoch11, step2299]: loss 16.236483
[epoch11, step2300]: loss 0.923764
[epoch11, step2301]: loss 1.124553
[epoch11, step2302]: loss 7.228790
[epoch11, step2303]: loss 2.118762
[epoch11, step2304]: loss 1.321831
[epoch11, step2305]: loss 20.468897
[epoch11, step2306]: loss 1.667064
[epoch11, step2307]: loss 1.180941
[epoch11, step2308]: loss 1.101824
[epoch11, step2309]: loss 3.676257
[epoch11, step2310]: loss 3.155198
[epoch11, step2311]: loss 1.166598
[epoch11, step2312]: loss 1.001158
[epoch11, step2313]: loss 9.535243
[epoch11, step2314]: loss 1.233258
[epoch11, step2315]: loss 2.942443
[epoch11, step2316]: loss 1.226959
[epoch11, step2317]: loss 1.838236
[epoch11, step2318]: loss 1.485518
[epoch11, step2319]: loss 0.736889
[epoch11, step2320]: loss 0.861498
[epoch11, step2321]: loss 3.953846
[epoch11, step2322]: loss 6.843529
[epoch11, step2323]: loss 5.370645
[epoch11, step2324]: loss 1.877690
[epoch11, step2325]: loss 2.201770
[epoch11, step2326]: loss 1.572529
[epoch11, step2327]: loss 1.597979
[epoch11, step2328]: loss 1.380270
[epoch11, step2329]: loss 1.729310
[epoch11, step2330]: loss 3.468196
[epoch11, step2331]: loss 9.969203
[epoch11, step2332]: loss 2.188109
[epoch11, step2333]: loss 0.833353
[epoch11, step2334]: loss 11.780777
[epoch11, step2335]: loss 2.159098
[epoch11, step2336]: loss 1.620532
[epoch11, step2337]: loss 2.153613
[epoch11, step2338]: loss 1.212015
[epoch11, step2339]: loss 12.012980
[epoch11, step2340]: loss 10.853430
[epoch11, step2341]: loss 2.751608
[epoch11, step2342]: loss 1.060904
[epoch11, step2343]: loss 0.884415
[epoch11, step2344]: loss 0.984281
[epoch11, step2345]: loss 2.303643
[epoch11, step2346]: loss 2.687818
[epoch11, step2347]: loss 0.996043
[epoch11, step2348]: loss 14.485970
[epoch11, step2349]: loss 5.037698
[epoch11, step2350]: loss 1.678614
[epoch11, step2351]: loss 11.362738
[epoch11, step2352]: loss 2.518011
[epoch11, step2353]: loss 12.089760
[epoch11, step2354]: loss 1.625543
[epoch11, step2355]: loss 1.262464
[epoch11, step2356]: loss 7.266568
[epoch11, step2357]: loss 8.060219
[epoch11, step2358]: loss 12.951510
[epoch11, step2359]: loss 10.352242
[epoch11, step2360]: loss 10.954740
[epoch11, step2361]: loss 1.617983
[epoch11, step2362]: loss 3.231853
[epoch11, step2363]: loss 2.648676
[epoch11, step2364]: loss 1.184279
[epoch11, step2365]: loss 2.576055
[epoch11, step2366]: loss 1.688566
[epoch11, step2367]: loss 3.409104
[epoch11, step2368]: loss 1.227014
[epoch11, step2369]: loss 16.062550
[epoch11, step2370]: loss 13.548988
[epoch11, step2371]: loss 3.347444
[epoch11, step2372]: loss 23.738338
[epoch11, step2373]: loss 14.274523
[epoch11, step2374]: loss 0.824090
[epoch11, step2375]: loss 3.524278
[epoch11, step2376]: loss 8.275463
[epoch11, step2377]: loss 5.338538
[epoch11, step2378]: loss 5.817277
[epoch11, step2379]: loss 12.100203
[epoch11, step2380]: loss 1.209769
[epoch11, step2381]: loss 8.930769
[epoch11, step2382]: loss 3.067605
[epoch11, step2383]: loss 8.737033
[epoch11, step2384]: loss 0.850746
[epoch11, step2385]: loss 4.288526
[epoch11, step2386]: loss 11.850071
[epoch11, step2387]: loss 1.255819
[epoch11, step2388]: loss 4.314296
[epoch11, step2389]: loss 3.027796
[epoch11, step2390]: loss 3.699096
[epoch11, step2391]: loss 1.400972
[epoch11, step2392]: loss 16.954916
[epoch11, step2393]: loss 0.814198
[epoch11, step2394]: loss 9.972762
[epoch11, step2395]: loss 11.598895
[epoch11, step2396]: loss 7.749247
[epoch11, step2397]: loss 2.039209
[epoch11, step2398]: loss 1.998162
[epoch11, step2399]: loss 0.809238
[epoch11, step2400]: loss 1.007690
[epoch11, step2401]: loss 1.515127
[epoch11, step2402]: loss 8.880771
[epoch11, step2403]: loss 1.756929
[epoch11, step2404]: loss 3.858082
[epoch11, step2405]: loss 1.394528
[epoch11, step2406]: loss 8.855197
[epoch11, step2407]: loss 1.019132
[epoch11, step2408]: loss 1.322666
[epoch11, step2409]: loss 3.308780
[epoch11, step2410]: loss 1.347065
[epoch11, step2411]: loss 13.324972
[epoch11, step2412]: loss 1.381692
[epoch11, step2413]: loss 1.227052
[epoch11, step2414]: loss 11.705665
[epoch11, step2415]: loss 3.148629
[epoch11, step2416]: loss 3.002065
[epoch11, step2417]: loss 13.055468
[epoch11, step2418]: loss 1.077160
[epoch11, step2419]: loss 1.136781
[epoch11, step2420]: loss 7.867236
[epoch11, step2421]: loss 1.065861
[epoch11, step2422]: loss 10.647303
[epoch11, step2423]: loss 12.066620
[epoch11, step2424]: loss 13.972838
[epoch11, step2425]: loss 8.923648
[epoch11, step2426]: loss 0.927163
[epoch11, step2427]: loss 1.752157
[epoch11, step2428]: loss 11.848137
[epoch11, step2429]: loss 9.217050
[epoch11, step2430]: loss 1.728257
[epoch11, step2431]: loss 3.294750
[epoch11, step2432]: loss 11.355109
[epoch11, step2433]: loss 16.302462
[epoch11, step2434]: loss 5.954403
[epoch11, step2435]: loss 3.627771
[epoch11, step2436]: loss 0.917682
[epoch11, step2437]: loss 1.254480
[epoch11, step2438]: loss 2.001415
[epoch11, step2439]: loss 12.973582
[epoch11, step2440]: loss 1.267565
[epoch11, step2441]: loss 8.043404
[epoch11, step2442]: loss 11.509588
[epoch11, step2443]: loss 1.178314
[epoch11, step2444]: loss 0.865954
[epoch11, step2445]: loss 2.559518
[epoch11, step2446]: loss 1.127174
[epoch11, step2447]: loss 1.118212
[epoch11, step2448]: loss 6.516860
[epoch11, step2449]: loss 4.721863
[epoch11, step2450]: loss 10.444253
[epoch11, step2451]: loss 1.171109
[epoch11, step2452]: loss 2.370312
[epoch11, step2453]: loss 0.918194
[epoch11, step2454]: loss 1.985595
[epoch11, step2455]: loss 1.372668
[epoch11, step2456]: loss 1.656624
[epoch11, step2457]: loss 8.251096
[epoch11, step2458]: loss 21.910166
[epoch11, step2459]: loss 1.623646
[epoch11, step2460]: loss 1.090781
[epoch11, step2461]: loss 1.139411
[epoch11, step2462]: loss 1.010100
[epoch11, step2463]: loss 1.557086
[epoch11, step2464]: loss 6.433758
[epoch11, step2465]: loss 3.998585
[epoch11, step2466]: loss 2.713134
[epoch11, step2467]: loss 4.042866
[epoch11, step2468]: loss 10.971747
[epoch11, step2469]: loss 2.210888
[epoch11, step2470]: loss 4.935823
[epoch11, step2471]: loss 1.130393
[epoch11, step2472]: loss 1.383284
[epoch11, step2473]: loss 4.822057
[epoch11, step2474]: loss 1.513229
[epoch11, step2475]: loss 1.346270
[epoch11, step2476]: loss 6.726681
[epoch11, step2477]: loss 9.503262
[epoch11, step2478]: loss 2.104370
[epoch11, step2479]: loss 10.825638
[epoch11, step2480]: loss 1.041525
[epoch11, step2481]: loss 1.752573
[epoch11, step2482]: loss 0.879561
[epoch11, step2483]: loss 3.103868
[epoch11, step2484]: loss 1.615403
[epoch11, step2485]: loss 2.638178
[epoch11, step2486]: loss 1.995052
[epoch11, step2487]: loss 9.259157
[epoch11, step2488]: loss 6.883725
[epoch11, step2489]: loss 12.793307
[epoch11, step2490]: loss 6.489098
[epoch11, step2491]: loss 1.715308
[epoch11, step2492]: loss 1.221264
[epoch11, step2493]: loss 1.670004
[epoch11, step2494]: loss 1.174594
[epoch11, step2495]: loss 1.425265
[epoch11, step2496]: loss 6.608351
[epoch11, step2497]: loss 2.806641
[epoch11, step2498]: loss 1.054845
[epoch11, step2499]: loss 2.142605
[epoch11, step2500]: loss 4.602495
[epoch11, step2501]: loss 2.813498
[epoch11, step2502]: loss 1.649677
[epoch11, step2503]: loss 18.677378
[epoch11, step2504]: loss 2.114769
[epoch11, step2505]: loss 2.899963
[epoch11, step2506]: loss 1.724581
[epoch11, step2507]: loss 1.808118
[epoch11, step2508]: loss 9.342735
[epoch11, step2509]: loss 6.817024
[epoch11, step2510]: loss 2.177147
[epoch11, step2511]: loss 7.317024
[epoch11, step2512]: loss 1.536473
[epoch11, step2513]: loss 1.201211
[epoch11, step2514]: loss 1.886923
[epoch11, step2515]: loss 1.166410
[epoch11, step2516]: loss 1.171200
[epoch11, step2517]: loss 1.010700
[epoch11, step2518]: loss 16.511490
[epoch11, step2519]: loss 20.908279
[epoch11, step2520]: loss 8.077977
[epoch11, step2521]: loss 1.401894
[epoch11, step2522]: loss 2.223826
[epoch11, step2523]: loss 7.549372
[epoch11, step2524]: loss 9.524666
[epoch11, step2525]: loss 10.898752
[epoch11, step2526]: loss 2.001869
[epoch11, step2527]: loss 10.075252
[epoch11, step2528]: loss 7.497829
[epoch11, step2529]: loss 18.001966
[epoch11, step2530]: loss 4.527292
[epoch11, step2531]: loss 4.104115
[epoch11, step2532]: loss 11.178485
[epoch11, step2533]: loss 2.429023
[epoch11, step2534]: loss 1.096565
[epoch11, step2535]: loss 0.892300
[epoch11, step2536]: loss 7.884037
[epoch11, step2537]: loss 0.868470
[epoch11, step2538]: loss 2.334066
[epoch11, step2539]: loss 1.473932
[epoch11, step2540]: loss 0.774198
[epoch11, step2541]: loss 1.798414
[epoch11, step2542]: loss 11.393504
[epoch11, step2543]: loss 3.021585
[epoch11, step2544]: loss 1.813459
[epoch11, step2545]: loss 2.374654
[epoch11, step2546]: loss 12.725193
[epoch11, step2547]: loss 1.199988
[epoch11, step2548]: loss 0.718932
[epoch11, step2549]: loss 20.498875
[epoch11, step2550]: loss 3.054665
[epoch11, step2551]: loss 4.151136
[epoch11, step2552]: loss 2.022220
[epoch11, step2553]: loss 3.195761
[epoch11, step2554]: loss 9.337326
[epoch11, step2555]: loss 4.142935
[epoch11, step2556]: loss 10.262524
[epoch11, step2557]: loss 10.333646
[epoch11, step2558]: loss 3.383504
[epoch11, step2559]: loss 2.275076
[epoch11, step2560]: loss 0.728668
[epoch11, step2561]: loss 2.551565
[epoch11, step2562]: loss 1.368481
[epoch11, step2563]: loss 1.720775
[epoch11, step2564]: loss 12.617594
[epoch11, step2565]: loss 1.626701
[epoch11, step2566]: loss 13.841270
[epoch11, step2567]: loss 1.340797
[epoch11, step2568]: loss 1.058233
[epoch11, step2569]: loss 7.744552
[epoch11, step2570]: loss 1.247333
[epoch11, step2571]: loss 3.342200
[epoch11, step2572]: loss 8.977809
[epoch11, step2573]: loss 12.649805
[epoch11, step2574]: loss 22.887764
[epoch11, step2575]: loss 1.897756
[epoch11, step2576]: loss 3.785264
[epoch11, step2577]: loss 11.720792
[epoch11, step2578]: loss 3.987937
[epoch11, step2579]: loss 2.629048
[epoch11, step2580]: loss 10.026394
[epoch11, step2581]: loss 3.555938
[epoch11, step2582]: loss 1.803905
[epoch11, step2583]: loss 0.752880
[epoch11, step2584]: loss 3.324347
[epoch11, step2585]: loss 2.442784
[epoch11, step2586]: loss 3.037223
[epoch11, step2587]: loss 2.066559
[epoch11, step2588]: loss 1.742728
[epoch11, step2589]: loss 1.295156
[epoch11, step2590]: loss 1.390454
[epoch11, step2591]: loss 12.590812
[epoch11, step2592]: loss 9.419944
[epoch11, step2593]: loss 1.128443
[epoch11, step2594]: loss 1.173795
[epoch11, step2595]: loss 0.832727
[epoch11, step2596]: loss 9.614147
[epoch11, step2597]: loss 7.198027
[epoch11, step2598]: loss 12.636007
[epoch11, step2599]: loss 0.946240
[epoch11, step2600]: loss 0.971335
[epoch11, step2601]: loss 1.191401
[epoch11, step2602]: loss 2.782223
[epoch11, step2603]: loss 24.057434
[epoch11, step2604]: loss 2.518262
[epoch11, step2605]: loss 1.144448
[epoch11, step2606]: loss 1.096458
[epoch11, step2607]: loss 8.060081
[epoch11, step2608]: loss 0.956523
[epoch11, step2609]: loss 0.838584
[epoch11, step2610]: loss 0.585473
[epoch11, step2611]: loss 9.662435
[epoch11, step2612]: loss 1.123666
[epoch11, step2613]: loss 1.918257
[epoch11, step2614]: loss 6.787889
[epoch11, step2615]: loss 1.557889
[epoch11, step2616]: loss 1.720646
[epoch11, step2617]: loss 3.885591
[epoch11, step2618]: loss 0.928174
[epoch11, step2619]: loss 6.784253
[epoch11, step2620]: loss 0.805497
[epoch11, step2621]: loss 1.817194
[epoch11, step2622]: loss 0.819993
[epoch11, step2623]: loss 2.688457
[epoch11, step2624]: loss 2.052126
[epoch11, step2625]: loss 15.499903
[epoch11, step2626]: loss 1.722183
[epoch11, step2627]: loss 1.475640
[epoch11, step2628]: loss 9.264338
[epoch11, step2629]: loss 1.990806
[epoch11, step2630]: loss 0.892187
[epoch11, step2631]: loss 3.842626
[epoch11, step2632]: loss 14.329544
[epoch11, step2633]: loss 1.460415
[epoch11, step2634]: loss 3.720942
[epoch11, step2635]: loss 15.141005
[epoch11, step2636]: loss 1.873255
[epoch11, step2637]: loss 3.135439
[epoch11, step2638]: loss 10.021563
[epoch11, step2639]: loss 0.849029
[epoch11, step2640]: loss 5.067752
[epoch11, step2641]: loss 1.435191
[epoch11, step2642]: loss 3.152125
[epoch11, step2643]: loss 1.579874
[epoch11, step2644]: loss 2.519437
[epoch11, step2645]: loss 1.244413
[epoch11, step2646]: loss 1.368889
[epoch11, step2647]: loss 13.796688
[epoch11, step2648]: loss 1.108536
[epoch11, step2649]: loss 6.255946
[epoch11, step2650]: loss 2.970184
[epoch11, step2651]: loss 6.621082
[epoch11, step2652]: loss 24.949831
[epoch11, step2653]: loss 3.390737
[epoch11, step2654]: loss 14.826585
[epoch11, step2655]: loss 1.014538
[epoch11, step2656]: loss 0.965998
[epoch11, step2657]: loss 1.428872
[epoch11, step2658]: loss 2.676514
[epoch11, step2659]: loss 1.008889
[epoch11, step2660]: loss 1.256462
[epoch11, step2661]: loss 1.968827
[epoch11, step2662]: loss 1.038860
[epoch11, step2663]: loss 2.230602
[epoch11, step2664]: loss 2.204027
[epoch11, step2665]: loss 4.689295
[epoch11, step2666]: loss 8.888907
[epoch11, step2667]: loss 1.422972
[epoch11, step2668]: loss 16.706942
[epoch11, step2669]: loss 1.311681
[epoch11, step2670]: loss 1.697992
[epoch11, step2671]: loss 1.055981
[epoch11, step2672]: loss 1.511397
[epoch11, step2673]: loss 4.560997
[epoch11, step2674]: loss 1.227914
[epoch11, step2675]: loss 1.597406
[epoch11, step2676]: loss 10.852924
[epoch11, step2677]: loss 2.285792
[epoch11, step2678]: loss 3.268976
[epoch11, step2679]: loss 2.258276
[epoch11, step2680]: loss 1.471602
[epoch11, step2681]: loss 4.140119
[epoch11, step2682]: loss 1.649364
[epoch11, step2683]: loss 2.266907
[epoch11, step2684]: loss 7.633414
[epoch11, step2685]: loss 1.151967
[epoch11, step2686]: loss 15.558746
[epoch11, step2687]: loss 1.513301
[epoch11, step2688]: loss 8.735727
[epoch11, step2689]: loss 1.639053
[epoch11, step2690]: loss 3.160496
[epoch11, step2691]: loss 9.749913
[epoch11, step2692]: loss 3.991227
[epoch11, step2693]: loss 1.240805
[epoch11, step2694]: loss 7.487494
[epoch11, step2695]: loss 6.016183
[epoch11, step2696]: loss 4.507523
[epoch11, step2697]: loss 3.220366
[epoch11, step2698]: loss 0.879016
[epoch11, step2699]: loss 0.800570
[epoch11, step2700]: loss 2.176807
[epoch11, step2701]: loss 13.737664
[epoch11, step2702]: loss 3.820518
[epoch11, step2703]: loss 11.798171
[epoch11, step2704]: loss 3.428976
[epoch11, step2705]: loss 1.945900
[epoch11, step2706]: loss 1.458652
[epoch11, step2707]: loss 5.429749
[epoch11, step2708]: loss 1.458555
[epoch11, step2709]: loss 2.996226
[epoch11, step2710]: loss 3.739680
[epoch11, step2711]: loss 7.340459
[epoch11, step2712]: loss 9.312199
[epoch11, step2713]: loss 4.003669
[epoch11, step2714]: loss 8.363579
[epoch11, step2715]: loss 0.957719
[epoch11, step2716]: loss 5.481510
[epoch11, step2717]: loss 16.177061
[epoch11, step2718]: loss 2.019544
[epoch11, step2719]: loss 1.775103
[epoch11, step2720]: loss 0.965698
[epoch11, step2721]: loss 2.631735
[epoch11, step2722]: loss 1.567155
[epoch11, step2723]: loss 0.715252
[epoch11, step2724]: loss 18.016031
[epoch11, step2725]: loss 11.414300
[epoch11, step2726]: loss 1.192009
[epoch11, step2727]: loss 3.242723
[epoch11, step2728]: loss 10.068020
[epoch11, step2729]: loss 10.255941
[epoch11, step2730]: loss 8.035615
[epoch11, step2731]: loss 8.322268
[epoch11, step2732]: loss 1.375095
[epoch11, step2733]: loss 1.181045
[epoch11, step2734]: loss 1.188733
[epoch11, step2735]: loss 8.057520
[epoch11, step2736]: loss 0.984833
[epoch11, step2737]: loss 9.365231
[epoch11, step2738]: loss 1.225481
[epoch11, step2739]: loss 7.929643
[epoch11, step2740]: loss 19.706657
[epoch11, step2741]: loss 0.756404
[epoch11, step2742]: loss 2.535066
[epoch11, step2743]: loss 1.812098
[epoch11, step2744]: loss 12.370742
[epoch11, step2745]: loss 15.844750
[epoch11, step2746]: loss 1.798273
[epoch11, step2747]: loss 2.737638
[epoch11, step2748]: loss 1.550707
[epoch11, step2749]: loss 1.117623
[epoch11, step2750]: loss 1.645255
[epoch11, step2751]: loss 1.330809
[epoch11, step2752]: loss 5.438674
[epoch11, step2753]: loss 0.943928
[epoch11, step2754]: loss 1.611074
[epoch11, step2755]: loss 2.487062
[epoch11, step2756]: loss 10.741764
[epoch11, step2757]: loss 2.151891
[epoch11, step2758]: loss 1.211724
[epoch11, step2759]: loss 1.028100
[epoch11, step2760]: loss 5.405510
[epoch11, step2761]: loss 10.222408
[epoch11, step2762]: loss 1.908623
[epoch11, step2763]: loss 4.674503
[epoch11, step2764]: loss 2.932095
[epoch11, step2765]: loss 2.526983
[epoch11, step2766]: loss 1.371673
[epoch11, step2767]: loss 1.314669
[epoch11, step2768]: loss 9.828697
[epoch11, step2769]: loss 1.319443
[epoch11, step2770]: loss 2.699492
[epoch11, step2771]: loss 11.755577
[epoch11, step2772]: loss 6.413896
[epoch11, step2773]: loss 1.138320
[epoch11, step2774]: loss 3.536547
[epoch11, step2775]: loss 0.943095
[epoch11, step2776]: loss 3.413296
[epoch11, step2777]: loss 9.887137
[epoch11, step2778]: loss 1.710348
[epoch11, step2779]: loss 1.626593
[epoch11, step2780]: loss 18.914171
[epoch11, step2781]: loss 10.552603
[epoch11, step2782]: loss 18.196922
[epoch11, step2783]: loss 8.533614
[epoch11, step2784]: loss 1.087531
[epoch11, step2785]: loss 1.235634
[epoch11, step2786]: loss 9.489386
[epoch11, step2787]: loss 2.171127
[epoch11, step2788]: loss 1.748441
[epoch11, step2789]: loss 1.152523
[epoch11, step2790]: loss 2.681490
[epoch11, step2791]: loss 8.591367
[epoch11, step2792]: loss 1.439960
[epoch11, step2793]: loss 3.408809
[epoch11, step2794]: loss 1.438938
[epoch11, step2795]: loss 1.599943
[epoch11, step2796]: loss 2.486661
[epoch11, step2797]: loss 3.847247
[epoch11, step2798]: loss 1.466244
[epoch11, step2799]: loss 1.480304
[epoch11, step2800]: loss 11.426107
[epoch11, step2801]: loss 8.849910
[epoch11, step2802]: loss 2.395080
[epoch11, step2803]: loss 2.082801
[epoch11, step2804]: loss 21.739420
[epoch11, step2805]: loss 6.993359
[epoch11, step2806]: loss 4.704640
[epoch11, step2807]: loss 3.345869
[epoch11, step2808]: loss 3.661758
[epoch11, step2809]: loss 2.084146
[epoch11, step2810]: loss 1.015057
[epoch11, step2811]: loss 9.485760
[epoch11, step2812]: loss 2.405821
[epoch11, step2813]: loss 0.893592
[epoch11, step2814]: loss 13.181466
[epoch11, step2815]: loss 5.801171
[epoch11, step2816]: loss 8.947242
[epoch11, step2817]: loss 9.357637
[epoch11, step2818]: loss 3.884016
[epoch11, step2819]: loss 1.098315
[epoch11, step2820]: loss 1.802215
[epoch11, step2821]: loss 2.269996
[epoch11, step2822]: loss 1.217046
[epoch11, step2823]: loss 1.868496
[epoch11, step2824]: loss 9.323627
[epoch11, step2825]: loss 21.539349
[epoch11, step2826]: loss 1.291085
[epoch11, step2827]: loss 1.024685
[epoch11, step2828]: loss 3.892406
[epoch11, step2829]: loss 5.443187
[epoch11, step2830]: loss 2.232732
[epoch11, step2831]: loss 9.735172
[epoch11, step2832]: loss 1.748005
[epoch11, step2833]: loss 9.747789
[epoch11, step2834]: loss 2.503388
[epoch11, step2835]: loss 0.979949
[epoch11, step2836]: loss 12.268476
[epoch11, step2837]: loss 3.217896
[epoch11, step2838]: loss 1.311315
[epoch11, step2839]: loss 4.773257
[epoch11, step2840]: loss 0.847446
[epoch11, step2841]: loss 7.498872
[epoch11, step2842]: loss 10.895802
[epoch11, step2843]: loss 4.752767
[epoch11, step2844]: loss 1.433859
[epoch11, step2845]: loss 2.423250
[epoch11, step2846]: loss 9.777184
[epoch11, step2847]: loss 1.068463
[epoch11, step2848]: loss 9.011090
[epoch11, step2849]: loss 3.653072
[epoch11, step2850]: loss 1.298608
[epoch11, step2851]: loss 2.989612
[epoch11, step2852]: loss 8.758837
[epoch11, step2853]: loss 14.848092
[epoch11, step2854]: loss 12.213982
[epoch11, step2855]: loss 20.638943
[epoch11, step2856]: loss 0.858009
[epoch11, step2857]: loss 5.581181
[epoch11, step2858]: loss 1.539658
[epoch11, step2859]: loss 1.149272
[epoch11, step2860]: loss 24.401363
[epoch11, step2861]: loss 14.537865
[epoch11, step2862]: loss 4.461352
[epoch11, step2863]: loss 9.029731
[epoch11, step2864]: loss 7.885798
[epoch11, step2865]: loss 1.009903
[epoch11, step2866]: loss 24.958603
[epoch11, step2867]: loss 9.768958
[epoch11, step2868]: loss 4.203418
[epoch11, step2869]: loss 4.179475
[epoch11, step2870]: loss 9.228990
[epoch11, step2871]: loss 1.672432
[epoch11, step2872]: loss 1.654351
[epoch11, step2873]: loss 0.830956
[epoch11, step2874]: loss 18.844507
[epoch11, step2875]: loss 22.976347
[epoch11, step2876]: loss 2.291745
[epoch11, step2877]: loss 18.933573
[epoch11, step2878]: loss 11.729743
[epoch11, step2879]: loss 4.639163
[epoch11, step2880]: loss 10.053782
[epoch11, step2881]: loss 0.972650
[epoch11, step2882]: loss 1.790773
[epoch11, step2883]: loss 4.323832
[epoch11, step2884]: loss 3.768410
[epoch11, step2885]: loss 0.932286
[epoch11, step2886]: loss 4.657457
[epoch11, step2887]: loss 1.071682
[epoch11, step2888]: loss 1.118599
[epoch11, step2889]: loss 1.110237
[epoch11, step2890]: loss 2.912589
[epoch11, step2891]: loss 2.604617
[epoch11, step2892]: loss 13.778077
[epoch11, step2893]: loss 1.767480
[epoch11, step2894]: loss 0.990807
[epoch11, step2895]: loss 1.530474
[epoch11, step2896]: loss 15.558325
[epoch11, step2897]: loss 0.866490
[epoch11, step2898]: loss 0.734513
[epoch11, step2899]: loss 2.160864
[epoch11, step2900]: loss 3.928853
[epoch11, step2901]: loss 1.664405
[epoch11, step2902]: loss 1.154681
[epoch11, step2903]: loss 14.257200
[epoch11, step2904]: loss 12.233110
[epoch11, step2905]: loss 9.046931
[epoch11, step2906]: loss 9.319135
[epoch11, step2907]: loss 3.379541
[epoch11, step2908]: loss 0.787706
[epoch11, step2909]: loss 8.469618
[epoch11, step2910]: loss 22.238594
[epoch11, step2911]: loss 13.182558
[epoch11, step2912]: loss 0.967015
[epoch11, step2913]: loss 1.713275
[epoch11, step2914]: loss 4.668455
[epoch11, step2915]: loss 1.122327
[epoch11, step2916]: loss 2.149883
[epoch11, step2917]: loss 0.834799
[epoch11, step2918]: loss 3.075883
[epoch11, step2919]: loss 3.817690
[epoch11, step2920]: loss 10.000259
[epoch11, step2921]: loss 12.388422
[epoch11, step2922]: loss 5.379479
[epoch11, step2923]: loss 1.196643
[epoch11, step2924]: loss 1.557150
[epoch11, step2925]: loss 1.615843
[epoch11, step2926]: loss 8.785350
[epoch11, step2927]: loss 4.458657
[epoch11, step2928]: loss 3.602717
[epoch11, step2929]: loss 8.117208
[epoch11, step2930]: loss 1.366037
[epoch11, step2931]: loss 1.528649
[epoch11, step2932]: loss 7.374652
[epoch11, step2933]: loss 6.980623
[epoch11, step2934]: loss 1.128791
[epoch11, step2935]: loss 6.898019
[epoch11, step2936]: loss 12.541019
[epoch11, step2937]: loss 1.274487
[epoch11, step2938]: loss 1.834931
[epoch11, step2939]: loss 2.791063
[epoch11, step2940]: loss 8.296755
[epoch11, step2941]: loss 1.740712
[epoch11, step2942]: loss 7.594895
[epoch11, step2943]: loss 2.588713
[epoch11, step2944]: loss 5.492486
[epoch11, step2945]: loss 2.091921
[epoch11, step2946]: loss 1.424927
[epoch11, step2947]: loss 10.721530
[epoch11, step2948]: loss 0.926413
[epoch11, step2949]: loss 4.454787
[epoch11, step2950]: loss 6.488048
[epoch11, step2951]: loss 2.896300
[epoch11, step2952]: loss 1.542669
[epoch11, step2953]: loss 1.243183
[epoch11, step2954]: loss 11.050106
[epoch11, step2955]: loss 2.174560
[epoch11, step2956]: loss 1.774954
[epoch11, step2957]: loss 1.342793
[epoch11, step2958]: loss 1.590248
[epoch11, step2959]: loss 0.892146
[epoch11, step2960]: loss 4.554146
[epoch11, step2961]: loss 1.296465
[epoch11, step2962]: loss 1.350849
[epoch11, step2963]: loss 13.098560
[epoch11, step2964]: loss 0.899496
[epoch11, step2965]: loss 8.714075
[epoch11, step2966]: loss 0.979477
[epoch11, step2967]: loss 0.748319
[epoch11, step2968]: loss 0.880238
[epoch11, step2969]: loss 1.224774
[epoch11, step2970]: loss 2.398933
[epoch11, step2971]: loss 3.572049
[epoch11, step2972]: loss 8.818359
[epoch11, step2973]: loss 7.026080
[epoch11, step2974]: loss 11.324839
[epoch11, step2975]: loss 2.834432
[epoch11, step2976]: loss 4.085821
[epoch11, step2977]: loss 5.644220
[epoch11, step2978]: loss 0.849010
[epoch11, step2979]: loss 1.738003
[epoch11, step2980]: loss 2.657579
[epoch11, step2981]: loss 1.002361
[epoch11, step2982]: loss 0.791883
[epoch11, step2983]: loss 3.684694
[epoch11, step2984]: loss 2.135308
[epoch11, step2985]: loss 9.341100
[epoch11, step2986]: loss 1.255752
[epoch11, step2987]: loss 6.987287
[epoch11, step2988]: loss 4.955370
[epoch11, step2989]: loss 3.118621
[epoch11, step2990]: loss 1.358897
[epoch11, step2991]: loss 1.290673
[epoch11, step2992]: loss 1.968989
[epoch11, step2993]: loss 3.478398
[epoch11, step2994]: loss 1.209142
[epoch11, step2995]: loss 8.681939
[epoch11, step2996]: loss 1.806256
[epoch11, step2997]: loss 21.314034
[epoch11, step2998]: loss 1.028866
[epoch11, step2999]: loss 8.308031
[epoch11, step3000]: loss 5.827811
[epoch11, step3001]: loss 2.447964
[epoch11, step3002]: loss 2.064754
[epoch11, step3003]: loss 4.137285
[epoch11, step3004]: loss 2.500337
[epoch11, step3005]: loss 4.532687
[epoch11, step3006]: loss 9.650545
[epoch11, step3007]: loss 10.616623
[epoch11, step3008]: loss 1.073594
[epoch11, step3009]: loss 8.479888
[epoch11, step3010]: loss 1.101409
[epoch11, step3011]: loss 1.139113
[epoch11, step3012]: loss 10.978443
[epoch11, step3013]: loss 4.464297
[epoch11, step3014]: loss 1.091776
[epoch11, step3015]: loss 1.867146
[epoch11, step3016]: loss 3.982770
[epoch11, step3017]: loss 6.989587
[epoch11, step3018]: loss 0.741394
[epoch11, step3019]: loss 8.114346
[epoch11, step3020]: loss 2.342424
[epoch11, step3021]: loss 5.691512
[epoch11, step3022]: loss 4.226191
[epoch11, step3023]: loss 0.884254
[epoch11, step3024]: loss 1.019827
[epoch11, step3025]: loss 17.419523
[epoch11, step3026]: loss 1.054151
[epoch11, step3027]: loss 4.996138
[epoch11, step3028]: loss 10.687098
[epoch11, step3029]: loss 11.644862
[epoch11, step3030]: loss 8.197713
[epoch11, step3031]: loss 9.797291
[epoch11, step3032]: loss 11.973901
[epoch11, step3033]: loss 3.478204
[epoch11, step3034]: loss 0.933065
[epoch11, step3035]: loss 9.831037
[epoch11, step3036]: loss 3.679607
[epoch11, step3037]: loss 9.767955
[epoch11, step3038]: loss 9.672365
[epoch11, step3039]: loss 9.463800
[epoch11, step3040]: loss 1.076092
[epoch11, step3041]: loss 3.384393
[epoch11, step3042]: loss 1.693290
[epoch11, step3043]: loss 0.848389
[epoch11, step3044]: loss 3.581996
[epoch11, step3045]: loss 3.827442
[epoch11, step3046]: loss 13.658846
[epoch11, step3047]: loss 8.935189
[epoch11, step3048]: loss 0.995983
[epoch11, step3049]: loss 9.469223
[epoch11, step3050]: loss 7.642109
[epoch11, step3051]: loss 16.762009
[epoch11, step3052]: loss 2.199289
[epoch11, step3053]: loss 1.015133
[epoch11, step3054]: loss 12.337803
[epoch11, step3055]: loss 13.684581
[epoch11, step3056]: loss 1.390761
[epoch11, step3057]: loss 8.898258
[epoch11, step3058]: loss 1.359758
[epoch11, step3059]: loss 2.802396
[epoch11, step3060]: loss 0.922613
[epoch11, step3061]: loss 0.737603
[epoch11, step3062]: loss 4.012616
[epoch11, step3063]: loss 1.095607
[epoch11, step3064]: loss 15.571186
[epoch11, step3065]: loss 1.239990
[epoch11, step3066]: loss 3.335232
[epoch11, step3067]: loss 10.541560
[epoch11, step3068]: loss 9.155415
[epoch11, step3069]: loss 0.827601
[epoch11, step3070]: loss 1.151019
[epoch11, step3071]: loss 1.163052
[epoch11, step3072]: loss 2.555993
[epoch11, step3073]: loss 11.548047
[epoch11, step3074]: loss 2.001192
[epoch11, step3075]: loss 3.627258
[epoch11, step3076]: loss 1.447286

[epoch11]: avg loss 1.447286

[epoch12, step1]: loss 21.368355
[epoch12, step2]: loss 1.531805
[epoch12, step3]: loss 2.071529
[epoch12, step4]: loss 6.082858
[epoch12, step5]: loss 22.145416
[epoch12, step6]: loss 1.253083
[epoch12, step7]: loss 1.158451
[epoch12, step8]: loss 8.047151
[epoch12, step9]: loss 9.297095
[epoch12, step10]: loss 11.409390
[epoch12, step11]: loss 2.449837
[epoch12, step12]: loss 4.109021
[epoch12, step13]: loss 0.813832
[epoch12, step14]: loss 0.944969
[epoch12, step15]: loss 5.341839
[epoch12, step16]: loss 0.953636
[epoch12, step17]: loss 1.820611
[epoch12, step18]: loss 1.094497
[epoch12, step19]: loss 0.959021
[epoch12, step20]: loss 1.958368
[epoch12, step21]: loss 0.798959
[epoch12, step22]: loss 1.847800
[epoch12, step23]: loss 4.270184
[epoch12, step24]: loss 18.355444
[epoch12, step25]: loss 1.453786
[epoch12, step26]: loss 0.948890
[epoch12, step27]: loss 1.292980
[epoch12, step28]: loss 1.118984
[epoch12, step29]: loss 9.417088
[epoch12, step30]: loss 5.166988
[epoch12, step31]: loss 0.994692
[epoch12, step32]: loss 8.327858
[epoch12, step33]: loss 1.338797
[epoch12, step34]: loss 13.676685
[epoch12, step35]: loss 1.804639
[epoch12, step36]: loss 0.841418
[epoch12, step37]: loss 1.604501
[epoch12, step38]: loss 1.248605
[epoch12, step39]: loss 1.868273
[epoch12, step40]: loss 15.367550
[epoch12, step41]: loss 1.716115
[epoch12, step42]: loss 2.218599
[epoch12, step43]: loss 28.229979
[epoch12, step44]: loss 3.264322
[epoch12, step45]: loss 2.916477
[epoch12, step46]: loss 1.824988
[epoch12, step47]: loss 4.309012
[epoch12, step48]: loss 1.537670
[epoch12, step49]: loss 5.831566
[epoch12, step50]: loss 15.975848
[epoch12, step51]: loss 1.022478
[epoch12, step52]: loss 3.270226
[epoch12, step53]: loss 1.294850
[epoch12, step54]: loss 1.332934
[epoch12, step55]: loss 12.204895
[epoch12, step56]: loss 2.925071
[epoch12, step57]: loss 8.459608
[epoch12, step58]: loss 12.482879
[epoch12, step59]: loss 14.697472
[epoch12, step60]: loss 10.471055
[epoch12, step61]: loss 4.233944
[epoch12, step62]: loss 0.913126
[epoch12, step63]: loss 9.715733
[epoch12, step64]: loss 1.495170
[epoch12, step65]: loss 5.851672
[epoch12, step66]: loss 1.809398
[epoch12, step67]: loss 1.877953
[epoch12, step68]: loss 13.166743
[epoch12, step69]: loss 1.580061
[epoch12, step70]: loss 6.478047
[epoch12, step71]: loss 4.066635
[epoch12, step72]: loss 8.997912
[epoch12, step73]: loss 4.743025
[epoch12, step74]: loss 1.101872
[epoch12, step75]: loss 1.352576
[epoch12, step76]: loss 6.613554
[epoch12, step77]: loss 1.361023
[epoch12, step78]: loss 3.900144
[epoch12, step79]: loss 0.813410
[epoch12, step80]: loss 5.880532
[epoch12, step81]: loss 3.898233
[epoch12, step82]: loss 5.376028
[epoch12, step83]: loss 20.906334
[epoch12, step84]: loss 3.266015
[epoch12, step85]: loss 1.563818
[epoch12, step86]: loss 1.627043
[epoch12, step87]: loss 9.082604
[epoch12, step88]: loss 2.304059
[epoch12, step89]: loss 13.217956
[epoch12, step90]: loss 2.355465
[epoch12, step91]: loss 5.848418
[epoch12, step92]: loss 16.660063
[epoch12, step93]: loss 15.068112
[epoch12, step94]: loss 6.786316
[epoch12, step95]: loss 0.857894
[epoch12, step96]: loss 1.015802
[epoch12, step97]: loss 1.846115
[epoch12, step98]: loss 2.978801
[epoch12, step99]: loss 1.220133
[epoch12, step100]: loss 4.762628
[epoch12, step101]: loss 4.039942
[epoch12, step102]: loss 1.752451
[epoch12, step103]: loss 0.730327
[epoch12, step104]: loss 5.268990
[epoch12, step105]: loss 0.675123
[epoch12, step106]: loss 1.224304
[epoch12, step107]: loss 2.743143
[epoch12, step108]: loss 2.248110
[epoch12, step109]: loss 1.289379
[epoch12, step110]: loss 0.963486
[epoch12, step111]: loss 4.190395
[epoch12, step112]: loss 5.728610
[epoch12, step113]: loss 1.124293
[epoch12, step114]: loss 1.198613
[epoch12, step115]: loss 2.069066
[epoch12, step116]: loss 1.109085
[epoch12, step117]: loss 3.254575
[epoch12, step118]: loss 4.444900
[epoch12, step119]: loss 11.680598
[epoch12, step120]: loss 8.546965
[epoch12, step121]: loss 10.114895
[epoch12, step122]: loss 1.868825
[epoch12, step123]: loss 1.317553
[epoch12, step124]: loss 10.630390
[epoch12, step125]: loss 19.879576
[epoch12, step126]: loss 1.223587
[epoch12, step127]: loss 9.526459
[epoch12, step128]: loss 4.363866
[epoch12, step129]: loss 9.092719
[epoch12, step130]: loss 8.710069
[epoch12, step131]: loss 1.162665
[epoch12, step132]: loss 2.502232
[epoch12, step133]: loss 4.736837
[epoch12, step134]: loss 0.960131
[epoch12, step135]: loss 1.434429
[epoch12, step136]: loss 0.730769
[epoch12, step137]: loss 1.043729
[epoch12, step138]: loss 1.004155
[epoch12, step139]: loss 2.875650
[epoch12, step140]: loss 1.935317
[epoch12, step141]: loss 1.850322
[epoch12, step142]: loss 10.575772
[epoch12, step143]: loss 2.919772
[epoch12, step144]: loss 9.222932
[epoch12, step145]: loss 0.897256
[epoch12, step146]: loss 0.850059
[epoch12, step147]: loss 1.345908
[epoch12, step148]: loss 7.997252
[epoch12, step149]: loss 1.963276
[epoch12, step150]: loss 1.955583
[epoch12, step151]: loss 1.183261
[epoch12, step152]: loss 9.716012
[epoch12, step153]: loss 4.003096
[epoch12, step154]: loss 1.603324
[epoch12, step155]: loss 5.387975
[epoch12, step156]: loss 3.591102
[epoch12, step157]: loss 8.516608
[epoch12, step158]: loss 0.932096
[epoch12, step159]: loss 1.603857
[epoch12, step160]: loss 19.744743
[epoch12, step161]: loss 7.866754
[epoch12, step162]: loss 10.213305
[epoch12, step163]: loss 1.972740
[epoch12, step164]: loss 2.435404
[epoch12, step165]: loss 1.456564
[epoch12, step166]: loss 1.990820
[epoch12, step167]: loss 1.238742
[epoch12, step168]: loss 1.006003
[epoch12, step169]: loss 1.459781
[epoch12, step170]: loss 2.953322
[epoch12, step171]: loss 11.583881
[epoch12, step172]: loss 1.305404
[epoch12, step173]: loss 2.143739
[epoch12, step174]: loss 3.390663
[epoch12, step175]: loss 1.822170
[epoch12, step176]: loss 7.659970
[epoch12, step177]: loss 0.765716
[epoch12, step178]: loss 3.633293
[epoch12, step179]: loss 2.764943
[epoch12, step180]: loss 1.633546
[epoch12, step181]: loss 8.528176
[epoch12, step182]: loss 3.346826
[epoch12, step183]: loss 1.062325
[epoch12, step184]: loss 1.331392
[epoch12, step185]: loss 2.077336
[epoch12, step186]: loss 10.658485
[epoch12, step187]: loss 2.667818
[epoch12, step188]: loss 4.667605
[epoch12, step189]: loss 6.210286
[epoch12, step190]: loss 1.347907
[epoch12, step191]: loss 1.633271
[epoch12, step192]: loss 1.051238
[epoch12, step193]: loss 7.547445
[epoch12, step194]: loss 10.782057
[epoch12, step195]: loss 7.418546
[epoch12, step196]: loss 0.675959
[epoch12, step197]: loss 16.505850
[epoch12, step198]: loss 2.514217
[epoch12, step199]: loss 18.791372
[epoch12, step200]: loss 1.937548
[epoch12, step201]: loss 2.870249
[epoch12, step202]: loss 5.820144
[epoch12, step203]: loss 3.534448
[epoch12, step204]: loss 4.101453
[epoch12, step205]: loss 8.229402
[epoch12, step206]: loss 0.780984
[epoch12, step207]: loss 2.745711
[epoch12, step208]: loss 0.952504
[epoch12, step209]: loss 12.192047
[epoch12, step210]: loss 3.430980
[epoch12, step211]: loss 6.364372
[epoch12, step212]: loss 0.976244
[epoch12, step213]: loss 3.318696
[epoch12, step214]: loss 0.963986
[epoch12, step215]: loss 8.391181
[epoch12, step216]: loss 12.867861
[epoch12, step217]: loss 3.179663
[epoch12, step218]: loss 0.921673
[epoch12, step219]: loss 0.754210
[epoch12, step220]: loss 1.310690
[epoch12, step221]: loss 1.627707
[epoch12, step222]: loss 1.426414
[epoch12, step223]: loss 1.621906
[epoch12, step224]: loss 17.520691
[epoch12, step225]: loss 6.224211
[epoch12, step226]: loss 3.326965
[epoch12, step227]: loss 5.555443
[epoch12, step228]: loss 9.346311
[epoch12, step229]: loss 2.555482
[epoch12, step230]: loss 6.872975
[epoch12, step231]: loss 2.806211
[epoch12, step232]: loss 4.489472
[epoch12, step233]: loss 11.342422
[epoch12, step234]: loss 2.570162
[epoch12, step235]: loss 1.878248
[epoch12, step236]: loss 0.942136
[epoch12, step237]: loss 0.989720
[epoch12, step238]: loss 1.726722
[epoch12, step239]: loss 1.932497
[epoch12, step240]: loss 11.374368
[epoch12, step241]: loss 5.645656
[epoch12, step242]: loss 11.560899
[epoch12, step243]: loss 26.463795
[epoch12, step244]: loss 1.568923
[epoch12, step245]: loss 1.984921
[epoch12, step246]: loss 0.947943
[epoch12, step247]: loss 12.877525
[epoch12, step248]: loss 8.585886
[epoch12, step249]: loss 3.442292
[epoch12, step250]: loss 7.382627
[epoch12, step251]: loss 3.587717
[epoch12, step252]: loss 0.939937
[epoch12, step253]: loss 1.315396
[epoch12, step254]: loss 12.408163
[epoch12, step255]: loss 2.158149
[epoch12, step256]: loss 2.814442
[epoch12, step257]: loss 5.192694
[epoch12, step258]: loss 6.573338
[epoch12, step259]: loss 2.416331
[epoch12, step260]: loss 3.077057
[epoch12, step261]: loss 2.287394
[epoch12, step262]: loss 1.478738
[epoch12, step263]: loss 3.593346
[epoch12, step264]: loss 2.254170
[epoch12, step265]: loss 1.648063
[epoch12, step266]: loss 3.229419
[epoch12, step267]: loss 11.526204
[epoch12, step268]: loss 0.988582
[epoch12, step269]: loss 12.344239
[epoch12, step270]: loss 11.896556
[epoch12, step271]: loss 1.860647
[epoch12, step272]: loss 15.589761
[epoch12, step273]: loss 13.875139
[epoch12, step274]: loss 2.466039
[epoch12, step275]: loss 6.918486
[epoch12, step276]: loss 2.931275
[epoch12, step277]: loss 3.794456
[epoch12, step278]: loss 4.953594
[epoch12, step279]: loss 1.371351
[epoch12, step280]: loss 2.957290
[epoch12, step281]: loss 1.321983
[epoch12, step282]: loss 9.067899
[epoch12, step283]: loss 4.169760
[epoch12, step284]: loss 1.629879
[epoch12, step285]: loss 5.204750
[epoch12, step286]: loss 1.086048
[epoch12, step287]: loss 0.827794
[epoch12, step288]: loss 11.465371
[epoch12, step289]: loss 1.975276
[epoch12, step290]: loss 0.816407
[epoch12, step291]: loss 5.087348
[epoch12, step292]: loss 1.761916
[epoch12, step293]: loss 7.665426
[epoch12, step294]: loss 1.853526
[epoch12, step295]: loss 1.567837
[epoch12, step296]: loss 4.927201
[epoch12, step297]: loss 0.981626
[epoch12, step298]: loss 2.042778
[epoch12, step299]: loss 2.108225
[epoch12, step300]: loss 0.927277
[epoch12, step301]: loss 1.251517
[epoch12, step302]: loss 0.996995
[epoch12, step303]: loss 24.621847
[epoch12, step304]: loss 2.999305
[epoch12, step305]: loss 1.634631
[epoch12, step306]: loss 17.674131
[epoch12, step307]: loss 2.509934
[epoch12, step308]: loss 10.189754
[epoch12, step309]: loss 10.018760
[epoch12, step310]: loss 5.055373
[epoch12, step311]: loss 6.529109
[epoch12, step312]: loss 2.266976
[epoch12, step313]: loss 1.846270
[epoch12, step314]: loss 13.982277
[epoch12, step315]: loss 2.104228
[epoch12, step316]: loss 4.269882
[epoch12, step317]: loss 3.541469
[epoch12, step318]: loss 12.095823
[epoch12, step319]: loss 1.331456
[epoch12, step320]: loss 3.443106
[epoch12, step321]: loss 27.651154
[epoch12, step322]: loss 3.727551
[epoch12, step323]: loss 13.003414
[epoch12, step324]: loss 9.252653
[epoch12, step325]: loss 18.786310
[epoch12, step326]: loss 1.144298
[epoch12, step327]: loss 1.275383
[epoch12, step328]: loss 3.410143
[epoch12, step329]: loss 1.500293
[epoch12, step330]: loss 1.917645
[epoch12, step331]: loss 6.055381
[epoch12, step332]: loss 0.946961
[epoch12, step333]: loss 1.733241
[epoch12, step334]: loss 1.697814
[epoch12, step335]: loss 2.399040
[epoch12, step336]: loss 9.552652
[epoch12, step337]: loss 9.483717
[epoch12, step338]: loss 1.941209
[epoch12, step339]: loss 6.066860
[epoch12, step340]: loss 1.322084
[epoch12, step341]: loss 1.125654
[epoch12, step342]: loss 10.000244
[epoch12, step343]: loss 0.845145
[epoch12, step344]: loss 1.515233
[epoch12, step345]: loss 7.505998
[epoch12, step346]: loss 1.842322
[epoch12, step347]: loss 9.251322
[epoch12, step348]: loss 0.946525
[epoch12, step349]: loss 1.038779
[epoch12, step350]: loss 2.253393
[epoch12, step351]: loss 1.630533
[epoch12, step352]: loss 7.843325
[epoch12, step353]: loss 1.218091
[epoch12, step354]: loss 4.744590
[epoch12, step355]: loss 8.327004
[epoch12, step356]: loss 1.557949
[epoch12, step357]: loss 2.533180
[epoch12, step358]: loss 1.015101
[epoch12, step359]: loss 12.426390
[epoch12, step360]: loss 5.378296
[epoch12, step361]: loss 3.198634
[epoch12, step362]: loss 10.982985
[epoch12, step363]: loss 1.769617
[epoch12, step364]: loss 1.833762
[epoch12, step365]: loss 14.520237
[epoch12, step366]: loss 7.906114
[epoch12, step367]: loss 1.197623
[epoch12, step368]: loss 1.203485
[epoch12, step369]: loss 0.792175
[epoch12, step370]: loss 1.559307
[epoch12, step371]: loss 1.646828
[epoch12, step372]: loss 1.317185
[epoch12, step373]: loss 1.190036
[epoch12, step374]: loss 8.069793
[epoch12, step375]: loss 1.060593
[epoch12, step376]: loss 1.705151
[epoch12, step377]: loss 1.380375
[epoch12, step378]: loss 11.867986
[epoch12, step379]: loss 5.662191
[epoch12, step380]: loss 1.067443
[epoch12, step381]: loss 10.693936
[epoch12, step382]: loss 1.327296
[epoch12, step383]: loss 1.017772
[epoch12, step384]: loss 9.385794
[epoch12, step385]: loss 5.404732
[epoch12, step386]: loss 13.690772
[epoch12, step387]: loss 9.916613
[epoch12, step388]: loss 2.586741
[epoch12, step389]: loss 11.477727
[epoch12, step390]: loss 0.824779
[epoch12, step391]: loss 1.404008
[epoch12, step392]: loss 1.428329
[epoch12, step393]: loss 1.571632
[epoch12, step394]: loss 0.807011
[epoch12, step395]: loss 2.245053
[epoch12, step396]: loss 3.186404
[epoch12, step397]: loss 0.773414
[epoch12, step398]: loss 2.873096
[epoch12, step399]: loss 1.107672
[epoch12, step400]: loss 7.099198
[epoch12, step401]: loss 9.072163
[epoch12, step402]: loss 7.071334
[epoch12, step403]: loss 4.868466
[epoch12, step404]: loss 1.172652
[epoch12, step405]: loss 17.600618
[epoch12, step406]: loss 1.973803
[epoch12, step407]: loss 3.232318
[epoch12, step408]: loss 4.874826
[epoch12, step409]: loss 11.681740
[epoch12, step410]: loss 1.567269
[epoch12, step411]: loss 1.540612
[epoch12, step412]: loss 1.354663
[epoch12, step413]: loss 3.536258
[epoch12, step414]: loss 0.703940
[epoch12, step415]: loss 8.479551
[epoch12, step416]: loss 2.501745
[epoch12, step417]: loss 4.103176
[epoch12, step418]: loss 2.524887
[epoch12, step419]: loss 1.166510
[epoch12, step420]: loss 13.812218
[epoch12, step421]: loss 13.273483
[epoch12, step422]: loss 8.229596
[epoch12, step423]: loss 9.570355
[epoch12, step424]: loss 11.122776
[epoch12, step425]: loss 2.083577
[epoch12, step426]: loss 3.173857
[epoch12, step427]: loss 3.456196
[epoch12, step428]: loss 3.141755
[epoch12, step429]: loss 2.205042
[epoch12, step430]: loss 0.924268
[epoch12, step431]: loss 8.492750
[epoch12, step432]: loss 9.708879
[epoch12, step433]: loss 0.823373
[epoch12, step434]: loss 1.864779
[epoch12, step435]: loss 9.542785
[epoch12, step436]: loss 1.929848
[epoch12, step437]: loss 2.390705
[epoch12, step438]: loss 1.907953
[epoch12, step439]: loss 1.010318
[epoch12, step440]: loss 0.994055
[epoch12, step441]: loss 12.379112
[epoch12, step442]: loss 2.066856
[epoch12, step443]: loss 1.007880
[epoch12, step444]: loss 3.026421
[epoch12, step445]: loss 1.249063
[epoch12, step446]: loss 0.993633
[epoch12, step447]: loss 3.134705
[epoch12, step448]: loss 9.142752
[epoch12, step449]: loss 2.231970
[epoch12, step450]: loss 7.951827
[epoch12, step451]: loss 0.967911
[epoch12, step452]: loss 1.318097
[epoch12, step453]: loss 1.316406
[epoch12, step454]: loss 1.113480
[epoch12, step455]: loss 1.505812
[epoch12, step456]: loss 1.538777
[epoch12, step457]: loss 1.247805
[epoch12, step458]: loss 1.840788
[epoch12, step459]: loss 8.694217
[epoch12, step460]: loss 14.237978
[epoch12, step461]: loss 1.046864
[epoch12, step462]: loss 0.790421
[epoch12, step463]: loss 12.936837
[epoch12, step464]: loss 1.768522
[epoch12, step465]: loss 1.007484
[epoch12, step466]: loss 2.663684
[epoch12, step467]: loss 1.644024
[epoch12, step468]: loss 2.786056
[epoch12, step469]: loss 3.374195
[epoch12, step470]: loss 1.167055
[epoch12, step471]: loss 2.471180
[epoch12, step472]: loss 1.039147
[epoch12, step473]: loss 5.209794
[epoch12, step474]: loss 1.945301
[epoch12, step475]: loss 7.190074
[epoch12, step476]: loss 2.244390
[epoch12, step477]: loss 0.986580
[epoch12, step478]: loss 5.113543
[epoch12, step479]: loss 1.006984
[epoch12, step480]: loss 1.372995
[epoch12, step481]: loss 2.101248
[epoch12, step482]: loss 7.992867
[epoch12, step483]: loss 4.596809
[epoch12, step484]: loss 1.393346
[epoch12, step485]: loss 2.033584
[epoch12, step486]: loss 4.000825
[epoch12, step487]: loss 2.110679
[epoch12, step488]: loss 0.976686
[epoch12, step489]: loss 1.055968
[epoch12, step490]: loss 1.245113
[epoch12, step491]: loss 8.589330
[epoch12, step492]: loss 4.082922
[epoch12, step493]: loss 1.220961
[epoch12, step494]: loss 17.401424
[epoch12, step495]: loss 18.681564
[epoch12, step496]: loss 7.938817
[epoch12, step497]: loss 2.927416
[epoch12, step498]: loss 1.405383
[epoch12, step499]: loss 2.225814
[epoch12, step500]: loss 12.954127
[epoch12, step501]: loss 8.833429
[epoch12, step502]: loss 10.375315
[epoch12, step503]: loss 1.647841
[epoch12, step504]: loss 3.647526
[epoch12, step505]: loss 12.854529
[epoch12, step506]: loss 13.149182
[epoch12, step507]: loss 4.667725
[epoch12, step508]: loss 2.938565
[epoch12, step509]: loss 3.148312
[epoch12, step510]: loss 18.662310
[epoch12, step511]: loss 1.626614
[epoch12, step512]: loss 14.460739
[epoch12, step513]: loss 2.448895
[epoch12, step514]: loss 1.454360
[epoch12, step515]: loss 1.047277
[epoch12, step516]: loss 0.884575
[epoch12, step517]: loss 1.123143
[epoch12, step518]: loss 2.814335
[epoch12, step519]: loss 2.017382
[epoch12, step520]: loss 1.006292
[epoch12, step521]: loss 4.090758
[epoch12, step522]: loss 1.324906
[epoch12, step523]: loss 2.443293
[epoch12, step524]: loss 2.023007
[epoch12, step525]: loss 9.457501
[epoch12, step526]: loss 8.481228
[epoch12, step527]: loss 1.436040
[epoch12, step528]: loss 2.565986
[epoch12, step529]: loss 2.771150
[epoch12, step530]: loss 10.021665
[epoch12, step531]: loss 1.675115
[epoch12, step532]: loss 1.180901
[epoch12, step533]: loss 17.024778
[epoch12, step534]: loss 0.920944
[epoch12, step535]: loss 0.856649
[epoch12, step536]: loss 8.387697
[epoch12, step537]: loss 2.493865
[epoch12, step538]: loss 6.447098
[epoch12, step539]: loss 5.221882
[epoch12, step540]: loss 11.946277
[epoch12, step541]: loss 1.379442
[epoch12, step542]: loss 1.778098
[epoch12, step543]: loss 1.871908
[epoch12, step544]: loss 1.267879
[epoch12, step545]: loss 9.161196
[epoch12, step546]: loss 9.746259
[epoch12, step547]: loss 3.037387
[epoch12, step548]: loss 2.154100
[epoch12, step549]: loss 1.469190
[epoch12, step550]: loss 10.621295
[epoch12, step551]: loss 8.432462
[epoch12, step552]: loss 1.410592
[epoch12, step553]: loss 1.892212
[epoch12, step554]: loss 1.521978
[epoch12, step555]: loss 3.427154
[epoch12, step556]: loss 6.156588
[epoch12, step557]: loss 2.067725
[epoch12, step558]: loss 8.948750
[epoch12, step559]: loss 1.374441
[epoch12, step560]: loss 2.053355
[epoch12, step561]: loss 1.052200
[epoch12, step562]: loss 1.187504
[epoch12, step563]: loss 2.601848
[epoch12, step564]: loss 8.693686
[epoch12, step565]: loss 10.210932
[epoch12, step566]: loss 1.679517
[epoch12, step567]: loss 6.051183
[epoch12, step568]: loss 3.390290
[epoch12, step569]: loss 1.752366
[epoch12, step570]: loss 14.393418
[epoch12, step571]: loss 6.487982
[epoch12, step572]: loss 15.593431
[epoch12, step573]: loss 6.109140
[epoch12, step574]: loss 2.721474
[epoch12, step575]: loss 1.391831
[epoch12, step576]: loss 5.553758
[epoch12, step577]: loss 5.505553
[epoch12, step578]: loss 5.958748
[epoch12, step579]: loss 1.300607
[epoch12, step580]: loss 1.073632
[epoch12, step581]: loss 10.020542
[epoch12, step582]: loss 1.809797
[epoch12, step583]: loss 2.126921
[epoch12, step584]: loss 1.314600
[epoch12, step585]: loss 11.324767
[epoch12, step586]: loss 11.279100
[epoch12, step587]: loss 12.209184
[epoch12, step588]: loss 1.066621
[epoch12, step589]: loss 1.315219
[epoch12, step590]: loss 1.719187
[epoch12, step591]: loss 5.341424
[epoch12, step592]: loss 5.647887
[epoch12, step593]: loss 18.810030
[epoch12, step594]: loss 4.719120
[epoch12, step595]: loss 5.731480
[epoch12, step596]: loss 6.211915
[epoch12, step597]: loss 1.187351
[epoch12, step598]: loss 4.399812
[epoch12, step599]: loss 3.777903
[epoch12, step600]: loss 18.960609
[epoch12, step601]: loss 13.855545
[epoch12, step602]: loss 3.131803
[epoch12, step603]: loss 6.689854
[epoch12, step604]: loss 1.328565
[epoch12, step605]: loss 13.914047
[epoch12, step606]: loss 1.328592
[epoch12, step607]: loss 2.924684
[epoch12, step608]: loss 0.940489
[epoch12, step609]: loss 0.642949
[epoch12, step610]: loss 8.994360
[epoch12, step611]: loss 5.068861
[epoch12, step612]: loss 1.268420
[epoch12, step613]: loss 1.219300
[epoch12, step614]: loss 1.985258
[epoch12, step615]: loss 1.247292
[epoch12, step616]: loss 0.943427
[epoch12, step617]: loss 3.967508
[epoch12, step618]: loss 1.490291
[epoch12, step619]: loss 2.364489
[epoch12, step620]: loss 7.489276
[epoch12, step621]: loss 9.639247
[epoch12, step622]: loss 13.502649
[epoch12, step623]: loss 2.155288
[epoch12, step624]: loss 2.497064
[epoch12, step625]: loss 17.151424
[epoch12, step626]: loss 7.463345
[epoch12, step627]: loss 8.884018
[epoch12, step628]: loss 8.662009
[epoch12, step629]: loss 10.737144
[epoch12, step630]: loss 5.265689
[epoch12, step631]: loss 5.292069
[epoch12, step632]: loss 9.362967
[epoch12, step633]: loss 1.423295
[epoch12, step634]: loss 2.302960
[epoch12, step635]: loss 9.894118
[epoch12, step636]: loss 3.314285
[epoch12, step637]: loss 1.055044
[epoch12, step638]: loss 1.075107
[epoch12, step639]: loss 0.843072
[epoch12, step640]: loss 6.604343
[epoch12, step641]: loss 0.897067
[epoch12, step642]: loss 0.941908
[epoch12, step643]: loss 10.660248
[epoch12, step644]: loss 14.091380
[epoch12, step645]: loss 1.858279
[epoch12, step646]: loss 4.972208
[epoch12, step647]: loss 2.555476
[epoch12, step648]: loss 1.385078
[epoch12, step649]: loss 5.301945
[epoch12, step650]: loss 1.308601
[epoch12, step651]: loss 6.639447
[epoch12, step652]: loss 12.369749
[epoch12, step653]: loss 1.482185
[epoch12, step654]: loss 3.296930
[epoch12, step655]: loss 12.298303
[epoch12, step656]: loss 7.519765
[epoch12, step657]: loss 0.932306
[epoch12, step658]: loss 5.649721
[epoch12, step659]: loss 10.204196
[epoch12, step660]: loss 3.110694
[epoch12, step661]: loss 2.307188
[epoch12, step662]: loss 8.866155
[epoch12, step663]: loss 23.010883
[epoch12, step664]: loss 2.633326
[epoch12, step665]: loss 1.247277
[epoch12, step666]: loss 0.988725
[epoch12, step667]: loss 9.740030
[epoch12, step668]: loss 1.238809
[epoch12, step669]: loss 0.770227
[epoch12, step670]: loss 10.299961
[epoch12, step671]: loss 5.127789
[epoch12, step672]: loss 0.992703
[epoch12, step673]: loss 1.072055
[epoch12, step674]: loss 1.722728
[epoch12, step675]: loss 4.303126
[epoch12, step676]: loss 1.686188
[epoch12, step677]: loss 1.805095
[epoch12, step678]: loss 1.439926
[epoch12, step679]: loss 1.388533
[epoch12, step680]: loss 8.973949
[epoch12, step681]: loss 2.714415
[epoch12, step682]: loss 2.587617
[epoch12, step683]: loss 1.465111
[epoch12, step684]: loss 4.329732
[epoch12, step685]: loss 11.687962
[epoch12, step686]: loss 4.492097
[epoch12, step687]: loss 3.127954
[epoch12, step688]: loss 3.746161
[epoch12, step689]: loss 4.439191
[epoch12, step690]: loss 1.191324
[epoch12, step691]: loss 2.622195
[epoch12, step692]: loss 2.016686
[epoch12, step693]: loss 3.009443
[epoch12, step694]: loss 2.733724
[epoch12, step695]: loss 1.449172
[epoch12, step696]: loss 1.184140
[epoch12, step697]: loss 1.353173
[epoch12, step698]: loss 1.162032
[epoch12, step699]: loss 14.593562
[epoch12, step700]: loss 1.007089
[epoch12, step701]: loss 1.482462
[epoch12, step702]: loss 1.949425
[epoch12, step703]: loss 1.076667
[epoch12, step704]: loss 1.857858
[epoch12, step705]: loss 2.612064
[epoch12, step706]: loss 2.947886
[epoch12, step707]: loss 10.899782
[epoch12, step708]: loss 1.068405
[epoch12, step709]: loss 14.012944
[epoch12, step710]: loss 4.294776
[epoch12, step711]: loss 9.045556
[epoch12, step712]: loss 3.232092
[epoch12, step713]: loss 10.882591
[epoch12, step714]: loss 26.062551
[epoch12, step715]: loss 12.053957
[epoch12, step716]: loss 9.948440
[epoch12, step717]: loss 7.873366
[epoch12, step718]: loss 1.716636
[epoch12, step719]: loss 4.190479
[epoch12, step720]: loss 11.671379
[epoch12, step721]: loss 0.674586
[epoch12, step722]: loss 1.230143
[epoch12, step723]: loss 1.621375
[epoch12, step724]: loss 4.934519
[epoch12, step725]: loss 8.655383
[epoch12, step726]: loss 1.212873
[epoch12, step727]: loss 2.886088
[epoch12, step728]: loss 1.110475
[epoch12, step729]: loss 2.305389
[epoch12, step730]: loss 12.189656
[epoch12, step731]: loss 1.182884
[epoch12, step732]: loss 1.165422
[epoch12, step733]: loss 0.801342
[epoch12, step734]: loss 1.150827
[epoch12, step735]: loss 1.203339
[epoch12, step736]: loss 1.123257
[epoch12, step737]: loss 1.233785
[epoch12, step738]: loss 1.104897
[epoch12, step739]: loss 12.665235
[epoch12, step740]: loss 2.341022
[epoch12, step741]: loss 1.855296
[epoch12, step742]: loss 1.600466
[epoch12, step743]: loss 0.994858
[epoch12, step744]: loss 7.783017
[epoch12, step745]: loss 1.073397
[epoch12, step746]: loss 9.075427
[epoch12, step747]: loss 2.447692
[epoch12, step748]: loss 9.489426
[epoch12, step749]: loss 1.535303
[epoch12, step750]: loss 2.065606
[epoch12, step751]: loss 4.323945
[epoch12, step752]: loss 2.607600
[epoch12, step753]: loss 12.087207
[epoch12, step754]: loss 12.310560
[epoch12, step755]: loss 1.150213
[epoch12, step756]: loss 1.235060
[epoch12, step757]: loss 4.396852
[epoch12, step758]: loss 3.754074
[epoch12, step759]: loss 6.502942
[epoch12, step760]: loss 11.262474
[epoch12, step761]: loss 2.004984
[epoch12, step762]: loss 3.642677
[epoch12, step763]: loss 2.426739
[epoch12, step764]: loss 1.892636
[epoch12, step765]: loss 1.049616
[epoch12, step766]: loss 1.325679
[epoch12, step767]: loss 3.532264
[epoch12, step768]: loss 13.733840
[epoch12, step769]: loss 0.851486
[epoch12, step770]: loss 8.520294
[epoch12, step771]: loss 1.092364
[epoch12, step772]: loss 2.815461
[epoch12, step773]: loss 5.823165
[epoch12, step774]: loss 1.115637
[epoch12, step775]: loss 1.226195
[epoch12, step776]: loss 0.984076
[epoch12, step777]: loss 2.885088
[epoch12, step778]: loss 1.588981
[epoch12, step779]: loss 1.198811
[epoch12, step780]: loss 3.098550
[epoch12, step781]: loss 0.974198
[epoch12, step782]: loss 1.464677
[epoch12, step783]: loss 1.071176
[epoch12, step784]: loss 2.965742
[epoch12, step785]: loss 2.317344
[epoch12, step786]: loss 1.045104
[epoch12, step787]: loss 3.847848
[epoch12, step788]: loss 2.759177
[epoch12, step789]: loss 2.472635
[epoch12, step790]: loss 23.549068
[epoch12, step791]: loss 1.339321
[epoch12, step792]: loss 0.962499
[epoch12, step793]: loss 1.163864
[epoch12, step794]: loss 8.737001
[epoch12, step795]: loss 7.515021
[epoch12, step796]: loss 1.493877
[epoch12, step797]: loss 1.746253
[epoch12, step798]: loss 3.499774
[epoch12, step799]: loss 14.525659
[epoch12, step800]: loss 7.472032
[epoch12, step801]: loss 3.310807
[epoch12, step802]: loss 1.546550
[epoch12, step803]: loss 0.740461
[epoch12, step804]: loss 2.931374
[epoch12, step805]: loss 9.879591
[epoch12, step806]: loss 1.270242
[epoch12, step807]: loss 2.289754
[epoch12, step808]: loss 5.150479
[epoch12, step809]: loss 7.585832
[epoch12, step810]: loss 2.186789
[epoch12, step811]: loss 2.385597
[epoch12, step812]: loss 1.541006
[epoch12, step813]: loss 9.237373
[epoch12, step814]: loss 1.027658
[epoch12, step815]: loss 1.390911
[epoch12, step816]: loss 1.057408
[epoch12, step817]: loss 9.781443
[epoch12, step818]: loss 1.050036
[epoch12, step819]: loss 9.828684
[epoch12, step820]: loss 1.787724
[epoch12, step821]: loss 9.261188
[epoch12, step822]: loss 5.460614
[epoch12, step823]: loss 9.658747
[epoch12, step824]: loss 8.875445
[epoch12, step825]: loss 1.114624
[epoch12, step826]: loss 2.922620
[epoch12, step827]: loss 1.363629
[epoch12, step828]: loss 1.030621
[epoch12, step829]: loss 1.603523
[epoch12, step830]: loss 3.368309
[epoch12, step831]: loss 2.160688
[epoch12, step832]: loss 1.037138
[epoch12, step833]: loss 2.110319
[epoch12, step834]: loss 2.382506
[epoch12, step835]: loss 1.897724
[epoch12, step836]: loss 3.255070
[epoch12, step837]: loss 1.067464
[epoch12, step838]: loss 0.992337
[epoch12, step839]: loss 11.760967
[epoch12, step840]: loss 0.958923
[epoch12, step841]: loss 0.981404
[epoch12, step842]: loss 3.778532
[epoch12, step843]: loss 8.497316
[epoch12, step844]: loss 9.548656
[epoch12, step845]: loss 4.184429
[epoch12, step846]: loss 2.093925
[epoch12, step847]: loss 1.064879
[epoch12, step848]: loss 1.461744
[epoch12, step849]: loss 10.298006
[epoch12, step850]: loss 1.240334
[epoch12, step851]: loss 2.454686
[epoch12, step852]: loss 24.819880
[epoch12, step853]: loss 2.126555
[epoch12, step854]: loss 12.159571
[epoch12, step855]: loss 4.543205
[epoch12, step856]: loss 0.805243
[epoch12, step857]: loss 5.348298
[epoch12, step858]: loss 10.708255
[epoch12, step859]: loss 1.109980
[epoch12, step860]: loss 1.665410
[epoch12, step861]: loss 1.303941
[epoch12, step862]: loss 1.730694
[epoch12, step863]: loss 0.998952
[epoch12, step864]: loss 11.399567
[epoch12, step865]: loss 1.451584
[epoch12, step866]: loss 8.107282
[epoch12, step867]: loss 5.674073
[epoch12, step868]: loss 9.261904
[epoch12, step869]: loss 0.781220
[epoch12, step870]: loss 5.287549
[epoch12, step871]: loss 1.420609
[epoch12, step872]: loss 12.809676
[epoch12, step873]: loss 2.457247
[epoch12, step874]: loss 1.105363
[epoch12, step875]: loss 2.778069
[epoch12, step876]: loss 0.957926
[epoch12, step877]: loss 9.371299
[epoch12, step878]: loss 14.887771
[epoch12, step879]: loss 1.770713
[epoch12, step880]: loss 1.235380
[epoch12, step881]: loss 9.304535
[epoch12, step882]: loss 0.793964
[epoch12, step883]: loss 1.077464
[epoch12, step884]: loss 12.400217
[epoch12, step885]: loss 1.565496
[epoch12, step886]: loss 3.393075
[epoch12, step887]: loss 7.875908
[epoch12, step888]: loss 16.761450
[epoch12, step889]: loss 1.467715
[epoch12, step890]: loss 11.458558
[epoch12, step891]: loss 3.424751
[epoch12, step892]: loss 2.257206
[epoch12, step893]: loss 1.846722
[epoch12, step894]: loss 1.416684
[epoch12, step895]: loss 1.779680
[epoch12, step896]: loss 1.124042
[epoch12, step897]: loss 14.883264
[epoch12, step898]: loss 1.879764
[epoch12, step899]: loss 0.940530
[epoch12, step900]: loss 1.208859
[epoch12, step901]: loss 3.927078
[epoch12, step902]: loss 2.286131
[epoch12, step903]: loss 19.978476
[epoch12, step904]: loss 7.511827
[epoch12, step905]: loss 1.376466
[epoch12, step906]: loss 9.859715
[epoch12, step907]: loss 3.113316
[epoch12, step908]: loss 14.058125
[epoch12, step909]: loss 6.840980
[epoch12, step910]: loss 1.830724
[epoch12, step911]: loss 6.961145
[epoch12, step912]: loss 0.864790
[epoch12, step913]: loss 4.409492
[epoch12, step914]: loss 11.023462
[epoch12, step915]: loss 2.257756
[epoch12, step916]: loss 8.261051
[epoch12, step917]: loss 1.544789
[epoch12, step918]: loss 1.435617
[epoch12, step919]: loss 8.194095
[epoch12, step920]: loss 0.951852
[epoch12, step921]: loss 15.940816
[epoch12, step922]: loss 2.983662
[epoch12, step923]: loss 3.338406
[epoch12, step924]: loss 1.726411
[epoch12, step925]: loss 6.509599
[epoch12, step926]: loss 8.312835
[epoch12, step927]: loss 15.537886
[epoch12, step928]: loss 1.319283
[epoch12, step929]: loss 0.813990
[epoch12, step930]: loss 1.221598
[epoch12, step931]: loss 1.954194
[epoch12, step932]: loss 0.783488
[epoch12, step933]: loss 11.053729
[epoch12, step934]: loss 2.006786
[epoch12, step935]: loss 2.737727
[epoch12, step936]: loss 1.711683
[epoch12, step937]: loss 0.678532
[epoch12, step938]: loss 1.997366
[epoch12, step939]: loss 8.357162
[epoch12, step940]: loss 1.103194
[epoch12, step941]: loss 4.716193
[epoch12, step942]: loss 4.892001
[epoch12, step943]: loss 1.796165
[epoch12, step944]: loss 0.743183
[epoch12, step945]: loss 2.137356
[epoch12, step946]: loss 0.714457
[epoch12, step947]: loss 0.989821
[epoch12, step948]: loss 7.902387
[epoch12, step949]: loss 7.261124
[epoch12, step950]: loss 1.129209
[epoch12, step951]: loss 0.900303
[epoch12, step952]: loss 0.989590
[epoch12, step953]: loss 4.911284
[epoch12, step954]: loss 0.931543
[epoch12, step955]: loss 3.950870
[epoch12, step956]: loss 1.445013
[epoch12, step957]: loss 0.753762
[epoch12, step958]: loss 1.437308
[epoch12, step959]: loss 1.122246
[epoch12, step960]: loss 4.308092
[epoch12, step961]: loss 1.336367
[epoch12, step962]: loss 6.058312
[epoch12, step963]: loss 4.989862
[epoch12, step964]: loss 5.987264
[epoch12, step965]: loss 4.679693
[epoch12, step966]: loss 2.544357
[epoch12, step967]: loss 5.418438
[epoch12, step968]: loss 1.254555
[epoch12, step969]: loss 1.025478
[epoch12, step970]: loss 6.596193
[epoch12, step971]: loss 1.692709
[epoch12, step972]: loss 1.718123
[epoch12, step973]: loss 9.340570
[epoch12, step974]: loss 5.686179
[epoch12, step975]: loss 2.436246
[epoch12, step976]: loss 3.482173
[epoch12, step977]: loss 2.415715
[epoch12, step978]: loss 9.585012
[epoch12, step979]: loss 1.287166
[epoch12, step980]: loss 9.177547
[epoch12, step981]: loss 3.665884
[epoch12, step982]: loss 3.132170
[epoch12, step983]: loss 9.771188
[epoch12, step984]: loss 9.416089
[epoch12, step985]: loss 8.885061
[epoch12, step986]: loss 4.541951
[epoch12, step987]: loss 2.067452
[epoch12, step988]: loss 2.236003
[epoch12, step989]: loss 1.439392
[epoch12, step990]: loss 12.208529
[epoch12, step991]: loss 8.515762
[epoch12, step992]: loss 8.150951
[epoch12, step993]: loss 8.088841
[epoch12, step994]: loss 2.252426
[epoch12, step995]: loss 5.703986
[epoch12, step996]: loss 1.091788
[epoch12, step997]: loss 1.058692
[epoch12, step998]: loss 4.027516
[epoch12, step999]: loss 2.025156
[epoch12, step1000]: loss 1.452124
[epoch12, step1001]: loss 1.724554
[epoch12, step1002]: loss 3.734333
[epoch12, step1003]: loss 13.983867
[epoch12, step1004]: loss 1.521627
[epoch12, step1005]: loss 1.740080
[epoch12, step1006]: loss 2.800730
[epoch12, step1007]: loss 10.929260
[epoch12, step1008]: loss 0.976930
[epoch12, step1009]: loss 1.862150
[epoch12, step1010]: loss 5.390052
[epoch12, step1011]: loss 11.023202
[epoch12, step1012]: loss 0.616246
[epoch12, step1013]: loss 2.018797
[epoch12, step1014]: loss 0.795406
[epoch12, step1015]: loss 4.004937
[epoch12, step1016]: loss 1.439560
[epoch12, step1017]: loss 2.273404
[epoch12, step1018]: loss 0.928606
[epoch12, step1019]: loss 1.428956
[epoch12, step1020]: loss 12.044930
[epoch12, step1021]: loss 0.767391
[epoch12, step1022]: loss 14.265101
[epoch12, step1023]: loss 1.179055
[epoch12, step1024]: loss 1.139742
[epoch12, step1025]: loss 5.674832
[epoch12, step1026]: loss 1.633663
[epoch12, step1027]: loss 2.029043
[epoch12, step1028]: loss 12.389249
[epoch12, step1029]: loss 2.973506
[epoch12, step1030]: loss 0.983248
[epoch12, step1031]: loss 2.497621
[epoch12, step1032]: loss 1.450586
[epoch12, step1033]: loss 0.745631
[epoch12, step1034]: loss 12.093273
[epoch12, step1035]: loss 1.735556
[epoch12, step1036]: loss 8.396806
[epoch12, step1037]: loss 1.342378
[epoch12, step1038]: loss 6.683747
[epoch12, step1039]: loss 0.989720
[epoch12, step1040]: loss 2.145731
[epoch12, step1041]: loss 1.207131
[epoch12, step1042]: loss 6.813441
[epoch12, step1043]: loss 24.929440
[epoch12, step1044]: loss 1.621534
[epoch12, step1045]: loss 6.024835
[epoch12, step1046]: loss 2.006170
[epoch12, step1047]: loss 13.254496
[epoch12, step1048]: loss 3.835311
[epoch12, step1049]: loss 8.818527
[epoch12, step1050]: loss 7.811047
[epoch12, step1051]: loss 22.490269
[epoch12, step1052]: loss 19.422663
[epoch12, step1053]: loss 1.157773
[epoch12, step1054]: loss 9.480971
[epoch12, step1055]: loss 1.147880
[epoch12, step1056]: loss 13.595501
[epoch12, step1057]: loss 3.937297
[epoch12, step1058]: loss 3.796057
[epoch12, step1059]: loss 3.254192
[epoch12, step1060]: loss 3.177887
[epoch12, step1061]: loss 1.251345
[epoch12, step1062]: loss 9.068251
[epoch12, step1063]: loss 7.929543
[epoch12, step1064]: loss 3.994485
[epoch12, step1065]: loss 1.613021
[epoch12, step1066]: loss 1.483826
[epoch12, step1067]: loss 2.112155
[epoch12, step1068]: loss 7.707697
[epoch12, step1069]: loss 0.981850
[epoch12, step1070]: loss 1.514441
[epoch12, step1071]: loss 1.775652
[epoch12, step1072]: loss 0.851198
[epoch12, step1073]: loss 1.547360
[epoch12, step1074]: loss 5.765162
[epoch12, step1075]: loss 11.680522
[epoch12, step1076]: loss 3.189520
[epoch12, step1077]: loss 1.268972
[epoch12, step1078]: loss 4.399619
[epoch12, step1079]: loss 5.854444
[epoch12, step1080]: loss 1.178115
[epoch12, step1081]: loss 1.509010
[epoch12, step1082]: loss 9.451151
[epoch12, step1083]: loss 10.521325
[epoch12, step1084]: loss 10.516324
[epoch12, step1085]: loss 3.386272
[epoch12, step1086]: loss 2.123807
[epoch12, step1087]: loss 3.430227
[epoch12, step1088]: loss 9.214629
[epoch12, step1089]: loss 8.038409
[epoch12, step1090]: loss 1.267060
[epoch12, step1091]: loss 0.800408
[epoch12, step1092]: loss 18.250948
[epoch12, step1093]: loss 8.280832
[epoch12, step1094]: loss 1.918449
[epoch12, step1095]: loss 3.106792
[epoch12, step1096]: loss 1.475415
[epoch12, step1097]: loss 3.461060
[epoch12, step1098]: loss 3.027452
[epoch12, step1099]: loss 1.932934
[epoch12, step1100]: loss 8.724038
[epoch12, step1101]: loss 1.747022
[epoch12, step1102]: loss 0.613698
[epoch12, step1103]: loss 2.517697
[epoch12, step1104]: loss 10.468488
[epoch12, step1105]: loss 10.290353
[epoch12, step1106]: loss 1.408339
[epoch12, step1107]: loss 1.532043
[epoch12, step1108]: loss 1.895345
[epoch12, step1109]: loss 2.576061
[epoch12, step1110]: loss 8.647102
[epoch12, step1111]: loss 8.348653
[epoch12, step1112]: loss 2.444612
[epoch12, step1113]: loss 10.117597
[epoch12, step1114]: loss 1.453805
[epoch12, step1115]: loss 1.298395
[epoch12, step1116]: loss 1.507248
[epoch12, step1117]: loss 1.485735
[epoch12, step1118]: loss 12.447975
[epoch12, step1119]: loss 1.514324
[epoch12, step1120]: loss 9.418139
[epoch12, step1121]: loss 0.979012
[epoch12, step1122]: loss 1.258744
[epoch12, step1123]: loss 0.878527
[epoch12, step1124]: loss 2.367782
[epoch12, step1125]: loss 10.351721
[epoch12, step1126]: loss 2.577139
[epoch12, step1127]: loss 0.865518
[epoch12, step1128]: loss 1.150224
[epoch12, step1129]: loss 0.900314
[epoch12, step1130]: loss 1.074982
[epoch12, step1131]: loss 5.680673
[epoch12, step1132]: loss 1.323953
[epoch12, step1133]: loss 3.885718
[epoch12, step1134]: loss 9.794827
[epoch12, step1135]: loss 1.365501
[epoch12, step1136]: loss 11.943172
[epoch12, step1137]: loss 3.697869
[epoch12, step1138]: loss 8.708447
[epoch12, step1139]: loss 2.993670
[epoch12, step1140]: loss 1.116338
[epoch12, step1141]: loss 3.356164
[epoch12, step1142]: loss 8.091265
[epoch12, step1143]: loss 10.513689
[epoch12, step1144]: loss 2.247069
[epoch12, step1145]: loss 14.122012
[epoch12, step1146]: loss 1.372462
[epoch12, step1147]: loss 1.483795
[epoch12, step1148]: loss 0.886411
[epoch12, step1149]: loss 1.076785
[epoch12, step1150]: loss 0.870233
[epoch12, step1151]: loss 11.450625
[epoch12, step1152]: loss 1.072995
[epoch12, step1153]: loss 1.343094
[epoch12, step1154]: loss 10.265764
[epoch12, step1155]: loss 1.631232
[epoch12, step1156]: loss 10.854409
[epoch12, step1157]: loss 2.185319
[epoch12, step1158]: loss 1.189874
[epoch12, step1159]: loss 10.304852
[epoch12, step1160]: loss 17.337578
[epoch12, step1161]: loss 25.829700
[epoch12, step1162]: loss 1.698124
[epoch12, step1163]: loss 0.968943
[epoch12, step1164]: loss 5.279182
[epoch12, step1165]: loss 8.532413
[epoch12, step1166]: loss 1.809523
[epoch12, step1167]: loss 3.113363
[epoch12, step1168]: loss 1.071226
[epoch12, step1169]: loss 2.191113
[epoch12, step1170]: loss 1.557676
[epoch12, step1171]: loss 2.036431
[epoch12, step1172]: loss 2.080365
[epoch12, step1173]: loss 9.340020
[epoch12, step1174]: loss 3.209933
[epoch12, step1175]: loss 13.087869
[epoch12, step1176]: loss 7.926099
[epoch12, step1177]: loss 9.569123
[epoch12, step1178]: loss 1.545962
[epoch12, step1179]: loss 0.677285
[epoch12, step1180]: loss 1.896737
[epoch12, step1181]: loss 4.561797
[epoch12, step1182]: loss 1.019831
[epoch12, step1183]: loss 9.408257
[epoch12, step1184]: loss 0.749079
[epoch12, step1185]: loss 9.166809
[epoch12, step1186]: loss 3.060940
[epoch12, step1187]: loss 1.136173
[epoch12, step1188]: loss 3.686751
[epoch12, step1189]: loss 6.585115
[epoch12, step1190]: loss 7.268653
[epoch12, step1191]: loss 2.639307
[epoch12, step1192]: loss 16.950005
[epoch12, step1193]: loss 1.219244
[epoch12, step1194]: loss 5.592177
[epoch12, step1195]: loss 4.954507
[epoch12, step1196]: loss 7.060222
[epoch12, step1197]: loss 3.448316
[epoch12, step1198]: loss 3.912991
[epoch12, step1199]: loss 3.423059
[epoch12, step1200]: loss 7.521694
[epoch12, step1201]: loss 1.643113
[epoch12, step1202]: loss 7.653119
[epoch12, step1203]: loss 2.164894
[epoch12, step1204]: loss 12.159145
[epoch12, step1205]: loss 2.493331
[epoch12, step1206]: loss 23.283075
[epoch12, step1207]: loss 1.623648
[epoch12, step1208]: loss 1.116282
[epoch12, step1209]: loss 8.785639
[epoch12, step1210]: loss 0.968144
[epoch12, step1211]: loss 2.289837
[epoch12, step1212]: loss 1.470751
[epoch12, step1213]: loss 2.062536
[epoch12, step1214]: loss 9.025741
[epoch12, step1215]: loss 0.800689
[epoch12, step1216]: loss 9.313177
[epoch12, step1217]: loss 7.694942
[epoch12, step1218]: loss 0.711052
[epoch12, step1219]: loss 2.618105
[epoch12, step1220]: loss 10.890131
[epoch12, step1221]: loss 8.356576
[epoch12, step1222]: loss 0.728359
[epoch12, step1223]: loss 2.355797
[epoch12, step1224]: loss 1.464358
[epoch12, step1225]: loss 10.762815
[epoch12, step1226]: loss 0.837543
[epoch12, step1227]: loss 7.456023
[epoch12, step1228]: loss 1.026867
[epoch12, step1229]: loss 2.504261
[epoch12, step1230]: loss 3.201321
[epoch12, step1231]: loss 1.593950
[epoch12, step1232]: loss 6.854195
[epoch12, step1233]: loss 1.843055
[epoch12, step1234]: loss 4.308549
[epoch12, step1235]: loss 10.916130
[epoch12, step1236]: loss 9.854679
[epoch12, step1237]: loss 2.319313
[epoch12, step1238]: loss 1.334307
[epoch12, step1239]: loss 12.018293
[epoch12, step1240]: loss 1.555980
[epoch12, step1241]: loss 1.060333
[epoch12, step1242]: loss 9.177311
[epoch12, step1243]: loss 4.339483
[epoch12, step1244]: loss 3.445572
[epoch12, step1245]: loss 0.899238
[epoch12, step1246]: loss 14.437061
[epoch12, step1247]: loss 0.846946
[epoch12, step1248]: loss 1.142782
[epoch12, step1249]: loss 1.231848
[epoch12, step1250]: loss 13.171999
[epoch12, step1251]: loss 0.909506
[epoch12, step1252]: loss 5.209277
[epoch12, step1253]: loss 0.881428
[epoch12, step1254]: loss 1.529092
[epoch12, step1255]: loss 9.294952
[epoch12, step1256]: loss 4.130337
[epoch12, step1257]: loss 1.043471
[epoch12, step1258]: loss 10.492458
[epoch12, step1259]: loss 9.085073
[epoch12, step1260]: loss 3.246446
[epoch12, step1261]: loss 2.274446
[epoch12, step1262]: loss 9.521218
[epoch12, step1263]: loss 3.241252
[epoch12, step1264]: loss 7.811362
[epoch12, step1265]: loss 4.070741
[epoch12, step1266]: loss 1.846935
[epoch12, step1267]: loss 3.199476
[epoch12, step1268]: loss 2.466468
[epoch12, step1269]: loss 8.750329
[epoch12, step1270]: loss 0.806471
[epoch12, step1271]: loss 1.768377
[epoch12, step1272]: loss 1.110305
[epoch12, step1273]: loss 1.766513
[epoch12, step1274]: loss 1.226913
[epoch12, step1275]: loss 0.929770
[epoch12, step1276]: loss 9.539940
[epoch12, step1277]: loss 1.946597
[epoch12, step1278]: loss 8.119231
[epoch12, step1279]: loss 4.510083
[epoch12, step1280]: loss 15.442101
[epoch12, step1281]: loss 7.685535
[epoch12, step1282]: loss 2.562602
[epoch12, step1283]: loss 14.037362
[epoch12, step1284]: loss 0.798962
[epoch12, step1285]: loss 1.951658
[epoch12, step1286]: loss 1.319376
[epoch12, step1287]: loss 1.513964
[epoch12, step1288]: loss 1.855922
[epoch12, step1289]: loss 0.882551
[epoch12, step1290]: loss 2.513678
[epoch12, step1291]: loss 1.352679
[epoch12, step1292]: loss 2.345119
[epoch12, step1293]: loss 3.218391
[epoch12, step1294]: loss 1.249675
[epoch12, step1295]: loss 1.385875
[epoch12, step1296]: loss 1.986430
[epoch12, step1297]: loss 5.776128
[epoch12, step1298]: loss 0.900586
[epoch12, step1299]: loss 6.223081
[epoch12, step1300]: loss 4.144497
[epoch12, step1301]: loss 17.162096
[epoch12, step1302]: loss 1.693254
[epoch12, step1303]: loss 1.074363
[epoch12, step1304]: loss 1.503774
[epoch12, step1305]: loss 2.891488
[epoch12, step1306]: loss 2.035632
[epoch12, step1307]: loss 2.398347
[epoch12, step1308]: loss 3.739373
[epoch12, step1309]: loss 0.986966
[epoch12, step1310]: loss 5.300603
[epoch12, step1311]: loss 1.345462
[epoch12, step1312]: loss 15.596761
[epoch12, step1313]: loss 0.904064
[epoch12, step1314]: loss 2.442078
[epoch12, step1315]: loss 0.861166
[epoch12, step1316]: loss 9.435901
[epoch12, step1317]: loss 2.682557
[epoch12, step1318]: loss 1.425640
[epoch12, step1319]: loss 2.714458
[epoch12, step1320]: loss 9.736917
[epoch12, step1321]: loss 0.983703
[epoch12, step1322]: loss 1.646915
[epoch12, step1323]: loss 9.479667
[epoch12, step1324]: loss 2.369025
[epoch12, step1325]: loss 1.045318
[epoch12, step1326]: loss 2.111855
[epoch12, step1327]: loss 0.707309
[epoch12, step1328]: loss 1.853638
[epoch12, step1329]: loss 10.189341
[epoch12, step1330]: loss 1.121466
[epoch12, step1331]: loss 1.374480
[epoch12, step1332]: loss 0.688276
[epoch12, step1333]: loss 11.461645
[epoch12, step1334]: loss 1.024166
[epoch12, step1335]: loss 6.787941
[epoch12, step1336]: loss 13.999045
[epoch12, step1337]: loss 12.517237
[epoch12, step1338]: loss 8.778767
[epoch12, step1339]: loss 8.614797
[epoch12, step1340]: loss 1.305787
[epoch12, step1341]: loss 3.601826
[epoch12, step1342]: loss 8.539232
[epoch12, step1343]: loss 1.046121
[epoch12, step1344]: loss 1.354870
[epoch12, step1345]: loss 4.839404
[epoch12, step1346]: loss 16.732986
[epoch12, step1347]: loss 1.063592
[epoch12, step1348]: loss 0.727382
[epoch12, step1349]: loss 1.461369
[epoch12, step1350]: loss 1.338424
[epoch12, step1351]: loss 3.423104
[epoch12, step1352]: loss 3.833811
[epoch12, step1353]: loss 1.558877
[epoch12, step1354]: loss 15.134981
[epoch12, step1355]: loss 2.049335
[epoch12, step1356]: loss 18.213066
[epoch12, step1357]: loss 1.403201
[epoch12, step1358]: loss 9.417338
[epoch12, step1359]: loss 4.686540
[epoch12, step1360]: loss 11.955057
[epoch12, step1361]: loss 2.074908
[epoch12, step1362]: loss 11.828131
[epoch12, step1363]: loss 1.234188
[epoch12, step1364]: loss 12.028172
[epoch12, step1365]: loss 2.106896
[epoch12, step1366]: loss 0.982897
[epoch12, step1367]: loss 0.819231
[epoch12, step1368]: loss 7.858345
[epoch12, step1369]: loss 9.074911
[epoch12, step1370]: loss 2.032064
[epoch12, step1371]: loss 3.965218
[epoch12, step1372]: loss 1.265705
[epoch12, step1373]: loss 1.306016
[epoch12, step1374]: loss 4.364869
[epoch12, step1375]: loss 0.834322
[epoch12, step1376]: loss 0.742652
[epoch12, step1377]: loss 3.429653
[epoch12, step1378]: loss 1.801059
[epoch12, step1379]: loss 3.309983
[epoch12, step1380]: loss 4.445936
[epoch12, step1381]: loss 14.690846
[epoch12, step1382]: loss 4.993054
[epoch12, step1383]: loss 1.426146
[epoch12, step1384]: loss 14.128928
[epoch12, step1385]: loss 11.939576
[epoch12, step1386]: loss 1.884841
[epoch12, step1387]: loss 1.513881
[epoch12, step1388]: loss 0.985277
[epoch12, step1389]: loss 0.843189
[epoch12, step1390]: loss 0.904792
[epoch12, step1391]: loss 2.161181
[epoch12, step1392]: loss 4.717010
[epoch12, step1393]: loss 1.745047
[epoch12, step1394]: loss 14.964741
[epoch12, step1395]: loss 1.753064
[epoch12, step1396]: loss 4.051971
[epoch12, step1397]: loss 0.938771
[epoch12, step1398]: loss 0.953580
[epoch12, step1399]: loss 1.099840
[epoch12, step1400]: loss 1.366923
[epoch12, step1401]: loss 3.297991
[epoch12, step1402]: loss 4.162156
[epoch12, step1403]: loss 1.790029
[epoch12, step1404]: loss 1.996187
[epoch12, step1405]: loss 8.498297
[epoch12, step1406]: loss 3.719724
[epoch12, step1407]: loss 0.853937
[epoch12, step1408]: loss 1.698876
[epoch12, step1409]: loss 10.374601
[epoch12, step1410]: loss 6.578844
[epoch12, step1411]: loss 2.122922
[epoch12, step1412]: loss 14.271807
[epoch12, step1413]: loss 1.048301
[epoch12, step1414]: loss 7.667830
[epoch12, step1415]: loss 2.964222
[epoch12, step1416]: loss 1.758649
[epoch12, step1417]: loss 11.074303
[epoch12, step1418]: loss 1.455433
[epoch12, step1419]: loss 15.685982
[epoch12, step1420]: loss 1.869737
[epoch12, step1421]: loss 3.521247
[epoch12, step1422]: loss 7.230054
[epoch12, step1423]: loss 1.744191
[epoch12, step1424]: loss 0.840996
[epoch12, step1425]: loss 2.968987
[epoch12, step1426]: loss 2.700842
[epoch12, step1427]: loss 8.803642
[epoch12, step1428]: loss 14.266036
[epoch12, step1429]: loss 2.210689
[epoch12, step1430]: loss 8.609879
[epoch12, step1431]: loss 0.997714
[epoch12, step1432]: loss 14.727218
[epoch12, step1433]: loss 8.567952
[epoch12, step1434]: loss 18.493582
[epoch12, step1435]: loss 8.612885
[epoch12, step1436]: loss 1.169886
[epoch12, step1437]: loss 1.885146
[epoch12, step1438]: loss 9.775325
[epoch12, step1439]: loss 0.887357
[epoch12, step1440]: loss 11.108584
[epoch12, step1441]: loss 0.803940
[epoch12, step1442]: loss 1.101839
[epoch12, step1443]: loss 5.144783
[epoch12, step1444]: loss 1.176707
[epoch12, step1445]: loss 1.163025
[epoch12, step1446]: loss 2.228588
[epoch12, step1447]: loss 2.843234
[epoch12, step1448]: loss 5.573591
[epoch12, step1449]: loss 4.862051
[epoch12, step1450]: loss 2.775704
[epoch12, step1451]: loss 0.661193
[epoch12, step1452]: loss 10.869393
[epoch12, step1453]: loss 14.770779
[epoch12, step1454]: loss 2.741388
[epoch12, step1455]: loss 2.019024
[epoch12, step1456]: loss 10.846760
[epoch12, step1457]: loss 11.448563
[epoch12, step1458]: loss 4.533181
[epoch12, step1459]: loss 6.650688
[epoch12, step1460]: loss 0.787646
[epoch12, step1461]: loss 11.638667
[epoch12, step1462]: loss 12.458665
[epoch12, step1463]: loss 0.687794
[epoch12, step1464]: loss 5.414883
[epoch12, step1465]: loss 19.805126
[epoch12, step1466]: loss 8.951355
[epoch12, step1467]: loss 0.928433
[epoch12, step1468]: loss 6.932745
[epoch12, step1469]: loss 1.156466
[epoch12, step1470]: loss 23.249744
[epoch12, step1471]: loss 2.694283
[epoch12, step1472]: loss 1.155033
[epoch12, step1473]: loss 2.177111
[epoch12, step1474]: loss 7.087417
[epoch12, step1475]: loss 7.591962
[epoch12, step1476]: loss 1.651561
[epoch12, step1477]: loss 1.938003
[epoch12, step1478]: loss 1.415257
[epoch12, step1479]: loss 1.336854
[epoch12, step1480]: loss 16.780851
[epoch12, step1481]: loss 12.849205
[epoch12, step1482]: loss 1.258520
[epoch12, step1483]: loss 1.819266
[epoch12, step1484]: loss 1.292934
[epoch12, step1485]: loss 3.202466
[epoch12, step1486]: loss 0.849781
[epoch12, step1487]: loss 1.762711
[epoch12, step1488]: loss 2.060126
[epoch12, step1489]: loss 3.315458
[epoch12, step1490]: loss 1.115952
[epoch12, step1491]: loss 1.861934
[epoch12, step1492]: loss 4.709342
[epoch12, step1493]: loss 6.749223
[epoch12, step1494]: loss 1.300660
[epoch12, step1495]: loss 0.917433
[epoch12, step1496]: loss 4.850442
[epoch12, step1497]: loss 4.125581
[epoch12, step1498]: loss 7.631577
[epoch12, step1499]: loss 1.362756
[epoch12, step1500]: loss 1.050446
[epoch12, step1501]: loss 3.516174
[epoch12, step1502]: loss 8.791568
[epoch12, step1503]: loss 1.356499
[epoch12, step1504]: loss 2.899185
[epoch12, step1505]: loss 22.868900
[epoch12, step1506]: loss 0.675243
[epoch12, step1507]: loss 1.168567
[epoch12, step1508]: loss 1.477876
[epoch12, step1509]: loss 5.455809
[epoch12, step1510]: loss 6.025065
[epoch12, step1511]: loss 8.509647
[epoch12, step1512]: loss 1.598637
[epoch12, step1513]: loss 1.123282
[epoch12, step1514]: loss 0.866217
[epoch12, step1515]: loss 6.436508
[epoch12, step1516]: loss 1.219191
[epoch12, step1517]: loss 1.086455
[epoch12, step1518]: loss 5.949095
[epoch12, step1519]: loss 0.784349
[epoch12, step1520]: loss 1.717115
[epoch12, step1521]: loss 3.311412
[epoch12, step1522]: loss 10.797316
[epoch12, step1523]: loss 11.768533
[epoch12, step1524]: loss 7.507948
[epoch12, step1525]: loss 0.863389
[epoch12, step1526]: loss 1.170307
[epoch12, step1527]: loss 9.241666
[epoch12, step1528]: loss 8.910622
[epoch12, step1529]: loss 5.939907
[epoch12, step1530]: loss 20.938438
[epoch12, step1531]: loss 3.833375
[epoch12, step1532]: loss 2.408053
[epoch12, step1533]: loss 1.904818
[epoch12, step1534]: loss 1.643425
[epoch12, step1535]: loss 8.714103
[epoch12, step1536]: loss 3.644901
[epoch12, step1537]: loss 0.942456
[epoch12, step1538]: loss 0.930098
[epoch12, step1539]: loss 1.540209
[epoch12, step1540]: loss 0.809367
[epoch12, step1541]: loss 1.026785
[epoch12, step1542]: loss 10.015399
[epoch12, step1543]: loss 8.302354
[epoch12, step1544]: loss 8.394002
[epoch12, step1545]: loss 17.961523
[epoch12, step1546]: loss 10.051075
[epoch12, step1547]: loss 7.844116
[epoch12, step1548]: loss 1.565107
[epoch12, step1549]: loss 1.269802
[epoch12, step1550]: loss 4.765828
[epoch12, step1551]: loss 9.431088
[epoch12, step1552]: loss 1.128754
[epoch12, step1553]: loss 0.926170
[epoch12, step1554]: loss 1.379050
[epoch12, step1555]: loss 8.715042
[epoch12, step1556]: loss 10.277391
[epoch12, step1557]: loss 1.300814
[epoch12, step1558]: loss 1.157362
[epoch12, step1559]: loss 1.349239
[epoch12, step1560]: loss 10.399030
[epoch12, step1561]: loss 5.008506
[epoch12, step1562]: loss 0.942599
[epoch12, step1563]: loss 3.186961
[epoch12, step1564]: loss 4.783966
[epoch12, step1565]: loss 1.682736
[epoch12, step1566]: loss 2.794381
[epoch12, step1567]: loss 6.877946
[epoch12, step1568]: loss 2.550512
[epoch12, step1569]: loss 3.496815
[epoch12, step1570]: loss 1.275463
[epoch12, step1571]: loss 1.927633
[epoch12, step1572]: loss 2.185112
[epoch12, step1573]: loss 1.754049
[epoch12, step1574]: loss 2.459426
[epoch12, step1575]: loss 1.801887
[epoch12, step1576]: loss 0.791983
[epoch12, step1577]: loss 9.027709
[epoch12, step1578]: loss 1.237516
[epoch12, step1579]: loss 5.515776
[epoch12, step1580]: loss 1.003724
[epoch12, step1581]: loss 2.559413
[epoch12, step1582]: loss 0.954973
[epoch12, step1583]: loss 0.918818
[epoch12, step1584]: loss 17.984035
[epoch12, step1585]: loss 0.969425
[epoch12, step1586]: loss 1.840533
[epoch12, step1587]: loss 22.211645
[epoch12, step1588]: loss 14.851928
[epoch12, step1589]: loss 12.125370
[epoch12, step1590]: loss 1.826475
[epoch12, step1591]: loss 1.433522
[epoch12, step1592]: loss 18.086344
[epoch12, step1593]: loss 14.176474
[epoch12, step1594]: loss 9.532126
[epoch12, step1595]: loss 0.994917
[epoch12, step1596]: loss 11.982006
[epoch12, step1597]: loss 3.166456
[epoch12, step1598]: loss 1.374477
[epoch12, step1599]: loss 7.086357
[epoch12, step1600]: loss 0.978281
[epoch12, step1601]: loss 1.037549
[epoch12, step1602]: loss 4.200634
[epoch12, step1603]: loss 10.638134
[epoch12, step1604]: loss 7.411217
[epoch12, step1605]: loss 0.981053
[epoch12, step1606]: loss 0.822075
[epoch12, step1607]: loss 5.056186
[epoch12, step1608]: loss 2.831543
[epoch12, step1609]: loss 1.323401
[epoch12, step1610]: loss 2.249863
[epoch12, step1611]: loss 7.061814
[epoch12, step1612]: loss 20.913731
[epoch12, step1613]: loss 0.830288
[epoch12, step1614]: loss 6.839876
[epoch12, step1615]: loss 4.260149
[epoch12, step1616]: loss 2.996485
[epoch12, step1617]: loss 8.732896
[epoch12, step1618]: loss 1.556327
[epoch12, step1619]: loss 1.926773
[epoch12, step1620]: loss 6.853686
[epoch12, step1621]: loss 11.592915
[epoch12, step1622]: loss 3.262802
[epoch12, step1623]: loss 3.733763
[epoch12, step1624]: loss 10.220879
[epoch12, step1625]: loss 3.471092
[epoch12, step1626]: loss 1.258425
[epoch12, step1627]: loss 1.399505
[epoch12, step1628]: loss 8.771769
[epoch12, step1629]: loss 0.911434
[epoch12, step1630]: loss 9.015013
[epoch12, step1631]: loss 1.550573
[epoch12, step1632]: loss 1.874737
[epoch12, step1633]: loss 1.114186
[epoch12, step1634]: loss 11.812382
[epoch12, step1635]: loss 1.044565
[epoch12, step1636]: loss 2.188591
[epoch12, step1637]: loss 0.734906
[epoch12, step1638]: loss 1.749183
[epoch12, step1639]: loss 5.476197
[epoch12, step1640]: loss 2.323522
[epoch12, step1641]: loss 1.567878
[epoch12, step1642]: loss 3.522863
[epoch12, step1643]: loss 3.649127
[epoch12, step1644]: loss 0.943686
[epoch12, step1645]: loss 8.864314
[epoch12, step1646]: loss 11.439672
[epoch12, step1647]: loss 16.995646
[epoch12, step1648]: loss 6.239606
[epoch12, step1649]: loss 7.809597
[epoch12, step1650]: loss 1.328110
[epoch12, step1651]: loss 9.380527
[epoch12, step1652]: loss 7.410974
[epoch12, step1653]: loss 1.120182
[epoch12, step1654]: loss 1.071404
[epoch12, step1655]: loss 0.785670
[epoch12, step1656]: loss 2.193748
[epoch12, step1657]: loss 1.651263
[epoch12, step1658]: loss 4.855225
[epoch12, step1659]: loss 12.404998
[epoch12, step1660]: loss 6.457484
[epoch12, step1661]: loss 5.138758
[epoch12, step1662]: loss 1.193286
[epoch12, step1663]: loss 11.731301
[epoch12, step1664]: loss 9.203076
[epoch12, step1665]: loss 6.744037
[epoch12, step1666]: loss 1.117111
[epoch12, step1667]: loss 3.304603
[epoch12, step1668]: loss 3.733333
[epoch12, step1669]: loss 2.226099
[epoch12, step1670]: loss 8.059763
[epoch12, step1671]: loss 2.352289
[epoch12, step1672]: loss 0.791347
[epoch12, step1673]: loss 1.501563
[epoch12, step1674]: loss 20.558924
[epoch12, step1675]: loss 1.906715
[epoch12, step1676]: loss 0.631921
[epoch12, step1677]: loss 13.216109
[epoch12, step1678]: loss 7.286641
[epoch12, step1679]: loss 5.214219
[epoch12, step1680]: loss 1.945751
[epoch12, step1681]: loss 16.941923
[epoch12, step1682]: loss 2.037669
[epoch12, step1683]: loss 2.337955
[epoch12, step1684]: loss 7.862829
[epoch12, step1685]: loss 1.849649
[epoch12, step1686]: loss 21.655380
[epoch12, step1687]: loss 11.119589
[epoch12, step1688]: loss 1.536933
[epoch12, step1689]: loss 23.448172
[epoch12, step1690]: loss 9.709501
[epoch12, step1691]: loss 4.107464
[epoch12, step1692]: loss 2.210033
[epoch12, step1693]: loss 4.336450
[epoch12, step1694]: loss 7.363624
[epoch12, step1695]: loss 1.835690
[epoch12, step1696]: loss 1.258427
[epoch12, step1697]: loss 0.920922
[epoch12, step1698]: loss 0.858025
[epoch12, step1699]: loss 8.472271
[epoch12, step1700]: loss 9.824965
[epoch12, step1701]: loss 3.246994
[epoch12, step1702]: loss 0.743975
[epoch12, step1703]: loss 1.222055
[epoch12, step1704]: loss 1.271301
[epoch12, step1705]: loss 0.731191
[epoch12, step1706]: loss 3.905538
[epoch12, step1707]: loss 3.608011
[epoch12, step1708]: loss 9.597274
[epoch12, step1709]: loss 1.354263
[epoch12, step1710]: loss 8.351766
[epoch12, step1711]: loss 1.045951
[epoch12, step1712]: loss 2.159624
[epoch12, step1713]: loss 10.825932
[epoch12, step1714]: loss 4.090780
[epoch12, step1715]: loss 5.518227
[epoch12, step1716]: loss 4.368826
[epoch12, step1717]: loss 0.933922
[epoch12, step1718]: loss 1.704816
[epoch12, step1719]: loss 2.769732
[epoch12, step1720]: loss 2.681898
[epoch12, step1721]: loss 1.298801
[epoch12, step1722]: loss 1.127934
[epoch12, step1723]: loss 0.960880
[epoch12, step1724]: loss 9.277901
[epoch12, step1725]: loss 2.962130
[epoch12, step1726]: loss 1.349252
[epoch12, step1727]: loss 1.229532
[epoch12, step1728]: loss 0.971658
[epoch12, step1729]: loss 10.715093
[epoch12, step1730]: loss 1.027431
[epoch12, step1731]: loss 1.292426
[epoch12, step1732]: loss 0.579251
[epoch12, step1733]: loss 3.762643
[epoch12, step1734]: loss 9.809003
[epoch12, step1735]: loss 6.956346
[epoch12, step1736]: loss 11.067701
[epoch12, step1737]: loss 5.606040
[epoch12, step1738]: loss 1.195645
[epoch12, step1739]: loss 2.305956
[epoch12, step1740]: loss 7.995528
[epoch12, step1741]: loss 3.196747
[epoch12, step1742]: loss 3.893650
[epoch12, step1743]: loss 2.722196
[epoch12, step1744]: loss 7.764445
[epoch12, step1745]: loss 0.777732
[epoch12, step1746]: loss 5.464410
[epoch12, step1747]: loss 4.374545
[epoch12, step1748]: loss 0.966912
[epoch12, step1749]: loss 1.695635
[epoch12, step1750]: loss 5.340130
[epoch12, step1751]: loss 10.229959
[epoch12, step1752]: loss 18.016293
[epoch12, step1753]: loss 1.138687
[epoch12, step1754]: loss 3.043568
[epoch12, step1755]: loss 1.326054
[epoch12, step1756]: loss 9.391153
[epoch12, step1757]: loss 1.198311
[epoch12, step1758]: loss 10.682242
[epoch12, step1759]: loss 13.546555
[epoch12, step1760]: loss 3.264313
[epoch12, step1761]: loss 2.139854
[epoch12, step1762]: loss 1.685454
[epoch12, step1763]: loss 1.907442
[epoch12, step1764]: loss 4.335511
[epoch12, step1765]: loss 2.088662
[epoch12, step1766]: loss 3.674048
[epoch12, step1767]: loss 0.897273
[epoch12, step1768]: loss 3.633631
[epoch12, step1769]: loss 9.085402
[epoch12, step1770]: loss 23.133848
[epoch12, step1771]: loss 1.239406
[epoch12, step1772]: loss 0.923866
[epoch12, step1773]: loss 15.906575
[epoch12, step1774]: loss 1.544686
[epoch12, step1775]: loss 13.846605
[epoch12, step1776]: loss 0.900534
[epoch12, step1777]: loss 1.046120
[epoch12, step1778]: loss 1.368054
[epoch12, step1779]: loss 2.854644
[epoch12, step1780]: loss 0.939793
[epoch12, step1781]: loss 1.628460
[epoch12, step1782]: loss 1.416210
[epoch12, step1783]: loss 1.369454
[epoch12, step1784]: loss 0.786858
[epoch12, step1785]: loss 0.917022
[epoch12, step1786]: loss 1.321296
[epoch12, step1787]: loss 1.139813
[epoch12, step1788]: loss 19.428421
[epoch12, step1789]: loss 5.446978
[epoch12, step1790]: loss 0.888650
[epoch12, step1791]: loss 2.263262
[epoch12, step1792]: loss 2.042848
[epoch12, step1793]: loss 5.211067
[epoch12, step1794]: loss 1.042991
[epoch12, step1795]: loss 18.363127
[epoch12, step1796]: loss 7.950890
[epoch12, step1797]: loss 16.862478
[epoch12, step1798]: loss 4.240122
[epoch12, step1799]: loss 15.729093
[epoch12, step1800]: loss 0.888881
[epoch12, step1801]: loss 1.258671
[epoch12, step1802]: loss 1.097356
[epoch12, step1803]: loss 2.288928
[epoch12, step1804]: loss 16.641397
[epoch12, step1805]: loss 0.691927
[epoch12, step1806]: loss 1.839162
[epoch12, step1807]: loss 13.527200
[epoch12, step1808]: loss 16.963993
[epoch12, step1809]: loss 1.450772
[epoch12, step1810]: loss 1.641128
[epoch12, step1811]: loss 0.870262
[epoch12, step1812]: loss 2.820573
[epoch12, step1813]: loss 0.961108
[epoch12, step1814]: loss 4.766640
[epoch12, step1815]: loss 1.166227
[epoch12, step1816]: loss 1.030766
[epoch12, step1817]: loss 1.157719
[epoch12, step1818]: loss 1.276106
[epoch12, step1819]: loss 4.113539
[epoch12, step1820]: loss 12.168720
[epoch12, step1821]: loss 1.281478
[epoch12, step1822]: loss 12.467826
[epoch12, step1823]: loss 2.555058
[epoch12, step1824]: loss 6.107365
[epoch12, step1825]: loss 1.349318
[epoch12, step1826]: loss 7.794083
[epoch12, step1827]: loss 2.548522
[epoch12, step1828]: loss 1.185358
[epoch12, step1829]: loss 0.948633
[epoch12, step1830]: loss 1.342611
[epoch12, step1831]: loss 13.196264
[epoch12, step1832]: loss 7.994117
[epoch12, step1833]: loss 3.586968
[epoch12, step1834]: loss 2.644642
[epoch12, step1835]: loss 1.142771
[epoch12, step1836]: loss 8.866265
[epoch12, step1837]: loss 1.655138
[epoch12, step1838]: loss 1.217310
[epoch12, step1839]: loss 12.541762
[epoch12, step1840]: loss 8.201358
[epoch12, step1841]: loss 13.744934
[epoch12, step1842]: loss 0.826506
[epoch12, step1843]: loss 7.285570
[epoch12, step1844]: loss 1.109071
[epoch12, step1845]: loss 1.655200
[epoch12, step1846]: loss 0.852896
[epoch12, step1847]: loss 1.104146
[epoch12, step1848]: loss 8.851162
[epoch12, step1849]: loss 6.483439
[epoch12, step1850]: loss 0.931314
[epoch12, step1851]: loss 9.416452
[epoch12, step1852]: loss 3.218813
[epoch12, step1853]: loss 22.829300
[epoch12, step1854]: loss 4.171482
[epoch12, step1855]: loss 1.568847
[epoch12, step1856]: loss 2.238649
[epoch12, step1857]: loss 5.936553
[epoch12, step1858]: loss 4.718042
[epoch12, step1859]: loss 0.752113
[epoch12, step1860]: loss 1.113903
[epoch12, step1861]: loss 1.308154
[epoch12, step1862]: loss 6.913632
[epoch12, step1863]: loss 1.237605
[epoch12, step1864]: loss 4.297954
[epoch12, step1865]: loss 8.250626
[epoch12, step1866]: loss 1.001822
[epoch12, step1867]: loss 8.608425
[epoch12, step1868]: loss 1.573855
[epoch12, step1869]: loss 1.384392
[epoch12, step1870]: loss 14.841297
[epoch12, step1871]: loss 1.812143
[epoch12, step1872]: loss 7.736063
[epoch12, step1873]: loss 1.095441
[epoch12, step1874]: loss 1.262536
[epoch12, step1875]: loss 3.814887
[epoch12, step1876]: loss 9.031345
[epoch12, step1877]: loss 8.559166
[epoch12, step1878]: loss 1.422063
[epoch12, step1879]: loss 3.446536
[epoch12, step1880]: loss 8.818563
[epoch12, step1881]: loss 8.999250
[epoch12, step1882]: loss 2.764551
[epoch12, step1883]: loss 4.602548
[epoch12, step1884]: loss 0.902297
[epoch12, step1885]: loss 3.285744
[epoch12, step1886]: loss 6.569079
[epoch12, step1887]: loss 2.493204
[epoch12, step1888]: loss 1.350657
[epoch12, step1889]: loss 3.431700
[epoch12, step1890]: loss 1.028002
[epoch12, step1891]: loss 5.103235
[epoch12, step1892]: loss 17.643364
[epoch12, step1893]: loss 0.897321
[epoch12, step1894]: loss 9.837112
[epoch12, step1895]: loss 0.929000
[epoch12, step1896]: loss 21.603231
[epoch12, step1897]: loss 8.886731
[epoch12, step1898]: loss 3.861166
[epoch12, step1899]: loss 1.659942
[epoch12, step1900]: loss 1.259645
[epoch12, step1901]: loss 2.509232
[epoch12, step1902]: loss 1.671904
[epoch12, step1903]: loss 7.684004
[epoch12, step1904]: loss 8.853457
[epoch12, step1905]: loss 1.519470
[epoch12, step1906]: loss 1.721825
[epoch12, step1907]: loss 2.264766
[epoch12, step1908]: loss 1.149831
[epoch12, step1909]: loss 5.324929
[epoch12, step1910]: loss 4.116551
[epoch12, step1911]: loss 2.608065
[epoch12, step1912]: loss 5.964725
[epoch12, step1913]: loss 1.030841
[epoch12, step1914]: loss 1.518194
[epoch12, step1915]: loss 3.907367
[epoch12, step1916]: loss 0.958048
[epoch12, step1917]: loss 9.195024
[epoch12, step1918]: loss 16.388092
[epoch12, step1919]: loss 0.945160
[epoch12, step1920]: loss 13.082245
[epoch12, step1921]: loss 10.675523
[epoch12, step1922]: loss 7.998991
[epoch12, step1923]: loss 1.001000
[epoch12, step1924]: loss 1.647842
[epoch12, step1925]: loss 0.986895
[epoch12, step1926]: loss 1.065350
[epoch12, step1927]: loss 1.026351
[epoch12, step1928]: loss 1.161709
[epoch12, step1929]: loss 0.913609
[epoch12, step1930]: loss 2.810436
[epoch12, step1931]: loss 0.990506
[epoch12, step1932]: loss 1.945423
[epoch12, step1933]: loss 2.384271
[epoch12, step1934]: loss 2.050669
[epoch12, step1935]: loss 2.028318
[epoch12, step1936]: loss 3.574324
[epoch12, step1937]: loss 1.319600
[epoch12, step1938]: loss 14.188667
[epoch12, step1939]: loss 1.389266
[epoch12, step1940]: loss 1.141169
[epoch12, step1941]: loss 7.550623
[epoch12, step1942]: loss 24.458055
[epoch12, step1943]: loss 21.119698
[epoch12, step1944]: loss 1.051902
[epoch12, step1945]: loss 4.027515
[epoch12, step1946]: loss 8.780538
[epoch12, step1947]: loss 5.101082
[epoch12, step1948]: loss 0.899904
[epoch12, step1949]: loss 1.070337
[epoch12, step1950]: loss 12.863194
[epoch12, step1951]: loss 8.961923
[epoch12, step1952]: loss 11.658323
[epoch12, step1953]: loss 1.443648
[epoch12, step1954]: loss 8.437692
[epoch12, step1955]: loss 4.180040
[epoch12, step1956]: loss 3.038888
[epoch12, step1957]: loss 2.319252
[epoch12, step1958]: loss 1.291417
[epoch12, step1959]: loss 1.484258
[epoch12, step1960]: loss 11.369852
[epoch12, step1961]: loss 1.222004
[epoch12, step1962]: loss 5.836060
[epoch12, step1963]: loss 1.243281
[epoch12, step1964]: loss 5.273321
[epoch12, step1965]: loss 0.894198
[epoch12, step1966]: loss 1.270011
[epoch12, step1967]: loss 3.394320
[epoch12, step1968]: loss 0.896164
[epoch12, step1969]: loss 3.067364
[epoch12, step1970]: loss 8.225421
[epoch12, step1971]: loss 10.179926
[epoch12, step1972]: loss 1.438296
[epoch12, step1973]: loss 1.399590
[epoch12, step1974]: loss 0.768539
[epoch12, step1975]: loss 8.455558
[epoch12, step1976]: loss 1.839453
[epoch12, step1977]: loss 2.367771
[epoch12, step1978]: loss 1.605880
[epoch12, step1979]: loss 0.737057
[epoch12, step1980]: loss 8.230711
[epoch12, step1981]: loss 1.319028
[epoch12, step1982]: loss 11.401800
[epoch12, step1983]: loss 2.509217
[epoch12, step1984]: loss 11.664146
[epoch12, step1985]: loss 1.379911
[epoch12, step1986]: loss 1.509537
[epoch12, step1987]: loss 0.990905
[epoch12, step1988]: loss 7.480679
[epoch12, step1989]: loss 10.350823
[epoch12, step1990]: loss 18.892069
[epoch12, step1991]: loss 1.978936
[epoch12, step1992]: loss 15.396961
[epoch12, step1993]: loss 2.187892
[epoch12, step1994]: loss 2.075099
[epoch12, step1995]: loss 7.357390
[epoch12, step1996]: loss 3.333581
[epoch12, step1997]: loss 2.245174
[epoch12, step1998]: loss 1.816780
[epoch12, step1999]: loss 1.305626
[epoch12, step2000]: loss 1.062858
[epoch12, step2001]: loss 1.590823
[epoch12, step2002]: loss 1.015025
[epoch12, step2003]: loss 17.726320
[epoch12, step2004]: loss 1.073472
[epoch12, step2005]: loss 1.674151
[epoch12, step2006]: loss 1.041739
[epoch12, step2007]: loss 1.562860
[epoch12, step2008]: loss 2.494956
[epoch12, step2009]: loss 0.634442
[epoch12, step2010]: loss 3.028244
[epoch12, step2011]: loss 1.708571
[epoch12, step2012]: loss 1.840548
[epoch12, step2013]: loss 1.621915
[epoch12, step2014]: loss 1.719695
[epoch12, step2015]: loss 1.859834
[epoch12, step2016]: loss 1.986928
[epoch12, step2017]: loss 1.498098
[epoch12, step2018]: loss 0.705220
[epoch12, step2019]: loss 0.949343
[epoch12, step2020]: loss 2.214031
[epoch12, step2021]: loss 3.413184
[epoch12, step2022]: loss 13.648474
[epoch12, step2023]: loss 9.266456
[epoch12, step2024]: loss 1.612062
[epoch12, step2025]: loss 30.708683
[epoch12, step2026]: loss 4.216802
[epoch12, step2027]: loss 2.924681
[epoch12, step2028]: loss 11.821371
[epoch12, step2029]: loss 8.772504
[epoch12, step2030]: loss 17.934328
[epoch12, step2031]: loss 1.079246
[epoch12, step2032]: loss 1.006665
[epoch12, step2033]: loss 3.321337
[epoch12, step2034]: loss 8.088854
[epoch12, step2035]: loss 9.524729
[epoch12, step2036]: loss 3.398148
[epoch12, step2037]: loss 1.385907
[epoch12, step2038]: loss 2.094677
[epoch12, step2039]: loss 2.371346
[epoch12, step2040]: loss 2.351830
[epoch12, step2041]: loss 0.918887
[epoch12, step2042]: loss 1.415515
[epoch12, step2043]: loss 1.005149
[epoch12, step2044]: loss 4.820230
[epoch12, step2045]: loss 5.968109
[epoch12, step2046]: loss 13.090422
[epoch12, step2047]: loss 10.757730
[epoch12, step2048]: loss 1.398056
[epoch12, step2049]: loss 11.617286
[epoch12, step2050]: loss 14.393990
[epoch12, step2051]: loss 4.741691
[epoch12, step2052]: loss 0.877485
[epoch12, step2053]: loss 2.850036
[epoch12, step2054]: loss 10.938065
[epoch12, step2055]: loss 0.888171
[epoch12, step2056]: loss 3.149024
[epoch12, step2057]: loss 5.365188
[epoch12, step2058]: loss 0.714776
[epoch12, step2059]: loss 1.460293
[epoch12, step2060]: loss 1.388846
[epoch12, step2061]: loss 1.257912
[epoch12, step2062]: loss 0.869554
[epoch12, step2063]: loss 9.644408
[epoch12, step2064]: loss 3.706129
[epoch12, step2065]: loss 1.668672
[epoch12, step2066]: loss 7.016088
[epoch12, step2067]: loss 1.314814
[epoch12, step2068]: loss 1.321053
[epoch12, step2069]: loss 1.137410
[epoch12, step2070]: loss 11.984428
[epoch12, step2071]: loss 3.911587
[epoch12, step2072]: loss 1.957646
[epoch12, step2073]: loss 1.442403
[epoch12, step2074]: loss 9.350607
[epoch12, step2075]: loss 3.141701
[epoch12, step2076]: loss 0.744599
[epoch12, step2077]: loss 1.885845
[epoch12, step2078]: loss 3.645665
[epoch12, step2079]: loss 1.981028
[epoch12, step2080]: loss 1.549492
[epoch12, step2081]: loss 3.681726
[epoch12, step2082]: loss 0.810901
[epoch12, step2083]: loss 1.262687
[epoch12, step2084]: loss 2.135609
[epoch12, step2085]: loss 4.389615
[epoch12, step2086]: loss 1.072205
[epoch12, step2087]: loss 3.913147
[epoch12, step2088]: loss 1.309787
[epoch12, step2089]: loss 9.694942
[epoch12, step2090]: loss 1.596581
[epoch12, step2091]: loss 0.870563
[epoch12, step2092]: loss 0.909257
[epoch12, step2093]: loss 2.283313
[epoch12, step2094]: loss 2.151867
[epoch12, step2095]: loss 1.717532
[epoch12, step2096]: loss 0.814646
[epoch12, step2097]: loss 1.009618
[epoch12, step2098]: loss 9.321537
[epoch12, step2099]: loss 1.141932
[epoch12, step2100]: loss 0.788160
[epoch12, step2101]: loss 13.070021
[epoch12, step2102]: loss 2.382672
[epoch12, step2103]: loss 3.315635
[epoch12, step2104]: loss 4.545190
[epoch12, step2105]: loss 0.832623
[epoch12, step2106]: loss 5.701630
[epoch12, step2107]: loss 1.397009
[epoch12, step2108]: loss 7.865892
[epoch12, step2109]: loss 0.984838
[epoch12, step2110]: loss 7.648313
[epoch12, step2111]: loss 0.940724
[epoch12, step2112]: loss 3.258750
[epoch12, step2113]: loss 1.015239
[epoch12, step2114]: loss 0.960884
[epoch12, step2115]: loss 13.625839
[epoch12, step2116]: loss 7.118396
[epoch12, step2117]: loss 1.781007
[epoch12, step2118]: loss 1.260404
[epoch12, step2119]: loss 4.139164
[epoch12, step2120]: loss 0.900446
[epoch12, step2121]: loss 1.060419
[epoch12, step2122]: loss 0.909978
[epoch12, step2123]: loss 1.463185
[epoch12, step2124]: loss 1.536021
[epoch12, step2125]: loss 1.564031
[epoch12, step2126]: loss 9.057461
[epoch12, step2127]: loss 1.462079
[epoch12, step2128]: loss 1.057586
[epoch12, step2129]: loss 8.802180
[epoch12, step2130]: loss 17.201513
[epoch12, step2131]: loss 0.742105
[epoch12, step2132]: loss 1.586339
[epoch12, step2133]: loss 28.843185
[epoch12, step2134]: loss 14.435368
[epoch12, step2135]: loss 13.042074
[epoch12, step2136]: loss 0.869816
[epoch12, step2137]: loss 0.960192
[epoch12, step2138]: loss 2.465684
[epoch12, step2139]: loss 2.901540
[epoch12, step2140]: loss 0.872915
[epoch12, step2141]: loss 1.999631
[epoch12, step2142]: loss 8.658989
[epoch12, step2143]: loss 11.504580
[epoch12, step2144]: loss 2.087334
[epoch12, step2145]: loss 3.737580
[epoch12, step2146]: loss 6.421821
[epoch12, step2147]: loss 1.803566
[epoch12, step2148]: loss 9.776822
[epoch12, step2149]: loss 2.125280
[epoch12, step2150]: loss 21.104963
[epoch12, step2151]: loss 4.712152
[epoch12, step2152]: loss 3.695239
[epoch12, step2153]: loss 1.859052
[epoch12, step2154]: loss 1.674851
[epoch12, step2155]: loss 23.564018
[epoch12, step2156]: loss 1.329003
[epoch12, step2157]: loss 1.998089
[epoch12, step2158]: loss 2.127813
[epoch12, step2159]: loss 8.354864
[epoch12, step2160]: loss 9.653547
[epoch12, step2161]: loss 1.693895
[epoch12, step2162]: loss 0.763983
[epoch12, step2163]: loss 0.840533
[epoch12, step2164]: loss 7.657448
[epoch12, step2165]: loss 10.158422
[epoch12, step2166]: loss 1.385270
[epoch12, step2167]: loss 2.586123
[epoch12, step2168]: loss 1.026541
[epoch12, step2169]: loss 17.065033
[epoch12, step2170]: loss 0.644654
[epoch12, step2171]: loss 11.795684
[epoch12, step2172]: loss 0.745804
[epoch12, step2173]: loss 1.256654
[epoch12, step2174]: loss 1.852813
[epoch12, step2175]: loss 8.152563
[epoch12, step2176]: loss 2.547642
[epoch12, step2177]: loss 1.430328
[epoch12, step2178]: loss 2.223120
[epoch12, step2179]: loss 2.546915
[epoch12, step2180]: loss 3.120034
[epoch12, step2181]: loss 0.933815
[epoch12, step2182]: loss 2.825989
[epoch12, step2183]: loss 1.272911
[epoch12, step2184]: loss 0.757973
[epoch12, step2185]: loss 8.534472
[epoch12, step2186]: loss 1.944467
[epoch12, step2187]: loss 8.264235
[epoch12, step2188]: loss 1.502132
[epoch12, step2189]: loss 0.853435
[epoch12, step2190]: loss 8.484750
[epoch12, step2191]: loss 0.902901
[epoch12, step2192]: loss 0.808795
[epoch12, step2193]: loss 1.326580
[epoch12, step2194]: loss 2.062414
[epoch12, step2195]: loss 11.190510
[epoch12, step2196]: loss 1.497514
[epoch12, step2197]: loss 1.016076
[epoch12, step2198]: loss 20.319881
[epoch12, step2199]: loss 2.978978
[epoch12, step2200]: loss 1.106425
[epoch12, step2201]: loss 11.078063
[epoch12, step2202]: loss 1.457036
[epoch12, step2203]: loss 6.129159
[epoch12, step2204]: loss 0.809299
[epoch12, step2205]: loss 15.417578
[epoch12, step2206]: loss 3.696082
[epoch12, step2207]: loss 12.737361
[epoch12, step2208]: loss 1.822637
[epoch12, step2209]: loss 2.781334
[epoch12, step2210]: loss 5.174348
[epoch12, step2211]: loss 2.437465
[epoch12, step2212]: loss 1.070250
[epoch12, step2213]: loss 8.265403
[epoch12, step2214]: loss 8.864570
[epoch12, step2215]: loss 0.643840
[epoch12, step2216]: loss 8.384840
[epoch12, step2217]: loss 1.631263
[epoch12, step2218]: loss 2.180564
[epoch12, step2219]: loss 1.717283
[epoch12, step2220]: loss 4.653472
[epoch12, step2221]: loss 0.930193
[epoch12, step2222]: loss 1.148279
[epoch12, step2223]: loss 4.361485
[epoch12, step2224]: loss 8.379601
[epoch12, step2225]: loss 31.655354
[epoch12, step2226]: loss 1.183008
[epoch12, step2227]: loss 20.907942
[epoch12, step2228]: loss 1.474182
[epoch12, step2229]: loss 0.987815
[epoch12, step2230]: loss 4.211298
[epoch12, step2231]: loss 8.422808
[epoch12, step2232]: loss 7.922745
[epoch12, step2233]: loss 3.117404
[epoch12, step2234]: loss 1.764286
[epoch12, step2235]: loss 2.311080
[epoch12, step2236]: loss 0.963763
[epoch12, step2237]: loss 1.092452
[epoch12, step2238]: loss 9.145454
[epoch12, step2239]: loss 10.267423
[epoch12, step2240]: loss 8.330587
[epoch12, step2241]: loss 9.160501
[epoch12, step2242]: loss 1.375531
[epoch12, step2243]: loss 3.698720
[epoch12, step2244]: loss 14.065770
[epoch12, step2245]: loss 11.418464
[epoch12, step2246]: loss 3.859357
[epoch12, step2247]: loss 0.851867
[epoch12, step2248]: loss 9.425014
[epoch12, step2249]: loss 0.831530
[epoch12, step2250]: loss 1.193454
[epoch12, step2251]: loss 10.480490
[epoch12, step2252]: loss 2.421453
[epoch12, step2253]: loss 3.809713
[epoch12, step2254]: loss 1.886325
[epoch12, step2255]: loss 1.648532
[epoch12, step2256]: loss 2.172628
[epoch12, step2257]: loss 2.742495
[epoch12, step2258]: loss 0.857177
[epoch12, step2259]: loss 1.449363
[epoch12, step2260]: loss 1.293999
[epoch12, step2261]: loss 0.691942
[epoch12, step2262]: loss 14.102892
[epoch12, step2263]: loss 1.022144
[epoch12, step2264]: loss 1.360618
[epoch12, step2265]: loss 2.371638
[epoch12, step2266]: loss 1.434145
[epoch12, step2267]: loss 10.275058
[epoch12, step2268]: loss 2.909759
[epoch12, step2269]: loss 1.274052
[epoch12, step2270]: loss 3.413027
[epoch12, step2271]: loss 11.044128
[epoch12, step2272]: loss 3.037582
[epoch12, step2273]: loss 1.250220
[epoch12, step2274]: loss 0.920713
[epoch12, step2275]: loss 2.440863
[epoch12, step2276]: loss 0.840159
[epoch12, step2277]: loss 0.932659
[epoch12, step2278]: loss 1.104841
[epoch12, step2279]: loss 13.850482
[epoch12, step2280]: loss 2.202527
[epoch12, step2281]: loss 1.000307
[epoch12, step2282]: loss 1.868343
[epoch12, step2283]: loss 2.173523
[epoch12, step2284]: loss 2.227139
[epoch12, step2285]: loss 1.258091
[epoch12, step2286]: loss 3.733775
[epoch12, step2287]: loss 1.475592
[epoch12, step2288]: loss 13.116894
[epoch12, step2289]: loss 7.429555
[epoch12, step2290]: loss 12.221623
[epoch12, step2291]: loss 0.929929
[epoch12, step2292]: loss 8.202195
[epoch12, step2293]: loss 1.131257
[epoch12, step2294]: loss 0.979180
[epoch12, step2295]: loss 9.895049
[epoch12, step2296]: loss 1.105181
[epoch12, step2297]: loss 1.377893
[epoch12, step2298]: loss 1.346421
[epoch12, step2299]: loss 0.929172
[epoch12, step2300]: loss 0.931567
[epoch12, step2301]: loss 0.862241
[epoch12, step2302]: loss 0.963390
[epoch12, step2303]: loss 10.267522
[epoch12, step2304]: loss 1.359537
[epoch12, step2305]: loss 1.162495
[epoch12, step2306]: loss 1.554711
[epoch12, step2307]: loss 3.285708
[epoch12, step2308]: loss 2.443090
[epoch12, step2309]: loss 0.993045
[epoch12, step2310]: loss 15.859326
[epoch12, step2311]: loss 1.349633
[epoch12, step2312]: loss 0.993063
[epoch12, step2313]: loss 4.792572
[epoch12, step2314]: loss 9.615599
[epoch12, step2315]: loss 1.283568
[epoch12, step2316]: loss 3.889157
[epoch12, step2317]: loss 8.525224
[epoch12, step2318]: loss 2.148477
[epoch12, step2319]: loss 3.597778
[epoch12, step2320]: loss 0.730400
[epoch12, step2321]: loss 0.966127
[epoch12, step2322]: loss 2.842637
[epoch12, step2323]: loss 3.036248
[epoch12, step2324]: loss 9.095348
[epoch12, step2325]: loss 1.281453
[epoch12, step2326]: loss 11.332641
[epoch12, step2327]: loss 2.026624
[epoch12, step2328]: loss 1.442201
[epoch12, step2329]: loss 2.482224
[epoch12, step2330]: loss 8.220098
[epoch12, step2331]: loss 5.475782
[epoch12, step2332]: loss 2.372231
[epoch12, step2333]: loss 2.013602
[epoch12, step2334]: loss 0.959280
[epoch12, step2335]: loss 1.459241
[epoch12, step2336]: loss 0.858043
[epoch12, step2337]: loss 0.852407
[epoch12, step2338]: loss 0.835717
[epoch12, step2339]: loss 11.746374
[epoch12, step2340]: loss 3.764119
[epoch12, step2341]: loss 2.471120
[epoch12, step2342]: loss 10.145387
[epoch12, step2343]: loss 3.015162
[epoch12, step2344]: loss 5.978301
[epoch12, step2345]: loss 1.028837
[epoch12, step2346]: loss 1.624251
[epoch12, step2347]: loss 1.634339
[epoch12, step2348]: loss 1.719201
[epoch12, step2349]: loss 8.182856
[epoch12, step2350]: loss 3.401992
[epoch12, step2351]: loss 0.993119
[epoch12, step2352]: loss 8.414702
[epoch12, step2353]: loss 2.385377
[epoch12, step2354]: loss 10.931430
[epoch12, step2355]: loss 2.995626
[epoch12, step2356]: loss 1.853079
[epoch12, step2357]: loss 4.099365
[epoch12, step2358]: loss 1.269128
[epoch12, step2359]: loss 0.768347
[epoch12, step2360]: loss 1.134719
[epoch12, step2361]: loss 1.507241
[epoch12, step2362]: loss 1.566234
[epoch12, step2363]: loss 14.299102
[epoch12, step2364]: loss 2.091251
[epoch12, step2365]: loss 12.599086
[epoch12, step2366]: loss 1.092436
[epoch12, step2367]: loss 0.774621
[epoch12, step2368]: loss 7.911375
[epoch12, step2369]: loss 1.814617
[epoch12, step2370]: loss 3.830438
[epoch12, step2371]: loss 10.995097
[epoch12, step2372]: loss 1.907867
[epoch12, step2373]: loss 23.770269
[epoch12, step2374]: loss 1.133443
[epoch12, step2375]: loss 10.553071
[epoch12, step2376]: loss 5.701871
[epoch12, step2377]: loss 1.140554
[epoch12, step2378]: loss 7.534578
[epoch12, step2379]: loss 1.299908
[epoch12, step2380]: loss 14.520730
[epoch12, step2381]: loss 2.724981
[epoch12, step2382]: loss 8.262371
[epoch12, step2383]: loss 0.922394
[epoch12, step2384]: loss 16.001303
[epoch12, step2385]: loss 6.872631
[epoch12, step2386]: loss 2.816107
[epoch12, step2387]: loss 2.420273
[epoch12, step2388]: loss 15.882270
[epoch12, step2389]: loss 3.238674
[epoch12, step2390]: loss 2.858761
[epoch12, step2391]: loss 2.936555
[epoch12, step2392]: loss 5.346496
[epoch12, step2393]: loss 12.087480
[epoch12, step2394]: loss 1.491515
[epoch12, step2395]: loss 4.153916
[epoch12, step2396]: loss 6.596947
[epoch12, step2397]: loss 2.404834
[epoch12, step2398]: loss 7.982484
[epoch12, step2399]: loss 0.969386
[epoch12, step2400]: loss 2.873247
[epoch12, step2401]: loss 8.861380
[epoch12, step2402]: loss 1.237640
[epoch12, step2403]: loss 2.009539
[epoch12, step2404]: loss 2.949772
[epoch12, step2405]: loss 0.860591
[epoch12, step2406]: loss 8.135319
[epoch12, step2407]: loss 9.122450
[epoch12, step2408]: loss 0.950308
[epoch12, step2409]: loss 6.526636
[epoch12, step2410]: loss 1.046979
[epoch12, step2411]: loss 4.051210
[epoch12, step2412]: loss 1.052658
[epoch12, step2413]: loss 1.458502
[epoch12, step2414]: loss 1.209227
[epoch12, step2415]: loss 0.990697
[epoch12, step2416]: loss 1.087765
[epoch12, step2417]: loss 4.050130
[epoch12, step2418]: loss 2.412984
[epoch12, step2419]: loss 16.699846
[epoch12, step2420]: loss 13.964622
[epoch12, step2421]: loss 7.540140
[epoch12, step2422]: loss 2.754552
[epoch12, step2423]: loss 2.964303
[epoch12, step2424]: loss 8.843472
[epoch12, step2425]: loss 1.818823
[epoch12, step2426]: loss 1.369713
[epoch12, step2427]: loss 12.511594
[epoch12, step2428]: loss 3.262067
[epoch12, step2429]: loss 0.744920
[epoch12, step2430]: loss 1.522868
[epoch12, step2431]: loss 10.395256
[epoch12, step2432]: loss 1.753301
[epoch12, step2433]: loss 9.877171
[epoch12, step2434]: loss 5.340031
[epoch12, step2435]: loss 1.169369
[epoch12, step2436]: loss 8.777796
[epoch12, step2437]: loss 0.755714
[epoch12, step2438]: loss 8.774767
[epoch12, step2439]: loss 3.742882
[epoch12, step2440]: loss 10.822062
[epoch12, step2441]: loss 9.267235
[epoch12, step2442]: loss 1.812568
[epoch12, step2443]: loss 1.635415
[epoch12, step2444]: loss 2.013671
[epoch12, step2445]: loss 3.565641
[epoch12, step2446]: loss 1.373445
[epoch12, step2447]: loss 2.026202
[epoch12, step2448]: loss 1.185446
[epoch12, step2449]: loss 6.226408
[epoch12, step2450]: loss 7.422986
[epoch12, step2451]: loss 12.956714
[epoch12, step2452]: loss 3.411670
[epoch12, step2453]: loss 1.292199
[epoch12, step2454]: loss 6.646415
[epoch12, step2455]: loss 4.203838
[epoch12, step2456]: loss 1.163617
[epoch12, step2457]: loss 7.674412
[epoch12, step2458]: loss 1.092750
[epoch12, step2459]: loss 3.335142
[epoch12, step2460]: loss 1.252422
[epoch12, step2461]: loss 12.355933
[epoch12, step2462]: loss 0.822341
[epoch12, step2463]: loss 1.360924
[epoch12, step2464]: loss 2.803755
[epoch12, step2465]: loss 9.214114
[epoch12, step2466]: loss 0.980350
[epoch12, step2467]: loss 3.377930
[epoch12, step2468]: loss 3.499821
[epoch12, step2469]: loss 8.184390
[epoch12, step2470]: loss 9.761169
[epoch12, step2471]: loss 1.687936
[epoch12, step2472]: loss 1.810491
[epoch12, step2473]: loss 1.402484
[epoch12, step2474]: loss 1.152915
[epoch12, step2475]: loss 0.832438
[epoch12, step2476]: loss 1.039849
[epoch12, step2477]: loss 10.590919
[epoch12, step2478]: loss 13.018321
[epoch12, step2479]: loss 2.312346
[epoch12, step2480]: loss 1.312860
[epoch12, step2481]: loss 2.812223
[epoch12, step2482]: loss 3.322905
[epoch12, step2483]: loss 7.479494
[epoch12, step2484]: loss 4.499709
[epoch12, step2485]: loss 1.159579
[epoch12, step2486]: loss 1.208748
[epoch12, step2487]: loss 0.873648
[epoch12, step2488]: loss 8.514543
[epoch12, step2489]: loss 10.389913
[epoch12, step2490]: loss 3.693844
[epoch12, step2491]: loss 7.273916
[epoch12, step2492]: loss 1.465766
[epoch12, step2493]: loss 4.260991
[epoch12, step2494]: loss 5.987125
[epoch12, step2495]: loss 10.886896
[epoch12, step2496]: loss 6.582835
[epoch12, step2497]: loss 0.923289
[epoch12, step2498]: loss 0.867895
[epoch12, step2499]: loss 3.407692
[epoch12, step2500]: loss 8.326385
[epoch12, step2501]: loss 5.085320
[epoch12, step2502]: loss 1.863893
[epoch12, step2503]: loss 13.886237
[epoch12, step2504]: loss 4.024278
[epoch12, step2505]: loss 1.769227
[epoch12, step2506]: loss 0.721755
[epoch12, step2507]: loss 2.205336
[epoch12, step2508]: loss 5.457809
[epoch12, step2509]: loss 1.015793
[epoch12, step2510]: loss 2.170482
[epoch12, step2511]: loss 0.863291
[epoch12, step2512]: loss 1.487301
[epoch12, step2513]: loss 16.274071
[epoch12, step2514]: loss 12.900637
[epoch12, step2515]: loss 9.003540
[epoch12, step2516]: loss 0.882271
[epoch12, step2517]: loss 1.839725
[epoch12, step2518]: loss 1.880136
[epoch12, step2519]: loss 0.915994
[epoch12, step2520]: loss 2.073496
[epoch12, step2521]: loss 1.179871
[epoch12, step2522]: loss 4.851539
[epoch12, step2523]: loss 0.711262
[epoch12, step2524]: loss 20.068985
[epoch12, step2525]: loss 7.205657
[epoch12, step2526]: loss 5.006176
[epoch12, step2527]: loss 1.180819
[epoch12, step2528]: loss 11.332455
[epoch12, step2529]: loss 1.721155
[epoch12, step2530]: loss 4.369892
[epoch12, step2531]: loss 8.374384
[epoch12, step2532]: loss 8.734721
[epoch12, step2533]: loss 1.464311
[epoch12, step2534]: loss 5.628984
[epoch12, step2535]: loss 4.506793
[epoch12, step2536]: loss 1.883058
[epoch12, step2537]: loss 0.941135
[epoch12, step2538]: loss 1.035063
[epoch12, step2539]: loss 4.767750
[epoch12, step2540]: loss 9.692868
[epoch12, step2541]: loss 2.501965
[epoch12, step2542]: loss 3.093724
[epoch12, step2543]: loss 2.820683
[epoch12, step2544]: loss 8.644495
[epoch12, step2545]: loss 5.533980
[epoch12, step2546]: loss 1.213365
[epoch12, step2547]: loss 0.640295
[epoch12, step2548]: loss 15.661990
[epoch12, step2549]: loss 1.043017
[epoch12, step2550]: loss 3.393439
[epoch12, step2551]: loss 1.677668
[epoch12, step2552]: loss 4.127412
[epoch12, step2553]: loss 1.280282
[epoch12, step2554]: loss 0.931783
[epoch12, step2555]: loss 5.842543
[epoch12, step2556]: loss 2.026683
[epoch12, step2557]: loss 3.523282
[epoch12, step2558]: loss 0.881209
[epoch12, step2559]: loss 0.965352
[epoch12, step2560]: loss 7.116086
[epoch12, step2561]: loss 5.079778
[epoch12, step2562]: loss 2.159587
[epoch12, step2563]: loss 5.263591
[epoch12, step2564]: loss 6.734772
[epoch12, step2565]: loss 5.806638
[epoch12, step2566]: loss 1.121679
[epoch12, step2567]: loss 9.017716
[epoch12, step2568]: loss 11.870347
[epoch12, step2569]: loss 1.186969
[epoch12, step2570]: loss 6.264797
[epoch12, step2571]: loss 14.769885
[epoch12, step2572]: loss 1.234597
[epoch12, step2573]: loss 2.510229
[epoch12, step2574]: loss 1.159826
[epoch12, step2575]: loss 8.379216
[epoch12, step2576]: loss 8.065472
[epoch12, step2577]: loss 1.183932
[epoch12, step2578]: loss 8.462469
[epoch12, step2579]: loss 1.911689
[epoch12, step2580]: loss 1.576131
[epoch12, step2581]: loss 2.184394
[epoch12, step2582]: loss 1.149256
[epoch12, step2583]: loss 1.287839
[epoch12, step2584]: loss 2.245267
[epoch12, step2585]: loss 16.211807
[epoch12, step2586]: loss 0.754968
[epoch12, step2587]: loss 2.952867
[epoch12, step2588]: loss 9.828835
[epoch12, step2589]: loss 2.369587
[epoch12, step2590]: loss 0.733707
[epoch12, step2591]: loss 5.674737
[epoch12, step2592]: loss 0.856244
[epoch12, step2593]: loss 4.412829
[epoch12, step2594]: loss 1.292987
[epoch12, step2595]: loss 3.083112
[epoch12, step2596]: loss 9.643291
[epoch12, step2597]: loss 9.277249
[epoch12, step2598]: loss 1.056478
[epoch12, step2599]: loss 2.144304
[epoch12, step2600]: loss 7.565622
[epoch12, step2601]: loss 6.648607
[epoch12, step2602]: loss 1.213912
[epoch12, step2603]: loss 4.711530
[epoch12, step2604]: loss 1.829851
[epoch12, step2605]: loss 1.064502
[epoch12, step2606]: loss 1.901697
[epoch12, step2607]: loss 1.320914
[epoch12, step2608]: loss 1.162595
[epoch12, step2609]: loss 2.291448
[epoch12, step2610]: loss 0.825390
[epoch12, step2611]: loss 1.322756
[epoch12, step2612]: loss 14.207513
[epoch12, step2613]: loss 3.426650
[epoch12, step2614]: loss 4.043216
[epoch12, step2615]: loss 2.486195
[epoch12, step2616]: loss 9.759332
[epoch12, step2617]: loss 10.151484
[epoch12, step2618]: loss 0.866513
[epoch12, step2619]: loss 14.841302
[epoch12, step2620]: loss 1.935403
[epoch12, step2621]: loss 21.818008
[epoch12, step2622]: loss 1.117506
[epoch12, step2623]: loss 14.043887
[epoch12, step2624]: loss 1.739624
[epoch12, step2625]: loss 7.398576
[epoch12, step2626]: loss 7.622371
[epoch12, step2627]: loss 9.928429
[epoch12, step2628]: loss 2.914651
[epoch12, step2629]: loss 3.592122
[epoch12, step2630]: loss 1.356335
[epoch12, step2631]: loss 1.906442
[epoch12, step2632]: loss 5.234550
[epoch12, step2633]: loss 1.457025
[epoch12, step2634]: loss 1.693386
[epoch12, step2635]: loss 0.998839
[epoch12, step2636]: loss 9.062599
[epoch12, step2637]: loss 2.601826
[epoch12, step2638]: loss 9.942237
[epoch12, step2639]: loss 1.263227
[epoch12, step2640]: loss 1.260338
[epoch12, step2641]: loss 1.144507
[epoch12, step2642]: loss 1.310945
[epoch12, step2643]: loss 1.071137
[epoch12, step2644]: loss 2.419878
[epoch12, step2645]: loss 1.692072
[epoch12, step2646]: loss 6.648080
[epoch12, step2647]: loss 1.415214
[epoch12, step2648]: loss 1.867931
[epoch12, step2649]: loss 6.929794
[epoch12, step2650]: loss 3.076640
[epoch12, step2651]: loss 1.173613
[epoch12, step2652]: loss 8.666317
[epoch12, step2653]: loss 1.111025
[epoch12, step2654]: loss 4.230608
[epoch12, step2655]: loss 4.638345
[epoch12, step2656]: loss 1.450305
[epoch12, step2657]: loss 1.638814
[epoch12, step2658]: loss 7.342321
[epoch12, step2659]: loss 1.026600
[epoch12, step2660]: loss 3.022245
[epoch12, step2661]: loss 0.929735
[epoch12, step2662]: loss 1.086845
[epoch12, step2663]: loss 8.140493
[epoch12, step2664]: loss 10.004804
[epoch12, step2665]: loss 7.238465
[epoch12, step2666]: loss 14.284185
[epoch12, step2667]: loss 1.987010
[epoch12, step2668]: loss 3.330539
[epoch12, step2669]: loss 0.684339
[epoch12, step2670]: loss 17.741821
[epoch12, step2671]: loss 8.460266
[epoch12, step2672]: loss 2.025874
[epoch12, step2673]: loss 1.972235
[epoch12, step2674]: loss 1.126779
[epoch12, step2675]: loss 0.930532
[epoch12, step2676]: loss 2.845641
[epoch12, step2677]: loss 1.198129
[epoch12, step2678]: loss 4.889259
[epoch12, step2679]: loss 0.869404
[epoch12, step2680]: loss 7.160224
[epoch12, step2681]: loss 1.310984
[epoch12, step2682]: loss 1.685397
[epoch12, step2683]: loss 5.673991
[epoch12, step2684]: loss 13.411049
[epoch12, step2685]: loss 16.001171
[epoch12, step2686]: loss 2.795496
[epoch12, step2687]: loss 6.441429
[epoch12, step2688]: loss 2.015727
[epoch12, step2689]: loss 11.979789
[epoch12, step2690]: loss 0.991821
[epoch12, step2691]: loss 1.457479
[epoch12, step2692]: loss 1.295744
[epoch12, step2693]: loss 4.050466
[epoch12, step2694]: loss 1.390322
[epoch12, step2695]: loss 2.061568
[epoch12, step2696]: loss 8.820518
[epoch12, step2697]: loss 1.037020
[epoch12, step2698]: loss 7.979522
[epoch12, step2699]: loss 2.868199
[epoch12, step2700]: loss 9.762315
[epoch12, step2701]: loss 1.942324
[epoch12, step2702]: loss 6.008371
[epoch12, step2703]: loss 3.071193
[epoch12, step2704]: loss 8.597391
[epoch12, step2705]: loss 3.871937
[epoch12, step2706]: loss 9.245046
[epoch12, step2707]: loss 6.554155
[epoch12, step2708]: loss 1.076125
[epoch12, step2709]: loss 8.208342
[epoch12, step2710]: loss 1.908253
[epoch12, step2711]: loss 1.238776
[epoch12, step2712]: loss 1.943173
[epoch12, step2713]: loss 1.419797
[epoch12, step2714]: loss 2.459304
[epoch12, step2715]: loss 3.735376
[epoch12, step2716]: loss 2.951994
[epoch12, step2717]: loss 9.470154
[epoch12, step2718]: loss 3.884098
[epoch12, step2719]: loss 11.736775
[epoch12, step2720]: loss 5.123854
[epoch12, step2721]: loss 1.416910
[epoch12, step2722]: loss 7.395277
[epoch12, step2723]: loss 1.163656
[epoch12, step2724]: loss 0.930311
[epoch12, step2725]: loss 0.706953
[epoch12, step2726]: loss 1.388097
[epoch12, step2727]: loss 1.284501
[epoch12, step2728]: loss 9.425448
[epoch12, step2729]: loss 4.706180
[epoch12, step2730]: loss 0.842140
[epoch12, step2731]: loss 3.752496
[epoch12, step2732]: loss 13.452149
[epoch12, step2733]: loss 1.121281
[epoch12, step2734]: loss 1.714209
[epoch12, step2735]: loss 1.776226
[epoch12, step2736]: loss 8.303648
[epoch12, step2737]: loss 1.635725
[epoch12, step2738]: loss 2.776146
[epoch12, step2739]: loss 9.024323
[epoch12, step2740]: loss 3.248002
[epoch12, step2741]: loss 8.315109
[epoch12, step2742]: loss 2.483030
[epoch12, step2743]: loss 3.407585
[epoch12, step2744]: loss 1.023149
[epoch12, step2745]: loss 1.380696
[epoch12, step2746]: loss 1.388480
[epoch12, step2747]: loss 2.104657
[epoch12, step2748]: loss 2.212771
[epoch12, step2749]: loss 6.922277
[epoch12, step2750]: loss 1.579780
[epoch12, step2751]: loss 0.733779
[epoch12, step2752]: loss 0.749384
[epoch12, step2753]: loss 0.873361
[epoch12, step2754]: loss 7.623961
[epoch12, step2755]: loss 14.329521
[epoch12, step2756]: loss 8.791308
[epoch12, step2757]: loss 3.445806
[epoch12, step2758]: loss 1.819937
[epoch12, step2759]: loss 8.358757
[epoch12, step2760]: loss 1.061646
[epoch12, step2761]: loss 2.751711
[epoch12, step2762]: loss 1.396150
[epoch12, step2763]: loss 13.534263
[epoch12, step2764]: loss 1.580912
[epoch12, step2765]: loss 0.741843
[epoch12, step2766]: loss 1.320210
[epoch12, step2767]: loss 23.949261
[epoch12, step2768]: loss 1.686180
[epoch12, step2769]: loss 13.302240
[epoch12, step2770]: loss 4.537619
[epoch12, step2771]: loss 8.165355
[epoch12, step2772]: loss 2.184052
[epoch12, step2773]: loss 0.953098
[epoch12, step2774]: loss 1.133223
[epoch12, step2775]: loss 2.596153
[epoch12, step2776]: loss 1.408386
[epoch12, step2777]: loss 1.385887
[epoch12, step2778]: loss 0.747360
[epoch12, step2779]: loss 1.639429
[epoch12, step2780]: loss 8.319347
[epoch12, step2781]: loss 1.186576
[epoch12, step2782]: loss 3.504099
[epoch12, step2783]: loss 1.253247
[epoch12, step2784]: loss 4.397552
[epoch12, step2785]: loss 4.677015
[epoch12, step2786]: loss 0.807611
[epoch12, step2787]: loss 7.324318
[epoch12, step2788]: loss 17.664246
[epoch12, step2789]: loss 1.729844
[epoch12, step2790]: loss 0.628293
[epoch12, step2791]: loss 9.243403
[epoch12, step2792]: loss 0.750854
[epoch12, step2793]: loss 1.697148
[epoch12, step2794]: loss 1.175389
[epoch12, step2795]: loss 0.855227
[epoch12, step2796]: loss 4.149534
[epoch12, step2797]: loss 1.188392
[epoch12, step2798]: loss 0.768912
[epoch12, step2799]: loss 4.170008
[epoch12, step2800]: loss 8.707778
[epoch12, step2801]: loss 3.285788
[epoch12, step2802]: loss 1.808540
[epoch12, step2803]: loss 1.052093
[epoch12, step2804]: loss 1.290916
[epoch12, step2805]: loss 1.080943
[epoch12, step2806]: loss 3.095723
[epoch12, step2807]: loss 2.221361
[epoch12, step2808]: loss 9.767053
[epoch12, step2809]: loss 7.376637
[epoch12, step2810]: loss 2.432466
[epoch12, step2811]: loss 8.544423
[epoch12, step2812]: loss 0.936803
[epoch12, step2813]: loss 1.709902
[epoch12, step2814]: loss 0.882153
[epoch12, step2815]: loss 1.304104
[epoch12, step2816]: loss 10.380089
[epoch12, step2817]: loss 1.732291
[epoch12, step2818]: loss 0.836349
[epoch12, step2819]: loss 9.968468
[epoch12, step2820]: loss 3.043970
[epoch12, step2821]: loss 3.576748
[epoch12, step2822]: loss 1.147201
[epoch12, step2823]: loss 0.728586
[epoch12, step2824]: loss 1.513507
[epoch12, step2825]: loss 0.967173
[epoch12, step2826]: loss 2.195135
[epoch12, step2827]: loss 3.114919
[epoch12, step2828]: loss 7.400228
[epoch12, step2829]: loss 10.919336
[epoch12, step2830]: loss 14.392807
[epoch12, step2831]: loss 12.423107
[epoch12, step2832]: loss 1.520988
[epoch12, step2833]: loss 1.029165
[epoch12, step2834]: loss 0.820243
[epoch12, step2835]: loss 0.756034
[epoch12, step2836]: loss 3.137048
[epoch12, step2837]: loss 0.767124
[epoch12, step2838]: loss 8.512151
[epoch12, step2839]: loss 1.395068
[epoch12, step2840]: loss 4.271535
[epoch12, step2841]: loss 3.206604
[epoch12, step2842]: loss 0.907764
[epoch12, step2843]: loss 1.471683
[epoch12, step2844]: loss 3.257329
[epoch12, step2845]: loss 18.069790
[epoch12, step2846]: loss 1.487385
[epoch12, step2847]: loss 0.632999
[epoch12, step2848]: loss 1.158455
[epoch12, step2849]: loss 3.657554
[epoch12, step2850]: loss 7.223322
[epoch12, step2851]: loss 0.849410
[epoch12, step2852]: loss 1.336612
[epoch12, step2853]: loss 1.069463
[epoch12, step2854]: loss 0.982018
[epoch12, step2855]: loss 0.813048
[epoch12, step2856]: loss 0.983154
[epoch12, step2857]: loss 0.754675
[epoch12, step2858]: loss 1.056015
[epoch12, step2859]: loss 1.287767
[epoch12, step2860]: loss 8.211315
[epoch12, step2861]: loss 2.503127
[epoch12, step2862]: loss 2.125343
[epoch12, step2863]: loss 6.482304
[epoch12, step2864]: loss 1.351005
[epoch12, step2865]: loss 2.496827
[epoch12, step2866]: loss 10.386894
[epoch12, step2867]: loss 14.901653
[epoch12, step2868]: loss 3.601667
[epoch12, step2869]: loss 20.564587
[epoch12, step2870]: loss 10.331923
[epoch12, step2871]: loss 1.395740
[epoch12, step2872]: loss 7.462123
[epoch12, step2873]: loss 2.143928
[epoch12, step2874]: loss 13.653488
[epoch12, step2875]: loss 7.378272
[epoch12, step2876]: loss 8.330893
[epoch12, step2877]: loss 1.360581
[epoch12, step2878]: loss 7.788280
[epoch12, step2879]: loss 16.470955
[epoch12, step2880]: loss 8.970311
[epoch12, step2881]: loss 1.044282
[epoch12, step2882]: loss 5.562528
[epoch12, step2883]: loss 1.310189
[epoch12, step2884]: loss 16.279501
[epoch12, step2885]: loss 14.164209
[epoch12, step2886]: loss 7.081321
[epoch12, step2887]: loss 0.505141
[epoch12, step2888]: loss 1.514197
[epoch12, step2889]: loss 12.806624
[epoch12, step2890]: loss 10.450825
[epoch12, step2891]: loss 5.041377
[epoch12, step2892]: loss 1.276734
[epoch12, step2893]: loss 2.468829
[epoch12, step2894]: loss 4.129110
[epoch12, step2895]: loss 0.718513
[epoch12, step2896]: loss 18.423887
[epoch12, step2897]: loss 6.393095
[epoch12, step2898]: loss 4.321877
[epoch12, step2899]: loss 0.878009
[epoch12, step2900]: loss 3.472091
[epoch12, step2901]: loss 7.042158
[epoch12, step2902]: loss 7.230714
[epoch12, step2903]: loss 8.140503
[epoch12, step2904]: loss 0.944626
[epoch12, step2905]: loss 13.271172
[epoch12, step2906]: loss 6.132802
[epoch12, step2907]: loss 2.306100
[epoch12, step2908]: loss 3.957391
[epoch12, step2909]: loss 0.980366
[epoch12, step2910]: loss 3.430800
[epoch12, step2911]: loss 2.812968
[epoch12, step2912]: loss 1.392055
[epoch12, step2913]: loss 0.834812
[epoch12, step2914]: loss 22.648129
[epoch12, step2915]: loss 14.787782
[epoch12, step2916]: loss 9.233765
[epoch12, step2917]: loss 1.265991
[epoch12, step2918]: loss 0.829173
[epoch12, step2919]: loss 1.760341
[epoch12, step2920]: loss 2.735452
[epoch12, step2921]: loss 3.356106
[epoch12, step2922]: loss 16.728102
[epoch12, step2923]: loss 4.687088
[epoch12, step2924]: loss 11.327445
[epoch12, step2925]: loss 7.425965
[epoch12, step2926]: loss 1.218099
[epoch12, step2927]: loss 8.618887
[epoch12, step2928]: loss 2.643944
[epoch12, step2929]: loss 7.092837
[epoch12, step2930]: loss 1.263474
[epoch12, step2931]: loss 2.340545
[epoch12, step2932]: loss 4.629339
[epoch12, step2933]: loss 1.769713
[epoch12, step2934]: loss 1.324622
[epoch12, step2935]: loss 11.228220
[epoch12, step2936]: loss 1.051051
[epoch12, step2937]: loss 1.654165
[epoch12, step2938]: loss 9.562551
[epoch12, step2939]: loss 1.277711
[epoch12, step2940]: loss 1.415111
[epoch12, step2941]: loss 1.512176
[epoch12, step2942]: loss 2.942239
[epoch12, step2943]: loss 3.474461
[epoch12, step2944]: loss 2.480596
[epoch12, step2945]: loss 5.619411
[epoch12, step2946]: loss 3.113511
[epoch12, step2947]: loss 0.861979
[epoch12, step2948]: loss 1.882091
[epoch12, step2949]: loss 8.626455
[epoch12, step2950]: loss 12.733742
[epoch12, step2951]: loss 11.375881
[epoch12, step2952]: loss 1.281144
[epoch12, step2953]: loss 1.315566
[epoch12, step2954]: loss 3.981216
[epoch12, step2955]: loss 9.264220
[epoch12, step2956]: loss 2.394790
[epoch12, step2957]: loss 7.932500
[epoch12, step2958]: loss 4.246406
[epoch12, step2959]: loss 11.483029
[epoch12, step2960]: loss 0.951253
[epoch12, step2961]: loss 2.037327
[epoch12, step2962]: loss 2.567375
[epoch12, step2963]: loss 3.795189
[epoch12, step2964]: loss 0.807788
[epoch12, step2965]: loss 2.374045
[epoch12, step2966]: loss 8.403369
[epoch12, step2967]: loss 0.807737
[epoch12, step2968]: loss 2.429263
[epoch12, step2969]: loss 0.920096
[epoch12, step2970]: loss 7.747085
[epoch12, step2971]: loss 5.783747
[epoch12, step2972]: loss 3.529040
[epoch12, step2973]: loss 1.425023
[epoch12, step2974]: loss 9.577436
[epoch12, step2975]: loss 6.761267
[epoch12, step2976]: loss 1.519959
[epoch12, step2977]: loss 4.056695
[epoch12, step2978]: loss 5.102105
[epoch12, step2979]: loss 1.723782
[epoch12, step2980]: loss 1.241903
[epoch12, step2981]: loss 8.745487
[epoch12, step2982]: loss 5.761880
[epoch12, step2983]: loss 2.086190
[epoch12, step2984]: loss 3.946111
[epoch12, step2985]: loss 15.003856
[epoch12, step2986]: loss 1.100203
[epoch12, step2987]: loss 2.670108
[epoch12, step2988]: loss 3.237493
[epoch12, step2989]: loss 1.358979
[epoch12, step2990]: loss 0.964918
[epoch12, step2991]: loss 13.957095
[epoch12, step2992]: loss 30.466396
[epoch12, step2993]: loss 11.736240
[epoch12, step2994]: loss 0.713524
[epoch12, step2995]: loss 3.435596
[epoch12, step2996]: loss 0.961311
[epoch12, step2997]: loss 8.153664
[epoch12, step2998]: loss 9.854202
[epoch12, step2999]: loss 6.706129
[epoch12, step3000]: loss 4.389457
[epoch12, step3001]: loss 1.032569
[epoch12, step3002]: loss 1.400403
[epoch12, step3003]: loss 2.282954
[epoch12, step3004]: loss 3.546247
[epoch12, step3005]: loss 0.737896
[epoch12, step3006]: loss 1.796261
[epoch12, step3007]: loss 2.904219
[epoch12, step3008]: loss 8.829353
[epoch12, step3009]: loss 11.677443
[epoch12, step3010]: loss 0.961595
[epoch12, step3011]: loss 1.220419
[epoch12, step3012]: loss 6.186275
[epoch12, step3013]: loss 1.094655
[epoch12, step3014]: loss 1.594815
[epoch12, step3015]: loss 8.906805
[epoch12, step3016]: loss 2.143320
[epoch12, step3017]: loss 1.274450
[epoch12, step3018]: loss 2.067641
[epoch12, step3019]: loss 5.830931
[epoch12, step3020]: loss 1.115497
[epoch12, step3021]: loss 1.380762
[epoch12, step3022]: loss 2.833332
[epoch12, step3023]: loss 39.035255
[epoch12, step3024]: loss 4.572170
[epoch12, step3025]: loss 4.979074
[epoch12, step3026]: loss 0.688795
[epoch12, step3027]: loss 1.550393
[epoch12, step3028]: loss 13.975080
[epoch12, step3029]: loss 1.308790
[epoch12, step3030]: loss 16.824881
[epoch12, step3031]: loss 3.296494
[epoch12, step3032]: loss 5.474989
[epoch12, step3033]: loss 11.869105
[epoch12, step3034]: loss 8.933935
[epoch12, step3035]: loss 3.223110
[epoch12, step3036]: loss 9.113696
[epoch12, step3037]: loss 1.152248
[epoch12, step3038]: loss 9.683463
[epoch12, step3039]: loss 1.610283
[epoch12, step3040]: loss 7.154037
[epoch12, step3041]: loss 0.966053
[epoch12, step3042]: loss 1.996197
[epoch12, step3043]: loss 0.907308
[epoch12, step3044]: loss 3.597863
[epoch12, step3045]: loss 2.291256
[epoch12, step3046]: loss 3.549505
[epoch12, step3047]: loss 8.489893
[epoch12, step3048]: loss 22.361189
[epoch12, step3049]: loss 1.711223
[epoch12, step3050]: loss 1.440360
[epoch12, step3051]: loss 1.053970
[epoch12, step3052]: loss 3.063767
[epoch12, step3053]: loss 1.062167
[epoch12, step3054]: loss 0.945281
[epoch12, step3055]: loss 6.398267
[epoch12, step3056]: loss 8.428637
[epoch12, step3057]: loss 2.205700
[epoch12, step3058]: loss 2.287378
[epoch12, step3059]: loss 1.255227
[epoch12, step3060]: loss 8.512647
[epoch12, step3061]: loss 2.884110
[epoch12, step3062]: loss 0.884980
[epoch12, step3063]: loss 11.369081
[epoch12, step3064]: loss 7.487473
[epoch12, step3065]: loss 3.848431
[epoch12, step3066]: loss 1.217390
[epoch12, step3067]: loss 4.145543
[epoch12, step3068]: loss 1.978599
[epoch12, step3069]: loss 1.139863
[epoch12, step3070]: loss 11.913156
[epoch12, step3071]: loss 6.016765
[epoch12, step3072]: loss 2.972632
[epoch12, step3073]: loss 3.568659
[epoch12, step3074]: loss 1.238616
[epoch12, step3075]: loss 2.404452
[epoch12, step3076]: loss 2.574508

[epoch12]: avg loss 2.574508

[epoch13, step1]: loss 2.881609
[epoch13, step2]: loss 0.852922
[epoch13, step3]: loss 1.012987
[epoch13, step4]: loss 2.610528
[epoch13, step5]: loss 2.519376
[epoch13, step6]: loss 1.734096
[epoch13, step7]: loss 3.222306
[epoch13, step8]: loss 2.623081
[epoch13, step9]: loss 2.156987
[epoch13, step10]: loss 2.353966
[epoch13, step11]: loss 1.310764
[epoch13, step12]: loss 8.334634
[epoch13, step13]: loss 1.462761
[epoch13, step14]: loss 3.847738
[epoch13, step15]: loss 0.990659
[epoch13, step16]: loss 1.242163
[epoch13, step17]: loss 0.780112
[epoch13, step18]: loss 3.906716
[epoch13, step19]: loss 1.360913
[epoch13, step20]: loss 7.467327
[epoch13, step21]: loss 2.186055
[epoch13, step22]: loss 8.973649
[epoch13, step23]: loss 3.452915
[epoch13, step24]: loss 1.151887
[epoch13, step25]: loss 2.395287
[epoch13, step26]: loss 1.908660
[epoch13, step27]: loss 3.594500
[epoch13, step28]: loss 2.385198
[epoch13, step29]: loss 0.902608
[epoch13, step30]: loss 2.188814
[epoch13, step31]: loss 11.479422
[epoch13, step32]: loss 2.597821
[epoch13, step33]: loss 15.834038
[epoch13, step34]: loss 2.711383
[epoch13, step35]: loss 11.970282
[epoch13, step36]: loss 0.997534
[epoch13, step37]: loss 0.700725
[epoch13, step38]: loss 2.463301
[epoch13, step39]: loss 1.135183
[epoch13, step40]: loss 3.763629
[epoch13, step41]: loss 1.343121
[epoch13, step42]: loss 16.331758
[epoch13, step43]: loss 18.554777
[epoch13, step44]: loss 1.451168
[epoch13, step45]: loss 3.831650
[epoch13, step46]: loss 8.644233
[epoch13, step47]: loss 0.915170
[epoch13, step48]: loss 13.696340
[epoch13, step49]: loss 2.805008
[epoch13, step50]: loss 0.810672
[epoch13, step51]: loss 2.425387
[epoch13, step52]: loss 9.300782
[epoch13, step53]: loss 17.791573
[epoch13, step54]: loss 3.516153
[epoch13, step55]: loss 1.675721
[epoch13, step56]: loss 0.924349
[epoch13, step57]: loss 0.956892
[epoch13, step58]: loss 1.393473
[epoch13, step59]: loss 3.364218
[epoch13, step60]: loss 0.891167
[epoch13, step61]: loss 8.034343
[epoch13, step62]: loss 0.880831
[epoch13, step63]: loss 18.459751
[epoch13, step64]: loss 0.945198
[epoch13, step65]: loss 1.157622
[epoch13, step66]: loss 9.570322
[epoch13, step67]: loss 0.901909
[epoch13, step68]: loss 7.929313
[epoch13, step69]: loss 9.080762
[epoch13, step70]: loss 3.925343
[epoch13, step71]: loss 11.808727
[epoch13, step72]: loss 1.455079
[epoch13, step73]: loss 7.167544
[epoch13, step74]: loss 0.791165
[epoch13, step75]: loss 6.732511
[epoch13, step76]: loss 10.655807
[epoch13, step77]: loss 1.267683
[epoch13, step78]: loss 7.907264
[epoch13, step79]: loss 4.042827
[epoch13, step80]: loss 2.269569
[epoch13, step81]: loss 25.977104
[epoch13, step82]: loss 1.656727
[epoch13, step83]: loss 3.643982
[epoch13, step84]: loss 22.886370
[epoch13, step85]: loss 1.705735
[epoch13, step86]: loss 8.209887
[epoch13, step87]: loss 9.670513
[epoch13, step88]: loss 15.300117
[epoch13, step89]: loss 6.003623
[epoch13, step90]: loss 9.504054
[epoch13, step91]: loss 9.286326
[epoch13, step92]: loss 2.967000
[epoch13, step93]: loss 1.147257
[epoch13, step94]: loss 0.947592
[epoch13, step95]: loss 1.417451
[epoch13, step96]: loss 2.489484
[epoch13, step97]: loss 0.988935
[epoch13, step98]: loss 1.361832
[epoch13, step99]: loss 0.838639
[epoch13, step100]: loss 0.801897
[epoch13, step101]: loss 0.952015
[epoch13, step102]: loss 3.372719
[epoch13, step103]: loss 1.424639
[epoch13, step104]: loss 1.404681
[epoch13, step105]: loss 1.488104
[epoch13, step106]: loss 2.472864
[epoch13, step107]: loss 4.509379
[epoch13, step108]: loss 2.730483
[epoch13, step109]: loss 1.023752
[epoch13, step110]: loss 1.579194
[epoch13, step111]: loss 14.350533
[epoch13, step112]: loss 16.053925
[epoch13, step113]: loss 1.307266
[epoch13, step114]: loss 1.766414
[epoch13, step115]: loss 0.926770
[epoch13, step116]: loss 11.361845
[epoch13, step117]: loss 6.702467
[epoch13, step118]: loss 12.832968
[epoch13, step119]: loss 1.524660
[epoch13, step120]: loss 18.483431
[epoch13, step121]: loss 1.995051
[epoch13, step122]: loss 4.674550
[epoch13, step123]: loss 0.931875
[epoch13, step124]: loss 2.730593
[epoch13, step125]: loss 2.843324
[epoch13, step126]: loss 5.611450
[epoch13, step127]: loss 7.063012
[epoch13, step128]: loss 1.215072
[epoch13, step129]: loss 4.484212
[epoch13, step130]: loss 1.836574
[epoch13, step131]: loss 1.616527
[epoch13, step132]: loss 1.624425
[epoch13, step133]: loss 7.110591
[epoch13, step134]: loss 11.192477
[epoch13, step135]: loss 2.725223
[epoch13, step136]: loss 1.644045
[epoch13, step137]: loss 17.644810
[epoch13, step138]: loss 9.601358
[epoch13, step139]: loss 15.254359
[epoch13, step140]: loss 0.805564
[epoch13, step141]: loss 0.869222
[epoch13, step142]: loss 2.074614
[epoch13, step143]: loss 11.267428
[epoch13, step144]: loss 1.374699
[epoch13, step145]: loss 1.429542
[epoch13, step146]: loss 1.585505
[epoch13, step147]: loss 0.870360
[epoch13, step148]: loss 1.677489
[epoch13, step149]: loss 2.154504
[epoch13, step150]: loss 1.158671
[epoch13, step151]: loss 8.479106
[epoch13, step152]: loss 2.864059
[epoch13, step153]: loss 4.795370
[epoch13, step154]: loss 0.857588
[epoch13, step155]: loss 1.923343
[epoch13, step156]: loss 1.490232
[epoch13, step157]: loss 1.077569
[epoch13, step158]: loss 2.919993
[epoch13, step159]: loss 1.459872
[epoch13, step160]: loss 3.095655
[epoch13, step161]: loss 6.063147
[epoch13, step162]: loss 3.591948
[epoch13, step163]: loss 1.286854
[epoch13, step164]: loss 1.473128
[epoch13, step165]: loss 1.952676
[epoch13, step166]: loss 5.103726
[epoch13, step167]: loss 1.470775
[epoch13, step168]: loss 1.601249
[epoch13, step169]: loss 14.054463
[epoch13, step170]: loss 12.028166
[epoch13, step171]: loss 2.348395
[epoch13, step172]: loss 1.586410
[epoch13, step173]: loss 2.527185
[epoch13, step174]: loss 0.815629
[epoch13, step175]: loss 10.936808
[epoch13, step176]: loss 4.005159
[epoch13, step177]: loss 10.980466
[epoch13, step178]: loss 1.046740
[epoch13, step179]: loss 9.020630
[epoch13, step180]: loss 16.539288
[epoch13, step181]: loss 14.551910
[epoch13, step182]: loss 0.797069
[epoch13, step183]: loss 1.048234
[epoch13, step184]: loss 3.175573
[epoch13, step185]: loss 1.716699
[epoch13, step186]: loss 0.665753
[epoch13, step187]: loss 8.732725
[epoch13, step188]: loss 1.389939
[epoch13, step189]: loss 10.706241
[epoch13, step190]: loss 9.281419
[epoch13, step191]: loss 0.976844
[epoch13, step192]: loss 20.768436
[epoch13, step193]: loss 3.235083
[epoch13, step194]: loss 6.780397
[epoch13, step195]: loss 0.863545
[epoch13, step196]: loss 4.092126
[epoch13, step197]: loss 7.843041
[epoch13, step198]: loss 7.885002
[epoch13, step199]: loss 0.808972
[epoch13, step200]: loss 0.930264
[epoch13, step201]: loss 1.009490
[epoch13, step202]: loss 2.247264
[epoch13, step203]: loss 1.146834
[epoch13, step204]: loss 10.906068
[epoch13, step205]: loss 11.472737
[epoch13, step206]: loss 0.813072
[epoch13, step207]: loss 13.655105
[epoch13, step208]: loss 1.425905
[epoch13, step209]: loss 6.613347
[epoch13, step210]: loss 1.867027
[epoch13, step211]: loss 15.751938
[epoch13, step212]: loss 11.739043
[epoch13, step213]: loss 1.178572
[epoch13, step214]: loss 0.944276
[epoch13, step215]: loss 0.894712
[epoch13, step216]: loss 0.949570
[epoch13, step217]: loss 8.561892
[epoch13, step218]: loss 8.022453
[epoch13, step219]: loss 0.948506
[epoch13, step220]: loss 0.888687
[epoch13, step221]: loss 13.346732
[epoch13, step222]: loss 3.203415
[epoch13, step223]: loss 15.359488
[epoch13, step224]: loss 4.362597
[epoch13, step225]: loss 8.375240
[epoch13, step226]: loss 1.279466
[epoch13, step227]: loss 1.472326
[epoch13, step228]: loss 3.705422
[epoch13, step229]: loss 2.342637
[epoch13, step230]: loss 3.313009
[epoch13, step231]: loss 4.706897
[epoch13, step232]: loss 0.821462
[epoch13, step233]: loss 1.406148
[epoch13, step234]: loss 0.978200
[epoch13, step235]: loss 9.176338
[epoch13, step236]: loss 2.320830
[epoch13, step237]: loss 6.699280
[epoch13, step238]: loss 6.478591
[epoch13, step239]: loss 1.743525
[epoch13, step240]: loss 25.883581
[epoch13, step241]: loss 3.472150
[epoch13, step242]: loss 2.933706
[epoch13, step243]: loss 4.675918
[epoch13, step244]: loss 1.663665
[epoch13, step245]: loss 1.068846
[epoch13, step246]: loss 0.669770
[epoch13, step247]: loss 2.481249
[epoch13, step248]: loss 5.557109
[epoch13, step249]: loss 3.372180
[epoch13, step250]: loss 2.142911
[epoch13, step251]: loss 1.495931
[epoch13, step252]: loss 0.770134
[epoch13, step253]: loss 10.012547
[epoch13, step254]: loss 0.800480
[epoch13, step255]: loss 4.996153
[epoch13, step256]: loss 1.628740
[epoch13, step257]: loss 1.373555
[epoch13, step258]: loss 1.517023
[epoch13, step259]: loss 9.456224
[epoch13, step260]: loss 2.102986
[epoch13, step261]: loss 0.970988
[epoch13, step262]: loss 3.112857
[epoch13, step263]: loss 5.531878
[epoch13, step264]: loss 1.064794
[epoch13, step265]: loss 5.125845
[epoch13, step266]: loss 1.432075
[epoch13, step267]: loss 11.079637
[epoch13, step268]: loss 1.146454
[epoch13, step269]: loss 1.975211
[epoch13, step270]: loss 1.544680
[epoch13, step271]: loss 2.984701
[epoch13, step272]: loss 0.703131
[epoch13, step273]: loss 4.945215
[epoch13, step274]: loss 0.869939
[epoch13, step275]: loss 16.250496
[epoch13, step276]: loss 23.298931
[epoch13, step277]: loss 1.710430
[epoch13, step278]: loss 9.810125
[epoch13, step279]: loss 1.590255
[epoch13, step280]: loss 1.824849
[epoch13, step281]: loss 2.866299
[epoch13, step282]: loss 7.742669
[epoch13, step283]: loss 1.446517
[epoch13, step284]: loss 2.281206
[epoch13, step285]: loss 3.034679
[epoch13, step286]: loss 0.852880
[epoch13, step287]: loss 4.174757
[epoch13, step288]: loss 1.665846
[epoch13, step289]: loss 8.139291
[epoch13, step290]: loss 0.938082
[epoch13, step291]: loss 1.126870
[epoch13, step292]: loss 4.842833
[epoch13, step293]: loss 18.037466
[epoch13, step294]: loss 1.559489
[epoch13, step295]: loss 1.262245
[epoch13, step296]: loss 0.754638
[epoch13, step297]: loss 6.034711
[epoch13, step298]: loss 1.127594
[epoch13, step299]: loss 1.972255
[epoch13, step300]: loss 7.043818
[epoch13, step301]: loss 15.818593
[epoch13, step302]: loss 1.070814
[epoch13, step303]: loss 11.920940
[epoch13, step304]: loss 5.417998
[epoch13, step305]: loss 7.407589
[epoch13, step306]: loss 1.130146
[epoch13, step307]: loss 1.970930
[epoch13, step308]: loss 9.349748
[epoch13, step309]: loss 1.723638
[epoch13, step310]: loss 29.279367
[epoch13, step311]: loss 7.501240
[epoch13, step312]: loss 2.273954
[epoch13, step313]: loss 3.073127
[epoch13, step314]: loss 11.099472
[epoch13, step315]: loss 9.776215
[epoch13, step316]: loss 0.944351
[epoch13, step317]: loss 2.117617
[epoch13, step318]: loss 1.337808
[epoch13, step319]: loss 0.779290
[epoch13, step320]: loss 0.973237
[epoch13, step321]: loss 2.096791
[epoch13, step322]: loss 1.360860
[epoch13, step323]: loss 4.264200
[epoch13, step324]: loss 11.157503
[epoch13, step325]: loss 4.317297
[epoch13, step326]: loss 4.061403
[epoch13, step327]: loss 0.848102
[epoch13, step328]: loss 11.546798
[epoch13, step329]: loss 1.032634
[epoch13, step330]: loss 1.446191
[epoch13, step331]: loss 5.951548
[epoch13, step332]: loss 1.218814
[epoch13, step333]: loss 4.322399
[epoch13, step334]: loss 2.048813
[epoch13, step335]: loss 5.701401
[epoch13, step336]: loss 1.875290
[epoch13, step337]: loss 7.276552
[epoch13, step338]: loss 2.994213
[epoch13, step339]: loss 5.275068
[epoch13, step340]: loss 3.250978
[epoch13, step341]: loss 21.092590
[epoch13, step342]: loss 2.740474
[epoch13, step343]: loss 1.923200
[epoch13, step344]: loss 11.300127
[epoch13, step345]: loss 1.323008
[epoch13, step346]: loss 12.519628
[epoch13, step347]: loss 7.225848
[epoch13, step348]: loss 1.269225
[epoch13, step349]: loss 11.994475
[epoch13, step350]: loss 8.690318
[epoch13, step351]: loss 11.439300
[epoch13, step352]: loss 1.248328
[epoch13, step353]: loss 1.175771
[epoch13, step354]: loss 7.566663
[epoch13, step355]: loss 7.176475
[epoch13, step356]: loss 5.169610
[epoch13, step357]: loss 3.097531
[epoch13, step358]: loss 2.141462
[epoch13, step359]: loss 6.485423
[epoch13, step360]: loss 0.967055
[epoch13, step361]: loss 1.387443
[epoch13, step362]: loss 0.946527
[epoch13, step363]: loss 1.487360
[epoch13, step364]: loss 0.957710
[epoch13, step365]: loss 1.206079
[epoch13, step366]: loss 1.587527
[epoch13, step367]: loss 1.610594
[epoch13, step368]: loss 4.255066
[epoch13, step369]: loss 1.696123
[epoch13, step370]: loss 1.654439
[epoch13, step371]: loss 4.067147
[epoch13, step372]: loss 0.693786
[epoch13, step373]: loss 11.387767
[epoch13, step374]: loss 0.790213
[epoch13, step375]: loss 4.122303
[epoch13, step376]: loss 17.057590
[epoch13, step377]: loss 6.924801
[epoch13, step378]: loss 0.895323
[epoch13, step379]: loss 0.859041
[epoch13, step380]: loss 0.928628
[epoch13, step381]: loss 2.186445
[epoch13, step382]: loss 1.494895
[epoch13, step383]: loss 3.642672
[epoch13, step384]: loss 0.953341
[epoch13, step385]: loss 1.043236
[epoch13, step386]: loss 1.051960
[epoch13, step387]: loss 8.308717
[epoch13, step388]: loss 3.068485
[epoch13, step389]: loss 0.620997
[epoch13, step390]: loss 17.341230
[epoch13, step391]: loss 2.565364
[epoch13, step392]: loss 1.018210
[epoch13, step393]: loss 1.759324
[epoch13, step394]: loss 1.155946
[epoch13, step395]: loss 15.894544
[epoch13, step396]: loss 8.261744
[epoch13, step397]: loss 3.117729
[epoch13, step398]: loss 1.571751
[epoch13, step399]: loss 1.094986
[epoch13, step400]: loss 1.548334
[epoch13, step401]: loss 1.974385
[epoch13, step402]: loss 7.750477
[epoch13, step403]: loss 3.688843
[epoch13, step404]: loss 1.480839
[epoch13, step405]: loss 1.157042
[epoch13, step406]: loss 4.672662
[epoch13, step407]: loss 11.089933
[epoch13, step408]: loss 1.117304
[epoch13, step409]: loss 1.448016
[epoch13, step410]: loss 13.741346
[epoch13, step411]: loss 1.147099
[epoch13, step412]: loss 1.429768
[epoch13, step413]: loss 1.219439
[epoch13, step414]: loss 2.174649
[epoch13, step415]: loss 1.369800
[epoch13, step416]: loss 10.481479
[epoch13, step417]: loss 11.815787
[epoch13, step418]: loss 11.498880
[epoch13, step419]: loss 17.603880
[epoch13, step420]: loss 6.199742
[epoch13, step421]: loss 1.566528
[epoch13, step422]: loss 20.574127
[epoch13, step423]: loss 2.599935
[epoch13, step424]: loss 1.140318
[epoch13, step425]: loss 12.427238
[epoch13, step426]: loss 3.271385
[epoch13, step427]: loss 11.107548
[epoch13, step428]: loss 5.031793
[epoch13, step429]: loss 2.151550
[epoch13, step430]: loss 5.087249
[epoch13, step431]: loss 0.934721
[epoch13, step432]: loss 7.159046
[epoch13, step433]: loss 1.027382
[epoch13, step434]: loss 8.371167
[epoch13, step435]: loss 1.233130
[epoch13, step436]: loss 4.872691
[epoch13, step437]: loss 1.033135
[epoch13, step438]: loss 1.316062
[epoch13, step439]: loss 1.265715
[epoch13, step440]: loss 9.623976
[epoch13, step441]: loss 1.040569
[epoch13, step442]: loss 7.634003
[epoch13, step443]: loss 1.950744
[epoch13, step444]: loss 1.084958
[epoch13, step445]: loss 8.984319
[epoch13, step446]: loss 1.640576
[epoch13, step447]: loss 12.540579
[epoch13, step448]: loss 9.668929
[epoch13, step449]: loss 3.357893
[epoch13, step450]: loss 2.974807
[epoch13, step451]: loss 3.420759
[epoch13, step452]: loss 1.916180
[epoch13, step453]: loss 2.928994
[epoch13, step454]: loss 1.275136
[epoch13, step455]: loss 8.353151
[epoch13, step456]: loss 4.010091
[epoch13, step457]: loss 1.046613
[epoch13, step458]: loss 4.275756
[epoch13, step459]: loss 10.254854
[epoch13, step460]: loss 1.811343
[epoch13, step461]: loss 2.428123
[epoch13, step462]: loss 3.048359
[epoch13, step463]: loss 3.881414
[epoch13, step464]: loss 5.641701
[epoch13, step465]: loss 2.020299
[epoch13, step466]: loss 9.360555
[epoch13, step467]: loss 1.148707
[epoch13, step468]: loss 7.270586
[epoch13, step469]: loss 7.488401
[epoch13, step470]: loss 18.255434
[epoch13, step471]: loss 2.929117
[epoch13, step472]: loss 2.383110
[epoch13, step473]: loss 1.986021
[epoch13, step474]: loss 12.740282
[epoch13, step475]: loss 2.989089
[epoch13, step476]: loss 9.510394
[epoch13, step477]: loss 1.983983
[epoch13, step478]: loss 2.911067
[epoch13, step479]: loss 11.498301
[epoch13, step480]: loss 1.057547
[epoch13, step481]: loss 1.733008
[epoch13, step482]: loss 7.753366
[epoch13, step483]: loss 11.186007
[epoch13, step484]: loss 8.923504
[epoch13, step485]: loss 4.223022
[epoch13, step486]: loss 14.852870
[epoch13, step487]: loss 1.015019
[epoch13, step488]: loss 1.047444
[epoch13, step489]: loss 7.180109
[epoch13, step490]: loss 7.828463
[epoch13, step491]: loss 1.120718
[epoch13, step492]: loss 0.889606
[epoch13, step493]: loss 0.871469
[epoch13, step494]: loss 1.928835
[epoch13, step495]: loss 1.452910
[epoch13, step496]: loss 11.320877
[epoch13, step497]: loss 1.138328
[epoch13, step498]: loss 2.578719
[epoch13, step499]: loss 7.250461
[epoch13, step500]: loss 1.431786
[epoch13, step501]: loss 5.080607
[epoch13, step502]: loss 1.847666
[epoch13, step503]: loss 3.950874
[epoch13, step504]: loss 6.507871
[epoch13, step505]: loss 5.910015
[epoch13, step506]: loss 0.732534
[epoch13, step507]: loss 1.398348
[epoch13, step508]: loss 13.221638
[epoch13, step509]: loss 1.266590
[epoch13, step510]: loss 2.851739
[epoch13, step511]: loss 7.543947
[epoch13, step512]: loss 6.759504
[epoch13, step513]: loss 1.777360
[epoch13, step514]: loss 6.774373
[epoch13, step515]: loss 0.915847
[epoch13, step516]: loss 1.070236
[epoch13, step517]: loss 0.966701
[epoch13, step518]: loss 1.434307
[epoch13, step519]: loss 4.093048
[epoch13, step520]: loss 1.570954
[epoch13, step521]: loss 2.340018
[epoch13, step522]: loss 5.249662
[epoch13, step523]: loss 1.308010
[epoch13, step524]: loss 1.741599
[epoch13, step525]: loss 4.707701
[epoch13, step526]: loss 1.518837
[epoch13, step527]: loss 0.856104
[epoch13, step528]: loss 8.337991
[epoch13, step529]: loss 12.934833
[epoch13, step530]: loss 1.078169
[epoch13, step531]: loss 1.776960
[epoch13, step532]: loss 2.187773
[epoch13, step533]: loss 1.238675
[epoch13, step534]: loss 15.316106
[epoch13, step535]: loss 9.400722
[epoch13, step536]: loss 1.077946
[epoch13, step537]: loss 5.352297
[epoch13, step538]: loss 2.101565
[epoch13, step539]: loss 7.999555
[epoch13, step540]: loss 0.682995
[epoch13, step541]: loss 9.089498
[epoch13, step542]: loss 7.881147
[epoch13, step543]: loss 4.157543
[epoch13, step544]: loss 1.380452
[epoch13, step545]: loss 1.177760
[epoch13, step546]: loss 3.485647
[epoch13, step547]: loss 3.562492
[epoch13, step548]: loss 9.125470
[epoch13, step549]: loss 1.019117
[epoch13, step550]: loss 4.468385
[epoch13, step551]: loss 8.415834
[epoch13, step552]: loss 1.689350
[epoch13, step553]: loss 10.379361
[epoch13, step554]: loss 8.345725
[epoch13, step555]: loss 9.625101
[epoch13, step556]: loss 1.106005
[epoch13, step557]: loss 1.992094
[epoch13, step558]: loss 1.053386
[epoch13, step559]: loss 11.550030
[epoch13, step560]: loss 5.317742
[epoch13, step561]: loss 0.904282
[epoch13, step562]: loss 1.937857
[epoch13, step563]: loss 2.034940
[epoch13, step564]: loss 1.722938
[epoch13, step565]: loss 0.955723
[epoch13, step566]: loss 1.626587
[epoch13, step567]: loss 6.572278
[epoch13, step568]: loss 0.926719
[epoch13, step569]: loss 1.593864
[epoch13, step570]: loss 9.041391
[epoch13, step571]: loss 5.980073
[epoch13, step572]: loss 3.448752
[epoch13, step573]: loss 1.333507
[epoch13, step574]: loss 0.892618
[epoch13, step575]: loss 1.008502
[epoch13, step576]: loss 9.349588
[epoch13, step577]: loss 3.563078
[epoch13, step578]: loss 1.133564
[epoch13, step579]: loss 2.440464
[epoch13, step580]: loss 1.223697
[epoch13, step581]: loss 10.221265
[epoch13, step582]: loss 4.195247
[epoch13, step583]: loss 1.217058
[epoch13, step584]: loss 7.460804
[epoch13, step585]: loss 1.496956
[epoch13, step586]: loss 1.289029
[epoch13, step587]: loss 1.138317
[epoch13, step588]: loss 1.348267
[epoch13, step589]: loss 3.789026
[epoch13, step590]: loss 6.384674
[epoch13, step591]: loss 1.845273
[epoch13, step592]: loss 1.247721
[epoch13, step593]: loss 1.092552
[epoch13, step594]: loss 2.038532
[epoch13, step595]: loss 11.382618
[epoch13, step596]: loss 5.024579
[epoch13, step597]: loss 1.056963
[epoch13, step598]: loss 9.302649
[epoch13, step599]: loss 1.508204
[epoch13, step600]: loss 8.997224
[epoch13, step601]: loss 1.242229
[epoch13, step602]: loss 7.456453
[epoch13, step603]: loss 1.974656
[epoch13, step604]: loss 1.545275
[epoch13, step605]: loss 1.413016
[epoch13, step606]: loss 7.078878
[epoch13, step607]: loss 1.280305
[epoch13, step608]: loss 7.353103
[epoch13, step609]: loss 3.046195
[epoch13, step610]: loss 0.986941
[epoch13, step611]: loss 1.973848
[epoch13, step612]: loss 0.752552
[epoch13, step613]: loss 1.151514
[epoch13, step614]: loss 0.964431
[epoch13, step615]: loss 1.897628
[epoch13, step616]: loss 0.652879
[epoch13, step617]: loss 3.973958
[epoch13, step618]: loss 7.047282
[epoch13, step619]: loss 1.703519
[epoch13, step620]: loss 1.895522
[epoch13, step621]: loss 11.079535
[epoch13, step622]: loss 0.934844
[epoch13, step623]: loss 6.017420
[epoch13, step624]: loss 5.534256
[epoch13, step625]: loss 5.298617
[epoch13, step626]: loss 8.018370
[epoch13, step627]: loss 2.089611
[epoch13, step628]: loss 1.352792
[epoch13, step629]: loss 1.734530
[epoch13, step630]: loss 0.969475
[epoch13, step631]: loss 1.362768
[epoch13, step632]: loss 1.961031
[epoch13, step633]: loss 1.630798
[epoch13, step634]: loss 1.443628
[epoch13, step635]: loss 0.853550
[epoch13, step636]: loss 0.906956
[epoch13, step637]: loss 1.203961
[epoch13, step638]: loss 9.167347
[epoch13, step639]: loss 2.296584
[epoch13, step640]: loss 7.302431
[epoch13, step641]: loss 2.078936
[epoch13, step642]: loss 1.736301
[epoch13, step643]: loss 3.775029
[epoch13, step644]: loss 3.896806
[epoch13, step645]: loss 3.462833
[epoch13, step646]: loss 2.525624
[epoch13, step647]: loss 1.114267
[epoch13, step648]: loss 1.930016
[epoch13, step649]: loss 1.243017
[epoch13, step650]: loss 3.175568
[epoch13, step651]: loss 6.152474
[epoch13, step652]: loss 2.013669
[epoch13, step653]: loss 0.996661
[epoch13, step654]: loss 1.714564
[epoch13, step655]: loss 14.369181
[epoch13, step656]: loss 2.258103
[epoch13, step657]: loss 3.953618
[epoch13, step658]: loss 5.867683
[epoch13, step659]: loss 3.098310
[epoch13, step660]: loss 2.804455
[epoch13, step661]: loss 1.298867
[epoch13, step662]: loss 1.313420
[epoch13, step663]: loss 3.051142
[epoch13, step664]: loss 3.167695
[epoch13, step665]: loss 2.481181
[epoch13, step666]: loss 15.784537
[epoch13, step667]: loss 1.061997
[epoch13, step668]: loss 1.925982
[epoch13, step669]: loss 5.852609
[epoch13, step670]: loss 0.726453
[epoch13, step671]: loss 1.058790
[epoch13, step672]: loss 0.868316
[epoch13, step673]: loss 2.118872
[epoch13, step674]: loss 1.049685
[epoch13, step675]: loss 2.063310
[epoch13, step676]: loss 0.804088
[epoch13, step677]: loss 8.355544
[epoch13, step678]: loss 2.817189
[epoch13, step679]: loss 1.119940
[epoch13, step680]: loss 9.584321
[epoch13, step681]: loss 1.871781
[epoch13, step682]: loss 11.493687
[epoch13, step683]: loss 2.696899
[epoch13, step684]: loss 2.098257
[epoch13, step685]: loss 1.423363
[epoch13, step686]: loss 7.241293
[epoch13, step687]: loss 1.124121
[epoch13, step688]: loss 5.363224
[epoch13, step689]: loss 3.582647
[epoch13, step690]: loss 4.447140
[epoch13, step691]: loss 10.848115
[epoch13, step692]: loss 21.055609
[epoch13, step693]: loss 1.662884
[epoch13, step694]: loss 1.097602
[epoch13, step695]: loss 1.185198
[epoch13, step696]: loss 2.690469
[epoch13, step697]: loss 1.669693
[epoch13, step698]: loss 8.138723
[epoch13, step699]: loss 8.762854
[epoch13, step700]: loss 9.534858
[epoch13, step701]: loss 3.270687
[epoch13, step702]: loss 3.367188
[epoch13, step703]: loss 2.002893
[epoch13, step704]: loss 1.087252
[epoch13, step705]: loss 0.731600
[epoch13, step706]: loss 5.505841
[epoch13, step707]: loss 1.272807
[epoch13, step708]: loss 0.986960
[epoch13, step709]: loss 0.954016
[epoch13, step710]: loss 0.982214
[epoch13, step711]: loss 9.811121
[epoch13, step712]: loss 4.773220
[epoch13, step713]: loss 1.002432
[epoch13, step714]: loss 8.462257
[epoch13, step715]: loss 13.459416
[epoch13, step716]: loss 5.668751
[epoch13, step717]: loss 1.258071
[epoch13, step718]: loss 8.954814
[epoch13, step719]: loss 2.704523
[epoch13, step720]: loss 0.997414
[epoch13, step721]: loss 0.970110
[epoch13, step722]: loss 7.529491
[epoch13, step723]: loss 2.305807
[epoch13, step724]: loss 5.328969
[epoch13, step725]: loss 1.297643
[epoch13, step726]: loss 3.026800
[epoch13, step727]: loss 8.759537
[epoch13, step728]: loss 1.131533
[epoch13, step729]: loss 1.201789
[epoch13, step730]: loss 1.643700
[epoch13, step731]: loss 8.501188
[epoch13, step732]: loss 8.399562
[epoch13, step733]: loss 13.402021
[epoch13, step734]: loss 0.972936
[epoch13, step735]: loss 6.506122
[epoch13, step736]: loss 8.348350
[epoch13, step737]: loss 7.300637
[epoch13, step738]: loss 3.436108
[epoch13, step739]: loss 3.734509
[epoch13, step740]: loss 3.705817
[epoch13, step741]: loss 15.528275
[epoch13, step742]: loss 5.982416
[epoch13, step743]: loss 6.928699
[epoch13, step744]: loss 0.921796
[epoch13, step745]: loss 2.866632
[epoch13, step746]: loss 1.498691
[epoch13, step747]: loss 1.174423
[epoch13, step748]: loss 1.049023
[epoch13, step749]: loss 9.113548
[epoch13, step750]: loss 8.227383
[epoch13, step751]: loss 1.026765
[epoch13, step752]: loss 2.785409
[epoch13, step753]: loss 2.026652
[epoch13, step754]: loss 1.289295
[epoch13, step755]: loss 8.883903
[epoch13, step756]: loss 0.751826
[epoch13, step757]: loss 9.846172
[epoch13, step758]: loss 1.003899
[epoch13, step759]: loss 1.029635
[epoch13, step760]: loss 11.271532
[epoch13, step761]: loss 4.739527
[epoch13, step762]: loss 1.235153
[epoch13, step763]: loss 7.146452
[epoch13, step764]: loss 0.712326
[epoch13, step765]: loss 1.609282
[epoch13, step766]: loss 2.688321
[epoch13, step767]: loss 9.922930
[epoch13, step768]: loss 0.700856
[epoch13, step769]: loss 1.745119
[epoch13, step770]: loss 1.829108
[epoch13, step771]: loss 4.250510
[epoch13, step772]: loss 4.481562
[epoch13, step773]: loss 1.341273
[epoch13, step774]: loss 2.965504
[epoch13, step775]: loss 2.251585
[epoch13, step776]: loss 0.989150
[epoch13, step777]: loss 0.778041
[epoch13, step778]: loss 8.014806
[epoch13, step779]: loss 11.760664
[epoch13, step780]: loss 1.430958
[epoch13, step781]: loss 0.818317
[epoch13, step782]: loss 8.187826
[epoch13, step783]: loss 1.599255
[epoch13, step784]: loss 2.406221
[epoch13, step785]: loss 8.679410
[epoch13, step786]: loss 0.983152
[epoch13, step787]: loss 9.917132
[epoch13, step788]: loss 0.911889
[epoch13, step789]: loss 2.764315
[epoch13, step790]: loss 9.742603
[epoch13, step791]: loss 8.727877
[epoch13, step792]: loss 6.014323
[epoch13, step793]: loss 3.436981
[epoch13, step794]: loss 1.272765
[epoch13, step795]: loss 1.089500
[epoch13, step796]: loss 3.331219
[epoch13, step797]: loss 3.054572
[epoch13, step798]: loss 1.263509
[epoch13, step799]: loss 6.947933
[epoch13, step800]: loss 1.091974
[epoch13, step801]: loss 1.696824
[epoch13, step802]: loss 1.598453
[epoch13, step803]: loss 14.367398
[epoch13, step804]: loss 3.039828
[epoch13, step805]: loss 1.436165
[epoch13, step806]: loss 12.274508
[epoch13, step807]: loss 1.119342
[epoch13, step808]: loss 7.043545
[epoch13, step809]: loss 1.659095
[epoch13, step810]: loss 2.709474
[epoch13, step811]: loss 11.788554
[epoch13, step812]: loss 3.689698
[epoch13, step813]: loss 3.701889
[epoch13, step814]: loss 1.167545
[epoch13, step815]: loss 8.603148
[epoch13, step816]: loss 0.731809
[epoch13, step817]: loss 8.404715
[epoch13, step818]: loss 1.967662
[epoch13, step819]: loss 1.904670
[epoch13, step820]: loss 7.566648
[epoch13, step821]: loss 6.929175
[epoch13, step822]: loss 0.685752
[epoch13, step823]: loss 3.155078
[epoch13, step824]: loss 13.830139
[epoch13, step825]: loss 3.416980
[epoch13, step826]: loss 5.249800
[epoch13, step827]: loss 1.914039
[epoch13, step828]: loss 1.725104
[epoch13, step829]: loss 1.778267
[epoch13, step830]: loss 4.553920
[epoch13, step831]: loss 4.743348
[epoch13, step832]: loss 11.425702
[epoch13, step833]: loss 1.864364
[epoch13, step834]: loss 1.608661
[epoch13, step835]: loss 2.641092
[epoch13, step836]: loss 9.074057
[epoch13, step837]: loss 11.096663
[epoch13, step838]: loss 1.445878
[epoch13, step839]: loss 1.060077
[epoch13, step840]: loss 21.489294
[epoch13, step841]: loss 1.044804
[epoch13, step842]: loss 1.625222
[epoch13, step843]: loss 9.772111
[epoch13, step844]: loss 0.807311
[epoch13, step845]: loss 3.578412
[epoch13, step846]: loss 1.130537
[epoch13, step847]: loss 3.164760
[epoch13, step848]: loss 9.334474
[epoch13, step849]: loss 1.753619
[epoch13, step850]: loss 3.078456
[epoch13, step851]: loss 1.399482
[epoch13, step852]: loss 1.893002
[epoch13, step853]: loss 10.436690
[epoch13, step854]: loss 1.048675
[epoch13, step855]: loss 3.064498
[epoch13, step856]: loss 3.989170
[epoch13, step857]: loss 9.461789
[epoch13, step858]: loss 3.209911
[epoch13, step859]: loss 2.617661
[epoch13, step860]: loss 1.327740
[epoch13, step861]: loss 1.282895
[epoch13, step862]: loss 1.148144
[epoch13, step863]: loss 4.312693
[epoch13, step864]: loss 1.638055
[epoch13, step865]: loss 1.511985
[epoch13, step866]: loss 0.859954
[epoch13, step867]: loss 1.122044
[epoch13, step868]: loss 0.910626
[epoch13, step869]: loss 1.332281
[epoch13, step870]: loss 0.935579
[epoch13, step871]: loss 3.213856
[epoch13, step872]: loss 1.599262
[epoch13, step873]: loss 1.659471
[epoch13, step874]: loss 0.906772
[epoch13, step875]: loss 8.022215
[epoch13, step876]: loss 3.637971
[epoch13, step877]: loss 0.895270
[epoch13, step878]: loss 2.041948
[epoch13, step879]: loss 1.290008
[epoch13, step880]: loss 2.150430
[epoch13, step881]: loss 4.332584
[epoch13, step882]: loss 1.424693
[epoch13, step883]: loss 10.812531
[epoch13, step884]: loss 0.849123
[epoch13, step885]: loss 0.885461
[epoch13, step886]: loss 4.128986
[epoch13, step887]: loss 0.993165
[epoch13, step888]: loss 3.479004
[epoch13, step889]: loss 0.800251
[epoch13, step890]: loss 14.740741
[epoch13, step891]: loss 2.403934
[epoch13, step892]: loss 0.726550
[epoch13, step893]: loss 0.903817
[epoch13, step894]: loss 0.883212
[epoch13, step895]: loss 3.402464
[epoch13, step896]: loss 7.494791
[epoch13, step897]: loss 8.259955
[epoch13, step898]: loss 1.244781
[epoch13, step899]: loss 12.185560
[epoch13, step900]: loss 5.326391
[epoch13, step901]: loss 0.928446
[epoch13, step902]: loss 1.917521
[epoch13, step903]: loss 5.677502
[epoch13, step904]: loss 5.062137
[epoch13, step905]: loss 5.987130
[epoch13, step906]: loss 1.221435
[epoch13, step907]: loss 1.752118
[epoch13, step908]: loss 2.117475
[epoch13, step909]: loss 1.210450
[epoch13, step910]: loss 3.082911
[epoch13, step911]: loss 1.533306
[epoch13, step912]: loss 10.615797
[epoch13, step913]: loss 2.990778
[epoch13, step914]: loss 0.757810
[epoch13, step915]: loss 0.806792
[epoch13, step916]: loss 1.401674
[epoch13, step917]: loss 17.113106
[epoch13, step918]: loss 1.361355
[epoch13, step919]: loss 3.578735
[epoch13, step920]: loss 2.281485
[epoch13, step921]: loss 11.273888
[epoch13, step922]: loss 3.491021
[epoch13, step923]: loss 1.019512
[epoch13, step924]: loss 1.693476
[epoch13, step925]: loss 2.893757
[epoch13, step926]: loss 16.686239
[epoch13, step927]: loss 1.343102
[epoch13, step928]: loss 2.530045
[epoch13, step929]: loss 1.216284
[epoch13, step930]: loss 1.610804
[epoch13, step931]: loss 1.339595
[epoch13, step932]: loss 1.386697
[epoch13, step933]: loss 11.217918
[epoch13, step934]: loss 0.789280
[epoch13, step935]: loss 8.023284
[epoch13, step936]: loss 2.990221
[epoch13, step937]: loss 10.537500
[epoch13, step938]: loss 0.794982
[epoch13, step939]: loss 1.109669
[epoch13, step940]: loss 1.114532
[epoch13, step941]: loss 1.353589
[epoch13, step942]: loss 1.481555
[epoch13, step943]: loss 3.977319
[epoch13, step944]: loss 1.341615
[epoch13, step945]: loss 15.684319
[epoch13, step946]: loss 6.359146
[epoch13, step947]: loss 3.513997
[epoch13, step948]: loss 1.498819
[epoch13, step949]: loss 9.532557
[epoch13, step950]: loss 0.730401
[epoch13, step951]: loss 1.620428
[epoch13, step952]: loss 7.571291
[epoch13, step953]: loss 6.696274
[epoch13, step954]: loss 1.194981
[epoch13, step955]: loss 10.043731
[epoch13, step956]: loss 2.801046
[epoch13, step957]: loss 1.249218
[epoch13, step958]: loss 1.840841
[epoch13, step959]: loss 1.146409
[epoch13, step960]: loss 2.735023
[epoch13, step961]: loss 2.014625
[epoch13, step962]: loss 4.958458
[epoch13, step963]: loss 3.016742
[epoch13, step964]: loss 2.921962
[epoch13, step965]: loss 1.097782
[epoch13, step966]: loss 2.969696
[epoch13, step967]: loss 0.813031
[epoch13, step968]: loss 1.803835
[epoch13, step969]: loss 2.809910
[epoch13, step970]: loss 1.500243
[epoch13, step971]: loss 9.410973
[epoch13, step972]: loss 1.199869
[epoch13, step973]: loss 2.728034
[epoch13, step974]: loss 1.974675
[epoch13, step975]: loss 1.229305
[epoch13, step976]: loss 0.728790
[epoch13, step977]: loss 3.299900
[epoch13, step978]: loss 3.245839
[epoch13, step979]: loss 1.293408
[epoch13, step980]: loss 1.452969
[epoch13, step981]: loss 0.934834
[epoch13, step982]: loss 4.875041
[epoch13, step983]: loss 1.694774
[epoch13, step984]: loss 3.413861
[epoch13, step985]: loss 16.907541
[epoch13, step986]: loss 3.516832
[epoch13, step987]: loss 7.967779
[epoch13, step988]: loss 14.895396
[epoch13, step989]: loss 1.804147
[epoch13, step990]: loss 8.197474
[epoch13, step991]: loss 9.019488
[epoch13, step992]: loss 1.285525
[epoch13, step993]: loss 13.444669
[epoch13, step994]: loss 1.080512
[epoch13, step995]: loss 1.813595
[epoch13, step996]: loss 4.035988
[epoch13, step997]: loss 2.774303
[epoch13, step998]: loss 10.666464
[epoch13, step999]: loss 1.287569
[epoch13, step1000]: loss 3.349560
[epoch13, step1001]: loss 2.991482
[epoch13, step1002]: loss 1.620452
[epoch13, step1003]: loss 1.153456
[epoch13, step1004]: loss 1.444994
[epoch13, step1005]: loss 1.716879
[epoch13, step1006]: loss 3.651687
[epoch13, step1007]: loss 8.599712
[epoch13, step1008]: loss 1.828831
[epoch13, step1009]: loss 0.748237
[epoch13, step1010]: loss 10.610858
[epoch13, step1011]: loss 1.011869
[epoch13, step1012]: loss 1.328981
[epoch13, step1013]: loss 3.143486
[epoch13, step1014]: loss 11.300844
[epoch13, step1015]: loss 0.949859
[epoch13, step1016]: loss 12.442410
[epoch13, step1017]: loss 3.017840
[epoch13, step1018]: loss 6.436630
[epoch13, step1019]: loss 6.732169
[epoch13, step1020]: loss 8.408220
[epoch13, step1021]: loss 1.010041
[epoch13, step1022]: loss 3.377266
[epoch13, step1023]: loss 13.306139
[epoch13, step1024]: loss 2.559267
[epoch13, step1025]: loss 3.634219
[epoch13, step1026]: loss 2.281430
[epoch13, step1027]: loss 6.767282
[epoch13, step1028]: loss 10.310544
[epoch13, step1029]: loss 0.615408
[epoch13, step1030]: loss 1.135326
[epoch13, step1031]: loss 1.313019
[epoch13, step1032]: loss 3.294436
[epoch13, step1033]: loss 6.827456
[epoch13, step1034]: loss 9.140415
[epoch13, step1035]: loss 4.284753
[epoch13, step1036]: loss 7.091934
[epoch13, step1037]: loss 16.054304
[epoch13, step1038]: loss 0.916519
[epoch13, step1039]: loss 12.902917
[epoch13, step1040]: loss 2.222116
[epoch13, step1041]: loss 1.368778
[epoch13, step1042]: loss 2.211097
[epoch13, step1043]: loss 1.977544
[epoch13, step1044]: loss 1.646148
[epoch13, step1045]: loss 4.562479
[epoch13, step1046]: loss 2.715219
[epoch13, step1047]: loss 2.225027
[epoch13, step1048]: loss 0.806499
[epoch13, step1049]: loss 15.857260
[epoch13, step1050]: loss 0.828474
[epoch13, step1051]: loss 1.224330
[epoch13, step1052]: loss 14.170170
[epoch13, step1053]: loss 1.261330
[epoch13, step1054]: loss 14.344525
[epoch13, step1055]: loss 0.898416
[epoch13, step1056]: loss 1.269153
[epoch13, step1057]: loss 8.233097
[epoch13, step1058]: loss 4.545053
[epoch13, step1059]: loss 16.278048
[epoch13, step1060]: loss 3.255830
[epoch13, step1061]: loss 7.358115
[epoch13, step1062]: loss 1.325353
[epoch13, step1063]: loss 0.889370
[epoch13, step1064]: loss 9.849606
[epoch13, step1065]: loss 11.486261
[epoch13, step1066]: loss 6.668231
[epoch13, step1067]: loss 1.235287
[epoch13, step1068]: loss 0.996107
[epoch13, step1069]: loss 0.804792
[epoch13, step1070]: loss 1.059506
[epoch13, step1071]: loss 19.828835
[epoch13, step1072]: loss 1.669980
[epoch13, step1073]: loss 6.922458
[epoch13, step1074]: loss 4.993435
[epoch13, step1075]: loss 19.753235
[epoch13, step1076]: loss 5.872899
[epoch13, step1077]: loss 1.156186
[epoch13, step1078]: loss 2.152321
[epoch13, step1079]: loss 9.001258
[epoch13, step1080]: loss 1.022585
[epoch13, step1081]: loss 2.163221
[epoch13, step1082]: loss 17.812899
[epoch13, step1083]: loss 3.176931
[epoch13, step1084]: loss 2.508047
[epoch13, step1085]: loss 10.285932
[epoch13, step1086]: loss 1.202835
[epoch13, step1087]: loss 8.470598
[epoch13, step1088]: loss 7.129850
[epoch13, step1089]: loss 1.479313
[epoch13, step1090]: loss 0.810623
[epoch13, step1091]: loss 1.132427
[epoch13, step1092]: loss 3.318094
[epoch13, step1093]: loss 2.638100
[epoch13, step1094]: loss 2.599184
[epoch13, step1095]: loss 7.320531
[epoch13, step1096]: loss 6.612275
[epoch13, step1097]: loss 3.174815
[epoch13, step1098]: loss 14.265705
[epoch13, step1099]: loss 1.372119
[epoch13, step1100]: loss 1.202287
[epoch13, step1101]: loss 3.475825
[epoch13, step1102]: loss 1.261016
[epoch13, step1103]: loss 1.100221
[epoch13, step1104]: loss 8.490008
[epoch13, step1105]: loss 2.842785
[epoch13, step1106]: loss 8.547299
[epoch13, step1107]: loss 1.590147
[epoch13, step1108]: loss 1.313750
[epoch13, step1109]: loss 0.795091
[epoch13, step1110]: loss 0.816046
[epoch13, step1111]: loss 0.930312
[epoch13, step1112]: loss 0.813452
[epoch13, step1113]: loss 4.250239
[epoch13, step1114]: loss 3.466473
[epoch13, step1115]: loss 2.554439
[epoch13, step1116]: loss 2.939131
[epoch13, step1117]: loss 0.907783
[epoch13, step1118]: loss 5.729421
[epoch13, step1119]: loss 0.875098
[epoch13, step1120]: loss 3.639604
[epoch13, step1121]: loss 1.273504
[epoch13, step1122]: loss 2.496067
[epoch13, step1123]: loss 17.105104
[epoch13, step1124]: loss 4.267102
[epoch13, step1125]: loss 8.294027
[epoch13, step1126]: loss 9.398768
[epoch13, step1127]: loss 10.965387
[epoch13, step1128]: loss 1.879548
[epoch13, step1129]: loss 10.363256
[epoch13, step1130]: loss 1.740680
[epoch13, step1131]: loss 1.772280
[epoch13, step1132]: loss 3.929735
[epoch13, step1133]: loss 0.685808
[epoch13, step1134]: loss 1.611258
[epoch13, step1135]: loss 16.097719
[epoch13, step1136]: loss 2.001009
[epoch13, step1137]: loss 0.798336
[epoch13, step1138]: loss 0.958734
[epoch13, step1139]: loss 7.587988
[epoch13, step1140]: loss 1.181437
[epoch13, step1141]: loss 10.949899
[epoch13, step1142]: loss 8.234530
[epoch13, step1143]: loss 0.892791
[epoch13, step1144]: loss 1.005806
[epoch13, step1145]: loss 20.978045
[epoch13, step1146]: loss 8.613251
[epoch13, step1147]: loss 1.118713
[epoch13, step1148]: loss 1.953446
[epoch13, step1149]: loss 4.777908
[epoch13, step1150]: loss 10.643001
[epoch13, step1151]: loss 12.876607
[epoch13, step1152]: loss 8.349678
[epoch13, step1153]: loss 2.211425
[epoch13, step1154]: loss 1.851511
[epoch13, step1155]: loss 1.294983
[epoch13, step1156]: loss 1.929179
[epoch13, step1157]: loss 2.038543
[epoch13, step1158]: loss 6.541986
[epoch13, step1159]: loss 0.948444
[epoch13, step1160]: loss 8.210748
[epoch13, step1161]: loss 1.110208
[epoch13, step1162]: loss 10.636027
[epoch13, step1163]: loss 9.644866
[epoch13, step1164]: loss 3.295035
[epoch13, step1165]: loss 1.583333
[epoch13, step1166]: loss 9.473013
[epoch13, step1167]: loss 3.544596
[epoch13, step1168]: loss 23.947639
[epoch13, step1169]: loss 5.966797
[epoch13, step1170]: loss 0.969111
[epoch13, step1171]: loss 1.129577
[epoch13, step1172]: loss 4.789958
[epoch13, step1173]: loss 1.818947
[epoch13, step1174]: loss 2.092567
[epoch13, step1175]: loss 3.962096
[epoch13, step1176]: loss 2.915772
[epoch13, step1177]: loss 2.581745
[epoch13, step1178]: loss 0.903514
[epoch13, step1179]: loss 7.331410
[epoch13, step1180]: loss 5.811015
[epoch13, step1181]: loss 7.889746
[epoch13, step1182]: loss 2.746232
[epoch13, step1183]: loss 0.915532
[epoch13, step1184]: loss 4.543974
[epoch13, step1185]: loss 10.013408
[epoch13, step1186]: loss 12.175813
[epoch13, step1187]: loss 8.319759
[epoch13, step1188]: loss 0.852017
[epoch13, step1189]: loss 1.016234
[epoch13, step1190]: loss 1.211378
[epoch13, step1191]: loss 5.058663
[epoch13, step1192]: loss 0.770603
[epoch13, step1193]: loss 2.313553
[epoch13, step1194]: loss 9.404103
[epoch13, step1195]: loss 0.962649
[epoch13, step1196]: loss 6.457215
[epoch13, step1197]: loss 1.689440
[epoch13, step1198]: loss 2.375142
[epoch13, step1199]: loss 1.142228
[epoch13, step1200]: loss 1.409814
[epoch13, step1201]: loss 15.091209
[epoch13, step1202]: loss 10.617944
[epoch13, step1203]: loss 12.128829
[epoch13, step1204]: loss 7.214139
[epoch13, step1205]: loss 8.859384
[epoch13, step1206]: loss 1.333310
[epoch13, step1207]: loss 1.666694
[epoch13, step1208]: loss 5.630807
[epoch13, step1209]: loss 20.993647
[epoch13, step1210]: loss 1.600190
[epoch13, step1211]: loss 16.686531
[epoch13, step1212]: loss 11.628518
[epoch13, step1213]: loss 0.788749
[epoch13, step1214]: loss 3.743959
[epoch13, step1215]: loss 1.659590
[epoch13, step1216]: loss 2.555083
[epoch13, step1217]: loss 7.757254
[epoch13, step1218]: loss 1.460852
[epoch13, step1219]: loss 9.920901
[epoch13, step1220]: loss 1.540231
[epoch13, step1221]: loss 4.495046
[epoch13, step1222]: loss 1.122456
[epoch13, step1223]: loss 7.782378
[epoch13, step1224]: loss 1.019976
[epoch13, step1225]: loss 1.721017
[epoch13, step1226]: loss 13.186280
[epoch13, step1227]: loss 8.891500
[epoch13, step1228]: loss 9.280197
[epoch13, step1229]: loss 0.697952
[epoch13, step1230]: loss 1.967022
[epoch13, step1231]: loss 3.203988
[epoch13, step1232]: loss 1.185508
[epoch13, step1233]: loss 10.634509
[epoch13, step1234]: loss 0.773427
[epoch13, step1235]: loss 1.164436
[epoch13, step1236]: loss 0.774489
[epoch13, step1237]: loss 1.262925
[epoch13, step1238]: loss 3.123633
[epoch13, step1239]: loss 22.050323
[epoch13, step1240]: loss 8.335543
[epoch13, step1241]: loss 0.789194
[epoch13, step1242]: loss 4.386477
[epoch13, step1243]: loss 1.299183
[epoch13, step1244]: loss 0.656973
[epoch13, step1245]: loss 6.836189
[epoch13, step1246]: loss 2.334050
[epoch13, step1247]: loss 1.331954
[epoch13, step1248]: loss 1.107113
[epoch13, step1249]: loss 1.759959
[epoch13, step1250]: loss 1.579054
[epoch13, step1251]: loss 1.843460
[epoch13, step1252]: loss 8.967709
[epoch13, step1253]: loss 1.333616
[epoch13, step1254]: loss 3.131535
[epoch13, step1255]: loss 2.928201
[epoch13, step1256]: loss 4.898674
[epoch13, step1257]: loss 1.391392
[epoch13, step1258]: loss 18.640495
[epoch13, step1259]: loss 1.007266
[epoch13, step1260]: loss 2.015764
[epoch13, step1261]: loss 1.405147
[epoch13, step1262]: loss 2.100933
[epoch13, step1263]: loss 0.973758
[epoch13, step1264]: loss 12.496006
[epoch13, step1265]: loss 0.854704
[epoch13, step1266]: loss 0.946891
[epoch13, step1267]: loss 3.958418
[epoch13, step1268]: loss 0.795915
[epoch13, step1269]: loss 14.923981
[epoch13, step1270]: loss 3.089211
[epoch13, step1271]: loss 1.708195
[epoch13, step1272]: loss 2.953831
[epoch13, step1273]: loss 7.224465
[epoch13, step1274]: loss 10.153418
[epoch13, step1275]: loss 14.021456
[epoch13, step1276]: loss 1.749608
[epoch13, step1277]: loss 1.519626
[epoch13, step1278]: loss 0.753107
[epoch13, step1279]: loss 3.463181
[epoch13, step1280]: loss 2.065684
[epoch13, step1281]: loss 8.680859
[epoch13, step1282]: loss 8.877814
[epoch13, step1283]: loss 1.883025
[epoch13, step1284]: loss 0.754315
[epoch13, step1285]: loss 3.106216
[epoch13, step1286]: loss 1.003510
[epoch13, step1287]: loss 1.184153
[epoch13, step1288]: loss 9.036191
[epoch13, step1289]: loss 1.839913
[epoch13, step1290]: loss 1.132453
[epoch13, step1291]: loss 7.849831
[epoch13, step1292]: loss 10.843069
[epoch13, step1293]: loss 1.371683
[epoch13, step1294]: loss 8.409639
[epoch13, step1295]: loss 4.727625
[epoch13, step1296]: loss 15.442786
[epoch13, step1297]: loss 1.455182
[epoch13, step1298]: loss 1.828931
[epoch13, step1299]: loss 24.283648
[epoch13, step1300]: loss 13.532284
[epoch13, step1301]: loss 3.852401
[epoch13, step1302]: loss 11.483007
[epoch13, step1303]: loss 4.590055
[epoch13, step1304]: loss 11.713381
[epoch13, step1305]: loss 2.309182
[epoch13, step1306]: loss 4.692993
[epoch13, step1307]: loss 9.748646
[epoch13, step1308]: loss 9.385254
[epoch13, step1309]: loss 0.941303
[epoch13, step1310]: loss 4.641050
[epoch13, step1311]: loss 3.833982
[epoch13, step1312]: loss 1.280004
[epoch13, step1313]: loss 3.172295
[epoch13, step1314]: loss 6.248007
[epoch13, step1315]: loss 11.300114
[epoch13, step1316]: loss 10.432700
[epoch13, step1317]: loss 4.108179
[epoch13, step1318]: loss 0.767755
[epoch13, step1319]: loss 5.365130
[epoch13, step1320]: loss 1.139528
[epoch13, step1321]: loss 3.089546
[epoch13, step1322]: loss 3.486926
[epoch13, step1323]: loss 15.488884
[epoch13, step1324]: loss 1.589100
[epoch13, step1325]: loss 0.751783
[epoch13, step1326]: loss 2.081988
[epoch13, step1327]: loss 8.976134
[epoch13, step1328]: loss 0.763198
[epoch13, step1329]: loss 0.929547
[epoch13, step1330]: loss 1.274387
[epoch13, step1331]: loss 3.797685
[epoch13, step1332]: loss 1.331587
[epoch13, step1333]: loss 0.975472
[epoch13, step1334]: loss 1.480964
[epoch13, step1335]: loss 1.676934
[epoch13, step1336]: loss 1.271716
[epoch13, step1337]: loss 2.082277
[epoch13, step1338]: loss 8.106403
[epoch13, step1339]: loss 6.014795
[epoch13, step1340]: loss 3.081988
[epoch13, step1341]: loss 2.566951
[epoch13, step1342]: loss 1.095854
[epoch13, step1343]: loss 3.454502
[epoch13, step1344]: loss 16.284904
[epoch13, step1345]: loss 1.011595
[epoch13, step1346]: loss 2.005035
[epoch13, step1347]: loss 5.175583
[epoch13, step1348]: loss 1.034406
[epoch13, step1349]: loss 12.486641
[epoch13, step1350]: loss 7.091222
[epoch13, step1351]: loss 12.375545
[epoch13, step1352]: loss 1.283086
[epoch13, step1353]: loss 0.599208
[epoch13, step1354]: loss 0.863816
[epoch13, step1355]: loss 4.562221
[epoch13, step1356]: loss 4.614811
[epoch13, step1357]: loss 8.354368
[epoch13, step1358]: loss 14.896250
[epoch13, step1359]: loss 2.790874
[epoch13, step1360]: loss 2.252633
[epoch13, step1361]: loss 3.375863
[epoch13, step1362]: loss 0.951476
[epoch13, step1363]: loss 9.926972
[epoch13, step1364]: loss 6.638201
[epoch13, step1365]: loss 1.075194
[epoch13, step1366]: loss 5.025309
[epoch13, step1367]: loss 0.960788
[epoch13, step1368]: loss 1.420854
[epoch13, step1369]: loss 1.044422
[epoch13, step1370]: loss 11.350047
[epoch13, step1371]: loss 0.845311
[epoch13, step1372]: loss 15.685892
[epoch13, step1373]: loss 3.572593
[epoch13, step1374]: loss 0.994106
[epoch13, step1375]: loss 12.821511
[epoch13, step1376]: loss 1.716413
[epoch13, step1377]: loss 9.812866
[epoch13, step1378]: loss 4.012332
[epoch13, step1379]: loss 0.561962
[epoch13, step1380]: loss 1.342529
[epoch13, step1381]: loss 2.348690
[epoch13, step1382]: loss 11.017399
[epoch13, step1383]: loss 3.620127
[epoch13, step1384]: loss 2.230120
[epoch13, step1385]: loss 0.803928
[epoch13, step1386]: loss 2.547906
[epoch13, step1387]: loss 1.536067
[epoch13, step1388]: loss 1.296859
[epoch13, step1389]: loss 39.844238
[epoch13, step1390]: loss 9.019054
[epoch13, step1391]: loss 3.964366
[epoch13, step1392]: loss 1.399142
[epoch13, step1393]: loss 2.141270
[epoch13, step1394]: loss 1.206551
[epoch13, step1395]: loss 1.040406
[epoch13, step1396]: loss 5.934317
[epoch13, step1397]: loss 11.137190
[epoch13, step1398]: loss 5.789878
[epoch13, step1399]: loss 0.664669
[epoch13, step1400]: loss 2.491607
[epoch13, step1401]: loss 10.398925
[epoch13, step1402]: loss 0.859971
[epoch13, step1403]: loss 1.325075
[epoch13, step1404]: loss 1.077894
[epoch13, step1405]: loss 14.388647
[epoch13, step1406]: loss 2.500310
[epoch13, step1407]: loss 1.211419
[epoch13, step1408]: loss 12.203555
[epoch13, step1409]: loss 3.874559
[epoch13, step1410]: loss 1.261758
[epoch13, step1411]: loss 1.250180
[epoch13, step1412]: loss 8.979447
[epoch13, step1413]: loss 3.304282
[epoch13, step1414]: loss 1.916225
[epoch13, step1415]: loss 1.204893
[epoch13, step1416]: loss 9.942119
[epoch13, step1417]: loss 9.497111
[epoch13, step1418]: loss 3.876710
[epoch13, step1419]: loss 1.390692
[epoch13, step1420]: loss 7.858813
[epoch13, step1421]: loss 15.586635
[epoch13, step1422]: loss 1.657715
[epoch13, step1423]: loss 1.417495
[epoch13, step1424]: loss 2.046164
[epoch13, step1425]: loss 1.954541
[epoch13, step1426]: loss 1.591915
[epoch13, step1427]: loss 1.765658
[epoch13, step1428]: loss 7.855708
[epoch13, step1429]: loss 1.887730
[epoch13, step1430]: loss 1.102190
[epoch13, step1431]: loss 1.103702
[epoch13, step1432]: loss 1.744646
[epoch13, step1433]: loss 1.399650
[epoch13, step1434]: loss 10.467549
[epoch13, step1435]: loss 1.184216
[epoch13, step1436]: loss 1.726568
[epoch13, step1437]: loss 4.897670
[epoch13, step1438]: loss 0.979530
[epoch13, step1439]: loss 1.465968
[epoch13, step1440]: loss 0.654986
[epoch13, step1441]: loss 1.526432
[epoch13, step1442]: loss 1.116068
[epoch13, step1443]: loss 9.971123
[epoch13, step1444]: loss 1.320635
[epoch13, step1445]: loss 6.811195
[epoch13, step1446]: loss 2.986869
[epoch13, step1447]: loss 2.983615
[epoch13, step1448]: loss 5.106571
[epoch13, step1449]: loss 6.891115
[epoch13, step1450]: loss 0.977618
[epoch13, step1451]: loss 6.312687
[epoch13, step1452]: loss 1.929710
[epoch13, step1453]: loss 1.318448
[epoch13, step1454]: loss 1.429060
[epoch13, step1455]: loss 8.711110
[epoch13, step1456]: loss 17.692478
[epoch13, step1457]: loss 2.109640
[epoch13, step1458]: loss 0.896537
[epoch13, step1459]: loss 12.326908
[epoch13, step1460]: loss 10.395018
[epoch13, step1461]: loss 1.806620
[epoch13, step1462]: loss 0.746620
[epoch13, step1463]: loss 3.252058
[epoch13, step1464]: loss 1.292871
[epoch13, step1465]: loss 7.182819
[epoch13, step1466]: loss 1.494022
[epoch13, step1467]: loss 1.046415
[epoch13, step1468]: loss 10.730026
[epoch13, step1469]: loss 1.165737
[epoch13, step1470]: loss 12.013307
[epoch13, step1471]: loss 0.892331
[epoch13, step1472]: loss 8.577675
[epoch13, step1473]: loss 0.959666
[epoch13, step1474]: loss 0.991174
[epoch13, step1475]: loss 2.612824
[epoch13, step1476]: loss 0.946893
[epoch13, step1477]: loss 1.053965
[epoch13, step1478]: loss 9.071711
[epoch13, step1479]: loss 1.353437
[epoch13, step1480]: loss 3.774100
[epoch13, step1481]: loss 3.715224
[epoch13, step1482]: loss 15.789472
[epoch13, step1483]: loss 1.864737
[epoch13, step1484]: loss 0.814946
[epoch13, step1485]: loss 0.700684
[epoch13, step1486]: loss 2.090234
[epoch13, step1487]: loss 2.053930
[epoch13, step1488]: loss 1.285136
[epoch13, step1489]: loss 7.695807
[epoch13, step1490]: loss 2.323420
[epoch13, step1491]: loss 6.085460
[epoch13, step1492]: loss 3.178265
[epoch13, step1493]: loss 2.004296
[epoch13, step1494]: loss 11.748210
[epoch13, step1495]: loss 6.916968
[epoch13, step1496]: loss 0.985343
[epoch13, step1497]: loss 2.849620
[epoch13, step1498]: loss 1.991088
[epoch13, step1499]: loss 0.753235
[epoch13, step1500]: loss 1.567639
[epoch13, step1501]: loss 1.426914
[epoch13, step1502]: loss 21.350918
[epoch13, step1503]: loss 1.300264
[epoch13, step1504]: loss 3.535092
[epoch13, step1505]: loss 0.909623
[epoch13, step1506]: loss 1.740788
[epoch13, step1507]: loss 24.052658
[epoch13, step1508]: loss 0.672084
[epoch13, step1509]: loss 5.736114
[epoch13, step1510]: loss 17.396238
[epoch13, step1511]: loss 1.206910
[epoch13, step1512]: loss 0.992402
[epoch13, step1513]: loss 4.070757
[epoch13, step1514]: loss 0.808624
[epoch13, step1515]: loss 2.267442
[epoch13, step1516]: loss 1.239238
[epoch13, step1517]: loss 1.279231
[epoch13, step1518]: loss 1.466107
[epoch13, step1519]: loss 3.481094
[epoch13, step1520]: loss 11.308981
[epoch13, step1521]: loss 2.456360
[epoch13, step1522]: loss 1.515563
[epoch13, step1523]: loss 7.666029
[epoch13, step1524]: loss 0.978363
[epoch13, step1525]: loss 9.026000
[epoch13, step1526]: loss 12.995314
[epoch13, step1527]: loss 2.470576
[epoch13, step1528]: loss 6.975679
[epoch13, step1529]: loss 2.347169
[epoch13, step1530]: loss 2.076020
[epoch13, step1531]: loss 0.895005
[epoch13, step1532]: loss 1.931531
[epoch13, step1533]: loss 1.403943
[epoch13, step1534]: loss 3.100897
[epoch13, step1535]: loss 1.647487
[epoch13, step1536]: loss 1.259856
[epoch13, step1537]: loss 1.831248
[epoch13, step1538]: loss 1.883706
[epoch13, step1539]: loss 8.314892
[epoch13, step1540]: loss 2.711429
[epoch13, step1541]: loss 9.884423
[epoch13, step1542]: loss 24.004431
[epoch13, step1543]: loss 1.047050
[epoch13, step1544]: loss 7.560230
[epoch13, step1545]: loss 5.947338
[epoch13, step1546]: loss 1.615269
[epoch13, step1547]: loss 0.710683
[epoch13, step1548]: loss 0.819801
[epoch13, step1549]: loss 11.656146
[epoch13, step1550]: loss 0.753687
[epoch13, step1551]: loss 14.055158
[epoch13, step1552]: loss 14.290636
[epoch13, step1553]: loss 12.821827
[epoch13, step1554]: loss 1.271829
[epoch13, step1555]: loss 1.059921
[epoch13, step1556]: loss 3.544697
[epoch13, step1557]: loss 1.487818
[epoch13, step1558]: loss 8.938848
[epoch13, step1559]: loss 5.943836
[epoch13, step1560]: loss 7.750136
[epoch13, step1561]: loss 1.239919
[epoch13, step1562]: loss 2.619922
[epoch13, step1563]: loss 1.812817
[epoch13, step1564]: loss 2.142124
[epoch13, step1565]: loss 1.564599
[epoch13, step1566]: loss 5.911197
[epoch13, step1567]: loss 1.555550
[epoch13, step1568]: loss 1.014409
[epoch13, step1569]: loss 4.759762
[epoch13, step1570]: loss 3.383926
[epoch13, step1571]: loss 4.161198
[epoch13, step1572]: loss 8.638858
[epoch13, step1573]: loss 0.694064
[epoch13, step1574]: loss 0.977421
[epoch13, step1575]: loss 0.935117
[epoch13, step1576]: loss 3.118155
[epoch13, step1577]: loss 1.639469
[epoch13, step1578]: loss 3.033458
[epoch13, step1579]: loss 11.291925
[epoch13, step1580]: loss 8.155416
[epoch13, step1581]: loss 2.810082
[epoch13, step1582]: loss 1.514711
[epoch13, step1583]: loss 1.942885
[epoch13, step1584]: loss 10.878964
[epoch13, step1585]: loss 8.608076
[epoch13, step1586]: loss 3.801270
[epoch13, step1587]: loss 1.328734
[epoch13, step1588]: loss 1.948238
[epoch13, step1589]: loss 10.834507
[epoch13, step1590]: loss 4.049428
[epoch13, step1591]: loss 2.918990
[epoch13, step1592]: loss 0.685457
[epoch13, step1593]: loss 3.975156
[epoch13, step1594]: loss 4.067084
[epoch13, step1595]: loss 6.746243
[epoch13, step1596]: loss 3.556876
[epoch13, step1597]: loss 1.533798
[epoch13, step1598]: loss 0.629349
[epoch13, step1599]: loss 4.885793
[epoch13, step1600]: loss 1.504266
[epoch13, step1601]: loss 3.733407
[epoch13, step1602]: loss 0.798333
[epoch13, step1603]: loss 9.643702
[epoch13, step1604]: loss 5.051384
[epoch13, step1605]: loss 15.495138
[epoch13, step1606]: loss 9.763892
[epoch13, step1607]: loss 3.312330
[epoch13, step1608]: loss 1.064925
[epoch13, step1609]: loss 8.218027
[epoch13, step1610]: loss 16.324886
[epoch13, step1611]: loss 1.660204
[epoch13, step1612]: loss 3.135060
[epoch13, step1613]: loss 3.395094
[epoch13, step1614]: loss 13.421065
[epoch13, step1615]: loss 14.975057
[epoch13, step1616]: loss 1.086045
[epoch13, step1617]: loss 0.817618
[epoch13, step1618]: loss 3.603487
[epoch13, step1619]: loss 8.878052
[epoch13, step1620]: loss 14.106811
[epoch13, step1621]: loss 2.495674
[epoch13, step1622]: loss 1.627165
[epoch13, step1623]: loss 12.594854
[epoch13, step1624]: loss 11.079171
[epoch13, step1625]: loss 2.715866
[epoch13, step1626]: loss 2.086333
[epoch13, step1627]: loss 4.029545
[epoch13, step1628]: loss 5.503441
[epoch13, step1629]: loss 1.509359
[epoch13, step1630]: loss 20.806553
[epoch13, step1631]: loss 0.767753
[epoch13, step1632]: loss 8.488348
[epoch13, step1633]: loss 0.669378
[epoch13, step1634]: loss 7.340367
[epoch13, step1635]: loss 3.256104
[epoch13, step1636]: loss 1.159082
[epoch13, step1637]: loss 1.552009
[epoch13, step1638]: loss 2.026170
[epoch13, step1639]: loss 1.903835
[epoch13, step1640]: loss 2.796916
[epoch13, step1641]: loss 0.775489
[epoch13, step1642]: loss 6.042384
[epoch13, step1643]: loss 18.851429
[epoch13, step1644]: loss 9.818300
[epoch13, step1645]: loss 1.428032
[epoch13, step1646]: loss 1.361024
[epoch13, step1647]: loss 1.429545
[epoch13, step1648]: loss 0.817526
[epoch13, step1649]: loss 1.588039
[epoch13, step1650]: loss 1.094352
[epoch13, step1651]: loss 1.150488
[epoch13, step1652]: loss 1.391992
[epoch13, step1653]: loss 1.005861
[epoch13, step1654]: loss 3.685479
[epoch13, step1655]: loss 4.736785
[epoch13, step1656]: loss 1.597987
[epoch13, step1657]: loss 1.511875
[epoch13, step1658]: loss 2.120682
[epoch13, step1659]: loss 2.401431
[epoch13, step1660]: loss 5.487166
[epoch13, step1661]: loss 2.806712
[epoch13, step1662]: loss 8.062906
[epoch13, step1663]: loss 0.837624
[epoch13, step1664]: loss 5.644847
[epoch13, step1665]: loss 1.060812
[epoch13, step1666]: loss 1.015331
[epoch13, step1667]: loss 2.174543
[epoch13, step1668]: loss 1.020205
[epoch13, step1669]: loss 8.981894
[epoch13, step1670]: loss 2.119302
[epoch13, step1671]: loss 1.427911
[epoch13, step1672]: loss 1.468491
[epoch13, step1673]: loss 11.475682
[epoch13, step1674]: loss 1.207575
[epoch13, step1675]: loss 1.896692
[epoch13, step1676]: loss 3.385215
[epoch13, step1677]: loss 1.343467
[epoch13, step1678]: loss 1.499661
[epoch13, step1679]: loss 17.302855
[epoch13, step1680]: loss 0.880222
[epoch13, step1681]: loss 0.835503
[epoch13, step1682]: loss 1.329033
[epoch13, step1683]: loss 2.573400
[epoch13, step1684]: loss 0.826622
[epoch13, step1685]: loss 1.141547
[epoch13, step1686]: loss 10.851109
[epoch13, step1687]: loss 1.004781
[epoch13, step1688]: loss 5.097054
[epoch13, step1689]: loss 11.454017
[epoch13, step1690]: loss 11.784238
[epoch13, step1691]: loss 16.547503
[epoch13, step1692]: loss 3.283816
[epoch13, step1693]: loss 10.770901
[epoch13, step1694]: loss 1.029550
[epoch13, step1695]: loss 1.058770
[epoch13, step1696]: loss 2.644605
[epoch13, step1697]: loss 2.248126
[epoch13, step1698]: loss 2.427439
[epoch13, step1699]: loss 8.254062
[epoch13, step1700]: loss 5.066864
[epoch13, step1701]: loss 3.662845
[epoch13, step1702]: loss 2.166209
[epoch13, step1703]: loss 2.933906
[epoch13, step1704]: loss 9.589456
[epoch13, step1705]: loss 1.021919
[epoch13, step1706]: loss 1.420107
[epoch13, step1707]: loss 1.383410
[epoch13, step1708]: loss 1.046144
[epoch13, step1709]: loss 2.447231
[epoch13, step1710]: loss 12.347929
[epoch13, step1711]: loss 3.107297
[epoch13, step1712]: loss 5.465303
[epoch13, step1713]: loss 1.422925
[epoch13, step1714]: loss 6.172009
[epoch13, step1715]: loss 2.231059
[epoch13, step1716]: loss 8.777402
[epoch13, step1717]: loss 3.096113
[epoch13, step1718]: loss 8.506368
[epoch13, step1719]: loss 2.947490
[epoch13, step1720]: loss 14.168857
[epoch13, step1721]: loss 1.634727
[epoch13, step1722]: loss 6.587583
[epoch13, step1723]: loss 2.715841
[epoch13, step1724]: loss 2.298173
[epoch13, step1725]: loss 3.473748
[epoch13, step1726]: loss 1.053627
[epoch13, step1727]: loss 0.888940
[epoch13, step1728]: loss 1.384714
[epoch13, step1729]: loss 9.344073
[epoch13, step1730]: loss 3.474719
[epoch13, step1731]: loss 1.148744
[epoch13, step1732]: loss 1.542249
[epoch13, step1733]: loss 1.079800
[epoch13, step1734]: loss 3.692349
[epoch13, step1735]: loss 3.300540
[epoch13, step1736]: loss 3.050370
[epoch13, step1737]: loss 11.948524
[epoch13, step1738]: loss 1.096858
[epoch13, step1739]: loss 1.079456
[epoch13, step1740]: loss 7.462485
[epoch13, step1741]: loss 3.183274
[epoch13, step1742]: loss 14.147719
[epoch13, step1743]: loss 1.697083
[epoch13, step1744]: loss 1.941078
[epoch13, step1745]: loss 9.377272
[epoch13, step1746]: loss 7.563656
[epoch13, step1747]: loss 12.864624
[epoch13, step1748]: loss 0.898805
[epoch13, step1749]: loss 2.319197
[epoch13, step1750]: loss 8.184851
[epoch13, step1751]: loss 8.436995
[epoch13, step1752]: loss 2.765857
[epoch13, step1753]: loss 11.826821
[epoch13, step1754]: loss 1.475982
[epoch13, step1755]: loss 7.230207
[epoch13, step1756]: loss 1.790751
[epoch13, step1757]: loss 3.773625
[epoch13, step1758]: loss 8.391791
[epoch13, step1759]: loss 7.905573
[epoch13, step1760]: loss 2.246208
[epoch13, step1761]: loss 1.289754
[epoch13, step1762]: loss 3.450744
[epoch13, step1763]: loss 1.159218
[epoch13, step1764]: loss 7.628703
[epoch13, step1765]: loss 1.667272
[epoch13, step1766]: loss 3.294472
[epoch13, step1767]: loss 1.921427
[epoch13, step1768]: loss 8.604877
[epoch13, step1769]: loss 1.440520
[epoch13, step1770]: loss 5.298218
[epoch13, step1771]: loss 9.179235
[epoch13, step1772]: loss 11.420556
[epoch13, step1773]: loss 1.543172
[epoch13, step1774]: loss 9.864237
[epoch13, step1775]: loss 6.930498
[epoch13, step1776]: loss 0.988836
[epoch13, step1777]: loss 2.195517
[epoch13, step1778]: loss 6.071046
[epoch13, step1779]: loss 2.530780
[epoch13, step1780]: loss 0.984210
[epoch13, step1781]: loss 8.498659
[epoch13, step1782]: loss 3.507993
[epoch13, step1783]: loss 2.736569
[epoch13, step1784]: loss 8.334897
[epoch13, step1785]: loss 10.014304
[epoch13, step1786]: loss 1.423436
[epoch13, step1787]: loss 1.179200
[epoch13, step1788]: loss 18.347523
[epoch13, step1789]: loss 8.535761
[epoch13, step1790]: loss 1.404861
[epoch13, step1791]: loss 1.020485
[epoch13, step1792]: loss 2.130678
[epoch13, step1793]: loss 2.863663
[epoch13, step1794]: loss 7.137410
[epoch13, step1795]: loss 1.875924
[epoch13, step1796]: loss 1.576506
[epoch13, step1797]: loss 10.331313
[epoch13, step1798]: loss 2.635610
[epoch13, step1799]: loss 8.441898
[epoch13, step1800]: loss 12.267125
[epoch13, step1801]: loss 1.148112
[epoch13, step1802]: loss 0.884695
[epoch13, step1803]: loss 2.040240
[epoch13, step1804]: loss 7.204228
[epoch13, step1805]: loss 0.738219
[epoch13, step1806]: loss 1.596819
[epoch13, step1807]: loss 9.481738
[epoch13, step1808]: loss 0.951547
[epoch13, step1809]: loss 0.955077
[epoch13, step1810]: loss 1.370851
[epoch13, step1811]: loss 1.980743
[epoch13, step1812]: loss 15.143228
[epoch13, step1813]: loss 7.964085
[epoch13, step1814]: loss 4.176476
[epoch13, step1815]: loss 10.721218
[epoch13, step1816]: loss 3.694489
[epoch13, step1817]: loss 1.119897
[epoch13, step1818]: loss 10.377276
[epoch13, step1819]: loss 1.893949
[epoch13, step1820]: loss 2.486958
[epoch13, step1821]: loss 0.910827
[epoch13, step1822]: loss 11.343154
[epoch13, step1823]: loss 2.637646
[epoch13, step1824]: loss 6.722060
[epoch13, step1825]: loss 0.697911
[epoch13, step1826]: loss 2.397863
[epoch13, step1827]: loss 2.604126
[epoch13, step1828]: loss 0.719112
[epoch13, step1829]: loss 0.805118
[epoch13, step1830]: loss 6.065739
[epoch13, step1831]: loss 0.884677
[epoch13, step1832]: loss 1.901036
[epoch13, step1833]: loss 2.805514
[epoch13, step1834]: loss 1.576355
[epoch13, step1835]: loss 1.749828
[epoch13, step1836]: loss 1.402537
[epoch13, step1837]: loss 1.109270
[epoch13, step1838]: loss 16.476160
[epoch13, step1839]: loss 0.911892
[epoch13, step1840]: loss 2.860974
[epoch13, step1841]: loss 1.021881
[epoch13, step1842]: loss 0.916207
[epoch13, step1843]: loss 1.027567
[epoch13, step1844]: loss 1.110365
[epoch13, step1845]: loss 10.682981
[epoch13, step1846]: loss 3.855181
[epoch13, step1847]: loss 15.777662
[epoch13, step1848]: loss 1.143980
[epoch13, step1849]: loss 1.463575
[epoch13, step1850]: loss 1.016716
[epoch13, step1851]: loss 0.869053
[epoch13, step1852]: loss 3.220277
[epoch13, step1853]: loss 0.879497
[epoch13, step1854]: loss 9.241235
[epoch13, step1855]: loss 12.292109
[epoch13, step1856]: loss 1.047836
[epoch13, step1857]: loss 1.349610
[epoch13, step1858]: loss 13.229811
[epoch13, step1859]: loss 1.219871
[epoch13, step1860]: loss 15.315956
[epoch13, step1861]: loss 0.881230
[epoch13, step1862]: loss 11.518288
[epoch13, step1863]: loss 8.117343
[epoch13, step1864]: loss 4.654224
[epoch13, step1865]: loss 1.998946
[epoch13, step1866]: loss 12.620641
[epoch13, step1867]: loss 8.600476
[epoch13, step1868]: loss 3.419527
[epoch13, step1869]: loss 3.223828
[epoch13, step1870]: loss 20.081787
[epoch13, step1871]: loss 9.483688
[epoch13, step1872]: loss 9.783301
[epoch13, step1873]: loss 1.574778
[epoch13, step1874]: loss 3.609907
[epoch13, step1875]: loss 6.606802
[epoch13, step1876]: loss 1.051517
[epoch13, step1877]: loss 3.454752
[epoch13, step1878]: loss 2.553167
[epoch13, step1879]: loss 7.775209
[epoch13, step1880]: loss 5.734324
[epoch13, step1881]: loss 1.438642
[epoch13, step1882]: loss 0.937962
[epoch13, step1883]: loss 0.725194
[epoch13, step1884]: loss 0.919349
[epoch13, step1885]: loss 1.164311
[epoch13, step1886]: loss 1.774821
[epoch13, step1887]: loss 1.457056
[epoch13, step1888]: loss 1.117091
[epoch13, step1889]: loss 0.911843
[epoch13, step1890]: loss 3.864890
[epoch13, step1891]: loss 10.541511
[epoch13, step1892]: loss 2.705611
[epoch13, step1893]: loss 1.274421
[epoch13, step1894]: loss 0.873863
[epoch13, step1895]: loss 8.840063
[epoch13, step1896]: loss 1.500647
[epoch13, step1897]: loss 0.740587
[epoch13, step1898]: loss 2.941178
[epoch13, step1899]: loss 1.744673
[epoch13, step1900]: loss 2.868236
[epoch13, step1901]: loss 4.386781
[epoch13, step1902]: loss 2.560347
[epoch13, step1903]: loss 0.865623
[epoch13, step1904]: loss 13.246759
[epoch13, step1905]: loss 10.672623
[epoch13, step1906]: loss 10.333920
[epoch13, step1907]: loss 1.203614
[epoch13, step1908]: loss 0.869248
[epoch13, step1909]: loss 1.412123
[epoch13, step1910]: loss 22.391064
[epoch13, step1911]: loss 1.345302
[epoch13, step1912]: loss 1.499223
[epoch13, step1913]: loss 3.022053
[epoch13, step1914]: loss 1.380441
[epoch13, step1915]: loss 10.575593
[epoch13, step1916]: loss 11.240519
[epoch13, step1917]: loss 1.684618
[epoch13, step1918]: loss 3.015473
[epoch13, step1919]: loss 1.292130
[epoch13, step1920]: loss 11.619113
[epoch13, step1921]: loss 1.181520
[epoch13, step1922]: loss 13.550432
[epoch13, step1923]: loss 8.510601
[epoch13, step1924]: loss 2.872109
[epoch13, step1925]: loss 0.642169
[epoch13, step1926]: loss 6.629799
[epoch13, step1927]: loss 1.637948
[epoch13, step1928]: loss 0.624096
[epoch13, step1929]: loss 1.343247
[epoch13, step1930]: loss 2.059603
[epoch13, step1931]: loss 1.024903
[epoch13, step1932]: loss 8.300056
[epoch13, step1933]: loss 10.395496
[epoch13, step1934]: loss 2.756564
[epoch13, step1935]: loss 2.303409
[epoch13, step1936]: loss 2.710804
[epoch13, step1937]: loss 2.184559
[epoch13, step1938]: loss 1.129678
[epoch13, step1939]: loss 1.250846
[epoch13, step1940]: loss 7.312733
[epoch13, step1941]: loss 1.865511
[epoch13, step1942]: loss 2.845778
[epoch13, step1943]: loss 2.555365
[epoch13, step1944]: loss 0.958491
[epoch13, step1945]: loss 0.913744
[epoch13, step1946]: loss 2.055318
[epoch13, step1947]: loss 8.119944
[epoch13, step1948]: loss 0.856341
[epoch13, step1949]: loss 8.733462
[epoch13, step1950]: loss 3.408733
[epoch13, step1951]: loss 7.196630
[epoch13, step1952]: loss 1.839445
[epoch13, step1953]: loss 6.046483
[epoch13, step1954]: loss 4.657188
[epoch13, step1955]: loss 0.901192
[epoch13, step1956]: loss 0.844005
[epoch13, step1957]: loss 10.239000
[epoch13, step1958]: loss 2.713721
[epoch13, step1959]: loss 1.597280
[epoch13, step1960]: loss 4.811025
[epoch13, step1961]: loss 9.346848
[epoch13, step1962]: loss 2.165791
[epoch13, step1963]: loss 1.597695
[epoch13, step1964]: loss 1.056625
[epoch13, step1965]: loss 1.179685
[epoch13, step1966]: loss 1.599539
[epoch13, step1967]: loss 1.015907
[epoch13, step1968]: loss 2.074100
[epoch13, step1969]: loss 2.100361
[epoch13, step1970]: loss 10.664515
[epoch13, step1971]: loss 2.852645
[epoch13, step1972]: loss 7.873621
[epoch13, step1973]: loss 1.016692
[epoch13, step1974]: loss 1.324928
[epoch13, step1975]: loss 1.781744
[epoch13, step1976]: loss 3.013339
[epoch13, step1977]: loss 7.376232
[epoch13, step1978]: loss 2.141800
[epoch13, step1979]: loss 1.985622
[epoch13, step1980]: loss 15.302980
[epoch13, step1981]: loss 10.660037
[epoch13, step1982]: loss 2.393055
[epoch13, step1983]: loss 5.723371
[epoch13, step1984]: loss 8.555838
[epoch13, step1985]: loss 3.062468
[epoch13, step1986]: loss 11.896413
[epoch13, step1987]: loss 16.305773
[epoch13, step1988]: loss 0.836680
[epoch13, step1989]: loss 1.128810
[epoch13, step1990]: loss 11.050880
[epoch13, step1991]: loss 1.276586
[epoch13, step1992]: loss 11.440045
[epoch13, step1993]: loss 0.745656
[epoch13, step1994]: loss 1.122532
[epoch13, step1995]: loss 7.801290
[epoch13, step1996]: loss 2.758264
[epoch13, step1997]: loss 12.822858
[epoch13, step1998]: loss 11.081863
[epoch13, step1999]: loss 2.488736
[epoch13, step2000]: loss 13.007426
[epoch13, step2001]: loss 1.701230
[epoch13, step2002]: loss 16.421507
[epoch13, step2003]: loss 4.542824
[epoch13, step2004]: loss 0.981271
[epoch13, step2005]: loss 1.027910
[epoch13, step2006]: loss 10.072607
[epoch13, step2007]: loss 16.395758
[epoch13, step2008]: loss 1.393116
[epoch13, step2009]: loss 1.191378
[epoch13, step2010]: loss 2.575884
[epoch13, step2011]: loss 1.356933
[epoch13, step2012]: loss 14.265676
[epoch13, step2013]: loss 5.968014
[epoch13, step2014]: loss 8.136221
[epoch13, step2015]: loss 1.179653
[epoch13, step2016]: loss 1.117352
[epoch13, step2017]: loss 1.214942
[epoch13, step2018]: loss 11.440311
[epoch13, step2019]: loss 0.932954
[epoch13, step2020]: loss 8.316786
[epoch13, step2021]: loss 3.132465
[epoch13, step2022]: loss 9.541350
[epoch13, step2023]: loss 2.667168
[epoch13, step2024]: loss 7.781520
[epoch13, step2025]: loss 1.675120
[epoch13, step2026]: loss 1.785567
[epoch13, step2027]: loss 1.201490
[epoch13, step2028]: loss 2.141766
[epoch13, step2029]: loss 1.829981
[epoch13, step2030]: loss 29.336349
[epoch13, step2031]: loss 8.251740
[epoch13, step2032]: loss 0.803751
[epoch13, step2033]: loss 9.699203
[epoch13, step2034]: loss 0.949002
[epoch13, step2035]: loss 1.724240
[epoch13, step2036]: loss 0.739348
[epoch13, step2037]: loss 0.925908
[epoch13, step2038]: loss 1.413743
[epoch13, step2039]: loss 7.344188
[epoch13, step2040]: loss 1.626382
[epoch13, step2041]: loss 3.476021
[epoch13, step2042]: loss 7.571847
[epoch13, step2043]: loss 3.586111
[epoch13, step2044]: loss 5.843523
[epoch13, step2045]: loss 11.116981
[epoch13, step2046]: loss 1.720213
[epoch13, step2047]: loss 1.375278
[epoch13, step2048]: loss 2.451617
[epoch13, step2049]: loss 1.216966
[epoch13, step2050]: loss 1.436275
[epoch13, step2051]: loss 2.782510
[epoch13, step2052]: loss 1.014035
[epoch13, step2053]: loss 0.634805
[epoch13, step2054]: loss 6.286123
[epoch13, step2055]: loss 9.486212
[epoch13, step2056]: loss 2.026531
[epoch13, step2057]: loss 2.088338
[epoch13, step2058]: loss 7.454704
[epoch13, step2059]: loss 1.908524
[epoch13, step2060]: loss 1.648800
[epoch13, step2061]: loss 10.074770
[epoch13, step2062]: loss 1.170158
[epoch13, step2063]: loss 0.885112
[epoch13, step2064]: loss 0.985623
[epoch13, step2065]: loss 1.058205
[epoch13, step2066]: loss 1.176193
[epoch13, step2067]: loss 1.033041
[epoch13, step2068]: loss 1.513218
[epoch13, step2069]: loss 8.832169
[epoch13, step2070]: loss 2.838125
[epoch13, step2071]: loss 1.017231
[epoch13, step2072]: loss 1.468544
[epoch13, step2073]: loss 9.640416
[epoch13, step2074]: loss 1.136380
[epoch13, step2075]: loss 0.730898
[epoch13, step2076]: loss 1.890194
[epoch13, step2077]: loss 0.729981
[epoch13, step2078]: loss 14.227057
[epoch13, step2079]: loss 3.703856
[epoch13, step2080]: loss 22.624857
[epoch13, step2081]: loss 10.883099
[epoch13, step2082]: loss 11.593535
[epoch13, step2083]: loss 11.456901
[epoch13, step2084]: loss 9.652987
[epoch13, step2085]: loss 5.202867
[epoch13, step2086]: loss 0.835557
[epoch13, step2087]: loss 1.787826
[epoch13, step2088]: loss 6.027168
[epoch13, step2089]: loss 9.395590
[epoch13, step2090]: loss 0.745247
[epoch13, step2091]: loss 0.857307
[epoch13, step2092]: loss 0.757630
[epoch13, step2093]: loss 9.948865
[epoch13, step2094]: loss 0.966070
[epoch13, step2095]: loss 0.807593
[epoch13, step2096]: loss 1.541236
[epoch13, step2097]: loss 1.805720
[epoch13, step2098]: loss 2.283687
[epoch13, step2099]: loss 18.905180
[epoch13, step2100]: loss 19.619654
[epoch13, step2101]: loss 3.465276
[epoch13, step2102]: loss 1.970059
[epoch13, step2103]: loss 1.061053
[epoch13, step2104]: loss 10.711268
[epoch13, step2105]: loss 0.690988
[epoch13, step2106]: loss 1.454753
[epoch13, step2107]: loss 3.600361
[epoch13, step2108]: loss 7.890610
[epoch13, step2109]: loss 9.679778
[epoch13, step2110]: loss 1.245197
[epoch13, step2111]: loss 12.389004
[epoch13, step2112]: loss 2.012514
[epoch13, step2113]: loss 1.783370
[epoch13, step2114]: loss 0.925884
[epoch13, step2115]: loss 2.694153
[epoch13, step2116]: loss 3.470612
[epoch13, step2117]: loss 7.985817
[epoch13, step2118]: loss 0.753247
[epoch13, step2119]: loss 2.190107
[epoch13, step2120]: loss 11.386724
[epoch13, step2121]: loss 2.009424
[epoch13, step2122]: loss 15.089102
[epoch13, step2123]: loss 1.164660
[epoch13, step2124]: loss 8.710373
[epoch13, step2125]: loss 2.884008
[epoch13, step2126]: loss 1.429486
[epoch13, step2127]: loss 4.273491
[epoch13, step2128]: loss 1.478443
[epoch13, step2129]: loss 6.608871
[epoch13, step2130]: loss 11.330509
[epoch13, step2131]: loss 0.621617
[epoch13, step2132]: loss 0.806776
[epoch13, step2133]: loss 1.075815
[epoch13, step2134]: loss 1.208829
[epoch13, step2135]: loss 12.689767
[epoch13, step2136]: loss 8.980360
[epoch13, step2137]: loss 1.990459
[epoch13, step2138]: loss 2.337486
[epoch13, step2139]: loss 2.467784
[epoch13, step2140]: loss 3.191430
[epoch13, step2141]: loss 1.428166
[epoch13, step2142]: loss 5.575413
[epoch13, step2143]: loss 1.769136
[epoch13, step2144]: loss 2.217339
[epoch13, step2145]: loss 1.225365
[epoch13, step2146]: loss 1.098793
[epoch13, step2147]: loss 7.888433
[epoch13, step2148]: loss 2.406438
[epoch13, step2149]: loss 5.788089
[epoch13, step2150]: loss 1.947108
[epoch13, step2151]: loss 2.029106
[epoch13, step2152]: loss 3.446037
[epoch13, step2153]: loss 1.311290
[epoch13, step2154]: loss 14.723376
[epoch13, step2155]: loss 6.848088
[epoch13, step2156]: loss 7.361940
[epoch13, step2157]: loss 2.470632
[epoch13, step2158]: loss 2.479163
[epoch13, step2159]: loss 3.927692
[epoch13, step2160]: loss 0.964158
[epoch13, step2161]: loss 6.088596
[epoch13, step2162]: loss 8.492433
[epoch13, step2163]: loss 2.447779
[epoch13, step2164]: loss 0.943089
[epoch13, step2165]: loss 3.425257
[epoch13, step2166]: loss 8.743039
[epoch13, step2167]: loss 9.813712
[epoch13, step2168]: loss 9.229835
[epoch13, step2169]: loss 8.184667
[epoch13, step2170]: loss 2.969345
[epoch13, step2171]: loss 2.371521
[epoch13, step2172]: loss 3.378704
[epoch13, step2173]: loss 1.091721
[epoch13, step2174]: loss 9.991452
[epoch13, step2175]: loss 9.258853
[epoch13, step2176]: loss 0.990921
[epoch13, step2177]: loss 8.111416
[epoch13, step2178]: loss 1.266631
[epoch13, step2179]: loss 1.517705
[epoch13, step2180]: loss 2.421434
[epoch13, step2181]: loss 2.406646
[epoch13, step2182]: loss 8.415119
[epoch13, step2183]: loss 1.423167
[epoch13, step2184]: loss 2.224316
[epoch13, step2185]: loss 1.276667
[epoch13, step2186]: loss 1.211381
[epoch13, step2187]: loss 0.962923
[epoch13, step2188]: loss 1.468318
[epoch13, step2189]: loss 1.007008
[epoch13, step2190]: loss 10.099825
[epoch13, step2191]: loss 15.927244
[epoch13, step2192]: loss 2.763923
[epoch13, step2193]: loss 1.493873
[epoch13, step2194]: loss 1.225369
[epoch13, step2195]: loss 1.105587
[epoch13, step2196]: loss 11.214973
[epoch13, step2197]: loss 0.744767
[epoch13, step2198]: loss 0.775618
[epoch13, step2199]: loss 0.881861
[epoch13, step2200]: loss 1.022575
[epoch13, step2201]: loss 1.253562
[epoch13, step2202]: loss 0.910696
[epoch13, step2203]: loss 2.586723
[epoch13, step2204]: loss 1.258247
[epoch13, step2205]: loss 13.491198
[epoch13, step2206]: loss 12.742808
[epoch13, step2207]: loss 0.892446
[epoch13, step2208]: loss 1.432473
[epoch13, step2209]: loss 7.530414
[epoch13, step2210]: loss 8.615106
[epoch13, step2211]: loss 1.295615
[epoch13, step2212]: loss 4.422734
[epoch13, step2213]: loss 1.521706
[epoch13, step2214]: loss 1.143072
[epoch13, step2215]: loss 0.854717
[epoch13, step2216]: loss 1.232096
[epoch13, step2217]: loss 11.937903
[epoch13, step2218]: loss 3.108261
[epoch13, step2219]: loss 1.134531
[epoch13, step2220]: loss 1.880373
[epoch13, step2221]: loss 2.167739
[epoch13, step2222]: loss 0.884004
[epoch13, step2223]: loss 0.854826
[epoch13, step2224]: loss 3.261074
[epoch13, step2225]: loss 3.504720
[epoch13, step2226]: loss 1.162150
[epoch13, step2227]: loss 1.010540
[epoch13, step2228]: loss 9.032397
[epoch13, step2229]: loss 7.766903
[epoch13, step2230]: loss 7.287856
[epoch13, step2231]: loss 0.715502
[epoch13, step2232]: loss 3.056726
[epoch13, step2233]: loss 1.304105
[epoch13, step2234]: loss 1.055909
[epoch13, step2235]: loss 1.327161
[epoch13, step2236]: loss 0.836083
[epoch13, step2237]: loss 10.875752
[epoch13, step2238]: loss 7.291155
[epoch13, step2239]: loss 1.301963
[epoch13, step2240]: loss 1.026799
[epoch13, step2241]: loss 3.643474
[epoch13, step2242]: loss 8.262824
[epoch13, step2243]: loss 0.805123
[epoch13, step2244]: loss 1.043185
[epoch13, step2245]: loss 0.867646
[epoch13, step2246]: loss 2.055116
[epoch13, step2247]: loss 8.007034
[epoch13, step2248]: loss 4.379839
[epoch13, step2249]: loss 1.126100
[epoch13, step2250]: loss 3.039782
[epoch13, step2251]: loss 2.831238
[epoch13, step2252]: loss 1.225363
[epoch13, step2253]: loss 1.340732
[epoch13, step2254]: loss 1.184365
[epoch13, step2255]: loss 1.741616
[epoch13, step2256]: loss 1.001350
[epoch13, step2257]: loss 0.878386
[epoch13, step2258]: loss 1.308529
[epoch13, step2259]: loss 2.122919
[epoch13, step2260]: loss 7.919899
[epoch13, step2261]: loss 2.900770
[epoch13, step2262]: loss 1.426811
[epoch13, step2263]: loss 6.704863
[epoch13, step2264]: loss 2.650487
[epoch13, step2265]: loss 4.321561
[epoch13, step2266]: loss 3.484883
[epoch13, step2267]: loss 7.968566
[epoch13, step2268]: loss 8.810732
[epoch13, step2269]: loss 1.106323
[epoch13, step2270]: loss 6.038494
[epoch13, step2271]: loss 1.499178
[epoch13, step2272]: loss 8.749204
[epoch13, step2273]: loss 1.051631
[epoch13, step2274]: loss 1.610010
[epoch13, step2275]: loss 7.874956
[epoch13, step2276]: loss 5.570423
[epoch13, step2277]: loss 5.527488
[epoch13, step2278]: loss 1.698448
[epoch13, step2279]: loss 7.345950
[epoch13, step2280]: loss 2.544852
[epoch13, step2281]: loss 2.638617
[epoch13, step2282]: loss 0.625221
[epoch13, step2283]: loss 1.024029
[epoch13, step2284]: loss 2.598957
[epoch13, step2285]: loss 17.160351
[epoch13, step2286]: loss 1.070819
[epoch13, step2287]: loss 13.327556
[epoch13, step2288]: loss 1.114614
[epoch13, step2289]: loss 0.770707
[epoch13, step2290]: loss 7.700904
[epoch13, step2291]: loss 9.210709
[epoch13, step2292]: loss 9.168650
[epoch13, step2293]: loss 1.321646
[epoch13, step2294]: loss 1.971599
[epoch13, step2295]: loss 4.851564
[epoch13, step2296]: loss 1.313454
[epoch13, step2297]: loss 0.764439
[epoch13, step2298]: loss 1.057815
[epoch13, step2299]: loss 8.207270
[epoch13, step2300]: loss 3.012094
[epoch13, step2301]: loss 0.801666
[epoch13, step2302]: loss 5.941018
[epoch13, step2303]: loss 8.095575
[epoch13, step2304]: loss 10.745422
[epoch13, step2305]: loss 1.955212
[epoch13, step2306]: loss 0.924870
[epoch13, step2307]: loss 8.199916
[epoch13, step2308]: loss 10.677371
[epoch13, step2309]: loss 0.918530
[epoch13, step2310]: loss 2.514080
[epoch13, step2311]: loss 3.068785
[epoch13, step2312]: loss 7.831717
[epoch13, step2313]: loss 0.984842
[epoch13, step2314]: loss 3.364651
[epoch13, step2315]: loss 6.451479
[epoch13, step2316]: loss 1.245640
[epoch13, step2317]: loss 1.230040
[epoch13, step2318]: loss 12.140720
[epoch13, step2319]: loss 0.945628
[epoch13, step2320]: loss 9.372357
[epoch13, step2321]: loss 10.012851
[epoch13, step2322]: loss 1.926634
[epoch13, step2323]: loss 7.616117
[epoch13, step2324]: loss 4.428354
[epoch13, step2325]: loss 3.888536
[epoch13, step2326]: loss 0.868701
[epoch13, step2327]: loss 1.246385
[epoch13, step2328]: loss 0.797520
[epoch13, step2329]: loss 1.568995
[epoch13, step2330]: loss 1.710073
[epoch13, step2331]: loss 8.468911
[epoch13, step2332]: loss 7.874839
[epoch13, step2333]: loss 7.739431
[epoch13, step2334]: loss 11.125593
[epoch13, step2335]: loss 1.122513
[epoch13, step2336]: loss 5.090986
[epoch13, step2337]: loss 6.025755
[epoch13, step2338]: loss 1.407990
[epoch13, step2339]: loss 1.446471
[epoch13, step2340]: loss 10.937508
[epoch13, step2341]: loss 1.922466
[epoch13, step2342]: loss 0.738533
[epoch13, step2343]: loss 11.425601
[epoch13, step2344]: loss 1.880045
[epoch13, step2345]: loss 0.914297
[epoch13, step2346]: loss 0.985011
[epoch13, step2347]: loss 4.194039
[epoch13, step2348]: loss 1.720565
[epoch13, step2349]: loss 10.125788
[epoch13, step2350]: loss 1.572112
[epoch13, step2351]: loss 10.115999
[epoch13, step2352]: loss 1.369915
[epoch13, step2353]: loss 1.165744
[epoch13, step2354]: loss 7.074792
[epoch13, step2355]: loss 9.519446
[epoch13, step2356]: loss 3.839302
[epoch13, step2357]: loss 12.432012
[epoch13, step2358]: loss 1.381779
[epoch13, step2359]: loss 0.964062
[epoch13, step2360]: loss 1.366268
[epoch13, step2361]: loss 0.720964
[epoch13, step2362]: loss 15.245433
[epoch13, step2363]: loss 2.681818
[epoch13, step2364]: loss 0.631930
[epoch13, step2365]: loss 1.518835
[epoch13, step2366]: loss 12.146903
[epoch13, step2367]: loss 1.398785
[epoch13, step2368]: loss 1.506569
[epoch13, step2369]: loss 12.930125
[epoch13, step2370]: loss 0.734079
[epoch13, step2371]: loss 0.680429
[epoch13, step2372]: loss 0.772172
[epoch13, step2373]: loss 5.895918
[epoch13, step2374]: loss 2.478334
[epoch13, step2375]: loss 8.314571
[epoch13, step2376]: loss 4.027300
[epoch13, step2377]: loss 7.941117
[epoch13, step2378]: loss 1.143004
[epoch13, step2379]: loss 9.296792
[epoch13, step2380]: loss 1.350371
[epoch13, step2381]: loss 0.765318
[epoch13, step2382]: loss 1.058807
[epoch13, step2383]: loss 7.019234
[epoch13, step2384]: loss 9.819033
[epoch13, step2385]: loss 8.025678
[epoch13, step2386]: loss 8.256598
[epoch13, step2387]: loss 1.176763
[epoch13, step2388]: loss 1.475822
[epoch13, step2389]: loss 9.150319
[epoch13, step2390]: loss 2.828126
[epoch13, step2391]: loss 10.975454
[epoch13, step2392]: loss 0.804520
[epoch13, step2393]: loss 11.583370
[epoch13, step2394]: loss 1.499958
[epoch13, step2395]: loss 1.379224
[epoch13, step2396]: loss 1.294923
[epoch13, step2397]: loss 8.022849
[epoch13, step2398]: loss 1.156815
[epoch13, step2399]: loss 16.154886
[epoch13, step2400]: loss 9.440181
[epoch13, step2401]: loss 3.123657
[epoch13, step2402]: loss 4.514297
[epoch13, step2403]: loss 15.689159
[epoch13, step2404]: loss 2.009074
[epoch13, step2405]: loss 0.721384
[epoch13, step2406]: loss 1.396366
[epoch13, step2407]: loss 6.333162
[epoch13, step2408]: loss 1.261989
[epoch13, step2409]: loss 1.062702
[epoch13, step2410]: loss 2.062173
[epoch13, step2411]: loss 11.394030
[epoch13, step2412]: loss 7.212429
[epoch13, step2413]: loss 0.949842
[epoch13, step2414]: loss 1.912010
[epoch13, step2415]: loss 1.066933
[epoch13, step2416]: loss 0.744233
[epoch13, step2417]: loss 0.942399
[epoch13, step2418]: loss 1.201028
[epoch13, step2419]: loss 1.735050
[epoch13, step2420]: loss 1.750466
[epoch13, step2421]: loss 1.388674
[epoch13, step2422]: loss 0.998967
[epoch13, step2423]: loss 2.341981
[epoch13, step2424]: loss 0.899138
[epoch13, step2425]: loss 0.863465
[epoch13, step2426]: loss 3.856039
[epoch13, step2427]: loss 17.942440
[epoch13, step2428]: loss 2.644565
[epoch13, step2429]: loss 1.621643
[epoch13, step2430]: loss 0.667270
[epoch13, step2431]: loss 9.282348
[epoch13, step2432]: loss 1.411015
[epoch13, step2433]: loss 3.925587
[epoch13, step2434]: loss 8.346918
[epoch13, step2435]: loss 2.137280
[epoch13, step2436]: loss 1.664081
[epoch13, step2437]: loss 1.061866
[epoch13, step2438]: loss 3.497948
[epoch13, step2439]: loss 1.118075
[epoch13, step2440]: loss 2.975746
[epoch13, step2441]: loss 0.890052
[epoch13, step2442]: loss 2.733367
[epoch13, step2443]: loss 1.926272
[epoch13, step2444]: loss 7.639739
[epoch13, step2445]: loss 0.728426
[epoch13, step2446]: loss 1.122858
[epoch13, step2447]: loss 16.909809
[epoch13, step2448]: loss 2.138792
[epoch13, step2449]: loss 9.999937
[epoch13, step2450]: loss 9.912751
[epoch13, step2451]: loss 1.315745
[epoch13, step2452]: loss 1.948126
[epoch13, step2453]: loss 11.135649
[epoch13, step2454]: loss 16.927088
[epoch13, step2455]: loss 1.256141
[epoch13, step2456]: loss 20.731903
[epoch13, step2457]: loss 5.553854
[epoch13, step2458]: loss 5.003734
[epoch13, step2459]: loss 1.490080
[epoch13, step2460]: loss 1.070397
[epoch13, step2461]: loss 1.341041
[epoch13, step2462]: loss 19.541544
[epoch13, step2463]: loss 12.133092
[epoch13, step2464]: loss 12.878448
[epoch13, step2465]: loss 0.838969
[epoch13, step2466]: loss 1.315442
[epoch13, step2467]: loss 1.155434
[epoch13, step2468]: loss 1.026183
[epoch13, step2469]: loss 2.528082
[epoch13, step2470]: loss 2.065211
[epoch13, step2471]: loss 2.701356
[epoch13, step2472]: loss 0.836257
[epoch13, step2473]: loss 1.122662
[epoch13, step2474]: loss 3.461122
[epoch13, step2475]: loss 1.369359
[epoch13, step2476]: loss 2.866738
[epoch13, step2477]: loss 1.283072
[epoch13, step2478]: loss 2.826445
[epoch13, step2479]: loss 1.615000
[epoch13, step2480]: loss 1.463682
[epoch13, step2481]: loss 9.121297
[epoch13, step2482]: loss 12.181917
[epoch13, step2483]: loss 1.027262
[epoch13, step2484]: loss 10.705089
[epoch13, step2485]: loss 3.174883
[epoch13, step2486]: loss 14.113420
[epoch13, step2487]: loss 1.252586
[epoch13, step2488]: loss 6.423072
[epoch13, step2489]: loss 5.444803
[epoch13, step2490]: loss 1.445490
[epoch13, step2491]: loss 7.885654
[epoch13, step2492]: loss 1.248300
[epoch13, step2493]: loss 0.787434
[epoch13, step2494]: loss 0.795999
[epoch13, step2495]: loss 2.376810
[epoch13, step2496]: loss 0.950617
[epoch13, step2497]: loss 0.842083
[epoch13, step2498]: loss 0.853989
[epoch13, step2499]: loss 7.224169
[epoch13, step2500]: loss 0.800636
[epoch13, step2501]: loss 10.487555
[epoch13, step2502]: loss 13.449509
[epoch13, step2503]: loss 15.610462
[epoch13, step2504]: loss 4.024756
[epoch13, step2505]: loss 0.631910
[epoch13, step2506]: loss 15.634507
[epoch13, step2507]: loss 7.772087
[epoch13, step2508]: loss 0.983704
[epoch13, step2509]: loss 2.300121
[epoch13, step2510]: loss 1.234133
[epoch13, step2511]: loss 13.520603
[epoch13, step2512]: loss 18.313416
[epoch13, step2513]: loss 10.941216
[epoch13, step2514]: loss 1.961549
[epoch13, step2515]: loss 2.807901
[epoch13, step2516]: loss 1.419327
[epoch13, step2517]: loss 0.834111
[epoch13, step2518]: loss 5.221156
[epoch13, step2519]: loss 8.865316
[epoch13, step2520]: loss 1.671564
[epoch13, step2521]: loss 12.054938
[epoch13, step2522]: loss 8.982266
[epoch13, step2523]: loss 3.516218
[epoch13, step2524]: loss 9.289336
[epoch13, step2525]: loss 1.551847
[epoch13, step2526]: loss 1.948083
[epoch13, step2527]: loss 1.892016
[epoch13, step2528]: loss 0.988858
[epoch13, step2529]: loss 0.740409
[epoch13, step2530]: loss 0.848009
[epoch13, step2531]: loss 1.106684
[epoch13, step2532]: loss 11.049566
[epoch13, step2533]: loss 1.198490
[epoch13, step2534]: loss 1.009009
[epoch13, step2535]: loss 12.013508
[epoch13, step2536]: loss 1.143262
[epoch13, step2537]: loss 1.433034
[epoch13, step2538]: loss 1.021188
[epoch13, step2539]: loss 9.442252
[epoch13, step2540]: loss 12.977221
[epoch13, step2541]: loss 1.495845
[epoch13, step2542]: loss 7.704663
[epoch13, step2543]: loss 1.046664
[epoch13, step2544]: loss 1.133612
[epoch13, step2545]: loss 1.505053
[epoch13, step2546]: loss 13.387517
[epoch13, step2547]: loss 7.325515
[epoch13, step2548]: loss 0.891447
[epoch13, step2549]: loss 1.104990
[epoch13, step2550]: loss 1.147657
[epoch13, step2551]: loss 2.289116
[epoch13, step2552]: loss 16.126032
[epoch13, step2553]: loss 5.698887
[epoch13, step2554]: loss 8.982227
[epoch13, step2555]: loss 8.665449
[epoch13, step2556]: loss 3.453200
[epoch13, step2557]: loss 2.651371
[epoch13, step2558]: loss 8.365996
[epoch13, step2559]: loss 4.306819
[epoch13, step2560]: loss 10.441807
[epoch13, step2561]: loss 1.353977
[epoch13, step2562]: loss 2.288843
[epoch13, step2563]: loss 3.764273
[epoch13, step2564]: loss 2.116297
[epoch13, step2565]: loss 8.573287
[epoch13, step2566]: loss 6.353852
[epoch13, step2567]: loss 7.421612
[epoch13, step2568]: loss 5.071561
[epoch13, step2569]: loss 10.539256
[epoch13, step2570]: loss 7.958364
[epoch13, step2571]: loss 0.889434
[epoch13, step2572]: loss 8.398219
[epoch13, step2573]: loss 6.123378
[epoch13, step2574]: loss 1.259216
[epoch13, step2575]: loss 0.978694
[epoch13, step2576]: loss 1.168762
[epoch13, step2577]: loss 3.205320
[epoch13, step2578]: loss 1.343813
[epoch13, step2579]: loss 2.822951
[epoch13, step2580]: loss 11.911313
[epoch13, step2581]: loss 6.680227
[epoch13, step2582]: loss 0.781939
[epoch13, step2583]: loss 1.381486
[epoch13, step2584]: loss 5.003825
[epoch13, step2585]: loss 13.172459
[epoch13, step2586]: loss 10.321689
[epoch13, step2587]: loss 8.956474
[epoch13, step2588]: loss 1.962981
[epoch13, step2589]: loss 2.877463
[epoch13, step2590]: loss 1.234384
[epoch13, step2591]: loss 3.288247
[epoch13, step2592]: loss 9.508029
[epoch13, step2593]: loss 6.985570
[epoch13, step2594]: loss 1.195508
[epoch13, step2595]: loss 1.565320
[epoch13, step2596]: loss 1.788229
[epoch13, step2597]: loss 9.063446
[epoch13, step2598]: loss 1.888312
[epoch13, step2599]: loss 1.257813
[epoch13, step2600]: loss 2.719224
[epoch13, step2601]: loss 0.976145
[epoch13, step2602]: loss 0.682943
[epoch13, step2603]: loss 1.643274
[epoch13, step2604]: loss 2.599730
[epoch13, step2605]: loss 7.590583
[epoch13, step2606]: loss 3.557471
[epoch13, step2607]: loss 1.947261
[epoch13, step2608]: loss 9.017185
[epoch13, step2609]: loss 1.245318
[epoch13, step2610]: loss 0.790149
[epoch13, step2611]: loss 0.894197
[epoch13, step2612]: loss 2.488133
[epoch13, step2613]: loss 16.030310
[epoch13, step2614]: loss 5.024707
[epoch13, step2615]: loss 2.755902
[epoch13, step2616]: loss 0.880745
[epoch13, step2617]: loss 1.850432
[epoch13, step2618]: loss 1.209193
[epoch13, step2619]: loss 18.702435
[epoch13, step2620]: loss 0.964076
[epoch13, step2621]: loss 6.101572
[epoch13, step2622]: loss 7.822498
[epoch13, step2623]: loss 0.980999
[epoch13, step2624]: loss 6.492718
[epoch13, step2625]: loss 6.200457
[epoch13, step2626]: loss 1.503830
[epoch13, step2627]: loss 0.755729
[epoch13, step2628]: loss 7.059248
[epoch13, step2629]: loss 2.822643
[epoch13, step2630]: loss 10.561844
[epoch13, step2631]: loss 3.806743
[epoch13, step2632]: loss 1.053265
[epoch13, step2633]: loss 4.608810
[epoch13, step2634]: loss 1.746862
[epoch13, step2635]: loss 4.489114
[epoch13, step2636]: loss 4.964715
[epoch13, step2637]: loss 1.195548
[epoch13, step2638]: loss 1.525733
[epoch13, step2639]: loss 1.386472
[epoch13, step2640]: loss 1.495526
[epoch13, step2641]: loss 17.482248
[epoch13, step2642]: loss 10.871945
[epoch13, step2643]: loss 0.837287
[epoch13, step2644]: loss 2.844449
[epoch13, step2645]: loss 1.869468
[epoch13, step2646]: loss 0.839743
[epoch13, step2647]: loss 7.408074
[epoch13, step2648]: loss 10.851179
[epoch13, step2649]: loss 3.112761
[epoch13, step2650]: loss 35.642830
[epoch13, step2651]: loss 3.135203
[epoch13, step2652]: loss 1.942924
[epoch13, step2653]: loss 8.486805
[epoch13, step2654]: loss 4.103461
[epoch13, step2655]: loss 2.906723
[epoch13, step2656]: loss 8.154951
[epoch13, step2657]: loss 1.700293
[epoch13, step2658]: loss 1.394346
[epoch13, step2659]: loss 1.725266
[epoch13, step2660]: loss 1.448691
[epoch13, step2661]: loss 1.933820
[epoch13, step2662]: loss 7.214704
[epoch13, step2663]: loss 1.309782
[epoch13, step2664]: loss 1.357032
[epoch13, step2665]: loss 1.584719
[epoch13, step2666]: loss 1.823800
[epoch13, step2667]: loss 9.612412
[epoch13, step2668]: loss 0.844356
[epoch13, step2669]: loss 0.765647
[epoch13, step2670]: loss 8.928056
[epoch13, step2671]: loss 1.478540
[epoch13, step2672]: loss 11.176271
[epoch13, step2673]: loss 1.212287
[epoch13, step2674]: loss 1.313772
[epoch13, step2675]: loss 12.444532
[epoch13, step2676]: loss 2.496602
[epoch13, step2677]: loss 7.447495
[epoch13, step2678]: loss 12.370615
[epoch13, step2679]: loss 1.355188
[epoch13, step2680]: loss 0.692568
[epoch13, step2681]: loss 2.223818
[epoch13, step2682]: loss 1.466415
[epoch13, step2683]: loss 9.521102
[epoch13, step2684]: loss 7.602417
[epoch13, step2685]: loss 7.594502
[epoch13, step2686]: loss 2.957668
[epoch13, step2687]: loss 2.808103
[epoch13, step2688]: loss 0.663188
[epoch13, step2689]: loss 1.322744
[epoch13, step2690]: loss 1.071621
[epoch13, step2691]: loss 2.118773
[epoch13, step2692]: loss 2.543697
[epoch13, step2693]: loss 0.739772
[epoch13, step2694]: loss 12.414605
[epoch13, step2695]: loss 0.949421
[epoch13, step2696]: loss 0.907447
[epoch13, step2697]: loss 0.992336
[epoch13, step2698]: loss 11.511237
[epoch13, step2699]: loss 3.261179
[epoch13, step2700]: loss 7.743925
[epoch13, step2701]: loss 10.405314
[epoch13, step2702]: loss 1.243994
[epoch13, step2703]: loss 0.919604
[epoch13, step2704]: loss 1.366542
[epoch13, step2705]: loss 3.339030
[epoch13, step2706]: loss 0.836822
[epoch13, step2707]: loss 0.965909
[epoch13, step2708]: loss 5.071803
[epoch13, step2709]: loss 3.040296
[epoch13, step2710]: loss 0.769547
[epoch13, step2711]: loss 14.416042
[epoch13, step2712]: loss 7.817165
[epoch13, step2713]: loss 4.189139
[epoch13, step2714]: loss 2.575205
[epoch13, step2715]: loss 2.781588
[epoch13, step2716]: loss 2.886791
[epoch13, step2717]: loss 3.462749
[epoch13, step2718]: loss 1.219263
[epoch13, step2719]: loss 1.501511
[epoch13, step2720]: loss 0.752359
[epoch13, step2721]: loss 9.695635
[epoch13, step2722]: loss 21.755024
[epoch13, step2723]: loss 7.389251
[epoch13, step2724]: loss 0.824388
[epoch13, step2725]: loss 8.090293
[epoch13, step2726]: loss 2.430017
[epoch13, step2727]: loss 3.089839
[epoch13, step2728]: loss 7.906957
[epoch13, step2729]: loss 0.724257
[epoch13, step2730]: loss 0.942468
[epoch13, step2731]: loss 5.078492
[epoch13, step2732]: loss 0.746598
[epoch13, step2733]: loss 0.670516
[epoch13, step2734]: loss 1.008245
[epoch13, step2735]: loss 1.441703
[epoch13, step2736]: loss 2.819520
[epoch13, step2737]: loss 1.524350
[epoch13, step2738]: loss 1.141440
[epoch13, step2739]: loss 7.569980
[epoch13, step2740]: loss 11.042257
[epoch13, step2741]: loss 1.119994
[epoch13, step2742]: loss 3.233438
[epoch13, step2743]: loss 1.193297
[epoch13, step2744]: loss 0.989285
[epoch13, step2745]: loss 3.738290
[epoch13, step2746]: loss 1.022232
[epoch13, step2747]: loss 1.082643
[epoch13, step2748]: loss 14.940838
[epoch13, step2749]: loss 0.818022
[epoch13, step2750]: loss 4.098399
[epoch13, step2751]: loss 1.041464
[epoch13, step2752]: loss 1.178946
[epoch13, step2753]: loss 2.093268
[epoch13, step2754]: loss 1.779719
[epoch13, step2755]: loss 12.109471
[epoch13, step2756]: loss 1.919219
[epoch13, step2757]: loss 0.664482
[epoch13, step2758]: loss 0.893524
[epoch13, step2759]: loss 10.943295
[epoch13, step2760]: loss 1.268403
[epoch13, step2761]: loss 1.831971
[epoch13, step2762]: loss 1.112333
[epoch13, step2763]: loss 1.165859
[epoch13, step2764]: loss 1.004895
[epoch13, step2765]: loss 1.091314
[epoch13, step2766]: loss 1.494106
[epoch13, step2767]: loss 5.187465
[epoch13, step2768]: loss 3.874086
[epoch13, step2769]: loss 5.005160
[epoch13, step2770]: loss 12.844407
[epoch13, step2771]: loss 8.452375
[epoch13, step2772]: loss 8.345659
[epoch13, step2773]: loss 1.741922
[epoch13, step2774]: loss 8.726513
[epoch13, step2775]: loss 0.892464
[epoch13, step2776]: loss 10.688536
[epoch13, step2777]: loss 1.553588
[epoch13, step2778]: loss 2.656757
[epoch13, step2779]: loss 15.444276
[epoch13, step2780]: loss 5.162373
[epoch13, step2781]: loss 1.721805
[epoch13, step2782]: loss 1.092557
[epoch13, step2783]: loss 5.743423
[epoch13, step2784]: loss 2.730570
[epoch13, step2785]: loss 1.420628
[epoch13, step2786]: loss 1.141467
[epoch13, step2787]: loss 11.007907
[epoch13, step2788]: loss 1.048297
[epoch13, step2789]: loss 0.822489
[epoch13, step2790]: loss 10.975712
[epoch13, step2791]: loss 1.370286
[epoch13, step2792]: loss 1.363456
[epoch13, step2793]: loss 1.610659
[epoch13, step2794]: loss 0.809387
[epoch13, step2795]: loss 11.480711
[epoch13, step2796]: loss 8.111626
[epoch13, step2797]: loss 14.530210
[epoch13, step2798]: loss 1.599911
[epoch13, step2799]: loss 1.665834
[epoch13, step2800]: loss 15.349299
[epoch13, step2801]: loss 3.248918
[epoch13, step2802]: loss 3.095353
[epoch13, step2803]: loss 11.775126
[epoch13, step2804]: loss 3.083183
[epoch13, step2805]: loss 0.791132
[epoch13, step2806]: loss 8.184737
[epoch13, step2807]: loss 1.235546
[epoch13, step2808]: loss 10.291168
[epoch13, step2809]: loss 1.783334
[epoch13, step2810]: loss 0.850571
[epoch13, step2811]: loss 0.710981
[epoch13, step2812]: loss 1.247257
[epoch13, step2813]: loss 7.717166
[epoch13, step2814]: loss 2.267840
[epoch13, step2815]: loss 3.773382
[epoch13, step2816]: loss 1.625249
[epoch13, step2817]: loss 2.666523
[epoch13, step2818]: loss 3.221315
[epoch13, step2819]: loss 1.700841
[epoch13, step2820]: loss 6.150756
[epoch13, step2821]: loss 0.855486
[epoch13, step2822]: loss 9.660014
[epoch13, step2823]: loss 3.737294
[epoch13, step2824]: loss 9.885272
[epoch13, step2825]: loss 1.399897
[epoch13, step2826]: loss 1.023189
[epoch13, step2827]: loss 1.054462
[epoch13, step2828]: loss 2.895159
[epoch13, step2829]: loss 1.020103
[epoch13, step2830]: loss 1.000017
[epoch13, step2831]: loss 8.282986
[epoch13, step2832]: loss 0.824586
[epoch13, step2833]: loss 2.838890
[epoch13, step2834]: loss 3.946433
[epoch13, step2835]: loss 1.245255
[epoch13, step2836]: loss 1.096094
[epoch13, step2837]: loss 1.262344
[epoch13, step2838]: loss 1.235841
[epoch13, step2839]: loss 3.169785
[epoch13, step2840]: loss 1.901087
[epoch13, step2841]: loss 1.415036
[epoch13, step2842]: loss 1.053137
[epoch13, step2843]: loss 1.167099
[epoch13, step2844]: loss 2.898012
[epoch13, step2845]: loss 0.722570
[epoch13, step2846]: loss 3.328726
[epoch13, step2847]: loss 0.837768
[epoch13, step2848]: loss 16.749092
[epoch13, step2849]: loss 8.148842
[epoch13, step2850]: loss 1.830386
[epoch13, step2851]: loss 3.126858
[epoch13, step2852]: loss 1.267814
[epoch13, step2853]: loss 0.931104
[epoch13, step2854]: loss 2.566289
[epoch13, step2855]: loss 7.797744
[epoch13, step2856]: loss 2.454187
[epoch13, step2857]: loss 1.767644
[epoch13, step2858]: loss 9.717954
[epoch13, step2859]: loss 1.277973
[epoch13, step2860]: loss 7.375456
[epoch13, step2861]: loss 1.049299
[epoch13, step2862]: loss 18.455202
[epoch13, step2863]: loss 4.680352
[epoch13, step2864]: loss 0.590398
[epoch13, step2865]: loss 5.501560
[epoch13, step2866]: loss 13.604747
[epoch13, step2867]: loss 1.120974
[epoch13, step2868]: loss 3.001007
[epoch13, step2869]: loss 4.173810
[epoch13, step2870]: loss 1.673948
[epoch13, step2871]: loss 10.327418
[epoch13, step2872]: loss 1.344404
[epoch13, step2873]: loss 0.910036
[epoch13, step2874]: loss 0.821494
[epoch13, step2875]: loss 10.486300
[epoch13, step2876]: loss 7.793791
[epoch13, step2877]: loss 1.519620
[epoch13, step2878]: loss 3.025070
[epoch13, step2879]: loss 1.418109
[epoch13, step2880]: loss 1.681338
[epoch13, step2881]: loss 1.418520
[epoch13, step2882]: loss 1.092225
[epoch13, step2883]: loss 1.693702
[epoch13, step2884]: loss 11.407044
[epoch13, step2885]: loss 7.294199
[epoch13, step2886]: loss 15.201247
[epoch13, step2887]: loss 6.968701
[epoch13, step2888]: loss 3.452706
[epoch13, step2889]: loss 1.755176
[epoch13, step2890]: loss 9.556560
[epoch13, step2891]: loss 8.790122
[epoch13, step2892]: loss 2.092597
[epoch13, step2893]: loss 1.377268
[epoch13, step2894]: loss 1.319568
[epoch13, step2895]: loss 0.695345
[epoch13, step2896]: loss 3.114865
[epoch13, step2897]: loss 1.259485
[epoch13, step2898]: loss 4.924731
[epoch13, step2899]: loss 4.868707
[epoch13, step2900]: loss 11.074111
[epoch13, step2901]: loss 6.563743
[epoch13, step2902]: loss 1.103082
[epoch13, step2903]: loss 10.495208
[epoch13, step2904]: loss 1.681902
[epoch13, step2905]: loss 7.051512
[epoch13, step2906]: loss 2.258701
[epoch13, step2907]: loss 0.929498
[epoch13, step2908]: loss 9.176431
[epoch13, step2909]: loss 1.625237
[epoch13, step2910]: loss 1.377223
[epoch13, step2911]: loss 2.820272
[epoch13, step2912]: loss 7.645269
[epoch13, step2913]: loss 1.176923
[epoch13, step2914]: loss 1.428257
[epoch13, step2915]: loss 3.093446
[epoch13, step2916]: loss 2.611826
[epoch13, step2917]: loss 1.544912
[epoch13, step2918]: loss 0.917493
[epoch13, step2919]: loss 0.800332
[epoch13, step2920]: loss 12.607512
[epoch13, step2921]: loss 0.794603
[epoch13, step2922]: loss 2.981964
[epoch13, step2923]: loss 1.268046
[epoch13, step2924]: loss 1.529717
[epoch13, step2925]: loss 0.847829
[epoch13, step2926]: loss 6.859620
[epoch13, step2927]: loss 1.756510
[epoch13, step2928]: loss 3.117766
[epoch13, step2929]: loss 7.850316
[epoch13, step2930]: loss 9.066935
[epoch13, step2931]: loss 3.172381
[epoch13, step2932]: loss 1.542711
[epoch13, step2933]: loss 2.822453
[epoch13, step2934]: loss 0.791426
[epoch13, step2935]: loss 7.331152
[epoch13, step2936]: loss 0.992809
[epoch13, step2937]: loss 1.259629
[epoch13, step2938]: loss 0.761547
[epoch13, step2939]: loss 3.989034
[epoch13, step2940]: loss 2.253774
[epoch13, step2941]: loss 17.739471
[epoch13, step2942]: loss 1.311498
[epoch13, step2943]: loss 5.387565
[epoch13, step2944]: loss 6.523441
[epoch13, step2945]: loss 1.960929
[epoch13, step2946]: loss 2.520861
[epoch13, step2947]: loss 13.056737
[epoch13, step2948]: loss 8.506422
[epoch13, step2949]: loss 1.484103
[epoch13, step2950]: loss 7.855279
[epoch13, step2951]: loss 3.922852
[epoch13, step2952]: loss 7.633517
[epoch13, step2953]: loss 0.943034
[epoch13, step2954]: loss 3.406755
[epoch13, step2955]: loss 0.863388
[epoch13, step2956]: loss 2.926863
[epoch13, step2957]: loss 14.977724
[epoch13, step2958]: loss 1.653805
[epoch13, step2959]: loss 1.876391
[epoch13, step2960]: loss 0.870575
[epoch13, step2961]: loss 1.098177
[epoch13, step2962]: loss 19.509962
[epoch13, step2963]: loss 0.953590
[epoch13, step2964]: loss 1.283033
[epoch13, step2965]: loss 0.537584
[epoch13, step2966]: loss 0.864578
[epoch13, step2967]: loss 12.148678
[epoch13, step2968]: loss 3.838598
[epoch13, step2969]: loss 7.627371
[epoch13, step2970]: loss 2.372469
[epoch13, step2971]: loss 2.152932
[epoch13, step2972]: loss 2.302689
[epoch13, step2973]: loss 0.966393
[epoch13, step2974]: loss 4.525378
[epoch13, step2975]: loss 1.298917
[epoch13, step2976]: loss 14.383697
[epoch13, step2977]: loss 1.461745
[epoch13, step2978]: loss 2.016469
[epoch13, step2979]: loss 1.898295
[epoch13, step2980]: loss 12.945498
[epoch13, step2981]: loss 0.731580
[epoch13, step2982]: loss 2.432387
[epoch13, step2983]: loss 5.971387
[epoch13, step2984]: loss 1.770267
[epoch13, step2985]: loss 21.348326
[epoch13, step2986]: loss 0.957664
[epoch13, step2987]: loss 8.884873
[epoch13, step2988]: loss 0.756137
[epoch13, step2989]: loss 14.959218
[epoch13, step2990]: loss 24.311399
[epoch13, step2991]: loss 14.890448
[epoch13, step2992]: loss 2.034225
[epoch13, step2993]: loss 9.773017
[epoch13, step2994]: loss 6.826331
[epoch13, step2995]: loss 1.999089
[epoch13, step2996]: loss 13.538739
[epoch13, step2997]: loss 6.824293
[epoch13, step2998]: loss 8.145664
[epoch13, step2999]: loss 1.748312
[epoch13, step3000]: loss 8.359651
[epoch13, step3001]: loss 1.189847
[epoch13, step3002]: loss 14.007189
[epoch13, step3003]: loss 4.657466
[epoch13, step3004]: loss 11.759502
[epoch13, step3005]: loss 2.430655
[epoch13, step3006]: loss 1.187275
[epoch13, step3007]: loss 0.776491
[epoch13, step3008]: loss 7.969395
[epoch13, step3009]: loss 1.327086
[epoch13, step3010]: loss 0.894549
[epoch13, step3011]: loss 11.741040
[epoch13, step3012]: loss 8.560400
[epoch13, step3013]: loss 0.825109
[epoch13, step3014]: loss 11.490864
[epoch13, step3015]: loss 0.772209
[epoch13, step3016]: loss 3.168347
[epoch13, step3017]: loss 1.063328
[epoch13, step3018]: loss 7.087437
[epoch13, step3019]: loss 7.291585
[epoch13, step3020]: loss 0.936866
[epoch13, step3021]: loss 1.338494
[epoch13, step3022]: loss 9.686437
[epoch13, step3023]: loss 13.047055
[epoch13, step3024]: loss 2.431038
[epoch13, step3025]: loss 3.807129
[epoch13, step3026]: loss 0.748315
[epoch13, step3027]: loss 2.757575
[epoch13, step3028]: loss 9.691863
[epoch13, step3029]: loss 0.761742
[epoch13, step3030]: loss 0.805918
[epoch13, step3031]: loss 1.094717
[epoch13, step3032]: loss 1.404292
[epoch13, step3033]: loss 3.435950
[epoch13, step3034]: loss 4.555353
[epoch13, step3035]: loss 0.919169
[epoch13, step3036]: loss 3.813587
[epoch13, step3037]: loss 1.713542
[epoch13, step3038]: loss 4.287786
[epoch13, step3039]: loss 1.758388
[epoch13, step3040]: loss 5.700807
[epoch13, step3041]: loss 2.779356
[epoch13, step3042]: loss 0.815200
[epoch13, step3043]: loss 1.968403
[epoch13, step3044]: loss 0.700238
[epoch13, step3045]: loss 11.527263
[epoch13, step3046]: loss 9.308091
[epoch13, step3047]: loss 1.384332
[epoch13, step3048]: loss 2.653858
[epoch13, step3049]: loss 3.045914
[epoch13, step3050]: loss 1.573391
[epoch13, step3051]: loss 1.690842
[epoch13, step3052]: loss 8.986319
[epoch13, step3053]: loss 14.642718
[epoch13, step3054]: loss 1.676761
[epoch13, step3055]: loss 0.981832
[epoch13, step3056]: loss 3.796526
[epoch13, step3057]: loss 3.410283
[epoch13, step3058]: loss 11.681255
[epoch13, step3059]: loss 1.328830
[epoch13, step3060]: loss 5.399793
[epoch13, step3061]: loss 2.567134
[epoch13, step3062]: loss 0.897511
[epoch13, step3063]: loss 0.940460
[epoch13, step3064]: loss 1.137535
[epoch13, step3065]: loss 10.207910
[epoch13, step3066]: loss 10.024356
[epoch13, step3067]: loss 1.323455
[epoch13, step3068]: loss 2.920062
[epoch13, step3069]: loss 1.536994
[epoch13, step3070]: loss 8.361602
[epoch13, step3071]: loss 6.700424
[epoch13, step3072]: loss 2.852927
[epoch13, step3073]: loss 0.991461
[epoch13, step3074]: loss 2.850160
[epoch13, step3075]: loss 4.294170
[epoch13, step3076]: loss 2.700401

[epoch13]: avg loss 2.700401

[epoch14, step1]: loss 5.631137
[epoch14, step2]: loss 1.038649
[epoch14, step3]: loss 1.159671
[epoch14, step4]: loss 3.246860
[epoch14, step5]: loss 6.887221
[epoch14, step6]: loss 1.020191
[epoch14, step7]: loss 3.545342
[epoch14, step8]: loss 1.019550
[epoch14, step9]: loss 4.121347
[epoch14, step10]: loss 3.043372
[epoch14, step11]: loss 0.918853
[epoch14, step12]: loss 1.668786
[epoch14, step13]: loss 1.975458
[epoch14, step14]: loss 14.610944
[epoch14, step15]: loss 7.748146
[epoch14, step16]: loss 1.010130
[epoch14, step17]: loss 1.043364
[epoch14, step18]: loss 7.808063
[epoch14, step19]: loss 0.925409
[epoch14, step20]: loss 0.969362
[epoch14, step21]: loss 26.391382
[epoch14, step22]: loss 1.972836
[epoch14, step23]: loss 11.093018
[epoch14, step24]: loss 10.851904
[epoch14, step25]: loss 7.519284
[epoch14, step26]: loss 1.388892
[epoch14, step27]: loss 1.385969
[epoch14, step28]: loss 2.039193
[epoch14, step29]: loss 5.589971
[epoch14, step30]: loss 2.014160
[epoch14, step31]: loss 0.819675
[epoch14, step32]: loss 3.038223
[epoch14, step33]: loss 1.945776
[epoch14, step34]: loss 0.938213
[epoch14, step35]: loss 16.909771
[epoch14, step36]: loss 1.121521
[epoch14, step37]: loss 3.727133
[epoch14, step38]: loss 1.213647
[epoch14, step39]: loss 1.835109
[epoch14, step40]: loss 0.868466
[epoch14, step41]: loss 1.061014
[epoch14, step42]: loss 9.364430
[epoch14, step43]: loss 4.304552
[epoch14, step44]: loss 0.747558
[epoch14, step45]: loss 0.995381
[epoch14, step46]: loss 1.141617
[epoch14, step47]: loss 1.806140
[epoch14, step48]: loss 8.838358
[epoch14, step49]: loss 12.179865
[epoch14, step50]: loss 0.791633
[epoch14, step51]: loss 0.869221
[epoch14, step52]: loss 0.855578
[epoch14, step53]: loss 2.020441
[epoch14, step54]: loss 8.809997
[epoch14, step55]: loss 7.042717
[epoch14, step56]: loss 3.547096
[epoch14, step57]: loss 1.973035
[epoch14, step58]: loss 1.090350
[epoch14, step59]: loss 2.146166
[epoch14, step60]: loss 0.631504
[epoch14, step61]: loss 5.555385
[epoch14, step62]: loss 1.541657
[epoch14, step63]: loss 0.987166
[epoch14, step64]: loss 2.837504
[epoch14, step65]: loss 0.815224
[epoch14, step66]: loss 2.948366
[epoch14, step67]: loss 13.579544
[epoch14, step68]: loss 1.308846
[epoch14, step69]: loss 9.523296
[epoch14, step70]: loss 9.232000
[epoch14, step71]: loss 0.590706
[epoch14, step72]: loss 1.814648
[epoch14, step73]: loss 0.669089
[epoch14, step74]: loss 0.867566
[epoch14, step75]: loss 5.116828
[epoch14, step76]: loss 11.184324
[epoch14, step77]: loss 1.320233
[epoch14, step78]: loss 1.085847
[epoch14, step79]: loss 10.376732
[epoch14, step80]: loss 10.411451
[epoch14, step81]: loss 11.886388
[epoch14, step82]: loss 2.290011
[epoch14, step83]: loss 1.293321
[epoch14, step84]: loss 1.243494
[epoch14, step85]: loss 3.158020
[epoch14, step86]: loss 0.603859
[epoch14, step87]: loss 1.403935
[epoch14, step88]: loss 1.896019
[epoch14, step89]: loss 0.902549
[epoch14, step90]: loss 10.322982
[epoch14, step91]: loss 1.340250
[epoch14, step92]: loss 11.323278
[epoch14, step93]: loss 7.388951
[epoch14, step94]: loss 1.970859
[epoch14, step95]: loss 12.533218
[epoch14, step96]: loss 1.737125
[epoch14, step97]: loss 0.940363
[epoch14, step98]: loss 11.806166
[epoch14, step99]: loss 7.668355
[epoch14, step100]: loss 1.785448
[epoch14, step101]: loss 11.188157
[epoch14, step102]: loss 1.886214
[epoch14, step103]: loss 1.957188
[epoch14, step104]: loss 4.069082
[epoch14, step105]: loss 1.592395
[epoch14, step106]: loss 0.855459
[epoch14, step107]: loss 15.538989
[epoch14, step108]: loss 1.384753
[epoch14, step109]: loss 0.988720
[epoch14, step110]: loss 1.278149
[epoch14, step111]: loss 8.569715
[epoch14, step112]: loss 2.158665
[epoch14, step113]: loss 2.987590
[epoch14, step114]: loss 2.042657
[epoch14, step115]: loss 6.407547
[epoch14, step116]: loss 1.452435
[epoch14, step117]: loss 4.507447
[epoch14, step118]: loss 2.398649
[epoch14, step119]: loss 2.055803
[epoch14, step120]: loss 1.191606
[epoch14, step121]: loss 1.941208
[epoch14, step122]: loss 0.765419
[epoch14, step123]: loss 1.420101
[epoch14, step124]: loss 1.390218
[epoch14, step125]: loss 9.798567
[epoch14, step126]: loss 3.017659
[epoch14, step127]: loss 1.364255
[epoch14, step128]: loss 1.971784
[epoch14, step129]: loss 0.936243
[epoch14, step130]: loss 2.074282
[epoch14, step131]: loss 8.036728
[epoch14, step132]: loss 0.901002
[epoch14, step133]: loss 8.678938
[epoch14, step134]: loss 2.812413
[epoch14, step135]: loss 4.000922
[epoch14, step136]: loss 13.721244
[epoch14, step137]: loss 1.252093
[epoch14, step138]: loss 0.665793
[epoch14, step139]: loss 0.788474
[epoch14, step140]: loss 1.336348
[epoch14, step141]: loss 1.228538
[epoch14, step142]: loss 11.293930
[epoch14, step143]: loss 2.194723
[epoch14, step144]: loss 2.911218
[epoch14, step145]: loss 4.344273
[epoch14, step146]: loss 11.492403
[epoch14, step147]: loss 0.911818
[epoch14, step148]: loss 22.323212
[epoch14, step149]: loss 0.743069
[epoch14, step150]: loss 7.306673
[epoch14, step151]: loss 4.793890
[epoch14, step152]: loss 1.462329
[epoch14, step153]: loss 7.037566
[epoch14, step154]: loss 9.985178
[epoch14, step155]: loss 13.278914
[epoch14, step156]: loss 7.581853
[epoch14, step157]: loss 1.398723
[epoch14, step158]: loss 3.325946
[epoch14, step159]: loss 2.190906
[epoch14, step160]: loss 0.962041
[epoch14, step161]: loss 1.592781
[epoch14, step162]: loss 27.955238
[epoch14, step163]: loss 2.070932
[epoch14, step164]: loss 2.378033
[epoch14, step165]: loss 7.571035
[epoch14, step166]: loss 1.020026
[epoch14, step167]: loss 11.243555
[epoch14, step168]: loss 1.084767
[epoch14, step169]: loss 2.071636
[epoch14, step170]: loss 1.330047
[epoch14, step171]: loss 1.405572
[epoch14, step172]: loss 13.569566
[epoch14, step173]: loss 4.858541
[epoch14, step174]: loss 2.747426
[epoch14, step175]: loss 5.183301
[epoch14, step176]: loss 0.907373
[epoch14, step177]: loss 5.921004
[epoch14, step178]: loss 11.505682
[epoch14, step179]: loss 1.250468
[epoch14, step180]: loss 3.773476
[epoch14, step181]: loss 1.358638
[epoch14, step182]: loss 0.838604
[epoch14, step183]: loss 0.793745
[epoch14, step184]: loss 3.719394
[epoch14, step185]: loss 1.655046
[epoch14, step186]: loss 1.287892
[epoch14, step187]: loss 2.442602
[epoch14, step188]: loss 12.926673
[epoch14, step189]: loss 1.242726
[epoch14, step190]: loss 1.245639
[epoch14, step191]: loss 7.692039
[epoch14, step192]: loss 1.175714
[epoch14, step193]: loss 0.694488
[epoch14, step194]: loss 5.013705
[epoch14, step195]: loss 13.141392
[epoch14, step196]: loss 10.920953
[epoch14, step197]: loss 0.898214
[epoch14, step198]: loss 1.433827
[epoch14, step199]: loss 8.643230
[epoch14, step200]: loss 1.003045
[epoch14, step201]: loss 8.371181
[epoch14, step202]: loss 0.782039
[epoch14, step203]: loss 1.422029
[epoch14, step204]: loss 13.860006
[epoch14, step205]: loss 0.679277
[epoch14, step206]: loss 10.123873
[epoch14, step207]: loss 1.148159
[epoch14, step208]: loss 1.780202
[epoch14, step209]: loss 1.098383
[epoch14, step210]: loss 2.816925
[epoch14, step211]: loss 7.329485
[epoch14, step212]: loss 9.659193
[epoch14, step213]: loss 1.215501
[epoch14, step214]: loss 5.510400
[epoch14, step215]: loss 0.865253
[epoch14, step216]: loss 8.286656
[epoch14, step217]: loss 6.909481
[epoch14, step218]: loss 2.944120
[epoch14, step219]: loss 7.510912
[epoch14, step220]: loss 2.558857
[epoch14, step221]: loss 1.171233
[epoch14, step222]: loss 8.594085
[epoch14, step223]: loss 7.228570
[epoch14, step224]: loss 1.467383
[epoch14, step225]: loss 3.767730
[epoch14, step226]: loss 2.177495
[epoch14, step227]: loss 13.950787
[epoch14, step228]: loss 7.629997
[epoch14, step229]: loss 5.581845
[epoch14, step230]: loss 7.181492
[epoch14, step231]: loss 1.188312
[epoch14, step232]: loss 1.799354
[epoch14, step233]: loss 1.417910
[epoch14, step234]: loss 1.062892
[epoch14, step235]: loss 13.952837
[epoch14, step236]: loss 3.469855
[epoch14, step237]: loss 23.337893
[epoch14, step238]: loss 1.018940
[epoch14, step239]: loss 9.673180
[epoch14, step240]: loss 6.342604
[epoch14, step241]: loss 13.951375
[epoch14, step242]: loss 2.028140
[epoch14, step243]: loss 10.389094
[epoch14, step244]: loss 2.990804
[epoch14, step245]: loss 1.281182
[epoch14, step246]: loss 8.670722
[epoch14, step247]: loss 1.303974
[epoch14, step248]: loss 0.804655
[epoch14, step249]: loss 2.762480
[epoch14, step250]: loss 1.009774
[epoch14, step251]: loss 1.847324
[epoch14, step252]: loss 8.917451
[epoch14, step253]: loss 1.495371
[epoch14, step254]: loss 1.705626
[epoch14, step255]: loss 1.004359
[epoch14, step256]: loss 36.423187
[epoch14, step257]: loss 2.211403
[epoch14, step258]: loss 4.019735
[epoch14, step259]: loss 0.959773
[epoch14, step260]: loss 1.262418
[epoch14, step261]: loss 2.686327
[epoch14, step262]: loss 1.031060
[epoch14, step263]: loss 2.011268
[epoch14, step264]: loss 0.890823
[epoch14, step265]: loss 2.906925
[epoch14, step266]: loss 4.771753
[epoch14, step267]: loss 1.520753
[epoch14, step268]: loss 5.687930
[epoch14, step269]: loss 1.483647
[epoch14, step270]: loss 1.058829
[epoch14, step271]: loss 0.698511
[epoch14, step272]: loss 1.043470
[epoch14, step273]: loss 13.051202
[epoch14, step274]: loss 0.937203
[epoch14, step275]: loss 1.070498
[epoch14, step276]: loss 10.426222
[epoch14, step277]: loss 7.464503
[epoch14, step278]: loss 6.719505
[epoch14, step279]: loss 0.830549
[epoch14, step280]: loss 10.500838
[epoch14, step281]: loss 1.179677
[epoch14, step282]: loss 10.249219
[epoch14, step283]: loss 1.824607
[epoch14, step284]: loss 8.122492
[epoch14, step285]: loss 0.691214
[epoch14, step286]: loss 2.539528
[epoch14, step287]: loss 1.899698
[epoch14, step288]: loss 0.688804
[epoch14, step289]: loss 3.073960
[epoch14, step290]: loss 1.559317
[epoch14, step291]: loss 7.529134
[epoch14, step292]: loss 2.331885
[epoch14, step293]: loss 3.192915
[epoch14, step294]: loss 3.204152
[epoch14, step295]: loss 2.975212
[epoch14, step296]: loss 7.551339
[epoch14, step297]: loss 9.098142
[epoch14, step298]: loss 1.265794
[epoch14, step299]: loss 2.371567
[epoch14, step300]: loss 6.999760
[epoch14, step301]: loss 7.575637
[epoch14, step302]: loss 0.852878
[epoch14, step303]: loss 0.990360
[epoch14, step304]: loss 9.676558
[epoch14, step305]: loss 1.201811
[epoch14, step306]: loss 9.616587
[epoch14, step307]: loss 20.501387
[epoch14, step308]: loss 2.252055
[epoch14, step309]: loss 7.886837
[epoch14, step310]: loss 7.821238
[epoch14, step311]: loss 3.631294
[epoch14, step312]: loss 1.123097
[epoch14, step313]: loss 2.495218
[epoch14, step314]: loss 1.610276
[epoch14, step315]: loss 8.600124
[epoch14, step316]: loss 0.944719
[epoch14, step317]: loss 1.663873
[epoch14, step318]: loss 2.704367
[epoch14, step319]: loss 0.867034
[epoch14, step320]: loss 1.693638
[epoch14, step321]: loss 10.649981
[epoch14, step322]: loss 3.998138
[epoch14, step323]: loss 2.344437
[epoch14, step324]: loss 1.695426
[epoch14, step325]: loss 4.215845
[epoch14, step326]: loss 3.198299
[epoch14, step327]: loss 1.387547
[epoch14, step328]: loss 1.381341
[epoch14, step329]: loss 2.513285
[epoch14, step330]: loss 1.138166
[epoch14, step331]: loss 12.706067
[epoch14, step332]: loss 1.021679
[epoch14, step333]: loss 17.086086
[epoch14, step334]: loss 10.268624
[epoch14, step335]: loss 1.052623
[epoch14, step336]: loss 1.047157
[epoch14, step337]: loss 1.718963
[epoch14, step338]: loss 18.529964
[epoch14, step339]: loss 2.003493
[epoch14, step340]: loss 2.460398
[epoch14, step341]: loss 0.706600
[epoch14, step342]: loss 3.223192
[epoch14, step343]: loss 0.933308
[epoch14, step344]: loss 2.410165
[epoch14, step345]: loss 4.476263
[epoch14, step346]: loss 0.884405
[epoch14, step347]: loss 1.065395
[epoch14, step348]: loss 0.665795
[epoch14, step349]: loss 3.101034
[epoch14, step350]: loss 6.596320
[epoch14, step351]: loss 2.662878
[epoch14, step352]: loss 1.010597
[epoch14, step353]: loss 1.299982
[epoch14, step354]: loss 1.689069
[epoch14, step355]: loss 1.323338
[epoch14, step356]: loss 8.091846
[epoch14, step357]: loss 11.542110
[epoch14, step358]: loss 3.512529
[epoch14, step359]: loss 9.973100
[epoch14, step360]: loss 0.985357
[epoch14, step361]: loss 0.744789
[epoch14, step362]: loss 1.582129
[epoch14, step363]: loss 1.488694
[epoch14, step364]: loss 2.989920
[epoch14, step365]: loss 0.917991
[epoch14, step366]: loss 3.351105
[epoch14, step367]: loss 3.775004
[epoch14, step368]: loss 0.967819
[epoch14, step369]: loss 0.991609
[epoch14, step370]: loss 2.478204
[epoch14, step371]: loss 11.560680
[epoch14, step372]: loss 3.773662
[epoch14, step373]: loss 2.454076
[epoch14, step374]: loss 1.871456
[epoch14, step375]: loss 11.076086
[epoch14, step376]: loss 1.092878
[epoch14, step377]: loss 0.936447
[epoch14, step378]: loss 1.176363
[epoch14, step379]: loss 1.262721
[epoch14, step380]: loss 8.799218
[epoch14, step381]: loss 5.446186
[epoch14, step382]: loss 17.453043
[epoch14, step383]: loss 8.602302
[epoch14, step384]: loss 5.303456
[epoch14, step385]: loss 1.542136
[epoch14, step386]: loss 10.644629
[epoch14, step387]: loss 0.494465
[epoch14, step388]: loss 2.269332
[epoch14, step389]: loss 0.784391
[epoch14, step390]: loss 1.489566
[epoch14, step391]: loss 2.407943
[epoch14, step392]: loss 2.264223
[epoch14, step393]: loss 2.807958
[epoch14, step394]: loss 1.251949
[epoch14, step395]: loss 1.159323
[epoch14, step396]: loss 2.070819
[epoch14, step397]: loss 7.512798
[epoch14, step398]: loss 9.057727
[epoch14, step399]: loss 1.336410
[epoch14, step400]: loss 1.938331
[epoch14, step401]: loss 2.194254
[epoch14, step402]: loss 1.069656
[epoch14, step403]: loss 3.493388
[epoch14, step404]: loss 1.214303
[epoch14, step405]: loss 15.103010
[epoch14, step406]: loss 7.957455
[epoch14, step407]: loss 8.458656
[epoch14, step408]: loss 1.284040
[epoch14, step409]: loss 10.632296
[epoch14, step410]: loss 1.287652
[epoch14, step411]: loss 9.581827
[epoch14, step412]: loss 4.434336
[epoch14, step413]: loss 1.091488
[epoch14, step414]: loss 7.491423
[epoch14, step415]: loss 5.592653
[epoch14, step416]: loss 3.064559
[epoch14, step417]: loss 1.617587
[epoch14, step418]: loss 0.805136
[epoch14, step419]: loss 3.339041
[epoch14, step420]: loss 1.342348
[epoch14, step421]: loss 1.700576
[epoch14, step422]: loss 23.787716
[epoch14, step423]: loss 7.713469
[epoch14, step424]: loss 1.044191
[epoch14, step425]: loss 5.280419
[epoch14, step426]: loss 0.997258
[epoch14, step427]: loss 1.703254
[epoch14, step428]: loss 12.505887
[epoch14, step429]: loss 9.688925
[epoch14, step430]: loss 0.937468
[epoch14, step431]: loss 7.404916
[epoch14, step432]: loss 3.913153
[epoch14, step433]: loss 3.626543
[epoch14, step434]: loss 1.084362
[epoch14, step435]: loss 2.073730
[epoch14, step436]: loss 3.517967
[epoch14, step437]: loss 3.227119
[epoch14, step438]: loss 4.365448
[epoch14, step439]: loss 0.869842
[epoch14, step440]: loss 8.051648
[epoch14, step441]: loss 1.175233
[epoch14, step442]: loss 7.104875
[epoch14, step443]: loss 5.941467
[epoch14, step444]: loss 4.135739
[epoch14, step445]: loss 1.239692
[epoch14, step446]: loss 0.696805
[epoch14, step447]: loss 1.138780
[epoch14, step448]: loss 2.725809
[epoch14, step449]: loss 7.796491
[epoch14, step450]: loss 4.415142
[epoch14, step451]: loss 1.178119
[epoch14, step452]: loss 1.140604
[epoch14, step453]: loss 7.312969
[epoch14, step454]: loss 2.117981
[epoch14, step455]: loss 0.538795
[epoch14, step456]: loss 7.894115
[epoch14, step457]: loss 0.963276
[epoch14, step458]: loss 0.583994
[epoch14, step459]: loss 0.998634
[epoch14, step460]: loss 1.938471
[epoch14, step461]: loss 3.689141
[epoch14, step462]: loss 8.270562
[epoch14, step463]: loss 7.106639
[epoch14, step464]: loss 6.539469
[epoch14, step465]: loss 1.042171
[epoch14, step466]: loss 1.085814
[epoch14, step467]: loss 0.819785
[epoch14, step468]: loss 1.652634
[epoch14, step469]: loss 7.679754
[epoch14, step470]: loss 1.062031
[epoch14, step471]: loss 2.611933
[epoch14, step472]: loss 9.270825
[epoch14, step473]: loss 1.729219
[epoch14, step474]: loss 1.643652
[epoch14, step475]: loss 8.473674
[epoch14, step476]: loss 2.793937
[epoch14, step477]: loss 1.038652
[epoch14, step478]: loss 7.334522
[epoch14, step479]: loss 1.160356
[epoch14, step480]: loss 3.897922
[epoch14, step481]: loss 9.268573
[epoch14, step482]: loss 1.022671
[epoch14, step483]: loss 1.080816
[epoch14, step484]: loss 7.363599
[epoch14, step485]: loss 0.935004
[epoch14, step486]: loss 2.192322
[epoch14, step487]: loss 1.758411
[epoch14, step488]: loss 7.276734
[epoch14, step489]: loss 0.877704
[epoch14, step490]: loss 1.525194
[epoch14, step491]: loss 7.784955
[epoch14, step492]: loss 3.886905
[epoch14, step493]: loss 3.621438
[epoch14, step494]: loss 12.047116
[epoch14, step495]: loss 9.770327
[epoch14, step496]: loss 0.999959
[epoch14, step497]: loss 1.336828
[epoch14, step498]: loss 0.751259
[epoch14, step499]: loss 1.269660
[epoch14, step500]: loss 10.334031
[epoch14, step501]: loss 1.056172
[epoch14, step502]: loss 3.486399
[epoch14, step503]: loss 0.775676
[epoch14, step504]: loss 7.104797
[epoch14, step505]: loss 0.773459
[epoch14, step506]: loss 5.413819
[epoch14, step507]: loss 18.068624
[epoch14, step508]: loss 0.990696
[epoch14, step509]: loss 1.526376
[epoch14, step510]: loss 8.555584
[epoch14, step511]: loss 6.440516
[epoch14, step512]: loss 0.960469
[epoch14, step513]: loss 5.894818
[epoch14, step514]: loss 0.936118
[epoch14, step515]: loss 1.058954
[epoch14, step516]: loss 1.770420
[epoch14, step517]: loss 1.703129
[epoch14, step518]: loss 2.512877
[epoch14, step519]: loss 2.801942
[epoch14, step520]: loss 9.549132
[epoch14, step521]: loss 0.932327
[epoch14, step522]: loss 1.273925
[epoch14, step523]: loss 0.809547
[epoch14, step524]: loss 0.946245
[epoch14, step525]: loss 1.076776
[epoch14, step526]: loss 1.672035
[epoch14, step527]: loss 3.356333
[epoch14, step528]: loss 2.306931
[epoch14, step529]: loss 1.254634
[epoch14, step530]: loss 3.565284
[epoch14, step531]: loss 14.277636
[epoch14, step532]: loss 8.698976
[epoch14, step533]: loss 1.586938
[epoch14, step534]: loss 1.208541
[epoch14, step535]: loss 1.975323
[epoch14, step536]: loss 19.394211
[epoch14, step537]: loss 1.206982
[epoch14, step538]: loss 1.739698
[epoch14, step539]: loss 2.311959
[epoch14, step540]: loss 4.116640
[epoch14, step541]: loss 0.958053
[epoch14, step542]: loss 1.450060
[epoch14, step543]: loss 10.812335
[epoch14, step544]: loss 6.750645
[epoch14, step545]: loss 2.213837
[epoch14, step546]: loss 1.799748
[epoch14, step547]: loss 1.471929
[epoch14, step548]: loss 1.039263
[epoch14, step549]: loss 4.356448
[epoch14, step550]: loss 7.625504
[epoch14, step551]: loss 12.189510
[epoch14, step552]: loss 1.596798
[epoch14, step553]: loss 2.018633
[epoch14, step554]: loss 2.033439
[epoch14, step555]: loss 2.632123
[epoch14, step556]: loss 1.610900
[epoch14, step557]: loss 1.140428
[epoch14, step558]: loss 1.051247
[epoch14, step559]: loss 1.022525
[epoch14, step560]: loss 1.978124
[epoch14, step561]: loss 0.611573
[epoch14, step562]: loss 7.374626
[epoch14, step563]: loss 3.013296
[epoch14, step564]: loss 7.640483
[epoch14, step565]: loss 1.266149
[epoch14, step566]: loss 1.170787
[epoch14, step567]: loss 8.424879
[epoch14, step568]: loss 32.641544
[epoch14, step569]: loss 4.603617
[epoch14, step570]: loss 15.353811
[epoch14, step571]: loss 0.703444
[epoch14, step572]: loss 1.868842
[epoch14, step573]: loss 1.043954
[epoch14, step574]: loss 2.038209
[epoch14, step575]: loss 2.960148
[epoch14, step576]: loss 7.733093
[epoch14, step577]: loss 22.401892
[epoch14, step578]: loss 1.265204
[epoch14, step579]: loss 11.507833
[epoch14, step580]: loss 2.551018
[epoch14, step581]: loss 0.700742
[epoch14, step582]: loss 1.042843
[epoch14, step583]: loss 0.995336
[epoch14, step584]: loss 1.456348
[epoch14, step585]: loss 9.605022
[epoch14, step586]: loss 3.543323
[epoch14, step587]: loss 0.864745
[epoch14, step588]: loss 1.025855
[epoch14, step589]: loss 2.962591
[epoch14, step590]: loss 1.481423
[epoch14, step591]: loss 2.893129
[epoch14, step592]: loss 8.918198
[epoch14, step593]: loss 2.713287
[epoch14, step594]: loss 1.398861
[epoch14, step595]: loss 1.133964
[epoch14, step596]: loss 2.772508
[epoch14, step597]: loss 11.133125
[epoch14, step598]: loss 0.860622
[epoch14, step599]: loss 4.373436
[epoch14, step600]: loss 3.400897
[epoch14, step601]: loss 5.282753
[epoch14, step602]: loss 1.612146
[epoch14, step603]: loss 4.183202
[epoch14, step604]: loss 1.068398
[epoch14, step605]: loss 14.076385
[epoch14, step606]: loss 4.197365
[epoch14, step607]: loss 9.461576
[epoch14, step608]: loss 0.801739
[epoch14, step609]: loss 0.957454
[epoch14, step610]: loss 1.162338
[epoch14, step611]: loss 2.001101
[epoch14, step612]: loss 20.349051
[epoch14, step613]: loss 0.760031
[epoch14, step614]: loss 1.706557
[epoch14, step615]: loss 2.564337
[epoch14, step616]: loss 2.809066
[epoch14, step617]: loss 3.111539
[epoch14, step618]: loss 0.916265
[epoch14, step619]: loss 7.608598
[epoch14, step620]: loss 5.518867
[epoch14, step621]: loss 1.433605
[epoch14, step622]: loss 3.545350
[epoch14, step623]: loss 7.332604
[epoch14, step624]: loss 7.637789
[epoch14, step625]: loss 0.751266
[epoch14, step626]: loss 1.916705
[epoch14, step627]: loss 0.755361
[epoch14, step628]: loss 2.078814
[epoch14, step629]: loss 3.662442
[epoch14, step630]: loss 0.699209
[epoch14, step631]: loss 2.512892
[epoch14, step632]: loss 12.150131
[epoch14, step633]: loss 0.686733
[epoch14, step634]: loss 16.169525
[epoch14, step635]: loss 4.061646
[epoch14, step636]: loss 11.690038
[epoch14, step637]: loss 2.249382
[epoch14, step638]: loss 2.589267
[epoch14, step639]: loss 2.483356
[epoch14, step640]: loss 4.498510
[epoch14, step641]: loss 1.425185
[epoch14, step642]: loss 0.991172
[epoch14, step643]: loss 3.229239
[epoch14, step644]: loss 0.760193
[epoch14, step645]: loss 3.462815
[epoch14, step646]: loss 1.937871
[epoch14, step647]: loss 0.722744
[epoch14, step648]: loss 7.673439
[epoch14, step649]: loss 1.382357
[epoch14, step650]: loss 2.688976
[epoch14, step651]: loss 1.174945
[epoch14, step652]: loss 0.626958
[epoch14, step653]: loss 6.835758
[epoch14, step654]: loss 0.986300
[epoch14, step655]: loss 1.142633
[epoch14, step656]: loss 0.820297
[epoch14, step657]: loss 2.679435
[epoch14, step658]: loss 0.766923
[epoch14, step659]: loss 7.060755
[epoch14, step660]: loss 3.471037
[epoch14, step661]: loss 0.703099
[epoch14, step662]: loss 7.955325
[epoch14, step663]: loss 5.620904
[epoch14, step664]: loss 2.629686
[epoch14, step665]: loss 1.326584
[epoch14, step666]: loss 5.264207
[epoch14, step667]: loss 0.804082
[epoch14, step668]: loss 6.071507
[epoch14, step669]: loss 0.869196
[epoch14, step670]: loss 0.983988
[epoch14, step671]: loss 9.162558
[epoch14, step672]: loss 0.718058
[epoch14, step673]: loss 2.127709
[epoch14, step674]: loss 1.633428
[epoch14, step675]: loss 2.548570
[epoch14, step676]: loss 2.812335
[epoch14, step677]: loss 1.800009
[epoch14, step678]: loss 0.578719
[epoch14, step679]: loss 1.962332
[epoch14, step680]: loss 9.529778
[epoch14, step681]: loss 20.956026
[epoch14, step682]: loss 1.251544
[epoch14, step683]: loss 13.699969
[epoch14, step684]: loss 6.193029
[epoch14, step685]: loss 0.916337
[epoch14, step686]: loss 1.376780
[epoch14, step687]: loss 0.603523
[epoch14, step688]: loss 9.280980
[epoch14, step689]: loss 1.730196
[epoch14, step690]: loss 1.340572
[epoch14, step691]: loss 0.806725
[epoch14, step692]: loss 3.206889
[epoch14, step693]: loss 8.872008
[epoch14, step694]: loss 11.484690
[epoch14, step695]: loss 4.480968
[epoch14, step696]: loss 12.536891
[epoch14, step697]: loss 8.309486
[epoch14, step698]: loss 7.173482
[epoch14, step699]: loss 1.452860
[epoch14, step700]: loss 4.747165
[epoch14, step701]: loss 1.046359
[epoch14, step702]: loss 6.132592
[epoch14, step703]: loss 7.793625
[epoch14, step704]: loss 1.081997
[epoch14, step705]: loss 0.917060
[epoch14, step706]: loss 1.211986
[epoch14, step707]: loss 7.424350
[epoch14, step708]: loss 1.233087
[epoch14, step709]: loss 11.171232
[epoch14, step710]: loss 0.959096
[epoch14, step711]: loss 2.510995
[epoch14, step712]: loss 4.481671
[epoch14, step713]: loss 8.772224
[epoch14, step714]: loss 3.468375
[epoch14, step715]: loss 0.883937
[epoch14, step716]: loss 0.652885
[epoch14, step717]: loss 0.863103
[epoch14, step718]: loss 17.031776
[epoch14, step719]: loss 11.024816
[epoch14, step720]: loss 1.594597
[epoch14, step721]: loss 1.943139
[epoch14, step722]: loss 0.568678
[epoch14, step723]: loss 6.661148
[epoch14, step724]: loss 1.070279
[epoch14, step725]: loss 1.166841
[epoch14, step726]: loss 1.560952
[epoch14, step727]: loss 0.758221
[epoch14, step728]: loss 9.322131
[epoch14, step729]: loss 3.067920
[epoch14, step730]: loss 12.638710
[epoch14, step731]: loss 2.915097
[epoch14, step732]: loss 2.772899
[epoch14, step733]: loss 0.685409
[epoch14, step734]: loss 14.552341
[epoch14, step735]: loss 15.014542
[epoch14, step736]: loss 7.908798
[epoch14, step737]: loss 1.220055
[epoch14, step738]: loss 1.902763
[epoch14, step739]: loss 13.669687
[epoch14, step740]: loss 11.561234
[epoch14, step741]: loss 3.451176
[epoch14, step742]: loss 0.943679
[epoch14, step743]: loss 0.763607
[epoch14, step744]: loss 1.178954
[epoch14, step745]: loss 1.081658
[epoch14, step746]: loss 1.245932
[epoch14, step747]: loss 1.167370
[epoch14, step748]: loss 1.362237
[epoch14, step749]: loss 1.883069
[epoch14, step750]: loss 0.876971
[epoch14, step751]: loss 2.061975
[epoch14, step752]: loss 9.174405
[epoch14, step753]: loss 4.109326
[epoch14, step754]: loss 11.565547
[epoch14, step755]: loss 11.913746
[epoch14, step756]: loss 1.234738
[epoch14, step757]: loss 3.019250
[epoch14, step758]: loss 1.749916
[epoch14, step759]: loss 3.330896
[epoch14, step760]: loss 0.900417
[epoch14, step761]: loss 16.114677
[epoch14, step762]: loss 1.447798
[epoch14, step763]: loss 0.761936
[epoch14, step764]: loss 2.670396
[epoch14, step765]: loss 0.833317
[epoch14, step766]: loss 1.196109
[epoch14, step767]: loss 2.932566
[epoch14, step768]: loss 8.320488
[epoch14, step769]: loss 2.206140
[epoch14, step770]: loss 2.063581
[epoch14, step771]: loss 0.864295
[epoch14, step772]: loss 3.217905
[epoch14, step773]: loss 1.407337
[epoch14, step774]: loss 2.608572
[epoch14, step775]: loss 3.043031
[epoch14, step776]: loss 2.003351
[epoch14, step777]: loss 7.661790
[epoch14, step778]: loss 7.243527
[epoch14, step779]: loss 13.760897
[epoch14, step780]: loss 9.211454
[epoch14, step781]: loss 1.467965
[epoch14, step782]: loss 1.541450
[epoch14, step783]: loss 16.593891
[epoch14, step784]: loss 5.991690
[epoch14, step785]: loss 22.773329
[epoch14, step786]: loss 6.077344
[epoch14, step787]: loss 2.242041
[epoch14, step788]: loss 0.986704
[epoch14, step789]: loss 0.701309
[epoch14, step790]: loss 8.951616
[epoch14, step791]: loss 8.128201
[epoch14, step792]: loss 13.510561
[epoch14, step793]: loss 0.857809
[epoch14, step794]: loss 1.479301
[epoch14, step795]: loss 2.587131
[epoch14, step796]: loss 7.121964
[epoch14, step797]: loss 8.016655
[epoch14, step798]: loss 3.227246
[epoch14, step799]: loss 6.806270
[epoch14, step800]: loss 10.347527
[epoch14, step801]: loss 8.258653
[epoch14, step802]: loss 1.717888
[epoch14, step803]: loss 2.667575
[epoch14, step804]: loss 0.772411
[epoch14, step805]: loss 8.002548
[epoch14, step806]: loss 4.417559
[epoch14, step807]: loss 9.625156
[epoch14, step808]: loss 8.822779
[epoch14, step809]: loss 3.346390
[epoch14, step810]: loss 0.945711
[epoch14, step811]: loss 7.087634
[epoch14, step812]: loss 5.263490
[epoch14, step813]: loss 7.556551
[epoch14, step814]: loss 0.726697
[epoch14, step815]: loss 5.174646
[epoch14, step816]: loss 1.709847
[epoch14, step817]: loss 1.478661
[epoch14, step818]: loss 6.808646
[epoch14, step819]: loss 1.435768
[epoch14, step820]: loss 2.392152
[epoch14, step821]: loss 1.691006
[epoch14, step822]: loss 4.648926
[epoch14, step823]: loss 0.822965
[epoch14, step824]: loss 7.548928
[epoch14, step825]: loss 3.866597
[epoch14, step826]: loss 7.895020
[epoch14, step827]: loss 0.970876
[epoch14, step828]: loss 1.080748
[epoch14, step829]: loss 1.382604
[epoch14, step830]: loss 1.988962
[epoch14, step831]: loss 7.424587
[epoch14, step832]: loss 11.695073
[epoch14, step833]: loss 0.888287
[epoch14, step834]: loss 3.427517
[epoch14, step835]: loss 2.438414
[epoch14, step836]: loss 2.196375
[epoch14, step837]: loss 3.994980
[epoch14, step838]: loss 13.304918
[epoch14, step839]: loss 5.605505
[epoch14, step840]: loss 11.168973
[epoch14, step841]: loss 27.347736
[epoch14, step842]: loss 2.541659
[epoch14, step843]: loss 0.765704
[epoch14, step844]: loss 0.820338
[epoch14, step845]: loss 0.807424
[epoch14, step846]: loss 21.808897
[epoch14, step847]: loss 1.092998
[epoch14, step848]: loss 7.692424
[epoch14, step849]: loss 10.865698
[epoch14, step850]: loss 11.778065
[epoch14, step851]: loss 0.910654
[epoch14, step852]: loss 2.613762
[epoch14, step853]: loss 0.763083
[epoch14, step854]: loss 1.314804
[epoch14, step855]: loss 1.444925
[epoch14, step856]: loss 20.402714
[epoch14, step857]: loss 1.058967
[epoch14, step858]: loss 2.563792
[epoch14, step859]: loss 2.098901
[epoch14, step860]: loss 3.121362
[epoch14, step861]: loss 7.024166
[epoch14, step862]: loss 11.574550
[epoch14, step863]: loss 6.287570
[epoch14, step864]: loss 1.135833
[epoch14, step865]: loss 8.921164
[epoch14, step866]: loss 11.420051
[epoch14, step867]: loss 1.836847
[epoch14, step868]: loss 1.837811
[epoch14, step869]: loss 0.749270
[epoch14, step870]: loss 9.297759
[epoch14, step871]: loss 0.608270
[epoch14, step872]: loss 1.914540
[epoch14, step873]: loss 0.939220
[epoch14, step874]: loss 15.386944
[epoch14, step875]: loss 3.286833
[epoch14, step876]: loss 2.816649
[epoch14, step877]: loss 9.116245
[epoch14, step878]: loss 1.004432
[epoch14, step879]: loss 0.786354
[epoch14, step880]: loss 1.199108
[epoch14, step881]: loss 1.865265
[epoch14, step882]: loss 2.746965
[epoch14, step883]: loss 10.240494
[epoch14, step884]: loss 1.947768
[epoch14, step885]: loss 15.227269
[epoch14, step886]: loss 1.383647
[epoch14, step887]: loss 2.465337
[epoch14, step888]: loss 1.208975
[epoch14, step889]: loss 1.338816
[epoch14, step890]: loss 7.924434
[epoch14, step891]: loss 1.761120
[epoch14, step892]: loss 2.968901
[epoch14, step893]: loss 12.414388
[epoch14, step894]: loss 0.708545
[epoch14, step895]: loss 2.432367
[epoch14, step896]: loss 0.917209
[epoch14, step897]: loss 4.713062
[epoch14, step898]: loss 1.067429
[epoch14, step899]: loss 1.541099
[epoch14, step900]: loss 0.937544
[epoch14, step901]: loss 1.784097
[epoch14, step902]: loss 3.473659
[epoch14, step903]: loss 1.009800
[epoch14, step904]: loss 3.839502
[epoch14, step905]: loss 6.779763
[epoch14, step906]: loss 7.527078
[epoch14, step907]: loss 1.237102
[epoch14, step908]: loss 2.699329
[epoch14, step909]: loss 1.994611
[epoch14, step910]: loss 0.794280
[epoch14, step911]: loss 1.051199
[epoch14, step912]: loss 1.256343
[epoch14, step913]: loss 7.644708
[epoch14, step914]: loss 1.447932
[epoch14, step915]: loss 1.028676
[epoch14, step916]: loss 1.275317
[epoch14, step917]: loss 1.142147
[epoch14, step918]: loss 0.671899
[epoch14, step919]: loss 4.800300
[epoch14, step920]: loss 7.519026
[epoch14, step921]: loss 17.891365
[epoch14, step922]: loss 4.683511
[epoch14, step923]: loss 0.961789
[epoch14, step924]: loss 1.225070
[epoch14, step925]: loss 2.887362
[epoch14, step926]: loss 0.777799
[epoch14, step927]: loss 14.780896
[epoch14, step928]: loss 0.970876
[epoch14, step929]: loss 7.454669
[epoch14, step930]: loss 1.217907
[epoch14, step931]: loss 4.464905
[epoch14, step932]: loss 12.441526
[epoch14, step933]: loss 1.164376
[epoch14, step934]: loss 9.170050
[epoch14, step935]: loss 0.949757
[epoch14, step936]: loss 1.894816
[epoch14, step937]: loss 10.675308
[epoch14, step938]: loss 3.938601
[epoch14, step939]: loss 13.661930
[epoch14, step940]: loss 3.992255
[epoch14, step941]: loss 1.314204
[epoch14, step942]: loss 1.650626
[epoch14, step943]: loss 0.916428
[epoch14, step944]: loss 9.016657
[epoch14, step945]: loss 2.470583
[epoch14, step946]: loss 1.417960
[epoch14, step947]: loss 1.566079
[epoch14, step948]: loss 5.203005
[epoch14, step949]: loss 1.489152
[epoch14, step950]: loss 2.475150
[epoch14, step951]: loss 2.252901
[epoch14, step952]: loss 2.521123
[epoch14, step953]: loss 10.904077
[epoch14, step954]: loss 18.068460
[epoch14, step955]: loss 0.898910
[epoch14, step956]: loss 2.175037
[epoch14, step957]: loss 0.894891
[epoch14, step958]: loss 1.425138
[epoch14, step959]: loss 10.610014
[epoch14, step960]: loss 12.264804
[epoch14, step961]: loss 15.961153
[epoch14, step962]: loss 5.613883
[epoch14, step963]: loss 7.559813
[epoch14, step964]: loss 0.929487
[epoch14, step965]: loss 0.692483
[epoch14, step966]: loss 1.113864
[epoch14, step967]: loss 8.892471
[epoch14, step968]: loss 1.160326
[epoch14, step969]: loss 0.914579
[epoch14, step970]: loss 1.955351
[epoch14, step971]: loss 1.052838
[epoch14, step972]: loss 11.526633
[epoch14, step973]: loss 1.479674
[epoch14, step974]: loss 7.527339
[epoch14, step975]: loss 3.123070
[epoch14, step976]: loss 0.910176
[epoch14, step977]: loss 10.506490
[epoch14, step978]: loss 0.905133
[epoch14, step979]: loss 1.065492
[epoch14, step980]: loss 6.507792
[epoch14, step981]: loss 8.177189
[epoch14, step982]: loss 1.684249
[epoch14, step983]: loss 1.356836
[epoch14, step984]: loss 3.751710
[epoch14, step985]: loss 1.031542
[epoch14, step986]: loss 7.530214
[epoch14, step987]: loss 5.553124
[epoch14, step988]: loss 1.237113
[epoch14, step989]: loss 3.106827
[epoch14, step990]: loss 2.084013
[epoch14, step991]: loss 0.767915
[epoch14, step992]: loss 1.151101
[epoch14, step993]: loss 1.607004
[epoch14, step994]: loss 1.003743
[epoch14, step995]: loss 7.529024
[epoch14, step996]: loss 7.735490
[epoch14, step997]: loss 1.455832
[epoch14, step998]: loss 1.528709
[epoch14, step999]: loss 8.475624
[epoch14, step1000]: loss 1.728611
[epoch14, step1001]: loss 1.000638
[epoch14, step1002]: loss 1.298044
[epoch14, step1003]: loss 1.841995
[epoch14, step1004]: loss 4.113670
[epoch14, step1005]: loss 0.814346
[epoch14, step1006]: loss 0.763838
[epoch14, step1007]: loss 13.032845
[epoch14, step1008]: loss 1.301963
[epoch14, step1009]: loss 0.765646
[epoch14, step1010]: loss 6.845213
[epoch14, step1011]: loss 1.516074
[epoch14, step1012]: loss 20.362572
[epoch14, step1013]: loss 11.141553
[epoch14, step1014]: loss 12.703157
[epoch14, step1015]: loss 2.726611
[epoch14, step1016]: loss 1.603097
[epoch14, step1017]: loss 1.482581
[epoch14, step1018]: loss 3.172445
[epoch14, step1019]: loss 2.360826
[epoch14, step1020]: loss 3.044775
[epoch14, step1021]: loss 0.711085
[epoch14, step1022]: loss 3.475002
[epoch14, step1023]: loss 1.549406
[epoch14, step1024]: loss 6.852706
[epoch14, step1025]: loss 1.626903
[epoch14, step1026]: loss 1.631538
[epoch14, step1027]: loss 1.641809
[epoch14, step1028]: loss 4.720532
[epoch14, step1029]: loss 1.164625
[epoch14, step1030]: loss 5.987781
[epoch14, step1031]: loss 1.122809
[epoch14, step1032]: loss 4.904279
[epoch14, step1033]: loss 7.658653
[epoch14, step1034]: loss 0.715410
[epoch14, step1035]: loss 9.265940
[epoch14, step1036]: loss 1.378768
[epoch14, step1037]: loss 7.749700
[epoch14, step1038]: loss 7.266551
[epoch14, step1039]: loss 0.880683
[epoch14, step1040]: loss 1.819015
[epoch14, step1041]: loss 0.822337
[epoch14, step1042]: loss 1.435650
[epoch14, step1043]: loss 0.816765
[epoch14, step1044]: loss 1.550969
[epoch14, step1045]: loss 1.821008
[epoch14, step1046]: loss 1.141006
[epoch14, step1047]: loss 0.744300
[epoch14, step1048]: loss 0.668033
[epoch14, step1049]: loss 1.671341
[epoch14, step1050]: loss 10.557664
[epoch14, step1051]: loss 0.999274
[epoch14, step1052]: loss 2.506601
[epoch14, step1053]: loss 1.005334
[epoch14, step1054]: loss 3.594822
[epoch14, step1055]: loss 0.715197
[epoch14, step1056]: loss 0.732167
[epoch14, step1057]: loss 4.563684
[epoch14, step1058]: loss 0.807558
[epoch14, step1059]: loss 17.206680
[epoch14, step1060]: loss 1.518003
[epoch14, step1061]: loss 0.987229
[epoch14, step1062]: loss 1.697630
[epoch14, step1063]: loss 1.707160
[epoch14, step1064]: loss 1.292450
[epoch14, step1065]: loss 7.958805
[epoch14, step1066]: loss 2.890352
[epoch14, step1067]: loss 2.798903
[epoch14, step1068]: loss 1.877917
[epoch14, step1069]: loss 8.008687
[epoch14, step1070]: loss 12.179215
[epoch14, step1071]: loss 0.777958
[epoch14, step1072]: loss 0.749747
[epoch14, step1073]: loss 1.521530
[epoch14, step1074]: loss 1.074139
[epoch14, step1075]: loss 0.514723
[epoch14, step1076]: loss 0.541905
[epoch14, step1077]: loss 3.121439
[epoch14, step1078]: loss 1.232913
[epoch14, step1079]: loss 3.816097
[epoch14, step1080]: loss 5.743968
[epoch14, step1081]: loss 1.149719
[epoch14, step1082]: loss 2.874182
[epoch14, step1083]: loss 1.467515
[epoch14, step1084]: loss 11.273477
[epoch14, step1085]: loss 1.265279
[epoch14, step1086]: loss 8.872769
[epoch14, step1087]: loss 1.694105
[epoch14, step1088]: loss 2.073531
[epoch14, step1089]: loss 1.919952
[epoch14, step1090]: loss 1.230253
[epoch14, step1091]: loss 1.112425
[epoch14, step1092]: loss 1.452319
[epoch14, step1093]: loss 12.756986
[epoch14, step1094]: loss 3.472509
[epoch14, step1095]: loss 2.206768
[epoch14, step1096]: loss 2.895466
[epoch14, step1097]: loss 1.140938
[epoch14, step1098]: loss 0.749155
[epoch14, step1099]: loss 4.615326
[epoch14, step1100]: loss 2.782965
[epoch14, step1101]: loss 10.112361
[epoch14, step1102]: loss 2.364088
[epoch14, step1103]: loss 1.290136
[epoch14, step1104]: loss 8.471108
[epoch14, step1105]: loss 1.381283
[epoch14, step1106]: loss 3.461592
[epoch14, step1107]: loss 11.074195
[epoch14, step1108]: loss 1.287899
[epoch14, step1109]: loss 5.342920
[epoch14, step1110]: loss 1.236553
[epoch14, step1111]: loss 4.305438
[epoch14, step1112]: loss 10.882940
[epoch14, step1113]: loss 0.790399
[epoch14, step1114]: loss 1.840810
[epoch14, step1115]: loss 15.820530
[epoch14, step1116]: loss 1.488862
[epoch14, step1117]: loss 1.654393
[epoch14, step1118]: loss 1.300966
[epoch14, step1119]: loss 0.938812
[epoch14, step1120]: loss 1.291923
[epoch14, step1121]: loss 1.139960
[epoch14, step1122]: loss 2.491896
[epoch14, step1123]: loss 2.294961
[epoch14, step1124]: loss 1.358531
[epoch14, step1125]: loss 7.532774
[epoch14, step1126]: loss 2.414939
[epoch14, step1127]: loss 11.284100
[epoch14, step1128]: loss 0.897659
[epoch14, step1129]: loss 3.303253
[epoch14, step1130]: loss 1.007365
[epoch14, step1131]: loss 1.949651
[epoch14, step1132]: loss 3.012108
[epoch14, step1133]: loss 1.221507
[epoch14, step1134]: loss 0.974581
[epoch14, step1135]: loss 1.970181
[epoch14, step1136]: loss 1.492456
[epoch14, step1137]: loss 3.855673
[epoch14, step1138]: loss 0.932759
[epoch14, step1139]: loss 9.557590
[epoch14, step1140]: loss 0.863718
[epoch14, step1141]: loss 2.453450
[epoch14, step1142]: loss 1.454612
[epoch14, step1143]: loss 1.475021
[epoch14, step1144]: loss 12.243838
[epoch14, step1145]: loss 9.649745
[epoch14, step1146]: loss 1.182347
[epoch14, step1147]: loss 7.043964
[epoch14, step1148]: loss 0.945963
[epoch14, step1149]: loss 1.143514
[epoch14, step1150]: loss 1.795096
[epoch14, step1151]: loss 3.379057
[epoch14, step1152]: loss 7.733335
[epoch14, step1153]: loss 3.500694
[epoch14, step1154]: loss 2.307485
[epoch14, step1155]: loss 9.069627
[epoch14, step1156]: loss 0.936011
[epoch14, step1157]: loss 9.320370
[epoch14, step1158]: loss 2.004466
[epoch14, step1159]: loss 3.698598
[epoch14, step1160]: loss 2.684178
[epoch14, step1161]: loss 4.504440
[epoch14, step1162]: loss 6.819125
[epoch14, step1163]: loss 0.700077
[epoch14, step1164]: loss 2.505319
[epoch14, step1165]: loss 9.418242
[epoch14, step1166]: loss 2.107274
[epoch14, step1167]: loss 7.567269
[epoch14, step1168]: loss 2.511337
[epoch14, step1169]: loss 2.786297
[epoch14, step1170]: loss 1.708796
[epoch14, step1171]: loss 1.354169
[epoch14, step1172]: loss 5.318869
[epoch14, step1173]: loss 2.434136
[epoch14, step1174]: loss 10.729350
[epoch14, step1175]: loss 1.381535
[epoch14, step1176]: loss 3.561856
[epoch14, step1177]: loss 0.777592
[epoch14, step1178]: loss 1.384617
[epoch14, step1179]: loss 4.505151
[epoch14, step1180]: loss 10.360702
[epoch14, step1181]: loss 1.353731
[epoch14, step1182]: loss 10.636988
[epoch14, step1183]: loss 1.039517
[epoch14, step1184]: loss 1.893961
[epoch14, step1185]: loss 1.523025
[epoch14, step1186]: loss 1.999926
[epoch14, step1187]: loss 6.339384
[epoch14, step1188]: loss 1.496417
[epoch14, step1189]: loss 0.924338
[epoch14, step1190]: loss 0.623934
[epoch14, step1191]: loss 1.744045
[epoch14, step1192]: loss 2.771084
[epoch14, step1193]: loss 8.532954
[epoch14, step1194]: loss 6.645333
[epoch14, step1195]: loss 7.340370
[epoch14, step1196]: loss 10.297854
[epoch14, step1197]: loss 0.697939
[epoch14, step1198]: loss 1.557676
[epoch14, step1199]: loss 1.077178
[epoch14, step1200]: loss 2.142150
[epoch14, step1201]: loss 0.952442
[epoch14, step1202]: loss 0.727410
[epoch14, step1203]: loss 6.849868
[epoch14, step1204]: loss 10.360101
[epoch14, step1205]: loss 1.090480
[epoch14, step1206]: loss 14.582345
[epoch14, step1207]: loss 5.958523
[epoch14, step1208]: loss 0.987065
[epoch14, step1209]: loss 2.329040
[epoch14, step1210]: loss 0.894388
[epoch14, step1211]: loss 7.922030
[epoch14, step1212]: loss 1.461431
[epoch14, step1213]: loss 0.716056
[epoch14, step1214]: loss 10.694378
[epoch14, step1215]: loss 2.385258
[epoch14, step1216]: loss 3.667853
[epoch14, step1217]: loss 6.208972
[epoch14, step1218]: loss 9.087883
[epoch14, step1219]: loss 2.901681
[epoch14, step1220]: loss 14.115935
[epoch14, step1221]: loss 9.026454
[epoch14, step1222]: loss 2.661098
[epoch14, step1223]: loss 4.032146
[epoch14, step1224]: loss 12.041109
[epoch14, step1225]: loss 5.052022
[epoch14, step1226]: loss 1.724963
[epoch14, step1227]: loss 10.925011
[epoch14, step1228]: loss 1.852368
[epoch14, step1229]: loss 1.934547
[epoch14, step1230]: loss 0.896759
[epoch14, step1231]: loss 4.256495
[epoch14, step1232]: loss 1.363360
[epoch14, step1233]: loss 0.876936
[epoch14, step1234]: loss 9.576514
[epoch14, step1235]: loss 0.998282
[epoch14, step1236]: loss 1.636527
[epoch14, step1237]: loss 13.581979
[epoch14, step1238]: loss 1.830391
[epoch14, step1239]: loss 4.834424
[epoch14, step1240]: loss 1.142820
[epoch14, step1241]: loss 4.048532
[epoch14, step1242]: loss 1.016764
[epoch14, step1243]: loss 1.446548
[epoch14, step1244]: loss 3.903797
[epoch14, step1245]: loss 1.078857
[epoch14, step1246]: loss 0.959309
[epoch14, step1247]: loss 7.015176
[epoch14, step1248]: loss 1.548394
[epoch14, step1249]: loss 7.168221
[epoch14, step1250]: loss 2.394205
[epoch14, step1251]: loss 1.602436
[epoch14, step1252]: loss 7.055219
[epoch14, step1253]: loss 1.530753
[epoch14, step1254]: loss 1.147980
[epoch14, step1255]: loss 0.756149
[epoch14, step1256]: loss 5.974533
[epoch14, step1257]: loss 3.479354
[epoch14, step1258]: loss 0.843929
[epoch14, step1259]: loss 15.797002
[epoch14, step1260]: loss 8.940684
[epoch14, step1261]: loss 4.401310
[epoch14, step1262]: loss 0.810268
[epoch14, step1263]: loss 0.582636
[epoch14, step1264]: loss 1.739644
[epoch14, step1265]: loss 0.899800
[epoch14, step1266]: loss 6.172010
[epoch14, step1267]: loss 3.272587
[epoch14, step1268]: loss 1.222158
[epoch14, step1269]: loss 1.711393
[epoch14, step1270]: loss 1.433749
[epoch14, step1271]: loss 8.357488
[epoch14, step1272]: loss 10.538877
[epoch14, step1273]: loss 0.618350
[epoch14, step1274]: loss 1.620179
[epoch14, step1275]: loss 0.829636
[epoch14, step1276]: loss 5.916247
[epoch14, step1277]: loss 6.925564
[epoch14, step1278]: loss 1.295985
[epoch14, step1279]: loss 2.824293
[epoch14, step1280]: loss 1.759044
[epoch14, step1281]: loss 10.737056
[epoch14, step1282]: loss 7.592762
[epoch14, step1283]: loss 1.816047
[epoch14, step1284]: loss 4.395644
[epoch14, step1285]: loss 1.456134
[epoch14, step1286]: loss 6.091664
[epoch14, step1287]: loss 3.588962
[epoch14, step1288]: loss 1.184430
[epoch14, step1289]: loss 7.641188
[epoch14, step1290]: loss 4.779212
[epoch14, step1291]: loss 1.509753
[epoch14, step1292]: loss 2.700548
[epoch14, step1293]: loss 3.479592
[epoch14, step1294]: loss 1.080606
[epoch14, step1295]: loss 2.893363
[epoch14, step1296]: loss 3.527785
[epoch14, step1297]: loss 1.142114
[epoch14, step1298]: loss 0.900504
[epoch14, step1299]: loss 1.575807
[epoch14, step1300]: loss 5.052653
[epoch14, step1301]: loss 2.598955
[epoch14, step1302]: loss 6.615256
[epoch14, step1303]: loss 3.106435
[epoch14, step1304]: loss 10.557558
[epoch14, step1305]: loss 2.196818
[epoch14, step1306]: loss 1.150554
[epoch14, step1307]: loss 3.590557
[epoch14, step1308]: loss 1.093262
[epoch14, step1309]: loss 5.031344
[epoch14, step1310]: loss 2.382724
[epoch14, step1311]: loss 2.583021
[epoch14, step1312]: loss 2.862480
[epoch14, step1313]: loss 1.042998
[epoch14, step1314]: loss 9.984157
[epoch14, step1315]: loss 3.400677
[epoch14, step1316]: loss 1.561311
[epoch14, step1317]: loss 2.499900
[epoch14, step1318]: loss 2.793521
[epoch14, step1319]: loss 0.561449
[epoch14, step1320]: loss 0.990649
[epoch14, step1321]: loss 1.049976
[epoch14, step1322]: loss 0.801290
[epoch14, step1323]: loss 10.274618
[epoch14, step1324]: loss 7.340630
[epoch14, step1325]: loss 0.808885
[epoch14, step1326]: loss 1.165623
[epoch14, step1327]: loss 1.892567
[epoch14, step1328]: loss 1.400950
[epoch14, step1329]: loss 0.914215
[epoch14, step1330]: loss 0.825998
[epoch14, step1331]: loss 0.972043
[epoch14, step1332]: loss 14.353749
[epoch14, step1333]: loss 6.760125
[epoch14, step1334]: loss 16.976833
[epoch14, step1335]: loss 1.913054
[epoch14, step1336]: loss 1.472541
[epoch14, step1337]: loss 7.054705
[epoch14, step1338]: loss 1.549262
[epoch14, step1339]: loss 2.610144
[epoch14, step1340]: loss 1.390263
[epoch14, step1341]: loss 7.557994
[epoch14, step1342]: loss 3.035673
[epoch14, step1343]: loss 0.826992
[epoch14, step1344]: loss 4.809394
[epoch14, step1345]: loss 1.584803
[epoch14, step1346]: loss 4.387652
[epoch14, step1347]: loss 1.266747
[epoch14, step1348]: loss 1.296247
[epoch14, step1349]: loss 15.587270
[epoch14, step1350]: loss 8.776958
[epoch14, step1351]: loss 2.190553
[epoch14, step1352]: loss 0.590041
[epoch14, step1353]: loss 0.759941
[epoch14, step1354]: loss 1.122240
[epoch14, step1355]: loss 6.659019
[epoch14, step1356]: loss 1.026687
[epoch14, step1357]: loss 13.588890
[epoch14, step1358]: loss 0.830648
[epoch14, step1359]: loss 8.500878
[epoch14, step1360]: loss 4.820096
[epoch14, step1361]: loss 23.394598
[epoch14, step1362]: loss 0.896032
[epoch14, step1363]: loss 0.783588
[epoch14, step1364]: loss 5.613306
[epoch14, step1365]: loss 0.640102
[epoch14, step1366]: loss 9.514239
[epoch14, step1367]: loss 7.407600
[epoch14, step1368]: loss 9.603339
[epoch14, step1369]: loss 6.661358
[epoch14, step1370]: loss 1.172161
[epoch14, step1371]: loss 2.771861
[epoch14, step1372]: loss 0.548230
[epoch14, step1373]: loss 5.807616
[epoch14, step1374]: loss 1.219516
[epoch14, step1375]: loss 7.594301
[epoch14, step1376]: loss 7.112979
[epoch14, step1377]: loss 2.953415
[epoch14, step1378]: loss 18.701099
[epoch14, step1379]: loss 0.871948
[epoch14, step1380]: loss 1.428676
[epoch14, step1381]: loss 0.888924
[epoch14, step1382]: loss 1.151081
[epoch14, step1383]: loss 3.549860
[epoch14, step1384]: loss 9.605268
[epoch14, step1385]: loss 0.917097
[epoch14, step1386]: loss 2.990642
[epoch14, step1387]: loss 0.958935
[epoch14, step1388]: loss 2.427049
[epoch14, step1389]: loss 22.414143
[epoch14, step1390]: loss 10.979911
[epoch14, step1391]: loss 2.194719
[epoch14, step1392]: loss 5.054428
[epoch14, step1393]: loss 0.940477
[epoch14, step1394]: loss 1.342402
[epoch14, step1395]: loss 1.704317
[epoch14, step1396]: loss 8.046223
[epoch14, step1397]: loss 0.929882
[epoch14, step1398]: loss 1.044511
[epoch14, step1399]: loss 1.495790
[epoch14, step1400]: loss 1.625737
[epoch14, step1401]: loss 9.594526
[epoch14, step1402]: loss 13.349764
[epoch14, step1403]: loss 11.936361
[epoch14, step1404]: loss 14.210912
[epoch14, step1405]: loss 1.975123
[epoch14, step1406]: loss 2.166058
[epoch14, step1407]: loss 0.920530
[epoch14, step1408]: loss 2.846739
[epoch14, step1409]: loss 0.800960
[epoch14, step1410]: loss 1.506825
[epoch14, step1411]: loss 2.763173
[epoch14, step1412]: loss 1.499790
[epoch14, step1413]: loss 1.533132
[epoch14, step1414]: loss 1.105330
[epoch14, step1415]: loss 2.753527
[epoch14, step1416]: loss 0.970737
[epoch14, step1417]: loss 8.782638
[epoch14, step1418]: loss 9.909378
[epoch14, step1419]: loss 9.778207
[epoch14, step1420]: loss 1.621901
[epoch14, step1421]: loss 21.293034
[epoch14, step1422]: loss 3.167894
[epoch14, step1423]: loss 1.364688
[epoch14, step1424]: loss 0.659213
[epoch14, step1425]: loss 7.095889
[epoch14, step1426]: loss 2.068368
[epoch14, step1427]: loss 0.900833
[epoch14, step1428]: loss 1.057625
[epoch14, step1429]: loss 1.298371
[epoch14, step1430]: loss 4.803188
[epoch14, step1431]: loss 3.719904
[epoch14, step1432]: loss 9.651102
[epoch14, step1433]: loss 1.201791
[epoch14, step1434]: loss 1.545008
[epoch14, step1435]: loss 1.200594
[epoch14, step1436]: loss 8.881619
[epoch14, step1437]: loss 1.236981
[epoch14, step1438]: loss 8.130615
[epoch14, step1439]: loss 9.299672
[epoch14, step1440]: loss 1.814520
[epoch14, step1441]: loss 8.588786
[epoch14, step1442]: loss 8.500760
[epoch14, step1443]: loss 1.478539
[epoch14, step1444]: loss 0.927087
[epoch14, step1445]: loss 6.125282
[epoch14, step1446]: loss 0.753651
[epoch14, step1447]: loss 0.884475
[epoch14, step1448]: loss 1.850300
[epoch14, step1449]: loss 2.585445
[epoch14, step1450]: loss 2.869697
[epoch14, step1451]: loss 1.175762
[epoch14, step1452]: loss 1.479618
[epoch14, step1453]: loss 11.477678
[epoch14, step1454]: loss 1.105501
[epoch14, step1455]: loss 1.496842
[epoch14, step1456]: loss 8.391097
[epoch14, step1457]: loss 8.962841
[epoch14, step1458]: loss 0.812799
[epoch14, step1459]: loss 2.331154
[epoch14, step1460]: loss 2.598009
[epoch14, step1461]: loss 9.576101
[epoch14, step1462]: loss 1.406902
[epoch14, step1463]: loss 11.932394
[epoch14, step1464]: loss 0.751689
[epoch14, step1465]: loss 1.069793
[epoch14, step1466]: loss 2.585715
[epoch14, step1467]: loss 1.487166
[epoch14, step1468]: loss 16.746660
[epoch14, step1469]: loss 1.169448
[epoch14, step1470]: loss 13.824027
[epoch14, step1471]: loss 3.158000
[epoch14, step1472]: loss 1.069324
[epoch14, step1473]: loss 1.057866
[epoch14, step1474]: loss 7.894330
[epoch14, step1475]: loss 0.835854
[epoch14, step1476]: loss 4.353469
[epoch14, step1477]: loss 2.183928
[epoch14, step1478]: loss 1.409263
[epoch14, step1479]: loss 1.079467
[epoch14, step1480]: loss 0.707493
[epoch14, step1481]: loss 1.187074
[epoch14, step1482]: loss 1.002688
[epoch14, step1483]: loss 1.121029
[epoch14, step1484]: loss 11.761548
[epoch14, step1485]: loss 1.224713
[epoch14, step1486]: loss 1.123764
[epoch14, step1487]: loss 0.769933
[epoch14, step1488]: loss 1.036315
[epoch14, step1489]: loss 0.904138
[epoch14, step1490]: loss 0.791486
[epoch14, step1491]: loss 7.449502
[epoch14, step1492]: loss 2.087564
[epoch14, step1493]: loss 1.365929
[epoch14, step1494]: loss 17.700691
[epoch14, step1495]: loss 9.081298
[epoch14, step1496]: loss 1.947456
[epoch14, step1497]: loss 11.609834
[epoch14, step1498]: loss 1.110908
[epoch14, step1499]: loss 0.531625
[epoch14, step1500]: loss 3.455004
[epoch14, step1501]: loss 3.410517
[epoch14, step1502]: loss 2.746995
[epoch14, step1503]: loss 1.285529
[epoch14, step1504]: loss 0.829267
[epoch14, step1505]: loss 8.431187
[epoch14, step1506]: loss 7.311112
[epoch14, step1507]: loss 0.837599
[epoch14, step1508]: loss 6.033835
[epoch14, step1509]: loss 12.473805
[epoch14, step1510]: loss 1.010523
[epoch14, step1511]: loss 0.899145
[epoch14, step1512]: loss 7.632159
[epoch14, step1513]: loss 1.398444
[epoch14, step1514]: loss 1.578692
[epoch14, step1515]: loss 8.636449
[epoch14, step1516]: loss 6.047324
[epoch14, step1517]: loss 0.836958
[epoch14, step1518]: loss 0.799754
[epoch14, step1519]: loss 13.861139
[epoch14, step1520]: loss 4.355800
[epoch14, step1521]: loss 7.289322
[epoch14, step1522]: loss 3.199629
[epoch14, step1523]: loss 4.949860
[epoch14, step1524]: loss 1.044567
[epoch14, step1525]: loss 1.486152
[epoch14, step1526]: loss 1.322247
[epoch14, step1527]: loss 1.845128
[epoch14, step1528]: loss 2.687734
[epoch14, step1529]: loss 0.749637
[epoch14, step1530]: loss 6.819476
[epoch14, step1531]: loss 1.364854
[epoch14, step1532]: loss 1.263694
[epoch14, step1533]: loss 16.053009
[epoch14, step1534]: loss 1.670292
[epoch14, step1535]: loss 1.323665
[epoch14, step1536]: loss 2.102302
[epoch14, step1537]: loss 0.946096
[epoch14, step1538]: loss 7.833184
[epoch14, step1539]: loss 1.166120
[epoch14, step1540]: loss 8.214039
[epoch14, step1541]: loss 3.665267
[epoch14, step1542]: loss 0.712741
[epoch14, step1543]: loss 0.655750
[epoch14, step1544]: loss 4.054499
[epoch14, step1545]: loss 2.832935
[epoch14, step1546]: loss 9.877158
[epoch14, step1547]: loss 1.091947
[epoch14, step1548]: loss 2.928994
[epoch14, step1549]: loss 16.831095
[epoch14, step1550]: loss 0.592650
[epoch14, step1551]: loss 1.475548
[epoch14, step1552]: loss 9.582820
[epoch14, step1553]: loss 11.226804
[epoch14, step1554]: loss 0.792959
[epoch14, step1555]: loss 10.149086
[epoch14, step1556]: loss 1.891385
[epoch14, step1557]: loss 9.581442
[epoch14, step1558]: loss 0.732713
[epoch14, step1559]: loss 9.073993
[epoch14, step1560]: loss 2.025940
[epoch14, step1561]: loss 2.591559
[epoch14, step1562]: loss 3.954495
[epoch14, step1563]: loss 1.748876
[epoch14, step1564]: loss 8.983360
[epoch14, step1565]: loss 6.821525
[epoch14, step1566]: loss 0.745979
[epoch14, step1567]: loss 1.102324
[epoch14, step1568]: loss 5.743442
[epoch14, step1569]: loss 1.051594
[epoch14, step1570]: loss 2.246120
[epoch14, step1571]: loss 2.819143
[epoch14, step1572]: loss 5.399022
[epoch14, step1573]: loss 11.351288
[epoch14, step1574]: loss 10.020567
[epoch14, step1575]: loss 1.195785
[epoch14, step1576]: loss 9.615692
[epoch14, step1577]: loss 0.691983
[epoch14, step1578]: loss 3.279150
[epoch14, step1579]: loss 1.253816
[epoch14, step1580]: loss 0.873712
[epoch14, step1581]: loss 5.091897
[epoch14, step1582]: loss 3.747652
[epoch14, step1583]: loss 7.870412
[epoch14, step1584]: loss 7.878333
[epoch14, step1585]: loss 9.678501
[epoch14, step1586]: loss 2.000849
[epoch14, step1587]: loss 2.560122
[epoch14, step1588]: loss 2.002512
[epoch14, step1589]: loss 16.333876
[epoch14, step1590]: loss 1.839691
[epoch14, step1591]: loss 0.669128
[epoch14, step1592]: loss 1.082068
[epoch14, step1593]: loss 5.971051
[epoch14, step1594]: loss 9.110149
[epoch14, step1595]: loss 0.719150
[epoch14, step1596]: loss 0.618516
[epoch14, step1597]: loss 1.238164
[epoch14, step1598]: loss 2.206814
[epoch14, step1599]: loss 1.577726
[epoch14, step1600]: loss 1.294073
[epoch14, step1601]: loss 13.355222
[epoch14, step1602]: loss 5.522591
[epoch14, step1603]: loss 2.314336
[epoch14, step1604]: loss 1.984027
[epoch14, step1605]: loss 1.131521
[epoch14, step1606]: loss 0.883814
[epoch14, step1607]: loss 1.360750
[epoch14, step1608]: loss 0.835616
[epoch14, step1609]: loss 2.594891
[epoch14, step1610]: loss 8.666134
[epoch14, step1611]: loss 1.696380
[epoch14, step1612]: loss 1.557598
[epoch14, step1613]: loss 1.479679
[epoch14, step1614]: loss 5.975650
[epoch14, step1615]: loss 1.230113
[epoch14, step1616]: loss 1.675692
[epoch14, step1617]: loss 9.964424
[epoch14, step1618]: loss 6.268244
[epoch14, step1619]: loss 1.062846
[epoch14, step1620]: loss 3.201150
[epoch14, step1621]: loss 9.087238
[epoch14, step1622]: loss 1.591806
[epoch14, step1623]: loss 0.923534
[epoch14, step1624]: loss 15.819417
[epoch14, step1625]: loss 2.265223
[epoch14, step1626]: loss 1.153541
[epoch14, step1627]: loss 2.698695
[epoch14, step1628]: loss 2.555486
[epoch14, step1629]: loss 0.818196
[epoch14, step1630]: loss 1.737405
[epoch14, step1631]: loss 0.716954
[epoch14, step1632]: loss 8.661846
[epoch14, step1633]: loss 2.698587
[epoch14, step1634]: loss 2.472168
[epoch14, step1635]: loss 7.880087
[epoch14, step1636]: loss 3.923527
[epoch14, step1637]: loss 9.006786
[epoch14, step1638]: loss 1.337750
[epoch14, step1639]: loss 12.590801
[epoch14, step1640]: loss 0.903306
[epoch14, step1641]: loss 0.886689
[epoch14, step1642]: loss 1.163775
[epoch14, step1643]: loss 1.611707
[epoch14, step1644]: loss 6.879900
[epoch14, step1645]: loss 2.621389
[epoch14, step1646]: loss 2.019667
[epoch14, step1647]: loss 4.518731
[epoch14, step1648]: loss 3.802225
[epoch14, step1649]: loss 0.977002
[epoch14, step1650]: loss 1.161031
[epoch14, step1651]: loss 1.685822
[epoch14, step1652]: loss 1.022061
[epoch14, step1653]: loss 1.085072
[epoch14, step1654]: loss 0.732271
[epoch14, step1655]: loss 1.147564
[epoch14, step1656]: loss 0.772385
[epoch14, step1657]: loss 1.063283
[epoch14, step1658]: loss 1.040050
[epoch14, step1659]: loss 2.850530
[epoch14, step1660]: loss 1.425809
[epoch14, step1661]: loss 8.650381
[epoch14, step1662]: loss 1.110661
[epoch14, step1663]: loss 2.565358
[epoch14, step1664]: loss 2.294311
[epoch14, step1665]: loss 3.503366
[epoch14, step1666]: loss 2.461682
[epoch14, step1667]: loss 7.932988
[epoch14, step1668]: loss 16.096678
[epoch14, step1669]: loss 7.309789
[epoch14, step1670]: loss 2.269196
[epoch14, step1671]: loss 6.276392
[epoch14, step1672]: loss 1.497802
[epoch14, step1673]: loss 15.094664
[epoch14, step1674]: loss 3.153004
[epoch14, step1675]: loss 3.167409
[epoch14, step1676]: loss 9.510957
[epoch14, step1677]: loss 1.723009
[epoch14, step1678]: loss 1.096570
[epoch14, step1679]: loss 2.249604
[epoch14, step1680]: loss 14.428642
[epoch14, step1681]: loss 0.862551
[epoch14, step1682]: loss 7.543976
[epoch14, step1683]: loss 20.753942
[epoch14, step1684]: loss 1.594146
[epoch14, step1685]: loss 1.093311
[epoch14, step1686]: loss 5.672400
[epoch14, step1687]: loss 1.110028
[epoch14, step1688]: loss 2.959543
[epoch14, step1689]: loss 8.199582
[epoch14, step1690]: loss 1.378392
[epoch14, step1691]: loss 13.794848
[epoch14, step1692]: loss 13.984742
[epoch14, step1693]: loss 1.027033
[epoch14, step1694]: loss 0.760951
[epoch14, step1695]: loss 0.846125
[epoch14, step1696]: loss 1.024445
[epoch14, step1697]: loss 3.075715
[epoch14, step1698]: loss 7.099278
[epoch14, step1699]: loss 1.072705
[epoch14, step1700]: loss 4.090567
[epoch14, step1701]: loss 8.158193
[epoch14, step1702]: loss 2.161041
[epoch14, step1703]: loss 1.006580
[epoch14, step1704]: loss 12.465057
[epoch14, step1705]: loss 3.550665
[epoch14, step1706]: loss 7.179687
[epoch14, step1707]: loss 10.673197
[epoch14, step1708]: loss 0.766396
[epoch14, step1709]: loss 2.495371
[epoch14, step1710]: loss 1.085550
[epoch14, step1711]: loss 0.810302
[epoch14, step1712]: loss 6.271997
[epoch14, step1713]: loss 1.155590
[epoch14, step1714]: loss 0.965270
[epoch14, step1715]: loss 7.855769
[epoch14, step1716]: loss 2.113140
[epoch14, step1717]: loss 2.118667
[epoch14, step1718]: loss 0.948334
[epoch14, step1719]: loss 7.649470
[epoch14, step1720]: loss 11.136671
[epoch14, step1721]: loss 0.666983
[epoch14, step1722]: loss 0.777474
[epoch14, step1723]: loss 0.754432
[epoch14, step1724]: loss 0.814339
[epoch14, step1725]: loss 0.770770
[epoch14, step1726]: loss 2.351095
[epoch14, step1727]: loss 2.412623
[epoch14, step1728]: loss 2.801986
[epoch14, step1729]: loss 3.402563
[epoch14, step1730]: loss 2.407571
[epoch14, step1731]: loss 7.067116
[epoch14, step1732]: loss 1.740449
[epoch14, step1733]: loss 4.811076
[epoch14, step1734]: loss 1.125143
[epoch14, step1735]: loss 4.792843
[epoch14, step1736]: loss 7.924130
[epoch14, step1737]: loss 8.244016
[epoch14, step1738]: loss 21.126434
[epoch14, step1739]: loss 1.012475
[epoch14, step1740]: loss 10.393823
[epoch14, step1741]: loss 3.835515
[epoch14, step1742]: loss 3.882296
[epoch14, step1743]: loss 1.568339
[epoch14, step1744]: loss 4.464508
[epoch14, step1745]: loss 0.978530
[epoch14, step1746]: loss 3.494112
[epoch14, step1747]: loss 1.596505
[epoch14, step1748]: loss 23.997698
[epoch14, step1749]: loss 7.871642
[epoch14, step1750]: loss 1.685312
[epoch14, step1751]: loss 7.737992
[epoch14, step1752]: loss 1.082382
[epoch14, step1753]: loss 1.478866
[epoch14, step1754]: loss 1.755197
[epoch14, step1755]: loss 2.608264
[epoch14, step1756]: loss 7.285926
[epoch14, step1757]: loss 1.814441
[epoch14, step1758]: loss 2.002142
[epoch14, step1759]: loss 1.591878
[epoch14, step1760]: loss 14.830763
[epoch14, step1761]: loss 19.088182
[epoch14, step1762]: loss 6.924186
[epoch14, step1763]: loss 6.222280
[epoch14, step1764]: loss 16.872742
[epoch14, step1765]: loss 11.094302
[epoch14, step1766]: loss 1.900350
[epoch14, step1767]: loss 1.125840
[epoch14, step1768]: loss 2.725252
[epoch14, step1769]: loss 1.476094
[epoch14, step1770]: loss 1.047889
[epoch14, step1771]: loss 0.590832
[epoch14, step1772]: loss 1.185759
[epoch14, step1773]: loss 12.693365
[epoch14, step1774]: loss 8.920895
[epoch14, step1775]: loss 2.943934
[epoch14, step1776]: loss 2.790677
[epoch14, step1777]: loss 1.175968
[epoch14, step1778]: loss 2.899378
[epoch14, step1779]: loss 2.189320
[epoch14, step1780]: loss 1.131716
[epoch14, step1781]: loss 1.667728
[epoch14, step1782]: loss 1.301772
[epoch14, step1783]: loss 7.404461
[epoch14, step1784]: loss 8.521658
[epoch14, step1785]: loss 2.924173
[epoch14, step1786]: loss 0.911228
[epoch14, step1787]: loss 1.345468
[epoch14, step1788]: loss 1.508839
[epoch14, step1789]: loss 2.305781
[epoch14, step1790]: loss 7.854827
[epoch14, step1791]: loss 15.644377
[epoch14, step1792]: loss 1.870205
[epoch14, step1793]: loss 1.228117
[epoch14, step1794]: loss 6.304383
[epoch14, step1795]: loss 12.653674
[epoch14, step1796]: loss 1.519033
[epoch14, step1797]: loss 0.615557
[epoch14, step1798]: loss 1.691581
[epoch14, step1799]: loss 21.831268
[epoch14, step1800]: loss 0.705788
[epoch14, step1801]: loss 1.582446
[epoch14, step1802]: loss 8.529925
[epoch14, step1803]: loss 1.256702
[epoch14, step1804]: loss 7.002429
[epoch14, step1805]: loss 0.595598
[epoch14, step1806]: loss 1.768290
[epoch14, step1807]: loss 2.002195
[epoch14, step1808]: loss 1.844574
[epoch14, step1809]: loss 0.943913
[epoch14, step1810]: loss 1.754875
[epoch14, step1811]: loss 8.075649
[epoch14, step1812]: loss 5.128906
[epoch14, step1813]: loss 11.436088
[epoch14, step1814]: loss 1.098259
[epoch14, step1815]: loss 2.153102
[epoch14, step1816]: loss 2.477251
[epoch14, step1817]: loss 1.544400
[epoch14, step1818]: loss 14.790430
[epoch14, step1819]: loss 1.678830
[epoch14, step1820]: loss 1.074177
[epoch14, step1821]: loss 1.423859
[epoch14, step1822]: loss 0.947269
[epoch14, step1823]: loss 17.532259
[epoch14, step1824]: loss 0.714306
[epoch14, step1825]: loss 0.683692
[epoch14, step1826]: loss 26.339809
[epoch14, step1827]: loss 9.916450
[epoch14, step1828]: loss 8.467125
[epoch14, step1829]: loss 7.081934
[epoch14, step1830]: loss 3.063262
[epoch14, step1831]: loss 7.232874
[epoch14, step1832]: loss 4.679875
[epoch14, step1833]: loss 12.440120
[epoch14, step1834]: loss 0.646415
[epoch14, step1835]: loss 1.069386
[epoch14, step1836]: loss 7.629199
[epoch14, step1837]: loss 5.014118
[epoch14, step1838]: loss 2.896648
[epoch14, step1839]: loss 7.495263
[epoch14, step1840]: loss 3.219400
[epoch14, step1841]: loss 3.122454
[epoch14, step1842]: loss 1.381787
[epoch14, step1843]: loss 1.078705
[epoch14, step1844]: loss 2.715435
[epoch14, step1845]: loss 0.991621
[epoch14, step1846]: loss 2.973097
[epoch14, step1847]: loss 1.654763
[epoch14, step1848]: loss 1.042158
[epoch14, step1849]: loss 1.594273
[epoch14, step1850]: loss 12.480864
[epoch14, step1851]: loss 3.805458
[epoch14, step1852]: loss 1.961706
[epoch14, step1853]: loss 1.130833
[epoch14, step1854]: loss 11.095454
[epoch14, step1855]: loss 10.546445
[epoch14, step1856]: loss 0.874064
[epoch14, step1857]: loss 3.992468
[epoch14, step1858]: loss 7.377535
[epoch14, step1859]: loss 1.484478
[epoch14, step1860]: loss 0.870078
[epoch14, step1861]: loss 25.125269
[epoch14, step1862]: loss 1.672898
[epoch14, step1863]: loss 2.769216
[epoch14, step1864]: loss 2.832639
[epoch14, step1865]: loss 1.448675
[epoch14, step1866]: loss 0.890800
[epoch14, step1867]: loss 1.021415
[epoch14, step1868]: loss 1.643879
[epoch14, step1869]: loss 0.826974
[epoch14, step1870]: loss 0.975092
[epoch14, step1871]: loss 1.109404
[epoch14, step1872]: loss 0.776275
[epoch14, step1873]: loss 2.150143
[epoch14, step1874]: loss 3.438380
[epoch14, step1875]: loss 2.274262
[epoch14, step1876]: loss 0.628886
[epoch14, step1877]: loss 11.836525
[epoch14, step1878]: loss 6.072143
[epoch14, step1879]: loss 1.109470
[epoch14, step1880]: loss 1.182346
[epoch14, step1881]: loss 11.504523
[epoch14, step1882]: loss 7.228396
[epoch14, step1883]: loss 0.957446
[epoch14, step1884]: loss 2.736603
[epoch14, step1885]: loss 1.361731
[epoch14, step1886]: loss 0.719884
[epoch14, step1887]: loss 1.183471
[epoch14, step1888]: loss 11.966282
[epoch14, step1889]: loss 13.096399
[epoch14, step1890]: loss 0.772302
[epoch14, step1891]: loss 0.784257
[epoch14, step1892]: loss 1.699286
[epoch14, step1893]: loss 0.988088
[epoch14, step1894]: loss 6.945030
[epoch14, step1895]: loss 1.555741
[epoch14, step1896]: loss 4.157418
[epoch14, step1897]: loss 7.992700
[epoch14, step1898]: loss 0.755103
[epoch14, step1899]: loss 1.899999
[epoch14, step1900]: loss 1.774356
[epoch14, step1901]: loss 1.207204
[epoch14, step1902]: loss 11.739420
[epoch14, step1903]: loss 1.719062
[epoch14, step1904]: loss 3.137076
[epoch14, step1905]: loss 10.037796
[epoch14, step1906]: loss 1.247994
[epoch14, step1907]: loss 1.419921
[epoch14, step1908]: loss 1.063067
[epoch14, step1909]: loss 0.961128
[epoch14, step1910]: loss 1.931216
[epoch14, step1911]: loss 0.615075
[epoch14, step1912]: loss 1.539323
[epoch14, step1913]: loss 2.124723
[epoch14, step1914]: loss 1.425040
[epoch14, step1915]: loss 5.977360
[epoch14, step1916]: loss 0.767216
[epoch14, step1917]: loss 0.753149
[epoch14, step1918]: loss 10.967504
[epoch14, step1919]: loss 1.117486
[epoch14, step1920]: loss 1.833236
[epoch14, step1921]: loss 0.729196
[epoch14, step1922]: loss 1.005210
[epoch14, step1923]: loss 2.462807
[epoch14, step1924]: loss 2.261182
[epoch14, step1925]: loss 2.133204
[epoch14, step1926]: loss 1.105828
[epoch14, step1927]: loss 3.405481
[epoch14, step1928]: loss 2.363579
[epoch14, step1929]: loss 13.856432
[epoch14, step1930]: loss 1.477541
[epoch14, step1931]: loss 9.546275
[epoch14, step1932]: loss 20.829983
[epoch14, step1933]: loss 1.126441
[epoch14, step1934]: loss 0.885152
[epoch14, step1935]: loss 1.150218
[epoch14, step1936]: loss 1.777599
[epoch14, step1937]: loss 7.755032
[epoch14, step1938]: loss 1.205194
[epoch14, step1939]: loss 0.634806
[epoch14, step1940]: loss 7.139688
[epoch14, step1941]: loss 1.246473
[epoch14, step1942]: loss 5.896119
[epoch14, step1943]: loss 8.502639
[epoch14, step1944]: loss 4.256479
[epoch14, step1945]: loss 1.154486
[epoch14, step1946]: loss 1.164757
[epoch14, step1947]: loss 2.533824
[epoch14, step1948]: loss 8.734670
[epoch14, step1949]: loss 0.770000
[epoch14, step1950]: loss 1.905114
[epoch14, step1951]: loss 2.912399
[epoch14, step1952]: loss 1.673749
[epoch14, step1953]: loss 8.253475
[epoch14, step1954]: loss 3.955368
[epoch14, step1955]: loss 1.659518
[epoch14, step1956]: loss 8.896895
[epoch14, step1957]: loss 17.419292
[epoch14, step1958]: loss 10.792652
[epoch14, step1959]: loss 1.251901
[epoch14, step1960]: loss 0.804615
[epoch14, step1961]: loss 0.583192
[epoch14, step1962]: loss 1.035889
[epoch14, step1963]: loss 0.766613
[epoch14, step1964]: loss 1.191952
[epoch14, step1965]: loss 13.767250
[epoch14, step1966]: loss 1.824918
[epoch14, step1967]: loss 1.629261
[epoch14, step1968]: loss 11.390187
[epoch14, step1969]: loss 0.824545
[epoch14, step1970]: loss 2.307855
[epoch14, step1971]: loss 0.792092
[epoch14, step1972]: loss 20.552509
[epoch14, step1973]: loss 0.732500
[epoch14, step1974]: loss 3.694398
[epoch14, step1975]: loss 2.513611
[epoch14, step1976]: loss 14.098185
[epoch14, step1977]: loss 5.608301
[epoch14, step1978]: loss 3.196937
[epoch14, step1979]: loss 1.490231
[epoch14, step1980]: loss 1.341874
[epoch14, step1981]: loss 1.100554
[epoch14, step1982]: loss 0.963629
[epoch14, step1983]: loss 1.260935
[epoch14, step1984]: loss 3.042363
[epoch14, step1985]: loss 19.881685
[epoch14, step1986]: loss 3.083982
[epoch14, step1987]: loss 3.938140
[epoch14, step1988]: loss 1.999374
[epoch14, step1989]: loss 0.852680
[epoch14, step1990]: loss 1.129550
[epoch14, step1991]: loss 2.092802
[epoch14, step1992]: loss 0.956027
[epoch14, step1993]: loss 0.844965
[epoch14, step1994]: loss 0.788638
[epoch14, step1995]: loss 7.388072
[epoch14, step1996]: loss 3.433042
[epoch14, step1997]: loss 2.124269
[epoch14, step1998]: loss 29.011339
[epoch14, step1999]: loss 13.257401
[epoch14, step2000]: loss 13.082414
[epoch14, step2001]: loss 2.556028
[epoch14, step2002]: loss 1.548948
[epoch14, step2003]: loss 1.413200
[epoch14, step2004]: loss 3.688542
[epoch14, step2005]: loss 1.510192
[epoch14, step2006]: loss 1.098635
[epoch14, step2007]: loss 1.142517
[epoch14, step2008]: loss 1.048883
[epoch14, step2009]: loss 0.912632
[epoch14, step2010]: loss 4.438625
[epoch14, step2011]: loss 4.344211
[epoch14, step2012]: loss 1.391047
[epoch14, step2013]: loss 1.374120
[epoch14, step2014]: loss 7.611107
[epoch14, step2015]: loss 0.890624
[epoch14, step2016]: loss 15.246713
[epoch14, step2017]: loss 3.511124
[epoch14, step2018]: loss 0.766846
[epoch14, step2019]: loss 0.839509
[epoch14, step2020]: loss 2.448521
[epoch14, step2021]: loss 8.313780
[epoch14, step2022]: loss 17.237116
[epoch14, step2023]: loss 0.762731
[epoch14, step2024]: loss 2.093605
[epoch14, step2025]: loss 0.926609
[epoch14, step2026]: loss 0.600662
[epoch14, step2027]: loss 2.167765
[epoch14, step2028]: loss 9.707894
[epoch14, step2029]: loss 2.130410
[epoch14, step2030]: loss 0.608584
[epoch14, step2031]: loss 2.651096
[epoch14, step2032]: loss 0.891579
[epoch14, step2033]: loss 1.148328
[epoch14, step2034]: loss 1.108365
[epoch14, step2035]: loss 0.783648
[epoch14, step2036]: loss 0.760898
[epoch14, step2037]: loss 2.271786
[epoch14, step2038]: loss 3.856399
[epoch14, step2039]: loss 7.009631
[epoch14, step2040]: loss 0.749302
[epoch14, step2041]: loss 16.216642
[epoch14, step2042]: loss 1.087718
[epoch14, step2043]: loss 4.809574
[epoch14, step2044]: loss 2.721513
[epoch14, step2045]: loss 19.314756
[epoch14, step2046]: loss 0.923056
[epoch14, step2047]: loss 7.642284
[epoch14, step2048]: loss 1.029431
[epoch14, step2049]: loss 1.201262
[epoch14, step2050]: loss 8.004026
[epoch14, step2051]: loss 1.486004
[epoch14, step2052]: loss 3.488222
[epoch14, step2053]: loss 4.842405
[epoch14, step2054]: loss 19.763262
[epoch14, step2055]: loss 0.690329
[epoch14, step2056]: loss 10.172689
[epoch14, step2057]: loss 0.891686
[epoch14, step2058]: loss 1.716424
[epoch14, step2059]: loss 2.230956
[epoch14, step2060]: loss 7.787115
[epoch14, step2061]: loss 0.726749
[epoch14, step2062]: loss 1.000762
[epoch14, step2063]: loss 0.599711
[epoch14, step2064]: loss 2.058760
[epoch14, step2065]: loss 1.980646
[epoch14, step2066]: loss 8.495410
[epoch14, step2067]: loss 1.034252
[epoch14, step2068]: loss 1.547910
[epoch14, step2069]: loss 1.943971
[epoch14, step2070]: loss 3.127284
[epoch14, step2071]: loss 1.763563
[epoch14, step2072]: loss 2.487370
[epoch14, step2073]: loss 0.547144
[epoch14, step2074]: loss 0.973784
[epoch14, step2075]: loss 0.895646
[epoch14, step2076]: loss 1.658848
[epoch14, step2077]: loss 2.959758
[epoch14, step2078]: loss 2.150273
[epoch14, step2079]: loss 14.239898
[epoch14, step2080]: loss 0.979381
[epoch14, step2081]: loss 13.956267
[epoch14, step2082]: loss 9.088911
[epoch14, step2083]: loss 7.174269
[epoch14, step2084]: loss 0.793601
[epoch14, step2085]: loss 8.902368
[epoch14, step2086]: loss 9.539358
[epoch14, step2087]: loss 9.734927
[epoch14, step2088]: loss 5.139011
[epoch14, step2089]: loss 9.221716
[epoch14, step2090]: loss 3.885179
[epoch14, step2091]: loss 0.699085
[epoch14, step2092]: loss 8.800658
[epoch14, step2093]: loss 0.685583
[epoch14, step2094]: loss 2.468693
[epoch14, step2095]: loss 8.900993
[epoch14, step2096]: loss 0.870266
[epoch14, step2097]: loss 1.074536
[epoch14, step2098]: loss 0.998501
[epoch14, step2099]: loss 2.828747
[epoch14, step2100]: loss 10.726842
[epoch14, step2101]: loss 1.256996
[epoch14, step2102]: loss 13.775611
[epoch14, step2103]: loss 1.283569
[epoch14, step2104]: loss 1.108196
[epoch14, step2105]: loss 3.423125
[epoch14, step2106]: loss 0.702343
[epoch14, step2107]: loss 2.804603
[epoch14, step2108]: loss 9.395482
[epoch14, step2109]: loss 21.875303
[epoch14, step2110]: loss 6.141342
[epoch14, step2111]: loss 1.107479
[epoch14, step2112]: loss 9.714876
[epoch14, step2113]: loss 11.447580
[epoch14, step2114]: loss 2.240686
[epoch14, step2115]: loss 1.068490
[epoch14, step2116]: loss 4.687408
[epoch14, step2117]: loss 5.845778
[epoch14, step2118]: loss 8.093327
[epoch14, step2119]: loss 10.126875
[epoch14, step2120]: loss 1.168331
[epoch14, step2121]: loss 8.580732
[epoch14, step2122]: loss 0.659027
[epoch14, step2123]: loss 10.793539
[epoch14, step2124]: loss 8.007296
[epoch14, step2125]: loss 1.716066
[epoch14, step2126]: loss 0.781077
[epoch14, step2127]: loss 0.884405
[epoch14, step2128]: loss 8.288224
[epoch14, step2129]: loss 3.184640
[epoch14, step2130]: loss 1.325386
[epoch14, step2131]: loss 4.378510
[epoch14, step2132]: loss 7.569037
[epoch14, step2133]: loss 3.572584
[epoch14, step2134]: loss 1.639570
[epoch14, step2135]: loss 0.658209
[epoch14, step2136]: loss 1.839300
[epoch14, step2137]: loss 6.455723
[epoch14, step2138]: loss 1.332714
[epoch14, step2139]: loss 2.047629
[epoch14, step2140]: loss 13.016554
[epoch14, step2141]: loss 2.395232
[epoch14, step2142]: loss 1.759467
[epoch14, step2143]: loss 0.882933
[epoch14, step2144]: loss 1.105680
[epoch14, step2145]: loss 1.538414
[epoch14, step2146]: loss 8.179460
[epoch14, step2147]: loss 3.995354
[epoch14, step2148]: loss 2.969991
[epoch14, step2149]: loss 1.892737
[epoch14, step2150]: loss 2.459900
[epoch14, step2151]: loss 1.767505
[epoch14, step2152]: loss 1.143839
[epoch14, step2153]: loss 0.917544
[epoch14, step2154]: loss 7.259717
[epoch14, step2155]: loss 6.340598
[epoch14, step2156]: loss 1.332907
[epoch14, step2157]: loss 9.970287
[epoch14, step2158]: loss 19.893534
[epoch14, step2159]: loss 3.502874
[epoch14, step2160]: loss 0.930509
[epoch14, step2161]: loss 1.326113
[epoch14, step2162]: loss 1.978405
[epoch14, step2163]: loss 13.863917
[epoch14, step2164]: loss 0.654675
[epoch14, step2165]: loss 1.244794
[epoch14, step2166]: loss 7.471322
[epoch14, step2167]: loss 0.851911
[epoch14, step2168]: loss 1.056973
[epoch14, step2169]: loss 6.542871
[epoch14, step2170]: loss 2.503809
[epoch14, step2171]: loss 0.847222
[epoch14, step2172]: loss 8.654199
[epoch14, step2173]: loss 9.351981
[epoch14, step2174]: loss 5.160554
[epoch14, step2175]: loss 1.202101
[epoch14, step2176]: loss 2.359616
[epoch14, step2177]: loss 1.371628
[epoch14, step2178]: loss 0.606619
[epoch14, step2179]: loss 2.101885
[epoch14, step2180]: loss 2.757427
[epoch14, step2181]: loss 2.754070
[epoch14, step2182]: loss 1.327653
[epoch14, step2183]: loss 2.652551
[epoch14, step2184]: loss 1.155525
[epoch14, step2185]: loss 10.197070
[epoch14, step2186]: loss 15.926051
[epoch14, step2187]: loss 0.810619
[epoch14, step2188]: loss 1.985268
[epoch14, step2189]: loss 3.130581
[epoch14, step2190]: loss 1.467958
[epoch14, step2191]: loss 1.174540
[epoch14, step2192]: loss 7.771197
[epoch14, step2193]: loss 4.460520
[epoch14, step2194]: loss 1.740449
[epoch14, step2195]: loss 8.143307
[epoch14, step2196]: loss 5.687459
[epoch14, step2197]: loss 1.022006
[epoch14, step2198]: loss 1.120838
[epoch14, step2199]: loss 2.783118
[epoch14, step2200]: loss 1.087425
[epoch14, step2201]: loss 0.914222
[epoch14, step2202]: loss 0.961774
[epoch14, step2203]: loss 0.989521
[epoch14, step2204]: loss 16.917442
[epoch14, step2205]: loss 1.511483
[epoch14, step2206]: loss 3.014524
[epoch14, step2207]: loss 2.976151
[epoch14, step2208]: loss 17.623533
[epoch14, step2209]: loss 1.949524
[epoch14, step2210]: loss 0.724417
[epoch14, step2211]: loss 15.777775
[epoch14, step2212]: loss 1.449344
[epoch14, step2213]: loss 6.074584
[epoch14, step2214]: loss 2.821773
[epoch14, step2215]: loss 10.220918
[epoch14, step2216]: loss 2.510848
[epoch14, step2217]: loss 1.350908
[epoch14, step2218]: loss 0.942829
[epoch14, step2219]: loss 1.348165
[epoch14, step2220]: loss 8.194138
[epoch14, step2221]: loss 6.213597
[epoch14, step2222]: loss 7.189213
[epoch14, step2223]: loss 10.278284
[epoch14, step2224]: loss 1.759783
[epoch14, step2225]: loss 2.847862
[epoch14, step2226]: loss 1.414013
[epoch14, step2227]: loss 12.587260
[epoch14, step2228]: loss 1.493306
[epoch14, step2229]: loss 0.924266
[epoch14, step2230]: loss 1.027860
[epoch14, step2231]: loss 2.989378
[epoch14, step2232]: loss 1.452820
[epoch14, step2233]: loss 1.663582
[epoch14, step2234]: loss 1.492771
[epoch14, step2235]: loss 0.712695
[epoch14, step2236]: loss 1.714986
[epoch14, step2237]: loss 0.967804
[epoch14, step2238]: loss 0.849746
[epoch14, step2239]: loss 2.526244
[epoch14, step2240]: loss 1.279756
[epoch14, step2241]: loss 0.721247
[epoch14, step2242]: loss 8.687231
[epoch14, step2243]: loss 5.177332
[epoch14, step2244]: loss 0.728591
[epoch14, step2245]: loss 1.211255
[epoch14, step2246]: loss 8.607244
[epoch14, step2247]: loss 0.947021
[epoch14, step2248]: loss 3.679043
[epoch14, step2249]: loss 1.783583
[epoch14, step2250]: loss 8.723944
[epoch14, step2251]: loss 9.287821
[epoch14, step2252]: loss 9.417109
[epoch14, step2253]: loss 2.819486
[epoch14, step2254]: loss 2.352179
[epoch14, step2255]: loss 8.629781
[epoch14, step2256]: loss 1.032805
[epoch14, step2257]: loss 7.486114
[epoch14, step2258]: loss 1.742722
[epoch14, step2259]: loss 3.339684
[epoch14, step2260]: loss 6.564240
[epoch14, step2261]: loss 1.589925
[epoch14, step2262]: loss 9.929193
[epoch14, step2263]: loss 2.910427
[epoch14, step2264]: loss 1.001627
[epoch14, step2265]: loss 1.817888
[epoch14, step2266]: loss 1.228004
[epoch14, step2267]: loss 12.329291
[epoch14, step2268]: loss 0.900835
[epoch14, step2269]: loss 3.008976
[epoch14, step2270]: loss 7.975153
[epoch14, step2271]: loss 1.714740
[epoch14, step2272]: loss 8.167552
[epoch14, step2273]: loss 8.234496
[epoch14, step2274]: loss 1.361892
[epoch14, step2275]: loss 3.677926
[epoch14, step2276]: loss 1.524974
[epoch14, step2277]: loss 1.485031
[epoch14, step2278]: loss 3.558033
[epoch14, step2279]: loss 1.130017
[epoch14, step2280]: loss 5.344491
[epoch14, step2281]: loss 8.905398
[epoch14, step2282]: loss 0.877910
[epoch14, step2283]: loss 9.482916
[epoch14, step2284]: loss 7.950668
[epoch14, step2285]: loss 0.745140
[epoch14, step2286]: loss 0.805720
[epoch14, step2287]: loss 6.833099
[epoch14, step2288]: loss 8.381647
[epoch14, step2289]: loss 1.038947
[epoch14, step2290]: loss 1.219217
[epoch14, step2291]: loss 1.369342
[epoch14, step2292]: loss 8.044099
[epoch14, step2293]: loss 6.787245
[epoch14, step2294]: loss 1.969714
[epoch14, step2295]: loss 10.082181
[epoch14, step2296]: loss 1.743219
[epoch14, step2297]: loss 8.636936
[epoch14, step2298]: loss 1.071214
[epoch14, step2299]: loss 7.587645
[epoch14, step2300]: loss 7.482242
[epoch14, step2301]: loss 9.282869
[epoch14, step2302]: loss 0.790595
[epoch14, step2303]: loss 11.249850
[epoch14, step2304]: loss 1.132411
[epoch14, step2305]: loss 2.373464
[epoch14, step2306]: loss 0.888893
[epoch14, step2307]: loss 5.545510
[epoch14, step2308]: loss 1.554007
[epoch14, step2309]: loss 3.108729
[epoch14, step2310]: loss 0.779304
[epoch14, step2311]: loss 3.204670
[epoch14, step2312]: loss 2.234740
[epoch14, step2313]: loss 1.820358
[epoch14, step2314]: loss 6.481455
[epoch14, step2315]: loss 1.875786
[epoch14, step2316]: loss 7.939489
[epoch14, step2317]: loss 6.313177
[epoch14, step2318]: loss 1.827183
[epoch14, step2319]: loss 2.052433
[epoch14, step2320]: loss 1.718052
[epoch14, step2321]: loss 2.221202
[epoch14, step2322]: loss 2.425198
[epoch14, step2323]: loss 1.767542
[epoch14, step2324]: loss 9.605367
[epoch14, step2325]: loss 1.435721
[epoch14, step2326]: loss 5.330948
[epoch14, step2327]: loss 1.351363
[epoch14, step2328]: loss 7.295784
[epoch14, step2329]: loss 2.790312
[epoch14, step2330]: loss 1.191107
[epoch14, step2331]: loss 16.196867
[epoch14, step2332]: loss 1.243941
[epoch14, step2333]: loss 1.042708
[epoch14, step2334]: loss 1.113446
[epoch14, step2335]: loss 2.659348
[epoch14, step2336]: loss 0.818528
[epoch14, step2337]: loss 1.051606
[epoch14, step2338]: loss 2.122737
[epoch14, step2339]: loss 7.418498
[epoch14, step2340]: loss 1.209494
[epoch14, step2341]: loss 2.234628
[epoch14, step2342]: loss 0.959639
[epoch14, step2343]: loss 0.790483
[epoch14, step2344]: loss 1.373585
[epoch14, step2345]: loss 6.802300
[epoch14, step2346]: loss 1.141814
[epoch14, step2347]: loss 2.335995
[epoch14, step2348]: loss 17.140205
[epoch14, step2349]: loss 3.760190
[epoch14, step2350]: loss 15.779864
[epoch14, step2351]: loss 2.361111
[epoch14, step2352]: loss 2.479818
[epoch14, step2353]: loss 0.938607
[epoch14, step2354]: loss 0.647446
[epoch14, step2355]: loss 0.943746
[epoch14, step2356]: loss 9.672606
[epoch14, step2357]: loss 1.961047
[epoch14, step2358]: loss 1.954344
[epoch14, step2359]: loss 1.408270
[epoch14, step2360]: loss 0.706365
[epoch14, step2361]: loss 0.603072
[epoch14, step2362]: loss 3.128507
[epoch14, step2363]: loss 1.266377
[epoch14, step2364]: loss 3.759597
[epoch14, step2365]: loss 11.831415
[epoch14, step2366]: loss 0.669129
[epoch14, step2367]: loss 3.729029
[epoch14, step2368]: loss 5.702104
[epoch14, step2369]: loss 1.106442
[epoch14, step2370]: loss 2.296589
[epoch14, step2371]: loss 18.692497
[epoch14, step2372]: loss 1.065545
[epoch14, step2373]: loss 1.944275
[epoch14, step2374]: loss 1.972273
[epoch14, step2375]: loss 2.125314
[epoch14, step2376]: loss 3.583774
[epoch14, step2377]: loss 0.911541
[epoch14, step2378]: loss 7.799860
[epoch14, step2379]: loss 9.332361
[epoch14, step2380]: loss 4.830066
[epoch14, step2381]: loss 2.225777
[epoch14, step2382]: loss 15.512340
[epoch14, step2383]: loss 2.353328
[epoch14, step2384]: loss 18.948015
[epoch14, step2385]: loss 2.482632
[epoch14, step2386]: loss 2.605364
[epoch14, step2387]: loss 12.079522
[epoch14, step2388]: loss 10.577132
[epoch14, step2389]: loss 1.089595
[epoch14, step2390]: loss 2.748260
[epoch14, step2391]: loss 0.966469
[epoch14, step2392]: loss 1.325316
[epoch14, step2393]: loss 4.249942
[epoch14, step2394]: loss 1.269532
[epoch14, step2395]: loss 20.488714
[epoch14, step2396]: loss 7.166187
[epoch14, step2397]: loss 9.356144
[epoch14, step2398]: loss 1.821779
[epoch14, step2399]: loss 6.488828
[epoch14, step2400]: loss 1.466873
[epoch14, step2401]: loss 1.396803
[epoch14, step2402]: loss 3.693197
[epoch14, step2403]: loss 13.906579
[epoch14, step2404]: loss 8.857891
[epoch14, step2405]: loss 0.968325
[epoch14, step2406]: loss 0.902903
[epoch14, step2407]: loss 2.658741
[epoch14, step2408]: loss 0.850959
[epoch14, step2409]: loss 2.988327
[epoch14, step2410]: loss 0.853517
[epoch14, step2411]: loss 13.761226
[epoch14, step2412]: loss 12.863465
[epoch14, step2413]: loss 1.476077
[epoch14, step2414]: loss 1.488364
[epoch14, step2415]: loss 10.157501
[epoch14, step2416]: loss 1.940264
[epoch14, step2417]: loss 1.878020
[epoch14, step2418]: loss 0.664746
[epoch14, step2419]: loss 1.898713
[epoch14, step2420]: loss 2.352046
[epoch14, step2421]: loss 0.639891
[epoch14, step2422]: loss 8.655817
[epoch14, step2423]: loss 0.637893
[epoch14, step2424]: loss 0.656941
[epoch14, step2425]: loss 2.641777
[epoch14, step2426]: loss 8.330358
[epoch14, step2427]: loss 10.574203
[epoch14, step2428]: loss 12.231339
[epoch14, step2429]: loss 0.907976
[epoch14, step2430]: loss 12.113980
[epoch14, step2431]: loss 13.508836
[epoch14, step2432]: loss 2.420040
[epoch14, step2433]: loss 2.966104
[epoch14, step2434]: loss 12.702128
[epoch14, step2435]: loss 0.863542
[epoch14, step2436]: loss 25.744759
[epoch14, step2437]: loss 6.642508
[epoch14, step2438]: loss 1.519900
[epoch14, step2439]: loss 0.862423
[epoch14, step2440]: loss 0.773722
[epoch14, step2441]: loss 7.339334
[epoch14, step2442]: loss 9.912246
[epoch14, step2443]: loss 9.216018
[epoch14, step2444]: loss 11.271916
[epoch14, step2445]: loss 8.714548
[epoch14, step2446]: loss 13.951645
[epoch14, step2447]: loss 4.554153
[epoch14, step2448]: loss 1.505658
[epoch14, step2449]: loss 2.739517
[epoch14, step2450]: loss 2.565446
[epoch14, step2451]: loss 10.562612
[epoch14, step2452]: loss 1.117822
[epoch14, step2453]: loss 10.341943
[epoch14, step2454]: loss 4.592400
[epoch14, step2455]: loss 2.476722
[epoch14, step2456]: loss 1.003532
[epoch14, step2457]: loss 1.159277
[epoch14, step2458]: loss 2.533065
[epoch14, step2459]: loss 1.331197
[epoch14, step2460]: loss 1.575378
[epoch14, step2461]: loss 7.421829
[epoch14, step2462]: loss 0.722857
[epoch14, step2463]: loss 2.101061
[epoch14, step2464]: loss 1.106527
[epoch14, step2465]: loss 0.891597
[epoch14, step2466]: loss 0.640260
[epoch14, step2467]: loss 10.199953
[epoch14, step2468]: loss 3.001359
[epoch14, step2469]: loss 4.913464
[epoch14, step2470]: loss 6.728396
[epoch14, step2471]: loss 2.756636
[epoch14, step2472]: loss 15.390737
[epoch14, step2473]: loss 1.089952
[epoch14, step2474]: loss 2.543732
[epoch14, step2475]: loss 13.046355
[epoch14, step2476]: loss 1.784164
[epoch14, step2477]: loss 0.604303
[epoch14, step2478]: loss 9.273181
[epoch14, step2479]: loss 1.833838
[epoch14, step2480]: loss 4.485260
[epoch14, step2481]: loss 2.792270
[epoch14, step2482]: loss 7.134582
[epoch14, step2483]: loss 1.253638
[epoch14, step2484]: loss 2.171921
[epoch14, step2485]: loss 1.399719
[epoch14, step2486]: loss 0.775055
[epoch14, step2487]: loss 1.194123
[epoch14, step2488]: loss 0.647476
[epoch14, step2489]: loss 0.625959
[epoch14, step2490]: loss 8.876539
[epoch14, step2491]: loss 3.303577
[epoch14, step2492]: loss 1.381090
[epoch14, step2493]: loss 1.570017
[epoch14, step2494]: loss 1.024861
[epoch14, step2495]: loss 13.257791
[epoch14, step2496]: loss 1.009641
[epoch14, step2497]: loss 8.801298
[epoch14, step2498]: loss 9.240041
[epoch14, step2499]: loss 1.156744
[epoch14, step2500]: loss 10.201770
[epoch14, step2501]: loss 7.490983
[epoch14, step2502]: loss 1.121137
[epoch14, step2503]: loss 2.933701
[epoch14, step2504]: loss 1.191802
[epoch14, step2505]: loss 1.140375
[epoch14, step2506]: loss 1.567599
[epoch14, step2507]: loss 0.863312
[epoch14, step2508]: loss 2.917585
[epoch14, step2509]: loss 9.419946
[epoch14, step2510]: loss 7.232542
[epoch14, step2511]: loss 1.106742
[epoch14, step2512]: loss 1.580654
[epoch14, step2513]: loss 5.242692
[epoch14, step2514]: loss 2.898681
[epoch14, step2515]: loss 2.004060
[epoch14, step2516]: loss 6.452131
[epoch14, step2517]: loss 0.841727
[epoch14, step2518]: loss 1.609039
[epoch14, step2519]: loss 2.544293
[epoch14, step2520]: loss 12.751644
[epoch14, step2521]: loss 1.845702
[epoch14, step2522]: loss 12.887335
[epoch14, step2523]: loss 8.790855
[epoch14, step2524]: loss 1.464103
[epoch14, step2525]: loss 17.511093
[epoch14, step2526]: loss 2.582237
[epoch14, step2527]: loss 0.802565
[epoch14, step2528]: loss 11.617717
[epoch14, step2529]: loss 3.453232
[epoch14, step2530]: loss 0.907371
[epoch14, step2531]: loss 9.222804
[epoch14, step2532]: loss 4.588049
[epoch14, step2533]: loss 0.985991
[epoch14, step2534]: loss 1.087408
[epoch14, step2535]: loss 1.753534
[epoch14, step2536]: loss 12.206729
[epoch14, step2537]: loss 13.464981
[epoch14, step2538]: loss 9.013859
[epoch14, step2539]: loss 1.540309
[epoch14, step2540]: loss 10.176761
[epoch14, step2541]: loss 3.209077
[epoch14, step2542]: loss 1.683665
[epoch14, step2543]: loss 0.775491
[epoch14, step2544]: loss 10.539993
[epoch14, step2545]: loss 10.156918
[epoch14, step2546]: loss 1.192223
[epoch14, step2547]: loss 2.203407
[epoch14, step2548]: loss 0.989226
[epoch14, step2549]: loss 1.412405
[epoch14, step2550]: loss 2.983272
[epoch14, step2551]: loss 11.564672
[epoch14, step2552]: loss 10.103563
[epoch14, step2553]: loss 0.985570
[epoch14, step2554]: loss 4.303587
[epoch14, step2555]: loss 1.476635
[epoch14, step2556]: loss 0.831962
[epoch14, step2557]: loss 11.329562
[epoch14, step2558]: loss 1.817117
[epoch14, step2559]: loss 3.426619
[epoch14, step2560]: loss 2.368077
[epoch14, step2561]: loss 7.501857
[epoch14, step2562]: loss 8.578970
[epoch14, step2563]: loss 10.097018
[epoch14, step2564]: loss 6.599822
[epoch14, step2565]: loss 4.936925
[epoch14, step2566]: loss 1.116436
[epoch14, step2567]: loss 3.294523
[epoch14, step2568]: loss 2.653500
[epoch14, step2569]: loss 4.331120
[epoch14, step2570]: loss 19.789837
[epoch14, step2571]: loss 11.741787
[epoch14, step2572]: loss 2.877868
[epoch14, step2573]: loss 11.941881
[epoch14, step2574]: loss 2.701236
[epoch14, step2575]: loss 18.039143
[epoch14, step2576]: loss 0.842541
[epoch14, step2577]: loss 1.282929
[epoch14, step2578]: loss 1.229491
[epoch14, step2579]: loss 6.459471
[epoch14, step2580]: loss 9.696014
[epoch14, step2581]: loss 0.481988
[epoch14, step2582]: loss 7.220199
[epoch14, step2583]: loss 6.090395
[epoch14, step2584]: loss 1.239334
[epoch14, step2585]: loss 11.938117
[epoch14, step2586]: loss 2.783124
[epoch14, step2587]: loss 1.214056
[epoch14, step2588]: loss 1.815507
[epoch14, step2589]: loss 2.139695
[epoch14, step2590]: loss 7.527055
[epoch14, step2591]: loss 18.536493
[epoch14, step2592]: loss 2.947615
[epoch14, step2593]: loss 4.235107
[epoch14, step2594]: loss 0.983175
[epoch14, step2595]: loss 1.057640
[epoch14, step2596]: loss 0.981090
[epoch14, step2597]: loss 3.704323
[epoch14, step2598]: loss 1.718757
[epoch14, step2599]: loss 1.172130
[epoch14, step2600]: loss 1.903692
[epoch14, step2601]: loss 6.673030
[epoch14, step2602]: loss 8.801197
[epoch14, step2603]: loss 1.705697
[epoch14, step2604]: loss 1.012021
[epoch14, step2605]: loss 1.052054
[epoch14, step2606]: loss 1.965630
[epoch14, step2607]: loss 1.437274
[epoch14, step2608]: loss 8.374541
[epoch14, step2609]: loss 5.587234
[epoch14, step2610]: loss 0.784055
[epoch14, step2611]: loss 8.973877
[epoch14, step2612]: loss 2.544411
[epoch14, step2613]: loss 8.919753
[epoch14, step2614]: loss 3.702841
[epoch14, step2615]: loss 1.963043
[epoch14, step2616]: loss 0.803973
[epoch14, step2617]: loss 1.560524
[epoch14, step2618]: loss 1.230249
[epoch14, step2619]: loss 1.247389
[epoch14, step2620]: loss 3.254934
[epoch14, step2621]: loss 0.890436
[epoch14, step2622]: loss 3.167797
[epoch14, step2623]: loss 10.817958
[epoch14, step2624]: loss 1.760037
[epoch14, step2625]: loss 0.710364
[epoch14, step2626]: loss 2.518421
[epoch14, step2627]: loss 0.655735
[epoch14, step2628]: loss 1.159959
[epoch14, step2629]: loss 2.884029
[epoch14, step2630]: loss 0.631144
[epoch14, step2631]: loss 0.906545
[epoch14, step2632]: loss 5.981392
[epoch14, step2633]: loss 13.423404
[epoch14, step2634]: loss 2.409335
[epoch14, step2635]: loss 6.562891
[epoch14, step2636]: loss 1.739090
[epoch14, step2637]: loss 11.740298
[epoch14, step2638]: loss 0.991926
[epoch14, step2639]: loss 1.036745
[epoch14, step2640]: loss 1.603279
[epoch14, step2641]: loss 3.583475
[epoch14, step2642]: loss 3.204269
[epoch14, step2643]: loss 1.084341
[epoch14, step2644]: loss 3.483140
[epoch14, step2645]: loss 1.122682
[epoch14, step2646]: loss 0.943501
[epoch14, step2647]: loss 2.475217
[epoch14, step2648]: loss 5.897653
[epoch14, step2649]: loss 1.005977
[epoch14, step2650]: loss 1.972092
[epoch14, step2651]: loss 1.062894
[epoch14, step2652]: loss 11.342259
[epoch14, step2653]: loss 3.741078
[epoch14, step2654]: loss 1.833271
[epoch14, step2655]: loss 1.964907
[epoch14, step2656]: loss 0.609010
[epoch14, step2657]: loss 2.773933
[epoch14, step2658]: loss 5.874958
[epoch14, step2659]: loss 0.914998
[epoch14, step2660]: loss 10.030384
[epoch14, step2661]: loss 0.828527
[epoch14, step2662]: loss 0.735275
[epoch14, step2663]: loss 2.957592
[epoch14, step2664]: loss 1.806374
[epoch14, step2665]: loss 0.897714
[epoch14, step2666]: loss 2.280494
[epoch14, step2667]: loss 2.322939
[epoch14, step2668]: loss 1.148770
[epoch14, step2669]: loss 15.300643
[epoch14, step2670]: loss 14.207432
[epoch14, step2671]: loss 7.896553
[epoch14, step2672]: loss 14.926537
[epoch14, step2673]: loss 5.882897
[epoch14, step2674]: loss 0.855146
[epoch14, step2675]: loss 1.078963
[epoch14, step2676]: loss 1.224774
[epoch14, step2677]: loss 0.813571
[epoch14, step2678]: loss 1.481123
[epoch14, step2679]: loss 4.749468
[epoch14, step2680]: loss 1.324145
[epoch14, step2681]: loss 21.301250
[epoch14, step2682]: loss 5.053356
[epoch14, step2683]: loss 1.305169
[epoch14, step2684]: loss 1.804023
[epoch14, step2685]: loss 0.955662
[epoch14, step2686]: loss 6.321377
[epoch14, step2687]: loss 6.187740
[epoch14, step2688]: loss 1.476121
[epoch14, step2689]: loss 7.789702
[epoch14, step2690]: loss 1.490941
[epoch14, step2691]: loss 1.014915
[epoch14, step2692]: loss 0.840279
[epoch14, step2693]: loss 16.722172
[epoch14, step2694]: loss 7.595922
[epoch14, step2695]: loss 3.023876
[epoch14, step2696]: loss 2.567157
[epoch14, step2697]: loss 11.396582
[epoch14, step2698]: loss 1.062406
[epoch14, step2699]: loss 1.043307
[epoch14, step2700]: loss 9.384170
[epoch14, step2701]: loss 7.876452
[epoch14, step2702]: loss 11.778584
[epoch14, step2703]: loss 1.379503
[epoch14, step2704]: loss 10.927766
[epoch14, step2705]: loss 2.471430
[epoch14, step2706]: loss 3.360876
[epoch14, step2707]: loss 8.065461
[epoch14, step2708]: loss 0.910253
[epoch14, step2709]: loss 6.335988
[epoch14, step2710]: loss 8.983047
[epoch14, step2711]: loss 12.682643
[epoch14, step2712]: loss 1.566159
[epoch14, step2713]: loss 8.128157
[epoch14, step2714]: loss 1.158370
[epoch14, step2715]: loss 3.188474
[epoch14, step2716]: loss 13.882610
[epoch14, step2717]: loss 0.979773
[epoch14, step2718]: loss 18.258839
[epoch14, step2719]: loss 0.989613
[epoch14, step2720]: loss 1.194846
[epoch14, step2721]: loss 4.839435
[epoch14, step2722]: loss 1.494017
[epoch14, step2723]: loss 1.101170
[epoch14, step2724]: loss 8.588238
[epoch14, step2725]: loss 7.166502
[epoch14, step2726]: loss 1.414536
[epoch14, step2727]: loss 8.402983
[epoch14, step2728]: loss 0.932383
[epoch14, step2729]: loss 0.743262
[epoch14, step2730]: loss 1.140628
[epoch14, step2731]: loss 2.572610
[epoch14, step2732]: loss 2.132162
[epoch14, step2733]: loss 16.125912
[epoch14, step2734]: loss 2.533046
[epoch14, step2735]: loss 6.735332
[epoch14, step2736]: loss 6.966101
[epoch14, step2737]: loss 3.584532
[epoch14, step2738]: loss 11.880445
[epoch14, step2739]: loss 3.544166
[epoch14, step2740]: loss 1.474081
[epoch14, step2741]: loss 7.671093
[epoch14, step2742]: loss 2.276388
[epoch14, step2743]: loss 3.380571
[epoch14, step2744]: loss 1.338249
[epoch14, step2745]: loss 2.343009
[epoch14, step2746]: loss 8.465765
[epoch14, step2747]: loss 1.862274
[epoch14, step2748]: loss 1.255907
[epoch14, step2749]: loss 4.243967
[epoch14, step2750]: loss 13.237108
[epoch14, step2751]: loss 0.666128
[epoch14, step2752]: loss 1.041132
[epoch14, step2753]: loss 8.114763
[epoch14, step2754]: loss 5.165353
[epoch14, step2755]: loss 8.566722
[epoch14, step2756]: loss 0.887514
[epoch14, step2757]: loss 14.469269
[epoch14, step2758]: loss 11.215593
[epoch14, step2759]: loss 2.935912
[epoch14, step2760]: loss 5.540355
[epoch14, step2761]: loss 5.298744
[epoch14, step2762]: loss 1.198615
[epoch14, step2763]: loss 15.395056
[epoch14, step2764]: loss 0.800011
[epoch14, step2765]: loss 4.548079
[epoch14, step2766]: loss 1.215585
[epoch14, step2767]: loss 0.745816
[epoch14, step2768]: loss 0.925792
[epoch14, step2769]: loss 3.634339
[epoch14, step2770]: loss 8.308878
[epoch14, step2771]: loss 8.475174
[epoch14, step2772]: loss 8.298827
[epoch14, step2773]: loss 8.543677
[epoch14, step2774]: loss 1.130811
[epoch14, step2775]: loss 1.101286
[epoch14, step2776]: loss 1.271037
[epoch14, step2777]: loss 3.064103
[epoch14, step2778]: loss 1.161828
[epoch14, step2779]: loss 0.988711
[epoch14, step2780]: loss 0.952716
[epoch14, step2781]: loss 11.760992
[epoch14, step2782]: loss 13.597686
[epoch14, step2783]: loss 8.121057
[epoch14, step2784]: loss 1.927838
[epoch14, step2785]: loss 0.881640
[epoch14, step2786]: loss 6.814276
[epoch14, step2787]: loss 1.587659
[epoch14, step2788]: loss 1.771600
[epoch14, step2789]: loss 0.861749
[epoch14, step2790]: loss 2.270638
[epoch14, step2791]: loss 0.882528
[epoch14, step2792]: loss 5.610636
[epoch14, step2793]: loss 1.434393
[epoch14, step2794]: loss 6.674695
[epoch14, step2795]: loss 7.119664
[epoch14, step2796]: loss 1.016123
[epoch14, step2797]: loss 3.256926
[epoch14, step2798]: loss 2.926616
[epoch14, step2799]: loss 13.031380
[epoch14, step2800]: loss 4.612918
[epoch14, step2801]: loss 4.586549
[epoch14, step2802]: loss 10.980230
[epoch14, step2803]: loss 0.615735
[epoch14, step2804]: loss 10.776189
[epoch14, step2805]: loss 0.998707
[epoch14, step2806]: loss 0.645240
[epoch14, step2807]: loss 2.636422
[epoch14, step2808]: loss 2.196969
[epoch14, step2809]: loss 0.825020
[epoch14, step2810]: loss 2.158316
[epoch14, step2811]: loss 9.478716
[epoch14, step2812]: loss 0.738019
[epoch14, step2813]: loss 9.353811
[epoch14, step2814]: loss 8.341345
[epoch14, step2815]: loss 10.032138
[epoch14, step2816]: loss 1.233274
[epoch14, step2817]: loss 1.646687
[epoch14, step2818]: loss 22.643618
[epoch14, step2819]: loss 0.962785
[epoch14, step2820]: loss 1.832792
[epoch14, step2821]: loss 1.539191
[epoch14, step2822]: loss 7.603912
[epoch14, step2823]: loss 9.950681
[epoch14, step2824]: loss 8.383186
[epoch14, step2825]: loss 3.493192
[epoch14, step2826]: loss 15.192780
[epoch14, step2827]: loss 1.812672
[epoch14, step2828]: loss 2.988687
[epoch14, step2829]: loss 1.075040
[epoch14, step2830]: loss 12.413832
[epoch14, step2831]: loss 14.248029
[epoch14, step2832]: loss 10.190686
[epoch14, step2833]: loss 7.069729
[epoch14, step2834]: loss 0.737603
[epoch14, step2835]: loss 1.103579
[epoch14, step2836]: loss 10.207135
[epoch14, step2837]: loss 2.708632
[epoch14, step2838]: loss 0.553671
[epoch14, step2839]: loss 0.951596
[epoch14, step2840]: loss 1.625627
[epoch14, step2841]: loss 3.404043
[epoch14, step2842]: loss 7.265743
[epoch14, step2843]: loss 1.828877
[epoch14, step2844]: loss 2.134093
[epoch14, step2845]: loss 0.950063
[epoch14, step2846]: loss 0.811117
[epoch14, step2847]: loss 2.941921
[epoch14, step2848]: loss 11.367787
[epoch14, step2849]: loss 7.719844
[epoch14, step2850]: loss 0.926059
[epoch14, step2851]: loss 1.306322
[epoch14, step2852]: loss 2.655473
[epoch14, step2853]: loss 1.043877
[epoch14, step2854]: loss 0.923597
[epoch14, step2855]: loss 0.960835
[epoch14, step2856]: loss 9.928638
[epoch14, step2857]: loss 12.697055
[epoch14, step2858]: loss 1.364670
[epoch14, step2859]: loss 1.431504
[epoch14, step2860]: loss 0.632519
[epoch14, step2861]: loss 0.744171
[epoch14, step2862]: loss 2.354960
[epoch14, step2863]: loss 1.030115
[epoch14, step2864]: loss 0.803533
[epoch14, step2865]: loss 0.620780
[epoch14, step2866]: loss 1.515112
[epoch14, step2867]: loss 1.420638
[epoch14, step2868]: loss 1.126902
[epoch14, step2869]: loss 3.291985
[epoch14, step2870]: loss 7.562671
[epoch14, step2871]: loss 1.119714
[epoch14, step2872]: loss 9.407773
[epoch14, step2873]: loss 1.847949
[epoch14, step2874]: loss 0.881487
[epoch14, step2875]: loss 2.443176
[epoch14, step2876]: loss 0.668789
[epoch14, step2877]: loss 0.934420
[epoch14, step2878]: loss 5.967538
[epoch14, step2879]: loss 3.471306
[epoch14, step2880]: loss 8.319018
[epoch14, step2881]: loss 0.597322
[epoch14, step2882]: loss 1.208288
[epoch14, step2883]: loss 1.673647
[epoch14, step2884]: loss 1.039230
[epoch14, step2885]: loss 15.241673
[epoch14, step2886]: loss 2.325640
[epoch14, step2887]: loss 0.955129
[epoch14, step2888]: loss 10.519708
[epoch14, step2889]: loss 0.864464
[epoch14, step2890]: loss 7.580744
[epoch14, step2891]: loss 2.625304
[epoch14, step2892]: loss 3.080349
[epoch14, step2893]: loss 0.676109
[epoch14, step2894]: loss 1.753899
[epoch14, step2895]: loss 15.196433
[epoch14, step2896]: loss 7.327875
[epoch14, step2897]: loss 2.470938
[epoch14, step2898]: loss 0.644870
[epoch14, step2899]: loss 7.318277
[epoch14, step2900]: loss 1.564406
[epoch14, step2901]: loss 0.976710
[epoch14, step2902]: loss 8.368792
[epoch14, step2903]: loss 0.734311
[epoch14, step2904]: loss 2.010861
[epoch14, step2905]: loss 1.057976
[epoch14, step2906]: loss 2.963109
[epoch14, step2907]: loss 1.719393
[epoch14, step2908]: loss 0.754305
[epoch14, step2909]: loss 0.900296
[epoch14, step2910]: loss 1.474609
[epoch14, step2911]: loss 2.577334
[epoch14, step2912]: loss 8.290314
[epoch14, step2913]: loss 0.969219
[epoch14, step2914]: loss 0.531688
[epoch14, step2915]: loss 3.631803
[epoch14, step2916]: loss 1.269473
[epoch14, step2917]: loss 1.000514
[epoch14, step2918]: loss 1.113335
[epoch14, step2919]: loss 2.054768
[epoch14, step2920]: loss 2.908487
[epoch14, step2921]: loss 10.180072
[epoch14, step2922]: loss 10.379071
[epoch14, step2923]: loss 0.972696
[epoch14, step2924]: loss 7.521819
[epoch14, step2925]: loss 3.417327
[epoch14, step2926]: loss 1.261042
[epoch14, step2927]: loss 0.739349
[epoch14, step2928]: loss 2.445650
[epoch14, step2929]: loss 8.976054
[epoch14, step2930]: loss 0.637918
[epoch14, step2931]: loss 7.302690
[epoch14, step2932]: loss 6.875550
[epoch14, step2933]: loss 1.669254
[epoch14, step2934]: loss 7.234805
[epoch14, step2935]: loss 12.251816
[epoch14, step2936]: loss 1.598526
[epoch14, step2937]: loss 1.499059
[epoch14, step2938]: loss 2.349148
[epoch14, step2939]: loss 12.918532
[epoch14, step2940]: loss 3.269372
[epoch14, step2941]: loss 2.236922
[epoch14, step2942]: loss 0.645774
[epoch14, step2943]: loss 8.417996
[epoch14, step2944]: loss 0.473315
[epoch14, step2945]: loss 9.384732
[epoch14, step2946]: loss 3.944098
[epoch14, step2947]: loss 1.419824
[epoch14, step2948]: loss 0.717744
[epoch14, step2949]: loss 0.719149
[epoch14, step2950]: loss 1.184225
[epoch14, step2951]: loss 1.114276
[epoch14, step2952]: loss 3.063385
[epoch14, step2953]: loss 9.010135
[epoch14, step2954]: loss 1.449817
[epoch14, step2955]: loss 19.618685
[epoch14, step2956]: loss 1.259499
[epoch14, step2957]: loss 1.291169
[epoch14, step2958]: loss 0.868983
[epoch14, step2959]: loss 2.222051
[epoch14, step2960]: loss 0.923548
[epoch14, step2961]: loss 27.080469
[epoch14, step2962]: loss 2.608590
[epoch14, step2963]: loss 1.806103
[epoch14, step2964]: loss 1.676392
[epoch14, step2965]: loss 5.987394
[epoch14, step2966]: loss 4.161394
[epoch14, step2967]: loss 7.333337
[epoch14, step2968]: loss 1.164686
[epoch14, step2969]: loss 4.972577
[epoch14, step2970]: loss 7.312045
[epoch14, step2971]: loss 8.333832
[epoch14, step2972]: loss 2.634084
[epoch14, step2973]: loss 1.370276
[epoch14, step2974]: loss 2.230615
[epoch14, step2975]: loss 1.015785
[epoch14, step2976]: loss 6.518764
[epoch14, step2977]: loss 2.883667
[epoch14, step2978]: loss 15.440426
[epoch14, step2979]: loss 0.610744
[epoch14, step2980]: loss 2.110907
[epoch14, step2981]: loss 29.226379
[epoch14, step2982]: loss 14.468508
[epoch14, step2983]: loss 2.683134
[epoch14, step2984]: loss 2.058336
[epoch14, step2985]: loss 1.590143
[epoch14, step2986]: loss 1.271031
[epoch14, step2987]: loss 3.064083
[epoch14, step2988]: loss 0.705072
[epoch14, step2989]: loss 15.370891
[epoch14, step2990]: loss 7.581188
[epoch14, step2991]: loss 2.367951
[epoch14, step2992]: loss 1.068868
[epoch14, step2993]: loss 0.639876
[epoch14, step2994]: loss 1.029997
[epoch14, step2995]: loss 2.998363
[epoch14, step2996]: loss 15.149410
[epoch14, step2997]: loss 12.020267
[epoch14, step2998]: loss 6.912382
[epoch14, step2999]: loss 2.055658
[epoch14, step3000]: loss 0.902747
[epoch14, step3001]: loss 0.917520
[epoch14, step3002]: loss 0.503332
[epoch14, step3003]: loss 14.136425
[epoch14, step3004]: loss 1.242786
[epoch14, step3005]: loss 0.685311
[epoch14, step3006]: loss 7.299082
[epoch14, step3007]: loss 1.565731
[epoch14, step3008]: loss 16.159351
[epoch14, step3009]: loss 4.171900
[epoch14, step3010]: loss 1.038706
[epoch14, step3011]: loss 5.415190
[epoch14, step3012]: loss 9.729530
[epoch14, step3013]: loss 0.923970
[epoch14, step3014]: loss 0.953309
[epoch14, step3015]: loss 4.853428
[epoch14, step3016]: loss 6.585124
[epoch14, step3017]: loss 7.400933
[epoch14, step3018]: loss 9.154351
[epoch14, step3019]: loss 1.982634
[epoch14, step3020]: loss 2.874559
[epoch14, step3021]: loss 0.862908
[epoch14, step3022]: loss 2.538790
[epoch14, step3023]: loss 1.995013
[epoch14, step3024]: loss 3.059321
[epoch14, step3025]: loss 8.112985
[epoch14, step3026]: loss 0.904328
[epoch14, step3027]: loss 3.308096
[epoch14, step3028]: loss 0.799960
[epoch14, step3029]: loss 0.856299
[epoch14, step3030]: loss 0.674005
[epoch14, step3031]: loss 0.969421
[epoch14, step3032]: loss 14.338424
[epoch14, step3033]: loss 1.995165
[epoch14, step3034]: loss 6.857760
[epoch14, step3035]: loss 2.011093
[epoch14, step3036]: loss 0.752256
[epoch14, step3037]: loss 1.898969
[epoch14, step3038]: loss 1.282544
[epoch14, step3039]: loss 0.889324
[epoch14, step3040]: loss 10.727142
[epoch14, step3041]: loss 0.626836
[epoch14, step3042]: loss 8.162628
[epoch14, step3043]: loss 1.495729
[epoch14, step3044]: loss 1.220672
[epoch14, step3045]: loss 7.861923
[epoch14, step3046]: loss 7.883462
[epoch14, step3047]: loss 9.633947
[epoch14, step3048]: loss 2.415600
[epoch14, step3049]: loss 0.883115
[epoch14, step3050]: loss 13.783482
[epoch14, step3051]: loss 5.652166
[epoch14, step3052]: loss 4.609965
[epoch14, step3053]: loss 0.718459
[epoch14, step3054]: loss 6.042759
[epoch14, step3055]: loss 2.099647
[epoch14, step3056]: loss 0.672224
[epoch14, step3057]: loss 0.872774
[epoch14, step3058]: loss 2.302232
[epoch14, step3059]: loss 9.553958
[epoch14, step3060]: loss 3.715904
[epoch14, step3061]: loss 12.385871
[epoch14, step3062]: loss 3.045021
[epoch14, step3063]: loss 6.494119
[epoch14, step3064]: loss 8.341372
[epoch14, step3065]: loss 10.901980
[epoch14, step3066]: loss 5.692827
[epoch14, step3067]: loss 0.841218
[epoch14, step3068]: loss 2.260825
[epoch14, step3069]: loss 0.805789
[epoch14, step3070]: loss 5.244451
[epoch14, step3071]: loss 4.579616
[epoch14, step3072]: loss 2.538370
[epoch14, step3073]: loss 5.174258
[epoch14, step3074]: loss 13.514616
[epoch14, step3075]: loss 10.366781
[epoch14, step3076]: loss 0.823129

[epoch14]: avg loss 0.823129

[epoch15, step1]: loss 4.925917
[epoch15, step2]: loss 9.816125
[epoch15, step3]: loss 3.653946
[epoch15, step4]: loss 1.431694
[epoch15, step5]: loss 1.333418
[epoch15, step6]: loss 1.826910
[epoch15, step7]: loss 2.371276
[epoch15, step8]: loss 6.589747
[epoch15, step9]: loss 7.718323
[epoch15, step10]: loss 14.271605
[epoch15, step11]: loss 7.616308
[epoch15, step12]: loss 11.147388
[epoch15, step13]: loss 9.804997
[epoch15, step14]: loss 5.551813
[epoch15, step15]: loss 8.827547
[epoch15, step16]: loss 1.110100
[epoch15, step17]: loss 0.826040
[epoch15, step18]: loss 0.888185
[epoch15, step19]: loss 0.965424
[epoch15, step20]: loss 1.879750
[epoch15, step21]: loss 8.168947
[epoch15, step22]: loss 1.011258
[epoch15, step23]: loss 1.243133
[epoch15, step24]: loss 1.877539
[epoch15, step25]: loss 1.242643
[epoch15, step26]: loss 14.299205
[epoch15, step27]: loss 2.246258
[epoch15, step28]: loss 1.246833
[epoch15, step29]: loss 2.729116
[epoch15, step30]: loss 1.000239
[epoch15, step31]: loss 0.672431
[epoch15, step32]: loss 1.055608
[epoch15, step33]: loss 3.205690
[epoch15, step34]: loss 10.166751
[epoch15, step35]: loss 1.150169
[epoch15, step36]: loss 6.862340
[epoch15, step37]: loss 7.703206
[epoch15, step38]: loss 3.045848
[epoch15, step39]: loss 0.698461
[epoch15, step40]: loss 8.191804
[epoch15, step41]: loss 1.012730
[epoch15, step42]: loss 1.440688
[epoch15, step43]: loss 0.983943
[epoch15, step44]: loss 0.944852
[epoch15, step45]: loss 2.788894
[epoch15, step46]: loss 6.520478
[epoch15, step47]: loss 7.949237
[epoch15, step48]: loss 7.574682
[epoch15, step49]: loss 1.513269
[epoch15, step50]: loss 1.475352
[epoch15, step51]: loss 7.157338
[epoch15, step52]: loss 0.656242
[epoch15, step53]: loss 6.929503
[epoch15, step54]: loss 1.165564
[epoch15, step55]: loss 5.010932
[epoch15, step56]: loss 13.261889
[epoch15, step57]: loss 3.453351
[epoch15, step58]: loss 1.505667
[epoch15, step59]: loss 7.513176
[epoch15, step60]: loss 0.775720
[epoch15, step61]: loss 9.214613
[epoch15, step62]: loss 0.947061
[epoch15, step63]: loss 1.813321
[epoch15, step64]: loss 0.603274
[epoch15, step65]: loss 7.476972
[epoch15, step66]: loss 1.836141
[epoch15, step67]: loss 1.003715
[epoch15, step68]: loss 0.854369
[epoch15, step69]: loss 12.882711
[epoch15, step70]: loss 0.587092
[epoch15, step71]: loss 4.823192
[epoch15, step72]: loss 4.913302
[epoch15, step73]: loss 9.534361
[epoch15, step74]: loss 1.735041
[epoch15, step75]: loss 17.290091
[epoch15, step76]: loss 0.830969
[epoch15, step77]: loss 6.305331
[epoch15, step78]: loss 2.087179
[epoch15, step79]: loss 2.906336
[epoch15, step80]: loss 0.820748
[epoch15, step81]: loss 14.490641
[epoch15, step82]: loss 2.881247
[epoch15, step83]: loss 2.352896
[epoch15, step84]: loss 7.988949
[epoch15, step85]: loss 8.243959
[epoch15, step86]: loss 13.743680
[epoch15, step87]: loss 19.333494
[epoch15, step88]: loss 0.790320
[epoch15, step89]: loss 3.672640
[epoch15, step90]: loss 0.675571
[epoch15, step91]: loss 1.808350
[epoch15, step92]: loss 3.305964
[epoch15, step93]: loss 0.738622
[epoch15, step94]: loss 2.686493
[epoch15, step95]: loss 2.467488
[epoch15, step96]: loss 2.315313
[epoch15, step97]: loss 1.078382
[epoch15, step98]: loss 1.922389
[epoch15, step99]: loss 2.560274
[epoch15, step100]: loss 8.610832
[epoch15, step101]: loss 2.101570
[epoch15, step102]: loss 0.600174
[epoch15, step103]: loss 0.975865
[epoch15, step104]: loss 1.062758
[epoch15, step105]: loss 0.644669
[epoch15, step106]: loss 2.942511
[epoch15, step107]: loss 1.637109
[epoch15, step108]: loss 3.695267
[epoch15, step109]: loss 4.865780
[epoch15, step110]: loss 3.049307
[epoch15, step111]: loss 1.522051
[epoch15, step112]: loss 2.509891
[epoch15, step113]: loss 2.765670
[epoch15, step114]: loss 6.654751
[epoch15, step115]: loss 2.973017
[epoch15, step116]: loss 0.939796
[epoch15, step117]: loss 6.977142
[epoch15, step118]: loss 15.409745
[epoch15, step119]: loss 2.754436
[epoch15, step120]: loss 2.631904
[epoch15, step121]: loss 6.476768
[epoch15, step122]: loss 0.676336
[epoch15, step123]: loss 4.813372
[epoch15, step124]: loss 1.432881
[epoch15, step125]: loss 2.347686
[epoch15, step126]: loss 1.820279
[epoch15, step127]: loss 1.384928
[epoch15, step128]: loss 1.658020
[epoch15, step129]: loss 1.109194
[epoch15, step130]: loss 2.643462
[epoch15, step131]: loss 2.782453
[epoch15, step132]: loss 0.749126
[epoch15, step133]: loss 2.292594
[epoch15, step134]: loss 1.769541
[epoch15, step135]: loss 8.635030
[epoch15, step136]: loss 0.853806
[epoch15, step137]: loss 1.598366
[epoch15, step138]: loss 7.847859
[epoch15, step139]: loss 5.017990
[epoch15, step140]: loss 1.584085
[epoch15, step141]: loss 2.396314
[epoch15, step142]: loss 1.399987
[epoch15, step143]: loss 0.746068
[epoch15, step144]: loss 2.695047
[epoch15, step145]: loss 6.486710
[epoch15, step146]: loss 1.805109
[epoch15, step147]: loss 1.648152
[epoch15, step148]: loss 3.060685
[epoch15, step149]: loss 1.155633
[epoch15, step150]: loss 3.953672
[epoch15, step151]: loss 2.679457
[epoch15, step152]: loss 11.987422
[epoch15, step153]: loss 8.657207
[epoch15, step154]: loss 0.998536
[epoch15, step155]: loss 1.833804
[epoch15, step156]: loss 1.462857
[epoch15, step157]: loss 2.400399
[epoch15, step158]: loss 11.707745
[epoch15, step159]: loss 2.222289
[epoch15, step160]: loss 10.301190
[epoch15, step161]: loss 2.919481
[epoch15, step162]: loss 0.979195
[epoch15, step163]: loss 9.387677
[epoch15, step164]: loss 1.311408
[epoch15, step165]: loss 8.308542
[epoch15, step166]: loss 2.419158
[epoch15, step167]: loss 1.688434
[epoch15, step168]: loss 0.919725
[epoch15, step169]: loss 11.381585
[epoch15, step170]: loss 0.774511
[epoch15, step171]: loss 2.124579
[epoch15, step172]: loss 1.839397
[epoch15, step173]: loss 18.190971
[epoch15, step174]: loss 1.698753
[epoch15, step175]: loss 1.039856
[epoch15, step176]: loss 9.377427
[epoch15, step177]: loss 2.464700
[epoch15, step178]: loss 1.593713
[epoch15, step179]: loss 7.355097
[epoch15, step180]: loss 4.066638
[epoch15, step181]: loss 1.063675
[epoch15, step182]: loss 2.256844
[epoch15, step183]: loss 10.026486
[epoch15, step184]: loss 2.691589
[epoch15, step185]: loss 3.815775
[epoch15, step186]: loss 2.874771
[epoch15, step187]: loss 4.588188
[epoch15, step188]: loss 6.030200
[epoch15, step189]: loss 4.126937
[epoch15, step190]: loss 3.561655
[epoch15, step191]: loss 14.798883
[epoch15, step192]: loss 10.549836
[epoch15, step193]: loss 9.481548
[epoch15, step194]: loss 9.250366
[epoch15, step195]: loss 17.887638
[epoch15, step196]: loss 7.669395
[epoch15, step197]: loss 11.238102
[epoch15, step198]: loss 1.499746
[epoch15, step199]: loss 20.724895
[epoch15, step200]: loss 0.836418
[epoch15, step201]: loss 10.392239
[epoch15, step202]: loss 0.907257
[epoch15, step203]: loss 8.892811
[epoch15, step204]: loss 1.047306
[epoch15, step205]: loss 1.850255
[epoch15, step206]: loss 0.644642
[epoch15, step207]: loss 10.000937
[epoch15, step208]: loss 10.617558
[epoch15, step209]: loss 12.611914
[epoch15, step210]: loss 0.804222
[epoch15, step211]: loss 1.527992
[epoch15, step212]: loss 1.121239
[epoch15, step213]: loss 8.032587
[epoch15, step214]: loss 13.293521
[epoch15, step215]: loss 3.702988
[epoch15, step216]: loss 0.838494
[epoch15, step217]: loss 6.168622
[epoch15, step218]: loss 8.597912
[epoch15, step219]: loss 2.545140
[epoch15, step220]: loss 0.887469
[epoch15, step221]: loss 2.326981
[epoch15, step222]: loss 2.963375
[epoch15, step223]: loss 0.798282
[epoch15, step224]: loss 1.034711
[epoch15, step225]: loss 7.415773
[epoch15, step226]: loss 1.313757
[epoch15, step227]: loss 0.888879
[epoch15, step228]: loss 1.050924
[epoch15, step229]: loss 1.536540
[epoch15, step230]: loss 0.671590
[epoch15, step231]: loss 1.036127
[epoch15, step232]: loss 2.421225
[epoch15, step233]: loss 24.865088
[epoch15, step234]: loss 2.574785
[epoch15, step235]: loss 0.806774
[epoch15, step236]: loss 2.466041
[epoch15, step237]: loss 3.469910
[epoch15, step238]: loss 5.570158
[epoch15, step239]: loss 5.922285
[epoch15, step240]: loss 0.996099
[epoch15, step241]: loss 0.973548
[epoch15, step242]: loss 11.649686
[epoch15, step243]: loss 1.008805
[epoch15, step244]: loss 1.294975
[epoch15, step245]: loss 6.616159
[epoch15, step246]: loss 6.979454
[epoch15, step247]: loss 2.732851
[epoch15, step248]: loss 0.816779
[epoch15, step249]: loss 11.663945
[epoch15, step250]: loss 1.774714
[epoch15, step251]: loss 1.011135
[epoch15, step252]: loss 9.240805
[epoch15, step253]: loss 6.886693
[epoch15, step254]: loss 1.309268
[epoch15, step255]: loss 7.210819
[epoch15, step256]: loss 0.743924
[epoch15, step257]: loss 13.992676
[epoch15, step258]: loss 3.823124
[epoch15, step259]: loss 7.630464
[epoch15, step260]: loss 2.999454
[epoch15, step261]: loss 1.547886
[epoch15, step262]: loss 1.167590
[epoch15, step263]: loss 6.924864
[epoch15, step264]: loss 0.739519
[epoch15, step265]: loss 1.248489
[epoch15, step266]: loss 3.687238
[epoch15, step267]: loss 0.779361
[epoch15, step268]: loss 3.515875
[epoch15, step269]: loss 12.380241
[epoch15, step270]: loss 0.943163
[epoch15, step271]: loss 4.101927
[epoch15, step272]: loss 2.241280
[epoch15, step273]: loss 1.105062
[epoch15, step274]: loss 6.895560
[epoch15, step275]: loss 2.827098
[epoch15, step276]: loss 5.614519
[epoch15, step277]: loss 2.930712
[epoch15, step278]: loss 0.782200
[epoch15, step279]: loss 1.217585
[epoch15, step280]: loss 8.384706
[epoch15, step281]: loss 9.049069
[epoch15, step282]: loss 0.725298
[epoch15, step283]: loss 0.651739
[epoch15, step284]: loss 0.983010
[epoch15, step285]: loss 9.589436
[epoch15, step286]: loss 3.960000
[epoch15, step287]: loss 1.051978
[epoch15, step288]: loss 10.443501
[epoch15, step289]: loss 0.808928
[epoch15, step290]: loss 12.676504
[epoch15, step291]: loss 8.480839
[epoch15, step292]: loss 9.436258
[epoch15, step293]: loss 2.464704
[epoch15, step294]: loss 0.944139
[epoch15, step295]: loss 13.141500
[epoch15, step296]: loss 7.269250
[epoch15, step297]: loss 0.964943
[epoch15, step298]: loss 2.139101
[epoch15, step299]: loss 1.903871
[epoch15, step300]: loss 10.718019
[epoch15, step301]: loss 0.739519
[epoch15, step302]: loss 0.752893
[epoch15, step303]: loss 1.556951
[epoch15, step304]: loss 13.577041
[epoch15, step305]: loss 1.161227
[epoch15, step306]: loss 7.589578
[epoch15, step307]: loss 3.598571
[epoch15, step308]: loss 1.271913
[epoch15, step309]: loss 1.639255
[epoch15, step310]: loss 1.170431
[epoch15, step311]: loss 18.243874
[epoch15, step312]: loss 9.151343
[epoch15, step313]: loss 5.770647
[epoch15, step314]: loss 10.789351
[epoch15, step315]: loss 1.369921
[epoch15, step316]: loss 0.783770
[epoch15, step317]: loss 7.246333
[epoch15, step318]: loss 0.993735
[epoch15, step319]: loss 0.833139
[epoch15, step320]: loss 4.192271
[epoch15, step321]: loss 5.794997
[epoch15, step322]: loss 6.343249
[epoch15, step323]: loss 0.799139
[epoch15, step324]: loss 1.450672
[epoch15, step325]: loss 1.342907
[epoch15, step326]: loss 2.288463
[epoch15, step327]: loss 4.195887
[epoch15, step328]: loss 2.120325
[epoch15, step329]: loss 10.840257
[epoch15, step330]: loss 0.763344
[epoch15, step331]: loss 2.273693
[epoch15, step332]: loss 1.020285
[epoch15, step333]: loss 6.994372
[epoch15, step334]: loss 0.589490
[epoch15, step335]: loss 11.412352
[epoch15, step336]: loss 1.268286
[epoch15, step337]: loss 0.714184
[epoch15, step338]: loss 5.955423
[epoch15, step339]: loss 0.757579
[epoch15, step340]: loss 2.805917
[epoch15, step341]: loss 6.712393
[epoch15, step342]: loss 2.163014
[epoch15, step343]: loss 3.000800
[epoch15, step344]: loss 1.529296
[epoch15, step345]: loss 0.867338
[epoch15, step346]: loss 7.041171
[epoch15, step347]: loss 1.110972
[epoch15, step348]: loss 1.112838
[epoch15, step349]: loss 3.646506
[epoch15, step350]: loss 6.418159
[epoch15, step351]: loss 0.906629
[epoch15, step352]: loss 1.656349
[epoch15, step353]: loss 4.559221
[epoch15, step354]: loss 1.059744
[epoch15, step355]: loss 7.451719
[epoch15, step356]: loss 10.259567
[epoch15, step357]: loss 8.813013
[epoch15, step358]: loss 1.648627
[epoch15, step359]: loss 3.693884
[epoch15, step360]: loss 3.196325
[epoch15, step361]: loss 1.316676
[epoch15, step362]: loss 7.797966
[epoch15, step363]: loss 16.092426
[epoch15, step364]: loss 1.119705
[epoch15, step365]: loss 4.145309
[epoch15, step366]: loss 0.794090
[epoch15, step367]: loss 8.823462
[epoch15, step368]: loss 5.350218
[epoch15, step369]: loss 1.790187
[epoch15, step370]: loss 10.155172
[epoch15, step371]: loss 9.309065
[epoch15, step372]: loss 15.587273
[epoch15, step373]: loss 5.882861
[epoch15, step374]: loss 1.657011
[epoch15, step375]: loss 12.945796
[epoch15, step376]: loss 6.570185
[epoch15, step377]: loss 1.080101
[epoch15, step378]: loss 1.280133
[epoch15, step379]: loss 0.887540
[epoch15, step380]: loss 3.433499
[epoch15, step381]: loss 0.925611
[epoch15, step382]: loss 1.070414
[epoch15, step383]: loss 3.175870
[epoch15, step384]: loss 0.796717
[epoch15, step385]: loss 0.762721
[epoch15, step386]: loss 1.370252
[epoch15, step387]: loss 15.258076
[epoch15, step388]: loss 16.340986
[epoch15, step389]: loss 2.705050
[epoch15, step390]: loss 9.578296
[epoch15, step391]: loss 0.551112
[epoch15, step392]: loss 3.392235
[epoch15, step393]: loss 1.341409
[epoch15, step394]: loss 1.937506
[epoch15, step395]: loss 5.454980
[epoch15, step396]: loss 1.213716
[epoch15, step397]: loss 1.093350
[epoch15, step398]: loss 4.527439
[epoch15, step399]: loss 0.926322
[epoch15, step400]: loss 0.996726
[epoch15, step401]: loss 7.427489
[epoch15, step402]: loss 10.083477
[epoch15, step403]: loss 8.558332
[epoch15, step404]: loss 2.421693
[epoch15, step405]: loss 1.435671
[epoch15, step406]: loss 2.711769
[epoch15, step407]: loss 7.793268
[epoch15, step408]: loss 4.954857
[epoch15, step409]: loss 2.244323
[epoch15, step410]: loss 0.637788
[epoch15, step411]: loss 3.976851
[epoch15, step412]: loss 13.187046
[epoch15, step413]: loss 15.485790
[epoch15, step414]: loss 2.551954
[epoch15, step415]: loss 0.946362
[epoch15, step416]: loss 7.765506
[epoch15, step417]: loss 12.648657
[epoch15, step418]: loss 7.058688
[epoch15, step419]: loss 1.399953
[epoch15, step420]: loss 0.872842
[epoch15, step421]: loss 7.664773
[epoch15, step422]: loss 0.675427
[epoch15, step423]: loss 11.341630
[epoch15, step424]: loss 1.490346
[epoch15, step425]: loss 1.913351
[epoch15, step426]: loss 0.603723
[epoch15, step427]: loss 13.400175
[epoch15, step428]: loss 1.660958
[epoch15, step429]: loss 8.267139
[epoch15, step430]: loss 1.528902
[epoch15, step431]: loss 14.520282
[epoch15, step432]: loss 4.228048
[epoch15, step433]: loss 2.344401
[epoch15, step434]: loss 3.021608
[epoch15, step435]: loss 2.061481
[epoch15, step436]: loss 4.835689
[epoch15, step437]: loss 2.108872
[epoch15, step438]: loss 14.236892
[epoch15, step439]: loss 5.712368
[epoch15, step440]: loss 2.046749
[epoch15, step441]: loss 1.480082
[epoch15, step442]: loss 0.563154
[epoch15, step443]: loss 7.443974
[epoch15, step444]: loss 6.932057
[epoch15, step445]: loss 17.934837
[epoch15, step446]: loss 0.669695
[epoch15, step447]: loss 10.753928
[epoch15, step448]: loss 0.476220
[epoch15, step449]: loss 1.115595
[epoch15, step450]: loss 1.373837
[epoch15, step451]: loss 7.903223
[epoch15, step452]: loss 1.600423
[epoch15, step453]: loss 6.949884
[epoch15, step454]: loss 1.257434
[epoch15, step455]: loss 6.813102
[epoch15, step456]: loss 0.709627
[epoch15, step457]: loss 1.046828
[epoch15, step458]: loss 2.662398
[epoch15, step459]: loss 2.292415
[epoch15, step460]: loss 16.328945
[epoch15, step461]: loss 1.231779
[epoch15, step462]: loss 2.399451
[epoch15, step463]: loss 3.020080
[epoch15, step464]: loss 2.771989
[epoch15, step465]: loss 0.879264
[epoch15, step466]: loss 0.871769
[epoch15, step467]: loss 1.248398
[epoch15, step468]: loss 8.418254
[epoch15, step469]: loss 6.930699
[epoch15, step470]: loss 3.530997
[epoch15, step471]: loss 2.905132
[epoch15, step472]: loss 2.259242
[epoch15, step473]: loss 4.112597
[epoch15, step474]: loss 8.548180
[epoch15, step475]: loss 6.517547
[epoch15, step476]: loss 6.752209
[epoch15, step477]: loss 7.906214
[epoch15, step478]: loss 3.126863
[epoch15, step479]: loss 5.250813
[epoch15, step480]: loss 2.111145
[epoch15, step481]: loss 10.969883
[epoch15, step482]: loss 1.820713
[epoch15, step483]: loss 2.928593
[epoch15, step484]: loss 0.973151
[epoch15, step485]: loss 11.979512
[epoch15, step486]: loss 10.954414
[epoch15, step487]: loss 3.225612
[epoch15, step488]: loss 1.620717
[epoch15, step489]: loss 2.927370
[epoch15, step490]: loss 0.650844
[epoch15, step491]: loss 0.919157
[epoch15, step492]: loss 9.987715
[epoch15, step493]: loss 1.150847
[epoch15, step494]: loss 23.380407
[epoch15, step495]: loss 2.280867
[epoch15, step496]: loss 1.812003
[epoch15, step497]: loss 1.286322
[epoch15, step498]: loss 8.734712
[epoch15, step499]: loss 1.067990
[epoch15, step500]: loss 0.947289
[epoch15, step501]: loss 12.059103
[epoch15, step502]: loss 0.732578
[epoch15, step503]: loss 1.210944
[epoch15, step504]: loss 0.638922
[epoch15, step505]: loss 0.768693
[epoch15, step506]: loss 1.640182
[epoch15, step507]: loss 7.395473
[epoch15, step508]: loss 12.238271
[epoch15, step509]: loss 8.837152
[epoch15, step510]: loss 2.748522
[epoch15, step511]: loss 0.960516
[epoch15, step512]: loss 1.068734
[epoch15, step513]: loss 1.771475
[epoch15, step514]: loss 0.801547
[epoch15, step515]: loss 0.987424
[epoch15, step516]: loss 0.857978
[epoch15, step517]: loss 1.080041
[epoch15, step518]: loss 1.443167
[epoch15, step519]: loss 1.571237
[epoch15, step520]: loss 21.420015
[epoch15, step521]: loss 0.937957
[epoch15, step522]: loss 3.399076
[epoch15, step523]: loss 1.250924
[epoch15, step524]: loss 5.257524
[epoch15, step525]: loss 0.844108
[epoch15, step526]: loss 0.743376
[epoch15, step527]: loss 5.813648
[epoch15, step528]: loss 1.767325
[epoch15, step529]: loss 1.573354
[epoch15, step530]: loss 1.056468
[epoch15, step531]: loss 3.723706
[epoch15, step532]: loss 2.522415
[epoch15, step533]: loss 8.417002
[epoch15, step534]: loss 11.362283
[epoch15, step535]: loss 0.946321
[epoch15, step536]: loss 2.641673
[epoch15, step537]: loss 2.467692
[epoch15, step538]: loss 0.947242
[epoch15, step539]: loss 11.262260
[epoch15, step540]: loss 3.584106
[epoch15, step541]: loss 1.222491
[epoch15, step542]: loss 10.218257
[epoch15, step543]: loss 1.507517
[epoch15, step544]: loss 1.186248
[epoch15, step545]: loss 8.319344
[epoch15, step546]: loss 6.228961
[epoch15, step547]: loss 2.035167
[epoch15, step548]: loss 1.659493
[epoch15, step549]: loss 0.893088
[epoch15, step550]: loss 5.303744
[epoch15, step551]: loss 18.579363
[epoch15, step552]: loss 8.149479
[epoch15, step553]: loss 1.624878
[epoch15, step554]: loss 1.377213
[epoch15, step555]: loss 1.144357
[epoch15, step556]: loss 0.747967
[epoch15, step557]: loss 0.973884
[epoch15, step558]: loss 2.102010
[epoch15, step559]: loss 7.628384
[epoch15, step560]: loss 0.929352
[epoch15, step561]: loss 10.440502
[epoch15, step562]: loss 3.322490
[epoch15, step563]: loss 3.875821
[epoch15, step564]: loss 7.787028
[epoch15, step565]: loss 1.582545
[epoch15, step566]: loss 9.046833
[epoch15, step567]: loss 9.619669
[epoch15, step568]: loss 6.817194
[epoch15, step569]: loss 7.655389
[epoch15, step570]: loss 0.996934
[epoch15, step571]: loss 1.107672
[epoch15, step572]: loss 8.293170
[epoch15, step573]: loss 1.534508
[epoch15, step574]: loss 13.191793
[epoch15, step575]: loss 1.255467
[epoch15, step576]: loss 1.281253
[epoch15, step577]: loss 1.944181
[epoch15, step578]: loss 4.087288
[epoch15, step579]: loss 4.158829
[epoch15, step580]: loss 8.777618
[epoch15, step581]: loss 2.144442
[epoch15, step582]: loss 0.554745
[epoch15, step583]: loss 1.456304
[epoch15, step584]: loss 0.840206
[epoch15, step585]: loss 1.070678
[epoch15, step586]: loss 7.871255
[epoch15, step587]: loss 5.143335
[epoch15, step588]: loss 1.912151
[epoch15, step589]: loss 2.061739
[epoch15, step590]: loss 2.471103
[epoch15, step591]: loss 1.223573
[epoch15, step592]: loss 0.826563
[epoch15, step593]: loss 5.633361
[epoch15, step594]: loss 6.634761
[epoch15, step595]: loss 2.444745
[epoch15, step596]: loss 1.206965
[epoch15, step597]: loss 9.598273
[epoch15, step598]: loss 1.617116
[epoch15, step599]: loss 8.782782
[epoch15, step600]: loss 2.043221
[epoch15, step601]: loss 10.898687
[epoch15, step602]: loss 5.407736
[epoch15, step603]: loss 11.673496
[epoch15, step604]: loss 16.790949
[epoch15, step605]: loss 9.904776
[epoch15, step606]: loss 0.675929
[epoch15, step607]: loss 5.503694
[epoch15, step608]: loss 0.754748
[epoch15, step609]: loss 3.055924
[epoch15, step610]: loss 7.737179
[epoch15, step611]: loss 1.040758
[epoch15, step612]: loss 0.911654
[epoch15, step613]: loss 1.531997
[epoch15, step614]: loss 4.866734
[epoch15, step615]: loss 3.385209
[epoch15, step616]: loss 4.195150
[epoch15, step617]: loss 6.625954
[epoch15, step618]: loss 1.114841
[epoch15, step619]: loss 1.293273
[epoch15, step620]: loss 13.276974
[epoch15, step621]: loss 8.847928
[epoch15, step622]: loss 1.458310
[epoch15, step623]: loss 1.602857
[epoch15, step624]: loss 15.268595
[epoch15, step625]: loss 10.009834
[epoch15, step626]: loss 2.371456
[epoch15, step627]: loss 1.585407
[epoch15, step628]: loss 2.641296
[epoch15, step629]: loss 2.776087
[epoch15, step630]: loss 0.519224
[epoch15, step631]: loss 1.670597
[epoch15, step632]: loss 7.533417
[epoch15, step633]: loss 1.288954
[epoch15, step634]: loss 1.015001
[epoch15, step635]: loss 1.892721
[epoch15, step636]: loss 3.391884
[epoch15, step637]: loss 2.692001
[epoch15, step638]: loss 2.373663
[epoch15, step639]: loss 1.191508
[epoch15, step640]: loss 3.715323
[epoch15, step641]: loss 0.507519
[epoch15, step642]: loss 1.557677
[epoch15, step643]: loss 1.265082
[epoch15, step644]: loss 0.949437
[epoch15, step645]: loss 0.749891
[epoch15, step646]: loss 9.377967
[epoch15, step647]: loss 2.066143
[epoch15, step648]: loss 0.999023
[epoch15, step649]: loss 3.328507
[epoch15, step650]: loss 2.034299
[epoch15, step651]: loss 0.719293
[epoch15, step652]: loss 8.436887
[epoch15, step653]: loss 7.302504
[epoch15, step654]: loss 2.777063
[epoch15, step655]: loss 3.456271
[epoch15, step656]: loss 2.201794
[epoch15, step657]: loss 1.223026
[epoch15, step658]: loss 1.405125
[epoch15, step659]: loss 10.302270
[epoch15, step660]: loss 0.877431
[epoch15, step661]: loss 1.382607
[epoch15, step662]: loss 1.118536
[epoch15, step663]: loss 0.600096
[epoch15, step664]: loss 9.746718
[epoch15, step665]: loss 0.802337
[epoch15, step666]: loss 0.535495
[epoch15, step667]: loss 2.674108
[epoch15, step668]: loss 1.806974
[epoch15, step669]: loss 7.535455
[epoch15, step670]: loss 1.380741
[epoch15, step671]: loss 2.182314
[epoch15, step672]: loss 0.815230
[epoch15, step673]: loss 7.952363
[epoch15, step674]: loss 0.706661
[epoch15, step675]: loss 1.285103
[epoch15, step676]: loss 16.119658
[epoch15, step677]: loss 2.205179
[epoch15, step678]: loss 7.874261
[epoch15, step679]: loss 1.656543
[epoch15, step680]: loss 2.566450
[epoch15, step681]: loss 1.313279
[epoch15, step682]: loss 7.601386
[epoch15, step683]: loss 1.299724
[epoch15, step684]: loss 0.865436
[epoch15, step685]: loss 14.834341
[epoch15, step686]: loss 17.536905
[epoch15, step687]: loss 2.361391
[epoch15, step688]: loss 8.644587
[epoch15, step689]: loss 4.718121
[epoch15, step690]: loss 7.220391
[epoch15, step691]: loss 1.022052
[epoch15, step692]: loss 1.878011
[epoch15, step693]: loss 1.276672
[epoch15, step694]: loss 1.186635
[epoch15, step695]: loss 1.571934
[epoch15, step696]: loss 1.041099
[epoch15, step697]: loss 17.019587
[epoch15, step698]: loss 1.929585
[epoch15, step699]: loss 2.281658
[epoch15, step700]: loss 0.760314
[epoch15, step701]: loss 4.734524
[epoch15, step702]: loss 1.824419
[epoch15, step703]: loss 7.567500
[epoch15, step704]: loss 7.899963
[epoch15, step705]: loss 8.052296
[epoch15, step706]: loss 1.257859
[epoch15, step707]: loss 8.179243
[epoch15, step708]: loss 4.542731
[epoch15, step709]: loss 11.945003
[epoch15, step710]: loss 2.509038
[epoch15, step711]: loss 11.593390
[epoch15, step712]: loss 0.747194
[epoch15, step713]: loss 0.820776
[epoch15, step714]: loss 7.815044
[epoch15, step715]: loss 0.706812
[epoch15, step716]: loss 0.678393
[epoch15, step717]: loss 0.782220
[epoch15, step718]: loss 0.960777
[epoch15, step719]: loss 2.827516
[epoch15, step720]: loss 2.632690
[epoch15, step721]: loss 8.948316
[epoch15, step722]: loss 12.976125
[epoch15, step723]: loss 0.551698
[epoch15, step724]: loss 9.539054
[epoch15, step725]: loss 2.890458
[epoch15, step726]: loss 1.232285
[epoch15, step727]: loss 3.200083
[epoch15, step728]: loss 8.279359
[epoch15, step729]: loss 2.549728
[epoch15, step730]: loss 11.288319
[epoch15, step731]: loss 0.766250
[epoch15, step732]: loss 12.563794
[epoch15, step733]: loss 6.606771
[epoch15, step734]: loss 0.915068
[epoch15, step735]: loss 1.471959
[epoch15, step736]: loss 1.372149
[epoch15, step737]: loss 1.134052
[epoch15, step738]: loss 2.124649
[epoch15, step739]: loss 13.165155
[epoch15, step740]: loss 16.317638
[epoch15, step741]: loss 1.103561
[epoch15, step742]: loss 0.680313
[epoch15, step743]: loss 4.049358
[epoch15, step744]: loss 0.883424
[epoch15, step745]: loss 0.864210
[epoch15, step746]: loss 1.311122
[epoch15, step747]: loss 0.678169
[epoch15, step748]: loss 8.356309
[epoch15, step749]: loss 11.228839
[epoch15, step750]: loss 0.896868
[epoch15, step751]: loss 1.166818
[epoch15, step752]: loss 7.772141
[epoch15, step753]: loss 1.029665
[epoch15, step754]: loss 1.930392
[epoch15, step755]: loss 1.262128
[epoch15, step756]: loss 0.973062
[epoch15, step757]: loss 2.396980
[epoch15, step758]: loss 0.991540
[epoch15, step759]: loss 0.533291
[epoch15, step760]: loss 7.302956
[epoch15, step761]: loss 0.682214
[epoch15, step762]: loss 2.688447
[epoch15, step763]: loss 3.850491
[epoch15, step764]: loss 1.028177
[epoch15, step765]: loss 4.480815
[epoch15, step766]: loss 1.384352
[epoch15, step767]: loss 1.036866
[epoch15, step768]: loss 1.279594
[epoch15, step769]: loss 0.714567
[epoch15, step770]: loss 1.119003
[epoch15, step771]: loss 15.637470
[epoch15, step772]: loss 2.154753
[epoch15, step773]: loss 1.217839
[epoch15, step774]: loss 10.619455
[epoch15, step775]: loss 2.577164
[epoch15, step776]: loss 1.520416
[epoch15, step777]: loss 2.260445
[epoch15, step778]: loss 0.853355
[epoch15, step779]: loss 6.850594
[epoch15, step780]: loss 1.522546
[epoch15, step781]: loss 9.897572
[epoch15, step782]: loss 10.601121
[epoch15, step783]: loss 0.914333
[epoch15, step784]: loss 0.739772
[epoch15, step785]: loss 12.985805
[epoch15, step786]: loss 1.165539
[epoch15, step787]: loss 9.060592
[epoch15, step788]: loss 0.523486
[epoch15, step789]: loss 9.548605
[epoch15, step790]: loss 4.659063
[epoch15, step791]: loss 1.108227
[epoch15, step792]: loss 3.220948
[epoch15, step793]: loss 0.827711
[epoch15, step794]: loss 1.501473
[epoch15, step795]: loss 0.808323
[epoch15, step796]: loss 0.662559
[epoch15, step797]: loss 9.795913
[epoch15, step798]: loss 1.550953
[epoch15, step799]: loss 7.015414
[epoch15, step800]: loss 2.528465
[epoch15, step801]: loss 5.337815
[epoch15, step802]: loss 1.496696
[epoch15, step803]: loss 0.958144
[epoch15, step804]: loss 9.649752
[epoch15, step805]: loss 0.770627
[epoch15, step806]: loss 6.504617
[epoch15, step807]: loss 2.026466
[epoch15, step808]: loss 0.934958
[epoch15, step809]: loss 2.203196
[epoch15, step810]: loss 4.471894
[epoch15, step811]: loss 1.675489
[epoch15, step812]: loss 0.521382
[epoch15, step813]: loss 7.456038
[epoch15, step814]: loss 0.952352
[epoch15, step815]: loss 1.197580
[epoch15, step816]: loss 7.789945
[epoch15, step817]: loss 1.028113
[epoch15, step818]: loss 10.880116
[epoch15, step819]: loss 1.631016
[epoch15, step820]: loss 2.012919
[epoch15, step821]: loss 1.662049
[epoch15, step822]: loss 1.919929
[epoch15, step823]: loss 2.951830
[epoch15, step824]: loss 9.221205
[epoch15, step825]: loss 18.664951
[epoch15, step826]: loss 1.288361
[epoch15, step827]: loss 3.253355
[epoch15, step828]: loss 2.853639
[epoch15, step829]: loss 1.707381
[epoch15, step830]: loss 1.496178
[epoch15, step831]: loss 10.400311
[epoch15, step832]: loss 5.749113
[epoch15, step833]: loss 2.722677
[epoch15, step834]: loss 0.759847
[epoch15, step835]: loss 1.166217
[epoch15, step836]: loss 0.731486
[epoch15, step837]: loss 6.522370
[epoch15, step838]: loss 1.475027
[epoch15, step839]: loss 15.724846
[epoch15, step840]: loss 17.428530
[epoch15, step841]: loss 0.842970
[epoch15, step842]: loss 3.033383
[epoch15, step843]: loss 0.981959
[epoch15, step844]: loss 3.215190
[epoch15, step845]: loss 2.429145
[epoch15, step846]: loss 4.541153
[epoch15, step847]: loss 1.103685
[epoch15, step848]: loss 2.481097
[epoch15, step849]: loss 0.588789
[epoch15, step850]: loss 2.470636
[epoch15, step851]: loss 0.703997
[epoch15, step852]: loss 1.262059
[epoch15, step853]: loss 1.510800
[epoch15, step854]: loss 4.408212
[epoch15, step855]: loss 9.897164
[epoch15, step856]: loss 0.795738
[epoch15, step857]: loss 2.018209
[epoch15, step858]: loss 1.387184
[epoch15, step859]: loss 1.300794
[epoch15, step860]: loss 2.260903
[epoch15, step861]: loss 2.711230
[epoch15, step862]: loss 6.654348
[epoch15, step863]: loss 0.939709
[epoch15, step864]: loss 2.947768
[epoch15, step865]: loss 10.313328
[epoch15, step866]: loss 3.228636
[epoch15, step867]: loss 8.362607
[epoch15, step868]: loss 0.680737
[epoch15, step869]: loss 1.058070
[epoch15, step870]: loss 0.789964
[epoch15, step871]: loss 1.056906
[epoch15, step872]: loss 1.282328
[epoch15, step873]: loss 1.211608
[epoch15, step874]: loss 5.991241
[epoch15, step875]: loss 19.650444
[epoch15, step876]: loss 4.174529
[epoch15, step877]: loss 2.985563
[epoch15, step878]: loss 11.820532
[epoch15, step879]: loss 1.405742
[epoch15, step880]: loss 4.976799
[epoch15, step881]: loss 15.854007
[epoch15, step882]: loss 1.559549
[epoch15, step883]: loss 13.828459
[epoch15, step884]: loss 2.200432
[epoch15, step885]: loss 0.863040
[epoch15, step886]: loss 9.856434
[epoch15, step887]: loss 0.931272
[epoch15, step888]: loss 0.882867
[epoch15, step889]: loss 6.916388
[epoch15, step890]: loss 14.032388
[epoch15, step891]: loss 1.211789
[epoch15, step892]: loss 1.733179
[epoch15, step893]: loss 1.092947
[epoch15, step894]: loss 1.777739
[epoch15, step895]: loss 3.289929
[epoch15, step896]: loss 1.993490
[epoch15, step897]: loss 2.361170
[epoch15, step898]: loss 1.047191
[epoch15, step899]: loss 2.487105
[epoch15, step900]: loss 8.034887
[epoch15, step901]: loss 2.757196
[epoch15, step902]: loss 0.897244
[epoch15, step903]: loss 0.952922
[epoch15, step904]: loss 7.231439
[epoch15, step905]: loss 1.135792
[epoch15, step906]: loss 0.856783
[epoch15, step907]: loss 9.305768
[epoch15, step908]: loss 0.874776
[epoch15, step909]: loss 1.919087
[epoch15, step910]: loss 11.225443
[epoch15, step911]: loss 6.448014
[epoch15, step912]: loss 6.813934
[epoch15, step913]: loss 3.679826
[epoch15, step914]: loss 11.376573
[epoch15, step915]: loss 0.758103
[epoch15, step916]: loss 15.565174
[epoch15, step917]: loss 5.572052
[epoch15, step918]: loss 11.678866
[epoch15, step919]: loss 0.861077
[epoch15, step920]: loss 1.959623
[epoch15, step921]: loss 1.616877
[epoch15, step922]: loss 0.788243
[epoch15, step923]: loss 6.767339
[epoch15, step924]: loss 0.790075
[epoch15, step925]: loss 2.566693
[epoch15, step926]: loss 5.708939
[epoch15, step927]: loss 18.208712
[epoch15, step928]: loss 0.976844
[epoch15, step929]: loss 1.695707
[epoch15, step930]: loss 14.937294
[epoch15, step931]: loss 0.710105
[epoch15, step932]: loss 6.601172
[epoch15, step933]: loss 2.504184
[epoch15, step934]: loss 7.585356
[epoch15, step935]: loss 9.806669
[epoch15, step936]: loss 18.987532
[epoch15, step937]: loss 2.440427
[epoch15, step938]: loss 1.330982
[epoch15, step939]: loss 19.354507
[epoch15, step940]: loss 0.834231
[epoch15, step941]: loss 4.802854
[epoch15, step942]: loss 2.665937
[epoch15, step943]: loss 1.708373
[epoch15, step944]: loss 4.745859
[epoch15, step945]: loss 0.858972
[epoch15, step946]: loss 0.584396
[epoch15, step947]: loss 0.903829
[epoch15, step948]: loss 1.038443
[epoch15, step949]: loss 1.586044
[epoch15, step950]: loss 15.424690
[epoch15, step951]: loss 1.314432
[epoch15, step952]: loss 5.338347
[epoch15, step953]: loss 0.991605
[epoch15, step954]: loss 0.771393
[epoch15, step955]: loss 1.095877
[epoch15, step956]: loss 0.942553
[epoch15, step957]: loss 1.163442
[epoch15, step958]: loss 3.065134
[epoch15, step959]: loss 6.658561
[epoch15, step960]: loss 2.177514
[epoch15, step961]: loss 0.874259
[epoch15, step962]: loss 2.972583
[epoch15, step963]: loss 3.259481
[epoch15, step964]: loss 0.853319
[epoch15, step965]: loss 11.031433
[epoch15, step966]: loss 1.356888
[epoch15, step967]: loss 9.533893
[epoch15, step968]: loss 9.170053
[epoch15, step969]: loss 8.941116
[epoch15, step970]: loss 1.601191
[epoch15, step971]: loss 2.674168
[epoch15, step972]: loss 2.570930
[epoch15, step973]: loss 10.928288
[epoch15, step974]: loss 1.219599
[epoch15, step975]: loss 3.247857
[epoch15, step976]: loss 18.328848
[epoch15, step977]: loss 2.182080
[epoch15, step978]: loss 1.205433
[epoch15, step979]: loss 1.760627
[epoch15, step980]: loss 2.096315
[epoch15, step981]: loss 1.943948
[epoch15, step982]: loss 1.026416
[epoch15, step983]: loss 11.403708
[epoch15, step984]: loss 1.110124
[epoch15, step985]: loss 0.583486
[epoch15, step986]: loss 8.099502
[epoch15, step987]: loss 0.721398
[epoch15, step988]: loss 1.709577
[epoch15, step989]: loss 1.398158
[epoch15, step990]: loss 7.452534
[epoch15, step991]: loss 0.768613
[epoch15, step992]: loss 1.167973
[epoch15, step993]: loss 0.690491
[epoch15, step994]: loss 3.045541
[epoch15, step995]: loss 4.224906
[epoch15, step996]: loss 0.777823
[epoch15, step997]: loss 1.138049
[epoch15, step998]: loss 1.262897
[epoch15, step999]: loss 1.338903
[epoch15, step1000]: loss 2.289099
[epoch15, step1001]: loss 2.786314
[epoch15, step1002]: loss 1.241587
[epoch15, step1003]: loss 0.993763
[epoch15, step1004]: loss 3.684102
[epoch15, step1005]: loss 1.092966
[epoch15, step1006]: loss 0.633169
[epoch15, step1007]: loss 0.968687
[epoch15, step1008]: loss 3.956930
[epoch15, step1009]: loss 7.942090
[epoch15, step1010]: loss 8.808738
[epoch15, step1011]: loss 0.942298
[epoch15, step1012]: loss 1.548567
[epoch15, step1013]: loss 2.805318
[epoch15, step1014]: loss 10.190045
[epoch15, step1015]: loss 1.002741
[epoch15, step1016]: loss 1.056764
[epoch15, step1017]: loss 0.847886
[epoch15, step1018]: loss 1.485485
[epoch15, step1019]: loss 1.570451
[epoch15, step1020]: loss 1.305961
[epoch15, step1021]: loss 0.752533
[epoch15, step1022]: loss 1.348288
[epoch15, step1023]: loss 6.507652
[epoch15, step1024]: loss 1.400964
[epoch15, step1025]: loss 1.935190
[epoch15, step1026]: loss 5.873821
[epoch15, step1027]: loss 0.797045
[epoch15, step1028]: loss 20.716854
[epoch15, step1029]: loss 2.289569
[epoch15, step1030]: loss 1.237810
[epoch15, step1031]: loss 2.048054
[epoch15, step1032]: loss 7.703657
[epoch15, step1033]: loss 2.026770
[epoch15, step1034]: loss 1.919395
[epoch15, step1035]: loss 1.004563
[epoch15, step1036]: loss 0.716373
[epoch15, step1037]: loss 8.155810
[epoch15, step1038]: loss 1.005685
[epoch15, step1039]: loss 1.151432
[epoch15, step1040]: loss 2.475428
[epoch15, step1041]: loss 9.539135
[epoch15, step1042]: loss 1.159482
[epoch15, step1043]: loss 0.717133
[epoch15, step1044]: loss 4.075235
[epoch15, step1045]: loss 1.139656
[epoch15, step1046]: loss 9.365620
[epoch15, step1047]: loss 0.703264
[epoch15, step1048]: loss 9.158088
[epoch15, step1049]: loss 12.870697
[epoch15, step1050]: loss 1.657849
[epoch15, step1051]: loss 1.578813
[epoch15, step1052]: loss 1.234530
[epoch15, step1053]: loss 6.914949
[epoch15, step1054]: loss 0.859605
[epoch15, step1055]: loss 0.890870
[epoch15, step1056]: loss 3.477571
[epoch15, step1057]: loss 0.920458
[epoch15, step1058]: loss 0.832367
[epoch15, step1059]: loss 27.887360
[epoch15, step1060]: loss 14.515775
[epoch15, step1061]: loss 7.492215
[epoch15, step1062]: loss 2.229100
[epoch15, step1063]: loss 8.148150
[epoch15, step1064]: loss 8.649708
[epoch15, step1065]: loss 8.499319
[epoch15, step1066]: loss 18.732204
[epoch15, step1067]: loss 0.828123
[epoch15, step1068]: loss 0.776418
[epoch15, step1069]: loss 4.103981
[epoch15, step1070]: loss 1.631972
[epoch15, step1071]: loss 1.102063
[epoch15, step1072]: loss 0.913962
[epoch15, step1073]: loss 6.737203
[epoch15, step1074]: loss 8.228989
[epoch15, step1075]: loss 2.149770
[epoch15, step1076]: loss 7.392562
[epoch15, step1077]: loss 10.610579
[epoch15, step1078]: loss 3.560296
[epoch15, step1079]: loss 0.882241
[epoch15, step1080]: loss 6.329039
[epoch15, step1081]: loss 6.533939
[epoch15, step1082]: loss 0.740577
[epoch15, step1083]: loss 2.464987
[epoch15, step1084]: loss 6.144831
[epoch15, step1085]: loss 8.793866
[epoch15, step1086]: loss 1.182353
[epoch15, step1087]: loss 19.686106
[epoch15, step1088]: loss 1.806982
[epoch15, step1089]: loss 1.917496
[epoch15, step1090]: loss 1.066707
[epoch15, step1091]: loss 20.855061
[epoch15, step1092]: loss 7.840110
[epoch15, step1093]: loss 2.741923
[epoch15, step1094]: loss 1.604984
[epoch15, step1095]: loss 1.237296
[epoch15, step1096]: loss 28.851418
[epoch15, step1097]: loss 1.202732
[epoch15, step1098]: loss 1.788146
[epoch15, step1099]: loss 1.248971
[epoch15, step1100]: loss 2.240128
[epoch15, step1101]: loss 12.812366
[epoch15, step1102]: loss 10.555183
[epoch15, step1103]: loss 7.652327
[epoch15, step1104]: loss 0.566585
[epoch15, step1105]: loss 6.374187
[epoch15, step1106]: loss 3.177149
[epoch15, step1107]: loss 1.928921
[epoch15, step1108]: loss 1.785380
[epoch15, step1109]: loss 1.752947
[epoch15, step1110]: loss 1.155954
[epoch15, step1111]: loss 3.411064
[epoch15, step1112]: loss 14.272961
[epoch15, step1113]: loss 17.233402
[epoch15, step1114]: loss 8.223092
[epoch15, step1115]: loss 0.879935
[epoch15, step1116]: loss 1.370226
[epoch15, step1117]: loss 2.076106
[epoch15, step1118]: loss 6.861814
[epoch15, step1119]: loss 2.480217
[epoch15, step1120]: loss 0.939318
[epoch15, step1121]: loss 2.695439
[epoch15, step1122]: loss 5.922971
[epoch15, step1123]: loss 0.784567
[epoch15, step1124]: loss 1.286699
[epoch15, step1125]: loss 2.896989
[epoch15, step1126]: loss 1.792952
[epoch15, step1127]: loss 0.896326
[epoch15, step1128]: loss 5.058582
[epoch15, step1129]: loss 6.509824
[epoch15, step1130]: loss 1.320634
[epoch15, step1131]: loss 8.781468
[epoch15, step1132]: loss 9.871934
[epoch15, step1133]: loss 8.706777
[epoch15, step1134]: loss 3.352191
[epoch15, step1135]: loss 9.500046
[epoch15, step1136]: loss 2.075030
[epoch15, step1137]: loss 1.665534
[epoch15, step1138]: loss 1.004501
[epoch15, step1139]: loss 0.622832
[epoch15, step1140]: loss 2.407528
[epoch15, step1141]: loss 2.745106
[epoch15, step1142]: loss 3.121270
[epoch15, step1143]: loss 2.602846
[epoch15, step1144]: loss 1.224596
[epoch15, step1145]: loss 1.338973
[epoch15, step1146]: loss 2.427466
[epoch15, step1147]: loss 11.187136
[epoch15, step1148]: loss 3.538591
[epoch15, step1149]: loss 9.357102
[epoch15, step1150]: loss 2.022528
[epoch15, step1151]: loss 7.265357
[epoch15, step1152]: loss 2.412872
[epoch15, step1153]: loss 1.093923
[epoch15, step1154]: loss 3.197927
[epoch15, step1155]: loss 5.975001
[epoch15, step1156]: loss 4.200717
[epoch15, step1157]: loss 15.330231
[epoch15, step1158]: loss 12.332621
[epoch15, step1159]: loss 3.565925
[epoch15, step1160]: loss 12.342072
[epoch15, step1161]: loss 0.615563
[epoch15, step1162]: loss 0.995273
[epoch15, step1163]: loss 1.443435
[epoch15, step1164]: loss 9.331157
[epoch15, step1165]: loss 0.807135
[epoch15, step1166]: loss 2.958616
[epoch15, step1167]: loss 0.697080
[epoch15, step1168]: loss 2.765938
[epoch15, step1169]: loss 3.359248
[epoch15, step1170]: loss 2.623791
[epoch15, step1171]: loss 0.615151
[epoch15, step1172]: loss 0.774488
[epoch15, step1173]: loss 3.146571
[epoch15, step1174]: loss 1.307150
[epoch15, step1175]: loss 2.842143
[epoch15, step1176]: loss 6.598433
[epoch15, step1177]: loss 1.063409
[epoch15, step1178]: loss 9.446093
[epoch15, step1179]: loss 2.296326
[epoch15, step1180]: loss 1.199068
[epoch15, step1181]: loss 1.405573
[epoch15, step1182]: loss 1.820669
[epoch15, step1183]: loss 1.725564
[epoch15, step1184]: loss 3.345638
[epoch15, step1185]: loss 0.859992
[epoch15, step1186]: loss 1.075556
[epoch15, step1187]: loss 4.778128
[epoch15, step1188]: loss 2.056557
[epoch15, step1189]: loss 1.747508
[epoch15, step1190]: loss 9.023252
[epoch15, step1191]: loss 7.461156
[epoch15, step1192]: loss 1.021355
[epoch15, step1193]: loss 6.896740
[epoch15, step1194]: loss 0.702580
[epoch15, step1195]: loss 3.513178
[epoch15, step1196]: loss 0.998587
[epoch15, step1197]: loss 8.141342
[epoch15, step1198]: loss 1.452618
[epoch15, step1199]: loss 0.599205
[epoch15, step1200]: loss 0.773855
[epoch15, step1201]: loss 3.903122
[epoch15, step1202]: loss 2.617307
[epoch15, step1203]: loss 11.644819
[epoch15, step1204]: loss 1.711337
[epoch15, step1205]: loss 0.775840
[epoch15, step1206]: loss 7.926851
[epoch15, step1207]: loss 1.492284
[epoch15, step1208]: loss 0.814582
[epoch15, step1209]: loss 1.077840
[epoch15, step1210]: loss 7.992049
[epoch15, step1211]: loss 3.487203
[epoch15, step1212]: loss 5.941938
[epoch15, step1213]: loss 1.269020
[epoch15, step1214]: loss 5.311002
[epoch15, step1215]: loss 0.781629
[epoch15, step1216]: loss 2.271673
[epoch15, step1217]: loss 1.204833
[epoch15, step1218]: loss 1.064276
[epoch15, step1219]: loss 6.858373
[epoch15, step1220]: loss 0.928434
[epoch15, step1221]: loss 0.919449
[epoch15, step1222]: loss 12.953472
[epoch15, step1223]: loss 7.363713
[epoch15, step1224]: loss 1.295164
[epoch15, step1225]: loss 10.713155
[epoch15, step1226]: loss 1.488272
[epoch15, step1227]: loss 1.107834
[epoch15, step1228]: loss 2.075941
[epoch15, step1229]: loss 0.873980
[epoch15, step1230]: loss 15.185204
[epoch15, step1231]: loss 0.832216
[epoch15, step1232]: loss 1.023168
[epoch15, step1233]: loss 11.543097
[epoch15, step1234]: loss 0.684741
[epoch15, step1235]: loss 1.041334
[epoch15, step1236]: loss 7.493468
[epoch15, step1237]: loss 13.991661
[epoch15, step1238]: loss 1.187914
[epoch15, step1239]: loss 2.973134
[epoch15, step1240]: loss 2.326696
[epoch15, step1241]: loss 1.056985
[epoch15, step1242]: loss 0.846399
[epoch15, step1243]: loss 1.456896
[epoch15, step1244]: loss 0.588056
[epoch15, step1245]: loss 0.816496
[epoch15, step1246]: loss 1.528716
[epoch15, step1247]: loss 0.700302
[epoch15, step1248]: loss 0.983190
[epoch15, step1249]: loss 0.960451
[epoch15, step1250]: loss 7.574358
[epoch15, step1251]: loss 14.062714
[epoch15, step1252]: loss 1.771536
[epoch15, step1253]: loss 0.697617
[epoch15, step1254]: loss 0.702268
[epoch15, step1255]: loss 1.308893
[epoch15, step1256]: loss 2.857184
[epoch15, step1257]: loss 0.780079
[epoch15, step1258]: loss 2.204450
[epoch15, step1259]: loss 2.742053
[epoch15, step1260]: loss 2.989606
[epoch15, step1261]: loss 7.479440
[epoch15, step1262]: loss 1.426742
[epoch15, step1263]: loss 19.235924
[epoch15, step1264]: loss 1.550413
[epoch15, step1265]: loss 0.706011
[epoch15, step1266]: loss 1.078262
[epoch15, step1267]: loss 1.030128
[epoch15, step1268]: loss 3.948724
[epoch15, step1269]: loss 1.012807
[epoch15, step1270]: loss 1.591341
[epoch15, step1271]: loss 1.306997
[epoch15, step1272]: loss 3.007651
[epoch15, step1273]: loss 2.767370
[epoch15, step1274]: loss 1.842274
[epoch15, step1275]: loss 15.366549
[epoch15, step1276]: loss 1.721957
[epoch15, step1277]: loss 2.741558
[epoch15, step1278]: loss 0.750296
[epoch15, step1279]: loss 1.256052
[epoch15, step1280]: loss 2.458123
[epoch15, step1281]: loss 3.319297
[epoch15, step1282]: loss 2.187004
[epoch15, step1283]: loss 7.147933
[epoch15, step1284]: loss 1.643627
[epoch15, step1285]: loss 1.049287
[epoch15, step1286]: loss 1.077095
[epoch15, step1287]: loss 0.706484
[epoch15, step1288]: loss 6.602780
[epoch15, step1289]: loss 0.631382
[epoch15, step1290]: loss 0.865690
[epoch15, step1291]: loss 4.206289
[epoch15, step1292]: loss 10.304714
[epoch15, step1293]: loss 2.640029
[epoch15, step1294]: loss 1.319771
[epoch15, step1295]: loss 2.953817
[epoch15, step1296]: loss 2.011848
[epoch15, step1297]: loss 1.183645
[epoch15, step1298]: loss 4.855342
[epoch15, step1299]: loss 7.563628
[epoch15, step1300]: loss 7.375603
[epoch15, step1301]: loss 1.376760
[epoch15, step1302]: loss 1.122952
[epoch15, step1303]: loss 1.195208
[epoch15, step1304]: loss 0.754275
[epoch15, step1305]: loss 7.084077
[epoch15, step1306]: loss 1.341938
[epoch15, step1307]: loss 0.745382
[epoch15, step1308]: loss 0.622822
[epoch15, step1309]: loss 2.519534
[epoch15, step1310]: loss 1.346605
[epoch15, step1311]: loss 10.327088
[epoch15, step1312]: loss 4.275427
[epoch15, step1313]: loss 0.651617
[epoch15, step1314]: loss 13.026082
[epoch15, step1315]: loss 6.666893
[epoch15, step1316]: loss 0.928820
[epoch15, step1317]: loss 1.974529
[epoch15, step1318]: loss 1.008365
[epoch15, step1319]: loss 10.583383
[epoch15, step1320]: loss 1.007249
[epoch15, step1321]: loss 2.301769
[epoch15, step1322]: loss 0.986911
[epoch15, step1323]: loss 0.698362
[epoch15, step1324]: loss 2.918864
[epoch15, step1325]: loss 7.037643
[epoch15, step1326]: loss 2.399077
[epoch15, step1327]: loss 5.698343
[epoch15, step1328]: loss 0.947833
[epoch15, step1329]: loss 17.109842
[epoch15, step1330]: loss 9.780190
[epoch15, step1331]: loss 0.762060
[epoch15, step1332]: loss 9.641898
[epoch15, step1333]: loss 8.267250
[epoch15, step1334]: loss 0.770822
[epoch15, step1335]: loss 8.514871
[epoch15, step1336]: loss 1.497034
[epoch15, step1337]: loss 1.415788
[epoch15, step1338]: loss 1.121245
[epoch15, step1339]: loss 0.746850
[epoch15, step1340]: loss 8.328641
[epoch15, step1341]: loss 2.605887
[epoch15, step1342]: loss 1.349580
[epoch15, step1343]: loss 9.165558
[epoch15, step1344]: loss 2.413924
[epoch15, step1345]: loss 7.153788
[epoch15, step1346]: loss 7.634734
[epoch15, step1347]: loss 1.356874
[epoch15, step1348]: loss 1.887646
[epoch15, step1349]: loss 9.289752
[epoch15, step1350]: loss 9.799774
[epoch15, step1351]: loss 4.390673
[epoch15, step1352]: loss 8.314868
[epoch15, step1353]: loss 1.544085
[epoch15, step1354]: loss 2.220381
[epoch15, step1355]: loss 6.590561
[epoch15, step1356]: loss 0.833061
[epoch15, step1357]: loss 1.596728
[epoch15, step1358]: loss 2.067703
[epoch15, step1359]: loss 7.398667
[epoch15, step1360]: loss 1.163113
[epoch15, step1361]: loss 0.799587
[epoch15, step1362]: loss 7.176857
[epoch15, step1363]: loss 1.023212
[epoch15, step1364]: loss 1.719450
[epoch15, step1365]: loss 1.084852
[epoch15, step1366]: loss 1.025292
[epoch15, step1367]: loss 10.494727
[epoch15, step1368]: loss 7.234540
[epoch15, step1369]: loss 13.638689
[epoch15, step1370]: loss 0.903162
[epoch15, step1371]: loss 7.008543
[epoch15, step1372]: loss 1.074549
[epoch15, step1373]: loss 8.017667
[epoch15, step1374]: loss 6.348481
[epoch15, step1375]: loss 1.435769
[epoch15, step1376]: loss 1.619243
[epoch15, step1377]: loss 1.129184
[epoch15, step1378]: loss 1.022296
[epoch15, step1379]: loss 14.854372
[epoch15, step1380]: loss 1.022056
[epoch15, step1381]: loss 7.210676
[epoch15, step1382]: loss 2.234116
[epoch15, step1383]: loss 3.324103
[epoch15, step1384]: loss 1.679857
[epoch15, step1385]: loss 1.831336
[epoch15, step1386]: loss 1.044953
[epoch15, step1387]: loss 1.565125
[epoch15, step1388]: loss 2.820699
[epoch15, step1389]: loss 2.490420
[epoch15, step1390]: loss 0.822825
[epoch15, step1391]: loss 9.852068
[epoch15, step1392]: loss 2.317145
[epoch15, step1393]: loss 10.163591
[epoch15, step1394]: loss 10.118287
[epoch15, step1395]: loss 10.924737
[epoch15, step1396]: loss 0.877868
[epoch15, step1397]: loss 10.529984
[epoch15, step1398]: loss 7.547185
[epoch15, step1399]: loss 0.936529
[epoch15, step1400]: loss 8.802287
[epoch15, step1401]: loss 2.021642
[epoch15, step1402]: loss 2.757705
[epoch15, step1403]: loss 2.714581
[epoch15, step1404]: loss 0.711575
[epoch15, step1405]: loss 7.623429
[epoch15, step1406]: loss 1.006871
[epoch15, step1407]: loss 1.246061
[epoch15, step1408]: loss 0.928911
[epoch15, step1409]: loss 4.537395
[epoch15, step1410]: loss 1.033584
[epoch15, step1411]: loss 2.599199
[epoch15, step1412]: loss 20.273911
[epoch15, step1413]: loss 8.571307
[epoch15, step1414]: loss 9.003651
[epoch15, step1415]: loss 1.630261
[epoch15, step1416]: loss 0.723814
[epoch15, step1417]: loss 5.801315
[epoch15, step1418]: loss 3.425498
[epoch15, step1419]: loss 0.989061
[epoch15, step1420]: loss 16.526739
[epoch15, step1421]: loss 1.268727
[epoch15, step1422]: loss 2.681517
[epoch15, step1423]: loss 1.171258
[epoch15, step1424]: loss 2.049662
[epoch15, step1425]: loss 0.706097
[epoch15, step1426]: loss 6.999905
[epoch15, step1427]: loss 2.222360
[epoch15, step1428]: loss 7.445046
[epoch15, step1429]: loss 1.045123
[epoch15, step1430]: loss 1.691167
[epoch15, step1431]: loss 1.667621
[epoch15, step1432]: loss 2.911048
[epoch15, step1433]: loss 0.834332
[epoch15, step1434]: loss 7.599162
[epoch15, step1435]: loss 1.207152
[epoch15, step1436]: loss 0.789750
[epoch15, step1437]: loss 0.811748
[epoch15, step1438]: loss 2.866298
[epoch15, step1439]: loss 3.602416
[epoch15, step1440]: loss 0.619013
[epoch15, step1441]: loss 6.647049
[epoch15, step1442]: loss 7.177734
[epoch15, step1443]: loss 1.342986
[epoch15, step1444]: loss 0.600824
[epoch15, step1445]: loss 0.900519
[epoch15, step1446]: loss 0.778730
[epoch15, step1447]: loss 0.697236
[epoch15, step1448]: loss 11.698282
[epoch15, step1449]: loss 6.911518
[epoch15, step1450]: loss 1.756926
[epoch15, step1451]: loss 1.015987
[epoch15, step1452]: loss 1.181408
[epoch15, step1453]: loss 1.043328
[epoch15, step1454]: loss 1.398575
[epoch15, step1455]: loss 1.015854
[epoch15, step1456]: loss 7.494056
[epoch15, step1457]: loss 2.236308
[epoch15, step1458]: loss 1.717024
[epoch15, step1459]: loss 1.353531
[epoch15, step1460]: loss 1.383057
[epoch15, step1461]: loss 1.008589
[epoch15, step1462]: loss 0.862119
[epoch15, step1463]: loss 24.040852
[epoch15, step1464]: loss 1.959332
[epoch15, step1465]: loss 9.398987
[epoch15, step1466]: loss 6.892514
[epoch15, step1467]: loss 4.419306
[epoch15, step1468]: loss 2.918899
[epoch15, step1469]: loss 1.526560
[epoch15, step1470]: loss 2.867087
[epoch15, step1471]: loss 3.008958
[epoch15, step1472]: loss 1.102273
[epoch15, step1473]: loss 1.915148
[epoch15, step1474]: loss 3.765188
[epoch15, step1475]: loss 7.580780
[epoch15, step1476]: loss 2.033804
[epoch15, step1477]: loss 2.739420
[epoch15, step1478]: loss 1.028727
[epoch15, step1479]: loss 1.562783
[epoch15, step1480]: loss 7.620029
[epoch15, step1481]: loss 0.736072
[epoch15, step1482]: loss 1.043487
[epoch15, step1483]: loss 3.727100
[epoch15, step1484]: loss 7.673009
[epoch15, step1485]: loss 1.271836
[epoch15, step1486]: loss 1.264784
[epoch15, step1487]: loss 0.775957
[epoch15, step1488]: loss 2.247856
[epoch15, step1489]: loss 3.842808
[epoch15, step1490]: loss 0.998474
[epoch15, step1491]: loss 0.766996
[epoch15, step1492]: loss 10.318472
[epoch15, step1493]: loss 0.854462
[epoch15, step1494]: loss 2.772152
[epoch15, step1495]: loss 13.797970
[epoch15, step1496]: loss 2.991023
[epoch15, step1497]: loss 7.035178
[epoch15, step1498]: loss 1.227690
[epoch15, step1499]: loss 0.696362
[epoch15, step1500]: loss 0.763434
[epoch15, step1501]: loss 0.956591
[epoch15, step1502]: loss 6.870819
[epoch15, step1503]: loss 12.777186
[epoch15, step1504]: loss 1.152700
[epoch15, step1505]: loss 1.402546
[epoch15, step1506]: loss 2.130877
[epoch15, step1507]: loss 9.707268
[epoch15, step1508]: loss 2.801947
[epoch15, step1509]: loss 6.201274
[epoch15, step1510]: loss 12.482965
[epoch15, step1511]: loss 1.219034
[epoch15, step1512]: loss 1.474285
[epoch15, step1513]: loss 0.813232
[epoch15, step1514]: loss 0.819125
[epoch15, step1515]: loss 9.297800
[epoch15, step1516]: loss 20.258192
[epoch15, step1517]: loss 1.294842
[epoch15, step1518]: loss 0.584880
[epoch15, step1519]: loss 0.548272
[epoch15, step1520]: loss 0.606576
[epoch15, step1521]: loss 0.868786
[epoch15, step1522]: loss 7.322174
[epoch15, step1523]: loss 2.849497
[epoch15, step1524]: loss 3.376486
[epoch15, step1525]: loss 0.875831
[epoch15, step1526]: loss 12.036275
[epoch15, step1527]: loss 1.320170
[epoch15, step1528]: loss 9.576562
[epoch15, step1529]: loss 4.483506
[epoch15, step1530]: loss 2.669046
[epoch15, step1531]: loss 12.328474
[epoch15, step1532]: loss 0.785427
[epoch15, step1533]: loss 0.909060
[epoch15, step1534]: loss 12.160315
[epoch15, step1535]: loss 7.355254
[epoch15, step1536]: loss 9.093367
[epoch15, step1537]: loss 0.689402
[epoch15, step1538]: loss 7.017449
[epoch15, step1539]: loss 1.275376
[epoch15, step1540]: loss 2.384013
[epoch15, step1541]: loss 2.462157
[epoch15, step1542]: loss 1.712746
[epoch15, step1543]: loss 1.945747
[epoch15, step1544]: loss 1.984832
[epoch15, step1545]: loss 1.317746
[epoch15, step1546]: loss 1.007498
[epoch15, step1547]: loss 2.863051
[epoch15, step1548]: loss 3.220958
[epoch15, step1549]: loss 0.559303
[epoch15, step1550]: loss 1.479674
[epoch15, step1551]: loss 2.792642
[epoch15, step1552]: loss 1.580881
[epoch15, step1553]: loss 1.499605
[epoch15, step1554]: loss 2.691540
[epoch15, step1555]: loss 8.858855
[epoch15, step1556]: loss 1.766887
[epoch15, step1557]: loss 5.405869
[epoch15, step1558]: loss 0.999113
[epoch15, step1559]: loss 1.154261
[epoch15, step1560]: loss 10.387468
[epoch15, step1561]: loss 1.146489
[epoch15, step1562]: loss 0.711961
[epoch15, step1563]: loss 2.122188
[epoch15, step1564]: loss 7.839502
[epoch15, step1565]: loss 3.415131
[epoch15, step1566]: loss 1.526063
[epoch15, step1567]: loss 1.621692
[epoch15, step1568]: loss 5.932319
[epoch15, step1569]: loss 0.860282
[epoch15, step1570]: loss 2.000142
[epoch15, step1571]: loss 2.804462
[epoch15, step1572]: loss 0.984263
[epoch15, step1573]: loss 1.748947
[epoch15, step1574]: loss 1.153032
[epoch15, step1575]: loss 7.338976
[epoch15, step1576]: loss 1.308885
[epoch15, step1577]: loss 6.206307
[epoch15, step1578]: loss 11.770527
[epoch15, step1579]: loss 2.193780
[epoch15, step1580]: loss 1.360942
[epoch15, step1581]: loss 0.595545
[epoch15, step1582]: loss 1.762158
[epoch15, step1583]: loss 2.648078
[epoch15, step1584]: loss 0.888226
[epoch15, step1585]: loss 0.567962
[epoch15, step1586]: loss 7.133081
[epoch15, step1587]: loss 1.707229
[epoch15, step1588]: loss 7.543571
[epoch15, step1589]: loss 2.853607
[epoch15, step1590]: loss 2.362653
[epoch15, step1591]: loss 1.069554
[epoch15, step1592]: loss 2.491009
[epoch15, step1593]: loss 2.870687
[epoch15, step1594]: loss 1.004504
[epoch15, step1595]: loss 2.976569
[epoch15, step1596]: loss 0.761702
[epoch15, step1597]: loss 7.004228
[epoch15, step1598]: loss 1.887195
[epoch15, step1599]: loss 2.608762
[epoch15, step1600]: loss 0.734593
[epoch15, step1601]: loss 3.533827
[epoch15, step1602]: loss 1.993231
[epoch15, step1603]: loss 0.649360
[epoch15, step1604]: loss 1.066534
[epoch15, step1605]: loss 7.242883
[epoch15, step1606]: loss 0.827758
[epoch15, step1607]: loss 2.595418
[epoch15, step1608]: loss 21.857784
[epoch15, step1609]: loss 9.746558
[epoch15, step1610]: loss 13.553259
[epoch15, step1611]: loss 2.712502
[epoch15, step1612]: loss 28.806099
[epoch15, step1613]: loss 9.873659
[epoch15, step1614]: loss 0.783865
[epoch15, step1615]: loss 2.938286
[epoch15, step1616]: loss 1.887985
[epoch15, step1617]: loss 0.750180
[epoch15, step1618]: loss 0.588580
[epoch15, step1619]: loss 1.825896
[epoch15, step1620]: loss 5.138633
[epoch15, step1621]: loss 3.240608
[epoch15, step1622]: loss 0.643408
[epoch15, step1623]: loss 1.207679
[epoch15, step1624]: loss 2.546073
[epoch15, step1625]: loss 4.824585
[epoch15, step1626]: loss 1.706119
[epoch15, step1627]: loss 1.526091
[epoch15, step1628]: loss 7.730608
[epoch15, step1629]: loss 0.460934
[epoch15, step1630]: loss 1.891119
[epoch15, step1631]: loss 8.020404
[epoch15, step1632]: loss 2.803629
[epoch15, step1633]: loss 2.822476
[epoch15, step1634]: loss 1.253502
[epoch15, step1635]: loss 1.146235
[epoch15, step1636]: loss 9.887997
[epoch15, step1637]: loss 7.161691
[epoch15, step1638]: loss 1.448169
[epoch15, step1639]: loss 7.402688
[epoch15, step1640]: loss 3.099934
[epoch15, step1641]: loss 7.929286
[epoch15, step1642]: loss 9.612703
[epoch15, step1643]: loss 0.962467
[epoch15, step1644]: loss 1.075827
[epoch15, step1645]: loss 1.263888
[epoch15, step1646]: loss 1.013985
[epoch15, step1647]: loss 9.866290
[epoch15, step1648]: loss 6.565937
[epoch15, step1649]: loss 2.744739
[epoch15, step1650]: loss 1.119839
[epoch15, step1651]: loss 7.727008
[epoch15, step1652]: loss 2.657837
[epoch15, step1653]: loss 10.832934
[epoch15, step1654]: loss 5.740699
[epoch15, step1655]: loss 1.672433
[epoch15, step1656]: loss 2.047784
[epoch15, step1657]: loss 1.175118
[epoch15, step1658]: loss 0.895895
[epoch15, step1659]: loss 10.453862
[epoch15, step1660]: loss 0.627995
[epoch15, step1661]: loss 0.782710
[epoch15, step1662]: loss 10.944187
[epoch15, step1663]: loss 2.648753
[epoch15, step1664]: loss 1.307634
[epoch15, step1665]: loss 0.636283
[epoch15, step1666]: loss 12.305025
[epoch15, step1667]: loss 4.094118
[epoch15, step1668]: loss 1.220611
[epoch15, step1669]: loss 11.649829
[epoch15, step1670]: loss 2.429703
[epoch15, step1671]: loss 0.786740
[epoch15, step1672]: loss 9.868378
[epoch15, step1673]: loss 1.757736
[epoch15, step1674]: loss 0.891822
[epoch15, step1675]: loss 7.206124
[epoch15, step1676]: loss 13.596877
[epoch15, step1677]: loss 6.942415
[epoch15, step1678]: loss 1.107182
[epoch15, step1679]: loss 1.291793
[epoch15, step1680]: loss 0.935522
[epoch15, step1681]: loss 2.811178
[epoch15, step1682]: loss 2.275374
[epoch15, step1683]: loss 1.754530
[epoch15, step1684]: loss 0.633918
[epoch15, step1685]: loss 0.819237
[epoch15, step1686]: loss 1.953589
[epoch15, step1687]: loss 1.830460
[epoch15, step1688]: loss 0.675041
[epoch15, step1689]: loss 6.176822
[epoch15, step1690]: loss 1.231936
[epoch15, step1691]: loss 6.661843
[epoch15, step1692]: loss 0.886314
[epoch15, step1693]: loss 1.196992
[epoch15, step1694]: loss 1.309416
[epoch15, step1695]: loss 2.726381
[epoch15, step1696]: loss 8.520216
[epoch15, step1697]: loss 9.641591
[epoch15, step1698]: loss 5.033001
[epoch15, step1699]: loss 0.523255
[epoch15, step1700]: loss 7.323531
[epoch15, step1701]: loss 9.374467
[epoch15, step1702]: loss 3.934797
[epoch15, step1703]: loss 1.486546
[epoch15, step1704]: loss 2.325099
[epoch15, step1705]: loss 9.504169
[epoch15, step1706]: loss 1.036954
[epoch15, step1707]: loss 1.229735
[epoch15, step1708]: loss 7.176714
[epoch15, step1709]: loss 2.116520
[epoch15, step1710]: loss 6.066532
[epoch15, step1711]: loss 2.238961
[epoch15, step1712]: loss 9.789127
[epoch15, step1713]: loss 10.179944
[epoch15, step1714]: loss 1.755793
[epoch15, step1715]: loss 9.150627
[epoch15, step1716]: loss 8.461757
[epoch15, step1717]: loss 1.249270
[epoch15, step1718]: loss 6.492799
[epoch15, step1719]: loss 0.692923
[epoch15, step1720]: loss 3.808988
[epoch15, step1721]: loss 3.085589
[epoch15, step1722]: loss 1.625657
[epoch15, step1723]: loss 1.427927
[epoch15, step1724]: loss 8.943402
[epoch15, step1725]: loss 0.857779
[epoch15, step1726]: loss 8.818020
[epoch15, step1727]: loss 5.487319
[epoch15, step1728]: loss 3.795056
[epoch15, step1729]: loss 2.456234
[epoch15, step1730]: loss 4.915849
[epoch15, step1731]: loss 3.113185
[epoch15, step1732]: loss 1.154585
[epoch15, step1733]: loss 1.714029
[epoch15, step1734]: loss 0.903962
[epoch15, step1735]: loss 3.696916
[epoch15, step1736]: loss 0.865770
[epoch15, step1737]: loss 14.823202
[epoch15, step1738]: loss 4.408823
[epoch15, step1739]: loss 6.754251
[epoch15, step1740]: loss 1.526671
[epoch15, step1741]: loss 6.705089
[epoch15, step1742]: loss 3.179327
[epoch15, step1743]: loss 8.951080
[epoch15, step1744]: loss 6.710334
[epoch15, step1745]: loss 6.255481
[epoch15, step1746]: loss 1.711868
[epoch15, step1747]: loss 0.752763
[epoch15, step1748]: loss 0.987041
[epoch15, step1749]: loss 0.667119
[epoch15, step1750]: loss 5.233767
[epoch15, step1751]: loss 2.756299
[epoch15, step1752]: loss 3.065380
[epoch15, step1753]: loss 1.186193
[epoch15, step1754]: loss 5.203532
[epoch15, step1755]: loss 1.583356
[epoch15, step1756]: loss 4.025045
[epoch15, step1757]: loss 2.035781
[epoch15, step1758]: loss 0.921241
[epoch15, step1759]: loss 10.295211
[epoch15, step1760]: loss 1.028604
[epoch15, step1761]: loss 0.931559
[epoch15, step1762]: loss 1.844875
[epoch15, step1763]: loss 5.030393
[epoch15, step1764]: loss 0.967175
[epoch15, step1765]: loss 1.320124
[epoch15, step1766]: loss 0.987543
[epoch15, step1767]: loss 6.522639
[epoch15, step1768]: loss 3.298812
[epoch15, step1769]: loss 1.585276
[epoch15, step1770]: loss 1.322010
[epoch15, step1771]: loss 0.891198
[epoch15, step1772]: loss 6.740617
[epoch15, step1773]: loss 2.394148
[epoch15, step1774]: loss 1.689679
[epoch15, step1775]: loss 1.394606
[epoch15, step1776]: loss 3.391612
[epoch15, step1777]: loss 1.077745
[epoch15, step1778]: loss 0.977785
[epoch15, step1779]: loss 2.029965
[epoch15, step1780]: loss 11.524822
[epoch15, step1781]: loss 0.826356
[epoch15, step1782]: loss 1.618720
[epoch15, step1783]: loss 2.672230
[epoch15, step1784]: loss 7.590179
[epoch15, step1785]: loss 0.924520
[epoch15, step1786]: loss 0.814384
[epoch15, step1787]: loss 8.298737
[epoch15, step1788]: loss 1.741090
[epoch15, step1789]: loss 1.438915
[epoch15, step1790]: loss 1.117426
[epoch15, step1791]: loss 4.040085
[epoch15, step1792]: loss 0.799932
[epoch15, step1793]: loss 0.601631
[epoch15, step1794]: loss 3.924902
[epoch15, step1795]: loss 0.772999
[epoch15, step1796]: loss 1.474902
[epoch15, step1797]: loss 1.364577
[epoch15, step1798]: loss 2.663299
[epoch15, step1799]: loss 14.799397
[epoch15, step1800]: loss 2.107497
[epoch15, step1801]: loss 3.135425
[epoch15, step1802]: loss 0.931867
[epoch15, step1803]: loss 3.558783
[epoch15, step1804]: loss 2.633464
[epoch15, step1805]: loss 0.682928
[epoch15, step1806]: loss 2.140721
[epoch15, step1807]: loss 10.212251
[epoch15, step1808]: loss 1.266234
[epoch15, step1809]: loss 0.963230
[epoch15, step1810]: loss 1.098130
[epoch15, step1811]: loss 0.908560
[epoch15, step1812]: loss 3.206954
[epoch15, step1813]: loss 10.665865
[epoch15, step1814]: loss 0.765703
[epoch15, step1815]: loss 6.197542
[epoch15, step1816]: loss 1.767362
[epoch15, step1817]: loss 2.439319
[epoch15, step1818]: loss 1.385262
[epoch15, step1819]: loss 0.777716
[epoch15, step1820]: loss 5.281529
[epoch15, step1821]: loss 8.919516
[epoch15, step1822]: loss 20.147161
[epoch15, step1823]: loss 1.462781
[epoch15, step1824]: loss 15.636429
[epoch15, step1825]: loss 6.550860
[epoch15, step1826]: loss 0.863874
[epoch15, step1827]: loss 10.058290
[epoch15, step1828]: loss 1.090904
[epoch15, step1829]: loss 1.271790
[epoch15, step1830]: loss 6.912719
[epoch15, step1831]: loss 0.985263
[epoch15, step1832]: loss 7.904833
[epoch15, step1833]: loss 2.663217
[epoch15, step1834]: loss 1.291482
[epoch15, step1835]: loss 16.219532
[epoch15, step1836]: loss 1.320736
[epoch15, step1837]: loss 0.722895
[epoch15, step1838]: loss 11.559085
[epoch15, step1839]: loss 0.874591
[epoch15, step1840]: loss 1.373667
[epoch15, step1841]: loss 0.768164
[epoch15, step1842]: loss 2.282847
[epoch15, step1843]: loss 7.047668
[epoch15, step1844]: loss 0.586802
[epoch15, step1845]: loss 3.665712
[epoch15, step1846]: loss 4.698304
[epoch15, step1847]: loss 0.679111
[epoch15, step1848]: loss 1.412391
[epoch15, step1849]: loss 4.644162
[epoch15, step1850]: loss 0.869350
[epoch15, step1851]: loss 2.959527
[epoch15, step1852]: loss 1.023639
[epoch15, step1853]: loss 7.831598
[epoch15, step1854]: loss 1.039114
[epoch15, step1855]: loss 10.261384
[epoch15, step1856]: loss 9.788171
[epoch15, step1857]: loss 0.782370
[epoch15, step1858]: loss 0.966745
[epoch15, step1859]: loss 1.090980
[epoch15, step1860]: loss 21.723093
[epoch15, step1861]: loss 10.260165
[epoch15, step1862]: loss 3.492147
[epoch15, step1863]: loss 1.031116
[epoch15, step1864]: loss 0.694272
[epoch15, step1865]: loss 1.086291
[epoch15, step1866]: loss 5.114815
[epoch15, step1867]: loss 1.185056
[epoch15, step1868]: loss 0.805343
[epoch15, step1869]: loss 6.576458
[epoch15, step1870]: loss 10.574162
[epoch15, step1871]: loss 8.022383
[epoch15, step1872]: loss 15.844510
[epoch15, step1873]: loss 0.991525
[epoch15, step1874]: loss 1.092596
[epoch15, step1875]: loss 0.965443
[epoch15, step1876]: loss 1.314612
[epoch15, step1877]: loss 7.366940
[epoch15, step1878]: loss 0.553257
[epoch15, step1879]: loss 11.623775
[epoch15, step1880]: loss 2.918915
[epoch15, step1881]: loss 2.601940
[epoch15, step1882]: loss 2.022668
[epoch15, step1883]: loss 0.704179
[epoch15, step1884]: loss 1.472551
[epoch15, step1885]: loss 1.874763
[epoch15, step1886]: loss 1.007028
[epoch15, step1887]: loss 0.794511
[epoch15, step1888]: loss 0.588309
[epoch15, step1889]: loss 7.236327
[epoch15, step1890]: loss 1.219290
[epoch15, step1891]: loss 1.924472
[epoch15, step1892]: loss 3.059439
[epoch15, step1893]: loss 0.568341
[epoch15, step1894]: loss 1.581445
[epoch15, step1895]: loss 2.020855
[epoch15, step1896]: loss 3.222345
[epoch15, step1897]: loss 2.547746
[epoch15, step1898]: loss 1.193746
[epoch15, step1899]: loss 4.644346
[epoch15, step1900]: loss 6.158363
[epoch15, step1901]: loss 0.988042
[epoch15, step1902]: loss 0.792748
[epoch15, step1903]: loss 1.332530
[epoch15, step1904]: loss 3.117507
[epoch15, step1905]: loss 9.384428
[epoch15, step1906]: loss 7.947336
[epoch15, step1907]: loss 0.778307
[epoch15, step1908]: loss 3.409162
[epoch15, step1909]: loss 2.512690
[epoch15, step1910]: loss 14.362765
[epoch15, step1911]: loss 1.484954
[epoch15, step1912]: loss 8.092365
[epoch15, step1913]: loss 0.629513
[epoch15, step1914]: loss 10.333934
[epoch15, step1915]: loss 1.380956
[epoch15, step1916]: loss 0.456455
[epoch15, step1917]: loss 2.622559
[epoch15, step1918]: loss 0.696384
[epoch15, step1919]: loss 1.397441
[epoch15, step1920]: loss 0.613209
[epoch15, step1921]: loss 0.913255
[epoch15, step1922]: loss 7.642070
[epoch15, step1923]: loss 1.976174
[epoch15, step1924]: loss 2.448738
[epoch15, step1925]: loss 4.526752
[epoch15, step1926]: loss 3.098994
[epoch15, step1927]: loss 3.139685
[epoch15, step1928]: loss 7.829376
[epoch15, step1929]: loss 2.934941
[epoch15, step1930]: loss 0.669891
[epoch15, step1931]: loss 1.108210
[epoch15, step1932]: loss 2.745843
[epoch15, step1933]: loss 0.945406
[epoch15, step1934]: loss 1.525207
[epoch15, step1935]: loss 1.286726
[epoch15, step1936]: loss 4.304086
[epoch15, step1937]: loss 9.845804
[epoch15, step1938]: loss 2.798370
[epoch15, step1939]: loss 0.803194
[epoch15, step1940]: loss 1.260659
[epoch15, step1941]: loss 2.437155
[epoch15, step1942]: loss 0.677516
[epoch15, step1943]: loss 1.554767
[epoch15, step1944]: loss 0.644346
[epoch15, step1945]: loss 1.804040
[epoch15, step1946]: loss 0.942576
[epoch15, step1947]: loss 2.306185
[epoch15, step1948]: loss 7.901175
[epoch15, step1949]: loss 3.883793
[epoch15, step1950]: loss 14.565327
[epoch15, step1951]: loss 1.951472
[epoch15, step1952]: loss 3.066803
[epoch15, step1953]: loss 0.989993
[epoch15, step1954]: loss 9.664311
[epoch15, step1955]: loss 6.365910
[epoch15, step1956]: loss 1.356463
[epoch15, step1957]: loss 9.834907
[epoch15, step1958]: loss 13.267963
[epoch15, step1959]: loss 3.325582
[epoch15, step1960]: loss 0.832959
[epoch15, step1961]: loss 1.216316
[epoch15, step1962]: loss 3.528867
[epoch15, step1963]: loss 6.097676
[epoch15, step1964]: loss 6.643100
[epoch15, step1965]: loss 2.314248
[epoch15, step1966]: loss 9.310536
[epoch15, step1967]: loss 3.062880
[epoch15, step1968]: loss 0.927503
[epoch15, step1969]: loss 0.674573
[epoch15, step1970]: loss 1.056185
[epoch15, step1971]: loss 2.746061
[epoch15, step1972]: loss 1.982054
[epoch15, step1973]: loss 1.479651
[epoch15, step1974]: loss 1.173717
[epoch15, step1975]: loss 1.459240
[epoch15, step1976]: loss 1.815637
[epoch15, step1977]: loss 1.569815
[epoch15, step1978]: loss 2.496878
[epoch15, step1979]: loss 16.395939
[epoch15, step1980]: loss 3.248635
[epoch15, step1981]: loss 6.547461
[epoch15, step1982]: loss 1.776524
[epoch15, step1983]: loss 6.040284
[epoch15, step1984]: loss 1.001674
[epoch15, step1985]: loss 1.045737
[epoch15, step1986]: loss 2.457930
[epoch15, step1987]: loss 0.888542
[epoch15, step1988]: loss 4.972452
[epoch15, step1989]: loss 12.540376
[epoch15, step1990]: loss 0.852283
[epoch15, step1991]: loss 6.250402
[epoch15, step1992]: loss 1.077816
[epoch15, step1993]: loss 1.814950
[epoch15, step1994]: loss 11.063075
[epoch15, step1995]: loss 1.034022
[epoch15, step1996]: loss 4.163298
[epoch15, step1997]: loss 2.750566
[epoch15, step1998]: loss 0.741496
[epoch15, step1999]: loss 0.905406
[epoch15, step2000]: loss 1.926481
[epoch15, step2001]: loss 0.969014
[epoch15, step2002]: loss 6.566438
[epoch15, step2003]: loss 1.816108
[epoch15, step2004]: loss 7.281513
[epoch15, step2005]: loss 1.493168
[epoch15, step2006]: loss 6.440266
[epoch15, step2007]: loss 9.615483
[epoch15, step2008]: loss 1.140839
[epoch15, step2009]: loss 1.189121
[epoch15, step2010]: loss 5.311279
[epoch15, step2011]: loss 4.354731
[epoch15, step2012]: loss 1.014881
[epoch15, step2013]: loss 7.015704
[epoch15, step2014]: loss 4.441117
[epoch15, step2015]: loss 0.822657
[epoch15, step2016]: loss 1.407676
[epoch15, step2017]: loss 0.821897
[epoch15, step2018]: loss 1.002636
[epoch15, step2019]: loss 3.731030
[epoch15, step2020]: loss 2.493108
[epoch15, step2021]: loss 3.174243
[epoch15, step2022]: loss 0.727221
[epoch15, step2023]: loss 7.353593
[epoch15, step2024]: loss 9.533325
[epoch15, step2025]: loss 0.849182
[epoch15, step2026]: loss 2.644276
[epoch15, step2027]: loss 7.617279
[epoch15, step2028]: loss 1.253993
[epoch15, step2029]: loss 1.172566
[epoch15, step2030]: loss 0.793658
[epoch15, step2031]: loss 1.312302
[epoch15, step2032]: loss 8.462683
[epoch15, step2033]: loss 1.189434
[epoch15, step2034]: loss 1.492985
[epoch15, step2035]: loss 10.146435
[epoch15, step2036]: loss 1.044874
[epoch15, step2037]: loss 0.702499
[epoch15, step2038]: loss 1.009032
[epoch15, step2039]: loss 2.426621
[epoch15, step2040]: loss 1.869424
[epoch15, step2041]: loss 1.382759
[epoch15, step2042]: loss 2.120749
[epoch15, step2043]: loss 0.590385
[epoch15, step2044]: loss 0.945732
[epoch15, step2045]: loss 0.673559
[epoch15, step2046]: loss 1.223965
[epoch15, step2047]: loss 0.802974
[epoch15, step2048]: loss 5.502813
[epoch15, step2049]: loss 0.844682
[epoch15, step2050]: loss 1.644185
[epoch15, step2051]: loss 1.274153
[epoch15, step2052]: loss 20.773136
[epoch15, step2053]: loss 0.830749
[epoch15, step2054]: loss 15.183625
[epoch15, step2055]: loss 1.770434
[epoch15, step2056]: loss 9.520442
[epoch15, step2057]: loss 0.635636
[epoch15, step2058]: loss 6.051404
[epoch15, step2059]: loss 7.474364
[epoch15, step2060]: loss 0.727047
[epoch15, step2061]: loss 2.205099
[epoch15, step2062]: loss 1.204538
[epoch15, step2063]: loss 3.203707
[epoch15, step2064]: loss 0.966084
[epoch15, step2065]: loss 1.414480
[epoch15, step2066]: loss 0.910439
[epoch15, step2067]: loss 7.571142
[epoch15, step2068]: loss 2.705082
[epoch15, step2069]: loss 1.996866
[epoch15, step2070]: loss 4.473334
[epoch15, step2071]: loss 1.930996
[epoch15, step2072]: loss 1.539307
[epoch15, step2073]: loss 2.441710
[epoch15, step2074]: loss 0.603116
[epoch15, step2075]: loss 2.198817
[epoch15, step2076]: loss 3.991970
[epoch15, step2077]: loss 1.058851
[epoch15, step2078]: loss 2.035480
[epoch15, step2079]: loss 3.060856
[epoch15, step2080]: loss 1.266346
[epoch15, step2081]: loss 11.035534
[epoch15, step2082]: loss 1.188166
[epoch15, step2083]: loss 2.184307
[epoch15, step2084]: loss 11.214829
[epoch15, step2085]: loss 6.886801
[epoch15, step2086]: loss 8.195511
[epoch15, step2087]: loss 1.592672
[epoch15, step2088]: loss 2.192889
[epoch15, step2089]: loss 1.186098
[epoch15, step2090]: loss 0.898147
[epoch15, step2091]: loss 6.937233
[epoch15, step2092]: loss 2.907908
[epoch15, step2093]: loss 1.391451
[epoch15, step2094]: loss 0.700051
[epoch15, step2095]: loss 5.124516
[epoch15, step2096]: loss 15.302236
[epoch15, step2097]: loss 9.059394
[epoch15, step2098]: loss 1.684190
[epoch15, step2099]: loss 1.995660
[epoch15, step2100]: loss 1.886537
[epoch15, step2101]: loss 9.758382
[epoch15, step2102]: loss 1.398989
[epoch15, step2103]: loss 0.905815
[epoch15, step2104]: loss 0.850775
[epoch15, step2105]: loss 1.169417
[epoch15, step2106]: loss 0.953355
[epoch15, step2107]: loss 0.828372
[epoch15, step2108]: loss 5.202085
[epoch15, step2109]: loss 11.982063
[epoch15, step2110]: loss 3.467361
[epoch15, step2111]: loss 1.397143
[epoch15, step2112]: loss 0.684843
[epoch15, step2113]: loss 0.845464
[epoch15, step2114]: loss 0.787955
[epoch15, step2115]: loss 0.427851
[epoch15, step2116]: loss 3.672282
[epoch15, step2117]: loss 9.524392
[epoch15, step2118]: loss 0.606352
[epoch15, step2119]: loss 1.218091
[epoch15, step2120]: loss 9.687396
[epoch15, step2121]: loss 7.650703
[epoch15, step2122]: loss 12.264925
[epoch15, step2123]: loss 1.303425
[epoch15, step2124]: loss 0.710900
[epoch15, step2125]: loss 1.545630
[epoch15, step2126]: loss 1.090036
[epoch15, step2127]: loss 2.028272
[epoch15, step2128]: loss 0.984649
[epoch15, step2129]: loss 11.479043
[epoch15, step2130]: loss 1.551211
[epoch15, step2131]: loss 1.119546
[epoch15, step2132]: loss 3.250574
[epoch15, step2133]: loss 7.582594
[epoch15, step2134]: loss 4.383393
[epoch15, step2135]: loss 8.378693
[epoch15, step2136]: loss 0.926860
[epoch15, step2137]: loss 2.972676
[epoch15, step2138]: loss 4.384359
[epoch15, step2139]: loss 17.717997
[epoch15, step2140]: loss 7.220863
[epoch15, step2141]: loss 3.605024
[epoch15, step2142]: loss 1.797193
[epoch15, step2143]: loss 1.326626
[epoch15, step2144]: loss 2.002708
[epoch15, step2145]: loss 1.387601
[epoch15, step2146]: loss 1.363539
[epoch15, step2147]: loss 2.628611
[epoch15, step2148]: loss 7.620286
[epoch15, step2149]: loss 2.515692
[epoch15, step2150]: loss 0.767166
[epoch15, step2151]: loss 1.474925
[epoch15, step2152]: loss 1.522021
[epoch15, step2153]: loss 8.028474
[epoch15, step2154]: loss 2.033910
[epoch15, step2155]: loss 15.592941
[epoch15, step2156]: loss 9.442540
[epoch15, step2157]: loss 1.024925
[epoch15, step2158]: loss 1.455355
[epoch15, step2159]: loss 5.588914
[epoch15, step2160]: loss 0.928949
[epoch15, step2161]: loss 1.181302
[epoch15, step2162]: loss 1.208816
[epoch15, step2163]: loss 3.609197
[epoch15, step2164]: loss 0.665079
[epoch15, step2165]: loss 1.623034
[epoch15, step2166]: loss 0.697480
[epoch15, step2167]: loss 18.094965
[epoch15, step2168]: loss 2.815373
[epoch15, step2169]: loss 20.343939
[epoch15, step2170]: loss 1.477098
[epoch15, step2171]: loss 1.052852
[epoch15, step2172]: loss 6.697736
[epoch15, step2173]: loss 8.618867
[epoch15, step2174]: loss 8.599423
[epoch15, step2175]: loss 0.650849
[epoch15, step2176]: loss 0.950375
[epoch15, step2177]: loss 3.830264
[epoch15, step2178]: loss 1.838404
[epoch15, step2179]: loss 8.001426
[epoch15, step2180]: loss 1.126020
[epoch15, step2181]: loss 6.084997
[epoch15, step2182]: loss 20.011488
[epoch15, step2183]: loss 0.923846
[epoch15, step2184]: loss 1.199557
[epoch15, step2185]: loss 18.079687
[epoch15, step2186]: loss 1.504338
[epoch15, step2187]: loss 14.149220
[epoch15, step2188]: loss 0.747238
[epoch15, step2189]: loss 1.243666
[epoch15, step2190]: loss 1.282986
[epoch15, step2191]: loss 14.152208
[epoch15, step2192]: loss 8.143165
[epoch15, step2193]: loss 6.049343
[epoch15, step2194]: loss 1.586771
[epoch15, step2195]: loss 2.205308
[epoch15, step2196]: loss 0.682854
[epoch15, step2197]: loss 3.941027
[epoch15, step2198]: loss 3.264601
[epoch15, step2199]: loss 1.526326
[epoch15, step2200]: loss 2.184764
[epoch15, step2201]: loss 0.897586
[epoch15, step2202]: loss 6.911636
[epoch15, step2203]: loss 0.922023
[epoch15, step2204]: loss 0.894160
[epoch15, step2205]: loss 11.782301
[epoch15, step2206]: loss 1.842417
[epoch15, step2207]: loss 9.562163
[epoch15, step2208]: loss 7.507943
[epoch15, step2209]: loss 0.856083
[epoch15, step2210]: loss 11.122338
[epoch15, step2211]: loss 0.959944
[epoch15, step2212]: loss 2.633514
[epoch15, step2213]: loss 17.402149
[epoch15, step2214]: loss 2.595430
[epoch15, step2215]: loss 10.465575
[epoch15, step2216]: loss 0.799364
[epoch15, step2217]: loss 0.886934
[epoch15, step2218]: loss 9.054081
[epoch15, step2219]: loss 0.917422
[epoch15, step2220]: loss 2.625258
[epoch15, step2221]: loss 22.595465
[epoch15, step2222]: loss 0.776565
[epoch15, step2223]: loss 2.817753
[epoch15, step2224]: loss 2.458508
[epoch15, step2225]: loss 8.376966
[epoch15, step2226]: loss 2.804759
[epoch15, step2227]: loss 1.598333
[epoch15, step2228]: loss 0.790550
[epoch15, step2229]: loss 1.238157
[epoch15, step2230]: loss 1.472953
[epoch15, step2231]: loss 2.667453
[epoch15, step2232]: loss 1.893688
[epoch15, step2233]: loss 2.774056
[epoch15, step2234]: loss 0.864718
[epoch15, step2235]: loss 1.290285
[epoch15, step2236]: loss 1.747484
[epoch15, step2237]: loss 4.727444
[epoch15, step2238]: loss 1.728751
[epoch15, step2239]: loss 3.461495
[epoch15, step2240]: loss 13.588644
[epoch15, step2241]: loss 4.130284
[epoch15, step2242]: loss 7.990082
[epoch15, step2243]: loss 0.756583
[epoch15, step2244]: loss 9.300693
[epoch15, step2245]: loss 2.143096
[epoch15, step2246]: loss 2.454922
[epoch15, step2247]: loss 10.094088
[epoch15, step2248]: loss 1.532457
[epoch15, step2249]: loss 0.872601
[epoch15, step2250]: loss 2.925308
[epoch15, step2251]: loss 0.934911
[epoch15, step2252]: loss 7.276127
[epoch15, step2253]: loss 4.993292
[epoch15, step2254]: loss 0.813092
[epoch15, step2255]: loss 0.842633
[epoch15, step2256]: loss 12.515824
[epoch15, step2257]: loss 6.634104
[epoch15, step2258]: loss 1.306907
[epoch15, step2259]: loss 1.553817
[epoch15, step2260]: loss 2.113793
[epoch15, step2261]: loss 1.750999
[epoch15, step2262]: loss 11.885293
[epoch15, step2263]: loss 8.179487
[epoch15, step2264]: loss 13.029025
[epoch15, step2265]: loss 2.682738
[epoch15, step2266]: loss 1.514555
[epoch15, step2267]: loss 1.654582
[epoch15, step2268]: loss 6.722291
[epoch15, step2269]: loss 7.673887
[epoch15, step2270]: loss 0.529687
[epoch15, step2271]: loss 1.033618
[epoch15, step2272]: loss 1.461423
[epoch15, step2273]: loss 22.441427
[epoch15, step2274]: loss 1.081374
[epoch15, step2275]: loss 6.445837
[epoch15, step2276]: loss 1.056591
[epoch15, step2277]: loss 1.109829
[epoch15, step2278]: loss 0.645230
[epoch15, step2279]: loss 7.011001
[epoch15, step2280]: loss 1.460247
[epoch15, step2281]: loss 0.961625
[epoch15, step2282]: loss 9.369251
[epoch15, step2283]: loss 0.774739
[epoch15, step2284]: loss 2.344526
[epoch15, step2285]: loss 2.245110
[epoch15, step2286]: loss 14.929681
[epoch15, step2287]: loss 1.243704
[epoch15, step2288]: loss 1.383829
[epoch15, step2289]: loss 0.889172
[epoch15, step2290]: loss 1.106193
[epoch15, step2291]: loss 9.129372
[epoch15, step2292]: loss 0.685768
[epoch15, step2293]: loss 12.940713
[epoch15, step2294]: loss 7.040688
[epoch15, step2295]: loss 7.747272
[epoch15, step2296]: loss 13.087260
[epoch15, step2297]: loss 2.617971
[epoch15, step2298]: loss 3.004285
[epoch15, step2299]: loss 7.747869
[epoch15, step2300]: loss 8.716476
[epoch15, step2301]: loss 22.767725
[epoch15, step2302]: loss 13.500150
[epoch15, step2303]: loss 9.170160
[epoch15, step2304]: loss 2.841961
[epoch15, step2305]: loss 8.864079
[epoch15, step2306]: loss 3.103249
[epoch15, step2307]: loss 1.509319
[epoch15, step2308]: loss 6.050943
[epoch15, step2309]: loss 2.639295
[epoch15, step2310]: loss 1.950419
[epoch15, step2311]: loss 2.987121
[epoch15, step2312]: loss 12.963507
[epoch15, step2313]: loss 6.585914
[epoch15, step2314]: loss 3.171755
[epoch15, step2315]: loss 1.191813
[epoch15, step2316]: loss 1.828031
[epoch15, step2317]: loss 2.159389
[epoch15, step2318]: loss 1.558950
[epoch15, step2319]: loss 1.575505
[epoch15, step2320]: loss 7.793577
[epoch15, step2321]: loss 0.760209
[epoch15, step2322]: loss 1.377143
[epoch15, step2323]: loss 7.276004
[epoch15, step2324]: loss 0.963290
[epoch15, step2325]: loss 1.155808
[epoch15, step2326]: loss 10.400867
[epoch15, step2327]: loss 9.567985
[epoch15, step2328]: loss 3.238230
[epoch15, step2329]: loss 0.506551
[epoch15, step2330]: loss 3.332846
[epoch15, step2331]: loss 3.207841
[epoch15, step2332]: loss 0.713758
[epoch15, step2333]: loss 0.927732
[epoch15, step2334]: loss 3.212624
[epoch15, step2335]: loss 9.108491
[epoch15, step2336]: loss 1.628600
[epoch15, step2337]: loss 0.974235
[epoch15, step2338]: loss 8.714311
[epoch15, step2339]: loss 1.481697
[epoch15, step2340]: loss 2.742011
[epoch15, step2341]: loss 8.689626
[epoch15, step2342]: loss 1.465842
[epoch15, step2343]: loss 3.954626
[epoch15, step2344]: loss 0.860864
[epoch15, step2345]: loss 12.272634
[epoch15, step2346]: loss 0.865372
[epoch15, step2347]: loss 2.433850
[epoch15, step2348]: loss 2.908612
[epoch15, step2349]: loss 1.154905
[epoch15, step2350]: loss 1.096379
[epoch15, step2351]: loss 7.052204
[epoch15, step2352]: loss 7.549019
[epoch15, step2353]: loss 2.300613
[epoch15, step2354]: loss 1.316047
[epoch15, step2355]: loss 2.577088
[epoch15, step2356]: loss 1.208853
[epoch15, step2357]: loss 5.035365
[epoch15, step2358]: loss 1.291005
[epoch15, step2359]: loss 5.324552
[epoch15, step2360]: loss 0.864189
[epoch15, step2361]: loss 1.433397
[epoch15, step2362]: loss 4.193325
[epoch15, step2363]: loss 1.376077
[epoch15, step2364]: loss 12.599807
[epoch15, step2365]: loss 0.461372
[epoch15, step2366]: loss 0.536924
[epoch15, step2367]: loss 0.846566
[epoch15, step2368]: loss 2.085730
[epoch15, step2369]: loss 0.743082
[epoch15, step2370]: loss 1.158060
[epoch15, step2371]: loss 2.105795
[epoch15, step2372]: loss 2.718279
[epoch15, step2373]: loss 0.889643
[epoch15, step2374]: loss 0.733482
[epoch15, step2375]: loss 3.939027
[epoch15, step2376]: loss 2.291945
[epoch15, step2377]: loss 8.700591
[epoch15, step2378]: loss 0.785640
[epoch15, step2379]: loss 1.141239
[epoch15, step2380]: loss 0.960759
[epoch15, step2381]: loss 6.016665
[epoch15, step2382]: loss 0.541606
[epoch15, step2383]: loss 1.044214
[epoch15, step2384]: loss 5.678061
[epoch15, step2385]: loss 7.055599
[epoch15, step2386]: loss 5.466069
[epoch15, step2387]: loss 1.890598
[epoch15, step2388]: loss 1.405923
[epoch15, step2389]: loss 1.050722
[epoch15, step2390]: loss 2.837090
[epoch15, step2391]: loss 0.702607
[epoch15, step2392]: loss 1.095565
[epoch15, step2393]: loss 0.929032
[epoch15, step2394]: loss 0.644786
[epoch15, step2395]: loss 0.813857
[epoch15, step2396]: loss 7.378414
[epoch15, step2397]: loss 1.484932
[epoch15, step2398]: loss 6.577378
[epoch15, step2399]: loss 4.163731
[epoch15, step2400]: loss 6.227536
[epoch15, step2401]: loss 3.445983
[epoch15, step2402]: loss 10.587511
[epoch15, step2403]: loss 10.147946
[epoch15, step2404]: loss 1.730489
[epoch15, step2405]: loss 2.779650
[epoch15, step2406]: loss 12.111487
[epoch15, step2407]: loss 1.782980
[epoch15, step2408]: loss 0.617266
[epoch15, step2409]: loss 2.912563
[epoch15, step2410]: loss 1.636354
[epoch15, step2411]: loss 3.615376
[epoch15, step2412]: loss 2.178199
[epoch15, step2413]: loss 1.013458
[epoch15, step2414]: loss 2.695698
[epoch15, step2415]: loss 0.496929
[epoch15, step2416]: loss 4.010126
[epoch15, step2417]: loss 4.236232
[epoch15, step2418]: loss 2.710392
[epoch15, step2419]: loss 7.877568
[epoch15, step2420]: loss 1.494535
[epoch15, step2421]: loss 6.296985
[epoch15, step2422]: loss 4.070237
[epoch15, step2423]: loss 0.804577
[epoch15, step2424]: loss 0.937252
[epoch15, step2425]: loss 2.554750
[epoch15, step2426]: loss 10.786741
[epoch15, step2427]: loss 3.591580
[epoch15, step2428]: loss 1.354068
[epoch15, step2429]: loss 1.584007
[epoch15, step2430]: loss 1.491482
[epoch15, step2431]: loss 1.439235
[epoch15, step2432]: loss 1.603226
[epoch15, step2433]: loss 1.183550
[epoch15, step2434]: loss 2.785789
[epoch15, step2435]: loss 0.773664
[epoch15, step2436]: loss 0.745899
[epoch15, step2437]: loss 0.893782
[epoch15, step2438]: loss 3.573002
[epoch15, step2439]: loss 7.602161
[epoch15, step2440]: loss 1.447420
[epoch15, step2441]: loss 2.235776
[epoch15, step2442]: loss 0.811153
[epoch15, step2443]: loss 2.839876
[epoch15, step2444]: loss 0.947035
[epoch15, step2445]: loss 16.464434
[epoch15, step2446]: loss 4.008611
[epoch15, step2447]: loss 0.928772
[epoch15, step2448]: loss 0.585608
[epoch15, step2449]: loss 1.308197
[epoch15, step2450]: loss 10.822941
[epoch15, step2451]: loss 7.889732
[epoch15, step2452]: loss 0.603069
[epoch15, step2453]: loss 7.804780
[epoch15, step2454]: loss 21.497219
[epoch15, step2455]: loss 0.847859
[epoch15, step2456]: loss 1.760476
[epoch15, step2457]: loss 3.053967
[epoch15, step2458]: loss 0.940867
[epoch15, step2459]: loss 7.911211
[epoch15, step2460]: loss 7.673024
[epoch15, step2461]: loss 7.106166
[epoch15, step2462]: loss 6.670177
[epoch15, step2463]: loss 2.507169
[epoch15, step2464]: loss 1.260197
[epoch15, step2465]: loss 2.561758
[epoch15, step2466]: loss 8.570160
[epoch15, step2467]: loss 1.979998
[epoch15, step2468]: loss 2.719290
[epoch15, step2469]: loss 0.949835
[epoch15, step2470]: loss 0.998598
[epoch15, step2471]: loss 9.478909
[epoch15, step2472]: loss 2.365791
[epoch15, step2473]: loss 2.178692
[epoch15, step2474]: loss 2.719798
[epoch15, step2475]: loss 17.864977
[epoch15, step2476]: loss 10.594161
[epoch15, step2477]: loss 0.918707
[epoch15, step2478]: loss 2.234587
[epoch15, step2479]: loss 5.108409
[epoch15, step2480]: loss 9.355662
[epoch15, step2481]: loss 1.153709
[epoch15, step2482]: loss 1.168668
[epoch15, step2483]: loss 1.631267
[epoch15, step2484]: loss 7.524374
[epoch15, step2485]: loss 0.841420
[epoch15, step2486]: loss 0.874075
[epoch15, step2487]: loss 12.850567
[epoch15, step2488]: loss 0.887577
[epoch15, step2489]: loss 0.775476
[epoch15, step2490]: loss 2.788468
[epoch15, step2491]: loss 5.387252
[epoch15, step2492]: loss 8.014753
[epoch15, step2493]: loss 1.422995
[epoch15, step2494]: loss 10.254069
[epoch15, step2495]: loss 1.162261
[epoch15, step2496]: loss 2.749693
[epoch15, step2497]: loss 7.850825
[epoch15, step2498]: loss 20.922722
[epoch15, step2499]: loss 1.826445
[epoch15, step2500]: loss 0.690278
[epoch15, step2501]: loss 1.240555
[epoch15, step2502]: loss 9.477145
[epoch15, step2503]: loss 1.655896
[epoch15, step2504]: loss 1.433702
[epoch15, step2505]: loss 0.652787
[epoch15, step2506]: loss 1.011933
[epoch15, step2507]: loss 0.481580
[epoch15, step2508]: loss 5.759771
[epoch15, step2509]: loss 4.359567
[epoch15, step2510]: loss 7.493659
[epoch15, step2511]: loss 2.115356
[epoch15, step2512]: loss 0.987811
[epoch15, step2513]: loss 2.299333
[epoch15, step2514]: loss 0.620128
[epoch15, step2515]: loss 4.021441
[epoch15, step2516]: loss 6.721971
[epoch15, step2517]: loss 1.727957
[epoch15, step2518]: loss 9.185810
[epoch15, step2519]: loss 7.562736
[epoch15, step2520]: loss 0.966747
[epoch15, step2521]: loss 6.599409
[epoch15, step2522]: loss 0.919597
[epoch15, step2523]: loss 12.850516
[epoch15, step2524]: loss 10.230092
[epoch15, step2525]: loss 2.517008
[epoch15, step2526]: loss 2.372535
[epoch15, step2527]: loss 1.804245
[epoch15, step2528]: loss 18.973818
[epoch15, step2529]: loss 1.253853
[epoch15, step2530]: loss 1.912349
[epoch15, step2531]: loss 1.321739
[epoch15, step2532]: loss 6.922727
[epoch15, step2533]: loss 2.588684
[epoch15, step2534]: loss 1.388457
[epoch15, step2535]: loss 0.977579
[epoch15, step2536]: loss 24.741877
[epoch15, step2537]: loss 1.635522
[epoch15, step2538]: loss 0.542549
[epoch15, step2539]: loss 1.990048
[epoch15, step2540]: loss 0.791912
[epoch15, step2541]: loss 3.593255
[epoch15, step2542]: loss 1.034483
[epoch15, step2543]: loss 3.441221
[epoch15, step2544]: loss 0.970317
[epoch15, step2545]: loss 1.942642
[epoch15, step2546]: loss 0.593479
[epoch15, step2547]: loss 7.672168
[epoch15, step2548]: loss 0.919472
[epoch15, step2549]: loss 3.116604
[epoch15, step2550]: loss 1.972578
[epoch15, step2551]: loss 1.342170
[epoch15, step2552]: loss 3.379811
[epoch15, step2553]: loss 0.934427
[epoch15, step2554]: loss 0.696907
[epoch15, step2555]: loss 1.123345
[epoch15, step2556]: loss 3.372335
[epoch15, step2557]: loss 2.478171
[epoch15, step2558]: loss 16.302534
[epoch15, step2559]: loss 6.779691
[epoch15, step2560]: loss 1.735345
[epoch15, step2561]: loss 6.256634
[epoch15, step2562]: loss 0.915154
[epoch15, step2563]: loss 0.434485
[epoch15, step2564]: loss 18.641590
[epoch15, step2565]: loss 0.912271
[epoch15, step2566]: loss 3.342290
[epoch15, step2567]: loss 0.723325
[epoch15, step2568]: loss 6.413033
[epoch15, step2569]: loss 1.386550
[epoch15, step2570]: loss 0.713116
[epoch15, step2571]: loss 2.500775
[epoch15, step2572]: loss 0.771464
[epoch15, step2573]: loss 0.859969
[epoch15, step2574]: loss 12.924900
[epoch15, step2575]: loss 7.251154
[epoch15, step2576]: loss 7.647477
[epoch15, step2577]: loss 6.065094
[epoch15, step2578]: loss 0.979351
[epoch15, step2579]: loss 10.666952
[epoch15, step2580]: loss 0.715410
[epoch15, step2581]: loss 0.598184
[epoch15, step2582]: loss 0.664401
[epoch15, step2583]: loss 1.304901
[epoch15, step2584]: loss 9.038424
[epoch15, step2585]: loss 9.504972
[epoch15, step2586]: loss 1.223020
[epoch15, step2587]: loss 1.363075
[epoch15, step2588]: loss 16.825039
[epoch15, step2589]: loss 0.993508
[epoch15, step2590]: loss 8.104293
[epoch15, step2591]: loss 2.814727
[epoch15, step2592]: loss 8.677363
[epoch15, step2593]: loss 12.839987
[epoch15, step2594]: loss 0.489996
[epoch15, step2595]: loss 2.741342
[epoch15, step2596]: loss 1.206545
[epoch15, step2597]: loss 3.506735
[epoch15, step2598]: loss 0.652098
[epoch15, step2599]: loss 8.866300
[epoch15, step2600]: loss 5.868811
[epoch15, step2601]: loss 2.566120
[epoch15, step2602]: loss 0.740600
[epoch15, step2603]: loss 5.742629
[epoch15, step2604]: loss 1.775923
[epoch15, step2605]: loss 2.351113
[epoch15, step2606]: loss 0.938550
[epoch15, step2607]: loss 0.680956
[epoch15, step2608]: loss 9.100958
[epoch15, step2609]: loss 2.419287
[epoch15, step2610]: loss 9.409865
[epoch15, step2611]: loss 8.735642
[epoch15, step2612]: loss 1.040414
[epoch15, step2613]: loss 1.613512
[epoch15, step2614]: loss 2.094792
[epoch15, step2615]: loss 2.888128
[epoch15, step2616]: loss 2.863822
[epoch15, step2617]: loss 0.800772
[epoch15, step2618]: loss 0.714911
[epoch15, step2619]: loss 2.279323
[epoch15, step2620]: loss 14.378970
[epoch15, step2621]: loss 0.978234
[epoch15, step2622]: loss 15.600174
[epoch15, step2623]: loss 1.561968
[epoch15, step2624]: loss 4.296646
[epoch15, step2625]: loss 5.326338
[epoch15, step2626]: loss 0.998403
[epoch15, step2627]: loss 8.767973
[epoch15, step2628]: loss 7.139758
[epoch15, step2629]: loss 0.889935
[epoch15, step2630]: loss 0.663275
[epoch15, step2631]: loss 10.291195
[epoch15, step2632]: loss 3.416926
[epoch15, step2633]: loss 0.894613
[epoch15, step2634]: loss 3.065760
[epoch15, step2635]: loss 6.219986
[epoch15, step2636]: loss 2.376925
[epoch15, step2637]: loss 2.146893
[epoch15, step2638]: loss 21.250505
[epoch15, step2639]: loss 2.695869
[epoch15, step2640]: loss 1.552680
[epoch15, step2641]: loss 0.853544
[epoch15, step2642]: loss 2.895470
[epoch15, step2643]: loss 9.107112
[epoch15, step2644]: loss 0.668103
[epoch15, step2645]: loss 7.702349
[epoch15, step2646]: loss 12.728263
[epoch15, step2647]: loss 6.278904
[epoch15, step2648]: loss 1.429879
[epoch15, step2649]: loss 0.922387
[epoch15, step2650]: loss 2.615251
[epoch15, step2651]: loss 0.816357
[epoch15, step2652]: loss 2.928937
[epoch15, step2653]: loss 1.145928
[epoch15, step2654]: loss 0.567466
[epoch15, step2655]: loss 1.573470
[epoch15, step2656]: loss 0.625572
[epoch15, step2657]: loss 1.287568
[epoch15, step2658]: loss 1.744120
[epoch15, step2659]: loss 1.996291
[epoch15, step2660]: loss 1.989482
[epoch15, step2661]: loss 2.181226
[epoch15, step2662]: loss 0.664451
[epoch15, step2663]: loss 0.727625
[epoch15, step2664]: loss 5.424556
[epoch15, step2665]: loss 2.265936
[epoch15, step2666]: loss 2.430552
[epoch15, step2667]: loss 6.705979
[epoch15, step2668]: loss 21.257492
[epoch15, step2669]: loss 1.245643
[epoch15, step2670]: loss 8.320584
[epoch15, step2671]: loss 6.920284
[epoch15, step2672]: loss 2.481069
[epoch15, step2673]: loss 12.539603
[epoch15, step2674]: loss 0.588506
[epoch15, step2675]: loss 4.949359
[epoch15, step2676]: loss 8.364260
[epoch15, step2677]: loss 3.641068
[epoch15, step2678]: loss 7.377181
[epoch15, step2679]: loss 8.260201
[epoch15, step2680]: loss 3.158909
[epoch15, step2681]: loss 7.324988
[epoch15, step2682]: loss 0.884271
[epoch15, step2683]: loss 0.904254
[epoch15, step2684]: loss 3.130452
[epoch15, step2685]: loss 2.209888
[epoch15, step2686]: loss 0.842983
[epoch15, step2687]: loss 17.414158
[epoch15, step2688]: loss 1.098527
[epoch15, step2689]: loss 0.865891
[epoch15, step2690]: loss 9.102827
[epoch15, step2691]: loss 8.481260
[epoch15, step2692]: loss 0.773938
[epoch15, step2693]: loss 10.944745
[epoch15, step2694]: loss 3.761409
[epoch15, step2695]: loss 10.725867
[epoch15, step2696]: loss 0.844518
[epoch15, step2697]: loss 11.874119
[epoch15, step2698]: loss 5.831411
[epoch15, step2699]: loss 2.370938
[epoch15, step2700]: loss 1.057792
[epoch15, step2701]: loss 1.062695
[epoch15, step2702]: loss 1.914985
[epoch15, step2703]: loss 1.035502
[epoch15, step2704]: loss 10.841266
[epoch15, step2705]: loss 13.787470
[epoch15, step2706]: loss 12.618872
[epoch15, step2707]: loss 3.889645
[epoch15, step2708]: loss 0.896991
[epoch15, step2709]: loss 3.168311
[epoch15, step2710]: loss 0.930510
[epoch15, step2711]: loss 7.649467
[epoch15, step2712]: loss 0.614111
[epoch15, step2713]: loss 1.238298
[epoch15, step2714]: loss 1.537057
[epoch15, step2715]: loss 2.453646
[epoch15, step2716]: loss 7.649551
[epoch15, step2717]: loss 7.263657
[epoch15, step2718]: loss 0.733981
[epoch15, step2719]: loss 1.721220
[epoch15, step2720]: loss 17.553570
[epoch15, step2721]: loss 0.916910
[epoch15, step2722]: loss 8.100297
[epoch15, step2723]: loss 16.092184
[epoch15, step2724]: loss 1.745054
[epoch15, step2725]: loss 1.133302
[epoch15, step2726]: loss 8.915924
[epoch15, step2727]: loss 0.898290
[epoch15, step2728]: loss 1.757291
[epoch15, step2729]: loss 8.293260
[epoch15, step2730]: loss 0.837272
[epoch15, step2731]: loss 2.052447
[epoch15, step2732]: loss 2.242248
[epoch15, step2733]: loss 6.738414
[epoch15, step2734]: loss 0.772435
[epoch15, step2735]: loss 1.770997
[epoch15, step2736]: loss 7.088700
[epoch15, step2737]: loss 1.847458
[epoch15, step2738]: loss 2.965984
[epoch15, step2739]: loss 1.649872
[epoch15, step2740]: loss 0.715402
[epoch15, step2741]: loss 12.077566
[epoch15, step2742]: loss 6.985334
[epoch15, step2743]: loss 6.884190
[epoch15, step2744]: loss 0.499117
[epoch15, step2745]: loss 0.908119
[epoch15, step2746]: loss 1.156837
[epoch15, step2747]: loss 1.741192
[epoch15, step2748]: loss 2.574354
[epoch15, step2749]: loss 1.302884
[epoch15, step2750]: loss 5.275855
[epoch15, step2751]: loss 2.797898
[epoch15, step2752]: loss 1.603795
[epoch15, step2753]: loss 0.902185
[epoch15, step2754]: loss 1.720099
[epoch15, step2755]: loss 1.250513
[epoch15, step2756]: loss 0.831741
[epoch15, step2757]: loss 7.115717
[epoch15, step2758]: loss 3.902395
[epoch15, step2759]: loss 1.985333
[epoch15, step2760]: loss 6.333438
[epoch15, step2761]: loss 2.554993
[epoch15, step2762]: loss 15.027111
[epoch15, step2763]: loss 2.845120
[epoch15, step2764]: loss 0.718416
[epoch15, step2765]: loss 1.344353
[epoch15, step2766]: loss 7.595710
[epoch15, step2767]: loss 0.860556
[epoch15, step2768]: loss 0.731538
[epoch15, step2769]: loss 19.997150
[epoch15, step2770]: loss 8.540413
[epoch15, step2771]: loss 1.020163
[epoch15, step2772]: loss 2.357406
[epoch15, step2773]: loss 12.186909
[epoch15, step2774]: loss 1.455184
[epoch15, step2775]: loss 1.148476
[epoch15, step2776]: loss 0.881696
[epoch15, step2777]: loss 7.994845
[epoch15, step2778]: loss 0.706415
[epoch15, step2779]: loss 0.644996
[epoch15, step2780]: loss 1.181655
[epoch15, step2781]: loss 7.945315
[epoch15, step2782]: loss 9.805317
[epoch15, step2783]: loss 6.151666
[epoch15, step2784]: loss 1.754573
[epoch15, step2785]: loss 1.051484
[epoch15, step2786]: loss 7.696228
[epoch15, step2787]: loss 7.151299
[epoch15, step2788]: loss 0.842693
[epoch15, step2789]: loss 0.890638
[epoch15, step2790]: loss 0.835278
[epoch15, step2791]: loss 1.255557
[epoch15, step2792]: loss 0.674510
[epoch15, step2793]: loss 1.256016
[epoch15, step2794]: loss 1.605545
[epoch15, step2795]: loss 4.183457
[epoch15, step2796]: loss 8.800815
[epoch15, step2797]: loss 4.870619
[epoch15, step2798]: loss 1.922530
[epoch15, step2799]: loss 0.942984
[epoch15, step2800]: loss 0.696929
[epoch15, step2801]: loss 1.161108
[epoch15, step2802]: loss 10.285811
[epoch15, step2803]: loss 1.356745
[epoch15, step2804]: loss 1.145940
[epoch15, step2805]: loss 5.510802
[epoch15, step2806]: loss 3.853777
[epoch15, step2807]: loss 0.554513
[epoch15, step2808]: loss 7.070050
[epoch15, step2809]: loss 1.010287
[epoch15, step2810]: loss 2.912848
[epoch15, step2811]: loss 1.360352
[epoch15, step2812]: loss 4.189013
[epoch15, step2813]: loss 0.888058
[epoch15, step2814]: loss 8.771585
[epoch15, step2815]: loss 1.015591
[epoch15, step2816]: loss 14.124063
[epoch15, step2817]: loss 0.856696
[epoch15, step2818]: loss 1.403351
[epoch15, step2819]: loss 1.514507
[epoch15, step2820]: loss 0.987151
[epoch15, step2821]: loss 1.357147
[epoch15, step2822]: loss 1.818158
[epoch15, step2823]: loss 2.295333
[epoch15, step2824]: loss 2.374277
[epoch15, step2825]: loss 7.190997
[epoch15, step2826]: loss 1.021905
[epoch15, step2827]: loss 1.469825
[epoch15, step2828]: loss 1.524168
[epoch15, step2829]: loss 0.578656
[epoch15, step2830]: loss 15.424829
[epoch15, step2831]: loss 1.312910
[epoch15, step2832]: loss 2.675805
[epoch15, step2833]: loss 9.178478
[epoch15, step2834]: loss 10.914439
[epoch15, step2835]: loss 1.356174
[epoch15, step2836]: loss 1.240001
[epoch15, step2837]: loss 5.603443
[epoch15, step2838]: loss 0.782784
[epoch15, step2839]: loss 1.098277
[epoch15, step2840]: loss 3.984798
[epoch15, step2841]: loss 3.793411
[epoch15, step2842]: loss 7.228935
[epoch15, step2843]: loss 0.650867
[epoch15, step2844]: loss 0.733807
[epoch15, step2845]: loss 4.274720
[epoch15, step2846]: loss 6.005179
[epoch15, step2847]: loss 1.792696
[epoch15, step2848]: loss 11.661287
[epoch15, step2849]: loss 8.598770
[epoch15, step2850]: loss 15.030169
[epoch15, step2851]: loss 1.570599
[epoch15, step2852]: loss 4.079965
[epoch15, step2853]: loss 14.025322
[epoch15, step2854]: loss 1.146009
[epoch15, step2855]: loss 5.332494
[epoch15, step2856]: loss 1.666831
[epoch15, step2857]: loss 6.931864
[epoch15, step2858]: loss 0.916968
[epoch15, step2859]: loss 1.603605
[epoch15, step2860]: loss 11.081120
[epoch15, step2861]: loss 7.965375
[epoch15, step2862]: loss 0.816567
[epoch15, step2863]: loss 12.646462
[epoch15, step2864]: loss 1.040895
[epoch15, step2865]: loss 10.354931
[epoch15, step2866]: loss 8.061651
[epoch15, step2867]: loss 11.955311
[epoch15, step2868]: loss 0.874680
[epoch15, step2869]: loss 9.639729
[epoch15, step2870]: loss 6.670388
[epoch15, step2871]: loss 0.606768
[epoch15, step2872]: loss 7.240232
[epoch15, step2873]: loss 1.685917
[epoch15, step2874]: loss 1.175620
[epoch15, step2875]: loss 7.266682
[epoch15, step2876]: loss 9.016967
[epoch15, step2877]: loss 0.751930
[epoch15, step2878]: loss 15.277162
[epoch15, step2879]: loss 4.040420
[epoch15, step2880]: loss 2.924085
[epoch15, step2881]: loss 0.910304
[epoch15, step2882]: loss 16.399576
[epoch15, step2883]: loss 0.985943
[epoch15, step2884]: loss 9.055657
[epoch15, step2885]: loss 1.040840
[epoch15, step2886]: loss 5.270193
[epoch15, step2887]: loss 17.700098
[epoch15, step2888]: loss 12.717552
[epoch15, step2889]: loss 1.780261
[epoch15, step2890]: loss 8.705890
[epoch15, step2891]: loss 1.763627
[epoch15, step2892]: loss 6.183106
[epoch15, step2893]: loss 5.904549
[epoch15, step2894]: loss 11.902052
[epoch15, step2895]: loss 8.531543
[epoch15, step2896]: loss 11.236038
[epoch15, step2897]: loss 2.842831
[epoch15, step2898]: loss 1.456004
[epoch15, step2899]: loss 0.550630
[epoch15, step2900]: loss 8.165303
[epoch15, step2901]: loss 9.304382
[epoch15, step2902]: loss 5.551222
[epoch15, step2903]: loss 1.324357
[epoch15, step2904]: loss 9.169690
[epoch15, step2905]: loss 2.174279
[epoch15, step2906]: loss 1.947437
[epoch15, step2907]: loss 0.614355
[epoch15, step2908]: loss 8.394400
[epoch15, step2909]: loss 3.152230
[epoch15, step2910]: loss 12.444790
[epoch15, step2911]: loss 1.268639
[epoch15, step2912]: loss 2.350550
[epoch15, step2913]: loss 1.380292
[epoch15, step2914]: loss 4.822632
[epoch15, step2915]: loss 1.129035
[epoch15, step2916]: loss 2.376049
[epoch15, step2917]: loss 18.370953
[epoch15, step2918]: loss 23.272192
[epoch15, step2919]: loss 0.775888
[epoch15, step2920]: loss 3.104034
[epoch15, step2921]: loss 0.867696
[epoch15, step2922]: loss 1.551418
[epoch15, step2923]: loss 2.962231
[epoch15, step2924]: loss 2.143640
[epoch15, step2925]: loss 8.392006
[epoch15, step2926]: loss 1.339474
[epoch15, step2927]: loss 13.207378
[epoch15, step2928]: loss 3.226562
[epoch15, step2929]: loss 0.762456
[epoch15, step2930]: loss 13.552749
[epoch15, step2931]: loss 0.889566
[epoch15, step2932]: loss 1.446843
[epoch15, step2933]: loss 8.485815
[epoch15, step2934]: loss 4.228940
[epoch15, step2935]: loss 1.369685
[epoch15, step2936]: loss 0.900395
[epoch15, step2937]: loss 4.771471
[epoch15, step2938]: loss 7.265598
[epoch15, step2939]: loss 7.300696
[epoch15, step2940]: loss 1.881256
[epoch15, step2941]: loss 16.525700
[epoch15, step2942]: loss 13.524363
[epoch15, step2943]: loss 0.642340
[epoch15, step2944]: loss 4.252338
[epoch15, step2945]: loss 2.416824
[epoch15, step2946]: loss 6.865098
[epoch15, step2947]: loss 1.179218
[epoch15, step2948]: loss 1.463398
[epoch15, step2949]: loss 0.782785
[epoch15, step2950]: loss 1.481529
[epoch15, step2951]: loss 1.731752
[epoch15, step2952]: loss 4.345565
[epoch15, step2953]: loss 13.133833
[epoch15, step2954]: loss 8.755955
[epoch15, step2955]: loss 20.220047
[epoch15, step2956]: loss 2.399604
[epoch15, step2957]: loss 13.061323
[epoch15, step2958]: loss 1.126984
[epoch15, step2959]: loss 6.789956
[epoch15, step2960]: loss 3.122840
[epoch15, step2961]: loss 8.062213
[epoch15, step2962]: loss 1.376094
[epoch15, step2963]: loss 1.592174
[epoch15, step2964]: loss 1.276867
[epoch15, step2965]: loss 2.366441
[epoch15, step2966]: loss 1.493546
[epoch15, step2967]: loss 0.612132
[epoch15, step2968]: loss 3.887436
[epoch15, step2969]: loss 3.808870
[epoch15, step2970]: loss 1.051641
[epoch15, step2971]: loss 6.613099
[epoch15, step2972]: loss 2.758933
[epoch15, step2973]: loss 8.457858
[epoch15, step2974]: loss 0.961716
[epoch15, step2975]: loss 1.022832
[epoch15, step2976]: loss 2.394448
[epoch15, step2977]: loss 2.309054
[epoch15, step2978]: loss 6.722517
[epoch15, step2979]: loss 1.598282
[epoch15, step2980]: loss 9.098473
[epoch15, step2981]: loss 11.837360
[epoch15, step2982]: loss 0.919511
[epoch15, step2983]: loss 3.169657
[epoch15, step2984]: loss 3.718541
[epoch15, step2985]: loss 2.843894
[epoch15, step2986]: loss 0.516818
[epoch15, step2987]: loss 0.765620
[epoch15, step2988]: loss 12.929233
[epoch15, step2989]: loss 2.727443
[epoch15, step2990]: loss 8.874022
[epoch15, step2991]: loss 1.195618
[epoch15, step2992]: loss 2.691749
[epoch15, step2993]: loss 2.046510
[epoch15, step2994]: loss 0.740831
[epoch15, step2995]: loss 1.308800
[epoch15, step2996]: loss 1.486469
[epoch15, step2997]: loss 3.368680
[epoch15, step2998]: loss 10.686949
[epoch15, step2999]: loss 11.595065
[epoch15, step3000]: loss 0.729223
[epoch15, step3001]: loss 0.650543
[epoch15, step3002]: loss 2.022779
[epoch15, step3003]: loss 1.134725
[epoch15, step3004]: loss 2.302721
[epoch15, step3005]: loss 6.560308
[epoch15, step3006]: loss 1.075866
[epoch15, step3007]: loss 1.537144
[epoch15, step3008]: loss 9.522936
[epoch15, step3009]: loss 16.521793
[epoch15, step3010]: loss 0.640525
[epoch15, step3011]: loss 1.863536
[epoch15, step3012]: loss 0.911137
[epoch15, step3013]: loss 1.040316
[epoch15, step3014]: loss 2.348068
[epoch15, step3015]: loss 1.310223
[epoch15, step3016]: loss 0.803068
[epoch15, step3017]: loss 6.565758
[epoch15, step3018]: loss 2.380169
[epoch15, step3019]: loss 1.439011
[epoch15, step3020]: loss 4.590938
[epoch15, step3021]: loss 6.197252
[epoch15, step3022]: loss 4.856152
[epoch15, step3023]: loss 0.796051
[epoch15, step3024]: loss 11.600153
[epoch15, step3025]: loss 0.936063
[epoch15, step3026]: loss 0.785720
[epoch15, step3027]: loss 2.033537
[epoch15, step3028]: loss 1.000006
[epoch15, step3029]: loss 0.904492
[epoch15, step3030]: loss 2.913532
[epoch15, step3031]: loss 2.844237
[epoch15, step3032]: loss 1.070894
[epoch15, step3033]: loss 1.329969
[epoch15, step3034]: loss 13.866378
[epoch15, step3035]: loss 1.015008
[epoch15, step3036]: loss 7.114193
[epoch15, step3037]: loss 1.016007
[epoch15, step3038]: loss 26.471058
[epoch15, step3039]: loss 5.174206
[epoch15, step3040]: loss 1.445384
[epoch15, step3041]: loss 0.694745
[epoch15, step3042]: loss 1.283560
[epoch15, step3043]: loss 0.860404
[epoch15, step3044]: loss 2.141679
[epoch15, step3045]: loss 13.181219
[epoch15, step3046]: loss 0.749114
[epoch15, step3047]: loss 9.412612
[epoch15, step3048]: loss 9.451801
[epoch15, step3049]: loss 14.502998
[epoch15, step3050]: loss 1.768973
[epoch15, step3051]: loss 2.833467
[epoch15, step3052]: loss 0.904645
[epoch15, step3053]: loss 6.072872
[epoch15, step3054]: loss 2.947925
[epoch15, step3055]: loss 0.853050
[epoch15, step3056]: loss 0.882538
[epoch15, step3057]: loss 0.561875
[epoch15, step3058]: loss 1.567840
[epoch15, step3059]: loss 6.260321
[epoch15, step3060]: loss 7.736645
[epoch15, step3061]: loss 1.118705
[epoch15, step3062]: loss 2.840126
[epoch15, step3063]: loss 1.790144
[epoch15, step3064]: loss 0.988185
[epoch15, step3065]: loss 2.681425
[epoch15, step3066]: loss 7.090187
[epoch15, step3067]: loss 2.265059
[epoch15, step3068]: loss 0.543958
[epoch15, step3069]: loss 0.544822
[epoch15, step3070]: loss 8.086333
[epoch15, step3071]: loss 0.832715
[epoch15, step3072]: loss 11.047132
[epoch15, step3073]: loss 1.390769
[epoch15, step3074]: loss 0.713138
[epoch15, step3075]: loss 8.382884
[epoch15, step3076]: loss 12.994850

[epoch15]: avg loss 12.994850

[epoch16, step1]: loss 1.303457
[epoch16, step2]: loss 13.531150
[epoch16, step3]: loss 2.425233
[epoch16, step4]: loss 1.320390
[epoch16, step5]: loss 1.821461
[epoch16, step6]: loss 5.929876
[epoch16, step7]: loss 0.804899
[epoch16, step8]: loss 2.838408
[epoch16, step9]: loss 1.244276
[epoch16, step10]: loss 0.625896
[epoch16, step11]: loss 1.874467
[epoch16, step12]: loss 2.708625
[epoch16, step13]: loss 2.909349
[epoch16, step14]: loss 2.733834
[epoch16, step15]: loss 8.588003
[epoch16, step16]: loss 0.903168
[epoch16, step17]: loss 1.610009
[epoch16, step18]: loss 1.022321
[epoch16, step19]: loss 6.130718
[epoch16, step20]: loss 3.167384
[epoch16, step21]: loss 0.900172
[epoch16, step22]: loss 1.948754
[epoch16, step23]: loss 18.752232
[epoch16, step24]: loss 1.193692
[epoch16, step25]: loss 3.212199
[epoch16, step26]: loss 1.193752
[epoch16, step27]: loss 0.903183
[epoch16, step28]: loss 9.443245
[epoch16, step29]: loss 2.867124
[epoch16, step30]: loss 1.963229
[epoch16, step31]: loss 8.849092
[epoch16, step32]: loss 1.318986
[epoch16, step33]: loss 0.666100
[epoch16, step34]: loss 0.784849
[epoch16, step35]: loss 2.642633
[epoch16, step36]: loss 1.910001
[epoch16, step37]: loss 0.535567
[epoch16, step38]: loss 11.152264
[epoch16, step39]: loss 1.111016
[epoch16, step40]: loss 0.933554
[epoch16, step41]: loss 5.161807
[epoch16, step42]: loss 6.528601
[epoch16, step43]: loss 5.589998
[epoch16, step44]: loss 0.645956
[epoch16, step45]: loss 1.394125
[epoch16, step46]: loss 1.392380
[epoch16, step47]: loss 0.693017
[epoch16, step48]: loss 8.305367
[epoch16, step49]: loss 8.040732
[epoch16, step50]: loss 2.751563
[epoch16, step51]: loss 1.104138
[epoch16, step52]: loss 3.627046
[epoch16, step53]: loss 11.231639
[epoch16, step54]: loss 5.160882
[epoch16, step55]: loss 12.802085
[epoch16, step56]: loss 0.987089
[epoch16, step57]: loss 0.961159
[epoch16, step58]: loss 1.087385
[epoch16, step59]: loss 4.995976
[epoch16, step60]: loss 6.565551
[epoch16, step61]: loss 1.264801
[epoch16, step62]: loss 8.543946
[epoch16, step63]: loss 0.804330
[epoch16, step64]: loss 0.823553
[epoch16, step65]: loss 3.282361
[epoch16, step66]: loss 4.416184
[epoch16, step67]: loss 25.300039
[epoch16, step68]: loss 11.345201
[epoch16, step69]: loss 7.294028
[epoch16, step70]: loss 7.836586
[epoch16, step71]: loss 1.154725
[epoch16, step72]: loss 0.895144
[epoch16, step73]: loss 14.528188
[epoch16, step74]: loss 0.852803
[epoch16, step75]: loss 1.150330
[epoch16, step76]: loss 12.730918
[epoch16, step77]: loss 1.075888
[epoch16, step78]: loss 0.826950
[epoch16, step79]: loss 1.380923
[epoch16, step80]: loss 1.127631
[epoch16, step81]: loss 0.563980
[epoch16, step82]: loss 6.217309
[epoch16, step83]: loss 2.007535
[epoch16, step84]: loss 0.958984
[epoch16, step85]: loss 2.192242
[epoch16, step86]: loss 0.894037
[epoch16, step87]: loss 1.928955
[epoch16, step88]: loss 3.334230
[epoch16, step89]: loss 5.516759
[epoch16, step90]: loss 0.732351
[epoch16, step91]: loss 0.876714
[epoch16, step92]: loss 12.402384
[epoch16, step93]: loss 0.528243
[epoch16, step94]: loss 5.309349
[epoch16, step95]: loss 9.270812
[epoch16, step96]: loss 0.909642
[epoch16, step97]: loss 1.693968
[epoch16, step98]: loss 7.758235
[epoch16, step99]: loss 4.632223
[epoch16, step100]: loss 0.532334
[epoch16, step101]: loss 5.037839
[epoch16, step102]: loss 8.554404
[epoch16, step103]: loss 8.585748
[epoch16, step104]: loss 0.806411
[epoch16, step105]: loss 5.212119
[epoch16, step106]: loss 0.928255
[epoch16, step107]: loss 1.056720
[epoch16, step108]: loss 1.169723
[epoch16, step109]: loss 1.159032
[epoch16, step110]: loss 7.547480
[epoch16, step111]: loss 1.350014
[epoch16, step112]: loss 2.473545
[epoch16, step113]: loss 2.488037
[epoch16, step114]: loss 7.418363
[epoch16, step115]: loss 1.452474
[epoch16, step116]: loss 1.295071
[epoch16, step117]: loss 1.559538
[epoch16, step118]: loss 1.030131
[epoch16, step119]: loss 3.124200
[epoch16, step120]: loss 1.126300
[epoch16, step121]: loss 3.457069
[epoch16, step122]: loss 4.954159
[epoch16, step123]: loss 13.019966
[epoch16, step124]: loss 0.774334
[epoch16, step125]: loss 1.389948
[epoch16, step126]: loss 8.534598
[epoch16, step127]: loss 3.339308
[epoch16, step128]: loss 1.046660
[epoch16, step129]: loss 0.586083
[epoch16, step130]: loss 9.154251
[epoch16, step131]: loss 2.593053
[epoch16, step132]: loss 3.199822
[epoch16, step133]: loss 0.756075
[epoch16, step134]: loss 0.697480
[epoch16, step135]: loss 2.980759
[epoch16, step136]: loss 5.359368
[epoch16, step137]: loss 4.075288
[epoch16, step138]: loss 0.872393
[epoch16, step139]: loss 1.000349
[epoch16, step140]: loss 10.877352
[epoch16, step141]: loss 2.326372
[epoch16, step142]: loss 11.354850
[epoch16, step143]: loss 0.954891
[epoch16, step144]: loss 0.579994
[epoch16, step145]: loss 1.211106
[epoch16, step146]: loss 5.485036
[epoch16, step147]: loss 6.756450
[epoch16, step148]: loss 13.693687
[epoch16, step149]: loss 8.009356
[epoch16, step150]: loss 9.993953
[epoch16, step151]: loss 1.017933
[epoch16, step152]: loss 2.123566
[epoch16, step153]: loss 28.442430
[epoch16, step154]: loss 6.860227
[epoch16, step155]: loss 1.052915
[epoch16, step156]: loss 0.636106
[epoch16, step157]: loss 1.807807
[epoch16, step158]: loss 14.141712
[epoch16, step159]: loss 0.771401
[epoch16, step160]: loss 0.817033
[epoch16, step161]: loss 2.746114
[epoch16, step162]: loss 1.011553
[epoch16, step163]: loss 1.407974
[epoch16, step164]: loss 0.894747
[epoch16, step165]: loss 13.170767
[epoch16, step166]: loss 2.592575
[epoch16, step167]: loss 12.655241
[epoch16, step168]: loss 1.036162
[epoch16, step169]: loss 3.142119
[epoch16, step170]: loss 7.254395
[epoch16, step171]: loss 9.498915
[epoch16, step172]: loss 0.961054
[epoch16, step173]: loss 1.008212
[epoch16, step174]: loss 1.538441
[epoch16, step175]: loss 7.071265
[epoch16, step176]: loss 9.328063
[epoch16, step177]: loss 1.020480
[epoch16, step178]: loss 1.542914
[epoch16, step179]: loss 1.129648
[epoch16, step180]: loss 1.596829
[epoch16, step181]: loss 2.378520
[epoch16, step182]: loss 7.939111
[epoch16, step183]: loss 15.750080
[epoch16, step184]: loss 9.581691
[epoch16, step185]: loss 5.973461
[epoch16, step186]: loss 1.612652
[epoch16, step187]: loss 6.475685
[epoch16, step188]: loss 0.757883
[epoch16, step189]: loss 0.906231
[epoch16, step190]: loss 2.461324
[epoch16, step191]: loss 3.186149
[epoch16, step192]: loss 1.485791
[epoch16, step193]: loss 1.142069
[epoch16, step194]: loss 2.205531
[epoch16, step195]: loss 7.862555
[epoch16, step196]: loss 1.296070
[epoch16, step197]: loss 9.578444
[epoch16, step198]: loss 1.002297
[epoch16, step199]: loss 1.652992
[epoch16, step200]: loss 18.470770
[epoch16, step201]: loss 1.100458
[epoch16, step202]: loss 1.617512
[epoch16, step203]: loss 2.765316
[epoch16, step204]: loss 2.824053
[epoch16, step205]: loss 2.702737
[epoch16, step206]: loss 0.752615
[epoch16, step207]: loss 0.759717
[epoch16, step208]: loss 0.967316
[epoch16, step209]: loss 1.239970
[epoch16, step210]: loss 15.589162
[epoch16, step211]: loss 0.842100
[epoch16, step212]: loss 3.180813
[epoch16, step213]: loss 1.401948
[epoch16, step214]: loss 2.223824
[epoch16, step215]: loss 0.954213
[epoch16, step216]: loss 7.719951
[epoch16, step217]: loss 0.920653
[epoch16, step218]: loss 7.403844
[epoch16, step219]: loss 1.325689
[epoch16, step220]: loss 0.582251
[epoch16, step221]: loss 2.390265
[epoch16, step222]: loss 2.079746
[epoch16, step223]: loss 8.923592
[epoch16, step224]: loss 0.643446
[epoch16, step225]: loss 1.460936
[epoch16, step226]: loss 8.678484
[epoch16, step227]: loss 1.811981
[epoch16, step228]: loss 0.648903
[epoch16, step229]: loss 0.586885
[epoch16, step230]: loss 0.838499
[epoch16, step231]: loss 1.613003
[epoch16, step232]: loss 2.722442
[epoch16, step233]: loss 0.814570
[epoch16, step234]: loss 0.694889
[epoch16, step235]: loss 4.667292
[epoch16, step236]: loss 1.383137
[epoch16, step237]: loss 7.407569
[epoch16, step238]: loss 4.259961
[epoch16, step239]: loss 0.767151
[epoch16, step240]: loss 1.141015
[epoch16, step241]: loss 0.654484
[epoch16, step242]: loss 6.578499
[epoch16, step243]: loss 5.455937
[epoch16, step244]: loss 1.147496
[epoch16, step245]: loss 1.869119
[epoch16, step246]: loss 3.995209
[epoch16, step247]: loss 1.763474
[epoch16, step248]: loss 2.156826
[epoch16, step249]: loss 1.444623
[epoch16, step250]: loss 1.882616
[epoch16, step251]: loss 0.675369
[epoch16, step252]: loss 2.121366
[epoch16, step253]: loss 1.309354
[epoch16, step254]: loss 1.076090
[epoch16, step255]: loss 11.539344
[epoch16, step256]: loss 0.621604
[epoch16, step257]: loss 1.275892
[epoch16, step258]: loss 1.233130
[epoch16, step259]: loss 11.076999
[epoch16, step260]: loss 0.713940
[epoch16, step261]: loss 2.943002
[epoch16, step262]: loss 1.019092
[epoch16, step263]: loss 2.452115
[epoch16, step264]: loss 0.861036
[epoch16, step265]: loss 4.625453
[epoch16, step266]: loss 0.807880
[epoch16, step267]: loss 9.835208
[epoch16, step268]: loss 0.982666
[epoch16, step269]: loss 0.771988
[epoch16, step270]: loss 7.412665
[epoch16, step271]: loss 1.039257
[epoch16, step272]: loss 10.330250
[epoch16, step273]: loss 2.284969
[epoch16, step274]: loss 1.946017
[epoch16, step275]: loss 1.204323
[epoch16, step276]: loss 2.182565
[epoch16, step277]: loss 4.504081
[epoch16, step278]: loss 1.144779
[epoch16, step279]: loss 1.200476
[epoch16, step280]: loss 2.323219
[epoch16, step281]: loss 0.812660
[epoch16, step282]: loss 1.360409
[epoch16, step283]: loss 0.720621
[epoch16, step284]: loss 1.138810
[epoch16, step285]: loss 1.058055
[epoch16, step286]: loss 2.739073
[epoch16, step287]: loss 2.174350
[epoch16, step288]: loss 6.960280
[epoch16, step289]: loss 0.855002
[epoch16, step290]: loss 0.835654
[epoch16, step291]: loss 0.768012
[epoch16, step292]: loss 0.787503
[epoch16, step293]: loss 1.036004
[epoch16, step294]: loss 13.815163
[epoch16, step295]: loss 7.685963
[epoch16, step296]: loss 10.942193
[epoch16, step297]: loss 0.515781
[epoch16, step298]: loss 0.738727
[epoch16, step299]: loss 1.610690
[epoch16, step300]: loss 5.513296
[epoch16, step301]: loss 0.907828
[epoch16, step302]: loss 0.784064
[epoch16, step303]: loss 11.669960
[epoch16, step304]: loss 3.129177
[epoch16, step305]: loss 2.304358
[epoch16, step306]: loss 1.780614
[epoch16, step307]: loss 0.703423
[epoch16, step308]: loss 0.632478
[epoch16, step309]: loss 1.010875
[epoch16, step310]: loss 1.157337
[epoch16, step311]: loss 12.232965
[epoch16, step312]: loss 10.866787
[epoch16, step313]: loss 3.305443
[epoch16, step314]: loss 11.496578
[epoch16, step315]: loss 4.920083
[epoch16, step316]: loss 2.902958
[epoch16, step317]: loss 0.817473
[epoch16, step318]: loss 9.130978
[epoch16, step319]: loss 1.088505
[epoch16, step320]: loss 3.030507
[epoch16, step321]: loss 14.780178
[epoch16, step322]: loss 2.954425
[epoch16, step323]: loss 2.127828
[epoch16, step324]: loss 1.277177
[epoch16, step325]: loss 14.008418
[epoch16, step326]: loss 0.992163
[epoch16, step327]: loss 0.696138
[epoch16, step328]: loss 3.445312
[epoch16, step329]: loss 2.351504
[epoch16, step330]: loss 11.888226
[epoch16, step331]: loss 0.842797
[epoch16, step332]: loss 8.296726
[epoch16, step333]: loss 0.752325
[epoch16, step334]: loss 2.895653
[epoch16, step335]: loss 1.164951
[epoch16, step336]: loss 7.897502
[epoch16, step337]: loss 1.099003
[epoch16, step338]: loss 7.146829
[epoch16, step339]: loss 0.820449
[epoch16, step340]: loss 0.752431
[epoch16, step341]: loss 0.743759
[epoch16, step342]: loss 0.931794
[epoch16, step343]: loss 8.126370
[epoch16, step344]: loss 1.567467
[epoch16, step345]: loss 2.603068
[epoch16, step346]: loss 2.589157
[epoch16, step347]: loss 8.593430
[epoch16, step348]: loss 0.922867
[epoch16, step349]: loss 0.807200
[epoch16, step350]: loss 8.297485
[epoch16, step351]: loss 0.657146
[epoch16, step352]: loss 9.496473
[epoch16, step353]: loss 0.648444
[epoch16, step354]: loss 9.649052
[epoch16, step355]: loss 0.881541
[epoch16, step356]: loss 5.267072
[epoch16, step357]: loss 17.824032
[epoch16, step358]: loss 0.741090
[epoch16, step359]: loss 0.614294
[epoch16, step360]: loss 1.063606
[epoch16, step361]: loss 9.238602
[epoch16, step362]: loss 0.781891
[epoch16, step363]: loss 0.689062
[epoch16, step364]: loss 1.039620
[epoch16, step365]: loss 6.332679
[epoch16, step366]: loss 8.390112
[epoch16, step367]: loss 1.114532
[epoch16, step368]: loss 1.505052
[epoch16, step369]: loss 5.747690
[epoch16, step370]: loss 12.064221
[epoch16, step371]: loss 4.271348
[epoch16, step372]: loss 1.556190
[epoch16, step373]: loss 0.795898
[epoch16, step374]: loss 0.747067
[epoch16, step375]: loss 6.772432
[epoch16, step376]: loss 1.191380
[epoch16, step377]: loss 2.654284
[epoch16, step378]: loss 0.839502
[epoch16, step379]: loss 4.584198
[epoch16, step380]: loss 1.868817
[epoch16, step381]: loss 13.204211
[epoch16, step382]: loss 10.098493
[epoch16, step383]: loss 4.242953
[epoch16, step384]: loss 8.576618
[epoch16, step385]: loss 17.278658
[epoch16, step386]: loss 4.476852
[epoch16, step387]: loss 1.313148
[epoch16, step388]: loss 2.826755
[epoch16, step389]: loss 0.694577
[epoch16, step390]: loss 3.431798
[epoch16, step391]: loss 9.555047
[epoch16, step392]: loss 8.330638
[epoch16, step393]: loss 1.035060
[epoch16, step394]: loss 1.595238
[epoch16, step395]: loss 1.121043
[epoch16, step396]: loss 1.231589
[epoch16, step397]: loss 0.816445
[epoch16, step398]: loss 16.942894
[epoch16, step399]: loss 0.720073
[epoch16, step400]: loss 6.183591
[epoch16, step401]: loss 1.198573
[epoch16, step402]: loss 20.346287
[epoch16, step403]: loss 2.899793
[epoch16, step404]: loss 0.858334
[epoch16, step405]: loss 6.131346
[epoch16, step406]: loss 1.335046
[epoch16, step407]: loss 1.233573
[epoch16, step408]: loss 2.776641
[epoch16, step409]: loss 1.706151
[epoch16, step410]: loss 2.627408
[epoch16, step411]: loss 0.793736
[epoch16, step412]: loss 12.252166
[epoch16, step413]: loss 1.527270
[epoch16, step414]: loss 1.583324
[epoch16, step415]: loss 8.415451
[epoch16, step416]: loss 2.620082
[epoch16, step417]: loss 10.351911
[epoch16, step418]: loss 1.013219
[epoch16, step419]: loss 0.898807
[epoch16, step420]: loss 7.296501
[epoch16, step421]: loss 0.991803
[epoch16, step422]: loss 1.752625
[epoch16, step423]: loss 12.499269
[epoch16, step424]: loss 1.014250
[epoch16, step425]: loss 1.518482
[epoch16, step426]: loss 5.634579
[epoch16, step427]: loss 6.869808
[epoch16, step428]: loss 1.526909
[epoch16, step429]: loss 2.561994
[epoch16, step430]: loss 6.116642
[epoch16, step431]: loss 0.727632
[epoch16, step432]: loss 11.332118
[epoch16, step433]: loss 0.856124
[epoch16, step434]: loss 0.935395
[epoch16, step435]: loss 6.767112
[epoch16, step436]: loss 0.850637
[epoch16, step437]: loss 1.103352
[epoch16, step438]: loss 0.933518
[epoch16, step439]: loss 0.750172
[epoch16, step440]: loss 1.160716
[epoch16, step441]: loss 1.141286
[epoch16, step442]: loss 8.992544
[epoch16, step443]: loss 7.249546
[epoch16, step444]: loss 1.493911
[epoch16, step445]: loss 1.588755
[epoch16, step446]: loss 1.293272
[epoch16, step447]: loss 21.728279
[epoch16, step448]: loss 2.615062
[epoch16, step449]: loss 10.207717
[epoch16, step450]: loss 8.018874
[epoch16, step451]: loss 0.630532
[epoch16, step452]: loss 0.572885
[epoch16, step453]: loss 2.493089
[epoch16, step454]: loss 0.922144
[epoch16, step455]: loss 2.234922
[epoch16, step456]: loss 9.531893
[epoch16, step457]: loss 1.322870
[epoch16, step458]: loss 1.218096
[epoch16, step459]: loss 3.010690
[epoch16, step460]: loss 0.700081
[epoch16, step461]: loss 1.568852
[epoch16, step462]: loss 4.455016
[epoch16, step463]: loss 0.847393
[epoch16, step464]: loss 7.758888
[epoch16, step465]: loss 0.784070
[epoch16, step466]: loss 0.929083
[epoch16, step467]: loss 8.532838
[epoch16, step468]: loss 0.755314
[epoch16, step469]: loss 0.576530
[epoch16, step470]: loss 1.462280
[epoch16, step471]: loss 2.994740
[epoch16, step472]: loss 0.898163
[epoch16, step473]: loss 5.929445
[epoch16, step474]: loss 1.122302
[epoch16, step475]: loss 2.004634
[epoch16, step476]: loss 0.930252
[epoch16, step477]: loss 1.274422
[epoch16, step478]: loss 2.666363
[epoch16, step479]: loss 0.738344
[epoch16, step480]: loss 3.546593
[epoch16, step481]: loss 1.486299
[epoch16, step482]: loss 0.735611
[epoch16, step483]: loss 1.117977
[epoch16, step484]: loss 1.163994
[epoch16, step485]: loss 1.744365
[epoch16, step486]: loss 0.470851
[epoch16, step487]: loss 2.373175
[epoch16, step488]: loss 13.791346
[epoch16, step489]: loss 0.920553
[epoch16, step490]: loss 9.662942
[epoch16, step491]: loss 0.742463
[epoch16, step492]: loss 2.215113
[epoch16, step493]: loss 1.493532
[epoch16, step494]: loss 6.322239
[epoch16, step495]: loss 1.670137
[epoch16, step496]: loss 1.015329
[epoch16, step497]: loss 2.222947
[epoch16, step498]: loss 1.939474
[epoch16, step499]: loss 7.307159
[epoch16, step500]: loss 2.208920
[epoch16, step501]: loss 0.599322
[epoch16, step502]: loss 1.466330
[epoch16, step503]: loss 1.928311
[epoch16, step504]: loss 1.009525
[epoch16, step505]: loss 2.275224
[epoch16, step506]: loss 1.612864
[epoch16, step507]: loss 11.478816
[epoch16, step508]: loss 1.632314
[epoch16, step509]: loss 2.448472
[epoch16, step510]: loss 3.931647
[epoch16, step511]: loss 10.067130
[epoch16, step512]: loss 1.633058
[epoch16, step513]: loss 0.988043
[epoch16, step514]: loss 6.287670
[epoch16, step515]: loss 0.760443
[epoch16, step516]: loss 0.942000
[epoch16, step517]: loss 2.150847
[epoch16, step518]: loss 3.256325
[epoch16, step519]: loss 2.452601
[epoch16, step520]: loss 0.937155
[epoch16, step521]: loss 1.737653
[epoch16, step522]: loss 5.606835
[epoch16, step523]: loss 2.698366
[epoch16, step524]: loss 8.836035
[epoch16, step525]: loss 12.266131
[epoch16, step526]: loss 6.853932
[epoch16, step527]: loss 0.732061
[epoch16, step528]: loss 2.400671
[epoch16, step529]: loss 0.636040
[epoch16, step530]: loss 2.430092
[epoch16, step531]: loss 3.428261
[epoch16, step532]: loss 1.819685
[epoch16, step533]: loss 2.632427
[epoch16, step534]: loss 15.798993
[epoch16, step535]: loss 1.477678
[epoch16, step536]: loss 1.089233
[epoch16, step537]: loss 1.235292
[epoch16, step538]: loss 0.708694
[epoch16, step539]: loss 13.245852
[epoch16, step540]: loss 0.707017
[epoch16, step541]: loss 0.522566
[epoch16, step542]: loss 1.221225
[epoch16, step543]: loss 0.758770
[epoch16, step544]: loss 6.416284
[epoch16, step545]: loss 4.220890
[epoch16, step546]: loss 10.311319
[epoch16, step547]: loss 1.686889
[epoch16, step548]: loss 7.237579
[epoch16, step549]: loss 1.898914
[epoch16, step550]: loss 0.687376
[epoch16, step551]: loss 1.661905
[epoch16, step552]: loss 8.401252
[epoch16, step553]: loss 3.479887
[epoch16, step554]: loss 0.765701
[epoch16, step555]: loss 3.778491
[epoch16, step556]: loss 0.712801
[epoch16, step557]: loss 3.231310
[epoch16, step558]: loss 1.166724
[epoch16, step559]: loss 1.336899
[epoch16, step560]: loss 1.006127
[epoch16, step561]: loss 1.125171
[epoch16, step562]: loss 2.822829
[epoch16, step563]: loss 1.145021
[epoch16, step564]: loss 2.691106
[epoch16, step565]: loss 2.746699
[epoch16, step566]: loss 0.786503
[epoch16, step567]: loss 1.218216
[epoch16, step568]: loss 0.941857
[epoch16, step569]: loss 1.973474
[epoch16, step570]: loss 0.779805
[epoch16, step571]: loss 2.113215
[epoch16, step572]: loss 0.740585
[epoch16, step573]: loss 3.095999
[epoch16, step574]: loss 11.608003
[epoch16, step575]: loss 5.726751
[epoch16, step576]: loss 0.755798
[epoch16, step577]: loss 2.207524
[epoch16, step578]: loss 1.388850
[epoch16, step579]: loss 1.679405
[epoch16, step580]: loss 1.146462
[epoch16, step581]: loss 1.098322
[epoch16, step582]: loss 2.391167
[epoch16, step583]: loss 2.849594
[epoch16, step584]: loss 6.616359
[epoch16, step585]: loss 2.995409
[epoch16, step586]: loss 1.406706
[epoch16, step587]: loss 21.296207
[epoch16, step588]: loss 1.177965
[epoch16, step589]: loss 1.061080
[epoch16, step590]: loss 9.548078
[epoch16, step591]: loss 12.380924
[epoch16, step592]: loss 8.103255
[epoch16, step593]: loss 3.628270
[epoch16, step594]: loss 1.440845
[epoch16, step595]: loss 1.385792
[epoch16, step596]: loss 6.821283
[epoch16, step597]: loss 1.909274
[epoch16, step598]: loss 1.707729
[epoch16, step599]: loss 1.077415
[epoch16, step600]: loss 1.864301
[epoch16, step601]: loss 0.650664
[epoch16, step602]: loss 0.902246
[epoch16, step603]: loss 2.127691
[epoch16, step604]: loss 5.081333
[epoch16, step605]: loss 0.620491
[epoch16, step606]: loss 1.192146
[epoch16, step607]: loss 0.898452
[epoch16, step608]: loss 9.596326
[epoch16, step609]: loss 18.969145
[epoch16, step610]: loss 7.135096
[epoch16, step611]: loss 0.665502
[epoch16, step612]: loss 6.451706
[epoch16, step613]: loss 8.780328
[epoch16, step614]: loss 0.971567
[epoch16, step615]: loss 0.868888
[epoch16, step616]: loss 1.117083
[epoch16, step617]: loss 7.006037
[epoch16, step618]: loss 2.178240
[epoch16, step619]: loss 0.731517
[epoch16, step620]: loss 9.627753
[epoch16, step621]: loss 2.973151
[epoch16, step622]: loss 1.703094
[epoch16, step623]: loss 7.967059
[epoch16, step624]: loss 0.658518
[epoch16, step625]: loss 2.565700
[epoch16, step626]: loss 1.030993
[epoch16, step627]: loss 4.729755
[epoch16, step628]: loss 1.384790
[epoch16, step629]: loss 2.758930
[epoch16, step630]: loss 2.404505
[epoch16, step631]: loss 0.530148
[epoch16, step632]: loss 6.500094
[epoch16, step633]: loss 10.874343
[epoch16, step634]: loss 7.369024
[epoch16, step635]: loss 9.803934
[epoch16, step636]: loss 0.965259
[epoch16, step637]: loss 4.590841
[epoch16, step638]: loss 0.722417
[epoch16, step639]: loss 7.402820
[epoch16, step640]: loss 0.803599
[epoch16, step641]: loss 6.929555
[epoch16, step642]: loss 0.909570
[epoch16, step643]: loss 3.688685
[epoch16, step644]: loss 1.314915
[epoch16, step645]: loss 1.929929
[epoch16, step646]: loss 3.117157
[epoch16, step647]: loss 1.651407
[epoch16, step648]: loss 13.029710
[epoch16, step649]: loss 11.582920
[epoch16, step650]: loss 6.292947
[epoch16, step651]: loss 0.790151
[epoch16, step652]: loss 1.366260
[epoch16, step653]: loss 1.151765
[epoch16, step654]: loss 2.151550
[epoch16, step655]: loss 1.533201
[epoch16, step656]: loss 8.906221
[epoch16, step657]: loss 8.676006
[epoch16, step658]: loss 2.674639
[epoch16, step659]: loss 2.439094
[epoch16, step660]: loss 1.252504
[epoch16, step661]: loss 1.105718
[epoch16, step662]: loss 2.302313
[epoch16, step663]: loss 3.956983
[epoch16, step664]: loss 1.552242
[epoch16, step665]: loss 6.709331
[epoch16, step666]: loss 7.321400
[epoch16, step667]: loss 0.727308
[epoch16, step668]: loss 2.136777
[epoch16, step669]: loss 1.529795
[epoch16, step670]: loss 0.726591
[epoch16, step671]: loss 1.710498
[epoch16, step672]: loss 2.270262
[epoch16, step673]: loss 0.526666
[epoch16, step674]: loss 0.947417
[epoch16, step675]: loss 1.585784
[epoch16, step676]: loss 3.422842
[epoch16, step677]: loss 17.292099
[epoch16, step678]: loss 1.228364
[epoch16, step679]: loss 0.626021
[epoch16, step680]: loss 13.947113
[epoch16, step681]: loss 0.836204
[epoch16, step682]: loss 15.833644
[epoch16, step683]: loss 1.672672
[epoch16, step684]: loss 5.710008
[epoch16, step685]: loss 3.500478
[epoch16, step686]: loss 12.332517
[epoch16, step687]: loss 1.315106
[epoch16, step688]: loss 9.628486
[epoch16, step689]: loss 1.267311
[epoch16, step690]: loss 1.611199
[epoch16, step691]: loss 9.107810
[epoch16, step692]: loss 2.306234
[epoch16, step693]: loss 5.785173
[epoch16, step694]: loss 0.697406
[epoch16, step695]: loss 15.427691
[epoch16, step696]: loss 1.898536
[epoch16, step697]: loss 1.061802
[epoch16, step698]: loss 0.916046
[epoch16, step699]: loss 11.442359
[epoch16, step700]: loss 6.772173
[epoch16, step701]: loss 0.626575
[epoch16, step702]: loss 7.054289
[epoch16, step703]: loss 2.946200
[epoch16, step704]: loss 2.606501
[epoch16, step705]: loss 9.663368
[epoch16, step706]: loss 1.834721
[epoch16, step707]: loss 0.798617
[epoch16, step708]: loss 1.870313
[epoch16, step709]: loss 1.286646
[epoch16, step710]: loss 7.471200
[epoch16, step711]: loss 1.834165
[epoch16, step712]: loss 8.430760
[epoch16, step713]: loss 1.426234
[epoch16, step714]: loss 1.120772
[epoch16, step715]: loss 1.145817
[epoch16, step716]: loss 1.277534
[epoch16, step717]: loss 15.837193
[epoch16, step718]: loss 0.577365
[epoch16, step719]: loss 9.375216
[epoch16, step720]: loss 2.256104
[epoch16, step721]: loss 0.958324
[epoch16, step722]: loss 1.205367
[epoch16, step723]: loss 0.850151
[epoch16, step724]: loss 1.706700
[epoch16, step725]: loss 3.141207
[epoch16, step726]: loss 1.333904
[epoch16, step727]: loss 0.895658
[epoch16, step728]: loss 6.132359
[epoch16, step729]: loss 8.688040
[epoch16, step730]: loss 8.707351
[epoch16, step731]: loss 1.805735
[epoch16, step732]: loss 0.796447
[epoch16, step733]: loss 1.240495
[epoch16, step734]: loss 0.917034
[epoch16, step735]: loss 1.017984
[epoch16, step736]: loss 0.670708
[epoch16, step737]: loss 16.294533
[epoch16, step738]: loss 6.500346
[epoch16, step739]: loss 10.604625
[epoch16, step740]: loss 10.694329
[epoch16, step741]: loss 1.300291
[epoch16, step742]: loss 2.394405
[epoch16, step743]: loss 2.346431
[epoch16, step744]: loss 1.457476
[epoch16, step745]: loss 0.881934
[epoch16, step746]: loss 0.853951
[epoch16, step747]: loss 7.264461
[epoch16, step748]: loss 1.467672
[epoch16, step749]: loss 2.575981
[epoch16, step750]: loss 1.659848
[epoch16, step751]: loss 14.362068
[epoch16, step752]: loss 11.339733
[epoch16, step753]: loss 1.704791
[epoch16, step754]: loss 6.237883
[epoch16, step755]: loss 2.654110
[epoch16, step756]: loss 7.447063
[epoch16, step757]: loss 13.155610
[epoch16, step758]: loss 2.164152
[epoch16, step759]: loss 0.833784
[epoch16, step760]: loss 8.613832
[epoch16, step761]: loss 2.442931
[epoch16, step762]: loss 0.734195
[epoch16, step763]: loss 0.530215
[epoch16, step764]: loss 2.051828
[epoch16, step765]: loss 2.321024
[epoch16, step766]: loss 12.802482
[epoch16, step767]: loss 2.828066
[epoch16, step768]: loss 5.838090
[epoch16, step769]: loss 6.643145
[epoch16, step770]: loss 10.219205
[epoch16, step771]: loss 2.026706
[epoch16, step772]: loss 6.197903
[epoch16, step773]: loss 1.765004
[epoch16, step774]: loss 3.170251
[epoch16, step775]: loss 1.490996
[epoch16, step776]: loss 4.625846
[epoch16, step777]: loss 2.915514
[epoch16, step778]: loss 4.389463
[epoch16, step779]: loss 1.648594
[epoch16, step780]: loss 8.899757
[epoch16, step781]: loss 3.749947
[epoch16, step782]: loss 16.755264
[epoch16, step783]: loss 26.693729
[epoch16, step784]: loss 1.722685
[epoch16, step785]: loss 1.486830
[epoch16, step786]: loss 0.858949
[epoch16, step787]: loss 0.622527
[epoch16, step788]: loss 7.519023
[epoch16, step789]: loss 0.801682
[epoch16, step790]: loss 3.675424
[epoch16, step791]: loss 0.963124
[epoch16, step792]: loss 0.578520
[epoch16, step793]: loss 0.832714
[epoch16, step794]: loss 11.854075
[epoch16, step795]: loss 8.381842
[epoch16, step796]: loss 0.607209
[epoch16, step797]: loss 3.378930
[epoch16, step798]: loss 4.217474
[epoch16, step799]: loss 8.397315
[epoch16, step800]: loss 1.554789
[epoch16, step801]: loss 2.106503
[epoch16, step802]: loss 0.976161
[epoch16, step803]: loss 9.549679
[epoch16, step804]: loss 6.483564
[epoch16, step805]: loss 5.036969
[epoch16, step806]: loss 1.045613
[epoch16, step807]: loss 2.888757
[epoch16, step808]: loss 2.165218
[epoch16, step809]: loss 0.943096
[epoch16, step810]: loss 12.824283
[epoch16, step811]: loss 1.149613
[epoch16, step812]: loss 11.160414
[epoch16, step813]: loss 0.879093
[epoch16, step814]: loss 6.114358
[epoch16, step815]: loss 7.750702
[epoch16, step816]: loss 2.359927
[epoch16, step817]: loss 1.356147
[epoch16, step818]: loss 1.199517
[epoch16, step819]: loss 2.379107
[epoch16, step820]: loss 0.919283
[epoch16, step821]: loss 1.418279
[epoch16, step822]: loss 9.721287
[epoch16, step823]: loss 0.913516
[epoch16, step824]: loss 9.551503
[epoch16, step825]: loss 2.723455
[epoch16, step826]: loss 5.824880
[epoch16, step827]: loss 30.872950
[epoch16, step828]: loss 6.954625
[epoch16, step829]: loss 2.104765
[epoch16, step830]: loss 2.779145
[epoch16, step831]: loss 1.462072
[epoch16, step832]: loss 9.849847
[epoch16, step833]: loss 17.837870
[epoch16, step834]: loss 5.711885
[epoch16, step835]: loss 1.704042
[epoch16, step836]: loss 6.863328
[epoch16, step837]: loss 5.154852
[epoch16, step838]: loss 11.565368
[epoch16, step839]: loss 0.683278
[epoch16, step840]: loss 1.017295
[epoch16, step841]: loss 1.975829
[epoch16, step842]: loss 7.039932
[epoch16, step843]: loss 0.952554
[epoch16, step844]: loss 1.026664
[epoch16, step845]: loss 1.116874
[epoch16, step846]: loss 0.819799
[epoch16, step847]: loss 0.868704
[epoch16, step848]: loss 2.836770
[epoch16, step849]: loss 12.024289
[epoch16, step850]: loss 1.395734
[epoch16, step851]: loss 2.038564
[epoch16, step852]: loss 3.034253
[epoch16, step853]: loss 1.014117
[epoch16, step854]: loss 4.005082
[epoch16, step855]: loss 1.267544
[epoch16, step856]: loss 1.164966
[epoch16, step857]: loss 7.368689
[epoch16, step858]: loss 2.307105
[epoch16, step859]: loss 4.745192
[epoch16, step860]: loss 1.610938
[epoch16, step861]: loss 3.294958
[epoch16, step862]: loss 0.614549
[epoch16, step863]: loss 4.893317
[epoch16, step864]: loss 1.352214
[epoch16, step865]: loss 3.697105
[epoch16, step866]: loss 0.909516
[epoch16, step867]: loss 1.121442
[epoch16, step868]: loss 1.989969
[epoch16, step869]: loss 0.696923
[epoch16, step870]: loss 0.969812
[epoch16, step871]: loss 1.546041
[epoch16, step872]: loss 1.654035
[epoch16, step873]: loss 1.762504
[epoch16, step874]: loss 12.179626
[epoch16, step875]: loss 3.380621
[epoch16, step876]: loss 1.305845
[epoch16, step877]: loss 17.624792
[epoch16, step878]: loss 1.002819
[epoch16, step879]: loss 4.873455
[epoch16, step880]: loss 1.326737
[epoch16, step881]: loss 4.261025
[epoch16, step882]: loss 7.606274
[epoch16, step883]: loss 6.697960
[epoch16, step884]: loss 1.071970
[epoch16, step885]: loss 3.198618
[epoch16, step886]: loss 1.332282
[epoch16, step887]: loss 1.994255
[epoch16, step888]: loss 0.566213
[epoch16, step889]: loss 1.677271
[epoch16, step890]: loss 1.383010
[epoch16, step891]: loss 1.342324
[epoch16, step892]: loss 1.061129
[epoch16, step893]: loss 1.188236
[epoch16, step894]: loss 2.568442
[epoch16, step895]: loss 3.302769
[epoch16, step896]: loss 2.375345
[epoch16, step897]: loss 0.835983
[epoch16, step898]: loss 1.577575
[epoch16, step899]: loss 13.557339
[epoch16, step900]: loss 1.890151
[epoch16, step901]: loss 2.281719
[epoch16, step902]: loss 2.312658
[epoch16, step903]: loss 0.799625
[epoch16, step904]: loss 1.567624
[epoch16, step905]: loss 3.091714
[epoch16, step906]: loss 8.546678
[epoch16, step907]: loss 9.065658
[epoch16, step908]: loss 2.751461
[epoch16, step909]: loss 4.083481
[epoch16, step910]: loss 3.253349
[epoch16, step911]: loss 1.017940
[epoch16, step912]: loss 9.520315
[epoch16, step913]: loss 2.508678
[epoch16, step914]: loss 12.889471
[epoch16, step915]: loss 10.315116
[epoch16, step916]: loss 2.583981
[epoch16, step917]: loss 27.854233
[epoch16, step918]: loss 8.869333
[epoch16, step919]: loss 0.862592
[epoch16, step920]: loss 7.215400
[epoch16, step921]: loss 0.821821
[epoch16, step922]: loss 0.902659
[epoch16, step923]: loss 1.644168
[epoch16, step924]: loss 7.045123
[epoch16, step925]: loss 8.814094
[epoch16, step926]: loss 8.159445
[epoch16, step927]: loss 0.784220
[epoch16, step928]: loss 1.402201
[epoch16, step929]: loss 8.391917
[epoch16, step930]: loss 0.749514
[epoch16, step931]: loss 8.260514
[epoch16, step932]: loss 0.968918
[epoch16, step933]: loss 17.295469
[epoch16, step934]: loss 0.872158
[epoch16, step935]: loss 9.058161
[epoch16, step936]: loss 13.556236
[epoch16, step937]: loss 2.436952
[epoch16, step938]: loss 13.236626
[epoch16, step939]: loss 1.934347
[epoch16, step940]: loss 1.539458
[epoch16, step941]: loss 8.046576
[epoch16, step942]: loss 8.397451
[epoch16, step943]: loss 1.321867
[epoch16, step944]: loss 1.808002
[epoch16, step945]: loss 5.259536
[epoch16, step946]: loss 11.673604
[epoch16, step947]: loss 0.913601
[epoch16, step948]: loss 1.179492
[epoch16, step949]: loss 10.020107
[epoch16, step950]: loss 2.462580
[epoch16, step951]: loss 1.606076
[epoch16, step952]: loss 2.771920
[epoch16, step953]: loss 15.340871
[epoch16, step954]: loss 1.104536
[epoch16, step955]: loss 4.013035
[epoch16, step956]: loss 1.360076
[epoch16, step957]: loss 8.456156
[epoch16, step958]: loss 0.896995
[epoch16, step959]: loss 0.810582
[epoch16, step960]: loss 1.576620
[epoch16, step961]: loss 3.016262
[epoch16, step962]: loss 10.002750
[epoch16, step963]: loss 0.926505
[epoch16, step964]: loss 0.949761
[epoch16, step965]: loss 1.993043
[epoch16, step966]: loss 2.832582
[epoch16, step967]: loss 0.868072
[epoch16, step968]: loss 0.884115
[epoch16, step969]: loss 1.785215
[epoch16, step970]: loss 1.597098
[epoch16, step971]: loss 1.153210
[epoch16, step972]: loss 0.560338
[epoch16, step973]: loss 18.466513
[epoch16, step974]: loss 3.274723
[epoch16, step975]: loss 0.760589
[epoch16, step976]: loss 10.571463
[epoch16, step977]: loss 1.289005
[epoch16, step978]: loss 7.208111
[epoch16, step979]: loss 17.165007
[epoch16, step980]: loss 0.832560
[epoch16, step981]: loss 1.337721
[epoch16, step982]: loss 24.399315
[epoch16, step983]: loss 1.077658
[epoch16, step984]: loss 4.493501
[epoch16, step985]: loss 9.898018
[epoch16, step986]: loss 1.024860
[epoch16, step987]: loss 7.976088
[epoch16, step988]: loss 6.618190
[epoch16, step989]: loss 7.286476
[epoch16, step990]: loss 7.300350
[epoch16, step991]: loss 0.913750
[epoch16, step992]: loss 3.615649
[epoch16, step993]: loss 0.718943
[epoch16, step994]: loss 0.730844
[epoch16, step995]: loss 9.788684
[epoch16, step996]: loss 0.781365
[epoch16, step997]: loss 0.583296
[epoch16, step998]: loss 0.762945
[epoch16, step999]: loss 1.534634
[epoch16, step1000]: loss 0.657425
[epoch16, step1001]: loss 1.321443
[epoch16, step1002]: loss 1.305069
[epoch16, step1003]: loss 11.939684
[epoch16, step1004]: loss 0.602656
[epoch16, step1005]: loss 0.707503
[epoch16, step1006]: loss 0.841945
[epoch16, step1007]: loss 0.645987
[epoch16, step1008]: loss 1.911686
[epoch16, step1009]: loss 0.834685
[epoch16, step1010]: loss 0.771136
[epoch16, step1011]: loss 2.256140
[epoch16, step1012]: loss 6.173473
[epoch16, step1013]: loss 3.825977
[epoch16, step1014]: loss 8.044002
[epoch16, step1015]: loss 0.569346
[epoch16, step1016]: loss 2.063919
[epoch16, step1017]: loss 1.225127
[epoch16, step1018]: loss 5.458958
[epoch16, step1019]: loss 14.946061
[epoch16, step1020]: loss 8.771870
[epoch16, step1021]: loss 2.443994
[epoch16, step1022]: loss 1.068983
[epoch16, step1023]: loss 6.959672
[epoch16, step1024]: loss 9.360668
[epoch16, step1025]: loss 2.711385
[epoch16, step1026]: loss 2.937949
[epoch16, step1027]: loss 1.267841
[epoch16, step1028]: loss 9.823872
[epoch16, step1029]: loss 3.227857
[epoch16, step1030]: loss 1.756342
[epoch16, step1031]: loss 5.350600
[epoch16, step1032]: loss 11.588924
[epoch16, step1033]: loss 0.538943
[epoch16, step1034]: loss 2.970723
[epoch16, step1035]: loss 11.268559
[epoch16, step1036]: loss 0.553695
[epoch16, step1037]: loss 1.832026
[epoch16, step1038]: loss 0.890782
[epoch16, step1039]: loss 1.366777
[epoch16, step1040]: loss 0.577846
[epoch16, step1041]: loss 8.703637
[epoch16, step1042]: loss 3.129549
[epoch16, step1043]: loss 0.626499
[epoch16, step1044]: loss 1.440801
[epoch16, step1045]: loss 13.248920
[epoch16, step1046]: loss 7.437505
[epoch16, step1047]: loss 1.848918
[epoch16, step1048]: loss 9.535846
[epoch16, step1049]: loss 0.995749
[epoch16, step1050]: loss 8.612379
[epoch16, step1051]: loss 7.244162
[epoch16, step1052]: loss 0.856354
[epoch16, step1053]: loss 13.065818
[epoch16, step1054]: loss 6.367828
[epoch16, step1055]: loss 9.257051
[epoch16, step1056]: loss 13.054173
[epoch16, step1057]: loss 1.486512
[epoch16, step1058]: loss 2.480873
[epoch16, step1059]: loss 9.332659
[epoch16, step1060]: loss 1.538965
[epoch16, step1061]: loss 6.918495
[epoch16, step1062]: loss 3.409198
[epoch16, step1063]: loss 1.474949
[epoch16, step1064]: loss 8.050564
[epoch16, step1065]: loss 0.813983
[epoch16, step1066]: loss 1.204451
[epoch16, step1067]: loss 14.181937
[epoch16, step1068]: loss 2.199428
[epoch16, step1069]: loss 5.962726
[epoch16, step1070]: loss 0.748035
[epoch16, step1071]: loss 6.827005
[epoch16, step1072]: loss 0.762080
[epoch16, step1073]: loss 3.142531
[epoch16, step1074]: loss 8.653507
[epoch16, step1075]: loss 1.539034
[epoch16, step1076]: loss 0.912692
[epoch16, step1077]: loss 3.438611
[epoch16, step1078]: loss 8.213217
[epoch16, step1079]: loss 0.599160
[epoch16, step1080]: loss 2.659608
[epoch16, step1081]: loss 0.743948
[epoch16, step1082]: loss 0.824083
[epoch16, step1083]: loss 0.822013
[epoch16, step1084]: loss 0.692598
[epoch16, step1085]: loss 0.985429
[epoch16, step1086]: loss 0.671610
[epoch16, step1087]: loss 0.871232
[epoch16, step1088]: loss 7.275847
[epoch16, step1089]: loss 0.553318
[epoch16, step1090]: loss 6.081557
[epoch16, step1091]: loss 10.042506
[epoch16, step1092]: loss 0.820917
[epoch16, step1093]: loss 5.902713
[epoch16, step1094]: loss 0.684109
[epoch16, step1095]: loss 14.069510
[epoch16, step1096]: loss 11.117653
[epoch16, step1097]: loss 6.670148
[epoch16, step1098]: loss 6.891284
[epoch16, step1099]: loss 2.855600
[epoch16, step1100]: loss 2.308642
[epoch16, step1101]: loss 3.593532
[epoch16, step1102]: loss 3.212110
[epoch16, step1103]: loss 3.401417
[epoch16, step1104]: loss 11.897406
[epoch16, step1105]: loss 2.248857
[epoch16, step1106]: loss 0.538454
[epoch16, step1107]: loss 4.653275
[epoch16, step1108]: loss 0.557033
[epoch16, step1109]: loss 1.559405
[epoch16, step1110]: loss 2.082225
[epoch16, step1111]: loss 1.788007
[epoch16, step1112]: loss 6.267844
[epoch16, step1113]: loss 2.295936
[epoch16, step1114]: loss 1.492090
[epoch16, step1115]: loss 7.953013
[epoch16, step1116]: loss 11.317485
[epoch16, step1117]: loss 0.866415
[epoch16, step1118]: loss 1.518352
[epoch16, step1119]: loss 7.485932
[epoch16, step1120]: loss 1.705258
[epoch16, step1121]: loss 4.908094
[epoch16, step1122]: loss 1.351784
[epoch16, step1123]: loss 0.736987
[epoch16, step1124]: loss 11.630429
[epoch16, step1125]: loss 1.064417
[epoch16, step1126]: loss 2.278035
[epoch16, step1127]: loss 2.646823
[epoch16, step1128]: loss 1.898850
[epoch16, step1129]: loss 5.284041
[epoch16, step1130]: loss 27.167751
[epoch16, step1131]: loss 0.958067
[epoch16, step1132]: loss 1.178809
[epoch16, step1133]: loss 3.063508
[epoch16, step1134]: loss 0.909331
[epoch16, step1135]: loss 1.047815
[epoch16, step1136]: loss 2.395666
[epoch16, step1137]: loss 1.167691
[epoch16, step1138]: loss 1.449377
[epoch16, step1139]: loss 12.815861
[epoch16, step1140]: loss 6.691762
[epoch16, step1141]: loss 1.557193
[epoch16, step1142]: loss 8.245173
[epoch16, step1143]: loss 1.115371
[epoch16, step1144]: loss 6.075667
[epoch16, step1145]: loss 2.166489
[epoch16, step1146]: loss 15.950157
[epoch16, step1147]: loss 4.240783
[epoch16, step1148]: loss 5.382311
[epoch16, step1149]: loss 9.486292
[epoch16, step1150]: loss 0.827030
[epoch16, step1151]: loss 11.913494
[epoch16, step1152]: loss 12.526802
[epoch16, step1153]: loss 2.466796
[epoch16, step1154]: loss 0.629138
[epoch16, step1155]: loss 6.805705
[epoch16, step1156]: loss 0.736996
[epoch16, step1157]: loss 1.143665
[epoch16, step1158]: loss 6.637241
[epoch16, step1159]: loss 0.653516
[epoch16, step1160]: loss 8.343854
[epoch16, step1161]: loss 8.551849
[epoch16, step1162]: loss 2.452866
[epoch16, step1163]: loss 1.956666
[epoch16, step1164]: loss 7.074651
[epoch16, step1165]: loss 0.916052
[epoch16, step1166]: loss 7.692168
[epoch16, step1167]: loss 1.540429
[epoch16, step1168]: loss 1.923786
[epoch16, step1169]: loss 2.167538
[epoch16, step1170]: loss 9.490520
[epoch16, step1171]: loss 1.567580
[epoch16, step1172]: loss 4.796222
[epoch16, step1173]: loss 0.480323
[epoch16, step1174]: loss 0.915256
[epoch16, step1175]: loss 1.268414
[epoch16, step1176]: loss 1.653583
[epoch16, step1177]: loss 0.634559
[epoch16, step1178]: loss 0.769367
[epoch16, step1179]: loss 1.375211
[epoch16, step1180]: loss 0.759053
[epoch16, step1181]: loss 12.508039
[epoch16, step1182]: loss 6.608100
[epoch16, step1183]: loss 0.908845
[epoch16, step1184]: loss 7.388073
[epoch16, step1185]: loss 0.688871
[epoch16, step1186]: loss 0.775575
[epoch16, step1187]: loss 1.082198
[epoch16, step1188]: loss 7.038219
[epoch16, step1189]: loss 0.670489
[epoch16, step1190]: loss 2.390276
[epoch16, step1191]: loss 0.548674
[epoch16, step1192]: loss 0.720865
[epoch16, step1193]: loss 1.988374
[epoch16, step1194]: loss 1.488637
[epoch16, step1195]: loss 2.141793
[epoch16, step1196]: loss 0.955029
[epoch16, step1197]: loss 0.964671
[epoch16, step1198]: loss 0.947578
[epoch16, step1199]: loss 0.896051
[epoch16, step1200]: loss 2.972701
[epoch16, step1201]: loss 1.582354
[epoch16, step1202]: loss 0.678305
[epoch16, step1203]: loss 0.638626
[epoch16, step1204]: loss 2.803149
[epoch16, step1205]: loss 0.935481
[epoch16, step1206]: loss 1.623503
[epoch16, step1207]: loss 0.578220
[epoch16, step1208]: loss 0.918472
[epoch16, step1209]: loss 1.548274
[epoch16, step1210]: loss 2.555342
[epoch16, step1211]: loss 14.678055
[epoch16, step1212]: loss 0.874171
[epoch16, step1213]: loss 1.301113
[epoch16, step1214]: loss 13.020650
[epoch16, step1215]: loss 1.031281
[epoch16, step1216]: loss 2.610626
[epoch16, step1217]: loss 6.287737
[epoch16, step1218]: loss 1.434158
[epoch16, step1219]: loss 6.851337
[epoch16, step1220]: loss 2.127687
[epoch16, step1221]: loss 1.127113
[epoch16, step1222]: loss 1.725952
[epoch16, step1223]: loss 6.565663
[epoch16, step1224]: loss 2.231266
[epoch16, step1225]: loss 0.822681
[epoch16, step1226]: loss 1.087187
[epoch16, step1227]: loss 1.105621
[epoch16, step1228]: loss 18.056211
[epoch16, step1229]: loss 1.339470
[epoch16, step1230]: loss 2.934355
[epoch16, step1231]: loss 5.527961
[epoch16, step1232]: loss 8.059346
[epoch16, step1233]: loss 0.883145
[epoch16, step1234]: loss 9.636598
[epoch16, step1235]: loss 3.407083
[epoch16, step1236]: loss 1.973765
[epoch16, step1237]: loss 9.194845
[epoch16, step1238]: loss 0.786750
[epoch16, step1239]: loss 2.158691
[epoch16, step1240]: loss 1.457107
[epoch16, step1241]: loss 1.296783
[epoch16, step1242]: loss 6.202910
[epoch16, step1243]: loss 15.803761
[epoch16, step1244]: loss 0.730405
[epoch16, step1245]: loss 1.553795
[epoch16, step1246]: loss 1.135726
[epoch16, step1247]: loss 0.632612
[epoch16, step1248]: loss 1.067995
[epoch16, step1249]: loss 1.824626
[epoch16, step1250]: loss 1.110592
[epoch16, step1251]: loss 9.280735
[epoch16, step1252]: loss 0.712726
[epoch16, step1253]: loss 6.793545
[epoch16, step1254]: loss 0.887275
[epoch16, step1255]: loss 4.053493
[epoch16, step1256]: loss 0.640216
[epoch16, step1257]: loss 0.696925
[epoch16, step1258]: loss 0.640026
[epoch16, step1259]: loss 3.121427
[epoch16, step1260]: loss 11.390012
[epoch16, step1261]: loss 1.015484
[epoch16, step1262]: loss 0.987734
[epoch16, step1263]: loss 0.974650
[epoch16, step1264]: loss 1.641217
[epoch16, step1265]: loss 1.019904
[epoch16, step1266]: loss 3.399565
[epoch16, step1267]: loss 10.143486
[epoch16, step1268]: loss 4.827372
[epoch16, step1269]: loss 16.188696
[epoch16, step1270]: loss 0.756518
[epoch16, step1271]: loss 7.362096
[epoch16, step1272]: loss 10.990066
[epoch16, step1273]: loss 2.262278
[epoch16, step1274]: loss 2.227078
[epoch16, step1275]: loss 2.618464
[epoch16, step1276]: loss 6.751587
[epoch16, step1277]: loss 17.387022
[epoch16, step1278]: loss 1.434507
[epoch16, step1279]: loss 1.779124
[epoch16, step1280]: loss 12.708909
[epoch16, step1281]: loss 3.865717
[epoch16, step1282]: loss 0.730872
[epoch16, step1283]: loss 0.856245
[epoch16, step1284]: loss 0.780667
[epoch16, step1285]: loss 9.344169
[epoch16, step1286]: loss 0.645694
[epoch16, step1287]: loss 4.105196
[epoch16, step1288]: loss 3.266638
[epoch16, step1289]: loss 0.515007
[epoch16, step1290]: loss 1.703749
[epoch16, step1291]: loss 1.487627
[epoch16, step1292]: loss 0.849848
[epoch16, step1293]: loss 0.767068
[epoch16, step1294]: loss 0.736193
[epoch16, step1295]: loss 1.967928
[epoch16, step1296]: loss 12.113169
[epoch16, step1297]: loss 1.732866
[epoch16, step1298]: loss 0.822580
[epoch16, step1299]: loss 2.327134
[epoch16, step1300]: loss 11.106115
[epoch16, step1301]: loss 0.836099
[epoch16, step1302]: loss 1.247041
[epoch16, step1303]: loss 1.299288
[epoch16, step1304]: loss 7.202985
[epoch16, step1305]: loss 1.526445
[epoch16, step1306]: loss 5.118687
[epoch16, step1307]: loss 1.143843
[epoch16, step1308]: loss 4.933445
[epoch16, step1309]: loss 9.826009
[epoch16, step1310]: loss 0.811548
[epoch16, step1311]: loss 3.116917
[epoch16, step1312]: loss 0.788173
[epoch16, step1313]: loss 12.851357
[epoch16, step1314]: loss 0.801061
[epoch16, step1315]: loss 1.298493
[epoch16, step1316]: loss 0.694482
[epoch16, step1317]: loss 1.468873
[epoch16, step1318]: loss 3.120822
[epoch16, step1319]: loss 0.636867
[epoch16, step1320]: loss 1.081022
[epoch16, step1321]: loss 0.678674
[epoch16, step1322]: loss 1.420892
[epoch16, step1323]: loss 0.869955
[epoch16, step1324]: loss 1.185491
[epoch16, step1325]: loss 6.273085
[epoch16, step1326]: loss 9.336355
[epoch16, step1327]: loss 0.786629
[epoch16, step1328]: loss 20.535118
[epoch16, step1329]: loss 0.915587
[epoch16, step1330]: loss 12.497456
[epoch16, step1331]: loss 1.777743
[epoch16, step1332]: loss 0.830557
[epoch16, step1333]: loss 5.528571
[epoch16, step1334]: loss 6.644402
[epoch16, step1335]: loss 6.420118
[epoch16, step1336]: loss 2.307604
[epoch16, step1337]: loss 1.164966
[epoch16, step1338]: loss 1.018837
[epoch16, step1339]: loss 3.289548
[epoch16, step1340]: loss 11.302613
[epoch16, step1341]: loss 0.868793
[epoch16, step1342]: loss 1.220433
[epoch16, step1343]: loss 1.687369
[epoch16, step1344]: loss 1.451102
[epoch16, step1345]: loss 2.906751
[epoch16, step1346]: loss 13.696256
[epoch16, step1347]: loss 1.582252
[epoch16, step1348]: loss 3.401869
[epoch16, step1349]: loss 0.993571
[epoch16, step1350]: loss 0.703946
[epoch16, step1351]: loss 13.033021
[epoch16, step1352]: loss 14.637494
[epoch16, step1353]: loss 0.696542
[epoch16, step1354]: loss 0.789300
[epoch16, step1355]: loss 0.727007
[epoch16, step1356]: loss 2.475338
[epoch16, step1357]: loss 11.968944
[epoch16, step1358]: loss 11.195684
[epoch16, step1359]: loss 1.268645
[epoch16, step1360]: loss 0.761148
[epoch16, step1361]: loss 2.624144
[epoch16, step1362]: loss 7.413708
[epoch16, step1363]: loss 1.716668
[epoch16, step1364]: loss 0.651339
[epoch16, step1365]: loss 0.740592
[epoch16, step1366]: loss 1.604282
[epoch16, step1367]: loss 0.587636
[epoch16, step1368]: loss 0.758316
[epoch16, step1369]: loss 1.500942
[epoch16, step1370]: loss 13.030249
[epoch16, step1371]: loss 7.145764
[epoch16, step1372]: loss 0.679913
[epoch16, step1373]: loss 1.793265
[epoch16, step1374]: loss 1.495660
[epoch16, step1375]: loss 12.027418
[epoch16, step1376]: loss 1.823528
[epoch16, step1377]: loss 1.544511
[epoch16, step1378]: loss 0.748056
[epoch16, step1379]: loss 0.652412
[epoch16, step1380]: loss 13.481078
[epoch16, step1381]: loss 3.783263
[epoch16, step1382]: loss 2.469812
[epoch16, step1383]: loss 9.897934
[epoch16, step1384]: loss 0.995725
[epoch16, step1385]: loss 1.103210
[epoch16, step1386]: loss 13.495327
[epoch16, step1387]: loss 0.850908
[epoch16, step1388]: loss 8.833128
[epoch16, step1389]: loss 0.845433
[epoch16, step1390]: loss 2.539866
[epoch16, step1391]: loss 0.993717
[epoch16, step1392]: loss 20.359644
[epoch16, step1393]: loss 14.504759
[epoch16, step1394]: loss 0.823791
[epoch16, step1395]: loss 3.161172
[epoch16, step1396]: loss 6.460248
[epoch16, step1397]: loss 3.803123
[epoch16, step1398]: loss 6.834701
[epoch16, step1399]: loss 10.229158
[epoch16, step1400]: loss 0.624907
[epoch16, step1401]: loss 0.793080
[epoch16, step1402]: loss 3.057887
[epoch16, step1403]: loss 0.557753
[epoch16, step1404]: loss 1.464851
[epoch16, step1405]: loss 1.703442
[epoch16, step1406]: loss 0.894486
[epoch16, step1407]: loss 1.066270
[epoch16, step1408]: loss 3.620971
[epoch16, step1409]: loss 7.138541
[epoch16, step1410]: loss 7.559847
[epoch16, step1411]: loss 7.323560
[epoch16, step1412]: loss 11.315340
[epoch16, step1413]: loss 10.479684
[epoch16, step1414]: loss 14.505611
[epoch16, step1415]: loss 0.661845
[epoch16, step1416]: loss 12.821582
[epoch16, step1417]: loss 7.366741
[epoch16, step1418]: loss 0.901936
[epoch16, step1419]: loss 0.878141
[epoch16, step1420]: loss 8.031139
[epoch16, step1421]: loss 6.086159
[epoch16, step1422]: loss 12.244970
[epoch16, step1423]: loss 6.479742
[epoch16, step1424]: loss 6.905463
[epoch16, step1425]: loss 2.992143
[epoch16, step1426]: loss 5.687584
[epoch16, step1427]: loss 1.321877
[epoch16, step1428]: loss 0.849663
[epoch16, step1429]: loss 0.754438
[epoch16, step1430]: loss 0.876734
[epoch16, step1431]: loss 1.060115
[epoch16, step1432]: loss 3.469546
[epoch16, step1433]: loss 1.249256
[epoch16, step1434]: loss 11.801812
[epoch16, step1435]: loss 7.007450
[epoch16, step1436]: loss 3.948656
[epoch16, step1437]: loss 6.286747
[epoch16, step1438]: loss 2.066209
[epoch16, step1439]: loss 8.197628
[epoch16, step1440]: loss 2.684732
[epoch16, step1441]: loss 8.287925
[epoch16, step1442]: loss 1.585000
[epoch16, step1443]: loss 1.086166
[epoch16, step1444]: loss 1.197217
[epoch16, step1445]: loss 1.396605
[epoch16, step1446]: loss 0.624225
[epoch16, step1447]: loss 1.134156
[epoch16, step1448]: loss 4.691514
[epoch16, step1449]: loss 3.371652
[epoch16, step1450]: loss 2.504273
[epoch16, step1451]: loss 0.779167
[epoch16, step1452]: loss 11.986227
[epoch16, step1453]: loss 1.817535
[epoch16, step1454]: loss 9.023709
[epoch16, step1455]: loss 0.728937
[epoch16, step1456]: loss 0.937746
[epoch16, step1457]: loss 1.469306
[epoch16, step1458]: loss 12.018553
[epoch16, step1459]: loss 1.491192
[epoch16, step1460]: loss 7.874855
[epoch16, step1461]: loss 1.004017
[epoch16, step1462]: loss 1.934908
[epoch16, step1463]: loss 6.766978
[epoch16, step1464]: loss 0.887587
[epoch16, step1465]: loss 1.296753
[epoch16, step1466]: loss 1.369200
[epoch16, step1467]: loss 6.814307
[epoch16, step1468]: loss 0.623120
[epoch16, step1469]: loss 7.212233
[epoch16, step1470]: loss 1.465364
[epoch16, step1471]: loss 1.547289
[epoch16, step1472]: loss 7.133667
[epoch16, step1473]: loss 6.443676
[epoch16, step1474]: loss 3.661377
[epoch16, step1475]: loss 0.631437
[epoch16, step1476]: loss 1.754138
[epoch16, step1477]: loss 5.103379
[epoch16, step1478]: loss 1.443285
[epoch16, step1479]: loss 11.782267
[epoch16, step1480]: loss 0.761666
[epoch16, step1481]: loss 2.087309
[epoch16, step1482]: loss 1.051788
[epoch16, step1483]: loss 0.650442
[epoch16, step1484]: loss 1.697192
[epoch16, step1485]: loss 0.724379
[epoch16, step1486]: loss 16.051338
[epoch16, step1487]: loss 9.135387
[epoch16, step1488]: loss 1.481776
[epoch16, step1489]: loss 0.926858
[epoch16, step1490]: loss 0.571628
[epoch16, step1491]: loss 1.771158
[epoch16, step1492]: loss 0.494648
[epoch16, step1493]: loss 7.561517
[epoch16, step1494]: loss 13.619177
[epoch16, step1495]: loss 1.629052
[epoch16, step1496]: loss 0.733073
[epoch16, step1497]: loss 1.902524
[epoch16, step1498]: loss 12.571513
[epoch16, step1499]: loss 6.867044
[epoch16, step1500]: loss 1.119660
[epoch16, step1501]: loss 1.324894
[epoch16, step1502]: loss 9.112624
[epoch16, step1503]: loss 13.443319
[epoch16, step1504]: loss 9.125402
[epoch16, step1505]: loss 2.111507
[epoch16, step1506]: loss 5.566109
[epoch16, step1507]: loss 0.884245
[epoch16, step1508]: loss 0.884543
[epoch16, step1509]: loss 0.705127
[epoch16, step1510]: loss 27.521469
[epoch16, step1511]: loss 9.330513
[epoch16, step1512]: loss 0.714297
[epoch16, step1513]: loss 10.653095
[epoch16, step1514]: loss 0.775215
[epoch16, step1515]: loss 2.054677
[epoch16, step1516]: loss 1.114248
[epoch16, step1517]: loss 0.709263
[epoch16, step1518]: loss 1.268021
[epoch16, step1519]: loss 2.396830
[epoch16, step1520]: loss 1.467013
[epoch16, step1521]: loss 0.859788
[epoch16, step1522]: loss 9.485407
[epoch16, step1523]: loss 1.383602
[epoch16, step1524]: loss 1.911174
[epoch16, step1525]: loss 3.264910
[epoch16, step1526]: loss 1.172323
[epoch16, step1527]: loss 0.640889
[epoch16, step1528]: loss 6.633867
[epoch16, step1529]: loss 7.745498
[epoch16, step1530]: loss 0.854851
[epoch16, step1531]: loss 1.802580
[epoch16, step1532]: loss 1.501305
[epoch16, step1533]: loss 4.705680
[epoch16, step1534]: loss 2.683714
[epoch16, step1535]: loss 0.877971
[epoch16, step1536]: loss 18.701563
[epoch16, step1537]: loss 3.599866
[epoch16, step1538]: loss 1.248517
[epoch16, step1539]: loss 1.005222
[epoch16, step1540]: loss 0.684011
[epoch16, step1541]: loss 1.672712
[epoch16, step1542]: loss 1.338212
[epoch16, step1543]: loss 0.682666
[epoch16, step1544]: loss 1.442222
[epoch16, step1545]: loss 0.903489
[epoch16, step1546]: loss 0.638148
[epoch16, step1547]: loss 6.692846
[epoch16, step1548]: loss 1.127629
[epoch16, step1549]: loss 1.005301
[epoch16, step1550]: loss 6.378715
[epoch16, step1551]: loss 10.761697
[epoch16, step1552]: loss 0.791685
[epoch16, step1553]: loss 1.355594
[epoch16, step1554]: loss 1.506894
[epoch16, step1555]: loss 2.779946
[epoch16, step1556]: loss 1.044335
[epoch16, step1557]: loss 10.087457
[epoch16, step1558]: loss 2.027427
[epoch16, step1559]: loss 2.855881
[epoch16, step1560]: loss 3.710174
[epoch16, step1561]: loss 1.228752
[epoch16, step1562]: loss 3.481404
[epoch16, step1563]: loss 10.130868
[epoch16, step1564]: loss 0.968681
[epoch16, step1565]: loss 4.019891
[epoch16, step1566]: loss 2.797878
[epoch16, step1567]: loss 0.718817
[epoch16, step1568]: loss 1.997139
[epoch16, step1569]: loss 1.974845
[epoch16, step1570]: loss 1.650762
[epoch16, step1571]: loss 3.658145
[epoch16, step1572]: loss 1.491536
[epoch16, step1573]: loss 6.378088
[epoch16, step1574]: loss 5.934528
[epoch16, step1575]: loss 3.575507
[epoch16, step1576]: loss 0.693342
[epoch16, step1577]: loss 1.353820
[epoch16, step1578]: loss 2.117959
[epoch16, step1579]: loss 0.628828
[epoch16, step1580]: loss 1.861284
[epoch16, step1581]: loss 8.999417
[epoch16, step1582]: loss 12.471599
[epoch16, step1583]: loss 12.019650
[epoch16, step1584]: loss 3.797060
[epoch16, step1585]: loss 0.742897
[epoch16, step1586]: loss 1.022013
[epoch16, step1587]: loss 3.783131
[epoch16, step1588]: loss 6.845874
[epoch16, step1589]: loss 0.717416
[epoch16, step1590]: loss 0.936007
[epoch16, step1591]: loss 2.233559
[epoch16, step1592]: loss 2.616910
[epoch16, step1593]: loss 2.487861
[epoch16, step1594]: loss 0.782152
[epoch16, step1595]: loss 6.735425
[epoch16, step1596]: loss 1.520791
[epoch16, step1597]: loss 1.616152
[epoch16, step1598]: loss 1.267346
[epoch16, step1599]: loss 7.090227
[epoch16, step1600]: loss 2.407537
[epoch16, step1601]: loss 7.312828
[epoch16, step1602]: loss 0.984707
[epoch16, step1603]: loss 1.992191
[epoch16, step1604]: loss 1.138104
[epoch16, step1605]: loss 8.832887
[epoch16, step1606]: loss 0.920420
[epoch16, step1607]: loss 1.526322
[epoch16, step1608]: loss 3.610415
[epoch16, step1609]: loss 9.720353
[epoch16, step1610]: loss 4.531268
[epoch16, step1611]: loss 1.397657
[epoch16, step1612]: loss 1.524451
[epoch16, step1613]: loss 1.456658
[epoch16, step1614]: loss 1.081562
[epoch16, step1615]: loss 0.898382
[epoch16, step1616]: loss 0.962990
[epoch16, step1617]: loss 0.634655
[epoch16, step1618]: loss 2.701497
[epoch16, step1619]: loss 6.302182
[epoch16, step1620]: loss 0.689802
[epoch16, step1621]: loss 2.368930
[epoch16, step1622]: loss 0.632831
[epoch16, step1623]: loss 7.356159
[epoch16, step1624]: loss 0.645762
[epoch16, step1625]: loss 2.275243
[epoch16, step1626]: loss 0.643253
[epoch16, step1627]: loss 1.693109
[epoch16, step1628]: loss 3.727285
[epoch16, step1629]: loss 0.830991
[epoch16, step1630]: loss 10.454220
[epoch16, step1631]: loss 0.857327
[epoch16, step1632]: loss 8.068598
[epoch16, step1633]: loss 9.991091
[epoch16, step1634]: loss 5.691294
[epoch16, step1635]: loss 7.437040
[epoch16, step1636]: loss 1.441446
[epoch16, step1637]: loss 7.067976
[epoch16, step1638]: loss 3.046583
[epoch16, step1639]: loss 3.297386
[epoch16, step1640]: loss 18.546179
[epoch16, step1641]: loss 2.645202
[epoch16, step1642]: loss 2.801273
[epoch16, step1643]: loss 0.621247
[epoch16, step1644]: loss 1.006454
[epoch16, step1645]: loss 4.756684
[epoch16, step1646]: loss 7.008881
[epoch16, step1647]: loss 1.530797
[epoch16, step1648]: loss 18.689341
[epoch16, step1649]: loss 7.403174
[epoch16, step1650]: loss 3.567628
[epoch16, step1651]: loss 5.812424
[epoch16, step1652]: loss 1.936486
[epoch16, step1653]: loss 9.767025
[epoch16, step1654]: loss 10.158264
[epoch16, step1655]: loss 1.403969
[epoch16, step1656]: loss 1.333337
[epoch16, step1657]: loss 6.469850
[epoch16, step1658]: loss 3.549931
[epoch16, step1659]: loss 5.029953
[epoch16, step1660]: loss 1.665856
[epoch16, step1661]: loss 1.143761
[epoch16, step1662]: loss 1.399901
[epoch16, step1663]: loss 3.297781
[epoch16, step1664]: loss 0.663961
[epoch16, step1665]: loss 3.153732
[epoch16, step1666]: loss 17.821089
[epoch16, step1667]: loss 0.617366
[epoch16, step1668]: loss 9.912923
[epoch16, step1669]: loss 3.103904
[epoch16, step1670]: loss 1.334976
[epoch16, step1671]: loss 3.073163
[epoch16, step1672]: loss 1.037596
[epoch16, step1673]: loss 10.806129
[epoch16, step1674]: loss 4.763739
[epoch16, step1675]: loss 8.916048
[epoch16, step1676]: loss 1.093665
[epoch16, step1677]: loss 0.808881
[epoch16, step1678]: loss 1.237727
[epoch16, step1679]: loss 15.886722
[epoch16, step1680]: loss 1.599906
[epoch16, step1681]: loss 2.798583
[epoch16, step1682]: loss 1.847087
[epoch16, step1683]: loss 1.057858
[epoch16, step1684]: loss 11.772212
[epoch16, step1685]: loss 0.832850
[epoch16, step1686]: loss 7.636912
[epoch16, step1687]: loss 8.474753
[epoch16, step1688]: loss 2.434860
[epoch16, step1689]: loss 1.393811
[epoch16, step1690]: loss 4.428813
[epoch16, step1691]: loss 11.242455
[epoch16, step1692]: loss 1.679085
[epoch16, step1693]: loss 0.699262
[epoch16, step1694]: loss 3.244164
[epoch16, step1695]: loss 1.053909
[epoch16, step1696]: loss 1.144370
[epoch16, step1697]: loss 1.388577
[epoch16, step1698]: loss 12.457479
[epoch16, step1699]: loss 3.531141
[epoch16, step1700]: loss 1.304848
[epoch16, step1701]: loss 8.379473
[epoch16, step1702]: loss 3.432214
[epoch16, step1703]: loss 1.840946
[epoch16, step1704]: loss 10.680885
[epoch16, step1705]: loss 1.393561
[epoch16, step1706]: loss 10.324127
[epoch16, step1707]: loss 6.887886
[epoch16, step1708]: loss 0.862062
[epoch16, step1709]: loss 0.846373
[epoch16, step1710]: loss 4.519794
[epoch16, step1711]: loss 0.931583
[epoch16, step1712]: loss 2.463517
[epoch16, step1713]: loss 12.854907
[epoch16, step1714]: loss 0.981410
[epoch16, step1715]: loss 9.325548
[epoch16, step1716]: loss 2.433275
[epoch16, step1717]: loss 8.357390
[epoch16, step1718]: loss 1.686722
[epoch16, step1719]: loss 2.217163
[epoch16, step1720]: loss 3.929051
[epoch16, step1721]: loss 1.251492
[epoch16, step1722]: loss 2.340562
[epoch16, step1723]: loss 1.074513
[epoch16, step1724]: loss 6.130404
[epoch16, step1725]: loss 2.395217
[epoch16, step1726]: loss 7.349600
[epoch16, step1727]: loss 21.231209
[epoch16, step1728]: loss 1.015754
[epoch16, step1729]: loss 1.115054
[epoch16, step1730]: loss 1.038720
[epoch16, step1731]: loss 14.041259
[epoch16, step1732]: loss 8.521504
[epoch16, step1733]: loss 0.675600
[epoch16, step1734]: loss 8.888478
[epoch16, step1735]: loss 1.673889
[epoch16, step1736]: loss 10.062407
[epoch16, step1737]: loss 2.571843
[epoch16, step1738]: loss 2.526735
[epoch16, step1739]: loss 1.713889
[epoch16, step1740]: loss 3.321575
[epoch16, step1741]: loss 3.346962
[epoch16, step1742]: loss 8.864056
[epoch16, step1743]: loss 2.865172
[epoch16, step1744]: loss 1.206823
[epoch16, step1745]: loss 9.564936
[epoch16, step1746]: loss 2.828550
[epoch16, step1747]: loss 9.174134
[epoch16, step1748]: loss 1.215579
[epoch16, step1749]: loss 2.325097
[epoch16, step1750]: loss 2.019784
[epoch16, step1751]: loss 1.168582
[epoch16, step1752]: loss 8.434106
[epoch16, step1753]: loss 7.372685
[epoch16, step1754]: loss 3.304733
[epoch16, step1755]: loss 1.799953
[epoch16, step1756]: loss 5.655173
[epoch16, step1757]: loss 0.917602
[epoch16, step1758]: loss 3.586529
[epoch16, step1759]: loss 0.663354
[epoch16, step1760]: loss 1.045266
[epoch16, step1761]: loss 1.082980
[epoch16, step1762]: loss 1.393677
[epoch16, step1763]: loss 8.772621
[epoch16, step1764]: loss 2.796459
[epoch16, step1765]: loss 4.643548
[epoch16, step1766]: loss 14.866661
[epoch16, step1767]: loss 1.246865
[epoch16, step1768]: loss 1.171855
[epoch16, step1769]: loss 2.245932
[epoch16, step1770]: loss 6.865110
[epoch16, step1771]: loss 0.834316
[epoch16, step1772]: loss 0.888572
[epoch16, step1773]: loss 11.025455
[epoch16, step1774]: loss 1.035398
[epoch16, step1775]: loss 0.793770
[epoch16, step1776]: loss 5.867136
[epoch16, step1777]: loss 2.374606
[epoch16, step1778]: loss 0.624492
[epoch16, step1779]: loss 9.494933
[epoch16, step1780]: loss 2.304321
[epoch16, step1781]: loss 2.863452
[epoch16, step1782]: loss 4.127404
[epoch16, step1783]: loss 6.240899
[epoch16, step1784]: loss 3.449412
[epoch16, step1785]: loss 1.356674
[epoch16, step1786]: loss 9.301024
[epoch16, step1787]: loss 4.137023
[epoch16, step1788]: loss 1.737615
[epoch16, step1789]: loss 0.761646
[epoch16, step1790]: loss 2.971606
[epoch16, step1791]: loss 2.976271
[epoch16, step1792]: loss 1.978750
[epoch16, step1793]: loss 6.437435
[epoch16, step1794]: loss 3.255684
[epoch16, step1795]: loss 8.180889
[epoch16, step1796]: loss 3.138258
[epoch16, step1797]: loss 8.201014
[epoch16, step1798]: loss 1.512230
[epoch16, step1799]: loss 6.391885
[epoch16, step1800]: loss 2.214543
[epoch16, step1801]: loss 0.690936
[epoch16, step1802]: loss 5.685350
[epoch16, step1803]: loss 10.321292
[epoch16, step1804]: loss 7.602365
[epoch16, step1805]: loss 2.207825
[epoch16, step1806]: loss 2.849085
[epoch16, step1807]: loss 6.045230
[epoch16, step1808]: loss 18.397394
[epoch16, step1809]: loss 2.266744
[epoch16, step1810]: loss 0.582943
[epoch16, step1811]: loss 1.038368
[epoch16, step1812]: loss 0.765012
[epoch16, step1813]: loss 2.305448
[epoch16, step1814]: loss 6.267035
[epoch16, step1815]: loss 12.524851
[epoch16, step1816]: loss 8.752371
[epoch16, step1817]: loss 9.193597
[epoch16, step1818]: loss 19.778570
[epoch16, step1819]: loss 1.474929
[epoch16, step1820]: loss 0.718326
[epoch16, step1821]: loss 0.781564
[epoch16, step1822]: loss 8.935637
[epoch16, step1823]: loss 1.006418
[epoch16, step1824]: loss 1.693463
[epoch16, step1825]: loss 7.404548
[epoch16, step1826]: loss 0.709328
[epoch16, step1827]: loss 0.521549
[epoch16, step1828]: loss 2.609967
[epoch16, step1829]: loss 6.942442
[epoch16, step1830]: loss 0.891619
[epoch16, step1831]: loss 6.348954
[epoch16, step1832]: loss 11.019990
[epoch16, step1833]: loss 6.466158
[epoch16, step1834]: loss 0.820315
[epoch16, step1835]: loss 3.487236
[epoch16, step1836]: loss 1.941978
[epoch16, step1837]: loss 1.391173
[epoch16, step1838]: loss 6.880248
[epoch16, step1839]: loss 7.443516
[epoch16, step1840]: loss 4.350761
[epoch16, step1841]: loss 7.943838
[epoch16, step1842]: loss 6.021693
[epoch16, step1843]: loss 1.252601
[epoch16, step1844]: loss 3.976895
[epoch16, step1845]: loss 5.764155
[epoch16, step1846]: loss 6.432751
[epoch16, step1847]: loss 1.927482
[epoch16, step1848]: loss 1.165416
[epoch16, step1849]: loss 1.304799
[epoch16, step1850]: loss 2.431589
[epoch16, step1851]: loss 5.298266
[epoch16, step1852]: loss 12.813640
[epoch16, step1853]: loss 2.401191
[epoch16, step1854]: loss 4.443248
[epoch16, step1855]: loss 1.296628
[epoch16, step1856]: loss 2.220605
[epoch16, step1857]: loss 1.243265
[epoch16, step1858]: loss 2.742985
[epoch16, step1859]: loss 1.136932
[epoch16, step1860]: loss 0.689294
[epoch16, step1861]: loss 7.099825
[epoch16, step1862]: loss 2.028981
[epoch16, step1863]: loss 2.391118
[epoch16, step1864]: loss 14.941786
[epoch16, step1865]: loss 3.465007
[epoch16, step1866]: loss 1.181958
[epoch16, step1867]: loss 6.878657
[epoch16, step1868]: loss 0.684773
[epoch16, step1869]: loss 2.278949
[epoch16, step1870]: loss 1.700863
[epoch16, step1871]: loss 1.042450
[epoch16, step1872]: loss 4.689347
[epoch16, step1873]: loss 7.206700
[epoch16, step1874]: loss 8.044521
[epoch16, step1875]: loss 1.450641
[epoch16, step1876]: loss 10.669491
[epoch16, step1877]: loss 7.972258
[epoch16, step1878]: loss 0.919513
[epoch16, step1879]: loss 7.070400
[epoch16, step1880]: loss 2.223192
[epoch16, step1881]: loss 0.587195
[epoch16, step1882]: loss 6.411488
[epoch16, step1883]: loss 0.833158
[epoch16, step1884]: loss 1.096754
[epoch16, step1885]: loss 1.111851
[epoch16, step1886]: loss 0.918550
[epoch16, step1887]: loss 2.170036
[epoch16, step1888]: loss 0.981301
[epoch16, step1889]: loss 1.023126
[epoch16, step1890]: loss 1.138165
[epoch16, step1891]: loss 0.497975
[epoch16, step1892]: loss 0.617139
[epoch16, step1893]: loss 7.039555
[epoch16, step1894]: loss 8.910283
[epoch16, step1895]: loss 1.544958
[epoch16, step1896]: loss 1.230995
[epoch16, step1897]: loss 7.412050
[epoch16, step1898]: loss 1.967019
[epoch16, step1899]: loss 0.800166
[epoch16, step1900]: loss 3.049220
[epoch16, step1901]: loss 3.401149
[epoch16, step1902]: loss 2.152023
[epoch16, step1903]: loss 1.443638
[epoch16, step1904]: loss 7.978491
[epoch16, step1905]: loss 8.690251
[epoch16, step1906]: loss 8.868955
[epoch16, step1907]: loss 0.426649
[epoch16, step1908]: loss 1.143121
[epoch16, step1909]: loss 4.104228
[epoch16, step1910]: loss 1.733393
[epoch16, step1911]: loss 0.620764
[epoch16, step1912]: loss 9.836892
[epoch16, step1913]: loss 0.757307
[epoch16, step1914]: loss 8.868158
[epoch16, step1915]: loss 7.107987
[epoch16, step1916]: loss 15.894681
[epoch16, step1917]: loss 1.744759
[epoch16, step1918]: loss 2.950572
[epoch16, step1919]: loss 0.818591
[epoch16, step1920]: loss 6.477211
[epoch16, step1921]: loss 3.878327
[epoch16, step1922]: loss 0.733121
[epoch16, step1923]: loss 0.702093
[epoch16, step1924]: loss 3.535344
[epoch16, step1925]: loss 0.795765
[epoch16, step1926]: loss 10.254952
[epoch16, step1927]: loss 0.544198
[epoch16, step1928]: loss 8.760465
[epoch16, step1929]: loss 9.674994
[epoch16, step1930]: loss 4.320913
[epoch16, step1931]: loss 0.975990
[epoch16, step1932]: loss 1.953222
[epoch16, step1933]: loss 1.040911
[epoch16, step1934]: loss 0.687024
[epoch16, step1935]: loss 4.890002
[epoch16, step1936]: loss 2.416993
[epoch16, step1937]: loss 8.671257
[epoch16, step1938]: loss 22.082407
[epoch16, step1939]: loss 0.945670
[epoch16, step1940]: loss 2.218637
[epoch16, step1941]: loss 1.129899
[epoch16, step1942]: loss 9.036987
[epoch16, step1943]: loss 0.539964
[epoch16, step1944]: loss 1.928385
[epoch16, step1945]: loss 0.405437
[epoch16, step1946]: loss 12.260631
[epoch16, step1947]: loss 6.324417
[epoch16, step1948]: loss 1.146078
[epoch16, step1949]: loss 1.480859
[epoch16, step1950]: loss 2.211581
[epoch16, step1951]: loss 3.589502
[epoch16, step1952]: loss 23.254833
[epoch16, step1953]: loss 1.047684
[epoch16, step1954]: loss 10.520200
[epoch16, step1955]: loss 2.605282
[epoch16, step1956]: loss 1.399404
[epoch16, step1957]: loss 5.093932
[epoch16, step1958]: loss 2.030871
[epoch16, step1959]: loss 2.223740
[epoch16, step1960]: loss 1.757805
[epoch16, step1961]: loss 0.960643
[epoch16, step1962]: loss 1.352559
[epoch16, step1963]: loss 1.366564
[epoch16, step1964]: loss 0.729900
[epoch16, step1965]: loss 6.354402
[epoch16, step1966]: loss 2.808881
[epoch16, step1967]: loss 1.049311
[epoch16, step1968]: loss 1.376065
[epoch16, step1969]: loss 2.462974
[epoch16, step1970]: loss 6.139694
[epoch16, step1971]: loss 2.047962
[epoch16, step1972]: loss 3.560127
[epoch16, step1973]: loss 9.707709
[epoch16, step1974]: loss 1.278373
[epoch16, step1975]: loss 0.785924
[epoch16, step1976]: loss 0.961653
[epoch16, step1977]: loss 0.873789
[epoch16, step1978]: loss 1.116615
[epoch16, step1979]: loss 2.941712
[epoch16, step1980]: loss 1.408731
[epoch16, step1981]: loss 7.392709
[epoch16, step1982]: loss 7.582768
[epoch16, step1983]: loss 0.919049
[epoch16, step1984]: loss 2.311853
[epoch16, step1985]: loss 0.680687
[epoch16, step1986]: loss 8.136469
[epoch16, step1987]: loss 8.207310
[epoch16, step1988]: loss 1.824706
[epoch16, step1989]: loss 12.707848
[epoch16, step1990]: loss 3.684326
[epoch16, step1991]: loss 2.897073
[epoch16, step1992]: loss 1.749328
[epoch16, step1993]: loss 0.811862
[epoch16, step1994]: loss 6.205184
[epoch16, step1995]: loss 1.551933
[epoch16, step1996]: loss 2.886518
[epoch16, step1997]: loss 0.887420
[epoch16, step1998]: loss 12.942265
[epoch16, step1999]: loss 1.420610
[epoch16, step2000]: loss 2.067014
[epoch16, step2001]: loss 1.828166
[epoch16, step2002]: loss 2.433822
[epoch16, step2003]: loss 0.878960
[epoch16, step2004]: loss 8.760395
[epoch16, step2005]: loss 3.091124
[epoch16, step2006]: loss 0.773352
[epoch16, step2007]: loss 1.579576
[epoch16, step2008]: loss 5.160256
[epoch16, step2009]: loss 2.182892
[epoch16, step2010]: loss 2.043431
[epoch16, step2011]: loss 2.431118
[epoch16, step2012]: loss 0.628297
[epoch16, step2013]: loss 6.765437
[epoch16, step2014]: loss 17.812948
[epoch16, step2015]: loss 1.345018
[epoch16, step2016]: loss 3.293900
[epoch16, step2017]: loss 3.015270
[epoch16, step2018]: loss 1.372781
[epoch16, step2019]: loss 0.583087
[epoch16, step2020]: loss 1.728092
[epoch16, step2021]: loss 10.188873
[epoch16, step2022]: loss 3.111439
[epoch16, step2023]: loss 1.954843
[epoch16, step2024]: loss 1.831305
[epoch16, step2025]: loss 1.986443
[epoch16, step2026]: loss 0.776912
[epoch16, step2027]: loss 2.213217
[epoch16, step2028]: loss 4.339248
[epoch16, step2029]: loss 8.374907
[epoch16, step2030]: loss 1.265364
[epoch16, step2031]: loss 8.590763
[epoch16, step2032]: loss 1.409527
[epoch16, step2033]: loss 0.882034
[epoch16, step2034]: loss 2.074276
[epoch16, step2035]: loss 0.560138
[epoch16, step2036]: loss 1.511634
[epoch16, step2037]: loss 1.968791
[epoch16, step2038]: loss 5.611896
[epoch16, step2039]: loss 0.543768
[epoch16, step2040]: loss 7.676382
[epoch16, step2041]: loss 1.189274
[epoch16, step2042]: loss 3.724730
[epoch16, step2043]: loss 1.789980
[epoch16, step2044]: loss 0.944623
[epoch16, step2045]: loss 0.571189
[epoch16, step2046]: loss 1.085894
[epoch16, step2047]: loss 0.612014
[epoch16, step2048]: loss 0.828234
[epoch16, step2049]: loss 0.906938
[epoch16, step2050]: loss 5.861208
[epoch16, step2051]: loss 15.085198
[epoch16, step2052]: loss 1.403794
[epoch16, step2053]: loss 11.769032
[epoch16, step2054]: loss 6.946369
[epoch16, step2055]: loss 0.785380
[epoch16, step2056]: loss 1.409787
[epoch16, step2057]: loss 1.697131
[epoch16, step2058]: loss 1.373913
[epoch16, step2059]: loss 18.133123
[epoch16, step2060]: loss 1.619070
[epoch16, step2061]: loss 0.722523
[epoch16, step2062]: loss 0.589716
[epoch16, step2063]: loss 0.626445
[epoch16, step2064]: loss 3.254927
[epoch16, step2065]: loss 0.805899
[epoch16, step2066]: loss 4.288815
[epoch16, step2067]: loss 18.700195
[epoch16, step2068]: loss 0.912304
[epoch16, step2069]: loss 0.657063
[epoch16, step2070]: loss 6.504022
[epoch16, step2071]: loss 1.949992
[epoch16, step2072]: loss 7.869725
[epoch16, step2073]: loss 1.146286
[epoch16, step2074]: loss 4.594842
[epoch16, step2075]: loss 1.527458
[epoch16, step2076]: loss 0.949849
[epoch16, step2077]: loss 7.189926
[epoch16, step2078]: loss 0.684399
[epoch16, step2079]: loss 2.446120
[epoch16, step2080]: loss 14.563505
[epoch16, step2081]: loss 1.261399
[epoch16, step2082]: loss 14.911430
[epoch16, step2083]: loss 6.556342
[epoch16, step2084]: loss 0.997307
[epoch16, step2085]: loss 0.717773
[epoch16, step2086]: loss 2.898485
[epoch16, step2087]: loss 2.439011
[epoch16, step2088]: loss 10.680320
[epoch16, step2089]: loss 0.803108
[epoch16, step2090]: loss 4.023033
[epoch16, step2091]: loss 2.001541
[epoch16, step2092]: loss 7.193544
[epoch16, step2093]: loss 0.969918
[epoch16, step2094]: loss 0.881636
[epoch16, step2095]: loss 14.401363
[epoch16, step2096]: loss 9.320572
[epoch16, step2097]: loss 11.837689
[epoch16, step2098]: loss 2.261774
[epoch16, step2099]: loss 7.200216
[epoch16, step2100]: loss 1.151023
[epoch16, step2101]: loss 5.761379
[epoch16, step2102]: loss 1.352463
[epoch16, step2103]: loss 0.613508
[epoch16, step2104]: loss 3.282672
[epoch16, step2105]: loss 1.900637
[epoch16, step2106]: loss 13.418529
[epoch16, step2107]: loss 0.619785
[epoch16, step2108]: loss 16.312658
[epoch16, step2109]: loss 0.637241
[epoch16, step2110]: loss 1.466625
[epoch16, step2111]: loss 2.815688
[epoch16, step2112]: loss 1.749445
[epoch16, step2113]: loss 1.191246
[epoch16, step2114]: loss 8.519732
[epoch16, step2115]: loss 0.873835
[epoch16, step2116]: loss 0.590643
[epoch16, step2117]: loss 2.167051
[epoch16, step2118]: loss 2.330220
[epoch16, step2119]: loss 1.450772
[epoch16, step2120]: loss 0.615670
[epoch16, step2121]: loss 0.972811
[epoch16, step2122]: loss 1.778241
[epoch16, step2123]: loss 1.348678
[epoch16, step2124]: loss 7.256935
[epoch16, step2125]: loss 14.165018
[epoch16, step2126]: loss 1.122491
[epoch16, step2127]: loss 1.854495
[epoch16, step2128]: loss 2.694201
[epoch16, step2129]: loss 1.354648
[epoch16, step2130]: loss 2.162431
[epoch16, step2131]: loss 1.142222
[epoch16, step2132]: loss 0.574816
[epoch16, step2133]: loss 6.688779
[epoch16, step2134]: loss 5.127044
[epoch16, step2135]: loss 1.065850
[epoch16, step2136]: loss 10.183677
[epoch16, step2137]: loss 7.857577
[epoch16, step2138]: loss 12.356015
[epoch16, step2139]: loss 1.178236
[epoch16, step2140]: loss 7.372758
[epoch16, step2141]: loss 26.306984
[epoch16, step2142]: loss 6.412273
[epoch16, step2143]: loss 0.986864
[epoch16, step2144]: loss 1.385557
[epoch16, step2145]: loss 14.402284
[epoch16, step2146]: loss 7.344196
[epoch16, step2147]: loss 3.684988
[epoch16, step2148]: loss 6.569047
[epoch16, step2149]: loss 6.849405
[epoch16, step2150]: loss 2.207041
[epoch16, step2151]: loss 0.737961
[epoch16, step2152]: loss 0.885710
[epoch16, step2153]: loss 6.322098
[epoch16, step2154]: loss 1.024053
[epoch16, step2155]: loss 0.848877
[epoch16, step2156]: loss 1.395525
[epoch16, step2157]: loss 3.263467
[epoch16, step2158]: loss 1.043507
[epoch16, step2159]: loss 3.065019
[epoch16, step2160]: loss 8.056702
[epoch16, step2161]: loss 1.217525
[epoch16, step2162]: loss 1.417015
[epoch16, step2163]: loss 1.070004
[epoch16, step2164]: loss 1.625579
[epoch16, step2165]: loss 1.975080
[epoch16, step2166]: loss 0.934247
[epoch16, step2167]: loss 2.900620
[epoch16, step2168]: loss 1.424283
[epoch16, step2169]: loss 0.644806
[epoch16, step2170]: loss 0.784551
[epoch16, step2171]: loss 1.529821
[epoch16, step2172]: loss 0.973349
[epoch16, step2173]: loss 0.957154
[epoch16, step2174]: loss 1.053103
[epoch16, step2175]: loss 18.532873
[epoch16, step2176]: loss 6.324616
[epoch16, step2177]: loss 16.983454
[epoch16, step2178]: loss 2.653356
[epoch16, step2179]: loss 2.341780
[epoch16, step2180]: loss 0.625296
[epoch16, step2181]: loss 6.666975
[epoch16, step2182]: loss 7.979311
[epoch16, step2183]: loss 7.949664
[epoch16, step2184]: loss 0.829672
[epoch16, step2185]: loss 1.967490
[epoch16, step2186]: loss 0.896412
[epoch16, step2187]: loss 9.847820
[epoch16, step2188]: loss 1.248003
[epoch16, step2189]: loss 1.189242
[epoch16, step2190]: loss 2.843424
[epoch16, step2191]: loss 1.037742
[epoch16, step2192]: loss 14.632719
[epoch16, step2193]: loss 1.442044
[epoch16, step2194]: loss 3.383515
[epoch16, step2195]: loss 1.716885
[epoch16, step2196]: loss 0.917817
[epoch16, step2197]: loss 0.508772
[epoch16, step2198]: loss 1.098140
[epoch16, step2199]: loss 1.313096
[epoch16, step2200]: loss 21.200842
[epoch16, step2201]: loss 1.195734
[epoch16, step2202]: loss 0.756619
[epoch16, step2203]: loss 6.728430
[epoch16, step2204]: loss 4.789583
[epoch16, step2205]: loss 1.350421
[epoch16, step2206]: loss 0.615105
[epoch16, step2207]: loss 1.936612
[epoch16, step2208]: loss 20.890671
[epoch16, step2209]: loss 0.811319
[epoch16, step2210]: loss 1.682242
[epoch16, step2211]: loss 16.290359
[epoch16, step2212]: loss 0.953014
[epoch16, step2213]: loss 1.063870
[epoch16, step2214]: loss 13.031063
[epoch16, step2215]: loss 5.946682
[epoch16, step2216]: loss 6.860078
[epoch16, step2217]: loss 0.639356
[epoch16, step2218]: loss 0.893377
[epoch16, step2219]: loss 0.937824
[epoch16, step2220]: loss 9.651107
[epoch16, step2221]: loss 0.662835
[epoch16, step2222]: loss 0.858001
[epoch16, step2223]: loss 1.194475
[epoch16, step2224]: loss 23.310038
[epoch16, step2225]: loss 7.702204
[epoch16, step2226]: loss 1.240323
[epoch16, step2227]: loss 2.247902
[epoch16, step2228]: loss 7.571513
[epoch16, step2229]: loss 1.203683
[epoch16, step2230]: loss 2.561257
[epoch16, step2231]: loss 0.750491
[epoch16, step2232]: loss 8.097542
[epoch16, step2233]: loss 6.320794
[epoch16, step2234]: loss 0.832159
[epoch16, step2235]: loss 0.564830
[epoch16, step2236]: loss 0.705335
[epoch16, step2237]: loss 1.785837
[epoch16, step2238]: loss 11.224060
[epoch16, step2239]: loss 1.360706
[epoch16, step2240]: loss 22.007849
[epoch16, step2241]: loss 2.580720
[epoch16, step2242]: loss 11.064918
[epoch16, step2243]: loss 0.840138
[epoch16, step2244]: loss 8.588026
[epoch16, step2245]: loss 5.541558
[epoch16, step2246]: loss 2.295135
[epoch16, step2247]: loss 9.009462
[epoch16, step2248]: loss 7.245574
[epoch16, step2249]: loss 0.992764
[epoch16, step2250]: loss 0.795588
[epoch16, step2251]: loss 0.934045
[epoch16, step2252]: loss 0.785779
[epoch16, step2253]: loss 0.996763
[epoch16, step2254]: loss 1.137597
[epoch16, step2255]: loss 9.459511
[epoch16, step2256]: loss 2.749761
[epoch16, step2257]: loss 4.136928
[epoch16, step2258]: loss 4.166093
[epoch16, step2259]: loss 2.165753
[epoch16, step2260]: loss 4.135725
[epoch16, step2261]: loss 19.558149
[epoch16, step2262]: loss 3.108066
[epoch16, step2263]: loss 1.954549
[epoch16, step2264]: loss 0.733023
[epoch16, step2265]: loss 1.769266
[epoch16, step2266]: loss 1.306934
[epoch16, step2267]: loss 8.315492
[epoch16, step2268]: loss 1.051255
[epoch16, step2269]: loss 7.475605
[epoch16, step2270]: loss 1.106103
[epoch16, step2271]: loss 1.749662
[epoch16, step2272]: loss 0.621822
[epoch16, step2273]: loss 0.595078
[epoch16, step2274]: loss 1.371243
[epoch16, step2275]: loss 1.276118
[epoch16, step2276]: loss 4.174830
[epoch16, step2277]: loss 11.343388
[epoch16, step2278]: loss 2.167387
[epoch16, step2279]: loss 0.600839
[epoch16, step2280]: loss 8.863104
[epoch16, step2281]: loss 1.191217
[epoch16, step2282]: loss 3.238210
[epoch16, step2283]: loss 2.916061
[epoch16, step2284]: loss 2.026255
[epoch16, step2285]: loss 2.183437
[epoch16, step2286]: loss 2.222340
[epoch16, step2287]: loss 0.883712
[epoch16, step2288]: loss 5.863759
[epoch16, step2289]: loss 11.817073
[epoch16, step2290]: loss 2.280675
[epoch16, step2291]: loss 0.627459
[epoch16, step2292]: loss 0.786280
[epoch16, step2293]: loss 1.048108
[epoch16, step2294]: loss 13.963041
[epoch16, step2295]: loss 8.225685
[epoch16, step2296]: loss 7.091470
[epoch16, step2297]: loss 2.048980
[epoch16, step2298]: loss 0.742582
[epoch16, step2299]: loss 0.738004
[epoch16, step2300]: loss 4.634527
[epoch16, step2301]: loss 2.902189
[epoch16, step2302]: loss 0.858939
[epoch16, step2303]: loss 9.178115
[epoch16, step2304]: loss 6.595730
[epoch16, step2305]: loss 1.388919
[epoch16, step2306]: loss 6.379095
[epoch16, step2307]: loss 6.591928
[epoch16, step2308]: loss 1.547334
[epoch16, step2309]: loss 0.615492
[epoch16, step2310]: loss 6.619115
[epoch16, step2311]: loss 0.813317
[epoch16, step2312]: loss 6.276147
[epoch16, step2313]: loss 1.299356
[epoch16, step2314]: loss 2.520318
[epoch16, step2315]: loss 0.676957
[epoch16, step2316]: loss 8.156417
[epoch16, step2317]: loss 6.957359
[epoch16, step2318]: loss 0.996885
[epoch16, step2319]: loss 0.781224
[epoch16, step2320]: loss 2.166148
[epoch16, step2321]: loss 2.663800
[epoch16, step2322]: loss 0.589093
[epoch16, step2323]: loss 2.514293
[epoch16, step2324]: loss 2.487988
[epoch16, step2325]: loss 11.484348
[epoch16, step2326]: loss 6.128820
[epoch16, step2327]: loss 0.441272
[epoch16, step2328]: loss 1.129279
[epoch16, step2329]: loss 3.181469
[epoch16, step2330]: loss 1.220688
[epoch16, step2331]: loss 0.891880
[epoch16, step2332]: loss 0.784485
[epoch16, step2333]: loss 1.380234
[epoch16, step2334]: loss 5.718090
[epoch16, step2335]: loss 1.264548
[epoch16, step2336]: loss 1.991816
[epoch16, step2337]: loss 1.196693
[epoch16, step2338]: loss 2.773825
[epoch16, step2339]: loss 7.417987
[epoch16, step2340]: loss 0.840520
[epoch16, step2341]: loss 2.052435
[epoch16, step2342]: loss 0.903009
[epoch16, step2343]: loss 1.475717
[epoch16, step2344]: loss 0.985158
[epoch16, step2345]: loss 1.039958
[epoch16, step2346]: loss 21.689203
[epoch16, step2347]: loss 6.130510
[epoch16, step2348]: loss 1.829275
[epoch16, step2349]: loss 6.241389
[epoch16, step2350]: loss 1.190168
[epoch16, step2351]: loss 0.793924
[epoch16, step2352]: loss 1.554773
[epoch16, step2353]: loss 3.311617
[epoch16, step2354]: loss 1.690077
[epoch16, step2355]: loss 1.682103
[epoch16, step2356]: loss 9.501570
[epoch16, step2357]: loss 0.480696
[epoch16, step2358]: loss 11.213202
[epoch16, step2359]: loss 1.670721
[epoch16, step2360]: loss 10.872187
[epoch16, step2361]: loss 0.948195
[epoch16, step2362]: loss 6.721364
[epoch16, step2363]: loss 1.387451
[epoch16, step2364]: loss 1.225728
[epoch16, step2365]: loss 1.823429
[epoch16, step2366]: loss 1.861774
[epoch16, step2367]: loss 0.828941
[epoch16, step2368]: loss 12.270029
[epoch16, step2369]: loss 2.297586
[epoch16, step2370]: loss 5.742125
[epoch16, step2371]: loss 0.638146
[epoch16, step2372]: loss 0.871674
[epoch16, step2373]: loss 1.527873
[epoch16, step2374]: loss 1.225578
[epoch16, step2375]: loss 0.961953
[epoch16, step2376]: loss 9.127127
[epoch16, step2377]: loss 1.805039
[epoch16, step2378]: loss 0.879025
[epoch16, step2379]: loss 3.894525
[epoch16, step2380]: loss 9.150746
[epoch16, step2381]: loss 0.871127
[epoch16, step2382]: loss 12.454574
[epoch16, step2383]: loss 0.943589
[epoch16, step2384]: loss 0.448223
[epoch16, step2385]: loss 3.077093
[epoch16, step2386]: loss 1.536424
[epoch16, step2387]: loss 2.340508
[epoch16, step2388]: loss 1.308232
[epoch16, step2389]: loss 7.568417
[epoch16, step2390]: loss 1.870491
[epoch16, step2391]: loss 2.068807
[epoch16, step2392]: loss 1.199743
[epoch16, step2393]: loss 13.143744
[epoch16, step2394]: loss 8.469086
[epoch16, step2395]: loss 2.587309
[epoch16, step2396]: loss 0.779268
[epoch16, step2397]: loss 1.234493
[epoch16, step2398]: loss 0.652431
[epoch16, step2399]: loss 2.233747
[epoch16, step2400]: loss 0.543907
[epoch16, step2401]: loss 1.166214
[epoch16, step2402]: loss 15.899609
[epoch16, step2403]: loss 4.042859
[epoch16, step2404]: loss 2.817240
[epoch16, step2405]: loss 1.141815
[epoch16, step2406]: loss 1.651912
[epoch16, step2407]: loss 17.117186
[epoch16, step2408]: loss 12.000356
[epoch16, step2409]: loss 0.487201
[epoch16, step2410]: loss 2.788444
[epoch16, step2411]: loss 10.890502
[epoch16, step2412]: loss 0.762006
[epoch16, step2413]: loss 5.812857
[epoch16, step2414]: loss 0.687069
[epoch16, step2415]: loss 1.185363
[epoch16, step2416]: loss 3.826467
[epoch16, step2417]: loss 3.874270
[epoch16, step2418]: loss 1.158883
[epoch16, step2419]: loss 0.873107
[epoch16, step2420]: loss 0.714679
[epoch16, step2421]: loss 0.656409
[epoch16, step2422]: loss 1.422223
[epoch16, step2423]: loss 0.724382
[epoch16, step2424]: loss 2.364873
[epoch16, step2425]: loss 0.738379
[epoch16, step2426]: loss 2.375500
[epoch16, step2427]: loss 6.718007
[epoch16, step2428]: loss 0.989138
[epoch16, step2429]: loss 13.724132
[epoch16, step2430]: loss 6.595176
[epoch16, step2431]: loss 0.583469
[epoch16, step2432]: loss 3.985298
[epoch16, step2433]: loss 0.845232
[epoch16, step2434]: loss 1.553959
[epoch16, step2435]: loss 0.676416
[epoch16, step2436]: loss 0.881745
[epoch16, step2437]: loss 0.670636
[epoch16, step2438]: loss 1.701822
[epoch16, step2439]: loss 7.837086
[epoch16, step2440]: loss 0.836905
[epoch16, step2441]: loss 1.449512
[epoch16, step2442]: loss 5.411205
[epoch16, step2443]: loss 1.693661
[epoch16, step2444]: loss 6.464565
[epoch16, step2445]: loss 0.875840
[epoch16, step2446]: loss 14.571039
[epoch16, step2447]: loss 1.401289
[epoch16, step2448]: loss 0.731637
[epoch16, step2449]: loss 1.066325
[epoch16, step2450]: loss 9.228966
[epoch16, step2451]: loss 0.579251
[epoch16, step2452]: loss 0.645717
[epoch16, step2453]: loss 1.116160
[epoch16, step2454]: loss 3.536018
[epoch16, step2455]: loss 3.895367
[epoch16, step2456]: loss 9.427568
[epoch16, step2457]: loss 0.791212
[epoch16, step2458]: loss 16.338266
[epoch16, step2459]: loss 2.335154
[epoch16, step2460]: loss 1.310456
[epoch16, step2461]: loss 1.048614
[epoch16, step2462]: loss 0.627767
[epoch16, step2463]: loss 0.693573
[epoch16, step2464]: loss 11.224978
[epoch16, step2465]: loss 0.771427
[epoch16, step2466]: loss 0.925019
[epoch16, step2467]: loss 1.094369
[epoch16, step2468]: loss 12.566940
[epoch16, step2469]: loss 6.741752
[epoch16, step2470]: loss 0.497143
[epoch16, step2471]: loss 1.433056
[epoch16, step2472]: loss 5.999041
[epoch16, step2473]: loss 0.607142
[epoch16, step2474]: loss 0.744276
[epoch16, step2475]: loss 0.499156
[epoch16, step2476]: loss 1.676346
[epoch16, step2477]: loss 1.911641
[epoch16, step2478]: loss 0.862934
[epoch16, step2479]: loss 0.571565
[epoch16, step2480]: loss 1.353682
[epoch16, step2481]: loss 0.416237
[epoch16, step2482]: loss 2.544242
[epoch16, step2483]: loss 21.639982
[epoch16, step2484]: loss 5.058558
[epoch16, step2485]: loss 2.693473
[epoch16, step2486]: loss 6.953359
[epoch16, step2487]: loss 2.938408
[epoch16, step2488]: loss 12.510574
[epoch16, step2489]: loss 0.555263
[epoch16, step2490]: loss 2.937669
[epoch16, step2491]: loss 7.922160
[epoch16, step2492]: loss 6.423805
[epoch16, step2493]: loss 0.985318
[epoch16, step2494]: loss 1.348298
[epoch16, step2495]: loss 2.979996
[epoch16, step2496]: loss 0.714218
[epoch16, step2497]: loss 1.087109
[epoch16, step2498]: loss 1.907135
[epoch16, step2499]: loss 1.952965
[epoch16, step2500]: loss 9.343390
[epoch16, step2501]: loss 0.714282
[epoch16, step2502]: loss 0.775368
[epoch16, step2503]: loss 2.056165
[epoch16, step2504]: loss 0.854076
[epoch16, step2505]: loss 0.943061
[epoch16, step2506]: loss 2.510738
[epoch16, step2507]: loss 1.010648
[epoch16, step2508]: loss 6.770657
[epoch16, step2509]: loss 0.764816
[epoch16, step2510]: loss 1.008409
[epoch16, step2511]: loss 10.994300
[epoch16, step2512]: loss 1.704981
[epoch16, step2513]: loss 1.062049
[epoch16, step2514]: loss 5.804202
[epoch16, step2515]: loss 12.390530
[epoch16, step2516]: loss 1.969489
[epoch16, step2517]: loss 7.374724
[epoch16, step2518]: loss 7.676346
[epoch16, step2519]: loss 12.106565
[epoch16, step2520]: loss 0.437477
[epoch16, step2521]: loss 3.260116
[epoch16, step2522]: loss 0.961228
[epoch16, step2523]: loss 10.654206
[epoch16, step2524]: loss 1.516572
[epoch16, step2525]: loss 0.740027
[epoch16, step2526]: loss 7.511846
[epoch16, step2527]: loss 1.150566
[epoch16, step2528]: loss 2.500358
[epoch16, step2529]: loss 1.224404
[epoch16, step2530]: loss 1.028248
[epoch16, step2531]: loss 9.805128
[epoch16, step2532]: loss 2.886550
[epoch16, step2533]: loss 4.447048
[epoch16, step2534]: loss 6.977516
[epoch16, step2535]: loss 1.329572
[epoch16, step2536]: loss 5.854698
[epoch16, step2537]: loss 0.546190
[epoch16, step2538]: loss 6.861373
[epoch16, step2539]: loss 1.211870
[epoch16, step2540]: loss 7.635827
[epoch16, step2541]: loss 3.553781
[epoch16, step2542]: loss 0.635097
[epoch16, step2543]: loss 1.094126
[epoch16, step2544]: loss 5.871372
[epoch16, step2545]: loss 1.357716
[epoch16, step2546]: loss 0.907891
[epoch16, step2547]: loss 6.473527
[epoch16, step2548]: loss 1.896644
[epoch16, step2549]: loss 0.719274
[epoch16, step2550]: loss 17.153320
[epoch16, step2551]: loss 7.965084
[epoch16, step2552]: loss 2.182433
[epoch16, step2553]: loss 1.834736
[epoch16, step2554]: loss 0.707221
[epoch16, step2555]: loss 0.836789
[epoch16, step2556]: loss 1.034414
[epoch16, step2557]: loss 2.123183
[epoch16, step2558]: loss 19.361393
[epoch16, step2559]: loss 1.088826
[epoch16, step2560]: loss 1.318539
[epoch16, step2561]: loss 1.710178
[epoch16, step2562]: loss 0.808012
[epoch16, step2563]: loss 0.477451
[epoch16, step2564]: loss 6.596179
[epoch16, step2565]: loss 1.848308
[epoch16, step2566]: loss 1.972837
[epoch16, step2567]: loss 0.911987
[epoch16, step2568]: loss 0.875949
[epoch16, step2569]: loss 1.544166
[epoch16, step2570]: loss 6.691211
[epoch16, step2571]: loss 6.717443
[epoch16, step2572]: loss 1.333113
[epoch16, step2573]: loss 0.889102
[epoch16, step2574]: loss 3.104173
[epoch16, step2575]: loss 1.879999
[epoch16, step2576]: loss 2.021280
[epoch16, step2577]: loss 0.667561
[epoch16, step2578]: loss 0.900367
[epoch16, step2579]: loss 1.000785
[epoch16, step2580]: loss 8.263013
[epoch16, step2581]: loss 2.273520
[epoch16, step2582]: loss 0.724047
[epoch16, step2583]: loss 10.085522
[epoch16, step2584]: loss 1.707971
[epoch16, step2585]: loss 1.045905
[epoch16, step2586]: loss 0.936117
[epoch16, step2587]: loss 12.936592
[epoch16, step2588]: loss 1.435850
[epoch16, step2589]: loss 9.372376
[epoch16, step2590]: loss 19.063305
[epoch16, step2591]: loss 1.640860
[epoch16, step2592]: loss 14.329404
[epoch16, step2593]: loss 3.287834
[epoch16, step2594]: loss 2.021749
[epoch16, step2595]: loss 8.207855
[epoch16, step2596]: loss 9.818814
[epoch16, step2597]: loss 14.431797
[epoch16, step2598]: loss 3.771822
[epoch16, step2599]: loss 0.781276
[epoch16, step2600]: loss 0.595132
[epoch16, step2601]: loss 1.297004
[epoch16, step2602]: loss 4.993845
[epoch16, step2603]: loss 1.535130
[epoch16, step2604]: loss 14.457045
[epoch16, step2605]: loss 12.173055
[epoch16, step2606]: loss 2.241963
[epoch16, step2607]: loss 11.770290
[epoch16, step2608]: loss 1.127553
[epoch16, step2609]: loss 1.617574
[epoch16, step2610]: loss 0.660187
[epoch16, step2611]: loss 8.509385
[epoch16, step2612]: loss 11.771040
[epoch16, step2613]: loss 2.717865
[epoch16, step2614]: loss 15.830899
[epoch16, step2615]: loss 0.779153
[epoch16, step2616]: loss 7.464891
[epoch16, step2617]: loss 5.430119
[epoch16, step2618]: loss 8.983919
[epoch16, step2619]: loss 2.705113
[epoch16, step2620]: loss 0.787650
[epoch16, step2621]: loss 3.492176
[epoch16, step2622]: loss 7.481782
[epoch16, step2623]: loss 11.293536
[epoch16, step2624]: loss 1.663881
[epoch16, step2625]: loss 1.058875
[epoch16, step2626]: loss 8.659178
[epoch16, step2627]: loss 8.646109
[epoch16, step2628]: loss 1.275396
[epoch16, step2629]: loss 1.342171
[epoch16, step2630]: loss 2.122938
[epoch16, step2631]: loss 1.681471
[epoch16, step2632]: loss 1.544464
[epoch16, step2633]: loss 18.460691
[epoch16, step2634]: loss 1.540474
[epoch16, step2635]: loss 1.428024
[epoch16, step2636]: loss 7.957911
[epoch16, step2637]: loss 0.976369
[epoch16, step2638]: loss 2.303035
[epoch16, step2639]: loss 0.875265
[epoch16, step2640]: loss 20.038671
[epoch16, step2641]: loss 1.473798
[epoch16, step2642]: loss 16.196960
[epoch16, step2643]: loss 0.582453
[epoch16, step2644]: loss 1.005398
[epoch16, step2645]: loss 15.709393
[epoch16, step2646]: loss 0.834522
[epoch16, step2647]: loss 2.045769
[epoch16, step2648]: loss 9.938095
[epoch16, step2649]: loss 10.942966
[epoch16, step2650]: loss 0.465836
[epoch16, step2651]: loss 0.679015
[epoch16, step2652]: loss 1.321206
[epoch16, step2653]: loss 1.066890
[epoch16, step2654]: loss 8.687395
[epoch16, step2655]: loss 9.043573
[epoch16, step2656]: loss 7.160330
[epoch16, step2657]: loss 0.640083
[epoch16, step2658]: loss 2.470452
[epoch16, step2659]: loss 10.011418
[epoch16, step2660]: loss 0.720153
[epoch16, step2661]: loss 2.439424
[epoch16, step2662]: loss 1.500044
[epoch16, step2663]: loss 4.537354
[epoch16, step2664]: loss 7.006882
[epoch16, step2665]: loss 8.473021
[epoch16, step2666]: loss 0.863258
[epoch16, step2667]: loss 0.869899
[epoch16, step2668]: loss 0.947340
[epoch16, step2669]: loss 1.236815
[epoch16, step2670]: loss 0.512042
[epoch16, step2671]: loss 11.200308
[epoch16, step2672]: loss 1.304644
[epoch16, step2673]: loss 0.879608
[epoch16, step2674]: loss 0.661007
[epoch16, step2675]: loss 2.776365
[epoch16, step2676]: loss 1.101547
[epoch16, step2677]: loss 2.393842
[epoch16, step2678]: loss 4.941652
[epoch16, step2679]: loss 0.627094
[epoch16, step2680]: loss 1.640472
[epoch16, step2681]: loss 7.094028
[epoch16, step2682]: loss 11.242814
[epoch16, step2683]: loss 2.045433
[epoch16, step2684]: loss 1.609789
[epoch16, step2685]: loss 0.723016
[epoch16, step2686]: loss 7.835629
[epoch16, step2687]: loss 1.058717
[epoch16, step2688]: loss 1.136025
[epoch16, step2689]: loss 0.620638
[epoch16, step2690]: loss 6.555682
[epoch16, step2691]: loss 1.304465
[epoch16, step2692]: loss 3.072681
[epoch16, step2693]: loss 1.386374
[epoch16, step2694]: loss 6.765524
[epoch16, step2695]: loss 0.745007
[epoch16, step2696]: loss 1.218560
[epoch16, step2697]: loss 1.203096
[epoch16, step2698]: loss 2.190354
[epoch16, step2699]: loss 2.397651
[epoch16, step2700]: loss 2.881483
[epoch16, step2701]: loss 0.957790
[epoch16, step2702]: loss 0.586221
[epoch16, step2703]: loss 1.393365
[epoch16, step2704]: loss 9.262465
[epoch16, step2705]: loss 1.169968
[epoch16, step2706]: loss 6.932832
[epoch16, step2707]: loss 2.864286
[epoch16, step2708]: loss 1.834240
[epoch16, step2709]: loss 0.745628
[epoch16, step2710]: loss 0.848109
[epoch16, step2711]: loss 2.496448
[epoch16, step2712]: loss 0.535220
[epoch16, step2713]: loss 0.822163
[epoch16, step2714]: loss 0.891454
[epoch16, step2715]: loss 14.080164
[epoch16, step2716]: loss 0.960481
[epoch16, step2717]: loss 0.618735
[epoch16, step2718]: loss 0.912666
[epoch16, step2719]: loss 3.579997
[epoch16, step2720]: loss 0.690698
[epoch16, step2721]: loss 0.998121
[epoch16, step2722]: loss 5.512684
[epoch16, step2723]: loss 0.853689
[epoch16, step2724]: loss 0.705783
[epoch16, step2725]: loss 12.278461
[epoch16, step2726]: loss 2.558582
[epoch16, step2727]: loss 1.240400
[epoch16, step2728]: loss 6.860105
[epoch16, step2729]: loss 7.374228
[epoch16, step2730]: loss 0.778584
[epoch16, step2731]: loss 0.867605
[epoch16, step2732]: loss 1.226129
[epoch16, step2733]: loss 1.079791
[epoch16, step2734]: loss 0.514001
[epoch16, step2735]: loss 1.614908
[epoch16, step2736]: loss 13.933952
[epoch16, step2737]: loss 0.652467
[epoch16, step2738]: loss 3.601043
[epoch16, step2739]: loss 6.492176
[epoch16, step2740]: loss 1.767041
[epoch16, step2741]: loss 0.784825
[epoch16, step2742]: loss 2.047761
[epoch16, step2743]: loss 1.089501
[epoch16, step2744]: loss 0.825925
[epoch16, step2745]: loss 1.277757
[epoch16, step2746]: loss 0.566705
[epoch16, step2747]: loss 2.475376
[epoch16, step2748]: loss 10.970035
[epoch16, step2749]: loss 0.578408
[epoch16, step2750]: loss 0.628276
[epoch16, step2751]: loss 1.071711
[epoch16, step2752]: loss 0.903761
[epoch16, step2753]: loss 15.515253
[epoch16, step2754]: loss 3.549997
[epoch16, step2755]: loss 1.445974
[epoch16, step2756]: loss 4.723703
[epoch16, step2757]: loss 14.488273
[epoch16, step2758]: loss 0.672317
[epoch16, step2759]: loss 4.307582
[epoch16, step2760]: loss 3.025812
[epoch16, step2761]: loss 4.980482
[epoch16, step2762]: loss 0.700229
[epoch16, step2763]: loss 9.852205
[epoch16, step2764]: loss 0.574235
[epoch16, step2765]: loss 1.020346
[epoch16, step2766]: loss 13.428184
[epoch16, step2767]: loss 1.422119
[epoch16, step2768]: loss 2.678982
[epoch16, step2769]: loss 1.016278
[epoch16, step2770]: loss 3.072322
[epoch16, step2771]: loss 0.896559
[epoch16, step2772]: loss 1.095464
[epoch16, step2773]: loss 7.981965
[epoch16, step2774]: loss 0.913678
[epoch16, step2775]: loss 6.093199
[epoch16, step2776]: loss 1.595802
[epoch16, step2777]: loss 6.740135
[epoch16, step2778]: loss 1.083863
[epoch16, step2779]: loss 3.291866
[epoch16, step2780]: loss 7.666211
[epoch16, step2781]: loss 14.276609
[epoch16, step2782]: loss 0.838539
[epoch16, step2783]: loss 4.411561
[epoch16, step2784]: loss 0.615006
[epoch16, step2785]: loss 2.422768
[epoch16, step2786]: loss 9.248667
[epoch16, step2787]: loss 2.637733
[epoch16, step2788]: loss 1.153785
[epoch16, step2789]: loss 2.127714
[epoch16, step2790]: loss 1.397561
[epoch16, step2791]: loss 2.448325
[epoch16, step2792]: loss 1.119379
[epoch16, step2793]: loss 6.104698
[epoch16, step2794]: loss 14.377514
[epoch16, step2795]: loss 0.744234
[epoch16, step2796]: loss 1.108356
[epoch16, step2797]: loss 2.707814
[epoch16, step2798]: loss 1.530167
[epoch16, step2799]: loss 1.027715
[epoch16, step2800]: loss 6.457419
[epoch16, step2801]: loss 2.966316
[epoch16, step2802]: loss 10.447449
[epoch16, step2803]: loss 9.037024
[epoch16, step2804]: loss 8.785650
[epoch16, step2805]: loss 3.141970
[epoch16, step2806]: loss 1.211414
[epoch16, step2807]: loss 3.725656
[epoch16, step2808]: loss 3.949350
[epoch16, step2809]: loss 7.022291
[epoch16, step2810]: loss 0.617326
[epoch16, step2811]: loss 8.971971
[epoch16, step2812]: loss 1.758719
[epoch16, step2813]: loss 1.035473
[epoch16, step2814]: loss 17.246740
[epoch16, step2815]: loss 2.357495
[epoch16, step2816]: loss 1.408095
[epoch16, step2817]: loss 8.217834
[epoch16, step2818]: loss 1.613409
[epoch16, step2819]: loss 0.564396
[epoch16, step2820]: loss 1.635280
[epoch16, step2821]: loss 0.895062
[epoch16, step2822]: loss 18.251436
[epoch16, step2823]: loss 11.887897
[epoch16, step2824]: loss 7.827972
[epoch16, step2825]: loss 3.862930
[epoch16, step2826]: loss 0.800285
[epoch16, step2827]: loss 2.758536
[epoch16, step2828]: loss 11.175267
[epoch16, step2829]: loss 7.300012
[epoch16, step2830]: loss 1.108244
[epoch16, step2831]: loss 5.888492
[epoch16, step2832]: loss 0.952676
[epoch16, step2833]: loss 0.654725
[epoch16, step2834]: loss 3.809927
[epoch16, step2835]: loss 0.998789
[epoch16, step2836]: loss 9.906468
[epoch16, step2837]: loss 1.242092
[epoch16, step2838]: loss 7.970420
[epoch16, step2839]: loss 9.838688
[epoch16, step2840]: loss 0.606417
[epoch16, step2841]: loss 21.953096
[epoch16, step2842]: loss 2.441335
[epoch16, step2843]: loss 2.363165
[epoch16, step2844]: loss 2.367641
[epoch16, step2845]: loss 3.067111
[epoch16, step2846]: loss 1.994253
[epoch16, step2847]: loss 1.079406
[epoch16, step2848]: loss 6.765752
[epoch16, step2849]: loss 1.179204
[epoch16, step2850]: loss 1.192743
[epoch16, step2851]: loss 1.050748
[epoch16, step2852]: loss 6.552685
[epoch16, step2853]: loss 0.989808
[epoch16, step2854]: loss 11.486625
[epoch16, step2855]: loss 2.046035
[epoch16, step2856]: loss 1.917840
[epoch16, step2857]: loss 6.266634
[epoch16, step2858]: loss 9.660497
[epoch16, step2859]: loss 4.150462
[epoch16, step2860]: loss 6.235156
[epoch16, step2861]: loss 7.666257
[epoch16, step2862]: loss 10.110155
[epoch16, step2863]: loss 1.723397
[epoch16, step2864]: loss 2.197096
[epoch16, step2865]: loss 0.496866
[epoch16, step2866]: loss 12.739327
[epoch16, step2867]: loss 7.478488
[epoch16, step2868]: loss 1.511401
[epoch16, step2869]: loss 1.179085
[epoch16, step2870]: loss 1.448366
[epoch16, step2871]: loss 0.885442
[epoch16, step2872]: loss 7.415645
[epoch16, step2873]: loss 0.638768
[epoch16, step2874]: loss 0.653155
[epoch16, step2875]: loss 2.450257
[epoch16, step2876]: loss 1.655946
[epoch16, step2877]: loss 0.810913
[epoch16, step2878]: loss 2.181357
[epoch16, step2879]: loss 1.047714
[epoch16, step2880]: loss 2.117143
[epoch16, step2881]: loss 0.970572
[epoch16, step2882]: loss 15.477681
[epoch16, step2883]: loss 0.750845
[epoch16, step2884]: loss 1.358899
[epoch16, step2885]: loss 0.540005
[epoch16, step2886]: loss 7.475620
[epoch16, step2887]: loss 2.117720
[epoch16, step2888]: loss 11.189192
[epoch16, step2889]: loss 2.522769
[epoch16, step2890]: loss 0.433967
[epoch16, step2891]: loss 6.376309
[epoch16, step2892]: loss 10.388920
[epoch16, step2893]: loss 6.320924
[epoch16, step2894]: loss 3.857172
[epoch16, step2895]: loss 2.440201
[epoch16, step2896]: loss 1.485291
[epoch16, step2897]: loss 3.326735
[epoch16, step2898]: loss 1.574383
[epoch16, step2899]: loss 3.448909
[epoch16, step2900]: loss 0.646764
[epoch16, step2901]: loss 1.229906
[epoch16, step2902]: loss 9.315483
[epoch16, step2903]: loss 14.106706
[epoch16, step2904]: loss 0.532697
[epoch16, step2905]: loss 13.286816
[epoch16, step2906]: loss 2.796965
[epoch16, step2907]: loss 1.296569
[epoch16, step2908]: loss 3.042068
[epoch16, step2909]: loss 1.535850
[epoch16, step2910]: loss 0.875568
[epoch16, step2911]: loss 1.719887
[epoch16, step2912]: loss 1.125146
[epoch16, step2913]: loss 1.179942
[epoch16, step2914]: loss 2.050565
[epoch16, step2915]: loss 2.565672
[epoch16, step2916]: loss 1.260051
[epoch16, step2917]: loss 0.933199
[epoch16, step2918]: loss 8.468682
[epoch16, step2919]: loss 6.375704
[epoch16, step2920]: loss 0.787913
[epoch16, step2921]: loss 1.015418
[epoch16, step2922]: loss 1.442271
[epoch16, step2923]: loss 1.555246
[epoch16, step2924]: loss 9.640356
[epoch16, step2925]: loss 8.720537
[epoch16, step2926]: loss 16.140181
[epoch16, step2927]: loss 1.812431
[epoch16, step2928]: loss 7.037944
[epoch16, step2929]: loss 0.559087
[epoch16, step2930]: loss 1.035409
[epoch16, step2931]: loss 2.372497
[epoch16, step2932]: loss 0.937683
[epoch16, step2933]: loss 2.620433
[epoch16, step2934]: loss 0.999063
[epoch16, step2935]: loss 3.160793
[epoch16, step2936]: loss 1.938975
[epoch16, step2937]: loss 5.909014
[epoch16, step2938]: loss 11.763717
[epoch16, step2939]: loss 1.880666
[epoch16, step2940]: loss 0.669227
[epoch16, step2941]: loss 0.595105
[epoch16, step2942]: loss 1.072317
[epoch16, step2943]: loss 9.120374
[epoch16, step2944]: loss 9.933244
[epoch16, step2945]: loss 0.810010
[epoch16, step2946]: loss 10.488649
[epoch16, step2947]: loss 7.863678
[epoch16, step2948]: loss 1.095599
[epoch16, step2949]: loss 3.809975
[epoch16, step2950]: loss 1.821792
[epoch16, step2951]: loss 5.918199
[epoch16, step2952]: loss 1.665111
[epoch16, step2953]: loss 7.714848
[epoch16, step2954]: loss 2.092505
[epoch16, step2955]: loss 0.937041
[epoch16, step2956]: loss 0.744848
[epoch16, step2957]: loss 0.978138
[epoch16, step2958]: loss 4.505584
[epoch16, step2959]: loss 22.389282
[epoch16, step2960]: loss 4.437140
[epoch16, step2961]: loss 1.151602
[epoch16, step2962]: loss 1.377547
[epoch16, step2963]: loss 0.727713
[epoch16, step2964]: loss 1.110143
[epoch16, step2965]: loss 16.220337
[epoch16, step2966]: loss 7.303121
[epoch16, step2967]: loss 0.940507
[epoch16, step2968]: loss 0.523885
[epoch16, step2969]: loss 2.060431
[epoch16, step2970]: loss 0.701045
[epoch16, step2971]: loss 0.891317
[epoch16, step2972]: loss 2.091645
[epoch16, step2973]: loss 8.824937
[epoch16, step2974]: loss 1.253191
[epoch16, step2975]: loss 1.002193
[epoch16, step2976]: loss 3.566982
[epoch16, step2977]: loss 2.921198
[epoch16, step2978]: loss 1.060717
[epoch16, step2979]: loss 3.725768
[epoch16, step2980]: loss 0.908522
[epoch16, step2981]: loss 1.897075
[epoch16, step2982]: loss 1.555401
[epoch16, step2983]: loss 3.472819
[epoch16, step2984]: loss 0.938576
[epoch16, step2985]: loss 11.976733
[epoch16, step2986]: loss 1.266620
[epoch16, step2987]: loss 0.752139
[epoch16, step2988]: loss 1.832616
[epoch16, step2989]: loss 7.808848
[epoch16, step2990]: loss 0.786870
[epoch16, step2991]: loss 1.510627
[epoch16, step2992]: loss 6.191042
[epoch16, step2993]: loss 0.954811
[epoch16, step2994]: loss 2.118197
[epoch16, step2995]: loss 2.113412
[epoch16, step2996]: loss 1.202057
[epoch16, step2997]: loss 1.458650
[epoch16, step2998]: loss 9.261852
[epoch16, step2999]: loss 5.358594
[epoch16, step3000]: loss 8.420131
[epoch16, step3001]: loss 11.213683
[epoch16, step3002]: loss 1.016555
[epoch16, step3003]: loss 2.073538
[epoch16, step3004]: loss 1.095673
[epoch16, step3005]: loss 4.218716
[epoch16, step3006]: loss 2.883085
[epoch16, step3007]: loss 1.219961
[epoch16, step3008]: loss 1.179382
[epoch16, step3009]: loss 0.436492
[epoch16, step3010]: loss 18.120850
[epoch16, step3011]: loss 3.607520
[epoch16, step3012]: loss 10.629212
[epoch16, step3013]: loss 13.915721
[epoch16, step3014]: loss 1.343884
[epoch16, step3015]: loss 2.261137
[epoch16, step3016]: loss 3.380063
[epoch16, step3017]: loss 0.773988
[epoch16, step3018]: loss 1.012383
[epoch16, step3019]: loss 1.143458
[epoch16, step3020]: loss 2.840151
[epoch16, step3021]: loss 0.942212
[epoch16, step3022]: loss 0.646504
[epoch16, step3023]: loss 14.840236
[epoch16, step3024]: loss 2.337266
[epoch16, step3025]: loss 0.667524
[epoch16, step3026]: loss 1.684233
[epoch16, step3027]: loss 0.910746
[epoch16, step3028]: loss 0.659922
[epoch16, step3029]: loss 6.985949
[epoch16, step3030]: loss 2.733682
[epoch16, step3031]: loss 0.576386
[epoch16, step3032]: loss 3.879594
[epoch16, step3033]: loss 0.953278
[epoch16, step3034]: loss 0.613579
[epoch16, step3035]: loss 8.448678
[epoch16, step3036]: loss 1.042131
[epoch16, step3037]: loss 7.311483
[epoch16, step3038]: loss 7.635415
[epoch16, step3039]: loss 9.030267
[epoch16, step3040]: loss 6.909576
[epoch16, step3041]: loss 1.390036
[epoch16, step3042]: loss 0.709138
[epoch16, step3043]: loss 4.768090
[epoch16, step3044]: loss 8.889136
[epoch16, step3045]: loss 1.162493
[epoch16, step3046]: loss 9.045816
[epoch16, step3047]: loss 1.794462
[epoch16, step3048]: loss 0.800080
[epoch16, step3049]: loss 1.292696
[epoch16, step3050]: loss 4.747323
[epoch16, step3051]: loss 1.365675
[epoch16, step3052]: loss 3.039820
[epoch16, step3053]: loss 0.625193
[epoch16, step3054]: loss 1.894144
[epoch16, step3055]: loss 1.278908
[epoch16, step3056]: loss 1.989972
[epoch16, step3057]: loss 1.626507
[epoch16, step3058]: loss 1.059234
[epoch16, step3059]: loss 8.756567
[epoch16, step3060]: loss 1.438402
[epoch16, step3061]: loss 2.840661
[epoch16, step3062]: loss 2.752688
[epoch16, step3063]: loss 10.737283
[epoch16, step3064]: loss 1.215147
[epoch16, step3065]: loss 6.618029
[epoch16, step3066]: loss 2.511395
[epoch16, step3067]: loss 2.656061
[epoch16, step3068]: loss 7.714502
[epoch16, step3069]: loss 9.059760
[epoch16, step3070]: loss 2.080357
[epoch16, step3071]: loss 1.158434
[epoch16, step3072]: loss 3.357791
[epoch16, step3073]: loss 3.463926
[epoch16, step3074]: loss 1.998589
[epoch16, step3075]: loss 2.166322
[epoch16, step3076]: loss 17.790178

[epoch16]: avg loss 17.790178

[epoch17, step1]: loss 7.316804
[epoch17, step2]: loss 0.932023
[epoch17, step3]: loss 0.805608
[epoch17, step4]: loss 1.140629
[epoch17, step5]: loss 2.818495
[epoch17, step6]: loss 0.613424
[epoch17, step7]: loss 0.616353
[epoch17, step8]: loss 0.750910
[epoch17, step9]: loss 0.568588
[epoch17, step10]: loss 14.874907
[epoch17, step11]: loss 0.532515
[epoch17, step12]: loss 1.956712
[epoch17, step13]: loss 0.778037
[epoch17, step14]: loss 8.321875
[epoch17, step15]: loss 6.219170
[epoch17, step16]: loss 0.917776
[epoch17, step17]: loss 1.393746
[epoch17, step18]: loss 1.713740
[epoch17, step19]: loss 3.217195
[epoch17, step20]: loss 10.838511
[epoch17, step21]: loss 2.282146
[epoch17, step22]: loss 2.202930
[epoch17, step23]: loss 6.301363
[epoch17, step24]: loss 0.936321
[epoch17, step25]: loss 0.584644
[epoch17, step26]: loss 1.275743
[epoch17, step27]: loss 5.377267
[epoch17, step28]: loss 1.446833
[epoch17, step29]: loss 1.340592
[epoch17, step30]: loss 0.521920
[epoch17, step31]: loss 0.694614
[epoch17, step32]: loss 0.714273
[epoch17, step33]: loss 7.663628
[epoch17, step34]: loss 0.697011
[epoch17, step35]: loss 9.193501
[epoch17, step36]: loss 1.671133
[epoch17, step37]: loss 0.832068
[epoch17, step38]: loss 0.736926
[epoch17, step39]: loss 1.011862
[epoch17, step40]: loss 8.105659
[epoch17, step41]: loss 0.820571
[epoch17, step42]: loss 0.819749
[epoch17, step43]: loss 8.551841
[epoch17, step44]: loss 1.238765
[epoch17, step45]: loss 1.465694
[epoch17, step46]: loss 0.820711
[epoch17, step47]: loss 7.306920
[epoch17, step48]: loss 9.799364
[epoch17, step49]: loss 2.654874
[epoch17, step50]: loss 6.199548
[epoch17, step51]: loss 0.576622
[epoch17, step52]: loss 10.899483
[epoch17, step53]: loss 1.171906
[epoch17, step54]: loss 5.938419
[epoch17, step55]: loss 1.902913
[epoch17, step56]: loss 1.322986
[epoch17, step57]: loss 0.939954
[epoch17, step58]: loss 2.436534
[epoch17, step59]: loss 0.481357
[epoch17, step60]: loss 0.805723
[epoch17, step61]: loss 1.030660
[epoch17, step62]: loss 0.863800
[epoch17, step63]: loss 1.053483
[epoch17, step64]: loss 10.425799
[epoch17, step65]: loss 0.670934
[epoch17, step66]: loss 1.573227
[epoch17, step67]: loss 20.042843
[epoch17, step68]: loss 0.862720
[epoch17, step69]: loss 9.644855
[epoch17, step70]: loss 1.757041
[epoch17, step71]: loss 6.108469
[epoch17, step72]: loss 1.842041
[epoch17, step73]: loss 2.160455
[epoch17, step74]: loss 3.009327
[epoch17, step75]: loss 0.751023
[epoch17, step76]: loss 6.339743
[epoch17, step77]: loss 7.324255
[epoch17, step78]: loss 0.763782
[epoch17, step79]: loss 1.121045
[epoch17, step80]: loss 1.317212
[epoch17, step81]: loss 15.251040
[epoch17, step82]: loss 5.701030
[epoch17, step83]: loss 2.335433
[epoch17, step84]: loss 2.475373
[epoch17, step85]: loss 2.723770
[epoch17, step86]: loss 2.253369
[epoch17, step87]: loss 10.205255
[epoch17, step88]: loss 2.344615
[epoch17, step89]: loss 1.101500
[epoch17, step90]: loss 13.698939
[epoch17, step91]: loss 1.915077
[epoch17, step92]: loss 6.321439
[epoch17, step93]: loss 1.451079
[epoch17, step94]: loss 6.510721
[epoch17, step95]: loss 0.873929
[epoch17, step96]: loss 2.401608
[epoch17, step97]: loss 1.268151
[epoch17, step98]: loss 0.743601
[epoch17, step99]: loss 0.608329
[epoch17, step100]: loss 11.050981
[epoch17, step101]: loss 4.225145
[epoch17, step102]: loss 0.965314
[epoch17, step103]: loss 1.605799
[epoch17, step104]: loss 7.163758
[epoch17, step105]: loss 1.682950
[epoch17, step106]: loss 2.596076
[epoch17, step107]: loss 2.884163
[epoch17, step108]: loss 9.798887
[epoch17, step109]: loss 2.743613
[epoch17, step110]: loss 0.481593
[epoch17, step111]: loss 15.762600
[epoch17, step112]: loss 2.002717
[epoch17, step113]: loss 0.622652
[epoch17, step114]: loss 1.048407
[epoch17, step115]: loss 0.976734
[epoch17, step116]: loss 16.018091
[epoch17, step117]: loss 0.879375
[epoch17, step118]: loss 6.450186
[epoch17, step119]: loss 1.344206
[epoch17, step120]: loss 0.804188
[epoch17, step121]: loss 5.890803
[epoch17, step122]: loss 0.896159
[epoch17, step123]: loss 6.826655
[epoch17, step124]: loss 1.182592
[epoch17, step125]: loss 3.423244
[epoch17, step126]: loss 0.812596
[epoch17, step127]: loss 6.877848
[epoch17, step128]: loss 0.776225
[epoch17, step129]: loss 4.652991
[epoch17, step130]: loss 2.547406
[epoch17, step131]: loss 4.187577
[epoch17, step132]: loss 0.979002
[epoch17, step133]: loss 2.023549
[epoch17, step134]: loss 0.818660
[epoch17, step135]: loss 2.507321
[epoch17, step136]: loss 1.146706
[epoch17, step137]: loss 1.300569
[epoch17, step138]: loss 0.798842
[epoch17, step139]: loss 1.591201
[epoch17, step140]: loss 1.385914
[epoch17, step141]: loss 7.388831
[epoch17, step142]: loss 0.917078
[epoch17, step143]: loss 5.743830
[epoch17, step144]: loss 6.818639
[epoch17, step145]: loss 7.351229
[epoch17, step146]: loss 1.089509
[epoch17, step147]: loss 2.447102
[epoch17, step148]: loss 0.963439
[epoch17, step149]: loss 0.512313
[epoch17, step150]: loss 1.875947
[epoch17, step151]: loss 1.091444
[epoch17, step152]: loss 10.078701
[epoch17, step153]: loss 0.921124
[epoch17, step154]: loss 4.417041
[epoch17, step155]: loss 1.067921
[epoch17, step156]: loss 4.464666
[epoch17, step157]: loss 0.553091
[epoch17, step158]: loss 8.197021
[epoch17, step159]: loss 7.450251
[epoch17, step160]: loss 0.660442
[epoch17, step161]: loss 1.168774
[epoch17, step162]: loss 2.223593
[epoch17, step163]: loss 1.355656
[epoch17, step164]: loss 1.308092
[epoch17, step165]: loss 2.780784
[epoch17, step166]: loss 2.887790
[epoch17, step167]: loss 1.012121
[epoch17, step168]: loss 2.984310
[epoch17, step169]: loss 8.610631
[epoch17, step170]: loss 0.969416
[epoch17, step171]: loss 1.025768
[epoch17, step172]: loss 7.078427
[epoch17, step173]: loss 0.438091
[epoch17, step174]: loss 0.833234
[epoch17, step175]: loss 1.669647
[epoch17, step176]: loss 0.864592
[epoch17, step177]: loss 1.461817
[epoch17, step178]: loss 2.866831
[epoch17, step179]: loss 1.691395
[epoch17, step180]: loss 0.866084
[epoch17, step181]: loss 2.012087
[epoch17, step182]: loss 11.353842
[epoch17, step183]: loss 11.067102
[epoch17, step184]: loss 9.260506
[epoch17, step185]: loss 1.104343
[epoch17, step186]: loss 0.997636
[epoch17, step187]: loss 21.168324
[epoch17, step188]: loss 2.464557
[epoch17, step189]: loss 2.396459
[epoch17, step190]: loss 0.941521
[epoch17, step191]: loss 3.082188
[epoch17, step192]: loss 0.686789
[epoch17, step193]: loss 0.757128
[epoch17, step194]: loss 2.392138
[epoch17, step195]: loss 3.223836
[epoch17, step196]: loss 1.659503
[epoch17, step197]: loss 1.762383
[epoch17, step198]: loss 1.447949
[epoch17, step199]: loss 0.783731
[epoch17, step200]: loss 0.641379
[epoch17, step201]: loss 0.804140
[epoch17, step202]: loss 8.971352
[epoch17, step203]: loss 1.162025
[epoch17, step204]: loss 2.488834
[epoch17, step205]: loss 2.278423
[epoch17, step206]: loss 5.316245
[epoch17, step207]: loss 6.671869
[epoch17, step208]: loss 7.969254
[epoch17, step209]: loss 7.587475
[epoch17, step210]: loss 0.645503
[epoch17, step211]: loss 0.553554
[epoch17, step212]: loss 2.095224
[epoch17, step213]: loss 6.794381
[epoch17, step214]: loss 0.824444
[epoch17, step215]: loss 1.738488
[epoch17, step216]: loss 8.444816
[epoch17, step217]: loss 0.742079
[epoch17, step218]: loss 2.721730
[epoch17, step219]: loss 1.065864
[epoch17, step220]: loss 2.763656
[epoch17, step221]: loss 24.716702
[epoch17, step222]: loss 6.700335
[epoch17, step223]: loss 10.654274
[epoch17, step224]: loss 0.797146
[epoch17, step225]: loss 0.854625
[epoch17, step226]: loss 0.451879
[epoch17, step227]: loss 0.747583
[epoch17, step228]: loss 1.363929
[epoch17, step229]: loss 1.349042
[epoch17, step230]: loss 10.612701
[epoch17, step231]: loss 1.688976
[epoch17, step232]: loss 12.426732
[epoch17, step233]: loss 0.779330
[epoch17, step234]: loss 7.690951
[epoch17, step235]: loss 6.580936
[epoch17, step236]: loss 10.026770
[epoch17, step237]: loss 0.878391
[epoch17, step238]: loss 1.101044
[epoch17, step239]: loss 1.951035
[epoch17, step240]: loss 11.588465
[epoch17, step241]: loss 0.849437
[epoch17, step242]: loss 2.296950
[epoch17, step243]: loss 3.668395
[epoch17, step244]: loss 2.641265
[epoch17, step245]: loss 0.796917
[epoch17, step246]: loss 1.513572
[epoch17, step247]: loss 0.582931
[epoch17, step248]: loss 1.795589
[epoch17, step249]: loss 2.618673
[epoch17, step250]: loss 1.365746
[epoch17, step251]: loss 0.966915
[epoch17, step252]: loss 19.201672
[epoch17, step253]: loss 0.773414
[epoch17, step254]: loss 0.809231
[epoch17, step255]: loss 5.007312
[epoch17, step256]: loss 8.709136
[epoch17, step257]: loss 2.603429
[epoch17, step258]: loss 2.049048
[epoch17, step259]: loss 0.650137
[epoch17, step260]: loss 0.512066
[epoch17, step261]: loss 0.777208
[epoch17, step262]: loss 2.885665
[epoch17, step263]: loss 0.712051
[epoch17, step264]: loss 0.586384
[epoch17, step265]: loss 1.748513
[epoch17, step266]: loss 6.442571
[epoch17, step267]: loss 1.256757
[epoch17, step268]: loss 4.697711
[epoch17, step269]: loss 1.747450
[epoch17, step270]: loss 2.157662
[epoch17, step271]: loss 0.681488
[epoch17, step272]: loss 3.108696
[epoch17, step273]: loss 6.627917
[epoch17, step274]: loss 5.123569
[epoch17, step275]: loss 3.917366
[epoch17, step276]: loss 1.439914
[epoch17, step277]: loss 1.272522
[epoch17, step278]: loss 8.570033
[epoch17, step279]: loss 7.484188
[epoch17, step280]: loss 2.301137
[epoch17, step281]: loss 0.896241
[epoch17, step282]: loss 0.935965
[epoch17, step283]: loss 0.680905
[epoch17, step284]: loss 2.567758
[epoch17, step285]: loss 1.374076
[epoch17, step286]: loss 11.537201
[epoch17, step287]: loss 0.930646
[epoch17, step288]: loss 1.432902
[epoch17, step289]: loss 5.241996
[epoch17, step290]: loss 7.599739
[epoch17, step291]: loss 0.880637
[epoch17, step292]: loss 0.469571
[epoch17, step293]: loss 7.754825
[epoch17, step294]: loss 8.491109
[epoch17, step295]: loss 11.887820
[epoch17, step296]: loss 3.325501
[epoch17, step297]: loss 3.413094
[epoch17, step298]: loss 6.870041
[epoch17, step299]: loss 1.117452
[epoch17, step300]: loss 0.520108
[epoch17, step301]: loss 0.676048
[epoch17, step302]: loss 1.506884
[epoch17, step303]: loss 2.357213
[epoch17, step304]: loss 0.699126
[epoch17, step305]: loss 0.613612
[epoch17, step306]: loss 9.836774
[epoch17, step307]: loss 10.628468
[epoch17, step308]: loss 2.470424
[epoch17, step309]: loss 0.741413
[epoch17, step310]: loss 2.663889
[epoch17, step311]: loss 1.339723
[epoch17, step312]: loss 1.294561
[epoch17, step313]: loss 1.138738
[epoch17, step314]: loss 1.708438
[epoch17, step315]: loss 1.110552
[epoch17, step316]: loss 0.761048
[epoch17, step317]: loss 1.184457
[epoch17, step318]: loss 0.692910
[epoch17, step319]: loss 3.397046
[epoch17, step320]: loss 0.727317
[epoch17, step321]: loss 2.522163
[epoch17, step322]: loss 0.612046
[epoch17, step323]: loss 1.219914
[epoch17, step324]: loss 1.735853
[epoch17, step325]: loss 0.520974
[epoch17, step326]: loss 0.893020
[epoch17, step327]: loss 0.854340
[epoch17, step328]: loss 1.351111
[epoch17, step329]: loss 0.942070
[epoch17, step330]: loss 2.923262
[epoch17, step331]: loss 5.749551
[epoch17, step332]: loss 16.363876
[epoch17, step333]: loss 0.451215
[epoch17, step334]: loss 2.933171
[epoch17, step335]: loss 0.651745
[epoch17, step336]: loss 3.612626
[epoch17, step337]: loss 0.761775
[epoch17, step338]: loss 0.657713
[epoch17, step339]: loss 8.073537
[epoch17, step340]: loss 1.163177
[epoch17, step341]: loss 1.122196
[epoch17, step342]: loss 0.686912
[epoch17, step343]: loss 7.177933
[epoch17, step344]: loss 3.001837
[epoch17, step345]: loss 2.094804
[epoch17, step346]: loss 0.708946
[epoch17, step347]: loss 8.653161
[epoch17, step348]: loss 0.573896
[epoch17, step349]: loss 0.546894
[epoch17, step350]: loss 1.616747
[epoch17, step351]: loss 1.027991
[epoch17, step352]: loss 0.857369
[epoch17, step353]: loss 1.180609
[epoch17, step354]: loss 0.590788
[epoch17, step355]: loss 1.334563
[epoch17, step356]: loss 12.585181
[epoch17, step357]: loss 1.965031
[epoch17, step358]: loss 4.398005
[epoch17, step359]: loss 0.936224
[epoch17, step360]: loss 1.668838
[epoch17, step361]: loss 0.762634
[epoch17, step362]: loss 2.296113
[epoch17, step363]: loss 6.204133
[epoch17, step364]: loss 6.153951
[epoch17, step365]: loss 6.640738
[epoch17, step366]: loss 0.619572
[epoch17, step367]: loss 0.971584
[epoch17, step368]: loss 8.357002
[epoch17, step369]: loss 1.831785
[epoch17, step370]: loss 11.188184
[epoch17, step371]: loss 1.994846
[epoch17, step372]: loss 1.836739
[epoch17, step373]: loss 2.154772
[epoch17, step374]: loss 5.945956
[epoch17, step375]: loss 0.741051
[epoch17, step376]: loss 1.143514
[epoch17, step377]: loss 28.191397
[epoch17, step378]: loss 9.071366
[epoch17, step379]: loss 11.407681
[epoch17, step380]: loss 0.609257
[epoch17, step381]: loss 2.868256
[epoch17, step382]: loss 9.594891
[epoch17, step383]: loss 1.590991
[epoch17, step384]: loss 0.714022
[epoch17, step385]: loss 1.954061
[epoch17, step386]: loss 1.706142
[epoch17, step387]: loss 13.352480
[epoch17, step388]: loss 1.541256
[epoch17, step389]: loss 2.908347
[epoch17, step390]: loss 2.359212
[epoch17, step391]: loss 1.328948
[epoch17, step392]: loss 12.927252
[epoch17, step393]: loss 7.092903
[epoch17, step394]: loss 1.465668
[epoch17, step395]: loss 1.247905
[epoch17, step396]: loss 6.932487
[epoch17, step397]: loss 0.945800
[epoch17, step398]: loss 1.108302
[epoch17, step399]: loss 2.405843
[epoch17, step400]: loss 3.543879
[epoch17, step401]: loss 16.513281
[epoch17, step402]: loss 0.806216
[epoch17, step403]: loss 6.274576
[epoch17, step404]: loss 4.545403
[epoch17, step405]: loss 0.820364
[epoch17, step406]: loss 6.196554
[epoch17, step407]: loss 1.656637
[epoch17, step408]: loss 1.415563
[epoch17, step409]: loss 2.219583
[epoch17, step410]: loss 0.588000
[epoch17, step411]: loss 0.486860
[epoch17, step412]: loss 2.885123
[epoch17, step413]: loss 2.912188
[epoch17, step414]: loss 1.517270
[epoch17, step415]: loss 1.875907
[epoch17, step416]: loss 0.746712
[epoch17, step417]: loss 1.386378
[epoch17, step418]: loss 0.586082
[epoch17, step419]: loss 2.116105
[epoch17, step420]: loss 16.170824
[epoch17, step421]: loss 7.090009
[epoch17, step422]: loss 0.810635
[epoch17, step423]: loss 14.277761
[epoch17, step424]: loss 1.587003
[epoch17, step425]: loss 5.419263
[epoch17, step426]: loss 10.948468
[epoch17, step427]: loss 6.746992
[epoch17, step428]: loss 8.469974
[epoch17, step429]: loss 0.710868
[epoch17, step430]: loss 3.790854
[epoch17, step431]: loss 1.059971
[epoch17, step432]: loss 9.089388
[epoch17, step433]: loss 1.713032
[epoch17, step434]: loss 0.689082
[epoch17, step435]: loss 0.449551
[epoch17, step436]: loss 0.756696
[epoch17, step437]: loss 1.500492
[epoch17, step438]: loss 0.763178
[epoch17, step439]: loss 12.543674
[epoch17, step440]: loss 1.316192
[epoch17, step441]: loss 2.417644
[epoch17, step442]: loss 2.936653
[epoch17, step443]: loss 8.671243
[epoch17, step444]: loss 3.954311
[epoch17, step445]: loss 1.027481
[epoch17, step446]: loss 16.540751
[epoch17, step447]: loss 2.580362
[epoch17, step448]: loss 2.098418
[epoch17, step449]: loss 0.774075
[epoch17, step450]: loss 0.636967
[epoch17, step451]: loss 10.443235
[epoch17, step452]: loss 1.500929
[epoch17, step453]: loss 1.695520
[epoch17, step454]: loss 0.799129
[epoch17, step455]: loss 4.063032
[epoch17, step456]: loss 7.092333
[epoch17, step457]: loss 1.239414
[epoch17, step458]: loss 2.583314
[epoch17, step459]: loss 4.641925
[epoch17, step460]: loss 2.083251
[epoch17, step461]: loss 1.074387
[epoch17, step462]: loss 0.644945
[epoch17, step463]: loss 1.411908
[epoch17, step464]: loss 1.179303
[epoch17, step465]: loss 8.731703
[epoch17, step466]: loss 10.937794
[epoch17, step467]: loss 0.878538
[epoch17, step468]: loss 1.166550
[epoch17, step469]: loss 15.025789
[epoch17, step470]: loss 1.082734
[epoch17, step471]: loss 7.281246
[epoch17, step472]: loss 0.863531
[epoch17, step473]: loss 0.589918
[epoch17, step474]: loss 9.651706
[epoch17, step475]: loss 1.002801
[epoch17, step476]: loss 1.018967
[epoch17, step477]: loss 11.320093
[epoch17, step478]: loss 0.883991
[epoch17, step479]: loss 1.698976
[epoch17, step480]: loss 2.841369
[epoch17, step481]: loss 1.922316
[epoch17, step482]: loss 0.796856
[epoch17, step483]: loss 7.531942
[epoch17, step484]: loss 9.897593
[epoch17, step485]: loss 21.032677
[epoch17, step486]: loss 5.090120
[epoch17, step487]: loss 5.319456
[epoch17, step488]: loss 7.546633
[epoch17, step489]: loss 1.915987
[epoch17, step490]: loss 2.484063
[epoch17, step491]: loss 6.358315
[epoch17, step492]: loss 1.150040
[epoch17, step493]: loss 1.649917
[epoch17, step494]: loss 0.859782
[epoch17, step495]: loss 0.644000
[epoch17, step496]: loss 0.604064
[epoch17, step497]: loss 9.090417
[epoch17, step498]: loss 1.073221
[epoch17, step499]: loss 2.343130
[epoch17, step500]: loss 2.083597
[epoch17, step501]: loss 8.563169
[epoch17, step502]: loss 1.980573
[epoch17, step503]: loss 9.239939
[epoch17, step504]: loss 6.848933
[epoch17, step505]: loss 0.659912
[epoch17, step506]: loss 3.963672
[epoch17, step507]: loss 0.987605
[epoch17, step508]: loss 0.995302
[epoch17, step509]: loss 0.827002
[epoch17, step510]: loss 1.156588
[epoch17, step511]: loss 1.276225
[epoch17, step512]: loss 0.531823
[epoch17, step513]: loss 0.829886
[epoch17, step514]: loss 1.337130
[epoch17, step515]: loss 1.982976
[epoch17, step516]: loss 1.958087
[epoch17, step517]: loss 0.625419
[epoch17, step518]: loss 1.282255
[epoch17, step519]: loss 6.495808
[epoch17, step520]: loss 0.513683
[epoch17, step521]: loss 2.780707
[epoch17, step522]: loss 0.607724
[epoch17, step523]: loss 0.531801
[epoch17, step524]: loss 0.933710
[epoch17, step525]: loss 2.743022
[epoch17, step526]: loss 6.736504
[epoch17, step527]: loss 8.591230
[epoch17, step528]: loss 7.263423
[epoch17, step529]: loss 2.488751
[epoch17, step530]: loss 1.243124
[epoch17, step531]: loss 6.709105
[epoch17, step532]: loss 7.904160
[epoch17, step533]: loss 1.251774
[epoch17, step534]: loss 5.587141
[epoch17, step535]: loss 1.896163
[epoch17, step536]: loss 3.092016
[epoch17, step537]: loss 2.662114
[epoch17, step538]: loss 1.546555
[epoch17, step539]: loss 1.327456
[epoch17, step540]: loss 19.032421
[epoch17, step541]: loss 2.023719
[epoch17, step542]: loss 1.972530
[epoch17, step543]: loss 7.775255
[epoch17, step544]: loss 0.730147
[epoch17, step545]: loss 23.876844
[epoch17, step546]: loss 1.330550
[epoch17, step547]: loss 7.649945
[epoch17, step548]: loss 1.064505
[epoch17, step549]: loss 1.929909
[epoch17, step550]: loss 1.702069
[epoch17, step551]: loss 12.183173
[epoch17, step552]: loss 11.119656
[epoch17, step553]: loss 0.777096
[epoch17, step554]: loss 0.611153
[epoch17, step555]: loss 1.424098
[epoch17, step556]: loss 5.536724
[epoch17, step557]: loss 2.496058
[epoch17, step558]: loss 2.107726
[epoch17, step559]: loss 3.694767
[epoch17, step560]: loss 4.563421
[epoch17, step561]: loss 3.541515
[epoch17, step562]: loss 2.331143
[epoch17, step563]: loss 7.653359
[epoch17, step564]: loss 1.028479
[epoch17, step565]: loss 2.861772
[epoch17, step566]: loss 0.829350
[epoch17, step567]: loss 10.548882
[epoch17, step568]: loss 1.876407
[epoch17, step569]: loss 2.682556
[epoch17, step570]: loss 1.825725
[epoch17, step571]: loss 20.017746
[epoch17, step572]: loss 6.177154
[epoch17, step573]: loss 1.730379
[epoch17, step574]: loss 2.283081
[epoch17, step575]: loss 0.856374
[epoch17, step576]: loss 0.866502
[epoch17, step577]: loss 8.271791
[epoch17, step578]: loss 12.730123
[epoch17, step579]: loss 0.698072
[epoch17, step580]: loss 2.069884
[epoch17, step581]: loss 2.686270
[epoch17, step582]: loss 10.552507
[epoch17, step583]: loss 6.058362
[epoch17, step584]: loss 1.826335
[epoch17, step585]: loss 2.931224
[epoch17, step586]: loss 3.639019
[epoch17, step587]: loss 13.593968
[epoch17, step588]: loss 6.517123
[epoch17, step589]: loss 9.953768
[epoch17, step590]: loss 6.372249
[epoch17, step591]: loss 1.954017
[epoch17, step592]: loss 6.141508
[epoch17, step593]: loss 1.042314
[epoch17, step594]: loss 11.282813
[epoch17, step595]: loss 6.104729
[epoch17, step596]: loss 2.427653
[epoch17, step597]: loss 1.039525
[epoch17, step598]: loss 0.898537
[epoch17, step599]: loss 2.534585
[epoch17, step600]: loss 0.798404
[epoch17, step601]: loss 1.321213
[epoch17, step602]: loss 2.895185
[epoch17, step603]: loss 0.635203
[epoch17, step604]: loss 3.266560
[epoch17, step605]: loss 1.520355
[epoch17, step606]: loss 6.249454
[epoch17, step607]: loss 1.417714
[epoch17, step608]: loss 14.814487
[epoch17, step609]: loss 0.697882
[epoch17, step610]: loss 5.038102
[epoch17, step611]: loss 2.838417
[epoch17, step612]: loss 11.368108
[epoch17, step613]: loss 11.171614
[epoch17, step614]: loss 0.721617
[epoch17, step615]: loss 2.234983
[epoch17, step616]: loss 1.246517
[epoch17, step617]: loss 1.730797
[epoch17, step618]: loss 0.865291
[epoch17, step619]: loss 1.148166
[epoch17, step620]: loss 1.026654
[epoch17, step621]: loss 8.449800
[epoch17, step622]: loss 0.710802
[epoch17, step623]: loss 1.290420
[epoch17, step624]: loss 1.447367
[epoch17, step625]: loss 1.114523
[epoch17, step626]: loss 1.963944
[epoch17, step627]: loss 7.343650
[epoch17, step628]: loss 0.854090
[epoch17, step629]: loss 0.733628
[epoch17, step630]: loss 3.686999
[epoch17, step631]: loss 3.134582
[epoch17, step632]: loss 0.776156
[epoch17, step633]: loss 6.269866
[epoch17, step634]: loss 0.869419
[epoch17, step635]: loss 6.671911
[epoch17, step636]: loss 1.438215
[epoch17, step637]: loss 2.383949
[epoch17, step638]: loss 1.925068
[epoch17, step639]: loss 11.134632
[epoch17, step640]: loss 10.953873
[epoch17, step641]: loss 0.603434
[epoch17, step642]: loss 2.415000
[epoch17, step643]: loss 8.136158
[epoch17, step644]: loss 0.578624
[epoch17, step645]: loss 1.848623
[epoch17, step646]: loss 6.722225
[epoch17, step647]: loss 12.202187
[epoch17, step648]: loss 15.160463
[epoch17, step649]: loss 1.224894
[epoch17, step650]: loss 0.720091
[epoch17, step651]: loss 1.845119
[epoch17, step652]: loss 6.155409
[epoch17, step653]: loss 1.348775
[epoch17, step654]: loss 1.505154
[epoch17, step655]: loss 5.817962
[epoch17, step656]: loss 3.090436
[epoch17, step657]: loss 0.737420
[epoch17, step658]: loss 0.815885
[epoch17, step659]: loss 13.722215
[epoch17, step660]: loss 0.721214
[epoch17, step661]: loss 6.217439
[epoch17, step662]: loss 0.513017
[epoch17, step663]: loss 0.888404
[epoch17, step664]: loss 6.385500
[epoch17, step665]: loss 1.237874
[epoch17, step666]: loss 3.803981
[epoch17, step667]: loss 1.242157
[epoch17, step668]: loss 1.138953
[epoch17, step669]: loss 10.042389
[epoch17, step670]: loss 0.843278
[epoch17, step671]: loss 1.193320
[epoch17, step672]: loss 0.804053
[epoch17, step673]: loss 1.305702
[epoch17, step674]: loss 20.563286
[epoch17, step675]: loss 2.782675
[epoch17, step676]: loss 15.631112
[epoch17, step677]: loss 8.496925
[epoch17, step678]: loss 0.777407
[epoch17, step679]: loss 2.272858
[epoch17, step680]: loss 1.442777
[epoch17, step681]: loss 1.081935
[epoch17, step682]: loss 2.300114
[epoch17, step683]: loss 2.403338
[epoch17, step684]: loss 9.008126
[epoch17, step685]: loss 0.793261
[epoch17, step686]: loss 2.063999
[epoch17, step687]: loss 6.162716
[epoch17, step688]: loss 9.558670
[epoch17, step689]: loss 4.053572
[epoch17, step690]: loss 7.968269
[epoch17, step691]: loss 0.711759
[epoch17, step692]: loss 1.040202
[epoch17, step693]: loss 7.460903
[epoch17, step694]: loss 1.316156
[epoch17, step695]: loss 1.230826
[epoch17, step696]: loss 2.813082
[epoch17, step697]: loss 0.912207
[epoch17, step698]: loss 0.612832
[epoch17, step699]: loss 6.790742
[epoch17, step700]: loss 2.028040
[epoch17, step701]: loss 0.867691
[epoch17, step702]: loss 5.897563
[epoch17, step703]: loss 1.678635
[epoch17, step704]: loss 1.595210
[epoch17, step705]: loss 8.331168
[epoch17, step706]: loss 0.981756
[epoch17, step707]: loss 1.265556
[epoch17, step708]: loss 4.067468
[epoch17, step709]: loss 0.819855
[epoch17, step710]: loss 3.018647
[epoch17, step711]: loss 2.298088
[epoch17, step712]: loss 1.013198
[epoch17, step713]: loss 1.395284
[epoch17, step714]: loss 1.369664
[epoch17, step715]: loss 2.584947
[epoch17, step716]: loss 2.769162
[epoch17, step717]: loss 23.090080
[epoch17, step718]: loss 6.714113
[epoch17, step719]: loss 11.404825
[epoch17, step720]: loss 0.729066
[epoch17, step721]: loss 0.819611
[epoch17, step722]: loss 1.180328
[epoch17, step723]: loss 6.594131
[epoch17, step724]: loss 5.704410
[epoch17, step725]: loss 8.201930
[epoch17, step726]: loss 1.244322
[epoch17, step727]: loss 0.853169
[epoch17, step728]: loss 1.135106
[epoch17, step729]: loss 5.789934
[epoch17, step730]: loss 0.721335
[epoch17, step731]: loss 0.797634
[epoch17, step732]: loss 5.243601
[epoch17, step733]: loss 3.543498
[epoch17, step734]: loss 0.650839
[epoch17, step735]: loss 6.582184
[epoch17, step736]: loss 9.309983
[epoch17, step737]: loss 6.200163
[epoch17, step738]: loss 0.638874
[epoch17, step739]: loss 1.254156
[epoch17, step740]: loss 1.665890
[epoch17, step741]: loss 2.664208
[epoch17, step742]: loss 5.132891
[epoch17, step743]: loss 12.805587
[epoch17, step744]: loss 7.104269
[epoch17, step745]: loss 2.850135
[epoch17, step746]: loss 4.378942
[epoch17, step747]: loss 1.084829
[epoch17, step748]: loss 1.486640
[epoch17, step749]: loss 11.360801
[epoch17, step750]: loss 0.695468
[epoch17, step751]: loss 0.884606
[epoch17, step752]: loss 6.647049
[epoch17, step753]: loss 0.641104
[epoch17, step754]: loss 1.385598
[epoch17, step755]: loss 1.078557
[epoch17, step756]: loss 1.170970
[epoch17, step757]: loss 1.131769
[epoch17, step758]: loss 0.574669
[epoch17, step759]: loss 6.371280
[epoch17, step760]: loss 2.327435
[epoch17, step761]: loss 1.906649
[epoch17, step762]: loss 0.782367
[epoch17, step763]: loss 3.900242
[epoch17, step764]: loss 5.217643
[epoch17, step765]: loss 12.881033
[epoch17, step766]: loss 1.224414
[epoch17, step767]: loss 1.179724
[epoch17, step768]: loss 6.331446
[epoch17, step769]: loss 2.576469
[epoch17, step770]: loss 0.647253
[epoch17, step771]: loss 7.079242
[epoch17, step772]: loss 1.776768
[epoch17, step773]: loss 6.442831
[epoch17, step774]: loss 16.614119
[epoch17, step775]: loss 0.780825
[epoch17, step776]: loss 1.934726
[epoch17, step777]: loss 0.999853
[epoch17, step778]: loss 6.911153
[epoch17, step779]: loss 2.564437
[epoch17, step780]: loss 11.174425
[epoch17, step781]: loss 1.565955
[epoch17, step782]: loss 18.415953
[epoch17, step783]: loss 8.094402
[epoch17, step784]: loss 0.816424
[epoch17, step785]: loss 1.463675
[epoch17, step786]: loss 9.005301
[epoch17, step787]: loss 1.130352
[epoch17, step788]: loss 3.020399
[epoch17, step789]: loss 1.099955
[epoch17, step790]: loss 1.938328
[epoch17, step791]: loss 1.283556
[epoch17, step792]: loss 2.810340
[epoch17, step793]: loss 1.479686
[epoch17, step794]: loss 1.195187
[epoch17, step795]: loss 5.985985
[epoch17, step796]: loss 8.491809
[epoch17, step797]: loss 0.573811
[epoch17, step798]: loss 2.816083
[epoch17, step799]: loss 14.111046
[epoch17, step800]: loss 1.209167
[epoch17, step801]: loss 0.622816
[epoch17, step802]: loss 0.645153
[epoch17, step803]: loss 3.610814
[epoch17, step804]: loss 8.365092
[epoch17, step805]: loss 6.329098
[epoch17, step806]: loss 2.141831
[epoch17, step807]: loss 0.711809
[epoch17, step808]: loss 9.220443
[epoch17, step809]: loss 1.281070
[epoch17, step810]: loss 8.121797
[epoch17, step811]: loss 11.172555
[epoch17, step812]: loss 0.579498
[epoch17, step813]: loss 0.921029
[epoch17, step814]: loss 0.835011
[epoch17, step815]: loss 0.855453
[epoch17, step816]: loss 7.711727
[epoch17, step817]: loss 0.854352
[epoch17, step818]: loss 0.988154
[epoch17, step819]: loss 0.866865
[epoch17, step820]: loss 1.428934
[epoch17, step821]: loss 0.773744
[epoch17, step822]: loss 0.591006
[epoch17, step823]: loss 0.987633
[epoch17, step824]: loss 2.703029
[epoch17, step825]: loss 6.387282
[epoch17, step826]: loss 17.069822
[epoch17, step827]: loss 0.801771
[epoch17, step828]: loss 0.714583
[epoch17, step829]: loss 2.028888
[epoch17, step830]: loss 1.655091
[epoch17, step831]: loss 0.730435
[epoch17, step832]: loss 1.220548
[epoch17, step833]: loss 8.285654
[epoch17, step834]: loss 7.014058
[epoch17, step835]: loss 2.481796
[epoch17, step836]: loss 0.731791
[epoch17, step837]: loss 13.198717
[epoch17, step838]: loss 0.978800
[epoch17, step839]: loss 2.527952
[epoch17, step840]: loss 2.405902
[epoch17, step841]: loss 3.532134
[epoch17, step842]: loss 6.383659
[epoch17, step843]: loss 0.781936
[epoch17, step844]: loss 0.703072
[epoch17, step845]: loss 12.459661
[epoch17, step846]: loss 7.250068
[epoch17, step847]: loss 1.772439
[epoch17, step848]: loss 1.609501
[epoch17, step849]: loss 1.316955
[epoch17, step850]: loss 2.398190
[epoch17, step851]: loss 2.140380
[epoch17, step852]: loss 14.122159
[epoch17, step853]: loss 1.706129
[epoch17, step854]: loss 0.701772
[epoch17, step855]: loss 10.846201
[epoch17, step856]: loss 0.556958
[epoch17, step857]: loss 8.385177
[epoch17, step858]: loss 2.338090
[epoch17, step859]: loss 1.233057
[epoch17, step860]: loss 1.057803
[epoch17, step861]: loss 9.936976
[epoch17, step862]: loss 3.920600
[epoch17, step863]: loss 6.416662
[epoch17, step864]: loss 1.268606
[epoch17, step865]: loss 0.958849
[epoch17, step866]: loss 4.343813
[epoch17, step867]: loss 0.818033
[epoch17, step868]: loss 0.872121
[epoch17, step869]: loss 1.540246
[epoch17, step870]: loss 1.612592
[epoch17, step871]: loss 2.047167
[epoch17, step872]: loss 3.150112
[epoch17, step873]: loss 1.721813
[epoch17, step874]: loss 0.656040
[epoch17, step875]: loss 13.015471
[epoch17, step876]: loss 6.098514
[epoch17, step877]: loss 1.056376
[epoch17, step878]: loss 1.406095
[epoch17, step879]: loss 1.479205
[epoch17, step880]: loss 0.729588
[epoch17, step881]: loss 1.604268
[epoch17, step882]: loss 2.645149
[epoch17, step883]: loss 11.300701
[epoch17, step884]: loss 6.648304
[epoch17, step885]: loss 15.272851
[epoch17, step886]: loss 1.570686
[epoch17, step887]: loss 2.000518
[epoch17, step888]: loss 0.873217
[epoch17, step889]: loss 0.867130
[epoch17, step890]: loss 0.833224
[epoch17, step891]: loss 5.791700
[epoch17, step892]: loss 0.785472
[epoch17, step893]: loss 1.154043
[epoch17, step894]: loss 5.097310
[epoch17, step895]: loss 13.729670
[epoch17, step896]: loss 1.311009
[epoch17, step897]: loss 4.210719
[epoch17, step898]: loss 1.317025
[epoch17, step899]: loss 12.637121
[epoch17, step900]: loss 1.328593
[epoch17, step901]: loss 1.598435
[epoch17, step902]: loss 0.740757
[epoch17, step903]: loss 1.325948
[epoch17, step904]: loss 0.703478
[epoch17, step905]: loss 16.536245
[epoch17, step906]: loss 2.106272
[epoch17, step907]: loss 9.748505
[epoch17, step908]: loss 3.565630
[epoch17, step909]: loss 0.762852
[epoch17, step910]: loss 8.955485
[epoch17, step911]: loss 1.351798
[epoch17, step912]: loss 2.485732
[epoch17, step913]: loss 0.583089
[epoch17, step914]: loss 1.296671
[epoch17, step915]: loss 11.993738
[epoch17, step916]: loss 0.834604
[epoch17, step917]: loss 1.028797
[epoch17, step918]: loss 1.060482
[epoch17, step919]: loss 0.775655
[epoch17, step920]: loss 9.680938
[epoch17, step921]: loss 1.184780
[epoch17, step922]: loss 4.037112
[epoch17, step923]: loss 0.851153
[epoch17, step924]: loss 1.181964
[epoch17, step925]: loss 1.168544
[epoch17, step926]: loss 10.146346
[epoch17, step927]: loss 0.616556
[epoch17, step928]: loss 7.033185
[epoch17, step929]: loss 1.015714
[epoch17, step930]: loss 2.601076
[epoch17, step931]: loss 2.180777
[epoch17, step932]: loss 1.021469
[epoch17, step933]: loss 9.204220
[epoch17, step934]: loss 7.091582
[epoch17, step935]: loss 1.485980
[epoch17, step936]: loss 2.978317
[epoch17, step937]: loss 1.920358
[epoch17, step938]: loss 2.749810
[epoch17, step939]: loss 1.421048
[epoch17, step940]: loss 1.084565
[epoch17, step941]: loss 1.150512
[epoch17, step942]: loss 0.711927
[epoch17, step943]: loss 0.806339
[epoch17, step944]: loss 5.865939
[epoch17, step945]: loss 1.057547
[epoch17, step946]: loss 4.901548
[epoch17, step947]: loss 0.810610
[epoch17, step948]: loss 3.650028
[epoch17, step949]: loss 0.497781
[epoch17, step950]: loss 12.602407
[epoch17, step951]: loss 23.386715
[epoch17, step952]: loss 0.575488
[epoch17, step953]: loss 0.777564
[epoch17, step954]: loss 1.184120
[epoch17, step955]: loss 4.693773
[epoch17, step956]: loss 11.624157
[epoch17, step957]: loss 1.953046
[epoch17, step958]: loss 4.734976
[epoch17, step959]: loss 1.804077
[epoch17, step960]: loss 0.986156
[epoch17, step961]: loss 5.837410
[epoch17, step962]: loss 7.908206
[epoch17, step963]: loss 0.871632
[epoch17, step964]: loss 1.067573
[epoch17, step965]: loss 0.532729
[epoch17, step966]: loss 7.073333
[epoch17, step967]: loss 11.452112
[epoch17, step968]: loss 5.379588
[epoch17, step969]: loss 1.756995
[epoch17, step970]: loss 2.534747
[epoch17, step971]: loss 10.347980
[epoch17, step972]: loss 3.316412
[epoch17, step973]: loss 0.599444
[epoch17, step974]: loss 7.369116
[epoch17, step975]: loss 1.155453
[epoch17, step976]: loss 1.003818
[epoch17, step977]: loss 0.894599
[epoch17, step978]: loss 2.592239
[epoch17, step979]: loss 0.606954
[epoch17, step980]: loss 17.775482
[epoch17, step981]: loss 7.310758
[epoch17, step982]: loss 1.242111
[epoch17, step983]: loss 2.142547
[epoch17, step984]: loss 1.013845
[epoch17, step985]: loss 1.277566
[epoch17, step986]: loss 0.496592
[epoch17, step987]: loss 3.700129
[epoch17, step988]: loss 2.676581
[epoch17, step989]: loss 1.366767
[epoch17, step990]: loss 0.521042
[epoch17, step991]: loss 2.578310
[epoch17, step992]: loss 1.651524
[epoch17, step993]: loss 1.271278
[epoch17, step994]: loss 9.185947
[epoch17, step995]: loss 7.051194
[epoch17, step996]: loss 0.890406
[epoch17, step997]: loss 0.877108
[epoch17, step998]: loss 0.590854
[epoch17, step999]: loss 7.499517
[epoch17, step1000]: loss 1.492123
[epoch17, step1001]: loss 0.593428
[epoch17, step1002]: loss 0.620351
[epoch17, step1003]: loss 0.874663
[epoch17, step1004]: loss 1.916360
[epoch17, step1005]: loss 0.754511
[epoch17, step1006]: loss 0.642315
[epoch17, step1007]: loss 6.397889
[epoch17, step1008]: loss 2.124340
[epoch17, step1009]: loss 8.210916
[epoch17, step1010]: loss 1.229139
[epoch17, step1011]: loss 0.776988
[epoch17, step1012]: loss 0.627650
[epoch17, step1013]: loss 7.318783
[epoch17, step1014]: loss 7.861874
[epoch17, step1015]: loss 2.081524
[epoch17, step1016]: loss 7.253683
[epoch17, step1017]: loss 2.765727
[epoch17, step1018]: loss 2.189650
[epoch17, step1019]: loss 8.625384
[epoch17, step1020]: loss 1.507965
[epoch17, step1021]: loss 3.090898
[epoch17, step1022]: loss 1.566439
[epoch17, step1023]: loss 1.658779
[epoch17, step1024]: loss 0.752056
[epoch17, step1025]: loss 1.093967
[epoch17, step1026]: loss 1.517206
[epoch17, step1027]: loss 0.939150
[epoch17, step1028]: loss 0.551822
[epoch17, step1029]: loss 8.097130
[epoch17, step1030]: loss 0.749471
[epoch17, step1031]: loss 2.126500
[epoch17, step1032]: loss 0.669548
[epoch17, step1033]: loss 1.544240
[epoch17, step1034]: loss 15.140289
[epoch17, step1035]: loss 4.422873
[epoch17, step1036]: loss 1.408660
[epoch17, step1037]: loss 3.453983
[epoch17, step1038]: loss 6.897294
[epoch17, step1039]: loss 0.877367
[epoch17, step1040]: loss 0.575268
[epoch17, step1041]: loss 3.658995
[epoch17, step1042]: loss 8.691360
[epoch17, step1043]: loss 2.593101
[epoch17, step1044]: loss 1.189990
[epoch17, step1045]: loss 0.637255
[epoch17, step1046]: loss 2.456314
[epoch17, step1047]: loss 18.860617
[epoch17, step1048]: loss 0.363261
[epoch17, step1049]: loss 1.798643
[epoch17, step1050]: loss 4.728489
[epoch17, step1051]: loss 1.535550
[epoch17, step1052]: loss 1.917981
[epoch17, step1053]: loss 0.613016
[epoch17, step1054]: loss 6.721202
[epoch17, step1055]: loss 6.918252
[epoch17, step1056]: loss 3.259694
[epoch17, step1057]: loss 0.699239
[epoch17, step1058]: loss 0.926024
[epoch17, step1059]: loss 8.421800
[epoch17, step1060]: loss 2.149560
[epoch17, step1061]: loss 1.080383
[epoch17, step1062]: loss 2.637410
[epoch17, step1063]: loss 0.929578
[epoch17, step1064]: loss 1.840153
[epoch17, step1065]: loss 1.756677
[epoch17, step1066]: loss 9.795420
[epoch17, step1067]: loss 3.882542
[epoch17, step1068]: loss 6.625248
[epoch17, step1069]: loss 2.981901
[epoch17, step1070]: loss 0.636685
[epoch17, step1071]: loss 1.080994
[epoch17, step1072]: loss 7.500723
[epoch17, step1073]: loss 0.656904
[epoch17, step1074]: loss 0.809393
[epoch17, step1075]: loss 3.127499
[epoch17, step1076]: loss 1.186719
[epoch17, step1077]: loss 0.560068
[epoch17, step1078]: loss 12.476143
[epoch17, step1079]: loss 4.416186
[epoch17, step1080]: loss 3.434896
[epoch17, step1081]: loss 1.011026
[epoch17, step1082]: loss 0.803016
[epoch17, step1083]: loss 0.918068
[epoch17, step1084]: loss 5.857713
[epoch17, step1085]: loss 9.600710
[epoch17, step1086]: loss 9.157042
[epoch17, step1087]: loss 3.209027
[epoch17, step1088]: loss 0.564396
[epoch17, step1089]: loss 6.712932
[epoch17, step1090]: loss 12.913936
[epoch17, step1091]: loss 18.788824
[epoch17, step1092]: loss 7.313521
[epoch17, step1093]: loss 3.097611
[epoch17, step1094]: loss 3.929351
[epoch17, step1095]: loss 1.112121
[epoch17, step1096]: loss 2.096364
[epoch17, step1097]: loss 0.936499
[epoch17, step1098]: loss 1.410810
[epoch17, step1099]: loss 1.067222
[epoch17, step1100]: loss 2.293798
[epoch17, step1101]: loss 0.867724
[epoch17, step1102]: loss 0.494784
[epoch17, step1103]: loss 2.634690
[epoch17, step1104]: loss 1.451457
[epoch17, step1105]: loss 9.621897
[epoch17, step1106]: loss 5.947977
[epoch17, step1107]: loss 0.778085
[epoch17, step1108]: loss 1.833163
[epoch17, step1109]: loss 12.166515
[epoch17, step1110]: loss 0.594151
[epoch17, step1111]: loss 0.680391
[epoch17, step1112]: loss 2.509019
[epoch17, step1113]: loss 2.949817
[epoch17, step1114]: loss 2.554605
[epoch17, step1115]: loss 0.842601
[epoch17, step1116]: loss 1.217044
[epoch17, step1117]: loss 0.782470
[epoch17, step1118]: loss 2.949856
[epoch17, step1119]: loss 2.981451
[epoch17, step1120]: loss 7.251697
[epoch17, step1121]: loss 13.221141
[epoch17, step1122]: loss 4.387370
[epoch17, step1123]: loss 4.482035
[epoch17, step1124]: loss 0.681958
[epoch17, step1125]: loss 2.653034
[epoch17, step1126]: loss 0.940156
[epoch17, step1127]: loss 0.629346
[epoch17, step1128]: loss 1.628218
[epoch17, step1129]: loss 1.432085
[epoch17, step1130]: loss 2.302917
[epoch17, step1131]: loss 0.712533
[epoch17, step1132]: loss 1.203976
[epoch17, step1133]: loss 1.132438
[epoch17, step1134]: loss 3.783983
[epoch17, step1135]: loss 1.810935
[epoch17, step1136]: loss 1.014367
[epoch17, step1137]: loss 1.273263
[epoch17, step1138]: loss 0.635297
[epoch17, step1139]: loss 0.851727
[epoch17, step1140]: loss 1.326660
[epoch17, step1141]: loss 5.160490
[epoch17, step1142]: loss 2.729158
[epoch17, step1143]: loss 3.317937
[epoch17, step1144]: loss 1.088961
[epoch17, step1145]: loss 0.536438
[epoch17, step1146]: loss 2.387362
[epoch17, step1147]: loss 0.666474
[epoch17, step1148]: loss 0.806885
[epoch17, step1149]: loss 0.976645
[epoch17, step1150]: loss 0.730381
[epoch17, step1151]: loss 0.612725
[epoch17, step1152]: loss 1.128205
[epoch17, step1153]: loss 7.082501
[epoch17, step1154]: loss 2.418106
[epoch17, step1155]: loss 3.410981
[epoch17, step1156]: loss 0.965808
[epoch17, step1157]: loss 13.383657
[epoch17, step1158]: loss 0.947674
[epoch17, step1159]: loss 1.385335
[epoch17, step1160]: loss 2.776972
[epoch17, step1161]: loss 6.924964
[epoch17, step1162]: loss 17.304623
[epoch17, step1163]: loss 1.620098
[epoch17, step1164]: loss 3.714910
[epoch17, step1165]: loss 1.203438
[epoch17, step1166]: loss 1.263504
[epoch17, step1167]: loss 1.400815
[epoch17, step1168]: loss 2.000979
[epoch17, step1169]: loss 8.140698
[epoch17, step1170]: loss 6.736003
[epoch17, step1171]: loss 0.872426
[epoch17, step1172]: loss 0.852144
[epoch17, step1173]: loss 1.247544
[epoch17, step1174]: loss 0.918578
[epoch17, step1175]: loss 0.817850
[epoch17, step1176]: loss 9.416619
[epoch17, step1177]: loss 1.085022
[epoch17, step1178]: loss 0.977199
[epoch17, step1179]: loss 1.468895
[epoch17, step1180]: loss 11.500012
[epoch17, step1181]: loss 8.410468
[epoch17, step1182]: loss 7.123870
[epoch17, step1183]: loss 2.630166
[epoch17, step1184]: loss 1.953021
[epoch17, step1185]: loss 2.551807
[epoch17, step1186]: loss 6.115106
[epoch17, step1187]: loss 3.437707
[epoch17, step1188]: loss 2.312756
[epoch17, step1189]: loss 3.431187
[epoch17, step1190]: loss 9.049430
[epoch17, step1191]: loss 7.003215
[epoch17, step1192]: loss 5.153267
[epoch17, step1193]: loss 1.179330
[epoch17, step1194]: loss 0.903803
[epoch17, step1195]: loss 1.552031
[epoch17, step1196]: loss 6.897535
[epoch17, step1197]: loss 0.799270
[epoch17, step1198]: loss 1.425396
[epoch17, step1199]: loss 0.631201
[epoch17, step1200]: loss 1.183830
[epoch17, step1201]: loss 10.647485
[epoch17, step1202]: loss 3.463023
[epoch17, step1203]: loss 13.014220
[epoch17, step1204]: loss 0.906655
[epoch17, step1205]: loss 6.919175
[epoch17, step1206]: loss 2.083183
[epoch17, step1207]: loss 7.957156
[epoch17, step1208]: loss 0.556965
[epoch17, step1209]: loss 14.940808
[epoch17, step1210]: loss 1.077680
[epoch17, step1211]: loss 1.866890
[epoch17, step1212]: loss 5.485938
[epoch17, step1213]: loss 6.119628
[epoch17, step1214]: loss 6.941539
[epoch17, step1215]: loss 11.866110
[epoch17, step1216]: loss 9.746837
[epoch17, step1217]: loss 0.910825
[epoch17, step1218]: loss 28.072418
[epoch17, step1219]: loss 7.215469
[epoch17, step1220]: loss 11.921089
[epoch17, step1221]: loss 1.175031
[epoch17, step1222]: loss 2.579517
[epoch17, step1223]: loss 1.344105
[epoch17, step1224]: loss 13.994454
[epoch17, step1225]: loss 1.023577
[epoch17, step1226]: loss 2.125237
[epoch17, step1227]: loss 5.255817
[epoch17, step1228]: loss 2.923033
[epoch17, step1229]: loss 0.658067
[epoch17, step1230]: loss 11.377301
[epoch17, step1231]: loss 1.332386
[epoch17, step1232]: loss 0.686448
[epoch17, step1233]: loss 1.087608
[epoch17, step1234]: loss 0.974376
[epoch17, step1235]: loss 0.915163
[epoch17, step1236]: loss 1.606781
[epoch17, step1237]: loss 0.623145
[epoch17, step1238]: loss 0.913848
[epoch17, step1239]: loss 1.387144
[epoch17, step1240]: loss 7.665710
[epoch17, step1241]: loss 1.238779
[epoch17, step1242]: loss 0.611037
[epoch17, step1243]: loss 4.510283
[epoch17, step1244]: loss 2.525069
[epoch17, step1245]: loss 11.774780
[epoch17, step1246]: loss 8.315721
[epoch17, step1247]: loss 19.456413
[epoch17, step1248]: loss 8.953117
[epoch17, step1249]: loss 8.254593
[epoch17, step1250]: loss 1.213984
[epoch17, step1251]: loss 0.957520
[epoch17, step1252]: loss 2.135203
[epoch17, step1253]: loss 0.766964
[epoch17, step1254]: loss 1.026117
[epoch17, step1255]: loss 0.864421
[epoch17, step1256]: loss 0.779609
[epoch17, step1257]: loss 11.395009
[epoch17, step1258]: loss 1.496347
[epoch17, step1259]: loss 2.124536
[epoch17, step1260]: loss 2.947339
[epoch17, step1261]: loss 0.477210
[epoch17, step1262]: loss 0.749837
[epoch17, step1263]: loss 2.446097
[epoch17, step1264]: loss 8.191600
[epoch17, step1265]: loss 3.678831
[epoch17, step1266]: loss 1.548570
[epoch17, step1267]: loss 0.892939
[epoch17, step1268]: loss 12.939803
[epoch17, step1269]: loss 1.131119
[epoch17, step1270]: loss 1.466579
[epoch17, step1271]: loss 27.053764
[epoch17, step1272]: loss 5.936124
[epoch17, step1273]: loss 2.291890
[epoch17, step1274]: loss 11.193141
[epoch17, step1275]: loss 2.503091
[epoch17, step1276]: loss 2.260675
[epoch17, step1277]: loss 0.900454
[epoch17, step1278]: loss 0.525241
[epoch17, step1279]: loss 1.116628
[epoch17, step1280]: loss 3.046924
[epoch17, step1281]: loss 6.427626
[epoch17, step1282]: loss 1.186768
[epoch17, step1283]: loss 0.621389
[epoch17, step1284]: loss 0.791094
[epoch17, step1285]: loss 1.366470
[epoch17, step1286]: loss 1.566530
[epoch17, step1287]: loss 0.911720
[epoch17, step1288]: loss 0.842875
[epoch17, step1289]: loss 7.115729
[epoch17, step1290]: loss 4.615875
[epoch17, step1291]: loss 0.591798
[epoch17, step1292]: loss 6.270096
[epoch17, step1293]: loss 1.247364
[epoch17, step1294]: loss 4.054863
[epoch17, step1295]: loss 1.724276
[epoch17, step1296]: loss 6.377125
[epoch17, step1297]: loss 5.119110
[epoch17, step1298]: loss 1.424727
[epoch17, step1299]: loss 7.550597
[epoch17, step1300]: loss 12.748581
[epoch17, step1301]: loss 21.320023
[epoch17, step1302]: loss 9.116212
[epoch17, step1303]: loss 1.126925
[epoch17, step1304]: loss 4.936295
[epoch17, step1305]: loss 0.797401
[epoch17, step1306]: loss 0.857691
[epoch17, step1307]: loss 3.375742
[epoch17, step1308]: loss 1.176067
[epoch17, step1309]: loss 1.053878
[epoch17, step1310]: loss 0.863200
[epoch17, step1311]: loss 1.500214
[epoch17, step1312]: loss 1.927067
[epoch17, step1313]: loss 0.598813
[epoch17, step1314]: loss 9.051482
[epoch17, step1315]: loss 1.183765
[epoch17, step1316]: loss 0.701421
[epoch17, step1317]: loss 0.995454
[epoch17, step1318]: loss 4.078379
[epoch17, step1319]: loss 0.696523
[epoch17, step1320]: loss 1.754099
[epoch17, step1321]: loss 7.056479
[epoch17, step1322]: loss 9.798759
[epoch17, step1323]: loss 2.226767
[epoch17, step1324]: loss 0.944833
[epoch17, step1325]: loss 3.017684
[epoch17, step1326]: loss 6.651036
[epoch17, step1327]: loss 19.876705
[epoch17, step1328]: loss 1.161443
[epoch17, step1329]: loss 9.114086
[epoch17, step1330]: loss 1.209230
[epoch17, step1331]: loss 0.833997
[epoch17, step1332]: loss 0.478400
[epoch17, step1333]: loss 3.702174
[epoch17, step1334]: loss 0.986718
[epoch17, step1335]: loss 0.748135
[epoch17, step1336]: loss 9.960933
[epoch17, step1337]: loss 0.656110
[epoch17, step1338]: loss 2.242147
[epoch17, step1339]: loss 0.701802
[epoch17, step1340]: loss 1.133386
[epoch17, step1341]: loss 5.624163
[epoch17, step1342]: loss 2.723629
[epoch17, step1343]: loss 1.584261
[epoch17, step1344]: loss 1.215021
[epoch17, step1345]: loss 4.551032
[epoch17, step1346]: loss 1.500038
[epoch17, step1347]: loss 1.503868
[epoch17, step1348]: loss 0.868702
[epoch17, step1349]: loss 0.821943
[epoch17, step1350]: loss 5.824947
[epoch17, step1351]: loss 6.572371
[epoch17, step1352]: loss 9.889097
[epoch17, step1353]: loss 6.238157
[epoch17, step1354]: loss 6.828404
[epoch17, step1355]: loss 13.923273
[epoch17, step1356]: loss 6.516785
[epoch17, step1357]: loss 0.595890
[epoch17, step1358]: loss 0.629111
[epoch17, step1359]: loss 0.651217
[epoch17, step1360]: loss 1.547598
[epoch17, step1361]: loss 12.965829
[epoch17, step1362]: loss 7.203686
[epoch17, step1363]: loss 0.582783
[epoch17, step1364]: loss 1.518922
[epoch17, step1365]: loss 1.195425
[epoch17, step1366]: loss 1.524855
[epoch17, step1367]: loss 5.767229
[epoch17, step1368]: loss 1.914375
[epoch17, step1369]: loss 3.978912
[epoch17, step1370]: loss 1.545693
[epoch17, step1371]: loss 0.803360
[epoch17, step1372]: loss 8.967569
[epoch17, step1373]: loss 0.791998
[epoch17, step1374]: loss 4.234848
[epoch17, step1375]: loss 8.527451
[epoch17, step1376]: loss 1.083188
[epoch17, step1377]: loss 0.848878
[epoch17, step1378]: loss 2.773970
[epoch17, step1379]: loss 7.032506
[epoch17, step1380]: loss 3.408873
[epoch17, step1381]: loss 1.040480
[epoch17, step1382]: loss 3.608426
[epoch17, step1383]: loss 0.658300
[epoch17, step1384]: loss 1.555259
[epoch17, step1385]: loss 5.325922
[epoch17, step1386]: loss 2.523471
[epoch17, step1387]: loss 0.473326
[epoch17, step1388]: loss 11.520552
[epoch17, step1389]: loss 2.652982
[epoch17, step1390]: loss 11.999359
[epoch17, step1391]: loss 5.348616
[epoch17, step1392]: loss 6.390145
[epoch17, step1393]: loss 6.583927
[epoch17, step1394]: loss 1.748672
[epoch17, step1395]: loss 1.460823
[epoch17, step1396]: loss 7.139384
[epoch17, step1397]: loss 1.262668
[epoch17, step1398]: loss 1.317081
[epoch17, step1399]: loss 5.125101
[epoch17, step1400]: loss 1.209162
[epoch17, step1401]: loss 1.450992
[epoch17, step1402]: loss 0.855235
[epoch17, step1403]: loss 6.471307
[epoch17, step1404]: loss 1.912928
[epoch17, step1405]: loss 1.611221
[epoch17, step1406]: loss 6.355825
[epoch17, step1407]: loss 9.602974
[epoch17, step1408]: loss 11.290318
[epoch17, step1409]: loss 0.895665
[epoch17, step1410]: loss 1.283025
[epoch17, step1411]: loss 0.751818
[epoch17, step1412]: loss 2.575282
[epoch17, step1413]: loss 0.455715
[epoch17, step1414]: loss 1.077941
[epoch17, step1415]: loss 1.328454
[epoch17, step1416]: loss 0.728495
[epoch17, step1417]: loss 2.277247
[epoch17, step1418]: loss 9.074620
[epoch17, step1419]: loss 10.515795
[epoch17, step1420]: loss 2.385231
[epoch17, step1421]: loss 10.847563
[epoch17, step1422]: loss 0.724135
[epoch17, step1423]: loss 4.130283
[epoch17, step1424]: loss 0.611393
[epoch17, step1425]: loss 0.786893
[epoch17, step1426]: loss 2.271910
[epoch17, step1427]: loss 5.162745
[epoch17, step1428]: loss 2.861891
[epoch17, step1429]: loss 8.347418
[epoch17, step1430]: loss 2.740608
[epoch17, step1431]: loss 0.658400
[epoch17, step1432]: loss 0.675292
[epoch17, step1433]: loss 3.199019
[epoch17, step1434]: loss 9.283591
[epoch17, step1435]: loss 0.612734
[epoch17, step1436]: loss 7.951097
[epoch17, step1437]: loss 5.498772
[epoch17, step1438]: loss 0.454204
[epoch17, step1439]: loss 1.005522
[epoch17, step1440]: loss 0.690668
[epoch17, step1441]: loss 2.817071
[epoch17, step1442]: loss 2.149530
[epoch17, step1443]: loss 0.928466
[epoch17, step1444]: loss 10.553887
[epoch17, step1445]: loss 8.630872
[epoch17, step1446]: loss 1.417397
[epoch17, step1447]: loss 3.299547
[epoch17, step1448]: loss 0.758167
[epoch17, step1449]: loss 6.677694
[epoch17, step1450]: loss 1.004493
[epoch17, step1451]: loss 1.036568
[epoch17, step1452]: loss 2.952111
[epoch17, step1453]: loss 11.207821
[epoch17, step1454]: loss 1.176663
[epoch17, step1455]: loss 7.928424
[epoch17, step1456]: loss 14.562594
[epoch17, step1457]: loss 2.907168
[epoch17, step1458]: loss 1.303593
[epoch17, step1459]: loss 1.775807
[epoch17, step1460]: loss 2.083313
[epoch17, step1461]: loss 1.532430
[epoch17, step1462]: loss 12.589230
[epoch17, step1463]: loss 1.624956
[epoch17, step1464]: loss 0.632940
[epoch17, step1465]: loss 8.061058
[epoch17, step1466]: loss 1.264834
[epoch17, step1467]: loss 2.962632
[epoch17, step1468]: loss 2.083919
[epoch17, step1469]: loss 5.658496
[epoch17, step1470]: loss 2.303589
[epoch17, step1471]: loss 2.707165
[epoch17, step1472]: loss 9.402422
[epoch17, step1473]: loss 2.167986
[epoch17, step1474]: loss 0.767857
[epoch17, step1475]: loss 1.192394
[epoch17, step1476]: loss 9.527447
[epoch17, step1477]: loss 1.201220
[epoch17, step1478]: loss 2.176757
[epoch17, step1479]: loss 1.259293
[epoch17, step1480]: loss 0.845393
[epoch17, step1481]: loss 1.404423
[epoch17, step1482]: loss 0.593196
[epoch17, step1483]: loss 0.961181
[epoch17, step1484]: loss 1.462962
[epoch17, step1485]: loss 0.788353
[epoch17, step1486]: loss 1.745472
[epoch17, step1487]: loss 2.138606
[epoch17, step1488]: loss 5.849908
[epoch17, step1489]: loss 9.543460
[epoch17, step1490]: loss 1.961601
[epoch17, step1491]: loss 0.886236
[epoch17, step1492]: loss 2.297983
[epoch17, step1493]: loss 7.159405
[epoch17, step1494]: loss 1.593660
[epoch17, step1495]: loss 0.462047
[epoch17, step1496]: loss 1.095482
[epoch17, step1497]: loss 1.152398
[epoch17, step1498]: loss 1.638054
[epoch17, step1499]: loss 4.780703
[epoch17, step1500]: loss 1.631949
[epoch17, step1501]: loss 7.615965
[epoch17, step1502]: loss 0.877107
[epoch17, step1503]: loss 6.619061
[epoch17, step1504]: loss 2.094910
[epoch17, step1505]: loss 1.414220
[epoch17, step1506]: loss 14.726705
[epoch17, step1507]: loss 0.627393
[epoch17, step1508]: loss 1.706047
[epoch17, step1509]: loss 1.148914
[epoch17, step1510]: loss 6.927317
[epoch17, step1511]: loss 2.042605
[epoch17, step1512]: loss 0.845152
[epoch17, step1513]: loss 0.574199
[epoch17, step1514]: loss 0.566901
[epoch17, step1515]: loss 9.317547
[epoch17, step1516]: loss 15.076868
[epoch17, step1517]: loss 8.364581
[epoch17, step1518]: loss 1.135465
[epoch17, step1519]: loss 2.259313
[epoch17, step1520]: loss 3.808950
[epoch17, step1521]: loss 11.171979
[epoch17, step1522]: loss 1.142270
[epoch17, step1523]: loss 1.366074
[epoch17, step1524]: loss 22.638594
[epoch17, step1525]: loss 10.515203
[epoch17, step1526]: loss 3.135664
[epoch17, step1527]: loss 13.086496
[epoch17, step1528]: loss 0.899072
[epoch17, step1529]: loss 0.688146
[epoch17, step1530]: loss 0.696085
[epoch17, step1531]: loss 3.068974
[epoch17, step1532]: loss 6.683410
[epoch17, step1533]: loss 0.567383
[epoch17, step1534]: loss 14.865658
[epoch17, step1535]: loss 0.814858
[epoch17, step1536]: loss 0.688874
[epoch17, step1537]: loss 0.711771
[epoch17, step1538]: loss 1.233596
[epoch17, step1539]: loss 6.552664
[epoch17, step1540]: loss 14.746966
[epoch17, step1541]: loss 1.555252
[epoch17, step1542]: loss 1.473642
[epoch17, step1543]: loss 1.348526
[epoch17, step1544]: loss 13.089408
[epoch17, step1545]: loss 10.017441
[epoch17, step1546]: loss 0.758824
[epoch17, step1547]: loss 0.610096
[epoch17, step1548]: loss 0.787092
[epoch17, step1549]: loss 8.751072
[epoch17, step1550]: loss 9.590305
[epoch17, step1551]: loss 8.230597
[epoch17, step1552]: loss 24.719259
[epoch17, step1553]: loss 3.108341
[epoch17, step1554]: loss 6.438848
[epoch17, step1555]: loss 1.056224
[epoch17, step1556]: loss 6.101501
[epoch17, step1557]: loss 1.725755
[epoch17, step1558]: loss 1.590851
[epoch17, step1559]: loss 15.524446
[epoch17, step1560]: loss 8.734197
[epoch17, step1561]: loss 1.419856
[epoch17, step1562]: loss 2.788764
[epoch17, step1563]: loss 8.658443
[epoch17, step1564]: loss 1.077808
[epoch17, step1565]: loss 9.592582
[epoch17, step1566]: loss 1.148982
[epoch17, step1567]: loss 7.405160
[epoch17, step1568]: loss 1.293919
[epoch17, step1569]: loss 1.183746
[epoch17, step1570]: loss 0.782914
[epoch17, step1571]: loss 2.818439
[epoch17, step1572]: loss 8.839480
[epoch17, step1573]: loss 7.095561
[epoch17, step1574]: loss 2.137425
[epoch17, step1575]: loss 6.857482
[epoch17, step1576]: loss 1.062476
[epoch17, step1577]: loss 12.553651
[epoch17, step1578]: loss 5.956474
[epoch17, step1579]: loss 1.043127
[epoch17, step1580]: loss 1.187777
[epoch17, step1581]: loss 4.853448
[epoch17, step1582]: loss 2.031461
[epoch17, step1583]: loss 1.154116
[epoch17, step1584]: loss 0.728331
[epoch17, step1585]: loss 8.571249
[epoch17, step1586]: loss 8.362349
[epoch17, step1587]: loss 1.805853
[epoch17, step1588]: loss 1.892013
[epoch17, step1589]: loss 2.798316
[epoch17, step1590]: loss 6.443821
[epoch17, step1591]: loss 1.386252
[epoch17, step1592]: loss 8.929688
[epoch17, step1593]: loss 0.933702
[epoch17, step1594]: loss 0.756133
[epoch17, step1595]: loss 0.873819
[epoch17, step1596]: loss 1.584763
[epoch17, step1597]: loss 1.355158
[epoch17, step1598]: loss 1.707502
[epoch17, step1599]: loss 8.092715
[epoch17, step1600]: loss 3.756004
[epoch17, step1601]: loss 0.518179
[epoch17, step1602]: loss 2.188772
[epoch17, step1603]: loss 1.276631
[epoch17, step1604]: loss 0.990818
[epoch17, step1605]: loss 4.612671
[epoch17, step1606]: loss 2.350737
[epoch17, step1607]: loss 1.304430
[epoch17, step1608]: loss 1.176758
[epoch17, step1609]: loss 1.482485
[epoch17, step1610]: loss 0.926004
[epoch17, step1611]: loss 9.149885
[epoch17, step1612]: loss 1.836074
[epoch17, step1613]: loss 0.769881
[epoch17, step1614]: loss 1.274507
[epoch17, step1615]: loss 0.882031
[epoch17, step1616]: loss 7.678659
[epoch17, step1617]: loss 0.830014
[epoch17, step1618]: loss 6.777377
[epoch17, step1619]: loss 6.177100
[epoch17, step1620]: loss 0.646173
[epoch17, step1621]: loss 2.732982
[epoch17, step1622]: loss 1.726365
[epoch17, step1623]: loss 0.723694
[epoch17, step1624]: loss 1.192578
[epoch17, step1625]: loss 6.086415
[epoch17, step1626]: loss 3.922076
[epoch17, step1627]: loss 0.745456
[epoch17, step1628]: loss 1.454672
[epoch17, step1629]: loss 1.483697
[epoch17, step1630]: loss 1.056727
[epoch17, step1631]: loss 1.536868
[epoch17, step1632]: loss 0.842349
[epoch17, step1633]: loss 1.577317
[epoch17, step1634]: loss 1.471978
[epoch17, step1635]: loss 1.828149
[epoch17, step1636]: loss 0.683037
[epoch17, step1637]: loss 16.242859
[epoch17, step1638]: loss 1.758540
[epoch17, step1639]: loss 15.218960
[epoch17, step1640]: loss 9.614709
[epoch17, step1641]: loss 9.716048
[epoch17, step1642]: loss 0.931398
[epoch17, step1643]: loss 0.997488
[epoch17, step1644]: loss 0.898954
[epoch17, step1645]: loss 1.560348
[epoch17, step1646]: loss 1.965605
[epoch17, step1647]: loss 1.238138
[epoch17, step1648]: loss 7.053308
[epoch17, step1649]: loss 0.607909
[epoch17, step1650]: loss 7.535064
[epoch17, step1651]: loss 2.186297
[epoch17, step1652]: loss 15.344230
[epoch17, step1653]: loss 12.754539
[epoch17, step1654]: loss 0.831892
[epoch17, step1655]: loss 0.601246
[epoch17, step1656]: loss 3.265814
[epoch17, step1657]: loss 0.686989
[epoch17, step1658]: loss 0.552257
[epoch17, step1659]: loss 0.713370
[epoch17, step1660]: loss 0.694437
[epoch17, step1661]: loss 1.474713
[epoch17, step1662]: loss 11.744070
[epoch17, step1663]: loss 0.722268
[epoch17, step1664]: loss 2.388449
[epoch17, step1665]: loss 1.880506
[epoch17, step1666]: loss 0.573735
[epoch17, step1667]: loss 9.272892
[epoch17, step1668]: loss 2.153669
[epoch17, step1669]: loss 8.622903
[epoch17, step1670]: loss 1.019336
[epoch17, step1671]: loss 1.187961
[epoch17, step1672]: loss 1.853562
[epoch17, step1673]: loss 0.691589
[epoch17, step1674]: loss 11.194654
[epoch17, step1675]: loss 1.789640
[epoch17, step1676]: loss 0.757569
[epoch17, step1677]: loss 1.133851
[epoch17, step1678]: loss 9.185234
[epoch17, step1679]: loss 1.323737
[epoch17, step1680]: loss 2.025071
[epoch17, step1681]: loss 0.890962
[epoch17, step1682]: loss 1.860751
[epoch17, step1683]: loss 0.589115
[epoch17, step1684]: loss 6.845045
[epoch17, step1685]: loss 1.293543
[epoch17, step1686]: loss 1.099556
[epoch17, step1687]: loss 5.252935
[epoch17, step1688]: loss 8.362998
[epoch17, step1689]: loss 10.067919
[epoch17, step1690]: loss 0.636040
[epoch17, step1691]: loss 8.318856
[epoch17, step1692]: loss 2.341779
[epoch17, step1693]: loss 0.969087
[epoch17, step1694]: loss 1.811773
[epoch17, step1695]: loss 2.341773
[epoch17, step1696]: loss 1.086014
[epoch17, step1697]: loss 0.750149
[epoch17, step1698]: loss 1.075276
[epoch17, step1699]: loss 8.013000
[epoch17, step1700]: loss 10.570529
[epoch17, step1701]: loss 0.865567
[epoch17, step1702]: loss 0.617021
[epoch17, step1703]: loss 3.090949
[epoch17, step1704]: loss 1.835303
[epoch17, step1705]: loss 0.710822
[epoch17, step1706]: loss 9.924671
[epoch17, step1707]: loss 0.628717
[epoch17, step1708]: loss 11.099577
[epoch17, step1709]: loss 1.838895
[epoch17, step1710]: loss 2.249766
[epoch17, step1711]: loss 2.805131
[epoch17, step1712]: loss 1.806967
[epoch17, step1713]: loss 4.854312
[epoch17, step1714]: loss 1.132891
[epoch17, step1715]: loss 1.136271
[epoch17, step1716]: loss 3.752411
[epoch17, step1717]: loss 1.751979
[epoch17, step1718]: loss 7.875608
[epoch17, step1719]: loss 0.775107
[epoch17, step1720]: loss 4.889519
[epoch17, step1721]: loss 1.974663
[epoch17, step1722]: loss 0.778359
[epoch17, step1723]: loss 2.746012
[epoch17, step1724]: loss 0.718987
[epoch17, step1725]: loss 9.992307
[epoch17, step1726]: loss 0.480621
[epoch17, step1727]: loss 0.717295
[epoch17, step1728]: loss 0.755979
[epoch17, step1729]: loss 6.919168
[epoch17, step1730]: loss 8.784937
[epoch17, step1731]: loss 7.469951
[epoch17, step1732]: loss 0.818506
[epoch17, step1733]: loss 6.319879
[epoch17, step1734]: loss 8.062658
[epoch17, step1735]: loss 2.873787
[epoch17, step1736]: loss 0.881043
[epoch17, step1737]: loss 0.449147
[epoch17, step1738]: loss 0.937393
[epoch17, step1739]: loss 1.007948
[epoch17, step1740]: loss 1.270717
[epoch17, step1741]: loss 9.439400
[epoch17, step1742]: loss 5.797212
[epoch17, step1743]: loss 0.743069
[epoch17, step1744]: loss 7.191027
[epoch17, step1745]: loss 3.586182
[epoch17, step1746]: loss 0.580339
[epoch17, step1747]: loss 0.605660
[epoch17, step1748]: loss 6.431374
[epoch17, step1749]: loss 1.174132
[epoch17, step1750]: loss 1.083956
[epoch17, step1751]: loss 0.992863
[epoch17, step1752]: loss 0.562847
[epoch17, step1753]: loss 1.585357
[epoch17, step1754]: loss 1.616406
[epoch17, step1755]: loss 1.169089
[epoch17, step1756]: loss 0.602439
[epoch17, step1757]: loss 5.426117
[epoch17, step1758]: loss 1.061506
[epoch17, step1759]: loss 1.274391
[epoch17, step1760]: loss 0.990762
[epoch17, step1761]: loss 2.496500
[epoch17, step1762]: loss 1.475875
[epoch17, step1763]: loss 0.975163
[epoch17, step1764]: loss 1.106185
[epoch17, step1765]: loss 2.013867
[epoch17, step1766]: loss 3.923020
[epoch17, step1767]: loss 9.853246
[epoch17, step1768]: loss 1.207206
[epoch17, step1769]: loss 16.906359
[epoch17, step1770]: loss 6.396107
[epoch17, step1771]: loss 9.759057
[epoch17, step1772]: loss 0.991468
[epoch17, step1773]: loss 6.610317
[epoch17, step1774]: loss 3.754139
[epoch17, step1775]: loss 1.464784
[epoch17, step1776]: loss 2.499635
[epoch17, step1777]: loss 1.135119
[epoch17, step1778]: loss 0.526778
[epoch17, step1779]: loss 0.910228
[epoch17, step1780]: loss 0.700042
[epoch17, step1781]: loss 0.917939
[epoch17, step1782]: loss 0.775282
[epoch17, step1783]: loss 3.178801
[epoch17, step1784]: loss 0.781465
[epoch17, step1785]: loss 11.095507
[epoch17, step1786]: loss 3.060706
[epoch17, step1787]: loss 2.365826
[epoch17, step1788]: loss 0.434504
[epoch17, step1789]: loss 0.977636
[epoch17, step1790]: loss 0.803101
[epoch17, step1791]: loss 2.731308
[epoch17, step1792]: loss 1.099943
[epoch17, step1793]: loss 0.974918
[epoch17, step1794]: loss 1.419458
[epoch17, step1795]: loss 1.450623
[epoch17, step1796]: loss 1.101916
[epoch17, step1797]: loss 1.543636
[epoch17, step1798]: loss 1.345689
[epoch17, step1799]: loss 8.147627
[epoch17, step1800]: loss 6.308934
[epoch17, step1801]: loss 7.713338
[epoch17, step1802]: loss 8.106369
[epoch17, step1803]: loss 1.581403
[epoch17, step1804]: loss 4.968896
[epoch17, step1805]: loss 5.619919
[epoch17, step1806]: loss 6.317695
[epoch17, step1807]: loss 1.585344
[epoch17, step1808]: loss 5.692411
[epoch17, step1809]: loss 3.213941
[epoch17, step1810]: loss 0.826171
[epoch17, step1811]: loss 4.615577
[epoch17, step1812]: loss 1.423039
[epoch17, step1813]: loss 8.437612
[epoch17, step1814]: loss 1.050005
[epoch17, step1815]: loss 4.760134
[epoch17, step1816]: loss 0.522563
[epoch17, step1817]: loss 0.970743
[epoch17, step1818]: loss 9.923631
[epoch17, step1819]: loss 3.352032
[epoch17, step1820]: loss 1.746358
[epoch17, step1821]: loss 2.765964
[epoch17, step1822]: loss 2.299709
[epoch17, step1823]: loss 1.273452
[epoch17, step1824]: loss 2.061843
[epoch17, step1825]: loss 6.225206
[epoch17, step1826]: loss 1.810940
[epoch17, step1827]: loss 1.462393
[epoch17, step1828]: loss 0.911679
[epoch17, step1829]: loss 2.067870
[epoch17, step1830]: loss 3.499874
[epoch17, step1831]: loss 0.904360
[epoch17, step1832]: loss 1.050486
[epoch17, step1833]: loss 1.289385
[epoch17, step1834]: loss 5.025061
[epoch17, step1835]: loss 11.357109
[epoch17, step1836]: loss 1.657286
[epoch17, step1837]: loss 7.044110
[epoch17, step1838]: loss 2.060152
[epoch17, step1839]: loss 6.280446
[epoch17, step1840]: loss 0.993774
[epoch17, step1841]: loss 4.236437
[epoch17, step1842]: loss 1.362084
[epoch17, step1843]: loss 1.535998
[epoch17, step1844]: loss 11.090078
[epoch17, step1845]: loss 1.059028
[epoch17, step1846]: loss 1.515683
[epoch17, step1847]: loss 3.172647
[epoch17, step1848]: loss 8.174844
[epoch17, step1849]: loss 6.197893
[epoch17, step1850]: loss 8.796288
[epoch17, step1851]: loss 3.242337
[epoch17, step1852]: loss 5.364930
[epoch17, step1853]: loss 1.084702
[epoch17, step1854]: loss 0.981500
[epoch17, step1855]: loss 11.113880
[epoch17, step1856]: loss 7.507165
[epoch17, step1857]: loss 0.588593
[epoch17, step1858]: loss 1.441550
[epoch17, step1859]: loss 1.141178
[epoch17, step1860]: loss 0.932703
[epoch17, step1861]: loss 4.699566
[epoch17, step1862]: loss 0.601376
[epoch17, step1863]: loss 1.783454
[epoch17, step1864]: loss 7.920182
[epoch17, step1865]: loss 0.717979
[epoch17, step1866]: loss 2.187217
[epoch17, step1867]: loss 1.280427
[epoch17, step1868]: loss 1.165610
[epoch17, step1869]: loss 1.175740
[epoch17, step1870]: loss 0.724926
[epoch17, step1871]: loss 0.962403
[epoch17, step1872]: loss 1.121743
[epoch17, step1873]: loss 9.633642
[epoch17, step1874]: loss 2.121309
[epoch17, step1875]: loss 0.583297
[epoch17, step1876]: loss 1.563617
[epoch17, step1877]: loss 0.605544
[epoch17, step1878]: loss 3.204512
[epoch17, step1879]: loss 0.507571
[epoch17, step1880]: loss 3.018622
[epoch17, step1881]: loss 8.675660
[epoch17, step1882]: loss 2.498549
[epoch17, step1883]: loss 8.994279
[epoch17, step1884]: loss 1.562567
[epoch17, step1885]: loss 0.776029
[epoch17, step1886]: loss 1.922667
[epoch17, step1887]: loss 5.705134
[epoch17, step1888]: loss 1.357562
[epoch17, step1889]: loss 2.412169
[epoch17, step1890]: loss 8.427393
[epoch17, step1891]: loss 1.002836
[epoch17, step1892]: loss 6.032551
[epoch17, step1893]: loss 9.635897
[epoch17, step1894]: loss 0.559167
[epoch17, step1895]: loss 0.711010
[epoch17, step1896]: loss 2.150166
[epoch17, step1897]: loss 1.801333
[epoch17, step1898]: loss 2.001658
[epoch17, step1899]: loss 1.635162
[epoch17, step1900]: loss 4.255311
[epoch17, step1901]: loss 1.477358
[epoch17, step1902]: loss 1.424140
[epoch17, step1903]: loss 1.177282
[epoch17, step1904]: loss 9.831078
[epoch17, step1905]: loss 1.552416
[epoch17, step1906]: loss 17.061531
[epoch17, step1907]: loss 1.227148
[epoch17, step1908]: loss 0.986532
[epoch17, step1909]: loss 0.697410
[epoch17, step1910]: loss 1.149602
[epoch17, step1911]: loss 2.782789
[epoch17, step1912]: loss 0.717239
[epoch17, step1913]: loss 0.945894
[epoch17, step1914]: loss 2.263556
[epoch17, step1915]: loss 1.593710
[epoch17, step1916]: loss 0.817577
[epoch17, step1917]: loss 0.797687
[epoch17, step1918]: loss 7.597593
[epoch17, step1919]: loss 0.457260
[epoch17, step1920]: loss 0.903411
[epoch17, step1921]: loss 6.018664
[epoch17, step1922]: loss 1.320670
[epoch17, step1923]: loss 10.525783
[epoch17, step1924]: loss 0.625909
[epoch17, step1925]: loss 20.793808
[epoch17, step1926]: loss 1.049519
[epoch17, step1927]: loss 9.476288
[epoch17, step1928]: loss 3.135323
[epoch17, step1929]: loss 0.971757
[epoch17, step1930]: loss 0.614036
[epoch17, step1931]: loss 0.673355
[epoch17, step1932]: loss 0.917434
[epoch17, step1933]: loss 9.225286
[epoch17, step1934]: loss 12.431189
[epoch17, step1935]: loss 21.859875
[epoch17, step1936]: loss 12.422813
[epoch17, step1937]: loss 0.523045
[epoch17, step1938]: loss 3.655059
[epoch17, step1939]: loss 0.820915
[epoch17, step1940]: loss 6.666965
[epoch17, step1941]: loss 5.301516
[epoch17, step1942]: loss 6.242448
[epoch17, step1943]: loss 1.136914
[epoch17, step1944]: loss 1.045324
[epoch17, step1945]: loss 2.844641
[epoch17, step1946]: loss 6.524315
[epoch17, step1947]: loss 1.211702
[epoch17, step1948]: loss 1.241411
[epoch17, step1949]: loss 10.127502
[epoch17, step1950]: loss 1.054437
[epoch17, step1951]: loss 1.114478
[epoch17, step1952]: loss 0.557573
[epoch17, step1953]: loss 1.113603
[epoch17, step1954]: loss 7.231851
[epoch17, step1955]: loss 12.682812
[epoch17, step1956]: loss 6.375717
[epoch17, step1957]: loss 0.727214
[epoch17, step1958]: loss 8.242586
[epoch17, step1959]: loss 0.816698
[epoch17, step1960]: loss 1.915158
[epoch17, step1961]: loss 2.025811
[epoch17, step1962]: loss 1.114977
[epoch17, step1963]: loss 0.762666
[epoch17, step1964]: loss 1.471521
[epoch17, step1965]: loss 1.306172
[epoch17, step1966]: loss 4.872633
[epoch17, step1967]: loss 2.217702
[epoch17, step1968]: loss 0.666663
[epoch17, step1969]: loss 1.015612
[epoch17, step1970]: loss 1.437860
[epoch17, step1971]: loss 6.147029
[epoch17, step1972]: loss 2.000771
[epoch17, step1973]: loss 6.537623
[epoch17, step1974]: loss 4.497843
[epoch17, step1975]: loss 0.826963
[epoch17, step1976]: loss 1.639113
[epoch17, step1977]: loss 1.105708
[epoch17, step1978]: loss 1.786952
[epoch17, step1979]: loss 6.210613
[epoch17, step1980]: loss 2.790586
[epoch17, step1981]: loss 11.237381
[epoch17, step1982]: loss 3.446965
[epoch17, step1983]: loss 8.963460
[epoch17, step1984]: loss 2.224375
[epoch17, step1985]: loss 0.519400
[epoch17, step1986]: loss 11.609748
[epoch17, step1987]: loss 0.604074
[epoch17, step1988]: loss 8.095412
[epoch17, step1989]: loss 9.199314
[epoch17, step1990]: loss 0.837679
[epoch17, step1991]: loss 6.234062
[epoch17, step1992]: loss 9.902830
[epoch17, step1993]: loss 3.371636
[epoch17, step1994]: loss 2.289028
[epoch17, step1995]: loss 0.808525
[epoch17, step1996]: loss 6.149543
[epoch17, step1997]: loss 11.597980
[epoch17, step1998]: loss 2.930175
[epoch17, step1999]: loss 0.672023
[epoch17, step2000]: loss 0.870370
[epoch17, step2001]: loss 3.133727
[epoch17, step2002]: loss 2.552703
[epoch17, step2003]: loss 2.186996
[epoch17, step2004]: loss 1.245111
[epoch17, step2005]: loss 0.600792
[epoch17, step2006]: loss 6.076194
[epoch17, step2007]: loss 1.110218
[epoch17, step2008]: loss 0.436933
[epoch17, step2009]: loss 0.706052
[epoch17, step2010]: loss 18.389763
[epoch17, step2011]: loss 0.758658
[epoch17, step2012]: loss 1.373700
[epoch17, step2013]: loss 8.954905
[epoch17, step2014]: loss 2.356789
[epoch17, step2015]: loss 14.794650
[epoch17, step2016]: loss 0.909942
[epoch17, step2017]: loss 1.303973
[epoch17, step2018]: loss 2.593225
[epoch17, step2019]: loss 5.464037
[epoch17, step2020]: loss 1.326181
[epoch17, step2021]: loss 0.742425
[epoch17, step2022]: loss 14.232559
[epoch17, step2023]: loss 1.497571
[epoch17, step2024]: loss 0.884000
[epoch17, step2025]: loss 0.636955
[epoch17, step2026]: loss 3.074415
[epoch17, step2027]: loss 6.242039
[epoch17, step2028]: loss 6.372280
[epoch17, step2029]: loss 4.301792
[epoch17, step2030]: loss 0.791971
[epoch17, step2031]: loss 0.606121
[epoch17, step2032]: loss 7.001971
[epoch17, step2033]: loss 1.170495
[epoch17, step2034]: loss 0.630386
[epoch17, step2035]: loss 2.203809
[epoch17, step2036]: loss 11.672834
[epoch17, step2037]: loss 0.766039
[epoch17, step2038]: loss 7.171993
[epoch17, step2039]: loss 3.166412
[epoch17, step2040]: loss 6.975129
[epoch17, step2041]: loss 0.693284
[epoch17, step2042]: loss 9.974345
[epoch17, step2043]: loss 1.472976
[epoch17, step2044]: loss 1.357699
[epoch17, step2045]: loss 0.506555
[epoch17, step2046]: loss 6.027093
[epoch17, step2047]: loss 16.987194
[epoch17, step2048]: loss 6.040999
[epoch17, step2049]: loss 1.621885
[epoch17, step2050]: loss 6.804773
[epoch17, step2051]: loss 1.257992
[epoch17, step2052]: loss 1.225957
[epoch17, step2053]: loss 6.101829
[epoch17, step2054]: loss 2.430291
[epoch17, step2055]: loss 11.424409
[epoch17, step2056]: loss 14.015915
[epoch17, step2057]: loss 2.536605
[epoch17, step2058]: loss 4.789470
[epoch17, step2059]: loss 2.284245
[epoch17, step2060]: loss 0.744399
[epoch17, step2061]: loss 9.249722
[epoch17, step2062]: loss 8.788145
[epoch17, step2063]: loss 1.710639
[epoch17, step2064]: loss 6.751176
[epoch17, step2065]: loss 0.759176
[epoch17, step2066]: loss 1.521411
[epoch17, step2067]: loss 12.003175
[epoch17, step2068]: loss 2.178797
[epoch17, step2069]: loss 0.614481
[epoch17, step2070]: loss 6.221975
[epoch17, step2071]: loss 3.084363
[epoch17, step2072]: loss 2.447178
[epoch17, step2073]: loss 1.184347
[epoch17, step2074]: loss 2.536675
[epoch17, step2075]: loss 8.486616
[epoch17, step2076]: loss 0.605902
[epoch17, step2077]: loss 5.864650
[epoch17, step2078]: loss 1.497697
[epoch17, step2079]: loss 3.011774
[epoch17, step2080]: loss 2.195273
[epoch17, step2081]: loss 2.517714
[epoch17, step2082]: loss 0.800106
[epoch17, step2083]: loss 0.699754
[epoch17, step2084]: loss 0.772372
[epoch17, step2085]: loss 1.017401
[epoch17, step2086]: loss 1.643482
[epoch17, step2087]: loss 6.496947
[epoch17, step2088]: loss 6.180547
[epoch17, step2089]: loss 10.439732
[epoch17, step2090]: loss 17.187338
[epoch17, step2091]: loss 1.777449
[epoch17, step2092]: loss 2.587639
[epoch17, step2093]: loss 6.973477
[epoch17, step2094]: loss 1.467579
[epoch17, step2095]: loss 5.504138
[epoch17, step2096]: loss 1.884753
[epoch17, step2097]: loss 0.633837
[epoch17, step2098]: loss 3.494874
[epoch17, step2099]: loss 1.603188
[epoch17, step2100]: loss 0.674613
[epoch17, step2101]: loss 2.019393
[epoch17, step2102]: loss 6.380983
[epoch17, step2103]: loss 3.099301
[epoch17, step2104]: loss 3.178318
[epoch17, step2105]: loss 5.554380
[epoch17, step2106]: loss 0.776845
[epoch17, step2107]: loss 11.033117
[epoch17, step2108]: loss 6.511179
[epoch17, step2109]: loss 1.228980
[epoch17, step2110]: loss 1.271641
[epoch17, step2111]: loss 5.625317
[epoch17, step2112]: loss 0.947718
[epoch17, step2113]: loss 2.799788
[epoch17, step2114]: loss 6.759154
[epoch17, step2115]: loss 6.069840
[epoch17, step2116]: loss 10.274099
[epoch17, step2117]: loss 10.246974
[epoch17, step2118]: loss 2.789080
[epoch17, step2119]: loss 0.746229
[epoch17, step2120]: loss 10.986655
[epoch17, step2121]: loss 3.268277
[epoch17, step2122]: loss 7.015690
[epoch17, step2123]: loss 0.881901
[epoch17, step2124]: loss 1.435234
[epoch17, step2125]: loss 6.208566
[epoch17, step2126]: loss 11.889872
[epoch17, step2127]: loss 6.358522
[epoch17, step2128]: loss 1.038365
[epoch17, step2129]: loss 4.740176
[epoch17, step2130]: loss 1.321587
[epoch17, step2131]: loss 2.875783
[epoch17, step2132]: loss 1.454702
[epoch17, step2133]: loss 1.407770
[epoch17, step2134]: loss 1.998510
[epoch17, step2135]: loss 8.870667
[epoch17, step2136]: loss 13.173376
[epoch17, step2137]: loss 1.087540
[epoch17, step2138]: loss 2.578213
[epoch17, step2139]: loss 5.078030
[epoch17, step2140]: loss 0.886641
[epoch17, step2141]: loss 11.990165
[epoch17, step2142]: loss 6.753667
[epoch17, step2143]: loss 0.625826
[epoch17, step2144]: loss 1.926710
[epoch17, step2145]: loss 1.209827
[epoch17, step2146]: loss 4.995634
[epoch17, step2147]: loss 1.488876
[epoch17, step2148]: loss 1.966291
[epoch17, step2149]: loss 2.572174
[epoch17, step2150]: loss 1.252533
[epoch17, step2151]: loss 5.695104
[epoch17, step2152]: loss 7.314595
[epoch17, step2153]: loss 0.922003
[epoch17, step2154]: loss 6.346625
[epoch17, step2155]: loss 0.511925
[epoch17, step2156]: loss 0.934848
[epoch17, step2157]: loss 1.815168
[epoch17, step2158]: loss 0.907594
[epoch17, step2159]: loss 0.563952
[epoch17, step2160]: loss 1.395043
[epoch17, step2161]: loss 3.965400
[epoch17, step2162]: loss 1.254231
[epoch17, step2163]: loss 9.346847
[epoch17, step2164]: loss 3.310889
[epoch17, step2165]: loss 1.214727
[epoch17, step2166]: loss 3.128515
[epoch17, step2167]: loss 1.133244
[epoch17, step2168]: loss 8.818255
[epoch17, step2169]: loss 6.759411
[epoch17, step2170]: loss 10.487501
[epoch17, step2171]: loss 2.871079
[epoch17, step2172]: loss 0.762635
[epoch17, step2173]: loss 10.972842
[epoch17, step2174]: loss 7.469293
[epoch17, step2175]: loss 9.395758
[epoch17, step2176]: loss 2.100720
[epoch17, step2177]: loss 7.302388
[epoch17, step2178]: loss 1.778291
[epoch17, step2179]: loss 1.001507
[epoch17, step2180]: loss 5.446077
[epoch17, step2181]: loss 0.786086
[epoch17, step2182]: loss 6.115324
[epoch17, step2183]: loss 1.070302
[epoch17, step2184]: loss 3.018871
[epoch17, step2185]: loss 7.624843
[epoch17, step2186]: loss 0.778229
[epoch17, step2187]: loss 1.541547
[epoch17, step2188]: loss 0.777661
[epoch17, step2189]: loss 1.782528
[epoch17, step2190]: loss 1.126966
[epoch17, step2191]: loss 7.267293
[epoch17, step2192]: loss 1.500637
[epoch17, step2193]: loss 0.810658
[epoch17, step2194]: loss 2.417615
[epoch17, step2195]: loss 0.583722
[epoch17, step2196]: loss 2.422930
[epoch17, step2197]: loss 2.008061
[epoch17, step2198]: loss 3.877307
[epoch17, step2199]: loss 6.275723
[epoch17, step2200]: loss 5.637363
[epoch17, step2201]: loss 11.843575
[epoch17, step2202]: loss 14.192181
[epoch17, step2203]: loss 0.963357
[epoch17, step2204]: loss 0.801509
[epoch17, step2205]: loss 4.293714
[epoch17, step2206]: loss 2.722273
[epoch17, step2207]: loss 6.363226
[epoch17, step2208]: loss 0.910721
[epoch17, step2209]: loss 1.845291
[epoch17, step2210]: loss 2.461055
[epoch17, step2211]: loss 11.998668
[epoch17, step2212]: loss 0.697623
[epoch17, step2213]: loss 0.717058
[epoch17, step2214]: loss 2.582157
[epoch17, step2215]: loss 5.763161
[epoch17, step2216]: loss 0.833545
[epoch17, step2217]: loss 11.449262
[epoch17, step2218]: loss 1.579385
[epoch17, step2219]: loss 5.600834
[epoch17, step2220]: loss 6.523593
[epoch17, step2221]: loss 19.562952
[epoch17, step2222]: loss 1.380240
[epoch17, step2223]: loss 5.885081
[epoch17, step2224]: loss 1.355208
[epoch17, step2225]: loss 5.903769
[epoch17, step2226]: loss 6.996550
[epoch17, step2227]: loss 1.183339
[epoch17, step2228]: loss 2.114163
[epoch17, step2229]: loss 0.680726
[epoch17, step2230]: loss 3.617661
[epoch17, step2231]: loss 0.680461
[epoch17, step2232]: loss 0.682653
[epoch17, step2233]: loss 2.767193
[epoch17, step2234]: loss 1.402782
[epoch17, step2235]: loss 9.062780
[epoch17, step2236]: loss 14.611304
[epoch17, step2237]: loss 15.298365
[epoch17, step2238]: loss 3.257582
[epoch17, step2239]: loss 6.120209
[epoch17, step2240]: loss 2.340945
[epoch17, step2241]: loss 10.239792
[epoch17, step2242]: loss 3.288391
[epoch17, step2243]: loss 6.609899
[epoch17, step2244]: loss 0.833041
[epoch17, step2245]: loss 1.559423
[epoch17, step2246]: loss 2.753050
[epoch17, step2247]: loss 5.964398
[epoch17, step2248]: loss 0.679848
[epoch17, step2249]: loss 0.846546
[epoch17, step2250]: loss 2.412963
[epoch17, step2251]: loss 0.975778
[epoch17, step2252]: loss 0.539617
[epoch17, step2253]: loss 7.003401
[epoch17, step2254]: loss 1.194142
[epoch17, step2255]: loss 1.157591
[epoch17, step2256]: loss 10.362973
[epoch17, step2257]: loss 1.272045
[epoch17, step2258]: loss 8.086429
[epoch17, step2259]: loss 11.425966
[epoch17, step2260]: loss 11.103425
[epoch17, step2261]: loss 3.336683
[epoch17, step2262]: loss 2.247917
[epoch17, step2263]: loss 6.501826
[epoch17, step2264]: loss 2.861005
[epoch17, step2265]: loss 2.127354
[epoch17, step2266]: loss 13.096773
[epoch17, step2267]: loss 0.929021
[epoch17, step2268]: loss 19.906563
[epoch17, step2269]: loss 0.939863
[epoch17, step2270]: loss 1.395297
[epoch17, step2271]: loss 8.281866
[epoch17, step2272]: loss 3.813955
[epoch17, step2273]: loss 10.820771
[epoch17, step2274]: loss 0.921655
[epoch17, step2275]: loss 0.422574
[epoch17, step2276]: loss 16.655233
[epoch17, step2277]: loss 1.407955
[epoch17, step2278]: loss 7.777808
[epoch17, step2279]: loss 2.669367
[epoch17, step2280]: loss 1.672935
[epoch17, step2281]: loss 0.748247
[epoch17, step2282]: loss 6.086925
[epoch17, step2283]: loss 11.872085
[epoch17, step2284]: loss 7.650807
[epoch17, step2285]: loss 0.764867
[epoch17, step2286]: loss 10.844939
[epoch17, step2287]: loss 9.770769
[epoch17, step2288]: loss 0.644380
[epoch17, step2289]: loss 10.454415
[epoch17, step2290]: loss 6.395561
[epoch17, step2291]: loss 1.120212
[epoch17, step2292]: loss 4.936044
[epoch17, step2293]: loss 1.445087
[epoch17, step2294]: loss 0.839280
[epoch17, step2295]: loss 5.707400
[epoch17, step2296]: loss 0.730638
[epoch17, step2297]: loss 4.710390
[epoch17, step2298]: loss 0.672142
[epoch17, step2299]: loss 1.067870
[epoch17, step2300]: loss 1.864175
[epoch17, step2301]: loss 0.710942
[epoch17, step2302]: loss 0.748898
[epoch17, step2303]: loss 0.785805
[epoch17, step2304]: loss 12.203018
[epoch17, step2305]: loss 0.606400
[epoch17, step2306]: loss 6.870934
[epoch17, step2307]: loss 0.977991
[epoch17, step2308]: loss 0.605809
[epoch17, step2309]: loss 1.204891
[epoch17, step2310]: loss 6.361932
[epoch17, step2311]: loss 17.114161
[epoch17, step2312]: loss 1.696427
[epoch17, step2313]: loss 10.106034
[epoch17, step2314]: loss 3.400865
[epoch17, step2315]: loss 1.836872
[epoch17, step2316]: loss 0.513349
[epoch17, step2317]: loss 1.791753
[epoch17, step2318]: loss 1.040758
[epoch17, step2319]: loss 0.981030
[epoch17, step2320]: loss 0.849614
[epoch17, step2321]: loss 8.629362
[epoch17, step2322]: loss 6.148237
[epoch17, step2323]: loss 0.966988
[epoch17, step2324]: loss 0.816400
[epoch17, step2325]: loss 8.368021
[epoch17, step2326]: loss 5.156808
[epoch17, step2327]: loss 3.131068
[epoch17, step2328]: loss 2.190441
[epoch17, step2329]: loss 9.674873
[epoch17, step2330]: loss 11.360728
[epoch17, step2331]: loss 1.863607
[epoch17, step2332]: loss 16.519226
[epoch17, step2333]: loss 20.831964
[epoch17, step2334]: loss 2.279012
[epoch17, step2335]: loss 3.461084
[epoch17, step2336]: loss 10.999460
[epoch17, step2337]: loss 14.182511
[epoch17, step2338]: loss 2.829715
[epoch17, step2339]: loss 2.631161
[epoch17, step2340]: loss 0.399420
[epoch17, step2341]: loss 1.286554
[epoch17, step2342]: loss 9.748109
[epoch17, step2343]: loss 2.489996
[epoch17, step2344]: loss 2.514936
[epoch17, step2345]: loss 3.467088
[epoch17, step2346]: loss 0.423281
[epoch17, step2347]: loss 2.130487
[epoch17, step2348]: loss 0.674891
[epoch17, step2349]: loss 6.341788
[epoch17, step2350]: loss 2.734875
[epoch17, step2351]: loss 1.048040
[epoch17, step2352]: loss 3.232192
[epoch17, step2353]: loss 0.909253
[epoch17, step2354]: loss 1.562105
[epoch17, step2355]: loss 7.996701
[epoch17, step2356]: loss 1.863928
[epoch17, step2357]: loss 0.750716
[epoch17, step2358]: loss 0.692555
[epoch17, step2359]: loss 7.778309
[epoch17, step2360]: loss 2.159929
[epoch17, step2361]: loss 11.992974
[epoch17, step2362]: loss 0.955821
[epoch17, step2363]: loss 1.025329
[epoch17, step2364]: loss 0.781209
[epoch17, step2365]: loss 0.997676
[epoch17, step2366]: loss 0.608075
[epoch17, step2367]: loss 8.331949
[epoch17, step2368]: loss 2.183120
[epoch17, step2369]: loss 8.479047
[epoch17, step2370]: loss 2.593038
[epoch17, step2371]: loss 0.995845
[epoch17, step2372]: loss 0.615160
[epoch17, step2373]: loss 1.278160
[epoch17, step2374]: loss 6.276789
[epoch17, step2375]: loss 6.899589
[epoch17, step2376]: loss 1.135768
[epoch17, step2377]: loss 2.355621
[epoch17, step2378]: loss 5.923462
[epoch17, step2379]: loss 1.176821
[epoch17, step2380]: loss 2.265928
[epoch17, step2381]: loss 1.761681
[epoch17, step2382]: loss 6.678105
[epoch17, step2383]: loss 4.370401
[epoch17, step2384]: loss 1.051762
[epoch17, step2385]: loss 6.904512
[epoch17, step2386]: loss 10.245135
[epoch17, step2387]: loss 14.238810
[epoch17, step2388]: loss 0.561637
[epoch17, step2389]: loss 0.597460
[epoch17, step2390]: loss 0.730541
[epoch17, step2391]: loss 8.464098
[epoch17, step2392]: loss 5.665358
[epoch17, step2393]: loss 1.266282
[epoch17, step2394]: loss 1.794664
[epoch17, step2395]: loss 2.349087
[epoch17, step2396]: loss 0.831215
[epoch17, step2397]: loss 1.372097
[epoch17, step2398]: loss 0.833751
[epoch17, step2399]: loss 0.581764
[epoch17, step2400]: loss 0.753103
[epoch17, step2401]: loss 8.423891
[epoch17, step2402]: loss 0.684378
[epoch17, step2403]: loss 2.836859
[epoch17, step2404]: loss 16.077557
[epoch17, step2405]: loss 1.035457
[epoch17, step2406]: loss 1.183079
[epoch17, step2407]: loss 0.489985
[epoch17, step2408]: loss 1.800074
[epoch17, step2409]: loss 0.797933
[epoch17, step2410]: loss 2.346898
[epoch17, step2411]: loss 0.928095
[epoch17, step2412]: loss 0.685144
[epoch17, step2413]: loss 1.092928
[epoch17, step2414]: loss 0.979905
[epoch17, step2415]: loss 11.963212
[epoch17, step2416]: loss 0.983397
[epoch17, step2417]: loss 1.933779
[epoch17, step2418]: loss 0.970835
[epoch17, step2419]: loss 1.602056
[epoch17, step2420]: loss 1.419384
[epoch17, step2421]: loss 0.639677
[epoch17, step2422]: loss 6.659883
[epoch17, step2423]: loss 2.309644
[epoch17, step2424]: loss 6.259537
[epoch17, step2425]: loss 6.294006
[epoch17, step2426]: loss 9.144423
[epoch17, step2427]: loss 0.754162
[epoch17, step2428]: loss 1.880533
[epoch17, step2429]: loss 3.069251
[epoch17, step2430]: loss 0.732176
[epoch17, step2431]: loss 3.610743
[epoch17, step2432]: loss 0.952767
[epoch17, step2433]: loss 6.984785
[epoch17, step2434]: loss 1.205817
[epoch17, step2435]: loss 4.029114
[epoch17, step2436]: loss 2.089572
[epoch17, step2437]: loss 4.845968
[epoch17, step2438]: loss 1.008580
[epoch17, step2439]: loss 18.368481
[epoch17, step2440]: loss 0.741781
[epoch17, step2441]: loss 0.640612
[epoch17, step2442]: loss 0.371130
[epoch17, step2443]: loss 1.316869
[epoch17, step2444]: loss 7.360157
[epoch17, step2445]: loss 9.080099
[epoch17, step2446]: loss 0.880647
[epoch17, step2447]: loss 3.040394
[epoch17, step2448]: loss 1.173694
[epoch17, step2449]: loss 3.402509
[epoch17, step2450]: loss 2.497674
[epoch17, step2451]: loss 0.853909
[epoch17, step2452]: loss 1.258826
[epoch17, step2453]: loss 8.091206
[epoch17, step2454]: loss 0.712906
[epoch17, step2455]: loss 1.661000
[epoch17, step2456]: loss 1.081285
[epoch17, step2457]: loss 1.710357
[epoch17, step2458]: loss 1.164885
[epoch17, step2459]: loss 0.578145
[epoch17, step2460]: loss 9.699999
[epoch17, step2461]: loss 1.824128
[epoch17, step2462]: loss 1.683919
[epoch17, step2463]: loss 2.248255
[epoch17, step2464]: loss 1.134015
[epoch17, step2465]: loss 0.919048
[epoch17, step2466]: loss 3.374955
[epoch17, step2467]: loss 1.093354
[epoch17, step2468]: loss 1.206287
[epoch17, step2469]: loss 3.550436
[epoch17, step2470]: loss 6.081604
[epoch17, step2471]: loss 3.314933
[epoch17, step2472]: loss 4.345818
[epoch17, step2473]: loss 7.279942
[epoch17, step2474]: loss 0.835895
[epoch17, step2475]: loss 0.763335
[epoch17, step2476]: loss 7.448865
[epoch17, step2477]: loss 4.854679
[epoch17, step2478]: loss 0.729688
[epoch17, step2479]: loss 1.075917
[epoch17, step2480]: loss 2.263818
[epoch17, step2481]: loss 1.472769
[epoch17, step2482]: loss 1.020543
[epoch17, step2483]: loss 0.557486
[epoch17, step2484]: loss 7.714964
[epoch17, step2485]: loss 38.406647
[epoch17, step2486]: loss 3.539318
[epoch17, step2487]: loss 11.526133
[epoch17, step2488]: loss 0.639969
[epoch17, step2489]: loss 1.034129
[epoch17, step2490]: loss 0.916537
[epoch17, step2491]: loss 2.358232
[epoch17, step2492]: loss 1.225295
[epoch17, step2493]: loss 2.158767
[epoch17, step2494]: loss 1.710603
[epoch17, step2495]: loss 2.478286
[epoch17, step2496]: loss 0.867634
[epoch17, step2497]: loss 0.980955
[epoch17, step2498]: loss 0.803167
[epoch17, step2499]: loss 1.914034
[epoch17, step2500]: loss 0.771701
[epoch17, step2501]: loss 2.625205
[epoch17, step2502]: loss 11.968589
[epoch17, step2503]: loss 8.868603
[epoch17, step2504]: loss 5.286235
[epoch17, step2505]: loss 2.369265
[epoch17, step2506]: loss 0.715749
[epoch17, step2507]: loss 0.730030
[epoch17, step2508]: loss 1.372768
[epoch17, step2509]: loss 6.295953
[epoch17, step2510]: loss 7.632817
[epoch17, step2511]: loss 0.965741
[epoch17, step2512]: loss 2.712696
[epoch17, step2513]: loss 7.087393
[epoch17, step2514]: loss 7.211547
[epoch17, step2515]: loss 4.627900
[epoch17, step2516]: loss 12.875538
[epoch17, step2517]: loss 12.149188
[epoch17, step2518]: loss 1.491849
[epoch17, step2519]: loss 3.144835
[epoch17, step2520]: loss 3.004650
[epoch17, step2521]: loss 1.223628
[epoch17, step2522]: loss 0.997051
[epoch17, step2523]: loss 5.736255
[epoch17, step2524]: loss 8.079823
[epoch17, step2525]: loss 5.717229
[epoch17, step2526]: loss 6.672674
[epoch17, step2527]: loss 11.659478
[epoch17, step2528]: loss 9.319859
[epoch17, step2529]: loss 5.437315
[epoch17, step2530]: loss 1.901618
[epoch17, step2531]: loss 1.667739
[epoch17, step2532]: loss 10.080937
[epoch17, step2533]: loss 8.371397
[epoch17, step2534]: loss 11.852527
[epoch17, step2535]: loss 0.689193
[epoch17, step2536]: loss 0.966667
[epoch17, step2537]: loss 7.010251
[epoch17, step2538]: loss 7.875404
[epoch17, step2539]: loss 13.086652
[epoch17, step2540]: loss 1.462201
[epoch17, step2541]: loss 0.530248
[epoch17, step2542]: loss 1.486764
[epoch17, step2543]: loss 1.197056
[epoch17, step2544]: loss 7.482358
[epoch17, step2545]: loss 7.008812
[epoch17, step2546]: loss 6.067610
[epoch17, step2547]: loss 1.038844
[epoch17, step2548]: loss 8.451918
[epoch17, step2549]: loss 1.542732
[epoch17, step2550]: loss 1.716798
[epoch17, step2551]: loss 3.967897
[epoch17, step2552]: loss 1.483121
[epoch17, step2553]: loss 1.585892
[epoch17, step2554]: loss 0.595760
[epoch17, step2555]: loss 2.548468
[epoch17, step2556]: loss 0.742748
[epoch17, step2557]: loss 7.458393
[epoch17, step2558]: loss 3.166102
[epoch17, step2559]: loss 3.736860
[epoch17, step2560]: loss 0.586636
[epoch17, step2561]: loss 6.113663
[epoch17, step2562]: loss 1.864343
[epoch17, step2563]: loss 0.690487
[epoch17, step2564]: loss 3.863959
[epoch17, step2565]: loss 2.451510
[epoch17, step2566]: loss 12.905655
[epoch17, step2567]: loss 3.564590
[epoch17, step2568]: loss 6.329327
[epoch17, step2569]: loss 0.778414
[epoch17, step2570]: loss 16.920359
[epoch17, step2571]: loss 6.692963
[epoch17, step2572]: loss 2.174825
[epoch17, step2573]: loss 1.018169
[epoch17, step2574]: loss 0.977632
[epoch17, step2575]: loss 10.239204
[epoch17, step2576]: loss 7.622332
[epoch17, step2577]: loss 0.656228
[epoch17, step2578]: loss 3.588148
[epoch17, step2579]: loss 0.603599
[epoch17, step2580]: loss 0.443544
[epoch17, step2581]: loss 0.936444
[epoch17, step2582]: loss 8.020457
[epoch17, step2583]: loss 7.386240
[epoch17, step2584]: loss 9.028132
[epoch17, step2585]: loss 14.908650
[epoch17, step2586]: loss 2.275782
[epoch17, step2587]: loss 2.261238
[epoch17, step2588]: loss 5.309859
[epoch17, step2589]: loss 3.257637
[epoch17, step2590]: loss 1.304171
[epoch17, step2591]: loss 2.243740
[epoch17, step2592]: loss 0.686937
[epoch17, step2593]: loss 5.578872
[epoch17, step2594]: loss 1.173708
[epoch17, step2595]: loss 3.916399
[epoch17, step2596]: loss 1.744596
[epoch17, step2597]: loss 4.664118
[epoch17, step2598]: loss 1.200006
[epoch17, step2599]: loss 8.916854
[epoch17, step2600]: loss 2.100253
[epoch17, step2601]: loss 0.557459
[epoch17, step2602]: loss 5.821116
[epoch17, step2603]: loss 6.131001
[epoch17, step2604]: loss 6.531715
[epoch17, step2605]: loss 1.018023
[epoch17, step2606]: loss 1.388532
[epoch17, step2607]: loss 7.909275
[epoch17, step2608]: loss 0.992415
[epoch17, step2609]: loss 11.043647
[epoch17, step2610]: loss 1.669472
[epoch17, step2611]: loss 0.993886
[epoch17, step2612]: loss 1.201001
[epoch17, step2613]: loss 1.649780
[epoch17, step2614]: loss 1.006692
[epoch17, step2615]: loss 0.809677
[epoch17, step2616]: loss 1.521902
[epoch17, step2617]: loss 0.700000
[epoch17, step2618]: loss 0.594094
[epoch17, step2619]: loss 2.382690
[epoch17, step2620]: loss 13.240458
[epoch17, step2621]: loss 0.803394
[epoch17, step2622]: loss 4.852698
[epoch17, step2623]: loss 1.489710
[epoch17, step2624]: loss 0.634116
[epoch17, step2625]: loss 3.096958
[epoch17, step2626]: loss 0.866677
[epoch17, step2627]: loss 0.651090
[epoch17, step2628]: loss 1.028105
[epoch17, step2629]: loss 4.034756
[epoch17, step2630]: loss 1.463974
[epoch17, step2631]: loss 6.831592
[epoch17, step2632]: loss 0.877301
[epoch17, step2633]: loss 10.932945
[epoch17, step2634]: loss 1.254455
[epoch17, step2635]: loss 0.797729
[epoch17, step2636]: loss 13.841561
[epoch17, step2637]: loss 7.172315
[epoch17, step2638]: loss 1.153773
[epoch17, step2639]: loss 13.359836
[epoch17, step2640]: loss 1.968270
[epoch17, step2641]: loss 0.842545
[epoch17, step2642]: loss 4.226412
[epoch17, step2643]: loss 9.177904
[epoch17, step2644]: loss 1.066144
[epoch17, step2645]: loss 2.020827
[epoch17, step2646]: loss 0.720092
[epoch17, step2647]: loss 1.052039
[epoch17, step2648]: loss 0.546546
[epoch17, step2649]: loss 0.691661
[epoch17, step2650]: loss 4.143328
[epoch17, step2651]: loss 1.035828
[epoch17, step2652]: loss 0.848021
[epoch17, step2653]: loss 19.315348
[epoch17, step2654]: loss 6.377104
[epoch17, step2655]: loss 0.741517
[epoch17, step2656]: loss 0.908130
[epoch17, step2657]: loss 2.270049
[epoch17, step2658]: loss 1.619739
[epoch17, step2659]: loss 0.909606
[epoch17, step2660]: loss 0.893731
[epoch17, step2661]: loss 1.168429
[epoch17, step2662]: loss 4.971772
[epoch17, step2663]: loss 11.361549
[epoch17, step2664]: loss 1.109262
[epoch17, step2665]: loss 0.854207
[epoch17, step2666]: loss 0.791416
[epoch17, step2667]: loss 0.725353
[epoch17, step2668]: loss 0.584964
[epoch17, step2669]: loss 11.928852
[epoch17, step2670]: loss 0.822207
[epoch17, step2671]: loss 1.415157
[epoch17, step2672]: loss 10.700505
[epoch17, step2673]: loss 0.667419
[epoch17, step2674]: loss 5.429875
[epoch17, step2675]: loss 2.614621
[epoch17, step2676]: loss 1.015795
[epoch17, step2677]: loss 7.240896
[epoch17, step2678]: loss 13.968320
[epoch17, step2679]: loss 12.492821
[epoch17, step2680]: loss 4.327673
[epoch17, step2681]: loss 0.815418
[epoch17, step2682]: loss 0.639889
[epoch17, step2683]: loss 11.632451
[epoch17, step2684]: loss 0.853293
[epoch17, step2685]: loss 2.667562
[epoch17, step2686]: loss 1.131435
[epoch17, step2687]: loss 2.124358
[epoch17, step2688]: loss 2.563952
[epoch17, step2689]: loss 1.434060
[epoch17, step2690]: loss 3.482525
[epoch17, step2691]: loss 1.081427
[epoch17, step2692]: loss 1.203476
[epoch17, step2693]: loss 0.492659
[epoch17, step2694]: loss 1.189980
[epoch17, step2695]: loss 3.249312
[epoch17, step2696]: loss 2.456004
[epoch17, step2697]: loss 1.574046
[epoch17, step2698]: loss 0.919424
[epoch17, step2699]: loss 1.612238
[epoch17, step2700]: loss 0.851989
[epoch17, step2701]: loss 0.757855
[epoch17, step2702]: loss 0.453223
[epoch17, step2703]: loss 8.542365
[epoch17, step2704]: loss 4.811032
[epoch17, step2705]: loss 1.501727
[epoch17, step2706]: loss 3.191681
[epoch17, step2707]: loss 19.122375
[epoch17, step2708]: loss 7.115917
[epoch17, step2709]: loss 0.588471
[epoch17, step2710]: loss 7.842935
[epoch17, step2711]: loss 0.576761
[epoch17, step2712]: loss 0.608603
[epoch17, step2713]: loss 0.688499
[epoch17, step2714]: loss 1.074908
[epoch17, step2715]: loss 5.794278
[epoch17, step2716]: loss 0.699147
[epoch17, step2717]: loss 0.988751
[epoch17, step2718]: loss 4.771031
[epoch17, step2719]: loss 1.837592
[epoch17, step2720]: loss 6.582172
[epoch17, step2721]: loss 1.347057
[epoch17, step2722]: loss 0.581957
[epoch17, step2723]: loss 2.175515
[epoch17, step2724]: loss 0.819247
[epoch17, step2725]: loss 2.020135
[epoch17, step2726]: loss 12.501225
[epoch17, step2727]: loss 12.860579
[epoch17, step2728]: loss 1.142471
[epoch17, step2729]: loss 1.146859
[epoch17, step2730]: loss 0.965743
[epoch17, step2731]: loss 11.125072
[epoch17, step2732]: loss 1.161415
[epoch17, step2733]: loss 4.644526
[epoch17, step2734]: loss 0.640822
[epoch17, step2735]: loss 4.630356
[epoch17, step2736]: loss 11.642767
[epoch17, step2737]: loss 1.474596
[epoch17, step2738]: loss 8.992921
[epoch17, step2739]: loss 0.840973
[epoch17, step2740]: loss 1.282092
[epoch17, step2741]: loss 15.901229
[epoch17, step2742]: loss 0.865265
[epoch17, step2743]: loss 1.706518
[epoch17, step2744]: loss 0.985495
[epoch17, step2745]: loss 0.684811
[epoch17, step2746]: loss 3.332083
[epoch17, step2747]: loss 6.929967
[epoch17, step2748]: loss 1.397524
[epoch17, step2749]: loss 2.000437
[epoch17, step2750]: loss 18.364471
[epoch17, step2751]: loss 9.644419
[epoch17, step2752]: loss 1.418544
[epoch17, step2753]: loss 0.541258
[epoch17, step2754]: loss 0.604830
[epoch17, step2755]: loss 0.859615
[epoch17, step2756]: loss 6.088258
[epoch17, step2757]: loss 1.090808
[epoch17, step2758]: loss 0.814632
[epoch17, step2759]: loss 2.056427
[epoch17, step2760]: loss 1.105026
[epoch17, step2761]: loss 0.591287
[epoch17, step2762]: loss 5.852924
[epoch17, step2763]: loss 9.448590
[epoch17, step2764]: loss 1.282447
[epoch17, step2765]: loss 7.313261
[epoch17, step2766]: loss 0.742357
[epoch17, step2767]: loss 8.764064
[epoch17, step2768]: loss 1.414046
[epoch17, step2769]: loss 9.661067
[epoch17, step2770]: loss 8.256111
[epoch17, step2771]: loss 16.204790
[epoch17, step2772]: loss 2.214396
[epoch17, step2773]: loss 14.384023
[epoch17, step2774]: loss 1.283179
[epoch17, step2775]: loss 9.577878
[epoch17, step2776]: loss 5.922284
[epoch17, step2777]: loss 0.642799
[epoch17, step2778]: loss 6.036056
[epoch17, step2779]: loss 7.718926
[epoch17, step2780]: loss 2.369545
[epoch17, step2781]: loss 6.796139
[epoch17, step2782]: loss 0.561313
[epoch17, step2783]: loss 0.878012
[epoch17, step2784]: loss 1.006546
[epoch17, step2785]: loss 1.772836
[epoch17, step2786]: loss 6.215816
[epoch17, step2787]: loss 0.799978
[epoch17, step2788]: loss 1.960108
[epoch17, step2789]: loss 5.813728
[epoch17, step2790]: loss 2.848644
[epoch17, step2791]: loss 2.067454
[epoch17, step2792]: loss 16.537643
[epoch17, step2793]: loss 1.374462
[epoch17, step2794]: loss 0.423466
[epoch17, step2795]: loss 2.360178
[epoch17, step2796]: loss 1.856246
[epoch17, step2797]: loss 1.518595
[epoch17, step2798]: loss 0.748963
[epoch17, step2799]: loss 1.288311
[epoch17, step2800]: loss 0.649659
[epoch17, step2801]: loss 0.613759
[epoch17, step2802]: loss 18.018436
[epoch17, step2803]: loss 8.245668
[epoch17, step2804]: loss 0.602124
[epoch17, step2805]: loss 5.481158
[epoch17, step2806]: loss 1.221996
[epoch17, step2807]: loss 1.336934
[epoch17, step2808]: loss 2.945732
[epoch17, step2809]: loss 0.730791
[epoch17, step2810]: loss 0.636064
[epoch17, step2811]: loss 1.492497
[epoch17, step2812]: loss 2.093510
[epoch17, step2813]: loss 0.575575
[epoch17, step2814]: loss 5.676798
[epoch17, step2815]: loss 12.622595
[epoch17, step2816]: loss 15.281203
[epoch17, step2817]: loss 0.985958
[epoch17, step2818]: loss 10.869967
[epoch17, step2819]: loss 1.280378
[epoch17, step2820]: loss 1.384102
[epoch17, step2821]: loss 8.660189
[epoch17, step2822]: loss 1.781734
[epoch17, step2823]: loss 7.240086
[epoch17, step2824]: loss 2.536413
[epoch17, step2825]: loss 10.833557
[epoch17, step2826]: loss 0.753796
[epoch17, step2827]: loss 12.611801
[epoch17, step2828]: loss 0.503804
[epoch17, step2829]: loss 1.084541
[epoch17, step2830]: loss 3.336791
[epoch17, step2831]: loss 1.505089
[epoch17, step2832]: loss 7.022239
[epoch17, step2833]: loss 0.914427
[epoch17, step2834]: loss 0.801912
[epoch17, step2835]: loss 7.850392
[epoch17, step2836]: loss 0.512686
[epoch17, step2837]: loss 2.895278
[epoch17, step2838]: loss 14.116630
[epoch17, step2839]: loss 0.736359
[epoch17, step2840]: loss 8.567369
[epoch17, step2841]: loss 0.726680
[epoch17, step2842]: loss 2.347309
[epoch17, step2843]: loss 6.548467
[epoch17, step2844]: loss 2.566751
[epoch17, step2845]: loss 0.814037
[epoch17, step2846]: loss 8.569384
[epoch17, step2847]: loss 0.710600
[epoch17, step2848]: loss 0.873299
[epoch17, step2849]: loss 8.887311
[epoch17, step2850]: loss 6.397922
[epoch17, step2851]: loss 2.328040
[epoch17, step2852]: loss 1.641571
[epoch17, step2853]: loss 1.708174
[epoch17, step2854]: loss 1.859814
[epoch17, step2855]: loss 1.885318
[epoch17, step2856]: loss 0.934722
[epoch17, step2857]: loss 5.954654
[epoch17, step2858]: loss 1.513691
[epoch17, step2859]: loss 0.598815
[epoch17, step2860]: loss 1.015337
[epoch17, step2861]: loss 6.450861
[epoch17, step2862]: loss 3.905607
[epoch17, step2863]: loss 1.372682
[epoch17, step2864]: loss 1.591977
[epoch17, step2865]: loss 2.239153
[epoch17, step2866]: loss 1.631848
[epoch17, step2867]: loss 0.747411
[epoch17, step2868]: loss 15.477406
[epoch17, step2869]: loss 1.443204
[epoch17, step2870]: loss 6.688834
[epoch17, step2871]: loss 1.783214
[epoch17, step2872]: loss 9.324258
[epoch17, step2873]: loss 0.952227
[epoch17, step2874]: loss 1.835908
[epoch17, step2875]: loss 2.354070
[epoch17, step2876]: loss 4.398616
[epoch17, step2877]: loss 0.593560
[epoch17, step2878]: loss 1.252679
[epoch17, step2879]: loss 1.878727
[epoch17, step2880]: loss 2.119032
[epoch17, step2881]: loss 0.894768
[epoch17, step2882]: loss 10.022738
[epoch17, step2883]: loss 0.984950
[epoch17, step2884]: loss 0.963095
[epoch17, step2885]: loss 1.628104
[epoch17, step2886]: loss 0.689300
[epoch17, step2887]: loss 6.526179
[epoch17, step2888]: loss 1.356336
[epoch17, step2889]: loss 0.867210
[epoch17, step2890]: loss 0.652575
[epoch17, step2891]: loss 0.491957
[epoch17, step2892]: loss 5.789839
[epoch17, step2893]: loss 5.326601
[epoch17, step2894]: loss 15.972948
[epoch17, step2895]: loss 9.722775
[epoch17, step2896]: loss 0.681210
[epoch17, step2897]: loss 12.557099
[epoch17, step2898]: loss 9.667557
[epoch17, step2899]: loss 4.322124
[epoch17, step2900]: loss 0.663872
[epoch17, step2901]: loss 0.611626
[epoch17, step2902]: loss 3.502041
[epoch17, step2903]: loss 2.680938
[epoch17, step2904]: loss 2.549650
[epoch17, step2905]: loss 0.771292
[epoch17, step2906]: loss 1.374957
[epoch17, step2907]: loss 30.739439
[epoch17, step2908]: loss 1.288741
[epoch17, step2909]: loss 1.701222
[epoch17, step2910]: loss 13.862857
[epoch17, step2911]: loss 14.659847
[epoch17, step2912]: loss 0.976124
[epoch17, step2913]: loss 0.707278
[epoch17, step2914]: loss 2.148646
[epoch17, step2915]: loss 7.284916
[epoch17, step2916]: loss 2.626619
[epoch17, step2917]: loss 0.693259
[epoch17, step2918]: loss 1.470359
[epoch17, step2919]: loss 1.063676
[epoch17, step2920]: loss 1.378762
[epoch17, step2921]: loss 2.020426
[epoch17, step2922]: loss 4.607607
[epoch17, step2923]: loss 2.232272
[epoch17, step2924]: loss 0.664405
[epoch17, step2925]: loss 3.899656
[epoch17, step2926]: loss 0.629827
[epoch17, step2927]: loss 2.137104
[epoch17, step2928]: loss 10.318174
[epoch17, step2929]: loss 1.313487
[epoch17, step2930]: loss 12.865084
[epoch17, step2931]: loss 14.636411
[epoch17, step2932]: loss 2.875695
[epoch17, step2933]: loss 0.851165
[epoch17, step2934]: loss 2.909682
[epoch17, step2935]: loss 0.580382
[epoch17, step2936]: loss 2.691772
[epoch17, step2937]: loss 0.854133
[epoch17, step2938]: loss 0.793348
[epoch17, step2939]: loss 1.704401
[epoch17, step2940]: loss 9.643486
[epoch17, step2941]: loss 0.616504
[epoch17, step2942]: loss 0.958131
[epoch17, step2943]: loss 1.580601
[epoch17, step2944]: loss 0.706809
[epoch17, step2945]: loss 2.271542
[epoch17, step2946]: loss 0.935206
[epoch17, step2947]: loss 11.855901
[epoch17, step2948]: loss 0.940520
[epoch17, step2949]: loss 1.249487
[epoch17, step2950]: loss 0.614957
[epoch17, step2951]: loss 5.672055
[epoch17, step2952]: loss 6.063096
[epoch17, step2953]: loss 10.939687
[epoch17, step2954]: loss 12.417388
[epoch17, step2955]: loss 9.670078
[epoch17, step2956]: loss 1.536266
[epoch17, step2957]: loss 2.651314
[epoch17, step2958]: loss 6.626370
[epoch17, step2959]: loss 0.591779
[epoch17, step2960]: loss 1.816839
[epoch17, step2961]: loss 4.160900
[epoch17, step2962]: loss 0.790414
[epoch17, step2963]: loss 3.059517
[epoch17, step2964]: loss 20.835495
[epoch17, step2965]: loss 1.296079
[epoch17, step2966]: loss 5.809586
[epoch17, step2967]: loss 0.805909
[epoch17, step2968]: loss 15.303595
[epoch17, step2969]: loss 2.582025
[epoch17, step2970]: loss 5.713508
[epoch17, step2971]: loss 1.908329
[epoch17, step2972]: loss 11.969798
[epoch17, step2973]: loss 19.497114
[epoch17, step2974]: loss 2.656749
[epoch17, step2975]: loss 1.827494
[epoch17, step2976]: loss 1.504621
[epoch17, step2977]: loss 9.971655
[epoch17, step2978]: loss 0.992539
[epoch17, step2979]: loss 2.332446
[epoch17, step2980]: loss 1.057095
[epoch17, step2981]: loss 6.665312
[epoch17, step2982]: loss 8.993443
[epoch17, step2983]: loss 0.884880
[epoch17, step2984]: loss 11.006858
[epoch17, step2985]: loss 12.978347
[epoch17, step2986]: loss 6.932310
[epoch17, step2987]: loss 1.477412
[epoch17, step2988]: loss 0.931958
[epoch17, step2989]: loss 0.868096
[epoch17, step2990]: loss 1.612895
[epoch17, step2991]: loss 1.210221
[epoch17, step2992]: loss 3.150206
[epoch17, step2993]: loss 1.415222
[epoch17, step2994]: loss 1.015127
[epoch17, step2995]: loss 2.387873
[epoch17, step2996]: loss 1.328906
[epoch17, step2997]: loss 14.781747
[epoch17, step2998]: loss 0.884005
[epoch17, step2999]: loss 0.803162
[epoch17, step3000]: loss 0.839633
[epoch17, step3001]: loss 8.924766
[epoch17, step3002]: loss 0.645735
[epoch17, step3003]: loss 11.994448
[epoch17, step3004]: loss 1.452998
[epoch17, step3005]: loss 11.079232
[epoch17, step3006]: loss 0.794486
[epoch17, step3007]: loss 1.223684
[epoch17, step3008]: loss 2.297840
[epoch17, step3009]: loss 0.903073
[epoch17, step3010]: loss 3.200778
[epoch17, step3011]: loss 1.167777
[epoch17, step3012]: loss 17.063354
[epoch17, step3013]: loss 0.828890
[epoch17, step3014]: loss 0.626722
[epoch17, step3015]: loss 0.740300
[epoch17, step3016]: loss 1.683433
[epoch17, step3017]: loss 0.445881
[epoch17, step3018]: loss 7.646486
[epoch17, step3019]: loss 8.577571
[epoch17, step3020]: loss 1.030499
[epoch17, step3021]: loss 0.477747
[epoch17, step3022]: loss 0.647218
[epoch17, step3023]: loss 1.819929
[epoch17, step3024]: loss 2.636564
[epoch17, step3025]: loss 0.861362
[epoch17, step3026]: loss 1.930924
[epoch17, step3027]: loss 0.721771
[epoch17, step3028]: loss 21.258675
[epoch17, step3029]: loss 5.392161
[epoch17, step3030]: loss 1.480305
[epoch17, step3031]: loss 2.500812
[epoch17, step3032]: loss 1.837440
[epoch17, step3033]: loss 11.245839
[epoch17, step3034]: loss 1.040349
[epoch17, step3035]: loss 6.404737
[epoch17, step3036]: loss 1.743867
[epoch17, step3037]: loss 0.871438
[epoch17, step3038]: loss 15.463478
[epoch17, step3039]: loss 1.702986
[epoch17, step3040]: loss 7.397378
[epoch17, step3041]: loss 1.021867
[epoch17, step3042]: loss 0.791250
[epoch17, step3043]: loss 8.202689
[epoch17, step3044]: loss 11.245157
[epoch17, step3045]: loss 3.863033
[epoch17, step3046]: loss 21.898153
[epoch17, step3047]: loss 0.829089
[epoch17, step3048]: loss 13.181415
[epoch17, step3049]: loss 0.708082
[epoch17, step3050]: loss 8.396821
[epoch17, step3051]: loss 11.789932
[epoch17, step3052]: loss 14.467755
[epoch17, step3053]: loss 1.047398
[epoch17, step3054]: loss 2.103713
[epoch17, step3055]: loss 0.725603
[epoch17, step3056]: loss 8.830392
[epoch17, step3057]: loss 0.980704
[epoch17, step3058]: loss 11.425245
[epoch17, step3059]: loss 2.656920
[epoch17, step3060]: loss 2.791879
[epoch17, step3061]: loss 1.021684
[epoch17, step3062]: loss 11.777249
[epoch17, step3063]: loss 2.471540
[epoch17, step3064]: loss 1.037084
[epoch17, step3065]: loss 9.224931
[epoch17, step3066]: loss 1.075125
[epoch17, step3067]: loss 3.706131
[epoch17, step3068]: loss 0.608316
[epoch17, step3069]: loss 7.802322
[epoch17, step3070]: loss 0.878880
[epoch17, step3071]: loss 21.059441
[epoch17, step3072]: loss 2.055214
[epoch17, step3073]: loss 7.200371
[epoch17, step3074]: loss 3.074121
[epoch17, step3075]: loss 0.544953
[epoch17, step3076]: loss 0.726630

[epoch17]: avg loss 0.726630

[epoch18, step1]: loss 1.009663
[epoch18, step2]: loss 0.715139
[epoch18, step3]: loss 1.259752
[epoch18, step4]: loss 1.518845
[epoch18, step5]: loss 8.600341
[epoch18, step6]: loss 0.845523
[epoch18, step7]: loss 7.622885
[epoch18, step8]: loss 8.991450
[epoch18, step9]: loss 0.512865
[epoch18, step10]: loss 0.626788
[epoch18, step11]: loss 1.287942
[epoch18, step12]: loss 5.656372
[epoch18, step13]: loss 3.649453
[epoch18, step14]: loss 0.842546
[epoch18, step15]: loss 11.621363
[epoch18, step16]: loss 0.973850
[epoch18, step17]: loss 1.037773
[epoch18, step18]: loss 0.503422
[epoch18, step19]: loss 2.309128
[epoch18, step20]: loss 15.545510
[epoch18, step21]: loss 0.685785
[epoch18, step22]: loss 11.622190
[epoch18, step23]: loss 1.034982
[epoch18, step24]: loss 9.722461
[epoch18, step25]: loss 1.066900
[epoch18, step26]: loss 0.696899
[epoch18, step27]: loss 2.760559
[epoch18, step28]: loss 1.660009
[epoch18, step29]: loss 14.405032
[epoch18, step30]: loss 0.687605
[epoch18, step31]: loss 0.819211
[epoch18, step32]: loss 0.681222
[epoch18, step33]: loss 0.986725
[epoch18, step34]: loss 0.736168
[epoch18, step35]: loss 8.627733
[epoch18, step36]: loss 3.477313
[epoch18, step37]: loss 1.258150
[epoch18, step38]: loss 1.779700
[epoch18, step39]: loss 1.465710
[epoch18, step40]: loss 1.251774
[epoch18, step41]: loss 1.229752
[epoch18, step42]: loss 0.837548
[epoch18, step43]: loss 1.089315
[epoch18, step44]: loss 0.974941
[epoch18, step45]: loss 5.976482
[epoch18, step46]: loss 9.273057
[epoch18, step47]: loss 7.091316
[epoch18, step48]: loss 5.768093
[epoch18, step49]: loss 1.523697
[epoch18, step50]: loss 2.769106
[epoch18, step51]: loss 8.825807
[epoch18, step52]: loss 1.108920
[epoch18, step53]: loss 10.081441
[epoch18, step54]: loss 1.387150
[epoch18, step55]: loss 7.812072
[epoch18, step56]: loss 0.695734
[epoch18, step57]: loss 1.754085
[epoch18, step58]: loss 6.788249
[epoch18, step59]: loss 1.927648
[epoch18, step60]: loss 7.697102
[epoch18, step61]: loss 10.822446
[epoch18, step62]: loss 5.761513
[epoch18, step63]: loss 6.897741
[epoch18, step64]: loss 0.980001
[epoch18, step65]: loss 0.931100
[epoch18, step66]: loss 6.378685
[epoch18, step67]: loss 1.323490
[epoch18, step68]: loss 1.767262
[epoch18, step69]: loss 6.151662
[epoch18, step70]: loss 3.780475
[epoch18, step71]: loss 18.259083
[epoch18, step72]: loss 8.748784
[epoch18, step73]: loss 6.013546
[epoch18, step74]: loss 0.672805
[epoch18, step75]: loss 0.799459
[epoch18, step76]: loss 1.787637
[epoch18, step77]: loss 1.338889
[epoch18, step78]: loss 2.645839
[epoch18, step79]: loss 1.045604
[epoch18, step80]: loss 1.908594
[epoch18, step81]: loss 13.754827
[epoch18, step82]: loss 0.990133
[epoch18, step83]: loss 2.217195
[epoch18, step84]: loss 9.516607
[epoch18, step85]: loss 1.034694
[epoch18, step86]: loss 1.074131
[epoch18, step87]: loss 1.665962
[epoch18, step88]: loss 0.874564
[epoch18, step89]: loss 0.688753
[epoch18, step90]: loss 5.558010
[epoch18, step91]: loss 2.092216
[epoch18, step92]: loss 11.237373
[epoch18, step93]: loss 11.842287
[epoch18, step94]: loss 2.215576
[epoch18, step95]: loss 2.581433
[epoch18, step96]: loss 0.762188
[epoch18, step97]: loss 12.590937
[epoch18, step98]: loss 0.923183
[epoch18, step99]: loss 10.989557
[epoch18, step100]: loss 1.503240
[epoch18, step101]: loss 0.700373
[epoch18, step102]: loss 0.642913
[epoch18, step103]: loss 10.373631
[epoch18, step104]: loss 0.579820
[epoch18, step105]: loss 2.606444
[epoch18, step106]: loss 1.837577
[epoch18, step107]: loss 1.583685
[epoch18, step108]: loss 2.377488
[epoch18, step109]: loss 8.499003
[epoch18, step110]: loss 6.796603
[epoch18, step111]: loss 1.603278
[epoch18, step112]: loss 1.017644
[epoch18, step113]: loss 3.270686
[epoch18, step114]: loss 0.543832
[epoch18, step115]: loss 2.945051
[epoch18, step116]: loss 9.330153
[epoch18, step117]: loss 4.649196
[epoch18, step118]: loss 1.921142
[epoch18, step119]: loss 0.469678
[epoch18, step120]: loss 1.575592
[epoch18, step121]: loss 4.096241
[epoch18, step122]: loss 12.705606
[epoch18, step123]: loss 16.800901
[epoch18, step124]: loss 0.843107
[epoch18, step125]: loss 1.605057
[epoch18, step126]: loss 0.882253
[epoch18, step127]: loss 5.598585
[epoch18, step128]: loss 7.397357
[epoch18, step129]: loss 0.811299
[epoch18, step130]: loss 11.684455
[epoch18, step131]: loss 2.388714
[epoch18, step132]: loss 12.902821
[epoch18, step133]: loss 1.100233
[epoch18, step134]: loss 1.937651
[epoch18, step135]: loss 10.861251
[epoch18, step136]: loss 1.815585
[epoch18, step137]: loss 9.595292
[epoch18, step138]: loss 0.695597
[epoch18, step139]: loss 0.891287
[epoch18, step140]: loss 1.711655
[epoch18, step141]: loss 0.658584
[epoch18, step142]: loss 6.412320
[epoch18, step143]: loss 1.607083
[epoch18, step144]: loss 1.733715
[epoch18, step145]: loss 0.935607
[epoch18, step146]: loss 3.539719
[epoch18, step147]: loss 0.645589
[epoch18, step148]: loss 1.228900
[epoch18, step149]: loss 0.606876
[epoch18, step150]: loss 1.834417
[epoch18, step151]: loss 11.965313
[epoch18, step152]: loss 0.998600
[epoch18, step153]: loss 1.745067
[epoch18, step154]: loss 0.860552
[epoch18, step155]: loss 6.807308
[epoch18, step156]: loss 9.667561
[epoch18, step157]: loss 1.208233
[epoch18, step158]: loss 0.954144
[epoch18, step159]: loss 8.247640
[epoch18, step160]: loss 0.698152
[epoch18, step161]: loss 1.998569
[epoch18, step162]: loss 1.961190
[epoch18, step163]: loss 1.797694
[epoch18, step164]: loss 0.919713
[epoch18, step165]: loss 0.809536
[epoch18, step166]: loss 0.760068
[epoch18, step167]: loss 13.721940
[epoch18, step168]: loss 2.544594
[epoch18, step169]: loss 5.462356
[epoch18, step170]: loss 1.850803
[epoch18, step171]: loss 15.390095
[epoch18, step172]: loss 3.498609
[epoch18, step173]: loss 3.043097
[epoch18, step174]: loss 4.244870
[epoch18, step175]: loss 0.793128
[epoch18, step176]: loss 0.482705
[epoch18, step177]: loss 2.497261
[epoch18, step178]: loss 16.440395
[epoch18, step179]: loss 1.941780
[epoch18, step180]: loss 2.030113
[epoch18, step181]: loss 3.166972
[epoch18, step182]: loss 1.704952
[epoch18, step183]: loss 11.824273
[epoch18, step184]: loss 0.682380
[epoch18, step185]: loss 1.438311
[epoch18, step186]: loss 0.986353
[epoch18, step187]: loss 1.365726
[epoch18, step188]: loss 0.613304
[epoch18, step189]: loss 1.180466
[epoch18, step190]: loss 14.039802
[epoch18, step191]: loss 1.073738
[epoch18, step192]: loss 0.816021
[epoch18, step193]: loss 0.595241
[epoch18, step194]: loss 13.901960
[epoch18, step195]: loss 1.155614
[epoch18, step196]: loss 7.488675
[epoch18, step197]: loss 6.799898
[epoch18, step198]: loss 7.426347
[epoch18, step199]: loss 2.211048
[epoch18, step200]: loss 5.638744
[epoch18, step201]: loss 1.135386
[epoch18, step202]: loss 6.974085
[epoch18, step203]: loss 1.226845
[epoch18, step204]: loss 2.584890
[epoch18, step205]: loss 7.239554
[epoch18, step206]: loss 2.387173
[epoch18, step207]: loss 0.825817
[epoch18, step208]: loss 1.710954
[epoch18, step209]: loss 1.288822
[epoch18, step210]: loss 1.164752
[epoch18, step211]: loss 6.206443
[epoch18, step212]: loss 2.579407
[epoch18, step213]: loss 10.535945
[epoch18, step214]: loss 1.558418
[epoch18, step215]: loss 0.643420
[epoch18, step216]: loss 1.146280
[epoch18, step217]: loss 2.524193
[epoch18, step218]: loss 2.772880
[epoch18, step219]: loss 10.665817
[epoch18, step220]: loss 1.326977
[epoch18, step221]: loss 0.762350
[epoch18, step222]: loss 0.457034
[epoch18, step223]: loss 1.225454
[epoch18, step224]: loss 6.741109
[epoch18, step225]: loss 1.199799
[epoch18, step226]: loss 1.352789
[epoch18, step227]: loss 2.562510
[epoch18, step228]: loss 0.811633
[epoch18, step229]: loss 8.593290
[epoch18, step230]: loss 2.160288
[epoch18, step231]: loss 4.013752
[epoch18, step232]: loss 1.696825
[epoch18, step233]: loss 1.818630
[epoch18, step234]: loss 6.585529
[epoch18, step235]: loss 1.144766
[epoch18, step236]: loss 1.775949
[epoch18, step237]: loss 7.053320
[epoch18, step238]: loss 0.796508
[epoch18, step239]: loss 1.732343
[epoch18, step240]: loss 1.426190
[epoch18, step241]: loss 0.692490
[epoch18, step242]: loss 7.506445
[epoch18, step243]: loss 0.918511
[epoch18, step244]: loss 0.847197
[epoch18, step245]: loss 1.243191
[epoch18, step246]: loss 1.043722
[epoch18, step247]: loss 11.064532
[epoch18, step248]: loss 1.061750
[epoch18, step249]: loss 6.976807
[epoch18, step250]: loss 1.755089
[epoch18, step251]: loss 1.487276
[epoch18, step252]: loss 6.121726
[epoch18, step253]: loss 0.616119
[epoch18, step254]: loss 0.586235
[epoch18, step255]: loss 1.434254
[epoch18, step256]: loss 1.491203
[epoch18, step257]: loss 1.947275
[epoch18, step258]: loss 0.622382
[epoch18, step259]: loss 1.684970
[epoch18, step260]: loss 5.994316
[epoch18, step261]: loss 1.608089
[epoch18, step262]: loss 0.514449
[epoch18, step263]: loss 0.810777
[epoch18, step264]: loss 5.887594
[epoch18, step265]: loss 8.427492
[epoch18, step266]: loss 13.638832
[epoch18, step267]: loss 2.088186
[epoch18, step268]: loss 1.427163
[epoch18, step269]: loss 20.660061
[epoch18, step270]: loss 0.535818
[epoch18, step271]: loss 1.439628
[epoch18, step272]: loss 0.778217
[epoch18, step273]: loss 0.870513
[epoch18, step274]: loss 2.853279
[epoch18, step275]: loss 0.721958
[epoch18, step276]: loss 1.587987
[epoch18, step277]: loss 1.302404
[epoch18, step278]: loss 2.133992
[epoch18, step279]: loss 1.269118
[epoch18, step280]: loss 1.412045
[epoch18, step281]: loss 12.711166
[epoch18, step282]: loss 0.791589
[epoch18, step283]: loss 1.965898
[epoch18, step284]: loss 5.582998
[epoch18, step285]: loss 1.142247
[epoch18, step286]: loss 0.828385
[epoch18, step287]: loss 2.093001
[epoch18, step288]: loss 0.563509
[epoch18, step289]: loss 0.969388
[epoch18, step290]: loss 0.541981
[epoch18, step291]: loss 11.051743
[epoch18, step292]: loss 0.917672
[epoch18, step293]: loss 1.362092
[epoch18, step294]: loss 0.685942
[epoch18, step295]: loss 2.268735
[epoch18, step296]: loss 13.675237
[epoch18, step297]: loss 10.128063
[epoch18, step298]: loss 1.049324
[epoch18, step299]: loss 1.011928
[epoch18, step300]: loss 10.968019
[epoch18, step301]: loss 12.704577
[epoch18, step302]: loss 14.342500
[epoch18, step303]: loss 2.444410
[epoch18, step304]: loss 1.073833
[epoch18, step305]: loss 2.454277
[epoch18, step306]: loss 0.788004
[epoch18, step307]: loss 1.335872
[epoch18, step308]: loss 0.692907
[epoch18, step309]: loss 0.994655
[epoch18, step310]: loss 0.971328
[epoch18, step311]: loss 5.726175
[epoch18, step312]: loss 1.365401
[epoch18, step313]: loss 1.084512
[epoch18, step314]: loss 9.480447
[epoch18, step315]: loss 1.182267
[epoch18, step316]: loss 1.699103
[epoch18, step317]: loss 4.059212
[epoch18, step318]: loss 7.001919
[epoch18, step319]: loss 0.402849
[epoch18, step320]: loss 0.680347
[epoch18, step321]: loss 1.007587
[epoch18, step322]: loss 0.944627
[epoch18, step323]: loss 2.831789
[epoch18, step324]: loss 12.229339
[epoch18, step325]: loss 7.698597
[epoch18, step326]: loss 3.326746
[epoch18, step327]: loss 12.014587
[epoch18, step328]: loss 0.878967
[epoch18, step329]: loss 0.946825
[epoch18, step330]: loss 1.255916
[epoch18, step331]: loss 1.543385
[epoch18, step332]: loss 4.807200
[epoch18, step333]: loss 2.630447
[epoch18, step334]: loss 0.817710
[epoch18, step335]: loss 10.079623
[epoch18, step336]: loss 2.657837
[epoch18, step337]: loss 2.006738
[epoch18, step338]: loss 0.731740
[epoch18, step339]: loss 9.696633
[epoch18, step340]: loss 12.173903
[epoch18, step341]: loss 0.630922
[epoch18, step342]: loss 0.654894
[epoch18, step343]: loss 0.756395
[epoch18, step344]: loss 0.800877
[epoch18, step345]: loss 3.221803
[epoch18, step346]: loss 5.632830
[epoch18, step347]: loss 0.618151
[epoch18, step348]: loss 7.671391
[epoch18, step349]: loss 1.769616
[epoch18, step350]: loss 0.962646
[epoch18, step351]: loss 2.025969
[epoch18, step352]: loss 1.497876
[epoch18, step353]: loss 12.168088
[epoch18, step354]: loss 1.906959
[epoch18, step355]: loss 10.688412
[epoch18, step356]: loss 0.969479
[epoch18, step357]: loss 7.302131
[epoch18, step358]: loss 2.614465
[epoch18, step359]: loss 1.000761
[epoch18, step360]: loss 10.113518
[epoch18, step361]: loss 0.762641
[epoch18, step362]: loss 0.886333
[epoch18, step363]: loss 1.311849
[epoch18, step364]: loss 2.072493
[epoch18, step365]: loss 9.423976
[epoch18, step366]: loss 5.770064
[epoch18, step367]: loss 3.028406
[epoch18, step368]: loss 5.026036
[epoch18, step369]: loss 0.720252
[epoch18, step370]: loss 3.424986
[epoch18, step371]: loss 1.014920
[epoch18, step372]: loss 8.541281
[epoch18, step373]: loss 19.524019
[epoch18, step374]: loss 0.725153
[epoch18, step375]: loss 3.554077
[epoch18, step376]: loss 0.914479
[epoch18, step377]: loss 2.130359
[epoch18, step378]: loss 5.838097
[epoch18, step379]: loss 1.075533
[epoch18, step380]: loss 0.891941
[epoch18, step381]: loss 2.530915
[epoch18, step382]: loss 2.275098
[epoch18, step383]: loss 1.330088
[epoch18, step384]: loss 4.488910
[epoch18, step385]: loss 0.800204
[epoch18, step386]: loss 14.370264
[epoch18, step387]: loss 10.165399
[epoch18, step388]: loss 7.842070
[epoch18, step389]: loss 0.731398
[epoch18, step390]: loss 0.800273
[epoch18, step391]: loss 0.557868
[epoch18, step392]: loss 2.532467
[epoch18, step393]: loss 3.018067
[epoch18, step394]: loss 0.593881
[epoch18, step395]: loss 4.287220
[epoch18, step396]: loss 1.947936
[epoch18, step397]: loss 5.593858
[epoch18, step398]: loss 6.098911
[epoch18, step399]: loss 0.817237
[epoch18, step400]: loss 8.620819
[epoch18, step401]: loss 0.790719
[epoch18, step402]: loss 7.052979
[epoch18, step403]: loss 2.215055
[epoch18, step404]: loss 1.055912
[epoch18, step405]: loss 1.413718
[epoch18, step406]: loss 5.967876
[epoch18, step407]: loss 1.129197
[epoch18, step408]: loss 6.948565
[epoch18, step409]: loss 11.286656
[epoch18, step410]: loss 0.919991
[epoch18, step411]: loss 1.290507
[epoch18, step412]: loss 10.829849
[epoch18, step413]: loss 9.513559
[epoch18, step414]: loss 11.470661
[epoch18, step415]: loss 2.635357
[epoch18, step416]: loss 1.682818
[epoch18, step417]: loss 7.184532
[epoch18, step418]: loss 0.875362
[epoch18, step419]: loss 1.581454
[epoch18, step420]: loss 0.986489
[epoch18, step421]: loss 1.200228
[epoch18, step422]: loss 8.272649
[epoch18, step423]: loss 1.161134
[epoch18, step424]: loss 19.659384
[epoch18, step425]: loss 13.766384
[epoch18, step426]: loss 0.818096
[epoch18, step427]: loss 0.623800
[epoch18, step428]: loss 2.124038
[epoch18, step429]: loss 5.815829
[epoch18, step430]: loss 0.651294
[epoch18, step431]: loss 0.795586
[epoch18, step432]: loss 5.963084
[epoch18, step433]: loss 1.977339
[epoch18, step434]: loss 15.121517
[epoch18, step435]: loss 0.898309
[epoch18, step436]: loss 0.788029
[epoch18, step437]: loss 0.789860
[epoch18, step438]: loss 1.030079
[epoch18, step439]: loss 6.065862
[epoch18, step440]: loss 11.431706
[epoch18, step441]: loss 0.734938
[epoch18, step442]: loss 1.771595
[epoch18, step443]: loss 9.406181
[epoch18, step444]: loss 0.658152
[epoch18, step445]: loss 1.504096
[epoch18, step446]: loss 6.202497
[epoch18, step447]: loss 2.500865
[epoch18, step448]: loss 6.509896
[epoch18, step449]: loss 0.608105
[epoch18, step450]: loss 18.225630
[epoch18, step451]: loss 0.811226
[epoch18, step452]: loss 2.161645
[epoch18, step453]: loss 7.182912
[epoch18, step454]: loss 0.758805
[epoch18, step455]: loss 7.986705
[epoch18, step456]: loss 7.604627
[epoch18, step457]: loss 15.351337
[epoch18, step458]: loss 1.336775
[epoch18, step459]: loss 2.029627
[epoch18, step460]: loss 3.305699
[epoch18, step461]: loss 3.054659
[epoch18, step462]: loss 0.855381
[epoch18, step463]: loss 1.659900
[epoch18, step464]: loss 1.022799
[epoch18, step465]: loss 2.471202
[epoch18, step466]: loss 1.665478
[epoch18, step467]: loss 8.399842
[epoch18, step468]: loss 6.698050
[epoch18, step469]: loss 2.709203
[epoch18, step470]: loss 0.601491
[epoch18, step471]: loss 1.133328
[epoch18, step472]: loss 0.720091
[epoch18, step473]: loss 2.985139
[epoch18, step474]: loss 0.902703
[epoch18, step475]: loss 3.217168
[epoch18, step476]: loss 0.536015
[epoch18, step477]: loss 0.767642
[epoch18, step478]: loss 0.864607
[epoch18, step479]: loss 1.283538
[epoch18, step480]: loss 6.204478
[epoch18, step481]: loss 3.165220
[epoch18, step482]: loss 6.534914
[epoch18, step483]: loss 0.636489
[epoch18, step484]: loss 2.575826
[epoch18, step485]: loss 1.015050
[epoch18, step486]: loss 5.736387
[epoch18, step487]: loss 0.908471
[epoch18, step488]: loss 1.175835
[epoch18, step489]: loss 0.800170
[epoch18, step490]: loss 1.166769
[epoch18, step491]: loss 0.584792
[epoch18, step492]: loss 1.908307
[epoch18, step493]: loss 0.812634
[epoch18, step494]: loss 2.164005
[epoch18, step495]: loss 5.950156
[epoch18, step496]: loss 11.237359
[epoch18, step497]: loss 1.307699
[epoch18, step498]: loss 6.476138
[epoch18, step499]: loss 0.802230
[epoch18, step500]: loss 2.524036
[epoch18, step501]: loss 0.822035
[epoch18, step502]: loss 8.270715
[epoch18, step503]: loss 1.755046
[epoch18, step504]: loss 2.298638
[epoch18, step505]: loss 4.328987
[epoch18, step506]: loss 1.341689
[epoch18, step507]: loss 10.402487
[epoch18, step508]: loss 1.786530
[epoch18, step509]: loss 2.451030
[epoch18, step510]: loss 8.756216
[epoch18, step511]: loss 1.065829
[epoch18, step512]: loss 5.750804
[epoch18, step513]: loss 1.214314
[epoch18, step514]: loss 1.092757
[epoch18, step515]: loss 2.778268
[epoch18, step516]: loss 0.906861
[epoch18, step517]: loss 0.801187
[epoch18, step518]: loss 0.823416
[epoch18, step519]: loss 2.171528
[epoch18, step520]: loss 5.742595
[epoch18, step521]: loss 0.718425
[epoch18, step522]: loss 3.755190
[epoch18, step523]: loss 6.210632
[epoch18, step524]: loss 7.283747
[epoch18, step525]: loss 1.192547
[epoch18, step526]: loss 0.642671
[epoch18, step527]: loss 5.601208
[epoch18, step528]: loss 0.829480
[epoch18, step529]: loss 1.298915
[epoch18, step530]: loss 8.764206
[epoch18, step531]: loss 0.942107
[epoch18, step532]: loss 1.178177
[epoch18, step533]: loss 5.736200
[epoch18, step534]: loss 0.627453
[epoch18, step535]: loss 15.418437
[epoch18, step536]: loss 2.468108
[epoch18, step537]: loss 2.132662
[epoch18, step538]: loss 1.964410
[epoch18, step539]: loss 7.527765
[epoch18, step540]: loss 5.194849
[epoch18, step541]: loss 12.032084
[epoch18, step542]: loss 2.386419
[epoch18, step543]: loss 1.288674
[epoch18, step544]: loss 0.520686
[epoch18, step545]: loss 11.515647
[epoch18, step546]: loss 2.225928
[epoch18, step547]: loss 1.651537
[epoch18, step548]: loss 6.572037
[epoch18, step549]: loss 1.346415
[epoch18, step550]: loss 9.333897
[epoch18, step551]: loss 11.995669
[epoch18, step552]: loss 13.693269
[epoch18, step553]: loss 0.837665
[epoch18, step554]: loss 0.754266
[epoch18, step555]: loss 0.863589
[epoch18, step556]: loss 1.606574
[epoch18, step557]: loss 2.339010
[epoch18, step558]: loss 1.893483
[epoch18, step559]: loss 1.432708
[epoch18, step560]: loss 8.352782
[epoch18, step561]: loss 2.253436
[epoch18, step562]: loss 4.247030
[epoch18, step563]: loss 9.455220
[epoch18, step564]: loss 10.596975
[epoch18, step565]: loss 13.144610
[epoch18, step566]: loss 1.251303
[epoch18, step567]: loss 1.225488
[epoch18, step568]: loss 0.770219
[epoch18, step569]: loss 16.213436
[epoch18, step570]: loss 3.505765
[epoch18, step571]: loss 10.128711
[epoch18, step572]: loss 1.317478
[epoch18, step573]: loss 9.086728
[epoch18, step574]: loss 10.181480
[epoch18, step575]: loss 1.885594
[epoch18, step576]: loss 1.381002
[epoch18, step577]: loss 2.872056
[epoch18, step578]: loss 0.507439
[epoch18, step579]: loss 3.438478
[epoch18, step580]: loss 0.663338
[epoch18, step581]: loss 5.869984
[epoch18, step582]: loss 6.321294
[epoch18, step583]: loss 1.008589
[epoch18, step584]: loss 4.347158
[epoch18, step585]: loss 2.787848
[epoch18, step586]: loss 2.391173
[epoch18, step587]: loss 6.569160
[epoch18, step588]: loss 11.389271
[epoch18, step589]: loss 1.953060
[epoch18, step590]: loss 4.407389
[epoch18, step591]: loss 0.616391
[epoch18, step592]: loss 5.863088
[epoch18, step593]: loss 2.591807
[epoch18, step594]: loss 0.748437
[epoch18, step595]: loss 1.052729
[epoch18, step596]: loss 2.031057
[epoch18, step597]: loss 1.651011
[epoch18, step598]: loss 2.351078
[epoch18, step599]: loss 1.472562
[epoch18, step600]: loss 6.066240
[epoch18, step601]: loss 5.728842
[epoch18, step602]: loss 0.483276
[epoch18, step603]: loss 0.736498
[epoch18, step604]: loss 0.981298
[epoch18, step605]: loss 1.695438
[epoch18, step606]: loss 1.056835
[epoch18, step607]: loss 10.879477
[epoch18, step608]: loss 1.630413
[epoch18, step609]: loss 12.420609
[epoch18, step610]: loss 1.514587
[epoch18, step611]: loss 0.956883
[epoch18, step612]: loss 1.597501
[epoch18, step613]: loss 4.140604
[epoch18, step614]: loss 8.757135
[epoch18, step615]: loss 0.797835
[epoch18, step616]: loss 1.006711
[epoch18, step617]: loss 1.246335
[epoch18, step618]: loss 0.816991
[epoch18, step619]: loss 6.754855
[epoch18, step620]: loss 8.963478
[epoch18, step621]: loss 0.523088
[epoch18, step622]: loss 4.189995
[epoch18, step623]: loss 8.349010
[epoch18, step624]: loss 1.469785
[epoch18, step625]: loss 6.504091
[epoch18, step626]: loss 3.247402
[epoch18, step627]: loss 5.585889
[epoch18, step628]: loss 0.603837
[epoch18, step629]: loss 6.563801
[epoch18, step630]: loss 2.498770
[epoch18, step631]: loss 0.652114
[epoch18, step632]: loss 9.334490
[epoch18, step633]: loss 9.108047
[epoch18, step634]: loss 6.023299
[epoch18, step635]: loss 3.876716
[epoch18, step636]: loss 0.887794
[epoch18, step637]: loss 8.708549
[epoch18, step638]: loss 7.265440
[epoch18, step639]: loss 6.565467
[epoch18, step640]: loss 2.802509
[epoch18, step641]: loss 6.749667
[epoch18, step642]: loss 5.506253
[epoch18, step643]: loss 2.590391
[epoch18, step644]: loss 3.750144
[epoch18, step645]: loss 0.830789
[epoch18, step646]: loss 1.222380
[epoch18, step647]: loss 10.691229
[epoch18, step648]: loss 1.245785
[epoch18, step649]: loss 2.082435
[epoch18, step650]: loss 6.048254
[epoch18, step651]: loss 1.915370
[epoch18, step652]: loss 0.581877
[epoch18, step653]: loss 6.220065
[epoch18, step654]: loss 6.501143
[epoch18, step655]: loss 0.679924
[epoch18, step656]: loss 15.193850
[epoch18, step657]: loss 18.177156
[epoch18, step658]: loss 23.366129
[epoch18, step659]: loss 0.798210
[epoch18, step660]: loss 0.739657
[epoch18, step661]: loss 6.060095
[epoch18, step662]: loss 0.692937
[epoch18, step663]: loss 1.079118
[epoch18, step664]: loss 1.967196
[epoch18, step665]: loss 0.709779
[epoch18, step666]: loss 6.515969
[epoch18, step667]: loss 1.822569
[epoch18, step668]: loss 0.711295
[epoch18, step669]: loss 0.853291
[epoch18, step670]: loss 8.988129
[epoch18, step671]: loss 12.100914
[epoch18, step672]: loss 1.130423
[epoch18, step673]: loss 7.913647
[epoch18, step674]: loss 1.633687
[epoch18, step675]: loss 10.645494
[epoch18, step676]: loss 0.643840
[epoch18, step677]: loss 5.641292
[epoch18, step678]: loss 2.686490
[epoch18, step679]: loss 5.711736
[epoch18, step680]: loss 2.638125
[epoch18, step681]: loss 6.184132
[epoch18, step682]: loss 1.408543
[epoch18, step683]: loss 5.027223
[epoch18, step684]: loss 4.494090
[epoch18, step685]: loss 2.834171
[epoch18, step686]: loss 1.853513
[epoch18, step687]: loss 16.150860
[epoch18, step688]: loss 1.009273
[epoch18, step689]: loss 1.542273
[epoch18, step690]: loss 0.885809
[epoch18, step691]: loss 0.471959
[epoch18, step692]: loss 1.425192
[epoch18, step693]: loss 1.800479
[epoch18, step694]: loss 9.051922
[epoch18, step695]: loss 2.914011
[epoch18, step696]: loss 3.401336
[epoch18, step697]: loss 0.799796
[epoch18, step698]: loss 1.313105
[epoch18, step699]: loss 1.449032
[epoch18, step700]: loss 0.780789
[epoch18, step701]: loss 3.493113
[epoch18, step702]: loss 13.835625
[epoch18, step703]: loss 1.584592
[epoch18, step704]: loss 3.252324
[epoch18, step705]: loss 0.807138
[epoch18, step706]: loss 12.048607
[epoch18, step707]: loss 0.361490
[epoch18, step708]: loss 0.552259
[epoch18, step709]: loss 0.887242
[epoch18, step710]: loss 1.659094
[epoch18, step711]: loss 5.500794
[epoch18, step712]: loss 1.571270
[epoch18, step713]: loss 0.739411
[epoch18, step714]: loss 0.585040
[epoch18, step715]: loss 15.569394
[epoch18, step716]: loss 5.676274
[epoch18, step717]: loss 2.303913
[epoch18, step718]: loss 2.196938
[epoch18, step719]: loss 0.665683
[epoch18, step720]: loss 1.093593
[epoch18, step721]: loss 11.069248
[epoch18, step722]: loss 7.975014
[epoch18, step723]: loss 1.954453
[epoch18, step724]: loss 10.534045
[epoch18, step725]: loss 3.251233
[epoch18, step726]: loss 2.669984
[epoch18, step727]: loss 0.985250
[epoch18, step728]: loss 3.101290
[epoch18, step729]: loss 0.581512
[epoch18, step730]: loss 19.968332
[epoch18, step731]: loss 0.500510
[epoch18, step732]: loss 2.080647
[epoch18, step733]: loss 9.737173
[epoch18, step734]: loss 1.417921
[epoch18, step735]: loss 7.279881
[epoch18, step736]: loss 7.119365
[epoch18, step737]: loss 0.922227
[epoch18, step738]: loss 2.311906
[epoch18, step739]: loss 1.894919
[epoch18, step740]: loss 6.548881
[epoch18, step741]: loss 7.392093
[epoch18, step742]: loss 0.542531
[epoch18, step743]: loss 0.534550
[epoch18, step744]: loss 1.518166
[epoch18, step745]: loss 1.140106
[epoch18, step746]: loss 1.014822
[epoch18, step747]: loss 0.737820
[epoch18, step748]: loss 2.688040
[epoch18, step749]: loss 1.872046
[epoch18, step750]: loss 0.733111
[epoch18, step751]: loss 5.564881
[epoch18, step752]: loss 1.028412
[epoch18, step753]: loss 2.263959
[epoch18, step754]: loss 12.585990
[epoch18, step755]: loss 8.519236
[epoch18, step756]: loss 2.125771
[epoch18, step757]: loss 2.584691
[epoch18, step758]: loss 14.621126
[epoch18, step759]: loss 0.992683
[epoch18, step760]: loss 0.663104
[epoch18, step761]: loss 0.532733
[epoch18, step762]: loss 6.554976
[epoch18, step763]: loss 4.085950
[epoch18, step764]: loss 0.502296
[epoch18, step765]: loss 1.514022
[epoch18, step766]: loss 1.347977
[epoch18, step767]: loss 0.859590
[epoch18, step768]: loss 4.938583
[epoch18, step769]: loss 1.647599
[epoch18, step770]: loss 0.963906
[epoch18, step771]: loss 0.622686
[epoch18, step772]: loss 7.168200
[epoch18, step773]: loss 6.627123
[epoch18, step774]: loss 24.980433
[epoch18, step775]: loss 2.577941
[epoch18, step776]: loss 4.522373
[epoch18, step777]: loss 1.057624
[epoch18, step778]: loss 1.946262
[epoch18, step779]: loss 0.816834
[epoch18, step780]: loss 0.461482
[epoch18, step781]: loss 6.157112
[epoch18, step782]: loss 6.286366
[epoch18, step783]: loss 0.604413
[epoch18, step784]: loss 2.118091
[epoch18, step785]: loss 3.142202
[epoch18, step786]: loss 0.614034
[epoch18, step787]: loss 0.876436
[epoch18, step788]: loss 1.564579
[epoch18, step789]: loss 17.359791
[epoch18, step790]: loss 3.054884
[epoch18, step791]: loss 6.126788
[epoch18, step792]: loss 9.765388
[epoch18, step793]: loss 0.893359
[epoch18, step794]: loss 8.349182
[epoch18, step795]: loss 1.277133
[epoch18, step796]: loss 6.903814
[epoch18, step797]: loss 2.880359
[epoch18, step798]: loss 2.934505
[epoch18, step799]: loss 0.838395
[epoch18, step800]: loss 6.180181
[epoch18, step801]: loss 1.518418
[epoch18, step802]: loss 2.112286
[epoch18, step803]: loss 7.219558
[epoch18, step804]: loss 14.539557
[epoch18, step805]: loss 0.876444
[epoch18, step806]: loss 18.148666
[epoch18, step807]: loss 5.859845
[epoch18, step808]: loss 0.752192
[epoch18, step809]: loss 1.346246
[epoch18, step810]: loss 1.207203
[epoch18, step811]: loss 0.709719
[epoch18, step812]: loss 3.730047
[epoch18, step813]: loss 0.847560
[epoch18, step814]: loss 3.326725
[epoch18, step815]: loss 3.048921
[epoch18, step816]: loss 10.893806
[epoch18, step817]: loss 1.822217
[epoch18, step818]: loss 2.355278
[epoch18, step819]: loss 0.875347
[epoch18, step820]: loss 1.302774
[epoch18, step821]: loss 0.810310
[epoch18, step822]: loss 2.005133
[epoch18, step823]: loss 9.649826
[epoch18, step824]: loss 7.389966
[epoch18, step825]: loss 1.170691
[epoch18, step826]: loss 0.884919
[epoch18, step827]: loss 7.055701
[epoch18, step828]: loss 2.927521
[epoch18, step829]: loss 0.906486
[epoch18, step830]: loss 6.599434
[epoch18, step831]: loss 0.933829
[epoch18, step832]: loss 0.874980
[epoch18, step833]: loss 5.686828
[epoch18, step834]: loss 5.925555
[epoch18, step835]: loss 0.623251
[epoch18, step836]: loss 1.527207
[epoch18, step837]: loss 1.137700
[epoch18, step838]: loss 2.305624
[epoch18, step839]: loss 3.118744
[epoch18, step840]: loss 10.275181
[epoch18, step841]: loss 1.733293
[epoch18, step842]: loss 7.431046
[epoch18, step843]: loss 8.590855
[epoch18, step844]: loss 5.686872
[epoch18, step845]: loss 1.072796
[epoch18, step846]: loss 6.647003
[epoch18, step847]: loss 0.901772
[epoch18, step848]: loss 1.598902
[epoch18, step849]: loss 1.209674
[epoch18, step850]: loss 9.667542
[epoch18, step851]: loss 0.660040
[epoch18, step852]: loss 0.590514
[epoch18, step853]: loss 5.911309
[epoch18, step854]: loss 3.287327
[epoch18, step855]: loss 1.470016
[epoch18, step856]: loss 1.353197
[epoch18, step857]: loss 3.370516
[epoch18, step858]: loss 1.492194
[epoch18, step859]: loss 0.949915
[epoch18, step860]: loss 0.728583
[epoch18, step861]: loss 0.481450
[epoch18, step862]: loss 0.973726
[epoch18, step863]: loss 2.462529
[epoch18, step864]: loss 12.156618
[epoch18, step865]: loss 1.149978
[epoch18, step866]: loss 10.167116
[epoch18, step867]: loss 1.013858
[epoch18, step868]: loss 1.269773
[epoch18, step869]: loss 1.768681
[epoch18, step870]: loss 2.299621
[epoch18, step871]: loss 0.891354
[epoch18, step872]: loss 0.812081
[epoch18, step873]: loss 0.673029
[epoch18, step874]: loss 0.668288
[epoch18, step875]: loss 1.042739
[epoch18, step876]: loss 1.058569
[epoch18, step877]: loss 2.603204
[epoch18, step878]: loss 2.368587
[epoch18, step879]: loss 1.660139
[epoch18, step880]: loss 3.464920
[epoch18, step881]: loss 0.634255
[epoch18, step882]: loss 6.049408
[epoch18, step883]: loss 0.830058
[epoch18, step884]: loss 0.880355
[epoch18, step885]: loss 12.352408
[epoch18, step886]: loss 1.167678
[epoch18, step887]: loss 0.949119
[epoch18, step888]: loss 1.892100
[epoch18, step889]: loss 0.444234
[epoch18, step890]: loss 1.612913
[epoch18, step891]: loss 9.361224
[epoch18, step892]: loss 1.629813
[epoch18, step893]: loss 1.026062
[epoch18, step894]: loss 11.819021
[epoch18, step895]: loss 1.010827
[epoch18, step896]: loss 1.857926
[epoch18, step897]: loss 8.763085
[epoch18, step898]: loss 16.347195
[epoch18, step899]: loss 0.779948
[epoch18, step900]: loss 3.669585
[epoch18, step901]: loss 9.094057
[epoch18, step902]: loss 11.822325
[epoch18, step903]: loss 1.180494
[epoch18, step904]: loss 1.115779
[epoch18, step905]: loss 4.839844
[epoch18, step906]: loss 1.315736
[epoch18, step907]: loss 6.409299
[epoch18, step908]: loss 6.713430
[epoch18, step909]: loss 0.816105
[epoch18, step910]: loss 13.831665
[epoch18, step911]: loss 2.323652
[epoch18, step912]: loss 2.733826
[epoch18, step913]: loss 0.724975
[epoch18, step914]: loss 7.684646
[epoch18, step915]: loss 7.377611
[epoch18, step916]: loss 0.805581
[epoch18, step917]: loss 2.186296
[epoch18, step918]: loss 1.134189
[epoch18, step919]: loss 6.747209
[epoch18, step920]: loss 0.842778
[epoch18, step921]: loss 7.554884
[epoch18, step922]: loss 0.813214
[epoch18, step923]: loss 5.964173
[epoch18, step924]: loss 0.929273
[epoch18, step925]: loss 0.814884
[epoch18, step926]: loss 23.367327
[epoch18, step927]: loss 0.935042
[epoch18, step928]: loss 0.572487
[epoch18, step929]: loss 0.586816
[epoch18, step930]: loss 0.501802
[epoch18, step931]: loss 3.317811
[epoch18, step932]: loss 2.398128
[epoch18, step933]: loss 10.969034
[epoch18, step934]: loss 4.211117
[epoch18, step935]: loss 1.074648
[epoch18, step936]: loss 1.595958
[epoch18, step937]: loss 6.622248
[epoch18, step938]: loss 12.855174
[epoch18, step939]: loss 2.228165
[epoch18, step940]: loss 2.050381
[epoch18, step941]: loss 11.304039
[epoch18, step942]: loss 1.406814
[epoch18, step943]: loss 5.714152
[epoch18, step944]: loss 1.118008
[epoch18, step945]: loss 3.603634
[epoch18, step946]: loss 0.599359
[epoch18, step947]: loss 0.931067
[epoch18, step948]: loss 0.965962
[epoch18, step949]: loss 6.730669
[epoch18, step950]: loss 1.222076
[epoch18, step951]: loss 0.812749
[epoch18, step952]: loss 2.174685
[epoch18, step953]: loss 0.646836
[epoch18, step954]: loss 8.365325
[epoch18, step955]: loss 0.570600
[epoch18, step956]: loss 1.700555
[epoch18, step957]: loss 2.503989
[epoch18, step958]: loss 1.231783
[epoch18, step959]: loss 0.714059
[epoch18, step960]: loss 4.816521
[epoch18, step961]: loss 1.019961
[epoch18, step962]: loss 4.351471
[epoch18, step963]: loss 1.063488
[epoch18, step964]: loss 2.556368
[epoch18, step965]: loss 5.912690
[epoch18, step966]: loss 3.191259
[epoch18, step967]: loss 0.761255
[epoch18, step968]: loss 2.309078
[epoch18, step969]: loss 2.497233
[epoch18, step970]: loss 0.943710
[epoch18, step971]: loss 13.932636
[epoch18, step972]: loss 16.626400
[epoch18, step973]: loss 1.228200
[epoch18, step974]: loss 0.926012
[epoch18, step975]: loss 0.449783
[epoch18, step976]: loss 1.228090
[epoch18, step977]: loss 7.972543
[epoch18, step978]: loss 1.053535
[epoch18, step979]: loss 2.692932
[epoch18, step980]: loss 0.946070
[epoch18, step981]: loss 1.717810
[epoch18, step982]: loss 0.456825
[epoch18, step983]: loss 0.447557
[epoch18, step984]: loss 12.613507
[epoch18, step985]: loss 1.304335
[epoch18, step986]: loss 3.218368
[epoch18, step987]: loss 1.892008
[epoch18, step988]: loss 0.988755
[epoch18, step989]: loss 2.096740
[epoch18, step990]: loss 16.406326
[epoch18, step991]: loss 1.115042
[epoch18, step992]: loss 0.674330
[epoch18, step993]: loss 0.545757
[epoch18, step994]: loss 0.686431
[epoch18, step995]: loss 9.460927
[epoch18, step996]: loss 1.951404
[epoch18, step997]: loss 1.785099
[epoch18, step998]: loss 0.804184
[epoch18, step999]: loss 14.156279
[epoch18, step1000]: loss 1.320539
[epoch18, step1001]: loss 12.901534
[epoch18, step1002]: loss 6.868835
[epoch18, step1003]: loss 25.026871
[epoch18, step1004]: loss 6.398124
[epoch18, step1005]: loss 1.000175
[epoch18, step1006]: loss 0.986070
[epoch18, step1007]: loss 1.008725
[epoch18, step1008]: loss 2.567591
[epoch18, step1009]: loss 0.922389
[epoch18, step1010]: loss 1.229988
[epoch18, step1011]: loss 4.830340
[epoch18, step1012]: loss 0.725553
[epoch18, step1013]: loss 1.711052
[epoch18, step1014]: loss 9.058077
[epoch18, step1015]: loss 0.544111
[epoch18, step1016]: loss 2.817180
[epoch18, step1017]: loss 6.410616
[epoch18, step1018]: loss 0.909771
[epoch18, step1019]: loss 9.648473
[epoch18, step1020]: loss 0.949437
[epoch18, step1021]: loss 7.731898
[epoch18, step1022]: loss 2.450694
[epoch18, step1023]: loss 2.177085
[epoch18, step1024]: loss 1.419713
[epoch18, step1025]: loss 3.226074
[epoch18, step1026]: loss 1.984427
[epoch18, step1027]: loss 0.664801
[epoch18, step1028]: loss 0.829873
[epoch18, step1029]: loss 6.138633
[epoch18, step1030]: loss 5.637592
[epoch18, step1031]: loss 8.339269
[epoch18, step1032]: loss 5.974627
[epoch18, step1033]: loss 2.079201
[epoch18, step1034]: loss 0.895251
[epoch18, step1035]: loss 0.690785
[epoch18, step1036]: loss 1.417349
[epoch18, step1037]: loss 10.236670
[epoch18, step1038]: loss 2.136058
[epoch18, step1039]: loss 2.497958
[epoch18, step1040]: loss 6.642731
[epoch18, step1041]: loss 2.416841
[epoch18, step1042]: loss 0.773895
[epoch18, step1043]: loss 4.840120
[epoch18, step1044]: loss 0.673511
[epoch18, step1045]: loss 0.594594
[epoch18, step1046]: loss 0.745017
[epoch18, step1047]: loss 1.850031
[epoch18, step1048]: loss 6.044679
[epoch18, step1049]: loss 2.136624
[epoch18, step1050]: loss 10.518718
[epoch18, step1051]: loss 0.379813
[epoch18, step1052]: loss 0.781128
[epoch18, step1053]: loss 0.634156
[epoch18, step1054]: loss 12.519594
[epoch18, step1055]: loss 2.553561
[epoch18, step1056]: loss 5.945047
[epoch18, step1057]: loss 8.594029
[epoch18, step1058]: loss 0.604940
[epoch18, step1059]: loss 2.927848
[epoch18, step1060]: loss 1.199649
[epoch18, step1061]: loss 5.508815
[epoch18, step1062]: loss 0.567431
[epoch18, step1063]: loss 6.616334
[epoch18, step1064]: loss 1.997706
[epoch18, step1065]: loss 0.652959
[epoch18, step1066]: loss 11.921803
[epoch18, step1067]: loss 0.763437
[epoch18, step1068]: loss 0.982221
[epoch18, step1069]: loss 0.885930
[epoch18, step1070]: loss 13.483255
[epoch18, step1071]: loss 3.763719
[epoch18, step1072]: loss 0.930818
[epoch18, step1073]: loss 5.446712
[epoch18, step1074]: loss 0.639307
[epoch18, step1075]: loss 1.170449
[epoch18, step1076]: loss 3.170012
[epoch18, step1077]: loss 0.844746
[epoch18, step1078]: loss 0.627518
[epoch18, step1079]: loss 5.938891
[epoch18, step1080]: loss 0.648747
[epoch18, step1081]: loss 6.314342
[epoch18, step1082]: loss 6.088526
[epoch18, step1083]: loss 1.905376
[epoch18, step1084]: loss 6.495691
[epoch18, step1085]: loss 4.621763
[epoch18, step1086]: loss 1.805720
[epoch18, step1087]: loss 0.525555
[epoch18, step1088]: loss 2.170569
[epoch18, step1089]: loss 0.649530
[epoch18, step1090]: loss 7.269806
[epoch18, step1091]: loss 2.504155
[epoch18, step1092]: loss 1.227127
[epoch18, step1093]: loss 1.878465
[epoch18, step1094]: loss 0.801088
[epoch18, step1095]: loss 1.179347
[epoch18, step1096]: loss 5.772028
[epoch18, step1097]: loss 1.712777
[epoch18, step1098]: loss 1.282556
[epoch18, step1099]: loss 14.485774
[epoch18, step1100]: loss 1.335322
[epoch18, step1101]: loss 1.451768
[epoch18, step1102]: loss 0.997306
[epoch18, step1103]: loss 6.054860
[epoch18, step1104]: loss 6.530418
[epoch18, step1105]: loss 3.473927
[epoch18, step1106]: loss 0.765804
[epoch18, step1107]: loss 7.072498
[epoch18, step1108]: loss 0.564985
[epoch18, step1109]: loss 5.027314
[epoch18, step1110]: loss 1.290661
[epoch18, step1111]: loss 1.525797
[epoch18, step1112]: loss 0.889075
[epoch18, step1113]: loss 0.727389
[epoch18, step1114]: loss 9.259766
[epoch18, step1115]: loss 10.199252
[epoch18, step1116]: loss 0.845196
[epoch18, step1117]: loss 0.934610
[epoch18, step1118]: loss 0.822661
[epoch18, step1119]: loss 0.814113
[epoch18, step1120]: loss 2.805093
[epoch18, step1121]: loss 8.317649
[epoch18, step1122]: loss 14.368017
[epoch18, step1123]: loss 10.865047
[epoch18, step1124]: loss 1.458198
[epoch18, step1125]: loss 1.451223
[epoch18, step1126]: loss 0.704912
[epoch18, step1127]: loss 1.269262
[epoch18, step1128]: loss 0.813625
[epoch18, step1129]: loss 3.155151
[epoch18, step1130]: loss 1.875387
[epoch18, step1131]: loss 6.149499
[epoch18, step1132]: loss 0.620298
[epoch18, step1133]: loss 2.044616
[epoch18, step1134]: loss 6.380488
[epoch18, step1135]: loss 11.446471
[epoch18, step1136]: loss 1.135563
[epoch18, step1137]: loss 0.877053
[epoch18, step1138]: loss 3.633882
[epoch18, step1139]: loss 1.068794
[epoch18, step1140]: loss 1.014191
[epoch18, step1141]: loss 0.624067
[epoch18, step1142]: loss 3.245522
[epoch18, step1143]: loss 0.960838
[epoch18, step1144]: loss 0.894213
[epoch18, step1145]: loss 1.651893
[epoch18, step1146]: loss 1.911328
[epoch18, step1147]: loss 0.869994
[epoch18, step1148]: loss 1.199211
[epoch18, step1149]: loss 3.068501
[epoch18, step1150]: loss 5.528313
[epoch18, step1151]: loss 9.529562
[epoch18, step1152]: loss 1.771829
[epoch18, step1153]: loss 1.400663
[epoch18, step1154]: loss 1.932540
[epoch18, step1155]: loss 10.093322
[epoch18, step1156]: loss 2.085797
[epoch18, step1157]: loss 0.532949
[epoch18, step1158]: loss 1.477317
[epoch18, step1159]: loss 2.531561
[epoch18, step1160]: loss 11.010165
[epoch18, step1161]: loss 14.342730
[epoch18, step1162]: loss 1.138094
[epoch18, step1163]: loss 0.741814
[epoch18, step1164]: loss 1.418099
[epoch18, step1165]: loss 7.814740
[epoch18, step1166]: loss 1.316874
[epoch18, step1167]: loss 6.357317
[epoch18, step1168]: loss 1.664522
[epoch18, step1169]: loss 2.095203
[epoch18, step1170]: loss 7.737925
[epoch18, step1171]: loss 0.589113
[epoch18, step1172]: loss 0.625975
[epoch18, step1173]: loss 6.141218
[epoch18, step1174]: loss 1.029756
[epoch18, step1175]: loss 0.708005
[epoch18, step1176]: loss 1.011095
[epoch18, step1177]: loss 1.451666
[epoch18, step1178]: loss 1.260603
[epoch18, step1179]: loss 0.844100
[epoch18, step1180]: loss 2.973620
[epoch18, step1181]: loss 1.186226
[epoch18, step1182]: loss 0.881377
[epoch18, step1183]: loss 1.194133
[epoch18, step1184]: loss 2.419958
[epoch18, step1185]: loss 2.121095
[epoch18, step1186]: loss 1.894356
[epoch18, step1187]: loss 8.005337
[epoch18, step1188]: loss 0.920076
[epoch18, step1189]: loss 0.682852
[epoch18, step1190]: loss 7.812799
[epoch18, step1191]: loss 1.300924
[epoch18, step1192]: loss 1.947651
[epoch18, step1193]: loss 0.829963
[epoch18, step1194]: loss 0.874676
[epoch18, step1195]: loss 2.296304
[epoch18, step1196]: loss 1.180788
[epoch18, step1197]: loss 5.635841
[epoch18, step1198]: loss 3.034354
[epoch18, step1199]: loss 1.437510
[epoch18, step1200]: loss 16.278610
[epoch18, step1201]: loss 6.478189
[epoch18, step1202]: loss 2.418763
[epoch18, step1203]: loss 1.413222
[epoch18, step1204]: loss 0.876735
[epoch18, step1205]: loss 10.801308
[epoch18, step1206]: loss 0.584797
[epoch18, step1207]: loss 14.571220
[epoch18, step1208]: loss 0.582485
[epoch18, step1209]: loss 5.633428
[epoch18, step1210]: loss 1.981103
[epoch18, step1211]: loss 8.837887
[epoch18, step1212]: loss 1.274853
[epoch18, step1213]: loss 0.912123
[epoch18, step1214]: loss 18.209148
[epoch18, step1215]: loss 6.135400
[epoch18, step1216]: loss 11.300354
[epoch18, step1217]: loss 3.640184
[epoch18, step1218]: loss 1.590244
[epoch18, step1219]: loss 0.525226
[epoch18, step1220]: loss 2.456204
[epoch18, step1221]: loss 0.574747
[epoch18, step1222]: loss 1.803031
[epoch18, step1223]: loss 0.807993
[epoch18, step1224]: loss 16.861347
[epoch18, step1225]: loss 0.703202
[epoch18, step1226]: loss 1.271724
[epoch18, step1227]: loss 8.892973
[epoch18, step1228]: loss 0.914116
[epoch18, step1229]: loss 0.649413
[epoch18, step1230]: loss 0.942842
[epoch18, step1231]: loss 1.544586
[epoch18, step1232]: loss 1.234685
[epoch18, step1233]: loss 5.862489
[epoch18, step1234]: loss 1.600793
[epoch18, step1235]: loss 0.774468
[epoch18, step1236]: loss 6.844962
[epoch18, step1237]: loss 1.506729
[epoch18, step1238]: loss 0.911140
[epoch18, step1239]: loss 15.656425
[epoch18, step1240]: loss 1.702083
[epoch18, step1241]: loss 2.300267
[epoch18, step1242]: loss 0.893602
[epoch18, step1243]: loss 13.768790
[epoch18, step1244]: loss 0.608749
[epoch18, step1245]: loss 5.656009
[epoch18, step1246]: loss 1.496658
[epoch18, step1247]: loss 1.301252
[epoch18, step1248]: loss 0.812363
[epoch18, step1249]: loss 0.566696
[epoch18, step1250]: loss 0.716190
[epoch18, step1251]: loss 0.853716
[epoch18, step1252]: loss 2.640479
[epoch18, step1253]: loss 0.499414
[epoch18, step1254]: loss 5.976213
[epoch18, step1255]: loss 0.654575
[epoch18, step1256]: loss 1.232794
[epoch18, step1257]: loss 5.357225
[epoch18, step1258]: loss 1.177909
[epoch18, step1259]: loss 0.616608
[epoch18, step1260]: loss 2.596217
[epoch18, step1261]: loss 0.929202
[epoch18, step1262]: loss 2.493876
[epoch18, step1263]: loss 3.182529
[epoch18, step1264]: loss 2.551540
[epoch18, step1265]: loss 0.642698
[epoch18, step1266]: loss 0.781944
[epoch18, step1267]: loss 1.172890
[epoch18, step1268]: loss 1.636471
[epoch18, step1269]: loss 12.123998
[epoch18, step1270]: loss 9.061785
[epoch18, step1271]: loss 11.396644
[epoch18, step1272]: loss 1.092283
[epoch18, step1273]: loss 0.700667
[epoch18, step1274]: loss 2.161540
[epoch18, step1275]: loss 6.961156
[epoch18, step1276]: loss 2.082851
[epoch18, step1277]: loss 5.587993
[epoch18, step1278]: loss 0.967732
[epoch18, step1279]: loss 0.659689
[epoch18, step1280]: loss 0.845665
[epoch18, step1281]: loss 5.469558
[epoch18, step1282]: loss 1.436318
[epoch18, step1283]: loss 0.682920
[epoch18, step1284]: loss 8.228625
[epoch18, step1285]: loss 1.995868
[epoch18, step1286]: loss 6.204578
[epoch18, step1287]: loss 1.507976
[epoch18, step1288]: loss 0.463765
[epoch18, step1289]: loss 2.411660
[epoch18, step1290]: loss 0.572983
[epoch18, step1291]: loss 0.765208
[epoch18, step1292]: loss 0.782499
[epoch18, step1293]: loss 2.496442
[epoch18, step1294]: loss 1.202917
[epoch18, step1295]: loss 2.135443
[epoch18, step1296]: loss 9.016994
[epoch18, step1297]: loss 8.018866
[epoch18, step1298]: loss 11.695628
[epoch18, step1299]: loss 11.914415
[epoch18, step1300]: loss 0.907952
[epoch18, step1301]: loss 0.751709
[epoch18, step1302]: loss 6.950524
[epoch18, step1303]: loss 1.060726
[epoch18, step1304]: loss 1.421149
[epoch18, step1305]: loss 5.233833
[epoch18, step1306]: loss 5.767460
[epoch18, step1307]: loss 16.772570
[epoch18, step1308]: loss 7.393391
[epoch18, step1309]: loss 0.757415
[epoch18, step1310]: loss 6.211236
[epoch18, step1311]: loss 0.884460
[epoch18, step1312]: loss 0.697708
[epoch18, step1313]: loss 1.467566
[epoch18, step1314]: loss 4.872473
[epoch18, step1315]: loss 1.596149
[epoch18, step1316]: loss 0.887299
[epoch18, step1317]: loss 2.006534
[epoch18, step1318]: loss 8.830276
[epoch18, step1319]: loss 12.212364
[epoch18, step1320]: loss 7.753495
[epoch18, step1321]: loss 1.099421
[epoch18, step1322]: loss 1.361403
[epoch18, step1323]: loss 9.207214
[epoch18, step1324]: loss 1.071780
[epoch18, step1325]: loss 0.727139
[epoch18, step1326]: loss 0.547071
[epoch18, step1327]: loss 1.100786
[epoch18, step1328]: loss 3.655474
[epoch18, step1329]: loss 0.830378
[epoch18, step1330]: loss 1.101306
[epoch18, step1331]: loss 9.621270
[epoch18, step1332]: loss 0.864906
[epoch18, step1333]: loss 0.762853
[epoch18, step1334]: loss 7.113873
[epoch18, step1335]: loss 0.746090
[epoch18, step1336]: loss 7.938243
[epoch18, step1337]: loss 0.689428
[epoch18, step1338]: loss 9.088599
[epoch18, step1339]: loss 6.223106
[epoch18, step1340]: loss 3.132548
[epoch18, step1341]: loss 13.556612
[epoch18, step1342]: loss 0.846669
[epoch18, step1343]: loss 6.040306
[epoch18, step1344]: loss 0.802390
[epoch18, step1345]: loss 11.021825
[epoch18, step1346]: loss 2.265904
[epoch18, step1347]: loss 1.276939
[epoch18, step1348]: loss 0.784381
[epoch18, step1349]: loss 6.142103
[epoch18, step1350]: loss 3.124102
[epoch18, step1351]: loss 0.566443
[epoch18, step1352]: loss 0.640527
[epoch18, step1353]: loss 5.218280
[epoch18, step1354]: loss 3.087332
[epoch18, step1355]: loss 2.484280
[epoch18, step1356]: loss 2.736792
[epoch18, step1357]: loss 0.613497
[epoch18, step1358]: loss 1.296329
[epoch18, step1359]: loss 0.716605
[epoch18, step1360]: loss 1.256061
[epoch18, step1361]: loss 0.673784
[epoch18, step1362]: loss 6.169963
[epoch18, step1363]: loss 0.713866
[epoch18, step1364]: loss 0.588937
[epoch18, step1365]: loss 1.369108
[epoch18, step1366]: loss 19.097515
[epoch18, step1367]: loss 0.794821
[epoch18, step1368]: loss 1.017683
[epoch18, step1369]: loss 5.604401
[epoch18, step1370]: loss 0.682974
[epoch18, step1371]: loss 7.318071
[epoch18, step1372]: loss 2.229712
[epoch18, step1373]: loss 1.685716
[epoch18, step1374]: loss 6.506138
[epoch18, step1375]: loss 1.605611
[epoch18, step1376]: loss 3.826076
[epoch18, step1377]: loss 0.757408
[epoch18, step1378]: loss 22.154110
[epoch18, step1379]: loss 9.413187
[epoch18, step1380]: loss 1.885635
[epoch18, step1381]: loss 1.073197
[epoch18, step1382]: loss 0.519191
[epoch18, step1383]: loss 8.167450
[epoch18, step1384]: loss 1.512255
[epoch18, step1385]: loss 7.456090
[epoch18, step1386]: loss 13.550503
[epoch18, step1387]: loss 4.074185
[epoch18, step1388]: loss 1.288825
[epoch18, step1389]: loss 0.614726
[epoch18, step1390]: loss 5.581153
[epoch18, step1391]: loss 1.725020
[epoch18, step1392]: loss 2.492411
[epoch18, step1393]: loss 0.797607
[epoch18, step1394]: loss 9.566228
[epoch18, step1395]: loss 5.900869
[epoch18, step1396]: loss 0.517054
[epoch18, step1397]: loss 2.080327
[epoch18, step1398]: loss 1.725524
[epoch18, step1399]: loss 6.471631
[epoch18, step1400]: loss 1.755249
[epoch18, step1401]: loss 6.289052
[epoch18, step1402]: loss 1.111495
[epoch18, step1403]: loss 9.043639
[epoch18, step1404]: loss 0.586378
[epoch18, step1405]: loss 8.119000
[epoch18, step1406]: loss 0.664345
[epoch18, step1407]: loss 1.185408
[epoch18, step1408]: loss 7.163263
[epoch18, step1409]: loss 12.155279
[epoch18, step1410]: loss 6.293406
[epoch18, step1411]: loss 0.456640
[epoch18, step1412]: loss 2.342485
[epoch18, step1413]: loss 3.699426
[epoch18, step1414]: loss 0.495111
[epoch18, step1415]: loss 5.665362
[epoch18, step1416]: loss 21.021816
[epoch18, step1417]: loss 1.587794
[epoch18, step1418]: loss 1.243493
[epoch18, step1419]: loss 2.048434
[epoch18, step1420]: loss 1.724177
[epoch18, step1421]: loss 9.132290
[epoch18, step1422]: loss 1.251061
[epoch18, step1423]: loss 4.235008
[epoch18, step1424]: loss 2.138458
[epoch18, step1425]: loss 1.657578
[epoch18, step1426]: loss 2.124247
[epoch18, step1427]: loss 0.619653
[epoch18, step1428]: loss 0.971403
[epoch18, step1429]: loss 1.094192
[epoch18, step1430]: loss 6.694632
[epoch18, step1431]: loss 1.458625
[epoch18, step1432]: loss 0.544554
[epoch18, step1433]: loss 4.400864
[epoch18, step1434]: loss 8.428652
[epoch18, step1435]: loss 2.600412
[epoch18, step1436]: loss 11.396118
[epoch18, step1437]: loss 2.258540
[epoch18, step1438]: loss 2.442630
[epoch18, step1439]: loss 1.759046
[epoch18, step1440]: loss 3.395772
[epoch18, step1441]: loss 0.799410
[epoch18, step1442]: loss 0.630454
[epoch18, step1443]: loss 0.942625
[epoch18, step1444]: loss 1.223839
[epoch18, step1445]: loss 2.394254
[epoch18, step1446]: loss 2.451162
[epoch18, step1447]: loss 1.582073
[epoch18, step1448]: loss 9.274014
[epoch18, step1449]: loss 3.754552
[epoch18, step1450]: loss 3.025582
[epoch18, step1451]: loss 1.223353
[epoch18, step1452]: loss 1.229242
[epoch18, step1453]: loss 1.919552
[epoch18, step1454]: loss 5.956431
[epoch18, step1455]: loss 7.888658
[epoch18, step1456]: loss 0.908317
[epoch18, step1457]: loss 17.983198
[epoch18, step1458]: loss 0.697638
[epoch18, step1459]: loss 5.726129
[epoch18, step1460]: loss 0.784519
[epoch18, step1461]: loss 14.362223
[epoch18, step1462]: loss 5.631373
[epoch18, step1463]: loss 1.757834
[epoch18, step1464]: loss 7.700368
[epoch18, step1465]: loss 2.959122
[epoch18, step1466]: loss 1.753679
[epoch18, step1467]: loss 1.644501
[epoch18, step1468]: loss 1.393738
[epoch18, step1469]: loss 0.777115
[epoch18, step1470]: loss 0.607129
[epoch18, step1471]: loss 1.790292
[epoch18, step1472]: loss 1.371046
[epoch18, step1473]: loss 9.996385
[epoch18, step1474]: loss 0.681077
[epoch18, step1475]: loss 0.731886
[epoch18, step1476]: loss 0.665747
[epoch18, step1477]: loss 9.936012
[epoch18, step1478]: loss 2.057490
[epoch18, step1479]: loss 0.806185
[epoch18, step1480]: loss 1.663242
[epoch18, step1481]: loss 6.313602
[epoch18, step1482]: loss 5.970799
[epoch18, step1483]: loss 2.868944
[epoch18, step1484]: loss 1.843131
[epoch18, step1485]: loss 6.183259
[epoch18, step1486]: loss 1.383227
[epoch18, step1487]: loss 7.195089
[epoch18, step1488]: loss 1.285391
[epoch18, step1489]: loss 0.561881
[epoch18, step1490]: loss 10.991448
[epoch18, step1491]: loss 6.367387
[epoch18, step1492]: loss 0.491373
[epoch18, step1493]: loss 3.107593
[epoch18, step1494]: loss 1.682194
[epoch18, step1495]: loss 0.878053
[epoch18, step1496]: loss 5.449256
[epoch18, step1497]: loss 11.878723
[epoch18, step1498]: loss 6.243145
[epoch18, step1499]: loss 3.227843
[epoch18, step1500]: loss 9.499660
[epoch18, step1501]: loss 1.055851
[epoch18, step1502]: loss 0.748130
[epoch18, step1503]: loss 1.022550
[epoch18, step1504]: loss 1.785682
[epoch18, step1505]: loss 1.270026
[epoch18, step1506]: loss 0.714838
[epoch18, step1507]: loss 2.358872
[epoch18, step1508]: loss 0.889545
[epoch18, step1509]: loss 0.544933
[epoch18, step1510]: loss 0.739378
[epoch18, step1511]: loss 1.587548
[epoch18, step1512]: loss 4.861398
[epoch18, step1513]: loss 5.080403
[epoch18, step1514]: loss 0.678054
[epoch18, step1515]: loss 0.508841
[epoch18, step1516]: loss 15.540173
[epoch18, step1517]: loss 8.752695
[epoch18, step1518]: loss 2.912602
[epoch18, step1519]: loss 1.248644
[epoch18, step1520]: loss 1.077852
[epoch18, step1521]: loss 11.494345
[epoch18, step1522]: loss 3.725839
[epoch18, step1523]: loss 0.809008
[epoch18, step1524]: loss 1.292186
[epoch18, step1525]: loss 1.811815
[epoch18, step1526]: loss 9.594592
[epoch18, step1527]: loss 0.871754
[epoch18, step1528]: loss 1.233415
[epoch18, step1529]: loss 1.650784
[epoch18, step1530]: loss 1.023451
[epoch18, step1531]: loss 0.699888
[epoch18, step1532]: loss 1.831907
[epoch18, step1533]: loss 1.345104
[epoch18, step1534]: loss 0.716607
[epoch18, step1535]: loss 1.448341
[epoch18, step1536]: loss 5.205485
[epoch18, step1537]: loss 1.264457
[epoch18, step1538]: loss 1.518363
[epoch18, step1539]: loss 0.414486
[epoch18, step1540]: loss 0.864830
[epoch18, step1541]: loss 3.854699
[epoch18, step1542]: loss 5.507263
[epoch18, step1543]: loss 12.345354
[epoch18, step1544]: loss 7.314572
[epoch18, step1545]: loss 7.063340
[epoch18, step1546]: loss 0.799857
[epoch18, step1547]: loss 11.171974
[epoch18, step1548]: loss 2.563556
[epoch18, step1549]: loss 5.850857
[epoch18, step1550]: loss 7.502708
[epoch18, step1551]: loss 1.517458
[epoch18, step1552]: loss 1.104502
[epoch18, step1553]: loss 6.909028
[epoch18, step1554]: loss 0.643601
[epoch18, step1555]: loss 1.676099
[epoch18, step1556]: loss 0.797525
[epoch18, step1557]: loss 0.737556
[epoch18, step1558]: loss 0.749964
[epoch18, step1559]: loss 25.719091
[epoch18, step1560]: loss 6.337162
[epoch18, step1561]: loss 0.682061
[epoch18, step1562]: loss 0.640816
[epoch18, step1563]: loss 1.316267
[epoch18, step1564]: loss 7.745181
[epoch18, step1565]: loss 8.716236
[epoch18, step1566]: loss 2.102143
[epoch18, step1567]: loss 3.599257
[epoch18, step1568]: loss 0.842768
[epoch18, step1569]: loss 0.862055
[epoch18, step1570]: loss 0.861937
[epoch18, step1571]: loss 2.839526
[epoch18, step1572]: loss 6.452926
[epoch18, step1573]: loss 1.040633
[epoch18, step1574]: loss 7.192781
[epoch18, step1575]: loss 6.221952
[epoch18, step1576]: loss 1.574657
[epoch18, step1577]: loss 12.402562
[epoch18, step1578]: loss 5.247770
[epoch18, step1579]: loss 0.942763
[epoch18, step1580]: loss 6.641938
[epoch18, step1581]: loss 2.551656
[epoch18, step1582]: loss 3.712724
[epoch18, step1583]: loss 5.811154
[epoch18, step1584]: loss 2.699907
[epoch18, step1585]: loss 1.146062
[epoch18, step1586]: loss 0.664492
[epoch18, step1587]: loss 0.421238
[epoch18, step1588]: loss 0.848126
[epoch18, step1589]: loss 9.945181
[epoch18, step1590]: loss 1.694267
[epoch18, step1591]: loss 5.663992
[epoch18, step1592]: loss 1.231075
[epoch18, step1593]: loss 0.648361
[epoch18, step1594]: loss 2.663031
[epoch18, step1595]: loss 0.636953
[epoch18, step1596]: loss 5.119205
[epoch18, step1597]: loss 2.173902
[epoch18, step1598]: loss 0.759273
[epoch18, step1599]: loss 4.019261
[epoch18, step1600]: loss 1.920738
[epoch18, step1601]: loss 0.779989
[epoch18, step1602]: loss 12.753176
[epoch18, step1603]: loss 5.864122
[epoch18, step1604]: loss 1.586246
[epoch18, step1605]: loss 1.122406
[epoch18, step1606]: loss 1.135626
[epoch18, step1607]: loss 0.991735
[epoch18, step1608]: loss 1.983032
[epoch18, step1609]: loss 1.224812
[epoch18, step1610]: loss 3.371286
[epoch18, step1611]: loss 3.627609
[epoch18, step1612]: loss 2.029604
[epoch18, step1613]: loss 2.164659
[epoch18, step1614]: loss 1.620634
[epoch18, step1615]: loss 0.945154
[epoch18, step1616]: loss 19.204002
[epoch18, step1617]: loss 5.763034
[epoch18, step1618]: loss 6.119092
[epoch18, step1619]: loss 13.434361
[epoch18, step1620]: loss 8.457180
[epoch18, step1621]: loss 8.307505
[epoch18, step1622]: loss 0.590786
[epoch18, step1623]: loss 1.629879
[epoch18, step1624]: loss 6.600974
[epoch18, step1625]: loss 1.760378
[epoch18, step1626]: loss 12.690078
[epoch18, step1627]: loss 3.041585
[epoch18, step1628]: loss 2.344382
[epoch18, step1629]: loss 0.831335
[epoch18, step1630]: loss 1.186329
[epoch18, step1631]: loss 2.596368
[epoch18, step1632]: loss 0.579220
[epoch18, step1633]: loss 1.253338
[epoch18, step1634]: loss 1.057095
[epoch18, step1635]: loss 0.635792
[epoch18, step1636]: loss 2.447398
[epoch18, step1637]: loss 5.954529
[epoch18, step1638]: loss 1.744814
[epoch18, step1639]: loss 1.887438
[epoch18, step1640]: loss 9.266718
[epoch18, step1641]: loss 1.326208
[epoch18, step1642]: loss 0.939896
[epoch18, step1643]: loss 0.740667
[epoch18, step1644]: loss 0.844931
[epoch18, step1645]: loss 4.906321
[epoch18, step1646]: loss 0.678833
[epoch18, step1647]: loss 0.818058
[epoch18, step1648]: loss 1.455857
[epoch18, step1649]: loss 6.240218
[epoch18, step1650]: loss 2.581163
[epoch18, step1651]: loss 1.313580
[epoch18, step1652]: loss 2.017688
[epoch18, step1653]: loss 8.913091
[epoch18, step1654]: loss 2.123961
[epoch18, step1655]: loss 8.298450
[epoch18, step1656]: loss 0.985251
[epoch18, step1657]: loss 6.171907
[epoch18, step1658]: loss 5.389048
[epoch18, step1659]: loss 2.811453
[epoch18, step1660]: loss 1.172547
[epoch18, step1661]: loss 5.743470
[epoch18, step1662]: loss 1.529142
[epoch18, step1663]: loss 0.942090
[epoch18, step1664]: loss 0.994745
[epoch18, step1665]: loss 1.270316
[epoch18, step1666]: loss 0.605576
[epoch18, step1667]: loss 3.165898
[epoch18, step1668]: loss 1.380462
[epoch18, step1669]: loss 0.801277
[epoch18, step1670]: loss 0.394622
[epoch18, step1671]: loss 2.649577
[epoch18, step1672]: loss 2.652199
[epoch18, step1673]: loss 1.282660
[epoch18, step1674]: loss 8.626997
[epoch18, step1675]: loss 0.932880
[epoch18, step1676]: loss 3.290470
[epoch18, step1677]: loss 5.820611
[epoch18, step1678]: loss 1.785716
[epoch18, step1679]: loss 3.664577
[epoch18, step1680]: loss 0.939956
[epoch18, step1681]: loss 0.771922
[epoch18, step1682]: loss 1.030250
[epoch18, step1683]: loss 4.288754
[epoch18, step1684]: loss 1.539086
[epoch18, step1685]: loss 4.945042
[epoch18, step1686]: loss 0.920455
[epoch18, step1687]: loss 2.567810
[epoch18, step1688]: loss 3.126038
[epoch18, step1689]: loss 2.207745
[epoch18, step1690]: loss 1.294745
[epoch18, step1691]: loss 6.338797
[epoch18, step1692]: loss 3.176973
[epoch18, step1693]: loss 1.069265
[epoch18, step1694]: loss 2.480811
[epoch18, step1695]: loss 0.954459
[epoch18, step1696]: loss 2.625502
[epoch18, step1697]: loss 15.850100
[epoch18, step1698]: loss 9.174779
[epoch18, step1699]: loss 2.953321
[epoch18, step1700]: loss 1.829920
[epoch18, step1701]: loss 6.674970
[epoch18, step1702]: loss 5.422490
[epoch18, step1703]: loss 1.130185
[epoch18, step1704]: loss 9.599208
[epoch18, step1705]: loss 7.349189
[epoch18, step1706]: loss 0.761246
[epoch18, step1707]: loss 5.581320
[epoch18, step1708]: loss 1.715999
[epoch18, step1709]: loss 1.466185
[epoch18, step1710]: loss 9.394490
[epoch18, step1711]: loss 3.414110
[epoch18, step1712]: loss 6.718008
[epoch18, step1713]: loss 0.690055
[epoch18, step1714]: loss 0.460436
[epoch18, step1715]: loss 3.625677
[epoch18, step1716]: loss 4.824911
[epoch18, step1717]: loss 15.101952
[epoch18, step1718]: loss 4.471628
[epoch18, step1719]: loss 1.798033
[epoch18, step1720]: loss 0.722898
[epoch18, step1721]: loss 2.915959
[epoch18, step1722]: loss 1.086386
[epoch18, step1723]: loss 6.587334
[epoch18, step1724]: loss 1.346919
[epoch18, step1725]: loss 19.216982
[epoch18, step1726]: loss 5.931404
[epoch18, step1727]: loss 17.344942
[epoch18, step1728]: loss 1.287573
[epoch18, step1729]: loss 1.843821
[epoch18, step1730]: loss 2.042966
[epoch18, step1731]: loss 0.788448
[epoch18, step1732]: loss 0.621734
[epoch18, step1733]: loss 0.546679
[epoch18, step1734]: loss 6.330799
[epoch18, step1735]: loss 11.371928
[epoch18, step1736]: loss 1.623657
[epoch18, step1737]: loss 1.717951
[epoch18, step1738]: loss 0.613739
[epoch18, step1739]: loss 0.496799
[epoch18, step1740]: loss 3.960840
[epoch18, step1741]: loss 0.808275
[epoch18, step1742]: loss 1.139687
[epoch18, step1743]: loss 15.362322
[epoch18, step1744]: loss 0.312246
[epoch18, step1745]: loss 20.387974
[epoch18, step1746]: loss 8.666857
[epoch18, step1747]: loss 5.672599
[epoch18, step1748]: loss 0.593065
[epoch18, step1749]: loss 0.886147
[epoch18, step1750]: loss 0.753008
[epoch18, step1751]: loss 4.729162
[epoch18, step1752]: loss 0.937772
[epoch18, step1753]: loss 0.760747
[epoch18, step1754]: loss 12.948388
[epoch18, step1755]: loss 1.711455
[epoch18, step1756]: loss 1.049867
[epoch18, step1757]: loss 5.596567
[epoch18, step1758]: loss 0.994832
[epoch18, step1759]: loss 0.602514
[epoch18, step1760]: loss 0.614939
[epoch18, step1761]: loss 10.893709
[epoch18, step1762]: loss 0.767839
[epoch18, step1763]: loss 3.561132
[epoch18, step1764]: loss 5.394964
[epoch18, step1765]: loss 5.983221
[epoch18, step1766]: loss 16.735064
[epoch18, step1767]: loss 0.481328
[epoch18, step1768]: loss 1.399941
[epoch18, step1769]: loss 2.609903
[epoch18, step1770]: loss 0.527240
[epoch18, step1771]: loss 11.974710
[epoch18, step1772]: loss 2.718522
[epoch18, step1773]: loss 0.573030
[epoch18, step1774]: loss 2.513763
[epoch18, step1775]: loss 0.783706
[epoch18, step1776]: loss 6.444556
[epoch18, step1777]: loss 10.627642
[epoch18, step1778]: loss 9.593413
[epoch18, step1779]: loss 6.245662
[epoch18, step1780]: loss 9.583948
[epoch18, step1781]: loss 1.218137
[epoch18, step1782]: loss 4.675825
[epoch18, step1783]: loss 1.674542
[epoch18, step1784]: loss 1.347783
[epoch18, step1785]: loss 0.824050
[epoch18, step1786]: loss 6.918339
[epoch18, step1787]: loss 1.489657
[epoch18, step1788]: loss 0.828331
[epoch18, step1789]: loss 1.517303
[epoch18, step1790]: loss 5.382032
[epoch18, step1791]: loss 5.350418
[epoch18, step1792]: loss 11.811665
[epoch18, step1793]: loss 1.702822
[epoch18, step1794]: loss 0.840873
[epoch18, step1795]: loss 1.790958
[epoch18, step1796]: loss 15.347388
[epoch18, step1797]: loss 1.385159
[epoch18, step1798]: loss 1.777499
[epoch18, step1799]: loss 2.074403
[epoch18, step1800]: loss 2.035730
[epoch18, step1801]: loss 5.097502
[epoch18, step1802]: loss 10.176310
[epoch18, step1803]: loss 2.172107
[epoch18, step1804]: loss 6.161195
[epoch18, step1805]: loss 0.489654
[epoch18, step1806]: loss 0.514836
[epoch18, step1807]: loss 8.774965
[epoch18, step1808]: loss 0.998962
[epoch18, step1809]: loss 1.326757
[epoch18, step1810]: loss 11.086114
[epoch18, step1811]: loss 0.774643
[epoch18, step1812]: loss 1.688125
[epoch18, step1813]: loss 1.073747
[epoch18, step1814]: loss 17.920662
[epoch18, step1815]: loss 0.903790
[epoch18, step1816]: loss 1.372183
[epoch18, step1817]: loss 1.985783
[epoch18, step1818]: loss 0.765316
[epoch18, step1819]: loss 1.947240
[epoch18, step1820]: loss 11.963604
[epoch18, step1821]: loss 1.113368
[epoch18, step1822]: loss 1.949068
[epoch18, step1823]: loss 8.477706
[epoch18, step1824]: loss 0.592453
[epoch18, step1825]: loss 3.927315
[epoch18, step1826]: loss 0.849770
[epoch18, step1827]: loss 0.665849
[epoch18, step1828]: loss 0.835798
[epoch18, step1829]: loss 0.849752
[epoch18, step1830]: loss 0.678381
[epoch18, step1831]: loss 0.940936
[epoch18, step1832]: loss 0.789342
[epoch18, step1833]: loss 5.960463
[epoch18, step1834]: loss 2.576565
[epoch18, step1835]: loss 6.298255
[epoch18, step1836]: loss 1.304624
[epoch18, step1837]: loss 2.280717
[epoch18, step1838]: loss 1.874633
[epoch18, step1839]: loss 10.986174
[epoch18, step1840]: loss 0.721412
[epoch18, step1841]: loss 1.796625
[epoch18, step1842]: loss 17.662376
[epoch18, step1843]: loss 16.984985
[epoch18, step1844]: loss 11.239311
[epoch18, step1845]: loss 0.754789
[epoch18, step1846]: loss 0.514243
[epoch18, step1847]: loss 0.902768
[epoch18, step1848]: loss 10.676509
[epoch18, step1849]: loss 8.113224
[epoch18, step1850]: loss 3.120689
[epoch18, step1851]: loss 0.714975
[epoch18, step1852]: loss 5.904773
[epoch18, step1853]: loss 1.548634
[epoch18, step1854]: loss 2.569228
[epoch18, step1855]: loss 12.779070
[epoch18, step1856]: loss 0.869457
[epoch18, step1857]: loss 1.142711
[epoch18, step1858]: loss 1.595373
[epoch18, step1859]: loss 2.595703
[epoch18, step1860]: loss 0.928097
[epoch18, step1861]: loss 2.210910
[epoch18, step1862]: loss 1.102668
[epoch18, step1863]: loss 2.711528
[epoch18, step1864]: loss 12.269078
[epoch18, step1865]: loss 4.851206
[epoch18, step1866]: loss 0.936923
[epoch18, step1867]: loss 5.847926
[epoch18, step1868]: loss 11.636546
[epoch18, step1869]: loss 1.211787
[epoch18, step1870]: loss 2.483031
[epoch18, step1871]: loss 3.090040
[epoch18, step1872]: loss 0.684886
[epoch18, step1873]: loss 6.964711
[epoch18, step1874]: loss 0.351555
[epoch18, step1875]: loss 2.868992
[epoch18, step1876]: loss 1.339607
[epoch18, step1877]: loss 2.454873
[epoch18, step1878]: loss 1.341441
[epoch18, step1879]: loss 1.046198
[epoch18, step1880]: loss 22.434855
[epoch18, step1881]: loss 5.707419
[epoch18, step1882]: loss 1.324613
[epoch18, step1883]: loss 0.525918
[epoch18, step1884]: loss 2.414252
[epoch18, step1885]: loss 1.404082
[epoch18, step1886]: loss 0.594762
[epoch18, step1887]: loss 1.713478
[epoch18, step1888]: loss 2.515404
[epoch18, step1889]: loss 5.785393
[epoch18, step1890]: loss 1.848554
[epoch18, step1891]: loss 1.475231
[epoch18, step1892]: loss 0.575074
[epoch18, step1893]: loss 0.895942
[epoch18, step1894]: loss 0.744185
[epoch18, step1895]: loss 1.250757
[epoch18, step1896]: loss 1.908302
[epoch18, step1897]: loss 10.095862
[epoch18, step1898]: loss 6.377775
[epoch18, step1899]: loss 9.453450
[epoch18, step1900]: loss 1.252810
[epoch18, step1901]: loss 1.451719
[epoch18, step1902]: loss 8.522170
[epoch18, step1903]: loss 7.010834
[epoch18, step1904]: loss 1.776302
[epoch18, step1905]: loss 10.803802
[epoch18, step1906]: loss 7.363297
[epoch18, step1907]: loss 3.225700
[epoch18, step1908]: loss 1.845219
[epoch18, step1909]: loss 2.005345
[epoch18, step1910]: loss 5.641295
[epoch18, step1911]: loss 0.667469
[epoch18, step1912]: loss 16.358440
[epoch18, step1913]: loss 10.940753
[epoch18, step1914]: loss 0.561267
[epoch18, step1915]: loss 4.905360
[epoch18, step1916]: loss 2.729403
[epoch18, step1917]: loss 8.958692
[epoch18, step1918]: loss 1.063142
[epoch18, step1919]: loss 2.364964
[epoch18, step1920]: loss 0.997568
[epoch18, step1921]: loss 2.144009
[epoch18, step1922]: loss 4.567972
[epoch18, step1923]: loss 0.605566
[epoch18, step1924]: loss 1.076272
[epoch18, step1925]: loss 3.918147
[epoch18, step1926]: loss 7.556630
[epoch18, step1927]: loss 0.751815
[epoch18, step1928]: loss 13.833362
[epoch18, step1929]: loss 0.839251
[epoch18, step1930]: loss 1.801130
[epoch18, step1931]: loss 0.664519
[epoch18, step1932]: loss 1.002190
[epoch18, step1933]: loss 7.906302
[epoch18, step1934]: loss 0.698275
[epoch18, step1935]: loss 0.911174
[epoch18, step1936]: loss 2.173989
[epoch18, step1937]: loss 5.431637
[epoch18, step1938]: loss 0.707037
[epoch18, step1939]: loss 0.828848
[epoch18, step1940]: loss 0.721729
[epoch18, step1941]: loss 9.890260
[epoch18, step1942]: loss 0.696080
[epoch18, step1943]: loss 6.334572
[epoch18, step1944]: loss 1.094914
[epoch18, step1945]: loss 2.873747
[epoch18, step1946]: loss 0.729513
[epoch18, step1947]: loss 2.256686
[epoch18, step1948]: loss 6.118659
[epoch18, step1949]: loss 14.195706
[epoch18, step1950]: loss 2.348656
[epoch18, step1951]: loss 1.087250
[epoch18, step1952]: loss 2.639312
[epoch18, step1953]: loss 1.242760
[epoch18, step1954]: loss 10.401849
[epoch18, step1955]: loss 0.680995
[epoch18, step1956]: loss 5.670999
[epoch18, step1957]: loss 1.031002
[epoch18, step1958]: loss 0.944803
[epoch18, step1959]: loss 1.911247
[epoch18, step1960]: loss 0.900783
[epoch18, step1961]: loss 0.464074
[epoch18, step1962]: loss 9.316170
[epoch18, step1963]: loss 5.485507
[epoch18, step1964]: loss 7.660645
[epoch18, step1965]: loss 1.973685
[epoch18, step1966]: loss 1.367530
[epoch18, step1967]: loss 1.392218
[epoch18, step1968]: loss 5.252046
[epoch18, step1969]: loss 1.721714
[epoch18, step1970]: loss 2.308510
[epoch18, step1971]: loss 1.521939
[epoch18, step1972]: loss 3.650963
[epoch18, step1973]: loss 6.782167
[epoch18, step1974]: loss 2.655137
[epoch18, step1975]: loss 14.381675
[epoch18, step1976]: loss 1.172292
[epoch18, step1977]: loss 1.197580
[epoch18, step1978]: loss 9.611229
[epoch18, step1979]: loss 14.512644
[epoch18, step1980]: loss 2.642530
[epoch18, step1981]: loss 7.087174
[epoch18, step1982]: loss 1.796350
[epoch18, step1983]: loss 1.899952
[epoch18, step1984]: loss 2.600729
[epoch18, step1985]: loss 7.069539
[epoch18, step1986]: loss 15.784289
[epoch18, step1987]: loss 1.342070
[epoch18, step1988]: loss 1.338340
[epoch18, step1989]: loss 14.311337
[epoch18, step1990]: loss 0.464774
[epoch18, step1991]: loss 0.751807
[epoch18, step1992]: loss 8.393769
[epoch18, step1993]: loss 0.942942
[epoch18, step1994]: loss 2.143982
[epoch18, step1995]: loss 0.521728
[epoch18, step1996]: loss 1.206188
[epoch18, step1997]: loss 11.149547
[epoch18, step1998]: loss 1.459187
[epoch18, step1999]: loss 2.045779
[epoch18, step2000]: loss 11.122563
[epoch18, step2001]: loss 3.891795
[epoch18, step2002]: loss 0.875659
[epoch18, step2003]: loss 1.086451
[epoch18, step2004]: loss 2.069479
[epoch18, step2005]: loss 1.093705
[epoch18, step2006]: loss 0.924643
[epoch18, step2007]: loss 7.120559
[epoch18, step2008]: loss 0.656655
[epoch18, step2009]: loss 6.309260
[epoch18, step2010]: loss 14.730818
[epoch18, step2011]: loss 0.470661
[epoch18, step2012]: loss 2.080270
[epoch18, step2013]: loss 2.064492
[epoch18, step2014]: loss 4.027472
[epoch18, step2015]: loss 0.597498
[epoch18, step2016]: loss 2.214463
[epoch18, step2017]: loss 0.759621
[epoch18, step2018]: loss 11.947189
[epoch18, step2019]: loss 2.653809
[epoch18, step2020]: loss 1.450801
[epoch18, step2021]: loss 0.866310
[epoch18, step2022]: loss 3.455337
[epoch18, step2023]: loss 3.740140
[epoch18, step2024]: loss 4.396353
[epoch18, step2025]: loss 0.694231
[epoch18, step2026]: loss 3.748890
[epoch18, step2027]: loss 1.552281
[epoch18, step2028]: loss 0.529907
[epoch18, step2029]: loss 0.892177
[epoch18, step2030]: loss 14.641170
[epoch18, step2031]: loss 8.367865
[epoch18, step2032]: loss 1.868196
[epoch18, step2033]: loss 3.121603
[epoch18, step2034]: loss 1.187485
[epoch18, step2035]: loss 1.124503
[epoch18, step2036]: loss 11.909871
[epoch18, step2037]: loss 0.617522
[epoch18, step2038]: loss 10.571087
[epoch18, step2039]: loss 0.722759
[epoch18, step2040]: loss 0.490774
[epoch18, step2041]: loss 1.462276
[epoch18, step2042]: loss 1.397251
[epoch18, step2043]: loss 2.446478
[epoch18, step2044]: loss 3.006460
[epoch18, step2045]: loss 1.037549
[epoch18, step2046]: loss 5.595669
[epoch18, step2047]: loss 1.519017
[epoch18, step2048]: loss 8.077610
[epoch18, step2049]: loss 0.875106
[epoch18, step2050]: loss 0.819373
[epoch18, step2051]: loss 1.218569
[epoch18, step2052]: loss 1.471560
[epoch18, step2053]: loss 1.024767
[epoch18, step2054]: loss 0.989387
[epoch18, step2055]: loss 0.644747
[epoch18, step2056]: loss 1.854057
[epoch18, step2057]: loss 0.528712
[epoch18, step2058]: loss 0.615285
[epoch18, step2059]: loss 16.350960
[epoch18, step2060]: loss 0.701313
[epoch18, step2061]: loss 1.406996
[epoch18, step2062]: loss 1.927737
[epoch18, step2063]: loss 12.188612
[epoch18, step2064]: loss 8.298322
[epoch18, step2065]: loss 11.062986
[epoch18, step2066]: loss 3.005015
[epoch18, step2067]: loss 6.387704
[epoch18, step2068]: loss 0.650670
[epoch18, step2069]: loss 1.013284
[epoch18, step2070]: loss 8.673783
[epoch18, step2071]: loss 0.844294
[epoch18, step2072]: loss 0.782197
[epoch18, step2073]: loss 8.843266
[epoch18, step2074]: loss 2.377386
[epoch18, step2075]: loss 0.537329
[epoch18, step2076]: loss 6.104342
[epoch18, step2077]: loss 0.624121
[epoch18, step2078]: loss 7.031271
[epoch18, step2079]: loss 8.012710
[epoch18, step2080]: loss 1.132261
[epoch18, step2081]: loss 5.655198
[epoch18, step2082]: loss 2.353156
[epoch18, step2083]: loss 1.241493
[epoch18, step2084]: loss 8.990355
[epoch18, step2085]: loss 2.599964
[epoch18, step2086]: loss 5.787317
[epoch18, step2087]: loss 0.857516
[epoch18, step2088]: loss 5.835732
[epoch18, step2089]: loss 0.848454
[epoch18, step2090]: loss 5.684324
[epoch18, step2091]: loss 0.736519
[epoch18, step2092]: loss 0.545154
[epoch18, step2093]: loss 11.064598
[epoch18, step2094]: loss 0.720247
[epoch18, step2095]: loss 9.177299
[epoch18, step2096]: loss 5.771262
[epoch18, step2097]: loss 1.505444
[epoch18, step2098]: loss 24.148649
[epoch18, step2099]: loss 0.887795
[epoch18, step2100]: loss 17.159336
[epoch18, step2101]: loss 0.637513
[epoch18, step2102]: loss 2.765256
[epoch18, step2103]: loss 0.880508
[epoch18, step2104]: loss 6.105625
[epoch18, step2105]: loss 0.768367
[epoch18, step2106]: loss 1.618880
[epoch18, step2107]: loss 4.378762
[epoch18, step2108]: loss 0.516919
[epoch18, step2109]: loss 0.923895
[epoch18, step2110]: loss 1.231089
[epoch18, step2111]: loss 0.548965
[epoch18, step2112]: loss 6.360429
[epoch18, step2113]: loss 12.789495
[epoch18, step2114]: loss 0.795843
[epoch18, step2115]: loss 0.845668
[epoch18, step2116]: loss 1.479581
[epoch18, step2117]: loss 2.339018
[epoch18, step2118]: loss 1.164092
[epoch18, step2119]: loss 0.662878
[epoch18, step2120]: loss 1.231420
[epoch18, step2121]: loss 7.112451
[epoch18, step2122]: loss 11.578143
[epoch18, step2123]: loss 0.774322
[epoch18, step2124]: loss 1.287235
[epoch18, step2125]: loss 9.109176
[epoch18, step2126]: loss 0.846771
[epoch18, step2127]: loss 2.151581
[epoch18, step2128]: loss 0.956422
[epoch18, step2129]: loss 5.691450
[epoch18, step2130]: loss 7.764390
[epoch18, step2131]: loss 2.472085
[epoch18, step2132]: loss 2.222988
[epoch18, step2133]: loss 12.033962
[epoch18, step2134]: loss 5.715782
[epoch18, step2135]: loss 11.568858
[epoch18, step2136]: loss 0.534374
[epoch18, step2137]: loss 1.120254
[epoch18, step2138]: loss 7.636554
[epoch18, step2139]: loss 1.872522
[epoch18, step2140]: loss 5.039687
[epoch18, step2141]: loss 9.497025
[epoch18, step2142]: loss 7.510078
[epoch18, step2143]: loss 1.802726
[epoch18, step2144]: loss 0.441241
[epoch18, step2145]: loss 0.804009
[epoch18, step2146]: loss 1.286335
[epoch18, step2147]: loss 2.068569
[epoch18, step2148]: loss 1.274440
[epoch18, step2149]: loss 1.471103
[epoch18, step2150]: loss 0.965460
[epoch18, step2151]: loss 1.109155
[epoch18, step2152]: loss 2.573476
[epoch18, step2153]: loss 0.662021
[epoch18, step2154]: loss 1.232613
[epoch18, step2155]: loss 1.003921
[epoch18, step2156]: loss 5.559836
[epoch18, step2157]: loss 0.571469
[epoch18, step2158]: loss 0.984713
[epoch18, step2159]: loss 1.449364
[epoch18, step2160]: loss 1.542597
[epoch18, step2161]: loss 0.805387
[epoch18, step2162]: loss 2.005888
[epoch18, step2163]: loss 0.626058
[epoch18, step2164]: loss 9.485366
[epoch18, step2165]: loss 8.836431
[epoch18, step2166]: loss 2.275284
[epoch18, step2167]: loss 9.228878
[epoch18, step2168]: loss 0.851996
[epoch18, step2169]: loss 3.119676
[epoch18, step2170]: loss 3.786666
[epoch18, step2171]: loss 1.566866
[epoch18, step2172]: loss 1.551304
[epoch18, step2173]: loss 3.142426
[epoch18, step2174]: loss 12.212480
[epoch18, step2175]: loss 0.659934
[epoch18, step2176]: loss 4.922207
[epoch18, step2177]: loss 2.301372
[epoch18, step2178]: loss 1.288875
[epoch18, step2179]: loss 0.868738
[epoch18, step2180]: loss 9.188194
[epoch18, step2181]: loss 11.644090
[epoch18, step2182]: loss 1.751676
[epoch18, step2183]: loss 0.965335
[epoch18, step2184]: loss 2.091389
[epoch18, step2185]: loss 5.382415
[epoch18, step2186]: loss 0.889187
[epoch18, step2187]: loss 8.133145
[epoch18, step2188]: loss 11.083166
[epoch18, step2189]: loss 0.783185
[epoch18, step2190]: loss 0.503413
[epoch18, step2191]: loss 1.411715
[epoch18, step2192]: loss 11.126317
[epoch18, step2193]: loss 3.938983
[epoch18, step2194]: loss 1.298617
[epoch18, step2195]: loss 0.764225
[epoch18, step2196]: loss 1.504514
[epoch18, step2197]: loss 7.718448
[epoch18, step2198]: loss 1.612264
[epoch18, step2199]: loss 2.302575
[epoch18, step2200]: loss 13.221065
[epoch18, step2201]: loss 1.497689
[epoch18, step2202]: loss 3.611989
[epoch18, step2203]: loss 9.956187
[epoch18, step2204]: loss 7.513758
[epoch18, step2205]: loss 2.979782
[epoch18, step2206]: loss 0.911068
[epoch18, step2207]: loss 8.362755
[epoch18, step2208]: loss 1.673534
[epoch18, step2209]: loss 2.616108
[epoch18, step2210]: loss 2.125285
[epoch18, step2211]: loss 0.728434
[epoch18, step2212]: loss 19.387644
[epoch18, step2213]: loss 5.091825
[epoch18, step2214]: loss 1.053827
[epoch18, step2215]: loss 1.682794
[epoch18, step2216]: loss 0.637004
[epoch18, step2217]: loss 3.091825
[epoch18, step2218]: loss 3.744190
[epoch18, step2219]: loss 11.971806
[epoch18, step2220]: loss 0.603959
[epoch18, step2221]: loss 0.945492
[epoch18, step2222]: loss 0.477736
[epoch18, step2223]: loss 12.328300
[epoch18, step2224]: loss 8.792656
[epoch18, step2225]: loss 1.045638
[epoch18, step2226]: loss 0.839344
[epoch18, step2227]: loss 3.059752
[epoch18, step2228]: loss 9.329985
[epoch18, step2229]: loss 0.567917
[epoch18, step2230]: loss 2.630760
[epoch18, step2231]: loss 0.497826
[epoch18, step2232]: loss 0.887363
[epoch18, step2233]: loss 2.088272
[epoch18, step2234]: loss 1.096905
[epoch18, step2235]: loss 0.752833
[epoch18, step2236]: loss 7.340379
[epoch18, step2237]: loss 1.242787
[epoch18, step2238]: loss 10.503236
[epoch18, step2239]: loss 0.422052
[epoch18, step2240]: loss 9.958745
[epoch18, step2241]: loss 3.953086
[epoch18, step2242]: loss 6.984524
[epoch18, step2243]: loss 9.456516
[epoch18, step2244]: loss 0.771440
[epoch18, step2245]: loss 6.371811
[epoch18, step2246]: loss 0.588739
[epoch18, step2247]: loss 1.032399
[epoch18, step2248]: loss 6.916779
[epoch18, step2249]: loss 1.332097
[epoch18, step2250]: loss 2.675137
[epoch18, step2251]: loss 0.495761
[epoch18, step2252]: loss 0.517270
[epoch18, step2253]: loss 0.777205
[epoch18, step2254]: loss 1.429898
[epoch18, step2255]: loss 0.604182
[epoch18, step2256]: loss 0.640115
[epoch18, step2257]: loss 0.629709
[epoch18, step2258]: loss 12.505069
[epoch18, step2259]: loss 2.860899
[epoch18, step2260]: loss 1.785985
[epoch18, step2261]: loss 1.877903
[epoch18, step2262]: loss 0.823782
[epoch18, step2263]: loss 1.716134
[epoch18, step2264]: loss 2.184556
[epoch18, step2265]: loss 13.620187
[epoch18, step2266]: loss 1.420067
[epoch18, step2267]: loss 0.652403
[epoch18, step2268]: loss 0.852428
[epoch18, step2269]: loss 20.098471
[epoch18, step2270]: loss 0.553290
[epoch18, step2271]: loss 0.799972
[epoch18, step2272]: loss 2.050499
[epoch18, step2273]: loss 2.448637
[epoch18, step2274]: loss 2.938040
[epoch18, step2275]: loss 9.149929
[epoch18, step2276]: loss 7.081585
[epoch18, step2277]: loss 9.007879
[epoch18, step2278]: loss 1.500749
[epoch18, step2279]: loss 0.702027
[epoch18, step2280]: loss 1.138098
[epoch18, step2281]: loss 2.615445
[epoch18, step2282]: loss 1.377994
[epoch18, step2283]: loss 1.559272
[epoch18, step2284]: loss 6.451475
[epoch18, step2285]: loss 0.469258
[epoch18, step2286]: loss 0.575911
[epoch18, step2287]: loss 0.509228
[epoch18, step2288]: loss 6.088441
[epoch18, step2289]: loss 1.157247
[epoch18, step2290]: loss 2.089062
[epoch18, step2291]: loss 2.854530
[epoch18, step2292]: loss 0.842816
[epoch18, step2293]: loss 2.284259
[epoch18, step2294]: loss 0.538220
[epoch18, step2295]: loss 0.879025
[epoch18, step2296]: loss 3.690230
[epoch18, step2297]: loss 0.759048
[epoch18, step2298]: loss 5.918748
[epoch18, step2299]: loss 1.690826
[epoch18, step2300]: loss 7.064682
[epoch18, step2301]: loss 8.437677
[epoch18, step2302]: loss 0.963453
[epoch18, step2303]: loss 0.554206
[epoch18, step2304]: loss 6.221839
[epoch18, step2305]: loss 0.746073
[epoch18, step2306]: loss 0.852736
[epoch18, step2307]: loss 4.128603
[epoch18, step2308]: loss 3.376859
[epoch18, step2309]: loss 11.192685
[epoch18, step2310]: loss 0.547727
[epoch18, step2311]: loss 0.946869
[epoch18, step2312]: loss 1.105139
[epoch18, step2313]: loss 0.883685
[epoch18, step2314]: loss 2.921537
[epoch18, step2315]: loss 1.176939
[epoch18, step2316]: loss 0.854998
[epoch18, step2317]: loss 1.715728
[epoch18, step2318]: loss 8.489681
[epoch18, step2319]: loss 7.257516
[epoch18, step2320]: loss 3.487405
[epoch18, step2321]: loss 9.128550
[epoch18, step2322]: loss 0.639847
[epoch18, step2323]: loss 2.462533
[epoch18, step2324]: loss 0.607276
[epoch18, step2325]: loss 5.497739
[epoch18, step2326]: loss 1.040491
[epoch18, step2327]: loss 1.217664
[epoch18, step2328]: loss 2.277478
[epoch18, step2329]: loss 4.001724
[epoch18, step2330]: loss 5.969202
[epoch18, step2331]: loss 1.522551
[epoch18, step2332]: loss 0.994542
[epoch18, step2333]: loss 1.809207
[epoch18, step2334]: loss 1.301471
[epoch18, step2335]: loss 0.954702
[epoch18, step2336]: loss 0.908603
[epoch18, step2337]: loss 2.204369
[epoch18, step2338]: loss 1.878601
[epoch18, step2339]: loss 0.789323
[epoch18, step2340]: loss 0.702714
[epoch18, step2341]: loss 9.739861
[epoch18, step2342]: loss 0.949080
[epoch18, step2343]: loss 1.176749
[epoch18, step2344]: loss 1.746359
[epoch18, step2345]: loss 2.670194
[epoch18, step2346]: loss 0.919108
[epoch18, step2347]: loss 2.484523
[epoch18, step2348]: loss 0.776436
[epoch18, step2349]: loss 1.809794
[epoch18, step2350]: loss 0.580128
[epoch18, step2351]: loss 5.690004
[epoch18, step2352]: loss 0.509288
[epoch18, step2353]: loss 0.762802
[epoch18, step2354]: loss 6.810118
[epoch18, step2355]: loss 2.183414
[epoch18, step2356]: loss 11.939823
[epoch18, step2357]: loss 5.760250
[epoch18, step2358]: loss 12.798764
[epoch18, step2359]: loss 2.441402
[epoch18, step2360]: loss 3.552177
[epoch18, step2361]: loss 0.812028
[epoch18, step2362]: loss 1.571085
[epoch18, step2363]: loss 1.794526
[epoch18, step2364]: loss 5.556701
[epoch18, step2365]: loss 6.255340
[epoch18, step2366]: loss 13.070360
[epoch18, step2367]: loss 9.496182
[epoch18, step2368]: loss 2.601246
[epoch18, step2369]: loss 2.662091
[epoch18, step2370]: loss 2.483323
[epoch18, step2371]: loss 0.946922
[epoch18, step2372]: loss 0.644411
[epoch18, step2373]: loss 1.746981
[epoch18, step2374]: loss 8.199175
[epoch18, step2375]: loss 2.124588
[epoch18, step2376]: loss 8.272679
[epoch18, step2377]: loss 8.142544
[epoch18, step2378]: loss 3.178380
[epoch18, step2379]: loss 6.305857
[epoch18, step2380]: loss 0.670693
[epoch18, step2381]: loss 6.718559
[epoch18, step2382]: loss 2.252368
[epoch18, step2383]: loss 3.162142
[epoch18, step2384]: loss 6.669014
[epoch18, step2385]: loss 1.156907
[epoch18, step2386]: loss 9.074008
[epoch18, step2387]: loss 8.757793
[epoch18, step2388]: loss 4.599971
[epoch18, step2389]: loss 1.617333
[epoch18, step2390]: loss 19.332981
[epoch18, step2391]: loss 3.171218
[epoch18, step2392]: loss 6.180791
[epoch18, step2393]: loss 0.833723
[epoch18, step2394]: loss 10.023357
[epoch18, step2395]: loss 0.989261
[epoch18, step2396]: loss 0.911309
[epoch18, step2397]: loss 0.587682
[epoch18, step2398]: loss 6.151020
[epoch18, step2399]: loss 11.200581
[epoch18, step2400]: loss 2.943827
[epoch18, step2401]: loss 5.615213
[epoch18, step2402]: loss 1.596444
[epoch18, step2403]: loss 1.239075
[epoch18, step2404]: loss 2.274103
[epoch18, step2405]: loss 0.702795
[epoch18, step2406]: loss 0.846772
[epoch18, step2407]: loss 2.426830
[epoch18, step2408]: loss 1.281286
[epoch18, step2409]: loss 0.545019
[epoch18, step2410]: loss 3.351653
[epoch18, step2411]: loss 0.746471
[epoch18, step2412]: loss 1.122552
[epoch18, step2413]: loss 0.843234
[epoch18, step2414]: loss 1.949399
[epoch18, step2415]: loss 0.719036
[epoch18, step2416]: loss 0.877427
[epoch18, step2417]: loss 0.931082
[epoch18, step2418]: loss 1.410318
[epoch18, step2419]: loss 1.279457
[epoch18, step2420]: loss 0.756532
[epoch18, step2421]: loss 0.681871
[epoch18, step2422]: loss 1.538762
[epoch18, step2423]: loss 1.098187
[epoch18, step2424]: loss 0.551410
[epoch18, step2425]: loss 6.598642
[epoch18, step2426]: loss 1.537084
[epoch18, step2427]: loss 9.708682
[epoch18, step2428]: loss 7.576692
[epoch18, step2429]: loss 1.020240
[epoch18, step2430]: loss 6.370101
[epoch18, step2431]: loss 1.314304
[epoch18, step2432]: loss 1.122039
[epoch18, step2433]: loss 0.440429
[epoch18, step2434]: loss 7.072334
[epoch18, step2435]: loss 1.838570
[epoch18, step2436]: loss 0.607673
[epoch18, step2437]: loss 1.569186
[epoch18, step2438]: loss 0.643410
[epoch18, step2439]: loss 5.399896
[epoch18, step2440]: loss 5.894373
[epoch18, step2441]: loss 4.896195
[epoch18, step2442]: loss 6.538633
[epoch18, step2443]: loss 1.044728
[epoch18, step2444]: loss 2.481739
[epoch18, step2445]: loss 0.768923
[epoch18, step2446]: loss 2.429117
[epoch18, step2447]: loss 1.290401
[epoch18, step2448]: loss 11.613558
[epoch18, step2449]: loss 7.523577
[epoch18, step2450]: loss 3.333560
[epoch18, step2451]: loss 1.275031
[epoch18, step2452]: loss 10.323952
[epoch18, step2453]: loss 0.633278
[epoch18, step2454]: loss 15.448047
[epoch18, step2455]: loss 1.935368
[epoch18, step2456]: loss 7.942568
[epoch18, step2457]: loss 3.065680
[epoch18, step2458]: loss 1.350451
[epoch18, step2459]: loss 0.874026
[epoch18, step2460]: loss 0.655991
[epoch18, step2461]: loss 0.740673
[epoch18, step2462]: loss 6.797959
[epoch18, step2463]: loss 0.771618
[epoch18, step2464]: loss 17.550014
[epoch18, step2465]: loss 6.110435
[epoch18, step2466]: loss 10.983599
[epoch18, step2467]: loss 2.843198
[epoch18, step2468]: loss 8.795057
[epoch18, step2469]: loss 1.225636
[epoch18, step2470]: loss 7.269449
[epoch18, step2471]: loss 0.932555
[epoch18, step2472]: loss 7.805355
[epoch18, step2473]: loss 2.995364
[epoch18, step2474]: loss 10.194258
[epoch18, step2475]: loss 8.207600
[epoch18, step2476]: loss 1.020257
[epoch18, step2477]: loss 1.141006
[epoch18, step2478]: loss 0.580363
[epoch18, step2479]: loss 1.664745
[epoch18, step2480]: loss 8.959744
[epoch18, step2481]: loss 0.446502
[epoch18, step2482]: loss 5.210740
[epoch18, step2483]: loss 9.656389
[epoch18, step2484]: loss 1.583995
[epoch18, step2485]: loss 0.862876
[epoch18, step2486]: loss 6.489755
[epoch18, step2487]: loss 0.497408
[epoch18, step2488]: loss 0.585709
[epoch18, step2489]: loss 1.953432
[epoch18, step2490]: loss 0.647609
[epoch18, step2491]: loss 0.874778
[epoch18, step2492]: loss 1.217765
[epoch18, step2493]: loss 2.646254
[epoch18, step2494]: loss 1.522748
[epoch18, step2495]: loss 0.692503
[epoch18, step2496]: loss 0.933686
[epoch18, step2497]: loss 6.516429
[epoch18, step2498]: loss 6.153656
[epoch18, step2499]: loss 1.674132
[epoch18, step2500]: loss 2.242634
[epoch18, step2501]: loss 0.894072
[epoch18, step2502]: loss 6.100657
[epoch18, step2503]: loss 0.821229
[epoch18, step2504]: loss 1.759666
[epoch18, step2505]: loss 2.017349
[epoch18, step2506]: loss 0.509267
[epoch18, step2507]: loss 9.446295
[epoch18, step2508]: loss 0.732277
[epoch18, step2509]: loss 0.611423
[epoch18, step2510]: loss 0.854260
[epoch18, step2511]: loss 0.482392
[epoch18, step2512]: loss 3.368653
[epoch18, step2513]: loss 2.903852
[epoch18, step2514]: loss 1.040459
[epoch18, step2515]: loss 2.180855
[epoch18, step2516]: loss 1.789435
[epoch18, step2517]: loss 0.517810
[epoch18, step2518]: loss 6.207955
[epoch18, step2519]: loss 1.222040
[epoch18, step2520]: loss 1.136710
[epoch18, step2521]: loss 1.022781
[epoch18, step2522]: loss 9.044494
[epoch18, step2523]: loss 2.292397
[epoch18, step2524]: loss 9.433554
[epoch18, step2525]: loss 1.499390
[epoch18, step2526]: loss 2.738153
[epoch18, step2527]: loss 1.259648
[epoch18, step2528]: loss 0.528323
[epoch18, step2529]: loss 0.778412
[epoch18, step2530]: loss 11.753583
[epoch18, step2531]: loss 3.425188
[epoch18, step2532]: loss 1.026815
[epoch18, step2533]: loss 6.349775
[epoch18, step2534]: loss 1.132604
[epoch18, step2535]: loss 2.902124
[epoch18, step2536]: loss 9.890495
[epoch18, step2537]: loss 0.992937
[epoch18, step2538]: loss 1.101490
[epoch18, step2539]: loss 3.460427
[epoch18, step2540]: loss 1.588244
[epoch18, step2541]: loss 7.702518
[epoch18, step2542]: loss 2.365463
[epoch18, step2543]: loss 4.104349
[epoch18, step2544]: loss 0.742953
[epoch18, step2545]: loss 10.319263
[epoch18, step2546]: loss 1.304698
[epoch18, step2547]: loss 1.489772
[epoch18, step2548]: loss 12.182042
[epoch18, step2549]: loss 0.908625
[epoch18, step2550]: loss 2.321007
[epoch18, step2551]: loss 1.967113
[epoch18, step2552]: loss 6.826164
[epoch18, step2553]: loss 1.031481
[epoch18, step2554]: loss 0.945008
[epoch18, step2555]: loss 0.579372
[epoch18, step2556]: loss 0.697482
[epoch18, step2557]: loss 9.031776
[epoch18, step2558]: loss 3.184543
[epoch18, step2559]: loss 9.587723
[epoch18, step2560]: loss 3.233503
[epoch18, step2561]: loss 2.411522
[epoch18, step2562]: loss 7.321063
[epoch18, step2563]: loss 6.635819
[epoch18, step2564]: loss 1.338080
[epoch18, step2565]: loss 2.183187
[epoch18, step2566]: loss 1.514640
[epoch18, step2567]: loss 2.667961
[epoch18, step2568]: loss 2.047940
[epoch18, step2569]: loss 3.548632
[epoch18, step2570]: loss 0.402462
[epoch18, step2571]: loss 1.798915
[epoch18, step2572]: loss 1.209452
[epoch18, step2573]: loss 0.655567
[epoch18, step2574]: loss 0.595561
[epoch18, step2575]: loss 2.912480
[epoch18, step2576]: loss 5.209061
[epoch18, step2577]: loss 11.573572
[epoch18, step2578]: loss 0.743943
[epoch18, step2579]: loss 2.031107
[epoch18, step2580]: loss 9.115679
[epoch18, step2581]: loss 0.719497
[epoch18, step2582]: loss 3.452234
[epoch18, step2583]: loss 1.698233
[epoch18, step2584]: loss 1.313359
[epoch18, step2585]: loss 0.503589
[epoch18, step2586]: loss 1.254001
[epoch18, step2587]: loss 7.734056
[epoch18, step2588]: loss 1.128997
[epoch18, step2589]: loss 11.086280
[epoch18, step2590]: loss 13.975417
[epoch18, step2591]: loss 1.243217
[epoch18, step2592]: loss 5.793354
[epoch18, step2593]: loss 3.182155
[epoch18, step2594]: loss 9.268687
[epoch18, step2595]: loss 8.432365
[epoch18, step2596]: loss 2.658090
[epoch18, step2597]: loss 0.362290
[epoch18, step2598]: loss 1.102729
[epoch18, step2599]: loss 2.231519
[epoch18, step2600]: loss 5.902978
[epoch18, step2601]: loss 6.691693
[epoch18, step2602]: loss 5.617035
[epoch18, step2603]: loss 2.556843
[epoch18, step2604]: loss 2.540873
[epoch18, step2605]: loss 2.248430
[epoch18, step2606]: loss 10.033775
[epoch18, step2607]: loss 1.102049
[epoch18, step2608]: loss 1.461795
[epoch18, step2609]: loss 0.764666
[epoch18, step2610]: loss 0.811807
[epoch18, step2611]: loss 1.004574
[epoch18, step2612]: loss 2.263124
[epoch18, step2613]: loss 0.942261
[epoch18, step2614]: loss 1.592237
[epoch18, step2615]: loss 5.704022
[epoch18, step2616]: loss 1.058976
[epoch18, step2617]: loss 12.917100
[epoch18, step2618]: loss 1.127243
[epoch18, step2619]: loss 1.082502
[epoch18, step2620]: loss 5.272894
[epoch18, step2621]: loss 7.372330
[epoch18, step2622]: loss 2.347617
[epoch18, step2623]: loss 2.534668
[epoch18, step2624]: loss 1.246570
[epoch18, step2625]: loss 11.559888
[epoch18, step2626]: loss 2.545216
[epoch18, step2627]: loss 2.053051
[epoch18, step2628]: loss 1.379571
[epoch18, step2629]: loss 0.709459
[epoch18, step2630]: loss 1.723514
[epoch18, step2631]: loss 7.357063
[epoch18, step2632]: loss 6.742723
[epoch18, step2633]: loss 9.500992
[epoch18, step2634]: loss 1.822173
[epoch18, step2635]: loss 1.180712
[epoch18, step2636]: loss 5.299869
[epoch18, step2637]: loss 1.560455
[epoch18, step2638]: loss 5.458960
[epoch18, step2639]: loss 0.482016
[epoch18, step2640]: loss 0.678303
[epoch18, step2641]: loss 2.149841
[epoch18, step2642]: loss 1.042171
[epoch18, step2643]: loss 5.703554
[epoch18, step2644]: loss 0.712523
[epoch18, step2645]: loss 5.679034
[epoch18, step2646]: loss 0.682538
[epoch18, step2647]: loss 2.583392
[epoch18, step2648]: loss 1.952390
[epoch18, step2649]: loss 3.109586
[epoch18, step2650]: loss 0.788960
[epoch18, step2651]: loss 1.690584
[epoch18, step2652]: loss 3.158942
[epoch18, step2653]: loss 1.632911
[epoch18, step2654]: loss 1.591932
[epoch18, step2655]: loss 0.556143
[epoch18, step2656]: loss 0.999929
[epoch18, step2657]: loss 4.788618
[epoch18, step2658]: loss 0.956510
[epoch18, step2659]: loss 1.441553
[epoch18, step2660]: loss 0.459706
[epoch18, step2661]: loss 12.759692
[epoch18, step2662]: loss 6.667493
[epoch18, step2663]: loss 1.083330
[epoch18, step2664]: loss 0.982609
[epoch18, step2665]: loss 1.187198
[epoch18, step2666]: loss 0.617077
[epoch18, step2667]: loss 0.921619
[epoch18, step2668]: loss 8.422396
[epoch18, step2669]: loss 0.499377
[epoch18, step2670]: loss 1.744973
[epoch18, step2671]: loss 1.125767
[epoch18, step2672]: loss 3.903897
[epoch18, step2673]: loss 6.222207
[epoch18, step2674]: loss 4.751666
[epoch18, step2675]: loss 0.929376
[epoch18, step2676]: loss 7.099030
[epoch18, step2677]: loss 6.117814
[epoch18, step2678]: loss 10.320273
[epoch18, step2679]: loss 7.006658
[epoch18, step2680]: loss 0.941729
[epoch18, step2681]: loss 5.283255
[epoch18, step2682]: loss 0.654402
[epoch18, step2683]: loss 0.840288
[epoch18, step2684]: loss 9.710709
[epoch18, step2685]: loss 2.955434
[epoch18, step2686]: loss 0.629079
[epoch18, step2687]: loss 14.256151
[epoch18, step2688]: loss 0.705965
[epoch18, step2689]: loss 10.076238
[epoch18, step2690]: loss 1.299190
[epoch18, step2691]: loss 1.828272
[epoch18, step2692]: loss 10.634094
[epoch18, step2693]: loss 6.434322
[epoch18, step2694]: loss 1.190951
[epoch18, step2695]: loss 3.793033
[epoch18, step2696]: loss 1.108917
[epoch18, step2697]: loss 1.249545
[epoch18, step2698]: loss 9.178592
[epoch18, step2699]: loss 11.100633
[epoch18, step2700]: loss 14.491664
[epoch18, step2701]: loss 0.928857
[epoch18, step2702]: loss 0.602571
[epoch18, step2703]: loss 1.541449
[epoch18, step2704]: loss 8.172389
[epoch18, step2705]: loss 5.639837
[epoch18, step2706]: loss 1.298897
[epoch18, step2707]: loss 0.637320
[epoch18, step2708]: loss 1.401001
[epoch18, step2709]: loss 0.782656
[epoch18, step2710]: loss 3.736622
[epoch18, step2711]: loss 1.747770
[epoch18, step2712]: loss 0.967753
[epoch18, step2713]: loss 3.079682
[epoch18, step2714]: loss 5.213616
[epoch18, step2715]: loss 3.177455
[epoch18, step2716]: loss 0.520597
[epoch18, step2717]: loss 2.282343
[epoch18, step2718]: loss 1.974862
[epoch18, step2719]: loss 2.770517
[epoch18, step2720]: loss 11.635423
[epoch18, step2721]: loss 2.194933
[epoch18, step2722]: loss 2.800296
[epoch18, step2723]: loss 1.675098
[epoch18, step2724]: loss 1.029585
[epoch18, step2725]: loss 4.939327
[epoch18, step2726]: loss 11.042520
[epoch18, step2727]: loss 1.539182
[epoch18, step2728]: loss 1.072844
[epoch18, step2729]: loss 0.434928
[epoch18, step2730]: loss 1.434240
[epoch18, step2731]: loss 3.358305
[epoch18, step2732]: loss 0.807267
[epoch18, step2733]: loss 0.732976
[epoch18, step2734]: loss 1.143900
[epoch18, step2735]: loss 0.644523
[epoch18, step2736]: loss 1.269264
[epoch18, step2737]: loss 5.112323
[epoch18, step2738]: loss 6.660105
[epoch18, step2739]: loss 1.938880
[epoch18, step2740]: loss 13.979930
[epoch18, step2741]: loss 5.746968
[epoch18, step2742]: loss 0.578611
[epoch18, step2743]: loss 5.043573
[epoch18, step2744]: loss 1.871095
[epoch18, step2745]: loss 3.453352
[epoch18, step2746]: loss 1.726558
[epoch18, step2747]: loss 0.556720
[epoch18, step2748]: loss 5.976494
[epoch18, step2749]: loss 0.693349
[epoch18, step2750]: loss 12.992120
[epoch18, step2751]: loss 5.342074
[epoch18, step2752]: loss 0.506228
[epoch18, step2753]: loss 6.420071
[epoch18, step2754]: loss 1.107766
[epoch18, step2755]: loss 0.460467
[epoch18, step2756]: loss 1.670231
[epoch18, step2757]: loss 9.101035
[epoch18, step2758]: loss 0.702106
[epoch18, step2759]: loss 1.021820
[epoch18, step2760]: loss 2.470735
[epoch18, step2761]: loss 0.749032
[epoch18, step2762]: loss 1.926996
[epoch18, step2763]: loss 0.525960
[epoch18, step2764]: loss 0.945293
[epoch18, step2765]: loss 1.529905
[epoch18, step2766]: loss 10.761998
[epoch18, step2767]: loss 0.950336
[epoch18, step2768]: loss 0.891817
[epoch18, step2769]: loss 0.443648
[epoch18, step2770]: loss 2.798968
[epoch18, step2771]: loss 0.916853
[epoch18, step2772]: loss 1.116269
[epoch18, step2773]: loss 0.350844
[epoch18, step2774]: loss 0.849356
[epoch18, step2775]: loss 2.901973
[epoch18, step2776]: loss 0.957385
[epoch18, step2777]: loss 0.986351
[epoch18, step2778]: loss 0.871214
[epoch18, step2779]: loss 10.570024
[epoch18, step2780]: loss 2.091607
[epoch18, step2781]: loss 2.137694
[epoch18, step2782]: loss 1.278179
[epoch18, step2783]: loss 1.428437
[epoch18, step2784]: loss 0.971287
[epoch18, step2785]: loss 1.211347
[epoch18, step2786]: loss 13.282540
[epoch18, step2787]: loss 1.066216
[epoch18, step2788]: loss 6.836409
[epoch18, step2789]: loss 4.083037
[epoch18, step2790]: loss 6.787446
[epoch18, step2791]: loss 5.681740
[epoch18, step2792]: loss 5.021385
[epoch18, step2793]: loss 1.811450
[epoch18, step2794]: loss 9.308623
[epoch18, step2795]: loss 1.340578
[epoch18, step2796]: loss 1.147627
[epoch18, step2797]: loss 2.283147
[epoch18, step2798]: loss 1.155796
[epoch18, step2799]: loss 0.977647
[epoch18, step2800]: loss 1.727141
[epoch18, step2801]: loss 4.626612
[epoch18, step2802]: loss 1.132178
[epoch18, step2803]: loss 5.498805
[epoch18, step2804]: loss 0.898868
[epoch18, step2805]: loss 3.091012
[epoch18, step2806]: loss 8.905768
[epoch18, step2807]: loss 2.070293
[epoch18, step2808]: loss 10.090787
[epoch18, step2809]: loss 2.275675
[epoch18, step2810]: loss 5.733541
[epoch18, step2811]: loss 1.250613
[epoch18, step2812]: loss 0.915326
[epoch18, step2813]: loss 2.395808
[epoch18, step2814]: loss 2.213673
[epoch18, step2815]: loss 0.653030
[epoch18, step2816]: loss 20.395184
[epoch18, step2817]: loss 17.580051
[epoch18, step2818]: loss 7.426884
[epoch18, step2819]: loss 1.221267
[epoch18, step2820]: loss 10.250437
[epoch18, step2821]: loss 3.265829
[epoch18, step2822]: loss 0.761629
[epoch18, step2823]: loss 1.999003
[epoch18, step2824]: loss 1.720971
[epoch18, step2825]: loss 1.394127
[epoch18, step2826]: loss 0.960391
[epoch18, step2827]: loss 2.044889
[epoch18, step2828]: loss 1.747325
[epoch18, step2829]: loss 2.819004
[epoch18, step2830]: loss 1.143068
[epoch18, step2831]: loss 1.871124
[epoch18, step2832]: loss 0.698003
[epoch18, step2833]: loss 0.591202
[epoch18, step2834]: loss 3.263361
[epoch18, step2835]: loss 2.143822
[epoch18, step2836]: loss 1.921415
[epoch18, step2837]: loss 5.579552
[epoch18, step2838]: loss 0.959034
[epoch18, step2839]: loss 0.979648
[epoch18, step2840]: loss 0.557821
[epoch18, step2841]: loss 6.415620
[epoch18, step2842]: loss 15.611197
[epoch18, step2843]: loss 0.893562
[epoch18, step2844]: loss 3.028515
[epoch18, step2845]: loss 1.578000
[epoch18, step2846]: loss 1.359272
[epoch18, step2847]: loss 0.695309
[epoch18, step2848]: loss 0.801724
[epoch18, step2849]: loss 6.933541
[epoch18, step2850]: loss 1.040241
[epoch18, step2851]: loss 2.446360
[epoch18, step2852]: loss 1.072600
[epoch18, step2853]: loss 9.610970
[epoch18, step2854]: loss 0.770714
[epoch18, step2855]: loss 10.758354
[epoch18, step2856]: loss 9.721349
[epoch18, step2857]: loss 1.460200
[epoch18, step2858]: loss 4.029844
[epoch18, step2859]: loss 2.353109
[epoch18, step2860]: loss 3.062858
[epoch18, step2861]: loss 1.149578
[epoch18, step2862]: loss 0.666357
[epoch18, step2863]: loss 3.889949
[epoch18, step2864]: loss 2.002168
[epoch18, step2865]: loss 0.749368
[epoch18, step2866]: loss 0.956235
[epoch18, step2867]: loss 1.436722
[epoch18, step2868]: loss 1.003588
[epoch18, step2869]: loss 10.683382
[epoch18, step2870]: loss 1.544377
[epoch18, step2871]: loss 14.071808
[epoch18, step2872]: loss 0.550224
[epoch18, step2873]: loss 6.614587
[epoch18, step2874]: loss 1.094062
[epoch18, step2875]: loss 12.224316
[epoch18, step2876]: loss 2.415131
[epoch18, step2877]: loss 1.632899
[epoch18, step2878]: loss 0.907129
[epoch18, step2879]: loss 0.764101
[epoch18, step2880]: loss 2.025703
[epoch18, step2881]: loss 11.135695
[epoch18, step2882]: loss 9.463537
[epoch18, step2883]: loss 10.418626
[epoch18, step2884]: loss 1.008440
[epoch18, step2885]: loss 0.719413
[epoch18, step2886]: loss 8.277203
[epoch18, step2887]: loss 1.404989
[epoch18, step2888]: loss 1.082681
[epoch18, step2889]: loss 2.414180
[epoch18, step2890]: loss 2.010612
[epoch18, step2891]: loss 1.109795
[epoch18, step2892]: loss 6.835660
[epoch18, step2893]: loss 5.911816
[epoch18, step2894]: loss 8.684536
[epoch18, step2895]: loss 6.672950
[epoch18, step2896]: loss 1.059661
[epoch18, step2897]: loss 1.541302
[epoch18, step2898]: loss 1.899784
[epoch18, step2899]: loss 2.507213
[epoch18, step2900]: loss 0.631809
[epoch18, step2901]: loss 2.572479
[epoch18, step2902]: loss 0.766268
[epoch18, step2903]: loss 0.714872
[epoch18, step2904]: loss 0.692667
[epoch18, step2905]: loss 5.536013
[epoch18, step2906]: loss 6.553373
[epoch18, step2907]: loss 0.568022
[epoch18, step2908]: loss 2.386162
[epoch18, step2909]: loss 11.519734
[epoch18, step2910]: loss 1.862108
[epoch18, step2911]: loss 8.155392
[epoch18, step2912]: loss 1.631844
[epoch18, step2913]: loss 8.124043
[epoch18, step2914]: loss 11.195503
[epoch18, step2915]: loss 1.830946
[epoch18, step2916]: loss 0.902711
[epoch18, step2917]: loss 12.792807
[epoch18, step2918]: loss 13.745741
[epoch18, step2919]: loss 9.453413
[epoch18, step2920]: loss 1.544293
[epoch18, step2921]: loss 0.617954
[epoch18, step2922]: loss 0.566456
[epoch18, step2923]: loss 1.118750
[epoch18, step2924]: loss 5.213167
[epoch18, step2925]: loss 1.804309
[epoch18, step2926]: loss 0.794030
[epoch18, step2927]: loss 0.909796
[epoch18, step2928]: loss 6.322162
[epoch18, step2929]: loss 11.160971
[epoch18, step2930]: loss 0.743273
[epoch18, step2931]: loss 1.766348
[epoch18, step2932]: loss 2.597916
[epoch18, step2933]: loss 0.871035
[epoch18, step2934]: loss 0.766599
[epoch18, step2935]: loss 0.609782
[epoch18, step2936]: loss 1.689705
[epoch18, step2937]: loss 0.700588
[epoch18, step2938]: loss 1.320801
[epoch18, step2939]: loss 1.050130
[epoch18, step2940]: loss 13.543633
[epoch18, step2941]: loss 0.994624
[epoch18, step2942]: loss 0.449179
[epoch18, step2943]: loss 0.687816
[epoch18, step2944]: loss 6.504700
[epoch18, step2945]: loss 12.144865
[epoch18, step2946]: loss 11.161450
[epoch18, step2947]: loss 0.871361
[epoch18, step2948]: loss 2.326889
[epoch18, step2949]: loss 1.422902
[epoch18, step2950]: loss 2.377070
[epoch18, step2951]: loss 1.225140
[epoch18, step2952]: loss 0.957936
[epoch18, step2953]: loss 8.078940
[epoch18, step2954]: loss 1.169126
[epoch18, step2955]: loss 1.613717
[epoch18, step2956]: loss 0.939953
[epoch18, step2957]: loss 0.892039
[epoch18, step2958]: loss 7.116620
[epoch18, step2959]: loss 1.942957
[epoch18, step2960]: loss 5.926542
[epoch18, step2961]: loss 9.672200
[epoch18, step2962]: loss 1.007744
[epoch18, step2963]: loss 0.833995
[epoch18, step2964]: loss 1.276136
[epoch18, step2965]: loss 2.423715
[epoch18, step2966]: loss 5.044670
[epoch18, step2967]: loss 1.228897
[epoch18, step2968]: loss 12.734294
[epoch18, step2969]: loss 1.411874
[epoch18, step2970]: loss 1.858768
[epoch18, step2971]: loss 1.005960
[epoch18, step2972]: loss 1.201321
[epoch18, step2973]: loss 0.898670
[epoch18, step2974]: loss 0.928247
[epoch18, step2975]: loss 2.052836
[epoch18, step2976]: loss 0.786369
[epoch18, step2977]: loss 1.266547
[epoch18, step2978]: loss 1.194725
[epoch18, step2979]: loss 2.002440
[epoch18, step2980]: loss 0.883091
[epoch18, step2981]: loss 2.973109
[epoch18, step2982]: loss 2.446633
[epoch18, step2983]: loss 6.536719
[epoch18, step2984]: loss 1.593707
[epoch18, step2985]: loss 3.554655
[epoch18, step2986]: loss 8.285273
[epoch18, step2987]: loss 2.329896
[epoch18, step2988]: loss 0.584506
[epoch18, step2989]: loss 7.442045
[epoch18, step2990]: loss 2.172365
[epoch18, step2991]: loss 0.926010
[epoch18, step2992]: loss 12.125511
[epoch18, step2993]: loss 1.160170
[epoch18, step2994]: loss 1.246877
[epoch18, step2995]: loss 1.067848
[epoch18, step2996]: loss 1.113459
[epoch18, step2997]: loss 1.118826
[epoch18, step2998]: loss 6.026756
[epoch18, step2999]: loss 8.477627
[epoch18, step3000]: loss 8.834891
[epoch18, step3001]: loss 1.181691
[epoch18, step3002]: loss 1.261496
[epoch18, step3003]: loss 1.046929
[epoch18, step3004]: loss 0.678260
[epoch18, step3005]: loss 0.617331
[epoch18, step3006]: loss 0.782203
[epoch18, step3007]: loss 1.310155
[epoch18, step3008]: loss 5.750544
[epoch18, step3009]: loss 0.886787
[epoch18, step3010]: loss 1.282281
[epoch18, step3011]: loss 8.591151
[epoch18, step3012]: loss 1.946116
[epoch18, step3013]: loss 0.544849
[epoch18, step3014]: loss 7.670902
[epoch18, step3015]: loss 1.256416
[epoch18, step3016]: loss 2.550904
[epoch18, step3017]: loss 4.268014
[epoch18, step3018]: loss 2.293817
[epoch18, step3019]: loss 4.631063
[epoch18, step3020]: loss 1.322572
[epoch18, step3021]: loss 2.678736
[epoch18, step3022]: loss 2.230505
[epoch18, step3023]: loss 9.200394
[epoch18, step3024]: loss 7.203022
[epoch18, step3025]: loss 0.783075
[epoch18, step3026]: loss 0.660865
[epoch18, step3027]: loss 1.126028
[epoch18, step3028]: loss 4.918209
[epoch18, step3029]: loss 0.734090
[epoch18, step3030]: loss 0.728070
[epoch18, step3031]: loss 2.328355
[epoch18, step3032]: loss 1.316146
[epoch18, step3033]: loss 1.292816
[epoch18, step3034]: loss 1.710937
[epoch18, step3035]: loss 0.499265
[epoch18, step3036]: loss 15.089795
[epoch18, step3037]: loss 7.747746
[epoch18, step3038]: loss 1.128495
[epoch18, step3039]: loss 0.906996
[epoch18, step3040]: loss 0.564975
[epoch18, step3041]: loss 1.917262
[epoch18, step3042]: loss 2.615491
[epoch18, step3043]: loss 14.095253
[epoch18, step3044]: loss 6.803870
[epoch18, step3045]: loss 0.808849
[epoch18, step3046]: loss 2.769122
[epoch18, step3047]: loss 1.521982
[epoch18, step3048]: loss 2.121530
[epoch18, step3049]: loss 1.144675
[epoch18, step3050]: loss 7.998542
[epoch18, step3051]: loss 1.313687
[epoch18, step3052]: loss 12.894952
[epoch18, step3053]: loss 1.180681
[epoch18, step3054]: loss 13.479160
[epoch18, step3055]: loss 2.398656
[epoch18, step3056]: loss 0.981887
[epoch18, step3057]: loss 12.916690
[epoch18, step3058]: loss 24.819733
[epoch18, step3059]: loss 12.055999
[epoch18, step3060]: loss 0.725530
[epoch18, step3061]: loss 1.078537
[epoch18, step3062]: loss 0.393246
[epoch18, step3063]: loss 9.628779
[epoch18, step3064]: loss 1.834260
[epoch18, step3065]: loss 1.367239
[epoch18, step3066]: loss 0.782223
[epoch18, step3067]: loss 2.352436
[epoch18, step3068]: loss 13.076304
[epoch18, step3069]: loss 0.617089
[epoch18, step3070]: loss 8.510280
[epoch18, step3071]: loss 7.650535
[epoch18, step3072]: loss 0.764980
[epoch18, step3073]: loss 0.775327
[epoch18, step3074]: loss 1.976828
[epoch18, step3075]: loss 3.949281
[epoch18, step3076]: loss 1.445119

[epoch18]: avg loss 1.445119

[epoch19, step1]: loss 0.754729
[epoch19, step2]: loss 12.319298
[epoch19, step3]: loss 0.576002
[epoch19, step4]: loss 14.245524
[epoch19, step5]: loss 0.729291
[epoch19, step6]: loss 4.385002
[epoch19, step7]: loss 1.984535
[epoch19, step8]: loss 11.346519
[epoch19, step9]: loss 6.833498
[epoch19, step10]: loss 1.942882
[epoch19, step11]: loss 1.104559
[epoch19, step12]: loss 2.500117
[epoch19, step13]: loss 11.679705
[epoch19, step14]: loss 1.266126
[epoch19, step15]: loss 1.066562
[epoch19, step16]: loss 0.786135
[epoch19, step17]: loss 4.224089
[epoch19, step18]: loss 1.631014
[epoch19, step19]: loss 0.868805
[epoch19, step20]: loss 0.765518
[epoch19, step21]: loss 2.959780
[epoch19, step22]: loss 2.146029
[epoch19, step23]: loss 4.753260
[epoch19, step24]: loss 1.980402
[epoch19, step25]: loss 1.966897
[epoch19, step26]: loss 1.292248
[epoch19, step27]: loss 0.698717
[epoch19, step28]: loss 8.042099
[epoch19, step29]: loss 1.182785
[epoch19, step30]: loss 2.415617
[epoch19, step31]: loss 0.931575
[epoch19, step32]: loss 1.109038
[epoch19, step33]: loss 6.379458
[epoch19, step34]: loss 1.296665
[epoch19, step35]: loss 0.561778
[epoch19, step36]: loss 9.388989
[epoch19, step37]: loss 7.290717
[epoch19, step38]: loss 1.963362
[epoch19, step39]: loss 0.753466
[epoch19, step40]: loss 0.623750
[epoch19, step41]: loss 5.693661
[epoch19, step42]: loss 14.092406
[epoch19, step43]: loss 0.759718
[epoch19, step44]: loss 9.794607
[epoch19, step45]: loss 3.479552
[epoch19, step46]: loss 0.662129
[epoch19, step47]: loss 0.846023
[epoch19, step48]: loss 10.377564
[epoch19, step49]: loss 2.133304
[epoch19, step50]: loss 6.848809
[epoch19, step51]: loss 1.400811
[epoch19, step52]: loss 1.430985
[epoch19, step53]: loss 2.358236
[epoch19, step54]: loss 2.906561
[epoch19, step55]: loss 2.928938
[epoch19, step56]: loss 1.644215
[epoch19, step57]: loss 1.955477
[epoch19, step58]: loss 1.948532
[epoch19, step59]: loss 1.325094
[epoch19, step60]: loss 7.875590
[epoch19, step61]: loss 0.936182
[epoch19, step62]: loss 1.190974
[epoch19, step63]: loss 0.802263
[epoch19, step64]: loss 8.669089
[epoch19, step65]: loss 0.699708
[epoch19, step66]: loss 0.546271
[epoch19, step67]: loss 0.481498
[epoch19, step68]: loss 1.469347
[epoch19, step69]: loss 6.350649
[epoch19, step70]: loss 1.418222
[epoch19, step71]: loss 1.014054
[epoch19, step72]: loss 18.888485
[epoch19, step73]: loss 3.128614
[epoch19, step74]: loss 5.545701
[epoch19, step75]: loss 1.282292
[epoch19, step76]: loss 10.099677
[epoch19, step77]: loss 0.815889
[epoch19, step78]: loss 13.451251
[epoch19, step79]: loss 4.977654
[epoch19, step80]: loss 1.421039
[epoch19, step81]: loss 12.621936
[epoch19, step82]: loss 1.072869
[epoch19, step83]: loss 0.879094
[epoch19, step84]: loss 0.978661
[epoch19, step85]: loss 13.844185
[epoch19, step86]: loss 1.536871
[epoch19, step87]: loss 0.924047
[epoch19, step88]: loss 2.926564
[epoch19, step89]: loss 0.830283
[epoch19, step90]: loss 3.193410
[epoch19, step91]: loss 5.365445
[epoch19, step92]: loss 1.381086
[epoch19, step93]: loss 7.360238
[epoch19, step94]: loss 10.832529
[epoch19, step95]: loss 0.771411
[epoch19, step96]: loss 1.271625
[epoch19, step97]: loss 1.648463
[epoch19, step98]: loss 11.892175
[epoch19, step99]: loss 4.057301
[epoch19, step100]: loss 8.000400
[epoch19, step101]: loss 5.515880
[epoch19, step102]: loss 0.642507
[epoch19, step103]: loss 0.941291
[epoch19, step104]: loss 0.561349
[epoch19, step105]: loss 1.392218
[epoch19, step106]: loss 1.459884
[epoch19, step107]: loss 1.847632
[epoch19, step108]: loss 5.924592
[epoch19, step109]: loss 0.821223
[epoch19, step110]: loss 0.697302
[epoch19, step111]: loss 2.390333
[epoch19, step112]: loss 6.884479
[epoch19, step113]: loss 1.829208
[epoch19, step114]: loss 0.736004
[epoch19, step115]: loss 11.069818
[epoch19, step116]: loss 16.892126
[epoch19, step117]: loss 0.762339
[epoch19, step118]: loss 11.375473
[epoch19, step119]: loss 0.712297
[epoch19, step120]: loss 7.544087
[epoch19, step121]: loss 2.054899
[epoch19, step122]: loss 6.567080
[epoch19, step123]: loss 8.721874
[epoch19, step124]: loss 2.054095
[epoch19, step125]: loss 0.726161
[epoch19, step126]: loss 2.803629
[epoch19, step127]: loss 4.908306
[epoch19, step128]: loss 3.124847
[epoch19, step129]: loss 4.738867
[epoch19, step130]: loss 7.840119
[epoch19, step131]: loss 1.045241
[epoch19, step132]: loss 1.008016
[epoch19, step133]: loss 1.377116
[epoch19, step134]: loss 0.765499
[epoch19, step135]: loss 0.772480
[epoch19, step136]: loss 0.849226
[epoch19, step137]: loss 11.500857
[epoch19, step138]: loss 1.104426
[epoch19, step139]: loss 0.577904
[epoch19, step140]: loss 7.702005
[epoch19, step141]: loss 2.431064
[epoch19, step142]: loss 6.532848
[epoch19, step143]: loss 1.574084
[epoch19, step144]: loss 6.130759
[epoch19, step145]: loss 9.139215
[epoch19, step146]: loss 1.722119
[epoch19, step147]: loss 0.875926
[epoch19, step148]: loss 8.579506
[epoch19, step149]: loss 5.853300
[epoch19, step150]: loss 1.348172
[epoch19, step151]: loss 0.974678
[epoch19, step152]: loss 1.234565
[epoch19, step153]: loss 1.262542
[epoch19, step154]: loss 8.525979
[epoch19, step155]: loss 0.809414
[epoch19, step156]: loss 0.802437
[epoch19, step157]: loss 2.502326
[epoch19, step158]: loss 2.270289
[epoch19, step159]: loss 9.731566
[epoch19, step160]: loss 0.782557
[epoch19, step161]: loss 1.695439
[epoch19, step162]: loss 0.680242
[epoch19, step163]: loss 4.548355
[epoch19, step164]: loss 10.435525
[epoch19, step165]: loss 5.452571
[epoch19, step166]: loss 5.113003
[epoch19, step167]: loss 0.584990
[epoch19, step168]: loss 0.633661
[epoch19, step169]: loss 0.767392
[epoch19, step170]: loss 1.235729
[epoch19, step171]: loss 0.670688
[epoch19, step172]: loss 2.172285
[epoch19, step173]: loss 0.754271
[epoch19, step174]: loss 6.379984
[epoch19, step175]: loss 0.930228
[epoch19, step176]: loss 0.599059
[epoch19, step177]: loss 0.590897
[epoch19, step178]: loss 18.709743
[epoch19, step179]: loss 1.253570
[epoch19, step180]: loss 1.260933
[epoch19, step181]: loss 2.358136
[epoch19, step182]: loss 2.180542
[epoch19, step183]: loss 0.735857
[epoch19, step184]: loss 1.201485
[epoch19, step185]: loss 0.861214
[epoch19, step186]: loss 6.594055
[epoch19, step187]: loss 0.766447
[epoch19, step188]: loss 0.882307
[epoch19, step189]: loss 2.430226
[epoch19, step190]: loss 0.520124
[epoch19, step191]: loss 8.210284
[epoch19, step192]: loss 9.757261
[epoch19, step193]: loss 2.321817
[epoch19, step194]: loss 6.217254
[epoch19, step195]: loss 1.581176
[epoch19, step196]: loss 1.167110
[epoch19, step197]: loss 0.900507
[epoch19, step198]: loss 6.059497
[epoch19, step199]: loss 8.051264
[epoch19, step200]: loss 1.225194
[epoch19, step201]: loss 5.332873
[epoch19, step202]: loss 1.460900
[epoch19, step203]: loss 2.011107
[epoch19, step204]: loss 0.977072
[epoch19, step205]: loss 1.355845
[epoch19, step206]: loss 10.911781
[epoch19, step207]: loss 5.933928
[epoch19, step208]: loss 9.609166
[epoch19, step209]: loss 0.875508
[epoch19, step210]: loss 0.531995
[epoch19, step211]: loss 1.604005
[epoch19, step212]: loss 1.445860
[epoch19, step213]: loss 1.821054
[epoch19, step214]: loss 0.606392
[epoch19, step215]: loss 2.226641
[epoch19, step216]: loss 0.622647
[epoch19, step217]: loss 0.440844
[epoch19, step218]: loss 0.867011
[epoch19, step219]: loss 0.643973
[epoch19, step220]: loss 8.562434
[epoch19, step221]: loss 6.238533
[epoch19, step222]: loss 0.983059
[epoch19, step223]: loss 0.582709
[epoch19, step224]: loss 5.937593
[epoch19, step225]: loss 4.406001
[epoch19, step226]: loss 1.698253
[epoch19, step227]: loss 0.924041
[epoch19, step228]: loss 2.891062
[epoch19, step229]: loss 2.466396
[epoch19, step230]: loss 14.462923
[epoch19, step231]: loss 0.652735
[epoch19, step232]: loss 2.521634
[epoch19, step233]: loss 6.368006
[epoch19, step234]: loss 0.698809
[epoch19, step235]: loss 5.773492
[epoch19, step236]: loss 10.137807
[epoch19, step237]: loss 24.254633
[epoch19, step238]: loss 1.871131
[epoch19, step239]: loss 2.183777
[epoch19, step240]: loss 11.957583
[epoch19, step241]: loss 6.707116
[epoch19, step242]: loss 0.581733
[epoch19, step243]: loss 1.682198
[epoch19, step244]: loss 6.237866
[epoch19, step245]: loss 0.744989
[epoch19, step246]: loss 6.773633
[epoch19, step247]: loss 9.420323
[epoch19, step248]: loss 0.812842
[epoch19, step249]: loss 0.608298
[epoch19, step250]: loss 2.459902
[epoch19, step251]: loss 1.936753
[epoch19, step252]: loss 2.001123
[epoch19, step253]: loss 0.787566
[epoch19, step254]: loss 1.283975
[epoch19, step255]: loss 0.885617
[epoch19, step256]: loss 0.536757
[epoch19, step257]: loss 2.167179
[epoch19, step258]: loss 1.556879
[epoch19, step259]: loss 0.848400
[epoch19, step260]: loss 0.765979
[epoch19, step261]: loss 0.662777
[epoch19, step262]: loss 0.685839
[epoch19, step263]: loss 1.955260
[epoch19, step264]: loss 5.707092
[epoch19, step265]: loss 16.735706
[epoch19, step266]: loss 5.666832
[epoch19, step267]: loss 1.122928
[epoch19, step268]: loss 1.030876
[epoch19, step269]: loss 0.650628
[epoch19, step270]: loss 0.899019
[epoch19, step271]: loss 2.694526
[epoch19, step272]: loss 1.076709
[epoch19, step273]: loss 0.837612
[epoch19, step274]: loss 18.015606
[epoch19, step275]: loss 7.254371
[epoch19, step276]: loss 1.431405
[epoch19, step277]: loss 0.782101
[epoch19, step278]: loss 4.485917
[epoch19, step279]: loss 6.954495
[epoch19, step280]: loss 14.994163
[epoch19, step281]: loss 0.708658
[epoch19, step282]: loss 3.261771
[epoch19, step283]: loss 0.697907
[epoch19, step284]: loss 0.635994
[epoch19, step285]: loss 0.730882
[epoch19, step286]: loss 0.908795
[epoch19, step287]: loss 0.920438
[epoch19, step288]: loss 11.368598
[epoch19, step289]: loss 9.934275
[epoch19, step290]: loss 0.732156
[epoch19, step291]: loss 10.911142
[epoch19, step292]: loss 1.617379
[epoch19, step293]: loss 2.461212
[epoch19, step294]: loss 0.812666
[epoch19, step295]: loss 4.196767
[epoch19, step296]: loss 1.306841
[epoch19, step297]: loss 2.989841
[epoch19, step298]: loss 0.721035
[epoch19, step299]: loss 4.631542
[epoch19, step300]: loss 0.553227
[epoch19, step301]: loss 3.171794
[epoch19, step302]: loss 1.042046
[epoch19, step303]: loss 0.841470
[epoch19, step304]: loss 1.234235
[epoch19, step305]: loss 0.601351
[epoch19, step306]: loss 2.534945
[epoch19, step307]: loss 1.376528
[epoch19, step308]: loss 11.070672
[epoch19, step309]: loss 1.130331
[epoch19, step310]: loss 1.137950
[epoch19, step311]: loss 1.832224
[epoch19, step312]: loss 0.496974
[epoch19, step313]: loss 0.677724
[epoch19, step314]: loss 7.832165
[epoch19, step315]: loss 0.888870
[epoch19, step316]: loss 0.839844
[epoch19, step317]: loss 18.156761
[epoch19, step318]: loss 1.374215
[epoch19, step319]: loss 0.564600
[epoch19, step320]: loss 10.687867
[epoch19, step321]: loss 4.938818
[epoch19, step322]: loss 2.301166
[epoch19, step323]: loss 1.106184
[epoch19, step324]: loss 9.936278
[epoch19, step325]: loss 7.220290
[epoch19, step326]: loss 6.135686
[epoch19, step327]: loss 0.755157
[epoch19, step328]: loss 1.819361
[epoch19, step329]: loss 2.919421
[epoch19, step330]: loss 0.627897
[epoch19, step331]: loss 18.101662
[epoch19, step332]: loss 7.798340
[epoch19, step333]: loss 11.700474
[epoch19, step334]: loss 0.829024
[epoch19, step335]: loss 0.762096
[epoch19, step336]: loss 1.368204
[epoch19, step337]: loss 0.666700
[epoch19, step338]: loss 0.544723
[epoch19, step339]: loss 1.951114
[epoch19, step340]: loss 0.642067
[epoch19, step341]: loss 4.390067
[epoch19, step342]: loss 2.135814
[epoch19, step343]: loss 0.456205
[epoch19, step344]: loss 14.491881
[epoch19, step345]: loss 8.642020
[epoch19, step346]: loss 2.703583
[epoch19, step347]: loss 9.545828
[epoch19, step348]: loss 2.650240
[epoch19, step349]: loss 6.647083
[epoch19, step350]: loss 1.128824
[epoch19, step351]: loss 0.651879
[epoch19, step352]: loss 12.880000
[epoch19, step353]: loss 0.529353
[epoch19, step354]: loss 11.635774
[epoch19, step355]: loss 1.572744
[epoch19, step356]: loss 2.103966
[epoch19, step357]: loss 1.228669
[epoch19, step358]: loss 3.474802
[epoch19, step359]: loss 1.103277
[epoch19, step360]: loss 2.260170
[epoch19, step361]: loss 2.632870
[epoch19, step362]: loss 10.583528
[epoch19, step363]: loss 9.683234
[epoch19, step364]: loss 0.577764
[epoch19, step365]: loss 2.210366
[epoch19, step366]: loss 0.533708
[epoch19, step367]: loss 1.010638
[epoch19, step368]: loss 19.000023
[epoch19, step369]: loss 1.822229
[epoch19, step370]: loss 1.682896
[epoch19, step371]: loss 2.788798
[epoch19, step372]: loss 2.057422
[epoch19, step373]: loss 0.653932
[epoch19, step374]: loss 0.974924
[epoch19, step375]: loss 1.322190
[epoch19, step376]: loss 0.925108
[epoch19, step377]: loss 2.580212
[epoch19, step378]: loss 0.739874
[epoch19, step379]: loss 0.578636
[epoch19, step380]: loss 1.090708
[epoch19, step381]: loss 15.137515
[epoch19, step382]: loss 0.779831
[epoch19, step383]: loss 1.456977
[epoch19, step384]: loss 8.969098
[epoch19, step385]: loss 4.742764
[epoch19, step386]: loss 0.794829
[epoch19, step387]: loss 0.466611
[epoch19, step388]: loss 1.421934
[epoch19, step389]: loss 5.245581
[epoch19, step390]: loss 1.406310
[epoch19, step391]: loss 11.692830
[epoch19, step392]: loss 0.874348
[epoch19, step393]: loss 0.860098
[epoch19, step394]: loss 6.058254
[epoch19, step395]: loss 15.440826
[epoch19, step396]: loss 3.556429
[epoch19, step397]: loss 0.494038
[epoch19, step398]: loss 0.660124
[epoch19, step399]: loss 13.215287
[epoch19, step400]: loss 7.046990
[epoch19, step401]: loss 0.714274
[epoch19, step402]: loss 1.922612
[epoch19, step403]: loss 0.459108
[epoch19, step404]: loss 8.040808
[epoch19, step405]: loss 2.501391
[epoch19, step406]: loss 1.869665
[epoch19, step407]: loss 6.253670
[epoch19, step408]: loss 0.895851
[epoch19, step409]: loss 0.818094
[epoch19, step410]: loss 0.683707
[epoch19, step411]: loss 1.601074
[epoch19, step412]: loss 4.731883
[epoch19, step413]: loss 0.873408
[epoch19, step414]: loss 3.070290
[epoch19, step415]: loss 5.798768
[epoch19, step416]: loss 0.858642
[epoch19, step417]: loss 0.712110
[epoch19, step418]: loss 0.735866
[epoch19, step419]: loss 9.885291
[epoch19, step420]: loss 0.701138
[epoch19, step421]: loss 0.805441
[epoch19, step422]: loss 6.682852
[epoch19, step423]: loss 1.943610
[epoch19, step424]: loss 2.567068
[epoch19, step425]: loss 9.762583
[epoch19, step426]: loss 1.009927
[epoch19, step427]: loss 1.028154
[epoch19, step428]: loss 1.348600
[epoch19, step429]: loss 7.263114
[epoch19, step430]: loss 3.160849
[epoch19, step431]: loss 0.760981
[epoch19, step432]: loss 12.039560
[epoch19, step433]: loss 3.836299
[epoch19, step434]: loss 2.256667
[epoch19, step435]: loss 5.628240
[epoch19, step436]: loss 9.669516
[epoch19, step437]: loss 2.716721
[epoch19, step438]: loss 9.095037
[epoch19, step439]: loss 0.482153
[epoch19, step440]: loss 0.779084
[epoch19, step441]: loss 3.729207
[epoch19, step442]: loss 0.483495
[epoch19, step443]: loss 1.091559
[epoch19, step444]: loss 6.293606
[epoch19, step445]: loss 0.817278
[epoch19, step446]: loss 0.572141
[epoch19, step447]: loss 0.427100
[epoch19, step448]: loss 1.157049
[epoch19, step449]: loss 13.269324
[epoch19, step450]: loss 8.468204
[epoch19, step451]: loss 2.581844
[epoch19, step452]: loss 2.775524
[epoch19, step453]: loss 2.614212
[epoch19, step454]: loss 0.750738
[epoch19, step455]: loss 7.930634
[epoch19, step456]: loss 14.129106
[epoch19, step457]: loss 1.074538
[epoch19, step458]: loss 1.100654
[epoch19, step459]: loss 1.340713
[epoch19, step460]: loss 5.950593
[epoch19, step461]: loss 0.451093
[epoch19, step462]: loss 0.795595
[epoch19, step463]: loss 1.291105
[epoch19, step464]: loss 6.760920
[epoch19, step465]: loss 3.213763
[epoch19, step466]: loss 1.433465
[epoch19, step467]: loss 1.382013
[epoch19, step468]: loss 8.338397
[epoch19, step469]: loss 16.782625
[epoch19, step470]: loss 0.993964
[epoch19, step471]: loss 1.930141
[epoch19, step472]: loss 2.410666
[epoch19, step473]: loss 12.382069
[epoch19, step474]: loss 1.289032
[epoch19, step475]: loss 0.996256
[epoch19, step476]: loss 1.723270
[epoch19, step477]: loss 0.593879
[epoch19, step478]: loss 2.435068
[epoch19, step479]: loss 0.643948
[epoch19, step480]: loss 7.375825
[epoch19, step481]: loss 1.774904
[epoch19, step482]: loss 0.835313
[epoch19, step483]: loss 5.149191
[epoch19, step484]: loss 0.942809
[epoch19, step485]: loss 9.015461
[epoch19, step486]: loss 1.159695
[epoch19, step487]: loss 2.367208
[epoch19, step488]: loss 1.700125
[epoch19, step489]: loss 1.069733
[epoch19, step490]: loss 0.384730
[epoch19, step491]: loss 16.257252
[epoch19, step492]: loss 1.462540
[epoch19, step493]: loss 13.593469
[epoch19, step494]: loss 1.483054
[epoch19, step495]: loss 11.112143
[epoch19, step496]: loss 8.170208
[epoch19, step497]: loss 6.069582
[epoch19, step498]: loss 10.073881
[epoch19, step499]: loss 1.217837
[epoch19, step500]: loss 0.788128
[epoch19, step501]: loss 0.675254
[epoch19, step502]: loss 1.180668
[epoch19, step503]: loss 0.661353
[epoch19, step504]: loss 1.068532
[epoch19, step505]: loss 0.622353
[epoch19, step506]: loss 0.777004
[epoch19, step507]: loss 0.660914
[epoch19, step508]: loss 0.487085
[epoch19, step509]: loss 5.925923
[epoch19, step510]: loss 1.995227
[epoch19, step511]: loss 1.589752
[epoch19, step512]: loss 1.500043
[epoch19, step513]: loss 2.524018
[epoch19, step514]: loss 1.208427
[epoch19, step515]: loss 0.840602
[epoch19, step516]: loss 6.219194
[epoch19, step517]: loss 0.924291
[epoch19, step518]: loss 1.072230
[epoch19, step519]: loss 1.961881
[epoch19, step520]: loss 9.386189
[epoch19, step521]: loss 5.289513
[epoch19, step522]: loss 0.608253
[epoch19, step523]: loss 9.912249
[epoch19, step524]: loss 4.290314
[epoch19, step525]: loss 1.833616
[epoch19, step526]: loss 0.578692
[epoch19, step527]: loss 2.273785
[epoch19, step528]: loss 0.664081
[epoch19, step529]: loss 7.568091
[epoch19, step530]: loss 0.812330
[epoch19, step531]: loss 2.231576
[epoch19, step532]: loss 0.946640
[epoch19, step533]: loss 1.351837
[epoch19, step534]: loss 0.649153
[epoch19, step535]: loss 2.277394
[epoch19, step536]: loss 1.834168
[epoch19, step537]: loss 4.836198
[epoch19, step538]: loss 1.295069
[epoch19, step539]: loss 13.209540
[epoch19, step540]: loss 1.053866
[epoch19, step541]: loss 5.274888
[epoch19, step542]: loss 5.289916
[epoch19, step543]: loss 0.685728
[epoch19, step544]: loss 1.543373
[epoch19, step545]: loss 1.250760
[epoch19, step546]: loss 1.600378
[epoch19, step547]: loss 14.479926
[epoch19, step548]: loss 1.290861
[epoch19, step549]: loss 0.522425
[epoch19, step550]: loss 11.439932
[epoch19, step551]: loss 0.644834
[epoch19, step552]: loss 1.546758
[epoch19, step553]: loss 1.735089
[epoch19, step554]: loss 0.652146
[epoch19, step555]: loss 1.041363
[epoch19, step556]: loss 1.298676
[epoch19, step557]: loss 8.721774
[epoch19, step558]: loss 5.542855
[epoch19, step559]: loss 0.700596
[epoch19, step560]: loss 0.708961
[epoch19, step561]: loss 0.743409
[epoch19, step562]: loss 8.152121
[epoch19, step563]: loss 1.434600
[epoch19, step564]: loss 8.355915
[epoch19, step565]: loss 6.044602
[epoch19, step566]: loss 0.726239
[epoch19, step567]: loss 2.239140
[epoch19, step568]: loss 2.711225
[epoch19, step569]: loss 0.504157
[epoch19, step570]: loss 5.354389
[epoch19, step571]: loss 1.305825
[epoch19, step572]: loss 11.972448
[epoch19, step573]: loss 1.776592
[epoch19, step574]: loss 0.640827
[epoch19, step575]: loss 7.061318
[epoch19, step576]: loss 0.783019
[epoch19, step577]: loss 12.529939
[epoch19, step578]: loss 8.968740
[epoch19, step579]: loss 1.236416
[epoch19, step580]: loss 0.969927
[epoch19, step581]: loss 4.124996
[epoch19, step582]: loss 3.069707
[epoch19, step583]: loss 6.117538
[epoch19, step584]: loss 0.909130
[epoch19, step585]: loss 0.975701
[epoch19, step586]: loss 1.413879
[epoch19, step587]: loss 1.192702
[epoch19, step588]: loss 0.787396
[epoch19, step589]: loss 10.611190
[epoch19, step590]: loss 1.695870
[epoch19, step591]: loss 16.527592
[epoch19, step592]: loss 1.693809
[epoch19, step593]: loss 6.245590
[epoch19, step594]: loss 0.692690
[epoch19, step595]: loss 1.662670
[epoch19, step596]: loss 2.801203
[epoch19, step597]: loss 2.705743
[epoch19, step598]: loss 0.666439
[epoch19, step599]: loss 0.672099
[epoch19, step600]: loss 0.988888
[epoch19, step601]: loss 0.861662
[epoch19, step602]: loss 3.138165
[epoch19, step603]: loss 3.581749
[epoch19, step604]: loss 1.508900
[epoch19, step605]: loss 4.778168
[epoch19, step606]: loss 1.434451
[epoch19, step607]: loss 4.030694
[epoch19, step608]: loss 0.524070
[epoch19, step609]: loss 0.794210
[epoch19, step610]: loss 0.602449
[epoch19, step611]: loss 1.196445
[epoch19, step612]: loss 0.949445
[epoch19, step613]: loss 0.903589
[epoch19, step614]: loss 0.838107
[epoch19, step615]: loss 0.766121
[epoch19, step616]: loss 0.437286
[epoch19, step617]: loss 5.383720
[epoch19, step618]: loss 1.164420
[epoch19, step619]: loss 0.766910
[epoch19, step620]: loss 0.785000
[epoch19, step621]: loss 2.735582
[epoch19, step622]: loss 1.148325
[epoch19, step623]: loss 0.544864
[epoch19, step624]: loss 0.840405
[epoch19, step625]: loss 11.746036
[epoch19, step626]: loss 1.729681
[epoch19, step627]: loss 11.806928
[epoch19, step628]: loss 0.937406
[epoch19, step629]: loss 1.098936
[epoch19, step630]: loss 1.222678
[epoch19, step631]: loss 1.354487
[epoch19, step632]: loss 1.900436
[epoch19, step633]: loss 9.584254
[epoch19, step634]: loss 2.388784
[epoch19, step635]: loss 11.684258
[epoch19, step636]: loss 0.860235
[epoch19, step637]: loss 6.315932
[epoch19, step638]: loss 0.732296
[epoch19, step639]: loss 2.077936
[epoch19, step640]: loss 3.128755
[epoch19, step641]: loss 3.925904
[epoch19, step642]: loss 1.010406
[epoch19, step643]: loss 0.788735
[epoch19, step644]: loss 1.594290
[epoch19, step645]: loss 0.697834
[epoch19, step646]: loss 1.848500
[epoch19, step647]: loss 0.786460
[epoch19, step648]: loss 8.601709
[epoch19, step649]: loss 0.660296
[epoch19, step650]: loss 1.521824
[epoch19, step651]: loss 9.258599
[epoch19, step652]: loss 2.332504
[epoch19, step653]: loss 1.063589
[epoch19, step654]: loss 0.494134
[epoch19, step655]: loss 2.878753
[epoch19, step656]: loss 2.253218
[epoch19, step657]: loss 1.431943
[epoch19, step658]: loss 1.243984
[epoch19, step659]: loss 6.266695
[epoch19, step660]: loss 0.425418
[epoch19, step661]: loss 1.023375
[epoch19, step662]: loss 6.143866
[epoch19, step663]: loss 6.479769
[epoch19, step664]: loss 1.078150
[epoch19, step665]: loss 0.868026
[epoch19, step666]: loss 1.070861
[epoch19, step667]: loss 2.254344
[epoch19, step668]: loss 1.736895
[epoch19, step669]: loss 0.890361
[epoch19, step670]: loss 1.053544
[epoch19, step671]: loss 1.164380
[epoch19, step672]: loss 8.944315
[epoch19, step673]: loss 6.931695
[epoch19, step674]: loss 2.567272
[epoch19, step675]: loss 0.660398
[epoch19, step676]: loss 1.072995
[epoch19, step677]: loss 0.658431
[epoch19, step678]: loss 1.770656
[epoch19, step679]: loss 0.799070
[epoch19, step680]: loss 1.733453
[epoch19, step681]: loss 1.514825
[epoch19, step682]: loss 0.854446
[epoch19, step683]: loss 1.167234
[epoch19, step684]: loss 1.582897
[epoch19, step685]: loss 6.366375
[epoch19, step686]: loss 0.992795
[epoch19, step687]: loss 3.561360
[epoch19, step688]: loss 10.408607
[epoch19, step689]: loss 1.531659
[epoch19, step690]: loss 1.127346
[epoch19, step691]: loss 11.572261
[epoch19, step692]: loss 0.598907
[epoch19, step693]: loss 2.456339
[epoch19, step694]: loss 1.209536
[epoch19, step695]: loss 2.264720
[epoch19, step696]: loss 0.933218
[epoch19, step697]: loss 4.469878
[epoch19, step698]: loss 0.755776
[epoch19, step699]: loss 1.253909
[epoch19, step700]: loss 0.594875
[epoch19, step701]: loss 0.936295
[epoch19, step702]: loss 2.472400
[epoch19, step703]: loss 1.232510
[epoch19, step704]: loss 1.038478
[epoch19, step705]: loss 12.474029
[epoch19, step706]: loss 5.682093
[epoch19, step707]: loss 6.209510
[epoch19, step708]: loss 8.071929
[epoch19, step709]: loss 1.077697
[epoch19, step710]: loss 2.094324
[epoch19, step711]: loss 1.518645
[epoch19, step712]: loss 2.414103
[epoch19, step713]: loss 1.593203
[epoch19, step714]: loss 8.975446
[epoch19, step715]: loss 0.842118
[epoch19, step716]: loss 13.341103
[epoch19, step717]: loss 0.915870
[epoch19, step718]: loss 0.723035
[epoch19, step719]: loss 10.484342
[epoch19, step720]: loss 2.725166
[epoch19, step721]: loss 1.914842
[epoch19, step722]: loss 1.502791
[epoch19, step723]: loss 1.201957
[epoch19, step724]: loss 11.326733
[epoch19, step725]: loss 4.717304
[epoch19, step726]: loss 2.114195
[epoch19, step727]: loss 0.815925
[epoch19, step728]: loss 0.934583
[epoch19, step729]: loss 0.533755
[epoch19, step730]: loss 0.757757
[epoch19, step731]: loss 0.821357
[epoch19, step732]: loss 0.653900
[epoch19, step733]: loss 0.630620
[epoch19, step734]: loss 1.188832
[epoch19, step735]: loss 1.293406
[epoch19, step736]: loss 0.945824
[epoch19, step737]: loss 3.538510
[epoch19, step738]: loss 0.951022
[epoch19, step739]: loss 2.418665
[epoch19, step740]: loss 1.666027
[epoch19, step741]: loss 1.021198
[epoch19, step742]: loss 0.855262
[epoch19, step743]: loss 1.011139
[epoch19, step744]: loss 6.909502
[epoch19, step745]: loss 0.879937
[epoch19, step746]: loss 2.234359
[epoch19, step747]: loss 10.562058
[epoch19, step748]: loss 2.518645
[epoch19, step749]: loss 1.303739
[epoch19, step750]: loss 1.766291
[epoch19, step751]: loss 2.855366
[epoch19, step752]: loss 0.693725
[epoch19, step753]: loss 11.482881
[epoch19, step754]: loss 6.626854
[epoch19, step755]: loss 0.683761
[epoch19, step756]: loss 6.250530
[epoch19, step757]: loss 5.954119
[epoch19, step758]: loss 2.872442
[epoch19, step759]: loss 1.706162
[epoch19, step760]: loss 3.163162
[epoch19, step761]: loss 0.499575
[epoch19, step762]: loss 5.519662
[epoch19, step763]: loss 1.802070
[epoch19, step764]: loss 9.925285
[epoch19, step765]: loss 0.645879
[epoch19, step766]: loss 0.559005
[epoch19, step767]: loss 0.758650
[epoch19, step768]: loss 0.544209
[epoch19, step769]: loss 0.546891
[epoch19, step770]: loss 9.272502
[epoch19, step771]: loss 1.128050
[epoch19, step772]: loss 0.699036
[epoch19, step773]: loss 11.120013
[epoch19, step774]: loss 5.516667
[epoch19, step775]: loss 12.938856
[epoch19, step776]: loss 1.369787
[epoch19, step777]: loss 0.882342
[epoch19, step778]: loss 1.327374
[epoch19, step779]: loss 0.606135
[epoch19, step780]: loss 0.597429
[epoch19, step781]: loss 0.584859
[epoch19, step782]: loss 2.001054
[epoch19, step783]: loss 8.514883
[epoch19, step784]: loss 4.793536
[epoch19, step785]: loss 6.701293
[epoch19, step786]: loss 2.185495
[epoch19, step787]: loss 6.461073
[epoch19, step788]: loss 7.435823
[epoch19, step789]: loss 0.579995
[epoch19, step790]: loss 7.844792
[epoch19, step791]: loss 0.754367
[epoch19, step792]: loss 0.826389
[epoch19, step793]: loss 1.031796
[epoch19, step794]: loss 0.514275
[epoch19, step795]: loss 0.533443
[epoch19, step796]: loss 1.869062
[epoch19, step797]: loss 0.666981
[epoch19, step798]: loss 1.119909
[epoch19, step799]: loss 8.663470
[epoch19, step800]: loss 1.114650
[epoch19, step801]: loss 5.805244
[epoch19, step802]: loss 12.838252
[epoch19, step803]: loss 6.044075
[epoch19, step804]: loss 2.679561
[epoch19, step805]: loss 1.096400
[epoch19, step806]: loss 0.450020
[epoch19, step807]: loss 5.511599
[epoch19, step808]: loss 0.521816
[epoch19, step809]: loss 0.545114
[epoch19, step810]: loss 1.188115
[epoch19, step811]: loss 5.225779
[epoch19, step812]: loss 1.114619
[epoch19, step813]: loss 0.985155
[epoch19, step814]: loss 0.522716
[epoch19, step815]: loss 1.591882
[epoch19, step816]: loss 1.724048
[epoch19, step817]: loss 5.973027
[epoch19, step818]: loss 2.867611
[epoch19, step819]: loss 0.787392
[epoch19, step820]: loss 0.865895
[epoch19, step821]: loss 0.897889
[epoch19, step822]: loss 1.045758
[epoch19, step823]: loss 0.722564
[epoch19, step824]: loss 10.019381
[epoch19, step825]: loss 0.801406
[epoch19, step826]: loss 2.797046
[epoch19, step827]: loss 2.888899
[epoch19, step828]: loss 5.018355
[epoch19, step829]: loss 1.779195
[epoch19, step830]: loss 2.236210
[epoch19, step831]: loss 0.491990
[epoch19, step832]: loss 10.142389
[epoch19, step833]: loss 9.346074
[epoch19, step834]: loss 0.926643
[epoch19, step835]: loss 14.126458
[epoch19, step836]: loss 11.846848
[epoch19, step837]: loss 1.050874
[epoch19, step838]: loss 6.274310
[epoch19, step839]: loss 4.351466
[epoch19, step840]: loss 4.204325
[epoch19, step841]: loss 4.593835
[epoch19, step842]: loss 0.562385
[epoch19, step843]: loss 12.102496
[epoch19, step844]: loss 0.893255
[epoch19, step845]: loss 2.048004
[epoch19, step846]: loss 0.946663
[epoch19, step847]: loss 1.009042
[epoch19, step848]: loss 7.004190
[epoch19, step849]: loss 1.522850
[epoch19, step850]: loss 0.827941
[epoch19, step851]: loss 12.810336
[epoch19, step852]: loss 1.622288
[epoch19, step853]: loss 0.615913
[epoch19, step854]: loss 3.044005
[epoch19, step855]: loss 3.454802
[epoch19, step856]: loss 2.461420
[epoch19, step857]: loss 8.576362
[epoch19, step858]: loss 2.805263
[epoch19, step859]: loss 5.018495
[epoch19, step860]: loss 1.373902
[epoch19, step861]: loss 1.107114
[epoch19, step862]: loss 0.599465
[epoch19, step863]: loss 1.947665
[epoch19, step864]: loss 2.174167
[epoch19, step865]: loss 1.782137
[epoch19, step866]: loss 2.696311
[epoch19, step867]: loss 1.909576
[epoch19, step868]: loss 6.333014
[epoch19, step869]: loss 2.351642
[epoch19, step870]: loss 0.748944
[epoch19, step871]: loss 1.155211
[epoch19, step872]: loss 8.358749
[epoch19, step873]: loss 0.605897
[epoch19, step874]: loss 6.609069
[epoch19, step875]: loss 1.003079
[epoch19, step876]: loss 1.250726
[epoch19, step877]: loss 9.056006
[epoch19, step878]: loss 1.074025
[epoch19, step879]: loss 1.762658
[epoch19, step880]: loss 5.836500
[epoch19, step881]: loss 21.807007
[epoch19, step882]: loss 0.855859
[epoch19, step883]: loss 3.067779
[epoch19, step884]: loss 1.686311
[epoch19, step885]: loss 12.901043
[epoch19, step886]: loss 0.790299
[epoch19, step887]: loss 1.232712
[epoch19, step888]: loss 2.302664
[epoch19, step889]: loss 1.766090
[epoch19, step890]: loss 1.192491
[epoch19, step891]: loss 1.193323
[epoch19, step892]: loss 4.894075
[epoch19, step893]: loss 5.565474
[epoch19, step894]: loss 2.302682
[epoch19, step895]: loss 2.868999
[epoch19, step896]: loss 8.451303
[epoch19, step897]: loss 0.704413
[epoch19, step898]: loss 11.495679
[epoch19, step899]: loss 2.077963
[epoch19, step900]: loss 0.852634
[epoch19, step901]: loss 19.480015
[epoch19, step902]: loss 8.843533
[epoch19, step903]: loss 4.243305
[epoch19, step904]: loss 12.111314
[epoch19, step905]: loss 1.016569
[epoch19, step906]: loss 2.606487
[epoch19, step907]: loss 0.929983
[epoch19, step908]: loss 15.860510
[epoch19, step909]: loss 0.691974
[epoch19, step910]: loss 12.348369
[epoch19, step911]: loss 1.113095
[epoch19, step912]: loss 1.916677
[epoch19, step913]: loss 2.491892
[epoch19, step914]: loss 0.963143
[epoch19, step915]: loss 2.281487
[epoch19, step916]: loss 1.379992
[epoch19, step917]: loss 1.093263
[epoch19, step918]: loss 4.950169
[epoch19, step919]: loss 1.216946
[epoch19, step920]: loss 2.336399
[epoch19, step921]: loss 0.804170
[epoch19, step922]: loss 4.780054
[epoch19, step923]: loss 12.310033
[epoch19, step924]: loss 1.408408
[epoch19, step925]: loss 18.748793
[epoch19, step926]: loss 0.551162
[epoch19, step927]: loss 2.449120
[epoch19, step928]: loss 2.260562
[epoch19, step929]: loss 9.867031
[epoch19, step930]: loss 0.996906
[epoch19, step931]: loss 1.089270
[epoch19, step932]: loss 0.485507
[epoch19, step933]: loss 0.600625
[epoch19, step934]: loss 1.441017
[epoch19, step935]: loss 0.731207
[epoch19, step936]: loss 0.859696
[epoch19, step937]: loss 0.759904
[epoch19, step938]: loss 1.904067
[epoch19, step939]: loss 1.719302
[epoch19, step940]: loss 7.195139
[epoch19, step941]: loss 1.627449
[epoch19, step942]: loss 1.074755
[epoch19, step943]: loss 1.992254
[epoch19, step944]: loss 0.673073
[epoch19, step945]: loss 0.908213
[epoch19, step946]: loss 1.366180
[epoch19, step947]: loss 0.846069
[epoch19, step948]: loss 0.731442
[epoch19, step949]: loss 0.886468
[epoch19, step950]: loss 6.997624
[epoch19, step951]: loss 1.215869
[epoch19, step952]: loss 1.257546
[epoch19, step953]: loss 6.184474
[epoch19, step954]: loss 0.774210
[epoch19, step955]: loss 2.140957
[epoch19, step956]: loss 5.589789
[epoch19, step957]: loss 0.990834
[epoch19, step958]: loss 0.658340
[epoch19, step959]: loss 6.949527
[epoch19, step960]: loss 10.691394
[epoch19, step961]: loss 0.648895
[epoch19, step962]: loss 1.363632
[epoch19, step963]: loss 0.818420
[epoch19, step964]: loss 6.012809
[epoch19, step965]: loss 0.923846
[epoch19, step966]: loss 5.183835
[epoch19, step967]: loss 0.603119
[epoch19, step968]: loss 5.568605
[epoch19, step969]: loss 3.180198
[epoch19, step970]: loss 2.325247
[epoch19, step971]: loss 6.528624
[epoch19, step972]: loss 2.352045
[epoch19, step973]: loss 0.939267
[epoch19, step974]: loss 5.278026
[epoch19, step975]: loss 1.063262
[epoch19, step976]: loss 0.621476
[epoch19, step977]: loss 1.946380
[epoch19, step978]: loss 18.019232
[epoch19, step979]: loss 5.269564
[epoch19, step980]: loss 1.197427
[epoch19, step981]: loss 0.847684
[epoch19, step982]: loss 1.572996
[epoch19, step983]: loss 10.732325
[epoch19, step984]: loss 0.524073
[epoch19, step985]: loss 7.647316
[epoch19, step986]: loss 6.868431
[epoch19, step987]: loss 10.501957
[epoch19, step988]: loss 8.449860
[epoch19, step989]: loss 2.408219
[epoch19, step990]: loss 0.878558
[epoch19, step991]: loss 0.595792
[epoch19, step992]: loss 2.108141
[epoch19, step993]: loss 5.588714
[epoch19, step994]: loss 6.994064
[epoch19, step995]: loss 7.061477
[epoch19, step996]: loss 3.523996
[epoch19, step997]: loss 0.779903
[epoch19, step998]: loss 12.322453
[epoch19, step999]: loss 0.564904
[epoch19, step1000]: loss 3.084105
[epoch19, step1001]: loss 2.153912
[epoch19, step1002]: loss 3.014386
[epoch19, step1003]: loss 14.085075
[epoch19, step1004]: loss 0.817013
[epoch19, step1005]: loss 1.876490
[epoch19, step1006]: loss 0.970801
[epoch19, step1007]: loss 2.014693
[epoch19, step1008]: loss 2.921114
[epoch19, step1009]: loss 5.390704
[epoch19, step1010]: loss 0.542022
[epoch19, step1011]: loss 0.630381
[epoch19, step1012]: loss 6.331175
[epoch19, step1013]: loss 0.616741
[epoch19, step1014]: loss 14.195773
[epoch19, step1015]: loss 0.711770
[epoch19, step1016]: loss 2.433580
[epoch19, step1017]: loss 0.809117
[epoch19, step1018]: loss 2.374870
[epoch19, step1019]: loss 5.433565
[epoch19, step1020]: loss 0.756814
[epoch19, step1021]: loss 2.136633
[epoch19, step1022]: loss 2.090225
[epoch19, step1023]: loss 1.002966
[epoch19, step1024]: loss 0.721010
[epoch19, step1025]: loss 0.470004
[epoch19, step1026]: loss 2.714163
[epoch19, step1027]: loss 0.537660
[epoch19, step1028]: loss 0.687762
[epoch19, step1029]: loss 1.021210
[epoch19, step1030]: loss 4.856875
[epoch19, step1031]: loss 8.096544
[epoch19, step1032]: loss 5.973635
[epoch19, step1033]: loss 0.616565
[epoch19, step1034]: loss 5.058483
[epoch19, step1035]: loss 1.611299
[epoch19, step1036]: loss 10.571213
[epoch19, step1037]: loss 2.370927
[epoch19, step1038]: loss 0.602490
[epoch19, step1039]: loss 12.156623
[epoch19, step1040]: loss 9.026850
[epoch19, step1041]: loss 0.527848
[epoch19, step1042]: loss 1.205867
[epoch19, step1043]: loss 0.593040
[epoch19, step1044]: loss 1.111114
[epoch19, step1045]: loss 9.414673
[epoch19, step1046]: loss 0.984518
[epoch19, step1047]: loss 7.542724
[epoch19, step1048]: loss 0.931616
[epoch19, step1049]: loss 1.135657
[epoch19, step1050]: loss 5.424482
[epoch19, step1051]: loss 2.057678
[epoch19, step1052]: loss 5.384143
[epoch19, step1053]: loss 2.494591
[epoch19, step1054]: loss 2.341418
[epoch19, step1055]: loss 8.963560
[epoch19, step1056]: loss 10.749831
[epoch19, step1057]: loss 8.864387
[epoch19, step1058]: loss 7.230760
[epoch19, step1059]: loss 4.356678
[epoch19, step1060]: loss 4.634281
[epoch19, step1061]: loss 11.713383
[epoch19, step1062]: loss 0.935050
[epoch19, step1063]: loss 0.850614
[epoch19, step1064]: loss 0.532732
[epoch19, step1065]: loss 8.502257
[epoch19, step1066]: loss 1.647205
[epoch19, step1067]: loss 6.621439
[epoch19, step1068]: loss 0.588070
[epoch19, step1069]: loss 0.777708
[epoch19, step1070]: loss 8.622081
[epoch19, step1071]: loss 12.734122
[epoch19, step1072]: loss 16.850811
[epoch19, step1073]: loss 10.645431
[epoch19, step1074]: loss 2.236980
[epoch19, step1075]: loss 14.183861
[epoch19, step1076]: loss 0.749193
[epoch19, step1077]: loss 5.547169
[epoch19, step1078]: loss 5.476395
[epoch19, step1079]: loss 11.237924
[epoch19, step1080]: loss 6.836854
[epoch19, step1081]: loss 1.479895
[epoch19, step1082]: loss 10.463129
[epoch19, step1083]: loss 1.253502
[epoch19, step1084]: loss 1.090261
[epoch19, step1085]: loss 6.639161
[epoch19, step1086]: loss 0.614460
[epoch19, step1087]: loss 1.074685
[epoch19, step1088]: loss 2.369943
[epoch19, step1089]: loss 1.618266
[epoch19, step1090]: loss 1.096714
[epoch19, step1091]: loss 2.644522
[epoch19, step1092]: loss 1.054951
[epoch19, step1093]: loss 0.989575
[epoch19, step1094]: loss 1.600625
[epoch19, step1095]: loss 0.694451
[epoch19, step1096]: loss 2.947627
[epoch19, step1097]: loss 16.616583
[epoch19, step1098]: loss 1.556862
[epoch19, step1099]: loss 0.687530
[epoch19, step1100]: loss 1.019551
[epoch19, step1101]: loss 2.061682
[epoch19, step1102]: loss 1.357270
[epoch19, step1103]: loss 1.803222
[epoch19, step1104]: loss 7.336038
[epoch19, step1105]: loss 3.346862
[epoch19, step1106]: loss 2.141630
[epoch19, step1107]: loss 0.594033
[epoch19, step1108]: loss 0.851098
[epoch19, step1109]: loss 3.313030
[epoch19, step1110]: loss 0.792793
[epoch19, step1111]: loss 0.706015
[epoch19, step1112]: loss 0.998036
[epoch19, step1113]: loss 7.702052
[epoch19, step1114]: loss 2.240651
[epoch19, step1115]: loss 0.981398
[epoch19, step1116]: loss 1.814582
[epoch19, step1117]: loss 1.714615
[epoch19, step1118]: loss 0.715045
[epoch19, step1119]: loss 1.866715
[epoch19, step1120]: loss 0.624438
[epoch19, step1121]: loss 14.070845
[epoch19, step1122]: loss 0.556288
[epoch19, step1123]: loss 0.665031
[epoch19, step1124]: loss 1.218413
[epoch19, step1125]: loss 1.604675
[epoch19, step1126]: loss 0.631866
[epoch19, step1127]: loss 0.516671
[epoch19, step1128]: loss 6.366910
[epoch19, step1129]: loss 0.877591
[epoch19, step1130]: loss 6.254833
[epoch19, step1131]: loss 3.016249
[epoch19, step1132]: loss 1.326129
[epoch19, step1133]: loss 5.021744
[epoch19, step1134]: loss 11.855977
[epoch19, step1135]: loss 6.586894
[epoch19, step1136]: loss 1.337669
[epoch19, step1137]: loss 1.040395
[epoch19, step1138]: loss 3.125067
[epoch19, step1139]: loss 5.039888
[epoch19, step1140]: loss 2.698298
[epoch19, step1141]: loss 1.909995
[epoch19, step1142]: loss 0.708727
[epoch19, step1143]: loss 10.316507
[epoch19, step1144]: loss 10.003992
[epoch19, step1145]: loss 6.250005
[epoch19, step1146]: loss 1.549019
[epoch19, step1147]: loss 0.474615
[epoch19, step1148]: loss 1.059628
[epoch19, step1149]: loss 8.619478
[epoch19, step1150]: loss 2.506776
[epoch19, step1151]: loss 1.866104
[epoch19, step1152]: loss 2.103955
[epoch19, step1153]: loss 5.695506
[epoch19, step1154]: loss 6.435417
[epoch19, step1155]: loss 10.344570
[epoch19, step1156]: loss 1.496122
[epoch19, step1157]: loss 1.124704
[epoch19, step1158]: loss 2.672614
[epoch19, step1159]: loss 3.148631
[epoch19, step1160]: loss 0.613652
[epoch19, step1161]: loss 8.939194
[epoch19, step1162]: loss 4.499365
[epoch19, step1163]: loss 2.181926
[epoch19, step1164]: loss 0.766717
[epoch19, step1165]: loss 0.882788
[epoch19, step1166]: loss 1.046450
[epoch19, step1167]: loss 9.413392
[epoch19, step1168]: loss 0.961666
[epoch19, step1169]: loss 2.231189
[epoch19, step1170]: loss 10.418815
[epoch19, step1171]: loss 2.006413
[epoch19, step1172]: loss 5.141036
[epoch19, step1173]: loss 0.883925
[epoch19, step1174]: loss 9.465514
[epoch19, step1175]: loss 0.565763
[epoch19, step1176]: loss 7.611787
[epoch19, step1177]: loss 0.748908
[epoch19, step1178]: loss 0.715403
[epoch19, step1179]: loss 0.724311
[epoch19, step1180]: loss 1.470274
[epoch19, step1181]: loss 1.281890
[epoch19, step1182]: loss 5.077796
[epoch19, step1183]: loss 0.903262
[epoch19, step1184]: loss 4.813940
[epoch19, step1185]: loss 0.960936
[epoch19, step1186]: loss 1.052419
[epoch19, step1187]: loss 0.719225
[epoch19, step1188]: loss 1.753348
[epoch19, step1189]: loss 2.414651
[epoch19, step1190]: loss 0.934200
[epoch19, step1191]: loss 4.829252
[epoch19, step1192]: loss 1.330557
[epoch19, step1193]: loss 14.257058
[epoch19, step1194]: loss 1.351233
[epoch19, step1195]: loss 0.789119
[epoch19, step1196]: loss 7.193397
[epoch19, step1197]: loss 1.402204
[epoch19, step1198]: loss 1.487204
[epoch19, step1199]: loss 1.618874
[epoch19, step1200]: loss 9.481576
[epoch19, step1201]: loss 0.903736
[epoch19, step1202]: loss 6.657115
[epoch19, step1203]: loss 3.636342
[epoch19, step1204]: loss 0.891463
[epoch19, step1205]: loss 0.640105
[epoch19, step1206]: loss 1.012844
[epoch19, step1207]: loss 1.930928
[epoch19, step1208]: loss 0.951602
[epoch19, step1209]: loss 0.846228
[epoch19, step1210]: loss 9.536248
[epoch19, step1211]: loss 4.304691
[epoch19, step1212]: loss 10.310408
[epoch19, step1213]: loss 5.755187
[epoch19, step1214]: loss 2.537512
[epoch19, step1215]: loss 9.246843
[epoch19, step1216]: loss 0.703724
[epoch19, step1217]: loss 10.989447
[epoch19, step1218]: loss 5.997770
[epoch19, step1219]: loss 1.035096
[epoch19, step1220]: loss 0.670795
[epoch19, step1221]: loss 1.186489
[epoch19, step1222]: loss 0.597019
[epoch19, step1223]: loss 0.544423
[epoch19, step1224]: loss 0.637538
[epoch19, step1225]: loss 0.606079
[epoch19, step1226]: loss 1.308510
[epoch19, step1227]: loss 0.887768
[epoch19, step1228]: loss 0.769172
[epoch19, step1229]: loss 3.140987
[epoch19, step1230]: loss 5.546538
[epoch19, step1231]: loss 9.088574
[epoch19, step1232]: loss 10.203248
[epoch19, step1233]: loss 0.939002
[epoch19, step1234]: loss 0.597852
[epoch19, step1235]: loss 0.537311
[epoch19, step1236]: loss 2.359806
[epoch19, step1237]: loss 1.157934
[epoch19, step1238]: loss 0.728532
[epoch19, step1239]: loss 0.908498
[epoch19, step1240]: loss 1.113746
[epoch19, step1241]: loss 0.687399
[epoch19, step1242]: loss 1.246720
[epoch19, step1243]: loss 0.785128
[epoch19, step1244]: loss 3.659553
[epoch19, step1245]: loss 1.447109
[epoch19, step1246]: loss 0.575955
[epoch19, step1247]: loss 7.413396
[epoch19, step1248]: loss 11.302025
[epoch19, step1249]: loss 3.398879
[epoch19, step1250]: loss 7.312640
[epoch19, step1251]: loss 0.750894
[epoch19, step1252]: loss 6.819736
[epoch19, step1253]: loss 9.236547
[epoch19, step1254]: loss 1.152471
[epoch19, step1255]: loss 9.429772
[epoch19, step1256]: loss 1.760931
[epoch19, step1257]: loss 4.880418
[epoch19, step1258]: loss 10.390908
[epoch19, step1259]: loss 2.105481
[epoch19, step1260]: loss 5.493653
[epoch19, step1261]: loss 0.596779
[epoch19, step1262]: loss 2.280396
[epoch19, step1263]: loss 0.483027
[epoch19, step1264]: loss 1.172156
[epoch19, step1265]: loss 0.517252
[epoch19, step1266]: loss 1.951332
[epoch19, step1267]: loss 12.110558
[epoch19, step1268]: loss 1.447075
[epoch19, step1269]: loss 11.710985
[epoch19, step1270]: loss 0.469741
[epoch19, step1271]: loss 8.975519
[epoch19, step1272]: loss 2.674366
[epoch19, step1273]: loss 0.980037
[epoch19, step1274]: loss 6.321170
[epoch19, step1275]: loss 19.019781
[epoch19, step1276]: loss 0.589687
[epoch19, step1277]: loss 6.082646
[epoch19, step1278]: loss 0.856917
[epoch19, step1279]: loss 1.458508
[epoch19, step1280]: loss 7.214531
[epoch19, step1281]: loss 0.668323
[epoch19, step1282]: loss 1.725771
[epoch19, step1283]: loss 0.530288
[epoch19, step1284]: loss 5.822388
[epoch19, step1285]: loss 3.052508
[epoch19, step1286]: loss 2.100114
[epoch19, step1287]: loss 0.637405
[epoch19, step1288]: loss 1.353764
[epoch19, step1289]: loss 0.570503
[epoch19, step1290]: loss 0.500418
[epoch19, step1291]: loss 0.489724
[epoch19, step1292]: loss 8.864564
[epoch19, step1293]: loss 11.418412
[epoch19, step1294]: loss 0.879230
[epoch19, step1295]: loss 0.702981
[epoch19, step1296]: loss 1.189557
[epoch19, step1297]: loss 6.562503
[epoch19, step1298]: loss 1.918883
[epoch19, step1299]: loss 18.680298
[epoch19, step1300]: loss 2.007972
[epoch19, step1301]: loss 0.706568
[epoch19, step1302]: loss 1.008185
[epoch19, step1303]: loss 1.277899
[epoch19, step1304]: loss 13.146182
[epoch19, step1305]: loss 1.647772
[epoch19, step1306]: loss 8.459562
[epoch19, step1307]: loss 0.716027
[epoch19, step1308]: loss 0.736903
[epoch19, step1309]: loss 0.808752
[epoch19, step1310]: loss 8.625623
[epoch19, step1311]: loss 0.787001
[epoch19, step1312]: loss 2.130408
[epoch19, step1313]: loss 1.802472
[epoch19, step1314]: loss 2.241270
[epoch19, step1315]: loss 0.903339
[epoch19, step1316]: loss 0.885408
[epoch19, step1317]: loss 1.164873
[epoch19, step1318]: loss 0.683435
[epoch19, step1319]: loss 0.739624
[epoch19, step1320]: loss 3.239522
[epoch19, step1321]: loss 0.530975
[epoch19, step1322]: loss 12.303123
[epoch19, step1323]: loss 1.452341
[epoch19, step1324]: loss 13.899291
[epoch19, step1325]: loss 0.665583
[epoch19, step1326]: loss 2.525562
[epoch19, step1327]: loss 22.232758
[epoch19, step1328]: loss 1.349399
[epoch19, step1329]: loss 3.737186
[epoch19, step1330]: loss 1.338033
[epoch19, step1331]: loss 1.892723
[epoch19, step1332]: loss 2.550881
[epoch19, step1333]: loss 0.744996
[epoch19, step1334]: loss 1.008797
[epoch19, step1335]: loss 2.308780
[epoch19, step1336]: loss 8.868364
[epoch19, step1337]: loss 1.130132
[epoch19, step1338]: loss 2.387589
[epoch19, step1339]: loss 0.716170
[epoch19, step1340]: loss 1.544365
[epoch19, step1341]: loss 6.126898
[epoch19, step1342]: loss 1.945144
[epoch19, step1343]: loss 5.730173
[epoch19, step1344]: loss 2.756014
[epoch19, step1345]: loss 1.145062
[epoch19, step1346]: loss 7.012468
[epoch19, step1347]: loss 1.030554
[epoch19, step1348]: loss 0.618169
[epoch19, step1349]: loss 0.382374
[epoch19, step1350]: loss 15.345424
[epoch19, step1351]: loss 0.548407
[epoch19, step1352]: loss 2.806455
[epoch19, step1353]: loss 9.089906
[epoch19, step1354]: loss 7.788370
[epoch19, step1355]: loss 1.083171
[epoch19, step1356]: loss 0.496492
[epoch19, step1357]: loss 0.520728
[epoch19, step1358]: loss 0.645567
[epoch19, step1359]: loss 0.755286
[epoch19, step1360]: loss 1.345159
[epoch19, step1361]: loss 7.997792
[epoch19, step1362]: loss 1.439251
[epoch19, step1363]: loss 1.718712
[epoch19, step1364]: loss 1.003628
[epoch19, step1365]: loss 6.695418
[epoch19, step1366]: loss 1.648154
[epoch19, step1367]: loss 0.785530
[epoch19, step1368]: loss 6.782686
[epoch19, step1369]: loss 1.076081
[epoch19, step1370]: loss 0.831626
[epoch19, step1371]: loss 0.849541
[epoch19, step1372]: loss 13.553236
[epoch19, step1373]: loss 5.846303
[epoch19, step1374]: loss 10.281721
[epoch19, step1375]: loss 1.331747
[epoch19, step1376]: loss 1.168627
[epoch19, step1377]: loss 1.038967
[epoch19, step1378]: loss 9.214886
[epoch19, step1379]: loss 0.648079
[epoch19, step1380]: loss 1.221539
[epoch19, step1381]: loss 12.374278
[epoch19, step1382]: loss 4.091478
[epoch19, step1383]: loss 1.945566
[epoch19, step1384]: loss 2.153661
[epoch19, step1385]: loss 1.944608
[epoch19, step1386]: loss 1.233528
[epoch19, step1387]: loss 0.917266
[epoch19, step1388]: loss 6.287563
[epoch19, step1389]: loss 1.061482
[epoch19, step1390]: loss 15.183968
[epoch19, step1391]: loss 15.081939
[epoch19, step1392]: loss 0.542427
[epoch19, step1393]: loss 16.242943
[epoch19, step1394]: loss 9.715135
[epoch19, step1395]: loss 1.722767
[epoch19, step1396]: loss 0.456869
[epoch19, step1397]: loss 4.215555
[epoch19, step1398]: loss 0.748788
[epoch19, step1399]: loss 1.997318
[epoch19, step1400]: loss 0.625217
[epoch19, step1401]: loss 0.639220
[epoch19, step1402]: loss 0.762516
[epoch19, step1403]: loss 5.539471
[epoch19, step1404]: loss 5.824640
[epoch19, step1405]: loss 0.624357
[epoch19, step1406]: loss 0.890499
[epoch19, step1407]: loss 6.696155
[epoch19, step1408]: loss 12.485176
[epoch19, step1409]: loss 9.681482
[epoch19, step1410]: loss 3.335667
[epoch19, step1411]: loss 5.283860
[epoch19, step1412]: loss 1.017640
[epoch19, step1413]: loss 1.785374
[epoch19, step1414]: loss 6.190007
[epoch19, step1415]: loss 3.693131
[epoch19, step1416]: loss 1.343272
[epoch19, step1417]: loss 0.750078
[epoch19, step1418]: loss 2.661599
[epoch19, step1419]: loss 1.366095
[epoch19, step1420]: loss 1.374751
[epoch19, step1421]: loss 2.496677
[epoch19, step1422]: loss 1.067950
[epoch19, step1423]: loss 1.484054
[epoch19, step1424]: loss 3.272825
[epoch19, step1425]: loss 1.544371
[epoch19, step1426]: loss 3.286029
[epoch19, step1427]: loss 1.953451
[epoch19, step1428]: loss 0.889550
[epoch19, step1429]: loss 11.680094
[epoch19, step1430]: loss 0.714873
[epoch19, step1431]: loss 1.402348
[epoch19, step1432]: loss 1.291022
[epoch19, step1433]: loss 9.163827
[epoch19, step1434]: loss 7.745840
[epoch19, step1435]: loss 16.074978
[epoch19, step1436]: loss 1.943637
[epoch19, step1437]: loss 0.880523
[epoch19, step1438]: loss 12.576635
[epoch19, step1439]: loss 1.163485
[epoch19, step1440]: loss 8.308569
[epoch19, step1441]: loss 1.106885
[epoch19, step1442]: loss 0.999632
[epoch19, step1443]: loss 1.409220
[epoch19, step1444]: loss 5.747422
[epoch19, step1445]: loss 0.847812
[epoch19, step1446]: loss 6.362390
[epoch19, step1447]: loss 0.647004
[epoch19, step1448]: loss 0.665134
[epoch19, step1449]: loss 0.474916
[epoch19, step1450]: loss 9.307528
[epoch19, step1451]: loss 8.221795
[epoch19, step1452]: loss 0.581834
[epoch19, step1453]: loss 0.841320
[epoch19, step1454]: loss 29.644251
[epoch19, step1455]: loss 1.305693
[epoch19, step1456]: loss 2.879230
[epoch19, step1457]: loss 3.249271
[epoch19, step1458]: loss 2.509053
[epoch19, step1459]: loss 1.819448
[epoch19, step1460]: loss 3.544862
[epoch19, step1461]: loss 17.713596
[epoch19, step1462]: loss 1.683449
[epoch19, step1463]: loss 0.611282
[epoch19, step1464]: loss 2.007143
[epoch19, step1465]: loss 0.644490
[epoch19, step1466]: loss 0.620432
[epoch19, step1467]: loss 1.577872
[epoch19, step1468]: loss 3.577261
[epoch19, step1469]: loss 0.863784
[epoch19, step1470]: loss 0.953483
[epoch19, step1471]: loss 9.979416
[epoch19, step1472]: loss 1.130194
[epoch19, step1473]: loss 1.955404
[epoch19, step1474]: loss 0.893570
[epoch19, step1475]: loss 6.214115
[epoch19, step1476]: loss 1.445036
[epoch19, step1477]: loss 5.233886
[epoch19, step1478]: loss 0.636985
[epoch19, step1479]: loss 1.123987
[epoch19, step1480]: loss 1.390820
[epoch19, step1481]: loss 4.990617
[epoch19, step1482]: loss 3.612241
[epoch19, step1483]: loss 1.181446
[epoch19, step1484]: loss 0.615340
[epoch19, step1485]: loss 0.858932
[epoch19, step1486]: loss 0.595169
[epoch19, step1487]: loss 11.036738
[epoch19, step1488]: loss 0.741272
[epoch19, step1489]: loss 1.239820
[epoch19, step1490]: loss 1.736997
[epoch19, step1491]: loss 11.647337
[epoch19, step1492]: loss 1.372594
[epoch19, step1493]: loss 0.918588
[epoch19, step1494]: loss 3.986629
[epoch19, step1495]: loss 3.584416
[epoch19, step1496]: loss 8.689240
[epoch19, step1497]: loss 4.247494
[epoch19, step1498]: loss 1.821256
[epoch19, step1499]: loss 22.242682
[epoch19, step1500]: loss 7.833865
[epoch19, step1501]: loss 0.632986
[epoch19, step1502]: loss 0.459092
[epoch19, step1503]: loss 1.427730
[epoch19, step1504]: loss 0.613635
[epoch19, step1505]: loss 2.207610
[epoch19, step1506]: loss 8.788101
[epoch19, step1507]: loss 12.195958
[epoch19, step1508]: loss 0.580179
[epoch19, step1509]: loss 0.672293
[epoch19, step1510]: loss 1.986983
[epoch19, step1511]: loss 2.660009
[epoch19, step1512]: loss 1.081782
[epoch19, step1513]: loss 4.636983
[epoch19, step1514]: loss 0.860649
[epoch19, step1515]: loss 0.521656
[epoch19, step1516]: loss 5.660758
[epoch19, step1517]: loss 5.635479
[epoch19, step1518]: loss 1.130025
[epoch19, step1519]: loss 1.971374
[epoch19, step1520]: loss 1.824859
[epoch19, step1521]: loss 0.799298
[epoch19, step1522]: loss 8.065289
[epoch19, step1523]: loss 5.521601
[epoch19, step1524]: loss 2.767735
[epoch19, step1525]: loss 5.652359
[epoch19, step1526]: loss 0.614500
[epoch19, step1527]: loss 0.709608
[epoch19, step1528]: loss 5.232378
[epoch19, step1529]: loss 1.352787
[epoch19, step1530]: loss 1.196739
[epoch19, step1531]: loss 1.164968
[epoch19, step1532]: loss 1.441905
[epoch19, step1533]: loss 0.698733
[epoch19, step1534]: loss 0.624158
[epoch19, step1535]: loss 0.628998
[epoch19, step1536]: loss 0.720886
[epoch19, step1537]: loss 1.793437
[epoch19, step1538]: loss 1.418887
[epoch19, step1539]: loss 1.182607
[epoch19, step1540]: loss 6.286194
[epoch19, step1541]: loss 1.100156
[epoch19, step1542]: loss 2.393804
[epoch19, step1543]: loss 1.305006
[epoch19, step1544]: loss 10.102398
[epoch19, step1545]: loss 14.011950
[epoch19, step1546]: loss 1.249856
[epoch19, step1547]: loss 2.048009
[epoch19, step1548]: loss 0.536863
[epoch19, step1549]: loss 6.065547
[epoch19, step1550]: loss 1.222485
[epoch19, step1551]: loss 0.484767
[epoch19, step1552]: loss 1.120349
[epoch19, step1553]: loss 14.700361
[epoch19, step1554]: loss 0.669927
[epoch19, step1555]: loss 10.357416
[epoch19, step1556]: loss 0.739246
[epoch19, step1557]: loss 1.713196
[epoch19, step1558]: loss 4.835411
[epoch19, step1559]: loss 0.669460
[epoch19, step1560]: loss 0.600407
[epoch19, step1561]: loss 9.643840
[epoch19, step1562]: loss 6.286673
[epoch19, step1563]: loss 0.996938
[epoch19, step1564]: loss 0.813896
[epoch19, step1565]: loss 1.848085
[epoch19, step1566]: loss 2.094293
[epoch19, step1567]: loss 0.749092
[epoch19, step1568]: loss 0.733947
[epoch19, step1569]: loss 12.464594
[epoch19, step1570]: loss 10.130039
[epoch19, step1571]: loss 1.750338
[epoch19, step1572]: loss 1.496437
[epoch19, step1573]: loss 5.366100
[epoch19, step1574]: loss 1.766036
[epoch19, step1575]: loss 8.562182
[epoch19, step1576]: loss 1.653790
[epoch19, step1577]: loss 0.879609
[epoch19, step1578]: loss 6.340429
[epoch19, step1579]: loss 0.462532
[epoch19, step1580]: loss 5.779071
[epoch19, step1581]: loss 7.806267
[epoch19, step1582]: loss 1.232164
[epoch19, step1583]: loss 0.588823
[epoch19, step1584]: loss 1.357919
[epoch19, step1585]: loss 5.634582
[epoch19, step1586]: loss 0.594028
[epoch19, step1587]: loss 1.009646
[epoch19, step1588]: loss 5.865000
[epoch19, step1589]: loss 1.217360
[epoch19, step1590]: loss 2.911742
[epoch19, step1591]: loss 7.674777
[epoch19, step1592]: loss 5.746335
[epoch19, step1593]: loss 8.905661
[epoch19, step1594]: loss 11.189717
[epoch19, step1595]: loss 1.026089
[epoch19, step1596]: loss 8.851014
[epoch19, step1597]: loss 0.541523
[epoch19, step1598]: loss 7.553655
[epoch19, step1599]: loss 2.936235
[epoch19, step1600]: loss 6.657952
[epoch19, step1601]: loss 1.051605
[epoch19, step1602]: loss 0.762677
[epoch19, step1603]: loss 1.637673
[epoch19, step1604]: loss 10.840259
[epoch19, step1605]: loss 2.469192
[epoch19, step1606]: loss 1.047482
[epoch19, step1607]: loss 0.553368
[epoch19, step1608]: loss 7.038872
[epoch19, step1609]: loss 1.659616
[epoch19, step1610]: loss 1.873269
[epoch19, step1611]: loss 1.514975
[epoch19, step1612]: loss 17.864660
[epoch19, step1613]: loss 0.535377
[epoch19, step1614]: loss 0.821783
[epoch19, step1615]: loss 1.251176
[epoch19, step1616]: loss 0.661247
[epoch19, step1617]: loss 0.444571
[epoch19, step1618]: loss 0.730731
[epoch19, step1619]: loss 12.647687
[epoch19, step1620]: loss 3.083495
[epoch19, step1621]: loss 1.598522
[epoch19, step1622]: loss 7.051444
[epoch19, step1623]: loss 5.958939
[epoch19, step1624]: loss 7.062158
[epoch19, step1625]: loss 2.312941
[epoch19, step1626]: loss 7.889489
[epoch19, step1627]: loss 2.370597
[epoch19, step1628]: loss 0.781215
[epoch19, step1629]: loss 7.069318
[epoch19, step1630]: loss 1.550039
[epoch19, step1631]: loss 1.233086
[epoch19, step1632]: loss 0.503169
[epoch19, step1633]: loss 8.243646
[epoch19, step1634]: loss 0.438201
[epoch19, step1635]: loss 2.233829
[epoch19, step1636]: loss 0.964564
[epoch19, step1637]: loss 2.286022
[epoch19, step1638]: loss 0.377140
[epoch19, step1639]: loss 1.665554
[epoch19, step1640]: loss 5.288701
[epoch19, step1641]: loss 0.721455
[epoch19, step1642]: loss 5.156300
[epoch19, step1643]: loss 0.824870
[epoch19, step1644]: loss 3.279718
[epoch19, step1645]: loss 1.609782
[epoch19, step1646]: loss 1.808463
[epoch19, step1647]: loss 1.095140
[epoch19, step1648]: loss 1.277812
[epoch19, step1649]: loss 19.005976
[epoch19, step1650]: loss 5.651837
[epoch19, step1651]: loss 5.268124
[epoch19, step1652]: loss 0.797063
[epoch19, step1653]: loss 1.731798
[epoch19, step1654]: loss 0.678821
[epoch19, step1655]: loss 15.550942
[epoch19, step1656]: loss 1.947279
[epoch19, step1657]: loss 1.140373
[epoch19, step1658]: loss 6.192934
[epoch19, step1659]: loss 1.360015
[epoch19, step1660]: loss 1.020818
[epoch19, step1661]: loss 2.433186
[epoch19, step1662]: loss 18.682478
[epoch19, step1663]: loss 7.205921
[epoch19, step1664]: loss 5.278687
[epoch19, step1665]: loss 1.245883
[epoch19, step1666]: loss 0.417248
[epoch19, step1667]: loss 9.813332
[epoch19, step1668]: loss 0.553832
[epoch19, step1669]: loss 11.846461
[epoch19, step1670]: loss 2.994725
[epoch19, step1671]: loss 6.016633
[epoch19, step1672]: loss 1.715937
[epoch19, step1673]: loss 1.139714
[epoch19, step1674]: loss 7.084948
[epoch19, step1675]: loss 0.490207
[epoch19, step1676]: loss 0.550075
[epoch19, step1677]: loss 0.651182
[epoch19, step1678]: loss 1.662191
[epoch19, step1679]: loss 5.534847
[epoch19, step1680]: loss 1.843827
[epoch19, step1681]: loss 0.930736
[epoch19, step1682]: loss 0.742193
[epoch19, step1683]: loss 5.747726
[epoch19, step1684]: loss 0.704777
[epoch19, step1685]: loss 0.735693
[epoch19, step1686]: loss 0.811296
[epoch19, step1687]: loss 2.415825
[epoch19, step1688]: loss 13.042447
[epoch19, step1689]: loss 1.872324
[epoch19, step1690]: loss 1.136679
[epoch19, step1691]: loss 0.831588
[epoch19, step1692]: loss 5.699686
[epoch19, step1693]: loss 1.270598
[epoch19, step1694]: loss 1.885715
[epoch19, step1695]: loss 2.722246
[epoch19, step1696]: loss 5.525803
[epoch19, step1697]: loss 0.602376
[epoch19, step1698]: loss 0.847727
[epoch19, step1699]: loss 9.693178
[epoch19, step1700]: loss 0.565065
[epoch19, step1701]: loss 0.483461
[epoch19, step1702]: loss 14.002573
[epoch19, step1703]: loss 1.062830
[epoch19, step1704]: loss 2.096742
[epoch19, step1705]: loss 2.752196
[epoch19, step1706]: loss 5.741778
[epoch19, step1707]: loss 12.195643
[epoch19, step1708]: loss 1.164228
[epoch19, step1709]: loss 0.771437
[epoch19, step1710]: loss 0.875241
[epoch19, step1711]: loss 11.672260
[epoch19, step1712]: loss 0.967507
[epoch19, step1713]: loss 2.350019
[epoch19, step1714]: loss 11.567763
[epoch19, step1715]: loss 1.875502
[epoch19, step1716]: loss 0.546593
[epoch19, step1717]: loss 0.578604
[epoch19, step1718]: loss 1.313426
[epoch19, step1719]: loss 0.498399
[epoch19, step1720]: loss 17.544405
[epoch19, step1721]: loss 1.178404
[epoch19, step1722]: loss 1.590286
[epoch19, step1723]: loss 1.141818
[epoch19, step1724]: loss 10.528771
[epoch19, step1725]: loss 1.029145
[epoch19, step1726]: loss 0.940299
[epoch19, step1727]: loss 5.537000
[epoch19, step1728]: loss 1.432522
[epoch19, step1729]: loss 2.815345
[epoch19, step1730]: loss 0.981123
[epoch19, step1731]: loss 1.657846
[epoch19, step1732]: loss 1.447756
[epoch19, step1733]: loss 3.253254
[epoch19, step1734]: loss 1.319529
[epoch19, step1735]: loss 9.894690
[epoch19, step1736]: loss 1.071587
[epoch19, step1737]: loss 1.786406
[epoch19, step1738]: loss 7.133735
[epoch19, step1739]: loss 1.458049
[epoch19, step1740]: loss 0.875745
[epoch19, step1741]: loss 0.960766
[epoch19, step1742]: loss 1.595988
[epoch19, step1743]: loss 0.936629
[epoch19, step1744]: loss 1.316581
[epoch19, step1745]: loss 9.704972
[epoch19, step1746]: loss 5.254348
[epoch19, step1747]: loss 0.515167
[epoch19, step1748]: loss 6.846902
[epoch19, step1749]: loss 3.201106
[epoch19, step1750]: loss 1.065841
[epoch19, step1751]: loss 1.299323
[epoch19, step1752]: loss 2.008842
[epoch19, step1753]: loss 2.077666
[epoch19, step1754]: loss 3.076658
[epoch19, step1755]: loss 1.672061
[epoch19, step1756]: loss 5.006365
[epoch19, step1757]: loss 2.044360
[epoch19, step1758]: loss 1.958136
[epoch19, step1759]: loss 0.830522
[epoch19, step1760]: loss 8.586795
[epoch19, step1761]: loss 1.848267
[epoch19, step1762]: loss 8.770149
[epoch19, step1763]: loss 7.634218
[epoch19, step1764]: loss 1.525788
[epoch19, step1765]: loss 0.703382
[epoch19, step1766]: loss 2.723111
[epoch19, step1767]: loss 2.843478
[epoch19, step1768]: loss 7.362231
[epoch19, step1769]: loss 1.214664
[epoch19, step1770]: loss 11.192986
[epoch19, step1771]: loss 1.540824
[epoch19, step1772]: loss 10.195922
[epoch19, step1773]: loss 11.183301
[epoch19, step1774]: loss 0.929815
[epoch19, step1775]: loss 0.350249
[epoch19, step1776]: loss 6.002872
[epoch19, step1777]: loss 11.649971
[epoch19, step1778]: loss 5.486865
[epoch19, step1779]: loss 3.924459
[epoch19, step1780]: loss 1.392991
[epoch19, step1781]: loss 0.697287
[epoch19, step1782]: loss 0.708331
[epoch19, step1783]: loss 0.908751
[epoch19, step1784]: loss 0.695086
[epoch19, step1785]: loss 6.082693
[epoch19, step1786]: loss 1.679296
[epoch19, step1787]: loss 0.486798
[epoch19, step1788]: loss 0.640987
[epoch19, step1789]: loss 6.348559
[epoch19, step1790]: loss 2.066208
[epoch19, step1791]: loss 0.620744
[epoch19, step1792]: loss 1.572458
[epoch19, step1793]: loss 0.541182
[epoch19, step1794]: loss 0.635812
[epoch19, step1795]: loss 1.887640
[epoch19, step1796]: loss 11.155867
[epoch19, step1797]: loss 5.438206
[epoch19, step1798]: loss 1.197958
[epoch19, step1799]: loss 1.042446
[epoch19, step1800]: loss 2.217236
[epoch19, step1801]: loss 12.265152
[epoch19, step1802]: loss 2.057352
[epoch19, step1803]: loss 0.999434
[epoch19, step1804]: loss 4.842545
[epoch19, step1805]: loss 1.433777
[epoch19, step1806]: loss 2.435581
[epoch19, step1807]: loss 10.627482
[epoch19, step1808]: loss 11.581948
[epoch19, step1809]: loss 2.553185
[epoch19, step1810]: loss 5.429595
[epoch19, step1811]: loss 1.463681
[epoch19, step1812]: loss 2.306587
[epoch19, step1813]: loss 0.948875
[epoch19, step1814]: loss 1.150052
[epoch19, step1815]: loss 4.995794
[epoch19, step1816]: loss 5.144438
[epoch19, step1817]: loss 0.784175
[epoch19, step1818]: loss 0.846267
[epoch19, step1819]: loss 2.378327
[epoch19, step1820]: loss 0.711396
[epoch19, step1821]: loss 16.410723
[epoch19, step1822]: loss 1.086616
[epoch19, step1823]: loss 10.100334
[epoch19, step1824]: loss 2.291677
[epoch19, step1825]: loss 1.305367
[epoch19, step1826]: loss 1.082835
[epoch19, step1827]: loss 1.228431
[epoch19, step1828]: loss 0.688255
[epoch19, step1829]: loss 1.671296
[epoch19, step1830]: loss 1.492883
[epoch19, step1831]: loss 0.658247
[epoch19, step1832]: loss 9.567198
[epoch19, step1833]: loss 0.492000
[epoch19, step1834]: loss 5.826835
[epoch19, step1835]: loss 6.271107
[epoch19, step1836]: loss 1.130729
[epoch19, step1837]: loss 0.794528
[epoch19, step1838]: loss 1.148663
[epoch19, step1839]: loss 0.617266
[epoch19, step1840]: loss 0.571214
[epoch19, step1841]: loss 7.179077
[epoch19, step1842]: loss 0.580129
[epoch19, step1843]: loss 0.490637
[epoch19, step1844]: loss 9.932359
[epoch19, step1845]: loss 1.358909
[epoch19, step1846]: loss 0.769038
[epoch19, step1847]: loss 2.831752
[epoch19, step1848]: loss 0.816561
[epoch19, step1849]: loss 1.443288
[epoch19, step1850]: loss 1.816312
[epoch19, step1851]: loss 16.610312
[epoch19, step1852]: loss 5.695925
[epoch19, step1853]: loss 0.991432
[epoch19, step1854]: loss 14.312806
[epoch19, step1855]: loss 9.267704
[epoch19, step1856]: loss 2.344041
[epoch19, step1857]: loss 0.976442
[epoch19, step1858]: loss 0.607874
[epoch19, step1859]: loss 1.553000
[epoch19, step1860]: loss 9.653930
[epoch19, step1861]: loss 0.452332
[epoch19, step1862]: loss 1.365409
[epoch19, step1863]: loss 9.353118
[epoch19, step1864]: loss 17.955477
[epoch19, step1865]: loss 1.886917
[epoch19, step1866]: loss 1.036697
[epoch19, step1867]: loss 0.720858
[epoch19, step1868]: loss 5.615848
[epoch19, step1869]: loss 0.679275
[epoch19, step1870]: loss 1.651956
[epoch19, step1871]: loss 0.519605
[epoch19, step1872]: loss 18.114119
[epoch19, step1873]: loss 8.896567
[epoch19, step1874]: loss 1.654467
[epoch19, step1875]: loss 5.180146
[epoch19, step1876]: loss 5.234378
[epoch19, step1877]: loss 0.904475
[epoch19, step1878]: loss 0.805379
[epoch19, step1879]: loss 11.953708
[epoch19, step1880]: loss 0.805528
[epoch19, step1881]: loss 1.268867
[epoch19, step1882]: loss 2.269873
[epoch19, step1883]: loss 1.243645
[epoch19, step1884]: loss 0.825645
[epoch19, step1885]: loss 0.812407
[epoch19, step1886]: loss 2.013304
[epoch19, step1887]: loss 16.361542
[epoch19, step1888]: loss 2.427667
[epoch19, step1889]: loss 7.836270
[epoch19, step1890]: loss 5.648378
[epoch19, step1891]: loss 4.925715
[epoch19, step1892]: loss 11.877438
[epoch19, step1893]: loss 1.078062
[epoch19, step1894]: loss 14.177106
[epoch19, step1895]: loss 0.568840
[epoch19, step1896]: loss 0.531433
[epoch19, step1897]: loss 2.723763
[epoch19, step1898]: loss 1.115909
[epoch19, step1899]: loss 1.096207
[epoch19, step1900]: loss 5.757368
[epoch19, step1901]: loss 5.754514
[epoch19, step1902]: loss 5.032181
[epoch19, step1903]: loss 6.235947
[epoch19, step1904]: loss 1.907411
[epoch19, step1905]: loss 2.842466
[epoch19, step1906]: loss 14.327904
[epoch19, step1907]: loss 0.500383
[epoch19, step1908]: loss 5.063218
[epoch19, step1909]: loss 9.533579
[epoch19, step1910]: loss 0.802025
[epoch19, step1911]: loss 7.983992
[epoch19, step1912]: loss 2.208908
[epoch19, step1913]: loss 1.597278
[epoch19, step1914]: loss 1.557181
[epoch19, step1915]: loss 0.616411
[epoch19, step1916]: loss 0.869064
[epoch19, step1917]: loss 6.897958
[epoch19, step1918]: loss 16.252357
[epoch19, step1919]: loss 8.116859
[epoch19, step1920]: loss 6.596211
[epoch19, step1921]: loss 10.320063
[epoch19, step1922]: loss 6.140163
[epoch19, step1923]: loss 1.193638
[epoch19, step1924]: loss 2.461891
[epoch19, step1925]: loss 0.893548
[epoch19, step1926]: loss 4.826787
[epoch19, step1927]: loss 12.856974
[epoch19, step1928]: loss 1.073163
[epoch19, step1929]: loss 2.440849
[epoch19, step1930]: loss 0.690719
[epoch19, step1931]: loss 1.292430
[epoch19, step1932]: loss 6.410070
[epoch19, step1933]: loss 1.293448
[epoch19, step1934]: loss 1.199095
[epoch19, step1935]: loss 0.936731
[epoch19, step1936]: loss 25.652164
[epoch19, step1937]: loss 6.354103
[epoch19, step1938]: loss 2.961673
[epoch19, step1939]: loss 0.526147
[epoch19, step1940]: loss 11.048065
[epoch19, step1941]: loss 16.637245
[epoch19, step1942]: loss 5.371290
[epoch19, step1943]: loss 2.966912
[epoch19, step1944]: loss 0.815476
[epoch19, step1945]: loss 3.789575
[epoch19, step1946]: loss 0.532904
[epoch19, step1947]: loss 1.459439
[epoch19, step1948]: loss 8.128669
[epoch19, step1949]: loss 0.732322
[epoch19, step1950]: loss 6.801503
[epoch19, step1951]: loss 0.771371
[epoch19, step1952]: loss 7.886137
[epoch19, step1953]: loss 0.953549
[epoch19, step1954]: loss 9.644715
[epoch19, step1955]: loss 1.151866
[epoch19, step1956]: loss 1.117939
[epoch19, step1957]: loss 2.232267
[epoch19, step1958]: loss 0.809765
[epoch19, step1959]: loss 9.623515
[epoch19, step1960]: loss 1.561720
[epoch19, step1961]: loss 0.598476
[epoch19, step1962]: loss 8.059352
[epoch19, step1963]: loss 1.436132
[epoch19, step1964]: loss 1.458684
[epoch19, step1965]: loss 0.654821
[epoch19, step1966]: loss 3.562323
[epoch19, step1967]: loss 9.969405
[epoch19, step1968]: loss 1.028395
[epoch19, step1969]: loss 1.679553
[epoch19, step1970]: loss 2.190361
[epoch19, step1971]: loss 1.568569
[epoch19, step1972]: loss 0.895894
[epoch19, step1973]: loss 2.683310
[epoch19, step1974]: loss 10.550229
[epoch19, step1975]: loss 3.530988
[epoch19, step1976]: loss 0.996642
[epoch19, step1977]: loss 1.399933
[epoch19, step1978]: loss 3.212622
[epoch19, step1979]: loss 0.576022
[epoch19, step1980]: loss 2.803958
[epoch19, step1981]: loss 0.769711
[epoch19, step1982]: loss 2.367325
[epoch19, step1983]: loss 10.132768
[epoch19, step1984]: loss 0.729327
[epoch19, step1985]: loss 0.534537
[epoch19, step1986]: loss 6.168104
[epoch19, step1987]: loss 6.965926
[epoch19, step1988]: loss 6.961847
[epoch19, step1989]: loss 0.988443
[epoch19, step1990]: loss 0.893070
[epoch19, step1991]: loss 0.495933
[epoch19, step1992]: loss 4.836996
[epoch19, step1993]: loss 1.085339
[epoch19, step1994]: loss 0.879066
[epoch19, step1995]: loss 6.555309
[epoch19, step1996]: loss 0.651904
[epoch19, step1997]: loss 11.201546
[epoch19, step1998]: loss 1.341380
[epoch19, step1999]: loss 0.928378
[epoch19, step2000]: loss 1.581644
[epoch19, step2001]: loss 0.837648
[epoch19, step2002]: loss 10.286135
[epoch19, step2003]: loss 1.705054
[epoch19, step2004]: loss 0.893377
[epoch19, step2005]: loss 1.905255
[epoch19, step2006]: loss 0.696470
[epoch19, step2007]: loss 0.839297
[epoch19, step2008]: loss 4.346424
[epoch19, step2009]: loss 1.053169
[epoch19, step2010]: loss 1.753278
[epoch19, step2011]: loss 0.786680
[epoch19, step2012]: loss 10.499441
[epoch19, step2013]: loss 10.477647
[epoch19, step2014]: loss 2.702639
[epoch19, step2015]: loss 0.687604
[epoch19, step2016]: loss 7.653715
[epoch19, step2017]: loss 3.583433
[epoch19, step2018]: loss 7.666108
[epoch19, step2019]: loss 8.223624
[epoch19, step2020]: loss 1.318677
[epoch19, step2021]: loss 0.890834
[epoch19, step2022]: loss 0.844631
[epoch19, step2023]: loss 1.374158
[epoch19, step2024]: loss 0.724820
[epoch19, step2025]: loss 0.997219
[epoch19, step2026]: loss 1.331170
[epoch19, step2027]: loss 0.945183
[epoch19, step2028]: loss 6.774281
[epoch19, step2029]: loss 2.637016
[epoch19, step2030]: loss 0.576506
[epoch19, step2031]: loss 1.836411
[epoch19, step2032]: loss 1.154228
[epoch19, step2033]: loss 1.222994
[epoch19, step2034]: loss 7.440494
[epoch19, step2035]: loss 0.653272
[epoch19, step2036]: loss 6.484974
[epoch19, step2037]: loss 11.194882
[epoch19, step2038]: loss 0.693101
[epoch19, step2039]: loss 0.698708
[epoch19, step2040]: loss 4.914832
[epoch19, step2041]: loss 3.389508
[epoch19, step2042]: loss 5.632562
[epoch19, step2043]: loss 2.753645
[epoch19, step2044]: loss 9.745965
[epoch19, step2045]: loss 0.634585
[epoch19, step2046]: loss 1.228426
[epoch19, step2047]: loss 3.376822
[epoch19, step2048]: loss 0.791328
[epoch19, step2049]: loss 2.817128
[epoch19, step2050]: loss 0.941478
[epoch19, step2051]: loss 2.552624
[epoch19, step2052]: loss 2.474349
[epoch19, step2053]: loss 0.686125
[epoch19, step2054]: loss 2.965630
[epoch19, step2055]: loss 1.054808
[epoch19, step2056]: loss 0.774118
[epoch19, step2057]: loss 1.000266
[epoch19, step2058]: loss 0.635687
[epoch19, step2059]: loss 0.902804
[epoch19, step2060]: loss 6.683871
[epoch19, step2061]: loss 1.755873
[epoch19, step2062]: loss 0.686024
[epoch19, step2063]: loss 1.462783
[epoch19, step2064]: loss 1.520174
[epoch19, step2065]: loss 9.022769
[epoch19, step2066]: loss 4.955866
[epoch19, step2067]: loss 1.350471
[epoch19, step2068]: loss 1.174675
[epoch19, step2069]: loss 0.909930
[epoch19, step2070]: loss 12.946599
[epoch19, step2071]: loss 1.193514
[epoch19, step2072]: loss 3.982690
[epoch19, step2073]: loss 0.932692
[epoch19, step2074]: loss 1.003096
[epoch19, step2075]: loss 7.023979
[epoch19, step2076]: loss 8.752522
[epoch19, step2077]: loss 1.635341
[epoch19, step2078]: loss 0.537176
[epoch19, step2079]: loss 7.630579
[epoch19, step2080]: loss 2.050234
[epoch19, step2081]: loss 0.869199
[epoch19, step2082]: loss 1.131441
[epoch19, step2083]: loss 1.921763
[epoch19, step2084]: loss 0.468798
[epoch19, step2085]: loss 6.313919
[epoch19, step2086]: loss 5.490478
[epoch19, step2087]: loss 1.200205
[epoch19, step2088]: loss 0.709186
[epoch19, step2089]: loss 0.640927
[epoch19, step2090]: loss 1.497594
[epoch19, step2091]: loss 0.588406
[epoch19, step2092]: loss 0.924646
[epoch19, step2093]: loss 0.615088
[epoch19, step2094]: loss 4.093585
[epoch19, step2095]: loss 13.063156
[epoch19, step2096]: loss 5.138490
[epoch19, step2097]: loss 8.203277
[epoch19, step2098]: loss 6.340695
[epoch19, step2099]: loss 1.108624
[epoch19, step2100]: loss 1.463721
[epoch19, step2101]: loss 0.387779
[epoch19, step2102]: loss 2.641388
[epoch19, step2103]: loss 1.288993
[epoch19, step2104]: loss 4.483701
[epoch19, step2105]: loss 0.794685
[epoch19, step2106]: loss 0.732657
[epoch19, step2107]: loss 7.208380
[epoch19, step2108]: loss 2.080276
[epoch19, step2109]: loss 0.659446
[epoch19, step2110]: loss 0.791169
[epoch19, step2111]: loss 12.805964
[epoch19, step2112]: loss 4.677841
[epoch19, step2113]: loss 0.919434
[epoch19, step2114]: loss 0.523725
[epoch19, step2115]: loss 5.086481
[epoch19, step2116]: loss 8.386743
[epoch19, step2117]: loss 3.819984
[epoch19, step2118]: loss 0.865611
[epoch19, step2119]: loss 3.824584
[epoch19, step2120]: loss 0.789363
[epoch19, step2121]: loss 4.575992
[epoch19, step2122]: loss 0.485884
[epoch19, step2123]: loss 1.385743
[epoch19, step2124]: loss 0.938450
[epoch19, step2125]: loss 1.088742
[epoch19, step2126]: loss 1.484617
[epoch19, step2127]: loss 0.535277
[epoch19, step2128]: loss 1.484733
[epoch19, step2129]: loss 7.224314
[epoch19, step2130]: loss 0.645219
[epoch19, step2131]: loss 1.390492
[epoch19, step2132]: loss 2.496774
[epoch19, step2133]: loss 16.873119
[epoch19, step2134]: loss 0.886485
[epoch19, step2135]: loss 0.424626
[epoch19, step2136]: loss 1.699950
[epoch19, step2137]: loss 2.200229
[epoch19, step2138]: loss 2.289875
[epoch19, step2139]: loss 2.117121
[epoch19, step2140]: loss 0.429274
[epoch19, step2141]: loss 1.425645
[epoch19, step2142]: loss 0.728342
[epoch19, step2143]: loss 11.541548
[epoch19, step2144]: loss 0.726912
[epoch19, step2145]: loss 0.708821
[epoch19, step2146]: loss 0.904773
[epoch19, step2147]: loss 6.820645
[epoch19, step2148]: loss 10.770449
[epoch19, step2149]: loss 7.553466
[epoch19, step2150]: loss 7.353255
[epoch19, step2151]: loss 1.789454
[epoch19, step2152]: loss 1.262285
[epoch19, step2153]: loss 7.337115
[epoch19, step2154]: loss 1.639992
[epoch19, step2155]: loss 1.803172
[epoch19, step2156]: loss 3.751080
[epoch19, step2157]: loss 0.701402
[epoch19, step2158]: loss 0.816825
[epoch19, step2159]: loss 0.832088
[epoch19, step2160]: loss 0.858072
[epoch19, step2161]: loss 1.257850
[epoch19, step2162]: loss 1.523057
[epoch19, step2163]: loss 6.643700
[epoch19, step2164]: loss 3.023489
[epoch19, step2165]: loss 6.701313
[epoch19, step2166]: loss 16.753489
[epoch19, step2167]: loss 2.023085
[epoch19, step2168]: loss 0.579018
[epoch19, step2169]: loss 7.217247
[epoch19, step2170]: loss 4.822970
[epoch19, step2171]: loss 2.065682
[epoch19, step2172]: loss 14.959677
[epoch19, step2173]: loss 0.987843
[epoch19, step2174]: loss 2.042489
[epoch19, step2175]: loss 0.441214
[epoch19, step2176]: loss 1.174568
[epoch19, step2177]: loss 5.958879
[epoch19, step2178]: loss 6.449925
[epoch19, step2179]: loss 3.069885
[epoch19, step2180]: loss 1.851369
[epoch19, step2181]: loss 0.537272
[epoch19, step2182]: loss 1.142937
[epoch19, step2183]: loss 0.845206
[epoch19, step2184]: loss 2.656359
[epoch19, step2185]: loss 10.057477
[epoch19, step2186]: loss 5.372204
[epoch19, step2187]: loss 0.824442
[epoch19, step2188]: loss 3.067580
[epoch19, step2189]: loss 1.469975
[epoch19, step2190]: loss 0.680880
[epoch19, step2191]: loss 15.859989
[epoch19, step2192]: loss 5.419710
[epoch19, step2193]: loss 4.670209
[epoch19, step2194]: loss 9.977484
[epoch19, step2195]: loss 0.934651
[epoch19, step2196]: loss 0.518682
[epoch19, step2197]: loss 1.536688
[epoch19, step2198]: loss 2.478320
[epoch19, step2199]: loss 8.151250
[epoch19, step2200]: loss 0.631877
[epoch19, step2201]: loss 1.201620
[epoch19, step2202]: loss 2.932842
[epoch19, step2203]: loss 9.410817
[epoch19, step2204]: loss 0.750344
[epoch19, step2205]: loss 2.397147
[epoch19, step2206]: loss 8.803166
[epoch19, step2207]: loss 1.649458
[epoch19, step2208]: loss 2.363687
[epoch19, step2209]: loss 0.976398
[epoch19, step2210]: loss 0.575085
[epoch19, step2211]: loss 0.518395
[epoch19, step2212]: loss 1.021689
[epoch19, step2213]: loss 2.815686
[epoch19, step2214]: loss 1.885856
[epoch19, step2215]: loss 2.133078
[epoch19, step2216]: loss 2.310637
[epoch19, step2217]: loss 2.491603
[epoch19, step2218]: loss 0.856380
[epoch19, step2219]: loss 7.233788
[epoch19, step2220]: loss 8.834586
[epoch19, step2221]: loss 6.727861
[epoch19, step2222]: loss 11.366728
[epoch19, step2223]: loss 1.104340
[epoch19, step2224]: loss 0.776016
[epoch19, step2225]: loss 0.939417
[epoch19, step2226]: loss 2.411054
[epoch19, step2227]: loss 1.569552
[epoch19, step2228]: loss 7.381852
[epoch19, step2229]: loss 0.632889
[epoch19, step2230]: loss 3.455048
[epoch19, step2231]: loss 9.099099
[epoch19, step2232]: loss 0.980865
[epoch19, step2233]: loss 12.984838
[epoch19, step2234]: loss 1.207692
[epoch19, step2235]: loss 7.140882
[epoch19, step2236]: loss 7.743996
[epoch19, step2237]: loss 0.580373
[epoch19, step2238]: loss 0.704863
[epoch19, step2239]: loss 3.815267
[epoch19, step2240]: loss 1.311730
[epoch19, step2241]: loss 8.554249
[epoch19, step2242]: loss 0.863263
[epoch19, step2243]: loss 13.298166
[epoch19, step2244]: loss 0.616726
[epoch19, step2245]: loss 1.083576
[epoch19, step2246]: loss 1.070547
[epoch19, step2247]: loss 1.437384
[epoch19, step2248]: loss 6.078610
[epoch19, step2249]: loss 1.471763
[epoch19, step2250]: loss 1.191828
[epoch19, step2251]: loss 6.030232
[epoch19, step2252]: loss 1.290154
[epoch19, step2253]: loss 0.758697
[epoch19, step2254]: loss 0.566728
[epoch19, step2255]: loss 8.271446
[epoch19, step2256]: loss 0.849794
[epoch19, step2257]: loss 0.627779
[epoch19, step2258]: loss 1.900810
[epoch19, step2259]: loss 0.724931
[epoch19, step2260]: loss 0.628728
[epoch19, step2261]: loss 1.133289
[epoch19, step2262]: loss 10.660692
[epoch19, step2263]: loss 2.475355
[epoch19, step2264]: loss 6.946943
[epoch19, step2265]: loss 0.550177
[epoch19, step2266]: loss 1.287606
[epoch19, step2267]: loss 1.000506
[epoch19, step2268]: loss 1.930434
[epoch19, step2269]: loss 10.883492
[epoch19, step2270]: loss 8.323380
[epoch19, step2271]: loss 0.455654
[epoch19, step2272]: loss 9.724154
[epoch19, step2273]: loss 1.141423
[epoch19, step2274]: loss 0.684250
[epoch19, step2275]: loss 2.081829
[epoch19, step2276]: loss 1.284110
[epoch19, step2277]: loss 1.759193
[epoch19, step2278]: loss 0.859008
[epoch19, step2279]: loss 0.831569
[epoch19, step2280]: loss 0.580219
[epoch19, step2281]: loss 0.490164
[epoch19, step2282]: loss 2.044075
[epoch19, step2283]: loss 1.705387
[epoch19, step2284]: loss 0.655292
[epoch19, step2285]: loss 1.578099
[epoch19, step2286]: loss 1.282267
[epoch19, step2287]: loss 0.499735
[epoch19, step2288]: loss 0.783001
[epoch19, step2289]: loss 12.335814
[epoch19, step2290]: loss 11.516377
[epoch19, step2291]: loss 0.604490
[epoch19, step2292]: loss 0.987685
[epoch19, step2293]: loss 4.843414
[epoch19, step2294]: loss 1.376322
[epoch19, step2295]: loss 1.344623
[epoch19, step2296]: loss 1.442452
[epoch19, step2297]: loss 18.871229
[epoch19, step2298]: loss 1.722883
[epoch19, step2299]: loss 6.684913
[epoch19, step2300]: loss 2.544178
[epoch19, step2301]: loss 9.422980
[epoch19, step2302]: loss 3.534160
[epoch19, step2303]: loss 1.901114
[epoch19, step2304]: loss 1.546893
[epoch19, step2305]: loss 1.031334
[epoch19, step2306]: loss 11.317032
[epoch19, step2307]: loss 1.723323
[epoch19, step2308]: loss 8.727355
[epoch19, step2309]: loss 1.505549
[epoch19, step2310]: loss 6.472865
[epoch19, step2311]: loss 5.963487
[epoch19, step2312]: loss 1.322344
[epoch19, step2313]: loss 1.000447
[epoch19, step2314]: loss 6.338883
[epoch19, step2315]: loss 1.108697
[epoch19, step2316]: loss 1.228258
[epoch19, step2317]: loss 2.755141
[epoch19, step2318]: loss 3.015061
[epoch19, step2319]: loss 6.719868
[epoch19, step2320]: loss 0.536636
[epoch19, step2321]: loss 10.675905
[epoch19, step2322]: loss 2.606390
[epoch19, step2323]: loss 16.940115
[epoch19, step2324]: loss 1.015545
[epoch19, step2325]: loss 0.890454
[epoch19, step2326]: loss 1.960566
[epoch19, step2327]: loss 1.007738
[epoch19, step2328]: loss 1.026072
[epoch19, step2329]: loss 2.338954
[epoch19, step2330]: loss 3.096733
[epoch19, step2331]: loss 3.691756
[epoch19, step2332]: loss 0.681787
[epoch19, step2333]: loss 0.922151
[epoch19, step2334]: loss 0.615143
[epoch19, step2335]: loss 0.845428
[epoch19, step2336]: loss 15.927697
[epoch19, step2337]: loss 2.694114
[epoch19, step2338]: loss 0.568016
[epoch19, step2339]: loss 6.465043
[epoch19, step2340]: loss 6.129046
[epoch19, step2341]: loss 0.787745
[epoch19, step2342]: loss 6.471739
[epoch19, step2343]: loss 8.498650
[epoch19, step2344]: loss 2.067278
[epoch19, step2345]: loss 1.421690
[epoch19, step2346]: loss 4.275969
[epoch19, step2347]: loss 1.122860
[epoch19, step2348]: loss 6.890590
[epoch19, step2349]: loss 6.950058
[epoch19, step2350]: loss 3.397651
[epoch19, step2351]: loss 1.053246
[epoch19, step2352]: loss 13.990409
[epoch19, step2353]: loss 2.255295
[epoch19, step2354]: loss 0.342934
[epoch19, step2355]: loss 1.459110
[epoch19, step2356]: loss 8.578712
[epoch19, step2357]: loss 8.806962
[epoch19, step2358]: loss 1.949962
[epoch19, step2359]: loss 11.698547
[epoch19, step2360]: loss 0.673707
[epoch19, step2361]: loss 13.443748
[epoch19, step2362]: loss 7.439245
[epoch19, step2363]: loss 0.708032
[epoch19, step2364]: loss 1.425078
[epoch19, step2365]: loss 3.917442
[epoch19, step2366]: loss 0.544261
[epoch19, step2367]: loss 2.317331
[epoch19, step2368]: loss 0.694343
[epoch19, step2369]: loss 0.817042
[epoch19, step2370]: loss 0.618001
[epoch19, step2371]: loss 3.087151
[epoch19, step2372]: loss 0.810676
[epoch19, step2373]: loss 7.168923
[epoch19, step2374]: loss 0.789401
[epoch19, step2375]: loss 0.769777
[epoch19, step2376]: loss 1.973850
[epoch19, step2377]: loss 8.359894
[epoch19, step2378]: loss 2.037139
[epoch19, step2379]: loss 1.910858
[epoch19, step2380]: loss 0.705975
[epoch19, step2381]: loss 1.325715
[epoch19, step2382]: loss 1.087412
[epoch19, step2383]: loss 11.871889
[epoch19, step2384]: loss 6.994304
[epoch19, step2385]: loss 5.901915
[epoch19, step2386]: loss 2.997112
[epoch19, step2387]: loss 9.221712
[epoch19, step2388]: loss 0.619745
[epoch19, step2389]: loss 0.830013
[epoch19, step2390]: loss 3.174042
[epoch19, step2391]: loss 0.608242
[epoch19, step2392]: loss 0.578056
[epoch19, step2393]: loss 0.787125
[epoch19, step2394]: loss 0.795858
[epoch19, step2395]: loss 7.812418
[epoch19, step2396]: loss 1.629325
[epoch19, step2397]: loss 2.398461
[epoch19, step2398]: loss 4.578857
[epoch19, step2399]: loss 4.712098
[epoch19, step2400]: loss 5.432426
[epoch19, step2401]: loss 2.479131
[epoch19, step2402]: loss 5.453257
[epoch19, step2403]: loss 14.557595
[epoch19, step2404]: loss 1.074925
[epoch19, step2405]: loss 2.110523
[epoch19, step2406]: loss 0.689691
[epoch19, step2407]: loss 1.136635
[epoch19, step2408]: loss 1.442072
[epoch19, step2409]: loss 1.587366
[epoch19, step2410]: loss 11.499983
[epoch19, step2411]: loss 0.920725
[epoch19, step2412]: loss 2.006818
[epoch19, step2413]: loss 1.627440
[epoch19, step2414]: loss 0.701307
[epoch19, step2415]: loss 1.020731
[epoch19, step2416]: loss 4.498514
[epoch19, step2417]: loss 1.734874
[epoch19, step2418]: loss 0.585634
[epoch19, step2419]: loss 0.835758
[epoch19, step2420]: loss 15.312180
[epoch19, step2421]: loss 0.604067
[epoch19, step2422]: loss 1.171216
[epoch19, step2423]: loss 6.599188
[epoch19, step2424]: loss 0.496454
[epoch19, step2425]: loss 0.802625
[epoch19, step2426]: loss 10.592244
[epoch19, step2427]: loss 14.374704
[epoch19, step2428]: loss 2.758728
[epoch19, step2429]: loss 1.750701
[epoch19, step2430]: loss 1.436113
[epoch19, step2431]: loss 1.425550
[epoch19, step2432]: loss 0.682926
[epoch19, step2433]: loss 2.852654
[epoch19, step2434]: loss 0.511782
[epoch19, step2435]: loss 1.725264
[epoch19, step2436]: loss 8.168758
[epoch19, step2437]: loss 0.628690
[epoch19, step2438]: loss 1.830325
[epoch19, step2439]: loss 2.802735
[epoch19, step2440]: loss 0.584719
[epoch19, step2441]: loss 10.444507
[epoch19, step2442]: loss 0.565301
[epoch19, step2443]: loss 1.985930
[epoch19, step2444]: loss 1.680644
[epoch19, step2445]: loss 5.648137
[epoch19, step2446]: loss 15.731035
[epoch19, step2447]: loss 0.821638
[epoch19, step2448]: loss 0.566399
[epoch19, step2449]: loss 0.759968
[epoch19, step2450]: loss 2.770540
[epoch19, step2451]: loss 6.715531
[epoch19, step2452]: loss 0.802868
[epoch19, step2453]: loss 0.446316
[epoch19, step2454]: loss 6.662373
[epoch19, step2455]: loss 0.863003
[epoch19, step2456]: loss 4.918797
[epoch19, step2457]: loss 2.011393
[epoch19, step2458]: loss 1.698513
[epoch19, step2459]: loss 0.700157
[epoch19, step2460]: loss 0.870350
[epoch19, step2461]: loss 9.431376
[epoch19, step2462]: loss 1.406086
[epoch19, step2463]: loss 1.182305
[epoch19, step2464]: loss 1.322927
[epoch19, step2465]: loss 1.204166
[epoch19, step2466]: loss 6.436578
[epoch19, step2467]: loss 0.950529
[epoch19, step2468]: loss 5.573799
[epoch19, step2469]: loss 15.100792
[epoch19, step2470]: loss 6.348760
[epoch19, step2471]: loss 13.584828
[epoch19, step2472]: loss 3.231818
[epoch19, step2473]: loss 0.654912
[epoch19, step2474]: loss 0.857076
[epoch19, step2475]: loss 0.857989
[epoch19, step2476]: loss 1.439745
[epoch19, step2477]: loss 6.166921
[epoch19, step2478]: loss 0.623076
[epoch19, step2479]: loss 6.183228
[epoch19, step2480]: loss 3.389877
[epoch19, step2481]: loss 1.776361
[epoch19, step2482]: loss 0.568682
[epoch19, step2483]: loss 1.284738
[epoch19, step2484]: loss 0.815078
[epoch19, step2485]: loss 0.989057
[epoch19, step2486]: loss 9.034799
[epoch19, step2487]: loss 5.276468
[epoch19, step2488]: loss 0.687903
[epoch19, step2489]: loss 1.111015
[epoch19, step2490]: loss 2.484603
[epoch19, step2491]: loss 0.942636
[epoch19, step2492]: loss 0.515207
[epoch19, step2493]: loss 1.295285
[epoch19, step2494]: loss 0.613296
[epoch19, step2495]: loss 1.025948
[epoch19, step2496]: loss 5.675552
[epoch19, step2497]: loss 1.994947
[epoch19, step2498]: loss 0.638432
[epoch19, step2499]: loss 0.428792
[epoch19, step2500]: loss 5.879053
[epoch19, step2501]: loss 1.664761
[epoch19, step2502]: loss 0.682584
[epoch19, step2503]: loss 3.437520
[epoch19, step2504]: loss 2.339956
[epoch19, step2505]: loss 4.123883
[epoch19, step2506]: loss 1.075495
[epoch19, step2507]: loss 3.147966
[epoch19, step2508]: loss 11.191301
[epoch19, step2509]: loss 1.446782
[epoch19, step2510]: loss 1.935666
[epoch19, step2511]: loss 7.206530
[epoch19, step2512]: loss 10.008804
[epoch19, step2513]: loss 9.736219
[epoch19, step2514]: loss 3.564046
[epoch19, step2515]: loss 2.469934
[epoch19, step2516]: loss 3.461436
[epoch19, step2517]: loss 6.541792
[epoch19, step2518]: loss 1.526544
[epoch19, step2519]: loss 0.479389
[epoch19, step2520]: loss 0.651656
[epoch19, step2521]: loss 0.370482
[epoch19, step2522]: loss 2.277539
[epoch19, step2523]: loss 0.799208
[epoch19, step2524]: loss 7.859197
[epoch19, step2525]: loss 9.215661
[epoch19, step2526]: loss 5.484933
[epoch19, step2527]: loss 14.264591
[epoch19, step2528]: loss 4.851197
[epoch19, step2529]: loss 3.199511
[epoch19, step2530]: loss 5.316647
[epoch19, step2531]: loss 1.640401
[epoch19, step2532]: loss 1.089946
[epoch19, step2533]: loss 1.504487
[epoch19, step2534]: loss 1.982591
[epoch19, step2535]: loss 1.811947
[epoch19, step2536]: loss 1.403866
[epoch19, step2537]: loss 0.623732
[epoch19, step2538]: loss 0.699934
[epoch19, step2539]: loss 6.666781
[epoch19, step2540]: loss 1.428392
[epoch19, step2541]: loss 1.126064
[epoch19, step2542]: loss 16.793755
[epoch19, step2543]: loss 3.025127
[epoch19, step2544]: loss 1.349816
[epoch19, step2545]: loss 10.857203
[epoch19, step2546]: loss 0.931455
[epoch19, step2547]: loss 11.615132
[epoch19, step2548]: loss 11.732630
[epoch19, step2549]: loss 1.529050
[epoch19, step2550]: loss 6.304744
[epoch19, step2551]: loss 1.842295
[epoch19, step2552]: loss 13.607141
[epoch19, step2553]: loss 0.542363
[epoch19, step2554]: loss 0.862395
[epoch19, step2555]: loss 2.357030
[epoch19, step2556]: loss 5.657551
[epoch19, step2557]: loss 0.650011
[epoch19, step2558]: loss 0.677182
[epoch19, step2559]: loss 0.361704
[epoch19, step2560]: loss 8.348053
[epoch19, step2561]: loss 0.872271
[epoch19, step2562]: loss 4.793490
[epoch19, step2563]: loss 4.892421
[epoch19, step2564]: loss 12.013916
[epoch19, step2565]: loss 12.379658
[epoch19, step2566]: loss 0.707940
[epoch19, step2567]: loss 1.833118
[epoch19, step2568]: loss 0.440859
[epoch19, step2569]: loss 8.757239
[epoch19, step2570]: loss 0.978229
[epoch19, step2571]: loss 0.661194
[epoch19, step2572]: loss 5.494070
[epoch19, step2573]: loss 0.635570
[epoch19, step2574]: loss 10.103552
[epoch19, step2575]: loss 3.753016
[epoch19, step2576]: loss 1.272228
[epoch19, step2577]: loss 1.280004
[epoch19, step2578]: loss 8.740777
[epoch19, step2579]: loss 0.636698
[epoch19, step2580]: loss 1.215172
[epoch19, step2581]: loss 5.768865
[epoch19, step2582]: loss 0.928403
[epoch19, step2583]: loss 1.769655
[epoch19, step2584]: loss 0.798306
[epoch19, step2585]: loss 0.966901
[epoch19, step2586]: loss 0.802787
[epoch19, step2587]: loss 0.697794
[epoch19, step2588]: loss 1.017991
[epoch19, step2589]: loss 8.534091
[epoch19, step2590]: loss 3.798067
[epoch19, step2591]: loss 3.227846
[epoch19, step2592]: loss 1.795530
[epoch19, step2593]: loss 0.912855
[epoch19, step2594]: loss 0.776273
[epoch19, step2595]: loss 12.112330
[epoch19, step2596]: loss 1.642356
[epoch19, step2597]: loss 6.775693
[epoch19, step2598]: loss 8.162329
[epoch19, step2599]: loss 5.249492
[epoch19, step2600]: loss 5.438932
[epoch19, step2601]: loss 1.197849
[epoch19, step2602]: loss 0.554273
[epoch19, step2603]: loss 1.037581
[epoch19, step2604]: loss 1.158113
[epoch19, step2605]: loss 12.417651
[epoch19, step2606]: loss 6.262736
[epoch19, step2607]: loss 0.594248
[epoch19, step2608]: loss 5.870964
[epoch19, step2609]: loss 6.019146
[epoch19, step2610]: loss 7.124752
[epoch19, step2611]: loss 0.546086
[epoch19, step2612]: loss 0.603591
[epoch19, step2613]: loss 2.960027
[epoch19, step2614]: loss 0.486680
[epoch19, step2615]: loss 2.394282
[epoch19, step2616]: loss 8.680174
[epoch19, step2617]: loss 9.596128
[epoch19, step2618]: loss 1.739620
[epoch19, step2619]: loss 0.523765
[epoch19, step2620]: loss 2.455582
[epoch19, step2621]: loss 0.626511
[epoch19, step2622]: loss 10.308250
[epoch19, step2623]: loss 0.926347
[epoch19, step2624]: loss 2.552350
[epoch19, step2625]: loss 2.008495
[epoch19, step2626]: loss 8.662973
[epoch19, step2627]: loss 1.265995
[epoch19, step2628]: loss 1.271495
[epoch19, step2629]: loss 0.798215
[epoch19, step2630]: loss 0.953317
[epoch19, step2631]: loss 6.764810
[epoch19, step2632]: loss 0.535101
[epoch19, step2633]: loss 1.197429
[epoch19, step2634]: loss 0.713456
[epoch19, step2635]: loss 3.559100
[epoch19, step2636]: loss 1.328943
[epoch19, step2637]: loss 18.223940
[epoch19, step2638]: loss 1.476233
[epoch19, step2639]: loss 12.636284
[epoch19, step2640]: loss 0.741508
[epoch19, step2641]: loss 0.523083
[epoch19, step2642]: loss 0.773264
[epoch19, step2643]: loss 2.362507
[epoch19, step2644]: loss 4.916749
[epoch19, step2645]: loss 0.492481
[epoch19, step2646]: loss 0.719261
[epoch19, step2647]: loss 0.907127
[epoch19, step2648]: loss 0.770813
[epoch19, step2649]: loss 1.283119
[epoch19, step2650]: loss 0.625890
[epoch19, step2651]: loss 3.322142
[epoch19, step2652]: loss 14.267523
[epoch19, step2653]: loss 6.927665
[epoch19, step2654]: loss 1.095720
[epoch19, step2655]: loss 4.308465
[epoch19, step2656]: loss 1.856472
[epoch19, step2657]: loss 0.734648
[epoch19, step2658]: loss 0.996484
[epoch19, step2659]: loss 9.115979
[epoch19, step2660]: loss 1.451097
[epoch19, step2661]: loss 2.777015
[epoch19, step2662]: loss 1.590214
[epoch19, step2663]: loss 1.949969
[epoch19, step2664]: loss 2.686290
[epoch19, step2665]: loss 7.015772
[epoch19, step2666]: loss 5.898557
[epoch19, step2667]: loss 2.773283
[epoch19, step2668]: loss 1.215058
[epoch19, step2669]: loss 1.131276
[epoch19, step2670]: loss 1.564536
[epoch19, step2671]: loss 0.792242
[epoch19, step2672]: loss 1.532876
[epoch19, step2673]: loss 1.230947
[epoch19, step2674]: loss 4.133460
[epoch19, step2675]: loss 0.891536
[epoch19, step2676]: loss 0.751842
[epoch19, step2677]: loss 0.766771
[epoch19, step2678]: loss 0.846535
[epoch19, step2679]: loss 1.095598
[epoch19, step2680]: loss 1.497190
[epoch19, step2681]: loss 0.877266
[epoch19, step2682]: loss 7.610727
[epoch19, step2683]: loss 0.591854
[epoch19, step2684]: loss 5.590392
[epoch19, step2685]: loss 7.386423
[epoch19, step2686]: loss 10.827120
[epoch19, step2687]: loss 0.548345
[epoch19, step2688]: loss 0.778476
[epoch19, step2689]: loss 1.397130
[epoch19, step2690]: loss 8.333645
[epoch19, step2691]: loss 0.603981
[epoch19, step2692]: loss 3.674058
[epoch19, step2693]: loss 0.940747
[epoch19, step2694]: loss 0.638602
[epoch19, step2695]: loss 1.226842
[epoch19, step2696]: loss 6.101402
[epoch19, step2697]: loss 0.793902
[epoch19, step2698]: loss 3.436420
[epoch19, step2699]: loss 0.587857
[epoch19, step2700]: loss 0.691509
[epoch19, step2701]: loss 2.372416
[epoch19, step2702]: loss 5.485483
[epoch19, step2703]: loss 0.932924
[epoch19, step2704]: loss 0.657569
[epoch19, step2705]: loss 5.479632
[epoch19, step2706]: loss 0.411780
[epoch19, step2707]: loss 0.574793
[epoch19, step2708]: loss 0.716663
[epoch19, step2709]: loss 3.519596
[epoch19, step2710]: loss 5.217193
[epoch19, step2711]: loss 1.267208
[epoch19, step2712]: loss 0.679679
[epoch19, step2713]: loss 0.518590
[epoch19, step2714]: loss 0.711495
[epoch19, step2715]: loss 2.402719
[epoch19, step2716]: loss 1.821910
[epoch19, step2717]: loss 11.343787
[epoch19, step2718]: loss 0.617660
[epoch19, step2719]: loss 0.466002
[epoch19, step2720]: loss 0.721734
[epoch19, step2721]: loss 9.031517
[epoch19, step2722]: loss 10.579416
[epoch19, step2723]: loss 3.706199
[epoch19, step2724]: loss 9.938308
[epoch19, step2725]: loss 1.189116
[epoch19, step2726]: loss 8.501151
[epoch19, step2727]: loss 1.125700
[epoch19, step2728]: loss 2.397940
[epoch19, step2729]: loss 8.521030
[epoch19, step2730]: loss 1.903366
[epoch19, step2731]: loss 1.041610
[epoch19, step2732]: loss 7.669670
[epoch19, step2733]: loss 2.191028
[epoch19, step2734]: loss 5.884579
[epoch19, step2735]: loss 1.060823
[epoch19, step2736]: loss 0.958696
[epoch19, step2737]: loss 6.035024
[epoch19, step2738]: loss 17.830957
[epoch19, step2739]: loss 0.422731
[epoch19, step2740]: loss 8.281466
[epoch19, step2741]: loss 0.526104
[epoch19, step2742]: loss 1.998274
[epoch19, step2743]: loss 0.528870
[epoch19, step2744]: loss 2.056792
[epoch19, step2745]: loss 1.450672
[epoch19, step2746]: loss 1.141541
[epoch19, step2747]: loss 4.984451
[epoch19, step2748]: loss 9.488238
[epoch19, step2749]: loss 6.086760
[epoch19, step2750]: loss 0.729634
[epoch19, step2751]: loss 9.881396
[epoch19, step2752]: loss 2.551087
[epoch19, step2753]: loss 2.713927
[epoch19, step2754]: loss 1.183838
[epoch19, step2755]: loss 4.960139
[epoch19, step2756]: loss 19.547495
[epoch19, step2757]: loss 8.010153
[epoch19, step2758]: loss 0.667819
[epoch19, step2759]: loss 0.779604
[epoch19, step2760]: loss 1.925849
[epoch19, step2761]: loss 5.634068
[epoch19, step2762]: loss 4.521605
[epoch19, step2763]: loss 4.023174
[epoch19, step2764]: loss 0.664988
[epoch19, step2765]: loss 5.486680
[epoch19, step2766]: loss 2.514883
[epoch19, step2767]: loss 0.706810
[epoch19, step2768]: loss 1.515476
[epoch19, step2769]: loss 0.441969
[epoch19, step2770]: loss 1.462459
[epoch19, step2771]: loss 0.706412
[epoch19, step2772]: loss 0.642439
[epoch19, step2773]: loss 1.578606
[epoch19, step2774]: loss 4.008581
[epoch19, step2775]: loss 0.643026
[epoch19, step2776]: loss 1.603502
[epoch19, step2777]: loss 10.817048
[epoch19, step2778]: loss 0.565593
[epoch19, step2779]: loss 2.275826
[epoch19, step2780]: loss 1.613259
[epoch19, step2781]: loss 0.574314
[epoch19, step2782]: loss 1.823920
[epoch19, step2783]: loss 0.987090
[epoch19, step2784]: loss 3.905452
[epoch19, step2785]: loss 7.575558
[epoch19, step2786]: loss 1.334102
[epoch19, step2787]: loss 0.580169
[epoch19, step2788]: loss 13.382352
[epoch19, step2789]: loss 1.015753
[epoch19, step2790]: loss 10.245795
[epoch19, step2791]: loss 8.474674
[epoch19, step2792]: loss 0.669430
[epoch19, step2793]: loss 0.902187
[epoch19, step2794]: loss 0.898106
[epoch19, step2795]: loss 1.677900
[epoch19, step2796]: loss 1.605501
[epoch19, step2797]: loss 2.749551
[epoch19, step2798]: loss 1.445268
[epoch19, step2799]: loss 0.737086
[epoch19, step2800]: loss 0.770624
[epoch19, step2801]: loss 0.632110
[epoch19, step2802]: loss 0.628635
[epoch19, step2803]: loss 1.519050
[epoch19, step2804]: loss 1.422092
[epoch19, step2805]: loss 0.599707
[epoch19, step2806]: loss 0.520311
[epoch19, step2807]: loss 1.144784
[epoch19, step2808]: loss 0.750483
[epoch19, step2809]: loss 1.908996
[epoch19, step2810]: loss 0.738633
[epoch19, step2811]: loss 5.679389
[epoch19, step2812]: loss 1.258998
[epoch19, step2813]: loss 9.581671
[epoch19, step2814]: loss 3.569610
[epoch19, step2815]: loss 0.703559
[epoch19, step2816]: loss 0.771939
[epoch19, step2817]: loss 6.353965
[epoch19, step2818]: loss 4.495153
[epoch19, step2819]: loss 1.437820
[epoch19, step2820]: loss 11.194334
[epoch19, step2821]: loss 0.523644
[epoch19, step2822]: loss 1.047534
[epoch19, step2823]: loss 1.050957
[epoch19, step2824]: loss 0.777700
[epoch19, step2825]: loss 0.711653
[epoch19, step2826]: loss 1.626355
[epoch19, step2827]: loss 1.730983
[epoch19, step2828]: loss 0.608760
[epoch19, step2829]: loss 0.909319
[epoch19, step2830]: loss 0.785976
[epoch19, step2831]: loss 0.515317
[epoch19, step2832]: loss 2.459162
[epoch19, step2833]: loss 7.676670
[epoch19, step2834]: loss 6.103233
[epoch19, step2835]: loss 0.779737
[epoch19, step2836]: loss 3.361791
[epoch19, step2837]: loss 1.208025
[epoch19, step2838]: loss 2.554147
[epoch19, step2839]: loss 0.962095
[epoch19, step2840]: loss 1.470567
[epoch19, step2841]: loss 0.550406
[epoch19, step2842]: loss 1.528827
[epoch19, step2843]: loss 1.356644
[epoch19, step2844]: loss 2.684994
[epoch19, step2845]: loss 16.371723
[epoch19, step2846]: loss 11.848202
[epoch19, step2847]: loss 12.481991
[epoch19, step2848]: loss 6.100267
[epoch19, step2849]: loss 6.156475
[epoch19, step2850]: loss 2.661222
[epoch19, step2851]: loss 1.275505
[epoch19, step2852]: loss 2.144356
[epoch19, step2853]: loss 0.611495
[epoch19, step2854]: loss 2.321056
[epoch19, step2855]: loss 0.719199
[epoch19, step2856]: loss 0.888860
[epoch19, step2857]: loss 12.245091
[epoch19, step2858]: loss 8.617612
[epoch19, step2859]: loss 1.433942
[epoch19, step2860]: loss 15.414796
[epoch19, step2861]: loss 2.890959
[epoch19, step2862]: loss 1.679335
[epoch19, step2863]: loss 1.270815
[epoch19, step2864]: loss 0.827356
[epoch19, step2865]: loss 5.065279
[epoch19, step2866]: loss 5.969697
[epoch19, step2867]: loss 0.593330
[epoch19, step2868]: loss 6.337333
[epoch19, step2869]: loss 7.361909
[epoch19, step2870]: loss 1.829449
[epoch19, step2871]: loss 9.961110
[epoch19, step2872]: loss 1.031588
[epoch19, step2873]: loss 0.439282
[epoch19, step2874]: loss 0.893450
[epoch19, step2875]: loss 7.627003
[epoch19, step2876]: loss 2.295588
[epoch19, step2877]: loss 8.269831
[epoch19, step2878]: loss 1.528862
[epoch19, step2879]: loss 11.043007
[epoch19, step2880]: loss 7.167698
[epoch19, step2881]: loss 14.855815
[epoch19, step2882]: loss 0.536978
[epoch19, step2883]: loss 0.667061
[epoch19, step2884]: loss 0.814196
[epoch19, step2885]: loss 2.043082
[epoch19, step2886]: loss 2.243037
[epoch19, step2887]: loss 6.425605
[epoch19, step2888]: loss 4.885044
[epoch19, step2889]: loss 0.655019
[epoch19, step2890]: loss 2.558524
[epoch19, step2891]: loss 16.976799
[epoch19, step2892]: loss 1.418244
[epoch19, step2893]: loss 0.608299
[epoch19, step2894]: loss 8.530846
[epoch19, step2895]: loss 5.814775
[epoch19, step2896]: loss 0.684751
[epoch19, step2897]: loss 4.647561
[epoch19, step2898]: loss 6.649570
[epoch19, step2899]: loss 2.071007
[epoch19, step2900]: loss 5.866450
[epoch19, step2901]: loss 3.378769
[epoch19, step2902]: loss 1.904553
[epoch19, step2903]: loss 0.744247
[epoch19, step2904]: loss 1.786271
[epoch19, step2905]: loss 1.318060
[epoch19, step2906]: loss 0.727187
[epoch19, step2907]: loss 8.766364
[epoch19, step2908]: loss 0.890816
[epoch19, step2909]: loss 2.397335
[epoch19, step2910]: loss 14.485853
[epoch19, step2911]: loss 4.782163
[epoch19, step2912]: loss 1.610300
[epoch19, step2913]: loss 0.662583
[epoch19, step2914]: loss 0.594790
[epoch19, step2915]: loss 1.416261
[epoch19, step2916]: loss 0.725253
[epoch19, step2917]: loss 1.142311
[epoch19, step2918]: loss 0.602474
[epoch19, step2919]: loss 2.870994
[epoch19, step2920]: loss 1.781265
[epoch19, step2921]: loss 2.243484
[epoch19, step2922]: loss 0.992552
[epoch19, step2923]: loss 0.607351
[epoch19, step2924]: loss 6.195727
[epoch19, step2925]: loss 0.530121
[epoch19, step2926]: loss 7.161489
[epoch19, step2927]: loss 20.950926
[epoch19, step2928]: loss 10.738364
[epoch19, step2929]: loss 3.322696
[epoch19, step2930]: loss 1.306624
[epoch19, step2931]: loss 8.672628
[epoch19, step2932]: loss 5.313136
[epoch19, step2933]: loss 1.036682
[epoch19, step2934]: loss 1.876004
[epoch19, step2935]: loss 1.485212
[epoch19, step2936]: loss 0.564183
[epoch19, step2937]: loss 0.714825
[epoch19, step2938]: loss 0.781968
[epoch19, step2939]: loss 4.917201
[epoch19, step2940]: loss 0.738911
[epoch19, step2941]: loss 1.412991
[epoch19, step2942]: loss 1.676936
[epoch19, step2943]: loss 11.246438
[epoch19, step2944]: loss 1.818151
[epoch19, step2945]: loss 7.835896
[epoch19, step2946]: loss 2.039283
[epoch19, step2947]: loss 1.913137
[epoch19, step2948]: loss 0.865610
[epoch19, step2949]: loss 0.579330
[epoch19, step2950]: loss 2.098470
[epoch19, step2951]: loss 17.044735
[epoch19, step2952]: loss 2.378291
[epoch19, step2953]: loss 1.498915
[epoch19, step2954]: loss 2.438264
[epoch19, step2955]: loss 5.561030
[epoch19, step2956]: loss 5.651771
[epoch19, step2957]: loss 6.071118
[epoch19, step2958]: loss 3.474828
[epoch19, step2959]: loss 3.975993
[epoch19, step2960]: loss 4.793740
[epoch19, step2961]: loss 0.410540
[epoch19, step2962]: loss 10.096282
[epoch19, step2963]: loss 2.559350
[epoch19, step2964]: loss 13.065758
[epoch19, step2965]: loss 0.860901
[epoch19, step2966]: loss 0.492540
[epoch19, step2967]: loss 0.613358
[epoch19, step2968]: loss 1.328891
[epoch19, step2969]: loss 0.597849
[epoch19, step2970]: loss 0.627020
[epoch19, step2971]: loss 0.498266
[epoch19, step2972]: loss 0.775662
[epoch19, step2973]: loss 2.133742
[epoch19, step2974]: loss 0.571285
[epoch19, step2975]: loss 5.065058
[epoch19, step2976]: loss 8.803630
[epoch19, step2977]: loss 3.148392
[epoch19, step2978]: loss 2.019952
[epoch19, step2979]: loss 1.544854
[epoch19, step2980]: loss 0.462255
[epoch19, step2981]: loss 0.982180
[epoch19, step2982]: loss 0.686536
[epoch19, step2983]: loss 0.658772
[epoch19, step2984]: loss 0.509823
[epoch19, step2985]: loss 0.844438
[epoch19, step2986]: loss 0.719690
[epoch19, step2987]: loss 5.242548
[epoch19, step2988]: loss 3.343711
[epoch19, step2989]: loss 17.495056
[epoch19, step2990]: loss 9.078424
[epoch19, step2991]: loss 0.579276
[epoch19, step2992]: loss 1.460610
[epoch19, step2993]: loss 8.247895
[epoch19, step2994]: loss 0.628391
[epoch19, step2995]: loss 10.969296
[epoch19, step2996]: loss 9.143921
[epoch19, step2997]: loss 5.200477
[epoch19, step2998]: loss 4.874027
[epoch19, step2999]: loss 2.475019
[epoch19, step3000]: loss 1.584669
[epoch19, step3001]: loss 1.914853
[epoch19, step3002]: loss 1.014561
[epoch19, step3003]: loss 5.803284
[epoch19, step3004]: loss 0.757357
[epoch19, step3005]: loss 1.519473
[epoch19, step3006]: loss 1.132865
[epoch19, step3007]: loss 8.355492
[epoch19, step3008]: loss 7.730848
[epoch19, step3009]: loss 1.226068
[epoch19, step3010]: loss 9.163855
[epoch19, step3011]: loss 0.742914
[epoch19, step3012]: loss 6.944319
[epoch19, step3013]: loss 6.569652
[epoch19, step3014]: loss 2.030580
[epoch19, step3015]: loss 2.036905
[epoch19, step3016]: loss 1.532514
[epoch19, step3017]: loss 11.935431
[epoch19, step3018]: loss 9.923223
[epoch19, step3019]: loss 0.611080
[epoch19, step3020]: loss 1.790406
[epoch19, step3021]: loss 1.484398
[epoch19, step3022]: loss 2.069867
[epoch19, step3023]: loss 5.374708
[epoch19, step3024]: loss 2.175370
[epoch19, step3025]: loss 1.137821
[epoch19, step3026]: loss 0.661852
[epoch19, step3027]: loss 4.802490
[epoch19, step3028]: loss 18.648420
[epoch19, step3029]: loss 4.500659
[epoch19, step3030]: loss 16.218544
[epoch19, step3031]: loss 3.566679
[epoch19, step3032]: loss 1.880089
[epoch19, step3033]: loss 0.680134
[epoch19, step3034]: loss 1.437905
[epoch19, step3035]: loss 5.133173
[epoch19, step3036]: loss 0.795998
[epoch19, step3037]: loss 4.454411
[epoch19, step3038]: loss 4.678870
[epoch19, step3039]: loss 8.977876
[epoch19, step3040]: loss 7.482293
[epoch19, step3041]: loss 1.518965
[epoch19, step3042]: loss 0.756967
[epoch19, step3043]: loss 16.051550
[epoch19, step3044]: loss 1.251504
[epoch19, step3045]: loss 8.310154
[epoch19, step3046]: loss 2.080308
[epoch19, step3047]: loss 1.575576
[epoch19, step3048]: loss 5.955995
[epoch19, step3049]: loss 4.803804
[epoch19, step3050]: loss 1.441970
[epoch19, step3051]: loss 1.964313
[epoch19, step3052]: loss 0.796986
[epoch19, step3053]: loss 14.260832
[epoch19, step3054]: loss 2.425215
[epoch19, step3055]: loss 0.913194
[epoch19, step3056]: loss 1.598761
[epoch19, step3057]: loss 1.305515
[epoch19, step3058]: loss 0.659226
[epoch19, step3059]: loss 3.105879
[epoch19, step3060]: loss 2.378476
[epoch19, step3061]: loss 8.317426
[epoch19, step3062]: loss 9.006161
[epoch19, step3063]: loss 1.675680
[epoch19, step3064]: loss 5.435571
[epoch19, step3065]: loss 2.101592
[epoch19, step3066]: loss 2.112007
[epoch19, step3067]: loss 13.243590
[epoch19, step3068]: loss 5.957885
[epoch19, step3069]: loss 0.684919
[epoch19, step3070]: loss 2.367783
[epoch19, step3071]: loss 4.515276
[epoch19, step3072]: loss 0.594871
[epoch19, step3073]: loss 15.314280
[epoch19, step3074]: loss 1.040134
[epoch19, step3075]: loss 2.222264
[epoch19, step3076]: loss 0.588830

[epoch19]: avg loss 0.588830

[epoch20, step1]: loss 0.810820
[epoch20, step2]: loss 10.718014
[epoch20, step3]: loss 5.861537
[epoch20, step4]: loss 3.408252
[epoch20, step5]: loss 3.508827
[epoch20, step6]: loss 0.655231
[epoch20, step7]: loss 4.854700
[epoch20, step8]: loss 0.639344
[epoch20, step9]: loss 0.539806
[epoch20, step10]: loss 6.094754
[epoch20, step11]: loss 7.694074
[epoch20, step12]: loss 0.658567
[epoch20, step13]: loss 2.065285
[epoch20, step14]: loss 0.445443
[epoch20, step15]: loss 1.183056
[epoch20, step16]: loss 4.039711
[epoch20, step17]: loss 7.767053
[epoch20, step18]: loss 0.657851
[epoch20, step19]: loss 1.001345
[epoch20, step20]: loss 2.367098
[epoch20, step21]: loss 0.596170
[epoch20, step22]: loss 0.884470
[epoch20, step23]: loss 0.966907
[epoch20, step24]: loss 0.657802
[epoch20, step25]: loss 6.510567
[epoch20, step26]: loss 1.480517
[epoch20, step27]: loss 2.723157
[epoch20, step28]: loss 2.422575
[epoch20, step29]: loss 5.879037
[epoch20, step30]: loss 16.152378
[epoch20, step31]: loss 14.219767
[epoch20, step32]: loss 9.610600
[epoch20, step33]: loss 4.994973
[epoch20, step34]: loss 0.491050
[epoch20, step35]: loss 7.726167
[epoch20, step36]: loss 0.862106
[epoch20, step37]: loss 0.891568
[epoch20, step38]: loss 0.687410
[epoch20, step39]: loss 0.728101
[epoch20, step40]: loss 0.978391
[epoch20, step41]: loss 0.600446
[epoch20, step42]: loss 1.761134
[epoch20, step43]: loss 0.737256
[epoch20, step44]: loss 6.396108
[epoch20, step45]: loss 0.681002
[epoch20, step46]: loss 0.929788
[epoch20, step47]: loss 0.639790
[epoch20, step48]: loss 1.705319
[epoch20, step49]: loss 0.621999
[epoch20, step50]: loss 6.899765
[epoch20, step51]: loss 0.774550
[epoch20, step52]: loss 3.908113
[epoch20, step53]: loss 0.722485
[epoch20, step54]: loss 1.432923
[epoch20, step55]: loss 0.526325
[epoch20, step56]: loss 1.254556
[epoch20, step57]: loss 0.551288
[epoch20, step58]: loss 0.725080
[epoch20, step59]: loss 0.739164
[epoch20, step60]: loss 1.833694
[epoch20, step61]: loss 0.551868
[epoch20, step62]: loss 10.861502
[epoch20, step63]: loss 2.284775
[epoch20, step64]: loss 0.491093
[epoch20, step65]: loss 0.588330
[epoch20, step66]: loss 3.028174
[epoch20, step67]: loss 0.987072
[epoch20, step68]: loss 1.478631
[epoch20, step69]: loss 7.016586
[epoch20, step70]: loss 9.201590
[epoch20, step71]: loss 0.960693
[epoch20, step72]: loss 0.952781
[epoch20, step73]: loss 6.847482
[epoch20, step74]: loss 0.818431
[epoch20, step75]: loss 10.837659
[epoch20, step76]: loss 5.722025
[epoch20, step77]: loss 2.552968
[epoch20, step78]: loss 1.892790
[epoch20, step79]: loss 11.846601
[epoch20, step80]: loss 5.144521
[epoch20, step81]: loss 0.892802
[epoch20, step82]: loss 1.589566
[epoch20, step83]: loss 2.541848
[epoch20, step84]: loss 1.037094
[epoch20, step85]: loss 6.695490
[epoch20, step86]: loss 0.879267
[epoch20, step87]: loss 0.879617
[epoch20, step88]: loss 3.691283
[epoch20, step89]: loss 11.341329
[epoch20, step90]: loss 6.259343
[epoch20, step91]: loss 7.644063
[epoch20, step92]: loss 1.481037
[epoch20, step93]: loss 2.744636
[epoch20, step94]: loss 8.154923
[epoch20, step95]: loss 2.256587
[epoch20, step96]: loss 7.445393
[epoch20, step97]: loss 0.538278
[epoch20, step98]: loss 9.105615
[epoch20, step99]: loss 2.547598
[epoch20, step100]: loss 1.306611
[epoch20, step101]: loss 1.299256
[epoch20, step102]: loss 1.005229
[epoch20, step103]: loss 8.795360
[epoch20, step104]: loss 0.484971
[epoch20, step105]: loss 1.269570
[epoch20, step106]: loss 0.487863
[epoch20, step107]: loss 2.136259
[epoch20, step108]: loss 1.521045
[epoch20, step109]: loss 0.588904
[epoch20, step110]: loss 7.491054
[epoch20, step111]: loss 1.009007
[epoch20, step112]: loss 6.940846
[epoch20, step113]: loss 1.529355
[epoch20, step114]: loss 1.076040
[epoch20, step115]: loss 14.943553
[epoch20, step116]: loss 0.860550
[epoch20, step117]: loss 1.588966
[epoch20, step118]: loss 2.072983
[epoch20, step119]: loss 7.310659
[epoch20, step120]: loss 0.895831
[epoch20, step121]: loss 1.606588
[epoch20, step122]: loss 5.810079
[epoch20, step123]: loss 2.547744
[epoch20, step124]: loss 5.264822
[epoch20, step125]: loss 8.055717
[epoch20, step126]: loss 0.518137
[epoch20, step127]: loss 1.142787
[epoch20, step128]: loss 6.560501
[epoch20, step129]: loss 2.196024
[epoch20, step130]: loss 0.627436
[epoch20, step131]: loss 8.746540
[epoch20, step132]: loss 3.708912
[epoch20, step133]: loss 4.823077
[epoch20, step134]: loss 2.220565
[epoch20, step135]: loss 10.891233
[epoch20, step136]: loss 7.687917
[epoch20, step137]: loss 1.438790
[epoch20, step138]: loss 1.308014
[epoch20, step139]: loss 5.629984
[epoch20, step140]: loss 0.653069
[epoch20, step141]: loss 3.268487
[epoch20, step142]: loss 5.180237
[epoch20, step143]: loss 0.713758
[epoch20, step144]: loss 6.597621
[epoch20, step145]: loss 10.763449
[epoch20, step146]: loss 0.687188
[epoch20, step147]: loss 2.984310
[epoch20, step148]: loss 2.401632
[epoch20, step149]: loss 0.592729
[epoch20, step150]: loss 9.253688
[epoch20, step151]: loss 1.172674
[epoch20, step152]: loss 0.823984
[epoch20, step153]: loss 3.533646
[epoch20, step154]: loss 1.572187
[epoch20, step155]: loss 2.161281
[epoch20, step156]: loss 6.229222
[epoch20, step157]: loss 0.925507
[epoch20, step158]: loss 1.044729
[epoch20, step159]: loss 0.760249
[epoch20, step160]: loss 10.952343
[epoch20, step161]: loss 5.415689
[epoch20, step162]: loss 7.299149
[epoch20, step163]: loss 8.929299
[epoch20, step164]: loss 2.096661
[epoch20, step165]: loss 1.832043
[epoch20, step166]: loss 1.410094
[epoch20, step167]: loss 1.039388
[epoch20, step168]: loss 1.364817
[epoch20, step169]: loss 1.424865
[epoch20, step170]: loss 2.656855
[epoch20, step171]: loss 0.530334
[epoch20, step172]: loss 0.728487
[epoch20, step173]: loss 1.761017
[epoch20, step174]: loss 6.227462
[epoch20, step175]: loss 5.804702
[epoch20, step176]: loss 1.663032
[epoch20, step177]: loss 16.685375
[epoch20, step178]: loss 1.341063
[epoch20, step179]: loss 1.795068
[epoch20, step180]: loss 6.851132
[epoch20, step181]: loss 2.599807
[epoch20, step182]: loss 2.356034
[epoch20, step183]: loss 1.414276
[epoch20, step184]: loss 23.177797
[epoch20, step185]: loss 1.410175
[epoch20, step186]: loss 1.253717
[epoch20, step187]: loss 5.259633
[epoch20, step188]: loss 0.813213
[epoch20, step189]: loss 11.064184
[epoch20, step190]: loss 1.291752
[epoch20, step191]: loss 3.667301
[epoch20, step192]: loss 3.723781
[epoch20, step193]: loss 1.470941
[epoch20, step194]: loss 0.636910
[epoch20, step195]: loss 0.854936
[epoch20, step196]: loss 0.682512
[epoch20, step197]: loss 0.618316
[epoch20, step198]: loss 5.962474
[epoch20, step199]: loss 5.496481
[epoch20, step200]: loss 3.704603
[epoch20, step201]: loss 1.175657
[epoch20, step202]: loss 13.184117
[epoch20, step203]: loss 7.696330
[epoch20, step204]: loss 7.120149
[epoch20, step205]: loss 5.486798
[epoch20, step206]: loss 4.833605
[epoch20, step207]: loss 1.278474
[epoch20, step208]: loss 0.449205
[epoch20, step209]: loss 16.292002
[epoch20, step210]: loss 17.973402
[epoch20, step211]: loss 0.899336
[epoch20, step212]: loss 2.266015
[epoch20, step213]: loss 6.041249
[epoch20, step214]: loss 0.599453
[epoch20, step215]: loss 1.758721
[epoch20, step216]: loss 4.621086
[epoch20, step217]: loss 0.501684
[epoch20, step218]: loss 0.769194
[epoch20, step219]: loss 1.596518
[epoch20, step220]: loss 1.997585
[epoch20, step221]: loss 3.254122
[epoch20, step222]: loss 1.201224
[epoch20, step223]: loss 3.013568
[epoch20, step224]: loss 0.491049
[epoch20, step225]: loss 9.746874
[epoch20, step226]: loss 16.459517
[epoch20, step227]: loss 1.474813
[epoch20, step228]: loss 1.755952
[epoch20, step229]: loss 0.572400
[epoch20, step230]: loss 2.576017
[epoch20, step231]: loss 0.696403
[epoch20, step232]: loss 1.876852
[epoch20, step233]: loss 1.201706
[epoch20, step234]: loss 0.889412
[epoch20, step235]: loss 1.256112
[epoch20, step236]: loss 1.013609
[epoch20, step237]: loss 1.313470
[epoch20, step238]: loss 1.918114
[epoch20, step239]: loss 0.754899
[epoch20, step240]: loss 2.262708
[epoch20, step241]: loss 1.153197
[epoch20, step242]: loss 2.081925
[epoch20, step243]: loss 0.698569
[epoch20, step244]: loss 2.355140
[epoch20, step245]: loss 6.927022
[epoch20, step246]: loss 5.751782
[epoch20, step247]: loss 0.837086
[epoch20, step248]: loss 4.909034
[epoch20, step249]: loss 2.562316
[epoch20, step250]: loss 1.328121
[epoch20, step251]: loss 2.573829
[epoch20, step252]: loss 1.256604
[epoch20, step253]: loss 0.986945
[epoch20, step254]: loss 0.781419
[epoch20, step255]: loss 2.789899
[epoch20, step256]: loss 12.566318
[epoch20, step257]: loss 6.088092
[epoch20, step258]: loss 0.733047
[epoch20, step259]: loss 8.570637
[epoch20, step260]: loss 1.504848
[epoch20, step261]: loss 1.170647
[epoch20, step262]: loss 1.014148
[epoch20, step263]: loss 1.190688
[epoch20, step264]: loss 0.636143
[epoch20, step265]: loss 10.759534
[epoch20, step266]: loss 11.701157
[epoch20, step267]: loss 2.137838
[epoch20, step268]: loss 1.937340
[epoch20, step269]: loss 0.535250
[epoch20, step270]: loss 1.968377
[epoch20, step271]: loss 6.402304
[epoch20, step272]: loss 0.752343
[epoch20, step273]: loss 15.014565
[epoch20, step274]: loss 0.982870
[epoch20, step275]: loss 1.010198
[epoch20, step276]: loss 3.510104
[epoch20, step277]: loss 1.353796
[epoch20, step278]: loss 13.706822
[epoch20, step279]: loss 11.368973
[epoch20, step280]: loss 1.800055
[epoch20, step281]: loss 1.991142
[epoch20, step282]: loss 0.524533
[epoch20, step283]: loss 9.743141
[epoch20, step284]: loss 1.307560
[epoch20, step285]: loss 1.367239
[epoch20, step286]: loss 10.789277
[epoch20, step287]: loss 4.341099
[epoch20, step288]: loss 11.437401
[epoch20, step289]: loss 1.930624
[epoch20, step290]: loss 1.110929
[epoch20, step291]: loss 2.616402
[epoch20, step292]: loss 15.961136
[epoch20, step293]: loss 7.626015
[epoch20, step294]: loss 0.844284
[epoch20, step295]: loss 9.354269
[epoch20, step296]: loss 10.892614
[epoch20, step297]: loss 0.989141
[epoch20, step298]: loss 6.160655
[epoch20, step299]: loss 0.586552
[epoch20, step300]: loss 1.434245
[epoch20, step301]: loss 11.032038
[epoch20, step302]: loss 4.974533
[epoch20, step303]: loss 1.568855
[epoch20, step304]: loss 0.992116
[epoch20, step305]: loss 12.013431
[epoch20, step306]: loss 1.057372
[epoch20, step307]: loss 5.829720
[epoch20, step308]: loss 5.923873
[epoch20, step309]: loss 2.194323
[epoch20, step310]: loss 1.011285
[epoch20, step311]: loss 12.558998
[epoch20, step312]: loss 0.640590
[epoch20, step313]: loss 6.025624
[epoch20, step314]: loss 1.143161
[epoch20, step315]: loss 0.502751
[epoch20, step316]: loss 0.731424
[epoch20, step317]: loss 0.617396
[epoch20, step318]: loss 7.883965
[epoch20, step319]: loss 0.470758
[epoch20, step320]: loss 1.374947
[epoch20, step321]: loss 0.587594
[epoch20, step322]: loss 2.465571
[epoch20, step323]: loss 2.251282
[epoch20, step324]: loss 8.471827
[epoch20, step325]: loss 10.903738
[epoch20, step326]: loss 1.845069
[epoch20, step327]: loss 1.170673
[epoch20, step328]: loss 1.100696
[epoch20, step329]: loss 1.232422
[epoch20, step330]: loss 0.864501
[epoch20, step331]: loss 0.553448
[epoch20, step332]: loss 1.936608
[epoch20, step333]: loss 6.772939
[epoch20, step334]: loss 0.658602
[epoch20, step335]: loss 0.692953
[epoch20, step336]: loss 1.660068
[epoch20, step337]: loss 4.663251
[epoch20, step338]: loss 0.672099
[epoch20, step339]: loss 2.840442
[epoch20, step340]: loss 0.653954
[epoch20, step341]: loss 1.894040
[epoch20, step342]: loss 5.645488
[epoch20, step343]: loss 1.108531
[epoch20, step344]: loss 0.422895
[epoch20, step345]: loss 1.690297
[epoch20, step346]: loss 10.062007
[epoch20, step347]: loss 6.798721
[epoch20, step348]: loss 1.222468
[epoch20, step349]: loss 1.729780
[epoch20, step350]: loss 1.161284
[epoch20, step351]: loss 1.439542
[epoch20, step352]: loss 2.313339
[epoch20, step353]: loss 1.805281
[epoch20, step354]: loss 1.250731
[epoch20, step355]: loss 1.551864
[epoch20, step356]: loss 0.617957
[epoch20, step357]: loss 6.307095
[epoch20, step358]: loss 2.521541
[epoch20, step359]: loss 2.328716
[epoch20, step360]: loss 12.816723
[epoch20, step361]: loss 1.727016
[epoch20, step362]: loss 0.756401
[epoch20, step363]: loss 8.541495
[epoch20, step364]: loss 1.336494
[epoch20, step365]: loss 0.985103
[epoch20, step366]: loss 10.006363
[epoch20, step367]: loss 8.972051
[epoch20, step368]: loss 4.939630
[epoch20, step369]: loss 2.400230
[epoch20, step370]: loss 1.787527
[epoch20, step371]: loss 10.532405
[epoch20, step372]: loss 0.661500
[epoch20, step373]: loss 1.941323
[epoch20, step374]: loss 5.327409
[epoch20, step375]: loss 0.517911
[epoch20, step376]: loss 0.799815
[epoch20, step377]: loss 11.577372
[epoch20, step378]: loss 0.684761
[epoch20, step379]: loss 1.015578
[epoch20, step380]: loss 2.043084
[epoch20, step381]: loss 12.554187
[epoch20, step382]: loss 2.710492
[epoch20, step383]: loss 0.892779
[epoch20, step384]: loss 5.499049
[epoch20, step385]: loss 0.723939
[epoch20, step386]: loss 0.678944
[epoch20, step387]: loss 0.601625
[epoch20, step388]: loss 2.594542
[epoch20, step389]: loss 5.277556
[epoch20, step390]: loss 9.244376
[epoch20, step391]: loss 1.271717
[epoch20, step392]: loss 0.629701
[epoch20, step393]: loss 21.742535
[epoch20, step394]: loss 4.785756
[epoch20, step395]: loss 0.757849
[epoch20, step396]: loss 1.931361
[epoch20, step397]: loss 2.794426
[epoch20, step398]: loss 2.220833
[epoch20, step399]: loss 12.152700
[epoch20, step400]: loss 2.251587
[epoch20, step401]: loss 2.640513
[epoch20, step402]: loss 0.489686
[epoch20, step403]: loss 2.311068
[epoch20, step404]: loss 1.285982
[epoch20, step405]: loss 5.681298
[epoch20, step406]: loss 8.463151
[epoch20, step407]: loss 5.794723
[epoch20, step408]: loss 22.835560
[epoch20, step409]: loss 1.553076
[epoch20, step410]: loss 0.895549
[epoch20, step411]: loss 1.094745
[epoch20, step412]: loss 0.738367
[epoch20, step413]: loss 8.844879
[epoch20, step414]: loss 0.847939
[epoch20, step415]: loss 1.040980
[epoch20, step416]: loss 4.372535
[epoch20, step417]: loss 1.032907
[epoch20, step418]: loss 0.661613
[epoch20, step419]: loss 10.292527
[epoch20, step420]: loss 10.334955
[epoch20, step421]: loss 1.014030
[epoch20, step422]: loss 1.526874
[epoch20, step423]: loss 0.620042
[epoch20, step424]: loss 8.355074
[epoch20, step425]: loss 0.756447
[epoch20, step426]: loss 1.368461
[epoch20, step427]: loss 10.282614
[epoch20, step428]: loss 1.597038
[epoch20, step429]: loss 1.048648
[epoch20, step430]: loss 6.324065
[epoch20, step431]: loss 2.776379
[epoch20, step432]: loss 1.521109
[epoch20, step433]: loss 1.374236
[epoch20, step434]: loss 0.770005
[epoch20, step435]: loss 0.872235
[epoch20, step436]: loss 21.380903
[epoch20, step437]: loss 0.614348
[epoch20, step438]: loss 1.335841
[epoch20, step439]: loss 0.576959
[epoch20, step440]: loss 9.640754
[epoch20, step441]: loss 1.133169
[epoch20, step442]: loss 0.674940
[epoch20, step443]: loss 9.231619
[epoch20, step444]: loss 10.005826
[epoch20, step445]: loss 3.275574
[epoch20, step446]: loss 6.838134
[epoch20, step447]: loss 1.406788
[epoch20, step448]: loss 4.322749
[epoch20, step449]: loss 10.633998
[epoch20, step450]: loss 8.117079
[epoch20, step451]: loss 1.798804
[epoch20, step452]: loss 1.616072
[epoch20, step453]: loss 0.574951
[epoch20, step454]: loss 0.812630
[epoch20, step455]: loss 2.244963
[epoch20, step456]: loss 0.437719
[epoch20, step457]: loss 6.973539
[epoch20, step458]: loss 1.138448
[epoch20, step459]: loss 5.788730
[epoch20, step460]: loss 1.641904
[epoch20, step461]: loss 0.661189
[epoch20, step462]: loss 12.955011
[epoch20, step463]: loss 0.771776
[epoch20, step464]: loss 3.747446
[epoch20, step465]: loss 0.779119
[epoch20, step466]: loss 2.221859
[epoch20, step467]: loss 0.746870
[epoch20, step468]: loss 0.626230
[epoch20, step469]: loss 0.656295
[epoch20, step470]: loss 2.240628
[epoch20, step471]: loss 5.617747
[epoch20, step472]: loss 5.547379
[epoch20, step473]: loss 3.415988
[epoch20, step474]: loss 10.737441
[epoch20, step475]: loss 1.413430
[epoch20, step476]: loss 8.454193
[epoch20, step477]: loss 1.635783
[epoch20, step478]: loss 1.829037
[epoch20, step479]: loss 0.633408
[epoch20, step480]: loss 7.093412
[epoch20, step481]: loss 0.557578
[epoch20, step482]: loss 2.887561
[epoch20, step483]: loss 8.486234
[epoch20, step484]: loss 0.602671
[epoch20, step485]: loss 0.953767
[epoch20, step486]: loss 6.025630
[epoch20, step487]: loss 1.974397
[epoch20, step488]: loss 0.723569
[epoch20, step489]: loss 1.370358
[epoch20, step490]: loss 0.784272
[epoch20, step491]: loss 3.999808
[epoch20, step492]: loss 1.167850
[epoch20, step493]: loss 0.942275
[epoch20, step494]: loss 8.407398
[epoch20, step495]: loss 1.800883
[epoch20, step496]: loss 3.042311
[epoch20, step497]: loss 4.590394
[epoch20, step498]: loss 5.448310
[epoch20, step499]: loss 1.606837
[epoch20, step500]: loss 0.554841
[epoch20, step501]: loss 15.156039
[epoch20, step502]: loss 0.612846
[epoch20, step503]: loss 0.581966
[epoch20, step504]: loss 1.858656
[epoch20, step505]: loss 5.891622
[epoch20, step506]: loss 5.427852
[epoch20, step507]: loss 1.911289
[epoch20, step508]: loss 2.594172
[epoch20, step509]: loss 0.655167
[epoch20, step510]: loss 8.025773
[epoch20, step511]: loss 1.493505
[epoch20, step512]: loss 1.776301
[epoch20, step513]: loss 4.923857
[epoch20, step514]: loss 0.783702
[epoch20, step515]: loss 9.856652
[epoch20, step516]: loss 0.978322
[epoch20, step517]: loss 0.863580
[epoch20, step518]: loss 1.828341
[epoch20, step519]: loss 10.565942
[epoch20, step520]: loss 0.710664
[epoch20, step521]: loss 1.644966
[epoch20, step522]: loss 0.736035
[epoch20, step523]: loss 10.944629
[epoch20, step524]: loss 5.896296
[epoch20, step525]: loss 3.476094
[epoch20, step526]: loss 8.678401
[epoch20, step527]: loss 8.848202
[epoch20, step528]: loss 0.835221
[epoch20, step529]: loss 1.029483
[epoch20, step530]: loss 1.546027
[epoch20, step531]: loss 2.262856
[epoch20, step532]: loss 0.765874
[epoch20, step533]: loss 0.865242
[epoch20, step534]: loss 5.535176
[epoch20, step535]: loss 1.670567
[epoch20, step536]: loss 2.224925
[epoch20, step537]: loss 1.823779
[epoch20, step538]: loss 9.534917
[epoch20, step539]: loss 8.525599
[epoch20, step540]: loss 2.103734
[epoch20, step541]: loss 0.910207
[epoch20, step542]: loss 8.680238
[epoch20, step543]: loss 1.888645
[epoch20, step544]: loss 0.623249
[epoch20, step545]: loss 3.237876
[epoch20, step546]: loss 3.517000
[epoch20, step547]: loss 0.570213
[epoch20, step548]: loss 1.216418
[epoch20, step549]: loss 11.038809
[epoch20, step550]: loss 0.411744
[epoch20, step551]: loss 5.286510
[epoch20, step552]: loss 8.512314
[epoch20, step553]: loss 2.786678
[epoch20, step554]: loss 5.792819
[epoch20, step555]: loss 2.407591
[epoch20, step556]: loss 4.679941
[epoch20, step557]: loss 6.304653
[epoch20, step558]: loss 0.811699
[epoch20, step559]: loss 4.814925
[epoch20, step560]: loss 15.714306
[epoch20, step561]: loss 21.124647
[epoch20, step562]: loss 1.029848
[epoch20, step563]: loss 17.120447
[epoch20, step564]: loss 6.865645
[epoch20, step565]: loss 4.736277
[epoch20, step566]: loss 8.564557
[epoch20, step567]: loss 4.411221
[epoch20, step568]: loss 1.004060
[epoch20, step569]: loss 7.947591
[epoch20, step570]: loss 17.226849
[epoch20, step571]: loss 2.046983
[epoch20, step572]: loss 2.890665
[epoch20, step573]: loss 2.654547
[epoch20, step574]: loss 0.669873
[epoch20, step575]: loss 6.586460
[epoch20, step576]: loss 4.427464
[epoch20, step577]: loss 0.742618
[epoch20, step578]: loss 2.713850
[epoch20, step579]: loss 0.916404
[epoch20, step580]: loss 14.388981
[epoch20, step581]: loss 0.607177
[epoch20, step582]: loss 22.719616
[epoch20, step583]: loss 1.105282
[epoch20, step584]: loss 5.244588
[epoch20, step585]: loss 0.871153
[epoch20, step586]: loss 0.777371
[epoch20, step587]: loss 7.411457
[epoch20, step588]: loss 7.320618
[epoch20, step589]: loss 1.041541
[epoch20, step590]: loss 1.083240
[epoch20, step591]: loss 0.989997
[epoch20, step592]: loss 2.478235
[epoch20, step593]: loss 5.264232
[epoch20, step594]: loss 2.235514
[epoch20, step595]: loss 1.331869
[epoch20, step596]: loss 0.992329
[epoch20, step597]: loss 0.928351
[epoch20, step598]: loss 1.640556
[epoch20, step599]: loss 3.734615
[epoch20, step600]: loss 4.424241
[epoch20, step601]: loss 0.630292
[epoch20, step602]: loss 0.624043
[epoch20, step603]: loss 0.777310
[epoch20, step604]: loss 2.481297
[epoch20, step605]: loss 5.462278
[epoch20, step606]: loss 2.942377
[epoch20, step607]: loss 0.712617
[epoch20, step608]: loss 1.077568
[epoch20, step609]: loss 5.707433
[epoch20, step610]: loss 1.817593
[epoch20, step611]: loss 3.990542
[epoch20, step612]: loss 1.431174
[epoch20, step613]: loss 6.009007
[epoch20, step614]: loss 0.877700
[epoch20, step615]: loss 0.616394
[epoch20, step616]: loss 0.618852
[epoch20, step617]: loss 7.060618
[epoch20, step618]: loss 1.810459
[epoch20, step619]: loss 7.314127
[epoch20, step620]: loss 1.669731
[epoch20, step621]: loss 1.942459
[epoch20, step622]: loss 2.686791
[epoch20, step623]: loss 2.022508
[epoch20, step624]: loss 1.563262
[epoch20, step625]: loss 0.401125
[epoch20, step626]: loss 0.807130
[epoch20, step627]: loss 0.860287
[epoch20, step628]: loss 0.848264
[epoch20, step629]: loss 3.068357
[epoch20, step630]: loss 2.136050
[epoch20, step631]: loss 0.621485
[epoch20, step632]: loss 15.726686
[epoch20, step633]: loss 1.348262
[epoch20, step634]: loss 0.672856
[epoch20, step635]: loss 1.627966
[epoch20, step636]: loss 1.826927
[epoch20, step637]: loss 1.958247
[epoch20, step638]: loss 7.899670
[epoch20, step639]: loss 1.639775
[epoch20, step640]: loss 1.737436
[epoch20, step641]: loss 4.133259
[epoch20, step642]: loss 0.681370
[epoch20, step643]: loss 1.897860
[epoch20, step644]: loss 0.682493
[epoch20, step645]: loss 1.794769
[epoch20, step646]: loss 0.624402
[epoch20, step647]: loss 12.690573
[epoch20, step648]: loss 0.656421
[epoch20, step649]: loss 6.922929
[epoch20, step650]: loss 0.790404
[epoch20, step651]: loss 1.562636
[epoch20, step652]: loss 0.593752
[epoch20, step653]: loss 12.049639
[epoch20, step654]: loss 1.281907
[epoch20, step655]: loss 8.008685
[epoch20, step656]: loss 1.995124
[epoch20, step657]: loss 1.302813
[epoch20, step658]: loss 2.037830
[epoch20, step659]: loss 11.133058
[epoch20, step660]: loss 0.734257
[epoch20, step661]: loss 1.561012
[epoch20, step662]: loss 8.857470
[epoch20, step663]: loss 7.322685
[epoch20, step664]: loss 0.945703
[epoch20, step665]: loss 0.376799
[epoch20, step666]: loss 0.833458
[epoch20, step667]: loss 0.727034
[epoch20, step668]: loss 8.428062
[epoch20, step669]: loss 5.641773
[epoch20, step670]: loss 0.672025
[epoch20, step671]: loss 1.740612
[epoch20, step672]: loss 0.720630
[epoch20, step673]: loss 17.811262
[epoch20, step674]: loss 0.815242
[epoch20, step675]: loss 10.630577
[epoch20, step676]: loss 11.031719
[epoch20, step677]: loss 3.104817
[epoch20, step678]: loss 1.049157
[epoch20, step679]: loss 9.533566
[epoch20, step680]: loss 6.457146
[epoch20, step681]: loss 0.704155
[epoch20, step682]: loss 3.917102
[epoch20, step683]: loss 9.419551
[epoch20, step684]: loss 2.374799
[epoch20, step685]: loss 0.598795
[epoch20, step686]: loss 0.555273
[epoch20, step687]: loss 0.378511
[epoch20, step688]: loss 6.478232
[epoch20, step689]: loss 0.936441
[epoch20, step690]: loss 8.196902
[epoch20, step691]: loss 1.552913
[epoch20, step692]: loss 0.709400
[epoch20, step693]: loss 17.476690
[epoch20, step694]: loss 1.983536
[epoch20, step695]: loss 8.942331
[epoch20, step696]: loss 1.599176
[epoch20, step697]: loss 1.434641
[epoch20, step698]: loss 1.749977
[epoch20, step699]: loss 0.783748
[epoch20, step700]: loss 0.607030
[epoch20, step701]: loss 0.479599
[epoch20, step702]: loss 0.698148
[epoch20, step703]: loss 5.630417
[epoch20, step704]: loss 4.000764
[epoch20, step705]: loss 0.525123
[epoch20, step706]: loss 1.526610
[epoch20, step707]: loss 1.559196
[epoch20, step708]: loss 3.234011
[epoch20, step709]: loss 1.260109
[epoch20, step710]: loss 3.508321
[epoch20, step711]: loss 0.681284
[epoch20, step712]: loss 5.980661
[epoch20, step713]: loss 0.876570
[epoch20, step714]: loss 1.028850
[epoch20, step715]: loss 0.794151
[epoch20, step716]: loss 1.867759
[epoch20, step717]: loss 3.327969
[epoch20, step718]: loss 10.346889
[epoch20, step719]: loss 1.024335
[epoch20, step720]: loss 2.498254
[epoch20, step721]: loss 8.710986
[epoch20, step722]: loss 0.489885
[epoch20, step723]: loss 2.527501
[epoch20, step724]: loss 1.387481
[epoch20, step725]: loss 0.475817
[epoch20, step726]: loss 0.535475
[epoch20, step727]: loss 1.303022
[epoch20, step728]: loss 10.414459
[epoch20, step729]: loss 3.498946
[epoch20, step730]: loss 0.987598
[epoch20, step731]: loss 1.563590
[epoch20, step732]: loss 2.140994
[epoch20, step733]: loss 11.594303
[epoch20, step734]: loss 3.111007
[epoch20, step735]: loss 0.739737
[epoch20, step736]: loss 4.768904
[epoch20, step737]: loss 1.387744
[epoch20, step738]: loss 1.783289
[epoch20, step739]: loss 0.977173
[epoch20, step740]: loss 1.302909
[epoch20, step741]: loss 5.247119
[epoch20, step742]: loss 9.086836
[epoch20, step743]: loss 3.767327
[epoch20, step744]: loss 5.620025
[epoch20, step745]: loss 6.784715
[epoch20, step746]: loss 5.622716
[epoch20, step747]: loss 6.861703
[epoch20, step748]: loss 1.402593
[epoch20, step749]: loss 7.990175
[epoch20, step750]: loss 4.748306
[epoch20, step751]: loss 1.178506
[epoch20, step752]: loss 4.853559
[epoch20, step753]: loss 5.458519
[epoch20, step754]: loss 0.428733
[epoch20, step755]: loss 4.392422
[epoch20, step756]: loss 2.537817
[epoch20, step757]: loss 0.654395
[epoch20, step758]: loss 0.971171
[epoch20, step759]: loss 4.922371
[epoch20, step760]: loss 4.674670
[epoch20, step761]: loss 0.941395
[epoch20, step762]: loss 2.639434
[epoch20, step763]: loss 2.219607
[epoch20, step764]: loss 1.757894
[epoch20, step765]: loss 4.713478
[epoch20, step766]: loss 1.151605
[epoch20, step767]: loss 5.533057
[epoch20, step768]: loss 5.541683
[epoch20, step769]: loss 0.676314
[epoch20, step770]: loss 1.261526
[epoch20, step771]: loss 5.851544
[epoch20, step772]: loss 0.914536
[epoch20, step773]: loss 1.092507
[epoch20, step774]: loss 0.603687
[epoch20, step775]: loss 1.405706
[epoch20, step776]: loss 1.198155
[epoch20, step777]: loss 1.111791
[epoch20, step778]: loss 9.382017
[epoch20, step779]: loss 5.688529
[epoch20, step780]: loss 0.818413
[epoch20, step781]: loss 6.153895
[epoch20, step782]: loss 1.375710
[epoch20, step783]: loss 0.547008
[epoch20, step784]: loss 2.521799
[epoch20, step785]: loss 1.350119
[epoch20, step786]: loss 0.818457
[epoch20, step787]: loss 0.852873
[epoch20, step788]: loss 1.763233
[epoch20, step789]: loss 1.217859
[epoch20, step790]: loss 0.968029
[epoch20, step791]: loss 1.298041
[epoch20, step792]: loss 1.859218
[epoch20, step793]: loss 0.780300
[epoch20, step794]: loss 13.992180
[epoch20, step795]: loss 2.815681
[epoch20, step796]: loss 1.194097
[epoch20, step797]: loss 2.300374
[epoch20, step798]: loss 2.585166
[epoch20, step799]: loss 0.991515
[epoch20, step800]: loss 0.573173
[epoch20, step801]: loss 1.517360
[epoch20, step802]: loss 1.280812
[epoch20, step803]: loss 1.451653
[epoch20, step804]: loss 3.885914
[epoch20, step805]: loss 7.630939
[epoch20, step806]: loss 4.320052
[epoch20, step807]: loss 4.091507
[epoch20, step808]: loss 6.012268
[epoch20, step809]: loss 1.674280
[epoch20, step810]: loss 3.852148
[epoch20, step811]: loss 1.039880
[epoch20, step812]: loss 2.624315
[epoch20, step813]: loss 2.186086
[epoch20, step814]: loss 6.793547
[epoch20, step815]: loss 0.769157
[epoch20, step816]: loss 0.674820
[epoch20, step817]: loss 5.141181
[epoch20, step818]: loss 13.680019
[epoch20, step819]: loss 0.859070
[epoch20, step820]: loss 0.504454
[epoch20, step821]: loss 1.815780
[epoch20, step822]: loss 8.459431
[epoch20, step823]: loss 2.654976
[epoch20, step824]: loss 4.562276
[epoch20, step825]: loss 0.792492
[epoch20, step826]: loss 10.827315
[epoch20, step827]: loss 7.753529
[epoch20, step828]: loss 8.684955
[epoch20, step829]: loss 1.151893
[epoch20, step830]: loss 1.502755
[epoch20, step831]: loss 9.859655
[epoch20, step832]: loss 1.163364
[epoch20, step833]: loss 1.384521
[epoch20, step834]: loss 1.506890
[epoch20, step835]: loss 7.986336
[epoch20, step836]: loss 0.642795
[epoch20, step837]: loss 0.590982
[epoch20, step838]: loss 8.938545
[epoch20, step839]: loss 15.247683
[epoch20, step840]: loss 0.825882
[epoch20, step841]: loss 2.432205
[epoch20, step842]: loss 0.606399
[epoch20, step843]: loss 0.503844
[epoch20, step844]: loss 0.407502
[epoch20, step845]: loss 8.177148
[epoch20, step846]: loss 2.063708
[epoch20, step847]: loss 15.263893
[epoch20, step848]: loss 15.605985
[epoch20, step849]: loss 0.600966
[epoch20, step850]: loss 0.787281
[epoch20, step851]: loss 2.116124
[epoch20, step852]: loss 0.774384
[epoch20, step853]: loss 1.195260
[epoch20, step854]: loss 11.333283
[epoch20, step855]: loss 14.580765
[epoch20, step856]: loss 4.682755
[epoch20, step857]: loss 5.360892
[epoch20, step858]: loss 1.189887
[epoch20, step859]: loss 1.615395
[epoch20, step860]: loss 2.827065
[epoch20, step861]: loss 3.805663
[epoch20, step862]: loss 2.228592
[epoch20, step863]: loss 1.031476
[epoch20, step864]: loss 0.918754
[epoch20, step865]: loss 0.458271
[epoch20, step866]: loss 6.830183
[epoch20, step867]: loss 10.807456
[epoch20, step868]: loss 2.572615
[epoch20, step869]: loss 3.904655
[epoch20, step870]: loss 0.814115
[epoch20, step871]: loss 7.530568
[epoch20, step872]: loss 12.172554
[epoch20, step873]: loss 1.945750
[epoch20, step874]: loss 1.082220
[epoch20, step875]: loss 4.585573
[epoch20, step876]: loss 0.500022
[epoch20, step877]: loss 0.321746
[epoch20, step878]: loss 0.696562
[epoch20, step879]: loss 2.958253
[epoch20, step880]: loss 5.627347
[epoch20, step881]: loss 0.504818
[epoch20, step882]: loss 0.770596
[epoch20, step883]: loss 1.948516
[epoch20, step884]: loss 4.366368
[epoch20, step885]: loss 0.516978
[epoch20, step886]: loss 0.730737
[epoch20, step887]: loss 8.765529
[epoch20, step888]: loss 1.353424
[epoch20, step889]: loss 1.034167
[epoch20, step890]: loss 6.833017
[epoch20, step891]: loss 0.990586
[epoch20, step892]: loss 11.386229
[epoch20, step893]: loss 8.283241
[epoch20, step894]: loss 1.444774
[epoch20, step895]: loss 0.554978
[epoch20, step896]: loss 0.696396
[epoch20, step897]: loss 10.888230
[epoch20, step898]: loss 2.424959
[epoch20, step899]: loss 0.560032
[epoch20, step900]: loss 0.771596
[epoch20, step901]: loss 0.666914
[epoch20, step902]: loss 0.394735
[epoch20, step903]: loss 0.476380
[epoch20, step904]: loss 1.142368
[epoch20, step905]: loss 5.126764
[epoch20, step906]: loss 2.916920
[epoch20, step907]: loss 6.811814
[epoch20, step908]: loss 20.333923
[epoch20, step909]: loss 6.929003
[epoch20, step910]: loss 0.346452
[epoch20, step911]: loss 0.537953
[epoch20, step912]: loss 5.215930
[epoch20, step913]: loss 1.034308
[epoch20, step914]: loss 1.190778
[epoch20, step915]: loss 4.828594
[epoch20, step916]: loss 6.146089
[epoch20, step917]: loss 1.216614
[epoch20, step918]: loss 1.136865
[epoch20, step919]: loss 0.388394
[epoch20, step920]: loss 6.761413
[epoch20, step921]: loss 0.469980
[epoch20, step922]: loss 2.274231
[epoch20, step923]: loss 1.776655
[epoch20, step924]: loss 10.418099
[epoch20, step925]: loss 1.709572
[epoch20, step926]: loss 2.746568
[epoch20, step927]: loss 0.724072
[epoch20, step928]: loss 0.881374
[epoch20, step929]: loss 2.287176
[epoch20, step930]: loss 0.535816
[epoch20, step931]: loss 6.387457
[epoch20, step932]: loss 1.017672
[epoch20, step933]: loss 6.463181
[epoch20, step934]: loss 0.626950
[epoch20, step935]: loss 2.224749
[epoch20, step936]: loss 0.494766
[epoch20, step937]: loss 1.665897
[epoch20, step938]: loss 0.997190
[epoch20, step939]: loss 0.440702
[epoch20, step940]: loss 2.116316
[epoch20, step941]: loss 0.463213
[epoch20, step942]: loss 1.223531
[epoch20, step943]: loss 2.535492
[epoch20, step944]: loss 0.625099
[epoch20, step945]: loss 8.926403
[epoch20, step946]: loss 6.176515
[epoch20, step947]: loss 1.343253
[epoch20, step948]: loss 0.659466
[epoch20, step949]: loss 1.266721
[epoch20, step950]: loss 1.088690
[epoch20, step951]: loss 1.030247
[epoch20, step952]: loss 1.583487
[epoch20, step953]: loss 0.889306
[epoch20, step954]: loss 1.065650
[epoch20, step955]: loss 0.777208
[epoch20, step956]: loss 1.304275
[epoch20, step957]: loss 8.432044
[epoch20, step958]: loss 1.294230
[epoch20, step959]: loss 0.706839
[epoch20, step960]: loss 2.007601
[epoch20, step961]: loss 7.180468
[epoch20, step962]: loss 0.678291
[epoch20, step963]: loss 1.753723
[epoch20, step964]: loss 0.620374
[epoch20, step965]: loss 0.898502
[epoch20, step966]: loss 4.674683
[epoch20, step967]: loss 1.259523
[epoch20, step968]: loss 0.607516
[epoch20, step969]: loss 0.957323
[epoch20, step970]: loss 1.804877
[epoch20, step971]: loss 0.432489
[epoch20, step972]: loss 4.834088
[epoch20, step973]: loss 4.787151
[epoch20, step974]: loss 2.859333
[epoch20, step975]: loss 0.836448
[epoch20, step976]: loss 4.939185
[epoch20, step977]: loss 5.961069
[epoch20, step978]: loss 5.803760
[epoch20, step979]: loss 8.857061
[epoch20, step980]: loss 0.651407
[epoch20, step981]: loss 1.841848
[epoch20, step982]: loss 0.508457
[epoch20, step983]: loss 1.079211
[epoch20, step984]: loss 9.310505
[epoch20, step985]: loss 13.798108
[epoch20, step986]: loss 5.445442
[epoch20, step987]: loss 0.501333
[epoch20, step988]: loss 4.530955
[epoch20, step989]: loss 1.756989
[epoch20, step990]: loss 1.153061
[epoch20, step991]: loss 0.663460
[epoch20, step992]: loss 5.624146
[epoch20, step993]: loss 0.787161
[epoch20, step994]: loss 1.085969
[epoch20, step995]: loss 2.080311
[epoch20, step996]: loss 0.469580
[epoch20, step997]: loss 0.675883
[epoch20, step998]: loss 0.944817
[epoch20, step999]: loss 5.784138
[epoch20, step1000]: loss 0.884659
[epoch20, step1001]: loss 2.981133
[epoch20, step1002]: loss 1.789627
[epoch20, step1003]: loss 0.981365
[epoch20, step1004]: loss 0.466151
[epoch20, step1005]: loss 1.122316
[epoch20, step1006]: loss 10.868215
[epoch20, step1007]: loss 0.503210
[epoch20, step1008]: loss 10.719533
[epoch20, step1009]: loss 1.616678
[epoch20, step1010]: loss 1.318856
[epoch20, step1011]: loss 0.567472
[epoch20, step1012]: loss 1.759181
[epoch20, step1013]: loss 0.920633
[epoch20, step1014]: loss 0.793967
[epoch20, step1015]: loss 2.658295
[epoch20, step1016]: loss 1.326752
[epoch20, step1017]: loss 0.705656
[epoch20, step1018]: loss 3.429004
[epoch20, step1019]: loss 0.536585
[epoch20, step1020]: loss 0.532850
[epoch20, step1021]: loss 2.170877
[epoch20, step1022]: loss 0.724246
[epoch20, step1023]: loss 0.748022
[epoch20, step1024]: loss 0.676759
[epoch20, step1025]: loss 2.091296
[epoch20, step1026]: loss 0.591173
[epoch20, step1027]: loss 4.128552
[epoch20, step1028]: loss 1.152942
[epoch20, step1029]: loss 0.826393
[epoch20, step1030]: loss 1.886324
[epoch20, step1031]: loss 4.966637
[epoch20, step1032]: loss 1.155678
[epoch20, step1033]: loss 15.347283
[epoch20, step1034]: loss 0.500806
[epoch20, step1035]: loss 8.466159
[epoch20, step1036]: loss 0.785031
[epoch20, step1037]: loss 4.390546
[epoch20, step1038]: loss 0.614942
[epoch20, step1039]: loss 0.588415
[epoch20, step1040]: loss 1.452455
[epoch20, step1041]: loss 1.866299
[epoch20, step1042]: loss 5.596781
[epoch20, step1043]: loss 1.422957
[epoch20, step1044]: loss 0.823380
[epoch20, step1045]: loss 0.677405
[epoch20, step1046]: loss 1.414474
[epoch20, step1047]: loss 10.029710
[epoch20, step1048]: loss 3.733060
[epoch20, step1049]: loss 1.199922
[epoch20, step1050]: loss 1.119945
[epoch20, step1051]: loss 15.175479
[epoch20, step1052]: loss 9.433855
[epoch20, step1053]: loss 4.878171
[epoch20, step1054]: loss 2.837345
[epoch20, step1055]: loss 2.645470
[epoch20, step1056]: loss 1.064100
[epoch20, step1057]: loss 2.664400
[epoch20, step1058]: loss 8.080527
[epoch20, step1059]: loss 6.626131
[epoch20, step1060]: loss 3.305820
[epoch20, step1061]: loss 0.574135
[epoch20, step1062]: loss 1.951977
[epoch20, step1063]: loss 6.856989
[epoch20, step1064]: loss 0.930603
[epoch20, step1065]: loss 2.168536
[epoch20, step1066]: loss 0.579848
[epoch20, step1067]: loss 1.744935
[epoch20, step1068]: loss 1.125665
[epoch20, step1069]: loss 2.935763
[epoch20, step1070]: loss 5.460147
[epoch20, step1071]: loss 16.207214
[epoch20, step1072]: loss 2.696891
[epoch20, step1073]: loss 8.385808
[epoch20, step1074]: loss 0.697463
[epoch20, step1075]: loss 2.204023
[epoch20, step1076]: loss 0.806843
[epoch20, step1077]: loss 1.910261
[epoch20, step1078]: loss 0.592271
[epoch20, step1079]: loss 2.416668
[epoch20, step1080]: loss 2.929433
[epoch20, step1081]: loss 7.816383
[epoch20, step1082]: loss 5.566705
[epoch20, step1083]: loss 6.191895
[epoch20, step1084]: loss 8.421996
[epoch20, step1085]: loss 1.803002
[epoch20, step1086]: loss 13.614385
[epoch20, step1087]: loss 2.162475
[epoch20, step1088]: loss 0.561345
[epoch20, step1089]: loss 9.512841
[epoch20, step1090]: loss 2.817038
[epoch20, step1091]: loss 0.984366
[epoch20, step1092]: loss 5.766748
[epoch20, step1093]: loss 1.818591
[epoch20, step1094]: loss 1.568706
[epoch20, step1095]: loss 0.978482
[epoch20, step1096]: loss 5.766461
[epoch20, step1097]: loss 3.718597
[epoch20, step1098]: loss 7.875522
[epoch20, step1099]: loss 0.768335
[epoch20, step1100]: loss 1.743789
[epoch20, step1101]: loss 5.201415
[epoch20, step1102]: loss 7.554219
[epoch20, step1103]: loss 0.886928
[epoch20, step1104]: loss 2.157083
[epoch20, step1105]: loss 7.280924
[epoch20, step1106]: loss 2.678330
[epoch20, step1107]: loss 4.568779
[epoch20, step1108]: loss 0.566326
[epoch20, step1109]: loss 0.792949
[epoch20, step1110]: loss 3.288573
[epoch20, step1111]: loss 1.592540
[epoch20, step1112]: loss 0.654550
[epoch20, step1113]: loss 1.833797
[epoch20, step1114]: loss 2.705062
[epoch20, step1115]: loss 12.021119
[epoch20, step1116]: loss 0.538492
[epoch20, step1117]: loss 1.226801
[epoch20, step1118]: loss 4.893958
[epoch20, step1119]: loss 0.668010
[epoch20, step1120]: loss 4.422769
[epoch20, step1121]: loss 1.489197
[epoch20, step1122]: loss 0.774724
[epoch20, step1123]: loss 0.847556
[epoch20, step1124]: loss 11.274401
[epoch20, step1125]: loss 1.534773
[epoch20, step1126]: loss 0.715025
[epoch20, step1127]: loss 2.948483
[epoch20, step1128]: loss 3.186443
[epoch20, step1129]: loss 0.677712
[epoch20, step1130]: loss 2.553813
[epoch20, step1131]: loss 1.802681
[epoch20, step1132]: loss 2.416446
[epoch20, step1133]: loss 0.879582
[epoch20, step1134]: loss 3.284867
[epoch20, step1135]: loss 3.960395
[epoch20, step1136]: loss 1.782272
[epoch20, step1137]: loss 1.243248
[epoch20, step1138]: loss 1.821878
[epoch20, step1139]: loss 0.686241
[epoch20, step1140]: loss 9.591652
[epoch20, step1141]: loss 6.050695
[epoch20, step1142]: loss 1.255668
[epoch20, step1143]: loss 6.582084
[epoch20, step1144]: loss 1.048307
[epoch20, step1145]: loss 1.255246
[epoch20, step1146]: loss 0.663818
[epoch20, step1147]: loss 1.302734
[epoch20, step1148]: loss 1.261055
[epoch20, step1149]: loss 3.433159
[epoch20, step1150]: loss 1.550233
[epoch20, step1151]: loss 0.891134
[epoch20, step1152]: loss 12.589994
[epoch20, step1153]: loss 1.498791
[epoch20, step1154]: loss 0.648952
[epoch20, step1155]: loss 1.796934
[epoch20, step1156]: loss 13.609892
[epoch20, step1157]: loss 5.573249
[epoch20, step1158]: loss 0.504342
[epoch20, step1159]: loss 2.034891
[epoch20, step1160]: loss 0.682900
[epoch20, step1161]: loss 7.656986
[epoch20, step1162]: loss 0.939479
[epoch20, step1163]: loss 4.979656
[epoch20, step1164]: loss 1.356656
[epoch20, step1165]: loss 1.986163
[epoch20, step1166]: loss 5.441150
[epoch20, step1167]: loss 1.951843
[epoch20, step1168]: loss 1.384396
[epoch20, step1169]: loss 13.484870
[epoch20, step1170]: loss 0.484821
[epoch20, step1171]: loss 5.678773
[epoch20, step1172]: loss 3.071669
[epoch20, step1173]: loss 1.394877
[epoch20, step1174]: loss 6.251899
[epoch20, step1175]: loss 1.285173
[epoch20, step1176]: loss 1.653399
[epoch20, step1177]: loss 0.933176
[epoch20, step1178]: loss 0.999153
[epoch20, step1179]: loss 0.789752
[epoch20, step1180]: loss 3.363345
[epoch20, step1181]: loss 0.513799
[epoch20, step1182]: loss 3.269495
[epoch20, step1183]: loss 0.584192
[epoch20, step1184]: loss 8.495646
[epoch20, step1185]: loss 0.537857
[epoch20, step1186]: loss 7.985905
[epoch20, step1187]: loss 9.622477
[epoch20, step1188]: loss 2.170394
[epoch20, step1189]: loss 17.957157
[epoch20, step1190]: loss 7.067141
[epoch20, step1191]: loss 1.107838
[epoch20, step1192]: loss 0.677598
[epoch20, step1193]: loss 4.807366
[epoch20, step1194]: loss 0.832735
[epoch20, step1195]: loss 0.974285
[epoch20, step1196]: loss 0.593946
[epoch20, step1197]: loss 0.975367
[epoch20, step1198]: loss 0.999165
[epoch20, step1199]: loss 0.876493
[epoch20, step1200]: loss 10.374893
[epoch20, step1201]: loss 0.972680
[epoch20, step1202]: loss 1.227993
[epoch20, step1203]: loss 2.242296
[epoch20, step1204]: loss 5.375744
[epoch20, step1205]: loss 10.602339
[epoch20, step1206]: loss 0.768450
[epoch20, step1207]: loss 0.710673
[epoch20, step1208]: loss 11.902940
[epoch20, step1209]: loss 1.461982
[epoch20, step1210]: loss 0.674684
[epoch20, step1211]: loss 1.320482
[epoch20, step1212]: loss 0.762850
[epoch20, step1213]: loss 3.625872
[epoch20, step1214]: loss 0.598267
[epoch20, step1215]: loss 1.084636
[epoch20, step1216]: loss 3.921041
[epoch20, step1217]: loss 3.091176
[epoch20, step1218]: loss 1.225994
[epoch20, step1219]: loss 1.421091
[epoch20, step1220]: loss 0.773161
[epoch20, step1221]: loss 6.534948
[epoch20, step1222]: loss 0.422832
[epoch20, step1223]: loss 6.761565
[epoch20, step1224]: loss 2.638285
[epoch20, step1225]: loss 11.529242
[epoch20, step1226]: loss 4.115529
[epoch20, step1227]: loss 3.075875
[epoch20, step1228]: loss 8.651711
[epoch20, step1229]: loss 0.928828
[epoch20, step1230]: loss 3.146521
[epoch20, step1231]: loss 6.259097
[epoch20, step1232]: loss 4.115914
[epoch20, step1233]: loss 1.796662
[epoch20, step1234]: loss 2.297882
[epoch20, step1235]: loss 0.687752
[epoch20, step1236]: loss 7.346166
[epoch20, step1237]: loss 12.568405
[epoch20, step1238]: loss 0.540035
[epoch20, step1239]: loss 10.253224
[epoch20, step1240]: loss 2.084445
[epoch20, step1241]: loss 3.045779
[epoch20, step1242]: loss 2.088426
[epoch20, step1243]: loss 1.756473
[epoch20, step1244]: loss 1.357165
[epoch20, step1245]: loss 6.232137
[epoch20, step1246]: loss 0.960723
[epoch20, step1247]: loss 1.510267
[epoch20, step1248]: loss 0.952709
[epoch20, step1249]: loss 0.618670
[epoch20, step1250]: loss 1.388872
[epoch20, step1251]: loss 9.544807
[epoch20, step1252]: loss 0.841940
[epoch20, step1253]: loss 7.048159
[epoch20, step1254]: loss 11.627526
[epoch20, step1255]: loss 0.932412
[epoch20, step1256]: loss 0.923645
[epoch20, step1257]: loss 12.832425
[epoch20, step1258]: loss 0.931657
[epoch20, step1259]: loss 0.957017
[epoch20, step1260]: loss 1.044058
[epoch20, step1261]: loss 0.469354
[epoch20, step1262]: loss 0.543239
[epoch20, step1263]: loss 0.713209
[epoch20, step1264]: loss 17.237152
[epoch20, step1265]: loss 9.474650
[epoch20, step1266]: loss 0.784633
[epoch20, step1267]: loss 1.158756
[epoch20, step1268]: loss 0.733860
[epoch20, step1269]: loss 0.716578
[epoch20, step1270]: loss 0.589032
[epoch20, step1271]: loss 1.255591
[epoch20, step1272]: loss 0.932511
[epoch20, step1273]: loss 2.904433
[epoch20, step1274]: loss 0.836872
[epoch20, step1275]: loss 0.580292
[epoch20, step1276]: loss 0.684402
[epoch20, step1277]: loss 0.505230
[epoch20, step1278]: loss 6.525296
[epoch20, step1279]: loss 0.745846
[epoch20, step1280]: loss 5.975832
[epoch20, step1281]: loss 0.687968
[epoch20, step1282]: loss 5.234183
[epoch20, step1283]: loss 0.636332
[epoch20, step1284]: loss 3.061347
[epoch20, step1285]: loss 5.764146
[epoch20, step1286]: loss 12.866208
[epoch20, step1287]: loss 0.465007
[epoch20, step1288]: loss 2.362350
[epoch20, step1289]: loss 4.152414
[epoch20, step1290]: loss 0.564939
[epoch20, step1291]: loss 4.414505
[epoch20, step1292]: loss 2.497095
[epoch20, step1293]: loss 0.913811
[epoch20, step1294]: loss 1.584991
[epoch20, step1295]: loss 1.087951
[epoch20, step1296]: loss 0.512365
[epoch20, step1297]: loss 9.846291
[epoch20, step1298]: loss 0.952443
[epoch20, step1299]: loss 0.430786
[epoch20, step1300]: loss 0.809002
[epoch20, step1301]: loss 1.129739
[epoch20, step1302]: loss 0.316301
[epoch20, step1303]: loss 0.982380
[epoch20, step1304]: loss 0.923879
[epoch20, step1305]: loss 1.787150
[epoch20, step1306]: loss 0.500947
[epoch20, step1307]: loss 1.405946
[epoch20, step1308]: loss 0.578952
[epoch20, step1309]: loss 0.646198
[epoch20, step1310]: loss 17.505051
[epoch20, step1311]: loss 0.755505
[epoch20, step1312]: loss 0.896959
[epoch20, step1313]: loss 1.108893
[epoch20, step1314]: loss 2.864970
[epoch20, step1315]: loss 1.787171
[epoch20, step1316]: loss 0.560124
[epoch20, step1317]: loss 18.964104
[epoch20, step1318]: loss 0.753555
[epoch20, step1319]: loss 1.065229
[epoch20, step1320]: loss 6.170845
[epoch20, step1321]: loss 5.254252
[epoch20, step1322]: loss 0.806482
[epoch20, step1323]: loss 1.980121
[epoch20, step1324]: loss 0.412839
[epoch20, step1325]: loss 2.018048
[epoch20, step1326]: loss 1.649230
[epoch20, step1327]: loss 5.589629
[epoch20, step1328]: loss 0.595398
[epoch20, step1329]: loss 1.212504
[epoch20, step1330]: loss 8.416864
[epoch20, step1331]: loss 1.045420
[epoch20, step1332]: loss 5.459958
[epoch20, step1333]: loss 9.440938
[epoch20, step1334]: loss 6.631554
[epoch20, step1335]: loss 5.197733
[epoch20, step1336]: loss 0.489264
[epoch20, step1337]: loss 0.943182
[epoch20, step1338]: loss 0.956164
[epoch20, step1339]: loss 5.839545
[epoch20, step1340]: loss 5.963479
[epoch20, step1341]: loss 0.815436
[epoch20, step1342]: loss 1.945636
[epoch20, step1343]: loss 8.452067
[epoch20, step1344]: loss 7.203790
[epoch20, step1345]: loss 4.607580
[epoch20, step1346]: loss 1.935973
[epoch20, step1347]: loss 1.442922
[epoch20, step1348]: loss 11.104118
[epoch20, step1349]: loss 5.787916
[epoch20, step1350]: loss 1.222054
[epoch20, step1351]: loss 1.725324
[epoch20, step1352]: loss 0.972320
[epoch20, step1353]: loss 0.970756
[epoch20, step1354]: loss 1.914055
[epoch20, step1355]: loss 2.354943
[epoch20, step1356]: loss 0.614270
[epoch20, step1357]: loss 1.905820
[epoch20, step1358]: loss 1.238607
[epoch20, step1359]: loss 0.977268
[epoch20, step1360]: loss 0.767775
[epoch20, step1361]: loss 3.076938
[epoch20, step1362]: loss 4.770150
[epoch20, step1363]: loss 0.523468
[epoch20, step1364]: loss 0.892906
[epoch20, step1365]: loss 0.632882
[epoch20, step1366]: loss 6.495842
[epoch20, step1367]: loss 0.918774
[epoch20, step1368]: loss 6.915037
[epoch20, step1369]: loss 1.397401
[epoch20, step1370]: loss 0.540584
[epoch20, step1371]: loss 1.750510
[epoch20, step1372]: loss 4.668880
[epoch20, step1373]: loss 2.339477
[epoch20, step1374]: loss 18.336636
[epoch20, step1375]: loss 0.969162
[epoch20, step1376]: loss 2.779703
[epoch20, step1377]: loss 11.397240
[epoch20, step1378]: loss 5.974834
[epoch20, step1379]: loss 5.288074
[epoch20, step1380]: loss 1.686107
[epoch20, step1381]: loss 3.032747
[epoch20, step1382]: loss 0.411849
[epoch20, step1383]: loss 1.358958
[epoch20, step1384]: loss 1.301753
[epoch20, step1385]: loss 11.315859
[epoch20, step1386]: loss 0.670177
[epoch20, step1387]: loss 6.821722
[epoch20, step1388]: loss 6.745571
[epoch20, step1389]: loss 1.534001
[epoch20, step1390]: loss 0.592065
[epoch20, step1391]: loss 0.853225
[epoch20, step1392]: loss 1.291218
[epoch20, step1393]: loss 0.930458
[epoch20, step1394]: loss 7.833609
[epoch20, step1395]: loss 0.692840
[epoch20, step1396]: loss 5.286787
[epoch20, step1397]: loss 0.920891
[epoch20, step1398]: loss 1.957154
[epoch20, step1399]: loss 0.406643
[epoch20, step1400]: loss 4.812479
[epoch20, step1401]: loss 3.337560
[epoch20, step1402]: loss 0.625732
[epoch20, step1403]: loss 1.074229
[epoch20, step1404]: loss 5.587958
[epoch20, step1405]: loss 0.891770
[epoch20, step1406]: loss 5.773089
[epoch20, step1407]: loss 0.927041
[epoch20, step1408]: loss 5.526538
[epoch20, step1409]: loss 0.922702
[epoch20, step1410]: loss 0.825217
[epoch20, step1411]: loss 7.531407
[epoch20, step1412]: loss 0.746248
[epoch20, step1413]: loss 0.818246
[epoch20, step1414]: loss 1.238296
[epoch20, step1415]: loss 0.411003
[epoch20, step1416]: loss 3.055103
[epoch20, step1417]: loss 0.857699
[epoch20, step1418]: loss 2.747794
[epoch20, step1419]: loss 2.470260
[epoch20, step1420]: loss 1.083733
[epoch20, step1421]: loss 4.058193
[epoch20, step1422]: loss 9.994911
[epoch20, step1423]: loss 7.128951
[epoch20, step1424]: loss 1.265250
[epoch20, step1425]: loss 0.891191
[epoch20, step1426]: loss 2.248224
[epoch20, step1427]: loss 4.523520
[epoch20, step1428]: loss 0.731839
[epoch20, step1429]: loss 1.381923
[epoch20, step1430]: loss 1.180837
[epoch20, step1431]: loss 1.479066
[epoch20, step1432]: loss 0.652292
[epoch20, step1433]: loss 2.361880
[epoch20, step1434]: loss 0.867919
[epoch20, step1435]: loss 2.049676
[epoch20, step1436]: loss 12.390575
[epoch20, step1437]: loss 8.686765
[epoch20, step1438]: loss 2.449689
[epoch20, step1439]: loss 0.965058
[epoch20, step1440]: loss 1.067581
[epoch20, step1441]: loss 1.354104
[epoch20, step1442]: loss 0.789989
[epoch20, step1443]: loss 1.610520
[epoch20, step1444]: loss 1.048529
[epoch20, step1445]: loss 1.413363
[epoch20, step1446]: loss 11.365055
[epoch20, step1447]: loss 0.573769
[epoch20, step1448]: loss 2.423388
[epoch20, step1449]: loss 1.822233
[epoch20, step1450]: loss 3.778478
[epoch20, step1451]: loss 4.700697
[epoch20, step1452]: loss 5.893555
[epoch20, step1453]: loss 2.361563
[epoch20, step1454]: loss 0.792452
[epoch20, step1455]: loss 5.527413
[epoch20, step1456]: loss 2.202918
[epoch20, step1457]: loss 1.060561
[epoch20, step1458]: loss 10.019359
[epoch20, step1459]: loss 0.780696
[epoch20, step1460]: loss 8.286787
[epoch20, step1461]: loss 0.965149
[epoch20, step1462]: loss 0.882681
[epoch20, step1463]: loss 0.603203
[epoch20, step1464]: loss 5.428418
[epoch20, step1465]: loss 4.533051
[epoch20, step1466]: loss 9.442545
[epoch20, step1467]: loss 1.629743
[epoch20, step1468]: loss 11.549622
[epoch20, step1469]: loss 1.716145
[epoch20, step1470]: loss 0.830910
[epoch20, step1471]: loss 1.326502
[epoch20, step1472]: loss 0.628623
[epoch20, step1473]: loss 2.003099
[epoch20, step1474]: loss 17.316187
[epoch20, step1475]: loss 2.041310
[epoch20, step1476]: loss 0.463214
[epoch20, step1477]: loss 0.586870
[epoch20, step1478]: loss 2.000170
[epoch20, step1479]: loss 1.147265
[epoch20, step1480]: loss 9.383901
[epoch20, step1481]: loss 0.839060
[epoch20, step1482]: loss 3.575949
[epoch20, step1483]: loss 0.635972
[epoch20, step1484]: loss 8.877665
[epoch20, step1485]: loss 12.787201
[epoch20, step1486]: loss 1.506885
[epoch20, step1487]: loss 3.027941
[epoch20, step1488]: loss 1.384557
[epoch20, step1489]: loss 0.784017
[epoch20, step1490]: loss 2.413904
[epoch20, step1491]: loss 10.957679
[epoch20, step1492]: loss 0.905397
[epoch20, step1493]: loss 5.538064
[epoch20, step1494]: loss 1.365680
[epoch20, step1495]: loss 8.792310
[epoch20, step1496]: loss 2.016910
[epoch20, step1497]: loss 0.606129
[epoch20, step1498]: loss 9.791604
[epoch20, step1499]: loss 0.718554
[epoch20, step1500]: loss 4.326204
[epoch20, step1501]: loss 1.681015
[epoch20, step1502]: loss 0.600184
[epoch20, step1503]: loss 10.220855
[epoch20, step1504]: loss 0.559467
[epoch20, step1505]: loss 0.933303
[epoch20, step1506]: loss 5.885452
[epoch20, step1507]: loss 3.356370
[epoch20, step1508]: loss 10.820951
[epoch20, step1509]: loss 0.770901
[epoch20, step1510]: loss 1.009973
[epoch20, step1511]: loss 0.968000
[epoch20, step1512]: loss 1.175919
[epoch20, step1513]: loss 4.125833
[epoch20, step1514]: loss 1.951716
[epoch20, step1515]: loss 0.786527
[epoch20, step1516]: loss 1.167642
[epoch20, step1517]: loss 10.259645
[epoch20, step1518]: loss 10.061256
[epoch20, step1519]: loss 1.709727
[epoch20, step1520]: loss 0.981734
[epoch20, step1521]: loss 0.721217
[epoch20, step1522]: loss 2.275297
[epoch20, step1523]: loss 0.911619
[epoch20, step1524]: loss 5.794683
[epoch20, step1525]: loss 0.790057
[epoch20, step1526]: loss 1.326533
[epoch20, step1527]: loss 6.384204
[epoch20, step1528]: loss 5.017339
[epoch20, step1529]: loss 0.598549
[epoch20, step1530]: loss 1.729431
[epoch20, step1531]: loss 0.622324
[epoch20, step1532]: loss 0.873454
[epoch20, step1533]: loss 0.601166
[epoch20, step1534]: loss 0.797263
[epoch20, step1535]: loss 0.648578
[epoch20, step1536]: loss 0.488522
[epoch20, step1537]: loss 1.805176
[epoch20, step1538]: loss 0.644663
[epoch20, step1539]: loss 6.572810
[epoch20, step1540]: loss 0.936031
[epoch20, step1541]: loss 2.797482
[epoch20, step1542]: loss 0.595210
[epoch20, step1543]: loss 1.721001
[epoch20, step1544]: loss 5.413006
[epoch20, step1545]: loss 1.629603
[epoch20, step1546]: loss 8.626503
[epoch20, step1547]: loss 1.006405
[epoch20, step1548]: loss 0.565242
[epoch20, step1549]: loss 0.759672
[epoch20, step1550]: loss 2.178436
[epoch20, step1551]: loss 0.683051
[epoch20, step1552]: loss 6.225595
[epoch20, step1553]: loss 1.179385
[epoch20, step1554]: loss 0.731738
[epoch20, step1555]: loss 0.657692
[epoch20, step1556]: loss 9.802239
[epoch20, step1557]: loss 0.665697
[epoch20, step1558]: loss 1.223191
[epoch20, step1559]: loss 5.725953
[epoch20, step1560]: loss 0.921372
[epoch20, step1561]: loss 1.047830
[epoch20, step1562]: loss 4.123433
[epoch20, step1563]: loss 1.135417
[epoch20, step1564]: loss 1.202117
[epoch20, step1565]: loss 0.946547
[epoch20, step1566]: loss 2.064682
[epoch20, step1567]: loss 0.534093
[epoch20, step1568]: loss 0.523067
[epoch20, step1569]: loss 5.864192
[epoch20, step1570]: loss 8.728935
[epoch20, step1571]: loss 1.362247
[epoch20, step1572]: loss 1.045637
[epoch20, step1573]: loss 0.952161
[epoch20, step1574]: loss 1.466586
[epoch20, step1575]: loss 1.727851
[epoch20, step1576]: loss 8.291836
[epoch20, step1577]: loss 6.474562
[epoch20, step1578]: loss 0.876782
[epoch20, step1579]: loss 15.576110
[epoch20, step1580]: loss 6.334920
[epoch20, step1581]: loss 7.900658
[epoch20, step1582]: loss 1.712559
[epoch20, step1583]: loss 1.194632
[epoch20, step1584]: loss 0.931562
[epoch20, step1585]: loss 7.359068
[epoch20, step1586]: loss 3.352086
[epoch20, step1587]: loss 0.987252
[epoch20, step1588]: loss 0.598921
[epoch20, step1589]: loss 0.542317
[epoch20, step1590]: loss 0.676882
[epoch20, step1591]: loss 1.009346
[epoch20, step1592]: loss 0.384952
[epoch20, step1593]: loss 2.783279
[epoch20, step1594]: loss 6.065837
[epoch20, step1595]: loss 7.231798
[epoch20, step1596]: loss 0.490230
[epoch20, step1597]: loss 0.465428
[epoch20, step1598]: loss 13.868227
[epoch20, step1599]: loss 4.385057
[epoch20, step1600]: loss 9.605441
[epoch20, step1601]: loss 5.527049
[epoch20, step1602]: loss 0.703979
[epoch20, step1603]: loss 10.249765
[epoch20, step1604]: loss 5.792377
[epoch20, step1605]: loss 1.290636
[epoch20, step1606]: loss 10.761548
[epoch20, step1607]: loss 2.372814
[epoch20, step1608]: loss 1.657091
[epoch20, step1609]: loss 1.260753
[epoch20, step1610]: loss 8.699785
[epoch20, step1611]: loss 0.607977
[epoch20, step1612]: loss 3.026937
[epoch20, step1613]: loss 8.563847
[epoch20, step1614]: loss 3.712939
[epoch20, step1615]: loss 1.480608
[epoch20, step1616]: loss 0.649680
[epoch20, step1617]: loss 1.006325
[epoch20, step1618]: loss 4.667994
[epoch20, step1619]: loss 1.713699
[epoch20, step1620]: loss 1.701519
[epoch20, step1621]: loss 1.705541
[epoch20, step1622]: loss 8.093925
[epoch20, step1623]: loss 9.340049
[epoch20, step1624]: loss 5.232095
[epoch20, step1625]: loss 3.072625
[epoch20, step1626]: loss 0.617058
[epoch20, step1627]: loss 0.527730
[epoch20, step1628]: loss 1.406646
[epoch20, step1629]: loss 2.415190
[epoch20, step1630]: loss 20.044676
[epoch20, step1631]: loss 1.992612
[epoch20, step1632]: loss 0.988863
[epoch20, step1633]: loss 1.593295
[epoch20, step1634]: loss 4.886680
[epoch20, step1635]: loss 0.703411
[epoch20, step1636]: loss 2.935166
[epoch20, step1637]: loss 8.362132
[epoch20, step1638]: loss 9.705428
[epoch20, step1639]: loss 2.489687
[epoch20, step1640]: loss 0.501120
[epoch20, step1641]: loss 8.883785
[epoch20, step1642]: loss 0.447466
[epoch20, step1643]: loss 0.852636
[epoch20, step1644]: loss 0.483246
[epoch20, step1645]: loss 2.264917
[epoch20, step1646]: loss 0.701130
[epoch20, step1647]: loss 2.056158
[epoch20, step1648]: loss 9.646807
[epoch20, step1649]: loss 0.491610
[epoch20, step1650]: loss 0.527473
[epoch20, step1651]: loss 0.966117
[epoch20, step1652]: loss 12.496253
[epoch20, step1653]: loss 0.781673
[epoch20, step1654]: loss 0.902858
[epoch20, step1655]: loss 6.236440
[epoch20, step1656]: loss 3.991624
[epoch20, step1657]: loss 7.362329
[epoch20, step1658]: loss 2.231063
[epoch20, step1659]: loss 1.422246
[epoch20, step1660]: loss 0.907141
[epoch20, step1661]: loss 0.845809
[epoch20, step1662]: loss 10.225170
[epoch20, step1663]: loss 0.744280
[epoch20, step1664]: loss 0.661286
[epoch20, step1665]: loss 2.235048
[epoch20, step1666]: loss 13.080124
[epoch20, step1667]: loss 2.140392
[epoch20, step1668]: loss 5.199251
[epoch20, step1669]: loss 3.310786
[epoch20, step1670]: loss 1.229135
[epoch20, step1671]: loss 1.958246
[epoch20, step1672]: loss 1.234049
[epoch20, step1673]: loss 4.959908
[epoch20, step1674]: loss 2.052677
[epoch20, step1675]: loss 0.575264
[epoch20, step1676]: loss 0.734068
[epoch20, step1677]: loss 3.647952
[epoch20, step1678]: loss 9.650047
[epoch20, step1679]: loss 0.447190
[epoch20, step1680]: loss 12.545685
[epoch20, step1681]: loss 0.721799
[epoch20, step1682]: loss 0.688807
[epoch20, step1683]: loss 1.461177
[epoch20, step1684]: loss 2.749261
[epoch20, step1685]: loss 1.028842
[epoch20, step1686]: loss 7.318916
[epoch20, step1687]: loss 4.328372
[epoch20, step1688]: loss 10.019737
[epoch20, step1689]: loss 8.769056
[epoch20, step1690]: loss 2.120039
[epoch20, step1691]: loss 5.533125
[epoch20, step1692]: loss 0.611298
[epoch20, step1693]: loss 0.689285
[epoch20, step1694]: loss 16.310133
[epoch20, step1695]: loss 8.892442
[epoch20, step1696]: loss 6.664179
[epoch20, step1697]: loss 2.268196
[epoch20, step1698]: loss 0.896028
[epoch20, step1699]: loss 1.552179
[epoch20, step1700]: loss 8.786892
[epoch20, step1701]: loss 1.283228
[epoch20, step1702]: loss 0.706140
[epoch20, step1703]: loss 0.856355
[epoch20, step1704]: loss 7.621654
[epoch20, step1705]: loss 5.493712
[epoch20, step1706]: loss 1.483289
[epoch20, step1707]: loss 5.358793
[epoch20, step1708]: loss 0.888581
[epoch20, step1709]: loss 0.651291
[epoch20, step1710]: loss 1.716678
[epoch20, step1711]: loss 0.503251
[epoch20, step1712]: loss 1.940723
[epoch20, step1713]: loss 8.553413
[epoch20, step1714]: loss 6.003088
[epoch20, step1715]: loss 1.817812
[epoch20, step1716]: loss 5.804780
[epoch20, step1717]: loss 0.515678
[epoch20, step1718]: loss 1.336644
[epoch20, step1719]: loss 1.000817
[epoch20, step1720]: loss 8.520414
[epoch20, step1721]: loss 2.950751
[epoch20, step1722]: loss 8.728354
[epoch20, step1723]: loss 1.824373
[epoch20, step1724]: loss 0.793986
[epoch20, step1725]: loss 2.833174
[epoch20, step1726]: loss 0.583252
[epoch20, step1727]: loss 1.105439
[epoch20, step1728]: loss 13.542882
[epoch20, step1729]: loss 0.545666
[epoch20, step1730]: loss 0.451437
[epoch20, step1731]: loss 4.053381
[epoch20, step1732]: loss 0.752698
[epoch20, step1733]: loss 0.725842
[epoch20, step1734]: loss 10.831413
[epoch20, step1735]: loss 0.910917
[epoch20, step1736]: loss 2.458740
[epoch20, step1737]: loss 10.566908
[epoch20, step1738]: loss 2.135841
[epoch20, step1739]: loss 2.372585
[epoch20, step1740]: loss 4.591089
[epoch20, step1741]: loss 0.683706
[epoch20, step1742]: loss 6.797216
[epoch20, step1743]: loss 5.403704
[epoch20, step1744]: loss 4.877211
[epoch20, step1745]: loss 7.107270
[epoch20, step1746]: loss 7.386603
[epoch20, step1747]: loss 2.258851
[epoch20, step1748]: loss 6.243037
[epoch20, step1749]: loss 8.308879
[epoch20, step1750]: loss 7.449772
[epoch20, step1751]: loss 0.818545
[epoch20, step1752]: loss 5.846335
[epoch20, step1753]: loss 4.361954
[epoch20, step1754]: loss 0.883680
[epoch20, step1755]: loss 0.603659
[epoch20, step1756]: loss 11.852029
[epoch20, step1757]: loss 6.959292
[epoch20, step1758]: loss 2.245168
[epoch20, step1759]: loss 4.675094
[epoch20, step1760]: loss 0.916610
[epoch20, step1761]: loss 0.748307
[epoch20, step1762]: loss 8.333761
[epoch20, step1763]: loss 6.131761
[epoch20, step1764]: loss 6.257780
[epoch20, step1765]: loss 2.521048
[epoch20, step1766]: loss 9.481376
[epoch20, step1767]: loss 0.639858
[epoch20, step1768]: loss 0.518173
[epoch20, step1769]: loss 1.957757
[epoch20, step1770]: loss 3.373655
[epoch20, step1771]: loss 0.971882
[epoch20, step1772]: loss 3.804233
[epoch20, step1773]: loss 9.329346
[epoch20, step1774]: loss 6.538747
[epoch20, step1775]: loss 10.505987
[epoch20, step1776]: loss 1.071515
[epoch20, step1777]: loss 8.146512
[epoch20, step1778]: loss 0.451523
[epoch20, step1779]: loss 1.961141
[epoch20, step1780]: loss 5.160193
[epoch20, step1781]: loss 1.691438
[epoch20, step1782]: loss 6.835331
[epoch20, step1783]: loss 5.896774
[epoch20, step1784]: loss 11.699801
[epoch20, step1785]: loss 0.835531
[epoch20, step1786]: loss 1.840421
[epoch20, step1787]: loss 0.695873
[epoch20, step1788]: loss 3.337293
[epoch20, step1789]: loss 4.860141
[epoch20, step1790]: loss 0.707347
[epoch20, step1791]: loss 1.036562
[epoch20, step1792]: loss 1.472341
[epoch20, step1793]: loss 13.599102
[epoch20, step1794]: loss 6.488529
[epoch20, step1795]: loss 1.934683
[epoch20, step1796]: loss 2.736758
[epoch20, step1797]: loss 0.624847
[epoch20, step1798]: loss 1.809636
[epoch20, step1799]: loss 0.731313
[epoch20, step1800]: loss 3.332397
[epoch20, step1801]: loss 0.893855
[epoch20, step1802]: loss 1.335018
[epoch20, step1803]: loss 0.670558
[epoch20, step1804]: loss 1.010897
[epoch20, step1805]: loss 0.563104
[epoch20, step1806]: loss 16.222132
[epoch20, step1807]: loss 0.600540
[epoch20, step1808]: loss 2.500706
[epoch20, step1809]: loss 5.917459
[epoch20, step1810]: loss 7.110113
[epoch20, step1811]: loss 0.960544
[epoch20, step1812]: loss 0.658281
[epoch20, step1813]: loss 1.921726
[epoch20, step1814]: loss 0.947999
[epoch20, step1815]: loss 0.537506
[epoch20, step1816]: loss 6.874493
[epoch20, step1817]: loss 8.055502
[epoch20, step1818]: loss 2.303334
[epoch20, step1819]: loss 6.849578
[epoch20, step1820]: loss 13.234062
[epoch20, step1821]: loss 0.992481
[epoch20, step1822]: loss 10.309033
[epoch20, step1823]: loss 6.551989
[epoch20, step1824]: loss 0.626168
[epoch20, step1825]: loss 0.632821
[epoch20, step1826]: loss 0.782029
[epoch20, step1827]: loss 8.272601
[epoch20, step1828]: loss 0.802016
[epoch20, step1829]: loss 1.642100
[epoch20, step1830]: loss 3.515008
[epoch20, step1831]: loss 11.308179
[epoch20, step1832]: loss 1.777492
[epoch20, step1833]: loss 4.597777
[epoch20, step1834]: loss 2.730125
[epoch20, step1835]: loss 1.455173
[epoch20, step1836]: loss 8.416506
[epoch20, step1837]: loss 1.118922
[epoch20, step1838]: loss 4.236874
[epoch20, step1839]: loss 8.306271
[epoch20, step1840]: loss 1.116480
[epoch20, step1841]: loss 1.833533
[epoch20, step1842]: loss 0.450873
[epoch20, step1843]: loss 4.266264
[epoch20, step1844]: loss 5.285594
[epoch20, step1845]: loss 1.159453
[epoch20, step1846]: loss 0.830388
[epoch20, step1847]: loss 0.592923
[epoch20, step1848]: loss 0.619957
[epoch20, step1849]: loss 2.082742
[epoch20, step1850]: loss 0.583682
[epoch20, step1851]: loss 11.738245
[epoch20, step1852]: loss 1.225151
[epoch20, step1853]: loss 8.809116
[epoch20, step1854]: loss 2.237046
[epoch20, step1855]: loss 1.042445
[epoch20, step1856]: loss 4.533241
[epoch20, step1857]: loss 0.441661
[epoch20, step1858]: loss 6.659525
[epoch20, step1859]: loss 1.061791
[epoch20, step1860]: loss 13.112112
[epoch20, step1861]: loss 0.684726
[epoch20, step1862]: loss 1.038322
[epoch20, step1863]: loss 5.204016
[epoch20, step1864]: loss 2.501917
[epoch20, step1865]: loss 0.577693
[epoch20, step1866]: loss 0.715971
[epoch20, step1867]: loss 1.297018
[epoch20, step1868]: loss 1.104204
[epoch20, step1869]: loss 2.103594
[epoch20, step1870]: loss 8.045251
[epoch20, step1871]: loss 2.230906
[epoch20, step1872]: loss 6.700689
[epoch20, step1873]: loss 7.035040
[epoch20, step1874]: loss 0.591564
[epoch20, step1875]: loss 1.399334
[epoch20, step1876]: loss 8.999579
[epoch20, step1877]: loss 1.171749
[epoch20, step1878]: loss 7.007075
[epoch20, step1879]: loss 0.345962
[epoch20, step1880]: loss 0.460893
[epoch20, step1881]: loss 1.122196
[epoch20, step1882]: loss 0.884015
[epoch20, step1883]: loss 1.114289
[epoch20, step1884]: loss 5.621817
[epoch20, step1885]: loss 5.338864
[epoch20, step1886]: loss 2.457779
[epoch20, step1887]: loss 0.930208
[epoch20, step1888]: loss 1.256165
[epoch20, step1889]: loss 0.537320
[epoch20, step1890]: loss 5.125838
[epoch20, step1891]: loss 2.656085
[epoch20, step1892]: loss 4.244530
[epoch20, step1893]: loss 11.510421
[epoch20, step1894]: loss 1.115498
[epoch20, step1895]: loss 0.685804
[epoch20, step1896]: loss 6.127011
[epoch20, step1897]: loss 0.506889
[epoch20, step1898]: loss 0.540294
[epoch20, step1899]: loss 0.564980
[epoch20, step1900]: loss 4.842102
[epoch20, step1901]: loss 0.868666
[epoch20, step1902]: loss 1.094744
[epoch20, step1903]: loss 6.408753
[epoch20, step1904]: loss 9.958337
[epoch20, step1905]: loss 0.665448
[epoch20, step1906]: loss 2.446496
[epoch20, step1907]: loss 8.378430
[epoch20, step1908]: loss 4.982936
[epoch20, step1909]: loss 1.966390
[epoch20, step1910]: loss 9.744969
[epoch20, step1911]: loss 0.923840
[epoch20, step1912]: loss 0.904427
[epoch20, step1913]: loss 5.907287
[epoch20, step1914]: loss 0.500171
[epoch20, step1915]: loss 7.272761
[epoch20, step1916]: loss 1.516916
[epoch20, step1917]: loss 12.048956
[epoch20, step1918]: loss 8.417269
[epoch20, step1919]: loss 4.643815
[epoch20, step1920]: loss 1.194416
[epoch20, step1921]: loss 0.650616
[epoch20, step1922]: loss 0.576594
[epoch20, step1923]: loss 0.693061
[epoch20, step1924]: loss 1.378957
[epoch20, step1925]: loss 4.673697
[epoch20, step1926]: loss 1.071761
[epoch20, step1927]: loss 10.142363
[epoch20, step1928]: loss 10.411462
[epoch20, step1929]: loss 10.660210
[epoch20, step1930]: loss 3.132652
[epoch20, step1931]: loss 0.651285
[epoch20, step1932]: loss 1.061904
[epoch20, step1933]: loss 13.542133
[epoch20, step1934]: loss 1.602626
[epoch20, step1935]: loss 1.739231
[epoch20, step1936]: loss 5.845809
[epoch20, step1937]: loss 0.856780
[epoch20, step1938]: loss 4.165761
[epoch20, step1939]: loss 1.684786
[epoch20, step1940]: loss 5.647147
[epoch20, step1941]: loss 2.037089
[epoch20, step1942]: loss 1.564946
[epoch20, step1943]: loss 0.910895
[epoch20, step1944]: loss 0.444302
[epoch20, step1945]: loss 2.659119
[epoch20, step1946]: loss 1.119694
[epoch20, step1947]: loss 4.138172
[epoch20, step1948]: loss 0.966298
[epoch20, step1949]: loss 0.773492
[epoch20, step1950]: loss 6.414156
[epoch20, step1951]: loss 0.647800
[epoch20, step1952]: loss 0.620305
[epoch20, step1953]: loss 8.717978
[epoch20, step1954]: loss 5.444738
[epoch20, step1955]: loss 0.749637
[epoch20, step1956]: loss 1.361712
[epoch20, step1957]: loss 0.548638
[epoch20, step1958]: loss 6.991971
[epoch20, step1959]: loss 5.825168
[epoch20, step1960]: loss 0.470118
[epoch20, step1961]: loss 0.779844
[epoch20, step1962]: loss 0.525652
[epoch20, step1963]: loss 0.880810
[epoch20, step1964]: loss 5.689933
[epoch20, step1965]: loss 0.551465
[epoch20, step1966]: loss 11.613977
[epoch20, step1967]: loss 0.620947
[epoch20, step1968]: loss 7.085732
[epoch20, step1969]: loss 0.443204
[epoch20, step1970]: loss 0.738397
[epoch20, step1971]: loss 8.070346
[epoch20, step1972]: loss 7.526313
[epoch20, step1973]: loss 0.858120
[epoch20, step1974]: loss 0.783444
[epoch20, step1975]: loss 8.053919
[epoch20, step1976]: loss 5.525206
[epoch20, step1977]: loss 1.173972
[epoch20, step1978]: loss 1.374451
[epoch20, step1979]: loss 0.936932
[epoch20, step1980]: loss 0.749968
[epoch20, step1981]: loss 7.967004
[epoch20, step1982]: loss 0.568824
[epoch20, step1983]: loss 12.397457
[epoch20, step1984]: loss 13.268682
[epoch20, step1985]: loss 1.359884
[epoch20, step1986]: loss 4.938085
[epoch20, step1987]: loss 4.287461
[epoch20, step1988]: loss 0.804681
[epoch20, step1989]: loss 0.755807
[epoch20, step1990]: loss 0.977768
[epoch20, step1991]: loss 0.807849
[epoch20, step1992]: loss 1.686490
[epoch20, step1993]: loss 5.186350
[epoch20, step1994]: loss 8.429196
[epoch20, step1995]: loss 1.379799
[epoch20, step1996]: loss 0.878127
[epoch20, step1997]: loss 3.137098
[epoch20, step1998]: loss 0.732970
[epoch20, step1999]: loss 2.264574
[epoch20, step2000]: loss 6.841490
[epoch20, step2001]: loss 0.543452
[epoch20, step2002]: loss 1.237884
[epoch20, step2003]: loss 0.671480
[epoch20, step2004]: loss 1.189992
[epoch20, step2005]: loss 0.771274
[epoch20, step2006]: loss 4.434906
[epoch20, step2007]: loss 4.670700
[epoch20, step2008]: loss 1.378816
[epoch20, step2009]: loss 3.325917
[epoch20, step2010]: loss 2.101891
[epoch20, step2011]: loss 2.072195
[epoch20, step2012]: loss 7.534199
[epoch20, step2013]: loss 1.592534
[epoch20, step2014]: loss 10.255630
[epoch20, step2015]: loss 0.399724
[epoch20, step2016]: loss 0.895142
[epoch20, step2017]: loss 1.180258
[epoch20, step2018]: loss 8.081347
[epoch20, step2019]: loss 0.568283
[epoch20, step2020]: loss 1.020828
[epoch20, step2021]: loss 0.767310
[epoch20, step2022]: loss 2.604870
[epoch20, step2023]: loss 1.123194
[epoch20, step2024]: loss 0.558721
[epoch20, step2025]: loss 9.638169
[epoch20, step2026]: loss 5.476244
[epoch20, step2027]: loss 0.546325
[epoch20, step2028]: loss 0.580702
[epoch20, step2029]: loss 0.467729
[epoch20, step2030]: loss 1.214338
[epoch20, step2031]: loss 7.256881
[epoch20, step2032]: loss 12.135086
[epoch20, step2033]: loss 0.471218
[epoch20, step2034]: loss 1.360229
[epoch20, step2035]: loss 10.191169
[epoch20, step2036]: loss 3.448164
[epoch20, step2037]: loss 0.910296
[epoch20, step2038]: loss 1.939729
[epoch20, step2039]: loss 0.910503
[epoch20, step2040]: loss 1.109333
[epoch20, step2041]: loss 0.919320
[epoch20, step2042]: loss 1.401496
[epoch20, step2043]: loss 1.104139
[epoch20, step2044]: loss 7.390322
[epoch20, step2045]: loss 0.854058
[epoch20, step2046]: loss 0.707903
[epoch20, step2047]: loss 2.422813
[epoch20, step2048]: loss 7.721836
[epoch20, step2049]: loss 1.368031
[epoch20, step2050]: loss 0.439874
[epoch20, step2051]: loss 2.940845
[epoch20, step2052]: loss 0.722176
[epoch20, step2053]: loss 1.076436
[epoch20, step2054]: loss 0.469837
[epoch20, step2055]: loss 0.583731
[epoch20, step2056]: loss 0.644769
[epoch20, step2057]: loss 0.723689
[epoch20, step2058]: loss 11.869310
[epoch20, step2059]: loss 8.838722
[epoch20, step2060]: loss 2.675059
[epoch20, step2061]: loss 5.546221
[epoch20, step2062]: loss 5.228548
[epoch20, step2063]: loss 0.975875
[epoch20, step2064]: loss 8.964816
[epoch20, step2065]: loss 1.681661
[epoch20, step2066]: loss 0.522977
[epoch20, step2067]: loss 3.157884
[epoch20, step2068]: loss 1.311139
[epoch20, step2069]: loss 4.810413
[epoch20, step2070]: loss 0.468481
[epoch20, step2071]: loss 0.688778
[epoch20, step2072]: loss 11.299565
[epoch20, step2073]: loss 1.073042
[epoch20, step2074]: loss 0.637298
[epoch20, step2075]: loss 0.810194
[epoch20, step2076]: loss 2.183404
[epoch20, step2077]: loss 0.585863
[epoch20, step2078]: loss 6.712704
[epoch20, step2079]: loss 0.485902
[epoch20, step2080]: loss 1.204797
[epoch20, step2081]: loss 10.702915
[epoch20, step2082]: loss 6.594171
[epoch20, step2083]: loss 2.230518
[epoch20, step2084]: loss 1.269769
[epoch20, step2085]: loss 7.487208
[epoch20, step2086]: loss 6.217071
[epoch20, step2087]: loss 1.942649
[epoch20, step2088]: loss 2.252923
[epoch20, step2089]: loss 1.220047
[epoch20, step2090]: loss 6.935495
[epoch20, step2091]: loss 2.153030
[epoch20, step2092]: loss 0.653787
[epoch20, step2093]: loss 0.912372
[epoch20, step2094]: loss 21.033895
[epoch20, step2095]: loss 0.979235
[epoch20, step2096]: loss 1.171579
[epoch20, step2097]: loss 2.560256
[epoch20, step2098]: loss 1.957003
[epoch20, step2099]: loss 2.549518
[epoch20, step2100]: loss 1.354135
[epoch20, step2101]: loss 2.172315
[epoch20, step2102]: loss 1.343326
[epoch20, step2103]: loss 11.016648
[epoch20, step2104]: loss 5.671304
[epoch20, step2105]: loss 1.961269
[epoch20, step2106]: loss 5.630265
[epoch20, step2107]: loss 0.658756
[epoch20, step2108]: loss 10.246659
[epoch20, step2109]: loss 8.384494
[epoch20, step2110]: loss 9.664127
[epoch20, step2111]: loss 1.804033
[epoch20, step2112]: loss 1.540362
[epoch20, step2113]: loss 9.858123
[epoch20, step2114]: loss 0.881532
[epoch20, step2115]: loss 12.262384
[epoch20, step2116]: loss 0.731596
[epoch20, step2117]: loss 14.773136
[epoch20, step2118]: loss 5.138941
[epoch20, step2119]: loss 12.279187
[epoch20, step2120]: loss 8.651582
[epoch20, step2121]: loss 1.133994
[epoch20, step2122]: loss 0.548754
[epoch20, step2123]: loss 0.938355
[epoch20, step2124]: loss 5.821715
[epoch20, step2125]: loss 4.289210
[epoch20, step2126]: loss 0.686929
[epoch20, step2127]: loss 1.056539
[epoch20, step2128]: loss 2.630651
[epoch20, step2129]: loss 6.098580
[epoch20, step2130]: loss 1.540585
[epoch20, step2131]: loss 6.417732
[epoch20, step2132]: loss 4.193188
[epoch20, step2133]: loss 5.639947
[epoch20, step2134]: loss 6.910520
[epoch20, step2135]: loss 1.414634
[epoch20, step2136]: loss 0.712435
[epoch20, step2137]: loss 1.320944
[epoch20, step2138]: loss 5.108077
[epoch20, step2139]: loss 0.877710
[epoch20, step2140]: loss 6.244583
[epoch20, step2141]: loss 0.430683
[epoch20, step2142]: loss 1.369389
[epoch20, step2143]: loss 0.629068
[epoch20, step2144]: loss 5.964637
[epoch20, step2145]: loss 1.360869
[epoch20, step2146]: loss 1.335175
[epoch20, step2147]: loss 0.989816
[epoch20, step2148]: loss 1.688411
[epoch20, step2149]: loss 1.487596
[epoch20, step2150]: loss 1.531963
[epoch20, step2151]: loss 1.314515
[epoch20, step2152]: loss 2.562126
[epoch20, step2153]: loss 8.780214
[epoch20, step2154]: loss 2.346119
[epoch20, step2155]: loss 1.575805
[epoch20, step2156]: loss 3.345116
[epoch20, step2157]: loss 0.700578
[epoch20, step2158]: loss 1.924721
[epoch20, step2159]: loss 0.636652
[epoch20, step2160]: loss 0.741535
[epoch20, step2161]: loss 1.970273
[epoch20, step2162]: loss 0.414253
[epoch20, step2163]: loss 0.705848
[epoch20, step2164]: loss 1.262739
[epoch20, step2165]: loss 0.814114
[epoch20, step2166]: loss 1.516355
[epoch20, step2167]: loss 0.729273
[epoch20, step2168]: loss 8.913162
[epoch20, step2169]: loss 8.099280
[epoch20, step2170]: loss 5.360328
[epoch20, step2171]: loss 9.547832
[epoch20, step2172]: loss 5.488203
[epoch20, step2173]: loss 1.368742
[epoch20, step2174]: loss 4.348702
[epoch20, step2175]: loss 12.743736
[epoch20, step2176]: loss 2.948993
[epoch20, step2177]: loss 8.023855
[epoch20, step2178]: loss 6.668251
[epoch20, step2179]: loss 1.073667
[epoch20, step2180]: loss 1.435466
[epoch20, step2181]: loss 0.611911
[epoch20, step2182]: loss 4.724516
[epoch20, step2183]: loss 0.808312
[epoch20, step2184]: loss 1.089925
[epoch20, step2185]: loss 0.376836
[epoch20, step2186]: loss 9.503250
[epoch20, step2187]: loss 1.074054
[epoch20, step2188]: loss 4.282895
[epoch20, step2189]: loss 0.551493
[epoch20, step2190]: loss 0.911849
[epoch20, step2191]: loss 5.823090
[epoch20, step2192]: loss 2.425227
[epoch20, step2193]: loss 0.470247
[epoch20, step2194]: loss 0.725666
[epoch20, step2195]: loss 6.531183
[epoch20, step2196]: loss 1.872961
[epoch20, step2197]: loss 1.730997
[epoch20, step2198]: loss 0.923357
[epoch20, step2199]: loss 0.939185
[epoch20, step2200]: loss 0.605816
[epoch20, step2201]: loss 0.952369
[epoch20, step2202]: loss 0.658990
[epoch20, step2203]: loss 1.264797
[epoch20, step2204]: loss 1.799907
[epoch20, step2205]: loss 5.051382
[epoch20, step2206]: loss 9.850383
[epoch20, step2207]: loss 1.479908
[epoch20, step2208]: loss 0.624636
[epoch20, step2209]: loss 13.164427
[epoch20, step2210]: loss 9.562271
[epoch20, step2211]: loss 5.458955
[epoch20, step2212]: loss 6.604007
[epoch20, step2213]: loss 1.635077
[epoch20, step2214]: loss 0.547329
[epoch20, step2215]: loss 5.353762
[epoch20, step2216]: loss 0.571687
[epoch20, step2217]: loss 1.038667
[epoch20, step2218]: loss 0.836341
[epoch20, step2219]: loss 6.649917
[epoch20, step2220]: loss 1.480434
[epoch20, step2221]: loss 1.012041
[epoch20, step2222]: loss 0.665558
[epoch20, step2223]: loss 0.555185
[epoch20, step2224]: loss 1.877137
[epoch20, step2225]: loss 0.550965
[epoch20, step2226]: loss 12.684449
[epoch20, step2227]: loss 0.449001
[epoch20, step2228]: loss 0.906968
[epoch20, step2229]: loss 1.784411
[epoch20, step2230]: loss 0.492884
[epoch20, step2231]: loss 3.488129
[epoch20, step2232]: loss 4.329166
[epoch20, step2233]: loss 5.223501
[epoch20, step2234]: loss 3.078442
[epoch20, step2235]: loss 1.337319
[epoch20, step2236]: loss 1.004577
[epoch20, step2237]: loss 1.155988
[epoch20, step2238]: loss 0.677719
[epoch20, step2239]: loss 5.535721
[epoch20, step2240]: loss 1.893167
[epoch20, step2241]: loss 0.801532
[epoch20, step2242]: loss 0.664180
[epoch20, step2243]: loss 0.455348
[epoch20, step2244]: loss 1.076483
[epoch20, step2245]: loss 7.235811
[epoch20, step2246]: loss 10.074868
[epoch20, step2247]: loss 0.577387
[epoch20, step2248]: loss 4.798798
[epoch20, step2249]: loss 0.549021
[epoch20, step2250]: loss 5.814661
[epoch20, step2251]: loss 0.592128
[epoch20, step2252]: loss 0.912058
[epoch20, step2253]: loss 0.549157
[epoch20, step2254]: loss 0.543843
[epoch20, step2255]: loss 9.096138
[epoch20, step2256]: loss 1.578880
[epoch20, step2257]: loss 1.898712
[epoch20, step2258]: loss 0.640022
[epoch20, step2259]: loss 6.278519
[epoch20, step2260]: loss 9.545734
[epoch20, step2261]: loss 0.555568
[epoch20, step2262]: loss 13.691822
[epoch20, step2263]: loss 1.279128
[epoch20, step2264]: loss 0.489985
[epoch20, step2265]: loss 1.095482
[epoch20, step2266]: loss 1.744832
[epoch20, step2267]: loss 0.654212
[epoch20, step2268]: loss 1.541471
[epoch20, step2269]: loss 17.775719
[epoch20, step2270]: loss 0.733709
[epoch20, step2271]: loss 0.939641
[epoch20, step2272]: loss 8.360121
[epoch20, step2273]: loss 4.745106
[epoch20, step2274]: loss 17.837278
[epoch20, step2275]: loss 1.845557
[epoch20, step2276]: loss 2.231745
[epoch20, step2277]: loss 0.700276
[epoch20, step2278]: loss 5.780554
[epoch20, step2279]: loss 2.362611
[epoch20, step2280]: loss 0.794308
[epoch20, step2281]: loss 6.404131
[epoch20, step2282]: loss 5.597632
[epoch20, step2283]: loss 6.377974
[epoch20, step2284]: loss 1.486694
[epoch20, step2285]: loss 1.567651
[epoch20, step2286]: loss 2.091463
[epoch20, step2287]: loss 10.615728
[epoch20, step2288]: loss 1.109955
[epoch20, step2289]: loss 2.798570
[epoch20, step2290]: loss 0.697188
[epoch20, step2291]: loss 0.676389
[epoch20, step2292]: loss 12.959124
[epoch20, step2293]: loss 1.086966
[epoch20, step2294]: loss 0.521713
[epoch20, step2295]: loss 2.776338
[epoch20, step2296]: loss 0.793885
[epoch20, step2297]: loss 0.537544
[epoch20, step2298]: loss 2.116228
[epoch20, step2299]: loss 4.811519
[epoch20, step2300]: loss 0.506591
[epoch20, step2301]: loss 1.218383
[epoch20, step2302]: loss 7.910965
[epoch20, step2303]: loss 0.484998
[epoch20, step2304]: loss 16.315355
[epoch20, step2305]: loss 1.555405
[epoch20, step2306]: loss 2.101044
[epoch20, step2307]: loss 0.604223
[epoch20, step2308]: loss 5.865977
[epoch20, step2309]: loss 6.081674
[epoch20, step2310]: loss 10.579727
[epoch20, step2311]: loss 0.736557
[epoch20, step2312]: loss 10.029429
[epoch20, step2313]: loss 3.385668
[epoch20, step2314]: loss 5.152207
[epoch20, step2315]: loss 1.667609
[epoch20, step2316]: loss 10.402995
[epoch20, step2317]: loss 0.817739
[epoch20, step2318]: loss 0.852836
[epoch20, step2319]: loss 0.822611
[epoch20, step2320]: loss 5.844569
[epoch20, step2321]: loss 2.723751
[epoch20, step2322]: loss 0.567144
[epoch20, step2323]: loss 4.225737
[epoch20, step2324]: loss 1.698188
[epoch20, step2325]: loss 1.391753
[epoch20, step2326]: loss 1.110079
[epoch20, step2327]: loss 5.808123
[epoch20, step2328]: loss 0.696250
[epoch20, step2329]: loss 0.733378
[epoch20, step2330]: loss 1.519435
[epoch20, step2331]: loss 2.765562
[epoch20, step2332]: loss 1.105388
[epoch20, step2333]: loss 0.412854
[epoch20, step2334]: loss 7.301183
[epoch20, step2335]: loss 12.260959
[epoch20, step2336]: loss 2.092276
[epoch20, step2337]: loss 11.965096
[epoch20, step2338]: loss 1.401065
[epoch20, step2339]: loss 10.371741
[epoch20, step2340]: loss 8.113442
[epoch20, step2341]: loss 1.410491
[epoch20, step2342]: loss 0.875851
[epoch20, step2343]: loss 2.439380
[epoch20, step2344]: loss 1.667200
[epoch20, step2345]: loss 1.851929
[epoch20, step2346]: loss 12.469392
[epoch20, step2347]: loss 0.687998
[epoch20, step2348]: loss 1.564530
[epoch20, step2349]: loss 1.444666
[epoch20, step2350]: loss 2.146596
[epoch20, step2351]: loss 6.818622
[epoch20, step2352]: loss 1.125262
[epoch20, step2353]: loss 0.905028
[epoch20, step2354]: loss 2.093793
[epoch20, step2355]: loss 2.468315
[epoch20, step2356]: loss 0.604261
[epoch20, step2357]: loss 1.050900
[epoch20, step2358]: loss 4.602737
[epoch20, step2359]: loss 16.242100
[epoch20, step2360]: loss 3.099699
[epoch20, step2361]: loss 2.691282
[epoch20, step2362]: loss 3.322322
[epoch20, step2363]: loss 0.755795
[epoch20, step2364]: loss 2.984232
[epoch20, step2365]: loss 9.147206
[epoch20, step2366]: loss 1.018568
[epoch20, step2367]: loss 1.182959
[epoch20, step2368]: loss 17.652529
[epoch20, step2369]: loss 0.944546
[epoch20, step2370]: loss 4.516550
[epoch20, step2371]: loss 1.803809
[epoch20, step2372]: loss 1.224730
[epoch20, step2373]: loss 6.485716
[epoch20, step2374]: loss 13.647362
[epoch20, step2375]: loss 0.589388
[epoch20, step2376]: loss 0.990895
[epoch20, step2377]: loss 6.001296
[epoch20, step2378]: loss 1.282094
[epoch20, step2379]: loss 1.068872
[epoch20, step2380]: loss 0.992631
[epoch20, step2381]: loss 0.680417
[epoch20, step2382]: loss 2.633611
[epoch20, step2383]: loss 6.596515
[epoch20, step2384]: loss 5.282157
[epoch20, step2385]: loss 8.485895
[epoch20, step2386]: loss 1.396507
[epoch20, step2387]: loss 0.728475
[epoch20, step2388]: loss 1.885308
[epoch20, step2389]: loss 0.593064
[epoch20, step2390]: loss 0.565136
[epoch20, step2391]: loss 1.780370
[epoch20, step2392]: loss 0.829154
[epoch20, step2393]: loss 1.451187
[epoch20, step2394]: loss 12.504337
[epoch20, step2395]: loss 0.559641
[epoch20, step2396]: loss 2.861665
[epoch20, step2397]: loss 1.095624
[epoch20, step2398]: loss 13.979743
[epoch20, step2399]: loss 6.977945
[epoch20, step2400]: loss 6.138688
[epoch20, step2401]: loss 3.520803
[epoch20, step2402]: loss 0.691154
[epoch20, step2403]: loss 1.019941
[epoch20, step2404]: loss 20.968052
[epoch20, step2405]: loss 0.927461
[epoch20, step2406]: loss 2.360898
[epoch20, step2407]: loss 0.841623
[epoch20, step2408]: loss 0.615245
[epoch20, step2409]: loss 0.806893
[epoch20, step2410]: loss 1.953149
[epoch20, step2411]: loss 0.439641
[epoch20, step2412]: loss 4.697278
[epoch20, step2413]: loss 14.410078
[epoch20, step2414]: loss 2.894866
[epoch20, step2415]: loss 2.104149
[epoch20, step2416]: loss 0.674133
[epoch20, step2417]: loss 1.227806
[epoch20, step2418]: loss 5.092084
[epoch20, step2419]: loss 0.489232
[epoch20, step2420]: loss 1.958510
[epoch20, step2421]: loss 2.263544
[epoch20, step2422]: loss 0.891414
[epoch20, step2423]: loss 0.883314
[epoch20, step2424]: loss 4.604658
[epoch20, step2425]: loss 0.453088
[epoch20, step2426]: loss 15.610470
[epoch20, step2427]: loss 0.559197
[epoch20, step2428]: loss 0.639371
[epoch20, step2429]: loss 1.913544
[epoch20, step2430]: loss 0.595798
[epoch20, step2431]: loss 8.840686
[epoch20, step2432]: loss 12.592326
[epoch20, step2433]: loss 1.046741
[epoch20, step2434]: loss 0.648815
[epoch20, step2435]: loss 0.865438
[epoch20, step2436]: loss 1.329010
[epoch20, step2437]: loss 2.901732
[epoch20, step2438]: loss 1.648288
[epoch20, step2439]: loss 1.048069
[epoch20, step2440]: loss 9.030916
[epoch20, step2441]: loss 1.021885
[epoch20, step2442]: loss 7.033729
[epoch20, step2443]: loss 0.617761
[epoch20, step2444]: loss 0.852746
[epoch20, step2445]: loss 0.704091
[epoch20, step2446]: loss 1.849678
[epoch20, step2447]: loss 0.462969
[epoch20, step2448]: loss 5.294521
[epoch20, step2449]: loss 5.376407
[epoch20, step2450]: loss 0.629097
[epoch20, step2451]: loss 0.679880
[epoch20, step2452]: loss 3.822784
[epoch20, step2453]: loss 8.761498
[epoch20, step2454]: loss 1.900154
[epoch20, step2455]: loss 1.472853
[epoch20, step2456]: loss 0.743110
[epoch20, step2457]: loss 0.663937
[epoch20, step2458]: loss 1.513871
[epoch20, step2459]: loss 0.541118
[epoch20, step2460]: loss 1.490247
[epoch20, step2461]: loss 0.510006
[epoch20, step2462]: loss 1.569556
[epoch20, step2463]: loss 2.196224
[epoch20, step2464]: loss 0.384522
[epoch20, step2465]: loss 0.379255
[epoch20, step2466]: loss 0.565054
[epoch20, step2467]: loss 1.440708
[epoch20, step2468]: loss 0.592231
[epoch20, step2469]: loss 1.449286
[epoch20, step2470]: loss 1.309099
[epoch20, step2471]: loss 1.024480
[epoch20, step2472]: loss 0.607717
[epoch20, step2473]: loss 2.821950
[epoch20, step2474]: loss 1.103452
[epoch20, step2475]: loss 0.700276
[epoch20, step2476]: loss 7.974283
[epoch20, step2477]: loss 13.661800
[epoch20, step2478]: loss 8.524069
[epoch20, step2479]: loss 1.985381
[epoch20, step2480]: loss 2.084409
[epoch20, step2481]: loss 0.925310
[epoch20, step2482]: loss 12.452949
[epoch20, step2483]: loss 9.329650
[epoch20, step2484]: loss 0.602350
[epoch20, step2485]: loss 2.154367
[epoch20, step2486]: loss 11.257005
[epoch20, step2487]: loss 0.553974
[epoch20, step2488]: loss 3.386835
[epoch20, step2489]: loss 1.057382
[epoch20, step2490]: loss 8.466071
[epoch20, step2491]: loss 0.959396
[epoch20, step2492]: loss 0.773643
[epoch20, step2493]: loss 1.229451
[epoch20, step2494]: loss 1.465977
[epoch20, step2495]: loss 2.779048
[epoch20, step2496]: loss 1.492996
[epoch20, step2497]: loss 0.776884
[epoch20, step2498]: loss 0.891430
[epoch20, step2499]: loss 3.399521
[epoch20, step2500]: loss 1.133372
[epoch20, step2501]: loss 0.641172
[epoch20, step2502]: loss 5.151994
[epoch20, step2503]: loss 0.645570
[epoch20, step2504]: loss 0.830078
[epoch20, step2505]: loss 0.607522
[epoch20, step2506]: loss 10.499369
[epoch20, step2507]: loss 0.990028
[epoch20, step2508]: loss 10.700584
[epoch20, step2509]: loss 0.714130
[epoch20, step2510]: loss 0.391353
[epoch20, step2511]: loss 1.896763
[epoch20, step2512]: loss 0.491416
[epoch20, step2513]: loss 1.253792
[epoch20, step2514]: loss 2.711860
[epoch20, step2515]: loss 0.884503
[epoch20, step2516]: loss 0.591641
[epoch20, step2517]: loss 0.990194
[epoch20, step2518]: loss 0.904322
[epoch20, step2519]: loss 0.554429
[epoch20, step2520]: loss 2.044343
[epoch20, step2521]: loss 0.852794
[epoch20, step2522]: loss 1.505379
[epoch20, step2523]: loss 2.827553
[epoch20, step2524]: loss 0.632175
[epoch20, step2525]: loss 0.946529
[epoch20, step2526]: loss 1.447074
[epoch20, step2527]: loss 5.538095
[epoch20, step2528]: loss 1.318840
[epoch20, step2529]: loss 2.435211
[epoch20, step2530]: loss 4.453324
[epoch20, step2531]: loss 2.338197
[epoch20, step2532]: loss 1.477767
[epoch20, step2533]: loss 10.116139
[epoch20, step2534]: loss 3.637188
[epoch20, step2535]: loss 6.377339
[epoch20, step2536]: loss 2.211499
[epoch20, step2537]: loss 0.448102
[epoch20, step2538]: loss 1.024326
[epoch20, step2539]: loss 1.873763
[epoch20, step2540]: loss 2.286660
[epoch20, step2541]: loss 0.929398
[epoch20, step2542]: loss 0.750017
[epoch20, step2543]: loss 10.827910
[epoch20, step2544]: loss 24.760605
[epoch20, step2545]: loss 1.593133
[epoch20, step2546]: loss 5.812647
[epoch20, step2547]: loss 3.538251
[epoch20, step2548]: loss 0.854377
[epoch20, step2549]: loss 1.499550
[epoch20, step2550]: loss 0.847703
[epoch20, step2551]: loss 0.518927
[epoch20, step2552]: loss 0.916237
[epoch20, step2553]: loss 1.512455
[epoch20, step2554]: loss 1.760526
[epoch20, step2555]: loss 3.333653
[epoch20, step2556]: loss 4.205871
[epoch20, step2557]: loss 0.490636
[epoch20, step2558]: loss 6.607115
[epoch20, step2559]: loss 10.597164
[epoch20, step2560]: loss 1.259205
[epoch20, step2561]: loss 8.901999
[epoch20, step2562]: loss 12.066644
[epoch20, step2563]: loss 1.136316
[epoch20, step2564]: loss 1.864451
[epoch20, step2565]: loss 1.831840
[epoch20, step2566]: loss 0.763446
[epoch20, step2567]: loss 1.853464
[epoch20, step2568]: loss 2.563966
[epoch20, step2569]: loss 3.925991
[epoch20, step2570]: loss 0.872504
[epoch20, step2571]: loss 0.940089
[epoch20, step2572]: loss 1.347686
[epoch20, step2573]: loss 0.819186
[epoch20, step2574]: loss 0.642719
[epoch20, step2575]: loss 1.963098
[epoch20, step2576]: loss 1.443351
[epoch20, step2577]: loss 2.074954
[epoch20, step2578]: loss 3.155705
[epoch20, step2579]: loss 3.041192
[epoch20, step2580]: loss 11.826794
[epoch20, step2581]: loss 2.349041
[epoch20, step2582]: loss 3.460590
[epoch20, step2583]: loss 1.165584
[epoch20, step2584]: loss 1.800488
[epoch20, step2585]: loss 5.089328
[epoch20, step2586]: loss 4.714322
[epoch20, step2587]: loss 0.856045
[epoch20, step2588]: loss 0.645639
[epoch20, step2589]: loss 12.200687
[epoch20, step2590]: loss 0.791319
[epoch20, step2591]: loss 12.816221
[epoch20, step2592]: loss 2.169346
[epoch20, step2593]: loss 1.572194
[epoch20, step2594]: loss 0.898844
[epoch20, step2595]: loss 1.139270
[epoch20, step2596]: loss 1.070042
[epoch20, step2597]: loss 2.337412
[epoch20, step2598]: loss 4.737238
[epoch20, step2599]: loss 1.949244
[epoch20, step2600]: loss 8.750506
[epoch20, step2601]: loss 2.034952
[epoch20, step2602]: loss 2.017453
[epoch20, step2603]: loss 0.599820
[epoch20, step2604]: loss 4.026198
[epoch20, step2605]: loss 4.779172
[epoch20, step2606]: loss 1.360076
[epoch20, step2607]: loss 0.498024
[epoch20, step2608]: loss 2.109771
[epoch20, step2609]: loss 0.800791
[epoch20, step2610]: loss 5.861400
[epoch20, step2611]: loss 4.445059
[epoch20, step2612]: loss 1.076018
[epoch20, step2613]: loss 0.591408
[epoch20, step2614]: loss 4.778313
[epoch20, step2615]: loss 1.833062
[epoch20, step2616]: loss 1.741251
[epoch20, step2617]: loss 1.371040
[epoch20, step2618]: loss 6.328610
[epoch20, step2619]: loss 1.058297
[epoch20, step2620]: loss 2.458196
[epoch20, step2621]: loss 0.843136
[epoch20, step2622]: loss 1.582858
[epoch20, step2623]: loss 4.216086
[epoch20, step2624]: loss 5.054182
[epoch20, step2625]: loss 0.471117
[epoch20, step2626]: loss 2.068497
[epoch20, step2627]: loss 1.472974
[epoch20, step2628]: loss 3.083669
[epoch20, step2629]: loss 1.009595
[epoch20, step2630]: loss 9.199460
[epoch20, step2631]: loss 1.057770
[epoch20, step2632]: loss 8.708221
[epoch20, step2633]: loss 6.875560
[epoch20, step2634]: loss 4.263754
[epoch20, step2635]: loss 0.467352
[epoch20, step2636]: loss 6.259879
[epoch20, step2637]: loss 11.633895
[epoch20, step2638]: loss 6.725156
[epoch20, step2639]: loss 0.972283
[epoch20, step2640]: loss 1.373851
[epoch20, step2641]: loss 1.089270
[epoch20, step2642]: loss 1.067884
[epoch20, step2643]: loss 2.133358
[epoch20, step2644]: loss 1.335957
[epoch20, step2645]: loss 1.331807
[epoch20, step2646]: loss 0.660348
[epoch20, step2647]: loss 0.779153
[epoch20, step2648]: loss 0.827830
[epoch20, step2649]: loss 0.378609
[epoch20, step2650]: loss 14.925863
[epoch20, step2651]: loss 0.537145
[epoch20, step2652]: loss 0.866356
[epoch20, step2653]: loss 0.323178
[epoch20, step2654]: loss 1.455372
[epoch20, step2655]: loss 3.557436
[epoch20, step2656]: loss 0.902034
[epoch20, step2657]: loss 2.194971
[epoch20, step2658]: loss 1.840133
[epoch20, step2659]: loss 0.973649
[epoch20, step2660]: loss 1.495638
[epoch20, step2661]: loss 2.525189
[epoch20, step2662]: loss 12.057998
[epoch20, step2663]: loss 2.055238
[epoch20, step2664]: loss 1.115127
[epoch20, step2665]: loss 4.450180
[epoch20, step2666]: loss 10.172125
[epoch20, step2667]: loss 9.148072
[epoch20, step2668]: loss 0.923880
[epoch20, step2669]: loss 1.208870
[epoch20, step2670]: loss 3.594359
[epoch20, step2671]: loss 1.962627
[epoch20, step2672]: loss 1.645808
[epoch20, step2673]: loss 8.712962
[epoch20, step2674]: loss 0.897113
[epoch20, step2675]: loss 1.658445
[epoch20, step2676]: loss 0.650831
[epoch20, step2677]: loss 0.402334
[epoch20, step2678]: loss 1.020628
[epoch20, step2679]: loss 4.069145
[epoch20, step2680]: loss 1.805887
[epoch20, step2681]: loss 1.089290
[epoch20, step2682]: loss 6.912465
[epoch20, step2683]: loss 1.716521
[epoch20, step2684]: loss 2.596532
[epoch20, step2685]: loss 9.099435
[epoch20, step2686]: loss 1.220672
[epoch20, step2687]: loss 10.003260
[epoch20, step2688]: loss 1.424639
[epoch20, step2689]: loss 11.652176
[epoch20, step2690]: loss 1.318232
[epoch20, step2691]: loss 2.590374
[epoch20, step2692]: loss 4.490503
[epoch20, step2693]: loss 1.979347
[epoch20, step2694]: loss 1.645568
[epoch20, step2695]: loss 2.261232
[epoch20, step2696]: loss 3.158864
[epoch20, step2697]: loss 5.029242
[epoch20, step2698]: loss 3.011932
[epoch20, step2699]: loss 7.001475
[epoch20, step2700]: loss 0.904269
[epoch20, step2701]: loss 1.894957
[epoch20, step2702]: loss 2.717708
[epoch20, step2703]: loss 1.110665
[epoch20, step2704]: loss 7.016820
[epoch20, step2705]: loss 1.109242
[epoch20, step2706]: loss 6.470566
[epoch20, step2707]: loss 13.232449
[epoch20, step2708]: loss 1.690049
[epoch20, step2709]: loss 5.418255
[epoch20, step2710]: loss 1.097842
[epoch20, step2711]: loss 0.734676
[epoch20, step2712]: loss 0.919566
[epoch20, step2713]: loss 1.203460
[epoch20, step2714]: loss 0.797721
[epoch20, step2715]: loss 0.640900
[epoch20, step2716]: loss 0.456840
[epoch20, step2717]: loss 13.903028
[epoch20, step2718]: loss 2.355290
[epoch20, step2719]: loss 8.278337
[epoch20, step2720]: loss 10.138793
[epoch20, step2721]: loss 8.716669
[epoch20, step2722]: loss 6.854734
[epoch20, step2723]: loss 1.461268
[epoch20, step2724]: loss 5.291821
[epoch20, step2725]: loss 1.294841
[epoch20, step2726]: loss 0.964126
[epoch20, step2727]: loss 1.573329
[epoch20, step2728]: loss 0.610003
[epoch20, step2729]: loss 2.594436
[epoch20, step2730]: loss 2.489445
[epoch20, step2731]: loss 7.131439
[epoch20, step2732]: loss 2.071825
[epoch20, step2733]: loss 0.425716
[epoch20, step2734]: loss 9.600104
[epoch20, step2735]: loss 5.159005
[epoch20, step2736]: loss 2.881393
[epoch20, step2737]: loss 3.068591
[epoch20, step2738]: loss 8.262030
[epoch20, step2739]: loss 5.511875
[epoch20, step2740]: loss 9.264103
[epoch20, step2741]: loss 1.526431
[epoch20, step2742]: loss 14.123633
[epoch20, step2743]: loss 8.895617
[epoch20, step2744]: loss 1.401801
[epoch20, step2745]: loss 1.660948
[epoch20, step2746]: loss 4.309305
[epoch20, step2747]: loss 8.707060
[epoch20, step2748]: loss 2.030225
[epoch20, step2749]: loss 0.753211
[epoch20, step2750]: loss 20.617813
[epoch20, step2751]: loss 6.493733
[epoch20, step2752]: loss 0.653966
[epoch20, step2753]: loss 0.575825
[epoch20, step2754]: loss 2.024776
[epoch20, step2755]: loss 11.672370
[epoch20, step2756]: loss 0.806040
[epoch20, step2757]: loss 0.912470
[epoch20, step2758]: loss 1.829911
[epoch20, step2759]: loss 5.622344
[epoch20, step2760]: loss 1.939550
[epoch20, step2761]: loss 1.057679
[epoch20, step2762]: loss 0.583950
[epoch20, step2763]: loss 2.085539
[epoch20, step2764]: loss 4.792884
[epoch20, step2765]: loss 0.758562
[epoch20, step2766]: loss 1.757396
[epoch20, step2767]: loss 1.887866
[epoch20, step2768]: loss 1.904822
[epoch20, step2769]: loss 8.699654
[epoch20, step2770]: loss 7.402945
[epoch20, step2771]: loss 2.690485
[epoch20, step2772]: loss 9.404967
[epoch20, step2773]: loss 1.976913
[epoch20, step2774]: loss 0.937666
[epoch20, step2775]: loss 1.364322
[epoch20, step2776]: loss 1.488680
[epoch20, step2777]: loss 0.885022
[epoch20, step2778]: loss 5.593037
[epoch20, step2779]: loss 0.681755
[epoch20, step2780]: loss 7.581514
[epoch20, step2781]: loss 0.889483
[epoch20, step2782]: loss 0.639888
[epoch20, step2783]: loss 2.679493
[epoch20, step2784]: loss 1.382547
[epoch20, step2785]: loss 1.684989
[epoch20, step2786]: loss 0.675921
[epoch20, step2787]: loss 6.621173
[epoch20, step2788]: loss 0.569957
[epoch20, step2789]: loss 0.915953
[epoch20, step2790]: loss 7.896998
[epoch20, step2791]: loss 0.539763
[epoch20, step2792]: loss 10.260336
[epoch20, step2793]: loss 0.504383
[epoch20, step2794]: loss 2.407545
[epoch20, step2795]: loss 26.024715
[epoch20, step2796]: loss 12.828173
[epoch20, step2797]: loss 3.245836
[epoch20, step2798]: loss 7.368110
[epoch20, step2799]: loss 0.910168
[epoch20, step2800]: loss 0.916266
[epoch20, step2801]: loss 1.965077
[epoch20, step2802]: loss 0.733048
[epoch20, step2803]: loss 2.635754
[epoch20, step2804]: loss 5.312054
[epoch20, step2805]: loss 2.417029
[epoch20, step2806]: loss 0.715453
[epoch20, step2807]: loss 0.943365
[epoch20, step2808]: loss 1.265506
[epoch20, step2809]: loss 1.342863
[epoch20, step2810]: loss 1.039706
[epoch20, step2811]: loss 0.778190
[epoch20, step2812]: loss 1.975564
[epoch20, step2813]: loss 10.855801
[epoch20, step2814]: loss 0.866743
[epoch20, step2815]: loss 1.007204
[epoch20, step2816]: loss 8.414395
[epoch20, step2817]: loss 1.509791
[epoch20, step2818]: loss 6.487941
[epoch20, step2819]: loss 0.671770
[epoch20, step2820]: loss 0.489103
[epoch20, step2821]: loss 1.728176
[epoch20, step2822]: loss 0.768102
[epoch20, step2823]: loss 0.583679
[epoch20, step2824]: loss 0.459463
[epoch20, step2825]: loss 0.929176
[epoch20, step2826]: loss 8.760821
[epoch20, step2827]: loss 15.582495
[epoch20, step2828]: loss 2.582075
[epoch20, step2829]: loss 1.117716
[epoch20, step2830]: loss 0.767958
[epoch20, step2831]: loss 3.147072
[epoch20, step2832]: loss 5.526731
[epoch20, step2833]: loss 1.477012
[epoch20, step2834]: loss 13.337016
[epoch20, step2835]: loss 1.423996
[epoch20, step2836]: loss 0.676592
[epoch20, step2837]: loss 2.876780
[epoch20, step2838]: loss 2.315646
[epoch20, step2839]: loss 11.139518
[epoch20, step2840]: loss 1.711477
[epoch20, step2841]: loss 8.239879
[epoch20, step2842]: loss 1.587555
[epoch20, step2843]: loss 5.169374
[epoch20, step2844]: loss 0.635461
[epoch20, step2845]: loss 1.007472
[epoch20, step2846]: loss 11.450083
[epoch20, step2847]: loss 4.175033
[epoch20, step2848]: loss 4.911071
[epoch20, step2849]: loss 1.940440
[epoch20, step2850]: loss 9.344906
[epoch20, step2851]: loss 1.163603
[epoch20, step2852]: loss 0.600357
[epoch20, step2853]: loss 0.667967
[epoch20, step2854]: loss 0.931612
[epoch20, step2855]: loss 0.422292
[epoch20, step2856]: loss 10.515648
[epoch20, step2857]: loss 1.941025
[epoch20, step2858]: loss 0.553178
[epoch20, step2859]: loss 1.273863
[epoch20, step2860]: loss 2.511663
[epoch20, step2861]: loss 0.986164
[epoch20, step2862]: loss 3.438807
[epoch20, step2863]: loss 1.421907
[epoch20, step2864]: loss 5.330422
[epoch20, step2865]: loss 0.693737
[epoch20, step2866]: loss 7.486264
[epoch20, step2867]: loss 1.759076
[epoch20, step2868]: loss 0.536579
[epoch20, step2869]: loss 5.408796
[epoch20, step2870]: loss 9.696404
[epoch20, step2871]: loss 13.593994
[epoch20, step2872]: loss 8.145663
[epoch20, step2873]: loss 8.780834
[epoch20, step2874]: loss 1.054875
[epoch20, step2875]: loss 2.260589
[epoch20, step2876]: loss 10.589517
[epoch20, step2877]: loss 0.554442
[epoch20, step2878]: loss 0.811093
[epoch20, step2879]: loss 0.524003
[epoch20, step2880]: loss 0.898944
[epoch20, step2881]: loss 10.241937
[epoch20, step2882]: loss 1.493283
[epoch20, step2883]: loss 2.891558
[epoch20, step2884]: loss 1.844008
[epoch20, step2885]: loss 14.158619
[epoch20, step2886]: loss 1.154885
[epoch20, step2887]: loss 0.910355
[epoch20, step2888]: loss 14.430109
[epoch20, step2889]: loss 0.411142
[epoch20, step2890]: loss 11.646202
[epoch20, step2891]: loss 3.520244
[epoch20, step2892]: loss 1.158084
[epoch20, step2893]: loss 2.474086
[epoch20, step2894]: loss 6.717779
[epoch20, step2895]: loss 1.009104
[epoch20, step2896]: loss 0.874485
[epoch20, step2897]: loss 1.021723
[epoch20, step2898]: loss 2.552225
[epoch20, step2899]: loss 8.048176
[epoch20, step2900]: loss 7.818062
[epoch20, step2901]: loss 0.856388
[epoch20, step2902]: loss 13.285519
[epoch20, step2903]: loss 0.950393
[epoch20, step2904]: loss 2.394912
[epoch20, step2905]: loss 8.654980
[epoch20, step2906]: loss 4.332844
[epoch20, step2907]: loss 6.023672
[epoch20, step2908]: loss 1.188409
[epoch20, step2909]: loss 1.780019
[epoch20, step2910]: loss 9.656302
[epoch20, step2911]: loss 1.287997
[epoch20, step2912]: loss 7.389087
[epoch20, step2913]: loss 0.960051
[epoch20, step2914]: loss 4.399878
[epoch20, step2915]: loss 5.833118
[epoch20, step2916]: loss 2.189234
[epoch20, step2917]: loss 0.716156
[epoch20, step2918]: loss 0.748930
[epoch20, step2919]: loss 6.820673
[epoch20, step2920]: loss 3.167421
[epoch20, step2921]: loss 4.357656
[epoch20, step2922]: loss 1.754082
[epoch20, step2923]: loss 5.245696
[epoch20, step2924]: loss 1.509022
[epoch20, step2925]: loss 0.700506
[epoch20, step2926]: loss 2.276086
[epoch20, step2927]: loss 1.493690
[epoch20, step2928]: loss 10.553009
[epoch20, step2929]: loss 7.410665
[epoch20, step2930]: loss 0.841009
[epoch20, step2931]: loss 2.068990
[epoch20, step2932]: loss 0.731705
[epoch20, step2933]: loss 1.729902
[epoch20, step2934]: loss 0.632536
[epoch20, step2935]: loss 6.335145
[epoch20, step2936]: loss 1.963346
[epoch20, step2937]: loss 0.634599
[epoch20, step2938]: loss 0.721599
[epoch20, step2939]: loss 3.242832
[epoch20, step2940]: loss 1.122366
[epoch20, step2941]: loss 3.138774
[epoch20, step2942]: loss 0.428467
[epoch20, step2943]: loss 6.663797
[epoch20, step2944]: loss 5.431877
[epoch20, step2945]: loss 6.264493
[epoch20, step2946]: loss 8.275244
[epoch20, step2947]: loss 7.827996
[epoch20, step2948]: loss 0.467407
[epoch20, step2949]: loss 8.001266
[epoch20, step2950]: loss 11.959332
[epoch20, step2951]: loss 8.280147
[epoch20, step2952]: loss 0.732972
[epoch20, step2953]: loss 1.271838
[epoch20, step2954]: loss 1.904781
[epoch20, step2955]: loss 2.669569
[epoch20, step2956]: loss 0.537921
[epoch20, step2957]: loss 1.046262
[epoch20, step2958]: loss 3.175256
[epoch20, step2959]: loss 5.573370
[epoch20, step2960]: loss 6.343372
[epoch20, step2961]: loss 0.594862
[epoch20, step2962]: loss 1.811760
[epoch20, step2963]: loss 10.541433
[epoch20, step2964]: loss 1.977022
[epoch20, step2965]: loss 5.882229
[epoch20, step2966]: loss 0.635941
[epoch20, step2967]: loss 1.810655
[epoch20, step2968]: loss 0.665490
[epoch20, step2969]: loss 1.127793
[epoch20, step2970]: loss 1.130534
[epoch20, step2971]: loss 2.700388
[epoch20, step2972]: loss 10.454065
[epoch20, step2973]: loss 0.469403
[epoch20, step2974]: loss 0.579757
[epoch20, step2975]: loss 1.197837
[epoch20, step2976]: loss 16.712692
[epoch20, step2977]: loss 1.134367
[epoch20, step2978]: loss 0.572240
[epoch20, step2979]: loss 8.577881
[epoch20, step2980]: loss 0.554074
[epoch20, step2981]: loss 5.762855
[epoch20, step2982]: loss 14.769696
[epoch20, step2983]: loss 3.275191
[epoch20, step2984]: loss 0.605128
[epoch20, step2985]: loss 10.217247
[epoch20, step2986]: loss 1.208359
[epoch20, step2987]: loss 4.500726
[epoch20, step2988]: loss 1.776735
[epoch20, step2989]: loss 0.912930
[epoch20, step2990]: loss 2.577379
[epoch20, step2991]: loss 1.769546
[epoch20, step2992]: loss 0.860198
[epoch20, step2993]: loss 0.420576
[epoch20, step2994]: loss 0.782214
[epoch20, step2995]: loss 0.843617
[epoch20, step2996]: loss 11.660947
[epoch20, step2997]: loss 0.457068
[epoch20, step2998]: loss 1.756624
[epoch20, step2999]: loss 1.731652
[epoch20, step3000]: loss 1.044172
[epoch20, step3001]: loss 2.009310
[epoch20, step3002]: loss 2.117180
[epoch20, step3003]: loss 0.524394
[epoch20, step3004]: loss 1.415301
[epoch20, step3005]: loss 2.294477
[epoch20, step3006]: loss 0.444757
[epoch20, step3007]: loss 0.401190
[epoch20, step3008]: loss 1.587153
[epoch20, step3009]: loss 0.827489
[epoch20, step3010]: loss 1.399547
[epoch20, step3011]: loss 4.418686
[epoch20, step3012]: loss 6.603026
[epoch20, step3013]: loss 4.275037
[epoch20, step3014]: loss 1.277281
[epoch20, step3015]: loss 1.575624
[epoch20, step3016]: loss 14.186878
[epoch20, step3017]: loss 25.031063
[epoch20, step3018]: loss 3.773829
[epoch20, step3019]: loss 5.598842
[epoch20, step3020]: loss 1.240818
[epoch20, step3021]: loss 3.150405
[epoch20, step3022]: loss 0.925645
[epoch20, step3023]: loss 0.730149
[epoch20, step3024]: loss 0.693228
[epoch20, step3025]: loss 0.580253
[epoch20, step3026]: loss 0.676232
[epoch20, step3027]: loss 0.710365
[epoch20, step3028]: loss 2.660029
[epoch20, step3029]: loss 8.043121
[epoch20, step3030]: loss 3.236266
[epoch20, step3031]: loss 0.767884
[epoch20, step3032]: loss 1.822510
[epoch20, step3033]: loss 5.040431
[epoch20, step3034]: loss 1.285186
[epoch20, step3035]: loss 6.480083
[epoch20, step3036]: loss 0.713475
[epoch20, step3037]: loss 1.250746
[epoch20, step3038]: loss 0.613611
[epoch20, step3039]: loss 1.450520
[epoch20, step3040]: loss 0.517870
[epoch20, step3041]: loss 0.639783
[epoch20, step3042]: loss 0.635934
[epoch20, step3043]: loss 1.867896
[epoch20, step3044]: loss 8.936443
[epoch20, step3045]: loss 2.256211
[epoch20, step3046]: loss 0.666112
[epoch20, step3047]: loss 0.854940
[epoch20, step3048]: loss 7.958561
[epoch20, step3049]: loss 6.503486
[epoch20, step3050]: loss 0.777147
[epoch20, step3051]: loss 0.729182
[epoch20, step3052]: loss 6.576894
[epoch20, step3053]: loss 9.935450
[epoch20, step3054]: loss 2.201657
[epoch20, step3055]: loss 1.096969
[epoch20, step3056]: loss 1.975513
[epoch20, step3057]: loss 0.684546
[epoch20, step3058]: loss 4.847268
[epoch20, step3059]: loss 1.269889
[epoch20, step3060]: loss 5.321553
[epoch20, step3061]: loss 1.631935
[epoch20, step3062]: loss 2.004518
[epoch20, step3063]: loss 2.105875
[epoch20, step3064]: loss 2.205452
[epoch20, step3065]: loss 2.031917
[epoch20, step3066]: loss 0.741598
[epoch20, step3067]: loss 0.749538
[epoch20, step3068]: loss 0.913257
[epoch20, step3069]: loss 10.742343
[epoch20, step3070]: loss 1.106088
[epoch20, step3071]: loss 0.731113
[epoch20, step3072]: loss 0.880089
[epoch20, step3073]: loss 1.041071
[epoch20, step3074]: loss 1.318903
[epoch20, step3075]: loss 0.927480
[epoch20, step3076]: loss 11.385509

[epoch20]: avg loss 11.385509

[TEST step1]: loss 1.409259
[TEST step2]: loss 1.132643
[TEST step3]: loss 0.494720
[TEST step4]: loss 1.308954
[TEST step5]: loss 0.805484
[TEST step6]: loss 1.249842
[TEST step7]: loss 0.616769
[TEST step8]: loss 1.445245
[TEST step9]: loss 0.498164
[TEST step10]: loss 0.582448
[TEST step11]: loss 2.192383
[TEST step12]: loss 8.441192
[TEST step13]: loss 0.443764
[TEST step14]: loss 8.896195
[TEST step15]: loss 0.836893
[TEST step16]: loss 4.682295
[TEST step17]: loss 7.883760
[TEST step18]: loss 6.955008
[TEST step19]: loss 0.794396
[TEST step20]: loss 0.492619
[TEST step21]: loss 5.712690
[TEST step22]: loss 7.964421
[TEST step23]: loss 0.568772
[TEST step24]: loss 0.842417
[TEST step25]: loss 0.667315
[TEST step26]: loss 0.970717
[TEST step27]: loss 1.059500
[TEST step28]: loss 10.207652
[TEST step29]: loss 1.341434
[TEST step30]: loss 0.612621
[TEST step31]: loss 2.949817
[TEST step32]: loss 6.273276
[TEST step33]: loss 7.641750
[TEST step34]: loss 4.181466
[TEST step35]: loss 2.167115
[TEST step36]: loss 1.638377
[TEST step37]: loss 8.043885
[TEST step38]: loss 0.580411
[TEST step39]: loss 0.656930
[TEST step40]: loss 2.476307
[TEST step41]: loss 0.747152
[TEST step42]: loss 1.049499
[TEST step43]: loss 2.327917
[TEST step44]: loss 0.655427
[TEST step45]: loss 5.908188
[TEST step46]: loss 6.130164
[TEST step47]: loss 0.622709
[TEST step48]: loss 16.529175
[TEST step49]: loss 0.587653
[TEST step50]: loss 3.072878
[TEST step51]: loss 1.107772
[TEST step52]: loss 1.862599
[TEST step53]: loss 2.459409
[TEST step54]: loss 3.584561
[TEST step55]: loss 0.985152
[TEST step56]: loss 6.510493
[TEST step57]: loss 0.691910
[TEST step58]: loss 8.475583
[TEST step59]: loss 5.921737
[TEST step60]: loss 0.657290
[TEST step61]: loss 0.694984
[TEST step62]: loss 1.405108
[TEST step63]: loss 0.889596
[TEST step64]: loss 3.288864
[TEST step65]: loss 8.946088
[TEST step66]: loss 7.533323
[TEST step67]: loss 1.680977
[TEST step68]: loss 1.163888
[TEST step69]: loss 0.502250
[TEST step70]: loss 5.435083
[TEST step71]: loss 0.785996
[TEST step72]: loss 2.245547
[TEST step73]: loss 0.880362
[TEST step74]: loss 1.801095
[TEST step75]: loss 0.841205
[TEST step76]: loss 1.448457
[TEST step77]: loss 4.383053
[TEST step78]: loss 5.835661
[TEST step79]: loss 0.666068
[TEST step80]: loss 2.339485
[TEST step81]: loss 0.962049
[TEST step82]: loss 6.110471
[TEST step83]: loss 2.591943
[TEST step84]: loss 1.257291
[TEST step85]: loss 1.105122
[TEST step86]: loss 11.745714
[TEST step87]: loss 6.864112
[TEST step88]: loss 0.846006
[TEST step89]: loss 1.100891
[TEST step90]: loss 0.802489
[TEST step91]: loss 0.813987
[TEST step92]: loss 4.226265
[TEST step93]: loss 0.845014
[TEST step94]: loss 2.759171
[TEST step95]: loss 13.409402
[TEST step96]: loss 1.078301
[TEST step97]: loss 18.781197
[TEST step98]: loss 1.641874
[TEST step99]: loss 3.614972
[TEST step100]: loss 6.055917
[TEST step101]: loss 1.969611
[TEST step102]: loss 0.469400
[TEST step103]: loss 1.540464
[TEST step104]: loss 1.720408
[TEST step105]: loss 6.385810
[TEST step106]: loss 1.038230
[TEST step107]: loss 6.197699
[TEST step108]: loss 0.725221
[TEST step109]: loss 1.292306
[TEST step110]: loss 6.685802
[TEST step111]: loss 1.008025
[TEST step112]: loss 2.806020
[TEST step113]: loss 5.148636
[TEST step114]: loss 1.461806
[TEST step115]: loss 0.994682
[TEST step116]: loss 1.159384
[TEST step117]: loss 1.845356
[TEST step118]: loss 1.196927
[TEST step119]: loss 4.844259
[TEST step120]: loss 0.442822
[TEST step121]: loss 0.799223
[TEST step122]: loss 2.759222
[TEST step123]: loss 0.375077
[TEST step124]: loss 0.827071
[TEST step125]: loss 0.919659
[TEST step126]: loss 1.144495
[TEST step127]: loss 2.481365
[TEST step128]: loss 10.444897
[TEST step129]: loss 0.632672
[TEST step130]: loss 12.303808
[TEST step131]: loss 6.872676
[TEST step132]: loss 0.542773
[TEST step133]: loss 0.725054
[TEST step134]: loss 19.136173
[TEST step135]: loss 14.208394
[TEST step136]: loss 7.124259
[TEST step137]: loss 0.468287
[TEST step138]: loss 0.732657
[TEST step139]: loss 5.859506
[TEST step140]: loss 0.682717
[TEST step141]: loss 0.922472
[TEST step142]: loss 1.069203
[TEST step143]: loss 1.392867
[TEST step144]: loss 1.323061
[TEST step145]: loss 1.084889
[TEST step146]: loss 0.515921
[TEST step147]: loss 2.307636
[TEST step148]: loss 4.656082
[TEST step149]: loss 1.444750
[TEST step150]: loss 9.793217
[TEST step151]: loss 0.552678
[TEST step152]: loss 1.064278
[TEST step153]: loss 7.184584
[TEST step154]: loss 8.012872
[TEST step155]: loss 0.490544
[TEST step156]: loss 2.672263
[TEST step157]: loss 1.975175
[TEST step158]: loss 1.064663
[TEST step159]: loss 8.238828
[TEST step160]: loss 25.422163
[TEST step161]: loss 0.610094
[TEST step162]: loss 3.863243
[TEST step163]: loss 6.097418
[TEST step164]: loss 0.575232
[TEST step165]: loss 1.698069
[TEST step166]: loss 3.355324
[TEST step167]: loss 1.142218
[TEST step168]: loss 1.105701
[TEST step169]: loss 0.861192
[TEST step170]: loss 1.230049
[TEST step171]: loss 0.474828
[TEST step172]: loss 5.772520
[TEST step173]: loss 1.406586
[TEST step174]: loss 12.469334
[TEST step175]: loss 5.053122
[TEST step176]: loss 0.563322
[TEST step177]: loss 0.881635
[TEST step178]: loss 6.401052
[TEST step179]: loss 11.093007
[TEST step180]: loss 1.895925
[TEST step181]: loss 10.663454
[TEST step182]: loss 6.925073
[TEST step183]: loss 4.150478
[TEST step184]: loss 15.012778
[TEST step185]: loss 0.993052
[TEST step186]: loss 1.062174
[TEST step187]: loss 1.010361
[TEST step188]: loss 0.611868
[TEST step189]: loss 0.320056
[TEST step190]: loss 1.325099
[TEST step191]: loss 0.394480
[TEST step192]: loss 0.423891
[TEST step193]: loss 0.501906
[TEST step194]: loss 8.231379
[TEST step195]: loss 5.588488
[TEST step196]: loss 3.757395
[TEST step197]: loss 0.849215
[TEST step198]: loss 0.718837
[TEST step199]: loss 1.170632
[TEST step200]: loss 2.716984
[TEST step201]: loss 1.649830
[TEST step202]: loss 0.551463
[TEST step203]: loss 0.775420
[TEST step204]: loss 1.344932
[TEST step205]: loss 0.796656
[TEST step206]: loss 0.674296
[TEST step207]: loss 0.480219
[TEST step208]: loss 1.514225
[TEST step209]: loss 3.076249
[TEST step210]: loss 0.713152
[TEST step211]: loss 2.465746
[TEST step212]: loss 1.961923
[TEST step213]: loss 0.797339
[TEST step214]: loss 1.573358
[TEST step215]: loss 9.432248
[TEST step216]: loss 0.344228
[TEST step217]: loss 2.673649
[TEST step218]: loss 0.699366
[TEST step219]: loss 1.435495
[TEST step220]: loss 2.053430
[TEST step221]: loss 1.977380
[TEST step222]: loss 8.836875
[TEST step223]: loss 0.772875
[TEST step224]: loss 13.142317
[TEST step225]: loss 1.852128
[TEST step226]: loss 1.124097
[TEST step227]: loss 6.221814
[TEST step228]: loss 12.872688
[TEST step229]: loss 0.788962
[TEST step230]: loss 9.186297
[TEST step231]: loss 0.747465
[TEST step232]: loss 5.824915
[TEST step233]: loss 0.787740
[TEST step234]: loss 0.832744
[TEST step235]: loss 1.321456
[TEST step236]: loss 0.787210
[TEST step237]: loss 1.107513
[TEST step238]: loss 1.557480
[TEST step239]: loss 0.513234
[TEST step240]: loss 1.429551
[TEST step241]: loss 1.216403
[TEST step242]: loss 0.616166
[TEST step243]: loss 5.240852
[TEST step244]: loss 1.046242
[TEST step245]: loss 3.858419
[TEST step246]: loss 11.216734
[TEST step247]: loss 4.743461
[TEST step248]: loss 6.651588
[TEST step249]: loss 8.241366
[TEST step250]: loss 3.351575
[TEST step251]: loss 6.311150
[TEST step252]: loss 1.841890
[TEST step253]: loss 0.958373
[TEST step254]: loss 1.208567
[TEST step255]: loss 1.797995
[TEST step256]: loss 0.764620
[TEST step257]: loss 2.798444
[TEST step258]: loss 0.929595
[TEST step259]: loss 5.627750
[TEST step260]: loss 0.664946
[TEST step261]: loss 1.785719
[TEST step262]: loss 0.783035
[TEST step263]: loss 1.964006
[TEST step264]: loss 3.696101
[TEST step265]: loss 8.426366
[TEST step266]: loss 13.100945
[TEST step267]: loss 1.793838
[TEST step268]: loss 2.152655
[TEST step269]: loss 4.421120
[TEST step270]: loss 1.658341
[TEST step271]: loss 2.324781
[TEST step272]: loss 7.738796
[TEST step273]: loss 1.351504
[TEST step274]: loss 1.670202
[TEST step275]: loss 0.626122
[TEST step276]: loss 0.613086
[TEST step277]: loss 6.214639
[TEST step278]: loss 1.528473
[TEST step279]: loss 15.691684
[TEST step280]: loss 1.796615
[TEST step281]: loss 2.147827
[TEST step282]: loss 1.483999
[TEST step283]: loss 0.756216
[TEST step284]: loss 0.432265
[TEST step285]: loss 0.584314
[TEST step286]: loss 5.219750
[TEST step287]: loss 8.368055
[TEST step288]: loss 0.398866
[TEST step289]: loss 0.519735
[TEST step290]: loss 9.445220
[TEST step291]: loss 0.568162
[TEST step292]: loss 0.543490
[TEST step293]: loss 3.016160
[TEST step294]: loss 0.678912
[TEST step295]: loss 13.416733
[TEST step296]: loss 0.776991
[TEST step297]: loss 1.637755
[TEST step298]: loss 1.332315
[TEST step299]: loss 0.655065
[TEST step300]: loss 0.602457
[TEST step301]: loss 0.829632
[TEST step302]: loss 13.287372
[TEST step303]: loss 21.809801
[TEST step304]: loss 0.888305
[TEST step305]: loss 0.555564
[TEST step306]: loss 0.596852
[TEST step307]: loss 0.509109
[TEST step308]: loss 0.713199
[TEST step309]: loss 0.799295
[TEST step310]: loss 0.657044
[TEST step311]: loss 16.298746
[TEST step312]: loss 2.758990
[TEST step313]: loss 6.628268
[TEST step314]: loss 1.905856
[TEST step315]: loss 5.123880
[TEST step316]: loss 0.675864
[TEST step317]: loss 1.303927
[TEST step318]: loss 0.637313
[TEST step319]: loss 12.657471
[TEST step320]: loss 4.090503
[TEST step321]: loss 0.549363
[TEST step322]: loss 5.413873
[TEST step323]: loss 0.433167
[TEST step324]: loss 3.622748
[TEST step325]: loss 0.590886
[TEST step326]: loss 1.446540
[TEST step327]: loss 0.638346
[TEST step328]: loss 1.165451
[TEST step329]: loss 0.472569
[TEST step330]: loss 0.969428
[TEST step331]: loss 8.212040
[TEST step332]: loss 0.915018
[TEST step333]: loss 0.550277
[TEST step334]: loss 5.665974
[TEST step335]: loss 8.120633
[TEST step336]: loss 0.912259
[TEST step337]: loss 4.349572
[TEST step338]: loss 0.655283
[TEST step339]: loss 1.462053
[TEST step340]: loss 12.835553
[TEST step341]: loss 12.394688
[TEST step342]: loss 1.419437
[TEST step343]: loss 1.436396
[TEST step344]: loss 2.986678
[TEST step345]: loss 0.735820
[TEST step346]: loss 1.580639
[TEST step347]: loss 1.712179
[TEST step348]: loss 13.678429
[TEST step349]: loss 5.460325
[TEST step350]: loss 1.460631
[TEST step351]: loss 12.204796
[TEST step352]: loss 0.780829
[TEST step353]: loss 6.125118
[TEST step354]: loss 6.543266
[TEST step355]: loss 0.565400
[TEST step356]: loss 0.612049
[TEST step357]: loss 4.279160
[TEST step358]: loss 1.794386
[TEST step359]: loss 4.280148
[TEST step360]: loss 0.604806
[TEST step361]: loss 15.270097
[TEST step362]: loss 0.916846
[TEST step363]: loss 0.858972
[TEST step364]: loss 1.558424
[TEST step365]: loss 0.669574
[TEST step366]: loss 5.347247
[TEST step367]: loss 4.982007
[TEST step368]: loss 0.501660
[TEST step369]: loss 4.176817
[TEST step370]: loss 9.184137
[TEST step371]: loss 2.697587
[TEST step372]: loss 2.357683
[TEST step373]: loss 2.105313
[TEST step374]: loss 7.694855
[TEST step375]: loss 8.956670
[TEST step376]: loss 1.808394
[TEST step377]: loss 1.263883
[TEST step378]: loss 2.330292
[TEST step379]: loss 0.874055
[TEST step380]: loss 5.224388
[TEST step381]: loss 11.427248
[TEST step382]: loss 1.001477
[TEST step383]: loss 12.619980
[TEST step384]: loss 1.377956
[TEST step385]: loss 0.680804
[TEST step386]: loss 9.159132
[TEST step387]: loss 1.111138
[TEST step388]: loss 1.431266
[TEST step389]: loss 0.601761
[TEST step390]: loss 1.485839
[TEST step391]: loss 0.543427
[TEST step392]: loss 1.468602
[TEST step393]: loss 8.824699
[TEST step394]: loss 1.087974
[TEST step395]: loss 9.487202
[TEST step396]: loss 14.996908
[TEST step397]: loss 13.412524
[TEST step398]: loss 1.301054
[TEST step399]: loss 5.645015
[TEST step400]: loss 0.895311
[TEST step401]: loss 8.682292
[TEST step402]: loss 8.698552
[TEST step403]: loss 0.517898
[TEST step404]: loss 4.314993
[TEST step405]: loss 4.764828
[TEST step406]: loss 8.206037
[TEST step407]: loss 4.146090
[TEST step408]: loss 2.355033
[TEST step409]: loss 4.823127
[TEST step410]: loss 1.370845
[TEST step411]: loss 1.273322
[TEST step412]: loss 3.101772
[TEST step413]: loss 0.479772
[TEST step414]: loss 2.259871
[TEST step415]: loss 0.550279
[TEST step416]: loss 0.615697
[TEST step417]: loss 0.497184
[TEST step418]: loss 0.402773
[TEST step419]: loss 8.453061
[TEST step420]: loss 2.047776
[TEST step421]: loss 0.622973
[TEST step422]: loss 0.855655
[TEST step423]: loss 2.328957
[TEST step424]: loss 2.644468
[TEST step425]: loss 1.599071
[TEST step426]: loss 1.004470
[TEST step427]: loss 1.622680
[TEST step428]: loss 0.669154
[TEST step429]: loss 0.533458
[TEST step430]: loss 4.065259
[TEST step431]: loss 0.572280
[TEST step432]: loss 0.675037
[TEST step433]: loss 0.655315
[TEST step434]: loss 1.533952
[TEST step435]: loss 8.869423
[TEST step436]: loss 1.185581
[TEST step437]: loss 0.695586
[TEST step438]: loss 8.276734
[TEST step439]: loss 0.638852
[TEST step440]: loss 2.121897
[TEST step441]: loss 0.695639
[TEST step442]: loss 1.420638
[TEST step443]: loss 4.893836
[TEST step444]: loss 0.544953
[TEST step445]: loss 5.376375
[TEST step446]: loss 8.930058
[TEST step447]: loss 1.156384
[TEST step448]: loss 2.105541
[TEST step449]: loss 6.984029
[TEST step450]: loss 5.601471
[TEST step451]: loss 7.564431
[TEST step452]: loss 0.677908
[TEST step453]: loss 2.433472
[TEST step454]: loss 5.897575
[TEST step455]: loss 0.840788
[TEST step456]: loss 0.947598
[TEST step457]: loss 3.849799
[TEST step458]: loss 1.401906
[TEST step459]: loss 1.767892
[TEST step460]: loss 0.788975
[TEST step461]: loss 8.706199
[TEST step462]: loss 5.230500
[TEST step463]: loss 0.535532
[TEST step464]: loss 1.372961
[TEST step465]: loss 4.313626
[TEST step466]: loss 2.597583
[TEST step467]: loss 5.291552
[TEST step468]: loss 12.604323
[TEST step469]: loss 2.312054
[TEST step470]: loss 3.286146
[TEST step471]: loss 0.432312
[TEST step472]: loss 8.978596
[TEST step473]: loss 4.366742
[TEST step474]: loss 0.639440
[TEST step475]: loss 1.916466
[TEST step476]: loss 7.206676
[TEST step477]: loss 4.860108
[TEST step478]: loss 0.492181
[TEST step479]: loss 0.474484
[TEST step480]: loss 10.437307
[TEST step481]: loss 9.594203
[TEST step482]: loss 1.010893
[TEST step483]: loss 7.270500
[TEST step484]: loss 4.570538
[TEST step485]: loss 3.465025
[TEST step486]: loss 0.566945
[TEST step487]: loss 2.210281
[TEST step488]: loss 0.559550
[TEST step489]: loss 2.152460
[TEST step490]: loss 7.529853
[TEST step491]: loss 0.887563
[TEST step492]: loss 4.370840
[TEST step493]: loss 11.058086
[TEST step494]: loss 5.565773
[TEST step495]: loss 1.003571
[TEST step496]: loss 1.018690
[TEST step497]: loss 0.713932
[TEST step498]: loss 6.640911
[TEST step499]: loss 0.811657
[TEST step500]: loss 7.928464
[TEST step501]: loss 2.169726
[TEST step502]: loss 4.183190
[TEST step503]: loss 6.192538
[TEST step504]: loss 1.327849
[TEST step505]: loss 1.498687
[TEST step506]: loss 1.496296
[TEST step507]: loss 0.533503
[TEST step508]: loss 2.549594
[TEST step509]: loss 2.089457
[TEST step510]: loss 0.611928
[TEST step511]: loss 1.005762
[TEST step512]: loss 0.889002
[TEST step513]: loss 0.732775
[TEST step514]: loss 0.697116
[TEST step515]: loss 8.171616
[TEST step516]: loss 7.289769
[TEST step517]: loss 0.695156
[TEST step518]: loss 4.193440
[TEST step519]: loss 0.789116
[TEST step520]: loss 0.782824
[TEST step521]: loss 0.871655
[TEST step522]: loss 5.307117
[TEST step523]: loss 8.311628
[TEST step524]: loss 1.158654
[TEST step525]: loss 0.539594
[TEST step526]: loss 15.747935
[TEST step527]: loss 0.804565
[TEST step528]: loss 0.535980
[TEST step529]: loss 1.019833
[TEST step530]: loss 0.586161
[TEST step531]: loss 0.454351
[TEST step532]: loss 2.057124
[TEST step533]: loss 0.437626
[TEST step534]: loss 0.912712
[TEST step535]: loss 1.263779
[TEST step536]: loss 3.442228
[TEST step537]: loss 10.799434
[TEST step538]: loss 7.615331
[TEST step539]: loss 11.458070
[TEST step540]: loss 13.206652
[TEST step541]: loss 0.581220
[TEST step542]: loss 1.283899
[TEST step543]: loss 0.634433
[TEST step544]: loss 5.993474
[TEST step545]: loss 0.970623
[TEST step546]: loss 0.930992
[TEST step547]: loss 4.907237
[TEST step548]: loss 0.517198
[TEST step549]: loss 0.918946
[TEST step550]: loss 0.899083
[TEST step551]: loss 9.081279
[TEST step552]: loss 2.322435
[TEST step553]: loss 6.997709
[TEST step554]: loss 1.255921
[TEST step555]: loss 4.990108
[TEST step556]: loss 3.481588
[TEST step557]: loss 6.730193
[TEST step558]: loss 0.677426
[TEST step559]: loss 1.447286
[TEST step560]: loss 2.847034
[TEST step561]: loss 5.229934
[TEST step562]: loss 10.863954
[TEST step563]: loss 15.213049
[TEST step564]: loss 4.782838
[TEST step565]: loss 0.650878
[TEST step566]: loss 0.344526
[TEST step567]: loss 1.008161
[TEST step568]: loss 6.531620
[TEST step569]: loss 1.580453
[TEST step570]: loss 0.467967
[TEST step571]: loss 1.122532
[TEST step572]: loss 0.387558
[TEST step573]: loss 1.680599
[TEST step574]: loss 7.681935
[TEST step575]: loss 0.550765
[TEST step576]: loss 12.673424
[TEST step577]: loss 1.645937
[TEST step578]: loss 1.255192
[TEST step579]: loss 0.974967
[TEST step580]: loss 0.654365
[TEST step581]: loss 2.824224
[TEST step582]: loss 1.523895
[TEST step583]: loss 0.507575
[TEST step584]: loss 1.544376
[TEST step585]: loss 0.499251
[TEST step586]: loss 1.361029
[TEST step587]: loss 0.764440
[TEST step588]: loss 4.750126
[TEST step589]: loss 16.105164
[TEST step590]: loss 8.884588
[TEST step591]: loss 2.352313
[TEST step592]: loss 8.198711
[TEST step593]: loss 0.646044
[TEST step594]: loss 6.682246
[TEST step595]: loss 0.637051
[TEST step596]: loss 0.731372
[TEST step597]: loss 0.804554
[TEST step598]: loss 6.420501
[TEST step599]: loss 6.007183
[TEST step600]: loss 1.297389
[TEST step601]: loss 11.169292
[TEST step602]: loss 0.593499
[TEST step603]: loss 1.283779
[TEST step604]: loss 0.853608
[TEST step605]: loss 1.503249
[TEST step606]: loss 0.400878
[TEST step607]: loss 0.857863
[TEST step608]: loss 0.518607
[TEST step609]: loss 0.759157
[TEST step610]: loss 0.479551
[TEST step611]: loss 1.680734
[TEST step612]: loss 0.513384
[TEST step613]: loss 1.393850
[TEST step614]: loss 0.537614
[TEST step615]: loss 0.990205
[TEST step616]: loss 0.482050
[TEST step617]: loss 0.933307
[TEST step618]: loss 0.904603
[TEST step619]: loss 7.165630
[TEST step620]: loss 4.691319
[TEST step621]: loss 11.179970
[TEST step622]: loss 1.422563
[TEST step623]: loss 9.431610
[TEST step624]: loss 1.737935
[TEST step625]: loss 0.732123
[TEST step626]: loss 15.078069
[TEST step627]: loss 0.796641
[TEST step628]: loss 0.658207
[TEST step629]: loss 15.457708
[TEST step630]: loss 1.170688
[TEST step631]: loss 1.722024
[TEST step632]: loss 9.221180
[TEST step633]: loss 7.356070
[TEST step634]: loss 0.929144
[TEST step635]: loss 5.717586
[TEST step636]: loss 8.842240
[TEST step637]: loss 2.036541
[TEST step638]: loss 1.078314
[TEST step639]: loss 3.973298
[TEST step640]: loss 13.567033
[TEST step641]: loss 6.574710
[TEST step642]: loss 5.765001
[TEST step643]: loss 2.060214
[TEST step644]: loss 4.955565
[TEST step645]: loss 12.572834
[TEST step646]: loss 1.496393
[TEST step647]: loss 2.340193
[TEST step648]: loss 10.447779
[TEST step649]: loss 1.037462
[TEST step650]: loss 0.862220
[TEST step651]: loss 0.848822
[TEST step652]: loss 1.187490
[TEST step653]: loss 0.935854
[TEST step654]: loss 4.983836
[TEST step655]: loss 0.537609
[TEST step656]: loss 1.334390
[TEST step657]: loss 0.505256
[TEST step658]: loss 6.489885
[TEST step659]: loss 5.212840
[TEST step660]: loss 0.509605
[TEST step661]: loss 0.621159
[TEST step662]: loss 1.281518
[TEST step663]: loss 1.601875
[TEST step664]: loss 0.715294
[TEST step665]: loss 0.783352
[TEST step666]: loss 0.859628
[TEST step667]: loss 8.424389
[TEST step668]: loss 0.762515
[TEST step669]: loss 6.890639
[TEST step670]: loss 0.656075
[TEST step671]: loss 9.992953
[TEST step672]: loss 0.838018
[TEST step673]: loss 0.746115
[TEST step674]: loss 4.143559
[TEST step675]: loss 0.598829
[TEST step676]: loss 1.490676
[TEST step677]: loss 1.305340
[TEST step678]: loss 0.601273
[TEST step679]: loss 11.618383
[TEST step680]: loss 1.320016
[TEST step681]: loss 8.292726
[TEST step682]: loss 2.271883
[TEST step683]: loss 1.654384
[TEST step684]: loss 8.267996
[TEST step685]: loss 10.303656
[TEST step686]: loss 0.501658
[TEST step687]: loss 16.383114
[TEST step688]: loss 2.496323
[TEST step689]: loss 1.001981
[TEST step690]: loss 4.346604
[TEST step691]: loss 0.954856
[TEST step692]: loss 0.599497
[TEST step693]: loss 1.065522
[TEST step694]: loss 0.804840
[TEST step695]: loss 4.471087
[TEST step696]: loss 3.283297
[TEST step697]: loss 5.290084
[TEST step698]: loss 0.389628
[TEST step699]: loss 1.635418
[TEST step700]: loss 7.299975
[TEST step701]: loss 0.848711
[TEST step702]: loss 0.841023
[TEST step703]: loss 1.996046
[TEST step704]: loss 6.663909
[TEST step705]: loss 2.166158
[TEST step706]: loss 7.678027
[TEST step707]: loss 10.060886
[TEST step708]: loss 8.045009
[TEST step709]: loss 0.736861
[TEST step710]: loss 5.692044
[TEST step711]: loss 8.144891
[TEST step712]: loss 1.173931
[TEST step713]: loss 3.227314
[TEST step714]: loss 1.177336
[TEST step715]: loss 8.982654
[TEST step716]: loss 0.817880
[TEST step717]: loss 1.620860
[TEST step718]: loss 1.892223
[TEST step719]: loss 1.042902
[TEST step720]: loss 1.001183
[TEST step721]: loss 1.183442
[TEST step722]: loss 2.075961
[TEST step723]: loss 1.290630
[TEST step724]: loss 1.394721
[TEST step725]: loss 0.419761
[TEST step726]: loss 9.330633
[TEST step727]: loss 8.874176
[TEST step728]: loss 1.362078
[TEST step729]: loss 1.128308
[TEST step730]: loss 5.283207
[TEST step731]: loss 3.033019
[TEST step732]: loss 2.471523
[TEST step733]: loss 13.376335
[TEST step734]: loss 4.166793
[TEST step735]: loss 4.844040
[TEST step736]: loss 1.457837
[TEST step737]: loss 1.255126
[TEST step738]: loss 0.547528
[TEST step739]: loss 0.844438
[TEST step740]: loss 9.675903
[TEST step741]: loss 4.739193
[TEST step742]: loss 7.666955
[TEST step743]: loss 1.228055
[TEST step744]: loss 2.342838
[TEST step745]: loss 0.658029
[TEST step746]: loss 2.711122
[TEST step747]: loss 0.668794
[TEST step748]: loss 0.565566
[TEST step749]: loss 8.491133
[TEST step750]: loss 3.210140
[TEST step751]: loss 8.442776
[TEST step752]: loss 26.956038
[TEST step753]: loss 0.627765
[TEST step754]: loss 0.457912
[TEST step755]: loss 2.213931
[TEST step756]: loss 10.457270
[TEST step757]: loss 0.385642
[TEST step758]: loss 4.836370
[TEST step759]: loss 0.501585
[TEST step760]: loss 2.964591
[TEST step761]: loss 1.022046
[TEST step762]: loss 1.704826
[TEST step763]: loss 0.761785
[TEST step764]: loss 10.883619
[TEST step765]: loss 1.246469
[TEST step766]: loss 11.334365
[TEST step767]: loss 1.058281
[TEST step768]: loss 2.129042
[TEST step769]: loss 9.657663

[TEST]: avg loss 9.657663

