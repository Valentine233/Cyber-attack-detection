[epoch1, step1]: loss 1.368533
[epoch1, step2]: loss 1.362324
[epoch1, step3]: loss 1.356135
[epoch1, step4]: loss 1.349912
[epoch1, step5]: loss 1.343717
[epoch1, step6]: loss 1.337558
[epoch1, step7]: loss 1.331280
[epoch1, step8]: loss 1.325167
[epoch1, step9]: loss 1.318795
[epoch1, step10]: loss 1.312508
[epoch1, step11]: loss 1.306340
[epoch1, step12]: loss 1.300022
[epoch1, step13]: loss 1.293499
[epoch1, step14]: loss 1.287094
[epoch1, step15]: loss 1.280764
[epoch1, step16]: loss 1.274044
[epoch1, step17]: loss 1.267788
[epoch1, step18]: loss 1.260910
[epoch1, step19]: loss 1.254028
[epoch1, step20]: loss 1.247582
[epoch1, step21]: loss 1.240631
[epoch1, step22]: loss 1.233290
[epoch1, step23]: loss 1.226136
[epoch1, step24]: loss 1.219284
[epoch1, step25]: loss 1.211517
[epoch1, step26]: loss 1.204553
[epoch1, step27]: loss 1.196527
[epoch1, step28]: loss 1.188687
[epoch1, step29]: loss 1.181284
[epoch1, step30]: loss 1.173345
[epoch1, step31]: loss 1.164415
[epoch1, step32]: loss 1.156150
[epoch1, step33]: loss 1.147988
[epoch1, step34]: loss 1.138585
[epoch1, step35]: loss 1.130260
[epoch1, step36]: loss 1.120162
[epoch1, step37]: loss 1.110359
[epoch1, step38]: loss 1.101233
[epoch1, step39]: loss 1.091212
[epoch1, step40]: loss 1.080144
[epoch1, step41]: loss 1.069168
[epoch1, step42]: loss 1.058976
[epoch1, step43]: loss 1.046534
[epoch1, step44]: loss 1.036066
[epoch1, step45]: loss 1.022664
[epoch1, step46]: loss 1.009606
[epoch1, step47]: loss 0.997418
[epoch1, step48]: loss 0.983870
[epoch1, step49]: loss 0.967974
[epoch1, step50]: loss 0.953926
[epoch1, step51]: loss 0.939362
[epoch1, step52]: loss 0.922003
[epoch1, step53]: loss 0.907570
[epoch1, step54]: loss 0.887952
[epoch1, step55]: loss 0.869314
[epoch1, step56]: loss 0.852274
[epoch1, step57]: loss 0.832068
[epoch1, step58]: loss 0.808753
[epoch1, step59]: loss 0.785870
[epoch1, step60]: loss 0.765144
[epoch1, step61]: loss 0.737344
[epoch1, step62]: loss 0.714863
[epoch1, step63]: loss 0.684534
[epoch1, step64]: loss 0.654879
[epoch1, step65]: loss 0.628658
[epoch1, step66]: loss 0.597202
[epoch1, step67]: loss 0.560874
[epoch1, step68]: loss 0.526391
[epoch1, step69]: loss 0.494013
[epoch1, step70]: loss 0.453301
[epoch1, step71]: loss 0.422777
[epoch1, step72]: loss 0.381879
[epoch1, step73]: loss 0.344229
[epoch1, step74]: loss 0.317831
[epoch1, step75]: loss 0.287534
[epoch1, step76]: loss 0.254448
[epoch1, step77]: loss 0.229976
[epoch1, step78]: loss 0.212563
[epoch1, step79]: loss 0.186063
[epoch1, step80]: loss 0.182381
[epoch1, step81]: loss 0.160201
[epoch1, step82]: loss 0.145769
[epoch1, step83]: loss 0.142770
[epoch1, step84]: loss 0.137650
[epoch1, step85]: loss 0.125142
[epoch1, step86]: loss 0.118659
[epoch1, step87]: loss 0.121016
[epoch1, step88]: loss 0.105552
[epoch1, step89]: loss 0.112436
[epoch1, step90]: loss 0.103997
[epoch1, step91]: loss 0.096911
[epoch1, step92]: loss 0.103355
[epoch1, step93]: loss 0.101469
[epoch1, step94]: loss 0.093113
[epoch1, step95]: loss 0.093115
[epoch1, step96]: loss 0.095262
[epoch1, step97]: loss 0.089613
[epoch1, step98]: loss 0.095765
[epoch1, step99]: loss 0.088056
[epoch1, step100]: loss 0.082518
[epoch1, step101]: loss 0.092162
[epoch1, step102]: loss 0.090745
[epoch1, step103]: loss 0.083671
[epoch1, step104]: loss 0.083701
[epoch1, step105]: loss 0.088331
[epoch1, step106]: loss 0.081009
[epoch1, step107]: loss 0.089099
[epoch1, step108]: loss 0.082534
[epoch1, step109]: loss 0.078365
[epoch1, step110]: loss 0.087424
[epoch1, step111]: loss 0.085806
[epoch1, step112]: loss 0.080097
[epoch1, step113]: loss 0.081399
[epoch1, step114]: loss 0.084088
[epoch1, step115]: loss 0.077849
[epoch1, step116]: loss 0.087663
[epoch1, step117]: loss 0.079094
[epoch1, step118]: loss 0.077533
[epoch1, step119]: loss 0.084398
[epoch1, step120]: loss 0.084049
[epoch1, step121]: loss 0.076794
[epoch1, step122]: loss 0.077226
[epoch1, step123]: loss 0.083151
[epoch1, step124]: loss 0.076345
[epoch1, step125]: loss 0.085176
[epoch1, step126]: loss 0.077134
[epoch1, step127]: loss 0.074326
[epoch1, step128]: loss 0.081558
[epoch1, step129]: loss 0.081218
[epoch1, step130]: loss 0.076074
[epoch1, step131]: loss 0.074605
[epoch1, step132]: loss 0.081186
[epoch1, step133]: loss 0.073859
[epoch1, step134]: loss 0.081596
[epoch1, step135]: loss 0.077042
[epoch1, step136]: loss 0.075368
[epoch1, step137]: loss 0.079753
[epoch1, step138]: loss 0.080576
[epoch1, step139]: loss 0.074188
[epoch1, step140]: loss 0.075679
[epoch1, step141]: loss 0.080030
[epoch1, step142]: loss 0.072996
[epoch1, step143]: loss 0.080645
[epoch1, step144]: loss 0.075440
[epoch1, step145]: loss 0.072335
[epoch1, step146]: loss 0.079533
[epoch1, step147]: loss 0.082445
[epoch1, step148]: loss 0.073109
[epoch1, step149]: loss 0.072630
[epoch1, step150]: loss 0.077752
[epoch1, step151]: loss 0.072334
[epoch1, step152]: loss 0.080524
[epoch1, step153]: loss 0.074251
[epoch1, step154]: loss 0.070215
[epoch1, step155]: loss 0.078316
[epoch1, step156]: loss 0.077959
[epoch1, step157]: loss 0.072928
[epoch1, step158]: loss 0.073169
[epoch1, step159]: loss 0.078165
[epoch1, step160]: loss 0.071864
[epoch1, step161]: loss 0.080666
[epoch1, step162]: loss 0.073417
[epoch1, step163]: loss 0.069932
[epoch1, step164]: loss 0.078010
[epoch1, step165]: loss 0.077904
[epoch1, step166]: loss 0.072360
[epoch1, step167]: loss 0.070970
[epoch1, step168]: loss 0.077790
[epoch1, step169]: loss 0.069742
[epoch1, step170]: loss 0.079224
[epoch1, step171]: loss 0.072652
[epoch1, step172]: loss 0.069558
[epoch1, step173]: loss 0.077130
[epoch1, step174]: loss 0.076524
[epoch1, step175]: loss 0.072421
[epoch1, step176]: loss 0.071706
[epoch1, step177]: loss 0.076457
[epoch1, step178]: loss 0.069629
[epoch1, step179]: loss 0.075966
[epoch1, step180]: loss 0.072041
[epoch1, step181]: loss 0.068849
[epoch1, step182]: loss 0.076166
[epoch1, step183]: loss 0.077366
[epoch1, step184]: loss 0.072112
[epoch1, step185]: loss 0.070870
[epoch1, step186]: loss 0.075215
[epoch1, step187]: loss 0.068969
[epoch1, step188]: loss 0.076285
[epoch1, step189]: loss 0.070594
[epoch1, step190]: loss 0.066923
[epoch1, step191]: loss 0.074161
[epoch1, step192]: loss 0.076163
[epoch1, step193]: loss 0.065782
[epoch1, step194]: loss 0.067901
[epoch1, step195]: loss 0.074805
[epoch1, step196]: loss 0.068144
[epoch1, step197]: loss 0.075704
[epoch1, step198]: loss 0.068017
[epoch1, step199]: loss 0.067188
[epoch1, step200]: loss 0.074924
[epoch1, step201]: loss 0.075416
[epoch1, step202]: loss 0.068069
[epoch1, step203]: loss 0.068909
[epoch1, step204]: loss 0.074114
[epoch1, step205]: loss 0.066095
[epoch1, step206]: loss 0.074582
[epoch1, step207]: loss 0.068796
[epoch1, step208]: loss 0.067212
[epoch1, step209]: loss 0.073667
[epoch1, step210]: loss 0.075449
[epoch1, step211]: loss 0.069130
[epoch1, step212]: loss 0.068983
[epoch1, step213]: loss 0.072093
[epoch1, step214]: loss 0.065551
[epoch1, step215]: loss 0.074862
[epoch1, step216]: loss 0.068895
[epoch1, step217]: loss 0.063974
[epoch1, step218]: loss 0.072998
[epoch1, step219]: loss 0.072533
[epoch1, step220]: loss 0.067883
[epoch1, step221]: loss 0.067998
[epoch1, step222]: loss 0.072163
[epoch1, step223]: loss 0.066412
[epoch1, step224]: loss 0.073086
[epoch1, step225]: loss 0.067691
[epoch1, step226]: loss 0.064944
[epoch1, step227]: loss 0.070071
[epoch1, step228]: loss 0.073313
[epoch1, step229]: loss 0.065156
[epoch1, step230]: loss 0.067353
[epoch1, step231]: loss 0.072041
[epoch1, step232]: loss 0.064412
[epoch1, step233]: loss 0.071507
[epoch1, step234]: loss 0.066234
[epoch1, step235]: loss 0.065056
[epoch1, step236]: loss 0.071353
[epoch1, step237]: loss 0.071814
[epoch1, step238]: loss 0.065584
[epoch1, step239]: loss 0.064809
[epoch1, step240]: loss 0.069668
[epoch1, step241]: loss 0.065641
[epoch1, step242]: loss 0.072039
[epoch1, step243]: loss 0.067662
[epoch1, step244]: loss 0.063742
[epoch1, step245]: loss 0.069734
[epoch1, step246]: loss 0.070910
[epoch1, step247]: loss 0.065992
[epoch1, step248]: loss 0.064905
[epoch1, step249]: loss 0.069063
[epoch1, step250]: loss 0.064324
[epoch1, step251]: loss 0.072700
[epoch1, step252]: loss 0.066829
[epoch1, step253]: loss 0.062668
[epoch1, step254]: loss 0.068568
[epoch1, step255]: loss 0.070443
[epoch1, step256]: loss 0.064384
[epoch1, step257]: loss 0.064476
[epoch1, step258]: loss 0.070410
[epoch1, step259]: loss 0.063277
[epoch1, step260]: loss 0.069814
[epoch1, step261]: loss 0.066720
[epoch1, step262]: loss 0.063437
[epoch1, step263]: loss 0.067761
[epoch1, step264]: loss 0.069057
[epoch1, step265]: loss 0.064716
[epoch1, step266]: loss 0.064315
[epoch1, step267]: loss 0.067536
[epoch1, step268]: loss 0.062794
[epoch1, step269]: loss 0.070356
[epoch1, step270]: loss 0.063967
[epoch1, step271]: loss 0.062256
[epoch1, step272]: loss 0.068541
[epoch1, step273]: loss 0.068537
[epoch1, step274]: loss 0.064584
[epoch1, step275]: loss 0.062996
[epoch1, step276]: loss 0.067231
[epoch1, step277]: loss 0.063153
[epoch1, step278]: loss 0.069935
[epoch1, step279]: loss 0.063548
[epoch1, step280]: loss 0.061368
[epoch1, step281]: loss 0.067505
[epoch1, step282]: loss 0.069062
[epoch1, step283]: loss 0.062419
[epoch1, step284]: loss 0.062250
[epoch1, step285]: loss 0.068685
[epoch1, step286]: loss 0.060476
[epoch1, step287]: loss 0.069331
[epoch1, step288]: loss 0.062850
[epoch1, step289]: loss 0.062526
[epoch1, step290]: loss 0.067550
[epoch1, step291]: loss 0.068311
[epoch1, step292]: loss 0.061184
[epoch1, step293]: loss 0.062002
[epoch1, step294]: loss 0.065394
[epoch1, step295]: loss 0.060465
[epoch1, step296]: loss 0.069795
[epoch1, step297]: loss 0.062463
[epoch1, step298]: loss 0.061317
[epoch1, step299]: loss 0.065402
[epoch1, step300]: loss 0.067703
[epoch1, step301]: loss 0.062158
[epoch1, step302]: loss 0.062794
[epoch1, step303]: loss 0.067053
[epoch1, step304]: loss 0.060101
[epoch1, step305]: loss 0.067363
[epoch1, step306]: loss 0.062623
[epoch1, step307]: loss 0.059239
[epoch1, step308]: loss 0.067189
[epoch1, step309]: loss 0.067168
[epoch1, step310]: loss 0.061898
[epoch1, step311]: loss 0.062320
[epoch1, step312]: loss 0.065302
[epoch1, step313]: loss 0.061057
[epoch1, step314]: loss 0.067327
[epoch1, step315]: loss 0.063701
[epoch1, step316]: loss 0.059276
[epoch1, step317]: loss 0.066051
[epoch1, step318]: loss 0.066393
[epoch1, step319]: loss 0.060375
[epoch1, step320]: loss 0.059493
[epoch1, step321]: loss 0.064584
[epoch1, step322]: loss 0.059629
[epoch1, step323]: loss 0.065761
[epoch1, step324]: loss 0.062615
[epoch1, step325]: loss 0.059473
[epoch1, step326]: loss 0.064807
[epoch1, step327]: loss 0.064678
[epoch1, step328]: loss 0.061007
[epoch1, step329]: loss 0.060287
[epoch1, step330]: loss 0.064208
[epoch1, step331]: loss 0.059597
[epoch1, step332]: loss 0.065338
[epoch1, step333]: loss 0.061019
[epoch1, step334]: loss 0.058565
[epoch1, step335]: loss 0.064957
[epoch1, step336]: loss 0.066692
[epoch1, step337]: loss 0.060561
[epoch1, step338]: loss 0.059477
[epoch1, step339]: loss 0.063746
[epoch1, step340]: loss 0.059565
[epoch1, step341]: loss 0.065018
[epoch1, step342]: loss 0.060100
[epoch1, step343]: loss 0.058626
[epoch1, step344]: loss 0.063573
[epoch1, step345]: loss 0.063637
[epoch1, step346]: loss 0.058949
[epoch1, step347]: loss 0.059263
[epoch1, step348]: loss 0.063890
[epoch1, step349]: loss 0.059286
[epoch1, step350]: loss 0.064473
[epoch1, step351]: loss 0.058979
[epoch1, step352]: loss 0.057717
[epoch1, step353]: loss 0.063377
[epoch1, step354]: loss 0.062631
[epoch1, step355]: loss 0.057764
[epoch1, step356]: loss 0.060419
[epoch1, step357]: loss 0.063308
[epoch1, step358]: loss 0.056006
[epoch1, step359]: loss 0.066251
[epoch1, step360]: loss 0.057959
[epoch1, step361]: loss 0.056379
[epoch1, step362]: loss 0.064117
[epoch1, step363]: loss 0.063413
[epoch1, step364]: loss 0.058652
[epoch1, step365]: loss 0.058450
[epoch1, step366]: loss 0.063450
[epoch1, step367]: loss 0.057635
[epoch1, step368]: loss 0.063404
[epoch1, step369]: loss 0.059090
[epoch1, step370]: loss 0.057997
[epoch1, step371]: loss 0.064125
[epoch1, step372]: loss 0.062701
[epoch1, step373]: loss 0.057642
[epoch1, step374]: loss 0.057253
[epoch1, step375]: loss 0.063208
[epoch1, step376]: loss 0.057262
[epoch1, step377]: loss 0.064189
[epoch1, step378]: loss 0.059525
[epoch1, step379]: loss 0.057588
[epoch1, step380]: loss 0.063235
[epoch1, step381]: loss 0.062402
[epoch1, step382]: loss 0.058579
[epoch1, step383]: loss 0.056601
[epoch1, step384]: loss 0.060981
[epoch1, step385]: loss 0.056876
[epoch1, step386]: loss 0.063762
[epoch1, step387]: loss 0.058658
[epoch1, step388]: loss 0.057426
[epoch1, step389]: loss 0.062058
[epoch1, step390]: loss 0.063733
[epoch1, step391]: loss 0.057144
[epoch1, step392]: loss 0.058534
[epoch1, step393]: loss 0.060611
[epoch1, step394]: loss 0.056581
[epoch1, step395]: loss 0.062684
[epoch1, step396]: loss 0.058318
[epoch1, step397]: loss 0.055444
[epoch1, step398]: loss 0.061813
[epoch1, step399]: loss 0.061924
[epoch1, step400]: loss 0.056911
[epoch1, step401]: loss 0.056983
[epoch1, step402]: loss 0.060562
[epoch1, step403]: loss 0.056112
[epoch1, step404]: loss 0.063135
[epoch1, step405]: loss 0.058100
[epoch1, step406]: loss 0.055980
[epoch1, step407]: loss 0.060786
[epoch1, step408]: loss 0.061733
[epoch1, step409]: loss 0.058912
[epoch1, step410]: loss 0.057938
[epoch1, step411]: loss 0.060536
[epoch1, step412]: loss 0.055056
[epoch1, step413]: loss 0.062127
[epoch1, step414]: loss 0.056853
[epoch1, step415]: loss 0.055774
[epoch1, step416]: loss 0.059886
[epoch1, step417]: loss 0.061684
[epoch1, step418]: loss 0.056402
[epoch1, step419]: loss 0.055440
[epoch1, step420]: loss 0.060740
[epoch1, step421]: loss 0.055022
[epoch1, step422]: loss 0.061820
[epoch1, step423]: loss 0.057238
[epoch1, step424]: loss 0.055251
[epoch1, step425]: loss 0.060744
[epoch1, step426]: loss 0.061504
[epoch1, step427]: loss 0.056693
[epoch1, step428]: loss 0.056042
[epoch1, step429]: loss 0.061084
[epoch1, step430]: loss 0.054952
[epoch1, step431]: loss 0.062100
[epoch1, step432]: loss 0.056639
[epoch1, step433]: loss 0.055717
[epoch1, step434]: loss 0.060082
[epoch1, step435]: loss 0.061274
[epoch1, step436]: loss 0.055359
[epoch1, step437]: loss 0.056338
[epoch1, step438]: loss 0.060543
[epoch1, step439]: loss 0.055281
[epoch1, step440]: loss 0.061102
[epoch1, step441]: loss 0.056992
[epoch1, step442]: loss 0.054243
[epoch1, step443]: loss 0.060527
[epoch1, step444]: loss 0.060013
[epoch1, step445]: loss 0.056434
[epoch1, step446]: loss 0.056399
[epoch1, step447]: loss 0.060678
[epoch1, step448]: loss 0.054867
[epoch1, step449]: loss 0.060664
[epoch1, step450]: loss 0.055085
[epoch1, step451]: loss 0.053693
[epoch1, step452]: loss 0.057678
[epoch1, step453]: loss 0.060204
[epoch1, step454]: loss 0.055225
[epoch1, step455]: loss 0.055604
[epoch1, step456]: loss 0.057585
[epoch1, step457]: loss 0.055329
[epoch1, step458]: loss 0.060073
[epoch1, step459]: loss 0.056849
[epoch1, step460]: loss 0.053987
[epoch1, step461]: loss 0.060302
[epoch1, step462]: loss 0.058680
[epoch1, step463]: loss 0.055437
[epoch1, step464]: loss 0.054941
[epoch1, step465]: loss 0.060660
[epoch1, step466]: loss 0.053809
[epoch1, step467]: loss 0.059727
[epoch1, step468]: loss 0.055461
[epoch1, step469]: loss 0.053686
[epoch1, step470]: loss 0.059285
[epoch1, step471]: loss 0.058622
[epoch1, step472]: loss 0.055433
[epoch1, step473]: loss 0.054184
[epoch1, step474]: loss 0.058424
[epoch1, step475]: loss 0.054000
[epoch1, step476]: loss 0.060660
[epoch1, step477]: loss 0.055096
[epoch1, step478]: loss 0.052594
[epoch1, step479]: loss 0.058277
[epoch1, step480]: loss 0.057585
[epoch1, step481]: loss 0.053767
[epoch1, step482]: loss 0.053590
[epoch1, step483]: loss 0.058761
[epoch1, step484]: loss 0.053827
[epoch1, step485]: loss 0.059846
[epoch1, step486]: loss 0.055622
[epoch1, step487]: loss 0.052027
[epoch1, step488]: loss 0.058818
[epoch1, step489]: loss 0.057686
[epoch1, step490]: loss 0.054775
[epoch1, step491]: loss 0.054426
[epoch1, step492]: loss 0.057325
[epoch1, step493]: loss 0.052719
[epoch1, step494]: loss 0.058368
[epoch1, step495]: loss 0.056466
[epoch1, step496]: loss 0.052699
[epoch1, step497]: loss 0.058012
[epoch1, step498]: loss 0.057946
[epoch1, step499]: loss 0.054423
[epoch1, step500]: loss 0.053364
[epoch1, step501]: loss 0.056856
[epoch1, step502]: loss 0.052728
[epoch1, step503]: loss 0.059243
[epoch1, step504]: loss 0.054120
[epoch1, step505]: loss 0.051368
[epoch1, step506]: loss 0.058257
[epoch1, step507]: loss 0.058331
[epoch1, step508]: loss 0.054538
[epoch1, step509]: loss 0.053605
[epoch1, step510]: loss 0.057434
[epoch1, step511]: loss 0.053128
[epoch1, step512]: loss 0.059165
[epoch1, step513]: loss 0.054406
[epoch1, step514]: loss 0.052641
[epoch1, step515]: loss 0.057365
[epoch1, step516]: loss 0.058433
[epoch1, step517]: loss 0.053460
[epoch1, step518]: loss 0.053574
[epoch1, step519]: loss 0.056919
[epoch1, step520]: loss 0.051711
[epoch1, step521]: loss 0.057780
[epoch1, step522]: loss 0.053023
[epoch1, step523]: loss 0.051930
[epoch1, step524]: loss 0.056139
[epoch1, step525]: loss 0.057966
[epoch1, step526]: loss 0.053412
[epoch1, step527]: loss 0.052813
[epoch1, step528]: loss 0.056998
[epoch1, step529]: loss 0.051415
[epoch1, step530]: loss 0.058679
[epoch1, step531]: loss 0.053470
[epoch1, step532]: loss 0.051000
[epoch1, step533]: loss 0.058265
[epoch1, step534]: loss 0.057157
[epoch1, step535]: loss 0.053513
[epoch1, step536]: loss 0.053099
[epoch1, step537]: loss 0.056435
[epoch1, step538]: loss 0.052078
[epoch1, step539]: loss 0.057488
[epoch1, step540]: loss 0.052838
[epoch1, step541]: loss 0.050736
[epoch1, step542]: loss 0.056539
[epoch1, step543]: loss 0.056441
[epoch1, step544]: loss 0.052574
[epoch1, step545]: loss 0.051562
[epoch1, step546]: loss 0.056958
[epoch1, step547]: loss 0.051195
[epoch1, step548]: loss 0.057363
[epoch1, step549]: loss 0.053586
[epoch1, step550]: loss 0.051183
[epoch1, step551]: loss 0.056140
[epoch1, step552]: loss 0.055875
[epoch1, step553]: loss 0.053128
[epoch1, step554]: loss 0.052188
[epoch1, step555]: loss 0.055555
[epoch1, step556]: loss 0.051331
[epoch1, step557]: loss 0.056443
[epoch1, step558]: loss 0.053312
[epoch1, step559]: loss 0.050090
[epoch1, step560]: loss 0.056072
[epoch1, step561]: loss 0.056266
[epoch1, step562]: loss 0.052222
[epoch1, step563]: loss 0.035837
[epoch1, step564]: loss 0.031883
[epoch1, step565]: loss 0.030826
[epoch1, step566]: loss 0.039083
[epoch1, step567]: loss 0.030358
[epoch1, step568]: loss 0.030278
[epoch1, step569]: loss 0.027360
[epoch1, step570]: loss 0.036466
[epoch1, step571]: loss 0.032210
[epoch1, step572]: loss 0.030494
[epoch1, step573]: loss 0.034021
[epoch1, step574]: loss 0.032176
[epoch1, step575]: loss 0.024398
[epoch1, step576]: loss 0.025492
[epoch1, step577]: loss 0.030678
[epoch1, step578]: loss 0.022557
[epoch1, step579]: loss 0.033402
[epoch1, step580]: loss 0.024038
[epoch1, step581]: loss 0.030506
[epoch1, step582]: loss 0.030095
[epoch1, step583]: loss 0.025760
[epoch1, step584]: loss 0.028089
[epoch1, step585]: loss 0.031007
[epoch1, step586]: loss 0.025733
[epoch1, step587]: loss 0.033036
[epoch1, step588]: loss 0.027216
[epoch1, step589]: loss 0.027206
[epoch1, step590]: loss 0.033235
[epoch1, step591]: loss 0.024503
[epoch1, step592]: loss 0.030873
[epoch1, step593]: loss 0.026668
[epoch1, step594]: loss 0.030825
[epoch1, step595]: loss 0.031877
[epoch1, step596]: loss 0.026534
[epoch1, step597]: loss 0.029867
[epoch1, step598]: loss 0.031645
[epoch1, step599]: loss 0.030072
[epoch1, step600]: loss 0.032974
[epoch1, step601]: loss 0.022569
[epoch1, step602]: loss 0.026525
[epoch1, step603]: loss 0.031091
[epoch1, step604]: loss 0.031690
[epoch1, step605]: loss 0.029975
[epoch1, step606]: loss 0.029252
[epoch1, step607]: loss 0.033381
[epoch1, step608]: loss 0.030821
[epoch1, step609]: loss 0.032106
[epoch1, step610]: loss 0.030147
[epoch1, step611]: loss 0.031352
[epoch1, step612]: loss 0.030880
[epoch1, step613]: loss 0.022517
[epoch1, step614]: loss 0.030179
[epoch1, step615]: loss 0.033999
[epoch1, step616]: loss 0.028444
[epoch1, step617]: loss 0.027957
[epoch1, step618]: loss 0.030611
[epoch1, step619]: loss 0.031504
[epoch1, step620]: loss 0.028934
[epoch1, step621]: loss 0.031135
[epoch1, step622]: loss 0.023988
[epoch1, step623]: loss 0.029064
[epoch1, step624]: loss 0.031358
[epoch1, step625]: loss 0.031371
[epoch1, step626]: loss 0.034063
[epoch1, step627]: loss 0.027085
[epoch1, step628]: loss 0.031348
[epoch1, step629]: loss 0.024298
[epoch1, step630]: loss 0.027524
[epoch1, step631]: loss 0.037162
[epoch1, step632]: loss 0.027810
[epoch1, step633]: loss 0.029224
[epoch1, step634]: loss 0.031723
[epoch1, step635]: loss 0.030432
[epoch1, step636]: loss 0.023871
[epoch1, step637]: loss 0.032622
[epoch1, step638]: loss 0.032206
[epoch1, step639]: loss 0.027018
[epoch1, step640]: loss 0.034744
[epoch1, step641]: loss 0.036218
[epoch1, step642]: loss 0.029399
[epoch1, step643]: loss 0.030377
[epoch1, step644]: loss 0.031071
[epoch1, step645]: loss 0.027811
[epoch1, step646]: loss 0.031641
[epoch1, step647]: loss 0.027925
[epoch1, step648]: loss 0.027293
[epoch1, step649]: loss 0.034513
[epoch1, step650]: loss 0.026141
[epoch1, step651]: loss 0.030896
[epoch1, step652]: loss 0.032005
[epoch1, step653]: loss 0.033362
[epoch1, step654]: loss 0.027370
[epoch1, step655]: loss 0.028402
[epoch1, step656]: loss 0.025007
[epoch1, step657]: loss 0.033318
[epoch1, step658]: loss 0.029927
[epoch1, step659]: loss 0.032797
[epoch1, step660]: loss 0.027649
[epoch1, step661]: loss 0.031988
[epoch1, step662]: loss 0.027856
[epoch1, step663]: loss 0.024888
[epoch1, step664]: loss 0.029400
[epoch1, step665]: loss 0.033154
[epoch1, step666]: loss 0.032007
[epoch1, step667]: loss 0.031382
[epoch1, step668]: loss 0.026388
[epoch1, step669]: loss 0.030820
[epoch1, step670]: loss 0.031877
[epoch1, step671]: loss 0.024141
[epoch1, step672]: loss 0.027848
[epoch1, step673]: loss 0.025859
[epoch1, step674]: loss 0.024665
[epoch1, step675]: loss 0.023116
[epoch1, step676]: loss 0.028573
[epoch1, step677]: loss 0.029975
[epoch1, step678]: loss 0.027336
[epoch1, step679]: loss 0.027811
[epoch1, step680]: loss 0.036307
[epoch1, step681]: loss 0.025763
[epoch1, step682]: loss 0.030620
[epoch1, step683]: loss 0.030263
[epoch1, step684]: loss 0.029404
[epoch1, step685]: loss 0.027807
[epoch1, step686]: loss 0.032501
[epoch1, step687]: loss 0.031746
[epoch1, step688]: loss 0.026925
[epoch1, step689]: loss 0.028354
[epoch1, step690]: loss 0.029681
[epoch1, step691]: loss 0.028628
[epoch1, step692]: loss 0.026514
[epoch1, step693]: loss 0.032888
[epoch1, step694]: loss 0.026622
[epoch1, step695]: loss 0.031401
[epoch1, step696]: loss 0.030379
[epoch1, step697]: loss 0.032169
[epoch1, step698]: loss 0.029188
[epoch1, step699]: loss 0.027127
[epoch1, step700]: loss 0.025291
[epoch1, step701]: loss 0.030446
[epoch1, step702]: loss 0.025218
[epoch1, step703]: loss 0.027030
[epoch1, step704]: loss 0.030449
[epoch1, step705]: loss 0.028824
[epoch1, step706]: loss 0.028017
[epoch1, step707]: loss 0.028029
[epoch1, step708]: loss 0.030542
[epoch1, step709]: loss 0.032197
[epoch1, step710]: loss 0.028212
[epoch1, step711]: loss 0.027869
[epoch1, step712]: loss 0.031147
[epoch1, step713]: loss 0.031152
[epoch1, step714]: loss 0.024775
[epoch1, step715]: loss 0.026818
[epoch1, step716]: loss 0.030697
[epoch1, step717]: loss 0.027466
[epoch1, step718]: loss 0.028837
[epoch1, step719]: loss 0.039109
[epoch1, step720]: loss 0.029110
[epoch1, step721]: loss 0.027040
[epoch1, step722]: loss 0.037072
[epoch1, step723]: loss 0.031276
[epoch1, step724]: loss 0.026780
[epoch1, step725]: loss 0.033551
[epoch1, step726]: loss 0.025581
[epoch1, step727]: loss 0.028231
[epoch1, step728]: loss 0.030890
[epoch1, step729]: loss 0.024712
[epoch1, step730]: loss 0.026141
[epoch1, step731]: loss 0.030659
[epoch1, step732]: loss 0.029998
[epoch1, step733]: loss 0.027781
[epoch1, step734]: loss 0.026886
[epoch1, step735]: loss 0.031621
[epoch1, step736]: loss 0.028907
[epoch1, step737]: loss 0.030805
[epoch1, step738]: loss 0.023806
[epoch1, step739]: loss 0.029491
[epoch1, step740]: loss 0.026358
[epoch1, step741]: loss 0.029123
[epoch1, step742]: loss 0.025562
[epoch1, step743]: loss 0.026996
[epoch1, step744]: loss 0.027578
[epoch1, step745]: loss 0.028910
[epoch1, step746]: loss 0.029750
[epoch1, step747]: loss 0.032308
[epoch1, step748]: loss 0.029883
[epoch1, step749]: loss 0.030616
[epoch1, step750]: loss 0.032448
[epoch1, step751]: loss 0.024831
[epoch1, step752]: loss 0.028863
[epoch1, step753]: loss 0.029910
[epoch1, step754]: loss 0.026239
[epoch1, step755]: loss 0.030619
[epoch1, step756]: loss 0.026887
[epoch1, step757]: loss 0.023784
[epoch1, step758]: loss 0.028951
[epoch1, step759]: loss 0.026852
[epoch1, step760]: loss 0.028061
[epoch1, step761]: loss 0.030293
[epoch1, step762]: loss 0.024793
[epoch1, step763]: loss 0.029865
[epoch1, step764]: loss 0.028118
[epoch1, step765]: loss 0.030308
[epoch1, step766]: loss 0.028596
[epoch1, step767]: loss 0.031503
[epoch1, step768]: loss 0.024566
[epoch1, step769]: loss 0.031190
[epoch1, step770]: loss 0.030560
[epoch1, step771]: loss 0.026555
[epoch1, step772]: loss 0.033695
[epoch1, step773]: loss 0.030448
[epoch1, step774]: loss 0.027146
[epoch1, step775]: loss 0.023708
[epoch1, step776]: loss 0.030188
[epoch1, step777]: loss 0.025977
[epoch1, step778]: loss 0.033320
[epoch1, step779]: loss 0.027875
[epoch1, step780]: loss 0.022805
[epoch1, step781]: loss 0.028368
[epoch1, step782]: loss 0.025895
[epoch1, step783]: loss 0.022180
[epoch1, step784]: loss 0.023316
[epoch1, step785]: loss 0.023993
[epoch1, step786]: loss 0.027952
[epoch1, step787]: loss 0.027025
[epoch1, step788]: loss 0.028321
[epoch1, step789]: loss 0.025988
[epoch1, step790]: loss 0.026808
[epoch1, step791]: loss 0.030849
[epoch1, step792]: loss 0.028817
[epoch1, step793]: loss 0.031461
[epoch1, step794]: loss 0.023162
[epoch1, step795]: loss 0.029681
[epoch1, step796]: loss 0.032199
[epoch1, step797]: loss 0.032538
[epoch1, step798]: loss 0.031347
[epoch1, step799]: loss 0.029250
[epoch1, step800]: loss 0.024691
[epoch1, step801]: loss 0.024980
[epoch1, step802]: loss 0.026188
[epoch1, step803]: loss 0.030087
[epoch1, step804]: loss 0.031881
[epoch1, step805]: loss 0.033921
[epoch1, step806]: loss 0.024548
[epoch1, step807]: loss 0.023470
[epoch1, step808]: loss 0.026436
[epoch1, step809]: loss 0.026314
[epoch1, step810]: loss 0.029875
[epoch1, step811]: loss 0.029967
[epoch1, step812]: loss 0.028476
[epoch1, step813]: loss 0.027363
[epoch1, step814]: loss 0.028870
[epoch1, step815]: loss 0.028518
[epoch1, step816]: loss 0.028095
[epoch1, step817]: loss 0.028543
[epoch1, step818]: loss 0.025526
[epoch1, step819]: loss 0.023349
[epoch1, step820]: loss 0.027086
[epoch1, step821]: loss 0.024900
[epoch1, step822]: loss 0.036164
[epoch1, step823]: loss 0.027536
[epoch1, step824]: loss 0.030660
[epoch1, step825]: loss 0.029209
[epoch1, step826]: loss 0.027962
[epoch1, step827]: loss 0.030742
[epoch1, step828]: loss 0.033351
[epoch1, step829]: loss 0.030054
[epoch1, step830]: loss 0.025853
[epoch1, step831]: loss 0.029925
[epoch1, step832]: loss 0.023710
[epoch1, step833]: loss 0.033830
[epoch1, step834]: loss 0.029853
[epoch1, step835]: loss 0.023374
[epoch1, step836]: loss 0.030953
[epoch1, step837]: loss 0.028918
[epoch1, step838]: loss 0.029995
[epoch1, step839]: loss 0.032875
[epoch1, step840]: loss 0.023074
[epoch1, step841]: loss 0.027527
[epoch1, step842]: loss 0.032004
[epoch1, step843]: loss 0.029250
[epoch1, step844]: loss 0.029162
[epoch1, step845]: loss 0.023852
[epoch1, step846]: loss 0.029416
[epoch1, step847]: loss 0.031361
[epoch1, step848]: loss 0.029161
[epoch1, step849]: loss 0.028894
[epoch1, step850]: loss 0.026618
[epoch1, step851]: loss 0.027434
[epoch1, step852]: loss 0.025986
[epoch1, step853]: loss 0.034200
[epoch1, step854]: loss 0.025252
[epoch1, step855]: loss 0.031147
[epoch1, step856]: loss 0.025203
[epoch1, step857]: loss 0.030147
[epoch1, step858]: loss 0.027564
[epoch1, step859]: loss 0.026703
[epoch1, step860]: loss 0.025505
[epoch1, step861]: loss 0.026640
[epoch1, step862]: loss 0.025999
[epoch1, step863]: loss 0.023144
[epoch1, step864]: loss 0.030546
[epoch1, step865]: loss 0.026615
[epoch1, step866]: loss 0.028618
[epoch1, step867]: loss 0.029898
[epoch1, step868]: loss 0.030570
[epoch1, step869]: loss 0.026642
[epoch1, step870]: loss 0.035743
[epoch1, step871]: loss 0.025120
[epoch1, step872]: loss 0.029136
[epoch1, step873]: loss 0.029502
[epoch1, step874]: loss 0.026612
[epoch1, step875]: loss 0.027761
[epoch1, step876]: loss 0.027857
[epoch1, step877]: loss 0.021260
[epoch1, step878]: loss 0.026576
[epoch1, step879]: loss 0.032228
[epoch1, step880]: loss 0.029018
[epoch1, step881]: loss 0.024991
[epoch1, step882]: loss 0.028005
[epoch1, step883]: loss 0.027766
[epoch1, step884]: loss 0.029999
[epoch1, step885]: loss 0.029482
[epoch1, step886]: loss 0.029998
[epoch1, step887]: loss 0.026877
[epoch1, step888]: loss 0.028044
[epoch1, step889]: loss 0.027069
[epoch1, step890]: loss 0.026832
[epoch1, step891]: loss 0.028890
[epoch1, step892]: loss 0.023590
[epoch1, step893]: loss 0.027375
[epoch1, step894]: loss 0.027785
[epoch1, step895]: loss 0.025792
[epoch1, step896]: loss 0.024817
[epoch1, step897]: loss 0.027422
[epoch1, step898]: loss 0.029295
[epoch1, step899]: loss 0.032274
[epoch1, step900]: loss 0.031013
[epoch1, step901]: loss 0.029336
[epoch1, step902]: loss 0.027094
[epoch1, step903]: loss 0.027929
[epoch1, step904]: loss 0.032534
[epoch1, step905]: loss 0.032054
[epoch1, step906]: loss 0.025174
[epoch1, step907]: loss 0.026202
[epoch1, step908]: loss 0.025655
[epoch1, step909]: loss 0.029311
[epoch1, step910]: loss 0.026187
[epoch1, step911]: loss 0.028706
[epoch1, step912]: loss 0.026808
[epoch1, step913]: loss 0.027684
[epoch1, step914]: loss 0.035492
[epoch1, step915]: loss 0.027387
[epoch1, step916]: loss 0.026561
[epoch1, step917]: loss 0.028476
[epoch1, step918]: loss 0.032111
[epoch1, step919]: loss 0.026838
[epoch1, step920]: loss 0.030849
[epoch1, step921]: loss 0.027709
[epoch1, step922]: loss 0.026128
[epoch1, step923]: loss 0.025629
[epoch1, step924]: loss 0.023756
[epoch1, step925]: loss 0.028950
[epoch1, step926]: loss 0.030267
[epoch1, step927]: loss 0.029258
[epoch1, step928]: loss 0.028539
[epoch1, step929]: loss 0.031547
[epoch1, step930]: loss 0.029513
[epoch1, step931]: loss 0.031762
[epoch1, step932]: loss 0.024495
[epoch1, step933]: loss 0.032600
[epoch1, step934]: loss 0.024979
[epoch1, step935]: loss 0.024967
[epoch1, step936]: loss 0.025560
[epoch1, step937]: loss 0.031478
[epoch1, step938]: loss 0.028497
[epoch1, step939]: loss 0.023147
[epoch1, step940]: loss 0.025856
[epoch1, step941]: loss 0.030435
[epoch1, step942]: loss 0.028999
[epoch1, step943]: loss 0.026347
[epoch1, step944]: loss 0.031544
[epoch1, step945]: loss 0.022436
[epoch1, step946]: loss 0.029035
[epoch1, step947]: loss 0.031750
[epoch1, step948]: loss 0.021909
[epoch1, step949]: loss 0.025397
[epoch1, step950]: loss 0.029660
[epoch1, step951]: loss 0.032916
[epoch1, step952]: loss 0.028420
[epoch1, step953]: loss 0.031474
[epoch1, step954]: loss 0.024914
[epoch1, step955]: loss 0.039287
[epoch1, step956]: loss 0.054887
[epoch1, step957]: loss 0.049198
[epoch1, step958]: loss 0.047591
[epoch1, step959]: loss 0.052844
[epoch1, step960]: loss 0.049473
[epoch1, step961]: loss 0.050932
[epoch1, step962]: loss 0.050085
[epoch1, step963]: loss 0.049063
[epoch1, step964]: loss 0.050281
[epoch1, step965]: loss 0.051957
[epoch1, step966]: loss 0.048843
[epoch1, step967]: loss 0.047656
[epoch1, step968]: loss 0.051701
[epoch1, step969]: loss 0.050584
[epoch1, step970]: loss 0.050260
[epoch1, step971]: loss 0.049312
[epoch1, step972]: loss 0.049917
[epoch1, step973]: loss 0.048759
[epoch1, step974]: loss 0.053216
[epoch1, step975]: loss 0.048754
[epoch1, step976]: loss 0.046995
[epoch1, step977]: loss 0.052148
[epoch1, step978]: loss 0.049639
[epoch1, step979]: loss 0.049457
[epoch1, step980]: loss 0.048146
[epoch1, step981]: loss 0.048843
[epoch1, step982]: loss 0.049243
[epoch1, step983]: loss 0.052158
[epoch1, step984]: loss 0.047222
[epoch1, step985]: loss 0.047283
[epoch1, step986]: loss 0.052318
[epoch1, step987]: loss 0.049864
[epoch1, step988]: loss 0.050301
[epoch1, step989]: loss 0.049419
[epoch1, step990]: loss 0.048571
[epoch1, step991]: loss 0.049673
[epoch1, step992]: loss 0.051523
[epoch1, step993]: loss 0.048156
[epoch1, step994]: loss 0.046532
[epoch1, step995]: loss 0.051326
[epoch1, step996]: loss 0.048728
[epoch1, step997]: loss 0.049689
[epoch1, step998]: loss 0.049431
[epoch1, step999]: loss 0.048918
[epoch1, step1000]: loss 0.049167
[epoch1, step1001]: loss 0.051745
[epoch1, step1002]: loss 0.048446
[epoch1, step1003]: loss 0.046925
[epoch1, step1004]: loss 0.051170
[epoch1, step1005]: loss 0.048038
[epoch1, step1006]: loss 0.049533
[epoch1, step1007]: loss 0.048036
[epoch1, step1008]: loss 0.047969
[epoch1, step1009]: loss 0.048713
[epoch1, step1010]: loss 0.052115
[epoch1, step1011]: loss 0.047824
[epoch1, step1012]: loss 0.047455
[epoch1, step1013]: loss 0.051182
[epoch1, step1014]: loss 0.049650
[epoch1, step1015]: loss 0.049836
[epoch1, step1016]: loss 0.047864
[epoch1, step1017]: loss 0.047852
[epoch1, step1018]: loss 0.048321
[epoch1, step1019]: loss 0.051595
[epoch1, step1020]: loss 0.047306
[epoch1, step1021]: loss 0.046296
[epoch1, step1022]: loss 0.050581
[epoch1, step1023]: loss 0.048526
[epoch1, step1024]: loss 0.050096
[epoch1, step1025]: loss 0.047522
[epoch1, step1026]: loss 0.047240
[epoch1, step1027]: loss 0.048010
[epoch1, step1028]: loss 0.051058
[epoch1, step1029]: loss 0.047278
[epoch1, step1030]: loss 0.045931
[epoch1, step1031]: loss 0.049085
[epoch1, step1032]: loss 0.048763
[epoch1, step1033]: loss 0.048492
[epoch1, step1034]: loss 0.047561
[epoch1, step1035]: loss 0.047079
[epoch1, step1036]: loss 0.048406
[epoch1, step1037]: loss 0.050695
[epoch1, step1038]: loss 0.047145
[epoch1, step1039]: loss 0.046682
[epoch1, step1040]: loss 0.049733
[epoch1, step1041]: loss 0.048015
[epoch1, step1042]: loss 0.047737
[epoch1, step1043]: loss 0.047521
[epoch1, step1044]: loss 0.047710
[epoch1, step1045]: loss 0.048250
[epoch1, step1046]: loss 0.051025
[epoch1, step1047]: loss 0.047440
[epoch1, step1048]: loss 0.045938
[epoch1, step1049]: loss 0.050313
[epoch1, step1050]: loss 0.048443
[epoch1, step1051]: loss 0.048856
[epoch1, step1052]: loss 0.048189
[epoch1, step1053]: loss 0.048201
[epoch1, step1054]: loss 0.048100
[epoch1, step1055]: loss 0.050038
[epoch1, step1056]: loss 0.046513
[epoch1, step1057]: loss 0.047021
[epoch1, step1058]: loss 0.051123
[epoch1, step1059]: loss 0.048430
[epoch1, step1060]: loss 0.048873
[epoch1, step1061]: loss 0.046824
[epoch1, step1062]: loss 0.048057
[epoch1, step1063]: loss 0.048046
[epoch1, step1064]: loss 0.050647
[epoch1, step1065]: loss 0.047000
[epoch1, step1066]: loss 0.045622
[epoch1, step1067]: loss 0.050139
[epoch1, step1068]: loss 0.046430
[epoch1, step1069]: loss 0.047800
[epoch1, step1070]: loss 0.047402
[epoch1, step1071]: loss 0.048087
[epoch1, step1072]: loss 0.048740
[epoch1, step1073]: loss 0.050167
[epoch1, step1074]: loss 0.046967
[epoch1, step1075]: loss 0.046441
[epoch1, step1076]: loss 0.049942
[epoch1, step1077]: loss 0.047835
[epoch1, step1078]: loss 0.048141
[epoch1, step1079]: loss 0.048603
[epoch1, step1080]: loss 0.047420
[epoch1, step1081]: loss 0.047478
[epoch1, step1082]: loss 0.050146
[epoch1, step1083]: loss 0.047688
[epoch1, step1084]: loss 0.046295
[epoch1, step1085]: loss 0.049273
[epoch1, step1086]: loss 0.047486
[epoch1, step1087]: loss 0.048496
[epoch1, step1088]: loss 0.047106
[epoch1, step1089]: loss 0.047753
[epoch1, step1090]: loss 0.048315
[epoch1, step1091]: loss 0.050752
[epoch1, step1092]: loss 0.046744
[epoch1, step1093]: loss 0.045816
[epoch1, step1094]: loss 0.048640
[epoch1, step1095]: loss 0.047243
[epoch1, step1096]: loss 0.047721
[epoch1, step1097]: loss 0.047198
[epoch1, step1098]: loss 0.047077
[epoch1, step1099]: loss 0.047226
[epoch1, step1100]: loss 0.050932
[epoch1, step1101]: loss 0.047212
[epoch1, step1102]: loss 0.045814
[epoch1, step1103]: loss 0.049078
[epoch1, step1104]: loss 0.047385
[epoch1, step1105]: loss 0.048328
[epoch1, step1106]: loss 0.045961
[epoch1, step1107]: loss 0.047260
[epoch1, step1108]: loss 0.047016
[epoch1, step1109]: loss 0.050417
[epoch1, step1110]: loss 0.047364
[epoch1, step1111]: loss 0.045947
[epoch1, step1112]: loss 0.049946
[epoch1, step1113]: loss 0.047013
[epoch1, step1114]: loss 0.048392
[epoch1, step1115]: loss 0.047006
[epoch1, step1116]: loss 0.047140
[epoch1, step1117]: loss 0.047489
[epoch1, step1118]: loss 0.049926
[epoch1, step1119]: loss 0.046278
[epoch1, step1120]: loss 0.045456
[epoch1, step1121]: loss 0.049325
[epoch1, step1122]: loss 0.046753
[epoch1, step1123]: loss 0.047064
[epoch1, step1124]: loss 0.047673
[epoch1, step1125]: loss 0.047283
[epoch1, step1126]: loss 0.048402
[epoch1, step1127]: loss 0.049907
[epoch1, step1128]: loss 0.046645
[epoch1, step1129]: loss 0.045395
[epoch1, step1130]: loss 0.049937
[epoch1, step1131]: loss 0.047651
[epoch1, step1132]: loss 0.048296
[epoch1, step1133]: loss 0.046234
[epoch1, step1134]: loss 0.046543
[epoch1, step1135]: loss 0.048271
[epoch1, step1136]: loss 0.050481
[epoch1, step1137]: loss 0.046441
[epoch1, step1138]: loss 0.045604
[epoch1, step1139]: loss 0.049231
[epoch1, step1140]: loss 0.046269
[epoch1, step1141]: loss 0.047367
[epoch1, step1142]: loss 0.046425
[epoch1, step1143]: loss 0.046181
[epoch1, step1144]: loss 0.047255
[epoch1, step1145]: loss 0.049023
[epoch1, step1146]: loss 0.045851
[epoch1, step1147]: loss 0.046248
[epoch1, step1148]: loss 0.049225
[epoch1, step1149]: loss 0.046655
[epoch1, step1150]: loss 0.047262
[epoch1, step1151]: loss 0.046814
[epoch1, step1152]: loss 0.047129
[epoch1, step1153]: loss 0.046221
[epoch1, step1154]: loss 0.049871
[epoch1, step1155]: loss 0.046188
[epoch1, step1156]: loss 0.044423
[epoch1, step1157]: loss 0.048676
[epoch1, step1158]: loss 0.047106
[epoch1, step1159]: loss 0.047589
[epoch1, step1160]: loss 0.047318
[epoch1, step1161]: loss 0.046996
[epoch1, step1162]: loss 0.046678
[epoch1, step1163]: loss 0.048593
[epoch1, step1164]: loss 0.045762
[epoch1, step1165]: loss 0.046247
[epoch1, step1166]: loss 0.048808
[epoch1, step1167]: loss 0.045851
[epoch1, step1168]: loss 0.047462
[epoch1, step1169]: loss 0.045937
[epoch1, step1170]: loss 0.046358
[epoch1, step1171]: loss 0.046484
[epoch1, step1172]: loss 0.049316
[epoch1, step1173]: loss 0.046053
[epoch1, step1174]: loss 0.045583
[epoch1, step1175]: loss 0.048594
[epoch1, step1176]: loss 0.046131
[epoch1, step1177]: loss 0.049415
[epoch1, step1178]: loss 0.046365
[epoch1, step1179]: loss 0.045988
[epoch1, step1180]: loss 0.046879
[epoch1, step1181]: loss 0.049946
[epoch1, step1182]: loss 0.045133
[epoch1, step1183]: loss 0.045603
[epoch1, step1184]: loss 0.048184
[epoch1, step1185]: loss 0.046686
[epoch1, step1186]: loss 0.046381
[epoch1, step1187]: loss 0.045255
[epoch1, step1188]: loss 0.045579
[epoch1, step1189]: loss 0.046230
[epoch1, step1190]: loss 0.048634
[epoch1, step1191]: loss 0.046503
[epoch1, step1192]: loss 0.044893
[epoch1, step1193]: loss 0.048298
[epoch1, step1194]: loss 0.046239
[epoch1, step1195]: loss 0.045711
[epoch1, step1196]: loss 0.045174
[epoch1, step1197]: loss 0.046394
[epoch1, step1198]: loss 0.046409
[epoch1, step1199]: loss 0.048388
[epoch1, step1200]: loss 0.045182
[epoch1, step1201]: loss 0.045166
[epoch1, step1202]: loss 0.049161
[epoch1, step1203]: loss 0.046272
[epoch1, step1204]: loss 0.046074
[epoch1, step1205]: loss 0.045282
[epoch1, step1206]: loss 0.045359
[epoch1, step1207]: loss 0.047418
[epoch1, step1208]: loss 0.048864
[epoch1, step1209]: loss 0.044119
[epoch1, step1210]: loss 0.045105
[epoch1, step1211]: loss 0.047651
[epoch1, step1212]: loss 0.045821
[epoch1, step1213]: loss 0.046313
[epoch1, step1214]: loss 0.046041
[epoch1, step1215]: loss 0.046587
[epoch1, step1216]: loss 0.045727
[epoch1, step1217]: loss 0.049213
[epoch1, step1218]: loss 0.044908
[epoch1, step1219]: loss 0.045229
[epoch1, step1220]: loss 0.048349
[epoch1, step1221]: loss 0.045029
[epoch1, step1222]: loss 0.046604
[epoch1, step1223]: loss 0.045496
[epoch1, step1224]: loss 0.046110
[epoch1, step1225]: loss 0.046132
[epoch1, step1226]: loss 0.048201
[epoch1, step1227]: loss 0.045140
[epoch1, step1228]: loss 0.043897
[epoch1, step1229]: loss 0.047868
[epoch1, step1230]: loss 0.046038
[epoch1, step1231]: loss 0.046269
[epoch1, step1232]: loss 0.046745
[epoch1, step1233]: loss 0.045537
[epoch1, step1234]: loss 0.045640
[epoch1, step1235]: loss 0.049047
[epoch1, step1236]: loss 0.045323
[epoch1, step1237]: loss 0.043935
[epoch1, step1238]: loss 0.047163
[epoch1, step1239]: loss 0.046281
[epoch1, step1240]: loss 0.046645
[epoch1, step1241]: loss 0.044923
[epoch1, step1242]: loss 0.045382
[epoch1, step1243]: loss 0.045601
[epoch1, step1244]: loss 0.048392
[epoch1, step1245]: loss 0.045317
[epoch1, step1246]: loss 0.044555
[epoch1, step1247]: loss 0.046722
[epoch1, step1248]: loss 0.045757
[epoch1, step1249]: loss 0.046711
[epoch1, step1250]: loss 0.045174
[epoch1, step1251]: loss 0.045563
[epoch1, step1252]: loss 0.046692
[epoch1, step1253]: loss 0.048261
[epoch1, step1254]: loss 0.044969
[epoch1, step1255]: loss 0.044308
[epoch1, step1256]: loss 0.048007
[epoch1, step1257]: loss 0.045732
[epoch1, step1258]: loss 0.046235
[epoch1, step1259]: loss 0.044786
[epoch1, step1260]: loss 0.045341
[epoch1, step1261]: loss 0.045367
[epoch1, step1262]: loss 0.046627
[epoch1, step1263]: loss 0.045406
[epoch1, step1264]: loss 0.043991
[epoch1, step1265]: loss 0.046194
[epoch1, step1266]: loss 0.045411
[epoch1, step1267]: loss 0.045984
[epoch1, step1268]: loss 0.045458
[epoch1, step1269]: loss 0.045273
[epoch1, step1270]: loss 0.044892
[epoch1, step1271]: loss 0.048388
[epoch1, step1272]: loss 0.044749
[epoch1, step1273]: loss 0.043842
[epoch1, step1274]: loss 0.046997
[epoch1, step1275]: loss 0.045821
[epoch1, step1276]: loss 0.045531
[epoch1, step1277]: loss 0.044869
[epoch1, step1278]: loss 0.045715
[epoch1, step1279]: loss 0.045464
[epoch1, step1280]: loss 0.047983
[epoch1, step1281]: loss 0.044371
[epoch1, step1282]: loss 0.043551
[epoch1, step1283]: loss 0.046424
[epoch1, step1284]: loss 0.044701
[epoch1, step1285]: loss 0.046187
[epoch1, step1286]: loss 0.044079
[epoch1, step1287]: loss 0.045636
[epoch1, step1288]: loss 0.045993
[epoch1, step1289]: loss 0.048612
[epoch1, step1290]: loss 0.044629
[epoch1, step1291]: loss 0.043644
[epoch1, step1292]: loss 0.047500
[epoch1, step1293]: loss 0.044325
[epoch1, step1294]: loss 0.045539
[epoch1, step1295]: loss 0.045173
[epoch1, step1296]: loss 0.045033
[epoch1, step1297]: loss 0.044838
[epoch1, step1298]: loss 0.048031
[epoch1, step1299]: loss 0.044588
[epoch1, step1300]: loss 0.044319
[epoch1, step1301]: loss 0.046179
[epoch1, step1302]: loss 0.045002
[epoch1, step1303]: loss 0.045751
[epoch1, step1304]: loss 0.044038
[epoch1, step1305]: loss 0.044973
[epoch1, step1306]: loss 0.044762
[epoch1, step1307]: loss 0.046828
[epoch1, step1308]: loss 0.044381
[epoch1, step1309]: loss 0.042871
[epoch1, step1310]: loss 0.046651
[epoch1, step1311]: loss 0.043856
[epoch1, step1312]: loss 0.046127
[epoch1, step1313]: loss 0.044612
[epoch1, step1314]: loss 0.044591
[epoch1, step1315]: loss 0.044605
[epoch1, step1316]: loss 0.048731
[epoch1, step1317]: loss 0.043590
[epoch1, step1318]: loss 0.043005
[epoch1, step1319]: loss 0.046022
[epoch1, step1320]: loss 0.044945
[epoch1, step1321]: loss 0.045757
[epoch1, step1322]: loss 0.044211
[epoch1, step1323]: loss 0.044909
[epoch1, step1324]: loss 0.045119
[epoch1, step1325]: loss 0.047098
[epoch1, step1326]: loss 0.044174
[epoch1, step1327]: loss 0.043738
[epoch1, step1328]: loss 0.047218
[epoch1, step1329]: loss 0.045131
[epoch1, step1330]: loss 0.045771
[epoch1, step1331]: loss 0.044177
[epoch1, step1332]: loss 0.045340
[epoch1, step1333]: loss 0.043936
[epoch1, step1334]: loss 0.047712
[epoch1, step1335]: loss 0.045061
[epoch1, step1336]: loss 0.043746
[epoch1, step1337]: loss 0.046420
[epoch1, step1338]: loss 0.044774
[epoch1, step1339]: loss 0.045464
[epoch1, step1340]: loss 0.044277
[epoch1, step1341]: loss 0.044822
[epoch1, step1342]: loss 0.044611
[epoch1, step1343]: loss 0.047409
[epoch1, step1344]: loss 0.044264
[epoch1, step1345]: loss 0.043196
[epoch1, step1346]: loss 0.046193
[epoch1, step1347]: loss 0.045202
[epoch1, step1348]: loss 0.044629
[epoch1, step1349]: loss 0.044411
[epoch1, step1350]: loss 0.044286
[epoch1, step1351]: loss 0.044250
[epoch1, step1352]: loss 0.046278
[epoch1, step1353]: loss 0.043616
[epoch1, step1354]: loss 0.042915
[epoch1, step1355]: loss 0.046407
[epoch1, step1356]: loss 0.044117
[epoch1, step1357]: loss 0.044399
[epoch1, step1358]: loss 0.043931
[epoch1, step1359]: loss 0.043863
[epoch1, step1360]: loss 0.044565
[epoch1, step1361]: loss 0.047263
[epoch1, step1362]: loss 0.044417
[epoch1, step1363]: loss 0.043657
[epoch1, step1364]: loss 0.046157
[epoch1, step1365]: loss 0.044286
[epoch1, step1366]: loss 0.044966
[epoch1, step1367]: loss 0.043178
[epoch1, step1368]: loss 0.045016
[epoch1, step1369]: loss 0.044460
[epoch1, step1370]: loss 0.046524
[epoch1, step1371]: loss 0.043884
[epoch1, step1372]: loss 0.042765
[epoch1, step1373]: loss 0.045959
[epoch1, step1374]: loss 0.045111
[epoch1, step1375]: loss 0.045522
[epoch1, step1376]: loss 0.043754
[epoch1, step1377]: loss 0.043194
[epoch1, step1378]: loss 0.044829
[epoch1, step1379]: loss 0.046147
[epoch1, step1380]: loss 0.044047
[epoch1, step1381]: loss 0.043133
[epoch1, step1382]: loss 0.046338
[epoch1, step1383]: loss 0.044027
[epoch1, step1384]: loss 0.044660
[epoch1, step1385]: loss 0.043368
[epoch1, step1386]: loss 0.044504
[epoch1, step1387]: loss 0.044843
[epoch1, step1388]: loss 0.045421
[epoch1, step1389]: loss 0.043453
[epoch1, step1390]: loss 0.042935
[epoch1, step1391]: loss 0.045733
[epoch1, step1392]: loss 0.044180
[epoch1, step1393]: loss 0.045198
[epoch1, step1394]: loss 0.044394
[epoch1, step1395]: loss 0.044017
[epoch1, step1396]: loss 0.044415
[epoch1, step1397]: loss 0.046343
[epoch1, step1398]: loss 0.043429
[epoch1, step1399]: loss 0.043900
[epoch1, step1400]: loss 0.046642
[epoch1, step1401]: loss 0.044136
[epoch1, step1402]: loss 0.044748
[epoch1, step1403]: loss 0.042675
[epoch1, step1404]: loss 0.043575
[epoch1, step1405]: loss 0.043946
[epoch1, step1406]: loss 0.046054
[epoch1, step1407]: loss 0.044524
[epoch1, step1408]: loss 0.042268
[epoch1, step1409]: loss 0.045285
[epoch1, step1410]: loss 0.043927
[epoch1, step1411]: loss 0.043658
[epoch1, step1412]: loss 0.043620
[epoch1, step1413]: loss 0.043865
[epoch1, step1414]: loss 0.043650
[epoch1, step1415]: loss 0.045789
[epoch1, step1416]: loss 0.043126
[epoch1, step1417]: loss 0.042435
[epoch1, step1418]: loss 0.045397
[epoch1, step1419]: loss 0.044389
[epoch1, step1420]: loss 0.044581
[epoch1, step1421]: loss 0.043742
[epoch1, step1422]: loss 0.043583
[epoch1, step1423]: loss 0.043388
[epoch1, step1424]: loss 0.046178
[epoch1, step1425]: loss 0.042157
[epoch1, step1426]: loss 0.042457
[epoch1, step1427]: loss 0.046179
[epoch1, step1428]: loss 0.044385
[epoch1, step1429]: loss 0.044262
[epoch1, step1430]: loss 0.043314
[epoch1, step1431]: loss 0.043719
[epoch1, step1432]: loss 0.043392
[epoch1, step1433]: loss 0.046131
[epoch1, step1434]: loss 0.042385
[epoch1, step1435]: loss 0.042778
[epoch1, step1436]: loss 0.045583
[epoch1, step1437]: loss 0.043726
[epoch1, step1438]: loss 0.044534
[epoch1, step1439]: loss 0.042962
[epoch1, step1440]: loss 0.042994
[epoch1, step1441]: loss 0.044037
[epoch1, step1442]: loss 0.044971
[epoch1, step1443]: loss 0.042424
[epoch1, step1444]: loss 0.041315
[epoch1, step1445]: loss 0.046268
[epoch1, step1446]: loss 0.043640
[epoch1, step1447]: loss 0.044712
[epoch1, step1448]: loss 0.043045
[epoch1, step1449]: loss 0.042504
[epoch1, step1450]: loss 0.043975
[epoch1, step1451]: loss 0.046634
[epoch1, step1452]: loss 0.042190
[epoch1, step1453]: loss 0.043003
[epoch1, step1454]: loss 0.045258
[epoch1, step1455]: loss 0.043716
[epoch1, step1456]: loss 0.043341
[epoch1, step1457]: loss 0.043137
[epoch1, step1458]: loss 0.043027
[epoch1, step1459]: loss 0.042952
[epoch1, step1460]: loss 0.045947
[epoch1, step1461]: loss 0.042758
[epoch1, step1462]: loss 0.042219
[epoch1, step1463]: loss 0.044560
[epoch1, step1464]: loss 0.043146
[epoch1, step1465]: loss 0.043035
[epoch1, step1466]: loss 0.042008
[epoch1, step1467]: loss 0.042641
[epoch1, step1468]: loss 0.042304
[epoch1, step1469]: loss 0.045196
[epoch1, step1470]: loss 0.042066
[epoch1, step1471]: loss 0.041285
[epoch1, step1472]: loss 0.044149
[epoch1, step1473]: loss 0.042866
[epoch1, step1474]: loss 0.043777
[epoch1, step1475]: loss 0.041885
[epoch1, step1476]: loss 0.043358
[epoch1, step1477]: loss 0.042700
[epoch1, step1478]: loss 0.045038
[epoch1, step1479]: loss 0.042019
[epoch1, step1480]: loss 0.041675
[epoch1, step1481]: loss 0.043360
[epoch1, step1482]: loss 0.043413
[epoch1, step1483]: loss 0.044235
[epoch1, step1484]: loss 0.042446
[epoch1, step1485]: loss 0.042239
[epoch1, step1486]: loss 0.041672
[epoch1, step1487]: loss 0.044574
[epoch1, step1488]: loss 0.041932
[epoch1, step1489]: loss 0.041169
[epoch1, step1490]: loss 0.044185
[epoch1, step1491]: loss 0.042627
[epoch1, step1492]: loss 0.042854
[epoch1, step1493]: loss 0.042062
[epoch1, step1494]: loss 0.042527
[epoch1, step1495]: loss 0.042231
[epoch1, step1496]: loss 0.043780
[epoch1, step1497]: loss 0.042039
[epoch1, step1498]: loss 0.041361
[epoch1, step1499]: loss 0.043662
[epoch1, step1500]: loss 0.042548
[epoch1, step1501]: loss 0.043033
[epoch1, step1502]: loss 0.041700
[epoch1, step1503]: loss 0.042189
[epoch1, step1504]: loss 0.041975
[epoch1, step1505]: loss 0.044936
[epoch1, step1506]: loss 0.041189
[epoch1, step1507]: loss 0.041407
[epoch1, step1508]: loss 0.045205
[epoch1, step1509]: loss 0.042222
[epoch1, step1510]: loss 0.042279
[epoch1, step1511]: loss 0.042816
[epoch1, step1512]: loss 0.042394
[epoch1, step1513]: loss 0.041330
[epoch1, step1514]: loss 0.044993
[epoch1, step1515]: loss 0.041958
[epoch1, step1516]: loss 0.041127

[epoch1]: avg loss 0.096438

[epoch2, step1]: loss 0.034181
[epoch2, step2]: loss 0.043876
[epoch2, step3]: loss 0.043930
[epoch2, step4]: loss 0.041106
[epoch2, step5]: loss 0.041720
[epoch2, step6]: loss 0.043845
[epoch2, step7]: loss 0.041697
[epoch2, step8]: loss 0.044951
[epoch2, step9]: loss 0.041380
[epoch2, step10]: loss 0.041537
[epoch2, step11]: loss 0.044134
[epoch2, step12]: loss 0.044194
[epoch2, step13]: loss 0.041485
[epoch2, step14]: loss 0.041672
[epoch2, step15]: loss 0.043865
[epoch2, step16]: loss 0.041196
[epoch2, step17]: loss 0.045210
[epoch2, step18]: loss 0.042377
[epoch2, step19]: loss 0.040929
[epoch2, step20]: loss 0.044707
[epoch2, step21]: loss 0.044060
[epoch2, step22]: loss 0.040975
[epoch2, step23]: loss 0.040502
[epoch2, step24]: loss 0.043683
[epoch2, step25]: loss 0.040493
[epoch2, step26]: loss 0.044020
[epoch2, step27]: loss 0.040925
[epoch2, step28]: loss 0.040748
[epoch2, step29]: loss 0.044009
[epoch2, step30]: loss 0.044561
[epoch2, step31]: loss 0.040700
[epoch2, step32]: loss 0.041615
[epoch2, step33]: loss 0.044571
[epoch2, step34]: loss 0.041758
[epoch2, step35]: loss 0.045014
[epoch2, step36]: loss 0.041504
[epoch2, step37]: loss 0.040664
[epoch2, step38]: loss 0.044365
[epoch2, step39]: loss 0.044636
[epoch2, step40]: loss 0.041469
[epoch2, step41]: loss 0.040881
[epoch2, step42]: loss 0.044032
[epoch2, step43]: loss 0.040821
[epoch2, step44]: loss 0.045333
[epoch2, step45]: loss 0.041358
[epoch2, step46]: loss 0.040929
[epoch2, step47]: loss 0.043517
[epoch2, step48]: loss 0.043613
[epoch2, step49]: loss 0.039714
[epoch2, step50]: loss 0.041331
[epoch2, step51]: loss 0.043286
[epoch2, step52]: loss 0.040780
[epoch2, step53]: loss 0.045065
[epoch2, step54]: loss 0.041034
[epoch2, step55]: loss 0.040991
[epoch2, step56]: loss 0.044472
[epoch2, step57]: loss 0.044268
[epoch2, step58]: loss 0.041142
[epoch2, step59]: loss 0.040166
[epoch2, step60]: loss 0.043967
[epoch2, step61]: loss 0.040063
[epoch2, step62]: loss 0.043981
[epoch2, step63]: loss 0.040594
[epoch2, step64]: loss 0.040071
[epoch2, step65]: loss 0.044009
[epoch2, step66]: loss 0.043808
[epoch2, step67]: loss 0.041224
[epoch2, step68]: loss 0.041228
[epoch2, step69]: loss 0.043359
[epoch2, step70]: loss 0.040752
[epoch2, step71]: loss 0.044119
[epoch2, step72]: loss 0.041210
[epoch2, step73]: loss 0.040344
[epoch2, step74]: loss 0.043649
[epoch2, step75]: loss 0.043985
[epoch2, step76]: loss 0.041481
[epoch2, step77]: loss 0.041651
[epoch2, step78]: loss 0.043626
[epoch2, step79]: loss 0.040061
[epoch2, step80]: loss 0.045325
[epoch2, step81]: loss 0.041015
[epoch2, step82]: loss 0.040060
[epoch2, step83]: loss 0.042718
[epoch2, step84]: loss 0.043875
[epoch2, step85]: loss 0.041477
[epoch2, step86]: loss 0.040955
[epoch2, step87]: loss 0.044299
[epoch2, step88]: loss 0.039509
[epoch2, step89]: loss 0.043726
[epoch2, step90]: loss 0.041379
[epoch2, step91]: loss 0.039769
[epoch2, step92]: loss 0.043646
[epoch2, step93]: loss 0.043455
[epoch2, step94]: loss 0.040632
[epoch2, step95]: loss 0.041229
[epoch2, step96]: loss 0.043065
[epoch2, step97]: loss 0.041183
[epoch2, step98]: loss 0.044167
[epoch2, step99]: loss 0.041207
[epoch2, step100]: loss 0.039303
[epoch2, step101]: loss 0.044529
[epoch2, step102]: loss 0.044056
[epoch2, step103]: loss 0.040630
[epoch2, step104]: loss 0.041084
[epoch2, step105]: loss 0.043418
[epoch2, step106]: loss 0.040465
[epoch2, step107]: loss 0.043982
[epoch2, step108]: loss 0.041161
[epoch2, step109]: loss 0.039877
[epoch2, step110]: loss 0.043871
[epoch2, step111]: loss 0.043370
[epoch2, step112]: loss 0.040830
[epoch2, step113]: loss 0.041550
[epoch2, step114]: loss 0.042962
[epoch2, step115]: loss 0.040519
[epoch2, step116]: loss 0.044629
[epoch2, step117]: loss 0.040899
[epoch2, step118]: loss 0.040690
[epoch2, step119]: loss 0.043688
[epoch2, step120]: loss 0.043566
[epoch2, step121]: loss 0.040393
[epoch2, step122]: loss 0.040710
[epoch2, step123]: loss 0.043441
[epoch2, step124]: loss 0.040861
[epoch2, step125]: loss 0.044446
[epoch2, step126]: loss 0.040774
[epoch2, step127]: loss 0.040091
[epoch2, step128]: loss 0.043068
[epoch2, step129]: loss 0.043139
[epoch2, step130]: loss 0.040778
[epoch2, step131]: loss 0.040077
[epoch2, step132]: loss 0.043401
[epoch2, step133]: loss 0.040052
[epoch2, step134]: loss 0.043552
[epoch2, step135]: loss 0.041147
[epoch2, step136]: loss 0.041046
[epoch2, step137]: loss 0.042978
[epoch2, step138]: loss 0.043187
[epoch2, step139]: loss 0.040489
[epoch2, step140]: loss 0.040874
[epoch2, step141]: loss 0.043205
[epoch2, step142]: loss 0.040161
[epoch2, step143]: loss 0.043320
[epoch2, step144]: loss 0.040863
[epoch2, step145]: loss 0.040010
[epoch2, step146]: loss 0.043250
[epoch2, step147]: loss 0.044579
[epoch2, step148]: loss 0.040364
[epoch2, step149]: loss 0.039958
[epoch2, step150]: loss 0.042762
[epoch2, step151]: loss 0.040513
[epoch2, step152]: loss 0.043737
[epoch2, step153]: loss 0.040997
[epoch2, step154]: loss 0.039463
[epoch2, step155]: loss 0.043173
[epoch2, step156]: loss 0.042888
[epoch2, step157]: loss 0.040632
[epoch2, step158]: loss 0.040812
[epoch2, step159]: loss 0.043159
[epoch2, step160]: loss 0.040663
[epoch2, step161]: loss 0.044310
[epoch2, step162]: loss 0.040904
[epoch2, step163]: loss 0.039840
[epoch2, step164]: loss 0.043296
[epoch2, step165]: loss 0.043394
[epoch2, step166]: loss 0.040799
[epoch2, step167]: loss 0.040069
[epoch2, step168]: loss 0.043583
[epoch2, step169]: loss 0.039774
[epoch2, step170]: loss 0.044129
[epoch2, step171]: loss 0.040751
[epoch2, step172]: loss 0.039865
[epoch2, step173]: loss 0.043370
[epoch2, step174]: loss 0.042991
[epoch2, step175]: loss 0.041060
[epoch2, step176]: loss 0.040588
[epoch2, step177]: loss 0.043145
[epoch2, step178]: loss 0.040149
[epoch2, step179]: loss 0.042706
[epoch2, step180]: loss 0.040892
[epoch2, step181]: loss 0.039849
[epoch2, step182]: loss 0.043465
[epoch2, step183]: loss 0.043718
[epoch2, step184]: loss 0.041271
[epoch2, step185]: loss 0.040765
[epoch2, step186]: loss 0.042922
[epoch2, step187]: loss 0.040448
[epoch2, step188]: loss 0.043189
[epoch2, step189]: loss 0.040746
[epoch2, step190]: loss 0.039510
[epoch2, step191]: loss 0.042604
[epoch2, step192]: loss 0.043832
[epoch2, step193]: loss 0.038786
[epoch2, step194]: loss 0.039512
[epoch2, step195]: loss 0.043149
[epoch2, step196]: loss 0.040047
[epoch2, step197]: loss 0.043374
[epoch2, step198]: loss 0.039442
[epoch2, step199]: loss 0.039678
[epoch2, step200]: loss 0.043281
[epoch2, step201]: loss 0.043440
[epoch2, step202]: loss 0.039873
[epoch2, step203]: loss 0.040235
[epoch2, step204]: loss 0.043031
[epoch2, step205]: loss 0.039427
[epoch2, step206]: loss 0.043082
[epoch2, step207]: loss 0.040346
[epoch2, step208]: loss 0.040005
[epoch2, step209]: loss 0.043101
[epoch2, step210]: loss 0.043832
[epoch2, step211]: loss 0.040768
[epoch2, step212]: loss 0.040781
[epoch2, step213]: loss 0.042393
[epoch2, step214]: loss 0.039523
[epoch2, step215]: loss 0.043716
[epoch2, step216]: loss 0.040590
[epoch2, step217]: loss 0.038762
[epoch2, step218]: loss 0.043029
[epoch2, step219]: loss 0.042805
[epoch2, step220]: loss 0.040370
[epoch2, step221]: loss 0.040465
[epoch2, step222]: loss 0.042749
[epoch2, step223]: loss 0.040019
[epoch2, step224]: loss 0.042948
[epoch2, step225]: loss 0.040257
[epoch2, step226]: loss 0.039477
[epoch2, step227]: loss 0.041778
[epoch2, step228]: loss 0.043499
[epoch2, step229]: loss 0.039276
[epoch2, step230]: loss 0.040432
[epoch2, step231]: loss 0.043011
[epoch2, step232]: loss 0.039273
[epoch2, step233]: loss 0.042489
[epoch2, step234]: loss 0.039749
[epoch2, step235]: loss 0.039836
[epoch2, step236]: loss 0.042756
[epoch2, step237]: loss 0.043005
[epoch2, step238]: loss 0.039750
[epoch2, step239]: loss 0.039368
[epoch2, step240]: loss 0.042048
[epoch2, step241]: loss 0.040197
[epoch2, step242]: loss 0.043122
[epoch2, step243]: loss 0.040635
[epoch2, step244]: loss 0.039341
[epoch2, step245]: loss 0.042248
[epoch2, step246]: loss 0.042750
[epoch2, step247]: loss 0.040161
[epoch2, step248]: loss 0.039606
[epoch2, step249]: loss 0.041943
[epoch2, step250]: loss 0.039870
[epoch2, step251]: loss 0.043522
[epoch2, step252]: loss 0.040615
[epoch2, step253]: loss 0.039051
[epoch2, step254]: loss 0.041936
[epoch2, step255]: loss 0.042739
[epoch2, step256]: loss 0.039550
[epoch2, step257]: loss 0.039711
[epoch2, step258]: loss 0.042978
[epoch2, step259]: loss 0.039626
[epoch2, step260]: loss 0.042334
[epoch2, step261]: loss 0.040937
[epoch2, step262]: loss 0.039928
[epoch2, step263]: loss 0.041726
[epoch2, step264]: loss 0.042580
[epoch2, step265]: loss 0.040265
[epoch2, step266]: loss 0.039720
[epoch2, step267]: loss 0.041745
[epoch2, step268]: loss 0.039380
[epoch2, step269]: loss 0.042905
[epoch2, step270]: loss 0.039412
[epoch2, step271]: loss 0.039285
[epoch2, step272]: loss 0.042404
[epoch2, step273]: loss 0.042239
[epoch2, step274]: loss 0.040145
[epoch2, step275]: loss 0.039270
[epoch2, step276]: loss 0.041774
[epoch2, step277]: loss 0.039961
[epoch2, step278]: loss 0.042783
[epoch2, step279]: loss 0.039595
[epoch2, step280]: loss 0.039025
[epoch2, step281]: loss 0.042165
[epoch2, step282]: loss 0.042761
[epoch2, step283]: loss 0.039125
[epoch2, step284]: loss 0.039176
[epoch2, step285]: loss 0.042826
[epoch2, step286]: loss 0.038807
[epoch2, step287]: loss 0.042688
[epoch2, step288]: loss 0.039465
[epoch2, step289]: loss 0.040011
[epoch2, step290]: loss 0.042342
[epoch2, step291]: loss 0.042750
[epoch2, step292]: loss 0.038662
[epoch2, step293]: loss 0.039251
[epoch2, step294]: loss 0.041351
[epoch2, step295]: loss 0.038789
[epoch2, step296]: loss 0.043345
[epoch2, step297]: loss 0.039217
[epoch2, step298]: loss 0.039418
[epoch2, step299]: loss 0.041361
[epoch2, step300]: loss 0.042453
[epoch2, step301]: loss 0.039334
[epoch2, step302]: loss 0.039757
[epoch2, step303]: loss 0.042366
[epoch2, step304]: loss 0.038846
[epoch2, step305]: loss 0.042020
[epoch2, step306]: loss 0.039587
[epoch2, step307]: loss 0.038384
[epoch2, step308]: loss 0.042870
[epoch2, step309]: loss 0.042457
[epoch2, step310]: loss 0.039478
[epoch2, step311]: loss 0.040033
[epoch2, step312]: loss 0.041711
[epoch2, step313]: loss 0.039713
[epoch2, step314]: loss 0.042565
[epoch2, step315]: loss 0.040224
[epoch2, step316]: loss 0.038721
[epoch2, step317]: loss 0.042190
[epoch2, step318]: loss 0.042133
[epoch2, step319]: loss 0.038724
[epoch2, step320]: loss 0.038219
[epoch2, step321]: loss 0.041406
[epoch2, step322]: loss 0.038894
[epoch2, step323]: loss 0.041542
[epoch2, step324]: loss 0.039886
[epoch2, step325]: loss 0.038884
[epoch2, step326]: loss 0.041855
[epoch2, step327]: loss 0.041355
[epoch2, step328]: loss 0.039286
[epoch2, step329]: loss 0.039055
[epoch2, step330]: loss 0.041355
[epoch2, step331]: loss 0.039357
[epoch2, step332]: loss 0.041861
[epoch2, step333]: loss 0.039030
[epoch2, step334]: loss 0.038698
[epoch2, step335]: loss 0.041950
[epoch2, step336]: loss 0.042703
[epoch2, step337]: loss 0.039125
[epoch2, step338]: loss 0.038531
[epoch2, step339]: loss 0.041292
[epoch2, step340]: loss 0.039267
[epoch2, step341]: loss 0.041430
[epoch2, step342]: loss 0.038768
[epoch2, step343]: loss 0.038754
[epoch2, step344]: loss 0.041466
[epoch2, step345]: loss 0.041134
[epoch2, step346]: loss 0.038447
[epoch2, step347]: loss 0.038815
[epoch2, step348]: loss 0.041639
[epoch2, step349]: loss 0.039456
[epoch2, step350]: loss 0.041736
[epoch2, step351]: loss 0.038135
[epoch2, step352]: loss 0.038516
[epoch2, step353]: loss 0.041418
[epoch2, step354]: loss 0.040710
[epoch2, step355]: loss 0.037802
[epoch2, step356]: loss 0.039382
[epoch2, step357]: loss 0.041360
[epoch2, step358]: loss 0.037435
[epoch2, step359]: loss 0.042471
[epoch2, step360]: loss 0.037802
[epoch2, step361]: loss 0.037726
[epoch2, step362]: loss 0.042261
[epoch2, step363]: loss 0.041439
[epoch2, step364]: loss 0.038617
[epoch2, step365]: loss 0.038779
[epoch2, step366]: loss 0.041895
[epoch2, step367]: loss 0.038732
[epoch2, step368]: loss 0.041389
[epoch2, step369]: loss 0.038550
[epoch2, step370]: loss 0.039081
[epoch2, step371]: loss 0.042325
[epoch2, step372]: loss 0.041143
[epoch2, step373]: loss 0.038088
[epoch2, step374]: loss 0.037845
[epoch2, step375]: loss 0.041732
[epoch2, step376]: loss 0.038547
[epoch2, step377]: loss 0.041672
[epoch2, step378]: loss 0.039079
[epoch2, step379]: loss 0.038824
[epoch2, step380]: loss 0.042209
[epoch2, step381]: loss 0.041225
[epoch2, step382]: loss 0.038926
[epoch2, step383]: loss 0.038006
[epoch2, step384]: loss 0.040745
[epoch2, step385]: loss 0.038665
[epoch2, step386]: loss 0.042005
[epoch2, step387]: loss 0.038597
[epoch2, step388]: loss 0.039076
[epoch2, step389]: loss 0.041417
[epoch2, step390]: loss 0.042222
[epoch2, step391]: loss 0.038121
[epoch2, step392]: loss 0.038958
[epoch2, step393]: loss 0.040635
[epoch2, step394]: loss 0.038566
[epoch2, step395]: loss 0.041231
[epoch2, step396]: loss 0.038630
[epoch2, step397]: loss 0.037887
[epoch2, step398]: loss 0.041736
[epoch2, step399]: loss 0.041336
[epoch2, step400]: loss 0.038356
[epoch2, step401]: loss 0.038415
[epoch2, step402]: loss 0.040767
[epoch2, step403]: loss 0.038760
[epoch2, step404]: loss 0.042198
[epoch2, step405]: loss 0.038745
[epoch2, step406]: loss 0.038734
[epoch2, step407]: loss 0.041289
[epoch2, step408]: loss 0.041536
[epoch2, step409]: loss 0.039806
[epoch2, step410]: loss 0.039154
[epoch2, step411]: loss 0.041176
[epoch2, step412]: loss 0.037989
[epoch2, step413]: loss 0.041321
[epoch2, step414]: loss 0.038098
[epoch2, step415]: loss 0.038527
[epoch2, step416]: loss 0.040846
[epoch2, step417]: loss 0.041517
[epoch2, step418]: loss 0.038258
[epoch2, step419]: loss 0.037777
[epoch2, step420]: loss 0.041259
[epoch2, step421]: loss 0.038569
[epoch2, step422]: loss 0.041625
[epoch2, step423]: loss 0.038551
[epoch2, step424]: loss 0.038554
[epoch2, step425]: loss 0.041356
[epoch2, step426]: loss 0.041720
[epoch2, step427]: loss 0.038634
[epoch2, step428]: loss 0.038356
[epoch2, step429]: loss 0.041713
[epoch2, step430]: loss 0.038481
[epoch2, step431]: loss 0.042019
[epoch2, step432]: loss 0.038211
[epoch2, step433]: loss 0.039012
[epoch2, step434]: loss 0.041032
[epoch2, step435]: loss 0.041595
[epoch2, step436]: loss 0.037876
[epoch2, step437]: loss 0.038619
[epoch2, step438]: loss 0.041408
[epoch2, step439]: loss 0.038684
[epoch2, step440]: loss 0.041211
[epoch2, step441]: loss 0.038783
[epoch2, step442]: loss 0.038257
[epoch2, step443]: loss 0.041458
[epoch2, step444]: loss 0.041159
[epoch2, step445]: loss 0.038865
[epoch2, step446]: loss 0.038783
[epoch2, step447]: loss 0.041693
[epoch2, step448]: loss 0.038420
[epoch2, step449]: loss 0.041088
[epoch2, step450]: loss 0.037620
[epoch2, step451]: loss 0.037826
[epoch2, step452]: loss 0.040009
[epoch2, step453]: loss 0.041151
[epoch2, step454]: loss 0.038181
[epoch2, step455]: loss 0.038354
[epoch2, step456]: loss 0.040091
[epoch2, step457]: loss 0.038990
[epoch2, step458]: loss 0.041065
[epoch2, step459]: loss 0.039040
[epoch2, step460]: loss 0.038139
[epoch2, step461]: loss 0.042078
[epoch2, step462]: loss 0.040730
[epoch2, step463]: loss 0.038329
[epoch2, step464]: loss 0.038300
[epoch2, step465]: loss 0.042198
[epoch2, step466]: loss 0.038124
[epoch2, step467]: loss 0.040928
[epoch2, step468]: loss 0.038183
[epoch2, step469]: loss 0.038175
[epoch2, step470]: loss 0.041159
[epoch2, step471]: loss 0.040524
[epoch2, step472]: loss 0.038587
[epoch2, step473]: loss 0.037848
[epoch2, step474]: loss 0.040613
[epoch2, step475]: loss 0.038641
[epoch2, step476]: loss 0.041640
[epoch2, step477]: loss 0.038220
[epoch2, step478]: loss 0.037767
[epoch2, step479]: loss 0.040772
[epoch2, step480]: loss 0.040217
[epoch2, step481]: loss 0.037826
[epoch2, step482]: loss 0.037546
[epoch2, step483]: loss 0.041206
[epoch2, step484]: loss 0.038236
[epoch2, step485]: loss 0.041257
[epoch2, step486]: loss 0.038424
[epoch2, step487]: loss 0.037337
[epoch2, step488]: loss 0.041408
[epoch2, step489]: loss 0.040132
[epoch2, step490]: loss 0.038480
[epoch2, step491]: loss 0.038258
[epoch2, step492]: loss 0.040468
[epoch2, step493]: loss 0.037961
[epoch2, step494]: loss 0.040321
[epoch2, step495]: loss 0.039401
[epoch2, step496]: loss 0.037965
[epoch2, step497]: loss 0.041293
[epoch2, step498]: loss 0.040898
[epoch2, step499]: loss 0.038266
[epoch2, step500]: loss 0.037830
[epoch2, step501]: loss 0.040286
[epoch2, step502]: loss 0.038008
[epoch2, step503]: loss 0.041402
[epoch2, step504]: loss 0.037804
[epoch2, step505]: loss 0.037152
[epoch2, step506]: loss 0.041247
[epoch2, step507]: loss 0.041133
[epoch2, step508]: loss 0.038459
[epoch2, step509]: loss 0.037976
[epoch2, step510]: loss 0.040766
[epoch2, step511]: loss 0.038526
[epoch2, step512]: loss 0.041226
[epoch2, step513]: loss 0.038388
[epoch2, step514]: loss 0.038262
[epoch2, step515]: loss 0.040807
[epoch2, step516]: loss 0.041298
[epoch2, step517]: loss 0.037944
[epoch2, step518]: loss 0.038185
[epoch2, step519]: loss 0.040620
[epoch2, step520]: loss 0.037682
[epoch2, step521]: loss 0.040702
[epoch2, step522]: loss 0.037536
[epoch2, step523]: loss 0.037959
[epoch2, step524]: loss 0.040040
[epoch2, step525]: loss 0.041192
[epoch2, step526]: loss 0.037978
[epoch2, step527]: loss 0.037694
[epoch2, step528]: loss 0.040790
[epoch2, step529]: loss 0.037602
[epoch2, step530]: loss 0.041227
[epoch2, step531]: loss 0.037945
[epoch2, step532]: loss 0.037545
[epoch2, step533]: loss 0.041677
[epoch2, step534]: loss 0.040822
[epoch2, step535]: loss 0.038335
[epoch2, step536]: loss 0.038134
[epoch2, step537]: loss 0.040631
[epoch2, step538]: loss 0.038113
[epoch2, step539]: loss 0.040634
[epoch2, step540]: loss 0.037601
[epoch2, step541]: loss 0.037397
[epoch2, step542]: loss 0.040753
[epoch2, step543]: loss 0.040536
[epoch2, step544]: loss 0.037747
[epoch2, step545]: loss 0.037184
[epoch2, step546]: loss 0.041075
[epoch2, step547]: loss 0.037884
[epoch2, step548]: loss 0.040799
[epoch2, step549]: loss 0.038249
[epoch2, step550]: loss 0.037898
[epoch2, step551]: loss 0.040500
[epoch2, step552]: loss 0.040177
[epoch2, step553]: loss 0.038218
[epoch2, step554]: loss 0.037741
[epoch2, step555]: loss 0.040196
[epoch2, step556]: loss 0.037842
[epoch2, step557]: loss 0.040270
[epoch2, step558]: loss 0.038235
[epoch2, step559]: loss 0.037259
[epoch2, step560]: loss 0.040704
[epoch2, step561]: loss 0.040601
[epoch2, step562]: loss 0.037808
[epoch2, step563]: loss 0.029560
[epoch2, step564]: loss 0.028442
[epoch2, step565]: loss 0.027324
[epoch2, step566]: loss 0.034155
[epoch2, step567]: loss 0.025100
[epoch2, step568]: loss 0.024800
[epoch2, step569]: loss 0.022331
[epoch2, step570]: loss 0.030188
[epoch2, step571]: loss 0.027174
[epoch2, step572]: loss 0.025634
[epoch2, step573]: loss 0.028318
[epoch2, step574]: loss 0.027220
[epoch2, step575]: loss 0.020697
[epoch2, step576]: loss 0.021669
[epoch2, step577]: loss 0.025817
[epoch2, step578]: loss 0.019311
[epoch2, step579]: loss 0.028206
[epoch2, step580]: loss 0.020558
[epoch2, step581]: loss 0.025894
[epoch2, step582]: loss 0.025589
[epoch2, step583]: loss 0.022087
[epoch2, step584]: loss 0.023987
[epoch2, step585]: loss 0.026406
[epoch2, step586]: loss 0.022121
[epoch2, step587]: loss 0.028091
[epoch2, step588]: loss 0.023335
[epoch2, step589]: loss 0.023445
[epoch2, step590]: loss 0.028246
[epoch2, step591]: loss 0.021110
[epoch2, step592]: loss 0.026341
[epoch2, step593]: loss 0.022873
[epoch2, step594]: loss 0.026450
[epoch2, step595]: loss 0.027095
[epoch2, step596]: loss 0.022849
[epoch2, step597]: loss 0.025470
[epoch2, step598]: loss 0.026866
[epoch2, step599]: loss 0.025698
[epoch2, step600]: loss 0.028043
[epoch2, step601]: loss 0.019620
[epoch2, step602]: loss 0.022819
[epoch2, step603]: loss 0.026401
[epoch2, step604]: loss 0.027000
[epoch2, step605]: loss 0.025759
[epoch2, step606]: loss 0.025109
[epoch2, step607]: loss 0.028228
[epoch2, step608]: loss 0.026154
[epoch2, step609]: loss 0.027625
[epoch2, step610]: loss 0.026323
[epoch2, step611]: loss 0.026896
[epoch2, step612]: loss 0.026155
[epoch2, step613]: loss 0.019698
[epoch2, step614]: loss 0.025558
[epoch2, step615]: loss 0.028740
[epoch2, step616]: loss 0.024313
[epoch2, step617]: loss 0.023922
[epoch2, step618]: loss 0.026223
[epoch2, step619]: loss 0.027195
[epoch2, step620]: loss 0.024699
[epoch2, step621]: loss 0.026622
[epoch2, step622]: loss 0.020981
[epoch2, step623]: loss 0.024768
[epoch2, step624]: loss 0.026859
[epoch2, step625]: loss 0.026462
[epoch2, step626]: loss 0.028713
[epoch2, step627]: loss 0.023475
[epoch2, step628]: loss 0.026410
[epoch2, step629]: loss 0.021065
[epoch2, step630]: loss 0.023812
[epoch2, step631]: loss 0.031645
[epoch2, step632]: loss 0.023731
[epoch2, step633]: loss 0.024976
[epoch2, step634]: loss 0.027448
[epoch2, step635]: loss 0.026201
[epoch2, step636]: loss 0.021216
[epoch2, step637]: loss 0.027868
[epoch2, step638]: loss 0.027388
[epoch2, step639]: loss 0.023370
[epoch2, step640]: loss 0.029755
[epoch2, step641]: loss 0.030823
[epoch2, step642]: loss 0.025327
[epoch2, step643]: loss 0.026136
[epoch2, step644]: loss 0.026500
[epoch2, step645]: loss 0.024151
[epoch2, step646]: loss 0.027025
[epoch2, step647]: loss 0.024135
[epoch2, step648]: loss 0.023655
[epoch2, step649]: loss 0.029127
[epoch2, step650]: loss 0.022735
[epoch2, step651]: loss 0.026684
[epoch2, step652]: loss 0.027383
[epoch2, step653]: loss 0.028543
[epoch2, step654]: loss 0.023627
[epoch2, step655]: loss 0.024336
[epoch2, step656]: loss 0.021942
[epoch2, step657]: loss 0.028305
[epoch2, step658]: loss 0.025602
[epoch2, step659]: loss 0.028023
[epoch2, step660]: loss 0.024209
[epoch2, step661]: loss 0.027134
[epoch2, step662]: loss 0.024234
[epoch2, step663]: loss 0.021733
[epoch2, step664]: loss 0.025334
[epoch2, step665]: loss 0.028499
[epoch2, step666]: loss 0.027190
[epoch2, step667]: loss 0.027018
[epoch2, step668]: loss 0.022958
[epoch2, step669]: loss 0.026602
[epoch2, step670]: loss 0.027540
[epoch2, step671]: loss 0.021567
[epoch2, step672]: loss 0.024466
[epoch2, step673]: loss 0.022650
[epoch2, step674]: loss 0.021779
[epoch2, step675]: loss 0.020596
[epoch2, step676]: loss 0.024791
[epoch2, step677]: loss 0.025871
[epoch2, step678]: loss 0.023790
[epoch2, step679]: loss 0.024320
[epoch2, step680]: loss 0.030956
[epoch2, step681]: loss 0.022526
[epoch2, step682]: loss 0.026404
[epoch2, step683]: loss 0.026042
[epoch2, step684]: loss 0.025276
[epoch2, step685]: loss 0.024501
[epoch2, step686]: loss 0.027697
[epoch2, step687]: loss 0.027044
[epoch2, step688]: loss 0.023477
[epoch2, step689]: loss 0.024756
[epoch2, step690]: loss 0.026003
[epoch2, step691]: loss 0.024805
[epoch2, step692]: loss 0.023041
[epoch2, step693]: loss 0.028303
[epoch2, step694]: loss 0.023205
[epoch2, step695]: loss 0.027167
[epoch2, step696]: loss 0.026069
[epoch2, step697]: loss 0.027966
[epoch2, step698]: loss 0.025350
[epoch2, step699]: loss 0.023662
[epoch2, step700]: loss 0.022179
[epoch2, step701]: loss 0.026348
[epoch2, step702]: loss 0.022172
[epoch2, step703]: loss 0.023640
[epoch2, step704]: loss 0.026289
[epoch2, step705]: loss 0.025179
[epoch2, step706]: loss 0.024298
[epoch2, step707]: loss 0.024499
[epoch2, step708]: loss 0.026620
[epoch2, step709]: loss 0.027838
[epoch2, step710]: loss 0.024484
[epoch2, step711]: loss 0.024410
[epoch2, step712]: loss 0.027256
[epoch2, step713]: loss 0.026816
[epoch2, step714]: loss 0.021988
[epoch2, step715]: loss 0.023498
[epoch2, step716]: loss 0.026516
[epoch2, step717]: loss 0.023984
[epoch2, step718]: loss 0.025433
[epoch2, step719]: loss 0.033917
[epoch2, step720]: loss 0.025344
[epoch2, step721]: loss 0.023602
[epoch2, step722]: loss 0.031665
[epoch2, step723]: loss 0.026888
[epoch2, step724]: loss 0.023538
[epoch2, step725]: loss 0.028891
[epoch2, step726]: loss 0.022528
[epoch2, step727]: loss 0.024874
[epoch2, step728]: loss 0.026910
[epoch2, step729]: loss 0.021850
[epoch2, step730]: loss 0.023165
[epoch2, step731]: loss 0.026557
[epoch2, step732]: loss 0.026179
[epoch2, step733]: loss 0.024290
[epoch2, step734]: loss 0.023565
[epoch2, step735]: loss 0.027476
[epoch2, step736]: loss 0.025337
[epoch2, step737]: loss 0.026890
[epoch2, step738]: loss 0.021061
[epoch2, step739]: loss 0.025896
[epoch2, step740]: loss 0.023132
[epoch2, step741]: loss 0.025619
[epoch2, step742]: loss 0.022563
[epoch2, step743]: loss 0.023784
[epoch2, step744]: loss 0.024284
[epoch2, step745]: loss 0.025099
[epoch2, step746]: loss 0.025960
[epoch2, step747]: loss 0.028113
[epoch2, step748]: loss 0.026394
[epoch2, step749]: loss 0.026887
[epoch2, step750]: loss 0.028266
[epoch2, step751]: loss 0.022164
[epoch2, step752]: loss 0.025460
[epoch2, step753]: loss 0.025955
[epoch2, step754]: loss 0.023321
[epoch2, step755]: loss 0.026765
[epoch2, step756]: loss 0.023797
[epoch2, step757]: loss 0.021187
[epoch2, step758]: loss 0.025344
[epoch2, step759]: loss 0.023622
[epoch2, step760]: loss 0.024574
[epoch2, step761]: loss 0.026601
[epoch2, step762]: loss 0.021994
[epoch2, step763]: loss 0.026063
[epoch2, step764]: loss 0.024449
[epoch2, step765]: loss 0.026693
[epoch2, step766]: loss 0.025176
[epoch2, step767]: loss 0.027577
[epoch2, step768]: loss 0.021899
[epoch2, step769]: loss 0.027201
[epoch2, step770]: loss 0.026729
[epoch2, step771]: loss 0.023542
[epoch2, step772]: loss 0.029558
[epoch2, step773]: loss 0.026867
[epoch2, step774]: loss 0.024132
[epoch2, step775]: loss 0.021341
[epoch2, step776]: loss 0.026421
[epoch2, step777]: loss 0.023376
[epoch2, step778]: loss 0.028898
[epoch2, step779]: loss 0.024546
[epoch2, step780]: loss 0.020595
[epoch2, step781]: loss 0.025125
[epoch2, step782]: loss 0.023227
[epoch2, step783]: loss 0.020023
[epoch2, step784]: loss 0.021002
[epoch2, step785]: loss 0.021545
[epoch2, step786]: loss 0.024678
[epoch2, step787]: loss 0.024020
[epoch2, step788]: loss 0.024982
[epoch2, step789]: loss 0.023258
[epoch2, step790]: loss 0.023711
[epoch2, step791]: loss 0.027225
[epoch2, step792]: loss 0.025314
[epoch2, step793]: loss 0.027616
[epoch2, step794]: loss 0.020774
[epoch2, step795]: loss 0.026161
[epoch2, step796]: loss 0.028179
[epoch2, step797]: loss 0.028586
[epoch2, step798]: loss 0.027500
[epoch2, step799]: loss 0.025875
[epoch2, step800]: loss 0.022035
[epoch2, step801]: loss 0.022437
[epoch2, step802]: loss 0.023341
[epoch2, step803]: loss 0.026592
[epoch2, step804]: loss 0.027957
[epoch2, step805]: loss 0.029538
[epoch2, step806]: loss 0.022094
[epoch2, step807]: loss 0.021049
[epoch2, step808]: loss 0.023547
[epoch2, step809]: loss 0.023447
[epoch2, step810]: loss 0.026353
[epoch2, step811]: loss 0.026372
[epoch2, step812]: loss 0.025056
[epoch2, step813]: loss 0.024213
[epoch2, step814]: loss 0.025586
[epoch2, step815]: loss 0.025051
[epoch2, step816]: loss 0.024875
[epoch2, step817]: loss 0.025271
[epoch2, step818]: loss 0.022799
[epoch2, step819]: loss 0.020984
[epoch2, step820]: loss 0.023927
[epoch2, step821]: loss 0.022257
[epoch2, step822]: loss 0.031419
[epoch2, step823]: loss 0.024335
[epoch2, step824]: loss 0.027423
[epoch2, step825]: loss 0.025859
[epoch2, step826]: loss 0.024865
[epoch2, step827]: loss 0.027354
[epoch2, step828]: loss 0.029198
[epoch2, step829]: loss 0.026920
[epoch2, step830]: loss 0.023054
[epoch2, step831]: loss 0.026619
[epoch2, step832]: loss 0.021421
[epoch2, step833]: loss 0.029631
[epoch2, step834]: loss 0.026237
[epoch2, step835]: loss 0.021199
[epoch2, step836]: loss 0.027373
[epoch2, step837]: loss 0.025797
[epoch2, step838]: loss 0.026534
[epoch2, step839]: loss 0.028909
[epoch2, step840]: loss 0.021005
[epoch2, step841]: loss 0.024673
[epoch2, step842]: loss 0.028063
[epoch2, step843]: loss 0.025729
[epoch2, step844]: loss 0.025783
[epoch2, step845]: loss 0.021646
[epoch2, step846]: loss 0.026195
[epoch2, step847]: loss 0.027425
[epoch2, step848]: loss 0.025938
[epoch2, step849]: loss 0.025625
[epoch2, step850]: loss 0.023743
[epoch2, step851]: loss 0.024670
[epoch2, step852]: loss 0.023389
[epoch2, step853]: loss 0.029996
[epoch2, step854]: loss 0.022765
[epoch2, step855]: loss 0.027507
[epoch2, step856]: loss 0.022627
[epoch2, step857]: loss 0.026566
[epoch2, step858]: loss 0.024798
[epoch2, step859]: loss 0.024018
[epoch2, step860]: loss 0.023053
[epoch2, step861]: loss 0.023726
[epoch2, step862]: loss 0.023369
[epoch2, step863]: loss 0.021121
[epoch2, step864]: loss 0.027143
[epoch2, step865]: loss 0.023776
[epoch2, step866]: loss 0.025462
[epoch2, step867]: loss 0.026592
[epoch2, step868]: loss 0.027303
[epoch2, step869]: loss 0.024120
[epoch2, step870]: loss 0.031805
[epoch2, step871]: loss 0.022560
[epoch2, step872]: loss 0.025940
[epoch2, step873]: loss 0.026188
[epoch2, step874]: loss 0.024144
[epoch2, step875]: loss 0.024813
[epoch2, step876]: loss 0.024876
[epoch2, step877]: loss 0.019601
[epoch2, step878]: loss 0.023815
[epoch2, step879]: loss 0.028495
[epoch2, step880]: loss 0.025927
[epoch2, step881]: loss 0.022610
[epoch2, step882]: loss 0.024982
[epoch2, step883]: loss 0.024721
[epoch2, step884]: loss 0.026911
[epoch2, step885]: loss 0.026422
[epoch2, step886]: loss 0.026834
[epoch2, step887]: loss 0.024506
[epoch2, step888]: loss 0.025166
[epoch2, step889]: loss 0.024221
[epoch2, step890]: loss 0.024032
[epoch2, step891]: loss 0.025849
[epoch2, step892]: loss 0.021418
[epoch2, step893]: loss 0.024746
[epoch2, step894]: loss 0.024986
[epoch2, step895]: loss 0.023129
[epoch2, step896]: loss 0.022550
[epoch2, step897]: loss 0.024723
[epoch2, step898]: loss 0.026210
[epoch2, step899]: loss 0.028703
[epoch2, step900]: loss 0.027515
[epoch2, step901]: loss 0.026240
[epoch2, step902]: loss 0.024364
[epoch2, step903]: loss 0.025149
[epoch2, step904]: loss 0.028648
[epoch2, step905]: loss 0.028249
[epoch2, step906]: loss 0.022777
[epoch2, step907]: loss 0.023883
[epoch2, step908]: loss 0.023038
[epoch2, step909]: loss 0.026187
[epoch2, step910]: loss 0.023508
[epoch2, step911]: loss 0.025795
[epoch2, step912]: loss 0.024091
[epoch2, step913]: loss 0.024857
[epoch2, step914]: loss 0.031431
[epoch2, step915]: loss 0.024485
[epoch2, step916]: loss 0.023835
[epoch2, step917]: loss 0.025463
[epoch2, step918]: loss 0.028956
[epoch2, step919]: loss 0.024720
[epoch2, step920]: loss 0.027819
[epoch2, step921]: loss 0.024843
[epoch2, step922]: loss 0.023739
[epoch2, step923]: loss 0.023357
[epoch2, step924]: loss 0.021697
[epoch2, step925]: loss 0.025956
[epoch2, step926]: loss 0.027038
[epoch2, step927]: loss 0.026313
[epoch2, step928]: loss 0.025513
[epoch2, step929]: loss 0.028121
[epoch2, step930]: loss 0.026374
[epoch2, step931]: loss 0.028319
[epoch2, step932]: loss 0.022192
[epoch2, step933]: loss 0.028888
[epoch2, step934]: loss 0.022604
[epoch2, step935]: loss 0.022888
[epoch2, step936]: loss 0.023142
[epoch2, step937]: loss 0.028162
[epoch2, step938]: loss 0.025972
[epoch2, step939]: loss 0.021342
[epoch2, step940]: loss 0.023584
[epoch2, step941]: loss 0.027131
[epoch2, step942]: loss 0.025903
[epoch2, step943]: loss 0.023901
[epoch2, step944]: loss 0.028452
[epoch2, step945]: loss 0.020711
[epoch2, step946]: loss 0.025929
[epoch2, step947]: loss 0.028529
[epoch2, step948]: loss 0.020159
[epoch2, step949]: loss 0.023243
[epoch2, step950]: loss 0.026653
[epoch2, step951]: loss 0.029288
[epoch2, step952]: loss 0.025495
[epoch2, step953]: loss 0.027973
[epoch2, step954]: loss 0.022845
[epoch2, step955]: loss 0.036696
[epoch2, step956]: loss 0.051317
[epoch2, step957]: loss 0.045209
[epoch2, step958]: loss 0.041784
[epoch2, step959]: loss 0.046116
[epoch2, step960]: loss 0.043445
[epoch2, step961]: loss 0.044713
[epoch2, step962]: loss 0.044062
[epoch2, step963]: loss 0.043261
[epoch2, step964]: loss 0.044271
[epoch2, step965]: loss 0.045634
[epoch2, step966]: loss 0.043162
[epoch2, step967]: loss 0.042247
[epoch2, step968]: loss 0.045463
[epoch2, step969]: loss 0.044601
[epoch2, step970]: loss 0.044362
[epoch2, step971]: loss 0.043638
[epoch2, step972]: loss 0.044106
[epoch2, step973]: loss 0.043207
[epoch2, step974]: loss 0.046573
[epoch2, step975]: loss 0.043128
[epoch2, step976]: loss 0.041722
[epoch2, step977]: loss 0.045467
[epoch2, step978]: loss 0.043418
[epoch2, step979]: loss 0.043048
[epoch2, step980]: loss 0.041774
[epoch2, step981]: loss 0.041977
[epoch2, step982]: loss 0.042985
[epoch2, step983]: loss 0.046703
[epoch2, step984]: loss 0.042241
[epoch2, step985]: loss 0.040841
[epoch2, step986]: loss 0.044567
[epoch2, step987]: loss 0.043001
[epoch2, step988]: loss 0.043437
[epoch2, step989]: loss 0.042809
[epoch2, step990]: loss 0.042113
[epoch2, step991]: loss 0.042752
[epoch2, step992]: loss 0.044057
[epoch2, step993]: loss 0.041846
[epoch2, step994]: loss 0.040390
[epoch2, step995]: loss 0.043926
[epoch2, step996]: loss 0.042080
[epoch2, step997]: loss 0.042813
[epoch2, step998]: loss 0.042629
[epoch2, step999]: loss 0.042253
[epoch2, step1000]: loss 0.042426
[epoch2, step1001]: loss 0.044306
[epoch2, step1002]: loss 0.041982
[epoch2, step1003]: loss 0.040756
[epoch2, step1004]: loss 0.043878
[epoch2, step1005]: loss 0.041674
[epoch2, step1006]: loss 0.042746
[epoch2, step1007]: loss 0.041637
[epoch2, step1008]: loss 0.041633
[epoch2, step1009]: loss 0.042197
[epoch2, step1010]: loss 0.044639
[epoch2, step1011]: loss 0.041580
[epoch2, step1012]: loss 0.041244
[epoch2, step1013]: loss 0.043977
[epoch2, step1014]: loss 0.042898
[epoch2, step1015]: loss 0.043045
[epoch2, step1016]: loss 0.041561
[epoch2, step1017]: loss 0.041628
[epoch2, step1018]: loss 0.042004
[epoch2, step1019]: loss 0.044351
[epoch2, step1020]: loss 0.041284
[epoch2, step1021]: loss 0.040522
[epoch2, step1022]: loss 0.043644
[epoch2, step1023]: loss 0.042181
[epoch2, step1024]: loss 0.043329
[epoch2, step1025]: loss 0.041391
[epoch2, step1026]: loss 0.041270
[epoch2, step1027]: loss 0.041860
[epoch2, step1028]: loss 0.044051
[epoch2, step1029]: loss 0.041342
[epoch2, step1030]: loss 0.040329
[epoch2, step1031]: loss 0.042650
[epoch2, step1032]: loss 0.042438
[epoch2, step1033]: loss 0.042259
[epoch2, step1034]: loss 0.041500
[epoch2, step1035]: loss 0.041226
[epoch2, step1036]: loss 0.042216
[epoch2, step1037]: loss 0.043889
[epoch2, step1038]: loss 0.041320
[epoch2, step1039]: loss 0.040943
[epoch2, step1040]: loss 0.043213
[epoch2, step1041]: loss 0.041987
[epoch2, step1042]: loss 0.041800
[epoch2, step1043]: loss 0.041557
[epoch2, step1044]: loss 0.041767
[epoch2, step1045]: loss 0.042188
[epoch2, step1046]: loss 0.044213
[epoch2, step1047]: loss 0.041609
[epoch2, step1048]: loss 0.040450
[epoch2, step1049]: loss 0.043703
[epoch2, step1050]: loss 0.042377
[epoch2, step1051]: loss 0.042657
[epoch2, step1052]: loss 0.042112
[epoch2, step1053]: loss 0.042157
[epoch2, step1054]: loss 0.042096
[epoch2, step1055]: loss 0.043508
[epoch2, step1056]: loss 0.040955
[epoch2, step1057]: loss 0.041250
[epoch2, step1058]: loss 0.044293
[epoch2, step1059]: loss 0.042362
[epoch2, step1060]: loss 0.042689
[epoch2, step1061]: loss 0.041144
[epoch2, step1062]: loss 0.042086
[epoch2, step1063]: loss 0.042104
[epoch2, step1064]: loss 0.043997
[epoch2, step1065]: loss 0.041371
[epoch2, step1066]: loss 0.040312
[epoch2, step1067]: loss 0.043643
[epoch2, step1068]: loss 0.040986
[epoch2, step1069]: loss 0.041987
[epoch2, step1070]: loss 0.041631
[epoch2, step1071]: loss 0.042186
[epoch2, step1072]: loss 0.042692
[epoch2, step1073]: loss 0.043746
[epoch2, step1074]: loss 0.041434
[epoch2, step1075]: loss 0.041001
[epoch2, step1076]: loss 0.043625
[epoch2, step1077]: loss 0.042128
[epoch2, step1078]: loss 0.042374
[epoch2, step1079]: loss 0.042558
[epoch2, step1080]: loss 0.041827
[epoch2, step1081]: loss 0.041868
[epoch2, step1082]: loss 0.043810
[epoch2, step1083]: loss 0.042011
[epoch2, step1084]: loss 0.040927
[epoch2, step1085]: loss 0.043162
[epoch2, step1086]: loss 0.041877
[epoch2, step1087]: loss 0.042620
[epoch2, step1088]: loss 0.041539
[epoch2, step1089]: loss 0.042062
[epoch2, step1090]: loss 0.042497
[epoch2, step1091]: loss 0.044283
[epoch2, step1092]: loss 0.041367
[epoch2, step1093]: loss 0.040633
[epoch2, step1094]: loss 0.042757
[epoch2, step1095]: loss 0.041760
[epoch2, step1096]: loss 0.042116
[epoch2, step1097]: loss 0.041670
[epoch2, step1098]: loss 0.041635
[epoch2, step1099]: loss 0.041772
[epoch2, step1100]: loss 0.044503
[epoch2, step1101]: loss 0.041781
[epoch2, step1102]: loss 0.040703
[epoch2, step1103]: loss 0.043164
[epoch2, step1104]: loss 0.041947
[epoch2, step1105]: loss 0.042650
[epoch2, step1106]: loss 0.040855
[epoch2, step1107]: loss 0.041867
[epoch2, step1108]: loss 0.041720
[epoch2, step1109]: loss 0.044244
[epoch2, step1110]: loss 0.042005
[epoch2, step1111]: loss 0.040915
[epoch2, step1112]: loss 0.043932
[epoch2, step1113]: loss 0.041780
[epoch2, step1114]: loss 0.042783
[epoch2, step1115]: loss 0.041709
[epoch2, step1116]: loss 0.041875
[epoch2, step1117]: loss 0.042156
[epoch2, step1118]: loss 0.043966
[epoch2, step1119]: loss 0.041275
[epoch2, step1120]: loss 0.040621
[epoch2, step1121]: loss 0.043540
[epoch2, step1122]: loss 0.041660
[epoch2, step1123]: loss 0.041887
[epoch2, step1124]: loss 0.042279
[epoch2, step1125]: loss 0.042058
[epoch2, step1126]: loss 0.042914
[epoch2, step1127]: loss 0.044036
[epoch2, step1128]: loss 0.041621
[epoch2, step1129]: loss 0.040651
[epoch2, step1130]: loss 0.044077
[epoch2, step1131]: loss 0.042407
[epoch2, step1132]: loss 0.042887
[epoch2, step1133]: loss 0.041305
[epoch2, step1134]: loss 0.041592
[epoch2, step1135]: loss 0.042898
[epoch2, step1136]: loss 0.044546
[epoch2, step1137]: loss 0.041550
[epoch2, step1138]: loss 0.040890
[epoch2, step1139]: loss 0.043645
[epoch2, step1140]: loss 0.041468
[epoch2, step1141]: loss 0.042281
[epoch2, step1142]: loss 0.041529
[epoch2, step1143]: loss 0.041405
[epoch2, step1144]: loss 0.042232
[epoch2, step1145]: loss 0.043562
[epoch2, step1146]: loss 0.041196
[epoch2, step1147]: loss 0.041456
[epoch2, step1148]: loss 0.043746
[epoch2, step1149]: loss 0.041846
[epoch2, step1150]: loss 0.042299
[epoch2, step1151]: loss 0.041915
[epoch2, step1152]: loss 0.042209
[epoch2, step1153]: loss 0.041555
[epoch2, step1154]: loss 0.044306
[epoch2, step1155]: loss 0.041528
[epoch2, step1156]: loss 0.040148
[epoch2, step1157]: loss 0.043431
[epoch2, step1158]: loss 0.042264
[epoch2, step1159]: loss 0.042646
[epoch2, step1160]: loss 0.042383
[epoch2, step1161]: loss 0.042195
[epoch2, step1162]: loss 0.041991
[epoch2, step1163]: loss 0.043454
[epoch2, step1164]: loss 0.041314
[epoch2, step1165]: loss 0.041665
[epoch2, step1166]: loss 0.043651
[epoch2, step1167]: loss 0.041404
[epoch2, step1168]: loss 0.042609
[epoch2, step1169]: loss 0.041436
[epoch2, step1170]: loss 0.041827
[epoch2, step1171]: loss 0.041923
[epoch2, step1172]: loss 0.044057
[epoch2, step1173]: loss 0.041519
[epoch2, step1174]: loss 0.041111
[epoch2, step1175]: loss 0.043494
[epoch2, step1176]: loss 0.041744
[epoch2, step1177]: loss 0.042766
[epoch2, step1178]: loss 0.041803
[epoch2, step1179]: loss 0.041550
[epoch2, step1180]: loss 0.042197
[epoch2, step1181]: loss 0.044522
[epoch2, step1182]: loss 0.040866
[epoch2, step1183]: loss 0.041194
[epoch2, step1184]: loss 0.043174
[epoch2, step1185]: loss 0.042080
[epoch2, step1186]: loss 0.041848
[epoch2, step1187]: loss 0.040936
[epoch2, step1188]: loss 0.041223
[epoch2, step1189]: loss 0.041757
[epoch2, step1190]: loss 0.043613
[epoch2, step1191]: loss 0.041976
[epoch2, step1192]: loss 0.040733
[epoch2, step1193]: loss 0.043396
[epoch2, step1194]: loss 0.041850
[epoch2, step1195]: loss 0.041453
[epoch2, step1196]: loss 0.041006
[epoch2, step1197]: loss 0.042016
[epoch2, step1198]: loss 0.042059
[epoch2, step1199]: loss 0.043613
[epoch2, step1200]: loss 0.041161
[epoch2, step1201]: loss 0.041143
[epoch2, step1202]: loss 0.044318
[epoch2, step1203]: loss 0.042086
[epoch2, step1204]: loss 0.041893
[epoch2, step1205]: loss 0.041199
[epoch2, step1206]: loss 0.041349
[epoch2, step1207]: loss 0.042226
[epoch2, step1208]: loss 0.044102
[epoch2, step1209]: loss 0.040396
[epoch2, step1210]: loss 0.041185
[epoch2, step1211]: loss 0.043058
[epoch2, step1212]: loss 0.041781
[epoch2, step1213]: loss 0.042074
[epoch2, step1214]: loss 0.041794
[epoch2, step1215]: loss 0.042285
[epoch2, step1216]: loss 0.041728
[epoch2, step1217]: loss 0.044462
[epoch2, step1218]: loss 0.041077
[epoch2, step1219]: loss 0.041364
[epoch2, step1220]: loss 0.043793
[epoch2, step1221]: loss 0.041252
[epoch2, step1222]: loss 0.042523
[epoch2, step1223]: loss 0.041518
[epoch2, step1224]: loss 0.042088
[epoch2, step1225]: loss 0.042053
[epoch2, step1226]: loss 0.043674
[epoch2, step1227]: loss 0.041349
[epoch2, step1228]: loss 0.040434
[epoch2, step1229]: loss 0.043338
[epoch2, step1230]: loss 0.042162
[epoch2, step1231]: loss 0.042258
[epoch2, step1232]: loss 0.042556
[epoch2, step1233]: loss 0.041679
[epoch2, step1234]: loss 0.041855
[epoch2, step1235]: loss 0.044448
[epoch2, step1236]: loss 0.041616
[epoch2, step1237]: loss 0.040492
[epoch2, step1238]: loss 0.043044
[epoch2, step1239]: loss 0.042421
[epoch2, step1240]: loss 0.042706
[epoch2, step1241]: loss 0.041306
[epoch2, step1242]: loss 0.041732
[epoch2, step1243]: loss 0.041904
[epoch2, step1244]: loss 0.044151
[epoch2, step1245]: loss 0.041664
[epoch2, step1246]: loss 0.041065
[epoch2, step1247]: loss 0.042785
[epoch2, step1248]: loss 0.042108
[epoch2, step1249]: loss 0.042783
[epoch2, step1250]: loss 0.041583
[epoch2, step1251]: loss 0.041878
[epoch2, step1252]: loss 0.042835
[epoch2, step1253]: loss 0.044127
[epoch2, step1254]: loss 0.041450
[epoch2, step1255]: loss 0.040950
[epoch2, step1256]: loss 0.043885
[epoch2, step1257]: loss 0.042147
[epoch2, step1258]: loss 0.042555
[epoch2, step1259]: loss 0.041362
[epoch2, step1260]: loss 0.041851
[epoch2, step1261]: loss 0.041874
[epoch2, step1262]: loss 0.042934
[epoch2, step1263]: loss 0.041877
[epoch2, step1264]: loss 0.040743
[epoch2, step1265]: loss 0.042476
[epoch2, step1266]: loss 0.041929
[epoch2, step1267]: loss 0.042462
[epoch2, step1268]: loss 0.041824
[epoch2, step1269]: loss 0.041869
[epoch2, step1270]: loss 0.041513
[epoch2, step1271]: loss 0.044362
[epoch2, step1272]: loss 0.041493
[epoch2, step1273]: loss 0.040688
[epoch2, step1274]: loss 0.043333
[epoch2, step1275]: loss 0.042371
[epoch2, step1276]: loss 0.042135
[epoch2, step1277]: loss 0.041611
[epoch2, step1278]: loss 0.042318
[epoch2, step1279]: loss 0.042162
[epoch2, step1280]: loss 0.044184
[epoch2, step1281]: loss 0.041274
[epoch2, step1282]: loss 0.040615
[epoch2, step1283]: loss 0.042970
[epoch2, step1284]: loss 0.041579
[epoch2, step1285]: loss 0.042786
[epoch2, step1286]: loss 0.041035
[epoch2, step1287]: loss 0.042343
[epoch2, step1288]: loss 0.042670
[epoch2, step1289]: loss 0.044747
[epoch2, step1290]: loss 0.041487
[epoch2, step1291]: loss 0.040611
[epoch2, step1292]: loss 0.043857
[epoch2, step1293]: loss 0.041296
[epoch2, step1294]: loss 0.042343
[epoch2, step1295]: loss 0.041981
[epoch2, step1296]: loss 0.041941
[epoch2, step1297]: loss 0.041751
[epoch2, step1298]: loss 0.044417
[epoch2, step1299]: loss 0.041567
[epoch2, step1300]: loss 0.041395
[epoch2, step1301]: loss 0.042743
[epoch2, step1302]: loss 0.042009
[epoch2, step1303]: loss 0.042550
[epoch2, step1304]: loss 0.041169
[epoch2, step1305]: loss 0.041953
[epoch2, step1306]: loss 0.041816
[epoch2, step1307]: loss 0.043500
[epoch2, step1308]: loss 0.041520
[epoch2, step1309]: loss 0.040262
[epoch2, step1310]: loss 0.043403
[epoch2, step1311]: loss 0.041112
[epoch2, step1312]: loss 0.043000
[epoch2, step1313]: loss 0.041733
[epoch2, step1314]: loss 0.041762
[epoch2, step1315]: loss 0.041775
[epoch2, step1316]: loss 0.045221
[epoch2, step1317]: loss 0.040940
[epoch2, step1318]: loss 0.040472
[epoch2, step1319]: loss 0.043007
[epoch2, step1320]: loss 0.042133
[epoch2, step1321]: loss 0.042776
[epoch2, step1322]: loss 0.041400
[epoch2, step1323]: loss 0.042080
[epoch2, step1324]: loss 0.041685
[epoch2, step1325]: loss 0.043920
[epoch2, step1326]: loss 0.041195
[epoch2, step1327]: loss 0.040646
[epoch2, step1328]: loss 0.043521
[epoch2, step1329]: loss 0.041896
[epoch2, step1330]: loss 0.042583
[epoch2, step1331]: loss 0.041452
[epoch2, step1332]: loss 0.041731
[epoch2, step1333]: loss 0.041199
[epoch2, step1334]: loss 0.044270
[epoch2, step1335]: loss 0.041885
[epoch2, step1336]: loss 0.040715
[epoch2, step1337]: loss 0.042980
[epoch2, step1338]: loss 0.041758
[epoch2, step1339]: loss 0.042488
[epoch2, step1340]: loss 0.041314
[epoch2, step1341]: loss 0.041974
[epoch2, step1342]: loss 0.041850
[epoch2, step1343]: loss 0.044127
[epoch2, step1344]: loss 0.041523
[epoch2, step1345]: loss 0.040724
[epoch2, step1346]: loss 0.043135
[epoch2, step1347]: loss 0.042486
[epoch2, step1348]: loss 0.041945
[epoch2, step1349]: loss 0.041720
[epoch2, step1350]: loss 0.041719
[epoch2, step1351]: loss 0.041581
[epoch2, step1352]: loss 0.043394
[epoch2, step1353]: loss 0.041125
[epoch2, step1354]: loss 0.040523
[epoch2, step1355]: loss 0.043525
[epoch2, step1356]: loss 0.041551
[epoch2, step1357]: loss 0.041868
[epoch2, step1358]: loss 0.041413
[epoch2, step1359]: loss 0.041414
[epoch2, step1360]: loss 0.042067
[epoch2, step1361]: loss 0.044257
[epoch2, step1362]: loss 0.041887
[epoch2, step1363]: loss 0.041150
[epoch2, step1364]: loss 0.043362
[epoch2, step1365]: loss 0.041888
[epoch2, step1366]: loss 0.042234
[epoch2, step1367]: loss 0.040901
[epoch2, step1368]: loss 0.042430
[epoch2, step1369]: loss 0.042033
[epoch2, step1370]: loss 0.043763
[epoch2, step1371]: loss 0.041561
[epoch2, step1372]: loss 0.040569
[epoch2, step1373]: loss 0.043398
[epoch2, step1374]: loss 0.042567
[epoch2, step1375]: loss 0.043015
[epoch2, step1376]: loss 0.041435
[epoch2, step1377]: loss 0.041069
[epoch2, step1378]: loss 0.042116
[epoch2, step1379]: loss 0.043610
[epoch2, step1380]: loss 0.041622
[epoch2, step1381]: loss 0.040744
[epoch2, step1382]: loss 0.043671
[epoch2, step1383]: loss 0.041723
[epoch2, step1384]: loss 0.042286
[epoch2, step1385]: loss 0.041067
[epoch2, step1386]: loss 0.041956
[epoch2, step1387]: loss 0.042365
[epoch2, step1388]: loss 0.043071
[epoch2, step1389]: loss 0.040743
[epoch2, step1390]: loss 0.040827
[epoch2, step1391]: loss 0.043207
[epoch2, step1392]: loss 0.041734
[epoch2, step1393]: loss 0.042606
[epoch2, step1394]: loss 0.042040
[epoch2, step1395]: loss 0.041896
[epoch2, step1396]: loss 0.041651
[epoch2, step1397]: loss 0.043683
[epoch2, step1398]: loss 0.041265
[epoch2, step1399]: loss 0.041471
[epoch2, step1400]: loss 0.043823
[epoch2, step1401]: loss 0.041758
[epoch2, step1402]: loss 0.042441
[epoch2, step1403]: loss 0.040711
[epoch2, step1404]: loss 0.041339
[epoch2, step1405]: loss 0.041854
[epoch2, step1406]: loss 0.043669
[epoch2, step1407]: loss 0.042236
[epoch2, step1408]: loss 0.040266
[epoch2, step1409]: loss 0.043025
[epoch2, step1410]: loss 0.041913
[epoch2, step1411]: loss 0.041470
[epoch2, step1412]: loss 0.041647
[epoch2, step1413]: loss 0.041821
[epoch2, step1414]: loss 0.041642
[epoch2, step1415]: loss 0.043594
[epoch2, step1416]: loss 0.041219
[epoch2, step1417]: loss 0.040696
[epoch2, step1418]: loss 0.043316
[epoch2, step1419]: loss 0.042450
[epoch2, step1420]: loss 0.042598
[epoch2, step1421]: loss 0.041878
[epoch2, step1422]: loss 0.041777
[epoch2, step1423]: loss 0.041593
[epoch2, step1424]: loss 0.044084
[epoch2, step1425]: loss 0.040480
[epoch2, step1426]: loss 0.040832
[epoch2, step1427]: loss 0.043951
[epoch2, step1428]: loss 0.042561
[epoch2, step1429]: loss 0.042371
[epoch2, step1430]: loss 0.041600
[epoch2, step1431]: loss 0.041877
[epoch2, step1432]: loss 0.041710
[epoch2, step1433]: loss 0.044105
[epoch2, step1434]: loss 0.040795
[epoch2, step1435]: loss 0.041199
[epoch2, step1436]: loss 0.043710
[epoch2, step1437]: loss 0.042060
[epoch2, step1438]: loss 0.042793
[epoch2, step1439]: loss 0.041437
[epoch2, step1440]: loss 0.041495
[epoch2, step1441]: loss 0.042471
[epoch2, step1442]: loss 0.043288
[epoch2, step1443]: loss 0.041026
[epoch2, step1444]: loss 0.040132
[epoch2, step1445]: loss 0.043754
[epoch2, step1446]: loss 0.042053
[epoch2, step1447]: loss 0.042939
[epoch2, step1448]: loss 0.041430
[epoch2, step1449]: loss 0.041167
[epoch2, step1450]: loss 0.042012
[epoch2, step1451]: loss 0.044068
[epoch2, step1452]: loss 0.041064
[epoch2, step1453]: loss 0.041626
[epoch2, step1454]: loss 0.043710
[epoch2, step1455]: loss 0.042463
[epoch2, step1456]: loss 0.042053
[epoch2, step1457]: loss 0.042008
[epoch2, step1458]: loss 0.041762
[epoch2, step1459]: loss 0.041869
[epoch2, step1460]: loss 0.044377
[epoch2, step1461]: loss 0.041779
[epoch2, step1462]: loss 0.041193
[epoch2, step1463]: loss 0.043333
[epoch2, step1464]: loss 0.042173
[epoch2, step1465]: loss 0.041936
[epoch2, step1466]: loss 0.041193
[epoch2, step1467]: loss 0.041633
[epoch2, step1468]: loss 0.041443
[epoch2, step1469]: loss 0.043880
[epoch2, step1470]: loss 0.041307
[epoch2, step1471]: loss 0.040525
[epoch2, step1472]: loss 0.043117
[epoch2, step1473]: loss 0.041889
[epoch2, step1474]: loss 0.042838
[epoch2, step1475]: loss 0.041192
[epoch2, step1476]: loss 0.042427
[epoch2, step1477]: loss 0.041658
[epoch2, step1478]: loss 0.044039
[epoch2, step1479]: loss 0.041157
[epoch2, step1480]: loss 0.040733
[epoch2, step1481]: loss 0.042508
[epoch2, step1482]: loss 0.041886
[epoch2, step1483]: loss 0.042457
[epoch2, step1484]: loss 0.041839
[epoch2, step1485]: loss 0.041362
[epoch2, step1486]: loss 0.040941
[epoch2, step1487]: loss 0.043718
[epoch2, step1488]: loss 0.041306
[epoch2, step1489]: loss 0.040558
[epoch2, step1490]: loss 0.043295
[epoch2, step1491]: loss 0.041924
[epoch2, step1492]: loss 0.042166
[epoch2, step1493]: loss 0.041511
[epoch2, step1494]: loss 0.041842
[epoch2, step1495]: loss 0.041543
[epoch2, step1496]: loss 0.043117
[epoch2, step1497]: loss 0.041431
[epoch2, step1498]: loss 0.040810
[epoch2, step1499]: loss 0.042905
[epoch2, step1500]: loss 0.041914
[epoch2, step1501]: loss 0.042355
[epoch2, step1502]: loss 0.041294
[epoch2, step1503]: loss 0.041627
[epoch2, step1504]: loss 0.041417
[epoch2, step1505]: loss 0.044160
[epoch2, step1506]: loss 0.040724
[epoch2, step1507]: loss 0.041044
[epoch2, step1508]: loss 0.043852
[epoch2, step1509]: loss 0.041657
[epoch2, step1510]: loss 0.041559
[epoch2, step1511]: loss 0.041987
[epoch2, step1512]: loss 0.041653
[epoch2, step1513]: loss 0.040781
[epoch2, step1514]: loss 0.043832
[epoch2, step1515]: loss 0.041578
[epoch2, step1516]: loss 0.040678

[epoch2]: avg loss 0.037306

[epoch3, step1]: loss 0.037311
[epoch3, step2]: loss 0.043141
[epoch3, step3]: loss 0.043344
[epoch3, step4]: loss 0.040762
[epoch3, step5]: loss 0.041231
[epoch3, step6]: loss 0.043290
[epoch3, step7]: loss 0.040956
[epoch3, step8]: loss 0.044338
[epoch3, step9]: loss 0.041022
[epoch3, step10]: loss 0.040784
[epoch3, step11]: loss 0.043474
[epoch3, step12]: loss 0.043550
[epoch3, step13]: loss 0.041115
[epoch3, step14]: loss 0.041367
[epoch3, step15]: loss 0.043196
[epoch3, step16]: loss 0.040850
[epoch3, step17]: loss 0.044574
[epoch3, step18]: loss 0.042116
[epoch3, step19]: loss 0.040685
[epoch3, step20]: loss 0.044117
[epoch3, step21]: loss 0.043618
[epoch3, step22]: loss 0.040802
[epoch3, step23]: loss 0.040501
[epoch3, step24]: loss 0.043211
[epoch3, step25]: loss 0.040306
[epoch3, step26]: loss 0.043627
[epoch3, step27]: loss 0.040967
[epoch3, step28]: loss 0.040544
[epoch3, step29]: loss 0.043449
[epoch3, step30]: loss 0.044123
[epoch3, step31]: loss 0.040643
[epoch3, step32]: loss 0.041535
[epoch3, step33]: loss 0.043793
[epoch3, step34]: loss 0.041368
[epoch3, step35]: loss 0.044531
[epoch3, step36]: loss 0.041322
[epoch3, step37]: loss 0.040494
[epoch3, step38]: loss 0.043212
[epoch3, step39]: loss 0.043524
[epoch3, step40]: loss 0.041378
[epoch3, step41]: loss 0.040691
[epoch3, step42]: loss 0.043507
[epoch3, step43]: loss 0.040684
[epoch3, step44]: loss 0.044522
[epoch3, step45]: loss 0.041437
[epoch3, step46]: loss 0.040609
[epoch3, step47]: loss 0.043066
[epoch3, step48]: loss 0.043330
[epoch3, step49]: loss 0.039675
[epoch3, step50]: loss 0.041307
[epoch3, step51]: loss 0.043015
[epoch3, step52]: loss 0.040652
[epoch3, step53]: loss 0.044821
[epoch3, step54]: loss 0.041223
[epoch3, step55]: loss 0.040850
[epoch3, step56]: loss 0.044194
[epoch3, step57]: loss 0.044034
[epoch3, step58]: loss 0.041116
[epoch3, step59]: loss 0.040386
[epoch3, step60]: loss 0.043619
[epoch3, step61]: loss 0.040152
[epoch3, step62]: loss 0.043768
[epoch3, step63]: loss 0.040798
[epoch3, step64]: loss 0.040104
[epoch3, step65]: loss 0.043543
[epoch3, step66]: loss 0.043608
[epoch3, step67]: loss 0.041222
[epoch3, step68]: loss 0.041199
[epoch3, step69]: loss 0.043181
[epoch3, step70]: loss 0.040612
[epoch3, step71]: loss 0.043853
[epoch3, step72]: loss 0.041401
[epoch3, step73]: loss 0.040283
[epoch3, step74]: loss 0.043518
[epoch3, step75]: loss 0.043727
[epoch3, step76]: loss 0.041591
[epoch3, step77]: loss 0.041703
[epoch3, step78]: loss 0.043369
[epoch3, step79]: loss 0.040262
[epoch3, step80]: loss 0.044905
[epoch3, step81]: loss 0.041434
[epoch3, step82]: loss 0.040181
[epoch3, step83]: loss 0.042714
[epoch3, step84]: loss 0.043835
[epoch3, step85]: loss 0.041610
[epoch3, step86]: loss 0.041299
[epoch3, step87]: loss 0.044160
[epoch3, step88]: loss 0.039765
[epoch3, step89]: loss 0.043869
[epoch3, step90]: loss 0.041739
[epoch3, step91]: loss 0.039993
[epoch3, step92]: loss 0.043522
[epoch3, step93]: loss 0.043582
[epoch3, step94]: loss 0.040954
[epoch3, step95]: loss 0.041561
[epoch3, step96]: loss 0.043016
[epoch3, step97]: loss 0.041288
[epoch3, step98]: loss 0.044199
[epoch3, step99]: loss 0.041479
[epoch3, step100]: loss 0.039607
[epoch3, step101]: loss 0.043889
[epoch3, step102]: loss 0.043604
[epoch3, step103]: loss 0.041009
[epoch3, step104]: loss 0.041243
[epoch3, step105]: loss 0.043380
[epoch3, step106]: loss 0.040654
[epoch3, step107]: loss 0.044117
[epoch3, step108]: loss 0.041611
[epoch3, step109]: loss 0.040082
[epoch3, step110]: loss 0.043974
[epoch3, step111]: loss 0.043446
[epoch3, step112]: loss 0.041253
[epoch3, step113]: loss 0.041882
[epoch3, step114]: loss 0.043124
[epoch3, step115]: loss 0.040731
[epoch3, step116]: loss 0.044818
[epoch3, step117]: loss 0.041409
[epoch3, step118]: loss 0.040870
[epoch3, step119]: loss 0.043806
[epoch3, step120]: loss 0.043736
[epoch3, step121]: loss 0.040860
[epoch3, step122]: loss 0.041088
[epoch3, step123]: loss 0.043605
[epoch3, step124]: loss 0.040941
[epoch3, step125]: loss 0.044593
[epoch3, step126]: loss 0.041363
[epoch3, step127]: loss 0.040282
[epoch3, step128]: loss 0.043348
[epoch3, step129]: loss 0.043259
[epoch3, step130]: loss 0.041210
[epoch3, step131]: loss 0.040636
[epoch3, step132]: loss 0.043425
[epoch3, step133]: loss 0.040498
[epoch3, step134]: loss 0.043726
[epoch3, step135]: loss 0.041882
[epoch3, step136]: loss 0.041245
[epoch3, step137]: loss 0.043159
[epoch3, step138]: loss 0.043545
[epoch3, step139]: loss 0.040931
[epoch3, step140]: loss 0.041577
[epoch3, step141]: loss 0.043467
[epoch3, step142]: loss 0.040613
[epoch3, step143]: loss 0.043837
[epoch3, step144]: loss 0.041690
[epoch3, step145]: loss 0.040439
[epoch3, step146]: loss 0.043546
[epoch3, step147]: loss 0.044810
[epoch3, step148]: loss 0.040925
[epoch3, step149]: loss 0.040741
[epoch3, step150]: loss 0.042962
[epoch3, step151]: loss 0.040766
[epoch3, step152]: loss 0.044234
[epoch3, step153]: loss 0.041617
[epoch3, step154]: loss 0.039959
[epoch3, step155]: loss 0.043466
[epoch3, step156]: loss 0.043345
[epoch3, step157]: loss 0.041251
[epoch3, step158]: loss 0.041366
[epoch3, step159]: loss 0.043561
[epoch3, step160]: loss 0.040954
[epoch3, step161]: loss 0.044721
[epoch3, step162]: loss 0.041654
[epoch3, step163]: loss 0.040208
[epoch3, step164]: loss 0.043749
[epoch3, step165]: loss 0.043720
[epoch3, step166]: loss 0.041387
[epoch3, step167]: loss 0.040797
[epoch3, step168]: loss 0.043798
[epoch3, step169]: loss 0.040406
[epoch3, step170]: loss 0.044492
[epoch3, step171]: loss 0.041687
[epoch3, step172]: loss 0.040392
[epoch3, step173]: loss 0.043750
[epoch3, step174]: loss 0.043491
[epoch3, step175]: loss 0.041753
[epoch3, step176]: loss 0.041443
[epoch3, step177]: loss 0.043589
[epoch3, step178]: loss 0.040676
[epoch3, step179]: loss 0.043413
[epoch3, step180]: loss 0.041734
[epoch3, step181]: loss 0.040379
[epoch3, step182]: loss 0.043661
[epoch3, step183]: loss 0.044164
[epoch3, step184]: loss 0.041891
[epoch3, step185]: loss 0.041337
[epoch3, step186]: loss 0.043328
[epoch3, step187]: loss 0.040643
[epoch3, step188]: loss 0.043771
[epoch3, step189]: loss 0.041313
[epoch3, step190]: loss 0.039743
[epoch3, step191]: loss 0.042992
[epoch3, step192]: loss 0.043826
[epoch3, step193]: loss 0.039240
[epoch3, step194]: loss 0.040204
[epoch3, step195]: loss 0.043311
[epoch3, step196]: loss 0.040438
[epoch3, step197]: loss 0.043681
[epoch3, step198]: loss 0.040278
[epoch3, step199]: loss 0.040028
[epoch3, step200]: loss 0.043506
[epoch3, step201]: loss 0.043738
[epoch3, step202]: loss 0.040380
[epoch3, step203]: loss 0.040802
[epoch3, step204]: loss 0.043229
[epoch3, step205]: loss 0.039680
[epoch3, step206]: loss 0.043413
[epoch3, step207]: loss 0.040787
[epoch3, step208]: loss 0.040243
[epoch3, step209]: loss 0.043178
[epoch3, step210]: loss 0.043983
[epoch3, step211]: loss 0.041069
[epoch3, step212]: loss 0.041033
[epoch3, step213]: loss 0.042556
[epoch3, step214]: loss 0.039651
[epoch3, step215]: loss 0.043733
[epoch3, step216]: loss 0.041062
[epoch3, step217]: loss 0.038969
[epoch3, step218]: loss 0.043143
[epoch3, step219]: loss 0.042844
[epoch3, step220]: loss 0.040730
[epoch3, step221]: loss 0.040799
[epoch3, step222]: loss 0.042848
[epoch3, step223]: loss 0.040303
[epoch3, step224]: loss 0.043118
[epoch3, step225]: loss 0.040741
[epoch3, step226]: loss 0.039619
[epoch3, step227]: loss 0.042018
[epoch3, step228]: loss 0.043450
[epoch3, step229]: loss 0.039634
[epoch3, step230]: loss 0.040737
[epoch3, step231]: loss 0.042985
[epoch3, step232]: loss 0.039553
[epoch3, step233]: loss 0.042580
[epoch3, step234]: loss 0.040206
[epoch3, step235]: loss 0.039871
[epoch3, step236]: loss 0.042794
[epoch3, step237]: loss 0.042984
[epoch3, step238]: loss 0.039941
[epoch3, step239]: loss 0.039660
[epoch3, step240]: loss 0.042056
[epoch3, step241]: loss 0.040275
[epoch3, step242]: loss 0.043020
[epoch3, step243]: loss 0.040995
[epoch3, step244]: loss 0.039388
[epoch3, step245]: loss 0.042210
[epoch3, step246]: loss 0.042705
[epoch3, step247]: loss 0.040289
[epoch3, step248]: loss 0.039829
[epoch3, step249]: loss 0.041955
[epoch3, step250]: loss 0.039833
[epoch3, step251]: loss 0.043467
[epoch3, step252]: loss 0.040764
[epoch3, step253]: loss 0.039041
[epoch3, step254]: loss 0.041823
[epoch3, step255]: loss 0.042632
[epoch3, step256]: loss 0.039641
[epoch3, step257]: loss 0.039775
[epoch3, step258]: loss 0.042747
[epoch3, step259]: loss 0.039530
[epoch3, step260]: loss 0.042165
[epoch3, step261]: loss 0.040808
[epoch3, step262]: loss 0.039554
[epoch3, step263]: loss 0.041556
[epoch3, step264]: loss 0.042029
[epoch3, step265]: loss 0.039869
[epoch3, step266]: loss 0.039712
[epoch3, step267]: loss 0.041430
[epoch3, step268]: loss 0.039356
[epoch3, step269]: loss 0.042487
[epoch3, step270]: loss 0.039465
[epoch3, step271]: loss 0.038984
[epoch3, step272]: loss 0.042428
[epoch3, step273]: loss 0.041952
[epoch3, step274]: loss 0.039878
[epoch3, step275]: loss 0.039399
[epoch3, step276]: loss 0.041431
[epoch3, step277]: loss 0.039545
[epoch3, step278]: loss 0.042405
[epoch3, step279]: loss 0.039125
[epoch3, step280]: loss 0.038648
[epoch3, step281]: loss 0.041479
[epoch3, step282]: loss 0.042131
[epoch3, step283]: loss 0.038520
[epoch3, step284]: loss 0.038480
[epoch3, step285]: loss 0.042042
[epoch3, step286]: loss 0.038073
[epoch3, step287]: loss 0.041787
[epoch3, step288]: loss 0.038538
[epoch3, step289]: loss 0.039096
[epoch3, step290]: loss 0.041468
[epoch3, step291]: loss 0.041684
[epoch3, step292]: loss 0.037878
[epoch3, step293]: loss 0.038154
[epoch3, step294]: loss 0.041017
[epoch3, step295]: loss 0.038997
[epoch3, step296]: loss 0.042162
[epoch3, step297]: loss 0.038709
[epoch3, step298]: loss 0.039303
[epoch3, step299]: loss 0.040808
[epoch3, step300]: loss 0.041461
[epoch3, step301]: loss 0.038984
[epoch3, step302]: loss 0.038941
[epoch3, step303]: loss 0.041436
[epoch3, step304]: loss 0.038042
[epoch3, step305]: loss 0.040892
[epoch3, step306]: loss 0.038249
[epoch3, step307]: loss 0.037694
[epoch3, step308]: loss 0.042261
[epoch3, step309]: loss 0.041087
[epoch3, step310]: loss 0.038455
[epoch3, step311]: loss 0.039191
[epoch3, step312]: loss 0.040666
[epoch3, step313]: loss 0.040064
[epoch3, step314]: loss 0.043344
[epoch3, step315]: loss 0.040124
[epoch3, step316]: loss 0.037597
[epoch3, step317]: loss 0.041206
[epoch3, step318]: loss 0.041098
[epoch3, step319]: loss 0.037500
[epoch3, step320]: loss 0.037156
[epoch3, step321]: loss 0.040507
[epoch3, step322]: loss 0.037976
[epoch3, step323]: loss 0.040187
[epoch3, step324]: loss 0.038714
[epoch3, step325]: loss 0.037994
[epoch3, step326]: loss 0.041128
[epoch3, step327]: loss 0.040625
[epoch3, step328]: loss 0.037885
[epoch3, step329]: loss 0.038031
[epoch3, step330]: loss 0.040543
[epoch3, step331]: loss 0.038144
[epoch3, step332]: loss 0.040336
[epoch3, step333]: loss 0.037834
[epoch3, step334]: loss 0.037825
[epoch3, step335]: loss 0.040844
[epoch3, step336]: loss 0.041552
[epoch3, step337]: loss 0.037815
[epoch3, step338]: loss 0.037495
[epoch3, step339]: loss 0.040246
[epoch3, step340]: loss 0.038602
[epoch3, step341]: loss 0.040192
[epoch3, step342]: loss 0.037570
[epoch3, step343]: loss 0.038138
[epoch3, step344]: loss 0.040248
[epoch3, step345]: loss 0.040168
[epoch3, step346]: loss 0.037174
[epoch3, step347]: loss 0.037624
[epoch3, step348]: loss 0.040834
[epoch3, step349]: loss 0.038215
[epoch3, step350]: loss 0.040188
[epoch3, step351]: loss 0.036853
[epoch3, step352]: loss 0.037569
[epoch3, step353]: loss 0.040326
[epoch3, step354]: loss 0.039561
[epoch3, step355]: loss 0.036568
[epoch3, step356]: loss 0.038282
[epoch3, step357]: loss 0.040463
[epoch3, step358]: loss 0.036416
[epoch3, step359]: loss 0.041294
[epoch3, step360]: loss 0.036478
[epoch3, step361]: loss 0.036883
[epoch3, step362]: loss 0.041512
[epoch3, step363]: loss 0.040225
[epoch3, step364]: loss 0.037522
[epoch3, step365]: loss 0.037821
[epoch3, step366]: loss 0.040900
[epoch3, step367]: loss 0.037996
[epoch3, step368]: loss 0.041017
[epoch3, step369]: loss 0.037431
[epoch3, step370]: loss 0.038251
[epoch3, step371]: loss 0.041550
[epoch3, step372]: loss 0.040008
[epoch3, step373]: loss 0.037056
[epoch3, step374]: loss 0.036675
[epoch3, step375]: loss 0.040748
[epoch3, step376]: loss 0.037482
[epoch3, step377]: loss 0.040542
[epoch3, step378]: loss 0.037639
[epoch3, step379]: loss 0.037888
[epoch3, step380]: loss 0.040729
[epoch3, step381]: loss 0.039865
[epoch3, step382]: loss 0.037723
[epoch3, step383]: loss 0.036454
[epoch3, step384]: loss 0.039349
[epoch3, step385]: loss 0.037351
[epoch3, step386]: loss 0.040410
[epoch3, step387]: loss 0.037300
[epoch3, step388]: loss 0.038061
[epoch3, step389]: loss 0.040197
[epoch3, step390]: loss 0.040887
[epoch3, step391]: loss 0.037041
[epoch3, step392]: loss 0.037842
[epoch3, step393]: loss 0.039663
[epoch3, step394]: loss 0.037639
[epoch3, step395]: loss 0.040112
[epoch3, step396]: loss 0.037592
[epoch3, step397]: loss 0.036894
[epoch3, step398]: loss 0.040866
[epoch3, step399]: loss 0.040792
[epoch3, step400]: loss 0.036924
[epoch3, step401]: loss 0.037505
[epoch3, step402]: loss 0.040480
[epoch3, step403]: loss 0.037483
[epoch3, step404]: loss 0.040395
[epoch3, step405]: loss 0.037849
[epoch3, step406]: loss 0.037611
[epoch3, step407]: loss 0.039805
[epoch3, step408]: loss 0.040253
[epoch3, step409]: loss 0.038447
[epoch3, step410]: loss 0.037618
[epoch3, step411]: loss 0.040171
[epoch3, step412]: loss 0.037373
[epoch3, step413]: loss 0.039847
[epoch3, step414]: loss 0.037255
[epoch3, step415]: loss 0.038058
[epoch3, step416]: loss 0.039502
[epoch3, step417]: loss 0.040088
[epoch3, step418]: loss 0.037119
[epoch3, step419]: loss 0.036125
[epoch3, step420]: loss 0.039900
[epoch3, step421]: loss 0.036737
[epoch3, step422]: loss 0.039615
[epoch3, step423]: loss 0.036774
[epoch3, step424]: loss 0.039389
[epoch3, step425]: loss 0.042787
[epoch3, step426]: loss 0.044154
[epoch3, step427]: loss 0.038176
[epoch3, step428]: loss 0.037063
[epoch3, step429]: loss 0.042127
[epoch3, step430]: loss 0.038391
[epoch3, step431]: loss 0.040802
[epoch3, step432]: loss 0.036949
[epoch3, step433]: loss 0.037595
[epoch3, step434]: loss 0.040820
[epoch3, step435]: loss 0.041171
[epoch3, step436]: loss 0.037971
[epoch3, step437]: loss 0.038259
[epoch3, step438]: loss 0.041829
[epoch3, step439]: loss 0.039448
[epoch3, step440]: loss 0.041309
[epoch3, step441]: loss 0.039081
[epoch3, step442]: loss 0.038314
[epoch3, step443]: loss 0.041460
[epoch3, step444]: loss 0.040803
[epoch3, step445]: loss 0.038564
[epoch3, step446]: loss 0.038666
[epoch3, step447]: loss 0.041811
[epoch3, step448]: loss 0.038364
[epoch3, step449]: loss 0.041210
[epoch3, step450]: loss 0.037871
[epoch3, step451]: loss 0.037777
[epoch3, step452]: loss 0.040171
[epoch3, step453]: loss 0.041449
[epoch3, step454]: loss 0.038076
[epoch3, step455]: loss 0.038716
[epoch3, step456]: loss 0.040180
[epoch3, step457]: loss 0.038929
[epoch3, step458]: loss 0.040991
[epoch3, step459]: loss 0.038994
[epoch3, step460]: loss 0.038158
[epoch3, step461]: loss 0.041770
[epoch3, step462]: loss 0.040363
[epoch3, step463]: loss 0.038194
[epoch3, step464]: loss 0.037967
[epoch3, step465]: loss 0.041986
[epoch3, step466]: loss 0.037917
[epoch3, step467]: loss 0.040668
[epoch3, step468]: loss 0.038155
[epoch3, step469]: loss 0.038021
[epoch3, step470]: loss 0.041527
[epoch3, step471]: loss 0.040438
[epoch3, step472]: loss 0.038515
[epoch3, step473]: loss 0.038227
[epoch3, step474]: loss 0.040849
[epoch3, step475]: loss 0.038485
[epoch3, step476]: loss 0.041738
[epoch3, step477]: loss 0.037965
[epoch3, step478]: loss 0.037632
[epoch3, step479]: loss 0.040822
[epoch3, step480]: loss 0.039862
[epoch3, step481]: loss 0.037382
[epoch3, step482]: loss 0.037301
[epoch3, step483]: loss 0.041055
[epoch3, step484]: loss 0.038137
[epoch3, step485]: loss 0.040940
[epoch3, step486]: loss 0.038397
[epoch3, step487]: loss 0.037163
[epoch3, step488]: loss 0.041469
[epoch3, step489]: loss 0.040063
[epoch3, step490]: loss 0.038172
[epoch3, step491]: loss 0.038359
[epoch3, step492]: loss 0.040315
[epoch3, step493]: loss 0.037912
[epoch3, step494]: loss 0.040412
[epoch3, step495]: loss 0.038990
[epoch3, step496]: loss 0.037959
[epoch3, step497]: loss 0.040898
[epoch3, step498]: loss 0.040349
[epoch3, step499]: loss 0.038023
[epoch3, step500]: loss 0.037364
[epoch3, step501]: loss 0.040100
[epoch3, step502]: loss 0.037693
[epoch3, step503]: loss 0.040701
[epoch3, step504]: loss 0.037607
[epoch3, step505]: loss 0.037002
[epoch3, step506]: loss 0.041234
[epoch3, step507]: loss 0.040704
[epoch3, step508]: loss 0.038203
[epoch3, step509]: loss 0.037841
[epoch3, step510]: loss 0.040626
[epoch3, step511]: loss 0.038517
[epoch3, step512]: loss 0.040846
[epoch3, step513]: loss 0.038130
[epoch3, step514]: loss 0.038402
[epoch3, step515]: loss 0.040696
[epoch3, step516]: loss 0.041188
[epoch3, step517]: loss 0.037757
[epoch3, step518]: loss 0.037818
[epoch3, step519]: loss 0.040565
[epoch3, step520]: loss 0.037289
[epoch3, step521]: loss 0.040039
[epoch3, step522]: loss 0.037082
[epoch3, step523]: loss 0.037698
[epoch3, step524]: loss 0.040017
[epoch3, step525]: loss 0.040790
[epoch3, step526]: loss 0.037637
[epoch3, step527]: loss 0.037479
[epoch3, step528]: loss 0.040657
[epoch3, step529]: loss 0.037443
[epoch3, step530]: loss 0.040731
[epoch3, step531]: loss 0.037671
[epoch3, step532]: loss 0.037327
[epoch3, step533]: loss 0.041662
[epoch3, step534]: loss 0.040490
[epoch3, step535]: loss 0.037847
[epoch3, step536]: loss 0.037940
[epoch3, step537]: loss 0.040438
[epoch3, step538]: loss 0.038146
[epoch3, step539]: loss 0.040342
[epoch3, step540]: loss 0.037261
[epoch3, step541]: loss 0.037374
[epoch3, step542]: loss 0.040574
[epoch3, step543]: loss 0.040193
[epoch3, step544]: loss 0.037328
[epoch3, step545]: loss 0.036938
[epoch3, step546]: loss 0.041019
[epoch3, step547]: loss 0.037446
[epoch3, step548]: loss 0.040211
[epoch3, step549]: loss 0.037917
[epoch3, step550]: loss 0.037727
[epoch3, step551]: loss 0.040484
[epoch3, step552]: loss 0.039915
[epoch3, step553]: loss 0.037819
[epoch3, step554]: loss 0.037516
[epoch3, step555]: loss 0.040143
[epoch3, step556]: loss 0.037817
[epoch3, step557]: loss 0.039808
[epoch3, step558]: loss 0.037952
[epoch3, step559]: loss 0.037242
[epoch3, step560]: loss 0.040549
[epoch3, step561]: loss 0.040435
[epoch3, step562]: loss 0.037375
[epoch3, step563]: loss 0.029472
[epoch3, step564]: loss 0.028937
[epoch3, step565]: loss 0.027748
[epoch3, step566]: loss 0.034714
[epoch3, step567]: loss 0.026326
[epoch3, step568]: loss 0.025376
[epoch3, step569]: loss 0.022507
[epoch3, step570]: loss 0.031954
[epoch3, step571]: loss 0.028006
[epoch3, step572]: loss 0.026450
[epoch3, step573]: loss 0.029645
[epoch3, step574]: loss 0.028619
[epoch3, step575]: loss 0.020859
[epoch3, step576]: loss 0.022112
[epoch3, step577]: loss 0.026507
[epoch3, step578]: loss 0.019000
[epoch3, step579]: loss 0.029133
[epoch3, step580]: loss 0.020339
[epoch3, step581]: loss 0.025868
[epoch3, step582]: loss 0.025775
[epoch3, step583]: loss 0.022394
[epoch3, step584]: loss 0.023911
[epoch3, step585]: loss 0.026681
[epoch3, step586]: loss 0.021894
[epoch3, step587]: loss 0.028275
[epoch3, step588]: loss 0.023373
[epoch3, step589]: loss 0.023318
[epoch3, step590]: loss 0.028110
[epoch3, step591]: loss 0.020706
[epoch3, step592]: loss 0.026277
[epoch3, step593]: loss 0.022368
[epoch3, step594]: loss 0.026077
[epoch3, step595]: loss 0.026686
[epoch3, step596]: loss 0.022753
[epoch3, step597]: loss 0.025328
[epoch3, step598]: loss 0.026502
[epoch3, step599]: loss 0.025440
[epoch3, step600]: loss 0.027317
[epoch3, step601]: loss 0.019622
[epoch3, step602]: loss 0.022713
[epoch3, step603]: loss 0.026020
[epoch3, step604]: loss 0.026805
[epoch3, step605]: loss 0.025568
[epoch3, step606]: loss 0.024934
[epoch3, step607]: loss 0.027728
[epoch3, step608]: loss 0.026027
[epoch3, step609]: loss 0.026988
[epoch3, step610]: loss 0.026103
[epoch3, step611]: loss 0.026529
[epoch3, step612]: loss 0.025712
[epoch3, step613]: loss 0.019597
[epoch3, step614]: loss 0.025320
[epoch3, step615]: loss 0.028297
[epoch3, step616]: loss 0.024114
[epoch3, step617]: loss 0.023823
[epoch3, step618]: loss 0.025839
[epoch3, step619]: loss 0.026803
[epoch3, step620]: loss 0.024472
[epoch3, step621]: loss 0.026403
[epoch3, step622]: loss 0.020891
[epoch3, step623]: loss 0.024580
[epoch3, step624]: loss 0.026551
[epoch3, step625]: loss 0.026279
[epoch3, step626]: loss 0.028687
[epoch3, step627]: loss 0.023272
[epoch3, step628]: loss 0.026059
[epoch3, step629]: loss 0.020940
[epoch3, step630]: loss 0.023596
[epoch3, step631]: loss 0.031246
[epoch3, step632]: loss 0.023505
[epoch3, step633]: loss 0.024785
[epoch3, step634]: loss 0.027213
[epoch3, step635]: loss 0.025950
[epoch3, step636]: loss 0.021030
[epoch3, step637]: loss 0.027504
[epoch3, step638]: loss 0.027236
[epoch3, step639]: loss 0.023065
[epoch3, step640]: loss 0.029565
[epoch3, step641]: loss 0.030534
[epoch3, step642]: loss 0.025182
[epoch3, step643]: loss 0.025918
[epoch3, step644]: loss 0.026386
[epoch3, step645]: loss 0.023824
[epoch3, step646]: loss 0.026801
[epoch3, step647]: loss 0.023891
[epoch3, step648]: loss 0.023401
[epoch3, step649]: loss 0.028734
[epoch3, step650]: loss 0.022632
[epoch3, step651]: loss 0.026309
[epoch3, step652]: loss 0.026936
[epoch3, step653]: loss 0.028387
[epoch3, step654]: loss 0.023493
[epoch3, step655]: loss 0.024200
[epoch3, step656]: loss 0.021824
[epoch3, step657]: loss 0.028045
[epoch3, step658]: loss 0.025369
[epoch3, step659]: loss 0.027591
[epoch3, step660]: loss 0.024043
[epoch3, step661]: loss 0.026970
[epoch3, step662]: loss 0.024093
[epoch3, step663]: loss 0.021530
[epoch3, step664]: loss 0.025297
[epoch3, step665]: loss 0.028910
[epoch3, step666]: loss 0.027149
[epoch3, step667]: loss 0.026950
[epoch3, step668]: loss 0.022747
[epoch3, step669]: loss 0.026692
[epoch3, step670]: loss 0.027263
[epoch3, step671]: loss 0.021491
[epoch3, step672]: loss 0.024378
[epoch3, step673]: loss 0.022490
[epoch3, step674]: loss 0.021599
[epoch3, step675]: loss 0.020611
[epoch3, step676]: loss 0.024741
[epoch3, step677]: loss 0.025676
[epoch3, step678]: loss 0.023482
[epoch3, step679]: loss 0.024242
[epoch3, step680]: loss 0.030412
[epoch3, step681]: loss 0.022174
[epoch3, step682]: loss 0.026281
[epoch3, step683]: loss 0.025946
[epoch3, step684]: loss 0.024767
[epoch3, step685]: loss 0.024303
[epoch3, step686]: loss 0.027040
[epoch3, step687]: loss 0.026667
[epoch3, step688]: loss 0.022790
[epoch3, step689]: loss 0.024483
[epoch3, step690]: loss 0.025398
[epoch3, step691]: loss 0.024325
[epoch3, step692]: loss 0.022571
[epoch3, step693]: loss 0.027598
[epoch3, step694]: loss 0.022953
[epoch3, step695]: loss 0.026572
[epoch3, step696]: loss 0.025923
[epoch3, step697]: loss 0.027243
[epoch3, step698]: loss 0.024891
[epoch3, step699]: loss 0.023546
[epoch3, step700]: loss 0.021683
[epoch3, step701]: loss 0.025981
[epoch3, step702]: loss 0.021784
[epoch3, step703]: loss 0.023007
[epoch3, step704]: loss 0.025463
[epoch3, step705]: loss 0.024988
[epoch3, step706]: loss 0.023927
[epoch3, step707]: loss 0.024570
[epoch3, step708]: loss 0.026193
[epoch3, step709]: loss 0.027507
[epoch3, step710]: loss 0.023895
[epoch3, step711]: loss 0.023803
[epoch3, step712]: loss 0.027131
[epoch3, step713]: loss 0.026376
[epoch3, step714]: loss 0.021514
[epoch3, step715]: loss 0.023105
[epoch3, step716]: loss 0.025958
[epoch3, step717]: loss 0.023668
[epoch3, step718]: loss 0.025033
[epoch3, step719]: loss 0.033364
[epoch3, step720]: loss 0.024777
[epoch3, step721]: loss 0.023142
[epoch3, step722]: loss 0.030901
[epoch3, step723]: loss 0.026155
[epoch3, step724]: loss 0.023042
[epoch3, step725]: loss 0.028165
[epoch3, step726]: loss 0.022331
[epoch3, step727]: loss 0.024727
[epoch3, step728]: loss 0.026589
[epoch3, step729]: loss 0.021279
[epoch3, step730]: loss 0.022811
[epoch3, step731]: loss 0.026000
[epoch3, step732]: loss 0.026030
[epoch3, step733]: loss 0.023965
[epoch3, step734]: loss 0.022997
[epoch3, step735]: loss 0.027439
[epoch3, step736]: loss 0.025188
[epoch3, step737]: loss 0.026545
[epoch3, step738]: loss 0.020756
[epoch3, step739]: loss 0.025538
[epoch3, step740]: loss 0.022515
[epoch3, step741]: loss 0.025280
[epoch3, step742]: loss 0.021967
[epoch3, step743]: loss 0.023334
[epoch3, step744]: loss 0.024039
[epoch3, step745]: loss 0.024611
[epoch3, step746]: loss 0.025377
[epoch3, step747]: loss 0.027612
[epoch3, step748]: loss 0.025773
[epoch3, step749]: loss 0.026447
[epoch3, step750]: loss 0.027601
[epoch3, step751]: loss 0.021732
[epoch3, step752]: loss 0.025244
[epoch3, step753]: loss 0.025680
[epoch3, step754]: loss 0.022797
[epoch3, step755]: loss 0.026258
[epoch3, step756]: loss 0.023555
[epoch3, step757]: loss 0.020624
[epoch3, step758]: loss 0.025258
[epoch3, step759]: loss 0.023131
[epoch3, step760]: loss 0.024114
[epoch3, step761]: loss 0.026440
[epoch3, step762]: loss 0.021703
[epoch3, step763]: loss 0.025644
[epoch3, step764]: loss 0.023694
[epoch3, step765]: loss 0.026220
[epoch3, step766]: loss 0.024700
[epoch3, step767]: loss 0.026914
[epoch3, step768]: loss 0.021568
[epoch3, step769]: loss 0.026732
[epoch3, step770]: loss 0.026026
[epoch3, step771]: loss 0.023367
[epoch3, step772]: loss 0.028818
[epoch3, step773]: loss 0.026538
[epoch3, step774]: loss 0.024117
[epoch3, step775]: loss 0.020775
[epoch3, step776]: loss 0.025700
[epoch3, step777]: loss 0.023137
[epoch3, step778]: loss 0.028064
[epoch3, step779]: loss 0.023889
[epoch3, step780]: loss 0.020267
[epoch3, step781]: loss 0.024505
[epoch3, step782]: loss 0.022874
[epoch3, step783]: loss 0.019508
[epoch3, step784]: loss 0.020438
[epoch3, step785]: loss 0.021549
[epoch3, step786]: loss 0.024347
[epoch3, step787]: loss 0.023426
[epoch3, step788]: loss 0.024774
[epoch3, step789]: loss 0.022595
[epoch3, step790]: loss 0.023377
[epoch3, step791]: loss 0.026788
[epoch3, step792]: loss 0.025130
[epoch3, step793]: loss 0.026994
[epoch3, step794]: loss 0.020400
[epoch3, step795]: loss 0.025677
[epoch3, step796]: loss 0.028021
[epoch3, step797]: loss 0.027954
[epoch3, step798]: loss 0.027303
[epoch3, step799]: loss 0.025814
[epoch3, step800]: loss 0.021536
[epoch3, step801]: loss 0.021794
[epoch3, step802]: loss 0.022911
[epoch3, step803]: loss 0.026181
[epoch3, step804]: loss 0.027516
[epoch3, step805]: loss 0.028513
[epoch3, step806]: loss 0.021513
[epoch3, step807]: loss 0.020751
[epoch3, step808]: loss 0.022921
[epoch3, step809]: loss 0.023124
[epoch3, step810]: loss 0.025933
[epoch3, step811]: loss 0.025720
[epoch3, step812]: loss 0.025063
[epoch3, step813]: loss 0.023808
[epoch3, step814]: loss 0.025369
[epoch3, step815]: loss 0.025295
[epoch3, step816]: loss 0.024704
[epoch3, step817]: loss 0.024760
[epoch3, step818]: loss 0.022583
[epoch3, step819]: loss 0.020727
[epoch3, step820]: loss 0.023702
[epoch3, step821]: loss 0.022111
[epoch3, step822]: loss 0.031475
[epoch3, step823]: loss 0.023955
[epoch3, step824]: loss 0.027472
[epoch3, step825]: loss 0.025522
[epoch3, step826]: loss 0.024635
[epoch3, step827]: loss 0.027473
[epoch3, step828]: loss 0.029179
[epoch3, step829]: loss 0.026547
[epoch3, step830]: loss 0.022697
[epoch3, step831]: loss 0.026341
[epoch3, step832]: loss 0.021005
[epoch3, step833]: loss 0.029555
[epoch3, step834]: loss 0.025455
[epoch3, step835]: loss 0.020634
[epoch3, step836]: loss 0.026862
[epoch3, step837]: loss 0.025576
[epoch3, step838]: loss 0.026280
[epoch3, step839]: loss 0.028422
[epoch3, step840]: loss 0.020889
[epoch3, step841]: loss 0.024291
[epoch3, step842]: loss 0.027583
[epoch3, step843]: loss 0.024930
[epoch3, step844]: loss 0.024987
[epoch3, step845]: loss 0.021210
[epoch3, step846]: loss 0.025366
[epoch3, step847]: loss 0.026980
[epoch3, step848]: loss 0.025139
[epoch3, step849]: loss 0.025130
[epoch3, step850]: loss 0.023070
[epoch3, step851]: loss 0.023882
[epoch3, step852]: loss 0.023188
[epoch3, step853]: loss 0.029253
[epoch3, step854]: loss 0.022670
[epoch3, step855]: loss 0.027283
[epoch3, step856]: loss 0.022161
[epoch3, step857]: loss 0.026065
[epoch3, step858]: loss 0.024469
[epoch3, step859]: loss 0.023715
[epoch3, step860]: loss 0.022728
[epoch3, step861]: loss 0.023304
[epoch3, step862]: loss 0.023092
[epoch3, step863]: loss 0.020774
[epoch3, step864]: loss 0.026487
[epoch3, step865]: loss 0.023501
[epoch3, step866]: loss 0.025256
[epoch3, step867]: loss 0.026184
[epoch3, step868]: loss 0.026891
[epoch3, step869]: loss 0.024056
[epoch3, step870]: loss 0.031277
[epoch3, step871]: loss 0.022128
[epoch3, step872]: loss 0.025452
[epoch3, step873]: loss 0.025804
[epoch3, step874]: loss 0.023767
[epoch3, step875]: loss 0.024329
[epoch3, step876]: loss 0.024207
[epoch3, step877]: loss 0.019249
[epoch3, step878]: loss 0.023335
[epoch3, step879]: loss 0.028279
[epoch3, step880]: loss 0.025466
[epoch3, step881]: loss 0.022229
[epoch3, step882]: loss 0.024401
[epoch3, step883]: loss 0.023974
[epoch3, step884]: loss 0.026464
[epoch3, step885]: loss 0.026101
[epoch3, step886]: loss 0.026402
[epoch3, step887]: loss 0.024131
[epoch3, step888]: loss 0.024645
[epoch3, step889]: loss 0.023620
[epoch3, step890]: loss 0.023559
[epoch3, step891]: loss 0.025652
[epoch3, step892]: loss 0.020998
[epoch3, step893]: loss 0.024662
[epoch3, step894]: loss 0.024996
[epoch3, step895]: loss 0.022698
[epoch3, step896]: loss 0.021975
[epoch3, step897]: loss 0.024093
[epoch3, step898]: loss 0.025565
[epoch3, step899]: loss 0.028118
[epoch3, step900]: loss 0.027080
[epoch3, step901]: loss 0.025566
[epoch3, step902]: loss 0.024041
[epoch3, step903]: loss 0.024315
[epoch3, step904]: loss 0.028109
[epoch3, step905]: loss 0.027685
[epoch3, step906]: loss 0.022442
[epoch3, step907]: loss 0.023663
[epoch3, step908]: loss 0.022835
[epoch3, step909]: loss 0.025610
[epoch3, step910]: loss 0.023268
[epoch3, step911]: loss 0.025211
[epoch3, step912]: loss 0.024000
[epoch3, step913]: loss 0.024241
[epoch3, step914]: loss 0.030477
[epoch3, step915]: loss 0.024148
[epoch3, step916]: loss 0.023910
[epoch3, step917]: loss 0.025134
[epoch3, step918]: loss 0.028597
[epoch3, step919]: loss 0.024232
[epoch3, step920]: loss 0.027629
[epoch3, step921]: loss 0.024677
[epoch3, step922]: loss 0.023321
[epoch3, step923]: loss 0.022681
[epoch3, step924]: loss 0.021155
[epoch3, step925]: loss 0.025742
[epoch3, step926]: loss 0.026589
[epoch3, step927]: loss 0.026098
[epoch3, step928]: loss 0.025086
[epoch3, step929]: loss 0.027906
[epoch3, step930]: loss 0.025904
[epoch3, step931]: loss 0.027392
[epoch3, step932]: loss 0.021780
[epoch3, step933]: loss 0.028240
[epoch3, step934]: loss 0.022145
[epoch3, step935]: loss 0.022068
[epoch3, step936]: loss 0.022612
[epoch3, step937]: loss 0.027441
[epoch3, step938]: loss 0.025343
[epoch3, step939]: loss 0.020919
[epoch3, step940]: loss 0.023033
[epoch3, step941]: loss 0.026941
[epoch3, step942]: loss 0.025654
[epoch3, step943]: loss 0.023289
[epoch3, step944]: loss 0.027792
[epoch3, step945]: loss 0.020603
[epoch3, step946]: loss 0.025527
[epoch3, step947]: loss 0.028027
[epoch3, step948]: loss 0.019587
[epoch3, step949]: loss 0.023039
[epoch3, step950]: loss 0.026579
[epoch3, step951]: loss 0.028915
[epoch3, step952]: loss 0.025195
[epoch3, step953]: loss 0.027767
[epoch3, step954]: loss 0.022200
[epoch3, step955]: loss 0.036754
[epoch3, step956]: loss 0.051958
[epoch3, step957]: loss 0.045435
[epoch3, step958]: loss 0.041323
[epoch3, step959]: loss 0.042883
[epoch3, step960]: loss 0.040408
[epoch3, step961]: loss 0.041816
[epoch3, step962]: loss 0.041284
[epoch3, step963]: loss 0.041386
[epoch3, step964]: loss 0.042532
[epoch3, step965]: loss 0.043673
[epoch3, step966]: loss 0.041653
[epoch3, step967]: loss 0.041015
[epoch3, step968]: loss 0.044076
[epoch3, step969]: loss 0.043342
[epoch3, step970]: loss 0.042781
[epoch3, step971]: loss 0.041710
[epoch3, step972]: loss 0.042499
[epoch3, step973]: loss 0.041399
[epoch3, step974]: loss 0.044349
[epoch3, step975]: loss 0.040687
[epoch3, step976]: loss 0.039147
[epoch3, step977]: loss 0.042916
[epoch3, step978]: loss 0.040975
[epoch3, step979]: loss 0.040871
[epoch3, step980]: loss 0.039886
[epoch3, step981]: loss 0.040621
[epoch3, step982]: loss 0.040767
[epoch3, step983]: loss 0.042507
[epoch3, step984]: loss 0.038706
[epoch3, step985]: loss 0.038921
[epoch3, step986]: loss 0.043086
[epoch3, step987]: loss 0.041252
[epoch3, step988]: loss 0.041203
[epoch3, step989]: loss 0.040118
[epoch3, step990]: loss 0.039823
[epoch3, step991]: loss 0.040647
[epoch3, step992]: loss 0.041993
[epoch3, step993]: loss 0.039435
[epoch3, step994]: loss 0.037811
[epoch3, step995]: loss 0.041606
[epoch3, step996]: loss 0.039921
[epoch3, step997]: loss 0.040261
[epoch3, step998]: loss 0.039854
[epoch3, step999]: loss 0.039977
[epoch3, step1000]: loss 0.040269
[epoch3, step1001]: loss 0.041646
[epoch3, step1002]: loss 0.039284
[epoch3, step1003]: loss 0.038153
[epoch3, step1004]: loss 0.041578
[epoch3, step1005]: loss 0.039320
[epoch3, step1006]: loss 0.039941
[epoch3, step1007]: loss 0.038623
[epoch3, step1008]: loss 0.039304
[epoch3, step1009]: loss 0.039892
[epoch3, step1010]: loss 0.041818
[epoch3, step1011]: loss 0.038790
[epoch3, step1012]: loss 0.038554
[epoch3, step1013]: loss 0.041576
[epoch3, step1014]: loss 0.040569
[epoch3, step1015]: loss 0.040145
[epoch3, step1016]: loss 0.038421
[epoch3, step1017]: loss 0.039240
[epoch3, step1018]: loss 0.039567
[epoch3, step1019]: loss 0.041376
[epoch3, step1020]: loss 0.038180
[epoch3, step1021]: loss 0.037598
[epoch3, step1022]: loss 0.041026
[epoch3, step1023]: loss 0.039557
[epoch3, step1024]: loss 0.040043
[epoch3, step1025]: loss 0.037976
[epoch3, step1026]: loss 0.038534
[epoch3, step1027]: loss 0.039156
[epoch3, step1028]: loss 0.040777
[epoch3, step1029]: loss 0.037983
[epoch3, step1030]: loss 0.037168
[epoch3, step1031]: loss 0.039778
[epoch3, step1032]: loss 0.039614
[epoch3, step1033]: loss 0.038792
[epoch3, step1034]: loss 0.037947
[epoch3, step1035]: loss 0.038415
[epoch3, step1036]: loss 0.039454
[epoch3, step1037]: loss 0.040418
[epoch3, step1038]: loss 0.037828
[epoch3, step1039]: loss 0.037748
[epoch3, step1040]: loss 0.040252
[epoch3, step1041]: loss 0.039002
[epoch3, step1042]: loss 0.038135
[epoch3, step1043]: loss 0.037826
[epoch3, step1044]: loss 0.038894
[epoch3, step1045]: loss 0.039338
[epoch3, step1046]: loss 0.040630
[epoch3, step1047]: loss 0.038005
[epoch3, step1048]: loss 0.037167
[epoch3, step1049]: loss 0.040674
[epoch3, step1050]: loss 0.039403
[epoch3, step1051]: loss 0.038940
[epoch3, step1052]: loss 0.038219
[epoch3, step1053]: loss 0.039226
[epoch3, step1054]: loss 0.039167
[epoch3, step1055]: loss 0.039817
[epoch3, step1056]: loss 0.037150
[epoch3, step1057]: loss 0.037894
[epoch3, step1058]: loss 0.041301
[epoch3, step1059]: loss 0.039298
[epoch3, step1060]: loss 0.038913
[epoch3, step1061]: loss 0.037080
[epoch3, step1062]: loss 0.039150
[epoch3, step1063]: loss 0.039077
[epoch3, step1064]: loss 0.040264
[epoch3, step1065]: loss 0.037565
[epoch3, step1066]: loss 0.036766
[epoch3, step1067]: loss 0.040548
[epoch3, step1068]: loss 0.037695
[epoch3, step1069]: loss 0.038067
[epoch3, step1070]: loss 0.037512
[epoch3, step1071]: loss 0.039206
[epoch3, step1072]: loss 0.039757
[epoch3, step1073]: loss 0.039884
[epoch3, step1074]: loss 0.037570
[epoch3, step1075]: loss 0.037462
[epoch3, step1076]: loss 0.040459
[epoch3, step1077]: loss 0.038940
[epoch3, step1078]: loss 0.038427
[epoch3, step1079]: loss 0.038422
[epoch3, step1080]: loss 0.038745
[epoch3, step1081]: loss 0.038726
[epoch3, step1082]: loss 0.039962
[epoch3, step1083]: loss 0.038167
[epoch3, step1084]: loss 0.037298
[epoch3, step1085]: loss 0.039810
[epoch3, step1086]: loss 0.038537
[epoch3, step1087]: loss 0.038693
[epoch3, step1088]: loss 0.037188
[epoch3, step1089]: loss 0.039016
[epoch3, step1090]: loss 0.039438
[epoch3, step1091]: loss 0.040396
[epoch3, step1092]: loss 0.037279
[epoch3, step1093]: loss 0.036992
[epoch3, step1094]: loss 0.039379
[epoch3, step1095]: loss 0.038404
[epoch3, step1096]: loss 0.038090
[epoch3, step1097]: loss 0.037423
[epoch3, step1098]: loss 0.038387
[epoch3, step1099]: loss 0.038521
[epoch3, step1100]: loss 0.040730
[epoch3, step1101]: loss 0.037737
[epoch3, step1102]: loss 0.037030
[epoch3, step1103]: loss 0.039786
[epoch3, step1104]: loss 0.038494
[epoch3, step1105]: loss 0.038666
[epoch3, step1106]: loss 0.036367
[epoch3, step1107]: loss 0.038568
[epoch3, step1108]: loss 0.038427
[epoch3, step1109]: loss 0.040276
[epoch3, step1110]: loss 0.037932
[epoch3, step1111]: loss 0.037170
[epoch3, step1112]: loss 0.040447
[epoch3, step1113]: loss 0.038339
[epoch3, step1114]: loss 0.038756
[epoch3, step1115]: loss 0.037333
[epoch3, step1116]: loss 0.038697
[epoch3, step1117]: loss 0.038947
[epoch3, step1118]: loss 0.040026
[epoch3, step1119]: loss 0.037093
[epoch3, step1120]: loss 0.036778
[epoch3, step1121]: loss 0.039944
[epoch3, step1122]: loss 0.038069
[epoch3, step1123]: loss 0.037602
[epoch3, step1124]: loss 0.037932
[epoch3, step1125]: loss 0.038778
[epoch3, step1126]: loss 0.039644
[epoch3, step1127]: loss 0.039889
[epoch3, step1128]: loss 0.037818
[epoch3, step1129]: loss 0.036749
[epoch3, step1130]: loss 0.041114
[epoch3, step1131]: loss 0.039317
[epoch3, step1132]: loss 0.039052
[epoch3, step1133]: loss 0.037019
[epoch3, step1134]: loss 0.038695
[epoch3, step1135]: loss 0.040027
[epoch3, step1136]: loss 0.040856
[epoch3, step1137]: loss 0.037473
[epoch3, step1138]: loss 0.037144
[epoch3, step1139]: loss 0.040445
[epoch3, step1140]: loss 0.038171
[epoch3, step1141]: loss 0.038226
[epoch3, step1142]: loss 0.036959
[epoch3, step1143]: loss 0.038131
[epoch3, step1144]: loss 0.038961
[epoch3, step1145]: loss 0.039357
[epoch3, step1146]: loss 0.037424
[epoch3, step1147]: loss 0.037710
[epoch3, step1148]: loss 0.040464
[epoch3, step1149]: loss 0.038591
[epoch3, step1150]: loss 0.038313
[epoch3, step1151]: loss 0.037613
[epoch3, step1152]: loss 0.039410
[epoch3, step1153]: loss 0.038466
[epoch3, step1154]: loss 0.040526
[epoch3, step1155]: loss 0.037646
[epoch3, step1156]: loss 0.036382
[epoch3, step1157]: loss 0.040334
[epoch3, step1158]: loss 0.038977
[epoch3, step1159]: loss 0.038630
[epoch3, step1160]: loss 0.037948
[epoch3, step1161]: loss 0.039163
[epoch3, step1162]: loss 0.038897
[epoch3, step1163]: loss 0.039414
[epoch3, step1164]: loss 0.037214
[epoch3, step1165]: loss 0.038185
[epoch3, step1166]: loss 0.040329
[epoch3, step1167]: loss 0.037932
[epoch3, step1168]: loss 0.038522
[epoch3, step1169]: loss 0.037198
[epoch3, step1170]: loss 0.038569
[epoch3, step1171]: loss 0.038684
[epoch3, step1172]: loss 0.040164
[epoch3, step1173]: loss 0.037445
[epoch3, step1174]: loss 0.037518
[epoch3, step1175]: loss 0.040298
[epoch3, step1176]: loss 0.038394
[epoch3, step1177]: loss 0.038841
[epoch3, step1178]: loss 0.037287
[epoch3, step1179]: loss 0.038473
[epoch3, step1180]: loss 0.039052
[epoch3, step1181]: loss 0.040543
[epoch3, step1182]: loss 0.036665
[epoch3, step1183]: loss 0.037325
[epoch3, step1184]: loss 0.039733
[epoch3, step1185]: loss 0.038731
[epoch3, step1186]: loss 0.037612
[epoch3, step1187]: loss 0.036265
[epoch3, step1188]: loss 0.037816
[epoch3, step1189]: loss 0.038411
[epoch3, step1190]: loss 0.039442
[epoch3, step1191]: loss 0.037731
[epoch3, step1192]: loss 0.037032
[epoch3, step1193]: loss 0.040064
[epoch3, step1194]: loss 0.038391
[epoch3, step1195]: loss 0.037273
[epoch3, step1196]: loss 0.036297
[epoch3, step1197]: loss 0.038709
[epoch3, step1198]: loss 0.038601
[epoch3, step1199]: loss 0.039425
[epoch3, step1200]: loss 0.036843
[epoch3, step1201]: loss 0.037260
[epoch3, step1202]: loss 0.041033
[epoch3, step1203]: loss 0.038709
[epoch3, step1204]: loss 0.037749
[epoch3, step1205]: loss 0.036549
[epoch3, step1206]: loss 0.037897
[epoch3, step1207]: loss 0.038939
[epoch3, step1208]: loss 0.039931
[epoch3, step1209]: loss 0.036831
[epoch3, step1210]: loss 0.037433
[epoch3, step1211]: loss 0.039615
[epoch3, step1212]: loss 0.038397
[epoch3, step1213]: loss 0.037997
[epoch3, step1214]: loss 0.037173
[epoch3, step1215]: loss 0.039243
[epoch3, step1216]: loss 0.038423
[epoch3, step1217]: loss 0.040573
[epoch3, step1218]: loss 0.036837
[epoch3, step1219]: loss 0.037608
[epoch3, step1220]: loss 0.040568
[epoch3, step1221]: loss 0.037726
[epoch3, step1222]: loss 0.038357
[epoch3, step1223]: loss 0.036863
[epoch3, step1224]: loss 0.038721
[epoch3, step1225]: loss 0.038651
[epoch3, step1226]: loss 0.039434
[epoch3, step1227]: loss 0.036966
[epoch3, step1228]: loss 0.036683
[epoch3, step1229]: loss 0.039805
[epoch3, step1230]: loss 0.038789
[epoch3, step1231]: loss 0.038198
[epoch3, step1232]: loss 0.038016
[epoch3, step1233]: loss 0.038411
[epoch3, step1234]: loss 0.038317
[epoch3, step1235]: loss 0.040158
[epoch3, step1236]: loss 0.037512
[epoch3, step1237]: loss 0.036350
[epoch3, step1238]: loss 0.039512
[epoch3, step1239]: loss 0.039136
[epoch3, step1240]: loss 0.038697
[epoch3, step1241]: loss 0.036602
[epoch3, step1242]: loss 0.038590
[epoch3, step1243]: loss 0.038769
[epoch3, step1244]: loss 0.040262
[epoch3, step1245]: loss 0.037511
[epoch3, step1246]: loss 0.037400
[epoch3, step1247]: loss 0.039476
[epoch3, step1248]: loss 0.038763
[epoch3, step1249]: loss 0.038778
[epoch3, step1250]: loss 0.036840
[epoch3, step1251]: loss 0.038790
[epoch3, step1252]: loss 0.039743
[epoch3, step1253]: loss 0.040155
[epoch3, step1254]: loss 0.037145
[epoch3, step1255]: loss 0.036991
[epoch3, step1256]: loss 0.040286
[epoch3, step1257]: loss 0.038766
[epoch3, step1258]: loss 0.038325
[epoch3, step1259]: loss 0.036686
[epoch3, step1260]: loss 0.038598
[epoch3, step1261]: loss 0.038616
[epoch3, step1262]: loss 0.038770
[epoch3, step1263]: loss 0.037755
[epoch3, step1264]: loss 0.037057
[epoch3, step1265]: loss 0.039009
[epoch3, step1266]: loss 0.038572
[epoch3, step1267]: loss 0.038466
[epoch3, step1268]: loss 0.037147
[epoch3, step1269]: loss 0.038827
[epoch3, step1270]: loss 0.038174
[epoch3, step1271]: loss 0.040352
[epoch3, step1272]: loss 0.037247
[epoch3, step1273]: loss 0.036645
[epoch3, step1274]: loss 0.039714
[epoch3, step1275]: loss 0.038704
[epoch3, step1276]: loss 0.037798
[epoch3, step1277]: loss 0.037127
[epoch3, step1278]: loss 0.038906
[epoch3, step1279]: loss 0.038894
[epoch3, step1280]: loss 0.040139
[epoch3, step1281]: loss 0.036991
[epoch3, step1282]: loss 0.037042
[epoch3, step1283]: loss 0.039546
[epoch3, step1284]: loss 0.038077
[epoch3, step1285]: loss 0.038719
[epoch3, step1286]: loss 0.036286
[epoch3, step1287]: loss 0.039249
[epoch3, step1288]: loss 0.039286
[epoch3, step1289]: loss 0.040496
[epoch3, step1290]: loss 0.037026
[epoch3, step1291]: loss 0.036482
[epoch3, step1292]: loss 0.040448
[epoch3, step1293]: loss 0.037529
[epoch3, step1294]: loss 0.037990
[epoch3, step1295]: loss 0.037502
[epoch3, step1296]: loss 0.038457
[epoch3, step1297]: loss 0.038402
[epoch3, step1298]: loss 0.040319
[epoch3, step1299]: loss 0.037154
[epoch3, step1300]: loss 0.037677
[epoch3, step1301]: loss 0.038911
[epoch3, step1302]: loss 0.038318
[epoch3, step1303]: loss 0.038295
[epoch3, step1304]: loss 0.036343
[epoch3, step1305]: loss 0.038759
[epoch3, step1306]: loss 0.038430
[epoch3, step1307]: loss 0.039066
[epoch3, step1308]: loss 0.037110
[epoch3, step1309]: loss 0.036063
[epoch3, step1310]: loss 0.039660
[epoch3, step1311]: loss 0.037208
[epoch3, step1312]: loss 0.038631
[epoch3, step1313]: loss 0.037024
[epoch3, step1314]: loss 0.038166
[epoch3, step1315]: loss 0.038269
[epoch3, step1316]: loss 0.041053
[epoch3, step1317]: loss 0.036446
[epoch3, step1318]: loss 0.036521
[epoch3, step1319]: loss 0.039257
[epoch3, step1320]: loss 0.038538
[epoch3, step1321]: loss 0.038529
[epoch3, step1322]: loss 0.036624
[epoch3, step1323]: loss 0.038778
[epoch3, step1324]: loss 0.038101
[epoch3, step1325]: loss 0.039496
[epoch3, step1326]: loss 0.036725
[epoch3, step1327]: loss 0.036545
[epoch3, step1328]: loss 0.039776
[epoch3, step1329]: loss 0.038076
[epoch3, step1330]: loss 0.038164
[epoch3, step1331]: loss 0.036615
[epoch3, step1332]: loss 0.038165
[epoch3, step1333]: loss 0.037611
[epoch3, step1334]: loss 0.039968
[epoch3, step1335]: loss 0.037595
[epoch3, step1336]: loss 0.036829
[epoch3, step1337]: loss 0.039183
[epoch3, step1338]: loss 0.038198
[epoch3, step1339]: loss 0.038127
[epoch3, step1340]: loss 0.036505
[epoch3, step1341]: loss 0.038641
[epoch3, step1342]: loss 0.038231
[epoch3, step1343]: loss 0.039791
[epoch3, step1344]: loss 0.037033
[epoch3, step1345]: loss 0.036711
[epoch3, step1346]: loss 0.039298
[epoch3, step1347]: loss 0.038799
[epoch3, step1348]: loss 0.037354
[epoch3, step1349]: loss 0.036964
[epoch3, step1350]: loss 0.038335
[epoch3, step1351]: loss 0.037939
[epoch3, step1352]: loss 0.039006
[epoch3, step1353]: loss 0.036695
[epoch3, step1354]: loss 0.036493
[epoch3, step1355]: loss 0.039854
[epoch3, step1356]: loss 0.038023
[epoch3, step1357]: loss 0.037448
[epoch3, step1358]: loss 0.036664
[epoch3, step1359]: loss 0.037922
[epoch3, step1360]: loss 0.038596
[epoch3, step1361]: loss 0.039920
[epoch3, step1362]: loss 0.037474
[epoch3, step1363]: loss 0.037288
[epoch3, step1364]: loss 0.039602
[epoch3, step1365]: loss 0.038207
[epoch3, step1366]: loss 0.037802
[epoch3, step1367]: loss 0.036036
[epoch3, step1368]: loss 0.039165
[epoch3, step1369]: loss 0.038616
[epoch3, step1370]: loss 0.039284
[epoch3, step1371]: loss 0.037100
[epoch3, step1372]: loss 0.036531
[epoch3, step1373]: loss 0.039712
[epoch3, step1374]: loss 0.038992
[epoch3, step1375]: loss 0.038637
[epoch3, step1376]: loss 0.036608
[epoch3, step1377]: loss 0.037547
[epoch3, step1378]: loss 0.038515
[epoch3, step1379]: loss 0.039178
[epoch3, step1380]: loss 0.037195
[epoch3, step1381]: loss 0.036771
[epoch3, step1382]: loss 0.039928
[epoch3, step1383]: loss 0.038045
[epoch3, step1384]: loss 0.037790
[epoch3, step1385]: loss 0.036121
[epoch3, step1386]: loss 0.038564
[epoch3, step1387]: loss 0.038902
[epoch3, step1388]: loss 0.038561
[epoch3, step1389]: loss 0.036134
[epoch3, step1390]: loss 0.036867
[epoch3, step1391]: loss 0.039354
[epoch3, step1392]: loss 0.038079
[epoch3, step1393]: loss 0.038096
[epoch3, step1394]: loss 0.037324
[epoch3, step1395]: loss 0.038421
[epoch3, step1396]: loss 0.037967
[epoch3, step1397]: loss 0.039282
[epoch3, step1398]: loss 0.036714
[epoch3, step1399]: loss 0.037615
[epoch3, step1400]: loss 0.040098
[epoch3, step1401]: loss 0.037947
[epoch3, step1402]: loss 0.038027
[epoch3, step1403]: loss 0.035742
[epoch3, step1404]: loss 0.037818
[epoch3, step1405]: loss 0.038197
[epoch3, step1406]: loss 0.039271
[epoch3, step1407]: loss 0.037826
[epoch3, step1408]: loss 0.036128
[epoch3, step1409]: loss 0.039191
[epoch3, step1410]: loss 0.038115
[epoch3, step1411]: loss 0.036850
[epoch3, step1412]: loss 0.036816
[epoch3, step1413]: loss 0.038336
[epoch3, step1414]: loss 0.037982
[epoch3, step1415]: loss 0.039209
[epoch3, step1416]: loss 0.036673
[epoch3, step1417]: loss 0.036671
[epoch3, step1418]: loss 0.039530
[epoch3, step1419]: loss 0.038866
[epoch3, step1420]: loss 0.038118
[epoch3, step1421]: loss 0.037097
[epoch3, step1422]: loss 0.038501
[epoch3, step1423]: loss 0.037885
[epoch3, step1424]: loss 0.039696
[epoch3, step1425]: loss 0.035786
[epoch3, step1426]: loss 0.036764
[epoch3, step1427]: loss 0.040452
[epoch3, step1428]: loss 0.039016
[epoch3, step1429]: loss 0.037845
[epoch3, step1430]: loss 0.036733
[epoch3, step1431]: loss 0.038419
[epoch3, step1432]: loss 0.038054
[epoch3, step1433]: loss 0.039675
[epoch3, step1434]: loss 0.036177
[epoch3, step1435]: loss 0.037170
[epoch3, step1436]: loss 0.039925
[epoch3, step1437]: loss 0.038398
[epoch3, step1438]: loss 0.038502
[epoch3, step1439]: loss 0.036670
[epoch3, step1440]: loss 0.038056
[epoch3, step1441]: loss 0.038954
[epoch3, step1442]: loss 0.038770
[epoch3, step1443]: loss 0.036382
[epoch3, step1444]: loss 0.036002
[epoch3, step1445]: loss 0.039936
[epoch3, step1446]: loss 0.038304
[epoch3, step1447]: loss 0.038575
[epoch3, step1448]: loss 0.036563
[epoch3, step1449]: loss 0.037661
[epoch3, step1450]: loss 0.038359
[epoch3, step1451]: loss 0.039736
[epoch3, step1452]: loss 0.036444
[epoch3, step1453]: loss 0.037696
[epoch3, step1454]: loss 0.040015
[epoch3, step1455]: loss 0.038710
[epoch3, step1456]: loss 0.037460
[epoch3, step1457]: loss 0.037207
[epoch3, step1458]: loss 0.038322
[epoch3, step1459]: loss 0.038248
[epoch3, step1460]: loss 0.040021
[epoch3, step1461]: loss 0.037359
[epoch3, step1462]: loss 0.037361
[epoch3, step1463]: loss 0.039529
[epoch3, step1464]: loss 0.038406
[epoch3, step1465]: loss 0.037483
[epoch3, step1466]: loss 0.036305
[epoch3, step1467]: loss 0.038188
[epoch3, step1468]: loss 0.037769
[epoch3, step1469]: loss 0.039418
[epoch3, step1470]: loss 0.036787
[epoch3, step1471]: loss 0.036381
[epoch3, step1472]: loss 0.039362
[epoch3, step1473]: loss 0.038074
[epoch3, step1474]: loss 0.038450
[epoch3, step1475]: loss 0.036298
[epoch3, step1476]: loss 0.039041
[epoch3, step1477]: loss 0.038003
[epoch3, step1478]: loss 0.039546
[epoch3, step1479]: loss 0.036578
[epoch3, step1480]: loss 0.036677
[epoch3, step1481]: loss 0.038578
[epoch3, step1482]: loss 0.038073
[epoch3, step1483]: loss 0.037929
[epoch3, step1484]: loss 0.036980
[epoch3, step1485]: loss 0.037989
[epoch3, step1486]: loss 0.037263
[epoch3, step1487]: loss 0.039256
[epoch3, step1488]: loss 0.036787
[epoch3, step1489]: loss 0.036515
[epoch3, step1490]: loss 0.039553
[epoch3, step1491]: loss 0.038188
[epoch3, step1492]: loss 0.037587
[epoch3, step1493]: loss 0.036623
[epoch3, step1494]: loss 0.038345
[epoch3, step1495]: loss 0.037906
[epoch3, step1496]: loss 0.038575
[epoch3, step1497]: loss 0.036961
[epoch3, step1498]: loss 0.036926
[epoch3, step1499]: loss 0.038887
[epoch3, step1500]: loss 0.038370
[epoch3, step1501]: loss 0.037855
[epoch3, step1502]: loss 0.036336
[epoch3, step1503]: loss 0.038057
[epoch3, step1504]: loss 0.037774
[epoch3, step1505]: loss 0.039706
[epoch3, step1506]: loss 0.036043
[epoch3, step1507]: loss 0.037014
[epoch3, step1508]: loss 0.040049
[epoch3, step1509]: loss 0.037778
[epoch3, step1510]: loss 0.037189
[epoch3, step1511]: loss 0.037200
[epoch3, step1512]: loss 0.038256
[epoch3, step1513]: loss 0.036888
[epoch3, step1514]: loss 0.039397
[epoch3, step1515]: loss 0.037070
[epoch3, step1516]: loss 0.036608

[epoch3]: avg loss 0.035780

[epoch4, step1]: loss 0.029823
[epoch4, step2]: loss 0.039202
[epoch4, step3]: loss 0.039187
[epoch4, step4]: loss 0.036369
[epoch4, step5]: loss 0.037069
[epoch4, step6]: loss 0.039404
[epoch4, step7]: loss 0.037422
[epoch4, step8]: loss 0.039586
[epoch4, step9]: loss 0.036178
[epoch4, step10]: loss 0.037777
[epoch4, step11]: loss 0.039585
[epoch4, step12]: loss 0.039387
[epoch4, step13]: loss 0.036711
[epoch4, step14]: loss 0.037169
[epoch4, step15]: loss 0.039356
[epoch4, step16]: loss 0.037476
[epoch4, step17]: loss 0.039900
[epoch4, step18]: loss 0.037273
[epoch4, step19]: loss 0.037362
[epoch4, step20]: loss 0.040373
[epoch4, step21]: loss 0.039302
[epoch4, step22]: loss 0.036234
[epoch4, step23]: loss 0.035914
[epoch4, step24]: loss 0.039463
[epoch4, step25]: loss 0.036497
[epoch4, step26]: loss 0.038918
[epoch4, step27]: loss 0.035927
[epoch4, step28]: loss 0.037199
[epoch4, step29]: loss 0.039651
[epoch4, step30]: loss 0.039958
[epoch4, step31]: loss 0.035984
[epoch4, step32]: loss 0.037243
[epoch4, step33]: loss 0.039945
[epoch4, step34]: loss 0.037849
[epoch4, step35]: loss 0.040016
[epoch4, step36]: loss 0.036268
[epoch4, step37]: loss 0.037308
[epoch4, step38]: loss 0.039402
[epoch4, step39]: loss 0.039361
[epoch4, step40]: loss 0.037057
[epoch4, step41]: loss 0.036191
[epoch4, step42]: loss 0.039778
[epoch4, step43]: loss 0.037154
[epoch4, step44]: loss 0.040099
[epoch4, step45]: loss 0.036438
[epoch4, step46]: loss 0.037302
[epoch4, step47]: loss 0.039010
[epoch4, step48]: loss 0.039014
[epoch4, step49]: loss 0.034945
[epoch4, step50]: loss 0.036904
[epoch4, step51]: loss 0.039192
[epoch4, step52]: loss 0.036963
[epoch4, step53]: loss 0.040047
[epoch4, step54]: loss 0.036184
[epoch4, step55]: loss 0.037672
[epoch4, step56]: loss 0.040437
[epoch4, step57]: loss 0.039876
[epoch4, step58]: loss 0.036576
[epoch4, step59]: loss 0.035831
[epoch4, step60]: loss 0.039937
[epoch4, step61]: loss 0.036331
[epoch4, step62]: loss 0.039007
[epoch4, step63]: loss 0.035829
[epoch4, step64]: loss 0.036758
[epoch4, step65]: loss 0.039681
[epoch4, step66]: loss 0.039408
[epoch4, step67]: loss 0.036676
[epoch4, step68]: loss 0.036671
[epoch4, step69]: loss 0.039414
[epoch4, step70]: loss 0.036937
[epoch4, step71]: loss 0.039157
[epoch4, step72]: loss 0.036456
[epoch4, step73]: loss 0.037027
[epoch4, step74]: loss 0.039546
[epoch4, step75]: loss 0.039570
[epoch4, step76]: loss 0.037067
[epoch4, step77]: loss 0.037312
[epoch4, step78]: loss 0.039745
[epoch4, step79]: loss 0.036462
[epoch4, step80]: loss 0.040327
[epoch4, step81]: loss 0.036494
[epoch4, step82]: loss 0.036741
[epoch4, step83]: loss 0.038799
[epoch4, step84]: loss 0.039637
[epoch4, step85]: loss 0.037176
[epoch4, step86]: loss 0.037005
[epoch4, step87]: loss 0.040437
[epoch4, step88]: loss 0.035924
[epoch4, step89]: loss 0.039220
[epoch4, step90]: loss 0.036899
[epoch4, step91]: loss 0.036557
[epoch4, step92]: loss 0.039676
[epoch4, step93]: loss 0.039411
[epoch4, step94]: loss 0.036287
[epoch4, step95]: loss 0.037170
[epoch4, step96]: loss 0.039106
[epoch4, step97]: loss 0.037738
[epoch4, step98]: loss 0.039617
[epoch4, step99]: loss 0.036495
[epoch4, step100]: loss 0.036003
[epoch4, step101]: loss 0.040067
[epoch4, step102]: loss 0.039353
[epoch4, step103]: loss 0.036381
[epoch4, step104]: loss 0.036741
[epoch4, step105]: loss 0.039751
[epoch4, step106]: loss 0.037137
[epoch4, step107]: loss 0.039528
[epoch4, step108]: loss 0.036841
[epoch4, step109]: loss 0.036781
[epoch4, step110]: loss 0.040111
[epoch4, step111]: loss 0.039227
[epoch4, step112]: loss 0.036631
[epoch4, step113]: loss 0.037546
[epoch4, step114]: loss 0.039255
[epoch4, step115]: loss 0.036950
[epoch4, step116]: loss 0.040267
[epoch4, step117]: loss 0.036443
[epoch4, step118]: loss 0.037728
[epoch4, step119]: loss 0.039941
[epoch4, step120]: loss 0.039589
[epoch4, step121]: loss 0.036284
[epoch4, step122]: loss 0.036656
[epoch4, step123]: loss 0.039793
[epoch4, step124]: loss 0.037371
[epoch4, step125]: loss 0.039920
[epoch4, step126]: loss 0.036407
[epoch4, step127]: loss 0.036822
[epoch4, step128]: loss 0.039435
[epoch4, step129]: loss 0.039262
[epoch4, step130]: loss 0.036671
[epoch4, step131]: loss 0.036126
[epoch4, step132]: loss 0.039582
[epoch4, step133]: loss 0.036770
[epoch4, step134]: loss 0.038847
[epoch4, step135]: loss 0.037022
[epoch4, step136]: loss 0.038112
[epoch4, step137]: loss 0.039266
[epoch4, step138]: loss 0.039399
[epoch4, step139]: loss 0.036448
[epoch4, step140]: loss 0.037282
[epoch4, step141]: loss 0.039758
[epoch4, step142]: loss 0.036965
[epoch4, step143]: loss 0.039051
[epoch4, step144]: loss 0.036763
[epoch4, step145]: loss 0.037054
[epoch4, step146]: loss 0.039543
[epoch4, step147]: loss 0.040787
[epoch4, step148]: loss 0.036200
[epoch4, step149]: loss 0.036246
[epoch4, step150]: loss 0.039199
[epoch4, step151]: loss 0.037037
[epoch4, step152]: loss 0.039390
[epoch4, step153]: loss 0.036647
[epoch4, step154]: loss 0.036652
[epoch4, step155]: loss 0.039452
[epoch4, step156]: loss 0.039073
[epoch4, step157]: loss 0.036600
[epoch4, step158]: loss 0.036998
[epoch4, step159]: loss 0.039696
[epoch4, step160]: loss 0.037282
[epoch4, step161]: loss 0.040005
[epoch4, step162]: loss 0.036764
[epoch4, step163]: loss 0.036940
[epoch4, step164]: loss 0.039788
[epoch4, step165]: loss 0.039482
[epoch4, step166]: loss 0.036827
[epoch4, step167]: loss 0.036304
[epoch4, step168]: loss 0.040187
[epoch4, step169]: loss 0.036640
[epoch4, step170]: loss 0.039819
[epoch4, step171]: loss 0.036864
[epoch4, step172]: loss 0.037138
[epoch4, step173]: loss 0.039830
[epoch4, step174]: loss 0.039252
[epoch4, step175]: loss 0.037212
[epoch4, step176]: loss 0.037020
[epoch4, step177]: loss 0.039866
[epoch4, step178]: loss 0.037003
[epoch4, step179]: loss 0.038632
[epoch4, step180]: loss 0.036882
[epoch4, step181]: loss 0.037165
[epoch4, step182]: loss 0.039872
[epoch4, step183]: loss 0.040216
[epoch4, step184]: loss 0.037563
[epoch4, step185]: loss 0.037035
[epoch4, step186]: loss 0.039756
[epoch4, step187]: loss 0.037113
[epoch4, step188]: loss 0.039319
[epoch4, step189]: loss 0.036511
[epoch4, step190]: loss 0.036347
[epoch4, step191]: loss 0.039390
[epoch4, step192]: loss 0.039984
[epoch4, step193]: loss 0.034643
[epoch4, step194]: loss 0.035940
[epoch4, step195]: loss 0.039798
[epoch4, step196]: loss 0.037128
[epoch4, step197]: loss 0.039312
[epoch4, step198]: loss 0.035709
[epoch4, step199]: loss 0.037137
[epoch4, step200]: loss 0.040024
[epoch4, step201]: loss 0.040031
[epoch4, step202]: loss 0.036226
[epoch4, step203]: loss 0.036845
[epoch4, step204]: loss 0.040175
[epoch4, step205]: loss 0.036327
[epoch4, step206]: loss 0.039218
[epoch4, step207]: loss 0.036373
[epoch4, step208]: loss 0.037317
[epoch4, step209]: loss 0.039816
[epoch4, step210]: loss 0.040359
[epoch4, step211]: loss 0.037160
[epoch4, step212]: loss 0.037130
[epoch4, step213]: loss 0.039108
[epoch4, step214]: loss 0.036379
[epoch4, step215]: loss 0.039723
[epoch4, step216]: loss 0.036848
[epoch4, step217]: loss 0.036027
[epoch4, step218]: loss 0.039923
[epoch4, step219]: loss 0.039318
[epoch4, step220]: loss 0.036925
[epoch4, step221]: loss 0.037119
[epoch4, step222]: loss 0.039863
[epoch4, step223]: loss 0.037379
[epoch4, step224]: loss 0.039355
[epoch4, step225]: loss 0.036417
[epoch4, step226]: loss 0.036842
[epoch4, step227]: loss 0.038630
[epoch4, step228]: loss 0.040103
[epoch4, step229]: loss 0.035830
[epoch4, step230]: loss 0.037200
[epoch4, step231]: loss 0.039986
[epoch4, step232]: loss 0.036627
[epoch4, step233]: loss 0.038847
[epoch4, step234]: loss 0.036033
[epoch4, step235]: loss 0.037246
[epoch4, step236]: loss 0.039557
[epoch4, step237]: loss 0.039587
[epoch4, step238]: loss 0.036290
[epoch4, step239]: loss 0.036084
[epoch4, step240]: loss 0.038967
[epoch4, step241]: loss 0.037483
[epoch4, step242]: loss 0.039373
[epoch4, step243]: loss 0.037293
[epoch4, step244]: loss 0.036906
[epoch4, step245]: loss 0.039107
[epoch4, step246]: loss 0.039587
[epoch4, step247]: loss 0.036920
[epoch4, step248]: loss 0.036450
[epoch4, step249]: loss 0.039106
[epoch4, step250]: loss 0.037156
[epoch4, step251]: loss 0.040051
[epoch4, step252]: loss 0.036968
[epoch4, step253]: loss 0.036512
[epoch4, step254]: loss 0.039086
[epoch4, step255]: loss 0.039565
[epoch4, step256]: loss 0.036326
[epoch4, step257]: loss 0.036574
[epoch4, step258]: loss 0.040091
[epoch4, step259]: loss 0.037005
[epoch4, step260]: loss 0.038938
[epoch4, step261]: loss 0.037307
[epoch4, step262]: loss 0.037316
[epoch4, step263]: loss 0.038968
[epoch4, step264]: loss 0.039201
[epoch4, step265]: loss 0.036856
[epoch4, step266]: loss 0.036890
[epoch4, step267]: loss 0.038784
[epoch4, step268]: loss 0.037033
[epoch4, step269]: loss 0.039842
[epoch4, step270]: loss 0.035963
[epoch4, step271]: loss 0.037120
[epoch4, step272]: loss 0.039551
[epoch4, step273]: loss 0.039120
[epoch4, step274]: loss 0.037082
[epoch4, step275]: loss 0.036212
[epoch4, step276]: loss 0.039075
[epoch4, step277]: loss 0.037369
[epoch4, step278]: loss 0.039526
[epoch4, step279]: loss 0.036105
[epoch4, step280]: loss 0.036840
[epoch4, step281]: loss 0.039511
[epoch4, step282]: loss 0.040021
[epoch4, step283]: loss 0.036144
[epoch4, step284]: loss 0.036362
[epoch4, step285]: loss 0.040242
[epoch4, step286]: loss 0.036339
[epoch4, step287]: loss 0.039800
[epoch4, step288]: loss 0.036028
[epoch4, step289]: loss 0.037767
[epoch4, step290]: loss 0.039596
[epoch4, step291]: loss 0.039892
[epoch4, step292]: loss 0.035752
[epoch4, step293]: loss 0.036379
[epoch4, step294]: loss 0.038828
[epoch4, step295]: loss 0.036351
[epoch4, step296]: loss 0.040279
[epoch4, step297]: loss 0.036140
[epoch4, step298]: loss 0.037216
[epoch4, step299]: loss 0.038566
[epoch4, step300]: loss 0.039781
[epoch4, step301]: loss 0.036486
[epoch4, step302]: loss 0.036977
[epoch4, step303]: loss 0.039799
[epoch4, step304]: loss 0.036537
[epoch4, step305]: loss 0.039012
[epoch4, step306]: loss 0.036700
[epoch4, step307]: loss 0.036465
[epoch4, step308]: loss 0.040037
[epoch4, step309]: loss 0.039766
[epoch4, step310]: loss 0.036633
[epoch4, step311]: loss 0.037164
[epoch4, step312]: loss 0.039077
[epoch4, step313]: loss 0.037380
[epoch4, step314]: loss 0.039573
[epoch4, step315]: loss 0.037429
[epoch4, step316]: loss 0.036725
[epoch4, step317]: loss 0.039782
[epoch4, step318]: loss 0.039537
[epoch4, step319]: loss 0.036129
[epoch4, step320]: loss 0.035746
[epoch4, step321]: loss 0.039019
[epoch4, step322]: loss 0.036750
[epoch4, step323]: loss 0.038751
[epoch4, step324]: loss 0.037343
[epoch4, step325]: loss 0.037111
[epoch4, step326]: loss 0.039197
[epoch4, step327]: loss 0.038861
[epoch4, step328]: loss 0.036717
[epoch4, step329]: loss 0.036513
[epoch4, step330]: loss 0.038995
[epoch4, step331]: loss 0.037067
[epoch4, step332]: loss 0.038792
[epoch4, step333]: loss 0.036447
[epoch4, step334]: loss 0.036921
[epoch4, step335]: loss 0.039542
[epoch4, step336]: loss 0.040366
[epoch4, step337]: loss 0.036805
[epoch4, step338]: loss 0.036287
[epoch4, step339]: loss 0.039246
[epoch4, step340]: loss 0.037374
[epoch4, step341]: loss 0.038893
[epoch4, step342]: loss 0.036201
[epoch4, step343]: loss 0.037101
[epoch4, step344]: loss 0.038950
[epoch4, step345]: loss 0.038809
[epoch4, step346]: loss 0.036026
[epoch4, step347]: loss 0.036311
[epoch4, step348]: loss 0.039598
[epoch4, step349]: loss 0.037321
[epoch4, step350]: loss 0.038891
[epoch4, step351]: loss 0.035737
[epoch4, step352]: loss 0.036680
[epoch4, step353]: loss 0.039269
[epoch4, step354]: loss 0.038503
[epoch4, step355]: loss 0.035339
[epoch4, step356]: loss 0.037261
[epoch4, step357]: loss 0.039421
[epoch4, step358]: loss 0.035446
[epoch4, step359]: loss 0.040244
[epoch4, step360]: loss 0.035283
[epoch4, step361]: loss 0.036235
[epoch4, step362]: loss 0.039934
[epoch4, step363]: loss 0.039168
[epoch4, step364]: loss 0.036332
[epoch4, step365]: loss 0.036367
[epoch4, step366]: loss 0.039806
[epoch4, step367]: loss 0.036834
[epoch4, step368]: loss 0.038758
[epoch4, step369]: loss 0.036220
[epoch4, step370]: loss 0.037346
[epoch4, step371]: loss 0.040147
[epoch4, step372]: loss 0.039030
[epoch4, step373]: loss 0.035850
[epoch4, step374]: loss 0.035835
[epoch4, step375]: loss 0.039867
[epoch4, step376]: loss 0.036882
[epoch4, step377]: loss 0.039511
[epoch4, step378]: loss 0.036919
[epoch4, step379]: loss 0.037434
[epoch4, step380]: loss 0.039966
[epoch4, step381]: loss 0.039131
[epoch4, step382]: loss 0.036681
[epoch4, step383]: loss 0.035611
[epoch4, step384]: loss 0.038723
[epoch4, step385]: loss 0.036633
[epoch4, step386]: loss 0.039534
[epoch4, step387]: loss 0.036368
[epoch4, step388]: loss 0.037615
[epoch4, step389]: loss 0.039292
[epoch4, step390]: loss 0.040208
[epoch4, step391]: loss 0.036033
[epoch4, step392]: loss 0.037171
[epoch4, step393]: loss 0.038704
[epoch4, step394]: loss 0.036900
[epoch4, step395]: loss 0.039001
[epoch4, step396]: loss 0.036563
[epoch4, step397]: loss 0.036571
[epoch4, step398]: loss 0.039551
[epoch4, step399]: loss 0.039446
[epoch4, step400]: loss 0.036239
[epoch4, step401]: loss 0.036343
[epoch4, step402]: loss 0.039175
[epoch4, step403]: loss 0.036653
[epoch4, step404]: loss 0.039688
[epoch4, step405]: loss 0.036633
[epoch4, step406]: loss 0.036990
[epoch4, step407]: loss 0.039156
[epoch4, step408]: loss 0.039429
[epoch4, step409]: loss 0.037648
[epoch4, step410]: loss 0.037184
[epoch4, step411]: loss 0.039100
[epoch4, step412]: loss 0.036345
[epoch4, step413]: loss 0.039204
[epoch4, step414]: loss 0.036230
[epoch4, step415]: loss 0.037257
[epoch4, step416]: loss 0.038674
[epoch4, step417]: loss 0.039751
[epoch4, step418]: loss 0.036490
[epoch4, step419]: loss 0.035645
[epoch4, step420]: loss 0.039611
[epoch4, step421]: loss 0.036399
[epoch4, step422]: loss 0.039210
[epoch4, step423]: loss 0.036425
[epoch4, step424]: loss 0.036834
[epoch4, step425]: loss 0.039486
[epoch4, step426]: loss 0.039673
[epoch4, step427]: loss 0.036704
[epoch4, step428]: loss 0.036384
[epoch4, step429]: loss 0.039932
[epoch4, step430]: loss 0.036764
[epoch4, step431]: loss 0.039571
[epoch4, step432]: loss 0.036485
[epoch4, step433]: loss 0.037811
[epoch4, step434]: loss 0.039216
[epoch4, step435]: loss 0.039971
[epoch4, step436]: loss 0.036382
[epoch4, step437]: loss 0.036604
[epoch4, step438]: loss 0.040036
[epoch4, step439]: loss 0.036907
[epoch4, step440]: loss 0.039262
[epoch4, step441]: loss 0.036706
[epoch4, step442]: loss 0.036662
[epoch4, step443]: loss 0.039835
[epoch4, step444]: loss 0.039004
[epoch4, step445]: loss 0.036832
[epoch4, step446]: loss 0.036951
[epoch4, step447]: loss 0.039986
[epoch4, step448]: loss 0.037021
[epoch4, step449]: loss 0.039010
[epoch4, step450]: loss 0.035873
[epoch4, step451]: loss 0.036722
[epoch4, step452]: loss 0.038205
[epoch4, step453]: loss 0.039748
[epoch4, step454]: loss 0.036483
[epoch4, step455]: loss 0.036757
[epoch4, step456]: loss 0.038630
[epoch4, step457]: loss 0.037327
[epoch4, step458]: loss 0.039062
[epoch4, step459]: loss 0.036984
[epoch4, step460]: loss 0.036968
[epoch4, step461]: loss 0.040017
[epoch4, step462]: loss 0.038723
[epoch4, step463]: loss 0.036473
[epoch4, step464]: loss 0.036402
[epoch4, step465]: loss 0.040584
[epoch4, step466]: loss 0.036727
[epoch4, step467]: loss 0.038940
[epoch4, step468]: loss 0.036558
[epoch4, step469]: loss 0.037129
[epoch4, step470]: loss 0.039551
[epoch4, step471]: loss 0.039092
[epoch4, step472]: loss 0.037157
[epoch4, step473]: loss 0.035976
[epoch4, step474]: loss 0.039199
[epoch4, step475]: loss 0.036812
[epoch4, step476]: loss 0.039664
[epoch4, step477]: loss 0.036159
[epoch4, step478]: loss 0.036159
[epoch4, step479]: loss 0.039171
[epoch4, step480]: loss 0.038399
[epoch4, step481]: loss 0.035862
[epoch4, step482]: loss 0.035955
[epoch4, step483]: loss 0.039695
[epoch4, step484]: loss 0.037035
[epoch4, step485]: loss 0.039349
[epoch4, step486]: loss 0.036883
[epoch4, step487]: loss 0.036488
[epoch4, step488]: loss 0.039794
[epoch4, step489]: loss 0.038734
[epoch4, step490]: loss 0.036891
[epoch4, step491]: loss 0.036748
[epoch4, step492]: loss 0.039106
[epoch4, step493]: loss 0.036406
[epoch4, step494]: loss 0.038725
[epoch4, step495]: loss 0.037502
[epoch4, step496]: loss 0.036922
[epoch4, step497]: loss 0.039644
[epoch4, step498]: loss 0.039286
[epoch4, step499]: loss 0.036632
[epoch4, step500]: loss 0.036079
[epoch4, step501]: loss 0.038753
[epoch4, step502]: loss 0.036656
[epoch4, step503]: loss 0.039502
[epoch4, step504]: loss 0.036199
[epoch4, step505]: loss 0.035965
[epoch4, step506]: loss 0.039811
[epoch4, step507]: loss 0.039848
[epoch4, step508]: loss 0.036869
[epoch4, step509]: loss 0.036514
[epoch4, step510]: loss 0.039587
[epoch4, step511]: loss 0.037066
[epoch4, step512]: loss 0.039725
[epoch4, step513]: loss 0.036560
[epoch4, step514]: loss 0.037044
[epoch4, step515]: loss 0.039311
[epoch4, step516]: loss 0.039747
[epoch4, step517]: loss 0.036416
[epoch4, step518]: loss 0.036601
[epoch4, step519]: loss 0.039304
[epoch4, step520]: loss 0.036278
[epoch4, step521]: loss 0.038958
[epoch4, step522]: loss 0.036058
[epoch4, step523]: loss 0.036928
[epoch4, step524]: loss 0.038570
[epoch4, step525]: loss 0.039783
[epoch4, step526]: loss 0.036519
[epoch4, step527]: loss 0.036245
[epoch4, step528]: loss 0.039847
[epoch4, step529]: loss 0.036185
[epoch4, step530]: loss 0.039736
[epoch4, step531]: loss 0.036265
[epoch4, step532]: loss 0.036369
[epoch4, step533]: loss 0.040413
[epoch4, step534]: loss 0.039164
[epoch4, step535]: loss 0.036913
[epoch4, step536]: loss 0.036576
[epoch4, step537]: loss 0.039372
[epoch4, step538]: loss 0.036755
[epoch4, step539]: loss 0.038957
[epoch4, step540]: loss 0.036047
[epoch4, step541]: loss 0.036237
[epoch4, step542]: loss 0.039351
[epoch4, step543]: loss 0.039007
[epoch4, step544]: loss 0.036313
[epoch4, step545]: loss 0.035752
[epoch4, step546]: loss 0.039759
[epoch4, step547]: loss 0.036721
[epoch4, step548]: loss 0.039337
[epoch4, step549]: loss 0.036634
[epoch4, step550]: loss 0.036840
[epoch4, step551]: loss 0.039103
[epoch4, step552]: loss 0.038733
[epoch4, step553]: loss 0.036806
[epoch4, step554]: loss 0.036382
[epoch4, step555]: loss 0.039023
[epoch4, step556]: loss 0.036457
[epoch4, step557]: loss 0.038759
[epoch4, step558]: loss 0.036557
[epoch4, step559]: loss 0.036163
[epoch4, step560]: loss 0.039376
[epoch4, step561]: loss 0.039097
[epoch4, step562]: loss 0.036390
[epoch4, step563]: loss 0.029242
[epoch4, step564]: loss 0.028852
[epoch4, step565]: loss 0.027946
[epoch4, step566]: loss 0.035492
[epoch4, step567]: loss 0.027257
[epoch4, step568]: loss 0.026276
[epoch4, step569]: loss 0.024157
[epoch4, step570]: loss 0.031497
[epoch4, step571]: loss 0.027130
[epoch4, step572]: loss 0.025825
[epoch4, step573]: loss 0.028436
[epoch4, step574]: loss 0.027743
[epoch4, step575]: loss 0.020870
[epoch4, step576]: loss 0.021855
[epoch4, step577]: loss 0.025025
[epoch4, step578]: loss 0.018240
[epoch4, step579]: loss 0.027904
[epoch4, step580]: loss 0.019775
[epoch4, step581]: loss 0.025200
[epoch4, step582]: loss 0.024788
[epoch4, step583]: loss 0.022124
[epoch4, step584]: loss 0.023863
[epoch4, step585]: loss 0.026332
[epoch4, step586]: loss 0.021682
[epoch4, step587]: loss 0.027982
[epoch4, step588]: loss 0.023341
[epoch4, step589]: loss 0.022944
[epoch4, step590]: loss 0.027555
[epoch4, step591]: loss 0.020549
[epoch4, step592]: loss 0.026311
[epoch4, step593]: loss 0.021891
[epoch4, step594]: loss 0.026084
[epoch4, step595]: loss 0.026882
[epoch4, step596]: loss 0.022470
[epoch4, step597]: loss 0.025061
[epoch4, step598]: loss 0.026997
[epoch4, step599]: loss 0.025641
[epoch4, step600]: loss 0.027826
[epoch4, step601]: loss 0.019394
[epoch4, step602]: loss 0.022828
[epoch4, step603]: loss 0.026034
[epoch4, step604]: loss 0.026822
[epoch4, step605]: loss 0.025399
[epoch4, step606]: loss 0.025230
[epoch4, step607]: loss 0.027173
[epoch4, step608]: loss 0.025875
[epoch4, step609]: loss 0.027226
[epoch4, step610]: loss 0.026972
[epoch4, step611]: loss 0.026333
[epoch4, step612]: loss 0.025623
[epoch4, step613]: loss 0.019265
[epoch4, step614]: loss 0.025369
[epoch4, step615]: loss 0.028618
[epoch4, step616]: loss 0.024031
[epoch4, step617]: loss 0.023665
[epoch4, step618]: loss 0.026100
[epoch4, step619]: loss 0.027158
[epoch4, step620]: loss 0.024530
[epoch4, step621]: loss 0.026222
[epoch4, step622]: loss 0.020441
[epoch4, step623]: loss 0.025000
[epoch4, step624]: loss 0.026507
[epoch4, step625]: loss 0.025674
[epoch4, step626]: loss 0.028000
[epoch4, step627]: loss 0.022857
[epoch4, step628]: loss 0.025383
[epoch4, step629]: loss 0.021003
[epoch4, step630]: loss 0.023431
[epoch4, step631]: loss 0.031534
[epoch4, step632]: loss 0.023269
[epoch4, step633]: loss 0.024762
[epoch4, step634]: loss 0.027531
[epoch4, step635]: loss 0.025774
[epoch4, step636]: loss 0.020954
[epoch4, step637]: loss 0.027250
[epoch4, step638]: loss 0.026975
[epoch4, step639]: loss 0.023042
[epoch4, step640]: loss 0.029274
[epoch4, step641]: loss 0.030626
[epoch4, step642]: loss 0.024869
[epoch4, step643]: loss 0.025999
[epoch4, step644]: loss 0.025743
[epoch4, step645]: loss 0.023656
[epoch4, step646]: loss 0.026292
[epoch4, step647]: loss 0.023621
[epoch4, step648]: loss 0.022863
[epoch4, step649]: loss 0.028560
[epoch4, step650]: loss 0.021921
[epoch4, step651]: loss 0.025854
[epoch4, step652]: loss 0.026636
[epoch4, step653]: loss 0.027886
[epoch4, step654]: loss 0.023128
[epoch4, step655]: loss 0.024320
[epoch4, step656]: loss 0.021561
[epoch4, step657]: loss 0.027808
[epoch4, step658]: loss 0.025343
[epoch4, step659]: loss 0.027677
[epoch4, step660]: loss 0.024053
[epoch4, step661]: loss 0.026386
[epoch4, step662]: loss 0.023995
[epoch4, step663]: loss 0.020994
[epoch4, step664]: loss 0.025181
[epoch4, step665]: loss 0.028498
[epoch4, step666]: loss 0.026657
[epoch4, step667]: loss 0.026720
[epoch4, step668]: loss 0.022116
[epoch4, step669]: loss 0.026714
[epoch4, step670]: loss 0.027708
[epoch4, step671]: loss 0.021352
[epoch4, step672]: loss 0.023827
[epoch4, step673]: loss 0.022206
[epoch4, step674]: loss 0.021351
[epoch4, step675]: loss 0.020114
[epoch4, step676]: loss 0.024454
[epoch4, step677]: loss 0.025293
[epoch4, step678]: loss 0.023267
[epoch4, step679]: loss 0.024050
[epoch4, step680]: loss 0.030690
[epoch4, step681]: loss 0.022177
[epoch4, step682]: loss 0.026215
[epoch4, step683]: loss 0.025904
[epoch4, step684]: loss 0.024561
[epoch4, step685]: loss 0.024336
[epoch4, step686]: loss 0.026968
[epoch4, step687]: loss 0.026633
[epoch4, step688]: loss 0.022553
[epoch4, step689]: loss 0.024538
[epoch4, step690]: loss 0.025331
[epoch4, step691]: loss 0.024229
[epoch4, step692]: loss 0.022465
[epoch4, step693]: loss 0.027288
[epoch4, step694]: loss 0.022845
[epoch4, step695]: loss 0.026643
[epoch4, step696]: loss 0.026024
[epoch4, step697]: loss 0.027152
[epoch4, step698]: loss 0.024808
[epoch4, step699]: loss 0.023603
[epoch4, step700]: loss 0.021603
[epoch4, step701]: loss 0.026024
[epoch4, step702]: loss 0.021815
[epoch4, step703]: loss 0.022976
[epoch4, step704]: loss 0.025330
[epoch4, step705]: loss 0.024818
[epoch4, step706]: loss 0.023955
[epoch4, step707]: loss 0.024824
[epoch4, step708]: loss 0.026243
[epoch4, step709]: loss 0.027545
[epoch4, step710]: loss 0.023904
[epoch4, step711]: loss 0.023586
[epoch4, step712]: loss 0.026918
[epoch4, step713]: loss 0.026356
[epoch4, step714]: loss 0.021436
[epoch4, step715]: loss 0.023566
[epoch4, step716]: loss 0.026041
[epoch4, step717]: loss 0.023744
[epoch4, step718]: loss 0.025034
[epoch4, step719]: loss 0.033038
[epoch4, step720]: loss 0.024643
[epoch4, step721]: loss 0.023186
[epoch4, step722]: loss 0.030558
[epoch4, step723]: loss 0.025960
[epoch4, step724]: loss 0.022760
[epoch4, step725]: loss 0.028026
[epoch4, step726]: loss 0.022210
[epoch4, step727]: loss 0.024706
[epoch4, step728]: loss 0.026484
[epoch4, step729]: loss 0.021392
[epoch4, step730]: loss 0.022519
[epoch4, step731]: loss 0.025837
[epoch4, step732]: loss 0.025929
[epoch4, step733]: loss 0.023848
[epoch4, step734]: loss 0.023013
[epoch4, step735]: loss 0.027443
[epoch4, step736]: loss 0.025251
[epoch4, step737]: loss 0.026808
[epoch4, step738]: loss 0.020667
[epoch4, step739]: loss 0.025603
[epoch4, step740]: loss 0.022487
[epoch4, step741]: loss 0.025152
[epoch4, step742]: loss 0.022126
[epoch4, step743]: loss 0.023493
[epoch4, step744]: loss 0.024045
[epoch4, step745]: loss 0.024820
[epoch4, step746]: loss 0.025138
[epoch4, step747]: loss 0.027630
[epoch4, step748]: loss 0.025721
[epoch4, step749]: loss 0.026196
[epoch4, step750]: loss 0.027344
[epoch4, step751]: loss 0.021945
[epoch4, step752]: loss 0.025580
[epoch4, step753]: loss 0.025739
[epoch4, step754]: loss 0.022792
[epoch4, step755]: loss 0.026356
[epoch4, step756]: loss 0.023539
[epoch4, step757]: loss 0.020629
[epoch4, step758]: loss 0.025455
[epoch4, step759]: loss 0.023166
[epoch4, step760]: loss 0.024195
[epoch4, step761]: loss 0.026610
[epoch4, step762]: loss 0.021520
[epoch4, step763]: loss 0.025707
[epoch4, step764]: loss 0.023860
[epoch4, step765]: loss 0.026130
[epoch4, step766]: loss 0.024849
[epoch4, step767]: loss 0.026737
[epoch4, step768]: loss 0.021359
[epoch4, step769]: loss 0.026822
[epoch4, step770]: loss 0.025965
[epoch4, step771]: loss 0.023404
[epoch4, step772]: loss 0.029084
[epoch4, step773]: loss 0.026570
[epoch4, step774]: loss 0.024445
[epoch4, step775]: loss 0.020625
[epoch4, step776]: loss 0.025614
[epoch4, step777]: loss 0.023299
[epoch4, step778]: loss 0.028012
[epoch4, step779]: loss 0.023821
[epoch4, step780]: loss 0.020322
[epoch4, step781]: loss 0.024479
[epoch4, step782]: loss 0.022830
[epoch4, step783]: loss 0.019418
[epoch4, step784]: loss 0.020436
[epoch4, step785]: loss 0.021582
[epoch4, step786]: loss 0.024530
[epoch4, step787]: loss 0.023601
[epoch4, step788]: loss 0.024766
[epoch4, step789]: loss 0.022662
[epoch4, step790]: loss 0.023294
[epoch4, step791]: loss 0.026766
[epoch4, step792]: loss 0.025335
[epoch4, step793]: loss 0.026892
[epoch4, step794]: loss 0.020625
[epoch4, step795]: loss 0.025703
[epoch4, step796]: loss 0.028039
[epoch4, step797]: loss 0.027678
[epoch4, step798]: loss 0.027282
[epoch4, step799]: loss 0.026064
[epoch4, step800]: loss 0.021647
[epoch4, step801]: loss 0.021801
[epoch4, step802]: loss 0.022859
[epoch4, step803]: loss 0.026400
[epoch4, step804]: loss 0.027589
[epoch4, step805]: loss 0.028244
[epoch4, step806]: loss 0.021247
[epoch4, step807]: loss 0.020569
[epoch4, step808]: loss 0.022990
[epoch4, step809]: loss 0.023066
[epoch4, step810]: loss 0.026061
[epoch4, step811]: loss 0.025753
[epoch4, step812]: loss 0.024637
[epoch4, step813]: loss 0.023484
[epoch4, step814]: loss 0.025284
[epoch4, step815]: loss 0.024799
[epoch4, step816]: loss 0.024323
[epoch4, step817]: loss 0.025325
[epoch4, step818]: loss 0.022610
[epoch4, step819]: loss 0.019884
[epoch4, step820]: loss 0.023589
[epoch4, step821]: loss 0.021807
[epoch4, step822]: loss 0.030562
[epoch4, step823]: loss 0.024064
[epoch4, step824]: loss 0.026942
[epoch4, step825]: loss 0.025232
[epoch4, step826]: loss 0.024447
[epoch4, step827]: loss 0.027179
[epoch4, step828]: loss 0.028741
[epoch4, step829]: loss 0.026363
[epoch4, step830]: loss 0.022615
[epoch4, step831]: loss 0.026412
[epoch4, step832]: loss 0.020897
[epoch4, step833]: loss 0.029114
[epoch4, step834]: loss 0.025488
[epoch4, step835]: loss 0.020929
[epoch4, step836]: loss 0.026989
[epoch4, step837]: loss 0.025428
[epoch4, step838]: loss 0.026069
[epoch4, step839]: loss 0.028375
[epoch4, step840]: loss 0.020792
[epoch4, step841]: loss 0.024175
[epoch4, step842]: loss 0.027650
[epoch4, step843]: loss 0.025092
[epoch4, step844]: loss 0.024905
[epoch4, step845]: loss 0.021156
[epoch4, step846]: loss 0.025448
[epoch4, step847]: loss 0.027103
[epoch4, step848]: loss 0.025408
[epoch4, step849]: loss 0.025090
[epoch4, step850]: loss 0.023050
[epoch4, step851]: loss 0.023988
[epoch4, step852]: loss 0.023464
[epoch4, step853]: loss 0.029341
[epoch4, step854]: loss 0.022863
[epoch4, step855]: loss 0.027475
[epoch4, step856]: loss 0.022409
[epoch4, step857]: loss 0.026191
[epoch4, step858]: loss 0.024539
[epoch4, step859]: loss 0.023906
[epoch4, step860]: loss 0.022795
[epoch4, step861]: loss 0.023814
[epoch4, step862]: loss 0.023292
[epoch4, step863]: loss 0.020967
[epoch4, step864]: loss 0.026983
[epoch4, step865]: loss 0.023650
[epoch4, step866]: loss 0.025346
[epoch4, step867]: loss 0.026387
[epoch4, step868]: loss 0.027132
[epoch4, step869]: loss 0.024240
[epoch4, step870]: loss 0.030954
[epoch4, step871]: loss 0.022072
[epoch4, step872]: loss 0.025662
[epoch4, step873]: loss 0.025971
[epoch4, step874]: loss 0.023790
[epoch4, step875]: loss 0.024149
[epoch4, step876]: loss 0.024306
[epoch4, step877]: loss 0.019142
[epoch4, step878]: loss 0.023358
[epoch4, step879]: loss 0.028297
[epoch4, step880]: loss 0.025558
[epoch4, step881]: loss 0.022381
[epoch4, step882]: loss 0.024177
[epoch4, step883]: loss 0.023693
[epoch4, step884]: loss 0.026531
[epoch4, step885]: loss 0.026090
[epoch4, step886]: loss 0.026755
[epoch4, step887]: loss 0.024209
[epoch4, step888]: loss 0.024746
[epoch4, step889]: loss 0.023667
[epoch4, step890]: loss 0.023364
[epoch4, step891]: loss 0.025746
[epoch4, step892]: loss 0.020971
[epoch4, step893]: loss 0.024855
[epoch4, step894]: loss 0.025195
[epoch4, step895]: loss 0.022620
[epoch4, step896]: loss 0.022095
[epoch4, step897]: loss 0.023865
[epoch4, step898]: loss 0.025597
[epoch4, step899]: loss 0.028310
[epoch4, step900]: loss 0.027472
[epoch4, step901]: loss 0.025584
[epoch4, step902]: loss 0.024043
[epoch4, step903]: loss 0.024094
[epoch4, step904]: loss 0.028129
[epoch4, step905]: loss 0.027598
[epoch4, step906]: loss 0.022613
[epoch4, step907]: loss 0.023740
[epoch4, step908]: loss 0.022774
[epoch4, step909]: loss 0.025566
[epoch4, step910]: loss 0.023335
[epoch4, step911]: loss 0.025226
[epoch4, step912]: loss 0.024018
[epoch4, step913]: loss 0.024079
[epoch4, step914]: loss 0.030724
[epoch4, step915]: loss 0.024043
[epoch4, step916]: loss 0.023845
[epoch4, step917]: loss 0.025296
[epoch4, step918]: loss 0.028689
[epoch4, step919]: loss 0.024292
[epoch4, step920]: loss 0.027644
[epoch4, step921]: loss 0.024558
[epoch4, step922]: loss 0.023233
[epoch4, step923]: loss 0.022502
[epoch4, step924]: loss 0.021356
[epoch4, step925]: loss 0.025442
[epoch4, step926]: loss 0.026578
[epoch4, step927]: loss 0.025814
[epoch4, step928]: loss 0.024969
[epoch4, step929]: loss 0.027836
[epoch4, step930]: loss 0.026057
[epoch4, step931]: loss 0.027437
[epoch4, step932]: loss 0.021626
[epoch4, step933]: loss 0.028291
[epoch4, step934]: loss 0.022106
[epoch4, step935]: loss 0.021831
[epoch4, step936]: loss 0.022431
[epoch4, step937]: loss 0.027161
[epoch4, step938]: loss 0.025223
[epoch4, step939]: loss 0.020809
[epoch4, step940]: loss 0.023003
[epoch4, step941]: loss 0.026945
[epoch4, step942]: loss 0.025646
[epoch4, step943]: loss 0.023314
[epoch4, step944]: loss 0.027534
[epoch4, step945]: loss 0.020613
[epoch4, step946]: loss 0.025558
[epoch4, step947]: loss 0.027821
[epoch4, step948]: loss 0.019625
[epoch4, step949]: loss 0.022886
[epoch4, step950]: loss 0.026830
[epoch4, step951]: loss 0.028877
[epoch4, step952]: loss 0.025298
[epoch4, step953]: loss 0.027734
[epoch4, step954]: loss 0.022151
[epoch4, step955]: loss 0.037138
[epoch4, step956]: loss 0.053048
[epoch4, step957]: loss 0.046207
[epoch4, step958]: loss 0.042612
[epoch4, step959]: loss 0.045294
[epoch4, step960]: loss 0.041180
[epoch4, step961]: loss 0.040260
[epoch4, step962]: loss 0.039799
[epoch4, step963]: loss 0.040812
[epoch4, step964]: loss 0.042260
[epoch4, step965]: loss 0.043483
[epoch4, step966]: loss 0.040956
[epoch4, step967]: loss 0.039711
[epoch4, step968]: loss 0.041702
[epoch4, step969]: loss 0.040222
[epoch4, step970]: loss 0.039377
[epoch4, step971]: loss 0.039271
[epoch4, step972]: loss 0.040608
[epoch4, step973]: loss 0.039518
[epoch4, step974]: loss 0.041498
[epoch4, step975]: loss 0.038329
[epoch4, step976]: loss 0.037743
[epoch4, step977]: loss 0.041670
[epoch4, step978]: loss 0.040036
[epoch4, step979]: loss 0.038829
[epoch4, step980]: loss 0.037444
[epoch4, step981]: loss 0.038989
[epoch4, step982]: loss 0.039254
[epoch4, step983]: loss 0.041117
[epoch4, step984]: loss 0.037337
[epoch4, step985]: loss 0.037210
[epoch4, step986]: loss 0.041522
[epoch4, step987]: loss 0.039754
[epoch4, step988]: loss 0.039441
[epoch4, step989]: loss 0.038582
[epoch4, step990]: loss 0.038996
[epoch4, step991]: loss 0.039754
[epoch4, step992]: loss 0.040156
[epoch4, step993]: loss 0.037761
[epoch4, step994]: loss 0.036548
[epoch4, step995]: loss 0.040627
[epoch4, step996]: loss 0.038880
[epoch4, step997]: loss 0.038756
[epoch4, step998]: loss 0.038207
[epoch4, step999]: loss 0.039017
[epoch4, step1000]: loss 0.039336
[epoch4, step1001]: loss 0.040167
[epoch4, step1002]: loss 0.037774
[epoch4, step1003]: loss 0.036918
[epoch4, step1004]: loss 0.040447
[epoch4, step1005]: loss 0.038252
[epoch4, step1006]: loss 0.038640
[epoch4, step1007]: loss 0.037042
[epoch4, step1008]: loss 0.038301
[epoch4, step1009]: loss 0.038870
[epoch4, step1010]: loss 0.040587
[epoch4, step1011]: loss 0.037523
[epoch4, step1012]: loss 0.037364
[epoch4, step1013]: loss 0.040516
[epoch4, step1014]: loss 0.039427
[epoch4, step1015]: loss 0.038968
[epoch4, step1016]: loss 0.036843
[epoch4, step1017]: loss 0.038265
[epoch4, step1018]: loss 0.038575
[epoch4, step1019]: loss 0.040202
[epoch4, step1020]: loss 0.036922
[epoch4, step1021]: loss 0.036378
[epoch4, step1022]: loss 0.039991
[epoch4, step1023]: loss 0.038565
[epoch4, step1024]: loss 0.039132
[epoch4, step1025]: loss 0.036481
[epoch4, step1026]: loss 0.037590
[epoch4, step1027]: loss 0.038447
[epoch4, step1028]: loss 0.039755
[epoch4, step1029]: loss 0.036830
[epoch4, step1030]: loss 0.035949
[epoch4, step1031]: loss 0.038722
[epoch4, step1032]: loss 0.038812
[epoch4, step1033]: loss 0.037694
[epoch4, step1034]: loss 0.036280
[epoch4, step1035]: loss 0.037464
[epoch4, step1036]: loss 0.038418
[epoch4, step1037]: loss 0.039248
[epoch4, step1038]: loss 0.036410
[epoch4, step1039]: loss 0.036603
[epoch4, step1040]: loss 0.039156
[epoch4, step1041]: loss 0.038139
[epoch4, step1042]: loss 0.037106
[epoch4, step1043]: loss 0.036340
[epoch4, step1044]: loss 0.038493
[epoch4, step1045]: loss 0.038388
[epoch4, step1046]: loss 0.039928
[epoch4, step1047]: loss 0.037000
[epoch4, step1048]: loss 0.035890
[epoch4, step1049]: loss 0.039812
[epoch4, step1050]: loss 0.038485
[epoch4, step1051]: loss 0.038042
[epoch4, step1052]: loss 0.036564
[epoch4, step1053]: loss 0.038507
[epoch4, step1054]: loss 0.038325
[epoch4, step1055]: loss 0.038859
[epoch4, step1056]: loss 0.035852
[epoch4, step1057]: loss 0.036942
[epoch4, step1058]: loss 0.040471
[epoch4, step1059]: loss 0.038668
[epoch4, step1060]: loss 0.038091
[epoch4, step1061]: loss 0.035755
[epoch4, step1062]: loss 0.038761
[epoch4, step1063]: loss 0.038179
[epoch4, step1064]: loss 0.039625
[epoch4, step1065]: loss 0.036590
[epoch4, step1066]: loss 0.035745
[epoch4, step1067]: loss 0.039911
[epoch4, step1068]: loss 0.036825
[epoch4, step1069]: loss 0.037368
[epoch4, step1070]: loss 0.036103
[epoch4, step1071]: loss 0.038645
[epoch4, step1072]: loss 0.038991
[epoch4, step1073]: loss 0.039089
[epoch4, step1074]: loss 0.036492
[epoch4, step1075]: loss 0.036583
[epoch4, step1076]: loss 0.039708
[epoch4, step1077]: loss 0.038262
[epoch4, step1078]: loss 0.037648
[epoch4, step1079]: loss 0.037354
[epoch4, step1080]: loss 0.038333
[epoch4, step1081]: loss 0.037960
[epoch4, step1082]: loss 0.039412
[epoch4, step1083]: loss 0.037295
[epoch4, step1084]: loss 0.036573
[epoch4, step1085]: loss 0.039355
[epoch4, step1086]: loss 0.037754
[epoch4, step1087]: loss 0.038183
[epoch4, step1088]: loss 0.036160
[epoch4, step1089]: loss 0.038476
[epoch4, step1090]: loss 0.038771
[epoch4, step1091]: loss 0.039522
[epoch4, step1092]: loss 0.036305
[epoch4, step1093]: loss 0.036033
[epoch4, step1094]: loss 0.038693
[epoch4, step1095]: loss 0.037783
[epoch4, step1096]: loss 0.037326
[epoch4, step1097]: loss 0.036285
[epoch4, step1098]: loss 0.037778
[epoch4, step1099]: loss 0.038060
[epoch4, step1100]: loss 0.040046
[epoch4, step1101]: loss 0.036839
[epoch4, step1102]: loss 0.036316
[epoch4, step1103]: loss 0.039075
[epoch4, step1104]: loss 0.038093
[epoch4, step1105]: loss 0.038258
[epoch4, step1106]: loss 0.035295
[epoch4, step1107]: loss 0.038224
[epoch4, step1108]: loss 0.037758
[epoch4, step1109]: loss 0.039780
[epoch4, step1110]: loss 0.037090
[epoch4, step1111]: loss 0.036535
[epoch4, step1112]: loss 0.040205
[epoch4, step1113]: loss 0.037849
[epoch4, step1114]: loss 0.038350
[epoch4, step1115]: loss 0.036255
[epoch4, step1116]: loss 0.038304
[epoch4, step1117]: loss 0.038236
[epoch4, step1118]: loss 0.039329
[epoch4, step1119]: loss 0.036287
[epoch4, step1120]: loss 0.036129
[epoch4, step1121]: loss 0.039506
[epoch4, step1122]: loss 0.037690
[epoch4, step1123]: loss 0.037072
[epoch4, step1124]: loss 0.037054
[epoch4, step1125]: loss 0.038656
[epoch4, step1126]: loss 0.039112
[epoch4, step1127]: loss 0.039713
[epoch4, step1128]: loss 0.036779
[epoch4, step1129]: loss 0.036304
[epoch4, step1130]: loss 0.040623
[epoch4, step1131]: loss 0.038499
[epoch4, step1132]: loss 0.038515
[epoch4, step1133]: loss 0.035867
[epoch4, step1134]: loss 0.037839
[epoch4, step1135]: loss 0.039230
[epoch4, step1136]: loss 0.039813
[epoch4, step1137]: loss 0.036536
[epoch4, step1138]: loss 0.036299
[epoch4, step1139]: loss 0.039649
[epoch4, step1140]: loss 0.037488
[epoch4, step1141]: loss 0.037427
[epoch4, step1142]: loss 0.036081
[epoch4, step1143]: loss 0.037582
[epoch4, step1144]: loss 0.038548
[epoch4, step1145]: loss 0.038989
[epoch4, step1146]: loss 0.036209
[epoch4, step1147]: loss 0.037264
[epoch4, step1148]: loss 0.039771
[epoch4, step1149]: loss 0.038006
[epoch4, step1150]: loss 0.037832
[epoch4, step1151]: loss 0.036449
[epoch4, step1152]: loss 0.038727
[epoch4, step1153]: loss 0.037548
[epoch4, step1154]: loss 0.039846
[epoch4, step1155]: loss 0.036662
[epoch4, step1156]: loss 0.035641
[epoch4, step1157]: loss 0.039531
[epoch4, step1158]: loss 0.038326
[epoch4, step1159]: loss 0.038093
[epoch4, step1160]: loss 0.036949
[epoch4, step1161]: loss 0.038661
[epoch4, step1162]: loss 0.038153
[epoch4, step1163]: loss 0.038784
[epoch4, step1164]: loss 0.036411
[epoch4, step1165]: loss 0.037382
[epoch4, step1166]: loss 0.039676
[epoch4, step1167]: loss 0.037381
[epoch4, step1168]: loss 0.038026
[epoch4, step1169]: loss 0.036035
[epoch4, step1170]: loss 0.038323
[epoch4, step1171]: loss 0.037964
[epoch4, step1172]: loss 0.039664
[epoch4, step1173]: loss 0.036706
[epoch4, step1174]: loss 0.036809
[epoch4, step1175]: loss 0.039724
[epoch4, step1176]: loss 0.037670
[epoch4, step1177]: loss 0.038355
[epoch4, step1178]: loss 0.036432
[epoch4, step1179]: loss 0.037824
[epoch4, step1180]: loss 0.038391
[epoch4, step1181]: loss 0.039758
[epoch4, step1182]: loss 0.035872
[epoch4, step1183]: loss 0.036533
[epoch4, step1184]: loss 0.039001
[epoch4, step1185]: loss 0.038008
[epoch4, step1186]: loss 0.036964
[epoch4, step1187]: loss 0.035372
[epoch4, step1188]: loss 0.037401
[epoch4, step1189]: loss 0.038064
[epoch4, step1190]: loss 0.039037
[epoch4, step1191]: loss 0.037119
[epoch4, step1192]: loss 0.036376
[epoch4, step1193]: loss 0.039477
[epoch4, step1194]: loss 0.038080
[epoch4, step1195]: loss 0.036878
[epoch4, step1196]: loss 0.035384
[epoch4, step1197]: loss 0.038488
[epoch4, step1198]: loss 0.038202
[epoch4, step1199]: loss 0.038989
[epoch4, step1200]: loss 0.036244
[epoch4, step1201]: loss 0.036752
[epoch4, step1202]: loss 0.040565
[epoch4, step1203]: loss 0.038154
[epoch4, step1204]: loss 0.037240
[epoch4, step1205]: loss 0.035585
[epoch4, step1206]: loss 0.037583
[epoch4, step1207]: loss 0.038392
[epoch4, step1208]: loss 0.039505
[epoch4, step1209]: loss 0.035330
[epoch4, step1210]: loss 0.036730
[epoch4, step1211]: loss 0.039012
[epoch4, step1212]: loss 0.037776
[epoch4, step1213]: loss 0.037308
[epoch4, step1214]: loss 0.036439
[epoch4, step1215]: loss 0.038766
[epoch4, step1216]: loss 0.037679
[epoch4, step1217]: loss 0.040090
[epoch4, step1218]: loss 0.036136
[epoch4, step1219]: loss 0.037175
[epoch4, step1220]: loss 0.040287
[epoch4, step1221]: loss 0.037003
[epoch4, step1222]: loss 0.038050
[epoch4, step1223]: loss 0.036069
[epoch4, step1224]: loss 0.038386
[epoch4, step1225]: loss 0.038225
[epoch4, step1226]: loss 0.038867
[epoch4, step1227]: loss 0.036367
[epoch4, step1228]: loss 0.035850
[epoch4, step1229]: loss 0.039213
[epoch4, step1230]: loss 0.038162
[epoch4, step1231]: loss 0.037407
[epoch4, step1232]: loss 0.037234
[epoch4, step1233]: loss 0.037853
[epoch4, step1234]: loss 0.038082
[epoch4, step1235]: loss 0.039953
[epoch4, step1236]: loss 0.036670
[epoch4, step1237]: loss 0.036079
[epoch4, step1238]: loss 0.038971
[epoch4, step1239]: loss 0.038688
[epoch4, step1240]: loss 0.038290
[epoch4, step1241]: loss 0.035627
[epoch4, step1242]: loss 0.038108
[epoch4, step1243]: loss 0.038044
[epoch4, step1244]: loss 0.039586
[epoch4, step1245]: loss 0.036855
[epoch4, step1246]: loss 0.036637
[epoch4, step1247]: loss 0.038877
[epoch4, step1248]: loss 0.038026
[epoch4, step1249]: loss 0.038300
[epoch4, step1250]: loss 0.035927
[epoch4, step1251]: loss 0.038301
[epoch4, step1252]: loss 0.039122
[epoch4, step1253]: loss 0.039502
[epoch4, step1254]: loss 0.036551
[epoch4, step1255]: loss 0.036464
[epoch4, step1256]: loss 0.040001
[epoch4, step1257]: loss 0.038251
[epoch4, step1258]: loss 0.037957
[epoch4, step1259]: loss 0.035775
[epoch4, step1260]: loss 0.038153
[epoch4, step1261]: loss 0.037937
[epoch4, step1262]: loss 0.038142
[epoch4, step1263]: loss 0.037059
[epoch4, step1264]: loss 0.036289
[epoch4, step1265]: loss 0.038227
[epoch4, step1266]: loss 0.038005
[epoch4, step1267]: loss 0.037823
[epoch4, step1268]: loss 0.036375
[epoch4, step1269]: loss 0.038280
[epoch4, step1270]: loss 0.037414
[epoch4, step1271]: loss 0.039927
[epoch4, step1272]: loss 0.036597
[epoch4, step1273]: loss 0.036245
[epoch4, step1274]: loss 0.039446
[epoch4, step1275]: loss 0.038267
[epoch4, step1276]: loss 0.037595
[epoch4, step1277]: loss 0.036102
[epoch4, step1278]: loss 0.038645
[epoch4, step1279]: loss 0.038363
[epoch4, step1280]: loss 0.039467
[epoch4, step1281]: loss 0.036345
[epoch4, step1282]: loss 0.036098
[epoch4, step1283]: loss 0.038781
[epoch4, step1284]: loss 0.037510
[epoch4, step1285]: loss 0.038090
[epoch4, step1286]: loss 0.035494
[epoch4, step1287]: loss 0.038755
[epoch4, step1288]: loss 0.039033
[epoch4, step1289]: loss 0.040375
[epoch4, step1290]: loss 0.036447
[epoch4, step1291]: loss 0.036208
[epoch4, step1292]: loss 0.040179
[epoch4, step1293]: loss 0.037126
[epoch4, step1294]: loss 0.037869
[epoch4, step1295]: loss 0.036554
[epoch4, step1296]: loss 0.038345
[epoch4, step1297]: loss 0.037947
[epoch4, step1298]: loss 0.039741
[epoch4, step1299]: loss 0.036667
[epoch4, step1300]: loss 0.036944
[epoch4, step1301]: loss 0.038510
[epoch4, step1302]: loss 0.037937
[epoch4, step1303]: loss 0.037853
[epoch4, step1304]: loss 0.035588
[epoch4, step1305]: loss 0.038463
[epoch4, step1306]: loss 0.037927
[epoch4, step1307]: loss 0.038900
[epoch4, step1308]: loss 0.036579
[epoch4, step1309]: loss 0.035788
[epoch4, step1310]: loss 0.039581
[epoch4, step1311]: loss 0.036827
[epoch4, step1312]: loss 0.038568
[epoch4, step1313]: loss 0.036148
[epoch4, step1314]: loss 0.038103
[epoch4, step1315]: loss 0.037957
[epoch4, step1316]: loss 0.040594
[epoch4, step1317]: loss 0.035896
[epoch4, step1318]: loss 0.035679
[epoch4, step1319]: loss 0.038832
[epoch4, step1320]: loss 0.038126
[epoch4, step1321]: loss 0.038054
[epoch4, step1322]: loss 0.035907
[epoch4, step1323]: loss 0.038476
[epoch4, step1324]: loss 0.037731
[epoch4, step1325]: loss 0.039309
[epoch4, step1326]: loss 0.036185
[epoch4, step1327]: loss 0.036281
[epoch4, step1328]: loss 0.039539
[epoch4, step1329]: loss 0.037883
[epoch4, step1330]: loss 0.038075
[epoch4, step1331]: loss 0.035805
[epoch4, step1332]: loss 0.038024
[epoch4, step1333]: loss 0.037214
[epoch4, step1334]: loss 0.039716
[epoch4, step1335]: loss 0.037019
[epoch4, step1336]: loss 0.036266
[epoch4, step1337]: loss 0.039140
[epoch4, step1338]: loss 0.037625
[epoch4, step1339]: loss 0.038027
[epoch4, step1340]: loss 0.035761
[epoch4, step1341]: loss 0.038311
[epoch4, step1342]: loss 0.037997
[epoch4, step1343]: loss 0.039323
[epoch4, step1344]: loss 0.036511
[epoch4, step1345]: loss 0.036089
[epoch4, step1346]: loss 0.038921
[epoch4, step1347]: loss 0.038525
[epoch4, step1348]: loss 0.036991
[epoch4, step1349]: loss 0.036362
[epoch4, step1350]: loss 0.038195
[epoch4, step1351]: loss 0.037651
[epoch4, step1352]: loss 0.038765
[epoch4, step1353]: loss 0.036063
[epoch4, step1354]: loss 0.036025
[epoch4, step1355]: loss 0.039505
[epoch4, step1356]: loss 0.037488
[epoch4, step1357]: loss 0.037219
[epoch4, step1358]: loss 0.035814
[epoch4, step1359]: loss 0.037643
[epoch4, step1360]: loss 0.038176
[epoch4, step1361]: loss 0.039569
[epoch4, step1362]: loss 0.037014
[epoch4, step1363]: loss 0.036691
[epoch4, step1364]: loss 0.039465
[epoch4, step1365]: loss 0.037791
[epoch4, step1366]: loss 0.037599
[epoch4, step1367]: loss 0.035133
[epoch4, step1368]: loss 0.038880
[epoch4, step1369]: loss 0.038105
[epoch4, step1370]: loss 0.038989
[epoch4, step1371]: loss 0.036573
[epoch4, step1372]: loss 0.036085
[epoch4, step1373]: loss 0.039402
[epoch4, step1374]: loss 0.038656
[epoch4, step1375]: loss 0.038551
[epoch4, step1376]: loss 0.035779
[epoch4, step1377]: loss 0.037227
[epoch4, step1378]: loss 0.038149
[epoch4, step1379]: loss 0.038930
[epoch4, step1380]: loss 0.036702
[epoch4, step1381]: loss 0.036239
[epoch4, step1382]: loss 0.039735
[epoch4, step1383]: loss 0.037729
[epoch4, step1384]: loss 0.037658
[epoch4, step1385]: loss 0.035283
[epoch4, step1386]: loss 0.038336
[epoch4, step1387]: loss 0.038516
[epoch4, step1388]: loss 0.038253
[epoch4, step1389]: loss 0.035664
[epoch4, step1390]: loss 0.036355
[epoch4, step1391]: loss 0.039187
[epoch4, step1392]: loss 0.037665
[epoch4, step1393]: loss 0.038071
[epoch4, step1394]: loss 0.036493
[epoch4, step1395]: loss 0.038223
[epoch4, step1396]: loss 0.037618
[epoch4, step1397]: loss 0.038919
[epoch4, step1398]: loss 0.036278
[epoch4, step1399]: loss 0.037013
[epoch4, step1400]: loss 0.039726
[epoch4, step1401]: loss 0.037658
[epoch4, step1402]: loss 0.037762
[epoch4, step1403]: loss 0.035054
[epoch4, step1404]: loss 0.037620
[epoch4, step1405]: loss 0.037907
[epoch4, step1406]: loss 0.038937
[epoch4, step1407]: loss 0.037335
[epoch4, step1408]: loss 0.035694
[epoch4, step1409]: loss 0.038817
[epoch4, step1410]: loss 0.037831
[epoch4, step1411]: loss 0.036648
[epoch4, step1412]: loss 0.036086
[epoch4, step1413]: loss 0.038066
[epoch4, step1414]: loss 0.037665
[epoch4, step1415]: loss 0.038921
[epoch4, step1416]: loss 0.036176
[epoch4, step1417]: loss 0.036210
[epoch4, step1418]: loss 0.039328
[epoch4, step1419]: loss 0.038492
[epoch4, step1420]: loss 0.038005
[epoch4, step1421]: loss 0.036214
[epoch4, step1422]: loss 0.038213
[epoch4, step1423]: loss 0.037513
[epoch4, step1424]: loss 0.039417
[epoch4, step1425]: loss 0.035364
[epoch4, step1426]: loss 0.036263
[epoch4, step1427]: loss 0.040042
[epoch4, step1428]: loss 0.038552
[epoch4, step1429]: loss 0.037722
[epoch4, step1430]: loss 0.035937
[epoch4, step1431]: loss 0.038120
[epoch4, step1432]: loss 0.037731
[epoch4, step1433]: loss 0.039394
[epoch4, step1434]: loss 0.035725
[epoch4, step1435]: loss 0.036666
[epoch4, step1436]: loss 0.039775
[epoch4, step1437]: loss 0.038010
[epoch4, step1438]: loss 0.038329
[epoch4, step1439]: loss 0.035750
[epoch4, step1440]: loss 0.037741
[epoch4, step1441]: loss 0.038567
[epoch4, step1442]: loss 0.038434
[epoch4, step1443]: loss 0.035954
[epoch4, step1444]: loss 0.035483
[epoch4, step1445]: loss 0.039766
[epoch4, step1446]: loss 0.037944
[epoch4, step1447]: loss 0.038429
[epoch4, step1448]: loss 0.035784
[epoch4, step1449]: loss 0.037372
[epoch4, step1450]: loss 0.037983
[epoch4, step1451]: loss 0.039444
[epoch4, step1452]: loss 0.035989
[epoch4, step1453]: loss 0.037316
[epoch4, step1454]: loss 0.039759
[epoch4, step1455]: loss 0.038414
[epoch4, step1456]: loss 0.037325
[epoch4, step1457]: loss 0.036392
[epoch4, step1458]: loss 0.038036
[epoch4, step1459]: loss 0.037809
[epoch4, step1460]: loss 0.039694
[epoch4, step1461]: loss 0.036914
[epoch4, step1462]: loss 0.036803
[epoch4, step1463]: loss 0.039215
[epoch4, step1464]: loss 0.038035
[epoch4, step1465]: loss 0.037247
[epoch4, step1466]: loss 0.035485
[epoch4, step1467]: loss 0.037852
[epoch4, step1468]: loss 0.037350
[epoch4, step1469]: loss 0.039176
[epoch4, step1470]: loss 0.036292
[epoch4, step1471]: loss 0.035892
[epoch4, step1472]: loss 0.039109
[epoch4, step1473]: loss 0.037658
[epoch4, step1474]: loss 0.038296
[epoch4, step1475]: loss 0.035459
[epoch4, step1476]: loss 0.038747
[epoch4, step1477]: loss 0.037542
[epoch4, step1478]: loss 0.039278
[epoch4, step1479]: loss 0.036177
[epoch4, step1480]: loss 0.036150
[epoch4, step1481]: loss 0.038293
[epoch4, step1482]: loss 0.037702
[epoch4, step1483]: loss 0.037856
[epoch4, step1484]: loss 0.036206
[epoch4, step1485]: loss 0.037627
[epoch4, step1486]: loss 0.036809
[epoch4, step1487]: loss 0.038949
[epoch4, step1488]: loss 0.036320
[epoch4, step1489]: loss 0.035967
[epoch4, step1490]: loss 0.039378
[epoch4, step1491]: loss 0.037724
[epoch4, step1492]: loss 0.037475
[epoch4, step1493]: loss 0.035812
[epoch4, step1494]: loss 0.038097
[epoch4, step1495]: loss 0.037504
[epoch4, step1496]: loss 0.038257
[epoch4, step1497]: loss 0.036536
[epoch4, step1498]: loss 0.036294
[epoch4, step1499]: loss 0.038716
[epoch4, step1500]: loss 0.037881
[epoch4, step1501]: loss 0.037744
[epoch4, step1502]: loss 0.035595
[epoch4, step1503]: loss 0.037853
[epoch4, step1504]: loss 0.037307
[epoch4, step1505]: loss 0.039368
[epoch4, step1506]: loss 0.035639
[epoch4, step1507]: loss 0.036566
[epoch4, step1508]: loss 0.039887
[epoch4, step1509]: loss 0.037439
[epoch4, step1510]: loss 0.036928
[epoch4, step1511]: loss 0.036446
[epoch4, step1512]: loss 0.037990
[epoch4, step1513]: loss 0.036479
[epoch4, step1514]: loss 0.039085
[epoch4, step1515]: loss 0.036672
[epoch4, step1516]: loss 0.036050

[epoch4]: avg loss 0.034559

[epoch5, step1]: loss 0.038241
[epoch5, step2]: loss 0.038832
[epoch5, step3]: loss 0.038804
[epoch5, step4]: loss 0.035811
[epoch5, step5]: loss 0.036429
[epoch5, step6]: loss 0.039227
[epoch5, step7]: loss 0.037003
[epoch5, step8]: loss 0.039412
[epoch5, step9]: loss 0.035377
[epoch5, step10]: loss 0.037415
[epoch5, step11]: loss 0.039206
[epoch5, step12]: loss 0.039100
[epoch5, step13]: loss 0.036306
[epoch5, step14]: loss 0.036444
[epoch5, step15]: loss 0.039143
[epoch5, step16]: loss 0.036874
[epoch5, step17]: loss 0.039609
[epoch5, step18]: loss 0.036630
[epoch5, step19]: loss 0.037033
[epoch5, step20]: loss 0.039981
[epoch5, step21]: loss 0.039019
[epoch5, step22]: loss 0.035813
[epoch5, step23]: loss 0.035512
[epoch5, step24]: loss 0.039217
[epoch5, step25]: loss 0.036199
[epoch5, step26]: loss 0.038727
[epoch5, step27]: loss 0.035299
[epoch5, step28]: loss 0.037007
[epoch5, step29]: loss 0.039175
[epoch5, step30]: loss 0.039715
[epoch5, step31]: loss 0.035613
[epoch5, step32]: loss 0.036774
[epoch5, step33]: loss 0.039827
[epoch5, step34]: loss 0.037468
[epoch5, step35]: loss 0.039665
[epoch5, step36]: loss 0.035652
[epoch5, step37]: loss 0.036937
[epoch5, step38]: loss 0.039018
[epoch5, step39]: loss 0.039001
[epoch5, step40]: loss 0.036469
[epoch5, step41]: loss 0.035737
[epoch5, step42]: loss 0.039526
[epoch5, step43]: loss 0.036661
[epoch5, step44]: loss 0.039676
[epoch5, step45]: loss 0.035798
[epoch5, step46]: loss 0.037021
[epoch5, step47]: loss 0.038720
[epoch5, step48]: loss 0.038776
[epoch5, step49]: loss 0.034543
[epoch5, step50]: loss 0.036337
[epoch5, step51]: loss 0.038935
[epoch5, step52]: loss 0.036547
[epoch5, step53]: loss 0.039891
[epoch5, step54]: loss 0.035569
[epoch5, step55]: loss 0.037224
[epoch5, step56]: loss 0.040008
[epoch5, step57]: loss 0.039541
[epoch5, step58]: loss 0.036100
[epoch5, step59]: loss 0.035320
[epoch5, step60]: loss 0.039718
[epoch5, step61]: loss 0.036040
[epoch5, step62]: loss 0.038764
[epoch5, step63]: loss 0.035106
[epoch5, step64]: loss 0.036392
[epoch5, step65]: loss 0.039290
[epoch5, step66]: loss 0.039080
[epoch5, step67]: loss 0.036322
[epoch5, step68]: loss 0.036319
[epoch5, step69]: loss 0.039167
[epoch5, step70]: loss 0.036508
[epoch5, step71]: loss 0.038959
[epoch5, step72]: loss 0.035893
[epoch5, step73]: loss 0.036669
[epoch5, step74]: loss 0.039176
[epoch5, step75]: loss 0.039203
[epoch5, step76]: loss 0.036715
[epoch5, step77]: loss 0.036838
[epoch5, step78]: loss 0.039375
[epoch5, step79]: loss 0.036089
[epoch5, step80]: loss 0.040095
[epoch5, step81]: loss 0.035899
[epoch5, step82]: loss 0.036343
[epoch5, step83]: loss 0.038364
[epoch5, step84]: loss 0.039363
[epoch5, step85]: loss 0.036705
[epoch5, step86]: loss 0.036493
[epoch5, step87]: loss 0.040288
[epoch5, step88]: loss 0.035628
[epoch5, step89]: loss 0.038916
[epoch5, step90]: loss 0.036277
[epoch5, step91]: loss 0.036257
[epoch5, step92]: loss 0.039291
[epoch5, step93]: loss 0.039073
[epoch5, step94]: loss 0.035923
[epoch5, step95]: loss 0.036753
[epoch5, step96]: loss 0.039072
[epoch5, step97]: loss 0.037282
[epoch5, step98]: loss 0.039363
[epoch5, step99]: loss 0.035938
[epoch5, step100]: loss 0.035738
[epoch5, step101]: loss 0.039756
[epoch5, step102]: loss 0.039012
[epoch5, step103]: loss 0.036085
[epoch5, step104]: loss 0.036293
[epoch5, step105]: loss 0.039365
[epoch5, step106]: loss 0.036713
[epoch5, step107]: loss 0.039158
[epoch5, step108]: loss 0.036208
[epoch5, step109]: loss 0.036347
[epoch5, step110]: loss 0.039737
[epoch5, step111]: loss 0.038916
[epoch5, step112]: loss 0.036259
[epoch5, step113]: loss 0.037108
[epoch5, step114]: loss 0.039003
[epoch5, step115]: loss 0.036733
[epoch5, step116]: loss 0.040236
[epoch5, step117]: loss 0.035802
[epoch5, step118]: loss 0.037489
[epoch5, step119]: loss 0.039770
[epoch5, step120]: loss 0.039206
[epoch5, step121]: loss 0.035998
[epoch5, step122]: loss 0.036139
[epoch5, step123]: loss 0.039566
[epoch5, step124]: loss 0.037025
[epoch5, step125]: loss 0.039614
[epoch5, step126]: loss 0.035871
[epoch5, step127]: loss 0.036544
[epoch5, step128]: loss 0.039039
[epoch5, step129]: loss 0.038853
[epoch5, step130]: loss 0.036271
[epoch5, step131]: loss 0.035658
[epoch5, step132]: loss 0.039352
[epoch5, step133]: loss 0.036498
[epoch5, step134]: loss 0.038851
[epoch5, step135]: loss 0.036354
[epoch5, step136]: loss 0.037855
[epoch5, step137]: loss 0.038948
[epoch5, step138]: loss 0.038881
[epoch5, step139]: loss 0.036087
[epoch5, step140]: loss 0.036575
[epoch5, step141]: loss 0.039459
[epoch5, step142]: loss 0.036522
[epoch5, step143]: loss 0.038635
[epoch5, step144]: loss 0.036255
[epoch5, step145]: loss 0.036726
[epoch5, step146]: loss 0.039275
[epoch5, step147]: loss 0.040471
[epoch5, step148]: loss 0.035876
[epoch5, step149]: loss 0.035789
[epoch5, step150]: loss 0.038858
[epoch5, step151]: loss 0.036871
[epoch5, step152]: loss 0.039476
[epoch5, step153]: loss 0.036056
[epoch5, step154]: loss 0.036315
[epoch5, step155]: loss 0.039406
[epoch5, step156]: loss 0.038589
[epoch5, step157]: loss 0.036445
[epoch5, step158]: loss 0.036399
[epoch5, step159]: loss 0.039425
[epoch5, step160]: loss 0.036861
[epoch5, step161]: loss 0.039640
[epoch5, step162]: loss 0.036213
[epoch5, step163]: loss 0.036456
[epoch5, step164]: loss 0.039459
[epoch5, step165]: loss 0.039094
[epoch5, step166]: loss 0.036552
[epoch5, step167]: loss 0.035868
[epoch5, step168]: loss 0.039742
[epoch5, step169]: loss 0.036491
[epoch5, step170]: loss 0.039719
[epoch5, step171]: loss 0.036301
[epoch5, step172]: loss 0.036848
[epoch5, step173]: loss 0.039564
[epoch5, step174]: loss 0.039084
[epoch5, step175]: loss 0.037074
[epoch5, step176]: loss 0.036436
[epoch5, step177]: loss 0.039650
[epoch5, step178]: loss 0.036684
[epoch5, step179]: loss 0.038430
[epoch5, step180]: loss 0.036252
[epoch5, step181]: loss 0.036833
[epoch5, step182]: loss 0.039549
[epoch5, step183]: loss 0.039851
[epoch5, step184]: loss 0.037180
[epoch5, step185]: loss 0.036613
[epoch5, step186]: loss 0.039447
[epoch5, step187]: loss 0.036882
[epoch5, step188]: loss 0.039150
[epoch5, step189]: loss 0.035986
[epoch5, step190]: loss 0.036137
[epoch5, step191]: loss 0.039059
[epoch5, step192]: loss 0.039725
[epoch5, step193]: loss 0.034454
[epoch5, step194]: loss 0.035420
[epoch5, step195]: loss 0.039614
[epoch5, step196]: loss 0.036722
[epoch5, step197]: loss 0.039071
[epoch5, step198]: loss 0.035098
[epoch5, step199]: loss 0.036692
[epoch5, step200]: loss 0.039655
[epoch5, step201]: loss 0.039653
[epoch5, step202]: loss 0.035797
[epoch5, step203]: loss 0.036404
[epoch5, step204]: loss 0.039736
[epoch5, step205]: loss 0.036121
[epoch5, step206]: loss 0.039053
[epoch5, step207]: loss 0.035903
[epoch5, step208]: loss 0.037087
[epoch5, step209]: loss 0.039393
[epoch5, step210]: loss 0.040140
[epoch5, step211]: loss 0.036904
[epoch5, step212]: loss 0.036856
[epoch5, step213]: loss 0.039171
[epoch5, step214]: loss 0.035917
[epoch5, step215]: loss 0.039649
[epoch5, step216]: loss 0.036287
[epoch5, step217]: loss 0.035777
[epoch5, step218]: loss 0.039713
[epoch5, step219]: loss 0.038901
[epoch5, step220]: loss 0.036588
[epoch5, step221]: loss 0.036499
[epoch5, step222]: loss 0.039452
[epoch5, step223]: loss 0.036790
[epoch5, step224]: loss 0.038770
[epoch5, step225]: loss 0.036100
[epoch5, step226]: loss 0.036451
[epoch5, step227]: loss 0.038287
[epoch5, step228]: loss 0.039849
[epoch5, step229]: loss 0.035388
[epoch5, step230]: loss 0.036769
[epoch5, step231]: loss 0.039788
[epoch5, step232]: loss 0.036337
[epoch5, step233]: loss 0.038840
[epoch5, step234]: loss 0.035554
[epoch5, step235]: loss 0.037182
[epoch5, step236]: loss 0.039677
[epoch5, step237]: loss 0.039205
[epoch5, step238]: loss 0.036268
[epoch5, step239]: loss 0.035806
[epoch5, step240]: loss 0.038694
[epoch5, step241]: loss 0.037108
[epoch5, step242]: loss 0.039078
[epoch5, step243]: loss 0.036629
[epoch5, step244]: loss 0.036418
[epoch5, step245]: loss 0.038943
[epoch5, step246]: loss 0.039080
[epoch5, step247]: loss 0.036595
[epoch5, step248]: loss 0.035862
[epoch5, step249]: loss 0.038758
[epoch5, step250]: loss 0.036985
[epoch5, step251]: loss 0.039573
[epoch5, step252]: loss 0.036893
[epoch5, step253]: loss 0.036548
[epoch5, step254]: loss 0.038673
[epoch5, step255]: loss 0.039622
[epoch5, step256]: loss 0.036537
[epoch5, step257]: loss 0.036039
[epoch5, step258]: loss 0.040171
[epoch5, step259]: loss 0.036887
[epoch5, step260]: loss 0.038610
[epoch5, step261]: loss 0.036948
[epoch5, step262]: loss 0.037098
[epoch5, step263]: loss 0.038558
[epoch5, step264]: loss 0.038992
[epoch5, step265]: loss 0.036731
[epoch5, step266]: loss 0.036230
[epoch5, step267]: loss 0.038664
[epoch5, step268]: loss 0.036959
[epoch5, step269]: loss 0.039495
[epoch5, step270]: loss 0.035633
[epoch5, step271]: loss 0.036934
[epoch5, step272]: loss 0.039247
[epoch5, step273]: loss 0.039063
[epoch5, step274]: loss 0.037101
[epoch5, step275]: loss 0.035704
[epoch5, step276]: loss 0.038993
[epoch5, step277]: loss 0.037124
[epoch5, step278]: loss 0.039248
[epoch5, step279]: loss 0.035733
[epoch5, step280]: loss 0.036466
[epoch5, step281]: loss 0.038929
[epoch5, step282]: loss 0.039517
[epoch5, step283]: loss 0.035760
[epoch5, step284]: loss 0.035705
[epoch5, step285]: loss 0.039909
[epoch5, step286]: loss 0.035902
[epoch5, step287]: loss 0.039332
[epoch5, step288]: loss 0.035741
[epoch5, step289]: loss 0.037632
[epoch5, step290]: loss 0.039273
[epoch5, step291]: loss 0.039660
[epoch5, step292]: loss 0.035820
[epoch5, step293]: loss 0.035810
[epoch5, step294]: loss 0.038660
[epoch5, step295]: loss 0.036146
[epoch5, step296]: loss 0.039736
[epoch5, step297]: loss 0.035803
[epoch5, step298]: loss 0.036846
[epoch5, step299]: loss 0.038257
[epoch5, step300]: loss 0.039269
[epoch5, step301]: loss 0.036224
[epoch5, step302]: loss 0.036518
[epoch5, step303]: loss 0.039606
[epoch5, step304]: loss 0.036241
[epoch5, step305]: loss 0.038718
[epoch5, step306]: loss 0.036226
[epoch5, step307]: loss 0.036146
[epoch5, step308]: loss 0.039786
[epoch5, step309]: loss 0.039625
[epoch5, step310]: loss 0.036385
[epoch5, step311]: loss 0.036884
[epoch5, step312]: loss 0.039037
[epoch5, step313]: loss 0.036928
[epoch5, step314]: loss 0.039270
[epoch5, step315]: loss 0.036965
[epoch5, step316]: loss 0.036497
[epoch5, step317]: loss 0.039714
[epoch5, step318]: loss 0.039167
[epoch5, step319]: loss 0.035795
[epoch5, step320]: loss 0.035127
[epoch5, step321]: loss 0.038812
[epoch5, step322]: loss 0.036376
[epoch5, step323]: loss 0.038471
[epoch5, step324]: loss 0.036785
[epoch5, step325]: loss 0.036745
[epoch5, step326]: loss 0.038928
[epoch5, step327]: loss 0.038490
[epoch5, step328]: loss 0.036372
[epoch5, step329]: loss 0.036028
[epoch5, step330]: loss 0.038659
[epoch5, step331]: loss 0.036894
[epoch5, step332]: loss 0.038833
[epoch5, step333]: loss 0.035922
[epoch5, step334]: loss 0.036721
[epoch5, step335]: loss 0.039382
[epoch5, step336]: loss 0.039937
[epoch5, step337]: loss 0.036540
[epoch5, step338]: loss 0.035728
[epoch5, step339]: loss 0.038962
[epoch5, step340]: loss 0.036997
[epoch5, step341]: loss 0.038617
[epoch5, step342]: loss 0.035775
[epoch5, step343]: loss 0.036787
[epoch5, step344]: loss 0.038633
[epoch5, step345]: loss 0.038493
[epoch5, step346]: loss 0.035751
[epoch5, step347]: loss 0.035920
[epoch5, step348]: loss 0.039444
[epoch5, step349]: loss 0.037015
[epoch5, step350]: loss 0.038692
[epoch5, step351]: loss 0.035255
[epoch5, step352]: loss 0.036460
[epoch5, step353]: loss 0.038902
[epoch5, step354]: loss 0.038219
[epoch5, step355]: loss 0.035190
[epoch5, step356]: loss 0.036878
[epoch5, step357]: loss 0.039346
[epoch5, step358]: loss 0.035043
[epoch5, step359]: loss 0.040083
[epoch5, step360]: loss 0.034815
[epoch5, step361]: loss 0.035974
[epoch5, step362]: loss 0.039736
[epoch5, step363]: loss 0.038755
[epoch5, step364]: loss 0.036012
[epoch5, step365]: loss 0.035857
[epoch5, step366]: loss 0.039487
[epoch5, step367]: loss 0.036509
[epoch5, step368]: loss 0.038467
[epoch5, step369]: loss 0.035858
[epoch5, step370]: loss 0.037130
[epoch5, step371]: loss 0.039900
[epoch5, step372]: loss 0.038766
[epoch5, step373]: loss 0.035541
[epoch5, step374]: loss 0.035558
[epoch5, step375]: loss 0.039793
[epoch5, step376]: loss 0.036418
[epoch5, step377]: loss 0.039365
[epoch5, step378]: loss 0.036330
[epoch5, step379]: loss 0.037179
[epoch5, step380]: loss 0.039626
[epoch5, step381]: loss 0.038754
[epoch5, step382]: loss 0.036493
[epoch5, step383]: loss 0.035152
[epoch5, step384]: loss 0.038402
[epoch5, step385]: loss 0.036373
[epoch5, step386]: loss 0.039221
[epoch5, step387]: loss 0.035975
[epoch5, step388]: loss 0.037342
[epoch5, step389]: loss 0.038987
[epoch5, step390]: loss 0.040043
[epoch5, step391]: loss 0.035697
[epoch5, step392]: loss 0.036782
[epoch5, step393]: loss 0.038709
[epoch5, step394]: loss 0.036476
[epoch5, step395]: loss 0.038933
[epoch5, step396]: loss 0.035998
[epoch5, step397]: loss 0.036209
[epoch5, step398]: loss 0.039233
[epoch5, step399]: loss 0.038990
[epoch5, step400]: loss 0.035847
[epoch5, step401]: loss 0.035914
[epoch5, step402]: loss 0.038975
[epoch5, step403]: loss 0.036311
[epoch5, step404]: loss 0.039405
[epoch5, step405]: loss 0.036157
[epoch5, step406]: loss 0.036815
[epoch5, step407]: loss 0.038848
[epoch5, step408]: loss 0.039189
[epoch5, step409]: loss 0.037387
[epoch5, step410]: loss 0.036827
[epoch5, step411]: loss 0.039123
[epoch5, step412]: loss 0.035871
[epoch5, step413]: loss 0.039263
[epoch5, step414]: loss 0.036169
[epoch5, step415]: loss 0.037776
[epoch5, step416]: loss 0.038871
[epoch5, step417]: loss 0.039392
[epoch5, step418]: loss 0.036463
[epoch5, step419]: loss 0.036472
[epoch5, step420]: loss 0.040169
[epoch5, step421]: loss 0.036431
[epoch5, step422]: loss 0.039546
[epoch5, step423]: loss 0.036503
[epoch5, step424]: loss 0.037071
[epoch5, step425]: loss 0.039932
[epoch5, step426]: loss 0.040252
[epoch5, step427]: loss 0.036796
[epoch5, step428]: loss 0.036502
[epoch5, step429]: loss 0.040485
[epoch5, step430]: loss 0.036672
[epoch5, step431]: loss 0.039999
[epoch5, step432]: loss 0.036299
[epoch5, step433]: loss 0.037820
[epoch5, step434]: loss 0.039598
[epoch5, step435]: loss 0.039891
[epoch5, step436]: loss 0.036153
[epoch5, step437]: loss 0.036593
[epoch5, step438]: loss 0.040147
[epoch5, step439]: loss 0.037040
[epoch5, step440]: loss 0.039392
[epoch5, step441]: loss 0.036481
[epoch5, step442]: loss 0.036852
[epoch5, step443]: loss 0.039911
[epoch5, step444]: loss 0.039191
[epoch5, step445]: loss 0.036750
[epoch5, step446]: loss 0.036814
[epoch5, step447]: loss 0.040232
[epoch5, step448]: loss 0.037017
[epoch5, step449]: loss 0.039465
[epoch5, step450]: loss 0.035422
[epoch5, step451]: loss 0.036687
[epoch5, step452]: loss 0.038486
[epoch5, step453]: loss 0.039396
[epoch5, step454]: loss 0.036420
[epoch5, step455]: loss 0.036459
[epoch5, step456]: loss 0.038344
[epoch5, step457]: loss 0.037275
[epoch5, step458]: loss 0.038861
[epoch5, step459]: loss 0.036686
[epoch5, step460]: loss 0.036703
[epoch5, step461]: loss 0.039993
[epoch5, step462]: loss 0.038535
[epoch5, step463]: loss 0.036383
[epoch5, step464]: loss 0.035958
[epoch5, step465]: loss 0.040571
[epoch5, step466]: loss 0.036476
[epoch5, step467]: loss 0.038732
[epoch5, step468]: loss 0.036055
[epoch5, step469]: loss 0.036656
[epoch5, step470]: loss 0.039641
[epoch5, step471]: loss 0.039190
[epoch5, step472]: loss 0.036693
[epoch5, step473]: loss 0.036086
[epoch5, step474]: loss 0.039796
[epoch5, step475]: loss 0.036876
[epoch5, step476]: loss 0.039515
[epoch5, step477]: loss 0.035994
[epoch5, step478]: loss 0.036036
[epoch5, step479]: loss 0.039031
[epoch5, step480]: loss 0.038153
[epoch5, step481]: loss 0.035604
[epoch5, step482]: loss 0.035528
[epoch5, step483]: loss 0.039557
[epoch5, step484]: loss 0.036753
[epoch5, step485]: loss 0.039130
[epoch5, step486]: loss 0.036533
[epoch5, step487]: loss 0.036092
[epoch5, step488]: loss 0.039598
[epoch5, step489]: loss 0.038562
[epoch5, step490]: loss 0.036594
[epoch5, step491]: loss 0.036473
[epoch5, step492]: loss 0.039289
[epoch5, step493]: loss 0.036228
[epoch5, step494]: loss 0.038671
[epoch5, step495]: loss 0.037564
[epoch5, step496]: loss 0.036524
[epoch5, step497]: loss 0.039215
[epoch5, step498]: loss 0.038777
[epoch5, step499]: loss 0.036418
[epoch5, step500]: loss 0.035571
[epoch5, step501]: loss 0.038579
[epoch5, step502]: loss 0.036240
[epoch5, step503]: loss 0.039129
[epoch5, step504]: loss 0.035760
[epoch5, step505]: loss 0.035627
[epoch5, step506]: loss 0.039749
[epoch5, step507]: loss 0.039593
[epoch5, step508]: loss 0.036603
[epoch5, step509]: loss 0.036226
[epoch5, step510]: loss 0.039414
[epoch5, step511]: loss 0.036870
[epoch5, step512]: loss 0.039534
[epoch5, step513]: loss 0.036122
[epoch5, step514]: loss 0.036959
[epoch5, step515]: loss 0.039115
[epoch5, step516]: loss 0.039586
[epoch5, step517]: loss 0.036242
[epoch5, step518]: loss 0.036208
[epoch5, step519]: loss 0.039196
[epoch5, step520]: loss 0.035924
[epoch5, step521]: loss 0.038772
[epoch5, step522]: loss 0.035450
[epoch5, step523]: loss 0.036575
[epoch5, step524]: loss 0.038337
[epoch5, step525]: loss 0.039459
[epoch5, step526]: loss 0.036243
[epoch5, step527]: loss 0.035910
[epoch5, step528]: loss 0.039428
[epoch5, step529]: loss 0.036001
[epoch5, step530]: loss 0.039528
[epoch5, step531]: loss 0.035735
[epoch5, step532]: loss 0.036270
[epoch5, step533]: loss 0.040088
[epoch5, step534]: loss 0.039058
[epoch5, step535]: loss 0.036691
[epoch5, step536]: loss 0.036288
[epoch5, step537]: loss 0.039330
[epoch5, step538]: loss 0.036492
[epoch5, step539]: loss 0.038967
[epoch5, step540]: loss 0.035599
[epoch5, step541]: loss 0.036049
[epoch5, step542]: loss 0.039195
[epoch5, step543]: loss 0.038656
[epoch5, step544]: loss 0.036090
[epoch5, step545]: loss 0.035207
[epoch5, step546]: loss 0.039686
[epoch5, step547]: loss 0.036170
[epoch5, step548]: loss 0.038858
[epoch5, step549]: loss 0.036333
[epoch5, step550]: loss 0.036595
[epoch5, step551]: loss 0.039002
[epoch5, step552]: loss 0.038530
[epoch5, step553]: loss 0.036578
[epoch5, step554]: loss 0.036025
[epoch5, step555]: loss 0.038836
[epoch5, step556]: loss 0.036331
[epoch5, step557]: loss 0.038712
[epoch5, step558]: loss 0.036195
[epoch5, step559]: loss 0.036031
[epoch5, step560]: loss 0.039375
[epoch5, step561]: loss 0.038769
[epoch5, step562]: loss 0.036183
[epoch5, step563]: loss 0.028934
[epoch5, step564]: loss 0.028658
[epoch5, step565]: loss 0.027868
[epoch5, step566]: loss 0.035409
[epoch5, step567]: loss 0.027279
[epoch5, step568]: loss 0.026387
[epoch5, step569]: loss 0.024145
[epoch5, step570]: loss 0.032322
[epoch5, step571]: loss 0.027825
[epoch5, step572]: loss 0.026283
[epoch5, step573]: loss 0.029444
[epoch5, step574]: loss 0.027592
[epoch5, step575]: loss 0.020947
[epoch5, step576]: loss 0.021837
[epoch5, step577]: loss 0.026123
[epoch5, step578]: loss 0.019250
[epoch5, step579]: loss 0.028036
[epoch5, step580]: loss 0.020344
[epoch5, step581]: loss 0.025538
[epoch5, step582]: loss 0.025045
[epoch5, step583]: loss 0.022287
[epoch5, step584]: loss 0.024045
[epoch5, step585]: loss 0.026920
[epoch5, step586]: loss 0.021911
[epoch5, step587]: loss 0.027975
[epoch5, step588]: loss 0.023478
[epoch5, step589]: loss 0.023442
[epoch5, step590]: loss 0.027748
[epoch5, step591]: loss 0.020651
[epoch5, step592]: loss 0.026159
[epoch5, step593]: loss 0.022294
[epoch5, step594]: loss 0.026200
[epoch5, step595]: loss 0.026815
[epoch5, step596]: loss 0.022507
[epoch5, step597]: loss 0.025170
[epoch5, step598]: loss 0.026407
[epoch5, step599]: loss 0.025277
[epoch5, step600]: loss 0.027109
[epoch5, step601]: loss 0.019440
[epoch5, step602]: loss 0.022549
[epoch5, step603]: loss 0.025560
[epoch5, step604]: loss 0.026630
[epoch5, step605]: loss 0.025481
[epoch5, step606]: loss 0.024788
[epoch5, step607]: loss 0.027482
[epoch5, step608]: loss 0.025533
[epoch5, step609]: loss 0.026901
[epoch5, step610]: loss 0.026413
[epoch5, step611]: loss 0.026427
[epoch5, step612]: loss 0.025252
[epoch5, step613]: loss 0.019561
[epoch5, step614]: loss 0.025235
[epoch5, step615]: loss 0.028049
[epoch5, step616]: loss 0.024057
[epoch5, step617]: loss 0.023668
[epoch5, step618]: loss 0.025816
[epoch5, step619]: loss 0.026956
[epoch5, step620]: loss 0.024328
[epoch5, step621]: loss 0.026246
[epoch5, step622]: loss 0.020800
[epoch5, step623]: loss 0.024680
[epoch5, step624]: loss 0.026313
[epoch5, step625]: loss 0.025941
[epoch5, step626]: loss 0.028289
[epoch5, step627]: loss 0.023073
[epoch5, step628]: loss 0.025393
[epoch5, step629]: loss 0.020844
[epoch5, step630]: loss 0.023481
[epoch5, step631]: loss 0.031299
[epoch5, step632]: loss 0.023348
[epoch5, step633]: loss 0.024531
[epoch5, step634]: loss 0.027177
[epoch5, step635]: loss 0.025785
[epoch5, step636]: loss 0.020941
[epoch5, step637]: loss 0.027275
[epoch5, step638]: loss 0.026977
[epoch5, step639]: loss 0.022880
[epoch5, step640]: loss 0.029427
[epoch5, step641]: loss 0.030373
[epoch5, step642]: loss 0.025040
[epoch5, step643]: loss 0.025727
[epoch5, step644]: loss 0.025987
[epoch5, step645]: loss 0.023601
[epoch5, step646]: loss 0.026408
[epoch5, step647]: loss 0.023673
[epoch5, step648]: loss 0.023138
[epoch5, step649]: loss 0.028386
[epoch5, step650]: loss 0.022293
[epoch5, step651]: loss 0.026125
[epoch5, step652]: loss 0.026783
[epoch5, step653]: loss 0.028016
[epoch5, step654]: loss 0.023124
[epoch5, step655]: loss 0.024012
[epoch5, step656]: loss 0.021623
[epoch5, step657]: loss 0.027667
[epoch5, step658]: loss 0.025144
[epoch5, step659]: loss 0.027470
[epoch5, step660]: loss 0.023987
[epoch5, step661]: loss 0.026640
[epoch5, step662]: loss 0.024043
[epoch5, step663]: loss 0.021135
[epoch5, step664]: loss 0.025098
[epoch5, step665]: loss 0.028261
[epoch5, step666]: loss 0.026907
[epoch5, step667]: loss 0.026588
[epoch5, step668]: loss 0.022385
[epoch5, step669]: loss 0.026373
[epoch5, step670]: loss 0.026944
[epoch5, step671]: loss 0.021332
[epoch5, step672]: loss 0.024021
[epoch5, step673]: loss 0.022201
[epoch5, step674]: loss 0.021420
[epoch5, step675]: loss 0.020290
[epoch5, step676]: loss 0.024530
[epoch5, step677]: loss 0.025343
[epoch5, step678]: loss 0.023268
[epoch5, step679]: loss 0.023927
[epoch5, step680]: loss 0.030448
[epoch5, step681]: loss 0.022075
[epoch5, step682]: loss 0.026224
[epoch5, step683]: loss 0.025761
[epoch5, step684]: loss 0.024921
[epoch5, step685]: loss 0.024319
[epoch5, step686]: loss 0.027301
[epoch5, step687]: loss 0.026787
[epoch5, step688]: loss 0.022711
[epoch5, step689]: loss 0.024491
[epoch5, step690]: loss 0.025307
[epoch5, step691]: loss 0.024284
[epoch5, step692]: loss 0.022519
[epoch5, step693]: loss 0.027641
[epoch5, step694]: loss 0.022819
[epoch5, step695]: loss 0.026440
[epoch5, step696]: loss 0.025943
[epoch5, step697]: loss 0.027162
[epoch5, step698]: loss 0.024831
[epoch5, step699]: loss 0.023474
[epoch5, step700]: loss 0.021734
[epoch5, step701]: loss 0.025899
[epoch5, step702]: loss 0.021701
[epoch5, step703]: loss 0.023065
[epoch5, step704]: loss 0.025507
[epoch5, step705]: loss 0.024985
[epoch5, step706]: loss 0.023728
[epoch5, step707]: loss 0.024570
[epoch5, step708]: loss 0.026051
[epoch5, step709]: loss 0.027521
[epoch5, step710]: loss 0.023873
[epoch5, step711]: loss 0.023801
[epoch5, step712]: loss 0.026947
[epoch5, step713]: loss 0.026296
[epoch5, step714]: loss 0.021336
[epoch5, step715]: loss 0.023064
[epoch5, step716]: loss 0.025864
[epoch5, step717]: loss 0.023592
[epoch5, step718]: loss 0.025016
[epoch5, step719]: loss 0.033070
[epoch5, step720]: loss 0.024848
[epoch5, step721]: loss 0.023063
[epoch5, step722]: loss 0.030755
[epoch5, step723]: loss 0.026134
[epoch5, step724]: loss 0.023060
[epoch5, step725]: loss 0.028044
[epoch5, step726]: loss 0.022226
[epoch5, step727]: loss 0.024679
[epoch5, step728]: loss 0.026305
[epoch5, step729]: loss 0.021315
[epoch5, step730]: loss 0.022668
[epoch5, step731]: loss 0.025942
[epoch5, step732]: loss 0.025829
[epoch5, step733]: loss 0.023879
[epoch5, step734]: loss 0.022775
[epoch5, step735]: loss 0.027272
[epoch5, step736]: loss 0.025002
[epoch5, step737]: loss 0.026628
[epoch5, step738]: loss 0.020669
[epoch5, step739]: loss 0.025453
[epoch5, step740]: loss 0.022385
[epoch5, step741]: loss 0.025143
[epoch5, step742]: loss 0.021803
[epoch5, step743]: loss 0.023160
[epoch5, step744]: loss 0.024021
[epoch5, step745]: loss 0.024520
[epoch5, step746]: loss 0.025287
[epoch5, step747]: loss 0.027349
[epoch5, step748]: loss 0.025957
[epoch5, step749]: loss 0.026453
[epoch5, step750]: loss 0.027694
[epoch5, step751]: loss 0.021741
[epoch5, step752]: loss 0.025247
[epoch5, step753]: loss 0.025608
[epoch5, step754]: loss 0.022787
[epoch5, step755]: loss 0.026135
[epoch5, step756]: loss 0.023481
[epoch5, step757]: loss 0.020627
[epoch5, step758]: loss 0.025175
[epoch5, step759]: loss 0.023092
[epoch5, step760]: loss 0.024081
[epoch5, step761]: loss 0.026406
[epoch5, step762]: loss 0.021548
[epoch5, step763]: loss 0.025484
[epoch5, step764]: loss 0.023787
[epoch5, step765]: loss 0.025906
[epoch5, step766]: loss 0.024767
[epoch5, step767]: loss 0.026572
[epoch5, step768]: loss 0.021410
[epoch5, step769]: loss 0.026790
[epoch5, step770]: loss 0.025866
[epoch5, step771]: loss 0.023408
[epoch5, step772]: loss 0.028923
[epoch5, step773]: loss 0.026622
[epoch5, step774]: loss 0.024111
[epoch5, step775]: loss 0.020817
[epoch5, step776]: loss 0.025655
[epoch5, step777]: loss 0.023104
[epoch5, step778]: loss 0.028135
[epoch5, step779]: loss 0.023763
[epoch5, step780]: loss 0.020144
[epoch5, step781]: loss 0.024601
[epoch5, step782]: loss 0.022826
[epoch5, step783]: loss 0.019434
[epoch5, step784]: loss 0.020382
[epoch5, step785]: loss 0.021394
[epoch5, step786]: loss 0.024291
[epoch5, step787]: loss 0.023380
[epoch5, step788]: loss 0.024887
[epoch5, step789]: loss 0.022576
[epoch5, step790]: loss 0.023131
[epoch5, step791]: loss 0.026813
[epoch5, step792]: loss 0.025025
[epoch5, step793]: loss 0.026883
[epoch5, step794]: loss 0.020335
[epoch5, step795]: loss 0.025652
[epoch5, step796]: loss 0.027791
[epoch5, step797]: loss 0.027819
[epoch5, step798]: loss 0.027001
[epoch5, step799]: loss 0.025719
[epoch5, step800]: loss 0.021518
[epoch5, step801]: loss 0.021959
[epoch5, step802]: loss 0.022978
[epoch5, step803]: loss 0.026383
[epoch5, step804]: loss 0.027326
[epoch5, step805]: loss 0.028418
[epoch5, step806]: loss 0.021464
[epoch5, step807]: loss 0.020598
[epoch5, step808]: loss 0.023051
[epoch5, step809]: loss 0.023077
[epoch5, step810]: loss 0.025864
[epoch5, step811]: loss 0.025793
[epoch5, step812]: loss 0.024835
[epoch5, step813]: loss 0.023824
[epoch5, step814]: loss 0.025066
[epoch5, step815]: loss 0.025088
[epoch5, step816]: loss 0.024171
[epoch5, step817]: loss 0.024764
[epoch5, step818]: loss 0.022557
[epoch5, step819]: loss 0.020299
[epoch5, step820]: loss 0.023729
[epoch5, step821]: loss 0.022004
[epoch5, step822]: loss 0.030536
[epoch5, step823]: loss 0.023918
[epoch5, step824]: loss 0.027008
[epoch5, step825]: loss 0.025377
[epoch5, step826]: loss 0.024442
[epoch5, step827]: loss 0.026966
[epoch5, step828]: loss 0.028718
[epoch5, step829]: loss 0.026584
[epoch5, step830]: loss 0.022499
[epoch5, step831]: loss 0.026268
[epoch5, step832]: loss 0.020903
[epoch5, step833]: loss 0.029086
[epoch5, step834]: loss 0.025458
[epoch5, step835]: loss 0.020526
[epoch5, step836]: loss 0.026985
[epoch5, step837]: loss 0.025537
[epoch5, step838]: loss 0.026135
[epoch5, step839]: loss 0.028442
[epoch5, step840]: loss 0.020633
[epoch5, step841]: loss 0.024286
[epoch5, step842]: loss 0.027582
[epoch5, step843]: loss 0.024994
[epoch5, step844]: loss 0.025145
[epoch5, step845]: loss 0.021161
[epoch5, step846]: loss 0.025472
[epoch5, step847]: loss 0.026886
[epoch5, step848]: loss 0.025059
[epoch5, step849]: loss 0.025093
[epoch5, step850]: loss 0.023118
[epoch5, step851]: loss 0.023968
[epoch5, step852]: loss 0.023094
[epoch5, step853]: loss 0.029224
[epoch5, step854]: loss 0.022698
[epoch5, step855]: loss 0.027257
[epoch5, step856]: loss 0.022163
[epoch5, step857]: loss 0.025802
[epoch5, step858]: loss 0.024299
[epoch5, step859]: loss 0.023650
[epoch5, step860]: loss 0.022626
[epoch5, step861]: loss 0.023246
[epoch5, step862]: loss 0.022961
[epoch5, step863]: loss 0.020698
[epoch5, step864]: loss 0.026458
[epoch5, step865]: loss 0.023394
[epoch5, step866]: loss 0.025229
[epoch5, step867]: loss 0.026040
[epoch5, step868]: loss 0.026804
[epoch5, step869]: loss 0.023908
[epoch5, step870]: loss 0.031009
[epoch5, step871]: loss 0.022061
[epoch5, step872]: loss 0.025451
[epoch5, step873]: loss 0.025822
[epoch5, step874]: loss 0.023700
[epoch5, step875]: loss 0.024163
[epoch5, step876]: loss 0.024260
[epoch5, step877]: loss 0.019047
[epoch5, step878]: loss 0.023368
[epoch5, step879]: loss 0.028001
[epoch5, step880]: loss 0.025557
[epoch5, step881]: loss 0.022191
[epoch5, step882]: loss 0.024182
[epoch5, step883]: loss 0.023805
[epoch5, step884]: loss 0.026498
[epoch5, step885]: loss 0.025975
[epoch5, step886]: loss 0.026462
[epoch5, step887]: loss 0.024158
[epoch5, step888]: loss 0.024652
[epoch5, step889]: loss 0.023616
[epoch5, step890]: loss 0.023414
[epoch5, step891]: loss 0.025499
[epoch5, step892]: loss 0.020987
[epoch5, step893]: loss 0.024642
[epoch5, step894]: loss 0.024813
[epoch5, step895]: loss 0.022610
[epoch5, step896]: loss 0.021926
[epoch5, step897]: loss 0.023893
[epoch5, step898]: loss 0.025518
[epoch5, step899]: loss 0.028083
[epoch5, step900]: loss 0.026998
[epoch5, step901]: loss 0.025484
[epoch5, step902]: loss 0.024014
[epoch5, step903]: loss 0.024083
[epoch5, step904]: loss 0.028091
[epoch5, step905]: loss 0.027651
[epoch5, step906]: loss 0.022485
[epoch5, step907]: loss 0.023578
[epoch5, step908]: loss 0.022619
[epoch5, step909]: loss 0.025432
[epoch5, step910]: loss 0.023184
[epoch5, step911]: loss 0.025208
[epoch5, step912]: loss 0.023790
[epoch5, step913]: loss 0.024107
[epoch5, step914]: loss 0.030551
[epoch5, step915]: loss 0.024028
[epoch5, step916]: loss 0.023758
[epoch5, step917]: loss 0.025148
[epoch5, step918]: loss 0.028527
[epoch5, step919]: loss 0.024114
[epoch5, step920]: loss 0.027541
[epoch5, step921]: loss 0.024505
[epoch5, step922]: loss 0.023159
[epoch5, step923]: loss 0.022605
[epoch5, step924]: loss 0.021287
[epoch5, step925]: loss 0.025379
[epoch5, step926]: loss 0.026604
[epoch5, step927]: loss 0.025762
[epoch5, step928]: loss 0.024995
[epoch5, step929]: loss 0.027584
[epoch5, step930]: loss 0.025808
[epoch5, step931]: loss 0.027286
[epoch5, step932]: loss 0.021632
[epoch5, step933]: loss 0.028303
[epoch5, step934]: loss 0.022062
[epoch5, step935]: loss 0.021985
[epoch5, step936]: loss 0.022420
[epoch5, step937]: loss 0.027178
[epoch5, step938]: loss 0.025264
[epoch5, step939]: loss 0.020725
[epoch5, step940]: loss 0.022933
[epoch5, step941]: loss 0.026787
[epoch5, step942]: loss 0.025489
[epoch5, step943]: loss 0.023258
[epoch5, step944]: loss 0.027627
[epoch5, step945]: loss 0.020473
[epoch5, step946]: loss 0.025489
[epoch5, step947]: loss 0.027765
[epoch5, step948]: loss 0.019397
[epoch5, step949]: loss 0.022890
[epoch5, step950]: loss 0.026563
[epoch5, step951]: loss 0.028701
[epoch5, step952]: loss 0.025125
[epoch5, step953]: loss 0.027534
[epoch5, step954]: loss 0.022131
[epoch5, step955]: loss 0.036454
[epoch5, step956]: loss 0.051853
[epoch5, step957]: loss 0.046638
[epoch5, step958]: loss 0.044346
[epoch5, step959]: loss 0.048691
[epoch5, step960]: loss 0.045204
[epoch5, step961]: loss 0.045902
[epoch5, step962]: loss 0.043774
[epoch5, step963]: loss 0.041663
[epoch5, step964]: loss 0.042162
[epoch5, step965]: loss 0.042160
[epoch5, step966]: loss 0.038738
[epoch5, step967]: loss 0.038860
[epoch5, step968]: loss 0.042249
[epoch5, step969]: loss 0.042271
[epoch5, step970]: loss 0.041886
[epoch5, step971]: loss 0.040666
[epoch5, step972]: loss 0.041726
[epoch5, step973]: loss 0.040054
[epoch5, step974]: loss 0.041801
[epoch5, step975]: loss 0.039007
[epoch5, step976]: loss 0.038250
[epoch5, step977]: loss 0.042261
[epoch5, step978]: loss 0.040182
[epoch5, step979]: loss 0.039047
[epoch5, step980]: loss 0.037965
[epoch5, step981]: loss 0.039486
[epoch5, step982]: loss 0.039826
[epoch5, step983]: loss 0.041270
[epoch5, step984]: loss 0.037527
[epoch5, step985]: loss 0.037840
[epoch5, step986]: loss 0.041501
[epoch5, step987]: loss 0.039763
[epoch5, step988]: loss 0.039551
[epoch5, step989]: loss 0.038864
[epoch5, step990]: loss 0.038765
[epoch5, step991]: loss 0.039817
[epoch5, step992]: loss 0.040536
[epoch5, step993]: loss 0.037799
[epoch5, step994]: loss 0.036831
[epoch5, step995]: loss 0.040675
[epoch5, step996]: loss 0.038714
[epoch5, step997]: loss 0.038957
[epoch5, step998]: loss 0.038529
[epoch5, step999]: loss 0.038789
[epoch5, step1000]: loss 0.039068
[epoch5, step1001]: loss 0.040484
[epoch5, step1002]: loss 0.037980
[epoch5, step1003]: loss 0.036805
[epoch5, step1004]: loss 0.040536
[epoch5, step1005]: loss 0.038182
[epoch5, step1006]: loss 0.038709
[epoch5, step1007]: loss 0.037112
[epoch5, step1008]: loss 0.038008
[epoch5, step1009]: loss 0.038643
[epoch5, step1010]: loss 0.040644
[epoch5, step1011]: loss 0.037428
[epoch5, step1012]: loss 0.037388
[epoch5, step1013]: loss 0.040291
[epoch5, step1014]: loss 0.039214
[epoch5, step1015]: loss 0.038787
[epoch5, step1016]: loss 0.037117
[epoch5, step1017]: loss 0.038058
[epoch5, step1018]: loss 0.038600
[epoch5, step1019]: loss 0.039999
[epoch5, step1020]: loss 0.036958
[epoch5, step1021]: loss 0.036589
[epoch5, step1022]: loss 0.039891
[epoch5, step1023]: loss 0.038433
[epoch5, step1024]: loss 0.038921
[epoch5, step1025]: loss 0.036787
[epoch5, step1026]: loss 0.037566
[epoch5, step1027]: loss 0.038083
[epoch5, step1028]: loss 0.039704
[epoch5, step1029]: loss 0.036875
[epoch5, step1030]: loss 0.036210
[epoch5, step1031]: loss 0.038653
[epoch5, step1032]: loss 0.038706
[epoch5, step1033]: loss 0.037856
[epoch5, step1034]: loss 0.036763
[epoch5, step1035]: loss 0.037438
[epoch5, step1036]: loss 0.038326
[epoch5, step1037]: loss 0.039277
[epoch5, step1038]: loss 0.036716
[epoch5, step1039]: loss 0.036659
[epoch5, step1040]: loss 0.038962
[epoch5, step1041]: loss 0.037902
[epoch5, step1042]: loss 0.036835
[epoch5, step1043]: loss 0.036424
[epoch5, step1044]: loss 0.037682
[epoch5, step1045]: loss 0.038049
[epoch5, step1046]: loss 0.039315
[epoch5, step1047]: loss 0.036272
[epoch5, step1048]: loss 0.035651
[epoch5, step1049]: loss 0.039132
[epoch5, step1050]: loss 0.038095
[epoch5, step1051]: loss 0.037504
[epoch5, step1052]: loss 0.036373
[epoch5, step1053]: loss 0.037984
[epoch5, step1054]: loss 0.037627
[epoch5, step1055]: loss 0.038231
[epoch5, step1056]: loss 0.035427
[epoch5, step1057]: loss 0.036566
[epoch5, step1058]: loss 0.039988
[epoch5, step1059]: loss 0.037805
[epoch5, step1060]: loss 0.037539
[epoch5, step1061]: loss 0.035253
[epoch5, step1062]: loss 0.037923
[epoch5, step1063]: loss 0.037476
[epoch5, step1064]: loss 0.038756
[epoch5, step1065]: loss 0.035914
[epoch5, step1066]: loss 0.035567
[epoch5, step1067]: loss 0.039041
[epoch5, step1068]: loss 0.036300
[epoch5, step1069]: loss 0.036815
[epoch5, step1070]: loss 0.035647
[epoch5, step1071]: loss 0.038052
[epoch5, step1072]: loss 0.038238
[epoch5, step1073]: loss 0.038587
[epoch5, step1074]: loss 0.036197
[epoch5, step1075]: loss 0.036153
[epoch5, step1076]: loss 0.039172
[epoch5, step1077]: loss 0.037458
[epoch5, step1078]: loss 0.037150
[epoch5, step1079]: loss 0.036799
[epoch5, step1080]: loss 0.037716
[epoch5, step1081]: loss 0.037385
[epoch5, step1082]: loss 0.038465
[epoch5, step1083]: loss 0.036689
[epoch5, step1084]: loss 0.035999
[epoch5, step1085]: loss 0.038487
[epoch5, step1086]: loss 0.037191
[epoch5, step1087]: loss 0.037288
[epoch5, step1088]: loss 0.035634
[epoch5, step1089]: loss 0.037809
[epoch5, step1090]: loss 0.038137
[epoch5, step1091]: loss 0.038924
[epoch5, step1092]: loss 0.035751
[epoch5, step1093]: loss 0.035821
[epoch5, step1094]: loss 0.038018
[epoch5, step1095]: loss 0.037171
[epoch5, step1096]: loss 0.036764
[epoch5, step1097]: loss 0.035875
[epoch5, step1098]: loss 0.037442
[epoch5, step1099]: loss 0.037170
[epoch5, step1100]: loss 0.039266
[epoch5, step1101]: loss 0.036274
[epoch5, step1102]: loss 0.035759
[epoch5, step1103]: loss 0.038437
[epoch5, step1104]: loss 0.037544
[epoch5, step1105]: loss 0.037502
[epoch5, step1106]: loss 0.034811
[epoch5, step1107]: loss 0.037751
[epoch5, step1108]: loss 0.037142
[epoch5, step1109]: loss 0.039068
[epoch5, step1110]: loss 0.036742
[epoch5, step1111]: loss 0.036111
[epoch5, step1112]: loss 0.039461
[epoch5, step1113]: loss 0.037069
[epoch5, step1114]: loss 0.037666
[epoch5, step1115]: loss 0.035969
[epoch5, step1116]: loss 0.037662
[epoch5, step1117]: loss 0.037729
[epoch5, step1118]: loss 0.038434
[epoch5, step1119]: loss 0.035851
[epoch5, step1120]: loss 0.035589
[epoch5, step1121]: loss 0.038793
[epoch5, step1122]: loss 0.036993
[epoch5, step1123]: loss 0.036390
[epoch5, step1124]: loss 0.036672
[epoch5, step1125]: loss 0.037876
[epoch5, step1126]: loss 0.038534
[epoch5, step1127]: loss 0.038870
[epoch5, step1128]: loss 0.036119
[epoch5, step1129]: loss 0.035760
[epoch5, step1130]: loss 0.039794
[epoch5, step1131]: loss 0.037928
[epoch5, step1132]: loss 0.037735
[epoch5, step1133]: loss 0.035330
[epoch5, step1134]: loss 0.037392
[epoch5, step1135]: loss 0.038520
[epoch5, step1136]: loss 0.039453
[epoch5, step1137]: loss 0.036240
[epoch5, step1138]: loss 0.035922
[epoch5, step1139]: loss 0.038911
[epoch5, step1140]: loss 0.036839
[epoch5, step1141]: loss 0.036840
[epoch5, step1142]: loss 0.035600
[epoch5, step1143]: loss 0.036974
[epoch5, step1144]: loss 0.037772
[epoch5, step1145]: loss 0.038208
[epoch5, step1146]: loss 0.035655
[epoch5, step1147]: loss 0.036681
[epoch5, step1148]: loss 0.039006
[epoch5, step1149]: loss 0.037263
[epoch5, step1150]: loss 0.037129
[epoch5, step1151]: loss 0.036165
[epoch5, step1152]: loss 0.038124
[epoch5, step1153]: loss 0.036960
[epoch5, step1154]: loss 0.039099
[epoch5, step1155]: loss 0.036209
[epoch5, step1156]: loss 0.035256
[epoch5, step1157]: loss 0.038882
[epoch5, step1158]: loss 0.037610
[epoch5, step1159]: loss 0.037514
[epoch5, step1160]: loss 0.036703
[epoch5, step1161]: loss 0.038037
[epoch5, step1162]: loss 0.037695
[epoch5, step1163]: loss 0.037877
[epoch5, step1164]: loss 0.035995
[epoch5, step1165]: loss 0.036799
[epoch5, step1166]: loss 0.039021
[epoch5, step1167]: loss 0.036680
[epoch5, step1168]: loss 0.037251
[epoch5, step1169]: loss 0.035743
[epoch5, step1170]: loss 0.037565
[epoch5, step1171]: loss 0.037694
[epoch5, step1172]: loss 0.038715
[epoch5, step1173]: loss 0.036081
[epoch5, step1174]: loss 0.036354
[epoch5, step1175]: loss 0.038921
[epoch5, step1176]: loss 0.037193
[epoch5, step1177]: loss 0.037514
[epoch5, step1178]: loss 0.035928
[epoch5, step1179]: loss 0.037411
[epoch5, step1180]: loss 0.037699
[epoch5, step1181]: loss 0.039294
[epoch5, step1182]: loss 0.035375
[epoch5, step1183]: loss 0.036403
[epoch5, step1184]: loss 0.038539
[epoch5, step1185]: loss 0.037604
[epoch5, step1186]: loss 0.036462
[epoch5, step1187]: loss 0.034929
[epoch5, step1188]: loss 0.036914
[epoch5, step1189]: loss 0.037245
[epoch5, step1190]: loss 0.038226
[epoch5, step1191]: loss 0.036663
[epoch5, step1192]: loss 0.035941
[epoch5, step1193]: loss 0.038944
[epoch5, step1194]: loss 0.037214
[epoch5, step1195]: loss 0.036089
[epoch5, step1196]: loss 0.035067
[epoch5, step1197]: loss 0.037828
[epoch5, step1198]: loss 0.037571
[epoch5, step1199]: loss 0.038356
[epoch5, step1200]: loss 0.035700
[epoch5, step1201]: loss 0.036429
[epoch5, step1202]: loss 0.039861
[epoch5, step1203]: loss 0.037477
[epoch5, step1204]: loss 0.036580
[epoch5, step1205]: loss 0.035260
[epoch5, step1206]: loss 0.037001
[epoch5, step1207]: loss 0.037801
[epoch5, step1208]: loss 0.038991
[epoch5, step1209]: loss 0.034872
[epoch5, step1210]: loss 0.036391
[epoch5, step1211]: loss 0.038623
[epoch5, step1212]: loss 0.037163
[epoch5, step1213]: loss 0.036777
[epoch5, step1214]: loss 0.035901
[epoch5, step1215]: loss 0.038164
[epoch5, step1216]: loss 0.037047
[epoch5, step1217]: loss 0.039291
[epoch5, step1218]: loss 0.035597
[epoch5, step1219]: loss 0.036533
[epoch5, step1220]: loss 0.039365
[epoch5, step1221]: loss 0.036547
[epoch5, step1222]: loss 0.037346
[epoch5, step1223]: loss 0.035718
[epoch5, step1224]: loss 0.038015
[epoch5, step1225]: loss 0.037649
[epoch5, step1226]: loss 0.038365
[epoch5, step1227]: loss 0.036017
[epoch5, step1228]: loss 0.035573
[epoch5, step1229]: loss 0.038689
[epoch5, step1230]: loss 0.037613
[epoch5, step1231]: loss 0.037165
[epoch5, step1232]: loss 0.036726
[epoch5, step1233]: loss 0.037381
[epoch5, step1234]: loss 0.037240
[epoch5, step1235]: loss 0.039117
[epoch5, step1236]: loss 0.036186
[epoch5, step1237]: loss 0.035476
[epoch5, step1238]: loss 0.038452
[epoch5, step1239]: loss 0.037981
[epoch5, step1240]: loss 0.037508
[epoch5, step1241]: loss 0.035364
[epoch5, step1242]: loss 0.037522
[epoch5, step1243]: loss 0.037361
[epoch5, step1244]: loss 0.038896
[epoch5, step1245]: loss 0.036355
[epoch5, step1246]: loss 0.036178
[epoch5, step1247]: loss 0.038084
[epoch5, step1248]: loss 0.037425
[epoch5, step1249]: loss 0.037794
[epoch5, step1250]: loss 0.035612
[epoch5, step1251]: loss 0.037896
[epoch5, step1252]: loss 0.038426
[epoch5, step1253]: loss 0.038949
[epoch5, step1254]: loss 0.036118
[epoch5, step1255]: loss 0.036060
[epoch5, step1256]: loss 0.039425
[epoch5, step1257]: loss 0.037657
[epoch5, step1258]: loss 0.037492
[epoch5, step1259]: loss 0.035664
[epoch5, step1260]: loss 0.037681
[epoch5, step1261]: loss 0.037389
[epoch5, step1262]: loss 0.037611
[epoch5, step1263]: loss 0.036569
[epoch5, step1264]: loss 0.035792
[epoch5, step1265]: loss 0.037882
[epoch5, step1266]: loss 0.037378
[epoch5, step1267]: loss 0.037528
[epoch5, step1268]: loss 0.035979
[epoch5, step1269]: loss 0.037703
[epoch5, step1270]: loss 0.036867
[epoch5, step1271]: loss 0.039091
[epoch5, step1272]: loss 0.036126
[epoch5, step1273]: loss 0.035662
[epoch5, step1274]: loss 0.038943
[epoch5, step1275]: loss 0.037765
[epoch5, step1276]: loss 0.037138
[epoch5, step1277]: loss 0.035791
[epoch5, step1278]: loss 0.038250
[epoch5, step1279]: loss 0.037895
[epoch5, step1280]: loss 0.038896
[epoch5, step1281]: loss 0.035894
[epoch5, step1282]: loss 0.035986
[epoch5, step1283]: loss 0.038357
[epoch5, step1284]: loss 0.036907
[epoch5, step1285]: loss 0.037702
[epoch5, step1286]: loss 0.035197
[epoch5, step1287]: loss 0.038301
[epoch5, step1288]: loss 0.038305
[epoch5, step1289]: loss 0.039576
[epoch5, step1290]: loss 0.036090
[epoch5, step1291]: loss 0.035583
[epoch5, step1292]: loss 0.039730
[epoch5, step1293]: loss 0.036692
[epoch5, step1294]: loss 0.037312
[epoch5, step1295]: loss 0.036295
[epoch5, step1296]: loss 0.037796
[epoch5, step1297]: loss 0.037481
[epoch5, step1298]: loss 0.039301
[epoch5, step1299]: loss 0.036299
[epoch5, step1300]: loss 0.036712
[epoch5, step1301]: loss 0.038039
[epoch5, step1302]: loss 0.037385
[epoch5, step1303]: loss 0.037437
[epoch5, step1304]: loss 0.035151
[epoch5, step1305]: loss 0.038155
[epoch5, step1306]: loss 0.037650
[epoch5, step1307]: loss 0.038286
[epoch5, step1308]: loss 0.036119
[epoch5, step1309]: loss 0.035407
[epoch5, step1310]: loss 0.039005
[epoch5, step1311]: loss 0.036413
[epoch5, step1312]: loss 0.038008
[epoch5, step1313]: loss 0.035911
[epoch5, step1314]: loss 0.037556
[epoch5, step1315]: loss 0.037357
[epoch5, step1316]: loss 0.040008
[epoch5, step1317]: loss 0.035572
[epoch5, step1318]: loss 0.035372
[epoch5, step1319]: loss 0.038297
[epoch5, step1320]: loss 0.037605
[epoch5, step1321]: loss 0.037631
[epoch5, step1322]: loss 0.035467
[epoch5, step1323]: loss 0.037948
[epoch5, step1324]: loss 0.037168
[epoch5, step1325]: loss 0.038632
[epoch5, step1326]: loss 0.035766
[epoch5, step1327]: loss 0.035839
[epoch5, step1328]: loss 0.038948
[epoch5, step1329]: loss 0.037311
[epoch5, step1330]: loss 0.037497
[epoch5, step1331]: loss 0.035475
[epoch5, step1332]: loss 0.037550
[epoch5, step1333]: loss 0.036677
[epoch5, step1334]: loss 0.039159
[epoch5, step1335]: loss 0.036713
[epoch5, step1336]: loss 0.035892
[epoch5, step1337]: loss 0.038451
[epoch5, step1338]: loss 0.037273
[epoch5, step1339]: loss 0.037459
[epoch5, step1340]: loss 0.035618
[epoch5, step1341]: loss 0.037951
[epoch5, step1342]: loss 0.037458
[epoch5, step1343]: loss 0.038785
[epoch5, step1344]: loss 0.036114
[epoch5, step1345]: loss 0.035915
[epoch5, step1346]: loss 0.038404
[epoch5, step1347]: loss 0.038046
[epoch5, step1348]: loss 0.036481
[epoch5, step1349]: loss 0.035994
[epoch5, step1350]: loss 0.037792
[epoch5, step1351]: loss 0.037011
[epoch5, step1352]: loss 0.038307
[epoch5, step1353]: loss 0.035826
[epoch5, step1354]: loss 0.035709
[epoch5, step1355]: loss 0.039180
[epoch5, step1356]: loss 0.037067
[epoch5, step1357]: loss 0.036859
[epoch5, step1358]: loss 0.035700
[epoch5, step1359]: loss 0.037126
[epoch5, step1360]: loss 0.037766
[epoch5, step1361]: loss 0.038852
[epoch5, step1362]: loss 0.036566
[epoch5, step1363]: loss 0.036292
[epoch5, step1364]: loss 0.038621
[epoch5, step1365]: loss 0.037449
[epoch5, step1366]: loss 0.036885
[epoch5, step1367]: loss 0.035129
[epoch5, step1368]: loss 0.038544
[epoch5, step1369]: loss 0.037729
[epoch5, step1370]: loss 0.038606
[epoch5, step1371]: loss 0.036317
[epoch5, step1372]: loss 0.035889
[epoch5, step1373]: loss 0.039154
[epoch5, step1374]: loss 0.038149
[epoch5, step1375]: loss 0.038097
[epoch5, step1376]: loss 0.035793
[epoch5, step1377]: loss 0.036841
[epoch5, step1378]: loss 0.037636
[epoch5, step1379]: loss 0.038161
[epoch5, step1380]: loss 0.036314
[epoch5, step1381]: loss 0.035693
[epoch5, step1382]: loss 0.038995
[epoch5, step1383]: loss 0.037129
[epoch5, step1384]: loss 0.036870
[epoch5, step1385]: loss 0.035215
[epoch5, step1386]: loss 0.037669
[epoch5, step1387]: loss 0.038167
[epoch5, step1388]: loss 0.037814
[epoch5, step1389]: loss 0.035252
[epoch5, step1390]: loss 0.036313
[epoch5, step1391]: loss 0.038644
[epoch5, step1392]: loss 0.037359
[epoch5, step1393]: loss 0.037497
[epoch5, step1394]: loss 0.036353
[epoch5, step1395]: loss 0.037805
[epoch5, step1396]: loss 0.037209
[epoch5, step1397]: loss 0.038363
[epoch5, step1398]: loss 0.035949
[epoch5, step1399]: loss 0.036663
[epoch5, step1400]: loss 0.039232
[epoch5, step1401]: loss 0.037091
[epoch5, step1402]: loss 0.037292
[epoch5, step1403]: loss 0.034740
[epoch5, step1404]: loss 0.037070
[epoch5, step1405]: loss 0.037324
[epoch5, step1406]: loss 0.038520
[epoch5, step1407]: loss 0.036913
[epoch5, step1408]: loss 0.035378
[epoch5, step1409]: loss 0.038460
[epoch5, step1410]: loss 0.037294
[epoch5, step1411]: loss 0.036228
[epoch5, step1412]: loss 0.035771
[epoch5, step1413]: loss 0.037706
[epoch5, step1414]: loss 0.037119
[epoch5, step1415]: loss 0.038382
[epoch5, step1416]: loss 0.035868
[epoch5, step1417]: loss 0.035781
[epoch5, step1418]: loss 0.038820
[epoch5, step1419]: loss 0.038001
[epoch5, step1420]: loss 0.037459
[epoch5, step1421]: loss 0.036084
[epoch5, step1422]: loss 0.037829
[epoch5, step1423]: loss 0.037019
[epoch5, step1424]: loss 0.038831
[epoch5, step1425]: loss 0.035017
[epoch5, step1426]: loss 0.035915
[epoch5, step1427]: loss 0.039708
[epoch5, step1428]: loss 0.038111
[epoch5, step1429]: loss 0.037157
[epoch5, step1430]: loss 0.035640
[epoch5, step1431]: loss 0.037706
[epoch5, step1432]: loss 0.037221
[epoch5, step1433]: loss 0.038817
[epoch5, step1434]: loss 0.035483
[epoch5, step1435]: loss 0.036348
[epoch5, step1436]: loss 0.039211
[epoch5, step1437]: loss 0.037550
[epoch5, step1438]: loss 0.037992
[epoch5, step1439]: loss 0.035548
[epoch5, step1440]: loss 0.037442
[epoch5, step1441]: loss 0.038152
[epoch5, step1442]: loss 0.037892
[epoch5, step1443]: loss 0.035688
[epoch5, step1444]: loss 0.035100
[epoch5, step1445]: loss 0.039122
[epoch5, step1446]: loss 0.037484
[epoch5, step1447]: loss 0.037926
[epoch5, step1448]: loss 0.035632
[epoch5, step1449]: loss 0.037022
[epoch5, step1450]: loss 0.037487
[epoch5, step1451]: loss 0.038962
[epoch5, step1452]: loss 0.035669
[epoch5, step1453]: loss 0.036991
[epoch5, step1454]: loss 0.039302
[epoch5, step1455]: loss 0.037940
[epoch5, step1456]: loss 0.036887
[epoch5, step1457]: loss 0.036223
[epoch5, step1458]: loss 0.037788
[epoch5, step1459]: loss 0.037541
[epoch5, step1460]: loss 0.039121
[epoch5, step1461]: loss 0.036664
[epoch5, step1462]: loss 0.036448
[epoch5, step1463]: loss 0.038779
[epoch5, step1464]: loss 0.037631
[epoch5, step1465]: loss 0.036840
[epoch5, step1466]: loss 0.035320
[epoch5, step1467]: loss 0.037539
[epoch5, step1468]: loss 0.036984
[epoch5, step1469]: loss 0.038617
[epoch5, step1470]: loss 0.036074
[epoch5, step1471]: loss 0.035641
[epoch5, step1472]: loss 0.038686
[epoch5, step1473]: loss 0.037286
[epoch5, step1474]: loss 0.037862
[epoch5, step1475]: loss 0.035413
[epoch5, step1476]: loss 0.038420
[epoch5, step1477]: loss 0.037216
[epoch5, step1478]: loss 0.038708
[epoch5, step1479]: loss 0.035901
[epoch5, step1480]: loss 0.035796
[epoch5, step1481]: loss 0.037925
[epoch5, step1482]: loss 0.037268
[epoch5, step1483]: loss 0.037235
[epoch5, step1484]: loss 0.036024
[epoch5, step1485]: loss 0.037346
[epoch5, step1486]: loss 0.036409
[epoch5, step1487]: loss 0.038498
[epoch5, step1488]: loss 0.035945
[epoch5, step1489]: loss 0.035786
[epoch5, step1490]: loss 0.038843
[epoch5, step1491]: loss 0.037405
[epoch5, step1492]: loss 0.037025
[epoch5, step1493]: loss 0.035670
[epoch5, step1494]: loss 0.037724
[epoch5, step1495]: loss 0.037230
[epoch5, step1496]: loss 0.037851
[epoch5, step1497]: loss 0.036240
[epoch5, step1498]: loss 0.036201
[epoch5, step1499]: loss 0.038322
[epoch5, step1500]: loss 0.037548
[epoch5, step1501]: loss 0.037388
[epoch5, step1502]: loss 0.035618
[epoch5, step1503]: loss 0.037528
[epoch5, step1504]: loss 0.037049
[epoch5, step1505]: loss 0.038811
[epoch5, step1506]: loss 0.035333
[epoch5, step1507]: loss 0.036129
[epoch5, step1508]: loss 0.039275
[epoch5, step1509]: loss 0.037093
[epoch5, step1510]: loss 0.036656
[epoch5, step1511]: loss 0.036412
[epoch5, step1512]: loss 0.037866
[epoch5, step1513]: loss 0.036171
[epoch5, step1514]: loss 0.038690
[epoch5, step1515]: loss 0.036329
[epoch5, step1516]: loss 0.035966

[epoch5]: avg loss 0.034316

[epoch6, step1]: loss 0.026554
[epoch6, step2]: loss 0.038373
[epoch6, step3]: loss 0.038462
[epoch6, step4]: loss 0.035929
[epoch6, step5]: loss 0.036106
[epoch6, step6]: loss 0.038817
[epoch6, step7]: loss 0.036523
[epoch6, step8]: loss 0.038763
[epoch6, step9]: loss 0.035289
[epoch6, step10]: loss 0.037044
[epoch6, step11]: loss 0.038632
[epoch6, step12]: loss 0.038570
[epoch6, step13]: loss 0.035907
[epoch6, step14]: loss 0.036325
[epoch6, step15]: loss 0.038716
[epoch6, step16]: loss 0.036643
[epoch6, step17]: loss 0.039225
[epoch6, step18]: loss 0.036477
[epoch6, step19]: loss 0.036665
[epoch6, step20]: loss 0.039553
[epoch6, step21]: loss 0.038575
[epoch6, step22]: loss 0.035666
[epoch6, step23]: loss 0.035205
[epoch6, step24]: loss 0.038983
[epoch6, step25]: loss 0.035934
[epoch6, step26]: loss 0.038266
[epoch6, step27]: loss 0.035129
[epoch6, step28]: loss 0.036742
[epoch6, step29]: loss 0.038780
[epoch6, step30]: loss 0.039266
[epoch6, step31]: loss 0.035353
[epoch6, step32]: loss 0.036653
[epoch6, step33]: loss 0.039418
[epoch6, step34]: loss 0.037213
[epoch6, step35]: loss 0.039277
[epoch6, step36]: loss 0.035492
[epoch6, step37]: loss 0.036622
[epoch6, step38]: loss 0.038832
[epoch6, step39]: loss 0.038766
[epoch6, step40]: loss 0.036199
[epoch6, step41]: loss 0.035435
[epoch6, step42]: loss 0.039101
[epoch6, step43]: loss 0.036280
[epoch6, step44]: loss 0.039258
[epoch6, step45]: loss 0.035800
[epoch6, step46]: loss 0.036750
[epoch6, step47]: loss 0.038304
[epoch6, step48]: loss 0.038369
[epoch6, step49]: loss 0.034226
[epoch6, step50]: loss 0.036194
[epoch6, step51]: loss 0.038629
[epoch6, step52]: loss 0.036211
[epoch6, step53]: loss 0.039353
[epoch6, step54]: loss 0.035388
[epoch6, step55]: loss 0.037118
[epoch6, step56]: loss 0.039651
[epoch6, step57]: loss 0.039152
[epoch6, step58]: loss 0.035837
[epoch6, step59]: loss 0.035097
[epoch6, step60]: loss 0.039342
[epoch6, step61]: loss 0.035604
[epoch6, step62]: loss 0.038307
[epoch6, step63]: loss 0.035101
[epoch6, step64]: loss 0.036130
[epoch6, step65]: loss 0.038938
[epoch6, step66]: loss 0.038619
[epoch6, step67]: loss 0.035955
[epoch6, step68]: loss 0.035998
[epoch6, step69]: loss 0.038686
[epoch6, step70]: loss 0.036217
[epoch6, step71]: loss 0.038477
[epoch6, step72]: loss 0.035655
[epoch6, step73]: loss 0.036578
[epoch6, step74]: loss 0.038617
[epoch6, step75]: loss 0.039100
[epoch6, step76]: loss 0.036385
[epoch6, step77]: loss 0.036691
[epoch6, step78]: loss 0.039133
[epoch6, step79]: loss 0.035685
[epoch6, step80]: loss 0.039657
[epoch6, step81]: loss 0.035777
[epoch6, step82]: loss 0.036062
[epoch6, step83]: loss 0.038422
[epoch6, step84]: loss 0.038730
[epoch6, step85]: loss 0.036609
[epoch6, step86]: loss 0.036355
[epoch6, step87]: loss 0.039737
[epoch6, step88]: loss 0.035259
[epoch6, step89]: loss 0.038520
[epoch6, step90]: loss 0.036188
[epoch6, step91]: loss 0.035955
[epoch6, step92]: loss 0.038894
[epoch6, step93]: loss 0.038773
[epoch6, step94]: loss 0.035592
[epoch6, step95]: loss 0.036606
[epoch6, step96]: loss 0.038559
[epoch6, step97]: loss 0.037008
[epoch6, step98]: loss 0.038919
[epoch6, step99]: loss 0.035731
[epoch6, step100]: loss 0.035464
[epoch6, step101]: loss 0.039425
[epoch6, step102]: loss 0.038635
[epoch6, step103]: loss 0.035791
[epoch6, step104]: loss 0.036048
[epoch6, step105]: loss 0.039083
[epoch6, step106]: loss 0.036343
[epoch6, step107]: loss 0.038929
[epoch6, step108]: loss 0.036078
[epoch6, step109]: loss 0.036157
[epoch6, step110]: loss 0.039361
[epoch6, step111]: loss 0.038506
[epoch6, step112]: loss 0.036008
[epoch6, step113]: loss 0.036880
[epoch6, step114]: loss 0.038687
[epoch6, step115]: loss 0.036206
[epoch6, step116]: loss 0.039794
[epoch6, step117]: loss 0.035595
[epoch6, step118]: loss 0.037245
[epoch6, step119]: loss 0.039369
[epoch6, step120]: loss 0.039029
[epoch6, step121]: loss 0.035768
[epoch6, step122]: loss 0.035997
[epoch6, step123]: loss 0.039295
[epoch6, step124]: loss 0.036761
[epoch6, step125]: loss 0.039368
[epoch6, step126]: loss 0.035787
[epoch6, step127]: loss 0.036296
[epoch6, step128]: loss 0.038693
[epoch6, step129]: loss 0.038596
[epoch6, step130]: loss 0.036143
[epoch6, step131]: loss 0.035545
[epoch6, step132]: loss 0.039012
[epoch6, step133]: loss 0.036162
[epoch6, step134]: loss 0.038231
[epoch6, step135]: loss 0.036306
[epoch6, step136]: loss 0.037487
[epoch6, step137]: loss 0.038553
[epoch6, step138]: loss 0.038667
[epoch6, step139]: loss 0.035797
[epoch6, step140]: loss 0.036612
[epoch6, step141]: loss 0.039198
[epoch6, step142]: loss 0.036270
[epoch6, step143]: loss 0.038402
[epoch6, step144]: loss 0.036018
[epoch6, step145]: loss 0.036430
[epoch6, step146]: loss 0.038866
[epoch6, step147]: loss 0.040073
[epoch6, step148]: loss 0.035580
[epoch6, step149]: loss 0.035693
[epoch6, step150]: loss 0.038770
[epoch6, step151]: loss 0.036299
[epoch6, step152]: loss 0.038751
[epoch6, step153]: loss 0.035879
[epoch6, step154]: loss 0.036115
[epoch6, step155]: loss 0.038744
[epoch6, step156]: loss 0.038290
[epoch6, step157]: loss 0.035973
[epoch6, step158]: loss 0.036326
[epoch6, step159]: loss 0.039088
[epoch6, step160]: loss 0.036608
[epoch6, step161]: loss 0.039331
[epoch6, step162]: loss 0.036028
[epoch6, step163]: loss 0.036378
[epoch6, step164]: loss 0.039048
[epoch6, step165]: loss 0.038793
[epoch6, step166]: loss 0.036249
[epoch6, step167]: loss 0.035700
[epoch6, step168]: loss 0.039678
[epoch6, step169]: loss 0.035980
[epoch6, step170]: loss 0.039197
[epoch6, step171]: loss 0.036183
[epoch6, step172]: loss 0.036593
[epoch6, step173]: loss 0.039199
[epoch6, step174]: loss 0.038506
[epoch6, step175]: loss 0.036613
[epoch6, step176]: loss 0.036335
[epoch6, step177]: loss 0.039259
[epoch6, step178]: loss 0.036333
[epoch6, step179]: loss 0.037995
[epoch6, step180]: loss 0.036106
[epoch6, step181]: loss 0.036620
[epoch6, step182]: loss 0.039195
[epoch6, step183]: loss 0.039504
[epoch6, step184]: loss 0.036940
[epoch6, step185]: loss 0.036483
[epoch6, step186]: loss 0.039263
[epoch6, step187]: loss 0.036462
[epoch6, step188]: loss 0.038713
[epoch6, step189]: loss 0.035926
[epoch6, step190]: loss 0.035827
[epoch6, step191]: loss 0.038898
[epoch6, step192]: loss 0.039320
[epoch6, step193]: loss 0.034210
[epoch6, step194]: loss 0.035223
[epoch6, step195]: loss 0.039243
[epoch6, step196]: loss 0.036409
[epoch6, step197]: loss 0.038613
[epoch6, step198]: loss 0.035083
[epoch6, step199]: loss 0.036498
[epoch6, step200]: loss 0.039355
[epoch6, step201]: loss 0.039321
[epoch6, step202]: loss 0.035515
[epoch6, step203]: loss 0.036240
[epoch6, step204]: loss 0.039589
[epoch6, step205]: loss 0.035829
[epoch6, step206]: loss 0.038564
[epoch6, step207]: loss 0.035704
[epoch6, step208]: loss 0.036942
[epoch6, step209]: loss 0.039261
[epoch6, step210]: loss 0.039770
[epoch6, step211]: loss 0.036618
[epoch6, step212]: loss 0.036574
[epoch6, step213]: loss 0.038657
[epoch6, step214]: loss 0.035751
[epoch6, step215]: loss 0.039129
[epoch6, step216]: loss 0.036129
[epoch6, step217]: loss 0.035689
[epoch6, step218]: loss 0.039176
[epoch6, step219]: loss 0.038666
[epoch6, step220]: loss 0.036304
[epoch6, step221]: loss 0.036440
[epoch6, step222]: loss 0.039451
[epoch6, step223]: loss 0.036475
[epoch6, step224]: loss 0.038512
[epoch6, step225]: loss 0.035833
[epoch6, step226]: loss 0.036216
[epoch6, step227]: loss 0.038015
[epoch6, step228]: loss 0.039454
[epoch6, step229]: loss 0.035132
[epoch6, step230]: loss 0.036478
[epoch6, step231]: loss 0.039481
[epoch6, step232]: loss 0.036112
[epoch6, step233]: loss 0.038137
[epoch6, step234]: loss 0.035473
[epoch6, step235]: loss 0.036767
[epoch6, step236]: loss 0.038903
[epoch6, step237]: loss 0.038975
[epoch6, step238]: loss 0.035765
[epoch6, step239]: loss 0.035493
[epoch6, step240]: loss 0.038677
[epoch6, step241]: loss 0.036693
[epoch6, step242]: loss 0.038757
[epoch6, step243]: loss 0.036674
[epoch6, step244]: loss 0.036274
[epoch6, step245]: loss 0.038548
[epoch6, step246]: loss 0.038763
[epoch6, step247]: loss 0.036289
[epoch6, step248]: loss 0.035722
[epoch6, step249]: loss 0.038429
[epoch6, step250]: loss 0.036670
[epoch6, step251]: loss 0.039277
[epoch6, step252]: loss 0.036397
[epoch6, step253]: loss 0.035983
[epoch6, step254]: loss 0.038482
[epoch6, step255]: loss 0.039152
[epoch6, step256]: loss 0.035692
[epoch6, step257]: loss 0.035947
[epoch6, step258]: loss 0.039699
[epoch6, step259]: loss 0.036406
[epoch6, step260]: loss 0.038392
[epoch6, step261]: loss 0.036722
[epoch6, step262]: loss 0.036874
[epoch6, step263]: loss 0.038409
[epoch6, step264]: loss 0.038560
[epoch6, step265]: loss 0.036228
[epoch6, step266]: loss 0.036039
[epoch6, step267]: loss 0.038333
[epoch6, step268]: loss 0.036281
[epoch6, step269]: loss 0.038838
[epoch6, step270]: loss 0.035438
[epoch6, step271]: loss 0.036505
[epoch6, step272]: loss 0.038771
[epoch6, step273]: loss 0.038636
[epoch6, step274]: loss 0.036424
[epoch6, step275]: loss 0.035735
[epoch6, step276]: loss 0.038839
[epoch6, step277]: loss 0.036774
[epoch6, step278]: loss 0.039076
[epoch6, step279]: loss 0.035591
[epoch6, step280]: loss 0.036474
[epoch6, step281]: loss 0.038840
[epoch6, step282]: loss 0.039265
[epoch6, step283]: loss 0.035613
[epoch6, step284]: loss 0.035569
[epoch6, step285]: loss 0.039740
[epoch6, step286]: loss 0.035597
[epoch6, step287]: loss 0.039002
[epoch6, step288]: loss 0.035514
[epoch6, step289]: loss 0.037151
[epoch6, step290]: loss 0.038880
[epoch6, step291]: loss 0.039255
[epoch6, step292]: loss 0.035195
[epoch6, step293]: loss 0.035864
[epoch6, step294]: loss 0.038536
[epoch6, step295]: loss 0.035760
[epoch6, step296]: loss 0.039701
[epoch6, step297]: loss 0.035711
[epoch6, step298]: loss 0.036912
[epoch6, step299]: loss 0.038110
[epoch6, step300]: loss 0.039122
[epoch6, step301]: loss 0.036023
[epoch6, step302]: loss 0.036425
[epoch6, step303]: loss 0.039364
[epoch6, step304]: loss 0.036165
[epoch6, step305]: loss 0.038650
[epoch6, step306]: loss 0.036033
[epoch6, step307]: loss 0.036208
[epoch6, step308]: loss 0.039402
[epoch6, step309]: loss 0.039337
[epoch6, step310]: loss 0.036118
[epoch6, step311]: loss 0.036562
[epoch6, step312]: loss 0.038810
[epoch6, step313]: loss 0.036627
[epoch6, step314]: loss 0.038882
[epoch6, step315]: loss 0.036979
[epoch6, step316]: loss 0.036111
[epoch6, step317]: loss 0.039272
[epoch6, step318]: loss 0.038822
[epoch6, step319]: loss 0.035485
[epoch6, step320]: loss 0.035074
[epoch6, step321]: loss 0.038497
[epoch6, step322]: loss 0.036184
[epoch6, step323]: loss 0.038093
[epoch6, step324]: loss 0.036782
[epoch6, step325]: loss 0.036537
[epoch6, step326]: loss 0.038583
[epoch6, step327]: loss 0.038282
[epoch6, step328]: loss 0.036116
[epoch6, step329]: loss 0.035948
[epoch6, step330]: loss 0.038614
[epoch6, step331]: loss 0.036452
[epoch6, step332]: loss 0.038291
[epoch6, step333]: loss 0.035873
[epoch6, step334]: loss 0.036450
[epoch6, step335]: loss 0.039072
[epoch6, step336]: loss 0.039612
[epoch6, step337]: loss 0.036421
[epoch6, step338]: loss 0.035573
[epoch6, step339]: loss 0.038872
[epoch6, step340]: loss 0.036836
[epoch6, step341]: loss 0.038232
[epoch6, step342]: loss 0.035603
[epoch6, step343]: loss 0.036576
[epoch6, step344]: loss 0.038357
[epoch6, step345]: loss 0.038213
[epoch6, step346]: loss 0.035484
[epoch6, step347]: loss 0.035806
[epoch6, step348]: loss 0.039227
[epoch6, step349]: loss 0.036763
[epoch6, step350]: loss 0.038366
[epoch6, step351]: loss 0.035144
[epoch6, step352]: loss 0.036235
[epoch6, step353]: loss 0.038690
[epoch6, step354]: loss 0.037849
[epoch6, step355]: loss 0.034915
[epoch6, step356]: loss 0.036633
[epoch6, step357]: loss 0.039041
[epoch6, step358]: loss 0.034861
[epoch6, step359]: loss 0.039700
[epoch6, step360]: loss 0.034648
[epoch6, step361]: loss 0.035838
[epoch6, step362]: loss 0.039430
[epoch6, step363]: loss 0.038570
[epoch6, step364]: loss 0.035882
[epoch6, step365]: loss 0.035809
[epoch6, step366]: loss 0.039374
[epoch6, step367]: loss 0.036287
[epoch6, step368]: loss 0.038232
[epoch6, step369]: loss 0.035724
[epoch6, step370]: loss 0.036924
[epoch6, step371]: loss 0.039593
[epoch6, step372]: loss 0.038485
[epoch6, step373]: loss 0.035474
[epoch6, step374]: loss 0.035314
[epoch6, step375]: loss 0.039625
[epoch6, step376]: loss 0.036250
[epoch6, step377]: loss 0.038952
[epoch6, step378]: loss 0.036351
[epoch6, step379]: loss 0.037033
[epoch6, step380]: loss 0.039425
[epoch6, step381]: loss 0.038544
[epoch6, step382]: loss 0.036255
[epoch6, step383]: loss 0.035059
[epoch6, step384]: loss 0.038230
[epoch6, step385]: loss 0.036090
[epoch6, step386]: loss 0.039048
[epoch6, step387]: loss 0.035889
[epoch6, step388]: loss 0.037403
[epoch6, step389]: loss 0.038883
[epoch6, step390]: loss 0.039830
[epoch6, step391]: loss 0.035579
[epoch6, step392]: loss 0.036581
[epoch6, step393]: loss 0.038478
[epoch6, step394]: loss 0.036290
[epoch6, step395]: loss 0.038602
[epoch6, step396]: loss 0.036075
[epoch6, step397]: loss 0.036093
[epoch6, step398]: loss 0.039047
[epoch6, step399]: loss 0.038723
[epoch6, step400]: loss 0.035609
[epoch6, step401]: loss 0.035823
[epoch6, step402]: loss 0.038857
[epoch6, step403]: loss 0.036267
[epoch6, step404]: loss 0.039235
[epoch6, step405]: loss 0.036170
[epoch6, step406]: loss 0.036651
[epoch6, step407]: loss 0.038615
[epoch6, step408]: loss 0.039035
[epoch6, step409]: loss 0.037355
[epoch6, step410]: loss 0.036772
[epoch6, step411]: loss 0.038861
[epoch6, step412]: loss 0.035721
[epoch6, step413]: loss 0.038758
[epoch6, step414]: loss 0.035593
[epoch6, step415]: loss 0.036604
[epoch6, step416]: loss 0.038215
[epoch6, step417]: loss 0.039018
[epoch6, step418]: loss 0.035909
[epoch6, step419]: loss 0.035249
[epoch6, step420]: loss 0.039132
[epoch6, step421]: loss 0.035971
[epoch6, step422]: loss 0.038769
[epoch6, step423]: loss 0.035984
[epoch6, step424]: loss 0.036574
[epoch6, step425]: loss 0.039001
[epoch6, step426]: loss 0.039205
[epoch6, step427]: loss 0.036280
[epoch6, step428]: loss 0.035922
[epoch6, step429]: loss 0.039635
[epoch6, step430]: loss 0.036155
[epoch6, step431]: loss 0.039129
[epoch6, step432]: loss 0.035738
[epoch6, step433]: loss 0.037164
[epoch6, step434]: loss 0.038745
[epoch6, step435]: loss 0.039214
[epoch6, step436]: loss 0.035659
[epoch6, step437]: loss 0.036205
[epoch6, step438]: loss 0.039540
[epoch6, step439]: loss 0.036493
[epoch6, step440]: loss 0.038777
[epoch6, step441]: loss 0.036123
[epoch6, step442]: loss 0.036322
[epoch6, step443]: loss 0.039298
[epoch6, step444]: loss 0.038596
[epoch6, step445]: loss 0.036404
[epoch6, step446]: loss 0.036447
[epoch6, step447]: loss 0.039709
[epoch6, step448]: loss 0.036382
[epoch6, step449]: loss 0.038652
[epoch6, step450]: loss 0.035247
[epoch6, step451]: loss 0.036243
[epoch6, step452]: loss 0.037988
[epoch6, step453]: loss 0.038980
[epoch6, step454]: loss 0.035856
[epoch6, step455]: loss 0.036229
[epoch6, step456]: loss 0.038103
[epoch6, step457]: loss 0.037032
[epoch6, step458]: loss 0.038594
[epoch6, step459]: loss 0.036659
[epoch6, step460]: loss 0.036615
[epoch6, step461]: loss 0.039561
[epoch6, step462]: loss 0.038268
[epoch6, step463]: loss 0.036102
[epoch6, step464]: loss 0.035908
[epoch6, step465]: loss 0.040491
[epoch6, step466]: loss 0.036264
[epoch6, step467]: loss 0.038686
[epoch6, step468]: loss 0.035901
[epoch6, step469]: loss 0.036638
[epoch6, step470]: loss 0.039136
[epoch6, step471]: loss 0.038526
[epoch6, step472]: loss 0.036488
[epoch6, step473]: loss 0.035610
[epoch6, step474]: loss 0.038820
[epoch6, step475]: loss 0.036463
[epoch6, step476]: loss 0.039310
[epoch6, step477]: loss 0.035795
[epoch6, step478]: loss 0.035938
[epoch6, step479]: loss 0.038685
[epoch6, step480]: loss 0.037982
[epoch6, step481]: loss 0.035498
[epoch6, step482]: loss 0.035422
[epoch6, step483]: loss 0.039399
[epoch6, step484]: loss 0.036424
[epoch6, step485]: loss 0.038999
[epoch6, step486]: loss 0.036219
[epoch6, step487]: loss 0.035887
[epoch6, step488]: loss 0.039258
[epoch6, step489]: loss 0.038105
[epoch6, step490]: loss 0.036389
[epoch6, step491]: loss 0.036217
[epoch6, step492]: loss 0.038608
[epoch6, step493]: loss 0.035983
[epoch6, step494]: loss 0.038184
[epoch6, step495]: loss 0.037027
[epoch6, step496]: loss 0.036604
[epoch6, step497]: loss 0.039044
[epoch6, step498]: loss 0.038813
[epoch6, step499]: loss 0.036262
[epoch6, step500]: loss 0.035586
[epoch6, step501]: loss 0.038506
[epoch6, step502]: loss 0.036065
[epoch6, step503]: loss 0.039074
[epoch6, step504]: loss 0.035623
[epoch6, step505]: loss 0.035549
[epoch6, step506]: loss 0.039300
[epoch6, step507]: loss 0.039232
[epoch6, step508]: loss 0.036485
[epoch6, step509]: loss 0.035933
[epoch6, step510]: loss 0.039166
[epoch6, step511]: loss 0.036645
[epoch6, step512]: loss 0.039166
[epoch6, step513]: loss 0.036121
[epoch6, step514]: loss 0.036748
[epoch6, step515]: loss 0.038871
[epoch6, step516]: loss 0.039324
[epoch6, step517]: loss 0.036034
[epoch6, step518]: loss 0.036156
[epoch6, step519]: loss 0.039165
[epoch6, step520]: loss 0.035631
[epoch6, step521]: loss 0.038774
[epoch6, step522]: loss 0.035470
[epoch6, step523]: loss 0.036461
[epoch6, step524]: loss 0.038201
[epoch6, step525]: loss 0.039157
[epoch6, step526]: loss 0.036075
[epoch6, step527]: loss 0.035704
[epoch6, step528]: loss 0.039120
[epoch6, step529]: loss 0.035795
[epoch6, step530]: loss 0.039162
[epoch6, step531]: loss 0.035716
[epoch6, step532]: loss 0.036124
[epoch6, step533]: loss 0.039800
[epoch6, step534]: loss 0.038797
[epoch6, step535]: loss 0.036608
[epoch6, step536]: loss 0.036212
[epoch6, step537]: loss 0.039100
[epoch6, step538]: loss 0.036300
[epoch6, step539]: loss 0.038605
[epoch6, step540]: loss 0.035523
[epoch6, step541]: loss 0.035900
[epoch6, step542]: loss 0.038869
[epoch6, step543]: loss 0.038555
[epoch6, step544]: loss 0.035901
[epoch6, step545]: loss 0.035226
[epoch6, step546]: loss 0.039493
[epoch6, step547]: loss 0.036158
[epoch6, step548]: loss 0.038801
[epoch6, step549]: loss 0.036156
[epoch6, step550]: loss 0.036464
[epoch6, step551]: loss 0.038684
[epoch6, step552]: loss 0.038272
[epoch6, step553]: loss 0.036457
[epoch6, step554]: loss 0.035855
[epoch6, step555]: loss 0.038623
[epoch6, step556]: loss 0.036070
[epoch6, step557]: loss 0.038253
[epoch6, step558]: loss 0.036114
[epoch6, step559]: loss 0.035893
[epoch6, step560]: loss 0.039024
[epoch6, step561]: loss 0.038649
[epoch6, step562]: loss 0.035999
[epoch6, step563]: loss 0.029035
[epoch6, step564]: loss 0.028861
[epoch6, step565]: loss 0.027984
[epoch6, step566]: loss 0.035213
[epoch6, step567]: loss 0.027340
[epoch6, step568]: loss 0.026611
[epoch6, step569]: loss 0.024227
[epoch6, step570]: loss 0.032361
[epoch6, step571]: loss 0.027751
[epoch6, step572]: loss 0.026610
[epoch6, step573]: loss 0.029620
[epoch6, step574]: loss 0.027952
[epoch6, step575]: loss 0.021286
[epoch6, step576]: loss 0.022093
[epoch6, step577]: loss 0.026630
[epoch6, step578]: loss 0.019091
[epoch6, step579]: loss 0.028883
[epoch6, step580]: loss 0.020180
[epoch6, step581]: loss 0.031852
[epoch6, step582]: loss 0.030204
[epoch6, step583]: loss 0.022601
[epoch6, step584]: loss 0.024072
[epoch6, step585]: loss 0.027030
[epoch6, step586]: loss 0.022206
[epoch6, step587]: loss 0.028850
[epoch6, step588]: loss 0.023875
[epoch6, step589]: loss 0.023983
[epoch6, step590]: loss 0.028740
[epoch6, step591]: loss 0.020932
[epoch6, step592]: loss 0.027188
[epoch6, step593]: loss 0.022424
[epoch6, step594]: loss 0.026471
[epoch6, step595]: loss 0.027483
[epoch6, step596]: loss 0.022568
[epoch6, step597]: loss 0.025191
[epoch6, step598]: loss 0.026663
[epoch6, step599]: loss 0.025401
[epoch6, step600]: loss 0.027204
[epoch6, step601]: loss 0.019572
[epoch6, step602]: loss 0.022311
[epoch6, step603]: loss 0.025756
[epoch6, step604]: loss 0.026960
[epoch6, step605]: loss 0.025902
[epoch6, step606]: loss 0.024933
[epoch6, step607]: loss 0.026945
[epoch6, step608]: loss 0.025873
[epoch6, step609]: loss 0.026880
[epoch6, step610]: loss 0.026783
[epoch6, step611]: loss 0.026533
[epoch6, step612]: loss 0.025254
[epoch6, step613]: loss 0.019363
[epoch6, step614]: loss 0.025154
[epoch6, step615]: loss 0.028495
[epoch6, step616]: loss 0.024037
[epoch6, step617]: loss 0.023562
[epoch6, step618]: loss 0.026095
[epoch6, step619]: loss 0.027074
[epoch6, step620]: loss 0.024235
[epoch6, step621]: loss 0.026048
[epoch6, step622]: loss 0.020472
[epoch6, step623]: loss 0.024668
[epoch6, step624]: loss 0.026335
[epoch6, step625]: loss 0.025645
[epoch6, step626]: loss 0.027879
[epoch6, step627]: loss 0.023017
[epoch6, step628]: loss 0.025105
[epoch6, step629]: loss 0.020965
[epoch6, step630]: loss 0.023330
[epoch6, step631]: loss 0.031292
[epoch6, step632]: loss 0.023183
[epoch6, step633]: loss 0.024556
[epoch6, step634]: loss 0.027381
[epoch6, step635]: loss 0.025807
[epoch6, step636]: loss 0.020982
[epoch6, step637]: loss 0.027592
[epoch6, step638]: loss 0.026928
[epoch6, step639]: loss 0.022949
[epoch6, step640]: loss 0.029217
[epoch6, step641]: loss 0.030507
[epoch6, step642]: loss 0.025084
[epoch6, step643]: loss 0.025699
[epoch6, step644]: loss 0.025757
[epoch6, step645]: loss 0.024020
[epoch6, step646]: loss 0.026227
[epoch6, step647]: loss 0.023793
[epoch6, step648]: loss 0.022942
[epoch6, step649]: loss 0.028352
[epoch6, step650]: loss 0.022016
[epoch6, step651]: loss 0.025985
[epoch6, step652]: loss 0.026666
[epoch6, step653]: loss 0.027802
[epoch6, step654]: loss 0.023076
[epoch6, step655]: loss 0.024097
[epoch6, step656]: loss 0.021455
[epoch6, step657]: loss 0.027574
[epoch6, step658]: loss 0.025202
[epoch6, step659]: loss 0.027369
[epoch6, step660]: loss 0.024099
[epoch6, step661]: loss 0.026419
[epoch6, step662]: loss 0.024165
[epoch6, step663]: loss 0.020829
[epoch6, step664]: loss 0.025140
[epoch6, step665]: loss 0.028242
[epoch6, step666]: loss 0.026624
[epoch6, step667]: loss 0.026576
[epoch6, step668]: loss 0.022291
[epoch6, step669]: loss 0.026517
[epoch6, step670]: loss 0.026952
[epoch6, step671]: loss 0.021379
[epoch6, step672]: loss 0.024075
[epoch6, step673]: loss 0.022200
[epoch6, step674]: loss 0.021416
[epoch6, step675]: loss 0.020272
[epoch6, step676]: loss 0.024585
[epoch6, step677]: loss 0.025276
[epoch6, step678]: loss 0.023197
[epoch6, step679]: loss 0.024156
[epoch6, step680]: loss 0.030448
[epoch6, step681]: loss 0.022098
[epoch6, step682]: loss 0.026311
[epoch6, step683]: loss 0.025825
[epoch6, step684]: loss 0.024680
[epoch6, step685]: loss 0.024281
[epoch6, step686]: loss 0.027132
[epoch6, step687]: loss 0.026766
[epoch6, step688]: loss 0.022523
[epoch6, step689]: loss 0.024546
[epoch6, step690]: loss 0.025268
[epoch6, step691]: loss 0.024229
[epoch6, step692]: loss 0.022432
[epoch6, step693]: loss 0.027240
[epoch6, step694]: loss 0.022661
[epoch6, step695]: loss 0.026541
[epoch6, step696]: loss 0.025965
[epoch6, step697]: loss 0.027166
[epoch6, step698]: loss 0.024726
[epoch6, step699]: loss 0.023513
[epoch6, step700]: loss 0.021630
[epoch6, step701]: loss 0.025850
[epoch6, step702]: loss 0.021643
[epoch6, step703]: loss 0.022821
[epoch6, step704]: loss 0.025080
[epoch6, step705]: loss 0.024992
[epoch6, step706]: loss 0.023754
[epoch6, step707]: loss 0.024925
[epoch6, step708]: loss 0.026164
[epoch6, step709]: loss 0.027642
[epoch6, step710]: loss 0.023755
[epoch6, step711]: loss 0.023682
[epoch6, step712]: loss 0.027106
[epoch6, step713]: loss 0.026243
[epoch6, step714]: loss 0.021318
[epoch6, step715]: loss 0.023096
[epoch6, step716]: loss 0.025898
[epoch6, step717]: loss 0.023625
[epoch6, step718]: loss 0.024991
[epoch6, step719]: loss 0.033380
[epoch6, step720]: loss 0.024729
[epoch6, step721]: loss 0.023034
[epoch6, step722]: loss 0.030608
[epoch6, step723]: loss 0.025962
[epoch6, step724]: loss 0.022892
[epoch6, step725]: loss 0.028213
[epoch6, step726]: loss 0.022253
[epoch6, step727]: loss 0.024690
[epoch6, step728]: loss 0.026415
[epoch6, step729]: loss 0.021116
[epoch6, step730]: loss 0.022594
[epoch6, step731]: loss 0.025814
[epoch6, step732]: loss 0.026006
[epoch6, step733]: loss 0.023815
[epoch6, step734]: loss 0.022785
[epoch6, step735]: loss 0.027499
[epoch6, step736]: loss 0.025107
[epoch6, step737]: loss 0.026613
[epoch6, step738]: loss 0.020652
[epoch6, step739]: loss 0.025581
[epoch6, step740]: loss 0.022338
[epoch6, step741]: loss 0.025125
[epoch6, step742]: loss 0.021772
[epoch6, step743]: loss 0.023205
[epoch6, step744]: loss 0.024060
[epoch6, step745]: loss 0.024615
[epoch6, step746]: loss 0.025209
[epoch6, step747]: loss 0.027414
[epoch6, step748]: loss 0.025797
[epoch6, step749]: loss 0.026270
[epoch6, step750]: loss 0.027612
[epoch6, step751]: loss 0.021777
[epoch6, step752]: loss 0.025387
[epoch6, step753]: loss 0.025761
[epoch6, step754]: loss 0.022768
[epoch6, step755]: loss 0.026229
[epoch6, step756]: loss 0.023684
[epoch6, step757]: loss 0.020544
[epoch6, step758]: loss 0.025224
[epoch6, step759]: loss 0.023116
[epoch6, step760]: loss 0.024080
[epoch6, step761]: loss 0.026545
[epoch6, step762]: loss 0.021529
[epoch6, step763]: loss 0.025596
[epoch6, step764]: loss 0.023616
[epoch6, step765]: loss 0.025892
[epoch6, step766]: loss 0.024683
[epoch6, step767]: loss 0.026747
[epoch6, step768]: loss 0.021317
[epoch6, step769]: loss 0.026709
[epoch6, step770]: loss 0.026040
[epoch6, step771]: loss 0.023245
[epoch6, step772]: loss 0.028853
[epoch6, step773]: loss 0.026589
[epoch6, step774]: loss 0.024262
[epoch6, step775]: loss 0.020701
[epoch6, step776]: loss 0.025504
[epoch6, step777]: loss 0.023173
[epoch6, step778]: loss 0.027905
[epoch6, step779]: loss 0.023787
[epoch6, step780]: loss 0.020158
[epoch6, step781]: loss 0.024487
[epoch6, step782]: loss 0.022754
[epoch6, step783]: loss 0.019372
[epoch6, step784]: loss 0.020197
[epoch6, step785]: loss 0.021500
[epoch6, step786]: loss 0.024301
[epoch6, step787]: loss 0.023237
[epoch6, step788]: loss 0.024939
[epoch6, step789]: loss 0.022474
[epoch6, step790]: loss 0.023141
[epoch6, step791]: loss 0.026753
[epoch6, step792]: loss 0.025105
[epoch6, step793]: loss 0.026836
[epoch6, step794]: loss 0.020367
[epoch6, step795]: loss 0.025600
[epoch6, step796]: loss 0.027816
[epoch6, step797]: loss 0.027660
[epoch6, step798]: loss 0.027025
[epoch6, step799]: loss 0.025731
[epoch6, step800]: loss 0.021362
[epoch6, step801]: loss 0.021652
[epoch6, step802]: loss 0.022806
[epoch6, step803]: loss 0.026237
[epoch6, step804]: loss 0.027230
[epoch6, step805]: loss 0.028178
[epoch6, step806]: loss 0.021265
[epoch6, step807]: loss 0.020576
[epoch6, step808]: loss 0.022914
[epoch6, step809]: loss 0.022998
[epoch6, step810]: loss 0.026058
[epoch6, step811]: loss 0.025714
[epoch6, step812]: loss 0.024589
[epoch6, step813]: loss 0.023676
[epoch6, step814]: loss 0.025093
[epoch6, step815]: loss 0.025088
[epoch6, step816]: loss 0.024134
[epoch6, step817]: loss 0.024729
[epoch6, step818]: loss 0.022466
[epoch6, step819]: loss 0.020150
[epoch6, step820]: loss 0.023725
[epoch6, step821]: loss 0.021926
[epoch6, step822]: loss 0.030507
[epoch6, step823]: loss 0.024053
[epoch6, step824]: loss 0.026917
[epoch6, step825]: loss 0.025385
[epoch6, step826]: loss 0.024429
[epoch6, step827]: loss 0.027027
[epoch6, step828]: loss 0.028653
[epoch6, step829]: loss 0.026455
[epoch6, step830]: loss 0.022618
[epoch6, step831]: loss 0.026344
[epoch6, step832]: loss 0.020823
[epoch6, step833]: loss 0.029129
[epoch6, step834]: loss 0.025412
[epoch6, step835]: loss 0.020423
[epoch6, step836]: loss 0.027003
[epoch6, step837]: loss 0.025576
[epoch6, step838]: loss 0.026202
[epoch6, step839]: loss 0.028444
[epoch6, step840]: loss 0.020769
[epoch6, step841]: loss 0.024245
[epoch6, step842]: loss 0.027561
[epoch6, step843]: loss 0.024704
[epoch6, step844]: loss 0.024954
[epoch6, step845]: loss 0.021107
[epoch6, step846]: loss 0.025335
[epoch6, step847]: loss 0.026853
[epoch6, step848]: loss 0.024944
[epoch6, step849]: loss 0.025007
[epoch6, step850]: loss 0.023056
[epoch6, step851]: loss 0.023832
[epoch6, step852]: loss 0.023058
[epoch6, step853]: loss 0.029186
[epoch6, step854]: loss 0.022641
[epoch6, step855]: loss 0.027325
[epoch6, step856]: loss 0.022108
[epoch6, step857]: loss 0.025767
[epoch6, step858]: loss 0.024290
[epoch6, step859]: loss 0.023655
[epoch6, step860]: loss 0.022554
[epoch6, step861]: loss 0.023276
[epoch6, step862]: loss 0.023051
[epoch6, step863]: loss 0.020729
[epoch6, step864]: loss 0.026396
[epoch6, step865]: loss 0.023479
[epoch6, step866]: loss 0.025237
[epoch6, step867]: loss 0.026025
[epoch6, step868]: loss 0.026689
[epoch6, step869]: loss 0.024054
[epoch6, step870]: loss 0.030947
[epoch6, step871]: loss 0.021988
[epoch6, step872]: loss 0.025379
[epoch6, step873]: loss 0.025825
[epoch6, step874]: loss 0.023680
[epoch6, step875]: loss 0.024160
[epoch6, step876]: loss 0.024126
[epoch6, step877]: loss 0.019099
[epoch6, step878]: loss 0.023260
[epoch6, step879]: loss 0.028077
[epoch6, step880]: loss 0.025438
[epoch6, step881]: loss 0.022238
[epoch6, step882]: loss 0.024059
[epoch6, step883]: loss 0.023700
[epoch6, step884]: loss 0.026541
[epoch6, step885]: loss 0.025985
[epoch6, step886]: loss 0.026451
[epoch6, step887]: loss 0.024172
[epoch6, step888]: loss 0.024562
[epoch6, step889]: loss 0.023507
[epoch6, step890]: loss 0.023396
[epoch6, step891]: loss 0.025510
[epoch6, step892]: loss 0.020914
[epoch6, step893]: loss 0.024743
[epoch6, step894]: loss 0.024893
[epoch6, step895]: loss 0.022568
[epoch6, step896]: loss 0.021742
[epoch6, step897]: loss 0.023865
[epoch6, step898]: loss 0.025448
[epoch6, step899]: loss 0.028094
[epoch6, step900]: loss 0.026921
[epoch6, step901]: loss 0.025439
[epoch6, step902]: loss 0.024021
[epoch6, step903]: loss 0.024052
[epoch6, step904]: loss 0.027991
[epoch6, step905]: loss 0.027499
[epoch6, step906]: loss 0.022429
[epoch6, step907]: loss 0.023645
[epoch6, step908]: loss 0.022549
[epoch6, step909]: loss 0.025325
[epoch6, step910]: loss 0.023095
[epoch6, step911]: loss 0.025120
[epoch6, step912]: loss 0.023783
[epoch6, step913]: loss 0.024085
[epoch6, step914]: loss 0.030413
[epoch6, step915]: loss 0.024002
[epoch6, step916]: loss 0.023819
[epoch6, step917]: loss 0.025104
[epoch6, step918]: loss 0.028552
[epoch6, step919]: loss 0.024093
[epoch6, step920]: loss 0.027568
[epoch6, step921]: loss 0.024512
[epoch6, step922]: loss 0.023129
[epoch6, step923]: loss 0.022569
[epoch6, step924]: loss 0.021190
[epoch6, step925]: loss 0.025389
[epoch6, step926]: loss 0.026574
[epoch6, step927]: loss 0.025764
[epoch6, step928]: loss 0.024911
[epoch6, step929]: loss 0.027547
[epoch6, step930]: loss 0.025698
[epoch6, step931]: loss 0.027255
[epoch6, step932]: loss 0.021630
[epoch6, step933]: loss 0.028130
[epoch6, step934]: loss 0.022008
[epoch6, step935]: loss 0.021993
[epoch6, step936]: loss 0.022495
[epoch6, step937]: loss 0.027121
[epoch6, step938]: loss 0.025266
[epoch6, step939]: loss 0.020715
[epoch6, step940]: loss 0.022944
[epoch6, step941]: loss 0.026826
[epoch6, step942]: loss 0.025515
[epoch6, step943]: loss 0.023266
[epoch6, step944]: loss 0.027588
[epoch6, step945]: loss 0.020523
[epoch6, step946]: loss 0.025435
[epoch6, step947]: loss 0.027813
[epoch6, step948]: loss 0.019311
[epoch6, step949]: loss 0.022921
[epoch6, step950]: loss 0.026600
[epoch6, step951]: loss 0.028561
[epoch6, step952]: loss 0.025065
[epoch6, step953]: loss 0.027542
[epoch6, step954]: loss 0.022082
[epoch6, step955]: loss 0.036473
[epoch6, step956]: loss 0.051835
[epoch6, step957]: loss 0.046324
[epoch6, step958]: loss 0.043903
[epoch6, step959]: loss 0.048011
[epoch6, step960]: loss 0.044694
[epoch6, step961]: loss 0.045488
[epoch6, step962]: loss 0.043836
[epoch6, step963]: loss 0.040552
[epoch6, step964]: loss 0.041153
[epoch6, step965]: loss 0.039949
[epoch6, step966]: loss 0.038946
[epoch6, step967]: loss 0.039510
[epoch6, step968]: loss 0.042798
[epoch6, step969]: loss 0.042523
[epoch6, step970]: loss 0.041864
[epoch6, step971]: loss 0.040276
[epoch6, step972]: loss 0.041335
[epoch6, step973]: loss 0.039481
[epoch6, step974]: loss 0.041109
[epoch6, step975]: loss 0.038584
[epoch6, step976]: loss 0.037902
[epoch6, step977]: loss 0.041695
[epoch6, step978]: loss 0.039391
[epoch6, step979]: loss 0.038307
[epoch6, step980]: loss 0.037432
[epoch6, step981]: loss 0.038890
[epoch6, step982]: loss 0.039134
[epoch6, step983]: loss 0.040340
[epoch6, step984]: loss 0.036798
[epoch6, step985]: loss 0.037088
[epoch6, step986]: loss 0.040919
[epoch6, step987]: loss 0.039267
[epoch6, step988]: loss 0.039027
[epoch6, step989]: loss 0.038235
[epoch6, step990]: loss 0.038534
[epoch6, step991]: loss 0.039428
[epoch6, step992]: loss 0.040155
[epoch6, step993]: loss 0.037305
[epoch6, step994]: loss 0.036499
[epoch6, step995]: loss 0.040288
[epoch6, step996]: loss 0.038349
[epoch6, step997]: loss 0.038523
[epoch6, step998]: loss 0.037919
[epoch6, step999]: loss 0.038438
[epoch6, step1000]: loss 0.038753
[epoch6, step1001]: loss 0.039972
[epoch6, step1002]: loss 0.037615
[epoch6, step1003]: loss 0.036587
[epoch6, step1004]: loss 0.040309
[epoch6, step1005]: loss 0.037759
[epoch6, step1006]: loss 0.038330
[epoch6, step1007]: loss 0.036909
[epoch6, step1008]: loss 0.037761
[epoch6, step1009]: loss 0.038429
[epoch6, step1010]: loss 0.040421
[epoch6, step1011]: loss 0.037112
[epoch6, step1012]: loss 0.037065
[epoch6, step1013]: loss 0.040150
[epoch6, step1014]: loss 0.039012
[epoch6, step1015]: loss 0.038491
[epoch6, step1016]: loss 0.036847
[epoch6, step1017]: loss 0.037835
[epoch6, step1018]: loss 0.038293
[epoch6, step1019]: loss 0.039761
[epoch6, step1020]: loss 0.036789
[epoch6, step1021]: loss 0.036325
[epoch6, step1022]: loss 0.039599
[epoch6, step1023]: loss 0.038243
[epoch6, step1024]: loss 0.038678
[epoch6, step1025]: loss 0.036442
[epoch6, step1026]: loss 0.037593
[epoch6, step1027]: loss 0.037927
[epoch6, step1028]: loss 0.039730
[epoch6, step1029]: loss 0.036646
[epoch6, step1030]: loss 0.035985
[epoch6, step1031]: loss 0.038512
[epoch6, step1032]: loss 0.038663
[epoch6, step1033]: loss 0.037727
[epoch6, step1034]: loss 0.036646
[epoch6, step1035]: loss 0.037342
[epoch6, step1036]: loss 0.038278
[epoch6, step1037]: loss 0.039250
[epoch6, step1038]: loss 0.036714
[epoch6, step1039]: loss 0.036588
[epoch6, step1040]: loss 0.038966
[epoch6, step1041]: loss 0.037841
[epoch6, step1042]: loss 0.036898
[epoch6, step1043]: loss 0.036678
[epoch6, step1044]: loss 0.037974
[epoch6, step1045]: loss 0.038278
[epoch6, step1046]: loss 0.039680
[epoch6, step1047]: loss 0.036816
[epoch6, step1048]: loss 0.035985
[epoch6, step1049]: loss 0.039533
[epoch6, step1050]: loss 0.038545
[epoch6, step1051]: loss 0.037922
[epoch6, step1052]: loss 0.037261
[epoch6, step1053]: loss 0.038277
[epoch6, step1054]: loss 0.038215
[epoch6, step1055]: loss 0.038807
[epoch6, step1056]: loss 0.036160
[epoch6, step1057]: loss 0.036944
[epoch6, step1058]: loss 0.040424
[epoch6, step1059]: loss 0.038295
[epoch6, step1060]: loss 0.038003
[epoch6, step1061]: loss 0.036141
[epoch6, step1062]: loss 0.038127
[epoch6, step1063]: loss 0.038060
[epoch6, step1064]: loss 0.039305
[epoch6, step1065]: loss 0.036631
[epoch6, step1066]: loss 0.036042
[epoch6, step1067]: loss 0.039408
[epoch6, step1068]: loss 0.036845
[epoch6, step1069]: loss 0.037280
[epoch6, step1070]: loss 0.036477
[epoch6, step1071]: loss 0.038327
[epoch6, step1072]: loss 0.038803
[epoch6, step1073]: loss 0.039109
[epoch6, step1074]: loss 0.036874
[epoch6, step1075]: loss 0.036575
[epoch6, step1076]: loss 0.039497
[epoch6, step1077]: loss 0.038027
[epoch6, step1078]: loss 0.037506
[epoch6, step1079]: loss 0.037604
[epoch6, step1080]: loss 0.037961
[epoch6, step1081]: loss 0.037826
[epoch6, step1082]: loss 0.039131
[epoch6, step1083]: loss 0.037330
[epoch6, step1084]: loss 0.036521
[epoch6, step1085]: loss 0.038902
[epoch6, step1086]: loss 0.037686
[epoch6, step1087]: loss 0.037750
[epoch6, step1088]: loss 0.036394
[epoch6, step1089]: loss 0.038091
[epoch6, step1090]: loss 0.038653
[epoch6, step1091]: loss 0.039426
[epoch6, step1092]: loss 0.036378
[epoch6, step1093]: loss 0.036206
[epoch6, step1094]: loss 0.038430
[epoch6, step1095]: loss 0.037508
[epoch6, step1096]: loss 0.037144
[epoch6, step1097]: loss 0.036571
[epoch6, step1098]: loss 0.037670
[epoch6, step1099]: loss 0.037617
[epoch6, step1100]: loss 0.039665
[epoch6, step1101]: loss 0.036881
[epoch6, step1102]: loss 0.036127
[epoch6, step1103]: loss 0.038756
[epoch6, step1104]: loss 0.037943
[epoch6, step1105]: loss 0.037727
[epoch6, step1106]: loss 0.035604
[epoch6, step1107]: loss 0.037969
[epoch6, step1108]: loss 0.037602
[epoch6, step1109]: loss 0.039484
[epoch6, step1110]: loss 0.037223
[epoch6, step1111]: loss 0.036486
[epoch6, step1112]: loss 0.039630
[epoch6, step1113]: loss 0.037532
[epoch6, step1114]: loss 0.037853
[epoch6, step1115]: loss 0.036695
[epoch6, step1116]: loss 0.037828
[epoch6, step1117]: loss 0.037984
[epoch6, step1118]: loss 0.038947
[epoch6, step1119]: loss 0.036318
[epoch6, step1120]: loss 0.036138
[epoch6, step1121]: loss 0.039170
[epoch6, step1122]: loss 0.037405
[epoch6, step1123]: loss 0.036800
[epoch6, step1124]: loss 0.037213
[epoch6, step1125]: loss 0.038115
[epoch6, step1126]: loss 0.038870
[epoch6, step1127]: loss 0.039204
[epoch6, step1128]: loss 0.036600
[epoch6, step1129]: loss 0.036071
[epoch6, step1130]: loss 0.040059
[epoch6, step1131]: loss 0.038227
[epoch6, step1132]: loss 0.037844
[epoch6, step1133]: loss 0.036014
[epoch6, step1134]: loss 0.037564
[epoch6, step1135]: loss 0.038870
[epoch6, step1136]: loss 0.039822
[epoch6, step1137]: loss 0.036507
[epoch6, step1138]: loss 0.036414
[epoch6, step1139]: loss 0.039178
[epoch6, step1140]: loss 0.037233
[epoch6, step1141]: loss 0.037128
[epoch6, step1142]: loss 0.036160
[epoch6, step1143]: loss 0.037230
[epoch6, step1144]: loss 0.038067
[epoch6, step1145]: loss 0.038479
[epoch6, step1146]: loss 0.036049
[epoch6, step1147]: loss 0.036897
[epoch6, step1148]: loss 0.039266
[epoch6, step1149]: loss 0.037448
[epoch6, step1150]: loss 0.037241
[epoch6, step1151]: loss 0.036690
[epoch6, step1152]: loss 0.038147
[epoch6, step1153]: loss 0.037300
[epoch6, step1154]: loss 0.039271
[epoch6, step1155]: loss 0.036436
[epoch6, step1156]: loss 0.035324
[epoch6, step1157]: loss 0.038748
[epoch6, step1158]: loss 0.037825
[epoch6, step1159]: loss 0.037376
[epoch6, step1160]: loss 0.036837
[epoch6, step1161]: loss 0.037910
[epoch6, step1162]: loss 0.037711
[epoch6, step1163]: loss 0.038134
[epoch6, step1164]: loss 0.035953
[epoch6, step1165]: loss 0.037069
[epoch6, step1166]: loss 0.039245
[epoch6, step1167]: loss 0.036646
[epoch6, step1168]: loss 0.037578
[epoch6, step1169]: loss 0.035725
[epoch6, step1170]: loss 0.037520
[epoch6, step1171]: loss 0.037773
[epoch6, step1172]: loss 0.038431
[epoch6, step1173]: loss 0.036119
[epoch6, step1174]: loss 0.036014
[epoch6, step1175]: loss 0.038745
[epoch6, step1176]: loss 0.037106
[epoch6, step1177]: loss 0.037244
[epoch6, step1178]: loss 0.035988
[epoch6, step1179]: loss 0.037358
[epoch6, step1180]: loss 0.037682
[epoch6, step1181]: loss 0.039351
[epoch6, step1182]: loss 0.035308
[epoch6, step1183]: loss 0.036448
[epoch6, step1184]: loss 0.038600
[epoch6, step1185]: loss 0.037447
[epoch6, step1186]: loss 0.036582
[epoch6, step1187]: loss 0.035139
[epoch6, step1188]: loss 0.036648
[epoch6, step1189]: loss 0.037346
[epoch6, step1190]: loss 0.038039
[epoch6, step1191]: loss 0.036511
[epoch6, step1192]: loss 0.035767
[epoch6, step1193]: loss 0.038688
[epoch6, step1194]: loss 0.037229
[epoch6, step1195]: loss 0.035805
[epoch6, step1196]: loss 0.035273
[epoch6, step1197]: loss 0.037784
[epoch6, step1198]: loss 0.037591
[epoch6, step1199]: loss 0.038338
[epoch6, step1200]: loss 0.035564
[epoch6, step1201]: loss 0.036503
[epoch6, step1202]: loss 0.039851
[epoch6, step1203]: loss 0.037438
[epoch6, step1204]: loss 0.036499
[epoch6, step1205]: loss 0.035219
[epoch6, step1206]: loss 0.036890
[epoch6, step1207]: loss 0.037725
[epoch6, step1208]: loss 0.039045
[epoch6, step1209]: loss 0.034908
[epoch6, step1210]: loss 0.036283
[epoch6, step1211]: loss 0.038549
[epoch6, step1212]: loss 0.037080
[epoch6, step1213]: loss 0.036798
[epoch6, step1214]: loss 0.035947
[epoch6, step1215]: loss 0.038149
[epoch6, step1216]: loss 0.037203
[epoch6, step1217]: loss 0.039030
[epoch6, step1218]: loss 0.035511
[epoch6, step1219]: loss 0.036348
[epoch6, step1220]: loss 0.039177
[epoch6, step1221]: loss 0.036594
[epoch6, step1222]: loss 0.037141
[epoch6, step1223]: loss 0.035815
[epoch6, step1224]: loss 0.037914
[epoch6, step1225]: loss 0.037563
[epoch6, step1226]: loss 0.038509
[epoch6, step1227]: loss 0.036042
[epoch6, step1228]: loss 0.035654
[epoch6, step1229]: loss 0.038875
[epoch6, step1230]: loss 0.037538
[epoch6, step1231]: loss 0.037181
[epoch6, step1232]: loss 0.037087
[epoch6, step1233]: loss 0.037085
[epoch6, step1234]: loss 0.037312
[epoch6, step1235]: loss 0.038856
[epoch6, step1236]: loss 0.036049
[epoch6, step1237]: loss 0.035164
[epoch6, step1238]: loss 0.038256
[epoch6, step1239]: loss 0.037908
[epoch6, step1240]: loss 0.037191
[epoch6, step1241]: loss 0.035478
[epoch6, step1242]: loss 0.037346
[epoch6, step1243]: loss 0.037559
[epoch6, step1244]: loss 0.038959
[epoch6, step1245]: loss 0.036283
[epoch6, step1246]: loss 0.036257
[epoch6, step1247]: loss 0.037931
[epoch6, step1248]: loss 0.037532
[epoch6, step1249]: loss 0.038000
[epoch6, step1250]: loss 0.035585
[epoch6, step1251]: loss 0.038085
[epoch6, step1252]: loss 0.038695
[epoch6, step1253]: loss 0.038881
[epoch6, step1254]: loss 0.036048
[epoch6, step1255]: loss 0.035752
[epoch6, step1256]: loss 0.039219
[epoch6, step1257]: loss 0.037580
[epoch6, step1258]: loss 0.037207
[epoch6, step1259]: loss 0.035665
[epoch6, step1260]: loss 0.037510
[epoch6, step1261]: loss 0.037387
[epoch6, step1262]: loss 0.037443
[epoch6, step1263]: loss 0.036497
[epoch6, step1264]: loss 0.035737
[epoch6, step1265]: loss 0.037652
[epoch6, step1266]: loss 0.037489
[epoch6, step1267]: loss 0.037412
[epoch6, step1268]: loss 0.036085
[epoch6, step1269]: loss 0.037711
[epoch6, step1270]: loss 0.036762
[epoch6, step1271]: loss 0.039324
[epoch6, step1272]: loss 0.036388
[epoch6, step1273]: loss 0.035380
[epoch6, step1274]: loss 0.038876
[epoch6, step1275]: loss 0.037647
[epoch6, step1276]: loss 0.036984
[epoch6, step1277]: loss 0.035811
[epoch6, step1278]: loss 0.038127
[epoch6, step1279]: loss 0.037888
[epoch6, step1280]: loss 0.038861
[epoch6, step1281]: loss 0.035822
[epoch6, step1282]: loss 0.035923
[epoch6, step1283]: loss 0.038282
[epoch6, step1284]: loss 0.036804
[epoch6, step1285]: loss 0.037657
[epoch6, step1286]: loss 0.035175
[epoch6, step1287]: loss 0.038238
[epoch6, step1288]: loss 0.038370
[epoch6, step1289]: loss 0.039374
[epoch6, step1290]: loss 0.036000
[epoch6, step1291]: loss 0.035488
[epoch6, step1292]: loss 0.039651
[epoch6, step1293]: loss 0.036667
[epoch6, step1294]: loss 0.037151
[epoch6, step1295]: loss 0.036286
[epoch6, step1296]: loss 0.037710
[epoch6, step1297]: loss 0.037399
[epoch6, step1298]: loss 0.039331
[epoch6, step1299]: loss 0.036282
[epoch6, step1300]: loss 0.036773
[epoch6, step1301]: loss 0.038034
[epoch6, step1302]: loss 0.037399
[epoch6, step1303]: loss 0.037363
[epoch6, step1304]: loss 0.035105
[epoch6, step1305]: loss 0.038076
[epoch6, step1306]: loss 0.037660
[epoch6, step1307]: loss 0.038315
[epoch6, step1308]: loss 0.036156
[epoch6, step1309]: loss 0.035299
[epoch6, step1310]: loss 0.038908
[epoch6, step1311]: loss 0.036422
[epoch6, step1312]: loss 0.037963
[epoch6, step1313]: loss 0.035903
[epoch6, step1314]: loss 0.037354
[epoch6, step1315]: loss 0.037188
[epoch6, step1316]: loss 0.040025
[epoch6, step1317]: loss 0.035492
[epoch6, step1318]: loss 0.035346
[epoch6, step1319]: loss 0.038312
[epoch6, step1320]: loss 0.037481
[epoch6, step1321]: loss 0.037657
[epoch6, step1322]: loss 0.035438
[epoch6, step1323]: loss 0.037904
[epoch6, step1324]: loss 0.037211
[epoch6, step1325]: loss 0.038406
[epoch6, step1326]: loss 0.035712
[epoch6, step1327]: loss 0.035614
[epoch6, step1328]: loss 0.038816
[epoch6, step1329]: loss 0.037177
[epoch6, step1330]: loss 0.037284
[epoch6, step1331]: loss 0.035506
[epoch6, step1332]: loss 0.037375
[epoch6, step1333]: loss 0.036526
[epoch6, step1334]: loss 0.039078
[epoch6, step1335]: loss 0.036528
[epoch6, step1336]: loss 0.035901
[epoch6, step1337]: loss 0.038350
[epoch6, step1338]: loss 0.037268
[epoch6, step1339]: loss 0.037381
[epoch6, step1340]: loss 0.035500
[epoch6, step1341]: loss 0.037795
[epoch6, step1342]: loss 0.037433
[epoch6, step1343]: loss 0.038622
[epoch6, step1344]: loss 0.036080
[epoch6, step1345]: loss 0.035661
[epoch6, step1346]: loss 0.038257
[epoch6, step1347]: loss 0.037878
[epoch6, step1348]: loss 0.036348
[epoch6, step1349]: loss 0.035891
[epoch6, step1350]: loss 0.037708
[epoch6, step1351]: loss 0.036984
[epoch6, step1352]: loss 0.038378
[epoch6, step1353]: loss 0.035574
[epoch6, step1354]: loss 0.035656
[epoch6, step1355]: loss 0.039040
[epoch6, step1356]: loss 0.036937
[epoch6, step1357]: loss 0.036817
[epoch6, step1358]: loss 0.035687
[epoch6, step1359]: loss 0.037137
[epoch6, step1360]: loss 0.037773
[epoch6, step1361]: loss 0.038779
[epoch6, step1362]: loss 0.036518
[epoch6, step1363]: loss 0.036198
[epoch6, step1364]: loss 0.038535
[epoch6, step1365]: loss 0.037412
[epoch6, step1366]: loss 0.036850
[epoch6, step1367]: loss 0.035014
[epoch6, step1368]: loss 0.038493
[epoch6, step1369]: loss 0.037626
[epoch6, step1370]: loss 0.038615
[epoch6, step1371]: loss 0.036414
[epoch6, step1372]: loss 0.035646
[epoch6, step1373]: loss 0.038863
[epoch6, step1374]: loss 0.038104
[epoch6, step1375]: loss 0.037919
[epoch6, step1376]: loss 0.035476
[epoch6, step1377]: loss 0.036917
[epoch6, step1378]: loss 0.037491
[epoch6, step1379]: loss 0.038372
[epoch6, step1380]: loss 0.036415
[epoch6, step1381]: loss 0.035805
[epoch6, step1382]: loss 0.039082
[epoch6, step1383]: loss 0.037235
[epoch6, step1384]: loss 0.036990
[epoch6, step1385]: loss 0.035024
[epoch6, step1386]: loss 0.037770
[epoch6, step1387]: loss 0.037961
[epoch6, step1388]: loss 0.037711
[epoch6, step1389]: loss 0.035392
[epoch6, step1390]: loss 0.035905
[epoch6, step1391]: loss 0.038483
[epoch6, step1392]: loss 0.037223
[epoch6, step1393]: loss 0.037317
[epoch6, step1394]: loss 0.036266
[epoch6, step1395]: loss 0.037620
[epoch6, step1396]: loss 0.036983
[epoch6, step1397]: loss 0.038428
[epoch6, step1398]: loss 0.035819
[epoch6, step1399]: loss 0.036688
[epoch6, step1400]: loss 0.039357
[epoch6, step1401]: loss 0.036946
[epoch6, step1402]: loss 0.037411
[epoch6, step1403]: loss 0.034765
[epoch6, step1404]: loss 0.036909
[epoch6, step1405]: loss 0.037291
[epoch6, step1406]: loss 0.038257
[epoch6, step1407]: loss 0.036865
[epoch6, step1408]: loss 0.035138
[epoch6, step1409]: loss 0.038255
[epoch6, step1410]: loss 0.037218
[epoch6, step1411]: loss 0.036007
[epoch6, step1412]: loss 0.035747
[epoch6, step1413]: loss 0.037541
[epoch6, step1414]: loss 0.036987
[epoch6, step1415]: loss 0.038393
[epoch6, step1416]: loss 0.035683
[epoch6, step1417]: loss 0.035844
[epoch6, step1418]: loss 0.038867
[epoch6, step1419]: loss 0.037865
[epoch6, step1420]: loss 0.037521
[epoch6, step1421]: loss 0.036174
[epoch6, step1422]: loss 0.037659
[epoch6, step1423]: loss 0.037051
[epoch6, step1424]: loss 0.038648
[epoch6, step1425]: loss 0.034940
[epoch6, step1426]: loss 0.035756
[epoch6, step1427]: loss 0.039488
[epoch6, step1428]: loss 0.038034
[epoch6, step1429]: loss 0.036892
[epoch6, step1430]: loss 0.035820
[epoch6, step1431]: loss 0.037755
[epoch6, step1432]: loss 0.037108
[epoch6, step1433]: loss 0.039020
[epoch6, step1434]: loss 0.035804
[epoch6, step1435]: loss 0.036009
[epoch6, step1436]: loss 0.039078
[epoch6, step1437]: loss 0.037565
[epoch6, step1438]: loss 0.037843
[epoch6, step1439]: loss 0.035501
[epoch6, step1440]: loss 0.037229
[epoch6, step1441]: loss 0.038028
[epoch6, step1442]: loss 0.037819
[epoch6, step1443]: loss 0.035575
[epoch6, step1444]: loss 0.035079
[epoch6, step1445]: loss 0.039058
[epoch6, step1446]: loss 0.037431
[epoch6, step1447]: loss 0.037778
[epoch6, step1448]: loss 0.035605
[epoch6, step1449]: loss 0.036979
[epoch6, step1450]: loss 0.037391
[epoch6, step1451]: loss 0.038967
[epoch6, step1452]: loss 0.035546
[epoch6, step1453]: loss 0.036903
[epoch6, step1454]: loss 0.039295
[epoch6, step1455]: loss 0.037829
[epoch6, step1456]: loss 0.036917
[epoch6, step1457]: loss 0.036361
[epoch6, step1458]: loss 0.037492
[epoch6, step1459]: loss 0.037463
[epoch6, step1460]: loss 0.038908
[epoch6, step1461]: loss 0.036487
[epoch6, step1462]: loss 0.036303
[epoch6, step1463]: loss 0.038565
[epoch6, step1464]: loss 0.037542
[epoch6, step1465]: loss 0.036565
[epoch6, step1466]: loss 0.035445
[epoch6, step1467]: loss 0.037525
[epoch6, step1468]: loss 0.036877
[epoch6, step1469]: loss 0.038757
[epoch6, step1470]: loss 0.036122
[epoch6, step1471]: loss 0.035490
[epoch6, step1472]: loss 0.038580
[epoch6, step1473]: loss 0.037177
[epoch6, step1474]: loss 0.037765
[epoch6, step1475]: loss 0.035417
[epoch6, step1476]: loss 0.038286
[epoch6, step1477]: loss 0.037169
[epoch6, step1478]: loss 0.038587
[epoch6, step1479]: loss 0.035801
[epoch6, step1480]: loss 0.035677
[epoch6, step1481]: loss 0.037823
[epoch6, step1482]: loss 0.037181
[epoch6, step1483]: loss 0.037125
[epoch6, step1484]: loss 0.035967
[epoch6, step1485]: loss 0.037244
[epoch6, step1486]: loss 0.036294
[epoch6, step1487]: loss 0.038450
[epoch6, step1488]: loss 0.035874
[epoch6, step1489]: loss 0.035727
[epoch6, step1490]: loss 0.038837
[epoch6, step1491]: loss 0.037248
[epoch6, step1492]: loss 0.037031
[epoch6, step1493]: loss 0.035730
[epoch6, step1494]: loss 0.037578
[epoch6, step1495]: loss 0.037314
[epoch6, step1496]: loss 0.037588
[epoch6, step1497]: loss 0.036101
[epoch6, step1498]: loss 0.035972
[epoch6, step1499]: loss 0.038053
[epoch6, step1500]: loss 0.037489
[epoch6, step1501]: loss 0.037122
[epoch6, step1502]: loss 0.035648
[epoch6, step1503]: loss 0.037439
[epoch6, step1504]: loss 0.036906
[epoch6, step1505]: loss 0.038972
[epoch6, step1506]: loss 0.035202
[epoch6, step1507]: loss 0.036231
[epoch6, step1508]: loss 0.039405
[epoch6, step1509]: loss 0.036936
[epoch6, step1510]: loss 0.036873
[epoch6, step1511]: loss 0.036482
[epoch6, step1512]: loss 0.037718
[epoch6, step1513]: loss 0.036250
[epoch6, step1514]: loss 0.038604
[epoch6, step1515]: loss 0.036303
[epoch6, step1516]: loss 0.035771

[epoch6]: avg loss 0.034209

[epoch7, step1]: loss 0.037228
[epoch7, step2]: loss 0.038194
[epoch7, step3]: loss 0.038459
[epoch7, step4]: loss 0.035657
[epoch7, step5]: loss 0.036098
[epoch7, step6]: loss 0.038573
[epoch7, step7]: loss 0.036742
[epoch7, step8]: loss 0.038661
[epoch7, step9]: loss 0.035581
[epoch7, step10]: loss 0.037227
[epoch7, step11]: loss 0.038640
[epoch7, step12]: loss 0.038775
[epoch7, step13]: loss 0.036524
[epoch7, step14]: loss 0.036206
[epoch7, step15]: loss 0.038711
[epoch7, step16]: loss 0.036740
[epoch7, step17]: loss 0.038840
[epoch7, step18]: loss 0.036546
[epoch7, step19]: loss 0.036460
[epoch7, step20]: loss 0.039417
[epoch7, step21]: loss 0.038410
[epoch7, step22]: loss 0.035661
[epoch7, step23]: loss 0.035186
[epoch7, step24]: loss 0.038887
[epoch7, step25]: loss 0.035984
[epoch7, step26]: loss 0.038081
[epoch7, step27]: loss 0.035504
[epoch7, step28]: loss 0.037444
[epoch7, step29]: loss 0.039267
[epoch7, step30]: loss 0.039019
[epoch7, step31]: loss 0.035577
[epoch7, step32]: loss 0.036688
[epoch7, step33]: loss 0.039205
[epoch7, step34]: loss 0.037149
[epoch7, step35]: loss 0.038962
[epoch7, step36]: loss 0.035568
[epoch7, step37]: loss 0.036281
[epoch7, step38]: loss 0.038601
[epoch7, step39]: loss 0.038350
[epoch7, step40]: loss 0.035987
[epoch7, step41]: loss 0.035266
[epoch7, step42]: loss 0.038890
[epoch7, step43]: loss 0.036256
[epoch7, step44]: loss 0.039101
[epoch7, step45]: loss 0.035798
[epoch7, step46]: loss 0.036360
[epoch7, step47]: loss 0.038368
[epoch7, step48]: loss 0.038443
[epoch7, step49]: loss 0.034164
[epoch7, step50]: loss 0.036329
[epoch7, step51]: loss 0.038807
[epoch7, step52]: loss 0.036104
[epoch7, step53]: loss 0.039483
[epoch7, step54]: loss 0.035813
[epoch7, step55]: loss 0.036679
[epoch7, step56]: loss 0.039556
[epoch7, step57]: loss 0.038885
[epoch7, step58]: loss 0.035646
[epoch7, step59]: loss 0.034828
[epoch7, step60]: loss 0.039235
[epoch7, step61]: loss 0.035435
[epoch7, step62]: loss 0.037913
[epoch7, step63]: loss 0.035061
[epoch7, step64]: loss 0.035886
[epoch7, step65]: loss 0.038854
[epoch7, step66]: loss 0.038492
[epoch7, step67]: loss 0.035971
[epoch7, step68]: loss 0.036073
[epoch7, step69]: loss 0.038471
[epoch7, step70]: loss 0.036310
[epoch7, step71]: loss 0.038452
[epoch7, step72]: loss 0.035608
[epoch7, step73]: loss 0.036582
[epoch7, step74]: loss 0.038537
[epoch7, step75]: loss 0.039253
[epoch7, step76]: loss 0.036595
[epoch7, step77]: loss 0.036365
[epoch7, step78]: loss 0.039124
[epoch7, step79]: loss 0.035556
[epoch7, step80]: loss 0.039390
[epoch7, step81]: loss 0.035622
[epoch7, step82]: loss 0.035871
[epoch7, step83]: loss 0.038270
[epoch7, step84]: loss 0.038682
[epoch7, step85]: loss 0.036342
[epoch7, step86]: loss 0.036289
[epoch7, step87]: loss 0.039678
[epoch7, step88]: loss 0.035264
[epoch7, step89]: loss 0.038463
[epoch7, step90]: loss 0.036156
[epoch7, step91]: loss 0.035897
[epoch7, step92]: loss 0.038785
[epoch7, step93]: loss 0.038776
[epoch7, step94]: loss 0.035590
[epoch7, step95]: loss 0.036362
[epoch7, step96]: loss 0.038388
[epoch7, step97]: loss 0.036847
[epoch7, step98]: loss 0.038825
[epoch7, step99]: loss 0.035666
[epoch7, step100]: loss 0.035299
[epoch7, step101]: loss 0.039240
[epoch7, step102]: loss 0.038533
[epoch7, step103]: loss 0.035667
[epoch7, step104]: loss 0.036063
[epoch7, step105]: loss 0.039071
[epoch7, step106]: loss 0.036204
[epoch7, step107]: loss 0.039001
[epoch7, step108]: loss 0.036093
[epoch7, step109]: loss 0.036014
[epoch7, step110]: loss 0.039390
[epoch7, step111]: loss 0.038245
[epoch7, step112]: loss 0.035947
[epoch7, step113]: loss 0.036640
[epoch7, step114]: loss 0.038423
[epoch7, step115]: loss 0.036091
[epoch7, step116]: loss 0.039559
[epoch7, step117]: loss 0.035534
[epoch7, step118]: loss 0.037106
[epoch7, step119]: loss 0.039219
[epoch7, step120]: loss 0.039004
[epoch7, step121]: loss 0.035625
[epoch7, step122]: loss 0.036011
[epoch7, step123]: loss 0.039141
[epoch7, step124]: loss 0.036721
[epoch7, step125]: loss 0.039409
[epoch7, step126]: loss 0.035794
[epoch7, step127]: loss 0.036305
[epoch7, step128]: loss 0.038737
[epoch7, step129]: loss 0.038472
[epoch7, step130]: loss 0.035999
[epoch7, step131]: loss 0.035350
[epoch7, step132]: loss 0.038808
[epoch7, step133]: loss 0.036125
[epoch7, step134]: loss 0.038066
[epoch7, step135]: loss 0.036267
[epoch7, step136]: loss 0.037359
[epoch7, step137]: loss 0.038431
[epoch7, step138]: loss 0.038612
[epoch7, step139]: loss 0.035697
[epoch7, step140]: loss 0.036641
[epoch7, step141]: loss 0.039219
[epoch7, step142]: loss 0.036189
[epoch7, step143]: loss 0.038443
[epoch7, step144]: loss 0.036129
[epoch7, step145]: loss 0.036329
[epoch7, step146]: loss 0.038862
[epoch7, step147]: loss 0.039753
[epoch7, step148]: loss 0.035475
[epoch7, step149]: loss 0.035539
[epoch7, step150]: loss 0.038588
[epoch7, step151]: loss 0.036265
[epoch7, step152]: loss 0.038496
[epoch7, step153]: loss 0.035760
[epoch7, step154]: loss 0.036017
[epoch7, step155]: loss 0.038538
[epoch7, step156]: loss 0.038240
[epoch7, step157]: loss 0.035825
[epoch7, step158]: loss 0.036321
[epoch7, step159]: loss 0.039056
[epoch7, step160]: loss 0.036449
[epoch7, step161]: loss 0.039338
[epoch7, step162]: loss 0.036012
[epoch7, step163]: loss 0.036318
[epoch7, step164]: loss 0.039113
[epoch7, step165]: loss 0.038494
[epoch7, step166]: loss 0.036198
[epoch7, step167]: loss 0.035462
[epoch7, step168]: loss 0.039413
[epoch7, step169]: loss 0.035874
[epoch7, step170]: loss 0.038943
[epoch7, step171]: loss 0.036105
[epoch7, step172]: loss 0.036398
[epoch7, step173]: loss 0.038992
[epoch7, step174]: loss 0.038446
[epoch7, step175]: loss 0.036438
[epoch7, step176]: loss 0.036346
[epoch7, step177]: loss 0.039120
[epoch7, step178]: loss 0.036314
[epoch7, step179]: loss 0.038183
[epoch7, step180]: loss 0.036018
[epoch7, step181]: loss 0.036675
[epoch7, step182]: loss 0.039521
[epoch7, step183]: loss 0.039210
[epoch7, step184]: loss 0.036980
[epoch7, step185]: loss 0.036349
[epoch7, step186]: loss 0.038879
[epoch7, step187]: loss 0.036411
[epoch7, step188]: loss 0.038306
[epoch7, step189]: loss 0.035791
[epoch7, step190]: loss 0.035541
[epoch7, step191]: loss 0.038680
[epoch7, step192]: loss 0.039174
[epoch7, step193]: loss 0.034059
[epoch7, step194]: loss 0.035144
[epoch7, step195]: loss 0.039058
[epoch7, step196]: loss 0.036407
[epoch7, step197]: loss 0.038410
[epoch7, step198]: loss 0.035199
[epoch7, step199]: loss 0.036503
[epoch7, step200]: loss 0.039201
[epoch7, step201]: loss 0.039370
[epoch7, step202]: loss 0.035614
[epoch7, step203]: loss 0.036051
[epoch7, step204]: loss 0.039416
[epoch7, step205]: loss 0.035699
[epoch7, step206]: loss 0.038410
[epoch7, step207]: loss 0.035646
[epoch7, step208]: loss 0.036831
[epoch7, step209]: loss 0.039123
[epoch7, step210]: loss 0.039619
[epoch7, step211]: loss 0.036497
[epoch7, step212]: loss 0.036485
[epoch7, step213]: loss 0.038517
[epoch7, step214]: loss 0.035624
[epoch7, step215]: loss 0.039045
[epoch7, step216]: loss 0.036050
[epoch7, step217]: loss 0.035640
[epoch7, step218]: loss 0.039067
[epoch7, step219]: loss 0.038558
[epoch7, step220]: loss 0.036285
[epoch7, step221]: loss 0.036251
[epoch7, step222]: loss 0.039308
[epoch7, step223]: loss 0.036348
[epoch7, step224]: loss 0.038345
[epoch7, step225]: loss 0.035728
[epoch7, step226]: loss 0.036062
[epoch7, step227]: loss 0.037857
[epoch7, step228]: loss 0.039399
[epoch7, step229]: loss 0.035045
[epoch7, step230]: loss 0.036456
[epoch7, step231]: loss 0.039497
[epoch7, step232]: loss 0.035971
[epoch7, step233]: loss 0.038121
[epoch7, step234]: loss 0.035453
[epoch7, step235]: loss 0.036623
[epoch7, step236]: loss 0.038930
[epoch7, step237]: loss 0.038692
[epoch7, step238]: loss 0.035673
[epoch7, step239]: loss 0.035277
[epoch7, step240]: loss 0.038382
[epoch7, step241]: loss 0.036620
[epoch7, step242]: loss 0.038512
[epoch7, step243]: loss 0.036551
[epoch7, step244]: loss 0.036128
[epoch7, step245]: loss 0.038290
[epoch7, step246]: loss 0.038778
[epoch7, step247]: loss 0.036136
[epoch7, step248]: loss 0.035796
[epoch7, step249]: loss 0.038440
[epoch7, step250]: loss 0.036538
[epoch7, step251]: loss 0.039339
[epoch7, step252]: loss 0.036327
[epoch7, step253]: loss 0.035912
[epoch7, step254]: loss 0.038653
[epoch7, step255]: loss 0.038890
[epoch7, step256]: loss 0.035715
[epoch7, step257]: loss 0.035658
[epoch7, step258]: loss 0.039422
[epoch7, step259]: loss 0.036324
[epoch7, step260]: loss 0.038115
[epoch7, step261]: loss 0.036625
[epoch7, step262]: loss 0.036670
[epoch7, step263]: loss 0.038239
[epoch7, step264]: loss 0.038512
[epoch7, step265]: loss 0.036037
[epoch7, step266]: loss 0.036057
[epoch7, step267]: loss 0.038267
[epoch7, step268]: loss 0.036192
[epoch7, step269]: loss 0.038815
[epoch7, step270]: loss 0.035350
[epoch7, step271]: loss 0.036404
[epoch7, step272]: loss 0.038691
[epoch7, step273]: loss 0.038518
[epoch7, step274]: loss 0.036460
[epoch7, step275]: loss 0.035489
[epoch7, step276]: loss 0.038628
[epoch7, step277]: loss 0.036646
[epoch7, step278]: loss 0.038865
[epoch7, step279]: loss 0.035460
[epoch7, step280]: loss 0.036382
[epoch7, step281]: loss 0.038629
[epoch7, step282]: loss 0.039251
[epoch7, step283]: loss 0.035499
[epoch7, step284]: loss 0.035592
[epoch7, step285]: loss 0.039703
[epoch7, step286]: loss 0.035478
[epoch7, step287]: loss 0.039050
[epoch7, step288]: loss 0.035417
[epoch7, step289]: loss 0.037084
[epoch7, step290]: loss 0.038831
[epoch7, step291]: loss 0.039064
[epoch7, step292]: loss 0.035249
[epoch7, step293]: loss 0.035608
[epoch7, step294]: loss 0.038471
[epoch7, step295]: loss 0.035627
[epoch7, step296]: loss 0.039478
[epoch7, step297]: loss 0.035592
[epoch7, step298]: loss 0.036715
[epoch7, step299]: loss 0.037905
[epoch7, step300]: loss 0.039055
[epoch7, step301]: loss 0.035921
[epoch7, step302]: loss 0.036442
[epoch7, step303]: loss 0.039287
[epoch7, step304]: loss 0.035976
[epoch7, step305]: loss 0.038540
[epoch7, step306]: loss 0.035895
[epoch7, step307]: loss 0.036081
[epoch7, step308]: loss 0.039289
[epoch7, step309]: loss 0.039118
[epoch7, step310]: loss 0.036187
[epoch7, step311]: loss 0.036383
[epoch7, step312]: loss 0.038578
[epoch7, step313]: loss 0.036537
[epoch7, step314]: loss 0.038687
[epoch7, step315]: loss 0.036782
[epoch7, step316]: loss 0.036046
[epoch7, step317]: loss 0.039193
[epoch7, step318]: loss 0.038786
[epoch7, step319]: loss 0.035390
[epoch7, step320]: loss 0.035108
[epoch7, step321]: loss 0.038502
[epoch7, step322]: loss 0.036014
[epoch7, step323]: loss 0.038124
[epoch7, step324]: loss 0.036646
[epoch7, step325]: loss 0.036480
[epoch7, step326]: loss 0.038595
[epoch7, step327]: loss 0.038117
[epoch7, step328]: loss 0.036184
[epoch7, step329]: loss 0.035733
[epoch7, step330]: loss 0.038372
[epoch7, step331]: loss 0.036356
[epoch7, step332]: loss 0.038071
[epoch7, step333]: loss 0.035741
[epoch7, step334]: loss 0.036391
[epoch7, step335]: loss 0.038795
[epoch7, step336]: loss 0.039608
[epoch7, step337]: loss 0.036328
[epoch7, step338]: loss 0.035690
[epoch7, step339]: loss 0.038990
[epoch7, step340]: loss 0.036760
[epoch7, step341]: loss 0.038296
[epoch7, step342]: loss 0.035646
[epoch7, step343]: loss 0.036386
[epoch7, step344]: loss 0.038346
[epoch7, step345]: loss 0.037959
[epoch7, step346]: loss 0.035435
[epoch7, step347]: loss 0.035588
[epoch7, step348]: loss 0.038944
[epoch7, step349]: loss 0.036700
[epoch7, step350]: loss 0.038119
[epoch7, step351]: loss 0.035100
[epoch7, step352]: loss 0.036092
[epoch7, step353]: loss 0.038492
[epoch7, step354]: loss 0.037806
[epoch7, step355]: loss 0.034745
[epoch7, step356]: loss 0.036669
[epoch7, step357]: loss 0.039039
[epoch7, step358]: loss 0.034671
[epoch7, step359]: loss 0.039687
[epoch7, step360]: loss 0.034620
[epoch7, step361]: loss 0.035752
[epoch7, step362]: loss 0.039482
[epoch7, step363]: loss 0.038282
[epoch7, step364]: loss 0.035797
[epoch7, step365]: loss 0.035642
[epoch7, step366]: loss 0.039140
[epoch7, step367]: loss 0.036176
[epoch7, step368]: loss 0.038041
[epoch7, step369]: loss 0.035668
[epoch7, step370]: loss 0.036804
[epoch7, step371]: loss 0.039411
[epoch7, step372]: loss 0.038364
[epoch7, step373]: loss 0.035285
[epoch7, step374]: loss 0.035318
[epoch7, step375]: loss 0.039667
[epoch7, step376]: loss 0.036182
[epoch7, step377]: loss 0.038893
[epoch7, step378]: loss 0.036298
[epoch7, step379]: loss 0.036799
[epoch7, step380]: loss 0.039406
[epoch7, step381]: loss 0.038259
[epoch7, step382]: loss 0.036188
[epoch7, step383]: loss 0.034862
[epoch7, step384]: loss 0.038018
[epoch7, step385]: loss 0.035949
[epoch7, step386]: loss 0.038689
[epoch7, step387]: loss 0.035777
[epoch7, step388]: loss 0.037242
[epoch7, step389]: loss 0.038646
[epoch7, step390]: loss 0.039731
[epoch7, step391]: loss 0.035351
[epoch7, step392]: loss 0.036564
[epoch7, step393]: loss 0.038297
[epoch7, step394]: loss 0.036232
[epoch7, step395]: loss 0.038526
[epoch7, step396]: loss 0.035965
[epoch7, step397]: loss 0.035969
[epoch7, step398]: loss 0.038897
[epoch7, step399]: loss 0.038667
[epoch7, step400]: loss 0.035648
[epoch7, step401]: loss 0.035637
[epoch7, step402]: loss 0.038786
[epoch7, step403]: loss 0.036051
[epoch7, step404]: loss 0.039068
[epoch7, step405]: loss 0.036124
[epoch7, step406]: loss 0.036480
[epoch7, step407]: loss 0.038486
[epoch7, step408]: loss 0.038866
[epoch7, step409]: loss 0.037217
[epoch7, step410]: loss 0.036721
[epoch7, step411]: loss 0.038771
[epoch7, step412]: loss 0.035594
[epoch7, step413]: loss 0.038699
[epoch7, step414]: loss 0.035584
[epoch7, step415]: loss 0.036493
[epoch7, step416]: loss 0.038153
[epoch7, step417]: loss 0.038758
[epoch7, step418]: loss 0.035825
[epoch7, step419]: loss 0.035088
[epoch7, step420]: loss 0.038936
[epoch7, step421]: loss 0.035828
[epoch7, step422]: loss 0.038565
[epoch7, step423]: loss 0.035911
[epoch7, step424]: loss 0.036398
[epoch7, step425]: loss 0.038811
[epoch7, step426]: loss 0.039115
[epoch7, step427]: loss 0.036151
[epoch7, step428]: loss 0.035932
[epoch7, step429]: loss 0.039600
[epoch7, step430]: loss 0.036013
[epoch7, step431]: loss 0.039119
[epoch7, step432]: loss 0.035815
[epoch7, step433]: loss 0.036959
[epoch7, step434]: loss 0.038647
[epoch7, step435]: loss 0.039020
[epoch7, step436]: loss 0.035539
[epoch7, step437]: loss 0.036081
[epoch7, step438]: loss 0.039327
[epoch7, step439]: loss 0.036427
[epoch7, step440]: loss 0.038578
[epoch7, step441]: loss 0.036135
[epoch7, step442]: loss 0.036190
[epoch7, step443]: loss 0.039144
[epoch7, step444]: loss 0.038517
[epoch7, step445]: loss 0.036227
[epoch7, step446]: loss 0.036465
[epoch7, step447]: loss 0.039648
[epoch7, step448]: loss 0.036224
[epoch7, step449]: loss 0.038629
[epoch7, step450]: loss 0.035331
[epoch7, step451]: loss 0.036098
[epoch7, step452]: loss 0.038040
[epoch7, step453]: loss 0.038774
[epoch7, step454]: loss 0.035778
[epoch7, step455]: loss 0.036062
[epoch7, step456]: loss 0.038010
[epoch7, step457]: loss 0.036875
[epoch7, step458]: loss 0.038440
[epoch7, step459]: loss 0.036690
[epoch7, step460]: loss 0.036539
[epoch7, step461]: loss 0.039488
[epoch7, step462]: loss 0.038181
[epoch7, step463]: loss 0.035966
[epoch7, step464]: loss 0.035909
[epoch7, step465]: loss 0.040353
[epoch7, step466]: loss 0.036168
[epoch7, step467]: loss 0.038644
[epoch7, step468]: loss 0.035866
[epoch7, step469]: loss 0.036556
[epoch7, step470]: loss 0.039022
[epoch7, step471]: loss 0.038489
[epoch7, step472]: loss 0.036526
[epoch7, step473]: loss 0.035513
[epoch7, step474]: loss 0.038617
[epoch7, step475]: loss 0.036255
[epoch7, step476]: loss 0.039141
[epoch7, step477]: loss 0.035705
[epoch7, step478]: loss 0.035789
[epoch7, step479]: loss 0.038544
[epoch7, step480]: loss 0.037855
[epoch7, step481]: loss 0.035398
[epoch7, step482]: loss 0.035355
[epoch7, step483]: loss 0.039280
[epoch7, step484]: loss 0.036273
[epoch7, step485]: loss 0.038929
[epoch7, step486]: loss 0.036136
[epoch7, step487]: loss 0.035897
[epoch7, step488]: loss 0.039204
[epoch7, step489]: loss 0.037862
[epoch7, step490]: loss 0.036254
[epoch7, step491]: loss 0.036132
[epoch7, step492]: loss 0.038408
[epoch7, step493]: loss 0.035897
[epoch7, step494]: loss 0.038035
[epoch7, step495]: loss 0.037012
[epoch7, step496]: loss 0.036530
[epoch7, step497]: loss 0.038809
[epoch7, step498]: loss 0.038747
[epoch7, step499]: loss 0.036132
[epoch7, step500]: loss 0.035591
[epoch7, step501]: loss 0.038512
[epoch7, step502]: loss 0.035904
[epoch7, step503]: loss 0.039073
[epoch7, step504]: loss 0.035708
[epoch7, step505]: loss 0.035268
[epoch7, step506]: loss 0.039192
[epoch7, step507]: loss 0.039046
[epoch7, step508]: loss 0.036336
[epoch7, step509]: loss 0.035768
[epoch7, step510]: loss 0.038913
[epoch7, step511]: loss 0.036530
[epoch7, step512]: loss 0.038946
[epoch7, step513]: loss 0.036133
[epoch7, step514]: loss 0.036585
[epoch7, step515]: loss 0.038735
[epoch7, step516]: loss 0.039213
[epoch7, step517]: loss 0.035846
[epoch7, step518]: loss 0.036155
[epoch7, step519]: loss 0.039059
[epoch7, step520]: loss 0.035526
[epoch7, step521]: loss 0.038787
[epoch7, step522]: loss 0.035442
[epoch7, step523]: loss 0.036359
[epoch7, step524]: loss 0.038095
[epoch7, step525]: loss 0.038992
[epoch7, step526]: loss 0.035972
[epoch7, step527]: loss 0.035581
[epoch7, step528]: loss 0.038954
[epoch7, step529]: loss 0.035681
[epoch7, step530]: loss 0.039021
[epoch7, step531]: loss 0.035635
[epoch7, step532]: loss 0.036059
[epoch7, step533]: loss 0.039644
[epoch7, step534]: loss 0.038688
[epoch7, step535]: loss 0.036519
[epoch7, step536]: loss 0.036079
[epoch7, step537]: loss 0.038905
[epoch7, step538]: loss 0.036178
[epoch7, step539]: loss 0.038506
[epoch7, step540]: loss 0.035450
[epoch7, step541]: loss 0.035776
[epoch7, step542]: loss 0.038711
[epoch7, step543]: loss 0.038487
[epoch7, step544]: loss 0.035865
[epoch7, step545]: loss 0.035098
[epoch7, step546]: loss 0.039334
[epoch7, step547]: loss 0.036066
[epoch7, step548]: loss 0.038657
[epoch7, step549]: loss 0.036072
[epoch7, step550]: loss 0.036332
[epoch7, step551]: loss 0.038516
[epoch7, step552]: loss 0.038171
[epoch7, step553]: loss 0.036370
[epoch7, step554]: loss 0.035756
[epoch7, step555]: loss 0.038472
[epoch7, step556]: loss 0.035911
[epoch7, step557]: loss 0.038147
[epoch7, step558]: loss 0.036041
[epoch7, step559]: loss 0.035786
[epoch7, step560]: loss 0.038891
[epoch7, step561]: loss 0.038532
[epoch7, step562]: loss 0.035965
[epoch7, step563]: loss 0.029059
[epoch7, step564]: loss 0.028886
[epoch7, step565]: loss 0.027828
[epoch7, step566]: loss 0.034589
[epoch7, step567]: loss 0.026866
[epoch7, step568]: loss 0.025988
[epoch7, step569]: loss 0.023586
[epoch7, step570]: loss 0.031478
[epoch7, step571]: loss 0.026984
[epoch7, step572]: loss 0.025907
[epoch7, step573]: loss 0.029018
[epoch7, step574]: loss 0.027646
[epoch7, step575]: loss 0.020833
[epoch7, step576]: loss 0.021567
[epoch7, step577]: loss 0.026116
[epoch7, step578]: loss 0.018933
[epoch7, step579]: loss 0.028568
[epoch7, step580]: loss 0.020133
[epoch7, step581]: loss 0.025776
[epoch7, step582]: loss 0.025368
[epoch7, step583]: loss 0.022201
[epoch7, step584]: loss 0.023812
[epoch7, step585]: loss 0.026731
[epoch7, step586]: loss 0.021892
[epoch7, step587]: loss 0.028113
[epoch7, step588]: loss 0.023662
[epoch7, step589]: loss 0.023230
[epoch7, step590]: loss 0.027618
[epoch7, step591]: loss 0.020443
[epoch7, step592]: loss 0.025932
[epoch7, step593]: loss 0.021830
[epoch7, step594]: loss 0.026288
[epoch7, step595]: loss 0.026583
[epoch7, step596]: loss 0.022443
[epoch7, step597]: loss 0.025230
[epoch7, step598]: loss 0.026731
[epoch7, step599]: loss 0.025193
[epoch7, step600]: loss 0.027060
[epoch7, step601]: loss 0.019772
[epoch7, step602]: loss 0.022600
[epoch7, step603]: loss 0.025795
[epoch7, step604]: loss 0.026424
[epoch7, step605]: loss 0.025286
[epoch7, step606]: loss 0.025336
[epoch7, step607]: loss 0.026760
[epoch7, step608]: loss 0.025970
[epoch7, step609]: loss 0.026460
[epoch7, step610]: loss 0.026568
[epoch7, step611]: loss 0.026594
[epoch7, step612]: loss 0.025346
[epoch7, step613]: loss 0.019085
[epoch7, step614]: loss 0.024933
[epoch7, step615]: loss 0.027849
[epoch7, step616]: loss 0.024002
[epoch7, step617]: loss 0.023273
[epoch7, step618]: loss 0.025854
[epoch7, step619]: loss 0.027266
[epoch7, step620]: loss 0.024277
[epoch7, step621]: loss 0.026227
[epoch7, step622]: loss 0.020305
[epoch7, step623]: loss 0.024693
[epoch7, step624]: loss 0.026220
[epoch7, step625]: loss 0.025845
[epoch7, step626]: loss 0.027831
[epoch7, step627]: loss 0.022815
[epoch7, step628]: loss 0.025437
[epoch7, step629]: loss 0.020753
[epoch7, step630]: loss 0.023286
[epoch7, step631]: loss 0.031418
[epoch7, step632]: loss 0.023212
[epoch7, step633]: loss 0.024543
[epoch7, step634]: loss 0.027527
[epoch7, step635]: loss 0.025889
[epoch7, step636]: loss 0.020765
[epoch7, step637]: loss 0.027242
[epoch7, step638]: loss 0.026782
[epoch7, step639]: loss 0.022919
[epoch7, step640]: loss 0.029106
[epoch7, step641]: loss 0.030474
[epoch7, step642]: loss 0.024882
[epoch7, step643]: loss 0.025570
[epoch7, step644]: loss 0.025743
[epoch7, step645]: loss 0.023564
[epoch7, step646]: loss 0.026102
[epoch7, step647]: loss 0.023664
[epoch7, step648]: loss 0.022948
[epoch7, step649]: loss 0.028275
[epoch7, step650]: loss 0.022013
[epoch7, step651]: loss 0.025737
[epoch7, step652]: loss 0.026746
[epoch7, step653]: loss 0.027807
[epoch7, step654]: loss 0.023108
[epoch7, step655]: loss 0.024208
[epoch7, step656]: loss 0.021400
[epoch7, step657]: loss 0.027494
[epoch7, step658]: loss 0.025216
[epoch7, step659]: loss 0.027244
[epoch7, step660]: loss 0.023884
[epoch7, step661]: loss 0.026434
[epoch7, step662]: loss 0.023973
[epoch7, step663]: loss 0.020879
[epoch7, step664]: loss 0.025022
[epoch7, step665]: loss 0.028036
[epoch7, step666]: loss 0.026746
[epoch7, step667]: loss 0.026532
[epoch7, step668]: loss 0.022240
[epoch7, step669]: loss 0.026433
[epoch7, step670]: loss 0.026614
[epoch7, step671]: loss 0.021293
[epoch7, step672]: loss 0.023693
[epoch7, step673]: loss 0.022137
[epoch7, step674]: loss 0.021173
[epoch7, step675]: loss 0.020067
[epoch7, step676]: loss 0.024727
[epoch7, step677]: loss 0.025271
[epoch7, step678]: loss 0.023205
[epoch7, step679]: loss 0.023814
[epoch7, step680]: loss 0.030453
[epoch7, step681]: loss 0.022070
[epoch7, step682]: loss 0.026162
[epoch7, step683]: loss 0.025851
[epoch7, step684]: loss 0.024865
[epoch7, step685]: loss 0.024270
[epoch7, step686]: loss 0.027277
[epoch7, step687]: loss 0.026841
[epoch7, step688]: loss 0.022496
[epoch7, step689]: loss 0.024433
[epoch7, step690]: loss 0.025028
[epoch7, step691]: loss 0.024235
[epoch7, step692]: loss 0.022482
[epoch7, step693]: loss 0.027107
[epoch7, step694]: loss 0.022764
[epoch7, step695]: loss 0.026369
[epoch7, step696]: loss 0.026090
[epoch7, step697]: loss 0.026851
[epoch7, step698]: loss 0.024627
[epoch7, step699]: loss 0.023476
[epoch7, step700]: loss 0.021689
[epoch7, step701]: loss 0.025966
[epoch7, step702]: loss 0.021626
[epoch7, step703]: loss 0.022854
[epoch7, step704]: loss 0.025095
[epoch7, step705]: loss 0.024845
[epoch7, step706]: loss 0.023769
[epoch7, step707]: loss 0.024842
[epoch7, step708]: loss 0.026070
[epoch7, step709]: loss 0.027503
[epoch7, step710]: loss 0.023768
[epoch7, step711]: loss 0.023426
[epoch7, step712]: loss 0.026767
[epoch7, step713]: loss 0.026274
[epoch7, step714]: loss 0.021292
[epoch7, step715]: loss 0.023238
[epoch7, step716]: loss 0.025881
[epoch7, step717]: loss 0.023565
[epoch7, step718]: loss 0.024903
[epoch7, step719]: loss 0.032902
[epoch7, step720]: loss 0.024760
[epoch7, step721]: loss 0.023030
[epoch7, step722]: loss 0.030620
[epoch7, step723]: loss 0.025905
[epoch7, step724]: loss 0.022892
[epoch7, step725]: loss 0.028099
[epoch7, step726]: loss 0.022246
[epoch7, step727]: loss 0.024541
[epoch7, step728]: loss 0.026334
[epoch7, step729]: loss 0.021102
[epoch7, step730]: loss 0.022603
[epoch7, step731]: loss 0.025713
[epoch7, step732]: loss 0.025878
[epoch7, step733]: loss 0.023858
[epoch7, step734]: loss 0.022682
[epoch7, step735]: loss 0.027394
[epoch7, step736]: loss 0.025063
[epoch7, step737]: loss 0.026556
[epoch7, step738]: loss 0.020654
[epoch7, step739]: loss 0.025474
[epoch7, step740]: loss 0.022282
[epoch7, step741]: loss 0.025020
[epoch7, step742]: loss 0.021651
[epoch7, step743]: loss 0.023164
[epoch7, step744]: loss 0.024003
[epoch7, step745]: loss 0.024546
[epoch7, step746]: loss 0.025063
[epoch7, step747]: loss 0.027235
[epoch7, step748]: loss 0.025853
[epoch7, step749]: loss 0.026227
[epoch7, step750]: loss 0.027718
[epoch7, step751]: loss 0.021738
[epoch7, step752]: loss 0.025246
[epoch7, step753]: loss 0.025731
[epoch7, step754]: loss 0.022501
[epoch7, step755]: loss 0.025993
[epoch7, step756]: loss 0.023684
[epoch7, step757]: loss 0.020614
[epoch7, step758]: loss 0.025352
[epoch7, step759]: loss 0.023182
[epoch7, step760]: loss 0.024127
[epoch7, step761]: loss 0.026452
[epoch7, step762]: loss 0.021459
[epoch7, step763]: loss 0.025398
[epoch7, step764]: loss 0.023536
[epoch7, step765]: loss 0.026103
[epoch7, step766]: loss 0.024571
[epoch7, step767]: loss 0.026668
[epoch7, step768]: loss 0.021367
[epoch7, step769]: loss 0.026635
[epoch7, step770]: loss 0.025837
[epoch7, step771]: loss 0.023333
[epoch7, step772]: loss 0.028718
[epoch7, step773]: loss 0.026518
[epoch7, step774]: loss 0.024219
[epoch7, step775]: loss 0.020549
[epoch7, step776]: loss 0.025575
[epoch7, step777]: loss 0.022861
[epoch7, step778]: loss 0.027968
[epoch7, step779]: loss 0.023764
[epoch7, step780]: loss 0.020115
[epoch7, step781]: loss 0.024324
[epoch7, step782]: loss 0.022611
[epoch7, step783]: loss 0.019281
[epoch7, step784]: loss 0.020158
[epoch7, step785]: loss 0.021436
[epoch7, step786]: loss 0.024205
[epoch7, step787]: loss 0.023079
[epoch7, step788]: loss 0.024800
[epoch7, step789]: loss 0.022402
[epoch7, step790]: loss 0.023155
[epoch7, step791]: loss 0.026672
[epoch7, step792]: loss 0.025024
[epoch7, step793]: loss 0.026861
[epoch7, step794]: loss 0.020372
[epoch7, step795]: loss 0.025546
[epoch7, step796]: loss 0.027719
[epoch7, step797]: loss 0.027694
[epoch7, step798]: loss 0.027118
[epoch7, step799]: loss 0.025763
[epoch7, step800]: loss 0.021277
[epoch7, step801]: loss 0.021513
[epoch7, step802]: loss 0.022655
[epoch7, step803]: loss 0.026103
[epoch7, step804]: loss 0.027185
[epoch7, step805]: loss 0.028102
[epoch7, step806]: loss 0.021201
[epoch7, step807]: loss 0.020613
[epoch7, step808]: loss 0.022830
[epoch7, step809]: loss 0.022925
[epoch7, step810]: loss 0.026066
[epoch7, step811]: loss 0.025728
[epoch7, step812]: loss 0.024599
[epoch7, step813]: loss 0.023660
[epoch7, step814]: loss 0.025058
[epoch7, step815]: loss 0.025093
[epoch7, step816]: loss 0.024109
[epoch7, step817]: loss 0.024746
[epoch7, step818]: loss 0.022480
[epoch7, step819]: loss 0.020104
[epoch7, step820]: loss 0.023729
[epoch7, step821]: loss 0.021894
[epoch7, step822]: loss 0.030421
[epoch7, step823]: loss 0.023943
[epoch7, step824]: loss 0.026625
[epoch7, step825]: loss 0.025254
[epoch7, step826]: loss 0.024438
[epoch7, step827]: loss 0.027116
[epoch7, step828]: loss 0.028850
[epoch7, step829]: loss 0.026411
[epoch7, step830]: loss 0.022473
[epoch7, step831]: loss 0.026201
[epoch7, step832]: loss 0.020800
[epoch7, step833]: loss 0.029066
[epoch7, step834]: loss 0.025428
[epoch7, step835]: loss 0.020401
[epoch7, step836]: loss 0.026963
[epoch7, step837]: loss 0.025562
[epoch7, step838]: loss 0.026106
[epoch7, step839]: loss 0.028514
[epoch7, step840]: loss 0.020639
[epoch7, step841]: loss 0.024332
[epoch7, step842]: loss 0.027501
[epoch7, step843]: loss 0.024787
[epoch7, step844]: loss 0.024946
[epoch7, step845]: loss 0.021019
[epoch7, step846]: loss 0.025344
[epoch7, step847]: loss 0.026701
[epoch7, step848]: loss 0.024890
[epoch7, step849]: loss 0.024955
[epoch7, step850]: loss 0.023085
[epoch7, step851]: loss 0.023864
[epoch7, step852]: loss 0.023039
[epoch7, step853]: loss 0.029213
[epoch7, step854]: loss 0.022700
[epoch7, step855]: loss 0.027363
[epoch7, step856]: loss 0.022110
[epoch7, step857]: loss 0.025936
[epoch7, step858]: loss 0.024360
[epoch7, step859]: loss 0.023554
[epoch7, step860]: loss 0.022578
[epoch7, step861]: loss 0.023456
[epoch7, step862]: loss 0.022833
[epoch7, step863]: loss 0.020691
[epoch7, step864]: loss 0.026338
[epoch7, step865]: loss 0.023396
[epoch7, step866]: loss 0.025065
[epoch7, step867]: loss 0.026049
[epoch7, step868]: loss 0.026547
[epoch7, step869]: loss 0.023979
[epoch7, step870]: loss 0.030767
[epoch7, step871]: loss 0.022016
[epoch7, step872]: loss 0.025256
[epoch7, step873]: loss 0.025847
[epoch7, step874]: loss 0.023703
[epoch7, step875]: loss 0.024157
[epoch7, step876]: loss 0.024244
[epoch7, step877]: loss 0.018988
[epoch7, step878]: loss 0.023302
[epoch7, step879]: loss 0.027892
[epoch7, step880]: loss 0.025522
[epoch7, step881]: loss 0.022169
[epoch7, step882]: loss 0.024148
[epoch7, step883]: loss 0.023843
[epoch7, step884]: loss 0.026430
[epoch7, step885]: loss 0.025873
[epoch7, step886]: loss 0.026390
[epoch7, step887]: loss 0.024082
[epoch7, step888]: loss 0.024487
[epoch7, step889]: loss 0.023508
[epoch7, step890]: loss 0.023518
[epoch7, step891]: loss 0.025408
[epoch7, step892]: loss 0.020831
[epoch7, step893]: loss 0.024609
[epoch7, step894]: loss 0.024790
[epoch7, step895]: loss 0.022599
[epoch7, step896]: loss 0.021782
[epoch7, step897]: loss 0.023917
[epoch7, step898]: loss 0.025384
[epoch7, step899]: loss 0.027966
[epoch7, step900]: loss 0.026793
[epoch7, step901]: loss 0.025326
[epoch7, step902]: loss 0.024109
[epoch7, step903]: loss 0.023961
[epoch7, step904]: loss 0.027988
[epoch7, step905]: loss 0.027553
[epoch7, step906]: loss 0.022382
[epoch7, step907]: loss 0.023524
[epoch7, step908]: loss 0.022320
[epoch7, step909]: loss 0.025401
[epoch7, step910]: loss 0.023028
[epoch7, step911]: loss 0.025178
[epoch7, step912]: loss 0.023743
[epoch7, step913]: loss 0.023948
[epoch7, step914]: loss 0.030249
[epoch7, step915]: loss 0.023947
[epoch7, step916]: loss 0.023800
[epoch7, step917]: loss 0.025027
[epoch7, step918]: loss 0.028456
[epoch7, step919]: loss 0.024044
[epoch7, step920]: loss 0.027366
[epoch7, step921]: loss 0.024464
[epoch7, step922]: loss 0.023027
[epoch7, step923]: loss 0.022396
[epoch7, step924]: loss 0.021174
[epoch7, step925]: loss 0.025242
[epoch7, step926]: loss 0.026471
[epoch7, step927]: loss 0.025598
[epoch7, step928]: loss 0.024825
[epoch7, step929]: loss 0.027557
[epoch7, step930]: loss 0.025592
[epoch7, step931]: loss 0.027124
[epoch7, step932]: loss 0.021583
[epoch7, step933]: loss 0.028090
[epoch7, step934]: loss 0.021911
[epoch7, step935]: loss 0.021891
[epoch7, step936]: loss 0.022307
[epoch7, step937]: loss 0.026920
[epoch7, step938]: loss 0.025150
[epoch7, step939]: loss 0.020711
[epoch7, step940]: loss 0.022932
[epoch7, step941]: loss 0.026746
[epoch7, step942]: loss 0.025381
[epoch7, step943]: loss 0.023012
[epoch7, step944]: loss 0.027545
[epoch7, step945]: loss 0.020530
[epoch7, step946]: loss 0.025430
[epoch7, step947]: loss 0.027834
[epoch7, step948]: loss 0.019254
[epoch7, step949]: loss 0.022837
[epoch7, step950]: loss 0.026489
[epoch7, step951]: loss 0.028537
[epoch7, step952]: loss 0.025076
[epoch7, step953]: loss 0.027509
[epoch7, step954]: loss 0.022143
[epoch7, step955]: loss 0.035807
[epoch7, step956]: loss 0.050494
[epoch7, step957]: loss 0.045311
[epoch7, step958]: loss 0.043162
[epoch7, step959]: loss 0.047252
[epoch7, step960]: loss 0.043806
[epoch7, step961]: loss 0.043984
[epoch7, step962]: loss 0.041475
[epoch7, step963]: loss 0.039696
[epoch7, step964]: loss 0.041258
[epoch7, step965]: loss 0.041683
[epoch7, step966]: loss 0.039266
[epoch7, step967]: loss 0.038270
[epoch7, step968]: loss 0.041154
[epoch7, step969]: loss 0.041063
[epoch7, step970]: loss 0.040816
[epoch7, step971]: loss 0.039407
[epoch7, step972]: loss 0.041103
[epoch7, step973]: loss 0.039464
[epoch7, step974]: loss 0.041767
[epoch7, step975]: loss 0.038778
[epoch7, step976]: loss 0.037841
[epoch7, step977]: loss 0.041542
[epoch7, step978]: loss 0.039540
[epoch7, step979]: loss 0.038854
[epoch7, step980]: loss 0.038036
[epoch7, step981]: loss 0.039329
[epoch7, step982]: loss 0.039092
[epoch7, step983]: loss 0.040805
[epoch7, step984]: loss 0.037179
[epoch7, step985]: loss 0.037383
[epoch7, step986]: loss 0.041312
[epoch7, step987]: loss 0.039414
[epoch7, step988]: loss 0.039422
[epoch7, step989]: loss 0.038319
[epoch7, step990]: loss 0.038851
[epoch7, step991]: loss 0.039364
[epoch7, step992]: loss 0.040173
[epoch7, step993]: loss 0.037371
[epoch7, step994]: loss 0.036379
[epoch7, step995]: loss 0.040292
[epoch7, step996]: loss 0.038394
[epoch7, step997]: loss 0.038808
[epoch7, step998]: loss 0.037971
[epoch7, step999]: loss 0.039060
[epoch7, step1000]: loss 0.038936
[epoch7, step1001]: loss 0.040040
[epoch7, step1002]: loss 0.038075
[epoch7, step1003]: loss 0.036947
[epoch7, step1004]: loss 0.040448
[epoch7, step1005]: loss 0.038146
[epoch7, step1006]: loss 0.038682
[epoch7, step1007]: loss 0.037055
[epoch7, step1008]: loss 0.038505
[epoch7, step1009]: loss 0.038677
[epoch7, step1010]: loss 0.040320
[epoch7, step1011]: loss 0.037396
[epoch7, step1012]: loss 0.037319
[epoch7, step1013]: loss 0.040286
[epoch7, step1014]: loss 0.039240
[epoch7, step1015]: loss 0.038917
[epoch7, step1016]: loss 0.036757
[epoch7, step1017]: loss 0.038220
[epoch7, step1018]: loss 0.038348
[epoch7, step1019]: loss 0.040257
[epoch7, step1020]: loss 0.036865
[epoch7, step1021]: loss 0.036341
[epoch7, step1022]: loss 0.039846
[epoch7, step1023]: loss 0.038357
[epoch7, step1024]: loss 0.039230
[epoch7, step1025]: loss 0.036302
[epoch7, step1026]: loss 0.037595
[epoch7, step1027]: loss 0.038215
[epoch7, step1028]: loss 0.039492
[epoch7, step1029]: loss 0.036833
[epoch7, step1030]: loss 0.036061
[epoch7, step1031]: loss 0.038804
[epoch7, step1032]: loss 0.038782
[epoch7, step1033]: loss 0.037758
[epoch7, step1034]: loss 0.036573
[epoch7, step1035]: loss 0.037801
[epoch7, step1036]: loss 0.038446
[epoch7, step1037]: loss 0.039387
[epoch7, step1038]: loss 0.036695
[epoch7, step1039]: loss 0.036701
[epoch7, step1040]: loss 0.039265
[epoch7, step1041]: loss 0.038050
[epoch7, step1042]: loss 0.037526
[epoch7, step1043]: loss 0.036366
[epoch7, step1044]: loss 0.038203
[epoch7, step1045]: loss 0.038361
[epoch7, step1046]: loss 0.039639
[epoch7, step1047]: loss 0.036952
[epoch7, step1048]: loss 0.036125
[epoch7, step1049]: loss 0.039609
[epoch7, step1050]: loss 0.038562
[epoch7, step1051]: loss 0.038271
[epoch7, step1052]: loss 0.036757
[epoch7, step1053]: loss 0.038592
[epoch7, step1054]: loss 0.038247
[epoch7, step1055]: loss 0.039021
[epoch7, step1056]: loss 0.036046
[epoch7, step1057]: loss 0.037039
[epoch7, step1058]: loss 0.040477
[epoch7, step1059]: loss 0.038570
[epoch7, step1060]: loss 0.038484
[epoch7, step1061]: loss 0.035807
[epoch7, step1062]: loss 0.038732
[epoch7, step1063]: loss 0.038083
[epoch7, step1064]: loss 0.039469
[epoch7, step1065]: loss 0.036727
[epoch7, step1066]: loss 0.035975
[epoch7, step1067]: loss 0.039837
[epoch7, step1068]: loss 0.037009
[epoch7, step1069]: loss 0.037480
[epoch7, step1070]: loss 0.036388
[epoch7, step1071]: loss 0.038792
[epoch7, step1072]: loss 0.038916
[epoch7, step1073]: loss 0.039193
[epoch7, step1074]: loss 0.036739
[epoch7, step1075]: loss 0.036677
[epoch7, step1076]: loss 0.039666
[epoch7, step1077]: loss 0.038235
[epoch7, step1078]: loss 0.037881
[epoch7, step1079]: loss 0.037419
[epoch7, step1080]: loss 0.038209
[epoch7, step1081]: loss 0.037944
[epoch7, step1082]: loss 0.039277
[epoch7, step1083]: loss 0.037398
[epoch7, step1084]: loss 0.036580
[epoch7, step1085]: loss 0.039000
[epoch7, step1086]: loss 0.037815
[epoch7, step1087]: loss 0.038172
[epoch7, step1088]: loss 0.036226
[epoch7, step1089]: loss 0.038755
[epoch7, step1090]: loss 0.038765
[epoch7, step1091]: loss 0.039723
[epoch7, step1092]: loss 0.036657
[epoch7, step1093]: loss 0.036419
[epoch7, step1094]: loss 0.038799
[epoch7, step1095]: loss 0.037929
[epoch7, step1096]: loss 0.037602
[epoch7, step1097]: loss 0.036467
[epoch7, step1098]: loss 0.038228
[epoch7, step1099]: loss 0.037917
[epoch7, step1100]: loss 0.039885
[epoch7, step1101]: loss 0.037100
[epoch7, step1102]: loss 0.036339
[epoch7, step1103]: loss 0.039025
[epoch7, step1104]: loss 0.037993
[epoch7, step1105]: loss 0.038444
[epoch7, step1106]: loss 0.035474
[epoch7, step1107]: loss 0.038383
[epoch7, step1108]: loss 0.037778
[epoch7, step1109]: loss 0.039800
[epoch7, step1110]: loss 0.037315
[epoch7, step1111]: loss 0.036491
[epoch7, step1112]: loss 0.040163
[epoch7, step1113]: loss 0.037978
[epoch7, step1114]: loss 0.038513
[epoch7, step1115]: loss 0.036450
[epoch7, step1116]: loss 0.038486
[epoch7, step1117]: loss 0.038233
[epoch7, step1118]: loss 0.039406
[epoch7, step1119]: loss 0.036532
[epoch7, step1120]: loss 0.036143
[epoch7, step1121]: loss 0.039485
[epoch7, step1122]: loss 0.037637
[epoch7, step1123]: loss 0.037279
[epoch7, step1124]: loss 0.037071
[epoch7, step1125]: loss 0.038565
[epoch7, step1126]: loss 0.038979
[epoch7, step1127]: loss 0.039552
[epoch7, step1128]: loss 0.036806
[epoch7, step1129]: loss 0.036337
[epoch7, step1130]: loss 0.040266
[epoch7, step1131]: loss 0.038635
[epoch7, step1132]: loss 0.038627
[epoch7, step1133]: loss 0.035777
[epoch7, step1134]: loss 0.038094
[epoch7, step1135]: loss 0.039047
[epoch7, step1136]: loss 0.039956
[epoch7, step1137]: loss 0.036699
[epoch7, step1138]: loss 0.036542
[epoch7, step1139]: loss 0.039742
[epoch7, step1140]: loss 0.037707
[epoch7, step1141]: loss 0.037738
[epoch7, step1142]: loss 0.036135
[epoch7, step1143]: loss 0.038026
[epoch7, step1144]: loss 0.038213
[epoch7, step1145]: loss 0.038825
[epoch7, step1146]: loss 0.036425
[epoch7, step1147]: loss 0.037205
[epoch7, step1148]: loss 0.039712
[epoch7, step1149]: loss 0.037954
[epoch7, step1150]: loss 0.037956
[epoch7, step1151]: loss 0.036548
[epoch7, step1152]: loss 0.038768
[epoch7, step1153]: loss 0.037521
[epoch7, step1154]: loss 0.039897
[epoch7, step1155]: loss 0.036936
[epoch7, step1156]: loss 0.035746
[epoch7, step1157]: loss 0.039492
[epoch7, step1158]: loss 0.038351
[epoch7, step1159]: loss 0.038356
[epoch7, step1160]: loss 0.036975
[epoch7, step1161]: loss 0.038848
[epoch7, step1162]: loss 0.038139
[epoch7, step1163]: loss 0.038732
[epoch7, step1164]: loss 0.036735
[epoch7, step1165]: loss 0.037386
[epoch7, step1166]: loss 0.039669
[epoch7, step1167]: loss 0.037377
[epoch7, step1168]: loss 0.038311
[epoch7, step1169]: loss 0.035956
[epoch7, step1170]: loss 0.038367
[epoch7, step1171]: loss 0.037927
[epoch7, step1172]: loss 0.039616
[epoch7, step1173]: loss 0.036857
[epoch7, step1174]: loss 0.036774
[epoch7, step1175]: loss 0.039419
[epoch7, step1176]: loss 0.037804
[epoch7, step1177]: loss 0.038412
[epoch7, step1178]: loss 0.036274
[epoch7, step1179]: loss 0.038147
[epoch7, step1180]: loss 0.038263
[epoch7, step1181]: loss 0.039917
[epoch7, step1182]: loss 0.036134
[epoch7, step1183]: loss 0.036686
[epoch7, step1184]: loss 0.038988
[epoch7, step1185]: loss 0.038012
[epoch7, step1186]: loss 0.037338
[epoch7, step1187]: loss 0.035451
[epoch7, step1188]: loss 0.037794
[epoch7, step1189]: loss 0.037947
[epoch7, step1190]: loss 0.039085
[epoch7, step1191]: loss 0.037227
[epoch7, step1192]: loss 0.036317
[epoch7, step1193]: loss 0.039485
[epoch7, step1194]: loss 0.038015
[epoch7, step1195]: loss 0.037048
[epoch7, step1196]: loss 0.035504
[epoch7, step1197]: loss 0.038596
[epoch7, step1198]: loss 0.038104
[epoch7, step1199]: loss 0.039061
[epoch7, step1200]: loss 0.036468
[epoch7, step1201]: loss 0.036790
[epoch7, step1202]: loss 0.040600
[epoch7, step1203]: loss 0.038265
[epoch7, step1204]: loss 0.037440
[epoch7, step1205]: loss 0.035673
[epoch7, step1206]: loss 0.037799
[epoch7, step1207]: loss 0.038380
[epoch7, step1208]: loss 0.039517
[epoch7, step1209]: loss 0.035591
[epoch7, step1210]: loss 0.036710
[epoch7, step1211]: loss 0.039025
[epoch7, step1212]: loss 0.037801
[epoch7, step1213]: loss 0.037537
[epoch7, step1214]: loss 0.036461
[epoch7, step1215]: loss 0.038762
[epoch7, step1216]: loss 0.037640
[epoch7, step1217]: loss 0.039966
[epoch7, step1218]: loss 0.036265
[epoch7, step1219]: loss 0.037159
[epoch7, step1220]: loss 0.039999
[epoch7, step1221]: loss 0.037190
[epoch7, step1222]: loss 0.038264
[epoch7, step1223]: loss 0.035930
[epoch7, step1224]: loss 0.038613
[epoch7, step1225]: loss 0.038118
[epoch7, step1226]: loss 0.039132
[epoch7, step1227]: loss 0.036695
[epoch7, step1228]: loss 0.036167
[epoch7, step1229]: loss 0.039429
[epoch7, step1230]: loss 0.038304
[epoch7, step1231]: loss 0.037678
[epoch7, step1232]: loss 0.037270
[epoch7, step1233]: loss 0.038224
[epoch7, step1234]: loss 0.037872
[epoch7, step1235]: loss 0.039947
[epoch7, step1236]: loss 0.036867
[epoch7, step1237]: loss 0.036080
[epoch7, step1238]: loss 0.038976
[epoch7, step1239]: loss 0.038685
[epoch7, step1240]: loss 0.038403
[epoch7, step1241]: loss 0.035738
[epoch7, step1242]: loss 0.038193
[epoch7, step1243]: loss 0.038116
[epoch7, step1244]: loss 0.039553
[epoch7, step1245]: loss 0.036962
[epoch7, step1246]: loss 0.036695
[epoch7, step1247]: loss 0.038861
[epoch7, step1248]: loss 0.038153
[epoch7, step1249]: loss 0.038470
[epoch7, step1250]: loss 0.035975
[epoch7, step1251]: loss 0.038451
[epoch7, step1252]: loss 0.039098
[epoch7, step1253]: loss 0.039460
[epoch7, step1254]: loss 0.036787
[epoch7, step1255]: loss 0.036672
[epoch7, step1256]: loss 0.040055
[epoch7, step1257]: loss 0.038384
[epoch7, step1258]: loss 0.038245
[epoch7, step1259]: loss 0.035800
[epoch7, step1260]: loss 0.038427
[epoch7, step1261]: loss 0.037952
[epoch7, step1262]: loss 0.038239
[epoch7, step1263]: loss 0.037386
[epoch7, step1264]: loss 0.036430
[epoch7, step1265]: loss 0.038317
[epoch7, step1266]: loss 0.038092
[epoch7, step1267]: loss 0.038103
[epoch7, step1268]: loss 0.036268
[epoch7, step1269]: loss 0.038381
[epoch7, step1270]: loss 0.037446
[epoch7, step1271]: loss 0.039840
[epoch7, step1272]: loss 0.036756
[epoch7, step1273]: loss 0.036248
[epoch7, step1274]: loss 0.039163
[epoch7, step1275]: loss 0.038354
[epoch7, step1276]: loss 0.037588
[epoch7, step1277]: loss 0.036078
[epoch7, step1278]: loss 0.038784
[epoch7, step1279]: loss 0.038302
[epoch7, step1280]: loss 0.039776
[epoch7, step1281]: loss 0.036564
[epoch7, step1282]: loss 0.036312
[epoch7, step1283]: loss 0.038935
[epoch7, step1284]: loss 0.037662
[epoch7, step1285]: loss 0.038689
[epoch7, step1286]: loss 0.035417
[epoch7, step1287]: loss 0.038990
[epoch7, step1288]: loss 0.038879
[epoch7, step1289]: loss 0.040152
[epoch7, step1290]: loss 0.036722
[epoch7, step1291]: loss 0.036217
[epoch7, step1292]: loss 0.040146
[epoch7, step1293]: loss 0.037316
[epoch7, step1294]: loss 0.037848
[epoch7, step1295]: loss 0.036708
[epoch7, step1296]: loss 0.038504
[epoch7, step1297]: loss 0.037867
[epoch7, step1298]: loss 0.039970
[epoch7, step1299]: loss 0.036844
[epoch7, step1300]: loss 0.037110
[epoch7, step1301]: loss 0.038616
[epoch7, step1302]: loss 0.038025
[epoch7, step1303]: loss 0.038248
[epoch7, step1304]: loss 0.035544
[epoch7, step1305]: loss 0.038627
[epoch7, step1306]: loss 0.037930
[epoch7, step1307]: loss 0.038899
[epoch7, step1308]: loss 0.036793
[epoch7, step1309]: loss 0.035813
[epoch7, step1310]: loss 0.039500
[epoch7, step1311]: loss 0.037066
[epoch7, step1312]: loss 0.038762
[epoch7, step1313]: loss 0.036149
[epoch7, step1314]: loss 0.038263
[epoch7, step1315]: loss 0.037892
[epoch7, step1316]: loss 0.040822
[epoch7, step1317]: loss 0.036134
[epoch7, step1318]: loss 0.035893
[epoch7, step1319]: loss 0.038993
[epoch7, step1320]: loss 0.038252
[epoch7, step1321]: loss 0.038494
[epoch7, step1322]: loss 0.035881
[epoch7, step1323]: loss 0.038749
[epoch7, step1324]: loss 0.037673
[epoch7, step1325]: loss 0.039397
[epoch7, step1326]: loss 0.036449
[epoch7, step1327]: loss 0.036357
[epoch7, step1328]: loss 0.039645
[epoch7, step1329]: loss 0.037940
[epoch7, step1330]: loss 0.038252
[epoch7, step1331]: loss 0.035962
[epoch7, step1332]: loss 0.038208
[epoch7, step1333]: loss 0.037355
[epoch7, step1334]: loss 0.039778
[epoch7, step1335]: loss 0.037108
[epoch7, step1336]: loss 0.036303
[epoch7, step1337]: loss 0.039126
[epoch7, step1338]: loss 0.037744
[epoch7, step1339]: loss 0.038233
[epoch7, step1340]: loss 0.035753
[epoch7, step1341]: loss 0.038529
[epoch7, step1342]: loss 0.038033
[epoch7, step1343]: loss 0.039573
[epoch7, step1344]: loss 0.036713
[epoch7, step1345]: loss 0.036274
[epoch7, step1346]: loss 0.039136
[epoch7, step1347]: loss 0.038624
[epoch7, step1348]: loss 0.037496
[epoch7, step1349]: loss 0.036311
[epoch7, step1350]: loss 0.038452
[epoch7, step1351]: loss 0.037702
[epoch7, step1352]: loss 0.038797
[epoch7, step1353]: loss 0.036351
[epoch7, step1354]: loss 0.036022
[epoch7, step1355]: loss 0.039469
[epoch7, step1356]: loss 0.037608
[epoch7, step1357]: loss 0.037331
[epoch7, step1358]: loss 0.036117
[epoch7, step1359]: loss 0.037906
[epoch7, step1360]: loss 0.038278
[epoch7, step1361]: loss 0.039661
[epoch7, step1362]: loss 0.037272
[epoch7, step1363]: loss 0.036771
[epoch7, step1364]: loss 0.039605
[epoch7, step1365]: loss 0.037973
[epoch7, step1366]: loss 0.037985
[epoch7, step1367]: loss 0.035297
[epoch7, step1368]: loss 0.039108
[epoch7, step1369]: loss 0.038145
[epoch7, step1370]: loss 0.039088
[epoch7, step1371]: loss 0.036783
[epoch7, step1372]: loss 0.036252
[epoch7, step1373]: loss 0.039587
[epoch7, step1374]: loss 0.038951
[epoch7, step1375]: loss 0.038774
[epoch7, step1376]: loss 0.036050
[epoch7, step1377]: loss 0.037550
[epoch7, step1378]: loss 0.038424
[epoch7, step1379]: loss 0.039140
[epoch7, step1380]: loss 0.036976
[epoch7, step1381]: loss 0.036408
[epoch7, step1382]: loss 0.039859
[epoch7, step1383]: loss 0.037948
[epoch7, step1384]: loss 0.038122
[epoch7, step1385]: loss 0.035491
[epoch7, step1386]: loss 0.038625
[epoch7, step1387]: loss 0.038673
[epoch7, step1388]: loss 0.038357
[epoch7, step1389]: loss 0.035908
[epoch7, step1390]: loss 0.036444
[epoch7, step1391]: loss 0.039338
[epoch7, step1392]: loss 0.037987
[epoch7, step1393]: loss 0.038283
[epoch7, step1394]: loss 0.036572
[epoch7, step1395]: loss 0.038456
[epoch7, step1396]: loss 0.037645
[epoch7, step1397]: loss 0.039253
[epoch7, step1398]: loss 0.036504
[epoch7, step1399]: loss 0.037201
[epoch7, step1400]: loss 0.039829
[epoch7, step1401]: loss 0.037946
[epoch7, step1402]: loss 0.038161
[epoch7, step1403]: loss 0.035232
[epoch7, step1404]: loss 0.038029
[epoch7, step1405]: loss 0.038063
[epoch7, step1406]: loss 0.039103
[epoch7, step1407]: loss 0.037640
[epoch7, step1408]: loss 0.035787
[epoch7, step1409]: loss 0.038939
[epoch7, step1410]: loss 0.037935
[epoch7, step1411]: loss 0.036978
[epoch7, step1412]: loss 0.036315
[epoch7, step1413]: loss 0.038346
[epoch7, step1414]: loss 0.037984
[epoch7, step1415]: loss 0.039013
[epoch7, step1416]: loss 0.036492
[epoch7, step1417]: loss 0.036373
[epoch7, step1418]: loss 0.039470
[epoch7, step1419]: loss 0.038739
[epoch7, step1420]: loss 0.038312
[epoch7, step1421]: loss 0.036309
[epoch7, step1422]: loss 0.038470
[epoch7, step1423]: loss 0.037694
[epoch7, step1424]: loss 0.039683
[epoch7, step1425]: loss 0.035592
[epoch7, step1426]: loss 0.036424
[epoch7, step1427]: loss 0.040016
[epoch7, step1428]: loss 0.038820
[epoch7, step1429]: loss 0.038023
[epoch7, step1430]: loss 0.036168
[epoch7, step1431]: loss 0.038378
[epoch7, step1432]: loss 0.037929
[epoch7, step1433]: loss 0.039656
[epoch7, step1434]: loss 0.035946
[epoch7, step1435]: loss 0.036825
[epoch7, step1436]: loss 0.039908
[epoch7, step1437]: loss 0.038255
[epoch7, step1438]: loss 0.038585
[epoch7, step1439]: loss 0.035936
[epoch7, step1440]: loss 0.037982
[epoch7, step1441]: loss 0.038702
[epoch7, step1442]: loss 0.038677
[epoch7, step1443]: loss 0.036162
[epoch7, step1444]: loss 0.035680
[epoch7, step1445]: loss 0.039919
[epoch7, step1446]: loss 0.038219
[epoch7, step1447]: loss 0.038736
[epoch7, step1448]: loss 0.035932
[epoch7, step1449]: loss 0.037671
[epoch7, step1450]: loss 0.038140
[epoch7, step1451]: loss 0.039670
[epoch7, step1452]: loss 0.036249
[epoch7, step1453]: loss 0.037531
[epoch7, step1454]: loss 0.039852
[epoch7, step1455]: loss 0.038693
[epoch7, step1456]: loss 0.037653
[epoch7, step1457]: loss 0.036517
[epoch7, step1458]: loss 0.038289
[epoch7, step1459]: loss 0.037934
[epoch7, step1460]: loss 0.039918
[epoch7, step1461]: loss 0.037209
[epoch7, step1462]: loss 0.036989
[epoch7, step1463]: loss 0.039271
[epoch7, step1464]: loss 0.038291
[epoch7, step1465]: loss 0.037553
[epoch7, step1466]: loss 0.035662
[epoch7, step1467]: loss 0.038151
[epoch7, step1468]: loss 0.037539
[epoch7, step1469]: loss 0.039450
[epoch7, step1470]: loss 0.036514
[epoch7, step1471]: loss 0.036003
[epoch7, step1472]: loss 0.039192
[epoch7, step1473]: loss 0.037871
[epoch7, step1474]: loss 0.038603
[epoch7, step1475]: loss 0.035601
[epoch7, step1476]: loss 0.038976
[epoch7, step1477]: loss 0.037694
[epoch7, step1478]: loss 0.039578
[epoch7, step1479]: loss 0.036455
[epoch7, step1480]: loss 0.036317
[epoch7, step1481]: loss 0.038399
[epoch7, step1482]: loss 0.037983
[epoch7, step1483]: loss 0.038295
[epoch7, step1484]: loss 0.036341
[epoch7, step1485]: loss 0.037914
[epoch7, step1486]: loss 0.037009
[epoch7, step1487]: loss 0.039189
[epoch7, step1488]: loss 0.036616
[epoch7, step1489]: loss 0.036068
[epoch7, step1490]: loss 0.039557
[epoch7, step1491]: loss 0.037929
[epoch7, step1492]: loss 0.037817
[epoch7, step1493]: loss 0.035953
[epoch7, step1494]: loss 0.038393
[epoch7, step1495]: loss 0.037675
[epoch7, step1496]: loss 0.038540
[epoch7, step1497]: loss 0.036839
[epoch7, step1498]: loss 0.036374
[epoch7, step1499]: loss 0.038893
[epoch7, step1500]: loss 0.038149
[epoch7, step1501]: loss 0.038135
[epoch7, step1502]: loss 0.035742
[epoch7, step1503]: loss 0.038211
[epoch7, step1504]: loss 0.037465
[epoch7, step1505]: loss 0.039612
[epoch7, step1506]: loss 0.035888
[epoch7, step1507]: loss 0.036838
[epoch7, step1508]: loss 0.040079
[epoch7, step1509]: loss 0.037840
[epoch7, step1510]: loss 0.037126
[epoch7, step1511]: loss 0.036632
[epoch7, step1512]: loss 0.038266
[epoch7, step1513]: loss 0.036710
[epoch7, step1514]: loss 0.039461
[epoch7, step1515]: loss 0.036928
[epoch7, step1516]: loss 0.036187

[epoch7]: avg loss 0.034324

[epoch8, step1]: loss 0.033891
[epoch8, step2]: loss 0.039105
[epoch8, step3]: loss 0.038909
[epoch8, step4]: loss 0.036088
[epoch8, step5]: loss 0.036476
[epoch8, step6]: loss 0.039493
[epoch8, step7]: loss 0.037098
[epoch8, step8]: loss 0.039806
[epoch8, step9]: loss 0.035553
[epoch8, step10]: loss 0.037647
[epoch8, step11]: loss 0.039420
[epoch8, step12]: loss 0.039394
[epoch8, step13]: loss 0.036596
[epoch8, step14]: loss 0.036607
[epoch8, step15]: loss 0.039424
[epoch8, step16]: loss 0.037054
[epoch8, step17]: loss 0.040008
[epoch8, step18]: loss 0.036870
[epoch8, step19]: loss 0.037338
[epoch8, step20]: loss 0.040336
[epoch8, step21]: loss 0.039295
[epoch8, step22]: loss 0.036138
[epoch8, step23]: loss 0.035667
[epoch8, step24]: loss 0.039413
[epoch8, step25]: loss 0.036403
[epoch8, step26]: loss 0.039191
[epoch8, step27]: loss 0.035498
[epoch8, step28]: loss 0.037282
[epoch8, step29]: loss 0.039379
[epoch8, step30]: loss 0.039938
[epoch8, step31]: loss 0.035956
[epoch8, step32]: loss 0.036860
[epoch8, step33]: loss 0.040047
[epoch8, step34]: loss 0.037785
[epoch8, step35]: loss 0.039981
[epoch8, step36]: loss 0.035892
[epoch8, step37]: loss 0.037258
[epoch8, step38]: loss 0.039150
[epoch8, step39]: loss 0.039250
[epoch8, step40]: loss 0.036859
[epoch8, step41]: loss 0.035886
[epoch8, step42]: loss 0.039767
[epoch8, step43]: loss 0.036902
[epoch8, step44]: loss 0.040036
[epoch8, step45]: loss 0.035914
[epoch8, step46]: loss 0.037289
[epoch8, step47]: loss 0.039074
[epoch8, step48]: loss 0.039151
[epoch8, step49]: loss 0.034909
[epoch8, step50]: loss 0.036478
[epoch8, step51]: loss 0.039076
[epoch8, step52]: loss 0.036772
[epoch8, step53]: loss 0.040357
[epoch8, step54]: loss 0.035790
[epoch8, step55]: loss 0.037465
[epoch8, step56]: loss 0.040210
[epoch8, step57]: loss 0.039822
[epoch8, step58]: loss 0.036440
[epoch8, step59]: loss 0.035481
[epoch8, step60]: loss 0.039990
[epoch8, step61]: loss 0.036405
[epoch8, step62]: loss 0.039251
[epoch8, step63]: loss 0.035277
[epoch8, step64]: loss 0.036641
[epoch8, step65]: loss 0.039498
[epoch8, step66]: loss 0.039362
[epoch8, step67]: loss 0.036683
[epoch8, step68]: loss 0.036471
[epoch8, step69]: loss 0.039373
[epoch8, step70]: loss 0.036770
[epoch8, step71]: loss 0.039390
[epoch8, step72]: loss 0.036182
[epoch8, step73]: loss 0.036834
[epoch8, step74]: loss 0.039438
[epoch8, step75]: loss 0.039453
[epoch8, step76]: loss 0.037054
[epoch8, step77]: loss 0.037007
[epoch8, step78]: loss 0.039695
[epoch8, step79]: loss 0.036308
[epoch8, step80]: loss 0.040656
[epoch8, step81]: loss 0.036186
[epoch8, step82]: loss 0.036638
[epoch8, step83]: loss 0.038511
[epoch8, step84]: loss 0.039735
[epoch8, step85]: loss 0.037072
[epoch8, step86]: loss 0.036509
[epoch8, step87]: loss 0.040603
[epoch8, step88]: loss 0.035881
[epoch8, step89]: loss 0.039321
[epoch8, step90]: loss 0.036467
[epoch8, step91]: loss 0.036546
[epoch8, step92]: loss 0.039562
[epoch8, step93]: loss 0.039254
[epoch8, step94]: loss 0.036301
[epoch8, step95]: loss 0.036868
[epoch8, step96]: loss 0.039372
[epoch8, step97]: loss 0.037553
[epoch8, step98]: loss 0.039745
[epoch8, step99]: loss 0.036146
[epoch8, step100]: loss 0.036067
[epoch8, step101]: loss 0.039839
[epoch8, step102]: loss 0.039455
[epoch8, step103]: loss 0.036464
[epoch8, step104]: loss 0.036566
[epoch8, step105]: loss 0.039705
[epoch8, step106]: loss 0.036918
[epoch8, step107]: loss 0.039633
[epoch8, step108]: loss 0.036352
[epoch8, step109]: loss 0.036630
[epoch8, step110]: loss 0.039999
[epoch8, step111]: loss 0.039259
[epoch8, step112]: loss 0.036689
[epoch8, step113]: loss 0.037188
[epoch8, step114]: loss 0.039411
[epoch8, step115]: loss 0.036890
[epoch8, step116]: loss 0.040424
[epoch8, step117]: loss 0.036085
[epoch8, step118]: loss 0.037624
[epoch8, step119]: loss 0.039872
[epoch8, step120]: loss 0.039585
[epoch8, step121]: loss 0.036331
[epoch8, step122]: loss 0.036416
[epoch8, step123]: loss 0.039978
[epoch8, step124]: loss 0.037206
[epoch8, step125]: loss 0.040244
[epoch8, step126]: loss 0.035899
[epoch8, step127]: loss 0.036903
[epoch8, step128]: loss 0.039270
[epoch8, step129]: loss 0.039035
[epoch8, step130]: loss 0.036648
[epoch8, step131]: loss 0.035675
[epoch8, step132]: loss 0.039758
[epoch8, step133]: loss 0.036586
[epoch8, step134]: loss 0.039206
[epoch8, step135]: loss 0.036494
[epoch8, step136]: loss 0.038022
[epoch8, step137]: loss 0.038956
[epoch8, step138]: loss 0.039288
[epoch8, step139]: loss 0.036388
[epoch8, step140]: loss 0.036860
[epoch8, step141]: loss 0.039913
[epoch8, step142]: loss 0.036796
[epoch8, step143]: loss 0.039251
[epoch8, step144]: loss 0.036368
[epoch8, step145]: loss 0.037132
[epoch8, step146]: loss 0.039505
[epoch8, step147]: loss 0.040815
[epoch8, step148]: loss 0.036372
[epoch8, step149]: loss 0.035842
[epoch8, step150]: loss 0.039231
[epoch8, step151]: loss 0.037002
[epoch8, step152]: loss 0.039823
[epoch8, step153]: loss 0.036297
[epoch8, step154]: loss 0.036370
[epoch8, step155]: loss 0.039621
[epoch8, step156]: loss 0.039092
[epoch8, step157]: loss 0.036751
[epoch8, step158]: loss 0.036764
[epoch8, step159]: loss 0.039872
[epoch8, step160]: loss 0.037208
[epoch8, step161]: loss 0.040343
[epoch8, step162]: loss 0.036401
[epoch8, step163]: loss 0.036783
[epoch8, step164]: loss 0.039658
[epoch8, step165]: loss 0.039534
[epoch8, step166]: loss 0.036962
[epoch8, step167]: loss 0.036042
[epoch8, step168]: loss 0.040221
[epoch8, step169]: loss 0.036476
[epoch8, step170]: loss 0.040086
[epoch8, step171]: loss 0.036503
[epoch8, step172]: loss 0.037064
[epoch8, step173]: loss 0.039861
[epoch8, step174]: loss 0.039457
[epoch8, step175]: loss 0.037331
[epoch8, step176]: loss 0.036758
[epoch8, step177]: loss 0.040012
[epoch8, step178]: loss 0.037140
[epoch8, step179]: loss 0.039077
[epoch8, step180]: loss 0.036515
[epoch8, step181]: loss 0.037218
[epoch8, step182]: loss 0.039893
[epoch8, step183]: loss 0.040251
[epoch8, step184]: loss 0.037631
[epoch8, step185]: loss 0.036756
[epoch8, step186]: loss 0.039830
[epoch8, step187]: loss 0.037140
[epoch8, step188]: loss 0.039599
[epoch8, step189]: loss 0.036271
[epoch8, step190]: loss 0.036443
[epoch8, step191]: loss 0.039308
[epoch8, step192]: loss 0.040001
[epoch8, step193]: loss 0.034791
[epoch8, step194]: loss 0.035693
[epoch8, step195]: loss 0.039990
[epoch8, step196]: loss 0.037010
[epoch8, step197]: loss 0.039648
[epoch8, step198]: loss 0.035290
[epoch8, step199]: loss 0.036994
[epoch8, step200]: loss 0.039971
[epoch8, step201]: loss 0.040005
[epoch8, step202]: loss 0.036240
[epoch8, step203]: loss 0.036571
[epoch8, step204]: loss 0.040032
[epoch8, step205]: loss 0.036407
[epoch8, step206]: loss 0.039649
[epoch8, step207]: loss 0.036165
[epoch8, step208]: loss 0.037437
[epoch8, step209]: loss 0.039694
[epoch8, step210]: loss 0.040499
[epoch8, step211]: loss 0.037317
[epoch8, step212]: loss 0.037037
[epoch8, step213]: loss 0.039569
[epoch8, step214]: loss 0.036213
[epoch8, step215]: loss 0.040179
[epoch8, step216]: loss 0.036479
[epoch8, step217]: loss 0.035950
[epoch8, step218]: loss 0.039941
[epoch8, step219]: loss 0.039450
[epoch8, step220]: loss 0.036956
[epoch8, step221]: loss 0.036844
[epoch8, step222]: loss 0.039832
[epoch8, step223]: loss 0.037086
[epoch8, step224]: loss 0.039455
[epoch8, step225]: loss 0.036293
[epoch8, step226]: loss 0.036848
[epoch8, step227]: loss 0.038591
[epoch8, step228]: loss 0.040221
[epoch8, step229]: loss 0.035897
[epoch8, step230]: loss 0.036890
[epoch8, step231]: loss 0.040178
[epoch8, step232]: loss 0.036386
[epoch8, step233]: loss 0.039156
[epoch8, step234]: loss 0.035753
[epoch8, step235]: loss 0.037374
[epoch8, step236]: loss 0.039650
[epoch8, step237]: loss 0.039701
[epoch8, step238]: loss 0.036457
[epoch8, step239]: loss 0.035934
[epoch8, step240]: loss 0.039204
[epoch8, step241]: loss 0.037402
[epoch8, step242]: loss 0.039816
[epoch8, step243]: loss 0.036774
[epoch8, step244]: loss 0.036968
[epoch8, step245]: loss 0.039256
[epoch8, step246]: loss 0.039652
[epoch8, step247]: loss 0.036955
[epoch8, step248]: loss 0.036196
[epoch8, step249]: loss 0.039183
[epoch8, step250]: loss 0.037053
[epoch8, step251]: loss 0.040357
[epoch8, step252]: loss 0.036848
[epoch8, step253]: loss 0.036725
[epoch8, step254]: loss 0.039043
[epoch8, step255]: loss 0.039685
[epoch8, step256]: loss 0.036413
[epoch8, step257]: loss 0.036384
[epoch8, step258]: loss 0.040447
[epoch8, step259]: loss 0.036833
[epoch8, step260]: loss 0.039378
[epoch8, step261]: loss 0.036985
[epoch8, step262]: loss 0.037513
[epoch8, step263]: loss 0.038775
[epoch8, step264]: loss 0.039441
[epoch8, step265]: loss 0.036959
[epoch8, step266]: loss 0.036533
[epoch8, step267]: loss 0.038960
[epoch8, step268]: loss 0.036692
[epoch8, step269]: loss 0.039903
[epoch8, step270]: loss 0.035903
[epoch8, step271]: loss 0.037197
[epoch8, step272]: loss 0.039618
[epoch8, step273]: loss 0.039376
[epoch8, step274]: loss 0.037291
[epoch8, step275]: loss 0.036093
[epoch8, step276]: loss 0.039302
[epoch8, step277]: loss 0.037381
[epoch8, step278]: loss 0.040059
[epoch8, step279]: loss 0.036039
[epoch8, step280]: loss 0.036851
[epoch8, step281]: loss 0.039253
[epoch8, step282]: loss 0.039971
[epoch8, step283]: loss 0.036153
[epoch8, step284]: loss 0.035930
[epoch8, step285]: loss 0.040393
[epoch8, step286]: loss 0.036060
[epoch8, step287]: loss 0.039971
[epoch8, step288]: loss 0.035816
[epoch8, step289]: loss 0.037813
[epoch8, step290]: loss 0.039653
[epoch8, step291]: loss 0.039803
[epoch8, step292]: loss 0.035834
[epoch8, step293]: loss 0.036172
[epoch8, step294]: loss 0.038850
[epoch8, step295]: loss 0.036299
[epoch8, step296]: loss 0.040513
[epoch8, step297]: loss 0.035994
[epoch8, step298]: loss 0.037326
[epoch8, step299]: loss 0.038680
[epoch8, step300]: loss 0.039804
[epoch8, step301]: loss 0.036795
[epoch8, step302]: loss 0.036909
[epoch8, step303]: loss 0.040158
[epoch8, step304]: loss 0.036430
[epoch8, step305]: loss 0.039569
[epoch8, step306]: loss 0.036283
[epoch8, step307]: loss 0.036508
[epoch8, step308]: loss 0.040031
[epoch8, step309]: loss 0.039957
[epoch8, step310]: loss 0.036810
[epoch8, step311]: loss 0.036901
[epoch8, step312]: loss 0.039267
[epoch8, step313]: loss 0.037360
[epoch8, step314]: loss 0.039728
[epoch8, step315]: loss 0.037123
[epoch8, step316]: loss 0.036768
[epoch8, step317]: loss 0.039772
[epoch8, step318]: loss 0.039790
[epoch8, step319]: loss 0.036175
[epoch8, step320]: loss 0.035492
[epoch8, step321]: loss 0.039358
[epoch8, step322]: loss 0.036800
[epoch8, step323]: loss 0.039311
[epoch8, step324]: loss 0.036944
[epoch8, step325]: loss 0.037236
[epoch8, step326]: loss 0.039244
[epoch8, step327]: loss 0.038997
[epoch8, step328]: loss 0.036829
[epoch8, step329]: loss 0.036129
[epoch8, step330]: loss 0.039231
[epoch8, step331]: loss 0.036853
[epoch8, step332]: loss 0.039264
[epoch8, step333]: loss 0.036247
[epoch8, step334]: loss 0.036963
[epoch8, step335]: loss 0.039627
[epoch8, step336]: loss 0.040455
[epoch8, step337]: loss 0.036853
[epoch8, step338]: loss 0.035994
[epoch8, step339]: loss 0.039373
[epoch8, step340]: loss 0.037212
[epoch8, step341]: loss 0.039284
[epoch8, step342]: loss 0.035992
[epoch8, step343]: loss 0.037177
[epoch8, step344]: loss 0.039036
[epoch8, step345]: loss 0.038919
[epoch8, step346]: loss 0.036310
[epoch8, step347]: loss 0.036042
[epoch8, step348]: loss 0.039783
[epoch8, step349]: loss 0.037284
[epoch8, step350]: loss 0.039327
[epoch8, step351]: loss 0.035578
[epoch8, step352]: loss 0.036844
[epoch8, step353]: loss 0.039308
[epoch8, step354]: loss 0.038681
[epoch8, step355]: loss 0.035690
[epoch8, step356]: loss 0.037067
[epoch8, step357]: loss 0.039683
[epoch8, step358]: loss 0.035533
[epoch8, step359]: loss 0.040533
[epoch8, step360]: loss 0.035170
[epoch8, step361]: loss 0.036268
[epoch8, step362]: loss 0.039875
[epoch8, step363]: loss 0.039307
[epoch8, step364]: loss 0.036408
[epoch8, step365]: loss 0.036141
[epoch8, step366]: loss 0.039983
[epoch8, step367]: loss 0.036754
[epoch8, step368]: loss 0.039124
[epoch8, step369]: loss 0.036064
[epoch8, step370]: loss 0.037587
[epoch8, step371]: loss 0.040401
[epoch8, step372]: loss 0.039163
[epoch8, step373]: loss 0.036036
[epoch8, step374]: loss 0.035765
[epoch8, step375]: loss 0.040012
[epoch8, step376]: loss 0.036758
[epoch8, step377]: loss 0.040045
[epoch8, step378]: loss 0.036582
[epoch8, step379]: loss 0.037548
[epoch8, step380]: loss 0.039861
[epoch8, step381]: loss 0.039180
[epoch8, step382]: loss 0.036878
[epoch8, step383]: loss 0.035548
[epoch8, step384]: loss 0.038858
[epoch8, step385]: loss 0.036837
[epoch8, step386]: loss 0.039859
[epoch8, step387]: loss 0.036223
[epoch8, step388]: loss 0.037547
[epoch8, step389]: loss 0.039375
[epoch8, step390]: loss 0.040464
[epoch8, step391]: loss 0.036162
[epoch8, step392]: loss 0.036997
[epoch8, step393]: loss 0.039239
[epoch8, step394]: loss 0.036807
[epoch8, step395]: loss 0.039524
[epoch8, step396]: loss 0.036216
[epoch8, step397]: loss 0.036649
[epoch8, step398]: loss 0.039611
[epoch8, step399]: loss 0.039458
[epoch8, step400]: loss 0.036295
[epoch8, step401]: loss 0.036161
[epoch8, step402]: loss 0.039187
[epoch8, step403]: loss 0.036624
[epoch8, step404]: loss 0.039964
[epoch8, step405]: loss 0.036462
[epoch8, step406]: loss 0.037342
[epoch8, step407]: loss 0.039415
[epoch8, step408]: loss 0.039561
[epoch8, step409]: loss 0.037855
[epoch8, step410]: loss 0.037048
[epoch8, step411]: loss 0.039523
[epoch8, step412]: loss 0.036321
[epoch8, step413]: loss 0.039743
[epoch8, step414]: loss 0.035748
[epoch8, step415]: loss 0.037220
[epoch8, step416]: loss 0.038823
[epoch8, step417]: loss 0.039797
[epoch8, step418]: loss 0.036381
[epoch8, step419]: loss 0.035725
[epoch8, step420]: loss 0.039826
[epoch8, step421]: loss 0.036668
[epoch8, step422]: loss 0.039702
[epoch8, step423]: loss 0.036363
[epoch8, step424]: loss 0.037239
[epoch8, step425]: loss 0.039868
[epoch8, step426]: loss 0.040003
[epoch8, step427]: loss 0.036856
[epoch8, step428]: loss 0.036264
[epoch8, step429]: loss 0.040377
[epoch8, step430]: loss 0.036626
[epoch8, step431]: loss 0.040097
[epoch8, step432]: loss 0.036278
[epoch8, step433]: loss 0.037870
[epoch8, step434]: loss 0.039477
[epoch8, step435]: loss 0.040096
[epoch8, step436]: loss 0.036239
[epoch8, step437]: loss 0.036512
[epoch8, step438]: loss 0.040143
[epoch8, step439]: loss 0.036982
[epoch8, step440]: loss 0.039824
[epoch8, step441]: loss 0.036423
[epoch8, step442]: loss 0.036941
[epoch8, step443]: loss 0.040006
[epoch8, step444]: loss 0.039392
[epoch8, step445]: loss 0.037096
[epoch8, step446]: loss 0.036770
[epoch8, step447]: loss 0.040450
[epoch8, step448]: loss 0.036981
[epoch8, step449]: loss 0.039635
[epoch8, step450]: loss 0.035678
[epoch8, step451]: loss 0.036819
[epoch8, step452]: loss 0.038417
[epoch8, step453]: loss 0.039774
[epoch8, step454]: loss 0.036575
[epoch8, step455]: loss 0.036533
[epoch8, step456]: loss 0.038701
[epoch8, step457]: loss 0.037467
[epoch8, step458]: loss 0.039578
[epoch8, step459]: loss 0.036994
[epoch8, step460]: loss 0.037088
[epoch8, step461]: loss 0.040244
[epoch8, step462]: loss 0.038988
[epoch8, step463]: loss 0.036751
[epoch8, step464]: loss 0.036290
[epoch8, step465]: loss 0.040942
[epoch8, step466]: loss 0.036666
[epoch8, step467]: loss 0.039541
[epoch8, step468]: loss 0.036043
[epoch8, step469]: loss 0.036993
[epoch8, step470]: loss 0.039669
[epoch8, step471]: loss 0.039145
[epoch8, step472]: loss 0.037056
[epoch8, step473]: loss 0.036212
[epoch8, step474]: loss 0.039691
[epoch8, step475]: loss 0.036935
[epoch8, step476]: loss 0.040331
[epoch8, step477]: loss 0.036219
[epoch8, step478]: loss 0.036570
[epoch8, step479]: loss 0.039392
[epoch8, step480]: loss 0.038694
[epoch8, step481]: loss 0.036154
[epoch8, step482]: loss 0.035907
[epoch8, step483]: loss 0.040029
[epoch8, step484]: loss 0.036961
[epoch8, step485]: loss 0.039973
[epoch8, step486]: loss 0.036664
[epoch8, step487]: loss 0.036293
[epoch8, step488]: loss 0.040103
[epoch8, step489]: loss 0.038963
[epoch8, step490]: loss 0.037068
[epoch8, step491]: loss 0.036532
[epoch8, step492]: loss 0.039394
[epoch8, step493]: loss 0.036586
[epoch8, step494]: loss 0.039272
[epoch8, step495]: loss 0.037528
[epoch8, step496]: loss 0.037059
[epoch8, step497]: loss 0.039528
[epoch8, step498]: loss 0.039256
[epoch8, step499]: loss 0.036875
[epoch8, step500]: loss 0.036023
[epoch8, step501]: loss 0.039173
[epoch8, step502]: loss 0.036639
[epoch8, step503]: loss 0.039879
[epoch8, step504]: loss 0.036145
[epoch8, step505]: loss 0.036292
[epoch8, step506]: loss 0.039889
[epoch8, step507]: loss 0.039845
[epoch8, step508]: loss 0.037222
[epoch8, step509]: loss 0.036377
[epoch8, step510]: loss 0.039725
[epoch8, step511]: loss 0.037228
[epoch8, step512]: loss 0.040120
[epoch8, step513]: loss 0.036479
[epoch8, step514]: loss 0.037365
[epoch8, step515]: loss 0.039495
[epoch8, step516]: loss 0.040096
[epoch8, step517]: loss 0.036675
[epoch8, step518]: loss 0.036585
[epoch8, step519]: loss 0.039542
[epoch8, step520]: loss 0.036374
[epoch8, step521]: loss 0.039396
[epoch8, step522]: loss 0.035680
[epoch8, step523]: loss 0.037036
[epoch8, step524]: loss 0.038748
[epoch8, step525]: loss 0.039902
[epoch8, step526]: loss 0.036778
[epoch8, step527]: loss 0.036159
[epoch8, step528]: loss 0.039924
[epoch8, step529]: loss 0.036472
[epoch8, step530]: loss 0.040243
[epoch8, step531]: loss 0.036112
[epoch8, step532]: loss 0.036635
[epoch8, step533]: loss 0.040616
[epoch8, step534]: loss 0.039584
[epoch8, step535]: loss 0.037146
[epoch8, step536]: loss 0.036497
[epoch8, step537]: loss 0.039635
[epoch8, step538]: loss 0.036964
[epoch8, step539]: loss 0.039484
[epoch8, step540]: loss 0.035945
[epoch8, step541]: loss 0.036376
[epoch8, step542]: loss 0.039460
[epoch8, step543]: loss 0.039231
[epoch8, step544]: loss 0.036493
[epoch8, step545]: loss 0.035698
[epoch8, step546]: loss 0.040316
[epoch8, step547]: loss 0.036471
[epoch8, step548]: loss 0.039676
[epoch8, step549]: loss 0.036553
[epoch8, step550]: loss 0.037100
[epoch8, step551]: loss 0.039526
[epoch8, step552]: loss 0.039016
[epoch8, step553]: loss 0.037243
[epoch8, step554]: loss 0.036217
[epoch8, step555]: loss 0.039368
[epoch8, step556]: loss 0.036664
[epoch8, step557]: loss 0.039153
[epoch8, step558]: loss 0.036665
[epoch8, step559]: loss 0.036219
[epoch8, step560]: loss 0.039714
[epoch8, step561]: loss 0.039363
[epoch8, step562]: loss 0.036604
[epoch8, step563]: loss 0.029050
[epoch8, step564]: loss 0.028415
[epoch8, step565]: loss 0.027557
[epoch8, step566]: loss 0.035150
[epoch8, step567]: loss 0.026408
[epoch8, step568]: loss 0.025884
[epoch8, step569]: loss 0.023532
[epoch8, step570]: loss 0.031679
[epoch8, step571]: loss 0.027607
[epoch8, step572]: loss 0.025846
[epoch8, step573]: loss 0.028954
[epoch8, step574]: loss 0.027735
[epoch8, step575]: loss 0.020502
[epoch8, step576]: loss 0.021667
[epoch8, step577]: loss 0.025778
[epoch8, step578]: loss 0.018911
[epoch8, step579]: loss 0.028269
[epoch8, step580]: loss 0.020216
[epoch8, step581]: loss 0.025464
[epoch8, step582]: loss 0.025248
[epoch8, step583]: loss 0.022344
[epoch8, step584]: loss 0.023549
[epoch8, step585]: loss 0.026294
[epoch8, step586]: loss 0.021892
[epoch8, step587]: loss 0.027863
[epoch8, step588]: loss 0.023405
[epoch8, step589]: loss 0.023500
[epoch8, step590]: loss 0.027761
[epoch8, step591]: loss 0.020805
[epoch8, step592]: loss 0.026325
[epoch8, step593]: loss 0.022586
[epoch8, step594]: loss 0.026050
[epoch8, step595]: loss 0.026579
[epoch8, step596]: loss 0.023039
[epoch8, step597]: loss 0.025224
[epoch8, step598]: loss 0.026435
[epoch8, step599]: loss 0.025340
[epoch8, step600]: loss 0.027602
[epoch8, step601]: loss 0.019794
[epoch8, step602]: loss 0.022755
[epoch8, step603]: loss 0.026027
[epoch8, step604]: loss 0.026710
[epoch8, step605]: loss 0.025586
[epoch8, step606]: loss 0.024962
[epoch8, step607]: loss 0.027831
[epoch8, step608]: loss 0.025885
[epoch8, step609]: loss 0.027299
[epoch8, step610]: loss 0.026023
[epoch8, step611]: loss 0.026650
[epoch8, step612]: loss 0.025925
[epoch8, step613]: loss 0.019729
[epoch8, step614]: loss 0.025317
[epoch8, step615]: loss 0.028445
[epoch8, step616]: loss 0.024151
[epoch8, step617]: loss 0.023770
[epoch8, step618]: loss 0.026036
[epoch8, step619]: loss 0.027085
[epoch8, step620]: loss 0.024471
[epoch8, step621]: loss 0.026479
[epoch8, step622]: loss 0.020821
[epoch8, step623]: loss 0.024624
[epoch8, step624]: loss 0.026688
[epoch8, step625]: loss 0.026285
[epoch8, step626]: loss 0.028486
[epoch8, step627]: loss 0.023315
[epoch8, step628]: loss 0.026275
[epoch8, step629]: loss 0.021007
[epoch8, step630]: loss 0.023579
[epoch8, step631]: loss 0.031275
[epoch8, step632]: loss 0.023579
[epoch8, step633]: loss 0.024802
[epoch8, step634]: loss 0.027347
[epoch8, step635]: loss 0.026054
[epoch8, step636]: loss 0.021050
[epoch8, step637]: loss 0.027737
[epoch8, step638]: loss 0.027106
[epoch8, step639]: loss 0.023194
[epoch8, step640]: loss 0.029747
[epoch8, step641]: loss 0.030727
[epoch8, step642]: loss 0.025249
[epoch8, step643]: loss 0.026149
[epoch8, step644]: loss 0.026316
[epoch8, step645]: loss 0.024027
[epoch8, step646]: loss 0.026903
[epoch8, step647]: loss 0.023986
[epoch8, step648]: loss 0.023423
[epoch8, step649]: loss 0.028872
[epoch8, step650]: loss 0.022662
[epoch8, step651]: loss 0.026708
[epoch8, step652]: loss 0.027030
[epoch8, step653]: loss 0.028298
[epoch8, step654]: loss 0.023460
[epoch8, step655]: loss 0.024178
[epoch8, step656]: loss 0.021840
[epoch8, step657]: loss 0.028057
[epoch8, step658]: loss 0.025485
[epoch8, step659]: loss 0.027927
[epoch8, step660]: loss 0.024073
[epoch8, step661]: loss 0.026902
[epoch8, step662]: loss 0.024118
[epoch8, step663]: loss 0.021482
[epoch8, step664]: loss 0.025165
[epoch8, step665]: loss 0.028256
[epoch8, step666]: loss 0.026864
[epoch8, step667]: loss 0.026804
[epoch8, step668]: loss 0.022694
[epoch8, step669]: loss 0.026491
[epoch8, step670]: loss 0.027543
[epoch8, step671]: loss 0.021464
[epoch8, step672]: loss 0.024374
[epoch8, step673]: loss 0.022314
[epoch8, step674]: loss 0.021484
[epoch8, step675]: loss 0.020341
[epoch8, step676]: loss 0.024619
[epoch8, step677]: loss 0.025465
[epoch8, step678]: loss 0.023442
[epoch8, step679]: loss 0.024315
[epoch8, step680]: loss 0.030747
[epoch8, step681]: loss 0.022195
[epoch8, step682]: loss 0.026344
[epoch8, step683]: loss 0.025846
[epoch8, step684]: loss 0.025019
[epoch8, step685]: loss 0.024498
[epoch8, step686]: loss 0.027389
[epoch8, step687]: loss 0.026818
[epoch8, step688]: loss 0.023219
[epoch8, step689]: loss 0.024567
[epoch8, step690]: loss 0.025781
[epoch8, step691]: loss 0.024572
[epoch8, step692]: loss 0.022847
[epoch8, step693]: loss 0.028067
[epoch8, step694]: loss 0.023096
[epoch8, step695]: loss 0.026899
[epoch8, step696]: loss 0.025693
[epoch8, step697]: loss 0.027740
[epoch8, step698]: loss 0.025239
[epoch8, step699]: loss 0.023532
[epoch8, step700]: loss 0.022020
[epoch8, step701]: loss 0.026225
[epoch8, step702]: loss 0.022074
[epoch8, step703]: loss 0.023520
[epoch8, step704]: loss 0.026025
[epoch8, step705]: loss 0.025036
[epoch8, step706]: loss 0.023963
[epoch8, step707]: loss 0.024318
[epoch8, step708]: loss 0.026426
[epoch8, step709]: loss 0.027716
[epoch8, step710]: loss 0.024322
[epoch8, step711]: loss 0.024344
[epoch8, step712]: loss 0.027301
[epoch8, step713]: loss 0.026573
[epoch8, step714]: loss 0.021923
[epoch8, step715]: loss 0.023213
[epoch8, step716]: loss 0.026267
[epoch8, step717]: loss 0.023922
[epoch8, step718]: loss 0.025312
[epoch8, step719]: loss 0.033865
[epoch8, step720]: loss 0.025086
[epoch8, step721]: loss 0.023474
[epoch8, step722]: loss 0.031421
[epoch8, step723]: loss 0.026647
[epoch8, step724]: loss 0.023441
[epoch8, step725]: loss 0.028748
[epoch8, step726]: loss 0.022385
[epoch8, step727]: loss 0.024938
[epoch8, step728]: loss 0.026675
[epoch8, step729]: loss 0.021795
[epoch8, step730]: loss 0.023060
[epoch8, step731]: loss 0.026396
[epoch8, step732]: loss 0.026134
[epoch8, step733]: loss 0.024121
[epoch8, step734]: loss 0.023424
[epoch8, step735]: loss 0.027418
[epoch8, step736]: loss 0.025250
[epoch8, step737]: loss 0.026784
[epoch8, step738]: loss 0.020883
[epoch8, step739]: loss 0.025776
[epoch8, step740]: loss 0.022889
[epoch8, step741]: loss 0.025426
[epoch8, step742]: loss 0.022397
[epoch8, step743]: loss 0.023624
[epoch8, step744]: loss 0.024181
[epoch8, step745]: loss 0.024894
[epoch8, step746]: loss 0.025866
[epoch8, step747]: loss 0.028005
[epoch8, step748]: loss 0.026361
[epoch8, step749]: loss 0.027065
[epoch8, step750]: loss 0.028054
[epoch8, step751]: loss 0.022048
[epoch8, step752]: loss 0.025374
[epoch8, step753]: loss 0.025619
[epoch8, step754]: loss 0.023366
[epoch8, step755]: loss 0.026691
[epoch8, step756]: loss 0.023708
[epoch8, step757]: loss 0.021025
[epoch8, step758]: loss 0.025128
[epoch8, step759]: loss 0.023420
[epoch8, step760]: loss 0.024398
[epoch8, step761]: loss 0.026545
[epoch8, step762]: loss 0.021929
[epoch8, step763]: loss 0.025943
[epoch8, step764]: loss 0.024137
[epoch8, step765]: loss 0.026339
[epoch8, step766]: loss 0.025105
[epoch8, step767]: loss 0.027237
[epoch8, step768]: loss 0.021713
[epoch8, step769]: loss 0.027018
[epoch8, step770]: loss 0.026546
[epoch8, step771]: loss 0.023408
[epoch8, step772]: loss 0.029523
[epoch8, step773]: loss 0.026809
[epoch8, step774]: loss 0.024074
[epoch8, step775]: loss 0.021352
[epoch8, step776]: loss 0.026051
[epoch8, step777]: loss 0.023435
[epoch8, step778]: loss 0.028499
[epoch8, step779]: loss 0.024219
[epoch8, step780]: loss 0.020549
[epoch8, step781]: loss 0.024994
[epoch8, step782]: loss 0.023207
[epoch8, step783]: loss 0.019923
[epoch8, step784]: loss 0.021008
[epoch8, step785]: loss 0.021544
[epoch8, step786]: loss 0.024553
[epoch8, step787]: loss 0.024060
[epoch8, step788]: loss 0.024908
[epoch8, step789]: loss 0.023134
[epoch8, step790]: loss 0.023478
[epoch8, step791]: loss 0.027094
[epoch8, step792]: loss 0.025249
[epoch8, step793]: loss 0.027527
[epoch8, step794]: loss 0.020613
[epoch8, step795]: loss 0.026006
[epoch8, step796]: loss 0.028154
[epoch8, step797]: loss 0.028503
[epoch8, step798]: loss 0.027244
[epoch8, step799]: loss 0.025797
[epoch8, step800]: loss 0.021842
[epoch8, step801]: loss 0.022432
[epoch8, step802]: loss 0.023103
[epoch8, step803]: loss 0.026490
[epoch8, step804]: loss 0.027654
[epoch8, step805]: loss 0.029048
[epoch8, step806]: loss 0.022134
[epoch8, step807]: loss 0.020935
[epoch8, step808]: loss 0.023486
[epoch8, step809]: loss 0.023404
[epoch8, step810]: loss 0.026100
[epoch8, step811]: loss 0.026166
[epoch8, step812]: loss 0.024857
[epoch8, step813]: loss 0.024115
[epoch8, step814]: loss 0.025319
[epoch8, step815]: loss 0.024874
[epoch8, step816]: loss 0.024671
[epoch8, step817]: loss 0.025047
[epoch8, step818]: loss 0.022747
[epoch8, step819]: loss 0.020894
[epoch8, step820]: loss 0.023731
[epoch8, step821]: loss 0.022125
[epoch8, step822]: loss 0.031357
[epoch8, step823]: loss 0.024142
[epoch8, step824]: loss 0.027328
[epoch8, step825]: loss 0.025621
[epoch8, step826]: loss 0.024701
[epoch8, step827]: loss 0.027487
[epoch8, step828]: loss 0.029092
[epoch8, step829]: loss 0.026811
[epoch8, step830]: loss 0.022834
[epoch8, step831]: loss 0.026528
[epoch8, step832]: loss 0.021396
[epoch8, step833]: loss 0.029200
[epoch8, step834]: loss 0.025910
[epoch8, step835]: loss 0.021206
[epoch8, step836]: loss 0.027095
[epoch8, step837]: loss 0.025541
[epoch8, step838]: loss 0.026224
[epoch8, step839]: loss 0.028724
[epoch8, step840]: loss 0.021050
[epoch8, step841]: loss 0.024499
[epoch8, step842]: loss 0.027767
[epoch8, step843]: loss 0.025422
[epoch8, step844]: loss 0.025571
[epoch8, step845]: loss 0.021684
[epoch8, step846]: loss 0.026010
[epoch8, step847]: loss 0.027171
[epoch8, step848]: loss 0.025673
[epoch8, step849]: loss 0.025424
[epoch8, step850]: loss 0.023561
[epoch8, step851]: loss 0.024550
[epoch8, step852]: loss 0.023320
[epoch8, step853]: loss 0.029741
[epoch8, step854]: loss 0.022723
[epoch8, step855]: loss 0.027376
[epoch8, step856]: loss 0.022429
[epoch8, step857]: loss 0.026244
[epoch8, step858]: loss 0.024580
[epoch8, step859]: loss 0.023911
[epoch8, step860]: loss 0.022969
[epoch8, step861]: loss 0.023405
[epoch8, step862]: loss 0.023263
[epoch8, step863]: loss 0.020917
[epoch8, step864]: loss 0.027040
[epoch8, step865]: loss 0.023688
[epoch8, step866]: loss 0.025461
[epoch8, step867]: loss 0.026535
[epoch8, step868]: loss 0.027248
[epoch8, step869]: loss 0.023948
[epoch8, step870]: loss 0.031797
[epoch8, step871]: loss 0.022482
[epoch8, step872]: loss 0.025772
[epoch8, step873]: loss 0.025937
[epoch8, step874]: loss 0.023944
[epoch8, step875]: loss 0.024637
[epoch8, step876]: loss 0.024685
[epoch8, step877]: loss 0.019619
[epoch8, step878]: loss 0.023558
[epoch8, step879]: loss 0.028104
[epoch8, step880]: loss 0.025787
[epoch8, step881]: loss 0.022468
[epoch8, step882]: loss 0.024660
[epoch8, step883]: loss 0.024353
[epoch8, step884]: loss 0.026959
[epoch8, step885]: loss 0.026403
[epoch8, step886]: loss 0.026792
[epoch8, step887]: loss 0.024564
[epoch8, step888]: loss 0.025015
[epoch8, step889]: loss 0.023962
[epoch8, step890]: loss 0.023826
[epoch8, step891]: loss 0.025782
[epoch8, step892]: loss 0.021334
[epoch8, step893]: loss 0.024698
[epoch8, step894]: loss 0.024919
[epoch8, step895]: loss 0.022915
[epoch8, step896]: loss 0.022234
[epoch8, step897]: loss 0.024525
[epoch8, step898]: loss 0.026122
[epoch8, step899]: loss 0.028509
[epoch8, step900]: loss 0.027357
[epoch8, step901]: loss 0.026154
[epoch8, step902]: loss 0.024237
[epoch8, step903]: loss 0.025114
[epoch8, step904]: loss 0.028338
[epoch8, step905]: loss 0.027875
[epoch8, step906]: loss 0.022708
[epoch8, step907]: loss 0.023778
[epoch8, step908]: loss 0.022859
[epoch8, step909]: loss 0.026127
[epoch8, step910]: loss 0.023384
[epoch8, step911]: loss 0.025551
[epoch8, step912]: loss 0.023996
[epoch8, step913]: loss 0.024685
[epoch8, step914]: loss 0.031168
[epoch8, step915]: loss 0.024320
[epoch8, step916]: loss 0.023777
[epoch8, step917]: loss 0.025220
[epoch8, step918]: loss 0.028899
[epoch8, step919]: loss 0.024753
[epoch8, step920]: loss 0.027816
[epoch8, step921]: loss 0.024638
[epoch8, step922]: loss 0.023665
[epoch8, step923]: loss 0.023257
[epoch8, step924]: loss 0.021480
[epoch8, step925]: loss 0.025701
[epoch8, step926]: loss 0.026760
[epoch8, step927]: loss 0.026341
[epoch8, step928]: loss 0.025108
[epoch8, step929]: loss 0.027952
[epoch8, step930]: loss 0.026144
[epoch8, step931]: loss 0.028021
[epoch8, step932]: loss 0.021976
[epoch8, step933]: loss 0.028543
[epoch8, step934]: loss 0.022449
[epoch8, step935]: loss 0.022796
[epoch8, step936]: loss 0.022934
[epoch8, step937]: loss 0.027986
[epoch8, step938]: loss 0.025869
[epoch8, step939]: loss 0.021261
[epoch8, step940]: loss 0.023380
[epoch8, step941]: loss 0.026921
[epoch8, step942]: loss 0.025767
[epoch8, step943]: loss 0.023846
[epoch8, step944]: loss 0.028322
[epoch8, step945]: loss 0.020630
[epoch8, step946]: loss 0.025704
[epoch8, step947]: loss 0.028555
[epoch8, step948]: loss 0.020052
[epoch8, step949]: loss 0.023102
[epoch8, step950]: loss 0.026567
[epoch8, step951]: loss 0.029085
[epoch8, step952]: loss 0.025328
[epoch8, step953]: loss 0.027704
[epoch8, step954]: loss 0.022863
[epoch8, step955]: loss 0.038271
[epoch8, step956]: loss 0.054803
[epoch8, step957]: loss 0.047892
[epoch8, step958]: loss 0.042830
[epoch8, step959]: loss 0.045350
[epoch8, step960]: loss 0.042315
[epoch8, step961]: loss 0.043378
[epoch8, step962]: loss 0.042722
[epoch8, step963]: loss 0.042023
[epoch8, step964]: loss 0.043019
[epoch8, step965]: loss 0.044345
[epoch8, step966]: loss 0.042389
[epoch8, step967]: loss 0.041812
[epoch8, step968]: loss 0.044712
[epoch8, step969]: loss 0.044113
[epoch8, step970]: loss 0.043990
[epoch8, step971]: loss 0.043390
[epoch8, step972]: loss 0.043768
[epoch8, step973]: loss 0.042920
[epoch8, step974]: loss 0.045911
[epoch8, step975]: loss 0.042736
[epoch8, step976]: loss 0.041389
[epoch8, step977]: loss 0.045046
[epoch8, step978]: loss 0.043180
[epoch8, step979]: loss 0.043021
[epoch8, step980]: loss 0.042007
[epoch8, step981]: loss 0.042504
[epoch8, step982]: loss 0.042832
[epoch8, step983]: loss 0.045117
[epoch8, step984]: loss 0.041297
[epoch8, step985]: loss 0.041244
[epoch8, step986]: loss 0.045103
[epoch8, step987]: loss 0.043156
[epoch8, step988]: loss 0.043418
[epoch8, step989]: loss 0.042641
[epoch8, step990]: loss 0.041933
[epoch8, step991]: loss 0.042714
[epoch8, step992]: loss 0.043988
[epoch8, step993]: loss 0.041604
[epoch8, step994]: loss 0.040406
[epoch8, step995]: loss 0.043680
[epoch8, step996]: loss 0.041884
[epoch8, step997]: loss 0.042511
[epoch8, step998]: loss 0.042244
[epoch8, step999]: loss 0.041869
[epoch8, step1000]: loss 0.042129
[epoch8, step1001]: loss 0.043906
[epoch8, step1002]: loss 0.041601
[epoch8, step1003]: loss 0.040425
[epoch8, step1004]: loss 0.043372
[epoch8, step1005]: loss 0.041266
[epoch8, step1006]: loss 0.042279
[epoch8, step1007]: loss 0.041195
[epoch8, step1008]: loss 0.041167
[epoch8, step1009]: loss 0.041703
[epoch8, step1010]: loss 0.044099
[epoch8, step1011]: loss 0.041118
[epoch8, step1012]: loss 0.040740
[epoch8, step1013]: loss 0.043466
[epoch8, step1014]: loss 0.042400
[epoch8, step1015]: loss 0.042543
[epoch8, step1016]: loss 0.041108
[epoch8, step1017]: loss 0.041156
[epoch8, step1018]: loss 0.041505
[epoch8, step1019]: loss 0.043826
[epoch8, step1020]: loss 0.040811
[epoch8, step1021]: loss 0.040022
[epoch8, step1022]: loss 0.043140
[epoch8, step1023]: loss 0.041707
[epoch8, step1024]: loss 0.042817
[epoch8, step1025]: loss 0.040936
[epoch8, step1026]: loss 0.040811
[epoch8, step1027]: loss 0.041373
[epoch8, step1028]: loss 0.043514
[epoch8, step1029]: loss 0.040875
[epoch8, step1030]: loss 0.039861
[epoch8, step1031]: loss 0.042152
[epoch8, step1032]: loss 0.041949
[epoch8, step1033]: loss 0.041760
[epoch8, step1034]: loss 0.041042
[epoch8, step1035]: loss 0.040770
[epoch8, step1036]: loss 0.041724
[epoch8, step1037]: loss 0.043350
[epoch8, step1038]: loss 0.040853
[epoch8, step1039]: loss 0.040474
[epoch8, step1040]: loss 0.042697
[epoch8, step1041]: loss 0.041501
[epoch8, step1042]: loss 0.041313
[epoch8, step1043]: loss 0.041094
[epoch8, step1044]: loss 0.041296
[epoch8, step1045]: loss 0.041703
[epoch8, step1046]: loss 0.043668
[epoch8, step1047]: loss 0.041138
[epoch8, step1048]: loss 0.040016
[epoch8, step1049]: loss 0.043173
[epoch8, step1050]: loss 0.041882
[epoch8, step1051]: loss 0.042154
[epoch8, step1052]: loss 0.041629
[epoch8, step1053]: loss 0.041679
[epoch8, step1054]: loss 0.041620
[epoch8, step1055]: loss 0.042982
[epoch8, step1056]: loss 0.040514
[epoch8, step1057]: loss 0.040808
[epoch8, step1058]: loss 0.043746
[epoch8, step1059]: loss 0.041877
[epoch8, step1060]: loss 0.042193
[epoch8, step1061]: loss 0.040699
[epoch8, step1062]: loss 0.041616
[epoch8, step1063]: loss 0.041631
[epoch8, step1064]: loss 0.043463
[epoch8, step1065]: loss 0.040917
[epoch8, step1066]: loss 0.039895
[epoch8, step1067]: loss 0.043130
[epoch8, step1068]: loss 0.040543
[epoch8, step1069]: loss 0.041513
[epoch8, step1070]: loss 0.041175
[epoch8, step1071]: loss 0.041719
[epoch8, step1072]: loss 0.042209
[epoch8, step1073]: loss 0.043238
[epoch8, step1074]: loss 0.040975
[epoch8, step1075]: loss 0.040557
[epoch8, step1076]: loss 0.043126
[epoch8, step1077]: loss 0.041659
[epoch8, step1078]: loss 0.041894
[epoch8, step1079]: loss 0.042087
[epoch8, step1080]: loss 0.041373
[epoch8, step1081]: loss 0.041409
[epoch8, step1082]: loss 0.043299
[epoch8, step1083]: loss 0.041545
[epoch8, step1084]: loss 0.040500
[epoch8, step1085]: loss 0.042670
[epoch8, step1086]: loss 0.041419
[epoch8, step1087]: loss 0.042136
[epoch8, step1088]: loss 0.041096
[epoch8, step1089]: loss 0.041608
[epoch8, step1090]: loss 0.042026
[epoch8, step1091]: loss 0.043756
[epoch8, step1092]: loss 0.040926
[epoch8, step1093]: loss 0.040222
[epoch8, step1094]: loss 0.042280
[epoch8, step1095]: loss 0.041310
[epoch8, step1096]: loss 0.041652
[epoch8, step1097]: loss 0.041227
[epoch8, step1098]: loss 0.041196
[epoch8, step1099]: loss 0.041323
[epoch8, step1100]: loss 0.043985
[epoch8, step1101]: loss 0.041329
[epoch8, step1102]: loss 0.040283
[epoch8, step1103]: loss 0.042685
[epoch8, step1104]: loss 0.041494
[epoch8, step1105]: loss 0.042177
[epoch8, step1106]: loss 0.040430
[epoch8, step1107]: loss 0.041425
[epoch8, step1108]: loss 0.041275
[epoch8, step1109]: loss 0.043739
[epoch8, step1110]: loss 0.041551
[epoch8, step1111]: loss 0.040494
[epoch8, step1112]: loss 0.043438
[epoch8, step1113]: loss 0.041335
[epoch8, step1114]: loss 0.042309
[epoch8, step1115]: loss 0.041269
[epoch8, step1116]: loss 0.041438
[epoch8, step1117]: loss 0.041706
[epoch8, step1118]: loss 0.043460
[epoch8, step1119]: loss 0.040846
[epoch8, step1120]: loss 0.040217
[epoch8, step1121]: loss 0.043054
[epoch8, step1122]: loss 0.041224
[epoch8, step1123]: loss 0.041440
[epoch8, step1124]: loss 0.041827
[epoch8, step1125]: loss 0.041620
[epoch8, step1126]: loss 0.042447
[epoch8, step1127]: loss 0.043535
[epoch8, step1128]: loss 0.041184
[epoch8, step1129]: loss 0.040244
[epoch8, step1130]: loss 0.043584
[epoch8, step1131]: loss 0.041952
[epoch8, step1132]: loss 0.042416
[epoch8, step1133]: loss 0.040879
[epoch8, step1134]: loss 0.041169
[epoch8, step1135]: loss 0.042435
[epoch8, step1136]: loss 0.044035
[epoch8, step1137]: loss 0.041119
[epoch8, step1138]: loss 0.040478
[epoch8, step1139]: loss 0.043166
[epoch8, step1140]: loss 0.041040
[epoch8, step1141]: loss 0.041830
[epoch8, step1142]: loss 0.041098
[epoch8, step1143]: loss 0.040988
[epoch8, step1144]: loss 0.041788
[epoch8, step1145]: loss 0.043083
[epoch8, step1146]: loss 0.040771
[epoch8, step1147]: loss 0.041028
[epoch8, step1148]: loss 0.043277
[epoch8, step1149]: loss 0.041408
[epoch8, step1150]: loss 0.041851
[epoch8, step1151]: loss 0.041475
[epoch8, step1152]: loss 0.041777
[epoch8, step1153]: loss 0.041127
[epoch8, step1154]: loss 0.043815
[epoch8, step1155]: loss 0.041100
[epoch8, step1156]: loss 0.039749
[epoch8, step1157]: loss 0.042969
[epoch8, step1158]: loss 0.041820
[epoch8, step1159]: loss 0.042192
[epoch8, step1160]: loss 0.041936
[epoch8, step1161]: loss 0.041767
[epoch8, step1162]: loss 0.041560
[epoch8, step1163]: loss 0.042978
[epoch8, step1164]: loss 0.040898
[epoch8, step1165]: loss 0.041239
[epoch8, step1166]: loss 0.043179
[epoch8, step1167]: loss 0.040985
[epoch8, step1168]: loss 0.042159
[epoch8, step1169]: loss 0.041011
[epoch8, step1170]: loss 0.041411
[epoch8, step1171]: loss 0.041496
[epoch8, step1172]: loss 0.043566
[epoch8, step1173]: loss 0.041099
[epoch8, step1174]: loss 0.040696
[epoch8, step1175]: loss 0.043034
[epoch8, step1176]: loss 0.041317
[epoch8, step1177]: loss 0.042315
[epoch8, step1178]: loss 0.041372
[epoch8, step1179]: loss 0.041142
[epoch8, step1180]: loss 0.041765
[epoch8, step1181]: loss 0.044032
[epoch8, step1182]: loss 0.040461
[epoch8, step1183]: loss 0.040778
[epoch8, step1184]: loss 0.042726
[epoch8, step1185]: loss 0.041644
[epoch8, step1186]: loss 0.041421
[epoch8, step1187]: loss 0.040520
[epoch8, step1188]: loss 0.040823
[epoch8, step1189]: loss 0.041336
[epoch8, step1190]: loss 0.043147
[epoch8, step1191]: loss 0.041549
[epoch8, step1192]: loss 0.040325
[epoch8, step1193]: loss 0.042951
[epoch8, step1194]: loss 0.041423
[epoch8, step1195]: loss 0.041035
[epoch8, step1196]: loss 0.040593
[epoch8, step1197]: loss 0.041604
[epoch8, step1198]: loss 0.041635
[epoch8, step1199]: loss 0.043152
[epoch8, step1200]: loss 0.040753
[epoch8, step1201]: loss 0.040732
[epoch8, step1202]: loss 0.043852
[epoch8, step1203]: loss 0.041655
[epoch8, step1204]: loss 0.041471
[epoch8, step1205]: loss 0.040781
[epoch8, step1206]: loss 0.040955
[epoch8, step1207]: loss 0.041799
[epoch8, step1208]: loss 0.043619
[epoch8, step1209]: loss 0.040013
[epoch8, step1210]: loss 0.040774
[epoch8, step1211]: loss 0.042616
[epoch8, step1212]: loss 0.041358
[epoch8, step1213]: loss 0.041647
[epoch8, step1214]: loss 0.041364
[epoch8, step1215]: loss 0.041870
[epoch8, step1216]: loss 0.041314
[epoch8, step1217]: loss 0.043974
[epoch8, step1218]: loss 0.040675
[epoch8, step1219]: loss 0.040947
[epoch8, step1220]: loss 0.043338
[epoch8, step1221]: loss 0.040841
[epoch8, step1222]: loss 0.042087
[epoch8, step1223]: loss 0.041091
[epoch8, step1224]: loss 0.041679
[epoch8, step1225]: loss 0.041631
[epoch8, step1226]: loss 0.043206
[epoch8, step1227]: loss 0.040938
[epoch8, step1228]: loss 0.040035
[epoch8, step1229]: loss 0.042896
[epoch8, step1230]: loss 0.041729
[epoch8, step1231]: loss 0.041827
[epoch8, step1232]: loss 0.042104
[epoch8, step1233]: loss 0.041278
[epoch8, step1234]: loss 0.041433
[epoch8, step1235]: loss 0.043966
[epoch8, step1236]: loss 0.041193
[epoch8, step1237]: loss 0.040084
[epoch8, step1238]: loss 0.042605
[epoch8, step1239]: loss 0.041976
[epoch8, step1240]: loss 0.042261
[epoch8, step1241]: loss 0.040868
[epoch8, step1242]: loss 0.041324
[epoch8, step1243]: loss 0.041477
[epoch8, step1244]: loss 0.043663
[epoch8, step1245]: loss 0.041233
[epoch8, step1246]: loss 0.040637
[epoch8, step1247]: loss 0.042344
[epoch8, step1248]: loss 0.041662
[epoch8, step1249]: loss 0.042323
[epoch8, step1250]: loss 0.041128
[epoch8, step1251]: loss 0.041458
[epoch8, step1252]: loss 0.042377
[epoch8, step1253]: loss 0.043626
[epoch8, step1254]: loss 0.041001
[epoch8, step1255]: loss 0.040505
[epoch8, step1256]: loss 0.043404
[epoch8, step1257]: loss 0.041676
[epoch8, step1258]: loss 0.042072
[epoch8, step1259]: loss 0.040874
[epoch8, step1260]: loss 0.041406
[epoch8, step1261]: loss 0.041401
[epoch8, step1262]: loss 0.042413
[epoch8, step1263]: loss 0.041375
[epoch8, step1264]: loss 0.040256
[epoch8, step1265]: loss 0.041980
[epoch8, step1266]: loss 0.041417
[epoch8, step1267]: loss 0.041927
[epoch8, step1268]: loss 0.041269
[epoch8, step1269]: loss 0.041380
[epoch8, step1270]: loss 0.040988
[epoch8, step1271]: loss 0.043767
[epoch8, step1272]: loss 0.040919
[epoch8, step1273]: loss 0.040134
[epoch8, step1274]: loss 0.042759
[epoch8, step1275]: loss 0.041777
[epoch8, step1276]: loss 0.041501
[epoch8, step1277]: loss 0.040950
[epoch8, step1278]: loss 0.041731
[epoch8, step1279]: loss 0.041522
[epoch8, step1280]: loss 0.043415
[epoch8, step1281]: loss 0.040551
[epoch8, step1282]: loss 0.039927
[epoch8, step1283]: loss 0.042224
[epoch8, step1284]: loss 0.040820
[epoch8, step1285]: loss 0.041913
[epoch8, step1286]: loss 0.040137
[epoch8, step1287]: loss 0.041546
[epoch8, step1288]: loss 0.041798
[epoch8, step1289]: loss 0.043688
[epoch8, step1290]: loss 0.040434
[epoch8, step1291]: loss 0.039610
[epoch8, step1292]: loss 0.042830
[epoch8, step1293]: loss 0.040216
[epoch8, step1294]: loss 0.041102
[epoch8, step1295]: loss 0.040693
[epoch8, step1296]: loss 0.040827
[epoch8, step1297]: loss 0.040566
[epoch8, step1298]: loss 0.042985
[epoch8, step1299]: loss 0.040118
[epoch8, step1300]: loss 0.040048
[epoch8, step1301]: loss 0.041355
[epoch8, step1302]: loss 0.040604
[epoch8, step1303]: loss 0.040903
[epoch8, step1304]: loss 0.039457
[epoch8, step1305]: loss 0.040515
[epoch8, step1306]: loss 0.040276
[epoch8, step1307]: loss 0.041671
[epoch8, step1308]: loss 0.039650
[epoch8, step1309]: loss 0.038504
[epoch8, step1310]: loss 0.041665
[epoch8, step1311]: loss 0.039295
[epoch8, step1312]: loss 0.040916
[epoch8, step1313]: loss 0.039498
[epoch8, step1314]: loss 0.039937
[epoch8, step1315]: loss 0.039844
[epoch8, step1316]: loss 0.042931
[epoch8, step1317]: loss 0.038532
[epoch8, step1318]: loss 0.038189
[epoch8, step1319]: loss 0.040797
[epoch8, step1320]: loss 0.039886
[epoch8, step1321]: loss 0.040071
[epoch8, step1322]: loss 0.038493
[epoch8, step1323]: loss 0.039754
[epoch8, step1324]: loss 0.039174
[epoch8, step1325]: loss 0.040942
[epoch8, step1326]: loss 0.038008
[epoch8, step1327]: loss 0.037657
[epoch8, step1328]: loss 0.040747
[epoch8, step1329]: loss 0.038993
[epoch8, step1330]: loss 0.039054
[epoch8, step1331]: loss 0.037651
[epoch8, step1332]: loss 0.038771
[epoch8, step1333]: loss 0.038124
[epoch8, step1334]: loss 0.040582
[epoch8, step1335]: loss 0.037997
[epoch8, step1336]: loss 0.037221
[epoch8, step1337]: loss 0.039705
[epoch8, step1338]: loss 0.038497
[epoch8, step1339]: loss 0.038391
[epoch8, step1340]: loss 0.036954
[epoch8, step1341]: loss 0.038955
[epoch8, step1342]: loss 0.038696
[epoch8, step1343]: loss 0.040134
[epoch8, step1344]: loss 0.037285
[epoch8, step1345]: loss 0.037146
[epoch8, step1346]: loss 0.039806
[epoch8, step1347]: loss 0.039153
[epoch8, step1348]: loss 0.037757
[epoch8, step1349]: loss 0.037040
[epoch8, step1350]: loss 0.038661
[epoch8, step1351]: loss 0.038252
[epoch8, step1352]: loss 0.039092
[epoch8, step1353]: loss 0.036724
[epoch8, step1354]: loss 0.036467
[epoch8, step1355]: loss 0.040055
[epoch8, step1356]: loss 0.037952
[epoch8, step1357]: loss 0.037437
[epoch8, step1358]: loss 0.036566
[epoch8, step1359]: loss 0.038017
[epoch8, step1360]: loss 0.038829
[epoch8, step1361]: loss 0.039913
[epoch8, step1362]: loss 0.037516
[epoch8, step1363]: loss 0.037425
[epoch8, step1364]: loss 0.039672
[epoch8, step1365]: loss 0.038397
[epoch8, step1366]: loss 0.037822
[epoch8, step1367]: loss 0.036109
[epoch8, step1368]: loss 0.039344
[epoch8, step1369]: loss 0.038622
[epoch8, step1370]: loss 0.039421
[epoch8, step1371]: loss 0.037034
[epoch8, step1372]: loss 0.036351
[epoch8, step1373]: loss 0.039676
[epoch8, step1374]: loss 0.038847
[epoch8, step1375]: loss 0.038554
[epoch8, step1376]: loss 0.036279
[epoch8, step1377]: loss 0.037504
[epoch8, step1378]: loss 0.038447
[epoch8, step1379]: loss 0.038962
[epoch8, step1380]: loss 0.037109
[epoch8, step1381]: loss 0.036499
[epoch8, step1382]: loss 0.039940
[epoch8, step1383]: loss 0.037970
[epoch8, step1384]: loss 0.037625
[epoch8, step1385]: loss 0.035954
[epoch8, step1386]: loss 0.038475
[epoch8, step1387]: loss 0.038822
[epoch8, step1388]: loss 0.038418
[epoch8, step1389]: loss 0.035956
[epoch8, step1390]: loss 0.036837
[epoch8, step1391]: loss 0.039272
[epoch8, step1392]: loss 0.037939
[epoch8, step1393]: loss 0.038086
[epoch8, step1394]: loss 0.037035
[epoch8, step1395]: loss 0.038453
[epoch8, step1396]: loss 0.037817
[epoch8, step1397]: loss 0.039074
[epoch8, step1398]: loss 0.036542
[epoch8, step1399]: loss 0.037331
[epoch8, step1400]: loss 0.039918
[epoch8, step1401]: loss 0.037731
[epoch8, step1402]: loss 0.037824
[epoch8, step1403]: loss 0.035463
[epoch8, step1404]: loss 0.037669
[epoch8, step1405]: loss 0.038057
[epoch8, step1406]: loss 0.039016
[epoch8, step1407]: loss 0.037601
[epoch8, step1408]: loss 0.035996
[epoch8, step1409]: loss 0.039004
[epoch8, step1410]: loss 0.037941
[epoch8, step1411]: loss 0.036721
[epoch8, step1412]: loss 0.036526
[epoch8, step1413]: loss 0.038261
[epoch8, step1414]: loss 0.037814
[epoch8, step1415]: loss 0.038941
[epoch8, step1416]: loss 0.036510
[epoch8, step1417]: loss 0.036435
[epoch8, step1418]: loss 0.039375
[epoch8, step1419]: loss 0.038698
[epoch8, step1420]: loss 0.037910
[epoch8, step1421]: loss 0.036779
[epoch8, step1422]: loss 0.038293
[epoch8, step1423]: loss 0.037704
[epoch8, step1424]: loss 0.039456
[epoch8, step1425]: loss 0.035518
[epoch8, step1426]: loss 0.036640
[epoch8, step1427]: loss 0.040215
[epoch8, step1428]: loss 0.038691
[epoch8, step1429]: loss 0.037763
[epoch8, step1430]: loss 0.036456
[epoch8, step1431]: loss 0.038254
[epoch8, step1432]: loss 0.037902
[epoch8, step1433]: loss 0.039374
[epoch8, step1434]: loss 0.035923
[epoch8, step1435]: loss 0.036929
[epoch8, step1436]: loss 0.039667
[epoch8, step1437]: loss 0.038202
[epoch8, step1438]: loss 0.038269
[epoch8, step1439]: loss 0.036258
[epoch8, step1440]: loss 0.037912
[epoch8, step1441]: loss 0.038714
[epoch8, step1442]: loss 0.038491
[epoch8, step1443]: loss 0.036165
[epoch8, step1444]: loss 0.035783
[epoch8, step1445]: loss 0.039751
[epoch8, step1446]: loss 0.038043
[epoch8, step1447]: loss 0.038422
[epoch8, step1448]: loss 0.036318
[epoch8, step1449]: loss 0.037427
[epoch8, step1450]: loss 0.038126
[epoch8, step1451]: loss 0.039514
[epoch8, step1452]: loss 0.036180
[epoch8, step1453]: loss 0.037463
[epoch8, step1454]: loss 0.039698
[epoch8, step1455]: loss 0.038443
[epoch8, step1456]: loss 0.037247
[epoch8, step1457]: loss 0.036855
[epoch8, step1458]: loss 0.038143
[epoch8, step1459]: loss 0.037975
[epoch8, step1460]: loss 0.039734
[epoch8, step1461]: loss 0.037089
[epoch8, step1462]: loss 0.037095
[epoch8, step1463]: loss 0.039269
[epoch8, step1464]: loss 0.038051
[epoch8, step1465]: loss 0.037297
[epoch8, step1466]: loss 0.035930
[epoch8, step1467]: loss 0.037955
[epoch8, step1468]: loss 0.037518
[epoch8, step1469]: loss 0.039026
[epoch8, step1470]: loss 0.036513
[epoch8, step1471]: loss 0.036051
[epoch8, step1472]: loss 0.039040
[epoch8, step1473]: loss 0.037754
[epoch8, step1474]: loss 0.038186
[epoch8, step1475]: loss 0.035924
[epoch8, step1476]: loss 0.038806
[epoch8, step1477]: loss 0.037698
[epoch8, step1478]: loss 0.039216
[epoch8, step1479]: loss 0.036305
[epoch8, step1480]: loss 0.036393
[epoch8, step1481]: loss 0.038329
[epoch8, step1482]: loss 0.037762
[epoch8, step1483]: loss 0.037710
[epoch8, step1484]: loss 0.036594
[epoch8, step1485]: loss 0.037773
[epoch8, step1486]: loss 0.036922
[epoch8, step1487]: loss 0.038895
[epoch8, step1488]: loss 0.036531
[epoch8, step1489]: loss 0.036151
[epoch8, step1490]: loss 0.039285
[epoch8, step1491]: loss 0.037867
[epoch8, step1492]: loss 0.037314
[epoch8, step1493]: loss 0.036262
[epoch8, step1494]: loss 0.038099
[epoch8, step1495]: loss 0.037677
[epoch8, step1496]: loss 0.038245
[epoch8, step1497]: loss 0.036674
[epoch8, step1498]: loss 0.036709
[epoch8, step1499]: loss 0.038591
[epoch8, step1500]: loss 0.038118
[epoch8, step1501]: loss 0.037713
[epoch8, step1502]: loss 0.035951
[epoch8, step1503]: loss 0.037927
[epoch8, step1504]: loss 0.037463
[epoch8, step1505]: loss 0.039315
[epoch8, step1506]: loss 0.035774
[epoch8, step1507]: loss 0.036643
[epoch8, step1508]: loss 0.039712
[epoch8, step1509]: loss 0.037440
[epoch8, step1510]: loss 0.036960
[epoch8, step1511]: loss 0.036798
[epoch8, step1512]: loss 0.038004
[epoch8, step1513]: loss 0.036610
[epoch8, step1514]: loss 0.039059
[epoch8, step1515]: loss 0.036788
[epoch8, step1516]: loss 0.036320

[epoch8]: avg loss 0.035558

[epoch9, step1]: loss 0.034091
[epoch9, step2]: loss 0.038825
[epoch9, step3]: loss 0.038781
[epoch9, step4]: loss 0.036076
[epoch9, step5]: loss 0.036805
[epoch9, step6]: loss 0.039125
[epoch9, step7]: loss 0.037215
[epoch9, step8]: loss 0.039286
[epoch9, step9]: loss 0.035844
[epoch9, step10]: loss 0.037654
[epoch9, step11]: loss 0.039151
[epoch9, step12]: loss 0.039063
[epoch9, step13]: loss 0.036420
[epoch9, step14]: loss 0.036708
[epoch9, step15]: loss 0.039137
[epoch9, step16]: loss 0.036929
[epoch9, step17]: loss 0.039539
[epoch9, step18]: loss 0.036926
[epoch9, step19]: loss 0.036942
[epoch9, step20]: loss 0.039994
[epoch9, step21]: loss 0.038927
[epoch9, step22]: loss 0.035900
[epoch9, step23]: loss 0.035640
[epoch9, step24]: loss 0.039134
[epoch9, step25]: loss 0.036286
[epoch9, step26]: loss 0.038648
[epoch9, step27]: loss 0.035611
[epoch9, step28]: loss 0.037115
[epoch9, step29]: loss 0.039277
[epoch9, step30]: loss 0.039680
[epoch9, step31]: loss 0.035783
[epoch9, step32]: loss 0.036917
[epoch9, step33]: loss 0.039669
[epoch9, step34]: loss 0.037470
[epoch9, step35]: loss 0.039779
[epoch9, step36]: loss 0.035896
[epoch9, step37]: loss 0.036980
[epoch9, step38]: loss 0.038991
[epoch9, step39]: loss 0.039001
[epoch9, step40]: loss 0.036624
[epoch9, step41]: loss 0.035885
[epoch9, step42]: loss 0.039431
[epoch9, step43]: loss 0.036798
[epoch9, step44]: loss 0.039784
[epoch9, step45]: loss 0.036097
[epoch9, step46]: loss 0.037019
[epoch9, step47]: loss 0.038646
[epoch9, step48]: loss 0.038695
[epoch9, step49]: loss 0.034591
[epoch9, step50]: loss 0.036570
[epoch9, step51]: loss 0.038926
[epoch9, step52]: loss 0.036605
[epoch9, step53]: loss 0.039784
[epoch9, step54]: loss 0.035856
[epoch9, step55]: loss 0.037450
[epoch9, step56]: loss 0.040060
[epoch9, step57]: loss 0.039500
[epoch9, step58]: loss 0.036245
[epoch9, step59]: loss 0.035497
[epoch9, step60]: loss 0.039605
[epoch9, step61]: loss 0.035981
[epoch9, step62]: loss 0.038685
[epoch9, step63]: loss 0.035477
[epoch9, step64]: loss 0.036493
[epoch9, step65]: loss 0.039294
[epoch9, step66]: loss 0.039043
[epoch9, step67]: loss 0.036376
[epoch9, step68]: loss 0.036411
[epoch9, step69]: loss 0.039050
[epoch9, step70]: loss 0.036609
[epoch9, step71]: loss 0.038865
[epoch9, step72]: loss 0.036149
[epoch9, step73]: loss 0.036847
[epoch9, step74]: loss 0.039153
[epoch9, step75]: loss 0.039310
[epoch9, step76]: loss 0.036767
[epoch9, step77]: loss 0.037078
[epoch9, step78]: loss 0.039382
[epoch9, step79]: loss 0.036109
[epoch9, step80]: loss 0.040020
[epoch9, step81]: loss 0.036123
[epoch9, step82]: loss 0.036476
[epoch9, step83]: loss 0.038627
[epoch9, step84]: loss 0.039252
[epoch9, step85]: loss 0.036858
[epoch9, step86]: loss 0.036735
[epoch9, step87]: loss 0.040238
[epoch9, step88]: loss 0.035584
[epoch9, step89]: loss 0.039005
[epoch9, step90]: loss 0.036563
[epoch9, step91]: loss 0.036353
[epoch9, step92]: loss 0.039456
[epoch9, step93]: loss 0.039111
[epoch9, step94]: loss 0.036114
[epoch9, step95]: loss 0.037006
[epoch9, step96]: loss 0.038825
[epoch9, step97]: loss 0.037378
[epoch9, step98]: loss 0.039391
[epoch9, step99]: loss 0.036161
[epoch9, step100]: loss 0.035829
[epoch9, step101]: loss 0.039784
[epoch9, step102]: loss 0.038994
[epoch9, step103]: loss 0.036223
[epoch9, step104]: loss 0.036592
[epoch9, step105]: loss 0.039346
[epoch9, step106]: loss 0.036803
[epoch9, step107]: loss 0.039243
[epoch9, step108]: loss 0.036482
[epoch9, step109]: loss 0.036531
[epoch9, step110]: loss 0.039735
[epoch9, step111]: loss 0.038891
[epoch9, step112]: loss 0.036367
[epoch9, step113]: loss 0.037262
[epoch9, step114]: loss 0.038958
[epoch9, step115]: loss 0.036644
[epoch9, step116]: loss 0.040103
[epoch9, step117]: loss 0.036043
[epoch9, step118]: loss 0.037523
[epoch9, step119]: loss 0.039578
[epoch9, step120]: loss 0.039252
[epoch9, step121]: loss 0.036013
[epoch9, step122]: loss 0.036346
[epoch9, step123]: loss 0.039512
[epoch9, step124]: loss 0.037054
[epoch9, step125]: loss 0.039674
[epoch9, step126]: loss 0.036042
[epoch9, step127]: loss 0.036584
[epoch9, step128]: loss 0.039048
[epoch9, step129]: loss 0.038876
[epoch9, step130]: loss 0.036350
[epoch9, step131]: loss 0.035812
[epoch9, step132]: loss 0.039276
[epoch9, step133]: loss 0.036485
[epoch9, step134]: loss 0.038576
[epoch9, step135]: loss 0.036688
[epoch9, step136]: loss 0.037864
[epoch9, step137]: loss 0.038902
[epoch9, step138]: loss 0.039033
[epoch9, step139]: loss 0.036129
[epoch9, step140]: loss 0.036947
[epoch9, step141]: loss 0.039479
[epoch9, step142]: loss 0.036608
[epoch9, step143]: loss 0.038738
[epoch9, step144]: loss 0.036414
[epoch9, step145]: loss 0.036807
[epoch9, step146]: loss 0.039194
[epoch9, step147]: loss 0.040396
[epoch9, step148]: loss 0.035866
[epoch9, step149]: loss 0.035966
[epoch9, step150]: loss 0.038928
[epoch9, step151]: loss 0.036722
[epoch9, step152]: loss 0.039099
[epoch9, step153]: loss 0.036284
[epoch9, step154]: loss 0.036427
[epoch9, step155]: loss 0.039102
[epoch9, step156]: loss 0.038714
[epoch9, step157]: loss 0.036298
[epoch9, step158]: loss 0.036690
[epoch9, step159]: loss 0.039423
[epoch9, step160]: loss 0.036964
[epoch9, step161]: loss 0.039703
[epoch9, step162]: loss 0.036412
[epoch9, step163]: loss 0.036751
[epoch9, step164]: loss 0.039431
[epoch9, step165]: loss 0.039101
[epoch9, step166]: loss 0.036542
[epoch9, step167]: loss 0.036012
[epoch9, step168]: loss 0.039873
[epoch9, step169]: loss 0.036348
[epoch9, step170]: loss 0.039498
[epoch9, step171]: loss 0.036526
[epoch9, step172]: loss 0.036931
[epoch9, step173]: loss 0.039483
[epoch9, step174]: loss 0.038906
[epoch9, step175]: loss 0.036917
[epoch9, step176]: loss 0.036705
[epoch9, step177]: loss 0.039639
[epoch9, step178]: loss 0.036648
[epoch9, step179]: loss 0.038349
[epoch9, step180]: loss 0.036528
[epoch9, step181]: loss 0.036910
[epoch9, step182]: loss 0.039522
[epoch9, step183]: loss 0.039800
[epoch9, step184]: loss 0.037207
[epoch9, step185]: loss 0.036690
[epoch9, step186]: loss 0.039463
[epoch9, step187]: loss 0.036839
[epoch9, step188]: loss 0.038968
[epoch9, step189]: loss 0.036282
[epoch9, step190]: loss 0.036223
[epoch9, step191]: loss 0.039065
[epoch9, step192]: loss 0.039739
[epoch9, step193]: loss 0.034382
[epoch9, step194]: loss 0.035654
[epoch9, step195]: loss 0.039581
[epoch9, step196]: loss 0.036778
[epoch9, step197]: loss 0.039063
[epoch9, step198]: loss 0.035347
[epoch9, step199]: loss 0.036895
[epoch9, step200]: loss 0.039681
[epoch9, step201]: loss 0.039612
[epoch9, step202]: loss 0.035882
[epoch9, step203]: loss 0.036493
[epoch9, step204]: loss 0.039832
[epoch9, step205]: loss 0.036081
[epoch9, step206]: loss 0.038849
[epoch9, step207]: loss 0.036100
[epoch9, step208]: loss 0.037193
[epoch9, step209]: loss 0.039473
[epoch9, step210]: loss 0.040090
[epoch9, step211]: loss 0.036858
[epoch9, step212]: loss 0.036904
[epoch9, step213]: loss 0.038912
[epoch9, step214]: loss 0.036076
[epoch9, step215]: loss 0.039533
[epoch9, step216]: loss 0.036509
[epoch9, step217]: loss 0.035940
[epoch9, step218]: loss 0.039555
[epoch9, step219]: loss 0.039011
[epoch9, step220]: loss 0.036603
[epoch9, step221]: loss 0.036746
[epoch9, step222]: loss 0.039685
[epoch9, step223]: loss 0.036883
[epoch9, step224]: loss 0.038863
[epoch9, step225]: loss 0.036144
[epoch9, step226]: loss 0.036601
[epoch9, step227]: loss 0.038259
[epoch9, step228]: loss 0.039780
[epoch9, step229]: loss 0.035409
[epoch9, step230]: loss 0.036832
[epoch9, step231]: loss 0.039802
[epoch9, step232]: loss 0.036334
[epoch9, step233]: loss 0.038467
[epoch9, step234]: loss 0.035813
[epoch9, step235]: loss 0.037077
[epoch9, step236]: loss 0.039236
[epoch9, step237]: loss 0.039268
[epoch9, step238]: loss 0.036060
[epoch9, step239]: loss 0.035812
[epoch9, step240]: loss 0.038796
[epoch9, step241]: loss 0.037133
[epoch9, step242]: loss 0.039059
[epoch9, step243]: loss 0.036945
[epoch9, step244]: loss 0.036645
[epoch9, step245]: loss 0.038801
[epoch9, step246]: loss 0.039237
[epoch9, step247]: loss 0.036561
[epoch9, step248]: loss 0.036116
[epoch9, step249]: loss 0.038750
[epoch9, step250]: loss 0.036929
[epoch9, step251]: loss 0.039690
[epoch9, step252]: loss 0.036727
[epoch9, step253]: loss 0.036353
[epoch9, step254]: loss 0.038775
[epoch9, step255]: loss 0.039342
[epoch9, step256]: loss 0.036021
[epoch9, step257]: loss 0.036299
[epoch9, step258]: loss 0.039906
[epoch9, step259]: loss 0.036690
[epoch9, step260]: loss 0.038763
[epoch9, step261]: loss 0.036973
[epoch9, step262]: loss 0.037175
[epoch9, step263]: loss 0.038586
[epoch9, step264]: loss 0.038946
[epoch9, step265]: loss 0.036532
[epoch9, step266]: loss 0.036475
[epoch9, step267]: loss 0.038586
[epoch9, step268]: loss 0.036539
[epoch9, step269]: loss 0.039223
[epoch9, step270]: loss 0.035752
[epoch9, step271]: loss 0.036841
[epoch9, step272]: loss 0.039134
[epoch9, step273]: loss 0.038907
[epoch9, step274]: loss 0.036721
[epoch9, step275]: loss 0.036010
[epoch9, step276]: loss 0.038914
[epoch9, step277]: loss 0.037120
[epoch9, step278]: loss 0.039334
[epoch9, step279]: loss 0.035886
[epoch9, step280]: loss 0.036761
[epoch9, step281]: loss 0.039078
[epoch9, step282]: loss 0.039680
[epoch9, step283]: loss 0.035911
[epoch9, step284]: loss 0.036027
[epoch9, step285]: loss 0.040039
[epoch9, step286]: loss 0.035887
[epoch9, step287]: loss 0.039467
[epoch9, step288]: loss 0.035766
[epoch9, step289]: loss 0.037511
[epoch9, step290]: loss 0.039227
[epoch9, step291]: loss 0.039500
[epoch9, step292]: loss 0.035424
[epoch9, step293]: loss 0.036085
[epoch9, step294]: loss 0.038528
[epoch9, step295]: loss 0.036110
[epoch9, step296]: loss 0.039959
[epoch9, step297]: loss 0.035928
[epoch9, step298]: loss 0.037092
[epoch9, step299]: loss 0.038268
[epoch9, step300]: loss 0.039555
[epoch9, step301]: loss 0.036235
[epoch9, step302]: loss 0.036754
[epoch9, step303]: loss 0.039651
[epoch9, step304]: loss 0.036238
[epoch9, step305]: loss 0.038843
[epoch9, step306]: loss 0.036327
[epoch9, step307]: loss 0.036330
[epoch9, step308]: loss 0.039696
[epoch9, step309]: loss 0.039494
[epoch9, step310]: loss 0.036380
[epoch9, step311]: loss 0.036820
[epoch9, step312]: loss 0.038888
[epoch9, step313]: loss 0.036919
[epoch9, step314]: loss 0.039125
[epoch9, step315]: loss 0.037184
[epoch9, step316]: loss 0.036505
[epoch9, step317]: loss 0.039461
[epoch9, step318]: loss 0.039287
[epoch9, step319]: loss 0.035853
[epoch9, step320]: loss 0.035469
[epoch9, step321]: loss 0.038806
[epoch9, step322]: loss 0.036494
[epoch9, step323]: loss 0.038555
[epoch9, step324]: loss 0.037020
[epoch9, step325]: loss 0.036867
[epoch9, step326]: loss 0.038905
[epoch9, step327]: loss 0.038522
[epoch9, step328]: loss 0.036424
[epoch9, step329]: loss 0.036142
[epoch9, step330]: loss 0.038727
[epoch9, step331]: loss 0.036865
[epoch9, step332]: loss 0.038561
[epoch9, step333]: loss 0.036147
[epoch9, step334]: loss 0.036682
[epoch9, step335]: loss 0.039313
[epoch9, step336]: loss 0.040087
[epoch9, step337]: loss 0.036590
[epoch9, step338]: loss 0.035963
[epoch9, step339]: loss 0.039090
[epoch9, step340]: loss 0.037110
[epoch9, step341]: loss 0.038607
[epoch9, step342]: loss 0.035911
[epoch9, step343]: loss 0.036906
[epoch9, step344]: loss 0.038674
[epoch9, step345]: loss 0.038467
[epoch9, step346]: loss 0.035765
[epoch9, step347]: loss 0.036038
[epoch9, step348]: loss 0.039381
[epoch9, step349]: loss 0.037059
[epoch9, step350]: loss 0.038638
[epoch9, step351]: loss 0.035495
[epoch9, step352]: loss 0.036531
[epoch9, step353]: loss 0.038999
[epoch9, step354]: loss 0.038200
[epoch9, step355]: loss 0.035144
[epoch9, step356]: loss 0.036985
[epoch9, step357]: loss 0.039242
[epoch9, step358]: loss 0.035108
[epoch9, step359]: loss 0.039959
[epoch9, step360]: loss 0.034992
[epoch9, step361]: loss 0.036072
[epoch9, step362]: loss 0.039694
[epoch9, step363]: loss 0.038850
[epoch9, step364]: loss 0.036089
[epoch9, step365]: loss 0.036084
[epoch9, step366]: loss 0.039529
[epoch9, step367]: loss 0.036596
[epoch9, step368]: loss 0.038470
[epoch9, step369]: loss 0.035977
[epoch9, step370]: loss 0.037188
[epoch9, step371]: loss 0.039875
[epoch9, step372]: loss 0.038755
[epoch9, step373]: loss 0.035630
[epoch9, step374]: loss 0.035589
[epoch9, step375]: loss 0.039715
[epoch9, step376]: loss 0.036552
[epoch9, step377]: loss 0.039223
[epoch9, step378]: loss 0.036607
[epoch9, step379]: loss 0.037213
[epoch9, step380]: loss 0.039744
[epoch9, step381]: loss 0.038795
[epoch9, step382]: loss 0.036462
[epoch9, step383]: loss 0.035362
[epoch9, step384]: loss 0.038442
[epoch9, step385]: loss 0.036387
[epoch9, step386]: loss 0.039283
[epoch9, step387]: loss 0.036165
[epoch9, step388]: loss 0.037507
[epoch9, step389]: loss 0.039063
[epoch9, step390]: loss 0.039994
[epoch9, step391]: loss 0.035867
[epoch9, step392]: loss 0.036908
[epoch9, step393]: loss 0.038624
[epoch9, step394]: loss 0.036582
[epoch9, step395]: loss 0.038800
[epoch9, step396]: loss 0.036199
[epoch9, step397]: loss 0.036265
[epoch9, step398]: loss 0.039247
[epoch9, step399]: loss 0.039019
[epoch9, step400]: loss 0.035841
[epoch9, step401]: loss 0.036118
[epoch9, step402]: loss 0.038989
[epoch9, step403]: loss 0.036445
[epoch9, step404]: loss 0.039426
[epoch9, step405]: loss 0.036468
[epoch9, step406]: loss 0.036946
[epoch9, step407]: loss 0.038882
[epoch9, step408]: loss 0.039226
[epoch9, step409]: loss 0.037423
[epoch9, step410]: loss 0.036927
[epoch9, step411]: loss 0.039021
[epoch9, step412]: loss 0.036030
[epoch9, step413]: loss 0.039039
[epoch9, step414]: loss 0.035827
[epoch9, step415]: loss 0.037008
[epoch9, step416]: loss 0.038448
[epoch9, step417]: loss 0.039317
[epoch9, step418]: loss 0.036057
[epoch9, step419]: loss 0.035532
[epoch9, step420]: loss 0.039383
[epoch9, step421]: loss 0.036225
[epoch9, step422]: loss 0.039027
[epoch9, step423]: loss 0.036321
[epoch9, step424]: loss 0.036829
[epoch9, step425]: loss 0.039231
[epoch9, step426]: loss 0.039554
[epoch9, step427]: loss 0.036544
[epoch9, step428]: loss 0.036233
[epoch9, step429]: loss 0.039806
[epoch9, step430]: loss 0.036423
[epoch9, step431]: loss 0.039423
[epoch9, step432]: loss 0.036123
[epoch9, step433]: loss 0.037481
[epoch9, step434]: loss 0.038976
[epoch9, step435]: loss 0.039560
[epoch9, step436]: loss 0.035907
[epoch9, step437]: loss 0.036506
[epoch9, step438]: loss 0.039779
[epoch9, step439]: loss 0.036777
[epoch9, step440]: loss 0.039075
[epoch9, step441]: loss 0.036521
[epoch9, step442]: loss 0.036637
[epoch9, step443]: loss 0.039590
[epoch9, step444]: loss 0.038856
[epoch9, step445]: loss 0.036638
[epoch9, step446]: loss 0.036756
[epoch9, step447]: loss 0.039883
[epoch9, step448]: loss 0.036666
[epoch9, step449]: loss 0.038897
[epoch9, step450]: loss 0.035492
[epoch9, step451]: loss 0.036506
[epoch9, step452]: loss 0.037992
[epoch9, step453]: loss 0.039329
[epoch9, step454]: loss 0.036103
[epoch9, step455]: loss 0.036506
[epoch9, step456]: loss 0.038400
[epoch9, step457]: loss 0.037146
[epoch9, step458]: loss 0.038794
[epoch9, step459]: loss 0.036825
[epoch9, step460]: loss 0.036872
[epoch9, step461]: loss 0.039800
[epoch9, step462]: loss 0.038502
[epoch9, step463]: loss 0.036289
[epoch9, step464]: loss 0.036181
[epoch9, step465]: loss 0.040546
[epoch9, step466]: loss 0.036429
[epoch9, step467]: loss 0.038787
[epoch9, step468]: loss 0.036178
[epoch9, step469]: loss 0.036839
[epoch9, step470]: loss 0.039356
[epoch9, step471]: loss 0.038683
[epoch9, step472]: loss 0.036646
[epoch9, step473]: loss 0.035901
[epoch9, step474]: loss 0.038985
[epoch9, step475]: loss 0.036653
[epoch9, step476]: loss 0.039493
[epoch9, step477]: loss 0.035995
[epoch9, step478]: loss 0.036153
[epoch9, step479]: loss 0.038964
[epoch9, step480]: loss 0.038274
[epoch9, step481]: loss 0.035691
[epoch9, step482]: loss 0.035776
[epoch9, step483]: loss 0.039632
[epoch9, step484]: loss 0.036732
[epoch9, step485]: loss 0.039283
[epoch9, step486]: loss 0.036491
[epoch9, step487]: loss 0.036241
[epoch9, step488]: loss 0.039707
[epoch9, step489]: loss 0.038354
[epoch9, step490]: loss 0.036576
[epoch9, step491]: loss 0.036530
[epoch9, step492]: loss 0.038896
[epoch9, step493]: loss 0.036315
[epoch9, step494]: loss 0.038459
[epoch9, step495]: loss 0.037325
[epoch9, step496]: loss 0.036795
[epoch9, step497]: loss 0.039568
[epoch9, step498]: loss 0.039249
[epoch9, step499]: loss 0.036547
[epoch9, step500]: loss 0.035835
[epoch9, step501]: loss 0.038684
[epoch9, step502]: loss 0.036451
[epoch9, step503]: loss 0.039321
[epoch9, step504]: loss 0.036016
[epoch9, step505]: loss 0.035846
[epoch9, step506]: loss 0.039570
[epoch9, step507]: loss 0.039597
[epoch9, step508]: loss 0.036700
[epoch9, step509]: loss 0.036260
[epoch9, step510]: loss 0.039397
[epoch9, step511]: loss 0.036921
[epoch9, step512]: loss 0.039490
[epoch9, step513]: loss 0.036507
[epoch9, step514]: loss 0.037100
[epoch9, step515]: loss 0.039120
[epoch9, step516]: loss 0.039575
[epoch9, step517]: loss 0.036276
[epoch9, step518]: loss 0.036492
[epoch9, step519]: loss 0.039329
[epoch9, step520]: loss 0.035947
[epoch9, step521]: loss 0.038882
[epoch9, step522]: loss 0.035730
[epoch9, step523]: loss 0.036854
[epoch9, step524]: loss 0.038538
[epoch9, step525]: loss 0.039559
[epoch9, step526]: loss 0.036367
[epoch9, step527]: loss 0.036008
[epoch9, step528]: loss 0.039408
[epoch9, step529]: loss 0.036073
[epoch9, step530]: loss 0.039520
[epoch9, step531]: loss 0.035983
[epoch9, step532]: loss 0.036377
[epoch9, step533]: loss 0.040106
[epoch9, step534]: loss 0.039072
[epoch9, step535]: loss 0.036662
[epoch9, step536]: loss 0.036539
[epoch9, step537]: loss 0.039242
[epoch9, step538]: loss 0.036706
[epoch9, step539]: loss 0.038920
[epoch9, step540]: loss 0.035792
[epoch9, step541]: loss 0.036170
[epoch9, step542]: loss 0.039219
[epoch9, step543]: loss 0.038976
[epoch9, step544]: loss 0.036157
[epoch9, step545]: loss 0.035463
[epoch9, step546]: loss 0.039742
[epoch9, step547]: loss 0.036295
[epoch9, step548]: loss 0.038957
[epoch9, step549]: loss 0.036547
[epoch9, step550]: loss 0.036685
[epoch9, step551]: loss 0.038934
[epoch9, step552]: loss 0.038566
[epoch9, step553]: loss 0.036630
[epoch9, step554]: loss 0.036190
[epoch9, step555]: loss 0.038829
[epoch9, step556]: loss 0.036285
[epoch9, step557]: loss 0.038505
[epoch9, step558]: loss 0.036461
[epoch9, step559]: loss 0.036077
[epoch9, step560]: loss 0.039204
[epoch9, step561]: loss 0.038963
[epoch9, step562]: loss 0.036167
[epoch9, step563]: loss 0.029100
[epoch9, step564]: loss 0.028617
[epoch9, step565]: loss 0.027420
[epoch9, step566]: loss 0.034934
[epoch9, step567]: loss 0.026276
[epoch9, step568]: loss 0.025085
[epoch9, step569]: loss 0.023097
[epoch9, step570]: loss 0.031275
[epoch9, step571]: loss 0.051375
[epoch9, step572]: loss 0.048132
[epoch9, step573]: loss 0.054537
[epoch9, step574]: loss 0.047838
[epoch9, step575]: loss 0.033071
[epoch9, step576]: loss 0.034115
[epoch9, step577]: loss 0.025525
[epoch9, step578]: loss 0.019091
[epoch9, step579]: loss 0.027529
[epoch9, step580]: loss 0.020429
[epoch9, step581]: loss 0.025575
[epoch9, step582]: loss 0.025030
[epoch9, step583]: loss 0.022466
[epoch9, step584]: loss 0.023693
[epoch9, step585]: loss 0.026173
[epoch9, step586]: loss 0.021910
[epoch9, step587]: loss 0.027750
[epoch9, step588]: loss 0.023318
[epoch9, step589]: loss 0.023485
[epoch9, step590]: loss 0.027293
[epoch9, step591]: loss 0.020932
[epoch9, step592]: loss 0.025901
[epoch9, step593]: loss 0.021894
[epoch9, step594]: loss 0.026319
[epoch9, step595]: loss 0.026795
[epoch9, step596]: loss 0.023675
[epoch9, step597]: loss 0.025644
[epoch9, step598]: loss 0.026402
[epoch9, step599]: loss 0.025534
[epoch9, step600]: loss 0.027718
[epoch9, step601]: loss 0.020100
[epoch9, step602]: loss 0.022834
[epoch9, step603]: loss 0.026102
[epoch9, step604]: loss 0.026905
[epoch9, step605]: loss 0.025716
[epoch9, step606]: loss 0.025057
[epoch9, step607]: loss 0.028027
[epoch9, step608]: loss 0.025988
[epoch9, step609]: loss 0.027374
[epoch9, step610]: loss 0.026051
[epoch9, step611]: loss 0.026800
[epoch9, step612]: loss 0.025915
[epoch9, step613]: loss 0.019507
[epoch9, step614]: loss 0.025391
[epoch9, step615]: loss 0.028433
[epoch9, step616]: loss 0.024118
[epoch9, step617]: loss 0.023761
[epoch9, step618]: loss 0.025952
[epoch9, step619]: loss 0.026998
[epoch9, step620]: loss 0.024546
[epoch9, step621]: loss 0.026465
[epoch9, step622]: loss 0.020927
[epoch9, step623]: loss 0.024643
[epoch9, step624]: loss 0.026664
[epoch9, step625]: loss 0.026357
[epoch9, step626]: loss 0.028538
[epoch9, step627]: loss 0.023251
[epoch9, step628]: loss 0.026328
[epoch9, step629]: loss 0.020982
[epoch9, step630]: loss 0.023655
[epoch9, step631]: loss 0.031381
[epoch9, step632]: loss 0.023638
[epoch9, step633]: loss 0.024779
[epoch9, step634]: loss 0.027395
[epoch9, step635]: loss 0.026024
[epoch9, step636]: loss 0.021080
[epoch9, step637]: loss 0.027626
[epoch9, step638]: loss 0.027237
[epoch9, step639]: loss 0.023087
[epoch9, step640]: loss 0.029652
[epoch9, step641]: loss 0.030595
[epoch9, step642]: loss 0.025130
[epoch9, step643]: loss 0.025910
[epoch9, step644]: loss 0.026255
[epoch9, step645]: loss 0.023926
[epoch9, step646]: loss 0.026785
[epoch9, step647]: loss 0.023980
[epoch9, step648]: loss 0.023533
[epoch9, step649]: loss 0.028908
[epoch9, step650]: loss 0.022625
[epoch9, step651]: loss 0.026557
[epoch9, step652]: loss 0.027225
[epoch9, step653]: loss 0.028341
[epoch9, step654]: loss 0.023495
[epoch9, step655]: loss 0.024239
[epoch9, step656]: loss 0.021818
[epoch9, step657]: loss 0.028087
[epoch9, step658]: loss 0.025471
[epoch9, step659]: loss 0.027839
[epoch9, step660]: loss 0.024006
[epoch9, step661]: loss 0.026947
[epoch9, step662]: loss 0.023982
[epoch9, step663]: loss 0.021569
[epoch9, step664]: loss 0.025093
[epoch9, step665]: loss 0.028296
[epoch9, step666]: loss 0.026989
[epoch9, step667]: loss 0.026785
[epoch9, step668]: loss 0.022716
[epoch9, step669]: loss 0.026435
[epoch9, step670]: loss 0.027353
[epoch9, step671]: loss 0.021479
[epoch9, step672]: loss 0.024222
[epoch9, step673]: loss 0.022391
[epoch9, step674]: loss 0.021514
[epoch9, step675]: loss 0.020382
[epoch9, step676]: loss 0.024595
[epoch9, step677]: loss 0.025535
[epoch9, step678]: loss 0.023491
[epoch9, step679]: loss 0.024152
[epoch9, step680]: loss 0.030765
[epoch9, step681]: loss 0.022292
[epoch9, step682]: loss 0.026268
[epoch9, step683]: loss 0.025871
[epoch9, step684]: loss 0.025091
[epoch9, step685]: loss 0.024378
[epoch9, step686]: loss 0.027526
[epoch9, step687]: loss 0.026917
[epoch9, step688]: loss 0.023256
[epoch9, step689]: loss 0.024557
[epoch9, step690]: loss 0.025640
[epoch9, step691]: loss 0.024594
[epoch9, step692]: loss 0.022864
[epoch9, step693]: loss 0.028007
[epoch9, step694]: loss 0.023029
[epoch9, step695]: loss 0.026907
[epoch9, step696]: loss 0.025795
[epoch9, step697]: loss 0.027687
[epoch9, step698]: loss 0.025150
[epoch9, step699]: loss 0.023512
[epoch9, step700]: loss 0.021995
[epoch9, step701]: loss 0.026092
[epoch9, step702]: loss 0.022040
[epoch9, step703]: loss 0.023430
[epoch9, step704]: loss 0.026019
[epoch9, step705]: loss 0.025044
[epoch9, step706]: loss 0.024029
[epoch9, step707]: loss 0.024259
[epoch9, step708]: loss 0.026413
[epoch9, step709]: loss 0.027617
[epoch9, step710]: loss 0.024307
[epoch9, step711]: loss 0.024271
[epoch9, step712]: loss 0.027048
[epoch9, step713]: loss 0.026576
[epoch9, step714]: loss 0.021866
[epoch9, step715]: loss 0.023289
[epoch9, step716]: loss 0.026278
[epoch9, step717]: loss 0.023851
[epoch9, step718]: loss 0.025317
[epoch9, step719]: loss 0.033509
[epoch9, step720]: loss 0.025176
[epoch9, step721]: loss 0.023467
[epoch9, step722]: loss 0.031362
[epoch9, step723]: loss 0.026660
[epoch9, step724]: loss 0.023390
[epoch9, step725]: loss 0.028670
[epoch9, step726]: loss 0.022377
[epoch9, step727]: loss 0.024742
[epoch9, step728]: loss 0.026653
[epoch9, step729]: loss 0.021737
[epoch9, step730]: loss 0.023013
[epoch9, step731]: loss 0.026360
[epoch9, step732]: loss 0.025981
[epoch9, step733]: loss 0.024099
[epoch9, step734]: loss 0.023374
[epoch9, step735]: loss 0.027264
[epoch9, step736]: loss 0.025155
[epoch9, step737]: loss 0.026749
[epoch9, step738]: loss 0.020889
[epoch9, step739]: loss 0.025693
[epoch9, step740]: loss 0.022936
[epoch9, step741]: loss 0.025440
[epoch9, step742]: loss 0.022405
[epoch9, step743]: loss 0.023601
[epoch9, step744]: loss 0.024104
[epoch9, step745]: loss 0.024853
[epoch9, step746]: loss 0.025787
[epoch9, step747]: loss 0.027912
[epoch9, step748]: loss 0.026298
[epoch9, step749]: loss 0.026813
[epoch9, step750]: loss 0.028079
[epoch9, step751]: loss 0.022014
[epoch9, step752]: loss 0.025293
[epoch9, step753]: loss 0.025678
[epoch9, step754]: loss 0.023198
[epoch9, step755]: loss 0.026583
[epoch9, step756]: loss 0.023620
[epoch9, step757]: loss 0.021052
[epoch9, step758]: loss 0.025158
[epoch9, step759]: loss 0.023458
[epoch9, step760]: loss 0.024431
[epoch9, step761]: loss 0.026434
[epoch9, step762]: loss 0.021856
[epoch9, step763]: loss 0.025917
[epoch9, step764]: loss 0.024302
[epoch9, step765]: loss 0.026239
[epoch9, step766]: loss 0.024966
[epoch9, step767]: loss 0.027210
[epoch9, step768]: loss 0.021649
[epoch9, step769]: loss 0.026987
[epoch9, step770]: loss 0.026544
[epoch9, step771]: loss 0.023359
[epoch9, step772]: loss 0.029477
[epoch9, step773]: loss 0.026734
[epoch9, step774]: loss 0.024047
[epoch9, step775]: loss 0.021183
[epoch9, step776]: loss 0.026141
[epoch9, step777]: loss 0.023286
[epoch9, step778]: loss 0.028596
[epoch9, step779]: loss 0.024269
[epoch9, step780]: loss 0.020474
[epoch9, step781]: loss 0.024951
[epoch9, step782]: loss 0.023118
[epoch9, step783]: loss 0.019917
[epoch9, step784]: loss 0.020924
[epoch9, step785]: loss 0.021438
[epoch9, step786]: loss 0.024508
[epoch9, step787]: loss 0.023904
[epoch9, step788]: loss 0.024818
[epoch9, step789]: loss 0.023058
[epoch9, step790]: loss 0.023503
[epoch9, step791]: loss 0.026984
[epoch9, step792]: loss 0.025166
[epoch9, step793]: loss 0.027454
[epoch9, step794]: loss 0.020609
[epoch9, step795]: loss 0.026032
[epoch9, step796]: loss 0.028049
[epoch9, step797]: loss 0.028449
[epoch9, step798]: loss 0.027286
[epoch9, step799]: loss 0.025720
[epoch9, step800]: loss 0.021864
[epoch9, step801]: loss 0.022314
[epoch9, step802]: loss 0.023142
[epoch9, step803]: loss 0.026400
[epoch9, step804]: loss 0.027657
[epoch9, step805]: loss 0.029148
[epoch9, step806]: loss 0.021984
[epoch9, step807]: loss 0.020947
[epoch9, step808]: loss 0.023410
[epoch9, step809]: loss 0.023316
[epoch9, step810]: loss 0.026116
[epoch9, step811]: loss 0.026158
[epoch9, step812]: loss 0.024885
[epoch9, step813]: loss 0.024066
[epoch9, step814]: loss 0.025328
[epoch9, step815]: loss 0.024879
[epoch9, step816]: loss 0.024672
[epoch9, step817]: loss 0.025044
[epoch9, step818]: loss 0.022666
[epoch9, step819]: loss 0.020873
[epoch9, step820]: loss 0.023730
[epoch9, step821]: loss 0.022115
[epoch9, step822]: loss 0.031212
[epoch9, step823]: loss 0.024166
[epoch9, step824]: loss 0.027368
[epoch9, step825]: loss 0.025674
[epoch9, step826]: loss 0.024768
[epoch9, step827]: loss 0.027254
[epoch9, step828]: loss 0.028968
[epoch9, step829]: loss 0.026824
[epoch9, step830]: loss 0.022834
[epoch9, step831]: loss 0.026442
[epoch9, step832]: loss 0.021324
[epoch9, step833]: loss 0.029284
[epoch9, step834]: loss 0.025977
[epoch9, step835]: loss 0.021138
[epoch9, step836]: loss 0.027108
[epoch9, step837]: loss 0.025630
[epoch9, step838]: loss 0.026312
[epoch9, step839]: loss 0.028642
[epoch9, step840]: loss 0.020958
[epoch9, step841]: loss 0.024552
[epoch9, step842]: loss 0.027795
[epoch9, step843]: loss 0.025530
[epoch9, step844]: loss 0.025586
[epoch9, step845]: loss 0.021584
[epoch9, step846]: loss 0.026052
[epoch9, step847]: loss 0.027196
[epoch9, step848]: loss 0.025695
[epoch9, step849]: loss 0.025414
[epoch9, step850]: loss 0.023572
[epoch9, step851]: loss 0.024540
[epoch9, step852]: loss 0.023251
[epoch9, step853]: loss 0.029759
[epoch9, step854]: loss 0.022629
[epoch9, step855]: loss 0.027344
[epoch9, step856]: loss 0.022450
[epoch9, step857]: loss 0.026246
[epoch9, step858]: loss 0.024610
[epoch9, step859]: loss 0.023817
[epoch9, step860]: loss 0.022928
[epoch9, step861]: loss 0.023441
[epoch9, step862]: loss 0.023186
[epoch9, step863]: loss 0.020912
[epoch9, step864]: loss 0.026929
[epoch9, step865]: loss 0.023620
[epoch9, step866]: loss 0.025349
[epoch9, step867]: loss 0.026466
[epoch9, step868]: loss 0.027132
[epoch9, step869]: loss 0.023883
[epoch9, step870]: loss 0.031558
[epoch9, step871]: loss 0.022442
[epoch9, step872]: loss 0.025763
[epoch9, step873]: loss 0.025979
[epoch9, step874]: loss 0.023945
[epoch9, step875]: loss 0.024621
[epoch9, step876]: loss 0.024705
[epoch9, step877]: loss 0.019514
[epoch9, step878]: loss 0.023589
[epoch9, step879]: loss 0.028191
[epoch9, step880]: loss 0.025733
[epoch9, step881]: loss 0.022406
[epoch9, step882]: loss 0.024705
[epoch9, step883]: loss 0.024440
[epoch9, step884]: loss 0.026807
[epoch9, step885]: loss 0.026261
[epoch9, step886]: loss 0.026673
[epoch9, step887]: loss 0.024503
[epoch9, step888]: loss 0.025040
[epoch9, step889]: loss 0.024012
[epoch9, step890]: loss 0.023840
[epoch9, step891]: loss 0.025665
[epoch9, step892]: loss 0.021307
[epoch9, step893]: loss 0.024668
[epoch9, step894]: loss 0.024869
[epoch9, step895]: loss 0.022948
[epoch9, step896]: loss 0.022286
[epoch9, step897]: loss 0.024495
[epoch9, step898]: loss 0.026054
[epoch9, step899]: loss 0.028485
[epoch9, step900]: loss 0.027296
[epoch9, step901]: loss 0.026079
[epoch9, step902]: loss 0.024224
[epoch9, step903]: loss 0.025009
[epoch9, step904]: loss 0.028373
[epoch9, step905]: loss 0.027985
[epoch9, step906]: loss 0.022662
[epoch9, step907]: loss 0.023835
[epoch9, step908]: loss 0.022885
[epoch9, step909]: loss 0.026057
[epoch9, step910]: loss 0.023394
[epoch9, step911]: loss 0.025620
[epoch9, step912]: loss 0.023927
[epoch9, step913]: loss 0.024676
[epoch9, step914]: loss 0.031052
[epoch9, step915]: loss 0.024316
[epoch9, step916]: loss 0.023716
[epoch9, step917]: loss 0.025259
[epoch9, step918]: loss 0.028837
[epoch9, step919]: loss 0.024679
[epoch9, step920]: loss 0.027724
[epoch9, step921]: loss 0.024619
[epoch9, step922]: loss 0.023601
[epoch9, step923]: loss 0.023227
[epoch9, step924]: loss 0.021496
[epoch9, step925]: loss 0.025719
[epoch9, step926]: loss 0.026758
[epoch9, step927]: loss 0.026219
[epoch9, step928]: loss 0.025202
[epoch9, step929]: loss 0.027906
[epoch9, step930]: loss 0.026146
[epoch9, step931]: loss 0.028081
[epoch9, step932]: loss 0.022045
[epoch9, step933]: loss 0.028597
[epoch9, step934]: loss 0.022484
[epoch9, step935]: loss 0.022804
[epoch9, step936]: loss 0.022981
[epoch9, step937]: loss 0.027938
[epoch9, step938]: loss 0.025830
[epoch9, step939]: loss 0.021197
[epoch9, step940]: loss 0.023432
[epoch9, step941]: loss 0.026921
[epoch9, step942]: loss 0.025755
[epoch9, step943]: loss 0.023792
[epoch9, step944]: loss 0.028221
[epoch9, step945]: loss 0.020557
[epoch9, step946]: loss 0.025741
[epoch9, step947]: loss 0.028391
[epoch9, step948]: loss 0.020032
[epoch9, step949]: loss 0.023066
[epoch9, step950]: loss 0.026503
[epoch9, step951]: loss 0.029131
[epoch9, step952]: loss 0.025305
[epoch9, step953]: loss 0.027733
[epoch9, step954]: loss 0.022751
[epoch9, step955]: loss 0.037017
[epoch9, step956]: loss 0.052005
[epoch9, step957]: loss 0.045707
[epoch9, step958]: loss 0.042543
[epoch9, step959]: loss 0.045404
[epoch9, step960]: loss 0.042301
[epoch9, step961]: loss 0.043423
[epoch9, step962]: loss 0.042885
[epoch9, step963]: loss 0.042269
[epoch9, step964]: loss 0.043309
[epoch9, step965]: loss 0.044655
[epoch9, step966]: loss 0.042565
[epoch9, step967]: loss 0.041845
[epoch9, step968]: loss 0.044590
[epoch9, step969]: loss 0.043553
[epoch9, step970]: loss 0.042731
[epoch9, step971]: loss 0.048564
[epoch9, step972]: loss 0.056819
[epoch9, step973]: loss 0.043771
[epoch9, step974]: loss 0.044204
[epoch9, step975]: loss 0.041441
[epoch9, step976]: loss 0.039930
[epoch9, step977]: loss 0.043314
[epoch9, step978]: loss 0.042468
[epoch9, step979]: loss 0.041064
[epoch9, step980]: loss 0.040073
[epoch9, step981]: loss 0.040931
[epoch9, step982]: loss 0.040839
[epoch9, step983]: loss 0.042104
[epoch9, step984]: loss 0.039168
[epoch9, step985]: loss 0.038944
[epoch9, step986]: loss 0.042274
[epoch9, step987]: loss 0.040517
[epoch9, step988]: loss 0.040501
[epoch9, step989]: loss 0.039723
[epoch9, step990]: loss 0.039796
[epoch9, step991]: loss 0.040260
[epoch9, step992]: loss 0.040837
[epoch9, step993]: loss 0.038540
[epoch9, step994]: loss 0.037505
[epoch9, step995]: loss 0.041166
[epoch9, step996]: loss 0.039269
[epoch9, step997]: loss 0.039323
[epoch9, step998]: loss 0.039001
[epoch9, step999]: loss 0.039485
[epoch9, step1000]: loss 0.039586
[epoch9, step1001]: loss 0.040626
[epoch9, step1002]: loss 0.038350
[epoch9, step1003]: loss 0.037447
[epoch9, step1004]: loss 0.040818
[epoch9, step1005]: loss 0.038629
[epoch9, step1006]: loss 0.038955
[epoch9, step1007]: loss 0.037776
[epoch9, step1008]: loss 0.038626
[epoch9, step1009]: loss 0.039125
[epoch9, step1010]: loss 0.040845
[epoch9, step1011]: loss 0.037733
[epoch9, step1012]: loss 0.037740
[epoch9, step1013]: loss 0.040765
[epoch9, step1014]: loss 0.039732
[epoch9, step1015]: loss 0.039071
[epoch9, step1016]: loss 0.037492
[epoch9, step1017]: loss 0.038476
[epoch9, step1018]: loss 0.038789
[epoch9, step1019]: loss 0.040362
[epoch9, step1020]: loss 0.037273
[epoch9, step1021]: loss 0.036818
[epoch9, step1022]: loss 0.040280
[epoch9, step1023]: loss 0.038835
[epoch9, step1024]: loss 0.039191
[epoch9, step1025]: loss 0.037180
[epoch9, step1026]: loss 0.038026
[epoch9, step1027]: loss 0.038583
[epoch9, step1028]: loss 0.039948
[epoch9, step1029]: loss 0.037223
[epoch9, step1030]: loss 0.036575
[epoch9, step1031]: loss 0.039160
[epoch9, step1032]: loss 0.039046
[epoch9, step1033]: loss 0.037966
[epoch9, step1034]: loss 0.037190
[epoch9, step1035]: loss 0.037918
[epoch9, step1036]: loss 0.038936
[epoch9, step1037]: loss 0.039720
[epoch9, step1038]: loss 0.037111
[epoch9, step1039]: loss 0.037200
[epoch9, step1040]: loss 0.039739
[epoch9, step1041]: loss 0.038498
[epoch9, step1042]: loss 0.037415
[epoch9, step1043]: loss 0.037150
[epoch9, step1044]: loss 0.038476
[epoch9, step1045]: loss 0.038897
[epoch9, step1046]: loss 0.040005
[epoch9, step1047]: loss 0.037350
[epoch9, step1048]: loss 0.036666
[epoch9, step1049]: loss 0.040256
[epoch9, step1050]: loss 0.038912
[epoch9, step1051]: loss 0.038274
[epoch9, step1052]: loss 0.037649
[epoch9, step1053]: loss 0.038904
[epoch9, step1054]: loss 0.038793
[epoch9, step1055]: loss 0.039209
[epoch9, step1056]: loss 0.036602
[epoch9, step1057]: loss 0.037504
[epoch9, step1058]: loss 0.040912
[epoch9, step1059]: loss 0.038897
[epoch9, step1060]: loss 0.038296
[epoch9, step1061]: loss 0.036562
[epoch9, step1062]: loss 0.038841
[epoch9, step1063]: loss 0.038798
[epoch9, step1064]: loss 0.039709
[epoch9, step1065]: loss 0.037010
[epoch9, step1066]: loss 0.036427
[epoch9, step1067]: loss 0.040211
[epoch9, step1068]: loss 0.037358
[epoch9, step1069]: loss 0.037510
[epoch9, step1070]: loss 0.037049
[epoch9, step1071]: loss 0.038962
[epoch9, step1072]: loss 0.039461
[epoch9, step1073]: loss 0.039416
[epoch9, step1074]: loss 0.037043
[epoch9, step1075]: loss 0.037163
[epoch9, step1076]: loss 0.040192
[epoch9, step1077]: loss 0.038622
[epoch9, step1078]: loss 0.037906
[epoch9, step1079]: loss 0.038007
[epoch9, step1080]: loss 0.038566
[epoch9, step1081]: loss 0.038529
[epoch9, step1082]: loss 0.039462
[epoch9, step1083]: loss 0.037636
[epoch9, step1084]: loss 0.037040
[epoch9, step1085]: loss 0.039651
[epoch9, step1086]: loss 0.038301
[epoch9, step1087]: loss 0.038156
[epoch9, step1088]: loss 0.036801
[epoch9, step1089]: loss 0.038829
[epoch9, step1090]: loss 0.039214
[epoch9, step1091]: loss 0.039936
[epoch9, step1092]: loss 0.036826
[epoch9, step1093]: loss 0.036640
[epoch9, step1094]: loss 0.039149
[epoch9, step1095]: loss 0.038118
[epoch9, step1096]: loss 0.037565
[epoch9, step1097]: loss 0.036798
[epoch9, step1098]: loss 0.038289
[epoch9, step1099]: loss 0.038266
[epoch9, step1100]: loss 0.040164
[epoch9, step1101]: loss 0.037154
[epoch9, step1102]: loss 0.036599
[epoch9, step1103]: loss 0.039436
[epoch9, step1104]: loss 0.038197
[epoch9, step1105]: loss 0.038025
[epoch9, step1106]: loss 0.035702
[epoch9, step1107]: loss 0.038305
[epoch9, step1108]: loss 0.037979
[epoch9, step1109]: loss 0.039659
[epoch9, step1110]: loss 0.037383
[epoch9, step1111]: loss 0.036846
[epoch9, step1112]: loss 0.040090
[epoch9, step1113]: loss 0.037994
[epoch9, step1114]: loss 0.038062
[epoch9, step1115]: loss 0.036869
[epoch9, step1116]: loss 0.038385
[epoch9, step1117]: loss 0.038631
[epoch9, step1118]: loss 0.039655
[epoch9, step1119]: loss 0.036383
[epoch9, step1120]: loss 0.036551
[epoch9, step1121]: loss 0.039693
[epoch9, step1122]: loss 0.037702
[epoch9, step1123]: loss 0.037021
[epoch9, step1124]: loss 0.037098
[epoch9, step1125]: loss 0.038455
[epoch9, step1126]: loss 0.039309
[epoch9, step1127]: loss 0.039296
[epoch9, step1128]: loss 0.036892
[epoch9, step1129]: loss 0.036325
[epoch9, step1130]: loss 0.040499
[epoch9, step1131]: loss 0.038710
[epoch9, step1132]: loss 0.038075
[epoch9, step1133]: loss 0.036282
[epoch9, step1134]: loss 0.037847
[epoch9, step1135]: loss 0.039794
[epoch9, step1136]: loss 0.040455
[epoch9, step1137]: loss 0.036607
[epoch9, step1138]: loss 0.036975
[epoch9, step1139]: loss 0.039927
[epoch9, step1140]: loss 0.037536
[epoch9, step1141]: loss 0.037692
[epoch9, step1142]: loss 0.036164
[epoch9, step1143]: loss 0.037756
[epoch9, step1144]: loss 0.038445
[epoch9, step1145]: loss 0.038738
[epoch9, step1146]: loss 0.036230
[epoch9, step1147]: loss 0.037088
[epoch9, step1148]: loss 0.039761
[epoch9, step1149]: loss 0.037869
[epoch9, step1150]: loss 0.037408
[epoch9, step1151]: loss 0.036736
[epoch9, step1152]: loss 0.038632
[epoch9, step1153]: loss 0.037758
[epoch9, step1154]: loss 0.039679
[epoch9, step1155]: loss 0.036902
[epoch9, step1156]: loss 0.036103
[epoch9, step1157]: loss 0.039418
[epoch9, step1158]: loss 0.038585
[epoch9, step1159]: loss 0.037984
[epoch9, step1160]: loss 0.037312
[epoch9, step1161]: loss 0.038841
[epoch9, step1162]: loss 0.038176
[epoch9, step1163]: loss 0.038848
[epoch9, step1164]: loss 0.036466
[epoch9, step1165]: loss 0.037532
[epoch9, step1166]: loss 0.039782
[epoch9, step1167]: loss 0.037285
[epoch9, step1168]: loss 0.037941
[epoch9, step1169]: loss 0.036109
[epoch9, step1170]: loss 0.038158
[epoch9, step1171]: loss 0.038101
[epoch9, step1172]: loss 0.039275
[epoch9, step1173]: loss 0.036652
[epoch9, step1174]: loss 0.036781
[epoch9, step1175]: loss 0.039456
[epoch9, step1176]: loss 0.037823
[epoch9, step1177]: loss 0.037875
[epoch9, step1178]: loss 0.036631
[epoch9, step1179]: loss 0.037852
[epoch9, step1180]: loss 0.038528
[epoch9, step1181]: loss 0.039964
[epoch9, step1182]: loss 0.035966
[epoch9, step1183]: loss 0.037032
[epoch9, step1184]: loss 0.039096
[epoch9, step1185]: loss 0.038303
[epoch9, step1186]: loss 0.036978
[epoch9, step1187]: loss 0.035592
[epoch9, step1188]: loss 0.037560
[epoch9, step1189]: loss 0.037921
[epoch9, step1190]: loss 0.038936
[epoch9, step1191]: loss 0.037101
[epoch9, step1192]: loss 0.036538
[epoch9, step1193]: loss 0.039427
[epoch9, step1194]: loss 0.037904
[epoch9, step1195]: loss 0.036524
[epoch9, step1196]: loss 0.035607
[epoch9, step1197]: loss 0.038433
[epoch9, step1198]: loss 0.038243
[epoch9, step1199]: loss 0.038882
[epoch9, step1200]: loss 0.036266
[epoch9, step1201]: loss 0.036854
[epoch9, step1202]: loss 0.040424
[epoch9, step1203]: loss 0.038189
[epoch9, step1204]: loss 0.036958
[epoch9, step1205]: loss 0.035880
[epoch9, step1206]: loss 0.037525
[epoch9, step1207]: loss 0.038548
[epoch9, step1208]: loss 0.039494
[epoch9, step1209]: loss 0.035408
[epoch9, step1210]: loss 0.037013
[epoch9, step1211]: loss 0.039015
[epoch9, step1212]: loss 0.037838
[epoch9, step1213]: loss 0.037242
[epoch9, step1214]: loss 0.036505
[epoch9, step1215]: loss 0.038770
[epoch9, step1216]: loss 0.037727
[epoch9, step1217]: loss 0.039917
[epoch9, step1218]: loss 0.036100
[epoch9, step1219]: loss 0.037133
[epoch9, step1220]: loss 0.039868
[epoch9, step1221]: loss 0.037105
[epoch9, step1222]: loss 0.037769
[epoch9, step1223]: loss 0.036165
[epoch9, step1224]: loss 0.038489
[epoch9, step1225]: loss 0.038223
[epoch9, step1226]: loss 0.038904
[epoch9, step1227]: loss 0.036375
[epoch9, step1228]: loss 0.036083
[epoch9, step1229]: loss 0.039202
[epoch9, step1230]: loss 0.038274
[epoch9, step1231]: loss 0.037437
[epoch9, step1232]: loss 0.037401
[epoch9, step1233]: loss 0.038020
[epoch9, step1234]: loss 0.037937
[epoch9, step1235]: loss 0.039859
[epoch9, step1236]: loss 0.036671
[epoch9, step1237]: loss 0.036112
[epoch9, step1238]: loss 0.038953
[epoch9, step1239]: loss 0.038585
[epoch9, step1240]: loss 0.038022
[epoch9, step1241]: loss 0.035968
[epoch9, step1242]: loss 0.038042
[epoch9, step1243]: loss 0.038044
[epoch9, step1244]: loss 0.039520
[epoch9, step1245]: loss 0.036753
[epoch9, step1246]: loss 0.036765
[epoch9, step1247]: loss 0.038607
[epoch9, step1248]: loss 0.038120
[epoch9, step1249]: loss 0.038087
[epoch9, step1250]: loss 0.036223
[epoch9, step1251]: loss 0.038323
[epoch9, step1252]: loss 0.039103
[epoch9, step1253]: loss 0.039545
[epoch9, step1254]: loss 0.036558
[epoch9, step1255]: loss 0.036637
[epoch9, step1256]: loss 0.039897
[epoch9, step1257]: loss 0.038274
[epoch9, step1258]: loss 0.037844
[epoch9, step1259]: loss 0.036017
[epoch9, step1260]: loss 0.038178
[epoch9, step1261]: loss 0.037966
[epoch9, step1262]: loss 0.038084
[epoch9, step1263]: loss 0.036991
[epoch9, step1264]: loss 0.036403
[epoch9, step1265]: loss 0.038231
[epoch9, step1266]: loss 0.037994
[epoch9, step1267]: loss 0.037783
[epoch9, step1268]: loss 0.036537
[epoch9, step1269]: loss 0.038225
[epoch9, step1270]: loss 0.037446
[epoch9, step1271]: loss 0.039783
[epoch9, step1272]: loss 0.036535
[epoch9, step1273]: loss 0.036261
[epoch9, step1274]: loss 0.039200
[epoch9, step1275]: loss 0.038332
[epoch9, step1276]: loss 0.037353
[epoch9, step1277]: loss 0.036249
[epoch9, step1278]: loss 0.038705
[epoch9, step1279]: loss 0.038319
[epoch9, step1280]: loss 0.039489
[epoch9, step1281]: loss 0.036299
[epoch9, step1282]: loss 0.036341
[epoch9, step1283]: loss 0.038769
[epoch9, step1284]: loss 0.037465
[epoch9, step1285]: loss 0.038081
[epoch9, step1286]: loss 0.035626
[epoch9, step1287]: loss 0.038790
[epoch9, step1288]: loss 0.038876
[epoch9, step1289]: loss 0.040111
[epoch9, step1290]: loss 0.036477
[epoch9, step1291]: loss 0.036158
[epoch9, step1292]: loss 0.039971
[epoch9, step1293]: loss 0.037167
[epoch9, step1294]: loss 0.037588
[epoch9, step1295]: loss 0.036808
[epoch9, step1296]: loss 0.038255
[epoch9, step1297]: loss 0.037926
[epoch9, step1298]: loss 0.039841
[epoch9, step1299]: loss 0.036598
[epoch9, step1300]: loss 0.037161
[epoch9, step1301]: loss 0.038412
[epoch9, step1302]: loss 0.037906
[epoch9, step1303]: loss 0.037845
[epoch9, step1304]: loss 0.035678
[epoch9, step1305]: loss 0.038392
[epoch9, step1306]: loss 0.037930
[epoch9, step1307]: loss 0.038633
[epoch9, step1308]: loss 0.036570
[epoch9, step1309]: loss 0.035717
[epoch9, step1310]: loss 0.039279
[epoch9, step1311]: loss 0.036853
[epoch9, step1312]: loss 0.038254
[epoch9, step1313]: loss 0.036388
[epoch9, step1314]: loss 0.037923
[epoch9, step1315]: loss 0.037813
[epoch9, step1316]: loss 0.040639
[epoch9, step1317]: loss 0.035844
[epoch9, step1318]: loss 0.035948
[epoch9, step1319]: loss 0.038763
[epoch9, step1320]: loss 0.038122
[epoch9, step1321]: loss 0.038109
[epoch9, step1322]: loss 0.036004
[epoch9, step1323]: loss 0.038407
[epoch9, step1324]: loss 0.037690
[epoch9, step1325]: loss 0.039118
[epoch9, step1326]: loss 0.036164
[epoch9, step1327]: loss 0.036252
[epoch9, step1328]: loss 0.039320
[epoch9, step1329]: loss 0.037730
[epoch9, step1330]: loss 0.037805
[epoch9, step1331]: loss 0.035989
[epoch9, step1332]: loss 0.037892
[epoch9, step1333]: loss 0.037137
[epoch9, step1334]: loss 0.039522
[epoch9, step1335]: loss 0.037023
[epoch9, step1336]: loss 0.036286
[epoch9, step1337]: loss 0.038721
[epoch9, step1338]: loss 0.037716
[epoch9, step1339]: loss 0.037646
[epoch9, step1340]: loss 0.035922
[epoch9, step1341]: loss 0.038219
[epoch9, step1342]: loss 0.037794
[epoch9, step1343]: loss 0.039386
[epoch9, step1344]: loss 0.036463
[epoch9, step1345]: loss 0.036327
[epoch9, step1346]: loss 0.038776
[epoch9, step1347]: loss 0.038431
[epoch9, step1348]: loss 0.036967
[epoch9, step1349]: loss 0.036333
[epoch9, step1350]: loss 0.038022
[epoch9, step1351]: loss 0.037453
[epoch9, step1352]: loss 0.038524
[epoch9, step1353]: loss 0.036146
[epoch9, step1354]: loss 0.035897
[epoch9, step1355]: loss 0.039457
[epoch9, step1356]: loss 0.037492
[epoch9, step1357]: loss 0.036940
[epoch9, step1358]: loss 0.036109
[epoch9, step1359]: loss 0.037478
[epoch9, step1360]: loss 0.038283
[epoch9, step1361]: loss 0.039466
[epoch9, step1362]: loss 0.036910
[epoch9, step1363]: loss 0.036892
[epoch9, step1364]: loss 0.039100
[epoch9, step1365]: loss 0.037767
[epoch9, step1366]: loss 0.037523
[epoch9, step1367]: loss 0.035340
[epoch9, step1368]: loss 0.038860
[epoch9, step1369]: loss 0.038195
[epoch9, step1370]: loss 0.038734
[epoch9, step1371]: loss 0.036607
[epoch9, step1372]: loss 0.035978
[epoch9, step1373]: loss 0.039186
[epoch9, step1374]: loss 0.038547
[epoch9, step1375]: loss 0.038185
[epoch9, step1376]: loss 0.035929
[epoch9, step1377]: loss 0.037099
[epoch9, step1378]: loss 0.038048
[epoch9, step1379]: loss 0.038673
[epoch9, step1380]: loss 0.036678
[epoch9, step1381]: loss 0.036288
[epoch9, step1382]: loss 0.039429
[epoch9, step1383]: loss 0.037572
[epoch9, step1384]: loss 0.037431
[epoch9, step1385]: loss 0.035451
[epoch9, step1386]: loss 0.038147
[epoch9, step1387]: loss 0.038423
[epoch9, step1388]: loss 0.037997
[epoch9, step1389]: loss 0.035583
[epoch9, step1390]: loss 0.036291
[epoch9, step1391]: loss 0.038808
[epoch9, step1392]: loss 0.037570
[epoch9, step1393]: loss 0.037636
[epoch9, step1394]: loss 0.036687
[epoch9, step1395]: loss 0.037966
[epoch9, step1396]: loss 0.037473
[epoch9, step1397]: loss 0.038782
[epoch9, step1398]: loss 0.036185
[epoch9, step1399]: loss 0.037102
[epoch9, step1400]: loss 0.039559
[epoch9, step1401]: loss 0.037442
[epoch9, step1402]: loss 0.037638
[epoch9, step1403]: loss 0.035072
[epoch9, step1404]: loss 0.037381
[epoch9, step1405]: loss 0.037691
[epoch9, step1406]: loss 0.038700
[epoch9, step1407]: loss 0.037289
[epoch9, step1408]: loss 0.035529
[epoch9, step1409]: loss 0.038640
[epoch9, step1410]: loss 0.037595
[epoch9, step1411]: loss 0.036393
[epoch9, step1412]: loss 0.036178
[epoch9, step1413]: loss 0.037822
[epoch9, step1414]: loss 0.037491
[epoch9, step1415]: loss 0.038679
[epoch9, step1416]: loss 0.036144
[epoch9, step1417]: loss 0.036130
[epoch9, step1418]: loss 0.038997
[epoch9, step1419]: loss 0.038384
[epoch9, step1420]: loss 0.037709
[epoch9, step1421]: loss 0.036477
[epoch9, step1422]: loss 0.038041
[epoch9, step1423]: loss 0.037340
[epoch9, step1424]: loss 0.039098
[epoch9, step1425]: loss 0.035230
[epoch9, step1426]: loss 0.036144
[epoch9, step1427]: loss 0.039853
[epoch9, step1428]: loss 0.038392
[epoch9, step1429]: loss 0.037377
[epoch9, step1430]: loss 0.036104
[epoch9, step1431]: loss 0.037859
[epoch9, step1432]: loss 0.037612
[epoch9, step1433]: loss 0.039108
[epoch9, step1434]: loss 0.035628
[epoch9, step1435]: loss 0.036678
[epoch9, step1436]: loss 0.039336
[epoch9, step1437]: loss 0.037931
[epoch9, step1438]: loss 0.038161
[epoch9, step1439]: loss 0.035913
[epoch9, step1440]: loss 0.037641
[epoch9, step1441]: loss 0.038396
[epoch9, step1442]: loss 0.038183
[epoch9, step1443]: loss 0.035865
[epoch9, step1444]: loss 0.035394
[epoch9, step1445]: loss 0.039348
[epoch9, step1446]: loss 0.037756
[epoch9, step1447]: loss 0.038127
[epoch9, step1448]: loss 0.035945
[epoch9, step1449]: loss 0.037119
[epoch9, step1450]: loss 0.037825
[epoch9, step1451]: loss 0.039213
[epoch9, step1452]: loss 0.035863
[epoch9, step1453]: loss 0.037145
[epoch9, step1454]: loss 0.039476
[epoch9, step1455]: loss 0.038168
[epoch9, step1456]: loss 0.037019
[epoch9, step1457]: loss 0.036599
[epoch9, step1458]: loss 0.037872
[epoch9, step1459]: loss 0.037711
[epoch9, step1460]: loss 0.039418
[epoch9, step1461]: loss 0.036824
[epoch9, step1462]: loss 0.036756
[epoch9, step1463]: loss 0.038953
[epoch9, step1464]: loss 0.037818
[epoch9, step1465]: loss 0.037075
[epoch9, step1466]: loss 0.035670
[epoch9, step1467]: loss 0.037637
[epoch9, step1468]: loss 0.037270
[epoch9, step1469]: loss 0.038818
[epoch9, step1470]: loss 0.036261
[epoch9, step1471]: loss 0.035819
[epoch9, step1472]: loss 0.038812
[epoch9, step1473]: loss 0.037542
[epoch9, step1474]: loss 0.038002
[epoch9, step1475]: loss 0.035693
[epoch9, step1476]: loss 0.038537
[epoch9, step1477]: loss 0.037481
[epoch9, step1478]: loss 0.038973
[epoch9, step1479]: loss 0.036058
[epoch9, step1480]: loss 0.036136
[epoch9, step1481]: loss 0.038053
[epoch9, step1482]: loss 0.037507
[epoch9, step1483]: loss 0.037482
[epoch9, step1484]: loss 0.036346
[epoch9, step1485]: loss 0.037491
[epoch9, step1486]: loss 0.036714
[epoch9, step1487]: loss 0.038667
[epoch9, step1488]: loss 0.036304
[epoch9, step1489]: loss 0.035897
[epoch9, step1490]: loss 0.039181
[epoch9, step1491]: loss 0.037690
[epoch9, step1492]: loss 0.037124
[epoch9, step1493]: loss 0.036141
[epoch9, step1494]: loss 0.037809
[epoch9, step1495]: loss 0.037497
[epoch9, step1496]: loss 0.038152
[epoch9, step1497]: loss 0.036401
[epoch9, step1498]: loss 0.036458
[epoch9, step1499]: loss 0.038386
[epoch9, step1500]: loss 0.037850
[epoch9, step1501]: loss 0.037502
[epoch9, step1502]: loss 0.035697
[epoch9, step1503]: loss 0.037587
[epoch9, step1504]: loss 0.037330
[epoch9, step1505]: loss 0.039142
[epoch9, step1506]: loss 0.035555
[epoch9, step1507]: loss 0.036466
[epoch9, step1508]: loss 0.039479
[epoch9, step1509]: loss 0.037237
[epoch9, step1510]: loss 0.036813
[epoch9, step1511]: loss 0.036589
[epoch9, step1512]: loss 0.037789
[epoch9, step1513]: loss 0.036400
[epoch9, step1514]: loss 0.038854
[epoch9, step1515]: loss 0.036552
[epoch9, step1516]: loss 0.036073

[epoch9]: avg loss 0.034671

[epoch10, step1]: loss 0.032176
[epoch10, step2]: loss 0.038639
[epoch10, step3]: loss 0.038620
[epoch10, step4]: loss 0.035915
[epoch10, step5]: loss 0.036614
[epoch10, step6]: loss 0.038924
[epoch10, step7]: loss 0.036934
[epoch10, step8]: loss 0.039182
[epoch10, step9]: loss 0.035583
[epoch10, step10]: loss 0.037202
[epoch10, step11]: loss 0.038980
[epoch10, step12]: loss 0.038868
[epoch10, step13]: loss 0.036151
[epoch10, step14]: loss 0.036436
[epoch10, step15]: loss 0.038989
[epoch10, step16]: loss 0.036889
[epoch10, step17]: loss 0.039328
[epoch10, step18]: loss 0.036777
[epoch10, step19]: loss 0.036815
[epoch10, step20]: loss 0.039764
[epoch10, step21]: loss 0.038738
[epoch10, step22]: loss 0.035708
[epoch10, step23]: loss 0.035445
[epoch10, step24]: loss 0.038964
[epoch10, step25]: loss 0.036035
[epoch10, step26]: loss 0.038429
[epoch10, step27]: loss 0.035532
[epoch10, step28]: loss 0.036784
[epoch10, step29]: loss 0.039160
[epoch10, step30]: loss 0.039491
[epoch10, step31]: loss 0.035472
[epoch10, step32]: loss 0.036766
[epoch10, step33]: loss 0.039428
[epoch10, step34]: loss 0.037220
[epoch10, step35]: loss 0.039552
[epoch10, step36]: loss 0.035716
[epoch10, step37]: loss 0.036768
[epoch10, step38]: loss 0.038876
[epoch10, step39]: loss 0.038778
[epoch10, step40]: loss 0.036547
[epoch10, step41]: loss 0.035687
[epoch10, step42]: loss 0.039272
[epoch10, step43]: loss 0.036642
[epoch10, step44]: loss 0.039607
[epoch10, step45]: loss 0.035934
[epoch10, step46]: loss 0.036750
[epoch10, step47]: loss 0.038449
[epoch10, step48]: loss 0.038471
[epoch10, step49]: loss 0.034454
[epoch10, step50]: loss 0.036356
[epoch10, step51]: loss 0.038793
[epoch10, step52]: loss 0.036416
[epoch10, step53]: loss 0.039552
[epoch10, step54]: loss 0.035702
[epoch10, step55]: loss 0.037125
[epoch10, step56]: loss 0.039873
[epoch10, step57]: loss 0.039308
[epoch10, step58]: loss 0.036019
[epoch10, step59]: loss 0.035286
[epoch10, step60]: loss 0.039460
[epoch10, step61]: loss 0.035769
[epoch10, step62]: loss 0.038514
[epoch10, step63]: loss 0.035335
[epoch10, step64]: loss 0.036269
[epoch10, step65]: loss 0.039132
[epoch10, step66]: loss 0.038838
[epoch10, step67]: loss 0.036145
[epoch10, step68]: loss 0.036175
[epoch10, step69]: loss 0.038882
[epoch10, step70]: loss 0.036379
[epoch10, step71]: loss 0.038631
[epoch10, step72]: loss 0.036011
[epoch10, step73]: loss 0.036584
[epoch10, step74]: loss 0.038906
[epoch10, step75]: loss 0.039091
[epoch10, step76]: loss 0.036569
[epoch10, step77]: loss 0.036851
[epoch10, step78]: loss 0.039151
[epoch10, step79]: loss 0.035887
[epoch10, step80]: loss 0.039821
[epoch10, step81]: loss 0.035987
[epoch10, step82]: loss 0.036202
[epoch10, step83]: loss 0.038451
[epoch10, step84]: loss 0.039040
[epoch10, step85]: loss 0.036690
[epoch10, step86]: loss 0.036542
[epoch10, step87]: loss 0.039972
[epoch10, step88]: loss 0.035409
[epoch10, step89]: loss 0.038789
[epoch10, step90]: loss 0.036396
[epoch10, step91]: loss 0.036074
[epoch10, step92]: loss 0.039190
[epoch10, step93]: loss 0.038880
[epoch10, step94]: loss 0.035932
[epoch10, step95]: loss 0.036685
[epoch10, step96]: loss 0.038639
[epoch10, step97]: loss 0.037259
[epoch10, step98]: loss 0.039232
[epoch10, step99]: loss 0.035989
[epoch10, step100]: loss 0.035543
[epoch10, step101]: loss 0.039559
[epoch10, step102]: loss 0.038806
[epoch10, step103]: loss 0.035898
[epoch10, step104]: loss 0.036232
[epoch10, step105]: loss 0.039331
[epoch10, step106]: loss 0.036653
[epoch10, step107]: loss 0.039130
[epoch10, step108]: loss 0.036322
[epoch10, step109]: loss 0.036317
[epoch10, step110]: loss 0.039569
[epoch10, step111]: loss 0.038685
[epoch10, step112]: loss 0.036170
[epoch10, step113]: loss 0.037061
[epoch10, step114]: loss 0.038744
[epoch10, step115]: loss 0.036426
[epoch10, step116]: loss 0.039831
[epoch10, step117]: loss 0.035952
[epoch10, step118]: loss 0.037258
[epoch10, step119]: loss 0.039408
[epoch10, step120]: loss 0.039066
[epoch10, step121]: loss 0.035860
[epoch10, step122]: loss 0.036211
[epoch10, step123]: loss 0.039304
[epoch10, step124]: loss 0.036851
[epoch10, step125]: loss 0.039499
[epoch10, step126]: loss 0.035932
[epoch10, step127]: loss 0.036319
[epoch10, step128]: loss 0.038931
[epoch10, step129]: loss 0.038747
[epoch10, step130]: loss 0.036230
[epoch10, step131]: loss 0.035682
[epoch10, step132]: loss 0.039067
[epoch10, step133]: loss 0.036295
[epoch10, step134]: loss 0.038414
[epoch10, step135]: loss 0.036543
[epoch10, step136]: loss 0.037614
[epoch10, step137]: loss 0.038760
[epoch10, step138]: loss 0.038865
[epoch10, step139]: loss 0.035995
[epoch10, step140]: loss 0.036751
[epoch10, step141]: loss 0.039350
[epoch10, step142]: loss 0.036469
[epoch10, step143]: loss 0.038593
[epoch10, step144]: loss 0.036332
[epoch10, step145]: loss 0.036599
[epoch10, step146]: loss 0.039025
[epoch10, step147]: loss 0.040229
[epoch10, step148]: loss 0.035717
[epoch10, step149]: loss 0.035841
[epoch10, step150]: loss 0.038745
[epoch10, step151]: loss 0.036566
[epoch10, step152]: loss 0.038970
[epoch10, step153]: loss 0.036178
[epoch10, step154]: loss 0.036214
[epoch10, step155]: loss 0.038972
[epoch10, step156]: loss 0.038590
[epoch10, step157]: loss 0.036163
[epoch10, step158]: loss 0.036544
[epoch10, step159]: loss 0.039234
[epoch10, step160]: loss 0.036783
[epoch10, step161]: loss 0.039566
[epoch10, step162]: loss 0.036267
[epoch10, step163]: loss 0.036489
[epoch10, step164]: loss 0.039291
[epoch10, step165]: loss 0.038899
[epoch10, step166]: loss 0.036409
[epoch10, step167]: loss 0.035853
[epoch10, step168]: loss 0.039694
[epoch10, step169]: loss 0.036165
[epoch10, step170]: loss 0.039340
[epoch10, step171]: loss 0.036423
[epoch10, step172]: loss 0.036661
[epoch10, step173]: loss 0.039318
[epoch10, step174]: loss 0.038729
[epoch10, step175]: loss 0.036765
[epoch10, step176]: loss 0.036565
[epoch10, step177]: loss 0.039422
[epoch10, step178]: loss 0.036470
[epoch10, step179]: loss 0.038238
[epoch10, step180]: loss 0.036412
[epoch10, step181]: loss 0.036720
[epoch10, step182]: loss 0.039391
[epoch10, step183]: loss 0.039645
[epoch10, step184]: loss 0.037085
[epoch10, step185]: loss 0.036551
[epoch10, step186]: loss 0.039249
[epoch10, step187]: loss 0.036635
[epoch10, step188]: loss 0.038856
[epoch10, step189]: loss 0.036138
[epoch10, step190]: loss 0.035930
[epoch10, step191]: loss 0.038959
[epoch10, step192]: loss 0.039593
[epoch10, step193]: loss 0.034249
[epoch10, step194]: loss 0.035542
[epoch10, step195]: loss 0.039387
[epoch10, step196]: loss 0.036606
[epoch10, step197]: loss 0.038941
[epoch10, step198]: loss 0.035233
[epoch10, step199]: loss 0.036688
[epoch10, step200]: loss 0.039537
[epoch10, step201]: loss 0.039426
[epoch10, step202]: loss 0.035766
[epoch10, step203]: loss 0.036353
[epoch10, step204]: loss 0.039668
[epoch10, step205]: loss 0.035909
[epoch10, step206]: loss 0.038705
[epoch10, step207]: loss 0.036002
[epoch10, step208]: loss 0.036939
[epoch10, step209]: loss 0.039356
[epoch10, step210]: loss 0.039909
[epoch10, step211]: loss 0.036709
[epoch10, step212]: loss 0.036741
[epoch10, step213]: loss 0.038694
[epoch10, step214]: loss 0.035881
[epoch10, step215]: loss 0.039352
[epoch10, step216]: loss 0.036419
[epoch10, step217]: loss 0.035698
[epoch10, step218]: loss 0.039387
[epoch10, step219]: loss 0.038813
[epoch10, step220]: loss 0.036454
[epoch10, step221]: loss 0.036605
[epoch10, step222]: loss 0.039494
[epoch10, step223]: loss 0.036660
[epoch10, step224]: loss 0.038688
[epoch10, step225]: loss 0.036041
[epoch10, step226]: loss 0.036370
[epoch10, step227]: loss 0.038133
[epoch10, step228]: loss 0.039638
[epoch10, step229]: loss 0.035291
[epoch10, step230]: loss 0.036715
[epoch10, step231]: loss 0.039578
[epoch10, step232]: loss 0.036184
[epoch10, step233]: loss 0.038340
[epoch10, step234]: loss 0.035697
[epoch10, step235]: loss 0.036812
[epoch10, step236]: loss 0.039044
[epoch10, step237]: loss 0.039137
[epoch10, step238]: loss 0.035907
[epoch10, step239]: loss 0.035653
[epoch10, step240]: loss 0.038573
[epoch10, step241]: loss 0.036992
[epoch10, step242]: loss 0.038929
[epoch10, step243]: loss 0.036803
[epoch10, step244]: loss 0.036446
[epoch10, step245]: loss 0.038690
[epoch10, step246]: loss 0.039042
[epoch10, step247]: loss 0.036473
[epoch10, step248]: loss 0.036013
[epoch10, step249]: loss 0.038560
[epoch10, step250]: loss 0.036742
[epoch10, step251]: loss 0.039562
[epoch10, step252]: loss 0.036599
[epoch10, step253]: loss 0.036107
[epoch10, step254]: loss 0.038598
[epoch10, step255]: loss 0.039152
[epoch10, step256]: loss 0.036087
[epoch10, step257]: loss 0.036124
[epoch10, step258]: loss 0.039682
[epoch10, step259]: loss 0.036586
[epoch10, step260]: loss 0.038905
[epoch10, step261]: loss 0.036844
[epoch10, step262]: loss 0.037012
[epoch10, step263]: loss 0.038470
[epoch10, step264]: loss 0.038796
[epoch10, step265]: loss 0.036561
[epoch10, step266]: loss 0.036353
[epoch10, step267]: loss 0.038428
[epoch10, step268]: loss 0.036474
[epoch10, step269]: loss 0.039250
[epoch10, step270]: loss 0.035605
[epoch10, step271]: loss 0.036569
[epoch10, step272]: loss 0.038985
[epoch10, step273]: loss 0.038743
[epoch10, step274]: loss 0.036613
[epoch10, step275]: loss 0.035856
[epoch10, step276]: loss 0.038809
[epoch10, step277]: loss 0.037028
[epoch10, step278]: loss 0.039226
[epoch10, step279]: loss 0.035777
[epoch10, step280]: loss 0.036534
[epoch10, step281]: loss 0.038878
[epoch10, step282]: loss 0.039508
[epoch10, step283]: loss 0.035753
[epoch10, step284]: loss 0.035805
[epoch10, step285]: loss 0.039940
[epoch10, step286]: loss 0.035735
[epoch10, step287]: loss 0.039300
[epoch10, step288]: loss 0.035756
[epoch10, step289]: loss 0.037325
[epoch10, step290]: loss 0.039056
[epoch10, step291]: loss 0.039390
[epoch10, step292]: loss 0.035351
[epoch10, step293]: loss 0.035962
[epoch10, step294]: loss 0.038395
[epoch10, step295]: loss 0.035991
[epoch10, step296]: loss 0.039880
[epoch10, step297]: loss 0.035856
[epoch10, step298]: loss 0.036856
[epoch10, step299]: loss 0.038150
[epoch10, step300]: loss 0.039469
[epoch10, step301]: loss 0.036168
[epoch10, step302]: loss 0.036607
[epoch10, step303]: loss 0.039450
[epoch10, step304]: loss 0.036100
[epoch10, step305]: loss 0.038722
[epoch10, step306]: loss 0.036248
[epoch10, step307]: loss 0.036137
[epoch10, step308]: loss 0.039539
[epoch10, step309]: loss 0.039340
[epoch10, step310]: loss 0.036246
[epoch10, step311]: loss 0.036695
[epoch10, step312]: loss 0.038709
[epoch10, step313]: loss 0.036730
[epoch10, step314]: loss 0.039019
[epoch10, step315]: loss 0.037076
[epoch10, step316]: loss 0.036259
[epoch10, step317]: loss 0.039353
[epoch10, step318]: loss 0.039053
[epoch10, step319]: loss 0.035678
[epoch10, step320]: loss 0.035345
[epoch10, step321]: loss 0.038629
[epoch10, step322]: loss 0.036285
[epoch10, step323]: loss 0.038387
[epoch10, step324]: loss 0.036904
[epoch10, step325]: loss 0.036650
[epoch10, step326]: loss 0.038765
[epoch10, step327]: loss 0.038351
[epoch10, step328]: loss 0.036286
[epoch10, step329]: loss 0.036026
[epoch10, step330]: loss 0.038520
[epoch10, step331]: loss 0.036690
[epoch10, step332]: loss 0.038397
[epoch10, step333]: loss 0.036061
[epoch10, step334]: loss 0.036495
[epoch10, step335]: loss 0.039136
[epoch10, step336]: loss 0.039869
[epoch10, step337]: loss 0.036472
[epoch10, step338]: loss 0.035843
[epoch10, step339]: loss 0.038969
[epoch10, step340]: loss 0.036952
[epoch10, step341]: loss 0.038506
[epoch10, step342]: loss 0.035842
[epoch10, step343]: loss 0.036699
[epoch10, step344]: loss 0.038522
[epoch10, step345]: loss 0.038327
[epoch10, step346]: loss 0.035679
[epoch10, step347]: loss 0.035912
[epoch10, step348]: loss 0.039206
[epoch10, step349]: loss 0.036892
[epoch10, step350]: loss 0.038525
[epoch10, step351]: loss 0.035375
[epoch10, step352]: loss 0.036310
[epoch10, step353]: loss 0.038899
[epoch10, step354]: loss 0.038088
[epoch10, step355]: loss 0.035002
[epoch10, step356]: loss 0.036871
[epoch10, step357]: loss 0.039024
[epoch10, step358]: loss 0.034958
[epoch10, step359]: loss 0.039836
[epoch10, step360]: loss 0.034855
[epoch10, step361]: loss 0.035876
[epoch10, step362]: loss 0.039577
[epoch10, step363]: loss 0.038657
[epoch10, step364]: loss 0.035968
[epoch10, step365]: loss 0.035971
[epoch10, step366]: loss 0.039346
[epoch10, step367]: loss 0.036425
[epoch10, step368]: loss 0.038371
[epoch10, step369]: loss 0.035876
[epoch10, step370]: loss 0.036968
[epoch10, step371]: loss 0.039709
[epoch10, step372]: loss 0.038623
[epoch10, step373]: loss 0.035515
[epoch10, step374]: loss 0.035494
[epoch10, step375]: loss 0.039550
[epoch10, step376]: loss 0.036373
[epoch10, step377]: loss 0.039090
[epoch10, step378]: loss 0.036476
[epoch10, step379]: loss 0.036989
[epoch10, step380]: loss 0.039597
[epoch10, step381]: loss 0.038620
[epoch10, step382]: loss 0.036330
[epoch10, step383]: loss 0.035252
[epoch10, step384]: loss 0.038231
[epoch10, step385]: loss 0.036214
[epoch10, step386]: loss 0.039153
[epoch10, step387]: loss 0.036049
[epoch10, step388]: loss 0.037310
[epoch10, step389]: loss 0.038889
[epoch10, step390]: loss 0.039822
[epoch10, step391]: loss 0.035734
[epoch10, step392]: loss 0.036818
[epoch10, step393]: loss 0.038426
[epoch10, step394]: loss 0.036409
[epoch10, step395]: loss 0.038682
[epoch10, step396]: loss 0.036111
[epoch10, step397]: loss 0.036040
[epoch10, step398]: loss 0.039101
[epoch10, step399]: loss 0.038887
[epoch10, step400]: loss 0.035697
[epoch10, step401]: loss 0.036025
[epoch10, step402]: loss 0.038830
[epoch10, step403]: loss 0.036290
[epoch10, step404]: loss 0.039322
[epoch10, step405]: loss 0.036353
[epoch10, step406]: loss 0.036706
[epoch10, step407]: loss 0.038768
[epoch10, step408]: loss 0.039101
[epoch10, step409]: loss 0.037301
[epoch10, step410]: loss 0.036871
[epoch10, step411]: loss 0.038777
[epoch10, step412]: loss 0.035889
[epoch10, step413]: loss 0.038937
[epoch10, step414]: loss 0.035745
[epoch10, step415]: loss 0.036771
[epoch10, step416]: loss 0.038282
[epoch10, step417]: loss 0.039189
[epoch10, step418]: loss 0.035888
[epoch10, step419]: loss 0.035454
[epoch10, step420]: loss 0.039206
[epoch10, step421]: loss 0.036075
[epoch10, step422]: loss 0.038945
[epoch10, step423]: loss 0.036140
[epoch10, step424]: loss 0.036553
[epoch10, step425]: loss 0.039090
[epoch10, step426]: loss 0.039338
[epoch10, step427]: loss 0.036384
[epoch10, step428]: loss 0.036038
[epoch10, step429]: loss 0.039658
[epoch10, step430]: loss 0.036310
[epoch10, step431]: loss 0.039251
[epoch10, step432]: loss 0.035909
[epoch10, step433]: loss 0.037341
[epoch10, step434]: loss 0.038835
[epoch10, step435]: loss 0.039403
[epoch10, step436]: loss 0.035734
[epoch10, step437]: loss 0.036489
[epoch10, step438]: loss 0.039592
[epoch10, step439]: loss 0.036623
[epoch10, step440]: loss 0.039006
[epoch10, step441]: loss 0.036225
[epoch10, step442]: loss 0.036474
[epoch10, step443]: loss 0.039528
[epoch10, step444]: loss 0.038621
[epoch10, step445]: loss 0.036526
[epoch10, step446]: loss 0.036641
[epoch10, step447]: loss 0.039663
[epoch10, step448]: loss 0.036464
[epoch10, step449]: loss 0.038768
[epoch10, step450]: loss 0.035401
[epoch10, step451]: loss 0.036267
[epoch10, step452]: loss 0.037903
[epoch10, step453]: loss 0.039158
[epoch10, step454]: loss 0.036051
[epoch10, step455]: loss 0.036462
[epoch10, step456]: loss 0.038174
[epoch10, step457]: loss 0.036965
[epoch10, step458]: loss 0.038712
[epoch10, step459]: loss 0.036727
[epoch10, step460]: loss 0.036633
[epoch10, step461]: loss 0.039620
[epoch10, step462]: loss 0.038366
[epoch10, step463]: loss 0.036154
[epoch10, step464]: loss 0.036100
[epoch10, step465]: loss 0.040335
[epoch10, step466]: loss 0.036285
[epoch10, step467]: loss 0.038657
[epoch10, step468]: loss 0.036061
[epoch10, step469]: loss 0.036650
[epoch10, step470]: loss 0.039164
[epoch10, step471]: loss 0.038538
[epoch10, step472]: loss 0.036502
[epoch10, step473]: loss 0.035809
[epoch10, step474]: loss 0.038763
[epoch10, step475]: loss 0.036485
[epoch10, step476]: loss 0.039386
[epoch10, step477]: loss 0.035852
[epoch10, step478]: loss 0.035905
[epoch10, step479]: loss 0.038810
[epoch10, step480]: loss 0.038099
[epoch10, step481]: loss 0.035550
[epoch10, step482]: loss 0.035655
[epoch10, step483]: loss 0.039408
[epoch10, step484]: loss 0.036520
[epoch10, step485]: loss 0.039149
[epoch10, step486]: loss 0.036373
[epoch10, step487]: loss 0.036009
[epoch10, step488]: loss 0.039406
[epoch10, step489]: loss 0.038154
[epoch10, step490]: loss 0.036439
[epoch10, step491]: loss 0.036451
[epoch10, step492]: loss 0.038642
[epoch10, step493]: loss 0.036105
[epoch10, step494]: loss 0.038326
[epoch10, step495]: loss 0.037155
[epoch10, step496]: loss 0.036595
[epoch10, step497]: loss 0.039373
[epoch10, step498]: loss 0.038939
[epoch10, step499]: loss 0.036336
[epoch10, step500]: loss 0.035848
[epoch10, step501]: loss 0.038515
[epoch10, step502]: loss 0.036252
[epoch10, step503]: loss 0.039211
[epoch10, step504]: loss 0.035763
[epoch10, step505]: loss 0.035601
[epoch10, step506]: loss 0.039517
[epoch10, step507]: loss 0.039449
[epoch10, step508]: loss 0.036617
[epoch10, step509]: loss 0.036221
[epoch10, step510]: loss 0.039229
[epoch10, step511]: loss 0.036750
[epoch10, step512]: loss 0.039399
[epoch10, step513]: loss 0.036283
[epoch10, step514]: loss 0.036675
[epoch10, step515]: loss 0.039053
[epoch10, step516]: loss 0.039318
[epoch10, step517]: loss 0.036129
[epoch10, step518]: loss 0.036258
[epoch10, step519]: loss 0.038995
[epoch10, step520]: loss 0.035778
[epoch10, step521]: loss 0.038613
[epoch10, step522]: loss 0.035646
[epoch10, step523]: loss 0.036432
[epoch10, step524]: loss 0.038226
[epoch10, step525]: loss 0.039299
[epoch10, step526]: loss 0.036131
[epoch10, step527]: loss 0.035881
[epoch10, step528]: loss 0.039140
[epoch10, step529]: loss 0.035884
[epoch10, step530]: loss 0.039244
[epoch10, step531]: loss 0.035892
[epoch10, step532]: loss 0.036190
[epoch10, step533]: loss 0.039909
[epoch10, step534]: loss 0.038896
[epoch10, step535]: loss 0.036560
[epoch10, step536]: loss 0.036377
[epoch10, step537]: loss 0.039032
[epoch10, step538]: loss 0.036387
[epoch10, step539]: loss 0.038785
[epoch10, step540]: loss 0.035655
[epoch10, step541]: loss 0.035901
[epoch10, step542]: loss 0.038951
[epoch10, step543]: loss 0.038651
[epoch10, step544]: loss 0.036001
[epoch10, step545]: loss 0.035422
[epoch10, step546]: loss 0.039468
[epoch10, step547]: loss 0.036212
[epoch10, step548]: loss 0.038835
[epoch10, step549]: loss 0.036416
[epoch10, step550]: loss 0.036501
[epoch10, step551]: loss 0.038755
[epoch10, step552]: loss 0.038443
[epoch10, step553]: loss 0.036507
[epoch10, step554]: loss 0.036092
[epoch10, step555]: loss 0.038662
[epoch10, step556]: loss 0.036076
[epoch10, step557]: loss 0.038562
[epoch10, step558]: loss 0.036293
[epoch10, step559]: loss 0.035847
[epoch10, step560]: loss 0.039114
[epoch10, step561]: loss 0.038659
[epoch10, step562]: loss 0.036130
[epoch10, step563]: loss 0.029120
[epoch10, step564]: loss 0.028799
[epoch10, step565]: loss 0.027486
[epoch10, step566]: loss 0.036099
[epoch10, step567]: loss 0.026801
[epoch10, step568]: loss 0.025682
[epoch10, step569]: loss 0.023593
[epoch10, step570]: loss 0.032212
[epoch10, step571]: loss 0.027912
[epoch10, step572]: loss 0.025983
[epoch10, step573]: loss 0.029736
[epoch10, step574]: loss 0.027788
[epoch10, step575]: loss 0.020879
[epoch10, step576]: loss 0.021584
[epoch10, step577]: loss 0.025946
[epoch10, step578]: loss 0.018537
[epoch10, step579]: loss 0.027956
[epoch10, step580]: loss 0.019923
[epoch10, step581]: loss 0.026665
[epoch10, step582]: loss 0.026283
[epoch10, step583]: loss 0.022245
[epoch10, step584]: loss 0.023590
[epoch10, step585]: loss 0.026308
[epoch10, step586]: loss 0.021729
[epoch10, step587]: loss 0.027755
[epoch10, step588]: loss 0.023517
[epoch10, step589]: loss 0.023089
[epoch10, step590]: loss 0.027382
[epoch10, step591]: loss 0.021110
[epoch10, step592]: loss 0.026156
[epoch10, step593]: loss 0.021862
[epoch10, step594]: loss 0.026257
[epoch10, step595]: loss 0.026918
[epoch10, step596]: loss 0.022366
[epoch10, step597]: loss 0.025338
[epoch10, step598]: loss 0.027188
[epoch10, step599]: loss 0.025285
[epoch10, step600]: loss 0.027122
[epoch10, step601]: loss 0.019731
[epoch10, step602]: loss 0.022681
[epoch10, step603]: loss 0.025854
[epoch10, step604]: loss 0.026677
[epoch10, step605]: loss 0.025370
[epoch10, step606]: loss 0.025462
[epoch10, step607]: loss 0.027295
[epoch10, step608]: loss 0.025930
[epoch10, step609]: loss 0.026608
[epoch10, step610]: loss 0.026742
[epoch10, step611]: loss 0.026602
[epoch10, step612]: loss 0.025345
[epoch10, step613]: loss 0.019163
[epoch10, step614]: loss 0.025048
[epoch10, step615]: loss 0.028226
[epoch10, step616]: loss 0.024119
[epoch10, step617]: loss 0.023413
[epoch10, step618]: loss 0.025988
[epoch10, step619]: loss 0.027526
[epoch10, step620]: loss 0.024311
[epoch10, step621]: loss 0.026273
[epoch10, step622]: loss 0.020160
[epoch10, step623]: loss 0.025087
[epoch10, step624]: loss 0.026487
[epoch10, step625]: loss 0.025951
[epoch10, step626]: loss 0.027693
[epoch10, step627]: loss 0.022856
[epoch10, step628]: loss 0.025207
[epoch10, step629]: loss 0.021207
[epoch10, step630]: loss 0.023441
[epoch10, step631]: loss 0.031371
[epoch10, step632]: loss 0.023380
[epoch10, step633]: loss 0.024553
[epoch10, step634]: loss 0.027697
[epoch10, step635]: loss 0.025914
[epoch10, step636]: loss 0.020776
[epoch10, step637]: loss 0.027500
[epoch10, step638]: loss 0.026866
[epoch10, step639]: loss 0.023082
[epoch10, step640]: loss 0.029267
[epoch10, step641]: loss 0.030569
[epoch10, step642]: loss 0.024848
[epoch10, step643]: loss 0.025825
[epoch10, step644]: loss 0.025752
[epoch10, step645]: loss 0.023744
[epoch10, step646]: loss 0.026154
[epoch10, step647]: loss 0.023655
[epoch10, step648]: loss 0.022828
[epoch10, step649]: loss 0.028467
[epoch10, step650]: loss 0.021984
[epoch10, step651]: loss 0.025869
[epoch10, step652]: loss 0.026793
[epoch10, step653]: loss 0.027847
[epoch10, step654]: loss 0.023120
[epoch10, step655]: loss 0.024260
[epoch10, step656]: loss 0.021386
[epoch10, step657]: loss 0.027550
[epoch10, step658]: loss 0.025259
[epoch10, step659]: loss 0.027278
[epoch10, step660]: loss 0.023999
[epoch10, step661]: loss 0.026279
[epoch10, step662]: loss 0.024088
[epoch10, step663]: loss 0.020831
[epoch10, step664]: loss 0.025345
[epoch10, step665]: loss 0.028155
[epoch10, step666]: loss 0.026627
[epoch10, step667]: loss 0.026434
[epoch10, step668]: loss 0.022309
[epoch10, step669]: loss 0.026504
[epoch10, step670]: loss 0.026942
[epoch10, step671]: loss 0.021425
[epoch10, step672]: loss 0.023998
[epoch10, step673]: loss 0.022192
[epoch10, step674]: loss 0.021393
[epoch10, step675]: loss 0.020162
[epoch10, step676]: loss 0.024696
[epoch10, step677]: loss 0.025285
[epoch10, step678]: loss 0.023234
[epoch10, step679]: loss 0.024148
[epoch10, step680]: loss 0.030430
[epoch10, step681]: loss 0.022152
[epoch10, step682]: loss 0.026663
[epoch10, step683]: loss 0.025937
[epoch10, step684]: loss 0.024690
[epoch10, step685]: loss 0.024342
[epoch10, step686]: loss 0.027197
[epoch10, step687]: loss 0.027083
[epoch10, step688]: loss 0.022424
[epoch10, step689]: loss 0.024733
[epoch10, step690]: loss 0.025485
[epoch10, step691]: loss 0.024229
[epoch10, step692]: loss 0.022265
[epoch10, step693]: loss 0.027112
[epoch10, step694]: loss 0.022658
[epoch10, step695]: loss 0.026479
[epoch10, step696]: loss 0.026109
[epoch10, step697]: loss 0.027028
[epoch10, step698]: loss 0.024750
[epoch10, step699]: loss 0.023622
[epoch10, step700]: loss 0.021657
[epoch10, step701]: loss 0.025836
[epoch10, step702]: loss 0.021573
[epoch10, step703]: loss 0.022786
[epoch10, step704]: loss 0.025045
[epoch10, step705]: loss 0.024960
[epoch10, step706]: loss 0.023724
[epoch10, step707]: loss 0.025001
[epoch10, step708]: loss 0.026158
[epoch10, step709]: loss 0.027736
[epoch10, step710]: loss 0.023726
[epoch10, step711]: loss 0.023587
[epoch10, step712]: loss 0.027194
[epoch10, step713]: loss 0.026244
[epoch10, step714]: loss 0.021283
[epoch10, step715]: loss 0.023269
[epoch10, step716]: loss 0.025947
[epoch10, step717]: loss 0.023586
[epoch10, step718]: loss 0.025002
[epoch10, step719]: loss 0.033299
[epoch10, step720]: loss 0.024741
[epoch10, step721]: loss 0.023032
[epoch10, step722]: loss 0.030449
[epoch10, step723]: loss 0.025908
[epoch10, step724]: loss 0.022961
[epoch10, step725]: loss 0.028050
[epoch10, step726]: loss 0.022254
[epoch10, step727]: loss 0.024753
[epoch10, step728]: loss 0.026305
[epoch10, step729]: loss 0.021094
[epoch10, step730]: loss 0.022655
[epoch10, step731]: loss 0.025852
[epoch10, step732]: loss 0.025974
[epoch10, step733]: loss 0.023817
[epoch10, step734]: loss 0.022653
[epoch10, step735]: loss 0.027493
[epoch10, step736]: loss 0.025194
[epoch10, step737]: loss 0.026812
[epoch10, step738]: loss 0.020762
[epoch10, step739]: loss 0.025557
[epoch10, step740]: loss 0.022121
[epoch10, step741]: loss 0.025100
[epoch10, step742]: loss 0.021649
[epoch10, step743]: loss 0.023202
[epoch10, step744]: loss 0.024081
[epoch10, step745]: loss 0.024652
[epoch10, step746]: loss 0.025170
[epoch10, step747]: loss 0.027415
[epoch10, step748]: loss 0.025730
[epoch10, step749]: loss 0.026226
[epoch10, step750]: loss 0.027517
[epoch10, step751]: loss 0.021723
[epoch10, step752]: loss 0.025462
[epoch10, step753]: loss 0.025743
[epoch10, step754]: loss 0.022594
[epoch10, step755]: loss 0.026247
[epoch10, step756]: loss 0.023533
[epoch10, step757]: loss 0.020521
[epoch10, step758]: loss 0.025374
[epoch10, step759]: loss 0.023102
[epoch10, step760]: loss 0.024150
[epoch10, step761]: loss 0.026608
[epoch10, step762]: loss 0.021542
[epoch10, step763]: loss 0.025445
[epoch10, step764]: loss 0.023646
[epoch10, step765]: loss 0.025678
[epoch10, step766]: loss 0.024620
[epoch10, step767]: loss 0.026278
[epoch10, step768]: loss 0.021507
[epoch10, step769]: loss 0.026896
[epoch10, step770]: loss 0.025805
[epoch10, step771]: loss 0.023468
[epoch10, step772]: loss 0.028737
[epoch10, step773]: loss 0.026610
[epoch10, step774]: loss 0.024215
[epoch10, step775]: loss 0.020644
[epoch10, step776]: loss 0.025560
[epoch10, step777]: loss 0.023130
[epoch10, step778]: loss 0.028202
[epoch10, step779]: loss 0.023679
[epoch10, step780]: loss 0.020039
[epoch10, step781]: loss 0.024496
[epoch10, step782]: loss 0.022827
[epoch10, step783]: loss 0.019272
[epoch10, step784]: loss 0.020150
[epoch10, step785]: loss 0.021523
[epoch10, step786]: loss 0.024285
[epoch10, step787]: loss 0.023181
[epoch10, step788]: loss 0.024774
[epoch10, step789]: loss 0.022488
[epoch10, step790]: loss 0.023218
[epoch10, step791]: loss 0.026768
[epoch10, step792]: loss 0.025111
[epoch10, step793]: loss 0.026755
[epoch10, step794]: loss 0.020325
[epoch10, step795]: loss 0.025570
[epoch10, step796]: loss 0.027858
[epoch10, step797]: loss 0.027638
[epoch10, step798]: loss 0.027028
[epoch10, step799]: loss 0.025790
[epoch10, step800]: loss 0.021327
[epoch10, step801]: loss 0.021658
[epoch10, step802]: loss 0.022749
[epoch10, step803]: loss 0.026172
[epoch10, step804]: loss 0.027293
[epoch10, step805]: loss 0.028192
[epoch10, step806]: loss 0.021233
[epoch10, step807]: loss 0.020507
[epoch10, step808]: loss 0.022913
[epoch10, step809]: loss 0.023010
[epoch10, step810]: loss 0.025986
[epoch10, step811]: loss 0.025651
[epoch10, step812]: loss 0.024570
[epoch10, step813]: loss 0.023657
[epoch10, step814]: loss 0.025023
[epoch10, step815]: loss 0.025059
[epoch10, step816]: loss 0.024105
[epoch10, step817]: loss 0.024773
[epoch10, step818]: loss 0.022556
[epoch10, step819]: loss 0.020116
[epoch10, step820]: loss 0.023727
[epoch10, step821]: loss 0.021893
[epoch10, step822]: loss 0.030551
[epoch10, step823]: loss 0.023994
[epoch10, step824]: loss 0.026836
[epoch10, step825]: loss 0.025274
[epoch10, step826]: loss 0.024394
[epoch10, step827]: loss 0.026840
[epoch10, step828]: loss 0.028593
[epoch10, step829]: loss 0.026573
[epoch10, step830]: loss 0.022440
[epoch10, step831]: loss 0.026329
[epoch10, step832]: loss 0.020820
[epoch10, step833]: loss 0.029094
[epoch10, step834]: loss 0.025286
[epoch10, step835]: loss 0.020374
[epoch10, step836]: loss 0.026899
[epoch10, step837]: loss 0.025476
[epoch10, step838]: loss 0.026180
[epoch10, step839]: loss 0.028463
[epoch10, step840]: loss 0.020588
[epoch10, step841]: loss 0.024162
[epoch10, step842]: loss 0.027537
[epoch10, step843]: loss 0.024815
[epoch10, step844]: loss 0.024930
[epoch10, step845]: loss 0.021174
[epoch10, step846]: loss 0.025328
[epoch10, step847]: loss 0.026781
[epoch10, step848]: loss 0.024984
[epoch10, step849]: loss 0.024958
[epoch10, step850]: loss 0.023127
[epoch10, step851]: loss 0.023934
[epoch10, step852]: loss 0.023115
[epoch10, step853]: loss 0.029160
[epoch10, step854]: loss 0.022666
[epoch10, step855]: loss 0.027295
[epoch10, step856]: loss 0.022147
[epoch10, step857]: loss 0.025923
[epoch10, step858]: loss 0.024321
[epoch10, step859]: loss 0.023558
[epoch10, step860]: loss 0.022668
[epoch10, step861]: loss 0.023290
[epoch10, step862]: loss 0.022948
[epoch10, step863]: loss 0.020592
[epoch10, step864]: loss 0.026240
[epoch10, step865]: loss 0.023388
[epoch10, step866]: loss 0.025256
[epoch10, step867]: loss 0.026010
[epoch10, step868]: loss 0.026769
[epoch10, step869]: loss 0.023905
[epoch10, step870]: loss 0.030722
[epoch10, step871]: loss 0.021977
[epoch10, step872]: loss 0.025389
[epoch10, step873]: loss 0.025773
[epoch10, step874]: loss 0.023655
[epoch10, step875]: loss 0.024071
[epoch10, step876]: loss 0.024251
[epoch10, step877]: loss 0.018991
[epoch10, step878]: loss 0.023265
[epoch10, step879]: loss 0.027895
[epoch10, step880]: loss 0.025605
[epoch10, step881]: loss 0.022136
[epoch10, step882]: loss 0.024118
[epoch10, step883]: loss 0.023800
[epoch10, step884]: loss 0.026339
[epoch10, step885]: loss 0.025883
[epoch10, step886]: loss 0.026535
[epoch10, step887]: loss 0.024150
[epoch10, step888]: loss 0.024636
[epoch10, step889]: loss 0.023478
[epoch10, step890]: loss 0.023409
[epoch10, step891]: loss 0.025490
[epoch10, step892]: loss 0.020953
[epoch10, step893]: loss 0.024629
[epoch10, step894]: loss 0.024913
[epoch10, step895]: loss 0.022587
[epoch10, step896]: loss 0.021805
[epoch10, step897]: loss 0.023787
[epoch10, step898]: loss 0.025429
[epoch10, step899]: loss 0.027957
[epoch10, step900]: loss 0.026992
[epoch10, step901]: loss 0.025381
[epoch10, step902]: loss 0.024064
[epoch10, step903]: loss 0.023943
[epoch10, step904]: loss 0.027998
[epoch10, step905]: loss 0.027585
[epoch10, step906]: loss 0.022481
[epoch10, step907]: loss 0.023581
[epoch10, step908]: loss 0.022385
[epoch10, step909]: loss 0.025403
[epoch10, step910]: loss 0.023097
[epoch10, step911]: loss 0.025182
[epoch10, step912]: loss 0.023732
[epoch10, step913]: loss 0.024034
[epoch10, step914]: loss 0.030490
[epoch10, step915]: loss 0.023928
[epoch10, step916]: loss 0.023691
[epoch10, step917]: loss 0.025057
[epoch10, step918]: loss 0.028542
[epoch10, step919]: loss 0.024202
[epoch10, step920]: loss 0.027497
[epoch10, step921]: loss 0.024433
[epoch10, step922]: loss 0.023097
[epoch10, step923]: loss 0.022438
[epoch10, step924]: loss 0.021288
[epoch10, step925]: loss 0.025264
[epoch10, step926]: loss 0.026516
[epoch10, step927]: loss 0.025669
[epoch10, step928]: loss 0.024865
[epoch10, step929]: loss 0.027640
[epoch10, step930]: loss 0.025745
[epoch10, step931]: loss 0.027163
[epoch10, step932]: loss 0.021558
[epoch10, step933]: loss 0.028193
[epoch10, step934]: loss 0.022009
[epoch10, step935]: loss 0.021892
[epoch10, step936]: loss 0.022305
[epoch10, step937]: loss 0.027021
[epoch10, step938]: loss 0.025152
[epoch10, step939]: loss 0.020727
[epoch10, step940]: loss 0.022871
[epoch10, step941]: loss 0.026682
[epoch10, step942]: loss 0.025403
[epoch10, step943]: loss 0.023161
[epoch10, step944]: loss 0.027505
[epoch10, step945]: loss 0.020410
[epoch10, step946]: loss 0.025453
[epoch10, step947]: loss 0.027848
[epoch10, step948]: loss 0.019566
[epoch10, step949]: loss 0.022729
[epoch10, step950]: loss 0.026595
[epoch10, step951]: loss 0.028853
[epoch10, step952]: loss 0.025134
[epoch10, step953]: loss 0.027574
[epoch10, step954]: loss 0.022198
[epoch10, step955]: loss 0.036881
[epoch10, step956]: loss 0.052688
[epoch10, step957]: loss 0.047329
[epoch10, step958]: loss 0.044548
[epoch10, step959]: loss 0.047194
[epoch10, step960]: loss 0.042699
[epoch10, step961]: loss 0.042264
[epoch10, step962]: loss 0.041171
[epoch10, step963]: loss 0.039498
[epoch10, step964]: loss 0.040907
[epoch10, step965]: loss 0.042609
[epoch10, step966]: loss 0.041210
[epoch10, step967]: loss 0.040542
[epoch10, step968]: loss 0.042476
[epoch10, step969]: loss 0.041304
[epoch10, step970]: loss 0.040376
[epoch10, step971]: loss 0.039377
[epoch10, step972]: loss 0.040528
[epoch10, step973]: loss 0.040199
[epoch10, step974]: loss 0.042698
[epoch10, step975]: loss 0.038956
[epoch10, step976]: loss 0.037815
[epoch10, step977]: loss 0.041718
[epoch10, step978]: loss 0.040151
[epoch10, step979]: loss 0.039514
[epoch10, step980]: loss 0.038561
[epoch10, step981]: loss 0.039429
[epoch10, step982]: loss 0.039622
[epoch10, step983]: loss 0.041021
[epoch10, step984]: loss 0.037293
[epoch10, step985]: loss 0.037560
[epoch10, step986]: loss 0.041629
[epoch10, step987]: loss 0.039852
[epoch10, step988]: loss 0.039443
[epoch10, step989]: loss 0.038597
[epoch10, step990]: loss 0.038706
[epoch10, step991]: loss 0.039683
[epoch10, step992]: loss 0.040329
[epoch10, step993]: loss 0.037657
[epoch10, step994]: loss 0.036611
[epoch10, step995]: loss 0.040306
[epoch10, step996]: loss 0.038493
[epoch10, step997]: loss 0.038693
[epoch10, step998]: loss 0.038227
[epoch10, step999]: loss 0.038565
[epoch10, step1000]: loss 0.038769
[epoch10, step1001]: loss 0.039878
[epoch10, step1002]: loss 0.037639
[epoch10, step1003]: loss 0.036611
[epoch10, step1004]: loss 0.040292
[epoch10, step1005]: loss 0.037880
[epoch10, step1006]: loss 0.038375
[epoch10, step1007]: loss 0.036784
[epoch10, step1008]: loss 0.037810
[epoch10, step1009]: loss 0.038379
[epoch10, step1010]: loss 0.040244
[epoch10, step1011]: loss 0.037114
[epoch10, step1012]: loss 0.037111
[epoch10, step1013]: loss 0.040088
[epoch10, step1014]: loss 0.038993
[epoch10, step1015]: loss 0.038564
[epoch10, step1016]: loss 0.036836
[epoch10, step1017]: loss 0.037851
[epoch10, step1018]: loss 0.038289
[epoch10, step1019]: loss 0.039604
[epoch10, step1020]: loss 0.036678
[epoch10, step1021]: loss 0.036291
[epoch10, step1022]: loss 0.039584
[epoch10, step1023]: loss 0.038180
[epoch10, step1024]: loss 0.038665
[epoch10, step1025]: loss 0.036431
[epoch10, step1026]: loss 0.037407
[epoch10, step1027]: loss 0.037825
[epoch10, step1028]: loss 0.039480
[epoch10, step1029]: loss 0.036625
[epoch10, step1030]: loss 0.035951
[epoch10, step1031]: loss 0.038440
[epoch10, step1032]: loss 0.038482
[epoch10, step1033]: loss 0.037640
[epoch10, step1034]: loss 0.036643
[epoch10, step1035]: loss 0.037273
[epoch10, step1036]: loss 0.038273
[epoch10, step1037]: loss 0.039162
[epoch10, step1038]: loss 0.036566
[epoch10, step1039]: loss 0.036569
[epoch10, step1040]: loss 0.038915
[epoch10, step1041]: loss 0.037752
[epoch10, step1042]: loss 0.036818
[epoch10, step1043]: loss 0.036591
[epoch10, step1044]: loss 0.037925
[epoch10, step1045]: loss 0.038146
[epoch10, step1046]: loss 0.039461
[epoch10, step1047]: loss 0.036740
[epoch10, step1048]: loss 0.035942
[epoch10, step1049]: loss 0.039486
[epoch10, step1050]: loss 0.038520
[epoch10, step1051]: loss 0.037812
[epoch10, step1052]: loss 0.037106
[epoch10, step1053]: loss 0.038151
[epoch10, step1054]: loss 0.038189
[epoch10, step1055]: loss 0.038791
[epoch10, step1056]: loss 0.036021
[epoch10, step1057]: loss 0.037000
[epoch10, step1058]: loss 0.040347
[epoch10, step1059]: loss 0.038224
[epoch10, step1060]: loss 0.037936
[epoch10, step1061]: loss 0.036046
[epoch10, step1062]: loss 0.038063
[epoch10, step1063]: loss 0.037969
[epoch10, step1064]: loss 0.039179
[epoch10, step1065]: loss 0.036505
[epoch10, step1066]: loss 0.036032
[epoch10, step1067]: loss 0.039357
[epoch10, step1068]: loss 0.036721
[epoch10, step1069]: loss 0.037129
[epoch10, step1070]: loss 0.036417
[epoch10, step1071]: loss 0.038209
[epoch10, step1072]: loss 0.038718
[epoch10, step1073]: loss 0.039039
[epoch10, step1074]: loss 0.036731
[epoch10, step1075]: loss 0.036594
[epoch10, step1076]: loss 0.039483
[epoch10, step1077]: loss 0.037916
[epoch10, step1078]: loss 0.037382
[epoch10, step1079]: loss 0.037484
[epoch10, step1080]: loss 0.037928
[epoch10, step1081]: loss 0.037727
[epoch10, step1082]: loss 0.038968
[epoch10, step1083]: loss 0.037178
[epoch10, step1084]: loss 0.036476
[epoch10, step1085]: loss 0.038869
[epoch10, step1086]: loss 0.037549
[epoch10, step1087]: loss 0.037626
[epoch10, step1088]: loss 0.036252
[epoch10, step1089]: loss 0.038039
[epoch10, step1090]: loss 0.038572
[epoch10, step1091]: loss 0.039328
[epoch10, step1092]: loss 0.036239
[epoch10, step1093]: loss 0.036184
[epoch10, step1094]: loss 0.038411
[epoch10, step1095]: loss 0.037411
[epoch10, step1096]: loss 0.037033
[epoch10, step1097]: loss 0.036384
[epoch10, step1098]: loss 0.037678
[epoch10, step1099]: loss 0.037554
[epoch10, step1100]: loss 0.039583
[epoch10, step1101]: loss 0.036762
[epoch10, step1102]: loss 0.036047
[epoch10, step1103]: loss 0.038701
[epoch10, step1104]: loss 0.037769
[epoch10, step1105]: loss 0.037672
[epoch10, step1106]: loss 0.035384
[epoch10, step1107]: loss 0.037977
[epoch10, step1108]: loss 0.037582
[epoch10, step1109]: loss 0.039420
[epoch10, step1110]: loss 0.037098
[epoch10, step1111]: loss 0.036421
[epoch10, step1112]: loss 0.039615
[epoch10, step1113]: loss 0.037481
[epoch10, step1114]: loss 0.037793
[epoch10, step1115]: loss 0.036492
[epoch10, step1116]: loss 0.037755
[epoch10, step1117]: loss 0.037924
[epoch10, step1118]: loss 0.038891
[epoch10, step1119]: loss 0.036227
[epoch10, step1120]: loss 0.036044
[epoch10, step1121]: loss 0.039145
[epoch10, step1122]: loss 0.037285
[epoch10, step1123]: loss 0.036693
[epoch10, step1124]: loss 0.037033
[epoch10, step1125]: loss 0.038059
[epoch10, step1126]: loss 0.038864
[epoch10, step1127]: loss 0.039024
[epoch10, step1128]: loss 0.036517
[epoch10, step1129]: loss 0.035954
[epoch10, step1130]: loss 0.039980
[epoch10, step1131]: loss 0.038102
[epoch10, step1132]: loss 0.037745
[epoch10, step1133]: loss 0.035832
[epoch10, step1134]: loss 0.037468
[epoch10, step1135]: loss 0.038809
[epoch10, step1136]: loss 0.039708
[epoch10, step1137]: loss 0.036401
[epoch10, step1138]: loss 0.036350
[epoch10, step1139]: loss 0.039128
[epoch10, step1140]: loss 0.037096
[epoch10, step1141]: loss 0.037043
[epoch10, step1142]: loss 0.035990
[epoch10, step1143]: loss 0.037136
[epoch10, step1144]: loss 0.038008
[epoch10, step1145]: loss 0.038432
[epoch10, step1146]: loss 0.035895
[epoch10, step1147]: loss 0.036878
[epoch10, step1148]: loss 0.039219
[epoch10, step1149]: loss 0.037347
[epoch10, step1150]: loss 0.037136
[epoch10, step1151]: loss 0.036608
[epoch10, step1152]: loss 0.038217
[epoch10, step1153]: loss 0.037263
[epoch10, step1154]: loss 0.039237
[epoch10, step1155]: loss 0.036366
[epoch10, step1156]: loss 0.035506
[epoch10, step1157]: loss 0.038836
[epoch10, step1158]: loss 0.037900
[epoch10, step1159]: loss 0.037516
[epoch10, step1160]: loss 0.037076
[epoch10, step1161]: loss 0.038150
[epoch10, step1162]: loss 0.037785
[epoch10, step1163]: loss 0.038238
[epoch10, step1164]: loss 0.036189
[epoch10, step1165]: loss 0.037195
[epoch10, step1166]: loss 0.039272
[epoch10, step1167]: loss 0.036857
[epoch10, step1168]: loss 0.037465
[epoch10, step1169]: loss 0.036001
[epoch10, step1170]: loss 0.037673
[epoch10, step1171]: loss 0.037891
[epoch10, step1172]: loss 0.038801
[epoch10, step1173]: loss 0.036324
[epoch10, step1174]: loss 0.036530
[epoch10, step1175]: loss 0.038985
[epoch10, step1176]: loss 0.037383
[epoch10, step1177]: loss 0.037538
[epoch10, step1178]: loss 0.036308
[epoch10, step1179]: loss 0.037619
[epoch10, step1180]: loss 0.037940
[epoch10, step1181]: loss 0.039456
[epoch10, step1182]: loss 0.035539
[epoch10, step1183]: loss 0.036677
[epoch10, step1184]: loss 0.038570
[epoch10, step1185]: loss 0.037819
[epoch10, step1186]: loss 0.036465
[epoch10, step1187]: loss 0.035322
[epoch10, step1188]: loss 0.037011
[epoch10, step1189]: loss 0.037491
[epoch10, step1190]: loss 0.038436
[epoch10, step1191]: loss 0.036780
[epoch10, step1192]: loss 0.036222
[epoch10, step1193]: loss 0.038996
[epoch10, step1194]: loss 0.037453
[epoch10, step1195]: loss 0.036131
[epoch10, step1196]: loss 0.035465
[epoch10, step1197]: loss 0.037952
[epoch10, step1198]: loss 0.037821
[epoch10, step1199]: loss 0.038554
[epoch10, step1200]: loss 0.035842
[epoch10, step1201]: loss 0.036713
[epoch10, step1202]: loss 0.039910
[epoch10, step1203]: loss 0.037700
[epoch10, step1204]: loss 0.036610
[epoch10, step1205]: loss 0.035666
[epoch10, step1206]: loss 0.037142
[epoch10, step1207]: loss 0.038036
[epoch10, step1208]: loss 0.039178
[epoch10, step1209]: loss 0.035010
[epoch10, step1210]: loss 0.036668
[epoch10, step1211]: loss 0.038698
[epoch10, step1212]: loss 0.037379
[epoch10, step1213]: loss 0.036803
[epoch10, step1214]: loss 0.036286
[epoch10, step1215]: loss 0.038300
[epoch10, step1216]: loss 0.037280
[epoch10, step1217]: loss 0.039469
[epoch10, step1218]: loss 0.035750
[epoch10, step1219]: loss 0.036774
[epoch10, step1220]: loss 0.039369
[epoch10, step1221]: loss 0.036788
[epoch10, step1222]: loss 0.037403
[epoch10, step1223]: loss 0.036117
[epoch10, step1224]: loss 0.038199
[epoch10, step1225]: loss 0.037841
[epoch10, step1226]: loss 0.038472
[epoch10, step1227]: loss 0.036064
[epoch10, step1228]: loss 0.035827
[epoch10, step1229]: loss 0.038712
[epoch10, step1230]: loss 0.037821
[epoch10, step1231]: loss 0.037202
[epoch10, step1232]: loss 0.037127
[epoch10, step1233]: loss 0.037459
[epoch10, step1234]: loss 0.037455
[epoch10, step1235]: loss 0.039259
[epoch10, step1236]: loss 0.036312
[epoch10, step1237]: loss 0.035705
[epoch10, step1238]: loss 0.038449
[epoch10, step1239]: loss 0.038231
[epoch10, step1240]: loss 0.037497
[epoch10, step1241]: loss 0.035702
[epoch10, step1242]: loss 0.037657
[epoch10, step1243]: loss 0.037528
[epoch10, step1244]: loss 0.039106
[epoch10, step1245]: loss 0.036457
[epoch10, step1246]: loss 0.036443
[epoch10, step1247]: loss 0.038077
[epoch10, step1248]: loss 0.037647
[epoch10, step1249]: loss 0.037783
[epoch10, step1250]: loss 0.035998
[epoch10, step1251]: loss 0.038011
[epoch10, step1252]: loss 0.038614
[epoch10, step1253]: loss 0.039122
[epoch10, step1254]: loss 0.036199
[epoch10, step1255]: loss 0.036276
[epoch10, step1256]: loss 0.039410
[epoch10, step1257]: loss 0.037892
[epoch10, step1258]: loss 0.037518
[epoch10, step1259]: loss 0.036047
[epoch10, step1260]: loss 0.037807
[epoch10, step1261]: loss 0.037575
[epoch10, step1262]: loss 0.037771
[epoch10, step1263]: loss 0.036655
[epoch10, step1264]: loss 0.036046
[epoch10, step1265]: loss 0.037861
[epoch10, step1266]: loss 0.037584
[epoch10, step1267]: loss 0.037567
[epoch10, step1268]: loss 0.036326
[epoch10, step1269]: loss 0.037823
[epoch10, step1270]: loss 0.037047
[epoch10, step1271]: loss 0.039250
[epoch10, step1272]: loss 0.036217
[epoch10, step1273]: loss 0.035888
[epoch10, step1274]: loss 0.038980
[epoch10, step1275]: loss 0.037951
[epoch10, step1276]: loss 0.037200
[epoch10, step1277]: loss 0.036172
[epoch10, step1278]: loss 0.038386
[epoch10, step1279]: loss 0.038097
[epoch10, step1280]: loss 0.039034
[epoch10, step1281]: loss 0.035961
[epoch10, step1282]: loss 0.036292
[epoch10, step1283]: loss 0.038377
[epoch10, step1284]: loss 0.037089
[epoch10, step1285]: loss 0.037648
[epoch10, step1286]: loss 0.035553
[epoch10, step1287]: loss 0.038389
[epoch10, step1288]: loss 0.038467
[epoch10, step1289]: loss 0.039787
[epoch10, step1290]: loss 0.036136
[epoch10, step1291]: loss 0.035893
[epoch10, step1292]: loss 0.039778
[epoch10, step1293]: loss 0.036843
[epoch10, step1294]: loss 0.037372
[epoch10, step1295]: loss 0.036632
[epoch10, step1296]: loss 0.038084
[epoch10, step1297]: loss 0.037657
[epoch10, step1298]: loss 0.039455
[epoch10, step1299]: loss 0.036397
[epoch10, step1300]: loss 0.036849
[epoch10, step1301]: loss 0.038029
[epoch10, step1302]: loss 0.037495
[epoch10, step1303]: loss 0.037491
[epoch10, step1304]: loss 0.035492
[epoch10, step1305]: loss 0.038243
[epoch10, step1306]: loss 0.037896
[epoch10, step1307]: loss 0.038351
[epoch10, step1308]: loss 0.036217
[epoch10, step1309]: loss 0.035559
[epoch10, step1310]: loss 0.038855
[epoch10, step1311]: loss 0.036572
[epoch10, step1312]: loss 0.037937
[epoch10, step1313]: loss 0.036244
[epoch10, step1314]: loss 0.037621
[epoch10, step1315]: loss 0.037406
[epoch10, step1316]: loss 0.040257
[epoch10, step1317]: loss 0.035614
[epoch10, step1318]: loss 0.035634
[epoch10, step1319]: loss 0.038432
[epoch10, step1320]: loss 0.037763
[epoch10, step1321]: loss 0.037756
[epoch10, step1322]: loss 0.035741
[epoch10, step1323]: loss 0.038145
[epoch10, step1324]: loss 0.037331
[epoch10, step1325]: loss 0.038701
[epoch10, step1326]: loss 0.035898
[epoch10, step1327]: loss 0.035949
[epoch10, step1328]: loss 0.038953
[epoch10, step1329]: loss 0.037361
[epoch10, step1330]: loss 0.037476
[epoch10, step1331]: loss 0.035752
[epoch10, step1332]: loss 0.037583
[epoch10, step1333]: loss 0.036810
[epoch10, step1334]: loss 0.039266
[epoch10, step1335]: loss 0.036752
[epoch10, step1336]: loss 0.036151
[epoch10, step1337]: loss 0.038345
[epoch10, step1338]: loss 0.037531
[epoch10, step1339]: loss 0.037384
[epoch10, step1340]: loss 0.035813
[epoch10, step1341]: loss 0.038062
[epoch10, step1342]: loss 0.037448
[epoch10, step1343]: loss 0.039109
[epoch10, step1344]: loss 0.036207
[epoch10, step1345]: loss 0.036207
[epoch10, step1346]: loss 0.038483
[epoch10, step1347]: loss 0.038131
[epoch10, step1348]: loss 0.036644
[epoch10, step1349]: loss 0.036114
[epoch10, step1350]: loss 0.037887
[epoch10, step1351]: loss 0.037153
[epoch10, step1352]: loss 0.038316
[epoch10, step1353]: loss 0.035799
[epoch10, step1354]: loss 0.035865
[epoch10, step1355]: loss 0.039037
[epoch10, step1356]: loss 0.037237
[epoch10, step1357]: loss 0.036757
[epoch10, step1358]: loss 0.035844
[epoch10, step1359]: loss 0.037286
[epoch10, step1360]: loss 0.037892
[epoch10, step1361]: loss 0.039168
[epoch10, step1362]: loss 0.036671
[epoch10, step1363]: loss 0.036685
[epoch10, step1364]: loss 0.038737
[epoch10, step1365]: loss 0.037575
[epoch10, step1366]: loss 0.037158
[epoch10, step1367]: loss 0.035203
[epoch10, step1368]: loss 0.038698
[epoch10, step1369]: loss 0.037899
[epoch10, step1370]: loss 0.038586
[epoch10, step1371]: loss 0.036328
[epoch10, step1372]: loss 0.035972
[epoch10, step1373]: loss 0.038927
[epoch10, step1374]: loss 0.038278
[epoch10, step1375]: loss 0.037944
[epoch10, step1376]: loss 0.035738
[epoch10, step1377]: loss 0.037123
[epoch10, step1378]: loss 0.037691
[epoch10, step1379]: loss 0.038450
[epoch10, step1380]: loss 0.036419
[epoch10, step1381]: loss 0.036076
[epoch10, step1382]: loss 0.039085
[epoch10, step1383]: loss 0.037294
[epoch10, step1384]: loss 0.037067
[epoch10, step1385]: loss 0.035346
[epoch10, step1386]: loss 0.037935
[epoch10, step1387]: loss 0.038095
[epoch10, step1388]: loss 0.037810
[epoch10, step1389]: loss 0.035339
[epoch10, step1390]: loss 0.036368
[epoch10, step1391]: loss 0.038525
[epoch10, step1392]: loss 0.037513
[epoch10, step1393]: loss 0.037431
[epoch10, step1394]: loss 0.036612
[epoch10, step1395]: loss 0.037901
[epoch10, step1396]: loss 0.037220
[epoch10, step1397]: loss 0.038572
[epoch10, step1398]: loss 0.035916
[epoch10, step1399]: loss 0.036971
[epoch10, step1400]: loss 0.039292
[epoch10, step1401]: loss 0.037180
[epoch10, step1402]: loss 0.037417
[epoch10, step1403]: loss 0.034921
[epoch10, step1404]: loss 0.037192
[epoch10, step1405]: loss 0.037400
[epoch10, step1406]: loss 0.038563
[epoch10, step1407]: loss 0.037010
[epoch10, step1408]: loss 0.035490
[epoch10, step1409]: loss 0.038403
[epoch10, step1410]: loss 0.037406
[epoch10, step1411]: loss 0.036177
[epoch10, step1412]: loss 0.036004
[epoch10, step1413]: loss 0.037768
[epoch10, step1414]: loss 0.037185
[epoch10, step1415]: loss 0.038536
[epoch10, step1416]: loss 0.035841
[epoch10, step1417]: loss 0.036027
[epoch10, step1418]: loss 0.038772
[epoch10, step1419]: loss 0.038147
[epoch10, step1420]: loss 0.037474
[epoch10, step1421]: loss 0.036361
[epoch10, step1422]: loss 0.037989
[epoch10, step1423]: loss 0.037112
[epoch10, step1424]: loss 0.038951
[epoch10, step1425]: loss 0.035040
[epoch10, step1426]: loss 0.036114
[epoch10, step1427]: loss 0.039690
[epoch10, step1428]: loss 0.038234
[epoch10, step1429]: loss 0.037179
[epoch10, step1430]: loss 0.035897
[epoch10, step1431]: loss 0.037811
[epoch10, step1432]: loss 0.037306
[epoch10, step1433]: loss 0.038913
[epoch10, step1434]: loss 0.035511
[epoch10, step1435]: loss 0.036510
[epoch10, step1436]: loss 0.039095
[epoch10, step1437]: loss 0.037704
[epoch10, step1438]: loss 0.037998
[epoch10, step1439]: loss 0.035751
[epoch10, step1440]: loss 0.037559
[epoch10, step1441]: loss 0.038203
[epoch10, step1442]: loss 0.038018
[epoch10, step1443]: loss 0.035682
[epoch10, step1444]: loss 0.035361
[epoch10, step1445]: loss 0.039084
[epoch10, step1446]: loss 0.037586
[epoch10, step1447]: loss 0.038003
[epoch10, step1448]: loss 0.035885
[epoch10, step1449]: loss 0.037143
[epoch10, step1450]: loss 0.037588
[epoch10, step1451]: loss 0.039065
[epoch10, step1452]: loss 0.035696
[epoch10, step1453]: loss 0.037151
[epoch10, step1454]: loss 0.039230
[epoch10, step1455]: loss 0.038037
[epoch10, step1456]: loss 0.036816
[epoch10, step1457]: loss 0.036479
[epoch10, step1458]: loss 0.037852
[epoch10, step1459]: loss 0.037594
[epoch10, step1460]: loss 0.039273
[epoch10, step1461]: loss 0.036638
[epoch10, step1462]: loss 0.036745
[epoch10, step1463]: loss 0.038745
[epoch10, step1464]: loss 0.037736
[epoch10, step1465]: loss 0.036884
[epoch10, step1466]: loss 0.035564
[epoch10, step1467]: loss 0.037642
[epoch10, step1468]: loss 0.037080
[epoch10, step1469]: loss 0.038713
[epoch10, step1470]: loss 0.036120
[epoch10, step1471]: loss 0.035779
[epoch10, step1472]: loss 0.038636
[epoch10, step1473]: loss 0.037390
[epoch10, step1474]: loss 0.037833
[epoch10, step1475]: loss 0.035628
[epoch10, step1476]: loss 0.038504
[epoch10, step1477]: loss 0.037237
[epoch10, step1478]: loss 0.038825
[epoch10, step1479]: loss 0.035865
[epoch10, step1480]: loss 0.036051
[epoch10, step1481]: loss 0.037921
[epoch10, step1482]: loss 0.037349
[epoch10, step1483]: loss 0.037258
[epoch10, step1484]: loss 0.036228
[epoch10, step1485]: loss 0.037493
[epoch10, step1486]: loss 0.036524
[epoch10, step1487]: loss 0.038580
[epoch10, step1488]: loss 0.035968
[epoch10, step1489]: loss 0.035958
[epoch10, step1490]: loss 0.038784
[epoch10, step1491]: loss 0.037496
[epoch10, step1492]: loss 0.036990
[epoch10, step1493]: loss 0.035914
[epoch10, step1494]: loss 0.037777
[epoch10, step1495]: loss 0.037315
[epoch10, step1496]: loss 0.037970
[epoch10, step1497]: loss 0.036244
[epoch10, step1498]: loss 0.036380
[epoch10, step1499]: loss 0.038171
[epoch10, step1500]: loss 0.037682
[epoch10, step1501]: loss 0.037318
[epoch10, step1502]: loss 0.035717
[epoch10, step1503]: loss 0.037527
[epoch10, step1504]: loss 0.037016
[epoch10, step1505]: loss 0.038964
[epoch10, step1506]: loss 0.035353
[epoch10, step1507]: loss 0.036365
[epoch10, step1508]: loss 0.039263
[epoch10, step1509]: loss 0.037122
[epoch10, step1510]: loss 0.036840
[epoch10, step1511]: loss 0.036538
[epoch10, step1512]: loss 0.037964
[epoch10, step1513]: loss 0.036161
[epoch10, step1514]: loss 0.038691
[epoch10, step1515]: loss 0.036462
[epoch10, step1516]: loss 0.036109

[epoch10]: avg loss 0.034287

[epoch11, step1]: loss 0.034629
[epoch11, step2]: loss 0.038471
[epoch11, step3]: loss 0.038448
[epoch11, step4]: loss 0.035876
[epoch11, step5]: loss 0.036477
[epoch11, step6]: loss 0.038732
[epoch11, step7]: loss 0.036800
[epoch11, step8]: loss 0.039037
[epoch11, step9]: loss 0.035472
[epoch11, step10]: loss 0.037295
[epoch11, step11]: loss 0.038747
[epoch11, step12]: loss 0.038599
[epoch11, step13]: loss 0.036113
[epoch11, step14]: loss 0.036325
[epoch11, step15]: loss 0.038744
[epoch11, step16]: loss 0.036573
[epoch11, step17]: loss 0.039006
[epoch11, step18]: loss 0.036582
[epoch11, step19]: loss 0.036498
[epoch11, step20]: loss 0.039559
[epoch11, step21]: loss 0.038525
[epoch11, step22]: loss 0.035576
[epoch11, step23]: loss 0.035415
[epoch11, step24]: loss 0.038887
[epoch11, step25]: loss 0.036012
[epoch11, step26]: loss 0.038368
[epoch11, step27]: loss 0.035290
[epoch11, step28]: loss 0.036927
[epoch11, step29]: loss 0.038848
[epoch11, step30]: loss 0.039361
[epoch11, step31]: loss 0.035354
[epoch11, step32]: loss 0.036777
[epoch11, step33]: loss 0.039378
[epoch11, step34]: loss 0.037202
[epoch11, step35]: loss 0.039263
[epoch11, step36]: loss 0.035668
[epoch11, step37]: loss 0.036662
[epoch11, step38]: loss 0.038881
[epoch11, step39]: loss 0.038784
[epoch11, step40]: loss 0.036184
[epoch11, step41]: loss 0.035533
[epoch11, step42]: loss 0.039058
[epoch11, step43]: loss 0.036322
[epoch11, step44]: loss 0.039293
[epoch11, step45]: loss 0.035879
[epoch11, step46]: loss 0.036737
[epoch11, step47]: loss 0.038257
[epoch11, step48]: loss 0.038286
[epoch11, step49]: loss 0.034269
[epoch11, step50]: loss 0.036219
[epoch11, step51]: loss 0.038555
[epoch11, step52]: loss 0.036272
[epoch11, step53]: loss 0.039331
[epoch11, step54]: loss 0.035581
[epoch11, step55]: loss 0.037128
[epoch11, step56]: loss 0.039645
[epoch11, step57]: loss 0.039202
[epoch11, step58]: loss 0.035804
[epoch11, step59]: loss 0.035183
[epoch11, step60]: loss 0.039306
[epoch11, step61]: loss 0.035643
[epoch11, step62]: loss 0.038322
[epoch11, step63]: loss 0.035220
[epoch11, step64]: loss 0.036228
[epoch11, step65]: loss 0.038913
[epoch11, step66]: loss 0.038670
[epoch11, step67]: loss 0.035977
[epoch11, step68]: loss 0.036081
[epoch11, step69]: loss 0.038651
[epoch11, step70]: loss 0.036196
[epoch11, step71]: loss 0.038460
[epoch11, step72]: loss 0.035776
[epoch11, step73]: loss 0.036590
[epoch11, step74]: loss 0.038627
[epoch11, step75]: loss 0.039098
[epoch11, step76]: loss 0.036371
[epoch11, step77]: loss 0.036721
[epoch11, step78]: loss 0.038941
[epoch11, step79]: loss 0.035796
[epoch11, step80]: loss 0.039583
[epoch11, step81]: loss 0.035868
[epoch11, step82]: loss 0.036143
[epoch11, step83]: loss 0.038360
[epoch11, step84]: loss 0.038904
[epoch11, step85]: loss 0.036554
[epoch11, step86]: loss 0.036584
[epoch11, step87]: loss 0.039763
[epoch11, step88]: loss 0.035293
[epoch11, step89]: loss 0.038660
[epoch11, step90]: loss 0.036298
[epoch11, step91]: loss 0.036074
[epoch11, step92]: loss 0.038937
[epoch11, step93]: loss 0.038764
[epoch11, step94]: loss 0.035630
[epoch11, step95]: loss 0.036557
[epoch11, step96]: loss 0.038447
[epoch11, step97]: loss 0.036997
[epoch11, step98]: loss 0.038938
[epoch11, step99]: loss 0.035862
[epoch11, step100]: loss 0.035428
[epoch11, step101]: loss 0.039371
[epoch11, step102]: loss 0.038618
[epoch11, step103]: loss 0.035724
[epoch11, step104]: loss 0.036173
[epoch11, step105]: loss 0.039036
[epoch11, step106]: loss 0.036428
[epoch11, step107]: loss 0.038965
[epoch11, step108]: loss 0.036210
[epoch11, step109]: loss 0.036248
[epoch11, step110]: loss 0.039346
[epoch11, step111]: loss 0.038540
[epoch11, step112]: loss 0.035995
[epoch11, step113]: loss 0.036985
[epoch11, step114]: loss 0.038529
[epoch11, step115]: loss 0.036290
[epoch11, step116]: loss 0.039835
[epoch11, step117]: loss 0.035726
[epoch11, step118]: loss 0.037295
[epoch11, step119]: loss 0.039275
[epoch11, step120]: loss 0.039036
[epoch11, step121]: loss 0.035767
[epoch11, step122]: loss 0.036064
[epoch11, step123]: loss 0.039239
[epoch11, step124]: loss 0.036760
[epoch11, step125]: loss 0.039250
[epoch11, step126]: loss 0.035842
[epoch11, step127]: loss 0.036214
[epoch11, step128]: loss 0.038712
[epoch11, step129]: loss 0.038672
[epoch11, step130]: loss 0.036159
[epoch11, step131]: loss 0.035636
[epoch11, step132]: loss 0.038849
[epoch11, step133]: loss 0.036236
[epoch11, step134]: loss 0.038243
[epoch11, step135]: loss 0.036448
[epoch11, step136]: loss 0.037621
[epoch11, step137]: loss 0.038527
[epoch11, step138]: loss 0.038734
[epoch11, step139]: loss 0.035780
[epoch11, step140]: loss 0.036663
[epoch11, step141]: loss 0.039144
[epoch11, step142]: loss 0.036289
[epoch11, step143]: loss 0.038395
[epoch11, step144]: loss 0.036123
[epoch11, step145]: loss 0.036490
[epoch11, step146]: loss 0.038873
[epoch11, step147]: loss 0.040080
[epoch11, step148]: loss 0.035558
[epoch11, step149]: loss 0.035731
[epoch11, step150]: loss 0.038652
[epoch11, step151]: loss 0.036357
[epoch11, step152]: loss 0.038714
[epoch11, step153]: loss 0.035986
[epoch11, step154]: loss 0.036214
[epoch11, step155]: loss 0.038658
[epoch11, step156]: loss 0.038314
[epoch11, step157]: loss 0.035958
[epoch11, step158]: loss 0.036440
[epoch11, step159]: loss 0.038976
[epoch11, step160]: loss 0.036596
[epoch11, step161]: loss 0.039338
[epoch11, step162]: loss 0.036160
[epoch11, step163]: loss 0.036479
[epoch11, step164]: loss 0.039013
[epoch11, step165]: loss 0.038770
[epoch11, step166]: loss 0.036208
[epoch11, step167]: loss 0.035777
[epoch11, step168]: loss 0.039533
[epoch11, step169]: loss 0.036070
[epoch11, step170]: loss 0.039184
[epoch11, step171]: loss 0.036295
[epoch11, step172]: loss 0.036683
[epoch11, step173]: loss 0.039088
[epoch11, step174]: loss 0.038589
[epoch11, step175]: loss 0.036607
[epoch11, step176]: loss 0.036425
[epoch11, step177]: loss 0.039225
[epoch11, step178]: loss 0.036284
[epoch11, step179]: loss 0.038064
[epoch11, step180]: loss 0.036176
[epoch11, step181]: loss 0.036637
[epoch11, step182]: loss 0.039203
[epoch11, step183]: loss 0.039448
[epoch11, step184]: loss 0.036901
[epoch11, step185]: loss 0.036454
[epoch11, step186]: loss 0.039064
[epoch11, step187]: loss 0.036513
[epoch11, step188]: loss 0.038617
[epoch11, step189]: loss 0.035924
[epoch11, step190]: loss 0.035841
[epoch11, step191]: loss 0.038793
[epoch11, step192]: loss 0.039452
[epoch11, step193]: loss 0.034155
[epoch11, step194]: loss 0.035375
[epoch11, step195]: loss 0.039209
[epoch11, step196]: loss 0.036445
[epoch11, step197]: loss 0.038725
[epoch11, step198]: loss 0.035122
[epoch11, step199]: loss 0.036588
[epoch11, step200]: loss 0.039301
[epoch11, step201]: loss 0.039279
[epoch11, step202]: loss 0.035535
[epoch11, step203]: loss 0.036245
[epoch11, step204]: loss 0.039438
[epoch11, step205]: loss 0.035869
[epoch11, step206]: loss 0.038561
[epoch11, step207]: loss 0.035811
[epoch11, step208]: loss 0.036997
[epoch11, step209]: loss 0.039157
[epoch11, step210]: loss 0.039752
[epoch11, step211]: loss 0.036565
[epoch11, step212]: loss 0.036639
[epoch11, step213]: loss 0.038569
[epoch11, step214]: loss 0.035708
[epoch11, step215]: loss 0.039117
[epoch11, step216]: loss 0.036227
[epoch11, step217]: loss 0.035742
[epoch11, step218]: loss 0.039157
[epoch11, step219]: loss 0.038638
[epoch11, step220]: loss 0.036263
[epoch11, step221]: loss 0.036485
[epoch11, step222]: loss 0.039316
[epoch11, step223]: loss 0.036532
[epoch11, step224]: loss 0.038463
[epoch11, step225]: loss 0.035936
[epoch11, step226]: loss 0.036259
[epoch11, step227]: loss 0.037904
[epoch11, step228]: loss 0.039507
[epoch11, step229]: loss 0.035112
[epoch11, step230]: loss 0.036593
[epoch11, step231]: loss 0.039479
[epoch11, step232]: loss 0.036121
[epoch11, step233]: loss 0.038175
[epoch11, step234]: loss 0.035509
[epoch11, step235]: loss 0.036813
[epoch11, step236]: loss 0.038842
[epoch11, step237]: loss 0.038917
[epoch11, step238]: loss 0.035722
[epoch11, step239]: loss 0.035507
[epoch11, step240]: loss 0.038426
[epoch11, step241]: loss 0.036731
[epoch11, step242]: loss 0.038705
[epoch11, step243]: loss 0.036721
[epoch11, step244]: loss 0.036295
[epoch11, step245]: loss 0.038399
[epoch11, step246]: loss 0.038859
[epoch11, step247]: loss 0.036251
[epoch11, step248]: loss 0.035850
[epoch11, step249]: loss 0.038386
[epoch11, step250]: loss 0.036707
[epoch11, step251]: loss 0.039320
[epoch11, step252]: loss 0.036460
[epoch11, step253]: loss 0.036027
[epoch11, step254]: loss 0.038500
[epoch11, step255]: loss 0.039115
[epoch11, step256]: loss 0.035713
[epoch11, step257]: loss 0.035931
[epoch11, step258]: loss 0.039534
[epoch11, step259]: loss 0.036463
[epoch11, step260]: loss 0.038344
[epoch11, step261]: loss 0.036762
[epoch11, step262]: loss 0.036890
[epoch11, step263]: loss 0.038311
[epoch11, step264]: loss 0.038622
[epoch11, step265]: loss 0.036197
[epoch11, step266]: loss 0.036132
[epoch11, step267]: loss 0.038243
[epoch11, step268]: loss 0.036224
[epoch11, step269]: loss 0.038893
[epoch11, step270]: loss 0.035485
[epoch11, step271]: loss 0.036560
[epoch11, step272]: loss 0.038736
[epoch11, step273]: loss 0.038580
[epoch11, step274]: loss 0.036376
[epoch11, step275]: loss 0.035714
[epoch11, step276]: loss 0.038659
[epoch11, step277]: loss 0.036817
[epoch11, step278]: loss 0.038988
[epoch11, step279]: loss 0.035599
[epoch11, step280]: loss 0.036590
[epoch11, step281]: loss 0.038677
[epoch11, step282]: loss 0.039390
[epoch11, step283]: loss 0.035564
[epoch11, step284]: loss 0.035717
[epoch11, step285]: loss 0.039705
[epoch11, step286]: loss 0.035621
[epoch11, step287]: loss 0.039140
[epoch11, step288]: loss 0.035552
[epoch11, step289]: loss 0.037222
[epoch11, step290]: loss 0.038867
[epoch11, step291]: loss 0.039146
[epoch11, step292]: loss 0.035208
[epoch11, step293]: loss 0.035778
[epoch11, step294]: loss 0.038407
[epoch11, step295]: loss 0.035750
[epoch11, step296]: loss 0.039575
[epoch11, step297]: loss 0.035712
[epoch11, step298]: loss 0.036884
[epoch11, step299]: loss 0.037934
[epoch11, step300]: loss 0.039123
[epoch11, step301]: loss 0.035939
[epoch11, step302]: loss 0.036530
[epoch11, step303]: loss 0.039231
[epoch11, step304]: loss 0.036163
[epoch11, step305]: loss 0.038692
[epoch11, step306]: loss 0.036079
[epoch11, step307]: loss 0.036252
[epoch11, step308]: loss 0.039318
[epoch11, step309]: loss 0.039182
[epoch11, step310]: loss 0.036146
[epoch11, step311]: loss 0.036590
[epoch11, step312]: loss 0.038620
[epoch11, step313]: loss 0.036658
[epoch11, step314]: loss 0.038743
[epoch11, step315]: loss 0.036930
[epoch11, step316]: loss 0.036150
[epoch11, step317]: loss 0.039240
[epoch11, step318]: loss 0.038882
[epoch11, step319]: loss 0.035412
[epoch11, step320]: loss 0.035234
[epoch11, step321]: loss 0.038455
[epoch11, step322]: loss 0.036184
[epoch11, step323]: loss 0.038183
[epoch11, step324]: loss 0.036789
[epoch11, step325]: loss 0.036645
[epoch11, step326]: loss 0.038532
[epoch11, step327]: loss 0.038222
[epoch11, step328]: loss 0.036141
[epoch11, step329]: loss 0.035914
[epoch11, step330]: loss 0.038387
[epoch11, step331]: loss 0.036489
[epoch11, step332]: loss 0.038221
[epoch11, step333]: loss 0.035898
[epoch11, step334]: loss 0.036522
[epoch11, step335]: loss 0.038892
[epoch11, step336]: loss 0.039653
[epoch11, step337]: loss 0.036396
[epoch11, step338]: loss 0.035698
[epoch11, step339]: loss 0.038875
[epoch11, step340]: loss 0.036841
[epoch11, step341]: loss 0.038264
[epoch11, step342]: loss 0.035649
[epoch11, step343]: loss 0.036643
[epoch11, step344]: loss 0.038288
[epoch11, step345]: loss 0.038145
[epoch11, step346]: loss 0.035476
[epoch11, step347]: loss 0.035792
[epoch11, step348]: loss 0.039044
[epoch11, step349]: loss 0.036809
[epoch11, step350]: loss 0.038336
[epoch11, step351]: loss 0.035177
[epoch11, step352]: loss 0.036264
[epoch11, step353]: loss 0.038596
[epoch11, step354]: loss 0.037863
[epoch11, step355]: loss 0.034875
[epoch11, step356]: loss 0.036675
[epoch11, step357]: loss 0.038925
[epoch11, step358]: loss 0.034781
[epoch11, step359]: loss 0.039637
[epoch11, step360]: loss 0.034697
[epoch11, step361]: loss 0.035860
[epoch11, step362]: loss 0.039363
[epoch11, step363]: loss 0.038490
[epoch11, step364]: loss 0.035788
[epoch11, step365]: loss 0.035862
[epoch11, step366]: loss 0.039205
[epoch11, step367]: loss 0.036321
[epoch11, step368]: loss 0.038152
[epoch11, step369]: loss 0.035772
[epoch11, step370]: loss 0.036948
[epoch11, step371]: loss 0.039487
[epoch11, step372]: loss 0.038453
[epoch11, step373]: loss 0.035388
[epoch11, step374]: loss 0.035339
[epoch11, step375]: loss 0.039500
[epoch11, step376]: loss 0.036276
[epoch11, step377]: loss 0.038911
[epoch11, step378]: loss 0.036347
[epoch11, step379]: loss 0.037004
[epoch11, step380]: loss 0.039298
[epoch11, step381]: loss 0.038484
[epoch11, step382]: loss 0.036174
[epoch11, step383]: loss 0.035084
[epoch11, step384]: loss 0.038073
[epoch11, step385]: loss 0.036067
[epoch11, step386]: loss 0.038924
[epoch11, step387]: loss 0.035923
[epoch11, step388]: loss 0.037376
[epoch11, step389]: loss 0.038721
[epoch11, step390]: loss 0.039810
[epoch11, step391]: loss 0.035476
[epoch11, step392]: loss 0.036613
[epoch11, step393]: loss 0.038349
[epoch11, step394]: loss 0.036278
[epoch11, step395]: loss 0.038472
[epoch11, step396]: loss 0.036023
[epoch11, step397]: loss 0.036032
[epoch11, step398]: loss 0.038873
[epoch11, step399]: loss 0.038714
[epoch11, step400]: loss 0.035522
[epoch11, step401]: loss 0.035911
[epoch11, step402]: loss 0.038766
[epoch11, step403]: loss 0.036205
[epoch11, step404]: loss 0.039262
[epoch11, step405]: loss 0.036226
[epoch11, step406]: loss 0.036670
[epoch11, step407]: loss 0.038554
[epoch11, step408]: loss 0.038913
[epoch11, step409]: loss 0.037224
[epoch11, step410]: loss 0.036718
[epoch11, step411]: loss 0.038694
[epoch11, step412]: loss 0.035708
[epoch11, step413]: loss 0.038669
[epoch11, step414]: loss 0.035620
[epoch11, step415]: loss 0.036577
[epoch11, step416]: loss 0.038076
[epoch11, step417]: loss 0.039001
[epoch11, step418]: loss 0.035782
[epoch11, step419]: loss 0.035289
[epoch11, step420]: loss 0.039020
[epoch11, step421]: loss 0.035973
[epoch11, step422]: loss 0.038694
[epoch11, step423]: loss 0.035971
[epoch11, step424]: loss 0.036566
[epoch11, step425]: loss 0.038872
[epoch11, step426]: loss 0.039154
[epoch11, step427]: loss 0.036204
[epoch11, step428]: loss 0.035949
[epoch11, step429]: loss 0.039446
[epoch11, step430]: loss 0.036167
[epoch11, step431]: loss 0.039082
[epoch11, step432]: loss 0.035753
[epoch11, step433]: loss 0.037213
[epoch11, step434]: loss 0.038607
[epoch11, step435]: loss 0.039180
[epoch11, step436]: loss 0.035604
[epoch11, step437]: loss 0.036203
[epoch11, step438]: loss 0.039416
[epoch11, step439]: loss 0.036450
[epoch11, step440]: loss 0.038732
[epoch11, step441]: loss 0.036138
[epoch11, step442]: loss 0.036338
[epoch11, step443]: loss 0.039201
[epoch11, step444]: loss 0.038536
[epoch11, step445]: loss 0.036302
[epoch11, step446]: loss 0.036472
[epoch11, step447]: loss 0.039490
[epoch11, step448]: loss 0.036378
[epoch11, step449]: loss 0.038624
[epoch11, step450]: loss 0.035291
[epoch11, step451]: loss 0.036295
[epoch11, step452]: loss 0.037965
[epoch11, step453]: loss 0.038951
[epoch11, step454]: loss 0.035830
[epoch11, step455]: loss 0.036227
[epoch11, step456]: loss 0.038123
[epoch11, step457]: loss 0.036900
[epoch11, step458]: loss 0.038494
[epoch11, step459]: loss 0.036678
[epoch11, step460]: loss 0.036567
[epoch11, step461]: loss 0.039467
[epoch11, step462]: loss 0.038178
[epoch11, step463]: loss 0.036011
[epoch11, step464]: loss 0.035930
[epoch11, step465]: loss 0.040215
[epoch11, step466]: loss 0.036278
[epoch11, step467]: loss 0.038666
[epoch11, step468]: loss 0.035956
[epoch11, step469]: loss 0.036603
[epoch11, step470]: loss 0.038967
[epoch11, step471]: loss 0.038337
[epoch11, step472]: loss 0.036398
[epoch11, step473]: loss 0.035656
[epoch11, step474]: loss 0.038745
[epoch11, step475]: loss 0.036342
[epoch11, step476]: loss 0.039126
[epoch11, step477]: loss 0.035715
[epoch11, step478]: loss 0.035790
[epoch11, step479]: loss 0.038631
[epoch11, step480]: loss 0.038107
[epoch11, step481]: loss 0.035498
[epoch11, step482]: loss 0.035475
[epoch11, step483]: loss 0.039244
[epoch11, step484]: loss 0.036395
[epoch11, step485]: loss 0.038935
[epoch11, step486]: loss 0.036293
[epoch11, step487]: loss 0.035863
[epoch11, step488]: loss 0.039144
[epoch11, step489]: loss 0.038084
[epoch11, step490]: loss 0.036283
[epoch11, step491]: loss 0.036289
[epoch11, step492]: loss 0.038480
[epoch11, step493]: loss 0.035967
[epoch11, step494]: loss 0.038166
[epoch11, step495]: loss 0.037024
[epoch11, step496]: loss 0.036615
[epoch11, step497]: loss 0.039003
[epoch11, step498]: loss 0.038779
[epoch11, step499]: loss 0.036191
[epoch11, step500]: loss 0.035549
[epoch11, step501]: loss 0.038358
[epoch11, step502]: loss 0.036004
[epoch11, step503]: loss 0.038962
[epoch11, step504]: loss 0.035641
[epoch11, step505]: loss 0.035527
[epoch11, step506]: loss 0.039137
[epoch11, step507]: loss 0.039165
[epoch11, step508]: loss 0.036361
[epoch11, step509]: loss 0.035964
[epoch11, step510]: loss 0.039016
[epoch11, step511]: loss 0.036656
[epoch11, step512]: loss 0.039145
[epoch11, step513]: loss 0.036136
[epoch11, step514]: loss 0.036736
[epoch11, step515]: loss 0.038744
[epoch11, step516]: loss 0.039258
[epoch11, step517]: loss 0.035958
[epoch11, step518]: loss 0.036142
[epoch11, step519]: loss 0.038943
[epoch11, step520]: loss 0.035626
[epoch11, step521]: loss 0.038592
[epoch11, step522]: loss 0.035533
[epoch11, step523]: loss 0.036394
[epoch11, step524]: loss 0.038023
[epoch11, step525]: loss 0.039113
[epoch11, step526]: loss 0.036009
[epoch11, step527]: loss 0.035697
[epoch11, step528]: loss 0.039009
[epoch11, step529]: loss 0.035737
[epoch11, step530]: loss 0.039102
[epoch11, step531]: loss 0.035674
[epoch11, step532]: loss 0.036125
[epoch11, step533]: loss 0.039672
[epoch11, step534]: loss 0.038695
[epoch11, step535]: loss 0.036528
[epoch11, step536]: loss 0.036227
[epoch11, step537]: loss 0.038936
[epoch11, step538]: loss 0.036276
[epoch11, step539]: loss 0.038530
[epoch11, step540]: loss 0.035528
[epoch11, step541]: loss 0.035938
[epoch11, step542]: loss 0.038716
[epoch11, step543]: loss 0.038544
[epoch11, step544]: loss 0.035826
[epoch11, step545]: loss 0.035243
[epoch11, step546]: loss 0.039348
[epoch11, step547]: loss 0.036126
[epoch11, step548]: loss 0.038764
[epoch11, step549]: loss 0.036176
[epoch11, step550]: loss 0.036424
[epoch11, step551]: loss 0.038584
[epoch11, step552]: loss 0.038172
[epoch11, step553]: loss 0.036352
[epoch11, step554]: loss 0.035837
[epoch11, step555]: loss 0.038478
[epoch11, step556]: loss 0.035955
[epoch11, step557]: loss 0.038144
[epoch11, step558]: loss 0.036123
[epoch11, step559]: loss 0.035821
[epoch11, step560]: loss 0.038859
[epoch11, step561]: loss 0.038563
[epoch11, step562]: loss 0.035859
[epoch11, step563]: loss 0.029213
[epoch11, step564]: loss 0.029098
[epoch11, step565]: loss 0.027913
[epoch11, step566]: loss 0.035119
[epoch11, step567]: loss 0.027148
[epoch11, step568]: loss 0.026205
[epoch11, step569]: loss 0.023735
[epoch11, step570]: loss 0.031830
[epoch11, step571]: loss 0.027322
[epoch11, step572]: loss 0.026238
[epoch11, step573]: loss 0.029183
[epoch11, step574]: loss 0.027727
[epoch11, step575]: loss 0.021299
[epoch11, step576]: loss 0.021899
[epoch11, step577]: loss 0.026261
[epoch11, step578]: loss 0.018724
[epoch11, step579]: loss 0.028939
[epoch11, step580]: loss 0.020301
[epoch11, step581]: loss 0.026608
[epoch11, step582]: loss 0.025502
[epoch11, step583]: loss 0.022384
[epoch11, step584]: loss 0.023896
[epoch11, step585]: loss 0.026621
[epoch11, step586]: loss 0.021696
[epoch11, step587]: loss 0.027889
[epoch11, step588]: loss 0.023286
[epoch11, step589]: loss 0.022775
[epoch11, step590]: loss 0.027510
[epoch11, step591]: loss 0.020559
[epoch11, step592]: loss 0.025841
[epoch11, step593]: loss 0.021704
[epoch11, step594]: loss 0.026291
[epoch11, step595]: loss 0.026234
[epoch11, step596]: loss 0.022259
[epoch11, step597]: loss 0.024884
[epoch11, step598]: loss 0.026546
[epoch11, step599]: loss 0.024991
[epoch11, step600]: loss 0.027133
[epoch11, step601]: loss 0.019568
[epoch11, step602]: loss 0.022498
[epoch11, step603]: loss 0.025533
[epoch11, step604]: loss 0.026104
[epoch11, step605]: loss 0.025034
[epoch11, step606]: loss 0.025173
[epoch11, step607]: loss 0.026370
[epoch11, step608]: loss 0.025748
[epoch11, step609]: loss 0.026126
[epoch11, step610]: loss 0.026385
[epoch11, step611]: loss 0.026361
[epoch11, step612]: loss 0.025272
[epoch11, step613]: loss 0.019143
[epoch11, step614]: loss 0.024875
[epoch11, step615]: loss 0.027831
[epoch11, step616]: loss 0.023918
[epoch11, step617]: loss 0.023157
[epoch11, step618]: loss 0.025722
[epoch11, step619]: loss 0.027231
[epoch11, step620]: loss 0.024231
[epoch11, step621]: loss 0.026250
[epoch11, step622]: loss 0.020331
[epoch11, step623]: loss 0.024633
[epoch11, step624]: loss 0.026296
[epoch11, step625]: loss 0.025800
[epoch11, step626]: loss 0.028039
[epoch11, step627]: loss 0.022551
[epoch11, step628]: loss 0.025187
[epoch11, step629]: loss 0.020672
[epoch11, step630]: loss 0.023408
[epoch11, step631]: loss 0.031347
[epoch11, step632]: loss 0.023111
[epoch11, step633]: loss 0.024505
[epoch11, step634]: loss 0.027181
[epoch11, step635]: loss 0.025563
[epoch11, step636]: loss 0.020765
[epoch11, step637]: loss 0.027178
[epoch11, step638]: loss 0.026873
[epoch11, step639]: loss 0.023065
[epoch11, step640]: loss 0.029062
[epoch11, step641]: loss 0.030300
[epoch11, step642]: loss 0.024806
[epoch11, step643]: loss 0.025561
[epoch11, step644]: loss 0.025652
[epoch11, step645]: loss 0.023498
[epoch11, step646]: loss 0.025870
[epoch11, step647]: loss 0.023582
[epoch11, step648]: loss 0.022823
[epoch11, step649]: loss 0.028504
[epoch11, step650]: loss 0.021857
[epoch11, step651]: loss 0.025769
[epoch11, step652]: loss 0.026675
[epoch11, step653]: loss 0.027660
[epoch11, step654]: loss 0.022953
[epoch11, step655]: loss 0.024241
[epoch11, step656]: loss 0.021435
[epoch11, step657]: loss 0.027201
[epoch11, step658]: loss 0.025081
[epoch11, step659]: loss 0.027513
[epoch11, step660]: loss 0.023854
[epoch11, step661]: loss 0.026222
[epoch11, step662]: loss 0.023901
[epoch11, step663]: loss 0.020844
[epoch11, step664]: loss 0.024966
[epoch11, step665]: loss 0.028149
[epoch11, step666]: loss 0.026666
[epoch11, step667]: loss 0.026455
[epoch11, step668]: loss 0.022087
[epoch11, step669]: loss 0.026371
[epoch11, step670]: loss 0.026619
[epoch11, step671]: loss 0.021391
[epoch11, step672]: loss 0.023491
[epoch11, step673]: loss 0.022097
[epoch11, step674]: loss 0.021242
[epoch11, step675]: loss 0.020039
[epoch11, step676]: loss 0.024444
[epoch11, step677]: loss 0.025043
[epoch11, step678]: loss 0.023050
[epoch11, step679]: loss 0.023682
[epoch11, step680]: loss 0.030442
[epoch11, step681]: loss 0.021901
[epoch11, step682]: loss 0.026001
[epoch11, step683]: loss 0.025626
[epoch11, step684]: loss 0.024769
[epoch11, step685]: loss 0.024374
[epoch11, step686]: loss 0.027214
[epoch11, step687]: loss 0.026672
[epoch11, step688]: loss 0.022487
[epoch11, step689]: loss 0.024530
[epoch11, step690]: loss 0.025017
[epoch11, step691]: loss 0.024123
[epoch11, step692]: loss 0.022593
[epoch11, step693]: loss 0.027324
[epoch11, step694]: loss 0.022731
[epoch11, step695]: loss 0.026345
[epoch11, step696]: loss 0.025978
[epoch11, step697]: loss 0.026622
[epoch11, step698]: loss 0.024736
[epoch11, step699]: loss 0.023492
[epoch11, step700]: loss 0.021673
[epoch11, step701]: loss 0.025886
[epoch11, step702]: loss 0.021619
[epoch11, step703]: loss 0.022838
[epoch11, step704]: loss 0.025240
[epoch11, step705]: loss 0.024802
[epoch11, step706]: loss 0.023697
[epoch11, step707]: loss 0.024583
[epoch11, step708]: loss 0.026347
[epoch11, step709]: loss 0.027161
[epoch11, step710]: loss 0.023595
[epoch11, step711]: loss 0.023244
[epoch11, step712]: loss 0.026812
[epoch11, step713]: loss 0.026242
[epoch11, step714]: loss 0.021317
[epoch11, step715]: loss 0.023173
[epoch11, step716]: loss 0.025770
[epoch11, step717]: loss 0.023619
[epoch11, step718]: loss 0.025045
[epoch11, step719]: loss 0.032963
[epoch11, step720]: loss 0.024675
[epoch11, step721]: loss 0.023023
[epoch11, step722]: loss 0.030454
[epoch11, step723]: loss 0.025830
[epoch11, step724]: loss 0.022858
[epoch11, step725]: loss 0.027648
[epoch11, step726]: loss 0.022333
[epoch11, step727]: loss 0.024575
[epoch11, step728]: loss 0.026257
[epoch11, step729]: loss 0.021220
[epoch11, step730]: loss 0.022612
[epoch11, step731]: loss 0.025656
[epoch11, step732]: loss 0.025682
[epoch11, step733]: loss 0.023808
[epoch11, step734]: loss 0.022610
[epoch11, step735]: loss 0.027335
[epoch11, step736]: loss 0.024995
[epoch11, step737]: loss 0.026706
[epoch11, step738]: loss 0.020642
[epoch11, step739]: loss 0.025453
[epoch11, step740]: loss 0.022245
[epoch11, step741]: loss 0.025054
[epoch11, step742]: loss 0.021634
[epoch11, step743]: loss 0.023314
[epoch11, step744]: loss 0.024066
[epoch11, step745]: loss 0.024534
[epoch11, step746]: loss 0.025000
[epoch11, step747]: loss 0.027293
[epoch11, step748]: loss 0.025513
[epoch11, step749]: loss 0.026039
[epoch11, step750]: loss 0.027395
[epoch11, step751]: loss 0.021552
[epoch11, step752]: loss 0.025053
[epoch11, step753]: loss 0.025723
[epoch11, step754]: loss 0.022557
[epoch11, step755]: loss 0.025897
[epoch11, step756]: loss 0.023321
[epoch11, step757]: loss 0.020452
[epoch11, step758]: loss 0.025420
[epoch11, step759]: loss 0.022824
[epoch11, step760]: loss 0.023843
[epoch11, step761]: loss 0.026228
[epoch11, step762]: loss 0.021445
[epoch11, step763]: loss 0.025316
[epoch11, step764]: loss 0.023426
[epoch11, step765]: loss 0.026002
[epoch11, step766]: loss 0.024473
[epoch11, step767]: loss 0.026298
[epoch11, step768]: loss 0.021468
[epoch11, step769]: loss 0.026536
[epoch11, step770]: loss 0.025587
[epoch11, step771]: loss 0.023382
[epoch11, step772]: loss 0.028514
[epoch11, step773]: loss 0.026537
[epoch11, step774]: loss 0.024251
[epoch11, step775]: loss 0.020545
[epoch11, step776]: loss 0.025456
[epoch11, step777]: loss 0.022953
[epoch11, step778]: loss 0.028197
[epoch11, step779]: loss 0.023765
[epoch11, step780]: loss 0.020031
[epoch11, step781]: loss 0.024312
[epoch11, step782]: loss 0.022576
[epoch11, step783]: loss 0.019165
[epoch11, step784]: loss 0.020111
[epoch11, step785]: loss 0.021434
[epoch11, step786]: loss 0.024118
[epoch11, step787]: loss 0.023090
[epoch11, step788]: loss 0.024566
[epoch11, step789]: loss 0.022430
[epoch11, step790]: loss 0.023167
[epoch11, step791]: loss 0.026581
[epoch11, step792]: loss 0.024995
[epoch11, step793]: loss 0.026732
[epoch11, step794]: loss 0.020343
[epoch11, step795]: loss 0.025481
[epoch11, step796]: loss 0.027746
[epoch11, step797]: loss 0.027657
[epoch11, step798]: loss 0.027082
[epoch11, step799]: loss 0.025847
[epoch11, step800]: loss 0.021229
[epoch11, step801]: loss 0.021545
[epoch11, step802]: loss 0.022665
[epoch11, step803]: loss 0.026058
[epoch11, step804]: loss 0.027106
[epoch11, step805]: loss 0.027947
[epoch11, step806]: loss 0.021256
[epoch11, step807]: loss 0.020527
[epoch11, step808]: loss 0.022980
[epoch11, step809]: loss 0.022988
[epoch11, step810]: loss 0.025895
[epoch11, step811]: loss 0.025487
[epoch11, step812]: loss 0.024562
[epoch11, step813]: loss 0.023483
[epoch11, step814]: loss 0.025014
[epoch11, step815]: loss 0.024898
[epoch11, step816]: loss 0.024062
[epoch11, step817]: loss 0.024744
[epoch11, step818]: loss 0.022577
[epoch11, step819]: loss 0.019917
[epoch11, step820]: loss 0.023504
[epoch11, step821]: loss 0.021657
[epoch11, step822]: loss 0.030301
[epoch11, step823]: loss 0.023894
[epoch11, step824]: loss 0.026635
[epoch11, step825]: loss 0.025088
[epoch11, step826]: loss 0.024384
[epoch11, step827]: loss 0.026764
[epoch11, step828]: loss 0.028879
[epoch11, step829]: loss 0.026307
[epoch11, step830]: loss 0.022423
[epoch11, step831]: loss 0.026306
[epoch11, step832]: loss 0.020997
[epoch11, step833]: loss 0.028964
[epoch11, step834]: loss 0.025265
[epoch11, step835]: loss 0.020682
[epoch11, step836]: loss 0.026905
[epoch11, step837]: loss 0.025787
[epoch11, step838]: loss 0.026222
[epoch11, step839]: loss 0.028258
[epoch11, step840]: loss 0.020642
[epoch11, step841]: loss 0.024246
[epoch11, step842]: loss 0.027519
[epoch11, step843]: loss 0.024866
[epoch11, step844]: loss 0.025034
[epoch11, step845]: loss 0.021015
[epoch11, step846]: loss 0.025408
[epoch11, step847]: loss 0.026628
[epoch11, step848]: loss 0.025019
[epoch11, step849]: loss 0.025072
[epoch11, step850]: loss 0.022920
[epoch11, step851]: loss 0.023890
[epoch11, step852]: loss 0.023225
[epoch11, step853]: loss 0.029050
[epoch11, step854]: loss 0.022656
[epoch11, step855]: loss 0.027173
[epoch11, step856]: loss 0.022189
[epoch11, step857]: loss 0.025464
[epoch11, step858]: loss 0.024186
[epoch11, step859]: loss 0.023495
[epoch11, step860]: loss 0.022493
[epoch11, step861]: loss 0.023049
[epoch11, step862]: loss 0.022985
[epoch11, step863]: loss 0.020473
[epoch11, step864]: loss 0.026270
[epoch11, step865]: loss 0.023282
[epoch11, step866]: loss 0.025018
[epoch11, step867]: loss 0.026125
[epoch11, step868]: loss 0.026642
[epoch11, step869]: loss 0.023818
[epoch11, step870]: loss 0.030834
[epoch11, step871]: loss 0.021977
[epoch11, step872]: loss 0.025173
[epoch11, step873]: loss 0.025680
[epoch11, step874]: loss 0.023716
[epoch11, step875]: loss 0.024102
[epoch11, step876]: loss 0.024045
[epoch11, step877]: loss 0.019063
[epoch11, step878]: loss 0.023301
[epoch11, step879]: loss 0.027688
[epoch11, step880]: loss 0.025468
[epoch11, step881]: loss 0.022178
[epoch11, step882]: loss 0.023999
[epoch11, step883]: loss 0.023939
[epoch11, step884]: loss 0.026390
[epoch11, step885]: loss 0.025923
[epoch11, step886]: loss 0.026463
[epoch11, step887]: loss 0.024216
[epoch11, step888]: loss 0.024625
[epoch11, step889]: loss 0.023431
[epoch11, step890]: loss 0.023530
[epoch11, step891]: loss 0.025381
[epoch11, step892]: loss 0.020833
[epoch11, step893]: loss 0.024674
[epoch11, step894]: loss 0.024842
[epoch11, step895]: loss 0.022500
[epoch11, step896]: loss 0.021746
[epoch11, step897]: loss 0.023779
[epoch11, step898]: loss 0.025464
[epoch11, step899]: loss 0.028006
[epoch11, step900]: loss 0.026859
[epoch11, step901]: loss 0.025305
[epoch11, step902]: loss 0.023958
[epoch11, step903]: loss 0.024002
[epoch11, step904]: loss 0.027869
[epoch11, step905]: loss 0.027444
[epoch11, step906]: loss 0.022397
[epoch11, step907]: loss 0.023692
[epoch11, step908]: loss 0.022400
[epoch11, step909]: loss 0.025305
[epoch11, step910]: loss 0.022998
[epoch11, step911]: loss 0.025268
[epoch11, step912]: loss 0.023729
[epoch11, step913]: loss 0.024036
[epoch11, step914]: loss 0.030295
[epoch11, step915]: loss 0.023936
[epoch11, step916]: loss 0.023752
[epoch11, step917]: loss 0.024939
[epoch11, step918]: loss 0.028462
[epoch11, step919]: loss 0.024269
[epoch11, step920]: loss 0.027463
[epoch11, step921]: loss 0.024448
[epoch11, step922]: loss 0.023168
[epoch11, step923]: loss 0.022545
[epoch11, step924]: loss 0.021159
[epoch11, step925]: loss 0.025207
[epoch11, step926]: loss 0.026429
[epoch11, step927]: loss 0.025506
[epoch11, step928]: loss 0.024791
[epoch11, step929]: loss 0.027669
[epoch11, step930]: loss 0.025500
[epoch11, step931]: loss 0.027091
[epoch11, step932]: loss 0.021584
[epoch11, step933]: loss 0.028055
[epoch11, step934]: loss 0.022030
[epoch11, step935]: loss 0.021901
[epoch11, step936]: loss 0.022311
[epoch11, step937]: loss 0.027056
[epoch11, step938]: loss 0.025128
[epoch11, step939]: loss 0.020642
[epoch11, step940]: loss 0.022796
[epoch11, step941]: loss 0.026570
[epoch11, step942]: loss 0.025329
[epoch11, step943]: loss 0.023008
[epoch11, step944]: loss 0.027464
[epoch11, step945]: loss 0.020476
[epoch11, step946]: loss 0.025390
[epoch11, step947]: loss 0.028015
[epoch11, step948]: loss 0.019339
[epoch11, step949]: loss 0.022815
[epoch11, step950]: loss 0.026497
[epoch11, step951]: loss 0.028674
[epoch11, step952]: loss 0.024992
[epoch11, step953]: loss 0.027506
[epoch11, step954]: loss 0.022315
[epoch11, step955]: loss 0.036711
[epoch11, step956]: loss 0.051872
[epoch11, step957]: loss 0.046474
[epoch11, step958]: loss 0.043762
[epoch11, step959]: loss 0.047381
[epoch11, step960]: loss 0.043474
[epoch11, step961]: loss 0.043088
[epoch11, step962]: loss 0.040838
[epoch11, step963]: loss 0.039728
[epoch11, step964]: loss 0.040469
[epoch11, step965]: loss 0.040416
[epoch11, step966]: loss 0.038998
[epoch11, step967]: loss 0.039209
[epoch11, step968]: loss 0.042098
[epoch11, step969]: loss 0.041372
[epoch11, step970]: loss 0.040569
[epoch11, step971]: loss 0.038848
[epoch11, step972]: loss 0.039853
[epoch11, step973]: loss 0.039258
[epoch11, step974]: loss 0.042231
[epoch11, step975]: loss 0.038968
[epoch11, step976]: loss 0.038050
[epoch11, step977]: loss 0.041983
[epoch11, step978]: loss 0.039648
[epoch11, step979]: loss 0.038046
[epoch11, step980]: loss 0.037114
[epoch11, step981]: loss 0.039194
[epoch11, step982]: loss 0.039390
[epoch11, step983]: loss 0.040118
[epoch11, step984]: loss 0.036277
[epoch11, step985]: loss 0.036744
[epoch11, step986]: loss 0.041131
[epoch11, step987]: loss 0.039444
[epoch11, step988]: loss 0.038443
[epoch11, step989]: loss 0.037646
[epoch11, step990]: loss 0.038465
[epoch11, step991]: loss 0.039359
[epoch11, step992]: loss 0.039449
[epoch11, step993]: loss 0.036754
[epoch11, step994]: loss 0.035806
[epoch11, step995]: loss 0.040058
[epoch11, step996]: loss 0.038204
[epoch11, step997]: loss 0.037775
[epoch11, step998]: loss 0.037418
[epoch11, step999]: loss 0.038539
[epoch11, step1000]: loss 0.038357
[epoch11, step1001]: loss 0.039169
[epoch11, step1002]: loss 0.036869
[epoch11, step1003]: loss 0.035869
[epoch11, step1004]: loss 0.040085
[epoch11, step1005]: loss 0.037372
[epoch11, step1006]: loss 0.037636
[epoch11, step1007]: loss 0.036190
[epoch11, step1008]: loss 0.037503
[epoch11, step1009]: loss 0.038014
[epoch11, step1010]: loss 0.039859
[epoch11, step1011]: loss 0.036382
[epoch11, step1012]: loss 0.036620
[epoch11, step1013]: loss 0.039622
[epoch11, step1014]: loss 0.038463
[epoch11, step1015]: loss 0.037893
[epoch11, step1016]: loss 0.035973
[epoch11, step1017]: loss 0.037337
[epoch11, step1018]: loss 0.037628
[epoch11, step1019]: loss 0.038953
[epoch11, step1020]: loss 0.035989
[epoch11, step1021]: loss 0.035658
[epoch11, step1022]: loss 0.039027
[epoch11, step1023]: loss 0.037655
[epoch11, step1024]: loss 0.037980
[epoch11, step1025]: loss 0.035556
[epoch11, step1026]: loss 0.037176
[epoch11, step1027]: loss 0.037369
[epoch11, step1028]: loss 0.038967
[epoch11, step1029]: loss 0.035942
[epoch11, step1030]: loss 0.035588
[epoch11, step1031]: loss 0.037869
[epoch11, step1032]: loss 0.038112
[epoch11, step1033]: loss 0.037130
[epoch11, step1034]: loss 0.035888
[epoch11, step1035]: loss 0.037052
[epoch11, step1036]: loss 0.037677
[epoch11, step1037]: loss 0.038656
[epoch11, step1038]: loss 0.035826
[epoch11, step1039]: loss 0.035987
[epoch11, step1040]: loss 0.038430
[epoch11, step1041]: loss 0.037244
[epoch11, step1042]: loss 0.036295
[epoch11, step1043]: loss 0.035744
[epoch11, step1044]: loss 0.037545
[epoch11, step1045]: loss 0.037587
[epoch11, step1046]: loss 0.038786
[epoch11, step1047]: loss 0.036104
[epoch11, step1048]: loss 0.035402
[epoch11, step1049]: loss 0.038934
[epoch11, step1050]: loss 0.037914
[epoch11, step1051]: loss 0.037252
[epoch11, step1052]: loss 0.036350
[epoch11, step1053]: loss 0.037745
[epoch11, step1054]: loss 0.037665
[epoch11, step1055]: loss 0.038245
[epoch11, step1056]: loss 0.035405
[epoch11, step1057]: loss 0.036561
[epoch11, step1058]: loss 0.039761
[epoch11, step1059]: loss 0.037814
[epoch11, step1060]: loss 0.037482
[epoch11, step1061]: loss 0.035351
[epoch11, step1062]: loss 0.037878
[epoch11, step1063]: loss 0.037442
[epoch11, step1064]: loss 0.038706
[epoch11, step1065]: loss 0.035879
[epoch11, step1066]: loss 0.035531
[epoch11, step1067]: loss 0.038894
[epoch11, step1068]: loss 0.036285
[epoch11, step1069]: loss 0.036680
[epoch11, step1070]: loss 0.035693
[epoch11, step1071]: loss 0.037942
[epoch11, step1072]: loss 0.038206
[epoch11, step1073]: loss 0.038498
[epoch11, step1074]: loss 0.036122
[epoch11, step1075]: loss 0.036079
[epoch11, step1076]: loss 0.038970
[epoch11, step1077]: loss 0.037439
[epoch11, step1078]: loss 0.036937
[epoch11, step1079]: loss 0.036829
[epoch11, step1080]: loss 0.037578
[epoch11, step1081]: loss 0.037252
[epoch11, step1082]: loss 0.038486
[epoch11, step1083]: loss 0.036625
[epoch11, step1084]: loss 0.036070
[epoch11, step1085]: loss 0.038394
[epoch11, step1086]: loss 0.037150
[epoch11, step1087]: loss 0.037259
[epoch11, step1088]: loss 0.035644
[epoch11, step1089]: loss 0.037836
[epoch11, step1090]: loss 0.038075
[epoch11, step1091]: loss 0.038920
[epoch11, step1092]: loss 0.035729
[epoch11, step1093]: loss 0.035785
[epoch11, step1094]: loss 0.038005
[epoch11, step1095]: loss 0.037000
[epoch11, step1096]: loss 0.036707
[epoch11, step1097]: loss 0.035775
[epoch11, step1098]: loss 0.037439
[epoch11, step1099]: loss 0.037112
[epoch11, step1100]: loss 0.039133
[epoch11, step1101]: loss 0.036280
[epoch11, step1102]: loss 0.035655
[epoch11, step1103]: loss 0.038296
[epoch11, step1104]: loss 0.037315
[epoch11, step1105]: loss 0.037312
[epoch11, step1106]: loss 0.034855
[epoch11, step1107]: loss 0.037694
[epoch11, step1108]: loss 0.037169
[epoch11, step1109]: loss 0.039035
[epoch11, step1110]: loss 0.036602
[epoch11, step1111]: loss 0.036068
[epoch11, step1112]: loss 0.039233
[epoch11, step1113]: loss 0.037139
[epoch11, step1114]: loss 0.037518
[epoch11, step1115]: loss 0.035987
[epoch11, step1116]: loss 0.037589
[epoch11, step1117]: loss 0.037519
[epoch11, step1118]: loss 0.038549
[epoch11, step1119]: loss 0.035815
[epoch11, step1120]: loss 0.035732
[epoch11, step1121]: loss 0.038831
[epoch11, step1122]: loss 0.036961
[epoch11, step1123]: loss 0.036456
[epoch11, step1124]: loss 0.036479
[epoch11, step1125]: loss 0.037855
[epoch11, step1126]: loss 0.038439
[epoch11, step1127]: loss 0.038666
[epoch11, step1128]: loss 0.036147
[epoch11, step1129]: loss 0.035627
[epoch11, step1130]: loss 0.039563
[epoch11, step1131]: loss 0.037751
[epoch11, step1132]: loss 0.037471
[epoch11, step1133]: loss 0.035382
[epoch11, step1134]: loss 0.037226
[epoch11, step1135]: loss 0.038442
[epoch11, step1136]: loss 0.039428
[epoch11, step1137]: loss 0.036030
[epoch11, step1138]: loss 0.036060
[epoch11, step1139]: loss 0.038814
[epoch11, step1140]: loss 0.036821
[epoch11, step1141]: loss 0.036865
[epoch11, step1142]: loss 0.035600
[epoch11, step1143]: loss 0.037033
[epoch11, step1144]: loss 0.037643
[epoch11, step1145]: loss 0.038143
[epoch11, step1146]: loss 0.035619
[epoch11, step1147]: loss 0.036579
[epoch11, step1148]: loss 0.038951
[epoch11, step1149]: loss 0.037048
[epoch11, step1150]: loss 0.037009
[epoch11, step1151]: loss 0.036209
[epoch11, step1152]: loss 0.038030
[epoch11, step1153]: loss 0.036924
[epoch11, step1154]: loss 0.038946
[epoch11, step1155]: loss 0.036082
[epoch11, step1156]: loss 0.035192
[epoch11, step1157]: loss 0.038598
[epoch11, step1158]: loss 0.037597
[epoch11, step1159]: loss 0.037298
[epoch11, step1160]: loss 0.036652
[epoch11, step1161]: loss 0.037942
[epoch11, step1162]: loss 0.037496
[epoch11, step1163]: loss 0.037993
[epoch11, step1164]: loss 0.035954
[epoch11, step1165]: loss 0.036891
[epoch11, step1166]: loss 0.039049
[epoch11, step1167]: loss 0.036564
[epoch11, step1168]: loss 0.037328
[epoch11, step1169]: loss 0.035624
[epoch11, step1170]: loss 0.037586
[epoch11, step1171]: loss 0.037487
[epoch11, step1172]: loss 0.038602
[epoch11, step1173]: loss 0.036082
[epoch11, step1174]: loss 0.036228
[epoch11, step1175]: loss 0.038706
[epoch11, step1176]: loss 0.037071
[epoch11, step1177]: loss 0.037353
[epoch11, step1178]: loss 0.035883
[epoch11, step1179]: loss 0.037524
[epoch11, step1180]: loss 0.037627
[epoch11, step1181]: loss 0.039196
[epoch11, step1182]: loss 0.035259
[epoch11, step1183]: loss 0.036360
[epoch11, step1184]: loss 0.038314
[epoch11, step1185]: loss 0.037481
[epoch11, step1186]: loss 0.036335
[epoch11, step1187]: loss 0.034972
[epoch11, step1188]: loss 0.036845
[epoch11, step1189]: loss 0.037175
[epoch11, step1190]: loss 0.038190
[epoch11, step1191]: loss 0.036495
[epoch11, step1192]: loss 0.035961
[epoch11, step1193]: loss 0.038818
[epoch11, step1194]: loss 0.037169
[epoch11, step1195]: loss 0.035953
[epoch11, step1196]: loss 0.035098
[epoch11, step1197]: loss 0.037807
[epoch11, step1198]: loss 0.037488
[epoch11, step1199]: loss 0.038247
[epoch11, step1200]: loss 0.035614
[epoch11, step1201]: loss 0.036383
[epoch11, step1202]: loss 0.039650
[epoch11, step1203]: loss 0.037403
[epoch11, step1204]: loss 0.036442
[epoch11, step1205]: loss 0.035295
[epoch11, step1206]: loss 0.036927
[epoch11, step1207]: loss 0.037753
[epoch11, step1208]: loss 0.038962
[epoch11, step1209]: loss 0.034770
[epoch11, step1210]: loss 0.036361
[epoch11, step1211]: loss 0.038447
[epoch11, step1212]: loss 0.037068
[epoch11, step1213]: loss 0.036649
[epoch11, step1214]: loss 0.035944
[epoch11, step1215]: loss 0.038100
[epoch11, step1216]: loss 0.036967
[epoch11, step1217]: loss 0.039162
[epoch11, step1218]: loss 0.035494
[epoch11, step1219]: loss 0.036468
[epoch11, step1220]: loss 0.039110
[epoch11, step1221]: loss 0.036517
[epoch11, step1222]: loss 0.037257
[epoch11, step1223]: loss 0.035804
[epoch11, step1224]: loss 0.037970
[epoch11, step1225]: loss 0.037480
[epoch11, step1226]: loss 0.038256
[epoch11, step1227]: loss 0.035851
[epoch11, step1228]: loss 0.035591
[epoch11, step1229]: loss 0.038513
[epoch11, step1230]: loss 0.037489
[epoch11, step1231]: loss 0.036973
[epoch11, step1232]: loss 0.036777
[epoch11, step1233]: loss 0.037263
[epoch11, step1234]: loss 0.037144
[epoch11, step1235]: loss 0.039014
[epoch11, step1236]: loss 0.036052
[epoch11, step1237]: loss 0.035393
[epoch11, step1238]: loss 0.038270
[epoch11, step1239]: loss 0.037958
[epoch11, step1240]: loss 0.037322
[epoch11, step1241]: loss 0.035360
[epoch11, step1242]: loss 0.037464
[epoch11, step1243]: loss 0.037224
[epoch11, step1244]: loss 0.038829
[epoch11, step1245]: loss 0.036221
[epoch11, step1246]: loss 0.036154
[epoch11, step1247]: loss 0.037846
[epoch11, step1248]: loss 0.037338
[epoch11, step1249]: loss 0.037613
[epoch11, step1250]: loss 0.035656
[epoch11, step1251]: loss 0.037825
[epoch11, step1252]: loss 0.038294
[epoch11, step1253]: loss 0.038901
[epoch11, step1254]: loss 0.035954
[epoch11, step1255]: loss 0.035992
[epoch11, step1256]: loss 0.039185
[epoch11, step1257]: loss 0.037573
[epoch11, step1258]: loss 0.037345
[epoch11, step1259]: loss 0.035717
[epoch11, step1260]: loss 0.037605
[epoch11, step1261]: loss 0.037250
[epoch11, step1262]: loss 0.037544
[epoch11, step1263]: loss 0.036427
[epoch11, step1264]: loss 0.035742
[epoch11, step1265]: loss 0.037637
[epoch11, step1266]: loss 0.037284
[epoch11, step1267]: loss 0.037426
[epoch11, step1268]: loss 0.035971
[epoch11, step1269]: loss 0.037603
[epoch11, step1270]: loss 0.036722
[epoch11, step1271]: loss 0.039000
[epoch11, step1272]: loss 0.035988
[epoch11, step1273]: loss 0.035606
[epoch11, step1274]: loss 0.038735
[epoch11, step1275]: loss 0.037617
[epoch11, step1276]: loss 0.037010
[epoch11, step1277]: loss 0.035844
[epoch11, step1278]: loss 0.038142
[epoch11, step1279]: loss 0.037789
[epoch11, step1280]: loss 0.038857
[epoch11, step1281]: loss 0.035748
[epoch11, step1282]: loss 0.036016
[epoch11, step1283]: loss 0.038147
[epoch11, step1284]: loss 0.036749
[epoch11, step1285]: loss 0.037499
[epoch11, step1286]: loss 0.035238
[epoch11, step1287]: loss 0.038187
[epoch11, step1288]: loss 0.038142
[epoch11, step1289]: loss 0.039461
[epoch11, step1290]: loss 0.035924
[epoch11, step1291]: loss 0.035568
[epoch11, step1292]: loss 0.039478
[epoch11, step1293]: loss 0.036554
[epoch11, step1294]: loss 0.037168
[epoch11, step1295]: loss 0.036306
[epoch11, step1296]: loss 0.037789
[epoch11, step1297]: loss 0.037365
[epoch11, step1298]: loss 0.039235
[epoch11, step1299]: loss 0.036226
[epoch11, step1300]: loss 0.036650
[epoch11, step1301]: loss 0.037839
[epoch11, step1302]: loss 0.037241
[epoch11, step1303]: loss 0.037271
[epoch11, step1304]: loss 0.035177
[epoch11, step1305]: loss 0.038034
[epoch11, step1306]: loss 0.037640
[epoch11, step1307]: loss 0.038215
[epoch11, step1308]: loss 0.035966
[epoch11, step1309]: loss 0.035231
[epoch11, step1310]: loss 0.038656
[epoch11, step1311]: loss 0.036248
[epoch11, step1312]: loss 0.037780
[epoch11, step1313]: loss 0.035890
[epoch11, step1314]: loss 0.037468
[epoch11, step1315]: loss 0.037112
[epoch11, step1316]: loss 0.039914
[epoch11, step1317]: loss 0.035367
[epoch11, step1318]: loss 0.035314
[epoch11, step1319]: loss 0.038113
[epoch11, step1320]: loss 0.037471
[epoch11, step1321]: loss 0.037558
[epoch11, step1322]: loss 0.035424
[epoch11, step1323]: loss 0.037854
[epoch11, step1324]: loss 0.037022
[epoch11, step1325]: loss 0.038505
[epoch11, step1326]: loss 0.035675
[epoch11, step1327]: loss 0.035706
[epoch11, step1328]: loss 0.038745
[epoch11, step1329]: loss 0.037089
[epoch11, step1330]: loss 0.037305
[epoch11, step1331]: loss 0.035462
[epoch11, step1332]: loss 0.037394
[epoch11, step1333]: loss 0.036489
[epoch11, step1334]: loss 0.039017
[epoch11, step1335]: loss 0.036550
[epoch11, step1336]: loss 0.035807
[epoch11, step1337]: loss 0.038102
[epoch11, step1338]: loss 0.037234
[epoch11, step1339]: loss 0.037164
[epoch11, step1340]: loss 0.035437
[epoch11, step1341]: loss 0.037785
[epoch11, step1342]: loss 0.037160
[epoch11, step1343]: loss 0.038776
[epoch11, step1344]: loss 0.036002
[epoch11, step1345]: loss 0.035809
[epoch11, step1346]: loss 0.038204
[epoch11, step1347]: loss 0.037826
[epoch11, step1348]: loss 0.036441
[epoch11, step1349]: loss 0.035794
[epoch11, step1350]: loss 0.037721
[epoch11, step1351]: loss 0.036903
[epoch11, step1352]: loss 0.038302
[epoch11, step1353]: loss 0.035548
[epoch11, step1354]: loss 0.035545
[epoch11, step1355]: loss 0.038809
[epoch11, step1356]: loss 0.036933
[epoch11, step1357]: loss 0.036638
[epoch11, step1358]: loss 0.035558
[epoch11, step1359]: loss 0.037118
[epoch11, step1360]: loss 0.037554
[epoch11, step1361]: loss 0.038838
[epoch11, step1362]: loss 0.036467
[epoch11, step1363]: loss 0.036271
[epoch11, step1364]: loss 0.038477
[epoch11, step1365]: loss 0.037301
[epoch11, step1366]: loss 0.036940
[epoch11, step1367]: loss 0.034876
[epoch11, step1368]: loss 0.038397
[epoch11, step1369]: loss 0.037626
[epoch11, step1370]: loss 0.038359
[epoch11, step1371]: loss 0.036140
[epoch11, step1372]: loss 0.035720
[epoch11, step1373]: loss 0.038732
[epoch11, step1374]: loss 0.037989
[epoch11, step1375]: loss 0.037832
[epoch11, step1376]: loss 0.035450
[epoch11, step1377]: loss 0.036889
[epoch11, step1378]: loss 0.037399
[epoch11, step1379]: loss 0.038163
[epoch11, step1380]: loss 0.036202
[epoch11, step1381]: loss 0.035783
[epoch11, step1382]: loss 0.038825
[epoch11, step1383]: loss 0.037046
[epoch11, step1384]: loss 0.036877
[epoch11, step1385]: loss 0.035003
[epoch11, step1386]: loss 0.037694
[epoch11, step1387]: loss 0.037776
[epoch11, step1388]: loss 0.037542
[epoch11, step1389]: loss 0.035140
[epoch11, step1390]: loss 0.036005
[epoch11, step1391]: loss 0.038282
[epoch11, step1392]: loss 0.037206
[epoch11, step1393]: loss 0.037224
[epoch11, step1394]: loss 0.036306
[epoch11, step1395]: loss 0.037593
[epoch11, step1396]: loss 0.036901
[epoch11, step1397]: loss 0.038335
[epoch11, step1398]: loss 0.035713
[epoch11, step1399]: loss 0.036644
[epoch11, step1400]: loss 0.039042
[epoch11, step1401]: loss 0.036897
[epoch11, step1402]: loss 0.037215
[epoch11, step1403]: loss 0.034630
[epoch11, step1404]: loss 0.036961
[epoch11, step1405]: loss 0.037104
[epoch11, step1406]: loss 0.038301
[epoch11, step1407]: loss 0.036802
[epoch11, step1408]: loss 0.035167
[epoch11, step1409]: loss 0.038194
[epoch11, step1410]: loss 0.037066
[epoch11, step1411]: loss 0.036007
[epoch11, step1412]: loss 0.035672
[epoch11, step1413]: loss 0.037527
[epoch11, step1414]: loss 0.036889
[epoch11, step1415]: loss 0.038231
[epoch11, step1416]: loss 0.035634
[epoch11, step1417]: loss 0.035697
[epoch11, step1418]: loss 0.038543
[epoch11, step1419]: loss 0.037830
[epoch11, step1420]: loss 0.037252
[epoch11, step1421]: loss 0.036030
[epoch11, step1422]: loss 0.037751
[epoch11, step1423]: loss 0.036824
[epoch11, step1424]: loss 0.038701
[epoch11, step1425]: loss 0.034860
[epoch11, step1426]: loss 0.035813
[epoch11, step1427]: loss 0.039413
[epoch11, step1428]: loss 0.037924
[epoch11, step1429]: loss 0.036984
[epoch11, step1430]: loss 0.035634
[epoch11, step1431]: loss 0.037551
[epoch11, step1432]: loss 0.037009
[epoch11, step1433]: loss 0.038679
[epoch11, step1434]: loss 0.035381
[epoch11, step1435]: loss 0.036173
[epoch11, step1436]: loss 0.038881
[epoch11, step1437]: loss 0.037509
[epoch11, step1438]: loss 0.037915
[epoch11, step1439]: loss 0.035388
[epoch11, step1440]: loss 0.037395
[epoch11, step1441]: loss 0.037919
[epoch11, step1442]: loss 0.037753
[epoch11, step1443]: loss 0.035520
[epoch11, step1444]: loss 0.035074
[epoch11, step1445]: loss 0.038915
[epoch11, step1446]: loss 0.037302
[epoch11, step1447]: loss 0.037684
[epoch11, step1448]: loss 0.035574
[epoch11, step1449]: loss 0.036834
[epoch11, step1450]: loss 0.037337
[epoch11, step1451]: loss 0.038947
[epoch11, step1452]: loss 0.035452
[epoch11, step1453]: loss 0.036751
[epoch11, step1454]: loss 0.039002
[epoch11, step1455]: loss 0.037707
[epoch11, step1456]: loss 0.036668
[epoch11, step1457]: loss 0.036164
[epoch11, step1458]: loss 0.037585
[epoch11, step1459]: loss 0.037267
[epoch11, step1460]: loss 0.038993
[epoch11, step1461]: loss 0.036448
[epoch11, step1462]: loss 0.036404
[epoch11, step1463]: loss 0.038513
[epoch11, step1464]: loss 0.037390
[epoch11, step1465]: loss 0.036671
[epoch11, step1466]: loss 0.035258
[epoch11, step1467]: loss 0.037394
[epoch11, step1468]: loss 0.036819
[epoch11, step1469]: loss 0.038469
[epoch11, step1470]: loss 0.035923
[epoch11, step1471]: loss 0.035500
[epoch11, step1472]: loss 0.038380
[epoch11, step1473]: loss 0.037128
[epoch11, step1474]: loss 0.037634
[epoch11, step1475]: loss 0.035371
[epoch11, step1476]: loss 0.038243
[epoch11, step1477]: loss 0.036967
[epoch11, step1478]: loss 0.038611
[epoch11, step1479]: loss 0.035691
[epoch11, step1480]: loss 0.035730
[epoch11, step1481]: loss 0.037748
[epoch11, step1482]: loss 0.037049
[epoch11, step1483]: loss 0.037079
[epoch11, step1484]: loss 0.035921
[epoch11, step1485]: loss 0.037278
[epoch11, step1486]: loss 0.036293
[epoch11, step1487]: loss 0.038304
[epoch11, step1488]: loss 0.035761
[epoch11, step1489]: loss 0.035616
[epoch11, step1490]: loss 0.038568
[epoch11, step1491]: loss 0.037191
[epoch11, step1492]: loss 0.036783
[epoch11, step1493]: loss 0.035627
[epoch11, step1494]: loss 0.037520
[epoch11, step1495]: loss 0.037021
[epoch11, step1496]: loss 0.037689
[epoch11, step1497]: loss 0.036043
[epoch11, step1498]: loss 0.036132
[epoch11, step1499]: loss 0.037944
[epoch11, step1500]: loss 0.037454
[epoch11, step1501]: loss 0.037120
[epoch11, step1502]: loss 0.035449
[epoch11, step1503]: loss 0.037370
[epoch11, step1504]: loss 0.036768
[epoch11, step1505]: loss 0.038778
[epoch11, step1506]: loss 0.035178
[epoch11, step1507]: loss 0.036051
[epoch11, step1508]: loss 0.039038
[epoch11, step1509]: loss 0.036839
[epoch11, step1510]: loss 0.036680
[epoch11, step1511]: loss 0.036307
[epoch11, step1512]: loss 0.037833
[epoch11, step1513]: loss 0.036061
[epoch11, step1514]: loss 0.038663
[epoch11, step1515]: loss 0.036263
[epoch11, step1516]: loss 0.035863

[epoch11]: avg loss 0.034086

[epoch12, step1]: loss 0.036000
[epoch12, step2]: loss 0.038207
[epoch12, step3]: loss 0.038675
[epoch12, step4]: loss 0.035641
[epoch12, step5]: loss 0.036298
[epoch12, step6]: loss 0.038672
[epoch12, step7]: loss 0.036432
[epoch12, step8]: loss 0.038777
[epoch12, step9]: loss 0.035216
[epoch12, step10]: loss 0.036885
[epoch12, step11]: loss 0.038508
[epoch12, step12]: loss 0.038292
[epoch12, step13]: loss 0.035892
[epoch12, step14]: loss 0.036045
[epoch12, step15]: loss 0.038418
[epoch12, step16]: loss 0.036313
[epoch12, step17]: loss 0.038794
[epoch12, step18]: loss 0.036360
[epoch12, step19]: loss 0.036343
[epoch12, step20]: loss 0.039232
[epoch12, step21]: loss 0.038247
[epoch12, step22]: loss 0.035389
[epoch12, step23]: loss 0.035221
[epoch12, step24]: loss 0.038632
[epoch12, step25]: loss 0.035709
[epoch12, step26]: loss 0.038126
[epoch12, step27]: loss 0.035059
[epoch12, step28]: loss 0.036811
[epoch12, step29]: loss 0.038704
[epoch12, step30]: loss 0.039177
[epoch12, step31]: loss 0.035204
[epoch12, step32]: loss 0.036404
[epoch12, step33]: loss 0.039242
[epoch12, step34]: loss 0.036894
[epoch12, step35]: loss 0.038980
[epoch12, step36]: loss 0.035451
[epoch12, step37]: loss 0.036307
[epoch12, step38]: loss 0.038429
[epoch12, step39]: loss 0.038315
[epoch12, step40]: loss 0.035918
[epoch12, step41]: loss 0.035273
[epoch12, step42]: loss 0.038747
[epoch12, step43]: loss 0.036135
[epoch12, step44]: loss 0.039148
[epoch12, step45]: loss 0.035580
[epoch12, step46]: loss 0.036461
[epoch12, step47]: loss 0.037940
[epoch12, step48]: loss 0.038133
[epoch12, step49]: loss 0.034127
[epoch12, step50]: loss 0.035978
[epoch12, step51]: loss 0.038386
[epoch12, step52]: loss 0.035986
[epoch12, step53]: loss 0.039110
[epoch12, step54]: loss 0.035273
[epoch12, step55]: loss 0.036802
[epoch12, step56]: loss 0.039338
[epoch12, step57]: loss 0.038866
[epoch12, step58]: loss 0.035560
[epoch12, step59]: loss 0.034849
[epoch12, step60]: loss 0.039099
[epoch12, step61]: loss 0.035391
[epoch12, step62]: loss 0.038012
[epoch12, step63]: loss 0.034967
[epoch12, step64]: loss 0.035973
[epoch12, step65]: loss 0.038632
[epoch12, step66]: loss 0.038450
[epoch12, step67]: loss 0.035779
[epoch12, step68]: loss 0.035891
[epoch12, step69]: loss 0.038436
[epoch12, step70]: loss 0.035981
[epoch12, step71]: loss 0.038195
[epoch12, step72]: loss 0.035519
[epoch12, step73]: loss 0.036410
[epoch12, step74]: loss 0.038379
[epoch12, step75]: loss 0.038982
[epoch12, step76]: loss 0.036175
[epoch12, step77]: loss 0.036394
[epoch12, step78]: loss 0.038781
[epoch12, step79]: loss 0.035487
[epoch12, step80]: loss 0.039325
[epoch12, step81]: loss 0.035564
[epoch12, step82]: loss 0.035896
[epoch12, step83]: loss 0.038083
[epoch12, step84]: loss 0.038625
[epoch12, step85]: loss 0.036289
[epoch12, step86]: loss 0.036244
[epoch12, step87]: loss 0.039550
[epoch12, step88]: loss 0.035045
[epoch12, step89]: loss 0.038340
[epoch12, step90]: loss 0.036043
[epoch12, step91]: loss 0.035785
[epoch12, step92]: loss 0.038679
[epoch12, step93]: loss 0.038538
[epoch12, step94]: loss 0.035411
[epoch12, step95]: loss 0.036329
[epoch12, step96]: loss 0.038222
[epoch12, step97]: loss 0.036791
[epoch12, step98]: loss 0.038631
[epoch12, step99]: loss 0.035597
[epoch12, step100]: loss 0.035231
[epoch12, step101]: loss 0.039108
[epoch12, step102]: loss 0.038387
[epoch12, step103]: loss 0.035533
[epoch12, step104]: loss 0.035856
[epoch12, step105]: loss 0.038932
[epoch12, step106]: loss 0.036140
[epoch12, step107]: loss 0.038772
[epoch12, step108]: loss 0.035910
[epoch12, step109]: loss 0.035969
[epoch12, step110]: loss 0.039107
[epoch12, step111]: loss 0.038237
[epoch12, step112]: loss 0.035801
[epoch12, step113]: loss 0.036665
[epoch12, step114]: loss 0.038285
[epoch12, step115]: loss 0.036067
[epoch12, step116]: loss 0.039422
[epoch12, step117]: loss 0.035495
[epoch12, step118]: loss 0.037052
[epoch12, step119]: loss 0.038997
[epoch12, step120]: loss 0.038859
[epoch12, step121]: loss 0.035569
[epoch12, step122]: loss 0.035832
[epoch12, step123]: loss 0.038978
[epoch12, step124]: loss 0.036472
[epoch12, step125]: loss 0.039038
[epoch12, step126]: loss 0.035565
[epoch12, step127]: loss 0.036042
[epoch12, step128]: loss 0.038422
[epoch12, step129]: loss 0.038399
[epoch12, step130]: loss 0.035881
[epoch12, step131]: loss 0.035310
[epoch12, step132]: loss 0.038623
[epoch12, step133]: loss 0.035981
[epoch12, step134]: loss 0.037947
[epoch12, step135]: loss 0.036169
[epoch12, step136]: loss 0.037289
[epoch12, step137]: loss 0.038271
[epoch12, step138]: loss 0.038481
[epoch12, step139]: loss 0.035566
[epoch12, step140]: loss 0.036403
[epoch12, step141]: loss 0.038911
[epoch12, step142]: loss 0.036044
[epoch12, step143]: loss 0.038141
[epoch12, step144]: loss 0.035869
[epoch12, step145]: loss 0.036210
[epoch12, step146]: loss 0.038555
[epoch12, step147]: loss 0.039760
[epoch12, step148]: loss 0.035312
[epoch12, step149]: loss 0.035522
[epoch12, step150]: loss 0.038438
[epoch12, step151]: loss 0.036110
[epoch12, step152]: loss 0.038415
[epoch12, step153]: loss 0.035636
[epoch12, step154]: loss 0.035980
[epoch12, step155]: loss 0.038393
[epoch12, step156]: loss 0.038112
[epoch12, step157]: loss 0.035734
[epoch12, step158]: loss 0.036185
[epoch12, step159]: loss 0.038783
[epoch12, step160]: loss 0.036334
[epoch12, step161]: loss 0.039028
[epoch12, step162]: loss 0.035871
[epoch12, step163]: loss 0.036179
[epoch12, step164]: loss 0.038750
[epoch12, step165]: loss 0.038508
[epoch12, step166]: loss 0.035988
[epoch12, step167]: loss 0.035488
[epoch12, step168]: loss 0.039277
[epoch12, step169]: loss 0.035827
[epoch12, step170]: loss 0.038929
[epoch12, step171]: loss 0.036014
[epoch12, step172]: loss 0.036384
[epoch12, step173]: loss 0.038855
[epoch12, step174]: loss 0.038342
[epoch12, step175]: loss 0.036399
[epoch12, step176]: loss 0.036171
[epoch12, step177]: loss 0.038971
[epoch12, step178]: loss 0.036061
[epoch12, step179]: loss 0.037770
[epoch12, step180]: loss 0.035883
[epoch12, step181]: loss 0.036430
[epoch12, step182]: loss 0.039021
[epoch12, step183]: loss 0.039200
[epoch12, step184]: loss 0.036663
[epoch12, step185]: loss 0.036148
[epoch12, step186]: loss 0.038852
[epoch12, step187]: loss 0.036236
[epoch12, step188]: loss 0.038355
[epoch12, step189]: loss 0.035656
[epoch12, step190]: loss 0.035586
[epoch12, step191]: loss 0.038548
[epoch12, step192]: loss 0.039099
[epoch12, step193]: loss 0.033899
[epoch12, step194]: loss 0.035093
[epoch12, step195]: loss 0.038941
[epoch12, step196]: loss 0.036215
[epoch12, step197]: loss 0.038431
[epoch12, step198]: loss 0.034866
[epoch12, step199]: loss 0.036324
[epoch12, step200]: loss 0.039031
[epoch12, step201]: loss 0.039063
[epoch12, step202]: loss 0.035366
[epoch12, step203]: loss 0.035975
[epoch12, step204]: loss 0.039190
[epoch12, step205]: loss 0.035598
[epoch12, step206]: loss 0.038290
[epoch12, step207]: loss 0.035528
[epoch12, step208]: loss 0.036705
[epoch12, step209]: loss 0.038886
[epoch12, step210]: loss 0.039450
[epoch12, step211]: loss 0.036309
[epoch12, step212]: loss 0.036334
[epoch12, step213]: loss 0.038300
[epoch12, step214]: loss 0.035463
[epoch12, step215]: loss 0.038845
[epoch12, step216]: loss 0.035950
[epoch12, step217]: loss 0.035520
[epoch12, step218]: loss 0.038871
[epoch12, step219]: loss 0.038395
[epoch12, step220]: loss 0.036031
[epoch12, step221]: loss 0.036223
[epoch12, step222]: loss 0.039124
[epoch12, step223]: loss 0.036261
[epoch12, step224]: loss 0.038207
[epoch12, step225]: loss 0.035625
[epoch12, step226]: loss 0.035981
[epoch12, step227]: loss 0.037661
[epoch12, step228]: loss 0.039215
[epoch12, step229]: loss 0.034897
[epoch12, step230]: loss 0.036286
[epoch12, step231]: loss 0.039249
[epoch12, step232]: loss 0.035867
[epoch12, step233]: loss 0.037889
[epoch12, step234]: loss 0.035232
[epoch12, step235]: loss 0.036517
[epoch12, step236]: loss 0.038599
[epoch12, step237]: loss 0.038661
[epoch12, step238]: loss 0.035503
[epoch12, step239]: loss 0.035228
[epoch12, step240]: loss 0.038190
[epoch12, step241]: loss 0.036501
[epoch12, step242]: loss 0.038423
[epoch12, step243]: loss 0.036429
[epoch12, step244]: loss 0.036022
[epoch12, step245]: loss 0.038141
[epoch12, step246]: loss 0.038594
[epoch12, step247]: loss 0.036025
[epoch12, step248]: loss 0.035576
[epoch12, step249]: loss 0.038143
[epoch12, step250]: loss 0.036456
[epoch12, step251]: loss 0.039044
[epoch12, step252]: loss 0.036157
[epoch12, step253]: loss 0.035750
[epoch12, step254]: loss 0.038274
[epoch12, step255]: loss 0.038861
[epoch12, step256]: loss 0.035496
[epoch12, step257]: loss 0.035648
[epoch12, step258]: loss 0.039278
[epoch12, step259]: loss 0.036220
[epoch12, step260]: loss 0.038073
[epoch12, step261]: loss 0.036454
[epoch12, step262]: loss 0.036589
[epoch12, step263]: loss 0.038080
[epoch12, step264]: loss 0.038366
[epoch12, step265]: loss 0.035958
[epoch12, step266]: loss 0.035844
[epoch12, step267]: loss 0.038011
[epoch12, step268]: loss 0.035993
[epoch12, step269]: loss 0.038611
[epoch12, step270]: loss 0.035209
[epoch12, step271]: loss 0.036289
[epoch12, step272]: loss 0.038485
[epoch12, step273]: loss 0.038307
[epoch12, step274]: loss 0.036166
[epoch12, step275]: loss 0.035438
[epoch12, step276]: loss 0.038445
[epoch12, step277]: loss 0.036555
[epoch12, step278]: loss 0.038742
[epoch12, step279]: loss 0.035311
[epoch12, step280]: loss 0.036310
[epoch12, step281]: loss 0.038466
[epoch12, step282]: loss 0.039115
[epoch12, step283]: loss 0.035357
[epoch12, step284]: loss 0.035396
[epoch12, step285]: loss 0.039466
[epoch12, step286]: loss 0.035340
[epoch12, step287]: loss 0.038817
[epoch12, step288]: loss 0.035293
[epoch12, step289]: loss 0.036934
[epoch12, step290]: loss 0.038615
[epoch12, step291]: loss 0.038867
[epoch12, step292]: loss 0.034942
[epoch12, step293]: loss 0.035536
[epoch12, step294]: loss 0.038196
[epoch12, step295]: loss 0.035561
[epoch12, step296]: loss 0.039363
[epoch12, step297]: loss 0.035413
[epoch12, step298]: loss 0.036619
[epoch12, step299]: loss 0.037698
[epoch12, step300]: loss 0.038875
[epoch12, step301]: loss 0.035774
[epoch12, step302]: loss 0.036226
[epoch12, step303]: loss 0.039024
[epoch12, step304]: loss 0.035808
[epoch12, step305]: loss 0.038305
[epoch12, step306]: loss 0.035759
[epoch12, step307]: loss 0.035939
[epoch12, step308]: loss 0.039042
[epoch12, step309]: loss 0.038947
[epoch12, step310]: loss 0.035881
[epoch12, step311]: loss 0.036302
[epoch12, step312]: loss 0.038337
[epoch12, step313]: loss 0.036409
[epoch12, step314]: loss 0.038495
[epoch12, step315]: loss 0.036643
[epoch12, step316]: loss 0.035922
[epoch12, step317]: loss 0.038965
[epoch12, step318]: loss 0.038637
[epoch12, step319]: loss 0.035212
[epoch12, step320]: loss 0.034940
[epoch12, step321]: loss 0.038234
[epoch12, step322]: loss 0.035920
[epoch12, step323]: loss 0.037918
[epoch12, step324]: loss 0.036521
[epoch12, step325]: loss 0.036316
[epoch12, step326]: loss 0.038282
[epoch12, step327]: loss 0.037933
[epoch12, step328]: loss 0.035917
[epoch12, step329]: loss 0.035606
[epoch12, step330]: loss 0.038144
[epoch12, step331]: loss 0.036219
[epoch12, step332]: loss 0.037923
[epoch12, step333]: loss 0.035611
[epoch12, step334]: loss 0.036251
[epoch12, step335]: loss 0.038620
[epoch12, step336]: loss 0.039384
[epoch12, step337]: loss 0.036179
[epoch12, step338]: loss 0.035445
[epoch12, step339]: loss 0.038636
[epoch12, step340]: loss 0.036637
[epoch12, step341]: loss 0.038012
[epoch12, step342]: loss 0.035365
[epoch12, step343]: loss 0.036366
[epoch12, step344]: loss 0.038044
[epoch12, step345]: loss 0.037868
[epoch12, step346]: loss 0.035276
[epoch12, step347]: loss 0.035480
[epoch12, step348]: loss 0.038787
[epoch12, step349]: loss 0.036533
[epoch12, step350]: loss 0.038025
[epoch12, step351]: loss 0.034916
[epoch12, step352]: loss 0.035962
[epoch12, step353]: loss 0.038329
[epoch12, step354]: loss 0.037609
[epoch12, step355]: loss 0.034655
[epoch12, step356]: loss 0.036406
[epoch12, step357]: loss 0.038688
[epoch12, step358]: loss 0.034575
[epoch12, step359]: loss 0.039382
[epoch12, step360]: loss 0.034428
[epoch12, step361]: loss 0.035622
[epoch12, step362]: loss 0.039140
[epoch12, step363]: loss 0.038220
[epoch12, step364]: loss 0.035616
[epoch12, step365]: loss 0.035562
[epoch12, step366]: loss 0.038971
[epoch12, step367]: loss 0.036040
[epoch12, step368]: loss 0.037878
[epoch12, step369]: loss 0.035485
[epoch12, step370]: loss 0.036629
[epoch12, step371]: loss 0.039239
[epoch12, step372]: loss 0.038137
[epoch12, step373]: loss 0.035136
[epoch12, step374]: loss 0.035062
[epoch12, step375]: loss 0.039220
[epoch12, step376]: loss 0.036099
[epoch12, step377]: loss 0.038629
[epoch12, step378]: loss 0.036079
[epoch12, step379]: loss 0.036711
[epoch12, step380]: loss 0.039038
[epoch12, step381]: loss 0.038253
[epoch12, step382]: loss 0.036005
[epoch12, step383]: loss 0.034822
[epoch12, step384]: loss 0.037885
[epoch12, step385]: loss 0.035817
[epoch12, step386]: loss 0.038622
[epoch12, step387]: loss 0.035619
[epoch12, step388]: loss 0.037075
[epoch12, step389]: loss 0.038481
[epoch12, step390]: loss 0.039524
[epoch12, step391]: loss 0.035245
[epoch12, step392]: loss 0.036305
[epoch12, step393]: loss 0.038132
[epoch12, step394]: loss 0.036000
[epoch12, step395]: loss 0.038189
[epoch12, step396]: loss 0.035754
[epoch12, step397]: loss 0.035765
[epoch12, step398]: loss 0.038613
[epoch12, step399]: loss 0.038459
[epoch12, step400]: loss 0.035339
[epoch12, step401]: loss 0.035598
[epoch12, step402]: loss 0.038549
[epoch12, step403]: loss 0.035935
[epoch12, step404]: loss 0.038956
[epoch12, step405]: loss 0.035974
[epoch12, step406]: loss 0.036353
[epoch12, step407]: loss 0.038298
[epoch12, step408]: loss 0.038627
[epoch12, step409]: loss 0.036983
[epoch12, step410]: loss 0.036430
[epoch12, step411]: loss 0.038435
[epoch12, step412]: loss 0.035471
[epoch12, step413]: loss 0.038405
[epoch12, step414]: loss 0.035356
[epoch12, step415]: loss 0.036300
[epoch12, step416]: loss 0.037799
[epoch12, step417]: loss 0.038702
[epoch12, step418]: loss 0.035578
[epoch12, step419]: loss 0.035009
[epoch12, step420]: loss 0.038749
[epoch12, step421]: loss 0.035722
[epoch12, step422]: loss 0.038417
[epoch12, step423]: loss 0.035701
[epoch12, step424]: loss 0.036261
[epoch12, step425]: loss 0.038623
[epoch12, step426]: loss 0.038877
[epoch12, step427]: loss 0.036009
[epoch12, step428]: loss 0.035657
[epoch12, step429]: loss 0.039197
[epoch12, step430]: loss 0.035903
[epoch12, step431]: loss 0.038788
[epoch12, step432]: loss 0.035489
[epoch12, step433]: loss 0.036905
[epoch12, step434]: loss 0.038358
[epoch12, step435]: loss 0.038904
[epoch12, step436]: loss 0.035399
[epoch12, step437]: loss 0.035921
[epoch12, step438]: loss 0.039161
[epoch12, step439]: loss 0.036210
[epoch12, step440]: loss 0.038462
[epoch12, step441]: loss 0.035868
[epoch12, step442]: loss 0.036046
[epoch12, step443]: loss 0.038942
[epoch12, step444]: loss 0.038270
[epoch12, step445]: loss 0.036113
[epoch12, step446]: loss 0.036157
[epoch12, step447]: loss 0.039253
[epoch12, step448]: loss 0.036102
[epoch12, step449]: loss 0.038312
[epoch12, step450]: loss 0.035046
[epoch12, step451]: loss 0.036001
[epoch12, step452]: loss 0.037775
[epoch12, step453]: loss 0.038689
[epoch12, step454]: loss 0.035623
[epoch12, step455]: loss 0.035978
[epoch12, step456]: loss 0.037938
[epoch12, step457]: loss 0.036621
[epoch12, step458]: loss 0.038225
[epoch12, step459]: loss 0.036387
[epoch12, step460]: loss 0.036321
[epoch12, step461]: loss 0.039196
[epoch12, step462]: loss 0.037931
[epoch12, step463]: loss 0.035823
[epoch12, step464]: loss 0.035650
[epoch12, step465]: loss 0.039950
[epoch12, step466]: loss 0.036011
[epoch12, step467]: loss 0.038322
[epoch12, step468]: loss 0.035667
[epoch12, step469]: loss 0.036289
[epoch12, step470]: loss 0.038736
[epoch12, step471]: loss 0.038098
[epoch12, step472]: loss 0.036207
[epoch12, step473]: loss 0.035403
[epoch12, step474]: loss 0.038499
[epoch12, step475]: loss 0.036087
[epoch12, step476]: loss 0.038894
[epoch12, step477]: loss 0.035442
[epoch12, step478]: loss 0.035520
[epoch12, step479]: loss 0.038398
[epoch12, step480]: loss 0.037849
[epoch12, step481]: loss 0.035305
[epoch12, step482]: loss 0.035211
[epoch12, step483]: loss 0.038983
[epoch12, step484]: loss 0.036146
[epoch12, step485]: loss 0.038648
[epoch12, step486]: loss 0.036034
[epoch12, step487]: loss 0.035596
[epoch12, step488]: loss 0.038906
[epoch12, step489]: loss 0.037837
[epoch12, step490]: loss 0.036102
[epoch12, step491]: loss 0.035972
[epoch12, step492]: loss 0.038246
[epoch12, step493]: loss 0.035694
[epoch12, step494]: loss 0.037883
[epoch12, step495]: loss 0.036753
[epoch12, step496]: loss 0.036334
[epoch12, step497]: loss 0.038778
[epoch12, step498]: loss 0.038529
[epoch12, step499]: loss 0.035976
[epoch12, step500]: loss 0.035277
[epoch12, step501]: loss 0.038115
[epoch12, step502]: loss 0.035761
[epoch12, step503]: loss 0.038722
[epoch12, step504]: loss 0.035380
[epoch12, step505]: loss 0.035258
[epoch12, step506]: loss 0.038900
[epoch12, step507]: loss 0.038871
[epoch12, step508]: loss 0.036156
[epoch12, step509]: loss 0.035647
[epoch12, step510]: loss 0.038772
[epoch12, step511]: loss 0.036393
[epoch12, step512]: loss 0.038824
[epoch12, step513]: loss 0.035878
[epoch12, step514]: loss 0.036426
[epoch12, step515]: loss 0.038492
[epoch12, step516]: loss 0.038999
[epoch12, step517]: loss 0.035766
[epoch12, step518]: loss 0.035870
[epoch12, step519]: loss 0.038705
[epoch12, step520]: loss 0.035395
[epoch12, step521]: loss 0.038325
[epoch12, step522]: loss 0.035310
[epoch12, step523]: loss 0.036105
[epoch12, step524]: loss 0.037783
[epoch12, step525]: loss 0.038821
[epoch12, step526]: loss 0.035804
[epoch12, step527]: loss 0.035403
[epoch12, step528]: loss 0.038740
[epoch12, step529]: loss 0.035516
[epoch12, step530]: loss 0.038825
[epoch12, step531]: loss 0.035395
[epoch12, step532]: loss 0.035848
[epoch12, step533]: loss 0.039402
[epoch12, step534]: loss 0.038398
[epoch12, step535]: loss 0.036353
[epoch12, step536]: loss 0.035967
[epoch12, step537]: loss 0.038710
[epoch12, step538]: loss 0.036017
[epoch12, step539]: loss 0.038252
[epoch12, step540]: loss 0.035272
[epoch12, step541]: loss 0.035648
[epoch12, step542]: loss 0.038485
[epoch12, step543]: loss 0.038269
[epoch12, step544]: loss 0.035650
[epoch12, step545]: loss 0.034953
[epoch12, step546]: loss 0.039106
[epoch12, step547]: loss 0.035894
[epoch12, step548]: loss 0.038461
[epoch12, step549]: loss 0.035912
[epoch12, step550]: loss 0.036140
[epoch12, step551]: loss 0.038337
[epoch12, step552]: loss 0.037902
[epoch12, step553]: loss 0.036121
[epoch12, step554]: loss 0.035582
[epoch12, step555]: loss 0.038212
[epoch12, step556]: loss 0.035724
[epoch12, step557]: loss 0.037887
[epoch12, step558]: loss 0.035853
[epoch12, step559]: loss 0.035590
[epoch12, step560]: loss 0.038619
[epoch12, step561]: loss 0.038298
[epoch12, step562]: loss 0.035674
[epoch12, step563]: loss 0.029120
[epoch12, step564]: loss 0.029110
[epoch12, step565]: loss 0.027784
[epoch12, step566]: loss 0.034628
[epoch12, step567]: loss 0.026804
[epoch12, step568]: loss 0.025803
[epoch12, step569]: loss 0.023174
[epoch12, step570]: loss 0.031146
[epoch12, step571]: loss 0.026985
[epoch12, step572]: loss 0.025921
[epoch12, step573]: loss 0.028836
[epoch12, step574]: loss 0.027561
[epoch12, step575]: loss 0.020700
[epoch12, step576]: loss 0.021606
[epoch12, step577]: loss 0.026135
[epoch12, step578]: loss 0.018595
[epoch12, step579]: loss 0.028387
[epoch12, step580]: loss 0.019980
[epoch12, step581]: loss 0.025990
[epoch12, step582]: loss 0.025307
[epoch12, step583]: loss 0.021693
[epoch12, step584]: loss 0.023794
[epoch12, step585]: loss 0.026166
[epoch12, step586]: loss 0.021714
[epoch12, step587]: loss 0.027659
[epoch12, step588]: loss 0.023048
[epoch12, step589]: loss 0.022899
[epoch12, step590]: loss 0.027225
[epoch12, step591]: loss 0.020631
[epoch12, step592]: loss 0.025704
[epoch12, step593]: loss 0.022162
[epoch12, step594]: loss 0.026209
[epoch12, step595]: loss 0.026591
[epoch12, step596]: loss 0.022151
[epoch12, step597]: loss 0.025007
[epoch12, step598]: loss 0.026878
[epoch12, step599]: loss 0.025161
[epoch12, step600]: loss 0.027177
[epoch12, step601]: loss 0.019628
[epoch12, step602]: loss 0.022716
[epoch12, step603]: loss 0.025893
[epoch12, step604]: loss 0.026460
[epoch12, step605]: loss 0.025036
[epoch12, step606]: loss 0.025026
[epoch12, step607]: loss 0.026929
[epoch12, step608]: loss 0.025886
[epoch12, step609]: loss 0.026341
[epoch12, step610]: loss 0.025831
[epoch12, step611]: loss 0.026397
[epoch12, step612]: loss 0.025555
[epoch12, step613]: loss 0.019181
[epoch12, step614]: loss 0.025188
[epoch12, step615]: loss 0.028208
[epoch12, step616]: loss 0.024076
[epoch12, step617]: loss 0.023485
[epoch12, step618]: loss 0.025841
[epoch12, step619]: loss 0.027024
[epoch12, step620]: loss 0.024313
[epoch12, step621]: loss 0.026289
[epoch12, step622]: loss 0.020291
[epoch12, step623]: loss 0.024916
[epoch12, step624]: loss 0.026393
[epoch12, step625]: loss 0.026028
[epoch12, step626]: loss 0.027970
[epoch12, step627]: loss 0.022710
[epoch12, step628]: loss 0.025653
[epoch12, step629]: loss 0.020801
[epoch12, step630]: loss 0.023314
[epoch12, step631]: loss 0.031159
[epoch12, step632]: loss 0.023501
[epoch12, step633]: loss 0.024711
[epoch12, step634]: loss 0.026991
[epoch12, step635]: loss 0.025637
[epoch12, step636]: loss 0.020615
[epoch12, step637]: loss 0.027182
[epoch12, step638]: loss 0.027068
[epoch12, step639]: loss 0.022956
[epoch12, step640]: loss 0.029325
[epoch12, step641]: loss 0.030065
[epoch12, step642]: loss 0.024824
[epoch12, step643]: loss 0.025598
[epoch12, step644]: loss 0.025751
[epoch12, step645]: loss 0.023581
[epoch12, step646]: loss 0.026235
[epoch12, step647]: loss 0.023695
[epoch12, step648]: loss 0.023031
[epoch12, step649]: loss 0.028593
[epoch12, step650]: loss 0.021936
[epoch12, step651]: loss 0.025845
[epoch12, step652]: loss 0.026918
[epoch12, step653]: loss 0.027886
[epoch12, step654]: loss 0.023094
[epoch12, step655]: loss 0.024212
[epoch12, step656]: loss 0.021478
[epoch12, step657]: loss 0.027543
[epoch12, step658]: loss 0.025248
[epoch12, step659]: loss 0.027407
[epoch12, step660]: loss 0.023880
[epoch12, step661]: loss 0.026342
[epoch12, step662]: loss 0.023852
[epoch12, step663]: loss 0.021154
[epoch12, step664]: loss 0.025031
[epoch12, step665]: loss 0.027667
[epoch12, step666]: loss 0.026792
[epoch12, step667]: loss 0.026403
[epoch12, step668]: loss 0.022333
[epoch12, step669]: loss 0.026405
[epoch12, step670]: loss 0.026741
[epoch12, step671]: loss 0.021323
[epoch12, step672]: loss 0.023622
[epoch12, step673]: loss 0.022186
[epoch12, step674]: loss 0.021225
[epoch12, step675]: loss 0.020003
[epoch12, step676]: loss 0.024628
[epoch12, step677]: loss 0.025266
[epoch12, step678]: loss 0.023186
[epoch12, step679]: loss 0.023921
[epoch12, step680]: loss 0.030565
[epoch12, step681]: loss 0.022016
[epoch12, step682]: loss 0.026273
[epoch12, step683]: loss 0.025887
[epoch12, step684]: loss 0.024729
[epoch12, step685]: loss 0.024297
[epoch12, step686]: loss 0.027062
[epoch12, step687]: loss 0.026751
[epoch12, step688]: loss 0.022569
[epoch12, step689]: loss 0.024484
[epoch12, step690]: loss 0.025033
[epoch12, step691]: loss 0.024219
[epoch12, step692]: loss 0.022478
[epoch12, step693]: loss 0.027083
[epoch12, step694]: loss 0.022863
[epoch12, step695]: loss 0.026305
[epoch12, step696]: loss 0.025998
[epoch12, step697]: loss 0.026895
[epoch12, step698]: loss 0.024743
[epoch12, step699]: loss 0.023507
[epoch12, step700]: loss 0.021610
[epoch12, step701]: loss 0.025865
[epoch12, step702]: loss 0.021778
[epoch12, step703]: loss 0.022744
[epoch12, step704]: loss 0.025272
[epoch12, step705]: loss 0.025046
[epoch12, step706]: loss 0.023803
[epoch12, step707]: loss 0.024552
[epoch12, step708]: loss 0.025953
[epoch12, step709]: loss 0.027475
[epoch12, step710]: loss 0.023752
[epoch12, step711]: loss 0.023518
[epoch12, step712]: loss 0.026788
[epoch12, step713]: loss 0.026315
[epoch12, step714]: loss 0.021286
[epoch12, step715]: loss 0.023060
[epoch12, step716]: loss 0.025843
[epoch12, step717]: loss 0.023557
[epoch12, step718]: loss 0.024963
[epoch12, step719]: loss 0.032761
[epoch12, step720]: loss 0.024789
[epoch12, step721]: loss 0.023032
[epoch12, step722]: loss 0.030551
[epoch12, step723]: loss 0.026038
[epoch12, step724]: loss 0.022925
[epoch12, step725]: loss 0.027809
[epoch12, step726]: loss 0.022449
[epoch12, step727]: loss 0.024598
[epoch12, step728]: loss 0.026452
[epoch12, step729]: loss 0.021196
[epoch12, step730]: loss 0.022765
[epoch12, step731]: loss 0.025887
[epoch12, step732]: loss 0.025872
[epoch12, step733]: loss 0.023885
[epoch12, step734]: loss 0.022774
[epoch12, step735]: loss 0.027341
[epoch12, step736]: loss 0.025088
[epoch12, step737]: loss 0.026764
[epoch12, step738]: loss 0.020704
[epoch12, step739]: loss 0.025462
[epoch12, step740]: loss 0.022265
[epoch12, step741]: loss 0.025233
[epoch12, step742]: loss 0.021779
[epoch12, step743]: loss 0.023185
[epoch12, step744]: loss 0.023855
[epoch12, step745]: loss 0.024584
[epoch12, step746]: loss 0.025165
[epoch12, step747]: loss 0.027490
[epoch12, step748]: loss 0.025590
[epoch12, step749]: loss 0.026112
[epoch12, step750]: loss 0.027564
[epoch12, step751]: loss 0.021678
[epoch12, step752]: loss 0.025290
[epoch12, step753]: loss 0.025733
[epoch12, step754]: loss 0.022625
[epoch12, step755]: loss 0.026102
[epoch12, step756]: loss 0.023399
[epoch12, step757]: loss 0.020509
[epoch12, step758]: loss 0.025280
[epoch12, step759]: loss 0.023038
[epoch12, step760]: loss 0.024023
[epoch12, step761]: loss 0.026363
[epoch12, step762]: loss 0.021644
[epoch12, step763]: loss 0.025518
[epoch12, step764]: loss 0.023576
[epoch12, step765]: loss 0.025977
[epoch12, step766]: loss 0.024516
[epoch12, step767]: loss 0.026620
[epoch12, step768]: loss 0.021506
[epoch12, step769]: loss 0.026693
[epoch12, step770]: loss 0.026008
[epoch12, step771]: loss 0.023282
[epoch12, step772]: loss 0.028662
[epoch12, step773]: loss 0.026516
[epoch12, step774]: loss 0.024238
[epoch12, step775]: loss 0.020568
[epoch12, step776]: loss 0.025581
[epoch12, step777]: loss 0.023018
[epoch12, step778]: loss 0.028084
[epoch12, step779]: loss 0.023724
[epoch12, step780]: loss 0.020078
[epoch12, step781]: loss 0.024351
[epoch12, step782]: loss 0.022786
[epoch12, step783]: loss 0.019335
[epoch12, step784]: loss 0.020284
[epoch12, step785]: loss 0.021453
[epoch12, step786]: loss 0.024282
[epoch12, step787]: loss 0.023246
[epoch12, step788]: loss 0.024794
[epoch12, step789]: loss 0.022375
[epoch12, step790]: loss 0.023283
[epoch12, step791]: loss 0.026736
[epoch12, step792]: loss 0.025085
[epoch12, step793]: loss 0.026923
[epoch12, step794]: loss 0.020285
[epoch12, step795]: loss 0.025631
[epoch12, step796]: loss 0.027949
[epoch12, step797]: loss 0.027832
[epoch12, step798]: loss 0.027277
[epoch12, step799]: loss 0.025915
[epoch12, step800]: loss 0.021504
[epoch12, step801]: loss 0.021715
[epoch12, step802]: loss 0.022743
[epoch12, step803]: loss 0.026179
[epoch12, step804]: loss 0.027438
[epoch12, step805]: loss 0.028267
[epoch12, step806]: loss 0.021314
[epoch12, step807]: loss 0.020681
[epoch12, step808]: loss 0.022962
[epoch12, step809]: loss 0.023045
[epoch12, step810]: loss 0.025928
[epoch12, step811]: loss 0.025747
[epoch12, step812]: loss 0.024561
[epoch12, step813]: loss 0.023608
[epoch12, step814]: loss 0.025194
[epoch12, step815]: loss 0.025018
[epoch12, step816]: loss 0.024350
[epoch12, step817]: loss 0.024703
[epoch12, step818]: loss 0.022395
[epoch12, step819]: loss 0.020081
[epoch12, step820]: loss 0.023424
[epoch12, step821]: loss 0.021747
[epoch12, step822]: loss 0.030550
[epoch12, step823]: loss 0.024022
[epoch12, step824]: loss 0.026740
[epoch12, step825]: loss 0.025283
[epoch12, step826]: loss 0.024369
[epoch12, step827]: loss 0.026943
[epoch12, step828]: loss 0.028696
[epoch12, step829]: loss 0.026305
[epoch12, step830]: loss 0.022610
[epoch12, step831]: loss 0.026284
[epoch12, step832]: loss 0.020967
[epoch12, step833]: loss 0.029069
[epoch12, step834]: loss 0.025487
[epoch12, step835]: loss 0.020569
[epoch12, step836]: loss 0.026923
[epoch12, step837]: loss 0.025639
[epoch12, step838]: loss 0.026181
[epoch12, step839]: loss 0.028391
[epoch12, step840]: loss 0.020691
[epoch12, step841]: loss 0.024314
[epoch12, step842]: loss 0.027672
[epoch12, step843]: loss 0.024950
[epoch12, step844]: loss 0.025099
[epoch12, step845]: loss 0.021058
[epoch12, step846]: loss 0.025314
[epoch12, step847]: loss 0.026816
[epoch12, step848]: loss 0.024946
[epoch12, step849]: loss 0.025023
[epoch12, step850]: loss 0.023104
[epoch12, step851]: loss 0.023880
[epoch12, step852]: loss 0.023221
[epoch12, step853]: loss 0.029161
[epoch12, step854]: loss 0.022603
[epoch12, step855]: loss 0.027209
[epoch12, step856]: loss 0.022130
[epoch12, step857]: loss 0.025896
[epoch12, step858]: loss 0.024267
[epoch12, step859]: loss 0.023630
[epoch12, step860]: loss 0.022591
[epoch12, step861]: loss 0.023313
[epoch12, step862]: loss 0.023128
[epoch12, step863]: loss 0.020709
[epoch12, step864]: loss 0.026365
[epoch12, step865]: loss 0.023452
[epoch12, step866]: loss 0.025171
[epoch12, step867]: loss 0.026078
[epoch12, step868]: loss 0.026777
[epoch12, step869]: loss 0.023937
[epoch12, step870]: loss 0.031138
[epoch12, step871]: loss 0.021986
[epoch12, step872]: loss 0.025370
[epoch12, step873]: loss 0.025807
[epoch12, step874]: loss 0.023766
[epoch12, step875]: loss 0.024159
[epoch12, step876]: loss 0.024318
[epoch12, step877]: loss 0.019180
[epoch12, step878]: loss 0.023340
[epoch12, step879]: loss 0.027976
[epoch12, step880]: loss 0.025587
[epoch12, step881]: loss 0.022183
[epoch12, step882]: loss 0.024205
[epoch12, step883]: loss 0.023775
[epoch12, step884]: loss 0.026414
[epoch12, step885]: loss 0.025960
[epoch12, step886]: loss 0.026452
[epoch12, step887]: loss 0.024188
[epoch12, step888]: loss 0.024644
[epoch12, step889]: loss 0.023560
[epoch12, step890]: loss 0.023360
[epoch12, step891]: loss 0.025678
[epoch12, step892]: loss 0.021028
[epoch12, step893]: loss 0.024692
[epoch12, step894]: loss 0.024914
[epoch12, step895]: loss 0.022647
[epoch12, step896]: loss 0.021890
[epoch12, step897]: loss 0.023912
[epoch12, step898]: loss 0.025551
[epoch12, step899]: loss 0.028107
[epoch12, step900]: loss 0.027288
[epoch12, step901]: loss 0.025423
[epoch12, step902]: loss 0.023916
[epoch12, step903]: loss 0.024198
[epoch12, step904]: loss 0.028062
[epoch12, step905]: loss 0.027701
[epoch12, step906]: loss 0.022321
[epoch12, step907]: loss 0.023633
[epoch12, step908]: loss 0.022425
[epoch12, step909]: loss 0.025470
[epoch12, step910]: loss 0.023123
[epoch12, step911]: loss 0.025192
[epoch12, step912]: loss 0.023895
[epoch12, step913]: loss 0.024012
[epoch12, step914]: loss 0.030537
[epoch12, step915]: loss 0.024054
[epoch12, step916]: loss 0.023762
[epoch12, step917]: loss 0.025054
[epoch12, step918]: loss 0.028511
[epoch12, step919]: loss 0.024206
[epoch12, step920]: loss 0.027516
[epoch12, step921]: loss 0.024508
[epoch12, step922]: loss 0.023245
[epoch12, step923]: loss 0.022481
[epoch12, step924]: loss 0.021178
[epoch12, step925]: loss 0.025437
[epoch12, step926]: loss 0.026511
[epoch12, step927]: loss 0.025799
[epoch12, step928]: loss 0.024887
[epoch12, step929]: loss 0.027638
[epoch12, step930]: loss 0.025855
[epoch12, step931]: loss 0.027328
[epoch12, step932]: loss 0.021661
[epoch12, step933]: loss 0.028254
[epoch12, step934]: loss 0.021950
[epoch12, step935]: loss 0.021973
[epoch12, step936]: loss 0.022542
[epoch12, step937]: loss 0.027280
[epoch12, step938]: loss 0.025125
[epoch12, step939]: loss 0.020855
[epoch12, step940]: loss 0.022937
[epoch12, step941]: loss 0.026815
[epoch12, step942]: loss 0.025411
[epoch12, step943]: loss 0.023152
[epoch12, step944]: loss 0.027574
[epoch12, step945]: loss 0.020539
[epoch12, step946]: loss 0.025485
[epoch12, step947]: loss 0.028008
[epoch12, step948]: loss 0.019656
[epoch12, step949]: loss 0.022821
[epoch12, step950]: loss 0.026659
[epoch12, step951]: loss 0.029029
[epoch12, step952]: loss 0.025252
[epoch12, step953]: loss 0.027642
[epoch12, step954]: loss 0.022138
[epoch12, step955]: loss 0.036521
[epoch12, step956]: loss 0.051873
[epoch12, step957]: loss 0.045991
[epoch12, step958]: loss 0.043539
[epoch12, step959]: loss 0.047404
[epoch12, step960]: loss 0.043847
[epoch12, step961]: loss 0.045020
[epoch12, step962]: loss 0.043396
[epoch12, step963]: loss 0.042145
[epoch12, step964]: loss 0.042652
[epoch12, step965]: loss 0.042795
[epoch12, step966]: loss 0.040676
[epoch12, step967]: loss 0.038827
[epoch12, step968]: loss 0.041330
[epoch12, step969]: loss 0.040411
[epoch12, step970]: loss 0.039645
[epoch12, step971]: loss 0.038009
[epoch12, step972]: loss 0.039203
[epoch12, step973]: loss 0.038382
[epoch12, step974]: loss 0.040538
[epoch12, step975]: loss 0.037109
[epoch12, step976]: loss 0.036445
[epoch12, step977]: loss 0.040180
[epoch12, step978]: loss 0.038492
[epoch12, step979]: loss 0.037554
[epoch12, step980]: loss 0.035940
[epoch12, step981]: loss 0.038311
[epoch12, step982]: loss 0.038412
[epoch12, step983]: loss 0.039506
[epoch12, step984]: loss 0.035782
[epoch12, step985]: loss 0.036462
[epoch12, step986]: loss 0.040276
[epoch12, step987]: loss 0.038460
[epoch12, step988]: loss 0.037784
[epoch12, step989]: loss 0.036719
[epoch12, step990]: loss 0.037559
[epoch12, step991]: loss 0.038294
[epoch12, step992]: loss 0.038642
[epoch12, step993]: loss 0.036063
[epoch12, step994]: loss 0.035351
[epoch12, step995]: loss 0.039022
[epoch12, step996]: loss 0.037315
[epoch12, step997]: loss 0.037206
[epoch12, step998]: loss 0.036817
[epoch12, step999]: loss 0.037609
[epoch12, step1000]: loss 0.037723
[epoch12, step1001]: loss 0.038676
[epoch12, step1002]: loss 0.036376
[epoch12, step1003]: loss 0.035630
[epoch12, step1004]: loss 0.039341
[epoch12, step1005]: loss 0.036814
[epoch12, step1006]: loss 0.037204
[epoch12, step1007]: loss 0.035527
[epoch12, step1008]: loss 0.036928
[epoch12, step1009]: loss 0.037307
[epoch12, step1010]: loss 0.039277
[epoch12, step1011]: loss 0.035882
[epoch12, step1012]: loss 0.035953
[epoch12, step1013]: loss 0.038957
[epoch12, step1014]: loss 0.038003
[epoch12, step1015]: loss 0.037352
[epoch12, step1016]: loss 0.035574
[epoch12, step1017]: loss 0.036975
[epoch12, step1018]: loss 0.037196
[epoch12, step1019]: loss 0.038647
[epoch12, step1020]: loss 0.035494
[epoch12, step1021]: loss 0.035276
[epoch12, step1022]: loss 0.038533
[epoch12, step1023]: loss 0.037312
[epoch12, step1024]: loss 0.037675
[epoch12, step1025]: loss 0.035332
[epoch12, step1026]: loss 0.036520
[epoch12, step1027]: loss 0.036826
[epoch12, step1028]: loss 0.038493
[epoch12, step1029]: loss 0.035481
[epoch12, step1030]: loss 0.035007
[epoch12, step1031]: loss 0.037683
[epoch12, step1032]: loss 0.037622
[epoch12, step1033]: loss 0.036866
[epoch12, step1034]: loss 0.035279
[epoch12, step1035]: loss 0.036512
[epoch12, step1036]: loss 0.037208
[epoch12, step1037]: loss 0.038095
[epoch12, step1038]: loss 0.035439
[epoch12, step1039]: loss 0.035596
[epoch12, step1040]: loss 0.037927
[epoch12, step1041]: loss 0.036947
[epoch12, step1042]: loss 0.035850
[epoch12, step1043]: loss 0.035511
[epoch12, step1044]: loss 0.036996
[epoch12, step1045]: loss 0.037204
[epoch12, step1046]: loss 0.038514
[epoch12, step1047]: loss 0.035674
[epoch12, step1048]: loss 0.035126
[epoch12, step1049]: loss 0.038572
[epoch12, step1050]: loss 0.037844
[epoch12, step1051]: loss 0.036990
[epoch12, step1052]: loss 0.035785
[epoch12, step1053]: loss 0.037337
[epoch12, step1054]: loss 0.037277
[epoch12, step1055]: loss 0.038019
[epoch12, step1056]: loss 0.035028
[epoch12, step1057]: loss 0.036058
[epoch12, step1058]: loss 0.039473
[epoch12, step1059]: loss 0.037371
[epoch12, step1060]: loss 0.037104
[epoch12, step1061]: loss 0.034921
[epoch12, step1062]: loss 0.037384
[epoch12, step1063]: loss 0.037091
[epoch12, step1064]: loss 0.038292
[epoch12, step1065]: loss 0.035576
[epoch12, step1066]: loss 0.035074
[epoch12, step1067]: loss 0.038455
[epoch12, step1068]: loss 0.035903
[epoch12, step1069]: loss 0.036205
[epoch12, step1070]: loss 0.035432
[epoch12, step1071]: loss 0.037465
[epoch12, step1072]: loss 0.037761
[epoch12, step1073]: loss 0.038296
[epoch12, step1074]: loss 0.035827
[epoch12, step1075]: loss 0.035775
[epoch12, step1076]: loss 0.038779
[epoch12, step1077]: loss 0.037086
[epoch12, step1078]: loss 0.036638
[epoch12, step1079]: loss 0.036352
[epoch12, step1080]: loss 0.037232
[epoch12, step1081]: loss 0.036799
[epoch12, step1082]: loss 0.038118
[epoch12, step1083]: loss 0.036293
[epoch12, step1084]: loss 0.035628
[epoch12, step1085]: loss 0.037996
[epoch12, step1086]: loss 0.036746
[epoch12, step1087]: loss 0.036924
[epoch12, step1088]: loss 0.035238
[epoch12, step1089]: loss 0.037311
[epoch12, step1090]: loss 0.037580
[epoch12, step1091]: loss 0.038502
[epoch12, step1092]: loss 0.035379
[epoch12, step1093]: loss 0.035430
[epoch12, step1094]: loss 0.037651
[epoch12, step1095]: loss 0.036627
[epoch12, step1096]: loss 0.036324
[epoch12, step1097]: loss 0.035358
[epoch12, step1098]: loss 0.037045
[epoch12, step1099]: loss 0.036694
[epoch12, step1100]: loss 0.038846
[epoch12, step1101]: loss 0.035967
[epoch12, step1102]: loss 0.035356
[epoch12, step1103]: loss 0.037987
[epoch12, step1104]: loss 0.036916
[epoch12, step1105]: loss 0.037043
[epoch12, step1106]: loss 0.034501
[epoch12, step1107]: loss 0.037155
[epoch12, step1108]: loss 0.036685
[epoch12, step1109]: loss 0.038688
[epoch12, step1110]: loss 0.036229
[epoch12, step1111]: loss 0.035538
[epoch12, step1112]: loss 0.038780
[epoch12, step1113]: loss 0.036673
[epoch12, step1114]: loss 0.037101
[epoch12, step1115]: loss 0.035643
[epoch12, step1116]: loss 0.037021
[epoch12, step1117]: loss 0.037052
[epoch12, step1118]: loss 0.038100
[epoch12, step1119]: loss 0.035415
[epoch12, step1120]: loss 0.035336
[epoch12, step1121]: loss 0.038318
[epoch12, step1122]: loss 0.036632
[epoch12, step1123]: loss 0.036050
[epoch12, step1124]: loss 0.036131
[epoch12, step1125]: loss 0.037313
[epoch12, step1126]: loss 0.037982
[epoch12, step1127]: loss 0.038364
[epoch12, step1128]: loss 0.035782
[epoch12, step1129]: loss 0.035276
[epoch12, step1130]: loss 0.039232
[epoch12, step1131]: loss 0.037401
[epoch12, step1132]: loss 0.037198
[epoch12, step1133]: loss 0.034953
[epoch12, step1134]: loss 0.036758
[epoch12, step1135]: loss 0.037952
[epoch12, step1136]: loss 0.039127
[epoch12, step1137]: loss 0.035681
[epoch12, step1138]: loss 0.035610
[epoch12, step1139]: loss 0.038418
[epoch12, step1140]: loss 0.036458
[epoch12, step1141]: loss 0.036499
[epoch12, step1142]: loss 0.035152
[epoch12, step1143]: loss 0.036492
[epoch12, step1144]: loss 0.037211
[epoch12, step1145]: loss 0.037718
[epoch12, step1146]: loss 0.035303
[epoch12, step1147]: loss 0.036141
[epoch12, step1148]: loss 0.038507
[epoch12, step1149]: loss 0.036679
[epoch12, step1150]: loss 0.036557
[epoch12, step1151]: loss 0.035946
[epoch12, step1152]: loss 0.037471
[epoch12, step1153]: loss 0.036518
[epoch12, step1154]: loss 0.038660
[epoch12, step1155]: loss 0.035710
[epoch12, step1156]: loss 0.034898
[epoch12, step1157]: loss 0.038247
[epoch12, step1158]: loss 0.037203
[epoch12, step1159]: loss 0.037033
[epoch12, step1160]: loss 0.036218
[epoch12, step1161]: loss 0.037482
[epoch12, step1162]: loss 0.037035
[epoch12, step1163]: loss 0.037534
[epoch12, step1164]: loss 0.035673
[epoch12, step1165]: loss 0.036373
[epoch12, step1166]: loss 0.038636
[epoch12, step1167]: loss 0.036199
[epoch12, step1168]: loss 0.036879
[epoch12, step1169]: loss 0.035349
[epoch12, step1170]: loss 0.037024
[epoch12, step1171]: loss 0.037168
[epoch12, step1172]: loss 0.038405
[epoch12, step1173]: loss 0.035801
[epoch12, step1174]: loss 0.035927
[epoch12, step1175]: loss 0.038458
[epoch12, step1176]: loss 0.036640
[epoch12, step1177]: loss 0.037170
[epoch12, step1178]: loss 0.035521
[epoch12, step1179]: loss 0.036973
[epoch12, step1180]: loss 0.037243
[epoch12, step1181]: loss 0.038696
[epoch12, step1182]: loss 0.034944
[epoch12, step1183]: loss 0.035839
[epoch12, step1184]: loss 0.037830
[epoch12, step1185]: loss 0.037110
[epoch12, step1186]: loss 0.035873
[epoch12, step1187]: loss 0.034683
[epoch12, step1188]: loss 0.036319
[epoch12, step1189]: loss 0.036847
[epoch12, step1190]: loss 0.037895
[epoch12, step1191]: loss 0.036176
[epoch12, step1192]: loss 0.035693
[epoch12, step1193]: loss 0.038531
[epoch12, step1194]: loss 0.036809
[epoch12, step1195]: loss 0.035727
[epoch12, step1196]: loss 0.034697
[epoch12, step1197]: loss 0.037290
[epoch12, step1198]: loss 0.037137
[epoch12, step1199]: loss 0.037794
[epoch12, step1200]: loss 0.035347
[epoch12, step1201]: loss 0.035876
[epoch12, step1202]: loss 0.039203
[epoch12, step1203]: loss 0.037039
[epoch12, step1204]: loss 0.035984
[epoch12, step1205]: loss 0.034995
[epoch12, step1206]: loss 0.036403
[epoch12, step1207]: loss 0.037392
[epoch12, step1208]: loss 0.038744
[epoch12, step1209]: loss 0.034439
[epoch12, step1210]: loss 0.036010
[epoch12, step1211]: loss 0.038247
[epoch12, step1212]: loss 0.036763
[epoch12, step1213]: loss 0.036387
[epoch12, step1214]: loss 0.035474
[epoch12, step1215]: loss 0.037584
[epoch12, step1216]: loss 0.036618
[epoch12, step1217]: loss 0.038690
[epoch12, step1218]: loss 0.035199
[epoch12, step1219]: loss 0.035967
[epoch12, step1220]: loss 0.038613
[epoch12, step1221]: loss 0.036062
[epoch12, step1222]: loss 0.036733
[epoch12, step1223]: loss 0.035573
[epoch12, step1224]: loss 0.037517
[epoch12, step1225]: loss 0.037163
[epoch12, step1226]: loss 0.037936
[epoch12, step1227]: loss 0.035439
[epoch12, step1228]: loss 0.035338
[epoch12, step1229]: loss 0.038219
[epoch12, step1230]: loss 0.037094
[epoch12, step1231]: loss 0.036723
[epoch12, step1232]: loss 0.036411
[epoch12, step1233]: loss 0.036842
[epoch12, step1234]: loss 0.036836
[epoch12, step1235]: loss 0.038520
[epoch12, step1236]: loss 0.035775
[epoch12, step1237]: loss 0.034896
[epoch12, step1238]: loss 0.037739
[epoch12, step1239]: loss 0.037640
[epoch12, step1240]: loss 0.036844
[epoch12, step1241]: loss 0.035089
[epoch12, step1242]: loss 0.036867
[epoch12, step1243]: loss 0.036855
[epoch12, step1244]: loss 0.038662
[epoch12, step1245]: loss 0.035953
[epoch12, step1246]: loss 0.035739
[epoch12, step1247]: loss 0.037545
[epoch12, step1248]: loss 0.036967
[epoch12, step1249]: loss 0.037281
[epoch12, step1250]: loss 0.035236
[epoch12, step1251]: loss 0.037325
[epoch12, step1252]: loss 0.037929
[epoch12, step1253]: loss 0.038415
[epoch12, step1254]: loss 0.035659
[epoch12, step1255]: loss 0.035512
[epoch12, step1256]: loss 0.038728
[epoch12, step1257]: loss 0.037247
[epoch12, step1258]: loss 0.036927
[epoch12, step1259]: loss 0.035473
[epoch12, step1260]: loss 0.037074
[epoch12, step1261]: loss 0.036866
[epoch12, step1262]: loss 0.037359
[epoch12, step1263]: loss 0.036128
[epoch12, step1264]: loss 0.035377
[epoch12, step1265]: loss 0.037459
[epoch12, step1266]: loss 0.036914
[epoch12, step1267]: loss 0.037264
[epoch12, step1268]: loss 0.035560
[epoch12, step1269]: loss 0.037087
[epoch12, step1270]: loss 0.036416
[epoch12, step1271]: loss 0.038475
[epoch12, step1272]: loss 0.035664
[epoch12, step1273]: loss 0.035096
[epoch12, step1274]: loss 0.038317
[epoch12, step1275]: loss 0.037227
[epoch12, step1276]: loss 0.036519
[epoch12, step1277]: loss 0.035606
[epoch12, step1278]: loss 0.037573
[epoch12, step1279]: loss 0.037520
[epoch12, step1280]: loss 0.038642
[epoch12, step1281]: loss 0.035472
[epoch12, step1282]: loss 0.035749
[epoch12, step1283]: loss 0.037824
[epoch12, step1284]: loss 0.036430
[epoch12, step1285]: loss 0.037212
[epoch12, step1286]: loss 0.034922
[epoch12, step1287]: loss 0.037710
[epoch12, step1288]: loss 0.037818
[epoch12, step1289]: loss 0.039103
[epoch12, step1290]: loss 0.035744
[epoch12, step1291]: loss 0.035206
[epoch12, step1292]: loss 0.038909
[epoch12, step1293]: loss 0.036191
[epoch12, step1294]: loss 0.036775
[epoch12, step1295]: loss 0.035975
[epoch12, step1296]: loss 0.037214
[epoch12, step1297]: loss 0.037107
[epoch12, step1298]: loss 0.038854
[epoch12, step1299]: loss 0.035786
[epoch12, step1300]: loss 0.036201
[epoch12, step1301]: loss 0.037475
[epoch12, step1302]: loss 0.036858
[epoch12, step1303]: loss 0.036965
[epoch12, step1304]: loss 0.034728
[epoch12, step1305]: loss 0.037606
[epoch12, step1306]: loss 0.037356
[epoch12, step1307]: loss 0.037795
[epoch12, step1308]: loss 0.035687
[epoch12, step1309]: loss 0.034763
[epoch12, step1310]: loss 0.038213
[epoch12, step1311]: loss 0.035918
[epoch12, step1312]: loss 0.037367
[epoch12, step1313]: loss 0.035544
[epoch12, step1314]: loss 0.036934
[epoch12, step1315]: loss 0.036731
[epoch12, step1316]: loss 0.039619
[epoch12, step1317]: loss 0.035072
[epoch12, step1318]: loss 0.034949
[epoch12, step1319]: loss 0.037771
[epoch12, step1320]: loss 0.037082
[epoch12, step1321]: loss 0.037188
[epoch12, step1322]: loss 0.034983
[epoch12, step1323]: loss 0.037383
[epoch12, step1324]: loss 0.036669
[epoch12, step1325]: loss 0.038125
[epoch12, step1326]: loss 0.035362
[epoch12, step1327]: loss 0.035240
[epoch12, step1328]: loss 0.038366
[epoch12, step1329]: loss 0.036754
[epoch12, step1330]: loss 0.036923
[epoch12, step1331]: loss 0.035123
[epoch12, step1332]: loss 0.036898
[epoch12, step1333]: loss 0.036097
[epoch12, step1334]: loss 0.038594
[epoch12, step1335]: loss 0.036232
[epoch12, step1336]: loss 0.035431
[epoch12, step1337]: loss 0.037725
[epoch12, step1338]: loss 0.036980
[epoch12, step1339]: loss 0.036792
[epoch12, step1340]: loss 0.035067
[epoch12, step1341]: loss 0.037298
[epoch12, step1342]: loss 0.036787
[epoch12, step1343]: loss 0.038441
[epoch12, step1344]: loss 0.035698
[epoch12, step1345]: loss 0.035444
[epoch12, step1346]: loss 0.037903
[epoch12, step1347]: loss 0.037467
[epoch12, step1348]: loss 0.036160
[epoch12, step1349]: loss 0.035389
[epoch12, step1350]: loss 0.037280
[epoch12, step1351]: loss 0.036546
[epoch12, step1352]: loss 0.038011
[epoch12, step1353]: loss 0.035240
[epoch12, step1354]: loss 0.035133
[epoch12, step1355]: loss 0.038390
[epoch12, step1356]: loss 0.036754
[epoch12, step1357]: loss 0.036336
[epoch12, step1358]: loss 0.035213
[epoch12, step1359]: loss 0.036666
[epoch12, step1360]: loss 0.037226
[epoch12, step1361]: loss 0.038614
[epoch12, step1362]: loss 0.036308
[epoch12, step1363]: loss 0.035964
[epoch12, step1364]: loss 0.038261
[epoch12, step1365]: loss 0.036885
[epoch12, step1366]: loss 0.036603
[epoch12, step1367]: loss 0.034525
[epoch12, step1368]: loss 0.037892
[epoch12, step1369]: loss 0.037403
[epoch12, step1370]: loss 0.037986
[epoch12, step1371]: loss 0.035795
[epoch12, step1372]: loss 0.035247
[epoch12, step1373]: loss 0.038464
[epoch12, step1374]: loss 0.037632
[epoch12, step1375]: loss 0.037512
[epoch12, step1376]: loss 0.035103
[epoch12, step1377]: loss 0.036459
[epoch12, step1378]: loss 0.037153
[epoch12, step1379]: loss 0.037733
[epoch12, step1380]: loss 0.035924
[epoch12, step1381]: loss 0.035328
[epoch12, step1382]: loss 0.038471
[epoch12, step1383]: loss 0.036682
[epoch12, step1384]: loss 0.036468
[epoch12, step1385]: loss 0.034746
[epoch12, step1386]: loss 0.037174
[epoch12, step1387]: loss 0.037449
[epoch12, step1388]: loss 0.037306
[epoch12, step1389]: loss 0.034895
[epoch12, step1390]: loss 0.035803
[epoch12, step1391]: loss 0.038027
[epoch12, step1392]: loss 0.036948
[epoch12, step1393]: loss 0.036958
[epoch12, step1394]: loss 0.036005
[epoch12, step1395]: loss 0.037090
[epoch12, step1396]: loss 0.036616
[epoch12, step1397]: loss 0.037862
[epoch12, step1398]: loss 0.035400
[epoch12, step1399]: loss 0.036172
[epoch12, step1400]: loss 0.038618
[epoch12, step1401]: loss 0.036637
[epoch12, step1402]: loss 0.036730
[epoch12, step1403]: loss 0.034443
[epoch12, step1404]: loss 0.036487
[epoch12, step1405]: loss 0.036823
[epoch12, step1406]: loss 0.037986
[epoch12, step1407]: loss 0.036523
[epoch12, step1408]: loss 0.034863
[epoch12, step1409]: loss 0.037936
[epoch12, step1410]: loss 0.036730
[epoch12, step1411]: loss 0.035756
[epoch12, step1412]: loss 0.035286
[epoch12, step1413]: loss 0.037106
[epoch12, step1414]: loss 0.036596
[epoch12, step1415]: loss 0.037881
[epoch12, step1416]: loss 0.035343
[epoch12, step1417]: loss 0.035257
[epoch12, step1418]: loss 0.038164
[epoch12, step1419]: loss 0.037533
[epoch12, step1420]: loss 0.036863
[epoch12, step1421]: loss 0.035795
[epoch12, step1422]: loss 0.037208
[epoch12, step1423]: loss 0.036573
[epoch12, step1424]: loss 0.038446
[epoch12, step1425]: loss 0.034603
[epoch12, step1426]: loss 0.035523
[epoch12, step1427]: loss 0.039131
[epoch12, step1428]: loss 0.037623
[epoch12, step1429]: loss 0.036773
[epoch12, step1430]: loss 0.035281
[epoch12, step1431]: loss 0.037102
[epoch12, step1432]: loss 0.036667
[epoch12, step1433]: loss 0.038257
[epoch12, step1434]: loss 0.035136
[epoch12, step1435]: loss 0.035724
[epoch12, step1436]: loss 0.038484
[epoch12, step1437]: loss 0.037292
[epoch12, step1438]: loss 0.037569
[epoch12, step1439]: loss 0.035033
[epoch12, step1440]: loss 0.037127
[epoch12, step1441]: loss 0.037637
[epoch12, step1442]: loss 0.037465
[epoch12, step1443]: loss 0.035196
[epoch12, step1444]: loss 0.034713
[epoch12, step1445]: loss 0.038661
[epoch12, step1446]: loss 0.037049
[epoch12, step1447]: loss 0.037455
[epoch12, step1448]: loss 0.035216
[epoch12, step1449]: loss 0.036359
[epoch12, step1450]: loss 0.036987
[epoch12, step1451]: loss 0.038413
[epoch12, step1452]: loss 0.035188
[epoch12, step1453]: loss 0.036312
[epoch12, step1454]: loss 0.038697
[epoch12, step1455]: loss 0.037376
[epoch12, step1456]: loss 0.036384
[epoch12, step1457]: loss 0.035884
[epoch12, step1458]: loss 0.037181
[epoch12, step1459]: loss 0.037008
[epoch12, step1460]: loss 0.038688
[epoch12, step1461]: loss 0.036151
[epoch12, step1462]: loss 0.036034
[epoch12, step1463]: loss 0.038237
[epoch12, step1464]: loss 0.037160
[epoch12, step1465]: loss 0.036392
[epoch12, step1466]: loss 0.034952
[epoch12, step1467]: loss 0.036931
[epoch12, step1468]: loss 0.036469
[epoch12, step1469]: loss 0.038123
[epoch12, step1470]: loss 0.035663
[epoch12, step1471]: loss 0.035062
[epoch12, step1472]: loss 0.038031
[epoch12, step1473]: loss 0.036799
[epoch12, step1474]: loss 0.037255
[epoch12, step1475]: loss 0.035102
[epoch12, step1476]: loss 0.037738
[epoch12, step1477]: loss 0.036622
[epoch12, step1478]: loss 0.038286
[epoch12, step1479]: loss 0.035375
[epoch12, step1480]: loss 0.035367
[epoch12, step1481]: loss 0.037437
[epoch12, step1482]: loss 0.036777
[epoch12, step1483]: loss 0.036811
[epoch12, step1484]: loss 0.035555
[epoch12, step1485]: loss 0.036839
[epoch12, step1486]: loss 0.035985
[epoch12, step1487]: loss 0.037928
[epoch12, step1488]: loss 0.035501
[epoch12, step1489]: loss 0.035186
[epoch12, step1490]: loss 0.038201
[epoch12, step1491]: loss 0.036864
[epoch12, step1492]: loss 0.036450
[epoch12, step1493]: loss 0.035296
[epoch12, step1494]: loss 0.037069
[epoch12, step1495]: loss 0.036618
[epoch12, step1496]: loss 0.037336
[epoch12, step1497]: loss 0.035752
[epoch12, step1498]: loss 0.035797
[epoch12, step1499]: loss 0.037666
[epoch12, step1500]: loss 0.037224
[epoch12, step1501]: loss 0.036809
[epoch12, step1502]: loss 0.035010
[epoch12, step1503]: loss 0.036840
[epoch12, step1504]: loss 0.036444
[epoch12, step1505]: loss 0.038345
[epoch12, step1506]: loss 0.034903
[epoch12, step1507]: loss 0.035649
[epoch12, step1508]: loss 0.038663
[epoch12, step1509]: loss 0.036504
[epoch12, step1510]: loss 0.036259
[epoch12, step1511]: loss 0.036048
[epoch12, step1512]: loss 0.037389
[epoch12, step1513]: loss 0.035677
[epoch12, step1514]: loss 0.038201
[epoch12, step1515]: loss 0.035954
[epoch12, step1516]: loss 0.035396

[epoch12]: avg loss 0.033869

[epoch13, step1]: loss 0.033681
[epoch13, step2]: loss 0.037799
[epoch13, step3]: loss 0.037969
[epoch13, step4]: loss 0.035405
[epoch13, step5]: loss 0.035837
[epoch13, step6]: loss 0.038324
[epoch13, step7]: loss 0.036247
[epoch13, step8]: loss 0.038517
[epoch13, step9]: loss 0.034993
[epoch13, step10]: loss 0.036494
[epoch13, step11]: loss 0.038195
[epoch13, step12]: loss 0.038003
[epoch13, step13]: loss 0.035526
[epoch13, step14]: loss 0.035767
[epoch13, step15]: loss 0.038039
[epoch13, step16]: loss 0.036029
[epoch13, step17]: loss 0.038433
[epoch13, step18]: loss 0.035973
[epoch13, step19]: loss 0.036019
[epoch13, step20]: loss 0.038884
[epoch13, step21]: loss 0.037981
[epoch13, step22]: loss 0.035160
[epoch13, step23]: loss 0.034903
[epoch13, step24]: loss 0.038372
[epoch13, step25]: loss 0.035485
[epoch13, step26]: loss 0.037902
[epoch13, step27]: loss 0.034737
[epoch13, step28]: loss 0.036417
[epoch13, step29]: loss 0.038597
[epoch13, step30]: loss 0.038801
[epoch13, step31]: loss 0.034906
[epoch13, step32]: loss 0.036002
[epoch13, step33]: loss 0.038683
[epoch13, step34]: loss 0.036562
[epoch13, step35]: loss 0.038559
[epoch13, step36]: loss 0.035149
[epoch13, step37]: loss 0.035973
[epoch13, step38]: loss 0.038007
[epoch13, step39]: loss 0.038050
[epoch13, step40]: loss 0.035690
[epoch13, step41]: loss 0.035039
[epoch13, step42]: loss 0.038451
[epoch13, step43]: loss 0.035846
[epoch13, step44]: loss 0.038981
[epoch13, step45]: loss 0.035207
[epoch13, step46]: loss 0.036023
[epoch13, step47]: loss 0.037659
[epoch13, step48]: loss 0.037710
[epoch13, step49]: loss 0.033964
[epoch13, step50]: loss 0.035523
[epoch13, step51]: loss 0.038081
[epoch13, step52]: loss 0.035677
[epoch13, step53]: loss 0.038695
[epoch13, step54]: loss 0.034977
[epoch13, step55]: loss 0.036366
[epoch13, step56]: loss 0.038955
[epoch13, step57]: loss 0.038533
[epoch13, step58]: loss 0.035300
[epoch13, step59]: loss 0.034548
[epoch13, step60]: loss 0.038709
[epoch13, step61]: loss 0.035134
[epoch13, step62]: loss 0.037738
[epoch13, step63]: loss 0.034707
[epoch13, step64]: loss 0.035629
[epoch13, step65]: loss 0.038314
[epoch13, step66]: loss 0.038083
[epoch13, step67]: loss 0.035543
[epoch13, step68]: loss 0.035520
[epoch13, step69]: loss 0.038078
[epoch13, step70]: loss 0.035710
[epoch13, step71]: loss 0.037851
[epoch13, step72]: loss 0.035235
[epoch13, step73]: loss 0.036026
[epoch13, step74]: loss 0.038067
[epoch13, step75]: loss 0.038510
[epoch13, step76]: loss 0.035900
[epoch13, step77]: loss 0.036039
[epoch13, step78]: loss 0.038406
[epoch13, step79]: loss 0.035212
[epoch13, step80]: loss 0.038986
[epoch13, step81]: loss 0.035219
[epoch13, step82]: loss 0.035450
[epoch13, step83]: loss 0.037897
[epoch13, step84]: loss 0.038272
[epoch13, step85]: loss 0.036091
[epoch13, step86]: loss 0.035995
[epoch13, step87]: loss 0.039120
[epoch13, step88]: loss 0.034748
[epoch13, step89]: loss 0.038134
[epoch13, step90]: loss 0.035675
[epoch13, step91]: loss 0.035439
[epoch13, step92]: loss 0.038319
[epoch13, step93]: loss 0.038186
[epoch13, step94]: loss 0.035185
[epoch13, step95]: loss 0.036000
[epoch13, step96]: loss 0.037888
[epoch13, step97]: loss 0.036535
[epoch13, step98]: loss 0.038245
[epoch13, step99]: loss 0.035333
[epoch13, step100]: loss 0.034842
[epoch13, step101]: loss 0.038670
[epoch13, step102]: loss 0.038053
[epoch13, step103]: loss 0.035305
[epoch13, step104]: loss 0.035489
[epoch13, step105]: loss 0.038680
[epoch13, step106]: loss 0.035978
[epoch13, step107]: loss 0.038505
[epoch13, step108]: loss 0.035600
[epoch13, step109]: loss 0.035617
[epoch13, step110]: loss 0.038796
[epoch13, step111]: loss 0.037873
[epoch13, step112]: loss 0.035587
[epoch13, step113]: loss 0.036338
[epoch13, step114]: loss 0.037975
[epoch13, step115]: loss 0.035823
[epoch13, step116]: loss 0.038927
[epoch13, step117]: loss 0.035255
[epoch13, step118]: loss 0.036629
[epoch13, step119]: loss 0.038549
[epoch13, step120]: loss 0.038459
[epoch13, step121]: loss 0.035302
[epoch13, step122]: loss 0.035529
[epoch13, step123]: loss 0.038532
[epoch13, step124]: loss 0.036165
[epoch13, step125]: loss 0.038696
[epoch13, step126]: loss 0.035170
[epoch13, step127]: loss 0.035614
[epoch13, step128]: loss 0.038112
[epoch13, step129]: loss 0.038087
[epoch13, step130]: loss 0.035647
[epoch13, step131]: loss 0.034922
[epoch13, step132]: loss 0.038299
[epoch13, step133]: loss 0.035645
[epoch13, step134]: loss 0.037634
[epoch13, step135]: loss 0.035821
[epoch13, step136]: loss 0.036853
[epoch13, step137]: loss 0.037916
[epoch13, step138]: loss 0.038085
[epoch13, step139]: loss 0.035315
[epoch13, step140]: loss 0.036007
[epoch13, step141]: loss 0.038482
[epoch13, step142]: loss 0.035767
[epoch13, step143]: loss 0.037799
[epoch13, step144]: loss 0.035572
[epoch13, step145]: loss 0.035837
[epoch13, step146]: loss 0.038188
[epoch13, step147]: loss 0.039415
[epoch13, step148]: loss 0.035090
[epoch13, step149]: loss 0.035197
[epoch13, step150]: loss 0.038115
[epoch13, step151]: loss 0.035802
[epoch13, step152]: loss 0.038123
[epoch13, step153]: loss 0.035287
[epoch13, step154]: loss 0.035629
[epoch13, step155]: loss 0.038087
[epoch13, step156]: loss 0.037802
[epoch13, step157]: loss 0.035516
[epoch13, step158]: loss 0.035876
[epoch13, step159]: loss 0.038343
[epoch13, step160]: loss 0.036039
[epoch13, step161]: loss 0.038641
[epoch13, step162]: loss 0.035571
[epoch13, step163]: loss 0.035747
[epoch13, step164]: loss 0.038416
[epoch13, step165]: loss 0.038194
[epoch13, step166]: loss 0.035754
[epoch13, step167]: loss 0.035183
[epoch13, step168]: loss 0.038883
[epoch13, step169]: loss 0.035542
[epoch13, step170]: loss 0.038671
[epoch13, step171]: loss 0.035688
[epoch13, step172]: loss 0.035993
[epoch13, step173]: loss 0.038543
[epoch13, step174]: loss 0.037966
[epoch13, step175]: loss 0.036169
[epoch13, step176]: loss 0.035785
[epoch13, step177]: loss 0.038584
[epoch13, step178]: loss 0.035773
[epoch13, step179]: loss 0.037410
[epoch13, step180]: loss 0.035560
[epoch13, step181]: loss 0.036035
[epoch13, step182]: loss 0.038737
[epoch13, step183]: loss 0.038825
[epoch13, step184]: loss 0.036400
[epoch13, step185]: loss 0.035734
[epoch13, step186]: loss 0.038447
[epoch13, step187]: loss 0.035972
[epoch13, step188]: loss 0.038048
[epoch13, step189]: loss 0.035339
[epoch13, step190]: loss 0.035208
[epoch13, step191]: loss 0.038270
[epoch13, step192]: loss 0.038704
[epoch13, step193]: loss 0.033676
[epoch13, step194]: loss 0.034723
[epoch13, step195]: loss 0.038581
[epoch13, step196]: loss 0.035872
[epoch13, step197]: loss 0.038095
[epoch13, step198]: loss 0.034534
[epoch13, step199]: loss 0.035893
[epoch13, step200]: loss 0.038665
[epoch13, step201]: loss 0.038641
[epoch13, step202]: loss 0.035067
[epoch13, step203]: loss 0.035609
[epoch13, step204]: loss 0.038749
[epoch13, step205]: loss 0.035386
[epoch13, step206]: loss 0.037975
[epoch13, step207]: loss 0.035231
[epoch13, step208]: loss 0.036333
[epoch13, step209]: loss 0.038523
[epoch13, step210]: loss 0.039116
[epoch13, step211]: loss 0.036152
[epoch13, step212]: loss 0.035980
[epoch13, step213]: loss 0.037976
[epoch13, step214]: loss 0.035151
[epoch13, step215]: loss 0.038563
[epoch13, step216]: loss 0.035600
[epoch13, step217]: loss 0.035146
[epoch13, step218]: loss 0.038535
[epoch13, step219]: loss 0.037988
[epoch13, step220]: loss 0.035775
[epoch13, step221]: loss 0.035820
[epoch13, step222]: loss 0.038744
[epoch13, step223]: loss 0.035936
[epoch13, step224]: loss 0.037817
[epoch13, step225]: loss 0.035281
[epoch13, step226]: loss 0.035547
[epoch13, step227]: loss 0.037311
[epoch13, step228]: loss 0.038875
[epoch13, step229]: loss 0.034658
[epoch13, step230]: loss 0.035944
[epoch13, step231]: loss 0.038947
[epoch13, step232]: loss 0.035567
[epoch13, step233]: loss 0.037586
[epoch13, step234]: loss 0.034888
[epoch13, step235]: loss 0.036082
[epoch13, step236]: loss 0.038298
[epoch13, step237]: loss 0.038275
[epoch13, step238]: loss 0.035272
[epoch13, step239]: loss 0.034853
[epoch13, step240]: loss 0.037788
[epoch13, step241]: loss 0.036233
[epoch13, step242]: loss 0.038080
[epoch13, step243]: loss 0.036073
[epoch13, step244]: loss 0.035600
[epoch13, step245]: loss 0.037781
[epoch13, step246]: loss 0.038217
[epoch13, step247]: loss 0.035761
[epoch13, step248]: loss 0.035249
[epoch13, step249]: loss 0.037736
[epoch13, step250]: loss 0.036188
[epoch13, step251]: loss 0.038711
[epoch13, step252]: loss 0.035804
[epoch13, step253]: loss 0.035355
[epoch13, step254]: loss 0.038012
[epoch13, step255]: loss 0.038553
[epoch13, step256]: loss 0.035292
[epoch13, step257]: loss 0.035282
[epoch13, step258]: loss 0.038880
[epoch13, step259]: loss 0.035947
[epoch13, step260]: loss 0.037751
[epoch13, step261]: loss 0.036107
[epoch13, step262]: loss 0.036168
[epoch13, step263]: loss 0.037777
[epoch13, step264]: loss 0.037990
[epoch13, step265]: loss 0.035730
[epoch13, step266]: loss 0.035492
[epoch13, step267]: loss 0.037627
[epoch13, step268]: loss 0.035681
[epoch13, step269]: loss 0.038306
[epoch13, step270]: loss 0.034884
[epoch13, step271]: loss 0.035911
[epoch13, step272]: loss 0.038171
[epoch13, step273]: loss 0.037921
[epoch13, step274]: loss 0.035938
[epoch13, step275]: loss 0.035055
[epoch13, step276]: loss 0.038107
[epoch13, step277]: loss 0.036277
[epoch13, step278]: loss 0.038431
[epoch13, step279]: loss 0.034975
[epoch13, step280]: loss 0.035905
[epoch13, step281]: loss 0.038220
[epoch13, step282]: loss 0.038790
[epoch13, step283]: loss 0.035162
[epoch13, step284]: loss 0.035012
[epoch13, step285]: loss 0.039108
[epoch13, step286]: loss 0.035035
[epoch13, step287]: loss 0.038513
[epoch13, step288]: loss 0.035014
[epoch13, step289]: loss 0.036553
[epoch13, step290]: loss 0.038333
[epoch13, step291]: loss 0.038476
[epoch13, step292]: loss 0.034701
[epoch13, step293]: loss 0.035145
[epoch13, step294]: loss 0.037727
[epoch13, step295]: loss 0.035266
[epoch13, step296]: loss 0.039023
[epoch13, step297]: loss 0.035051
[epoch13, step298]: loss 0.036143
[epoch13, step299]: loss 0.037345
[epoch13, step300]: loss 0.038489
[epoch13, step301]: loss 0.035517
[epoch13, step302]: loss 0.035845
[epoch13, step303]: loss 0.038653
[epoch13, step304]: loss 0.035486
[epoch13, step305]: loss 0.037973
[epoch13, step306]: loss 0.035390
[epoch13, step307]: loss 0.035557
[epoch13, step308]: loss 0.038723
[epoch13, step309]: loss 0.038627
[epoch13, step310]: loss 0.035639
[epoch13, step311]: loss 0.035884
[epoch13, step312]: loss 0.037912
[epoch13, step313]: loss 0.036112
[epoch13, step314]: loss 0.038145
[epoch13, step315]: loss 0.036290
[epoch13, step316]: loss 0.035508
[epoch13, step317]: loss 0.038627
[epoch13, step318]: loss 0.038287
[epoch13, step319]: loss 0.034988
[epoch13, step320]: loss 0.034581
[epoch13, step321]: loss 0.037874
[epoch13, step322]: loss 0.035618
[epoch13, step323]: loss 0.037614
[epoch13, step324]: loss 0.036254
[epoch13, step325]: loss 0.035874
[epoch13, step326]: loss 0.037970
[epoch13, step327]: loss 0.037529
[epoch13, step328]: loss 0.035666
[epoch13, step329]: loss 0.035206
[epoch13, step330]: loss 0.037757
[epoch13, step331]: loss 0.035895
[epoch13, step332]: loss 0.037585
[epoch13, step333]: loss 0.035270
[epoch13, step334]: loss 0.035867
[epoch13, step335]: loss 0.038263
[epoch13, step336]: loss 0.039008
[epoch13, step337]: loss 0.035942
[epoch13, step338]: loss 0.035123
[epoch13, step339]: loss 0.038277
[epoch13, step340]: loss 0.036409
[epoch13, step341]: loss 0.037704
[epoch13, step342]: loss 0.035052
[epoch13, step343]: loss 0.036008
[epoch13, step344]: loss 0.037735
[epoch13, step345]: loss 0.037468
[epoch13, step346]: loss 0.035042
[epoch13, step347]: loss 0.035083
[epoch13, step348]: loss 0.038380
[epoch13, step349]: loss 0.036236
[epoch13, step350]: loss 0.037691
[epoch13, step351]: loss 0.034629
[epoch13, step352]: loss 0.035575
[epoch13, step353]: loss 0.037976
[epoch13, step354]: loss 0.037270
[epoch13, step355]: loss 0.034452
[epoch13, step356]: loss 0.036066
[epoch13, step357]: loss 0.038306
[epoch13, step358]: loss 0.034298
[epoch13, step359]: loss 0.039035
[epoch13, step360]: loss 0.034120
[epoch13, step361]: loss 0.035253
[epoch13, step362]: loss 0.038912
[epoch13, step363]: loss 0.037842
[epoch13, step364]: loss 0.035419
[epoch13, step365]: loss 0.035158
[epoch13, step366]: loss 0.038581
[epoch13, step367]: loss 0.035851
[epoch13, step368]: loss 0.037498
[epoch13, step369]: loss 0.035079
[epoch13, step370]: loss 0.036150
[epoch13, step371]: loss 0.038871
[epoch13, step372]: loss 0.037797
[epoch13, step373]: loss 0.034902
[epoch13, step374]: loss 0.034695
[epoch13, step375]: loss 0.038818
[epoch13, step376]: loss 0.035812
[epoch13, step377]: loss 0.038282
[epoch13, step378]: loss 0.035791
[epoch13, step379]: loss 0.036320
[epoch13, step380]: loss 0.038713
[epoch13, step381]: loss 0.037956
[epoch13, step382]: loss 0.035833
[epoch13, step383]: loss 0.034579
[epoch13, step384]: loss 0.037583
[epoch13, step385]: loss 0.035626
[epoch13, step386]: loss 0.038359
[epoch13, step387]: loss 0.035345
[epoch13, step388]: loss 0.036455
[epoch13, step389]: loss 0.038126
[epoch13, step390]: loss 0.039153
[epoch13, step391]: loss 0.035006
[epoch13, step392]: loss 0.035925
[epoch13, step393]: loss 0.037816
[epoch13, step394]: loss 0.035710
[epoch13, step395]: loss 0.037792
[epoch13, step396]: loss 0.035292
[epoch13, step397]: loss 0.035332
[epoch13, step398]: loss 0.038313
[epoch13, step399]: loss 0.038073
[epoch13, step400]: loss 0.035068
[epoch13, step401]: loss 0.035217
[epoch13, step402]: loss 0.038164
[epoch13, step403]: loss 0.035591
[epoch13, step404]: loss 0.038534
[epoch13, step405]: loss 0.035647
[epoch13, step406]: loss 0.035939
[epoch13, step407]: loss 0.037955
[epoch13, step408]: loss 0.038257
[epoch13, step409]: loss 0.036724
[epoch13, step410]: loss 0.036047
[epoch13, step411]: loss 0.038069
[epoch13, step412]: loss 0.035205
[epoch13, step413]: loss 0.038128
[epoch13, step414]: loss 0.035030
[epoch13, step415]: loss 0.035918
[epoch13, step416]: loss 0.037514
[epoch13, step417]: loss 0.038306
[epoch13, step418]: loss 0.035272
[epoch13, step419]: loss 0.034610
[epoch13, step420]: loss 0.038327
[epoch13, step421]: loss 0.035432
[epoch13, step422]: loss 0.038036
[epoch13, step423]: loss 0.035342
[epoch13, step424]: loss 0.035801
[epoch13, step425]: loss 0.038275
[epoch13, step426]: loss 0.038507
[epoch13, step427]: loss 0.035795
[epoch13, step428]: loss 0.035323
[epoch13, step429]: loss 0.038812
[epoch13, step430]: loss 0.035616
[epoch13, step431]: loss 0.038480
[epoch13, step432]: loss 0.035200
[epoch13, step433]: loss 0.036507
[epoch13, step434]: loss 0.038083
[epoch13, step435]: loss 0.038577
[epoch13, step436]: loss 0.035174
[epoch13, step437]: loss 0.035558
[epoch13, step438]: loss 0.038785
[epoch13, step439]: loss 0.035901
[epoch13, step440]: loss 0.038148
[epoch13, step441]: loss 0.035528
[epoch13, step442]: loss 0.035617
[epoch13, step443]: loss 0.038624
[epoch13, step444]: loss 0.037893
[epoch13, step445]: loss 0.035868
[epoch13, step446]: loss 0.035767
[epoch13, step447]: loss 0.038879
[epoch13, step448]: loss 0.035807
[epoch13, step449]: loss 0.037952
[epoch13, step450]: loss 0.034748
[epoch13, step451]: loss 0.035617
[epoch13, step452]: loss 0.037523
[epoch13, step453]: loss 0.038358
[epoch13, step454]: loss 0.035423
[epoch13, step455]: loss 0.035729
[epoch13, step456]: loss 0.037620
[epoch13, step457]: loss 0.036293
[epoch13, step458]: loss 0.037825
[epoch13, step459]: loss 0.035970
[epoch13, step460]: loss 0.036010
[epoch13, step461]: loss 0.038844
[epoch13, step462]: loss 0.037592
[epoch13, step463]: loss 0.035617
[epoch13, step464]: loss 0.035329
[epoch13, step465]: loss 0.039542
[epoch13, step466]: loss 0.035566
[epoch13, step467]: loss 0.037941
[epoch13, step468]: loss 0.035318
[epoch13, step469]: loss 0.035858
[epoch13, step470]: loss 0.038407
[epoch13, step471]: loss 0.037692
[epoch13, step472]: loss 0.035893
[epoch13, step473]: loss 0.034992
[epoch13, step474]: loss 0.038060
[epoch13, step475]: loss 0.035813
[epoch13, step476]: loss 0.038570
[epoch13, step477]: loss 0.035127
[epoch13, step478]: loss 0.035157
[epoch13, step479]: loss 0.038025
[epoch13, step480]: loss 0.037479
[epoch13, step481]: loss 0.035101
[epoch13, step482]: loss 0.034835
[epoch13, step483]: loss 0.038613
[epoch13, step484]: loss 0.035847
[epoch13, step485]: loss 0.038339
[epoch13, step486]: loss 0.035652
[epoch13, step487]: loss 0.035200
[epoch13, step488]: loss 0.038607
[epoch13, step489]: loss 0.037453
[epoch13, step490]: loss 0.035880
[epoch13, step491]: loss 0.035590
[epoch13, step492]: loss 0.037872
[epoch13, step493]: loss 0.035406
[epoch13, step494]: loss 0.037576
[epoch13, step495]: loss 0.036467
[epoch13, step496]: loss 0.035990
[epoch13, step497]: loss 0.038331
[epoch13, step498]: loss 0.038182
[epoch13, step499]: loss 0.035751
[epoch13, step500]: loss 0.034889
[epoch13, step501]: loss 0.037805
[epoch13, step502]: loss 0.035447
[epoch13, step503]: loss 0.038390
[epoch13, step504]: loss 0.035032
[epoch13, step505]: loss 0.034853
[epoch13, step506]: loss 0.038595
[epoch13, step507]: loss 0.038509
[epoch13, step508]: loss 0.035929
[epoch13, step509]: loss 0.035279
[epoch13, step510]: loss 0.038353
[epoch13, step511]: loss 0.036113
[epoch13, step512]: loss 0.038507
[epoch13, step513]: loss 0.035544
[epoch13, step514]: loss 0.036015
[epoch13, step515]: loss 0.038172
[epoch13, step516]: loss 0.038636
[epoch13, step517]: loss 0.035541
[epoch13, step518]: loss 0.035523
[epoch13, step519]: loss 0.038348
[epoch13, step520]: loss 0.035115
[epoch13, step521]: loss 0.037926
[epoch13, step522]: loss 0.035031
[epoch13, step523]: loss 0.035700
[epoch13, step524]: loss 0.037482
[epoch13, step525]: loss 0.038431
[epoch13, step526]: loss 0.035552
[epoch13, step527]: loss 0.035037
[epoch13, step528]: loss 0.038348
[epoch13, step529]: loss 0.035289
[epoch13, step530]: loss 0.038502
[epoch13, step531]: loss 0.035067
[epoch13, step532]: loss 0.035473
[epoch13, step533]: loss 0.039103
[epoch13, step534]: loss 0.038025
[epoch13, step535]: loss 0.036179
[epoch13, step536]: loss 0.035648
[epoch13, step537]: loss 0.038417
[epoch13, step538]: loss 0.035723
[epoch13, step539]: loss 0.037904
[epoch13, step540]: loss 0.034890
[epoch13, step541]: loss 0.035259
[epoch13, step542]: loss 0.038177
[epoch13, step543]: loss 0.037897
[epoch13, step544]: loss 0.035440
[epoch13, step545]: loss 0.034619
[epoch13, step546]: loss 0.038768
[epoch13, step547]: loss 0.035514
[epoch13, step548]: loss 0.038097
[epoch13, step549]: loss 0.035643
[epoch13, step550]: loss 0.035732
[epoch13, step551]: loss 0.038085
[epoch13, step552]: loss 0.037526
[epoch13, step553]: loss 0.035914
[epoch13, step554]: loss 0.035226
[epoch13, step555]: loss 0.037838
[epoch13, step556]: loss 0.035455
[epoch13, step557]: loss 0.037572
[epoch13, step558]: loss 0.035507
[epoch13, step559]: loss 0.035263
[epoch13, step560]: loss 0.038408
[epoch13, step561]: loss 0.037908
[epoch13, step562]: loss 0.035432
[epoch13, step563]: loss 0.028999
[epoch13, step564]: loss 0.029081
[epoch13, step565]: loss 0.027681
[epoch13, step566]: loss 0.034239
[epoch13, step567]: loss 0.026418
[epoch13, step568]: loss 0.025422
[epoch13, step569]: loss 0.022724
[epoch13, step570]: loss 0.030533
[epoch13, step571]: loss 0.026809
[epoch13, step572]: loss 0.025673
[epoch13, step573]: loss 0.028314
[epoch13, step574]: loss 0.027524
[epoch13, step575]: loss 0.020581
[epoch13, step576]: loss 0.021514
[epoch13, step577]: loss 0.025813
[epoch13, step578]: loss 0.018597
[epoch13, step579]: loss 0.028216
[epoch13, step580]: loss 0.020063
[epoch13, step581]: loss 0.025439
[epoch13, step582]: loss 0.024868
[epoch13, step583]: loss 0.021623
[epoch13, step584]: loss 0.023567
[epoch13, step585]: loss 0.025864
[epoch13, step586]: loss 0.021450
[epoch13, step587]: loss 0.027340
[epoch13, step588]: loss 0.022834
[epoch13, step589]: loss 0.022708
[epoch13, step590]: loss 0.027123
[epoch13, step591]: loss 0.020457
[epoch13, step592]: loss 0.025586
[epoch13, step593]: loss 0.021933
[epoch13, step594]: loss 0.025865
[epoch13, step595]: loss 0.026414
[epoch13, step596]: loss 0.021997
[epoch13, step597]: loss 0.024885
[epoch13, step598]: loss 0.026532
[epoch13, step599]: loss 0.024881
[epoch13, step600]: loss 0.027004
[epoch13, step601]: loss 0.019509
[epoch13, step602]: loss 0.022518
[epoch13, step603]: loss 0.025724
[epoch13, step604]: loss 0.026492
[epoch13, step605]: loss 0.025339
[epoch13, step606]: loss 0.024910
[epoch13, step607]: loss 0.026792
[epoch13, step608]: loss 0.025564
[epoch13, step609]: loss 0.026389
[epoch13, step610]: loss 0.025861
[epoch13, step611]: loss 0.026170
[epoch13, step612]: loss 0.025486
[epoch13, step613]: loss 0.019326
[epoch13, step614]: loss 0.025103
[epoch13, step615]: loss 0.028092
[epoch13, step616]: loss 0.024093
[epoch13, step617]: loss 0.023437
[epoch13, step618]: loss 0.025655
[epoch13, step619]: loss 0.026880
[epoch13, step620]: loss 0.024361
[epoch13, step621]: loss 0.026193
[epoch13, step622]: loss 0.020343
[epoch13, step623]: loss 0.024703
[epoch13, step624]: loss 0.026345
[epoch13, step625]: loss 0.025868
[epoch13, step626]: loss 0.028092
[epoch13, step627]: loss 0.022723
[epoch13, step628]: loss 0.025460
[epoch13, step629]: loss 0.020760
[epoch13, step630]: loss 0.023213
[epoch13, step631]: loss 0.030977
[epoch13, step632]: loss 0.023294
[epoch13, step633]: loss 0.024748
[epoch13, step634]: loss 0.026963
[epoch13, step635]: loss 0.025446
[epoch13, step636]: loss 0.020612
[epoch13, step637]: loss 0.027030
[epoch13, step638]: loss 0.026874
[epoch13, step639]: loss 0.022961
[epoch13, step640]: loss 0.029473
[epoch13, step641]: loss 0.030143
[epoch13, step642]: loss 0.024919
[epoch13, step643]: loss 0.025613
[epoch13, step644]: loss 0.025735
[epoch13, step645]: loss 0.023572
[epoch13, step646]: loss 0.026204
[epoch13, step647]: loss 0.023685
[epoch13, step648]: loss 0.022951
[epoch13, step649]: loss 0.028457
[epoch13, step650]: loss 0.021933
[epoch13, step651]: loss 0.025813
[epoch13, step652]: loss 0.026578
[epoch13, step653]: loss 0.027861
[epoch13, step654]: loss 0.023065
[epoch13, step655]: loss 0.024189
[epoch13, step656]: loss 0.021464
[epoch13, step657]: loss 0.027650
[epoch13, step658]: loss 0.025267
[epoch13, step659]: loss 0.027617
[epoch13, step660]: loss 0.024034
[epoch13, step661]: loss 0.026567
[epoch13, step662]: loss 0.024056
[epoch13, step663]: loss 0.021108
[epoch13, step664]: loss 0.024884
[epoch13, step665]: loss 0.027543
[epoch13, step666]: loss 0.026699
[epoch13, step667]: loss 0.026343
[epoch13, step668]: loss 0.022257
[epoch13, step669]: loss 0.026474
[epoch13, step670]: loss 0.026853
[epoch13, step671]: loss 0.021600
[epoch13, step672]: loss 0.023666
[epoch13, step673]: loss 0.022118
[epoch13, step674]: loss 0.021237
[epoch13, step675]: loss 0.019986
[epoch13, step676]: loss 0.024642
[epoch13, step677]: loss 0.025169
[epoch13, step678]: loss 0.023202
[epoch13, step679]: loss 0.023827
[epoch13, step680]: loss 0.030530
[epoch13, step681]: loss 0.021892
[epoch13, step682]: loss 0.026285
[epoch13, step683]: loss 0.026015
[epoch13, step684]: loss 0.024718
[epoch13, step685]: loss 0.024237
[epoch13, step686]: loss 0.026991
[epoch13, step687]: loss 0.026700
[epoch13, step688]: loss 0.022446
[epoch13, step689]: loss 0.024505
[epoch13, step690]: loss 0.025085
[epoch13, step691]: loss 0.024235
[epoch13, step692]: loss 0.022353
[epoch13, step693]: loss 0.027152
[epoch13, step694]: loss 0.022910
[epoch13, step695]: loss 0.026289
[epoch13, step696]: loss 0.025839
[epoch13, step697]: loss 0.026825
[epoch13, step698]: loss 0.024728
[epoch13, step699]: loss 0.023482
[epoch13, step700]: loss 0.021583
[epoch13, step701]: loss 0.025991
[epoch13, step702]: loss 0.021776
[epoch13, step703]: loss 0.022875
[epoch13, step704]: loss 0.025282
[epoch13, step705]: loss 0.024876
[epoch13, step706]: loss 0.023664
[epoch13, step707]: loss 0.024590
[epoch13, step708]: loss 0.026021
[epoch13, step709]: loss 0.027327
[epoch13, step710]: loss 0.023763
[epoch13, step711]: loss 0.023553
[epoch13, step712]: loss 0.026821
[epoch13, step713]: loss 0.026267
[epoch13, step714]: loss 0.021329
[epoch13, step715]: loss 0.023013
[epoch13, step716]: loss 0.025736
[epoch13, step717]: loss 0.023606
[epoch13, step718]: loss 0.024970
[epoch13, step719]: loss 0.032796
[epoch13, step720]: loss 0.024748
[epoch13, step721]: loss 0.023038
[epoch13, step722]: loss 0.030621
[epoch13, step723]: loss 0.026007
[epoch13, step724]: loss 0.022880
[epoch13, step725]: loss 0.027871
[epoch13, step726]: loss 0.022370
[epoch13, step727]: loss 0.024634
[epoch13, step728]: loss 0.026393
[epoch13, step729]: loss 0.021149
[epoch13, step730]: loss 0.022651
[epoch13, step731]: loss 0.025850
[epoch13, step732]: loss 0.025867
[epoch13, step733]: loss 0.023937
[epoch13, step734]: loss 0.022727
[epoch13, step735]: loss 0.027390
[epoch13, step736]: loss 0.025166
[epoch13, step737]: loss 0.026593
[epoch13, step738]: loss 0.020675
[epoch13, step739]: loss 0.025463
[epoch13, step740]: loss 0.022394
[epoch13, step741]: loss 0.025169
[epoch13, step742]: loss 0.021804
[epoch13, step743]: loss 0.023175
[epoch13, step744]: loss 0.023931
[epoch13, step745]: loss 0.024513
[epoch13, step746]: loss 0.025171
[epoch13, step747]: loss 0.027387
[epoch13, step748]: loss 0.025657
[epoch13, step749]: loss 0.026348
[epoch13, step750]: loss 0.027497
[epoch13, step751]: loss 0.021685
[epoch13, step752]: loss 0.025113
[epoch13, step753]: loss 0.025634
[epoch13, step754]: loss 0.022781
[epoch13, step755]: loss 0.026168
[epoch13, step756]: loss 0.023488
[epoch13, step757]: loss 0.020482
[epoch13, step758]: loss 0.025121
[epoch13, step759]: loss 0.023057
[epoch13, step760]: loss 0.023935
[epoch13, step761]: loss 0.026398
[epoch13, step762]: loss 0.021644
[epoch13, step763]: loss 0.025515
[epoch13, step764]: loss 0.023495
[epoch13, step765]: loss 0.025927
[epoch13, step766]: loss 0.024719
[epoch13, step767]: loss 0.026641
[epoch13, step768]: loss 0.021441
[epoch13, step769]: loss 0.026623
[epoch13, step770]: loss 0.025884
[epoch13, step771]: loss 0.023247
[epoch13, step772]: loss 0.028881
[epoch13, step773]: loss 0.026612
[epoch13, step774]: loss 0.024138
[epoch13, step775]: loss 0.020679
[epoch13, step776]: loss 0.025508
[epoch13, step777]: loss 0.023168
[epoch13, step778]: loss 0.027967
[epoch13, step779]: loss 0.023770
[epoch13, step780]: loss 0.020158
[epoch13, step781]: loss 0.024299
[epoch13, step782]: loss 0.022826
[epoch13, step783]: loss 0.019398
[epoch13, step784]: loss 0.020397
[epoch13, step785]: loss 0.021447
[epoch13, step786]: loss 0.024223
[epoch13, step787]: loss 0.023269
[epoch13, step788]: loss 0.024814
[epoch13, step789]: loss 0.022411
[epoch13, step790]: loss 0.023136
[epoch13, step791]: loss 0.026611
[epoch13, step792]: loss 0.025115
[epoch13, step793]: loss 0.026868
[epoch13, step794]: loss 0.020298
[epoch13, step795]: loss 0.025686
[epoch13, step796]: loss 0.028045
[epoch13, step797]: loss 0.027824
[epoch13, step798]: loss 0.027290
[epoch13, step799]: loss 0.025897
[epoch13, step800]: loss 0.021382
[epoch13, step801]: loss 0.021643
[epoch13, step802]: loss 0.022681
[epoch13, step803]: loss 0.026188
[epoch13, step804]: loss 0.027415
[epoch13, step805]: loss 0.028165
[epoch13, step806]: loss 0.021327
[epoch13, step807]: loss 0.020643
[epoch13, step808]: loss 0.022922
[epoch13, step809]: loss 0.023051
[epoch13, step810]: loss 0.025845
[epoch13, step811]: loss 0.025739
[epoch13, step812]: loss 0.024504
[epoch13, step813]: loss 0.023655
[epoch13, step814]: loss 0.025083
[epoch13, step815]: loss 0.024968
[epoch13, step816]: loss 0.024288
[epoch13, step817]: loss 0.024651
[epoch13, step818]: loss 0.022396
[epoch13, step819]: loss 0.020056
[epoch13, step820]: loss 0.023409
[epoch13, step821]: loss 0.021780
[epoch13, step822]: loss 0.030425
[epoch13, step823]: loss 0.023997
[epoch13, step824]: loss 0.026765
[epoch13, step825]: loss 0.025302
[epoch13, step826]: loss 0.024390
[epoch13, step827]: loss 0.026924
[epoch13, step828]: loss 0.028861
[epoch13, step829]: loss 0.026532
[epoch13, step830]: loss 0.022511
[epoch13, step831]: loss 0.026460
[epoch13, step832]: loss 0.020887
[epoch13, step833]: loss 0.029073
[epoch13, step834]: loss 0.025478
[epoch13, step835]: loss 0.020571
[epoch13, step836]: loss 0.026953
[epoch13, step837]: loss 0.025756
[epoch13, step838]: loss 0.026165
[epoch13, step839]: loss 0.028371
[epoch13, step840]: loss 0.020792
[epoch13, step841]: loss 0.024383
[epoch13, step842]: loss 0.027607
[epoch13, step843]: loss 0.024814
[epoch13, step844]: loss 0.024903
[epoch13, step845]: loss 0.021054
[epoch13, step846]: loss 0.025261
[epoch13, step847]: loss 0.026893
[epoch13, step848]: loss 0.024918
[epoch13, step849]: loss 0.025063
[epoch13, step850]: loss 0.022981
[epoch13, step851]: loss 0.023863
[epoch13, step852]: loss 0.023108
[epoch13, step853]: loss 0.029101
[epoch13, step854]: loss 0.022756
[epoch13, step855]: loss 0.027255
[epoch13, step856]: loss 0.022101
[epoch13, step857]: loss 0.026056
[epoch13, step858]: loss 0.024343
[epoch13, step859]: loss 0.023720
[epoch13, step860]: loss 0.022684
[epoch13, step861]: loss 0.023487
[epoch13, step862]: loss 0.023076
[epoch13, step863]: loss 0.020558
[epoch13, step864]: loss 0.026345
[epoch13, step865]: loss 0.023432
[epoch13, step866]: loss 0.025227
[epoch13, step867]: loss 0.026015
[epoch13, step868]: loss 0.026779
[epoch13, step869]: loss 0.023871
[epoch13, step870]: loss 0.031065
[epoch13, step871]: loss 0.021984
[epoch13, step872]: loss 0.025532
[epoch13, step873]: loss 0.025792
[epoch13, step874]: loss 0.023789
[epoch13, step875]: loss 0.024097
[epoch13, step876]: loss 0.024319
[epoch13, step877]: loss 0.019124
[epoch13, step878]: loss 0.023348
[epoch13, step879]: loss 0.027866
[epoch13, step880]: loss 0.025585
[epoch13, step881]: loss 0.022150
[epoch13, step882]: loss 0.024212
[epoch13, step883]: loss 0.023797
[epoch13, step884]: loss 0.026333
[epoch13, step885]: loss 0.025935
[epoch13, step886]: loss 0.026560
[epoch13, step887]: loss 0.024188
[epoch13, step888]: loss 0.024599
[epoch13, step889]: loss 0.023539
[epoch13, step890]: loss 0.023486
[epoch13, step891]: loss 0.025619
[epoch13, step892]: loss 0.021039
[epoch13, step893]: loss 0.024721
[epoch13, step894]: loss 0.025012
[epoch13, step895]: loss 0.022617
[epoch13, step896]: loss 0.021783
[epoch13, step897]: loss 0.023861
[epoch13, step898]: loss 0.025463
[epoch13, step899]: loss 0.028059
[epoch13, step900]: loss 0.026892
[epoch13, step901]: loss 0.025455
[epoch13, step902]: loss 0.023945
[epoch13, step903]: loss 0.024071
[epoch13, step904]: loss 0.028049
[epoch13, step905]: loss 0.027662
[epoch13, step906]: loss 0.022392
[epoch13, step907]: loss 0.023659
[epoch13, step908]: loss 0.022472
[epoch13, step909]: loss 0.025473
[epoch13, step910]: loss 0.023057
[epoch13, step911]: loss 0.025237
[epoch13, step912]: loss 0.023850
[epoch13, step913]: loss 0.023961
[epoch13, step914]: loss 0.030419
[epoch13, step915]: loss 0.024059
[epoch13, step916]: loss 0.023833
[epoch13, step917]: loss 0.025043
[epoch13, step918]: loss 0.028579
[epoch13, step919]: loss 0.024180
[epoch13, step920]: loss 0.027499
[epoch13, step921]: loss 0.024481
[epoch13, step922]: loss 0.023285
[epoch13, step923]: loss 0.022559
[epoch13, step924]: loss 0.021173
[epoch13, step925]: loss 0.025338
[epoch13, step926]: loss 0.026446
[epoch13, step927]: loss 0.025734
[epoch13, step928]: loss 0.024867
[epoch13, step929]: loss 0.027657
[epoch13, step930]: loss 0.025762
[epoch13, step931]: loss 0.027256
[epoch13, step932]: loss 0.021672
[epoch13, step933]: loss 0.028251
[epoch13, step934]: loss 0.021976
[epoch13, step935]: loss 0.021916
[epoch13, step936]: loss 0.022407
[epoch13, step937]: loss 0.027164
[epoch13, step938]: loss 0.025186
[epoch13, step939]: loss 0.020763
[epoch13, step940]: loss 0.022901
[epoch13, step941]: loss 0.026856
[epoch13, step942]: loss 0.025529
[epoch13, step943]: loss 0.023188
[epoch13, step944]: loss 0.027590
[epoch13, step945]: loss 0.020521
[epoch13, step946]: loss 0.025427
[epoch13, step947]: loss 0.027912
[epoch13, step948]: loss 0.019337
[epoch13, step949]: loss 0.022903
[epoch13, step950]: loss 0.026544
[epoch13, step951]: loss 0.028533
[epoch13, step952]: loss 0.025164
[epoch13, step953]: loss 0.027513
[epoch13, step954]: loss 0.022135
[epoch13, step955]: loss 0.037050
[epoch13, step956]: loss 0.052764
[epoch13, step957]: loss 0.046902
[epoch13, step958]: loss 0.044264
[epoch13, step959]: loss 0.047667
[epoch13, step960]: loss 0.043516
[epoch13, step961]: loss 0.043806
[epoch13, step962]: loss 0.041621
[epoch13, step963]: loss 0.040255
[epoch13, step964]: loss 0.041358
[epoch13, step965]: loss 0.041436
[epoch13, step966]: loss 0.039690
[epoch13, step967]: loss 0.039088
[epoch13, step968]: loss 0.041453
[epoch13, step969]: loss 0.040718
[epoch13, step970]: loss 0.039919
[epoch13, step971]: loss 0.038289
[epoch13, step972]: loss 0.039463
[epoch13, step973]: loss 0.038603
[epoch13, step974]: loss 0.040452
[epoch13, step975]: loss 0.037698
[epoch13, step976]: loss 0.036680
[epoch13, step977]: loss 0.040465
[epoch13, step978]: loss 0.038623
[epoch13, step979]: loss 0.037728
[epoch13, step980]: loss 0.036753
[epoch13, step981]: loss 0.038281
[epoch13, step982]: loss 0.038559
[epoch13, step983]: loss 0.039348
[epoch13, step984]: loss 0.036070
[epoch13, step985]: loss 0.036207
[epoch13, step986]: loss 0.040125
[epoch13, step987]: loss 0.038315
[epoch13, step988]: loss 0.038020
[epoch13, step989]: loss 0.037272
[epoch13, step990]: loss 0.037469
[epoch13, step991]: loss 0.038422
[epoch13, step992]: loss 0.038764
[epoch13, step993]: loss 0.036314
[epoch13, step994]: loss 0.035378
[epoch13, step995]: loss 0.039249
[epoch13, step996]: loss 0.037461
[epoch13, step997]: loss 0.037231
[epoch13, step998]: loss 0.036732
[epoch13, step999]: loss 0.037502
[epoch13, step1000]: loss 0.037815
[epoch13, step1001]: loss 0.038497
[epoch13, step1002]: loss 0.036336
[epoch13, step1003]: loss 0.035492
[epoch13, step1004]: loss 0.039388
[epoch13, step1005]: loss 0.036878
[epoch13, step1006]: loss 0.036900
[epoch13, step1007]: loss 0.035633
[epoch13, step1008]: loss 0.036708
[epoch13, step1009]: loss 0.037388
[epoch13, step1010]: loss 0.039241
[epoch13, step1011]: loss 0.035900
[epoch13, step1012]: loss 0.036118
[epoch13, step1013]: loss 0.038964
[epoch13, step1014]: loss 0.038061
[epoch13, step1015]: loss 0.037460
[epoch13, step1016]: loss 0.035610
[epoch13, step1017]: loss 0.036981
[epoch13, step1018]: loss 0.037264
[epoch13, step1019]: loss 0.038491
[epoch13, step1020]: loss 0.035546
[epoch13, step1021]: loss 0.035199
[epoch13, step1022]: loss 0.038533
[epoch13, step1023]: loss 0.037273
[epoch13, step1024]: loss 0.037593
[epoch13, step1025]: loss 0.035287
[epoch13, step1026]: loss 0.036308
[epoch13, step1027]: loss 0.036905
[epoch13, step1028]: loss 0.038162
[epoch13, step1029]: loss 0.035519
[epoch13, step1030]: loss 0.034828
[epoch13, step1031]: loss 0.037470
[epoch13, step1032]: loss 0.037608
[epoch13, step1033]: loss 0.036581
[epoch13, step1034]: loss 0.035407
[epoch13, step1035]: loss 0.036240
[epoch13, step1036]: loss 0.037234
[epoch13, step1037]: loss 0.038083
[epoch13, step1038]: loss 0.035434
[epoch13, step1039]: loss 0.035626
[epoch13, step1040]: loss 0.037886
[epoch13, step1041]: loss 0.036873
[epoch13, step1042]: loss 0.035848
[epoch13, step1043]: loss 0.035342
[epoch13, step1044]: loss 0.036877
[epoch13, step1045]: loss 0.037112
[epoch13, step1046]: loss 0.038303
[epoch13, step1047]: loss 0.035664
[epoch13, step1048]: loss 0.034934
[epoch13, step1049]: loss 0.038392
[epoch13, step1050]: loss 0.037737
[epoch13, step1051]: loss 0.036787
[epoch13, step1052]: loss 0.035812
[epoch13, step1053]: loss 0.037139
[epoch13, step1054]: loss 0.037223
[epoch13, step1055]: loss 0.037850
[epoch13, step1056]: loss 0.034898
[epoch13, step1057]: loss 0.035935
[epoch13, step1058]: loss 0.039245
[epoch13, step1059]: loss 0.037280
[epoch13, step1060]: loss 0.036914
[epoch13, step1061]: loss 0.034879
[epoch13, step1062]: loss 0.037194
[epoch13, step1063]: loss 0.037005
[epoch13, step1064]: loss 0.038164
[epoch13, step1065]: loss 0.035490
[epoch13, step1066]: loss 0.035027
[epoch13, step1067]: loss 0.038372
[epoch13, step1068]: loss 0.035792
[epoch13, step1069]: loss 0.036176
[epoch13, step1070]: loss 0.035280
[epoch13, step1071]: loss 0.037301
[epoch13, step1072]: loss 0.037692
[epoch13, step1073]: loss 0.038046
[epoch13, step1074]: loss 0.035722
[epoch13, step1075]: loss 0.035530
[epoch13, step1076]: loss 0.038334
[epoch13, step1077]: loss 0.036934
[epoch13, step1078]: loss 0.036327
[epoch13, step1079]: loss 0.036332
[epoch13, step1080]: loss 0.036983
[epoch13, step1081]: loss 0.036729
[epoch13, step1082]: loss 0.037979
[epoch13, step1083]: loss 0.036119
[epoch13, step1084]: loss 0.035513
[epoch13, step1085]: loss 0.037792
[epoch13, step1086]: loss 0.036640
[epoch13, step1087]: loss 0.036762
[epoch13, step1088]: loss 0.035144
[epoch13, step1089]: loss 0.037135
[epoch13, step1090]: loss 0.037469
[epoch13, step1091]: loss 0.038347
[epoch13, step1092]: loss 0.035280
[epoch13, step1093]: loss 0.035251
[epoch13, step1094]: loss 0.037404
[epoch13, step1095]: loss 0.036456
[epoch13, step1096]: loss 0.036210
[epoch13, step1097]: loss 0.035181
[epoch13, step1098]: loss 0.036852
[epoch13, step1099]: loss 0.036574
[epoch13, step1100]: loss 0.038551
[epoch13, step1101]: loss 0.035812
[epoch13, step1102]: loss 0.035145
[epoch13, step1103]: loss 0.037735
[epoch13, step1104]: loss 0.036751
[epoch13, step1105]: loss 0.036812
[epoch13, step1106]: loss 0.034402
[epoch13, step1107]: loss 0.036915
[epoch13, step1108]: loss 0.036543
[epoch13, step1109]: loss 0.038524
[epoch13, step1110]: loss 0.036074
[epoch13, step1111]: loss 0.035451
[epoch13, step1112]: loss 0.038660
[epoch13, step1113]: loss 0.036518
[epoch13, step1114]: loss 0.037042
[epoch13, step1115]: loss 0.035414
[epoch13, step1116]: loss 0.036830
[epoch13, step1117]: loss 0.036891
[epoch13, step1118]: loss 0.037829
[epoch13, step1119]: loss 0.035273
[epoch13, step1120]: loss 0.035109
[epoch13, step1121]: loss 0.038091
[epoch13, step1122]: loss 0.036433
[epoch13, step1123]: loss 0.035834
[epoch13, step1124]: loss 0.035972
[epoch13, step1125]: loss 0.037060
[epoch13, step1126]: loss 0.037837
[epoch13, step1127]: loss 0.038097
[epoch13, step1128]: loss 0.035597
[epoch13, step1129]: loss 0.035124
[epoch13, step1130]: loss 0.038986
[epoch13, step1131]: loss 0.037274
[epoch13, step1132]: loss 0.037102
[epoch13, step1133]: loss 0.034731
[epoch13, step1134]: loss 0.036550
[epoch13, step1135]: loss 0.037762
[epoch13, step1136]: loss 0.038888
[epoch13, step1137]: loss 0.035528
[epoch13, step1138]: loss 0.035376
[epoch13, step1139]: loss 0.038251
[epoch13, step1140]: loss 0.036233
[epoch13, step1141]: loss 0.036366
[epoch13, step1142]: loss 0.034892
[epoch13, step1143]: loss 0.036262
[epoch13, step1144]: loss 0.037019
[epoch13, step1145]: loss 0.037442
[epoch13, step1146]: loss 0.035130
[epoch13, step1147]: loss 0.035921
[epoch13, step1148]: loss 0.038303
[epoch13, step1149]: loss 0.036470
[epoch13, step1150]: loss 0.036394
[epoch13, step1151]: loss 0.035699
[epoch13, step1152]: loss 0.037200
[epoch13, step1153]: loss 0.036284
[epoch13, step1154]: loss 0.038345
[epoch13, step1155]: loss 0.035496
[epoch13, step1156]: loss 0.034706
[epoch13, step1157]: loss 0.037999
[epoch13, step1158]: loss 0.037025
[epoch13, step1159]: loss 0.036810
[epoch13, step1160]: loss 0.035967
[epoch13, step1161]: loss 0.037228
[epoch13, step1162]: loss 0.036788
[epoch13, step1163]: loss 0.037327
[epoch13, step1164]: loss 0.035489
[epoch13, step1165]: loss 0.036229
[epoch13, step1166]: loss 0.038500
[epoch13, step1167]: loss 0.035968
[epoch13, step1168]: loss 0.036823
[epoch13, step1169]: loss 0.034933
[epoch13, step1170]: loss 0.036783
[epoch13, step1171]: loss 0.036884
[epoch13, step1172]: loss 0.038037
[epoch13, step1173]: loss 0.035614
[epoch13, step1174]: loss 0.035664
[epoch13, step1175]: loss 0.038186
[epoch13, step1176]: loss 0.036419
[epoch13, step1177]: loss 0.036962
[epoch13, step1178]: loss 0.035234
[epoch13, step1179]: loss 0.036648
[epoch13, step1180]: loss 0.036956
[epoch13, step1181]: loss 0.038501
[epoch13, step1182]: loss 0.034782
[epoch13, step1183]: loss 0.035671
[epoch13, step1184]: loss 0.037699
[epoch13, step1185]: loss 0.036861
[epoch13, step1186]: loss 0.035855
[epoch13, step1187]: loss 0.034243
[epoch13, step1188]: loss 0.036089
[epoch13, step1189]: loss 0.036574
[epoch13, step1190]: loss 0.037534
[epoch13, step1191]: loss 0.035996
[epoch13, step1192]: loss 0.035394
[epoch13, step1193]: loss 0.038225
[epoch13, step1194]: loss 0.036516
[epoch13, step1195]: loss 0.035495
[epoch13, step1196]: loss 0.034400
[epoch13, step1197]: loss 0.037019
[epoch13, step1198]: loss 0.036837
[epoch13, step1199]: loss 0.037571
[epoch13, step1200]: loss 0.035182
[epoch13, step1201]: loss 0.035692
[epoch13, step1202]: loss 0.039088
[epoch13, step1203]: loss 0.036739
[epoch13, step1204]: loss 0.035951
[epoch13, step1205]: loss 0.034548
[epoch13, step1206]: loss 0.036150
[epoch13, step1207]: loss 0.037057
[epoch13, step1208]: loss 0.038366
[epoch13, step1209]: loss 0.034252
[epoch13, step1210]: loss 0.035674
[epoch13, step1211]: loss 0.037981
[epoch13, step1212]: loss 0.036501
[epoch13, step1213]: loss 0.036126
[epoch13, step1214]: loss 0.035160
[epoch13, step1215]: loss 0.037294
[epoch13, step1216]: loss 0.036321
[epoch13, step1217]: loss 0.038467
[epoch13, step1218]: loss 0.035023
[epoch13, step1219]: loss 0.035779
[epoch13, step1220]: loss 0.038483
[epoch13, step1221]: loss 0.035750
[epoch13, step1222]: loss 0.036682
[epoch13, step1223]: loss 0.035146
[epoch13, step1224]: loss 0.037270
[epoch13, step1225]: loss 0.036874
[epoch13, step1226]: loss 0.037539
[epoch13, step1227]: loss 0.035303
[epoch13, step1228]: loss 0.035023
[epoch13, step1229]: loss 0.037989
[epoch13, step1230]: loss 0.036780
[epoch13, step1231]: loss 0.036486
[epoch13, step1232]: loss 0.036125
[epoch13, step1233]: loss 0.036597
[epoch13, step1234]: loss 0.036620
[epoch13, step1235]: loss 0.038274
[epoch13, step1236]: loss 0.035679
[epoch13, step1237]: loss 0.034650
[epoch13, step1238]: loss 0.037514
[epoch13, step1239]: loss 0.037341
[epoch13, step1240]: loss 0.036734
[epoch13, step1241]: loss 0.034666
[epoch13, step1242]: loss 0.036564
[epoch13, step1243]: loss 0.036543
[epoch13, step1244]: loss 0.038250
[epoch13, step1245]: loss 0.035703
[epoch13, step1246]: loss 0.035440
[epoch13, step1247]: loss 0.037199
[epoch13, step1248]: loss 0.036763
[epoch13, step1249]: loss 0.036997
[epoch13, step1250]: loss 0.034958
[epoch13, step1251]: loss 0.037070
[epoch13, step1252]: loss 0.037608
[epoch13, step1253]: loss 0.038185
[epoch13, step1254]: loss 0.035415
[epoch13, step1255]: loss 0.035349
[epoch13, step1256]: loss 0.038606
[epoch13, step1257]: loss 0.036917
[epoch13, step1258]: loss 0.036861
[epoch13, step1259]: loss 0.035068
[epoch13, step1260]: loss 0.036799
[epoch13, step1261]: loss 0.036611
[epoch13, step1262]: loss 0.036948
[epoch13, step1263]: loss 0.036004
[epoch13, step1264]: loss 0.035023
[epoch13, step1265]: loss 0.037113
[epoch13, step1266]: loss 0.036602
[epoch13, step1267]: loss 0.036978
[epoch13, step1268]: loss 0.035236
[epoch13, step1269]: loss 0.036800
[epoch13, step1270]: loss 0.036076
[epoch13, step1271]: loss 0.038296
[epoch13, step1272]: loss 0.035476
[epoch13, step1273]: loss 0.034937
[epoch13, step1274]: loss 0.038188
[epoch13, step1275]: loss 0.036928
[epoch13, step1276]: loss 0.036489
[epoch13, step1277]: loss 0.035153
[epoch13, step1278]: loss 0.037274
[epoch13, step1279]: loss 0.037141
[epoch13, step1280]: loss 0.038269
[epoch13, step1281]: loss 0.035275
[epoch13, step1282]: loss 0.035393
[epoch13, step1283]: loss 0.037549
[epoch13, step1284]: loss 0.036095
[epoch13, step1285]: loss 0.036928
[epoch13, step1286]: loss 0.034645
[epoch13, step1287]: loss 0.037367
[epoch13, step1288]: loss 0.037488
[epoch13, step1289]: loss 0.038764
[epoch13, step1290]: loss 0.035466
[epoch13, step1291]: loss 0.034970
[epoch13, step1292]: loss 0.038705
[epoch13, step1293]: loss 0.035922
[epoch13, step1294]: loss 0.036630
[epoch13, step1295]: loss 0.035598
[epoch13, step1296]: loss 0.036942
[epoch13, step1297]: loss 0.036829
[epoch13, step1298]: loss 0.038512
[epoch13, step1299]: loss 0.035619
[epoch13, step1300]: loss 0.035918
[epoch13, step1301]: loss 0.037299
[epoch13, step1302]: loss 0.036550
[epoch13, step1303]: loss 0.036775
[epoch13, step1304]: loss 0.034450
[epoch13, step1305]: loss 0.037283
[epoch13, step1306]: loss 0.037151
[epoch13, step1307]: loss 0.037498
[epoch13, step1308]: loss 0.035516
[epoch13, step1309]: loss 0.034473
[epoch13, step1310]: loss 0.038016
[epoch13, step1311]: loss 0.035637
[epoch13, step1312]: loss 0.037205
[epoch13, step1313]: loss 0.035148
[epoch13, step1314]: loss 0.036644
[epoch13, step1315]: loss 0.036443
[epoch13, step1316]: loss 0.039267
[epoch13, step1317]: loss 0.034870
[epoch13, step1318]: loss 0.034695
[epoch13, step1319]: loss 0.037542
[epoch13, step1320]: loss 0.036769
[epoch13, step1321]: loss 0.036964
[epoch13, step1322]: loss 0.034664
[epoch13, step1323]: loss 0.037057
[epoch13, step1324]: loss 0.036361
[epoch13, step1325]: loss 0.037828
[epoch13, step1326]: loss 0.035169
[epoch13, step1327]: loss 0.034997
[epoch13, step1328]: loss 0.038221
[epoch13, step1329]: loss 0.036399
[epoch13, step1330]: loss 0.036764
[epoch13, step1331]: loss 0.034804
[epoch13, step1332]: loss 0.036606
[epoch13, step1333]: loss 0.035881
[epoch13, step1334]: loss 0.038218
[epoch13, step1335]: loss 0.036051
[epoch13, step1336]: loss 0.035111
[epoch13, step1337]: loss 0.037472
[epoch13, step1338]: loss 0.036710
[epoch13, step1339]: loss 0.036601
[epoch13, step1340]: loss 0.034753
[epoch13, step1341]: loss 0.036968
[epoch13, step1342]: loss 0.036523
[epoch13, step1343]: loss 0.038102
[epoch13, step1344]: loss 0.035471
[epoch13, step1345]: loss 0.035168
[epoch13, step1346]: loss 0.037663
[epoch13, step1347]: loss 0.037173
[epoch13, step1348]: loss 0.035954
[epoch13, step1349]: loss 0.035062
[epoch13, step1350]: loss 0.036997
[epoch13, step1351]: loss 0.036282
[epoch13, step1352]: loss 0.037822
[epoch13, step1353]: loss 0.035073
[epoch13, step1354]: loss 0.034933
[epoch13, step1355]: loss 0.038296
[epoch13, step1356]: loss 0.036445
[epoch13, step1357]: loss 0.036263
[epoch13, step1358]: loss 0.034845
[epoch13, step1359]: loss 0.036311
[epoch13, step1360]: loss 0.036981
[epoch13, step1361]: loss 0.038153
[epoch13, step1362]: loss 0.036082
[epoch13, step1363]: loss 0.035552
[epoch13, step1364]: loss 0.037950
[epoch13, step1365]: loss 0.036578
[epoch13, step1366]: loss 0.036363
[epoch13, step1367]: loss 0.034208
[epoch13, step1368]: loss 0.037548
[epoch13, step1369]: loss 0.037031
[epoch13, step1370]: loss 0.037699
[epoch13, step1371]: loss 0.035606
[epoch13, step1372]: loss 0.035002
[epoch13, step1373]: loss 0.038250
[epoch13, step1374]: loss 0.037313
[epoch13, step1375]: loss 0.037347
[epoch13, step1376]: loss 0.034899
[epoch13, step1377]: loss 0.036195
[epoch13, step1378]: loss 0.036993
[epoch13, step1379]: loss 0.037322
[epoch13, step1380]: loss 0.035679
[epoch13, step1381]: loss 0.034990
[epoch13, step1382]: loss 0.038146
[epoch13, step1383]: loss 0.036392
[epoch13, step1384]: loss 0.036194
[epoch13, step1385]: loss 0.034479
[epoch13, step1386]: loss 0.036945
[epoch13, step1387]: loss 0.037128
[epoch13, step1388]: loss 0.037008
[epoch13, step1389]: loss 0.034699
[epoch13, step1390]: loss 0.035525
[epoch13, step1391]: loss 0.037920
[epoch13, step1392]: loss 0.036619
[epoch13, step1393]: loss 0.036789
[epoch13, step1394]: loss 0.035900
[epoch13, step1395]: loss 0.036688
[epoch13, step1396]: loss 0.036456
[epoch13, step1397]: loss 0.037397
[epoch13, step1398]: loss 0.035189
[epoch13, step1399]: loss 0.035761
[epoch13, step1400]: loss 0.038288
[epoch13, step1401]: loss 0.036303
[epoch13, step1402]: loss 0.036412
[epoch13, step1403]: loss 0.034130
[epoch13, step1404]: loss 0.036105
[epoch13, step1405]: loss 0.036615
[epoch13, step1406]: loss 0.037470
[epoch13, step1407]: loss 0.036346
[epoch13, step1408]: loss 0.034582
[epoch13, step1409]: loss 0.037415
[epoch13, step1410]: loss 0.036697
[epoch13, step1411]: loss 0.035586
[epoch13, step1412]: loss 0.034976
[epoch13, step1413]: loss 0.036904
[epoch13, step1414]: loss 0.036314
[epoch13, step1415]: loss 0.037763
[epoch13, step1416]: loss 0.035310
[epoch13, step1417]: loss 0.034909
[epoch13, step1418]: loss 0.038019
[epoch13, step1419]: loss 0.037182
[epoch13, step1420]: loss 0.036679
[epoch13, step1421]: loss 0.035366
[epoch13, step1422]: loss 0.036861
[epoch13, step1423]: loss 0.036274
[epoch13, step1424]: loss 0.038028
[epoch13, step1425]: loss 0.034401
[epoch13, step1426]: loss 0.035218
[epoch13, step1427]: loss 0.038697
[epoch13, step1428]: loss 0.037439
[epoch13, step1429]: loss 0.036585
[epoch13, step1430]: loss 0.035022
[epoch13, step1431]: loss 0.036861
[epoch13, step1432]: loss 0.036385
[epoch13, step1433]: loss 0.038066
[epoch13, step1434]: loss 0.034972
[epoch13, step1435]: loss 0.035490
[epoch13, step1436]: loss 0.038382
[epoch13, step1437]: loss 0.036849
[epoch13, step1438]: loss 0.037439
[epoch13, step1439]: loss 0.034771
[epoch13, step1440]: loss 0.036775
[epoch13, step1441]: loss 0.037489
[epoch13, step1442]: loss 0.036970
[epoch13, step1443]: loss 0.034995
[epoch13, step1444]: loss 0.034313
[epoch13, step1445]: loss 0.038281
[epoch13, step1446]: loss 0.036752
[epoch13, step1447]: loss 0.037064
[epoch13, step1448]: loss 0.035050
[epoch13, step1449]: loss 0.036101
[epoch13, step1450]: loss 0.036717
[epoch13, step1451]: loss 0.038244
[epoch13, step1452]: loss 0.034992
[epoch13, step1453]: loss 0.036165
[epoch13, step1454]: loss 0.038721
[epoch13, step1455]: loss 0.037025
[epoch13, step1456]: loss 0.036336
[epoch13, step1457]: loss 0.035734
[epoch13, step1458]: loss 0.036789
[epoch13, step1459]: loss 0.036904
[epoch13, step1460]: loss 0.038055
[epoch13, step1461]: loss 0.035907
[epoch13, step1462]: loss 0.035527
[epoch13, step1463]: loss 0.037790
[epoch13, step1464]: loss 0.036794
[epoch13, step1465]: loss 0.035903
[epoch13, step1466]: loss 0.034741
[epoch13, step1467]: loss 0.036502
[epoch13, step1468]: loss 0.036272
[epoch13, step1469]: loss 0.037752
[epoch13, step1470]: loss 0.035443
[epoch13, step1471]: loss 0.034935
[epoch13, step1472]: loss 0.037663
[epoch13, step1473]: loss 0.036738
[epoch13, step1474]: loss 0.037292
[epoch13, step1475]: loss 0.034690
[epoch13, step1476]: loss 0.037551
[epoch13, step1477]: loss 0.036422
[epoch13, step1478]: loss 0.037983
[epoch13, step1479]: loss 0.035371
[epoch13, step1480]: loss 0.034886
[epoch13, step1481]: loss 0.037096
[epoch13, step1482]: loss 0.036462
[epoch13, step1483]: loss 0.036493
[epoch13, step1484]: loss 0.035244
[epoch13, step1485]: loss 0.036501
[epoch13, step1486]: loss 0.035676
[epoch13, step1487]: loss 0.037613
[epoch13, step1488]: loss 0.035249
[epoch13, step1489]: loss 0.034958
[epoch13, step1490]: loss 0.037967
[epoch13, step1491]: loss 0.036604
[epoch13, step1492]: loss 0.036297
[epoch13, step1493]: loss 0.034930
[epoch13, step1494]: loss 0.036792
[epoch13, step1495]: loss 0.036329
[epoch13, step1496]: loss 0.037029
[epoch13, step1497]: loss 0.035580
[epoch13, step1498]: loss 0.035476
[epoch13, step1499]: loss 0.037527
[epoch13, step1500]: loss 0.036887
[epoch13, step1501]: loss 0.036639
[epoch13, step1502]: loss 0.034816
[epoch13, step1503]: loss 0.036583
[epoch13, step1504]: loss 0.036301
[epoch13, step1505]: loss 0.037972
[epoch13, step1506]: loss 0.034730
[epoch13, step1507]: loss 0.035351
[epoch13, step1508]: loss 0.038390
[epoch13, step1509]: loss 0.036262
[epoch13, step1510]: loss 0.035941
[epoch13, step1511]: loss 0.035725
[epoch13, step1512]: loss 0.037043
[epoch13, step1513]: loss 0.035322
[epoch13, step1514]: loss 0.037914
[epoch13, step1515]: loss 0.035712
[epoch13, step1516]: loss 0.035141

[epoch13]: avg loss 0.033657

[epoch14, step1]: loss 0.028714
[epoch14, step2]: loss 0.037658
[epoch14, step3]: loss 0.037660
[epoch14, step4]: loss 0.035592
[epoch14, step5]: loss 0.035319
[epoch14, step6]: loss 0.038015
[epoch14, step7]: loss 0.035966
[epoch14, step8]: loss 0.037917
[epoch14, step9]: loss 0.034587
[epoch14, step10]: loss 0.036038
[epoch14, step11]: loss 0.037792
[epoch14, step12]: loss 0.037580
[epoch14, step13]: loss 0.035319
[epoch14, step14]: loss 0.035480
[epoch14, step15]: loss 0.037669
[epoch14, step16]: loss 0.035861
[epoch14, step17]: loss 0.038042
[epoch14, step18]: loss 0.035951
[epoch14, step19]: loss 0.035947
[epoch14, step20]: loss 0.038595
[epoch14, step21]: loss 0.037864
[epoch14, step22]: loss 0.035112
[epoch14, step23]: loss 0.034550
[epoch14, step24]: loss 0.038125
[epoch14, step25]: loss 0.034988
[epoch14, step26]: loss 0.037681
[epoch14, step27]: loss 0.034422
[epoch14, step28]: loss 0.035809
[epoch14, step29]: loss 0.037983
[epoch14, step30]: loss 0.038350
[epoch14, step31]: loss 0.034734
[epoch14, step32]: loss 0.035715
[epoch14, step33]: loss 0.038420
[epoch14, step34]: loss 0.036364
[epoch14, step35]: loss 0.038338
[epoch14, step36]: loss 0.034811
[epoch14, step37]: loss 0.035716
[epoch14, step38]: loss 0.037753
[epoch14, step39]: loss 0.037755
[epoch14, step40]: loss 0.035532
[epoch14, step41]: loss 0.034707
[epoch14, step42]: loss 0.038242
[epoch14, step43]: loss 0.035518
[epoch14, step44]: loss 0.038704
[epoch14, step45]: loss 0.034909
[epoch14, step46]: loss 0.035743
[epoch14, step47]: loss 0.037446
[epoch14, step48]: loss 0.037380
[epoch14, step49]: loss 0.033798
[epoch14, step50]: loss 0.035232
[epoch14, step51]: loss 0.037806
[epoch14, step52]: loss 0.035434
[epoch14, step53]: loss 0.038503
[epoch14, step54]: loss 0.034661
[epoch14, step55]: loss 0.036090
[epoch14, step56]: loss 0.038668
[epoch14, step57]: loss 0.038234
[epoch14, step58]: loss 0.035132
[epoch14, step59]: loss 0.034278
[epoch14, step60]: loss 0.038533
[epoch14, step61]: loss 0.034800
[epoch14, step62]: loss 0.037490
[epoch14, step63]: loss 0.034453
[epoch14, step64]: loss 0.035369
[epoch14, step65]: loss 0.038100
[epoch14, step66]: loss 0.037728
[epoch14, step67]: loss 0.035365
[epoch14, step68]: loss 0.035203
[epoch14, step69]: loss 0.037793
[epoch14, step70]: loss 0.035458
[epoch14, step71]: loss 0.037614
[epoch14, step72]: loss 0.034942
[epoch14, step73]: loss 0.035761
[epoch14, step74]: loss 0.037821
[epoch14, step75]: loss 0.038176
[epoch14, step76]: loss 0.035758
[epoch14, step77]: loss 0.035754
[epoch14, step78]: loss 0.038160
[epoch14, step79]: loss 0.034930
[epoch14, step80]: loss 0.038770
[epoch14, step81]: loss 0.034916
[epoch14, step82]: loss 0.035179
[epoch14, step83]: loss 0.037693
[epoch14, step84]: loss 0.037951
[epoch14, step85]: loss 0.035962
[epoch14, step86]: loss 0.035692
[epoch14, step87]: loss 0.038848
[epoch14, step88]: loss 0.034486
[epoch14, step89]: loss 0.037916
[epoch14, step90]: loss 0.035348
[epoch14, step91]: loss 0.035218
[epoch14, step92]: loss 0.038061
[epoch14, step93]: loss 0.037901
[epoch14, step94]: loss 0.035043
[epoch14, step95]: loss 0.035696
[epoch14, step96]: loss 0.037654
[epoch14, step97]: loss 0.036278
[epoch14, step98]: loss 0.038044
[epoch14, step99]: loss 0.035048
[epoch14, step100]: loss 0.034616
[epoch14, step101]: loss 0.038383
[epoch14, step102]: loss 0.037776
[epoch14, step103]: loss 0.035152
[epoch14, step104]: loss 0.035176
[epoch14, step105]: loss 0.038400
[epoch14, step106]: loss 0.035674
[epoch14, step107]: loss 0.038211
[epoch14, step108]: loss 0.035322
[epoch14, step109]: loss 0.035371
[epoch14, step110]: loss 0.038522
[epoch14, step111]: loss 0.037577
[epoch14, step112]: loss 0.035409
[epoch14, step113]: loss 0.036047
[epoch14, step114]: loss 0.037721
[epoch14, step115]: loss 0.035593
[epoch14, step116]: loss 0.038748
[epoch14, step117]: loss 0.034935
[epoch14, step118]: loss 0.036398
[epoch14, step119]: loss 0.038306
[epoch14, step120]: loss 0.038135
[epoch14, step121]: loss 0.035163
[epoch14, step122]: loss 0.035189
[epoch14, step123]: loss 0.038293
[epoch14, step124]: loss 0.035863
[epoch14, step125]: loss 0.038440
[epoch14, step126]: loss 0.034882
[epoch14, step127]: loss 0.035359
[epoch14, step128]: loss 0.037823
[epoch14, step129]: loss 0.037784
[epoch14, step130]: loss 0.035440
[epoch14, step131]: loss 0.034658
[epoch14, step132]: loss 0.038071
[epoch14, step133]: loss 0.035399
[epoch14, step134]: loss 0.037460
[epoch14, step135]: loss 0.035504
[epoch14, step136]: loss 0.036606
[epoch14, step137]: loss 0.037701
[epoch14, step138]: loss 0.037772
[epoch14, step139]: loss 0.035207
[epoch14, step140]: loss 0.035631
[epoch14, step141]: loss 0.038237
[epoch14, step142]: loss 0.035461
[epoch14, step143]: loss 0.037548
[epoch14, step144]: loss 0.035260
[epoch14, step145]: loss 0.035563
[epoch14, step146]: loss 0.037940
[epoch14, step147]: loss 0.039095
[epoch14, step148]: loss 0.034906
[epoch14, step149]: loss 0.034926
[epoch14, step150]: loss 0.037878
[epoch14, step151]: loss 0.035541
[epoch14, step152]: loss 0.037922
[epoch14, step153]: loss 0.035005
[epoch14, step154]: loss 0.035378
[epoch14, step155]: loss 0.037855
[epoch14, step156]: loss 0.037506
[epoch14, step157]: loss 0.035379
[epoch14, step158]: loss 0.035578
[epoch14, step159]: loss 0.038101
[epoch14, step160]: loss 0.035776
[epoch14, step161]: loss 0.038439
[epoch14, step162]: loss 0.035242
[epoch14, step163]: loss 0.035515
[epoch14, step164]: loss 0.038152
[epoch14, step165]: loss 0.037880
[epoch14, step166]: loss 0.035602
[epoch14, step167]: loss 0.034896
[epoch14, step168]: loss 0.038655
[epoch14, step169]: loss 0.035239
[epoch14, step170]: loss 0.038439
[epoch14, step171]: loss 0.035414
[epoch14, step172]: loss 0.035718
[epoch14, step173]: loss 0.038373
[epoch14, step174]: loss 0.037638
[epoch14, step175]: loss 0.035983
[epoch14, step176]: loss 0.035467
[epoch14, step177]: loss 0.038284
[epoch14, step178]: loss 0.035529
[epoch14, step179]: loss 0.037144
[epoch14, step180]: loss 0.035273
[epoch14, step181]: loss 0.035755
[epoch14, step182]: loss 0.038442
[epoch14, step183]: loss 0.038575
[epoch14, step184]: loss 0.036225
[epoch14, step185]: loss 0.035469
[epoch14, step186]: loss 0.038214
[epoch14, step187]: loss 0.035704
[epoch14, step188]: loss 0.037833
[epoch14, step189]: loss 0.035057
[epoch14, step190]: loss 0.034969
[epoch14, step191]: loss 0.038078
[epoch14, step192]: loss 0.038383
[epoch14, step193]: loss 0.033551
[epoch14, step194]: loss 0.034411
[epoch14, step195]: loss 0.038342
[epoch14, step196]: loss 0.035589
[epoch14, step197]: loss 0.037874
[epoch14, step198]: loss 0.034233
[epoch14, step199]: loss 0.035613
[epoch14, step200]: loss 0.038411
[epoch14, step201]: loss 0.038329
[epoch14, step202]: loss 0.034896
[epoch14, step203]: loss 0.035328
[epoch14, step204]: loss 0.038477
[epoch14, step205]: loss 0.035147
[epoch14, step206]: loss 0.037754
[epoch14, step207]: loss 0.034942
[epoch14, step208]: loss 0.036089
[epoch14, step209]: loss 0.038262
[epoch14, step210]: loss 0.038857
[epoch14, step211]: loss 0.036058
[epoch14, step212]: loss 0.035626
[epoch14, step213]: loss 0.037734
[epoch14, step214]: loss 0.034882
[epoch14, step215]: loss 0.038265
[epoch14, step216]: loss 0.035313
[epoch14, step217]: loss 0.034848
[epoch14, step218]: loss 0.038249
[epoch14, step219]: loss 0.037687
[epoch14, step220]: loss 0.035554
[epoch14, step221]: loss 0.035579
[epoch14, step222]: loss 0.038487
[epoch14, step223]: loss 0.035699
[epoch14, step224]: loss 0.037653
[epoch14, step225]: loss 0.034971
[epoch14, step226]: loss 0.035333
[epoch14, step227]: loss 0.037119
[epoch14, step228]: loss 0.038599
[epoch14, step229]: loss 0.034583
[epoch14, step230]: loss 0.035545
[epoch14, step231]: loss 0.038672
[epoch14, step232]: loss 0.035281
[epoch14, step233]: loss 0.037281
[epoch14, step234]: loss 0.034620
[epoch14, step235]: loss 0.035792
[epoch14, step236]: loss 0.038039
[epoch14, step237]: loss 0.037998
[epoch14, step238]: loss 0.035074
[epoch14, step239]: loss 0.034622
[epoch14, step240]: loss 0.037533
[epoch14, step241]: loss 0.036036
[epoch14, step242]: loss 0.037918
[epoch14, step243]: loss 0.035760
[epoch14, step244]: loss 0.035385
[epoch14, step245]: loss 0.037550
[epoch14, step246]: loss 0.037945
[epoch14, step247]: loss 0.035637
[epoch14, step248]: loss 0.034987
[epoch14, step249]: loss 0.037568
[epoch14, step250]: loss 0.035882
[epoch14, step251]: loss 0.038526
[epoch14, step252]: loss 0.035531
[epoch14, step253]: loss 0.035109
[epoch14, step254]: loss 0.037846
[epoch14, step255]: loss 0.038231
[epoch14, step256]: loss 0.035156
[epoch14, step257]: loss 0.034953
[epoch14, step258]: loss 0.038621
[epoch14, step259]: loss 0.035654
[epoch14, step260]: loss 0.037498
[epoch14, step261]: loss 0.035818
[epoch14, step262]: loss 0.035897
[epoch14, step263]: loss 0.037524
[epoch14, step264]: loss 0.037687
[epoch14, step265]: loss 0.035548
[epoch14, step266]: loss 0.035254
[epoch14, step267]: loss 0.037394
[epoch14, step268]: loss 0.035403
[epoch14, step269]: loss 0.038113
[epoch14, step270]: loss 0.034615
[epoch14, step271]: loss 0.035680
[epoch14, step272]: loss 0.037990
[epoch14, step273]: loss 0.037638
[epoch14, step274]: loss 0.035844
[epoch14, step275]: loss 0.034699
[epoch14, step276]: loss 0.037859
[epoch14, step277]: loss 0.035978
[epoch14, step278]: loss 0.038153
[epoch14, step279]: loss 0.034703
[epoch14, step280]: loss 0.035617
[epoch14, step281]: loss 0.037945
[epoch14, step282]: loss 0.038494
[epoch14, step283]: loss 0.034965
[epoch14, step284]: loss 0.034769
[epoch14, step285]: loss 0.038825
[epoch14, step286]: loss 0.034808
[epoch14, step287]: loss 0.038315
[epoch14, step288]: loss 0.034739
[epoch14, step289]: loss 0.036342
[epoch14, step290]: loss 0.038137
[epoch14, step291]: loss 0.038225
[epoch14, step292]: loss 0.034626
[epoch14, step293]: loss 0.034830
[epoch14, step294]: loss 0.037423
[epoch14, step295]: loss 0.034959
[epoch14, step296]: loss 0.038773
[epoch14, step297]: loss 0.034763
[epoch14, step298]: loss 0.035858
[epoch14, step299]: loss 0.037104
[epoch14, step300]: loss 0.038180
[epoch14, step301]: loss 0.035312
[epoch14, step302]: loss 0.035570
[epoch14, step303]: loss 0.038412
[epoch14, step304]: loss 0.035289
[epoch14, step305]: loss 0.037784
[epoch14, step306]: loss 0.035082
[epoch14, step307]: loss 0.035326
[epoch14, step308]: loss 0.038510
[epoch14, step309]: loss 0.038354
[epoch14, step310]: loss 0.035540
[epoch14, step311]: loss 0.035568
[epoch14, step312]: loss 0.037691
[epoch14, step313]: loss 0.035860
[epoch14, step314]: loss 0.037939
[epoch14, step315]: loss 0.036013
[epoch14, step316]: loss 0.035231
[epoch14, step317]: loss 0.038343
[epoch14, step318]: loss 0.038014
[epoch14, step319]: loss 0.034853
[epoch14, step320]: loss 0.034313
[epoch14, step321]: loss 0.037668
[epoch14, step322]: loss 0.035346
[epoch14, step323]: loss 0.037419
[epoch14, step324]: loss 0.035999
[epoch14, step325]: loss 0.035646
[epoch14, step326]: loss 0.037796
[epoch14, step327]: loss 0.037201
[epoch14, step328]: loss 0.035483
[epoch14, step329]: loss 0.034917
[epoch14, step330]: loss 0.037499
[epoch14, step331]: loss 0.035679
[epoch14, step332]: loss 0.037387
[epoch14, step333]: loss 0.034983
[epoch14, step334]: loss 0.035650
[epoch14, step335]: loss 0.038034
[epoch14, step336]: loss 0.038751
[epoch14, step337]: loss 0.035828
[epoch14, step338]: loss 0.034801
[epoch14, step339]: loss 0.038023
[epoch14, step340]: loss 0.036108
[epoch14, step341]: loss 0.037493
[epoch14, step342]: loss 0.034754
[epoch14, step343]: loss 0.035745
[epoch14, step344]: loss 0.037523
[epoch14, step345]: loss 0.037225
[epoch14, step346]: loss 0.034925
[epoch14, step347]: loss 0.034800
[epoch14, step348]: loss 0.038143
[epoch14, step349]: loss 0.035960
[epoch14, step350]: loss 0.037500
[epoch14, step351]: loss 0.034343
[epoch14, step352]: loss 0.035326
[epoch14, step353]: loss 0.037754
[epoch14, step354]: loss 0.036970
[epoch14, step355]: loss 0.034309
[epoch14, step356]: loss 0.035770
[epoch14, step357]: loss 0.038050
[epoch14, step358]: loss 0.034066
[epoch14, step359]: loss 0.038776
[epoch14, step360]: loss 0.033854
[epoch14, step361]: loss 0.035023
[epoch14, step362]: loss 0.038651
[epoch14, step363]: loss 0.037621
[epoch14, step364]: loss 0.035325
[epoch14, step365]: loss 0.034852
[epoch14, step366]: loss 0.038327
[epoch14, step367]: loss 0.035600
[epoch14, step368]: loss 0.037260
[epoch14, step369]: loss 0.034814
[epoch14, step370]: loss 0.035892
[epoch14, step371]: loss 0.038625
[epoch14, step372]: loss 0.037509
[epoch14, step373]: loss 0.034713
[epoch14, step374]: loss 0.034452
[epoch14, step375]: loss 0.038574
[epoch14, step376]: loss 0.035627
[epoch14, step377]: loss 0.038116
[epoch14, step378]: loss 0.035496
[epoch14, step379]: loss 0.036111
[epoch14, step380]: loss 0.038486
[epoch14, step381]: loss 0.037711
[epoch14, step382]: loss 0.035776
[epoch14, step383]: loss 0.034268
[epoch14, step384]: loss 0.037356
[epoch14, step385]: loss 0.035414
[epoch14, step386]: loss 0.038128
[epoch14, step387]: loss 0.035115
[epoch14, step388]: loss 0.036153
[epoch14, step389]: loss 0.037880
[epoch14, step390]: loss 0.038847
[epoch14, step391]: loss 0.034851
[epoch14, step392]: loss 0.035661
[epoch14, step393]: loss 0.037621
[epoch14, step394]: loss 0.035469
[epoch14, step395]: loss 0.037673
[epoch14, step396]: loss 0.034993
[epoch14, step397]: loss 0.035173
[epoch14, step398]: loss 0.038187
[epoch14, step399]: loss 0.037806
[epoch14, step400]: loss 0.035016
[epoch14, step401]: loss 0.034833
[epoch14, step402]: loss 0.037922
[epoch14, step403]: loss 0.035293
[epoch14, step404]: loss 0.038222
[epoch14, step405]: loss 0.035342
[epoch14, step406]: loss 0.035657
[epoch14, step407]: loss 0.037688
[epoch14, step408]: loss 0.037941
[epoch14, step409]: loss 0.036494
[epoch14, step410]: loss 0.035815
[epoch14, step411]: loss 0.037800
[epoch14, step412]: loss 0.034995
[epoch14, step413]: loss 0.037948
[epoch14, step414]: loss 0.034735
[epoch14, step415]: loss 0.035717
[epoch14, step416]: loss 0.037295
[epoch14, step417]: loss 0.038098
[epoch14, step418]: loss 0.035166
[epoch14, step419]: loss 0.034323
[epoch14, step420]: loss 0.038128
[epoch14, step421]: loss 0.035146
[epoch14, step422]: loss 0.037861
[epoch14, step423]: loss 0.035049
[epoch14, step424]: loss 0.035563
[epoch14, step425]: loss 0.038069
[epoch14, step426]: loss 0.038196
[epoch14, step427]: loss 0.035696
[epoch14, step428]: loss 0.035064
[epoch14, step429]: loss 0.038566
[epoch14, step430]: loss 0.035364
[epoch14, step431]: loss 0.038290
[epoch14, step432]: loss 0.034935
[epoch14, step433]: loss 0.036281
[epoch14, step434]: loss 0.037895
[epoch14, step435]: loss 0.038338
[epoch14, step436]: loss 0.035060
[epoch14, step437]: loss 0.035245
[epoch14, step438]: loss 0.038525
[epoch14, step439]: loss 0.035621
[epoch14, step440]: loss 0.037899
[epoch14, step441]: loss 0.035253
[epoch14, step442]: loss 0.035341
[epoch14, step443]: loss 0.038355
[epoch14, step444]: loss 0.037621
[epoch14, step445]: loss 0.035661
[epoch14, step446]: loss 0.035530
[epoch14, step447]: loss 0.038677
[epoch14, step448]: loss 0.035563
[epoch14, step449]: loss 0.037779
[epoch14, step450]: loss 0.034499
[epoch14, step451]: loss 0.035400
[epoch14, step452]: loss 0.037365
[epoch14, step453]: loss 0.038089
[epoch14, step454]: loss 0.035314
[epoch14, step455]: loss 0.035440
[epoch14, step456]: loss 0.037401
[epoch14, step457]: loss 0.036020
[epoch14, step458]: loss 0.037615
[epoch14, step459]: loss 0.035666
[epoch14, step460]: loss 0.035789
[epoch14, step461]: loss 0.038596
[epoch14, step462]: loss 0.037308
[epoch14, step463]: loss 0.035454
[epoch14, step464]: loss 0.035082
[epoch14, step465]: loss 0.039319
[epoch14, step466]: loss 0.035308
[epoch14, step467]: loss 0.037743
[epoch14, step468]: loss 0.035050
[epoch14, step469]: loss 0.035626
[epoch14, step470]: loss 0.038233
[epoch14, step471]: loss 0.037396
[epoch14, step472]: loss 0.035748
[epoch14, step473]: loss 0.034719
[epoch14, step474]: loss 0.037834
[epoch14, step475]: loss 0.035575
[epoch14, step476]: loss 0.038390
[epoch14, step477]: loss 0.034863
[epoch14, step478]: loss 0.034943
[epoch14, step479]: loss 0.037776
[epoch14, step480]: loss 0.037227
[epoch14, step481]: loss 0.034974
[epoch14, step482]: loss 0.034544
[epoch14, step483]: loss 0.038364
[epoch14, step484]: loss 0.035583
[epoch14, step485]: loss 0.038132
[epoch14, step486]: loss 0.035368
[epoch14, step487]: loss 0.034969
[epoch14, step488]: loss 0.038372
[epoch14, step489]: loss 0.037192
[epoch14, step490]: loss 0.035737
[epoch14, step491]: loss 0.035279
[epoch14, step492]: loss 0.037628
[epoch14, step493]: loss 0.035162
[epoch14, step494]: loss 0.037366
[epoch14, step495]: loss 0.036191
[epoch14, step496]: loss 0.035765
[epoch14, step497]: loss 0.038045
[epoch14, step498]: loss 0.037915
[epoch14, step499]: loss 0.035610
[epoch14, step500]: loss 0.034609
[epoch14, step501]: loss 0.037544
[epoch14, step502]: loss 0.035206
[epoch14, step503]: loss 0.038168
[epoch14, step504]: loss 0.034756
[epoch14, step505]: loss 0.034633
[epoch14, step506]: loss 0.038341
[epoch14, step507]: loss 0.038280
[epoch14, step508]: loss 0.035809
[epoch14, step509]: loss 0.035005
[epoch14, step510]: loss 0.038125
[epoch14, step511]: loss 0.035864
[epoch14, step512]: loss 0.038308
[epoch14, step513]: loss 0.035248
[epoch14, step514]: loss 0.035790
[epoch14, step515]: loss 0.037962
[epoch14, step516]: loss 0.038363
[epoch14, step517]: loss 0.035424
[epoch14, step518]: loss 0.035217
[epoch14, step519]: loss 0.038046
[epoch14, step520]: loss 0.034900
[epoch14, step521]: loss 0.037654
[epoch14, step522]: loss 0.034758
[epoch14, step523]: loss 0.035473
[epoch14, step524]: loss 0.037240
[epoch14, step525]: loss 0.038208
[epoch14, step526]: loss 0.035423
[epoch14, step527]: loss 0.034840
[epoch14, step528]: loss 0.038175
[epoch14, step529]: loss 0.035009
[epoch14, step530]: loss 0.038352
[epoch14, step531]: loss 0.034838
[epoch14, step532]: loss 0.035269
[epoch14, step533]: loss 0.038980
[epoch14, step534]: loss 0.037691
[epoch14, step535]: loss 0.035967
[epoch14, step536]: loss 0.035303
[epoch14, step537]: loss 0.038074
[epoch14, step538]: loss 0.035530
[epoch14, step539]: loss 0.037673
[epoch14, step540]: loss 0.034681
[epoch14, step541]: loss 0.034996
[epoch14, step542]: loss 0.037922
[epoch14, step543]: loss 0.037661
[epoch14, step544]: loss 0.035276
[epoch14, step545]: loss 0.034435
[epoch14, step546]: loss 0.038619
[epoch14, step547]: loss 0.035252
[epoch14, step548]: loss 0.037941
[epoch14, step549]: loss 0.035434
[epoch14, step550]: loss 0.035514
[epoch14, step551]: loss 0.038016
[epoch14, step552]: loss 0.037113
[epoch14, step553]: loss 0.035744
[epoch14, step554]: loss 0.034863
[epoch14, step555]: loss 0.037552
[epoch14, step556]: loss 0.035217
[epoch14, step557]: loss 0.037244
[epoch14, step558]: loss 0.035269
[epoch14, step559]: loss 0.034977
[epoch14, step560]: loss 0.038136
[epoch14, step561]: loss 0.037669
[epoch14, step562]: loss 0.035150
[epoch14, step563]: loss 0.028966
[epoch14, step564]: loss 0.029349
[epoch14, step565]: loss 0.027768
[epoch14, step566]: loss 0.034643
[epoch14, step567]: loss 0.026814
[epoch14, step568]: loss 0.025846
[epoch14, step569]: loss 0.023132
[epoch14, step570]: loss 0.031149
[epoch14, step571]: loss 0.027070
[epoch14, step572]: loss 0.025832
[epoch14, step573]: loss 0.029010
[epoch14, step574]: loss 0.027707
[epoch14, step575]: loss 0.020682
[epoch14, step576]: loss 0.021451
[epoch14, step577]: loss 0.026082
[epoch14, step578]: loss 0.018673
[epoch14, step579]: loss 0.028265
[epoch14, step580]: loss 0.020133
[epoch14, step581]: loss 0.025928
[epoch14, step582]: loss 0.025150
[epoch14, step583]: loss 0.021918
[epoch14, step584]: loss 0.023584
[epoch14, step585]: loss 0.025858
[epoch14, step586]: loss 0.021547
[epoch14, step587]: loss 0.027659
[epoch14, step588]: loss 0.022861
[epoch14, step589]: loss 0.022836
[epoch14, step590]: loss 0.027084
[epoch14, step591]: loss 0.020340
[epoch14, step592]: loss 0.025890
[epoch14, step593]: loss 0.022038
[epoch14, step594]: loss 0.026001
[epoch14, step595]: loss 0.026464
[epoch14, step596]: loss 0.022175
[epoch14, step597]: loss 0.024792
[epoch14, step598]: loss 0.026708
[epoch14, step599]: loss 0.025021
[epoch14, step600]: loss 0.026983
[epoch14, step601]: loss 0.019572
[epoch14, step602]: loss 0.022683
[epoch14, step603]: loss 0.025727
[epoch14, step604]: loss 0.026432
[epoch14, step605]: loss 0.025194
[epoch14, step606]: loss 0.025009
[epoch14, step607]: loss 0.026939
[epoch14, step608]: loss 0.025617
[epoch14, step609]: loss 0.026531
[epoch14, step610]: loss 0.025893
[epoch14, step611]: loss 0.026174
[epoch14, step612]: loss 0.025482
[epoch14, step613]: loss 0.019353
[epoch14, step614]: loss 0.025091
[epoch14, step615]: loss 0.028204
[epoch14, step616]: loss 0.024098
[epoch14, step617]: loss 0.023501
[epoch14, step618]: loss 0.025724
[epoch14, step619]: loss 0.026948
[epoch14, step620]: loss 0.024361
[epoch14, step621]: loss 0.026239
[epoch14, step622]: loss 0.020403
[epoch14, step623]: loss 0.024571
[epoch14, step624]: loss 0.026450
[epoch14, step625]: loss 0.025882
[epoch14, step626]: loss 0.028324
[epoch14, step627]: loss 0.022669
[epoch14, step628]: loss 0.025407
[epoch14, step629]: loss 0.020729
[epoch14, step630]: loss 0.023269
[epoch14, step631]: loss 0.031307
[epoch14, step632]: loss 0.023294
[epoch14, step633]: loss 0.024684
[epoch14, step634]: loss 0.027325
[epoch14, step635]: loss 0.025371
[epoch14, step636]: loss 0.020672
[epoch14, step637]: loss 0.027199
[epoch14, step638]: loss 0.026964
[epoch14, step639]: loss 0.022849
[epoch14, step640]: loss 0.029612
[epoch14, step641]: loss 0.030343
[epoch14, step642]: loss 0.025007
[epoch14, step643]: loss 0.025700
[epoch14, step644]: loss 0.025859
[epoch14, step645]: loss 0.023497
[epoch14, step646]: loss 0.026252
[epoch14, step647]: loss 0.023655
[epoch14, step648]: loss 0.023057
[epoch14, step649]: loss 0.028527
[epoch14, step650]: loss 0.021974
[epoch14, step651]: loss 0.026146
[epoch14, step652]: loss 0.026766
[epoch14, step653]: loss 0.027951
[epoch14, step654]: loss 0.023211
[epoch14, step655]: loss 0.024414
[epoch14, step656]: loss 0.021552
[epoch14, step657]: loss 0.027792
[epoch14, step658]: loss 0.025492
[epoch14, step659]: loss 0.027597
[epoch14, step660]: loss 0.023900
[epoch14, step661]: loss 0.026503
[epoch14, step662]: loss 0.024027
[epoch14, step663]: loss 0.021055
[epoch14, step664]: loss 0.024862
[epoch14, step665]: loss 0.027819
[epoch14, step666]: loss 0.026834
[epoch14, step667]: loss 0.026446
[epoch14, step668]: loss 0.022228
[epoch14, step669]: loss 0.026434
[epoch14, step670]: loss 0.026682
[epoch14, step671]: loss 0.021674
[epoch14, step672]: loss 0.023553
[epoch14, step673]: loss 0.022100
[epoch14, step674]: loss 0.021179
[epoch14, step675]: loss 0.019949
[epoch14, step676]: loss 0.024690
[epoch14, step677]: loss 0.025155
[epoch14, step678]: loss 0.023165
[epoch14, step679]: loss 0.023822
[epoch14, step680]: loss 0.030621
[epoch14, step681]: loss 0.021954
[epoch14, step682]: loss 0.026214
[epoch14, step683]: loss 0.025992
[epoch14, step684]: loss 0.024693
[epoch14, step685]: loss 0.024382
[epoch14, step686]: loss 0.027183
[epoch14, step687]: loss 0.026726
[epoch14, step688]: loss 0.022530
[epoch14, step689]: loss 0.024648
[epoch14, step690]: loss 0.025218
[epoch14, step691]: loss 0.024331
[epoch14, step692]: loss 0.022462
[epoch14, step693]: loss 0.027150
[epoch14, step694]: loss 0.022757
[epoch14, step695]: loss 0.026280
[epoch14, step696]: loss 0.025993
[epoch14, step697]: loss 0.026756
[epoch14, step698]: loss 0.024652
[epoch14, step699]: loss 0.023554
[epoch14, step700]: loss 0.021676
[epoch14, step701]: loss 0.026142
[epoch14, step702]: loss 0.021813
[epoch14, step703]: loss 0.022945
[epoch14, step704]: loss 0.025479
[epoch14, step705]: loss 0.024861
[epoch14, step706]: loss 0.023645
[epoch14, step707]: loss 0.024561
[epoch14, step708]: loss 0.026028
[epoch14, step709]: loss 0.027417
[epoch14, step710]: loss 0.023852
[epoch14, step711]: loss 0.023674
[epoch14, step712]: loss 0.026725
[epoch14, step713]: loss 0.026250
[epoch14, step714]: loss 0.021298
[epoch14, step715]: loss 0.023090
[epoch14, step716]: loss 0.025756
[epoch14, step717]: loss 0.023651
[epoch14, step718]: loss 0.025138
[epoch14, step719]: loss 0.032857
[epoch14, step720]: loss 0.024837
[epoch14, step721]: loss 0.023018
[epoch14, step722]: loss 0.030836
[epoch14, step723]: loss 0.026132
[epoch14, step724]: loss 0.022950
[epoch14, step725]: loss 0.027794
[epoch14, step726]: loss 0.022351
[epoch14, step727]: loss 0.024678
[epoch14, step728]: loss 0.026431
[epoch14, step729]: loss 0.021227
[epoch14, step730]: loss 0.022693
[epoch14, step731]: loss 0.025908
[epoch14, step732]: loss 0.026036
[epoch14, step733]: loss 0.024030
[epoch14, step734]: loss 0.022812
[epoch14, step735]: loss 0.027570
[epoch14, step736]: loss 0.025214
[epoch14, step737]: loss 0.026487
[epoch14, step738]: loss 0.020662
[epoch14, step739]: loss 0.025497
[epoch14, step740]: loss 0.022393
[epoch14, step741]: loss 0.025258
[epoch14, step742]: loss 0.021760
[epoch14, step743]: loss 0.023173
[epoch14, step744]: loss 0.023998
[epoch14, step745]: loss 0.024484
[epoch14, step746]: loss 0.025224
[epoch14, step747]: loss 0.027442
[epoch14, step748]: loss 0.025656
[epoch14, step749]: loss 0.026462
[epoch14, step750]: loss 0.027655
[epoch14, step751]: loss 0.021592
[epoch14, step752]: loss 0.024987
[epoch14, step753]: loss 0.025526
[epoch14, step754]: loss 0.022658
[epoch14, step755]: loss 0.026276
[epoch14, step756]: loss 0.023407
[epoch14, step757]: loss 0.020526
[epoch14, step758]: loss 0.025154
[epoch14, step759]: loss 0.023100
[epoch14, step760]: loss 0.023957
[epoch14, step761]: loss 0.026442
[epoch14, step762]: loss 0.021536
[epoch14, step763]: loss 0.025402
[epoch14, step764]: loss 0.023429
[epoch14, step765]: loss 0.026044
[epoch14, step766]: loss 0.024684
[epoch14, step767]: loss 0.026606
[epoch14, step768]: loss 0.021514
[epoch14, step769]: loss 0.026638
[epoch14, step770]: loss 0.025873
[epoch14, step771]: loss 0.023178
[epoch14, step772]: loss 0.028967
[epoch14, step773]: loss 0.026687
[epoch14, step774]: loss 0.024056
[epoch14, step775]: loss 0.020668
[epoch14, step776]: loss 0.025643
[epoch14, step777]: loss 0.023174
[epoch14, step778]: loss 0.028096
[epoch14, step779]: loss 0.023722
[epoch14, step780]: loss 0.020094
[epoch14, step781]: loss 0.024260
[epoch14, step782]: loss 0.022903
[epoch14, step783]: loss 0.019431
[epoch14, step784]: loss 0.020484
[epoch14, step785]: loss 0.021490
[epoch14, step786]: loss 0.024284
[epoch14, step787]: loss 0.023313
[epoch14, step788]: loss 0.024690
[epoch14, step789]: loss 0.022413
[epoch14, step790]: loss 0.023227
[epoch14, step791]: loss 0.026629
[epoch14, step792]: loss 0.025133
[epoch14, step793]: loss 0.026834
[epoch14, step794]: loss 0.020271
[epoch14, step795]: loss 0.025756
[epoch14, step796]: loss 0.028013
[epoch14, step797]: loss 0.027863
[epoch14, step798]: loss 0.027360
[epoch14, step799]: loss 0.025998
[epoch14, step800]: loss 0.021386
[epoch14, step801]: loss 0.021627
[epoch14, step802]: loss 0.022548
[epoch14, step803]: loss 0.026333
[epoch14, step804]: loss 0.027469
[epoch14, step805]: loss 0.028199
[epoch14, step806]: loss 0.021298
[epoch14, step807]: loss 0.020656
[epoch14, step808]: loss 0.022940
[epoch14, step809]: loss 0.023002
[epoch14, step810]: loss 0.025791
[epoch14, step811]: loss 0.025781
[epoch14, step812]: loss 0.024468
[epoch14, step813]: loss 0.023644
[epoch14, step814]: loss 0.025147
[epoch14, step815]: loss 0.025078
[epoch14, step816]: loss 0.024307
[epoch14, step817]: loss 0.024706
[epoch14, step818]: loss 0.022473
[epoch14, step819]: loss 0.020122
[epoch14, step820]: loss 0.023424
[epoch14, step821]: loss 0.021885
[epoch14, step822]: loss 0.030344
[epoch14, step823]: loss 0.024123
[epoch14, step824]: loss 0.026739
[epoch14, step825]: loss 0.025232
[epoch14, step826]: loss 0.024440
[epoch14, step827]: loss 0.026865
[epoch14, step828]: loss 0.028691
[epoch14, step829]: loss 0.026400
[epoch14, step830]: loss 0.022485
[epoch14, step831]: loss 0.026446
[epoch14, step832]: loss 0.020847
[epoch14, step833]: loss 0.029059
[epoch14, step834]: loss 0.025513
[epoch14, step835]: loss 0.020580
[epoch14, step836]: loss 0.027054
[epoch14, step837]: loss 0.025863
[epoch14, step838]: loss 0.026091
[epoch14, step839]: loss 0.028486
[epoch14, step840]: loss 0.020771
[epoch14, step841]: loss 0.024601
[epoch14, step842]: loss 0.027672
[epoch14, step843]: loss 0.024993
[epoch14, step844]: loss 0.025029
[epoch14, step845]: loss 0.021071
[epoch14, step846]: loss 0.025379
[epoch14, step847]: loss 0.026805
[epoch14, step848]: loss 0.024884
[epoch14, step849]: loss 0.025097
[epoch14, step850]: loss 0.022988
[epoch14, step851]: loss 0.023913
[epoch14, step852]: loss 0.023115
[epoch14, step853]: loss 0.029053
[epoch14, step854]: loss 0.022874
[epoch14, step855]: loss 0.027309
[epoch14, step856]: loss 0.022153
[epoch14, step857]: loss 0.026045
[epoch14, step858]: loss 0.024378
[epoch14, step859]: loss 0.023777
[epoch14, step860]: loss 0.022736
[epoch14, step861]: loss 0.023501
[epoch14, step862]: loss 0.023079
[epoch14, step863]: loss 0.020609
[epoch14, step864]: loss 0.026349
[epoch14, step865]: loss 0.023470
[epoch14, step866]: loss 0.025217
[epoch14, step867]: loss 0.025914
[epoch14, step868]: loss 0.026859
[epoch14, step869]: loss 0.023864
[epoch14, step870]: loss 0.030990
[epoch14, step871]: loss 0.021955
[epoch14, step872]: loss 0.025528
[epoch14, step873]: loss 0.025867
[epoch14, step874]: loss 0.023729
[epoch14, step875]: loss 0.024129
[epoch14, step876]: loss 0.024422
[epoch14, step877]: loss 0.019042
[epoch14, step878]: loss 0.023368
[epoch14, step879]: loss 0.027873
[epoch14, step880]: loss 0.025840
[epoch14, step881]: loss 0.022109
[epoch14, step882]: loss 0.024162
[epoch14, step883]: loss 0.023756
[epoch14, step884]: loss 0.026331
[epoch14, step885]: loss 0.025995
[epoch14, step886]: loss 0.026671
[epoch14, step887]: loss 0.024170
[epoch14, step888]: loss 0.024641
[epoch14, step889]: loss 0.023523
[epoch14, step890]: loss 0.023497
[epoch14, step891]: loss 0.025583
[epoch14, step892]: loss 0.021115
[epoch14, step893]: loss 0.024712
[epoch14, step894]: loss 0.024949
[epoch14, step895]: loss 0.022637
[epoch14, step896]: loss 0.021773
[epoch14, step897]: loss 0.023913
[epoch14, step898]: loss 0.025426
[epoch14, step899]: loss 0.027995
[epoch14, step900]: loss 0.026918
[epoch14, step901]: loss 0.025423
[epoch14, step902]: loss 0.023933
[epoch14, step903]: loss 0.024127
[epoch14, step904]: loss 0.028048
[epoch14, step905]: loss 0.027732
[epoch14, step906]: loss 0.022404
[epoch14, step907]: loss 0.023637
[epoch14, step908]: loss 0.022458
[epoch14, step909]: loss 0.025492
[epoch14, step910]: loss 0.023081
[epoch14, step911]: loss 0.025220
[epoch14, step912]: loss 0.023838
[epoch14, step913]: loss 0.024007
[epoch14, step914]: loss 0.030529
[epoch14, step915]: loss 0.024083
[epoch14, step916]: loss 0.023805
[epoch14, step917]: loss 0.025058
[epoch14, step918]: loss 0.028552
[epoch14, step919]: loss 0.024244
[epoch14, step920]: loss 0.027485
[epoch14, step921]: loss 0.024523
[epoch14, step922]: loss 0.023304
[epoch14, step923]: loss 0.022541
[epoch14, step924]: loss 0.021166
[epoch14, step925]: loss 0.025339
[epoch14, step926]: loss 0.026441
[epoch14, step927]: loss 0.025817
[epoch14, step928]: loss 0.024898
[epoch14, step929]: loss 0.027685
[epoch14, step930]: loss 0.025730
[epoch14, step931]: loss 0.027177
[epoch14, step932]: loss 0.021690
[epoch14, step933]: loss 0.028219
[epoch14, step934]: loss 0.021942
[epoch14, step935]: loss 0.021921
[epoch14, step936]: loss 0.022465
[epoch14, step937]: loss 0.027192
[epoch14, step938]: loss 0.025132
[epoch14, step939]: loss 0.020754
[epoch14, step940]: loss 0.022872
[epoch14, step941]: loss 0.026859
[epoch14, step942]: loss 0.025526
[epoch14, step943]: loss 0.023237
[epoch14, step944]: loss 0.027520
[epoch14, step945]: loss 0.020526
[epoch14, step946]: loss 0.025471
[epoch14, step947]: loss 0.028012
[epoch14, step948]: loss 0.019412
[epoch14, step949]: loss 0.022910
[epoch14, step950]: loss 0.026608
[epoch14, step951]: loss 0.028715
[epoch14, step952]: loss 0.025152
[epoch14, step953]: loss 0.027489
[epoch14, step954]: loss 0.022193
[epoch14, step955]: loss 0.037342
[epoch14, step956]: loss 0.052894
[epoch14, step957]: loss 0.046826
[epoch14, step958]: loss 0.044544
[epoch14, step959]: loss 0.048784
[epoch14, step960]: loss 0.045056
[epoch14, step961]: loss 0.046136
[epoch14, step962]: loss 0.044442
[epoch14, step963]: loss 0.042495
[epoch14, step964]: loss 0.043339
[epoch14, step965]: loss 0.043603
[epoch14, step966]: loss 0.041246
[epoch14, step967]: loss 0.039892
[epoch14, step968]: loss 0.042165
[epoch14, step969]: loss 0.041534
[epoch14, step970]: loss 0.041081
[epoch14, step971]: loss 0.040133
[epoch14, step972]: loss 0.041390
[epoch14, step973]: loss 0.040884
[epoch14, step974]: loss 0.042232
[epoch14, step975]: loss 0.039181
[epoch14, step976]: loss 0.038183
[epoch14, step977]: loss 0.041475
[epoch14, step978]: loss 0.040991
[epoch14, step979]: loss 0.037949
[epoch14, step980]: loss 0.036633
[epoch14, step981]: loss 0.037770
[epoch14, step982]: loss 0.038322
[epoch14, step983]: loss 0.038901
[epoch14, step984]: loss 0.035375
[epoch14, step985]: loss 0.035808
[epoch14, step986]: loss 0.040022
[epoch14, step987]: loss 0.038126
[epoch14, step988]: loss 0.037784
[epoch14, step989]: loss 0.036581
[epoch14, step990]: loss 0.037384
[epoch14, step991]: loss 0.038552
[epoch14, step992]: loss 0.038271
[epoch14, step993]: loss 0.036256
[epoch14, step994]: loss 0.035259
[epoch14, step995]: loss 0.039420
[epoch14, step996]: loss 0.038003
[epoch14, step997]: loss 0.037188
[epoch14, step998]: loss 0.037143
[epoch14, step999]: loss 0.038673
[epoch14, step1000]: loss 0.038075
[epoch14, step1001]: loss 0.038985
[epoch14, step1002]: loss 0.036956
[epoch14, step1003]: loss 0.035183
[epoch14, step1004]: loss 0.039730
[epoch14, step1005]: loss 0.037151
[epoch14, step1006]: loss 0.036949
[epoch14, step1007]: loss 0.035318
[epoch14, step1008]: loss 0.036903
[epoch14, step1009]: loss 0.037570
[epoch14, step1010]: loss 0.038918
[epoch14, step1011]: loss 0.035933
[epoch14, step1012]: loss 0.036004
[epoch14, step1013]: loss 0.039202
[epoch14, step1014]: loss 0.038377
[epoch14, step1015]: loss 0.037259
[epoch14, step1016]: loss 0.035837
[epoch14, step1017]: loss 0.037300
[epoch14, step1018]: loss 0.037590
[epoch14, step1019]: loss 0.039012
[epoch14, step1020]: loss 0.035613
[epoch14, step1021]: loss 0.035505
[epoch14, step1022]: loss 0.039033
[epoch14, step1023]: loss 0.037383
[epoch14, step1024]: loss 0.037917
[epoch14, step1025]: loss 0.035142
[epoch14, step1026]: loss 0.036662
[epoch14, step1027]: loss 0.037103
[epoch14, step1028]: loss 0.038349
[epoch14, step1029]: loss 0.035531
[epoch14, step1030]: loss 0.034830
[epoch14, step1031]: loss 0.037588
[epoch14, step1032]: loss 0.037674
[epoch14, step1033]: loss 0.036472
[epoch14, step1034]: loss 0.035484
[epoch14, step1035]: loss 0.036515
[epoch14, step1036]: loss 0.037563
[epoch14, step1037]: loss 0.038211
[epoch14, step1038]: loss 0.035496
[epoch14, step1039]: loss 0.035863
[epoch14, step1040]: loss 0.038138
[epoch14, step1041]: loss 0.037136
[epoch14, step1042]: loss 0.036055
[epoch14, step1043]: loss 0.035417
[epoch14, step1044]: loss 0.037400
[epoch14, step1045]: loss 0.037408
[epoch14, step1046]: loss 0.038498
[epoch14, step1047]: loss 0.035868
[epoch14, step1048]: loss 0.035131
[epoch14, step1049]: loss 0.038740
[epoch14, step1050]: loss 0.037614
[epoch14, step1051]: loss 0.036916
[epoch14, step1052]: loss 0.035888
[epoch14, step1053]: loss 0.037433
[epoch14, step1054]: loss 0.037484
[epoch14, step1055]: loss 0.037907
[epoch14, step1056]: loss 0.035001
[epoch14, step1057]: loss 0.036096
[epoch14, step1058]: loss 0.039406
[epoch14, step1059]: loss 0.037603
[epoch14, step1060]: loss 0.036968
[epoch14, step1061]: loss 0.035130
[epoch14, step1062]: loss 0.037541
[epoch14, step1063]: loss 0.037341
[epoch14, step1064]: loss 0.038443
[epoch14, step1065]: loss 0.035472
[epoch14, step1066]: loss 0.035409
[epoch14, step1067]: loss 0.038728
[epoch14, step1068]: loss 0.036081
[epoch14, step1069]: loss 0.036597
[epoch14, step1070]: loss 0.035228
[epoch14, step1071]: loss 0.037670
[epoch14, step1072]: loss 0.038008
[epoch14, step1073]: loss 0.038078
[epoch14, step1074]: loss 0.035808
[epoch14, step1075]: loss 0.035698
[epoch14, step1076]: loss 0.038640
[epoch14, step1077]: loss 0.037200
[epoch14, step1078]: loss 0.036570
[epoch14, step1079]: loss 0.036481
[epoch14, step1080]: loss 0.037230
[epoch14, step1081]: loss 0.036998
[epoch14, step1082]: loss 0.038118
[epoch14, step1083]: loss 0.036205
[epoch14, step1084]: loss 0.035724
[epoch14, step1085]: loss 0.038095
[epoch14, step1086]: loss 0.036907
[epoch14, step1087]: loss 0.036859
[epoch14, step1088]: loss 0.035343
[epoch14, step1089]: loss 0.037530
[epoch14, step1090]: loss 0.037792
[epoch14, step1091]: loss 0.038605
[epoch14, step1092]: loss 0.035392
[epoch14, step1093]: loss 0.035520
[epoch14, step1094]: loss 0.037794
[epoch14, step1095]: loss 0.036687
[epoch14, step1096]: loss 0.036397
[epoch14, step1097]: loss 0.035406
[epoch14, step1098]: loss 0.037040
[epoch14, step1099]: loss 0.036886
[epoch14, step1100]: loss 0.038697
[epoch14, step1101]: loss 0.035925
[epoch14, step1102]: loss 0.035277
[epoch14, step1103]: loss 0.037962
[epoch14, step1104]: loss 0.037148
[epoch14, step1105]: loss 0.036864
[epoch14, step1106]: loss 0.034510
[epoch14, step1107]: loss 0.037329
[epoch14, step1108]: loss 0.036871
[epoch14, step1109]: loss 0.038639
[epoch14, step1110]: loss 0.036307
[epoch14, step1111]: loss 0.035781
[epoch14, step1112]: loss 0.039004
[epoch14, step1113]: loss 0.036832
[epoch14, step1114]: loss 0.037189
[epoch14, step1115]: loss 0.035542
[epoch14, step1116]: loss 0.037228
[epoch14, step1117]: loss 0.037248
[epoch14, step1118]: loss 0.038067
[epoch14, step1119]: loss 0.035472
[epoch14, step1120]: loss 0.035390
[epoch14, step1121]: loss 0.038468
[epoch14, step1122]: loss 0.036667
[epoch14, step1123]: loss 0.036055
[epoch14, step1124]: loss 0.036186
[epoch14, step1125]: loss 0.037519
[epoch14, step1126]: loss 0.038231
[epoch14, step1127]: loss 0.038323
[epoch14, step1128]: loss 0.035794
[epoch14, step1129]: loss 0.035314
[epoch14, step1130]: loss 0.039372
[epoch14, step1131]: loss 0.037438
[epoch14, step1132]: loss 0.037123
[epoch14, step1133]: loss 0.034980
[epoch14, step1134]: loss 0.036936
[epoch14, step1135]: loss 0.038140
[epoch14, step1136]: loss 0.039090
[epoch14, step1137]: loss 0.035678
[epoch14, step1138]: loss 0.035619
[epoch14, step1139]: loss 0.038557
[epoch14, step1140]: loss 0.036455
[epoch14, step1141]: loss 0.036494
[epoch14, step1142]: loss 0.035199
[epoch14, step1143]: loss 0.036632
[epoch14, step1144]: loss 0.037393
[epoch14, step1145]: loss 0.037687
[epoch14, step1146]: loss 0.035239
[epoch14, step1147]: loss 0.036169
[epoch14, step1148]: loss 0.038619
[epoch14, step1149]: loss 0.036753
[epoch14, step1150]: loss 0.036594
[epoch14, step1151]: loss 0.035876
[epoch14, step1152]: loss 0.037668
[epoch14, step1153]: loss 0.036651
[epoch14, step1154]: loss 0.038634
[epoch14, step1155]: loss 0.035781
[epoch14, step1156]: loss 0.034826
[epoch14, step1157]: loss 0.038364
[epoch14, step1158]: loss 0.037260
[epoch14, step1159]: loss 0.036952
[epoch14, step1160]: loss 0.036201
[epoch14, step1161]: loss 0.037564
[epoch14, step1162]: loss 0.037332
[epoch14, step1163]: loss 0.037510
[epoch14, step1164]: loss 0.035633
[epoch14, step1165]: loss 0.036437
[epoch14, step1166]: loss 0.038673
[epoch14, step1167]: loss 0.036308
[epoch14, step1168]: loss 0.036924
[epoch14, step1169]: loss 0.035278
[epoch14, step1170]: loss 0.037194
[epoch14, step1171]: loss 0.037256
[epoch14, step1172]: loss 0.038213
[epoch14, step1173]: loss 0.035709
[epoch14, step1174]: loss 0.035860
[epoch14, step1175]: loss 0.038408
[epoch14, step1176]: loss 0.036816
[epoch14, step1177]: loss 0.036963
[epoch14, step1178]: loss 0.035515
[epoch14, step1179]: loss 0.037272
[epoch14, step1180]: loss 0.037350
[epoch14, step1181]: loss 0.038813
[epoch14, step1182]: loss 0.034992
[epoch14, step1183]: loss 0.035961
[epoch14, step1184]: loss 0.038072
[epoch14, step1185]: loss 0.037145
[epoch14, step1186]: loss 0.035981
[epoch14, step1187]: loss 0.034564
[epoch14, step1188]: loss 0.036443
[epoch14, step1189]: loss 0.037033
[epoch14, step1190]: loss 0.037852
[epoch14, step1191]: loss 0.036106
[epoch14, step1192]: loss 0.035597
[epoch14, step1193]: loss 0.038559
[epoch14, step1194]: loss 0.036871
[epoch14, step1195]: loss 0.035608
[epoch14, step1196]: loss 0.034859
[epoch14, step1197]: loss 0.037505
[epoch14, step1198]: loss 0.037343
[epoch14, step1199]: loss 0.037871
[epoch14, step1200]: loss 0.035340
[epoch14, step1201]: loss 0.035987
[epoch14, step1202]: loss 0.039368
[epoch14, step1203]: loss 0.037115
[epoch14, step1204]: loss 0.036055
[epoch14, step1205]: loss 0.034939
[epoch14, step1206]: loss 0.036614
[epoch14, step1207]: loss 0.037523
[epoch14, step1208]: loss 0.038561
[epoch14, step1209]: loss 0.034511
[epoch14, step1210]: loss 0.036025
[epoch14, step1211]: loss 0.038111
[epoch14, step1212]: loss 0.036867
[epoch14, step1213]: loss 0.036369
[epoch14, step1214]: loss 0.035621
[epoch14, step1215]: loss 0.037732
[epoch14, step1216]: loss 0.036743
[epoch14, step1217]: loss 0.038792
[epoch14, step1218]: loss 0.035124
[epoch14, step1219]: loss 0.036056
[epoch14, step1220]: loss 0.038872
[epoch14, step1221]: loss 0.036233
[epoch14, step1222]: loss 0.036769
[epoch14, step1223]: loss 0.035406
[epoch14, step1224]: loss 0.037618
[epoch14, step1225]: loss 0.037347
[epoch14, step1226]: loss 0.037987
[epoch14, step1227]: loss 0.035658
[epoch14, step1228]: loss 0.035208
[epoch14, step1229]: loss 0.038293
[epoch14, step1230]: loss 0.037195
[epoch14, step1231]: loss 0.036632
[epoch14, step1232]: loss 0.036333
[epoch14, step1233]: loss 0.036913
[epoch14, step1234]: loss 0.036924
[epoch14, step1235]: loss 0.038553
[epoch14, step1236]: loss 0.035673
[epoch14, step1237]: loss 0.034986
[epoch14, step1238]: loss 0.038002
[epoch14, step1239]: loss 0.037660
[epoch14, step1240]: loss 0.036926
[epoch14, step1241]: loss 0.035098
[epoch14, step1242]: loss 0.037132
[epoch14, step1243]: loss 0.037113
[epoch14, step1244]: loss 0.038471
[epoch14, step1245]: loss 0.035949
[epoch14, step1246]: loss 0.035803
[epoch14, step1247]: loss 0.037597
[epoch14, step1248]: loss 0.037052
[epoch14, step1249]: loss 0.037410
[epoch14, step1250]: loss 0.035249
[epoch14, step1251]: loss 0.037628
[epoch14, step1252]: loss 0.038078
[epoch14, step1253]: loss 0.038500
[epoch14, step1254]: loss 0.035631
[epoch14, step1255]: loss 0.035637
[epoch14, step1256]: loss 0.038955
[epoch14, step1257]: loss 0.037316
[epoch14, step1258]: loss 0.036961
[epoch14, step1259]: loss 0.035377
[epoch14, step1260]: loss 0.037288
[epoch14, step1261]: loss 0.037069
[epoch14, step1262]: loss 0.037104
[epoch14, step1263]: loss 0.036131
[epoch14, step1264]: loss 0.035354
[epoch14, step1265]: loss 0.037418
[epoch14, step1266]: loss 0.037016
[epoch14, step1267]: loss 0.037042
[epoch14, step1268]: loss 0.035587
[epoch14, step1269]: loss 0.037210
[epoch14, step1270]: loss 0.036517
[epoch14, step1271]: loss 0.038559
[epoch14, step1272]: loss 0.035622
[epoch14, step1273]: loss 0.035229
[epoch14, step1274]: loss 0.038453
[epoch14, step1275]: loss 0.037418
[epoch14, step1276]: loss 0.036632
[epoch14, step1277]: loss 0.035517
[epoch14, step1278]: loss 0.037811
[epoch14, step1279]: loss 0.037581
[epoch14, step1280]: loss 0.038457
[epoch14, step1281]: loss 0.035445
[epoch14, step1282]: loss 0.035618
[epoch14, step1283]: loss 0.037903
[epoch14, step1284]: loss 0.036500
[epoch14, step1285]: loss 0.037151
[epoch14, step1286]: loss 0.034881
[epoch14, step1287]: loss 0.037796
[epoch14, step1288]: loss 0.037947
[epoch14, step1289]: loss 0.038988
[epoch14, step1290]: loss 0.035603
[epoch14, step1291]: loss 0.035130
[epoch14, step1292]: loss 0.039332
[epoch14, step1293]: loss 0.036297
[epoch14, step1294]: loss 0.036698
[epoch14, step1295]: loss 0.035955
[epoch14, step1296]: loss 0.037408
[epoch14, step1297]: loss 0.037152
[epoch14, step1298]: loss 0.038872
[epoch14, step1299]: loss 0.035959
[epoch14, step1300]: loss 0.036340
[epoch14, step1301]: loss 0.037598
[epoch14, step1302]: loss 0.037042
[epoch14, step1303]: loss 0.036881
[epoch14, step1304]: loss 0.034813
[epoch14, step1305]: loss 0.037885
[epoch14, step1306]: loss 0.037426
[epoch14, step1307]: loss 0.037856
[epoch14, step1308]: loss 0.035733
[epoch14, step1309]: loss 0.035087
[epoch14, step1310]: loss 0.038577
[epoch14, step1311]: loss 0.036116
[epoch14, step1312]: loss 0.037546
[epoch14, step1313]: loss 0.035589
[epoch14, step1314]: loss 0.036967
[epoch14, step1315]: loss 0.036917
[epoch14, step1316]: loss 0.039421
[epoch14, step1317]: loss 0.035065
[epoch14, step1318]: loss 0.034951
[epoch14, step1319]: loss 0.037850
[epoch14, step1320]: loss 0.037161
[epoch14, step1321]: loss 0.037056
[epoch14, step1322]: loss 0.035081
[epoch14, step1323]: loss 0.037452
[epoch14, step1324]: loss 0.036833
[epoch14, step1325]: loss 0.038055
[epoch14, step1326]: loss 0.035317
[epoch14, step1327]: loss 0.035311
[epoch14, step1328]: loss 0.038448
[epoch14, step1329]: loss 0.036856
[epoch14, step1330]: loss 0.036907
[epoch14, step1331]: loss 0.035162
[epoch14, step1332]: loss 0.037061
[epoch14, step1333]: loss 0.036270
[epoch14, step1334]: loss 0.038621
[epoch14, step1335]: loss 0.036229
[epoch14, step1336]: loss 0.035429
[epoch14, step1337]: loss 0.037897
[epoch14, step1338]: loss 0.036989
[epoch14, step1339]: loss 0.036856
[epoch14, step1340]: loss 0.035165
[epoch14, step1341]: loss 0.037461
[epoch14, step1342]: loss 0.037050
[epoch14, step1343]: loss 0.038351
[epoch14, step1344]: loss 0.035710
[epoch14, step1345]: loss 0.035413
[epoch14, step1346]: loss 0.037957
[epoch14, step1347]: loss 0.037595
[epoch14, step1348]: loss 0.036019
[epoch14, step1349]: loss 0.035417
[epoch14, step1350]: loss 0.037390
[epoch14, step1351]: loss 0.036771
[epoch14, step1352]: loss 0.037909
[epoch14, step1353]: loss 0.035284
[epoch14, step1354]: loss 0.035236
[epoch14, step1355]: loss 0.038617
[epoch14, step1356]: loss 0.036733
[epoch14, step1357]: loss 0.036304
[epoch14, step1358]: loss 0.035314
[epoch14, step1359]: loss 0.036805
[epoch14, step1360]: loss 0.037362
[epoch14, step1361]: loss 0.038435
[epoch14, step1362]: loss 0.036087
[epoch14, step1363]: loss 0.036046
[epoch14, step1364]: loss 0.038240
[epoch14, step1365]: loss 0.037118
[epoch14, step1366]: loss 0.036594
[epoch14, step1367]: loss 0.034515
[epoch14, step1368]: loss 0.038010
[epoch14, step1369]: loss 0.037370
[epoch14, step1370]: loss 0.037974
[epoch14, step1371]: loss 0.035883
[epoch14, step1372]: loss 0.035381
[epoch14, step1373]: loss 0.038469
[epoch14, step1374]: loss 0.037800
[epoch14, step1375]: loss 0.037443
[epoch14, step1376]: loss 0.035139
[epoch14, step1377]: loss 0.036631
[epoch14, step1378]: loss 0.037211
[epoch14, step1379]: loss 0.037919
[epoch14, step1380]: loss 0.035967
[epoch14, step1381]: loss 0.035515
[epoch14, step1382]: loss 0.038711
[epoch14, step1383]: loss 0.037013
[epoch14, step1384]: loss 0.036519
[epoch14, step1385]: loss 0.034739
[epoch14, step1386]: loss 0.037423
[epoch14, step1387]: loss 0.037726
[epoch14, step1388]: loss 0.037259
[epoch14, step1389]: loss 0.034997
[epoch14, step1390]: loss 0.035603
[epoch14, step1391]: loss 0.038133
[epoch14, step1392]: loss 0.036921
[epoch14, step1393]: loss 0.036834
[epoch14, step1394]: loss 0.035970
[epoch14, step1395]: loss 0.037240
[epoch14, step1396]: loss 0.036745
[epoch14, step1397]: loss 0.037912
[epoch14, step1398]: loss 0.035374
[epoch14, step1399]: loss 0.036274
[epoch14, step1400]: loss 0.038799
[epoch14, step1401]: loss 0.036710
[epoch14, step1402]: loss 0.036803
[epoch14, step1403]: loss 0.034357
[epoch14, step1404]: loss 0.036650
[epoch14, step1405]: loss 0.036952
[epoch14, step1406]: loss 0.037937
[epoch14, step1407]: loss 0.036496
[epoch14, step1408]: loss 0.034816
[epoch14, step1409]: loss 0.037993
[epoch14, step1410]: loss 0.036839
[epoch14, step1411]: loss 0.035631
[epoch14, step1412]: loss 0.035342
[epoch14, step1413]: loss 0.037169
[epoch14, step1414]: loss 0.036729
[epoch14, step1415]: loss 0.037803
[epoch14, step1416]: loss 0.035352
[epoch14, step1417]: loss 0.035318
[epoch14, step1418]: loss 0.038287
[epoch14, step1419]: loss 0.037589
[epoch14, step1420]: loss 0.036870
[epoch14, step1421]: loss 0.035710
[epoch14, step1422]: loss 0.037399
[epoch14, step1423]: loss 0.036678
[epoch14, step1424]: loss 0.038298
[epoch14, step1425]: loss 0.034566
[epoch14, step1426]: loss 0.035490
[epoch14, step1427]: loss 0.039213
[epoch14, step1428]: loss 0.037692
[epoch14, step1429]: loss 0.036602
[epoch14, step1430]: loss 0.035305
[epoch14, step1431]: loss 0.037224
[epoch14, step1432]: loss 0.036849
[epoch14, step1433]: loss 0.038275
[epoch14, step1434]: loss 0.035083
[epoch14, step1435]: loss 0.035840
[epoch14, step1436]: loss 0.038653
[epoch14, step1437]: loss 0.037354
[epoch14, step1438]: loss 0.037517
[epoch14, step1439]: loss 0.035124
[epoch14, step1440]: loss 0.036952
[epoch14, step1441]: loss 0.037768
[epoch14, step1442]: loss 0.037433
[epoch14, step1443]: loss 0.035273
[epoch14, step1444]: loss 0.034727
[epoch14, step1445]: loss 0.038720
[epoch14, step1446]: loss 0.037051
[epoch14, step1447]: loss 0.037293
[epoch14, step1448]: loss 0.035250
[epoch14, step1449]: loss 0.036608
[epoch14, step1450]: loss 0.037130
[epoch14, step1451]: loss 0.038419
[epoch14, step1452]: loss 0.035185
[epoch14, step1453]: loss 0.036456
[epoch14, step1454]: loss 0.038759
[epoch14, step1455]: loss 0.037595
[epoch14, step1456]: loss 0.036319
[epoch14, step1457]: loss 0.035888
[epoch14, step1458]: loss 0.037202
[epoch14, step1459]: loss 0.037127
[epoch14, step1460]: loss 0.038605
[epoch14, step1461]: loss 0.036153
[epoch14, step1462]: loss 0.036088
[epoch14, step1463]: loss 0.038291
[epoch14, step1464]: loss 0.037208
[epoch14, step1465]: loss 0.036316
[epoch14, step1466]: loss 0.034958
[epoch14, step1467]: loss 0.037079
[epoch14, step1468]: loss 0.036638
[epoch14, step1469]: loss 0.038077
[epoch14, step1470]: loss 0.035618
[epoch14, step1471]: loss 0.035121
[epoch14, step1472]: loss 0.038154
[epoch14, step1473]: loss 0.036872
[epoch14, step1474]: loss 0.037217
[epoch14, step1475]: loss 0.035083
[epoch14, step1476]: loss 0.037884
[epoch14, step1477]: loss 0.036794
[epoch14, step1478]: loss 0.038195
[epoch14, step1479]: loss 0.035351
[epoch14, step1480]: loss 0.035388
[epoch14, step1481]: loss 0.037505
[epoch14, step1482]: loss 0.036851
[epoch14, step1483]: loss 0.036702
[epoch14, step1484]: loss 0.035615
[epoch14, step1485]: loss 0.036968
[epoch14, step1486]: loss 0.036140
[epoch14, step1487]: loss 0.037923
[epoch14, step1488]: loss 0.035491
[epoch14, step1489]: loss 0.035281
[epoch14, step1490]: loss 0.038331
[epoch14, step1491]: loss 0.036993
[epoch14, step1492]: loss 0.036452
[epoch14, step1493]: loss 0.035299
[epoch14, step1494]: loss 0.037208
[epoch14, step1495]: loss 0.036922
[epoch14, step1496]: loss 0.037338
[epoch14, step1497]: loss 0.035708
[epoch14, step1498]: loss 0.035794
[epoch14, step1499]: loss 0.037771
[epoch14, step1500]: loss 0.037182
[epoch14, step1501]: loss 0.036840
[epoch14, step1502]: loss 0.035258
[epoch14, step1503]: loss 0.037106
[epoch14, step1504]: loss 0.036673
[epoch14, step1505]: loss 0.038425
[epoch14, step1506]: loss 0.034890
[epoch14, step1507]: loss 0.035707
[epoch14, step1508]: loss 0.038784
[epoch14, step1509]: loss 0.036687
[epoch14, step1510]: loss 0.036252
[epoch14, step1511]: loss 0.035933
[epoch14, step1512]: loss 0.037474
[epoch14, step1513]: loss 0.036025
[epoch14, step1514]: loss 0.038503
[epoch14, step1515]: loss 0.035933
[epoch14, step1516]: loss 0.035521

[epoch14]: avg loss 0.033693

[epoch15, step1]: loss 0.033798
[epoch15, step2]: loss 0.037855
[epoch15, step3]: loss 0.037970
[epoch15, step4]: loss 0.035414
[epoch15, step5]: loss 0.035850
[epoch15, step6]: loss 0.038380
[epoch15, step7]: loss 0.036452
[epoch15, step8]: loss 0.038497
[epoch15, step9]: loss 0.035080
[epoch15, step10]: loss 0.036687
[epoch15, step11]: loss 0.038323
[epoch15, step12]: loss 0.038008
[epoch15, step13]: loss 0.035615
[epoch15, step14]: loss 0.035764
[epoch15, step15]: loss 0.038232
[epoch15, step16]: loss 0.036230
[epoch15, step17]: loss 0.038395
[epoch15, step18]: loss 0.036002
[epoch15, step19]: loss 0.036133
[epoch15, step20]: loss 0.039042
[epoch15, step21]: loss 0.037977
[epoch15, step22]: loss 0.035125
[epoch15, step23]: loss 0.034882
[epoch15, step24]: loss 0.038384
[epoch15, step25]: loss 0.035433
[epoch15, step26]: loss 0.037824
[epoch15, step27]: loss 0.034872
[epoch15, step28]: loss 0.036295
[epoch15, step29]: loss 0.038470
[epoch15, step30]: loss 0.038765
[epoch15, step31]: loss 0.034910
[epoch15, step32]: loss 0.036025
[epoch15, step33]: loss 0.038821
[epoch15, step34]: loss 0.036599
[epoch15, step35]: loss 0.038723
[epoch15, step36]: loss 0.035002
[epoch15, step37]: loss 0.036262
[epoch15, step38]: loss 0.038477
[epoch15, step39]: loss 0.038174
[epoch15, step40]: loss 0.035579
[epoch15, step41]: loss 0.034991
[epoch15, step42]: loss 0.038551
[epoch15, step43]: loss 0.035940
[epoch15, step44]: loss 0.038756
[epoch15, step45]: loss 0.035366
[epoch15, step46]: loss 0.036265
[epoch15, step47]: loss 0.037878
[epoch15, step48]: loss 0.037749
[epoch15, step49]: loss 0.033854
[epoch15, step50]: loss 0.035620
[epoch15, step51]: loss 0.038073
[epoch15, step52]: loss 0.035780
[epoch15, step53]: loss 0.038701
[epoch15, step54]: loss 0.034983
[epoch15, step55]: loss 0.036568
[epoch15, step56]: loss 0.039146
[epoch15, step57]: loss 0.038564
[epoch15, step58]: loss 0.035270
[epoch15, step59]: loss 0.034586
[epoch15, step60]: loss 0.038800
[epoch15, step61]: loss 0.035215
[epoch15, step62]: loss 0.037719
[epoch15, step63]: loss 0.034685
[epoch15, step64]: loss 0.035701
[epoch15, step65]: loss 0.038501
[epoch15, step66]: loss 0.038074
[epoch15, step67]: loss 0.035537
[epoch15, step68]: loss 0.035505
[epoch15, step69]: loss 0.038150
[epoch15, step70]: loss 0.035757
[epoch15, step71]: loss 0.037834
[epoch15, step72]: loss 0.035196
[epoch15, step73]: loss 0.036132
[epoch15, step74]: loss 0.038193
[epoch15, step75]: loss 0.038645
[epoch15, step76]: loss 0.035847
[epoch15, step77]: loss 0.036153
[epoch15, step78]: loss 0.038440
[epoch15, step79]: loss 0.035386
[epoch15, step80]: loss 0.039028
[epoch15, step81]: loss 0.035306
[epoch15, step82]: loss 0.035664
[epoch15, step83]: loss 0.038033
[epoch15, step84]: loss 0.038273
[epoch15, step85]: loss 0.036064
[epoch15, step86]: loss 0.036001
[epoch15, step87]: loss 0.039287
[epoch15, step88]: loss 0.034837
[epoch15, step89]: loss 0.038055
[epoch15, step90]: loss 0.035766
[epoch15, step91]: loss 0.035541
[epoch15, step92]: loss 0.038521
[epoch15, step93]: loss 0.038152
[epoch15, step94]: loss 0.035178
[epoch15, step95]: loss 0.035974
[epoch15, step96]: loss 0.037946
[epoch15, step97]: loss 0.036548
[epoch15, step98]: loss 0.038323
[epoch15, step99]: loss 0.035294
[epoch15, step100]: loss 0.034960
[epoch15, step101]: loss 0.038921
[epoch15, step102]: loss 0.038048
[epoch15, step103]: loss 0.035231
[epoch15, step104]: loss 0.035616
[epoch15, step105]: loss 0.038524
[epoch15, step106]: loss 0.035958
[epoch15, step107]: loss 0.038470
[epoch15, step108]: loss 0.035630
[epoch15, step109]: loss 0.035721
[epoch15, step110]: loss 0.038939
[epoch15, step111]: loss 0.037928
[epoch15, step112]: loss 0.035528
[epoch15, step113]: loss 0.036310
[epoch15, step114]: loss 0.038048
[epoch15, step115]: loss 0.035810
[epoch15, step116]: loss 0.039175
[epoch15, step117]: loss 0.035120
[epoch15, step118]: loss 0.036840
[epoch15, step119]: loss 0.038935
[epoch15, step120]: loss 0.038589
[epoch15, step121]: loss 0.035331
[epoch15, step122]: loss 0.035532
[epoch15, step123]: loss 0.038714
[epoch15, step124]: loss 0.036358
[epoch15, step125]: loss 0.038794
[epoch15, step126]: loss 0.035419
[epoch15, step127]: loss 0.035915
[epoch15, step128]: loss 0.038297
[epoch15, step129]: loss 0.038116
[epoch15, step130]: loss 0.035593
[epoch15, step131]: loss 0.034993
[epoch15, step132]: loss 0.038407
[epoch15, step133]: loss 0.035826
[epoch15, step134]: loss 0.037600
[epoch15, step135]: loss 0.035899
[epoch15, step136]: loss 0.037011
[epoch15, step137]: loss 0.038122
[epoch15, step138]: loss 0.038122
[epoch15, step139]: loss 0.035298
[epoch15, step140]: loss 0.036148
[epoch15, step141]: loss 0.038655
[epoch15, step142]: loss 0.035935
[epoch15, step143]: loss 0.037849
[epoch15, step144]: loss 0.035642
[epoch15, step145]: loss 0.035997
[epoch15, step146]: loss 0.038372
[epoch15, step147]: loss 0.039439
[epoch15, step148]: loss 0.035030
[epoch15, step149]: loss 0.035249
[epoch15, step150]: loss 0.038234
[epoch15, step151]: loss 0.035972
[epoch15, step152]: loss 0.038075
[epoch15, step153]: loss 0.035350
[epoch15, step154]: loss 0.035731
[epoch15, step155]: loss 0.038229
[epoch15, step156]: loss 0.037726
[epoch15, step157]: loss 0.035465
[epoch15, step158]: loss 0.035791
[epoch15, step159]: loss 0.038530
[epoch15, step160]: loss 0.036157
[epoch15, step161]: loss 0.038677
[epoch15, step162]: loss 0.035597
[epoch15, step163]: loss 0.036012
[epoch15, step164]: loss 0.038586
[epoch15, step165]: loss 0.038181
[epoch15, step166]: loss 0.035733
[epoch15, step167]: loss 0.035182
[epoch15, step168]: loss 0.039025
[epoch15, step169]: loss 0.035631
[epoch15, step170]: loss 0.038582
[epoch15, step171]: loss 0.035732
[epoch15, step172]: loss 0.036119
[epoch15, step173]: loss 0.038683
[epoch15, step174]: loss 0.037987
[epoch15, step175]: loss 0.036106
[epoch15, step176]: loss 0.035819
[epoch15, step177]: loss 0.038741
[epoch15, step178]: loss 0.035850
[epoch15, step179]: loss 0.037426
[epoch15, step180]: loss 0.035605
[epoch15, step181]: loss 0.036152
[epoch15, step182]: loss 0.038741
[epoch15, step183]: loss 0.038862
[epoch15, step184]: loss 0.036429
[epoch15, step185]: loss 0.035935
[epoch15, step186]: loss 0.038574
[epoch15, step187]: loss 0.036101
[epoch15, step188]: loss 0.038061
[epoch15, step189]: loss 0.035411
[epoch15, step190]: loss 0.035370
[epoch15, step191]: loss 0.038377
[epoch15, step192]: loss 0.038925
[epoch15, step193]: loss 0.033803
[epoch15, step194]: loss 0.034897
[epoch15, step195]: loss 0.038776
[epoch15, step196]: loss 0.035994
[epoch15, step197]: loss 0.038094
[epoch15, step198]: loss 0.034618
[epoch15, step199]: loss 0.036104
[epoch15, step200]: loss 0.038932
[epoch15, step201]: loss 0.038772
[epoch15, step202]: loss 0.035153
[epoch15, step203]: loss 0.035704
[epoch15, step204]: loss 0.038886
[epoch15, step205]: loss 0.035466
[epoch15, step206]: loss 0.037910
[epoch15, step207]: loss 0.035243
[epoch15, step208]: loss 0.036517
[epoch15, step209]: loss 0.038906
[epoch15, step210]: loss 0.039178
[epoch15, step211]: loss 0.036010
[epoch15, step212]: loss 0.036039
[epoch15, step213]: loss 0.038069
[epoch15, step214]: loss 0.035307
[epoch15, step215]: loss 0.038510
[epoch15, step216]: loss 0.035688
[epoch15, step217]: loss 0.035293
[epoch15, step218]: loss 0.038682
[epoch15, step219]: loss 0.038041
[epoch15, step220]: loss 0.035760
[epoch15, step221]: loss 0.035882
[epoch15, step222]: loss 0.038886
[epoch15, step223]: loss 0.036045
[epoch15, step224]: loss 0.037822
[epoch15, step225]: loss 0.035299
[epoch15, step226]: loss 0.035705
[epoch15, step227]: loss 0.037669
[epoch15, step228]: loss 0.038975
[epoch15, step229]: loss 0.034623
[epoch15, step230]: loss 0.035990
[epoch15, step231]: loss 0.038922
[epoch15, step232]: loss 0.035729
[epoch15, step233]: loss 0.037621
[epoch15, step234]: loss 0.035163
[epoch15, step235]: loss 0.036403
[epoch15, step236]: loss 0.038563
[epoch15, step237]: loss 0.038437
[epoch15, step238]: loss 0.035270
[epoch15, step239]: loss 0.034928
[epoch15, step240]: loss 0.037991
[epoch15, step241]: loss 0.036281
[epoch15, step242]: loss 0.038102
[epoch15, step243]: loss 0.036235
[epoch15, step244]: loss 0.035838
[epoch15, step245]: loss 0.038013
[epoch15, step246]: loss 0.038279
[epoch15, step247]: loss 0.035747
[epoch15, step248]: loss 0.035287
[epoch15, step249]: loss 0.037939
[epoch15, step250]: loss 0.036319
[epoch15, step251]: loss 0.038831
[epoch15, step252]: loss 0.036059
[epoch15, step253]: loss 0.035620
[epoch15, step254]: loss 0.037852
[epoch15, step255]: loss 0.038428
[epoch15, step256]: loss 0.035229
[epoch15, step257]: loss 0.035357
[epoch15, step258]: loss 0.039002
[epoch15, step259]: loss 0.036009
[epoch15, step260]: loss 0.037993
[epoch15, step261]: loss 0.036077
[epoch15, step262]: loss 0.036467
[epoch15, step263]: loss 0.037845
[epoch15, step264]: loss 0.038335
[epoch15, step265]: loss 0.035638
[epoch15, step266]: loss 0.035519
[epoch15, step267]: loss 0.037767
[epoch15, step268]: loss 0.035797
[epoch15, step269]: loss 0.038261
[epoch15, step270]: loss 0.035032
[epoch15, step271]: loss 0.036024
[epoch15, step272]: loss 0.038327
[epoch15, step273]: loss 0.038001
[epoch15, step274]: loss 0.035877
[epoch15, step275]: loss 0.035153
[epoch15, step276]: loss 0.038257
[epoch15, step277]: loss 0.036519
[epoch15, step278]: loss 0.038465
[epoch15, step279]: loss 0.035028
[epoch15, step280]: loss 0.036069
[epoch15, step281]: loss 0.038262
[epoch15, step282]: loss 0.038735
[epoch15, step283]: loss 0.035136
[epoch15, step284]: loss 0.035139
[epoch15, step285]: loss 0.039204
[epoch15, step286]: loss 0.035172
[epoch15, step287]: loss 0.038453
[epoch15, step288]: loss 0.035025
[epoch15, step289]: loss 0.036677
[epoch15, step290]: loss 0.038384
[epoch15, step291]: loss 0.038618
[epoch15, step292]: loss 0.034723
[epoch15, step293]: loss 0.035284
[epoch15, step294]: loss 0.037958
[epoch15, step295]: loss 0.035371
[epoch15, step296]: loss 0.039093
[epoch15, step297]: loss 0.035336
[epoch15, step298]: loss 0.036550
[epoch15, step299]: loss 0.037697
[epoch15, step300]: loss 0.038690
[epoch15, step301]: loss 0.035656
[epoch15, step302]: loss 0.036036
[epoch15, step303]: loss 0.038810
[epoch15, step304]: loss 0.035543
[epoch15, step305]: loss 0.037943
[epoch15, step306]: loss 0.035514
[epoch15, step307]: loss 0.035752
[epoch15, step308]: loss 0.038840
[epoch15, step309]: loss 0.038725
[epoch15, step310]: loss 0.035562
[epoch15, step311]: loss 0.035998
[epoch15, step312]: loss 0.038072
[epoch15, step313]: loss 0.036233
[epoch15, step314]: loss 0.038178
[epoch15, step315]: loss 0.036361
[epoch15, step316]: loss 0.035711
[epoch15, step317]: loss 0.038799
[epoch15, step318]: loss 0.038311
[epoch15, step319]: loss 0.034927
[epoch15, step320]: loss 0.034645
[epoch15, step321]: loss 0.037963
[epoch15, step322]: loss 0.035722
[epoch15, step323]: loss 0.037570
[epoch15, step324]: loss 0.036276
[epoch15, step325]: loss 0.036065
[epoch15, step326]: loss 0.038104
[epoch15, step327]: loss 0.037626
[epoch15, step328]: loss 0.035635
[epoch15, step329]: loss 0.035322
[epoch15, step330]: loss 0.037895
[epoch15, step331]: loss 0.036065
[epoch15, step332]: loss 0.037557
[epoch15, step333]: loss 0.035335
[epoch15, step334]: loss 0.036028
[epoch15, step335]: loss 0.038403
[epoch15, step336]: loss 0.039070
[epoch15, step337]: loss 0.035885
[epoch15, step338]: loss 0.035184
[epoch15, step339]: loss 0.038363
[epoch15, step340]: loss 0.036484
[epoch15, step341]: loss 0.037680
[epoch15, step342]: loss 0.035100
[epoch15, step343]: loss 0.036113
[epoch15, step344]: loss 0.037861
[epoch15, step345]: loss 0.037575
[epoch15, step346]: loss 0.034978
[epoch15, step347]: loss 0.035225
[epoch15, step348]: loss 0.038513
[epoch15, step349]: loss 0.036337
[epoch15, step350]: loss 0.037687
[epoch15, step351]: loss 0.034662
[epoch15, step352]: loss 0.035718
[epoch15, step353]: loss 0.038102
[epoch15, step354]: loss 0.037263
[epoch15, step355]: loss 0.034328
[epoch15, step356]: loss 0.036104
[epoch15, step357]: loss 0.038487
[epoch15, step358]: loss 0.034386
[epoch15, step359]: loss 0.039071
[epoch15, step360]: loss 0.034165
[epoch15, step361]: loss 0.035382
[epoch15, step362]: loss 0.038897
[epoch15, step363]: loss 0.037917
[epoch15, step364]: loss 0.035305
[epoch15, step365]: loss 0.035322
[epoch15, step366]: loss 0.038706
[epoch15, step367]: loss 0.035861
[epoch15, step368]: loss 0.037602
[epoch15, step369]: loss 0.035273
[epoch15, step370]: loss 0.036408
[epoch15, step371]: loss 0.039010
[epoch15, step372]: loss 0.037851
[epoch15, step373]: loss 0.034876
[epoch15, step374]: loss 0.034829
[epoch15, step375]: loss 0.039023
[epoch15, step376]: loss 0.035855
[epoch15, step377]: loss 0.038319
[epoch15, step378]: loss 0.035880
[epoch15, step379]: loss 0.036550
[epoch15, step380]: loss 0.038912
[epoch15, step381]: loss 0.037987
[epoch15, step382]: loss 0.035760
[epoch15, step383]: loss 0.034605
[epoch15, step384]: loss 0.037603
[epoch15, step385]: loss 0.035623
[epoch15, step386]: loss 0.038276
[epoch15, step387]: loss 0.035383
[epoch15, step388]: loss 0.036956
[epoch15, step389]: loss 0.038351
[epoch15, step390]: loss 0.039255
[epoch15, step391]: loss 0.035012
[epoch15, step392]: loss 0.036100
[epoch15, step393]: loss 0.037882
[epoch15, step394]: loss 0.035835
[epoch15, step395]: loss 0.037935
[epoch15, step396]: loss 0.035614
[epoch15, step397]: loss 0.035650
[epoch15, step398]: loss 0.038530
[epoch15, step399]: loss 0.038215
[epoch15, step400]: loss 0.035145
[epoch15, step401]: loss 0.035318
[epoch15, step402]: loss 0.038268
[epoch15, step403]: loss 0.035694
[epoch15, step404]: loss 0.038660
[epoch15, step405]: loss 0.035784
[epoch15, step406]: loss 0.036047
[epoch15, step407]: loss 0.038083
[epoch15, step408]: loss 0.038261
[epoch15, step409]: loss 0.036622
[epoch15, step410]: loss 0.036149
[epoch15, step411]: loss 0.038138
[epoch15, step412]: loss 0.035300
[epoch15, step413]: loss 0.038048
[epoch15, step414]: loss 0.035097
[epoch15, step415]: loss 0.036115
[epoch15, step416]: loss 0.037585
[epoch15, step417]: loss 0.038406
[epoch15, step418]: loss 0.035289
[epoch15, step419]: loss 0.034757
[epoch15, step420]: loss 0.038507
[epoch15, step421]: loss 0.035501
[epoch15, step422]: loss 0.038109
[epoch15, step423]: loss 0.035453
[epoch15, step424]: loss 0.035995
[epoch15, step425]: loss 0.038439
[epoch15, step426]: loss 0.038522
[epoch15, step427]: loss 0.035698
[epoch15, step428]: loss 0.035378
[epoch15, step429]: loss 0.038908
[epoch15, step430]: loss 0.035700
[epoch15, step431]: loss 0.038424
[epoch15, step432]: loss 0.035252
[epoch15, step433]: loss 0.036640
[epoch15, step434]: loss 0.038139
[epoch15, step435]: loss 0.038593
[epoch15, step436]: loss 0.035120
[epoch15, step437]: loss 0.035667
[epoch15, step438]: loss 0.038921
[epoch15, step439]: loss 0.036031
[epoch15, step440]: loss 0.038128
[epoch15, step441]: loss 0.035643
[epoch15, step442]: loss 0.035800
[epoch15, step443]: loss 0.038748
[epoch15, step444]: loss 0.037959
[epoch15, step445]: loss 0.035802
[epoch15, step446]: loss 0.035881
[epoch15, step447]: loss 0.038972
[epoch15, step448]: loss 0.035928
[epoch15, step449]: loss 0.037969
[epoch15, step450]: loss 0.034803
[epoch15, step451]: loss 0.035748
[epoch15, step452]: loss 0.037617
[epoch15, step453]: loss 0.038415
[epoch15, step454]: loss 0.035323
[epoch15, step455]: loss 0.035718
[epoch15, step456]: loss 0.037636
[epoch15, step457]: loss 0.036475
[epoch15, step458]: loss 0.037934
[epoch15, step459]: loss 0.036227
[epoch15, step460]: loss 0.036126
[epoch15, step461]: loss 0.039073
[epoch15, step462]: loss 0.037682
[epoch15, step463]: loss 0.035576
[epoch15, step464]: loss 0.035391
[epoch15, step465]: loss 0.039713
[epoch15, step466]: loss 0.035787
[epoch15, step467]: loss 0.037994
[epoch15, step468]: loss 0.035472
[epoch15, step469]: loss 0.036083
[epoch15, step470]: loss 0.038491
[epoch15, step471]: loss 0.037752
[epoch15, step472]: loss 0.035838
[epoch15, step473]: loss 0.035123
[epoch15, step474]: loss 0.038183
[epoch15, step475]: loss 0.035920
[epoch15, step476]: loss 0.038557
[epoch15, step477]: loss 0.035198
[epoch15, step478]: loss 0.035299
[epoch15, step479]: loss 0.038157
[epoch15, step480]: loss 0.037561
[epoch15, step481]: loss 0.035019
[epoch15, step482]: loss 0.034933
[epoch15, step483]: loss 0.038709
[epoch15, step484]: loss 0.035939
[epoch15, step485]: loss 0.038323
[epoch15, step486]: loss 0.035782
[epoch15, step487]: loss 0.035298
[epoch15, step488]: loss 0.038704
[epoch15, step489]: loss 0.037479
[epoch15, step490]: loss 0.035769
[epoch15, step491]: loss 0.035704
[epoch15, step492]: loss 0.037942
[epoch15, step493]: loss 0.035492
[epoch15, step494]: loss 0.037490
[epoch15, step495]: loss 0.036474
[epoch15, step496]: loss 0.036088
[epoch15, step497]: loss 0.038559
[epoch15, step498]: loss 0.038247
[epoch15, step499]: loss 0.035638
[epoch15, step500]: loss 0.035032
[epoch15, step501]: loss 0.037827
[epoch15, step502]: loss 0.035578
[epoch15, step503]: loss 0.038382
[epoch15, step504]: loss 0.035127
[epoch15, step505]: loss 0.035008
[epoch15, step506]: loss 0.038680
[epoch15, step507]: loss 0.038597
[epoch15, step508]: loss 0.035863
[epoch15, step509]: loss 0.035378
[epoch15, step510]: loss 0.038497
[epoch15, step511]: loss 0.036157
[epoch15, step512]: loss 0.038480
[epoch15, step513]: loss 0.035625
[epoch15, step514]: loss 0.036191
[epoch15, step515]: loss 0.038297
[epoch15, step516]: loss 0.038657
[epoch15, step517]: loss 0.035432
[epoch15, step518]: loss 0.035584
[epoch15, step519]: loss 0.038494
[epoch15, step520]: loss 0.035156
[epoch15, step521]: loss 0.038179
[epoch15, step522]: loss 0.035016
[epoch15, step523]: loss 0.035882
[epoch15, step524]: loss 0.037543
[epoch15, step525]: loss 0.038504
[epoch15, step526]: loss 0.035459
[epoch15, step527]: loss 0.035156
[epoch15, step528]: loss 0.038448
[epoch15, step529]: loss 0.035301
[epoch15, step530]: loss 0.038468
[epoch15, step531]: loss 0.035193
[epoch15, step532]: loss 0.035651
[epoch15, step533]: loss 0.039200
[epoch15, step534]: loss 0.038090
[epoch15, step535]: loss 0.036003
[epoch15, step536]: loss 0.035665
[epoch15, step537]: loss 0.038388
[epoch15, step538]: loss 0.035834
[epoch15, step539]: loss 0.037956
[epoch15, step540]: loss 0.035048
[epoch15, step541]: loss 0.035386
[epoch15, step542]: loss 0.038295
[epoch15, step543]: loss 0.037921
[epoch15, step544]: loss 0.035322
[epoch15, step545]: loss 0.034672
[epoch15, step546]: loss 0.038793
[epoch15, step547]: loss 0.035734
[epoch15, step548]: loss 0.038166
[epoch15, step549]: loss 0.035629
[epoch15, step550]: loss 0.035898
[epoch15, step551]: loss 0.038088
[epoch15, step552]: loss 0.037591
[epoch15, step553]: loss 0.035825
[epoch15, step554]: loss 0.035342
[epoch15, step555]: loss 0.037953
[epoch15, step556]: loss 0.035579
[epoch15, step557]: loss 0.037551
[epoch15, step558]: loss 0.035599
[epoch15, step559]: loss 0.035385
[epoch15, step560]: loss 0.038435
[epoch15, step561]: loss 0.037985
[epoch15, step562]: loss 0.035369
[epoch15, step563]: loss 0.029032
[epoch15, step564]: loss 0.028995
[epoch15, step565]: loss 0.027758
[epoch15, step566]: loss 0.034639
[epoch15, step567]: loss 0.026741
[epoch15, step568]: loss 0.025884
[epoch15, step569]: loss 0.023370
[epoch15, step570]: loss 0.031303
[epoch15, step571]: loss 0.027079
[epoch15, step572]: loss 0.025909
[epoch15, step573]: loss 0.028973
[epoch15, step574]: loss 0.027793
[epoch15, step575]: loss 0.020756
[epoch15, step576]: loss 0.021678
[epoch15, step577]: loss 0.026409
[epoch15, step578]: loss 0.018806
[epoch15, step579]: loss 0.028830
[epoch15, step580]: loss 0.020425
[epoch15, step581]: loss 0.026182
[epoch15, step582]: loss 0.025384
[epoch15, step583]: loss 0.021899
[epoch15, step584]: loss 0.023851
[epoch15, step585]: loss 0.026157
[epoch15, step586]: loss 0.021739
[epoch15, step587]: loss 0.027686
[epoch15, step588]: loss 0.022933
[epoch15, step589]: loss 0.022944
[epoch15, step590]: loss 0.027511
[epoch15, step591]: loss 0.020549
[epoch15, step592]: loss 0.025749
[epoch15, step593]: loss 0.022056
[epoch15, step594]: loss 0.026170
[epoch15, step595]: loss 0.026730
[epoch15, step596]: loss 0.021986
[epoch15, step597]: loss 0.025059
[epoch15, step598]: loss 0.026746
[epoch15, step599]: loss 0.025200
[epoch15, step600]: loss 0.026983
[epoch15, step601]: loss 0.019550
[epoch15, step602]: loss 0.022677
[epoch15, step603]: loss 0.025775
[epoch15, step604]: loss 0.026487
[epoch15, step605]: loss 0.025248
[epoch15, step606]: loss 0.025006
[epoch15, step607]: loss 0.026893
[epoch15, step608]: loss 0.025747
[epoch15, step609]: loss 0.026369
[epoch15, step610]: loss 0.025730
[epoch15, step611]: loss 0.026192
[epoch15, step612]: loss 0.025723
[epoch15, step613]: loss 0.019293
[epoch15, step614]: loss 0.025178
[epoch15, step615]: loss 0.028204
[epoch15, step616]: loss 0.024107
[epoch15, step617]: loss 0.023520
[epoch15, step618]: loss 0.025741
[epoch15, step619]: loss 0.026823
[epoch15, step620]: loss 0.024453
[epoch15, step621]: loss 0.026260
[epoch15, step622]: loss 0.020407
[epoch15, step623]: loss 0.024675
[epoch15, step624]: loss 0.026306
[epoch15, step625]: loss 0.025970
[epoch15, step626]: loss 0.028123
[epoch15, step627]: loss 0.022668
[epoch15, step628]: loss 0.025566
[epoch15, step629]: loss 0.020734
[epoch15, step630]: loss 0.023408
[epoch15, step631]: loss 0.031329
[epoch15, step632]: loss 0.023327
[epoch15, step633]: loss 0.024717
[epoch15, step634]: loss 0.026958
[epoch15, step635]: loss 0.025411
[epoch15, step636]: loss 0.020624
[epoch15, step637]: loss 0.027005
[epoch15, step638]: loss 0.026935
[epoch15, step639]: loss 0.023055
[epoch15, step640]: loss 0.029559
[epoch15, step641]: loss 0.030110
[epoch15, step642]: loss 0.024990
[epoch15, step643]: loss 0.025544
[epoch15, step644]: loss 0.025812
[epoch15, step645]: loss 0.023688
[epoch15, step646]: loss 0.026277
[epoch15, step647]: loss 0.023751
[epoch15, step648]: loss 0.022979
[epoch15, step649]: loss 0.028577
[epoch15, step650]: loss 0.021911
[epoch15, step651]: loss 0.025900
[epoch15, step652]: loss 0.026757
[epoch15, step653]: loss 0.028141
[epoch15, step654]: loss 0.023055
[epoch15, step655]: loss 0.024107
[epoch15, step656]: loss 0.021386
[epoch15, step657]: loss 0.027619
[epoch15, step658]: loss 0.025213
[epoch15, step659]: loss 0.027563
[epoch15, step660]: loss 0.024116
[epoch15, step661]: loss 0.026680
[epoch15, step662]: loss 0.024030
[epoch15, step663]: loss 0.021193
[epoch15, step664]: loss 0.024976
[epoch15, step665]: loss 0.027577
[epoch15, step666]: loss 0.026852
[epoch15, step667]: loss 0.026451
[epoch15, step668]: loss 0.022318
[epoch15, step669]: loss 0.026376
[epoch15, step670]: loss 0.026551
[epoch15, step671]: loss 0.021564
[epoch15, step672]: loss 0.023526
[epoch15, step673]: loss 0.022125
[epoch15, step674]: loss 0.021184
[epoch15, step675]: loss 0.019975
[epoch15, step676]: loss 0.024575
[epoch15, step677]: loss 0.025120
[epoch15, step678]: loss 0.023196
[epoch15, step679]: loss 0.023739
[epoch15, step680]: loss 0.030595
[epoch15, step681]: loss 0.021899
[epoch15, step682]: loss 0.026265
[epoch15, step683]: loss 0.025903
[epoch15, step684]: loss 0.024636
[epoch15, step685]: loss 0.024286
[epoch15, step686]: loss 0.027128
[epoch15, step687]: loss 0.026629
[epoch15, step688]: loss 0.022502
[epoch15, step689]: loss 0.024485
[epoch15, step690]: loss 0.025044
[epoch15, step691]: loss 0.024179
[epoch15, step692]: loss 0.022443
[epoch15, step693]: loss 0.027112
[epoch15, step694]: loss 0.022816
[epoch15, step695]: loss 0.026205
[epoch15, step696]: loss 0.025989
[epoch15, step697]: loss 0.026821
[epoch15, step698]: loss 0.024595
[epoch15, step699]: loss 0.023432
[epoch15, step700]: loss 0.021625
[epoch15, step701]: loss 0.025972
[epoch15, step702]: loss 0.021773
[epoch15, step703]: loss 0.022873
[epoch15, step704]: loss 0.025281
[epoch15, step705]: loss 0.024854
[epoch15, step706]: loss 0.023760
[epoch15, step707]: loss 0.024629
[epoch15, step708]: loss 0.026084
[epoch15, step709]: loss 0.027305
[epoch15, step710]: loss 0.023841
[epoch15, step711]: loss 0.023571
[epoch15, step712]: loss 0.026714
[epoch15, step713]: loss 0.026247
[epoch15, step714]: loss 0.021312
[epoch15, step715]: loss 0.023058
[epoch15, step716]: loss 0.025751
[epoch15, step717]: loss 0.023604
[epoch15, step718]: loss 0.025040
[epoch15, step719]: loss 0.032832
[epoch15, step720]: loss 0.024820
[epoch15, step721]: loss 0.023033
[epoch15, step722]: loss 0.030700
[epoch15, step723]: loss 0.026062
[epoch15, step724]: loss 0.022898
[epoch15, step725]: loss 0.027828
[epoch15, step726]: loss 0.022379
[epoch15, step727]: loss 0.024567
[epoch15, step728]: loss 0.026335
[epoch15, step729]: loss 0.021197
[epoch15, step730]: loss 0.022606
[epoch15, step731]: loss 0.025905
[epoch15, step732]: loss 0.025853
[epoch15, step733]: loss 0.023887
[epoch15, step734]: loss 0.022782
[epoch15, step735]: loss 0.027337
[epoch15, step736]: loss 0.025117
[epoch15, step737]: loss 0.026643
[epoch15, step738]: loss 0.020712
[epoch15, step739]: loss 0.025432
[epoch15, step740]: loss 0.022440
[epoch15, step741]: loss 0.025148
[epoch15, step742]: loss 0.021861
[epoch15, step743]: loss 0.023222
[epoch15, step744]: loss 0.023869
[epoch15, step745]: loss 0.024557
[epoch15, step746]: loss 0.025132
[epoch15, step747]: loss 0.027329
[epoch15, step748]: loss 0.025589
[epoch15, step749]: loss 0.026158
[epoch15, step750]: loss 0.027537
[epoch15, step751]: loss 0.021667
[epoch15, step752]: loss 0.025087
[epoch15, step753]: loss 0.025743
[epoch15, step754]: loss 0.022713
[epoch15, step755]: loss 0.026187
[epoch15, step756]: loss 0.023463
[epoch15, step757]: loss 0.020482
[epoch15, step758]: loss 0.025197
[epoch15, step759]: loss 0.023056
[epoch15, step760]: loss 0.023980
[epoch15, step761]: loss 0.026329
[epoch15, step762]: loss 0.021631
[epoch15, step763]: loss 0.025505
[epoch15, step764]: loss 0.023637
[epoch15, step765]: loss 0.025880
[epoch15, step766]: loss 0.024669
[epoch15, step767]: loss 0.026684
[epoch15, step768]: loss 0.021417
[epoch15, step769]: loss 0.026646
[epoch15, step770]: loss 0.026036
[epoch15, step771]: loss 0.023264
[epoch15, step772]: loss 0.028822
[epoch15, step773]: loss 0.026540
[epoch15, step774]: loss 0.024157
[epoch15, step775]: loss 0.020594
[epoch15, step776]: loss 0.025522
[epoch15, step777]: loss 0.023047
[epoch15, step778]: loss 0.028001
[epoch15, step779]: loss 0.023781
[epoch15, step780]: loss 0.020132
[epoch15, step781]: loss 0.024286
[epoch15, step782]: loss 0.022845
[epoch15, step783]: loss 0.019410
[epoch15, step784]: loss 0.020358
[epoch15, step785]: loss 0.021508
[epoch15, step786]: loss 0.024276
[epoch15, step787]: loss 0.023240
[epoch15, step788]: loss 0.024795
[epoch15, step789]: loss 0.022391
[epoch15, step790]: loss 0.023212
[epoch15, step791]: loss 0.026574
[epoch15, step792]: loss 0.025069
[epoch15, step793]: loss 0.026813
[epoch15, step794]: loss 0.020297
[epoch15, step795]: loss 0.025656
[epoch15, step796]: loss 0.027952
[epoch15, step797]: loss 0.027771
[epoch15, step798]: loss 0.027206
[epoch15, step799]: loss 0.025871
[epoch15, step800]: loss 0.021447
[epoch15, step801]: loss 0.021637
[epoch15, step802]: loss 0.022747
[epoch15, step803]: loss 0.026190
[epoch15, step804]: loss 0.027445
[epoch15, step805]: loss 0.028296
[epoch15, step806]: loss 0.021291
[epoch15, step807]: loss 0.020607
[epoch15, step808]: loss 0.022926
[epoch15, step809]: loss 0.023037
[epoch15, step810]: loss 0.025769
[epoch15, step811]: loss 0.025723
[epoch15, step812]: loss 0.024594
[epoch15, step813]: loss 0.023568
[epoch15, step814]: loss 0.025104
[epoch15, step815]: loss 0.024999
[epoch15, step816]: loss 0.024288
[epoch15, step817]: loss 0.024698
[epoch15, step818]: loss 0.022444
[epoch15, step819]: loss 0.020077
[epoch15, step820]: loss 0.023438
[epoch15, step821]: loss 0.021814
[epoch15, step822]: loss 0.030419
[epoch15, step823]: loss 0.024019
[epoch15, step824]: loss 0.026753
[epoch15, step825]: loss 0.025332
[epoch15, step826]: loss 0.024376
[epoch15, step827]: loss 0.026808
[epoch15, step828]: loss 0.028909
[epoch15, step829]: loss 0.026559
[epoch15, step830]: loss 0.022546
[epoch15, step831]: loss 0.026470
[epoch15, step832]: loss 0.020817
[epoch15, step833]: loss 0.029217
[epoch15, step834]: loss 0.025509
[epoch15, step835]: loss 0.020534
[epoch15, step836]: loss 0.026895
[epoch15, step837]: loss 0.025689
[epoch15, step838]: loss 0.026175
[epoch15, step839]: loss 0.028356
[epoch15, step840]: loss 0.020732
[epoch15, step841]: loss 0.024303
[epoch15, step842]: loss 0.027490
[epoch15, step843]: loss 0.024940
[epoch15, step844]: loss 0.025063
[epoch15, step845]: loss 0.021109
[epoch15, step846]: loss 0.025353
[epoch15, step847]: loss 0.026838
[epoch15, step848]: loss 0.024903
[epoch15, step849]: loss 0.025107
[epoch15, step850]: loss 0.022993
[epoch15, step851]: loss 0.023912
[epoch15, step852]: loss 0.023201
[epoch15, step853]: loss 0.029120
[epoch15, step854]: loss 0.022676
[epoch15, step855]: loss 0.027189
[epoch15, step856]: loss 0.022187
[epoch15, step857]: loss 0.025709
[epoch15, step858]: loss 0.024227
[epoch15, step859]: loss 0.023722
[epoch15, step860]: loss 0.022513
[epoch15, step861]: loss 0.023312
[epoch15, step862]: loss 0.023162
[epoch15, step863]: loss 0.020607
[epoch15, step864]: loss 0.026353
[epoch15, step865]: loss 0.023501
[epoch15, step866]: loss 0.025227
[epoch15, step867]: loss 0.026082
[epoch15, step868]: loss 0.026754
[epoch15, step869]: loss 0.023859
[epoch15, step870]: loss 0.030988
[epoch15, step871]: loss 0.021997
[epoch15, step872]: loss 0.025335
[epoch15, step873]: loss 0.025843
[epoch15, step874]: loss 0.023692
[epoch15, step875]: loss 0.024187
[epoch15, step876]: loss 0.024212
[epoch15, step877]: loss 0.019032
[epoch15, step878]: loss 0.023281
[epoch15, step879]: loss 0.028047
[epoch15, step880]: loss 0.025657
[epoch15, step881]: loss 0.022154
[epoch15, step882]: loss 0.024203
[epoch15, step883]: loss 0.023797
[epoch15, step884]: loss 0.026214
[epoch15, step885]: loss 0.025858
[epoch15, step886]: loss 0.026537
[epoch15, step887]: loss 0.024242
[epoch15, step888]: loss 0.024718
[epoch15, step889]: loss 0.023546
[epoch15, step890]: loss 0.023411
[epoch15, step891]: loss 0.025618
[epoch15, step892]: loss 0.021111
[epoch15, step893]: loss 0.024688
[epoch15, step894]: loss 0.024949
[epoch15, step895]: loss 0.022691
[epoch15, step896]: loss 0.021843
[epoch15, step897]: loss 0.023831
[epoch15, step898]: loss 0.025360
[epoch15, step899]: loss 0.027953
[epoch15, step900]: loss 0.027069
[epoch15, step901]: loss 0.025387
[epoch15, step902]: loss 0.023929
[epoch15, step903]: loss 0.024060
[epoch15, step904]: loss 0.028080
[epoch15, step905]: loss 0.027665
[epoch15, step906]: loss 0.022383
[epoch15, step907]: loss 0.023676
[epoch15, step908]: loss 0.022494
[epoch15, step909]: loss 0.025483
[epoch15, step910]: loss 0.023139
[epoch15, step911]: loss 0.025277
[epoch15, step912]: loss 0.023817
[epoch15, step913]: loss 0.023981
[epoch15, step914]: loss 0.030397
[epoch15, step915]: loss 0.024114
[epoch15, step916]: loss 0.023841
[epoch15, step917]: loss 0.025016
[epoch15, step918]: loss 0.028591
[epoch15, step919]: loss 0.024151
[epoch15, step920]: loss 0.027553
[epoch15, step921]: loss 0.024621
[epoch15, step922]: loss 0.023234
[epoch15, step923]: loss 0.022563
[epoch15, step924]: loss 0.021160
[epoch15, step925]: loss 0.025491
[epoch15, step926]: loss 0.026492
[epoch15, step927]: loss 0.025731
[epoch15, step928]: loss 0.025024
[epoch15, step929]: loss 0.027647
[epoch15, step930]: loss 0.025774
[epoch15, step931]: loss 0.027336
[epoch15, step932]: loss 0.021703
[epoch15, step933]: loss 0.028180
[epoch15, step934]: loss 0.021935
[epoch15, step935]: loss 0.021992
[epoch15, step936]: loss 0.022457
[epoch15, step937]: loss 0.027231
[epoch15, step938]: loss 0.025229
[epoch15, step939]: loss 0.020747
[epoch15, step940]: loss 0.022895
[epoch15, step941]: loss 0.026802
[epoch15, step942]: loss 0.025475
[epoch15, step943]: loss 0.023123
[epoch15, step944]: loss 0.027483
[epoch15, step945]: loss 0.020545
[epoch15, step946]: loss 0.025476
[epoch15, step947]: loss 0.027938
[epoch15, step948]: loss 0.019428
[epoch15, step949]: loss 0.022862
[epoch15, step950]: loss 0.026521
[epoch15, step951]: loss 0.028619
[epoch15, step952]: loss 0.025207
[epoch15, step953]: loss 0.027515
[epoch15, step954]: loss 0.022139
[epoch15, step955]: loss 0.036775
[epoch15, step956]: loss 0.052153
[epoch15, step957]: loss 0.046458
[epoch15, step958]: loss 0.043956
[epoch15, step959]: loss 0.047415
[epoch15, step960]: loss 0.043699
[epoch15, step961]: loss 0.044953
[epoch15, step962]: loss 0.043046
[epoch15, step963]: loss 0.041140
[epoch15, step964]: loss 0.041279
[epoch15, step965]: loss 0.041377
[epoch15, step966]: loss 0.039055
[epoch15, step967]: loss 0.037974
[epoch15, step968]: loss 0.039944
[epoch15, step969]: loss 0.039070
[epoch15, step970]: loss 0.039035
[epoch15, step971]: loss 0.037756
[epoch15, step972]: loss 0.039848
[epoch15, step973]: loss 0.039198
[epoch15, step974]: loss 0.040668
[epoch15, step975]: loss 0.037494
[epoch15, step976]: loss 0.036655
[epoch15, step977]: loss 0.040138
[epoch15, step978]: loss 0.038395
[epoch15, step979]: loss 0.037091
[epoch15, step980]: loss 0.035700
[epoch15, step981]: loss 0.037418
[epoch15, step982]: loss 0.037873
[epoch15, step983]: loss 0.038817
[epoch15, step984]: loss 0.035250
[epoch15, step985]: loss 0.035683
[epoch15, step986]: loss 0.039676
[epoch15, step987]: loss 0.037995
[epoch15, step988]: loss 0.037642
[epoch15, step989]: loss 0.036490
[epoch15, step990]: loss 0.037143
[epoch15, step991]: loss 0.038103
[epoch15, step992]: loss 0.038109
[epoch15, step993]: loss 0.035717
[epoch15, step994]: loss 0.034902
[epoch15, step995]: loss 0.039022
[epoch15, step996]: loss 0.037165
[epoch15, step997]: loss 0.036869
[epoch15, step998]: loss 0.036275
[epoch15, step999]: loss 0.037314
[epoch15, step1000]: loss 0.037784
[epoch15, step1001]: loss 0.038156
[epoch15, step1002]: loss 0.036046
[epoch15, step1003]: loss 0.035443
[epoch15, step1004]: loss 0.039387
[epoch15, step1005]: loss 0.036909
[epoch15, step1006]: loss 0.036820
[epoch15, step1007]: loss 0.035351
[epoch15, step1008]: loss 0.036797
[epoch15, step1009]: loss 0.037384
[epoch15, step1010]: loss 0.038997
[epoch15, step1011]: loss 0.035556
[epoch15, step1012]: loss 0.036026
[epoch15, step1013]: loss 0.038844
[epoch15, step1014]: loss 0.037793
[epoch15, step1015]: loss 0.037284
[epoch15, step1016]: loss 0.035200
[epoch15, step1017]: loss 0.036861
[epoch15, step1018]: loss 0.037115
[epoch15, step1019]: loss 0.038217
[epoch15, step1020]: loss 0.035291
[epoch15, step1021]: loss 0.035042
[epoch15, step1022]: loss 0.038404
[epoch15, step1023]: loss 0.037014
[epoch15, step1024]: loss 0.037390
[epoch15, step1025]: loss 0.034962
[epoch15, step1026]: loss 0.036257
[epoch15, step1027]: loss 0.036866
[epoch15, step1028]: loss 0.038018
[epoch15, step1029]: loss 0.035260
[epoch15, step1030]: loss 0.034810
[epoch15, step1031]: loss 0.037442
[epoch15, step1032]: loss 0.037508
[epoch15, step1033]: loss 0.036339
[epoch15, step1034]: loss 0.035340
[epoch15, step1035]: loss 0.036266
[epoch15, step1036]: loss 0.037378
[epoch15, step1037]: loss 0.037876
[epoch15, step1038]: loss 0.035221
[epoch15, step1039]: loss 0.035687
[epoch15, step1040]: loss 0.037889
[epoch15, step1041]: loss 0.036813
[epoch15, step1042]: loss 0.035708
[epoch15, step1043]: loss 0.035215
[epoch15, step1044]: loss 0.037144
[epoch15, step1045]: loss 0.037225
[epoch15, step1046]: loss 0.038227
[epoch15, step1047]: loss 0.035456
[epoch15, step1048]: loss 0.034899
[epoch15, step1049]: loss 0.038361
[epoch15, step1050]: loss 0.037369
[epoch15, step1051]: loss 0.036659
[epoch15, step1052]: loss 0.035873
[epoch15, step1053]: loss 0.037153
[epoch15, step1054]: loss 0.037261
[epoch15, step1055]: loss 0.037489
[epoch15, step1056]: loss 0.034783
[epoch15, step1057]: loss 0.036055
[epoch15, step1058]: loss 0.039272
[epoch15, step1059]: loss 0.037286
[epoch15, step1060]: loss 0.036785
[epoch15, step1061]: loss 0.034803
[epoch15, step1062]: loss 0.037228
[epoch15, step1063]: loss 0.037097
[epoch15, step1064]: loss 0.037958
[epoch15, step1065]: loss 0.035237
[epoch15, step1066]: loss 0.035168
[epoch15, step1067]: loss 0.038292
[epoch15, step1068]: loss 0.035873
[epoch15, step1069]: loss 0.036153
[epoch15, step1070]: loss 0.035089
[epoch15, step1071]: loss 0.037251
[epoch15, step1072]: loss 0.037805
[epoch15, step1073]: loss 0.037851
[epoch15, step1074]: loss 0.035628
[epoch15, step1075]: loss 0.035686
[epoch15, step1076]: loss 0.038651
[epoch15, step1077]: loss 0.036952
[epoch15, step1078]: loss 0.036233
[epoch15, step1079]: loss 0.036312
[epoch15, step1080]: loss 0.036962
[epoch15, step1081]: loss 0.036896
[epoch15, step1082]: loss 0.037845
[epoch15, step1083]: loss 0.036045
[epoch15, step1084]: loss 0.035681
[epoch15, step1085]: loss 0.037858
[epoch15, step1086]: loss 0.036619
[epoch15, step1087]: loss 0.036722
[epoch15, step1088]: loss 0.035036
[epoch15, step1089]: loss 0.037151
[epoch15, step1090]: loss 0.037544
[epoch15, step1091]: loss 0.038085
[epoch15, step1092]: loss 0.035081
[epoch15, step1093]: loss 0.035306
[epoch15, step1094]: loss 0.037566
[epoch15, step1095]: loss 0.036467
[epoch15, step1096]: loss 0.035969
[epoch15, step1097]: loss 0.035281
[epoch15, step1098]: loss 0.036787
[epoch15, step1099]: loss 0.036790
[epoch15, step1100]: loss 0.038457
[epoch15, step1101]: loss 0.035730
[epoch15, step1102]: loss 0.035341
[epoch15, step1103]: loss 0.037775
[epoch15, step1104]: loss 0.036887
[epoch15, step1105]: loss 0.036748
[epoch15, step1106]: loss 0.034415
[epoch15, step1107]: loss 0.037093
[epoch15, step1108]: loss 0.036688
[epoch15, step1109]: loss 0.038389
[epoch15, step1110]: loss 0.035975
[epoch15, step1111]: loss 0.035505
[epoch15, step1112]: loss 0.038693
[epoch15, step1113]: loss 0.036499
[epoch15, step1114]: loss 0.036797
[epoch15, step1115]: loss 0.035405
[epoch15, step1116]: loss 0.036774
[epoch15, step1117]: loss 0.037043
[epoch15, step1118]: loss 0.037685
[epoch15, step1119]: loss 0.035177
[epoch15, step1120]: loss 0.035173
[epoch15, step1121]: loss 0.038120
[epoch15, step1122]: loss 0.036466
[epoch15, step1123]: loss 0.035706
[epoch15, step1124]: loss 0.036056
[epoch15, step1125]: loss 0.037069
[epoch15, step1126]: loss 0.038058
[epoch15, step1127]: loss 0.038001
[epoch15, step1128]: loss 0.035463
[epoch15, step1129]: loss 0.035239
[epoch15, step1130]: loss 0.039194
[epoch15, step1131]: loss 0.037258
[epoch15, step1132]: loss 0.036861
[epoch15, step1133]: loss 0.034783
[epoch15, step1134]: loss 0.036568
[epoch15, step1135]: loss 0.037919
[epoch15, step1136]: loss 0.038772
[epoch15, step1137]: loss 0.035367
[epoch15, step1138]: loss 0.035451
[epoch15, step1139]: loss 0.038158
[epoch15, step1140]: loss 0.036273
[epoch15, step1141]: loss 0.036110
[epoch15, step1142]: loss 0.034984
[epoch15, step1143]: loss 0.036227
[epoch15, step1144]: loss 0.037178
[epoch15, step1145]: loss 0.037371
[epoch15, step1146]: loss 0.034972
[epoch15, step1147]: loss 0.036063
[epoch15, step1148]: loss 0.038267
[epoch15, step1149]: loss 0.036521
[epoch15, step1150]: loss 0.036231
[epoch15, step1151]: loss 0.035718
[epoch15, step1152]: loss 0.037218
[epoch15, step1153]: loss 0.036452
[epoch15, step1154]: loss 0.038206
[epoch15, step1155]: loss 0.035390
[epoch15, step1156]: loss 0.034749
[epoch15, step1157]: loss 0.037895
[epoch15, step1158]: loss 0.037022
[epoch15, step1159]: loss 0.036547
[epoch15, step1160]: loss 0.036045
[epoch15, step1161]: loss 0.037187
[epoch15, step1162]: loss 0.037035
[epoch15, step1163]: loss 0.037236
[epoch15, step1164]: loss 0.035308
[epoch15, step1165]: loss 0.036328
[epoch15, step1166]: loss 0.038343
[epoch15, step1167]: loss 0.036040
[epoch15, step1168]: loss 0.036604
[epoch15, step1169]: loss 0.034984
[epoch15, step1170]: loss 0.036763
[epoch15, step1171]: loss 0.037106
[epoch15, step1172]: loss 0.037857
[epoch15, step1173]: loss 0.035336
[epoch15, step1174]: loss 0.035657
[epoch15, step1175]: loss 0.038010
[epoch15, step1176]: loss 0.036445
[epoch15, step1177]: loss 0.036628
[epoch15, step1178]: loss 0.035249
[epoch15, step1179]: loss 0.036899
[epoch15, step1180]: loss 0.037038
[epoch15, step1181]: loss 0.038397
[epoch15, step1182]: loss 0.034547
[epoch15, step1183]: loss 0.035721
[epoch15, step1184]: loss 0.037579
[epoch15, step1185]: loss 0.036837
[epoch15, step1186]: loss 0.035564
[epoch15, step1187]: loss 0.034313
[epoch15, step1188]: loss 0.036123
[epoch15, step1189]: loss 0.036669
[epoch15, step1190]: loss 0.037426
[epoch15, step1191]: loss 0.035768
[epoch15, step1192]: loss 0.035388
[epoch15, step1193]: loss 0.038099
[epoch15, step1194]: loss 0.036520
[epoch15, step1195]: loss 0.035325
[epoch15, step1196]: loss 0.034308
[epoch15, step1197]: loss 0.036979
[epoch15, step1198]: loss 0.036818
[epoch15, step1199]: loss 0.037384
[epoch15, step1200]: loss 0.034846
[epoch15, step1201]: loss 0.035736
[epoch15, step1202]: loss 0.038880
[epoch15, step1203]: loss 0.036740
[epoch15, step1204]: loss 0.035644
[epoch15, step1205]: loss 0.034631
[epoch15, step1206]: loss 0.036128
[epoch15, step1207]: loss 0.037112
[epoch15, step1208]: loss 0.038245
[epoch15, step1209]: loss 0.034001
[epoch15, step1210]: loss 0.035731
[epoch15, step1211]: loss 0.037853
[epoch15, step1212]: loss 0.036518
[epoch15, step1213]: loss 0.035921
[epoch15, step1214]: loss 0.035063
[epoch15, step1215]: loss 0.037240
[epoch15, step1216]: loss 0.036305
[epoch15, step1217]: loss 0.038251
[epoch15, step1218]: loss 0.034728
[epoch15, step1219]: loss 0.035711
[epoch15, step1220]: loss 0.038273
[epoch15, step1221]: loss 0.035798
[epoch15, step1222]: loss 0.036379
[epoch15, step1223]: loss 0.035201
[epoch15, step1224]: loss 0.037142
[epoch15, step1225]: loss 0.036883
[epoch15, step1226]: loss 0.037455
[epoch15, step1227]: loss 0.035069
[epoch15, step1228]: loss 0.034932
[epoch15, step1229]: loss 0.037771
[epoch15, step1230]: loss 0.036815
[epoch15, step1231]: loss 0.036250
[epoch15, step1232]: loss 0.035962
[epoch15, step1233]: loss 0.036491
[epoch15, step1234]: loss 0.036486
[epoch15, step1235]: loss 0.038129
[epoch15, step1236]: loss 0.035288
[epoch15, step1237]: loss 0.034676
[epoch15, step1238]: loss 0.037542
[epoch15, step1239]: loss 0.037368
[epoch15, step1240]: loss 0.036545
[epoch15, step1241]: loss 0.034679
[epoch15, step1242]: loss 0.036578
[epoch15, step1243]: loss 0.036580
[epoch15, step1244]: loss 0.038068
[epoch15, step1245]: loss 0.035502
[epoch15, step1246]: loss 0.035362
[epoch15, step1247]: loss 0.037106
[epoch15, step1248]: loss 0.036639
[epoch15, step1249]: loss 0.036779
[epoch15, step1250]: loss 0.034863
[epoch15, step1251]: loss 0.036964
[epoch15, step1252]: loss 0.037686
[epoch15, step1253]: loss 0.037968
[epoch15, step1254]: loss 0.035229
[epoch15, step1255]: loss 0.035318
[epoch15, step1256]: loss 0.038393
[epoch15, step1257]: loss 0.036911
[epoch15, step1258]: loss 0.036562
[epoch15, step1259]: loss 0.035024
[epoch15, step1260]: loss 0.036711
[epoch15, step1261]: loss 0.036588
[epoch15, step1262]: loss 0.036865
[epoch15, step1263]: loss 0.035637
[epoch15, step1264]: loss 0.035002
[epoch15, step1265]: loss 0.037066
[epoch15, step1266]: loss 0.036610
[epoch15, step1267]: loss 0.036789
[epoch15, step1268]: loss 0.035132
[epoch15, step1269]: loss 0.036737
[epoch15, step1270]: loss 0.036061
[epoch15, step1271]: loss 0.038046
[epoch15, step1272]: loss 0.035205
[epoch15, step1273]: loss 0.034847
[epoch15, step1274]: loss 0.037993
[epoch15, step1275]: loss 0.036954
[epoch15, step1276]: loss 0.036200
[epoch15, step1277]: loss 0.035215
[epoch15, step1278]: loss 0.037282
[epoch15, step1279]: loss 0.037201
[epoch15, step1280]: loss 0.038082
[epoch15, step1281]: loss 0.035005
[epoch15, step1282]: loss 0.035353
[epoch15, step1283]: loss 0.037430
[epoch15, step1284]: loss 0.036051
[epoch15, step1285]: loss 0.036696
[epoch15, step1286]: loss 0.034558
[epoch15, step1287]: loss 0.037256
[epoch15, step1288]: loss 0.037512
[epoch15, step1289]: loss 0.038736
[epoch15, step1290]: loss 0.035159
[epoch15, step1291]: loss 0.034879
[epoch15, step1292]: loss 0.038813
[epoch15, step1293]: loss 0.035880
[epoch15, step1294]: loss 0.036473
[epoch15, step1295]: loss 0.035579
[epoch15, step1296]: loss 0.037035
[epoch15, step1297]: loss 0.036748
[epoch15, step1298]: loss 0.038316
[epoch15, step1299]: loss 0.035510
[epoch15, step1300]: loss 0.035843
[epoch15, step1301]: loss 0.037098
[epoch15, step1302]: loss 0.036641
[epoch15, step1303]: loss 0.036451
[epoch15, step1304]: loss 0.034517
[epoch15, step1305]: loss 0.037286
[epoch15, step1306]: loss 0.037155
[epoch15, step1307]: loss 0.037426
[epoch15, step1308]: loss 0.035291
[epoch15, step1309]: loss 0.034558
[epoch15, step1310]: loss 0.038054
[epoch15, step1311]: loss 0.035561
[epoch15, step1312]: loss 0.037099
[epoch15, step1313]: loss 0.035008
[epoch15, step1314]: loss 0.036549
[epoch15, step1315]: loss 0.036388
[epoch15, step1316]: loss 0.038870
[epoch15, step1317]: loss 0.034651
[epoch15, step1318]: loss 0.034494
[epoch15, step1319]: loss 0.037334
[epoch15, step1320]: loss 0.036801
[epoch15, step1321]: loss 0.036553
[epoch15, step1322]: loss 0.034743
[epoch15, step1323]: loss 0.037023
[epoch15, step1324]: loss 0.036399
[epoch15, step1325]: loss 0.037710
[epoch15, step1326]: loss 0.034913
[epoch15, step1327]: loss 0.034954
[epoch15, step1328]: loss 0.038038
[epoch15, step1329]: loss 0.036361
[epoch15, step1330]: loss 0.036597
[epoch15, step1331]: loss 0.034532
[epoch15, step1332]: loss 0.036518
[epoch15, step1333]: loss 0.035796
[epoch15, step1334]: loss 0.038091
[epoch15, step1335]: loss 0.035771
[epoch15, step1336]: loss 0.034996
[epoch15, step1337]: loss 0.037353
[epoch15, step1338]: loss 0.036588
[epoch15, step1339]: loss 0.036408
[epoch15, step1340]: loss 0.034832
[epoch15, step1341]: loss 0.036939
[epoch15, step1342]: loss 0.036677
[epoch15, step1343]: loss 0.037952
[epoch15, step1344]: loss 0.035365
[epoch15, step1345]: loss 0.035168
[epoch15, step1346]: loss 0.037553
[epoch15, step1347]: loss 0.037235
[epoch15, step1348]: loss 0.035741
[epoch15, step1349]: loss 0.035022
[epoch15, step1350]: loss 0.036993
[epoch15, step1351]: loss 0.036352
[epoch15, step1352]: loss 0.037680
[epoch15, step1353]: loss 0.034826
[epoch15, step1354]: loss 0.034818
[epoch15, step1355]: loss 0.038176
[epoch15, step1356]: loss 0.036376
[epoch15, step1357]: loss 0.035961
[epoch15, step1358]: loss 0.034779
[epoch15, step1359]: loss 0.036312
[epoch15, step1360]: loss 0.036911
[epoch15, step1361]: loss 0.037908
[epoch15, step1362]: loss 0.035800
[epoch15, step1363]: loss 0.035557
[epoch15, step1364]: loss 0.037803
[epoch15, step1365]: loss 0.036658
[epoch15, step1366]: loss 0.036058
[epoch15, step1367]: loss 0.034269
[epoch15, step1368]: loss 0.037661
[epoch15, step1369]: loss 0.037099
[epoch15, step1370]: loss 0.037621
[epoch15, step1371]: loss 0.035468
[epoch15, step1372]: loss 0.034970
[epoch15, step1373]: loss 0.038230
[epoch15, step1374]: loss 0.037298
[epoch15, step1375]: loss 0.037135
[epoch15, step1376]: loss 0.034699
[epoch15, step1377]: loss 0.035998
[epoch15, step1378]: loss 0.036798
[epoch15, step1379]: loss 0.037078
[epoch15, step1380]: loss 0.035433
[epoch15, step1381]: loss 0.034890
[epoch15, step1382]: loss 0.038050
[epoch15, step1383]: loss 0.036298
[epoch15, step1384]: loss 0.035947
[epoch15, step1385]: loss 0.034293
[epoch15, step1386]: loss 0.036713
[epoch15, step1387]: loss 0.037219
[epoch15, step1388]: loss 0.036623
[epoch15, step1389]: loss 0.034416
[epoch15, step1390]: loss 0.035425
[epoch15, step1391]: loss 0.037486
[epoch15, step1392]: loss 0.036685
[epoch15, step1393]: loss 0.036395
[epoch15, step1394]: loss 0.035671
[epoch15, step1395]: loss 0.036745
[epoch15, step1396]: loss 0.036341
[epoch15, step1397]: loss 0.037611
[epoch15, step1398]: loss 0.034948
[epoch15, step1399]: loss 0.035896
[epoch15, step1400]: loss 0.038391
[epoch15, step1401]: loss 0.036212
[epoch15, step1402]: loss 0.036446
[epoch15, step1403]: loss 0.033817
[epoch15, step1404]: loss 0.036100
[epoch15, step1405]: loss 0.036462
[epoch15, step1406]: loss 0.037254
[epoch15, step1407]: loss 0.036057
[epoch15, step1408]: loss 0.034348
[epoch15, step1409]: loss 0.037345
[epoch15, step1410]: loss 0.036430
[epoch15, step1411]: loss 0.035093
[epoch15, step1412]: loss 0.034970
[epoch15, step1413]: loss 0.036718
[epoch15, step1414]: loss 0.036256
[epoch15, step1415]: loss 0.037493
[epoch15, step1416]: loss 0.034887
[epoch15, step1417]: loss 0.034995
[epoch15, step1418]: loss 0.037889
[epoch15, step1419]: loss 0.037132
[epoch15, step1420]: loss 0.036521
[epoch15, step1421]: loss 0.035177
[epoch15, step1422]: loss 0.036818
[epoch15, step1423]: loss 0.036208
[epoch15, step1424]: loss 0.037775
[epoch15, step1425]: loss 0.034155
[epoch15, step1426]: loss 0.035105
[epoch15, step1427]: loss 0.038628
[epoch15, step1428]: loss 0.037296
[epoch15, step1429]: loss 0.036252
[epoch15, step1430]: loss 0.034908
[epoch15, step1431]: loss 0.036718
[epoch15, step1432]: loss 0.036344
[epoch15, step1433]: loss 0.037804
[epoch15, step1434]: loss 0.034615
[epoch15, step1435]: loss 0.035406
[epoch15, step1436]: loss 0.038099
[epoch15, step1437]: loss 0.036765
[epoch15, step1438]: loss 0.037057
[epoch15, step1439]: loss 0.034621
[epoch15, step1440]: loss 0.036524
[epoch15, step1441]: loss 0.037260
[epoch15, step1442]: loss 0.036895
[epoch15, step1443]: loss 0.034773
[epoch15, step1444]: loss 0.034356
[epoch15, step1445]: loss 0.038192
[epoch15, step1446]: loss 0.036706
[epoch15, step1447]: loss 0.036926
[epoch15, step1448]: loss 0.034791
[epoch15, step1449]: loss 0.035989
[epoch15, step1450]: loss 0.036663
[epoch15, step1451]: loss 0.037994
[epoch15, step1452]: loss 0.034696
[epoch15, step1453]: loss 0.035946
[epoch15, step1454]: loss 0.038391
[epoch15, step1455]: loss 0.036949
[epoch15, step1456]: loss 0.035954
[epoch15, step1457]: loss 0.035280
[epoch15, step1458]: loss 0.036643
[epoch15, step1459]: loss 0.036620
[epoch15, step1460]: loss 0.038008
[epoch15, step1461]: loss 0.035665
[epoch15, step1462]: loss 0.035508
[epoch15, step1463]: loss 0.037684
[epoch15, step1464]: loss 0.036756
[epoch15, step1465]: loss 0.035729
[epoch15, step1466]: loss 0.034623
[epoch15, step1467]: loss 0.036648
[epoch15, step1468]: loss 0.036210
[epoch15, step1469]: loss 0.037754
[epoch15, step1470]: loss 0.035210
[epoch15, step1471]: loss 0.034813
[epoch15, step1472]: loss 0.037834
[epoch15, step1473]: loss 0.036354
[epoch15, step1474]: loss 0.036923
[epoch15, step1475]: loss 0.034480
[epoch15, step1476]: loss 0.037283
[epoch15, step1477]: loss 0.036302
[epoch15, step1478]: loss 0.037466
[epoch15, step1479]: loss 0.034884
[epoch15, step1480]: loss 0.034734
[epoch15, step1481]: loss 0.036973
[epoch15, step1482]: loss 0.036313
[epoch15, step1483]: loss 0.036033
[epoch15, step1484]: loss 0.035166
[epoch15, step1485]: loss 0.036302
[epoch15, step1486]: loss 0.035931
[epoch15, step1487]: loss 0.037389
[epoch15, step1488]: loss 0.035007
[epoch15, step1489]: loss 0.034911
[epoch15, step1490]: loss 0.037737
[epoch15, step1491]: loss 0.036602
[epoch15, step1492]: loss 0.036028
[epoch15, step1493]: loss 0.034844
[epoch15, step1494]: loss 0.036674
[epoch15, step1495]: loss 0.036285
[epoch15, step1496]: loss 0.036811
[epoch15, step1497]: loss 0.035278
[epoch15, step1498]: loss 0.035377
[epoch15, step1499]: loss 0.037316
[epoch15, step1500]: loss 0.036756
[epoch15, step1501]: loss 0.036381
[epoch15, step1502]: loss 0.034540
[epoch15, step1503]: loss 0.036448
[epoch15, step1504]: loss 0.036107
[epoch15, step1505]: loss 0.037757
[epoch15, step1506]: loss 0.034462
[epoch15, step1507]: loss 0.035217
[epoch15, step1508]: loss 0.038224
[epoch15, step1509]: loss 0.036146
[epoch15, step1510]: loss 0.035702
[epoch15, step1511]: loss 0.035582
[epoch15, step1512]: loss 0.036875
[epoch15, step1513]: loss 0.035362
[epoch15, step1514]: loss 0.037624
[epoch15, step1515]: loss 0.035440
[epoch15, step1516]: loss 0.035067

[epoch15]: avg loss 0.033652

[epoch16, step1]: loss 0.034378
[epoch16, step2]: loss 0.037472
[epoch16, step3]: loss 0.037209
[epoch16, step4]: loss 0.034925
[epoch16, step5]: loss 0.035281
[epoch16, step6]: loss 0.037600
[epoch16, step7]: loss 0.035878
[epoch16, step8]: loss 0.037671
[epoch16, step9]: loss 0.034569
[epoch16, step10]: loss 0.036483
[epoch16, step11]: loss 0.037655
[epoch16, step12]: loss 0.037686
[epoch16, step13]: loss 0.035395
[epoch16, step14]: loss 0.035198
[epoch16, step15]: loss 0.037746
[epoch16, step16]: loss 0.035632
[epoch16, step17]: loss 0.037870
[epoch16, step18]: loss 0.035428
[epoch16, step19]: loss 0.035542
[epoch16, step20]: loss 0.038427
[epoch16, step21]: loss 0.037267
[epoch16, step22]: loss 0.034699
[epoch16, step23]: loss 0.034398
[epoch16, step24]: loss 0.037775
[epoch16, step25]: loss 0.035063
[epoch16, step26]: loss 0.037116
[epoch16, step27]: loss 0.034363
[epoch16, step28]: loss 0.036073
[epoch16, step29]: loss 0.038061
[epoch16, step30]: loss 0.038313
[epoch16, step31]: loss 0.034435
[epoch16, step32]: loss 0.035677
[epoch16, step33]: loss 0.038374
[epoch16, step34]: loss 0.036365
[epoch16, step35]: loss 0.038158
[epoch16, step36]: loss 0.034661
[epoch16, step37]: loss 0.035686
[epoch16, step38]: loss 0.037594
[epoch16, step39]: loss 0.037566
[epoch16, step40]: loss 0.035269
[epoch16, step41]: loss 0.034598
[epoch16, step42]: loss 0.038032
[epoch16, step43]: loss 0.035486
[epoch16, step44]: loss 0.038489
[epoch16, step45]: loss 0.034629
[epoch16, step46]: loss 0.035620
[epoch16, step47]: loss 0.037233
[epoch16, step48]: loss 0.037142
[epoch16, step49]: loss 0.033471
[epoch16, step50]: loss 0.035043
[epoch16, step51]: loss 0.037624
[epoch16, step52]: loss 0.035314
[epoch16, step53]: loss 0.038059
[epoch16, step54]: loss 0.034484
[epoch16, step55]: loss 0.035910
[epoch16, step56]: loss 0.038692
[epoch16, step57]: loss 0.037969
[epoch16, step58]: loss 0.034790
[epoch16, step59]: loss 0.034208
[epoch16, step60]: loss 0.038205
[epoch16, step61]: loss 0.034927
[epoch16, step62]: loss 0.037472
[epoch16, step63]: loss 0.034089
[epoch16, step64]: loss 0.035314
[epoch16, step65]: loss 0.038132
[epoch16, step66]: loss 0.037372
[epoch16, step67]: loss 0.035148
[epoch16, step68]: loss 0.034933
[epoch16, step69]: loss 0.037584
[epoch16, step70]: loss 0.035284
[epoch16, step71]: loss 0.037169
[epoch16, step72]: loss 0.034663
[epoch16, step73]: loss 0.035518
[epoch16, step74]: loss 0.037675
[epoch16, step75]: loss 0.038035
[epoch16, step76]: loss 0.035346
[epoch16, step77]: loss 0.035580
[epoch16, step78]: loss 0.037794
[epoch16, step79]: loss 0.034984
[epoch16, step80]: loss 0.038342
[epoch16, step81]: loss 0.034849
[epoch16, step82]: loss 0.035224
[epoch16, step83]: loss 0.037478
[epoch16, step84]: loss 0.037828
[epoch16, step85]: loss 0.035591
[epoch16, step86]: loss 0.035521
[epoch16, step87]: loss 0.038838
[epoch16, step88]: loss 0.034292
[epoch16, step89]: loss 0.037629
[epoch16, step90]: loss 0.035113
[epoch16, step91]: loss 0.034966
[epoch16, step92]: loss 0.037943
[epoch16, step93]: loss 0.037479
[epoch16, step94]: loss 0.034694
[epoch16, step95]: loss 0.035414
[epoch16, step96]: loss 0.037333
[epoch16, step97]: loss 0.036120
[epoch16, step98]: loss 0.037556
[epoch16, step99]: loss 0.034822
[epoch16, step100]: loss 0.034372
[epoch16, step101]: loss 0.038330
[epoch16, step102]: loss 0.037473
[epoch16, step103]: loss 0.034731
[epoch16, step104]: loss 0.035077
[epoch16, step105]: loss 0.038072
[epoch16, step106]: loss 0.035622
[epoch16, step107]: loss 0.038026
[epoch16, step108]: loss 0.034944
[epoch16, step109]: loss 0.035245
[epoch16, step110]: loss 0.038384
[epoch16, step111]: loss 0.037332
[epoch16, step112]: loss 0.035146
[epoch16, step113]: loss 0.035810
[epoch16, step114]: loss 0.037509
[epoch16, step115]: loss 0.035430
[epoch16, step116]: loss 0.038430
[epoch16, step117]: loss 0.034606
[epoch16, step118]: loss 0.036254
[epoch16, step119]: loss 0.038100
[epoch16, step120]: loss 0.037902
[epoch16, step121]: loss 0.034836
[epoch16, step122]: loss 0.034970
[epoch16, step123]: loss 0.037965
[epoch16, step124]: loss 0.035780
[epoch16, step125]: loss 0.037972
[epoch16, step126]: loss 0.034702
[epoch16, step127]: loss 0.035165
[epoch16, step128]: loss 0.037703
[epoch16, step129]: loss 0.037535
[epoch16, step130]: loss 0.035081
[epoch16, step131]: loss 0.034532
[epoch16, step132]: loss 0.037794
[epoch16, step133]: loss 0.035344
[epoch16, step134]: loss 0.037204
[epoch16, step135]: loss 0.035231
[epoch16, step136]: loss 0.036510
[epoch16, step137]: loss 0.037485
[epoch16, step138]: loss 0.037494
[epoch16, step139]: loss 0.034805
[epoch16, step140]: loss 0.035467
[epoch16, step141]: loss 0.037953
[epoch16, step142]: loss 0.035359
[epoch16, step143]: loss 0.037212
[epoch16, step144]: loss 0.034961
[epoch16, step145]: loss 0.035381
[epoch16, step146]: loss 0.037731
[epoch16, step147]: loss 0.038785
[epoch16, step148]: loss 0.034512
[epoch16, step149]: loss 0.034733
[epoch16, step150]: loss 0.037534
[epoch16, step151]: loss 0.035467
[epoch16, step152]: loss 0.037446
[epoch16, step153]: loss 0.034809
[epoch16, step154]: loss 0.035232
[epoch16, step155]: loss 0.037629
[epoch16, step156]: loss 0.037221
[epoch16, step157]: loss 0.034911
[epoch16, step158]: loss 0.035392
[epoch16, step159]: loss 0.037824
[epoch16, step160]: loss 0.035743
[epoch16, step161]: loss 0.038150
[epoch16, step162]: loss 0.035001
[epoch16, step163]: loss 0.035359
[epoch16, step164]: loss 0.038020
[epoch16, step165]: loss 0.037611
[epoch16, step166]: loss 0.035223
[epoch16, step167]: loss 0.034704
[epoch16, step168]: loss 0.038379
[epoch16, step169]: loss 0.035195
[epoch16, step170]: loss 0.038138
[epoch16, step171]: loss 0.035038
[epoch16, step172]: loss 0.035587
[epoch16, step173]: loss 0.038091
[epoch16, step174]: loss 0.037350
[epoch16, step175]: loss 0.035628
[epoch16, step176]: loss 0.035241
[epoch16, step177]: loss 0.038010
[epoch16, step178]: loss 0.035361
[epoch16, step179]: loss 0.036766
[epoch16, step180]: loss 0.035038
[epoch16, step181]: loss 0.035513
[epoch16, step182]: loss 0.038197
[epoch16, step183]: loss 0.038221
[epoch16, step184]: loss 0.035799
[epoch16, step185]: loss 0.035307
[epoch16, step186]: loss 0.037826
[epoch16, step187]: loss 0.035648
[epoch16, step188]: loss 0.037461
[epoch16, step189]: loss 0.034761
[epoch16, step190]: loss 0.034805
[epoch16, step191]: loss 0.037787
[epoch16, step192]: loss 0.038150
[epoch16, step193]: loss 0.033140
[epoch16, step194]: loss 0.034247
[epoch16, step195]: loss 0.038070
[epoch16, step196]: loss 0.035521
[epoch16, step197]: loss 0.037560
[epoch16, step198]: loss 0.033933
[epoch16, step199]: loss 0.035472
[epoch16, step200]: loss 0.038224
[epoch16, step201]: loss 0.038030
[epoch16, step202]: loss 0.034567
[epoch16, step203]: loss 0.035070
[epoch16, step204]: loss 0.038145
[epoch16, step205]: loss 0.034989
[epoch16, step206]: loss 0.037314
[epoch16, step207]: loss 0.034680
[epoch16, step208]: loss 0.035876
[epoch16, step209]: loss 0.038016
[epoch16, step210]: loss 0.038544
[epoch16, step211]: loss 0.035514
[epoch16, step212]: loss 0.035541
[epoch16, step213]: loss 0.037429
[epoch16, step214]: loss 0.034863
[epoch16, step215]: loss 0.037959
[epoch16, step216]: loss 0.035000
[epoch16, step217]: loss 0.034742
[epoch16, step218]: loss 0.038010
[epoch16, step219]: loss 0.037401
[epoch16, step220]: loss 0.035218
[epoch16, step221]: loss 0.035311
[epoch16, step222]: loss 0.038203
[epoch16, step223]: loss 0.035552
[epoch16, step224]: loss 0.037258
[epoch16, step225]: loss 0.034695
[epoch16, step226]: loss 0.035117
[epoch16, step227]: loss 0.036881
[epoch16, step228]: loss 0.038241
[epoch16, step229]: loss 0.034078
[epoch16, step230]: loss 0.035405
[epoch16, step231]: loss 0.038326
[epoch16, step232]: loss 0.035278
[epoch16, step233]: loss 0.036981
[epoch16, step234]: loss 0.034344
[epoch16, step235]: loss 0.035670
[epoch16, step236]: loss 0.037836
[epoch16, step237]: loss 0.037722
[epoch16, step238]: loss 0.034719
[epoch16, step239]: loss 0.034370
[epoch16, step240]: loss 0.037280
[epoch16, step241]: loss 0.035877
[epoch16, step242]: loss 0.037518
[epoch16, step243]: loss 0.035486
[epoch16, step244]: loss 0.035172
[epoch16, step245]: loss 0.037310
[epoch16, step246]: loss 0.037585
[epoch16, step247]: loss 0.035211
[epoch16, step248]: loss 0.034721
[epoch16, step249]: loss 0.037162
[epoch16, step250]: loss 0.035819
[epoch16, step251]: loss 0.038025
[epoch16, step252]: loss 0.035379
[epoch16, step253]: loss 0.034996
[epoch16, step254]: loss 0.037512
[epoch16, step255]: loss 0.038085
[epoch16, step256]: loss 0.034781
[epoch16, step257]: loss 0.034812
[epoch16, step258]: loss 0.038498
[epoch16, step259]: loss 0.035478
[epoch16, step260]: loss 0.037191
[epoch16, step261]: loss 0.035509
[epoch16, step262]: loss 0.035708
[epoch16, step263]: loss 0.037387
[epoch16, step264]: loss 0.037260
[epoch16, step265]: loss 0.035171
[epoch16, step266]: loss 0.034889
[epoch16, step267]: loss 0.037055
[epoch16, step268]: loss 0.035294
[epoch16, step269]: loss 0.037563
[epoch16, step270]: loss 0.034397
[epoch16, step271]: loss 0.035421
[epoch16, step272]: loss 0.037721
[epoch16, step273]: loss 0.037333
[epoch16, step274]: loss 0.035302
[epoch16, step275]: loss 0.034615
[epoch16, step276]: loss 0.037512
[epoch16, step277]: loss 0.035947
[epoch16, step278]: loss 0.037863
[epoch16, step279]: loss 0.034372
[epoch16, step280]: loss 0.035476
[epoch16, step281]: loss 0.037696
[epoch16, step282]: loss 0.038166
[epoch16, step283]: loss 0.034630
[epoch16, step284]: loss 0.034526
[epoch16, step285]: loss 0.038564
[epoch16, step286]: loss 0.034667
[epoch16, step287]: loss 0.037928
[epoch16, step288]: loss 0.034375
[epoch16, step289]: loss 0.036120
[epoch16, step290]: loss 0.037833
[epoch16, step291]: loss 0.037878
[epoch16, step292]: loss 0.034154
[epoch16, step293]: loss 0.034617
[epoch16, step294]: loss 0.037223
[epoch16, step295]: loss 0.034886
[epoch16, step296]: loss 0.038363
[epoch16, step297]: loss 0.034501
[epoch16, step298]: loss 0.035719
[epoch16, step299]: loss 0.036926
[epoch16, step300]: loss 0.037892
[epoch16, step301]: loss 0.034939
[epoch16, step302]: loss 0.035380
[epoch16, step303]: loss 0.038095
[epoch16, step304]: loss 0.035069
[epoch16, step305]: loss 0.037361
[epoch16, step306]: loss 0.034790
[epoch16, step307]: loss 0.035091
[epoch16, step308]: loss 0.038217
[epoch16, step309]: loss 0.038058
[epoch16, step310]: loss 0.035024
[epoch16, step311]: loss 0.035370
[epoch16, step312]: loss 0.037381
[epoch16, step313]: loss 0.035736
[epoch16, step314]: loss 0.037514
[epoch16, step315]: loss 0.035709
[epoch16, step316]: loss 0.035084
[epoch16, step317]: loss 0.038219
[epoch16, step318]: loss 0.037650
[epoch16, step319]: loss 0.034394
[epoch16, step320]: loss 0.034115
[epoch16, step321]: loss 0.037267
[epoch16, step322]: loss 0.035291
[epoch16, step323]: loss 0.037053
[epoch16, step324]: loss 0.035599
[epoch16, step325]: loss 0.035450
[epoch16, step326]: loss 0.037478
[epoch16, step327]: loss 0.036969
[epoch16, step328]: loss 0.035132
[epoch16, step329]: loss 0.034714
[epoch16, step330]: loss 0.037265
[epoch16, step331]: loss 0.035500
[epoch16, step332]: loss 0.036987
[epoch16, step333]: loss 0.034679
[epoch16, step334]: loss 0.035413
[epoch16, step335]: loss 0.037778
[epoch16, step336]: loss 0.038375
[epoch16, step337]: loss 0.035330
[epoch16, step338]: loss 0.034675
[epoch16, step339]: loss 0.037662
[epoch16, step340]: loss 0.036104
[epoch16, step341]: loss 0.037059
[epoch16, step342]: loss 0.034490
[epoch16, step343]: loss 0.035562
[epoch16, step344]: loss 0.037259
[epoch16, step345]: loss 0.036910
[epoch16, step346]: loss 0.034445
[epoch16, step347]: loss 0.034666
[epoch16, step348]: loss 0.037796
[epoch16, step349]: loss 0.035879
[epoch16, step350]: loss 0.037151
[epoch16, step351]: loss 0.034038
[epoch16, step352]: loss 0.035163
[epoch16, step353]: loss 0.037492
[epoch16, step354]: loss 0.036659
[epoch16, step355]: loss 0.033899
[epoch16, step356]: loss 0.035532
[epoch16, step357]: loss 0.037799
[epoch16, step358]: loss 0.033938
[epoch16, step359]: loss 0.038422
[epoch16, step360]: loss 0.033513
[epoch16, step361]: loss 0.034830
[epoch16, step362]: loss 0.038386
[epoch16, step363]: loss 0.037265
[epoch16, step364]: loss 0.034871
[epoch16, step365]: loss 0.034675
[epoch16, step366]: loss 0.037977
[epoch16, step367]: loss 0.035481
[epoch16, step368]: loss 0.036937
[epoch16, step369]: loss 0.034494
[epoch16, step370]: loss 0.035712
[epoch16, step371]: loss 0.038358
[epoch16, step372]: loss 0.037192
[epoch16, step373]: loss 0.034333
[epoch16, step374]: loss 0.034180
[epoch16, step375]: loss 0.038306
[epoch16, step376]: loss 0.035492
[epoch16, step377]: loss 0.037696
[epoch16, step378]: loss 0.035140
[epoch16, step379]: loss 0.035858
[epoch16, step380]: loss 0.038247
[epoch16, step381]: loss 0.037285
[epoch16, step382]: loss 0.035220
[epoch16, step383]: loss 0.034032
[epoch16, step384]: loss 0.037034
[epoch16, step385]: loss 0.035261
[epoch16, step386]: loss 0.037788
[epoch16, step387]: loss 0.034713
[epoch16, step388]: loss 0.036014
[epoch16, step389]: loss 0.037604
[epoch16, step390]: loss 0.038555
[epoch16, step391]: loss 0.034471
[epoch16, step392]: loss 0.035376
[epoch16, step393]: loss 0.037272
[epoch16, step394]: loss 0.035296
[epoch16, step395]: loss 0.037169
[epoch16, step396]: loss 0.034760
[epoch16, step397]: loss 0.034852
[epoch16, step398]: loss 0.037859
[epoch16, step399]: loss 0.037449
[epoch16, step400]: loss 0.034486
[epoch16, step401]: loss 0.034748
[epoch16, step402]: loss 0.037603
[epoch16, step403]: loss 0.035278
[epoch16, step404]: loss 0.038000
[epoch16, step405]: loss 0.034987
[epoch16, step406]: loss 0.035512
[epoch16, step407]: loss 0.037470
[epoch16, step408]: loss 0.037614
[epoch16, step409]: loss 0.036151
[epoch16, step410]: loss 0.035479
[epoch16, step411]: loss 0.037500
[epoch16, step412]: loss 0.034804
[epoch16, step413]: loss 0.037494
[epoch16, step414]: loss 0.034424
[epoch16, step415]: loss 0.035481
[epoch16, step416]: loss 0.037003
[epoch16, step417]: loss 0.037717
[epoch16, step418]: loss 0.034697
[epoch16, step419]: loss 0.034108
[epoch16, step420]: loss 0.037759
[epoch16, step421]: loss 0.035017
[epoch16, step422]: loss 0.037405
[epoch16, step423]: loss 0.034821
[epoch16, step424]: loss 0.035337
[epoch16, step425]: loss 0.037792
[epoch16, step426]: loss 0.037879
[epoch16, step427]: loss 0.035268
[epoch16, step428]: loss 0.034855
[epoch16, step429]: loss 0.038220
[epoch16, step430]: loss 0.035272
[epoch16, step431]: loss 0.037920
[epoch16, step432]: loss 0.034565
[epoch16, step433]: loss 0.036032
[epoch16, step434]: loss 0.037602
[epoch16, step435]: loss 0.037949
[epoch16, step436]: loss 0.034572
[epoch16, step437]: loss 0.035076
[epoch16, step438]: loss 0.038201
[epoch16, step439]: loss 0.035531
[epoch16, step440]: loss 0.037525
[epoch16, step441]: loss 0.034932
[epoch16, step442]: loss 0.035147
[epoch16, step443]: loss 0.038089
[epoch16, step444]: loss 0.037281
[epoch16, step445]: loss 0.035245
[epoch16, step446]: loss 0.035258
[epoch16, step447]: loss 0.038296
[epoch16, step448]: loss 0.035457
[epoch16, step449]: loss 0.037323
[epoch16, step450]: loss 0.034182
[epoch16, step451]: loss 0.035151
[epoch16, step452]: loss 0.037010
[epoch16, step453]: loss 0.037748
[epoch16, step454]: loss 0.034825
[epoch16, step455]: loss 0.035208
[epoch16, step456]: loss 0.037025
[epoch16, step457]: loss 0.035923
[epoch16, step458]: loss 0.037242
[epoch16, step459]: loss 0.035378
[epoch16, step460]: loss 0.035543
[epoch16, step461]: loss 0.038400
[epoch16, step462]: loss 0.036963
[epoch16, step463]: loss 0.035045
[epoch16, step464]: loss 0.034858
[epoch16, step465]: loss 0.038930
[epoch16, step466]: loss 0.035250
[epoch16, step467]: loss 0.037409
[epoch16, step468]: loss 0.034671
[epoch16, step469]: loss 0.035470
[epoch16, step470]: loss 0.037941
[epoch16, step471]: loss 0.037091
[epoch16, step472]: loss 0.035368
[epoch16, step473]: loss 0.034427
[epoch16, step474]: loss 0.037527
[epoch16, step475]: loss 0.035388
[epoch16, step476]: loss 0.037958
[epoch16, step477]: loss 0.034513
[epoch16, step478]: loss 0.034679
[epoch16, step479]: loss 0.037504
[epoch16, step480]: loss 0.036889
[epoch16, step481]: loss 0.034510
[epoch16, step482]: loss 0.034294
[epoch16, step483]: loss 0.037994
[epoch16, step484]: loss 0.035504
[epoch16, step485]: loss 0.037702
[epoch16, step486]: loss 0.035070
[epoch16, step487]: loss 0.034733
[epoch16, step488]: loss 0.038065
[epoch16, step489]: loss 0.036822
[epoch16, step490]: loss 0.035222
[epoch16, step491]: loss 0.035096
[epoch16, step492]: loss 0.037287
[epoch16, step493]: loss 0.035038
[epoch16, step494]: loss 0.036988
[epoch16, step495]: loss 0.035799
[epoch16, step496]: loss 0.035524
[epoch16, step497]: loss 0.037789
[epoch16, step498]: loss 0.037581
[epoch16, step499]: loss 0.035128
[epoch16, step500]: loss 0.034408
[epoch16, step501]: loss 0.037249
[epoch16, step502]: loss 0.035105
[epoch16, step503]: loss 0.037795
[epoch16, step504]: loss 0.034409
[epoch16, step505]: loss 0.034406
[epoch16, step506]: loss 0.038046
[epoch16, step507]: loss 0.037888
[epoch16, step508]: loss 0.035372
[epoch16, step509]: loss 0.034774
[epoch16, step510]: loss 0.037797
[epoch16, step511]: loss 0.035696
[epoch16, step512]: loss 0.037914
[epoch16, step513]: loss 0.034884
[epoch16, step514]: loss 0.035545
[epoch16, step515]: loss 0.037682
[epoch16, step516]: loss 0.037954
[epoch16, step517]: loss 0.034909
[epoch16, step518]: loss 0.034971
[epoch16, step519]: loss 0.037760
[epoch16, step520]: loss 0.034770
[epoch16, step521]: loss 0.037277
[epoch16, step522]: loss 0.034440
[epoch16, step523]: loss 0.035233
[epoch16, step524]: loss 0.036998
[epoch16, step525]: loss 0.037856
[epoch16, step526]: loss 0.034974
[epoch16, step527]: loss 0.034588
[epoch16, step528]: loss 0.037795
[epoch16, step529]: loss 0.034864
[epoch16, step530]: loss 0.037921
[epoch16, step531]: loss 0.034466
[epoch16, step532]: loss 0.035026
[epoch16, step533]: loss 0.038577
[epoch16, step534]: loss 0.037421
[epoch16, step535]: loss 0.035537
[epoch16, step536]: loss 0.035040
[epoch16, step537]: loss 0.037741
[epoch16, step538]: loss 0.035353
[epoch16, step539]: loss 0.037321
[epoch16, step540]: loss 0.034370
[epoch16, step541]: loss 0.034774
[epoch16, step542]: loss 0.037715
[epoch16, step543]: loss 0.037264
[epoch16, step544]: loss 0.034848
[epoch16, step545]: loss 0.034162
[epoch16, step546]: loss 0.038186
[epoch16, step547]: loss 0.035224
[epoch16, step548]: loss 0.037554
[epoch16, step549]: loss 0.034946
[epoch16, step550]: loss 0.035264
[epoch16, step551]: loss 0.037532
[epoch16, step552]: loss 0.036928
[epoch16, step553]: loss 0.035315
[epoch16, step554]: loss 0.034701
[epoch16, step555]: loss 0.037286
[epoch16, step556]: loss 0.035065
[epoch16, step557]: loss 0.036940
[epoch16, step558]: loss 0.034908
[epoch16, step559]: loss 0.034766
[epoch16, step560]: loss 0.037840
[epoch16, step561]: loss 0.037329
[epoch16, step562]: loss 0.034812
[epoch16, step563]: loss 0.028883
[epoch16, step564]: loss 0.029514
[epoch16, step565]: loss 0.027737
[epoch16, step566]: loss 0.034621
[epoch16, step567]: loss 0.026909
[epoch16, step568]: loss 0.025919
[epoch16, step569]: loss 0.023162
[epoch16, step570]: loss 0.031239
[epoch16, step571]: loss 0.027132
[epoch16, step572]: loss 0.025673
[epoch16, step573]: loss 0.028842
[epoch16, step574]: loss 0.027700
[epoch16, step575]: loss 0.020523
[epoch16, step576]: loss 0.021307
[epoch16, step577]: loss 0.025977
[epoch16, step578]: loss 0.018646
[epoch16, step579]: loss 0.028349
[epoch16, step580]: loss 0.019903
[epoch16, step581]: loss 0.025610
[epoch16, step582]: loss 0.024949
[epoch16, step583]: loss 0.021869
[epoch16, step584]: loss 0.023754
[epoch16, step585]: loss 0.026110
[epoch16, step586]: loss 0.021599
[epoch16, step587]: loss 0.027616
[epoch16, step588]: loss 0.022901
[epoch16, step589]: loss 0.022892
[epoch16, step590]: loss 0.026872
[epoch16, step591]: loss 0.020397
[epoch16, step592]: loss 0.025479
[epoch16, step593]: loss 0.021962
[epoch16, step594]: loss 0.026100
[epoch16, step595]: loss 0.026458
[epoch16, step596]: loss 0.022113
[epoch16, step597]: loss 0.024873
[epoch16, step598]: loss 0.026600
[epoch16, step599]: loss 0.025078
[epoch16, step600]: loss 0.026811
[epoch16, step601]: loss 0.019519
[epoch16, step602]: loss 0.022659
[epoch16, step603]: loss 0.025727
[epoch16, step604]: loss 0.026459
[epoch16, step605]: loss 0.025024
[epoch16, step606]: loss 0.024910
[epoch16, step607]: loss 0.026947
[epoch16, step608]: loss 0.025579
[epoch16, step609]: loss 0.026217
[epoch16, step610]: loss 0.025901
[epoch16, step611]: loss 0.026147
[epoch16, step612]: loss 0.025248
[epoch16, step613]: loss 0.019320
[epoch16, step614]: loss 0.025227
[epoch16, step615]: loss 0.028140
[epoch16, step616]: loss 0.024086
[epoch16, step617]: loss 0.023576
[epoch16, step618]: loss 0.025796
[epoch16, step619]: loss 0.026826
[epoch16, step620]: loss 0.024216
[epoch16, step621]: loss 0.026237
[epoch16, step622]: loss 0.020380
[epoch16, step623]: loss 0.024504
[epoch16, step624]: loss 0.026375
[epoch16, step625]: loss 0.025893
[epoch16, step626]: loss 0.028535
[epoch16, step627]: loss 0.022723
[epoch16, step628]: loss 0.025248
[epoch16, step629]: loss 0.020789
[epoch16, step630]: loss 0.023595
[epoch16, step631]: loss 0.031089
[epoch16, step632]: loss 0.023370
[epoch16, step633]: loss 0.024778
[epoch16, step634]: loss 0.026986
[epoch16, step635]: loss 0.025447
[epoch16, step636]: loss 0.020694
[epoch16, step637]: loss 0.026959
[epoch16, step638]: loss 0.026961
[epoch16, step639]: loss 0.022813
[epoch16, step640]: loss 0.029507
[epoch16, step641]: loss 0.030023
[epoch16, step642]: loss 0.025023
[epoch16, step643]: loss 0.025429
[epoch16, step644]: loss 0.025842
[epoch16, step645]: loss 0.023532
[epoch16, step646]: loss 0.026203
[epoch16, step647]: loss 0.023803
[epoch16, step648]: loss 0.023045
[epoch16, step649]: loss 0.028570
[epoch16, step650]: loss 0.021966
[epoch16, step651]: loss 0.026090
[epoch16, step652]: loss 0.027123
[epoch16, step653]: loss 0.028116
[epoch16, step654]: loss 0.022925
[epoch16, step655]: loss 0.024250
[epoch16, step656]: loss 0.021553
[epoch16, step657]: loss 0.027447
[epoch16, step658]: loss 0.025163
[epoch16, step659]: loss 0.027562
[epoch16, step660]: loss 0.023799
[epoch16, step661]: loss 0.026516
[epoch16, step662]: loss 0.023906
[epoch16, step663]: loss 0.021094
[epoch16, step664]: loss 0.024874
[epoch16, step665]: loss 0.027704
[epoch16, step666]: loss 0.026949
[epoch16, step667]: loss 0.026327
[epoch16, step668]: loss 0.022204
[epoch16, step669]: loss 0.026469
[epoch16, step670]: loss 0.026643
[epoch16, step671]: loss 0.021619
[epoch16, step672]: loss 0.023508
[epoch16, step673]: loss 0.022045
[epoch16, step674]: loss 0.021133
[epoch16, step675]: loss 0.019961
[epoch16, step676]: loss 0.024778
[epoch16, step677]: loss 0.025104
[epoch16, step678]: loss 0.023083
[epoch16, step679]: loss 0.023750
[epoch16, step680]: loss 0.030526
[epoch16, step681]: loss 0.021878
[epoch16, step682]: loss 0.026209
[epoch16, step683]: loss 0.025868
[epoch16, step684]: loss 0.024740
[epoch16, step685]: loss 0.024353
[epoch16, step686]: loss 0.027119
[epoch16, step687]: loss 0.026786
[epoch16, step688]: loss 0.022486
[epoch16, step689]: loss 0.024505
[epoch16, step690]: loss 0.024944
[epoch16, step691]: loss 0.024244
[epoch16, step692]: loss 0.022433
[epoch16, step693]: loss 0.027025
[epoch16, step694]: loss 0.022823
[epoch16, step695]: loss 0.026216
[epoch16, step696]: loss 0.026000
[epoch16, step697]: loss 0.026754
[epoch16, step698]: loss 0.024646
[epoch16, step699]: loss 0.023440
[epoch16, step700]: loss 0.021607
[epoch16, step701]: loss 0.025991
[epoch16, step702]: loss 0.021710
[epoch16, step703]: loss 0.022894
[epoch16, step704]: loss 0.025261
[epoch16, step705]: loss 0.024865
[epoch16, step706]: loss 0.023705
[epoch16, step707]: loss 0.024543
[epoch16, step708]: loss 0.025961
[epoch16, step709]: loss 0.027329
[epoch16, step710]: loss 0.023763
[epoch16, step711]: loss 0.023451
[epoch16, step712]: loss 0.026649
[epoch16, step713]: loss 0.026265
[epoch16, step714]: loss 0.021315
[epoch16, step715]: loss 0.023045
[epoch16, step716]: loss 0.025662
[epoch16, step717]: loss 0.023600
[epoch16, step718]: loss 0.025102
[epoch16, step719]: loss 0.032692
[epoch16, step720]: loss 0.024801
[epoch16, step721]: loss 0.022986
[epoch16, step722]: loss 0.030779
[epoch16, step723]: loss 0.025912
[epoch16, step724]: loss 0.023014
[epoch16, step725]: loss 0.027802
[epoch16, step726]: loss 0.022332
[epoch16, step727]: loss 0.024557
[epoch16, step728]: loss 0.026436
[epoch16, step729]: loss 0.021182
[epoch16, step730]: loss 0.022605
[epoch16, step731]: loss 0.025842
[epoch16, step732]: loss 0.025854
[epoch16, step733]: loss 0.024008
[epoch16, step734]: loss 0.022627
[epoch16, step735]: loss 0.027397
[epoch16, step736]: loss 0.025112
[epoch16, step737]: loss 0.026544
[epoch16, step738]: loss 0.020602
[epoch16, step739]: loss 0.025465
[epoch16, step740]: loss 0.022319
[epoch16, step741]: loss 0.025236
[epoch16, step742]: loss 0.021715
[epoch16, step743]: loss 0.023089
[epoch16, step744]: loss 0.023881
[epoch16, step745]: loss 0.024438
[epoch16, step746]: loss 0.025164
[epoch16, step747]: loss 0.027429
[epoch16, step748]: loss 0.025633
[epoch16, step749]: loss 0.026312
[epoch16, step750]: loss 0.027519
[epoch16, step751]: loss 0.021547
[epoch16, step752]: loss 0.025084
[epoch16, step753]: loss 0.025557
[epoch16, step754]: loss 0.022561
[epoch16, step755]: loss 0.026087
[epoch16, step756]: loss 0.023485
[epoch16, step757]: loss 0.020492
[epoch16, step758]: loss 0.024987
[epoch16, step759]: loss 0.023103
[epoch16, step760]: loss 0.023980
[epoch16, step761]: loss 0.026410
[epoch16, step762]: loss 0.021602
[epoch16, step763]: loss 0.025508
[epoch16, step764]: loss 0.023464
[epoch16, step765]: loss 0.025886
[epoch16, step766]: loss 0.024636
[epoch16, step767]: loss 0.026486
[epoch16, step768]: loss 0.021457
[epoch16, step769]: loss 0.026672
[epoch16, step770]: loss 0.025778
[epoch16, step771]: loss 0.023203
[epoch16, step772]: loss 0.028817
[epoch16, step773]: loss 0.026738
[epoch16, step774]: loss 0.024134
[epoch16, step775]: loss 0.020566
[epoch16, step776]: loss 0.025539
[epoch16, step777]: loss 0.022984
[epoch16, step778]: loss 0.028094
[epoch16, step779]: loss 0.023683
[epoch16, step780]: loss 0.020072
[epoch16, step781]: loss 0.024329
[epoch16, step782]: loss 0.022819
[epoch16, step783]: loss 0.019313
[epoch16, step784]: loss 0.020258
[epoch16, step785]: loss 0.021457
[epoch16, step786]: loss 0.024182
[epoch16, step787]: loss 0.023247
[epoch16, step788]: loss 0.024760
[epoch16, step789]: loss 0.022310
[epoch16, step790]: loss 0.023067
[epoch16, step791]: loss 0.026567
[epoch16, step792]: loss 0.024956
[epoch16, step793]: loss 0.026897
[epoch16, step794]: loss 0.020300
[epoch16, step795]: loss 0.025669
[epoch16, step796]: loss 0.027815
[epoch16, step797]: loss 0.027827
[epoch16, step798]: loss 0.027335
[epoch16, step799]: loss 0.025882
[epoch16, step800]: loss 0.021357
[epoch16, step801]: loss 0.021611
[epoch16, step802]: loss 0.022696
[epoch16, step803]: loss 0.026291
[epoch16, step804]: loss 0.027259
[epoch16, step805]: loss 0.028091
[epoch16, step806]: loss 0.021300
[epoch16, step807]: loss 0.020602
[epoch16, step808]: loss 0.022766
[epoch16, step809]: loss 0.022940
[epoch16, step810]: loss 0.025941
[epoch16, step811]: loss 0.025751
[epoch16, step812]: loss 0.024504
[epoch16, step813]: loss 0.023589
[epoch16, step814]: loss 0.025100
[epoch16, step815]: loss 0.024929
[epoch16, step816]: loss 0.024277
[epoch16, step817]: loss 0.024611
[epoch16, step818]: loss 0.022392
[epoch16, step819]: loss 0.020061
[epoch16, step820]: loss 0.023364
[epoch16, step821]: loss 0.021754
[epoch16, step822]: loss 0.030356
[epoch16, step823]: loss 0.023952
[epoch16, step824]: loss 0.026776
[epoch16, step825]: loss 0.025344
[epoch16, step826]: loss 0.024323
[epoch16, step827]: loss 0.026842
[epoch16, step828]: loss 0.029023
[epoch16, step829]: loss 0.026630
[epoch16, step830]: loss 0.022499
[epoch16, step831]: loss 0.026415
[epoch16, step832]: loss 0.020838
[epoch16, step833]: loss 0.029256
[epoch16, step834]: loss 0.025415
[epoch16, step835]: loss 0.020434
[epoch16, step836]: loss 0.026629
[epoch16, step837]: loss 0.025600
[epoch16, step838]: loss 0.026304
[epoch16, step839]: loss 0.028334
[epoch16, step840]: loss 0.020672
[epoch16, step841]: loss 0.024378
[epoch16, step842]: loss 0.027553
[epoch16, step843]: loss 0.024755
[epoch16, step844]: loss 0.024992
[epoch16, step845]: loss 0.020993
[epoch16, step846]: loss 0.025303
[epoch16, step847]: loss 0.026806
[epoch16, step848]: loss 0.024813
[epoch16, step849]: loss 0.025059
[epoch16, step850]: loss 0.023035
[epoch16, step851]: loss 0.023916
[epoch16, step852]: loss 0.023300
[epoch16, step853]: loss 0.029188
[epoch16, step854]: loss 0.022688
[epoch16, step855]: loss 0.027197
[epoch16, step856]: loss 0.022174
[epoch16, step857]: loss 0.025615
[epoch16, step858]: loss 0.024158
[epoch16, step859]: loss 0.023546
[epoch16, step860]: loss 0.022609
[epoch16, step861]: loss 0.023214
[epoch16, step862]: loss 0.023084
[epoch16, step863]: loss 0.020552
[epoch16, step864]: loss 0.026374
[epoch16, step865]: loss 0.023380
[epoch16, step866]: loss 0.025170
[epoch16, step867]: loss 0.025901
[epoch16, step868]: loss 0.026647
[epoch16, step869]: loss 0.023869
[epoch16, step870]: loss 0.031106
[epoch16, step871]: loss 0.021938
[epoch16, step872]: loss 0.025339
[epoch16, step873]: loss 0.025681
[epoch16, step874]: loss 0.023787
[epoch16, step875]: loss 0.024120
[epoch16, step876]: loss 0.024178
[epoch16, step877]: loss 0.019065
[epoch16, step878]: loss 0.023347
[epoch16, step879]: loss 0.027819
[epoch16, step880]: loss 0.025572
[epoch16, step881]: loss 0.022097
[epoch16, step882]: loss 0.024166
[epoch16, step883]: loss 0.023746
[epoch16, step884]: loss 0.026341
[epoch16, step885]: loss 0.025878
[epoch16, step886]: loss 0.026404
[epoch16, step887]: loss 0.024351
[epoch16, step888]: loss 0.024588
[epoch16, step889]: loss 0.023472
[epoch16, step890]: loss 0.023530
[epoch16, step891]: loss 0.025539
[epoch16, step892]: loss 0.020907
[epoch16, step893]: loss 0.024678
[epoch16, step894]: loss 0.024896
[epoch16, step895]: loss 0.022640
[epoch16, step896]: loss 0.021855
[epoch16, step897]: loss 0.023849
[epoch16, step898]: loss 0.025361
[epoch16, step899]: loss 0.028104
[epoch16, step900]: loss 0.026925
[epoch16, step901]: loss 0.025334
[epoch16, step902]: loss 0.023915
[epoch16, step903]: loss 0.024133
[epoch16, step904]: loss 0.027937
[epoch16, step905]: loss 0.027479
[epoch16, step906]: loss 0.022301
[epoch16, step907]: loss 0.023784
[epoch16, step908]: loss 0.022473
[epoch16, step909]: loss 0.025338
[epoch16, step910]: loss 0.023071
[epoch16, step911]: loss 0.025254
[epoch16, step912]: loss 0.023939
[epoch16, step913]: loss 0.023953
[epoch16, step914]: loss 0.030372
[epoch16, step915]: loss 0.024053
[epoch16, step916]: loss 0.023863
[epoch16, step917]: loss 0.024974
[epoch16, step918]: loss 0.028577
[epoch16, step919]: loss 0.024169
[epoch16, step920]: loss 0.027582
[epoch16, step921]: loss 0.024444
[epoch16, step922]: loss 0.023170
[epoch16, step923]: loss 0.022446
[epoch16, step924]: loss 0.021164
[epoch16, step925]: loss 0.025321
[epoch16, step926]: loss 0.026466
[epoch16, step927]: loss 0.025629
[epoch16, step928]: loss 0.024817
[epoch16, step929]: loss 0.027532
[epoch16, step930]: loss 0.025771
[epoch16, step931]: loss 0.027323
[epoch16, step932]: loss 0.021645
[epoch16, step933]: loss 0.028202
[epoch16, step934]: loss 0.022025
[epoch16, step935]: loss 0.021960
[epoch16, step936]: loss 0.022419
[epoch16, step937]: loss 0.027165
[epoch16, step938]: loss 0.025265
[epoch16, step939]: loss 0.020780
[epoch16, step940]: loss 0.023013
[epoch16, step941]: loss 0.026867
[epoch16, step942]: loss 0.025471
[epoch16, step943]: loss 0.023133
[epoch16, step944]: loss 0.027633
[epoch16, step945]: loss 0.020575
[epoch16, step946]: loss 0.025389
[epoch16, step947]: loss 0.027893
[epoch16, step948]: loss 0.019260
[epoch16, step949]: loss 0.022874
[epoch16, step950]: loss 0.026573
[epoch16, step951]: loss 0.028498
[epoch16, step952]: loss 0.025158
[epoch16, step953]: loss 0.027536
[epoch16, step954]: loss 0.022106
[epoch16, step955]: loss 0.036604
[epoch16, step956]: loss 0.051740
[epoch16, step957]: loss 0.045939
[epoch16, step958]: loss 0.043491
[epoch16, step959]: loss 0.047143
[epoch16, step960]: loss 0.043199
[epoch16, step961]: loss 0.043422
[epoch16, step962]: loss 0.040974
[epoch16, step963]: loss 0.039340
[epoch16, step964]: loss 0.039869
[epoch16, step965]: loss 0.039144
[epoch16, step966]: loss 0.037166
[epoch16, step967]: loss 0.036878
[epoch16, step968]: loss 0.039615
[epoch16, step969]: loss 0.039314
[epoch16, step970]: loss 0.038699
[epoch16, step971]: loss 0.037078
[epoch16, step972]: loss 0.039224
[epoch16, step973]: loss 0.038377
[epoch16, step974]: loss 0.039508
[epoch16, step975]: loss 0.036150
[epoch16, step976]: loss 0.035447
[epoch16, step977]: loss 0.039547
[epoch16, step978]: loss 0.037994
[epoch16, step979]: loss 0.036873
[epoch16, step980]: loss 0.035750
[epoch16, step981]: loss 0.037720
[epoch16, step982]: loss 0.038139
[epoch16, step983]: loss 0.039593
[epoch16, step984]: loss 0.035302
[epoch16, step985]: loss 0.035695
[epoch16, step986]: loss 0.039794
[epoch16, step987]: loss 0.037862
[epoch16, step988]: loss 0.037270
[epoch16, step989]: loss 0.036126
[epoch16, step990]: loss 0.036844
[epoch16, step991]: loss 0.037777
[epoch16, step992]: loss 0.037902
[epoch16, step993]: loss 0.035580
[epoch16, step994]: loss 0.034734
[epoch16, step995]: loss 0.038688
[epoch16, step996]: loss 0.036942
[epoch16, step997]: loss 0.036748
[epoch16, step998]: loss 0.036120
[epoch16, step999]: loss 0.037077
[epoch16, step1000]: loss 0.037552
[epoch16, step1001]: loss 0.037969
[epoch16, step1002]: loss 0.036010
[epoch16, step1003]: loss 0.035222
[epoch16, step1004]: loss 0.039006
[epoch16, step1005]: loss 0.036998
[epoch16, step1006]: loss 0.036955
[epoch16, step1007]: loss 0.034975
[epoch16, step1008]: loss 0.036766
[epoch16, step1009]: loss 0.036989
[epoch16, step1010]: loss 0.038766
[epoch16, step1011]: loss 0.035408
[epoch16, step1012]: loss 0.035532
[epoch16, step1013]: loss 0.038538
[epoch16, step1014]: loss 0.037581
[epoch16, step1015]: loss 0.036834
[epoch16, step1016]: loss 0.034945
[epoch16, step1017]: loss 0.036461
[epoch16, step1018]: loss 0.036818
[epoch16, step1019]: loss 0.037970
[epoch16, step1020]: loss 0.035117
[epoch16, step1021]: loss 0.034798
[epoch16, step1022]: loss 0.038126
[epoch16, step1023]: loss 0.037027
[epoch16, step1024]: loss 0.037131
[epoch16, step1025]: loss 0.034944
[epoch16, step1026]: loss 0.036088
[epoch16, step1027]: loss 0.036632
[epoch16, step1028]: loss 0.037917
[epoch16, step1029]: loss 0.035032
[epoch16, step1030]: loss 0.034549
[epoch16, step1031]: loss 0.037156
[epoch16, step1032]: loss 0.037254
[epoch16, step1033]: loss 0.036219
[epoch16, step1034]: loss 0.034817
[epoch16, step1035]: loss 0.035992
[epoch16, step1036]: loss 0.036886
[epoch16, step1037]: loss 0.037563
[epoch16, step1038]: loss 0.034997
[epoch16, step1039]: loss 0.035191
[epoch16, step1040]: loss 0.037505
[epoch16, step1041]: loss 0.036621
[epoch16, step1042]: loss 0.035359
[epoch16, step1043]: loss 0.034961
[epoch16, step1044]: loss 0.036595
[epoch16, step1045]: loss 0.036907
[epoch16, step1046]: loss 0.037926
[epoch16, step1047]: loss 0.035213
[epoch16, step1048]: loss 0.034627
[epoch16, step1049]: loss 0.038055
[epoch16, step1050]: loss 0.037431
[epoch16, step1051]: loss 0.036325
[epoch16, step1052]: loss 0.035349
[epoch16, step1053]: loss 0.036841
[epoch16, step1054]: loss 0.036998
[epoch16, step1055]: loss 0.037378
[epoch16, step1056]: loss 0.034496
[epoch16, step1057]: loss 0.035580
[epoch16, step1058]: loss 0.038908
[epoch16, step1059]: loss 0.037031
[epoch16, step1060]: loss 0.036384
[epoch16, step1061]: loss 0.034527
[epoch16, step1062]: loss 0.036907
[epoch16, step1063]: loss 0.036855
[epoch16, step1064]: loss 0.037781
[epoch16, step1065]: loss 0.035074
[epoch16, step1066]: loss 0.034674
[epoch16, step1067]: loss 0.038044
[epoch16, step1068]: loss 0.035517
[epoch16, step1069]: loss 0.035696
[epoch16, step1070]: loss 0.034916
[epoch16, step1071]: loss 0.036994
[epoch16, step1072]: loss 0.037430
[epoch16, step1073]: loss 0.037629
[epoch16, step1074]: loss 0.035336
[epoch16, step1075]: loss 0.035208
[epoch16, step1076]: loss 0.038144
[epoch16, step1077]: loss 0.036681
[epoch16, step1078]: loss 0.035862
[epoch16, step1079]: loss 0.035951
[epoch16, step1080]: loss 0.036695
[epoch16, step1081]: loss 0.036520
[epoch16, step1082]: loss 0.037493
[epoch16, step1083]: loss 0.035733
[epoch16, step1084]: loss 0.035203
[epoch16, step1085]: loss 0.037427
[epoch16, step1086]: loss 0.036412
[epoch16, step1087]: loss 0.036261
[epoch16, step1088]: loss 0.034840
[epoch16, step1089]: loss 0.036846
[epoch16, step1090]: loss 0.037260
[epoch16, step1091]: loss 0.037918
[epoch16, step1092]: loss 0.034853
[epoch16, step1093]: loss 0.034985
[epoch16, step1094]: loss 0.037077
[epoch16, step1095]: loss 0.036210
[epoch16, step1096]: loss 0.035672
[epoch16, step1097]: loss 0.034903
[epoch16, step1098]: loss 0.036463
[epoch16, step1099]: loss 0.036378
[epoch16, step1100]: loss 0.038132
[epoch16, step1101]: loss 0.035451
[epoch16, step1102]: loss 0.034882
[epoch16, step1103]: loss 0.037385
[epoch16, step1104]: loss 0.036570
[epoch16, step1105]: loss 0.036317
[epoch16, step1106]: loss 0.034139
[epoch16, step1107]: loss 0.036673
[epoch16, step1108]: loss 0.036353
[epoch16, step1109]: loss 0.038153
[epoch16, step1110]: loss 0.035667
[epoch16, step1111]: loss 0.035102
[epoch16, step1112]: loss 0.038275
[epoch16, step1113]: loss 0.036231
[epoch16, step1114]: loss 0.036469
[epoch16, step1115]: loss 0.035114
[epoch16, step1116]: loss 0.036468
[epoch16, step1117]: loss 0.036676
[epoch16, step1118]: loss 0.037377
[epoch16, step1119]: loss 0.034925
[epoch16, step1120]: loss 0.034827
[epoch16, step1121]: loss 0.037723
[epoch16, step1122]: loss 0.036251
[epoch16, step1123]: loss 0.035330
[epoch16, step1124]: loss 0.035705
[epoch16, step1125]: loss 0.036815
[epoch16, step1126]: loss 0.037673
[epoch16, step1127]: loss 0.037704
[epoch16, step1128]: loss 0.035248
[epoch16, step1129]: loss 0.034785
[epoch16, step1130]: loss 0.038531
[epoch16, step1131]: loss 0.037004
[epoch16, step1132]: loss 0.036511
[epoch16, step1133]: loss 0.034519
[epoch16, step1134]: loss 0.036253
[epoch16, step1135]: loss 0.037511
[epoch16, step1136]: loss 0.038494
[epoch16, step1137]: loss 0.035097
[epoch16, step1138]: loss 0.035052
[epoch16, step1139]: loss 0.037794
[epoch16, step1140]: loss 0.036009
[epoch16, step1141]: loss 0.035751
[epoch16, step1142]: loss 0.034670
[epoch16, step1143]: loss 0.035878
[epoch16, step1144]: loss 0.036827
[epoch16, step1145]: loss 0.036970
[epoch16, step1146]: loss 0.034795
[epoch16, step1147]: loss 0.035667
[epoch16, step1148]: loss 0.037909
[epoch16, step1149]: loss 0.036345
[epoch16, step1150]: loss 0.035891
[epoch16, step1151]: loss 0.035502
[epoch16, step1152]: loss 0.037037
[epoch16, step1153]: loss 0.036019
[epoch16, step1154]: loss 0.037969
[epoch16, step1155]: loss 0.035171
[epoch16, step1156]: loss 0.034299
[epoch16, step1157]: loss 0.037663
[epoch16, step1158]: loss 0.036675
[epoch16, step1159]: loss 0.036283
[epoch16, step1160]: loss 0.035588
[epoch16, step1161]: loss 0.036818
[epoch16, step1162]: loss 0.036549
[epoch16, step1163]: loss 0.036774
[epoch16, step1164]: loss 0.035146
[epoch16, step1165]: loss 0.035850
[epoch16, step1166]: loss 0.038038
[epoch16, step1167]: loss 0.035806
[epoch16, step1168]: loss 0.036208
[epoch16, step1169]: loss 0.034801
[epoch16, step1170]: loss 0.036568
[epoch16, step1171]: loss 0.036674
[epoch16, step1172]: loss 0.037661
[epoch16, step1173]: loss 0.035242
[epoch16, step1174]: loss 0.035336
[epoch16, step1175]: loss 0.037824
[epoch16, step1176]: loss 0.036164
[epoch16, step1177]: loss 0.036454
[epoch16, step1178]: loss 0.034915
[epoch16, step1179]: loss 0.036251
[epoch16, step1180]: loss 0.036718
[epoch16, step1181]: loss 0.038002
[epoch16, step1182]: loss 0.034388
[epoch16, step1183]: loss 0.035355
[epoch16, step1184]: loss 0.037265
[epoch16, step1185]: loss 0.036649
[epoch16, step1186]: loss 0.035260
[epoch16, step1187]: loss 0.034084
[epoch16, step1188]: loss 0.035766
[epoch16, step1189]: loss 0.036458
[epoch16, step1190]: loss 0.037105
[epoch16, step1191]: loss 0.035582
[epoch16, step1192]: loss 0.035120
[epoch16, step1193]: loss 0.037766
[epoch16, step1194]: loss 0.036308
[epoch16, step1195]: loss 0.034988
[epoch16, step1196]: loss 0.034119
[epoch16, step1197]: loss 0.036686
[epoch16, step1198]: loss 0.036663
[epoch16, step1199]: loss 0.037090
[epoch16, step1200]: loss 0.034722
[epoch16, step1201]: loss 0.035416
[epoch16, step1202]: loss 0.038614
[epoch16, step1203]: loss 0.036544
[epoch16, step1204]: loss 0.035403
[epoch16, step1205]: loss 0.034350
[epoch16, step1206]: loss 0.035825
[epoch16, step1207]: loss 0.036896
[epoch16, step1208]: loss 0.037917
[epoch16, step1209]: loss 0.033836
[epoch16, step1210]: loss 0.035389
[epoch16, step1211]: loss 0.037548
[epoch16, step1212]: loss 0.036292
[epoch16, step1213]: loss 0.035568
[epoch16, step1214]: loss 0.034902
[epoch16, step1215]: loss 0.036915
[epoch16, step1216]: loss 0.036210
[epoch16, step1217]: loss 0.037950
[epoch16, step1218]: loss 0.034581
[epoch16, step1219]: loss 0.035531
[epoch16, step1220]: loss 0.038009
[epoch16, step1221]: loss 0.035602
[epoch16, step1222]: loss 0.036121
[epoch16, step1223]: loss 0.034982
[epoch16, step1224]: loss 0.037026
[epoch16, step1225]: loss 0.036666
[epoch16, step1226]: loss 0.037104
[epoch16, step1227]: loss 0.034839
[epoch16, step1228]: loss 0.034699
[epoch16, step1229]: loss 0.037519
[epoch16, step1230]: loss 0.036549
[epoch16, step1231]: loss 0.035922
[epoch16, step1232]: loss 0.035734
[epoch16, step1233]: loss 0.036168
[epoch16, step1234]: loss 0.036338
[epoch16, step1235]: loss 0.037781
[epoch16, step1236]: loss 0.035212
[epoch16, step1237]: loss 0.034464
[epoch16, step1238]: loss 0.037118
[epoch16, step1239]: loss 0.037159
[epoch16, step1240]: loss 0.036254
[epoch16, step1241]: loss 0.034492
[epoch16, step1242]: loss 0.036407
[epoch16, step1243]: loss 0.036310
[epoch16, step1244]: loss 0.037859
[epoch16, step1245]: loss 0.035374
[epoch16, step1246]: loss 0.035060
[epoch16, step1247]: loss 0.036890
[epoch16, step1248]: loss 0.036376
[epoch16, step1249]: loss 0.036462
[epoch16, step1250]: loss 0.034584
[epoch16, step1251]: loss 0.036634
[epoch16, step1252]: loss 0.037463
[epoch16, step1253]: loss 0.037519
[epoch16, step1254]: loss 0.035085
[epoch16, step1255]: loss 0.035011
[epoch16, step1256]: loss 0.038103
[epoch16, step1257]: loss 0.036741
[epoch16, step1258]: loss 0.036194
[epoch16, step1259]: loss 0.034971
[epoch16, step1260]: loss 0.036592
[epoch16, step1261]: loss 0.036353
[epoch16, step1262]: loss 0.036631
[epoch16, step1263]: loss 0.035514
[epoch16, step1264]: loss 0.034725
[epoch16, step1265]: loss 0.036863
[epoch16, step1266]: loss 0.036345
[epoch16, step1267]: loss 0.036488
[epoch16, step1268]: loss 0.034838
[epoch16, step1269]: loss 0.036414
[epoch16, step1270]: loss 0.035868
[epoch16, step1271]: loss 0.037668
[epoch16, step1272]: loss 0.035046
[epoch16, step1273]: loss 0.034566
[epoch16, step1274]: loss 0.037748
[epoch16, step1275]: loss 0.036746
[epoch16, step1276]: loss 0.035852
[epoch16, step1277]: loss 0.035068
[epoch16, step1278]: loss 0.036970
[epoch16, step1279]: loss 0.037066
[epoch16, step1280]: loss 0.037862
[epoch16, step1281]: loss 0.034851
[epoch16, step1282]: loss 0.035127
[epoch16, step1283]: loss 0.037145
[epoch16, step1284]: loss 0.035863
[epoch16, step1285]: loss 0.036388
[epoch16, step1286]: loss 0.034392
[epoch16, step1287]: loss 0.037040
[epoch16, step1288]: loss 0.037371
[epoch16, step1289]: loss 0.038238
[epoch16, step1290]: loss 0.035060
[epoch16, step1291]: loss 0.034682
[epoch16, step1292]: loss 0.038253
[epoch16, step1293]: loss 0.035704
[epoch16, step1294]: loss 0.036129
[epoch16, step1295]: loss 0.035318
[epoch16, step1296]: loss 0.036638
[epoch16, step1297]: loss 0.036651
[epoch16, step1298]: loss 0.038035
[epoch16, step1299]: loss 0.035203
[epoch16, step1300]: loss 0.035557
[epoch16, step1301]: loss 0.036848
[epoch16, step1302]: loss 0.036339
[epoch16, step1303]: loss 0.036166
[epoch16, step1304]: loss 0.034173
[epoch16, step1305]: loss 0.036809
[epoch16, step1306]: loss 0.036900
[epoch16, step1307]: loss 0.037006
[epoch16, step1308]: loss 0.035060
[epoch16, step1309]: loss 0.034239
[epoch16, step1310]: loss 0.037552
[epoch16, step1311]: loss 0.035414
[epoch16, step1312]: loss 0.036633
[epoch16, step1313]: loss 0.034958
[epoch16, step1314]: loss 0.036400
[epoch16, step1315]: loss 0.036253
[epoch16, step1316]: loss 0.038757
[epoch16, step1317]: loss 0.034412
[epoch16, step1318]: loss 0.034374
[epoch16, step1319]: loss 0.037117
[epoch16, step1320]: loss 0.036490
[epoch16, step1321]: loss 0.036386
[epoch16, step1322]: loss 0.034387
[epoch16, step1323]: loss 0.036665
[epoch16, step1324]: loss 0.036248
[epoch16, step1325]: loss 0.037266
[epoch16, step1326]: loss 0.034691
[epoch16, step1327]: loss 0.034666
[epoch16, step1328]: loss 0.037651
[epoch16, step1329]: loss 0.036239
[epoch16, step1330]: loss 0.036152
[epoch16, step1331]: loss 0.034553
[epoch16, step1332]: loss 0.036318
[epoch16, step1333]: loss 0.035592
[epoch16, step1334]: loss 0.037813
[epoch16, step1335]: loss 0.035580
[epoch16, step1336]: loss 0.034861
[epoch16, step1337]: loss 0.037094
[epoch16, step1338]: loss 0.036423
[epoch16, step1339]: loss 0.036087
[epoch16, step1340]: loss 0.034416
[epoch16, step1341]: loss 0.036580
[epoch16, step1342]: loss 0.036354
[epoch16, step1343]: loss 0.037530
[epoch16, step1344]: loss 0.035076
[epoch16, step1345]: loss 0.034813
[epoch16, step1346]: loss 0.037163
[epoch16, step1347]: loss 0.036946
[epoch16, step1348]: loss 0.035375
[epoch16, step1349]: loss 0.034846
[epoch16, step1350]: loss 0.036679
[epoch16, step1351]: loss 0.036030
[epoch16, step1352]: loss 0.037377
[epoch16, step1353]: loss 0.034575
[epoch16, step1354]: loss 0.034616
[epoch16, step1355]: loss 0.037831
[epoch16, step1356]: loss 0.036165
[epoch16, step1357]: loss 0.035724
[epoch16, step1358]: loss 0.034441
[epoch16, step1359]: loss 0.035948
[epoch16, step1360]: loss 0.036692
[epoch16, step1361]: loss 0.037605
[epoch16, step1362]: loss 0.035604
[epoch16, step1363]: loss 0.035299
[epoch16, step1364]: loss 0.037491
[epoch16, step1365]: loss 0.036383
[epoch16, step1366]: loss 0.035799
[epoch16, step1367]: loss 0.034071
[epoch16, step1368]: loss 0.037342
[epoch16, step1369]: loss 0.036844
[epoch16, step1370]: loss 0.037267
[epoch16, step1371]: loss 0.035228
[epoch16, step1372]: loss 0.034588
[epoch16, step1373]: loss 0.037812
[epoch16, step1374]: loss 0.036959
[epoch16, step1375]: loss 0.036735
[epoch16, step1376]: loss 0.034349
[epoch16, step1377]: loss 0.035773
[epoch16, step1378]: loss 0.036545
[epoch16, step1379]: loss 0.036782
[epoch16, step1380]: loss 0.035222
[epoch16, step1381]: loss 0.034640
[epoch16, step1382]: loss 0.037800
[epoch16, step1383]: loss 0.036061
[epoch16, step1384]: loss 0.035680
[epoch16, step1385]: loss 0.034139
[epoch16, step1386]: loss 0.036430
[epoch16, step1387]: loss 0.037057
[epoch16, step1388]: loss 0.036545
[epoch16, step1389]: loss 0.034211
[epoch16, step1390]: loss 0.035211
[epoch16, step1391]: loss 0.037381
[epoch16, step1392]: loss 0.036292
[epoch16, step1393]: loss 0.036170
[epoch16, step1394]: loss 0.035240
[epoch16, step1395]: loss 0.036356
[epoch16, step1396]: loss 0.036044
[epoch16, step1397]: loss 0.036966
[epoch16, step1398]: loss 0.034734
[epoch16, step1399]: loss 0.035538
[epoch16, step1400]: loss 0.037946
[epoch16, step1401]: loss 0.036053
[epoch16, step1402]: loss 0.035954
[epoch16, step1403]: loss 0.033806
[epoch16, step1404]: loss 0.035867
[epoch16, step1405]: loss 0.036282
[epoch16, step1406]: loss 0.037075
[epoch16, step1407]: loss 0.035821
[epoch16, step1408]: loss 0.034167
[epoch16, step1409]: loss 0.037136
[epoch16, step1410]: loss 0.036168
[epoch16, step1411]: loss 0.034919
[epoch16, step1412]: loss 0.034512
[epoch16, step1413]: loss 0.036398
[epoch16, step1414]: loss 0.035950
[epoch16, step1415]: loss 0.037089
[epoch16, step1416]: loss 0.034615
[epoch16, step1417]: loss 0.034632
[epoch16, step1418]: loss 0.037398
[epoch16, step1419]: loss 0.036888
[epoch16, step1420]: loss 0.036121
[epoch16, step1421]: loss 0.035152
[epoch16, step1422]: loss 0.036684
[epoch16, step1423]: loss 0.035921
[epoch16, step1424]: loss 0.037563
[epoch16, step1425]: loss 0.034064
[epoch16, step1426]: loss 0.034737
[epoch16, step1427]: loss 0.038459
[epoch16, step1428]: loss 0.036802
[epoch16, step1429]: loss 0.035953
[epoch16, step1430]: loss 0.034383
[epoch16, step1431]: loss 0.036281
[epoch16, step1432]: loss 0.035966
[epoch16, step1433]: loss 0.037181
[epoch16, step1434]: loss 0.034417
[epoch16, step1435]: loss 0.034959
[epoch16, step1436]: loss 0.037681
[epoch16, step1437]: loss 0.036728
[epoch16, step1438]: loss 0.036694
[epoch16, step1439]: loss 0.034454
[epoch16, step1440]: loss 0.036687
[epoch16, step1441]: loss 0.037036
[epoch16, step1442]: loss 0.036638
[epoch16, step1443]: loss 0.034499
[epoch16, step1444]: loss 0.033929
[epoch16, step1445]: loss 0.038005
[epoch16, step1446]: loss 0.036107
[epoch16, step1447]: loss 0.036655
[epoch16, step1448]: loss 0.034210
[epoch16, step1449]: loss 0.035524
[epoch16, step1450]: loss 0.036262
[epoch16, step1451]: loss 0.037273
[epoch16, step1452]: loss 0.034425
[epoch16, step1453]: loss 0.035409
[epoch16, step1454]: loss 0.037748
[epoch16, step1455]: loss 0.036671
[epoch16, step1456]: loss 0.035340
[epoch16, step1457]: loss 0.035166
[epoch16, step1458]: loss 0.036278
[epoch16, step1459]: loss 0.036514
[epoch16, step1460]: loss 0.037966
[epoch16, step1461]: loss 0.035353
[epoch16, step1462]: loss 0.035410
[epoch16, step1463]: loss 0.037921
[epoch16, step1464]: loss 0.036287
[epoch16, step1465]: loss 0.035836
[epoch16, step1466]: loss 0.034316
[epoch16, step1467]: loss 0.035949
[epoch16, step1468]: loss 0.035946
[epoch16, step1469]: loss 0.036865
[epoch16, step1470]: loss 0.034909
[epoch16, step1471]: loss 0.034088
[epoch16, step1472]: loss 0.037145
[epoch16, step1473]: loss 0.036000
[epoch16, step1474]: loss 0.036213
[epoch16, step1475]: loss 0.034158
[epoch16, step1476]: loss 0.036807
[epoch16, step1477]: loss 0.036011
[epoch16, step1478]: loss 0.036908
[epoch16, step1479]: loss 0.034760
[epoch16, step1480]: loss 0.034366
[epoch16, step1481]: loss 0.036876
[epoch16, step1482]: loss 0.036377
[epoch16, step1483]: loss 0.035703
[epoch16, step1484]: loss 0.035347
[epoch16, step1485]: loss 0.036994
[epoch16, step1486]: loss 0.035735
[epoch16, step1487]: loss 0.037007
[epoch16, step1488]: loss 0.035273
[epoch16, step1489]: loss 0.034303
[epoch16, step1490]: loss 0.037517
[epoch16, step1491]: loss 0.036357
[epoch16, step1492]: loss 0.035481
[epoch16, step1493]: loss 0.034405
[epoch16, step1494]: loss 0.036138
[epoch16, step1495]: loss 0.035898
[epoch16, step1496]: loss 0.036044
[epoch16, step1497]: loss 0.034928
[epoch16, step1498]: loss 0.034678
[epoch16, step1499]: loss 0.036828
[epoch16, step1500]: loss 0.036278
[epoch16, step1501]: loss 0.035756
[epoch16, step1502]: loss 0.034232
[epoch16, step1503]: loss 0.035979
[epoch16, step1504]: loss 0.035926
[epoch16, step1505]: loss 0.037186
[epoch16, step1506]: loss 0.034429
[epoch16, step1507]: loss 0.034812
[epoch16, step1508]: loss 0.038170
[epoch16, step1509]: loss 0.036230
[epoch16, step1510]: loss 0.035376
[epoch16, step1511]: loss 0.035659
[epoch16, step1512]: loss 0.037608
[epoch16, step1513]: loss 0.035486
[epoch16, step1514]: loss 0.036860
[epoch16, step1515]: loss 0.035297
[epoch16, step1516]: loss 0.034347

[epoch16]: avg loss 0.033310

[epoch17, step1]: loss 0.031244
[epoch17, step2]: loss 0.037074
[epoch17, step3]: loss 0.036800
[epoch17, step4]: loss 0.034630
[epoch17, step5]: loss 0.034838
[epoch17, step6]: loss 0.037209
[epoch17, step7]: loss 0.035535
[epoch17, step8]: loss 0.037176
[epoch17, step9]: loss 0.034179
[epoch17, step10]: loss 0.035840
[epoch17, step11]: loss 0.037321
[epoch17, step12]: loss 0.037092
[epoch17, step13]: loss 0.034722
[epoch17, step14]: loss 0.035035
[epoch17, step15]: loss 0.037255
[epoch17, step16]: loss 0.035499
[epoch17, step17]: loss 0.037795
[epoch17, step18]: loss 0.035032
[epoch17, step19]: loss 0.035382
[epoch17, step20]: loss 0.038053
[epoch17, step21]: loss 0.037053
[epoch17, step22]: loss 0.034407
[epoch17, step23]: loss 0.034094
[epoch17, step24]: loss 0.037547
[epoch17, step25]: loss 0.034695
[epoch17, step26]: loss 0.037008
[epoch17, step27]: loss 0.033778
[epoch17, step28]: loss 0.035402
[epoch17, step29]: loss 0.037458
[epoch17, step30]: loss 0.037690
[epoch17, step31]: loss 0.034088
[epoch17, step32]: loss 0.035167
[epoch17, step33]: loss 0.037828
[epoch17, step34]: loss 0.035993
[epoch17, step35]: loss 0.037658
[epoch17, step36]: loss 0.034544
[epoch17, step37]: loss 0.035575
[epoch17, step38]: loss 0.037237
[epoch17, step39]: loss 0.037400
[epoch17, step40]: loss 0.035337
[epoch17, step41]: loss 0.033942
[epoch17, step42]: loss 0.037757
[epoch17, step43]: loss 0.035134
[epoch17, step44]: loss 0.037914
[epoch17, step45]: loss 0.034350
[epoch17, step46]: loss 0.035117
[epoch17, step47]: loss 0.036819
[epoch17, step48]: loss 0.036689
[epoch17, step49]: loss 0.033142
[epoch17, step50]: loss 0.034659
[epoch17, step51]: loss 0.037203
[epoch17, step52]: loss 0.035034
[epoch17, step53]: loss 0.037639
[epoch17, step54]: loss 0.034318
[epoch17, step55]: loss 0.035580
[epoch17, step56]: loss 0.038620
[epoch17, step57]: loss 0.038094
[epoch17, step58]: loss 0.034656
[epoch17, step59]: loss 0.034228
[epoch17, step60]: loss 0.038796
[epoch17, step61]: loss 0.034702
[epoch17, step62]: loss 0.036694
[epoch17, step63]: loss 0.034133
[epoch17, step64]: loss 0.034673
[epoch17, step65]: loss 0.037659
[epoch17, step66]: loss 0.036832
[epoch17, step67]: loss 0.034602
[epoch17, step68]: loss 0.034467
[epoch17, step69]: loss 0.037086
[epoch17, step70]: loss 0.034891
[epoch17, step71]: loss 0.036668
[epoch17, step72]: loss 0.034195
[epoch17, step73]: loss 0.035042
[epoch17, step74]: loss 0.037508
[epoch17, step75]: loss 0.037492
[epoch17, step76]: loss 0.035334
[epoch17, step77]: loss 0.035584
[epoch17, step78]: loss 0.037395
[epoch17, step79]: loss 0.035058
[epoch17, step80]: loss 0.038819
[epoch17, step81]: loss 0.034386
[epoch17, step82]: loss 0.035286
[epoch17, step83]: loss 0.038005
[epoch17, step84]: loss 0.037577
[epoch17, step85]: loss 0.035203
[epoch17, step86]: loss 0.035211
[epoch17, step87]: loss 0.038498
[epoch17, step88]: loss 0.033960
[epoch17, step89]: loss 0.037217
[epoch17, step90]: loss 0.034848
[epoch17, step91]: loss 0.034460
[epoch17, step92]: loss 0.037977
[epoch17, step93]: loss 0.037265
[epoch17, step94]: loss 0.034547
[epoch17, step95]: loss 0.035492
[epoch17, step96]: loss 0.037007
[epoch17, step97]: loss 0.036222
[epoch17, step98]: loss 0.038382
[epoch17, step99]: loss 0.034730
[epoch17, step100]: loss 0.033991
[epoch17, step101]: loss 0.038233
[epoch17, step102]: loss 0.036784
[epoch17, step103]: loss 0.034535
[epoch17, step104]: loss 0.034397
[epoch17, step105]: loss 0.037703
[epoch17, step106]: loss 0.035064
[epoch17, step107]: loss 0.037422
[epoch17, step108]: loss 0.034530
[epoch17, step109]: loss 0.034619
[epoch17, step110]: loss 0.038085
[epoch17, step111]: loss 0.036738
[epoch17, step112]: loss 0.034924
[epoch17, step113]: loss 0.035571
[epoch17, step114]: loss 0.037073
[epoch17, step115]: loss 0.035333
[epoch17, step116]: loss 0.037854
[epoch17, step117]: loss 0.034690
[epoch17, step118]: loss 0.036630
[epoch17, step119]: loss 0.037984
[epoch17, step120]: loss 0.037677
[epoch17, step121]: loss 0.035239
[epoch17, step122]: loss 0.034594
[epoch17, step123]: loss 0.037743
[epoch17, step124]: loss 0.035714
[epoch17, step125]: loss 0.037521
[epoch17, step126]: loss 0.034451
[epoch17, step127]: loss 0.034654
[epoch17, step128]: loss 0.037330
[epoch17, step129]: loss 0.036926
[epoch17, step130]: loss 0.034745
[epoch17, step131]: loss 0.033989
[epoch17, step132]: loss 0.037379
[epoch17, step133]: loss 0.034894
[epoch17, step134]: loss 0.036572
[epoch17, step135]: loss 0.034916
[epoch17, step136]: loss 0.035849
[epoch17, step137]: loss 0.037405
[epoch17, step138]: loss 0.036839
[epoch17, step139]: loss 0.034673
[epoch17, step140]: loss 0.035106
[epoch17, step141]: loss 0.037626
[epoch17, step142]: loss 0.035249
[epoch17, step143]: loss 0.036672
[epoch17, step144]: loss 0.035050
[epoch17, step145]: loss 0.035447
[epoch17, step146]: loss 0.037452
[epoch17, step147]: loss 0.038710
[epoch17, step148]: loss 0.034694
[epoch17, step149]: loss 0.034214
[epoch17, step150]: loss 0.037388
[epoch17, step151]: loss 0.035095
[epoch17, step152]: loss 0.037072
[epoch17, step153]: loss 0.034424
[epoch17, step154]: loss 0.034855
[epoch17, step155]: loss 0.037171
[epoch17, step156]: loss 0.036644
[epoch17, step157]: loss 0.034579
[epoch17, step158]: loss 0.034763
[epoch17, step159]: loss 0.037415
[epoch17, step160]: loss 0.035387
[epoch17, step161]: loss 0.037656
[epoch17, step162]: loss 0.034784
[epoch17, step163]: loss 0.034965
[epoch17, step164]: loss 0.037938
[epoch17, step165]: loss 0.037383
[epoch17, step166]: loss 0.034846
[epoch17, step167]: loss 0.034494
[epoch17, step168]: loss 0.038136
[epoch17, step169]: loss 0.034894
[epoch17, step170]: loss 0.037793
[epoch17, step171]: loss 0.034570
[epoch17, step172]: loss 0.035194
[epoch17, step173]: loss 0.037674
[epoch17, step174]: loss 0.036892
[epoch17, step175]: loss 0.035326
[epoch17, step176]: loss 0.034899
[epoch17, step177]: loss 0.037622
[epoch17, step178]: loss 0.035030
[epoch17, step179]: loss 0.036364
[epoch17, step180]: loss 0.034729
[epoch17, step181]: loss 0.035333
[epoch17, step182]: loss 0.037807
[epoch17, step183]: loss 0.037797
[epoch17, step184]: loss 0.035586
[epoch17, step185]: loss 0.035062
[epoch17, step186]: loss 0.037447
[epoch17, step187]: loss 0.035336
[epoch17, step188]: loss 0.037195
[epoch17, step189]: loss 0.034458
[epoch17, step190]: loss 0.034508
[epoch17, step191]: loss 0.037416
[epoch17, step192]: loss 0.037695
[epoch17, step193]: loss 0.032797
[epoch17, step194]: loss 0.033894
[epoch17, step195]: loss 0.037590
[epoch17, step196]: loss 0.035330
[epoch17, step197]: loss 0.037297
[epoch17, step198]: loss 0.033644
[epoch17, step199]: loss 0.035131
[epoch17, step200]: loss 0.037940
[epoch17, step201]: loss 0.037626
[epoch17, step202]: loss 0.034326
[epoch17, step203]: loss 0.034763
[epoch17, step204]: loss 0.037737
[epoch17, step205]: loss 0.034667
[epoch17, step206]: loss 0.036874
[epoch17, step207]: loss 0.034529
[epoch17, step208]: loss 0.035900
[epoch17, step209]: loss 0.037794
[epoch17, step210]: loss 0.038478
[epoch17, step211]: loss 0.035729
[epoch17, step212]: loss 0.034966
[epoch17, step213]: loss 0.037238
[epoch17, step214]: loss 0.034739
[epoch17, step215]: loss 0.037330
[epoch17, step216]: loss 0.034715
[epoch17, step217]: loss 0.034229
[epoch17, step218]: loss 0.037597
[epoch17, step219]: loss 0.036712
[epoch17, step220]: loss 0.034926
[epoch17, step221]: loss 0.034741
[epoch17, step222]: loss 0.037720
[epoch17, step223]: loss 0.035267
[epoch17, step224]: loss 0.036750
[epoch17, step225]: loss 0.034391
[epoch17, step226]: loss 0.034576
[epoch17, step227]: loss 0.036977
[epoch17, step228]: loss 0.037888
[epoch17, step229]: loss 0.033803
[epoch17, step230]: loss 0.035098
[epoch17, step231]: loss 0.037764
[epoch17, step232]: loss 0.035287
[epoch17, step233]: loss 0.036782
[epoch17, step234]: loss 0.034071
[epoch17, step235]: loss 0.035410
[epoch17, step236]: loss 0.037546
[epoch17, step237]: loss 0.037413
[epoch17, step238]: loss 0.034423
[epoch17, step239]: loss 0.034024
[epoch17, step240]: loss 0.036939
[epoch17, step241]: loss 0.035700
[epoch17, step242]: loss 0.037266
[epoch17, step243]: loss 0.035169
[epoch17, step244]: loss 0.034888
[epoch17, step245]: loss 0.036903
[epoch17, step246]: loss 0.037187
[epoch17, step247]: loss 0.035022
[epoch17, step248]: loss 0.034360
[epoch17, step249]: loss 0.036936
[epoch17, step250]: loss 0.035451
[epoch17, step251]: loss 0.037794
[epoch17, step252]: loss 0.034876
[epoch17, step253]: loss 0.034452
[epoch17, step254]: loss 0.037252
[epoch17, step255]: loss 0.037560
[epoch17, step256]: loss 0.034426
[epoch17, step257]: loss 0.034436
[epoch17, step258]: loss 0.037805
[epoch17, step259]: loss 0.035492
[epoch17, step260]: loss 0.036825
[epoch17, step261]: loss 0.035251
[epoch17, step262]: loss 0.035320
[epoch17, step263]: loss 0.037000
[epoch17, step264]: loss 0.036843
[epoch17, step265]: loss 0.034819
[epoch17, step266]: loss 0.034564
[epoch17, step267]: loss 0.036792
[epoch17, step268]: loss 0.035286
[epoch17, step269]: loss 0.037191
[epoch17, step270]: loss 0.034159
[epoch17, step271]: loss 0.035290
[epoch17, step272]: loss 0.037253
[epoch17, step273]: loss 0.037131
[epoch17, step274]: loss 0.035231
[epoch17, step275]: loss 0.034092
[epoch17, step276]: loss 0.037288
[epoch17, step277]: loss 0.035389
[epoch17, step278]: loss 0.037375
[epoch17, step279]: loss 0.033890
[epoch17, step280]: loss 0.034952
[epoch17, step281]: loss 0.037388
[epoch17, step282]: loss 0.037570
[epoch17, step283]: loss 0.034382
[epoch17, step284]: loss 0.034204
[epoch17, step285]: loss 0.038113
[epoch17, step286]: loss 0.034457
[epoch17, step287]: loss 0.037307
[epoch17, step288]: loss 0.034326
[epoch17, step289]: loss 0.035778
[epoch17, step290]: loss 0.037642
[epoch17, step291]: loss 0.037765
[epoch17, step292]: loss 0.033782
[epoch17, step293]: loss 0.034492
[epoch17, step294]: loss 0.037196
[epoch17, step295]: loss 0.034647
[epoch17, step296]: loss 0.038185
[epoch17, step297]: loss 0.033974
[epoch17, step298]: loss 0.035365
[epoch17, step299]: loss 0.036646
[epoch17, step300]: loss 0.037459
[epoch17, step301]: loss 0.034602
[epoch17, step302]: loss 0.034980
[epoch17, step303]: loss 0.037670
[epoch17, step304]: loss 0.034849
[epoch17, step305]: loss 0.036762
[epoch17, step306]: loss 0.034815
[epoch17, step307]: loss 0.034915
[epoch17, step308]: loss 0.037893
[epoch17, step309]: loss 0.037690
[epoch17, step310]: loss 0.034781
[epoch17, step311]: loss 0.035080
[epoch17, step312]: loss 0.037404
[epoch17, step313]: loss 0.035234
[epoch17, step314]: loss 0.037420
[epoch17, step315]: loss 0.035287
[epoch17, step316]: loss 0.034820
[epoch17, step317]: loss 0.038078
[epoch17, step318]: loss 0.037045
[epoch17, step319]: loss 0.034159
[epoch17, step320]: loss 0.033642
[epoch17, step321]: loss 0.036788
[epoch17, step322]: loss 0.034857
[epoch17, step323]: loss 0.036440
[epoch17, step324]: loss 0.035290
[epoch17, step325]: loss 0.035063
[epoch17, step326]: loss 0.037305
[epoch17, step327]: loss 0.036578
[epoch17, step328]: loss 0.034859
[epoch17, step329]: loss 0.034479
[epoch17, step330]: loss 0.036949
[epoch17, step331]: loss 0.035378
[epoch17, step332]: loss 0.036415
[epoch17, step333]: loss 0.034645
[epoch17, step334]: loss 0.035276
[epoch17, step335]: loss 0.037493
[epoch17, step336]: loss 0.038242
[epoch17, step337]: loss 0.035135
[epoch17, step338]: loss 0.034502
[epoch17, step339]: loss 0.037694
[epoch17, step340]: loss 0.035722
[epoch17, step341]: loss 0.036984
[epoch17, step342]: loss 0.034235
[epoch17, step343]: loss 0.035083
[epoch17, step344]: loss 0.037064
[epoch17, step345]: loss 0.036428
[epoch17, step346]: loss 0.034148
[epoch17, step347]: loss 0.034233
[epoch17, step348]: loss 0.037382
[epoch17, step349]: loss 0.035472
[epoch17, step350]: loss 0.036565
[epoch17, step351]: loss 0.033710
[epoch17, step352]: loss 0.034617
[epoch17, step353]: loss 0.037482
[epoch17, step354]: loss 0.036355
[epoch17, step355]: loss 0.033531
[epoch17, step356]: loss 0.035336
[epoch17, step357]: loss 0.037669
[epoch17, step358]: loss 0.033737
[epoch17, step359]: loss 0.038454
[epoch17, step360]: loss 0.033039
[epoch17, step361]: loss 0.034544
[epoch17, step362]: loss 0.038232
[epoch17, step363]: loss 0.036887
[epoch17, step364]: loss 0.034585
[epoch17, step365]: loss 0.034386
[epoch17, step366]: loss 0.037673
[epoch17, step367]: loss 0.035148
[epoch17, step368]: loss 0.036810
[epoch17, step369]: loss 0.034156
[epoch17, step370]: loss 0.035499
[epoch17, step371]: loss 0.038039
[epoch17, step372]: loss 0.036821
[epoch17, step373]: loss 0.034116
[epoch17, step374]: loss 0.033796
[epoch17, step375]: loss 0.037863
[epoch17, step376]: loss 0.035194
[epoch17, step377]: loss 0.037252
[epoch17, step378]: loss 0.034798
[epoch17, step379]: loss 0.035490
[epoch17, step380]: loss 0.037992
[epoch17, step381]: loss 0.036855
[epoch17, step382]: loss 0.034762
[epoch17, step383]: loss 0.033546
[epoch17, step384]: loss 0.036587
[epoch17, step385]: loss 0.034870
[epoch17, step386]: loss 0.037261
[epoch17, step387]: loss 0.034607
[epoch17, step388]: loss 0.036327
[epoch17, step389]: loss 0.037394
[epoch17, step390]: loss 0.038421
[epoch17, step391]: loss 0.034644
[epoch17, step392]: loss 0.034862
[epoch17, step393]: loss 0.037035
[epoch17, step394]: loss 0.035003
[epoch17, step395]: loss 0.036831
[epoch17, step396]: loss 0.034408
[epoch17, step397]: loss 0.034356
[epoch17, step398]: loss 0.037352
[epoch17, step399]: loss 0.036942
[epoch17, step400]: loss 0.034189
[epoch17, step401]: loss 0.034312
[epoch17, step402]: loss 0.037169
[epoch17, step403]: loss 0.035038
[epoch17, step404]: loss 0.037368
[epoch17, step405]: loss 0.034948
[epoch17, step406]: loss 0.035193
[epoch17, step407]: loss 0.037089
[epoch17, step408]: loss 0.037392
[epoch17, step409]: loss 0.035742
[epoch17, step410]: loss 0.035217
[epoch17, step411]: loss 0.037136
[epoch17, step412]: loss 0.034640
[epoch17, step413]: loss 0.037247
[epoch17, step414]: loss 0.034105
[epoch17, step415]: loss 0.035302
[epoch17, step416]: loss 0.036723
[epoch17, step417]: loss 0.037351
[epoch17, step418]: loss 0.034603
[epoch17, step419]: loss 0.033696
[epoch17, step420]: loss 0.037468
[epoch17, step421]: loss 0.034602
[epoch17, step422]: loss 0.037055
[epoch17, step423]: loss 0.034426
[epoch17, step424]: loss 0.034852
[epoch17, step425]: loss 0.037444
[epoch17, step426]: loss 0.037377
[epoch17, step427]: loss 0.035144
[epoch17, step428]: loss 0.034508
[epoch17, step429]: loss 0.037704
[epoch17, step430]: loss 0.035065
[epoch17, step431]: loss 0.037436
[epoch17, step432]: loss 0.034621
[epoch17, step433]: loss 0.036276
[epoch17, step434]: loss 0.037420
[epoch17, step435]: loss 0.037847
[epoch17, step436]: loss 0.035080
[epoch17, step437]: loss 0.035028
[epoch17, step438]: loss 0.037762
[epoch17, step439]: loss 0.035376
[epoch17, step440]: loss 0.036910
[epoch17, step441]: loss 0.034707
[epoch17, step442]: loss 0.034618
[epoch17, step443]: loss 0.037728
[epoch17, step444]: loss 0.036614
[epoch17, step445]: loss 0.034890
[epoch17, step446]: loss 0.034790
[epoch17, step447]: loss 0.037834
[epoch17, step448]: loss 0.035063
[epoch17, step449]: loss 0.036734
[epoch17, step450]: loss 0.033748
[epoch17, step451]: loss 0.034540
[epoch17, step452]: loss 0.036569
[epoch17, step453]: loss 0.037218
[epoch17, step454]: loss 0.034805
[epoch17, step455]: loss 0.035430
[epoch17, step456]: loss 0.036680
[epoch17, step457]: loss 0.035906
[epoch17, step458]: loss 0.037639
[epoch17, step459]: loss 0.035153
[epoch17, step460]: loss 0.035229
[epoch17, step461]: loss 0.038672
[epoch17, step462]: loss 0.036450
[epoch17, step463]: loss 0.035154
[epoch17, step464]: loss 0.034683
[epoch17, step465]: loss 0.038374
[epoch17, step466]: loss 0.034981
[epoch17, step467]: loss 0.036857
[epoch17, step468]: loss 0.034418
[epoch17, step469]: loss 0.035032
[epoch17, step470]: loss 0.037701
[epoch17, step471]: loss 0.036628
[epoch17, step472]: loss 0.035114
[epoch17, step473]: loss 0.033902
[epoch17, step474]: loss 0.037240
[epoch17, step475]: loss 0.035116
[epoch17, step476]: loss 0.037535
[epoch17, step477]: loss 0.034376
[epoch17, step478]: loss 0.034079
[epoch17, step479]: loss 0.037676
[epoch17, step480]: loss 0.037244
[epoch17, step481]: loss 0.034314
[epoch17, step482]: loss 0.034493
[epoch17, step483]: loss 0.039008
[epoch17, step484]: loss 0.035749
[epoch17, step485]: loss 0.037151
[epoch17, step486]: loss 0.035059
[epoch17, step487]: loss 0.034325
[epoch17, step488]: loss 0.037696
[epoch17, step489]: loss 0.036346
[epoch17, step490]: loss 0.034898
[epoch17, step491]: loss 0.034681
[epoch17, step492]: loss 0.036807
[epoch17, step493]: loss 0.034618
[epoch17, step494]: loss 0.036386
[epoch17, step495]: loss 0.035309
[epoch17, step496]: loss 0.034871
[epoch17, step497]: loss 0.037786
[epoch17, step498]: loss 0.036996
[epoch17, step499]: loss 0.035056
[epoch17, step500]: loss 0.034019
[epoch17, step501]: loss 0.037008
[epoch17, step502]: loss 0.035041
[epoch17, step503]: loss 0.037303
[epoch17, step504]: loss 0.034474
[epoch17, step505]: loss 0.034510
[epoch17, step506]: loss 0.037835
[epoch17, step507]: loss 0.037872
[epoch17, step508]: loss 0.035974
[epoch17, step509]: loss 0.034447
[epoch17, step510]: loss 0.037648
[epoch17, step511]: loss 0.035763
[epoch17, step512]: loss 0.037385
[epoch17, step513]: loss 0.034626
[epoch17, step514]: loss 0.035178
[epoch17, step515]: loss 0.037391
[epoch17, step516]: loss 0.037558
[epoch17, step517]: loss 0.035244
[epoch17, step518]: loss 0.034725
[epoch17, step519]: loss 0.037556
[epoch17, step520]: loss 0.034587
[epoch17, step521]: loss 0.037305
[epoch17, step522]: loss 0.034336
[epoch17, step523]: loss 0.035514
[epoch17, step524]: loss 0.036886
[epoch17, step525]: loss 0.037528
[epoch17, step526]: loss 0.035140
[epoch17, step527]: loss 0.034107
[epoch17, step528]: loss 0.037523
[epoch17, step529]: loss 0.034789
[epoch17, step530]: loss 0.037260
[epoch17, step531]: loss 0.034162
[epoch17, step532]: loss 0.034432
[epoch17, step533]: loss 0.038112
[epoch17, step534]: loss 0.036846
[epoch17, step535]: loss 0.035197
[epoch17, step536]: loss 0.034596
[epoch17, step537]: loss 0.037220
[epoch17, step538]: loss 0.035006
[epoch17, step539]: loss 0.036909
[epoch17, step540]: loss 0.033891
[epoch17, step541]: loss 0.034309
[epoch17, step542]: loss 0.037517
[epoch17, step543]: loss 0.036647
[epoch17, step544]: loss 0.034691
[epoch17, step545]: loss 0.033599
[epoch17, step546]: loss 0.037872
[epoch17, step547]: loss 0.034968
[epoch17, step548]: loss 0.037068
[epoch17, step549]: loss 0.034815
[epoch17, step550]: loss 0.034603
[epoch17, step551]: loss 0.037688
[epoch17, step552]: loss 0.037394
[epoch17, step553]: loss 0.034975
[epoch17, step554]: loss 0.034882
[epoch17, step555]: loss 0.038129
[epoch17, step556]: loss 0.035280
[epoch17, step557]: loss 0.036527
[epoch17, step558]: loss 0.034745
[epoch17, step559]: loss 0.034432
[epoch17, step560]: loss 0.037358
[epoch17, step561]: loss 0.036921
[epoch17, step562]: loss 0.034510
[epoch17, step563]: loss 0.028877
[epoch17, step564]: loss 0.029979
[epoch17, step565]: loss 0.027591
[epoch17, step566]: loss 0.035156
[epoch17, step567]: loss 0.026884
[epoch17, step568]: loss 0.025950
[epoch17, step569]: loss 0.023256
[epoch17, step570]: loss 0.031427
[epoch17, step571]: loss 0.027253
[epoch17, step572]: loss 0.026010
[epoch17, step573]: loss 0.029301
[epoch17, step574]: loss 0.027974
[epoch17, step575]: loss 0.020697
[epoch17, step576]: loss 0.021467
[epoch17, step577]: loss 0.026053
[epoch17, step578]: loss 0.018845
[epoch17, step579]: loss 0.028507
[epoch17, step580]: loss 0.019885
[epoch17, step581]: loss 0.025536
[epoch17, step582]: loss 0.025025
[epoch17, step583]: loss 0.021880
[epoch17, step584]: loss 0.023826
[epoch17, step585]: loss 0.026410
[epoch17, step586]: loss 0.021676
[epoch17, step587]: loss 0.027835
[epoch17, step588]: loss 0.023261
[epoch17, step589]: loss 0.022914
[epoch17, step590]: loss 0.026775
[epoch17, step591]: loss 0.020361
[epoch17, step592]: loss 0.025688
[epoch17, step593]: loss 0.022078
[epoch17, step594]: loss 0.026159
[epoch17, step595]: loss 0.026346
[epoch17, step596]: loss 0.022197
[epoch17, step597]: loss 0.024947
[epoch17, step598]: loss 0.026569
[epoch17, step599]: loss 0.025269
[epoch17, step600]: loss 0.027382
[epoch17, step601]: loss 0.019506
[epoch17, step602]: loss 0.022421
[epoch17, step603]: loss 0.025499
[epoch17, step604]: loss 0.026372
[epoch17, step605]: loss 0.025037
[epoch17, step606]: loss 0.025251
[epoch17, step607]: loss 0.026730
[epoch17, step608]: loss 0.025434
[epoch17, step609]: loss 0.026107
[epoch17, step610]: loss 0.026153
[epoch17, step611]: loss 0.026324
[epoch17, step612]: loss 0.025057
[epoch17, step613]: loss 0.019152
[epoch17, step614]: loss 0.025329
[epoch17, step615]: loss 0.027864
[epoch17, step616]: loss 0.024306
[epoch17, step617]: loss 0.023409
[epoch17, step618]: loss 0.025556
[epoch17, step619]: loss 0.027083
[epoch17, step620]: loss 0.024207
[epoch17, step621]: loss 0.026495
[epoch17, step622]: loss 0.020390
[epoch17, step623]: loss 0.024433
[epoch17, step624]: loss 0.026449
[epoch17, step625]: loss 0.025703
[epoch17, step626]: loss 0.028512
[epoch17, step627]: loss 0.022551
[epoch17, step628]: loss 0.024967
[epoch17, step629]: loss 0.020708
[epoch17, step630]: loss 0.023241
[epoch17, step631]: loss 0.030832
[epoch17, step632]: loss 0.023415
[epoch17, step633]: loss 0.024668
[epoch17, step634]: loss 0.027158
[epoch17, step635]: loss 0.025320
[epoch17, step636]: loss 0.020676
[epoch17, step637]: loss 0.027221
[epoch17, step638]: loss 0.026747
[epoch17, step639]: loss 0.022566
[epoch17, step640]: loss 0.029787
[epoch17, step641]: loss 0.029980
[epoch17, step642]: loss 0.025100
[epoch17, step643]: loss 0.025669
[epoch17, step644]: loss 0.025493
[epoch17, step645]: loss 0.023248
[epoch17, step646]: loss 0.025811
[epoch17, step647]: loss 0.023265
[epoch17, step648]: loss 0.023085
[epoch17, step649]: loss 0.028528
[epoch17, step650]: loss 0.021805
[epoch17, step651]: loss 0.026101
[epoch17, step652]: loss 0.027080
[epoch17, step653]: loss 0.027941
[epoch17, step654]: loss 0.023164
[epoch17, step655]: loss 0.024508
[epoch17, step656]: loss 0.021713
[epoch17, step657]: loss 0.027418
[epoch17, step658]: loss 0.025270
[epoch17, step659]: loss 0.027691
[epoch17, step660]: loss 0.023812
[epoch17, step661]: loss 0.026392
[epoch17, step662]: loss 0.023779
[epoch17, step663]: loss 0.021788
[epoch17, step664]: loss 0.029285
[epoch17, step665]: loss 0.032891
[epoch17, step666]: loss 0.031054
[epoch17, step667]: loss 0.028108
[epoch17, step668]: loss 0.023152
[epoch17, step669]: loss 0.027295
[epoch17, step670]: loss 0.027970
[epoch17, step671]: loss 0.024014
[epoch17, step672]: loss 0.024668
[epoch17, step673]: loss 0.023048
[epoch17, step674]: loss 0.022170
[epoch17, step675]: loss 0.020379
[epoch17, step676]: loss 0.024920
[epoch17, step677]: loss 0.025660
[epoch17, step678]: loss 0.023328
[epoch17, step679]: loss 0.024281
[epoch17, step680]: loss 0.031541
[epoch17, step681]: loss 0.022283
[epoch17, step682]: loss 0.026773
[epoch17, step683]: loss 0.026277
[epoch17, step684]: loss 0.025102
[epoch17, step685]: loss 0.024627
[epoch17, step686]: loss 0.027685
[epoch17, step687]: loss 0.026948
[epoch17, step688]: loss 0.022702
[epoch17, step689]: loss 0.024707
[epoch17, step690]: loss 0.025254
[epoch17, step691]: loss 0.024152
[epoch17, step692]: loss 0.022461
[epoch17, step693]: loss 0.027145
[epoch17, step694]: loss 0.022907
[epoch17, step695]: loss 0.026464
[epoch17, step696]: loss 0.026081
[epoch17, step697]: loss 0.027012
[epoch17, step698]: loss 0.024799
[epoch17, step699]: loss 0.023655
[epoch17, step700]: loss 0.021842
[epoch17, step701]: loss 0.026027
[epoch17, step702]: loss 0.021939
[epoch17, step703]: loss 0.022979
[epoch17, step704]: loss 0.025178
[epoch17, step705]: loss 0.024859
[epoch17, step706]: loss 0.023925
[epoch17, step707]: loss 0.024666
[epoch17, step708]: loss 0.026172
[epoch17, step709]: loss 0.027398
[epoch17, step710]: loss 0.023901
[epoch17, step711]: loss 0.023525
[epoch17, step712]: loss 0.026735
[epoch17, step713]: loss 0.026324
[epoch17, step714]: loss 0.021389
[epoch17, step715]: loss 0.023181
[epoch17, step716]: loss 0.025842
[epoch17, step717]: loss 0.023491
[epoch17, step718]: loss 0.025133
[epoch17, step719]: loss 0.032995
[epoch17, step720]: loss 0.024825
[epoch17, step721]: loss 0.023090
[epoch17, step722]: loss 0.030590
[epoch17, step723]: loss 0.025825
[epoch17, step724]: loss 0.022895
[epoch17, step725]: loss 0.027877
[epoch17, step726]: loss 0.022453
[epoch17, step727]: loss 0.024614
[epoch17, step728]: loss 0.026383
[epoch17, step729]: loss 0.021121
[epoch17, step730]: loss 0.022598
[epoch17, step731]: loss 0.025862
[epoch17, step732]: loss 0.025692
[epoch17, step733]: loss 0.023762
[epoch17, step734]: loss 0.022739
[epoch17, step735]: loss 0.027313
[epoch17, step736]: loss 0.025103
[epoch17, step737]: loss 0.026757
[epoch17, step738]: loss 0.020642
[epoch17, step739]: loss 0.025503
[epoch17, step740]: loss 0.022433
[epoch17, step741]: loss 0.025094
[epoch17, step742]: loss 0.021815
[epoch17, step743]: loss 0.023270
[epoch17, step744]: loss 0.023850
[epoch17, step745]: loss 0.024432
[epoch17, step746]: loss 0.024980
[epoch17, step747]: loss 0.027348
[epoch17, step748]: loss 0.025596
[epoch17, step749]: loss 0.026136
[epoch17, step750]: loss 0.027529
[epoch17, step751]: loss 0.021762
[epoch17, step752]: loss 0.025019
[epoch17, step753]: loss 0.025471
[epoch17, step754]: loss 0.022618
[epoch17, step755]: loss 0.026161
[epoch17, step756]: loss 0.023452
[epoch17, step757]: loss 0.020505
[epoch17, step758]: loss 0.025094
[epoch17, step759]: loss 0.023119
[epoch17, step760]: loss 0.023880
[epoch17, step761]: loss 0.026432
[epoch17, step762]: loss 0.021494
[epoch17, step763]: loss 0.025452
[epoch17, step764]: loss 0.023330
[epoch17, step765]: loss 0.026097
[epoch17, step766]: loss 0.024466
[epoch17, step767]: loss 0.026705
[epoch17, step768]: loss 0.021399
[epoch17, step769]: loss 0.026625
[epoch17, step770]: loss 0.026054
[epoch17, step771]: loss 0.023306
[epoch17, step772]: loss 0.028768
[epoch17, step773]: loss 0.026558
[epoch17, step774]: loss 0.024271
[epoch17, step775]: loss 0.020528
[epoch17, step776]: loss 0.025376
[epoch17, step777]: loss 0.023061
[epoch17, step778]: loss 0.028023
[epoch17, step779]: loss 0.023740
[epoch17, step780]: loss 0.020199
[epoch17, step781]: loss 0.024354
[epoch17, step782]: loss 0.022680
[epoch17, step783]: loss 0.019290
[epoch17, step784]: loss 0.020288
[epoch17, step785]: loss 0.021377
[epoch17, step786]: loss 0.024126
[epoch17, step787]: loss 0.023203
[epoch17, step788]: loss 0.024623
[epoch17, step789]: loss 0.022388
[epoch17, step790]: loss 0.023138
[epoch17, step791]: loss 0.026617
[epoch17, step792]: loss 0.025024
[epoch17, step793]: loss 0.026910
[epoch17, step794]: loss 0.020317
[epoch17, step795]: loss 0.025637
[epoch17, step796]: loss 0.027806
[epoch17, step797]: loss 0.027744
[epoch17, step798]: loss 0.027226
[epoch17, step799]: loss 0.025911
[epoch17, step800]: loss 0.021335
[epoch17, step801]: loss 0.021569
[epoch17, step802]: loss 0.022680
[epoch17, step803]: loss 0.026102
[epoch17, step804]: loss 0.027284
[epoch17, step805]: loss 0.027958
[epoch17, step806]: loss 0.021287
[epoch17, step807]: loss 0.020626
[epoch17, step808]: loss 0.022878
[epoch17, step809]: loss 0.023027
[epoch17, step810]: loss 0.025873
[epoch17, step811]: loss 0.025530
[epoch17, step812]: loss 0.024685
[epoch17, step813]: loss 0.023426
[epoch17, step814]: loss 0.025092
[epoch17, step815]: loss 0.025092
[epoch17, step816]: loss 0.024429
[epoch17, step817]: loss 0.024767
[epoch17, step818]: loss 0.022432
[epoch17, step819]: loss 0.019935
[epoch17, step820]: loss 0.023455
[epoch17, step821]: loss 0.021806
[epoch17, step822]: loss 0.030341
[epoch17, step823]: loss 0.023995
[epoch17, step824]: loss 0.026705
[epoch17, step825]: loss 0.025200
[epoch17, step826]: loss 0.024347
[epoch17, step827]: loss 0.026916
[epoch17, step828]: loss 0.028641
[epoch17, step829]: loss 0.026319
[epoch17, step830]: loss 0.022483
[epoch17, step831]: loss 0.026361
[epoch17, step832]: loss 0.020851
[epoch17, step833]: loss 0.028858
[epoch17, step834]: loss 0.025434
[epoch17, step835]: loss 0.020686
[epoch17, step836]: loss 0.026979
[epoch17, step837]: loss 0.025731
[epoch17, step838]: loss 0.026216
[epoch17, step839]: loss 0.028281
[epoch17, step840]: loss 0.020640
[epoch17, step841]: loss 0.024329
[epoch17, step842]: loss 0.027393
[epoch17, step843]: loss 0.024951
[epoch17, step844]: loss 0.025231
[epoch17, step845]: loss 0.021080
[epoch17, step846]: loss 0.025508
[epoch17, step847]: loss 0.026636
[epoch17, step848]: loss 0.024873
[epoch17, step849]: loss 0.025065
[epoch17, step850]: loss 0.022963
[epoch17, step851]: loss 0.023976
[epoch17, step852]: loss 0.023140
[epoch17, step853]: loss 0.029319
[epoch17, step854]: loss 0.022656
[epoch17, step855]: loss 0.027231
[epoch17, step856]: loss 0.022172
[epoch17, step857]: loss 0.025713
[epoch17, step858]: loss 0.024274
[epoch17, step859]: loss 0.023524
[epoch17, step860]: loss 0.022494
[epoch17, step861]: loss 0.023175
[epoch17, step862]: loss 0.023093
[epoch17, step863]: loss 0.020680
[epoch17, step864]: loss 0.026321
[epoch17, step865]: loss 0.023567
[epoch17, step866]: loss 0.025264
[epoch17, step867]: loss 0.026020
[epoch17, step868]: loss 0.026783
[epoch17, step869]: loss 0.023804
[epoch17, step870]: loss 0.030881
[epoch17, step871]: loss 0.021907
[epoch17, step872]: loss 0.025445
[epoch17, step873]: loss 0.025837
[epoch17, step874]: loss 0.023656
[epoch17, step875]: loss 0.024161
[epoch17, step876]: loss 0.024172
[epoch17, step877]: loss 0.019152
[epoch17, step878]: loss 0.023184
[epoch17, step879]: loss 0.027975
[epoch17, step880]: loss 0.025646
[epoch17, step881]: loss 0.022123
[epoch17, step882]: loss 0.024126
[epoch17, step883]: loss 0.023746
[epoch17, step884]: loss 0.026376
[epoch17, step885]: loss 0.025928
[epoch17, step886]: loss 0.026580
[epoch17, step887]: loss 0.024151
[epoch17, step888]: loss 0.024527
[epoch17, step889]: loss 0.023368
[epoch17, step890]: loss 0.023612
[epoch17, step891]: loss 0.025467
[epoch17, step892]: loss 0.021022
[epoch17, step893]: loss 0.024648
[epoch17, step894]: loss 0.025054
[epoch17, step895]: loss 0.022644
[epoch17, step896]: loss 0.021888
[epoch17, step897]: loss 0.023897
[epoch17, step898]: loss 0.025184
[epoch17, step899]: loss 0.027954
[epoch17, step900]: loss 0.026897
[epoch17, step901]: loss 0.025208
[epoch17, step902]: loss 0.023862
[epoch17, step903]: loss 0.024036
[epoch17, step904]: loss 0.027959
[epoch17, step905]: loss 0.027645
[epoch17, step906]: loss 0.022451
[epoch17, step907]: loss 0.023708
[epoch17, step908]: loss 0.022568
[epoch17, step909]: loss 0.025464
[epoch17, step910]: loss 0.023112
[epoch17, step911]: loss 0.025187
[epoch17, step912]: loss 0.023907
[epoch17, step913]: loss 0.024002
[epoch17, step914]: loss 0.030282
[epoch17, step915]: loss 0.024007
[epoch17, step916]: loss 0.023788
[epoch17, step917]: loss 0.025040
[epoch17, step918]: loss 0.028603
[epoch17, step919]: loss 0.024340
[epoch17, step920]: loss 0.027569
[epoch17, step921]: loss 0.024327
[epoch17, step922]: loss 0.023197
[epoch17, step923]: loss 0.022362
[epoch17, step924]: loss 0.021112
[epoch17, step925]: loss 0.025281
[epoch17, step926]: loss 0.026400
[epoch17, step927]: loss 0.025705
[epoch17, step928]: loss 0.024811
[epoch17, step929]: loss 0.027642
[epoch17, step930]: loss 0.025686
[epoch17, step931]: loss 0.027154
[epoch17, step932]: loss 0.021520
[epoch17, step933]: loss 0.028074
[epoch17, step934]: loss 0.021935
[epoch17, step935]: loss 0.021924
[epoch17, step936]: loss 0.022406
[epoch17, step937]: loss 0.027090
[epoch17, step938]: loss 0.025129
[epoch17, step939]: loss 0.020687
[epoch17, step940]: loss 0.022909
[epoch17, step941]: loss 0.026693
[epoch17, step942]: loss 0.025340
[epoch17, step943]: loss 0.023117
[epoch17, step944]: loss 0.027447
[epoch17, step945]: loss 0.020547
[epoch17, step946]: loss 0.025363
[epoch17, step947]: loss 0.027944
[epoch17, step948]: loss 0.019268
[epoch17, step949]: loss 0.022778
[epoch17, step950]: loss 0.026593
[epoch17, step951]: loss 0.028544
[epoch17, step952]: loss 0.025146
[epoch17, step953]: loss 0.027386
[epoch17, step954]: loss 0.022127
[epoch17, step955]: loss 0.037186
[epoch17, step956]: loss 0.052753
[epoch17, step957]: loss 0.046240
[epoch17, step958]: loss 0.043127
[epoch17, step959]: loss 0.045949
[epoch17, step960]: loss 0.041920
[epoch17, step961]: loss 0.042309
[epoch17, step962]: loss 0.040379
[epoch17, step963]: loss 0.038497
[epoch17, step964]: loss 0.038965
[epoch17, step965]: loss 0.039633
[epoch17, step966]: loss 0.037547
[epoch17, step967]: loss 0.036625
[epoch17, step968]: loss 0.039798
[epoch17, step969]: loss 0.039464
[epoch17, step970]: loss 0.038673
[epoch17, step971]: loss 0.036844
[epoch17, step972]: loss 0.038902
[epoch17, step973]: loss 0.037359
[epoch17, step974]: loss 0.039426
[epoch17, step975]: loss 0.036389
[epoch17, step976]: loss 0.036071
[epoch17, step977]: loss 0.039897
[epoch17, step978]: loss 0.037947
[epoch17, step979]: loss 0.037307
[epoch17, step980]: loss 0.035455
[epoch17, step981]: loss 0.037682
[epoch17, step982]: loss 0.038185
[epoch17, step983]: loss 0.038678
[epoch17, step984]: loss 0.035111
[epoch17, step985]: loss 0.035565
[epoch17, step986]: loss 0.039862
[epoch17, step987]: loss 0.037963
[epoch17, step988]: loss 0.037270
[epoch17, step989]: loss 0.035979
[epoch17, step990]: loss 0.037228
[epoch17, step991]: loss 0.038044
[epoch17, step992]: loss 0.037887
[epoch17, step993]: loss 0.035466
[epoch17, step994]: loss 0.034982
[epoch17, step995]: loss 0.038827
[epoch17, step996]: loss 0.036872
[epoch17, step997]: loss 0.036800
[epoch17, step998]: loss 0.036243
[epoch17, step999]: loss 0.037486
[epoch17, step1000]: loss 0.037355
[epoch17, step1001]: loss 0.038319
[epoch17, step1002]: loss 0.036043
[epoch17, step1003]: loss 0.035372
[epoch17, step1004]: loss 0.039235
[epoch17, step1005]: loss 0.036208
[epoch17, step1006]: loss 0.037179
[epoch17, step1007]: loss 0.035461
[epoch17, step1008]: loss 0.036489
[epoch17, step1009]: loss 0.037280
[epoch17, step1010]: loss 0.038448
[epoch17, step1011]: loss 0.035493
[epoch17, step1012]: loss 0.035496
[epoch17, step1013]: loss 0.038730
[epoch17, step1014]: loss 0.037432
[epoch17, step1015]: loss 0.036845
[epoch17, step1016]: loss 0.034868
[epoch17, step1017]: loss 0.036570
[epoch17, step1018]: loss 0.037147
[epoch17, step1019]: loss 0.037813
[epoch17, step1020]: loss 0.035288
[epoch17, step1021]: loss 0.034962
[epoch17, step1022]: loss 0.038292
[epoch17, step1023]: loss 0.037121
[epoch17, step1024]: loss 0.037376
[epoch17, step1025]: loss 0.034971
[epoch17, step1026]: loss 0.036565
[epoch17, step1027]: loss 0.036553
[epoch17, step1028]: loss 0.038057
[epoch17, step1029]: loss 0.035658
[epoch17, step1030]: loss 0.034323
[epoch17, step1031]: loss 0.037387
[epoch17, step1032]: loss 0.037148
[epoch17, step1033]: loss 0.036386
[epoch17, step1034]: loss 0.034828
[epoch17, step1035]: loss 0.036007
[epoch17, step1036]: loss 0.037061
[epoch17, step1037]: loss 0.037425
[epoch17, step1038]: loss 0.035122
[epoch17, step1039]: loss 0.035011
[epoch17, step1040]: loss 0.037573
[epoch17, step1041]: loss 0.036373
[epoch17, step1042]: loss 0.035512
[epoch17, step1043]: loss 0.034913
[epoch17, step1044]: loss 0.036701
[epoch17, step1045]: loss 0.036982
[epoch17, step1046]: loss 0.037780
[epoch17, step1047]: loss 0.035263
[epoch17, step1048]: loss 0.034744
[epoch17, step1049]: loss 0.038070
[epoch17, step1050]: loss 0.037433
[epoch17, step1051]: loss 0.036549
[epoch17, step1052]: loss 0.035401
[epoch17, step1053]: loss 0.037107
[epoch17, step1054]: loss 0.037049
[epoch17, step1055]: loss 0.037586
[epoch17, step1056]: loss 0.034832
[epoch17, step1057]: loss 0.035615
[epoch17, step1058]: loss 0.039420
[epoch17, step1059]: loss 0.036861
[epoch17, step1060]: loss 0.036685
[epoch17, step1061]: loss 0.034430
[epoch17, step1062]: loss 0.037079
[epoch17, step1063]: loss 0.036720
[epoch17, step1064]: loss 0.037591
[epoch17, step1065]: loss 0.035188
[epoch17, step1066]: loss 0.034762
[epoch17, step1067]: loss 0.038287
[epoch17, step1068]: loss 0.035610
[epoch17, step1069]: loss 0.035909
[epoch17, step1070]: loss 0.034986
[epoch17, step1071]: loss 0.037204
[epoch17, step1072]: loss 0.037546
[epoch17, step1073]: loss 0.037852
[epoch17, step1074]: loss 0.035486
[epoch17, step1075]: loss 0.035280
[epoch17, step1076]: loss 0.038456
[epoch17, step1077]: loss 0.036605
[epoch17, step1078]: loss 0.036543
[epoch17, step1079]: loss 0.035959
[epoch17, step1080]: loss 0.036799
[epoch17, step1081]: loss 0.036847
[epoch17, step1082]: loss 0.037204
[epoch17, step1083]: loss 0.035955
[epoch17, step1084]: loss 0.035028
[epoch17, step1085]: loss 0.037700
[epoch17, step1086]: loss 0.036280
[epoch17, step1087]: loss 0.036360
[epoch17, step1088]: loss 0.034676
[epoch17, step1089]: loss 0.036937
[epoch17, step1090]: loss 0.037234
[epoch17, step1091]: loss 0.037791
[epoch17, step1092]: loss 0.034924
[epoch17, step1093]: loss 0.035184
[epoch17, step1094]: loss 0.037438
[epoch17, step1095]: loss 0.036251
[epoch17, step1096]: loss 0.036106
[epoch17, step1097]: loss 0.034909
[epoch17, step1098]: loss 0.036670
[epoch17, step1099]: loss 0.036360
[epoch17, step1100]: loss 0.038218
[epoch17, step1101]: loss 0.035642
[epoch17, step1102]: loss 0.034935
[epoch17, step1103]: loss 0.037708
[epoch17, step1104]: loss 0.036250
[epoch17, step1105]: loss 0.036807
[epoch17, step1106]: loss 0.034091
[epoch17, step1107]: loss 0.036612
[epoch17, step1108]: loss 0.036433
[epoch17, step1109]: loss 0.038073
[epoch17, step1110]: loss 0.035754
[epoch17, step1111]: loss 0.035035
[epoch17, step1112]: loss 0.038548
[epoch17, step1113]: loss 0.036291
[epoch17, step1114]: loss 0.036803
[epoch17, step1115]: loss 0.035172
[epoch17, step1116]: loss 0.036716
[epoch17, step1117]: loss 0.036789
[epoch17, step1118]: loss 0.037592
[epoch17, step1119]: loss 0.035031
[epoch17, step1120]: loss 0.034812
[epoch17, step1121]: loss 0.037978
[epoch17, step1122]: loss 0.036075
[epoch17, step1123]: loss 0.035764
[epoch17, step1124]: loss 0.035389
[epoch17, step1125]: loss 0.036995
[epoch17, step1126]: loss 0.037672
[epoch17, step1127]: loss 0.037620
[epoch17, step1128]: loss 0.035274
[epoch17, step1129]: loss 0.034793
[epoch17, step1130]: loss 0.039034
[epoch17, step1131]: loss 0.036788
[epoch17, step1132]: loss 0.036878
[epoch17, step1133]: loss 0.034401
[epoch17, step1134]: loss 0.036297
[epoch17, step1135]: loss 0.037555
[epoch17, step1136]: loss 0.038535
[epoch17, step1137]: loss 0.035384
[epoch17, step1138]: loss 0.035231
[epoch17, step1139]: loss 0.038229
[epoch17, step1140]: loss 0.035996
[epoch17, step1141]: loss 0.036345
[epoch17, step1142]: loss 0.034784
[epoch17, step1143]: loss 0.035922
[epoch17, step1144]: loss 0.037095
[epoch17, step1145]: loss 0.036932
[epoch17, step1146]: loss 0.034939
[epoch17, step1147]: loss 0.035414
[epoch17, step1148]: loss 0.038091
[epoch17, step1149]: loss 0.036073
[epoch17, step1150]: loss 0.035964
[epoch17, step1151]: loss 0.035245
[epoch17, step1152]: loss 0.037045
[epoch17, step1153]: loss 0.035981
[epoch17, step1154]: loss 0.037832
[epoch17, step1155]: loss 0.035271
[epoch17, step1156]: loss 0.034353
[epoch17, step1157]: loss 0.037624
[epoch17, step1158]: loss 0.036721
[epoch17, step1159]: loss 0.036308
[epoch17, step1160]: loss 0.035792
[epoch17, step1161]: loss 0.037193
[epoch17, step1162]: loss 0.036560
[epoch17, step1163]: loss 0.037299
[epoch17, step1164]: loss 0.035665
[epoch17, step1165]: loss 0.035699
[epoch17, step1166]: loss 0.038248
[epoch17, step1167]: loss 0.035756
[epoch17, step1168]: loss 0.036239
[epoch17, step1169]: loss 0.034639
[epoch17, step1170]: loss 0.036417
[epoch17, step1171]: loss 0.036903
[epoch17, step1172]: loss 0.037313
[epoch17, step1173]: loss 0.035151
[epoch17, step1174]: loss 0.034947
[epoch17, step1175]: loss 0.037703
[epoch17, step1176]: loss 0.035883
[epoch17, step1177]: loss 0.036359
[epoch17, step1178]: loss 0.034943
[epoch17, step1179]: loss 0.036746
[epoch17, step1180]: loss 0.036820
[epoch17, step1181]: loss 0.038163
[epoch17, step1182]: loss 0.034538
[epoch17, step1183]: loss 0.035434
[epoch17, step1184]: loss 0.037361
[epoch17, step1185]: loss 0.036584
[epoch17, step1186]: loss 0.035509
[epoch17, step1187]: loss 0.034165
[epoch17, step1188]: loss 0.036098
[epoch17, step1189]: loss 0.036335
[epoch17, step1190]: loss 0.037465
[epoch17, step1191]: loss 0.035987
[epoch17, step1192]: loss 0.034870
[epoch17, step1193]: loss 0.038045
[epoch17, step1194]: loss 0.036170
[epoch17, step1195]: loss 0.035345
[epoch17, step1196]: loss 0.034172
[epoch17, step1197]: loss 0.036722
[epoch17, step1198]: loss 0.036766
[epoch17, step1199]: loss 0.036991
[epoch17, step1200]: loss 0.034823
[epoch17, step1201]: loss 0.035248
[epoch17, step1202]: loss 0.038676
[epoch17, step1203]: loss 0.036378
[epoch17, step1204]: loss 0.035470
[epoch17, step1205]: loss 0.034371
[epoch17, step1206]: loss 0.035912
[epoch17, step1207]: loss 0.036845
[epoch17, step1208]: loss 0.038074
[epoch17, step1209]: loss 0.033835
[epoch17, step1210]: loss 0.035497
[epoch17, step1211]: loss 0.037792
[epoch17, step1212]: loss 0.036313
[epoch17, step1213]: loss 0.035855
[epoch17, step1214]: loss 0.034831
[epoch17, step1215]: loss 0.037183
[epoch17, step1216]: loss 0.036180
[epoch17, step1217]: loss 0.038108
[epoch17, step1218]: loss 0.034662
[epoch17, step1219]: loss 0.035496
[epoch17, step1220]: loss 0.038399
[epoch17, step1221]: loss 0.035469
[epoch17, step1222]: loss 0.036515
[epoch17, step1223]: loss 0.034962
[epoch17, step1224]: loss 0.037047
[epoch17, step1225]: loss 0.036718
[epoch17, step1226]: loss 0.037006
[epoch17, step1227]: loss 0.034913
[epoch17, step1228]: loss 0.034731
[epoch17, step1229]: loss 0.037559
[epoch17, step1230]: loss 0.036423
[epoch17, step1231]: loss 0.036144
[epoch17, step1232]: loss 0.035583
[epoch17, step1233]: loss 0.036171
[epoch17, step1234]: loss 0.036242
[epoch17, step1235]: loss 0.037909
[epoch17, step1236]: loss 0.035110
[epoch17, step1237]: loss 0.034525
[epoch17, step1238]: loss 0.037066
[epoch17, step1239]: loss 0.037196
[epoch17, step1240]: loss 0.036502
[epoch17, step1241]: loss 0.034183
[epoch17, step1242]: loss 0.036276
[epoch17, step1243]: loss 0.036328
[epoch17, step1244]: loss 0.038017
[epoch17, step1245]: loss 0.035436
[epoch17, step1246]: loss 0.035088
[epoch17, step1247]: loss 0.037148
[epoch17, step1248]: loss 0.036377
[epoch17, step1249]: loss 0.036721
[epoch17, step1250]: loss 0.034719
[epoch17, step1251]: loss 0.036830
[epoch17, step1252]: loss 0.037406
[epoch17, step1253]: loss 0.037760
[epoch17, step1254]: loss 0.035122
[epoch17, step1255]: loss 0.034970
[epoch17, step1256]: loss 0.038279
[epoch17, step1257]: loss 0.036498
[epoch17, step1258]: loss 0.036496
[epoch17, step1259]: loss 0.034689
[epoch17, step1260]: loss 0.036600
[epoch17, step1261]: loss 0.036306
[epoch17, step1262]: loss 0.036693
[epoch17, step1263]: loss 0.035807
[epoch17, step1264]: loss 0.034707
[epoch17, step1265]: loss 0.036857
[epoch17, step1266]: loss 0.036323
[epoch17, step1267]: loss 0.036694
[epoch17, step1268]: loss 0.034863
[epoch17, step1269]: loss 0.036528
[epoch17, step1270]: loss 0.035917
[epoch17, step1271]: loss 0.037718
[epoch17, step1272]: loss 0.035247
[epoch17, step1273]: loss 0.034448
[epoch17, step1274]: loss 0.037913
[epoch17, step1275]: loss 0.036692
[epoch17, step1276]: loss 0.036057
[epoch17, step1277]: loss 0.034885
[epoch17, step1278]: loss 0.037047
[epoch17, step1279]: loss 0.036738
[epoch17, step1280]: loss 0.037971
[epoch17, step1281]: loss 0.034959
[epoch17, step1282]: loss 0.035241
[epoch17, step1283]: loss 0.037271
[epoch17, step1284]: loss 0.035852
[epoch17, step1285]: loss 0.036772
[epoch17, step1286]: loss 0.034290
[epoch17, step1287]: loss 0.037209
[epoch17, step1288]: loss 0.037048
[epoch17, step1289]: loss 0.038390
[epoch17, step1290]: loss 0.035146
[epoch17, step1291]: loss 0.034447
[epoch17, step1292]: loss 0.038561
[epoch17, step1293]: loss 0.035442
[epoch17, step1294]: loss 0.036292
[epoch17, step1295]: loss 0.035254
[epoch17, step1296]: loss 0.036697
[epoch17, step1297]: loss 0.036580
[epoch17, step1298]: loss 0.038161
[epoch17, step1299]: loss 0.035358
[epoch17, step1300]: loss 0.035672
[epoch17, step1301]: loss 0.037149
[epoch17, step1302]: loss 0.036471
[epoch17, step1303]: loss 0.036460
[epoch17, step1304]: loss 0.034341
[epoch17, step1305]: loss 0.036849
[epoch17, step1306]: loss 0.036352
[epoch17, step1307]: loss 0.036925
[epoch17, step1308]: loss 0.035316
[epoch17, step1309]: loss 0.034238
[epoch17, step1310]: loss 0.037767
[epoch17, step1311]: loss 0.035281
[epoch17, step1312]: loss 0.036982
[epoch17, step1313]: loss 0.034710
[epoch17, step1314]: loss 0.036306
[epoch17, step1315]: loss 0.036125
[epoch17, step1316]: loss 0.038887
[epoch17, step1317]: loss 0.034636
[epoch17, step1318]: loss 0.034165
[epoch17, step1319]: loss 0.037292
[epoch17, step1320]: loss 0.036250
[epoch17, step1321]: loss 0.036584
[epoch17, step1322]: loss 0.034597
[epoch17, step1323]: loss 0.036629
[epoch17, step1324]: loss 0.036242
[epoch17, step1325]: loss 0.037064
[epoch17, step1326]: loss 0.034887
[epoch17, step1327]: loss 0.034435
[epoch17, step1328]: loss 0.037785
[epoch17, step1329]: loss 0.036062
[epoch17, step1330]: loss 0.036179
[epoch17, step1331]: loss 0.034441
[epoch17, step1332]: loss 0.036317
[epoch17, step1333]: loss 0.035534
[epoch17, step1334]: loss 0.038054
[epoch17, step1335]: loss 0.035836
[epoch17, step1336]: loss 0.034866
[epoch17, step1337]: loss 0.037499
[epoch17, step1338]: loss 0.036315
[epoch17, step1339]: loss 0.036376
[epoch17, step1340]: loss 0.034556
[epoch17, step1341]: loss 0.036725
[epoch17, step1342]: loss 0.036468
[epoch17, step1343]: loss 0.037485
[epoch17, step1344]: loss 0.035303
[epoch17, step1345]: loss 0.034569
[epoch17, step1346]: loss 0.037240
[epoch17, step1347]: loss 0.036684
[epoch17, step1348]: loss 0.035495
[epoch17, step1349]: loss 0.034771
[epoch17, step1350]: loss 0.036810
[epoch17, step1351]: loss 0.036026
[epoch17, step1352]: loss 0.037259
[epoch17, step1353]: loss 0.034516
[epoch17, step1354]: loss 0.034722
[epoch17, step1355]: loss 0.037956
[epoch17, step1356]: loss 0.036067
[epoch17, step1357]: loss 0.035883
[epoch17, step1358]: loss 0.034530
[epoch17, step1359]: loss 0.035970
[epoch17, step1360]: loss 0.036817
[epoch17, step1361]: loss 0.037967
[epoch17, step1362]: loss 0.035597
[epoch17, step1363]: loss 0.035414
[epoch17, step1364]: loss 0.038170
[epoch17, step1365]: loss 0.036200
[epoch17, step1366]: loss 0.036282
[epoch17, step1367]: loss 0.034294
[epoch17, step1368]: loss 0.037133
[epoch17, step1369]: loss 0.036765
[epoch17, step1370]: loss 0.037112
[epoch17, step1371]: loss 0.035212
[epoch17, step1372]: loss 0.034419
[epoch17, step1373]: loss 0.037547
[epoch17, step1374]: loss 0.036813
[epoch17, step1375]: loss 0.036756
[epoch17, step1376]: loss 0.034534
[epoch17, step1377]: loss 0.035769
[epoch17, step1378]: loss 0.036420
[epoch17, step1379]: loss 0.037007
[epoch17, step1380]: loss 0.035206
[epoch17, step1381]: loss 0.034605
[epoch17, step1382]: loss 0.037866
[epoch17, step1383]: loss 0.036025
[epoch17, step1384]: loss 0.035972
[epoch17, step1385]: loss 0.034338
[epoch17, step1386]: loss 0.036826
[epoch17, step1387]: loss 0.036834
[epoch17, step1388]: loss 0.036714
[epoch17, step1389]: loss 0.034688
[epoch17, step1390]: loss 0.034949
[epoch17, step1391]: loss 0.037574
[epoch17, step1392]: loss 0.036157
[epoch17, step1393]: loss 0.036299
[epoch17, step1394]: loss 0.035394
[epoch17, step1395]: loss 0.036466
[epoch17, step1396]: loss 0.036303
[epoch17, step1397]: loss 0.037398
[epoch17, step1398]: loss 0.034687
[epoch17, step1399]: loss 0.035557
[epoch17, step1400]: loss 0.038230
[epoch17, step1401]: loss 0.035862
[epoch17, step1402]: loss 0.036297
[epoch17, step1403]: loss 0.033734
[epoch17, step1404]: loss 0.036045
[epoch17, step1405]: loss 0.036180
[epoch17, step1406]: loss 0.037326
[epoch17, step1407]: loss 0.035905
[epoch17, step1408]: loss 0.034442
[epoch17, step1409]: loss 0.037694
[epoch17, step1410]: loss 0.036140
[epoch17, step1411]: loss 0.035287
[epoch17, step1412]: loss 0.034890
[epoch17, step1413]: loss 0.036330
[epoch17, step1414]: loss 0.036377
[epoch17, step1415]: loss 0.036854
[epoch17, step1416]: loss 0.034941
[epoch17, step1417]: loss 0.034642
[epoch17, step1418]: loss 0.037409
[epoch17, step1419]: loss 0.036722
[epoch17, step1420]: loss 0.036196
[epoch17, step1421]: loss 0.035082
[epoch17, step1422]: loss 0.036338
[epoch17, step1423]: loss 0.035972
[epoch17, step1424]: loss 0.037301
[epoch17, step1425]: loss 0.034086
[epoch17, step1426]: loss 0.034769
[epoch17, step1427]: loss 0.038344
[epoch17, step1428]: loss 0.037084
[epoch17, step1429]: loss 0.035960
[epoch17, step1430]: loss 0.034855
[epoch17, step1431]: loss 0.036892
[epoch17, step1432]: loss 0.036217
[epoch17, step1433]: loss 0.037994
[epoch17, step1434]: loss 0.035554
[epoch17, step1435]: loss 0.035374
[epoch17, step1436]: loss 0.037868
[epoch17, step1437]: loss 0.036666
[epoch17, step1438]: loss 0.036846
[epoch17, step1439]: loss 0.034478
[epoch17, step1440]: loss 0.036279
[epoch17, step1441]: loss 0.036941
[epoch17, step1442]: loss 0.036374
[epoch17, step1443]: loss 0.034806
[epoch17, step1444]: loss 0.033875
[epoch17, step1445]: loss 0.037872
[epoch17, step1446]: loss 0.036644
[epoch17, step1447]: loss 0.036541
[epoch17, step1448]: loss 0.034918
[epoch17, step1449]: loss 0.036565
[epoch17, step1450]: loss 0.036753
[epoch17, step1451]: loss 0.037576
[epoch17, step1452]: loss 0.034887
[epoch17, step1453]: loss 0.035616
[epoch17, step1454]: loss 0.038112
[epoch17, step1455]: loss 0.036742
[epoch17, step1456]: loss 0.035630
[epoch17, step1457]: loss 0.034997
[epoch17, step1458]: loss 0.036281
[epoch17, step1459]: loss 0.036359
[epoch17, step1460]: loss 0.037641
[epoch17, step1461]: loss 0.035488
[epoch17, step1462]: loss 0.035216
[epoch17, step1463]: loss 0.037567
[epoch17, step1464]: loss 0.036463
[epoch17, step1465]: loss 0.035538
[epoch17, step1466]: loss 0.034316
[epoch17, step1467]: loss 0.036470
[epoch17, step1468]: loss 0.035906
[epoch17, step1469]: loss 0.037638
[epoch17, step1470]: loss 0.035545
[epoch17, step1471]: loss 0.034306
[epoch17, step1472]: loss 0.037649
[epoch17, step1473]: loss 0.036388
[epoch17, step1474]: loss 0.036452
[epoch17, step1475]: loss 0.034313
[epoch17, step1476]: loss 0.037106
[epoch17, step1477]: loss 0.036034
[epoch17, step1478]: loss 0.037139
[epoch17, step1479]: loss 0.034852
[epoch17, step1480]: loss 0.034510
[epoch17, step1481]: loss 0.036626
[epoch17, step1482]: loss 0.035890
[epoch17, step1483]: loss 0.036048
[epoch17, step1484]: loss 0.034830
[epoch17, step1485]: loss 0.036261
[epoch17, step1486]: loss 0.035395
[epoch17, step1487]: loss 0.037091
[epoch17, step1488]: loss 0.034681
[epoch17, step1489]: loss 0.034563
[epoch17, step1490]: loss 0.037624
[epoch17, step1491]: loss 0.036444
[epoch17, step1492]: loss 0.036145
[epoch17, step1493]: loss 0.034690
[epoch17, step1494]: loss 0.036674
[epoch17, step1495]: loss 0.036095
[epoch17, step1496]: loss 0.036483
[epoch17, step1497]: loss 0.035232
[epoch17, step1498]: loss 0.034947
[epoch17, step1499]: loss 0.037059
[epoch17, step1500]: loss 0.036338
[epoch17, step1501]: loss 0.036063
[epoch17, step1502]: loss 0.034188
[epoch17, step1503]: loss 0.036097
[epoch17, step1504]: loss 0.035774
[epoch17, step1505]: loss 0.037597
[epoch17, step1506]: loss 0.034325
[epoch17, step1507]: loss 0.035095
[epoch17, step1508]: loss 0.038222
[epoch17, step1509]: loss 0.035722
[epoch17, step1510]: loss 0.035744
[epoch17, step1511]: loss 0.035108
[epoch17, step1512]: loss 0.036635
[epoch17, step1513]: loss 0.034944
[epoch17, step1514]: loss 0.037188
[epoch17, step1515]: loss 0.035142
[epoch17, step1516]: loss 0.034766

[epoch17]: avg loss 0.033247

[epoch18, step1]: loss 0.030819
[epoch18, step2]: loss 0.037123
[epoch18, step3]: loss 0.037028
[epoch18, step4]: loss 0.034748
[epoch18, step5]: loss 0.035107
[epoch18, step6]: loss 0.037567
[epoch18, step7]: loss 0.035693
[epoch18, step8]: loss 0.037468
[epoch18, step9]: loss 0.034166
[epoch18, step10]: loss 0.036077
[epoch18, step11]: loss 0.037525
[epoch18, step12]: loss 0.037542
[epoch18, step13]: loss 0.035200
[epoch18, step14]: loss 0.035005
[epoch18, step15]: loss 0.037426
[epoch18, step16]: loss 0.035418
[epoch18, step17]: loss 0.037942
[epoch18, step18]: loss 0.035061
[epoch18, step19]: loss 0.035577
[epoch18, step20]: loss 0.038166
[epoch18, step21]: loss 0.037282
[epoch18, step22]: loss 0.034723
[epoch18, step23]: loss 0.033988
[epoch18, step24]: loss 0.037559
[epoch18, step25]: loss 0.034589
[epoch18, step26]: loss 0.037082
[epoch18, step27]: loss 0.034110
[epoch18, step28]: loss 0.035292
[epoch18, step29]: loss 0.037512
[epoch18, step30]: loss 0.037729
[epoch18, step31]: loss 0.034311
[epoch18, step32]: loss 0.035322
[epoch18, step33]: loss 0.038010
[epoch18, step34]: loss 0.035817
[epoch18, step35]: loss 0.037816
[epoch18, step36]: loss 0.034575
[epoch18, step37]: loss 0.035398
[epoch18, step38]: loss 0.037351
[epoch18, step39]: loss 0.037480
[epoch18, step40]: loss 0.035254
[epoch18, step41]: loss 0.034173
[epoch18, step42]: loss 0.037806
[epoch18, step43]: loss 0.034919
[epoch18, step44]: loss 0.038189
[epoch18, step45]: loss 0.034555
[epoch18, step46]: loss 0.035451
[epoch18, step47]: loss 0.037036
[epoch18, step48]: loss 0.036919
[epoch18, step49]: loss 0.033246
[epoch18, step50]: loss 0.034857
[epoch18, step51]: loss 0.037370
[epoch18, step52]: loss 0.035028
[epoch18, step53]: loss 0.037981
[epoch18, step54]: loss 0.034111
[epoch18, step55]: loss 0.035782
[epoch18, step56]: loss 0.038267
[epoch18, step57]: loss 0.037573
[epoch18, step58]: loss 0.034902
[epoch18, step59]: loss 0.033537
[epoch18, step60]: loss 0.038330
[epoch18, step61]: loss 0.034538
[epoch18, step62]: loss 0.036888
[epoch18, step63]: loss 0.034005
[epoch18, step64]: loss 0.035057
[epoch18, step65]: loss 0.037700
[epoch18, step66]: loss 0.037102
[epoch18, step67]: loss 0.034907
[epoch18, step68]: loss 0.034765
[epoch18, step69]: loss 0.037382
[epoch18, step70]: loss 0.034802
[epoch18, step71]: loss 0.037217
[epoch18, step72]: loss 0.034465
[epoch18, step73]: loss 0.035303
[epoch18, step74]: loss 0.037315
[epoch18, step75]: loss 0.037397
[epoch18, step76]: loss 0.035184
[epoch18, step77]: loss 0.035274
[epoch18, step78]: loss 0.037647
[epoch18, step79]: loss 0.034634
[epoch18, step80]: loss 0.038203
[epoch18, step81]: loss 0.034369
[epoch18, step82]: loss 0.034819
[epoch18, step83]: loss 0.037241
[epoch18, step84]: loss 0.037337
[epoch18, step85]: loss 0.035464
[epoch18, step86]: loss 0.035326
[epoch18, step87]: loss 0.038404
[epoch18, step88]: loss 0.034102
[epoch18, step89]: loss 0.037655
[epoch18, step90]: loss 0.034853
[epoch18, step91]: loss 0.034965
[epoch18, step92]: loss 0.037503
[epoch18, step93]: loss 0.037450
[epoch18, step94]: loss 0.034605
[epoch18, step95]: loss 0.035220
[epoch18, step96]: loss 0.037133
[epoch18, step97]: loss 0.035847
[epoch18, step98]: loss 0.037456
[epoch18, step99]: loss 0.034471
[epoch18, step100]: loss 0.034284
[epoch18, step101]: loss 0.038002
[epoch18, step102]: loss 0.037452
[epoch18, step103]: loss 0.035129
[epoch18, step104]: loss 0.034540
[epoch18, step105]: loss 0.037993
[epoch18, step106]: loss 0.035099
[epoch18, step107]: loss 0.037664
[epoch18, step108]: loss 0.034748
[epoch18, step109]: loss 0.034797
[epoch18, step110]: loss 0.037862
[epoch18, step111]: loss 0.036924
[epoch18, step112]: loss 0.034794
[epoch18, step113]: loss 0.035482
[epoch18, step114]: loss 0.037339
[epoch18, step115]: loss 0.035134
[epoch18, step116]: loss 0.037959
[epoch18, step117]: loss 0.034454
[epoch18, step118]: loss 0.036253
[epoch18, step119]: loss 0.037629
[epoch18, step120]: loss 0.037618
[epoch18, step121]: loss 0.034942
[epoch18, step122]: loss 0.034468
[epoch18, step123]: loss 0.038061
[epoch18, step124]: loss 0.035269
[epoch18, step125]: loss 0.037816
[epoch18, step126]: loss 0.034543
[epoch18, step127]: loss 0.034894
[epoch18, step128]: loss 0.037355
[epoch18, step129]: loss 0.036928
[epoch18, step130]: loss 0.034782
[epoch18, step131]: loss 0.034300
[epoch18, step132]: loss 0.037273
[epoch18, step133]: loss 0.035143
[epoch18, step134]: loss 0.036680
[epoch18, step135]: loss 0.035138
[epoch18, step136]: loss 0.036363
[epoch18, step137]: loss 0.037123
[epoch18, step138]: loss 0.037354
[epoch18, step139]: loss 0.034872
[epoch18, step140]: loss 0.035062
[epoch18, step141]: loss 0.037909
[epoch18, step142]: loss 0.035043
[epoch18, step143]: loss 0.037077
[epoch18, step144]: loss 0.034792
[epoch18, step145]: loss 0.035320
[epoch18, step146]: loss 0.037590
[epoch18, step147]: loss 0.038611
[epoch18, step148]: loss 0.034663
[epoch18, step149]: loss 0.034046
[epoch18, step150]: loss 0.037384
[epoch18, step151]: loss 0.035097
[epoch18, step152]: loss 0.037588
[epoch18, step153]: loss 0.034642
[epoch18, step154]: loss 0.034990
[epoch18, step155]: loss 0.037761
[epoch18, step156]: loss 0.036545
[epoch18, step157]: loss 0.034954
[epoch18, step158]: loss 0.034859
[epoch18, step159]: loss 0.037578
[epoch18, step160]: loss 0.035229
[epoch18, step161]: loss 0.037854
[epoch18, step162]: loss 0.034823
[epoch18, step163]: loss 0.034993
[epoch18, step164]: loss 0.037834
[epoch18, step165]: loss 0.037195
[epoch18, step166]: loss 0.035066
[epoch18, step167]: loss 0.034419
[epoch18, step168]: loss 0.037985
[epoch18, step169]: loss 0.034977
[epoch18, step170]: loss 0.037633
[epoch18, step171]: loss 0.035029
[epoch18, step172]: loss 0.035402
[epoch18, step173]: loss 0.037544
[epoch18, step174]: loss 0.037212
[epoch18, step175]: loss 0.035575
[epoch18, step176]: loss 0.035124
[epoch18, step177]: loss 0.038115
[epoch18, step178]: loss 0.035072
[epoch18, step179]: loss 0.036898
[epoch18, step180]: loss 0.035078
[epoch18, step181]: loss 0.035015
[epoch18, step182]: loss 0.037786
[epoch18, step183]: loss 0.037695
[epoch18, step184]: loss 0.035821
[epoch18, step185]: loss 0.034915
[epoch18, step186]: loss 0.037424
[epoch18, step187]: loss 0.034964
[epoch18, step188]: loss 0.036984
[epoch18, step189]: loss 0.034531
[epoch18, step190]: loss 0.034462
[epoch18, step191]: loss 0.037335
[epoch18, step192]: loss 0.037846
[epoch18, step193]: loss 0.032965
[epoch18, step194]: loss 0.033828
[epoch18, step195]: loss 0.037491
[epoch18, step196]: loss 0.035263
[epoch18, step197]: loss 0.037342
[epoch18, step198]: loss 0.033782
[epoch18, step199]: loss 0.035122
[epoch18, step200]: loss 0.037845
[epoch18, step201]: loss 0.037783
[epoch18, step202]: loss 0.034443
[epoch18, step203]: loss 0.034924
[epoch18, step204]: loss 0.037957
[epoch18, step205]: loss 0.034377
[epoch18, step206]: loss 0.037430
[epoch18, step207]: loss 0.034393
[epoch18, step208]: loss 0.035497
[epoch18, step209]: loss 0.038094
[epoch18, step210]: loss 0.038070
[epoch18, step211]: loss 0.035362
[epoch18, step212]: loss 0.035127
[epoch18, step213]: loss 0.037083
[epoch18, step214]: loss 0.034523
[epoch18, step215]: loss 0.037490
[epoch18, step216]: loss 0.034727
[epoch18, step217]: loss 0.034411
[epoch18, step218]: loss 0.037549
[epoch18, step219]: loss 0.036955
[epoch18, step220]: loss 0.035004
[epoch18, step221]: loss 0.034947
[epoch18, step222]: loss 0.037838
[epoch18, step223]: loss 0.035200
[epoch18, step224]: loss 0.037141
[epoch18, step225]: loss 0.034490
[epoch18, step226]: loss 0.034731
[epoch18, step227]: loss 0.036579
[epoch18, step228]: loss 0.037858
[epoch18, step229]: loss 0.033881
[epoch18, step230]: loss 0.035014
[epoch18, step231]: loss 0.038082
[epoch18, step232]: loss 0.035016
[epoch18, step233]: loss 0.036773
[epoch18, step234]: loss 0.034093
[epoch18, step235]: loss 0.035612
[epoch18, step236]: loss 0.037373
[epoch18, step237]: loss 0.037403
[epoch18, step238]: loss 0.034708
[epoch18, step239]: loss 0.033905
[epoch18, step240]: loss 0.036829
[epoch18, step241]: loss 0.035336
[epoch18, step242]: loss 0.037411
[epoch18, step243]: loss 0.035221
[epoch18, step244]: loss 0.035106
[epoch18, step245]: loss 0.037045
[epoch18, step246]: loss 0.037254
[epoch18, step247]: loss 0.035368
[epoch18, step248]: loss 0.034037
[epoch18, step249]: loss 0.036994
[epoch18, step250]: loss 0.035216
[epoch18, step251]: loss 0.037881
[epoch18, step252]: loss 0.035203
[epoch18, step253]: loss 0.034346
[epoch18, step254]: loss 0.037170
[epoch18, step255]: loss 0.037571
[epoch18, step256]: loss 0.034678
[epoch18, step257]: loss 0.034390
[epoch18, step258]: loss 0.037861
[epoch18, step259]: loss 0.035214
[epoch18, step260]: loss 0.036740
[epoch18, step261]: loss 0.035451
[epoch18, step262]: loss 0.035353
[epoch18, step263]: loss 0.037018
[epoch18, step264]: loss 0.036875
[epoch18, step265]: loss 0.034977
[epoch18, step266]: loss 0.034622
[epoch18, step267]: loss 0.037109
[epoch18, step268]: loss 0.035070
[epoch18, step269]: loss 0.037294
[epoch18, step270]: loss 0.034128
[epoch18, step271]: loss 0.035118
[epoch18, step272]: loss 0.037085
[epoch18, step273]: loss 0.036896
[epoch18, step274]: loss 0.035195
[epoch18, step275]: loss 0.034136
[epoch18, step276]: loss 0.037238
[epoch18, step277]: loss 0.035434
[epoch18, step278]: loss 0.037325
[epoch18, step279]: loss 0.034247
[epoch18, step280]: loss 0.035182
[epoch18, step281]: loss 0.037207
[epoch18, step282]: loss 0.037721
[epoch18, step283]: loss 0.034628
[epoch18, step284]: loss 0.034192
[epoch18, step285]: loss 0.038203
[epoch18, step286]: loss 0.034248
[epoch18, step287]: loss 0.037619
[epoch18, step288]: loss 0.034116
[epoch18, step289]: loss 0.035713
[epoch18, step290]: loss 0.037536
[epoch18, step291]: loss 0.037436
[epoch18, step292]: loss 0.033869
[epoch18, step293]: loss 0.034365
[epoch18, step294]: loss 0.036446
[epoch18, step295]: loss 0.034467
[epoch18, step296]: loss 0.037935
[epoch18, step297]: loss 0.034333
[epoch18, step298]: loss 0.035316
[epoch18, step299]: loss 0.036510
[epoch18, step300]: loss 0.037563
[epoch18, step301]: loss 0.034806
[epoch18, step302]: loss 0.035265
[epoch18, step303]: loss 0.038171
[epoch18, step304]: loss 0.034552
[epoch18, step305]: loss 0.037068
[epoch18, step306]: loss 0.034687
[epoch18, step307]: loss 0.034549
[epoch18, step308]: loss 0.037978
[epoch18, step309]: loss 0.037470
[epoch18, step310]: loss 0.034938
[epoch18, step311]: loss 0.034987
[epoch18, step312]: loss 0.037416
[epoch18, step313]: loss 0.034868
[epoch18, step314]: loss 0.037335
[epoch18, step315]: loss 0.035403
[epoch18, step316]: loss 0.034686
[epoch18, step317]: loss 0.037965
[epoch18, step318]: loss 0.037540
[epoch18, step319]: loss 0.034334
[epoch18, step320]: loss 0.033681
[epoch18, step321]: loss 0.037049
[epoch18, step322]: loss 0.034730
[epoch18, step323]: loss 0.036899
[epoch18, step324]: loss 0.035452
[epoch18, step325]: loss 0.035053
[epoch18, step326]: loss 0.037099
[epoch18, step327]: loss 0.036458
[epoch18, step328]: loss 0.034837
[epoch18, step329]: loss 0.034607
[epoch18, step330]: loss 0.036828
[epoch18, step331]: loss 0.035210
[epoch18, step332]: loss 0.036578
[epoch18, step333]: loss 0.034529
[epoch18, step334]: loss 0.035341
[epoch18, step335]: loss 0.037374
[epoch18, step336]: loss 0.038285
[epoch18, step337]: loss 0.035494
[epoch18, step338]: loss 0.034236
[epoch18, step339]: loss 0.037484
[epoch18, step340]: loss 0.035624
[epoch18, step341]: loss 0.036868
[epoch18, step342]: loss 0.034134
[epoch18, step343]: loss 0.035299
[epoch18, step344]: loss 0.036879
[epoch18, step345]: loss 0.036574
[epoch18, step346]: loss 0.034240
[epoch18, step347]: loss 0.034480
[epoch18, step348]: loss 0.037458
[epoch18, step349]: loss 0.035368
[epoch18, step350]: loss 0.036528
[epoch18, step351]: loss 0.034024
[epoch18, step352]: loss 0.034779
[epoch18, step353]: loss 0.037201
[epoch18, step354]: loss 0.036301
[epoch18, step355]: loss 0.033775
[epoch18, step356]: loss 0.035321
[epoch18, step357]: loss 0.037783
[epoch18, step358]: loss 0.033477
[epoch18, step359]: loss 0.038637
[epoch18, step360]: loss 0.033501
[epoch18, step361]: loss 0.034518
[epoch18, step362]: loss 0.038383
[epoch18, step363]: loss 0.036697
[epoch18, step364]: loss 0.034583
[epoch18, step365]: loss 0.034223
[epoch18, step366]: loss 0.037480
[epoch18, step367]: loss 0.035025
[epoch18, step368]: loss 0.036465
[epoch18, step369]: loss 0.034122
[epoch18, step370]: loss 0.035389
[epoch18, step371]: loss 0.038040
[epoch18, step372]: loss 0.036722
[epoch18, step373]: loss 0.034089
[epoch18, step374]: loss 0.034204
[epoch18, step375]: loss 0.038283
[epoch18, step376]: loss 0.035149
[epoch18, step377]: loss 0.037633
[epoch18, step378]: loss 0.034719
[epoch18, step379]: loss 0.035630
[epoch18, step380]: loss 0.038170
[epoch18, step381]: loss 0.036698
[epoch18, step382]: loss 0.034700
[epoch18, step383]: loss 0.033502
[epoch18, step384]: loss 0.036637
[epoch18, step385]: loss 0.034523
[epoch18, step386]: loss 0.037457
[epoch18, step387]: loss 0.034420
[epoch18, step388]: loss 0.035583
[epoch18, step389]: loss 0.037238
[epoch18, step390]: loss 0.038209
[epoch18, step391]: loss 0.034177
[epoch18, step392]: loss 0.035125
[epoch18, step393]: loss 0.037272
[epoch18, step394]: loss 0.034906
[epoch18, step395]: loss 0.037019
[epoch18, step396]: loss 0.034411
[epoch18, step397]: loss 0.034637
[epoch18, step398]: loss 0.037301
[epoch18, step399]: loss 0.037105
[epoch18, step400]: loss 0.034371
[epoch18, step401]: loss 0.034493
[epoch18, step402]: loss 0.037634
[epoch18, step403]: loss 0.034758
[epoch18, step404]: loss 0.037717
[epoch18, step405]: loss 0.035130
[epoch18, step406]: loss 0.035136
[epoch18, step407]: loss 0.037397
[epoch18, step408]: loss 0.037130
[epoch18, step409]: loss 0.035843
[epoch18, step410]: loss 0.035073
[epoch18, step411]: loss 0.037142
[epoch18, step412]: loss 0.034507
[epoch18, step413]: loss 0.037178
[epoch18, step414]: loss 0.034209
[epoch18, step415]: loss 0.035339
[epoch18, step416]: loss 0.036695
[epoch18, step417]: loss 0.037223
[epoch18, step418]: loss 0.035029
[epoch18, step419]: loss 0.033757
[epoch18, step420]: loss 0.037667
[epoch18, step421]: loss 0.034752
[epoch18, step422]: loss 0.036987
[epoch18, step423]: loss 0.034662
[epoch18, step424]: loss 0.034898
[epoch18, step425]: loss 0.037549
[epoch18, step426]: loss 0.037502
[epoch18, step427]: loss 0.034980
[epoch18, step428]: loss 0.034585
[epoch18, step429]: loss 0.037944
[epoch18, step430]: loss 0.034769
[epoch18, step431]: loss 0.037615
[epoch18, step432]: loss 0.034367
[epoch18, step433]: loss 0.035747
[epoch18, step434]: loss 0.037135
[epoch18, step435]: loss 0.037481
[epoch18, step436]: loss 0.034195
[epoch18, step437]: loss 0.034785
[epoch18, step438]: loss 0.037412
[epoch18, step439]: loss 0.035343
[epoch18, step440]: loss 0.037135
[epoch18, step441]: loss 0.034882
[epoch18, step442]: loss 0.035017
[epoch18, step443]: loss 0.037885
[epoch18, step444]: loss 0.036620
[epoch18, step445]: loss 0.034978
[epoch18, step446]: loss 0.034880
[epoch18, step447]: loss 0.038030
[epoch18, step448]: loss 0.034791
[epoch18, step449]: loss 0.037051
[epoch18, step450]: loss 0.034026
[epoch18, step451]: loss 0.035005
[epoch18, step452]: loss 0.036623
[epoch18, step453]: loss 0.037331
[epoch18, step454]: loss 0.034555
[epoch18, step455]: loss 0.034536
[epoch18, step456]: loss 0.036823
[epoch18, step457]: loss 0.035339
[epoch18, step458]: loss 0.037077
[epoch18, step459]: loss 0.035092
[epoch18, step460]: loss 0.034740
[epoch18, step461]: loss 0.038037
[epoch18, step462]: loss 0.036403
[epoch18, step463]: loss 0.035042
[epoch18, step464]: loss 0.034299
[epoch18, step465]: loss 0.038598
[epoch18, step466]: loss 0.034748
[epoch18, step467]: loss 0.037033
[epoch18, step468]: loss 0.034490
[epoch18, step469]: loss 0.035268
[epoch18, step470]: loss 0.037698
[epoch18, step471]: loss 0.036586
[epoch18, step472]: loss 0.035128
[epoch18, step473]: loss 0.034217
[epoch18, step474]: loss 0.036804
[epoch18, step475]: loss 0.034903
[epoch18, step476]: loss 0.037357
[epoch18, step477]: loss 0.034535
[epoch18, step478]: loss 0.034129
[epoch18, step479]: loss 0.036839
[epoch18, step480]: loss 0.036594
[epoch18, step481]: loss 0.034257
[epoch18, step482]: loss 0.034036
[epoch18, step483]: loss 0.037709
[epoch18, step484]: loss 0.035210
[epoch18, step485]: loss 0.037434
[epoch18, step486]: loss 0.034652
[epoch18, step487]: loss 0.034495
[epoch18, step488]: loss 0.037821
[epoch18, step489]: loss 0.035940
[epoch18, step490]: loss 0.035053
[epoch18, step491]: loss 0.034540
[epoch18, step492]: loss 0.036896
[epoch18, step493]: loss 0.034444
[epoch18, step494]: loss 0.036573
[epoch18, step495]: loss 0.035444
[epoch18, step496]: loss 0.034997
[epoch18, step497]: loss 0.037356
[epoch18, step498]: loss 0.037048
[epoch18, step499]: loss 0.034862
[epoch18, step500]: loss 0.034158
[epoch18, step501]: loss 0.036641
[epoch18, step502]: loss 0.034855
[epoch18, step503]: loss 0.037539
[epoch18, step504]: loss 0.034112
[epoch18, step505]: loss 0.034261
[epoch18, step506]: loss 0.037631
[epoch18, step507]: loss 0.037936
[epoch18, step508]: loss 0.036086
[epoch18, step509]: loss 0.034623
[epoch18, step510]: loss 0.037377
[epoch18, step511]: loss 0.035473
[epoch18, step512]: loss 0.037377
[epoch18, step513]: loss 0.034375
[epoch18, step514]: loss 0.034649
[epoch18, step515]: loss 0.037135
[epoch18, step516]: loss 0.037078
[epoch18, step517]: loss 0.034397
[epoch18, step518]: loss 0.034619
[epoch18, step519]: loss 0.037430
[epoch18, step520]: loss 0.033959
[epoch18, step521]: loss 0.036983
[epoch18, step522]: loss 0.033875
[epoch18, step523]: loss 0.034327
[epoch18, step524]: loss 0.036886
[epoch18, step525]: loss 0.037189
[epoch18, step526]: loss 0.034761
[epoch18, step527]: loss 0.033960
[epoch18, step528]: loss 0.037229
[epoch18, step529]: loss 0.034479
[epoch18, step530]: loss 0.037192
[epoch18, step531]: loss 0.034218
[epoch18, step532]: loss 0.034734
[epoch18, step533]: loss 0.038422
[epoch18, step534]: loss 0.037727
[epoch18, step535]: loss 0.035019
[epoch18, step536]: loss 0.034886
[epoch18, step537]: loss 0.037766
[epoch18, step538]: loss 0.035120
[epoch18, step539]: loss 0.037099
[epoch18, step540]: loss 0.034354
[epoch18, step541]: loss 0.034415
[epoch18, step542]: loss 0.037406
[epoch18, step543]: loss 0.036563
[epoch18, step544]: loss 0.034673
[epoch18, step545]: loss 0.033713
[epoch18, step546]: loss 0.037383
[epoch18, step547]: loss 0.034607
[epoch18, step548]: loss 0.037112
[epoch18, step549]: loss 0.034943
[epoch18, step550]: loss 0.034547
[epoch18, step551]: loss 0.037219
[epoch18, step552]: loss 0.036772
[epoch18, step553]: loss 0.034964
[epoch18, step554]: loss 0.034555
[epoch18, step555]: loss 0.037218
[epoch18, step556]: loss 0.034747
[epoch18, step557]: loss 0.036903
[epoch18, step558]: loss 0.034624
[epoch18, step559]: loss 0.034394
[epoch18, step560]: loss 0.037452
[epoch18, step561]: loss 0.036769
[epoch18, step562]: loss 0.034622
[epoch18, step563]: loss 0.028965
[epoch18, step564]: loss 0.029884
[epoch18, step565]: loss 0.028130
[epoch18, step566]: loss 0.036090
[epoch18, step567]: loss 0.027338
[epoch18, step568]: loss 0.026432
[epoch18, step569]: loss 0.023352
[epoch18, step570]: loss 0.031498
[epoch18, step571]: loss 0.027124
[epoch18, step572]: loss 0.025773
[epoch18, step573]: loss 0.029205
[epoch18, step574]: loss 0.028001
[epoch18, step575]: loss 0.020880
[epoch18, step576]: loss 0.021601
[epoch18, step577]: loss 0.026698
[epoch18, step578]: loss 0.019532
[epoch18, step579]: loss 0.028651
[epoch18, step580]: loss 0.020832
[epoch18, step581]: loss 0.026438
[epoch18, step582]: loss 0.025630
[epoch18, step583]: loss 0.022519
[epoch18, step584]: loss 0.024106
[epoch18, step585]: loss 0.026676
[epoch18, step586]: loss 0.021959
[epoch18, step587]: loss 0.028381
[epoch18, step588]: loss 0.023605
[epoch18, step589]: loss 0.023121
[epoch18, step590]: loss 0.027804
[epoch18, step591]: loss 0.020975
[epoch18, step592]: loss 0.025918
[epoch18, step593]: loss 0.022409
[epoch18, step594]: loss 0.026481
[epoch18, step595]: loss 0.026852
[epoch18, step596]: loss 0.022127
[epoch18, step597]: loss 0.025073
[epoch18, step598]: loss 0.026818
[epoch18, step599]: loss 0.025295
[epoch18, step600]: loss 0.027059
[epoch18, step601]: loss 0.019357
[epoch18, step602]: loss 0.022708
[epoch18, step603]: loss 0.026066
[epoch18, step604]: loss 0.026839
[epoch18, step605]: loss 0.025256
[epoch18, step606]: loss 0.025076
[epoch18, step607]: loss 0.027237
[epoch18, step608]: loss 0.025706
[epoch18, step609]: loss 0.026373
[epoch18, step610]: loss 0.025871
[epoch18, step611]: loss 0.026318
[epoch18, step612]: loss 0.025408
[epoch18, step613]: loss 0.019603
[epoch18, step614]: loss 0.025343
[epoch18, step615]: loss 0.028297
[epoch18, step616]: loss 0.024202
[epoch18, step617]: loss 0.023690
[epoch18, step618]: loss 0.025907
[epoch18, step619]: loss 0.027035
[epoch18, step620]: loss 0.024036
[epoch18, step621]: loss 0.026414
[epoch18, step622]: loss 0.020298
[epoch18, step623]: loss 0.024754
[epoch18, step624]: loss 0.026665
[epoch18, step625]: loss 0.025797
[epoch18, step626]: loss 0.028511
[epoch18, step627]: loss 0.022478
[epoch18, step628]: loss 0.025168
[epoch18, step629]: loss 0.020704
[epoch18, step630]: loss 0.023447
[epoch18, step631]: loss 0.030889
[epoch18, step632]: loss 0.023485
[epoch18, step633]: loss 0.024676
[epoch18, step634]: loss 0.027245
[epoch18, step635]: loss 0.025354
[epoch18, step636]: loss 0.020726
[epoch18, step637]: loss 0.027063
[epoch18, step638]: loss 0.026746
[epoch18, step639]: loss 0.022829
[epoch18, step640]: loss 0.029563
[epoch18, step641]: loss 0.030123
[epoch18, step642]: loss 0.025231
[epoch18, step643]: loss 0.025561
[epoch18, step644]: loss 0.025680
[epoch18, step645]: loss 0.023552
[epoch18, step646]: loss 0.025923
[epoch18, step647]: loss 0.023573
[epoch18, step648]: loss 0.023227
[epoch18, step649]: loss 0.028412
[epoch18, step650]: loss 0.021959
[epoch18, step651]: loss 0.026372
[epoch18, step652]: loss 0.027516
[epoch18, step653]: loss 0.028089
[epoch18, step654]: loss 0.023039
[epoch18, step655]: loss 0.024425
[epoch18, step656]: loss 0.021537
[epoch18, step657]: loss 0.027348
[epoch18, step658]: loss 0.025192
[epoch18, step659]: loss 0.027583
[epoch18, step660]: loss 0.023820
[epoch18, step661]: loss 0.026163
[epoch18, step662]: loss 0.023891
[epoch18, step663]: loss 0.020688
[epoch18, step664]: loss 0.025022
[epoch18, step665]: loss 0.028249
[epoch18, step666]: loss 0.026283
[epoch18, step667]: loss 0.026203
[epoch18, step668]: loss 0.021999
[epoch18, step669]: loss 0.026643
[epoch18, step670]: loss 0.026618
[epoch18, step671]: loss 0.021604
[epoch18, step672]: loss 0.023721
[epoch18, step673]: loss 0.021876
[epoch18, step674]: loss 0.021086
[epoch18, step675]: loss 0.019875
[epoch18, step676]: loss 0.024418
[epoch18, step677]: loss 0.025050
[epoch18, step678]: loss 0.023038
[epoch18, step679]: loss 0.023534
[epoch18, step680]: loss 0.030691
[epoch18, step681]: loss 0.021821
[epoch18, step682]: loss 0.026392
[epoch18, step683]: loss 0.025584
[epoch18, step684]: loss 0.024474
[epoch18, step685]: loss 0.024359
[epoch18, step686]: loss 0.027045
[epoch18, step687]: loss 0.026521
[epoch18, step688]: loss 0.022400
[epoch18, step689]: loss 0.024515
[epoch18, step690]: loss 0.025101
[epoch18, step691]: loss 0.024018
[epoch18, step692]: loss 0.022415
[epoch18, step693]: loss 0.026680
[epoch18, step694]: loss 0.022896
[epoch18, step695]: loss 0.026463
[epoch18, step696]: loss 0.025975
[epoch18, step697]: loss 0.026803
[epoch18, step698]: loss 0.024495
[epoch18, step699]: loss 0.023297
[epoch18, step700]: loss 0.021610
[epoch18, step701]: loss 0.025830
[epoch18, step702]: loss 0.021622
[epoch18, step703]: loss 0.022708
[epoch18, step704]: loss 0.024901
[epoch18, step705]: loss 0.024782
[epoch18, step706]: loss 0.023771
[epoch18, step707]: loss 0.024806
[epoch18, step708]: loss 0.026135
[epoch18, step709]: loss 0.027086
[epoch18, step710]: loss 0.023609
[epoch18, step711]: loss 0.023400
[epoch18, step712]: loss 0.026685
[epoch18, step713]: loss 0.026144
[epoch18, step714]: loss 0.021265
[epoch18, step715]: loss 0.023206
[epoch18, step716]: loss 0.025610
[epoch18, step717]: loss 0.023515
[epoch18, step718]: loss 0.025143
[epoch18, step719]: loss 0.032731
[epoch18, step720]: loss 0.024686
[epoch18, step721]: loss 0.023037
[epoch18, step722]: loss 0.030408
[epoch18, step723]: loss 0.025497
[epoch18, step724]: loss 0.022895
[epoch18, step725]: loss 0.027571
[epoch18, step726]: loss 0.022190
[epoch18, step727]: loss 0.024565
[epoch18, step728]: loss 0.026119
[epoch18, step729]: loss 0.021039
[epoch18, step730]: loss 0.022413
[epoch18, step731]: loss 0.025733
[epoch18, step732]: loss 0.025576
[epoch18, step733]: loss 0.023669
[epoch18, step734]: loss 0.022487
[epoch18, step735]: loss 0.027371
[epoch18, step736]: loss 0.024945
[epoch18, step737]: loss 0.026633
[epoch18, step738]: loss 0.020502
[epoch18, step739]: loss 0.025345
[epoch18, step740]: loss 0.022277
[epoch18, step741]: loss 0.024940
[epoch18, step742]: loss 0.021637
[epoch18, step743]: loss 0.023344
[epoch18, step744]: loss 0.023837
[epoch18, step745]: loss 0.024376
[epoch18, step746]: loss 0.024690
[epoch18, step747]: loss 0.027109
[epoch18, step748]: loss 0.025538
[epoch18, step749]: loss 0.026060
[epoch18, step750]: loss 0.027225
[epoch18, step751]: loss 0.021751
[epoch18, step752]: loss 0.024725
[epoch18, step753]: loss 0.025214
[epoch18, step754]: loss 0.022424
[epoch18, step755]: loss 0.026110
[epoch18, step756]: loss 0.023455
[epoch18, step757]: loss 0.020528
[epoch18, step758]: loss 0.024851
[epoch18, step759]: loss 0.022926
[epoch18, step760]: loss 0.023695
[epoch18, step761]: loss 0.026280
[epoch18, step762]: loss 0.021333
[epoch18, step763]: loss 0.025181
[epoch18, step764]: loss 0.023285
[epoch18, step765]: loss 0.025782
[epoch18, step766]: loss 0.024501
[epoch18, step767]: loss 0.026335
[epoch18, step768]: loss 0.021258
[epoch18, step769]: loss 0.026377
[epoch18, step770]: loss 0.025639
[epoch18, step771]: loss 0.023066
[epoch18, step772]: loss 0.028694
[epoch18, step773]: loss 0.026726
[epoch18, step774]: loss 0.024274
[epoch18, step775]: loss 0.020609
[epoch18, step776]: loss 0.025552
[epoch18, step777]: loss 0.023344
[epoch18, step778]: loss 0.028115
[epoch18, step779]: loss 0.023961
[epoch18, step780]: loss 0.020102
[epoch18, step781]: loss 0.024206
[epoch18, step782]: loss 0.022436
[epoch18, step783]: loss 0.019030
[epoch18, step784]: loss 0.019970
[epoch18, step785]: loss 0.021400
[epoch18, step786]: loss 0.023988
[epoch18, step787]: loss 0.023075
[epoch18, step788]: loss 0.024776
[epoch18, step789]: loss 0.022494
[epoch18, step790]: loss 0.023050
[epoch18, step791]: loss 0.026828
[epoch18, step792]: loss 0.024799
[epoch18, step793]: loss 0.026823
[epoch18, step794]: loss 0.020393
[epoch18, step795]: loss 0.025474
[epoch18, step796]: loss 0.027584
[epoch18, step797]: loss 0.027575
[epoch18, step798]: loss 0.027084
[epoch18, step799]: loss 0.025817
[epoch18, step800]: loss 0.021318
[epoch18, step801]: loss 0.021491
[epoch18, step802]: loss 0.022570
[epoch18, step803]: loss 0.025894
[epoch18, step804]: loss 0.027299
[epoch18, step805]: loss 0.027887
[epoch18, step806]: loss 0.021032
[epoch18, step807]: loss 0.020371
[epoch18, step808]: loss 0.022745
[epoch18, step809]: loss 0.022971
[epoch18, step810]: loss 0.026039
[epoch18, step811]: loss 0.025623
[epoch18, step812]: loss 0.024364
[epoch18, step813]: loss 0.023359
[epoch18, step814]: loss 0.024904
[epoch18, step815]: loss 0.024857
[epoch18, step816]: loss 0.024129
[epoch18, step817]: loss 0.024713
[epoch18, step818]: loss 0.022442
[epoch18, step819]: loss 0.019708
[epoch18, step820]: loss 0.023092
[epoch18, step821]: loss 0.021708
[epoch18, step822]: loss 0.030239
[epoch18, step823]: loss 0.023733
[epoch18, step824]: loss 0.026550
[epoch18, step825]: loss 0.025012
[epoch18, step826]: loss 0.024314
[epoch18, step827]: loss 0.026471
[epoch18, step828]: loss 0.028567
[epoch18, step829]: loss 0.026350
[epoch18, step830]: loss 0.022376
[epoch18, step831]: loss 0.026184
[epoch18, step832]: loss 0.020946
[epoch18, step833]: loss 0.028845
[epoch18, step834]: loss 0.025168
[epoch18, step835]: loss 0.020508
[epoch18, step836]: loss 0.026677
[epoch18, step837]: loss 0.025380
[epoch18, step838]: loss 0.026114
[epoch18, step839]: loss 0.028148
[epoch18, step840]: loss 0.020492
[epoch18, step841]: loss 0.024251
[epoch18, step842]: loss 0.027280
[epoch18, step843]: loss 0.024600
[epoch18, step844]: loss 0.024916
[epoch18, step845]: loss 0.021021
[epoch18, step846]: loss 0.025495
[epoch18, step847]: loss 0.026329
[epoch18, step848]: loss 0.024925
[epoch18, step849]: loss 0.024713
[epoch18, step850]: loss 0.022742
[epoch18, step851]: loss 0.023986
[epoch18, step852]: loss 0.023138
[epoch18, step853]: loss 0.029083
[epoch18, step854]: loss 0.022774
[epoch18, step855]: loss 0.027061
[epoch18, step856]: loss 0.022307
[epoch18, step857]: loss 0.025330
[epoch18, step858]: loss 0.024191
[epoch18, step859]: loss 0.023495
[epoch18, step860]: loss 0.022484
[epoch18, step861]: loss 0.023010
[epoch18, step862]: loss 0.023099
[epoch18, step863]: loss 0.020348
[epoch18, step864]: loss 0.026332
[epoch18, step865]: loss 0.023243
[epoch18, step866]: loss 0.025073
[epoch18, step867]: loss 0.026089
[epoch18, step868]: loss 0.026553
[epoch18, step869]: loss 0.023787
[epoch18, step870]: loss 0.030545
[epoch18, step871]: loss 0.021921
[epoch18, step872]: loss 0.025125
[epoch18, step873]: loss 0.025536
[epoch18, step874]: loss 0.023719
[epoch18, step875]: loss 0.024062
[epoch18, step876]: loss 0.024076
[epoch18, step877]: loss 0.019099
[epoch18, step878]: loss 0.023236
[epoch18, step879]: loss 0.027471
[epoch18, step880]: loss 0.025399
[epoch18, step881]: loss 0.022113
[epoch18, step882]: loss 0.023661
[epoch18, step883]: loss 0.023683
[epoch18, step884]: loss 0.026280
[epoch18, step885]: loss 0.025776
[epoch18, step886]: loss 0.026473
[epoch18, step887]: loss 0.024045
[epoch18, step888]: loss 0.024486
[epoch18, step889]: loss 0.023513
[epoch18, step890]: loss 0.023600
[epoch18, step891]: loss 0.025097
[epoch18, step892]: loss 0.020696
[epoch18, step893]: loss 0.024704
[epoch18, step894]: loss 0.024904
[epoch18, step895]: loss 0.022366
[epoch18, step896]: loss 0.021484
[epoch18, step897]: loss 0.023522
[epoch18, step898]: loss 0.025323
[epoch18, step899]: loss 0.027953
[epoch18, step900]: loss 0.026756
[epoch18, step901]: loss 0.025052
[epoch18, step902]: loss 0.023846
[epoch18, step903]: loss 0.023930
[epoch18, step904]: loss 0.027813
[epoch18, step905]: loss 0.027648
[epoch18, step906]: loss 0.022256
[epoch18, step907]: loss 0.023740
[epoch18, step908]: loss 0.022511
[epoch18, step909]: loss 0.025233
[epoch18, step910]: loss 0.022994
[epoch18, step911]: loss 0.025005
[epoch18, step912]: loss 0.023736
[epoch18, step913]: loss 0.023763
[epoch18, step914]: loss 0.029895
[epoch18, step915]: loss 0.023757
[epoch18, step916]: loss 0.023498
[epoch18, step917]: loss 0.025065
[epoch18, step918]: loss 0.028382
[epoch18, step919]: loss 0.024455
[epoch18, step920]: loss 0.027560
[epoch18, step921]: loss 0.024244
[epoch18, step922]: loss 0.022918
[epoch18, step923]: loss 0.022222
[epoch18, step924]: loss 0.021226
[epoch18, step925]: loss 0.025315
[epoch18, step926]: loss 0.026653
[epoch18, step927]: loss 0.025642
[epoch18, step928]: loss 0.024659
[epoch18, step929]: loss 0.027671
[epoch18, step930]: loss 0.025589
[epoch18, step931]: loss 0.026900
[epoch18, step932]: loss 0.021350
[epoch18, step933]: loss 0.027908
[epoch18, step934]: loss 0.021852
[epoch18, step935]: loss 0.022098
[epoch18, step936]: loss 0.022320
[epoch18, step937]: loss 0.027031
[epoch18, step938]: loss 0.025030
[epoch18, step939]: loss 0.020520
[epoch18, step940]: loss 0.023030
[epoch18, step941]: loss 0.026753
[epoch18, step942]: loss 0.025287
[epoch18, step943]: loss 0.022963
[epoch18, step944]: loss 0.027598
[epoch18, step945]: loss 0.020365
[epoch18, step946]: loss 0.025181
[epoch18, step947]: loss 0.027837
[epoch18, step948]: loss 0.019081
[epoch18, step949]: loss 0.022648
[epoch18, step950]: loss 0.026549
[epoch18, step951]: loss 0.028533
[epoch18, step952]: loss 0.024938
[epoch18, step953]: loss 0.027393
[epoch18, step954]: loss 0.022198
[epoch18, step955]: loss 0.036833
[epoch18, step956]: loss 0.051979
[epoch18, step957]: loss 0.046260
[epoch18, step958]: loss 0.043703
[epoch18, step959]: loss 0.047116
[epoch18, step960]: loss 0.043309
[epoch18, step961]: loss 0.043326
[epoch18, step962]: loss 0.040774
[epoch18, step963]: loss 0.038907
[epoch18, step964]: loss 0.039733
[epoch18, step965]: loss 0.039206
[epoch18, step966]: loss 0.037340
[epoch18, step967]: loss 0.036628
[epoch18, step968]: loss 0.039493
[epoch18, step969]: loss 0.039386
[epoch18, step970]: loss 0.037565
[epoch18, step971]: loss 0.036271
[epoch18, step972]: loss 0.039282
[epoch18, step973]: loss 0.037968
[epoch18, step974]: loss 0.039082
[epoch18, step975]: loss 0.036172
[epoch18, step976]: loss 0.035123
[epoch18, step977]: loss 0.038521
[epoch18, step978]: loss 0.037268
[epoch18, step979]: loss 0.035979
[epoch18, step980]: loss 0.034803
[epoch18, step981]: loss 0.036768
[epoch18, step982]: loss 0.037398
[epoch18, step983]: loss 0.038279
[epoch18, step984]: loss 0.034661
[epoch18, step985]: loss 0.035415
[epoch18, step986]: loss 0.039550
[epoch18, step987]: loss 0.037393
[epoch18, step988]: loss 0.037056
[epoch18, step989]: loss 0.035515
[epoch18, step990]: loss 0.036481
[epoch18, step991]: loss 0.037316
[epoch18, step992]: loss 0.037019
[epoch18, step993]: loss 0.034981
[epoch18, step994]: loss 0.034019
[epoch18, step995]: loss 0.037857
[epoch18, step996]: loss 0.036124
[epoch18, step997]: loss 0.035895
[epoch18, step998]: loss 0.035254
[epoch18, step999]: loss 0.036429
[epoch18, step1000]: loss 0.036873
[epoch18, step1001]: loss 0.037379
[epoch18, step1002]: loss 0.035131
[epoch18, step1003]: loss 0.034687
[epoch18, step1004]: loss 0.038322
[epoch18, step1005]: loss 0.035816
[epoch18, step1006]: loss 0.036297
[epoch18, step1007]: loss 0.034059
[epoch18, step1008]: loss 0.035929
[epoch18, step1009]: loss 0.036132
[epoch18, step1010]: loss 0.038007
[epoch18, step1011]: loss 0.034866
[epoch18, step1012]: loss 0.034721
[epoch18, step1013]: loss 0.037817
[epoch18, step1014]: loss 0.036909
[epoch18, step1015]: loss 0.036055
[epoch18, step1016]: loss 0.034419
[epoch18, step1017]: loss 0.035857
[epoch18, step1018]: loss 0.036398
[epoch18, step1019]: loss 0.037458
[epoch18, step1020]: loss 0.034435
[epoch18, step1021]: loss 0.034389
[epoch18, step1022]: loss 0.037495
[epoch18, step1023]: loss 0.036417
[epoch18, step1024]: loss 0.036840
[epoch18, step1025]: loss 0.034030
[epoch18, step1026]: loss 0.035643
[epoch18, step1027]: loss 0.035854
[epoch18, step1028]: loss 0.037275
[epoch18, step1029]: loss 0.034689
[epoch18, step1030]: loss 0.033754
[epoch18, step1031]: loss 0.036392
[epoch18, step1032]: loss 0.036364
[epoch18, step1033]: loss 0.035629
[epoch18, step1034]: loss 0.033987
[epoch18, step1035]: loss 0.035279
[epoch18, step1036]: loss 0.036147
[epoch18, step1037]: loss 0.036825
[epoch18, step1038]: loss 0.034358
[epoch18, step1039]: loss 0.034312
[epoch18, step1040]: loss 0.036640
[epoch18, step1041]: loss 0.035799
[epoch18, step1042]: loss 0.034866
[epoch18, step1043]: loss 0.034214
[epoch18, step1044]: loss 0.036010
[epoch18, step1045]: loss 0.036344
[epoch18, step1046]: loss 0.037165
[epoch18, step1047]: loss 0.034664
[epoch18, step1048]: loss 0.034161
[epoch18, step1049]: loss 0.037283
[epoch18, step1050]: loss 0.036890
[epoch18, step1051]: loss 0.035751
[epoch18, step1052]: loss 0.034935
[epoch18, step1053]: loss 0.036449
[epoch18, step1054]: loss 0.036359
[epoch18, step1055]: loss 0.037063
[epoch18, step1056]: loss 0.034259
[epoch18, step1057]: loss 0.034900
[epoch18, step1058]: loss 0.038563
[epoch18, step1059]: loss 0.036407
[epoch18, step1060]: loss 0.035940
[epoch18, step1061]: loss 0.033891
[epoch18, step1062]: loss 0.036208
[epoch18, step1063]: loss 0.036051
[epoch18, step1064]: loss 0.036924
[epoch18, step1065]: loss 0.034681
[epoch18, step1066]: loss 0.034010
[epoch18, step1067]: loss 0.037234
[epoch18, step1068]: loss 0.035071
[epoch18, step1069]: loss 0.035092
[epoch18, step1070]: loss 0.034590
[epoch18, step1071]: loss 0.036398
[epoch18, step1072]: loss 0.036687
[epoch18, step1073]: loss 0.037360
[epoch18, step1074]: loss 0.034699
[epoch18, step1075]: loss 0.034650
[epoch18, step1076]: loss 0.037453
[epoch18, step1077]: loss 0.036135
[epoch18, step1078]: loss 0.035569
[epoch18, step1079]: loss 0.035112
[epoch18, step1080]: loss 0.036107
[epoch18, step1081]: loss 0.035869
[epoch18, step1082]: loss 0.036803
[epoch18, step1083]: loss 0.035123
[epoch18, step1084]: loss 0.034565
[epoch18, step1085]: loss 0.036887
[epoch18, step1086]: loss 0.035747
[epoch18, step1087]: loss 0.035689
[epoch18, step1088]: loss 0.034141
[epoch18, step1089]: loss 0.036212
[epoch18, step1090]: loss 0.036573
[epoch18, step1091]: loss 0.037298
[epoch18, step1092]: loss 0.034391
[epoch18, step1093]: loss 0.034444
[epoch18, step1094]: loss 0.036492
[epoch18, step1095]: loss 0.035869
[epoch18, step1096]: loss 0.035602
[epoch18, step1097]: loss 0.034248
[epoch18, step1098]: loss 0.036020
[epoch18, step1099]: loss 0.035804
[epoch18, step1100]: loss 0.037389
[epoch18, step1101]: loss 0.034990
[epoch18, step1102]: loss 0.034175
[epoch18, step1103]: loss 0.036774
[epoch18, step1104]: loss 0.035828
[epoch18, step1105]: loss 0.035695
[epoch18, step1106]: loss 0.033410
[epoch18, step1107]: loss 0.035976
[epoch18, step1108]: loss 0.035714
[epoch18, step1109]: loss 0.037406
[epoch18, step1110]: loss 0.035236
[epoch18, step1111]: loss 0.034454
[epoch18, step1112]: loss 0.037522
[epoch18, step1113]: loss 0.035719
[epoch18, step1114]: loss 0.035798
[epoch18, step1115]: loss 0.034878
[epoch18, step1116]: loss 0.035981
[epoch18, step1117]: loss 0.036207
[epoch18, step1118]: loss 0.036972
[epoch18, step1119]: loss 0.034324
[epoch18, step1120]: loss 0.034308
[epoch18, step1121]: loss 0.037168
[epoch18, step1122]: loss 0.035645
[epoch18, step1123]: loss 0.034967
[epoch18, step1124]: loss 0.035021
[epoch18, step1125]: loss 0.036186
[epoch18, step1126]: loss 0.036912
[epoch18, step1127]: loss 0.036969
[epoch18, step1128]: loss 0.034660
[epoch18, step1129]: loss 0.034211
[epoch18, step1130]: loss 0.038175
[epoch18, step1131]: loss 0.036452
[epoch18, step1132]: loss 0.036492
[epoch18, step1133]: loss 0.033820
[epoch18, step1134]: loss 0.035712
[epoch18, step1135]: loss 0.036998
[epoch18, step1136]: loss 0.037703
[epoch18, step1137]: loss 0.034716
[epoch18, step1138]: loss 0.034314
[epoch18, step1139]: loss 0.037101
[epoch18, step1140]: loss 0.035223
[epoch18, step1141]: loss 0.035340
[epoch18, step1142]: loss 0.033992
[epoch18, step1143]: loss 0.035299
[epoch18, step1144]: loss 0.036193
[epoch18, step1145]: loss 0.036270
[epoch18, step1146]: loss 0.034219
[epoch18, step1147]: loss 0.035057
[epoch18, step1148]: loss 0.037203
[epoch18, step1149]: loss 0.035607
[epoch18, step1150]: loss 0.035237
[epoch18, step1151]: loss 0.035184
[epoch18, step1152]: loss 0.036523
[epoch18, step1153]: loss 0.035446
[epoch18, step1154]: loss 0.037350
[epoch18, step1155]: loss 0.034567
[epoch18, step1156]: loss 0.033972
[epoch18, step1157]: loss 0.036948
[epoch18, step1158]: loss 0.036136
[epoch18, step1159]: loss 0.035756
[epoch18, step1160]: loss 0.034990
[epoch18, step1161]: loss 0.036174
[epoch18, step1162]: loss 0.035960
[epoch18, step1163]: loss 0.036335
[epoch18, step1164]: loss 0.034765
[epoch18, step1165]: loss 0.035236
[epoch18, step1166]: loss 0.037422
[epoch18, step1167]: loss 0.034899
[epoch18, step1168]: loss 0.035618
[epoch18, step1169]: loss 0.034129
[epoch18, step1170]: loss 0.035648
[epoch18, step1171]: loss 0.036263
[epoch18, step1172]: loss 0.036721
[epoch18, step1173]: loss 0.034631
[epoch18, step1174]: loss 0.034400
[epoch18, step1175]: loss 0.037077
[epoch18, step1176]: loss 0.035400
[epoch18, step1177]: loss 0.035722
[epoch18, step1178]: loss 0.034523
[epoch18, step1179]: loss 0.035990
[epoch18, step1180]: loss 0.036380
[epoch18, step1181]: loss 0.037946
[epoch18, step1182]: loss 0.033893
[epoch18, step1183]: loss 0.035040
[epoch18, step1184]: loss 0.037116
[epoch18, step1185]: loss 0.035953
[epoch18, step1186]: loss 0.034866
[epoch18, step1187]: loss 0.033656
[epoch18, step1188]: loss 0.035055
[epoch18, step1189]: loss 0.035526
[epoch18, step1190]: loss 0.036345
[epoch18, step1191]: loss 0.035070
[epoch18, step1192]: loss 0.034296
[epoch18, step1193]: loss 0.036910
[epoch18, step1194]: loss 0.035505
[epoch18, step1195]: loss 0.034312
[epoch18, step1196]: loss 0.033540
[epoch18, step1197]: loss 0.036002
[epoch18, step1198]: loss 0.036038
[epoch18, step1199]: loss 0.036327
[epoch18, step1200]: loss 0.034080
[epoch18, step1201]: loss 0.034828
[epoch18, step1202]: loss 0.038045
[epoch18, step1203]: loss 0.035896
[epoch18, step1204]: loss 0.034647
[epoch18, step1205]: loss 0.034132
[epoch18, step1206]: loss 0.035170
[epoch18, step1207]: loss 0.036286
[epoch18, step1208]: loss 0.037500
[epoch18, step1209]: loss 0.033276
[epoch18, step1210]: loss 0.034885
[epoch18, step1211]: loss 0.036960
[epoch18, step1212]: loss 0.035863
[epoch18, step1213]: loss 0.035191
[epoch18, step1214]: loss 0.034303
[epoch18, step1215]: loss 0.036495
[epoch18, step1216]: loss 0.035401
[epoch18, step1217]: loss 0.037338
[epoch18, step1218]: loss 0.034045
[epoch18, step1219]: loss 0.034768
[epoch18, step1220]: loss 0.037232
[epoch18, step1221]: loss 0.035062
[epoch18, step1222]: loss 0.035683
[epoch18, step1223]: loss 0.034420
[epoch18, step1224]: loss 0.036420
[epoch18, step1225]: loss 0.035895
[epoch18, step1226]: loss 0.036287
[epoch18, step1227]: loss 0.034360
[epoch18, step1228]: loss 0.034255
[epoch18, step1229]: loss 0.036951
[epoch18, step1230]: loss 0.035934
[epoch18, step1231]: loss 0.035517
[epoch18, step1232]: loss 0.035028
[epoch18, step1233]: loss 0.035461
[epoch18, step1234]: loss 0.035541
[epoch18, step1235]: loss 0.037243
[epoch18, step1236]: loss 0.034513
[epoch18, step1237]: loss 0.034078
[epoch18, step1238]: loss 0.036263
[epoch18, step1239]: loss 0.036671
[epoch18, step1240]: loss 0.035637
[epoch18, step1241]: loss 0.033704
[epoch18, step1242]: loss 0.035489
[epoch18, step1243]: loss 0.035629
[epoch18, step1244]: loss 0.037381
[epoch18, step1245]: loss 0.034725
[epoch18, step1246]: loss 0.034696
[epoch18, step1247]: loss 0.036567
[epoch18, step1248]: loss 0.035866
[epoch18, step1249]: loss 0.036101
[epoch18, step1250]: loss 0.034109
[epoch18, step1251]: loss 0.036393
[epoch18, step1252]: loss 0.036696
[epoch18, step1253]: loss 0.037059
[epoch18, step1254]: loss 0.034519
[epoch18, step1255]: loss 0.034117
[epoch18, step1256]: loss 0.037167
[epoch18, step1257]: loss 0.036137
[epoch18, step1258]: loss 0.035618
[epoch18, step1259]: loss 0.034391
[epoch18, step1260]: loss 0.035749
[epoch18, step1261]: loss 0.035707
[epoch18, step1262]: loss 0.036002
[epoch18, step1263]: loss 0.035342
[epoch18, step1264]: loss 0.034220
[epoch18, step1265]: loss 0.036012
[epoch18, step1266]: loss 0.035594
[epoch18, step1267]: loss 0.035771
[epoch18, step1268]: loss 0.034778
[epoch18, step1269]: loss 0.035914
[epoch18, step1270]: loss 0.035292
[epoch18, step1271]: loss 0.037244
[epoch18, step1272]: loss 0.034661
[epoch18, step1273]: loss 0.034001
[epoch18, step1274]: loss 0.037349
[epoch18, step1275]: loss 0.036093
[epoch18, step1276]: loss 0.035507
[epoch18, step1277]: loss 0.034139
[epoch18, step1278]: loss 0.036239
[epoch18, step1279]: loss 0.036172
[epoch18, step1280]: loss 0.037007
[epoch18, step1281]: loss 0.034418
[epoch18, step1282]: loss 0.034673
[epoch18, step1283]: loss 0.036387
[epoch18, step1284]: loss 0.035455
[epoch18, step1285]: loss 0.035824
[epoch18, step1286]: loss 0.034068
[epoch18, step1287]: loss 0.036522
[epoch18, step1288]: loss 0.036417
[epoch18, step1289]: loss 0.037976
[epoch18, step1290]: loss 0.034311
[epoch18, step1291]: loss 0.033921
[epoch18, step1292]: loss 0.038245
[epoch18, step1293]: loss 0.035199
[epoch18, step1294]: loss 0.035970
[epoch18, step1295]: loss 0.034955
[epoch18, step1296]: loss 0.035768
[epoch18, step1297]: loss 0.035932
[epoch18, step1298]: loss 0.037283
[epoch18, step1299]: loss 0.034540
[epoch18, step1300]: loss 0.034924
[epoch18, step1301]: loss 0.036357
[epoch18, step1302]: loss 0.035831
[epoch18, step1303]: loss 0.035440
[epoch18, step1304]: loss 0.033849
[epoch18, step1305]: loss 0.036141
[epoch18, step1306]: loss 0.036358
[epoch18, step1307]: loss 0.036452
[epoch18, step1308]: loss 0.034721
[epoch18, step1309]: loss 0.033931
[epoch18, step1310]: loss 0.037014
[epoch18, step1311]: loss 0.034751
[epoch18, step1312]: loss 0.036378
[epoch18, step1313]: loss 0.034182
[epoch18, step1314]: loss 0.035544
[epoch18, step1315]: loss 0.035443
[epoch18, step1316]: loss 0.037903
[epoch18, step1317]: loss 0.033954
[epoch18, step1318]: loss 0.033844
[epoch18, step1319]: loss 0.036471
[epoch18, step1320]: loss 0.035526
[epoch18, step1321]: loss 0.035836
[epoch18, step1322]: loss 0.034023
[epoch18, step1323]: loss 0.036033
[epoch18, step1324]: loss 0.035390
[epoch18, step1325]: loss 0.036414
[epoch18, step1326]: loss 0.034311
[epoch18, step1327]: loss 0.034102
[epoch18, step1328]: loss 0.037104
[epoch18, step1329]: loss 0.035431
[epoch18, step1330]: loss 0.035434
[epoch18, step1331]: loss 0.034034
[epoch18, step1332]: loss 0.035609
[epoch18, step1333]: loss 0.035037
[epoch18, step1334]: loss 0.037538
[epoch18, step1335]: loss 0.035150
[epoch18, step1336]: loss 0.034246
[epoch18, step1337]: loss 0.036777
[epoch18, step1338]: loss 0.035798
[epoch18, step1339]: loss 0.035726
[epoch18, step1340]: loss 0.033888
[epoch18, step1341]: loss 0.035981
[epoch18, step1342]: loss 0.035629
[epoch18, step1343]: loss 0.036916
[epoch18, step1344]: loss 0.034680
[epoch18, step1345]: loss 0.034074
[epoch18, step1346]: loss 0.036416
[epoch18, step1347]: loss 0.036075
[epoch18, step1348]: loss 0.034703
[epoch18, step1349]: loss 0.034462
[epoch18, step1350]: loss 0.036277
[epoch18, step1351]: loss 0.035659
[epoch18, step1352]: loss 0.037122
[epoch18, step1353]: loss 0.033857
[epoch18, step1354]: loss 0.034395
[epoch18, step1355]: loss 0.037755
[epoch18, step1356]: loss 0.035463
[epoch18, step1357]: loss 0.035469
[epoch18, step1358]: loss 0.034015
[epoch18, step1359]: loss 0.035092
[epoch18, step1360]: loss 0.036750
[epoch18, step1361]: loss 0.036972
[epoch18, step1362]: loss 0.034779
[epoch18, step1363]: loss 0.034525
[epoch18, step1364]: loss 0.036867
[epoch18, step1365]: loss 0.035625
[epoch18, step1366]: loss 0.035133
[epoch18, step1367]: loss 0.033329
[epoch18, step1368]: loss 0.036274
[epoch18, step1369]: loss 0.035933
[epoch18, step1370]: loss 0.036337
[epoch18, step1371]: loss 0.034854
[epoch18, step1372]: loss 0.034184
[epoch18, step1373]: loss 0.036775
[epoch18, step1374]: loss 0.036262
[epoch18, step1375]: loss 0.036163
[epoch18, step1376]: loss 0.034391
[epoch18, step1377]: loss 0.035270
[epoch18, step1378]: loss 0.035813
[epoch18, step1379]: loss 0.036598
[epoch18, step1380]: loss 0.034523
[epoch18, step1381]: loss 0.034067
[epoch18, step1382]: loss 0.037198
[epoch18, step1383]: loss 0.035481
[epoch18, step1384]: loss 0.035300
[epoch18, step1385]: loss 0.033480
[epoch18, step1386]: loss 0.035895
[epoch18, step1387]: loss 0.036019
[epoch18, step1388]: loss 0.035732
[epoch18, step1389]: loss 0.033665
[epoch18, step1390]: loss 0.034513
[epoch18, step1391]: loss 0.036619
[epoch18, step1392]: loss 0.035693
[epoch18, step1393]: loss 0.035467
[epoch18, step1394]: loss 0.034891
[epoch18, step1395]: loss 0.035761
[epoch18, step1396]: loss 0.035676
[epoch18, step1397]: loss 0.037020
[epoch18, step1398]: loss 0.033977
[epoch18, step1399]: loss 0.035209
[epoch18, step1400]: loss 0.037425
[epoch18, step1401]: loss 0.035407
[epoch18, step1402]: loss 0.035716
[epoch18, step1403]: loss 0.033163
[epoch18, step1404]: loss 0.035340
[epoch18, step1405]: loss 0.035424
[epoch18, step1406]: loss 0.036527
[epoch18, step1407]: loss 0.035144
[epoch18, step1408]: loss 0.033792
[epoch18, step1409]: loss 0.036597
[epoch18, step1410]: loss 0.035552
[epoch18, step1411]: loss 0.034369
[epoch18, step1412]: loss 0.034026
[epoch18, step1413]: loss 0.035841
[epoch18, step1414]: loss 0.035125
[epoch18, step1415]: loss 0.036439
[epoch18, step1416]: loss 0.034130
[epoch18, step1417]: loss 0.034251
[epoch18, step1418]: loss 0.037025
[epoch18, step1419]: loss 0.036041
[epoch18, step1420]: loss 0.035443
[epoch18, step1421]: loss 0.034517
[epoch18, step1422]: loss 0.036126
[epoch18, step1423]: loss 0.035280
[epoch18, step1424]: loss 0.036519
[epoch18, step1425]: loss 0.033601
[epoch18, step1426]: loss 0.034403
[epoch18, step1427]: loss 0.037908
[epoch18, step1428]: loss 0.036476
[epoch18, step1429]: loss 0.035596
[epoch18, step1430]: loss 0.034039
[epoch18, step1431]: loss 0.035840
[epoch18, step1432]: loss 0.035346
[epoch18, step1433]: loss 0.036834
[epoch18, step1434]: loss 0.033883
[epoch18, step1435]: loss 0.034726
[epoch18, step1436]: loss 0.037381
[epoch18, step1437]: loss 0.035679
[epoch18, step1438]: loss 0.036326
[epoch18, step1439]: loss 0.033986
[epoch18, step1440]: loss 0.035461
[epoch18, step1441]: loss 0.036045
[epoch18, step1442]: loss 0.035627
[epoch18, step1443]: loss 0.033878
[epoch18, step1444]: loss 0.033279
[epoch18, step1445]: loss 0.036847
[epoch18, step1446]: loss 0.035807
[epoch18, step1447]: loss 0.035747
[epoch18, step1448]: loss 0.034010
[epoch18, step1449]: loss 0.035165
[epoch18, step1450]: loss 0.035768
[epoch18, step1451]: loss 0.037016
[epoch18, step1452]: loss 0.033839
[epoch18, step1453]: loss 0.035432
[epoch18, step1454]: loss 0.037335
[epoch18, step1455]: loss 0.036277
[epoch18, step1456]: loss 0.035182
[epoch18, step1457]: loss 0.034468
[epoch18, step1458]: loss 0.035758
[epoch18, step1459]: loss 0.035830
[epoch18, step1460]: loss 0.036909
[epoch18, step1461]: loss 0.034939
[epoch18, step1462]: loss 0.034686
[epoch18, step1463]: loss 0.036775
[epoch18, step1464]: loss 0.035956
[epoch18, step1465]: loss 0.034814
[epoch18, step1466]: loss 0.033804
[epoch18, step1467]: loss 0.035397
[epoch18, step1468]: loss 0.035506
[epoch18, step1469]: loss 0.036471
[epoch18, step1470]: loss 0.034490
[epoch18, step1471]: loss 0.034041
[epoch18, step1472]: loss 0.036834
[epoch18, step1473]: loss 0.035832
[epoch18, step1474]: loss 0.035934
[epoch18, step1475]: loss 0.033846
[epoch18, step1476]: loss 0.036548
[epoch18, step1477]: loss 0.035450
[epoch18, step1478]: loss 0.036560
[epoch18, step1479]: loss 0.034355
[epoch18, step1480]: loss 0.034108
[epoch18, step1481]: loss 0.035807
[epoch18, step1482]: loss 0.035293
[epoch18, step1483]: loss 0.035452
[epoch18, step1484]: loss 0.034172
[epoch18, step1485]: loss 0.035645
[epoch18, step1486]: loss 0.034835
[epoch18, step1487]: loss 0.036429
[epoch18, step1488]: loss 0.034273
[epoch18, step1489]: loss 0.033974
[epoch18, step1490]: loss 0.036876
[epoch18, step1491]: loss 0.036117
[epoch18, step1492]: loss 0.035220
[epoch18, step1493]: loss 0.034130
[epoch18, step1494]: loss 0.036024
[epoch18, step1495]: loss 0.035579
[epoch18, step1496]: loss 0.035867
[epoch18, step1497]: loss 0.034625
[epoch18, step1498]: loss 0.034671
[epoch18, step1499]: loss 0.036126
[epoch18, step1500]: loss 0.035888
[epoch18, step1501]: loss 0.035347
[epoch18, step1502]: loss 0.033651
[epoch18, step1503]: loss 0.035578
[epoch18, step1504]: loss 0.035099
[epoch18, step1505]: loss 0.036829
[epoch18, step1506]: loss 0.033681
[epoch18, step1507]: loss 0.034499
[epoch18, step1508]: loss 0.037474
[epoch18, step1509]: loss 0.034935
[epoch18, step1510]: loss 0.034752
[epoch18, step1511]: loss 0.034679
[epoch18, step1512]: loss 0.035877
[epoch18, step1513]: loss 0.034502
[epoch18, step1514]: loss 0.036540
[epoch18, step1515]: loss 0.034610
[epoch18, step1516]: loss 0.034310

[epoch18]: avg loss 0.032978

[epoch19, step1]: loss 0.031367
[epoch19, step2]: loss 0.036345
[epoch19, step3]: loss 0.036219
[epoch19, step4]: loss 0.034155
[epoch19, step5]: loss 0.034657
[epoch19, step6]: loss 0.036752
[epoch19, step7]: loss 0.035044
[epoch19, step8]: loss 0.036482
[epoch19, step9]: loss 0.033729
[epoch19, step10]: loss 0.035485
[epoch19, step11]: loss 0.036995
[epoch19, step12]: loss 0.036625
[epoch19, step13]: loss 0.034349
[epoch19, step14]: loss 0.034477
[epoch19, step15]: loss 0.036433
[epoch19, step16]: loss 0.035070
[epoch19, step17]: loss 0.037163
[epoch19, step18]: loss 0.034769
[epoch19, step19]: loss 0.035088
[epoch19, step20]: loss 0.037343
[epoch19, step21]: loss 0.036615
[epoch19, step22]: loss 0.034120
[epoch19, step23]: loss 0.033732
[epoch19, step24]: loss 0.036890
[epoch19, step25]: loss 0.034016
[epoch19, step26]: loss 0.036504
[epoch19, step27]: loss 0.033505
[epoch19, step28]: loss 0.034783
[epoch19, step29]: loss 0.036669
[epoch19, step30]: loss 0.037040
[epoch19, step31]: loss 0.033918
[epoch19, step32]: loss 0.034926
[epoch19, step33]: loss 0.037297
[epoch19, step34]: loss 0.035153
[epoch19, step35]: loss 0.037306
[epoch19, step36]: loss 0.034076
[epoch19, step37]: loss 0.034654
[epoch19, step38]: loss 0.036886
[epoch19, step39]: loss 0.036610
[epoch19, step40]: loss 0.034239
[epoch19, step41]: loss 0.034115
[epoch19, step42]: loss 0.037069
[epoch19, step43]: loss 0.034319
[epoch19, step44]: loss 0.037824
[epoch19, step45]: loss 0.034183
[epoch19, step46]: loss 0.034995
[epoch19, step47]: loss 0.036541
[epoch19, step48]: loss 0.036222
[epoch19, step49]: loss 0.032811
[epoch19, step50]: loss 0.034257
[epoch19, step51]: loss 0.036808
[epoch19, step52]: loss 0.034429
[epoch19, step53]: loss 0.037068
[epoch19, step54]: loss 0.033734
[epoch19, step55]: loss 0.035158
[epoch19, step56]: loss 0.037578
[epoch19, step57]: loss 0.036913
[epoch19, step58]: loss 0.033959
[epoch19, step59]: loss 0.033351
[epoch19, step60]: loss 0.037228
[epoch19, step61]: loss 0.034041
[epoch19, step62]: loss 0.036413
[epoch19, step63]: loss 0.033627
[epoch19, step64]: loss 0.034608
[epoch19, step65]: loss 0.037036
[epoch19, step66]: loss 0.036470
[epoch19, step67]: loss 0.034289
[epoch19, step68]: loss 0.034191
[epoch19, step69]: loss 0.036537
[epoch19, step70]: loss 0.034257
[epoch19, step71]: loss 0.036500
[epoch19, step72]: loss 0.034007
[epoch19, step73]: loss 0.034530
[epoch19, step74]: loss 0.036446
[epoch19, step75]: loss 0.036822
[epoch19, step76]: loss 0.034685
[epoch19, step77]: loss 0.034817
[epoch19, step78]: loss 0.036914
[epoch19, step79]: loss 0.034419
[epoch19, step80]: loss 0.037499
[epoch19, step81]: loss 0.034178
[epoch19, step82]: loss 0.034680
[epoch19, step83]: loss 0.036660
[epoch19, step84]: loss 0.036990
[epoch19, step85]: loss 0.034991
[epoch19, step86]: loss 0.034784
[epoch19, step87]: loss 0.037989
[epoch19, step88]: loss 0.033586
[epoch19, step89]: loss 0.036878
[epoch19, step90]: loss 0.034574
[epoch19, step91]: loss 0.034249
[epoch19, step92]: loss 0.036614
[epoch19, step93]: loss 0.036689
[epoch19, step94]: loss 0.033758
[epoch19, step95]: loss 0.034509
[epoch19, step96]: loss 0.036226
[epoch19, step97]: loss 0.035265
[epoch19, step98]: loss 0.036577
[epoch19, step99]: loss 0.034157
[epoch19, step100]: loss 0.033542
[epoch19, step101]: loss 0.037260
[epoch19, step102]: loss 0.036876
[epoch19, step103]: loss 0.034275
[epoch19, step104]: loss 0.034299
[epoch19, step105]: loss 0.037463
[epoch19, step106]: loss 0.034518
[epoch19, step107]: loss 0.037221
[epoch19, step108]: loss 0.034330
[epoch19, step109]: loss 0.034230
[epoch19, step110]: loss 0.037335
[epoch19, step111]: loss 0.036248
[epoch19, step112]: loss 0.034218
[epoch19, step113]: loss 0.035026
[epoch19, step114]: loss 0.036776
[epoch19, step115]: loss 0.034409
[epoch19, step116]: loss 0.037327
[epoch19, step117]: loss 0.033817
[epoch19, step118]: loss 0.035577
[epoch19, step119]: loss 0.037129
[epoch19, step120]: loss 0.037032
[epoch19, step121]: loss 0.034353
[epoch19, step122]: loss 0.034526
[epoch19, step123]: loss 0.037115
[epoch19, step124]: loss 0.034947
[epoch19, step125]: loss 0.037179
[epoch19, step126]: loss 0.034337
[epoch19, step127]: loss 0.034640
[epoch19, step128]: loss 0.036763
[epoch19, step129]: loss 0.036739
[epoch19, step130]: loss 0.034542
[epoch19, step131]: loss 0.033976
[epoch19, step132]: loss 0.036990
[epoch19, step133]: loss 0.034641
[epoch19, step134]: loss 0.036123
[epoch19, step135]: loss 0.034562
[epoch19, step136]: loss 0.035397
[epoch19, step137]: loss 0.036697
[epoch19, step138]: loss 0.036749
[epoch19, step139]: loss 0.033988
[epoch19, step140]: loss 0.034696
[epoch19, step141]: loss 0.036926
[epoch19, step142]: loss 0.034553
[epoch19, step143]: loss 0.036332
[epoch19, step144]: loss 0.034376
[epoch19, step145]: loss 0.035063
[epoch19, step146]: loss 0.037456
[epoch19, step147]: loss 0.037824
[epoch19, step148]: loss 0.033976
[epoch19, step149]: loss 0.033875
[epoch19, step150]: loss 0.036146
[epoch19, step151]: loss 0.034663
[epoch19, step152]: loss 0.036410
[epoch19, step153]: loss 0.034300
[epoch19, step154]: loss 0.034544
[epoch19, step155]: loss 0.036742
[epoch19, step156]: loss 0.036416
[epoch19, step157]: loss 0.034301
[epoch19, step158]: loss 0.034462
[epoch19, step159]: loss 0.036890
[epoch19, step160]: loss 0.034772
[epoch19, step161]: loss 0.037188
[epoch19, step162]: loss 0.034300
[epoch19, step163]: loss 0.034596
[epoch19, step164]: loss 0.037038
[epoch19, step165]: loss 0.036540
[epoch19, step166]: loss 0.034697
[epoch19, step167]: loss 0.034008
[epoch19, step168]: loss 0.037364
[epoch19, step169]: loss 0.034550
[epoch19, step170]: loss 0.036955
[epoch19, step171]: loss 0.034714
[epoch19, step172]: loss 0.035026
[epoch19, step173]: loss 0.036892
[epoch19, step174]: loss 0.036747
[epoch19, step175]: loss 0.035105
[epoch19, step176]: loss 0.034629
[epoch19, step177]: loss 0.037378
[epoch19, step178]: loss 0.034580
[epoch19, step179]: loss 0.036142
[epoch19, step180]: loss 0.034653
[epoch19, step181]: loss 0.034407
[epoch19, step182]: loss 0.037043
[epoch19, step183]: loss 0.037074
[epoch19, step184]: loss 0.035330
[epoch19, step185]: loss 0.034467
[epoch19, step186]: loss 0.036716
[epoch19, step187]: loss 0.034417
[epoch19, step188]: loss 0.036302
[epoch19, step189]: loss 0.034133
[epoch19, step190]: loss 0.033654
[epoch19, step191]: loss 0.036785
[epoch19, step192]: loss 0.037240
[epoch19, step193]: loss 0.032421
[epoch19, step194]: loss 0.033389
[epoch19, step195]: loss 0.036812
[epoch19, step196]: loss 0.034740
[epoch19, step197]: loss 0.036590
[epoch19, step198]: loss 0.033575
[epoch19, step199]: loss 0.034803
[epoch19, step200]: loss 0.037117
[epoch19, step201]: loss 0.037483
[epoch19, step202]: loss 0.033938
[epoch19, step203]: loss 0.034299
[epoch19, step204]: loss 0.037237
[epoch19, step205]: loss 0.034037
[epoch19, step206]: loss 0.036862
[epoch19, step207]: loss 0.033872
[epoch19, step208]: loss 0.034789
[epoch19, step209]: loss 0.037233
[epoch19, step210]: loss 0.037475
[epoch19, step211]: loss 0.034600
[epoch19, step212]: loss 0.034757
[epoch19, step213]: loss 0.036486
[epoch19, step214]: loss 0.034146
[epoch19, step215]: loss 0.036786
[epoch19, step216]: loss 0.034304
[epoch19, step217]: loss 0.033887
[epoch19, step218]: loss 0.037011
[epoch19, step219]: loss 0.036282
[epoch19, step220]: loss 0.034472
[epoch19, step221]: loss 0.034450
[epoch19, step222]: loss 0.037041
[epoch19, step223]: loss 0.034742
[epoch19, step224]: loss 0.036303
[epoch19, step225]: loss 0.034330
[epoch19, step226]: loss 0.034157
[epoch19, step227]: loss 0.036091
[epoch19, step228]: loss 0.037392
[epoch19, step229]: loss 0.033199
[epoch19, step230]: loss 0.034769
[epoch19, step231]: loss 0.037440
[epoch19, step232]: loss 0.034535
[epoch19, step233]: loss 0.036593
[epoch19, step234]: loss 0.033533
[epoch19, step235]: loss 0.035359
[epoch19, step236]: loss 0.037043
[epoch19, step237]: loss 0.036563
[epoch19, step238]: loss 0.034430
[epoch19, step239]: loss 0.033269
[epoch19, step240]: loss 0.036093
[epoch19, step241]: loss 0.034725
[epoch19, step242]: loss 0.036655
[epoch19, step243]: loss 0.034823
[epoch19, step244]: loss 0.034393
[epoch19, step245]: loss 0.036315
[epoch19, step246]: loss 0.036426
[epoch19, step247]: loss 0.034468
[epoch19, step248]: loss 0.033889
[epoch19, step249]: loss 0.036108
[epoch19, step250]: loss 0.034925
[epoch19, step251]: loss 0.036978
[epoch19, step252]: loss 0.035058
[epoch19, step253]: loss 0.033980
[epoch19, step254]: loss 0.036436
[epoch19, step255]: loss 0.037211
[epoch19, step256]: loss 0.034431
[epoch19, step257]: loss 0.034087
[epoch19, step258]: loss 0.037327
[epoch19, step259]: loss 0.034742
[epoch19, step260]: loss 0.036230
[epoch19, step261]: loss 0.034998
[epoch19, step262]: loss 0.034770
[epoch19, step263]: loss 0.036511
[epoch19, step264]: loss 0.036269
[epoch19, step265]: loss 0.034366
[epoch19, step266]: loss 0.034063
[epoch19, step267]: loss 0.036434
[epoch19, step268]: loss 0.034400
[epoch19, step269]: loss 0.036498
[epoch19, step270]: loss 0.033863
[epoch19, step271]: loss 0.034419
[epoch19, step272]: loss 0.036678
[epoch19, step273]: loss 0.036258
[epoch19, step274]: loss 0.034891
[epoch19, step275]: loss 0.033989
[epoch19, step276]: loss 0.036697
[epoch19, step277]: loss 0.035248
[epoch19, step278]: loss 0.037089
[epoch19, step279]: loss 0.033647
[epoch19, step280]: loss 0.034651
[epoch19, step281]: loss 0.036975
[epoch19, step282]: loss 0.037262
[epoch19, step283]: loss 0.034054
[epoch19, step284]: loss 0.033767
[epoch19, step285]: loss 0.037512
[epoch19, step286]: loss 0.033824
[epoch19, step287]: loss 0.036841
[epoch19, step288]: loss 0.033602
[epoch19, step289]: loss 0.035213
[epoch19, step290]: loss 0.037050
[epoch19, step291]: loss 0.036800
[epoch19, step292]: loss 0.033379
[epoch19, step293]: loss 0.034049
[epoch19, step294]: loss 0.036005
[epoch19, step295]: loss 0.034111
[epoch19, step296]: loss 0.037343
[epoch19, step297]: loss 0.034453
[epoch19, step298]: loss 0.034957
[epoch19, step299]: loss 0.036050
[epoch19, step300]: loss 0.037287
[epoch19, step301]: loss 0.034709
[epoch19, step302]: loss 0.034731
[epoch19, step303]: loss 0.037495
[epoch19, step304]: loss 0.034123
[epoch19, step305]: loss 0.036197
[epoch19, step306]: loss 0.034352
[epoch19, step307]: loss 0.034013
[epoch19, step308]: loss 0.037514
[epoch19, step309]: loss 0.037066
[epoch19, step310]: loss 0.034175
[epoch19, step311]: loss 0.034500
[epoch19, step312]: loss 0.036569
[epoch19, step313]: loss 0.034355
[epoch19, step314]: loss 0.036639
[epoch19, step315]: loss 0.034837
[epoch19, step316]: loss 0.034032
[epoch19, step317]: loss 0.037467
[epoch19, step318]: loss 0.036923
[epoch19, step319]: loss 0.033599
[epoch19, step320]: loss 0.033561
[epoch19, step321]: loss 0.036231
[epoch19, step322]: loss 0.034429
[epoch19, step323]: loss 0.036300
[epoch19, step324]: loss 0.034989
[epoch19, step325]: loss 0.034367
[epoch19, step326]: loss 0.036546
[epoch19, step327]: loss 0.035947
[epoch19, step328]: loss 0.034423
[epoch19, step329]: loss 0.034172
[epoch19, step330]: loss 0.036078
[epoch19, step331]: loss 0.034837
[epoch19, step332]: loss 0.035924
[epoch19, step333]: loss 0.034217
[epoch19, step334]: loss 0.034775
[epoch19, step335]: loss 0.036888
[epoch19, step336]: loss 0.037630
[epoch19, step337]: loss 0.035038
[epoch19, step338]: loss 0.033801
[epoch19, step339]: loss 0.036747
[epoch19, step340]: loss 0.035089
[epoch19, step341]: loss 0.036233
[epoch19, step342]: loss 0.033438
[epoch19, step343]: loss 0.034800
[epoch19, step344]: loss 0.036327
[epoch19, step345]: loss 0.036047
[epoch19, step346]: loss 0.033653
[epoch19, step347]: loss 0.034045
[epoch19, step348]: loss 0.036744
[epoch19, step349]: loss 0.035318
[epoch19, step350]: loss 0.035829
[epoch19, step351]: loss 0.033608
[epoch19, step352]: loss 0.033941
[epoch19, step353]: loss 0.036777
[epoch19, step354]: loss 0.035982
[epoch19, step355]: loss 0.033295
[epoch19, step356]: loss 0.035119
[epoch19, step357]: loss 0.037256
[epoch19, step358]: loss 0.032961
[epoch19, step359]: loss 0.038584
[epoch19, step360]: loss 0.033725
[epoch19, step361]: loss 0.033811
[epoch19, step362]: loss 0.037592
[epoch19, step363]: loss 0.036190
[epoch19, step364]: loss 0.034071
[epoch19, step365]: loss 0.033955
[epoch19, step366]: loss 0.036847
[epoch19, step367]: loss 0.034529
[epoch19, step368]: loss 0.035964
[epoch19, step369]: loss 0.033723
[epoch19, step370]: loss 0.034796
[epoch19, step371]: loss 0.037401
[epoch19, step372]: loss 0.035966
[epoch19, step373]: loss 0.033776
[epoch19, step374]: loss 0.033376
[epoch19, step375]: loss 0.037643
[epoch19, step376]: loss 0.034769
[epoch19, step377]: loss 0.036730
[epoch19, step378]: loss 0.034433
[epoch19, step379]: loss 0.035112
[epoch19, step380]: loss 0.037364
[epoch19, step381]: loss 0.036354
[epoch19, step382]: loss 0.034129
[epoch19, step383]: loss 0.033079
[epoch19, step384]: loss 0.036104
[epoch19, step385]: loss 0.034064
[epoch19, step386]: loss 0.036885
[epoch19, step387]: loss 0.033865
[epoch19, step388]: loss 0.035336
[epoch19, step389]: loss 0.036478
[epoch19, step390]: loss 0.037807
[epoch19, step391]: loss 0.033613
[epoch19, step392]: loss 0.034787
[epoch19, step393]: loss 0.036664
[epoch19, step394]: loss 0.034364
[epoch19, step395]: loss 0.036238
[epoch19, step396]: loss 0.034112
[epoch19, step397]: loss 0.033873
[epoch19, step398]: loss 0.036594
[epoch19, step399]: loss 0.036339
[epoch19, step400]: loss 0.033846
[epoch19, step401]: loss 0.034159
[epoch19, step402]: loss 0.036894
[epoch19, step403]: loss 0.034443
[epoch19, step404]: loss 0.037030
[epoch19, step405]: loss 0.034753
[epoch19, step406]: loss 0.034660
[epoch19, step407]: loss 0.036514
[epoch19, step408]: loss 0.036798
[epoch19, step409]: loss 0.035414
[epoch19, step410]: loss 0.034656
[epoch19, step411]: loss 0.036755
[epoch19, step412]: loss 0.034037
[epoch19, step413]: loss 0.036809
[epoch19, step414]: loss 0.034089
[epoch19, step415]: loss 0.034830
[epoch19, step416]: loss 0.036165
[epoch19, step417]: loss 0.036486
[epoch19, step418]: loss 0.034240
[epoch19, step419]: loss 0.033455
[epoch19, step420]: loss 0.036651
[epoch19, step421]: loss 0.034127
[epoch19, step422]: loss 0.036469
[epoch19, step423]: loss 0.034360
[epoch19, step424]: loss 0.034141
[epoch19, step425]: loss 0.036990
[epoch19, step426]: loss 0.037152
[epoch19, step427]: loss 0.034597
[epoch19, step428]: loss 0.034428
[epoch19, step429]: loss 0.037454
[epoch19, step430]: loss 0.034454
[epoch19, step431]: loss 0.037168
[epoch19, step432]: loss 0.033912
[epoch19, step433]: loss 0.034918
[epoch19, step434]: loss 0.037167
[epoch19, step435]: loss 0.037201
[epoch19, step436]: loss 0.033716
[epoch19, step437]: loss 0.034355
[epoch19, step438]: loss 0.037051
[epoch19, step439]: loss 0.034747
[epoch19, step440]: loss 0.036550
[epoch19, step441]: loss 0.034286
[epoch19, step442]: loss 0.034184
[epoch19, step443]: loss 0.037431
[epoch19, step444]: loss 0.036079
[epoch19, step445]: loss 0.034494
[epoch19, step446]: loss 0.034866
[epoch19, step447]: loss 0.037053
[epoch19, step448]: loss 0.034536
[epoch19, step449]: loss 0.036296
[epoch19, step450]: loss 0.033938
[epoch19, step451]: loss 0.035026
[epoch19, step452]: loss 0.036345
[epoch19, step453]: loss 0.037142
[epoch19, step454]: loss 0.034819
[epoch19, step455]: loss 0.034647
[epoch19, step456]: loss 0.035968
[epoch19, step457]: loss 0.035024
[epoch19, step458]: loss 0.036199
[epoch19, step459]: loss 0.034705
[epoch19, step460]: loss 0.034860
[epoch19, step461]: loss 0.037712
[epoch19, step462]: loss 0.035823
[epoch19, step463]: loss 0.034715
[epoch19, step464]: loss 0.033942
[epoch19, step465]: loss 0.037976
[epoch19, step466]: loss 0.034278
[epoch19, step467]: loss 0.036190
[epoch19, step468]: loss 0.034370
[epoch19, step469]: loss 0.034402
[epoch19, step470]: loss 0.037590
[epoch19, step471]: loss 0.036265
[epoch19, step472]: loss 0.034473
[epoch19, step473]: loss 0.034231
[epoch19, step474]: loss 0.036208
[epoch19, step475]: loss 0.034684
[epoch19, step476]: loss 0.037233
[epoch19, step477]: loss 0.033857
[epoch19, step478]: loss 0.033625
[epoch19, step479]: loss 0.036231
[epoch19, step480]: loss 0.035708
[epoch19, step481]: loss 0.033614
[epoch19, step482]: loss 0.033545
[epoch19, step483]: loss 0.036956
[epoch19, step484]: loss 0.034778
[epoch19, step485]: loss 0.036686
[epoch19, step486]: loss 0.034171
[epoch19, step487]: loss 0.033874
[epoch19, step488]: loss 0.037245
[epoch19, step489]: loss 0.035778
[epoch19, step490]: loss 0.034468
[epoch19, step491]: loss 0.034362
[epoch19, step492]: loss 0.036302
[epoch19, step493]: loss 0.034287
[epoch19, step494]: loss 0.036274
[epoch19, step495]: loss 0.034889
[epoch19, step496]: loss 0.034750
[epoch19, step497]: loss 0.036736
[epoch19, step498]: loss 0.036385
[epoch19, step499]: loss 0.034454
[epoch19, step500]: loss 0.034243
[epoch19, step501]: loss 0.036431
[epoch19, step502]: loss 0.034621
[epoch19, step503]: loss 0.037065
[epoch19, step504]: loss 0.033832
[epoch19, step505]: loss 0.033558
[epoch19, step506]: loss 0.037094
[epoch19, step507]: loss 0.037172
[epoch19, step508]: loss 0.034592
[epoch19, step509]: loss 0.034054
[epoch19, step510]: loss 0.036989
[epoch19, step511]: loss 0.034957
[epoch19, step512]: loss 0.037131
[epoch19, step513]: loss 0.034008
[epoch19, step514]: loss 0.034385
[epoch19, step515]: loss 0.036679
[epoch19, step516]: loss 0.036522
[epoch19, step517]: loss 0.033870
[epoch19, step518]: loss 0.034177
[epoch19, step519]: loss 0.036711
[epoch19, step520]: loss 0.033847
[epoch19, step521]: loss 0.036339
[epoch19, step522]: loss 0.033587
[epoch19, step523]: loss 0.033780
[epoch19, step524]: loss 0.036619
[epoch19, step525]: loss 0.036769
[epoch19, step526]: loss 0.034462
[epoch19, step527]: loss 0.034425
[epoch19, step528]: loss 0.036902
[epoch19, step529]: loss 0.034418
[epoch19, step530]: loss 0.037791
[epoch19, step531]: loss 0.033925
[epoch19, step532]: loss 0.034805
[epoch19, step533]: loss 0.037977
[epoch19, step534]: loss 0.036311
[epoch19, step535]: loss 0.034621
[epoch19, step536]: loss 0.034219
[epoch19, step537]: loss 0.036402
[epoch19, step538]: loss 0.034678
[epoch19, step539]: loss 0.036169
[epoch19, step540]: loss 0.033451
[epoch19, step541]: loss 0.033895
[epoch19, step542]: loss 0.036793
[epoch19, step543]: loss 0.036043
[epoch19, step544]: loss 0.033979
[epoch19, step545]: loss 0.033381
[epoch19, step546]: loss 0.036788
[epoch19, step547]: loss 0.034274
[epoch19, step548]: loss 0.036547
[epoch19, step549]: loss 0.034625
[epoch19, step550]: loss 0.034211
[epoch19, step551]: loss 0.036812
[epoch19, step552]: loss 0.036988
[epoch19, step553]: loss 0.035048
[epoch19, step554]: loss 0.033775
[epoch19, step555]: loss 0.036521
[epoch19, step556]: loss 0.034313
[epoch19, step557]: loss 0.035967
[epoch19, step558]: loss 0.034002
[epoch19, step559]: loss 0.033646
[epoch19, step560]: loss 0.036514
[epoch19, step561]: loss 0.036250
[epoch19, step562]: loss 0.033884
[epoch19, step563]: loss 0.029388
[epoch19, step564]: loss 0.030665
[epoch19, step565]: loss 0.028541
[epoch19, step566]: loss 0.036541
[epoch19, step567]: loss 0.028131
[epoch19, step568]: loss 0.027896
[epoch19, step569]: loss 0.024063
[epoch19, step570]: loss 0.032858
[epoch19, step571]: loss 0.028314
[epoch19, step572]: loss 0.026993
[epoch19, step573]: loss 0.029970
[epoch19, step574]: loss 0.028182
[epoch19, step575]: loss 0.020764
[epoch19, step576]: loss 0.022036
[epoch19, step577]: loss 0.025899
[epoch19, step578]: loss 0.018559
[epoch19, step579]: loss 0.028924
[epoch19, step580]: loss 0.020123
[epoch19, step581]: loss 0.025617
[epoch19, step582]: loss 0.025306
[epoch19, step583]: loss 0.021611
[epoch19, step584]: loss 0.024112
[epoch19, step585]: loss 0.026243
[epoch19, step586]: loss 0.022024
[epoch19, step587]: loss 0.027768
[epoch19, step588]: loss 0.023143
[epoch19, step589]: loss 0.023016
[epoch19, step590]: loss 0.027109
[epoch19, step591]: loss 0.020316
[epoch19, step592]: loss 0.025766
[epoch19, step593]: loss 0.022389
[epoch19, step594]: loss 0.026363
[epoch19, step595]: loss 0.026543
[epoch19, step596]: loss 0.022243
[epoch19, step597]: loss 0.024974
[epoch19, step598]: loss 0.026649
[epoch19, step599]: loss 0.025224
[epoch19, step600]: loss 0.028078
[epoch19, step601]: loss 0.019528
[epoch19, step602]: loss 0.022454
[epoch19, step603]: loss 0.025916
[epoch19, step604]: loss 0.026691
[epoch19, step605]: loss 0.025028
[epoch19, step606]: loss 0.024887
[epoch19, step607]: loss 0.026563
[epoch19, step608]: loss 0.025675
[epoch19, step609]: loss 0.026150
[epoch19, step610]: loss 0.026038
[epoch19, step611]: loss 0.026269
[epoch19, step612]: loss 0.025256
[epoch19, step613]: loss 0.019573
[epoch19, step614]: loss 0.025412
[epoch19, step615]: loss 0.027855
[epoch19, step616]: loss 0.024153
[epoch19, step617]: loss 0.023614
[epoch19, step618]: loss 0.025979
[epoch19, step619]: loss 0.026734
[epoch19, step620]: loss 0.023971
[epoch19, step621]: loss 0.026070
[epoch19, step622]: loss 0.020165
[epoch19, step623]: loss 0.024567
[epoch19, step624]: loss 0.026192
[epoch19, step625]: loss 0.025639
[epoch19, step626]: loss 0.028375
[epoch19, step627]: loss 0.022461
[epoch19, step628]: loss 0.025031
[epoch19, step629]: loss 0.020605
[epoch19, step630]: loss 0.023204
[epoch19, step631]: loss 0.030614
[epoch19, step632]: loss 0.023298
[epoch19, step633]: loss 0.024872
[epoch19, step634]: loss 0.027033
[epoch19, step635]: loss 0.025139
[epoch19, step636]: loss 0.020407
[epoch19, step637]: loss 0.027069
[epoch19, step638]: loss 0.026755
[epoch19, step639]: loss 0.022580
[epoch19, step640]: loss 0.029568
[epoch19, step641]: loss 0.029619
[epoch19, step642]: loss 0.024795
[epoch19, step643]: loss 0.026163
[epoch19, step644]: loss 0.025993
[epoch19, step645]: loss 0.023081
[epoch19, step646]: loss 0.025868
[epoch19, step647]: loss 0.023313
[epoch19, step648]: loss 0.022878
[epoch19, step649]: loss 0.028019
[epoch19, step650]: loss 0.021920
[epoch19, step651]: loss 0.026059
[epoch19, step652]: loss 0.027123
[epoch19, step653]: loss 0.027989
[epoch19, step654]: loss 0.022876
[epoch19, step655]: loss 0.024383
[epoch19, step656]: loss 0.021590
[epoch19, step657]: loss 0.027596
[epoch19, step658]: loss 0.024963
[epoch19, step659]: loss 0.027596
[epoch19, step660]: loss 0.023840
[epoch19, step661]: loss 0.026265
[epoch19, step662]: loss 0.023847
[epoch19, step663]: loss 0.020681
[epoch19, step664]: loss 0.024991
[epoch19, step665]: loss 0.027700
[epoch19, step666]: loss 0.026546
[epoch19, step667]: loss 0.026024
[epoch19, step668]: loss 0.021908
[epoch19, step669]: loss 0.026527
[epoch19, step670]: loss 0.026491
[epoch19, step671]: loss 0.021340
[epoch19, step672]: loss 0.023442
[epoch19, step673]: loss 0.021926
[epoch19, step674]: loss 0.020951
[epoch19, step675]: loss 0.019815
[epoch19, step676]: loss 0.024394
[epoch19, step677]: loss 0.025036
[epoch19, step678]: loss 0.022960
[epoch19, step679]: loss 0.023825
[epoch19, step680]: loss 0.030336
[epoch19, step681]: loss 0.021901
[epoch19, step682]: loss 0.026185
[epoch19, step683]: loss 0.025801
[epoch19, step684]: loss 0.024390
[epoch19, step685]: loss 0.024294
[epoch19, step686]: loss 0.027018
[epoch19, step687]: loss 0.026396
[epoch19, step688]: loss 0.022134
[epoch19, step689]: loss 0.024480
[epoch19, step690]: loss 0.024811
[epoch19, step691]: loss 0.024115
[epoch19, step692]: loss 0.022454
[epoch19, step693]: loss 0.026486
[epoch19, step694]: loss 0.022751
[epoch19, step695]: loss 0.026484
[epoch19, step696]: loss 0.025915
[epoch19, step697]: loss 0.026565
[epoch19, step698]: loss 0.024489
[epoch19, step699]: loss 0.023346
[epoch19, step700]: loss 0.021472
[epoch19, step701]: loss 0.025482
[epoch19, step702]: loss 0.021408
[epoch19, step703]: loss 0.022692
[epoch19, step704]: loss 0.024622
[epoch19, step705]: loss 0.024634
[epoch19, step706]: loss 0.023873
[epoch19, step707]: loss 0.024726
[epoch19, step708]: loss 0.025793
[epoch19, step709]: loss 0.027592
[epoch19, step710]: loss 0.023272
[epoch19, step711]: loss 0.023165
[epoch19, step712]: loss 0.026130
[epoch19, step713]: loss 0.026235
[epoch19, step714]: loss 0.021096
[epoch19, step715]: loss 0.023156
[epoch19, step716]: loss 0.025236
[epoch19, step717]: loss 0.023581
[epoch19, step718]: loss 0.025150
[epoch19, step719]: loss 0.032266
[epoch19, step720]: loss 0.024403
[epoch19, step721]: loss 0.023053
[epoch19, step722]: loss 0.030566
[epoch19, step723]: loss 0.025604
[epoch19, step724]: loss 0.023127
[epoch19, step725]: loss 0.027597
[epoch19, step726]: loss 0.022140
[epoch19, step727]: loss 0.024372
[epoch19, step728]: loss 0.026052
[epoch19, step729]: loss 0.021156
[epoch19, step730]: loss 0.022500
[epoch19, step731]: loss 0.025552
[epoch19, step732]: loss 0.025445
[epoch19, step733]: loss 0.023811
[epoch19, step734]: loss 0.022541
[epoch19, step735]: loss 0.027329
[epoch19, step736]: loss 0.024757
[epoch19, step737]: loss 0.026273
[epoch19, step738]: loss 0.020381
[epoch19, step739]: loss 0.025227
[epoch19, step740]: loss 0.022305
[epoch19, step741]: loss 0.025097
[epoch19, step742]: loss 0.021402
[epoch19, step743]: loss 0.023299
[epoch19, step744]: loss 0.023832
[epoch19, step745]: loss 0.024233
[epoch19, step746]: loss 0.024475
[epoch19, step747]: loss 0.026719
[epoch19, step748]: loss 0.025531
[epoch19, step749]: loss 0.025985
[epoch19, step750]: loss 0.027071
[epoch19, step751]: loss 0.021562
[epoch19, step752]: loss 0.024685
[epoch19, step753]: loss 0.025249
[epoch19, step754]: loss 0.022351
[epoch19, step755]: loss 0.026067
[epoch19, step756]: loss 0.023377
[epoch19, step757]: loss 0.020488
[epoch19, step758]: loss 0.024831
[epoch19, step759]: loss 0.022850
[epoch19, step760]: loss 0.023697
[epoch19, step761]: loss 0.026098
[epoch19, step762]: loss 0.021361
[epoch19, step763]: loss 0.025079
[epoch19, step764]: loss 0.023203
[epoch19, step765]: loss 0.025953
[epoch19, step766]: loss 0.024400
[epoch19, step767]: loss 0.026096
[epoch19, step768]: loss 0.021382
[epoch19, step769]: loss 0.026497
[epoch19, step770]: loss 0.025451
[epoch19, step771]: loss 0.023090
[epoch19, step772]: loss 0.028361
[epoch19, step773]: loss 0.026567
[epoch19, step774]: loss 0.024208
[epoch19, step775]: loss 0.020569
[epoch19, step776]: loss 0.025382
[epoch19, step777]: loss 0.023034
[epoch19, step778]: loss 0.028149
[epoch19, step779]: loss 0.023961
[epoch19, step780]: loss 0.020004
[epoch19, step781]: loss 0.024227
[epoch19, step782]: loss 0.022277
[epoch19, step783]: loss 0.018935
[epoch19, step784]: loss 0.019972
[epoch19, step785]: loss 0.021257
[epoch19, step786]: loss 0.023796
[epoch19, step787]: loss 0.023197
[epoch19, step788]: loss 0.024585
[epoch19, step789]: loss 0.022305
[epoch19, step790]: loss 0.023034
[epoch19, step791]: loss 0.026642
[epoch19, step792]: loss 0.024848
[epoch19, step793]: loss 0.026663
[epoch19, step794]: loss 0.020291
[epoch19, step795]: loss 0.025333
[epoch19, step796]: loss 0.027475
[epoch19, step797]: loss 0.027394
[epoch19, step798]: loss 0.027077
[epoch19, step799]: loss 0.025894
[epoch19, step800]: loss 0.021296
[epoch19, step801]: loss 0.021485
[epoch19, step802]: loss 0.022470
[epoch19, step803]: loss 0.026066
[epoch19, step804]: loss 0.027278
[epoch19, step805]: loss 0.027865
[epoch19, step806]: loss 0.021072
[epoch19, step807]: loss 0.020324
[epoch19, step808]: loss 0.022641
[epoch19, step809]: loss 0.022853
[epoch19, step810]: loss 0.025887
[epoch19, step811]: loss 0.025858
[epoch19, step812]: loss 0.024175
[epoch19, step813]: loss 0.023375
[epoch19, step814]: loss 0.024877
[epoch19, step815]: loss 0.025076
[epoch19, step816]: loss 0.024001
[epoch19, step817]: loss 0.024456
[epoch19, step818]: loss 0.022620
[epoch19, step819]: loss 0.019778
[epoch19, step820]: loss 0.022982
[epoch19, step821]: loss 0.021576
[epoch19, step822]: loss 0.029934
[epoch19, step823]: loss 0.023704
[epoch19, step824]: loss 0.026439
[epoch19, step825]: loss 0.024733
[epoch19, step826]: loss 0.024362
[epoch19, step827]: loss 0.026529
[epoch19, step828]: loss 0.028557
[epoch19, step829]: loss 0.025872
[epoch19, step830]: loss 0.022344
[epoch19, step831]: loss 0.026231
[epoch19, step832]: loss 0.020748
[epoch19, step833]: loss 0.029026
[epoch19, step834]: loss 0.025024
[epoch19, step835]: loss 0.020409
[epoch19, step836]: loss 0.026229
[epoch19, step837]: loss 0.025090
[epoch19, step838]: loss 0.026090
[epoch19, step839]: loss 0.028296
[epoch19, step840]: loss 0.020348
[epoch19, step841]: loss 0.024372
[epoch19, step842]: loss 0.027610
[epoch19, step843]: loss 0.024513
[epoch19, step844]: loss 0.024664
[epoch19, step845]: loss 0.021024
[epoch19, step846]: loss 0.025360
[epoch19, step847]: loss 0.026256
[epoch19, step848]: loss 0.024832
[epoch19, step849]: loss 0.024823
[epoch19, step850]: loss 0.022691
[epoch19, step851]: loss 0.024018
[epoch19, step852]: loss 0.023172
[epoch19, step853]: loss 0.029287
[epoch19, step854]: loss 0.022746
[epoch19, step855]: loss 0.026901
[epoch19, step856]: loss 0.022309
[epoch19, step857]: loss 0.025778
[epoch19, step858]: loss 0.024254
[epoch19, step859]: loss 0.023486
[epoch19, step860]: loss 0.022724
[epoch19, step861]: loss 0.023167
[epoch19, step862]: loss 0.023023
[epoch19, step863]: loss 0.020257
[epoch19, step864]: loss 0.026276
[epoch19, step865]: loss 0.023128
[epoch19, step866]: loss 0.024848
[epoch19, step867]: loss 0.026332
[epoch19, step868]: loss 0.026530
[epoch19, step869]: loss 0.023748
[epoch19, step870]: loss 0.030616
[epoch19, step871]: loss 0.022036
[epoch19, step872]: loss 0.024956
[epoch19, step873]: loss 0.025475
[epoch19, step874]: loss 0.023681
[epoch19, step875]: loss 0.024037
[epoch19, step876]: loss 0.023809
[epoch19, step877]: loss 0.019147
[epoch19, step878]: loss 0.023416
[epoch19, step879]: loss 0.027399
[epoch19, step880]: loss 0.025394
[epoch19, step881]: loss 0.022100
[epoch19, step882]: loss 0.023598
[epoch19, step883]: loss 0.023728
[epoch19, step884]: loss 0.026322
[epoch19, step885]: loss 0.025826
[epoch19, step886]: loss 0.026489
[epoch19, step887]: loss 0.024021
[epoch19, step888]: loss 0.024301
[epoch19, step889]: loss 0.023350
[epoch19, step890]: loss 0.023554
[epoch19, step891]: loss 0.025102
[epoch19, step892]: loss 0.020754
[epoch19, step893]: loss 0.024465
[epoch19, step894]: loss 0.024759
[epoch19, step895]: loss 0.022450
[epoch19, step896]: loss 0.021480
[epoch19, step897]: loss 0.023533
[epoch19, step898]: loss 0.025297
[epoch19, step899]: loss 0.028037
[epoch19, step900]: loss 0.026942
[epoch19, step901]: loss 0.024971
[epoch19, step902]: loss 0.023978
[epoch19, step903]: loss 0.023953
[epoch19, step904]: loss 0.027629
[epoch19, step905]: loss 0.027364
[epoch19, step906]: loss 0.022144
[epoch19, step907]: loss 0.023557
[epoch19, step908]: loss 0.022262
[epoch19, step909]: loss 0.025271
[epoch19, step910]: loss 0.022896
[epoch19, step911]: loss 0.025321
[epoch19, step912]: loss 0.023841
[epoch19, step913]: loss 0.023504
[epoch19, step914]: loss 0.030021
[epoch19, step915]: loss 0.023816
[epoch19, step916]: loss 0.023659
[epoch19, step917]: loss 0.024797
[epoch19, step918]: loss 0.028436
[epoch19, step919]: loss 0.024363
[epoch19, step920]: loss 0.027446
[epoch19, step921]: loss 0.024047
[epoch19, step922]: loss 0.022953
[epoch19, step923]: loss 0.022347
[epoch19, step924]: loss 0.021337
[epoch19, step925]: loss 0.024934
[epoch19, step926]: loss 0.026410
[epoch19, step927]: loss 0.025645
[epoch19, step928]: loss 0.024589
[epoch19, step929]: loss 0.027375
[epoch19, step930]: loss 0.025582
[epoch19, step931]: loss 0.026927
[epoch19, step932]: loss 0.021495
[epoch19, step933]: loss 0.027988
[epoch19, step934]: loss 0.021986
[epoch19, step935]: loss 0.022041
[epoch19, step936]: loss 0.022307
[epoch19, step937]: loss 0.026805
[epoch19, step938]: loss 0.024839
[epoch19, step939]: loss 0.020458
[epoch19, step940]: loss 0.022872
[epoch19, step941]: loss 0.026907
[epoch19, step942]: loss 0.025183
[epoch19, step943]: loss 0.023008
[epoch19, step944]: loss 0.027550
[epoch19, step945]: loss 0.020321
[epoch19, step946]: loss 0.025092
[epoch19, step947]: loss 0.027811
[epoch19, step948]: loss 0.019164
[epoch19, step949]: loss 0.022506
[epoch19, step950]: loss 0.026592
[epoch19, step951]: loss 0.028222
[epoch19, step952]: loss 0.024967
[epoch19, step953]: loss 0.027210
[epoch19, step954]: loss 0.022225
[epoch19, step955]: loss 0.037184
[epoch19, step956]: loss 0.052359
[epoch19, step957]: loss 0.046586
[epoch19, step958]: loss 0.043726
[epoch19, step959]: loss 0.046477
[epoch19, step960]: loss 0.042230
[epoch19, step961]: loss 0.042638
[epoch19, step962]: loss 0.040963
[epoch19, step963]: loss 0.039638
[epoch19, step964]: loss 0.039523
[epoch19, step965]: loss 0.039144
[epoch19, step966]: loss 0.038099
[epoch19, step967]: loss 0.036795
[epoch19, step968]: loss 0.039131
[epoch19, step969]: loss 0.038766
[epoch19, step970]: loss 0.036771
[epoch19, step971]: loss 0.035594
[epoch19, step972]: loss 0.037577
[epoch19, step973]: loss 0.036543
[epoch19, step974]: loss 0.038393
[epoch19, step975]: loss 0.035558
[epoch19, step976]: loss 0.034551
[epoch19, step977]: loss 0.038368
[epoch19, step978]: loss 0.036882
[epoch19, step979]: loss 0.035807
[epoch19, step980]: loss 0.034270
[epoch19, step981]: loss 0.036371
[epoch19, step982]: loss 0.037112
[epoch19, step983]: loss 0.037657
[epoch19, step984]: loss 0.034520
[epoch19, step985]: loss 0.035045
[epoch19, step986]: loss 0.038832
[epoch19, step987]: loss 0.037388
[epoch19, step988]: loss 0.036465
[epoch19, step989]: loss 0.035788
[epoch19, step990]: loss 0.036540
[epoch19, step991]: loss 0.037462
[epoch19, step992]: loss 0.037254
[epoch19, step993]: loss 0.035055
[epoch19, step994]: loss 0.034346
[epoch19, step995]: loss 0.038142
[epoch19, step996]: loss 0.036280
[epoch19, step997]: loss 0.035921
[epoch19, step998]: loss 0.035391
[epoch19, step999]: loss 0.036380
[epoch19, step1000]: loss 0.036803
[epoch19, step1001]: loss 0.037140
[epoch19, step1002]: loss 0.035140
[epoch19, step1003]: loss 0.034477
[epoch19, step1004]: loss 0.038103
[epoch19, step1005]: loss 0.035592
[epoch19, step1006]: loss 0.035784
[epoch19, step1007]: loss 0.034442
[epoch19, step1008]: loss 0.035850
[epoch19, step1009]: loss 0.036080
[epoch19, step1010]: loss 0.038016
[epoch19, step1011]: loss 0.035045
[epoch19, step1012]: loss 0.034691
[epoch19, step1013]: loss 0.037752
[epoch19, step1014]: loss 0.036525
[epoch19, step1015]: loss 0.036067
[epoch19, step1016]: loss 0.034177
[epoch19, step1017]: loss 0.035745
[epoch19, step1018]: loss 0.036212
[epoch19, step1019]: loss 0.036808
[epoch19, step1020]: loss 0.034430
[epoch19, step1021]: loss 0.034086
[epoch19, step1022]: loss 0.037170
[epoch19, step1023]: loss 0.035912
[epoch19, step1024]: loss 0.036105
[epoch19, step1025]: loss 0.034276
[epoch19, step1026]: loss 0.035212
[epoch19, step1027]: loss 0.035889
[epoch19, step1028]: loss 0.037001
[epoch19, step1029]: loss 0.034185
[epoch19, step1030]: loss 0.033882
[epoch19, step1031]: loss 0.036524
[epoch19, step1032]: loss 0.036125
[epoch19, step1033]: loss 0.035710
[epoch19, step1034]: loss 0.033857
[epoch19, step1035]: loss 0.035009
[epoch19, step1036]: loss 0.035998
[epoch19, step1037]: loss 0.036399
[epoch19, step1038]: loss 0.034297
[epoch19, step1039]: loss 0.034125
[epoch19, step1040]: loss 0.036411
[epoch19, step1041]: loss 0.035386
[epoch19, step1042]: loss 0.034467
[epoch19, step1043]: loss 0.033856
[epoch19, step1044]: loss 0.035547
[epoch19, step1045]: loss 0.036008
[epoch19, step1046]: loss 0.036597
[epoch19, step1047]: loss 0.034527
[epoch19, step1048]: loss 0.033598
[epoch19, step1049]: loss 0.037017
[epoch19, step1050]: loss 0.036748
[epoch19, step1051]: loss 0.035207
[epoch19, step1052]: loss 0.034947
[epoch19, step1053]: loss 0.036170
[epoch19, step1054]: loss 0.036150
[epoch19, step1055]: loss 0.036855
[epoch19, step1056]: loss 0.034195
[epoch19, step1057]: loss 0.034733
[epoch19, step1058]: loss 0.038461
[epoch19, step1059]: loss 0.036029
[epoch19, step1060]: loss 0.035535
[epoch19, step1061]: loss 0.033745
[epoch19, step1062]: loss 0.035771
[epoch19, step1063]: loss 0.035671
[epoch19, step1064]: loss 0.036301
[epoch19, step1065]: loss 0.034623
[epoch19, step1066]: loss 0.033982
[epoch19, step1067]: loss 0.037024
[epoch19, step1068]: loss 0.035159
[epoch19, step1069]: loss 0.034974
[epoch19, step1070]: loss 0.034226
[epoch19, step1071]: loss 0.036083
[epoch19, step1072]: loss 0.036450
[epoch19, step1073]: loss 0.037011
[epoch19, step1074]: loss 0.034992
[epoch19, step1075]: loss 0.034011
[epoch19, step1076]: loss 0.037327
[epoch19, step1077]: loss 0.035774
[epoch19, step1078]: loss 0.035064
[epoch19, step1079]: loss 0.034870
[epoch19, step1080]: loss 0.035548
[epoch19, step1081]: loss 0.035722
[epoch19, step1082]: loss 0.036235
[epoch19, step1083]: loss 0.035186
[epoch19, step1084]: loss 0.034318
[epoch19, step1085]: loss 0.036669
[epoch19, step1086]: loss 0.035361
[epoch19, step1087]: loss 0.035340
[epoch19, step1088]: loss 0.034121
[epoch19, step1089]: loss 0.035642
[epoch19, step1090]: loss 0.036453
[epoch19, step1091]: loss 0.037232
[epoch19, step1092]: loss 0.034250
[epoch19, step1093]: loss 0.034389
[epoch19, step1094]: loss 0.036914
[epoch19, step1095]: loss 0.035213
[epoch19, step1096]: loss 0.035218
[epoch19, step1097]: loss 0.034283
[epoch19, step1098]: loss 0.035889
[epoch19, step1099]: loss 0.035659
[epoch19, step1100]: loss 0.036849
[epoch19, step1101]: loss 0.034789
[epoch19, step1102]: loss 0.033841
[epoch19, step1103]: loss 0.036384
[epoch19, step1104]: loss 0.035469
[epoch19, step1105]: loss 0.035382
[epoch19, step1106]: loss 0.033013
[epoch19, step1107]: loss 0.035761
[epoch19, step1108]: loss 0.035444
[epoch19, step1109]: loss 0.037058
[epoch19, step1110]: loss 0.034985
[epoch19, step1111]: loss 0.033936
[epoch19, step1112]: loss 0.037241
[epoch19, step1113]: loss 0.035089
[epoch19, step1114]: loss 0.035640
[epoch19, step1115]: loss 0.034541
[epoch19, step1116]: loss 0.035519
[epoch19, step1117]: loss 0.035966
[epoch19, step1118]: loss 0.036138
[epoch19, step1119]: loss 0.034600
[epoch19, step1120]: loss 0.034049
[epoch19, step1121]: loss 0.036705
[epoch19, step1122]: loss 0.035391
[epoch19, step1123]: loss 0.034577
[epoch19, step1124]: loss 0.034861
[epoch19, step1125]: loss 0.036190
[epoch19, step1126]: loss 0.036605
[epoch19, step1127]: loss 0.036792
[epoch19, step1128]: loss 0.034795
[epoch19, step1129]: loss 0.033650
[epoch19, step1130]: loss 0.037924
[epoch19, step1131]: loss 0.035679
[epoch19, step1132]: loss 0.035757
[epoch19, step1133]: loss 0.033577
[epoch19, step1134]: loss 0.035094
[epoch19, step1135]: loss 0.036466
[epoch19, step1136]: loss 0.037172
[epoch19, step1137]: loss 0.034453
[epoch19, step1138]: loss 0.034161
[epoch19, step1139]: loss 0.036884
[epoch19, step1140]: loss 0.034939
[epoch19, step1141]: loss 0.034922
[epoch19, step1142]: loss 0.033892
[epoch19, step1143]: loss 0.034970
[epoch19, step1144]: loss 0.036126
[epoch19, step1145]: loss 0.035803
[epoch19, step1146]: loss 0.034220
[epoch19, step1147]: loss 0.034834
[epoch19, step1148]: loss 0.036948
[epoch19, step1149]: loss 0.035310
[epoch19, step1150]: loss 0.034888
[epoch19, step1151]: loss 0.035026
[epoch19, step1152]: loss 0.036272
[epoch19, step1153]: loss 0.035296
[epoch19, step1154]: loss 0.037077
[epoch19, step1155]: loss 0.034339
[epoch19, step1156]: loss 0.033696
[epoch19, step1157]: loss 0.036626
[epoch19, step1158]: loss 0.035737
[epoch19, step1159]: loss 0.035488
[epoch19, step1160]: loss 0.034646
[epoch19, step1161]: loss 0.035653
[epoch19, step1162]: loss 0.035657
[epoch19, step1163]: loss 0.035865
[epoch19, step1164]: loss 0.034581
[epoch19, step1165]: loss 0.035023
[epoch19, step1166]: loss 0.037045
[epoch19, step1167]: loss 0.034587
[epoch19, step1168]: loss 0.035410
[epoch19, step1169]: loss 0.033820
[epoch19, step1170]: loss 0.035368
[epoch19, step1171]: loss 0.036107
[epoch19, step1172]: loss 0.036345
[epoch19, step1173]: loss 0.034649
[epoch19, step1174]: loss 0.034426
[epoch19, step1175]: loss 0.036784
[epoch19, step1176]: loss 0.035215
[epoch19, step1177]: loss 0.035592
[epoch19, step1178]: loss 0.034472
[epoch19, step1179]: loss 0.036239
[epoch19, step1180]: loss 0.035731
[epoch19, step1181]: loss 0.037503
[epoch19, step1182]: loss 0.034089
[epoch19, step1183]: loss 0.034483
[epoch19, step1184]: loss 0.036590
[epoch19, step1185]: loss 0.035826
[epoch19, step1186]: loss 0.034250
[epoch19, step1187]: loss 0.033307
[epoch19, step1188]: loss 0.034670
[epoch19, step1189]: loss 0.035027
[epoch19, step1190]: loss 0.036008
[epoch19, step1191]: loss 0.034808
[epoch19, step1192]: loss 0.033914
[epoch19, step1193]: loss 0.036549
[epoch19, step1194]: loss 0.035093
[epoch19, step1195]: loss 0.034065
[epoch19, step1196]: loss 0.033325
[epoch19, step1197]: loss 0.035727
[epoch19, step1198]: loss 0.035862
[epoch19, step1199]: loss 0.035971
[epoch19, step1200]: loss 0.033962
[epoch19, step1201]: loss 0.034627
[epoch19, step1202]: loss 0.037933
[epoch19, step1203]: loss 0.035940
[epoch19, step1204]: loss 0.034371
[epoch19, step1205]: loss 0.034273
[epoch19, step1206]: loss 0.035756
[epoch19, step1207]: loss 0.036214
[epoch19, step1208]: loss 0.037179
[epoch19, step1209]: loss 0.033611
[epoch19, step1210]: loss 0.034488
[epoch19, step1211]: loss 0.036894
[epoch19, step1212]: loss 0.035482
[epoch19, step1213]: loss 0.034573
[epoch19, step1214]: loss 0.034133
[epoch19, step1215]: loss 0.036113
[epoch19, step1216]: loss 0.035160
[epoch19, step1217]: loss 0.036754
[epoch19, step1218]: loss 0.033814
[epoch19, step1219]: loss 0.034170
[epoch19, step1220]: loss 0.036897
[epoch19, step1221]: loss 0.034642
[epoch19, step1222]: loss 0.035205
[epoch19, step1223]: loss 0.034331
[epoch19, step1224]: loss 0.035824
[epoch19, step1225]: loss 0.035821
[epoch19, step1226]: loss 0.035783
[epoch19, step1227]: loss 0.034162
[epoch19, step1228]: loss 0.034045
[epoch19, step1229]: loss 0.036708
[epoch19, step1230]: loss 0.035766
[epoch19, step1231]: loss 0.035014
[epoch19, step1232]: loss 0.034941
[epoch19, step1233]: loss 0.035201
[epoch19, step1234]: loss 0.035496
[epoch19, step1235]: loss 0.037105
[epoch19, step1236]: loss 0.034343
[epoch19, step1237]: loss 0.033920
[epoch19, step1238]: loss 0.036082
[epoch19, step1239]: loss 0.036182
[epoch19, step1240]: loss 0.035307
[epoch19, step1241]: loss 0.033455
[epoch19, step1242]: loss 0.035155
[epoch19, step1243]: loss 0.035396
[epoch19, step1244]: loss 0.037023
[epoch19, step1245]: loss 0.034396
[epoch19, step1246]: loss 0.034422
[epoch19, step1247]: loss 0.036124
[epoch19, step1248]: loss 0.035735
[epoch19, step1249]: loss 0.035807
[epoch19, step1250]: loss 0.033985
[epoch19, step1251]: loss 0.036217
[epoch19, step1252]: loss 0.036500
[epoch19, step1253]: loss 0.036865
[epoch19, step1254]: loss 0.034355
[epoch19, step1255]: loss 0.033900
[epoch19, step1256]: loss 0.036930
[epoch19, step1257]: loss 0.035957
[epoch19, step1258]: loss 0.035529
[epoch19, step1259]: loss 0.034020
[epoch19, step1260]: loss 0.035522
[epoch19, step1261]: loss 0.035374
[epoch19, step1262]: loss 0.035810
[epoch19, step1263]: loss 0.034907
[epoch19, step1264]: loss 0.033830
[epoch19, step1265]: loss 0.035868
[epoch19, step1266]: loss 0.035176
[epoch19, step1267]: loss 0.035458
[epoch19, step1268]: loss 0.034412
[epoch19, step1269]: loss 0.035427
[epoch19, step1270]: loss 0.035347
[epoch19, step1271]: loss 0.037182
[epoch19, step1272]: loss 0.034408
[epoch19, step1273]: loss 0.033799
[epoch19, step1274]: loss 0.037311
[epoch19, step1275]: loss 0.035816
[epoch19, step1276]: loss 0.035421
[epoch19, step1277]: loss 0.033935
[epoch19, step1278]: loss 0.036092
[epoch19, step1279]: loss 0.036066
[epoch19, step1280]: loss 0.036464
[epoch19, step1281]: loss 0.034066
[epoch19, step1282]: loss 0.034139
[epoch19, step1283]: loss 0.036117
[epoch19, step1284]: loss 0.035087
[epoch19, step1285]: loss 0.035540
[epoch19, step1286]: loss 0.033712
[epoch19, step1287]: loss 0.036047
[epoch19, step1288]: loss 0.036450
[epoch19, step1289]: loss 0.037633
[epoch19, step1290]: loss 0.034109
[epoch19, step1291]: loss 0.033605
[epoch19, step1292]: loss 0.037752
[epoch19, step1293]: loss 0.035010
[epoch19, step1294]: loss 0.035675
[epoch19, step1295]: loss 0.034528
[epoch19, step1296]: loss 0.035546
[epoch19, step1297]: loss 0.035731
[epoch19, step1298]: loss 0.036955
[epoch19, step1299]: loss 0.034474
[epoch19, step1300]: loss 0.034560
[epoch19, step1301]: loss 0.036185
[epoch19, step1302]: loss 0.035726
[epoch19, step1303]: loss 0.035267
[epoch19, step1304]: loss 0.033824
[epoch19, step1305]: loss 0.035652
[epoch19, step1306]: loss 0.035882
[epoch19, step1307]: loss 0.036040
[epoch19, step1308]: loss 0.034571
[epoch19, step1309]: loss 0.033652
[epoch19, step1310]: loss 0.036699
[epoch19, step1311]: loss 0.034615
[epoch19, step1312]: loss 0.036202
[epoch19, step1313]: loss 0.033936
[epoch19, step1314]: loss 0.035221
[epoch19, step1315]: loss 0.035189
[epoch19, step1316]: loss 0.037603
[epoch19, step1317]: loss 0.033640
[epoch19, step1318]: loss 0.033719
[epoch19, step1319]: loss 0.036143
[epoch19, step1320]: loss 0.035336
[epoch19, step1321]: loss 0.035483
[epoch19, step1322]: loss 0.033850
[epoch19, step1323]: loss 0.035645
[epoch19, step1324]: loss 0.035507
[epoch19, step1325]: loss 0.036273
[epoch19, step1326]: loss 0.034171
[epoch19, step1327]: loss 0.033997
[epoch19, step1328]: loss 0.036780
[epoch19, step1329]: loss 0.035340
[epoch19, step1330]: loss 0.035457
[epoch19, step1331]: loss 0.033765
[epoch19, step1332]: loss 0.035718
[epoch19, step1333]: loss 0.034860
[epoch19, step1334]: loss 0.037282
[epoch19, step1335]: loss 0.035430
[epoch19, step1336]: loss 0.033452
[epoch19, step1337]: loss 0.036403
[epoch19, step1338]: loss 0.035585
[epoch19, step1339]: loss 0.035418
[epoch19, step1340]: loss 0.033539
[epoch19, step1341]: loss 0.035445
[epoch19, step1342]: loss 0.035393
[epoch19, step1343]: loss 0.036550
[epoch19, step1344]: loss 0.034318
[epoch19, step1345]: loss 0.033764
[epoch19, step1346]: loss 0.036194
[epoch19, step1347]: loss 0.035806
[epoch19, step1348]: loss 0.034513
[epoch19, step1349]: loss 0.034139
[epoch19, step1350]: loss 0.035875
[epoch19, step1351]: loss 0.035434
[epoch19, step1352]: loss 0.036238
[epoch19, step1353]: loss 0.033928
[epoch19, step1354]: loss 0.034264
[epoch19, step1355]: loss 0.037058
[epoch19, step1356]: loss 0.035491
[epoch19, step1357]: loss 0.035734
[epoch19, step1358]: loss 0.033629
[epoch19, step1359]: loss 0.035179
[epoch19, step1360]: loss 0.036458
[epoch19, step1361]: loss 0.036494
[epoch19, step1362]: loss 0.034694
[epoch19, step1363]: loss 0.034252
[epoch19, step1364]: loss 0.036797
[epoch19, step1365]: loss 0.035369
[epoch19, step1366]: loss 0.034996
[epoch19, step1367]: loss 0.033047
[epoch19, step1368]: loss 0.036010
[epoch19, step1369]: loss 0.035787
[epoch19, step1370]: loss 0.036090
[epoch19, step1371]: loss 0.034583
[epoch19, step1372]: loss 0.033785
[epoch19, step1373]: loss 0.036632
[epoch19, step1374]: loss 0.035827
[epoch19, step1375]: loss 0.035934
[epoch19, step1376]: loss 0.034099
[epoch19, step1377]: loss 0.034801
[epoch19, step1378]: loss 0.035654
[epoch19, step1379]: loss 0.036125
[epoch19, step1380]: loss 0.034524
[epoch19, step1381]: loss 0.033829
[epoch19, step1382]: loss 0.036936
[epoch19, step1383]: loss 0.035302
[epoch19, step1384]: loss 0.034816
[epoch19, step1385]: loss 0.033584
[epoch19, step1386]: loss 0.036027
[epoch19, step1387]: loss 0.035817
[epoch19, step1388]: loss 0.035955
[epoch19, step1389]: loss 0.034051
[epoch19, step1390]: loss 0.034111
[epoch19, step1391]: loss 0.036595
[epoch19, step1392]: loss 0.035914
[epoch19, step1393]: loss 0.035119
[epoch19, step1394]: loss 0.034702
[epoch19, step1395]: loss 0.035435
[epoch19, step1396]: loss 0.035446
[epoch19, step1397]: loss 0.036502
[epoch19, step1398]: loss 0.033732
[epoch19, step1399]: loss 0.034583
[epoch19, step1400]: loss 0.037149
[epoch19, step1401]: loss 0.035001
[epoch19, step1402]: loss 0.035190
[epoch19, step1403]: loss 0.032814
[epoch19, step1404]: loss 0.034918
[epoch19, step1405]: loss 0.035457
[epoch19, step1406]: loss 0.035910
[epoch19, step1407]: loss 0.035240
[epoch19, step1408]: loss 0.033751
[epoch19, step1409]: loss 0.036339
[epoch19, step1410]: loss 0.035685
[epoch19, step1411]: loss 0.034173
[epoch19, step1412]: loss 0.034371
[epoch19, step1413]: loss 0.036160
[epoch19, step1414]: loss 0.035221
[epoch19, step1415]: loss 0.036680
[epoch19, step1416]: loss 0.034974
[epoch19, step1417]: loss 0.034141
[epoch19, step1418]: loss 0.036551
[epoch19, step1419]: loss 0.036301
[epoch19, step1420]: loss 0.035454
[epoch19, step1421]: loss 0.034251
[epoch19, step1422]: loss 0.036014
[epoch19, step1423]: loss 0.035067
[epoch19, step1424]: loss 0.036217
[epoch19, step1425]: loss 0.033451
[epoch19, step1426]: loss 0.033810
[epoch19, step1427]: loss 0.037904
[epoch19, step1428]: loss 0.036306
[epoch19, step1429]: loss 0.035060
[epoch19, step1430]: loss 0.034120
[epoch19, step1431]: loss 0.035909
[epoch19, step1432]: loss 0.035078
[epoch19, step1433]: loss 0.036833
[epoch19, step1434]: loss 0.034364
[epoch19, step1435]: loss 0.034264
[epoch19, step1436]: loss 0.037032
[epoch19, step1437]: loss 0.035768
[epoch19, step1438]: loss 0.035752
[epoch19, step1439]: loss 0.033739
[epoch19, step1440]: loss 0.035298
[epoch19, step1441]: loss 0.035791
[epoch19, step1442]: loss 0.035273
[epoch19, step1443]: loss 0.033847
[epoch19, step1444]: loss 0.032869
[epoch19, step1445]: loss 0.036787
[epoch19, step1446]: loss 0.035570
[epoch19, step1447]: loss 0.035607
[epoch19, step1448]: loss 0.033736
[epoch19, step1449]: loss 0.034800
[epoch19, step1450]: loss 0.035909
[epoch19, step1451]: loss 0.036892
[epoch19, step1452]: loss 0.033709
[epoch19, step1453]: loss 0.035370
[epoch19, step1454]: loss 0.037251
[epoch19, step1455]: loss 0.036177
[epoch19, step1456]: loss 0.035103
[epoch19, step1457]: loss 0.034156
[epoch19, step1458]: loss 0.035456
[epoch19, step1459]: loss 0.035560
[epoch19, step1460]: loss 0.036635
[epoch19, step1461]: loss 0.034648
[epoch19, step1462]: loss 0.034376
[epoch19, step1463]: loss 0.036667
[epoch19, step1464]: loss 0.035818
[epoch19, step1465]: loss 0.034579
[epoch19, step1466]: loss 0.033412
[epoch19, step1467]: loss 0.035070
[epoch19, step1468]: loss 0.035434
[epoch19, step1469]: loss 0.036359
[epoch19, step1470]: loss 0.034219
[epoch19, step1471]: loss 0.033752
[epoch19, step1472]: loss 0.036631
[epoch19, step1473]: loss 0.035717
[epoch19, step1474]: loss 0.035564
[epoch19, step1475]: loss 0.033756
[epoch19, step1476]: loss 0.036501
[epoch19, step1477]: loss 0.035285
[epoch19, step1478]: loss 0.036340
[epoch19, step1479]: loss 0.034144
[epoch19, step1480]: loss 0.033889
[epoch19, step1481]: loss 0.035706
[epoch19, step1482]: loss 0.035007
[epoch19, step1483]: loss 0.035129
[epoch19, step1484]: loss 0.033859
[epoch19, step1485]: loss 0.035385
[epoch19, step1486]: loss 0.034587
[epoch19, step1487]: loss 0.035915
[epoch19, step1488]: loss 0.034154
[epoch19, step1489]: loss 0.034191
[epoch19, step1490]: loss 0.036676
[epoch19, step1491]: loss 0.036200
[epoch19, step1492]: loss 0.036153
[epoch19, step1493]: loss 0.034287
[epoch19, step1494]: loss 0.035682
[epoch19, step1495]: loss 0.035812
[epoch19, step1496]: loss 0.035351
[epoch19, step1497]: loss 0.034180
[epoch19, step1498]: loss 0.034474
[epoch19, step1499]: loss 0.035781
[epoch19, step1500]: loss 0.035719
[epoch19, step1501]: loss 0.034922
[epoch19, step1502]: loss 0.033347
[epoch19, step1503]: loss 0.035333
[epoch19, step1504]: loss 0.034880
[epoch19, step1505]: loss 0.036525
[epoch19, step1506]: loss 0.033472
[epoch19, step1507]: loss 0.034052
[epoch19, step1508]: loss 0.037501
[epoch19, step1509]: loss 0.034564
[epoch19, step1510]: loss 0.034633
[epoch19, step1511]: loss 0.034499
[epoch19, step1512]: loss 0.035540
[epoch19, step1513]: loss 0.034518
[epoch19, step1514]: loss 0.036136
[epoch19, step1515]: loss 0.034498
[epoch19, step1516]: loss 0.034298

[epoch19]: avg loss 0.032685

[epoch20, step1]: loss 0.030497
[epoch20, step2]: loss 0.036802
[epoch20, step3]: loss 0.036616
[epoch20, step4]: loss 0.034072
[epoch20, step5]: loss 0.034976
[epoch20, step6]: loss 0.037159
[epoch20, step7]: loss 0.034913
[epoch20, step8]: loss 0.036831
[epoch20, step9]: loss 0.033807
[epoch20, step10]: loss 0.034498
[epoch20, step11]: loss 0.036884
[epoch20, step12]: loss 0.036051
[epoch20, step13]: loss 0.033983
[epoch20, step14]: loss 0.034125
[epoch20, step15]: loss 0.036214
[epoch20, step16]: loss 0.034700
[epoch20, step17]: loss 0.036963
[epoch20, step18]: loss 0.034267
[epoch20, step19]: loss 0.034392
[epoch20, step20]: loss 0.037119
[epoch20, step21]: loss 0.035986
[epoch20, step22]: loss 0.033930
[epoch20, step23]: loss 0.033739
[epoch20, step24]: loss 0.036635
[epoch20, step25]: loss 0.034097
[epoch20, step26]: loss 0.036113
[epoch20, step27]: loss 0.033425
[epoch20, step28]: loss 0.034714
[epoch20, step29]: loss 0.036516
[epoch20, step30]: loss 0.036849
[epoch20, step31]: loss 0.033730
[epoch20, step32]: loss 0.034785
[epoch20, step33]: loss 0.037082
[epoch20, step34]: loss 0.034876
[epoch20, step35]: loss 0.037077
[epoch20, step36]: loss 0.033823
[epoch20, step37]: loss 0.034366
[epoch20, step38]: loss 0.036837
[epoch20, step39]: loss 0.036293
[epoch20, step40]: loss 0.034008
[epoch20, step41]: loss 0.033774
[epoch20, step42]: loss 0.036541
[epoch20, step43]: loss 0.034181
[epoch20, step44]: loss 0.037533
[epoch20, step45]: loss 0.034160
[epoch20, step46]: loss 0.034916
[epoch20, step47]: loss 0.036199
[epoch20, step48]: loss 0.036273
[epoch20, step49]: loss 0.032623
[epoch20, step50]: loss 0.034158
[epoch20, step51]: loss 0.036879
[epoch20, step52]: loss 0.034220
[epoch20, step53]: loss 0.036950
[epoch20, step54]: loss 0.033429
[epoch20, step55]: loss 0.035127
[epoch20, step56]: loss 0.037367
[epoch20, step57]: loss 0.036598
[epoch20, step58]: loss 0.033908
[epoch20, step59]: loss 0.033046
[epoch20, step60]: loss 0.036896
[epoch20, step61]: loss 0.033666
[epoch20, step62]: loss 0.036020
[epoch20, step63]: loss 0.033505
[epoch20, step64]: loss 0.034190
[epoch20, step65]: loss 0.036585
[epoch20, step66]: loss 0.036340
[epoch20, step67]: loss 0.033976
[epoch20, step68]: loss 0.034159
[epoch20, step69]: loss 0.036429
[epoch20, step70]: loss 0.034271
[epoch20, step71]: loss 0.036406
[epoch20, step72]: loss 0.033950
[epoch20, step73]: loss 0.034543
[epoch20, step74]: loss 0.036160
[epoch20, step75]: loss 0.036616
[epoch20, step76]: loss 0.034473
[epoch20, step77]: loss 0.034741
[epoch20, step78]: loss 0.036864
[epoch20, step79]: loss 0.034226
[epoch20, step80]: loss 0.037578
[epoch20, step81]: loss 0.033596
[epoch20, step82]: loss 0.034088
[epoch20, step83]: loss 0.036332
[epoch20, step84]: loss 0.036411
[epoch20, step85]: loss 0.034523
[epoch20, step86]: loss 0.034554
[epoch20, step87]: loss 0.037453
[epoch20, step88]: loss 0.033303
[epoch20, step89]: loss 0.036497
[epoch20, step90]: loss 0.034479
[epoch20, step91]: loss 0.034160
[epoch20, step92]: loss 0.036537
[epoch20, step93]: loss 0.036833
[epoch20, step94]: loss 0.033519
[epoch20, step95]: loss 0.034486
[epoch20, step96]: loss 0.036263
[epoch20, step97]: loss 0.034954
[epoch20, step98]: loss 0.036463
[epoch20, step99]: loss 0.033577
[epoch20, step100]: loss 0.033190
[epoch20, step101]: loss 0.037094
[epoch20, step102]: loss 0.036555
[epoch20, step103]: loss 0.034004
[epoch20, step104]: loss 0.033870
[epoch20, step105]: loss 0.037043
[epoch20, step106]: loss 0.034299
[epoch20, step107]: loss 0.036948
[epoch20, step108]: loss 0.034002
[epoch20, step109]: loss 0.033956
[epoch20, step110]: loss 0.037277
[epoch20, step111]: loss 0.035950
[epoch20, step112]: loss 0.034050
[epoch20, step113]: loss 0.034806
[epoch20, step114]: loss 0.036648
[epoch20, step115]: loss 0.034331
[epoch20, step116]: loss 0.037024
[epoch20, step117]: loss 0.033651
[epoch20, step118]: loss 0.035251
[epoch20, step119]: loss 0.037148
[epoch20, step120]: loss 0.037107
[epoch20, step121]: loss 0.034216
[epoch20, step122]: loss 0.034454
[epoch20, step123]: loss 0.037407
[epoch20, step124]: loss 0.034459
[epoch20, step125]: loss 0.037195
[epoch20, step126]: loss 0.033921
[epoch20, step127]: loss 0.034346
[epoch20, step128]: loss 0.036590
[epoch20, step129]: loss 0.036031
[epoch20, step130]: loss 0.034024
[epoch20, step131]: loss 0.033619
[epoch20, step132]: loss 0.036529
[epoch20, step133]: loss 0.034344
[epoch20, step134]: loss 0.035618
[epoch20, step135]: loss 0.034456
[epoch20, step136]: loss 0.035056
[epoch20, step137]: loss 0.036937
[epoch20, step138]: loss 0.036861
[epoch20, step139]: loss 0.033754
[epoch20, step140]: loss 0.034668
[epoch20, step141]: loss 0.036769
[epoch20, step142]: loss 0.034478
[epoch20, step143]: loss 0.036672
[epoch20, step144]: loss 0.033922
[epoch20, step145]: loss 0.035057
[epoch20, step146]: loss 0.037369
[epoch20, step147]: loss 0.037241
[epoch20, step148]: loss 0.033802
[epoch20, step149]: loss 0.033581
[epoch20, step150]: loss 0.035995
[epoch20, step151]: loss 0.034208
[epoch20, step152]: loss 0.036025
[epoch20, step153]: loss 0.033714
[epoch20, step154]: loss 0.034060
[epoch20, step155]: loss 0.036430
[epoch20, step156]: loss 0.035704
[epoch20, step157]: loss 0.033957
[epoch20, step158]: loss 0.034201
[epoch20, step159]: loss 0.036598
[epoch20, step160]: loss 0.034712
[epoch20, step161]: loss 0.036818
[epoch20, step162]: loss 0.034426
[epoch20, step163]: loss 0.034464
[epoch20, step164]: loss 0.037118
[epoch20, step165]: loss 0.036739
[epoch20, step166]: loss 0.034512
[epoch20, step167]: loss 0.034000
[epoch20, step168]: loss 0.037884
[epoch20, step169]: loss 0.034309
[epoch20, step170]: loss 0.037015
[epoch20, step171]: loss 0.034387
[epoch20, step172]: loss 0.034555
[epoch20, step173]: loss 0.036692
[epoch20, step174]: loss 0.036040
[epoch20, step175]: loss 0.034594
[epoch20, step176]: loss 0.034252
[epoch20, step177]: loss 0.036855
[epoch20, step178]: loss 0.034172
[epoch20, step179]: loss 0.035608
[epoch20, step180]: loss 0.033987
[epoch20, step181]: loss 0.034134
[epoch20, step182]: loss 0.036666
[epoch20, step183]: loss 0.036770
[epoch20, step184]: loss 0.035071
[epoch20, step185]: loss 0.034241
[epoch20, step186]: loss 0.036513
[epoch20, step187]: loss 0.034360
[epoch20, step188]: loss 0.035982
[epoch20, step189]: loss 0.033912
[epoch20, step190]: loss 0.033547
[epoch20, step191]: loss 0.036825
[epoch20, step192]: loss 0.036983
[epoch20, step193]: loss 0.032563
[epoch20, step194]: loss 0.033783
[epoch20, step195]: loss 0.036850
[epoch20, step196]: loss 0.034742
[epoch20, step197]: loss 0.037510
[epoch20, step198]: loss 0.033357
[epoch20, step199]: loss 0.034300
[epoch20, step200]: loss 0.037200
[epoch20, step201]: loss 0.036647
[epoch20, step202]: loss 0.033594
[epoch20, step203]: loss 0.033836
[epoch20, step204]: loss 0.036803
[epoch20, step205]: loss 0.033811
[epoch20, step206]: loss 0.036145
[epoch20, step207]: loss 0.033546
[epoch20, step208]: loss 0.034534
[epoch20, step209]: loss 0.036984
[epoch20, step210]: loss 0.037047
[epoch20, step211]: loss 0.034406
[epoch20, step212]: loss 0.034342
[epoch20, step213]: loss 0.036324
[epoch20, step214]: loss 0.033916
[epoch20, step215]: loss 0.036661
[epoch20, step216]: loss 0.034069
[epoch20, step217]: loss 0.033770
[epoch20, step218]: loss 0.036955
[epoch20, step219]: loss 0.035876
[epoch20, step220]: loss 0.034521
[epoch20, step221]: loss 0.034392
[epoch20, step222]: loss 0.036898
[epoch20, step223]: loss 0.034554
[epoch20, step224]: loss 0.036132
[epoch20, step225]: loss 0.034172
[epoch20, step226]: loss 0.034343
[epoch20, step227]: loss 0.035802
[epoch20, step228]: loss 0.037160
[epoch20, step229]: loss 0.033511
[epoch20, step230]: loss 0.034106
[epoch20, step231]: loss 0.037208
[epoch20, step232]: loss 0.034532
[epoch20, step233]: loss 0.035711
[epoch20, step234]: loss 0.033324
[epoch20, step235]: loss 0.034532
[epoch20, step236]: loss 0.036625
[epoch20, step237]: loss 0.036327
[epoch20, step238]: loss 0.034033
[epoch20, step239]: loss 0.033055
[epoch20, step240]: loss 0.035987
[epoch20, step241]: loss 0.034588
[epoch20, step242]: loss 0.036498
[epoch20, step243]: loss 0.034687
[epoch20, step244]: loss 0.034114
[epoch20, step245]: loss 0.036405
[epoch20, step246]: loss 0.036006
[epoch20, step247]: loss 0.034637
[epoch20, step248]: loss 0.033776
[epoch20, step249]: loss 0.035885
[epoch20, step250]: loss 0.034950
[epoch20, step251]: loss 0.036988
[epoch20, step252]: loss 0.034655
[epoch20, step253]: loss 0.033479
[epoch20, step254]: loss 0.036313
[epoch20, step255]: loss 0.036797
[epoch20, step256]: loss 0.034141
[epoch20, step257]: loss 0.034026
[epoch20, step258]: loss 0.037148
[epoch20, step259]: loss 0.034761
[epoch20, step260]: loss 0.036050
[epoch20, step261]: loss 0.034863
[epoch20, step262]: loss 0.034691
[epoch20, step263]: loss 0.036332
[epoch20, step264]: loss 0.035939
[epoch20, step265]: loss 0.034340
[epoch20, step266]: loss 0.033846
[epoch20, step267]: loss 0.036171
[epoch20, step268]: loss 0.034298
[epoch20, step269]: loss 0.036438
[epoch20, step270]: loss 0.033628
[epoch20, step271]: loss 0.034132
[epoch20, step272]: loss 0.036399
[epoch20, step273]: loss 0.036006
[epoch20, step274]: loss 0.034749
[epoch20, step275]: loss 0.033919
[epoch20, step276]: loss 0.036501
[epoch20, step277]: loss 0.035155
[epoch20, step278]: loss 0.037234
[epoch20, step279]: loss 0.033376
[epoch20, step280]: loss 0.034424
[epoch20, step281]: loss 0.037173
[epoch20, step282]: loss 0.036695
[epoch20, step283]: loss 0.034181
[epoch20, step284]: loss 0.034345
[epoch20, step285]: loss 0.037460
[epoch20, step286]: loss 0.033852
[epoch20, step287]: loss 0.036856
[epoch20, step288]: loss 0.033590
[epoch20, step289]: loss 0.035178
[epoch20, step290]: loss 0.037770
[epoch20, step291]: loss 0.036583
[epoch20, step292]: loss 0.033592
[epoch20, step293]: loss 0.034780
[epoch20, step294]: loss 0.036430
[epoch20, step295]: loss 0.033838
[epoch20, step296]: loss 0.037737
[epoch20, step297]: loss 0.033553
[epoch20, step298]: loss 0.034519
[epoch20, step299]: loss 0.035914
[epoch20, step300]: loss 0.036831
[epoch20, step301]: loss 0.034181
[epoch20, step302]: loss 0.034526
[epoch20, step303]: loss 0.037002
[epoch20, step304]: loss 0.033929
[epoch20, step305]: loss 0.035744
[epoch20, step306]: loss 0.034030
[epoch20, step307]: loss 0.033781
[epoch20, step308]: loss 0.037683
[epoch20, step309]: loss 0.036674
[epoch20, step310]: loss 0.034200
[epoch20, step311]: loss 0.034362
[epoch20, step312]: loss 0.036513
[epoch20, step313]: loss 0.034105
[epoch20, step314]: loss 0.036421
[epoch20, step315]: loss 0.034838
[epoch20, step316]: loss 0.033741
[epoch20, step317]: loss 0.037619
[epoch20, step318]: loss 0.036943
[epoch20, step319]: loss 0.033567
[epoch20, step320]: loss 0.033575
[epoch20, step321]: loss 0.036334
[epoch20, step322]: loss 0.033994
[epoch20, step323]: loss 0.036280
[epoch20, step324]: loss 0.034784
[epoch20, step325]: loss 0.034106
[epoch20, step326]: loss 0.036374
[epoch20, step327]: loss 0.035651
[epoch20, step328]: loss 0.034192
[epoch20, step329]: loss 0.033823
[epoch20, step330]: loss 0.036008
[epoch20, step331]: loss 0.034401
[epoch20, step332]: loss 0.035683
[epoch20, step333]: loss 0.033796
[epoch20, step334]: loss 0.033919
[epoch20, step335]: loss 0.037255
[epoch20, step336]: loss 0.037567
[epoch20, step337]: loss 0.034645
[epoch20, step338]: loss 0.033759
[epoch20, step339]: loss 0.036341
[epoch20, step340]: loss 0.035093
[epoch20, step341]: loss 0.036447
[epoch20, step342]: loss 0.033096
[epoch20, step343]: loss 0.034754
[epoch20, step344]: loss 0.036319
[epoch20, step345]: loss 0.035874
[epoch20, step346]: loss 0.033430
[epoch20, step347]: loss 0.033852
[epoch20, step348]: loss 0.036709
[epoch20, step349]: loss 0.035058
[epoch20, step350]: loss 0.035547
[epoch20, step351]: loss 0.033296
[epoch20, step352]: loss 0.033690
[epoch20, step353]: loss 0.036590
[epoch20, step354]: loss 0.035518
[epoch20, step355]: loss 0.033206
[epoch20, step356]: loss 0.034815
[epoch20, step357]: loss 0.036543
[epoch20, step358]: loss 0.033045
[epoch20, step359]: loss 0.038527
[epoch20, step360]: loss 0.032872
[epoch20, step361]: loss 0.034318
[epoch20, step362]: loss 0.038148
[epoch20, step363]: loss 0.036061
[epoch20, step364]: loss 0.034065
[epoch20, step365]: loss 0.033945
[epoch20, step366]: loss 0.036633
[epoch20, step367]: loss 0.034587
[epoch20, step368]: loss 0.036078
[epoch20, step369]: loss 0.033456
[epoch20, step370]: loss 0.034603
[epoch20, step371]: loss 0.037377
[epoch20, step372]: loss 0.035759
[epoch20, step373]: loss 0.033952
[epoch20, step374]: loss 0.034028
[epoch20, step375]: loss 0.037739
[epoch20, step376]: loss 0.034625
[epoch20, step377]: loss 0.037273
[epoch20, step378]: loss 0.034498
[epoch20, step379]: loss 0.034805
[epoch20, step380]: loss 0.037655
[epoch20, step381]: loss 0.035843
[epoch20, step382]: loss 0.034141
[epoch20, step383]: loss 0.032616
[epoch20, step384]: loss 0.035855
[epoch20, step385]: loss 0.033606
[epoch20, step386]: loss 0.036396
[epoch20, step387]: loss 0.033717
[epoch20, step388]: loss 0.034974
[epoch20, step389]: loss 0.036436
[epoch20, step390]: loss 0.037357
[epoch20, step391]: loss 0.033573
[epoch20, step392]: loss 0.034551
[epoch20, step393]: loss 0.036419
[epoch20, step394]: loss 0.034220
[epoch20, step395]: loss 0.035865
[epoch20, step396]: loss 0.034093
[epoch20, step397]: loss 0.033483
[epoch20, step398]: loss 0.036783
[epoch20, step399]: loss 0.036705
[epoch20, step400]: loss 0.033813
[epoch20, step401]: loss 0.034258
[epoch20, step402]: loss 0.037529
[epoch20, step403]: loss 0.034544
[epoch20, step404]: loss 0.036899
[epoch20, step405]: loss 0.034787
[epoch20, step406]: loss 0.034089
[epoch20, step407]: loss 0.036232
[epoch20, step408]: loss 0.036289
[epoch20, step409]: loss 0.035197
[epoch20, step410]: loss 0.034330
[epoch20, step411]: loss 0.036272
[epoch20, step412]: loss 0.033746
[epoch20, step413]: loss 0.036120
[epoch20, step414]: loss 0.033646
[epoch20, step415]: loss 0.034563
[epoch20, step416]: loss 0.035976
[epoch20, step417]: loss 0.036310
[epoch20, step418]: loss 0.034182
[epoch20, step419]: loss 0.033889
[epoch20, step420]: loss 0.036523
[epoch20, step421]: loss 0.034336
[epoch20, step422]: loss 0.037632
[epoch20, step423]: loss 0.034405
[epoch20, step424]: loss 0.033876
[epoch20, step425]: loss 0.037246
[epoch20, step426]: loss 0.036506
[epoch20, step427]: loss 0.034474
[epoch20, step428]: loss 0.033769
[epoch20, step429]: loss 0.037276
[epoch20, step430]: loss 0.034229
[epoch20, step431]: loss 0.036671
[epoch20, step432]: loss 0.033502
[epoch20, step433]: loss 0.034567
[epoch20, step434]: loss 0.036862
[epoch20, step435]: loss 0.036949
[epoch20, step436]: loss 0.033905
[epoch20, step437]: loss 0.034828
[epoch20, step438]: loss 0.036892
[epoch20, step439]: loss 0.035072
[epoch20, step440]: loss 0.037321
[epoch20, step441]: loss 0.034328
[epoch20, step442]: loss 0.034580
[epoch20, step443]: loss 0.037948
[epoch20, step444]: loss 0.035922
[epoch20, step445]: loss 0.034395
[epoch20, step446]: loss 0.034757
[epoch20, step447]: loss 0.036811
[epoch20, step448]: loss 0.034412
[epoch20, step449]: loss 0.036042
[epoch20, step450]: loss 0.033141
[epoch20, step451]: loss 0.034112
[epoch20, step452]: loss 0.035784
[epoch20, step453]: loss 0.036216
[epoch20, step454]: loss 0.033980
[epoch20, step455]: loss 0.034201
[epoch20, step456]: loss 0.035688
[epoch20, step457]: loss 0.035081
[epoch20, step458]: loss 0.035925
[epoch20, step459]: loss 0.034596
[epoch20, step460]: loss 0.034491
[epoch20, step461]: loss 0.037653
[epoch20, step462]: loss 0.035610
[epoch20, step463]: loss 0.034583
[epoch20, step464]: loss 0.034015
[epoch20, step465]: loss 0.037513
[epoch20, step466]: loss 0.034366
[epoch20, step467]: loss 0.035915
[epoch20, step468]: loss 0.034190
[epoch20, step469]: loss 0.034591
[epoch20, step470]: loss 0.036893
[epoch20, step471]: loss 0.035913
[epoch20, step472]: loss 0.034269
[epoch20, step473]: loss 0.033836
[epoch20, step474]: loss 0.035910
[epoch20, step475]: loss 0.034410
[epoch20, step476]: loss 0.036584
[epoch20, step477]: loss 0.034007
[epoch20, step478]: loss 0.033498
[epoch20, step479]: loss 0.036106
[epoch20, step480]: loss 0.035579
[epoch20, step481]: loss 0.033356
[epoch20, step482]: loss 0.033445
[epoch20, step483]: loss 0.036587
[epoch20, step484]: loss 0.034527
[epoch20, step485]: loss 0.036295
[epoch20, step486]: loss 0.034019
[epoch20, step487]: loss 0.033567
[epoch20, step488]: loss 0.037272
[epoch20, step489]: loss 0.035720
[epoch20, step490]: loss 0.034295
[epoch20, step491]: loss 0.034236
[epoch20, step492]: loss 0.036228
[epoch20, step493]: loss 0.033992
[epoch20, step494]: loss 0.036277
[epoch20, step495]: loss 0.034691
[epoch20, step496]: loss 0.034506
[epoch20, step497]: loss 0.036496
[epoch20, step498]: loss 0.036165
[epoch20, step499]: loss 0.034229
[epoch20, step500]: loss 0.033874
[epoch20, step501]: loss 0.036110
[epoch20, step502]: loss 0.034465
[epoch20, step503]: loss 0.036566
[epoch20, step504]: loss 0.033614
[epoch20, step505]: loss 0.033261
[epoch20, step506]: loss 0.037235
[epoch20, step507]: loss 0.037102
[epoch20, step508]: loss 0.034231
[epoch20, step509]: loss 0.033969
[epoch20, step510]: loss 0.036718
[epoch20, step511]: loss 0.034841
[epoch20, step512]: loss 0.036846
[epoch20, step513]: loss 0.033651
[epoch20, step514]: loss 0.034162
[epoch20, step515]: loss 0.036399
[epoch20, step516]: loss 0.036418
[epoch20, step517]: loss 0.033719
[epoch20, step518]: loss 0.034085
[epoch20, step519]: loss 0.036568
[epoch20, step520]: loss 0.033703
[epoch20, step521]: loss 0.036190
[epoch20, step522]: loss 0.033420
[epoch20, step523]: loss 0.033613
[epoch20, step524]: loss 0.036714
[epoch20, step525]: loss 0.036668
[epoch20, step526]: loss 0.033973
[epoch20, step527]: loss 0.034010
[epoch20, step528]: loss 0.036441
[epoch20, step529]: loss 0.034294
[epoch20, step530]: loss 0.037408
[epoch20, step531]: loss 0.033572
[epoch20, step532]: loss 0.034715
[epoch20, step533]: loss 0.038149
[epoch20, step534]: loss 0.036399
[epoch20, step535]: loss 0.034825
[epoch20, step536]: loss 0.034471
[epoch20, step537]: loss 0.036455
[epoch20, step538]: loss 0.034647
[epoch20, step539]: loss 0.036470
[epoch20, step540]: loss 0.033377
[epoch20, step541]: loss 0.033968
[epoch20, step542]: loss 0.037448
[epoch20, step543]: loss 0.036029
[epoch20, step544]: loss 0.034281
[epoch20, step545]: loss 0.033911
[epoch20, step546]: loss 0.036851
[epoch20, step547]: loss 0.034157
[epoch20, step548]: loss 0.037003
[epoch20, step549]: loss 0.034092
[epoch20, step550]: loss 0.034059
[epoch20, step551]: loss 0.036366
[epoch20, step552]: loss 0.035385
[epoch20, step553]: loss 0.034608
[epoch20, step554]: loss 0.033516
[epoch20, step555]: loss 0.036251
[epoch20, step556]: loss 0.034290
[epoch20, step557]: loss 0.035695
[epoch20, step558]: loss 0.033742
[epoch20, step559]: loss 0.033554
[epoch20, step560]: loss 0.036366
[epoch20, step561]: loss 0.035925
[epoch20, step562]: loss 0.033873
[epoch20, step563]: loss 0.029396
[epoch20, step564]: loss 0.031336
[epoch20, step565]: loss 0.028863
[epoch20, step566]: loss 0.037689
[epoch20, step567]: loss 0.028834
[epoch20, step568]: loss 0.028382
[epoch20, step569]: loss 0.024346
[epoch20, step570]: loss 0.033368
[epoch20, step571]: loss 0.028152
[epoch20, step572]: loss 0.027121
[epoch20, step573]: loss 0.030418
[epoch20, step574]: loss 0.028416
[epoch20, step575]: loss 0.020647
[epoch20, step576]: loss 0.021812
[epoch20, step577]: loss 0.026137
[epoch20, step578]: loss 0.018620
[epoch20, step579]: loss 0.029125
[epoch20, step580]: loss 0.020140
[epoch20, step581]: loss 0.025744
[epoch20, step582]: loss 0.025541
[epoch20, step583]: loss 0.021917
[epoch20, step584]: loss 0.024064
[epoch20, step585]: loss 0.027037
[epoch20, step586]: loss 0.022220
[epoch20, step587]: loss 0.028448
[epoch20, step588]: loss 0.023280
[epoch20, step589]: loss 0.023746
[epoch20, step590]: loss 0.026964
[epoch20, step591]: loss 0.020434
[epoch20, step592]: loss 0.026844
[epoch20, step593]: loss 0.022685
[epoch20, step594]: loss 0.026587
[epoch20, step595]: loss 0.026338
[epoch20, step596]: loss 0.023138
[epoch20, step597]: loss 0.025336
[epoch20, step598]: loss 0.026905
[epoch20, step599]: loss 0.025351
[epoch20, step600]: loss 0.028794
[epoch20, step601]: loss 0.019749
[epoch20, step602]: loss 0.022586
[epoch20, step603]: loss 0.025718
[epoch20, step604]: loss 0.026666
[epoch20, step605]: loss 0.025598
[epoch20, step606]: loss 0.025152
[epoch20, step607]: loss 0.027384
[epoch20, step608]: loss 0.025950
[epoch20, step609]: loss 0.026575
[epoch20, step610]: loss 0.026328
[epoch20, step611]: loss 0.026448
[epoch20, step612]: loss 0.025251
[epoch20, step613]: loss 0.019778
[epoch20, step614]: loss 0.025957
[epoch20, step615]: loss 0.028358
[epoch20, step616]: loss 0.024910
[epoch20, step617]: loss 0.023892
[epoch20, step618]: loss 0.026581
[epoch20, step619]: loss 0.027024
[epoch20, step620]: loss 0.024372
[epoch20, step621]: loss 0.026376
[epoch20, step622]: loss 0.020547
[epoch20, step623]: loss 0.024584
[epoch20, step624]: loss 0.026671
[epoch20, step625]: loss 0.025900
[epoch20, step626]: loss 0.029376
[epoch20, step627]: loss 0.022704
[epoch20, step628]: loss 0.025017
[epoch20, step629]: loss 0.020726
[epoch20, step630]: loss 0.023921
[epoch20, step631]: loss 0.031390
[epoch20, step632]: loss 0.024193
[epoch20, step633]: loss 0.024649
[epoch20, step634]: loss 0.026774
[epoch20, step635]: loss 0.025523
[epoch20, step636]: loss 0.020995
[epoch20, step637]: loss 0.027289
[epoch20, step638]: loss 0.026589
[epoch20, step639]: loss 0.022652
[epoch20, step640]: loss 0.029980
[epoch20, step641]: loss 0.030042
[epoch20, step642]: loss 0.025687
[epoch20, step643]: loss 0.025557
[epoch20, step644]: loss 0.026015
[epoch20, step645]: loss 0.023688
[epoch20, step646]: loss 0.026005
[epoch20, step647]: loss 0.023640
[epoch20, step648]: loss 0.023573
[epoch20, step649]: loss 0.028617
[epoch20, step650]: loss 0.021735
[epoch20, step651]: loss 0.026911
[epoch20, step652]: loss 0.028135
[epoch20, step653]: loss 0.028778
[epoch20, step654]: loss 0.023225
[epoch20, step655]: loss 0.024772
[epoch20, step656]: loss 0.021586
[epoch20, step657]: loss 0.027758
[epoch20, step658]: loss 0.025637
[epoch20, step659]: loss 0.028203
[epoch20, step660]: loss 0.024135
[epoch20, step661]: loss 0.026148
[epoch20, step662]: loss 0.023931
[epoch20, step663]: loss 0.020686
[epoch20, step664]: loss 0.025150
[epoch20, step665]: loss 0.028568
[epoch20, step666]: loss 0.026337
[epoch20, step667]: loss 0.026373
[epoch20, step668]: loss 0.022133
[epoch20, step669]: loss 0.027025
[epoch20, step670]: loss 0.026708
[epoch20, step671]: loss 0.021676
[epoch20, step672]: loss 0.023799
[epoch20, step673]: loss 0.021763
[epoch20, step674]: loss 0.021027
[epoch20, step675]: loss 0.019849
[epoch20, step676]: loss 0.024385
[epoch20, step677]: loss 0.024962
[epoch20, step678]: loss 0.023194
[epoch20, step679]: loss 0.023780
[epoch20, step680]: loss 0.030941
[epoch20, step681]: loss 0.021745
[epoch20, step682]: loss 0.026531
[epoch20, step683]: loss 0.025623
[epoch20, step684]: loss 0.024669
[epoch20, step685]: loss 0.024353
[epoch20, step686]: loss 0.027214
[epoch20, step687]: loss 0.026767
[epoch20, step688]: loss 0.022072
[epoch20, step689]: loss 0.024383
[epoch20, step690]: loss 0.025066
[epoch20, step691]: loss 0.024264
[epoch20, step692]: loss 0.022494
[epoch20, step693]: loss 0.026911
[epoch20, step694]: loss 0.022964
[epoch20, step695]: loss 0.026550
[epoch20, step696]: loss 0.025985
[epoch20, step697]: loss 0.026996
[epoch20, step698]: loss 0.024681
[epoch20, step699]: loss 0.023322
[epoch20, step700]: loss 0.021641
[epoch20, step701]: loss 0.025557
[epoch20, step702]: loss 0.021662
[epoch20, step703]: loss 0.022937
[epoch20, step704]: loss 0.024975
[epoch20, step705]: loss 0.024848
[epoch20, step706]: loss 0.023531
[epoch20, step707]: loss 0.024496
[epoch20, step708]: loss 0.026101
[epoch20, step709]: loss 0.026975
[epoch20, step710]: loss 0.023565
[epoch20, step711]: loss 0.023574
[epoch20, step712]: loss 0.026326
[epoch20, step713]: loss 0.026105
[epoch20, step714]: loss 0.021416
[epoch20, step715]: loss 0.023449
[epoch20, step716]: loss 0.025595
[epoch20, step717]: loss 0.023621
[epoch20, step718]: loss 0.025358
[epoch20, step719]: loss 0.032969
[epoch20, step720]: loss 0.024618
[epoch20, step721]: loss 0.023180
[epoch20, step722]: loss 0.030860
[epoch20, step723]: loss 0.025974
[epoch20, step724]: loss 0.023067
[epoch20, step725]: loss 0.027904
[epoch20, step726]: loss 0.022203
[epoch20, step727]: loss 0.024340
[epoch20, step728]: loss 0.026362
[epoch20, step729]: loss 0.020987
[epoch20, step730]: loss 0.022463
[epoch20, step731]: loss 0.025564
[epoch20, step732]: loss 0.031680
[epoch20, step733]: loss 0.027166
[epoch20, step734]: loss 0.027145
[epoch20, step735]: loss 0.035351
[epoch20, step736]: loss 0.031823
[epoch20, step737]: loss 0.032240
[epoch20, step738]: loss 0.023563
[epoch20, step739]: loss 0.030077
[epoch20, step740]: loss 0.024597
[epoch20, step741]: loss 0.027243
[epoch20, step742]: loss 0.023657
[epoch20, step743]: loss 0.024603
[epoch20, step744]: loss 0.024557
[epoch20, step745]: loss 0.025568
[epoch20, step746]: loss 0.025210
[epoch20, step747]: loss 0.027202
[epoch20, step748]: loss 0.025445
[epoch20, step749]: loss 0.026239
[epoch20, step750]: loss 0.027794
[epoch20, step751]: loss 0.022195
[epoch20, step752]: loss 0.025625
[epoch20, step753]: loss 0.026673
[epoch20, step754]: loss 0.022576
[epoch20, step755]: loss 0.027030
[epoch20, step756]: loss 0.024055
[epoch20, step757]: loss 0.020422
[epoch20, step758]: loss 0.024940
[epoch20, step759]: loss 0.023480
[epoch20, step760]: loss 0.023944
[epoch20, step761]: loss 0.026038
[epoch20, step762]: loss 0.021707
[epoch20, step763]: loss 0.024979
[epoch20, step764]: loss 0.023440
[epoch20, step765]: loss 0.025993
[epoch20, step766]: loss 0.024646
[epoch20, step767]: loss 0.026574
[epoch20, step768]: loss 0.021398
[epoch20, step769]: loss 0.026633
[epoch20, step770]: loss 0.025733
[epoch20, step771]: loss 0.023107
[epoch20, step772]: loss 0.028847
[epoch20, step773]: loss 0.026982
[epoch20, step774]: loss 0.024037
[epoch20, step775]: loss 0.020838
[epoch20, step776]: loss 0.025887
[epoch20, step777]: loss 0.023161
[epoch20, step778]: loss 0.028807
[epoch20, step779]: loss 0.024290
[epoch20, step780]: loss 0.020313
[epoch20, step781]: loss 0.024246
[epoch20, step782]: loss 0.022523
[epoch20, step783]: loss 0.019166
[epoch20, step784]: loss 0.020318
[epoch20, step785]: loss 0.021225
[epoch20, step786]: loss 0.023815
[epoch20, step787]: loss 0.023304
[epoch20, step788]: loss 0.024651
[epoch20, step789]: loss 0.022481
[epoch20, step790]: loss 0.022856
[epoch20, step791]: loss 0.026847
[epoch20, step792]: loss 0.024923
[epoch20, step793]: loss 0.026971
[epoch20, step794]: loss 0.020443
[epoch20, step795]: loss 0.025493
[epoch20, step796]: loss 0.027615
[epoch20, step797]: loss 0.027738
[epoch20, step798]: loss 0.027171
[epoch20, step799]: loss 0.025864
[epoch20, step800]: loss 0.021451
[epoch20, step801]: loss 0.021771
[epoch20, step802]: loss 0.022564
[epoch20, step803]: loss 0.026177
[epoch20, step804]: loss 0.027350
[epoch20, step805]: loss 0.028373
[epoch20, step806]: loss 0.021366
[epoch20, step807]: loss 0.020660
[epoch20, step808]: loss 0.022935
[epoch20, step809]: loss 0.023016
[epoch20, step810]: loss 0.025573
[epoch20, step811]: loss 0.025708
[epoch20, step812]: loss 0.024355
[epoch20, step813]: loss 0.023497
[epoch20, step814]: loss 0.024942
[epoch20, step815]: loss 0.024936
[epoch20, step816]: loss 0.024065
[epoch20, step817]: loss 0.024467
[epoch20, step818]: loss 0.022462
[epoch20, step819]: loss 0.020003
[epoch20, step820]: loss 0.023124
[epoch20, step821]: loss 0.021717
[epoch20, step822]: loss 0.030175
[epoch20, step823]: loss 0.023775
[epoch20, step824]: loss 0.026504
[epoch20, step825]: loss 0.024732
[epoch20, step826]: loss 0.024304
[epoch20, step827]: loss 0.026735
[epoch20, step828]: loss 0.028746
[epoch20, step829]: loss 0.025860
[epoch20, step830]: loss 0.022537
[epoch20, step831]: loss 0.026045
[epoch20, step832]: loss 0.021035
[epoch20, step833]: loss 0.028636
[epoch20, step834]: loss 0.025436
[epoch20, step835]: loss 0.020538
[epoch20, step836]: loss 0.026539
[epoch20, step837]: loss 0.025483
[epoch20, step838]: loss 0.026273
[epoch20, step839]: loss 0.028540
[epoch20, step840]: loss 0.020466
[epoch20, step841]: loss 0.024588
[epoch20, step842]: loss 0.027674
[epoch20, step843]: loss 0.024721
[epoch20, step844]: loss 0.024718
[epoch20, step845]: loss 0.021028
[epoch20, step846]: loss 0.025499
[epoch20, step847]: loss 0.026568
[epoch20, step848]: loss 0.024916
[epoch20, step849]: loss 0.025006
[epoch20, step850]: loss 0.022834
[epoch20, step851]: loss 0.024015
[epoch20, step852]: loss 0.023352
[epoch20, step853]: loss 0.029244
[epoch20, step854]: loss 0.022638
[epoch20, step855]: loss 0.027021
[epoch20, step856]: loss 0.022202
[epoch20, step857]: loss 0.025705
[epoch20, step858]: loss 0.024129
[epoch20, step859]: loss 0.023320
[epoch20, step860]: loss 0.022545
[epoch20, step861]: loss 0.023028
[epoch20, step862]: loss 0.023015
[epoch20, step863]: loss 0.020360
[epoch20, step864]: loss 0.026282
[epoch20, step865]: loss 0.023116
[epoch20, step866]: loss 0.024909
[epoch20, step867]: loss 0.026012
[epoch20, step868]: loss 0.026604
[epoch20, step869]: loss 0.023695
[epoch20, step870]: loss 0.030452
[epoch20, step871]: loss 0.022046
[epoch20, step872]: loss 0.025145
[epoch20, step873]: loss 0.025596
[epoch20, step874]: loss 0.023557
[epoch20, step875]: loss 0.024046
[epoch20, step876]: loss 0.024162
[epoch20, step877]: loss 0.019128
[epoch20, step878]: loss 0.023395
[epoch20, step879]: loss 0.027442
[epoch20, step880]: loss 0.025472
[epoch20, step881]: loss 0.022031
[epoch20, step882]: loss 0.023721
[epoch20, step883]: loss 0.023927
[epoch20, step884]: loss 0.026280
[epoch20, step885]: loss 0.025872
[epoch20, step886]: loss 0.026525
[epoch20, step887]: loss 0.024098
[epoch20, step888]: loss 0.024530
[epoch20, step889]: loss 0.023287
[epoch20, step890]: loss 0.023450
[epoch20, step891]: loss 0.025112
[epoch20, step892]: loss 0.020768
[epoch20, step893]: loss 0.024393
[epoch20, step894]: loss 0.024869
[epoch20, step895]: loss 0.022536
[epoch20, step896]: loss 0.021590
[epoch20, step897]: loss 0.023533
[epoch20, step898]: loss 0.025410
[epoch20, step899]: loss 0.027824
[epoch20, step900]: loss 0.026770
[epoch20, step901]: loss 0.025078
[epoch20, step902]: loss 0.024003
[epoch20, step903]: loss 0.023927
[epoch20, step904]: loss 0.027583
[epoch20, step905]: loss 0.027379
[epoch20, step906]: loss 0.022066
[epoch20, step907]: loss 0.023498
[epoch20, step908]: loss 0.022196
[epoch20, step909]: loss 0.025291
[epoch20, step910]: loss 0.022881
[epoch20, step911]: loss 0.025317
[epoch20, step912]: loss 0.023546
[epoch20, step913]: loss 0.023613
[epoch20, step914]: loss 0.030084
[epoch20, step915]: loss 0.023900
[epoch20, step916]: loss 0.023650
[epoch20, step917]: loss 0.024818
[epoch20, step918]: loss 0.028561
[epoch20, step919]: loss 0.024347
[epoch20, step920]: loss 0.027415
[epoch20, step921]: loss 0.024190
[epoch20, step922]: loss 0.023038
[epoch20, step923]: loss 0.022382
[epoch20, step924]: loss 0.021277
[epoch20, step925]: loss 0.024840
[epoch20, step926]: loss 0.026300
[epoch20, step927]: loss 0.025565
[epoch20, step928]: loss 0.024592
[epoch20, step929]: loss 0.027444
[epoch20, step930]: loss 0.025496
[epoch20, step931]: loss 0.026854
[epoch20, step932]: loss 0.021572
[epoch20, step933]: loss 0.027799
[epoch20, step934]: loss 0.022051
[epoch20, step935]: loss 0.021982
[epoch20, step936]: loss 0.022341
[epoch20, step937]: loss 0.026739
[epoch20, step938]: loss 0.024868
[epoch20, step939]: loss 0.020523
[epoch20, step940]: loss 0.022887
[epoch20, step941]: loss 0.026804
[epoch20, step942]: loss 0.025288
[epoch20, step943]: loss 0.023160
[epoch20, step944]: loss 0.027540
[epoch20, step945]: loss 0.020290
[epoch20, step946]: loss 0.025103
[epoch20, step947]: loss 0.027887
[epoch20, step948]: loss 0.019072
[epoch20, step949]: loss 0.022439
[epoch20, step950]: loss 0.026672
[epoch20, step951]: loss 0.028376
[epoch20, step952]: loss 0.024859
[epoch20, step953]: loss 0.027346
[epoch20, step954]: loss 0.022223
[epoch20, step955]: loss 0.036689
[epoch20, step956]: loss 0.051699
[epoch20, step957]: loss 0.046005
[epoch20, step958]: loss 0.043248
[epoch20, step959]: loss 0.046813
[epoch20, step960]: loss 0.043394
[epoch20, step961]: loss 0.043717
[epoch20, step962]: loss 0.042148
[epoch20, step963]: loss 0.040742
[epoch20, step964]: loss 0.041059
[epoch20, step965]: loss 0.041225
[epoch20, step966]: loss 0.038579
[epoch20, step967]: loss 0.037414
[epoch20, step968]: loss 0.039433
[epoch20, step969]: loss 0.038882
[epoch20, step970]: loss 0.038027
[epoch20, step971]: loss 0.035960
[epoch20, step972]: loss 0.037693
[epoch20, step973]: loss 0.037204
[epoch20, step974]: loss 0.039225
[epoch20, step975]: loss 0.035433
[epoch20, step976]: loss 0.035207
[epoch20, step977]: loss 0.039042
[epoch20, step978]: loss 0.037234
[epoch20, step979]: loss 0.035485
[epoch20, step980]: loss 0.034788
[epoch20, step981]: loss 0.036325
[epoch20, step982]: loss 0.036987
[epoch20, step983]: loss 0.038076
[epoch20, step984]: loss 0.034154
[epoch20, step985]: loss 0.034972
[epoch20, step986]: loss 0.039891
[epoch20, step987]: loss 0.036946
[epoch20, step988]: loss 0.036458
[epoch20, step989]: loss 0.035542
[epoch20, step990]: loss 0.036113
[epoch20, step991]: loss 0.037575
[epoch20, step992]: loss 0.036836
[epoch20, step993]: loss 0.034524
[epoch20, step994]: loss 0.033815
[epoch20, step995]: loss 0.037608
[epoch20, step996]: loss 0.036051
[epoch20, step997]: loss 0.035534
[epoch20, step998]: loss 0.035375
[epoch20, step999]: loss 0.036521
[epoch20, step1000]: loss 0.036232
[epoch20, step1001]: loss 0.037162
[epoch20, step1002]: loss 0.035047
[epoch20, step1003]: loss 0.033958
[epoch20, step1004]: loss 0.038577
[epoch20, step1005]: loss 0.035332
[epoch20, step1006]: loss 0.035622
[epoch20, step1007]: loss 0.033697
[epoch20, step1008]: loss 0.035200
[epoch20, step1009]: loss 0.035685
[epoch20, step1010]: loss 0.037215
[epoch20, step1011]: loss 0.034458
[epoch20, step1012]: loss 0.034529
[epoch20, step1013]: loss 0.037653
[epoch20, step1014]: loss 0.036510
[epoch20, step1015]: loss 0.035677
[epoch20, step1016]: loss 0.034097
[epoch20, step1017]: loss 0.035422
[epoch20, step1018]: loss 0.036022
[epoch20, step1019]: loss 0.036436
[epoch20, step1020]: loss 0.034537
[epoch20, step1021]: loss 0.033913
[epoch20, step1022]: loss 0.037211
[epoch20, step1023]: loss 0.036283
[epoch20, step1024]: loss 0.036002
[epoch20, step1025]: loss 0.034694
[epoch20, step1026]: loss 0.036492
[epoch20, step1027]: loss 0.036221
[epoch20, step1028]: loss 0.036163
[epoch20, step1029]: loss 0.034563
[epoch20, step1030]: loss 0.033459
[epoch20, step1031]: loss 0.035872
[epoch20, step1032]: loss 0.036053
[epoch20, step1033]: loss 0.034869
[epoch20, step1034]: loss 0.033744
[epoch20, step1035]: loss 0.034598
[epoch20, step1036]: loss 0.035808
[epoch20, step1037]: loss 0.035802
[epoch20, step1038]: loss 0.034064
[epoch20, step1039]: loss 0.033986
[epoch20, step1040]: loss 0.036346
[epoch20, step1041]: loss 0.035226
[epoch20, step1042]: loss 0.034025
[epoch20, step1043]: loss 0.033835
[epoch20, step1044]: loss 0.035322
[epoch20, step1045]: loss 0.035598
[epoch20, step1046]: loss 0.036238
[epoch20, step1047]: loss 0.034523
[epoch20, step1048]: loss 0.033236
[epoch20, step1049]: loss 0.037152
[epoch20, step1050]: loss 0.036307
[epoch20, step1051]: loss 0.035089
[epoch20, step1052]: loss 0.034733
[epoch20, step1053]: loss 0.035505
[epoch20, step1054]: loss 0.036006
[epoch20, step1055]: loss 0.036587
[epoch20, step1056]: loss 0.033591
[epoch20, step1057]: loss 0.035082
[epoch20, step1058]: loss 0.038653
[epoch20, step1059]: loss 0.035605
[epoch20, step1060]: loss 0.035647
[epoch20, step1061]: loss 0.033953
[epoch20, step1062]: loss 0.035521
[epoch20, step1063]: loss 0.035719
[epoch20, step1064]: loss 0.036541
[epoch20, step1065]: loss 0.034060
[epoch20, step1066]: loss 0.033779
[epoch20, step1067]: loss 0.037035
[epoch20, step1068]: loss 0.034384
[epoch20, step1069]: loss 0.034638
[epoch20, step1070]: loss 0.033927
[epoch20, step1071]: loss 0.035668
[epoch20, step1072]: loss 0.036369
[epoch20, step1073]: loss 0.036201
[epoch20, step1074]: loss 0.035059
[epoch20, step1075]: loss 0.035088
[epoch20, step1076]: loss 0.036928
[epoch20, step1077]: loss 0.035505
[epoch20, step1078]: loss 0.035278
[epoch20, step1079]: loss 0.034770
[epoch20, step1080]: loss 0.035966
[epoch20, step1081]: loss 0.035757
[epoch20, step1082]: loss 0.035901
[epoch20, step1083]: loss 0.034875
[epoch20, step1084]: loss 0.034227
[epoch20, step1085]: loss 0.036009
[epoch20, step1086]: loss 0.035373
[epoch20, step1087]: loss 0.035263
[epoch20, step1088]: loss 0.033610
[epoch20, step1089]: loss 0.035755
[epoch20, step1090]: loss 0.036426
[epoch20, step1091]: loss 0.036238
[epoch20, step1092]: loss 0.034585
[epoch20, step1093]: loss 0.034468
[epoch20, step1094]: loss 0.035872
[epoch20, step1095]: loss 0.035416
[epoch20, step1096]: loss 0.035780
[epoch20, step1097]: loss 0.034176
[epoch20, step1098]: loss 0.035076
[epoch20, step1099]: loss 0.035147
[epoch20, step1100]: loss 0.036317
[epoch20, step1101]: loss 0.034476
[epoch20, step1102]: loss 0.033650
[epoch20, step1103]: loss 0.036386
[epoch20, step1104]: loss 0.035013
[epoch20, step1105]: loss 0.035205
[epoch20, step1106]: loss 0.032799
[epoch20, step1107]: loss 0.035275
[epoch20, step1108]: loss 0.035002
[epoch20, step1109]: loss 0.036330
[epoch20, step1110]: loss 0.034896
[epoch20, step1111]: loss 0.033685
[epoch20, step1112]: loss 0.036908
[epoch20, step1113]: loss 0.034704
[epoch20, step1114]: loss 0.035249
[epoch20, step1115]: loss 0.034083
[epoch20, step1116]: loss 0.035258
[epoch20, step1117]: loss 0.035681
[epoch20, step1118]: loss 0.035957
[epoch20, step1119]: loss 0.034014
[epoch20, step1120]: loss 0.033616
[epoch20, step1121]: loss 0.036948
[epoch20, step1122]: loss 0.035007
[epoch20, step1123]: loss 0.034193
[epoch20, step1124]: loss 0.035024
[epoch20, step1125]: loss 0.035893
[epoch20, step1126]: loss 0.036478
[epoch20, step1127]: loss 0.036436
[epoch20, step1128]: loss 0.034977
[epoch20, step1129]: loss 0.033332
[epoch20, step1130]: loss 0.037684
[epoch20, step1131]: loss 0.035895
[epoch20, step1132]: loss 0.035322
[epoch20, step1133]: loss 0.033181
[epoch20, step1134]: loss 0.034823
[epoch20, step1135]: loss 0.036185
[epoch20, step1136]: loss 0.036881
[epoch20, step1137]: loss 0.033985
[epoch20, step1138]: loss 0.033647
[epoch20, step1139]: loss 0.036397
[epoch20, step1140]: loss 0.034444
[epoch20, step1141]: loss 0.034871
[epoch20, step1142]: loss 0.033215
[epoch20, step1143]: loss 0.034773
[epoch20, step1144]: loss 0.035584
[epoch20, step1145]: loss 0.035478
[epoch20, step1146]: loss 0.033729
[epoch20, step1147]: loss 0.034578
[epoch20, step1148]: loss 0.036538
[epoch20, step1149]: loss 0.034885
[epoch20, step1150]: loss 0.034598
[epoch20, step1151]: loss 0.034327
[epoch20, step1152]: loss 0.035566
[epoch20, step1153]: loss 0.035074
[epoch20, step1154]: loss 0.036061
[epoch20, step1155]: loss 0.034090
[epoch20, step1156]: loss 0.033096
[epoch20, step1157]: loss 0.036619
[epoch20, step1158]: loss 0.036052
[epoch20, step1159]: loss 0.035119
[epoch20, step1160]: loss 0.035103
[epoch20, step1161]: loss 0.036082
[epoch20, step1162]: loss 0.035185
[epoch20, step1163]: loss 0.035808
[epoch20, step1164]: loss 0.034449
[epoch20, step1165]: loss 0.034425
[epoch20, step1166]: loss 0.036779
[epoch20, step1167]: loss 0.034126
[epoch20, step1168]: loss 0.034962
[epoch20, step1169]: loss 0.033261
[epoch20, step1170]: loss 0.035135
[epoch20, step1171]: loss 0.035576
[epoch20, step1172]: loss 0.035958
[epoch20, step1173]: loss 0.034089
[epoch20, step1174]: loss 0.033887
[epoch20, step1175]: loss 0.036509
[epoch20, step1176]: loss 0.034615
[epoch20, step1177]: loss 0.035301
[epoch20, step1178]: loss 0.033739
[epoch20, step1179]: loss 0.034941
[epoch20, step1180]: loss 0.035533
[epoch20, step1181]: loss 0.036285
[epoch20, step1182]: loss 0.033815
[epoch20, step1183]: loss 0.034027
[epoch20, step1184]: loss 0.036472
[epoch20, step1185]: loss 0.035602
[epoch20, step1186]: loss 0.034088
[epoch20, step1187]: loss 0.033333
[epoch20, step1188]: loss 0.034501
[epoch20, step1189]: loss 0.035206
[epoch20, step1190]: loss 0.036709
[epoch20, step1191]: loss 0.034442
[epoch20, step1192]: loss 0.034284
[epoch20, step1193]: loss 0.037489
[epoch20, step1194]: loss 0.035145
[epoch20, step1195]: loss 0.033721
[epoch20, step1196]: loss 0.033024
[epoch20, step1197]: loss 0.035599
[epoch20, step1198]: loss 0.035685
[epoch20, step1199]: loss 0.035878
[epoch20, step1200]: loss 0.033400
[epoch20, step1201]: loss 0.034250
[epoch20, step1202]: loss 0.037354
[epoch20, step1203]: loss 0.035246
[epoch20, step1204]: loss 0.034158
[epoch20, step1205]: loss 0.033142
[epoch20, step1206]: loss 0.034669
[epoch20, step1207]: loss 0.035790
[epoch20, step1208]: loss 0.036620
[epoch20, step1209]: loss 0.033209
[epoch20, step1210]: loss 0.034409
[epoch20, step1211]: loss 0.036653
[epoch20, step1212]: loss 0.034995
[epoch20, step1213]: loss 0.034277
[epoch20, step1214]: loss 0.034103
[epoch20, step1215]: loss 0.036169
[epoch20, step1216]: loss 0.034764
[epoch20, step1217]: loss 0.036865
[epoch20, step1218]: loss 0.033841
[epoch20, step1219]: loss 0.034108
[epoch20, step1220]: loss 0.036678
[epoch20, step1221]: loss 0.034337
[epoch20, step1222]: loss 0.035199
[epoch20, step1223]: loss 0.034173
[epoch20, step1224]: loss 0.035508
[epoch20, step1225]: loss 0.035358
[epoch20, step1226]: loss 0.035293
[epoch20, step1227]: loss 0.033940
[epoch20, step1228]: loss 0.033407
[epoch20, step1229]: loss 0.036574
[epoch20, step1230]: loss 0.035282
[epoch20, step1231]: loss 0.034716
[epoch20, step1232]: loss 0.034450
[epoch20, step1233]: loss 0.034664
[epoch20, step1234]: loss 0.035337
[epoch20, step1235]: loss 0.036524
[epoch20, step1236]: loss 0.034403
[epoch20, step1237]: loss 0.034124
[epoch20, step1238]: loss 0.035661
[epoch20, step1239]: loss 0.035993
[epoch20, step1240]: loss 0.036076
[epoch20, step1241]: loss 0.033309
[epoch20, step1242]: loss 0.034908
[epoch20, step1243]: loss 0.035689
[epoch20, step1244]: loss 0.036259
[epoch20, step1245]: loss 0.034122
[epoch20, step1246]: loss 0.034017
[epoch20, step1247]: loss 0.035991
[epoch20, step1248]: loss 0.035231
[epoch20, step1249]: loss 0.035396
[epoch20, step1250]: loss 0.033563
[epoch20, step1251]: loss 0.035662
[epoch20, step1252]: loss 0.036282
[epoch20, step1253]: loss 0.036203
[epoch20, step1254]: loss 0.034221
[epoch20, step1255]: loss 0.033456
[epoch20, step1256]: loss 0.036882
[epoch20, step1257]: loss 0.036012
[epoch20, step1258]: loss 0.034834
[epoch20, step1259]: loss 0.034470
[epoch20, step1260]: loss 0.036188
[epoch20, step1261]: loss 0.035678
[epoch20, step1262]: loss 0.035006
[epoch20, step1263]: loss 0.034560
[epoch20, step1264]: loss 0.033517
[epoch20, step1265]: loss 0.035332
[epoch20, step1266]: loss 0.035048
[epoch20, step1267]: loss 0.035421
[epoch20, step1268]: loss 0.033706
[epoch20, step1269]: loss 0.035305
[epoch20, step1270]: loss 0.034943
[epoch20, step1271]: loss 0.036222
[epoch20, step1272]: loss 0.034368
[epoch20, step1273]: loss 0.033211
[epoch20, step1274]: loss 0.037445
[epoch20, step1275]: loss 0.035453
[epoch20, step1276]: loss 0.034783
[epoch20, step1277]: loss 0.033768
[epoch20, step1278]: loss 0.035390
[epoch20, step1279]: loss 0.036963
[epoch20, step1280]: loss 0.037097
[epoch20, step1281]: loss 0.034097
[epoch20, step1282]: loss 0.035101
[epoch20, step1283]: loss 0.036784
[epoch20, step1284]: loss 0.035095
[epoch20, step1285]: loss 0.036068
[epoch20, step1286]: loss 0.034261
[epoch20, step1287]: loss 0.036187
[epoch20, step1288]: loss 0.035970
[epoch20, step1289]: loss 0.037165
[epoch20, step1290]: loss 0.033808
[epoch20, step1291]: loss 0.033481
[epoch20, step1292]: loss 0.037493
[epoch20, step1293]: loss 0.034305
[epoch20, step1294]: loss 0.035252
[epoch20, step1295]: loss 0.034747
[epoch20, step1296]: loss 0.035505
[epoch20, step1297]: loss 0.036002
[epoch20, step1298]: loss 0.037757
[epoch20, step1299]: loss 0.034384
[epoch20, step1300]: loss 0.034549
[epoch20, step1301]: loss 0.036551
[epoch20, step1302]: loss 0.035519
[epoch20, step1303]: loss 0.035248
[epoch20, step1304]: loss 0.033620
[epoch20, step1305]: loss 0.035127
[epoch20, step1306]: loss 0.034998
[epoch20, step1307]: loss 0.035154
[epoch20, step1308]: loss 0.034360
[epoch20, step1309]: loss 0.032975
[epoch20, step1310]: loss 0.036063
[epoch20, step1311]: loss 0.033899
[epoch20, step1312]: loss 0.035341
[epoch20, step1313]: loss 0.033700
[epoch20, step1314]: loss 0.034676
[epoch20, step1315]: loss 0.035256
[epoch20, step1316]: loss 0.037002
[epoch20, step1317]: loss 0.033318
[epoch20, step1318]: loss 0.033436
[epoch20, step1319]: loss 0.036008
[epoch20, step1320]: loss 0.035266
[epoch20, step1321]: loss 0.035209
[epoch20, step1322]: loss 0.033800
[epoch20, step1323]: loss 0.035514
[epoch20, step1324]: loss 0.035500
[epoch20, step1325]: loss 0.036104
[epoch20, step1326]: loss 0.033791
[epoch20, step1327]: loss 0.033861
[epoch20, step1328]: loss 0.036723
[epoch20, step1329]: loss 0.034792
[epoch20, step1330]: loss 0.035342
[epoch20, step1331]: loss 0.033000
[epoch20, step1332]: loss 0.034993
[epoch20, step1333]: loss 0.034481
[epoch20, step1334]: loss 0.036408
[epoch20, step1335]: loss 0.034638
[epoch20, step1336]: loss 0.033354
[epoch20, step1337]: loss 0.035568
[epoch20, step1338]: loss 0.035611
[epoch20, step1339]: loss 0.034994
[epoch20, step1340]: loss 0.033533
[epoch20, step1341]: loss 0.035285
[epoch20, step1342]: loss 0.034941
[epoch20, step1343]: loss 0.036621
[epoch20, step1344]: loss 0.034090
[epoch20, step1345]: loss 0.033787
[epoch20, step1346]: loss 0.035888
[epoch20, step1347]: loss 0.035567
[epoch20, step1348]: loss 0.034330
[epoch20, step1349]: loss 0.033967
[epoch20, step1350]: loss 0.036185
[epoch20, step1351]: loss 0.034686
[epoch20, step1352]: loss 0.036413
[epoch20, step1353]: loss 0.033232
[epoch20, step1354]: loss 0.033472
[epoch20, step1355]: loss 0.036782
[epoch20, step1356]: loss 0.034854
[epoch20, step1357]: loss 0.034851
[epoch20, step1358]: loss 0.033253
[epoch20, step1359]: loss 0.034666
[epoch20, step1360]: loss 0.035718
[epoch20, step1361]: loss 0.036150
[epoch20, step1362]: loss 0.034232
[epoch20, step1363]: loss 0.033985
[epoch20, step1364]: loss 0.036321
[epoch20, step1365]: loss 0.035174
[epoch20, step1366]: loss 0.034644
[epoch20, step1367]: loss 0.033085
[epoch20, step1368]: loss 0.036197
[epoch20, step1369]: loss 0.035647
[epoch20, step1370]: loss 0.036221
[epoch20, step1371]: loss 0.034190
[epoch20, step1372]: loss 0.033525
[epoch20, step1373]: loss 0.036157
[epoch20, step1374]: loss 0.035390
[epoch20, step1375]: loss 0.035598
[epoch20, step1376]: loss 0.033487
[epoch20, step1377]: loss 0.034376
[epoch20, step1378]: loss 0.035009
[epoch20, step1379]: loss 0.035403
[epoch20, step1380]: loss 0.034180
[epoch20, step1381]: loss 0.033224
[epoch20, step1382]: loss 0.036755
[epoch20, step1383]: loss 0.034710
[epoch20, step1384]: loss 0.034455
[epoch20, step1385]: loss 0.033122
[epoch20, step1386]: loss 0.035130
[epoch20, step1387]: loss 0.035825
[epoch20, step1388]: loss 0.035571
[epoch20, step1389]: loss 0.033025
[epoch20, step1390]: loss 0.033821
[epoch20, step1391]: loss 0.036374
[epoch20, step1392]: loss 0.035270
[epoch20, step1393]: loss 0.035273
[epoch20, step1394]: loss 0.033860
[epoch20, step1395]: loss 0.035187
[epoch20, step1396]: loss 0.034898
[epoch20, step1397]: loss 0.035734
[epoch20, step1398]: loss 0.033344
[epoch20, step1399]: loss 0.034245
[epoch20, step1400]: loss 0.037221
[epoch20, step1401]: loss 0.034746
[epoch20, step1402]: loss 0.035092
[epoch20, step1403]: loss 0.032782
[epoch20, step1404]: loss 0.034571
[epoch20, step1405]: loss 0.035036
[epoch20, step1406]: loss 0.035606
[epoch20, step1407]: loss 0.034413
[epoch20, step1408]: loss 0.032722
[epoch20, step1409]: loss 0.035866
[epoch20, step1410]: loss 0.035410
[epoch20, step1411]: loss 0.034788
[epoch20, step1412]: loss 0.033477
[epoch20, step1413]: loss 0.034929
[epoch20, step1414]: loss 0.034544
[epoch20, step1415]: loss 0.035751
[epoch20, step1416]: loss 0.033246
[epoch20, step1417]: loss 0.033308
[epoch20, step1418]: loss 0.035840
[epoch20, step1419]: loss 0.035055
[epoch20, step1420]: loss 0.034605
[epoch20, step1421]: loss 0.033651
[epoch20, step1422]: loss 0.034713
[epoch20, step1423]: loss 0.034249
[epoch20, step1424]: loss 0.035232
[epoch20, step1425]: loss 0.032853
[epoch20, step1426]: loss 0.033201
[epoch20, step1427]: loss 0.037104
[epoch20, step1428]: loss 0.035330
[epoch20, step1429]: loss 0.034401
[epoch20, step1430]: loss 0.033091
[epoch20, step1431]: loss 0.034587
[epoch20, step1432]: loss 0.034238
[epoch20, step1433]: loss 0.035515
[epoch20, step1434]: loss 0.032884
[epoch20, step1435]: loss 0.033616
[epoch20, step1436]: loss 0.035959
[epoch20, step1437]: loss 0.034289
[epoch20, step1438]: loss 0.035647
[epoch20, step1439]: loss 0.032537
[epoch20, step1440]: loss 0.034119
[epoch20, step1441]: loss 0.034556
[epoch20, step1442]: loss 0.034218
[epoch20, step1443]: loss 0.032820
[epoch20, step1444]: loss 0.031959
[epoch20, step1445]: loss 0.035458
[epoch20, step1446]: loss 0.034009
[epoch20, step1447]: loss 0.034167
[epoch20, step1448]: loss 0.032200
[epoch20, step1449]: loss 0.033838
[epoch20, step1450]: loss 0.037288
[epoch20, step1451]: loss 0.040245
[epoch20, step1452]: loss 0.036070
[epoch20, step1453]: loss 0.040132
[epoch20, step1454]: loss 0.040180
[epoch20, step1455]: loss 0.038110
[epoch20, step1456]: loss 0.040565
[epoch20, step1457]: loss 0.036571
[epoch20, step1458]: loss 0.039233
[epoch20, step1459]: loss 0.039379
[epoch20, step1460]: loss 0.037866
[epoch20, step1461]: loss 0.042872
[epoch20, step1462]: loss 0.035136
[epoch20, step1463]: loss 0.036805
[epoch20, step1464]: loss 0.036247
[epoch20, step1465]: loss 0.035201
[epoch20, step1466]: loss 0.033833
[epoch20, step1467]: loss 0.035686
[epoch20, step1468]: loss 0.035468
[epoch20, step1469]: loss 0.036189
[epoch20, step1470]: loss 0.034260
[epoch20, step1471]: loss 0.033667
[epoch20, step1472]: loss 0.036815
[epoch20, step1473]: loss 0.035477
[epoch20, step1474]: loss 0.035715
[epoch20, step1475]: loss 0.033925
[epoch20, step1476]: loss 0.036121
[epoch20, step1477]: loss 0.035456
[epoch20, step1478]: loss 0.036282
[epoch20, step1479]: loss 0.033927
[epoch20, step1480]: loss 0.033779
[epoch20, step1481]: loss 0.035619
[epoch20, step1482]: loss 0.034994
[epoch20, step1483]: loss 0.034699
[epoch20, step1484]: loss 0.033915
[epoch20, step1485]: loss 0.034590
[epoch20, step1486]: loss 0.034166
[epoch20, step1487]: loss 0.035720
[epoch20, step1488]: loss 0.033988
[epoch20, step1489]: loss 0.033720
[epoch20, step1490]: loss 0.036102
[epoch20, step1491]: loss 0.036227
[epoch20, step1492]: loss 0.036395
[epoch20, step1493]: loss 0.034266
[epoch20, step1494]: loss 0.035043
[epoch20, step1495]: loss 0.035703
[epoch20, step1496]: loss 0.036122
[epoch20, step1497]: loss 0.034401
[epoch20, step1498]: loss 0.033452
[epoch20, step1499]: loss 0.036045
[epoch20, step1500]: loss 0.035896
[epoch20, step1501]: loss 0.034814
[epoch20, step1502]: loss 0.034092
[epoch20, step1503]: loss 0.036687
[epoch20, step1504]: loss 0.035982
[epoch20, step1505]: loss 0.036154
[epoch20, step1506]: loss 0.033935
[epoch20, step1507]: loss 0.034818
[epoch20, step1508]: loss 0.037633
[epoch20, step1509]: loss 0.033991
[epoch20, step1510]: loss 0.034697
[epoch20, step1511]: loss 0.035094
[epoch20, step1512]: loss 0.035320
[epoch20, step1513]: loss 0.033891
[epoch20, step1514]: loss 0.036815
[epoch20, step1515]: loss 0.034447
[epoch20, step1516]: loss 0.033237

[epoch20]: avg loss 0.032636

