[epoch1, step1]: loss 1.409586
[epoch1, step2]: loss 1.403597
[epoch1, step3]: loss 1.397692
[epoch1, step4]: loss 1.391835
[epoch1, step5]: loss 1.385977
[epoch1, step6]: loss 1.380159
[epoch1, step7]: loss 1.374335
[epoch1, step8]: loss 1.368603
[epoch1, step9]: loss 1.362765
[epoch1, step10]: loss 1.356985
[epoch1, step11]: loss 1.351304
[epoch1, step12]: loss 1.345546
[epoch1, step13]: loss 1.339659
[epoch1, step14]: loss 1.333870
[epoch1, step15]: loss 1.328155
[epoch1, step16]: loss 1.322160
[epoch1, step17]: loss 1.316542
[epoch1, step18]: loss 1.310452
[epoch1, step19]: loss 1.304371
[epoch1, step20]: loss 1.298663
[epoch1, step21]: loss 1.292562
[epoch1, step22]: loss 1.286156
[epoch1, step23]: loss 1.279921
[epoch1, step24]: loss 1.273957
[epoch1, step25]: loss 1.267247
[epoch1, step26]: loss 1.261231
[epoch1, step27]: loss 1.254340
[epoch1, step28]: loss 1.247625
[epoch1, step29]: loss 1.241301
[epoch1, step30]: loss 1.234545
[epoch1, step31]: loss 1.226965
[epoch1, step32]: loss 1.219974
[epoch1, step33]: loss 1.213090
[epoch1, step34]: loss 1.205172
[epoch1, step35]: loss 1.198195
[epoch1, step36]: loss 1.189729
[epoch1, step37]: loss 1.181537
[epoch1, step38]: loss 1.173943
[epoch1, step39]: loss 1.165610
[epoch1, step40]: loss 1.156410
[epoch1, step41]: loss 1.147311
[epoch1, step42]: loss 1.138899
[epoch1, step43]: loss 1.128602
[epoch1, step44]: loss 1.119997
[epoch1, step45]: loss 1.108932
[epoch1, step46]: loss 1.098183
[epoch1, step47]: loss 1.088184
[epoch1, step48]: loss 1.077062
[epoch1, step49]: loss 1.063990
[epoch1, step50]: loss 1.052486
[epoch1, step51]: loss 1.040564
[epoch1, step52]: loss 1.026329
[epoch1, step53]: loss 1.014538
[epoch1, step54]: loss 0.998456
[epoch1, step55]: loss 0.983199
[epoch1, step56]: loss 0.969257
[epoch1, step57]: loss 0.952701
[epoch1, step58]: loss 0.933588
[epoch1, step59]: loss 0.914812
[epoch1, step60]: loss 0.897750
[epoch1, step61]: loss 0.874879
[epoch1, step62]: loss 0.856227
[epoch1, step63]: loss 0.831108
[epoch1, step64]: loss 0.806359
[epoch1, step65]: loss 0.784099
[epoch1, step66]: loss 0.757286
[epoch1, step67]: loss 0.726094
[epoch1, step68]: loss 0.695706
[epoch1, step69]: loss 0.666111
[epoch1, step70]: loss 0.628650
[epoch1, step71]: loss 0.597933
[epoch1, step72]: loss 0.556917
[epoch1, step73]: loss 0.516328
[epoch1, step74]: loss 0.482996
[epoch1, step75]: loss 0.444096
[epoch1, step76]: loss 0.400449
[epoch1, step77]: loss 0.363019
[epoch1, step78]: loss 0.331579
[epoch1, step79]: loss 0.290865
[epoch1, step80]: loss 0.273992
[epoch1, step81]: loss 0.238854
[epoch1, step82]: loss 0.212978
[epoch1, step83]: loss 0.200839
[epoch1, step84]: loss 0.187764
[epoch1, step85]: loss 0.167645
[epoch1, step86]: loss 0.155144
[epoch1, step87]: loss 0.153344
[epoch1, step88]: loss 0.132299
[epoch1, step89]: loss 0.136913
[epoch1, step90]: loss 0.124877
[epoch1, step91]: loss 0.114810
[epoch1, step92]: loss 0.120337
[epoch1, step93]: loss 0.116816
[epoch1, step94]: loss 0.106274
[epoch1, step95]: loss 0.105348
[epoch1, step96]: loss 0.107011
[epoch1, step97]: loss 0.100040
[epoch1, step98]: loss 0.106469
[epoch1, step99]: loss 0.097387
[epoch1, step100]: loss 0.090827
[epoch1, step101]: loss 0.101418
[epoch1, step102]: loss 0.099608
[epoch1, step103]: loss 0.091473
[epoch1, step104]: loss 0.091366
[epoch1, step105]: loss 0.096461
[epoch1, step106]: loss 0.088133
[epoch1, step107]: loss 0.097151
[epoch1, step108]: loss 0.089709
[epoch1, step109]: loss 0.084974
[epoch1, step110]: loss 0.095103
[epoch1, step111]: loss 0.093246
[epoch1, step112]: loss 0.086807
[epoch1, step113]: loss 0.088238
[epoch1, step114]: loss 0.091222
[epoch1, step115]: loss 0.084210
[epoch1, step116]: loss 0.095165
[epoch1, step117]: loss 0.085557
[epoch1, step118]: loss 0.083790
[epoch1, step119]: loss 0.091429
[epoch1, step120]: loss 0.091011
[epoch1, step121]: loss 0.082899
[epoch1, step122]: loss 0.083357
[epoch1, step123]: loss 0.089921
[epoch1, step124]: loss 0.082329
[epoch1, step125]: loss 0.092105
[epoch1, step126]: loss 0.083151
[epoch1, step127]: loss 0.080012
[epoch1, step128]: loss 0.087992
[epoch1, step129]: loss 0.087582
[epoch1, step130]: loss 0.081863
[epoch1, step131]: loss 0.080213
[epoch1, step132]: loss 0.087442
[epoch1, step133]: loss 0.079333
[epoch1, step134]: loss 0.087820
[epoch1, step135]: loss 0.082774
[epoch1, step136]: loss 0.080902
[epoch1, step137]: loss 0.085682
[epoch1, step138]: loss 0.086547
[epoch1, step139]: loss 0.079511
[epoch1, step140]: loss 0.081111
[epoch1, step141]: loss 0.085835
[epoch1, step142]: loss 0.078113
[epoch1, step143]: loss 0.086430
[epoch1, step144]: loss 0.080715
[epoch1, step145]: loss 0.077297
[epoch1, step146]: loss 0.085101
[epoch1, step147]: loss 0.088230
[epoch1, step148]: loss 0.078044
[epoch1, step149]: loss 0.077491
[epoch1, step150]: loss 0.083016
[epoch1, step151]: loss 0.077108
[epoch1, step152]: loss 0.085945
[epoch1, step153]: loss 0.079119
[epoch1, step154]: loss 0.074724
[epoch1, step155]: loss 0.083444
[epoch1, step156]: loss 0.083023
[epoch1, step157]: loss 0.077561
[epoch1, step158]: loss 0.077790
[epoch1, step159]: loss 0.083137
[epoch1, step160]: loss 0.076324
[epoch1, step161]: loss 0.085754
[epoch1, step162]: loss 0.077931
[epoch1, step163]: loss 0.074160
[epoch1, step164]: loss 0.082795
[epoch1, step165]: loss 0.082646
[epoch1, step166]: loss 0.076676
[epoch1, step167]: loss 0.075159
[epoch1, step168]: loss 0.082423
[epoch1, step169]: loss 0.073791
[epoch1, step170]: loss 0.083887
[epoch1, step171]: loss 0.076841
[epoch1, step172]: loss 0.073513
[epoch1, step173]: loss 0.081554
[epoch1, step174]: loss 0.080876
[epoch1, step175]: loss 0.076480
[epoch1, step176]: loss 0.075692
[epoch1, step177]: loss 0.080713
[epoch1, step178]: loss 0.073432
[epoch1, step179]: loss 0.080130
[epoch1, step180]: loss 0.075938
[epoch1, step181]: loss 0.072529
[epoch1, step182]: loss 0.080252
[epoch1, step183]: loss 0.081492
[epoch1, step184]: loss 0.075906
[epoch1, step185]: loss 0.074567
[epoch1, step186]: loss 0.079130
[epoch1, step187]: loss 0.072510
[epoch1, step188]: loss 0.080202
[epoch1, step189]: loss 0.074175
[epoch1, step190]: loss 0.070284
[epoch1, step191]: loss 0.077882
[epoch1, step192]: loss 0.079961
[epoch1, step193]: loss 0.069018
[epoch1, step194]: loss 0.071224
[epoch1, step195]: loss 0.078453
[epoch1, step196]: loss 0.071435
[epoch1, step197]: loss 0.079344
[epoch1, step198]: loss 0.071259
[epoch1, step199]: loss 0.070370
[epoch1, step200]: loss 0.078449
[epoch1, step201]: loss 0.078939
[epoch1, step202]: loss 0.071229
[epoch1, step203]: loss 0.072086
[epoch1, step204]: loss 0.077503
[epoch1, step205]: loss 0.069105
[epoch1, step206]: loss 0.077943
[epoch1, step207]: loss 0.071884
[epoch1, step208]: loss 0.070213
[epoch1, step209]: loss 0.076919
[epoch1, step210]: loss 0.078752
[epoch1, step211]: loss 0.072151
[epoch1, step212]: loss 0.071978
[epoch1, step213]: loss 0.075192
[epoch1, step214]: loss 0.068372
[epoch1, step215]: loss 0.078025
[epoch1, step216]: loss 0.071808
[epoch1, step217]: loss 0.066684
[epoch1, step218]: loss 0.076026
[epoch1, step219]: loss 0.075522
[epoch1, step220]: loss 0.070684
[epoch1, step221]: loss 0.070786
[epoch1, step222]: loss 0.075079
[epoch1, step223]: loss 0.069110
[epoch1, step224]: loss 0.075995
[epoch1, step225]: loss 0.070398
[epoch1, step226]: loss 0.067543
[epoch1, step227]: loss 0.072823
[epoch1, step228]: loss 0.076152
[epoch1, step229]: loss 0.067716
[epoch1, step230]: loss 0.069967
[epoch1, step231]: loss 0.074784
[epoch1, step232]: loss 0.066905
[epoch1, step233]: loss 0.074200
[epoch1, step234]: loss 0.068753
[epoch1, step235]: loss 0.067527
[epoch1, step236]: loss 0.073992
[epoch1, step237]: loss 0.074451
[epoch1, step238]: loss 0.068028
[epoch1, step239]: loss 0.067219
[epoch1, step240]: loss 0.072199
[epoch1, step241]: loss 0.068048
[epoch1, step242]: loss 0.074606
[epoch1, step243]: loss 0.070098
[epoch1, step244]: loss 0.066061
[epoch1, step245]: loss 0.072198
[epoch1, step246]: loss 0.073392
[epoch1, step247]: loss 0.068334
[epoch1, step248]: loss 0.067208
[epoch1, step249]: loss 0.071461
[epoch1, step250]: loss 0.066591
[epoch1, step251]: loss 0.075165
[epoch1, step252]: loss 0.069137
[epoch1, step253]: loss 0.064864
[epoch1, step254]: loss 0.070898
[epoch1, step255]: loss 0.072808
[epoch1, step256]: loss 0.066593
[epoch1, step257]: loss 0.066678
[epoch1, step258]: loss 0.072744
[epoch1, step259]: loss 0.065433
[epoch1, step260]: loss 0.072115
[epoch1, step261]: loss 0.068939
[epoch1, step262]: loss 0.065571
[epoch1, step263]: loss 0.069987
[epoch1, step264]: loss 0.071304
[epoch1, step265]: loss 0.066856
[epoch1, step266]: loss 0.066436
[epoch1, step267]: loss 0.069725
[epoch1, step268]: loss 0.064866
[epoch1, step269]: loss 0.072594
[epoch1, step270]: loss 0.066051
[epoch1, step271]: loss 0.064294
[epoch1, step272]: loss 0.070715
[epoch1, step273]: loss 0.070705
[epoch1, step274]: loss 0.066654
[epoch1, step275]: loss 0.065023
[epoch1, step276]: loss 0.069348
[epoch1, step277]: loss 0.065170
[epoch1, step278]: loss 0.072102
[epoch1, step279]: loss 0.065561
[epoch1, step280]: loss 0.063326
[epoch1, step281]: loss 0.069597
[epoch1, step282]: loss 0.071184
[epoch1, step283]: loss 0.064382
[epoch1, step284]: loss 0.064203
[epoch1, step285]: loss 0.070781
[epoch1, step286]: loss 0.062377
[epoch1, step287]: loss 0.071430
[epoch1, step288]: loss 0.064794
[epoch1, step289]: loss 0.064458
[epoch1, step290]: loss 0.069592
[epoch1, step291]: loss 0.070365
[epoch1, step292]: loss 0.063069
[epoch1, step293]: loss 0.063900
[epoch1, step294]: loss 0.067365
[epoch1, step295]: loss 0.062317
[epoch1, step296]: loss 0.071858
[epoch1, step297]: loss 0.064351
[epoch1, step298]: loss 0.063174
[epoch1, step299]: loss 0.067348
[epoch1, step300]: loss 0.069697
[epoch1, step301]: loss 0.064020
[epoch1, step302]: loss 0.064664
[epoch1, step303]: loss 0.069018
[epoch1, step304]: loss 0.061899
[epoch1, step305]: loss 0.069325
[epoch1, step306]: loss 0.064470
[epoch1, step307]: loss 0.061004
[epoch1, step308]: loss 0.069132
[epoch1, step309]: loss 0.069106
[epoch1, step310]: loss 0.063710
[epoch1, step311]: loss 0.064137
[epoch1, step312]: loss 0.067182
[epoch1, step313]: loss 0.062836
[epoch1, step314]: loss 0.069244
[epoch1, step315]: loss 0.065531
[epoch1, step316]: loss 0.061000
[epoch1, step317]: loss 0.067924
[epoch1, step318]: loss 0.068268
[epoch1, step319]: loss 0.062111
[epoch1, step320]: loss 0.061205
[epoch1, step321]: loss 0.066404
[epoch1, step322]: loss 0.061335
[epoch1, step323]: loss 0.067598
[epoch1, step324]: loss 0.064377
[epoch1, step325]: loss 0.061161
[epoch1, step326]: loss 0.066607
[epoch1, step327]: loss 0.066471
[epoch1, step328]: loss 0.062714
[epoch1, step329]: loss 0.061974
[epoch1, step330]: loss 0.065975
[epoch1, step331]: loss 0.061260
[epoch1, step332]: loss 0.067118
[epoch1, step333]: loss 0.062702
[epoch1, step334]: loss 0.060193
[epoch1, step335]: loss 0.066713
[epoch1, step336]: loss 0.068478
[epoch1, step337]: loss 0.062216
[epoch1, step338]: loss 0.061104
[epoch1, step339]: loss 0.065454
[epoch1, step340]: loss 0.061185
[epoch1, step341]: loss 0.066741
[epoch1, step342]: loss 0.061720
[epoch1, step343]: loss 0.060212
[epoch1, step344]: loss 0.065250
[epoch1, step345]: loss 0.065310
[epoch1, step346]: loss 0.060527
[epoch1, step347]: loss 0.060842
[epoch1, step348]: loss 0.065550
[epoch1, step349]: loss 0.060855
[epoch1, step350]: loss 0.066133
[epoch1, step351]: loss 0.060532
[epoch1, step352]: loss 0.059243
[epoch1, step353]: loss 0.064999
[epoch1, step354]: loss 0.064234
[epoch1, step355]: loss 0.059275
[epoch1, step356]: loss 0.061972
[epoch1, step357]: loss 0.064907
[epoch1, step358]: loss 0.057472
[epoch1, step359]: loss 0.067890
[epoch1, step360]: loss 0.059450
[epoch1, step361]: loss 0.057838
[epoch1, step362]: loss 0.065704
[epoch1, step363]: loss 0.064983
[epoch1, step364]: loss 0.060136
[epoch1, step365]: loss 0.059925
[epoch1, step366]: loss 0.065004
[epoch1, step367]: loss 0.059088
[epoch1, step368]: loss 0.064949
[epoch1, step369]: loss 0.060558
[epoch1, step370]: loss 0.059442
[epoch1, step371]: loss 0.065667
[epoch1, step372]: loss 0.064215
[epoch1, step373]: loss 0.059068
[epoch1, step374]: loss 0.058669
[epoch1, step375]: loss 0.064717
[epoch1, step376]: loss 0.058669
[epoch1, step377]: loss 0.065705
[epoch1, step378]: loss 0.060960
[epoch1, step379]: loss 0.058988
[epoch1, step380]: loss 0.064722
[epoch1, step381]: loss 0.063871
[epoch1, step382]: loss 0.059982
[epoch1, step383]: loss 0.057969
[epoch1, step384]: loss 0.062414
[epoch1, step385]: loss 0.058240
[epoch1, step386]: loss 0.065232
[epoch1, step387]: loss 0.060042
[epoch1, step388]: loss 0.058786
[epoch1, step389]: loss 0.063488
[epoch1, step390]: loss 0.065186
[epoch1, step391]: loss 0.058488
[epoch1, step392]: loss 0.059896
[epoch1, step393]: loss 0.062002
[epoch1, step394]: loss 0.057904
[epoch1, step395]: loss 0.064098
[epoch1, step396]: loss 0.059660
[epoch1, step397]: loss 0.056737
[epoch1, step398]: loss 0.063201
[epoch1, step399]: loss 0.063310
[epoch1, step400]: loss 0.058216
[epoch1, step401]: loss 0.058285
[epoch1, step402]: loss 0.061914
[epoch1, step403]: loss 0.057393
[epoch1, step404]: loss 0.064519
[epoch1, step405]: loss 0.059403
[epoch1, step406]: loss 0.057246
[epoch1, step407]: loss 0.062122
[epoch1, step408]: loss 0.063079
[epoch1, step409]: loss 0.060211
[epoch1, step410]: loss 0.059218
[epoch1, step411]: loss 0.061851
[epoch1, step412]: loss 0.056285
[epoch1, step413]: loss 0.063457
[epoch1, step414]: loss 0.058101
[epoch1, step415]: loss 0.057002
[epoch1, step416]: loss 0.061170
[epoch1, step417]: loss 0.062992
[epoch1, step418]: loss 0.057627
[epoch1, step419]: loss 0.056647
[epoch1, step420]: loss 0.062020
[epoch1, step421]: loss 0.056215
[epoch1, step422]: loss 0.063107
[epoch1, step423]: loss 0.058455
[epoch1, step424]: loss 0.056436
[epoch1, step425]: loss 0.062003
[epoch1, step426]: loss 0.062770
[epoch1, step427]: loss 0.057886
[epoch1, step428]: loss 0.057221
[epoch1, step429]: loss 0.062330
[epoch1, step430]: loss 0.056109
[epoch1, step431]: loss 0.063351
[epoch1, step432]: loss 0.057810
[epoch1, step433]: loss 0.056871
[epoch1, step434]: loss 0.061291
[epoch1, step435]: loss 0.062494
[epoch1, step436]: loss 0.056497
[epoch1, step437]: loss 0.057484
[epoch1, step438]: loss 0.061739
[epoch1, step439]: loss 0.056405
[epoch1, step440]: loss 0.062297
[epoch1, step441]: loss 0.058130
[epoch1, step442]: loss 0.055341
[epoch1, step443]: loss 0.061700
[epoch1, step444]: loss 0.061174
[epoch1, step445]: loss 0.057548
[epoch1, step446]: loss 0.057506
[epoch1, step447]: loss 0.061833
[epoch1, step448]: loss 0.055948
[epoch1, step449]: loss 0.061809
[epoch1, step450]: loss 0.056160
[epoch1, step451]: loss 0.054747
[epoch1, step452]: loss 0.058773
[epoch1, step453]: loss 0.061324
[epoch1, step454]: loss 0.056285
[epoch1, step455]: loss 0.056662
[epoch1, step456]: loss 0.058660
[epoch1, step457]: loss 0.056374
[epoch1, step458]: loss 0.061167
[epoch1, step459]: loss 0.057903
[epoch1, step460]: loss 0.055004
[epoch1, step461]: loss 0.061381
[epoch1, step462]: loss 0.059738
[epoch1, step463]: loss 0.056458
[epoch1, step464]: loss 0.055951
[epoch1, step465]: loss 0.061719
[epoch1, step466]: loss 0.054799
[epoch1, step467]: loss 0.060771
[epoch1, step468]: loss 0.056458
[epoch1, step469]: loss 0.054659
[epoch1, step470]: loss 0.060307
[epoch1, step471]: loss 0.059633
[epoch1, step472]: loss 0.056411
[epoch1, step473]: loss 0.055146
[epoch1, step474]: loss 0.059416
[epoch1, step475]: loss 0.054949
[epoch1, step476]: loss 0.061663
[epoch1, step477]: loss 0.056048
[epoch1, step478]: loss 0.053516
[epoch1, step479]: loss 0.059241
[epoch1, step480]: loss 0.058540
[epoch1, step481]: loss 0.054689
[epoch1, step482]: loss 0.054504
[epoch1, step483]: loss 0.059706
[epoch1, step484]: loss 0.054732
[epoch1, step485]: loss 0.060792
[epoch1, step486]: loss 0.056532
[epoch1, step487]: loss 0.052903
[epoch1, step488]: loss 0.059735
[epoch1, step489]: loss 0.058593
[epoch1, step490]: loss 0.055659
[epoch1, step491]: loss 0.055300
[epoch1, step492]: loss 0.058209
[epoch1, step493]: loss 0.053571
[epoch1, step494]: loss 0.059253
[epoch1, step495]: loss 0.057331
[epoch1, step496]: loss 0.053534
[epoch1, step497]: loss 0.058870
[epoch1, step498]: loss 0.058800
[epoch1, step499]: loss 0.055256
[epoch1, step500]: loss 0.054183
[epoch1, step501]: loss 0.057683
[epoch1, step502]: loss 0.053532
[epoch1, step503]: loss 0.060074
[epoch1, step504]: loss 0.054923
[epoch1, step505]: loss 0.052149
[epoch1, step506]: loss 0.059057
[epoch1, step507]: loss 0.059127
[epoch1, step508]: loss 0.055318
[epoch1, step509]: loss 0.054372
[epoch1, step510]: loss 0.058200
[epoch1, step511]: loss 0.053878
[epoch1, step512]: loss 0.059930
[epoch1, step513]: loss 0.055151
[epoch1, step514]: loss 0.053368
[epoch1, step515]: loss 0.058095
[epoch1, step516]: loss 0.059159
[epoch1, step517]: loss 0.054176
[epoch1, step518]: loss 0.054277
[epoch1, step519]: loss 0.057611
[epoch1, step520]: loss 0.052396
[epoch1, step521]: loss 0.058471
[epoch1, step522]: loss 0.053699
[epoch1, step523]: loss 0.052594
[epoch1, step524]: loss 0.056792
[epoch1, step525]: loss 0.058611
[epoch1, step526]: loss 0.054055
[epoch1, step527]: loss 0.053441
[epoch1, step528]: loss 0.057607
[epoch1, step529]: loss 0.052024
[epoch1, step530]: loss 0.059284
[epoch1, step531]: loss 0.054063
[epoch1, step532]: loss 0.051590
[epoch1, step533]: loss 0.058819
[epoch1, step534]: loss 0.057705
[epoch1, step535]: loss 0.054072
[epoch1, step536]: loss 0.053635
[epoch1, step537]: loss 0.056944
[epoch1, step538]: loss 0.052595
[epoch1, step539]: loss 0.057986
[epoch1, step540]: loss 0.053334
[epoch1, step541]: loss 0.051230
[epoch1, step542]: loss 0.056981
[epoch1, step543]: loss 0.056881
[epoch1, step544]: loss 0.053025
[epoch1, step545]: loss 0.052005
[epoch1, step546]: loss 0.057333
[epoch1, step547]: loss 0.051613
[epoch1, step548]: loss 0.057729
[epoch1, step549]: loss 0.053975
[epoch1, step550]: loss 0.051584
[epoch1, step551]: loss 0.056449
[epoch1, step552]: loss 0.056241
[epoch1, step553]: loss 0.053474
[epoch1, step554]: loss 0.052578
[epoch1, step555]: loss 0.055889
[epoch1, step556]: loss 0.051669
[epoch1, step557]: loss 0.056692
[epoch1, step558]: loss 0.053579
[epoch1, step559]: loss 0.050386
[epoch1, step560]: loss 0.056273
[epoch1, step561]: loss 0.056429
[epoch1, step562]: loss 0.052481
[epoch1, step563]: loss 0.045945
[epoch1, step564]: loss 0.046200
[epoch1, step565]: loss 0.044182
[epoch1, step566]: loss 0.053244
[epoch1, step567]: loss 0.043013
[epoch1, step568]: loss 0.043949
[epoch1, step569]: loss 0.039992
[epoch1, step570]: loss 0.050598
[epoch1, step571]: loss 0.045876
[epoch1, step572]: loss 0.044826
[epoch1, step573]: loss 0.047112
[epoch1, step574]: loss 0.047545
[epoch1, step575]: loss 0.037502
[epoch1, step576]: loss 0.038894
[epoch1, step577]: loss 0.044582
[epoch1, step578]: loss 0.035621
[epoch1, step579]: loss 0.048110
[epoch1, step580]: loss 0.037523
[epoch1, step581]: loss 0.044676
[epoch1, step582]: loss 0.043708
[epoch1, step583]: loss 0.040215
[epoch1, step584]: loss 0.041828
[epoch1, step585]: loss 0.044747
[epoch1, step586]: loss 0.040140
[epoch1, step587]: loss 0.047713
[epoch1, step588]: loss 0.041463
[epoch1, step589]: loss 0.041192
[epoch1, step590]: loss 0.047592
[epoch1, step591]: loss 0.038210
[epoch1, step592]: loss 0.044994
[epoch1, step593]: loss 0.040650
[epoch1, step594]: loss 0.044618
[epoch1, step595]: loss 0.046667
[epoch1, step596]: loss 0.041418
[epoch1, step597]: loss 0.043558
[epoch1, step598]: loss 0.046224
[epoch1, step599]: loss 0.043091
[epoch1, step600]: loss 0.046986
[epoch1, step601]: loss 0.035739
[epoch1, step602]: loss 0.040662
[epoch1, step603]: loss 0.045953
[epoch1, step604]: loss 0.046688
[epoch1, step605]: loss 0.043601
[epoch1, step606]: loss 0.042762
[epoch1, step607]: loss 0.047863
[epoch1, step608]: loss 0.044879
[epoch1, step609]: loss 0.046131
[epoch1, step610]: loss 0.045589
[epoch1, step611]: loss 0.045635
[epoch1, step612]: loss 0.044439
[epoch1, step613]: loss 0.036543
[epoch1, step614]: loss 0.042970
[epoch1, step615]: loss 0.049821
[epoch1, step616]: loss 0.041851
[epoch1, step617]: loss 0.040998
[epoch1, step618]: loss 0.045822
[epoch1, step619]: loss 0.046486
[epoch1, step620]: loss 0.042830
[epoch1, step621]: loss 0.045591
[epoch1, step622]: loss 0.037246
[epoch1, step623]: loss 0.041445
[epoch1, step624]: loss 0.045760
[epoch1, step625]: loss 0.044498
[epoch1, step626]: loss 0.047800
[epoch1, step627]: loss 0.040529
[epoch1, step628]: loss 0.044446
[epoch1, step629]: loss 0.036900
[epoch1, step630]: loss 0.039789
[epoch1, step631]: loss 0.052103
[epoch1, step632]: loss 0.042116
[epoch1, step633]: loss 0.043135
[epoch1, step634]: loss 0.045023
[epoch1, step635]: loss 0.044624
[epoch1, step636]: loss 0.037744
[epoch1, step637]: loss 0.046081
[epoch1, step638]: loss 0.046330
[epoch1, step639]: loss 0.039131
[epoch1, step640]: loss 0.048225
[epoch1, step641]: loss 0.050481
[epoch1, step642]: loss 0.043426
[epoch1, step643]: loss 0.043305
[epoch1, step644]: loss 0.044585
[epoch1, step645]: loss 0.041218
[epoch1, step646]: loss 0.043824
[epoch1, step647]: loss 0.040419
[epoch1, step648]: loss 0.042071
[epoch1, step649]: loss 0.048309
[epoch1, step650]: loss 0.039711
[epoch1, step651]: loss 0.045375
[epoch1, step652]: loss 0.045223
[epoch1, step653]: loss 0.046435
[epoch1, step654]: loss 0.040172
[epoch1, step655]: loss 0.042103
[epoch1, step656]: loss 0.039384
[epoch1, step657]: loss 0.046705
[epoch1, step658]: loss 0.043295
[epoch1, step659]: loss 0.046309
[epoch1, step660]: loss 0.039444
[epoch1, step661]: loss 0.045477
[epoch1, step662]: loss 0.040759
[epoch1, step663]: loss 0.038614
[epoch1, step664]: loss 0.043171
[epoch1, step665]: loss 0.045580
[epoch1, step666]: loss 0.045227
[epoch1, step667]: loss 0.045031
[epoch1, step668]: loss 0.040534
[epoch1, step669]: loss 0.044360
[epoch1, step670]: loss 0.045529
[epoch1, step671]: loss 0.037010
[epoch1, step672]: loss 0.042125
[epoch1, step673]: loss 0.040123
[epoch1, step674]: loss 0.037168
[epoch1, step675]: loss 0.035910
[epoch1, step676]: loss 0.041233
[epoch1, step677]: loss 0.042518
[epoch1, step678]: loss 0.039742
[epoch1, step679]: loss 0.040914
[epoch1, step680]: loss 0.050191
[epoch1, step681]: loss 0.037727
[epoch1, step682]: loss 0.043574
[epoch1, step683]: loss 0.043297
[epoch1, step684]: loss 0.042671
[epoch1, step685]: loss 0.041266
[epoch1, step686]: loss 0.046120
[epoch1, step687]: loss 0.043985
[epoch1, step688]: loss 0.041112
[epoch1, step689]: loss 0.041296
[epoch1, step690]: loss 0.043201
[epoch1, step691]: loss 0.042003
[epoch1, step692]: loss 0.039998
[epoch1, step693]: loss 0.046435
[epoch1, step694]: loss 0.038660
[epoch1, step695]: loss 0.045093
[epoch1, step696]: loss 0.042628
[epoch1, step697]: loss 0.045582
[epoch1, step698]: loss 0.041554
[epoch1, step699]: loss 0.040193
[epoch1, step700]: loss 0.037617
[epoch1, step701]: loss 0.043724
[epoch1, step702]: loss 0.037187
[epoch1, step703]: loss 0.040388
[epoch1, step704]: loss 0.044123
[epoch1, step705]: loss 0.041799
[epoch1, step706]: loss 0.040186
[epoch1, step707]: loss 0.040297
[epoch1, step708]: loss 0.042279
[epoch1, step709]: loss 0.045132
[epoch1, step710]: loss 0.039974
[epoch1, step711]: loss 0.043114
[epoch1, step712]: loss 0.043339
[epoch1, step713]: loss 0.044369
[epoch1, step714]: loss 0.037848
[epoch1, step715]: loss 0.039450
[epoch1, step716]: loss 0.043086
[epoch1, step717]: loss 0.039042
[epoch1, step718]: loss 0.041575
[epoch1, step719]: loss 0.053272
[epoch1, step720]: loss 0.041402
[epoch1, step721]: loss 0.039564
[epoch1, step722]: loss 0.050435
[epoch1, step723]: loss 0.044385
[epoch1, step724]: loss 0.038913
[epoch1, step725]: loss 0.045340
[epoch1, step726]: loss 0.037712
[epoch1, step727]: loss 0.040299
[epoch1, step728]: loss 0.043492
[epoch1, step729]: loss 0.037545
[epoch1, step730]: loss 0.038409
[epoch1, step731]: loss 0.043162
[epoch1, step732]: loss 0.042494
[epoch1, step733]: loss 0.040144
[epoch1, step734]: loss 0.039464
[epoch1, step735]: loss 0.044890
[epoch1, step736]: loss 0.041688
[epoch1, step737]: loss 0.043721
[epoch1, step738]: loss 0.035673
[epoch1, step739]: loss 0.043366
[epoch1, step740]: loss 0.039558
[epoch1, step741]: loss 0.042651
[epoch1, step742]: loss 0.038569
[epoch1, step743]: loss 0.040008
[epoch1, step744]: loss 0.039599
[epoch1, step745]: loss 0.040097
[epoch1, step746]: loss 0.042713
[epoch1, step747]: loss 0.045894
[epoch1, step748]: loss 0.042308
[epoch1, step749]: loss 0.042611
[epoch1, step750]: loss 0.044930
[epoch1, step751]: loss 0.038296
[epoch1, step752]: loss 0.040662
[epoch1, step753]: loss 0.041720
[epoch1, step754]: loss 0.039548
[epoch1, step755]: loss 0.042894
[epoch1, step756]: loss 0.039842
[epoch1, step757]: loss 0.035456
[epoch1, step758]: loss 0.039983
[epoch1, step759]: loss 0.038432
[epoch1, step760]: loss 0.039869
[epoch1, step761]: loss 0.043070
[epoch1, step762]: loss 0.036551
[epoch1, step763]: loss 0.042345
[epoch1, step764]: loss 0.040842
[epoch1, step765]: loss 0.042822
[epoch1, step766]: loss 0.041439
[epoch1, step767]: loss 0.046226
[epoch1, step768]: loss 0.035894
[epoch1, step769]: loss 0.042691
[epoch1, step770]: loss 0.041696
[epoch1, step771]: loss 0.038186
[epoch1, step772]: loss 0.045494
[epoch1, step773]: loss 0.041909
[epoch1, step774]: loss 0.040164
[epoch1, step775]: loss 0.034980
[epoch1, step776]: loss 0.042625
[epoch1, step777]: loss 0.037528
[epoch1, step778]: loss 0.044359
[epoch1, step779]: loss 0.040262
[epoch1, step780]: loss 0.034440
[epoch1, step781]: loss 0.040321
[epoch1, step782]: loss 0.037751
[epoch1, step783]: loss 0.034739
[epoch1, step784]: loss 0.035632
[epoch1, step785]: loss 0.036292
[epoch1, step786]: loss 0.039668
[epoch1, step787]: loss 0.039227
[epoch1, step788]: loss 0.041023
[epoch1, step789]: loss 0.040346
[epoch1, step790]: loss 0.038699
[epoch1, step791]: loss 0.043628
[epoch1, step792]: loss 0.040936
[epoch1, step793]: loss 0.043370
[epoch1, step794]: loss 0.035226
[epoch1, step795]: loss 0.040802
[epoch1, step796]: loss 0.044791
[epoch1, step797]: loss 0.043661
[epoch1, step798]: loss 0.043913
[epoch1, step799]: loss 0.042136
[epoch1, step800]: loss 0.036797
[epoch1, step801]: loss 0.038415
[epoch1, step802]: loss 0.038131
[epoch1, step803]: loss 0.042383
[epoch1, step804]: loss 0.044383
[epoch1, step805]: loss 0.044683
[epoch1, step806]: loss 0.036886
[epoch1, step807]: loss 0.035567
[epoch1, step808]: loss 0.039358
[epoch1, step809]: loss 0.036964
[epoch1, step810]: loss 0.041466
[epoch1, step811]: loss 0.041030
[epoch1, step812]: loss 0.039905
[epoch1, step813]: loss 0.038817
[epoch1, step814]: loss 0.041200
[epoch1, step815]: loss 0.039739
[epoch1, step816]: loss 0.040577
[epoch1, step817]: loss 0.040504
[epoch1, step818]: loss 0.036703
[epoch1, step819]: loss 0.036137
[epoch1, step820]: loss 0.038938
[epoch1, step821]: loss 0.035840
[epoch1, step822]: loss 0.047086
[epoch1, step823]: loss 0.039410
[epoch1, step824]: loss 0.042030
[epoch1, step825]: loss 0.041552
[epoch1, step826]: loss 0.039262
[epoch1, step827]: loss 0.042406
[epoch1, step828]: loss 0.044650
[epoch1, step829]: loss 0.043056
[epoch1, step830]: loss 0.037367
[epoch1, step831]: loss 0.042372
[epoch1, step832]: loss 0.036217
[epoch1, step833]: loss 0.044498
[epoch1, step834]: loss 0.042372
[epoch1, step835]: loss 0.035120
[epoch1, step836]: loss 0.044103
[epoch1, step837]: loss 0.041199
[epoch1, step838]: loss 0.040864
[epoch1, step839]: loss 0.044522
[epoch1, step840]: loss 0.034628
[epoch1, step841]: loss 0.039991
[epoch1, step842]: loss 0.043649
[epoch1, step843]: loss 0.041263
[epoch1, step844]: loss 0.040486
[epoch1, step845]: loss 0.035958
[epoch1, step846]: loss 0.043384
[epoch1, step847]: loss 0.043036
[epoch1, step848]: loss 0.040166
[epoch1, step849]: loss 0.039321
[epoch1, step850]: loss 0.038074
[epoch1, step851]: loss 0.039947
[epoch1, step852]: loss 0.037230
[epoch1, step853]: loss 0.046562
[epoch1, step854]: loss 0.037794
[epoch1, step855]: loss 0.042840
[epoch1, step856]: loss 0.035941
[epoch1, step857]: loss 0.040413
[epoch1, step858]: loss 0.039206
[epoch1, step859]: loss 0.038131
[epoch1, step860]: loss 0.037550
[epoch1, step861]: loss 0.037292
[epoch1, step862]: loss 0.036930
[epoch1, step863]: loss 0.035026
[epoch1, step864]: loss 0.042070
[epoch1, step865]: loss 0.039002
[epoch1, step866]: loss 0.039923
[epoch1, step867]: loss 0.041715
[epoch1, step868]: loss 0.042792
[epoch1, step869]: loss 0.038187
[epoch1, step870]: loss 0.046987
[epoch1, step871]: loss 0.038011
[epoch1, step872]: loss 0.041335
[epoch1, step873]: loss 0.041088
[epoch1, step874]: loss 0.038543
[epoch1, step875]: loss 0.038863
[epoch1, step876]: loss 0.040014
[epoch1, step877]: loss 0.033006
[epoch1, step878]: loss 0.037539
[epoch1, step879]: loss 0.044344
[epoch1, step880]: loss 0.040400
[epoch1, step881]: loss 0.037206
[epoch1, step882]: loss 0.038699
[epoch1, step883]: loss 0.038357
[epoch1, step884]: loss 0.041398
[epoch1, step885]: loss 0.041273
[epoch1, step886]: loss 0.041489
[epoch1, step887]: loss 0.039032
[epoch1, step888]: loss 0.039862
[epoch1, step889]: loss 0.038892
[epoch1, step890]: loss 0.039091
[epoch1, step891]: loss 0.041146
[epoch1, step892]: loss 0.033866
[epoch1, step893]: loss 0.039032
[epoch1, step894]: loss 0.039692
[epoch1, step895]: loss 0.036052
[epoch1, step896]: loss 0.037048
[epoch1, step897]: loss 0.040498
[epoch1, step898]: loss 0.041734
[epoch1, step899]: loss 0.044032
[epoch1, step900]: loss 0.041897
[epoch1, step901]: loss 0.041505
[epoch1, step902]: loss 0.038387
[epoch1, step903]: loss 0.040084
[epoch1, step904]: loss 0.043047
[epoch1, step905]: loss 0.043069
[epoch1, step906]: loss 0.035935
[epoch1, step907]: loss 0.038085
[epoch1, step908]: loss 0.036653
[epoch1, step909]: loss 0.041724
[epoch1, step910]: loss 0.037410
[epoch1, step911]: loss 0.039847
[epoch1, step912]: loss 0.037644
[epoch1, step913]: loss 0.038830
[epoch1, step914]: loss 0.045045
[epoch1, step915]: loss 0.038233
[epoch1, step916]: loss 0.037463
[epoch1, step917]: loss 0.039228
[epoch1, step918]: loss 0.044629
[epoch1, step919]: loss 0.039018
[epoch1, step920]: loss 0.042401
[epoch1, step921]: loss 0.038732
[epoch1, step922]: loss 0.038040
[epoch1, step923]: loss 0.037796
[epoch1, step924]: loss 0.034536
[epoch1, step925]: loss 0.040363
[epoch1, step926]: loss 0.040203
[epoch1, step927]: loss 0.040166
[epoch1, step928]: loss 0.038682
[epoch1, step929]: loss 0.042702
[epoch1, step930]: loss 0.039894
[epoch1, step931]: loss 0.042168
[epoch1, step932]: loss 0.034930
[epoch1, step933]: loss 0.044607
[epoch1, step934]: loss 0.037284
[epoch1, step935]: loss 0.037105
[epoch1, step936]: loss 0.036520
[epoch1, step937]: loss 0.041642
[epoch1, step938]: loss 0.042145
[epoch1, step939]: loss 0.035048
[epoch1, step940]: loss 0.037605
[epoch1, step941]: loss 0.041728
[epoch1, step942]: loss 0.040706
[epoch1, step943]: loss 0.038270
[epoch1, step944]: loss 0.042453
[epoch1, step945]: loss 0.033899
[epoch1, step946]: loss 0.040274
[epoch1, step947]: loss 0.043301
[epoch1, step948]: loss 0.034332
[epoch1, step949]: loss 0.037134
[epoch1, step950]: loss 0.041437
[epoch1, step951]: loss 0.044052
[epoch1, step952]: loss 0.039159
[epoch1, step953]: loss 0.042407
[epoch1, step954]: loss 0.037136
[epoch1, step955]: loss 0.047432
[epoch1, step956]: loss 0.058070
[epoch1, step957]: loss 0.054576
[epoch1, step958]: loss 0.053311
[epoch1, step959]: loss 0.056829
[epoch1, step960]: loss 0.054425
[epoch1, step961]: loss 0.055540
[epoch1, step962]: loss 0.054699
[epoch1, step963]: loss 0.053545
[epoch1, step964]: loss 0.054488
[epoch1, step965]: loss 0.055700
[epoch1, step966]: loss 0.053908
[epoch1, step967]: loss 0.053239
[epoch1, step968]: loss 0.055093
[epoch1, step969]: loss 0.054285
[epoch1, step970]: loss 0.054994
[epoch1, step971]: loss 0.053827
[epoch1, step972]: loss 0.053367
[epoch1, step973]: loss 0.053307
[epoch1, step974]: loss 0.056139
[epoch1, step975]: loss 0.053073
[epoch1, step976]: loss 0.052326
[epoch1, step977]: loss 0.055029
[epoch1, step978]: loss 0.053568
[epoch1, step979]: loss 0.053827
[epoch1, step980]: loss 0.052990
[epoch1, step981]: loss 0.052765
[epoch1, step982]: loss 0.053286
[epoch1, step983]: loss 0.055185
[epoch1, step984]: loss 0.052697
[epoch1, step985]: loss 0.052261
[epoch1, step986]: loss 0.054979
[epoch1, step987]: loss 0.053467
[epoch1, step988]: loss 0.054119
[epoch1, step989]: loss 0.053751
[epoch1, step990]: loss 0.052424
[epoch1, step991]: loss 0.053764
[epoch1, step992]: loss 0.054962
[epoch1, step993]: loss 0.052721
[epoch1, step994]: loss 0.051996
[epoch1, step995]: loss 0.054489
[epoch1, step996]: loss 0.052800
[epoch1, step997]: loss 0.053798
[epoch1, step998]: loss 0.053415
[epoch1, step999]: loss 0.052788
[epoch1, step1000]: loss 0.052613
[epoch1, step1001]: loss 0.054977
[epoch1, step1002]: loss 0.052682
[epoch1, step1003]: loss 0.051891
[epoch1, step1004]: loss 0.054471
[epoch1, step1005]: loss 0.052325
[epoch1, step1006]: loss 0.053248
[epoch1, step1007]: loss 0.052580
[epoch1, step1008]: loss 0.052130
[epoch1, step1009]: loss 0.052706
[epoch1, step1010]: loss 0.054839
[epoch1, step1011]: loss 0.052152
[epoch1, step1012]: loss 0.051497
[epoch1, step1013]: loss 0.053697
[epoch1, step1014]: loss 0.052859
[epoch1, step1015]: loss 0.053261
[epoch1, step1016]: loss 0.052312
[epoch1, step1017]: loss 0.051683
[epoch1, step1018]: loss 0.052267
[epoch1, step1019]: loss 0.054300
[epoch1, step1020]: loss 0.051655
[epoch1, step1021]: loss 0.050994
[epoch1, step1022]: loss 0.053287
[epoch1, step1023]: loss 0.052139
[epoch1, step1024]: loss 0.053264
[epoch1, step1025]: loss 0.051768
[epoch1, step1026]: loss 0.051325
[epoch1, step1027]: loss 0.051890
[epoch1, step1028]: loss 0.054003
[epoch1, step1029]: loss 0.051764
[epoch1, step1030]: loss 0.050508
[epoch1, step1031]: loss 0.052844
[epoch1, step1032]: loss 0.052000
[epoch1, step1033]: loss 0.052702
[epoch1, step1034]: loss 0.051849
[epoch1, step1035]: loss 0.051266
[epoch1, step1036]: loss 0.051846
[epoch1, step1037]: loss 0.053604
[epoch1, step1038]: loss 0.051392
[epoch1, step1039]: loss 0.050801
[epoch1, step1040]: loss 0.052987
[epoch1, step1041]: loss 0.051638
[epoch1, step1042]: loss 0.052038
[epoch1, step1043]: loss 0.051517
[epoch1, step1044]: loss 0.051300
[epoch1, step1045]: loss 0.051709
[epoch1, step1046]: loss 0.053777
[epoch1, step1047]: loss 0.051613
[epoch1, step1048]: loss 0.050423
[epoch1, step1049]: loss 0.053376
[epoch1, step1050]: loss 0.051878
[epoch1, step1051]: loss 0.052393
[epoch1, step1052]: loss 0.052097
[epoch1, step1053]: loss 0.051527
[epoch1, step1054]: loss 0.051689
[epoch1, step1055]: loss 0.053279
[epoch1, step1056]: loss 0.051062
[epoch1, step1057]: loss 0.050748
[epoch1, step1058]: loss 0.053828
[epoch1, step1059]: loss 0.052436
[epoch1, step1060]: loss 0.052249
[epoch1, step1061]: loss 0.051220
[epoch1, step1062]: loss 0.051317
[epoch1, step1063]: loss 0.051585
[epoch1, step1064]: loss 0.053466
[epoch1, step1065]: loss 0.051171
[epoch1, step1066]: loss 0.050520
[epoch1, step1067]: loss 0.052626
[epoch1, step1068]: loss 0.050941
[epoch1, step1069]: loss 0.051905
[epoch1, step1070]: loss 0.051499
[epoch1, step1071]: loss 0.051268
[epoch1, step1072]: loss 0.051538
[epoch1, step1073]: loss 0.053196
[epoch1, step1074]: loss 0.050891
[epoch1, step1075]: loss 0.050678
[epoch1, step1076]: loss 0.052848
[epoch1, step1077]: loss 0.051374
[epoch1, step1078]: loss 0.052155
[epoch1, step1079]: loss 0.051964
[epoch1, step1080]: loss 0.050994
[epoch1, step1081]: loss 0.051232
[epoch1, step1082]: loss 0.052979
[epoch1, step1083]: loss 0.051408
[epoch1, step1084]: loss 0.050368
[epoch1, step1085]: loss 0.052043
[epoch1, step1086]: loss 0.051093
[epoch1, step1087]: loss 0.051764
[epoch1, step1088]: loss 0.050983
[epoch1, step1089]: loss 0.050624
[epoch1, step1090]: loss 0.051176
[epoch1, step1091]: loss 0.053168
[epoch1, step1092]: loss 0.050814
[epoch1, step1093]: loss 0.049787
[epoch1, step1094]: loss 0.051638
[epoch1, step1095]: loss 0.050724
[epoch1, step1096]: loss 0.051443
[epoch1, step1097]: loss 0.050889
[epoch1, step1098]: loss 0.050565
[epoch1, step1099]: loss 0.051050
[epoch1, step1100]: loss 0.053085
[epoch1, step1101]: loss 0.051101
[epoch1, step1102]: loss 0.049883
[epoch1, step1103]: loss 0.051891
[epoch1, step1104]: loss 0.050844
[epoch1, step1105]: loss 0.051560
[epoch1, step1106]: loss 0.050579
[epoch1, step1107]: loss 0.050508
[epoch1, step1108]: loss 0.051236
[epoch1, step1109]: loss 0.053198
[epoch1, step1110]: loss 0.050898
[epoch1, step1111]: loss 0.050322
[epoch1, step1112]: loss 0.052153
[epoch1, step1113]: loss 0.050784
[epoch1, step1114]: loss 0.051809
[epoch1, step1115]: loss 0.050804
[epoch1, step1116]: loss 0.050629
[epoch1, step1117]: loss 0.050569
[epoch1, step1118]: loss 0.052596
[epoch1, step1119]: loss 0.050262
[epoch1, step1120]: loss 0.049555
[epoch1, step1121]: loss 0.051833
[epoch1, step1122]: loss 0.050231
[epoch1, step1123]: loss 0.051096
[epoch1, step1124]: loss 0.050975
[epoch1, step1125]: loss 0.050467
[epoch1, step1126]: loss 0.051159
[epoch1, step1127]: loss 0.052399
[epoch1, step1128]: loss 0.050571
[epoch1, step1129]: loss 0.049599
[epoch1, step1130]: loss 0.051957
[epoch1, step1131]: loss 0.050761
[epoch1, step1132]: loss 0.051216
[epoch1, step1133]: loss 0.050244
[epoch1, step1134]: loss 0.049844
[epoch1, step1135]: loss 0.051072
[epoch1, step1136]: loss 0.052611
[epoch1, step1137]: loss 0.050286
[epoch1, step1138]: loss 0.049682
[epoch1, step1139]: loss 0.051695
[epoch1, step1140]: loss 0.050343
[epoch1, step1141]: loss 0.050929
[epoch1, step1142]: loss 0.050428
[epoch1, step1143]: loss 0.050004
[epoch1, step1144]: loss 0.050712
[epoch1, step1145]: loss 0.052045
[epoch1, step1146]: loss 0.049945
[epoch1, step1147]: loss 0.050202
[epoch1, step1148]: loss 0.051669
[epoch1, step1149]: loss 0.050671
[epoch1, step1150]: loss 0.050862
[epoch1, step1151]: loss 0.050727
[epoch1, step1152]: loss 0.050559
[epoch1, step1153]: loss 0.050000
[epoch1, step1154]: loss 0.052460
[epoch1, step1155]: loss 0.050160
[epoch1, step1156]: loss 0.049128
[epoch1, step1157]: loss 0.051605
[epoch1, step1158]: loss 0.050478
[epoch1, step1159]: loss 0.051036
[epoch1, step1160]: loss 0.050597
[epoch1, step1161]: loss 0.050202
[epoch1, step1162]: loss 0.050339
[epoch1, step1163]: loss 0.051567
[epoch1, step1164]: loss 0.050028
[epoch1, step1165]: loss 0.049830
[epoch1, step1166]: loss 0.051470
[epoch1, step1167]: loss 0.049807
[epoch1, step1168]: loss 0.050812
[epoch1, step1169]: loss 0.050140
[epoch1, step1170]: loss 0.049810
[epoch1, step1171]: loss 0.050088
[epoch1, step1172]: loss 0.051809
[epoch1, step1173]: loss 0.050042
[epoch1, step1174]: loss 0.049556
[epoch1, step1175]: loss 0.051264
[epoch1, step1176]: loss 0.049984
[epoch1, step1177]: loss 0.050933
[epoch1, step1178]: loss 0.050199
[epoch1, step1179]: loss 0.049562
[epoch1, step1180]: loss 0.050294
[epoch1, step1181]: loss 0.052152
[epoch1, step1182]: loss 0.049742
[epoch1, step1183]: loss 0.049853
[epoch1, step1184]: loss 0.050770
[epoch1, step1185]: loss 0.050483
[epoch1, step1186]: loss 0.050716
[epoch1, step1187]: loss 0.049603
[epoch1, step1188]: loss 0.049483
[epoch1, step1189]: loss 0.049807
[epoch1, step1190]: loss 0.051393
[epoch1, step1191]: loss 0.050135
[epoch1, step1192]: loss 0.049081
[epoch1, step1193]: loss 0.051128
[epoch1, step1194]: loss 0.049854
[epoch1, step1195]: loss 0.049986
[epoch1, step1196]: loss 0.049485
[epoch1, step1197]: loss 0.049781
[epoch1, step1198]: loss 0.049944
[epoch1, step1199]: loss 0.051422
[epoch1, step1200]: loss 0.049459
[epoch1, step1201]: loss 0.049318
[epoch1, step1202]: loss 0.051417
[epoch1, step1203]: loss 0.050022
[epoch1, step1204]: loss 0.050142
[epoch1, step1205]: loss 0.049781
[epoch1, step1206]: loss 0.049261
[epoch1, step1207]: loss 0.050035
[epoch1, step1208]: loss 0.051792
[epoch1, step1209]: loss 0.049057
[epoch1, step1210]: loss 0.049626
[epoch1, step1211]: loss 0.050641
[epoch1, step1212]: loss 0.050019
[epoch1, step1213]: loss 0.050195
[epoch1, step1214]: loss 0.049987
[epoch1, step1215]: loss 0.050012
[epoch1, step1216]: loss 0.049538
[epoch1, step1217]: loss 0.051779
[epoch1, step1218]: loss 0.049318
[epoch1, step1219]: loss 0.049193
[epoch1, step1220]: loss 0.051134
[epoch1, step1221]: loss 0.049208
[epoch1, step1222]: loss 0.050609
[epoch1, step1223]: loss 0.049742
[epoch1, step1224]: loss 0.049496
[epoch1, step1225]: loss 0.049817
[epoch1, step1226]: loss 0.051162
[epoch1, step1227]: loss 0.049510
[epoch1, step1228]: loss 0.048480
[epoch1, step1229]: loss 0.050743
[epoch1, step1230]: loss 0.049825
[epoch1, step1231]: loss 0.050000
[epoch1, step1232]: loss 0.050126
[epoch1, step1233]: loss 0.049190
[epoch1, step1234]: loss 0.049526
[epoch1, step1235]: loss 0.051498
[epoch1, step1236]: loss 0.049666
[epoch1, step1237]: loss 0.048750
[epoch1, step1238]: loss 0.050542
[epoch1, step1239]: loss 0.049873
[epoch1, step1240]: loss 0.050258
[epoch1, step1241]: loss 0.049759
[epoch1, step1242]: loss 0.049328
[epoch1, step1243]: loss 0.049784
[epoch1, step1244]: loss 0.051566
[epoch1, step1245]: loss 0.049706
[epoch1, step1246]: loss 0.049269
[epoch1, step1247]: loss 0.050375
[epoch1, step1248]: loss 0.049773
[epoch1, step1249]: loss 0.050599
[epoch1, step1250]: loss 0.049636
[epoch1, step1251]: loss 0.049374
[epoch1, step1252]: loss 0.050040
[epoch1, step1253]: loss 0.051269
[epoch1, step1254]: loss 0.049322
[epoch1, step1255]: loss 0.048690
[epoch1, step1256]: loss 0.050767
[epoch1, step1257]: loss 0.049542
[epoch1, step1258]: loss 0.050249
[epoch1, step1259]: loss 0.049517
[epoch1, step1260]: loss 0.049365
[epoch1, step1261]: loss 0.049344
[epoch1, step1262]: loss 0.050572
[epoch1, step1263]: loss 0.049532
[epoch1, step1264]: loss 0.048656
[epoch1, step1265]: loss 0.050167
[epoch1, step1266]: loss 0.049486
[epoch1, step1267]: loss 0.050071
[epoch1, step1268]: loss 0.049442
[epoch1, step1269]: loss 0.049101
[epoch1, step1270]: loss 0.049149
[epoch1, step1271]: loss 0.051419
[epoch1, step1272]: loss 0.049356
[epoch1, step1273]: loss 0.048574
[epoch1, step1274]: loss 0.050573
[epoch1, step1275]: loss 0.049897
[epoch1, step1276]: loss 0.049938
[epoch1, step1277]: loss 0.049597
[epoch1, step1278]: loss 0.049492
[epoch1, step1279]: loss 0.049540
[epoch1, step1280]: loss 0.051381
[epoch1, step1281]: loss 0.049185
[epoch1, step1282]: loss 0.048442
[epoch1, step1283]: loss 0.050148
[epoch1, step1284]: loss 0.049110
[epoch1, step1285]: loss 0.050270
[epoch1, step1286]: loss 0.048795
[epoch1, step1287]: loss 0.049378
[epoch1, step1288]: loss 0.049635
[epoch1, step1289]: loss 0.051443
[epoch1, step1290]: loss 0.049135
[epoch1, step1291]: loss 0.048205
[epoch1, step1292]: loss 0.050672
[epoch1, step1293]: loss 0.048881
[epoch1, step1294]: loss 0.049694
[epoch1, step1295]: loss 0.049365
[epoch1, step1296]: loss 0.048997
[epoch1, step1297]: loss 0.049287
[epoch1, step1298]: loss 0.051166
[epoch1, step1299]: loss 0.049119
[epoch1, step1300]: loss 0.048988
[epoch1, step1301]: loss 0.049922
[epoch1, step1302]: loss 0.049576
[epoch1, step1303]: loss 0.049836
[epoch1, step1304]: loss 0.049252
[epoch1, step1305]: loss 0.049005
[epoch1, step1306]: loss 0.049158
[epoch1, step1307]: loss 0.050687
[epoch1, step1308]: loss 0.049219
[epoch1, step1309]: loss 0.048223
[epoch1, step1310]: loss 0.050284
[epoch1, step1311]: loss 0.048828
[epoch1, step1312]: loss 0.049967
[epoch1, step1313]: loss 0.049283
[epoch1, step1314]: loss 0.049009
[epoch1, step1315]: loss 0.048943
[epoch1, step1316]: loss 0.051685
[epoch1, step1317]: loss 0.048672
[epoch1, step1318]: loss 0.048132
[epoch1, step1319]: loss 0.050068
[epoch1, step1320]: loss 0.049105
[epoch1, step1321]: loss 0.049967
[epoch1, step1322]: loss 0.049033
[epoch1, step1323]: loss 0.049017
[epoch1, step1324]: loss 0.048942
[epoch1, step1325]: loss 0.050586
[epoch1, step1326]: loss 0.048818
[epoch1, step1327]: loss 0.048243
[epoch1, step1328]: loss 0.050251
[epoch1, step1329]: loss 0.049124
[epoch1, step1330]: loss 0.049685
[epoch1, step1331]: loss 0.048881
[epoch1, step1332]: loss 0.048768
[epoch1, step1333]: loss 0.048712
[epoch1, step1334]: loss 0.050982
[epoch1, step1335]: loss 0.049136
[epoch1, step1336]: loss 0.048100
[epoch1, step1337]: loss 0.049670
[epoch1, step1338]: loss 0.048988
[epoch1, step1339]: loss 0.049568
[epoch1, step1340]: loss 0.049035
[epoch1, step1341]: loss 0.048904
[epoch1, step1342]: loss 0.048885
[epoch1, step1343]: loss 0.051028
[epoch1, step1344]: loss 0.048986
[epoch1, step1345]: loss 0.048415
[epoch1, step1346]: loss 0.049891
[epoch1, step1347]: loss 0.049298
[epoch1, step1348]: loss 0.049500
[epoch1, step1349]: loss 0.049111
[epoch1, step1350]: loss 0.048613
[epoch1, step1351]: loss 0.048761
[epoch1, step1352]: loss 0.050530
[epoch1, step1353]: loss 0.048729
[epoch1, step1354]: loss 0.048132
[epoch1, step1355]: loss 0.050036
[epoch1, step1356]: loss 0.048740
[epoch1, step1357]: loss 0.049226
[epoch1, step1358]: loss 0.048916
[epoch1, step1359]: loss 0.048662
[epoch1, step1360]: loss 0.048997
[epoch1, step1361]: loss 0.050842
[epoch1, step1362]: loss 0.049003
[epoch1, step1363]: loss 0.048387
[epoch1, step1364]: loss 0.049742
[epoch1, step1365]: loss 0.049031
[epoch1, step1366]: loss 0.049345
[epoch1, step1367]: loss 0.048692
[epoch1, step1368]: loss 0.049115
[epoch1, step1369]: loss 0.049008
[epoch1, step1370]: loss 0.050503
[epoch1, step1371]: loss 0.048750
[epoch1, step1372]: loss 0.048051
[epoch1, step1373]: loss 0.050107
[epoch1, step1374]: loss 0.049227
[epoch1, step1375]: loss 0.049845
[epoch1, step1376]: loss 0.048741
[epoch1, step1377]: loss 0.048387
[epoch1, step1378]: loss 0.048991
[epoch1, step1379]: loss 0.050523
[epoch1, step1380]: loss 0.048696
[epoch1, step1381]: loss 0.048148
[epoch1, step1382]: loss 0.050089
[epoch1, step1383]: loss 0.048909
[epoch1, step1384]: loss 0.049398
[epoch1, step1385]: loss 0.048497
[epoch1, step1386]: loss 0.048665
[epoch1, step1387]: loss 0.048957
[epoch1, step1388]: loss 0.050257
[epoch1, step1389]: loss 0.048132
[epoch1, step1390]: loss 0.048105
[epoch1, step1391]: loss 0.049854
[epoch1, step1392]: loss 0.048887
[epoch1, step1393]: loss 0.049427
[epoch1, step1394]: loss 0.049309
[epoch1, step1395]: loss 0.048689
[epoch1, step1396]: loss 0.048628
[epoch1, step1397]: loss 0.050506
[epoch1, step1398]: loss 0.048649
[epoch1, step1399]: loss 0.048472
[epoch1, step1400]: loss 0.050112
[epoch1, step1401]: loss 0.048786
[epoch1, step1402]: loss 0.049255
[epoch1, step1403]: loss 0.048327
[epoch1, step1404]: loss 0.048443
[epoch1, step1405]: loss 0.048656
[epoch1, step1406]: loss 0.050207
[epoch1, step1407]: loss 0.049151
[epoch1, step1408]: loss 0.047835
[epoch1, step1409]: loss 0.049535
[epoch1, step1410]: loss 0.048764
[epoch1, step1411]: loss 0.048722
[epoch1, step1412]: loss 0.048680
[epoch1, step1413]: loss 0.048512
[epoch1, step1414]: loss 0.048501
[epoch1, step1415]: loss 0.050304
[epoch1, step1416]: loss 0.048340
[epoch1, step1417]: loss 0.047964
[epoch1, step1418]: loss 0.049660
[epoch1, step1419]: loss 0.049143
[epoch1, step1420]: loss 0.049267
[epoch1, step1421]: loss 0.048977
[epoch1, step1422]: loss 0.048593
[epoch1, step1423]: loss 0.048401
[epoch1, step1424]: loss 0.050434
[epoch1, step1425]: loss 0.048004
[epoch1, step1426]: loss 0.048087
[epoch1, step1427]: loss 0.050097
[epoch1, step1428]: loss 0.049030
[epoch1, step1429]: loss 0.049272
[epoch1, step1430]: loss 0.048725
[epoch1, step1431]: loss 0.048752
[epoch1, step1432]: loss 0.048574
[epoch1, step1433]: loss 0.050475
[epoch1, step1434]: loss 0.048113
[epoch1, step1435]: loss 0.048136
[epoch1, step1436]: loss 0.049955
[epoch1, step1437]: loss 0.048872
[epoch1, step1438]: loss 0.049243
[epoch1, step1439]: loss 0.048665
[epoch1, step1440]: loss 0.048239
[epoch1, step1441]: loss 0.049055
[epoch1, step1442]: loss 0.049928
[epoch1, step1443]: loss 0.048339
[epoch1, step1444]: loss 0.047649
[epoch1, step1445]: loss 0.049719
[epoch1, step1446]: loss 0.048670
[epoch1, step1447]: loss 0.049479
[epoch1, step1448]: loss 0.048522
[epoch1, step1449]: loss 0.048115
[epoch1, step1450]: loss 0.048602
[epoch1, step1451]: loss 0.050447
[epoch1, step1452]: loss 0.048293
[epoch1, step1453]: loss 0.048334
[epoch1, step1454]: loss 0.049772
[epoch1, step1455]: loss 0.049097
[epoch1, step1456]: loss 0.048947
[epoch1, step1457]: loss 0.048792
[epoch1, step1458]: loss 0.048497
[epoch1, step1459]: loss 0.048442
[epoch1, step1460]: loss 0.050561
[epoch1, step1461]: loss 0.048725
[epoch1, step1462]: loss 0.048121
[epoch1, step1463]: loss 0.049580
[epoch1, step1464]: loss 0.048888
[epoch1, step1465]: loss 0.048979
[epoch1, step1466]: loss 0.048448
[epoch1, step1467]: loss 0.048343
[epoch1, step1468]: loss 0.048208
[epoch1, step1469]: loss 0.050294
[epoch1, step1470]: loss 0.048508
[epoch1, step1471]: loss 0.047611
[epoch1, step1472]: loss 0.049518
[epoch1, step1473]: loss 0.048545
[epoch1, step1474]: loss 0.049449
[epoch1, step1475]: loss 0.048423
[epoch1, step1476]: loss 0.048557
[epoch1, step1477]: loss 0.048559
[epoch1, step1478]: loss 0.050268
[epoch1, step1479]: loss 0.048268
[epoch1, step1480]: loss 0.047801
[epoch1, step1481]: loss 0.049256
[epoch1, step1482]: loss 0.048568
[epoch1, step1483]: loss 0.049027
[epoch1, step1484]: loss 0.048734
[epoch1, step1485]: loss 0.048065
[epoch1, step1486]: loss 0.048006
[epoch1, step1487]: loss 0.050221
[epoch1, step1488]: loss 0.048233
[epoch1, step1489]: loss 0.047852
[epoch1, step1490]: loss 0.049424
[epoch1, step1491]: loss 0.048626
[epoch1, step1492]: loss 0.048798
[epoch1, step1493]: loss 0.048669
[epoch1, step1494]: loss 0.048387
[epoch1, step1495]: loss 0.048351
[epoch1, step1496]: loss 0.049768
[epoch1, step1497]: loss 0.048400
[epoch1, step1498]: loss 0.047862
[epoch1, step1499]: loss 0.049230
[epoch1, step1500]: loss 0.048635
[epoch1, step1501]: loss 0.048974
[epoch1, step1502]: loss 0.048471
[epoch1, step1503]: loss 0.048191
[epoch1, step1504]: loss 0.048102
[epoch1, step1505]: loss 0.050308
[epoch1, step1506]: loss 0.047771
[epoch1, step1507]: loss 0.047891
[epoch1, step1508]: loss 0.049713
[epoch1, step1509]: loss 0.048407
[epoch1, step1510]: loss 0.048705
[epoch1, step1511]: loss 0.048809
[epoch1, step1512]: loss 0.048307
[epoch1, step1513]: loss 0.047824
[epoch1, step1514]: loss 0.050009
[epoch1, step1515]: loss 0.048309
[epoch1, step1516]: loss 0.047622

[epoch1]: avg loss 0.107076

[epoch2, step1]: loss 0.047946
[epoch2, step2]: loss 0.044209
[epoch2, step3]: loss 0.044349
[epoch2, step4]: loss 0.042121
[epoch2, step5]: loss 0.042475
[epoch2, step6]: loss 0.044113
[epoch2, step7]: loss 0.042107
[epoch2, step8]: loss 0.045040
[epoch2, step9]: loss 0.041925
[epoch2, step10]: loss 0.041733
[epoch2, step11]: loss 0.044082
[epoch2, step12]: loss 0.044182
[epoch2, step13]: loss 0.041855
[epoch2, step14]: loss 0.041954
[epoch2, step15]: loss 0.043794
[epoch2, step16]: loss 0.041444
[epoch2, step17]: loss 0.045169
[epoch2, step18]: loss 0.042652
[epoch2, step19]: loss 0.041221
[epoch2, step20]: loss 0.044762
[epoch2, step21]: loss 0.044239
[epoch2, step22]: loss 0.041339
[epoch2, step23]: loss 0.040982
[epoch2, step24]: loss 0.043858
[epoch2, step25]: loss 0.040772
[epoch2, step26]: loss 0.044326
[epoch2, step27]: loss 0.041452
[epoch2, step28]: loss 0.041026
[epoch2, step29]: loss 0.044124
[epoch2, step30]: loss 0.044848
[epoch2, step31]: loss 0.041143
[epoch2, step32]: loss 0.042062
[epoch2, step33]: loss 0.044485
[epoch2, step34]: loss 0.041896
[epoch2, step35]: loss 0.045278
[epoch2, step36]: loss 0.041826
[epoch2, step37]: loss 0.040981
[epoch2, step38]: loss 0.043826
[epoch2, step39]: loss 0.044177
[epoch2, step40]: loss 0.041908
[epoch2, step41]: loss 0.041151
[epoch2, step42]: loss 0.044128
[epoch2, step43]: loss 0.041158
[epoch2, step44]: loss 0.045193
[epoch2, step45]: loss 0.041921
[epoch2, step46]: loss 0.041103
[epoch2, step47]: loss 0.043644
[epoch2, step48]: loss 0.043918
[epoch2, step49]: loss 0.040164
[epoch2, step50]: loss 0.041800
[epoch2, step51]: loss 0.043587
[epoch2, step52]: loss 0.041155
[epoch2, step53]: loss 0.045442
[epoch2, step54]: loss 0.041716
[epoch2, step55]: loss 0.041368
[epoch2, step56]: loss 0.044770
[epoch2, step57]: loss 0.044612
[epoch2, step58]: loss 0.041652
[epoch2, step59]: loss 0.040864
[epoch2, step60]: loss 0.044188
[epoch2, step61]: loss 0.040648
[epoch2, step62]: loss 0.044357
[epoch2, step63]: loss 0.041281
[epoch2, step64]: loss 0.040602
[epoch2, step65]: loss 0.044102
[epoch2, step66]: loss 0.044179
[epoch2, step67]: loss 0.041747
[epoch2, step68]: loss 0.041689
[epoch2, step69]: loss 0.043732
[epoch2, step70]: loss 0.041104
[epoch2, step71]: loss 0.044443
[epoch2, step72]: loss 0.041877
[epoch2, step73]: loss 0.040772
[epoch2, step74]: loss 0.044063
[epoch2, step75]: loss 0.044299
[epoch2, step76]: loss 0.042107
[epoch2, step77]: loss 0.042183
[epoch2, step78]: loss 0.043920
[epoch2, step79]: loss 0.040722
[epoch2, step80]: loss 0.045522
[epoch2, step81]: loss 0.041896
[epoch2, step82]: loss 0.040647
[epoch2, step83]: loss 0.043240
[epoch2, step84]: loss 0.044406
[epoch2, step85]: loss 0.042118
[epoch2, step86]: loss 0.041757
[epoch2, step87]: loss 0.044733
[epoch2, step88]: loss 0.040199
[epoch2, step89]: loss 0.044454
[epoch2, step90]: loss 0.042203
[epoch2, step91]: loss 0.040444
[epoch2, step92]: loss 0.044065
[epoch2, step93]: loss 0.044138
[epoch2, step94]: loss 0.041440
[epoch2, step95]: loss 0.042027
[epoch2, step96]: loss 0.043546
[epoch2, step97]: loss 0.041764
[epoch2, step98]: loss 0.044778
[epoch2, step99]: loss 0.041935
[epoch2, step100]: loss 0.040054
[epoch2, step101]: loss 0.044423
[epoch2, step102]: loss 0.044152
[epoch2, step103]: loss 0.041491
[epoch2, step104]: loss 0.041695
[epoch2, step105]: loss 0.043909
[epoch2, step106]: loss 0.041107
[epoch2, step107]: loss 0.044684
[epoch2, step108]: loss 0.042060
[epoch2, step109]: loss 0.040533
[epoch2, step110]: loss 0.044503
[epoch2, step111]: loss 0.043981
[epoch2, step112]: loss 0.041734
[epoch2, step113]: loss 0.042343
[epoch2, step114]: loss 0.043640
[epoch2, step115]: loss 0.041181
[epoch2, step116]: loss 0.045398
[epoch2, step117]: loss 0.041850
[epoch2, step118]: loss 0.041332
[epoch2, step119]: loss 0.044325
[epoch2, step120]: loss 0.044277
[epoch2, step121]: loss 0.041320
[epoch2, step122]: loss 0.041519
[epoch2, step123]: loss 0.044129
[epoch2, step124]: loss 0.041383
[epoch2, step125]: loss 0.045165
[epoch2, step126]: loss 0.041791
[epoch2, step127]: loss 0.040720
[epoch2, step128]: loss 0.043852
[epoch2, step129]: loss 0.043780
[epoch2, step130]: loss 0.041676
[epoch2, step131]: loss 0.041056
[epoch2, step132]: loss 0.043936
[epoch2, step133]: loss 0.040934
[epoch2, step134]: loss 0.044265
[epoch2, step135]: loss 0.042323
[epoch2, step136]: loss 0.041707
[epoch2, step137]: loss 0.043651
[epoch2, step138]: loss 0.044061
[epoch2, step139]: loss 0.041392
[epoch2, step140]: loss 0.042017
[epoch2, step141]: loss 0.043969
[epoch2, step142]: loss 0.041050
[epoch2, step143]: loss 0.044371
[epoch2, step144]: loss 0.042125
[epoch2, step145]: loss 0.040880
[epoch2, step146]: loss 0.044042
[epoch2, step147]: loss 0.045349
[epoch2, step148]: loss 0.041379
[epoch2, step149]: loss 0.041160
[epoch2, step150]: loss 0.043454
[epoch2, step151]: loss 0.041197
[epoch2, step152]: loss 0.044779
[epoch2, step153]: loss 0.042047
[epoch2, step154]: loss 0.040383
[epoch2, step155]: loss 0.043960
[epoch2, step156]: loss 0.043856
[epoch2, step157]: loss 0.041712
[epoch2, step158]: loss 0.041798
[epoch2, step159]: loss 0.044061
[epoch2, step160]: loss 0.041393
[epoch2, step161]: loss 0.045275
[epoch2, step162]: loss 0.042090
[epoch2, step163]: loss 0.040644
[epoch2, step164]: loss 0.044245
[epoch2, step165]: loss 0.044247
[epoch2, step166]: loss 0.041855
[epoch2, step167]: loss 0.041229
[epoch2, step168]: loss 0.044304
[epoch2, step169]: loss 0.040843
[epoch2, step170]: loss 0.045056
[epoch2, step171]: loss 0.042136
[epoch2, step172]: loss 0.040849
[epoch2, step173]: loss 0.044255
[epoch2, step174]: loss 0.044034
[epoch2, step175]: loss 0.042257
[epoch2, step176]: loss 0.041920
[epoch2, step177]: loss 0.044107
[epoch2, step178]: loss 0.041157
[epoch2, step179]: loss 0.044003
[epoch2, step180]: loss 0.042236
[epoch2, step181]: loss 0.040889
[epoch2, step182]: loss 0.044213
[epoch2, step183]: loss 0.044793
[epoch2, step184]: loss 0.042482
[epoch2, step185]: loss 0.041910
[epoch2, step186]: loss 0.043930
[epoch2, step187]: loss 0.041212
[epoch2, step188]: loss 0.044522
[epoch2, step189]: loss 0.041946
[epoch2, step190]: loss 0.040369
[epoch2, step191]: loss 0.043682
[epoch2, step192]: loss 0.044630
[epoch2, step193]: loss 0.039980
[epoch2, step194]: loss 0.040913
[epoch2, step195]: loss 0.044113
[epoch2, step196]: loss 0.041162
[epoch2, step197]: loss 0.044635
[epoch2, step198]: loss 0.041106
[epoch2, step199]: loss 0.040796
[epoch2, step200]: loss 0.044395
[epoch2, step201]: loss 0.044665
[epoch2, step202]: loss 0.041324
[epoch2, step203]: loss 0.041687
[epoch2, step204]: loss 0.044162
[epoch2, step205]: loss 0.040535
[epoch2, step206]: loss 0.044486
[epoch2, step207]: loss 0.041786
[epoch2, step208]: loss 0.041119
[epoch2, step209]: loss 0.044172
[epoch2, step210]: loss 0.045043
[epoch2, step211]: loss 0.042136
[epoch2, step212]: loss 0.042048
[epoch2, step213]: loss 0.043568
[epoch2, step214]: loss 0.040595
[epoch2, step215]: loss 0.044962
[epoch2, step216]: loss 0.042155
[epoch2, step217]: loss 0.039929
[epoch2, step218]: loss 0.044196
[epoch2, step219]: loss 0.044020
[epoch2, step220]: loss 0.041874
[epoch2, step221]: loss 0.041904
[epoch2, step222]: loss 0.043931
[epoch2, step223]: loss 0.041305
[epoch2, step224]: loss 0.044465
[epoch2, step225]: loss 0.041906
[epoch2, step226]: loss 0.040679
[epoch2, step227]: loss 0.043150
[epoch2, step228]: loss 0.044719
[epoch2, step229]: loss 0.040896
[epoch2, step230]: loss 0.041913
[epoch2, step231]: loss 0.044200
[epoch2, step232]: loss 0.040657
[epoch2, step233]: loss 0.044050
[epoch2, step234]: loss 0.041516
[epoch2, step235]: loss 0.041020
[epoch2, step236]: loss 0.044076
[epoch2, step237]: loss 0.044338
[epoch2, step238]: loss 0.041385
[epoch2, step239]: loss 0.040991
[epoch2, step240]: loss 0.043390
[epoch2, step241]: loss 0.041523
[epoch2, step242]: loss 0.044628
[epoch2, step243]: loss 0.042493
[epoch2, step244]: loss 0.040667
[epoch2, step245]: loss 0.043618
[epoch2, step246]: loss 0.044222
[epoch2, step247]: loss 0.041870
[epoch2, step248]: loss 0.041324
[epoch2, step249]: loss 0.043405
[epoch2, step250]: loss 0.041176
[epoch2, step251]: loss 0.045270
[epoch2, step252]: loss 0.042390
[epoch2, step253]: loss 0.040428
[epoch2, step254]: loss 0.043353
[epoch2, step255]: loss 0.044307
[epoch2, step256]: loss 0.041374
[epoch2, step257]: loss 0.041398
[epoch2, step258]: loss 0.044364
[epoch2, step259]: loss 0.040942
[epoch2, step260]: loss 0.044170
[epoch2, step261]: loss 0.042621
[epoch2, step262]: loss 0.041074
[epoch2, step263]: loss 0.043255
[epoch2, step264]: loss 0.043927
[epoch2, step265]: loss 0.041816
[epoch2, step266]: loss 0.041596
[epoch2, step267]: loss 0.043251
[epoch2, step268]: loss 0.040979
[epoch2, step269]: loss 0.044739
[epoch2, step270]: loss 0.041553
[epoch2, step271]: loss 0.040763
[epoch2, step272]: loss 0.043934
[epoch2, step273]: loss 0.043970
[epoch2, step274]: loss 0.042025
[epoch2, step275]: loss 0.041212
[epoch2, step276]: loss 0.043389
[epoch2, step277]: loss 0.041417
[epoch2, step278]: loss 0.044834
[epoch2, step279]: loss 0.041607
[epoch2, step280]: loss 0.040576
[epoch2, step281]: loss 0.043708
[epoch2, step282]: loss 0.044526
[epoch2, step283]: loss 0.041208
[epoch2, step284]: loss 0.041099
[epoch2, step285]: loss 0.044408
[epoch2, step286]: loss 0.040331
[epoch2, step287]: loss 0.044828
[epoch2, step288]: loss 0.041522
[epoch2, step289]: loss 0.041416
[epoch2, step290]: loss 0.044016
[epoch2, step291]: loss 0.044438
[epoch2, step292]: loss 0.040839
[epoch2, step293]: loss 0.041231
[epoch2, step294]: loss 0.043020
[epoch2, step295]: loss 0.040573
[epoch2, step296]: loss 0.045357
[epoch2, step297]: loss 0.041583
[epoch2, step298]: loss 0.041054
[epoch2, step299]: loss 0.043196
[epoch2, step300]: loss 0.044413
[epoch2, step301]: loss 0.041586
[epoch2, step302]: loss 0.041888
[epoch2, step303]: loss 0.044143
[epoch2, step304]: loss 0.040628
[epoch2, step305]: loss 0.044391
[epoch2, step306]: loss 0.041917
[epoch2, step307]: loss 0.040229
[epoch2, step308]: loss 0.044387
[epoch2, step309]: loss 0.044409
[epoch2, step310]: loss 0.041702
[epoch2, step311]: loss 0.041895
[epoch2, step312]: loss 0.043505
[epoch2, step313]: loss 0.041371
[epoch2, step314]: loss 0.044639
[epoch2, step315]: loss 0.042733
[epoch2, step316]: loss 0.040489
[epoch2, step317]: loss 0.044063
[epoch2, step318]: loss 0.044271
[epoch2, step319]: loss 0.041160
[epoch2, step320]: loss 0.040681
[epoch2, step321]: loss 0.043388
[epoch2, step322]: loss 0.040868
[epoch2, step323]: loss 0.044089
[epoch2, step324]: loss 0.042410
[epoch2, step325]: loss 0.040822
[epoch2, step326]: loss 0.043669
[epoch2, step327]: loss 0.043633
[epoch2, step328]: loss 0.041721
[epoch2, step329]: loss 0.041315
[epoch2, step330]: loss 0.043445
[epoch2, step331]: loss 0.041073
[epoch2, step332]: loss 0.044124
[epoch2, step333]: loss 0.041809
[epoch2, step334]: loss 0.040563
[epoch2, step335]: loss 0.044006
[epoch2, step336]: loss 0.044960
[epoch2, step337]: loss 0.041716
[epoch2, step338]: loss 0.041116
[epoch2, step339]: loss 0.043448
[epoch2, step340]: loss 0.041283
[epoch2, step341]: loss 0.044208
[epoch2, step342]: loss 0.041552
[epoch2, step343]: loss 0.040818
[epoch2, step344]: loss 0.043512
[epoch2, step345]: loss 0.043578
[epoch2, step346]: loss 0.041080
[epoch2, step347]: loss 0.041222
[epoch2, step348]: loss 0.043768
[epoch2, step349]: loss 0.041352
[epoch2, step350]: loss 0.044163
[epoch2, step351]: loss 0.041170
[epoch2, step352]: loss 0.040542
[epoch2, step353]: loss 0.043648
[epoch2, step354]: loss 0.043273
[epoch2, step355]: loss 0.040653
[epoch2, step356]: loss 0.042064
[epoch2, step357]: loss 0.043696
[epoch2, step358]: loss 0.039784
[epoch2, step359]: loss 0.045379
[epoch2, step360]: loss 0.040832
[epoch2, step361]: loss 0.040020
[epoch2, step362]: loss 0.044290
[epoch2, step363]: loss 0.043937
[epoch2, step364]: loss 0.041345
[epoch2, step365]: loss 0.041206
[epoch2, step366]: loss 0.044009
[epoch2, step367]: loss 0.040874
[epoch2, step368]: loss 0.044059
[epoch2, step369]: loss 0.041656
[epoch2, step370]: loss 0.041109
[epoch2, step371]: loss 0.044531
[epoch2, step372]: loss 0.043769
[epoch2, step373]: loss 0.041005
[epoch2, step374]: loss 0.040765
[epoch2, step375]: loss 0.044101
[epoch2, step376]: loss 0.040887
[epoch2, step377]: loss 0.044714
[epoch2, step378]: loss 0.042117
[epoch2, step379]: loss 0.041098
[epoch2, step380]: loss 0.044262
[epoch2, step381]: loss 0.043827
[epoch2, step382]: loss 0.041733
[epoch2, step383]: loss 0.040620
[epoch2, step384]: loss 0.043088
[epoch2, step385]: loss 0.040882
[epoch2, step386]: loss 0.044701
[epoch2, step387]: loss 0.041845
[epoch2, step388]: loss 0.041215
[epoch2, step389]: loss 0.043827
[epoch2, step390]: loss 0.044783
[epoch2, step391]: loss 0.041143
[epoch2, step392]: loss 0.041887
[epoch2, step393]: loss 0.043097
[epoch2, step394]: loss 0.040920
[epoch2, step395]: loss 0.044321
[epoch2, step396]: loss 0.041864
[epoch2, step397]: loss 0.040312
[epoch2, step398]: loss 0.043906
[epoch2, step399]: loss 0.043997
[epoch2, step400]: loss 0.041208
[epoch2, step401]: loss 0.041221
[epoch2, step402]: loss 0.043280
[epoch2, step403]: loss 0.040843
[epoch2, step404]: loss 0.044799
[epoch2, step405]: loss 0.041935
[epoch2, step406]: loss 0.040793
[epoch2, step407]: loss 0.043545
[epoch2, step408]: loss 0.044106
[epoch2, step409]: loss 0.042527
[epoch2, step410]: loss 0.041949
[epoch2, step411]: loss 0.043474
[epoch2, step412]: loss 0.040436
[epoch2, step413]: loss 0.044444
[epoch2, step414]: loss 0.041429
[epoch2, step415]: loss 0.040867
[epoch2, step416]: loss 0.043240
[epoch2, step417]: loss 0.044288
[epoch2, step418]: loss 0.041300
[epoch2, step419]: loss 0.040727
[epoch2, step420]: loss 0.043794
[epoch2, step421]: loss 0.040595
[epoch2, step422]: loss 0.044482
[epoch2, step423]: loss 0.041832
[epoch2, step424]: loss 0.040749
[epoch2, step425]: loss 0.043933
[epoch2, step426]: loss 0.044393
[epoch2, step427]: loss 0.041652
[epoch2, step428]: loss 0.041250
[epoch2, step429]: loss 0.044196
[epoch2, step430]: loss 0.040738
[epoch2, step431]: loss 0.044846
[epoch2, step432]: loss 0.041683
[epoch2, step433]: loss 0.041201
[epoch2, step434]: loss 0.043752
[epoch2, step435]: loss 0.044461
[epoch2, step436]: loss 0.041074
[epoch2, step437]: loss 0.041610
[epoch2, step438]: loss 0.044079
[epoch2, step439]: loss 0.041113
[epoch2, step440]: loss 0.044468
[epoch2, step441]: loss 0.042071
[epoch2, step442]: loss 0.040538
[epoch2, step443]: loss 0.044200
[epoch2, step444]: loss 0.043926
[epoch2, step445]: loss 0.041875
[epoch2, step446]: loss 0.041825
[epoch2, step447]: loss 0.044350
[epoch2, step448]: loss 0.041055
[epoch2, step449]: loss 0.044407
[epoch2, step450]: loss 0.041155
[epoch2, step451]: loss 0.040397
[epoch2, step452]: loss 0.042742
[epoch2, step453]: loss 0.044232
[epoch2, step454]: loss 0.041352
[epoch2, step455]: loss 0.041544
[epoch2, step456]: loss 0.042747
[epoch2, step457]: loss 0.041489
[epoch2, step458]: loss 0.044265
[epoch2, step459]: loss 0.042346
[epoch2, step460]: loss 0.040721
[epoch2, step461]: loss 0.044464
[epoch2, step462]: loss 0.043533
[epoch2, step463]: loss 0.041643
[epoch2, step464]: loss 0.041320
[epoch2, step465]: loss 0.044737
[epoch2, step466]: loss 0.040763
[epoch2, step467]: loss 0.044252
[epoch2, step468]: loss 0.041708
[epoch2, step469]: loss 0.040710
[epoch2, step470]: loss 0.044053
[epoch2, step471]: loss 0.043683
[epoch2, step472]: loss 0.041812
[epoch2, step473]: loss 0.041046
[epoch2, step474]: loss 0.043603
[epoch2, step475]: loss 0.041044
[epoch2, step476]: loss 0.044989
[epoch2, step477]: loss 0.041665
[epoch2, step478]: loss 0.040230
[epoch2, step479]: loss 0.043636
[epoch2, step480]: loss 0.043248
[epoch2, step481]: loss 0.040993
[epoch2, step482]: loss 0.040856
[epoch2, step483]: loss 0.043984
[epoch2, step484]: loss 0.041099
[epoch2, step485]: loss 0.044695
[epoch2, step486]: loss 0.042139
[epoch2, step487]: loss 0.040041
[epoch2, step488]: loss 0.044142
[epoch2, step489]: loss 0.043484
[epoch2, step490]: loss 0.041753
[epoch2, step491]: loss 0.041512
[epoch2, step492]: loss 0.043304
[epoch2, step493]: loss 0.040597
[epoch2, step494]: loss 0.043990
[epoch2, step495]: loss 0.042815
[epoch2, step496]: loss 0.040598
[epoch2, step497]: loss 0.043835
[epoch2, step498]: loss 0.043815
[epoch2, step499]: loss 0.041704
[epoch2, step500]: loss 0.041039
[epoch2, step501]: loss 0.043191
[epoch2, step502]: loss 0.040758
[epoch2, step503]: loss 0.044693
[epoch2, step504]: loss 0.041566
[epoch2, step505]: loss 0.039952
[epoch2, step506]: loss 0.044152
[epoch2, step507]: loss 0.044219
[epoch2, step508]: loss 0.041933
[epoch2, step509]: loss 0.041336
[epoch2, step510]: loss 0.043708
[epoch2, step511]: loss 0.041152
[epoch2, step512]: loss 0.044816
[epoch2, step513]: loss 0.041897
[epoch2, step514]: loss 0.040874
[epoch2, step515]: loss 0.043781
[epoch2, step516]: loss 0.044447
[epoch2, step517]: loss 0.041440
[epoch2, step518]: loss 0.041480
[epoch2, step519]: loss 0.043559
[epoch2, step520]: loss 0.040454
[epoch2, step521]: loss 0.044142
[epoch2, step522]: loss 0.041218
[epoch2, step523]: loss 0.040598
[epoch2, step524]: loss 0.043196
[epoch2, step525]: loss 0.044334
[epoch2, step526]: loss 0.041561
[epoch2, step527]: loss 0.041163
[epoch2, step528]: loss 0.043774
[epoch2, step529]: loss 0.040406
[epoch2, step530]: loss 0.044867
[epoch2, step531]: loss 0.041631
[epoch2, step532]: loss 0.040162
[epoch2, step533]: loss 0.044668
[epoch2, step534]: loss 0.044005
[epoch2, step535]: loss 0.041771
[epoch2, step536]: loss 0.041481
[epoch2, step537]: loss 0.043593
[epoch2, step538]: loss 0.040959
[epoch2, step539]: loss 0.044297
[epoch2, step540]: loss 0.041398
[epoch2, step541]: loss 0.040143
[epoch2, step542]: loss 0.043767
[epoch2, step543]: loss 0.043725
[epoch2, step544]: loss 0.041340
[epoch2, step545]: loss 0.040683
[epoch2, step546]: loss 0.044077
[epoch2, step547]: loss 0.040550
[epoch2, step548]: loss 0.044388
[epoch2, step549]: loss 0.041999
[epoch2, step550]: loss 0.040553
[epoch2, step551]: loss 0.043678
[epoch2, step552]: loss 0.043530
[epoch2, step553]: loss 0.041827
[epoch2, step554]: loss 0.041206
[epoch2, step555]: loss 0.043362
[epoch2, step556]: loss 0.040774
[epoch2, step557]: loss 0.043970
[epoch2, step558]: loss 0.041978
[epoch2, step559]: loss 0.040006
[epoch2, step560]: loss 0.043793
[epoch2, step561]: loss 0.043931
[epoch2, step562]: loss 0.041402
[epoch2, step563]: loss 0.037228
[epoch2, step564]: loss 0.037779
[epoch2, step565]: loss 0.036543
[epoch2, step566]: loss 0.042422
[epoch2, step567]: loss 0.036450
[epoch2, step568]: loss 0.036554
[epoch2, step569]: loss 0.033463
[epoch2, step570]: loss 0.040520
[epoch2, step571]: loss 0.038045
[epoch2, step572]: loss 0.037666
[epoch2, step573]: loss 0.038836
[epoch2, step574]: loss 0.040141
[epoch2, step575]: loss 0.031997
[epoch2, step576]: loss 0.033388
[epoch2, step577]: loss 0.037001
[epoch2, step578]: loss 0.030569
[epoch2, step579]: loss 0.039753
[epoch2, step580]: loss 0.031800
[epoch2, step581]: loss 0.037153
[epoch2, step582]: loss 0.036359
[epoch2, step583]: loss 0.033660
[epoch2, step584]: loss 0.034845
[epoch2, step585]: loss 0.037296
[epoch2, step586]: loss 0.033705
[epoch2, step587]: loss 0.039566
[epoch2, step588]: loss 0.034614
[epoch2, step589]: loss 0.034922
[epoch2, step590]: loss 0.039604
[epoch2, step591]: loss 0.031960
[epoch2, step592]: loss 0.037504
[epoch2, step593]: loss 0.033900
[epoch2, step594]: loss 0.037588
[epoch2, step595]: loss 0.038793
[epoch2, step596]: loss 0.035230
[epoch2, step597]: loss 0.036375
[epoch2, step598]: loss 0.038494
[epoch2, step599]: loss 0.036239
[epoch2, step600]: loss 0.039325
[epoch2, step601]: loss 0.030420
[epoch2, step602]: loss 0.034418
[epoch2, step603]: loss 0.038273
[epoch2, step604]: loss 0.038889
[epoch2, step605]: loss 0.036454
[epoch2, step606]: loss 0.036074
[epoch2, step607]: loss 0.039713
[epoch2, step608]: loss 0.037446
[epoch2, step609]: loss 0.038242
[epoch2, step610]: loss 0.038630
[epoch2, step611]: loss 0.038066
[epoch2, step612]: loss 0.036956
[epoch2, step613]: loss 0.031120
[epoch2, step614]: loss 0.036091
[epoch2, step615]: loss 0.041158
[epoch2, step616]: loss 0.035264
[epoch2, step617]: loss 0.034760
[epoch2, step618]: loss 0.038392
[epoch2, step619]: loss 0.039203
[epoch2, step620]: loss 0.035957
[epoch2, step621]: loss 0.038351
[epoch2, step622]: loss 0.032010
[epoch2, step623]: loss 0.034984
[epoch2, step624]: loss 0.038761
[epoch2, step625]: loss 0.037351
[epoch2, step626]: loss 0.040030
[epoch2, step627]: loss 0.034528
[epoch2, step628]: loss 0.037066
[epoch2, step629]: loss 0.031624
[epoch2, step630]: loss 0.033797
[epoch2, step631]: loss 0.043560
[epoch2, step632]: loss 0.035704
[epoch2, step633]: loss 0.036416
[epoch2, step634]: loss 0.038575
[epoch2, step635]: loss 0.037777
[epoch2, step636]: loss 0.032908
[epoch2, step637]: loss 0.039064
[epoch2, step638]: loss 0.039160
[epoch2, step639]: loss 0.033539
[epoch2, step640]: loss 0.040811
[epoch2, step641]: loss 0.042534
[epoch2, step642]: loss 0.036920
[epoch2, step643]: loss 0.037063
[epoch2, step644]: loss 0.037615
[epoch2, step645]: loss 0.035344
[epoch2, step646]: loss 0.037278
[epoch2, step647]: loss 0.034551
[epoch2, step648]: loss 0.035867
[epoch2, step649]: loss 0.040380
[epoch2, step650]: loss 0.034003
[epoch2, step651]: loss 0.039252
[epoch2, step652]: loss 0.038598
[epoch2, step653]: loss 0.039407
[epoch2, step654]: loss 0.034246
[epoch2, step655]: loss 0.035551
[epoch2, step656]: loss 0.033944
[epoch2, step657]: loss 0.039717
[epoch2, step658]: loss 0.036816
[epoch2, step659]: loss 0.039310
[epoch2, step660]: loss 0.034240
[epoch2, step661]: loss 0.038514
[epoch2, step662]: loss 0.035260
[epoch2, step663]: loss 0.033339
[epoch2, step664]: loss 0.036995
[epoch2, step665]: loss 0.039046
[epoch2, step666]: loss 0.038399
[epoch2, step667]: loss 0.039031
[epoch2, step668]: loss 0.034777
[epoch2, step669]: loss 0.038475
[epoch2, step670]: loss 0.039549
[epoch2, step671]: loss 0.032564
[epoch2, step672]: loss 0.036673
[epoch2, step673]: loss 0.034660
[epoch2, step674]: loss 0.032300
[epoch2, step675]: loss 0.031582
[epoch2, step676]: loss 0.035566
[epoch2, step677]: loss 0.036847
[epoch2, step678]: loss 0.034472
[epoch2, step679]: loss 0.035661
[epoch2, step680]: loss 0.042919
[epoch2, step681]: loss 0.032819
[epoch2, step682]: loss 0.037792
[epoch2, step683]: loss 0.037300
[epoch2, step684]: loss 0.036555
[epoch2, step685]: loss 0.036109
[epoch2, step686]: loss 0.039148
[epoch2, step687]: loss 0.037593
[epoch2, step688]: loss 0.035674
[epoch2, step689]: loss 0.035798
[epoch2, step690]: loss 0.037644
[epoch2, step691]: loss 0.036383
[epoch2, step692]: loss 0.034747
[epoch2, step693]: loss 0.039988
[epoch2, step694]: loss 0.033744
[epoch2, step695]: loss 0.039155
[epoch2, step696]: loss 0.036457
[epoch2, step697]: loss 0.039489
[epoch2, step698]: loss 0.036295
[epoch2, step699]: loss 0.035148
[epoch2, step700]: loss 0.032737
[epoch2, step701]: loss 0.037718
[epoch2, step702]: loss 0.032590
[epoch2, step703]: loss 0.035263
[epoch2, step704]: loss 0.038107
[epoch2, step705]: loss 0.036590
[epoch2, step706]: loss 0.035035
[epoch2, step707]: loss 0.035271
[epoch2, step708]: loss 0.037052
[epoch2, step709]: loss 0.039300
[epoch2, step710]: loss 0.034803
[epoch2, step711]: loss 0.037742
[epoch2, step712]: loss 0.038330
[epoch2, step713]: loss 0.038300
[epoch2, step714]: loss 0.033120
[epoch2, step715]: loss 0.034263
[epoch2, step716]: loss 0.037236
[epoch2, step717]: loss 0.034142
[epoch2, step718]: loss 0.036864
[epoch2, step719]: loss 0.046563
[epoch2, step720]: loss 0.036208
[epoch2, step721]: loss 0.034607
[epoch2, step722]: loss 0.042959
[epoch2, step723]: loss 0.038701
[epoch2, step724]: loss 0.034279
[epoch2, step725]: loss 0.039517
[epoch2, step726]: loss 0.033403
[epoch2, step727]: loss 0.035557
[epoch2, step728]: loss 0.038114
[epoch2, step729]: loss 0.033272
[epoch2, step730]: loss 0.034080
[epoch2, step731]: loss 0.037774
[epoch2, step732]: loss 0.037501
[epoch2, step733]: loss 0.035309
[epoch2, step734]: loss 0.034665
[epoch2, step735]: loss 0.039325
[epoch2, step736]: loss 0.036654
[epoch2, step737]: loss 0.038445
[epoch2, step738]: loss 0.031355
[epoch2, step739]: loss 0.038081
[epoch2, step740]: loss 0.034448
[epoch2, step741]: loss 0.037755
[epoch2, step742]: loss 0.033930
[epoch2, step743]: loss 0.035430
[epoch2, step744]: loss 0.034985
[epoch2, step745]: loss 0.035401
[epoch2, step746]: loss 0.037747
[epoch2, step747]: loss 0.040023
[epoch2, step748]: loss 0.037587
[epoch2, step749]: loss 0.037767
[epoch2, step750]: loss 0.039441
[epoch2, step751]: loss 0.034071
[epoch2, step752]: loss 0.036141
[epoch2, step753]: loss 0.036451
[epoch2, step754]: loss 0.035056
[epoch2, step755]: loss 0.037906
[epoch2, step756]: loss 0.035332
[epoch2, step757]: loss 0.031637
[epoch2, step758]: loss 0.035532
[epoch2, step759]: loss 0.034093
[epoch2, step760]: loss 0.035261
[epoch2, step761]: loss 0.038272
[epoch2, step762]: loss 0.032772
[epoch2, step763]: loss 0.037468
[epoch2, step764]: loss 0.035900
[epoch2, step765]: loss 0.037863
[epoch2, step766]: loss 0.037063
[epoch2, step767]: loss 0.040936
[epoch2, step768]: loss 0.032160
[epoch2, step769]: loss 0.037776
[epoch2, step770]: loss 0.037108
[epoch2, step771]: loss 0.034051
[epoch2, step772]: loss 0.040449
[epoch2, step773]: loss 0.037378
[epoch2, step774]: loss 0.035842
[epoch2, step775]: loss 0.031587
[epoch2, step776]: loss 0.037815
[epoch2, step777]: loss 0.033904
[epoch2, step778]: loss 0.039242
[epoch2, step779]: loss 0.035968
[epoch2, step780]: loss 0.031152
[epoch2, step781]: loss 0.035998
[epoch2, step782]: loss 0.034004
[epoch2, step783]: loss 0.031387
[epoch2, step784]: loss 0.032177
[epoch2, step785]: loss 0.032672
[epoch2, step786]: loss 0.035520
[epoch2, step787]: loss 0.035238
[epoch2, step788]: loss 0.036642
[epoch2, step789]: loss 0.036245
[epoch2, step790]: loss 0.034822
[epoch2, step791]: loss 0.039086
[epoch2, step792]: loss 0.036572
[epoch2, step793]: loss 0.038751
[epoch2, step794]: loss 0.031759
[epoch2, step795]: loss 0.036604
[epoch2, step796]: loss 0.039819
[epoch2, step797]: loss 0.039013
[epoch2, step798]: loss 0.039263
[epoch2, step799]: loss 0.037943
[epoch2, step800]: loss 0.033008
[epoch2, step801]: loss 0.034579
[epoch2, step802]: loss 0.034222
[epoch2, step803]: loss 0.038022
[epoch2, step804]: loss 0.039418
[epoch2, step805]: loss 0.039707
[epoch2, step806]: loss 0.033429
[epoch2, step807]: loss 0.032303
[epoch2, step808]: loss 0.035282
[epoch2, step809]: loss 0.033448
[epoch2, step810]: loss 0.037219
[epoch2, step811]: loss 0.036801
[epoch2, step812]: loss 0.035918
[epoch2, step813]: loss 0.034758
[epoch2, step814]: loss 0.037038
[epoch2, step815]: loss 0.035503
[epoch2, step816]: loss 0.036400
[epoch2, step817]: loss 0.036554
[epoch2, step818]: loss 0.033365
[epoch2, step819]: loss 0.032649
[epoch2, step820]: loss 0.035049
[epoch2, step821]: loss 0.032392
[epoch2, step822]: loss 0.041972
[epoch2, step823]: loss 0.035447
[epoch2, step824]: loss 0.038354
[epoch2, step825]: loss 0.037380
[epoch2, step826]: loss 0.035466
[epoch2, step827]: loss 0.038420
[epoch2, step828]: loss 0.040140
[epoch2, step829]: loss 0.038929
[epoch2, step830]: loss 0.033961
[epoch2, step831]: loss 0.038260
[epoch2, step832]: loss 0.033089
[epoch2, step833]: loss 0.040113
[epoch2, step834]: loss 0.038271
[epoch2, step835]: loss 0.032226
[epoch2, step836]: loss 0.039825
[epoch2, step837]: loss 0.037371
[epoch2, step838]: loss 0.037031
[epoch2, step839]: loss 0.040160
[epoch2, step840]: loss 0.031848
[epoch2, step841]: loss 0.036153
[epoch2, step842]: loss 0.039324
[epoch2, step843]: loss 0.037253
[epoch2, step844]: loss 0.036630
[epoch2, step845]: loss 0.032847
[epoch2, step846]: loss 0.039672
[epoch2, step847]: loss 0.038510
[epoch2, step848]: loss 0.036624
[epoch2, step849]: loss 0.035638
[epoch2, step850]: loss 0.034568
[epoch2, step851]: loss 0.036418
[epoch2, step852]: loss 0.033908
[epoch2, step853]: loss 0.042312
[epoch2, step854]: loss 0.034445
[epoch2, step855]: loss 0.038740
[epoch2, step856]: loss 0.032617
[epoch2, step857]: loss 0.036388
[epoch2, step858]: loss 0.035767
[epoch2, step859]: loss 0.034900
[epoch2, step860]: loss 0.034311
[epoch2, step861]: loss 0.034271
[epoch2, step862]: loss 0.033788
[epoch2, step863]: loss 0.032433
[epoch2, step864]: loss 0.038332
[epoch2, step865]: loss 0.035595
[epoch2, step866]: loss 0.036398
[epoch2, step867]: loss 0.038070
[epoch2, step868]: loss 0.039161
[epoch2, step869]: loss 0.035142
[epoch2, step870]: loss 0.042818
[epoch2, step871]: loss 0.034639
[epoch2, step872]: loss 0.037598
[epoch2, step873]: loss 0.037414
[epoch2, step874]: loss 0.035449
[epoch2, step875]: loss 0.035649
[epoch2, step876]: loss 0.036590
[epoch2, step877]: loss 0.030609
[epoch2, step878]: loss 0.034469
[epoch2, step879]: loss 0.040426
[epoch2, step880]: loss 0.037022
[epoch2, step881]: loss 0.034260
[epoch2, step882]: loss 0.035521
[epoch2, step883]: loss 0.035259
[epoch2, step884]: loss 0.037956
[epoch2, step885]: loss 0.037811
[epoch2, step886]: loss 0.038001
[epoch2, step887]: loss 0.035998
[epoch2, step888]: loss 0.036667
[epoch2, step889]: loss 0.035761
[epoch2, step890]: loss 0.035957
[epoch2, step891]: loss 0.037772
[epoch2, step892]: loss 0.031425
[epoch2, step893]: loss 0.036094
[epoch2, step894]: loss 0.036468
[epoch2, step895]: loss 0.033360
[epoch2, step896]: loss 0.034145
[epoch2, step897]: loss 0.037134
[epoch2, step898]: loss 0.038650
[epoch2, step899]: loss 0.040397
[epoch2, step900]: loss 0.038183
[epoch2, step901]: loss 0.037890
[epoch2, step902]: loss 0.035366
[epoch2, step903]: loss 0.037181
[epoch2, step904]: loss 0.039184
[epoch2, step905]: loss 0.039425
[epoch2, step906]: loss 0.033290
[epoch2, step907]: loss 0.035014
[epoch2, step908]: loss 0.034009
[epoch2, step909]: loss 0.038178
[epoch2, step910]: loss 0.034558
[epoch2, step911]: loss 0.036809
[epoch2, step912]: loss 0.034685
[epoch2, step913]: loss 0.035883
[epoch2, step914]: loss 0.041141
[epoch2, step915]: loss 0.035264
[epoch2, step916]: loss 0.034521
[epoch2, step917]: loss 0.036235
[epoch2, step918]: loss 0.041111
[epoch2, step919]: loss 0.036306
[epoch2, step920]: loss 0.039212
[epoch2, step921]: loss 0.035695
[epoch2, step922]: loss 0.035229
[epoch2, step923]: loss 0.034925
[epoch2, step924]: loss 0.031921
[epoch2, step925]: loss 0.037112
[epoch2, step926]: loss 0.036871
[epoch2, step927]: loss 0.037195
[epoch2, step928]: loss 0.035689
[epoch2, step929]: loss 0.039333
[epoch2, step930]: loss 0.036853
[epoch2, step931]: loss 0.038963
[epoch2, step932]: loss 0.032440
[epoch2, step933]: loss 0.040878
[epoch2, step934]: loss 0.034398
[epoch2, step935]: loss 0.034546
[epoch2, step936]: loss 0.033781
[epoch2, step937]: loss 0.038686
[epoch2, step938]: loss 0.039223
[epoch2, step939]: loss 0.032629
[epoch2, step940]: loss 0.035260
[epoch2, step941]: loss 0.038527
[epoch2, step942]: loss 0.037620
[epoch2, step943]: loss 0.035568
[epoch2, step944]: loss 0.039337
[epoch2, step945]: loss 0.031806
[epoch2, step946]: loss 0.037231
[epoch2, step947]: loss 0.040101
[epoch2, step948]: loss 0.032100
[epoch2, step949]: loss 0.034673
[epoch2, step950]: loss 0.038364
[epoch2, step951]: loss 0.040773
[epoch2, step952]: loss 0.036417
[epoch2, step953]: loss 0.039291
[epoch2, step954]: loss 0.034570
[epoch2, step955]: loss 0.043051
[epoch2, step956]: loss 0.052872
[epoch2, step957]: loss 0.049542
[epoch2, step958]: loss 0.048170
[epoch2, step959]: loss 0.051075
[epoch2, step960]: loss 0.048970
[epoch2, step961]: loss 0.049883
[epoch2, step962]: loss 0.049173
[epoch2, step963]: loss 0.047965
[epoch2, step964]: loss 0.048737
[epoch2, step965]: loss 0.049713
[epoch2, step966]: loss 0.047917
[epoch2, step967]: loss 0.047283
[epoch2, step968]: loss 0.048820
[epoch2, step969]: loss 0.048331
[epoch2, step970]: loss 0.048526
[epoch2, step971]: loss 0.047814
[epoch2, step972]: loss 0.047558
[epoch2, step973]: loss 0.047539
[epoch2, step974]: loss 0.049521
[epoch2, step975]: loss 0.047680
[epoch2, step976]: loss 0.047040
[epoch2, step977]: loss 0.049013
[epoch2, step978]: loss 0.048194
[epoch2, step979]: loss 0.048210
[epoch2, step980]: loss 0.047761
[epoch2, step981]: loss 0.047681
[epoch2, step982]: loss 0.047948
[epoch2, step983]: loss 0.049345
[epoch2, step984]: loss 0.047459
[epoch2, step985]: loss 0.047326
[epoch2, step986]: loss 0.049076
[epoch2, step987]: loss 0.048135
[epoch2, step988]: loss 0.048593
[epoch2, step989]: loss 0.048053
[epoch2, step990]: loss 0.047467
[epoch2, step991]: loss 0.047959
[epoch2, step992]: loss 0.048976
[epoch2, step993]: loss 0.047511
[epoch2, step994]: loss 0.046597
[epoch2, step995]: loss 0.048808
[epoch2, step996]: loss 0.047632
[epoch2, step997]: loss 0.048327
[epoch2, step998]: loss 0.047980
[epoch2, step999]: loss 0.047524
[epoch2, step1000]: loss 0.047661
[epoch2, step1001]: loss 0.049167
[epoch2, step1002]: loss 0.047633
[epoch2, step1003]: loss 0.046885
[epoch2, step1004]: loss 0.048833
[epoch2, step1005]: loss 0.047503
[epoch2, step1006]: loss 0.047983
[epoch2, step1007]: loss 0.047585
[epoch2, step1008]: loss 0.047316
[epoch2, step1009]: loss 0.047689
[epoch2, step1010]: loss 0.049542
[epoch2, step1011]: loss 0.047311
[epoch2, step1012]: loss 0.047073
[epoch2, step1013]: loss 0.048688
[epoch2, step1014]: loss 0.048126
[epoch2, step1015]: loss 0.048398
[epoch2, step1016]: loss 0.047629
[epoch2, step1017]: loss 0.047252
[epoch2, step1018]: loss 0.047689
[epoch2, step1019]: loss 0.049282
[epoch2, step1020]: loss 0.047210
[epoch2, step1021]: loss 0.046752
[epoch2, step1022]: loss 0.048476
[epoch2, step1023]: loss 0.047723
[epoch2, step1024]: loss 0.048513
[epoch2, step1025]: loss 0.047354
[epoch2, step1026]: loss 0.047104
[epoch2, step1027]: loss 0.047535
[epoch2, step1028]: loss 0.049144
[epoch2, step1029]: loss 0.047398
[epoch2, step1030]: loss 0.046558
[epoch2, step1031]: loss 0.048069
[epoch2, step1032]: loss 0.047772
[epoch2, step1033]: loss 0.048155
[epoch2, step1034]: loss 0.047521
[epoch2, step1035]: loss 0.047127
[epoch2, step1036]: loss 0.047650
[epoch2, step1037]: loss 0.048967
[epoch2, step1038]: loss 0.047230
[epoch2, step1039]: loss 0.046897
[epoch2, step1040]: loss 0.048363
[epoch2, step1041]: loss 0.047592
[epoch2, step1042]: loss 0.047779
[epoch2, step1043]: loss 0.047394
[epoch2, step1044]: loss 0.047247
[epoch2, step1045]: loss 0.047661
[epoch2, step1046]: loss 0.049227
[epoch2, step1047]: loss 0.047510
[epoch2, step1048]: loss 0.046697
[epoch2, step1049]: loss 0.048719
[epoch2, step1050]: loss 0.047915
[epoch2, step1051]: loss 0.048152
[epoch2, step1052]: loss 0.047913
[epoch2, step1053]: loss 0.047608
[epoch2, step1054]: loss 0.047645
[epoch2, step1055]: loss 0.048972
[epoch2, step1056]: loss 0.047110
[epoch2, step1057]: loss 0.047059
[epoch2, step1058]: loss 0.048903
[epoch2, step1059]: loss 0.048035
[epoch2, step1060]: loss 0.048237
[epoch2, step1061]: loss 0.047178
[epoch2, step1062]: loss 0.047475
[epoch2, step1063]: loss 0.047595
[epoch2, step1064]: loss 0.049086
[epoch2, step1065]: loss 0.047375
[epoch2, step1066]: loss 0.046722
[epoch2, step1067]: loss 0.048613
[epoch2, step1068]: loss 0.047106
[epoch2, step1069]: loss 0.047885
[epoch2, step1070]: loss 0.047612
[epoch2, step1071]: loss 0.047398
[epoch2, step1072]: loss 0.047821
[epoch2, step1073]: loss 0.048904
[epoch2, step1074]: loss 0.047186
[epoch2, step1075]: loss 0.046981
[epoch2, step1076]: loss 0.048678
[epoch2, step1077]: loss 0.047768
[epoch2, step1078]: loss 0.048092
[epoch2, step1079]: loss 0.048045
[epoch2, step1080]: loss 0.047384
[epoch2, step1081]: loss 0.047509
[epoch2, step1082]: loss 0.049067
[epoch2, step1083]: loss 0.047685
[epoch2, step1084]: loss 0.047051
[epoch2, step1085]: loss 0.048360
[epoch2, step1086]: loss 0.047653
[epoch2, step1087]: loss 0.048157
[epoch2, step1088]: loss 0.047510
[epoch2, step1089]: loss 0.047299
[epoch2, step1090]: loss 0.047721
[epoch2, step1091]: loss 0.049367
[epoch2, step1092]: loss 0.047407
[epoch2, step1093]: loss 0.046644
[epoch2, step1094]: loss 0.048024
[epoch2, step1095]: loss 0.047460
[epoch2, step1096]: loss 0.047949
[epoch2, step1097]: loss 0.047462
[epoch2, step1098]: loss 0.047336
[epoch2, step1099]: loss 0.047519
[epoch2, step1100]: loss 0.049418
[epoch2, step1101]: loss 0.047640
[epoch2, step1102]: loss 0.046699
[epoch2, step1103]: loss 0.048343
[epoch2, step1104]: loss 0.047598
[epoch2, step1105]: loss 0.048109
[epoch2, step1106]: loss 0.047182
[epoch2, step1107]: loss 0.047380
[epoch2, step1108]: loss 0.047523
[epoch2, step1109]: loss 0.049295
[epoch2, step1110]: loss 0.047610
[epoch2, step1111]: loss 0.046941
[epoch2, step1112]: loss 0.048685
[epoch2, step1113]: loss 0.047490
[epoch2, step1114]: loss 0.048257
[epoch2, step1115]: loss 0.047564
[epoch2, step1116]: loss 0.047393
[epoch2, step1117]: loss 0.047495
[epoch2, step1118]: loss 0.049006
[epoch2, step1119]: loss 0.047206
[epoch2, step1120]: loss 0.046556
[epoch2, step1121]: loss 0.048490
[epoch2, step1122]: loss 0.047286
[epoch2, step1123]: loss 0.047844
[epoch2, step1124]: loss 0.047817
[epoch2, step1125]: loss 0.047412
[epoch2, step1126]: loss 0.048073
[epoch2, step1127]: loss 0.049009
[epoch2, step1128]: loss 0.047553
[epoch2, step1129]: loss 0.046678
[epoch2, step1130]: loss 0.048756
[epoch2, step1131]: loss 0.047708
[epoch2, step1132]: loss 0.048149
[epoch2, step1133]: loss 0.047222
[epoch2, step1134]: loss 0.047002
[epoch2, step1135]: loss 0.048021
[epoch2, step1136]: loss 0.049348
[epoch2, step1137]: loss 0.047344
[epoch2, step1138]: loss 0.046806
[epoch2, step1139]: loss 0.048623
[epoch2, step1140]: loss 0.047374
[epoch2, step1141]: loss 0.047992
[epoch2, step1142]: loss 0.047418
[epoch2, step1143]: loss 0.047179
[epoch2, step1144]: loss 0.047815
[epoch2, step1145]: loss 0.048908
[epoch2, step1146]: loss 0.047112
[epoch2, step1147]: loss 0.047226
[epoch2, step1148]: loss 0.048683
[epoch2, step1149]: loss 0.047636
[epoch2, step1150]: loss 0.047863
[epoch2, step1151]: loss 0.047740
[epoch2, step1152]: loss 0.047570
[epoch2, step1153]: loss 0.047313
[epoch2, step1154]: loss 0.049154
[epoch2, step1155]: loss 0.047303
[epoch2, step1156]: loss 0.046488
[epoch2, step1157]: loss 0.048535
[epoch2, step1158]: loss 0.047797
[epoch2, step1159]: loss 0.048033
[epoch2, step1160]: loss 0.047813
[epoch2, step1161]: loss 0.047471
[epoch2, step1162]: loss 0.047573
[epoch2, step1163]: loss 0.048726
[epoch2, step1164]: loss 0.047290
[epoch2, step1165]: loss 0.047305
[epoch2, step1166]: loss 0.048656
[epoch2, step1167]: loss 0.047304
[epoch2, step1168]: loss 0.048107
[epoch2, step1169]: loss 0.047531
[epoch2, step1170]: loss 0.047313
[epoch2, step1171]: loss 0.047497
[epoch2, step1172]: loss 0.049015
[epoch2, step1173]: loss 0.047443
[epoch2, step1174]: loss 0.047082
[epoch2, step1175]: loss 0.048482
[epoch2, step1176]: loss 0.047508
[epoch2, step1177]: loss 0.048256
[epoch2, step1178]: loss 0.047556
[epoch2, step1179]: loss 0.047172
[epoch2, step1180]: loss 0.047507
[epoch2, step1181]: loss 0.049324
[epoch2, step1182]: loss 0.047106
[epoch2, step1183]: loss 0.047033
[epoch2, step1184]: loss 0.048120
[epoch2, step1185]: loss 0.047782
[epoch2, step1186]: loss 0.047726
[epoch2, step1187]: loss 0.047207
[epoch2, step1188]: loss 0.047022
[epoch2, step1189]: loss 0.047362
[epoch2, step1190]: loss 0.048782
[epoch2, step1191]: loss 0.047624
[epoch2, step1192]: loss 0.046784
[epoch2, step1193]: loss 0.048559
[epoch2, step1194]: loss 0.047521
[epoch2, step1195]: loss 0.047564
[epoch2, step1196]: loss 0.047128
[epoch2, step1197]: loss 0.047442
[epoch2, step1198]: loss 0.047584
[epoch2, step1199]: loss 0.048861
[epoch2, step1200]: loss 0.047141
[epoch2, step1201]: loss 0.046996
[epoch2, step1202]: loss 0.048895
[epoch2, step1203]: loss 0.047639
[epoch2, step1204]: loss 0.047788
[epoch2, step1205]: loss 0.047343
[epoch2, step1206]: loss 0.047046
[epoch2, step1207]: loss 0.047608
[epoch2, step1208]: loss 0.049234
[epoch2, step1209]: loss 0.046774
[epoch2, step1210]: loss 0.047173
[epoch2, step1211]: loss 0.048276
[epoch2, step1212]: loss 0.047533
[epoch2, step1213]: loss 0.047727
[epoch2, step1214]: loss 0.047600
[epoch2, step1215]: loss 0.047586
[epoch2, step1216]: loss 0.047348
[epoch2, step1217]: loss 0.049145
[epoch2, step1218]: loss 0.047090
[epoch2, step1219]: loss 0.046954
[epoch2, step1220]: loss 0.048642
[epoch2, step1221]: loss 0.047140
[epoch2, step1222]: loss 0.048139
[epoch2, step1223]: loss 0.047557
[epoch2, step1224]: loss 0.047335
[epoch2, step1225]: loss 0.047632
[epoch2, step1226]: loss 0.048834
[epoch2, step1227]: loss 0.047346
[epoch2, step1228]: loss 0.046527
[epoch2, step1229]: loss 0.048478
[epoch2, step1230]: loss 0.047720
[epoch2, step1231]: loss 0.047837
[epoch2, step1232]: loss 0.047915
[epoch2, step1233]: loss 0.047175
[epoch2, step1234]: loss 0.047377
[epoch2, step1235]: loss 0.049197
[epoch2, step1236]: loss 0.047500
[epoch2, step1237]: loss 0.046742
[epoch2, step1238]: loss 0.048297
[epoch2, step1239]: loss 0.047778
[epoch2, step1240]: loss 0.048086
[epoch2, step1241]: loss 0.047521
[epoch2, step1242]: loss 0.047339
[epoch2, step1243]: loss 0.047486
[epoch2, step1244]: loss 0.049167
[epoch2, step1245]: loss 0.047562
[epoch2, step1246]: loss 0.046998
[epoch2, step1247]: loss 0.048206
[epoch2, step1248]: loss 0.047638
[epoch2, step1249]: loss 0.048282
[epoch2, step1250]: loss 0.047563
[epoch2, step1251]: loss 0.047307
[epoch2, step1252]: loss 0.048007
[epoch2, step1253]: loss 0.049000
[epoch2, step1254]: loss 0.047356
[epoch2, step1255]: loss 0.046765
[epoch2, step1256]: loss 0.048649
[epoch2, step1257]: loss 0.047599
[epoch2, step1258]: loss 0.048184
[epoch2, step1259]: loss 0.047513
[epoch2, step1260]: loss 0.047435
[epoch2, step1261]: loss 0.047430
[epoch2, step1262]: loss 0.048486
[epoch2, step1263]: loss 0.047574
[epoch2, step1264]: loss 0.046748
[epoch2, step1265]: loss 0.048180
[epoch2, step1266]: loss 0.047515
[epoch2, step1267]: loss 0.048102
[epoch2, step1268]: loss 0.047430
[epoch2, step1269]: loss 0.047226
[epoch2, step1270]: loss 0.047282
[epoch2, step1271]: loss 0.049270
[epoch2, step1272]: loss 0.047436
[epoch2, step1273]: loss 0.046633
[epoch2, step1274]: loss 0.048586
[epoch2, step1275]: loss 0.047883
[epoch2, step1276]: loss 0.047971
[epoch2, step1277]: loss 0.047572
[epoch2, step1278]: loss 0.047499
[epoch2, step1279]: loss 0.047710
[epoch2, step1280]: loss 0.049150
[epoch2, step1281]: loss 0.047319
[epoch2, step1282]: loss 0.046617
[epoch2, step1283]: loss 0.048140
[epoch2, step1284]: loss 0.047385
[epoch2, step1285]: loss 0.048215
[epoch2, step1286]: loss 0.047068
[epoch2, step1287]: loss 0.047582
[epoch2, step1288]: loss 0.047822
[epoch2, step1289]: loss 0.049455
[epoch2, step1290]: loss 0.047358
[epoch2, step1291]: loss 0.046610
[epoch2, step1292]: loss 0.048762
[epoch2, step1293]: loss 0.047211
[epoch2, step1294]: loss 0.047905
[epoch2, step1295]: loss 0.047565
[epoch2, step1296]: loss 0.047326
[epoch2, step1297]: loss 0.047459
[epoch2, step1298]: loss 0.049259
[epoch2, step1299]: loss 0.047331
[epoch2, step1300]: loss 0.047222
[epoch2, step1301]: loss 0.048116
[epoch2, step1302]: loss 0.047750
[epoch2, step1303]: loss 0.048072
[epoch2, step1304]: loss 0.047399
[epoch2, step1305]: loss 0.047318
[epoch2, step1306]: loss 0.047416
[epoch2, step1307]: loss 0.048839
[epoch2, step1308]: loss 0.047475
[epoch2, step1309]: loss 0.046506
[epoch2, step1310]: loss 0.048515
[epoch2, step1311]: loss 0.047065
[epoch2, step1312]: loss 0.048185
[epoch2, step1313]: loss 0.047446
[epoch2, step1314]: loss 0.047230
[epoch2, step1315]: loss 0.047332
[epoch2, step1316]: loss 0.049610
[epoch2, step1317]: loss 0.047014
[epoch2, step1318]: loss 0.046486
[epoch2, step1319]: loss 0.048242
[epoch2, step1320]: loss 0.047535
[epoch2, step1321]: loss 0.048121
[epoch2, step1322]: loss 0.047438
[epoch2, step1323]: loss 0.047417
[epoch2, step1324]: loss 0.047361
[epoch2, step1325]: loss 0.048862
[epoch2, step1326]: loss 0.047229
[epoch2, step1327]: loss 0.046791
[epoch2, step1328]: loss 0.048548
[epoch2, step1329]: loss 0.047580
[epoch2, step1330]: loss 0.048053
[epoch2, step1331]: loss 0.047280
[epoch2, step1332]: loss 0.047269
[epoch2, step1333]: loss 0.047082
[epoch2, step1334]: loss 0.049263
[epoch2, step1335]: loss 0.047497
[epoch2, step1336]: loss 0.046549
[epoch2, step1337]: loss 0.048061
[epoch2, step1338]: loss 0.047329
[epoch2, step1339]: loss 0.047983
[epoch2, step1340]: loss 0.047356
[epoch2, step1341]: loss 0.047335
[epoch2, step1342]: loss 0.047374
[epoch2, step1343]: loss 0.049213
[epoch2, step1344]: loss 0.047460
[epoch2, step1345]: loss 0.046838
[epoch2, step1346]: loss 0.048293
[epoch2, step1347]: loss 0.047750
[epoch2, step1348]: loss 0.047934
[epoch2, step1349]: loss 0.047531
[epoch2, step1350]: loss 0.047137
[epoch2, step1351]: loss 0.047302
[epoch2, step1352]: loss 0.048857
[epoch2, step1353]: loss 0.047246
[epoch2, step1354]: loss 0.046623
[epoch2, step1355]: loss 0.048473
[epoch2, step1356]: loss 0.047236
[epoch2, step1357]: loss 0.047731
[epoch2, step1358]: loss 0.047358
[epoch2, step1359]: loss 0.047203
[epoch2, step1360]: loss 0.047545
[epoch2, step1361]: loss 0.049161
[epoch2, step1362]: loss 0.047528
[epoch2, step1363]: loss 0.046861
[epoch2, step1364]: loss 0.048235
[epoch2, step1365]: loss 0.047538
[epoch2, step1366]: loss 0.047864
[epoch2, step1367]: loss 0.047193
[epoch2, step1368]: loss 0.047645
[epoch2, step1369]: loss 0.047594
[epoch2, step1370]: loss 0.048879
[epoch2, step1371]: loss 0.047337
[epoch2, step1372]: loss 0.046606
[epoch2, step1373]: loss 0.048600
[epoch2, step1374]: loss 0.047770
[epoch2, step1375]: loss 0.048360
[epoch2, step1376]: loss 0.047282
[epoch2, step1377]: loss 0.047028
[epoch2, step1378]: loss 0.047604
[epoch2, step1379]: loss 0.048953
[epoch2, step1380]: loss 0.047312
[epoch2, step1381]: loss 0.046723
[epoch2, step1382]: loss 0.048620
[epoch2, step1383]: loss 0.047491
[epoch2, step1384]: loss 0.047980
[epoch2, step1385]: loss 0.047077
[epoch2, step1386]: loss 0.047299
[epoch2, step1387]: loss 0.047609
[epoch2, step1388]: loss 0.048725
[epoch2, step1389]: loss 0.046828
[epoch2, step1390]: loss 0.046709
[epoch2, step1391]: loss 0.048434
[epoch2, step1392]: loss 0.047518
[epoch2, step1393]: loss 0.048039
[epoch2, step1394]: loss 0.047865
[epoch2, step1395]: loss 0.047362
[epoch2, step1396]: loss 0.047329
[epoch2, step1397]: loss 0.049008
[epoch2, step1398]: loss 0.047328
[epoch2, step1399]: loss 0.047078
[epoch2, step1400]: loss 0.048708
[epoch2, step1401]: loss 0.047440
[epoch2, step1402]: loss 0.047910
[epoch2, step1403]: loss 0.046982
[epoch2, step1404]: loss 0.047156
[epoch2, step1405]: loss 0.047386
[epoch2, step1406]: loss 0.048748
[epoch2, step1407]: loss 0.047822
[epoch2, step1408]: loss 0.046514
[epoch2, step1409]: loss 0.048198
[epoch2, step1410]: loss 0.047460
[epoch2, step1411]: loss 0.047444
[epoch2, step1412]: loss 0.047342
[epoch2, step1413]: loss 0.047253
[epoch2, step1414]: loss 0.047270
[epoch2, step1415]: loss 0.048881
[epoch2, step1416]: loss 0.047101
[epoch2, step1417]: loss 0.046669
[epoch2, step1418]: loss 0.048348
[epoch2, step1419]: loss 0.047840
[epoch2, step1420]: loss 0.047981
[epoch2, step1421]: loss 0.047645
[epoch2, step1422]: loss 0.047361
[epoch2, step1423]: loss 0.047197
[epoch2, step1424]: loss 0.049037
[epoch2, step1425]: loss 0.046811
[epoch2, step1426]: loss 0.046806
[epoch2, step1427]: loss 0.048780
[epoch2, step1428]: loss 0.047752
[epoch2, step1429]: loss 0.048011
[epoch2, step1430]: loss 0.047430
[epoch2, step1431]: loss 0.047528
[epoch2, step1432]: loss 0.047386
[epoch2, step1433]: loss 0.049087
[epoch2, step1434]: loss 0.046940
[epoch2, step1435]: loss 0.046869
[epoch2, step1436]: loss 0.048668
[epoch2, step1437]: loss 0.047635
[epoch2, step1438]: loss 0.048003
[epoch2, step1439]: loss 0.047406
[epoch2, step1440]: loss 0.047077
[epoch2, step1441]: loss 0.047862
[epoch2, step1442]: loss 0.048609
[epoch2, step1443]: loss 0.047176
[epoch2, step1444]: loss 0.046455
[epoch2, step1445]: loss 0.048477
[epoch2, step1446]: loss 0.047482
[epoch2, step1447]: loss 0.048250
[epoch2, step1448]: loss 0.047301
[epoch2, step1449]: loss 0.046987
[epoch2, step1450]: loss 0.047459
[epoch2, step1451]: loss 0.049130
[epoch2, step1452]: loss 0.047151
[epoch2, step1453]: loss 0.047113
[epoch2, step1454]: loss 0.048557
[epoch2, step1455]: loss 0.047896
[epoch2, step1456]: loss 0.047781
[epoch2, step1457]: loss 0.047569
[epoch2, step1458]: loss 0.047368
[epoch2, step1459]: loss 0.047327
[epoch2, step1460]: loss 0.049260
[epoch2, step1461]: loss 0.047572
[epoch2, step1462]: loss 0.046932
[epoch2, step1463]: loss 0.048396
[epoch2, step1464]: loss 0.047718
[epoch2, step1465]: loss 0.047825
[epoch2, step1466]: loss 0.047270
[epoch2, step1467]: loss 0.047238
[epoch2, step1468]: loss 0.047137
[epoch2, step1469]: loss 0.049019
[epoch2, step1470]: loss 0.047393
[epoch2, step1471]: loss 0.046476
[epoch2, step1472]: loss 0.048354
[epoch2, step1473]: loss 0.047430
[epoch2, step1474]: loss 0.048279
[epoch2, step1475]: loss 0.047271
[epoch2, step1476]: loss 0.047458
[epoch2, step1477]: loss 0.047481
[epoch2, step1478]: loss 0.049024
[epoch2, step1479]: loss 0.047184
[epoch2, step1480]: loss 0.046680
[epoch2, step1481]: loss 0.048129
[epoch2, step1482]: loss 0.047474
[epoch2, step1483]: loss 0.047899
[epoch2, step1484]: loss 0.047583
[epoch2, step1485]: loss 0.047018
[epoch2, step1486]: loss 0.046975
[epoch2, step1487]: loss 0.049005
[epoch2, step1488]: loss 0.047163
[epoch2, step1489]: loss 0.046752
[epoch2, step1490]: loss 0.048302
[epoch2, step1491]: loss 0.047541
[epoch2, step1492]: loss 0.047696
[epoch2, step1493]: loss 0.047530
[epoch2, step1494]: loss 0.047336
[epoch2, step1495]: loss 0.047303
[epoch2, step1496]: loss 0.048588
[epoch2, step1497]: loss 0.047322
[epoch2, step1498]: loss 0.046767
[epoch2, step1499]: loss 0.048124
[epoch2, step1500]: loss 0.047554
[epoch2, step1501]: loss 0.047862
[epoch2, step1502]: loss 0.047341
[epoch2, step1503]: loss 0.047153
[epoch2, step1504]: loss 0.047072
[epoch2, step1505]: loss 0.049089
[epoch2, step1506]: loss 0.046722
[epoch2, step1507]: loss 0.046791
[epoch2, step1508]: loss 0.048575
[epoch2, step1509]: loss 0.047339
[epoch2, step1510]: loss 0.047592
[epoch2, step1511]: loss 0.047653
[epoch2, step1512]: loss 0.047256
[epoch2, step1513]: loss 0.046801
[epoch2, step1514]: loss 0.048792
[epoch2, step1515]: loss 0.047209
[epoch2, step1516]: loss 0.046529

[epoch2]: avg loss 0.042917

[epoch3, step1]: loss 0.040330
[epoch3, step2]: loss 0.043295
[epoch3, step3]: loss 0.043342
[epoch3, step4]: loss 0.041123
[epoch3, step5]: loss 0.041418
[epoch3, step6]: loss 0.043066
[epoch3, step7]: loss 0.041032
[epoch3, step8]: loss 0.043970
[epoch3, step9]: loss 0.040801
[epoch3, step10]: loss 0.040690
[epoch3, step11]: loss 0.043126
[epoch3, step12]: loss 0.043248
[epoch3, step13]: loss 0.040839
[epoch3, step14]: loss 0.040966
[epoch3, step15]: loss 0.042942
[epoch3, step16]: loss 0.040506
[epoch3, step17]: loss 0.044300
[epoch3, step18]: loss 0.041685
[epoch3, step19]: loss 0.040332
[epoch3, step20]: loss 0.043861
[epoch3, step21]: loss 0.043275
[epoch3, step22]: loss 0.040359
[epoch3, step23]: loss 0.040009
[epoch3, step24]: loss 0.042864
[epoch3, step25]: loss 0.039840
[epoch3, step26]: loss 0.043187
[epoch3, step27]: loss 0.040358
[epoch3, step28]: loss 0.040074
[epoch3, step29]: loss 0.042972
[epoch3, step30]: loss 0.043592
[epoch3, step31]: loss 0.039974
[epoch3, step32]: loss 0.040842
[epoch3, step33]: loss 0.043201
[epoch3, step34]: loss 0.040699
[epoch3, step35]: loss 0.043776
[epoch3, step36]: loss 0.040365
[epoch3, step37]: loss 0.039736
[epoch3, step38]: loss 0.042365
[epoch3, step39]: loss 0.042588
[epoch3, step40]: loss 0.040318
[epoch3, step41]: loss 0.039575
[epoch3, step42]: loss 0.042520
[epoch3, step43]: loss 0.039689
[epoch3, step44]: loss 0.043299
[epoch3, step45]: loss 0.040098
[epoch3, step46]: loss 0.039618
[epoch3, step47]: loss 0.041939
[epoch3, step48]: loss 0.042120
[epoch3, step49]: loss 0.038417
[epoch3, step50]: loss 0.040022
[epoch3, step51]: loss 0.041864
[epoch3, step52]: loss 0.039566
[epoch3, step53]: loss 0.043405
[epoch3, step54]: loss 0.039806
[epoch3, step55]: loss 0.039783
[epoch3, step56]: loss 0.042979
[epoch3, step57]: loss 0.042718
[epoch3, step58]: loss 0.039744
[epoch3, step59]: loss 0.039011
[epoch3, step60]: loss 0.042389
[epoch3, step61]: loss 0.038975
[epoch3, step62]: loss 0.042242
[epoch3, step63]: loss 0.039273
[epoch3, step64]: loss 0.038936
[epoch3, step65]: loss 0.042246
[epoch3, step66]: loss 0.042209
[epoch3, step67]: loss 0.039731
[epoch3, step68]: loss 0.039737
[epoch3, step69]: loss 0.041857
[epoch3, step70]: loss 0.039358
[epoch3, step71]: loss 0.042222
[epoch3, step72]: loss 0.039773
[epoch3, step73]: loss 0.039035
[epoch3, step74]: loss 0.042124
[epoch3, step75]: loss 0.042242
[epoch3, step76]: loss 0.039989
[epoch3, step77]: loss 0.040136
[epoch3, step78]: loss 0.041958
[epoch3, step79]: loss 0.038900
[epoch3, step80]: loss 0.043166
[epoch3, step81]: loss 0.039690
[epoch3, step82]: loss 0.038839
[epoch3, step83]: loss 0.041222
[epoch3, step84]: loss 0.042247
[epoch3, step85]: loss 0.039901
[epoch3, step86]: loss 0.039640
[epoch3, step87]: loss 0.042675
[epoch3, step88]: loss 0.038332
[epoch3, step89]: loss 0.042000
[epoch3, step90]: loss 0.039910
[epoch3, step91]: loss 0.038575
[epoch3, step92]: loss 0.041956
[epoch3, step93]: loss 0.041896
[epoch3, step94]: loss 0.039134
[epoch3, step95]: loss 0.039819
[epoch3, step96]: loss 0.041417
[epoch3, step97]: loss 0.039815
[epoch3, step98]: loss 0.042216
[epoch3, step99]: loss 0.039547
[epoch3, step100]: loss 0.038098
[epoch3, step101]: loss 0.042243
[epoch3, step102]: loss 0.041828
[epoch3, step103]: loss 0.039085
[epoch3, step104]: loss 0.039413
[epoch3, step105]: loss 0.041702
[epoch3, step106]: loss 0.039093
[epoch3, step107]: loss 0.042025
[epoch3, step108]: loss 0.039582
[epoch3, step109]: loss 0.038513
[epoch3, step110]: loss 0.042247
[epoch3, step111]: loss 0.041578
[epoch3, step112]: loss 0.039231
[epoch3, step113]: loss 0.039973
[epoch3, step114]: loss 0.041356
[epoch3, step115]: loss 0.039101
[epoch3, step116]: loss 0.042622
[epoch3, step117]: loss 0.039284
[epoch3, step118]: loss 0.039252
[epoch3, step119]: loss 0.042000
[epoch3, step120]: loss 0.041785
[epoch3, step121]: loss 0.038734
[epoch3, step122]: loss 0.039089
[epoch3, step123]: loss 0.041768
[epoch3, step124]: loss 0.039265
[epoch3, step125]: loss 0.042289
[epoch3, step126]: loss 0.039152
[epoch3, step127]: loss 0.038576
[epoch3, step128]: loss 0.041454
[epoch3, step129]: loss 0.041222
[epoch3, step130]: loss 0.038990
[epoch3, step131]: loss 0.038543
[epoch3, step132]: loss 0.041507
[epoch3, step133]: loss 0.038731
[epoch3, step134]: loss 0.041311
[epoch3, step135]: loss 0.039579
[epoch3, step136]: loss 0.039507
[epoch3, step137]: loss 0.041180
[epoch3, step138]: loss 0.041429
[epoch3, step139]: loss 0.038611
[epoch3, step140]: loss 0.039422
[epoch3, step141]: loss 0.041469
[epoch3, step142]: loss 0.038787
[epoch3, step143]: loss 0.041313
[epoch3, step144]: loss 0.039292
[epoch3, step145]: loss 0.038604
[epoch3, step146]: loss 0.041501
[epoch3, step147]: loss 0.042634
[epoch3, step148]: loss 0.038516
[epoch3, step149]: loss 0.038493
[epoch3, step150]: loss 0.040870
[epoch3, step151]: loss 0.038904
[epoch3, step152]: loss 0.041606
[epoch3, step153]: loss 0.039140
[epoch3, step154]: loss 0.038043
[epoch3, step155]: loss 0.041349
[epoch3, step156]: loss 0.041061
[epoch3, step157]: loss 0.038753
[epoch3, step158]: loss 0.039053
[epoch3, step159]: loss 0.041413
[epoch3, step160]: loss 0.039038
[epoch3, step161]: loss 0.042010
[epoch3, step162]: loss 0.039086
[epoch3, step163]: loss 0.038245
[epoch3, step164]: loss 0.041566
[epoch3, step165]: loss 0.041382
[epoch3, step166]: loss 0.038801
[epoch3, step167]: loss 0.038392
[epoch3, step168]: loss 0.041593
[epoch3, step169]: loss 0.038405
[epoch3, step170]: loss 0.041693
[epoch3, step171]: loss 0.039036
[epoch3, step172]: loss 0.038394
[epoch3, step173]: loss 0.041510
[epoch3, step174]: loss 0.041089
[epoch3, step175]: loss 0.039114
[epoch3, step176]: loss 0.039012
[epoch3, step177]: loss 0.041323
[epoch3, step178]: loss 0.038680
[epoch3, step179]: loss 0.040548
[epoch3, step180]: loss 0.039046
[epoch3, step181]: loss 0.038388
[epoch3, step182]: loss 0.041393
[epoch3, step183]: loss 0.041806
[epoch3, step184]: loss 0.039248
[epoch3, step185]: loss 0.038924
[epoch3, step186]: loss 0.041079
[epoch3, step187]: loss 0.038671
[epoch3, step188]: loss 0.040979
[epoch3, step189]: loss 0.038659
[epoch3, step190]: loss 0.037801
[epoch3, step191]: loss 0.040773
[epoch3, step192]: loss 0.041591
[epoch3, step193]: loss 0.036596
[epoch3, step194]: loss 0.037816
[epoch3, step195]: loss 0.041219
[epoch3, step196]: loss 0.038523
[epoch3, step197]: loss 0.041003
[epoch3, step198]: loss 0.037687
[epoch3, step199]: loss 0.038165
[epoch3, step200]: loss 0.041457
[epoch3, step201]: loss 0.041545
[epoch3, step202]: loss 0.037874
[epoch3, step203]: loss 0.038517
[epoch3, step204]: loss 0.041194
[epoch3, step205]: loss 0.037815
[epoch3, step206]: loss 0.040735
[epoch3, step207]: loss 0.038293
[epoch3, step208]: loss 0.038456
[epoch3, step209]: loss 0.041155
[epoch3, step210]: loss 0.041830
[epoch3, step211]: loss 0.038635
[epoch3, step212]: loss 0.038850
[epoch3, step213]: loss 0.040503
[epoch3, step214]: loss 0.037913
[epoch3, step215]: loss 0.041175
[epoch3, step216]: loss 0.038649
[epoch3, step217]: loss 0.037305
[epoch3, step218]: loss 0.041117
[epoch3, step219]: loss 0.040846
[epoch3, step220]: loss 0.038343
[epoch3, step221]: loss 0.038573
[epoch3, step222]: loss 0.040975
[epoch3, step223]: loss 0.038342
[epoch3, step224]: loss 0.040594
[epoch3, step225]: loss 0.038122
[epoch3, step226]: loss 0.037810
[epoch3, step227]: loss 0.039973
[epoch3, step228]: loss 0.041317
[epoch3, step229]: loss 0.037161
[epoch3, step230]: loss 0.038456
[epoch3, step231]: loss 0.041068
[epoch3, step232]: loss 0.037780
[epoch3, step233]: loss 0.040008
[epoch3, step234]: loss 0.037748
[epoch3, step235]: loss 0.038190
[epoch3, step236]: loss 0.040933
[epoch3, step237]: loss 0.040894
[epoch3, step238]: loss 0.037619
[epoch3, step239]: loss 0.037549
[epoch3, step240]: loss 0.040158
[epoch3, step241]: loss 0.038811
[epoch3, step242]: loss 0.040699
[epoch3, step243]: loss 0.038680
[epoch3, step244]: loss 0.037943
[epoch3, step245]: loss 0.040381
[epoch3, step246]: loss 0.040857
[epoch3, step247]: loss 0.038105
[epoch3, step248]: loss 0.037742
[epoch3, step249]: loss 0.040290
[epoch3, step250]: loss 0.038060
[epoch3, step251]: loss 0.041171
[epoch3, step252]: loss 0.038376
[epoch3, step253]: loss 0.037421
[epoch3, step254]: loss 0.040044
[epoch3, step255]: loss 0.040697
[epoch3, step256]: loss 0.037422
[epoch3, step257]: loss 0.037742
[epoch3, step258]: loss 0.041112
[epoch3, step259]: loss 0.038036
[epoch3, step260]: loss 0.039930
[epoch3, step261]: loss 0.038717
[epoch3, step262]: loss 0.038307
[epoch3, step263]: loss 0.039878
[epoch3, step264]: loss 0.040494
[epoch3, step265]: loss 0.037867
[epoch3, step266]: loss 0.037964
[epoch3, step267]: loss 0.040085
[epoch3, step268]: loss 0.037751
[epoch3, step269]: loss 0.040506
[epoch3, step270]: loss 0.037332
[epoch3, step271]: loss 0.037757
[epoch3, step272]: loss 0.040599
[epoch3, step273]: loss 0.040285
[epoch3, step274]: loss 0.037956
[epoch3, step275]: loss 0.037449
[epoch3, step276]: loss 0.039995
[epoch3, step277]: loss 0.038557
[epoch3, step278]: loss 0.040591
[epoch3, step279]: loss 0.037437
[epoch3, step280]: loss 0.037727
[epoch3, step281]: loss 0.040307
[epoch3, step282]: loss 0.041061
[epoch3, step283]: loss 0.037142
[epoch3, step284]: loss 0.037277
[epoch3, step285]: loss 0.041320
[epoch3, step286]: loss 0.036969
[epoch3, step287]: loss 0.040465
[epoch3, step288]: loss 0.037178
[epoch3, step289]: loss 0.038471
[epoch3, step290]: loss 0.040654
[epoch3, step291]: loss 0.040698
[epoch3, step292]: loss 0.036594
[epoch3, step293]: loss 0.037450
[epoch3, step294]: loss 0.039564
[epoch3, step295]: loss 0.037623
[epoch3, step296]: loss 0.041246
[epoch3, step297]: loss 0.037194
[epoch3, step298]: loss 0.038180
[epoch3, step299]: loss 0.039722
[epoch3, step300]: loss 0.040760
[epoch3, step301]: loss 0.037375
[epoch3, step302]: loss 0.038060
[epoch3, step303]: loss 0.040887
[epoch3, step304]: loss 0.037403
[epoch3, step305]: loss 0.039907
[epoch3, step306]: loss 0.037626
[epoch3, step307]: loss 0.037194
[epoch3, step308]: loss 0.041045
[epoch3, step309]: loss 0.040720
[epoch3, step310]: loss 0.037432
[epoch3, step311]: loss 0.038083
[epoch3, step312]: loss 0.040096
[epoch3, step313]: loss 0.038401
[epoch3, step314]: loss 0.040301
[epoch3, step315]: loss 0.038431
[epoch3, step316]: loss 0.037522
[epoch3, step317]: loss 0.040657
[epoch3, step318]: loss 0.040603
[epoch3, step319]: loss 0.036833
[epoch3, step320]: loss 0.036697
[epoch3, step321]: loss 0.040027
[epoch3, step322]: loss 0.037681
[epoch3, step323]: loss 0.039593
[epoch3, step324]: loss 0.038127
[epoch3, step325]: loss 0.037895
[epoch3, step326]: loss 0.040236
[epoch3, step327]: loss 0.039895
[epoch3, step328]: loss 0.037413
[epoch3, step329]: loss 0.037403
[epoch3, step330]: loss 0.040074
[epoch3, step331]: loss 0.037952
[epoch3, step332]: loss 0.039650
[epoch3, step333]: loss 0.037415
[epoch3, step334]: loss 0.037594
[epoch3, step335]: loss 0.040593
[epoch3, step336]: loss 0.041330
[epoch3, step337]: loss 0.037396
[epoch3, step338]: loss 0.037157
[epoch3, step339]: loss 0.040060
[epoch3, step340]: loss 0.038193
[epoch3, step341]: loss 0.039714
[epoch3, step342]: loss 0.037138
[epoch3, step343]: loss 0.037902
[epoch3, step344]: loss 0.040041
[epoch3, step345]: loss 0.039809
[epoch3, step346]: loss 0.036698
[epoch3, step347]: loss 0.037282
[epoch3, step348]: loss 0.040448
[epoch3, step349]: loss 0.038249
[epoch3, step350]: loss 0.039668
[epoch3, step351]: loss 0.036680
[epoch3, step352]: loss 0.037567
[epoch3, step353]: loss 0.040191
[epoch3, step354]: loss 0.039441
[epoch3, step355]: loss 0.036207
[epoch3, step356]: loss 0.038191
[epoch3, step357]: loss 0.040324
[epoch3, step358]: loss 0.036498
[epoch3, step359]: loss 0.040963
[epoch3, step360]: loss 0.036317
[epoch3, step361]: loss 0.036992
[epoch3, step362]: loss 0.040898
[epoch3, step363]: loss 0.040190
[epoch3, step364]: loss 0.036969
[epoch3, step365]: loss 0.037242
[epoch3, step366]: loss 0.040708
[epoch3, step367]: loss 0.037706
[epoch3, step368]: loss 0.039517
[epoch3, step369]: loss 0.037202
[epoch3, step370]: loss 0.038216
[epoch3, step371]: loss 0.041180
[epoch3, step372]: loss 0.039952
[epoch3, step373]: loss 0.036575
[epoch3, step374]: loss 0.036752
[epoch3, step375]: loss 0.040755
[epoch3, step376]: loss 0.037796
[epoch3, step377]: loss 0.040312
[epoch3, step378]: loss 0.037651
[epoch3, step379]: loss 0.038209
[epoch3, step380]: loss 0.040858
[epoch3, step381]: loss 0.040025
[epoch3, step382]: loss 0.037372
[epoch3, step383]: loss 0.036562
[epoch3, step384]: loss 0.039646
[epoch3, step385]: loss 0.037720
[epoch3, step386]: loss 0.040228
[epoch3, step387]: loss 0.037375
[epoch3, step388]: loss 0.038324
[epoch3, step389]: loss 0.040390
[epoch3, step390]: loss 0.041090
[epoch3, step391]: loss 0.036703
[epoch3, step392]: loss 0.037973
[epoch3, step393]: loss 0.039639
[epoch3, step394]: loss 0.037787
[epoch3, step395]: loss 0.039849
[epoch3, step396]: loss 0.037372
[epoch3, step397]: loss 0.037275
[epoch3, step398]: loss 0.040471
[epoch3, step399]: loss 0.040200
[epoch3, step400]: loss 0.036770
[epoch3, step401]: loss 0.037208
[epoch3, step402]: loss 0.039834
[epoch3, step403]: loss 0.037686
[epoch3, step404]: loss 0.040345
[epoch3, step405]: loss 0.037453
[epoch3, step406]: loss 0.037831
[epoch3, step407]: loss 0.040056
[epoch3, step408]: loss 0.040306
[epoch3, step409]: loss 0.038223
[epoch3, step410]: loss 0.038018
[epoch3, step411]: loss 0.040033
[epoch3, step412]: loss 0.037225
[epoch3, step413]: loss 0.039969
[epoch3, step414]: loss 0.036870
[epoch3, step415]: loss 0.037894
[epoch3, step416]: loss 0.039694
[epoch3, step417]: loss 0.040499
[epoch3, step418]: loss 0.036851
[epoch3, step419]: loss 0.036622
[epoch3, step420]: loss 0.040372
[epoch3, step421]: loss 0.037412
[epoch3, step422]: loss 0.040011
[epoch3, step423]: loss 0.037289
[epoch3, step424]: loss 0.037732
[epoch3, step425]: loss 0.040464
[epoch3, step426]: loss 0.040572
[epoch3, step427]: loss 0.037234
[epoch3, step428]: loss 0.037163
[epoch3, step429]: loss 0.040780
[epoch3, step430]: loss 0.037546
[epoch3, step431]: loss 0.040329
[epoch3, step432]: loss 0.037175
[epoch3, step433]: loss 0.038316
[epoch3, step434]: loss 0.040186
[epoch3, step435]: loss 0.040695
[epoch3, step436]: loss 0.036584
[epoch3, step437]: loss 0.037532
[epoch3, step438]: loss 0.040692
[epoch3, step439]: loss 0.037822
[epoch3, step440]: loss 0.039988
[epoch3, step441]: loss 0.037384
[epoch3, step442]: loss 0.037362
[epoch3, step443]: loss 0.040671
[epoch3, step444]: loss 0.039905
[epoch3, step445]: loss 0.037461
[epoch3, step446]: loss 0.037668
[epoch3, step447]: loss 0.040836
[epoch3, step448]: loss 0.037786
[epoch3, step449]: loss 0.039678
[epoch3, step450]: loss 0.036569
[epoch3, step451]: loss 0.037235
[epoch3, step452]: loss 0.038972
[epoch3, step453]: loss 0.040323
[epoch3, step454]: loss 0.036765
[epoch3, step455]: loss 0.037400
[epoch3, step456]: loss 0.039054
[epoch3, step457]: loss 0.038121
[epoch3, step458]: loss 0.039592
[epoch3, step459]: loss 0.037716
[epoch3, step460]: loss 0.037473
[epoch3, step461]: loss 0.040806
[epoch3, step462]: loss 0.039398
[epoch3, step463]: loss 0.037048
[epoch3, step464]: loss 0.037095
[epoch3, step465]: loss 0.041167
[epoch3, step466]: loss 0.037392
[epoch3, step467]: loss 0.039542
[epoch3, step468]: loss 0.037000
[epoch3, step469]: loss 0.037482
[epoch3, step470]: loss 0.040277
[epoch3, step471]: loss 0.039574
[epoch3, step472]: loss 0.037210
[epoch3, step473]: loss 0.036752
[epoch3, step474]: loss 0.039827
[epoch3, step475]: loss 0.037629
[epoch3, step476]: loss 0.040339
[epoch3, step477]: loss 0.036805
[epoch3, step478]: loss 0.036855
[epoch3, step479]: loss 0.039808
[epoch3, step480]: loss 0.039029
[epoch3, step481]: loss 0.036291
[epoch3, step482]: loss 0.036498
[epoch3, step483]: loss 0.040257
[epoch3, step484]: loss 0.037646
[epoch3, step485]: loss 0.039935
[epoch3, step486]: loss 0.037463
[epoch3, step487]: loss 0.036823
[epoch3, step488]: loss 0.040335
[epoch3, step489]: loss 0.039368
[epoch3, step490]: loss 0.037265
[epoch3, step491]: loss 0.037238
[epoch3, step492]: loss 0.039667
[epoch3, step493]: loss 0.036891
[epoch3, step494]: loss 0.039064
[epoch3, step495]: loss 0.038076
[epoch3, step496]: loss 0.037209
[epoch3, step497]: loss 0.040104
[epoch3, step498]: loss 0.039540
[epoch3, step499]: loss 0.037163
[epoch3, step500]: loss 0.036645
[epoch3, step501]: loss 0.039350
[epoch3, step502]: loss 0.037301
[epoch3, step503]: loss 0.039864
[epoch3, step504]: loss 0.036936
[epoch3, step505]: loss 0.036767
[epoch3, step506]: loss 0.040343
[epoch3, step507]: loss 0.040349
[epoch3, step508]: loss 0.037700
[epoch3, step509]: loss 0.036762
[epoch3, step510]: loss 0.040112
[epoch3, step511]: loss 0.037429
[epoch3, step512]: loss 0.039876
[epoch3, step513]: loss 0.036993
[epoch3, step514]: loss 0.037371
[epoch3, step515]: loss 0.039913
[epoch3, step516]: loss 0.040109
[epoch3, step517]: loss 0.036794
[epoch3, step518]: loss 0.036995
[epoch3, step519]: loss 0.039845
[epoch3, step520]: loss 0.036715
[epoch3, step521]: loss 0.039245
[epoch3, step522]: loss 0.036398
[epoch3, step523]: loss 0.037013
[epoch3, step524]: loss 0.039670
[epoch3, step525]: loss 0.040336
[epoch3, step526]: loss 0.036895
[epoch3, step527]: loss 0.036951
[epoch3, step528]: loss 0.040060
[epoch3, step529]: loss 0.036952
[epoch3, step530]: loss 0.040710
[epoch3, step531]: loss 0.036796
[epoch3, step532]: loss 0.036883
[epoch3, step533]: loss 0.041294
[epoch3, step534]: loss 0.039693
[epoch3, step535]: loss 0.037349
[epoch3, step536]: loss 0.037127
[epoch3, step537]: loss 0.039749
[epoch3, step538]: loss 0.037154
[epoch3, step539]: loss 0.039402
[epoch3, step540]: loss 0.036403
[epoch3, step541]: loss 0.036527
[epoch3, step542]: loss 0.039899
[epoch3, step543]: loss 0.039409
[epoch3, step544]: loss 0.036751
[epoch3, step545]: loss 0.035989
[epoch3, step546]: loss 0.040558
[epoch3, step547]: loss 0.037140
[epoch3, step548]: loss 0.039363
[epoch3, step549]: loss 0.037398
[epoch3, step550]: loss 0.037280
[epoch3, step551]: loss 0.039719
[epoch3, step552]: loss 0.039279
[epoch3, step553]: loss 0.037083
[epoch3, step554]: loss 0.036858
[epoch3, step555]: loss 0.039497
[epoch3, step556]: loss 0.037119
[epoch3, step557]: loss 0.039211
[epoch3, step558]: loss 0.036996
[epoch3, step559]: loss 0.036544
[epoch3, step560]: loss 0.039851
[epoch3, step561]: loss 0.039601
[epoch3, step562]: loss 0.036640
[epoch3, step563]: loss 0.036500
[epoch3, step564]: loss 0.039234
[epoch3, step565]: loss 0.037928
[epoch3, step566]: loss 0.044841
[epoch3, step567]: loss 0.037557
[epoch3, step568]: loss 0.036244
[epoch3, step569]: loss 0.033050
[epoch3, step570]: loss 0.043032
[epoch3, step571]: loss 0.039726
[epoch3, step572]: loss 0.038030
[epoch3, step573]: loss 0.039830
[epoch3, step574]: loss 0.040655
[epoch3, step575]: loss 0.032594
[epoch3, step576]: loss 0.033414
[epoch3, step577]: loss 0.037313
[epoch3, step578]: loss 0.030205
[epoch3, step579]: loss 0.039256
[epoch3, step580]: loss 0.031156
[epoch3, step581]: loss 0.036401
[epoch3, step582]: loss 0.035770
[epoch3, step583]: loss 0.033785
[epoch3, step584]: loss 0.034354
[epoch3, step585]: loss 0.036915
[epoch3, step586]: loss 0.033494
[epoch3, step587]: loss 0.039621
[epoch3, step588]: loss 0.034743
[epoch3, step589]: loss 0.034519
[epoch3, step590]: loss 0.039229
[epoch3, step591]: loss 0.031879
[epoch3, step592]: loss 0.037457
[epoch3, step593]: loss 0.033880
[epoch3, step594]: loss 0.037059
[epoch3, step595]: loss 0.038532
[epoch3, step596]: loss 0.034867
[epoch3, step597]: loss 0.036207
[epoch3, step598]: loss 0.038087
[epoch3, step599]: loss 0.035905
[epoch3, step600]: loss 0.039018
[epoch3, step601]: loss 0.030485
[epoch3, step602]: loss 0.034144
[epoch3, step603]: loss 0.037828
[epoch3, step604]: loss 0.038881
[epoch3, step605]: loss 0.036454
[epoch3, step606]: loss 0.035457
[epoch3, step607]: loss 0.039397
[epoch3, step608]: loss 0.036985
[epoch3, step609]: loss 0.038272
[epoch3, step610]: loss 0.038156
[epoch3, step611]: loss 0.037691
[epoch3, step612]: loss 0.036693
[epoch3, step613]: loss 0.031292
[epoch3, step614]: loss 0.035815
[epoch3, step615]: loss 0.040848
[epoch3, step616]: loss 0.035154
[epoch3, step617]: loss 0.034574
[epoch3, step618]: loss 0.038219
[epoch3, step619]: loss 0.038819
[epoch3, step620]: loss 0.035889
[epoch3, step621]: loss 0.038000
[epoch3, step622]: loss 0.031980
[epoch3, step623]: loss 0.034854
[epoch3, step624]: loss 0.038587
[epoch3, step625]: loss 0.037097
[epoch3, step626]: loss 0.039896
[epoch3, step627]: loss 0.034208
[epoch3, step628]: loss 0.036802
[epoch3, step629]: loss 0.031181
[epoch3, step630]: loss 0.033633
[epoch3, step631]: loss 0.043254
[epoch3, step632]: loss 0.035488
[epoch3, step633]: loss 0.036510
[epoch3, step634]: loss 0.037714
[epoch3, step635]: loss 0.037377
[epoch3, step636]: loss 0.032713
[epoch3, step637]: loss 0.039050
[epoch3, step638]: loss 0.038991
[epoch3, step639]: loss 0.033132
[epoch3, step640]: loss 0.040676
[epoch3, step641]: loss 0.042029
[epoch3, step642]: loss 0.036977
[epoch3, step643]: loss 0.036853
[epoch3, step644]: loss 0.037364
[epoch3, step645]: loss 0.035026
[epoch3, step646]: loss 0.036912
[epoch3, step647]: loss 0.034593
[epoch3, step648]: loss 0.036208
[epoch3, step649]: loss 0.040382
[epoch3, step650]: loss 0.034168
[epoch3, step651]: loss 0.038563
[epoch3, step652]: loss 0.038505
[epoch3, step653]: loss 0.039101
[epoch3, step654]: loss 0.034186
[epoch3, step655]: loss 0.035534
[epoch3, step656]: loss 0.033849
[epoch3, step657]: loss 0.039426
[epoch3, step658]: loss 0.036641
[epoch3, step659]: loss 0.039204
[epoch3, step660]: loss 0.034054
[epoch3, step661]: loss 0.038331
[epoch3, step662]: loss 0.035075
[epoch3, step663]: loss 0.033095
[epoch3, step664]: loss 0.036791
[epoch3, step665]: loss 0.038922
[epoch3, step666]: loss 0.038131
[epoch3, step667]: loss 0.038893
[epoch3, step668]: loss 0.034407
[epoch3, step669]: loss 0.038242
[epoch3, step670]: loss 0.039518
[epoch3, step671]: loss 0.032412
[epoch3, step672]: loss 0.036526
[epoch3, step673]: loss 0.034416
[epoch3, step674]: loss 0.032200
[epoch3, step675]: loss 0.031365
[epoch3, step676]: loss 0.035547
[epoch3, step677]: loss 0.036452
[epoch3, step678]: loss 0.034225
[epoch3, step679]: loss 0.035434
[epoch3, step680]: loss 0.042631
[epoch3, step681]: loss 0.032732
[epoch3, step682]: loss 0.037548
[epoch3, step683]: loss 0.036913
[epoch3, step684]: loss 0.036417
[epoch3, step685]: loss 0.035778
[epoch3, step686]: loss 0.039216
[epoch3, step687]: loss 0.037708
[epoch3, step688]: loss 0.035507
[epoch3, step689]: loss 0.035584
[epoch3, step690]: loss 0.037347
[epoch3, step691]: loss 0.036255
[epoch3, step692]: loss 0.034540
[epoch3, step693]: loss 0.039695
[epoch3, step694]: loss 0.033645
[epoch3, step695]: loss 0.038807
[epoch3, step696]: loss 0.036447
[epoch3, step697]: loss 0.039154
[epoch3, step698]: loss 0.036057
[epoch3, step699]: loss 0.035004
[epoch3, step700]: loss 0.032814
[epoch3, step701]: loss 0.037592
[epoch3, step702]: loss 0.032559
[epoch3, step703]: loss 0.035121
[epoch3, step704]: loss 0.037945
[epoch3, step705]: loss 0.036470
[epoch3, step706]: loss 0.034893
[epoch3, step707]: loss 0.035108
[epoch3, step708]: loss 0.036831
[epoch3, step709]: loss 0.039126
[epoch3, step710]: loss 0.034609
[epoch3, step711]: loss 0.037559
[epoch3, step712]: loss 0.037892
[epoch3, step713]: loss 0.038229
[epoch3, step714]: loss 0.032937
[epoch3, step715]: loss 0.034284
[epoch3, step716]: loss 0.037194
[epoch3, step717]: loss 0.033951
[epoch3, step718]: loss 0.036582
[epoch3, step719]: loss 0.046071
[epoch3, step720]: loss 0.036232
[epoch3, step721]: loss 0.034548
[epoch3, step722]: loss 0.042931
[epoch3, step723]: loss 0.038705
[epoch3, step724]: loss 0.034144
[epoch3, step725]: loss 0.039367
[epoch3, step726]: loss 0.033238
[epoch3, step727]: loss 0.035420
[epoch3, step728]: loss 0.037942
[epoch3, step729]: loss 0.033109
[epoch3, step730]: loss 0.033926
[epoch3, step731]: loss 0.037566
[epoch3, step732]: loss 0.037306
[epoch3, step733]: loss 0.035215
[epoch3, step734]: loss 0.034604
[epoch3, step735]: loss 0.039406
[epoch3, step736]: loss 0.036351
[epoch3, step737]: loss 0.038184
[epoch3, step738]: loss 0.031378
[epoch3, step739]: loss 0.038136
[epoch3, step740]: loss 0.034504
[epoch3, step741]: loss 0.037555
[epoch3, step742]: loss 0.033933
[epoch3, step743]: loss 0.035306
[epoch3, step744]: loss 0.034903
[epoch3, step745]: loss 0.035388
[epoch3, step746]: loss 0.037524
[epoch3, step747]: loss 0.039869
[epoch3, step748]: loss 0.037374
[epoch3, step749]: loss 0.037615
[epoch3, step750]: loss 0.039248
[epoch3, step751]: loss 0.033948
[epoch3, step752]: loss 0.035951
[epoch3, step753]: loss 0.036239
[epoch3, step754]: loss 0.034994
[epoch3, step755]: loss 0.037791
[epoch3, step756]: loss 0.035176
[epoch3, step757]: loss 0.031444
[epoch3, step758]: loss 0.035333
[epoch3, step759]: loss 0.033914
[epoch3, step760]: loss 0.035093
[epoch3, step761]: loss 0.038056
[epoch3, step762]: loss 0.032670
[epoch3, step763]: loss 0.037340
[epoch3, step764]: loss 0.035755
[epoch3, step765]: loss 0.037894
[epoch3, step766]: loss 0.036768
[epoch3, step767]: loss 0.040838
[epoch3, step768]: loss 0.032220
[epoch3, step769]: loss 0.037644
[epoch3, step770]: loss 0.036930
[epoch3, step771]: loss 0.033957
[epoch3, step772]: loss 0.040364
[epoch3, step773]: loss 0.037384
[epoch3, step774]: loss 0.035931
[epoch3, step775]: loss 0.031538
[epoch3, step776]: loss 0.037664
[epoch3, step777]: loss 0.033903
[epoch3, step778]: loss 0.039065
[epoch3, step779]: loss 0.035957
[epoch3, step780]: loss 0.031169
[epoch3, step781]: loss 0.035894
[epoch3, step782]: loss 0.034009
[epoch3, step783]: loss 0.031390
[epoch3, step784]: loss 0.032127
[epoch3, step785]: loss 0.032569
[epoch3, step786]: loss 0.035509
[epoch3, step787]: loss 0.035154
[epoch3, step788]: loss 0.036758
[epoch3, step789]: loss 0.036114
[epoch3, step790]: loss 0.034561
[epoch3, step791]: loss 0.038980
[epoch3, step792]: loss 0.036613
[epoch3, step793]: loss 0.038800
[epoch3, step794]: loss 0.031730
[epoch3, step795]: loss 0.036691
[epoch3, step796]: loss 0.039694
[epoch3, step797]: loss 0.039068
[epoch3, step798]: loss 0.039028
[epoch3, step799]: loss 0.037632
[epoch3, step800]: loss 0.032922
[epoch3, step801]: loss 0.034566
[epoch3, step802]: loss 0.034093
[epoch3, step803]: loss 0.038138
[epoch3, step804]: loss 0.039360
[epoch3, step805]: loss 0.039558
[epoch3, step806]: loss 0.033273
[epoch3, step807]: loss 0.032058
[epoch3, step808]: loss 0.035056
[epoch3, step809]: loss 0.033382
[epoch3, step810]: loss 0.037113
[epoch3, step811]: loss 0.036455
[epoch3, step812]: loss 0.035783
[epoch3, step813]: loss 0.034771
[epoch3, step814]: loss 0.036779
[epoch3, step815]: loss 0.035233
[epoch3, step816]: loss 0.036503
[epoch3, step817]: loss 0.036391
[epoch3, step818]: loss 0.033345
[epoch3, step819]: loss 0.032546
[epoch3, step820]: loss 0.035005
[epoch3, step821]: loss 0.032297
[epoch3, step822]: loss 0.042036
[epoch3, step823]: loss 0.035275
[epoch3, step824]: loss 0.038225
[epoch3, step825]: loss 0.037300
[epoch3, step826]: loss 0.035278
[epoch3, step827]: loss 0.038280
[epoch3, step828]: loss 0.039989
[epoch3, step829]: loss 0.038928
[epoch3, step830]: loss 0.033832
[epoch3, step831]: loss 0.038156
[epoch3, step832]: loss 0.033028
[epoch3, step833]: loss 0.039855
[epoch3, step834]: loss 0.038045
[epoch3, step835]: loss 0.032069
[epoch3, step836]: loss 0.039626
[epoch3, step837]: loss 0.037210
[epoch3, step838]: loss 0.036714
[epoch3, step839]: loss 0.039862
[epoch3, step840]: loss 0.031681
[epoch3, step841]: loss 0.036139
[epoch3, step842]: loss 0.039186
[epoch3, step843]: loss 0.037013
[epoch3, step844]: loss 0.036627
[epoch3, step845]: loss 0.032848
[epoch3, step846]: loss 0.039543
[epoch3, step847]: loss 0.038327
[epoch3, step848]: loss 0.036406
[epoch3, step849]: loss 0.035609
[epoch3, step850]: loss 0.034440
[epoch3, step851]: loss 0.036146
[epoch3, step852]: loss 0.033889
[epoch3, step853]: loss 0.042007
[epoch3, step854]: loss 0.034407
[epoch3, step855]: loss 0.038482
[epoch3, step856]: loss 0.032560
[epoch3, step857]: loss 0.036333
[epoch3, step858]: loss 0.035717
[epoch3, step859]: loss 0.034813
[epoch3, step860]: loss 0.034213
[epoch3, step861]: loss 0.034109
[epoch3, step862]: loss 0.033677
[epoch3, step863]: loss 0.032295
[epoch3, step864]: loss 0.038331
[epoch3, step865]: loss 0.035510
[epoch3, step866]: loss 0.036321
[epoch3, step867]: loss 0.038082
[epoch3, step868]: loss 0.039225
[epoch3, step869]: loss 0.034985
[epoch3, step870]: loss 0.043116
[epoch3, step871]: loss 0.034618
[epoch3, step872]: loss 0.037448
[epoch3, step873]: loss 0.037276
[epoch3, step874]: loss 0.035316
[epoch3, step875]: loss 0.035485
[epoch3, step876]: loss 0.036399
[epoch3, step877]: loss 0.030585
[epoch3, step878]: loss 0.034314
[epoch3, step879]: loss 0.040252
[epoch3, step880]: loss 0.036757
[epoch3, step881]: loss 0.034057
[epoch3, step882]: loss 0.035298
[epoch3, step883]: loss 0.034965
[epoch3, step884]: loss 0.037864
[epoch3, step885]: loss 0.037759
[epoch3, step886]: loss 0.037794
[epoch3, step887]: loss 0.035889
[epoch3, step888]: loss 0.036521
[epoch3, step889]: loss 0.035643
[epoch3, step890]: loss 0.035896
[epoch3, step891]: loss 0.037616
[epoch3, step892]: loss 0.031294
[epoch3, step893]: loss 0.035980
[epoch3, step894]: loss 0.036361
[epoch3, step895]: loss 0.033242
[epoch3, step896]: loss 0.034062
[epoch3, step897]: loss 0.037003
[epoch3, step898]: loss 0.038319
[epoch3, step899]: loss 0.040367
[epoch3, step900]: loss 0.038207
[epoch3, step901]: loss 0.037738
[epoch3, step902]: loss 0.035151
[epoch3, step903]: loss 0.037175
[epoch3, step904]: loss 0.038949
[epoch3, step905]: loss 0.039158
[epoch3, step906]: loss 0.033430
[epoch3, step907]: loss 0.034837
[epoch3, step908]: loss 0.033858
[epoch3, step909]: loss 0.038214
[epoch3, step910]: loss 0.034506
[epoch3, step911]: loss 0.036703
[epoch3, step912]: loss 0.034667
[epoch3, step913]: loss 0.035928
[epoch3, step914]: loss 0.040924
[epoch3, step915]: loss 0.035114
[epoch3, step916]: loss 0.034375
[epoch3, step917]: loss 0.036356
[epoch3, step918]: loss 0.041136
[epoch3, step919]: loss 0.036150
[epoch3, step920]: loss 0.039299
[epoch3, step921]: loss 0.035502
[epoch3, step922]: loss 0.035106
[epoch3, step923]: loss 0.034884
[epoch3, step924]: loss 0.031826
[epoch3, step925]: loss 0.037088
[epoch3, step926]: loss 0.036927
[epoch3, step927]: loss 0.036993
[epoch3, step928]: loss 0.035847
[epoch3, step929]: loss 0.039473
[epoch3, step930]: loss 0.036927
[epoch3, step931]: loss 0.039158
[epoch3, step932]: loss 0.032581
[epoch3, step933]: loss 0.040951
[epoch3, step934]: loss 0.034634
[epoch3, step935]: loss 0.034517
[epoch3, step936]: loss 0.033826
[epoch3, step937]: loss 0.038516
[epoch3, step938]: loss 0.039165
[epoch3, step939]: loss 0.032539
[epoch3, step940]: loss 0.035027
[epoch3, step941]: loss 0.038560
[epoch3, step942]: loss 0.037647
[epoch3, step943]: loss 0.035460
[epoch3, step944]: loss 0.039228
[epoch3, step945]: loss 0.031504
[epoch3, step946]: loss 0.037073
[epoch3, step947]: loss 0.040035
[epoch3, step948]: loss 0.031817
[epoch3, step949]: loss 0.034612
[epoch3, step950]: loss 0.038259
[epoch3, step951]: loss 0.040806
[epoch3, step952]: loss 0.036157
[epoch3, step953]: loss 0.038968
[epoch3, step954]: loss 0.034382
[epoch3, step955]: loss 0.042715
[epoch3, step956]: loss 0.052339
[epoch3, step957]: loss 0.049037
[epoch3, step958]: loss 0.047622
[epoch3, step959]: loss 0.050364
[epoch3, step960]: loss 0.048283
[epoch3, step961]: loss 0.049126
[epoch3, step962]: loss 0.048458
[epoch3, step963]: loss 0.047390
[epoch3, step964]: loss 0.048026
[epoch3, step965]: loss 0.048895
[epoch3, step966]: loss 0.047502
[epoch3, step967]: loss 0.046802
[epoch3, step968]: loss 0.048274
[epoch3, step969]: loss 0.047954
[epoch3, step970]: loss 0.048195
[epoch3, step971]: loss 0.047604
[epoch3, step972]: loss 0.047440
[epoch3, step973]: loss 0.047430
[epoch3, step974]: loss 0.049193
[epoch3, step975]: loss 0.047557
[epoch3, step976]: loss 0.046858
[epoch3, step977]: loss 0.048708
[epoch3, step978]: loss 0.047815
[epoch3, step979]: loss 0.047933
[epoch3, step980]: loss 0.047301
[epoch3, step981]: loss 0.047281
[epoch3, step982]: loss 0.047598
[epoch3, step983]: loss 0.048891
[epoch3, step984]: loss 0.047060
[epoch3, step985]: loss 0.046770
[epoch3, step986]: loss 0.048779
[epoch3, step987]: loss 0.047794
[epoch3, step988]: loss 0.048244
[epoch3, step989]: loss 0.047760
[epoch3, step990]: loss 0.047099
[epoch3, step991]: loss 0.047742
[epoch3, step992]: loss 0.048803
[epoch3, step993]: loss 0.047253
[epoch3, step994]: loss 0.046418
[epoch3, step995]: loss 0.048659
[epoch3, step996]: loss 0.047424
[epoch3, step997]: loss 0.048152
[epoch3, step998]: loss 0.047780
[epoch3, step999]: loss 0.047329
[epoch3, step1000]: loss 0.047429
[epoch3, step1001]: loss 0.048958
[epoch3, step1002]: loss 0.047410
[epoch3, step1003]: loss 0.046643
[epoch3, step1004]: loss 0.048588
[epoch3, step1005]: loss 0.047202
[epoch3, step1006]: loss 0.047784
[epoch3, step1007]: loss 0.047212
[epoch3, step1008]: loss 0.047093
[epoch3, step1009]: loss 0.047471
[epoch3, step1010]: loss 0.049196
[epoch3, step1011]: loss 0.047122
[epoch3, step1012]: loss 0.046776
[epoch3, step1013]: loss 0.048445
[epoch3, step1014]: loss 0.047825
[epoch3, step1015]: loss 0.048159
[epoch3, step1016]: loss 0.047312
[epoch3, step1017]: loss 0.047036
[epoch3, step1018]: loss 0.047496
[epoch3, step1019]: loss 0.048994
[epoch3, step1020]: loss 0.047023
[epoch3, step1021]: loss 0.046516
[epoch3, step1022]: loss 0.048259
[epoch3, step1023]: loss 0.047455
[epoch3, step1024]: loss 0.048296
[epoch3, step1025]: loss 0.047048
[epoch3, step1026]: loss 0.046888
[epoch3, step1027]: loss 0.047322
[epoch3, step1028]: loss 0.048897
[epoch3, step1029]: loss 0.047185
[epoch3, step1030]: loss 0.046300
[epoch3, step1031]: loss 0.047863
[epoch3, step1032]: loss 0.047490
[epoch3, step1033]: loss 0.047943
[epoch3, step1034]: loss 0.047211
[epoch3, step1035]: loss 0.046904
[epoch3, step1036]: loss 0.047444
[epoch3, step1037]: loss 0.048720
[epoch3, step1038]: loss 0.047021
[epoch3, step1039]: loss 0.046651
[epoch3, step1040]: loss 0.048154
[epoch3, step1041]: loss 0.047326
[epoch3, step1042]: loss 0.047563
[epoch3, step1043]: loss 0.047104
[epoch3, step1044]: loss 0.047035
[epoch3, step1045]: loss 0.047460
[epoch3, step1046]: loss 0.048973
[epoch3, step1047]: loss 0.047303
[epoch3, step1048]: loss 0.046484
[epoch3, step1049]: loss 0.048497
[epoch3, step1050]: loss 0.047646
[epoch3, step1051]: loss 0.047940
[epoch3, step1052]: loss 0.047600
[epoch3, step1053]: loss 0.047397
[epoch3, step1054]: loss 0.047436
[epoch3, step1055]: loss 0.048712
[epoch3, step1056]: loss 0.046914
[epoch3, step1057]: loss 0.046825
[epoch3, step1058]: loss 0.048675
[epoch3, step1059]: loss 0.047752
[epoch3, step1060]: loss 0.048030
[epoch3, step1061]: loss 0.046864
[epoch3, step1062]: loss 0.047261
[epoch3, step1063]: loss 0.047385
[epoch3, step1064]: loss 0.048818
[epoch3, step1065]: loss 0.047173
[epoch3, step1066]: loss 0.046477
[epoch3, step1067]: loss 0.048396
[epoch3, step1068]: loss 0.046846
[epoch3, step1069]: loss 0.047678
[epoch3, step1070]: loss 0.047307
[epoch3, step1071]: loss 0.047184
[epoch3, step1072]: loss 0.047610
[epoch3, step1073]: loss 0.048656
[epoch3, step1074]: loss 0.046984
[epoch3, step1075]: loss 0.046745
[epoch3, step1076]: loss 0.048465
[epoch3, step1077]: loss 0.047505
[epoch3, step1078]: loss 0.047891
[epoch3, step1079]: loss 0.047736
[epoch3, step1080]: loss 0.047175
[epoch3, step1081]: loss 0.047294
[epoch3, step1082]: loss 0.048815
[epoch3, step1083]: loss 0.047478
[epoch3, step1084]: loss 0.046802
[epoch3, step1085]: loss 0.048148
[epoch3, step1086]: loss 0.047389
[epoch3, step1087]: loss 0.047953
[epoch3, step1088]: loss 0.047205
[epoch3, step1089]: loss 0.047091
[epoch3, step1090]: loss 0.047510
[epoch3, step1091]: loss 0.049103
[epoch3, step1092]: loss 0.047208
[epoch3, step1093]: loss 0.046407
[epoch3, step1094]: loss 0.047818
[epoch3, step1095]: loss 0.047209
[epoch3, step1096]: loss 0.047747
[epoch3, step1097]: loss 0.047170
[epoch3, step1098]: loss 0.047131
[epoch3, step1099]: loss 0.047313
[epoch3, step1100]: loss 0.049166
[epoch3, step1101]: loss 0.047439
[epoch3, step1102]: loss 0.046463
[epoch3, step1103]: loss 0.048135
[epoch3, step1104]: loss 0.047346
[epoch3, step1105]: loss 0.047910
[epoch3, step1106]: loss 0.046892
[epoch3, step1107]: loss 0.047176
[epoch3, step1108]: loss 0.047317
[epoch3, step1109]: loss 0.049048
[epoch3, step1110]: loss 0.047411
[epoch3, step1111]: loss 0.046699
[epoch3, step1112]: loss 0.048476
[epoch3, step1113]: loss 0.047242
[epoch3, step1114]: loss 0.048056
[epoch3, step1115]: loss 0.047271
[epoch3, step1116]: loss 0.047191
[epoch3, step1117]: loss 0.047293
[epoch3, step1118]: loss 0.048762
[epoch3, step1119]: loss 0.047015
[epoch3, step1120]: loss 0.046322
[epoch3, step1121]: loss 0.048284
[epoch3, step1122]: loss 0.047044
[epoch3, step1123]: loss 0.047650
[epoch3, step1124]: loss 0.047523
[epoch3, step1125]: loss 0.047213
[epoch3, step1126]: loss 0.047866
[epoch3, step1127]: loss 0.048772
[epoch3, step1128]: loss 0.047358
[epoch3, step1129]: loss 0.046448
[epoch3, step1130]: loss 0.048549
[epoch3, step1131]: loss 0.047459
[epoch3, step1132]: loss 0.047956
[epoch3, step1133]: loss 0.046931
[epoch3, step1134]: loss 0.046809
[epoch3, step1135]: loss 0.047818
[epoch3, step1136]: loss 0.049106
[epoch3, step1137]: loss 0.047155
[epoch3, step1138]: loss 0.046571
[epoch3, step1139]: loss 0.048420
[epoch3, step1140]: loss 0.047132
[epoch3, step1141]: loss 0.047801
[epoch3, step1142]: loss 0.047128
[epoch3, step1143]: loss 0.046984
[epoch3, step1144]: loss 0.047620
[epoch3, step1145]: loss 0.048676
[epoch3, step1146]: loss 0.046929
[epoch3, step1147]: loss 0.046989
[epoch3, step1148]: loss 0.048483
[epoch3, step1149]: loss 0.047393
[epoch3, step1150]: loss 0.047677
[epoch3, step1151]: loss 0.047444
[epoch3, step1152]: loss 0.047371
[epoch3, step1153]: loss 0.047123
[epoch3, step1154]: loss 0.048919
[epoch3, step1155]: loss 0.047120
[epoch3, step1156]: loss 0.046253
[epoch3, step1157]: loss 0.048338
[epoch3, step1158]: loss 0.047555
[epoch3, step1159]: loss 0.047843
[epoch3, step1160]: loss 0.047524
[epoch3, step1161]: loss 0.047272
[epoch3, step1162]: loss 0.047385
[epoch3, step1163]: loss 0.048502
[epoch3, step1164]: loss 0.047111
[epoch3, step1165]: loss 0.047062
[epoch3, step1166]: loss 0.048457
[epoch3, step1167]: loss 0.047072
[epoch3, step1168]: loss 0.047923
[epoch3, step1169]: loss 0.047241
[epoch3, step1170]: loss 0.047114
[epoch3, step1171]: loss 0.047307
[epoch3, step1172]: loss 0.048783
[epoch3, step1173]: loss 0.047263
[epoch3, step1174]: loss 0.046829
[epoch3, step1175]: loss 0.048286
[epoch3, step1176]: loss 0.047277
[epoch3, step1177]: loss 0.048071
[epoch3, step1178]: loss 0.047274
[epoch3, step1179]: loss 0.046975
[epoch3, step1180]: loss 0.047317
[epoch3, step1181]: loss 0.049089
[epoch3, step1182]: loss 0.046934
[epoch3, step1183]: loss 0.046775
[epoch3, step1184]: loss 0.047930
[epoch3, step1185]: loss 0.047552
[epoch3, step1186]: loss 0.047551
[epoch3, step1187]: loss 0.046937
[epoch3, step1188]: loss 0.046830
[epoch3, step1189]: loss 0.047173
[epoch3, step1190]: loss 0.048559
[epoch3, step1191]: loss 0.047444
[epoch3, step1192]: loss 0.046524
[epoch3, step1193]: loss 0.048365
[epoch3, step1194]: loss 0.047302
[epoch3, step1195]: loss 0.047388
[epoch3, step1196]: loss 0.046872
[epoch3, step1197]: loss 0.047247
[epoch3, step1198]: loss 0.047393
[epoch3, step1199]: loss 0.048644
[epoch3, step1200]: loss 0.046970
[epoch3, step1201]: loss 0.046736
[epoch3, step1202]: loss 0.048695
[epoch3, step1203]: loss 0.047419
[epoch3, step1204]: loss 0.047612
[epoch3, step1205]: loss 0.047081
[epoch3, step1206]: loss 0.046861
[epoch3, step1207]: loss 0.047417
[epoch3, step1208]: loss 0.049007
[epoch3, step1209]: loss 0.046612
[epoch3, step1210]: loss 0.046902
[epoch3, step1211]: loss 0.048086
[epoch3, step1212]: loss 0.047313
[epoch3, step1213]: loss 0.047552
[epoch3, step1214]: loss 0.047331
[epoch3, step1215]: loss 0.047392
[epoch3, step1216]: loss 0.047163
[epoch3, step1217]: loss 0.048919
[epoch3, step1218]: loss 0.046924
[epoch3, step1219]: loss 0.046687
[epoch3, step1220]: loss 0.048449
[epoch3, step1221]: loss 0.046931
[epoch3, step1222]: loss 0.047957
[epoch3, step1223]: loss 0.047297
[epoch3, step1224]: loss 0.047146
[epoch3, step1225]: loss 0.047445
[epoch3, step1226]: loss 0.048619
[epoch3, step1227]: loss 0.047177
[epoch3, step1228]: loss 0.046275
[epoch3, step1229]: loss 0.048289
[epoch3, step1230]: loss 0.047506
[epoch3, step1231]: loss 0.047663
[epoch3, step1232]: loss 0.047653
[epoch3, step1233]: loss 0.046992
[epoch3, step1234]: loss 0.047191
[epoch3, step1235]: loss 0.048980
[epoch3, step1236]: loss 0.047328
[epoch3, step1237]: loss 0.046480
[epoch3, step1238]: loss 0.048113
[epoch3, step1239]: loss 0.047557
[epoch3, step1240]: loss 0.047908
[epoch3, step1241]: loss 0.047262
[epoch3, step1242]: loss 0.047151
[epoch3, step1243]: loss 0.047303
[epoch3, step1244]: loss 0.048946
[epoch3, step1245]: loss 0.047392
[epoch3, step1246]: loss 0.046736
[epoch3, step1247]: loss 0.048023
[epoch3, step1248]: loss 0.047425
[epoch3, step1249]: loss 0.048101
[epoch3, step1250]: loss 0.047309
[epoch3, step1251]: loss 0.047123
[epoch3, step1252]: loss 0.047816
[epoch3, step1253]: loss 0.048785
[epoch3, step1254]: loss 0.047190
[epoch3, step1255]: loss 0.046511
[epoch3, step1256]: loss 0.048460
[epoch3, step1257]: loss 0.047388
[epoch3, step1258]: loss 0.048008
[epoch3, step1259]: loss 0.047261
[epoch3, step1260]: loss 0.047250
[epoch3, step1261]: loss 0.047248
[epoch3, step1262]: loss 0.048281
[epoch3, step1263]: loss 0.047405
[epoch3, step1264]: loss 0.046489
[epoch3, step1265]: loss 0.048002
[epoch3, step1266]: loss 0.047307
[epoch3, step1267]: loss 0.047926
[epoch3, step1268]: loss 0.047186
[epoch3, step1269]: loss 0.047044
[epoch3, step1270]: loss 0.047105
[epoch3, step1271]: loss 0.049058
[epoch3, step1272]: loss 0.047270
[epoch3, step1273]: loss 0.046383
[epoch3, step1274]: loss 0.048403
[epoch3, step1275]: loss 0.047673
[epoch3, step1276]: loss 0.047797
[epoch3, step1277]: loss 0.047329
[epoch3, step1278]: loss 0.047316
[epoch3, step1279]: loss 0.047528
[epoch3, step1280]: loss 0.048940
[epoch3, step1281]: loss 0.047157
[epoch3, step1282]: loss 0.046375
[epoch3, step1283]: loss 0.047963
[epoch3, step1284]: loss 0.047183
[epoch3, step1285]: loss 0.048041
[epoch3, step1286]: loss 0.046831
[epoch3, step1287]: loss 0.047397
[epoch3, step1288]: loss 0.047640
[epoch3, step1289]: loss 0.049236
[epoch3, step1290]: loss 0.047195
[epoch3, step1291]: loss 0.046365
[epoch3, step1292]: loss 0.048575
[epoch3, step1293]: loss 0.047016
[epoch3, step1294]: loss 0.047734
[epoch3, step1295]: loss 0.047327
[epoch3, step1296]: loss 0.047150
[epoch3, step1297]: loss 0.047283
[epoch3, step1298]: loss 0.049050
[epoch3, step1299]: loss 0.047169
[epoch3, step1300]: loss 0.046968
[epoch3, step1301]: loss 0.047941
[epoch3, step1302]: loss 0.047542
[epoch3, step1303]: loss 0.047903
[epoch3, step1304]: loss 0.047157
[epoch3, step1305]: loss 0.047140
[epoch3, step1306]: loss 0.047240
[epoch3, step1307]: loss 0.048634
[epoch3, step1308]: loss 0.047312
[epoch3, step1309]: loss 0.046260
[epoch3, step1310]: loss 0.048337
[epoch3, step1311]: loss 0.046873
[epoch3, step1312]: loss 0.048009
[epoch3, step1313]: loss 0.047218
[epoch3, step1314]: loss 0.047055
[epoch3, step1315]: loss 0.047164
[epoch3, step1316]: loss 0.049402
[epoch3, step1317]: loss 0.046859
[epoch3, step1318]: loss 0.046258
[epoch3, step1319]: loss 0.048068
[epoch3, step1320]: loss 0.047340
[epoch3, step1321]: loss 0.047953
[epoch3, step1322]: loss 0.047208
[epoch3, step1323]: loss 0.047243
[epoch3, step1324]: loss 0.047189
[epoch3, step1325]: loss 0.048663
[epoch3, step1326]: loss 0.047072
[epoch3, step1327]: loss 0.046552
[epoch3, step1328]: loss 0.048371
[epoch3, step1329]: loss 0.047384
[epoch3, step1330]: loss 0.047885
[epoch3, step1331]: loss 0.047055
[epoch3, step1332]: loss 0.047097
[epoch3, step1333]: loss 0.046918
[epoch3, step1334]: loss 0.049058
[epoch3, step1335]: loss 0.047337
[epoch3, step1336]: loss 0.046319
[epoch3, step1337]: loss 0.047892
[epoch3, step1338]: loss 0.047139
[epoch3, step1339]: loss 0.047817
[epoch3, step1340]: loss 0.047132
[epoch3, step1341]: loss 0.047163
[epoch3, step1342]: loss 0.047207
[epoch3, step1343]: loss 0.049013
[epoch3, step1344]: loss 0.047302
[epoch3, step1345]: loss 0.046607
[epoch3, step1346]: loss 0.048122
[epoch3, step1347]: loss 0.047554
[epoch3, step1348]: loss 0.047772
[epoch3, step1349]: loss 0.047304
[epoch3, step1350]: loss 0.046971
[epoch3, step1351]: loss 0.047134
[epoch3, step1352]: loss 0.048663
[epoch3, step1353]: loss 0.047092
[epoch3, step1354]: loss 0.046391
[epoch3, step1355]: loss 0.048301
[epoch3, step1356]: loss 0.047048
[epoch3, step1357]: loss 0.047570
[epoch3, step1358]: loss 0.047138
[epoch3, step1359]: loss 0.047035
[epoch3, step1360]: loss 0.047378
[epoch3, step1361]: loss 0.048966
[epoch3, step1362]: loss 0.047371
[epoch3, step1363]: loss 0.046637
[epoch3, step1364]: loss 0.048067
[epoch3, step1365]: loss 0.047350
[epoch3, step1366]: loss 0.047706
[epoch3, step1367]: loss 0.046977
[epoch3, step1368]: loss 0.047473
[epoch3, step1369]: loss 0.047425
[epoch3, step1370]: loss 0.048687
[epoch3, step1371]: loss 0.047184
[epoch3, step1372]: loss 0.046381
[epoch3, step1373]: loss 0.048427
[epoch3, step1374]: loss 0.047578
[epoch3, step1375]: loss 0.048193
[epoch3, step1376]: loss 0.047068
[epoch3, step1377]: loss 0.046867
[epoch3, step1378]: loss 0.047438
[epoch3, step1379]: loss 0.048762
[epoch3, step1380]: loss 0.047160
[epoch3, step1381]: loss 0.046504
[epoch3, step1382]: loss 0.048448
[epoch3, step1383]: loss 0.047304
[epoch3, step1384]: loss 0.047823
[epoch3, step1385]: loss 0.046865
[epoch3, step1386]: loss 0.047134
[epoch3, step1387]: loss 0.047443
[epoch3, step1388]: loss 0.048539
[epoch3, step1389]: loss 0.046684
[epoch3, step1390]: loss 0.046485
[epoch3, step1391]: loss 0.048268
[epoch3, step1392]: loss 0.047333
[epoch3, step1393]: loss 0.047880
[epoch3, step1394]: loss 0.047649
[epoch3, step1395]: loss 0.047198
[epoch3, step1396]: loss 0.047169
[epoch3, step1397]: loss 0.048824
[epoch3, step1398]: loss 0.047177
[epoch3, step1399]: loss 0.046855
[epoch3, step1400]: loss 0.048538
[epoch3, step1401]: loss 0.047254
[epoch3, step1402]: loss 0.047756
[epoch3, step1403]: loss 0.046775
[epoch3, step1404]: loss 0.046995
[epoch3, step1405]: loss 0.047229
[epoch3, step1406]: loss 0.048561
[epoch3, step1407]: loss 0.047667
[epoch3, step1408]: loss 0.046306
[epoch3, step1409]: loss 0.048037
[epoch3, step1410]: loss 0.047284
[epoch3, step1411]: loss 0.047295
[epoch3, step1412]: loss 0.047142
[epoch3, step1413]: loss 0.047097
[epoch3, step1414]: loss 0.047113
[epoch3, step1415]: loss 0.048703
[epoch3, step1416]: loss 0.046956
[epoch3, step1417]: loss 0.046459
[epoch3, step1418]: loss 0.048188
[epoch3, step1419]: loss 0.047655
[epoch3, step1420]: loss 0.047829
[epoch3, step1421]: loss 0.047434
[epoch3, step1422]: loss 0.047201
[epoch3, step1423]: loss 0.047042
[epoch3, step1424]: loss 0.048854
[epoch3, step1425]: loss 0.046672
[epoch3, step1426]: loss 0.046594
[epoch3, step1427]: loss 0.048614
[epoch3, step1428]: loss 0.047572
[epoch3, step1429]: loss 0.047858
[epoch3, step1430]: loss 0.047229
[epoch3, step1431]: loss 0.047370
[epoch3, step1432]: loss 0.047233
[epoch3, step1433]: loss 0.048905
[epoch3, step1434]: loss 0.046802
[epoch3, step1435]: loss 0.046664
[epoch3, step1436]: loss 0.048504
[epoch3, step1437]: loss 0.047459
[epoch3, step1438]: loss 0.047854
[epoch3, step1439]: loss 0.047208
[epoch3, step1440]: loss 0.046929
[epoch3, step1441]: loss 0.047702
[epoch3, step1442]: loss 0.048439
[epoch3, step1443]: loss 0.047035
[epoch3, step1444]: loss 0.046261
[epoch3, step1445]: loss 0.048320
[epoch3, step1446]: loss 0.047310
[epoch3, step1447]: loss 0.048100
[epoch3, step1448]: loss 0.047109
[epoch3, step1449]: loss 0.046841
[epoch3, step1450]: loss 0.047307
[epoch3, step1451]: loss 0.048959
[epoch3, step1452]: loss 0.047012
[epoch3, step1453]: loss 0.046909
[epoch3, step1454]: loss 0.048403
[epoch3, step1455]: loss 0.047719
[epoch3, step1456]: loss 0.047641
[epoch3, step1457]: loss 0.047375
[epoch3, step1458]: loss 0.047220
[epoch3, step1459]: loss 0.047179
[epoch3, step1460]: loss 0.049086
[epoch3, step1461]: loss 0.047431
[epoch3, step1462]: loss 0.046737
[epoch3, step1463]: loss 0.048244
[epoch3, step1464]: loss 0.047547
[epoch3, step1465]: loss 0.047688
[epoch3, step1466]: loss 0.047087
[epoch3, step1467]: loss 0.047096
[epoch3, step1468]: loss 0.046998
[epoch3, step1469]: loss 0.048851
[epoch3, step1470]: loss 0.047259
[epoch3, step1471]: loss 0.046297
[epoch3, step1472]: loss 0.048207
[epoch3, step1473]: loss 0.047275
[epoch3, step1474]: loss 0.048135
[epoch3, step1475]: loss 0.047104
[epoch3, step1476]: loss 0.047318
[epoch3, step1477]: loss 0.047358
[epoch3, step1478]: loss 0.048848
[epoch3, step1479]: loss 0.047059
[epoch3, step1480]: loss 0.046473
[epoch3, step1481]: loss 0.047997
[epoch3, step1482]: loss 0.047312
[epoch3, step1483]: loss 0.047771
[epoch3, step1484]: loss 0.047430
[epoch3, step1485]: loss 0.046882
[epoch3, step1486]: loss 0.046911
[epoch3, step1487]: loss 0.048850
[epoch3, step1488]: loss 0.047081
[epoch3, step1489]: loss 0.046648
[epoch3, step1490]: loss 0.048181
[epoch3, step1491]: loss 0.047461
[epoch3, step1492]: loss 0.047585
[epoch3, step1493]: loss 0.047431
[epoch3, step1494]: loss 0.047247
[epoch3, step1495]: loss 0.047178
[epoch3, step1496]: loss 0.048496
[epoch3, step1497]: loss 0.047219
[epoch3, step1498]: loss 0.046626
[epoch3, step1499]: loss 0.048026
[epoch3, step1500]: loss 0.047391
[epoch3, step1501]: loss 0.047792
[epoch3, step1502]: loss 0.047167
[epoch3, step1503]: loss 0.047036
[epoch3, step1504]: loss 0.046961
[epoch3, step1505]: loss 0.048959
[epoch3, step1506]: loss 0.046645
[epoch3, step1507]: loss 0.046612
[epoch3, step1508]: loss 0.048478
[epoch3, step1509]: loss 0.047214
[epoch3, step1510]: loss 0.047518
[epoch3, step1511]: loss 0.047532
[epoch3, step1512]: loss 0.047165
[epoch3, step1513]: loss 0.046727
[epoch3, step1514]: loss 0.048706
[epoch3, step1515]: loss 0.047152
[epoch3, step1516]: loss 0.046417

[epoch3]: avg loss 0.041617

[epoch4, step1]: loss 0.040238
[epoch4, step2]: loss 0.043319
[epoch4, step3]: loss 0.043357
[epoch4, step4]: loss 0.041124
[epoch4, step5]: loss 0.041402
[epoch4, step6]: loss 0.043053
[epoch4, step7]: loss 0.040911
[epoch4, step8]: loss 0.043964
[epoch4, step9]: loss 0.040687
[epoch4, step10]: loss 0.040583
[epoch4, step11]: loss 0.043130
[epoch4, step12]: loss 0.043277
[epoch4, step13]: loss 0.040813
[epoch4, step14]: loss 0.040996
[epoch4, step15]: loss 0.042990
[epoch4, step16]: loss 0.040501
[epoch4, step17]: loss 0.044386
[epoch4, step18]: loss 0.041663
[epoch4, step19]: loss 0.040312
[epoch4, step20]: loss 0.043844
[epoch4, step21]: loss 0.043262
[epoch4, step22]: loss 0.040349
[epoch4, step23]: loss 0.039987
[epoch4, step24]: loss 0.042833
[epoch4, step25]: loss 0.039819
[epoch4, step26]: loss 0.043138
[epoch4, step27]: loss 0.040332
[epoch4, step28]: loss 0.040054
[epoch4, step29]: loss 0.042925
[epoch4, step30]: loss 0.043532
[epoch4, step31]: loss 0.040005
[epoch4, step32]: loss 0.040891
[epoch4, step33]: loss 0.043192
[epoch4, step34]: loss 0.040746
[epoch4, step35]: loss 0.043785
[epoch4, step36]: loss 0.040504
[epoch4, step37]: loss 0.039920
[epoch4, step38]: loss 0.042499
[epoch4, step39]: loss 0.042750
[epoch4, step40]: loss 0.040617
[epoch4, step41]: loss 0.039944
[epoch4, step42]: loss 0.042758
[epoch4, step43]: loss 0.039987
[epoch4, step44]: loss 0.043601
[epoch4, step45]: loss 0.040492
[epoch4, step46]: loss 0.039928
[epoch4, step47]: loss 0.042259
[epoch4, step48]: loss 0.042447
[epoch4, step49]: loss 0.038807
[epoch4, step50]: loss 0.040427
[epoch4, step51]: loss 0.042188
[epoch4, step52]: loss 0.039819
[epoch4, step53]: loss 0.043817
[epoch4, step54]: loss 0.040149
[epoch4, step55]: loss 0.040043
[epoch4, step56]: loss 0.043298
[epoch4, step57]: loss 0.043057
[epoch4, step58]: loss 0.040108
[epoch4, step59]: loss 0.039386
[epoch4, step60]: loss 0.042696
[epoch4, step61]: loss 0.039225
[epoch4, step62]: loss 0.042646
[epoch4, step63]: loss 0.039615
[epoch4, step64]: loss 0.039201
[epoch4, step65]: loss 0.042541
[epoch4, step66]: loss 0.042523
[epoch4, step67]: loss 0.040101
[epoch4, step68]: loss 0.040090
[epoch4, step69]: loss 0.042144
[epoch4, step70]: loss 0.039604
[epoch4, step71]: loss 0.042606
[epoch4, step72]: loss 0.040095
[epoch4, step73]: loss 0.039295
[epoch4, step74]: loss 0.042388
[epoch4, step75]: loss 0.042521
[epoch4, step76]: loss 0.040344
[epoch4, step77]: loss 0.040450
[epoch4, step78]: loss 0.042223
[epoch4, step79]: loss 0.039167
[epoch4, step80]: loss 0.043517
[epoch4, step81]: loss 0.040007
[epoch4, step82]: loss 0.039095
[epoch4, step83]: loss 0.041477
[epoch4, step84]: loss 0.042509
[epoch4, step85]: loss 0.040234
[epoch4, step86]: loss 0.039895
[epoch4, step87]: loss 0.042917
[epoch4, step88]: loss 0.038558
[epoch4, step89]: loss 0.042334
[epoch4, step90]: loss 0.040202
[epoch4, step91]: loss 0.038794
[epoch4, step92]: loss 0.042188
[epoch4, step93]: loss 0.042152
[epoch4, step94]: loss 0.039445
[epoch4, step95]: loss 0.040051
[epoch4, step96]: loss 0.041646
[epoch4, step97]: loss 0.039974
[epoch4, step98]: loss 0.042520
[epoch4, step99]: loss 0.039780
[epoch4, step100]: loss 0.038288
[epoch4, step101]: loss 0.042431
[epoch4, step102]: loss 0.042032
[epoch4, step103]: loss 0.039357
[epoch4, step104]: loss 0.039583
[epoch4, step105]: loss 0.041879
[epoch4, step106]: loss 0.039227
[epoch4, step107]: loss 0.042267
[epoch4, step108]: loss 0.039763
[epoch4, step109]: loss 0.038655
[epoch4, step110]: loss 0.042376
[epoch4, step111]: loss 0.041725
[epoch4, step112]: loss 0.039439
[epoch4, step113]: loss 0.040060
[epoch4, step114]: loss 0.041474
[epoch4, step115]: loss 0.039173
[epoch4, step116]: loss 0.042782
[epoch4, step117]: loss 0.039389
[epoch4, step118]: loss 0.039319
[epoch4, step119]: loss 0.042067
[epoch4, step120]: loss 0.041866
[epoch4, step121]: loss 0.038860
[epoch4, step122]: loss 0.039094
[epoch4, step123]: loss 0.041813
[epoch4, step124]: loss 0.039224
[epoch4, step125]: loss 0.042370
[epoch4, step126]: loss 0.039124
[epoch4, step127]: loss 0.038552
[epoch4, step128]: loss 0.041442
[epoch4, step129]: loss 0.041192
[epoch4, step130]: loss 0.038998
[epoch4, step131]: loss 0.038418
[epoch4, step132]: loss 0.041450
[epoch4, step133]: loss 0.038604
[epoch4, step134]: loss 0.041246
[epoch4, step135]: loss 0.039415
[epoch4, step136]: loss 0.039374
[epoch4, step137]: loss 0.041039
[epoch4, step138]: loss 0.041258
[epoch4, step139]: loss 0.038438
[epoch4, step140]: loss 0.039121
[epoch4, step141]: loss 0.041271
[epoch4, step142]: loss 0.038505
[epoch4, step143]: loss 0.041057
[epoch4, step144]: loss 0.038935
[epoch4, step145]: loss 0.038342
[epoch4, step146]: loss 0.041215
[epoch4, step147]: loss 0.042325
[epoch4, step148]: loss 0.038153
[epoch4, step149]: loss 0.038026
[epoch4, step150]: loss 0.040516
[epoch4, step151]: loss 0.038498
[epoch4, step152]: loss 0.041135
[epoch4, step153]: loss 0.038570
[epoch4, step154]: loss 0.037656
[epoch4, step155]: loss 0.040893
[epoch4, step156]: loss 0.040554
[epoch4, step157]: loss 0.038167
[epoch4, step158]: loss 0.038402
[epoch4, step159]: loss 0.040919
[epoch4, step160]: loss 0.038473
[epoch4, step161]: loss 0.041317
[epoch4, step162]: loss 0.038283
[epoch4, step163]: loss 0.037738
[epoch4, step164]: loss 0.040937
[epoch4, step165]: loss 0.040693
[epoch4, step166]: loss 0.038007
[epoch4, step167]: loss 0.037542
[epoch4, step168]: loss 0.040950
[epoch4, step169]: loss 0.037736
[epoch4, step170]: loss 0.040808
[epoch4, step171]: loss 0.038089
[epoch4, step172]: loss 0.037835
[epoch4, step173]: loss 0.040794
[epoch4, step174]: loss 0.040327
[epoch4, step175]: loss 0.038149
[epoch4, step176]: loss 0.038065
[epoch4, step177]: loss 0.040601
[epoch4, step178]: loss 0.038010
[epoch4, step179]: loss 0.039613
[epoch4, step180]: loss 0.037946
[epoch4, step181]: loss 0.037858
[epoch4, step182]: loss 0.040626
[epoch4, step183]: loss 0.041046
[epoch4, step184]: loss 0.038281
[epoch4, step185]: loss 0.037851
[epoch4, step186]: loss 0.040368
[epoch4, step187]: loss 0.037815
[epoch4, step188]: loss 0.040065
[epoch4, step189]: loss 0.037372
[epoch4, step190]: loss 0.036971
[epoch4, step191]: loss 0.039942
[epoch4, step192]: loss 0.040619
[epoch4, step193]: loss 0.035708
[epoch4, step194]: loss 0.036549
[epoch4, step195]: loss 0.040463
[epoch4, step196]: loss 0.037801
[epoch4, step197]: loss 0.040102
[epoch4, step198]: loss 0.036555
[epoch4, step199]: loss 0.037602
[epoch4, step200]: loss 0.040935
[epoch4, step201]: loss 0.040939
[epoch4, step202]: loss 0.036949
[epoch4, step203]: loss 0.037631
[epoch4, step204]: loss 0.040714
[epoch4, step205]: loss 0.037187
[epoch4, step206]: loss 0.039989
[epoch4, step207]: loss 0.037190
[epoch4, step208]: loss 0.038011
[epoch4, step209]: loss 0.040423
[epoch4, step210]: loss 0.041169
[epoch4, step211]: loss 0.037823
[epoch4, step212]: loss 0.037871
[epoch4, step213]: loss 0.039975
[epoch4, step214]: loss 0.036939
[epoch4, step215]: loss 0.040513
[epoch4, step216]: loss 0.037332
[epoch4, step217]: loss 0.036530
[epoch4, step218]: loss 0.040479
[epoch4, step219]: loss 0.039916
[epoch4, step220]: loss 0.037481
[epoch4, step221]: loss 0.037572
[epoch4, step222]: loss 0.040229
[epoch4, step223]: loss 0.037643
[epoch4, step224]: loss 0.039764
[epoch4, step225]: loss 0.036988
[epoch4, step226]: loss 0.037171
[epoch4, step227]: loss 0.039009
[epoch4, step228]: loss 0.040452
[epoch4, step229]: loss 0.036196
[epoch4, step230]: loss 0.037552
[epoch4, step231]: loss 0.040311
[epoch4, step232]: loss 0.036908
[epoch4, step233]: loss 0.039156
[epoch4, step234]: loss 0.036664
[epoch4, step235]: loss 0.037445
[epoch4, step236]: loss 0.039959
[epoch4, step237]: loss 0.039998
[epoch4, step238]: loss 0.036665
[epoch4, step239]: loss 0.036507
[epoch4, step240]: loss 0.039272
[epoch4, step241]: loss 0.037856
[epoch4, step242]: loss 0.039691
[epoch4, step243]: loss 0.037728
[epoch4, step244]: loss 0.037122
[epoch4, step245]: loss 0.039445
[epoch4, step246]: loss 0.039899
[epoch4, step247]: loss 0.037201
[epoch4, step248]: loss 0.036807
[epoch4, step249]: loss 0.039284
[epoch4, step250]: loss 0.037417
[epoch4, step251]: loss 0.040325
[epoch4, step252]: loss 0.037406
[epoch4, step253]: loss 0.036719
[epoch4, step254]: loss 0.039194
[epoch4, step255]: loss 0.039922
[epoch4, step256]: loss 0.036690
[epoch4, step257]: loss 0.036782
[epoch4, step258]: loss 0.040442
[epoch4, step259]: loss 0.037302
[epoch4, step260]: loss 0.039345
[epoch4, step261]: loss 0.037654
[epoch4, step262]: loss 0.037516
[epoch4, step263]: loss 0.039077
[epoch4, step264]: loss 0.039554
[epoch4, step265]: loss 0.037133
[epoch4, step266]: loss 0.037017
[epoch4, step267]: loss 0.039141
[epoch4, step268]: loss 0.037270
[epoch4, step269]: loss 0.040011
[epoch4, step270]: loss 0.036411
[epoch4, step271]: loss 0.037182
[epoch4, step272]: loss 0.039700
[epoch4, step273]: loss 0.039571
[epoch4, step274]: loss 0.037298
[epoch4, step275]: loss 0.036541
[epoch4, step276]: loss 0.039416
[epoch4, step277]: loss 0.037833
[epoch4, step278]: loss 0.039978
[epoch4, step279]: loss 0.036446
[epoch4, step280]: loss 0.037032
[epoch4, step281]: loss 0.039526
[epoch4, step282]: loss 0.040185
[epoch4, step283]: loss 0.036510
[epoch4, step284]: loss 0.036509
[epoch4, step285]: loss 0.040447
[epoch4, step286]: loss 0.036561
[epoch4, step287]: loss 0.040041
[epoch4, step288]: loss 0.036412
[epoch4, step289]: loss 0.037912
[epoch4, step290]: loss 0.039717
[epoch4, step291]: loss 0.040063
[epoch4, step292]: loss 0.035949
[epoch4, step293]: loss 0.036598
[epoch4, step294]: loss 0.038992
[epoch4, step295]: loss 0.036517
[epoch4, step296]: loss 0.040346
[epoch4, step297]: loss 0.036472
[epoch4, step298]: loss 0.037378
[epoch4, step299]: loss 0.038762
[epoch4, step300]: loss 0.039978
[epoch4, step301]: loss 0.036675
[epoch4, step302]: loss 0.037281
[epoch4, step303]: loss 0.039950
[epoch4, step304]: loss 0.036854
[epoch4, step305]: loss 0.039316
[epoch4, step306]: loss 0.036932
[epoch4, step307]: loss 0.036733
[epoch4, step308]: loss 0.040130
[epoch4, step309]: loss 0.040017
[epoch4, step310]: loss 0.036860
[epoch4, step311]: loss 0.037286
[epoch4, step312]: loss 0.039332
[epoch4, step313]: loss 0.037322
[epoch4, step314]: loss 0.039540
[epoch4, step315]: loss 0.037666
[epoch4, step316]: loss 0.036744
[epoch4, step317]: loss 0.039871
[epoch4, step318]: loss 0.039704
[epoch4, step319]: loss 0.036240
[epoch4, step320]: loss 0.035932
[epoch4, step321]: loss 0.039118
[epoch4, step322]: loss 0.037054
[epoch4, step323]: loss 0.038941
[epoch4, step324]: loss 0.037562
[epoch4, step325]: loss 0.037289
[epoch4, step326]: loss 0.039340
[epoch4, step327]: loss 0.039098
[epoch4, step328]: loss 0.036866
[epoch4, step329]: loss 0.036603
[epoch4, step330]: loss 0.039171
[epoch4, step331]: loss 0.037228
[epoch4, step332]: loss 0.038943
[epoch4, step333]: loss 0.036613
[epoch4, step334]: loss 0.036910
[epoch4, step335]: loss 0.039698
[epoch4, step336]: loss 0.040463
[epoch4, step337]: loss 0.036933
[epoch4, step338]: loss 0.036367
[epoch4, step339]: loss 0.039355
[epoch4, step340]: loss 0.037587
[epoch4, step341]: loss 0.038974
[epoch4, step342]: loss 0.036475
[epoch4, step343]: loss 0.037231
[epoch4, step344]: loss 0.039085
[epoch4, step345]: loss 0.038979
[epoch4, step346]: loss 0.036163
[epoch4, step347]: loss 0.036479
[epoch4, step348]: loss 0.039690
[epoch4, step349]: loss 0.037451
[epoch4, step350]: loss 0.038982
[epoch4, step351]: loss 0.035938
[epoch4, step352]: loss 0.036788
[epoch4, step353]: loss 0.039412
[epoch4, step354]: loss 0.038633
[epoch4, step355]: loss 0.035507
[epoch4, step356]: loss 0.037442
[epoch4, step357]: loss 0.039473
[epoch4, step358]: loss 0.035636
[epoch4, step359]: loss 0.040311
[epoch4, step360]: loss 0.035494
[epoch4, step361]: loss 0.036436
[epoch4, step362]: loss 0.040072
[epoch4, step363]: loss 0.039332
[epoch4, step364]: loss 0.036491
[epoch4, step365]: loss 0.036496
[epoch4, step366]: loss 0.039884
[epoch4, step367]: loss 0.036929
[epoch4, step368]: loss 0.038809
[epoch4, step369]: loss 0.036387
[epoch4, step370]: loss 0.037415
[epoch4, step371]: loss 0.040248
[epoch4, step372]: loss 0.039129
[epoch4, step373]: loss 0.035966
[epoch4, step374]: loss 0.035997
[epoch4, step375]: loss 0.039939
[epoch4, step376]: loss 0.037038
[epoch4, step377]: loss 0.039576
[epoch4, step378]: loss 0.037037
[epoch4, step379]: loss 0.037537
[epoch4, step380]: loss 0.040064
[epoch4, step381]: loss 0.039225
[epoch4, step382]: loss 0.036809
[epoch4, step383]: loss 0.035737
[epoch4, step384]: loss 0.038759
[epoch4, step385]: loss 0.036748
[epoch4, step386]: loss 0.039557
[epoch4, step387]: loss 0.036576
[epoch4, step388]: loss 0.037707
[epoch4, step389]: loss 0.039411
[epoch4, step390]: loss 0.040366
[epoch4, step391]: loss 0.036180
[epoch4, step392]: loss 0.037297
[epoch4, step393]: loss 0.038839
[epoch4, step394]: loss 0.037032
[epoch4, step395]: loss 0.039117
[epoch4, step396]: loss 0.036662
[epoch4, step397]: loss 0.036590
[epoch4, step398]: loss 0.039589
[epoch4, step399]: loss 0.039465
[epoch4, step400]: loss 0.036207
[epoch4, step401]: loss 0.036479
[epoch4, step402]: loss 0.039254
[epoch4, step403]: loss 0.036774
[epoch4, step404]: loss 0.039699
[epoch4, step405]: loss 0.036811
[epoch4, step406]: loss 0.037104
[epoch4, step407]: loss 0.039234
[epoch4, step408]: loss 0.039572
[epoch4, step409]: loss 0.037704
[epoch4, step410]: loss 0.037309
[epoch4, step411]: loss 0.039192
[epoch4, step412]: loss 0.036487
[epoch4, step413]: loss 0.039337
[epoch4, step414]: loss 0.036234
[epoch4, step415]: loss 0.037250
[epoch4, step416]: loss 0.038755
[epoch4, step417]: loss 0.039726
[epoch4, step418]: loss 0.036330
[epoch4, step419]: loss 0.035863
[epoch4, step420]: loss 0.039641
[epoch4, step421]: loss 0.036558
[epoch4, step422]: loss 0.039272
[epoch4, step423]: loss 0.036636
[epoch4, step424]: loss 0.037004
[epoch4, step425]: loss 0.039564
[epoch4, step426]: loss 0.039866
[epoch4, step427]: loss 0.036804
[epoch4, step428]: loss 0.036538
[epoch4, step429]: loss 0.040043
[epoch4, step430]: loss 0.036882
[epoch4, step431]: loss 0.039755
[epoch4, step432]: loss 0.036437
[epoch4, step433]: loss 0.037709
[epoch4, step434]: loss 0.039295
[epoch4, step435]: loss 0.039897
[epoch4, step436]: loss 0.036182
[epoch4, step437]: loss 0.036814
[epoch4, step438]: loss 0.039950
[epoch4, step439]: loss 0.037149
[epoch4, step440]: loss 0.039288
[epoch4, step441]: loss 0.036872
[epoch4, step442]: loss 0.036812
[epoch4, step443]: loss 0.039932
[epoch4, step444]: loss 0.039230
[epoch4, step445]: loss 0.036875
[epoch4, step446]: loss 0.037101
[epoch4, step447]: loss 0.040111
[epoch4, step448]: loss 0.037066
[epoch4, step449]: loss 0.039193
[epoch4, step450]: loss 0.035820
[epoch4, step451]: loss 0.036735
[epoch4, step452]: loss 0.038281
[epoch4, step453]: loss 0.039680
[epoch4, step454]: loss 0.036424
[epoch4, step455]: loss 0.036810
[epoch4, step456]: loss 0.038598
[epoch4, step457]: loss 0.037482
[epoch4, step458]: loss 0.039033
[epoch4, step459]: loss 0.037181
[epoch4, step460]: loss 0.037064
[epoch4, step461]: loss 0.040123
[epoch4, step462]: loss 0.038841
[epoch4, step463]: loss 0.036567
[epoch4, step464]: loss 0.036550
[epoch4, step465]: loss 0.040714
[epoch4, step466]: loss 0.036842
[epoch4, step467]: loss 0.039101
[epoch4, step468]: loss 0.036466
[epoch4, step469]: loss 0.037057
[epoch4, step470]: loss 0.039624
[epoch4, step471]: loss 0.038987
[epoch4, step472]: loss 0.036878
[epoch4, step473]: loss 0.036179
[epoch4, step474]: loss 0.039185
[epoch4, step475]: loss 0.037003
[epoch4, step476]: loss 0.039711
[epoch4, step477]: loss 0.036369
[epoch4, step478]: loss 0.036355
[epoch4, step479]: loss 0.039242
[epoch4, step480]: loss 0.038607
[epoch4, step481]: loss 0.035930
[epoch4, step482]: loss 0.036095
[epoch4, step483]: loss 0.039832
[epoch4, step484]: loss 0.037096
[epoch4, step485]: loss 0.039502
[epoch4, step486]: loss 0.036831
[epoch4, step487]: loss 0.036495
[epoch4, step488]: loss 0.039992
[epoch4, step489]: loss 0.038714
[epoch4, step490]: loss 0.036823
[epoch4, step491]: loss 0.036813
[epoch4, step492]: loss 0.039083
[epoch4, step493]: loss 0.036610
[epoch4, step494]: loss 0.038700
[epoch4, step495]: loss 0.037648
[epoch4, step496]: loss 0.036986
[epoch4, step497]: loss 0.039829
[epoch4, step498]: loss 0.039537
[epoch4, step499]: loss 0.036766
[epoch4, step500]: loss 0.036133
[epoch4, step501]: loss 0.038836
[epoch4, step502]: loss 0.036793
[epoch4, step503]: loss 0.039544
[epoch4, step504]: loss 0.036363
[epoch4, step505]: loss 0.036052
[epoch4, step506]: loss 0.039839
[epoch4, step507]: loss 0.039948
[epoch4, step508]: loss 0.036937
[epoch4, step509]: loss 0.036528
[epoch4, step510]: loss 0.039556
[epoch4, step511]: loss 0.037227
[epoch4, step512]: loss 0.039717
[epoch4, step513]: loss 0.036776
[epoch4, step514]: loss 0.037202
[epoch4, step515]: loss 0.039382
[epoch4, step516]: loss 0.039856
[epoch4, step517]: loss 0.036537
[epoch4, step518]: loss 0.036719
[epoch4, step519]: loss 0.039461
[epoch4, step520]: loss 0.036304
[epoch4, step521]: loss 0.038970
[epoch4, step522]: loss 0.036052
[epoch4, step523]: loss 0.036985
[epoch4, step524]: loss 0.038697
[epoch4, step525]: loss 0.039784
[epoch4, step526]: loss 0.036522
[epoch4, step527]: loss 0.036223
[epoch4, step528]: loss 0.039688
[epoch4, step529]: loss 0.036399
[epoch4, step530]: loss 0.039671
[epoch4, step531]: loss 0.036275
[epoch4, step532]: loss 0.036491
[epoch4, step533]: loss 0.040396
[epoch4, step534]: loss 0.039380
[epoch4, step535]: loss 0.036910
[epoch4, step536]: loss 0.036723
[epoch4, step537]: loss 0.039378
[epoch4, step538]: loss 0.036904
[epoch4, step539]: loss 0.039072
[epoch4, step540]: loss 0.036079
[epoch4, step541]: loss 0.036381
[epoch4, step542]: loss 0.039350
[epoch4, step543]: loss 0.039139
[epoch4, step544]: loss 0.036375
[epoch4, step545]: loss 0.035794
[epoch4, step546]: loss 0.039905
[epoch4, step547]: loss 0.036624
[epoch4, step548]: loss 0.039203
[epoch4, step549]: loss 0.036744
[epoch4, step550]: loss 0.036844
[epoch4, step551]: loss 0.039190
[epoch4, step552]: loss 0.038788
[epoch4, step553]: loss 0.036819
[epoch4, step554]: loss 0.036403
[epoch4, step555]: loss 0.038961
[epoch4, step556]: loss 0.036639
[epoch4, step557]: loss 0.038723
[epoch4, step558]: loss 0.036734
[epoch4, step559]: loss 0.036267
[epoch4, step560]: loss 0.039428
[epoch4, step561]: loss 0.039247
[epoch4, step562]: loss 0.036438
[epoch4, step563]: loss 0.036598
[epoch4, step564]: loss 0.039595
[epoch4, step565]: loss 0.038366
[epoch4, step566]: loss 0.044838
[epoch4, step567]: loss 0.037898
[epoch4, step568]: loss 0.036540
[epoch4, step569]: loss 0.033901
[epoch4, step570]: loss 0.042371
[epoch4, step571]: loss 0.038737
[epoch4, step572]: loss 0.038417
[epoch4, step573]: loss 0.040493
[epoch4, step574]: loss 0.041664
[epoch4, step575]: loss 0.032825
[epoch4, step576]: loss 0.034126
[epoch4, step577]: loss 0.037077
[epoch4, step578]: loss 0.029858
[epoch4, step579]: loss 0.041327
[epoch4, step580]: loss 0.030960
[epoch4, step581]: loss 0.036937
[epoch4, step582]: loss 0.035490
[epoch4, step583]: loss 0.034007
[epoch4, step584]: loss 0.035157
[epoch4, step585]: loss 0.037717
[epoch4, step586]: loss 0.034038
[epoch4, step587]: loss 0.039937
[epoch4, step588]: loss 0.034829
[epoch4, step589]: loss 0.035041
[epoch4, step590]: loss 0.040405
[epoch4, step591]: loss 0.032012
[epoch4, step592]: loss 0.038012
[epoch4, step593]: loss 0.034039
[epoch4, step594]: loss 0.037841
[epoch4, step595]: loss 0.038980
[epoch4, step596]: loss 0.034524
[epoch4, step597]: loss 0.036057
[epoch4, step598]: loss 0.039119
[epoch4, step599]: loss 0.035894
[epoch4, step600]: loss 0.038971
[epoch4, step601]: loss 0.030473
[epoch4, step602]: loss 0.034286
[epoch4, step603]: loss 0.039175
[epoch4, step604]: loss 0.039218
[epoch4, step605]: loss 0.036762
[epoch4, step606]: loss 0.036012
[epoch4, step607]: loss 0.039601
[epoch4, step608]: loss 0.037606
[epoch4, step609]: loss 0.038088
[epoch4, step610]: loss 0.038399
[epoch4, step611]: loss 0.037796
[epoch4, step612]: loss 0.036636
[epoch4, step613]: loss 0.031386
[epoch4, step614]: loss 0.035962
[epoch4, step615]: loss 0.040988
[epoch4, step616]: loss 0.035096
[epoch4, step617]: loss 0.034635
[epoch4, step618]: loss 0.038059
[epoch4, step619]: loss 0.038864
[epoch4, step620]: loss 0.035783
[epoch4, step621]: loss 0.038232
[epoch4, step622]: loss 0.031993
[epoch4, step623]: loss 0.034823
[epoch4, step624]: loss 0.038552
[epoch4, step625]: loss 0.037098
[epoch4, step626]: loss 0.039704
[epoch4, step627]: loss 0.034256
[epoch4, step628]: loss 0.036693
[epoch4, step629]: loss 0.031299
[epoch4, step630]: loss 0.033576
[epoch4, step631]: loss 0.043459
[epoch4, step632]: loss 0.035519
[epoch4, step633]: loss 0.036527
[epoch4, step634]: loss 0.037830
[epoch4, step635]: loss 0.037431
[epoch4, step636]: loss 0.032679
[epoch4, step637]: loss 0.039119
[epoch4, step638]: loss 0.038910
[epoch4, step639]: loss 0.033125
[epoch4, step640]: loss 0.040554
[epoch4, step641]: loss 0.041997
[epoch4, step642]: loss 0.036721
[epoch4, step643]: loss 0.036889
[epoch4, step644]: loss 0.037350
[epoch4, step645]: loss 0.035229
[epoch4, step646]: loss 0.037021
[epoch4, step647]: loss 0.034511
[epoch4, step648]: loss 0.035895
[epoch4, step649]: loss 0.040296
[epoch4, step650]: loss 0.033982
[epoch4, step651]: loss 0.038641
[epoch4, step652]: loss 0.038416
[epoch4, step653]: loss 0.039067
[epoch4, step654]: loss 0.034108
[epoch4, step655]: loss 0.035488
[epoch4, step656]: loss 0.033804
[epoch4, step657]: loss 0.039399
[epoch4, step658]: loss 0.036607
[epoch4, step659]: loss 0.039161
[epoch4, step660]: loss 0.033974
[epoch4, step661]: loss 0.038233
[epoch4, step662]: loss 0.035006
[epoch4, step663]: loss 0.033121
[epoch4, step664]: loss 0.036786
[epoch4, step665]: loss 0.038808
[epoch4, step666]: loss 0.038133
[epoch4, step667]: loss 0.038653
[epoch4, step668]: loss 0.034449
[epoch4, step669]: loss 0.038148
[epoch4, step670]: loss 0.039281
[epoch4, step671]: loss 0.032345
[epoch4, step672]: loss 0.036395
[epoch4, step673]: loss 0.034408
[epoch4, step674]: loss 0.032174
[epoch4, step675]: loss 0.031367
[epoch4, step676]: loss 0.035470
[epoch4, step677]: loss 0.036386
[epoch4, step678]: loss 0.034178
[epoch4, step679]: loss 0.035469
[epoch4, step680]: loss 0.042582
[epoch4, step681]: loss 0.032702
[epoch4, step682]: loss 0.037512
[epoch4, step683]: loss 0.036789
[epoch4, step684]: loss 0.036341
[epoch4, step685]: loss 0.035735
[epoch4, step686]: loss 0.039105
[epoch4, step687]: loss 0.037630
[epoch4, step688]: loss 0.035471
[epoch4, step689]: loss 0.035523
[epoch4, step690]: loss 0.037269
[epoch4, step691]: loss 0.036205
[epoch4, step692]: loss 0.034559
[epoch4, step693]: loss 0.039633
[epoch4, step694]: loss 0.033676
[epoch4, step695]: loss 0.038771
[epoch4, step696]: loss 0.036453
[epoch4, step697]: loss 0.039195
[epoch4, step698]: loss 0.036016
[epoch4, step699]: loss 0.034917
[epoch4, step700]: loss 0.032820
[epoch4, step701]: loss 0.037583
[epoch4, step702]: loss 0.032572
[epoch4, step703]: loss 0.035086
[epoch4, step704]: loss 0.037893
[epoch4, step705]: loss 0.036339
[epoch4, step706]: loss 0.034844
[epoch4, step707]: loss 0.035043
[epoch4, step708]: loss 0.036734
[epoch4, step709]: loss 0.039003
[epoch4, step710]: loss 0.034605
[epoch4, step711]: loss 0.037487
[epoch4, step712]: loss 0.037862
[epoch4, step713]: loss 0.038138
[epoch4, step714]: loss 0.032964
[epoch4, step715]: loss 0.034241
[epoch4, step716]: loss 0.037006
[epoch4, step717]: loss 0.033941
[epoch4, step718]: loss 0.036729
[epoch4, step719]: loss 0.046331
[epoch4, step720]: loss 0.036121
[epoch4, step721]: loss 0.034361
[epoch4, step722]: loss 0.042569
[epoch4, step723]: loss 0.038575
[epoch4, step724]: loss 0.034093
[epoch4, step725]: loss 0.039356
[epoch4, step726]: loss 0.033395
[epoch4, step727]: loss 0.035412
[epoch4, step728]: loss 0.038037
[epoch4, step729]: loss 0.033155
[epoch4, step730]: loss 0.033942
[epoch4, step731]: loss 0.037619
[epoch4, step732]: loss 0.037264
[epoch4, step733]: loss 0.035104
[epoch4, step734]: loss 0.034490
[epoch4, step735]: loss 0.039219
[epoch4, step736]: loss 0.036402
[epoch4, step737]: loss 0.038237
[epoch4, step738]: loss 0.031210
[epoch4, step739]: loss 0.038060
[epoch4, step740]: loss 0.034385
[epoch4, step741]: loss 0.037516
[epoch4, step742]: loss 0.033777
[epoch4, step743]: loss 0.035269
[epoch4, step744]: loss 0.034872
[epoch4, step745]: loss 0.035331
[epoch4, step746]: loss 0.037537
[epoch4, step747]: loss 0.039840
[epoch4, step748]: loss 0.037477
[epoch4, step749]: loss 0.037586
[epoch4, step750]: loss 0.039320
[epoch4, step751]: loss 0.033959
[epoch4, step752]: loss 0.035958
[epoch4, step753]: loss 0.036150
[epoch4, step754]: loss 0.034910
[epoch4, step755]: loss 0.037734
[epoch4, step756]: loss 0.035078
[epoch4, step757]: loss 0.031348
[epoch4, step758]: loss 0.035255
[epoch4, step759]: loss 0.033931
[epoch4, step760]: loss 0.035072
[epoch4, step761]: loss 0.037917
[epoch4, step762]: loss 0.032763
[epoch4, step763]: loss 0.037280
[epoch4, step764]: loss 0.035632
[epoch4, step765]: loss 0.037979
[epoch4, step766]: loss 0.036805
[epoch4, step767]: loss 0.040763
[epoch4, step768]: loss 0.032054
[epoch4, step769]: loss 0.037578
[epoch4, step770]: loss 0.036872
[epoch4, step771]: loss 0.033983
[epoch4, step772]: loss 0.040158
[epoch4, step773]: loss 0.037250
[epoch4, step774]: loss 0.035717
[epoch4, step775]: loss 0.031555
[epoch4, step776]: loss 0.037665
[epoch4, step777]: loss 0.033861
[epoch4, step778]: loss 0.039048
[epoch4, step779]: loss 0.035925
[epoch4, step780]: loss 0.030990
[epoch4, step781]: loss 0.035864
[epoch4, step782]: loss 0.033839
[epoch4, step783]: loss 0.031196
[epoch4, step784]: loss 0.032082
[epoch4, step785]: loss 0.032548
[epoch4, step786]: loss 0.035371
[epoch4, step787]: loss 0.035148
[epoch4, step788]: loss 0.036562
[epoch4, step789]: loss 0.036174
[epoch4, step790]: loss 0.034742
[epoch4, step791]: loss 0.038975
[epoch4, step792]: loss 0.036523
[epoch4, step793]: loss 0.038633
[epoch4, step794]: loss 0.031682
[epoch4, step795]: loss 0.036384
[epoch4, step796]: loss 0.039703
[epoch4, step797]: loss 0.038817
[epoch4, step798]: loss 0.038946
[epoch4, step799]: loss 0.037491
[epoch4, step800]: loss 0.032973
[epoch4, step801]: loss 0.034364
[epoch4, step802]: loss 0.034105
[epoch4, step803]: loss 0.037874
[epoch4, step804]: loss 0.039101
[epoch4, step805]: loss 0.039454
[epoch4, step806]: loss 0.033401
[epoch4, step807]: loss 0.032241
[epoch4, step808]: loss 0.035117
[epoch4, step809]: loss 0.033316
[epoch4, step810]: loss 0.037008
[epoch4, step811]: loss 0.036605
[epoch4, step812]: loss 0.035766
[epoch4, step813]: loss 0.034551
[epoch4, step814]: loss 0.036833
[epoch4, step815]: loss 0.035257
[epoch4, step816]: loss 0.036400
[epoch4, step817]: loss 0.036377
[epoch4, step818]: loss 0.033301
[epoch4, step819]: loss 0.032541
[epoch4, step820]: loss 0.034979
[epoch4, step821]: loss 0.032361
[epoch4, step822]: loss 0.041965
[epoch4, step823]: loss 0.035296
[epoch4, step824]: loss 0.038024
[epoch4, step825]: loss 0.037292
[epoch4, step826]: loss 0.035246
[epoch4, step827]: loss 0.038096
[epoch4, step828]: loss 0.039903
[epoch4, step829]: loss 0.038796
[epoch4, step830]: loss 0.033784
[epoch4, step831]: loss 0.038074
[epoch4, step832]: loss 0.032854
[epoch4, step833]: loss 0.039943
[epoch4, step834]: loss 0.037986
[epoch4, step835]: loss 0.032014
[epoch4, step836]: loss 0.039778
[epoch4, step837]: loss 0.037153
[epoch4, step838]: loss 0.036671
[epoch4, step839]: loss 0.040079
[epoch4, step840]: loss 0.031599
[epoch4, step841]: loss 0.035912
[epoch4, step842]: loss 0.039207
[epoch4, step843]: loss 0.037036
[epoch4, step844]: loss 0.036509
[epoch4, step845]: loss 0.032928
[epoch4, step846]: loss 0.039454
[epoch4, step847]: loss 0.038235
[epoch4, step848]: loss 0.036378
[epoch4, step849]: loss 0.035561
[epoch4, step850]: loss 0.034405
[epoch4, step851]: loss 0.036129
[epoch4, step852]: loss 0.033896
[epoch4, step853]: loss 0.041950
[epoch4, step854]: loss 0.034368
[epoch4, step855]: loss 0.038435
[epoch4, step856]: loss 0.032601
[epoch4, step857]: loss 0.036285
[epoch4, step858]: loss 0.035610
[epoch4, step859]: loss 0.034752
[epoch4, step860]: loss 0.034130
[epoch4, step861]: loss 0.034084
[epoch4, step862]: loss 0.033635
[epoch4, step863]: loss 0.032230
[epoch4, step864]: loss 0.038151
[epoch4, step865]: loss 0.035482
[epoch4, step866]: loss 0.036276
[epoch4, step867]: loss 0.037991
[epoch4, step868]: loss 0.039066
[epoch4, step869]: loss 0.034915
[epoch4, step870]: loss 0.042826
[epoch4, step871]: loss 0.034508
[epoch4, step872]: loss 0.037437
[epoch4, step873]: loss 0.037270
[epoch4, step874]: loss 0.035308
[epoch4, step875]: loss 0.035588
[epoch4, step876]: loss 0.036462
[epoch4, step877]: loss 0.030512
[epoch4, step878]: loss 0.034312
[epoch4, step879]: loss 0.040220
[epoch4, step880]: loss 0.036909
[epoch4, step881]: loss 0.034101
[epoch4, step882]: loss 0.035355
[epoch4, step883]: loss 0.035070
[epoch4, step884]: loss 0.037825
[epoch4, step885]: loss 0.037629
[epoch4, step886]: loss 0.037779
[epoch4, step887]: loss 0.035840
[epoch4, step888]: loss 0.036465
[epoch4, step889]: loss 0.035600
[epoch4, step890]: loss 0.035880
[epoch4, step891]: loss 0.037613
[epoch4, step892]: loss 0.031340
[epoch4, step893]: loss 0.036066
[epoch4, step894]: loss 0.036484
[epoch4, step895]: loss 0.033255
[epoch4, step896]: loss 0.034152
[epoch4, step897]: loss 0.036980
[epoch4, step898]: loss 0.038187
[epoch4, step899]: loss 0.040554
[epoch4, step900]: loss 0.038166
[epoch4, step901]: loss 0.037735
[epoch4, step902]: loss 0.035112
[epoch4, step903]: loss 0.037241
[epoch4, step904]: loss 0.038919
[epoch4, step905]: loss 0.039194
[epoch4, step906]: loss 0.033258
[epoch4, step907]: loss 0.034821
[epoch4, step908]: loss 0.033904
[epoch4, step909]: loss 0.038138
[epoch4, step910]: loss 0.034540
[epoch4, step911]: loss 0.036598
[epoch4, step912]: loss 0.034595
[epoch4, step913]: loss 0.035781
[epoch4, step914]: loss 0.040893
[epoch4, step915]: loss 0.035048
[epoch4, step916]: loss 0.034461
[epoch4, step917]: loss 0.036082
[epoch4, step918]: loss 0.040769
[epoch4, step919]: loss 0.036190
[epoch4, step920]: loss 0.039151
[epoch4, step921]: loss 0.035600
[epoch4, step922]: loss 0.035125
[epoch4, step923]: loss 0.034707
[epoch4, step924]: loss 0.031652
[epoch4, step925]: loss 0.036893
[epoch4, step926]: loss 0.036628
[epoch4, step927]: loss 0.037038
[epoch4, step928]: loss 0.035474
[epoch4, step929]: loss 0.039150
[epoch4, step930]: loss 0.036729
[epoch4, step931]: loss 0.038855
[epoch4, step932]: loss 0.032342
[epoch4, step933]: loss 0.040646
[epoch4, step934]: loss 0.034273
[epoch4, step935]: loss 0.034502
[epoch4, step936]: loss 0.033651
[epoch4, step937]: loss 0.038573
[epoch4, step938]: loss 0.039000
[epoch4, step939]: loss 0.032588
[epoch4, step940]: loss 0.035140
[epoch4, step941]: loss 0.038366
[epoch4, step942]: loss 0.037425
[epoch4, step943]: loss 0.035337
[epoch4, step944]: loss 0.039139
[epoch4, step945]: loss 0.031749
[epoch4, step946]: loss 0.037023
[epoch4, step947]: loss 0.039940
[epoch4, step948]: loss 0.032071
[epoch4, step949]: loss 0.034551
[epoch4, step950]: loss 0.038199
[epoch4, step951]: loss 0.040604
[epoch4, step952]: loss 0.036309
[epoch4, step953]: loss 0.039103
[epoch4, step954]: loss 0.034437
[epoch4, step955]: loss 0.042742
[epoch4, step956]: loss 0.052372
[epoch4, step957]: loss 0.049131
[epoch4, step958]: loss 0.047701
[epoch4, step959]: loss 0.050522
[epoch4, step960]: loss 0.048413
[epoch4, step961]: loss 0.049266
[epoch4, step962]: loss 0.048537
[epoch4, step963]: loss 0.047465
[epoch4, step964]: loss 0.048139
[epoch4, step965]: loss 0.049036
[epoch4, step966]: loss 0.047601
[epoch4, step967]: loss 0.046965
[epoch4, step968]: loss 0.048454
[epoch4, step969]: loss 0.048162
[epoch4, step970]: loss 0.048431
[epoch4, step971]: loss 0.047854
[epoch4, step972]: loss 0.047662
[epoch4, step973]: loss 0.047679
[epoch4, step974]: loss 0.049435
[epoch4, step975]: loss 0.047767
[epoch4, step976]: loss 0.047167
[epoch4, step977]: loss 0.048878
[epoch4, step978]: loss 0.048095
[epoch4, step979]: loss 0.048055
[epoch4, step980]: loss 0.047545
[epoch4, step981]: loss 0.047456
[epoch4, step982]: loss 0.047659
[epoch4, step983]: loss 0.049127
[epoch4, step984]: loss 0.047117
[epoch4, step985]: loss 0.046851
[epoch4, step986]: loss 0.048920
[epoch4, step987]: loss 0.047864
[epoch4, step988]: loss 0.048345
[epoch4, step989]: loss 0.047815
[epoch4, step990]: loss 0.047110
[epoch4, step991]: loss 0.047753
[epoch4, step992]: loss 0.048822
[epoch4, step993]: loss 0.047251
[epoch4, step994]: loss 0.046339
[epoch4, step995]: loss 0.048626
[epoch4, step996]: loss 0.047416
[epoch4, step997]: loss 0.048103
[epoch4, step998]: loss 0.047720
[epoch4, step999]: loss 0.047277
[epoch4, step1000]: loss 0.047344
[epoch4, step1001]: loss 0.048852
[epoch4, step1002]: loss 0.047341
[epoch4, step1003]: loss 0.046498
[epoch4, step1004]: loss 0.048472
[epoch4, step1005]: loss 0.047145
[epoch4, step1006]: loss 0.047687
[epoch4, step1007]: loss 0.047145
[epoch4, step1008]: loss 0.047025
[epoch4, step1009]: loss 0.047384
[epoch4, step1010]: loss 0.049083
[epoch4, step1011]: loss 0.047041
[epoch4, step1012]: loss 0.046675
[epoch4, step1013]: loss 0.048341
[epoch4, step1014]: loss 0.047754
[epoch4, step1015]: loss 0.048068
[epoch4, step1016]: loss 0.047228
[epoch4, step1017]: loss 0.046950
[epoch4, step1018]: loss 0.047388
[epoch4, step1019]: loss 0.048905
[epoch4, step1020]: loss 0.046926
[epoch4, step1021]: loss 0.046371
[epoch4, step1022]: loss 0.048163
[epoch4, step1023]: loss 0.047399
[epoch4, step1024]: loss 0.048200
[epoch4, step1025]: loss 0.047002
[epoch4, step1026]: loss 0.046810
[epoch4, step1027]: loss 0.047224
[epoch4, step1028]: loss 0.048832
[epoch4, step1029]: loss 0.047103
[epoch4, step1030]: loss 0.046201
[epoch4, step1031]: loss 0.047772
[epoch4, step1032]: loss 0.047432
[epoch4, step1033]: loss 0.047865
[epoch4, step1034]: loss 0.047149
[epoch4, step1035]: loss 0.046833
[epoch4, step1036]: loss 0.047342
[epoch4, step1037]: loss 0.048631
[epoch4, step1038]: loss 0.046946
[epoch4, step1039]: loss 0.046523
[epoch4, step1040]: loss 0.048055
[epoch4, step1041]: loss 0.047275
[epoch4, step1042]: loss 0.047476
[epoch4, step1043]: loss 0.047055
[epoch4, step1044]: loss 0.046960
[epoch4, step1045]: loss 0.047368
[epoch4, step1046]: loss 0.048887
[epoch4, step1047]: loss 0.047226
[epoch4, step1048]: loss 0.046377
[epoch4, step1049]: loss 0.048398
[epoch4, step1050]: loss 0.047597
[epoch4, step1051]: loss 0.047854
[epoch4, step1052]: loss 0.047550
[epoch4, step1053]: loss 0.047320
[epoch4, step1054]: loss 0.047342
[epoch4, step1055]: loss 0.048639
[epoch4, step1056]: loss 0.046839
[epoch4, step1057]: loss 0.046707
[epoch4, step1058]: loss 0.048578
[epoch4, step1059]: loss 0.047706
[epoch4, step1060]: loss 0.047936
[epoch4, step1061]: loss 0.046833
[epoch4, step1062]: loss 0.047190
[epoch4, step1063]: loss 0.047299
[epoch4, step1064]: loss 0.048754
[epoch4, step1065]: loss 0.047097
[epoch4, step1066]: loss 0.046379
[epoch4, step1067]: loss 0.048307
[epoch4, step1068]: loss 0.046802
[epoch4, step1069]: loss 0.047597
[epoch4, step1070]: loss 0.047264
[epoch4, step1071]: loss 0.047115
[epoch4, step1072]: loss 0.047522
[epoch4, step1073]: loss 0.048592
[epoch4, step1074]: loss 0.046911
[epoch4, step1075]: loss 0.046628
[epoch4, step1076]: loss 0.048377
[epoch4, step1077]: loss 0.047454
[epoch4, step1078]: loss 0.047802
[epoch4, step1079]: loss 0.047688
[epoch4, step1080]: loss 0.047103
[epoch4, step1081]: loss 0.047220
[epoch4, step1082]: loss 0.048746
[epoch4, step1083]: loss 0.047404
[epoch4, step1084]: loss 0.046713
[epoch4, step1085]: loss 0.048061
[epoch4, step1086]: loss 0.047348
[epoch4, step1087]: loss 0.047866
[epoch4, step1088]: loss 0.047169
[epoch4, step1089]: loss 0.047029
[epoch4, step1090]: loss 0.047430
[epoch4, step1091]: loss 0.049035
[epoch4, step1092]: loss 0.047138
[epoch4, step1093]: loss 0.046320
[epoch4, step1094]: loss 0.047737
[epoch4, step1095]: loss 0.047164
[epoch4, step1096]: loss 0.047664
[epoch4, step1097]: loss 0.047129
[epoch4, step1098]: loss 0.047065
[epoch4, step1099]: loss 0.047235
[epoch4, step1100]: loss 0.049103
[epoch4, step1101]: loss 0.047366
[epoch4, step1102]: loss 0.046370
[epoch4, step1103]: loss 0.048053
[epoch4, step1104]: loss 0.047297
[epoch4, step1105]: loss 0.047828
[epoch4, step1106]: loss 0.046850
[epoch4, step1107]: loss 0.047109
[epoch4, step1108]: loss 0.047240
[epoch4, step1109]: loss 0.048981
[epoch4, step1110]: loss 0.047339
[epoch4, step1111]: loss 0.046604
[epoch4, step1112]: loss 0.048388
[epoch4, step1113]: loss 0.047198
[epoch4, step1114]: loss 0.047969
[epoch4, step1115]: loss 0.047231
[epoch4, step1116]: loss 0.047126
[epoch4, step1117]: loss 0.047220
[epoch4, step1118]: loss 0.048695
[epoch4, step1119]: loss 0.046949
[epoch4, step1120]: loss 0.046247
[epoch4, step1121]: loss 0.048198
[epoch4, step1122]: loss 0.047005
[epoch4, step1123]: loss 0.047572
[epoch4, step1124]: loss 0.047483
[epoch4, step1125]: loss 0.047149
[epoch4, step1126]: loss 0.047783
[epoch4, step1127]: loss 0.048709
[epoch4, step1128]: loss 0.047287
[epoch4, step1129]: loss 0.046358
[epoch4, step1130]: loss 0.048462
[epoch4, step1131]: loss 0.047413
[epoch4, step1132]: loss 0.047872
[epoch4, step1133]: loss 0.046897
[epoch4, step1134]: loss 0.046747
[epoch4, step1135]: loss 0.047736
[epoch4, step1136]: loss 0.049038
[epoch4, step1137]: loss 0.047085
[epoch4, step1138]: loss 0.046486
[epoch4, step1139]: loss 0.048333
[epoch4, step1140]: loss 0.047094
[epoch4, step1141]: loss 0.047719
[epoch4, step1142]: loss 0.047098
[epoch4, step1143]: loss 0.046925
[epoch4, step1144]: loss 0.047537
[epoch4, step1145]: loss 0.048614
[epoch4, step1146]: loss 0.046861
[epoch4, step1147]: loss 0.046901
[epoch4, step1148]: loss 0.048396
[epoch4, step1149]: loss 0.047350
[epoch4, step1150]: loss 0.047596
[epoch4, step1151]: loss 0.047409
[epoch4, step1152]: loss 0.047308
[epoch4, step1153]: loss 0.047046
[epoch4, step1154]: loss 0.048854
[epoch4, step1155]: loss 0.047049
[epoch4, step1156]: loss 0.046179
[epoch4, step1157]: loss 0.048253
[epoch4, step1158]: loss 0.047511
[epoch4, step1159]: loss 0.047762
[epoch4, step1160]: loss 0.047488
[epoch4, step1161]: loss 0.047214
[epoch4, step1162]: loss 0.047305
[epoch4, step1163]: loss 0.048439
[epoch4, step1164]: loss 0.047039
[epoch4, step1165]: loss 0.046984
[epoch4, step1166]: loss 0.048371
[epoch4, step1167]: loss 0.047033
[epoch4, step1168]: loss 0.047837
[epoch4, step1169]: loss 0.047213
[epoch4, step1170]: loss 0.047063
[epoch4, step1171]: loss 0.047231
[epoch4, step1172]: loss 0.048723
[epoch4, step1173]: loss 0.047190
[epoch4, step1174]: loss 0.046766
[epoch4, step1175]: loss 0.048205
[epoch4, step1176]: loss 0.047232
[epoch4, step1177]: loss 0.047986
[epoch4, step1178]: loss 0.047239
[epoch4, step1179]: loss 0.046926
[epoch4, step1180]: loss 0.047244
[epoch4, step1181]: loss 0.049028
[epoch4, step1182]: loss 0.046862
[epoch4, step1183]: loss 0.046720
[epoch4, step1184]: loss 0.047852
[epoch4, step1185]: loss 0.047503
[epoch4, step1186]: loss 0.047468
[epoch4, step1187]: loss 0.046900
[epoch4, step1188]: loss 0.046779
[epoch4, step1189]: loss 0.047105
[epoch4, step1190]: loss 0.048502
[epoch4, step1191]: loss 0.047370
[epoch4, step1192]: loss 0.046479
[epoch4, step1193]: loss 0.048288
[epoch4, step1194]: loss 0.047250
[epoch4, step1195]: loss 0.047312
[epoch4, step1196]: loss 0.046826
[epoch4, step1197]: loss 0.047193
[epoch4, step1198]: loss 0.047324
[epoch4, step1199]: loss 0.048582
[epoch4, step1200]: loss 0.046899
[epoch4, step1201]: loss 0.046688
[epoch4, step1202]: loss 0.048614
[epoch4, step1203]: loss 0.047369
[epoch4, step1204]: loss 0.047533
[epoch4, step1205]: loss 0.047038
[epoch4, step1206]: loss 0.046809
[epoch4, step1207]: loss 0.047351
[epoch4, step1208]: loss 0.048941
[epoch4, step1209]: loss 0.046546
[epoch4, step1210]: loss 0.046868
[epoch4, step1211]: loss 0.048008
[epoch4, step1212]: loss 0.047269
[epoch4, step1213]: loss 0.047475
[epoch4, step1214]: loss 0.047291
[epoch4, step1215]: loss 0.047341
[epoch4, step1216]: loss 0.047096
[epoch4, step1217]: loss 0.048860
[epoch4, step1218]: loss 0.046853
[epoch4, step1219]: loss 0.046651
[epoch4, step1220]: loss 0.048371
[epoch4, step1221]: loss 0.046883
[epoch4, step1222]: loss 0.047880
[epoch4, step1223]: loss 0.047251
[epoch4, step1224]: loss 0.047095
[epoch4, step1225]: loss 0.047376
[epoch4, step1226]: loss 0.048559
[epoch4, step1227]: loss 0.047104
[epoch4, step1228]: loss 0.046236
[epoch4, step1229]: loss 0.048212
[epoch4, step1230]: loss 0.047455
[epoch4, step1231]: loss 0.047585
[epoch4, step1232]: loss 0.047605
[epoch4, step1233]: loss 0.046938
[epoch4, step1234]: loss 0.047128
[epoch4, step1235]: loss 0.048917
[epoch4, step1236]: loss 0.047256
[epoch4, step1237]: loss 0.046452
[epoch4, step1238]: loss 0.048036
[epoch4, step1239]: loss 0.047512
[epoch4, step1240]: loss 0.047831
[epoch4, step1241]: loss 0.047219
[epoch4, step1242]: loss 0.047103
[epoch4, step1243]: loss 0.047236
[epoch4, step1244]: loss 0.048885
[epoch4, step1245]: loss 0.047319
[epoch4, step1246]: loss 0.046702
[epoch4, step1247]: loss 0.047947
[epoch4, step1248]: loss 0.047378
[epoch4, step1249]: loss 0.048021
[epoch4, step1250]: loss 0.047265
[epoch4, step1251]: loss 0.047073
[epoch4, step1252]: loss 0.047749
[epoch4, step1253]: loss 0.048724
[epoch4, step1254]: loss 0.047118
[epoch4, step1255]: loss 0.046481
[epoch4, step1256]: loss 0.048381
[epoch4, step1257]: loss 0.047343
[epoch4, step1258]: loss 0.047929
[epoch4, step1259]: loss 0.047217
[epoch4, step1260]: loss 0.047201
[epoch4, step1261]: loss 0.047183
[epoch4, step1262]: loss 0.048225
[epoch4, step1263]: loss 0.047331
[epoch4, step1264]: loss 0.046460
[epoch4, step1265]: loss 0.047927
[epoch4, step1266]: loss 0.047258
[epoch4, step1267]: loss 0.047852
[epoch4, step1268]: loss 0.047135
[epoch4, step1269]: loss 0.046995
[epoch4, step1270]: loss 0.047038
[epoch4, step1271]: loss 0.048999
[epoch4, step1272]: loss 0.047197
[epoch4, step1273]: loss 0.046344
[epoch4, step1274]: loss 0.048328
[epoch4, step1275]: loss 0.047623
[epoch4, step1276]: loss 0.047721
[epoch4, step1277]: loss 0.047277
[epoch4, step1278]: loss 0.047263
[epoch4, step1279]: loss 0.047463
[epoch4, step1280]: loss 0.048872
[epoch4, step1281]: loss 0.047087
[epoch4, step1282]: loss 0.046345
[epoch4, step1283]: loss 0.047886
[epoch4, step1284]: loss 0.047143
[epoch4, step1285]: loss 0.047959
[epoch4, step1286]: loss 0.046791
[epoch4, step1287]: loss 0.047350
[epoch4, step1288]: loss 0.047573
[epoch4, step1289]: loss 0.049176
[epoch4, step1290]: loss 0.047124
[epoch4, step1291]: loss 0.046337
[epoch4, step1292]: loss 0.048498
[epoch4, step1293]: loss 0.046968
[epoch4, step1294]: loss 0.047660
[epoch4, step1295]: loss 0.047274
[epoch4, step1296]: loss 0.047100
[epoch4, step1297]: loss 0.047216
[epoch4, step1298]: loss 0.048990
[epoch4, step1299]: loss 0.047096
[epoch4, step1300]: loss 0.046929
[epoch4, step1301]: loss 0.047867
[epoch4, step1302]: loss 0.047494
[epoch4, step1303]: loss 0.047824
[epoch4, step1304]: loss 0.047107
[epoch4, step1305]: loss 0.047089
[epoch4, step1306]: loss 0.047176
[epoch4, step1307]: loss 0.048574
[epoch4, step1308]: loss 0.047238
[epoch4, step1309]: loss 0.046230
[epoch4, step1310]: loss 0.048260
[epoch4, step1311]: loss 0.046828
[epoch4, step1312]: loss 0.047933
[epoch4, step1313]: loss 0.047164
[epoch4, step1314]: loss 0.047008
[epoch4, step1315]: loss 0.047095
[epoch4, step1316]: loss 0.049338
[epoch4, step1317]: loss 0.046787
[epoch4, step1318]: loss 0.046215
[epoch4, step1319]: loss 0.047993
[epoch4, step1320]: loss 0.047287
[epoch4, step1321]: loss 0.047873
[epoch4, step1322]: loss 0.047152
[epoch4, step1323]: loss 0.047190
[epoch4, step1324]: loss 0.047125
[epoch4, step1325]: loss 0.048597
[epoch4, step1326]: loss 0.046999
[epoch4, step1327]: loss 0.046515
[epoch4, step1328]: loss 0.048291
[epoch4, step1329]: loss 0.047336
[epoch4, step1330]: loss 0.047804
[epoch4, step1331]: loss 0.047002
[epoch4, step1332]: loss 0.047048
[epoch4, step1333]: loss 0.046854
[epoch4, step1334]: loss 0.048992
[epoch4, step1335]: loss 0.047262
[epoch4, step1336]: loss 0.046284
[epoch4, step1337]: loss 0.047815
[epoch4, step1338]: loss 0.047091
[epoch4, step1339]: loss 0.047737
[epoch4, step1340]: loss 0.047076
[epoch4, step1341]: loss 0.047113
[epoch4, step1342]: loss 0.047137
[epoch4, step1343]: loss 0.048949
[epoch4, step1344]: loss 0.047224
[epoch4, step1345]: loss 0.046561
[epoch4, step1346]: loss 0.048043
[epoch4, step1347]: loss 0.047500
[epoch4, step1348]: loss 0.047688
[epoch4, step1349]: loss 0.047244
[epoch4, step1350]: loss 0.046917
[epoch4, step1351]: loss 0.047069
[epoch4, step1352]: loss 0.048593
[epoch4, step1353]: loss 0.047016
[epoch4, step1354]: loss 0.046355
[epoch4, step1355]: loss 0.048219
[epoch4, step1356]: loss 0.047002
[epoch4, step1357]: loss 0.047487
[epoch4, step1358]: loss 0.047081
[epoch4, step1359]: loss 0.046986
[epoch4, step1360]: loss 0.047306
[epoch4, step1361]: loss 0.048898
[epoch4, step1362]: loss 0.047290
[epoch4, step1363]: loss 0.046589
[epoch4, step1364]: loss 0.047986
[epoch4, step1365]: loss 0.047295
[epoch4, step1366]: loss 0.047619
[epoch4, step1367]: loss 0.046914
[epoch4, step1368]: loss 0.047417
[epoch4, step1369]: loss 0.047355
[epoch4, step1370]: loss 0.048613
[epoch4, step1371]: loss 0.047103
[epoch4, step1372]: loss 0.046339
[epoch4, step1373]: loss 0.048340
[epoch4, step1374]: loss 0.047526
[epoch4, step1375]: loss 0.048101
[epoch4, step1376]: loss 0.047007
[epoch4, step1377]: loss 0.046815
[epoch4, step1378]: loss 0.047366
[epoch4, step1379]: loss 0.048685
[epoch4, step1380]: loss 0.047077
[epoch4, step1381]: loss 0.046460
[epoch4, step1382]: loss 0.048360
[epoch4, step1383]: loss 0.047253
[epoch4, step1384]: loss 0.047729
[epoch4, step1385]: loss 0.046804
[epoch4, step1386]: loss 0.047081
[epoch4, step1387]: loss 0.047365
[epoch4, step1388]: loss 0.048466
[epoch4, step1389]: loss 0.046594
[epoch4, step1390]: loss 0.046435
[epoch4, step1391]: loss 0.048181
[epoch4, step1392]: loss 0.047272
[epoch4, step1393]: loss 0.047786
[epoch4, step1394]: loss 0.047572
[epoch4, step1395]: loss 0.047137
[epoch4, step1396]: loss 0.047089
[epoch4, step1397]: loss 0.048738
[epoch4, step1398]: loss 0.047083
[epoch4, step1399]: loss 0.046797
[epoch4, step1400]: loss 0.048440
[epoch4, step1401]: loss 0.047199
[epoch4, step1402]: loss 0.047649
[epoch4, step1403]: loss 0.046708
[epoch4, step1404]: loss 0.046936
[epoch4, step1405]: loss 0.047149
[epoch4, step1406]: loss 0.048471
[epoch4, step1407]: loss 0.047565
[epoch4, step1408]: loss 0.046253
[epoch4, step1409]: loss 0.047935
[epoch4, step1410]: loss 0.047221
[epoch4, step1411]: loss 0.047184
[epoch4, step1412]: loss 0.047057
[epoch4, step1413]: loss 0.047027
[epoch4, step1414]: loss 0.047019
[epoch4, step1415]: loss 0.048608
[epoch4, step1416]: loss 0.046839
[epoch4, step1417]: loss 0.046386
[epoch4, step1418]: loss 0.048078
[epoch4, step1419]: loss 0.047578
[epoch4, step1420]: loss 0.047699
[epoch4, step1421]: loss 0.047330
[epoch4, step1422]: loss 0.047116
[epoch4, step1423]: loss 0.046935
[epoch4, step1424]: loss 0.048726
[epoch4, step1425]: loss 0.046529
[epoch4, step1426]: loss 0.046500
[epoch4, step1427]: loss 0.048464
[epoch4, step1428]: loss 0.047473
[epoch4, step1429]: loss 0.047670
[epoch4, step1430]: loss 0.047079
[epoch4, step1431]: loss 0.047237
[epoch4, step1432]: loss 0.047080
[epoch4, step1433]: loss 0.048689
[epoch4, step1434]: loss 0.046553
[epoch4, step1435]: loss 0.046484
[epoch4, step1436]: loss 0.048245
[epoch4, step1437]: loss 0.047249
[epoch4, step1438]: loss 0.047474
[epoch4, step1439]: loss 0.046848
[epoch4, step1440]: loss 0.046748
[epoch4, step1441]: loss 0.047306
[epoch4, step1442]: loss 0.047967
[epoch4, step1443]: loss 0.046565
[epoch4, step1444]: loss 0.045884
[epoch4, step1445]: loss 0.047924
[epoch4, step1446]: loss 0.046964
[epoch4, step1447]: loss 0.047628
[epoch4, step1448]: loss 0.046702
[epoch4, step1449]: loss 0.046480
[epoch4, step1450]: loss 0.047073
[epoch4, step1451]: loss 0.048452
[epoch4, step1452]: loss 0.046560
[epoch4, step1453]: loss 0.046619
[epoch4, step1454]: loss 0.047938
[epoch4, step1455]: loss 0.047301
[epoch4, step1456]: loss 0.047056
[epoch4, step1457]: loss 0.046694
[epoch4, step1458]: loss 0.046770
[epoch4, step1459]: loss 0.046542
[epoch4, step1460]: loss 0.048363
[epoch4, step1461]: loss 0.046596
[epoch4, step1462]: loss 0.045919
[epoch4, step1463]: loss 0.047519
[epoch4, step1464]: loss 0.046715
[epoch4, step1465]: loss 0.046703
[epoch4, step1466]: loss 0.045993
[epoch4, step1467]: loss 0.046295
[epoch4, step1468]: loss 0.046218
[epoch4, step1469]: loss 0.047758
[epoch4, step1470]: loss 0.046185
[epoch4, step1471]: loss 0.045378
[epoch4, step1472]: loss 0.047287
[epoch4, step1473]: loss 0.046404
[epoch4, step1474]: loss 0.046928
[epoch4, step1475]: loss 0.045939
[epoch4, step1476]: loss 0.046442
[epoch4, step1477]: loss 0.046415
[epoch4, step1478]: loss 0.047716
[epoch4, step1479]: loss 0.045740
[epoch4, step1480]: loss 0.045496
[epoch4, step1481]: loss 0.046907
[epoch4, step1482]: loss 0.046251
[epoch4, step1483]: loss 0.046461
[epoch4, step1484]: loss 0.045958
[epoch4, step1485]: loss 0.045862
[epoch4, step1486]: loss 0.045645
[epoch4, step1487]: loss 0.047437
[epoch4, step1488]: loss 0.045491
[epoch4, step1489]: loss 0.045216
[epoch4, step1490]: loss 0.046884
[epoch4, step1491]: loss 0.046066
[epoch4, step1492]: loss 0.045890
[epoch4, step1493]: loss 0.045623
[epoch4, step1494]: loss 0.045933
[epoch4, step1495]: loss 0.045884
[epoch4, step1496]: loss 0.046747
[epoch4, step1497]: loss 0.045376
[epoch4, step1498]: loss 0.045168
[epoch4, step1499]: loss 0.046474
[epoch4, step1500]: loss 0.045940
[epoch4, step1501]: loss 0.045871
[epoch4, step1502]: loss 0.045089
[epoch4, step1503]: loss 0.045650
[epoch4, step1504]: loss 0.045321
[epoch4, step1505]: loss 0.047032
[epoch4, step1506]: loss 0.044355
[epoch4, step1507]: loss 0.044840
[epoch4, step1508]: loss 0.046773
[epoch4, step1509]: loss 0.045430
[epoch4, step1510]: loss 0.045224
[epoch4, step1511]: loss 0.045051
[epoch4, step1512]: loss 0.045548
[epoch4, step1513]: loss 0.044836
[epoch4, step1514]: loss 0.046449
[epoch4, step1515]: loss 0.044618
[epoch4, step1516]: loss 0.044378

[epoch4]: avg loss 0.041369

[epoch5, step1]: loss 0.040410
[epoch5, step2]: loss 0.040786
[epoch5, step3]: loss 0.040595
[epoch5, step4]: loss 0.037650
[epoch5, step5]: loss 0.038558
[epoch5, step6]: loss 0.040715
[epoch5, step7]: loss 0.038264
[epoch5, step8]: loss 0.040958
[epoch5, step9]: loss 0.037393
[epoch5, step10]: loss 0.038242
[epoch5, step11]: loss 0.040399
[epoch5, step12]: loss 0.040197
[epoch5, step13]: loss 0.037540
[epoch5, step14]: loss 0.037774
[epoch5, step15]: loss 0.040162
[epoch5, step16]: loss 0.037900
[epoch5, step17]: loss 0.040661
[epoch5, step18]: loss 0.038237
[epoch5, step19]: loss 0.037861
[epoch5, step20]: loss 0.041253
[epoch5, step21]: loss 0.040159
[epoch5, step22]: loss 0.037001
[epoch5, step23]: loss 0.037011
[epoch5, step24]: loss 0.040175
[epoch5, step25]: loss 0.037321
[epoch5, step26]: loss 0.039741
[epoch5, step27]: loss 0.036889
[epoch5, step28]: loss 0.037818
[epoch5, step29]: loss 0.040337
[epoch5, step30]: loss 0.040635
[epoch5, step31]: loss 0.036753
[epoch5, step32]: loss 0.037794
[epoch5, step33]: loss 0.040688
[epoch5, step34]: loss 0.038306
[epoch5, step35]: loss 0.040413
[epoch5, step36]: loss 0.037175
[epoch5, step37]: loss 0.037555
[epoch5, step38]: loss 0.040034
[epoch5, step39]: loss 0.039886
[epoch5, step40]: loss 0.037413
[epoch5, step41]: loss 0.037003
[epoch5, step42]: loss 0.040321
[epoch5, step43]: loss 0.037731
[epoch5, step44]: loss 0.040385
[epoch5, step45]: loss 0.037281
[epoch5, step46]: loss 0.037871
[epoch5, step47]: loss 0.039740
[epoch5, step48]: loss 0.039689
[epoch5, step49]: loss 0.035533
[epoch5, step50]: loss 0.037487
[epoch5, step51]: loss 0.039786
[epoch5, step52]: loss 0.037455
[epoch5, step53]: loss 0.040580
[epoch5, step54]: loss 0.036925
[epoch5, step55]: loss 0.037952
[epoch5, step56]: loss 0.040982
[epoch5, step57]: loss 0.040338
[epoch5, step58]: loss 0.036982
[epoch5, step59]: loss 0.036496
[epoch5, step60]: loss 0.040396
[epoch5, step61]: loss 0.037023
[epoch5, step62]: loss 0.039430
[epoch5, step63]: loss 0.036483
[epoch5, step64]: loss 0.037204
[epoch5, step65]: loss 0.040235
[epoch5, step66]: loss 0.039926
[epoch5, step67]: loss 0.037034
[epoch5, step68]: loss 0.037362
[epoch5, step69]: loss 0.039924
[epoch5, step70]: loss 0.037431
[epoch5, step71]: loss 0.039493
[epoch5, step72]: loss 0.037024
[epoch5, step73]: loss 0.037354
[epoch5, step74]: loss 0.040175
[epoch5, step75]: loss 0.039987
[epoch5, step76]: loss 0.037378
[epoch5, step77]: loss 0.037855
[epoch5, step78]: loss 0.040096
[epoch5, step79]: loss 0.037035
[epoch5, step80]: loss 0.040583
[epoch5, step81]: loss 0.037050
[epoch5, step82]: loss 0.037243
[epoch5, step83]: loss 0.039294
[epoch5, step84]: loss 0.040121
[epoch5, step85]: loss 0.037363
[epoch5, step86]: loss 0.037446
[epoch5, step87]: loss 0.040986
[epoch5, step88]: loss 0.036470
[epoch5, step89]: loss 0.039534
[epoch5, step90]: loss 0.037350
[epoch5, step91]: loss 0.037090
[epoch5, step92]: loss 0.040156
[epoch5, step93]: loss 0.039828
[epoch5, step94]: loss 0.036634
[epoch5, step95]: loss 0.037674
[epoch5, step96]: loss 0.039711
[epoch5, step97]: loss 0.038149
[epoch5, step98]: loss 0.039807
[epoch5, step99]: loss 0.037031
[epoch5, step100]: loss 0.036573
[epoch5, step101]: loss 0.040585
[epoch5, step102]: loss 0.039826
[epoch5, step103]: loss 0.036659
[epoch5, step104]: loss 0.037351
[epoch5, step105]: loss 0.040089
[epoch5, step106]: loss 0.037492
[epoch5, step107]: loss 0.039731
[epoch5, step108]: loss 0.037207
[epoch5, step109]: loss 0.037197
[epoch5, step110]: loss 0.040676
[epoch5, step111]: loss 0.039682
[epoch5, step112]: loss 0.036912
[epoch5, step113]: loss 0.038079
[epoch5, step114]: loss 0.039813
[epoch5, step115]: loss 0.037550
[epoch5, step116]: loss 0.040541
[epoch5, step117]: loss 0.036969
[epoch5, step118]: loss 0.038143
[epoch5, step119]: loss 0.040486
[epoch5, step120]: loss 0.040022
[epoch5, step121]: loss 0.036465
[epoch5, step122]: loss 0.037179
[epoch5, step123]: loss 0.040365
[epoch5, step124]: loss 0.037777
[epoch5, step125]: loss 0.040313
[epoch5, step126]: loss 0.036903
[epoch5, step127]: loss 0.037440
[epoch5, step128]: loss 0.039941
[epoch5, step129]: loss 0.039481
[epoch5, step130]: loss 0.036885
[epoch5, step131]: loss 0.036614
[epoch5, step132]: loss 0.040199
[epoch5, step133]: loss 0.037201
[epoch5, step134]: loss 0.039282
[epoch5, step135]: loss 0.037382
[epoch5, step136]: loss 0.038457
[epoch5, step137]: loss 0.039740
[epoch5, step138]: loss 0.039727
[epoch5, step139]: loss 0.036544
[epoch5, step140]: loss 0.037676
[epoch5, step141]: loss 0.040174
[epoch5, step142]: loss 0.037410
[epoch5, step143]: loss 0.039391
[epoch5, step144]: loss 0.037239
[epoch5, step145]: loss 0.037592
[epoch5, step146]: loss 0.040166
[epoch5, step147]: loss 0.041179
[epoch5, step148]: loss 0.036537
[epoch5, step149]: loss 0.036774
[epoch5, step150]: loss 0.039640
[epoch5, step151]: loss 0.037550
[epoch5, step152]: loss 0.039875
[epoch5, step153]: loss 0.037128
[epoch5, step154]: loss 0.037039
[epoch5, step155]: loss 0.040061
[epoch5, step156]: loss 0.039541
[epoch5, step157]: loss 0.036900
[epoch5, step158]: loss 0.037434
[epoch5, step159]: loss 0.040303
[epoch5, step160]: loss 0.037748
[epoch5, step161]: loss 0.040381
[epoch5, step162]: loss 0.037169
[epoch5, step163]: loss 0.037327
[epoch5, step164]: loss 0.040382
[epoch5, step165]: loss 0.039963
[epoch5, step166]: loss 0.037045
[epoch5, step167]: loss 0.036822
[epoch5, step168]: loss 0.040568
[epoch5, step169]: loss 0.037148
[epoch5, step170]: loss 0.040174
[epoch5, step171]: loss 0.037244
[epoch5, step172]: loss 0.037581
[epoch5, step173]: loss 0.040396
[epoch5, step174]: loss 0.039761
[epoch5, step175]: loss 0.037483
[epoch5, step176]: loss 0.037580
[epoch5, step177]: loss 0.040371
[epoch5, step178]: loss 0.037481
[epoch5, step179]: loss 0.039066
[epoch5, step180]: loss 0.037319
[epoch5, step181]: loss 0.037612
[epoch5, step182]: loss 0.040341
[epoch5, step183]: loss 0.040573
[epoch5, step184]: loss 0.037733
[epoch5, step185]: loss 0.037540
[epoch5, step186]: loss 0.040171
[epoch5, step187]: loss 0.037535
[epoch5, step188]: loss 0.039591
[epoch5, step189]: loss 0.037006
[epoch5, step190]: loss 0.036996
[epoch5, step191]: loss 0.039762
[epoch5, step192]: loss 0.040397
[epoch5, step193]: loss 0.035031
[epoch5, step194]: loss 0.036443
[epoch5, step195]: loss 0.040377
[epoch5, step196]: loss 0.037473
[epoch5, step197]: loss 0.039711
[epoch5, step198]: loss 0.036101
[epoch5, step199]: loss 0.037499
[epoch5, step200]: loss 0.040553
[epoch5, step201]: loss 0.040429
[epoch5, step202]: loss 0.036474
[epoch5, step203]: loss 0.037299
[epoch5, step204]: loss 0.040427
[epoch5, step205]: loss 0.036804
[epoch5, step206]: loss 0.039545
[epoch5, step207]: loss 0.036838
[epoch5, step208]: loss 0.037891
[epoch5, step209]: loss 0.040305
[epoch5, step210]: loss 0.040857
[epoch5, step211]: loss 0.037360
[epoch5, step212]: loss 0.037709
[epoch5, step213]: loss 0.039784
[epoch5, step214]: loss 0.036867
[epoch5, step215]: loss 0.040079
[epoch5, step216]: loss 0.037235
[epoch5, step217]: loss 0.036557
[epoch5, step218]: loss 0.040325
[epoch5, step219]: loss 0.039744
[epoch5, step220]: loss 0.037093
[epoch5, step221]: loss 0.037518
[epoch5, step222]: loss 0.040189
[epoch5, step223]: loss 0.037621
[epoch5, step224]: loss 0.039533
[epoch5, step225]: loss 0.036950
[epoch5, step226]: loss 0.037356
[epoch5, step227]: loss 0.039179
[epoch5, step228]: loss 0.040499
[epoch5, step229]: loss 0.036023
[epoch5, step230]: loss 0.037527
[epoch5, step231]: loss 0.040482
[epoch5, step232]: loss 0.036912
[epoch5, step233]: loss 0.039093
[epoch5, step234]: loss 0.036541
[epoch5, step235]: loss 0.037770
[epoch5, step236]: loss 0.040207
[epoch5, step237]: loss 0.040098
[epoch5, step238]: loss 0.036554
[epoch5, step239]: loss 0.036529
[epoch5, step240]: loss 0.039602
[epoch5, step241]: loss 0.037885
[epoch5, step242]: loss 0.039709
[epoch5, step243]: loss 0.037580
[epoch5, step244]: loss 0.037368
[epoch5, step245]: loss 0.039699
[epoch5, step246]: loss 0.039965
[epoch5, step247]: loss 0.037079
[epoch5, step248]: loss 0.036885
[epoch5, step249]: loss 0.039613
[epoch5, step250]: loss 0.037494
[epoch5, step251]: loss 0.040390
[epoch5, step252]: loss 0.037479
[epoch5, step253]: loss 0.037106
[epoch5, step254]: loss 0.039409
[epoch5, step255]: loss 0.040069
[epoch5, step256]: loss 0.036548
[epoch5, step257]: loss 0.036973
[epoch5, step258]: loss 0.040683
[epoch5, step259]: loss 0.037233
[epoch5, step260]: loss 0.039241
[epoch5, step261]: loss 0.037733
[epoch5, step262]: loss 0.037847
[epoch5, step263]: loss 0.039297
[epoch5, step264]: loss 0.039669
[epoch5, step265]: loss 0.037029
[epoch5, step266]: loss 0.037188
[epoch5, step267]: loss 0.039453
[epoch5, step268]: loss 0.037258
[epoch5, step269]: loss 0.039852
[epoch5, step270]: loss 0.036575
[epoch5, step271]: loss 0.037494
[epoch5, step272]: loss 0.040048
[epoch5, step273]: loss 0.039709
[epoch5, step274]: loss 0.037259
[epoch5, step275]: loss 0.036755
[epoch5, step276]: loss 0.039616
[epoch5, step277]: loss 0.037751
[epoch5, step278]: loss 0.039937
[epoch5, step279]: loss 0.036634
[epoch5, step280]: loss 0.037268
[epoch5, step281]: loss 0.039798
[epoch5, step282]: loss 0.040315
[epoch5, step283]: loss 0.036366
[epoch5, step284]: loss 0.036635
[epoch5, step285]: loss 0.040736
[epoch5, step286]: loss 0.036543
[epoch5, step287]: loss 0.039943
[epoch5, step288]: loss 0.036544
[epoch5, step289]: loss 0.038242
[epoch5, step290]: loss 0.040139
[epoch5, step291]: loss 0.040228
[epoch5, step292]: loss 0.035971
[epoch5, step293]: loss 0.036783
[epoch5, step294]: loss 0.039203
[epoch5, step295]: loss 0.036806
[epoch5, step296]: loss 0.040510
[epoch5, step297]: loss 0.036607
[epoch5, step298]: loss 0.037816
[epoch5, step299]: loss 0.039232
[epoch5, step300]: loss 0.040203
[epoch5, step301]: loss 0.036777
[epoch5, step302]: loss 0.037508
[epoch5, step303]: loss 0.040449
[epoch5, step304]: loss 0.036886
[epoch5, step305]: loss 0.039477
[epoch5, step306]: loss 0.036963
[epoch5, step307]: loss 0.036883
[epoch5, step308]: loss 0.040547
[epoch5, step309]: loss 0.040198
[epoch5, step310]: loss 0.036905
[epoch5, step311]: loss 0.037508
[epoch5, step312]: loss 0.039733
[epoch5, step313]: loss 0.037712
[epoch5, step314]: loss 0.039724
[epoch5, step315]: loss 0.037863
[epoch5, step316]: loss 0.037179
[epoch5, step317]: loss 0.040192
[epoch5, step318]: loss 0.040079
[epoch5, step319]: loss 0.036310
[epoch5, step320]: loss 0.036201
[epoch5, step321]: loss 0.039624
[epoch5, step322]: loss 0.037146
[epoch5, step323]: loss 0.039186
[epoch5, step324]: loss 0.037489
[epoch5, step325]: loss 0.037527
[epoch5, step326]: loss 0.039759
[epoch5, step327]: loss 0.039349
[epoch5, step328]: loss 0.036920
[epoch5, step329]: loss 0.036862
[epoch5, step330]: loss 0.039673
[epoch5, step331]: loss 0.037373
[epoch5, step332]: loss 0.039172
[epoch5, step333]: loss 0.036861
[epoch5, step334]: loss 0.037265
[epoch5, step335]: loss 0.040132
[epoch5, step336]: loss 0.040833
[epoch5, step337]: loss 0.036908
[epoch5, step338]: loss 0.036682
[epoch5, step339]: loss 0.039691
[epoch5, step340]: loss 0.037640
[epoch5, step341]: loss 0.039265
[epoch5, step342]: loss 0.036592
[epoch5, step343]: loss 0.037552
[epoch5, step344]: loss 0.039583
[epoch5, step345]: loss 0.039341
[epoch5, step346]: loss 0.036235
[epoch5, step347]: loss 0.036792
[epoch5, step348]: loss 0.040046
[epoch5, step349]: loss 0.037729
[epoch5, step350]: loss 0.039212
[epoch5, step351]: loss 0.036207
[epoch5, step352]: loss 0.037267
[epoch5, step353]: loss 0.039739
[epoch5, step354]: loss 0.039021
[epoch5, step355]: loss 0.035772
[epoch5, step356]: loss 0.037725
[epoch5, step357]: loss 0.039978
[epoch5, step358]: loss 0.035931
[epoch5, step359]: loss 0.040576
[epoch5, step360]: loss 0.035767
[epoch5, step361]: loss 0.036597
[epoch5, step362]: loss 0.040445
[epoch5, step363]: loss 0.039656
[epoch5, step364]: loss 0.036519
[epoch5, step365]: loss 0.036732
[epoch5, step366]: loss 0.040285
[epoch5, step367]: loss 0.037171
[epoch5, step368]: loss 0.039050
[epoch5, step369]: loss 0.036722
[epoch5, step370]: loss 0.037884
[epoch5, step371]: loss 0.040720
[epoch5, step372]: loss 0.039546
[epoch5, step373]: loss 0.036142
[epoch5, step374]: loss 0.036313
[epoch5, step375]: loss 0.040417
[epoch5, step376]: loss 0.037194
[epoch5, step377]: loss 0.039853
[epoch5, step378]: loss 0.037167
[epoch5, step379]: loss 0.037836
[epoch5, step380]: loss 0.040413
[epoch5, step381]: loss 0.039573
[epoch5, step382]: loss 0.036935
[epoch5, step383]: loss 0.036108
[epoch5, step384]: loss 0.039277
[epoch5, step385]: loss 0.037180
[epoch5, step386]: loss 0.039781
[epoch5, step387]: loss 0.036918
[epoch5, step388]: loss 0.038000
[epoch5, step389]: loss 0.039943
[epoch5, step390]: loss 0.040695
[epoch5, step391]: loss 0.036294
[epoch5, step392]: loss 0.037529
[epoch5, step393]: loss 0.039330
[epoch5, step394]: loss 0.037202
[epoch5, step395]: loss 0.039439
[epoch5, step396]: loss 0.036867
[epoch5, step397]: loss 0.036906
[epoch5, step398]: loss 0.040035
[epoch5, step399]: loss 0.039748
[epoch5, step400]: loss 0.036353
[epoch5, step401]: loss 0.036751
[epoch5, step402]: loss 0.039477
[epoch5, step403]: loss 0.037144
[epoch5, step404]: loss 0.039854
[epoch5, step405]: loss 0.037060
[epoch5, step406]: loss 0.037550
[epoch5, step407]: loss 0.039637
[epoch5, step408]: loss 0.039975
[epoch5, step409]: loss 0.037816
[epoch5, step410]: loss 0.037621
[epoch5, step411]: loss 0.039781
[epoch5, step412]: loss 0.036684
[epoch5, step413]: loss 0.039582
[epoch5, step414]: loss 0.036406
[epoch5, step415]: loss 0.037542
[epoch5, step416]: loss 0.039298
[epoch5, step417]: loss 0.040096
[epoch5, step418]: loss 0.036464
[epoch5, step419]: loss 0.036250
[epoch5, step420]: loss 0.040049
[epoch5, step421]: loss 0.036914
[epoch5, step422]: loss 0.039525
[epoch5, step423]: loss 0.036990
[epoch5, step424]: loss 0.037546
[epoch5, step425]: loss 0.040069
[epoch5, step426]: loss 0.040325
[epoch5, step427]: loss 0.036904
[epoch5, step428]: loss 0.036855
[epoch5, step429]: loss 0.040650
[epoch5, step430]: loss 0.036978
[epoch5, step431]: loss 0.040078
[epoch5, step432]: loss 0.036642
[epoch5, step433]: loss 0.037898
[epoch5, step434]: loss 0.039877
[epoch5, step435]: loss 0.040208
[epoch5, step436]: loss 0.036231
[epoch5, step437]: loss 0.037114
[epoch5, step438]: loss 0.040354
[epoch5, step439]: loss 0.037429
[epoch5, step440]: loss 0.039450
[epoch5, step441]: loss 0.037181
[epoch5, step442]: loss 0.037133
[epoch5, step443]: loss 0.040414
[epoch5, step444]: loss 0.039701
[epoch5, step445]: loss 0.037104
[epoch5, step446]: loss 0.037530
[epoch5, step447]: loss 0.040682
[epoch5, step448]: loss 0.037485
[epoch5, step449]: loss 0.039606
[epoch5, step450]: loss 0.036134
[epoch5, step451]: loss 0.037067
[epoch5, step452]: loss 0.038747
[epoch5, step453]: loss 0.040066
[epoch5, step454]: loss 0.036534
[epoch5, step455]: loss 0.037119
[epoch5, step456]: loss 0.038940
[epoch5, step457]: loss 0.037853
[epoch5, step458]: loss 0.039347
[epoch5, step459]: loss 0.037422
[epoch5, step460]: loss 0.037390
[epoch5, step461]: loss 0.040676
[epoch5, step462]: loss 0.039275
[epoch5, step463]: loss 0.036826
[epoch5, step464]: loss 0.036907
[epoch5, step465]: loss 0.041121
[epoch5, step466]: loss 0.037108
[epoch5, step467]: loss 0.039297
[epoch5, step468]: loss 0.036825
[epoch5, step469]: loss 0.037472
[epoch5, step470]: loss 0.040195
[epoch5, step471]: loss 0.039529
[epoch5, step472]: loss 0.037086
[epoch5, step473]: loss 0.036634
[epoch5, step474]: loss 0.039980
[epoch5, step475]: loss 0.037328
[epoch5, step476]: loss 0.040234
[epoch5, step477]: loss 0.036628
[epoch5, step478]: loss 0.036785
[epoch5, step479]: loss 0.039756
[epoch5, step480]: loss 0.038884
[epoch5, step481]: loss 0.036139
[epoch5, step482]: loss 0.036295
[epoch5, step483]: loss 0.040271
[epoch5, step484]: loss 0.037415
[epoch5, step485]: loss 0.039707
[epoch5, step486]: loss 0.037257
[epoch5, step487]: loss 0.036602
[epoch5, step488]: loss 0.040348
[epoch5, step489]: loss 0.039239
[epoch5, step490]: loss 0.036953
[epoch5, step491]: loss 0.037167
[epoch5, step492]: loss 0.039536
[epoch5, step493]: loss 0.036963
[epoch5, step494]: loss 0.039087
[epoch5, step495]: loss 0.037966
[epoch5, step496]: loss 0.037302
[epoch5, step497]: loss 0.039961
[epoch5, step498]: loss 0.039645
[epoch5, step499]: loss 0.036930
[epoch5, step500]: loss 0.036609
[epoch5, step501]: loss 0.039464
[epoch5, step502]: loss 0.037045
[epoch5, step503]: loss 0.039863
[epoch5, step504]: loss 0.036543
[epoch5, step505]: loss 0.036499
[epoch5, step506]: loss 0.040324
[epoch5, step507]: loss 0.040010
[epoch5, step508]: loss 0.037157
[epoch5, step509]: loss 0.036910
[epoch5, step510]: loss 0.039965
[epoch5, step511]: loss 0.037584
[epoch5, step512]: loss 0.039880
[epoch5, step513]: loss 0.037110
[epoch5, step514]: loss 0.037737
[epoch5, step515]: loss 0.039904
[epoch5, step516]: loss 0.040445
[epoch5, step517]: loss 0.036782
[epoch5, step518]: loss 0.037045
[epoch5, step519]: loss 0.039963
[epoch5, step520]: loss 0.036639
[epoch5, step521]: loss 0.039307
[epoch5, step522]: loss 0.036157
[epoch5, step523]: loss 0.037184
[epoch5, step524]: loss 0.039271
[epoch5, step525]: loss 0.040085
[epoch5, step526]: loss 0.036762
[epoch5, step527]: loss 0.036640
[epoch5, step528]: loss 0.040047
[epoch5, step529]: loss 0.036666
[epoch5, step530]: loss 0.039880
[epoch5, step531]: loss 0.036737
[epoch5, step532]: loss 0.036755
[epoch5, step533]: loss 0.040967
[epoch5, step534]: loss 0.039822
[epoch5, step535]: loss 0.036990
[epoch5, step536]: loss 0.037153
[epoch5, step537]: loss 0.039866
[epoch5, step538]: loss 0.037375
[epoch5, step539]: loss 0.039455
[epoch5, step540]: loss 0.036411
[epoch5, step541]: loss 0.036775
[epoch5, step542]: loss 0.039898
[epoch5, step543]: loss 0.039538
[epoch5, step544]: loss 0.036536
[epoch5, step545]: loss 0.036205
[epoch5, step546]: loss 0.040466
[epoch5, step547]: loss 0.036822
[epoch5, step548]: loss 0.039516
[epoch5, step549]: loss 0.037025
[epoch5, step550]: loss 0.037212
[epoch5, step551]: loss 0.039808
[epoch5, step552]: loss 0.039268
[epoch5, step553]: loss 0.037045
[epoch5, step554]: loss 0.036773
[epoch5, step555]: loss 0.039598
[epoch5, step556]: loss 0.037121
[epoch5, step557]: loss 0.038985
[epoch5, step558]: loss 0.037140
[epoch5, step559]: loss 0.036669
[epoch5, step560]: loss 0.039932
[epoch5, step561]: loss 0.039824
[epoch5, step562]: loss 0.036641
[epoch5, step563]: loss 0.036495
[epoch5, step564]: loss 0.039224
[epoch5, step565]: loss 0.037892
[epoch5, step566]: loss 0.045506
[epoch5, step567]: loss 0.037483
[epoch5, step568]: loss 0.035950
[epoch5, step569]: loss 0.033175
[epoch5, step570]: loss 0.041870
[epoch5, step571]: loss 0.038614
[epoch5, step572]: loss 0.037961
[epoch5, step573]: loss 0.039517
[epoch5, step574]: loss 0.040623
[epoch5, step575]: loss 0.031675
[epoch5, step576]: loss 0.033050
[epoch5, step577]: loss 0.045166
[epoch5, step578]: loss 0.030359
[epoch5, step579]: loss 0.039452
[epoch5, step580]: loss 0.031480
[epoch5, step581]: loss 0.037002
[epoch5, step582]: loss 0.036287
[epoch5, step583]: loss 0.033572
[epoch5, step584]: loss 0.034833
[epoch5, step585]: loss 0.037181
[epoch5, step586]: loss 0.033569
[epoch5, step587]: loss 0.039393
[epoch5, step588]: loss 0.034456
[epoch5, step589]: loss 0.034426
[epoch5, step590]: loss 0.039405
[epoch5, step591]: loss 0.031816
[epoch5, step592]: loss 0.037664
[epoch5, step593]: loss 0.033803
[epoch5, step594]: loss 0.037110
[epoch5, step595]: loss 0.038530
[epoch5, step596]: loss 0.034740
[epoch5, step597]: loss 0.036135
[epoch5, step598]: loss 0.038109
[epoch5, step599]: loss 0.035913
[epoch5, step600]: loss 0.038796
[epoch5, step601]: loss 0.030625
[epoch5, step602]: loss 0.034199
[epoch5, step603]: loss 0.037669
[epoch5, step604]: loss 0.038768
[epoch5, step605]: loss 0.036489
[epoch5, step606]: loss 0.035393
[epoch5, step607]: loss 0.039295
[epoch5, step608]: loss 0.036856
[epoch5, step609]: loss 0.038168
[epoch5, step610]: loss 0.037976
[epoch5, step611]: loss 0.037535
[epoch5, step612]: loss 0.036554
[epoch5, step613]: loss 0.031233
[epoch5, step614]: loss 0.035748
[epoch5, step615]: loss 0.040727
[epoch5, step616]: loss 0.035081
[epoch5, step617]: loss 0.034516
[epoch5, step618]: loss 0.038079
[epoch5, step619]: loss 0.038737
[epoch5, step620]: loss 0.035762
[epoch5, step621]: loss 0.038023
[epoch5, step622]: loss 0.031850
[epoch5, step623]: loss 0.034761
[epoch5, step624]: loss 0.038365
[epoch5, step625]: loss 0.037077
[epoch5, step626]: loss 0.039750
[epoch5, step627]: loss 0.034159
[epoch5, step628]: loss 0.036784
[epoch5, step629]: loss 0.031233
[epoch5, step630]: loss 0.033538
[epoch5, step631]: loss 0.043336
[epoch5, step632]: loss 0.035430
[epoch5, step633]: loss 0.036283
[epoch5, step634]: loss 0.037863
[epoch5, step635]: loss 0.037356
[epoch5, step636]: loss 0.032517
[epoch5, step637]: loss 0.038866
[epoch5, step638]: loss 0.038800
[epoch5, step639]: loss 0.033069
[epoch5, step640]: loss 0.040543
[epoch5, step641]: loss 0.041954
[epoch5, step642]: loss 0.036776
[epoch5, step643]: loss 0.036792
[epoch5, step644]: loss 0.037167
[epoch5, step645]: loss 0.035052
[epoch5, step646]: loss 0.036827
[epoch5, step647]: loss 0.034532
[epoch5, step648]: loss 0.035994
[epoch5, step649]: loss 0.040192
[epoch5, step650]: loss 0.033986
[epoch5, step651]: loss 0.038569
[epoch5, step652]: loss 0.038339
[epoch5, step653]: loss 0.039000
[epoch5, step654]: loss 0.034106
[epoch5, step655]: loss 0.035456
[epoch5, step656]: loss 0.033739
[epoch5, step657]: loss 0.039343
[epoch5, step658]: loss 0.036573
[epoch5, step659]: loss 0.039149
[epoch5, step660]: loss 0.033922
[epoch5, step661]: loss 0.038296
[epoch5, step662]: loss 0.034974
[epoch5, step663]: loss 0.033069
[epoch5, step664]: loss 0.036716
[epoch5, step665]: loss 0.038791
[epoch5, step666]: loss 0.038172
[epoch5, step667]: loss 0.038611
[epoch5, step668]: loss 0.034437
[epoch5, step669]: loss 0.038047
[epoch5, step670]: loss 0.039144
[epoch5, step671]: loss 0.032356
[epoch5, step672]: loss 0.036330
[epoch5, step673]: loss 0.034303
[epoch5, step674]: loss 0.032086
[epoch5, step675]: loss 0.031228
[epoch5, step676]: loss 0.035475
[epoch5, step677]: loss 0.036179
[epoch5, step678]: loss 0.034108
[epoch5, step679]: loss 0.035432
[epoch5, step680]: loss 0.042577
[epoch5, step681]: loss 0.032667
[epoch5, step682]: loss 0.037466
[epoch5, step683]: loss 0.036790
[epoch5, step684]: loss 0.036283
[epoch5, step685]: loss 0.035739
[epoch5, step686]: loss 0.038935
[epoch5, step687]: loss 0.037486
[epoch5, step688]: loss 0.035411
[epoch5, step689]: loss 0.035528
[epoch5, step690]: loss 0.037175
[epoch5, step691]: loss 0.036140
[epoch5, step692]: loss 0.034522
[epoch5, step693]: loss 0.039587
[epoch5, step694]: loss 0.033621
[epoch5, step695]: loss 0.038738
[epoch5, step696]: loss 0.036415
[epoch5, step697]: loss 0.039092
[epoch5, step698]: loss 0.035968
[epoch5, step699]: loss 0.034899
[epoch5, step700]: loss 0.032753
[epoch5, step701]: loss 0.037480
[epoch5, step702]: loss 0.032460
[epoch5, step703]: loss 0.035009
[epoch5, step704]: loss 0.037884
[epoch5, step705]: loss 0.036292
[epoch5, step706]: loss 0.034796
[epoch5, step707]: loss 0.034894
[epoch5, step708]: loss 0.036674
[epoch5, step709]: loss 0.038984
[epoch5, step710]: loss 0.034558
[epoch5, step711]: loss 0.037499
[epoch5, step712]: loss 0.037821
[epoch5, step713]: loss 0.038130
[epoch5, step714]: loss 0.032989
[epoch5, step715]: loss 0.034202
[epoch5, step716]: loss 0.036959
[epoch5, step717]: loss 0.033946
[epoch5, step718]: loss 0.036633
[epoch5, step719]: loss 0.045963
[epoch5, step720]: loss 0.036066
[epoch5, step721]: loss 0.034440
[epoch5, step722]: loss 0.042567
[epoch5, step723]: loss 0.038467
[epoch5, step724]: loss 0.034170
[epoch5, step725]: loss 0.039245
[epoch5, step726]: loss 0.033329
[epoch5, step727]: loss 0.035406
[epoch5, step728]: loss 0.037925
[epoch5, step729]: loss 0.033146
[epoch5, step730]: loss 0.033884
[epoch5, step731]: loss 0.037591
[epoch5, step732]: loss 0.037230
[epoch5, step733]: loss 0.035115
[epoch5, step734]: loss 0.034469
[epoch5, step735]: loss 0.039107
[epoch5, step736]: loss 0.036461
[epoch5, step737]: loss 0.038306
[epoch5, step738]: loss 0.031153
[epoch5, step739]: loss 0.037801
[epoch5, step740]: loss 0.034306
[epoch5, step741]: loss 0.037430
[epoch5, step742]: loss 0.033761
[epoch5, step743]: loss 0.035189
[epoch5, step744]: loss 0.034796
[epoch5, step745]: loss 0.035235
[epoch5, step746]: loss 0.037511
[epoch5, step747]: loss 0.039795
[epoch5, step748]: loss 0.037419
[epoch5, step749]: loss 0.037652
[epoch5, step750]: loss 0.039124
[epoch5, step751]: loss 0.033887
[epoch5, step752]: loss 0.035884
[epoch5, step753]: loss 0.036037
[epoch5, step754]: loss 0.034995
[epoch5, step755]: loss 0.037718
[epoch5, step756]: loss 0.035075
[epoch5, step757]: loss 0.031447
[epoch5, step758]: loss 0.035237
[epoch5, step759]: loss 0.033909
[epoch5, step760]: loss 0.035026
[epoch5, step761]: loss 0.037841
[epoch5, step762]: loss 0.032543
[epoch5, step763]: loss 0.037255
[epoch5, step764]: loss 0.035716
[epoch5, step765]: loss 0.037979
[epoch5, step766]: loss 0.036737
[epoch5, step767]: loss 0.040593
[epoch5, step768]: loss 0.032041
[epoch5, step769]: loss 0.037492
[epoch5, step770]: loss 0.036855
[epoch5, step771]: loss 0.033972
[epoch5, step772]: loss 0.040173
[epoch5, step773]: loss 0.037167
[epoch5, step774]: loss 0.035752
[epoch5, step775]: loss 0.031555
[epoch5, step776]: loss 0.037537
[epoch5, step777]: loss 0.033929
[epoch5, step778]: loss 0.038886
[epoch5, step779]: loss 0.035616
[epoch5, step780]: loss 0.030942
[epoch5, step781]: loss 0.035800
[epoch5, step782]: loss 0.033810
[epoch5, step783]: loss 0.031113
[epoch5, step784]: loss 0.031957
[epoch5, step785]: loss 0.032387
[epoch5, step786]: loss 0.035412
[epoch5, step787]: loss 0.035141
[epoch5, step788]: loss 0.036630
[epoch5, step789]: loss 0.036164
[epoch5, step790]: loss 0.034600
[epoch5, step791]: loss 0.038960
[epoch5, step792]: loss 0.036453
[epoch5, step793]: loss 0.038515
[epoch5, step794]: loss 0.031614
[epoch5, step795]: loss 0.036396
[epoch5, step796]: loss 0.039484
[epoch5, step797]: loss 0.038774
[epoch5, step798]: loss 0.038813
[epoch5, step799]: loss 0.037505
[epoch5, step800]: loss 0.032993
[epoch5, step801]: loss 0.034537
[epoch5, step802]: loss 0.034077
[epoch5, step803]: loss 0.037859
[epoch5, step804]: loss 0.039074
[epoch5, step805]: loss 0.039284
[epoch5, step806]: loss 0.033364
[epoch5, step807]: loss 0.032181
[epoch5, step808]: loss 0.035069
[epoch5, step809]: loss 0.033292
[epoch5, step810]: loss 0.036986
[epoch5, step811]: loss 0.036526
[epoch5, step812]: loss 0.035623
[epoch5, step813]: loss 0.034620
[epoch5, step814]: loss 0.036889
[epoch5, step815]: loss 0.035305
[epoch5, step816]: loss 0.036293
[epoch5, step817]: loss 0.036337
[epoch5, step818]: loss 0.033118
[epoch5, step819]: loss 0.032476
[epoch5, step820]: loss 0.034921
[epoch5, step821]: loss 0.032240
[epoch5, step822]: loss 0.041889
[epoch5, step823]: loss 0.035246
[epoch5, step824]: loss 0.038090
[epoch5, step825]: loss 0.037267
[epoch5, step826]: loss 0.035226
[epoch5, step827]: loss 0.038149
[epoch5, step828]: loss 0.039914
[epoch5, step829]: loss 0.038815
[epoch5, step830]: loss 0.033770
[epoch5, step831]: loss 0.038056
[epoch5, step832]: loss 0.032918
[epoch5, step833]: loss 0.039788
[epoch5, step834]: loss 0.037902
[epoch5, step835]: loss 0.032071
[epoch5, step836]: loss 0.039586
[epoch5, step837]: loss 0.037134
[epoch5, step838]: loss 0.036655
[epoch5, step839]: loss 0.039866
[epoch5, step840]: loss 0.031640
[epoch5, step841]: loss 0.036051
[epoch5, step842]: loss 0.039058
[epoch5, step843]: loss 0.036991
[epoch5, step844]: loss 0.036513
[epoch5, step845]: loss 0.032786
[epoch5, step846]: loss 0.039369
[epoch5, step847]: loss 0.038290
[epoch5, step848]: loss 0.036337
[epoch5, step849]: loss 0.035503
[epoch5, step850]: loss 0.034398
[epoch5, step851]: loss 0.036135
[epoch5, step852]: loss 0.033799
[epoch5, step853]: loss 0.041895
[epoch5, step854]: loss 0.034328
[epoch5, step855]: loss 0.038417
[epoch5, step856]: loss 0.032510
[epoch5, step857]: loss 0.036244
[epoch5, step858]: loss 0.035652
[epoch5, step859]: loss 0.034736
[epoch5, step860]: loss 0.034151
[epoch5, step861]: loss 0.034095
[epoch5, step862]: loss 0.033616
[epoch5, step863]: loss 0.032203
[epoch5, step864]: loss 0.038307
[epoch5, step865]: loss 0.035427
[epoch5, step866]: loss 0.036229
[epoch5, step867]: loss 0.037941
[epoch5, step868]: loss 0.039066
[epoch5, step869]: loss 0.034869
[epoch5, step870]: loss 0.042900
[epoch5, step871]: loss 0.034500
[epoch5, step872]: loss 0.037391
[epoch5, step873]: loss 0.037188
[epoch5, step874]: loss 0.035311
[epoch5, step875]: loss 0.035409
[epoch5, step876]: loss 0.036332
[epoch5, step877]: loss 0.030567
[epoch5, step878]: loss 0.034258
[epoch5, step879]: loss 0.040067
[epoch5, step880]: loss 0.036746
[epoch5, step881]: loss 0.034073
[epoch5, step882]: loss 0.035222
[epoch5, step883]: loss 0.035010
[epoch5, step884]: loss 0.037858
[epoch5, step885]: loss 0.037595
[epoch5, step886]: loss 0.037682
[epoch5, step887]: loss 0.035847
[epoch5, step888]: loss 0.036419
[epoch5, step889]: loss 0.035510
[epoch5, step890]: loss 0.035758
[epoch5, step891]: loss 0.037502
[epoch5, step892]: loss 0.031255
[epoch5, step893]: loss 0.036001
[epoch5, step894]: loss 0.036361
[epoch5, step895]: loss 0.033213
[epoch5, step896]: loss 0.034054
[epoch5, step897]: loss 0.036880
[epoch5, step898]: loss 0.038238
[epoch5, step899]: loss 0.040246
[epoch5, step900]: loss 0.038043
[epoch5, step901]: loss 0.037714
[epoch5, step902]: loss 0.035080
[epoch5, step903]: loss 0.037034
[epoch5, step904]: loss 0.038860
[epoch5, step905]: loss 0.039156
[epoch5, step906]: loss 0.033171
[epoch5, step907]: loss 0.034900
[epoch5, step908]: loss 0.033818
[epoch5, step909]: loss 0.038017
[epoch5, step910]: loss 0.034431
[epoch5, step911]: loss 0.036639
[epoch5, step912]: loss 0.034571
[epoch5, step913]: loss 0.035711
[epoch5, step914]: loss 0.040867
[epoch5, step915]: loss 0.035087
[epoch5, step916]: loss 0.034425
[epoch5, step917]: loss 0.036047
[epoch5, step918]: loss 0.040707
[epoch5, step919]: loss 0.035940
[epoch5, step920]: loss 0.039018
[epoch5, step921]: loss 0.035500
[epoch5, step922]: loss 0.035104
[epoch5, step923]: loss 0.034721
[epoch5, step924]: loss 0.031612
[epoch5, step925]: loss 0.036843
[epoch5, step926]: loss 0.036585
[epoch5, step927]: loss 0.037058
[epoch5, step928]: loss 0.035454
[epoch5, step929]: loss 0.039215
[epoch5, step930]: loss 0.036680
[epoch5, step931]: loss 0.038763
[epoch5, step932]: loss 0.032305
[epoch5, step933]: loss 0.040729
[epoch5, step934]: loss 0.034338
[epoch5, step935]: loss 0.034333
[epoch5, step936]: loss 0.033642
[epoch5, step937]: loss 0.038325
[epoch5, step938]: loss 0.038791
[epoch5, step939]: loss 0.032511
[epoch5, step940]: loss 0.034953
[epoch5, step941]: loss 0.038333
[epoch5, step942]: loss 0.037444
[epoch5, step943]: loss 0.035366
[epoch5, step944]: loss 0.039053
[epoch5, step945]: loss 0.031623
[epoch5, step946]: loss 0.037002
[epoch5, step947]: loss 0.039935
[epoch5, step948]: loss 0.031890
[epoch5, step949]: loss 0.034492
[epoch5, step950]: loss 0.038167
[epoch5, step951]: loss 0.040569
[epoch5, step952]: loss 0.036126
[epoch5, step953]: loss 0.038923
[epoch5, step954]: loss 0.034420
[epoch5, step955]: loss 0.042791
[epoch5, step956]: loss 0.052408
[epoch5, step957]: loss 0.049001
[epoch5, step958]: loss 0.047644
[epoch5, step959]: loss 0.050379
[epoch5, step960]: loss 0.048359
[epoch5, step961]: loss 0.049212
[epoch5, step962]: loss 0.048588
[epoch5, step963]: loss 0.047458
[epoch5, step964]: loss 0.047996
[epoch5, step965]: loss 0.048834
[epoch5, step966]: loss 0.047608
[epoch5, step967]: loss 0.046930
[epoch5, step968]: loss 0.048365
[epoch5, step969]: loss 0.048010
[epoch5, step970]: loss 0.048271
[epoch5, step971]: loss 0.047794
[epoch5, step972]: loss 0.047562
[epoch5, step973]: loss 0.047409
[epoch5, step974]: loss 0.049220
[epoch5, step975]: loss 0.047443
[epoch5, step976]: loss 0.046795
[epoch5, step977]: loss 0.048579
[epoch5, step978]: loss 0.047603
[epoch5, step979]: loss 0.047748
[epoch5, step980]: loss 0.047053
[epoch5, step981]: loss 0.047099
[epoch5, step982]: loss 0.047508
[epoch5, step983]: loss 0.048850
[epoch5, step984]: loss 0.046883
[epoch5, step985]: loss 0.046564
[epoch5, step986]: loss 0.048710
[epoch5, step987]: loss 0.047702
[epoch5, step988]: loss 0.048142
[epoch5, step989]: loss 0.047673
[epoch5, step990]: loss 0.047017
[epoch5, step991]: loss 0.047632
[epoch5, step992]: loss 0.048694
[epoch5, step993]: loss 0.047181
[epoch5, step994]: loss 0.046229
[epoch5, step995]: loss 0.048520
[epoch5, step996]: loss 0.047330
[epoch5, step997]: loss 0.048011
[epoch5, step998]: loss 0.047603
[epoch5, step999]: loss 0.047214
[epoch5, step1000]: loss 0.047297
[epoch5, step1001]: loss 0.048770
[epoch5, step1002]: loss 0.047304
[epoch5, step1003]: loss 0.046416
[epoch5, step1004]: loss 0.048410
[epoch5, step1005]: loss 0.047104
[epoch5, step1006]: loss 0.047653
[epoch5, step1007]: loss 0.047076
[epoch5, step1008]: loss 0.046969
[epoch5, step1009]: loss 0.047336
[epoch5, step1010]: loss 0.049043
[epoch5, step1011]: loss 0.047015
[epoch5, step1012]: loss 0.046532
[epoch5, step1013]: loss 0.048301
[epoch5, step1014]: loss 0.047704
[epoch5, step1015]: loss 0.048024
[epoch5, step1016]: loss 0.047165
[epoch5, step1017]: loss 0.046895
[epoch5, step1018]: loss 0.047356
[epoch5, step1019]: loss 0.048866
[epoch5, step1020]: loss 0.046907
[epoch5, step1021]: loss 0.046274
[epoch5, step1022]: loss 0.048119
[epoch5, step1023]: loss 0.047337
[epoch5, step1024]: loss 0.048160
[epoch5, step1025]: loss 0.046903
[epoch5, step1026]: loss 0.046750
[epoch5, step1027]: loss 0.047188
[epoch5, step1028]: loss 0.048754
[epoch5, step1029]: loss 0.047076
[epoch5, step1030]: loss 0.046078
[epoch5, step1031]: loss 0.047724
[epoch5, step1032]: loss 0.047374
[epoch5, step1033]: loss 0.047809
[epoch5, step1034]: loss 0.047059
[epoch5, step1035]: loss 0.046771
[epoch5, step1036]: loss 0.047309
[epoch5, step1037]: loss 0.048571
[epoch5, step1038]: loss 0.046918
[epoch5, step1039]: loss 0.046421
[epoch5, step1040]: loss 0.048007
[epoch5, step1041]: loss 0.047214
[epoch5, step1042]: loss 0.047438
[epoch5, step1043]: loss 0.046957
[epoch5, step1044]: loss 0.046894
[epoch5, step1045]: loss 0.047323
[epoch5, step1046]: loss 0.048823
[epoch5, step1047]: loss 0.047190
[epoch5, step1048]: loss 0.046254
[epoch5, step1049]: loss 0.048344
[epoch5, step1050]: loss 0.047526
[epoch5, step1051]: loss 0.047804
[epoch5, step1052]: loss 0.047444
[epoch5, step1053]: loss 0.047244
[epoch5, step1054]: loss 0.047299
[epoch5, step1055]: loss 0.048567
[epoch5, step1056]: loss 0.046807
[epoch5, step1057]: loss 0.046586
[epoch5, step1058]: loss 0.048516
[epoch5, step1059]: loss 0.047628
[epoch5, step1060]: loss 0.047889
[epoch5, step1061]: loss 0.046727
[epoch5, step1062]: loss 0.047114
[epoch5, step1063]: loss 0.047250
[epoch5, step1064]: loss 0.048672
[epoch5, step1065]: loss 0.047057
[epoch5, step1066]: loss 0.046244
[epoch5, step1067]: loss 0.048246
[epoch5, step1068]: loss 0.046736
[epoch5, step1069]: loss 0.047541
[epoch5, step1070]: loss 0.047157
[epoch5, step1071]: loss 0.047039
[epoch5, step1072]: loss 0.047472
[epoch5, step1073]: loss 0.048517
[epoch5, step1074]: loss 0.046869
[epoch5, step1075]: loss 0.046504
[epoch5, step1076]: loss 0.048315
[epoch5, step1077]: loss 0.047383
[epoch5, step1078]: loss 0.047748
[epoch5, step1079]: loss 0.047573
[epoch5, step1080]: loss 0.047033
[epoch5, step1081]: loss 0.047162
[epoch5, step1082]: loss 0.048662
[epoch5, step1083]: loss 0.047354
[epoch5, step1084]: loss 0.046568
[epoch5, step1085]: loss 0.047996
[epoch5, step1086]: loss 0.047269
[epoch5, step1087]: loss 0.047804
[epoch5, step1088]: loss 0.047055
[epoch5, step1089]: loss 0.046954
[epoch5, step1090]: loss 0.047374
[epoch5, step1091]: loss 0.048941
[epoch5, step1092]: loss 0.047089
[epoch5, step1093]: loss 0.046184
[epoch5, step1094]: loss 0.047674
[epoch5, step1095]: loss 0.047088
[epoch5, step1096]: loss 0.047601
[epoch5, step1097]: loss 0.047016
[epoch5, step1098]: loss 0.046987
[epoch5, step1099]: loss 0.047176
[epoch5, step1100]: loss 0.049015
[epoch5, step1101]: loss 0.047310
[epoch5, step1102]: loss 0.046232
[epoch5, step1103]: loss 0.047986
[epoch5, step1104]: loss 0.047218
[epoch5, step1105]: loss 0.047760
[epoch5, step1106]: loss 0.046740
[epoch5, step1107]: loss 0.047029
[epoch5, step1108]: loss 0.047180
[epoch5, step1109]: loss 0.048889
[epoch5, step1110]: loss 0.047280
[epoch5, step1111]: loss 0.046469
[epoch5, step1112]: loss 0.048312
[epoch5, step1113]: loss 0.047115
[epoch5, step1114]: loss 0.047898
[epoch5, step1115]: loss 0.047110
[epoch5, step1116]: loss 0.047045
[epoch5, step1117]: loss 0.047155
[epoch5, step1118]: loss 0.048598
[epoch5, step1119]: loss 0.046892
[epoch5, step1120]: loss 0.046105
[epoch5, step1121]: loss 0.048120
[epoch5, step1122]: loss 0.046920
[epoch5, step1123]: loss 0.047499
[epoch5, step1124]: loss 0.047356
[epoch5, step1125]: loss 0.047063
[epoch5, step1126]: loss 0.047711
[epoch5, step1127]: loss 0.048612
[epoch5, step1128]: loss 0.047221
[epoch5, step1129]: loss 0.046217
[epoch5, step1130]: loss 0.048381
[epoch5, step1131]: loss 0.047322
[epoch5, step1132]: loss 0.047795
[epoch5, step1133]: loss 0.046776
[epoch5, step1134]: loss 0.046665
[epoch5, step1135]: loss 0.047659
[epoch5, step1136]: loss 0.048933
[epoch5, step1137]: loss 0.047018
[epoch5, step1138]: loss 0.046339
[epoch5, step1139]: loss 0.048248
[epoch5, step1140]: loss 0.047000
[epoch5, step1141]: loss 0.047639
[epoch5, step1142]: loss 0.046968
[epoch5, step1143]: loss 0.046837
[epoch5, step1144]: loss 0.047460
[epoch5, step1145]: loss 0.048507
[epoch5, step1146]: loss 0.046791
[epoch5, step1147]: loss 0.046747
[epoch5, step1148]: loss 0.048308
[epoch5, step1149]: loss 0.047252
[epoch5, step1150]: loss 0.047514
[epoch5, step1151]: loss 0.047275
[epoch5, step1152]: loss 0.047215
[epoch5, step1153]: loss 0.046969
[epoch5, step1154]: loss 0.048742
[epoch5, step1155]: loss 0.046973
[epoch5, step1156]: loss 0.046030
[epoch5, step1157]: loss 0.048162
[epoch5, step1158]: loss 0.047408
[epoch5, step1159]: loss 0.047672
[epoch5, step1160]: loss 0.047350
[epoch5, step1161]: loss 0.047118
[epoch5, step1162]: loss 0.047223
[epoch5, step1163]: loss 0.048328
[epoch5, step1164]: loss 0.046959
[epoch5, step1165]: loss 0.046826
[epoch5, step1166]: loss 0.048275
[epoch5, step1167]: loss 0.046929
[epoch5, step1168]: loss 0.047744
[epoch5, step1169]: loss 0.047069
[epoch5, step1170]: loss 0.046964
[epoch5, step1171]: loss 0.047145
[epoch5, step1172]: loss 0.048601
[epoch5, step1173]: loss 0.047101
[epoch5, step1174]: loss 0.046602
[epoch5, step1175]: loss 0.048105
[epoch5, step1176]: loss 0.047123
[epoch5, step1177]: loss 0.047883
[epoch5, step1178]: loss 0.047094
[epoch5, step1179]: loss 0.046826
[epoch5, step1180]: loss 0.047154
[epoch5, step1181]: loss 0.048900
[epoch5, step1182]: loss 0.046770
[epoch5, step1183]: loss 0.046559
[epoch5, step1184]: loss 0.047751
[epoch5, step1185]: loss 0.047386
[epoch5, step1186]: loss 0.047366
[epoch5, step1187]: loss 0.046752
[epoch5, step1188]: loss 0.046677
[epoch5, step1189]: loss 0.047008
[epoch5, step1190]: loss 0.048374
[epoch5, step1191]: loss 0.047266
[epoch5, step1192]: loss 0.046315
[epoch5, step1193]: loss 0.048178
[epoch5, step1194]: loss 0.047132
[epoch5, step1195]: loss 0.047201
[epoch5, step1196]: loss 0.046676
[epoch5, step1197]: loss 0.047081
[epoch5, step1198]: loss 0.047221
[epoch5, step1199]: loss 0.048446
[epoch5, step1200]: loss 0.046790
[epoch5, step1201]: loss 0.046525
[epoch5, step1202]: loss 0.048491
[epoch5, step1203]: loss 0.047243
[epoch5, step1204]: loss 0.047414
[epoch5, step1205]: loss 0.046874
[epoch5, step1206]: loss 0.046699
[epoch5, step1207]: loss 0.047236
[epoch5, step1208]: loss 0.048788
[epoch5, step1209]: loss 0.046430
[epoch5, step1210]: loss 0.046686
[epoch5, step1211]: loss 0.047881
[epoch5, step1212]: loss 0.047130
[epoch5, step1213]: loss 0.047343
[epoch5, step1214]: loss 0.047109
[epoch5, step1215]: loss 0.047213
[epoch5, step1216]: loss 0.046974
[epoch5, step1217]: loss 0.048699
[epoch5, step1218]: loss 0.046716
[epoch5, step1219]: loss 0.046465
[epoch5, step1220]: loss 0.048232
[epoch5, step1221]: loss 0.046737
[epoch5, step1222]: loss 0.047728
[epoch5, step1223]: loss 0.047059
[epoch5, step1224]: loss 0.046960
[epoch5, step1225]: loss 0.047239
[epoch5, step1226]: loss 0.048384
[epoch5, step1227]: loss 0.046945
[epoch5, step1228]: loss 0.046049
[epoch5, step1229]: loss 0.048055
[epoch5, step1230]: loss 0.047292
[epoch5, step1231]: loss 0.047414
[epoch5, step1232]: loss 0.047389
[epoch5, step1233]: loss 0.046793
[epoch5, step1234]: loss 0.046969
[epoch5, step1235]: loss 0.048716
[epoch5, step1236]: loss 0.047064
[epoch5, step1237]: loss 0.046244
[epoch5, step1238]: loss 0.047851
[epoch5, step1239]: loss 0.047327
[epoch5, step1240]: loss 0.047618
[epoch5, step1241]: loss 0.046974
[epoch5, step1242]: loss 0.046932
[epoch5, step1243]: loss 0.047045
[epoch5, step1244]: loss 0.048642
[epoch5, step1245]: loss 0.047069
[epoch5, step1246]: loss 0.046468
[epoch5, step1247]: loss 0.047704
[epoch5, step1248]: loss 0.047148
[epoch5, step1249]: loss 0.047719
[epoch5, step1250]: loss 0.046931
[epoch5, step1251]: loss 0.046823
[epoch5, step1252]: loss 0.047442
[epoch5, step1253]: loss 0.048329
[epoch5, step1254]: loss 0.046643
[epoch5, step1255]: loss 0.046015
[epoch5, step1256]: loss 0.047870
[epoch5, step1257]: loss 0.046620
[epoch5, step1258]: loss 0.046703
[epoch5, step1259]: loss 0.045271
[epoch5, step1260]: loss 0.046046
[epoch5, step1261]: loss 0.045818
[epoch5, step1262]: loss 0.046382
[epoch5, step1263]: loss 0.045404
[epoch5, step1264]: loss 0.044551
[epoch5, step1265]: loss 0.046459
[epoch5, step1266]: loss 0.045476
[epoch5, step1267]: loss 0.045592
[epoch5, step1268]: loss 0.044750
[epoch5, step1269]: loss 0.045391
[epoch5, step1270]: loss 0.045235
[epoch5, step1271]: loss 0.046985
[epoch5, step1272]: loss 0.044708
[epoch5, step1273]: loss 0.044300
[epoch5, step1274]: loss 0.046611
[epoch5, step1275]: loss 0.045770
[epoch5, step1276]: loss 0.045167
[epoch5, step1277]: loss 0.044596
[epoch5, step1278]: loss 0.045545
[epoch5, step1279]: loss 0.045635
[epoch5, step1280]: loss 0.046585
[epoch5, step1281]: loss 0.044434
[epoch5, step1282]: loss 0.044245
[epoch5, step1283]: loss 0.045949
[epoch5, step1284]: loss 0.045082
[epoch5, step1285]: loss 0.045418
[epoch5, step1286]: loss 0.043858
[epoch5, step1287]: loss 0.045710
[epoch5, step1288]: loss 0.045702
[epoch5, step1289]: loss 0.046670
[epoch5, step1290]: loss 0.044316
[epoch5, step1291]: loss 0.043943
[epoch5, step1292]: loss 0.046505
[epoch5, step1293]: loss 0.044824
[epoch5, step1294]: loss 0.044765
[epoch5, step1295]: loss 0.044354
[epoch5, step1296]: loss 0.045146
[epoch5, step1297]: loss 0.045405
[epoch5, step1298]: loss 0.046394
[epoch5, step1299]: loss 0.044412
[epoch5, step1300]: loss 0.045052
[epoch5, step1301]: loss 0.045778
[epoch5, step1302]: loss 0.045736
[epoch5, step1303]: loss 0.045535
[epoch5, step1304]: loss 0.043971
[epoch5, step1305]: loss 0.045433
[epoch5, step1306]: loss 0.045234
[epoch5, step1307]: loss 0.045781
[epoch5, step1308]: loss 0.044432
[epoch5, step1309]: loss 0.043591
[epoch5, step1310]: loss 0.046153
[epoch5, step1311]: loss 0.044446
[epoch5, step1312]: loss 0.045010
[epoch5, step1313]: loss 0.044030
[epoch5, step1314]: loss 0.044931
[epoch5, step1315]: loss 0.045124
[epoch5, step1316]: loss 0.046616
[epoch5, step1317]: loss 0.043911
[epoch5, step1318]: loss 0.043841
[epoch5, step1319]: loss 0.045801
[epoch5, step1320]: loss 0.045344
[epoch5, step1321]: loss 0.044931
[epoch5, step1322]: loss 0.044213
[epoch5, step1323]: loss 0.045488
[epoch5, step1324]: loss 0.045000
[epoch5, step1325]: loss 0.045986
[epoch5, step1326]: loss 0.043918
[epoch5, step1327]: loss 0.044144
[epoch5, step1328]: loss 0.046152
[epoch5, step1329]: loss 0.045186
[epoch5, step1330]: loss 0.044855
[epoch5, step1331]: loss 0.043860
[epoch5, step1332]: loss 0.045169
[epoch5, step1333]: loss 0.044654
[epoch5, step1334]: loss 0.046350
[epoch5, step1335]: loss 0.044229
[epoch5, step1336]: loss 0.043832
[epoch5, step1337]: loss 0.045518
[epoch5, step1338]: loss 0.044931
[epoch5, step1339]: loss 0.044740
[epoch5, step1340]: loss 0.043950
[epoch5, step1341]: loss 0.045277
[epoch5, step1342]: loss 0.044992
[epoch5, step1343]: loss 0.046295
[epoch5, step1344]: loss 0.044135
[epoch5, step1345]: loss 0.044167
[epoch5, step1346]: loss 0.045786
[epoch5, step1347]: loss 0.045393
[epoch5, step1348]: loss 0.044664
[epoch5, step1349]: loss 0.044098
[epoch5, step1350]: loss 0.045010
[epoch5, step1351]: loss 0.044897
[epoch5, step1352]: loss 0.045837
[epoch5, step1353]: loss 0.043867
[epoch5, step1354]: loss 0.043898
[epoch5, step1355]: loss 0.045984
[epoch5, step1356]: loss 0.044755
[epoch5, step1357]: loss 0.044431
[epoch5, step1358]: loss 0.043869
[epoch5, step1359]: loss 0.045101
[epoch5, step1360]: loss 0.045163
[epoch5, step1361]: loss 0.046181
[epoch5, step1362]: loss 0.044165
[epoch5, step1363]: loss 0.044172
[epoch5, step1364]: loss 0.045691
[epoch5, step1365]: loss 0.045086
[epoch5, step1366]: loss 0.044569
[epoch5, step1367]: loss 0.043630
[epoch5, step1368]: loss 0.045623
[epoch5, step1369]: loss 0.045222
[epoch5, step1370]: loss 0.045826
[epoch5, step1371]: loss 0.043923
[epoch5, step1372]: loss 0.043855
[epoch5, step1373]: loss 0.046121
[epoch5, step1374]: loss 0.045358
[epoch5, step1375]: loss 0.045157
[epoch5, step1376]: loss 0.043711
[epoch5, step1377]: loss 0.044877
[epoch5, step1378]: loss 0.045202
[epoch5, step1379]: loss 0.045912
[epoch5, step1380]: loss 0.043866
[epoch5, step1381]: loss 0.043976
[epoch5, step1382]: loss 0.046147
[epoch5, step1383]: loss 0.044979
[epoch5, step1384]: loss 0.044718
[epoch5, step1385]: loss 0.043416
[epoch5, step1386]: loss 0.045202
[epoch5, step1387]: loss 0.045186
[epoch5, step1388]: loss 0.045607
[epoch5, step1389]: loss 0.043278
[epoch5, step1390]: loss 0.043940
[epoch5, step1391]: loss 0.045907
[epoch5, step1392]: loss 0.045005
[epoch5, step1393]: loss 0.044761
[epoch5, step1394]: loss 0.044329
[epoch5, step1395]: loss 0.045261
[epoch5, step1396]: loss 0.044857
[epoch5, step1397]: loss 0.045932
[epoch5, step1398]: loss 0.043855
[epoch5, step1399]: loss 0.044393
[epoch5, step1400]: loss 0.046233
[epoch5, step1401]: loss 0.044902
[epoch5, step1402]: loss 0.044622
[epoch5, step1403]: loss 0.043259
[epoch5, step1404]: loss 0.045027
[epoch5, step1405]: loss 0.044885
[epoch5, step1406]: loss 0.045609
[epoch5, step1407]: loss 0.044427
[epoch5, step1408]: loss 0.043676
[epoch5, step1409]: loss 0.045616
[epoch5, step1410]: loss 0.044895
[epoch5, step1411]: loss 0.044051
[epoch5, step1412]: loss 0.043650
[epoch5, step1413]: loss 0.045117
[epoch5, step1414]: loss 0.044743
[epoch5, step1415]: loss 0.045742
[epoch5, step1416]: loss 0.043561
[epoch5, step1417]: loss 0.043866
[epoch5, step1418]: loss 0.045780
[epoch5, step1419]: loss 0.045367
[epoch5, step1420]: loss 0.044670
[epoch5, step1421]: loss 0.044002
[epoch5, step1422]: loss 0.045254
[epoch5, step1423]: loss 0.044660
[epoch5, step1424]: loss 0.045937
[epoch5, step1425]: loss 0.043205
[epoch5, step1426]: loss 0.044026
[epoch5, step1427]: loss 0.046317
[epoch5, step1428]: loss 0.045232
[epoch5, step1429]: loss 0.044738
[epoch5, step1430]: loss 0.043711
[epoch5, step1431]: loss 0.045469
[epoch5, step1432]: loss 0.044847
[epoch5, step1433]: loss 0.045964
[epoch5, step1434]: loss 0.043350
[epoch5, step1435]: loss 0.044039
[epoch5, step1436]: loss 0.046162
[epoch5, step1437]: loss 0.045065
[epoch5, step1438]: loss 0.044691
[epoch5, step1439]: loss 0.043674
[epoch5, step1440]: loss 0.044867
[epoch5, step1441]: loss 0.045442
[epoch5, step1442]: loss 0.045417
[epoch5, step1443]: loss 0.043625
[epoch5, step1444]: loss 0.043554
[epoch5, step1445]: loss 0.045943
[epoch5, step1446]: loss 0.044866
[epoch5, step1447]: loss 0.045022
[epoch5, step1448]: loss 0.043526
[epoch5, step1449]: loss 0.044778
[epoch5, step1450]: loss 0.044920
[epoch5, step1451]: loss 0.045998
[epoch5, step1452]: loss 0.043593
[epoch5, step1453]: loss 0.044294
[epoch5, step1454]: loss 0.046013
[epoch5, step1455]: loss 0.045361
[epoch5, step1456]: loss 0.044408
[epoch5, step1457]: loss 0.043839
[epoch5, step1458]: loss 0.045201
[epoch5, step1459]: loss 0.044775
[epoch5, step1460]: loss 0.046194
[epoch5, step1461]: loss 0.044092
[epoch5, step1462]: loss 0.044085
[epoch5, step1463]: loss 0.045841
[epoch5, step1464]: loss 0.045109
[epoch5, step1465]: loss 0.044522
[epoch5, step1466]: loss 0.043471
[epoch5, step1467]: loss 0.045043
[epoch5, step1468]: loss 0.044509
[epoch5, step1469]: loss 0.045899
[epoch5, step1470]: loss 0.043890
[epoch5, step1471]: loss 0.043461
[epoch5, step1472]: loss 0.045774
[epoch5, step1473]: loss 0.044745
[epoch5, step1474]: loss 0.045022
[epoch5, step1475]: loss 0.043476
[epoch5, step1476]: loss 0.045282
[epoch5, step1477]: loss 0.044939
[epoch5, step1478]: loss 0.045929
[epoch5, step1479]: loss 0.043638
[epoch5, step1480]: loss 0.043734
[epoch5, step1481]: loss 0.045509
[epoch5, step1482]: loss 0.044795
[epoch5, step1483]: loss 0.044596
[epoch5, step1484]: loss 0.043846
[epoch5, step1485]: loss 0.044753
[epoch5, step1486]: loss 0.044309
[epoch5, step1487]: loss 0.045931
[epoch5, step1488]: loss 0.043624
[epoch5, step1489]: loss 0.043811
[epoch5, step1490]: loss 0.045739
[epoch5, step1491]: loss 0.044857
[epoch5, step1492]: loss 0.044375
[epoch5, step1493]: loss 0.043755
[epoch5, step1494]: loss 0.045117
[epoch5, step1495]: loss 0.044709
[epoch5, step1496]: loss 0.045424
[epoch5, step1497]: loss 0.043807
[epoch5, step1498]: loss 0.043836
[epoch5, step1499]: loss 0.045521
[epoch5, step1500]: loss 0.044898
[epoch5, step1501]: loss 0.044568
[epoch5, step1502]: loss 0.043584
[epoch5, step1503]: loss 0.044923
[epoch5, step1504]: loss 0.044440
[epoch5, step1505]: loss 0.046123
[epoch5, step1506]: loss 0.043133
[epoch5, step1507]: loss 0.043903
[epoch5, step1508]: loss 0.046148
[epoch5, step1509]: loss 0.044639
[epoch5, step1510]: loss 0.044333
[epoch5, step1511]: loss 0.043910
[epoch5, step1512]: loss 0.045015
[epoch5, step1513]: loss 0.044124
[epoch5, step1514]: loss 0.045753
[epoch5, step1515]: loss 0.043726
[epoch5, step1516]: loss 0.043610

[epoch5]: avg loss 0.040756

[epoch6, step1]: loss 0.041550
[epoch6, step2]: loss 0.041578
[epoch6, step3]: loss 0.039937
[epoch6, step4]: loss 0.036957
[epoch6, step5]: loss 0.037648
[epoch6, step6]: loss 0.040120
[epoch6, step7]: loss 0.037743
[epoch6, step8]: loss 0.040048
[epoch6, step9]: loss 0.036676
[epoch6, step10]: loss 0.037712
[epoch6, step11]: loss 0.039762
[epoch6, step12]: loss 0.039572
[epoch6, step13]: loss 0.036801
[epoch6, step14]: loss 0.037251
[epoch6, step15]: loss 0.039643
[epoch6, step16]: loss 0.037422
[epoch6, step17]: loss 0.040328
[epoch6, step18]: loss 0.037644
[epoch6, step19]: loss 0.037505
[epoch6, step20]: loss 0.041354
[epoch6, step21]: loss 0.040006
[epoch6, step22]: loss 0.036415
[epoch6, step23]: loss 0.036812
[epoch6, step24]: loss 0.040075
[epoch6, step25]: loss 0.036834
[epoch6, step26]: loss 0.039481
[epoch6, step27]: loss 0.036435
[epoch6, step28]: loss 0.037440
[epoch6, step29]: loss 0.039890
[epoch6, step30]: loss 0.040297
[epoch6, step31]: loss 0.036194
[epoch6, step32]: loss 0.037371
[epoch6, step33]: loss 0.040407
[epoch6, step34]: loss 0.038098
[epoch6, step35]: loss 0.040007
[epoch6, step36]: loss 0.036656
[epoch6, step37]: loss 0.037500
[epoch6, step38]: loss 0.039537
[epoch6, step39]: loss 0.039522
[epoch6, step40]: loss 0.036985
[epoch6, step41]: loss 0.036364
[epoch6, step42]: loss 0.040006
[epoch6, step43]: loss 0.037130
[epoch6, step44]: loss 0.039823
[epoch6, step45]: loss 0.036671
[epoch6, step46]: loss 0.037412
[epoch6, step47]: loss 0.039413
[epoch6, step48]: loss 0.039228
[epoch6, step49]: loss 0.035039
[epoch6, step50]: loss 0.037146
[epoch6, step51]: loss 0.039413
[epoch6, step52]: loss 0.037293
[epoch6, step53]: loss 0.040251
[epoch6, step54]: loss 0.036492
[epoch6, step55]: loss 0.037973
[epoch6, step56]: loss 0.040512
[epoch6, step57]: loss 0.040095
[epoch6, step58]: loss 0.036585
[epoch6, step59]: loss 0.036033
[epoch6, step60]: loss 0.040216
[epoch6, step61]: loss 0.036495
[epoch6, step62]: loss 0.039032
[epoch6, step63]: loss 0.035925
[epoch6, step64]: loss 0.036853
[epoch6, step65]: loss 0.039800
[epoch6, step66]: loss 0.039492
[epoch6, step67]: loss 0.036603
[epoch6, step68]: loss 0.036873
[epoch6, step69]: loss 0.039561
[epoch6, step70]: loss 0.037080
[epoch6, step71]: loss 0.039041
[epoch6, step72]: loss 0.036604
[epoch6, step73]: loss 0.037101
[epoch6, step74]: loss 0.039796
[epoch6, step75]: loss 0.039679
[epoch6, step76]: loss 0.036968
[epoch6, step77]: loss 0.037508
[epoch6, step78]: loss 0.039781
[epoch6, step79]: loss 0.036764
[epoch6, step80]: loss 0.040256
[epoch6, step81]: loss 0.036627
[epoch6, step82]: loss 0.037098
[epoch6, step83]: loss 0.038862
[epoch6, step84]: loss 0.039842
[epoch6, step85]: loss 0.037019
[epoch6, step86]: loss 0.036995
[epoch6, step87]: loss 0.040725
[epoch6, step88]: loss 0.036076
[epoch6, step89]: loss 0.039147
[epoch6, step90]: loss 0.036895
[epoch6, step91]: loss 0.036761
[epoch6, step92]: loss 0.039753
[epoch6, step93]: loss 0.039488
[epoch6, step94]: loss 0.036289
[epoch6, step95]: loss 0.037232
[epoch6, step96]: loss 0.039371
[epoch6, step97]: loss 0.037772
[epoch6, step98]: loss 0.039406
[epoch6, step99]: loss 0.036643
[epoch6, step100]: loss 0.036249
[epoch6, step101]: loss 0.040148
[epoch6, step102]: loss 0.039512
[epoch6, step103]: loss 0.036323
[epoch6, step104]: loss 0.036943
[epoch6, step105]: loss 0.039720
[epoch6, step106]: loss 0.037137
[epoch6, step107]: loss 0.039306
[epoch6, step108]: loss 0.036871
[epoch6, step109]: loss 0.036889
[epoch6, step110]: loss 0.040225
[epoch6, step111]: loss 0.039431
[epoch6, step112]: loss 0.036574
[epoch6, step113]: loss 0.037681
[epoch6, step114]: loss 0.039505
[epoch6, step115]: loss 0.037176
[epoch6, step116]: loss 0.040165
[epoch6, step117]: loss 0.036524
[epoch6, step118]: loss 0.037740
[epoch6, step119]: loss 0.040032
[epoch6, step120]: loss 0.039685
[epoch6, step121]: loss 0.036133
[epoch6, step122]: loss 0.036731
[epoch6, step123]: loss 0.040016
[epoch6, step124]: loss 0.037373
[epoch6, step125]: loss 0.039866
[epoch6, step126]: loss 0.036502
[epoch6, step127]: loss 0.037065
[epoch6, step128]: loss 0.039522
[epoch6, step129]: loss 0.039189
[epoch6, step130]: loss 0.036500
[epoch6, step131]: loss 0.036258
[epoch6, step132]: loss 0.039839
[epoch6, step133]: loss 0.036873
[epoch6, step134]: loss 0.038964
[epoch6, step135]: loss 0.037003
[epoch6, step136]: loss 0.038137
[epoch6, step137]: loss 0.039306
[epoch6, step138]: loss 0.039447
[epoch6, step139]: loss 0.036190
[epoch6, step140]: loss 0.037259
[epoch6, step141]: loss 0.039839
[epoch6, step142]: loss 0.037021
[epoch6, step143]: loss 0.039005
[epoch6, step144]: loss 0.036857
[epoch6, step145]: loss 0.037262
[epoch6, step146]: loss 0.039733
[epoch6, step147]: loss 0.040897
[epoch6, step148]: loss 0.036186
[epoch6, step149]: loss 0.036375
[epoch6, step150]: loss 0.039336
[epoch6, step151]: loss 0.037164
[epoch6, step152]: loss 0.039508
[epoch6, step153]: loss 0.036692
[epoch6, step154]: loss 0.036654
[epoch6, step155]: loss 0.039651
[epoch6, step156]: loss 0.039209
[epoch6, step157]: loss 0.036532
[epoch6, step158]: loss 0.037009
[epoch6, step159]: loss 0.039948
[epoch6, step160]: loss 0.037396
[epoch6, step161]: loss 0.039940
[epoch6, step162]: loss 0.036830
[epoch6, step163]: loss 0.037002
[epoch6, step164]: loss 0.039966
[epoch6, step165]: loss 0.039726
[epoch6, step166]: loss 0.036688
[epoch6, step167]: loss 0.036463
[epoch6, step168]: loss 0.040286
[epoch6, step169]: loss 0.036788
[epoch6, step170]: loss 0.039832
[epoch6, step171]: loss 0.036779
[epoch6, step172]: loss 0.037183
[epoch6, step173]: loss 0.039987
[epoch6, step174]: loss 0.039413
[epoch6, step175]: loss 0.037113
[epoch6, step176]: loss 0.037148
[epoch6, step177]: loss 0.040015
[epoch6, step178]: loss 0.037139
[epoch6, step179]: loss 0.038614
[epoch6, step180]: loss 0.036977
[epoch6, step181]: loss 0.037267
[epoch6, step182]: loss 0.039945
[epoch6, step183]: loss 0.040329
[epoch6, step184]: loss 0.037357
[epoch6, step185]: loss 0.037205
[epoch6, step186]: loss 0.039885
[epoch6, step187]: loss 0.037201
[epoch6, step188]: loss 0.039266
[epoch6, step189]: loss 0.036581
[epoch6, step190]: loss 0.036647
[epoch6, step191]: loss 0.039369
[epoch6, step192]: loss 0.040079
[epoch6, step193]: loss 0.034673
[epoch6, step194]: loss 0.036056
[epoch6, step195]: loss 0.040039
[epoch6, step196]: loss 0.037147
[epoch6, step197]: loss 0.039296
[epoch6, step198]: loss 0.035772
[epoch6, step199]: loss 0.037177
[epoch6, step200]: loss 0.040153
[epoch6, step201]: loss 0.040199
[epoch6, step202]: loss 0.036133
[epoch6, step203]: loss 0.036958
[epoch6, step204]: loss 0.040149
[epoch6, step205]: loss 0.036463
[epoch6, step206]: loss 0.039228
[epoch6, step207]: loss 0.036408
[epoch6, step208]: loss 0.037515
[epoch6, step209]: loss 0.039907
[epoch6, step210]: loss 0.040517
[epoch6, step211]: loss 0.036995
[epoch6, step212]: loss 0.037308
[epoch6, step213]: loss 0.039439
[epoch6, step214]: loss 0.036547
[epoch6, step215]: loss 0.039636
[epoch6, step216]: loss 0.036894
[epoch6, step217]: loss 0.036207
[epoch6, step218]: loss 0.039938
[epoch6, step219]: loss 0.039492
[epoch6, step220]: loss 0.036726
[epoch6, step221]: loss 0.037208
[epoch6, step222]: loss 0.039906
[epoch6, step223]: loss 0.037320
[epoch6, step224]: loss 0.039214
[epoch6, step225]: loss 0.036547
[epoch6, step226]: loss 0.037016
[epoch6, step227]: loss 0.038802
[epoch6, step228]: loss 0.040195
[epoch6, step229]: loss 0.035669
[epoch6, step230]: loss 0.037157
[epoch6, step231]: loss 0.040157
[epoch6, step232]: loss 0.036605
[epoch6, step233]: loss 0.038698
[epoch6, step234]: loss 0.036201
[epoch6, step235]: loss 0.037435
[epoch6, step236]: loss 0.039821
[epoch6, step237]: loss 0.039854
[epoch6, step238]: loss 0.036211
[epoch6, step239]: loss 0.036215
[epoch6, step240]: loss 0.039325
[epoch6, step241]: loss 0.037568
[epoch6, step242]: loss 0.039380
[epoch6, step243]: loss 0.037178
[epoch6, step244]: loss 0.037015
[epoch6, step245]: loss 0.039317
[epoch6, step246]: loss 0.039655
[epoch6, step247]: loss 0.036722
[epoch6, step248]: loss 0.036538
[epoch6, step249]: loss 0.039291
[epoch6, step250]: loss 0.037199
[epoch6, step251]: loss 0.039982
[epoch6, step252]: loss 0.037141
[epoch6, step253]: loss 0.036771
[epoch6, step254]: loss 0.039037
[epoch6, step255]: loss 0.039820
[epoch6, step256]: loss 0.036205
[epoch6, step257]: loss 0.036665
[epoch6, step258]: loss 0.040409
[epoch6, step259]: loss 0.036934
[epoch6, step260]: loss 0.038925
[epoch6, step261]: loss 0.037317
[epoch6, step262]: loss 0.037482
[epoch6, step263]: loss 0.038936
[epoch6, step264]: loss 0.039343
[epoch6, step265]: loss 0.036676
[epoch6, step266]: loss 0.036830
[epoch6, step267]: loss 0.039134
[epoch6, step268]: loss 0.036973
[epoch6, step269]: loss 0.039442
[epoch6, step270]: loss 0.036242
[epoch6, step271]: loss 0.037150
[epoch6, step272]: loss 0.039681
[epoch6, step273]: loss 0.039461
[epoch6, step274]: loss 0.036912
[epoch6, step275]: loss 0.036468
[epoch6, step276]: loss 0.039353
[epoch6, step277]: loss 0.037461
[epoch6, step278]: loss 0.039629
[epoch6, step279]: loss 0.036241
[epoch6, step280]: loss 0.036925
[epoch6, step281]: loss 0.039443
[epoch6, step282]: loss 0.039996
[epoch6, step283]: loss 0.036032
[epoch6, step284]: loss 0.036293
[epoch6, step285]: loss 0.040418
[epoch6, step286]: loss 0.036265
[epoch6, step287]: loss 0.039550
[epoch6, step288]: loss 0.036207
[epoch6, step289]: loss 0.037896
[epoch6, step290]: loss 0.039777
[epoch6, step291]: loss 0.039973
[epoch6, step292]: loss 0.035648
[epoch6, step293]: loss 0.036486
[epoch6, step294]: loss 0.038941
[epoch6, step295]: loss 0.036526
[epoch6, step296]: loss 0.040187
[epoch6, step297]: loss 0.036222
[epoch6, step298]: loss 0.037471
[epoch6, step299]: loss 0.038888
[epoch6, step300]: loss 0.039889
[epoch6, step301]: loss 0.036447
[epoch6, step302]: loss 0.037162
[epoch6, step303]: loss 0.040139
[epoch6, step304]: loss 0.036610
[epoch6, step305]: loss 0.039096
[epoch6, step306]: loss 0.036631
[epoch6, step307]: loss 0.036564
[epoch6, step308]: loss 0.040191
[epoch6, step309]: loss 0.039941
[epoch6, step310]: loss 0.036582
[epoch6, step311]: loss 0.037214
[epoch6, step312]: loss 0.039488
[epoch6, step313]: loss 0.037421
[epoch6, step314]: loss 0.039427
[epoch6, step315]: loss 0.037453
[epoch6, step316]: loss 0.036835
[epoch6, step317]: loss 0.039842
[epoch6, step318]: loss 0.039747
[epoch6, step319]: loss 0.035995
[epoch6, step320]: loss 0.035850
[epoch6, step321]: loss 0.039326
[epoch6, step322]: loss 0.036862
[epoch6, step323]: loss 0.038794
[epoch6, step324]: loss 0.037156
[epoch6, step325]: loss 0.037215
[epoch6, step326]: loss 0.039417
[epoch6, step327]: loss 0.039102
[epoch6, step328]: loss 0.036602
[epoch6, step329]: loss 0.036584
[epoch6, step330]: loss 0.039425
[epoch6, step331]: loss 0.037103
[epoch6, step332]: loss 0.038887
[epoch6, step333]: loss 0.036478
[epoch6, step334]: loss 0.036935
[epoch6, step335]: loss 0.039791
[epoch6, step336]: loss 0.040510
[epoch6, step337]: loss 0.036607
[epoch6, step338]: loss 0.036339
[epoch6, step339]: loss 0.039407
[epoch6, step340]: loss 0.037338
[epoch6, step341]: loss 0.038924
[epoch6, step342]: loss 0.036238
[epoch6, step343]: loss 0.037231
[epoch6, step344]: loss 0.039244
[epoch6, step345]: loss 0.039041
[epoch6, step346]: loss 0.035933
[epoch6, step347]: loss 0.036484
[epoch6, step348]: loss 0.039786
[epoch6, step349]: loss 0.037422
[epoch6, step350]: loss 0.038921
[epoch6, step351]: loss 0.035811
[epoch6, step352]: loss 0.036921
[epoch6, step353]: loss 0.039402
[epoch6, step354]: loss 0.038687
[epoch6, step355]: loss 0.035477
[epoch6, step356]: loss 0.037371
[epoch6, step357]: loss 0.039679
[epoch6, step358]: loss 0.035681
[epoch6, step359]: loss 0.040188
[epoch6, step360]: loss 0.035462
[epoch6, step361]: loss 0.036345
[epoch6, step362]: loss 0.040106
[epoch6, step363]: loss 0.039424
[epoch6, step364]: loss 0.036229
[epoch6, step365]: loss 0.036463
[epoch6, step366]: loss 0.040051
[epoch6, step367]: loss 0.036903
[epoch6, step368]: loss 0.038806
[epoch6, step369]: loss 0.036334
[epoch6, step370]: loss 0.037573
[epoch6, step371]: loss 0.040367
[epoch6, step372]: loss 0.039235
[epoch6, step373]: loss 0.035863
[epoch6, step374]: loss 0.035979
[epoch6, step375]: loss 0.040143
[epoch6, step376]: loss 0.036913
[epoch6, step377]: loss 0.039495
[epoch6, step378]: loss 0.036832
[epoch6, step379]: loss 0.037553
[epoch6, step380]: loss 0.040076
[epoch6, step381]: loss 0.039315
[epoch6, step382]: loss 0.036644
[epoch6, step383]: loss 0.035831
[epoch6, step384]: loss 0.039054
[epoch6, step385]: loss 0.036896
[epoch6, step386]: loss 0.039519
[epoch6, step387]: loss 0.036528
[epoch6, step388]: loss 0.037676
[epoch6, step389]: loss 0.039614
[epoch6, step390]: loss 0.040350
[epoch6, step391]: loss 0.036008
[epoch6, step392]: loss 0.037188
[epoch6, step393]: loss 0.039042
[epoch6, step394]: loss 0.036938
[epoch6, step395]: loss 0.039082
[epoch6, step396]: loss 0.036570
[epoch6, step397]: loss 0.036655
[epoch6, step398]: loss 0.039700
[epoch6, step399]: loss 0.039515
[epoch6, step400]: loss 0.036083
[epoch6, step401]: loss 0.036484
[epoch6, step402]: loss 0.039273
[epoch6, step403]: loss 0.036852
[epoch6, step404]: loss 0.039635
[epoch6, step405]: loss 0.036629
[epoch6, step406]: loss 0.037206
[epoch6, step407]: loss 0.039307
[epoch6, step408]: loss 0.039607
[epoch6, step409]: loss 0.037509
[epoch6, step410]: loss 0.037272
[epoch6, step411]: loss 0.039481
[epoch6, step412]: loss 0.036406
[epoch6, step413]: loss 0.039249
[epoch6, step414]: loss 0.036089
[epoch6, step415]: loss 0.037291
[epoch6, step416]: loss 0.038966
[epoch6, step417]: loss 0.039813
[epoch6, step418]: loss 0.036197
[epoch6, step419]: loss 0.035939
[epoch6, step420]: loss 0.039831
[epoch6, step421]: loss 0.036585
[epoch6, step422]: loss 0.039291
[epoch6, step423]: loss 0.036531
[epoch6, step424]: loss 0.037159
[epoch6, step425]: loss 0.039729
[epoch6, step426]: loss 0.039938
[epoch6, step427]: loss 0.036574
[epoch6, step428]: loss 0.036516
[epoch6, step429]: loss 0.040292
[epoch6, step430]: loss 0.036745
[epoch6, step431]: loss 0.039697
[epoch6, step432]: loss 0.036356
[epoch6, step433]: loss 0.037672
[epoch6, step434]: loss 0.039527
[epoch6, step435]: loss 0.040005
[epoch6, step436]: loss 0.035964
[epoch6, step437]: loss 0.036892
[epoch6, step438]: loss 0.040156
[epoch6, step439]: loss 0.037151
[epoch6, step440]: loss 0.039283
[epoch6, step441]: loss 0.036781
[epoch6, step442]: loss 0.036909
[epoch6, step443]: loss 0.040019
[epoch6, step444]: loss 0.039434
[epoch6, step445]: loss 0.036821
[epoch6, step446]: loss 0.037144
[epoch6, step447]: loss 0.040482
[epoch6, step448]: loss 0.037087
[epoch6, step449]: loss 0.039261
[epoch6, step450]: loss 0.035788
[epoch6, step451]: loss 0.036749
[epoch6, step452]: loss 0.038429
[epoch6, step453]: loss 0.039752
[epoch6, step454]: loss 0.036266
[epoch6, step455]: loss 0.036809
[epoch6, step456]: loss 0.038684
[epoch6, step457]: loss 0.037564
[epoch6, step458]: loss 0.039051
[epoch6, step459]: loss 0.037084
[epoch6, step460]: loss 0.037116
[epoch6, step461]: loss 0.040310
[epoch6, step462]: loss 0.039012
[epoch6, step463]: loss 0.036563
[epoch6, step464]: loss 0.036603
[epoch6, step465]: loss 0.040908
[epoch6, step466]: loss 0.036784
[epoch6, step467]: loss 0.039097
[epoch6, step468]: loss 0.036381
[epoch6, step469]: loss 0.037124
[epoch6, step470]: loss 0.039865
[epoch6, step471]: loss 0.039157
[epoch6, step472]: loss 0.036788
[epoch6, step473]: loss 0.036283
[epoch6, step474]: loss 0.039655
[epoch6, step475]: loss 0.037065
[epoch6, step476]: loss 0.039862
[epoch6, step477]: loss 0.036336
[epoch6, step478]: loss 0.036564
[epoch6, step479]: loss 0.039415
[epoch6, step480]: loss 0.038674
[epoch6, step481]: loss 0.035880
[epoch6, step482]: loss 0.036059
[epoch6, step483]: loss 0.040050
[epoch6, step484]: loss 0.037147
[epoch6, step485]: loss 0.039514
[epoch6, step486]: loss 0.036861
[epoch6, step487]: loss 0.036355
[epoch6, step488]: loss 0.039961
[epoch6, step489]: loss 0.038968
[epoch6, step490]: loss 0.036699
[epoch6, step491]: loss 0.036810
[epoch6, step492]: loss 0.039352
[epoch6, step493]: loss 0.036577
[epoch6, step494]: loss 0.038835
[epoch6, step495]: loss 0.037556
[epoch6, step496]: loss 0.037001
[epoch6, step497]: loss 0.039650
[epoch6, step498]: loss 0.039272
[epoch6, step499]: loss 0.036670
[epoch6, step500]: loss 0.036245
[epoch6, step501]: loss 0.039171
[epoch6, step502]: loss 0.036755
[epoch6, step503]: loss 0.039496
[epoch6, step504]: loss 0.036243
[epoch6, step505]: loss 0.036250
[epoch6, step506]: loss 0.039970
[epoch6, step507]: loss 0.039764
[epoch6, step508]: loss 0.036895
[epoch6, step509]: loss 0.036613
[epoch6, step510]: loss 0.039800
[epoch6, step511]: loss 0.037204
[epoch6, step512]: loss 0.039716
[epoch6, step513]: loss 0.036574
[epoch6, step514]: loss 0.037306
[epoch6, step515]: loss 0.039590
[epoch6, step516]: loss 0.039981
[epoch6, step517]: loss 0.036385
[epoch6, step518]: loss 0.036721
[epoch6, step519]: loss 0.039591
[epoch6, step520]: loss 0.036406
[epoch6, step521]: loss 0.038940
[epoch6, step522]: loss 0.035856
[epoch6, step523]: loss 0.036972
[epoch6, step524]: loss 0.038920
[epoch6, step525]: loss 0.039891
[epoch6, step526]: loss 0.036503
[epoch6, step527]: loss 0.036403
[epoch6, step528]: loss 0.039878
[epoch6, step529]: loss 0.036362
[epoch6, step530]: loss 0.039778
[epoch6, step531]: loss 0.036287
[epoch6, step532]: loss 0.036500
[epoch6, step533]: loss 0.040586
[epoch6, step534]: loss 0.039496
[epoch6, step535]: loss 0.036750
[epoch6, step536]: loss 0.036722
[epoch6, step537]: loss 0.039639
[epoch6, step538]: loss 0.036977
[epoch6, step539]: loss 0.039099
[epoch6, step540]: loss 0.036044
[epoch6, step541]: loss 0.036461
[epoch6, step542]: loss 0.039546
[epoch6, step543]: loss 0.039214
[epoch6, step544]: loss 0.036270
[epoch6, step545]: loss 0.035872
[epoch6, step546]: loss 0.040201
[epoch6, step547]: loss 0.036523
[epoch6, step548]: loss 0.039241
[epoch6, step549]: loss 0.036680
[epoch6, step550]: loss 0.036945
[epoch6, step551]: loss 0.039484
[epoch6, step552]: loss 0.038978
[epoch6, step553]: loss 0.036808
[epoch6, step554]: loss 0.036422
[epoch6, step555]: loss 0.039390
[epoch6, step556]: loss 0.036768
[epoch6, step557]: loss 0.038759
[epoch6, step558]: loss 0.036657
[epoch6, step559]: loss 0.036308
[epoch6, step560]: loss 0.039590
[epoch6, step561]: loss 0.039421
[epoch6, step562]: loss 0.036340
[epoch6, step563]: loss 0.036233
[epoch6, step564]: loss 0.039236
[epoch6, step565]: loss 0.037953
[epoch6, step566]: loss 0.045505
[epoch6, step567]: loss 0.037924
[epoch6, step568]: loss 0.036397
[epoch6, step569]: loss 0.033495
[epoch6, step570]: loss 0.042378
[epoch6, step571]: loss 0.038750
[epoch6, step572]: loss 0.037973
[epoch6, step573]: loss 0.040108
[epoch6, step574]: loss 0.041763
[epoch6, step575]: loss 0.031863
[epoch6, step576]: loss 0.033539
[epoch6, step577]: loss 0.036645
[epoch6, step578]: loss 0.030102
[epoch6, step579]: loss 0.039823
[epoch6, step580]: loss 0.030852
[epoch6, step581]: loss 0.036419
[epoch6, step582]: loss 0.035601
[epoch6, step583]: loss 0.034502
[epoch6, step584]: loss 0.034297
[epoch6, step585]: loss 0.037335
[epoch6, step586]: loss 0.033872
[epoch6, step587]: loss 0.039757
[epoch6, step588]: loss 0.034696
[epoch6, step589]: loss 0.035281
[epoch6, step590]: loss 0.039126
[epoch6, step591]: loss 0.032011
[epoch6, step592]: loss 0.037070
[epoch6, step593]: loss 0.033882
[epoch6, step594]: loss 0.037327
[epoch6, step595]: loss 0.038293
[epoch6, step596]: loss 0.034871
[epoch6, step597]: loss 0.035928
[epoch6, step598]: loss 0.037962
[epoch6, step599]: loss 0.035984
[epoch6, step600]: loss 0.039187
[epoch6, step601]: loss 0.030285
[epoch6, step602]: loss 0.034221
[epoch6, step603]: loss 0.038137
[epoch6, step604]: loss 0.038548
[epoch6, step605]: loss 0.036251
[epoch6, step606]: loss 0.035757
[epoch6, step607]: loss 0.039333
[epoch6, step608]: loss 0.037045
[epoch6, step609]: loss 0.038003
[epoch6, step610]: loss 0.038240
[epoch6, step611]: loss 0.037691
[epoch6, step612]: loss 0.036641
[epoch6, step613]: loss 0.031019
[epoch6, step614]: loss 0.035799
[epoch6, step615]: loss 0.040783
[epoch6, step616]: loss 0.034991
[epoch6, step617]: loss 0.034489
[epoch6, step618]: loss 0.038044
[epoch6, step619]: loss 0.038994
[epoch6, step620]: loss 0.035562
[epoch6, step621]: loss 0.038357
[epoch6, step622]: loss 0.031763
[epoch6, step623]: loss 0.034758
[epoch6, step624]: loss 0.038045
[epoch6, step625]: loss 0.037007
[epoch6, step626]: loss 0.039167
[epoch6, step627]: loss 0.034278
[epoch6, step628]: loss 0.036554
[epoch6, step629]: loss 0.031195
[epoch6, step630]: loss 0.033101
[epoch6, step631]: loss 0.043301
[epoch6, step632]: loss 0.034894
[epoch6, step633]: loss 0.035723
[epoch6, step634]: loss 0.038486
[epoch6, step635]: loss 0.037314
[epoch6, step636]: loss 0.032155
[epoch6, step637]: loss 0.038868
[epoch6, step638]: loss 0.038733
[epoch6, step639]: loss 0.032850
[epoch6, step640]: loss 0.040626
[epoch6, step641]: loss 0.042039
[epoch6, step642]: loss 0.036334
[epoch6, step643]: loss 0.036640
[epoch6, step644]: loss 0.037339
[epoch6, step645]: loss 0.034776
[epoch6, step646]: loss 0.036765
[epoch6, step647]: loss 0.034141
[epoch6, step648]: loss 0.035396
[epoch6, step649]: loss 0.039805
[epoch6, step650]: loss 0.033797
[epoch6, step651]: loss 0.038034
[epoch6, step652]: loss 0.038069
[epoch6, step653]: loss 0.039054
[epoch6, step654]: loss 0.033843
[epoch6, step655]: loss 0.035099
[epoch6, step656]: loss 0.033896
[epoch6, step657]: loss 0.039012
[epoch6, step658]: loss 0.036361
[epoch6, step659]: loss 0.038951
[epoch6, step660]: loss 0.033928
[epoch6, step661]: loss 0.038079
[epoch6, step662]: loss 0.034848
[epoch6, step663]: loss 0.032946
[epoch6, step664]: loss 0.036854
[epoch6, step665]: loss 0.038702
[epoch6, step666]: loss 0.038049
[epoch6, step667]: loss 0.038296
[epoch6, step668]: loss 0.034348
[epoch6, step669]: loss 0.037937
[epoch6, step670]: loss 0.038709
[epoch6, step671]: loss 0.032283
[epoch6, step672]: loss 0.036250
[epoch6, step673]: loss 0.034355
[epoch6, step674]: loss 0.032091
[epoch6, step675]: loss 0.031274
[epoch6, step676]: loss 0.035612
[epoch6, step677]: loss 0.036234
[epoch6, step678]: loss 0.034008
[epoch6, step679]: loss 0.035230
[epoch6, step680]: loss 0.042655
[epoch6, step681]: loss 0.032415
[epoch6, step682]: loss 0.037470
[epoch6, step683]: loss 0.036933
[epoch6, step684]: loss 0.036586
[epoch6, step685]: loss 0.035798
[epoch6, step686]: loss 0.039251
[epoch6, step687]: loss 0.037734
[epoch6, step688]: loss 0.035330
[epoch6, step689]: loss 0.035658
[epoch6, step690]: loss 0.037026
[epoch6, step691]: loss 0.036025
[epoch6, step692]: loss 0.034470
[epoch6, step693]: loss 0.039763
[epoch6, step694]: loss 0.033496
[epoch6, step695]: loss 0.038635
[epoch6, step696]: loss 0.036428
[epoch6, step697]: loss 0.038729
[epoch6, step698]: loss 0.035814
[epoch6, step699]: loss 0.034941
[epoch6, step700]: loss 0.033089
[epoch6, step701]: loss 0.037500
[epoch6, step702]: loss 0.032299
[epoch6, step703]: loss 0.035019
[epoch6, step704]: loss 0.037709
[epoch6, step705]: loss 0.036053
[epoch6, step706]: loss 0.034668
[epoch6, step707]: loss 0.035085
[epoch6, step708]: loss 0.036523
[epoch6, step709]: loss 0.038883
[epoch6, step710]: loss 0.034328
[epoch6, step711]: loss 0.037144
[epoch6, step712]: loss 0.037875
[epoch6, step713]: loss 0.038014
[epoch6, step714]: loss 0.032815
[epoch6, step715]: loss 0.033782
[epoch6, step716]: loss 0.036741
[epoch6, step717]: loss 0.034036
[epoch6, step718]: loss 0.036650
[epoch6, step719]: loss 0.046013
[epoch6, step720]: loss 0.035881
[epoch6, step721]: loss 0.034388
[epoch6, step722]: loss 0.042932
[epoch6, step723]: loss 0.038073
[epoch6, step724]: loss 0.034282
[epoch6, step725]: loss 0.038980
[epoch6, step726]: loss 0.032987
[epoch6, step727]: loss 0.035388
[epoch6, step728]: loss 0.037768
[epoch6, step729]: loss 0.033025
[epoch6, step730]: loss 0.033825
[epoch6, step731]: loss 0.037402
[epoch6, step732]: loss 0.037138
[epoch6, step733]: loss 0.034965
[epoch6, step734]: loss 0.034322
[epoch6, step735]: loss 0.039126
[epoch6, step736]: loss 0.036156
[epoch6, step737]: loss 0.037853
[epoch6, step738]: loss 0.031067
[epoch6, step739]: loss 0.037715
[epoch6, step740]: loss 0.033973
[epoch6, step741]: loss 0.037298
[epoch6, step742]: loss 0.033881
[epoch6, step743]: loss 0.034768
[epoch6, step744]: loss 0.034858
[epoch6, step745]: loss 0.035093
[epoch6, step746]: loss 0.037443
[epoch6, step747]: loss 0.039718
[epoch6, step748]: loss 0.036774
[epoch6, step749]: loss 0.037650
[epoch6, step750]: loss 0.038929
[epoch6, step751]: loss 0.033697
[epoch6, step752]: loss 0.035876
[epoch6, step753]: loss 0.036028
[epoch6, step754]: loss 0.035007
[epoch6, step755]: loss 0.037463
[epoch6, step756]: loss 0.035067
[epoch6, step757]: loss 0.031182
[epoch6, step758]: loss 0.035094
[epoch6, step759]: loss 0.033803
[epoch6, step760]: loss 0.035008
[epoch6, step761]: loss 0.038025
[epoch6, step762]: loss 0.032566
[epoch6, step763]: loss 0.037125
[epoch6, step764]: loss 0.035757
[epoch6, step765]: loss 0.037343
[epoch6, step766]: loss 0.036852
[epoch6, step767]: loss 0.040257
[epoch6, step768]: loss 0.031968
[epoch6, step769]: loss 0.037699
[epoch6, step770]: loss 0.036701
[epoch6, step771]: loss 0.034026
[epoch6, step772]: loss 0.040021
[epoch6, step773]: loss 0.037250
[epoch6, step774]: loss 0.035593
[epoch6, step775]: loss 0.031166
[epoch6, step776]: loss 0.037512
[epoch6, step777]: loss 0.033860
[epoch6, step778]: loss 0.039106
[epoch6, step779]: loss 0.035849
[epoch6, step780]: loss 0.030839
[epoch6, step781]: loss 0.035737
[epoch6, step782]: loss 0.033743
[epoch6, step783]: loss 0.031070
[epoch6, step784]: loss 0.031826
[epoch6, step785]: loss 0.032281
[epoch6, step786]: loss 0.035368
[epoch6, step787]: loss 0.034993
[epoch6, step788]: loss 0.036635
[epoch6, step789]: loss 0.035942
[epoch6, step790]: loss 0.034332
[epoch6, step791]: loss 0.038744
[epoch6, step792]: loss 0.036372
[epoch6, step793]: loss 0.038375
[epoch6, step794]: loss 0.031348
[epoch6, step795]: loss 0.036421
[epoch6, step796]: loss 0.039540
[epoch6, step797]: loss 0.038493
[epoch6, step798]: loss 0.039028
[epoch6, step799]: loss 0.037663
[epoch6, step800]: loss 0.032769
[epoch6, step801]: loss 0.034554
[epoch6, step802]: loss 0.033929
[epoch6, step803]: loss 0.037749
[epoch6, step804]: loss 0.039166
[epoch6, step805]: loss 0.039071
[epoch6, step806]: loss 0.033003
[epoch6, step807]: loss 0.032014
[epoch6, step808]: loss 0.034895
[epoch6, step809]: loss 0.033141
[epoch6, step810]: loss 0.036949
[epoch6, step811]: loss 0.036324
[epoch6, step812]: loss 0.035520
[epoch6, step813]: loss 0.034776
[epoch6, step814]: loss 0.036691
[epoch6, step815]: loss 0.035452
[epoch6, step816]: loss 0.036076
[epoch6, step817]: loss 0.036215
[epoch6, step818]: loss 0.033087
[epoch6, step819]: loss 0.032370
[epoch6, step820]: loss 0.034872
[epoch6, step821]: loss 0.032102
[epoch6, step822]: loss 0.041720
[epoch6, step823]: loss 0.034980
[epoch6, step824]: loss 0.038074
[epoch6, step825]: loss 0.037337
[epoch6, step826]: loss 0.035215
[epoch6, step827]: loss 0.038181
[epoch6, step828]: loss 0.039945
[epoch6, step829]: loss 0.038875
[epoch6, step830]: loss 0.033695
[epoch6, step831]: loss 0.037874
[epoch6, step832]: loss 0.032770
[epoch6, step833]: loss 0.039733
[epoch6, step834]: loss 0.037880
[epoch6, step835]: loss 0.031821
[epoch6, step836]: loss 0.039564
[epoch6, step837]: loss 0.037062
[epoch6, step838]: loss 0.036540
[epoch6, step839]: loss 0.039645
[epoch6, step840]: loss 0.031643
[epoch6, step841]: loss 0.035948
[epoch6, step842]: loss 0.039025
[epoch6, step843]: loss 0.036537
[epoch6, step844]: loss 0.036400
[epoch6, step845]: loss 0.032627
[epoch6, step846]: loss 0.039165
[epoch6, step847]: loss 0.038370
[epoch6, step848]: loss 0.036088
[epoch6, step849]: loss 0.035533
[epoch6, step850]: loss 0.034544
[epoch6, step851]: loss 0.035774
[epoch6, step852]: loss 0.033539
[epoch6, step853]: loss 0.041595
[epoch6, step854]: loss 0.034724
[epoch6, step855]: loss 0.038506
[epoch6, step856]: loss 0.032407
[epoch6, step857]: loss 0.036134
[epoch6, step858]: loss 0.035489
[epoch6, step859]: loss 0.034623
[epoch6, step860]: loss 0.034106
[epoch6, step861]: loss 0.033927
[epoch6, step862]: loss 0.033571
[epoch6, step863]: loss 0.032032
[epoch6, step864]: loss 0.038408
[epoch6, step865]: loss 0.035455
[epoch6, step866]: loss 0.036341
[epoch6, step867]: loss 0.038107
[epoch6, step868]: loss 0.039021
[epoch6, step869]: loss 0.034754
[epoch6, step870]: loss 0.042690
[epoch6, step871]: loss 0.034494
[epoch6, step872]: loss 0.037275
[epoch6, step873]: loss 0.037150
[epoch6, step874]: loss 0.035349
[epoch6, step875]: loss 0.035352
[epoch6, step876]: loss 0.036145
[epoch6, step877]: loss 0.030736
[epoch6, step878]: loss 0.034270
[epoch6, step879]: loss 0.039785
[epoch6, step880]: loss 0.036575
[epoch6, step881]: loss 0.034108
[epoch6, step882]: loss 0.035044
[epoch6, step883]: loss 0.034872
[epoch6, step884]: loss 0.037860
[epoch6, step885]: loss 0.037474
[epoch6, step886]: loss 0.037744
[epoch6, step887]: loss 0.035892
[epoch6, step888]: loss 0.036238
[epoch6, step889]: loss 0.035399
[epoch6, step890]: loss 0.035627
[epoch6, step891]: loss 0.037376
[epoch6, step892]: loss 0.031042
[epoch6, step893]: loss 0.035876
[epoch6, step894]: loss 0.036031
[epoch6, step895]: loss 0.032840
[epoch6, step896]: loss 0.034192
[epoch6, step897]: loss 0.036931
[epoch6, step898]: loss 0.038009
[epoch6, step899]: loss 0.040108
[epoch6, step900]: loss 0.037749
[epoch6, step901]: loss 0.037642
[epoch6, step902]: loss 0.034655
[epoch6, step903]: loss 0.036696
[epoch6, step904]: loss 0.039038
[epoch6, step905]: loss 0.039176
[epoch6, step906]: loss 0.033279
[epoch6, step907]: loss 0.034744
[epoch6, step908]: loss 0.033732
[epoch6, step909]: loss 0.037817
[epoch6, step910]: loss 0.034302
[epoch6, step911]: loss 0.036375
[epoch6, step912]: loss 0.034462
[epoch6, step913]: loss 0.035302
[epoch6, step914]: loss 0.040895
[epoch6, step915]: loss 0.034921
[epoch6, step916]: loss 0.034388
[epoch6, step917]: loss 0.036001
[epoch6, step918]: loss 0.040840
[epoch6, step919]: loss 0.035483
[epoch6, step920]: loss 0.039072
[epoch6, step921]: loss 0.035325
[epoch6, step922]: loss 0.034823
[epoch6, step923]: loss 0.034572
[epoch6, step924]: loss 0.031445
[epoch6, step925]: loss 0.036637
[epoch6, step926]: loss 0.036508
[epoch6, step927]: loss 0.036780
[epoch6, step928]: loss 0.035490
[epoch6, step929]: loss 0.039082
[epoch6, step930]: loss 0.036573
[epoch6, step931]: loss 0.038511
[epoch6, step932]: loss 0.031889
[epoch6, step933]: loss 0.040248
[epoch6, step934]: loss 0.034095
[epoch6, step935]: loss 0.034514
[epoch6, step936]: loss 0.033296
[epoch6, step937]: loss 0.038034
[epoch6, step938]: loss 0.038980
[epoch6, step939]: loss 0.032113
[epoch6, step940]: loss 0.034945
[epoch6, step941]: loss 0.038332
[epoch6, step942]: loss 0.037338
[epoch6, step943]: loss 0.035263
[epoch6, step944]: loss 0.038825
[epoch6, step945]: loss 0.031474
[epoch6, step946]: loss 0.036923
[epoch6, step947]: loss 0.039887
[epoch6, step948]: loss 0.031504
[epoch6, step949]: loss 0.034299
[epoch6, step950]: loss 0.038212
[epoch6, step951]: loss 0.040736
[epoch6, step952]: loss 0.035755
[epoch6, step953]: loss 0.038700
[epoch6, step954]: loss 0.034068
[epoch6, step955]: loss 0.042894
[epoch6, step956]: loss 0.052801
[epoch6, step957]: loss 0.049007
[epoch6, step958]: loss 0.047127
[epoch6, step959]: loss 0.048836
[epoch6, step960]: loss 0.046061
[epoch6, step961]: loss 0.047318
[epoch6, step962]: loss 0.047190
[epoch6, step963]: loss 0.047260
[epoch6, step964]: loss 0.047471
[epoch6, step965]: loss 0.047028
[epoch6, step966]: loss 0.045312
[epoch6, step967]: loss 0.045135
[epoch6, step968]: loss 0.047649
[epoch6, step969]: loss 0.047699
[epoch6, step970]: loss 0.046827
[epoch6, step971]: loss 0.045394
[epoch6, step972]: loss 0.046203
[epoch6, step973]: loss 0.046033
[epoch6, step974]: loss 0.047713
[epoch6, step975]: loss 0.045604
[epoch6, step976]: loss 0.045289
[epoch6, step977]: loss 0.047377
[epoch6, step978]: loss 0.046052
[epoch6, step979]: loss 0.045476
[epoch6, step980]: loss 0.044886
[epoch6, step981]: loss 0.045533
[epoch6, step982]: loss 0.046000
[epoch6, step983]: loss 0.046807
[epoch6, step984]: loss 0.044635
[epoch6, step985]: loss 0.044882
[epoch6, step986]: loss 0.047382
[epoch6, step987]: loss 0.045938
[epoch6, step988]: loss 0.045864
[epoch6, step989]: loss 0.045244
[epoch6, step990]: loss 0.045184
[epoch6, step991]: loss 0.046140
[epoch6, step992]: loss 0.046358
[epoch6, step993]: loss 0.044715
[epoch6, step994]: loss 0.044382
[epoch6, step995]: loss 0.046902
[epoch6, step996]: loss 0.045425
[epoch6, step997]: loss 0.045463
[epoch6, step998]: loss 0.045032
[epoch6, step999]: loss 0.045428
[epoch6, step1000]: loss 0.045656
[epoch6, step1001]: loss 0.046309
[epoch6, step1002]: loss 0.044810
[epoch6, step1003]: loss 0.044454
[epoch6, step1004]: loss 0.046683
[epoch6, step1005]: loss 0.045028
[epoch6, step1006]: loss 0.045018
[epoch6, step1007]: loss 0.044276
[epoch6, step1008]: loss 0.045048
[epoch6, step1009]: loss 0.045443
[epoch6, step1010]: loss 0.046599
[epoch6, step1011]: loss 0.044266
[epoch6, step1012]: loss 0.044134
[epoch6, step1013]: loss 0.046381
[epoch6, step1014]: loss 0.045831
[epoch6, step1015]: loss 0.045271
[epoch6, step1016]: loss 0.044312
[epoch6, step1017]: loss 0.045046
[epoch6, step1018]: loss 0.045429
[epoch6, step1019]: loss 0.046389
[epoch6, step1020]: loss 0.044028
[epoch6, step1021]: loss 0.043927
[epoch6, step1022]: loss 0.046107
[epoch6, step1023]: loss 0.045280
[epoch6, step1024]: loss 0.045362
[epoch6, step1025]: loss 0.043826
[epoch6, step1026]: loss 0.044816
[epoch6, step1027]: loss 0.045169
[epoch6, step1028]: loss 0.046085
[epoch6, step1029]: loss 0.044140
[epoch6, step1030]: loss 0.043527
[epoch6, step1031]: loss 0.045530
[epoch6, step1032]: loss 0.045298
[epoch6, step1033]: loss 0.044834
[epoch6, step1034]: loss 0.043971
[epoch6, step1035]: loss 0.044775
[epoch6, step1036]: loss 0.045292
[epoch6, step1037]: loss 0.045852
[epoch6, step1038]: loss 0.043865
[epoch6, step1039]: loss 0.043997
[epoch6, step1040]: loss 0.045820
[epoch6, step1041]: loss 0.045117
[epoch6, step1042]: loss 0.044311
[epoch6, step1043]: loss 0.043760
[epoch6, step1044]: loss 0.044972
[epoch6, step1045]: loss 0.045215
[epoch6, step1046]: loss 0.046085
[epoch6, step1047]: loss 0.044064
[epoch6, step1048]: loss 0.043698
[epoch6, step1049]: loss 0.046162
[epoch6, step1050]: loss 0.045428
[epoch6, step1051]: loss 0.044639
[epoch6, step1052]: loss 0.044267
[epoch6, step1053]: loss 0.045338
[epoch6, step1054]: loss 0.045183
[epoch6, step1055]: loss 0.045714
[epoch6, step1056]: loss 0.043507
[epoch6, step1057]: loss 0.044144
[epoch6, step1058]: loss 0.046329
[epoch6, step1059]: loss 0.045576
[epoch6, step1060]: loss 0.044723
[epoch6, step1061]: loss 0.043302
[epoch6, step1062]: loss 0.045250
[epoch6, step1063]: loss 0.045018
[epoch6, step1064]: loss 0.045817
[epoch6, step1065]: loss 0.043686
[epoch6, step1066]: loss 0.043628
[epoch6, step1067]: loss 0.045969
[epoch6, step1068]: loss 0.044306
[epoch6, step1069]: loss 0.044244
[epoch6, step1070]: loss 0.043686
[epoch6, step1071]: loss 0.045089
[epoch6, step1072]: loss 0.045277
[epoch6, step1073]: loss 0.045495
[epoch6, step1074]: loss 0.043400
[epoch6, step1075]: loss 0.043905
[epoch6, step1076]: loss 0.046009
[epoch6, step1077]: loss 0.045128
[epoch6, step1078]: loss 0.044434
[epoch6, step1079]: loss 0.044163
[epoch6, step1080]: loss 0.045056
[epoch6, step1081]: loss 0.044903
[epoch6, step1082]: loss 0.045705
[epoch6, step1083]: loss 0.043966
[epoch6, step1084]: loss 0.044005
[epoch6, step1085]: loss 0.045636
[epoch6, step1086]: loss 0.044925
[epoch6, step1087]: loss 0.044547
[epoch6, step1088]: loss 0.043443
[epoch6, step1089]: loss 0.044893
[epoch6, step1090]: loss 0.045111
[epoch6, step1091]: loss 0.046002
[epoch6, step1092]: loss 0.043598
[epoch6, step1093]: loss 0.043326
[epoch6, step1094]: loss 0.045125
[epoch6, step1095]: loss 0.044625
[epoch6, step1096]: loss 0.044167
[epoch6, step1097]: loss 0.043440
[epoch6, step1098]: loss 0.044812
[epoch6, step1099]: loss 0.044758
[epoch6, step1100]: loss 0.046206
[epoch6, step1101]: loss 0.043777
[epoch6, step1102]: loss 0.043443
[epoch6, step1103]: loss 0.045534
[epoch6, step1104]: loss 0.044698
[epoch6, step1105]: loss 0.044378
[epoch6, step1106]: loss 0.042991
[epoch6, step1107]: loss 0.044798
[epoch6, step1108]: loss 0.044700
[epoch6, step1109]: loss 0.045888
[epoch6, step1110]: loss 0.043652
[epoch6, step1111]: loss 0.043672
[epoch6, step1112]: loss 0.045855
[epoch6, step1113]: loss 0.044572
[epoch6, step1114]: loss 0.044567
[epoch6, step1115]: loss 0.043299
[epoch6, step1116]: loss 0.044787
[epoch6, step1117]: loss 0.044603
[epoch6, step1118]: loss 0.045478
[epoch6, step1119]: loss 0.043107
[epoch6, step1120]: loss 0.043138
[epoch6, step1121]: loss 0.045596
[epoch6, step1122]: loss 0.044283
[epoch6, step1123]: loss 0.044060
[epoch6, step1124]: loss 0.043566
[epoch6, step1125]: loss 0.044782
[epoch6, step1126]: loss 0.045291
[epoch6, step1127]: loss 0.045451
[epoch6, step1128]: loss 0.043510
[epoch6, step1129]: loss 0.043265
[epoch6, step1130]: loss 0.045884
[epoch6, step1131]: loss 0.044800
[epoch6, step1132]: loss 0.044412
[epoch6, step1133]: loss 0.042841
[epoch6, step1134]: loss 0.044261
[epoch6, step1135]: loss 0.045201
[epoch6, step1136]: loss 0.045841
[epoch6, step1137]: loss 0.043248
[epoch6, step1138]: loss 0.043415
[epoch6, step1139]: loss 0.045705
[epoch6, step1140]: loss 0.044365
[epoch6, step1141]: loss 0.044242
[epoch6, step1142]: loss 0.043053
[epoch6, step1143]: loss 0.044461
[epoch6, step1144]: loss 0.044906
[epoch6, step1145]: loss 0.045308
[epoch6, step1146]: loss 0.042964
[epoch6, step1147]: loss 0.043938
[epoch6, step1148]: loss 0.045794
[epoch6, step1149]: loss 0.044664
[epoch6, step1150]: loss 0.044108
[epoch6, step1151]: loss 0.043396
[epoch6, step1152]: loss 0.044943
[epoch6, step1153]: loss 0.044253
[epoch6, step1154]: loss 0.045600
[epoch6, step1155]: loss 0.043195
[epoch6, step1156]: loss 0.043037
[epoch6, step1157]: loss 0.045664
[epoch6, step1158]: loss 0.044819
[epoch6, step1159]: loss 0.044309
[epoch6, step1160]: loss 0.043468
[epoch6, step1161]: loss 0.044808
[epoch6, step1162]: loss 0.044559
[epoch6, step1163]: loss 0.045083
[epoch6, step1164]: loss 0.043186
[epoch6, step1165]: loss 0.044051
[epoch6, step1166]: loss 0.045827
[epoch6, step1167]: loss 0.044161
[epoch6, step1168]: loss 0.044365
[epoch6, step1169]: loss 0.043124
[epoch6, step1170]: loss 0.044590
[epoch6, step1171]: loss 0.044469
[epoch6, step1172]: loss 0.045395
[epoch6, step1173]: loss 0.043354
[epoch6, step1174]: loss 0.043730
[epoch6, step1175]: loss 0.045526
[epoch6, step1176]: loss 0.044481
[epoch6, step1177]: loss 0.044569
[epoch6, step1178]: loss 0.043172
[epoch6, step1179]: loss 0.044428
[epoch6, step1180]: loss 0.044480
[epoch6, step1181]: loss 0.045790
[epoch6, step1182]: loss 0.042953
[epoch6, step1183]: loss 0.043697
[epoch6, step1184]: loss 0.045128
[epoch6, step1185]: loss 0.044795
[epoch6, step1186]: loss 0.043949
[epoch6, step1187]: loss 0.042731
[epoch6, step1188]: loss 0.044252
[epoch6, step1189]: loss 0.044279
[epoch6, step1190]: loss 0.045160
[epoch6, step1191]: loss 0.043614
[epoch6, step1192]: loss 0.043448
[epoch6, step1193]: loss 0.045826
[epoch6, step1194]: loss 0.044332
[epoch6, step1195]: loss 0.043887
[epoch6, step1196]: loss 0.042730
[epoch6, step1197]: loss 0.044884
[epoch6, step1198]: loss 0.044898
[epoch6, step1199]: loss 0.044906
[epoch6, step1200]: loss 0.043139
[epoch6, step1201]: loss 0.043323
[epoch6, step1202]: loss 0.045932
[epoch6, step1203]: loss 0.044483
[epoch6, step1204]: loss 0.043735
[epoch6, step1205]: loss 0.042970
[epoch6, step1206]: loss 0.044139
[epoch6, step1207]: loss 0.044740
[epoch6, step1208]: loss 0.045507
[epoch6, step1209]: loss 0.042737
[epoch6, step1210]: loss 0.043931
[epoch6, step1211]: loss 0.045171
[epoch6, step1212]: loss 0.044662
[epoch6, step1213]: loss 0.044018
[epoch6, step1214]: loss 0.043223
[epoch6, step1215]: loss 0.044981
[epoch6, step1216]: loss 0.044255
[epoch6, step1217]: loss 0.045627
[epoch6, step1218]: loss 0.043006
[epoch6, step1219]: loss 0.043680
[epoch6, step1220]: loss 0.046043
[epoch6, step1221]: loss 0.043884
[epoch6, step1222]: loss 0.044660
[epoch6, step1223]: loss 0.043551
[epoch6, step1224]: loss 0.044472
[epoch6, step1225]: loss 0.044793
[epoch6, step1226]: loss 0.044880
[epoch6, step1227]: loss 0.043289
[epoch6, step1228]: loss 0.042740
[epoch6, step1229]: loss 0.045417
[epoch6, step1230]: loss 0.044567
[epoch6, step1231]: loss 0.043760
[epoch6, step1232]: loss 0.043629
[epoch6, step1233]: loss 0.044270
[epoch6, step1234]: loss 0.044454
[epoch6, step1235]: loss 0.045372
[epoch6, step1236]: loss 0.043794
[epoch6, step1237]: loss 0.043777
[epoch6, step1238]: loss 0.045362
[epoch6, step1239]: loss 0.045067
[epoch6, step1240]: loss 0.045323
[epoch6, step1241]: loss 0.043519
[epoch6, step1242]: loss 0.044584
[epoch6, step1243]: loss 0.044701
[epoch6, step1244]: loss 0.045267
[epoch6, step1245]: loss 0.043600
[epoch6, step1246]: loss 0.043332
[epoch6, step1247]: loss 0.045087
[epoch6, step1248]: loss 0.044483
[epoch6, step1249]: loss 0.044307
[epoch6, step1250]: loss 0.043282
[epoch6, step1251]: loss 0.044468
[epoch6, step1252]: loss 0.045228
[epoch6, step1253]: loss 0.045352
[epoch6, step1254]: loss 0.043303
[epoch6, step1255]: loss 0.043345
[epoch6, step1256]: loss 0.045631
[epoch6, step1257]: loss 0.044660
[epoch6, step1258]: loss 0.044459
[epoch6, step1259]: loss 0.043172
[epoch6, step1260]: loss 0.044752
[epoch6, step1261]: loss 0.044381
[epoch6, step1262]: loss 0.044786
[epoch6, step1263]: loss 0.043508
[epoch6, step1264]: loss 0.043351
[epoch6, step1265]: loss 0.045204
[epoch6, step1266]: loss 0.044445
[epoch6, step1267]: loss 0.044407
[epoch6, step1268]: loss 0.042990
[epoch6, step1269]: loss 0.044505
[epoch6, step1270]: loss 0.044162
[epoch6, step1271]: loss 0.045756
[epoch6, step1272]: loss 0.043440
[epoch6, step1273]: loss 0.043275
[epoch6, step1274]: loss 0.045987
[epoch6, step1275]: loss 0.044807
[epoch6, step1276]: loss 0.044462
[epoch6, step1277]: loss 0.043635
[epoch6, step1278]: loss 0.044675
[epoch6, step1279]: loss 0.044900
[epoch6, step1280]: loss 0.045276
[epoch6, step1281]: loss 0.043259
[epoch6, step1282]: loss 0.042833
[epoch6, step1283]: loss 0.044998
[epoch6, step1284]: loss 0.044148
[epoch6, step1285]: loss 0.044203
[epoch6, step1286]: loss 0.042584
[epoch6, step1287]: loss 0.044758
[epoch6, step1288]: loss 0.044931
[epoch6, step1289]: loss 0.045609
[epoch6, step1290]: loss 0.043511
[epoch6, step1291]: loss 0.043178
[epoch6, step1292]: loss 0.045768
[epoch6, step1293]: loss 0.044231
[epoch6, step1294]: loss 0.044002
[epoch6, step1295]: loss 0.043469
[epoch6, step1296]: loss 0.044970
[epoch6, step1297]: loss 0.044454
[epoch6, step1298]: loss 0.046149
[epoch6, step1299]: loss 0.044288
[epoch6, step1300]: loss 0.043777
[epoch6, step1301]: loss 0.045155
[epoch6, step1302]: loss 0.044978
[epoch6, step1303]: loss 0.044081
[epoch6, step1304]: loss 0.043103
[epoch6, step1305]: loss 0.044545
[epoch6, step1306]: loss 0.044339
[epoch6, step1307]: loss 0.044905
[epoch6, step1308]: loss 0.043406
[epoch6, step1309]: loss 0.042685
[epoch6, step1310]: loss 0.045548
[epoch6, step1311]: loss 0.043769
[epoch6, step1312]: loss 0.044201
[epoch6, step1313]: loss 0.043044
[epoch6, step1314]: loss 0.044379
[epoch6, step1315]: loss 0.044373
[epoch6, step1316]: loss 0.045766
[epoch6, step1317]: loss 0.043151
[epoch6, step1318]: loss 0.043037
[epoch6, step1319]: loss 0.045144
[epoch6, step1320]: loss 0.044651
[epoch6, step1321]: loss 0.044269
[epoch6, step1322]: loss 0.043317
[epoch6, step1323]: loss 0.045108
[epoch6, step1324]: loss 0.044356
[epoch6, step1325]: loss 0.045655
[epoch6, step1326]: loss 0.044225
[epoch6, step1327]: loss 0.043326
[epoch6, step1328]: loss 0.045606
[epoch6, step1329]: loss 0.044720
[epoch6, step1330]: loss 0.044035
[epoch6, step1331]: loss 0.042915
[epoch6, step1332]: loss 0.044420
[epoch6, step1333]: loss 0.043929
[epoch6, step1334]: loss 0.045373
[epoch6, step1335]: loss 0.043434
[epoch6, step1336]: loss 0.042763
[epoch6, step1337]: loss 0.044984
[epoch6, step1338]: loss 0.044112
[epoch6, step1339]: loss 0.043954
[epoch6, step1340]: loss 0.043014
[epoch6, step1341]: loss 0.044473
[epoch6, step1342]: loss 0.044503
[epoch6, step1343]: loss 0.045427
[epoch6, step1344]: loss 0.043729
[epoch6, step1345]: loss 0.043918
[epoch6, step1346]: loss 0.045413
[epoch6, step1347]: loss 0.044866
[epoch6, step1348]: loss 0.044759
[epoch6, step1349]: loss 0.043285
[epoch6, step1350]: loss 0.044485
[epoch6, step1351]: loss 0.044661
[epoch6, step1352]: loss 0.044929
[epoch6, step1353]: loss 0.043346
[epoch6, step1354]: loss 0.042914
[epoch6, step1355]: loss 0.045437
[epoch6, step1356]: loss 0.044084
[epoch6, step1357]: loss 0.043622
[epoch6, step1358]: loss 0.042886
[epoch6, step1359]: loss 0.044301
[epoch6, step1360]: loss 0.044485
[epoch6, step1361]: loss 0.045306
[epoch6, step1362]: loss 0.043561
[epoch6, step1363]: loss 0.043277
[epoch6, step1364]: loss 0.045222
[epoch6, step1365]: loss 0.044493
[epoch6, step1366]: loss 0.043787
[epoch6, step1367]: loss 0.043018
[epoch6, step1368]: loss 0.044967
[epoch6, step1369]: loss 0.044806
[epoch6, step1370]: loss 0.045754
[epoch6, step1371]: loss 0.043402
[epoch6, step1372]: loss 0.043331
[epoch6, step1373]: loss 0.046322
[epoch6, step1374]: loss 0.044969
[epoch6, step1375]: loss 0.044516
[epoch6, step1376]: loss 0.043022
[epoch6, step1377]: loss 0.044079
[epoch6, step1378]: loss 0.044649
[epoch6, step1379]: loss 0.045042
[epoch6, step1380]: loss 0.043206
[epoch6, step1381]: loss 0.043014
[epoch6, step1382]: loss 0.045595
[epoch6, step1383]: loss 0.044342
[epoch6, step1384]: loss 0.043909
[epoch6, step1385]: loss 0.042760
[epoch6, step1386]: loss 0.044471
[epoch6, step1387]: loss 0.044777
[epoch6, step1388]: loss 0.045232
[epoch6, step1389]: loss 0.042631
[epoch6, step1390]: loss 0.043426
[epoch6, step1391]: loss 0.045717
[epoch6, step1392]: loss 0.044322
[epoch6, step1393]: loss 0.044484
[epoch6, step1394]: loss 0.043689
[epoch6, step1395]: loss 0.044597
[epoch6, step1396]: loss 0.044362
[epoch6, step1397]: loss 0.045199
[epoch6, step1398]: loss 0.043256
[epoch6, step1399]: loss 0.043570
[epoch6, step1400]: loss 0.045732
[epoch6, step1401]: loss 0.044339
[epoch6, step1402]: loss 0.043938
[epoch6, step1403]: loss 0.042699
[epoch6, step1404]: loss 0.044567
[epoch6, step1405]: loss 0.044286
[epoch6, step1406]: loss 0.045364
[epoch6, step1407]: loss 0.044277
[epoch6, step1408]: loss 0.042729
[epoch6, step1409]: loss 0.045221
[epoch6, step1410]: loss 0.044252
[epoch6, step1411]: loss 0.043492
[epoch6, step1412]: loss 0.042888
[epoch6, step1413]: loss 0.044475
[epoch6, step1414]: loss 0.044141
[epoch6, step1415]: loss 0.045214
[epoch6, step1416]: loss 0.043021
[epoch6, step1417]: loss 0.043237
[epoch6, step1418]: loss 0.045559
[epoch6, step1419]: loss 0.044729
[epoch6, step1420]: loss 0.044356
[epoch6, step1421]: loss 0.043361
[epoch6, step1422]: loss 0.044645
[epoch6, step1423]: loss 0.044234
[epoch6, step1424]: loss 0.045201
[epoch6, step1425]: loss 0.042638
[epoch6, step1426]: loss 0.043214
[epoch6, step1427]: loss 0.045798
[epoch6, step1428]: loss 0.044720
[epoch6, step1429]: loss 0.044030
[epoch6, step1430]: loss 0.043326
[epoch6, step1431]: loss 0.045165
[epoch6, step1432]: loss 0.044323
[epoch6, step1433]: loss 0.045926
[epoch6, step1434]: loss 0.043701
[epoch6, step1435]: loss 0.043266
[epoch6, step1436]: loss 0.045923
[epoch6, step1437]: loss 0.044973
[epoch6, step1438]: loss 0.044078
[epoch6, step1439]: loss 0.043096
[epoch6, step1440]: loss 0.044346
[epoch6, step1441]: loss 0.044877
[epoch6, step1442]: loss 0.044668
[epoch6, step1443]: loss 0.043175
[epoch6, step1444]: loss 0.042616
[epoch6, step1445]: loss 0.045680
[epoch6, step1446]: loss 0.044456
[epoch6, step1447]: loss 0.044260
[epoch6, step1448]: loss 0.043209
[epoch6, step1449]: loss 0.044185
[epoch6, step1450]: loss 0.044567
[epoch6, step1451]: loss 0.045943
[epoch6, step1452]: loss 0.043147
[epoch6, step1453]: loss 0.043980
[epoch6, step1454]: loss 0.046316
[epoch6, step1455]: loss 0.045146
[epoch6, step1456]: loss 0.043799
[epoch6, step1457]: loss 0.043315
[epoch6, step1458]: loss 0.044507
[epoch6, step1459]: loss 0.044295
[epoch6, step1460]: loss 0.045421
[epoch6, step1461]: loss 0.043522
[epoch6, step1462]: loss 0.043284
[epoch6, step1463]: loss 0.045337
[epoch6, step1464]: loss 0.044656
[epoch6, step1465]: loss 0.043733
[epoch6, step1466]: loss 0.043057
[epoch6, step1467]: loss 0.044465
[epoch6, step1468]: loss 0.044161
[epoch6, step1469]: loss 0.045723
[epoch6, step1470]: loss 0.043387
[epoch6, step1471]: loss 0.043248
[epoch6, step1472]: loss 0.046067
[epoch6, step1473]: loss 0.044525
[epoch6, step1474]: loss 0.044475
[epoch6, step1475]: loss 0.043102
[epoch6, step1476]: loss 0.044614
[epoch6, step1477]: loss 0.044533
[epoch6, step1478]: loss 0.045116
[epoch6, step1479]: loss 0.043087
[epoch6, step1480]: loss 0.042931
[epoch6, step1481]: loss 0.045014
[epoch6, step1482]: loss 0.044314
[epoch6, step1483]: loss 0.043833
[epoch6, step1484]: loss 0.043338
[epoch6, step1485]: loss 0.044106
[epoch6, step1486]: loss 0.043982
[epoch6, step1487]: loss 0.045410
[epoch6, step1488]: loss 0.043089
[epoch6, step1489]: loss 0.043368
[epoch6, step1490]: loss 0.045301
[epoch6, step1491]: loss 0.044610
[epoch6, step1492]: loss 0.044151
[epoch6, step1493]: loss 0.043129
[epoch6, step1494]: loss 0.044781
[epoch6, step1495]: loss 0.044466
[epoch6, step1496]: loss 0.044724
[epoch6, step1497]: loss 0.043345
[epoch6, step1498]: loss 0.043209
[epoch6, step1499]: loss 0.045107
[epoch6, step1500]: loss 0.044500
[epoch6, step1501]: loss 0.044005
[epoch6, step1502]: loss 0.043027
[epoch6, step1503]: loss 0.044396
[epoch6, step1504]: loss 0.044009
[epoch6, step1505]: loss 0.045568
[epoch6, step1506]: loss 0.042596
[epoch6, step1507]: loss 0.043444
[epoch6, step1508]: loss 0.045780
[epoch6, step1509]: loss 0.044256
[epoch6, step1510]: loss 0.043864
[epoch6, step1511]: loss 0.043334
[epoch6, step1512]: loss 0.044597
[epoch6, step1513]: loss 0.043654
[epoch6, step1514]: loss 0.045295
[epoch6, step1515]: loss 0.043339
[epoch6, step1516]: loss 0.043109

[epoch6]: avg loss 0.039970

[epoch7, step1]: loss 0.042818
[epoch7, step2]: loss 0.039186
[epoch7, step3]: loss 0.039315
[epoch7, step4]: loss 0.036636
[epoch7, step5]: loss 0.036800
[epoch7, step6]: loss 0.039474
[epoch7, step7]: loss 0.037251
[epoch7, step8]: loss 0.039269
[epoch7, step9]: loss 0.036100
[epoch7, step10]: loss 0.037178
[epoch7, step11]: loss 0.039335
[epoch7, step12]: loss 0.039118
[epoch7, step13]: loss 0.036338
[epoch7, step14]: loss 0.036738
[epoch7, step15]: loss 0.039235
[epoch7, step16]: loss 0.036989
[epoch7, step17]: loss 0.039531
[epoch7, step18]: loss 0.037230
[epoch7, step19]: loss 0.037163
[epoch7, step20]: loss 0.040049
[epoch7, step21]: loss 0.039375
[epoch7, step22]: loss 0.035980
[epoch7, step23]: loss 0.035912
[epoch7, step24]: loss 0.039420
[epoch7, step25]: loss 0.036324
[epoch7, step26]: loss 0.038760
[epoch7, step27]: loss 0.035943
[epoch7, step28]: loss 0.036952
[epoch7, step29]: loss 0.039474
[epoch7, step30]: loss 0.039606
[epoch7, step31]: loss 0.035817
[epoch7, step32]: loss 0.036783
[epoch7, step33]: loss 0.039878
[epoch7, step34]: loss 0.037474
[epoch7, step35]: loss 0.039379
[epoch7, step36]: loss 0.036165
[epoch7, step37]: loss 0.036856
[epoch7, step38]: loss 0.039011
[epoch7, step39]: loss 0.039076
[epoch7, step40]: loss 0.036430
[epoch7, step41]: loss 0.035995
[epoch7, step42]: loss 0.039556
[epoch7, step43]: loss 0.036770
[epoch7, step44]: loss 0.039492
[epoch7, step45]: loss 0.036246
[epoch7, step46]: loss 0.037056
[epoch7, step47]: loss 0.038886
[epoch7, step48]: loss 0.038876
[epoch7, step49]: loss 0.034682
[epoch7, step50]: loss 0.036578
[epoch7, step51]: loss 0.039089
[epoch7, step52]: loss 0.036677
[epoch7, step53]: loss 0.039798
[epoch7, step54]: loss 0.036015
[epoch7, step55]: loss 0.037276
[epoch7, step56]: loss 0.040136
[epoch7, step57]: loss 0.039560
[epoch7, step58]: loss 0.036155
[epoch7, step59]: loss 0.035589
[epoch7, step60]: loss 0.039693
[epoch7, step61]: loss 0.036149
[epoch7, step62]: loss 0.038624
[epoch7, step63]: loss 0.035554
[epoch7, step64]: loss 0.036475
[epoch7, step65]: loss 0.039377
[epoch7, step66]: loss 0.039163
[epoch7, step67]: loss 0.036288
[epoch7, step68]: loss 0.036493
[epoch7, step69]: loss 0.039258
[epoch7, step70]: loss 0.036646
[epoch7, step71]: loss 0.038776
[epoch7, step72]: loss 0.036174
[epoch7, step73]: loss 0.036674
[epoch7, step74]: loss 0.039391
[epoch7, step75]: loss 0.039241
[epoch7, step76]: loss 0.036654
[epoch7, step77]: loss 0.036990
[epoch7, step78]: loss 0.039435
[epoch7, step79]: loss 0.036248
[epoch7, step80]: loss 0.039831
[epoch7, step81]: loss 0.036183
[epoch7, step82]: loss 0.036552
[epoch7, step83]: loss 0.038478
[epoch7, step84]: loss 0.039391
[epoch7, step85]: loss 0.036678
[epoch7, step86]: loss 0.036573
[epoch7, step87]: loss 0.040350
[epoch7, step88]: loss 0.035692
[epoch7, step89]: loss 0.038805
[epoch7, step90]: loss 0.036517
[epoch7, step91]: loss 0.036346
[epoch7, step92]: loss 0.039426
[epoch7, step93]: loss 0.039081
[epoch7, step94]: loss 0.035980
[epoch7, step95]: loss 0.036816
[epoch7, step96]: loss 0.039064
[epoch7, step97]: loss 0.037371
[epoch7, step98]: loss 0.039057
[epoch7, step99]: loss 0.036223
[epoch7, step100]: loss 0.035898
[epoch7, step101]: loss 0.039754
[epoch7, step102]: loss 0.039143
[epoch7, step103]: loss 0.036028
[epoch7, step104]: loss 0.036511
[epoch7, step105]: loss 0.039487
[epoch7, step106]: loss 0.036681
[epoch7, step107]: loss 0.039025
[epoch7, step108]: loss 0.036365
[epoch7, step109]: loss 0.036452
[epoch7, step110]: loss 0.039887
[epoch7, step111]: loss 0.038952
[epoch7, step112]: loss 0.036310
[epoch7, step113]: loss 0.037177
[epoch7, step114]: loss 0.039202
[epoch7, step115]: loss 0.036756
[epoch7, step116]: loss 0.039744
[epoch7, step117]: loss 0.036142
[epoch7, step118]: loss 0.037325
[epoch7, step119]: loss 0.039690
[epoch7, step120]: loss 0.039276
[epoch7, step121]: loss 0.035868
[epoch7, step122]: loss 0.036314
[epoch7, step123]: loss 0.039739
[epoch7, step124]: loss 0.036987
[epoch7, step125]: loss 0.039516
[epoch7, step126]: loss 0.036087
[epoch7, step127]: loss 0.036658
[epoch7, step128]: loss 0.039193
[epoch7, step129]: loss 0.038763
[epoch7, step130]: loss 0.036248
[epoch7, step131]: loss 0.035825
[epoch7, step132]: loss 0.039556
[epoch7, step133]: loss 0.036493
[epoch7, step134]: loss 0.038599
[epoch7, step135]: loss 0.036651
[epoch7, step136]: loss 0.037756
[epoch7, step137]: loss 0.039005
[epoch7, step138]: loss 0.039047
[epoch7, step139]: loss 0.035947
[epoch7, step140]: loss 0.036836
[epoch7, step141]: loss 0.039569
[epoch7, step142]: loss 0.036642
[epoch7, step143]: loss 0.038670
[epoch7, step144]: loss 0.036440
[epoch7, step145]: loss 0.036857
[epoch7, step146]: loss 0.039394
[epoch7, step147]: loss 0.040456
[epoch7, step148]: loss 0.035955
[epoch7, step149]: loss 0.035957
[epoch7, step150]: loss 0.039060
[epoch7, step151]: loss 0.036792
[epoch7, step152]: loss 0.039135
[epoch7, step153]: loss 0.036377
[epoch7, step154]: loss 0.036302
[epoch7, step155]: loss 0.039354
[epoch7, step156]: loss 0.038838
[epoch7, step157]: loss 0.036292
[epoch7, step158]: loss 0.036617
[epoch7, step159]: loss 0.039688
[epoch7, step160]: loss 0.037032
[epoch7, step161]: loss 0.039622
[epoch7, step162]: loss 0.036409
[epoch7, step163]: loss 0.036607
[epoch7, step164]: loss 0.039630
[epoch7, step165]: loss 0.039306
[epoch7, step166]: loss 0.036472
[epoch7, step167]: loss 0.036034
[epoch7, step168]: loss 0.040008
[epoch7, step169]: loss 0.036409
[epoch7, step170]: loss 0.039434
[epoch7, step171]: loss 0.036482
[epoch7, step172]: loss 0.036825
[epoch7, step173]: loss 0.039692
[epoch7, step174]: loss 0.039042
[epoch7, step175]: loss 0.036881
[epoch7, step176]: loss 0.036759
[epoch7, step177]: loss 0.039761
[epoch7, step178]: loss 0.036783
[epoch7, step179]: loss 0.038320
[epoch7, step180]: loss 0.036573
[epoch7, step181]: loss 0.036888
[epoch7, step182]: loss 0.039627
[epoch7, step183]: loss 0.039902
[epoch7, step184]: loss 0.037153
[epoch7, step185]: loss 0.036744
[epoch7, step186]: loss 0.039596
[epoch7, step187]: loss 0.036828
[epoch7, step188]: loss 0.038873
[epoch7, step189]: loss 0.036277
[epoch7, step190]: loss 0.036300
[epoch7, step191]: loss 0.039067
[epoch7, step192]: loss 0.039716
[epoch7, step193]: loss 0.034478
[epoch7, step194]: loss 0.035673
[epoch7, step195]: loss 0.039794
[epoch7, step196]: loss 0.036789
[epoch7, step197]: loss 0.038996
[epoch7, step198]: loss 0.035401
[epoch7, step199]: loss 0.036783
[epoch7, step200]: loss 0.039844
[epoch7, step201]: loss 0.039777
[epoch7, step202]: loss 0.035925
[epoch7, step203]: loss 0.036535
[epoch7, step204]: loss 0.039872
[epoch7, step205]: loss 0.036109
[epoch7, step206]: loss 0.038850
[epoch7, step207]: loss 0.036127
[epoch7, step208]: loss 0.037164
[epoch7, step209]: loss 0.039621
[epoch7, step210]: loss 0.040140
[epoch7, step211]: loss 0.036790
[epoch7, step212]: loss 0.036916
[epoch7, step213]: loss 0.039212
[epoch7, step214]: loss 0.036196
[epoch7, step215]: loss 0.039347
[epoch7, step216]: loss 0.036515
[epoch7, step217]: loss 0.035853
[epoch7, step218]: loss 0.039656
[epoch7, step219]: loss 0.039078
[epoch7, step220]: loss 0.036531
[epoch7, step221]: loss 0.036745
[epoch7, step222]: loss 0.039618
[epoch7, step223]: loss 0.036960
[epoch7, step224]: loss 0.038820
[epoch7, step225]: loss 0.036253
[epoch7, step226]: loss 0.036668
[epoch7, step227]: loss 0.038511
[epoch7, step228]: loss 0.039838
[epoch7, step229]: loss 0.035467
[epoch7, step230]: loss 0.036773
[epoch7, step231]: loss 0.039914
[epoch7, step232]: loss 0.036268
[epoch7, step233]: loss 0.038410
[epoch7, step234]: loss 0.035847
[epoch7, step235]: loss 0.037069
[epoch7, step236]: loss 0.039537
[epoch7, step237]: loss 0.039444
[epoch7, step238]: loss 0.036030
[epoch7, step239]: loss 0.035772
[epoch7, step240]: loss 0.039051
[epoch7, step241]: loss 0.037207
[epoch7, step242]: loss 0.038984
[epoch7, step243]: loss 0.036885
[epoch7, step244]: loss 0.036671
[epoch7, step245]: loss 0.039026
[epoch7, step246]: loss 0.039305
[epoch7, step247]: loss 0.036511
[epoch7, step248]: loss 0.036169
[epoch7, step249]: loss 0.039069
[epoch7, step250]: loss 0.036848
[epoch7, step251]: loss 0.039689
[epoch7, step252]: loss 0.036776
[epoch7, step253]: loss 0.036425
[epoch7, step254]: loss 0.038771
[epoch7, step255]: loss 0.039400
[epoch7, step256]: loss 0.036014
[epoch7, step257]: loss 0.036223
[epoch7, step258]: loss 0.040120
[epoch7, step259]: loss 0.036588
[epoch7, step260]: loss 0.038530
[epoch7, step261]: loss 0.037030
[epoch7, step262]: loss 0.037140
[epoch7, step263]: loss 0.038659
[epoch7, step264]: loss 0.039006
[epoch7, step265]: loss 0.036477
[epoch7, step266]: loss 0.036459
[epoch7, step267]: loss 0.038919
[epoch7, step268]: loss 0.036629
[epoch7, step269]: loss 0.039147
[epoch7, step270]: loss 0.035906
[epoch7, step271]: loss 0.036792
[epoch7, step272]: loss 0.039411
[epoch7, step273]: loss 0.039055
[epoch7, step274]: loss 0.036713
[epoch7, step275]: loss 0.036036
[epoch7, step276]: loss 0.039069
[epoch7, step277]: loss 0.037124
[epoch7, step278]: loss 0.039232
[epoch7, step279]: loss 0.035970
[epoch7, step280]: loss 0.036592
[epoch7, step281]: loss 0.039157
[epoch7, step282]: loss 0.039664
[epoch7, step283]: loss 0.035844
[epoch7, step284]: loss 0.035932
[epoch7, step285]: loss 0.040190
[epoch7, step286]: loss 0.035931
[epoch7, step287]: loss 0.039249
[epoch7, step288]: loss 0.035887
[epoch7, step289]: loss 0.037534
[epoch7, step290]: loss 0.039516
[epoch7, step291]: loss 0.039564
[epoch7, step292]: loss 0.035462
[epoch7, step293]: loss 0.036057
[epoch7, step294]: loss 0.038674
[epoch7, step295]: loss 0.036201
[epoch7, step296]: loss 0.039792
[epoch7, step297]: loss 0.035952
[epoch7, step298]: loss 0.037130
[epoch7, step299]: loss 0.038619
[epoch7, step300]: loss 0.039544
[epoch7, step301]: loss 0.036248
[epoch7, step302]: loss 0.036784
[epoch7, step303]: loss 0.039909
[epoch7, step304]: loss 0.036276
[epoch7, step305]: loss 0.038793
[epoch7, step306]: loss 0.036308
[epoch7, step307]: loss 0.036228
[epoch7, step308]: loss 0.039927
[epoch7, step309]: loss 0.039554
[epoch7, step310]: loss 0.036408
[epoch7, step311]: loss 0.036756
[epoch7, step312]: loss 0.039210
[epoch7, step313]: loss 0.037079
[epoch7, step314]: loss 0.039021
[epoch7, step315]: loss 0.037166
[epoch7, step316]: loss 0.036505
[epoch7, step317]: loss 0.039549
[epoch7, step318]: loss 0.039422
[epoch7, step319]: loss 0.035808
[epoch7, step320]: loss 0.035495
[epoch7, step321]: loss 0.039112
[epoch7, step322]: loss 0.036525
[epoch7, step323]: loss 0.038492
[epoch7, step324]: loss 0.036849
[epoch7, step325]: loss 0.036876
[epoch7, step326]: loss 0.039174
[epoch7, step327]: loss 0.038718
[epoch7, step328]: loss 0.036412
[epoch7, step329]: loss 0.036161
[epoch7, step330]: loss 0.039157
[epoch7, step331]: loss 0.036774
[epoch7, step332]: loss 0.038511
[epoch7, step333]: loss 0.036203
[epoch7, step334]: loss 0.036606
[epoch7, step335]: loss 0.039511
[epoch7, step336]: loss 0.040168
[epoch7, step337]: loss 0.036429
[epoch7, step338]: loss 0.035948
[epoch7, step339]: loss 0.039173
[epoch7, step340]: loss 0.036998
[epoch7, step341]: loss 0.038588
[epoch7, step342]: loss 0.035942
[epoch7, step343]: loss 0.036885
[epoch7, step344]: loss 0.038977
[epoch7, step345]: loss 0.038673
[epoch7, step346]: loss 0.035732
[epoch7, step347]: loss 0.036086
[epoch7, step348]: loss 0.039519
[epoch7, step349]: loss 0.037102
[epoch7, step350]: loss 0.038565
[epoch7, step351]: loss 0.035541
[epoch7, step352]: loss 0.036592
[epoch7, step353]: loss 0.039142
[epoch7, step354]: loss 0.038360
[epoch7, step355]: loss 0.035304
[epoch7, step356]: loss 0.036964
[epoch7, step357]: loss 0.039440
[epoch7, step358]: loss 0.035368
[epoch7, step359]: loss 0.039832
[epoch7, step360]: loss 0.035188
[epoch7, step361]: loss 0.036010
[epoch7, step362]: loss 0.039837
[epoch7, step363]: loss 0.039074
[epoch7, step364]: loss 0.036043
[epoch7, step365]: loss 0.036062
[epoch7, step366]: loss 0.039794
[epoch7, step367]: loss 0.036578
[epoch7, step368]: loss 0.038441
[epoch7, step369]: loss 0.036066
[epoch7, step370]: loss 0.037235
[epoch7, step371]: loss 0.040097
[epoch7, step372]: loss 0.038898
[epoch7, step373]: loss 0.035686
[epoch7, step374]: loss 0.035588
[epoch7, step375]: loss 0.039903
[epoch7, step376]: loss 0.036580
[epoch7, step377]: loss 0.039133
[epoch7, step378]: loss 0.036549
[epoch7, step379]: loss 0.037213
[epoch7, step380]: loss 0.039815
[epoch7, step381]: loss 0.038963
[epoch7, step382]: loss 0.036456
[epoch7, step383]: loss 0.035431
[epoch7, step384]: loss 0.038805
[epoch7, step385]: loss 0.036575
[epoch7, step386]: loss 0.039137
[epoch7, step387]: loss 0.036268
[epoch7, step388]: loss 0.037340
[epoch7, step389]: loss 0.039358
[epoch7, step390]: loss 0.040005
[epoch7, step391]: loss 0.035824
[epoch7, step392]: loss 0.036794
[epoch7, step393]: loss 0.038804
[epoch7, step394]: loss 0.036629
[epoch7, step395]: loss 0.038744
[epoch7, step396]: loss 0.036282
[epoch7, step397]: loss 0.036342
[epoch7, step398]: loss 0.039444
[epoch7, step399]: loss 0.039172
[epoch7, step400]: loss 0.035920
[epoch7, step401]: loss 0.036058
[epoch7, step402]: loss 0.039021
[epoch7, step403]: loss 0.036532
[epoch7, step404]: loss 0.039230
[epoch7, step405]: loss 0.036372
[epoch7, step406]: loss 0.036872
[epoch7, step407]: loss 0.039045
[epoch7, step408]: loss 0.039276
[epoch7, step409]: loss 0.037301
[epoch7, step410]: loss 0.036897
[epoch7, step411]: loss 0.039257
[epoch7, step412]: loss 0.036095
[epoch7, step413]: loss 0.038894
[epoch7, step414]: loss 0.035848
[epoch7, step415]: loss 0.036967
[epoch7, step416]: loss 0.038747
[epoch7, step417]: loss 0.039451
[epoch7, step418]: loss 0.036000
[epoch7, step419]: loss 0.035559
[epoch7, step420]: loss 0.039586
[epoch7, step421]: loss 0.036283
[epoch7, step422]: loss 0.038925
[epoch7, step423]: loss 0.036271
[epoch7, step424]: loss 0.036843
[epoch7, step425]: loss 0.039496
[epoch7, step426]: loss 0.039602
[epoch7, step427]: loss 0.036402
[epoch7, step428]: loss 0.036102
[epoch7, step429]: loss 0.040031
[epoch7, step430]: loss 0.036433
[epoch7, step431]: loss 0.039282
[epoch7, step432]: loss 0.036109
[epoch7, step433]: loss 0.037344
[epoch7, step434]: loss 0.039275
[epoch7, step435]: loss 0.039676
[epoch7, step436]: loss 0.035772
[epoch7, step437]: loss 0.036518
[epoch7, step438]: loss 0.039908
[epoch7, step439]: loss 0.036859
[epoch7, step440]: loss 0.038917
[epoch7, step441]: loss 0.036523
[epoch7, step442]: loss 0.036607
[epoch7, step443]: loss 0.039796
[epoch7, step444]: loss 0.039115
[epoch7, step445]: loss 0.036659
[epoch7, step446]: loss 0.036706
[epoch7, step447]: loss 0.040213
[epoch7, step448]: loss 0.036773
[epoch7, step449]: loss 0.038824
[epoch7, step450]: loss 0.035551
[epoch7, step451]: loss 0.036424
[epoch7, step452]: loss 0.038171
[epoch7, step453]: loss 0.039443
[epoch7, step454]: loss 0.036050
[epoch7, step455]: loss 0.036471
[epoch7, step456]: loss 0.038478
[epoch7, step457]: loss 0.037271
[epoch7, step458]: loss 0.038727
[epoch7, step459]: loss 0.036836
[epoch7, step460]: loss 0.036815
[epoch7, step461]: loss 0.040112
[epoch7, step462]: loss 0.038680
[epoch7, step463]: loss 0.036419
[epoch7, step464]: loss 0.036165
[epoch7, step465]: loss 0.040633
[epoch7, step466]: loss 0.036469
[epoch7, step467]: loss 0.038648
[epoch7, step468]: loss 0.036152
[epoch7, step469]: loss 0.036800
[epoch7, step470]: loss 0.039600
[epoch7, step471]: loss 0.038859
[epoch7, step472]: loss 0.036570
[epoch7, step473]: loss 0.035946
[epoch7, step474]: loss 0.039430
[epoch7, step475]: loss 0.036782
[epoch7, step476]: loss 0.039491
[epoch7, step477]: loss 0.036122
[epoch7, step478]: loss 0.036259
[epoch7, step479]: loss 0.039213
[epoch7, step480]: loss 0.038362
[epoch7, step481]: loss 0.035696
[epoch7, step482]: loss 0.035695
[epoch7, step483]: loss 0.039821
[epoch7, step484]: loss 0.036858
[epoch7, step485]: loss 0.039154
[epoch7, step486]: loss 0.036612
[epoch7, step487]: loss 0.036065
[epoch7, step488]: loss 0.039731
[epoch7, step489]: loss 0.038659
[epoch7, step490]: loss 0.036545
[epoch7, step491]: loss 0.036394
[epoch7, step492]: loss 0.039077
[epoch7, step493]: loss 0.036297
[epoch7, step494]: loss 0.038393
[epoch7, step495]: loss 0.037329
[epoch7, step496]: loss 0.036691
[epoch7, step497]: loss 0.039394
[epoch7, step498]: loss 0.039002
[epoch7, step499]: loss 0.036478
[epoch7, step500]: loss 0.035903
[epoch7, step501]: loss 0.038959
[epoch7, step502]: loss 0.036483
[epoch7, step503]: loss 0.039154
[epoch7, step504]: loss 0.036014
[epoch7, step505]: loss 0.035962
[epoch7, step506]: loss 0.039761
[epoch7, step507]: loss 0.039450
[epoch7, step508]: loss 0.036736
[epoch7, step509]: loss 0.036209
[epoch7, step510]: loss 0.039528
[epoch7, step511]: loss 0.036918
[epoch7, step512]: loss 0.039271
[epoch7, step513]: loss 0.036361
[epoch7, step514]: loss 0.036999
[epoch7, step515]: loss 0.039336
[epoch7, step516]: loss 0.039705
[epoch7, step517]: loss 0.036198
[epoch7, step518]: loss 0.036383
[epoch7, step519]: loss 0.039367
[epoch7, step520]: loss 0.036144
[epoch7, step521]: loss 0.038590
[epoch7, step522]: loss 0.035644
[epoch7, step523]: loss 0.036684
[epoch7, step524]: loss 0.038725
[epoch7, step525]: loss 0.039579
[epoch7, step526]: loss 0.036332
[epoch7, step527]: loss 0.036027
[epoch7, step528]: loss 0.039612
[epoch7, step529]: loss 0.036097
[epoch7, step530]: loss 0.039347
[epoch7, step531]: loss 0.036088
[epoch7, step532]: loss 0.036205
[epoch7, step533]: loss 0.040332
[epoch7, step534]: loss 0.039238
[epoch7, step535]: loss 0.036584
[epoch7, step536]: loss 0.036362
[epoch7, step537]: loss 0.039409
[epoch7, step538]: loss 0.036705
[epoch7, step539]: loss 0.038717
[epoch7, step540]: loss 0.035839
[epoch7, step541]: loss 0.036179
[epoch7, step542]: loss 0.039322
[epoch7, step543]: loss 0.038930
[epoch7, step544]: loss 0.036088
[epoch7, step545]: loss 0.035548
[epoch7, step546]: loss 0.039959
[epoch7, step547]: loss 0.036271
[epoch7, step548]: loss 0.038866
[epoch7, step549]: loss 0.036493
[epoch7, step550]: loss 0.036657
[epoch7, step551]: loss 0.039284
[epoch7, step552]: loss 0.038706
[epoch7, step553]: loss 0.036648
[epoch7, step554]: loss 0.036056
[epoch7, step555]: loss 0.039155
[epoch7, step556]: loss 0.036505
[epoch7, step557]: loss 0.038365
[epoch7, step558]: loss 0.036459
[epoch7, step559]: loss 0.036034
[epoch7, step560]: loss 0.039350
[epoch7, step561]: loss 0.039159
[epoch7, step562]: loss 0.036160
[epoch7, step563]: loss 0.036050
[epoch7, step564]: loss 0.039361
[epoch7, step565]: loss 0.038100
[epoch7, step566]: loss 0.045800
[epoch7, step567]: loss 0.038497
[epoch7, step568]: loss 0.036797
[epoch7, step569]: loss 0.033964
[epoch7, step570]: loss 0.043313
[epoch7, step571]: loss 0.039116
[epoch7, step572]: loss 0.038462
[epoch7, step573]: loss 0.041204
[epoch7, step574]: loss 0.042476
[epoch7, step575]: loss 0.032781
[epoch7, step576]: loss 0.034154
[epoch7, step577]: loss 0.036973
[epoch7, step578]: loss 0.030435
[epoch7, step579]: loss 0.040337
[epoch7, step580]: loss 0.031046
[epoch7, step581]: loss 0.036973
[epoch7, step582]: loss 0.036145
[epoch7, step583]: loss 0.035350
[epoch7, step584]: loss 0.034561
[epoch7, step585]: loss 0.037818
[epoch7, step586]: loss 0.034150
[epoch7, step587]: loss 0.040220
[epoch7, step588]: loss 0.034714
[epoch7, step589]: loss 0.035693
[epoch7, step590]: loss 0.039323
[epoch7, step591]: loss 0.031828
[epoch7, step592]: loss 0.036975
[epoch7, step593]: loss 0.034003
[epoch7, step594]: loss 0.037553
[epoch7, step595]: loss 0.038440
[epoch7, step596]: loss 0.035482
[epoch7, step597]: loss 0.035798
[epoch7, step598]: loss 0.037848
[epoch7, step599]: loss 0.036236
[epoch7, step600]: loss 0.039577
[epoch7, step601]: loss 0.030612
[epoch7, step602]: loss 0.034490
[epoch7, step603]: loss 0.038438
[epoch7, step604]: loss 0.038561
[epoch7, step605]: loss 0.036217
[epoch7, step606]: loss 0.036118
[epoch7, step607]: loss 0.039430
[epoch7, step608]: loss 0.037193
[epoch7, step609]: loss 0.038144
[epoch7, step610]: loss 0.039140
[epoch7, step611]: loss 0.038158
[epoch7, step612]: loss 0.036618
[epoch7, step613]: loss 0.031164
[epoch7, step614]: loss 0.035818
[epoch7, step615]: loss 0.040641
[epoch7, step616]: loss 0.035059
[epoch7, step617]: loss 0.034544
[epoch7, step618]: loss 0.038485
[epoch7, step619]: loss 0.039138
[epoch7, step620]: loss 0.035684
[epoch7, step621]: loss 0.038200
[epoch7, step622]: loss 0.031891
[epoch7, step623]: loss 0.034710
[epoch7, step624]: loss 0.038595
[epoch7, step625]: loss 0.036992
[epoch7, step626]: loss 0.039732
[epoch7, step627]: loss 0.034217
[epoch7, step628]: loss 0.036912
[epoch7, step629]: loss 0.031176
[epoch7, step630]: loss 0.033635
[epoch7, step631]: loss 0.043330
[epoch7, step632]: loss 0.035104
[epoch7, step633]: loss 0.036312
[epoch7, step634]: loss 0.038507
[epoch7, step635]: loss 0.037546
[epoch7, step636]: loss 0.033014
[epoch7, step637]: loss 0.038975
[epoch7, step638]: loss 0.039003
[epoch7, step639]: loss 0.033191
[epoch7, step640]: loss 0.041001
[epoch7, step641]: loss 0.041847
[epoch7, step642]: loss 0.036968
[epoch7, step643]: loss 0.036776
[epoch7, step644]: loss 0.037370
[epoch7, step645]: loss 0.034879
[epoch7, step646]: loss 0.036886
[epoch7, step647]: loss 0.034497
[epoch7, step648]: loss 0.036340
[epoch7, step649]: loss 0.040524
[epoch7, step650]: loss 0.034217
[epoch7, step651]: loss 0.038598
[epoch7, step652]: loss 0.038899
[epoch7, step653]: loss 0.039241
[epoch7, step654]: loss 0.033967
[epoch7, step655]: loss 0.035629
[epoch7, step656]: loss 0.033999
[epoch7, step657]: loss 0.039366
[epoch7, step658]: loss 0.036752
[epoch7, step659]: loss 0.039243
[epoch7, step660]: loss 0.034003
[epoch7, step661]: loss 0.038225
[epoch7, step662]: loss 0.034854
[epoch7, step663]: loss 0.033231
[epoch7, step664]: loss 0.036782
[epoch7, step665]: loss 0.038648
[epoch7, step666]: loss 0.038190
[epoch7, step667]: loss 0.038347
[epoch7, step668]: loss 0.034697
[epoch7, step669]: loss 0.037852
[epoch7, step670]: loss 0.038699
[epoch7, step671]: loss 0.032279
[epoch7, step672]: loss 0.036209
[epoch7, step673]: loss 0.034373
[epoch7, step674]: loss 0.032062
[epoch7, step675]: loss 0.031166
[epoch7, step676]: loss 0.035464
[epoch7, step677]: loss 0.036446
[epoch7, step678]: loss 0.034178
[epoch7, step679]: loss 0.035308
[epoch7, step680]: loss 0.042860
[epoch7, step681]: loss 0.032622
[epoch7, step682]: loss 0.037462
[epoch7, step683]: loss 0.036961
[epoch7, step684]: loss 0.036463
[epoch7, step685]: loss 0.035695
[epoch7, step686]: loss 0.039145
[epoch7, step687]: loss 0.037633
[epoch7, step688]: loss 0.035439
[epoch7, step689]: loss 0.035560
[epoch7, step690]: loss 0.037188
[epoch7, step691]: loss 0.036218
[epoch7, step692]: loss 0.034546
[epoch7, step693]: loss 0.039595
[epoch7, step694]: loss 0.033693
[epoch7, step695]: loss 0.038656
[epoch7, step696]: loss 0.036478
[epoch7, step697]: loss 0.039154
[epoch7, step698]: loss 0.035989
[epoch7, step699]: loss 0.034896
[epoch7, step700]: loss 0.032955
[epoch7, step701]: loss 0.037642
[epoch7, step702]: loss 0.032467
[epoch7, step703]: loss 0.035022
[epoch7, step704]: loss 0.037831
[epoch7, step705]: loss 0.036254
[epoch7, step706]: loss 0.034796
[epoch7, step707]: loss 0.034919
[epoch7, step708]: loss 0.036622
[epoch7, step709]: loss 0.039028
[epoch7, step710]: loss 0.034541
[epoch7, step711]: loss 0.037539
[epoch7, step712]: loss 0.037775
[epoch7, step713]: loss 0.038228
[epoch7, step714]: loss 0.032864
[epoch7, step715]: loss 0.034265
[epoch7, step716]: loss 0.037012
[epoch7, step717]: loss 0.033911
[epoch7, step718]: loss 0.036758
[epoch7, step719]: loss 0.046156
[epoch7, step720]: loss 0.036116
[epoch7, step721]: loss 0.034435
[epoch7, step722]: loss 0.042572
[epoch7, step723]: loss 0.038412
[epoch7, step724]: loss 0.034208
[epoch7, step725]: loss 0.039151
[epoch7, step726]: loss 0.033364
[epoch7, step727]: loss 0.035477
[epoch7, step728]: loss 0.037977
[epoch7, step729]: loss 0.033135
[epoch7, step730]: loss 0.033892
[epoch7, step731]: loss 0.037523
[epoch7, step732]: loss 0.037107
[epoch7, step733]: loss 0.035060
[epoch7, step734]: loss 0.034405
[epoch7, step735]: loss 0.039235
[epoch7, step736]: loss 0.036276
[epoch7, step737]: loss 0.038161
[epoch7, step738]: loss 0.031114
[epoch7, step739]: loss 0.037894
[epoch7, step740]: loss 0.034403
[epoch7, step741]: loss 0.037551
[epoch7, step742]: loss 0.033700
[epoch7, step743]: loss 0.035290
[epoch7, step744]: loss 0.034790
[epoch7, step745]: loss 0.035232
[epoch7, step746]: loss 0.037373
[epoch7, step747]: loss 0.039772
[epoch7, step748]: loss 0.037348
[epoch7, step749]: loss 0.037645
[epoch7, step750]: loss 0.039083
[epoch7, step751]: loss 0.033892
[epoch7, step752]: loss 0.035799
[epoch7, step753]: loss 0.036132
[epoch7, step754]: loss 0.035028
[epoch7, step755]: loss 0.037701
[epoch7, step756]: loss 0.035087
[epoch7, step757]: loss 0.031507
[epoch7, step758]: loss 0.035301
[epoch7, step759]: loss 0.033875
[epoch7, step760]: loss 0.034996
[epoch7, step761]: loss 0.038019
[epoch7, step762]: loss 0.032540
[epoch7, step763]: loss 0.037350
[epoch7, step764]: loss 0.035849
[epoch7, step765]: loss 0.038005
[epoch7, step766]: loss 0.036595
[epoch7, step767]: loss 0.040787
[epoch7, step768]: loss 0.031964
[epoch7, step769]: loss 0.037590
[epoch7, step770]: loss 0.036764
[epoch7, step771]: loss 0.033918
[epoch7, step772]: loss 0.040411
[epoch7, step773]: loss 0.037135
[epoch7, step774]: loss 0.035730
[epoch7, step775]: loss 0.031418
[epoch7, step776]: loss 0.037368
[epoch7, step777]: loss 0.033790
[epoch7, step778]: loss 0.038911
[epoch7, step779]: loss 0.035960
[epoch7, step780]: loss 0.031012
[epoch7, step781]: loss 0.035772
[epoch7, step782]: loss 0.034009
[epoch7, step783]: loss 0.031259
[epoch7, step784]: loss 0.032173
[epoch7, step785]: loss 0.032706
[epoch7, step786]: loss 0.035375
[epoch7, step787]: loss 0.035094
[epoch7, step788]: loss 0.036469
[epoch7, step789]: loss 0.036011
[epoch7, step790]: loss 0.034727
[epoch7, step791]: loss 0.038802
[epoch7, step792]: loss 0.036538
[epoch7, step793]: loss 0.038507
[epoch7, step794]: loss 0.031612
[epoch7, step795]: loss 0.036411
[epoch7, step796]: loss 0.039580
[epoch7, step797]: loss 0.038727
[epoch7, step798]: loss 0.038845
[epoch7, step799]: loss 0.037491
[epoch7, step800]: loss 0.032869
[epoch7, step801]: loss 0.034455
[epoch7, step802]: loss 0.034012
[epoch7, step803]: loss 0.037778
[epoch7, step804]: loss 0.039071
[epoch7, step805]: loss 0.039391
[epoch7, step806]: loss 0.033308
[epoch7, step807]: loss 0.032224
[epoch7, step808]: loss 0.035047
[epoch7, step809]: loss 0.033352
[epoch7, step810]: loss 0.037003
[epoch7, step811]: loss 0.036537
[epoch7, step812]: loss 0.035732
[epoch7, step813]: loss 0.034638
[epoch7, step814]: loss 0.036800
[epoch7, step815]: loss 0.035347
[epoch7, step816]: loss 0.036350
[epoch7, step817]: loss 0.036484
[epoch7, step818]: loss 0.032971
[epoch7, step819]: loss 0.032490
[epoch7, step820]: loss 0.034969
[epoch7, step821]: loss 0.032190
[epoch7, step822]: loss 0.041817
[epoch7, step823]: loss 0.035221
[epoch7, step824]: loss 0.038168
[epoch7, step825]: loss 0.037301
[epoch7, step826]: loss 0.035274
[epoch7, step827]: loss 0.038241
[epoch7, step828]: loss 0.040076
[epoch7, step829]: loss 0.038953
[epoch7, step830]: loss 0.033763
[epoch7, step831]: loss 0.038096
[epoch7, step832]: loss 0.032962
[epoch7, step833]: loss 0.039648
[epoch7, step834]: loss 0.037828
[epoch7, step835]: loss 0.032090
[epoch7, step836]: loss 0.039479
[epoch7, step837]: loss 0.037138
[epoch7, step838]: loss 0.036707
[epoch7, step839]: loss 0.039903
[epoch7, step840]: loss 0.031737
[epoch7, step841]: loss 0.035973
[epoch7, step842]: loss 0.039075
[epoch7, step843]: loss 0.037062
[epoch7, step844]: loss 0.036423
[epoch7, step845]: loss 0.032735
[epoch7, step846]: loss 0.039207
[epoch7, step847]: loss 0.038402
[epoch7, step848]: loss 0.036237
[epoch7, step849]: loss 0.035445
[epoch7, step850]: loss 0.034256
[epoch7, step851]: loss 0.036054
[epoch7, step852]: loss 0.033684
[epoch7, step853]: loss 0.042056
[epoch7, step854]: loss 0.034357
[epoch7, step855]: loss 0.038478
[epoch7, step856]: loss 0.032331
[epoch7, step857]: loss 0.036124
[epoch7, step858]: loss 0.035626
[epoch7, step859]: loss 0.034704
[epoch7, step860]: loss 0.034149
[epoch7, step861]: loss 0.034010
[epoch7, step862]: loss 0.033606
[epoch7, step863]: loss 0.032141
[epoch7, step864]: loss 0.038289
[epoch7, step865]: loss 0.035420
[epoch7, step866]: loss 0.036126
[epoch7, step867]: loss 0.037874
[epoch7, step868]: loss 0.039160
[epoch7, step869]: loss 0.034880
[epoch7, step870]: loss 0.042864
[epoch7, step871]: loss 0.034464
[epoch7, step872]: loss 0.037319
[epoch7, step873]: loss 0.037066
[epoch7, step874]: loss 0.035238
[epoch7, step875]: loss 0.035362
[epoch7, step876]: loss 0.036254
[epoch7, step877]: loss 0.030634
[epoch7, step878]: loss 0.034400
[epoch7, step879]: loss 0.040001
[epoch7, step880]: loss 0.036740
[epoch7, step881]: loss 0.034078
[epoch7, step882]: loss 0.035141
[epoch7, step883]: loss 0.034971
[epoch7, step884]: loss 0.037790
[epoch7, step885]: loss 0.037600
[epoch7, step886]: loss 0.037702
[epoch7, step887]: loss 0.035939
[epoch7, step888]: loss 0.036530
[epoch7, step889]: loss 0.035466
[epoch7, step890]: loss 0.035781
[epoch7, step891]: loss 0.037561
[epoch7, step892]: loss 0.031210
[epoch7, step893]: loss 0.036036
[epoch7, step894]: loss 0.036373
[epoch7, step895]: loss 0.033191
[epoch7, step896]: loss 0.034016
[epoch7, step897]: loss 0.036851
[epoch7, step898]: loss 0.038119
[epoch7, step899]: loss 0.040309
[epoch7, step900]: loss 0.038074
[epoch7, step901]: loss 0.037662
[epoch7, step902]: loss 0.035014
[epoch7, step903]: loss 0.037214
[epoch7, step904]: loss 0.038774
[epoch7, step905]: loss 0.039012
[epoch7, step906]: loss 0.033268
[epoch7, step907]: loss 0.034840
[epoch7, step908]: loss 0.033765
[epoch7, step909]: loss 0.038068
[epoch7, step910]: loss 0.034423
[epoch7, step911]: loss 0.036787
[epoch7, step912]: loss 0.034547
[epoch7, step913]: loss 0.035744
[epoch7, step914]: loss 0.040859
[epoch7, step915]: loss 0.035006
[epoch7, step916]: loss 0.034419
[epoch7, step917]: loss 0.035987
[epoch7, step918]: loss 0.040712
[epoch7, step919]: loss 0.035854
[epoch7, step920]: loss 0.039089
[epoch7, step921]: loss 0.035464
[epoch7, step922]: loss 0.035249
[epoch7, step923]: loss 0.034821
[epoch7, step924]: loss 0.031633
[epoch7, step925]: loss 0.036844
[epoch7, step926]: loss 0.036552
[epoch7, step927]: loss 0.037137
[epoch7, step928]: loss 0.035340
[epoch7, step929]: loss 0.039221
[epoch7, step930]: loss 0.036600
[epoch7, step931]: loss 0.038834
[epoch7, step932]: loss 0.032249
[epoch7, step933]: loss 0.040766
[epoch7, step934]: loss 0.034257
[epoch7, step935]: loss 0.034264
[epoch7, step936]: loss 0.033531
[epoch7, step937]: loss 0.038421
[epoch7, step938]: loss 0.038805
[epoch7, step939]: loss 0.032524
[epoch7, step940]: loss 0.034740
[epoch7, step941]: loss 0.038405
[epoch7, step942]: loss 0.037335
[epoch7, step943]: loss 0.035257
[epoch7, step944]: loss 0.039081
[epoch7, step945]: loss 0.031727
[epoch7, step946]: loss 0.036981
[epoch7, step947]: loss 0.040044
[epoch7, step948]: loss 0.031948
[epoch7, step949]: loss 0.034539
[epoch7, step950]: loss 0.038148
[epoch7, step951]: loss 0.040626
[epoch7, step952]: loss 0.036150
[epoch7, step953]: loss 0.038810
[epoch7, step954]: loss 0.034491
[epoch7, step955]: loss 0.042433
[epoch7, step956]: loss 0.051243
[epoch7, step957]: loss 0.046782
[epoch7, step958]: loss 0.044666
[epoch7, step959]: loss 0.047424
[epoch7, step960]: loss 0.045583
[epoch7, step961]: loss 0.046132
[epoch7, step962]: loss 0.044850
[epoch7, step963]: loss 0.045180
[epoch7, step964]: loss 0.046238
[epoch7, step965]: loss 0.046541
[epoch7, step966]: loss 0.044815
[epoch7, step967]: loss 0.044705
[epoch7, step968]: loss 0.046414
[epoch7, step969]: loss 0.046083
[epoch7, step970]: loss 0.045449
[epoch7, step971]: loss 0.044749
[epoch7, step972]: loss 0.045495
[epoch7, step973]: loss 0.045321
[epoch7, step974]: loss 0.046620
[epoch7, step975]: loss 0.044420
[epoch7, step976]: loss 0.044178
[epoch7, step977]: loss 0.046669
[epoch7, step978]: loss 0.045513
[epoch7, step979]: loss 0.044841
[epoch7, step980]: loss 0.044189
[epoch7, step981]: loss 0.045018
[epoch7, step982]: loss 0.045448
[epoch7, step983]: loss 0.046299
[epoch7, step984]: loss 0.044046
[epoch7, step985]: loss 0.044211
[epoch7, step986]: loss 0.046713
[epoch7, step987]: loss 0.045562
[epoch7, step988]: loss 0.045290
[epoch7, step989]: loss 0.044681
[epoch7, step990]: loss 0.044831
[epoch7, step991]: loss 0.045509
[epoch7, step992]: loss 0.045748
[epoch7, step993]: loss 0.044134
[epoch7, step994]: loss 0.043692
[epoch7, step995]: loss 0.046245
[epoch7, step996]: loss 0.045077
[epoch7, step997]: loss 0.044953
[epoch7, step998]: loss 0.044515
[epoch7, step999]: loss 0.045131
[epoch7, step1000]: loss 0.045086
[epoch7, step1001]: loss 0.045867
[epoch7, step1002]: loss 0.044181
[epoch7, step1003]: loss 0.043759
[epoch7, step1004]: loss 0.046134
[epoch7, step1005]: loss 0.044657
[epoch7, step1006]: loss 0.044444
[epoch7, step1007]: loss 0.043771
[epoch7, step1008]: loss 0.044695
[epoch7, step1009]: loss 0.045014
[epoch7, step1010]: loss 0.046190
[epoch7, step1011]: loss 0.043708
[epoch7, step1012]: loss 0.043829
[epoch7, step1013]: loss 0.045915
[epoch7, step1014]: loss 0.045322
[epoch7, step1015]: loss 0.044800
[epoch7, step1016]: loss 0.043722
[epoch7, step1017]: loss 0.044589
[epoch7, step1018]: loss 0.044923
[epoch7, step1019]: loss 0.045760
[epoch7, step1020]: loss 0.043448
[epoch7, step1021]: loss 0.043417
[epoch7, step1022]: loss 0.045566
[epoch7, step1023]: loss 0.044793
[epoch7, step1024]: loss 0.044823
[epoch7, step1025]: loss 0.043274
[epoch7, step1026]: loss 0.044392
[epoch7, step1027]: loss 0.044658
[epoch7, step1028]: loss 0.045571
[epoch7, step1029]: loss 0.043517
[epoch7, step1030]: loss 0.043161
[epoch7, step1031]: loss 0.045031
[epoch7, step1032]: loss 0.044849
[epoch7, step1033]: loss 0.044355
[epoch7, step1034]: loss 0.043373
[epoch7, step1035]: loss 0.044475
[epoch7, step1036]: loss 0.044783
[epoch7, step1037]: loss 0.045359
[epoch7, step1038]: loss 0.043233
[epoch7, step1039]: loss 0.043596
[epoch7, step1040]: loss 0.045393
[epoch7, step1041]: loss 0.044644
[epoch7, step1042]: loss 0.043881
[epoch7, step1043]: loss 0.043170
[epoch7, step1044]: loss 0.044672
[epoch7, step1045]: loss 0.044794
[epoch7, step1046]: loss 0.045630
[epoch7, step1047]: loss 0.043548
[epoch7, step1048]: loss 0.043348
[epoch7, step1049]: loss 0.045813
[epoch7, step1050]: loss 0.045021
[epoch7, step1051]: loss 0.044317
[epoch7, step1052]: loss 0.043755
[epoch7, step1053]: loss 0.045085
[epoch7, step1054]: loss 0.044747
[epoch7, step1055]: loss 0.045331
[epoch7, step1056]: loss 0.043058
[epoch7, step1057]: loss 0.043747
[epoch7, step1058]: loss 0.046031
[epoch7, step1059]: loss 0.045125
[epoch7, step1060]: loss 0.044435
[epoch7, step1061]: loss 0.042853
[epoch7, step1062]: loss 0.044893
[epoch7, step1063]: loss 0.044643
[epoch7, step1064]: loss 0.045456
[epoch7, step1065]: loss 0.043378
[epoch7, step1066]: loss 0.043272
[epoch7, step1067]: loss 0.045668
[epoch7, step1068]: loss 0.043934
[epoch7, step1069]: loss 0.044001
[epoch7, step1070]: loss 0.043367
[epoch7, step1071]: loss 0.044758
[epoch7, step1072]: loss 0.044912
[epoch7, step1073]: loss 0.045210
[epoch7, step1074]: loss 0.043146
[epoch7, step1075]: loss 0.043594
[epoch7, step1076]: loss 0.045712
[epoch7, step1077]: loss 0.044763
[epoch7, step1078]: loss 0.044226
[epoch7, step1079]: loss 0.043880
[epoch7, step1080]: loss 0.044747
[epoch7, step1081]: loss 0.044517
[epoch7, step1082]: loss 0.045422
[epoch7, step1083]: loss 0.043727
[epoch7, step1084]: loss 0.043723
[epoch7, step1085]: loss 0.045327
[epoch7, step1086]: loss 0.044615
[epoch7, step1087]: loss 0.044346
[epoch7, step1088]: loss 0.043210
[epoch7, step1089]: loss 0.044675
[epoch7, step1090]: loss 0.044764
[epoch7, step1091]: loss 0.045759
[epoch7, step1092]: loss 0.043385
[epoch7, step1093]: loss 0.043164
[epoch7, step1094]: loss 0.044914
[epoch7, step1095]: loss 0.044353
[epoch7, step1096]: loss 0.044060
[epoch7, step1097]: loss 0.043148
[epoch7, step1098]: loss 0.044673
[epoch7, step1099]: loss 0.044509
[epoch7, step1100]: loss 0.045814
[epoch7, step1101]: loss 0.043651
[epoch7, step1102]: loss 0.043258
[epoch7, step1103]: loss 0.045283
[epoch7, step1104]: loss 0.044543
[epoch7, step1105]: loss 0.044267
[epoch7, step1106]: loss 0.042820
[epoch7, step1107]: loss 0.044768
[epoch7, step1108]: loss 0.044501
[epoch7, step1109]: loss 0.045683
[epoch7, step1110]: loss 0.043619
[epoch7, step1111]: loss 0.043536
[epoch7, step1112]: loss 0.045715
[epoch7, step1113]: loss 0.044380
[epoch7, step1114]: loss 0.044441
[epoch7, step1115]: loss 0.043237
[epoch7, step1116]: loss 0.044757
[epoch7, step1117]: loss 0.044454
[epoch7, step1118]: loss 0.045301
[epoch7, step1119]: loss 0.043126
[epoch7, step1120]: loss 0.043049
[epoch7, step1121]: loss 0.045453
[epoch7, step1122]: loss 0.044134
[epoch7, step1123]: loss 0.043933
[epoch7, step1124]: loss 0.043549
[epoch7, step1125]: loss 0.044777
[epoch7, step1126]: loss 0.045159
[epoch7, step1127]: loss 0.045335
[epoch7, step1128]: loss 0.043536
[epoch7, step1129]: loss 0.043210
[epoch7, step1130]: loss 0.045788
[epoch7, step1131]: loss 0.044636
[epoch7, step1132]: loss 0.044316
[epoch7, step1133]: loss 0.042813
[epoch7, step1134]: loss 0.044276
[epoch7, step1135]: loss 0.045084
[epoch7, step1136]: loss 0.045701
[epoch7, step1137]: loss 0.043279
[epoch7, step1138]: loss 0.043336
[epoch7, step1139]: loss 0.045604
[epoch7, step1140]: loss 0.044224
[epoch7, step1141]: loss 0.044106
[epoch7, step1142]: loss 0.043050
[epoch7, step1143]: loss 0.044479
[epoch7, step1144]: loss 0.044823
[epoch7, step1145]: loss 0.045193
[epoch7, step1146]: loss 0.043001
[epoch7, step1147]: loss 0.043856
[epoch7, step1148]: loss 0.045683
[epoch7, step1149]: loss 0.044528
[epoch7, step1150]: loss 0.043969
[epoch7, step1151]: loss 0.043419
[epoch7, step1152]: loss 0.044961
[epoch7, step1153]: loss 0.044192
[epoch7, step1154]: loss 0.045483
[epoch7, step1155]: loss 0.043230
[epoch7, step1156]: loss 0.042948
[epoch7, step1157]: loss 0.045500
[epoch7, step1158]: loss 0.044713
[epoch7, step1159]: loss 0.044160
[epoch7, step1160]: loss 0.043503
[epoch7, step1161]: loss 0.044836
[epoch7, step1162]: loss 0.044511
[epoch7, step1163]: loss 0.044957
[epoch7, step1164]: loss 0.043204
[epoch7, step1165]: loss 0.043943
[epoch7, step1166]: loss 0.045634
[epoch7, step1167]: loss 0.044104
[epoch7, step1168]: loss 0.044255
[epoch7, step1169]: loss 0.043166
[epoch7, step1170]: loss 0.044640
[epoch7, step1171]: loss 0.044398
[epoch7, step1172]: loss 0.045323
[epoch7, step1173]: loss 0.043387
[epoch7, step1174]: loss 0.043665
[epoch7, step1175]: loss 0.045437
[epoch7, step1176]: loss 0.044339
[epoch7, step1177]: loss 0.044442
[epoch7, step1178]: loss 0.043159
[epoch7, step1179]: loss 0.044449
[epoch7, step1180]: loss 0.044409
[epoch7, step1181]: loss 0.045641
[epoch7, step1182]: loss 0.042971
[epoch7, step1183]: loss 0.043582
[epoch7, step1184]: loss 0.044957
[epoch7, step1185]: loss 0.044680
[epoch7, step1186]: loss 0.043775
[epoch7, step1187]: loss 0.042779
[epoch7, step1188]: loss 0.044272
[epoch7, step1189]: loss 0.044241
[epoch7, step1190]: loss 0.045052
[epoch7, step1191]: loss 0.043587
[epoch7, step1192]: loss 0.043306
[epoch7, step1193]: loss 0.045545
[epoch7, step1194]: loss 0.044360
[epoch7, step1195]: loss 0.043621
[epoch7, step1196]: loss 0.042640
[epoch7, step1197]: loss 0.044775
[epoch7, step1198]: loss 0.044494
[epoch7, step1199]: loss 0.045078
[epoch7, step1200]: loss 0.043009
[epoch7, step1201]: loss 0.043535
[epoch7, step1202]: loss 0.045886
[epoch7, step1203]: loss 0.044511
[epoch7, step1204]: loss 0.043840
[epoch7, step1205]: loss 0.042938
[epoch7, step1206]: loss 0.044299
[epoch7, step1207]: loss 0.044529
[epoch7, step1208]: loss 0.045588
[epoch7, step1209]: loss 0.042581
[epoch7, step1210]: loss 0.043768
[epoch7, step1211]: loss 0.045208
[epoch7, step1212]: loss 0.044342
[epoch7, step1213]: loss 0.043832
[epoch7, step1214]: loss 0.043153
[epoch7, step1215]: loss 0.044925
[epoch7, step1216]: loss 0.044189
[epoch7, step1217]: loss 0.045384
[epoch7, step1218]: loss 0.042928
[epoch7, step1219]: loss 0.043442
[epoch7, step1220]: loss 0.045561
[epoch7, step1221]: loss 0.043885
[epoch7, step1222]: loss 0.044220
[epoch7, step1223]: loss 0.043194
[epoch7, step1224]: loss 0.044625
[epoch7, step1225]: loss 0.044563
[epoch7, step1226]: loss 0.045142
[epoch7, step1227]: loss 0.043245
[epoch7, step1228]: loss 0.043015
[epoch7, step1229]: loss 0.045471
[epoch7, step1230]: loss 0.044571
[epoch7, step1231]: loss 0.044004
[epoch7, step1232]: loss 0.043520
[epoch7, step1233]: loss 0.044421
[epoch7, step1234]: loss 0.044229
[epoch7, step1235]: loss 0.045393
[epoch7, step1236]: loss 0.043409
[epoch7, step1237]: loss 0.043131
[epoch7, step1238]: loss 0.045115
[epoch7, step1239]: loss 0.044655
[epoch7, step1240]: loss 0.044123
[epoch7, step1241]: loss 0.043146
[epoch7, step1242]: loss 0.044578
[epoch7, step1243]: loss 0.044404
[epoch7, step1244]: loss 0.045504
[epoch7, step1245]: loss 0.043476
[epoch7, step1246]: loss 0.043591
[epoch7, step1247]: loss 0.045135
[epoch7, step1248]: loss 0.044457
[epoch7, step1249]: loss 0.044546
[epoch7, step1250]: loss 0.043075
[epoch7, step1251]: loss 0.044570
[epoch7, step1252]: loss 0.044996
[epoch7, step1253]: loss 0.045163
[epoch7, step1254]: loss 0.043230
[epoch7, step1255]: loss 0.043164
[epoch7, step1256]: loss 0.045544
[epoch7, step1257]: loss 0.044428
[epoch7, step1258]: loss 0.044238
[epoch7, step1259]: loss 0.043129
[epoch7, step1260]: loss 0.044694
[epoch7, step1261]: loss 0.044303
[epoch7, step1262]: loss 0.044708
[epoch7, step1263]: loss 0.043490
[epoch7, step1264]: loss 0.043270
[epoch7, step1265]: loss 0.045109
[epoch7, step1266]: loss 0.044312
[epoch7, step1267]: loss 0.044347
[epoch7, step1268]: loss 0.042925
[epoch7, step1269]: loss 0.044459
[epoch7, step1270]: loss 0.044108
[epoch7, step1271]: loss 0.045463
[epoch7, step1272]: loss 0.043321
[epoch7, step1273]: loss 0.042971
[epoch7, step1274]: loss 0.045427
[epoch7, step1275]: loss 0.044745
[epoch7, step1276]: loss 0.043967
[epoch7, step1277]: loss 0.043186
[epoch7, step1278]: loss 0.044753
[epoch7, step1279]: loss 0.044638
[epoch7, step1280]: loss 0.045493
[epoch7, step1281]: loss 0.043166
[epoch7, step1282]: loss 0.043122
[epoch7, step1283]: loss 0.045044
[epoch7, step1284]: loss 0.044140
[epoch7, step1285]: loss 0.044492
[epoch7, step1286]: loss 0.042481
[epoch7, step1287]: loss 0.044894
[epoch7, step1288]: loss 0.044770
[epoch7, step1289]: loss 0.045670
[epoch7, step1290]: loss 0.043220
[epoch7, step1291]: loss 0.042936
[epoch7, step1292]: loss 0.045661
[epoch7, step1293]: loss 0.043922
[epoch7, step1294]: loss 0.043892
[epoch7, step1295]: loss 0.043181
[epoch7, step1296]: loss 0.044545
[epoch7, step1297]: loss 0.044321
[epoch7, step1298]: loss 0.045605
[epoch7, step1299]: loss 0.043175
[epoch7, step1300]: loss 0.043834
[epoch7, step1301]: loss 0.045014
[epoch7, step1302]: loss 0.044560
[epoch7, step1303]: loss 0.044319
[epoch7, step1304]: loss 0.042839
[epoch7, step1305]: loss 0.044548
[epoch7, step1306]: loss 0.044255
[epoch7, step1307]: loss 0.044938
[epoch7, step1308]: loss 0.043350
[epoch7, step1309]: loss 0.042789
[epoch7, step1310]: loss 0.045337
[epoch7, step1311]: loss 0.043748
[epoch7, step1312]: loss 0.044209
[epoch7, step1313]: loss 0.043026
[epoch7, step1314]: loss 0.044404
[epoch7, step1315]: loss 0.044172
[epoch7, step1316]: loss 0.046048
[epoch7, step1317]: loss 0.042794
[epoch7, step1318]: loss 0.042927
[epoch7, step1319]: loss 0.045178
[epoch7, step1320]: loss 0.044288
[epoch7, step1321]: loss 0.044352
[epoch7, step1322]: loss 0.042907
[epoch7, step1323]: loss 0.044678
[epoch7, step1324]: loss 0.044185
[epoch7, step1325]: loss 0.044941
[epoch7, step1326]: loss 0.043058
[epoch7, step1327]: loss 0.043131
[epoch7, step1328]: loss 0.045363
[epoch7, step1329]: loss 0.044355
[epoch7, step1330]: loss 0.044041
[epoch7, step1331]: loss 0.042833
[epoch7, step1332]: loss 0.044452
[epoch7, step1333]: loss 0.043871
[epoch7, step1334]: loss 0.045614
[epoch7, step1335]: loss 0.043339
[epoch7, step1336]: loss 0.043001
[epoch7, step1337]: loss 0.044951
[epoch7, step1338]: loss 0.044013
[epoch7, step1339]: loss 0.044208
[epoch7, step1340]: loss 0.042786
[epoch7, step1341]: loss 0.044532
[epoch7, step1342]: loss 0.044205
[epoch7, step1343]: loss 0.045332
[epoch7, step1344]: loss 0.043314
[epoch7, step1345]: loss 0.043168
[epoch7, step1346]: loss 0.045057
[epoch7, step1347]: loss 0.044554
[epoch7, step1348]: loss 0.043887
[epoch7, step1349]: loss 0.043121
[epoch7, step1350]: loss 0.044287
[epoch7, step1351]: loss 0.044111
[epoch7, step1352]: loss 0.045100
[epoch7, step1353]: loss 0.043049
[epoch7, step1354]: loss 0.043075
[epoch7, step1355]: loss 0.045424
[epoch7, step1356]: loss 0.043923
[epoch7, step1357]: loss 0.043869
[epoch7, step1358]: loss 0.042819
[epoch7, step1359]: loss 0.044379
[epoch7, step1360]: loss 0.044415
[epoch7, step1361]: loss 0.045263
[epoch7, step1362]: loss 0.043424
[epoch7, step1363]: loss 0.043184
[epoch7, step1364]: loss 0.044981
[epoch7, step1365]: loss 0.044285
[epoch7, step1366]: loss 0.043809
[epoch7, step1367]: loss 0.042706
[epoch7, step1368]: loss 0.044874
[epoch7, step1369]: loss 0.044463
[epoch7, step1370]: loss 0.045120
[epoch7, step1371]: loss 0.043128
[epoch7, step1372]: loss 0.043043
[epoch7, step1373]: loss 0.045576
[epoch7, step1374]: loss 0.044575
[epoch7, step1375]: loss 0.044635
[epoch7, step1376]: loss 0.042686
[epoch7, step1377]: loss 0.044143
[epoch7, step1378]: loss 0.044475
[epoch7, step1379]: loss 0.045038
[epoch7, step1380]: loss 0.043162
[epoch7, step1381]: loss 0.043024
[epoch7, step1382]: loss 0.045421
[epoch7, step1383]: loss 0.044247
[epoch7, step1384]: loss 0.043949
[epoch7, step1385]: loss 0.042566
[epoch7, step1386]: loss 0.044469
[epoch7, step1387]: loss 0.044460
[epoch7, step1388]: loss 0.044946
[epoch7, step1389]: loss 0.042560
[epoch7, step1390]: loss 0.043135
[epoch7, step1391]: loss 0.045403
[epoch7, step1392]: loss 0.044231
[epoch7, step1393]: loss 0.044232
[epoch7, step1394]: loss 0.043352
[epoch7, step1395]: loss 0.044515
[epoch7, step1396]: loss 0.044093
[epoch7, step1397]: loss 0.045082
[epoch7, step1398]: loss 0.043152
[epoch7, step1399]: loss 0.043416
[epoch7, step1400]: loss 0.045482
[epoch7, step1401]: loss 0.044192
[epoch7, step1402]: loss 0.043875
[epoch7, step1403]: loss 0.042495
[epoch7, step1404]: loss 0.044347
[epoch7, step1405]: loss 0.044159
[epoch7, step1406]: loss 0.044989
[epoch7, step1407]: loss 0.043788
[epoch7, step1408]: loss 0.042882
[epoch7, step1409]: loss 0.045167
[epoch7, step1410]: loss 0.044084
[epoch7, step1411]: loss 0.043482
[epoch7, step1412]: loss 0.042854
[epoch7, step1413]: loss 0.044315
[epoch7, step1414]: loss 0.044112
[epoch7, step1415]: loss 0.044844
[epoch7, step1416]: loss 0.042874
[epoch7, step1417]: loss 0.042836
[epoch7, step1418]: loss 0.045076
[epoch7, step1419]: loss 0.044583
[epoch7, step1420]: loss 0.043859
[epoch7, step1421]: loss 0.043161
[epoch7, step1422]: loss 0.044431
[epoch7, step1423]: loss 0.043991
[epoch7, step1424]: loss 0.045188
[epoch7, step1425]: loss 0.042527
[epoch7, step1426]: loss 0.043263
[epoch7, step1427]: loss 0.045617
[epoch7, step1428]: loss 0.044628
[epoch7, step1429]: loss 0.044156
[epoch7, step1430]: loss 0.042855
[epoch7, step1431]: loss 0.044759
[epoch7, step1432]: loss 0.044173
[epoch7, step1433]: loss 0.045260
[epoch7, step1434]: loss 0.042762
[epoch7, step1435]: loss 0.043155
[epoch7, step1436]: loss 0.045536
[epoch7, step1437]: loss 0.044332
[epoch7, step1438]: loss 0.044102
[epoch7, step1439]: loss 0.042786
[epoch7, step1440]: loss 0.044142
[epoch7, step1441]: loss 0.044663
[epoch7, step1442]: loss 0.044681
[epoch7, step1443]: loss 0.042945
[epoch7, step1444]: loss 0.042712
[epoch7, step1445]: loss 0.045309
[epoch7, step1446]: loss 0.044166
[epoch7, step1447]: loss 0.044370
[epoch7, step1448]: loss 0.042694
[epoch7, step1449]: loss 0.044047
[epoch7, step1450]: loss 0.044191
[epoch7, step1451]: loss 0.045324
[epoch7, step1452]: loss 0.042975
[epoch7, step1453]: loss 0.043499
[epoch7, step1454]: loss 0.045416
[epoch7, step1455]: loss 0.044674
[epoch7, step1456]: loss 0.043826
[epoch7, step1457]: loss 0.042956
[epoch7, step1458]: loss 0.044491
[epoch7, step1459]: loss 0.044019
[epoch7, step1460]: loss 0.045418
[epoch7, step1461]: loss 0.043457
[epoch7, step1462]: loss 0.043277
[epoch7, step1463]: loss 0.045182
[epoch7, step1464]: loss 0.044425
[epoch7, step1465]: loss 0.043879
[epoch7, step1466]: loss 0.042646
[epoch7, step1467]: loss 0.044342
[epoch7, step1468]: loss 0.043797
[epoch7, step1469]: loss 0.045177
[epoch7, step1470]: loss 0.043259
[epoch7, step1471]: loss 0.042672
[epoch7, step1472]: loss 0.045155
[epoch7, step1473]: loss 0.044042
[epoch7, step1474]: loss 0.044453
[epoch7, step1475]: loss 0.042580
[epoch7, step1476]: loss 0.044573
[epoch7, step1477]: loss 0.044164
[epoch7, step1478]: loss 0.045211
[epoch7, step1479]: loss 0.043008
[epoch7, step1480]: loss 0.042960
[epoch7, step1481]: loss 0.044887
[epoch7, step1482]: loss 0.044128
[epoch7, step1483]: loss 0.044032
[epoch7, step1484]: loss 0.042972
[epoch7, step1485]: loss 0.044068
[epoch7, step1486]: loss 0.043615
[epoch7, step1487]: loss 0.045144
[epoch7, step1488]: loss 0.043032
[epoch7, step1489]: loss 0.043016
[epoch7, step1490]: loss 0.045128
[epoch7, step1491]: loss 0.044171
[epoch7, step1492]: loss 0.043719
[epoch7, step1493]: loss 0.042886
[epoch7, step1494]: loss 0.044430
[epoch7, step1495]: loss 0.043984
[epoch7, step1496]: loss 0.044714
[epoch7, step1497]: loss 0.043215
[epoch7, step1498]: loss 0.043065
[epoch7, step1499]: loss 0.044941
[epoch7, step1500]: loss 0.044284
[epoch7, step1501]: loss 0.044018
[epoch7, step1502]: loss 0.042717
[epoch7, step1503]: loss 0.044238
[epoch7, step1504]: loss 0.043745
[epoch7, step1505]: loss 0.045239
[epoch7, step1506]: loss 0.042524
[epoch7, step1507]: loss 0.043112
[epoch7, step1508]: loss 0.045454
[epoch7, step1509]: loss 0.044065
[epoch7, step1510]: loss 0.043691
[epoch7, step1511]: loss 0.043118
[epoch7, step1512]: loss 0.044380
[epoch7, step1513]: loss 0.043367
[epoch7, step1514]: loss 0.045049
[epoch7, step1515]: loss 0.043190
[epoch7, step1516]: loss 0.042826

[epoch7]: avg loss 0.039788

[epoch8, step1]: loss 0.038782
[epoch8, step2]: loss 0.038991
[epoch8, step3]: loss 0.039026
[epoch8, step4]: loss 0.036160
[epoch8, step5]: loss 0.036736
[epoch8, step6]: loss 0.039356
[epoch8, step7]: loss 0.037078
[epoch8, step8]: loss 0.039265
[epoch8, step9]: loss 0.035923
[epoch8, step10]: loss 0.037110
[epoch8, step11]: loss 0.039250
[epoch8, step12]: loss 0.038937
[epoch8, step13]: loss 0.036146
[epoch8, step14]: loss 0.036526
[epoch8, step15]: loss 0.039158
[epoch8, step16]: loss 0.036887
[epoch8, step17]: loss 0.039321
[epoch8, step18]: loss 0.036958
[epoch8, step19]: loss 0.037094
[epoch8, step20]: loss 0.039984
[epoch8, step21]: loss 0.039149
[epoch8, step22]: loss 0.035737
[epoch8, step23]: loss 0.035709
[epoch8, step24]: loss 0.039224
[epoch8, step25]: loss 0.036315
[epoch8, step26]: loss 0.038439
[epoch8, step27]: loss 0.035692
[epoch8, step28]: loss 0.036899
[epoch8, step29]: loss 0.039280
[epoch8, step30]: loss 0.039559
[epoch8, step31]: loss 0.035615
[epoch8, step32]: loss 0.036668
[epoch8, step33]: loss 0.039738
[epoch8, step34]: loss 0.037336
[epoch8, step35]: loss 0.039229
[epoch8, step36]: loss 0.036080
[epoch8, step37]: loss 0.036771
[epoch8, step38]: loss 0.038854
[epoch8, step39]: loss 0.038963
[epoch8, step40]: loss 0.036339
[epoch8, step41]: loss 0.035883
[epoch8, step42]: loss 0.039429
[epoch8, step43]: loss 0.036653
[epoch8, step44]: loss 0.039362
[epoch8, step45]: loss 0.036112
[epoch8, step46]: loss 0.036941
[epoch8, step47]: loss 0.038745
[epoch8, step48]: loss 0.038704
[epoch8, step49]: loss 0.034553
[epoch8, step50]: loss 0.036418
[epoch8, step51]: loss 0.038920
[epoch8, step52]: loss 0.036552
[epoch8, step53]: loss 0.039562
[epoch8, step54]: loss 0.035885
[epoch8, step55]: loss 0.037189
[epoch8, step56]: loss 0.039882
[epoch8, step57]: loss 0.039456
[epoch8, step58]: loss 0.036092
[epoch8, step59]: loss 0.035493
[epoch8, step60]: loss 0.039544
[epoch8, step61]: loss 0.036011
[epoch8, step62]: loss 0.038543
[epoch8, step63]: loss 0.035433
[epoch8, step64]: loss 0.036340
[epoch8, step65]: loss 0.039235
[epoch8, step66]: loss 0.038948
[epoch8, step67]: loss 0.036154
[epoch8, step68]: loss 0.036280
[epoch8, step69]: loss 0.039039
[epoch8, step70]: loss 0.036481
[epoch8, step71]: loss 0.038519
[epoch8, step72]: loss 0.036012
[epoch8, step73]: loss 0.036526
[epoch8, step74]: loss 0.039120
[epoch8, step75]: loss 0.039132
[epoch8, step76]: loss 0.036528
[epoch8, step77]: loss 0.036851
[epoch8, step78]: loss 0.039253
[epoch8, step79]: loss 0.036130
[epoch8, step80]: loss 0.039701
[epoch8, step81]: loss 0.036001
[epoch8, step82]: loss 0.036412
[epoch8, step83]: loss 0.038303
[epoch8, step84]: loss 0.039156
[epoch8, step85]: loss 0.036553
[epoch8, step86]: loss 0.036341
[epoch8, step87]: loss 0.040106
[epoch8, step88]: loss 0.035510
[epoch8, step89]: loss 0.038598
[epoch8, step90]: loss 0.036333
[epoch8, step91]: loss 0.036173
[epoch8, step92]: loss 0.039116
[epoch8, step93]: loss 0.038938
[epoch8, step94]: loss 0.035855
[epoch8, step95]: loss 0.036618
[epoch8, step96]: loss 0.038837
[epoch8, step97]: loss 0.037194
[epoch8, step98]: loss 0.038896
[epoch8, step99]: loss 0.036021
[epoch8, step100]: loss 0.035721
[epoch8, step101]: loss 0.039519
[epoch8, step102]: loss 0.038953
[epoch8, step103]: loss 0.035928
[epoch8, step104]: loss 0.036247
[epoch8, step105]: loss 0.039272
[epoch8, step106]: loss 0.036464
[epoch8, step107]: loss 0.038850
[epoch8, step108]: loss 0.036150
[epoch8, step109]: loss 0.036234
[epoch8, step110]: loss 0.039597
[epoch8, step111]: loss 0.038709
[epoch8, step112]: loss 0.036124
[epoch8, step113]: loss 0.036934
[epoch8, step114]: loss 0.038920
[epoch8, step115]: loss 0.036570
[epoch8, step116]: loss 0.039502
[epoch8, step117]: loss 0.035919
[epoch8, step118]: loss 0.037122
[epoch8, step119]: loss 0.039357
[epoch8, step120]: loss 0.039072
[epoch8, step121]: loss 0.035729
[epoch8, step122]: loss 0.036065
[epoch8, step123]: loss 0.039500
[epoch8, step124]: loss 0.036746
[epoch8, step125]: loss 0.039333
[epoch8, step126]: loss 0.035892
[epoch8, step127]: loss 0.036450
[epoch8, step128]: loss 0.038944
[epoch8, step129]: loss 0.038461
[epoch8, step130]: loss 0.036067
[epoch8, step131]: loss 0.035563
[epoch8, step132]: loss 0.039237
[epoch8, step133]: loss 0.036273
[epoch8, step134]: loss 0.038365
[epoch8, step135]: loss 0.036423
[epoch8, step136]: loss 0.037515
[epoch8, step137]: loss 0.038708
[epoch8, step138]: loss 0.038813
[epoch8, step139]: loss 0.035780
[epoch8, step140]: loss 0.036548
[epoch8, step141]: loss 0.039272
[epoch8, step142]: loss 0.036406
[epoch8, step143]: loss 0.038508
[epoch8, step144]: loss 0.036176
[epoch8, step145]: loss 0.036620
[epoch8, step146]: loss 0.039101
[epoch8, step147]: loss 0.040130
[epoch8, step148]: loss 0.035767
[epoch8, step149]: loss 0.035649
[epoch8, step150]: loss 0.038735
[epoch8, step151]: loss 0.036497
[epoch8, step152]: loss 0.038881
[epoch8, step153]: loss 0.036089
[epoch8, step154]: loss 0.036043
[epoch8, step155]: loss 0.039021
[epoch8, step156]: loss 0.038541
[epoch8, step157]: loss 0.036113
[epoch8, step158]: loss 0.036286
[epoch8, step159]: loss 0.039363
[epoch8, step160]: loss 0.036748
[epoch8, step161]: loss 0.039407
[epoch8, step162]: loss 0.036130
[epoch8, step163]: loss 0.036314
[epoch8, step164]: loss 0.039293
[epoch8, step165]: loss 0.038994
[epoch8, step166]: loss 0.036233
[epoch8, step167]: loss 0.035698
[epoch8, step168]: loss 0.039563
[epoch8, step169]: loss 0.036218
[epoch8, step170]: loss 0.039184
[epoch8, step171]: loss 0.036152
[epoch8, step172]: loss 0.036519
[epoch8, step173]: loss 0.039245
[epoch8, step174]: loss 0.038834
[epoch8, step175]: loss 0.036778
[epoch8, step176]: loss 0.036369
[epoch8, step177]: loss 0.039499
[epoch8, step178]: loss 0.036442
[epoch8, step179]: loss 0.038098
[epoch8, step180]: loss 0.036273
[epoch8, step181]: loss 0.036543
[epoch8, step182]: loss 0.039310
[epoch8, step183]: loss 0.039504
[epoch8, step184]: loss 0.036992
[epoch8, step185]: loss 0.036324
[epoch8, step186]: loss 0.039214
[epoch8, step187]: loss 0.036462
[epoch8, step188]: loss 0.038594
[epoch8, step189]: loss 0.035965
[epoch8, step190]: loss 0.035916
[epoch8, step191]: loss 0.038696
[epoch8, step192]: loss 0.039349
[epoch8, step193]: loss 0.034238
[epoch8, step194]: loss 0.035209
[epoch8, step195]: loss 0.039371
[epoch8, step196]: loss 0.036464
[epoch8, step197]: loss 0.038745
[epoch8, step198]: loss 0.035000
[epoch8, step199]: loss 0.036422
[epoch8, step200]: loss 0.039411
[epoch8, step201]: loss 0.039436
[epoch8, step202]: loss 0.035740
[epoch8, step203]: loss 0.036106
[epoch8, step204]: loss 0.039463
[epoch8, step205]: loss 0.035728
[epoch8, step206]: loss 0.038614
[epoch8, step207]: loss 0.035716
[epoch8, step208]: loss 0.036705
[epoch8, step209]: loss 0.039220
[epoch8, step210]: loss 0.039723
[epoch8, step211]: loss 0.036449
[epoch8, step212]: loss 0.036472
[epoch8, step213]: loss 0.038675
[epoch8, step214]: loss 0.035966
[epoch8, step215]: loss 0.038935
[epoch8, step216]: loss 0.036184
[epoch8, step217]: loss 0.035426
[epoch8, step218]: loss 0.039132
[epoch8, step219]: loss 0.038874
[epoch8, step220]: loss 0.036350
[epoch8, step221]: loss 0.036259
[epoch8, step222]: loss 0.039240
[epoch8, step223]: loss 0.036545
[epoch8, step224]: loss 0.038631
[epoch8, step225]: loss 0.035913
[epoch8, step226]: loss 0.036200
[epoch8, step227]: loss 0.038111
[epoch8, step228]: loss 0.039238
[epoch8, step229]: loss 0.035144
[epoch8, step230]: loss 0.036131
[epoch8, step231]: loss 0.039299
[epoch8, step232]: loss 0.035924
[epoch8, step233]: loss 0.037873
[epoch8, step234]: loss 0.035460
[epoch8, step235]: loss 0.036702
[epoch8, step236]: loss 0.038889
[epoch8, step237]: loss 0.039174
[epoch8, step238]: loss 0.035741
[epoch8, step239]: loss 0.035300
[epoch8, step240]: loss 0.038700
[epoch8, step241]: loss 0.036711
[epoch8, step242]: loss 0.038685
[epoch8, step243]: loss 0.036473
[epoch8, step244]: loss 0.036298
[epoch8, step245]: loss 0.038739
[epoch8, step246]: loss 0.038609
[epoch8, step247]: loss 0.036269
[epoch8, step248]: loss 0.035361
[epoch8, step249]: loss 0.038440
[epoch8, step250]: loss 0.036242
[epoch8, step251]: loss 0.039186
[epoch8, step252]: loss 0.036274
[epoch8, step253]: loss 0.035773
[epoch8, step254]: loss 0.038078
[epoch8, step255]: loss 0.039075
[epoch8, step256]: loss 0.035705
[epoch8, step257]: loss 0.035806
[epoch8, step258]: loss 0.039932
[epoch8, step259]: loss 0.036171
[epoch8, step260]: loss 0.038185
[epoch8, step261]: loss 0.036851
[epoch8, step262]: loss 0.036325
[epoch8, step263]: loss 0.037979
[epoch8, step264]: loss 0.038256
[epoch8, step265]: loss 0.036120
[epoch8, step266]: loss 0.035552
[epoch8, step267]: loss 0.038373
[epoch8, step268]: loss 0.036315
[epoch8, step269]: loss 0.038683
[epoch8, step270]: loss 0.035484
[epoch8, step271]: loss 0.036327
[epoch8, step272]: loss 0.038899
[epoch8, step273]: loss 0.038717
[epoch8, step274]: loss 0.036480
[epoch8, step275]: loss 0.035639
[epoch8, step276]: loss 0.038688
[epoch8, step277]: loss 0.036696
[epoch8, step278]: loss 0.039012
[epoch8, step279]: loss 0.035439
[epoch8, step280]: loss 0.036072
[epoch8, step281]: loss 0.038685
[epoch8, step282]: loss 0.039146
[epoch8, step283]: loss 0.035606
[epoch8, step284]: loss 0.035306
[epoch8, step285]: loss 0.039604
[epoch8, step286]: loss 0.035472
[epoch8, step287]: loss 0.038791
[epoch8, step288]: loss 0.035174
[epoch8, step289]: loss 0.036984
[epoch8, step290]: loss 0.038747
[epoch8, step291]: loss 0.039171
[epoch8, step292]: loss 0.035143
[epoch8, step293]: loss 0.035325
[epoch8, step294]: loss 0.037990
[epoch8, step295]: loss 0.035513
[epoch8, step296]: loss 0.039267
[epoch8, step297]: loss 0.035167
[epoch8, step298]: loss 0.036251
[epoch8, step299]: loss 0.037654
[epoch8, step300]: loss 0.038791
[epoch8, step301]: loss 0.035681
[epoch8, step302]: loss 0.036077
[epoch8, step303]: loss 0.039243
[epoch8, step304]: loss 0.035819
[epoch8, step305]: loss 0.038028
[epoch8, step306]: loss 0.036182
[epoch8, step307]: loss 0.035750
[epoch8, step308]: loss 0.039269
[epoch8, step309]: loss 0.039288
[epoch8, step310]: loss 0.036330
[epoch8, step311]: loss 0.035946
[epoch8, step312]: loss 0.038715
[epoch8, step313]: loss 0.036732
[epoch8, step314]: loss 0.038551
[epoch8, step315]: loss 0.036484
[epoch8, step316]: loss 0.035901
[epoch8, step317]: loss 0.038973
[epoch8, step318]: loss 0.038907
[epoch8, step319]: loss 0.035336
[epoch8, step320]: loss 0.034878
[epoch8, step321]: loss 0.038429
[epoch8, step322]: loss 0.036123
[epoch8, step323]: loss 0.038364
[epoch8, step324]: loss 0.036219
[epoch8, step325]: loss 0.036314
[epoch8, step326]: loss 0.038476
[epoch8, step327]: loss 0.037967
[epoch8, step328]: loss 0.035906
[epoch8, step329]: loss 0.035351
[epoch8, step330]: loss 0.038390
[epoch8, step331]: loss 0.036148
[epoch8, step332]: loss 0.037808
[epoch8, step333]: loss 0.035388
[epoch8, step334]: loss 0.035823
[epoch8, step335]: loss 0.038550
[epoch8, step336]: loss 0.039324
[epoch8, step337]: loss 0.035928
[epoch8, step338]: loss 0.035180
[epoch8, step339]: loss 0.038180
[epoch8, step340]: loss 0.036595
[epoch8, step341]: loss 0.038343
[epoch8, step342]: loss 0.034959
[epoch8, step343]: loss 0.036208
[epoch8, step344]: loss 0.038098
[epoch8, step345]: loss 0.037681
[epoch8, step346]: loss 0.035192
[epoch8, step347]: loss 0.035110
[epoch8, step348]: loss 0.038854
[epoch8, step349]: loss 0.036193
[epoch8, step350]: loss 0.037691
[epoch8, step351]: loss 0.034725
[epoch8, step352]: loss 0.035609
[epoch8, step353]: loss 0.038333
[epoch8, step354]: loss 0.037415
[epoch8, step355]: loss 0.034553
[epoch8, step356]: loss 0.036219
[epoch8, step357]: loss 0.038478
[epoch8, step358]: loss 0.034644
[epoch8, step359]: loss 0.039560
[epoch8, step360]: loss 0.034134
[epoch8, step361]: loss 0.035314
[epoch8, step362]: loss 0.039182
[epoch8, step363]: loss 0.037958
[epoch8, step364]: loss 0.035482
[epoch8, step365]: loss 0.035248
[epoch8, step366]: loss 0.038736
[epoch8, step367]: loss 0.035905
[epoch8, step368]: loss 0.037915
[epoch8, step369]: loss 0.035161
[epoch8, step370]: loss 0.036501
[epoch8, step371]: loss 0.039173
[epoch8, step372]: loss 0.038362
[epoch8, step373]: loss 0.035352
[epoch8, step374]: loss 0.035085
[epoch8, step375]: loss 0.039275
[epoch8, step376]: loss 0.035792
[epoch8, step377]: loss 0.038796
[epoch8, step378]: loss 0.036159
[epoch8, step379]: loss 0.036323
[epoch8, step380]: loss 0.038894
[epoch8, step381]: loss 0.037819
[epoch8, step382]: loss 0.035680
[epoch8, step383]: loss 0.034222
[epoch8, step384]: loss 0.037713
[epoch8, step385]: loss 0.035572
[epoch8, step386]: loss 0.038319
[epoch8, step387]: loss 0.035365
[epoch8, step388]: loss 0.036638
[epoch8, step389]: loss 0.038420
[epoch8, step390]: loss 0.039088
[epoch8, step391]: loss 0.035078
[epoch8, step392]: loss 0.036125
[epoch8, step393]: loss 0.037741
[epoch8, step394]: loss 0.036048
[epoch8, step395]: loss 0.037926
[epoch8, step396]: loss 0.035526
[epoch8, step397]: loss 0.035877
[epoch8, step398]: loss 0.038486
[epoch8, step399]: loss 0.038770
[epoch8, step400]: loss 0.036284
[epoch8, step401]: loss 0.035571
[epoch8, step402]: loss 0.038134
[epoch8, step403]: loss 0.036072
[epoch8, step404]: loss 0.038645
[epoch8, step405]: loss 0.035629
[epoch8, step406]: loss 0.036053
[epoch8, step407]: loss 0.038217
[epoch8, step408]: loss 0.038313
[epoch8, step409]: loss 0.037003
[epoch8, step410]: loss 0.036208
[epoch8, step411]: loss 0.038070
[epoch8, step412]: loss 0.035745
[epoch8, step413]: loss 0.038797
[epoch8, step414]: loss 0.035290
[epoch8, step415]: loss 0.036252
[epoch8, step416]: loss 0.038672
[epoch8, step417]: loss 0.038754
[epoch8, step418]: loss 0.035466
[epoch8, step419]: loss 0.034826
[epoch8, step420]: loss 0.038648
[epoch8, step421]: loss 0.035542
[epoch8, step422]: loss 0.037911
[epoch8, step423]: loss 0.035623
[epoch8, step424]: loss 0.035637
[epoch8, step425]: loss 0.038473
[epoch8, step426]: loss 0.038686
[epoch8, step427]: loss 0.035761
[epoch8, step428]: loss 0.035375
[epoch8, step429]: loss 0.039080
[epoch8, step430]: loss 0.035996
[epoch8, step431]: loss 0.039120
[epoch8, step432]: loss 0.035104
[epoch8, step433]: loss 0.036806
[epoch8, step434]: loss 0.038350
[epoch8, step435]: loss 0.038246
[epoch8, step436]: loss 0.035177
[epoch8, step437]: loss 0.035646
[epoch8, step438]: loss 0.038790
[epoch8, step439]: loss 0.035954
[epoch8, step440]: loss 0.038173
[epoch8, step441]: loss 0.035682
[epoch8, step442]: loss 0.035642
[epoch8, step443]: loss 0.038711
[epoch8, step444]: loss 0.037777
[epoch8, step445]: loss 0.035785
[epoch8, step446]: loss 0.035817
[epoch8, step447]: loss 0.038787
[epoch8, step448]: loss 0.036004
[epoch8, step449]: loss 0.038041
[epoch8, step450]: loss 0.034646
[epoch8, step451]: loss 0.035384
[epoch8, step452]: loss 0.037062
[epoch8, step453]: loss 0.038713
[epoch8, step454]: loss 0.035459
[epoch8, step455]: loss 0.035590
[epoch8, step456]: loss 0.037918
[epoch8, step457]: loss 0.036413
[epoch8, step458]: loss 0.038239
[epoch8, step459]: loss 0.035959
[epoch8, step460]: loss 0.035711
[epoch8, step461]: loss 0.038867
[epoch8, step462]: loss 0.037492
[epoch8, step463]: loss 0.035793
[epoch8, step464]: loss 0.035137
[epoch8, step465]: loss 0.039459
[epoch8, step466]: loss 0.035680
[epoch8, step467]: loss 0.038087
[epoch8, step468]: loss 0.035207
[epoch8, step469]: loss 0.035916
[epoch8, step470]: loss 0.038572
[epoch8, step471]: loss 0.037830
[epoch8, step472]: loss 0.036012
[epoch8, step473]: loss 0.035182
[epoch8, step474]: loss 0.037991
[epoch8, step475]: loss 0.035973
[epoch8, step476]: loss 0.038392
[epoch8, step477]: loss 0.035265
[epoch8, step478]: loss 0.035063
[epoch8, step479]: loss 0.037864
[epoch8, step480]: loss 0.037256
[epoch8, step481]: loss 0.034853
[epoch8, step482]: loss 0.034859
[epoch8, step483]: loss 0.038471
[epoch8, step484]: loss 0.036285
[epoch8, step485]: loss 0.037965
[epoch8, step486]: loss 0.035989
[epoch8, step487]: loss 0.035826
[epoch8, step488]: loss 0.038975
[epoch8, step489]: loss 0.037476
[epoch8, step490]: loss 0.036518
[epoch8, step491]: loss 0.035751
[epoch8, step492]: loss 0.037995
[epoch8, step493]: loss 0.035570
[epoch8, step494]: loss 0.037400
[epoch8, step495]: loss 0.036583
[epoch8, step496]: loss 0.035633
[epoch8, step497]: loss 0.038449
[epoch8, step498]: loss 0.037947
[epoch8, step499]: loss 0.036408
[epoch8, step500]: loss 0.034740
[epoch8, step501]: loss 0.037998
[epoch8, step502]: loss 0.035743
[epoch8, step503]: loss 0.038608
[epoch8, step504]: loss 0.035339
[epoch8, step505]: loss 0.035034
[epoch8, step506]: loss 0.039304
[epoch8, step507]: loss 0.039533
[epoch8, step508]: loss 0.036404
[epoch8, step509]: loss 0.035455
[epoch8, step510]: loss 0.038908
[epoch8, step511]: loss 0.036320
[epoch8, step512]: loss 0.038937
[epoch8, step513]: loss 0.036011
[epoch8, step514]: loss 0.035950
[epoch8, step515]: loss 0.038464
[epoch8, step516]: loss 0.038602
[epoch8, step517]: loss 0.035568
[epoch8, step518]: loss 0.035575
[epoch8, step519]: loss 0.038227
[epoch8, step520]: loss 0.035186
[epoch8, step521]: loss 0.037841
[epoch8, step522]: loss 0.034558
[epoch8, step523]: loss 0.035461
[epoch8, step524]: loss 0.037965
[epoch8, step525]: loss 0.038283
[epoch8, step526]: loss 0.035774
[epoch8, step527]: loss 0.035622
[epoch8, step528]: loss 0.038477
[epoch8, step529]: loss 0.035402
[epoch8, step530]: loss 0.039444
[epoch8, step531]: loss 0.035304
[epoch8, step532]: loss 0.035564
[epoch8, step533]: loss 0.039156
[epoch8, step534]: loss 0.038192
[epoch8, step535]: loss 0.036089
[epoch8, step536]: loss 0.035311
[epoch8, step537]: loss 0.037958
[epoch8, step538]: loss 0.035974
[epoch8, step539]: loss 0.038010
[epoch8, step540]: loss 0.034954
[epoch8, step541]: loss 0.035252
[epoch8, step542]: loss 0.038219
[epoch8, step543]: loss 0.037707
[epoch8, step544]: loss 0.035497
[epoch8, step545]: loss 0.034861
[epoch8, step546]: loss 0.039012
[epoch8, step547]: loss 0.035392
[epoch8, step548]: loss 0.038554
[epoch8, step549]: loss 0.035747
[epoch8, step550]: loss 0.036032
[epoch8, step551]: loss 0.038212
[epoch8, step552]: loss 0.037780
[epoch8, step553]: loss 0.036297
[epoch8, step554]: loss 0.034988
[epoch8, step555]: loss 0.037845
[epoch8, step556]: loss 0.035448
[epoch8, step557]: loss 0.037641
[epoch8, step558]: loss 0.035366
[epoch8, step559]: loss 0.034998
[epoch8, step560]: loss 0.038133
[epoch8, step561]: loss 0.038087
[epoch8, step562]: loss 0.035613
[epoch8, step563]: loss 0.035812
[epoch8, step564]: loss 0.039959
[epoch8, step565]: loss 0.038638
[epoch8, step566]: loss 0.044646
[epoch8, step567]: loss 0.038132
[epoch8, step568]: loss 0.036762
[epoch8, step569]: loss 0.033624
[epoch8, step570]: loss 0.042358
[epoch8, step571]: loss 0.039103
[epoch8, step572]: loss 0.038797
[epoch8, step573]: loss 0.040376
[epoch8, step574]: loss 0.043438
[epoch8, step575]: loss 0.032677
[epoch8, step576]: loss 0.034204
[epoch8, step577]: loss 0.036728
[epoch8, step578]: loss 0.030397
[epoch8, step579]: loss 0.039819
[epoch8, step580]: loss 0.030767
[epoch8, step581]: loss 0.036887
[epoch8, step582]: loss 0.036289
[epoch8, step583]: loss 0.035228
[epoch8, step584]: loss 0.034711
[epoch8, step585]: loss 0.037639
[epoch8, step586]: loss 0.034042
[epoch8, step587]: loss 0.039925
[epoch8, step588]: loss 0.034806
[epoch8, step589]: loss 0.035540
[epoch8, step590]: loss 0.039475
[epoch8, step591]: loss 0.031825
[epoch8, step592]: loss 0.037568
[epoch8, step593]: loss 0.033087
[epoch8, step594]: loss 0.037971
[epoch8, step595]: loss 0.038553
[epoch8, step596]: loss 0.035901
[epoch8, step597]: loss 0.036204
[epoch8, step598]: loss 0.038179
[epoch8, step599]: loss 0.035980
[epoch8, step600]: loss 0.038589
[epoch8, step601]: loss 0.030686
[epoch8, step602]: loss 0.034256
[epoch8, step603]: loss 0.037523
[epoch8, step604]: loss 0.038515
[epoch8, step605]: loss 0.035931
[epoch8, step606]: loss 0.036110
[epoch8, step607]: loss 0.038907
[epoch8, step608]: loss 0.037454
[epoch8, step609]: loss 0.037567
[epoch8, step610]: loss 0.039132
[epoch8, step611]: loss 0.037804
[epoch8, step612]: loss 0.036482
[epoch8, step613]: loss 0.030552
[epoch8, step614]: loss 0.035625
[epoch8, step615]: loss 0.041006
[epoch8, step616]: loss 0.034655
[epoch8, step617]: loss 0.034338
[epoch8, step618]: loss 0.038244
[epoch8, step619]: loss 0.038878
[epoch8, step620]: loss 0.035256
[epoch8, step621]: loss 0.037975
[epoch8, step622]: loss 0.031804
[epoch8, step623]: loss 0.034785
[epoch8, step624]: loss 0.038043
[epoch8, step625]: loss 0.036840
[epoch8, step626]: loss 0.039279
[epoch8, step627]: loss 0.034239
[epoch8, step628]: loss 0.036711
[epoch8, step629]: loss 0.031339
[epoch8, step630]: loss 0.033189
[epoch8, step631]: loss 0.044024
[epoch8, step632]: loss 0.034968
[epoch8, step633]: loss 0.035656
[epoch8, step634]: loss 0.038844
[epoch8, step635]: loss 0.037698
[epoch8, step636]: loss 0.032421
[epoch8, step637]: loss 0.038656
[epoch8, step638]: loss 0.038739
[epoch8, step639]: loss 0.033162
[epoch8, step640]: loss 0.040758
[epoch8, step641]: loss 0.041858
[epoch8, step642]: loss 0.035972
[epoch8, step643]: loss 0.036486
[epoch8, step644]: loss 0.037008
[epoch8, step645]: loss 0.034791
[epoch8, step646]: loss 0.036518
[epoch8, step647]: loss 0.034407
[epoch8, step648]: loss 0.035203
[epoch8, step649]: loss 0.039658
[epoch8, step650]: loss 0.033405
[epoch8, step651]: loss 0.037658
[epoch8, step652]: loss 0.037996
[epoch8, step653]: loss 0.038999
[epoch8, step654]: loss 0.033490
[epoch8, step655]: loss 0.035071
[epoch8, step656]: loss 0.033547
[epoch8, step657]: loss 0.038838
[epoch8, step658]: loss 0.035972
[epoch8, step659]: loss 0.038356
[epoch8, step660]: loss 0.034035
[epoch8, step661]: loss 0.037408
[epoch8, step662]: loss 0.034732
[epoch8, step663]: loss 0.032587
[epoch8, step664]: loss 0.036677
[epoch8, step665]: loss 0.038261
[epoch8, step666]: loss 0.037145
[epoch8, step667]: loss 0.038202
[epoch8, step668]: loss 0.034168
[epoch8, step669]: loss 0.037919
[epoch8, step670]: loss 0.038405
[epoch8, step671]: loss 0.032286
[epoch8, step672]: loss 0.036154
[epoch8, step673]: loss 0.034130
[epoch8, step674]: loss 0.031711
[epoch8, step675]: loss 0.031065
[epoch8, step676]: loss 0.035759
[epoch8, step677]: loss 0.036578
[epoch8, step678]: loss 0.034060
[epoch8, step679]: loss 0.035589
[epoch8, step680]: loss 0.042394
[epoch8, step681]: loss 0.032476
[epoch8, step682]: loss 0.037664
[epoch8, step683]: loss 0.036718
[epoch8, step684]: loss 0.036141
[epoch8, step685]: loss 0.036075
[epoch8, step686]: loss 0.038614
[epoch8, step687]: loss 0.037607
[epoch8, step688]: loss 0.035028
[epoch8, step689]: loss 0.035500
[epoch8, step690]: loss 0.036906
[epoch8, step691]: loss 0.036628
[epoch8, step692]: loss 0.034376
[epoch8, step693]: loss 0.040257
[epoch8, step694]: loss 0.033289
[epoch8, step695]: loss 0.038445
[epoch8, step696]: loss 0.036402
[epoch8, step697]: loss 0.039089
[epoch8, step698]: loss 0.036311
[epoch8, step699]: loss 0.034838
[epoch8, step700]: loss 0.032574
[epoch8, step701]: loss 0.037123
[epoch8, step702]: loss 0.032086
[epoch8, step703]: loss 0.034651
[epoch8, step704]: loss 0.037170
[epoch8, step705]: loss 0.036376
[epoch8, step706]: loss 0.034604
[epoch8, step707]: loss 0.035087
[epoch8, step708]: loss 0.036035
[epoch8, step709]: loss 0.038866
[epoch8, step710]: loss 0.033893
[epoch8, step711]: loss 0.036849
[epoch8, step712]: loss 0.037851
[epoch8, step713]: loss 0.038092
[epoch8, step714]: loss 0.032552
[epoch8, step715]: loss 0.033821
[epoch8, step716]: loss 0.036816
[epoch8, step717]: loss 0.033619
[epoch8, step718]: loss 0.036392
[epoch8, step719]: loss 0.045856
[epoch8, step720]: loss 0.035449
[epoch8, step721]: loss 0.034195
[epoch8, step722]: loss 0.042486
[epoch8, step723]: loss 0.037890
[epoch8, step724]: loss 0.034054
[epoch8, step725]: loss 0.038388
[epoch8, step726]: loss 0.032935
[epoch8, step727]: loss 0.035356
[epoch8, step728]: loss 0.037956
[epoch8, step729]: loss 0.032929
[epoch8, step730]: loss 0.033515
[epoch8, step731]: loss 0.036795
[epoch8, step732]: loss 0.036956
[epoch8, step733]: loss 0.034603
[epoch8, step734]: loss 0.034171
[epoch8, step735]: loss 0.039509
[epoch8, step736]: loss 0.035929
[epoch8, step737]: loss 0.037798
[epoch8, step738]: loss 0.030990
[epoch8, step739]: loss 0.037460
[epoch8, step740]: loss 0.033764
[epoch8, step741]: loss 0.037186
[epoch8, step742]: loss 0.033285
[epoch8, step743]: loss 0.034864
[epoch8, step744]: loss 0.034653
[epoch8, step745]: loss 0.034941
[epoch8, step746]: loss 0.036790
[epoch8, step747]: loss 0.039533
[epoch8, step748]: loss 0.036781
[epoch8, step749]: loss 0.037121
[epoch8, step750]: loss 0.039101
[epoch8, step751]: loss 0.033944
[epoch8, step752]: loss 0.035867
[epoch8, step753]: loss 0.035943
[epoch8, step754]: loss 0.034569
[epoch8, step755]: loss 0.037276
[epoch8, step756]: loss 0.034733
[epoch8, step757]: loss 0.030710
[epoch8, step758]: loss 0.035124
[epoch8, step759]: loss 0.033467
[epoch8, step760]: loss 0.034827
[epoch8, step761]: loss 0.037753
[epoch8, step762]: loss 0.032283
[epoch8, step763]: loss 0.036947
[epoch8, step764]: loss 0.035589
[epoch8, step765]: loss 0.037167
[epoch8, step766]: loss 0.036652
[epoch8, step767]: loss 0.039381
[epoch8, step768]: loss 0.031673
[epoch8, step769]: loss 0.037201
[epoch8, step770]: loss 0.036044
[epoch8, step771]: loss 0.033707
[epoch8, step772]: loss 0.039769
[epoch8, step773]: loss 0.036811
[epoch8, step774]: loss 0.035633
[epoch8, step775]: loss 0.030797
[epoch8, step776]: loss 0.037439
[epoch8, step777]: loss 0.033784
[epoch8, step778]: loss 0.038288
[epoch8, step779]: loss 0.035399
[epoch8, step780]: loss 0.030238
[epoch8, step781]: loss 0.035406
[epoch8, step782]: loss 0.033217
[epoch8, step783]: loss 0.030827
[epoch8, step784]: loss 0.031589
[epoch8, step785]: loss 0.032397
[epoch8, step786]: loss 0.035087
[epoch8, step787]: loss 0.034944
[epoch8, step788]: loss 0.036824
[epoch8, step789]: loss 0.035192
[epoch8, step790]: loss 0.034485
[epoch8, step791]: loss 0.038513
[epoch8, step792]: loss 0.035937
[epoch8, step793]: loss 0.038163
[epoch8, step794]: loss 0.031331
[epoch8, step795]: loss 0.036344
[epoch8, step796]: loss 0.038971
[epoch8, step797]: loss 0.037954
[epoch8, step798]: loss 0.038211
[epoch8, step799]: loss 0.037487
[epoch8, step800]: loss 0.032199
[epoch8, step801]: loss 0.034049
[epoch8, step802]: loss 0.033582
[epoch8, step803]: loss 0.037777
[epoch8, step804]: loss 0.038648
[epoch8, step805]: loss 0.038626
[epoch8, step806]: loss 0.032601
[epoch8, step807]: loss 0.031872
[epoch8, step808]: loss 0.034249
[epoch8, step809]: loss 0.032868
[epoch8, step810]: loss 0.036794
[epoch8, step811]: loss 0.036014
[epoch8, step812]: loss 0.035147
[epoch8, step813]: loss 0.034147
[epoch8, step814]: loss 0.036614
[epoch8, step815]: loss 0.035117
[epoch8, step816]: loss 0.035458
[epoch8, step817]: loss 0.035986
[epoch8, step818]: loss 0.033068
[epoch8, step819]: loss 0.031840
[epoch8, step820]: loss 0.034568
[epoch8, step821]: loss 0.032258
[epoch8, step822]: loss 0.041119
[epoch8, step823]: loss 0.034803
[epoch8, step824]: loss 0.037654
[epoch8, step825]: loss 0.036847
[epoch8, step826]: loss 0.035070
[epoch8, step827]: loss 0.038450
[epoch8, step828]: loss 0.039577
[epoch8, step829]: loss 0.038677
[epoch8, step830]: loss 0.033792
[epoch8, step831]: loss 0.037749
[epoch8, step832]: loss 0.032537
[epoch8, step833]: loss 0.039432
[epoch8, step834]: loss 0.037233
[epoch8, step835]: loss 0.031367
[epoch8, step836]: loss 0.039632
[epoch8, step837]: loss 0.036873
[epoch8, step838]: loss 0.035708
[epoch8, step839]: loss 0.039407
[epoch8, step840]: loss 0.031480
[epoch8, step841]: loss 0.035720
[epoch8, step842]: loss 0.038610
[epoch8, step843]: loss 0.036439
[epoch8, step844]: loss 0.035929
[epoch8, step845]: loss 0.032460
[epoch8, step846]: loss 0.038904
[epoch8, step847]: loss 0.037714
[epoch8, step848]: loss 0.035726
[epoch8, step849]: loss 0.034965
[epoch8, step850]: loss 0.033917
[epoch8, step851]: loss 0.035430
[epoch8, step852]: loss 0.033293
[epoch8, step853]: loss 0.040891
[epoch8, step854]: loss 0.034295
[epoch8, step855]: loss 0.038007
[epoch8, step856]: loss 0.032131
[epoch8, step857]: loss 0.035480
[epoch8, step858]: loss 0.034927
[epoch8, step859]: loss 0.034540
[epoch8, step860]: loss 0.033523
[epoch8, step861]: loss 0.033574
[epoch8, step862]: loss 0.033502
[epoch8, step863]: loss 0.031711
[epoch8, step864]: loss 0.037944
[epoch8, step865]: loss 0.034917
[epoch8, step866]: loss 0.035731
[epoch8, step867]: loss 0.036901
[epoch8, step868]: loss 0.037933
[epoch8, step869]: loss 0.034758
[epoch8, step870]: loss 0.041952
[epoch8, step871]: loss 0.034079
[epoch8, step872]: loss 0.036491
[epoch8, step873]: loss 0.036293
[epoch8, step874]: loss 0.035039
[epoch8, step875]: loss 0.034758
[epoch8, step876]: loss 0.036292
[epoch8, step877]: loss 0.030223
[epoch8, step878]: loss 0.033981
[epoch8, step879]: loss 0.039517
[epoch8, step880]: loss 0.036282
[epoch8, step881]: loss 0.033277
[epoch8, step882]: loss 0.034632
[epoch8, step883]: loss 0.034461
[epoch8, step884]: loss 0.037578
[epoch8, step885]: loss 0.036461
[epoch8, step886]: loss 0.036896
[epoch8, step887]: loss 0.035310
[epoch8, step888]: loss 0.035532
[epoch8, step889]: loss 0.035077
[epoch8, step890]: loss 0.034889
[epoch8, step891]: loss 0.036880
[epoch8, step892]: loss 0.030707
[epoch8, step893]: loss 0.035307
[epoch8, step894]: loss 0.035628
[epoch8, step895]: loss 0.033077
[epoch8, step896]: loss 0.033486
[epoch8, step897]: loss 0.036214
[epoch8, step898]: loss 0.037499
[epoch8, step899]: loss 0.039555
[epoch8, step900]: loss 0.037319
[epoch8, step901]: loss 0.037538
[epoch8, step902]: loss 0.034372
[epoch8, step903]: loss 0.035855
[epoch8, step904]: loss 0.038175
[epoch8, step905]: loss 0.038595
[epoch8, step906]: loss 0.032703
[epoch8, step907]: loss 0.034451
[epoch8, step908]: loss 0.032759
[epoch8, step909]: loss 0.037526
[epoch8, step910]: loss 0.033955
[epoch8, step911]: loss 0.035719
[epoch8, step912]: loss 0.033710
[epoch8, step913]: loss 0.035062
[epoch8, step914]: loss 0.040146
[epoch8, step915]: loss 0.034417
[epoch8, step916]: loss 0.033925
[epoch8, step917]: loss 0.035316
[epoch8, step918]: loss 0.039869
[epoch8, step919]: loss 0.035177
[epoch8, step920]: loss 0.038184
[epoch8, step921]: loss 0.034505
[epoch8, step922]: loss 0.034560
[epoch8, step923]: loss 0.033829
[epoch8, step924]: loss 0.030821
[epoch8, step925]: loss 0.036214
[epoch8, step926]: loss 0.036009
[epoch8, step927]: loss 0.035996
[epoch8, step928]: loss 0.034947
[epoch8, step929]: loss 0.038221
[epoch8, step930]: loss 0.036448
[epoch8, step931]: loss 0.037923
[epoch8, step932]: loss 0.032081
[epoch8, step933]: loss 0.039266
[epoch8, step934]: loss 0.033330
[epoch8, step935]: loss 0.033999
[epoch8, step936]: loss 0.032894
[epoch8, step937]: loss 0.037128
[epoch8, step938]: loss 0.038399
[epoch8, step939]: loss 0.031612
[epoch8, step940]: loss 0.034218
[epoch8, step941]: loss 0.038377
[epoch8, step942]: loss 0.036447
[epoch8, step943]: loss 0.034431
[epoch8, step944]: loss 0.038364
[epoch8, step945]: loss 0.031618
[epoch8, step946]: loss 0.036439
[epoch8, step947]: loss 0.039344
[epoch8, step948]: loss 0.030554
[epoch8, step949]: loss 0.034113
[epoch8, step950]: loss 0.038048
[epoch8, step951]: loss 0.039853
[epoch8, step952]: loss 0.035347
[epoch8, step953]: loss 0.038540
[epoch8, step954]: loss 0.033666
[epoch8, step955]: loss 0.042032
[epoch8, step956]: loss 0.051166
[epoch8, step957]: loss 0.047881
[epoch8, step958]: loss 0.046388
[epoch8, step959]: loss 0.048818
[epoch8, step960]: loss 0.046006
[epoch8, step961]: loss 0.045819
[epoch8, step962]: loss 0.045329
[epoch8, step963]: loss 0.044081
[epoch8, step964]: loss 0.044614
[epoch8, step965]: loss 0.044398
[epoch8, step966]: loss 0.043906
[epoch8, step967]: loss 0.043525
[epoch8, step968]: loss 0.044813
[epoch8, step969]: loss 0.044864
[epoch8, step970]: loss 0.043942
[epoch8, step971]: loss 0.042933
[epoch8, step972]: loss 0.043960
[epoch8, step973]: loss 0.043658
[epoch8, step974]: loss 0.045416
[epoch8, step975]: loss 0.043024
[epoch8, step976]: loss 0.042495
[epoch8, step977]: loss 0.044692
[epoch8, step978]: loss 0.043832
[epoch8, step979]: loss 0.042924
[epoch8, step980]: loss 0.041870
[epoch8, step981]: loss 0.043255
[epoch8, step982]: loss 0.043044
[epoch8, step983]: loss 0.043936
[epoch8, step984]: loss 0.042186
[epoch8, step985]: loss 0.042180
[epoch8, step986]: loss 0.044577
[epoch8, step987]: loss 0.043314
[epoch8, step988]: loss 0.043681
[epoch8, step989]: loss 0.042574
[epoch8, step990]: loss 0.042957
[epoch8, step991]: loss 0.043223
[epoch8, step992]: loss 0.044224
[epoch8, step993]: loss 0.042350
[epoch8, step994]: loss 0.041416
[epoch8, step995]: loss 0.044167
[epoch8, step996]: loss 0.043039
[epoch8, step997]: loss 0.043548
[epoch8, step998]: loss 0.042503
[epoch8, step999]: loss 0.043076
[epoch8, step1000]: loss 0.043378
[epoch8, step1001]: loss 0.043530
[epoch8, step1002]: loss 0.042088
[epoch8, step1003]: loss 0.041697
[epoch8, step1004]: loss 0.043928
[epoch8, step1005]: loss 0.042696
[epoch8, step1006]: loss 0.042483
[epoch8, step1007]: loss 0.041978
[epoch8, step1008]: loss 0.042826
[epoch8, step1009]: loss 0.043017
[epoch8, step1010]: loss 0.044396
[epoch8, step1011]: loss 0.042182
[epoch8, step1012]: loss 0.041916
[epoch8, step1013]: loss 0.044028
[epoch8, step1014]: loss 0.043053
[epoch8, step1015]: loss 0.043385
[epoch8, step1016]: loss 0.041487
[epoch8, step1017]: loss 0.042653
[epoch8, step1018]: loss 0.042879
[epoch8, step1019]: loss 0.043545
[epoch8, step1020]: loss 0.041635
[epoch8, step1021]: loss 0.041077
[epoch8, step1022]: loss 0.042953
[epoch8, step1023]: loss 0.042683
[epoch8, step1024]: loss 0.043023
[epoch8, step1025]: loss 0.041635
[epoch8, step1026]: loss 0.042308
[epoch8, step1027]: loss 0.042753
[epoch8, step1028]: loss 0.044107
[epoch8, step1029]: loss 0.042415
[epoch8, step1030]: loss 0.040694
[epoch8, step1031]: loss 0.043469
[epoch8, step1032]: loss 0.042988
[epoch8, step1033]: loss 0.042474
[epoch8, step1034]: loss 0.041393
[epoch8, step1035]: loss 0.042044
[epoch8, step1036]: loss 0.042569
[epoch8, step1037]: loss 0.042946
[epoch8, step1038]: loss 0.041390
[epoch8, step1039]: loss 0.041172
[epoch8, step1040]: loss 0.043077
[epoch8, step1041]: loss 0.042269
[epoch8, step1042]: loss 0.042049
[epoch8, step1043]: loss 0.041690
[epoch8, step1044]: loss 0.042523
[epoch8, step1045]: loss 0.042412
[epoch8, step1046]: loss 0.043746
[epoch8, step1047]: loss 0.041571
[epoch8, step1048]: loss 0.041401
[epoch8, step1049]: loss 0.044176
[epoch8, step1050]: loss 0.042733
[epoch8, step1051]: loss 0.042619
[epoch8, step1052]: loss 0.042205
[epoch8, step1053]: loss 0.042625
[epoch8, step1054]: loss 0.042370
[epoch8, step1055]: loss 0.042911
[epoch8, step1056]: loss 0.040686
[epoch8, step1057]: loss 0.041188
[epoch8, step1058]: loss 0.043641
[epoch8, step1059]: loss 0.042587
[epoch8, step1060]: loss 0.042026
[epoch8, step1061]: loss 0.040360
[epoch8, step1062]: loss 0.042548
[epoch8, step1063]: loss 0.042036
[epoch8, step1064]: loss 0.042650
[epoch8, step1065]: loss 0.041587
[epoch8, step1066]: loss 0.040489
[epoch8, step1067]: loss 0.043522
[epoch8, step1068]: loss 0.041600
[epoch8, step1069]: loss 0.041845
[epoch8, step1070]: loss 0.041202
[epoch8, step1071]: loss 0.042669
[epoch8, step1072]: loss 0.042473
[epoch8, step1073]: loss 0.043472
[epoch8, step1074]: loss 0.041700
[epoch8, step1075]: loss 0.041065
[epoch8, step1076]: loss 0.042776
[epoch8, step1077]: loss 0.042194
[epoch8, step1078]: loss 0.041872
[epoch8, step1079]: loss 0.041423
[epoch8, step1080]: loss 0.041536
[epoch8, step1081]: loss 0.041547
[epoch8, step1082]: loss 0.042343
[epoch8, step1083]: loss 0.041480
[epoch8, step1084]: loss 0.040305
[epoch8, step1085]: loss 0.042130
[epoch8, step1086]: loss 0.041284
[epoch8, step1087]: loss 0.041302
[epoch8, step1088]: loss 0.040567
[epoch8, step1089]: loss 0.041522
[epoch8, step1090]: loss 0.041849
[epoch8, step1091]: loss 0.042920
[epoch8, step1092]: loss 0.040447
[epoch8, step1093]: loss 0.040451
[epoch8, step1094]: loss 0.042226
[epoch8, step1095]: loss 0.041249
[epoch8, step1096]: loss 0.041784
[epoch8, step1097]: loss 0.040331
[epoch8, step1098]: loss 0.042703
[epoch8, step1099]: loss 0.043309
[epoch8, step1100]: loss 0.043753
[epoch8, step1101]: loss 0.042419
[epoch8, step1102]: loss 0.041356
[epoch8, step1103]: loss 0.043510
[epoch8, step1104]: loss 0.042533
[epoch8, step1105]: loss 0.043223
[epoch8, step1106]: loss 0.041933
[epoch8, step1107]: loss 0.042613
[epoch8, step1108]: loss 0.042501
[epoch8, step1109]: loss 0.044016
[epoch8, step1110]: loss 0.042233
[epoch8, step1111]: loss 0.041835
[epoch8, step1112]: loss 0.043929
[epoch8, step1113]: loss 0.043015
[epoch8, step1114]: loss 0.043028
[epoch8, step1115]: loss 0.042098
[epoch8, step1116]: loss 0.042818
[epoch8, step1117]: loss 0.042402
[epoch8, step1118]: loss 0.043692
[epoch8, step1119]: loss 0.041611
[epoch8, step1120]: loss 0.041280
[epoch8, step1121]: loss 0.043271
[epoch8, step1122]: loss 0.042746
[epoch8, step1123]: loss 0.042423
[epoch8, step1124]: loss 0.042565
[epoch8, step1125]: loss 0.042595
[epoch8, step1126]: loss 0.043080
[epoch8, step1127]: loss 0.043615
[epoch8, step1128]: loss 0.042281
[epoch8, step1129]: loss 0.041285
[epoch8, step1130]: loss 0.044009
[epoch8, step1131]: loss 0.043407
[epoch8, step1132]: loss 0.042939
[epoch8, step1133]: loss 0.040750
[epoch8, step1134]: loss 0.042642
[epoch8, step1135]: loss 0.043458
[epoch8, step1136]: loss 0.044141
[epoch8, step1137]: loss 0.041806
[epoch8, step1138]: loss 0.041215
[epoch8, step1139]: loss 0.043646
[epoch8, step1140]: loss 0.042388
[epoch8, step1141]: loss 0.042892
[epoch8, step1142]: loss 0.041893
[epoch8, step1143]: loss 0.042694
[epoch8, step1144]: loss 0.042564
[epoch8, step1145]: loss 0.043216
[epoch8, step1146]: loss 0.041949
[epoch8, step1147]: loss 0.041985
[epoch8, step1148]: loss 0.043946
[epoch8, step1149]: loss 0.042766
[epoch8, step1150]: loss 0.042281
[epoch8, step1151]: loss 0.042412
[epoch8, step1152]: loss 0.043411
[epoch8, step1153]: loss 0.042158
[epoch8, step1154]: loss 0.044329
[epoch8, step1155]: loss 0.042559
[epoch8, step1156]: loss 0.040908
[epoch8, step1157]: loss 0.043916
[epoch8, step1158]: loss 0.043040
[epoch8, step1159]: loss 0.042073
[epoch8, step1160]: loss 0.042352
[epoch8, step1161]: loss 0.043412
[epoch8, step1162]: loss 0.042483
[epoch8, step1163]: loss 0.042352
[epoch8, step1164]: loss 0.041778
[epoch8, step1165]: loss 0.041704
[epoch8, step1166]: loss 0.043314
[epoch8, step1167]: loss 0.042233
[epoch8, step1168]: loss 0.042238
[epoch8, step1169]: loss 0.041986
[epoch8, step1170]: loss 0.042443
[epoch8, step1171]: loss 0.041881
[epoch8, step1172]: loss 0.044620
[epoch8, step1173]: loss 0.042309
[epoch8, step1174]: loss 0.042166
[epoch8, step1175]: loss 0.043230
[epoch8, step1176]: loss 0.042614
[epoch8, step1177]: loss 0.043277
[epoch8, step1178]: loss 0.042400
[epoch8, step1179]: loss 0.042086
[epoch8, step1180]: loss 0.042640
[epoch8, step1181]: loss 0.043777
[epoch8, step1182]: loss 0.042054
[epoch8, step1183]: loss 0.041506
[epoch8, step1184]: loss 0.043062
[epoch8, step1185]: loss 0.042545
[epoch8, step1186]: loss 0.042474
[epoch8, step1187]: loss 0.041256
[epoch8, step1188]: loss 0.042242
[epoch8, step1189]: loss 0.042738
[epoch8, step1190]: loss 0.043396
[epoch8, step1191]: loss 0.042345
[epoch8, step1192]: loss 0.041562
[epoch8, step1193]: loss 0.044003
[epoch8, step1194]: loss 0.042964
[epoch8, step1195]: loss 0.042210
[epoch8, step1196]: loss 0.041672
[epoch8, step1197]: loss 0.042724
[epoch8, step1198]: loss 0.042951
[epoch8, step1199]: loss 0.043309
[epoch8, step1200]: loss 0.042320
[epoch8, step1201]: loss 0.041355
[epoch8, step1202]: loss 0.044378
[epoch8, step1203]: loss 0.042782
[epoch8, step1204]: loss 0.042392
[epoch8, step1205]: loss 0.041940
[epoch8, step1206]: loss 0.041895
[epoch8, step1207]: loss 0.042993
[epoch8, step1208]: loss 0.044535
[epoch8, step1209]: loss 0.041840
[epoch8, step1210]: loss 0.041389
[epoch8, step1211]: loss 0.043916
[epoch8, step1212]: loss 0.042465
[epoch8, step1213]: loss 0.042350
[epoch8, step1214]: loss 0.042081
[epoch8, step1215]: loss 0.042823
[epoch8, step1216]: loss 0.042784
[epoch8, step1217]: loss 0.043205
[epoch8, step1218]: loss 0.041538
[epoch8, step1219]: loss 0.041980
[epoch8, step1220]: loss 0.043692
[epoch8, step1221]: loss 0.041750
[epoch8, step1222]: loss 0.042082
[epoch8, step1223]: loss 0.041455
[epoch8, step1224]: loss 0.042403
[epoch8, step1225]: loss 0.042526
[epoch8, step1226]: loss 0.043934
[epoch8, step1227]: loss 0.042144
[epoch8, step1228]: loss 0.041623
[epoch8, step1229]: loss 0.043554
[epoch8, step1230]: loss 0.042541
[epoch8, step1231]: loss 0.042396
[epoch8, step1232]: loss 0.043113
[epoch8, step1233]: loss 0.042421
[epoch8, step1234]: loss 0.042417
[epoch8, step1235]: loss 0.043386
[epoch8, step1236]: loss 0.042081
[epoch8, step1237]: loss 0.041393
[epoch8, step1238]: loss 0.042893
[epoch8, step1239]: loss 0.042788
[epoch8, step1240]: loss 0.042847
[epoch8, step1241]: loss 0.041486
[epoch8, step1242]: loss 0.042417
[epoch8, step1243]: loss 0.042891
[epoch8, step1244]: loss 0.043967
[epoch8, step1245]: loss 0.042295
[epoch8, step1246]: loss 0.041338
[epoch8, step1247]: loss 0.043552
[epoch8, step1248]: loss 0.042101
[epoch8, step1249]: loss 0.042465
[epoch8, step1250]: loss 0.041122
[epoch8, step1251]: loss 0.042101
[epoch8, step1252]: loss 0.043395
[epoch8, step1253]: loss 0.043265
[epoch8, step1254]: loss 0.042073
[epoch8, step1255]: loss 0.041813
[epoch8, step1256]: loss 0.043873
[epoch8, step1257]: loss 0.042086
[epoch8, step1258]: loss 0.042262
[epoch8, step1259]: loss 0.041546
[epoch8, step1260]: loss 0.042255
[epoch8, step1261]: loss 0.042410
[epoch8, step1262]: loss 0.041958
[epoch8, step1263]: loss 0.042292
[epoch8, step1264]: loss 0.041881
[epoch8, step1265]: loss 0.042184
[epoch8, step1266]: loss 0.042134
[epoch8, step1267]: loss 0.042032
[epoch8, step1268]: loss 0.041652
[epoch8, step1269]: loss 0.042469
[epoch8, step1270]: loss 0.042167
[epoch8, step1271]: loss 0.043437
[epoch8, step1272]: loss 0.041757
[epoch8, step1273]: loss 0.041060
[epoch8, step1274]: loss 0.043114
[epoch8, step1275]: loss 0.042582
[epoch8, step1276]: loss 0.042439
[epoch8, step1277]: loss 0.041186
[epoch8, step1278]: loss 0.042299
[epoch8, step1279]: loss 0.042085
[epoch8, step1280]: loss 0.043763
[epoch8, step1281]: loss 0.041654
[epoch8, step1282]: loss 0.041506
[epoch8, step1283]: loss 0.042807
[epoch8, step1284]: loss 0.042398
[epoch8, step1285]: loss 0.042643
[epoch8, step1286]: loss 0.040894
[epoch8, step1287]: loss 0.043022
[epoch8, step1288]: loss 0.042506
[epoch8, step1289]: loss 0.043690
[epoch8, step1290]: loss 0.041916
[epoch8, step1291]: loss 0.041437
[epoch8, step1292]: loss 0.043740
[epoch8, step1293]: loss 0.041576
[epoch8, step1294]: loss 0.042070
[epoch8, step1295]: loss 0.041831
[epoch8, step1296]: loss 0.042345
[epoch8, step1297]: loss 0.042368
[epoch8, step1298]: loss 0.043694
[epoch8, step1299]: loss 0.042376
[epoch8, step1300]: loss 0.042257
[epoch8, step1301]: loss 0.043013
[epoch8, step1302]: loss 0.042827
[epoch8, step1303]: loss 0.042126
[epoch8, step1304]: loss 0.040812
[epoch8, step1305]: loss 0.042062
[epoch8, step1306]: loss 0.042225
[epoch8, step1307]: loss 0.043555
[epoch8, step1308]: loss 0.042003
[epoch8, step1309]: loss 0.041405
[epoch8, step1310]: loss 0.044209
[epoch8, step1311]: loss 0.041885
[epoch8, step1312]: loss 0.042541
[epoch8, step1313]: loss 0.041820
[epoch8, step1314]: loss 0.042722
[epoch8, step1315]: loss 0.042508
[epoch8, step1316]: loss 0.043733
[epoch8, step1317]: loss 0.040960
[epoch8, step1318]: loss 0.041066
[epoch8, step1319]: loss 0.043009
[epoch8, step1320]: loss 0.042432
[epoch8, step1321]: loss 0.042158
[epoch8, step1322]: loss 0.041346
[epoch8, step1323]: loss 0.042759
[epoch8, step1324]: loss 0.042238
[epoch8, step1325]: loss 0.042479
[epoch8, step1326]: loss 0.042005
[epoch8, step1327]: loss 0.042661
[epoch8, step1328]: loss 0.044545
[epoch8, step1329]: loss 0.042667
[epoch8, step1330]: loss 0.042314
[epoch8, step1331]: loss 0.041502
[epoch8, step1332]: loss 0.042022
[epoch8, step1333]: loss 0.042880
[epoch8, step1334]: loss 0.042859
[epoch8, step1335]: loss 0.041971
[epoch8, step1336]: loss 0.040966
[epoch8, step1337]: loss 0.043095
[epoch8, step1338]: loss 0.041699
[epoch8, step1339]: loss 0.042294
[epoch8, step1340]: loss 0.041163
[epoch8, step1341]: loss 0.042267
[epoch8, step1342]: loss 0.042347
[epoch8, step1343]: loss 0.043122
[epoch8, step1344]: loss 0.041745
[epoch8, step1345]: loss 0.041291
[epoch8, step1346]: loss 0.043537
[epoch8, step1347]: loss 0.042364
[epoch8, step1348]: loss 0.042814
[epoch8, step1349]: loss 0.041863
[epoch8, step1350]: loss 0.042586
[epoch8, step1351]: loss 0.041859
[epoch8, step1352]: loss 0.042935
[epoch8, step1353]: loss 0.042078
[epoch8, step1354]: loss 0.040576
[epoch8, step1355]: loss 0.043287
[epoch8, step1356]: loss 0.042455
[epoch8, step1357]: loss 0.041576
[epoch8, step1358]: loss 0.041598
[epoch8, step1359]: loss 0.042009
[epoch8, step1360]: loss 0.042367
[epoch8, step1361]: loss 0.043082
[epoch8, step1362]: loss 0.041967
[epoch8, step1363]: loss 0.040671
[epoch8, step1364]: loss 0.042866
[epoch8, step1365]: loss 0.042008
[epoch8, step1366]: loss 0.041809
[epoch8, step1367]: loss 0.041342
[epoch8, step1368]: loss 0.042287
[epoch8, step1369]: loss 0.042475
[epoch8, step1370]: loss 0.043028
[epoch8, step1371]: loss 0.041220
[epoch8, step1372]: loss 0.041308
[epoch8, step1373]: loss 0.042844
[epoch8, step1374]: loss 0.042894
[epoch8, step1375]: loss 0.043384
[epoch8, step1376]: loss 0.041270
[epoch8, step1377]: loss 0.042013
[epoch8, step1378]: loss 0.043627
[epoch8, step1379]: loss 0.042673
[epoch8, step1380]: loss 0.042178
[epoch8, step1381]: loss 0.041243
[epoch8, step1382]: loss 0.043438
[epoch8, step1383]: loss 0.041910
[epoch8, step1384]: loss 0.041863
[epoch8, step1385]: loss 0.040801
[epoch8, step1386]: loss 0.042500
[epoch8, step1387]: loss 0.042872
[epoch8, step1388]: loss 0.042890
[epoch8, step1389]: loss 0.040934
[epoch8, step1390]: loss 0.041293
[epoch8, step1391]: loss 0.043415
[epoch8, step1392]: loss 0.042259
[epoch8, step1393]: loss 0.043034
[epoch8, step1394]: loss 0.041949
[epoch8, step1395]: loss 0.042420
[epoch8, step1396]: loss 0.042340
[epoch8, step1397]: loss 0.042731
[epoch8, step1398]: loss 0.041373
[epoch8, step1399]: loss 0.041638
[epoch8, step1400]: loss 0.043526
[epoch8, step1401]: loss 0.042597
[epoch8, step1402]: loss 0.041857
[epoch8, step1403]: loss 0.040966
[epoch8, step1404]: loss 0.042320
[epoch8, step1405]: loss 0.042672
[epoch8, step1406]: loss 0.042702
[epoch8, step1407]: loss 0.042945
[epoch8, step1408]: loss 0.041193
[epoch8, step1409]: loss 0.042662
[epoch8, step1410]: loss 0.042492
[epoch8, step1411]: loss 0.042453
[epoch8, step1412]: loss 0.041558
[epoch8, step1413]: loss 0.041723
[epoch8, step1414]: loss 0.043364
[epoch8, step1415]: loss 0.042564
[epoch8, step1416]: loss 0.041852
[epoch8, step1417]: loss 0.041013
[epoch8, step1418]: loss 0.042800
[epoch8, step1419]: loss 0.043041
[epoch8, step1420]: loss 0.042258
[epoch8, step1421]: loss 0.041322
[epoch8, step1422]: loss 0.042463
[epoch8, step1423]: loss 0.043008
[epoch8, step1424]: loss 0.044286
[epoch8, step1425]: loss 0.041107
[epoch8, step1426]: loss 0.041934
[epoch8, step1427]: loss 0.044231
[epoch8, step1428]: loss 0.042317
[epoch8, step1429]: loss 0.042860
[epoch8, step1430]: loss 0.042305
[epoch8, step1431]: loss 0.042456
[epoch8, step1432]: loss 0.042577
[epoch8, step1433]: loss 0.043460
[epoch8, step1434]: loss 0.040959
[epoch8, step1435]: loss 0.041118
[epoch8, step1436]: loss 0.043518
[epoch8, step1437]: loss 0.041991
[epoch8, step1438]: loss 0.041920
[epoch8, step1439]: loss 0.041045
[epoch8, step1440]: loss 0.041720
[epoch8, step1441]: loss 0.042746
[epoch8, step1442]: loss 0.042431
[epoch8, step1443]: loss 0.041378
[epoch8, step1444]: loss 0.041256
[epoch8, step1445]: loss 0.043700
[epoch8, step1446]: loss 0.042309
[epoch8, step1447]: loss 0.042197
[epoch8, step1448]: loss 0.041765
[epoch8, step1449]: loss 0.042390
[epoch8, step1450]: loss 0.041963
[epoch8, step1451]: loss 0.043647
[epoch8, step1452]: loss 0.042650
[epoch8, step1453]: loss 0.042317
[epoch8, step1454]: loss 0.043066
[epoch8, step1455]: loss 0.042587
[epoch8, step1456]: loss 0.041881
[epoch8, step1457]: loss 0.041222
[epoch8, step1458]: loss 0.041962
[epoch8, step1459]: loss 0.041599
[epoch8, step1460]: loss 0.043329
[epoch8, step1461]: loss 0.041932
[epoch8, step1462]: loss 0.041651
[epoch8, step1463]: loss 0.042639
[epoch8, step1464]: loss 0.042341
[epoch8, step1465]: loss 0.041655
[epoch8, step1466]: loss 0.041741
[epoch8, step1467]: loss 0.042918
[epoch8, step1468]: loss 0.041300
[epoch8, step1469]: loss 0.044153
[epoch8, step1470]: loss 0.042280
[epoch8, step1471]: loss 0.040859
[epoch8, step1472]: loss 0.042806
[epoch8, step1473]: loss 0.042487
[epoch8, step1474]: loss 0.042899
[epoch8, step1475]: loss 0.040556
[epoch8, step1476]: loss 0.042610
[epoch8, step1477]: loss 0.041831
[epoch8, step1478]: loss 0.042646
[epoch8, step1479]: loss 0.042148
[epoch8, step1480]: loss 0.041261
[epoch8, step1481]: loss 0.042187
[epoch8, step1482]: loss 0.042477
[epoch8, step1483]: loss 0.042530
[epoch8, step1484]: loss 0.041719
[epoch8, step1485]: loss 0.042653
[epoch8, step1486]: loss 0.041515
[epoch8, step1487]: loss 0.043290
[epoch8, step1488]: loss 0.042871
[epoch8, step1489]: loss 0.041290
[epoch8, step1490]: loss 0.043495
[epoch8, step1491]: loss 0.041906
[epoch8, step1492]: loss 0.041486
[epoch8, step1493]: loss 0.040789
[epoch8, step1494]: loss 0.041802
[epoch8, step1495]: loss 0.041717
[epoch8, step1496]: loss 0.042277
[epoch8, step1497]: loss 0.042174
[epoch8, step1498]: loss 0.040709
[epoch8, step1499]: loss 0.043489
[epoch8, step1500]: loss 0.042389
[epoch8, step1501]: loss 0.042133
[epoch8, step1502]: loss 0.041970
[epoch8, step1503]: loss 0.042556
[epoch8, step1504]: loss 0.041628
[epoch8, step1505]: loss 0.044727
[epoch8, step1506]: loss 0.042067
[epoch8, step1507]: loss 0.042019
[epoch8, step1508]: loss 0.043551
[epoch8, step1509]: loss 0.042963
[epoch8, step1510]: loss 0.042535
[epoch8, step1511]: loss 0.041563
[epoch8, step1512]: loss 0.042020
[epoch8, step1513]: loss 0.041449
[epoch8, step1514]: loss 0.043089
[epoch8, step1515]: loss 0.042090
[epoch8, step1516]: loss 0.041321

[epoch8]: avg loss 0.038827

[epoch9, step1]: loss 0.040137
[epoch9, step2]: loss 0.038953
[epoch9, step3]: loss 0.039290
[epoch9, step4]: loss 0.036014
[epoch9, step5]: loss 0.035898
[epoch9, step6]: loss 0.039357
[epoch9, step7]: loss 0.037161
[epoch9, step8]: loss 0.038752
[epoch9, step9]: loss 0.035332
[epoch9, step10]: loss 0.037029
[epoch9, step11]: loss 0.039591
[epoch9, step12]: loss 0.038034
[epoch9, step13]: loss 0.036343
[epoch9, step14]: loss 0.037023
[epoch9, step15]: loss 0.039218
[epoch9, step16]: loss 0.036653
[epoch9, step17]: loss 0.039177
[epoch9, step18]: loss 0.037587
[epoch9, step19]: loss 0.036210
[epoch9, step20]: loss 0.039643
[epoch9, step21]: loss 0.037292
[epoch9, step22]: loss 0.035762
[epoch9, step23]: loss 0.035638
[epoch9, step24]: loss 0.038023
[epoch9, step25]: loss 0.034907
[epoch9, step26]: loss 0.038149
[epoch9, step27]: loss 0.035157
[epoch9, step28]: loss 0.035964
[epoch9, step29]: loss 0.038211
[epoch9, step30]: loss 0.037232
[epoch9, step31]: loss 0.034836
[epoch9, step32]: loss 0.035371
[epoch9, step33]: loss 0.037503
[epoch9, step34]: loss 0.035666
[epoch9, step35]: loss 0.037917
[epoch9, step36]: loss 0.034375
[epoch9, step37]: loss 0.035255
[epoch9, step38]: loss 0.037933
[epoch9, step39]: loss 0.037594
[epoch9, step40]: loss 0.034941
[epoch9, step41]: loss 0.035192
[epoch9, step42]: loss 0.038481
[epoch9, step43]: loss 0.035936
[epoch9, step44]: loss 0.039413
[epoch9, step45]: loss 0.035373
[epoch9, step46]: loss 0.034844
[epoch9, step47]: loss 0.037570
[epoch9, step48]: loss 0.037795
[epoch9, step49]: loss 0.034095
[epoch9, step50]: loss 0.034793
[epoch9, step51]: loss 0.037097
[epoch9, step52]: loss 0.035069
[epoch9, step53]: loss 0.037744
[epoch9, step54]: loss 0.034347
[epoch9, step55]: loss 0.035521
[epoch9, step56]: loss 0.038167
[epoch9, step57]: loss 0.037423
[epoch9, step58]: loss 0.034972
[epoch9, step59]: loss 0.033286
[epoch9, step60]: loss 0.038314
[epoch9, step61]: loss 0.034091
[epoch9, step62]: loss 0.036317
[epoch9, step63]: loss 0.033580
[epoch9, step64]: loss 0.034708
[epoch9, step65]: loss 0.037485
[epoch9, step66]: loss 0.037053
[epoch9, step67]: loss 0.036871
[epoch9, step68]: loss 0.036356
[epoch9, step69]: loss 0.038371
[epoch9, step70]: loss 0.036587
[epoch9, step71]: loss 0.038811
[epoch9, step72]: loss 0.035672
[epoch9, step73]: loss 0.036089
[epoch9, step74]: loss 0.039022
[epoch9, step75]: loss 0.038510
[epoch9, step76]: loss 0.036449
[epoch9, step77]: loss 0.036140
[epoch9, step78]: loss 0.038810
[epoch9, step79]: loss 0.035606
[epoch9, step80]: loss 0.039645
[epoch9, step81]: loss 0.035441
[epoch9, step82]: loss 0.035776
[epoch9, step83]: loss 0.037884
[epoch9, step84]: loss 0.038838
[epoch9, step85]: loss 0.036332
[epoch9, step86]: loss 0.035709
[epoch9, step87]: loss 0.039751
[epoch9, step88]: loss 0.035100
[epoch9, step89]: loss 0.038368
[epoch9, step90]: loss 0.035638
[epoch9, step91]: loss 0.035643
[epoch9, step92]: loss 0.038908
[epoch9, step93]: loss 0.038151
[epoch9, step94]: loss 0.035513
[epoch9, step95]: loss 0.035876
[epoch9, step96]: loss 0.038404
[epoch9, step97]: loss 0.036740
[epoch9, step98]: loss 0.038529
[epoch9, step99]: loss 0.035304
[epoch9, step100]: loss 0.035127
[epoch9, step101]: loss 0.039007
[epoch9, step102]: loss 0.038369
[epoch9, step103]: loss 0.035643
[epoch9, step104]: loss 0.035617
[epoch9, step105]: loss 0.038775
[epoch9, step106]: loss 0.036076
[epoch9, step107]: loss 0.038452
[epoch9, step108]: loss 0.035488
[epoch9, step109]: loss 0.035604
[epoch9, step110]: loss 0.039274
[epoch9, step111]: loss 0.038076
[epoch9, step112]: loss 0.035841
[epoch9, step113]: loss 0.036171
[epoch9, step114]: loss 0.038370
[epoch9, step115]: loss 0.035995
[epoch9, step116]: loss 0.039247
[epoch9, step117]: loss 0.035179
[epoch9, step118]: loss 0.036559
[epoch9, step119]: loss 0.039036
[epoch9, step120]: loss 0.038535
[epoch9, step121]: loss 0.035472
[epoch9, step122]: loss 0.035394
[epoch9, step123]: loss 0.038935
[epoch9, step124]: loss 0.036248
[epoch9, step125]: loss 0.039042
[epoch9, step126]: loss 0.034985
[epoch9, step127]: loss 0.035797
[epoch9, step128]: loss 0.038438
[epoch9, step129]: loss 0.037833
[epoch9, step130]: loss 0.035785
[epoch9, step131]: loss 0.034697
[epoch9, step132]: loss 0.038733
[epoch9, step133]: loss 0.035688
[epoch9, step134]: loss 0.038045
[epoch9, step135]: loss 0.035495
[epoch9, step136]: loss 0.036906
[epoch9, step137]: loss 0.038093
[epoch9, step138]: loss 0.038099
[epoch9, step139]: loss 0.035509
[epoch9, step140]: loss 0.035721
[epoch9, step141]: loss 0.038837
[epoch9, step142]: loss 0.035836
[epoch9, step143]: loss 0.037992
[epoch9, step144]: loss 0.035428
[epoch9, step145]: loss 0.036115
[epoch9, step146]: loss 0.038764
[epoch9, step147]: loss 0.039467
[epoch9, step148]: loss 0.035447
[epoch9, step149]: loss 0.034728
[epoch9, step150]: loss 0.038064
[epoch9, step151]: loss 0.035944
[epoch9, step152]: loss 0.038363
[epoch9, step153]: loss 0.035215
[epoch9, step154]: loss 0.035267
[epoch9, step155]: loss 0.038587
[epoch9, step156]: loss 0.037942
[epoch9, step157]: loss 0.035933
[epoch9, step158]: loss 0.035634
[epoch9, step159]: loss 0.038621
[epoch9, step160]: loss 0.036090
[epoch9, step161]: loss 0.038731
[epoch9, step162]: loss 0.035465
[epoch9, step163]: loss 0.035760
[epoch9, step164]: loss 0.038631
[epoch9, step165]: loss 0.038270
[epoch9, step166]: loss 0.036232
[epoch9, step167]: loss 0.034873
[epoch9, step168]: loss 0.039057
[epoch9, step169]: loss 0.035225
[epoch9, step170]: loss 0.038709
[epoch9, step171]: loss 0.035494
[epoch9, step172]: loss 0.035873
[epoch9, step173]: loss 0.039105
[epoch9, step174]: loss 0.038289
[epoch9, step175]: loss 0.036119
[epoch9, step176]: loss 0.035762
[epoch9, step177]: loss 0.038829
[epoch9, step178]: loss 0.036201
[epoch9, step179]: loss 0.037709
[epoch9, step180]: loss 0.035677
[epoch9, step181]: loss 0.036112
[epoch9, step182]: loss 0.038789
[epoch9, step183]: loss 0.039027
[epoch9, step184]: loss 0.036674
[epoch9, step185]: loss 0.035763
[epoch9, step186]: loss 0.038955
[epoch9, step187]: loss 0.035878
[epoch9, step188]: loss 0.038459
[epoch9, step189]: loss 0.035527
[epoch9, step190]: loss 0.035269
[epoch9, step191]: loss 0.038442
[epoch9, step192]: loss 0.038495
[epoch9, step193]: loss 0.033757
[epoch9, step194]: loss 0.034467
[epoch9, step195]: loss 0.038680
[epoch9, step196]: loss 0.035966
[epoch9, step197]: loss 0.038144
[epoch9, step198]: loss 0.034323
[epoch9, step199]: loss 0.035727
[epoch9, step200]: loss 0.038978
[epoch9, step201]: loss 0.038717
[epoch9, step202]: loss 0.035159
[epoch9, step203]: loss 0.035703
[epoch9, step204]: loss 0.039017
[epoch9, step205]: loss 0.035322
[epoch9, step206]: loss 0.038526
[epoch9, step207]: loss 0.035394
[epoch9, step208]: loss 0.035842
[epoch9, step209]: loss 0.038857
[epoch9, step210]: loss 0.038906
[epoch9, step211]: loss 0.036091
[epoch9, step212]: loss 0.035697
[epoch9, step213]: loss 0.038211
[epoch9, step214]: loss 0.035254
[epoch9, step215]: loss 0.038391
[epoch9, step216]: loss 0.035428
[epoch9, step217]: loss 0.034677
[epoch9, step218]: loss 0.038835
[epoch9, step219]: loss 0.038118
[epoch9, step220]: loss 0.035782
[epoch9, step221]: loss 0.035758
[epoch9, step222]: loss 0.038580
[epoch9, step223]: loss 0.035859
[epoch9, step224]: loss 0.038304
[epoch9, step225]: loss 0.035186
[epoch9, step226]: loss 0.035523
[epoch9, step227]: loss 0.037895
[epoch9, step228]: loss 0.038563
[epoch9, step229]: loss 0.034902
[epoch9, step230]: loss 0.035530
[epoch9, step231]: loss 0.038828
[epoch9, step232]: loss 0.035266
[epoch9, step233]: loss 0.037515
[epoch9, step234]: loss 0.034687
[epoch9, step235]: loss 0.035977
[epoch9, step236]: loss 0.038346
[epoch9, step237]: loss 0.038478
[epoch9, step238]: loss 0.035417
[epoch9, step239]: loss 0.034987
[epoch9, step240]: loss 0.038240
[epoch9, step241]: loss 0.036321
[epoch9, step242]: loss 0.038672
[epoch9, step243]: loss 0.036235
[epoch9, step244]: loss 0.035628
[epoch9, step245]: loss 0.038218
[epoch9, step246]: loss 0.037978
[epoch9, step247]: loss 0.035788
[epoch9, step248]: loss 0.034982
[epoch9, step249]: loss 0.037776
[epoch9, step250]: loss 0.035572
[epoch9, step251]: loss 0.038382
[epoch9, step252]: loss 0.035920
[epoch9, step253]: loss 0.035394
[epoch9, step254]: loss 0.037794
[epoch9, step255]: loss 0.038105
[epoch9, step256]: loss 0.035275
[epoch9, step257]: loss 0.035696
[epoch9, step258]: loss 0.039623
[epoch9, step259]: loss 0.035804
[epoch9, step260]: loss 0.038055
[epoch9, step261]: loss 0.036564
[epoch9, step262]: loss 0.035952
[epoch9, step263]: loss 0.037806
[epoch9, step264]: loss 0.037977
[epoch9, step265]: loss 0.035664
[epoch9, step266]: loss 0.035173
[epoch9, step267]: loss 0.037673
[epoch9, step268]: loss 0.035611
[epoch9, step269]: loss 0.038207
[epoch9, step270]: loss 0.034934
[epoch9, step271]: loss 0.035649
[epoch9, step272]: loss 0.038481
[epoch9, step273]: loss 0.037958
[epoch9, step274]: loss 0.036260
[epoch9, step275]: loss 0.034996
[epoch9, step276]: loss 0.037779
[epoch9, step277]: loss 0.036347
[epoch9, step278]: loss 0.038595
[epoch9, step279]: loss 0.034799
[epoch9, step280]: loss 0.035708
[epoch9, step281]: loss 0.038189
[epoch9, step282]: loss 0.038087
[epoch9, step283]: loss 0.035183
[epoch9, step284]: loss 0.034780
[epoch9, step285]: loss 0.039032
[epoch9, step286]: loss 0.035129
[epoch9, step287]: loss 0.038439
[epoch9, step288]: loss 0.034809
[epoch9, step289]: loss 0.036158
[epoch9, step290]: loss 0.038689
[epoch9, step291]: loss 0.038298
[epoch9, step292]: loss 0.034563
[epoch9, step293]: loss 0.034909
[epoch9, step294]: loss 0.037172
[epoch9, step295]: loss 0.035457
[epoch9, step296]: loss 0.038643
[epoch9, step297]: loss 0.035026
[epoch9, step298]: loss 0.035940
[epoch9, step299]: loss 0.037456
[epoch9, step300]: loss 0.038359
[epoch9, step301]: loss 0.035878
[epoch9, step302]: loss 0.035645
[epoch9, step303]: loss 0.039152
[epoch9, step304]: loss 0.035123
[epoch9, step305]: loss 0.037685
[epoch9, step306]: loss 0.035124
[epoch9, step307]: loss 0.034813
[epoch9, step308]: loss 0.038989
[epoch9, step309]: loss 0.037891
[epoch9, step310]: loss 0.035482
[epoch9, step311]: loss 0.035821
[epoch9, step312]: loss 0.038222
[epoch9, step313]: loss 0.035672
[epoch9, step314]: loss 0.038344
[epoch9, step315]: loss 0.036031
[epoch9, step316]: loss 0.035670
[epoch9, step317]: loss 0.039130
[epoch9, step318]: loss 0.038204
[epoch9, step319]: loss 0.035211
[epoch9, step320]: loss 0.034530
[epoch9, step321]: loss 0.037915
[epoch9, step322]: loss 0.035480
[epoch9, step323]: loss 0.037630
[epoch9, step324]: loss 0.035555
[epoch9, step325]: loss 0.035890
[epoch9, step326]: loss 0.038289
[epoch9, step327]: loss 0.037284
[epoch9, step328]: loss 0.035593
[epoch9, step329]: loss 0.034808
[epoch9, step330]: loss 0.037535
[epoch9, step331]: loss 0.035595
[epoch9, step332]: loss 0.037729
[epoch9, step333]: loss 0.035657
[epoch9, step334]: loss 0.036552
[epoch9, step335]: loss 0.039234
[epoch9, step336]: loss 0.038976
[epoch9, step337]: loss 0.035967
[epoch9, step338]: loss 0.034555
[epoch9, step339]: loss 0.038124
[epoch9, step340]: loss 0.036017
[epoch9, step341]: loss 0.037520
[epoch9, step342]: loss 0.034729
[epoch9, step343]: loss 0.035403
[epoch9, step344]: loss 0.037851
[epoch9, step345]: loss 0.037408
[epoch9, step346]: loss 0.034884
[epoch9, step347]: loss 0.034951
[epoch9, step348]: loss 0.038226
[epoch9, step349]: loss 0.035974
[epoch9, step350]: loss 0.037830
[epoch9, step351]: loss 0.034612
[epoch9, step352]: loss 0.035261
[epoch9, step353]: loss 0.038075
[epoch9, step354]: loss 0.037212
[epoch9, step355]: loss 0.034536
[epoch9, step356]: loss 0.035924
[epoch9, step357]: loss 0.038228
[epoch9, step358]: loss 0.034068
[epoch9, step359]: loss 0.039586
[epoch9, step360]: loss 0.033963
[epoch9, step361]: loss 0.034948
[epoch9, step362]: loss 0.038497
[epoch9, step363]: loss 0.037788
[epoch9, step364]: loss 0.035426
[epoch9, step365]: loss 0.034770
[epoch9, step366]: loss 0.038545
[epoch9, step367]: loss 0.035444
[epoch9, step368]: loss 0.037440
[epoch9, step369]: loss 0.034701
[epoch9, step370]: loss 0.036060
[epoch9, step371]: loss 0.039096
[epoch9, step372]: loss 0.037804
[epoch9, step373]: loss 0.035089
[epoch9, step374]: loss 0.034428
[epoch9, step375]: loss 0.039001
[epoch9, step376]: loss 0.035391
[epoch9, step377]: loss 0.038290
[epoch9, step378]: loss 0.035252
[epoch9, step379]: loss 0.036338
[epoch9, step380]: loss 0.038423
[epoch9, step381]: loss 0.037842
[epoch9, step382]: loss 0.035669
[epoch9, step383]: loss 0.034489
[epoch9, step384]: loss 0.037550
[epoch9, step385]: loss 0.035090
[epoch9, step386]: loss 0.038429
[epoch9, step387]: loss 0.035457
[epoch9, step388]: loss 0.036404
[epoch9, step389]: loss 0.038701
[epoch9, step390]: loss 0.038608
[epoch9, step391]: loss 0.035027
[epoch9, step392]: loss 0.035680
[epoch9, step393]: loss 0.037609
[epoch9, step394]: loss 0.035555
[epoch9, step395]: loss 0.037789
[epoch9, step396]: loss 0.034803
[epoch9, step397]: loss 0.035066
[epoch9, step398]: loss 0.038216
[epoch9, step399]: loss 0.037917
[epoch9, step400]: loss 0.035326
[epoch9, step401]: loss 0.035114
[epoch9, step402]: loss 0.037854
[epoch9, step403]: loss 0.035693
[epoch9, step404]: loss 0.038763
[epoch9, step405]: loss 0.035142
[epoch9, step406]: loss 0.035684
[epoch9, step407]: loss 0.038268
[epoch9, step408]: loss 0.037958
[epoch9, step409]: loss 0.036577
[epoch9, step410]: loss 0.035419
[epoch9, step411]: loss 0.037812
[epoch9, step412]: loss 0.035067
[epoch9, step413]: loss 0.038071
[epoch9, step414]: loss 0.034996
[epoch9, step415]: loss 0.035958
[epoch9, step416]: loss 0.037571
[epoch9, step417]: loss 0.037471
[epoch9, step418]: loss 0.035760
[epoch9, step419]: loss 0.034403
[epoch9, step420]: loss 0.038216
[epoch9, step421]: loss 0.035360
[epoch9, step422]: loss 0.037669
[epoch9, step423]: loss 0.034938
[epoch9, step424]: loss 0.035167
[epoch9, step425]: loss 0.038059
[epoch9, step426]: loss 0.038501
[epoch9, step427]: loss 0.036115
[epoch9, step428]: loss 0.035623
[epoch9, step429]: loss 0.039257
[epoch9, step430]: loss 0.035489
[epoch9, step431]: loss 0.038133
[epoch9, step432]: loss 0.035319
[epoch9, step433]: loss 0.036252
[epoch9, step434]: loss 0.037787
[epoch9, step435]: loss 0.038376
[epoch9, step436]: loss 0.034751
[epoch9, step437]: loss 0.035076
[epoch9, step438]: loss 0.038004
[epoch9, step439]: loss 0.036011
[epoch9, step440]: loss 0.037945
[epoch9, step441]: loss 0.034814
[epoch9, step442]: loss 0.035261
[epoch9, step443]: loss 0.038998
[epoch9, step444]: loss 0.037029
[epoch9, step445]: loss 0.035579
[epoch9, step446]: loss 0.036018
[epoch9, step447]: loss 0.038966
[epoch9, step448]: loss 0.035580
[epoch9, step449]: loss 0.037952
[epoch9, step450]: loss 0.034875
[epoch9, step451]: loss 0.035051
[epoch9, step452]: loss 0.037404
[epoch9, step453]: loss 0.037758
[epoch9, step454]: loss 0.034744
[epoch9, step455]: loss 0.035390
[epoch9, step456]: loss 0.036733
[epoch9, step457]: loss 0.035695
[epoch9, step458]: loss 0.037181
[epoch9, step459]: loss 0.035251
[epoch9, step460]: loss 0.035397
[epoch9, step461]: loss 0.038780
[epoch9, step462]: loss 0.036583
[epoch9, step463]: loss 0.035417
[epoch9, step464]: loss 0.034773
[epoch9, step465]: loss 0.039156
[epoch9, step466]: loss 0.035494
[epoch9, step467]: loss 0.037207
[epoch9, step468]: loss 0.034907
[epoch9, step469]: loss 0.035167
[epoch9, step470]: loss 0.038044
[epoch9, step471]: loss 0.037536
[epoch9, step472]: loss 0.035448
[epoch9, step473]: loss 0.035180
[epoch9, step474]: loss 0.037641
[epoch9, step475]: loss 0.035379
[epoch9, step476]: loss 0.038389
[epoch9, step477]: loss 0.035281
[epoch9, step478]: loss 0.034261
[epoch9, step479]: loss 0.037604
[epoch9, step480]: loss 0.036937
[epoch9, step481]: loss 0.034982
[epoch9, step482]: loss 0.034188
[epoch9, step483]: loss 0.037903
[epoch9, step484]: loss 0.035482
[epoch9, step485]: loss 0.037712
[epoch9, step486]: loss 0.035567
[epoch9, step487]: loss 0.034764
[epoch9, step488]: loss 0.039650
[epoch9, step489]: loss 0.037880
[epoch9, step490]: loss 0.036447
[epoch9, step491]: loss 0.035144
[epoch9, step492]: loss 0.038184
[epoch9, step493]: loss 0.035413
[epoch9, step494]: loss 0.037448
[epoch9, step495]: loss 0.036204
[epoch9, step496]: loss 0.035570
[epoch9, step497]: loss 0.038004
[epoch9, step498]: loss 0.037230
[epoch9, step499]: loss 0.035228
[epoch9, step500]: loss 0.034833
[epoch9, step501]: loss 0.037514
[epoch9, step502]: loss 0.035506
[epoch9, step503]: loss 0.038026
[epoch9, step504]: loss 0.035080
[epoch9, step505]: loss 0.035043
[epoch9, step506]: loss 0.038770
[epoch9, step507]: loss 0.038543
[epoch9, step508]: loss 0.036231
[epoch9, step509]: loss 0.034839
[epoch9, step510]: loss 0.038529
[epoch9, step511]: loss 0.036293
[epoch9, step512]: loss 0.038385
[epoch9, step513]: loss 0.034993
[epoch9, step514]: loss 0.035313
[epoch9, step515]: loss 0.037872
[epoch9, step516]: loss 0.037573
[epoch9, step517]: loss 0.035030
[epoch9, step518]: loss 0.034906
[epoch9, step519]: loss 0.037944
[epoch9, step520]: loss 0.034821
[epoch9, step521]: loss 0.037846
[epoch9, step522]: loss 0.034407
[epoch9, step523]: loss 0.035031
[epoch9, step524]: loss 0.037805
[epoch9, step525]: loss 0.039311
[epoch9, step526]: loss 0.035888
[epoch9, step527]: loss 0.034401
[epoch9, step528]: loss 0.038452
[epoch9, step529]: loss 0.035035
[epoch9, step530]: loss 0.038579
[epoch9, step531]: loss 0.034685
[epoch9, step532]: loss 0.034804
[epoch9, step533]: loss 0.038465
[epoch9, step534]: loss 0.037135
[epoch9, step535]: loss 0.035451
[epoch9, step536]: loss 0.035416
[epoch9, step537]: loss 0.038129
[epoch9, step538]: loss 0.035463
[epoch9, step539]: loss 0.037417
[epoch9, step540]: loss 0.034272
[epoch9, step541]: loss 0.034562
[epoch9, step542]: loss 0.037820
[epoch9, step543]: loss 0.037184
[epoch9, step544]: loss 0.035254
[epoch9, step545]: loss 0.034584
[epoch9, step546]: loss 0.038106
[epoch9, step547]: loss 0.035347
[epoch9, step548]: loss 0.038718
[epoch9, step549]: loss 0.035057
[epoch9, step550]: loss 0.035514
[epoch9, step551]: loss 0.037287
[epoch9, step552]: loss 0.036583
[epoch9, step553]: loss 0.035599
[epoch9, step554]: loss 0.034575
[epoch9, step555]: loss 0.037141
[epoch9, step556]: loss 0.034808
[epoch9, step557]: loss 0.036943
[epoch9, step558]: loss 0.035134
[epoch9, step559]: loss 0.034676
[epoch9, step560]: loss 0.037955
[epoch9, step561]: loss 0.037112
[epoch9, step562]: loss 0.034978
[epoch9, step563]: loss 0.035721
[epoch9, step564]: loss 0.039974
[epoch9, step565]: loss 0.039309
[epoch9, step566]: loss 0.045056
[epoch9, step567]: loss 0.037729
[epoch9, step568]: loss 0.037306
[epoch9, step569]: loss 0.033733
[epoch9, step570]: loss 0.041168
[epoch9, step571]: loss 0.038197
[epoch9, step572]: loss 0.037413
[epoch9, step573]: loss 0.039591
[epoch9, step574]: loss 0.041636
[epoch9, step575]: loss 0.032088
[epoch9, step576]: loss 0.034282
[epoch9, step577]: loss 0.037034
[epoch9, step578]: loss 0.029553
[epoch9, step579]: loss 0.039619
[epoch9, step580]: loss 0.030387
[epoch9, step581]: loss 0.036875
[epoch9, step582]: loss 0.036200
[epoch9, step583]: loss 0.035045
[epoch9, step584]: loss 0.034210
[epoch9, step585]: loss 0.036931
[epoch9, step586]: loss 0.034370
[epoch9, step587]: loss 0.039425
[epoch9, step588]: loss 0.034799
[epoch9, step589]: loss 0.034532
[epoch9, step590]: loss 0.038560
[epoch9, step591]: loss 0.031566
[epoch9, step592]: loss 0.037189
[epoch9, step593]: loss 0.032681
[epoch9, step594]: loss 0.037646
[epoch9, step595]: loss 0.038492
[epoch9, step596]: loss 0.035876
[epoch9, step597]: loss 0.035876
[epoch9, step598]: loss 0.036851
[epoch9, step599]: loss 0.035076
[epoch9, step600]: loss 0.037896
[epoch9, step601]: loss 0.029993
[epoch9, step602]: loss 0.033315
[epoch9, step603]: loss 0.036967
[epoch9, step604]: loss 0.037664
[epoch9, step605]: loss 0.035716
[epoch9, step606]: loss 0.035202
[epoch9, step607]: loss 0.039211
[epoch9, step608]: loss 0.036856
[epoch9, step609]: loss 0.037775
[epoch9, step610]: loss 0.038517
[epoch9, step611]: loss 0.037184
[epoch9, step612]: loss 0.035862
[epoch9, step613]: loss 0.030371
[epoch9, step614]: loss 0.034854
[epoch9, step615]: loss 0.039855
[epoch9, step616]: loss 0.034359
[epoch9, step617]: loss 0.033800
[epoch9, step618]: loss 0.037713
[epoch9, step619]: loss 0.038573
[epoch9, step620]: loss 0.035517
[epoch9, step621]: loss 0.037193
[epoch9, step622]: loss 0.031519
[epoch9, step623]: loss 0.034226
[epoch9, step624]: loss 0.037700
[epoch9, step625]: loss 0.035935
[epoch9, step626]: loss 0.038644
[epoch9, step627]: loss 0.033446
[epoch9, step628]: loss 0.035960
[epoch9, step629]: loss 0.031062
[epoch9, step630]: loss 0.032786
[epoch9, step631]: loss 0.042933
[epoch9, step632]: loss 0.035520
[epoch9, step633]: loss 0.035844
[epoch9, step634]: loss 0.037759
[epoch9, step635]: loss 0.037669
[epoch9, step636]: loss 0.032019
[epoch9, step637]: loss 0.038696
[epoch9, step638]: loss 0.038604
[epoch9, step639]: loss 0.032579
[epoch9, step640]: loss 0.039802
[epoch9, step641]: loss 0.041453
[epoch9, step642]: loss 0.036239
[epoch9, step643]: loss 0.035139
[epoch9, step644]: loss 0.036110
[epoch9, step645]: loss 0.034488
[epoch9, step646]: loss 0.035438
[epoch9, step647]: loss 0.034054
[epoch9, step648]: loss 0.035130
[epoch9, step649]: loss 0.039314
[epoch9, step650]: loss 0.033593
[epoch9, step651]: loss 0.038137
[epoch9, step652]: loss 0.038063
[epoch9, step653]: loss 0.038174
[epoch9, step654]: loss 0.033536
[epoch9, step655]: loss 0.035064
[epoch9, step656]: loss 0.033135
[epoch9, step657]: loss 0.039026
[epoch9, step658]: loss 0.035554
[epoch9, step659]: loss 0.037872
[epoch9, step660]: loss 0.033103
[epoch9, step661]: loss 0.036747
[epoch9, step662]: loss 0.033994
[epoch9, step663]: loss 0.032610
[epoch9, step664]: loss 0.036443
[epoch9, step665]: loss 0.037835
[epoch9, step666]: loss 0.037594
[epoch9, step667]: loss 0.036821
[epoch9, step668]: loss 0.033738
[epoch9, step669]: loss 0.037336
[epoch9, step670]: loss 0.038149
[epoch9, step671]: loss 0.032045
[epoch9, step672]: loss 0.034823
[epoch9, step673]: loss 0.033537
[epoch9, step674]: loss 0.031663
[epoch9, step675]: loss 0.031047
[epoch9, step676]: loss 0.034201
[epoch9, step677]: loss 0.035718
[epoch9, step678]: loss 0.032971
[epoch9, step679]: loss 0.034549
[epoch9, step680]: loss 0.041373
[epoch9, step681]: loss 0.032052
[epoch9, step682]: loss 0.036343
[epoch9, step683]: loss 0.035845
[epoch9, step684]: loss 0.035596
[epoch9, step685]: loss 0.035197
[epoch9, step686]: loss 0.038388
[epoch9, step687]: loss 0.036681
[epoch9, step688]: loss 0.035006
[epoch9, step689]: loss 0.036103
[epoch9, step690]: loss 0.035931
[epoch9, step691]: loss 0.035097
[epoch9, step692]: loss 0.034416
[epoch9, step693]: loss 0.038807
[epoch9, step694]: loss 0.032886
[epoch9, step695]: loss 0.038110
[epoch9, step696]: loss 0.035355
[epoch9, step697]: loss 0.037920
[epoch9, step698]: loss 0.035326
[epoch9, step699]: loss 0.034052
[epoch9, step700]: loss 0.031848
[epoch9, step701]: loss 0.036732
[epoch9, step702]: loss 0.031972
[epoch9, step703]: loss 0.034210
[epoch9, step704]: loss 0.036459
[epoch9, step705]: loss 0.036082
[epoch9, step706]: loss 0.034301
[epoch9, step707]: loss 0.033927
[epoch9, step708]: loss 0.035472
[epoch9, step709]: loss 0.037610
[epoch9, step710]: loss 0.033519
[epoch9, step711]: loss 0.036830
[epoch9, step712]: loss 0.036748
[epoch9, step713]: loss 0.038082
[epoch9, step714]: loss 0.032277
[epoch9, step715]: loss 0.033944
[epoch9, step716]: loss 0.036137
[epoch9, step717]: loss 0.034050
[epoch9, step718]: loss 0.035823
[epoch9, step719]: loss 0.044557
[epoch9, step720]: loss 0.034994
[epoch9, step721]: loss 0.033615
[epoch9, step722]: loss 0.041274
[epoch9, step723]: loss 0.037831
[epoch9, step724]: loss 0.033137
[epoch9, step725]: loss 0.037134
[epoch9, step726]: loss 0.032489
[epoch9, step727]: loss 0.034504
[epoch9, step728]: loss 0.037041
[epoch9, step729]: loss 0.032543
[epoch9, step730]: loss 0.033107
[epoch9, step731]: loss 0.036592
[epoch9, step732]: loss 0.036287
[epoch9, step733]: loss 0.034657
[epoch9, step734]: loss 0.034156
[epoch9, step735]: loss 0.038051
[epoch9, step736]: loss 0.036382
[epoch9, step737]: loss 0.037433
[epoch9, step738]: loss 0.030931
[epoch9, step739]: loss 0.036501
[epoch9, step740]: loss 0.033585
[epoch9, step741]: loss 0.036407
[epoch9, step742]: loss 0.033353
[epoch9, step743]: loss 0.034368
[epoch9, step744]: loss 0.033700
[epoch9, step745]: loss 0.034033
[epoch9, step746]: loss 0.036228
[epoch9, step747]: loss 0.038949
[epoch9, step748]: loss 0.036562
[epoch9, step749]: loss 0.036071
[epoch9, step750]: loss 0.038417
[epoch9, step751]: loss 0.033268
[epoch9, step752]: loss 0.034847
[epoch9, step753]: loss 0.035475
[epoch9, step754]: loss 0.034318
[epoch9, step755]: loss 0.036265
[epoch9, step756]: loss 0.033886
[epoch9, step757]: loss 0.030248
[epoch9, step758]: loss 0.034539
[epoch9, step759]: loss 0.033333
[epoch9, step760]: loss 0.034407
[epoch9, step761]: loss 0.037546
[epoch9, step762]: loss 0.031781
[epoch9, step763]: loss 0.035462
[epoch9, step764]: loss 0.035071
[epoch9, step765]: loss 0.037235
[epoch9, step766]: loss 0.036324
[epoch9, step767]: loss 0.039630
[epoch9, step768]: loss 0.031610
[epoch9, step769]: loss 0.036385
[epoch9, step770]: loss 0.035155
[epoch9, step771]: loss 0.033426
[epoch9, step772]: loss 0.038951
[epoch9, step773]: loss 0.035969
[epoch9, step774]: loss 0.035226
[epoch9, step775]: loss 0.030017
[epoch9, step776]: loss 0.037380
[epoch9, step777]: loss 0.033250
[epoch9, step778]: loss 0.037409
[epoch9, step779]: loss 0.035602
[epoch9, step780]: loss 0.030100
[epoch9, step781]: loss 0.035144
[epoch9, step782]: loss 0.032425
[epoch9, step783]: loss 0.030466
[epoch9, step784]: loss 0.031271
[epoch9, step785]: loss 0.031659
[epoch9, step786]: loss 0.034353
[epoch9, step787]: loss 0.034642
[epoch9, step788]: loss 0.036230
[epoch9, step789]: loss 0.034833
[epoch9, step790]: loss 0.034288
[epoch9, step791]: loss 0.037882
[epoch9, step792]: loss 0.035554
[epoch9, step793]: loss 0.037174
[epoch9, step794]: loss 0.030532
[epoch9, step795]: loss 0.035209
[epoch9, step796]: loss 0.038425
[epoch9, step797]: loss 0.037116
[epoch9, step798]: loss 0.037850
[epoch9, step799]: loss 0.037430
[epoch9, step800]: loss 0.032001
[epoch9, step801]: loss 0.034112
[epoch9, step802]: loss 0.033531
[epoch9, step803]: loss 0.036976
[epoch9, step804]: loss 0.037679
[epoch9, step805]: loss 0.038295
[epoch9, step806]: loss 0.032819
[epoch9, step807]: loss 0.031601
[epoch9, step808]: loss 0.034273
[epoch9, step809]: loss 0.032404
[epoch9, step810]: loss 0.036511
[epoch9, step811]: loss 0.035679
[epoch9, step812]: loss 0.033859
[epoch9, step813]: loss 0.034015
[epoch9, step814]: loss 0.036431
[epoch9, step815]: loss 0.034086
[epoch9, step816]: loss 0.034715
[epoch9, step817]: loss 0.035574
[epoch9, step818]: loss 0.032813
[epoch9, step819]: loss 0.031466
[epoch9, step820]: loss 0.034501
[epoch9, step821]: loss 0.031964
[epoch9, step822]: loss 0.040338
[epoch9, step823]: loss 0.033999
[epoch9, step824]: loss 0.036396
[epoch9, step825]: loss 0.036113
[epoch9, step826]: loss 0.034811
[epoch9, step827]: loss 0.037858
[epoch9, step828]: loss 0.039503
[epoch9, step829]: loss 0.038361
[epoch9, step830]: loss 0.033419
[epoch9, step831]: loss 0.037016
[epoch9, step832]: loss 0.031725
[epoch9, step833]: loss 0.038685
[epoch9, step834]: loss 0.037105
[epoch9, step835]: loss 0.031274
[epoch9, step836]: loss 0.038865
[epoch9, step837]: loss 0.035868
[epoch9, step838]: loss 0.035172
[epoch9, step839]: loss 0.039323
[epoch9, step840]: loss 0.031186
[epoch9, step841]: loss 0.035160
[epoch9, step842]: loss 0.037321
[epoch9, step843]: loss 0.035800
[epoch9, step844]: loss 0.035797
[epoch9, step845]: loss 0.031968
[epoch9, step846]: loss 0.038580
[epoch9, step847]: loss 0.037194
[epoch9, step848]: loss 0.035447
[epoch9, step849]: loss 0.034036
[epoch9, step850]: loss 0.033877
[epoch9, step851]: loss 0.035345
[epoch9, step852]: loss 0.032991
[epoch9, step853]: loss 0.040427
[epoch9, step854]: loss 0.034089
[epoch9, step855]: loss 0.037459
[epoch9, step856]: loss 0.031981
[epoch9, step857]: loss 0.034562
[epoch9, step858]: loss 0.034763
[epoch9, step859]: loss 0.034496
[epoch9, step860]: loss 0.032724
[epoch9, step861]: loss 0.032763
[epoch9, step862]: loss 0.032843
[epoch9, step863]: loss 0.031445
[epoch9, step864]: loss 0.036788
[epoch9, step865]: loss 0.034636
[epoch9, step866]: loss 0.035525
[epoch9, step867]: loss 0.036812
[epoch9, step868]: loss 0.036766
[epoch9, step869]: loss 0.033649
[epoch9, step870]: loss 0.041657
[epoch9, step871]: loss 0.033867
[epoch9, step872]: loss 0.036253
[epoch9, step873]: loss 0.035582
[epoch9, step874]: loss 0.034339
[epoch9, step875]: loss 0.034248
[epoch9, step876]: loss 0.036250
[epoch9, step877]: loss 0.030258
[epoch9, step878]: loss 0.033918
[epoch9, step879]: loss 0.038063
[epoch9, step880]: loss 0.036405
[epoch9, step881]: loss 0.033007
[epoch9, step882]: loss 0.034283
[epoch9, step883]: loss 0.034418
[epoch9, step884]: loss 0.036736
[epoch9, step885]: loss 0.035427
[epoch9, step886]: loss 0.036110
[epoch9, step887]: loss 0.034957
[epoch9, step888]: loss 0.035591
[epoch9, step889]: loss 0.034798
[epoch9, step890]: loss 0.034210
[epoch9, step891]: loss 0.036463
[epoch9, step892]: loss 0.030403
[epoch9, step893]: loss 0.034406
[epoch9, step894]: loss 0.035635
[epoch9, step895]: loss 0.032557
[epoch9, step896]: loss 0.032953
[epoch9, step897]: loss 0.035722
[epoch9, step898]: loss 0.036735
[epoch9, step899]: loss 0.039209
[epoch9, step900]: loss 0.037280
[epoch9, step901]: loss 0.037100
[epoch9, step902]: loss 0.033941
[epoch9, step903]: loss 0.035210
[epoch9, step904]: loss 0.037659
[epoch9, step905]: loss 0.038452
[epoch9, step906]: loss 0.032139
[epoch9, step907]: loss 0.033940
[epoch9, step908]: loss 0.031797
[epoch9, step909]: loss 0.037657
[epoch9, step910]: loss 0.033903
[epoch9, step911]: loss 0.035991
[epoch9, step912]: loss 0.033505
[epoch9, step913]: loss 0.034804
[epoch9, step914]: loss 0.039625
[epoch9, step915]: loss 0.034449
[epoch9, step916]: loss 0.033662
[epoch9, step917]: loss 0.035130
[epoch9, step918]: loss 0.039702
[epoch9, step919]: loss 0.035038
[epoch9, step920]: loss 0.037693
[epoch9, step921]: loss 0.034084
[epoch9, step922]: loss 0.034629
[epoch9, step923]: loss 0.033443
[epoch9, step924]: loss 0.030413
[epoch9, step925]: loss 0.035869
[epoch9, step926]: loss 0.034873
[epoch9, step927]: loss 0.035504
[epoch9, step928]: loss 0.035101
[epoch9, step929]: loss 0.038317
[epoch9, step930]: loss 0.036804
[epoch9, step931]: loss 0.037393
[epoch9, step932]: loss 0.031946
[epoch9, step933]: loss 0.038779
[epoch9, step934]: loss 0.033031
[epoch9, step935]: loss 0.034336
[epoch9, step936]: loss 0.032547
[epoch9, step937]: loss 0.036307
[epoch9, step938]: loss 0.038211
[epoch9, step939]: loss 0.031400
[epoch9, step940]: loss 0.033784
[epoch9, step941]: loss 0.038498
[epoch9, step942]: loss 0.035951
[epoch9, step943]: loss 0.033982
[epoch9, step944]: loss 0.038415
[epoch9, step945]: loss 0.031104
[epoch9, step946]: loss 0.035681
[epoch9, step947]: loss 0.038981
[epoch9, step948]: loss 0.030546
[epoch9, step949]: loss 0.033631
[epoch9, step950]: loss 0.038070
[epoch9, step951]: loss 0.038996
[epoch9, step952]: loss 0.034810
[epoch9, step953]: loss 0.037672
[epoch9, step954]: loss 0.033312
[epoch9, step955]: loss 0.042081
[epoch9, step956]: loss 0.051370
[epoch9, step957]: loss 0.047359
[epoch9, step958]: loss 0.045857
[epoch9, step959]: loss 0.049012
[epoch9, step960]: loss 0.045987
[epoch9, step961]: loss 0.046450
[epoch9, step962]: loss 0.045526
[epoch9, step963]: loss 0.044262
[epoch9, step964]: loss 0.044661
[epoch9, step965]: loss 0.045963
[epoch9, step966]: loss 0.043999
[epoch9, step967]: loss 0.043035
[epoch9, step968]: loss 0.045006
[epoch9, step969]: loss 0.044500
[epoch9, step970]: loss 0.043616
[epoch9, step971]: loss 0.043651
[epoch9, step972]: loss 0.043572
[epoch9, step973]: loss 0.043836
[epoch9, step974]: loss 0.045127
[epoch9, step975]: loss 0.043389
[epoch9, step976]: loss 0.042492
[epoch9, step977]: loss 0.044230
[epoch9, step978]: loss 0.043439
[epoch9, step979]: loss 0.042860
[epoch9, step980]: loss 0.042350
[epoch9, step981]: loss 0.043421
[epoch9, step982]: loss 0.042840
[epoch9, step983]: loss 0.043831
[epoch9, step984]: loss 0.042500
[epoch9, step985]: loss 0.042367
[epoch9, step986]: loss 0.045168
[epoch9, step987]: loss 0.043290
[epoch9, step988]: loss 0.043648
[epoch9, step989]: loss 0.043121
[epoch9, step990]: loss 0.042721
[epoch9, step991]: loss 0.042955
[epoch9, step992]: loss 0.043658
[epoch9, step993]: loss 0.042909
[epoch9, step994]: loss 0.041402
[epoch9, step995]: loss 0.043858
[epoch9, step996]: loss 0.043394
[epoch9, step997]: loss 0.043081
[epoch9, step998]: loss 0.043415
[epoch9, step999]: loss 0.042796
[epoch9, step1000]: loss 0.043262
[epoch9, step1001]: loss 0.043383
[epoch9, step1002]: loss 0.042312
[epoch9, step1003]: loss 0.042247
[epoch9, step1004]: loss 0.043796
[epoch9, step1005]: loss 0.042690
[epoch9, step1006]: loss 0.042246
[epoch9, step1007]: loss 0.042169
[epoch9, step1008]: loss 0.042503
[epoch9, step1009]: loss 0.043196
[epoch9, step1010]: loss 0.043415
[epoch9, step1011]: loss 0.042567
[epoch9, step1012]: loss 0.041884
[epoch9, step1013]: loss 0.043284
[epoch9, step1014]: loss 0.043159
[epoch9, step1015]: loss 0.042857
[epoch9, step1016]: loss 0.042098
[epoch9, step1017]: loss 0.042646
[epoch9, step1018]: loss 0.042425
[epoch9, step1019]: loss 0.044133
[epoch9, step1020]: loss 0.042408
[epoch9, step1021]: loss 0.041101
[epoch9, step1022]: loss 0.042868
[epoch9, step1023]: loss 0.042770
[epoch9, step1024]: loss 0.043477
[epoch9, step1025]: loss 0.041631
[epoch9, step1026]: loss 0.041772
[epoch9, step1027]: loss 0.043037
[epoch9, step1028]: loss 0.042866
[epoch9, step1029]: loss 0.042510
[epoch9, step1030]: loss 0.041029
[epoch9, step1031]: loss 0.043360
[epoch9, step1032]: loss 0.043029
[epoch9, step1033]: loss 0.042183
[epoch9, step1034]: loss 0.041835
[epoch9, step1035]: loss 0.042336
[epoch9, step1036]: loss 0.042618
[epoch9, step1037]: loss 0.043027
[epoch9, step1038]: loss 0.041779
[epoch9, step1039]: loss 0.041825
[epoch9, step1040]: loss 0.043326
[epoch9, step1041]: loss 0.042398
[epoch9, step1042]: loss 0.042556
[epoch9, step1043]: loss 0.042209
[epoch9, step1044]: loss 0.042993
[epoch9, step1045]: loss 0.042723
[epoch9, step1046]: loss 0.043337
[epoch9, step1047]: loss 0.041958
[epoch9, step1048]: loss 0.041678
[epoch9, step1049]: loss 0.043880
[epoch9, step1050]: loss 0.042474
[epoch9, step1051]: loss 0.042620
[epoch9, step1052]: loss 0.041930
[epoch9, step1053]: loss 0.042747
[epoch9, step1054]: loss 0.042618
[epoch9, step1055]: loss 0.042761
[epoch9, step1056]: loss 0.040810
[epoch9, step1057]: loss 0.041777
[epoch9, step1058]: loss 0.044004
[epoch9, step1059]: loss 0.042823
[epoch9, step1060]: loss 0.042591
[epoch9, step1061]: loss 0.041306
[epoch9, step1062]: loss 0.042906
[epoch9, step1063]: loss 0.043157
[epoch9, step1064]: loss 0.044160
[epoch9, step1065]: loss 0.042135
[epoch9, step1066]: loss 0.041421
[epoch9, step1067]: loss 0.044304
[epoch9, step1068]: loss 0.041786
[epoch9, step1069]: loss 0.041886
[epoch9, step1070]: loss 0.041739
[epoch9, step1071]: loss 0.042537
[epoch9, step1072]: loss 0.042688
[epoch9, step1073]: loss 0.042599
[epoch9, step1074]: loss 0.041407
[epoch9, step1075]: loss 0.041070
[epoch9, step1076]: loss 0.042887
[epoch9, step1077]: loss 0.042389
[epoch9, step1078]: loss 0.042757
[epoch9, step1079]: loss 0.042512
[epoch9, step1080]: loss 0.041964
[epoch9, step1081]: loss 0.042744
[epoch9, step1082]: loss 0.043142
[epoch9, step1083]: loss 0.042483
[epoch9, step1084]: loss 0.041143
[epoch9, step1085]: loss 0.042458
[epoch9, step1086]: loss 0.041491
[epoch9, step1087]: loss 0.042509
[epoch9, step1088]: loss 0.041639
[epoch9, step1089]: loss 0.042411
[epoch9, step1090]: loss 0.042891
[epoch9, step1091]: loss 0.043024
[epoch9, step1092]: loss 0.041297
[epoch9, step1093]: loss 0.040844
[epoch9, step1094]: loss 0.042582
[epoch9, step1095]: loss 0.041983
[epoch9, step1096]: loss 0.041582
[epoch9, step1097]: loss 0.042348
[epoch9, step1098]: loss 0.041891
[epoch9, step1099]: loss 0.042226
[epoch9, step1100]: loss 0.044104
[epoch9, step1101]: loss 0.042441
[epoch9, step1102]: loss 0.040730
[epoch9, step1103]: loss 0.043363
[epoch9, step1104]: loss 0.042410
[epoch9, step1105]: loss 0.042387
[epoch9, step1106]: loss 0.041340
[epoch9, step1107]: loss 0.041374
[epoch9, step1108]: loss 0.041175
[epoch9, step1109]: loss 0.042492
[epoch9, step1110]: loss 0.042349
[epoch9, step1111]: loss 0.040978
[epoch9, step1112]: loss 0.043056
[epoch9, step1113]: loss 0.041944
[epoch9, step1114]: loss 0.041902
[epoch9, step1115]: loss 0.041907
[epoch9, step1116]: loss 0.041886
[epoch9, step1117]: loss 0.041998
[epoch9, step1118]: loss 0.042921
[epoch9, step1119]: loss 0.041825
[epoch9, step1120]: loss 0.041315
[epoch9, step1121]: loss 0.042695
[epoch9, step1122]: loss 0.043048
[epoch9, step1123]: loss 0.042891
[epoch9, step1124]: loss 0.042309
[epoch9, step1125]: loss 0.042106
[epoch9, step1126]: loss 0.043422
[epoch9, step1127]: loss 0.042809
[epoch9, step1128]: loss 0.041969
[epoch9, step1129]: loss 0.041539
[epoch9, step1130]: loss 0.043660
[epoch9, step1131]: loss 0.043115
[epoch9, step1132]: loss 0.042184
[epoch9, step1133]: loss 0.040921
[epoch9, step1134]: loss 0.042061
[epoch9, step1135]: loss 0.043489
[epoch9, step1136]: loss 0.044195
[epoch9, step1137]: loss 0.041568
[epoch9, step1138]: loss 0.041277
[epoch9, step1139]: loss 0.043112
[epoch9, step1140]: loss 0.042142
[epoch9, step1141]: loss 0.042551
[epoch9, step1142]: loss 0.042054
[epoch9, step1143]: loss 0.042344
[epoch9, step1144]: loss 0.042179
[epoch9, step1145]: loss 0.042728
[epoch9, step1146]: loss 0.041860
[epoch9, step1147]: loss 0.041537
[epoch9, step1148]: loss 0.043719
[epoch9, step1149]: loss 0.042276
[epoch9, step1150]: loss 0.041984
[epoch9, step1151]: loss 0.042028
[epoch9, step1152]: loss 0.042763
[epoch9, step1153]: loss 0.041774
[epoch9, step1154]: loss 0.043073
[epoch9, step1155]: loss 0.041997
[epoch9, step1156]: loss 0.041119
[epoch9, step1157]: loss 0.043579
[epoch9, step1158]: loss 0.042487
[epoch9, step1159]: loss 0.041780
[epoch9, step1160]: loss 0.042141
[epoch9, step1161]: loss 0.043148
[epoch9, step1162]: loss 0.042094
[epoch9, step1163]: loss 0.042354
[epoch9, step1164]: loss 0.041414
[epoch9, step1165]: loss 0.041681
[epoch9, step1166]: loss 0.043418
[epoch9, step1167]: loss 0.041959
[epoch9, step1168]: loss 0.042232
[epoch9, step1169]: loss 0.041239
[epoch9, step1170]: loss 0.041988
[epoch9, step1171]: loss 0.041743
[epoch9, step1172]: loss 0.043851
[epoch9, step1173]: loss 0.042101
[epoch9, step1174]: loss 0.041573
[epoch9, step1175]: loss 0.042208
[epoch9, step1176]: loss 0.042094
[epoch9, step1177]: loss 0.042527
[epoch9, step1178]: loss 0.041513
[epoch9, step1179]: loss 0.041629
[epoch9, step1180]: loss 0.042144
[epoch9, step1181]: loss 0.043381
[epoch9, step1182]: loss 0.041912
[epoch9, step1183]: loss 0.041069
[epoch9, step1184]: loss 0.042307
[epoch9, step1185]: loss 0.042191
[epoch9, step1186]: loss 0.042453
[epoch9, step1187]: loss 0.040942
[epoch9, step1188]: loss 0.042499
[epoch9, step1189]: loss 0.042587
[epoch9, step1190]: loss 0.043229
[epoch9, step1191]: loss 0.043091
[epoch9, step1192]: loss 0.041026
[epoch9, step1193]: loss 0.042983
[epoch9, step1194]: loss 0.043056
[epoch9, step1195]: loss 0.041282
[epoch9, step1196]: loss 0.041005
[epoch9, step1197]: loss 0.042227
[epoch9, step1198]: loss 0.041901
[epoch9, step1199]: loss 0.042194
[epoch9, step1200]: loss 0.042097
[epoch9, step1201]: loss 0.040825
[epoch9, step1202]: loss 0.043525
[epoch9, step1203]: loss 0.042443
[epoch9, step1204]: loss 0.042116
[epoch9, step1205]: loss 0.041075
[epoch9, step1206]: loss 0.041376
[epoch9, step1207]: loss 0.042118
[epoch9, step1208]: loss 0.042689
[epoch9, step1209]: loss 0.041689
[epoch9, step1210]: loss 0.041535
[epoch9, step1211]: loss 0.043241
[epoch9, step1212]: loss 0.042690
[epoch9, step1213]: loss 0.043263
[epoch9, step1214]: loss 0.042412
[epoch9, step1215]: loss 0.042582
[epoch9, step1216]: loss 0.043037
[epoch9, step1217]: loss 0.043437
[epoch9, step1218]: loss 0.041454
[epoch9, step1219]: loss 0.042198
[epoch9, step1220]: loss 0.043994
[epoch9, step1221]: loss 0.041803
[epoch9, step1222]: loss 0.041845
[epoch9, step1223]: loss 0.041692
[epoch9, step1224]: loss 0.042370
[epoch9, step1225]: loss 0.042150
[epoch9, step1226]: loss 0.043933
[epoch9, step1227]: loss 0.042490
[epoch9, step1228]: loss 0.040728
[epoch9, step1229]: loss 0.042620
[epoch9, step1230]: loss 0.042027
[epoch9, step1231]: loss 0.041734
[epoch9, step1232]: loss 0.042379
[epoch9, step1233]: loss 0.042055
[epoch9, step1234]: loss 0.041699
[epoch9, step1235]: loss 0.043129
[epoch9, step1236]: loss 0.041858
[epoch9, step1237]: loss 0.040991
[epoch9, step1238]: loss 0.042024
[epoch9, step1239]: loss 0.042552
[epoch9, step1240]: loss 0.043100
[epoch9, step1241]: loss 0.040710
[epoch9, step1242]: loss 0.042107
[epoch9, step1243]: loss 0.042531
[epoch9, step1244]: loss 0.042843
[epoch9, step1245]: loss 0.041862
[epoch9, step1246]: loss 0.041031
[epoch9, step1247]: loss 0.042976
[epoch9, step1248]: loss 0.041741
[epoch9, step1249]: loss 0.042057
[epoch9, step1250]: loss 0.040743
[epoch9, step1251]: loss 0.041617
[epoch9, step1252]: loss 0.043059
[epoch9, step1253]: loss 0.042931
[epoch9, step1254]: loss 0.041641
[epoch9, step1255]: loss 0.041711
[epoch9, step1256]: loss 0.043315
[epoch9, step1257]: loss 0.041619
[epoch9, step1258]: loss 0.041693
[epoch9, step1259]: loss 0.041195
[epoch9, step1260]: loss 0.041987
[epoch9, step1261]: loss 0.041592
[epoch9, step1262]: loss 0.041821
[epoch9, step1263]: loss 0.042113
[epoch9, step1264]: loss 0.042124
[epoch9, step1265]: loss 0.042024
[epoch9, step1266]: loss 0.041816
[epoch9, step1267]: loss 0.041905
[epoch9, step1268]: loss 0.041352
[epoch9, step1269]: loss 0.042204
[epoch9, step1270]: loss 0.041770
[epoch9, step1271]: loss 0.042937
[epoch9, step1272]: loss 0.041560
[epoch9, step1273]: loss 0.040705
[epoch9, step1274]: loss 0.042663
[epoch9, step1275]: loss 0.042002
[epoch9, step1276]: loss 0.041898
[epoch9, step1277]: loss 0.041188
[epoch9, step1278]: loss 0.041889
[epoch9, step1279]: loss 0.041720
[epoch9, step1280]: loss 0.043359
[epoch9, step1281]: loss 0.041387
[epoch9, step1282]: loss 0.041268
[epoch9, step1283]: loss 0.042110
[epoch9, step1284]: loss 0.042455
[epoch9, step1285]: loss 0.042089
[epoch9, step1286]: loss 0.041237
[epoch9, step1287]: loss 0.043191
[epoch9, step1288]: loss 0.042345
[epoch9, step1289]: loss 0.044115
[epoch9, step1290]: loss 0.042801
[epoch9, step1291]: loss 0.041364
[epoch9, step1292]: loss 0.043127
[epoch9, step1293]: loss 0.041700
[epoch9, step1294]: loss 0.041725
[epoch9, step1295]: loss 0.041888
[epoch9, step1296]: loss 0.042548
[epoch9, step1297]: loss 0.041988
[epoch9, step1298]: loss 0.042848
[epoch9, step1299]: loss 0.042671
[epoch9, step1300]: loss 0.042204
[epoch9, step1301]: loss 0.042646
[epoch9, step1302]: loss 0.043051
[epoch9, step1303]: loss 0.041929
[epoch9, step1304]: loss 0.041215
[epoch9, step1305]: loss 0.043122
[epoch9, step1306]: loss 0.042772
[epoch9, step1307]: loss 0.042625
[epoch9, step1308]: loss 0.042000
[epoch9, step1309]: loss 0.040623
[epoch9, step1310]: loss 0.043111
[epoch9, step1311]: loss 0.041407
[epoch9, step1312]: loss 0.041756
[epoch9, step1313]: loss 0.040910
[epoch9, step1314]: loss 0.042336
[epoch9, step1315]: loss 0.041832
[epoch9, step1316]: loss 0.043839
[epoch9, step1317]: loss 0.041138
[epoch9, step1318]: loss 0.040312
[epoch9, step1319]: loss 0.042664
[epoch9, step1320]: loss 0.042490
[epoch9, step1321]: loss 0.042022
[epoch9, step1322]: loss 0.041071
[epoch9, step1323]: loss 0.042749
[epoch9, step1324]: loss 0.042039
[epoch9, step1325]: loss 0.042497
[epoch9, step1326]: loss 0.041206
[epoch9, step1327]: loss 0.041485
[epoch9, step1328]: loss 0.043974
[epoch9, step1329]: loss 0.042746
[epoch9, step1330]: loss 0.041876
[epoch9, step1331]: loss 0.041187
[epoch9, step1332]: loss 0.041828
[epoch9, step1333]: loss 0.042562
[epoch9, step1334]: loss 0.042453
[epoch9, step1335]: loss 0.041879
[epoch9, step1336]: loss 0.041067
[epoch9, step1337]: loss 0.042861
[epoch9, step1338]: loss 0.041718
[epoch9, step1339]: loss 0.041746
[epoch9, step1340]: loss 0.040743
[epoch9, step1341]: loss 0.042138
[epoch9, step1342]: loss 0.042089
[epoch9, step1343]: loss 0.042263
[epoch9, step1344]: loss 0.041765
[epoch9, step1345]: loss 0.040822
[epoch9, step1346]: loss 0.043473
[epoch9, step1347]: loss 0.042561
[epoch9, step1348]: loss 0.042478
[epoch9, step1349]: loss 0.041846
[epoch9, step1350]: loss 0.042587
[epoch9, step1351]: loss 0.041416
[epoch9, step1352]: loss 0.042693
[epoch9, step1353]: loss 0.042370
[epoch9, step1354]: loss 0.040685
[epoch9, step1355]: loss 0.042551
[epoch9, step1356]: loss 0.041944
[epoch9, step1357]: loss 0.041370
[epoch9, step1358]: loss 0.041441
[epoch9, step1359]: loss 0.041783
[epoch9, step1360]: loss 0.041920
[epoch9, step1361]: loss 0.042945
[epoch9, step1362]: loss 0.041821
[epoch9, step1363]: loss 0.040439
[epoch9, step1364]: loss 0.042448
[epoch9, step1365]: loss 0.041709
[epoch9, step1366]: loss 0.041616
[epoch9, step1367]: loss 0.040931
[epoch9, step1368]: loss 0.041938
[epoch9, step1369]: loss 0.042140
[epoch9, step1370]: loss 0.042310
[epoch9, step1371]: loss 0.041283
[epoch9, step1372]: loss 0.040994
[epoch9, step1373]: loss 0.042246
[epoch9, step1374]: loss 0.042909
[epoch9, step1375]: loss 0.042858
[epoch9, step1376]: loss 0.040752
[epoch9, step1377]: loss 0.041854
[epoch9, step1378]: loss 0.042824
[epoch9, step1379]: loss 0.042691
[epoch9, step1380]: loss 0.042204
[epoch9, step1381]: loss 0.040889
[epoch9, step1382]: loss 0.043137
[epoch9, step1383]: loss 0.041449
[epoch9, step1384]: loss 0.041969
[epoch9, step1385]: loss 0.040690
[epoch9, step1386]: loss 0.042401
[epoch9, step1387]: loss 0.042625
[epoch9, step1388]: loss 0.042427
[epoch9, step1389]: loss 0.040890
[epoch9, step1390]: loss 0.040714
[epoch9, step1391]: loss 0.042871
[epoch9, step1392]: loss 0.041982
[epoch9, step1393]: loss 0.042163
[epoch9, step1394]: loss 0.041339
[epoch9, step1395]: loss 0.042087
[epoch9, step1396]: loss 0.041548
[epoch9, step1397]: loss 0.042291
[epoch9, step1398]: loss 0.041189
[epoch9, step1399]: loss 0.041367
[epoch9, step1400]: loss 0.043429
[epoch9, step1401]: loss 0.042731
[epoch9, step1402]: loss 0.041801
[epoch9, step1403]: loss 0.040808
[epoch9, step1404]: loss 0.042036
[epoch9, step1405]: loss 0.042349
[epoch9, step1406]: loss 0.042809
[epoch9, step1407]: loss 0.042450
[epoch9, step1408]: loss 0.040733
[epoch9, step1409]: loss 0.042424
[epoch9, step1410]: loss 0.041826
[epoch9, step1411]: loss 0.041525
[epoch9, step1412]: loss 0.041115
[epoch9, step1413]: loss 0.041505
[epoch9, step1414]: loss 0.042131
[epoch9, step1415]: loss 0.042539
[epoch9, step1416]: loss 0.041669
[epoch9, step1417]: loss 0.040490
[epoch9, step1418]: loss 0.042350
[epoch9, step1419]: loss 0.042497
[epoch9, step1420]: loss 0.042081
[epoch9, step1421]: loss 0.041112
[epoch9, step1422]: loss 0.042062
[epoch9, step1423]: loss 0.042072
[epoch9, step1424]: loss 0.043557
[epoch9, step1425]: loss 0.040955
[epoch9, step1426]: loss 0.041150
[epoch9, step1427]: loss 0.042758
[epoch9, step1428]: loss 0.042183
[epoch9, step1429]: loss 0.043058
[epoch9, step1430]: loss 0.041421
[epoch9, step1431]: loss 0.042577
[epoch9, step1432]: loss 0.043656
[epoch9, step1433]: loss 0.043490
[epoch9, step1434]: loss 0.040920
[epoch9, step1435]: loss 0.041396
[epoch9, step1436]: loss 0.044202
[epoch9, step1437]: loss 0.041858
[epoch9, step1438]: loss 0.041872
[epoch9, step1439]: loss 0.041233
[epoch9, step1440]: loss 0.041711
[epoch9, step1441]: loss 0.042760
[epoch9, step1442]: loss 0.043060
[epoch9, step1443]: loss 0.041000
[epoch9, step1444]: loss 0.040941
[epoch9, step1445]: loss 0.043895
[epoch9, step1446]: loss 0.041749
[epoch9, step1447]: loss 0.042057
[epoch9, step1448]: loss 0.041073
[epoch9, step1449]: loss 0.041552
[epoch9, step1450]: loss 0.041492
[epoch9, step1451]: loss 0.042903
[epoch9, step1452]: loss 0.041850
[epoch9, step1453]: loss 0.041643
[epoch9, step1454]: loss 0.042935
[epoch9, step1455]: loss 0.042147
[epoch9, step1456]: loss 0.041947
[epoch9, step1457]: loss 0.040995
[epoch9, step1458]: loss 0.041806
[epoch9, step1459]: loss 0.041362
[epoch9, step1460]: loss 0.043586
[epoch9, step1461]: loss 0.041833
[epoch9, step1462]: loss 0.041318
[epoch9, step1463]: loss 0.042083
[epoch9, step1464]: loss 0.041506
[epoch9, step1465]: loss 0.041483
[epoch9, step1466]: loss 0.040989
[epoch9, step1467]: loss 0.042325
[epoch9, step1468]: loss 0.041064
[epoch9, step1469]: loss 0.042688
[epoch9, step1470]: loss 0.041648
[epoch9, step1471]: loss 0.040835
[epoch9, step1472]: loss 0.042148
[epoch9, step1473]: loss 0.042168
[epoch9, step1474]: loss 0.043986
[epoch9, step1475]: loss 0.040882
[epoch9, step1476]: loss 0.042216
[epoch9, step1477]: loss 0.041942
[epoch9, step1478]: loss 0.042440
[epoch9, step1479]: loss 0.041348
[epoch9, step1480]: loss 0.040881
[epoch9, step1481]: loss 0.041834
[epoch9, step1482]: loss 0.042014
[epoch9, step1483]: loss 0.042006
[epoch9, step1484]: loss 0.041224
[epoch9, step1485]: loss 0.041787
[epoch9, step1486]: loss 0.041054
[epoch9, step1487]: loss 0.042173
[epoch9, step1488]: loss 0.042232
[epoch9, step1489]: loss 0.041305
[epoch9, step1490]: loss 0.043107
[epoch9, step1491]: loss 0.042059
[epoch9, step1492]: loss 0.042635
[epoch9, step1493]: loss 0.040892
[epoch9, step1494]: loss 0.041585
[epoch9, step1495]: loss 0.041920
[epoch9, step1496]: loss 0.041845
[epoch9, step1497]: loss 0.042089
[epoch9, step1498]: loss 0.040587
[epoch9, step1499]: loss 0.043201
[epoch9, step1500]: loss 0.042517
[epoch9, step1501]: loss 0.042261
[epoch9, step1502]: loss 0.041304
[epoch9, step1503]: loss 0.042213
[epoch9, step1504]: loss 0.041704
[epoch9, step1505]: loss 0.043482
[epoch9, step1506]: loss 0.041102
[epoch9, step1507]: loss 0.041575
[epoch9, step1508]: loss 0.043282
[epoch9, step1509]: loss 0.042734
[epoch9, step1510]: loss 0.042911
[epoch9, step1511]: loss 0.041764
[epoch9, step1512]: loss 0.041740
[epoch9, step1513]: loss 0.041276
[epoch9, step1514]: loss 0.042958
[epoch9, step1515]: loss 0.041394
[epoch9, step1516]: loss 0.040437

[epoch9]: avg loss 0.038457

[epoch10, step1]: loss 0.036457
[epoch10, step2]: loss 0.038243
[epoch10, step3]: loss 0.038098
[epoch10, step4]: loss 0.035158
[epoch10, step5]: loss 0.035339
[epoch10, step6]: loss 0.038033
[epoch10, step7]: loss 0.035811
[epoch10, step8]: loss 0.037914
[epoch10, step9]: loss 0.034452
[epoch10, step10]: loss 0.036068
[epoch10, step11]: loss 0.038501
[epoch10, step12]: loss 0.037271
[epoch10, step13]: loss 0.035334
[epoch10, step14]: loss 0.035187
[epoch10, step15]: loss 0.037253
[epoch10, step16]: loss 0.035771
[epoch10, step17]: loss 0.038234
[epoch10, step18]: loss 0.035200
[epoch10, step19]: loss 0.034968
[epoch10, step20]: loss 0.038252
[epoch10, step21]: loss 0.036881
[epoch10, step22]: loss 0.034610
[epoch10, step23]: loss 0.034434
[epoch10, step24]: loss 0.037588
[epoch10, step25]: loss 0.034890
[epoch10, step26]: loss 0.037195
[epoch10, step27]: loss 0.034365
[epoch10, step28]: loss 0.036057
[epoch10, step29]: loss 0.038290
[epoch10, step30]: loss 0.037586
[epoch10, step31]: loss 0.035277
[epoch10, step32]: loss 0.036288
[epoch10, step33]: loss 0.038027
[epoch10, step34]: loss 0.035165
[epoch10, step35]: loss 0.038556
[epoch10, step36]: loss 0.034490
[epoch10, step37]: loss 0.035306
[epoch10, step38]: loss 0.038361
[epoch10, step39]: loss 0.037482
[epoch10, step40]: loss 0.035136
[epoch10, step41]: loss 0.035102
[epoch10, step42]: loss 0.037820
[epoch10, step43]: loss 0.034989
[epoch10, step44]: loss 0.039329
[epoch10, step45]: loss 0.035528
[epoch10, step46]: loss 0.035478
[epoch10, step47]: loss 0.037468
[epoch10, step48]: loss 0.037508
[epoch10, step49]: loss 0.033611
[epoch10, step50]: loss 0.034852
[epoch10, step51]: loss 0.037712
[epoch10, step52]: loss 0.035328
[epoch10, step53]: loss 0.037626
[epoch10, step54]: loss 0.034471
[epoch10, step55]: loss 0.035974
[epoch10, step56]: loss 0.038579
[epoch10, step57]: loss 0.037634
[epoch10, step58]: loss 0.034981
[epoch10, step59]: loss 0.034000
[epoch10, step60]: loss 0.039058
[epoch10, step61]: loss 0.034632
[epoch10, step62]: loss 0.036665
[epoch10, step63]: loss 0.034178
[epoch10, step64]: loss 0.034629
[epoch10, step65]: loss 0.037503
[epoch10, step66]: loss 0.037776
[epoch10, step67]: loss 0.035043
[epoch10, step68]: loss 0.034600
[epoch10, step69]: loss 0.037505
[epoch10, step70]: loss 0.034742
[epoch10, step71]: loss 0.037834
[epoch10, step72]: loss 0.034569
[epoch10, step73]: loss 0.035093
[epoch10, step74]: loss 0.036388
[epoch10, step75]: loss 0.037809
[epoch10, step76]: loss 0.035654
[epoch10, step77]: loss 0.035296
[epoch10, step78]: loss 0.037601
[epoch10, step79]: loss 0.034725
[epoch10, step80]: loss 0.038361
[epoch10, step81]: loss 0.034880
[epoch10, step82]: loss 0.034966
[epoch10, step83]: loss 0.036800
[epoch10, step84]: loss 0.037624
[epoch10, step85]: loss 0.035357
[epoch10, step86]: loss 0.035358
[epoch10, step87]: loss 0.038497
[epoch10, step88]: loss 0.034449
[epoch10, step89]: loss 0.037511
[epoch10, step90]: loss 0.035491
[epoch10, step91]: loss 0.034597
[epoch10, step92]: loss 0.037863
[epoch10, step93]: loss 0.037259
[epoch10, step94]: loss 0.034106
[epoch10, step95]: loss 0.035141
[epoch10, step96]: loss 0.037011
[epoch10, step97]: loss 0.035513
[epoch10, step98]: loss 0.037923
[epoch10, step99]: loss 0.034918
[epoch10, step100]: loss 0.034082
[epoch10, step101]: loss 0.038192
[epoch10, step102]: loss 0.037013
[epoch10, step103]: loss 0.035415
[epoch10, step104]: loss 0.034744
[epoch10, step105]: loss 0.037803
[epoch10, step106]: loss 0.035087
[epoch10, step107]: loss 0.037420
[epoch10, step108]: loss 0.035047
[epoch10, step109]: loss 0.034679
[epoch10, step110]: loss 0.037690
[epoch10, step111]: loss 0.036837
[epoch10, step112]: loss 0.034743
[epoch10, step113]: loss 0.035852
[epoch10, step114]: loss 0.037368
[epoch10, step115]: loss 0.034800
[epoch10, step116]: loss 0.038564
[epoch10, step117]: loss 0.034582
[epoch10, step118]: loss 0.036135
[epoch10, step119]: loss 0.037797
[epoch10, step120]: loss 0.038461
[epoch10, step121]: loss 0.035284
[epoch10, step122]: loss 0.034684
[epoch10, step123]: loss 0.037967
[epoch10, step124]: loss 0.035336
[epoch10, step125]: loss 0.038192
[epoch10, step126]: loss 0.035074
[epoch10, step127]: loss 0.034304
[epoch10, step128]: loss 0.037587
[epoch10, step129]: loss 0.036717
[epoch10, step130]: loss 0.035166
[epoch10, step131]: loss 0.034426
[epoch10, step132]: loss 0.037577
[epoch10, step133]: loss 0.034900
[epoch10, step134]: loss 0.036799
[epoch10, step135]: loss 0.035239
[epoch10, step136]: loss 0.036417
[epoch10, step137]: loss 0.037445
[epoch10, step138]: loss 0.038011
[epoch10, step139]: loss 0.034763
[epoch10, step140]: loss 0.035356
[epoch10, step141]: loss 0.037787
[epoch10, step142]: loss 0.034937
[epoch10, step143]: loss 0.036984
[epoch10, step144]: loss 0.035269
[epoch10, step145]: loss 0.035686
[epoch10, step146]: loss 0.038774
[epoch10, step147]: loss 0.038549
[epoch10, step148]: loss 0.034711
[epoch10, step149]: loss 0.034248
[epoch10, step150]: loss 0.037003
[epoch10, step151]: loss 0.034787
[epoch10, step152]: loss 0.036798
[epoch10, step153]: loss 0.034433
[epoch10, step154]: loss 0.034529
[epoch10, step155]: loss 0.037041
[epoch10, step156]: loss 0.036571
[epoch10, step157]: loss 0.035029
[epoch10, step158]: loss 0.035065
[epoch10, step159]: loss 0.037129
[epoch10, step160]: loss 0.035184
[epoch10, step161]: loss 0.037384
[epoch10, step162]: loss 0.035137
[epoch10, step163]: loss 0.035455
[epoch10, step164]: loss 0.037162
[epoch10, step165]: loss 0.037159
[epoch10, step166]: loss 0.035884
[epoch10, step167]: loss 0.034544
[epoch10, step168]: loss 0.038400
[epoch10, step169]: loss 0.034574
[epoch10, step170]: loss 0.037870
[epoch10, step171]: loss 0.035502
[epoch10, step172]: loss 0.035450
[epoch10, step173]: loss 0.037807
[epoch10, step174]: loss 0.037307
[epoch10, step175]: loss 0.035180
[epoch10, step176]: loss 0.035103
[epoch10, step177]: loss 0.037709
[epoch10, step178]: loss 0.034883
[epoch10, step179]: loss 0.036536
[epoch10, step180]: loss 0.034734
[epoch10, step181]: loss 0.035062
[epoch10, step182]: loss 0.037490
[epoch10, step183]: loss 0.037826
[epoch10, step184]: loss 0.036335
[epoch10, step185]: loss 0.034691
[epoch10, step186]: loss 0.037451
[epoch10, step187]: loss 0.034654
[epoch10, step188]: loss 0.037063
[epoch10, step189]: loss 0.035323
[epoch10, step190]: loss 0.034516
[epoch10, step191]: loss 0.037715
[epoch10, step192]: loss 0.037701
[epoch10, step193]: loss 0.033115
[epoch10, step194]: loss 0.034146
[epoch10, step195]: loss 0.037370
[epoch10, step196]: loss 0.035153
[epoch10, step197]: loss 0.037268
[epoch10, step198]: loss 0.033865
[epoch10, step199]: loss 0.034893
[epoch10, step200]: loss 0.037677
[epoch10, step201]: loss 0.037973
[epoch10, step202]: loss 0.034467
[epoch10, step203]: loss 0.035289
[epoch10, step204]: loss 0.037981
[epoch10, step205]: loss 0.034657
[epoch10, step206]: loss 0.038013
[epoch10, step207]: loss 0.034734
[epoch10, step208]: loss 0.034995
[epoch10, step209]: loss 0.037951
[epoch10, step210]: loss 0.037838
[epoch10, step211]: loss 0.035168
[epoch10, step212]: loss 0.035051
[epoch10, step213]: loss 0.037224
[epoch10, step214]: loss 0.034502
[epoch10, step215]: loss 0.037436
[epoch10, step216]: loss 0.034872
[epoch10, step217]: loss 0.034404
[epoch10, step218]: loss 0.037596
[epoch10, step219]: loss 0.036937
[epoch10, step220]: loss 0.035015
[epoch10, step221]: loss 0.035067
[epoch10, step222]: loss 0.037600
[epoch10, step223]: loss 0.034843
[epoch10, step224]: loss 0.037173
[epoch10, step225]: loss 0.034551
[epoch10, step226]: loss 0.034374
[epoch10, step227]: loss 0.036197
[epoch10, step228]: loss 0.037731
[epoch10, step229]: loss 0.033854
[epoch10, step230]: loss 0.035306
[epoch10, step231]: loss 0.038264
[epoch10, step232]: loss 0.034622
[epoch10, step233]: loss 0.037187
[epoch10, step234]: loss 0.034129
[epoch10, step235]: loss 0.035601
[epoch10, step236]: loss 0.037158
[epoch10, step237]: loss 0.037088
[epoch10, step238]: loss 0.035344
[epoch10, step239]: loss 0.034160
[epoch10, step240]: loss 0.036828
[epoch10, step241]: loss 0.034996
[epoch10, step242]: loss 0.037582
[epoch10, step243]: loss 0.035423
[epoch10, step244]: loss 0.034931
[epoch10, step245]: loss 0.036826
[epoch10, step246]: loss 0.036968
[epoch10, step247]: loss 0.035246
[epoch10, step248]: loss 0.034359
[epoch10, step249]: loss 0.036705
[epoch10, step250]: loss 0.034949
[epoch10, step251]: loss 0.037796
[epoch10, step252]: loss 0.035651
[epoch10, step253]: loss 0.034310
[epoch10, step254]: loss 0.037055
[epoch10, step255]: loss 0.037444
[epoch10, step256]: loss 0.035157
[epoch10, step257]: loss 0.034732
[epoch10, step258]: loss 0.038114
[epoch10, step259]: loss 0.035226
[epoch10, step260]: loss 0.037128
[epoch10, step261]: loss 0.035580
[epoch10, step262]: loss 0.035170
[epoch10, step263]: loss 0.036679
[epoch10, step264]: loss 0.037213
[epoch10, step265]: loss 0.034843
[epoch10, step266]: loss 0.034538
[epoch10, step267]: loss 0.037070
[epoch10, step268]: loss 0.035056
[epoch10, step269]: loss 0.036985
[epoch10, step270]: loss 0.034623
[epoch10, step271]: loss 0.034977
[epoch10, step272]: loss 0.037101
[epoch10, step273]: loss 0.037102
[epoch10, step274]: loss 0.035421
[epoch10, step275]: loss 0.034646
[epoch10, step276]: loss 0.037644
[epoch10, step277]: loss 0.035480
[epoch10, step278]: loss 0.037950
[epoch10, step279]: loss 0.034684
[epoch10, step280]: loss 0.034834
[epoch10, step281]: loss 0.037627
[epoch10, step282]: loss 0.037710
[epoch10, step283]: loss 0.034545
[epoch10, step284]: loss 0.034365
[epoch10, step285]: loss 0.038016
[epoch10, step286]: loss 0.034221
[epoch10, step287]: loss 0.037344
[epoch10, step288]: loss 0.034185
[epoch10, step289]: loss 0.035629
[epoch10, step290]: loss 0.037557
[epoch10, step291]: loss 0.037202
[epoch10, step292]: loss 0.034321
[epoch10, step293]: loss 0.034784
[epoch10, step294]: loss 0.037448
[epoch10, step295]: loss 0.034735
[epoch10, step296]: loss 0.038010
[epoch10, step297]: loss 0.034918
[epoch10, step298]: loss 0.035344
[epoch10, step299]: loss 0.036173
[epoch10, step300]: loss 0.037673
[epoch10, step301]: loss 0.035091
[epoch10, step302]: loss 0.035281
[epoch10, step303]: loss 0.038444
[epoch10, step304]: loss 0.035197
[epoch10, step305]: loss 0.037038
[epoch10, step306]: loss 0.034793
[epoch10, step307]: loss 0.034727
[epoch10, step308]: loss 0.038631
[epoch10, step309]: loss 0.037611
[epoch10, step310]: loss 0.034985
[epoch10, step311]: loss 0.036239
[epoch10, step312]: loss 0.037769
[epoch10, step313]: loss 0.034665
[epoch10, step314]: loss 0.038072
[epoch10, step315]: loss 0.037529
[epoch10, step316]: loss 0.036292
[epoch10, step317]: loss 0.037927
[epoch10, step318]: loss 0.037347
[epoch10, step319]: loss 0.034932
[epoch10, step320]: loss 0.034672
[epoch10, step321]: loss 0.036845
[epoch10, step322]: loss 0.035136
[epoch10, step323]: loss 0.038426
[epoch10, step324]: loss 0.036767
[epoch10, step325]: loss 0.034999
[epoch10, step326]: loss 0.037195
[epoch10, step327]: loss 0.037127
[epoch10, step328]: loss 0.035443
[epoch10, step329]: loss 0.034573
[epoch10, step330]: loss 0.036672
[epoch10, step331]: loss 0.036071
[epoch10, step332]: loss 0.037641
[epoch10, step333]: loss 0.034621
[epoch10, step334]: loss 0.035396
[epoch10, step335]: loss 0.038535
[epoch10, step336]: loss 0.038278
[epoch10, step337]: loss 0.035389
[epoch10, step338]: loss 0.034313
[epoch10, step339]: loss 0.037201
[epoch10, step340]: loss 0.035432
[epoch10, step341]: loss 0.036538
[epoch10, step342]: loss 0.034288
[epoch10, step343]: loss 0.034769
[epoch10, step344]: loss 0.036796
[epoch10, step345]: loss 0.036700
[epoch10, step346]: loss 0.034571
[epoch10, step347]: loss 0.034949
[epoch10, step348]: loss 0.037509
[epoch10, step349]: loss 0.036145
[epoch10, step350]: loss 0.037403
[epoch10, step351]: loss 0.034113
[epoch10, step352]: loss 0.034366
[epoch10, step353]: loss 0.037223
[epoch10, step354]: loss 0.036026
[epoch10, step355]: loss 0.033971
[epoch10, step356]: loss 0.035508
[epoch10, step357]: loss 0.037224
[epoch10, step358]: loss 0.033227
[epoch10, step359]: loss 0.039285
[epoch10, step360]: loss 0.033703
[epoch10, step361]: loss 0.034492
[epoch10, step362]: loss 0.037938
[epoch10, step363]: loss 0.036401
[epoch10, step364]: loss 0.034657
[epoch10, step365]: loss 0.034293
[epoch10, step366]: loss 0.037511
[epoch10, step367]: loss 0.035103
[epoch10, step368]: loss 0.036528
[epoch10, step369]: loss 0.034541
[epoch10, step370]: loss 0.035309
[epoch10, step371]: loss 0.037687
[epoch10, step372]: loss 0.036692
[epoch10, step373]: loss 0.034110
[epoch10, step374]: loss 0.033974
[epoch10, step375]: loss 0.038651
[epoch10, step376]: loss 0.035121
[epoch10, step377]: loss 0.037498
[epoch10, step378]: loss 0.034850
[epoch10, step379]: loss 0.035163
[epoch10, step380]: loss 0.037731
[epoch10, step381]: loss 0.036512
[epoch10, step382]: loss 0.034760
[epoch10, step383]: loss 0.033715
[epoch10, step384]: loss 0.036247
[epoch10, step385]: loss 0.034571
[epoch10, step386]: loss 0.037181
[epoch10, step387]: loss 0.034684
[epoch10, step388]: loss 0.035731
[epoch10, step389]: loss 0.036637
[epoch10, step390]: loss 0.038524
[epoch10, step391]: loss 0.034481
[epoch10, step392]: loss 0.035063
[epoch10, step393]: loss 0.037249
[epoch10, step394]: loss 0.034570
[epoch10, step395]: loss 0.037197
[epoch10, step396]: loss 0.034467
[epoch10, step397]: loss 0.034443
[epoch10, step398]: loss 0.037137
[epoch10, step399]: loss 0.036835
[epoch10, step400]: loss 0.034895
[epoch10, step401]: loss 0.034349
[epoch10, step402]: loss 0.037333
[epoch10, step403]: loss 0.034897
[epoch10, step404]: loss 0.037451
[epoch10, step405]: loss 0.035267
[epoch10, step406]: loss 0.035173
[epoch10, step407]: loss 0.037096
[epoch10, step408]: loss 0.037418
[epoch10, step409]: loss 0.036305
[epoch10, step410]: loss 0.035003
[epoch10, step411]: loss 0.037000
[epoch10, step412]: loss 0.034443
[epoch10, step413]: loss 0.037260
[epoch10, step414]: loss 0.034545
[epoch10, step415]: loss 0.035193
[epoch10, step416]: loss 0.036462
[epoch10, step417]: loss 0.036927
[epoch10, step418]: loss 0.035038
[epoch10, step419]: loss 0.034015
[epoch10, step420]: loss 0.037380
[epoch10, step421]: loss 0.034777
[epoch10, step422]: loss 0.037188
[epoch10, step423]: loss 0.034547
[epoch10, step424]: loss 0.034524
[epoch10, step425]: loss 0.037173
[epoch10, step426]: loss 0.038031
[epoch10, step427]: loss 0.036169
[epoch10, step428]: loss 0.035060
[epoch10, step429]: loss 0.038019
[epoch10, step430]: loss 0.034976
[epoch10, step431]: loss 0.037253
[epoch10, step432]: loss 0.034377
[epoch10, step433]: loss 0.035293
[epoch10, step434]: loss 0.037053
[epoch10, step435]: loss 0.037554
[epoch10, step436]: loss 0.034856
[epoch10, step437]: loss 0.034715
[epoch10, step438]: loss 0.037789
[epoch10, step439]: loss 0.035660
[epoch10, step440]: loss 0.037627
[epoch10, step441]: loss 0.034582
[epoch10, step442]: loss 0.035157
[epoch10, step443]: loss 0.037839
[epoch10, step444]: loss 0.036583
[epoch10, step445]: loss 0.035869
[epoch10, step446]: loss 0.035107
[epoch10, step447]: loss 0.037720
[epoch10, step448]: loss 0.035019
[epoch10, step449]: loss 0.037006
[epoch10, step450]: loss 0.033957
[epoch10, step451]: loss 0.034650
[epoch10, step452]: loss 0.036416
[epoch10, step453]: loss 0.037002
[epoch10, step454]: loss 0.034462
[epoch10, step455]: loss 0.034615
[epoch10, step456]: loss 0.036269
[epoch10, step457]: loss 0.035486
[epoch10, step458]: loss 0.036617
[epoch10, step459]: loss 0.035123
[epoch10, step460]: loss 0.035310
[epoch10, step461]: loss 0.038898
[epoch10, step462]: loss 0.036249
[epoch10, step463]: loss 0.035281
[epoch10, step464]: loss 0.034842
[epoch10, step465]: loss 0.038745
[epoch10, step466]: loss 0.034881
[epoch10, step467]: loss 0.037114
[epoch10, step468]: loss 0.035439
[epoch10, step469]: loss 0.035279
[epoch10, step470]: loss 0.037301
[epoch10, step471]: loss 0.036830
[epoch10, step472]: loss 0.035252
[epoch10, step473]: loss 0.034306
[epoch10, step474]: loss 0.037061
[epoch10, step475]: loss 0.034694
[epoch10, step476]: loss 0.037467
[epoch10, step477]: loss 0.034422
[epoch10, step478]: loss 0.033850
[epoch10, step479]: loss 0.036723
[epoch10, step480]: loss 0.036324
[epoch10, step481]: loss 0.034622
[epoch10, step482]: loss 0.034428
[epoch10, step483]: loss 0.037383
[epoch10, step484]: loss 0.035453
[epoch10, step485]: loss 0.037940
[epoch10, step486]: loss 0.034739
[epoch10, step487]: loss 0.034755
[epoch10, step488]: loss 0.038227
[epoch10, step489]: loss 0.036068
[epoch10, step490]: loss 0.035391
[epoch10, step491]: loss 0.034897
[epoch10, step492]: loss 0.036942
[epoch10, step493]: loss 0.034427
[epoch10, step494]: loss 0.036417
[epoch10, step495]: loss 0.035323
[epoch10, step496]: loss 0.035222
[epoch10, step497]: loss 0.037238
[epoch10, step498]: loss 0.036898
[epoch10, step499]: loss 0.034911
[epoch10, step500]: loss 0.034717
[epoch10, step501]: loss 0.036953
[epoch10, step502]: loss 0.034884
[epoch10, step503]: loss 0.037905
[epoch10, step504]: loss 0.034429
[epoch10, step505]: loss 0.034079
[epoch10, step506]: loss 0.037817
[epoch10, step507]: loss 0.037855
[epoch10, step508]: loss 0.035144
[epoch10, step509]: loss 0.034550
[epoch10, step510]: loss 0.037833
[epoch10, step511]: loss 0.035264
[epoch10, step512]: loss 0.038049
[epoch10, step513]: loss 0.035186
[epoch10, step514]: loss 0.034763
[epoch10, step515]: loss 0.037191
[epoch10, step516]: loss 0.037241
[epoch10, step517]: loss 0.034568
[epoch10, step518]: loss 0.034775
[epoch10, step519]: loss 0.037478
[epoch10, step520]: loss 0.034246
[epoch10, step521]: loss 0.037471
[epoch10, step522]: loss 0.034487
[epoch10, step523]: loss 0.034395
[epoch10, step524]: loss 0.037459
[epoch10, step525]: loss 0.038445
[epoch10, step526]: loss 0.035067
[epoch10, step527]: loss 0.034407
[epoch10, step528]: loss 0.038221
[epoch10, step529]: loss 0.035058
[epoch10, step530]: loss 0.037369
[epoch10, step531]: loss 0.034269
[epoch10, step532]: loss 0.034864
[epoch10, step533]: loss 0.037829
[epoch10, step534]: loss 0.036859
[epoch10, step535]: loss 0.035410
[epoch10, step536]: loss 0.034735
[epoch10, step537]: loss 0.036975
[epoch10, step538]: loss 0.035193
[epoch10, step539]: loss 0.036824
[epoch10, step540]: loss 0.034044
[epoch10, step541]: loss 0.034250
[epoch10, step542]: loss 0.037362
[epoch10, step543]: loss 0.036609
[epoch10, step544]: loss 0.034795
[epoch10, step545]: loss 0.034091
[epoch10, step546]: loss 0.037452
[epoch10, step547]: loss 0.035160
[epoch10, step548]: loss 0.038964
[epoch10, step549]: loss 0.035473
[epoch10, step550]: loss 0.034604
[epoch10, step551]: loss 0.036901
[epoch10, step552]: loss 0.036094
[epoch10, step553]: loss 0.035415
[epoch10, step554]: loss 0.034191
[epoch10, step555]: loss 0.036642
[epoch10, step556]: loss 0.034463
[epoch10, step557]: loss 0.036400
[epoch10, step558]: loss 0.034683
[epoch10, step559]: loss 0.034058
[epoch10, step560]: loss 0.037194
[epoch10, step561]: loss 0.036518
[epoch10, step562]: loss 0.034800
[epoch10, step563]: loss 0.035934
[epoch10, step564]: loss 0.040214
[epoch10, step565]: loss 0.039132
[epoch10, step566]: loss 0.046242
[epoch10, step567]: loss 0.038716
[epoch10, step568]: loss 0.038617
[epoch10, step569]: loss 0.035337
[epoch10, step570]: loss 0.041988
[epoch10, step571]: loss 0.037905
[epoch10, step572]: loss 0.037163
[epoch10, step573]: loss 0.038560
[epoch10, step574]: loss 0.040013
[epoch10, step575]: loss 0.032001
[epoch10, step576]: loss 0.033484
[epoch10, step577]: loss 0.036366
[epoch10, step578]: loss 0.030048
[epoch10, step579]: loss 0.039353
[epoch10, step580]: loss 0.030544
[epoch10, step581]: loss 0.035459
[epoch10, step582]: loss 0.035163
[epoch10, step583]: loss 0.035387
[epoch10, step584]: loss 0.034374
[epoch10, step585]: loss 0.037110
[epoch10, step586]: loss 0.034490
[epoch10, step587]: loss 0.040104
[epoch10, step588]: loss 0.034847
[epoch10, step589]: loss 0.034890
[epoch10, step590]: loss 0.039187
[epoch10, step591]: loss 0.032194
[epoch10, step592]: loss 0.037728
[epoch10, step593]: loss 0.033454
[epoch10, step594]: loss 0.037886
[epoch10, step595]: loss 0.038414
[epoch10, step596]: loss 0.036905
[epoch10, step597]: loss 0.036093
[epoch10, step598]: loss 0.037754
[epoch10, step599]: loss 0.035865
[epoch10, step600]: loss 0.038580
[epoch10, step601]: loss 0.030506
[epoch10, step602]: loss 0.033904
[epoch10, step603]: loss 0.037343
[epoch10, step604]: loss 0.038251
[epoch10, step605]: loss 0.036069
[epoch10, step606]: loss 0.034838
[epoch10, step607]: loss 0.039580
[epoch10, step608]: loss 0.037144
[epoch10, step609]: loss 0.037577
[epoch10, step610]: loss 0.040067
[epoch10, step611]: loss 0.037561
[epoch10, step612]: loss 0.035274
[epoch10, step613]: loss 0.030204
[epoch10, step614]: loss 0.034915
[epoch10, step615]: loss 0.040196
[epoch10, step616]: loss 0.034203
[epoch10, step617]: loss 0.033532
[epoch10, step618]: loss 0.037695
[epoch10, step619]: loss 0.039100
[epoch10, step620]: loss 0.035543
[epoch10, step621]: loss 0.037145
[epoch10, step622]: loss 0.031702
[epoch10, step623]: loss 0.033771
[epoch10, step624]: loss 0.037559
[epoch10, step625]: loss 0.035421
[epoch10, step626]: loss 0.038799
[epoch10, step627]: loss 0.033544
[epoch10, step628]: loss 0.035666
[epoch10, step629]: loss 0.030665
[epoch10, step630]: loss 0.032747
[epoch10, step631]: loss 0.042610
[epoch10, step632]: loss 0.035518
[epoch10, step633]: loss 0.035432
[epoch10, step634]: loss 0.038004
[epoch10, step635]: loss 0.036947
[epoch10, step636]: loss 0.032499
[epoch10, step637]: loss 0.038416
[epoch10, step638]: loss 0.037891
[epoch10, step639]: loss 0.032342
[epoch10, step640]: loss 0.039810
[epoch10, step641]: loss 0.041327
[epoch10, step642]: loss 0.035384
[epoch10, step643]: loss 0.035475
[epoch10, step644]: loss 0.035859
[epoch10, step645]: loss 0.034614
[epoch10, step646]: loss 0.035530
[epoch10, step647]: loss 0.034205
[epoch10, step648]: loss 0.034879
[epoch10, step649]: loss 0.038553
[epoch10, step650]: loss 0.033168
[epoch10, step651]: loss 0.037850
[epoch10, step652]: loss 0.037760
[epoch10, step653]: loss 0.038492
[epoch10, step654]: loss 0.033983
[epoch10, step655]: loss 0.034973
[epoch10, step656]: loss 0.033013
[epoch10, step657]: loss 0.038669
[epoch10, step658]: loss 0.035647
[epoch10, step659]: loss 0.037699
[epoch10, step660]: loss 0.033271
[epoch10, step661]: loss 0.036743
[epoch10, step662]: loss 0.034096
[epoch10, step663]: loss 0.032248
[epoch10, step664]: loss 0.036503
[epoch10, step665]: loss 0.038013
[epoch10, step666]: loss 0.038029
[epoch10, step667]: loss 0.037172
[epoch10, step668]: loss 0.033750
[epoch10, step669]: loss 0.037378
[epoch10, step670]: loss 0.037925
[epoch10, step671]: loss 0.032079
[epoch10, step672]: loss 0.035128
[epoch10, step673]: loss 0.033328
[epoch10, step674]: loss 0.031855
[epoch10, step675]: loss 0.031376
[epoch10, step676]: loss 0.034136
[epoch10, step677]: loss 0.035753
[epoch10, step678]: loss 0.033211
[epoch10, step679]: loss 0.035070
[epoch10, step680]: loss 0.041930
[epoch10, step681]: loss 0.032225
[epoch10, step682]: loss 0.036732
[epoch10, step683]: loss 0.036624
[epoch10, step684]: loss 0.035494
[epoch10, step685]: loss 0.035423
[epoch10, step686]: loss 0.038174
[epoch10, step687]: loss 0.036724
[epoch10, step688]: loss 0.035434
[epoch10, step689]: loss 0.036158
[epoch10, step690]: loss 0.035727
[epoch10, step691]: loss 0.035465
[epoch10, step692]: loss 0.034842
[epoch10, step693]: loss 0.039548
[epoch10, step694]: loss 0.032539
[epoch10, step695]: loss 0.038060
[epoch10, step696]: loss 0.035621
[epoch10, step697]: loss 0.037708
[epoch10, step698]: loss 0.035161
[epoch10, step699]: loss 0.033874
[epoch10, step700]: loss 0.031415
[epoch10, step701]: loss 0.036423
[epoch10, step702]: loss 0.031841
[epoch10, step703]: loss 0.034392
[epoch10, step704]: loss 0.036141
[epoch10, step705]: loss 0.036670
[epoch10, step706]: loss 0.033951
[epoch10, step707]: loss 0.033913
[epoch10, step708]: loss 0.035369
[epoch10, step709]: loss 0.037384
[epoch10, step710]: loss 0.033406
[epoch10, step711]: loss 0.036818
[epoch10, step712]: loss 0.037283
[epoch10, step713]: loss 0.038094
[epoch10, step714]: loss 0.032115
[epoch10, step715]: loss 0.033636
[epoch10, step716]: loss 0.036100
[epoch10, step717]: loss 0.034117
[epoch10, step718]: loss 0.035870
[epoch10, step719]: loss 0.045147
[epoch10, step720]: loss 0.034790
[epoch10, step721]: loss 0.033511
[epoch10, step722]: loss 0.041557
[epoch10, step723]: loss 0.038200
[epoch10, step724]: loss 0.033078
[epoch10, step725]: loss 0.037242
[epoch10, step726]: loss 0.032428
[epoch10, step727]: loss 0.034703
[epoch10, step728]: loss 0.036975
[epoch10, step729]: loss 0.032352
[epoch10, step730]: loss 0.033057
[epoch10, step731]: loss 0.036305
[epoch10, step732]: loss 0.036614
[epoch10, step733]: loss 0.034714
[epoch10, step734]: loss 0.034306
[epoch10, step735]: loss 0.038155
[epoch10, step736]: loss 0.036818
[epoch10, step737]: loss 0.037758
[epoch10, step738]: loss 0.031123
[epoch10, step739]: loss 0.036660
[epoch10, step740]: loss 0.033660
[epoch10, step741]: loss 0.036333
[epoch10, step742]: loss 0.033332
[epoch10, step743]: loss 0.034411
[epoch10, step744]: loss 0.033812
[epoch10, step745]: loss 0.034106
[epoch10, step746]: loss 0.036578
[epoch10, step747]: loss 0.039207
[epoch10, step748]: loss 0.036607
[epoch10, step749]: loss 0.036308
[epoch10, step750]: loss 0.038943
[epoch10, step751]: loss 0.033403
[epoch10, step752]: loss 0.035407
[epoch10, step753]: loss 0.035351
[epoch10, step754]: loss 0.034026
[epoch10, step755]: loss 0.036105
[epoch10, step756]: loss 0.033919
[epoch10, step757]: loss 0.030425
[epoch10, step758]: loss 0.034285
[epoch10, step759]: loss 0.033483
[epoch10, step760]: loss 0.034813
[epoch10, step761]: loss 0.037444
[epoch10, step762]: loss 0.031594
[epoch10, step763]: loss 0.035441
[epoch10, step764]: loss 0.035018
[epoch10, step765]: loss 0.036814
[epoch10, step766]: loss 0.036243
[epoch10, step767]: loss 0.039248
[epoch10, step768]: loss 0.031291
[epoch10, step769]: loss 0.036250
[epoch10, step770]: loss 0.035154
[epoch10, step771]: loss 0.033374
[epoch10, step772]: loss 0.038457
[epoch10, step773]: loss 0.036009
[epoch10, step774]: loss 0.035104
[epoch10, step775]: loss 0.029958
[epoch10, step776]: loss 0.037420
[epoch10, step777]: loss 0.033691
[epoch10, step778]: loss 0.037400
[epoch10, step779]: loss 0.035574
[epoch10, step780]: loss 0.030167
[epoch10, step781]: loss 0.035366
[epoch10, step782]: loss 0.032410
[epoch10, step783]: loss 0.030295
[epoch10, step784]: loss 0.031083
[epoch10, step785]: loss 0.031671
[epoch10, step786]: loss 0.034277
[epoch10, step787]: loss 0.034640
[epoch10, step788]: loss 0.036131
[epoch10, step789]: loss 0.034659
[epoch10, step790]: loss 0.034311
[epoch10, step791]: loss 0.037917
[epoch10, step792]: loss 0.035611
[epoch10, step793]: loss 0.037455
[epoch10, step794]: loss 0.030754
[epoch10, step795]: loss 0.035243
[epoch10, step796]: loss 0.038300
[epoch10, step797]: loss 0.037108
[epoch10, step798]: loss 0.037716
[epoch10, step799]: loss 0.037290
[epoch10, step800]: loss 0.032082
[epoch10, step801]: loss 0.034186
[epoch10, step802]: loss 0.033585
[epoch10, step803]: loss 0.037145
[epoch10, step804]: loss 0.037657
[epoch10, step805]: loss 0.038099
[epoch10, step806]: loss 0.032434
[epoch10, step807]: loss 0.031416
[epoch10, step808]: loss 0.034291
[epoch10, step809]: loss 0.032027
[epoch10, step810]: loss 0.036323
[epoch10, step811]: loss 0.035536
[epoch10, step812]: loss 0.033981
[epoch10, step813]: loss 0.034006
[epoch10, step814]: loss 0.036637
[epoch10, step815]: loss 0.034119
[epoch10, step816]: loss 0.034701
[epoch10, step817]: loss 0.035362
[epoch10, step818]: loss 0.032650
[epoch10, step819]: loss 0.031343
[epoch10, step820]: loss 0.034202
[epoch10, step821]: loss 0.031989
[epoch10, step822]: loss 0.040038
[epoch10, step823]: loss 0.034259
[epoch10, step824]: loss 0.036780
[epoch10, step825]: loss 0.036578
[epoch10, step826]: loss 0.034868
[epoch10, step827]: loss 0.038025
[epoch10, step828]: loss 0.040063
[epoch10, step829]: loss 0.038744
[epoch10, step830]: loss 0.033587
[epoch10, step831]: loss 0.037002
[epoch10, step832]: loss 0.031639
[epoch10, step833]: loss 0.038787
[epoch10, step834]: loss 0.036911
[epoch10, step835]: loss 0.031172
[epoch10, step836]: loss 0.038942
[epoch10, step837]: loss 0.036000
[epoch10, step838]: loss 0.034881
[epoch10, step839]: loss 0.039351
[epoch10, step840]: loss 0.031426
[epoch10, step841]: loss 0.035376
[epoch10, step842]: loss 0.037038
[epoch10, step843]: loss 0.035649
[epoch10, step844]: loss 0.035918
[epoch10, step845]: loss 0.031953
[epoch10, step846]: loss 0.039450
[epoch10, step847]: loss 0.037270
[epoch10, step848]: loss 0.035525
[epoch10, step849]: loss 0.033836
[epoch10, step850]: loss 0.033936
[epoch10, step851]: loss 0.035626
[epoch10, step852]: loss 0.033222
[epoch10, step853]: loss 0.040495
[epoch10, step854]: loss 0.034097
[epoch10, step855]: loss 0.037785
[epoch10, step856]: loss 0.031842
[epoch10, step857]: loss 0.034571
[epoch10, step858]: loss 0.034911
[epoch10, step859]: loss 0.034215
[epoch10, step860]: loss 0.032775
[epoch10, step861]: loss 0.032597
[epoch10, step862]: loss 0.032762
[epoch10, step863]: loss 0.031726
[epoch10, step864]: loss 0.036891
[epoch10, step865]: loss 0.034170
[epoch10, step866]: loss 0.035442
[epoch10, step867]: loss 0.036884
[epoch10, step868]: loss 0.036853
[epoch10, step869]: loss 0.034061
[epoch10, step870]: loss 0.041418
[epoch10, step871]: loss 0.033337
[epoch10, step872]: loss 0.035989
[epoch10, step873]: loss 0.035634
[epoch10, step874]: loss 0.034662
[epoch10, step875]: loss 0.034507
[epoch10, step876]: loss 0.036793
[epoch10, step877]: loss 0.030135
[epoch10, step878]: loss 0.033517
[epoch10, step879]: loss 0.037971
[epoch10, step880]: loss 0.036318
[epoch10, step881]: loss 0.032824
[epoch10, step882]: loss 0.034218
[epoch10, step883]: loss 0.034239
[epoch10, step884]: loss 0.037097
[epoch10, step885]: loss 0.035248
[epoch10, step886]: loss 0.036053
[epoch10, step887]: loss 0.034976
[epoch10, step888]: loss 0.035727
[epoch10, step889]: loss 0.034852
[epoch10, step890]: loss 0.034240
[epoch10, step891]: loss 0.036104
[epoch10, step892]: loss 0.030679
[epoch10, step893]: loss 0.034584
[epoch10, step894]: loss 0.035900
[epoch10, step895]: loss 0.032430
[epoch10, step896]: loss 0.032912
[epoch10, step897]: loss 0.035658
[epoch10, step898]: loss 0.037043
[epoch10, step899]: loss 0.038882
[epoch10, step900]: loss 0.036428
[epoch10, step901]: loss 0.037067
[epoch10, step902]: loss 0.034402
[epoch10, step903]: loss 0.035359
[epoch10, step904]: loss 0.037610
[epoch10, step905]: loss 0.037956
[epoch10, step906]: loss 0.031813
[epoch10, step907]: loss 0.033936
[epoch10, step908]: loss 0.031736
[epoch10, step909]: loss 0.037730
[epoch10, step910]: loss 0.033854
[epoch10, step911]: loss 0.035689
[epoch10, step912]: loss 0.033443
[epoch10, step913]: loss 0.034670
[epoch10, step914]: loss 0.039924
[epoch10, step915]: loss 0.034276
[epoch10, step916]: loss 0.033707
[epoch10, step917]: loss 0.035631
[epoch10, step918]: loss 0.039769
[epoch10, step919]: loss 0.035124
[epoch10, step920]: loss 0.038124
[epoch10, step921]: loss 0.034154
[epoch10, step922]: loss 0.034500
[epoch10, step923]: loss 0.033338
[epoch10, step924]: loss 0.030204
[epoch10, step925]: loss 0.035976
[epoch10, step926]: loss 0.034815
[epoch10, step927]: loss 0.035403
[epoch10, step928]: loss 0.035283
[epoch10, step929]: loss 0.038429
[epoch10, step930]: loss 0.037012
[epoch10, step931]: loss 0.037523
[epoch10, step932]: loss 0.032241
[epoch10, step933]: loss 0.039426
[epoch10, step934]: loss 0.032673
[epoch10, step935]: loss 0.033750
[epoch10, step936]: loss 0.032540
[epoch10, step937]: loss 0.036359
[epoch10, step938]: loss 0.038518
[epoch10, step939]: loss 0.031370
[epoch10, step940]: loss 0.034155
[epoch10, step941]: loss 0.038223
[epoch10, step942]: loss 0.036144
[epoch10, step943]: loss 0.033795
[epoch10, step944]: loss 0.038367
[epoch10, step945]: loss 0.031402
[epoch10, step946]: loss 0.035356
[epoch10, step947]: loss 0.039247
[epoch10, step948]: loss 0.030174
[epoch10, step949]: loss 0.033741
[epoch10, step950]: loss 0.038106
[epoch10, step951]: loss 0.039579
[epoch10, step952]: loss 0.034833
[epoch10, step953]: loss 0.037410
[epoch10, step954]: loss 0.033207
[epoch10, step955]: loss 0.041876
[epoch10, step956]: loss 0.050665
[epoch10, step957]: loss 0.047322
[epoch10, step958]: loss 0.046517
[epoch10, step959]: loss 0.049892
[epoch10, step960]: loss 0.046668
[epoch10, step961]: loss 0.046911
[epoch10, step962]: loss 0.046379
[epoch10, step963]: loss 0.044784
[epoch10, step964]: loss 0.045537
[epoch10, step965]: loss 0.046896
[epoch10, step966]: loss 0.045246
[epoch10, step967]: loss 0.044452
[epoch10, step968]: loss 0.045548
[epoch10, step969]: loss 0.045377
[epoch10, step970]: loss 0.044554
[epoch10, step971]: loss 0.044329
[epoch10, step972]: loss 0.045029
[epoch10, step973]: loss 0.044960
[epoch10, step974]: loss 0.045997
[epoch10, step975]: loss 0.043426
[epoch10, step976]: loss 0.042402
[epoch10, step977]: loss 0.045638
[epoch10, step978]: loss 0.044522
[epoch10, step979]: loss 0.043079
[epoch10, step980]: loss 0.042917
[epoch10, step981]: loss 0.044012
[epoch10, step982]: loss 0.044132
[epoch10, step983]: loss 0.043990
[epoch10, step984]: loss 0.042498
[epoch10, step985]: loss 0.042577
[epoch10, step986]: loss 0.044192
[epoch10, step987]: loss 0.043386
[epoch10, step988]: loss 0.043414
[epoch10, step989]: loss 0.042998
[epoch10, step990]: loss 0.042622
[epoch10, step991]: loss 0.043176
[epoch10, step992]: loss 0.043928
[epoch10, step993]: loss 0.042636
[epoch10, step994]: loss 0.041413
[epoch10, step995]: loss 0.044020
[epoch10, step996]: loss 0.043449
[epoch10, step997]: loss 0.042730
[epoch10, step998]: loss 0.043193
[epoch10, step999]: loss 0.042875
[epoch10, step1000]: loss 0.042917
[epoch10, step1001]: loss 0.043154
[epoch10, step1002]: loss 0.042112
[epoch10, step1003]: loss 0.041898
[epoch10, step1004]: loss 0.043994
[epoch10, step1005]: loss 0.042505
[epoch10, step1006]: loss 0.042151
[epoch10, step1007]: loss 0.041665
[epoch10, step1008]: loss 0.042485
[epoch10, step1009]: loss 0.042670
[epoch10, step1010]: loss 0.043591
[epoch10, step1011]: loss 0.042108
[epoch10, step1012]: loss 0.041562
[epoch10, step1013]: loss 0.043156
[epoch10, step1014]: loss 0.042820
[epoch10, step1015]: loss 0.042798
[epoch10, step1016]: loss 0.042032
[epoch10, step1017]: loss 0.042406
[epoch10, step1018]: loss 0.042348
[epoch10, step1019]: loss 0.043996
[epoch10, step1020]: loss 0.042163
[epoch10, step1021]: loss 0.041342
[epoch10, step1022]: loss 0.043251
[epoch10, step1023]: loss 0.042641
[epoch10, step1024]: loss 0.043328
[epoch10, step1025]: loss 0.041410
[epoch10, step1026]: loss 0.041822
[epoch10, step1027]: loss 0.042750
[epoch10, step1028]: loss 0.042975
[epoch10, step1029]: loss 0.042063
[epoch10, step1030]: loss 0.040763
[epoch10, step1031]: loss 0.042915
[epoch10, step1032]: loss 0.042603
[epoch10, step1033]: loss 0.042034
[epoch10, step1034]: loss 0.041472
[epoch10, step1035]: loss 0.042111
[epoch10, step1036]: loss 0.042513
[epoch10, step1037]: loss 0.042782
[epoch10, step1038]: loss 0.041720
[epoch10, step1039]: loss 0.041373
[epoch10, step1040]: loss 0.043127
[epoch10, step1041]: loss 0.042287
[epoch10, step1042]: loss 0.042431
[epoch10, step1043]: loss 0.042177
[epoch10, step1044]: loss 0.042712
[epoch10, step1045]: loss 0.042766
[epoch10, step1046]: loss 0.043210
[epoch10, step1047]: loss 0.041933
[epoch10, step1048]: loss 0.041969
[epoch10, step1049]: loss 0.043878
[epoch10, step1050]: loss 0.042864
[epoch10, step1051]: loss 0.042217
[epoch10, step1052]: loss 0.042060
[epoch10, step1053]: loss 0.042832
[epoch10, step1054]: loss 0.042574
[epoch10, step1055]: loss 0.043223
[epoch10, step1056]: loss 0.040819
[epoch10, step1057]: loss 0.041539
[epoch10, step1058]: loss 0.043893
[epoch10, step1059]: loss 0.043068
[epoch10, step1060]: loss 0.042344
[epoch10, step1061]: loss 0.041397
[epoch10, step1062]: loss 0.043290
[epoch10, step1063]: loss 0.042663
[epoch10, step1064]: loss 0.043198
[epoch10, step1065]: loss 0.041710
[epoch10, step1066]: loss 0.041083
[epoch10, step1067]: loss 0.043483
[epoch10, step1068]: loss 0.041544
[epoch10, step1069]: loss 0.041771
[epoch10, step1070]: loss 0.041419
[epoch10, step1071]: loss 0.042631
[epoch10, step1072]: loss 0.042607
[epoch10, step1073]: loss 0.042969
[epoch10, step1074]: loss 0.041496
[epoch10, step1075]: loss 0.040975
[epoch10, step1076]: loss 0.042974
[epoch10, step1077]: loss 0.042295
[epoch10, step1078]: loss 0.042767
[epoch10, step1079]: loss 0.042513
[epoch10, step1080]: loss 0.042442
[epoch10, step1081]: loss 0.041818
[epoch10, step1082]: loss 0.043232
[epoch10, step1083]: loss 0.042294
[epoch10, step1084]: loss 0.040672
[epoch10, step1085]: loss 0.042149
[epoch10, step1086]: loss 0.041685
[epoch10, step1087]: loss 0.042006
[epoch10, step1088]: loss 0.041454
[epoch10, step1089]: loss 0.042429
[epoch10, step1090]: loss 0.042401
[epoch10, step1091]: loss 0.043277
[epoch10, step1092]: loss 0.041303
[epoch10, step1093]: loss 0.040859
[epoch10, step1094]: loss 0.042708
[epoch10, step1095]: loss 0.041746
[epoch10, step1096]: loss 0.041574
[epoch10, step1097]: loss 0.041763
[epoch10, step1098]: loss 0.041788
[epoch10, step1099]: loss 0.042409
[epoch10, step1100]: loss 0.043684
[epoch10, step1101]: loss 0.041618
[epoch10, step1102]: loss 0.040658
[epoch10, step1103]: loss 0.042712
[epoch10, step1104]: loss 0.041928
[epoch10, step1105]: loss 0.042689
[epoch10, step1106]: loss 0.041134
[epoch10, step1107]: loss 0.041694
[epoch10, step1108]: loss 0.041167
[epoch10, step1109]: loss 0.042698
[epoch10, step1110]: loss 0.042064
[epoch10, step1111]: loss 0.041034
[epoch10, step1112]: loss 0.042885
[epoch10, step1113]: loss 0.041894
[epoch10, step1114]: loss 0.041914
[epoch10, step1115]: loss 0.041731
[epoch10, step1116]: loss 0.041767
[epoch10, step1117]: loss 0.041771
[epoch10, step1118]: loss 0.042827
[epoch10, step1119]: loss 0.041862
[epoch10, step1120]: loss 0.041257
[epoch10, step1121]: loss 0.042831
[epoch10, step1122]: loss 0.043472
[epoch10, step1123]: loss 0.042144
[epoch10, step1124]: loss 0.042319
[epoch10, step1125]: loss 0.042100
[epoch10, step1126]: loss 0.042636
[epoch10, step1127]: loss 0.042774
[epoch10, step1128]: loss 0.041933
[epoch10, step1129]: loss 0.040887
[epoch10, step1130]: loss 0.043104
[epoch10, step1131]: loss 0.043020
[epoch10, step1132]: loss 0.042037
[epoch10, step1133]: loss 0.040499
[epoch10, step1134]: loss 0.042107
[epoch10, step1135]: loss 0.043446
[epoch10, step1136]: loss 0.043756
[epoch10, step1137]: loss 0.041702
[epoch10, step1138]: loss 0.041744
[epoch10, step1139]: loss 0.043394
[epoch10, step1140]: loss 0.042404
[epoch10, step1141]: loss 0.042590
[epoch10, step1142]: loss 0.042315
[epoch10, step1143]: loss 0.041998
[epoch10, step1144]: loss 0.041838
[epoch10, step1145]: loss 0.042662
[epoch10, step1146]: loss 0.041725
[epoch10, step1147]: loss 0.041514
[epoch10, step1148]: loss 0.043549
[epoch10, step1149]: loss 0.042180
[epoch10, step1150]: loss 0.041886
[epoch10, step1151]: loss 0.041757
[epoch10, step1152]: loss 0.042704
[epoch10, step1153]: loss 0.041869
[epoch10, step1154]: loss 0.042934
[epoch10, step1155]: loss 0.042452
[epoch10, step1156]: loss 0.041350
[epoch10, step1157]: loss 0.043052
[epoch10, step1158]: loss 0.042179
[epoch10, step1159]: loss 0.042253
[epoch10, step1160]: loss 0.041938
[epoch10, step1161]: loss 0.042933
[epoch10, step1162]: loss 0.042311
[epoch10, step1163]: loss 0.041857
[epoch10, step1164]: loss 0.041096
[epoch10, step1165]: loss 0.041269
[epoch10, step1166]: loss 0.042705
[epoch10, step1167]: loss 0.041991
[epoch10, step1168]: loss 0.041697
[epoch10, step1169]: loss 0.041069
[epoch10, step1170]: loss 0.041788
[epoch10, step1171]: loss 0.041510
[epoch10, step1172]: loss 0.043507
[epoch10, step1173]: loss 0.042048
[epoch10, step1174]: loss 0.041585
[epoch10, step1175]: loss 0.041744
[epoch10, step1176]: loss 0.042230
[epoch10, step1177]: loss 0.042341
[epoch10, step1178]: loss 0.041147
[epoch10, step1179]: loss 0.041656
[epoch10, step1180]: loss 0.041917
[epoch10, step1181]: loss 0.043579
[epoch10, step1182]: loss 0.041756
[epoch10, step1183]: loss 0.040927
[epoch10, step1184]: loss 0.042284
[epoch10, step1185]: loss 0.041996
[epoch10, step1186]: loss 0.042289
[epoch10, step1187]: loss 0.040261
[epoch10, step1188]: loss 0.041658
[epoch10, step1189]: loss 0.042502
[epoch10, step1190]: loss 0.042178
[epoch10, step1191]: loss 0.041981
[epoch10, step1192]: loss 0.040710
[epoch10, step1193]: loss 0.042881
[epoch10, step1194]: loss 0.043126
[epoch10, step1195]: loss 0.041122
[epoch10, step1196]: loss 0.040940
[epoch10, step1197]: loss 0.042275
[epoch10, step1198]: loss 0.041640
[epoch10, step1199]: loss 0.042656
[epoch10, step1200]: loss 0.041930
[epoch10, step1201]: loss 0.040685
[epoch10, step1202]: loss 0.043428
[epoch10, step1203]: loss 0.042205
[epoch10, step1204]: loss 0.041939
[epoch10, step1205]: loss 0.040770
[epoch10, step1206]: loss 0.040951
[epoch10, step1207]: loss 0.042256
[epoch10, step1208]: loss 0.042673
[epoch10, step1209]: loss 0.041154
[epoch10, step1210]: loss 0.040792
[epoch10, step1211]: loss 0.043001
[epoch10, step1212]: loss 0.042157
[epoch10, step1213]: loss 0.041405
[epoch10, step1214]: loss 0.041389
[epoch10, step1215]: loss 0.042588
[epoch10, step1216]: loss 0.042310
[epoch10, step1217]: loss 0.043053
[epoch10, step1218]: loss 0.041263
[epoch10, step1219]: loss 0.041485
[epoch10, step1220]: loss 0.043676
[epoch10, step1221]: loss 0.041500
[epoch10, step1222]: loss 0.041579
[epoch10, step1223]: loss 0.040850
[epoch10, step1224]: loss 0.041845
[epoch10, step1225]: loss 0.042014
[epoch10, step1226]: loss 0.042638
[epoch10, step1227]: loss 0.041730
[epoch10, step1228]: loss 0.040492
[epoch10, step1229]: loss 0.042975
[epoch10, step1230]: loss 0.042386
[epoch10, step1231]: loss 0.041413
[epoch10, step1232]: loss 0.042580
[epoch10, step1233]: loss 0.042567
[epoch10, step1234]: loss 0.041712
[epoch10, step1235]: loss 0.043208
[epoch10, step1236]: loss 0.042011
[epoch10, step1237]: loss 0.040870
[epoch10, step1238]: loss 0.041881
[epoch10, step1239]: loss 0.042624
[epoch10, step1240]: loss 0.042286
[epoch10, step1241]: loss 0.040333
[epoch10, step1242]: loss 0.041530
[epoch10, step1243]: loss 0.042481
[epoch10, step1244]: loss 0.042364
[epoch10, step1245]: loss 0.041448
[epoch10, step1246]: loss 0.040562
[epoch10, step1247]: loss 0.042563
[epoch10, step1248]: loss 0.041535
[epoch10, step1249]: loss 0.041756
[epoch10, step1250]: loss 0.040606
[epoch10, step1251]: loss 0.041134
[epoch10, step1252]: loss 0.043462
[epoch10, step1253]: loss 0.042498
[epoch10, step1254]: loss 0.041497
[epoch10, step1255]: loss 0.041941
[epoch10, step1256]: loss 0.043019
[epoch10, step1257]: loss 0.041834
[epoch10, step1258]: loss 0.042144
[epoch10, step1259]: loss 0.041104
[epoch10, step1260]: loss 0.041638
[epoch10, step1261]: loss 0.042041
[epoch10, step1262]: loss 0.041552
[epoch10, step1263]: loss 0.041707
[epoch10, step1264]: loss 0.042147
[epoch10, step1265]: loss 0.041571
[epoch10, step1266]: loss 0.041585
[epoch10, step1267]: loss 0.041437
[epoch10, step1268]: loss 0.040906
[epoch10, step1269]: loss 0.041920
[epoch10, step1270]: loss 0.041590
[epoch10, step1271]: loss 0.042420
[epoch10, step1272]: loss 0.041367
[epoch10, step1273]: loss 0.040421
[epoch10, step1274]: loss 0.042573
[epoch10, step1275]: loss 0.041555
[epoch10, step1276]: loss 0.041810
[epoch10, step1277]: loss 0.041271
[epoch10, step1278]: loss 0.041418
[epoch10, step1279]: loss 0.041948
[epoch10, step1280]: loss 0.043841
[epoch10, step1281]: loss 0.041425
[epoch10, step1282]: loss 0.041459
[epoch10, step1283]: loss 0.042779
[epoch10, step1284]: loss 0.041884
[epoch10, step1285]: loss 0.041933
[epoch10, step1286]: loss 0.040617
[epoch10, step1287]: loss 0.042375
[epoch10, step1288]: loss 0.042250
[epoch10, step1289]: loss 0.042723
[epoch10, step1290]: loss 0.041421
[epoch10, step1291]: loss 0.040622
[epoch10, step1292]: loss 0.042734
[epoch10, step1293]: loss 0.041132
[epoch10, step1294]: loss 0.041277
[epoch10, step1295]: loss 0.041359
[epoch10, step1296]: loss 0.041739
[epoch10, step1297]: loss 0.041857
[epoch10, step1298]: loss 0.042554
[epoch10, step1299]: loss 0.042275
[epoch10, step1300]: loss 0.042206
[epoch10, step1301]: loss 0.042141
[epoch10, step1302]: loss 0.042460
[epoch10, step1303]: loss 0.041523
[epoch10, step1304]: loss 0.040536
[epoch10, step1305]: loss 0.041810
[epoch10, step1306]: loss 0.041708
[epoch10, step1307]: loss 0.043487
[epoch10, step1308]: loss 0.042486
[epoch10, step1309]: loss 0.040624
[epoch10, step1310]: loss 0.042962
[epoch10, step1311]: loss 0.041605
[epoch10, step1312]: loss 0.041359
[epoch10, step1313]: loss 0.040578
[epoch10, step1314]: loss 0.042323
[epoch10, step1315]: loss 0.041750
[epoch10, step1316]: loss 0.042878
[epoch10, step1317]: loss 0.040802
[epoch10, step1318]: loss 0.040234
[epoch10, step1319]: loss 0.042308
[epoch10, step1320]: loss 0.042059
[epoch10, step1321]: loss 0.041607
[epoch10, step1322]: loss 0.040813
[epoch10, step1323]: loss 0.042218
[epoch10, step1324]: loss 0.041937
[epoch10, step1325]: loss 0.042054
[epoch10, step1326]: loss 0.040939
[epoch10, step1327]: loss 0.041203
[epoch10, step1328]: loss 0.043640
[epoch10, step1329]: loss 0.042438
[epoch10, step1330]: loss 0.041086
[epoch10, step1331]: loss 0.041029
[epoch10, step1332]: loss 0.041279
[epoch10, step1333]: loss 0.041805
[epoch10, step1334]: loss 0.042659
[epoch10, step1335]: loss 0.041445
[epoch10, step1336]: loss 0.040544
[epoch10, step1337]: loss 0.042665
[epoch10, step1338]: loss 0.041254
[epoch10, step1339]: loss 0.041651
[epoch10, step1340]: loss 0.040415
[epoch10, step1341]: loss 0.041643
[epoch10, step1342]: loss 0.041821
[epoch10, step1343]: loss 0.042116
[epoch10, step1344]: loss 0.041365
[epoch10, step1345]: loss 0.040735
[epoch10, step1346]: loss 0.042754
[epoch10, step1347]: loss 0.041767
[epoch10, step1348]: loss 0.041639
[epoch10, step1349]: loss 0.041789
[epoch10, step1350]: loss 0.042534
[epoch10, step1351]: loss 0.041328
[epoch10, step1352]: loss 0.042613
[epoch10, step1353]: loss 0.042076
[epoch10, step1354]: loss 0.040354
[epoch10, step1355]: loss 0.042241
[epoch10, step1356]: loss 0.041793
[epoch10, step1357]: loss 0.040996
[epoch10, step1358]: loss 0.040796
[epoch10, step1359]: loss 0.041248
[epoch10, step1360]: loss 0.041606
[epoch10, step1361]: loss 0.042777
[epoch10, step1362]: loss 0.041512
[epoch10, step1363]: loss 0.040109
[epoch10, step1364]: loss 0.042312
[epoch10, step1365]: loss 0.041570
[epoch10, step1366]: loss 0.041282
[epoch10, step1367]: loss 0.040934
[epoch10, step1368]: loss 0.041542
[epoch10, step1369]: loss 0.042237
[epoch10, step1370]: loss 0.042777
[epoch10, step1371]: loss 0.040627
[epoch10, step1372]: loss 0.040848
[epoch10, step1373]: loss 0.042693
[epoch10, step1374]: loss 0.042649
[epoch10, step1375]: loss 0.042527
[epoch10, step1376]: loss 0.041187
[epoch10, step1377]: loss 0.041197
[epoch10, step1378]: loss 0.042660
[epoch10, step1379]: loss 0.042343
[epoch10, step1380]: loss 0.042184
[epoch10, step1381]: loss 0.040576
[epoch10, step1382]: loss 0.043239
[epoch10, step1383]: loss 0.041573
[epoch10, step1384]: loss 0.041334
[epoch10, step1385]: loss 0.041074
[epoch10, step1386]: loss 0.042975
[epoch10, step1387]: loss 0.042919
[epoch10, step1388]: loss 0.041934
[epoch10, step1389]: loss 0.040723
[epoch10, step1390]: loss 0.040612
[epoch10, step1391]: loss 0.042484
[epoch10, step1392]: loss 0.042110
[epoch10, step1393]: loss 0.041209
[epoch10, step1394]: loss 0.041126
[epoch10, step1395]: loss 0.041656
[epoch10, step1396]: loss 0.041278
[epoch10, step1397]: loss 0.041882
[epoch10, step1398]: loss 0.040792
[epoch10, step1399]: loss 0.040973
[epoch10, step1400]: loss 0.043447
[epoch10, step1401]: loss 0.042317
[epoch10, step1402]: loss 0.041423
[epoch10, step1403]: loss 0.040788
[epoch10, step1404]: loss 0.041519
[epoch10, step1405]: loss 0.042569
[epoch10, step1406]: loss 0.042859
[epoch10, step1407]: loss 0.042070
[epoch10, step1408]: loss 0.040626
[epoch10, step1409]: loss 0.042622
[epoch10, step1410]: loss 0.041462
[epoch10, step1411]: loss 0.041287
[epoch10, step1412]: loss 0.040807
[epoch10, step1413]: loss 0.040887
[epoch10, step1414]: loss 0.042256
[epoch10, step1415]: loss 0.041880
[epoch10, step1416]: loss 0.041066
[epoch10, step1417]: loss 0.040043
[epoch10, step1418]: loss 0.041929
[epoch10, step1419]: loss 0.042180
[epoch10, step1420]: loss 0.041429
[epoch10, step1421]: loss 0.040852
[epoch10, step1422]: loss 0.041416
[epoch10, step1423]: loss 0.042220
[epoch10, step1424]: loss 0.043454
[epoch10, step1425]: loss 0.040853
[epoch10, step1426]: loss 0.041244
[epoch10, step1427]: loss 0.042439
[epoch10, step1428]: loss 0.042125
[epoch10, step1429]: loss 0.043375
[epoch10, step1430]: loss 0.041330
[epoch10, step1431]: loss 0.041576
[epoch10, step1432]: loss 0.042329
[epoch10, step1433]: loss 0.042852
[epoch10, step1434]: loss 0.040369
[epoch10, step1435]: loss 0.040406
[epoch10, step1436]: loss 0.042902
[epoch10, step1437]: loss 0.041528
[epoch10, step1438]: loss 0.041371
[epoch10, step1439]: loss 0.040440
[epoch10, step1440]: loss 0.041101
[epoch10, step1441]: loss 0.042434
[epoch10, step1442]: loss 0.041871
[epoch10, step1443]: loss 0.040864
[epoch10, step1444]: loss 0.040428
[epoch10, step1445]: loss 0.043588
[epoch10, step1446]: loss 0.041649
[epoch10, step1447]: loss 0.041371
[epoch10, step1448]: loss 0.041286
[epoch10, step1449]: loss 0.041178
[epoch10, step1450]: loss 0.041646
[epoch10, step1451]: loss 0.043402
[epoch10, step1452]: loss 0.041343
[epoch10, step1453]: loss 0.041503
[epoch10, step1454]: loss 0.042768
[epoch10, step1455]: loss 0.041834
[epoch10, step1456]: loss 0.041603
[epoch10, step1457]: loss 0.040512
[epoch10, step1458]: loss 0.041380
[epoch10, step1459]: loss 0.041134
[epoch10, step1460]: loss 0.042966
[epoch10, step1461]: loss 0.041265
[epoch10, step1462]: loss 0.041009
[epoch10, step1463]: loss 0.041724
[epoch10, step1464]: loss 0.041336
[epoch10, step1465]: loss 0.041296
[epoch10, step1466]: loss 0.040808
[epoch10, step1467]: loss 0.042108
[epoch10, step1468]: loss 0.040976
[epoch10, step1469]: loss 0.042556
[epoch10, step1470]: loss 0.040966
[epoch10, step1471]: loss 0.040142
[epoch10, step1472]: loss 0.041638
[epoch10, step1473]: loss 0.041670
[epoch10, step1474]: loss 0.042534
[epoch10, step1475]: loss 0.039886
[epoch10, step1476]: loss 0.041820
[epoch10, step1477]: loss 0.041315
[epoch10, step1478]: loss 0.042327
[epoch10, step1479]: loss 0.041041
[epoch10, step1480]: loss 0.040358
[epoch10, step1481]: loss 0.041498
[epoch10, step1482]: loss 0.041757
[epoch10, step1483]: loss 0.041609
[epoch10, step1484]: loss 0.041132
[epoch10, step1485]: loss 0.041418
[epoch10, step1486]: loss 0.041116
[epoch10, step1487]: loss 0.042965
[epoch10, step1488]: loss 0.041803
[epoch10, step1489]: loss 0.040582
[epoch10, step1490]: loss 0.043318
[epoch10, step1491]: loss 0.041190
[epoch10, step1492]: loss 0.041244
[epoch10, step1493]: loss 0.040475
[epoch10, step1494]: loss 0.040923
[epoch10, step1495]: loss 0.041513
[epoch10, step1496]: loss 0.041821
[epoch10, step1497]: loss 0.041552
[epoch10, step1498]: loss 0.040374
[epoch10, step1499]: loss 0.043624
[epoch10, step1500]: loss 0.041791
[epoch10, step1501]: loss 0.041601
[epoch10, step1502]: loss 0.041071
[epoch10, step1503]: loss 0.041552
[epoch10, step1504]: loss 0.041100
[epoch10, step1505]: loss 0.042833
[epoch10, step1506]: loss 0.040762
[epoch10, step1507]: loss 0.040952
[epoch10, step1508]: loss 0.043071
[epoch10, step1509]: loss 0.042732
[epoch10, step1510]: loss 0.042471
[epoch10, step1511]: loss 0.040926
[epoch10, step1512]: loss 0.042129
[epoch10, step1513]: loss 0.040875
[epoch10, step1514]: loss 0.042191
[epoch10, step1515]: loss 0.040931
[epoch10, step1516]: loss 0.039900

[epoch10]: avg loss 0.038158

[epoch11, step1]: loss 0.042194
[epoch11, step2]: loss 0.039222
[epoch11, step3]: loss 0.038541
[epoch11, step4]: loss 0.035685
[epoch11, step5]: loss 0.035587
[epoch11, step6]: loss 0.037887
[epoch11, step7]: loss 0.035835
[epoch11, step8]: loss 0.037447
[epoch11, step9]: loss 0.034459
[epoch11, step10]: loss 0.036365
[epoch11, step11]: loss 0.038524
[epoch11, step12]: loss 0.037953
[epoch11, step13]: loss 0.035491
[epoch11, step14]: loss 0.035100
[epoch11, step15]: loss 0.037146
[epoch11, step16]: loss 0.035627
[epoch11, step17]: loss 0.037311
[epoch11, step18]: loss 0.034999
[epoch11, step19]: loss 0.035006
[epoch11, step20]: loss 0.038573
[epoch11, step21]: loss 0.036903
[epoch11, step22]: loss 0.034646
[epoch11, step23]: loss 0.033953
[epoch11, step24]: loss 0.036786
[epoch11, step25]: loss 0.034581
[epoch11, step26]: loss 0.036694
[epoch11, step27]: loss 0.033950
[epoch11, step28]: loss 0.035244
[epoch11, step29]: loss 0.037226
[epoch11, step30]: loss 0.037227
[epoch11, step31]: loss 0.034212
[epoch11, step32]: loss 0.034979
[epoch11, step33]: loss 0.037370
[epoch11, step34]: loss 0.035130
[epoch11, step35]: loss 0.037836
[epoch11, step36]: loss 0.033788
[epoch11, step37]: loss 0.034758
[epoch11, step38]: loss 0.037157
[epoch11, step39]: loss 0.036751
[epoch11, step40]: loss 0.034616
[epoch11, step41]: loss 0.033912
[epoch11, step42]: loss 0.037029
[epoch11, step43]: loss 0.034600
[epoch11, step44]: loss 0.037959
[epoch11, step45]: loss 0.034412
[epoch11, step46]: loss 0.034801
[epoch11, step47]: loss 0.036691
[epoch11, step48]: loss 0.036781
[epoch11, step49]: loss 0.032952
[epoch11, step50]: loss 0.034390
[epoch11, step51]: loss 0.036892
[epoch11, step52]: loss 0.034805
[epoch11, step53]: loss 0.037500
[epoch11, step54]: loss 0.033526
[epoch11, step55]: loss 0.035181
[epoch11, step56]: loss 0.037748
[epoch11, step57]: loss 0.036670
[epoch11, step58]: loss 0.034432
[epoch11, step59]: loss 0.033114
[epoch11, step60]: loss 0.037450
[epoch11, step61]: loss 0.033788
[epoch11, step62]: loss 0.036122
[epoch11, step63]: loss 0.033536
[epoch11, step64]: loss 0.034150
[epoch11, step65]: loss 0.036961
[epoch11, step66]: loss 0.036994
[epoch11, step67]: loss 0.034634
[epoch11, step68]: loss 0.034311
[epoch11, step69]: loss 0.036604
[epoch11, step70]: loss 0.034758
[epoch11, step71]: loss 0.037100
[epoch11, step72]: loss 0.034346
[epoch11, step73]: loss 0.034800
[epoch11, step74]: loss 0.036429
[epoch11, step75]: loss 0.036949
[epoch11, step76]: loss 0.035119
[epoch11, step77]: loss 0.035127
[epoch11, step78]: loss 0.037390
[epoch11, step79]: loss 0.034474
[epoch11, step80]: loss 0.038089
[epoch11, step81]: loss 0.034602
[epoch11, step82]: loss 0.034796
[epoch11, step83]: loss 0.036559
[epoch11, step84]: loss 0.037129
[epoch11, step85]: loss 0.035413
[epoch11, step86]: loss 0.034982
[epoch11, step87]: loss 0.038082
[epoch11, step88]: loss 0.034090
[epoch11, step89]: loss 0.036771
[epoch11, step90]: loss 0.034697
[epoch11, step91]: loss 0.034009
[epoch11, step92]: loss 0.037035
[epoch11, step93]: loss 0.036610
[epoch11, step94]: loss 0.033889
[epoch11, step95]: loss 0.034637
[epoch11, step96]: loss 0.036493
[epoch11, step97]: loss 0.035403
[epoch11, step98]: loss 0.037041
[epoch11, step99]: loss 0.034631
[epoch11, step100]: loss 0.033962
[epoch11, step101]: loss 0.037967
[epoch11, step102]: loss 0.037067
[epoch11, step103]: loss 0.035476
[epoch11, step104]: loss 0.034739
[epoch11, step105]: loss 0.037105
[epoch11, step106]: loss 0.035130
[epoch11, step107]: loss 0.037590
[epoch11, step108]: loss 0.034841
[epoch11, step109]: loss 0.034202
[epoch11, step110]: loss 0.038095
[epoch11, step111]: loss 0.036786
[epoch11, step112]: loss 0.034377
[epoch11, step113]: loss 0.035671
[epoch11, step114]: loss 0.037193
[epoch11, step115]: loss 0.034469
[epoch11, step116]: loss 0.038141
[epoch11, step117]: loss 0.033831
[epoch11, step118]: loss 0.035525
[epoch11, step119]: loss 0.037326
[epoch11, step120]: loss 0.037252
[epoch11, step121]: loss 0.034145
[epoch11, step122]: loss 0.034175
[epoch11, step123]: loss 0.037582
[epoch11, step124]: loss 0.034719
[epoch11, step125]: loss 0.037563
[epoch11, step126]: loss 0.034234
[epoch11, step127]: loss 0.034126
[epoch11, step128]: loss 0.036851
[epoch11, step129]: loss 0.036323
[epoch11, step130]: loss 0.034633
[epoch11, step131]: loss 0.033908
[epoch11, step132]: loss 0.036804
[epoch11, step133]: loss 0.034720
[epoch11, step134]: loss 0.036249
[epoch11, step135]: loss 0.034891
[epoch11, step136]: loss 0.035967
[epoch11, step137]: loss 0.036812
[epoch11, step138]: loss 0.037223
[epoch11, step139]: loss 0.034379
[epoch11, step140]: loss 0.034586
[epoch11, step141]: loss 0.037309
[epoch11, step142]: loss 0.034589
[epoch11, step143]: loss 0.036503
[epoch11, step144]: loss 0.034682
[epoch11, step145]: loss 0.034788
[epoch11, step146]: loss 0.037338
[epoch11, step147]: loss 0.037480
[epoch11, step148]: loss 0.034175
[epoch11, step149]: loss 0.033875
[epoch11, step150]: loss 0.036820
[epoch11, step151]: loss 0.034721
[epoch11, step152]: loss 0.036426
[epoch11, step153]: loss 0.034252
[epoch11, step154]: loss 0.034502
[epoch11, step155]: loss 0.036957
[epoch11, step156]: loss 0.036470
[epoch11, step157]: loss 0.034597
[epoch11, step158]: loss 0.034751
[epoch11, step159]: loss 0.036971
[epoch11, step160]: loss 0.034802
[epoch11, step161]: loss 0.037358
[epoch11, step162]: loss 0.034504
[epoch11, step163]: loss 0.034641
[epoch11, step164]: loss 0.036963
[epoch11, step165]: loss 0.036407
[epoch11, step166]: loss 0.035048
[epoch11, step167]: loss 0.033881
[epoch11, step168]: loss 0.037498
[epoch11, step169]: loss 0.034476
[epoch11, step170]: loss 0.036773
[epoch11, step171]: loss 0.035024
[epoch11, step172]: loss 0.034855
[epoch11, step173]: loss 0.037345
[epoch11, step174]: loss 0.036905
[epoch11, step175]: loss 0.035395
[epoch11, step176]: loss 0.034826
[epoch11, step177]: loss 0.037501
[epoch11, step178]: loss 0.034649
[epoch11, step179]: loss 0.036375
[epoch11, step180]: loss 0.034587
[epoch11, step181]: loss 0.034548
[epoch11, step182]: loss 0.037268
[epoch11, step183]: loss 0.036974
[epoch11, step184]: loss 0.035457
[epoch11, step185]: loss 0.034267
[epoch11, step186]: loss 0.036819
[epoch11, step187]: loss 0.034712
[epoch11, step188]: loss 0.036502
[epoch11, step189]: loss 0.034511
[epoch11, step190]: loss 0.033850
[epoch11, step191]: loss 0.037182
[epoch11, step192]: loss 0.037000
[epoch11, step193]: loss 0.032524
[epoch11, step194]: loss 0.033410
[epoch11, step195]: loss 0.036793
[epoch11, step196]: loss 0.034767
[epoch11, step197]: loss 0.036630
[epoch11, step198]: loss 0.033491
[epoch11, step199]: loss 0.034468
[epoch11, step200]: loss 0.037814
[epoch11, step201]: loss 0.038183
[epoch11, step202]: loss 0.034367
[epoch11, step203]: loss 0.034544
[epoch11, step204]: loss 0.038178
[epoch11, step205]: loss 0.034396
[epoch11, step206]: loss 0.036792
[epoch11, step207]: loss 0.034232
[epoch11, step208]: loss 0.034471
[epoch11, step209]: loss 0.037377
[epoch11, step210]: loss 0.037238
[epoch11, step211]: loss 0.034566
[epoch11, step212]: loss 0.035121
[epoch11, step213]: loss 0.036893
[epoch11, step214]: loss 0.034162
[epoch11, step215]: loss 0.037243
[epoch11, step216]: loss 0.034294
[epoch11, step217]: loss 0.033985
[epoch11, step218]: loss 0.037705
[epoch11, step219]: loss 0.036461
[epoch11, step220]: loss 0.034685
[epoch11, step221]: loss 0.034604
[epoch11, step222]: loss 0.037454
[epoch11, step223]: loss 0.035469
[epoch11, step224]: loss 0.036916
[epoch11, step225]: loss 0.034907
[epoch11, step226]: loss 0.034806
[epoch11, step227]: loss 0.035870
[epoch11, step228]: loss 0.037124
[epoch11, step229]: loss 0.033939
[epoch11, step230]: loss 0.034524
[epoch11, step231]: loss 0.037462
[epoch11, step232]: loss 0.034310
[epoch11, step233]: loss 0.036208
[epoch11, step234]: loss 0.033653
[epoch11, step235]: loss 0.034921
[epoch11, step236]: loss 0.036726
[epoch11, step237]: loss 0.036591
[epoch11, step238]: loss 0.034477
[epoch11, step239]: loss 0.033580
[epoch11, step240]: loss 0.036169
[epoch11, step241]: loss 0.034847
[epoch11, step242]: loss 0.036825
[epoch11, step243]: loss 0.034837
[epoch11, step244]: loss 0.034130
[epoch11, step245]: loss 0.036682
[epoch11, step246]: loss 0.036513
[epoch11, step247]: loss 0.034693
[epoch11, step248]: loss 0.034392
[epoch11, step249]: loss 0.036291
[epoch11, step250]: loss 0.034693
[epoch11, step251]: loss 0.037866
[epoch11, step252]: loss 0.035435
[epoch11, step253]: loss 0.033695
[epoch11, step254]: loss 0.036724
[epoch11, step255]: loss 0.036651
[epoch11, step256]: loss 0.034372
[epoch11, step257]: loss 0.034165
[epoch11, step258]: loss 0.037363
[epoch11, step259]: loss 0.034939
[epoch11, step260]: loss 0.036248
[epoch11, step261]: loss 0.034982
[epoch11, step262]: loss 0.034823
[epoch11, step263]: loss 0.036440
[epoch11, step264]: loss 0.036573
[epoch11, step265]: loss 0.034488
[epoch11, step266]: loss 0.034191
[epoch11, step267]: loss 0.036720
[epoch11, step268]: loss 0.034738
[epoch11, step269]: loss 0.036804
[epoch11, step270]: loss 0.034182
[epoch11, step271]: loss 0.034817
[epoch11, step272]: loss 0.036773
[epoch11, step273]: loss 0.036448
[epoch11, step274]: loss 0.034960
[epoch11, step275]: loss 0.033903
[epoch11, step276]: loss 0.036541
[epoch11, step277]: loss 0.034815
[epoch11, step278]: loss 0.037256
[epoch11, step279]: loss 0.034333
[epoch11, step280]: loss 0.034849
[epoch11, step281]: loss 0.037064
[epoch11, step282]: loss 0.037015
[epoch11, step283]: loss 0.034081
[epoch11, step284]: loss 0.033833
[epoch11, step285]: loss 0.037625
[epoch11, step286]: loss 0.034161
[epoch11, step287]: loss 0.036966
[epoch11, step288]: loss 0.034032
[epoch11, step289]: loss 0.035205
[epoch11, step290]: loss 0.036956
[epoch11, step291]: loss 0.037224
[epoch11, step292]: loss 0.033459
[epoch11, step293]: loss 0.034023
[epoch11, step294]: loss 0.036235
[epoch11, step295]: loss 0.034488
[epoch11, step296]: loss 0.037818
[epoch11, step297]: loss 0.034044
[epoch11, step298]: loss 0.034733
[epoch11, step299]: loss 0.035997
[epoch11, step300]: loss 0.036848
[epoch11, step301]: loss 0.034392
[epoch11, step302]: loss 0.034680
[epoch11, step303]: loss 0.037230
[epoch11, step304]: loss 0.034121
[epoch11, step305]: loss 0.036319
[epoch11, step306]: loss 0.034950
[epoch11, step307]: loss 0.034117
[epoch11, step308]: loss 0.037944
[epoch11, step309]: loss 0.037581
[epoch11, step310]: loss 0.034254
[epoch11, step311]: loss 0.035128
[epoch11, step312]: loss 0.037393
[epoch11, step313]: loss 0.035139
[epoch11, step314]: loss 0.036770
[epoch11, step315]: loss 0.035089
[epoch11, step316]: loss 0.034161
[epoch11, step317]: loss 0.037192
[epoch11, step318]: loss 0.036727
[epoch11, step319]: loss 0.033643
[epoch11, step320]: loss 0.033323
[epoch11, step321]: loss 0.036081
[epoch11, step322]: loss 0.034176
[epoch11, step323]: loss 0.036082
[epoch11, step324]: loss 0.035233
[epoch11, step325]: loss 0.034291
[epoch11, step326]: loss 0.036575
[epoch11, step327]: loss 0.035840
[epoch11, step328]: loss 0.034575
[epoch11, step329]: loss 0.034527
[epoch11, step330]: loss 0.036101
[epoch11, step331]: loss 0.035042
[epoch11, step332]: loss 0.036951
[epoch11, step333]: loss 0.034384
[epoch11, step334]: loss 0.034413
[epoch11, step335]: loss 0.037264
[epoch11, step336]: loss 0.037502
[epoch11, step337]: loss 0.034915
[epoch11, step338]: loss 0.033570
[epoch11, step339]: loss 0.036693
[epoch11, step340]: loss 0.035228
[epoch11, step341]: loss 0.036106
[epoch11, step342]: loss 0.034112
[epoch11, step343]: loss 0.035026
[epoch11, step344]: loss 0.036369
[epoch11, step345]: loss 0.036458
[epoch11, step346]: loss 0.034010
[epoch11, step347]: loss 0.033843
[epoch11, step348]: loss 0.037295
[epoch11, step349]: loss 0.035211
[epoch11, step350]: loss 0.036017
[epoch11, step351]: loss 0.033368
[epoch11, step352]: loss 0.034011
[epoch11, step353]: loss 0.036598
[epoch11, step354]: loss 0.035430
[epoch11, step355]: loss 0.033529
[epoch11, step356]: loss 0.035115
[epoch11, step357]: loss 0.036637
[epoch11, step358]: loss 0.032898
[epoch11, step359]: loss 0.038456
[epoch11, step360]: loss 0.033555
[epoch11, step361]: loss 0.034913
[epoch11, step362]: loss 0.037559
[epoch11, step363]: loss 0.036767
[epoch11, step364]: loss 0.035314
[epoch11, step365]: loss 0.034508
[epoch11, step366]: loss 0.037246
[epoch11, step367]: loss 0.034925
[epoch11, step368]: loss 0.035940
[epoch11, step369]: loss 0.033628
[epoch11, step370]: loss 0.034682
[epoch11, step371]: loss 0.037702
[epoch11, step372]: loss 0.035844
[epoch11, step373]: loss 0.033471
[epoch11, step374]: loss 0.033310
[epoch11, step375]: loss 0.037731
[epoch11, step376]: loss 0.034659
[epoch11, step377]: loss 0.036950
[epoch11, step378]: loss 0.034644
[epoch11, step379]: loss 0.034578
[epoch11, step380]: loss 0.037695
[epoch11, step381]: loss 0.036125
[epoch11, step382]: loss 0.034465
[epoch11, step383]: loss 0.033551
[epoch11, step384]: loss 0.035739
[epoch11, step385]: loss 0.034221
[epoch11, step386]: loss 0.037334
[epoch11, step387]: loss 0.034027
[epoch11, step388]: loss 0.035451
[epoch11, step389]: loss 0.036913
[epoch11, step390]: loss 0.037606
[epoch11, step391]: loss 0.034100
[epoch11, step392]: loss 0.035276
[epoch11, step393]: loss 0.036735
[epoch11, step394]: loss 0.034268
[epoch11, step395]: loss 0.036369
[epoch11, step396]: loss 0.033982
[epoch11, step397]: loss 0.033888
[epoch11, step398]: loss 0.037013
[epoch11, step399]: loss 0.036138
[epoch11, step400]: loss 0.034224
[epoch11, step401]: loss 0.034611
[epoch11, step402]: loss 0.037011
[epoch11, step403]: loss 0.034729
[epoch11, step404]: loss 0.038070
[epoch11, step405]: loss 0.034834
[epoch11, step406]: loss 0.034423
[epoch11, step407]: loss 0.036850
[epoch11, step408]: loss 0.036377
[epoch11, step409]: loss 0.035577
[epoch11, step410]: loss 0.034433
[epoch11, step411]: loss 0.036079
[epoch11, step412]: loss 0.034486
[epoch11, step413]: loss 0.036283
[epoch11, step414]: loss 0.034042
[epoch11, step415]: loss 0.034282
[epoch11, step416]: loss 0.035761
[epoch11, step417]: loss 0.036264
[epoch11, step418]: loss 0.034407
[epoch11, step419]: loss 0.033720
[epoch11, step420]: loss 0.036813
[epoch11, step421]: loss 0.034639
[epoch11, step422]: loss 0.036777
[epoch11, step423]: loss 0.033793
[epoch11, step424]: loss 0.033948
[epoch11, step425]: loss 0.036855
[epoch11, step426]: loss 0.037123
[epoch11, step427]: loss 0.034861
[epoch11, step428]: loss 0.034271
[epoch11, step429]: loss 0.037325
[epoch11, step430]: loss 0.034024
[epoch11, step431]: loss 0.036846
[epoch11, step432]: loss 0.033791
[epoch11, step433]: loss 0.034625
[epoch11, step434]: loss 0.036922
[epoch11, step435]: loss 0.037103
[epoch11, step436]: loss 0.033838
[epoch11, step437]: loss 0.034363
[epoch11, step438]: loss 0.036787
[epoch11, step439]: loss 0.035348
[epoch11, step440]: loss 0.036974
[epoch11, step441]: loss 0.033856
[epoch11, step442]: loss 0.034781
[epoch11, step443]: loss 0.038470
[epoch11, step444]: loss 0.036765
[epoch11, step445]: loss 0.034635
[epoch11, step446]: loss 0.034661
[epoch11, step447]: loss 0.037171
[epoch11, step448]: loss 0.034405
[epoch11, step449]: loss 0.036173
[epoch11, step450]: loss 0.033442
[epoch11, step451]: loss 0.034087
[epoch11, step452]: loss 0.036814
[epoch11, step453]: loss 0.036860
[epoch11, step454]: loss 0.034524
[epoch11, step455]: loss 0.034765
[epoch11, step456]: loss 0.036295
[epoch11, step457]: loss 0.034812
[epoch11, step458]: loss 0.036723
[epoch11, step459]: loss 0.034613
[epoch11, step460]: loss 0.034426
[epoch11, step461]: loss 0.038072
[epoch11, step462]: loss 0.035666
[epoch11, step463]: loss 0.034758
[epoch11, step464]: loss 0.033546
[epoch11, step465]: loss 0.037847
[epoch11, step466]: loss 0.034301
[epoch11, step467]: loss 0.036244
[epoch11, step468]: loss 0.033984
[epoch11, step469]: loss 0.034173
[epoch11, step470]: loss 0.037051
[epoch11, step471]: loss 0.036089
[epoch11, step472]: loss 0.034532
[epoch11, step473]: loss 0.033965
[epoch11, step474]: loss 0.036079
[epoch11, step475]: loss 0.034119
[epoch11, step476]: loss 0.036971
[epoch11, step477]: loss 0.034095
[epoch11, step478]: loss 0.034116
[epoch11, step479]: loss 0.036722
[epoch11, step480]: loss 0.035934
[epoch11, step481]: loss 0.034225
[epoch11, step482]: loss 0.033190
[epoch11, step483]: loss 0.036565
[epoch11, step484]: loss 0.034428
[epoch11, step485]: loss 0.036757
[epoch11, step486]: loss 0.034136
[epoch11, step487]: loss 0.033609
[epoch11, step488]: loss 0.037041
[epoch11, step489]: loss 0.035362
[epoch11, step490]: loss 0.034883
[epoch11, step491]: loss 0.034343
[epoch11, step492]: loss 0.036398
[epoch11, step493]: loss 0.033689
[epoch11, step494]: loss 0.035675
[epoch11, step495]: loss 0.035153
[epoch11, step496]: loss 0.035178
[epoch11, step497]: loss 0.037329
[epoch11, step498]: loss 0.036753
[epoch11, step499]: loss 0.034234
[epoch11, step500]: loss 0.034190
[epoch11, step501]: loss 0.036765
[epoch11, step502]: loss 0.034136
[epoch11, step503]: loss 0.037291
[epoch11, step504]: loss 0.033902
[epoch11, step505]: loss 0.033582
[epoch11, step506]: loss 0.037682
[epoch11, step507]: loss 0.037355
[epoch11, step508]: loss 0.034837
[epoch11, step509]: loss 0.034141
[epoch11, step510]: loss 0.036771
[epoch11, step511]: loss 0.035052
[epoch11, step512]: loss 0.037490
[epoch11, step513]: loss 0.034140
[epoch11, step514]: loss 0.034605
[epoch11, step515]: loss 0.036991
[epoch11, step516]: loss 0.036748
[epoch11, step517]: loss 0.034043
[epoch11, step518]: loss 0.034204
[epoch11, step519]: loss 0.036513
[epoch11, step520]: loss 0.033913
[epoch11, step521]: loss 0.036473
[epoch11, step522]: loss 0.033738
[epoch11, step523]: loss 0.033933
[epoch11, step524]: loss 0.036220
[epoch11, step525]: loss 0.036612
[epoch11, step526]: loss 0.034558
[epoch11, step527]: loss 0.034168
[epoch11, step528]: loss 0.036677
[epoch11, step529]: loss 0.034585
[epoch11, step530]: loss 0.038636
[epoch11, step531]: loss 0.034370
[epoch11, step532]: loss 0.034317
[epoch11, step533]: loss 0.037520
[epoch11, step534]: loss 0.036478
[epoch11, step535]: loss 0.034808
[epoch11, step536]: loss 0.034523
[epoch11, step537]: loss 0.036332
[epoch11, step538]: loss 0.034954
[epoch11, step539]: loss 0.036208
[epoch11, step540]: loss 0.033244
[epoch11, step541]: loss 0.034290
[epoch11, step542]: loss 0.038046
[epoch11, step543]: loss 0.036517
[epoch11, step544]: loss 0.034119
[epoch11, step545]: loss 0.033882
[epoch11, step546]: loss 0.037389
[epoch11, step547]: loss 0.034332
[epoch11, step548]: loss 0.037396
[epoch11, step549]: loss 0.034062
[epoch11, step550]: loss 0.034317
[epoch11, step551]: loss 0.036162
[epoch11, step552]: loss 0.035721
[epoch11, step553]: loss 0.034633
[epoch11, step554]: loss 0.033789
[epoch11, step555]: loss 0.035791
[epoch11, step556]: loss 0.034304
[epoch11, step557]: loss 0.035776
[epoch11, step558]: loss 0.034565
[epoch11, step559]: loss 0.034338
[epoch11, step560]: loss 0.036933
[epoch11, step561]: loss 0.036448
[epoch11, step562]: loss 0.034467
[epoch11, step563]: loss 0.035533
[epoch11, step564]: loss 0.040633
[epoch11, step565]: loss 0.039578
[epoch11, step566]: loss 0.045367
[epoch11, step567]: loss 0.039019
[epoch11, step568]: loss 0.038630
[epoch11, step569]: loss 0.035121
[epoch11, step570]: loss 0.042700
[epoch11, step571]: loss 0.037917
[epoch11, step572]: loss 0.036719
[epoch11, step573]: loss 0.039191
[epoch11, step574]: loss 0.040961
[epoch11, step575]: loss 0.032162
[epoch11, step576]: loss 0.033146
[epoch11, step577]: loss 0.037402
[epoch11, step578]: loss 0.030209
[epoch11, step579]: loss 0.039729
[epoch11, step580]: loss 0.030451
[epoch11, step581]: loss 0.035361
[epoch11, step582]: loss 0.034540
[epoch11, step583]: loss 0.035271
[epoch11, step584]: loss 0.033794
[epoch11, step585]: loss 0.037140
[epoch11, step586]: loss 0.034736
[epoch11, step587]: loss 0.039152
[epoch11, step588]: loss 0.033327
[epoch11, step589]: loss 0.033724
[epoch11, step590]: loss 0.037866
[epoch11, step591]: loss 0.032145
[epoch11, step592]: loss 0.036603
[epoch11, step593]: loss 0.032098
[epoch11, step594]: loss 0.036731
[epoch11, step595]: loss 0.037657
[epoch11, step596]: loss 0.035840
[epoch11, step597]: loss 0.035186
[epoch11, step598]: loss 0.038425
[epoch11, step599]: loss 0.035144
[epoch11, step600]: loss 0.037369
[epoch11, step601]: loss 0.029831
[epoch11, step602]: loss 0.032494
[epoch11, step603]: loss 0.036666
[epoch11, step604]: loss 0.036718
[epoch11, step605]: loss 0.034596
[epoch11, step606]: loss 0.034888
[epoch11, step607]: loss 0.037497
[epoch11, step608]: loss 0.036680
[epoch11, step609]: loss 0.036018
[epoch11, step610]: loss 0.038863
[epoch11, step611]: loss 0.037854
[epoch11, step612]: loss 0.033988
[epoch11, step613]: loss 0.029329
[epoch11, step614]: loss 0.034404
[epoch11, step615]: loss 0.039714
[epoch11, step616]: loss 0.033933
[epoch11, step617]: loss 0.032364
[epoch11, step618]: loss 0.037409
[epoch11, step619]: loss 0.039924
[epoch11, step620]: loss 0.034471
[epoch11, step621]: loss 0.036570
[epoch11, step622]: loss 0.031480
[epoch11, step623]: loss 0.033317
[epoch11, step624]: loss 0.036975
[epoch11, step625]: loss 0.036216
[epoch11, step626]: loss 0.036859
[epoch11, step627]: loss 0.032920
[epoch11, step628]: loss 0.034409
[epoch11, step629]: loss 0.029594
[epoch11, step630]: loss 0.030892
[epoch11, step631]: loss 0.042550
[epoch11, step632]: loss 0.033980
[epoch11, step633]: loss 0.033886
[epoch11, step634]: loss 0.036442
[epoch11, step635]: loss 0.036993
[epoch11, step636]: loss 0.030606
[epoch11, step637]: loss 0.037851
[epoch11, step638]: loss 0.038045
[epoch11, step639]: loss 0.031250
[epoch11, step640]: loss 0.038876
[epoch11, step641]: loss 0.039894
[epoch11, step642]: loss 0.034644
[epoch11, step643]: loss 0.033371
[epoch11, step644]: loss 0.036396
[epoch11, step645]: loss 0.033342
[epoch11, step646]: loss 0.034326
[epoch11, step647]: loss 0.032516
[epoch11, step648]: loss 0.035575
[epoch11, step649]: loss 0.037808
[epoch11, step650]: loss 0.032904
[epoch11, step651]: loss 0.036972
[epoch11, step652]: loss 0.037213
[epoch11, step653]: loss 0.037915
[epoch11, step654]: loss 0.031772
[epoch11, step655]: loss 0.033435
[epoch11, step656]: loss 0.033156
[epoch11, step657]: loss 0.038228
[epoch11, step658]: loss 0.034405
[epoch11, step659]: loss 0.036373
[epoch11, step660]: loss 0.031553
[epoch11, step661]: loss 0.035739
[epoch11, step662]: loss 0.033459
[epoch11, step663]: loss 0.032500
[epoch11, step664]: loss 0.036742
[epoch11, step665]: loss 0.036547
[epoch11, step666]: loss 0.036542
[epoch11, step667]: loss 0.036664
[epoch11, step668]: loss 0.034908
[epoch11, step669]: loss 0.037209
[epoch11, step670]: loss 0.036560
[epoch11, step671]: loss 0.030540
[epoch11, step672]: loss 0.035046
[epoch11, step673]: loss 0.033618
[epoch11, step674]: loss 0.030121
[epoch11, step675]: loss 0.030403
[epoch11, step676]: loss 0.032679
[epoch11, step677]: loss 0.034297
[epoch11, step678]: loss 0.031661
[epoch11, step679]: loss 0.033850
[epoch11, step680]: loss 0.040607
[epoch11, step681]: loss 0.030098
[epoch11, step682]: loss 0.035306
[epoch11, step683]: loss 0.034801
[epoch11, step684]: loss 0.034344
[epoch11, step685]: loss 0.035029
[epoch11, step686]: loss 0.038632
[epoch11, step687]: loss 0.035811
[epoch11, step688]: loss 0.034823
[epoch11, step689]: loss 0.035448
[epoch11, step690]: loss 0.035268
[epoch11, step691]: loss 0.034994
[epoch11, step692]: loss 0.034857
[epoch11, step693]: loss 0.038559
[epoch11, step694]: loss 0.032412
[epoch11, step695]: loss 0.039000
[epoch11, step696]: loss 0.035731
[epoch11, step697]: loss 0.038000
[epoch11, step698]: loss 0.033736
[epoch11, step699]: loss 0.033997
[epoch11, step700]: loss 0.032462
[epoch11, step701]: loss 0.036464
[epoch11, step702]: loss 0.031289
[epoch11, step703]: loss 0.034541
[epoch11, step704]: loss 0.036351
[epoch11, step705]: loss 0.035532
[epoch11, step706]: loss 0.034372
[epoch11, step707]: loss 0.035194
[epoch11, step708]: loss 0.034897
[epoch11, step709]: loss 0.038380
[epoch11, step710]: loss 0.032435
[epoch11, step711]: loss 0.036868
[epoch11, step712]: loss 0.035305
[epoch11, step713]: loss 0.036280
[epoch11, step714]: loss 0.031070
[epoch11, step715]: loss 0.033171
[epoch11, step716]: loss 0.035971
[epoch11, step717]: loss 0.031847
[epoch11, step718]: loss 0.034630
[epoch11, step719]: loss 0.043656
[epoch11, step720]: loss 0.033793
[epoch11, step721]: loss 0.032493
[epoch11, step722]: loss 0.040017
[epoch11, step723]: loss 0.037285
[epoch11, step724]: loss 0.031609
[epoch11, step725]: loss 0.035967
[epoch11, step726]: loss 0.031844
[epoch11, step727]: loss 0.033087
[epoch11, step728]: loss 0.036313
[epoch11, step729]: loss 0.032270
[epoch11, step730]: loss 0.032617
[epoch11, step731]: loss 0.036173
[epoch11, step732]: loss 0.035694
[epoch11, step733]: loss 0.034001
[epoch11, step734]: loss 0.032944
[epoch11, step735]: loss 0.037941
[epoch11, step736]: loss 0.034862
[epoch11, step737]: loss 0.037121
[epoch11, step738]: loss 0.029610
[epoch11, step739]: loss 0.036349
[epoch11, step740]: loss 0.031982
[epoch11, step741]: loss 0.035710
[epoch11, step742]: loss 0.032705
[epoch11, step743]: loss 0.032969
[epoch11, step744]: loss 0.032597
[epoch11, step745]: loss 0.033155
[epoch11, step746]: loss 0.035309
[epoch11, step747]: loss 0.037983
[epoch11, step748]: loss 0.035368
[epoch11, step749]: loss 0.034365
[epoch11, step750]: loss 0.037178
[epoch11, step751]: loss 0.032761
[epoch11, step752]: loss 0.034956
[epoch11, step753]: loss 0.035888
[epoch11, step754]: loss 0.033663
[epoch11, step755]: loss 0.034662
[epoch11, step756]: loss 0.033217
[epoch11, step757]: loss 0.029720
[epoch11, step758]: loss 0.033358
[epoch11, step759]: loss 0.031810
[epoch11, step760]: loss 0.033593
[epoch11, step761]: loss 0.036358
[epoch11, step762]: loss 0.030196
[epoch11, step763]: loss 0.034339
[epoch11, step764]: loss 0.035324
[epoch11, step765]: loss 0.035582
[epoch11, step766]: loss 0.035926
[epoch11, step767]: loss 0.039116
[epoch11, step768]: loss 0.029943
[epoch11, step769]: loss 0.035654
[epoch11, step770]: loss 0.033585
[epoch11, step771]: loss 0.032429
[epoch11, step772]: loss 0.037196
[epoch11, step773]: loss 0.034753
[epoch11, step774]: loss 0.034810
[epoch11, step775]: loss 0.029162
[epoch11, step776]: loss 0.037562
[epoch11, step777]: loss 0.031961
[epoch11, step778]: loss 0.037258
[epoch11, step779]: loss 0.035120
[epoch11, step780]: loss 0.028829
[epoch11, step781]: loss 0.034255
[epoch11, step782]: loss 0.031049
[epoch11, step783]: loss 0.029721
[epoch11, step784]: loss 0.031413
[epoch11, step785]: loss 0.030854
[epoch11, step786]: loss 0.033929
[epoch11, step787]: loss 0.033062
[epoch11, step788]: loss 0.036040
[epoch11, step789]: loss 0.034646
[epoch11, step790]: loss 0.032673
[epoch11, step791]: loss 0.037661
[epoch11, step792]: loss 0.034451
[epoch11, step793]: loss 0.035822
[epoch11, step794]: loss 0.029727
[epoch11, step795]: loss 0.034893
[epoch11, step796]: loss 0.037394
[epoch11, step797]: loss 0.036335
[epoch11, step798]: loss 0.036300
[epoch11, step799]: loss 0.036462
[epoch11, step800]: loss 0.031642
[epoch11, step801]: loss 0.034156
[epoch11, step802]: loss 0.033328
[epoch11, step803]: loss 0.036798
[epoch11, step804]: loss 0.038180
[epoch11, step805]: loss 0.037708
[epoch11, step806]: loss 0.032494
[epoch11, step807]: loss 0.032137
[epoch11, step808]: loss 0.034037
[epoch11, step809]: loss 0.030883
[epoch11, step810]: loss 0.035180
[epoch11, step811]: loss 0.033870
[epoch11, step812]: loss 0.031964
[epoch11, step813]: loss 0.033083
[epoch11, step814]: loss 0.035606
[epoch11, step815]: loss 0.033075
[epoch11, step816]: loss 0.033165
[epoch11, step817]: loss 0.034468
[epoch11, step818]: loss 0.030762
[epoch11, step819]: loss 0.031564
[epoch11, step820]: loss 0.034049
[epoch11, step821]: loss 0.030964
[epoch11, step822]: loss 0.038564
[epoch11, step823]: loss 0.033181
[epoch11, step824]: loss 0.035254
[epoch11, step825]: loss 0.035484
[epoch11, step826]: loss 0.032956
[epoch11, step827]: loss 0.036545
[epoch11, step828]: loss 0.038698
[epoch11, step829]: loss 0.039008
[epoch11, step830]: loss 0.032824
[epoch11, step831]: loss 0.037186
[epoch11, step832]: loss 0.031507
[epoch11, step833]: loss 0.037934
[epoch11, step834]: loss 0.035857
[epoch11, step835]: loss 0.030429
[epoch11, step836]: loss 0.038282
[epoch11, step837]: loss 0.035812
[epoch11, step838]: loss 0.034118
[epoch11, step839]: loss 0.038771
[epoch11, step840]: loss 0.030993
[epoch11, step841]: loss 0.034586
[epoch11, step842]: loss 0.037865
[epoch11, step843]: loss 0.035713
[epoch11, step844]: loss 0.035154
[epoch11, step845]: loss 0.031888
[epoch11, step846]: loss 0.038926
[epoch11, step847]: loss 0.036704
[epoch11, step848]: loss 0.034355
[epoch11, step849]: loss 0.032565
[epoch11, step850]: loss 0.032312
[epoch11, step851]: loss 0.034824
[epoch11, step852]: loss 0.032215
[epoch11, step853]: loss 0.040004
[epoch11, step854]: loss 0.033045
[epoch11, step855]: loss 0.036642
[epoch11, step856]: loss 0.030160
[epoch11, step857]: loss 0.033206
[epoch11, step858]: loss 0.034006
[epoch11, step859]: loss 0.033553
[epoch11, step860]: loss 0.031680
[epoch11, step861]: loss 0.032354
[epoch11, step862]: loss 0.031264
[epoch11, step863]: loss 0.031523
[epoch11, step864]: loss 0.036185
[epoch11, step865]: loss 0.033215
[epoch11, step866]: loss 0.034637
[epoch11, step867]: loss 0.035520
[epoch11, step868]: loss 0.035741
[epoch11, step869]: loss 0.032820
[epoch11, step870]: loss 0.040416
[epoch11, step871]: loss 0.033746
[epoch11, step872]: loss 0.035705
[epoch11, step873]: loss 0.034806
[epoch11, step874]: loss 0.032424
[epoch11, step875]: loss 0.033452
[epoch11, step876]: loss 0.035412
[epoch11, step877]: loss 0.029282
[epoch11, step878]: loss 0.033620
[epoch11, step879]: loss 0.037426
[epoch11, step880]: loss 0.036214
[epoch11, step881]: loss 0.032627
[epoch11, step882]: loss 0.032195
[epoch11, step883]: loss 0.032554
[epoch11, step884]: loss 0.035457
[epoch11, step885]: loss 0.033892
[epoch11, step886]: loss 0.035059
[epoch11, step887]: loss 0.033739
[epoch11, step888]: loss 0.034212
[epoch11, step889]: loss 0.033719
[epoch11, step890]: loss 0.034667
[epoch11, step891]: loss 0.035621
[epoch11, step892]: loss 0.029424
[epoch11, step893]: loss 0.033400
[epoch11, step894]: loss 0.034398
[epoch11, step895]: loss 0.030830
[epoch11, step896]: loss 0.034316
[epoch11, step897]: loss 0.035296
[epoch11, step898]: loss 0.036003
[epoch11, step899]: loss 0.038625
[epoch11, step900]: loss 0.035689
[epoch11, step901]: loss 0.036886
[epoch11, step902]: loss 0.033040
[epoch11, step903]: loss 0.034879
[epoch11, step904]: loss 0.037970
[epoch11, step905]: loss 0.037332
[epoch11, step906]: loss 0.031166
[epoch11, step907]: loss 0.032808
[epoch11, step908]: loss 0.031376
[epoch11, step909]: loss 0.036728
[epoch11, step910]: loss 0.034037
[epoch11, step911]: loss 0.035632
[epoch11, step912]: loss 0.033449
[epoch11, step913]: loss 0.035074
[epoch11, step914]: loss 0.039186
[epoch11, step915]: loss 0.032828
[epoch11, step916]: loss 0.032801
[epoch11, step917]: loss 0.034829
[epoch11, step918]: loss 0.039143
[epoch11, step919]: loss 0.033460
[epoch11, step920]: loss 0.036962
[epoch11, step921]: loss 0.032986
[epoch11, step922]: loss 0.033666
[epoch11, step923]: loss 0.033633
[epoch11, step924]: loss 0.029314
[epoch11, step925]: loss 0.034400
[epoch11, step926]: loss 0.034938
[epoch11, step927]: loss 0.034133
[epoch11, step928]: loss 0.033967
[epoch11, step929]: loss 0.036337
[epoch11, step930]: loss 0.035259
[epoch11, step931]: loss 0.036127
[epoch11, step932]: loss 0.030421
[epoch11, step933]: loss 0.037765
[epoch11, step934]: loss 0.032630
[epoch11, step935]: loss 0.033538
[epoch11, step936]: loss 0.030731
[epoch11, step937]: loss 0.035277
[epoch11, step938]: loss 0.038366
[epoch11, step939]: loss 0.030636
[epoch11, step940]: loss 0.034073
[epoch11, step941]: loss 0.037752
[epoch11, step942]: loss 0.035400
[epoch11, step943]: loss 0.033275
[epoch11, step944]: loss 0.036874
[epoch11, step945]: loss 0.031266
[epoch11, step946]: loss 0.034200
[epoch11, step947]: loss 0.037634
[epoch11, step948]: loss 0.030114
[epoch11, step949]: loss 0.033256
[epoch11, step950]: loss 0.036562
[epoch11, step951]: loss 0.037813
[epoch11, step952]: loss 0.033608
[epoch11, step953]: loss 0.036674
[epoch11, step954]: loss 0.032431
[epoch11, step955]: loss 0.040219
[epoch11, step956]: loss 0.050229
[epoch11, step957]: loss 0.044875
[epoch11, step958]: loss 0.043987
[epoch11, step959]: loss 0.048259
[epoch11, step960]: loss 0.045429
[epoch11, step961]: loss 0.045217
[epoch11, step962]: loss 0.044077
[epoch11, step963]: loss 0.041826
[epoch11, step964]: loss 0.043535
[epoch11, step965]: loss 0.044744
[epoch11, step966]: loss 0.043640
[epoch11, step967]: loss 0.042650
[epoch11, step968]: loss 0.043454
[epoch11, step969]: loss 0.044026
[epoch11, step970]: loss 0.042428
[epoch11, step971]: loss 0.042542
[epoch11, step972]: loss 0.043461
[epoch11, step973]: loss 0.042968
[epoch11, step974]: loss 0.044200
[epoch11, step975]: loss 0.042341
[epoch11, step976]: loss 0.041152
[epoch11, step977]: loss 0.043403
[epoch11, step978]: loss 0.043512
[epoch11, step979]: loss 0.041730
[epoch11, step980]: loss 0.041255
[epoch11, step981]: loss 0.041608
[epoch11, step982]: loss 0.041590
[epoch11, step983]: loss 0.043261
[epoch11, step984]: loss 0.041043
[epoch11, step985]: loss 0.040606
[epoch11, step986]: loss 0.043358
[epoch11, step987]: loss 0.042162
[epoch11, step988]: loss 0.042351
[epoch11, step989]: loss 0.041611
[epoch11, step990]: loss 0.042386
[epoch11, step991]: loss 0.041626
[epoch11, step992]: loss 0.042489
[epoch11, step993]: loss 0.041532
[epoch11, step994]: loss 0.039573
[epoch11, step995]: loss 0.043045
[epoch11, step996]: loss 0.042339
[epoch11, step997]: loss 0.041232
[epoch11, step998]: loss 0.041142
[epoch11, step999]: loss 0.041723
[epoch11, step1000]: loss 0.041959
[epoch11, step1001]: loss 0.043337
[epoch11, step1002]: loss 0.040845
[epoch11, step1003]: loss 0.040536
[epoch11, step1004]: loss 0.043280
[epoch11, step1005]: loss 0.042023
[epoch11, step1006]: loss 0.040840
[epoch11, step1007]: loss 0.040227
[epoch11, step1008]: loss 0.041457
[epoch11, step1009]: loss 0.041438
[epoch11, step1010]: loss 0.042018
[epoch11, step1011]: loss 0.040316
[epoch11, step1012]: loss 0.040175
[epoch11, step1013]: loss 0.042525
[epoch11, step1014]: loss 0.041954
[epoch11, step1015]: loss 0.041370
[epoch11, step1016]: loss 0.040091
[epoch11, step1017]: loss 0.040640
[epoch11, step1018]: loss 0.040963
[epoch11, step1019]: loss 0.041201
[epoch11, step1020]: loss 0.040157
[epoch11, step1021]: loss 0.039280
[epoch11, step1022]: loss 0.041994
[epoch11, step1023]: loss 0.041176
[epoch11, step1024]: loss 0.042180
[epoch11, step1025]: loss 0.039191
[epoch11, step1026]: loss 0.040403
[epoch11, step1027]: loss 0.041426
[epoch11, step1028]: loss 0.041093
[epoch11, step1029]: loss 0.039848
[epoch11, step1030]: loss 0.039454
[epoch11, step1031]: loss 0.042462
[epoch11, step1032]: loss 0.040718
[epoch11, step1033]: loss 0.040517
[epoch11, step1034]: loss 0.040780
[epoch11, step1035]: loss 0.041847
[epoch11, step1036]: loss 0.042663
[epoch11, step1037]: loss 0.042544
[epoch11, step1038]: loss 0.041217
[epoch11, step1039]: loss 0.042618
[epoch11, step1040]: loss 0.044871
[epoch11, step1041]: loss 0.043145
[epoch11, step1042]: loss 0.042600
[epoch11, step1043]: loss 0.041325
[epoch11, step1044]: loss 0.043364
[epoch11, step1045]: loss 0.043104
[epoch11, step1046]: loss 0.041962
[epoch11, step1047]: loss 0.041161
[epoch11, step1048]: loss 0.041137
[epoch11, step1049]: loss 0.043212
[epoch11, step1050]: loss 0.041140
[epoch11, step1051]: loss 0.041711
[epoch11, step1052]: loss 0.042377
[epoch11, step1053]: loss 0.042725
[epoch11, step1054]: loss 0.042978
[epoch11, step1055]: loss 0.042030
[epoch11, step1056]: loss 0.038655
[epoch11, step1057]: loss 0.039280
[epoch11, step1058]: loss 0.042497
[epoch11, step1059]: loss 0.043685
[epoch11, step1060]: loss 0.043619
[epoch11, step1061]: loss 0.042229
[epoch11, step1062]: loss 0.042855
[epoch11, step1063]: loss 0.042462
[epoch11, step1064]: loss 0.042831
[epoch11, step1065]: loss 0.041573
[epoch11, step1066]: loss 0.040104
[epoch11, step1067]: loss 0.042254
[epoch11, step1068]: loss 0.041455
[epoch11, step1069]: loss 0.039948
[epoch11, step1070]: loss 0.040060
[epoch11, step1071]: loss 0.041162
[epoch11, step1072]: loss 0.043077
[epoch11, step1073]: loss 0.042459
[epoch11, step1074]: loss 0.041228
[epoch11, step1075]: loss 0.040814
[epoch11, step1076]: loss 0.042220
[epoch11, step1077]: loss 0.040533
[epoch11, step1078]: loss 0.041151
[epoch11, step1079]: loss 0.040122
[epoch11, step1080]: loss 0.041365
[epoch11, step1081]: loss 0.042254
[epoch11, step1082]: loss 0.043190
[epoch11, step1083]: loss 0.040947
[epoch11, step1084]: loss 0.040372
[epoch11, step1085]: loss 0.042665
[epoch11, step1086]: loss 0.041563
[epoch11, step1087]: loss 0.040553
[epoch11, step1088]: loss 0.039640
[epoch11, step1089]: loss 0.041427
[epoch11, step1090]: loss 0.042102
[epoch11, step1091]: loss 0.042954
[epoch11, step1092]: loss 0.041197
[epoch11, step1093]: loss 0.040548
[epoch11, step1094]: loss 0.042189
[epoch11, step1095]: loss 0.041443
[epoch11, step1096]: loss 0.041879
[epoch11, step1097]: loss 0.041294
[epoch11, step1098]: loss 0.041038
[epoch11, step1099]: loss 0.041561
[epoch11, step1100]: loss 0.042500
[epoch11, step1101]: loss 0.040022
[epoch11, step1102]: loss 0.039325
[epoch11, step1103]: loss 0.042456
[epoch11, step1104]: loss 0.040624
[epoch11, step1105]: loss 0.041553
[epoch11, step1106]: loss 0.040756
[epoch11, step1107]: loss 0.040564
[epoch11, step1108]: loss 0.040176
[epoch11, step1109]: loss 0.041123
[epoch11, step1110]: loss 0.040355
[epoch11, step1111]: loss 0.039338
[epoch11, step1112]: loss 0.041147
[epoch11, step1113]: loss 0.040338
[epoch11, step1114]: loss 0.041149
[epoch11, step1115]: loss 0.039213
[epoch11, step1116]: loss 0.040278
[epoch11, step1117]: loss 0.041249
[epoch11, step1118]: loss 0.041125
[epoch11, step1119]: loss 0.039519
[epoch11, step1120]: loss 0.039229
[epoch11, step1121]: loss 0.041646
[epoch11, step1122]: loss 0.040905
[epoch11, step1123]: loss 0.039696
[epoch11, step1124]: loss 0.040921
[epoch11, step1125]: loss 0.041288
[epoch11, step1126]: loss 0.042798
[epoch11, step1127]: loss 0.042282
[epoch11, step1128]: loss 0.041087
[epoch11, step1129]: loss 0.039323
[epoch11, step1130]: loss 0.042868
[epoch11, step1131]: loss 0.040692
[epoch11, step1132]: loss 0.040249
[epoch11, step1133]: loss 0.039804
[epoch11, step1134]: loss 0.042300
[epoch11, step1135]: loss 0.042230
[epoch11, step1136]: loss 0.043304
[epoch11, step1137]: loss 0.041366
[epoch11, step1138]: loss 0.041077
[epoch11, step1139]: loss 0.044713
[epoch11, step1140]: loss 0.042600
[epoch11, step1141]: loss 0.042054
[epoch11, step1142]: loss 0.043116
[epoch11, step1143]: loss 0.043975
[epoch11, step1144]: loss 0.042944
[epoch11, step1145]: loss 0.042025
[epoch11, step1146]: loss 0.041007
[epoch11, step1147]: loss 0.041367
[epoch11, step1148]: loss 0.043243
[epoch11, step1149]: loss 0.041234
[epoch11, step1150]: loss 0.042053
[epoch11, step1151]: loss 0.043084
[epoch11, step1152]: loss 0.042274
[epoch11, step1153]: loss 0.041151
[epoch11, step1154]: loss 0.041958
[epoch11, step1155]: loss 0.039906
[epoch11, step1156]: loss 0.039815
[epoch11, step1157]: loss 0.042835
[epoch11, step1158]: loss 0.041081
[epoch11, step1159]: loss 0.041479
[epoch11, step1160]: loss 0.041188
[epoch11, step1161]: loss 0.042188
[epoch11, step1162]: loss 0.041999
[epoch11, step1163]: loss 0.041065
[epoch11, step1164]: loss 0.040143
[epoch11, step1165]: loss 0.040040
[epoch11, step1166]: loss 0.042175
[epoch11, step1167]: loss 0.040833
[epoch11, step1168]: loss 0.041138
[epoch11, step1169]: loss 0.039626
[epoch11, step1170]: loss 0.040572
[epoch11, step1171]: loss 0.039656
[epoch11, step1172]: loss 0.042013
[epoch11, step1173]: loss 0.039864
[epoch11, step1174]: loss 0.040348
[epoch11, step1175]: loss 0.041117
[epoch11, step1176]: loss 0.039958
[epoch11, step1177]: loss 0.040924
[epoch11, step1178]: loss 0.039386
[epoch11, step1179]: loss 0.039347
[epoch11, step1180]: loss 0.039996
[epoch11, step1181]: loss 0.041620
[epoch11, step1182]: loss 0.039746
[epoch11, step1183]: loss 0.039372
[epoch11, step1184]: loss 0.040651
[epoch11, step1185]: loss 0.041182
[epoch11, step1186]: loss 0.040434
[epoch11, step1187]: loss 0.039148
[epoch11, step1188]: loss 0.040481
[epoch11, step1189]: loss 0.040769
[epoch11, step1190]: loss 0.040064
[epoch11, step1191]: loss 0.039700
[epoch11, step1192]: loss 0.038472
[epoch11, step1193]: loss 0.041064
[epoch11, step1194]: loss 0.040993
[epoch11, step1195]: loss 0.039070
[epoch11, step1196]: loss 0.039001
[epoch11, step1197]: loss 0.041661
[epoch11, step1198]: loss 0.041596
[epoch11, step1199]: loss 0.041197
[epoch11, step1200]: loss 0.040887
[epoch11, step1201]: loss 0.040356
[epoch11, step1202]: loss 0.042314
[epoch11, step1203]: loss 0.040739
[epoch11, step1204]: loss 0.039990
[epoch11, step1205]: loss 0.038956
[epoch11, step1206]: loss 0.040504
[epoch11, step1207]: loss 0.040784
[epoch11, step1208]: loss 0.041886
[epoch11, step1209]: loss 0.041378
[epoch11, step1210]: loss 0.038561
[epoch11, step1211]: loss 0.042826
[epoch11, step1212]: loss 0.041751
[epoch11, step1213]: loss 0.040862
[epoch11, step1214]: loss 0.038493
[epoch11, step1215]: loss 0.041049
[epoch11, step1216]: loss 0.041040
[epoch11, step1217]: loss 0.041269
[epoch11, step1218]: loss 0.039100
[epoch11, step1219]: loss 0.040606
[epoch11, step1220]: loss 0.042709
[epoch11, step1221]: loss 0.039719
[epoch11, step1222]: loss 0.040442
[epoch11, step1223]: loss 0.039649
[epoch11, step1224]: loss 0.040386
[epoch11, step1225]: loss 0.040073
[epoch11, step1226]: loss 0.040667
[epoch11, step1227]: loss 0.039473
[epoch11, step1228]: loss 0.038072
[epoch11, step1229]: loss 0.041503
[epoch11, step1230]: loss 0.041059
[epoch11, step1231]: loss 0.039770
[epoch11, step1232]: loss 0.041328
[epoch11, step1233]: loss 0.040761
[epoch11, step1234]: loss 0.040449
[epoch11, step1235]: loss 0.041301
[epoch11, step1236]: loss 0.040092
[epoch11, step1237]: loss 0.038446
[epoch11, step1238]: loss 0.039952
[epoch11, step1239]: loss 0.039942
[epoch11, step1240]: loss 0.040519
[epoch11, step1241]: loss 0.039348
[epoch11, step1242]: loss 0.039999
[epoch11, step1243]: loss 0.040781
[epoch11, step1244]: loss 0.040872
[epoch11, step1245]: loss 0.039725
[epoch11, step1246]: loss 0.038719
[epoch11, step1247]: loss 0.040510
[epoch11, step1248]: loss 0.040004
[epoch11, step1249]: loss 0.039930
[epoch11, step1250]: loss 0.039289
[epoch11, step1251]: loss 0.039574
[epoch11, step1252]: loss 0.041307
[epoch11, step1253]: loss 0.040591
[epoch11, step1254]: loss 0.038837
[epoch11, step1255]: loss 0.039699
[epoch11, step1256]: loss 0.041199
[epoch11, step1257]: loss 0.039610
[epoch11, step1258]: loss 0.039451
[epoch11, step1259]: loss 0.038620
[epoch11, step1260]: loss 0.040067
[epoch11, step1261]: loss 0.039407
[epoch11, step1262]: loss 0.040342
[epoch11, step1263]: loss 0.040331
[epoch11, step1264]: loss 0.040369
[epoch11, step1265]: loss 0.040376
[epoch11, step1266]: loss 0.039418
[epoch11, step1267]: loss 0.039959
[epoch11, step1268]: loss 0.038592
[epoch11, step1269]: loss 0.039862
[epoch11, step1270]: loss 0.039696
[epoch11, step1271]: loss 0.041210
[epoch11, step1272]: loss 0.039088
[epoch11, step1273]: loss 0.038298
[epoch11, step1274]: loss 0.040974
[epoch11, step1275]: loss 0.039954
[epoch11, step1276]: loss 0.039384
[epoch11, step1277]: loss 0.038691
[epoch11, step1278]: loss 0.039932
[epoch11, step1279]: loss 0.040460
[epoch11, step1280]: loss 0.042105
[epoch11, step1281]: loss 0.041423
[epoch11, step1282]: loss 0.041175
[epoch11, step1283]: loss 0.042487
[epoch11, step1284]: loss 0.042430
[epoch11, step1285]: loss 0.040606
[epoch11, step1286]: loss 0.040619
[epoch11, step1287]: loss 0.041346
[epoch11, step1288]: loss 0.040194
[epoch11, step1289]: loss 0.042230
[epoch11, step1290]: loss 0.040357
[epoch11, step1291]: loss 0.039220
[epoch11, step1292]: loss 0.042556
[epoch11, step1293]: loss 0.039066
[epoch11, step1294]: loss 0.039624
[epoch11, step1295]: loss 0.039698
[epoch11, step1296]: loss 0.039762
[epoch11, step1297]: loss 0.040418
[epoch11, step1298]: loss 0.041125
[epoch11, step1299]: loss 0.040055
[epoch11, step1300]: loss 0.039792
[epoch11, step1301]: loss 0.040502
[epoch11, step1302]: loss 0.039726
[epoch11, step1303]: loss 0.039531
[epoch11, step1304]: loss 0.038357
[epoch11, step1305]: loss 0.039588
[epoch11, step1306]: loss 0.039851
[epoch11, step1307]: loss 0.041045
[epoch11, step1308]: loss 0.039263
[epoch11, step1309]: loss 0.038409
[epoch11, step1310]: loss 0.041139
[epoch11, step1311]: loss 0.039928
[epoch11, step1312]: loss 0.039454
[epoch11, step1313]: loss 0.038694
[epoch11, step1314]: loss 0.040436
[epoch11, step1315]: loss 0.039952
[epoch11, step1316]: loss 0.041511
[epoch11, step1317]: loss 0.039222
[epoch11, step1318]: loss 0.038783
[epoch11, step1319]: loss 0.040484
[epoch11, step1320]: loss 0.040271
[epoch11, step1321]: loss 0.040069
[epoch11, step1322]: loss 0.039492
[epoch11, step1323]: loss 0.040747
[epoch11, step1324]: loss 0.039766
[epoch11, step1325]: loss 0.040561
[epoch11, step1326]: loss 0.039337
[epoch11, step1327]: loss 0.039294
[epoch11, step1328]: loss 0.042867
[epoch11, step1329]: loss 0.041252
[epoch11, step1330]: loss 0.041565
[epoch11, step1331]: loss 0.040660
[epoch11, step1332]: loss 0.040506
[epoch11, step1333]: loss 0.040994
[epoch11, step1334]: loss 0.040451
[epoch11, step1335]: loss 0.039557
[epoch11, step1336]: loss 0.038647
[epoch11, step1337]: loss 0.041501
[epoch11, step1338]: loss 0.039420
[epoch11, step1339]: loss 0.040736
[epoch11, step1340]: loss 0.040301
[epoch11, step1341]: loss 0.041868
[epoch11, step1342]: loss 0.041959
[epoch11, step1343]: loss 0.042211
[epoch11, step1344]: loss 0.041111
[epoch11, step1345]: loss 0.040544
[epoch11, step1346]: loss 0.041994
[epoch11, step1347]: loss 0.041212
[epoch11, step1348]: loss 0.040067
[epoch11, step1349]: loss 0.039621
[epoch11, step1350]: loss 0.040657
[epoch11, step1351]: loss 0.040446
[epoch11, step1352]: loss 0.040657
[epoch11, step1353]: loss 0.041003
[epoch11, step1354]: loss 0.039368
[epoch11, step1355]: loss 0.042457
[epoch11, step1356]: loss 0.040720
[epoch11, step1357]: loss 0.040723
[epoch11, step1358]: loss 0.039931
[epoch11, step1359]: loss 0.039685
[epoch11, step1360]: loss 0.039994
[epoch11, step1361]: loss 0.041748
[epoch11, step1362]: loss 0.041167
[epoch11, step1363]: loss 0.039307
[epoch11, step1364]: loss 0.040902
[epoch11, step1365]: loss 0.039989
[epoch11, step1366]: loss 0.039495
[epoch11, step1367]: loss 0.039495
[epoch11, step1368]: loss 0.040707
[epoch11, step1369]: loss 0.040347
[epoch11, step1370]: loss 0.041709
[epoch11, step1371]: loss 0.040681
[epoch11, step1372]: loss 0.039781
[epoch11, step1373]: loss 0.040661
[epoch11, step1374]: loss 0.040947
[epoch11, step1375]: loss 0.040604
[epoch11, step1376]: loss 0.039335
[epoch11, step1377]: loss 0.040085
[epoch11, step1378]: loss 0.041910
[epoch11, step1379]: loss 0.042973
[epoch11, step1380]: loss 0.040858
[epoch11, step1381]: loss 0.038824
[epoch11, step1382]: loss 0.041589
[epoch11, step1383]: loss 0.040129
[epoch11, step1384]: loss 0.039978
[epoch11, step1385]: loss 0.038877
[epoch11, step1386]: loss 0.040559
[epoch11, step1387]: loss 0.041961
[epoch11, step1388]: loss 0.041838
[epoch11, step1389]: loss 0.038680
[epoch11, step1390]: loss 0.039539
[epoch11, step1391]: loss 0.042514
[epoch11, step1392]: loss 0.041213
[epoch11, step1393]: loss 0.039505
[epoch11, step1394]: loss 0.039553
[epoch11, step1395]: loss 0.040273
[epoch11, step1396]: loss 0.039844
[epoch11, step1397]: loss 0.040161
[epoch11, step1398]: loss 0.040286
[epoch11, step1399]: loss 0.040461
[epoch11, step1400]: loss 0.043196
[epoch11, step1401]: loss 0.043107
[epoch11, step1402]: loss 0.042468
[epoch11, step1403]: loss 0.041349
[epoch11, step1404]: loss 0.041787
[epoch11, step1405]: loss 0.042859
[epoch11, step1406]: loss 0.041988
[epoch11, step1407]: loss 0.040727
[epoch11, step1408]: loss 0.039611
[epoch11, step1409]: loss 0.041988
[epoch11, step1410]: loss 0.042711
[epoch11, step1411]: loss 0.041323
[epoch11, step1412]: loss 0.040933
[epoch11, step1413]: loss 0.039810
[epoch11, step1414]: loss 0.039820
[epoch11, step1415]: loss 0.041213
[epoch11, step1416]: loss 0.041018
[epoch11, step1417]: loss 0.040170
[epoch11, step1418]: loss 0.042987
[epoch11, step1419]: loss 0.041801
[epoch11, step1420]: loss 0.041718
[epoch11, step1421]: loss 0.038887
[epoch11, step1422]: loss 0.040660
[epoch11, step1423]: loss 0.042273
[epoch11, step1424]: loss 0.041488
[epoch11, step1425]: loss 0.040645
[epoch11, step1426]: loss 0.039384
[epoch11, step1427]: loss 0.040954
[epoch11, step1428]: loss 0.040041
[epoch11, step1429]: loss 0.040166
[epoch11, step1430]: loss 0.039093
[epoch11, step1431]: loss 0.041239
[epoch11, step1432]: loss 0.040876
[epoch11, step1433]: loss 0.041074
[epoch11, step1434]: loss 0.038865
[epoch11, step1435]: loss 0.039074
[epoch11, step1436]: loss 0.041135
[epoch11, step1437]: loss 0.039965
[epoch11, step1438]: loss 0.040489
[epoch11, step1439]: loss 0.039019
[epoch11, step1440]: loss 0.039879
[epoch11, step1441]: loss 0.040868
[epoch11, step1442]: loss 0.040004
[epoch11, step1443]: loss 0.039266
[epoch11, step1444]: loss 0.038843
[epoch11, step1445]: loss 0.041942
[epoch11, step1446]: loss 0.040267
[epoch11, step1447]: loss 0.039997
[epoch11, step1448]: loss 0.038805
[epoch11, step1449]: loss 0.039348
[epoch11, step1450]: loss 0.039642
[epoch11, step1451]: loss 0.040103
[epoch11, step1452]: loss 0.040070
[epoch11, step1453]: loss 0.039747
[epoch11, step1454]: loss 0.041668
[epoch11, step1455]: loss 0.040674
[epoch11, step1456]: loss 0.040695
[epoch11, step1457]: loss 0.038938
[epoch11, step1458]: loss 0.039921
[epoch11, step1459]: loss 0.040234
[epoch11, step1460]: loss 0.042969
[epoch11, step1461]: loss 0.039888
[epoch11, step1462]: loss 0.039709
[epoch11, step1463]: loss 0.041678
[epoch11, step1464]: loss 0.040643
[epoch11, step1465]: loss 0.040278
[epoch11, step1466]: loss 0.038380
[epoch11, step1467]: loss 0.040614
[epoch11, step1468]: loss 0.039844
[epoch11, step1469]: loss 0.040680
[epoch11, step1470]: loss 0.039145
[epoch11, step1471]: loss 0.038410
[epoch11, step1472]: loss 0.040666
[epoch11, step1473]: loss 0.039726
[epoch11, step1474]: loss 0.040538
[epoch11, step1475]: loss 0.038508
[epoch11, step1476]: loss 0.040137
[epoch11, step1477]: loss 0.040236
[epoch11, step1478]: loss 0.041017
[epoch11, step1479]: loss 0.039076
[epoch11, step1480]: loss 0.038812
[epoch11, step1481]: loss 0.041618
[epoch11, step1482]: loss 0.040591
[epoch11, step1483]: loss 0.039340
[epoch11, step1484]: loss 0.039139
[epoch11, step1485]: loss 0.039554
[epoch11, step1486]: loss 0.039794
[epoch11, step1487]: loss 0.039859
[epoch11, step1488]: loss 0.039225
[epoch11, step1489]: loss 0.038602
[epoch11, step1490]: loss 0.041074
[epoch11, step1491]: loss 0.039928
[epoch11, step1492]: loss 0.039661
[epoch11, step1493]: loss 0.039060
[epoch11, step1494]: loss 0.039113
[epoch11, step1495]: loss 0.039354
[epoch11, step1496]: loss 0.041042
[epoch11, step1497]: loss 0.040027
[epoch11, step1498]: loss 0.038612
[epoch11, step1499]: loss 0.042806
[epoch11, step1500]: loss 0.039809
[epoch11, step1501]: loss 0.039397
[epoch11, step1502]: loss 0.038617
[epoch11, step1503]: loss 0.039139
[epoch11, step1504]: loss 0.038875
[epoch11, step1505]: loss 0.042572
[epoch11, step1506]: loss 0.039873
[epoch11, step1507]: loss 0.041508
[epoch11, step1508]: loss 0.043651
[epoch11, step1509]: loss 0.041690
[epoch11, step1510]: loss 0.041031
[epoch11, step1511]: loss 0.040343
[epoch11, step1512]: loss 0.039982
[epoch11, step1513]: loss 0.038986
[epoch11, step1514]: loss 0.040696
[epoch11, step1515]: loss 0.039040
[epoch11, step1516]: loss 0.038075

[epoch11]: avg loss 0.037329

[epoch12, step1]: loss 0.041987
[epoch12, step2]: loss 0.039550
[epoch12, step3]: loss 0.039212
[epoch12, step4]: loss 0.037003
[epoch12, step5]: loss 0.036011
[epoch12, step6]: loss 0.038799
[epoch12, step7]: loss 0.036278
[epoch12, step8]: loss 0.037708
[epoch12, step9]: loss 0.034787
[epoch12, step10]: loss 0.036514
[epoch12, step11]: loss 0.038833
[epoch12, step12]: loss 0.038012
[epoch12, step13]: loss 0.036101
[epoch12, step14]: loss 0.034330
[epoch12, step15]: loss 0.037400
[epoch12, step16]: loss 0.036125
[epoch12, step17]: loss 0.037654
[epoch12, step18]: loss 0.036973
[epoch12, step19]: loss 0.035553
[epoch12, step20]: loss 0.039661
[epoch12, step21]: loss 0.036399
[epoch12, step22]: loss 0.035197
[epoch12, step23]: loss 0.036045
[epoch12, step24]: loss 0.038166
[epoch12, step25]: loss 0.035614
[epoch12, step26]: loss 0.037938
[epoch12, step27]: loss 0.034191
[epoch12, step28]: loss 0.037040
[epoch12, step29]: loss 0.038222
[epoch12, step30]: loss 0.037487
[epoch12, step31]: loss 0.034032
[epoch12, step32]: loss 0.035215
[epoch12, step33]: loss 0.036357
[epoch12, step34]: loss 0.034833
[epoch12, step35]: loss 0.037959
[epoch12, step36]: loss 0.034269
[epoch12, step37]: loss 0.034255
[epoch12, step38]: loss 0.037868
[epoch12, step39]: loss 0.037427
[epoch12, step40]: loss 0.035209
[epoch12, step41]: loss 0.033935
[epoch12, step42]: loss 0.036506
[epoch12, step43]: loss 0.034562
[epoch12, step44]: loss 0.038713
[epoch12, step45]: loss 0.034459
[epoch12, step46]: loss 0.035320
[epoch12, step47]: loss 0.037487
[epoch12, step48]: loss 0.036793
[epoch12, step49]: loss 0.034131
[epoch12, step50]: loss 0.034407
[epoch12, step51]: loss 0.037472
[epoch12, step52]: loss 0.034945
[epoch12, step53]: loss 0.037869
[epoch12, step54]: loss 0.032816
[epoch12, step55]: loss 0.034815
[epoch12, step56]: loss 0.037932
[epoch12, step57]: loss 0.037014
[epoch12, step58]: loss 0.034594
[epoch12, step59]: loss 0.034842
[epoch12, step60]: loss 0.038123
[epoch12, step61]: loss 0.034317
[epoch12, step62]: loss 0.036901
[epoch12, step63]: loss 0.034165
[epoch12, step64]: loss 0.034196
[epoch12, step65]: loss 0.037702
[epoch12, step66]: loss 0.036500
[epoch12, step67]: loss 0.034420
[epoch12, step68]: loss 0.034841
[epoch12, step69]: loss 0.037349
[epoch12, step70]: loss 0.034535
[epoch12, step71]: loss 0.037563
[epoch12, step72]: loss 0.034589
[epoch12, step73]: loss 0.035332
[epoch12, step74]: loss 0.036213
[epoch12, step75]: loss 0.037938
[epoch12, step76]: loss 0.035308
[epoch12, step77]: loss 0.035511
[epoch12, step78]: loss 0.037742
[epoch12, step79]: loss 0.033327
[epoch12, step80]: loss 0.038893
[epoch12, step81]: loss 0.033947
[epoch12, step82]: loss 0.034237
[epoch12, step83]: loss 0.036562
[epoch12, step84]: loss 0.037119
[epoch12, step85]: loss 0.036134
[epoch12, step86]: loss 0.035861
[epoch12, step87]: loss 0.038761
[epoch12, step88]: loss 0.034350
[epoch12, step89]: loss 0.037175
[epoch12, step90]: loss 0.035201
[epoch12, step91]: loss 0.035467
[epoch12, step92]: loss 0.037086
[epoch12, step93]: loss 0.038118
[epoch12, step94]: loss 0.033888
[epoch12, step95]: loss 0.034648
[epoch12, step96]: loss 0.036880
[epoch12, step97]: loss 0.034566
[epoch12, step98]: loss 0.036879
[epoch12, step99]: loss 0.034354
[epoch12, step100]: loss 0.033971
[epoch12, step101]: loss 0.037945
[epoch12, step102]: loss 0.037109
[epoch12, step103]: loss 0.034332
[epoch12, step104]: loss 0.034282
[epoch12, step105]: loss 0.037150
[epoch12, step106]: loss 0.034262
[epoch12, step107]: loss 0.036905
[epoch12, step108]: loss 0.034717
[epoch12, step109]: loss 0.034012
[epoch12, step110]: loss 0.038214
[epoch12, step111]: loss 0.036980
[epoch12, step112]: loss 0.033997
[epoch12, step113]: loss 0.035848
[epoch12, step114]: loss 0.036828
[epoch12, step115]: loss 0.034117
[epoch12, step116]: loss 0.039078
[epoch12, step117]: loss 0.033466
[epoch12, step118]: loss 0.035957
[epoch12, step119]: loss 0.036867
[epoch12, step120]: loss 0.038350
[epoch12, step121]: loss 0.034719
[epoch12, step122]: loss 0.034268
[epoch12, step123]: loss 0.037099
[epoch12, step124]: loss 0.034739
[epoch12, step125]: loss 0.036890
[epoch12, step126]: loss 0.034913
[epoch12, step127]: loss 0.033387
[epoch12, step128]: loss 0.037295
[epoch12, step129]: loss 0.037324
[epoch12, step130]: loss 0.035080
[epoch12, step131]: loss 0.036265
[epoch12, step132]: loss 0.037008
[epoch12, step133]: loss 0.035281
[epoch12, step134]: loss 0.037192
[epoch12, step135]: loss 0.035164
[epoch12, step136]: loss 0.036217
[epoch12, step137]: loss 0.037021
[epoch12, step138]: loss 0.037946
[epoch12, step139]: loss 0.036071
[epoch12, step140]: loss 0.034897
[epoch12, step141]: loss 0.038656
[epoch12, step142]: loss 0.035263
[epoch12, step143]: loss 0.036988
[epoch12, step144]: loss 0.035318
[epoch12, step145]: loss 0.036978
[epoch12, step146]: loss 0.038010
[epoch12, step147]: loss 0.038472
[epoch12, step148]: loss 0.036049
[epoch12, step149]: loss 0.034793
[epoch12, step150]: loss 0.037622
[epoch12, step151]: loss 0.035374
[epoch12, step152]: loss 0.037294
[epoch12, step153]: loss 0.034650
[epoch12, step154]: loss 0.035941
[epoch12, step155]: loss 0.037754
[epoch12, step156]: loss 0.036793
[epoch12, step157]: loss 0.035308
[epoch12, step158]: loss 0.037692
[epoch12, step159]: loss 0.038498
[epoch12, step160]: loss 0.037415
[epoch12, step161]: loss 0.037536
[epoch12, step162]: loss 0.038475
[epoch12, step163]: loss 0.038399
[epoch12, step164]: loss 0.039582
[epoch12, step165]: loss 0.038104
[epoch12, step166]: loss 0.037291
[epoch12, step167]: loss 0.034525
[epoch12, step168]: loss 0.037604
[epoch12, step169]: loss 0.036055
[epoch12, step170]: loss 0.038806
[epoch12, step171]: loss 0.035581
[epoch12, step172]: loss 0.036066
[epoch12, step173]: loss 0.039645
[epoch12, step174]: loss 0.039026
[epoch12, step175]: loss 0.036968
[epoch12, step176]: loss 0.036640
[epoch12, step177]: loss 0.039733
[epoch12, step178]: loss 0.036564
[epoch12, step179]: loss 0.037443
[epoch12, step180]: loss 0.036124
[epoch12, step181]: loss 0.036545
[epoch12, step182]: loss 0.039116
[epoch12, step183]: loss 0.039341
[epoch12, step184]: loss 0.037679
[epoch12, step185]: loss 0.036257
[epoch12, step186]: loss 0.038995
[epoch12, step187]: loss 0.036767
[epoch12, step188]: loss 0.037820
[epoch12, step189]: loss 0.035771
[epoch12, step190]: loss 0.035369
[epoch12, step191]: loss 0.038257
[epoch12, step192]: loss 0.038152
[epoch12, step193]: loss 0.033682
[epoch12, step194]: loss 0.034322
[epoch12, step195]: loss 0.038559
[epoch12, step196]: loss 0.036146
[epoch12, step197]: loss 0.037834
[epoch12, step198]: loss 0.034562
[epoch12, step199]: loss 0.036256
[epoch12, step200]: loss 0.039093
[epoch12, step201]: loss 0.038453
[epoch12, step202]: loss 0.035709
[epoch12, step203]: loss 0.035090
[epoch12, step204]: loss 0.038703
[epoch12, step205]: loss 0.035568
[epoch12, step206]: loss 0.037822
[epoch12, step207]: loss 0.035088
[epoch12, step208]: loss 0.035574
[epoch12, step209]: loss 0.038107
[epoch12, step210]: loss 0.038419
[epoch12, step211]: loss 0.036265
[epoch12, step212]: loss 0.035502
[epoch12, step213]: loss 0.038099
[epoch12, step214]: loss 0.035220
[epoch12, step215]: loss 0.038597
[epoch12, step216]: loss 0.035235
[epoch12, step217]: loss 0.034633
[epoch12, step218]: loss 0.038733
[epoch12, step219]: loss 0.038117
[epoch12, step220]: loss 0.036378
[epoch12, step221]: loss 0.035247
[epoch12, step222]: loss 0.038303
[epoch12, step223]: loss 0.036193
[epoch12, step224]: loss 0.037494
[epoch12, step225]: loss 0.034982
[epoch12, step226]: loss 0.035050
[epoch12, step227]: loss 0.037047
[epoch12, step228]: loss 0.038037
[epoch12, step229]: loss 0.034632
[epoch12, step230]: loss 0.035156
[epoch12, step231]: loss 0.038494
[epoch12, step232]: loss 0.035223
[epoch12, step233]: loss 0.037134
[epoch12, step234]: loss 0.034442
[epoch12, step235]: loss 0.036300
[epoch12, step236]: loss 0.038265
[epoch12, step237]: loss 0.038103
[epoch12, step238]: loss 0.035426
[epoch12, step239]: loss 0.034284
[epoch12, step240]: loss 0.037588
[epoch12, step241]: loss 0.036013
[epoch12, step242]: loss 0.038034
[epoch12, step243]: loss 0.035198
[epoch12, step244]: loss 0.035463
[epoch12, step245]: loss 0.038137
[epoch12, step246]: loss 0.037778
[epoch12, step247]: loss 0.035800
[epoch12, step248]: loss 0.034430
[epoch12, step249]: loss 0.037446
[epoch12, step250]: loss 0.035483
[epoch12, step251]: loss 0.038684
[epoch12, step252]: loss 0.035311
[epoch12, step253]: loss 0.035392
[epoch12, step254]: loss 0.037864
[epoch12, step255]: loss 0.037842
[epoch12, step256]: loss 0.035241
[epoch12, step257]: loss 0.034872
[epoch12, step258]: loss 0.038867
[epoch12, step259]: loss 0.035558
[epoch12, step260]: loss 0.037562
[epoch12, step261]: loss 0.035465
[epoch12, step262]: loss 0.035997
[epoch12, step263]: loss 0.037290
[epoch12, step264]: loss 0.037822
[epoch12, step265]: loss 0.035680
[epoch12, step266]: loss 0.034974
[epoch12, step267]: loss 0.037862
[epoch12, step268]: loss 0.035294
[epoch12, step269]: loss 0.038040
[epoch12, step270]: loss 0.034508
[epoch12, step271]: loss 0.035642
[epoch12, step272]: loss 0.038110
[epoch12, step273]: loss 0.037581
[epoch12, step274]: loss 0.036144
[epoch12, step275]: loss 0.034383
[epoch12, step276]: loss 0.037752
[epoch12, step277]: loss 0.035721
[epoch12, step278]: loss 0.038239
[epoch12, step279]: loss 0.034634
[epoch12, step280]: loss 0.035125
[epoch12, step281]: loss 0.037814
[epoch12, step282]: loss 0.037861
[epoch12, step283]: loss 0.034677
[epoch12, step284]: loss 0.034246
[epoch12, step285]: loss 0.038468
[epoch12, step286]: loss 0.034598
[epoch12, step287]: loss 0.037951
[epoch12, step288]: loss 0.034202
[epoch12, step289]: loss 0.036005
[epoch12, step290]: loss 0.037850
[epoch12, step291]: loss 0.038203
[epoch12, step292]: loss 0.034651
[epoch12, step293]: loss 0.034448
[epoch12, step294]: loss 0.037335
[epoch12, step295]: loss 0.034659
[epoch12, step296]: loss 0.038402
[epoch12, step297]: loss 0.034411
[epoch12, step298]: loss 0.035168
[epoch12, step299]: loss 0.037059
[epoch12, step300]: loss 0.037470
[epoch12, step301]: loss 0.035393
[epoch12, step302]: loss 0.035192
[epoch12, step303]: loss 0.038210
[epoch12, step304]: loss 0.034653
[epoch12, step305]: loss 0.037651
[epoch12, step306]: loss 0.035262
[epoch12, step307]: loss 0.034798
[epoch12, step308]: loss 0.038646
[epoch12, step309]: loss 0.038432
[epoch12, step310]: loss 0.035188
[epoch12, step311]: loss 0.035386
[epoch12, step312]: loss 0.037726
[epoch12, step313]: loss 0.035919
[epoch12, step314]: loss 0.038530
[epoch12, step315]: loss 0.035671
[epoch12, step316]: loss 0.034819
[epoch12, step317]: loss 0.038404
[epoch12, step318]: loss 0.037788
[epoch12, step319]: loss 0.034553
[epoch12, step320]: loss 0.033775
[epoch12, step321]: loss 0.037467
[epoch12, step322]: loss 0.035310
[epoch12, step323]: loss 0.037367
[epoch12, step324]: loss 0.035669
[epoch12, step325]: loss 0.035800
[epoch12, step326]: loss 0.037512
[epoch12, step327]: loss 0.037081
[epoch12, step328]: loss 0.035319
[epoch12, step329]: loss 0.034530
[epoch12, step330]: loss 0.037571
[epoch12, step331]: loss 0.035251
[epoch12, step332]: loss 0.037294
[epoch12, step333]: loss 0.034511
[epoch12, step334]: loss 0.035083
[epoch12, step335]: loss 0.037836
[epoch12, step336]: loss 0.038841
[epoch12, step337]: loss 0.035359
[epoch12, step338]: loss 0.034319
[epoch12, step339]: loss 0.037604
[epoch12, step340]: loss 0.035569
[epoch12, step341]: loss 0.037603
[epoch12, step342]: loss 0.034272
[epoch12, step343]: loss 0.035553
[epoch12, step344]: loss 0.037353
[epoch12, step345]: loss 0.037040
[epoch12, step346]: loss 0.034949
[epoch12, step347]: loss 0.034166
[epoch12, step348]: loss 0.037852
[epoch12, step349]: loss 0.035627
[epoch12, step350]: loss 0.037285
[epoch12, step351]: loss 0.034163
[epoch12, step352]: loss 0.035078
[epoch12, step353]: loss 0.037683
[epoch12, step354]: loss 0.036827
[epoch12, step355]: loss 0.034221
[epoch12, step356]: loss 0.035339
[epoch12, step357]: loss 0.038169
[epoch12, step358]: loss 0.033970
[epoch12, step359]: loss 0.039116
[epoch12, step360]: loss 0.033560
[epoch12, step361]: loss 0.034369
[epoch12, step362]: loss 0.038026
[epoch12, step363]: loss 0.036907
[epoch12, step364]: loss 0.034805
[epoch12, step365]: loss 0.034170
[epoch12, step366]: loss 0.037873
[epoch12, step367]: loss 0.034948
[epoch12, step368]: loss 0.036972
[epoch12, step369]: loss 0.034438
[epoch12, step370]: loss 0.035811
[epoch12, step371]: loss 0.038603
[epoch12, step372]: loss 0.037339
[epoch12, step373]: loss 0.034733
[epoch12, step374]: loss 0.033924
[epoch12, step375]: loss 0.037886
[epoch12, step376]: loss 0.034853
[epoch12, step377]: loss 0.037948
[epoch12, step378]: loss 0.034520
[epoch12, step379]: loss 0.035492
[epoch12, step380]: loss 0.037875
[epoch12, step381]: loss 0.036666
[epoch12, step382]: loss 0.035110
[epoch12, step383]: loss 0.033489
[epoch12, step384]: loss 0.037052
[epoch12, step385]: loss 0.035069
[epoch12, step386]: loss 0.037833
[epoch12, step387]: loss 0.035002
[epoch12, step388]: loss 0.036798
[epoch12, step389]: loss 0.038123
[epoch12, step390]: loss 0.037928
[epoch12, step391]: loss 0.035469
[epoch12, step392]: loss 0.036169
[epoch12, step393]: loss 0.037774
[epoch12, step394]: loss 0.035102
[epoch12, step395]: loss 0.037934
[epoch12, step396]: loss 0.035806
[epoch12, step397]: loss 0.036100
[epoch12, step398]: loss 0.037995
[epoch12, step399]: loss 0.037768
[epoch12, step400]: loss 0.035780
[epoch12, step401]: loss 0.035308
[epoch12, step402]: loss 0.037195
[epoch12, step403]: loss 0.034941
[epoch12, step404]: loss 0.038275
[epoch12, step405]: loss 0.035439
[epoch12, step406]: loss 0.035216
[epoch12, step407]: loss 0.037787
[epoch12, step408]: loss 0.039395
[epoch12, step409]: loss 0.037222
[epoch12, step410]: loss 0.035033
[epoch12, step411]: loss 0.037756
[epoch12, step412]: loss 0.035359
[epoch12, step413]: loss 0.037997
[epoch12, step414]: loss 0.034060
[epoch12, step415]: loss 0.035185
[epoch12, step416]: loss 0.037012
[epoch12, step417]: loss 0.037171
[epoch12, step418]: loss 0.034744
[epoch12, step419]: loss 0.034045
[epoch12, step420]: loss 0.037526
[epoch12, step421]: loss 0.034771
[epoch12, step422]: loss 0.037682
[epoch12, step423]: loss 0.034406
[epoch12, step424]: loss 0.035318
[epoch12, step425]: loss 0.038375
[epoch12, step426]: loss 0.037448
[epoch12, step427]: loss 0.035248
[epoch12, step428]: loss 0.034924
[epoch12, step429]: loss 0.038394
[epoch12, step430]: loss 0.034863
[epoch12, step431]: loss 0.037420
[epoch12, step432]: loss 0.035024
[epoch12, step433]: loss 0.036204
[epoch12, step434]: loss 0.037045
[epoch12, step435]: loss 0.037638
[epoch12, step436]: loss 0.034725
[epoch12, step437]: loss 0.034497
[epoch12, step438]: loss 0.038165
[epoch12, step439]: loss 0.035132
[epoch12, step440]: loss 0.037181
[epoch12, step441]: loss 0.034918
[epoch12, step442]: loss 0.034392
[epoch12, step443]: loss 0.037612
[epoch12, step444]: loss 0.036422
[epoch12, step445]: loss 0.034978
[epoch12, step446]: loss 0.034531
[epoch12, step447]: loss 0.037613
[epoch12, step448]: loss 0.034755
[epoch12, step449]: loss 0.036719
[epoch12, step450]: loss 0.033832
[epoch12, step451]: loss 0.034505
[epoch12, step452]: loss 0.036481
[epoch12, step453]: loss 0.037022
[epoch12, step454]: loss 0.034412
[epoch12, step455]: loss 0.034348
[epoch12, step456]: loss 0.036350
[epoch12, step457]: loss 0.035679
[epoch12, step458]: loss 0.037462
[epoch12, step459]: loss 0.034918
[epoch12, step460]: loss 0.034991
[epoch12, step461]: loss 0.038258
[epoch12, step462]: loss 0.036103
[epoch12, step463]: loss 0.034818
[epoch12, step464]: loss 0.033940
[epoch12, step465]: loss 0.038289
[epoch12, step466]: loss 0.034657
[epoch12, step467]: loss 0.036710
[epoch12, step468]: loss 0.034198
[epoch12, step469]: loss 0.034796
[epoch12, step470]: loss 0.037377
[epoch12, step471]: loss 0.036451
[epoch12, step472]: loss 0.035032
[epoch12, step473]: loss 0.034199
[epoch12, step474]: loss 0.036616
[epoch12, step475]: loss 0.034752
[epoch12, step476]: loss 0.037594
[epoch12, step477]: loss 0.034074
[epoch12, step478]: loss 0.033985
[epoch12, step479]: loss 0.036895
[epoch12, step480]: loss 0.036446
[epoch12, step481]: loss 0.034459
[epoch12, step482]: loss 0.033529
[epoch12, step483]: loss 0.037297
[epoch12, step484]: loss 0.034775
[epoch12, step485]: loss 0.037012
[epoch12, step486]: loss 0.034502
[epoch12, step487]: loss 0.034150
[epoch12, step488]: loss 0.037540
[epoch12, step489]: loss 0.035842
[epoch12, step490]: loss 0.035048
[epoch12, step491]: loss 0.034693
[epoch12, step492]: loss 0.036992
[epoch12, step493]: loss 0.034793
[epoch12, step494]: loss 0.036636
[epoch12, step495]: loss 0.035257
[epoch12, step496]: loss 0.034973
[epoch12, step497]: loss 0.037598
[epoch12, step498]: loss 0.036423
[epoch12, step499]: loss 0.034787
[epoch12, step500]: loss 0.033737
[epoch12, step501]: loss 0.036618
[epoch12, step502]: loss 0.034249
[epoch12, step503]: loss 0.037200
[epoch12, step504]: loss 0.034009
[epoch12, step505]: loss 0.033599
[epoch12, step506]: loss 0.037724
[epoch12, step507]: loss 0.037366
[epoch12, step508]: loss 0.034790
[epoch12, step509]: loss 0.034385
[epoch12, step510]: loss 0.037346
[epoch12, step511]: loss 0.035080
[epoch12, step512]: loss 0.037972
[epoch12, step513]: loss 0.034363
[epoch12, step514]: loss 0.035191
[epoch12, step515]: loss 0.037766
[epoch12, step516]: loss 0.037145
[epoch12, step517]: loss 0.034853
[epoch12, step518]: loss 0.035049
[epoch12, step519]: loss 0.037157
[epoch12, step520]: loss 0.034071
[epoch12, step521]: loss 0.036997
[epoch12, step522]: loss 0.034003
[epoch12, step523]: loss 0.034431
[epoch12, step524]: loss 0.037469
[epoch12, step525]: loss 0.037319
[epoch12, step526]: loss 0.034754
[epoch12, step527]: loss 0.034321
[epoch12, step528]: loss 0.037130
[epoch12, step529]: loss 0.034513
[epoch12, step530]: loss 0.038006
[epoch12, step531]: loss 0.033973
[epoch12, step532]: loss 0.034638
[epoch12, step533]: loss 0.038322
[epoch12, step534]: loss 0.036662
[epoch12, step535]: loss 0.035273
[epoch12, step536]: loss 0.034514
[epoch12, step537]: loss 0.036771
[epoch12, step538]: loss 0.034776
[epoch12, step539]: loss 0.036522
[epoch12, step540]: loss 0.033663
[epoch12, step541]: loss 0.034110
[epoch12, step542]: loss 0.037014
[epoch12, step543]: loss 0.036192
[epoch12, step544]: loss 0.034370
[epoch12, step545]: loss 0.033459
[epoch12, step546]: loss 0.037324
[epoch12, step547]: loss 0.034588
[epoch12, step548]: loss 0.037339
[epoch12, step549]: loss 0.034842
[epoch12, step550]: loss 0.035476
[epoch12, step551]: loss 0.037171
[epoch12, step552]: loss 0.036405
[epoch12, step553]: loss 0.035585
[epoch12, step554]: loss 0.034180
[epoch12, step555]: loss 0.036557
[epoch12, step556]: loss 0.034477
[epoch12, step557]: loss 0.036164
[epoch12, step558]: loss 0.034424
[epoch12, step559]: loss 0.033940
[epoch12, step560]: loss 0.037170
[epoch12, step561]: loss 0.036375
[epoch12, step562]: loss 0.034548
[epoch12, step563]: loss 0.035334
[epoch12, step564]: loss 0.039982
[epoch12, step565]: loss 0.039084
[epoch12, step566]: loss 0.045818
[epoch12, step567]: loss 0.038431
[epoch12, step568]: loss 0.038353
[epoch12, step569]: loss 0.035944
[epoch12, step570]: loss 0.044559
[epoch12, step571]: loss 0.038528
[epoch12, step572]: loss 0.037236
[epoch12, step573]: loss 0.040477
[epoch12, step574]: loss 0.041648
[epoch12, step575]: loss 0.032104
[epoch12, step576]: loss 0.033063
[epoch12, step577]: loss 0.036516
[epoch12, step578]: loss 0.029237
[epoch12, step579]: loss 0.039325
[epoch12, step580]: loss 0.029966
[epoch12, step581]: loss 0.037218
[epoch12, step582]: loss 0.036011
[epoch12, step583]: loss 0.035309
[epoch12, step584]: loss 0.033852
[epoch12, step585]: loss 0.035822
[epoch12, step586]: loss 0.034455
[epoch12, step587]: loss 0.041063
[epoch12, step588]: loss 0.035163
[epoch12, step589]: loss 0.038077
[epoch12, step590]: loss 0.039900
[epoch12, step591]: loss 0.033427
[epoch12, step592]: loss 0.037636
[epoch12, step593]: loss 0.032470
[epoch12, step594]: loss 0.037659
[epoch12, step595]: loss 0.038838
[epoch12, step596]: loss 0.036710
[epoch12, step597]: loss 0.036546
[epoch12, step598]: loss 0.036535
[epoch12, step599]: loss 0.035103
[epoch12, step600]: loss 0.038068
[epoch12, step601]: loss 0.030435
[epoch12, step602]: loss 0.032865
[epoch12, step603]: loss 0.036633
[epoch12, step604]: loss 0.038177
[epoch12, step605]: loss 0.035883
[epoch12, step606]: loss 0.033899
[epoch12, step607]: loss 0.038484
[epoch12, step608]: loss 0.037613
[epoch12, step609]: loss 0.037230
[epoch12, step610]: loss 0.039357
[epoch12, step611]: loss 0.038695
[epoch12, step612]: loss 0.035425
[epoch12, step613]: loss 0.030286
[epoch12, step614]: loss 0.035482
[epoch12, step615]: loss 0.040829
[epoch12, step616]: loss 0.034723
[epoch12, step617]: loss 0.034059
[epoch12, step618]: loss 0.037653
[epoch12, step619]: loss 0.038637
[epoch12, step620]: loss 0.035029
[epoch12, step621]: loss 0.037756
[epoch12, step622]: loss 0.031362
[epoch12, step623]: loss 0.034044
[epoch12, step624]: loss 0.037466
[epoch12, step625]: loss 0.036351
[epoch12, step626]: loss 0.039493
[epoch12, step627]: loss 0.033550
[epoch12, step628]: loss 0.035929
[epoch12, step629]: loss 0.031384
[epoch12, step630]: loss 0.032850
[epoch12, step631]: loss 0.042142
[epoch12, step632]: loss 0.034679
[epoch12, step633]: loss 0.035178
[epoch12, step634]: loss 0.036765
[epoch12, step635]: loss 0.037011
[epoch12, step636]: loss 0.032442
[epoch12, step637]: loss 0.038541
[epoch12, step638]: loss 0.038726
[epoch12, step639]: loss 0.032677
[epoch12, step640]: loss 0.040500
[epoch12, step641]: loss 0.040925
[epoch12, step642]: loss 0.036231
[epoch12, step643]: loss 0.034715
[epoch12, step644]: loss 0.038003
[epoch12, step645]: loss 0.034527
[epoch12, step646]: loss 0.035715
[epoch12, step647]: loss 0.034372
[epoch12, step648]: loss 0.035387
[epoch12, step649]: loss 0.038486
[epoch12, step650]: loss 0.033647
[epoch12, step651]: loss 0.037681
[epoch12, step652]: loss 0.038642
[epoch12, step653]: loss 0.038873
[epoch12, step654]: loss 0.033754
[epoch12, step655]: loss 0.034917
[epoch12, step656]: loss 0.033270
[epoch12, step657]: loss 0.038144
[epoch12, step658]: loss 0.035493
[epoch12, step659]: loss 0.037622
[epoch12, step660]: loss 0.033565
[epoch12, step661]: loss 0.036446
[epoch12, step662]: loss 0.034383
[epoch12, step663]: loss 0.032437
[epoch12, step664]: loss 0.036525
[epoch12, step665]: loss 0.037537
[epoch12, step666]: loss 0.037233
[epoch12, step667]: loss 0.037328
[epoch12, step668]: loss 0.034102
[epoch12, step669]: loss 0.037621
[epoch12, step670]: loss 0.037616
[epoch12, step671]: loss 0.031998
[epoch12, step672]: loss 0.034996
[epoch12, step673]: loss 0.033319
[epoch12, step674]: loss 0.031619
[epoch12, step675]: loss 0.031032
[epoch12, step676]: loss 0.033395
[epoch12, step677]: loss 0.035665
[epoch12, step678]: loss 0.033470
[epoch12, step679]: loss 0.035073
[epoch12, step680]: loss 0.040950
[epoch12, step681]: loss 0.032083
[epoch12, step682]: loss 0.036106
[epoch12, step683]: loss 0.035555
[epoch12, step684]: loss 0.035585
[epoch12, step685]: loss 0.035605
[epoch12, step686]: loss 0.038921
[epoch12, step687]: loss 0.036572
[epoch12, step688]: loss 0.034925
[epoch12, step689]: loss 0.035888
[epoch12, step690]: loss 0.035844
[epoch12, step691]: loss 0.035782
[epoch12, step692]: loss 0.034558
[epoch12, step693]: loss 0.039552
[epoch12, step694]: loss 0.032604
[epoch12, step695]: loss 0.038354
[epoch12, step696]: loss 0.035303
[epoch12, step697]: loss 0.037914
[epoch12, step698]: loss 0.035600
[epoch12, step699]: loss 0.034106
[epoch12, step700]: loss 0.031504
[epoch12, step701]: loss 0.036274
[epoch12, step702]: loss 0.031714
[epoch12, step703]: loss 0.034409
[epoch12, step704]: loss 0.036721
[epoch12, step705]: loss 0.036749
[epoch12, step706]: loss 0.034493
[epoch12, step707]: loss 0.033362
[epoch12, step708]: loss 0.035430
[epoch12, step709]: loss 0.037548
[epoch12, step710]: loss 0.033393
[epoch12, step711]: loss 0.037019
[epoch12, step712]: loss 0.037314
[epoch12, step713]: loss 0.037959
[epoch12, step714]: loss 0.032092
[epoch12, step715]: loss 0.033874
[epoch12, step716]: loss 0.035825
[epoch12, step717]: loss 0.033463
[epoch12, step718]: loss 0.036363
[epoch12, step719]: loss 0.045641
[epoch12, step720]: loss 0.035017
[epoch12, step721]: loss 0.033413
[epoch12, step722]: loss 0.041374
[epoch12, step723]: loss 0.037437
[epoch12, step724]: loss 0.033092
[epoch12, step725]: loss 0.037294
[epoch12, step726]: loss 0.032420
[epoch12, step727]: loss 0.034469
[epoch12, step728]: loss 0.037473
[epoch12, step729]: loss 0.032289
[epoch12, step730]: loss 0.033130
[epoch12, step731]: loss 0.036578
[epoch12, step732]: loss 0.036350
[epoch12, step733]: loss 0.034531
[epoch12, step734]: loss 0.034580
[epoch12, step735]: loss 0.038207
[epoch12, step736]: loss 0.036038
[epoch12, step737]: loss 0.037559
[epoch12, step738]: loss 0.030811
[epoch12, step739]: loss 0.036860
[epoch12, step740]: loss 0.033021
[epoch12, step741]: loss 0.036630
[epoch12, step742]: loss 0.033001
[epoch12, step743]: loss 0.034117
[epoch12, step744]: loss 0.033875
[epoch12, step745]: loss 0.033843
[epoch12, step746]: loss 0.036544
[epoch12, step747]: loss 0.039062
[epoch12, step748]: loss 0.036563
[epoch12, step749]: loss 0.035956
[epoch12, step750]: loss 0.038460
[epoch12, step751]: loss 0.033306
[epoch12, step752]: loss 0.035272
[epoch12, step753]: loss 0.035687
[epoch12, step754]: loss 0.034135
[epoch12, step755]: loss 0.036126
[epoch12, step756]: loss 0.034144
[epoch12, step757]: loss 0.030059
[epoch12, step758]: loss 0.034598
[epoch12, step759]: loss 0.033352
[epoch12, step760]: loss 0.034590
[epoch12, step761]: loss 0.037771
[epoch12, step762]: loss 0.031581
[epoch12, step763]: loss 0.035633
[epoch12, step764]: loss 0.035192
[epoch12, step765]: loss 0.036781
[epoch12, step766]: loss 0.036483
[epoch12, step767]: loss 0.039036
[epoch12, step768]: loss 0.031544
[epoch12, step769]: loss 0.036528
[epoch12, step770]: loss 0.035264
[epoch12, step771]: loss 0.033414
[epoch12, step772]: loss 0.038795
[epoch12, step773]: loss 0.036191
[epoch12, step774]: loss 0.035566
[epoch12, step775]: loss 0.029805
[epoch12, step776]: loss 0.037894
[epoch12, step777]: loss 0.033751
[epoch12, step778]: loss 0.037598
[epoch12, step779]: loss 0.035183
[epoch12, step780]: loss 0.030165
[epoch12, step781]: loss 0.035167
[epoch12, step782]: loss 0.032426
[epoch12, step783]: loss 0.030714
[epoch12, step784]: loss 0.031374
[epoch12, step785]: loss 0.031732
[epoch12, step786]: loss 0.034636
[epoch12, step787]: loss 0.034831
[epoch12, step788]: loss 0.036523
[epoch12, step789]: loss 0.035019
[epoch12, step790]: loss 0.034391
[epoch12, step791]: loss 0.038224
[epoch12, step792]: loss 0.035682
[epoch12, step793]: loss 0.037395
[epoch12, step794]: loss 0.030510
[epoch12, step795]: loss 0.035153
[epoch12, step796]: loss 0.038205
[epoch12, step797]: loss 0.037373
[epoch12, step798]: loss 0.037604
[epoch12, step799]: loss 0.037509
[epoch12, step800]: loss 0.031337
[epoch12, step801]: loss 0.033950
[epoch12, step802]: loss 0.033350
[epoch12, step803]: loss 0.037534
[epoch12, step804]: loss 0.037520
[epoch12, step805]: loss 0.037889
[epoch12, step806]: loss 0.032825
[epoch12, step807]: loss 0.031472
[epoch12, step808]: loss 0.034030
[epoch12, step809]: loss 0.032364
[epoch12, step810]: loss 0.036142
[epoch12, step811]: loss 0.035287
[epoch12, step812]: loss 0.033491
[epoch12, step813]: loss 0.033903
[epoch12, step814]: loss 0.036808
[epoch12, step815]: loss 0.033856
[epoch12, step816]: loss 0.034436
[epoch12, step817]: loss 0.035679
[epoch12, step818]: loss 0.032687
[epoch12, step819]: loss 0.031368
[epoch12, step820]: loss 0.034393
[epoch12, step821]: loss 0.032096
[epoch12, step822]: loss 0.039905
[epoch12, step823]: loss 0.033852
[epoch12, step824]: loss 0.036527
[epoch12, step825]: loss 0.036480
[epoch12, step826]: loss 0.034935
[epoch12, step827]: loss 0.037854
[epoch12, step828]: loss 0.039644
[epoch12, step829]: loss 0.038937
[epoch12, step830]: loss 0.033404
[epoch12, step831]: loss 0.037172
[epoch12, step832]: loss 0.031601
[epoch12, step833]: loss 0.038754
[epoch12, step834]: loss 0.036811
[epoch12, step835]: loss 0.031285
[epoch12, step836]: loss 0.039238
[epoch12, step837]: loss 0.036259
[epoch12, step838]: loss 0.034761
[epoch12, step839]: loss 0.039193
[epoch12, step840]: loss 0.031684
[epoch12, step841]: loss 0.035517
[epoch12, step842]: loss 0.037243
[epoch12, step843]: loss 0.035786
[epoch12, step844]: loss 0.035756
[epoch12, step845]: loss 0.031870
[epoch12, step846]: loss 0.038964
[epoch12, step847]: loss 0.037163
[epoch12, step848]: loss 0.035796
[epoch12, step849]: loss 0.033925
[epoch12, step850]: loss 0.033539
[epoch12, step851]: loss 0.035367
[epoch12, step852]: loss 0.033264
[epoch12, step853]: loss 0.040291
[epoch12, step854]: loss 0.033925
[epoch12, step855]: loss 0.037481
[epoch12, step856]: loss 0.031783
[epoch12, step857]: loss 0.034196
[epoch12, step858]: loss 0.034722
[epoch12, step859]: loss 0.034271
[epoch12, step860]: loss 0.032680
[epoch12, step861]: loss 0.032511
[epoch12, step862]: loss 0.032765
[epoch12, step863]: loss 0.031724
[epoch12, step864]: loss 0.036917
[epoch12, step865]: loss 0.034120
[epoch12, step866]: loss 0.035275
[epoch12, step867]: loss 0.036703
[epoch12, step868]: loss 0.036578
[epoch12, step869]: loss 0.034078
[epoch12, step870]: loss 0.041463
[epoch12, step871]: loss 0.033439
[epoch12, step872]: loss 0.035919
[epoch12, step873]: loss 0.035791
[epoch12, step874]: loss 0.034921
[epoch12, step875]: loss 0.034148
[epoch12, step876]: loss 0.036419
[epoch12, step877]: loss 0.030135
[epoch12, step878]: loss 0.033469
[epoch12, step879]: loss 0.037701
[epoch12, step880]: loss 0.036487
[epoch12, step881]: loss 0.032629
[epoch12, step882]: loss 0.034200
[epoch12, step883]: loss 0.034144
[epoch12, step884]: loss 0.037088
[epoch12, step885]: loss 0.035241
[epoch12, step886]: loss 0.035918
[epoch12, step887]: loss 0.035255
[epoch12, step888]: loss 0.035482
[epoch12, step889]: loss 0.034794
[epoch12, step890]: loss 0.034051
[epoch12, step891]: loss 0.036017
[epoch12, step892]: loss 0.030579
[epoch12, step893]: loss 0.034451
[epoch12, step894]: loss 0.035547
[epoch12, step895]: loss 0.032267
[epoch12, step896]: loss 0.032851
[epoch12, step897]: loss 0.035724
[epoch12, step898]: loss 0.036921
[epoch12, step899]: loss 0.038985
[epoch12, step900]: loss 0.036420
[epoch12, step901]: loss 0.036944
[epoch12, step902]: loss 0.034551
[epoch12, step903]: loss 0.034957
[epoch12, step904]: loss 0.037623
[epoch12, step905]: loss 0.038226
[epoch12, step906]: loss 0.031638
[epoch12, step907]: loss 0.033893
[epoch12, step908]: loss 0.031491
[epoch12, step909]: loss 0.037591
[epoch12, step910]: loss 0.033788
[epoch12, step911]: loss 0.035658
[epoch12, step912]: loss 0.033187
[epoch12, step913]: loss 0.034650
[epoch12, step914]: loss 0.039476
[epoch12, step915]: loss 0.034278
[epoch12, step916]: loss 0.033572
[epoch12, step917]: loss 0.035350
[epoch12, step918]: loss 0.039882
[epoch12, step919]: loss 0.035201
[epoch12, step920]: loss 0.037826
[epoch12, step921]: loss 0.034038
[epoch12, step922]: loss 0.034368
[epoch12, step923]: loss 0.033225
[epoch12, step924]: loss 0.030129
[epoch12, step925]: loss 0.035986
[epoch12, step926]: loss 0.035036
[epoch12, step927]: loss 0.035462
[epoch12, step928]: loss 0.034755
[epoch12, step929]: loss 0.038551
[epoch12, step930]: loss 0.036751
[epoch12, step931]: loss 0.037207
[epoch12, step932]: loss 0.031761
[epoch12, step933]: loss 0.038888
[epoch12, step934]: loss 0.032426
[epoch12, step935]: loss 0.033932
[epoch12, step936]: loss 0.032319
[epoch12, step937]: loss 0.036401
[epoch12, step938]: loss 0.038060
[epoch12, step939]: loss 0.031405
[epoch12, step940]: loss 0.034025
[epoch12, step941]: loss 0.038237
[epoch12, step942]: loss 0.036065
[epoch12, step943]: loss 0.033857
[epoch12, step944]: loss 0.038534
[epoch12, step945]: loss 0.031227
[epoch12, step946]: loss 0.035470
[epoch12, step947]: loss 0.039035
[epoch12, step948]: loss 0.030184
[epoch12, step949]: loss 0.033870
[epoch12, step950]: loss 0.038114
[epoch12, step951]: loss 0.039576
[epoch12, step952]: loss 0.034643
[epoch12, step953]: loss 0.037275
[epoch12, step954]: loss 0.033231
[epoch12, step955]: loss 0.041771
[epoch12, step956]: loss 0.051527
[epoch12, step957]: loss 0.047897
[epoch12, step958]: loss 0.045470
[epoch12, step959]: loss 0.049378
[epoch12, step960]: loss 0.046779
[epoch12, step961]: loss 0.046789
[epoch12, step962]: loss 0.045496
[epoch12, step963]: loss 0.043463
[epoch12, step964]: loss 0.044508
[epoch12, step965]: loss 0.046509
[epoch12, step966]: loss 0.044622
[epoch12, step967]: loss 0.042741
[epoch12, step968]: loss 0.044284
[epoch12, step969]: loss 0.044578
[epoch12, step970]: loss 0.043730
[epoch12, step971]: loss 0.043765
[epoch12, step972]: loss 0.043515
[epoch12, step973]: loss 0.043451
[epoch12, step974]: loss 0.045806
[epoch12, step975]: loss 0.043418
[epoch12, step976]: loss 0.042122
[epoch12, step977]: loss 0.044213
[epoch12, step978]: loss 0.043518
[epoch12, step979]: loss 0.042424
[epoch12, step980]: loss 0.041784
[epoch12, step981]: loss 0.043299
[epoch12, step982]: loss 0.042287
[epoch12, step983]: loss 0.043612
[epoch12, step984]: loss 0.042222
[epoch12, step985]: loss 0.042240
[epoch12, step986]: loss 0.043811
[epoch12, step987]: loss 0.042780
[epoch12, step988]: loss 0.043561
[epoch12, step989]: loss 0.042698
[epoch12, step990]: loss 0.042378
[epoch12, step991]: loss 0.042544
[epoch12, step992]: loss 0.042867
[epoch12, step993]: loss 0.042323
[epoch12, step994]: loss 0.040675
[epoch12, step995]: loss 0.043298
[epoch12, step996]: loss 0.042685
[epoch12, step997]: loss 0.042404
[epoch12, step998]: loss 0.042628
[epoch12, step999]: loss 0.042314
[epoch12, step1000]: loss 0.042857
[epoch12, step1001]: loss 0.043118
[epoch12, step1002]: loss 0.041966
[epoch12, step1003]: loss 0.041749
[epoch12, step1004]: loss 0.043052
[epoch12, step1005]: loss 0.042212
[epoch12, step1006]: loss 0.042302
[epoch12, step1007]: loss 0.041393
[epoch12, step1008]: loss 0.042104
[epoch12, step1009]: loss 0.042536
[epoch12, step1010]: loss 0.042898
[epoch12, step1011]: loss 0.041752
[epoch12, step1012]: loss 0.041089
[epoch12, step1013]: loss 0.042756
[epoch12, step1014]: loss 0.042270
[epoch12, step1015]: loss 0.042240
[epoch12, step1016]: loss 0.041220
[epoch12, step1017]: loss 0.041567
[epoch12, step1018]: loss 0.041737
[epoch12, step1019]: loss 0.042737
[epoch12, step1020]: loss 0.041679
[epoch12, step1021]: loss 0.040760
[epoch12, step1022]: loss 0.042286
[epoch12, step1023]: loss 0.042247
[epoch12, step1024]: loss 0.043263
[epoch12, step1025]: loss 0.041043
[epoch12, step1026]: loss 0.041371
[epoch12, step1027]: loss 0.042478
[epoch12, step1028]: loss 0.042016
[epoch12, step1029]: loss 0.041682
[epoch12, step1030]: loss 0.040214
[epoch12, step1031]: loss 0.042528
[epoch12, step1032]: loss 0.041963
[epoch12, step1033]: loss 0.041543
[epoch12, step1034]: loss 0.040909
[epoch12, step1035]: loss 0.041301
[epoch12, step1036]: loss 0.041785
[epoch12, step1037]: loss 0.042002
[epoch12, step1038]: loss 0.041299
[epoch12, step1039]: loss 0.041176
[epoch12, step1040]: loss 0.042667
[epoch12, step1041]: loss 0.041544
[epoch12, step1042]: loss 0.041909
[epoch12, step1043]: loss 0.041523
[epoch12, step1044]: loss 0.042356
[epoch12, step1045]: loss 0.042008
[epoch12, step1046]: loss 0.042750
[epoch12, step1047]: loss 0.041741
[epoch12, step1048]: loss 0.040978
[epoch12, step1049]: loss 0.043726
[epoch12, step1050]: loss 0.042128
[epoch12, step1051]: loss 0.041804
[epoch12, step1052]: loss 0.041446
[epoch12, step1053]: loss 0.041983
[epoch12, step1054]: loss 0.042134
[epoch12, step1055]: loss 0.042175
[epoch12, step1056]: loss 0.040308
[epoch12, step1057]: loss 0.041085
[epoch12, step1058]: loss 0.043368
[epoch12, step1059]: loss 0.042276
[epoch12, step1060]: loss 0.041839
[epoch12, step1061]: loss 0.040796
[epoch12, step1062]: loss 0.042475
[epoch12, step1063]: loss 0.042447
[epoch12, step1064]: loss 0.042719
[epoch12, step1065]: loss 0.041264
[epoch12, step1066]: loss 0.040561
[epoch12, step1067]: loss 0.042971
[epoch12, step1068]: loss 0.040853
[epoch12, step1069]: loss 0.041462
[epoch12, step1070]: loss 0.040871
[epoch12, step1071]: loss 0.042122
[epoch12, step1072]: loss 0.041997
[epoch12, step1073]: loss 0.042176
[epoch12, step1074]: loss 0.041166
[epoch12, step1075]: loss 0.040314
[epoch12, step1076]: loss 0.042484
[epoch12, step1077]: loss 0.041739
[epoch12, step1078]: loss 0.042207
[epoch12, step1079]: loss 0.041918
[epoch12, step1080]: loss 0.041773
[epoch12, step1081]: loss 0.041472
[epoch12, step1082]: loss 0.042070
[epoch12, step1083]: loss 0.041584
[epoch12, step1084]: loss 0.040354
[epoch12, step1085]: loss 0.041769
[epoch12, step1086]: loss 0.041115
[epoch12, step1087]: loss 0.041600
[epoch12, step1088]: loss 0.040740
[epoch12, step1089]: loss 0.041751
[epoch12, step1090]: loss 0.042262
[epoch12, step1091]: loss 0.042192
[epoch12, step1092]: loss 0.040849
[epoch12, step1093]: loss 0.040232
[epoch12, step1094]: loss 0.041933
[epoch12, step1095]: loss 0.041132
[epoch12, step1096]: loss 0.040714
[epoch12, step1097]: loss 0.041532
[epoch12, step1098]: loss 0.041079
[epoch12, step1099]: loss 0.042205
[epoch12, step1100]: loss 0.043293
[epoch12, step1101]: loss 0.041539
[epoch12, step1102]: loss 0.040757
[epoch12, step1103]: loss 0.042584
[epoch12, step1104]: loss 0.041085
[epoch12, step1105]: loss 0.042161
[epoch12, step1106]: loss 0.040813
[epoch12, step1107]: loss 0.040951
[epoch12, step1108]: loss 0.040808
[epoch12, step1109]: loss 0.041815
[epoch12, step1110]: loss 0.041723
[epoch12, step1111]: loss 0.040309
[epoch12, step1112]: loss 0.042188
[epoch12, step1113]: loss 0.041101
[epoch12, step1114]: loss 0.041113
[epoch12, step1115]: loss 0.041237
[epoch12, step1116]: loss 0.041178
[epoch12, step1117]: loss 0.041375
[epoch12, step1118]: loss 0.042376
[epoch12, step1119]: loss 0.041040
[epoch12, step1120]: loss 0.040280
[epoch12, step1121]: loss 0.042111
[epoch12, step1122]: loss 0.042745
[epoch12, step1123]: loss 0.040605
[epoch12, step1124]: loss 0.041991
[epoch12, step1125]: loss 0.042444
[epoch12, step1126]: loss 0.042617
[epoch12, step1127]: loss 0.041894
[epoch12, step1128]: loss 0.041603
[epoch12, step1129]: loss 0.040070
[epoch12, step1130]: loss 0.042791
[epoch12, step1131]: loss 0.042318
[epoch12, step1132]: loss 0.041202
[epoch12, step1133]: loss 0.040004
[epoch12, step1134]: loss 0.041224
[epoch12, step1135]: loss 0.042253
[epoch12, step1136]: loss 0.042948
[epoch12, step1137]: loss 0.041250
[epoch12, step1138]: loss 0.040251
[epoch12, step1139]: loss 0.043064
[epoch12, step1140]: loss 0.041750
[epoch12, step1141]: loss 0.040999
[epoch12, step1142]: loss 0.042363
[epoch12, step1143]: loss 0.041859
[epoch12, step1144]: loss 0.041318
[epoch12, step1145]: loss 0.042714
[epoch12, step1146]: loss 0.041996
[epoch12, step1147]: loss 0.040764
[epoch12, step1148]: loss 0.043734
[epoch12, step1149]: loss 0.042465
[epoch12, step1150]: loss 0.041319
[epoch12, step1151]: loss 0.041132
[epoch12, step1152]: loss 0.042409
[epoch12, step1153]: loss 0.041393
[epoch12, step1154]: loss 0.041917
[epoch12, step1155]: loss 0.041850
[epoch12, step1156]: loss 0.041068
[epoch12, step1157]: loss 0.042919
[epoch12, step1158]: loss 0.041548
[epoch12, step1159]: loss 0.041684
[epoch12, step1160]: loss 0.041301
[epoch12, step1161]: loss 0.042290
[epoch12, step1162]: loss 0.041902
[epoch12, step1163]: loss 0.041077
[epoch12, step1164]: loss 0.040681
[epoch12, step1165]: loss 0.040602
[epoch12, step1166]: loss 0.042352
[epoch12, step1167]: loss 0.041468
[epoch12, step1168]: loss 0.041052
[epoch12, step1169]: loss 0.040587
[epoch12, step1170]: loss 0.041084
[epoch12, step1171]: loss 0.041124
[epoch12, step1172]: loss 0.043435
[epoch12, step1173]: loss 0.041250
[epoch12, step1174]: loss 0.041058
[epoch12, step1175]: loss 0.041842
[epoch12, step1176]: loss 0.041327
[epoch12, step1177]: loss 0.041957
[epoch12, step1178]: loss 0.040915
[epoch12, step1179]: loss 0.040759
[epoch12, step1180]: loss 0.041512
[epoch12, step1181]: loss 0.042723
[epoch12, step1182]: loss 0.041174
[epoch12, step1183]: loss 0.040605
[epoch12, step1184]: loss 0.041854
[epoch12, step1185]: loss 0.041666
[epoch12, step1186]: loss 0.041709
[epoch12, step1187]: loss 0.040265
[epoch12, step1188]: loss 0.041669
[epoch12, step1189]: loss 0.041772
[epoch12, step1190]: loss 0.042420
[epoch12, step1191]: loss 0.042368
[epoch12, step1192]: loss 0.040145
[epoch12, step1193]: loss 0.042454
[epoch12, step1194]: loss 0.042382
[epoch12, step1195]: loss 0.040602
[epoch12, step1196]: loss 0.040158
[epoch12, step1197]: loss 0.041484
[epoch12, step1198]: loss 0.041253
[epoch12, step1199]: loss 0.041200
[epoch12, step1200]: loss 0.041387
[epoch12, step1201]: loss 0.040155
[epoch12, step1202]: loss 0.042700
[epoch12, step1203]: loss 0.041564
[epoch12, step1204]: loss 0.041327
[epoch12, step1205]: loss 0.040742
[epoch12, step1206]: loss 0.040489
[epoch12, step1207]: loss 0.041706
[epoch12, step1208]: loss 0.042064
[epoch12, step1209]: loss 0.040571
[epoch12, step1210]: loss 0.040592
[epoch12, step1211]: loss 0.042369
[epoch12, step1212]: loss 0.041516
[epoch12, step1213]: loss 0.041485
[epoch12, step1214]: loss 0.040801
[epoch12, step1215]: loss 0.042012
[epoch12, step1216]: loss 0.041992
[epoch12, step1217]: loss 0.042222
[epoch12, step1218]: loss 0.040663
[epoch12, step1219]: loss 0.040922
[epoch12, step1220]: loss 0.042874
[epoch12, step1221]: loss 0.041057
[epoch12, step1222]: loss 0.041457
[epoch12, step1223]: loss 0.040552
[epoch12, step1224]: loss 0.041386
[epoch12, step1225]: loss 0.041516
[epoch12, step1226]: loss 0.042432
[epoch12, step1227]: loss 0.041270
[epoch12, step1228]: loss 0.040217
[epoch12, step1229]: loss 0.042932
[epoch12, step1230]: loss 0.041455
[epoch12, step1231]: loss 0.041235
[epoch12, step1232]: loss 0.041800
[epoch12, step1233]: loss 0.041260
[epoch12, step1234]: loss 0.041563
[epoch12, step1235]: loss 0.042143
[epoch12, step1236]: loss 0.041223
[epoch12, step1237]: loss 0.040336
[epoch12, step1238]: loss 0.041360
[epoch12, step1239]: loss 0.041622
[epoch12, step1240]: loss 0.041874
[epoch12, step1241]: loss 0.040338
[epoch12, step1242]: loss 0.041181
[epoch12, step1243]: loss 0.041964
[epoch12, step1244]: loss 0.041720
[epoch12, step1245]: loss 0.041212
[epoch12, step1246]: loss 0.040842
[epoch12, step1247]: loss 0.041968
[epoch12, step1248]: loss 0.041677
[epoch12, step1249]: loss 0.041741
[epoch12, step1250]: loss 0.040314
[epoch12, step1251]: loss 0.041138
[epoch12, step1252]: loss 0.043092
[epoch12, step1253]: loss 0.041949
[epoch12, step1254]: loss 0.041146
[epoch12, step1255]: loss 0.041513
[epoch12, step1256]: loss 0.042556
[epoch12, step1257]: loss 0.041007
[epoch12, step1258]: loss 0.040885
[epoch12, step1259]: loss 0.040497
[epoch12, step1260]: loss 0.041768
[epoch12, step1261]: loss 0.041223
[epoch12, step1262]: loss 0.040888
[epoch12, step1263]: loss 0.041302
[epoch12, step1264]: loss 0.041498
[epoch12, step1265]: loss 0.041374
[epoch12, step1266]: loss 0.040900
[epoch12, step1267]: loss 0.041147
[epoch12, step1268]: loss 0.040672
[epoch12, step1269]: loss 0.041345
[epoch12, step1270]: loss 0.041363
[epoch12, step1271]: loss 0.041862
[epoch12, step1272]: loss 0.041271
[epoch12, step1273]: loss 0.040370
[epoch12, step1274]: loss 0.042265
[epoch12, step1275]: loss 0.041755
[epoch12, step1276]: loss 0.041941
[epoch12, step1277]: loss 0.040479
[epoch12, step1278]: loss 0.041531
[epoch12, step1279]: loss 0.041940
[epoch12, step1280]: loss 0.041920
[epoch12, step1281]: loss 0.040725
[epoch12, step1282]: loss 0.040263
[epoch12, step1283]: loss 0.041533
[epoch12, step1284]: loss 0.041502
[epoch12, step1285]: loss 0.041249
[epoch12, step1286]: loss 0.039988
[epoch12, step1287]: loss 0.041946
[epoch12, step1288]: loss 0.041645
[epoch12, step1289]: loss 0.042181
[epoch12, step1290]: loss 0.041218
[epoch12, step1291]: loss 0.040118
[epoch12, step1292]: loss 0.042416
[epoch12, step1293]: loss 0.040919
[epoch12, step1294]: loss 0.041013
[epoch12, step1295]: loss 0.041511
[epoch12, step1296]: loss 0.041732
[epoch12, step1297]: loss 0.041494
[epoch12, step1298]: loss 0.043018
[epoch12, step1299]: loss 0.042659
[epoch12, step1300]: loss 0.041841
[epoch12, step1301]: loss 0.041893
[epoch12, step1302]: loss 0.042130
[epoch12, step1303]: loss 0.041278
[epoch12, step1304]: loss 0.040149
[epoch12, step1305]: loss 0.041156
[epoch12, step1306]: loss 0.041667
[epoch12, step1307]: loss 0.042148
[epoch12, step1308]: loss 0.041486
[epoch12, step1309]: loss 0.040824
[epoch12, step1310]: loss 0.042885
[epoch12, step1311]: loss 0.040994
[epoch12, step1312]: loss 0.041605
[epoch12, step1313]: loss 0.040418
[epoch12, step1314]: loss 0.041760
[epoch12, step1315]: loss 0.041401
[epoch12, step1316]: loss 0.042729
[epoch12, step1317]: loss 0.040265
[epoch12, step1318]: loss 0.040196
[epoch12, step1319]: loss 0.042203
[epoch12, step1320]: loss 0.041444
[epoch12, step1321]: loss 0.041420
[epoch12, step1322]: loss 0.040554
[epoch12, step1323]: loss 0.041831
[epoch12, step1324]: loss 0.041695
[epoch12, step1325]: loss 0.041219
[epoch12, step1326]: loss 0.040590
[epoch12, step1327]: loss 0.040384
[epoch12, step1328]: loss 0.043465
[epoch12, step1329]: loss 0.041715
[epoch12, step1330]: loss 0.040560
[epoch12, step1331]: loss 0.040582
[epoch12, step1332]: loss 0.040690
[epoch12, step1333]: loss 0.041346
[epoch12, step1334]: loss 0.042231
[epoch12, step1335]: loss 0.041201
[epoch12, step1336]: loss 0.040258
[epoch12, step1337]: loss 0.042415
[epoch12, step1338]: loss 0.040816
[epoch12, step1339]: loss 0.041562
[epoch12, step1340]: loss 0.040183
[epoch12, step1341]: loss 0.041468
[epoch12, step1342]: loss 0.041434
[epoch12, step1343]: loss 0.041779
[epoch12, step1344]: loss 0.040775
[epoch12, step1345]: loss 0.040210
[epoch12, step1346]: loss 0.042137
[epoch12, step1347]: loss 0.041287
[epoch12, step1348]: loss 0.041274
[epoch12, step1349]: loss 0.041387
[epoch12, step1350]: loss 0.042089
[epoch12, step1351]: loss 0.040913
[epoch12, step1352]: loss 0.042395
[epoch12, step1353]: loss 0.042409
[epoch12, step1354]: loss 0.040359
[epoch12, step1355]: loss 0.041940
[epoch12, step1356]: loss 0.041231
[epoch12, step1357]: loss 0.040903
[epoch12, step1358]: loss 0.040440
[epoch12, step1359]: loss 0.041217
[epoch12, step1360]: loss 0.041140
[epoch12, step1361]: loss 0.042276
[epoch12, step1362]: loss 0.041606
[epoch12, step1363]: loss 0.040678
[epoch12, step1364]: loss 0.041623
[epoch12, step1365]: loss 0.041577
[epoch12, step1366]: loss 0.042323
[epoch12, step1367]: loss 0.040856
[epoch12, step1368]: loss 0.041166
[epoch12, step1369]: loss 0.041963
[epoch12, step1370]: loss 0.041248
[epoch12, step1371]: loss 0.040622
[epoch12, step1372]: loss 0.039861
[epoch12, step1373]: loss 0.041622
[epoch12, step1374]: loss 0.041904
[epoch12, step1375]: loss 0.041677
[epoch12, step1376]: loss 0.040542
[epoch12, step1377]: loss 0.040670
[epoch12, step1378]: loss 0.042634
[epoch12, step1379]: loss 0.042705
[epoch12, step1380]: loss 0.041114
[epoch12, step1381]: loss 0.040527
[epoch12, step1382]: loss 0.043056
[epoch12, step1383]: loss 0.040746
[epoch12, step1384]: loss 0.041811
[epoch12, step1385]: loss 0.040787
[epoch12, step1386]: loss 0.041401
[epoch12, step1387]: loss 0.042122
[epoch12, step1388]: loss 0.041495
[epoch12, step1389]: loss 0.040068
[epoch12, step1390]: loss 0.040177
[epoch12, step1391]: loss 0.042480
[epoch12, step1392]: loss 0.041164
[epoch12, step1393]: loss 0.040952
[epoch12, step1394]: loss 0.041187
[epoch12, step1395]: loss 0.041231
[epoch12, step1396]: loss 0.041127
[epoch12, step1397]: loss 0.041508
[epoch12, step1398]: loss 0.040663
[epoch12, step1399]: loss 0.040832
[epoch12, step1400]: loss 0.043175
[epoch12, step1401]: loss 0.042037
[epoch12, step1402]: loss 0.041022
[epoch12, step1403]: loss 0.040154
[epoch12, step1404]: loss 0.041380
[epoch12, step1405]: loss 0.041574
[epoch12, step1406]: loss 0.042137
[epoch12, step1407]: loss 0.042009
[epoch12, step1408]: loss 0.039871
[epoch12, step1409]: loss 0.042022
[epoch12, step1410]: loss 0.041122
[epoch12, step1411]: loss 0.040860
[epoch12, step1412]: loss 0.040404
[epoch12, step1413]: loss 0.040876
[epoch12, step1414]: loss 0.041656
[epoch12, step1415]: loss 0.041387
[epoch12, step1416]: loss 0.040798
[epoch12, step1417]: loss 0.039768
[epoch12, step1418]: loss 0.041572
[epoch12, step1419]: loss 0.041730
[epoch12, step1420]: loss 0.041000
[epoch12, step1421]: loss 0.040805
[epoch12, step1422]: loss 0.041220
[epoch12, step1423]: loss 0.041710
[epoch12, step1424]: loss 0.043535
[epoch12, step1425]: loss 0.040452
[epoch12, step1426]: loss 0.040995
[epoch12, step1427]: loss 0.043075
[epoch12, step1428]: loss 0.041372
[epoch12, step1429]: loss 0.042184
[epoch12, step1430]: loss 0.041206
[epoch12, step1431]: loss 0.041448
[epoch12, step1432]: loss 0.041665
[epoch12, step1433]: loss 0.042459
[epoch12, step1434]: loss 0.040191
[epoch12, step1435]: loss 0.040320
[epoch12, step1436]: loss 0.043079
[epoch12, step1437]: loss 0.040955
[epoch12, step1438]: loss 0.041006
[epoch12, step1439]: loss 0.040396
[epoch12, step1440]: loss 0.040814
[epoch12, step1441]: loss 0.042359
[epoch12, step1442]: loss 0.041726
[epoch12, step1443]: loss 0.040602
[epoch12, step1444]: loss 0.040339
[epoch12, step1445]: loss 0.042745
[epoch12, step1446]: loss 0.041290
[epoch12, step1447]: loss 0.041340
[epoch12, step1448]: loss 0.040457
[epoch12, step1449]: loss 0.040976
[epoch12, step1450]: loss 0.040905
[epoch12, step1451]: loss 0.042156
[epoch12, step1452]: loss 0.041081
[epoch12, step1453]: loss 0.040928
[epoch12, step1454]: loss 0.042248
[epoch12, step1455]: loss 0.041349
[epoch12, step1456]: loss 0.041312
[epoch12, step1457]: loss 0.040400
[epoch12, step1458]: loss 0.040913
[epoch12, step1459]: loss 0.040807
[epoch12, step1460]: loss 0.042468
[epoch12, step1461]: loss 0.041003
[epoch12, step1462]: loss 0.040583
[epoch12, step1463]: loss 0.041760
[epoch12, step1464]: loss 0.041449
[epoch12, step1465]: loss 0.040767
[epoch12, step1466]: loss 0.040357
[epoch12, step1467]: loss 0.041676
[epoch12, step1468]: loss 0.040524
[epoch12, step1469]: loss 0.042241
[epoch12, step1470]: loss 0.040580
[epoch12, step1471]: loss 0.039829
[epoch12, step1472]: loss 0.041733
[epoch12, step1473]: loss 0.041035
[epoch12, step1474]: loss 0.041959
[epoch12, step1475]: loss 0.039739
[epoch12, step1476]: loss 0.041426
[epoch12, step1477]: loss 0.041099
[epoch12, step1478]: loss 0.042004
[epoch12, step1479]: loss 0.040777
[epoch12, step1480]: loss 0.040027
[epoch12, step1481]: loss 0.041226
[epoch12, step1482]: loss 0.041348
[epoch12, step1483]: loss 0.041309
[epoch12, step1484]: loss 0.040919
[epoch12, step1485]: loss 0.041426
[epoch12, step1486]: loss 0.040406
[epoch12, step1487]: loss 0.042042
[epoch12, step1488]: loss 0.041892
[epoch12, step1489]: loss 0.039984
[epoch12, step1490]: loss 0.042636
[epoch12, step1491]: loss 0.041333
[epoch12, step1492]: loss 0.040590
[epoch12, step1493]: loss 0.039981
[epoch12, step1494]: loss 0.040815
[epoch12, step1495]: loss 0.040793
[epoch12, step1496]: loss 0.041013
[epoch12, step1497]: loss 0.041141
[epoch12, step1498]: loss 0.039878
[epoch12, step1499]: loss 0.043342
[epoch12, step1500]: loss 0.041154
[epoch12, step1501]: loss 0.041053
[epoch12, step1502]: loss 0.040964
[epoch12, step1503]: loss 0.041649
[epoch12, step1504]: loss 0.040544
[epoch12, step1505]: loss 0.043473
[epoch12, step1506]: loss 0.040512
[epoch12, step1507]: loss 0.040319
[epoch12, step1508]: loss 0.042670
[epoch12, step1509]: loss 0.041562
[epoch12, step1510]: loss 0.041036
[epoch12, step1511]: loss 0.040388
[epoch12, step1512]: loss 0.041023
[epoch12, step1513]: loss 0.040920
[epoch12, step1514]: loss 0.041994
[epoch12, step1515]: loss 0.041241
[epoch12, step1516]: loss 0.040828

[epoch12]: avg loss 0.038053

[epoch13, step1]: loss 0.044291
[epoch13, step2]: loss 0.039587
[epoch13, step3]: loss 0.039394
[epoch13, step4]: loss 0.035951
[epoch13, step5]: loss 0.035600
[epoch13, step6]: loss 0.038868
[epoch13, step7]: loss 0.036679
[epoch13, step8]: loss 0.038583
[epoch13, step9]: loss 0.034680
[epoch13, step10]: loss 0.036617
[epoch13, step11]: loss 0.039113
[epoch13, step12]: loss 0.038169
[epoch13, step13]: loss 0.036024
[epoch13, step14]: loss 0.036204
[epoch13, step15]: loss 0.038196
[epoch13, step16]: loss 0.035912
[epoch13, step17]: loss 0.039018
[epoch13, step18]: loss 0.036071
[epoch13, step19]: loss 0.035316
[epoch13, step20]: loss 0.039029
[epoch13, step21]: loss 0.037218
[epoch13, step22]: loss 0.034440
[epoch13, step23]: loss 0.034140
[epoch13, step24]: loss 0.037436
[epoch13, step25]: loss 0.034867
[epoch13, step26]: loss 0.036918
[epoch13, step27]: loss 0.034054
[epoch13, step28]: loss 0.035057
[epoch13, step29]: loss 0.037356
[epoch13, step30]: loss 0.037088
[epoch13, step31]: loss 0.034293
[epoch13, step32]: loss 0.035155
[epoch13, step33]: loss 0.037613
[epoch13, step34]: loss 0.035243
[epoch13, step35]: loss 0.037911
[epoch13, step36]: loss 0.034061
[epoch13, step37]: loss 0.034959
[epoch13, step38]: loss 0.037192
[epoch13, step39]: loss 0.037049
[epoch13, step40]: loss 0.035216
[epoch13, step41]: loss 0.034256
[epoch13, step42]: loss 0.037610
[epoch13, step43]: loss 0.034882
[epoch13, step44]: loss 0.038219
[epoch13, step45]: loss 0.034392
[epoch13, step46]: loss 0.035073
[epoch13, step47]: loss 0.037126
[epoch13, step48]: loss 0.036940
[epoch13, step49]: loss 0.033178
[epoch13, step50]: loss 0.034436
[epoch13, step51]: loss 0.036983
[epoch13, step52]: loss 0.034838
[epoch13, step53]: loss 0.037507
[epoch13, step54]: loss 0.033789
[epoch13, step55]: loss 0.035421
[epoch13, step56]: loss 0.038107
[epoch13, step57]: loss 0.037161
[epoch13, step58]: loss 0.034679
[epoch13, step59]: loss 0.033468
[epoch13, step60]: loss 0.037768
[epoch13, step61]: loss 0.033910
[epoch13, step62]: loss 0.036652
[epoch13, step63]: loss 0.033535
[epoch13, step64]: loss 0.034315
[epoch13, step65]: loss 0.037262
[epoch13, step66]: loss 0.036959
[epoch13, step67]: loss 0.034652
[epoch13, step68]: loss 0.034094
[epoch13, step69]: loss 0.036936
[epoch13, step70]: loss 0.034458
[epoch13, step71]: loss 0.037026
[epoch13, step72]: loss 0.034212
[epoch13, step73]: loss 0.034448
[epoch13, step74]: loss 0.036142
[epoch13, step75]: loss 0.036913
[epoch13, step76]: loss 0.034965
[epoch13, step77]: loss 0.035067
[epoch13, step78]: loss 0.037355
[epoch13, step79]: loss 0.034278
[epoch13, step80]: loss 0.037970
[epoch13, step81]: loss 0.034231
[epoch13, step82]: loss 0.034600
[epoch13, step83]: loss 0.036456
[epoch13, step84]: loss 0.036864
[epoch13, step85]: loss 0.034788
[epoch13, step86]: loss 0.034624
[epoch13, step87]: loss 0.037970
[epoch13, step88]: loss 0.033750
[epoch13, step89]: loss 0.036922
[epoch13, step90]: loss 0.034761
[epoch13, step91]: loss 0.034204
[epoch13, step92]: loss 0.037226
[epoch13, step93]: loss 0.036579
[epoch13, step94]: loss 0.033720
[epoch13, step95]: loss 0.034461
[epoch13, step96]: loss 0.036471
[epoch13, step97]: loss 0.034948
[epoch13, step98]: loss 0.037146
[epoch13, step99]: loss 0.034179
[epoch13, step100]: loss 0.033511
[epoch13, step101]: loss 0.037869
[epoch13, step102]: loss 0.036408
[epoch13, step103]: loss 0.034564
[epoch13, step104]: loss 0.034357
[epoch13, step105]: loss 0.037052
[epoch13, step106]: loss 0.034496
[epoch13, step107]: loss 0.037325
[epoch13, step108]: loss 0.034650
[epoch13, step109]: loss 0.034386
[epoch13, step110]: loss 0.037153
[epoch13, step111]: loss 0.036099
[epoch13, step112]: loss 0.034326
[epoch13, step113]: loss 0.035141
[epoch13, step114]: loss 0.036906
[epoch13, step115]: loss 0.034477
[epoch13, step116]: loss 0.037974
[epoch13, step117]: loss 0.033750
[epoch13, step118]: loss 0.035383
[epoch13, step119]: loss 0.037136
[epoch13, step120]: loss 0.037356
[epoch13, step121]: loss 0.034330
[epoch13, step122]: loss 0.033983
[epoch13, step123]: loss 0.037328
[epoch13, step124]: loss 0.034632
[epoch13, step125]: loss 0.037559
[epoch13, step126]: loss 0.034001
[epoch13, step127]: loss 0.034114
[epoch13, step128]: loss 0.036837
[epoch13, step129]: loss 0.036193
[epoch13, step130]: loss 0.034421
[epoch13, step131]: loss 0.033916
[epoch13, step132]: loss 0.036755
[epoch13, step133]: loss 0.034530
[epoch13, step134]: loss 0.036377
[epoch13, step135]: loss 0.034512
[epoch13, step136]: loss 0.035729
[epoch13, step137]: loss 0.036606
[epoch13, step138]: loss 0.037203
[epoch13, step139]: loss 0.034240
[epoch13, step140]: loss 0.034657
[epoch13, step141]: loss 0.037252
[epoch13, step142]: loss 0.034305
[epoch13, step143]: loss 0.036450
[epoch13, step144]: loss 0.034163
[epoch13, step145]: loss 0.034772
[epoch13, step146]: loss 0.037619
[epoch13, step147]: loss 0.037609
[epoch13, step148]: loss 0.034067
[epoch13, step149]: loss 0.033569
[epoch13, step150]: loss 0.036221
[epoch13, step151]: loss 0.034408
[epoch13, step152]: loss 0.036492
[epoch13, step153]: loss 0.033941
[epoch13, step154]: loss 0.033955
[epoch13, step155]: loss 0.036924
[epoch13, step156]: loss 0.036125
[epoch13, step157]: loss 0.034711
[epoch13, step158]: loss 0.034689
[epoch13, step159]: loss 0.036739
[epoch13, step160]: loss 0.034604
[epoch13, step161]: loss 0.036936
[epoch13, step162]: loss 0.034832
[epoch13, step163]: loss 0.034533
[epoch13, step164]: loss 0.036794
[epoch13, step165]: loss 0.036198
[epoch13, step166]: loss 0.034970
[epoch13, step167]: loss 0.033668
[epoch13, step168]: loss 0.037515
[epoch13, step169]: loss 0.034359
[epoch13, step170]: loss 0.037219
[epoch13, step171]: loss 0.034897
[epoch13, step172]: loss 0.034685
[epoch13, step173]: loss 0.037574
[epoch13, step174]: loss 0.037194
[epoch13, step175]: loss 0.035319
[epoch13, step176]: loss 0.034597
[epoch13, step177]: loss 0.037238
[epoch13, step178]: loss 0.034638
[epoch13, step179]: loss 0.036407
[epoch13, step180]: loss 0.034137
[epoch13, step181]: loss 0.034916
[epoch13, step182]: loss 0.037685
[epoch13, step183]: loss 0.036799
[epoch13, step184]: loss 0.035907
[epoch13, step185]: loss 0.034198
[epoch13, step186]: loss 0.036785
[epoch13, step187]: loss 0.034538
[epoch13, step188]: loss 0.036646
[epoch13, step189]: loss 0.034278
[epoch13, step190]: loss 0.033566
[epoch13, step191]: loss 0.036630
[epoch13, step192]: loss 0.036829
[epoch13, step193]: loss 0.032398
[epoch13, step194]: loss 0.033287
[epoch13, step195]: loss 0.036731
[epoch13, step196]: loss 0.034601
[epoch13, step197]: loss 0.036704
[epoch13, step198]: loss 0.033430
[epoch13, step199]: loss 0.034617
[epoch13, step200]: loss 0.037456
[epoch13, step201]: loss 0.037203
[epoch13, step202]: loss 0.033600
[epoch13, step203]: loss 0.034538
[epoch13, step204]: loss 0.037648
[epoch13, step205]: loss 0.033916
[epoch13, step206]: loss 0.037175
[epoch13, step207]: loss 0.034460
[epoch13, step208]: loss 0.034231
[epoch13, step209]: loss 0.037539
[epoch13, step210]: loss 0.037348
[epoch13, step211]: loss 0.034569
[epoch13, step212]: loss 0.034750
[epoch13, step213]: loss 0.037108
[epoch13, step214]: loss 0.034109
[epoch13, step215]: loss 0.037318
[epoch13, step216]: loss 0.035086
[epoch13, step217]: loss 0.034247
[epoch13, step218]: loss 0.036840
[epoch13, step219]: loss 0.037156
[epoch13, step220]: loss 0.035755
[epoch13, step221]: loss 0.035128
[epoch13, step222]: loss 0.037034
[epoch13, step223]: loss 0.034978
[epoch13, step224]: loss 0.037013
[epoch13, step225]: loss 0.034287
[epoch13, step226]: loss 0.033453
[epoch13, step227]: loss 0.036329
[epoch13, step228]: loss 0.038232
[epoch13, step229]: loss 0.033838
[epoch13, step230]: loss 0.034284
[epoch13, step231]: loss 0.037430
[epoch13, step232]: loss 0.033871
[epoch13, step233]: loss 0.036230
[epoch13, step234]: loss 0.033511
[epoch13, step235]: loss 0.034611
[epoch13, step236]: loss 0.036572
[epoch13, step237]: loss 0.036281
[epoch13, step238]: loss 0.034249
[epoch13, step239]: loss 0.033610
[epoch13, step240]: loss 0.035917
[epoch13, step241]: loss 0.034933
[epoch13, step242]: loss 0.037107
[epoch13, step243]: loss 0.034821
[epoch13, step244]: loss 0.034298
[epoch13, step245]: loss 0.036814
[epoch13, step246]: loss 0.036841
[epoch13, step247]: loss 0.034385
[epoch13, step248]: loss 0.033494
[epoch13, step249]: loss 0.036970
[epoch13, step250]: loss 0.035306
[epoch13, step251]: loss 0.037902
[epoch13, step252]: loss 0.035849
[epoch13, step253]: loss 0.034567
[epoch13, step254]: loss 0.037245
[epoch13, step255]: loss 0.037095
[epoch13, step256]: loss 0.034747
[epoch13, step257]: loss 0.034214
[epoch13, step258]: loss 0.037416
[epoch13, step259]: loss 0.034548
[epoch13, step260]: loss 0.036798
[epoch13, step261]: loss 0.035519
[epoch13, step262]: loss 0.035945
[epoch13, step263]: loss 0.037074
[epoch13, step264]: loss 0.038503
[epoch13, step265]: loss 0.036133
[epoch13, step266]: loss 0.035165
[epoch13, step267]: loss 0.037092
[epoch13, step268]: loss 0.035133
[epoch13, step269]: loss 0.037899
[epoch13, step270]: loss 0.034887
[epoch13, step271]: loss 0.035107
[epoch13, step272]: loss 0.037898
[epoch13, step273]: loss 0.037486
[epoch13, step274]: loss 0.036304
[epoch13, step275]: loss 0.034474
[epoch13, step276]: loss 0.037327
[epoch13, step277]: loss 0.035718
[epoch13, step278]: loss 0.037791
[epoch13, step279]: loss 0.034783
[epoch13, step280]: loss 0.034789
[epoch13, step281]: loss 0.037444
[epoch13, step282]: loss 0.037729
[epoch13, step283]: loss 0.034540
[epoch13, step284]: loss 0.034403
[epoch13, step285]: loss 0.038129
[epoch13, step286]: loss 0.034321
[epoch13, step287]: loss 0.038035
[epoch13, step288]: loss 0.034103
[epoch13, step289]: loss 0.035606
[epoch13, step290]: loss 0.037843
[epoch13, step291]: loss 0.037373
[epoch13, step292]: loss 0.034164
[epoch13, step293]: loss 0.034438
[epoch13, step294]: loss 0.036738
[epoch13, step295]: loss 0.034590
[epoch13, step296]: loss 0.037668
[epoch13, step297]: loss 0.034547
[epoch13, step298]: loss 0.034827
[epoch13, step299]: loss 0.036377
[epoch13, step300]: loss 0.037373
[epoch13, step301]: loss 0.034971
[epoch13, step302]: loss 0.035082
[epoch13, step303]: loss 0.038034
[epoch13, step304]: loss 0.034439
[epoch13, step305]: loss 0.036874
[epoch13, step306]: loss 0.034638
[epoch13, step307]: loss 0.034298
[epoch13, step308]: loss 0.037886
[epoch13, step309]: loss 0.037323
[epoch13, step310]: loss 0.034585
[epoch13, step311]: loss 0.035234
[epoch13, step312]: loss 0.036987
[epoch13, step313]: loss 0.034438
[epoch13, step314]: loss 0.037246
[epoch13, step315]: loss 0.035039
[epoch13, step316]: loss 0.034754
[epoch13, step317]: loss 0.037765
[epoch13, step318]: loss 0.036831
[epoch13, step319]: loss 0.034243
[epoch13, step320]: loss 0.034352
[epoch13, step321]: loss 0.037058
[epoch13, step322]: loss 0.034978
[epoch13, step323]: loss 0.036865
[epoch13, step324]: loss 0.035797
[epoch13, step325]: loss 0.035051
[epoch13, step326]: loss 0.037065
[epoch13, step327]: loss 0.036389
[epoch13, step328]: loss 0.035194
[epoch13, step329]: loss 0.034706
[epoch13, step330]: loss 0.036264
[epoch13, step331]: loss 0.035157
[epoch13, step332]: loss 0.037702
[epoch13, step333]: loss 0.034191
[epoch13, step334]: loss 0.034578
[epoch13, step335]: loss 0.038275
[epoch13, step336]: loss 0.037523
[epoch13, step337]: loss 0.035339
[epoch13, step338]: loss 0.033987
[epoch13, step339]: loss 0.036660
[epoch13, step340]: loss 0.035038
[epoch13, step341]: loss 0.036195
[epoch13, step342]: loss 0.033751
[epoch13, step343]: loss 0.034414
[epoch13, step344]: loss 0.036519
[epoch13, step345]: loss 0.036089
[epoch13, step346]: loss 0.034548
[epoch13, step347]: loss 0.034118
[epoch13, step348]: loss 0.037133
[epoch13, step349]: loss 0.035535
[epoch13, step350]: loss 0.036609
[epoch13, step351]: loss 0.033523
[epoch13, step352]: loss 0.034305
[epoch13, step353]: loss 0.037320
[epoch13, step354]: loss 0.035877
[epoch13, step355]: loss 0.033476
[epoch13, step356]: loss 0.034697
[epoch13, step357]: loss 0.036967
[epoch13, step358]: loss 0.033000
[epoch13, step359]: loss 0.038887
[epoch13, step360]: loss 0.033324
[epoch13, step361]: loss 0.034032
[epoch13, step362]: loss 0.037572
[epoch13, step363]: loss 0.035915
[epoch13, step364]: loss 0.034186
[epoch13, step365]: loss 0.033733
[epoch13, step366]: loss 0.037003
[epoch13, step367]: loss 0.034426
[epoch13, step368]: loss 0.036107
[epoch13, step369]: loss 0.034055
[epoch13, step370]: loss 0.034845
[epoch13, step371]: loss 0.037738
[epoch13, step372]: loss 0.036279
[epoch13, step373]: loss 0.033659
[epoch13, step374]: loss 0.033838
[epoch13, step375]: loss 0.037781
[epoch13, step376]: loss 0.034730
[epoch13, step377]: loss 0.037184
[epoch13, step378]: loss 0.034323
[epoch13, step379]: loss 0.034881
[epoch13, step380]: loss 0.037299
[epoch13, step381]: loss 0.035989
[epoch13, step382]: loss 0.034241
[epoch13, step383]: loss 0.033154
[epoch13, step384]: loss 0.035785
[epoch13, step385]: loss 0.034173
[epoch13, step386]: loss 0.036621
[epoch13, step387]: loss 0.034173
[epoch13, step388]: loss 0.035116
[epoch13, step389]: loss 0.036283
[epoch13, step390]: loss 0.037757
[epoch13, step391]: loss 0.033797
[epoch13, step392]: loss 0.034968
[epoch13, step393]: loss 0.036591
[epoch13, step394]: loss 0.034434
[epoch13, step395]: loss 0.037030
[epoch13, step396]: loss 0.033964
[epoch13, step397]: loss 0.034216
[epoch13, step398]: loss 0.037469
[epoch13, step399]: loss 0.036105
[epoch13, step400]: loss 0.034746
[epoch13, step401]: loss 0.034173
[epoch13, step402]: loss 0.036671
[epoch13, step403]: loss 0.034547
[epoch13, step404]: loss 0.037007
[epoch13, step405]: loss 0.034487
[epoch13, step406]: loss 0.034366
[epoch13, step407]: loss 0.037315
[epoch13, step408]: loss 0.036761
[epoch13, step409]: loss 0.035663
[epoch13, step410]: loss 0.034839
[epoch13, step411]: loss 0.036495
[epoch13, step412]: loss 0.034249
[epoch13, step413]: loss 0.037271
[epoch13, step414]: loss 0.034154
[epoch13, step415]: loss 0.034473
[epoch13, step416]: loss 0.036613
[epoch13, step417]: loss 0.036563
[epoch13, step418]: loss 0.035126
[epoch13, step419]: loss 0.033440
[epoch13, step420]: loss 0.036693
[epoch13, step421]: loss 0.034509
[epoch13, step422]: loss 0.036392
[epoch13, step423]: loss 0.034111
[epoch13, step424]: loss 0.034024
[epoch13, step425]: loss 0.036948
[epoch13, step426]: loss 0.036920
[epoch13, step427]: loss 0.034552
[epoch13, step428]: loss 0.034238
[epoch13, step429]: loss 0.037248
[epoch13, step430]: loss 0.034605
[epoch13, step431]: loss 0.036841
[epoch13, step432]: loss 0.033720
[epoch13, step433]: loss 0.035217
[epoch13, step434]: loss 0.036478
[epoch13, step435]: loss 0.037266
[epoch13, step436]: loss 0.034129
[epoch13, step437]: loss 0.033915
[epoch13, step438]: loss 0.036946
[epoch13, step439]: loss 0.035021
[epoch13, step440]: loss 0.036781
[epoch13, step441]: loss 0.034026
[epoch13, step442]: loss 0.034263
[epoch13, step443]: loss 0.037365
[epoch13, step444]: loss 0.036160
[epoch13, step445]: loss 0.034519
[epoch13, step446]: loss 0.034485
[epoch13, step447]: loss 0.037192
[epoch13, step448]: loss 0.034402
[epoch13, step449]: loss 0.036683
[epoch13, step450]: loss 0.033510
[epoch13, step451]: loss 0.034257
[epoch13, step452]: loss 0.035986
[epoch13, step453]: loss 0.036778
[epoch13, step454]: loss 0.034165
[epoch13, step455]: loss 0.034129
[epoch13, step456]: loss 0.036125
[epoch13, step457]: loss 0.034982
[epoch13, step458]: loss 0.036093
[epoch13, step459]: loss 0.034524
[epoch13, step460]: loss 0.034835
[epoch13, step461]: loss 0.038231
[epoch13, step462]: loss 0.035472
[epoch13, step463]: loss 0.034731
[epoch13, step464]: loss 0.033524
[epoch13, step465]: loss 0.037943
[epoch13, step466]: loss 0.034244
[epoch13, step467]: loss 0.036458
[epoch13, step468]: loss 0.034038
[epoch13, step469]: loss 0.034155
[epoch13, step470]: loss 0.036832
[epoch13, step471]: loss 0.035949
[epoch13, step472]: loss 0.034803
[epoch13, step473]: loss 0.034353
[epoch13, step474]: loss 0.036128
[epoch13, step475]: loss 0.034644
[epoch13, step476]: loss 0.036772
[epoch13, step477]: loss 0.034617
[epoch13, step478]: loss 0.034106
[epoch13, step479]: loss 0.036593
[epoch13, step480]: loss 0.036167
[epoch13, step481]: loss 0.034368
[epoch13, step482]: loss 0.033461
[epoch13, step483]: loss 0.036678
[epoch13, step484]: loss 0.034865
[epoch13, step485]: loss 0.037253
[epoch13, step486]: loss 0.034109
[epoch13, step487]: loss 0.033577
[epoch13, step488]: loss 0.037185
[epoch13, step489]: loss 0.035519
[epoch13, step490]: loss 0.034912
[epoch13, step491]: loss 0.034328
[epoch13, step492]: loss 0.036484
[epoch13, step493]: loss 0.034376
[epoch13, step494]: loss 0.035902
[epoch13, step495]: loss 0.035302
[epoch13, step496]: loss 0.034624
[epoch13, step497]: loss 0.036566
[epoch13, step498]: loss 0.036397
[epoch13, step499]: loss 0.034560
[epoch13, step500]: loss 0.034106
[epoch13, step501]: loss 0.036557
[epoch13, step502]: loss 0.034206
[epoch13, step503]: loss 0.037290
[epoch13, step504]: loss 0.033469
[epoch13, step505]: loss 0.033222
[epoch13, step506]: loss 0.036957
[epoch13, step507]: loss 0.036992
[epoch13, step508]: loss 0.034515
[epoch13, step509]: loss 0.033885
[epoch13, step510]: loss 0.036776
[epoch13, step511]: loss 0.034936
[epoch13, step512]: loss 0.036929
[epoch13, step513]: loss 0.034559
[epoch13, step514]: loss 0.034718
[epoch13, step515]: loss 0.036532
[epoch13, step516]: loss 0.036874
[epoch13, step517]: loss 0.034459
[epoch13, step518]: loss 0.034157
[epoch13, step519]: loss 0.036790
[epoch13, step520]: loss 0.033979
[epoch13, step521]: loss 0.036727
[epoch13, step522]: loss 0.033654
[epoch13, step523]: loss 0.033722
[epoch13, step524]: loss 0.035988
[epoch13, step525]: loss 0.036742
[epoch13, step526]: loss 0.034419
[epoch13, step527]: loss 0.033414
[epoch13, step528]: loss 0.036676
[epoch13, step529]: loss 0.034361
[epoch13, step530]: loss 0.036910
[epoch13, step531]: loss 0.033984
[epoch13, step532]: loss 0.035063
[epoch13, step533]: loss 0.037484
[epoch13, step534]: loss 0.036671
[epoch13, step535]: loss 0.035378
[epoch13, step536]: loss 0.034093
[epoch13, step537]: loss 0.036565
[epoch13, step538]: loss 0.034744
[epoch13, step539]: loss 0.036274
[epoch13, step540]: loss 0.033510
[epoch13, step541]: loss 0.033681
[epoch13, step542]: loss 0.036987
[epoch13, step543]: loss 0.035871
[epoch13, step544]: loss 0.034485
[epoch13, step545]: loss 0.033391
[epoch13, step546]: loss 0.036966
[epoch13, step547]: loss 0.034208
[epoch13, step548]: loss 0.036904
[epoch13, step549]: loss 0.034782
[epoch13, step550]: loss 0.035114
[epoch13, step551]: loss 0.036858
[epoch13, step552]: loss 0.036206
[epoch13, step553]: loss 0.035575
[epoch13, step554]: loss 0.033996
[epoch13, step555]: loss 0.036074
[epoch13, step556]: loss 0.034240
[epoch13, step557]: loss 0.035889
[epoch13, step558]: loss 0.034152
[epoch13, step559]: loss 0.033558
[epoch13, step560]: loss 0.036673
[epoch13, step561]: loss 0.036130
[epoch13, step562]: loss 0.034089
[epoch13, step563]: loss 0.035882
[epoch13, step564]: loss 0.041067
[epoch13, step565]: loss 0.040202
[epoch13, step566]: loss 0.048351
[epoch13, step567]: loss 0.040182
[epoch13, step568]: loss 0.039916
[epoch13, step569]: loss 0.036287
[epoch13, step570]: loss 0.043924
[epoch13, step571]: loss 0.039592
[epoch13, step572]: loss 0.037109
[epoch13, step573]: loss 0.038996
[epoch13, step574]: loss 0.040811
[epoch13, step575]: loss 0.031944
[epoch13, step576]: loss 0.033959
[epoch13, step577]: loss 0.036810
[epoch13, step578]: loss 0.029829
[epoch13, step579]: loss 0.039227
[epoch13, step580]: loss 0.030600
[epoch13, step581]: loss 0.035651
[epoch13, step582]: loss 0.035476
[epoch13, step583]: loss 0.035451
[epoch13, step584]: loss 0.034273
[epoch13, step585]: loss 0.036988
[epoch13, step586]: loss 0.034649
[epoch13, step587]: loss 0.039781
[epoch13, step588]: loss 0.034832
[epoch13, step589]: loss 0.034682
[epoch13, step590]: loss 0.039181
[epoch13, step591]: loss 0.031980
[epoch13, step592]: loss 0.037393
[epoch13, step593]: loss 0.032895
[epoch13, step594]: loss 0.037380
[epoch13, step595]: loss 0.038068
[epoch13, step596]: loss 0.036532
[epoch13, step597]: loss 0.035685
[epoch13, step598]: loss 0.036578
[epoch13, step599]: loss 0.034673
[epoch13, step600]: loss 0.037673
[epoch13, step601]: loss 0.030463
[epoch13, step602]: loss 0.033308
[epoch13, step603]: loss 0.036551
[epoch13, step604]: loss 0.038394
[epoch13, step605]: loss 0.036181
[epoch13, step606]: loss 0.034404
[epoch13, step607]: loss 0.039297
[epoch13, step608]: loss 0.037440
[epoch13, step609]: loss 0.037276
[epoch13, step610]: loss 0.039491
[epoch13, step611]: loss 0.038075
[epoch13, step612]: loss 0.035078
[epoch13, step613]: loss 0.030729
[epoch13, step614]: loss 0.034806
[epoch13, step615]: loss 0.040201
[epoch13, step616]: loss 0.034365
[epoch13, step617]: loss 0.033773
[epoch13, step618]: loss 0.037143
[epoch13, step619]: loss 0.039054
[epoch13, step620]: loss 0.035382
[epoch13, step621]: loss 0.037813
[epoch13, step622]: loss 0.031592
[epoch13, step623]: loss 0.033780
[epoch13, step624]: loss 0.038306
[epoch13, step625]: loss 0.036315
[epoch13, step626]: loss 0.039069
[epoch13, step627]: loss 0.033748
[epoch13, step628]: loss 0.035802
[epoch13, step629]: loss 0.031235
[epoch13, step630]: loss 0.032447
[epoch13, step631]: loss 0.042422
[epoch13, step632]: loss 0.035012
[epoch13, step633]: loss 0.035360
[epoch13, step634]: loss 0.037513
[epoch13, step635]: loss 0.037185
[epoch13, step636]: loss 0.032909
[epoch13, step637]: loss 0.038359
[epoch13, step638]: loss 0.038709
[epoch13, step639]: loss 0.032330
[epoch13, step640]: loss 0.040207
[epoch13, step641]: loss 0.041342
[epoch13, step642]: loss 0.035617
[epoch13, step643]: loss 0.035139
[epoch13, step644]: loss 0.036521
[epoch13, step645]: loss 0.034111
[epoch13, step646]: loss 0.035440
[epoch13, step647]: loss 0.034248
[epoch13, step648]: loss 0.034763
[epoch13, step649]: loss 0.037975
[epoch13, step650]: loss 0.033647
[epoch13, step651]: loss 0.038136
[epoch13, step652]: loss 0.037998
[epoch13, step653]: loss 0.038344
[epoch13, step654]: loss 0.033297
[epoch13, step655]: loss 0.034840
[epoch13, step656]: loss 0.033726
[epoch13, step657]: loss 0.039544
[epoch13, step658]: loss 0.035528
[epoch13, step659]: loss 0.037979
[epoch13, step660]: loss 0.033026
[epoch13, step661]: loss 0.036380
[epoch13, step662]: loss 0.033847
[epoch13, step663]: loss 0.032654
[epoch13, step664]: loss 0.036656
[epoch13, step665]: loss 0.037822
[epoch13, step666]: loss 0.037117
[epoch13, step667]: loss 0.037388
[epoch13, step668]: loss 0.033743
[epoch13, step669]: loss 0.038001
[epoch13, step670]: loss 0.037924
[epoch13, step671]: loss 0.032058
[epoch13, step672]: loss 0.034937
[epoch13, step673]: loss 0.032999
[epoch13, step674]: loss 0.031476
[epoch13, step675]: loss 0.030937
[epoch13, step676]: loss 0.033873
[epoch13, step677]: loss 0.035401
[epoch13, step678]: loss 0.033076
[epoch13, step679]: loss 0.034920
[epoch13, step680]: loss 0.040852
[epoch13, step681]: loss 0.031786
[epoch13, step682]: loss 0.036347
[epoch13, step683]: loss 0.035700
[epoch13, step684]: loss 0.035487
[epoch13, step685]: loss 0.034756
[epoch13, step686]: loss 0.038335
[epoch13, step687]: loss 0.036105
[epoch13, step688]: loss 0.035000
[epoch13, step689]: loss 0.036056
[epoch13, step690]: loss 0.035678
[epoch13, step691]: loss 0.035241
[epoch13, step692]: loss 0.034459
[epoch13, step693]: loss 0.038748
[epoch13, step694]: loss 0.032458
[epoch13, step695]: loss 0.038027
[epoch13, step696]: loss 0.035339
[epoch13, step697]: loss 0.038010
[epoch13, step698]: loss 0.035362
[epoch13, step699]: loss 0.033936
[epoch13, step700]: loss 0.031056
[epoch13, step701]: loss 0.035940
[epoch13, step702]: loss 0.031267
[epoch13, step703]: loss 0.034104
[epoch13, step704]: loss 0.036471
[epoch13, step705]: loss 0.036250
[epoch13, step706]: loss 0.033794
[epoch13, step707]: loss 0.033764
[epoch13, step708]: loss 0.034701
[epoch13, step709]: loss 0.037516
[epoch13, step710]: loss 0.032953
[epoch13, step711]: loss 0.036938
[epoch13, step712]: loss 0.036560
[epoch13, step713]: loss 0.037673
[epoch13, step714]: loss 0.032016
[epoch13, step715]: loss 0.033205
[epoch13, step716]: loss 0.035830
[epoch13, step717]: loss 0.033194
[epoch13, step718]: loss 0.035524
[epoch13, step719]: loss 0.044713
[epoch13, step720]: loss 0.034670
[epoch13, step721]: loss 0.032835
[epoch13, step722]: loss 0.040913
[epoch13, step723]: loss 0.037544
[epoch13, step724]: loss 0.032465
[epoch13, step725]: loss 0.036545
[epoch13, step726]: loss 0.031887
[epoch13, step727]: loss 0.034136
[epoch13, step728]: loss 0.036843
[epoch13, step729]: loss 0.032494
[epoch13, step730]: loss 0.032671
[epoch13, step731]: loss 0.035556
[epoch13, step732]: loss 0.036076
[epoch13, step733]: loss 0.034388
[epoch13, step734]: loss 0.033985
[epoch13, step735]: loss 0.038452
[epoch13, step736]: loss 0.036016
[epoch13, step737]: loss 0.037834
[epoch13, step738]: loss 0.031099
[epoch13, step739]: loss 0.036978
[epoch13, step740]: loss 0.032516
[epoch13, step741]: loss 0.035999
[epoch13, step742]: loss 0.033025
[epoch13, step743]: loss 0.034008
[epoch13, step744]: loss 0.033588
[epoch13, step745]: loss 0.034084
[epoch13, step746]: loss 0.036235
[epoch13, step747]: loss 0.039085
[epoch13, step748]: loss 0.036818
[epoch13, step749]: loss 0.035891
[epoch13, step750]: loss 0.038677
[epoch13, step751]: loss 0.033453
[epoch13, step752]: loss 0.035133
[epoch13, step753]: loss 0.035858
[epoch13, step754]: loss 0.034451
[epoch13, step755]: loss 0.035949
[epoch13, step756]: loss 0.033716
[epoch13, step757]: loss 0.029877
[epoch13, step758]: loss 0.034002
[epoch13, step759]: loss 0.033030
[epoch13, step760]: loss 0.034476
[epoch13, step761]: loss 0.037550
[epoch13, step762]: loss 0.031249
[epoch13, step763]: loss 0.035173
[epoch13, step764]: loss 0.035172
[epoch13, step765]: loss 0.036743
[epoch13, step766]: loss 0.036141
[epoch13, step767]: loss 0.039128
[epoch13, step768]: loss 0.030243
[epoch13, step769]: loss 0.036113
[epoch13, step770]: loss 0.034684
[epoch13, step771]: loss 0.033458
[epoch13, step772]: loss 0.038536
[epoch13, step773]: loss 0.036001
[epoch13, step774]: loss 0.035275
[epoch13, step775]: loss 0.029982
[epoch13, step776]: loss 0.037288
[epoch13, step777]: loss 0.033739
[epoch13, step778]: loss 0.037515
[epoch13, step779]: loss 0.035150
[epoch13, step780]: loss 0.030121
[epoch13, step781]: loss 0.035112
[epoch13, step782]: loss 0.032451
[epoch13, step783]: loss 0.030552
[epoch13, step784]: loss 0.031535
[epoch13, step785]: loss 0.031954
[epoch13, step786]: loss 0.034603
[epoch13, step787]: loss 0.034866
[epoch13, step788]: loss 0.036580
[epoch13, step789]: loss 0.034901
[epoch13, step790]: loss 0.034721
[epoch13, step791]: loss 0.038228
[epoch13, step792]: loss 0.035952
[epoch13, step793]: loss 0.037160
[epoch13, step794]: loss 0.030325
[epoch13, step795]: loss 0.035057
[epoch13, step796]: loss 0.037999
[epoch13, step797]: loss 0.037439
[epoch13, step798]: loss 0.037610
[epoch13, step799]: loss 0.037319
[epoch13, step800]: loss 0.031340
[epoch13, step801]: loss 0.033981
[epoch13, step802]: loss 0.033665
[epoch13, step803]: loss 0.037359
[epoch13, step804]: loss 0.037749
[epoch13, step805]: loss 0.038093
[epoch13, step806]: loss 0.032703
[epoch13, step807]: loss 0.031592
[epoch13, step808]: loss 0.034113
[epoch13, step809]: loss 0.032190
[epoch13, step810]: loss 0.036277
[epoch13, step811]: loss 0.035394
[epoch13, step812]: loss 0.033411
[epoch13, step813]: loss 0.033792
[epoch13, step814]: loss 0.036772
[epoch13, step815]: loss 0.033883
[epoch13, step816]: loss 0.034443
[epoch13, step817]: loss 0.035640
[epoch13, step818]: loss 0.032772
[epoch13, step819]: loss 0.031443
[epoch13, step820]: loss 0.034555
[epoch13, step821]: loss 0.032142
[epoch13, step822]: loss 0.039931
[epoch13, step823]: loss 0.033956
[epoch13, step824]: loss 0.036428
[epoch13, step825]: loss 0.036524
[epoch13, step826]: loss 0.035003
[epoch13, step827]: loss 0.038044
[epoch13, step828]: loss 0.039590
[epoch13, step829]: loss 0.038822
[epoch13, step830]: loss 0.033710
[epoch13, step831]: loss 0.037300
[epoch13, step832]: loss 0.031624
[epoch13, step833]: loss 0.038615
[epoch13, step834]: loss 0.036864
[epoch13, step835]: loss 0.031365
[epoch13, step836]: loss 0.039147
[epoch13, step837]: loss 0.036092
[epoch13, step838]: loss 0.034636
[epoch13, step839]: loss 0.039536
[epoch13, step840]: loss 0.031497
[epoch13, step841]: loss 0.035203
[epoch13, step842]: loss 0.037189
[epoch13, step843]: loss 0.036008
[epoch13, step844]: loss 0.035893
[epoch13, step845]: loss 0.031890
[epoch13, step846]: loss 0.039155
[epoch13, step847]: loss 0.036943
[epoch13, step848]: loss 0.035762
[epoch13, step849]: loss 0.033712
[epoch13, step850]: loss 0.033722
[epoch13, step851]: loss 0.035336
[epoch13, step852]: loss 0.033089
[epoch13, step853]: loss 0.040454
[epoch13, step854]: loss 0.033990
[epoch13, step855]: loss 0.037615
[epoch13, step856]: loss 0.031660
[epoch13, step857]: loss 0.034246
[epoch13, step858]: loss 0.034733
[epoch13, step859]: loss 0.034299
[epoch13, step860]: loss 0.032615
[epoch13, step861]: loss 0.032780
[epoch13, step862]: loss 0.032989
[epoch13, step863]: loss 0.031721
[epoch13, step864]: loss 0.036933
[epoch13, step865]: loss 0.034040
[epoch13, step866]: loss 0.035453
[epoch13, step867]: loss 0.036840
[epoch13, step868]: loss 0.036506
[epoch13, step869]: loss 0.034225
[epoch13, step870]: loss 0.041651
[epoch13, step871]: loss 0.033472
[epoch13, step872]: loss 0.036011
[epoch13, step873]: loss 0.035686
[epoch13, step874]: loss 0.034499
[epoch13, step875]: loss 0.034460
[epoch13, step876]: loss 0.036823
[epoch13, step877]: loss 0.029981
[epoch13, step878]: loss 0.033671
[epoch13, step879]: loss 0.037778
[epoch13, step880]: loss 0.036344
[epoch13, step881]: loss 0.032733
[epoch13, step882]: loss 0.034061
[epoch13, step883]: loss 0.034014
[epoch13, step884]: loss 0.037104
[epoch13, step885]: loss 0.035112
[epoch13, step886]: loss 0.035951
[epoch13, step887]: loss 0.035012
[epoch13, step888]: loss 0.035382
[epoch13, step889]: loss 0.034796
[epoch13, step890]: loss 0.034155
[epoch13, step891]: loss 0.036210
[epoch13, step892]: loss 0.030852
[epoch13, step893]: loss 0.034667
[epoch13, step894]: loss 0.035737
[epoch13, step895]: loss 0.032140
[epoch13, step896]: loss 0.032735
[epoch13, step897]: loss 0.035772
[epoch13, step898]: loss 0.037112
[epoch13, step899]: loss 0.038945
[epoch13, step900]: loss 0.036204
[epoch13, step901]: loss 0.037103
[epoch13, step902]: loss 0.034498
[epoch13, step903]: loss 0.035376
[epoch13, step904]: loss 0.037391
[epoch13, step905]: loss 0.037910
[epoch13, step906]: loss 0.031743
[epoch13, step907]: loss 0.033830
[epoch13, step908]: loss 0.031490
[epoch13, step909]: loss 0.037406
[epoch13, step910]: loss 0.033626
[epoch13, step911]: loss 0.035507
[epoch13, step912]: loss 0.033253
[epoch13, step913]: loss 0.034738
[epoch13, step914]: loss 0.039706
[epoch13, step915]: loss 0.034019
[epoch13, step916]: loss 0.033615
[epoch13, step917]: loss 0.035382
[epoch13, step918]: loss 0.039753
[epoch13, step919]: loss 0.035220
[epoch13, step920]: loss 0.037786
[epoch13, step921]: loss 0.034153
[epoch13, step922]: loss 0.034466
[epoch13, step923]: loss 0.033209
[epoch13, step924]: loss 0.030200
[epoch13, step925]: loss 0.036123
[epoch13, step926]: loss 0.035218
[epoch13, step927]: loss 0.035843
[epoch13, step928]: loss 0.035324
[epoch13, step929]: loss 0.038198
[epoch13, step930]: loss 0.036452
[epoch13, step931]: loss 0.037430
[epoch13, step932]: loss 0.032360
[epoch13, step933]: loss 0.039316
[epoch13, step934]: loss 0.032459
[epoch13, step935]: loss 0.033172
[epoch13, step936]: loss 0.032480
[epoch13, step937]: loss 0.036439
[epoch13, step938]: loss 0.038144
[epoch13, step939]: loss 0.031661
[epoch13, step940]: loss 0.034208
[epoch13, step941]: loss 0.037944
[epoch13, step942]: loss 0.036705
[epoch13, step943]: loss 0.033550
[epoch13, step944]: loss 0.038159
[epoch13, step945]: loss 0.031394
[epoch13, step946]: loss 0.035627
[epoch13, step947]: loss 0.039285
[epoch13, step948]: loss 0.030439
[epoch13, step949]: loss 0.034223
[epoch13, step950]: loss 0.038581
[epoch13, step951]: loss 0.039011
[epoch13, step952]: loss 0.034915
[epoch13, step953]: loss 0.037153
[epoch13, step954]: loss 0.033325
[epoch13, step955]: loss 0.042254
[epoch13, step956]: loss 0.052108
[epoch13, step957]: loss 0.047897
[epoch13, step958]: loss 0.045228
[epoch13, step959]: loss 0.047998
[epoch13, step960]: loss 0.045545
[epoch13, step961]: loss 0.045983
[epoch13, step962]: loss 0.044692
[epoch13, step963]: loss 0.043011
[epoch13, step964]: loss 0.043472
[epoch13, step965]: loss 0.043484
[epoch13, step966]: loss 0.042453
[epoch13, step967]: loss 0.042197
[epoch13, step968]: loss 0.044422
[epoch13, step969]: loss 0.044327
[epoch13, step970]: loss 0.043156
[epoch13, step971]: loss 0.042425
[epoch13, step972]: loss 0.043309
[epoch13, step973]: loss 0.042774
[epoch13, step974]: loss 0.043940
[epoch13, step975]: loss 0.042003
[epoch13, step976]: loss 0.041125
[epoch13, step977]: loss 0.043215
[epoch13, step978]: loss 0.042420
[epoch13, step979]: loss 0.041743
[epoch13, step980]: loss 0.041120
[epoch13, step981]: loss 0.042369
[epoch13, step982]: loss 0.042172
[epoch13, step983]: loss 0.043448
[epoch13, step984]: loss 0.041648
[epoch13, step985]: loss 0.041277
[epoch13, step986]: loss 0.043608
[epoch13, step987]: loss 0.042559
[epoch13, step988]: loss 0.042633
[epoch13, step989]: loss 0.041593
[epoch13, step990]: loss 0.041871
[epoch13, step991]: loss 0.041899
[epoch13, step992]: loss 0.042163
[epoch13, step993]: loss 0.041417
[epoch13, step994]: loss 0.040265
[epoch13, step995]: loss 0.042937
[epoch13, step996]: loss 0.042193
[epoch13, step997]: loss 0.041479
[epoch13, step998]: loss 0.042078
[epoch13, step999]: loss 0.041907
[epoch13, step1000]: loss 0.042128
[epoch13, step1001]: loss 0.042254
[epoch13, step1002]: loss 0.041055
[epoch13, step1003]: loss 0.041047
[epoch13, step1004]: loss 0.042910
[epoch13, step1005]: loss 0.041446
[epoch13, step1006]: loss 0.041573
[epoch13, step1007]: loss 0.040553
[epoch13, step1008]: loss 0.041489
[epoch13, step1009]: loss 0.041732
[epoch13, step1010]: loss 0.042548
[epoch13, step1011]: loss 0.041006
[epoch13, step1012]: loss 0.040368
[epoch13, step1013]: loss 0.042258
[epoch13, step1014]: loss 0.041860
[epoch13, step1015]: loss 0.041766
[epoch13, step1016]: loss 0.040805
[epoch13, step1017]: loss 0.041365
[epoch13, step1018]: loss 0.041456
[epoch13, step1019]: loss 0.042862
[epoch13, step1020]: loss 0.041447
[epoch13, step1021]: loss 0.039801
[epoch13, step1022]: loss 0.042034
[epoch13, step1023]: loss 0.041558
[epoch13, step1024]: loss 0.041869
[epoch13, step1025]: loss 0.039999
[epoch13, step1026]: loss 0.040787
[epoch13, step1027]: loss 0.041864
[epoch13, step1028]: loss 0.041827
[epoch13, step1029]: loss 0.041175
[epoch13, step1030]: loss 0.040146
[epoch13, step1031]: loss 0.042141
[epoch13, step1032]: loss 0.041909
[epoch13, step1033]: loss 0.041539
[epoch13, step1034]: loss 0.040729
[epoch13, step1035]: loss 0.041504
[epoch13, step1036]: loss 0.041675
[epoch13, step1037]: loss 0.042126
[epoch13, step1038]: loss 0.040987
[epoch13, step1039]: loss 0.040816
[epoch13, step1040]: loss 0.042499
[epoch13, step1041]: loss 0.041409
[epoch13, step1042]: loss 0.040943
[epoch13, step1043]: loss 0.040372
[epoch13, step1044]: loss 0.041084
[epoch13, step1045]: loss 0.041304
[epoch13, step1046]: loss 0.041290
[epoch13, step1047]: loss 0.040434
[epoch13, step1048]: loss 0.040179
[epoch13, step1049]: loss 0.042487
[epoch13, step1050]: loss 0.041259
[epoch13, step1051]: loss 0.041536
[epoch13, step1052]: loss 0.040606
[epoch13, step1053]: loss 0.041156
[epoch13, step1054]: loss 0.041350
[epoch13, step1055]: loss 0.041120
[epoch13, step1056]: loss 0.039786
[epoch13, step1057]: loss 0.039562
[epoch13, step1058]: loss 0.042064
[epoch13, step1059]: loss 0.041558
[epoch13, step1060]: loss 0.041203
[epoch13, step1061]: loss 0.040435
[epoch13, step1062]: loss 0.042252
[epoch13, step1063]: loss 0.042098
[epoch13, step1064]: loss 0.041329
[epoch13, step1065]: loss 0.040187
[epoch13, step1066]: loss 0.039190
[epoch13, step1067]: loss 0.042359
[epoch13, step1068]: loss 0.040293
[epoch13, step1069]: loss 0.041270
[epoch13, step1070]: loss 0.040534
[epoch13, step1071]: loss 0.041998
[epoch13, step1072]: loss 0.041794
[epoch13, step1073]: loss 0.042006
[epoch13, step1074]: loss 0.040354
[epoch13, step1075]: loss 0.039972
[epoch13, step1076]: loss 0.042206
[epoch13, step1077]: loss 0.041329
[epoch13, step1078]: loss 0.041756
[epoch13, step1079]: loss 0.040748
[epoch13, step1080]: loss 0.041222
[epoch13, step1081]: loss 0.041905
[epoch13, step1082]: loss 0.041568
[epoch13, step1083]: loss 0.040541
[epoch13, step1084]: loss 0.040549
[epoch13, step1085]: loss 0.041058
[epoch13, step1086]: loss 0.041266
[epoch13, step1087]: loss 0.041249
[epoch13, step1088]: loss 0.040014
[epoch13, step1089]: loss 0.040944
[epoch13, step1090]: loss 0.041235
[epoch13, step1091]: loss 0.042030
[epoch13, step1092]: loss 0.041201
[epoch13, step1093]: loss 0.040421
[epoch13, step1094]: loss 0.042119
[epoch13, step1095]: loss 0.040407
[epoch13, step1096]: loss 0.040515
[epoch13, step1097]: loss 0.040245
[epoch13, step1098]: loss 0.041596
[epoch13, step1099]: loss 0.042383
[epoch13, step1100]: loss 0.043162
[epoch13, step1101]: loss 0.042215
[epoch13, step1102]: loss 0.041324
[epoch13, step1103]: loss 0.042933
[epoch13, step1104]: loss 0.041852
[epoch13, step1105]: loss 0.042708
[epoch13, step1106]: loss 0.040711
[epoch13, step1107]: loss 0.041843
[epoch13, step1108]: loss 0.041984
[epoch13, step1109]: loss 0.042286
[epoch13, step1110]: loss 0.041643
[epoch13, step1111]: loss 0.040506
[epoch13, step1112]: loss 0.042665
[epoch13, step1113]: loss 0.041378
[epoch13, step1114]: loss 0.041223
[epoch13, step1115]: loss 0.040999
[epoch13, step1116]: loss 0.041145
[epoch13, step1117]: loss 0.041705
[epoch13, step1118]: loss 0.041976
[epoch13, step1119]: loss 0.041143
[epoch13, step1120]: loss 0.040890
[epoch13, step1121]: loss 0.042402
[epoch13, step1122]: loss 0.043033
[epoch13, step1123]: loss 0.042043
[epoch13, step1124]: loss 0.041722
[epoch13, step1125]: loss 0.041051
[epoch13, step1126]: loss 0.042489
[epoch13, step1127]: loss 0.041580
[epoch13, step1128]: loss 0.041263
[epoch13, step1129]: loss 0.040175
[epoch13, step1130]: loss 0.042455
[epoch13, step1131]: loss 0.042295
[epoch13, step1132]: loss 0.041065
[epoch13, step1133]: loss 0.039924
[epoch13, step1134]: loss 0.041299
[epoch13, step1135]: loss 0.042524
[epoch13, step1136]: loss 0.042821
[epoch13, step1137]: loss 0.041321
[epoch13, step1138]: loss 0.040444
[epoch13, step1139]: loss 0.042904
[epoch13, step1140]: loss 0.041783
[epoch13, step1141]: loss 0.041231
[epoch13, step1142]: loss 0.042170
[epoch13, step1143]: loss 0.042051
[epoch13, step1144]: loss 0.041693
[epoch13, step1145]: loss 0.042009
[epoch13, step1146]: loss 0.041440
[epoch13, step1147]: loss 0.040381
[epoch13, step1148]: loss 0.043210
[epoch13, step1149]: loss 0.041494
[epoch13, step1150]: loss 0.041044
[epoch13, step1151]: loss 0.040828
[epoch13, step1152]: loss 0.041679
[epoch13, step1153]: loss 0.041174
[epoch13, step1154]: loss 0.041787
[epoch13, step1155]: loss 0.040783
[epoch13, step1156]: loss 0.039849
[epoch13, step1157]: loss 0.042653
[epoch13, step1158]: loss 0.041076
[epoch13, step1159]: loss 0.040775
[epoch13, step1160]: loss 0.040885
[epoch13, step1161]: loss 0.042026
[epoch13, step1162]: loss 0.041208
[epoch13, step1163]: loss 0.040808
[epoch13, step1164]: loss 0.040654
[epoch13, step1165]: loss 0.040549
[epoch13, step1166]: loss 0.041961
[epoch13, step1167]: loss 0.041672
[epoch13, step1168]: loss 0.040940
[epoch13, step1169]: loss 0.040847
[epoch13, step1170]: loss 0.041734
[epoch13, step1171]: loss 0.041586
[epoch13, step1172]: loss 0.042943
[epoch13, step1173]: loss 0.041103
[epoch13, step1174]: loss 0.040697
[epoch13, step1175]: loss 0.041458
[epoch13, step1176]: loss 0.041489
[epoch13, step1177]: loss 0.041547
[epoch13, step1178]: loss 0.040778
[epoch13, step1179]: loss 0.040202
[epoch13, step1180]: loss 0.041197
[epoch13, step1181]: loss 0.042939
[epoch13, step1182]: loss 0.040978
[epoch13, step1183]: loss 0.040617
[epoch13, step1184]: loss 0.041927
[epoch13, step1185]: loss 0.041659
[epoch13, step1186]: loss 0.041872
[epoch13, step1187]: loss 0.039930
[epoch13, step1188]: loss 0.041188
[epoch13, step1189]: loss 0.041729
[epoch13, step1190]: loss 0.041738
[epoch13, step1191]: loss 0.041784
[epoch13, step1192]: loss 0.039732
[epoch13, step1193]: loss 0.042194
[epoch13, step1194]: loss 0.041945
[epoch13, step1195]: loss 0.040665
[epoch13, step1196]: loss 0.039719
[epoch13, step1197]: loss 0.041323
[epoch13, step1198]: loss 0.041210
[epoch13, step1199]: loss 0.041249
[epoch13, step1200]: loss 0.041120
[epoch13, step1201]: loss 0.040073
[epoch13, step1202]: loss 0.042647
[epoch13, step1203]: loss 0.041652
[epoch13, step1204]: loss 0.041411
[epoch13, step1205]: loss 0.040262
[epoch13, step1206]: loss 0.040399
[epoch13, step1207]: loss 0.041273
[epoch13, step1208]: loss 0.042170
[epoch13, step1209]: loss 0.040474
[epoch13, step1210]: loss 0.040222
[epoch13, step1211]: loss 0.042473
[epoch13, step1212]: loss 0.041395
[epoch13, step1213]: loss 0.041434
[epoch13, step1214]: loss 0.040439
[epoch13, step1215]: loss 0.041769
[epoch13, step1216]: loss 0.041963
[epoch13, step1217]: loss 0.041937
[epoch13, step1218]: loss 0.040480
[epoch13, step1219]: loss 0.040755
[epoch13, step1220]: loss 0.042669
[epoch13, step1221]: loss 0.040829
[epoch13, step1222]: loss 0.041469
[epoch13, step1223]: loss 0.040256
[epoch13, step1224]: loss 0.041238
[epoch13, step1225]: loss 0.041435
[epoch13, step1226]: loss 0.042195
[epoch13, step1227]: loss 0.041182
[epoch13, step1228]: loss 0.039843
[epoch13, step1229]: loss 0.042133
[epoch13, step1230]: loss 0.040999
[epoch13, step1231]: loss 0.040937
[epoch13, step1232]: loss 0.041272
[epoch13, step1233]: loss 0.040999
[epoch13, step1234]: loss 0.041122
[epoch13, step1235]: loss 0.042153
[epoch13, step1236]: loss 0.041058
[epoch13, step1237]: loss 0.040061
[epoch13, step1238]: loss 0.041282
[epoch13, step1239]: loss 0.041319
[epoch13, step1240]: loss 0.041770
[epoch13, step1241]: loss 0.040524
[epoch13, step1242]: loss 0.041625
[epoch13, step1243]: loss 0.041857
[epoch13, step1244]: loss 0.042176
[epoch13, step1245]: loss 0.041091
[epoch13, step1246]: loss 0.040042
[epoch13, step1247]: loss 0.042100
[epoch13, step1248]: loss 0.041224
[epoch13, step1249]: loss 0.041132
[epoch13, step1250]: loss 0.040311
[epoch13, step1251]: loss 0.040402
[epoch13, step1252]: loss 0.042740
[epoch13, step1253]: loss 0.041866
[epoch13, step1254]: loss 0.040801
[epoch13, step1255]: loss 0.041086
[epoch13, step1256]: loss 0.042380
[epoch13, step1257]: loss 0.040523
[epoch13, step1258]: loss 0.040904
[epoch13, step1259]: loss 0.040267
[epoch13, step1260]: loss 0.041564
[epoch13, step1261]: loss 0.041102
[epoch13, step1262]: loss 0.040520
[epoch13, step1263]: loss 0.041153
[epoch13, step1264]: loss 0.041668
[epoch13, step1265]: loss 0.041179
[epoch13, step1266]: loss 0.040484
[epoch13, step1267]: loss 0.041047
[epoch13, step1268]: loss 0.040577
[epoch13, step1269]: loss 0.041239
[epoch13, step1270]: loss 0.041436
[epoch13, step1271]: loss 0.041533
[epoch13, step1272]: loss 0.040814
[epoch13, step1273]: loss 0.040163
[epoch13, step1274]: loss 0.042192
[epoch13, step1275]: loss 0.041652
[epoch13, step1276]: loss 0.041132
[epoch13, step1277]: loss 0.040527
[epoch13, step1278]: loss 0.041510
[epoch13, step1279]: loss 0.041421
[epoch13, step1280]: loss 0.042999
[epoch13, step1281]: loss 0.041656
[epoch13, step1282]: loss 0.040426
[epoch13, step1283]: loss 0.041501
[epoch13, step1284]: loss 0.041313
[epoch13, step1285]: loss 0.041225
[epoch13, step1286]: loss 0.039891
[epoch13, step1287]: loss 0.041834
[epoch13, step1288]: loss 0.041750
[epoch13, step1289]: loss 0.042096
[epoch13, step1290]: loss 0.040898
[epoch13, step1291]: loss 0.039937
[epoch13, step1292]: loss 0.042057
[epoch13, step1293]: loss 0.040393
[epoch13, step1294]: loss 0.040762
[epoch13, step1295]: loss 0.040637
[epoch13, step1296]: loss 0.041136
[epoch13, step1297]: loss 0.041234
[epoch13, step1298]: loss 0.041883
[epoch13, step1299]: loss 0.041557
[epoch13, step1300]: loss 0.041063
[epoch13, step1301]: loss 0.042062
[epoch13, step1302]: loss 0.041994
[epoch13, step1303]: loss 0.040849
[epoch13, step1304]: loss 0.040613
[epoch13, step1305]: loss 0.041132
[epoch13, step1306]: loss 0.040982
[epoch13, step1307]: loss 0.042550
[epoch13, step1308]: loss 0.041586
[epoch13, step1309]: loss 0.039840
[epoch13, step1310]: loss 0.042694
[epoch13, step1311]: loss 0.040688
[epoch13, step1312]: loss 0.041978
[epoch13, step1313]: loss 0.040111
[epoch13, step1314]: loss 0.041384
[epoch13, step1315]: loss 0.041591
[epoch13, step1316]: loss 0.042622
[epoch13, step1317]: loss 0.040306
[epoch13, step1318]: loss 0.040133
[epoch13, step1319]: loss 0.042534
[epoch13, step1320]: loss 0.041818
[epoch13, step1321]: loss 0.041520
[epoch13, step1322]: loss 0.040343
[epoch13, step1323]: loss 0.041223
[epoch13, step1324]: loss 0.041731
[epoch13, step1325]: loss 0.042395
[epoch13, step1326]: loss 0.040471
[epoch13, step1327]: loss 0.040570
[epoch13, step1328]: loss 0.044195
[epoch13, step1329]: loss 0.042367
[epoch13, step1330]: loss 0.040643
[epoch13, step1331]: loss 0.040531
[epoch13, step1332]: loss 0.040665
[epoch13, step1333]: loss 0.041341
[epoch13, step1334]: loss 0.041803
[epoch13, step1335]: loss 0.040870
[epoch13, step1336]: loss 0.039625
[epoch13, step1337]: loss 0.041807
[epoch13, step1338]: loss 0.040623
[epoch13, step1339]: loss 0.040483
[epoch13, step1340]: loss 0.040516
[epoch13, step1341]: loss 0.041025
[epoch13, step1342]: loss 0.040742
[epoch13, step1343]: loss 0.040900
[epoch13, step1344]: loss 0.040394
[epoch13, step1345]: loss 0.039733
[epoch13, step1346]: loss 0.041556
[epoch13, step1347]: loss 0.040596
[epoch13, step1348]: loss 0.041020
[epoch13, step1349]: loss 0.040263
[epoch13, step1350]: loss 0.040024
[epoch13, step1351]: loss 0.040187
[epoch13, step1352]: loss 0.040813
[epoch13, step1353]: loss 0.040595
[epoch13, step1354]: loss 0.039380
[epoch13, step1355]: loss 0.041946
[epoch13, step1356]: loss 0.040486
[epoch13, step1357]: loss 0.040264
[epoch13, step1358]: loss 0.039905
[epoch13, step1359]: loss 0.040847
[epoch13, step1360]: loss 0.041310
[epoch13, step1361]: loss 0.041476
[epoch13, step1362]: loss 0.039987
[epoch13, step1363]: loss 0.038754
[epoch13, step1364]: loss 0.041137
[epoch13, step1365]: loss 0.041731
[epoch13, step1366]: loss 0.040659
[epoch13, step1367]: loss 0.040461
[epoch13, step1368]: loss 0.041126
[epoch13, step1369]: loss 0.042337
[epoch13, step1370]: loss 0.042449
[epoch13, step1371]: loss 0.040204
[epoch13, step1372]: loss 0.040181
[epoch13, step1373]: loss 0.042305
[epoch13, step1374]: loss 0.041455
[epoch13, step1375]: loss 0.042161
[epoch13, step1376]: loss 0.041435
[epoch13, step1377]: loss 0.041132
[epoch13, step1378]: loss 0.042524
[epoch13, step1379]: loss 0.041851
[epoch13, step1380]: loss 0.041894
[epoch13, step1381]: loss 0.041069
[epoch13, step1382]: loss 0.043800
[epoch13, step1383]: loss 0.040821
[epoch13, step1384]: loss 0.041639
[epoch13, step1385]: loss 0.041727
[epoch13, step1386]: loss 0.042310
[epoch13, step1387]: loss 0.041599
[epoch13, step1388]: loss 0.042312
[epoch13, step1389]: loss 0.040366
[epoch13, step1390]: loss 0.040267
[epoch13, step1391]: loss 0.042668
[epoch13, step1392]: loss 0.041125
[epoch13, step1393]: loss 0.041425
[epoch13, step1394]: loss 0.041017
[epoch13, step1395]: loss 0.041337
[epoch13, step1396]: loss 0.041310
[epoch13, step1397]: loss 0.041551
[epoch13, step1398]: loss 0.040532
[epoch13, step1399]: loss 0.040749
[epoch13, step1400]: loss 0.043192
[epoch13, step1401]: loss 0.041750
[epoch13, step1402]: loss 0.040792
[epoch13, step1403]: loss 0.040271
[epoch13, step1404]: loss 0.041190
[epoch13, step1405]: loss 0.041601
[epoch13, step1406]: loss 0.042410
[epoch13, step1407]: loss 0.041980
[epoch13, step1408]: loss 0.039903
[epoch13, step1409]: loss 0.042071
[epoch13, step1410]: loss 0.041198
[epoch13, step1411]: loss 0.040895
[epoch13, step1412]: loss 0.040345
[epoch13, step1413]: loss 0.040909
[epoch13, step1414]: loss 0.041619
[epoch13, step1415]: loss 0.041309
[epoch13, step1416]: loss 0.040615
[epoch13, step1417]: loss 0.039772
[epoch13, step1418]: loss 0.041772
[epoch13, step1419]: loss 0.041655
[epoch13, step1420]: loss 0.040953
[epoch13, step1421]: loss 0.040534
[epoch13, step1422]: loss 0.040943
[epoch13, step1423]: loss 0.041482
[epoch13, step1424]: loss 0.042187
[epoch13, step1425]: loss 0.040488
[epoch13, step1426]: loss 0.040783
[epoch13, step1427]: loss 0.042018
[epoch13, step1428]: loss 0.041611
[epoch13, step1429]: loss 0.042772
[epoch13, step1430]: loss 0.040512
[epoch13, step1431]: loss 0.041528
[epoch13, step1432]: loss 0.042390
[epoch13, step1433]: loss 0.042386
[epoch13, step1434]: loss 0.040137
[epoch13, step1435]: loss 0.040273
[epoch13, step1436]: loss 0.042716
[epoch13, step1437]: loss 0.041237
[epoch13, step1438]: loss 0.041134
[epoch13, step1439]: loss 0.040159
[epoch13, step1440]: loss 0.041034
[epoch13, step1441]: loss 0.043064
[epoch13, step1442]: loss 0.042221
[epoch13, step1443]: loss 0.040507
[epoch13, step1444]: loss 0.040330
[epoch13, step1445]: loss 0.042849
[epoch13, step1446]: loss 0.041173
[epoch13, step1447]: loss 0.041392
[epoch13, step1448]: loss 0.039998
[epoch13, step1449]: loss 0.040739
[epoch13, step1450]: loss 0.040949
[epoch13, step1451]: loss 0.041727
[epoch13, step1452]: loss 0.040834
[epoch13, step1453]: loss 0.040839
[epoch13, step1454]: loss 0.041993
[epoch13, step1455]: loss 0.041608
[epoch13, step1456]: loss 0.041472
[epoch13, step1457]: loss 0.040570
[epoch13, step1458]: loss 0.041288
[epoch13, step1459]: loss 0.040673
[epoch13, step1460]: loss 0.043218
[epoch13, step1461]: loss 0.041593
[epoch13, step1462]: loss 0.040438
[epoch13, step1463]: loss 0.041765
[epoch13, step1464]: loss 0.041144
[epoch13, step1465]: loss 0.040954
[epoch13, step1466]: loss 0.040077
[epoch13, step1467]: loss 0.041979
[epoch13, step1468]: loss 0.040376
[epoch13, step1469]: loss 0.041468
[epoch13, step1470]: loss 0.040910
[epoch13, step1471]: loss 0.039785
[epoch13, step1472]: loss 0.041478
[epoch13, step1473]: loss 0.041377
[epoch13, step1474]: loss 0.041710
[epoch13, step1475]: loss 0.040413
[epoch13, step1476]: loss 0.042408
[epoch13, step1477]: loss 0.041677
[epoch13, step1478]: loss 0.041715
[epoch13, step1479]: loss 0.040908
[epoch13, step1480]: loss 0.040023
[epoch13, step1481]: loss 0.041472
[epoch13, step1482]: loss 0.041306
[epoch13, step1483]: loss 0.041380
[epoch13, step1484]: loss 0.040418
[epoch13, step1485]: loss 0.041015
[epoch13, step1486]: loss 0.040411
[epoch13, step1487]: loss 0.041353
[epoch13, step1488]: loss 0.041023
[epoch13, step1489]: loss 0.040213
[epoch13, step1490]: loss 0.042125
[epoch13, step1491]: loss 0.041150
[epoch13, step1492]: loss 0.041001
[epoch13, step1493]: loss 0.040273
[epoch13, step1494]: loss 0.040771
[epoch13, step1495]: loss 0.040670
[epoch13, step1496]: loss 0.041313
[epoch13, step1497]: loss 0.041180
[epoch13, step1498]: loss 0.040180
[epoch13, step1499]: loss 0.042666
[epoch13, step1500]: loss 0.041118
[epoch13, step1501]: loss 0.041434
[epoch13, step1502]: loss 0.040485
[epoch13, step1503]: loss 0.041138
[epoch13, step1504]: loss 0.041217
[epoch13, step1505]: loss 0.042412
[epoch13, step1506]: loss 0.040009
[epoch13, step1507]: loss 0.040261
[epoch13, step1508]: loss 0.042727
[epoch13, step1509]: loss 0.041329
[epoch13, step1510]: loss 0.041148
[epoch13, step1511]: loss 0.040472
[epoch13, step1512]: loss 0.040722
[epoch13, step1513]: loss 0.040706
[epoch13, step1514]: loss 0.041686
[epoch13, step1515]: loss 0.040563
[epoch13, step1516]: loss 0.039834

[epoch13]: avg loss 0.037732

[epoch14, step1]: loss 0.042653
[epoch14, step2]: loss 0.038300
[epoch14, step3]: loss 0.036927
[epoch14, step4]: loss 0.034761
[epoch14, step5]: loss 0.034770
[epoch14, step6]: loss 0.037579
[epoch14, step7]: loss 0.035499
[epoch14, step8]: loss 0.036759
[epoch14, step9]: loss 0.034019
[epoch14, step10]: loss 0.035416
[epoch14, step11]: loss 0.038091
[epoch14, step12]: loss 0.037165
[epoch14, step13]: loss 0.034592
[epoch14, step14]: loss 0.034428
[epoch14, step15]: loss 0.036474
[epoch14, step16]: loss 0.034740
[epoch14, step17]: loss 0.037042
[epoch14, step18]: loss 0.034475
[epoch14, step19]: loss 0.034119
[epoch14, step20]: loss 0.038102
[epoch14, step21]: loss 0.036399
[epoch14, step22]: loss 0.033866
[epoch14, step23]: loss 0.033700
[epoch14, step24]: loss 0.036575
[epoch14, step25]: loss 0.034366
[epoch14, step26]: loss 0.036771
[epoch14, step27]: loss 0.033403
[epoch14, step28]: loss 0.035370
[epoch14, step29]: loss 0.037861
[epoch14, step30]: loss 0.036941
[epoch14, step31]: loss 0.033922
[epoch14, step32]: loss 0.034990
[epoch14, step33]: loss 0.036935
[epoch14, step34]: loss 0.034888
[epoch14, step35]: loss 0.037376
[epoch14, step36]: loss 0.033406
[epoch14, step37]: loss 0.034633
[epoch14, step38]: loss 0.037072
[epoch14, step39]: loss 0.036288
[epoch14, step40]: loss 0.034645
[epoch14, step41]: loss 0.033722
[epoch14, step42]: loss 0.037116
[epoch14, step43]: loss 0.034952
[epoch14, step44]: loss 0.037726
[epoch14, step45]: loss 0.034238
[epoch14, step46]: loss 0.035437
[epoch14, step47]: loss 0.036886
[epoch14, step48]: loss 0.036633
[epoch14, step49]: loss 0.033041
[epoch14, step50]: loss 0.033957
[epoch14, step51]: loss 0.036695
[epoch14, step52]: loss 0.034600
[epoch14, step53]: loss 0.037121
[epoch14, step54]: loss 0.033422
[epoch14, step55]: loss 0.034924
[epoch14, step56]: loss 0.037733
[epoch14, step57]: loss 0.036537
[epoch14, step58]: loss 0.034259
[epoch14, step59]: loss 0.032923
[epoch14, step60]: loss 0.037396
[epoch14, step61]: loss 0.033747
[epoch14, step62]: loss 0.036072
[epoch14, step63]: loss 0.033181
[epoch14, step64]: loss 0.033844
[epoch14, step65]: loss 0.036985
[epoch14, step66]: loss 0.036748
[epoch14, step67]: loss 0.034367
[epoch14, step68]: loss 0.034092
[epoch14, step69]: loss 0.036639
[epoch14, step70]: loss 0.034430
[epoch14, step71]: loss 0.037343
[epoch14, step72]: loss 0.033897
[epoch14, step73]: loss 0.034376
[epoch14, step74]: loss 0.036408
[epoch14, step75]: loss 0.036469
[epoch14, step76]: loss 0.034809
[epoch14, step77]: loss 0.034482
[epoch14, step78]: loss 0.036767
[epoch14, step79]: loss 0.033968
[epoch14, step80]: loss 0.037454
[epoch14, step81]: loss 0.033935
[epoch14, step82]: loss 0.034440
[epoch14, step83]: loss 0.036262
[epoch14, step84]: loss 0.036565
[epoch14, step85]: loss 0.034722
[epoch14, step86]: loss 0.034364
[epoch14, step87]: loss 0.037390
[epoch14, step88]: loss 0.033671
[epoch14, step89]: loss 0.036442
[epoch14, step90]: loss 0.034694
[epoch14, step91]: loss 0.034012
[epoch14, step92]: loss 0.036976
[epoch14, step93]: loss 0.036799
[epoch14, step94]: loss 0.033611
[epoch14, step95]: loss 0.034493
[epoch14, step96]: loss 0.036788
[epoch14, step97]: loss 0.034940
[epoch14, step98]: loss 0.037199
[epoch14, step99]: loss 0.034136
[epoch14, step100]: loss 0.033128
[epoch14, step101]: loss 0.038037
[epoch14, step102]: loss 0.036163
[epoch14, step103]: loss 0.034311
[epoch14, step104]: loss 0.033882
[epoch14, step105]: loss 0.036881
[epoch14, step106]: loss 0.034438
[epoch14, step107]: loss 0.036517
[epoch14, step108]: loss 0.034147
[epoch14, step109]: loss 0.033751
[epoch14, step110]: loss 0.037250
[epoch14, step111]: loss 0.036135
[epoch14, step112]: loss 0.034357
[epoch14, step113]: loss 0.035065
[epoch14, step114]: loss 0.036630
[epoch14, step115]: loss 0.034451
[epoch14, step116]: loss 0.037616
[epoch14, step117]: loss 0.033951
[epoch14, step118]: loss 0.035504
[epoch14, step119]: loss 0.037160
[epoch14, step120]: loss 0.037327
[epoch14, step121]: loss 0.034658
[epoch14, step122]: loss 0.033986
[epoch14, step123]: loss 0.037274
[epoch14, step124]: loss 0.035185
[epoch14, step125]: loss 0.037216
[epoch14, step126]: loss 0.034077
[epoch14, step127]: loss 0.033806
[epoch14, step128]: loss 0.036679
[epoch14, step129]: loss 0.036142
[epoch14, step130]: loss 0.034356
[epoch14, step131]: loss 0.033763
[epoch14, step132]: loss 0.036551
[epoch14, step133]: loss 0.034326
[epoch14, step134]: loss 0.036003
[epoch14, step135]: loss 0.034290
[epoch14, step136]: loss 0.035064
[epoch14, step137]: loss 0.036810
[epoch14, step138]: loss 0.036921
[epoch14, step139]: loss 0.034203
[epoch14, step140]: loss 0.034773
[epoch14, step141]: loss 0.037064
[epoch14, step142]: loss 0.034837
[epoch14, step143]: loss 0.036941
[epoch14, step144]: loss 0.034123
[epoch14, step145]: loss 0.034971
[epoch14, step146]: loss 0.038158
[epoch14, step147]: loss 0.037901
[epoch14, step148]: loss 0.033803
[epoch14, step149]: loss 0.034225
[epoch14, step150]: loss 0.036407
[epoch14, step151]: loss 0.033996
[epoch14, step152]: loss 0.036043
[epoch14, step153]: loss 0.033835
[epoch14, step154]: loss 0.033908
[epoch14, step155]: loss 0.036493
[epoch14, step156]: loss 0.035774
[epoch14, step157]: loss 0.034274
[epoch14, step158]: loss 0.034770
[epoch14, step159]: loss 0.036445
[epoch14, step160]: loss 0.034881
[epoch14, step161]: loss 0.037187
[epoch14, step162]: loss 0.034461
[epoch14, step163]: loss 0.034762
[epoch14, step164]: loss 0.036772
[epoch14, step165]: loss 0.036587
[epoch14, step166]: loss 0.035220
[epoch14, step167]: loss 0.033652
[epoch14, step168]: loss 0.037542
[epoch14, step169]: loss 0.034366
[epoch14, step170]: loss 0.036766
[epoch14, step171]: loss 0.034231
[epoch14, step172]: loss 0.034477
[epoch14, step173]: loss 0.036988
[epoch14, step174]: loss 0.036426
[epoch14, step175]: loss 0.035180
[epoch14, step176]: loss 0.034170
[epoch14, step177]: loss 0.036966
[epoch14, step178]: loss 0.034458
[epoch14, step179]: loss 0.035954
[epoch14, step180]: loss 0.033901
[epoch14, step181]: loss 0.034301
[epoch14, step182]: loss 0.037084
[epoch14, step183]: loss 0.036906
[epoch14, step184]: loss 0.035298
[epoch14, step185]: loss 0.034154
[epoch14, step186]: loss 0.036693
[epoch14, step187]: loss 0.034527
[epoch14, step188]: loss 0.036525
[epoch14, step189]: loss 0.034018
[epoch14, step190]: loss 0.033716
[epoch14, step191]: loss 0.036457
[epoch14, step192]: loss 0.037102
[epoch14, step193]: loss 0.032626
[epoch14, step194]: loss 0.033103
[epoch14, step195]: loss 0.036739
[epoch14, step196]: loss 0.034628
[epoch14, step197]: loss 0.036759
[epoch14, step198]: loss 0.032954
[epoch14, step199]: loss 0.034294
[epoch14, step200]: loss 0.037081
[epoch14, step201]: loss 0.036683
[epoch14, step202]: loss 0.033650
[epoch14, step203]: loss 0.034237
[epoch14, step204]: loss 0.037054
[epoch14, step205]: loss 0.034078
[epoch14, step206]: loss 0.036879
[epoch14, step207]: loss 0.033830
[epoch14, step208]: loss 0.034235
[epoch14, step209]: loss 0.036991
[epoch14, step210]: loss 0.037300
[epoch14, step211]: loss 0.034509
[epoch14, step212]: loss 0.034426
[epoch14, step213]: loss 0.036481
[epoch14, step214]: loss 0.034118
[epoch14, step215]: loss 0.036853
[epoch14, step216]: loss 0.034401
[epoch14, step217]: loss 0.033627
[epoch14, step218]: loss 0.037024
[epoch14, step219]: loss 0.036547
[epoch14, step220]: loss 0.034411
[epoch14, step221]: loss 0.034544
[epoch14, step222]: loss 0.037317
[epoch14, step223]: loss 0.034867
[epoch14, step224]: loss 0.036586
[epoch14, step225]: loss 0.033991
[epoch14, step226]: loss 0.033482
[epoch14, step227]: loss 0.035761
[epoch14, step228]: loss 0.036843
[epoch14, step229]: loss 0.033362
[epoch14, step230]: loss 0.034255
[epoch14, step231]: loss 0.037157
[epoch14, step232]: loss 0.033958
[epoch14, step233]: loss 0.036126
[epoch14, step234]: loss 0.033470
[epoch14, step235]: loss 0.034608
[epoch14, step236]: loss 0.036400
[epoch14, step237]: loss 0.036363
[epoch14, step238]: loss 0.034594
[epoch14, step239]: loss 0.034006
[epoch14, step240]: loss 0.035805
[epoch14, step241]: loss 0.034895
[epoch14, step242]: loss 0.038071
[epoch14, step243]: loss 0.035246
[epoch14, step244]: loss 0.034064
[epoch14, step245]: loss 0.036649
[epoch14, step246]: loss 0.036164
[epoch14, step247]: loss 0.034505
[epoch14, step248]: loss 0.033525
[epoch14, step249]: loss 0.035787
[epoch14, step250]: loss 0.034350
[epoch14, step251]: loss 0.036849
[epoch14, step252]: loss 0.034665
[epoch14, step253]: loss 0.033706
[epoch14, step254]: loss 0.036351
[epoch14, step255]: loss 0.036314
[epoch14, step256]: loss 0.034254
[epoch14, step257]: loss 0.034331
[epoch14, step258]: loss 0.037111
[epoch14, step259]: loss 0.035081
[epoch14, step260]: loss 0.037020
[epoch14, step261]: loss 0.034572
[epoch14, step262]: loss 0.035121
[epoch14, step263]: loss 0.037059
[epoch14, step264]: loss 0.036809
[epoch14, step265]: loss 0.034188
[epoch14, step266]: loss 0.034042
[epoch14, step267]: loss 0.037178
[epoch14, step268]: loss 0.034608
[epoch14, step269]: loss 0.036961
[epoch14, step270]: loss 0.035032
[epoch14, step271]: loss 0.035024
[epoch14, step272]: loss 0.036542
[epoch14, step273]: loss 0.037010
[epoch14, step274]: loss 0.035835
[epoch14, step275]: loss 0.033896
[epoch14, step276]: loss 0.036329
[epoch14, step277]: loss 0.035082
[epoch14, step278]: loss 0.036820
[epoch14, step279]: loss 0.033483
[epoch14, step280]: loss 0.034199
[epoch14, step281]: loss 0.036856
[epoch14, step282]: loss 0.037071
[epoch14, step283]: loss 0.034120
[epoch14, step284]: loss 0.033595
[epoch14, step285]: loss 0.037697
[epoch14, step286]: loss 0.034373
[epoch14, step287]: loss 0.037176
[epoch14, step288]: loss 0.033366
[epoch14, step289]: loss 0.034909
[epoch14, step290]: loss 0.036738
[epoch14, step291]: loss 0.037030
[epoch14, step292]: loss 0.033615
[epoch14, step293]: loss 0.033810
[epoch14, step294]: loss 0.036198
[epoch14, step295]: loss 0.034083
[epoch14, step296]: loss 0.037329
[epoch14, step297]: loss 0.033536
[epoch14, step298]: loss 0.034145
[epoch14, step299]: loss 0.035703
[epoch14, step300]: loss 0.036361
[epoch14, step301]: loss 0.034220
[epoch14, step302]: loss 0.034453
[epoch14, step303]: loss 0.037234
[epoch14, step304]: loss 0.033954
[epoch14, step305]: loss 0.036174
[epoch14, step306]: loss 0.034750
[epoch14, step307]: loss 0.033661
[epoch14, step308]: loss 0.037619
[epoch14, step309]: loss 0.037002
[epoch14, step310]: loss 0.034148
[epoch14, step311]: loss 0.034903
[epoch14, step312]: loss 0.036593
[epoch14, step313]: loss 0.034034
[epoch14, step314]: loss 0.036850
[epoch14, step315]: loss 0.034915
[epoch14, step316]: loss 0.034122
[epoch14, step317]: loss 0.037309
[epoch14, step318]: loss 0.036573
[epoch14, step319]: loss 0.033498
[epoch14, step320]: loss 0.033105
[epoch14, step321]: loss 0.036170
[epoch14, step322]: loss 0.034151
[epoch14, step323]: loss 0.036078
[epoch14, step324]: loss 0.034635
[epoch14, step325]: loss 0.034261
[epoch14, step326]: loss 0.036578
[epoch14, step327]: loss 0.035692
[epoch14, step328]: loss 0.034476
[epoch14, step329]: loss 0.033880
[epoch14, step330]: loss 0.035812
[epoch14, step331]: loss 0.034640
[epoch14, step332]: loss 0.035974
[epoch14, step333]: loss 0.034103
[epoch14, step334]: loss 0.034169
[epoch14, step335]: loss 0.037288
[epoch14, step336]: loss 0.038495
[epoch14, step337]: loss 0.035007
[epoch14, step338]: loss 0.033601
[epoch14, step339]: loss 0.036838
[epoch14, step340]: loss 0.034922
[epoch14, step341]: loss 0.036281
[epoch14, step342]: loss 0.033757
[epoch14, step343]: loss 0.034288
[epoch14, step344]: loss 0.036222
[epoch14, step345]: loss 0.035813
[epoch14, step346]: loss 0.033782
[epoch14, step347]: loss 0.033898
[epoch14, step348]: loss 0.036643
[epoch14, step349]: loss 0.034986
[epoch14, step350]: loss 0.036014
[epoch14, step351]: loss 0.033092
[epoch14, step352]: loss 0.033496
[epoch14, step353]: loss 0.036577
[epoch14, step354]: loss 0.035290
[epoch14, step355]: loss 0.033109
[epoch14, step356]: loss 0.034647
[epoch14, step357]: loss 0.036390
[epoch14, step358]: loss 0.032684
[epoch14, step359]: loss 0.038482
[epoch14, step360]: loss 0.033582
[epoch14, step361]: loss 0.034651
[epoch14, step362]: loss 0.037455
[epoch14, step363]: loss 0.036354
[epoch14, step364]: loss 0.034915
[epoch14, step365]: loss 0.033976
[epoch14, step366]: loss 0.036702
[epoch14, step367]: loss 0.034692
[epoch14, step368]: loss 0.035988
[epoch14, step369]: loss 0.033619
[epoch14, step370]: loss 0.034693
[epoch14, step371]: loss 0.037561
[epoch14, step372]: loss 0.035713
[epoch14, step373]: loss 0.033716
[epoch14, step374]: loss 0.033630
[epoch14, step375]: loss 0.037361
[epoch14, step376]: loss 0.034629
[epoch14, step377]: loss 0.036750
[epoch14, step378]: loss 0.034409
[epoch14, step379]: loss 0.034840
[epoch14, step380]: loss 0.037379
[epoch14, step381]: loss 0.036038
[epoch14, step382]: loss 0.034070
[epoch14, step383]: loss 0.032930
[epoch14, step384]: loss 0.035531
[epoch14, step385]: loss 0.033851
[epoch14, step386]: loss 0.036615
[epoch14, step387]: loss 0.033981
[epoch14, step388]: loss 0.035001
[epoch14, step389]: loss 0.036193
[epoch14, step390]: loss 0.037616
[epoch14, step391]: loss 0.033615
[epoch14, step392]: loss 0.034847
[epoch14, step393]: loss 0.036549
[epoch14, step394]: loss 0.034415
[epoch14, step395]: loss 0.036627
[epoch14, step396]: loss 0.033680
[epoch14, step397]: loss 0.034025
[epoch14, step398]: loss 0.036850
[epoch14, step399]: loss 0.036253
[epoch14, step400]: loss 0.034179
[epoch14, step401]: loss 0.033658
[epoch14, step402]: loss 0.036333
[epoch14, step403]: loss 0.034386
[epoch14, step404]: loss 0.036964
[epoch14, step405]: loss 0.034533
[epoch14, step406]: loss 0.034660
[epoch14, step407]: loss 0.036772
[epoch14, step408]: loss 0.036941
[epoch14, step409]: loss 0.035464
[epoch14, step410]: loss 0.034434
[epoch14, step411]: loss 0.036634
[epoch14, step412]: loss 0.033914
[epoch14, step413]: loss 0.036588
[epoch14, step414]: loss 0.033892
[epoch14, step415]: loss 0.034483
[epoch14, step416]: loss 0.036190
[epoch14, step417]: loss 0.036222
[epoch14, step418]: loss 0.034636
[epoch14, step419]: loss 0.033190
[epoch14, step420]: loss 0.036614
[epoch14, step421]: loss 0.034273
[epoch14, step422]: loss 0.036235
[epoch14, step423]: loss 0.033887
[epoch14, step424]: loss 0.033725
[epoch14, step425]: loss 0.036713
[epoch14, step426]: loss 0.036748
[epoch14, step427]: loss 0.034531
[epoch14, step428]: loss 0.034240
[epoch14, step429]: loss 0.036846
[epoch14, step430]: loss 0.034595
[epoch14, step431]: loss 0.037467
[epoch14, step432]: loss 0.033654
[epoch14, step433]: loss 0.035116
[epoch14, step434]: loss 0.037135
[epoch14, step435]: loss 0.037016
[epoch14, step436]: loss 0.033792
[epoch14, step437]: loss 0.034543
[epoch14, step438]: loss 0.036728
[epoch14, step439]: loss 0.034683
[epoch14, step440]: loss 0.036831
[epoch14, step441]: loss 0.033786
[epoch14, step442]: loss 0.034039
[epoch14, step443]: loss 0.037324
[epoch14, step444]: loss 0.035600
[epoch14, step445]: loss 0.034469
[epoch14, step446]: loss 0.034188
[epoch14, step447]: loss 0.036853
[epoch14, step448]: loss 0.034254
[epoch14, step449]: loss 0.036238
[epoch14, step450]: loss 0.033762
[epoch14, step451]: loss 0.034140
[epoch14, step452]: loss 0.035920
[epoch14, step453]: loss 0.036741
[epoch14, step454]: loss 0.033774
[epoch14, step455]: loss 0.034261
[epoch14, step456]: loss 0.035924
[epoch14, step457]: loss 0.034605
[epoch14, step458]: loss 0.036105
[epoch14, step459]: loss 0.034256
[epoch14, step460]: loss 0.034309
[epoch14, step461]: loss 0.037552
[epoch14, step462]: loss 0.035388
[epoch14, step463]: loss 0.034372
[epoch14, step464]: loss 0.033801
[epoch14, step465]: loss 0.037599
[epoch14, step466]: loss 0.034326
[epoch14, step467]: loss 0.036092
[epoch14, step468]: loss 0.033979
[epoch14, step469]: loss 0.034137
[epoch14, step470]: loss 0.036747
[epoch14, step471]: loss 0.035991
[epoch14, step472]: loss 0.034521
[epoch14, step473]: loss 0.034220
[epoch14, step474]: loss 0.035908
[epoch14, step475]: loss 0.034363
[epoch14, step476]: loss 0.036828
[epoch14, step477]: loss 0.034004
[epoch14, step478]: loss 0.033404
[epoch14, step479]: loss 0.036172
[epoch14, step480]: loss 0.035860
[epoch14, step481]: loss 0.033909
[epoch14, step482]: loss 0.033320
[epoch14, step483]: loss 0.036687
[epoch14, step484]: loss 0.034749
[epoch14, step485]: loss 0.036862
[epoch14, step486]: loss 0.033966
[epoch14, step487]: loss 0.033463
[epoch14, step488]: loss 0.037178
[epoch14, step489]: loss 0.035551
[epoch14, step490]: loss 0.034656
[epoch14, step491]: loss 0.034384
[epoch14, step492]: loss 0.036423
[epoch14, step493]: loss 0.034380
[epoch14, step494]: loss 0.036356
[epoch14, step495]: loss 0.034790
[epoch14, step496]: loss 0.034507
[epoch14, step497]: loss 0.037308
[epoch14, step498]: loss 0.036279
[epoch14, step499]: loss 0.034546
[epoch14, step500]: loss 0.034531
[epoch14, step501]: loss 0.036406
[epoch14, step502]: loss 0.034591
[epoch14, step503]: loss 0.037345
[epoch14, step504]: loss 0.033491
[epoch14, step505]: loss 0.033076
[epoch14, step506]: loss 0.037673
[epoch14, step507]: loss 0.037083
[epoch14, step508]: loss 0.034435
[epoch14, step509]: loss 0.034237
[epoch14, step510]: loss 0.036973
[epoch14, step511]: loss 0.034810
[epoch14, step512]: loss 0.037482
[epoch14, step513]: loss 0.034224
[epoch14, step514]: loss 0.034024
[epoch14, step515]: loss 0.036502
[epoch14, step516]: loss 0.036337
[epoch14, step517]: loss 0.033908
[epoch14, step518]: loss 0.033941
[epoch14, step519]: loss 0.036455
[epoch14, step520]: loss 0.033766
[epoch14, step521]: loss 0.036563
[epoch14, step522]: loss 0.033402
[epoch14, step523]: loss 0.033607
[epoch14, step524]: loss 0.036274
[epoch14, step525]: loss 0.036780
[epoch14, step526]: loss 0.034333
[epoch14, step527]: loss 0.033783
[epoch14, step528]: loss 0.036571
[epoch14, step529]: loss 0.034574
[epoch14, step530]: loss 0.037797
[epoch14, step531]: loss 0.033718
[epoch14, step532]: loss 0.034524
[epoch14, step533]: loss 0.037925
[epoch14, step534]: loss 0.036072
[epoch14, step535]: loss 0.034761
[epoch14, step536]: loss 0.034115
[epoch14, step537]: loss 0.036339
[epoch14, step538]: loss 0.034606
[epoch14, step539]: loss 0.036282
[epoch14, step540]: loss 0.033182
[epoch14, step541]: loss 0.033719
[epoch14, step542]: loss 0.036693
[epoch14, step543]: loss 0.035882
[epoch14, step544]: loss 0.034166
[epoch14, step545]: loss 0.033289
[epoch14, step546]: loss 0.036749
[epoch14, step547]: loss 0.034072
[epoch14, step548]: loss 0.036782
[epoch14, step549]: loss 0.034761
[epoch14, step550]: loss 0.034532
[epoch14, step551]: loss 0.036164
[epoch14, step552]: loss 0.036055
[epoch14, step553]: loss 0.034705
[epoch14, step554]: loss 0.033803
[epoch14, step555]: loss 0.036081
[epoch14, step556]: loss 0.033992
[epoch14, step557]: loss 0.035996
[epoch14, step558]: loss 0.034009
[epoch14, step559]: loss 0.033639
[epoch14, step560]: loss 0.036594
[epoch14, step561]: loss 0.036133
[epoch14, step562]: loss 0.033994
[epoch14, step563]: loss 0.035568
[epoch14, step564]: loss 0.040657
[epoch14, step565]: loss 0.039552
[epoch14, step566]: loss 0.046277
[epoch14, step567]: loss 0.039513
[epoch14, step568]: loss 0.040024
[epoch14, step569]: loss 0.035953
[epoch14, step570]: loss 0.044253
[epoch14, step571]: loss 0.039181
[epoch14, step572]: loss 0.037206
[epoch14, step573]: loss 0.038450
[epoch14, step574]: loss 0.040961
[epoch14, step575]: loss 0.031872
[epoch14, step576]: loss 0.032823
[epoch14, step577]: loss 0.037388
[epoch14, step578]: loss 0.029592
[epoch14, step579]: loss 0.039683
[epoch14, step580]: loss 0.030678
[epoch14, step581]: loss 0.036409
[epoch14, step582]: loss 0.036495
[epoch14, step583]: loss 0.035739
[epoch14, step584]: loss 0.033866
[epoch14, step585]: loss 0.037030
[epoch14, step586]: loss 0.034606
[epoch14, step587]: loss 0.040046
[epoch14, step588]: loss 0.035001
[epoch14, step589]: loss 0.035233
[epoch14, step590]: loss 0.039521
[epoch14, step591]: loss 0.031844
[epoch14, step592]: loss 0.037982
[epoch14, step593]: loss 0.033209
[epoch14, step594]: loss 0.038235
[epoch14, step595]: loss 0.039080
[epoch14, step596]: loss 0.036510
[epoch14, step597]: loss 0.036134
[epoch14, step598]: loss 0.036964
[epoch14, step599]: loss 0.034572
[epoch14, step600]: loss 0.038159
[epoch14, step601]: loss 0.030536
[epoch14, step602]: loss 0.033752
[epoch14, step603]: loss 0.036275
[epoch14, step604]: loss 0.039494
[epoch14, step605]: loss 0.035873
[epoch14, step606]: loss 0.034490
[epoch14, step607]: loss 0.038681
[epoch14, step608]: loss 0.037075
[epoch14, step609]: loss 0.037726
[epoch14, step610]: loss 0.039397
[epoch14, step611]: loss 0.038902
[epoch14, step612]: loss 0.035129
[epoch14, step613]: loss 0.030689
[epoch14, step614]: loss 0.035551
[epoch14, step615]: loss 0.040653
[epoch14, step616]: loss 0.034589
[epoch14, step617]: loss 0.034185
[epoch14, step618]: loss 0.037565
[epoch14, step619]: loss 0.039182
[epoch14, step620]: loss 0.035583
[epoch14, step621]: loss 0.038088
[epoch14, step622]: loss 0.031233
[epoch14, step623]: loss 0.033028
[epoch14, step624]: loss 0.038437
[epoch14, step625]: loss 0.036457
[epoch14, step626]: loss 0.038924
[epoch14, step627]: loss 0.033198
[epoch14, step628]: loss 0.035193
[epoch14, step629]: loss 0.030671
[epoch14, step630]: loss 0.032341
[epoch14, step631]: loss 0.042286
[epoch14, step632]: loss 0.034905
[epoch14, step633]: loss 0.034994
[epoch14, step634]: loss 0.037070
[epoch14, step635]: loss 0.036913
[epoch14, step636]: loss 0.032426
[epoch14, step637]: loss 0.038342
[epoch14, step638]: loss 0.038631
[epoch14, step639]: loss 0.032558
[epoch14, step640]: loss 0.040526
[epoch14, step641]: loss 0.040266
[epoch14, step642]: loss 0.035388
[epoch14, step643]: loss 0.035164
[epoch14, step644]: loss 0.036268
[epoch14, step645]: loss 0.033917
[epoch14, step646]: loss 0.036222
[epoch14, step647]: loss 0.034484
[epoch14, step648]: loss 0.034398
[epoch14, step649]: loss 0.037595
[epoch14, step650]: loss 0.033054
[epoch14, step651]: loss 0.038245
[epoch14, step652]: loss 0.038119
[epoch14, step653]: loss 0.038188
[epoch14, step654]: loss 0.033253
[epoch14, step655]: loss 0.034940
[epoch14, step656]: loss 0.034106
[epoch14, step657]: loss 0.038546
[epoch14, step658]: loss 0.035509
[epoch14, step659]: loss 0.037685
[epoch14, step660]: loss 0.032829
[epoch14, step661]: loss 0.036158
[epoch14, step662]: loss 0.033836
[epoch14, step663]: loss 0.032332
[epoch14, step664]: loss 0.036599
[epoch14, step665]: loss 0.037472
[epoch14, step666]: loss 0.037071
[epoch14, step667]: loss 0.037681
[epoch14, step668]: loss 0.033999
[epoch14, step669]: loss 0.038177
[epoch14, step670]: loss 0.037690
[epoch14, step671]: loss 0.032239
[epoch14, step672]: loss 0.035011
[epoch14, step673]: loss 0.033201
[epoch14, step674]: loss 0.031629
[epoch14, step675]: loss 0.030854
[epoch14, step676]: loss 0.034100
[epoch14, step677]: loss 0.035113
[epoch14, step678]: loss 0.033025
[epoch14, step679]: loss 0.035060
[epoch14, step680]: loss 0.040679
[epoch14, step681]: loss 0.031899
[epoch14, step682]: loss 0.036215
[epoch14, step683]: loss 0.035584
[epoch14, step684]: loss 0.035403
[epoch14, step685]: loss 0.035129
[epoch14, step686]: loss 0.038409
[epoch14, step687]: loss 0.036179
[epoch14, step688]: loss 0.034958
[epoch14, step689]: loss 0.036106
[epoch14, step690]: loss 0.036104
[epoch14, step691]: loss 0.035249
[epoch14, step692]: loss 0.034078
[epoch14, step693]: loss 0.038689
[epoch14, step694]: loss 0.032792
[epoch14, step695]: loss 0.038370
[epoch14, step696]: loss 0.035210
[epoch14, step697]: loss 0.038037
[epoch14, step698]: loss 0.035258
[epoch14, step699]: loss 0.033945
[epoch14, step700]: loss 0.031345
[epoch14, step701]: loss 0.036423
[epoch14, step702]: loss 0.031844
[epoch14, step703]: loss 0.034299
[epoch14, step704]: loss 0.036134
[epoch14, step705]: loss 0.036022
[epoch14, step706]: loss 0.034072
[epoch14, step707]: loss 0.033653
[epoch14, step708]: loss 0.035041
[epoch14, step709]: loss 0.037639
[epoch14, step710]: loss 0.033182
[epoch14, step711]: loss 0.037425
[epoch14, step712]: loss 0.037550
[epoch14, step713]: loss 0.038362
[epoch14, step714]: loss 0.032157
[epoch14, step715]: loss 0.033586
[epoch14, step716]: loss 0.036163
[epoch14, step717]: loss 0.033774
[epoch14, step718]: loss 0.036041
[epoch14, step719]: loss 0.045261
[epoch14, step720]: loss 0.034795
[epoch14, step721]: loss 0.033142
[epoch14, step722]: loss 0.041182
[epoch14, step723]: loss 0.037995
[epoch14, step724]: loss 0.032932
[epoch14, step725]: loss 0.036946
[epoch14, step726]: loss 0.032005
[epoch14, step727]: loss 0.034319
[epoch14, step728]: loss 0.037108
[epoch14, step729]: loss 0.032337
[epoch14, step730]: loss 0.032835
[epoch14, step731]: loss 0.036552
[epoch14, step732]: loss 0.036653
[epoch14, step733]: loss 0.034498
[epoch14, step734]: loss 0.034076
[epoch14, step735]: loss 0.038281
[epoch14, step736]: loss 0.036012
[epoch14, step737]: loss 0.037192
[epoch14, step738]: loss 0.030883
[epoch14, step739]: loss 0.036869
[epoch14, step740]: loss 0.033526
[epoch14, step741]: loss 0.036723
[epoch14, step742]: loss 0.033189
[epoch14, step743]: loss 0.033965
[epoch14, step744]: loss 0.033493
[epoch14, step745]: loss 0.033758
[epoch14, step746]: loss 0.036419
[epoch14, step747]: loss 0.039186
[epoch14, step748]: loss 0.036384
[epoch14, step749]: loss 0.035572
[epoch14, step750]: loss 0.038403
[epoch14, step751]: loss 0.033108
[epoch14, step752]: loss 0.035037
[epoch14, step753]: loss 0.035785
[epoch14, step754]: loss 0.034023
[epoch14, step755]: loss 0.037115
[epoch14, step756]: loss 0.034136
[epoch14, step757]: loss 0.030236
[epoch14, step758]: loss 0.034661
[epoch14, step759]: loss 0.033476
[epoch14, step760]: loss 0.034848
[epoch14, step761]: loss 0.038149
[epoch14, step762]: loss 0.031610
[epoch14, step763]: loss 0.035330
[epoch14, step764]: loss 0.034925
[epoch14, step765]: loss 0.037308
[epoch14, step766]: loss 0.037026
[epoch14, step767]: loss 0.039044
[epoch14, step768]: loss 0.030940
[epoch14, step769]: loss 0.036707
[epoch14, step770]: loss 0.034761
[epoch14, step771]: loss 0.033490
[epoch14, step772]: loss 0.038149
[epoch14, step773]: loss 0.035701
[epoch14, step774]: loss 0.035715
[epoch14, step775]: loss 0.029717
[epoch14, step776]: loss 0.038138
[epoch14, step777]: loss 0.033330
[epoch14, step778]: loss 0.037098
[epoch14, step779]: loss 0.035242
[epoch14, step780]: loss 0.030151
[epoch14, step781]: loss 0.034924
[epoch14, step782]: loss 0.032095
[epoch14, step783]: loss 0.030534
[epoch14, step784]: loss 0.031330
[epoch14, step785]: loss 0.031716
[epoch14, step786]: loss 0.034531
[epoch14, step787]: loss 0.034590
[epoch14, step788]: loss 0.036344
[epoch14, step789]: loss 0.034855
[epoch14, step790]: loss 0.033988
[epoch14, step791]: loss 0.038118
[epoch14, step792]: loss 0.035868
[epoch14, step793]: loss 0.037285
[epoch14, step794]: loss 0.030236
[epoch14, step795]: loss 0.034920
[epoch14, step796]: loss 0.038243
[epoch14, step797]: loss 0.036967
[epoch14, step798]: loss 0.037237
[epoch14, step799]: loss 0.037266
[epoch14, step800]: loss 0.031159
[epoch14, step801]: loss 0.034047
[epoch14, step802]: loss 0.033157
[epoch14, step803]: loss 0.037139
[epoch14, step804]: loss 0.037918
[epoch14, step805]: loss 0.038010
[epoch14, step806]: loss 0.032450
[epoch14, step807]: loss 0.031695
[epoch14, step808]: loss 0.033887
[epoch14, step809]: loss 0.031661
[epoch14, step810]: loss 0.035573
[epoch14, step811]: loss 0.034729
[epoch14, step812]: loss 0.032749
[epoch14, step813]: loss 0.033251
[epoch14, step814]: loss 0.036130
[epoch14, step815]: loss 0.033632
[epoch14, step816]: loss 0.033976
[epoch14, step817]: loss 0.035034
[epoch14, step818]: loss 0.031655
[epoch14, step819]: loss 0.031198
[epoch14, step820]: loss 0.033955
[epoch14, step821]: loss 0.031709
[epoch14, step822]: loss 0.039722
[epoch14, step823]: loss 0.033767
[epoch14, step824]: loss 0.035566
[epoch14, step825]: loss 0.036086
[epoch14, step826]: loss 0.034579
[epoch14, step827]: loss 0.036756
[epoch14, step828]: loss 0.038949
[epoch14, step829]: loss 0.038982
[epoch14, step830]: loss 0.033616
[epoch14, step831]: loss 0.037673
[epoch14, step832]: loss 0.032333
[epoch14, step833]: loss 0.038478
[epoch14, step834]: loss 0.036585
[epoch14, step835]: loss 0.030568
[epoch14, step836]: loss 0.038972
[epoch14, step837]: loss 0.036371
[epoch14, step838]: loss 0.034307
[epoch14, step839]: loss 0.040368
[epoch14, step840]: loss 0.031658
[epoch14, step841]: loss 0.035359
[epoch14, step842]: loss 0.037274
[epoch14, step843]: loss 0.035741
[epoch14, step844]: loss 0.035548
[epoch14, step845]: loss 0.032231
[epoch14, step846]: loss 0.039118
[epoch14, step847]: loss 0.037631
[epoch14, step848]: loss 0.035312
[epoch14, step849]: loss 0.033277
[epoch14, step850]: loss 0.033286
[epoch14, step851]: loss 0.034886
[epoch14, step852]: loss 0.032538
[epoch14, step853]: loss 0.040286
[epoch14, step854]: loss 0.033995
[epoch14, step855]: loss 0.037450
[epoch14, step856]: loss 0.031328
[epoch14, step857]: loss 0.034063
[epoch14, step858]: loss 0.034111
[epoch14, step859]: loss 0.033907
[epoch14, step860]: loss 0.031936
[epoch14, step861]: loss 0.032623
[epoch14, step862]: loss 0.032667
[epoch14, step863]: loss 0.031542
[epoch14, step864]: loss 0.037408
[epoch14, step865]: loss 0.033637
[epoch14, step866]: loss 0.034914
[epoch14, step867]: loss 0.035687
[epoch14, step868]: loss 0.036425
[epoch14, step869]: loss 0.034779
[epoch14, step870]: loss 0.041751
[epoch14, step871]: loss 0.033775
[epoch14, step872]: loss 0.035874
[epoch14, step873]: loss 0.035108
[epoch14, step874]: loss 0.033693
[epoch14, step875]: loss 0.034319
[epoch14, step876]: loss 0.036671
[epoch14, step877]: loss 0.029519
[epoch14, step878]: loss 0.033947
[epoch14, step879]: loss 0.039090
[epoch14, step880]: loss 0.036523
[epoch14, step881]: loss 0.033241
[epoch14, step882]: loss 0.034640
[epoch14, step883]: loss 0.034139
[epoch14, step884]: loss 0.036908
[epoch14, step885]: loss 0.035402
[epoch14, step886]: loss 0.036104
[epoch14, step887]: loss 0.035094
[epoch14, step888]: loss 0.035576
[epoch14, step889]: loss 0.034892
[epoch14, step890]: loss 0.034398
[epoch14, step891]: loss 0.036535
[epoch14, step892]: loss 0.030699
[epoch14, step893]: loss 0.034753
[epoch14, step894]: loss 0.035703
[epoch14, step895]: loss 0.032207
[epoch14, step896]: loss 0.032756
[epoch14, step897]: loss 0.035620
[epoch14, step898]: loss 0.036888
[epoch14, step899]: loss 0.039133
[epoch14, step900]: loss 0.036460
[epoch14, step901]: loss 0.037121
[epoch14, step902]: loss 0.034280
[epoch14, step903]: loss 0.035126
[epoch14, step904]: loss 0.037612
[epoch14, step905]: loss 0.038138
[epoch14, step906]: loss 0.031836
[epoch14, step907]: loss 0.033935
[epoch14, step908]: loss 0.031622
[epoch14, step909]: loss 0.037579
[epoch14, step910]: loss 0.033626
[epoch14, step911]: loss 0.035539
[epoch14, step912]: loss 0.033493
[epoch14, step913]: loss 0.034702
[epoch14, step914]: loss 0.039448
[epoch14, step915]: loss 0.034079
[epoch14, step916]: loss 0.033569
[epoch14, step917]: loss 0.035345
[epoch14, step918]: loss 0.039521
[epoch14, step919]: loss 0.035187
[epoch14, step920]: loss 0.037792
[epoch14, step921]: loss 0.034225
[epoch14, step922]: loss 0.034889
[epoch14, step923]: loss 0.033178
[epoch14, step924]: loss 0.030170
[epoch14, step925]: loss 0.035766
[epoch14, step926]: loss 0.035170
[epoch14, step927]: loss 0.035834
[epoch14, step928]: loss 0.035399
[epoch14, step929]: loss 0.037908
[epoch14, step930]: loss 0.036371
[epoch14, step931]: loss 0.037272
[epoch14, step932]: loss 0.032431
[epoch14, step933]: loss 0.039484
[epoch14, step934]: loss 0.032754
[epoch14, step935]: loss 0.032920
[epoch14, step936]: loss 0.032535
[epoch14, step937]: loss 0.036227
[epoch14, step938]: loss 0.038124
[epoch14, step939]: loss 0.031612
[epoch14, step940]: loss 0.034333
[epoch14, step941]: loss 0.038136
[epoch14, step942]: loss 0.036850
[epoch14, step943]: loss 0.033556
[epoch14, step944]: loss 0.038137
[epoch14, step945]: loss 0.031351
[epoch14, step946]: loss 0.035492
[epoch14, step947]: loss 0.039387
[epoch14, step948]: loss 0.030352
[epoch14, step949]: loss 0.034189
[epoch14, step950]: loss 0.038389
[epoch14, step951]: loss 0.039322
[epoch14, step952]: loss 0.034867
[epoch14, step953]: loss 0.037247
[epoch14, step954]: loss 0.033203
[epoch14, step955]: loss 0.042066
[epoch14, step956]: loss 0.052397
[epoch14, step957]: loss 0.048115
[epoch14, step958]: loss 0.044471
[epoch14, step959]: loss 0.047572
[epoch14, step960]: loss 0.045771
[epoch14, step961]: loss 0.046467
[epoch14, step962]: loss 0.045641
[epoch14, step963]: loss 0.043461
[epoch14, step964]: loss 0.044194
[epoch14, step965]: loss 0.045580
[epoch14, step966]: loss 0.044774
[epoch14, step967]: loss 0.043513
[epoch14, step968]: loss 0.044727
[epoch14, step969]: loss 0.044474
[epoch14, step970]: loss 0.043518
[epoch14, step971]: loss 0.043303
[epoch14, step972]: loss 0.043942
[epoch14, step973]: loss 0.043678
[epoch14, step974]: loss 0.044369
[epoch14, step975]: loss 0.042693
[epoch14, step976]: loss 0.041538
[epoch14, step977]: loss 0.044075
[epoch14, step978]: loss 0.043230
[epoch14, step979]: loss 0.042016
[epoch14, step980]: loss 0.041648
[epoch14, step981]: loss 0.043027
[epoch14, step982]: loss 0.042885
[epoch14, step983]: loss 0.043807
[epoch14, step984]: loss 0.041954
[epoch14, step985]: loss 0.041881
[epoch14, step986]: loss 0.044120
[epoch14, step987]: loss 0.043080
[epoch14, step988]: loss 0.042866
[epoch14, step989]: loss 0.042111
[epoch14, step990]: loss 0.042353
[epoch14, step991]: loss 0.042747
[epoch14, step992]: loss 0.042756
[epoch14, step993]: loss 0.041731
[epoch14, step994]: loss 0.040723
[epoch14, step995]: loss 0.043521
[epoch14, step996]: loss 0.042677
[epoch14, step997]: loss 0.041834
[epoch14, step998]: loss 0.042539
[epoch14, step999]: loss 0.042178
[epoch14, step1000]: loss 0.042436
[epoch14, step1001]: loss 0.042684
[epoch14, step1002]: loss 0.041523
[epoch14, step1003]: loss 0.040973
[epoch14, step1004]: loss 0.043332
[epoch14, step1005]: loss 0.041545
[epoch14, step1006]: loss 0.041634
[epoch14, step1007]: loss 0.040862
[epoch14, step1008]: loss 0.041518
[epoch14, step1009]: loss 0.042054
[epoch14, step1010]: loss 0.042666
[epoch14, step1011]: loss 0.041032
[epoch14, step1012]: loss 0.040591
[epoch14, step1013]: loss 0.042653
[epoch14, step1014]: loss 0.042185
[epoch14, step1015]: loss 0.041730
[epoch14, step1016]: loss 0.041155
[epoch14, step1017]: loss 0.041332
[epoch14, step1018]: loss 0.041983
[epoch14, step1019]: loss 0.043105
[epoch14, step1020]: loss 0.041062
[epoch14, step1021]: loss 0.040551
[epoch14, step1022]: loss 0.042653
[epoch14, step1023]: loss 0.041845
[epoch14, step1024]: loss 0.042518
[epoch14, step1025]: loss 0.040640
[epoch14, step1026]: loss 0.040937
[epoch14, step1027]: loss 0.041972
[epoch14, step1028]: loss 0.041805
[epoch14, step1029]: loss 0.041032
[epoch14, step1030]: loss 0.039982
[epoch14, step1031]: loss 0.042168
[epoch14, step1032]: loss 0.041645
[epoch14, step1033]: loss 0.041192
[epoch14, step1034]: loss 0.040564
[epoch14, step1035]: loss 0.040999
[epoch14, step1036]: loss 0.042125
[epoch14, step1037]: loss 0.041818
[epoch14, step1038]: loss 0.040854
[epoch14, step1039]: loss 0.041046
[epoch14, step1040]: loss 0.042235
[epoch14, step1041]: loss 0.041524
[epoch14, step1042]: loss 0.041524
[epoch14, step1043]: loss 0.041012
[epoch14, step1044]: loss 0.041861
[epoch14, step1045]: loss 0.041825
[epoch14, step1046]: loss 0.042392
[epoch14, step1047]: loss 0.040989
[epoch14, step1048]: loss 0.040588
[epoch14, step1049]: loss 0.043095
[epoch14, step1050]: loss 0.041870
[epoch14, step1051]: loss 0.041547
[epoch14, step1052]: loss 0.040872
[epoch14, step1053]: loss 0.041555
[epoch14, step1054]: loss 0.041792
[epoch14, step1055]: loss 0.041684
[epoch14, step1056]: loss 0.040081
[epoch14, step1057]: loss 0.040478
[epoch14, step1058]: loss 0.042853
[epoch14, step1059]: loss 0.041796
[epoch14, step1060]: loss 0.041244
[epoch14, step1061]: loss 0.039802
[epoch14, step1062]: loss 0.042104
[epoch14, step1063]: loss 0.041753
[epoch14, step1064]: loss 0.041778
[epoch14, step1065]: loss 0.041830
[epoch14, step1066]: loss 0.041362
[epoch14, step1067]: loss 0.043699
[epoch14, step1068]: loss 0.041832
[epoch14, step1069]: loss 0.041997
[epoch14, step1070]: loss 0.041551
[epoch14, step1071]: loss 0.042873
[epoch14, step1072]: loss 0.042785
[epoch14, step1073]: loss 0.042847
[epoch14, step1074]: loss 0.041788
[epoch14, step1075]: loss 0.040355
[epoch14, step1076]: loss 0.042659
[epoch14, step1077]: loss 0.041562
[epoch14, step1078]: loss 0.042081
[epoch14, step1079]: loss 0.041269
[epoch14, step1080]: loss 0.041120
[epoch14, step1081]: loss 0.041527
[epoch14, step1082]: loss 0.041450
[epoch14, step1083]: loss 0.040944
[epoch14, step1084]: loss 0.039961
[epoch14, step1085]: loss 0.041600
[epoch14, step1086]: loss 0.040656
[epoch14, step1087]: loss 0.040398
[epoch14, step1088]: loss 0.040344
[epoch14, step1089]: loss 0.041011
[epoch14, step1090]: loss 0.041810
[epoch14, step1091]: loss 0.042816
[epoch14, step1092]: loss 0.040176
[epoch14, step1093]: loss 0.039714
[epoch14, step1094]: loss 0.042025
[epoch14, step1095]: loss 0.040584
[epoch14, step1096]: loss 0.040239
[epoch14, step1097]: loss 0.040344
[epoch14, step1098]: loss 0.039943
[epoch14, step1099]: loss 0.041266
[epoch14, step1100]: loss 0.042148
[epoch14, step1101]: loss 0.039991
[epoch14, step1102]: loss 0.039311
[epoch14, step1103]: loss 0.041600
[epoch14, step1104]: loss 0.040500
[epoch14, step1105]: loss 0.040975
[epoch14, step1106]: loss 0.039575
[epoch14, step1107]: loss 0.040087
[epoch14, step1108]: loss 0.040038
[epoch14, step1109]: loss 0.040933
[epoch14, step1110]: loss 0.040192
[epoch14, step1111]: loss 0.039222
[epoch14, step1112]: loss 0.041362
[epoch14, step1113]: loss 0.040270
[epoch14, step1114]: loss 0.040476
[epoch14, step1115]: loss 0.039955
[epoch14, step1116]: loss 0.040243
[epoch14, step1117]: loss 0.040595
[epoch14, step1118]: loss 0.041411
[epoch14, step1119]: loss 0.039300
[epoch14, step1120]: loss 0.038996
[epoch14, step1121]: loss 0.041160
[epoch14, step1122]: loss 0.041442
[epoch14, step1123]: loss 0.039535
[epoch14, step1124]: loss 0.040150
[epoch14, step1125]: loss 0.040533
[epoch14, step1126]: loss 0.041164
[epoch14, step1127]: loss 0.041250
[epoch14, step1128]: loss 0.039908
[epoch14, step1129]: loss 0.038819
[epoch14, step1130]: loss 0.042006
[epoch14, step1131]: loss 0.041363
[epoch14, step1132]: loss 0.039925
[epoch14, step1133]: loss 0.038621
[epoch14, step1134]: loss 0.040305
[epoch14, step1135]: loss 0.041270
[epoch14, step1136]: loss 0.041409
[epoch14, step1137]: loss 0.039095
[epoch14, step1138]: loss 0.038968
[epoch14, step1139]: loss 0.041553
[epoch14, step1140]: loss 0.040200
[epoch14, step1141]: loss 0.039606
[epoch14, step1142]: loss 0.040468
[epoch14, step1143]: loss 0.040667
[epoch14, step1144]: loss 0.040076
[epoch14, step1145]: loss 0.041234
[epoch14, step1146]: loss 0.040200
[epoch14, step1147]: loss 0.039814
[epoch14, step1148]: loss 0.042402
[epoch14, step1149]: loss 0.040838
[epoch14, step1150]: loss 0.040369
[epoch14, step1151]: loss 0.039896
[epoch14, step1152]: loss 0.040895
[epoch14, step1153]: loss 0.040064
[epoch14, step1154]: loss 0.040894
[epoch14, step1155]: loss 0.039189
[epoch14, step1156]: loss 0.038486
[epoch14, step1157]: loss 0.041852
[epoch14, step1158]: loss 0.040170
[epoch14, step1159]: loss 0.039340
[epoch14, step1160]: loss 0.039359
[epoch14, step1161]: loss 0.040964
[epoch14, step1162]: loss 0.040588
[epoch14, step1163]: loss 0.040106
[epoch14, step1164]: loss 0.039337
[epoch14, step1165]: loss 0.040420
[epoch14, step1166]: loss 0.041686
[epoch14, step1167]: loss 0.039776
[epoch14, step1168]: loss 0.039949
[epoch14, step1169]: loss 0.038523
[epoch14, step1170]: loss 0.039526
[epoch14, step1171]: loss 0.039450
[epoch14, step1172]: loss 0.041181
[epoch14, step1173]: loss 0.039338
[epoch14, step1174]: loss 0.038882
[epoch14, step1175]: loss 0.040603
[epoch14, step1176]: loss 0.040262
[epoch14, step1177]: loss 0.040002
[epoch14, step1178]: loss 0.038686
[epoch14, step1179]: loss 0.038891
[epoch14, step1180]: loss 0.039493
[epoch14, step1181]: loss 0.041139
[epoch14, step1182]: loss 0.039397
[epoch14, step1183]: loss 0.038572
[epoch14, step1184]: loss 0.040342
[epoch14, step1185]: loss 0.040869
[epoch14, step1186]: loss 0.040638
[epoch14, step1187]: loss 0.038374
[epoch14, step1188]: loss 0.039562
[epoch14, step1189]: loss 0.040320
[epoch14, step1190]: loss 0.039639
[epoch14, step1191]: loss 0.040542
[epoch14, step1192]: loss 0.038045
[epoch14, step1193]: loss 0.040741
[epoch14, step1194]: loss 0.040907
[epoch14, step1195]: loss 0.039470
[epoch14, step1196]: loss 0.038280
[epoch14, step1197]: loss 0.040613
[epoch14, step1198]: loss 0.041040
[epoch14, step1199]: loss 0.040798
[epoch14, step1200]: loss 0.039160
[epoch14, step1201]: loss 0.038457
[epoch14, step1202]: loss 0.041660
[epoch14, step1203]: loss 0.040473
[epoch14, step1204]: loss 0.040141
[epoch14, step1205]: loss 0.038109
[epoch14, step1206]: loss 0.039027
[epoch14, step1207]: loss 0.041031
[epoch14, step1208]: loss 0.040996
[epoch14, step1209]: loss 0.039489
[epoch14, step1210]: loss 0.038563
[epoch14, step1211]: loss 0.041626
[epoch14, step1212]: loss 0.039596
[epoch14, step1213]: loss 0.039833
[epoch14, step1214]: loss 0.039484
[epoch14, step1215]: loss 0.040695
[epoch14, step1216]: loss 0.040313
[epoch14, step1217]: loss 0.040299
[epoch14, step1218]: loss 0.038835
[epoch14, step1219]: loss 0.038963
[epoch14, step1220]: loss 0.041045
[epoch14, step1221]: loss 0.039127
[epoch14, step1222]: loss 0.039245
[epoch14, step1223]: loss 0.038254
[epoch14, step1224]: loss 0.039220
[epoch14, step1225]: loss 0.039749
[epoch14, step1226]: loss 0.040465
[epoch14, step1227]: loss 0.039162
[epoch14, step1228]: loss 0.038795
[epoch14, step1229]: loss 0.040526
[epoch14, step1230]: loss 0.039709
[epoch14, step1231]: loss 0.039666
[epoch14, step1232]: loss 0.039096
[epoch14, step1233]: loss 0.039976
[epoch14, step1234]: loss 0.040304
[epoch14, step1235]: loss 0.040298
[epoch14, step1236]: loss 0.039298
[epoch14, step1237]: loss 0.038021
[epoch14, step1238]: loss 0.039909
[epoch14, step1239]: loss 0.040373
[epoch14, step1240]: loss 0.040014
[epoch14, step1241]: loss 0.038550
[epoch14, step1242]: loss 0.039775
[epoch14, step1243]: loss 0.041078
[epoch14, step1244]: loss 0.040222
[epoch14, step1245]: loss 0.038772
[epoch14, step1246]: loss 0.038502
[epoch14, step1247]: loss 0.040033
[epoch14, step1248]: loss 0.039865
[epoch14, step1249]: loss 0.040874
[epoch14, step1250]: loss 0.038282
[epoch14, step1251]: loss 0.038910
[epoch14, step1252]: loss 0.041014
[epoch14, step1253]: loss 0.040402
[epoch14, step1254]: loss 0.038584
[epoch14, step1255]: loss 0.038934
[epoch14, step1256]: loss 0.041327
[epoch14, step1257]: loss 0.039415
[epoch14, step1258]: loss 0.038677
[epoch14, step1259]: loss 0.038651
[epoch14, step1260]: loss 0.039848
[epoch14, step1261]: loss 0.039471
[epoch14, step1262]: loss 0.039147
[epoch14, step1263]: loss 0.042259
[epoch14, step1264]: loss 0.042129
[epoch14, step1265]: loss 0.042096
[epoch14, step1266]: loss 0.042161
[epoch14, step1267]: loss 0.042216
[epoch14, step1268]: loss 0.041624
[epoch14, step1269]: loss 0.042192
[epoch14, step1270]: loss 0.041731
[epoch14, step1271]: loss 0.042523
[epoch14, step1272]: loss 0.041149
[epoch14, step1273]: loss 0.040364
[epoch14, step1274]: loss 0.042642
[epoch14, step1275]: loss 0.041496
[epoch14, step1276]: loss 0.041515
[epoch14, step1277]: loss 0.040461
[epoch14, step1278]: loss 0.041276
[epoch14, step1279]: loss 0.041634
[epoch14, step1280]: loss 0.041991
[epoch14, step1281]: loss 0.040838
[epoch14, step1282]: loss 0.040507
[epoch14, step1283]: loss 0.041709
[epoch14, step1284]: loss 0.041308
[epoch14, step1285]: loss 0.041268
[epoch14, step1286]: loss 0.040402
[epoch14, step1287]: loss 0.041771
[epoch14, step1288]: loss 0.041889
[epoch14, step1289]: loss 0.042509
[epoch14, step1290]: loss 0.040884
[epoch14, step1291]: loss 0.040418
[epoch14, step1292]: loss 0.042372
[epoch14, step1293]: loss 0.040546
[epoch14, step1294]: loss 0.040887
[epoch14, step1295]: loss 0.040591
[epoch14, step1296]: loss 0.040956
[epoch14, step1297]: loss 0.041277
[epoch14, step1298]: loss 0.041974
[epoch14, step1299]: loss 0.041291
[epoch14, step1300]: loss 0.041295
[epoch14, step1301]: loss 0.041491
[epoch14, step1302]: loss 0.041545
[epoch14, step1303]: loss 0.040800
[epoch14, step1304]: loss 0.039982
[epoch14, step1305]: loss 0.040797
[epoch14, step1306]: loss 0.041390
[epoch14, step1307]: loss 0.042058
[epoch14, step1308]: loss 0.040712
[epoch14, step1309]: loss 0.040189
[epoch14, step1310]: loss 0.042741
[epoch14, step1311]: loss 0.040528
[epoch14, step1312]: loss 0.041192
[epoch14, step1313]: loss 0.040207
[epoch14, step1314]: loss 0.041413
[epoch14, step1315]: loss 0.041427
[epoch14, step1316]: loss 0.042049
[epoch14, step1317]: loss 0.039827
[epoch14, step1318]: loss 0.039876
[epoch14, step1319]: loss 0.041589
[epoch14, step1320]: loss 0.040112
[epoch14, step1321]: loss 0.040803
[epoch14, step1322]: loss 0.040758
[epoch14, step1323]: loss 0.041778
[epoch14, step1324]: loss 0.041325
[epoch14, step1325]: loss 0.040764
[epoch14, step1326]: loss 0.039018
[epoch14, step1327]: loss 0.039760
[epoch14, step1328]: loss 0.042604
[epoch14, step1329]: loss 0.040016
[epoch14, step1330]: loss 0.039513
[epoch14, step1331]: loss 0.039434
[epoch14, step1332]: loss 0.039451
[epoch14, step1333]: loss 0.040178
[epoch14, step1334]: loss 0.040803
[epoch14, step1335]: loss 0.039462
[epoch14, step1336]: loss 0.038862
[epoch14, step1337]: loss 0.041785
[epoch14, step1338]: loss 0.040114
[epoch14, step1339]: loss 0.040623
[epoch14, step1340]: loss 0.039816
[epoch14, step1341]: loss 0.040611
[epoch14, step1342]: loss 0.041088
[epoch14, step1343]: loss 0.040964
[epoch14, step1344]: loss 0.039713
[epoch14, step1345]: loss 0.039077
[epoch14, step1346]: loss 0.041554
[epoch14, step1347]: loss 0.040244
[epoch14, step1348]: loss 0.040594
[epoch14, step1349]: loss 0.039719
[epoch14, step1350]: loss 0.040076
[epoch14, step1351]: loss 0.040352
[epoch14, step1352]: loss 0.040909
[epoch14, step1353]: loss 0.039835
[epoch14, step1354]: loss 0.038742
[epoch14, step1355]: loss 0.040710
[epoch14, step1356]: loss 0.039169
[epoch14, step1357]: loss 0.039654
[epoch14, step1358]: loss 0.038518
[epoch14, step1359]: loss 0.039284
[epoch14, step1360]: loss 0.039623
[epoch14, step1361]: loss 0.041031
[epoch14, step1362]: loss 0.038587
[epoch14, step1363]: loss 0.037966
[epoch14, step1364]: loss 0.040066
[epoch14, step1365]: loss 0.039113
[epoch14, step1366]: loss 0.038990
[epoch14, step1367]: loss 0.038101
[epoch14, step1368]: loss 0.039511
[epoch14, step1369]: loss 0.039886
[epoch14, step1370]: loss 0.040186
[epoch14, step1371]: loss 0.039146
[epoch14, step1372]: loss 0.039192
[epoch14, step1373]: loss 0.040231
[epoch14, step1374]: loss 0.039766
[epoch14, step1375]: loss 0.040777
[epoch14, step1376]: loss 0.038157
[epoch14, step1377]: loss 0.038974
[epoch14, step1378]: loss 0.040248
[epoch14, step1379]: loss 0.039907
[epoch14, step1380]: loss 0.039323
[epoch14, step1381]: loss 0.037902
[epoch14, step1382]: loss 0.040511
[epoch14, step1383]: loss 0.038688
[epoch14, step1384]: loss 0.038846
[epoch14, step1385]: loss 0.037545
[epoch14, step1386]: loss 0.040175
[epoch14, step1387]: loss 0.040718
[epoch14, step1388]: loss 0.040121
[epoch14, step1389]: loss 0.038602
[epoch14, step1390]: loss 0.038597
[epoch14, step1391]: loss 0.040542
[epoch14, step1392]: loss 0.039209
[epoch14, step1393]: loss 0.039189
[epoch14, step1394]: loss 0.039516
[epoch14, step1395]: loss 0.039655
[epoch14, step1396]: loss 0.039426
[epoch14, step1397]: loss 0.039964
[epoch14, step1398]: loss 0.038750
[epoch14, step1399]: loss 0.038533
[epoch14, step1400]: loss 0.041275
[epoch14, step1401]: loss 0.039847
[epoch14, step1402]: loss 0.038596
[epoch14, step1403]: loss 0.037465
[epoch14, step1404]: loss 0.039625
[epoch14, step1405]: loss 0.040652
[epoch14, step1406]: loss 0.040329
[epoch14, step1407]: loss 0.039518
[epoch14, step1408]: loss 0.038851
[epoch14, step1409]: loss 0.041455
[epoch14, step1410]: loss 0.040518
[epoch14, step1411]: loss 0.040054
[epoch14, step1412]: loss 0.038217
[epoch14, step1413]: loss 0.038416
[epoch14, step1414]: loss 0.040160
[epoch14, step1415]: loss 0.041030
[epoch14, step1416]: loss 0.039313
[epoch14, step1417]: loss 0.037906
[epoch14, step1418]: loss 0.040234
[epoch14, step1419]: loss 0.039954
[epoch14, step1420]: loss 0.039889
[epoch14, step1421]: loss 0.038875
[epoch14, step1422]: loss 0.039143
[epoch14, step1423]: loss 0.039810
[epoch14, step1424]: loss 0.040799
[epoch14, step1425]: loss 0.038175
[epoch14, step1426]: loss 0.039501
[epoch14, step1427]: loss 0.041032
[epoch14, step1428]: loss 0.039365
[epoch14, step1429]: loss 0.040153
[epoch14, step1430]: loss 0.039100
[epoch14, step1431]: loss 0.040135
[epoch14, step1432]: loss 0.040583
[epoch14, step1433]: loss 0.041725
[epoch14, step1434]: loss 0.038964
[epoch14, step1435]: loss 0.038484
[epoch14, step1436]: loss 0.041046
[epoch14, step1437]: loss 0.038745
[epoch14, step1438]: loss 0.039329
[epoch14, step1439]: loss 0.038516
[epoch14, step1440]: loss 0.038833
[epoch14, step1441]: loss 0.040198
[epoch14, step1442]: loss 0.040366
[epoch14, step1443]: loss 0.038890
[epoch14, step1444]: loss 0.038783
[epoch14, step1445]: loss 0.042074
[epoch14, step1446]: loss 0.039661
[epoch14, step1447]: loss 0.039078
[epoch14, step1448]: loss 0.038405
[epoch14, step1449]: loss 0.038947
[epoch14, step1450]: loss 0.039615
[epoch14, step1451]: loss 0.041432
[epoch14, step1452]: loss 0.038841
[epoch14, step1453]: loss 0.038799
[epoch14, step1454]: loss 0.040561
[epoch14, step1455]: loss 0.039366
[epoch14, step1456]: loss 0.040164
[epoch14, step1457]: loss 0.038416
[epoch14, step1458]: loss 0.039189
[epoch14, step1459]: loss 0.039217
[epoch14, step1460]: loss 0.040273
[epoch14, step1461]: loss 0.039472
[epoch14, step1462]: loss 0.040097
[epoch14, step1463]: loss 0.040231
[epoch14, step1464]: loss 0.038810
[epoch14, step1465]: loss 0.038998
[epoch14, step1466]: loss 0.037513
[epoch14, step1467]: loss 0.039680
[epoch14, step1468]: loss 0.038593
[epoch14, step1469]: loss 0.039892
[epoch14, step1470]: loss 0.038186
[epoch14, step1471]: loss 0.037607
[epoch14, step1472]: loss 0.039409
[epoch14, step1473]: loss 0.038912
[epoch14, step1474]: loss 0.039812
[epoch14, step1475]: loss 0.037445
[epoch14, step1476]: loss 0.039579
[epoch14, step1477]: loss 0.039079
[epoch14, step1478]: loss 0.039809
[epoch14, step1479]: loss 0.037970
[epoch14, step1480]: loss 0.037481
[epoch14, step1481]: loss 0.039303
[epoch14, step1482]: loss 0.039638
[epoch14, step1483]: loss 0.039232
[epoch14, step1484]: loss 0.038325
[epoch14, step1485]: loss 0.039284
[epoch14, step1486]: loss 0.039565
[epoch14, step1487]: loss 0.039826
[epoch14, step1488]: loss 0.038767
[epoch14, step1489]: loss 0.038194
[epoch14, step1490]: loss 0.040521
[epoch14, step1491]: loss 0.038894
[epoch14, step1492]: loss 0.038652
[epoch14, step1493]: loss 0.037804
[epoch14, step1494]: loss 0.038429
[epoch14, step1495]: loss 0.038993
[epoch14, step1496]: loss 0.040013
[epoch14, step1497]: loss 0.038729
[epoch14, step1498]: loss 0.037313
[epoch14, step1499]: loss 0.041181
[epoch14, step1500]: loss 0.038995
[epoch14, step1501]: loss 0.038609
[epoch14, step1502]: loss 0.038159
[epoch14, step1503]: loss 0.039391
[epoch14, step1504]: loss 0.038629
[epoch14, step1505]: loss 0.041465
[epoch14, step1506]: loss 0.037361
[epoch14, step1507]: loss 0.038871
[epoch14, step1508]: loss 0.041619
[epoch14, step1509]: loss 0.039412
[epoch14, step1510]: loss 0.039348
[epoch14, step1511]: loss 0.037965
[epoch14, step1512]: loss 0.038391
[epoch14, step1513]: loss 0.039476
[epoch14, step1514]: loss 0.040157
[epoch14, step1515]: loss 0.038913
[epoch14, step1516]: loss 0.037314

[epoch14]: avg loss 0.037296

[epoch15, step1]: loss 0.044493
[epoch15, step2]: loss 0.045108
[epoch15, step3]: loss 0.043217
[epoch15, step4]: loss 0.039926
[epoch15, step5]: loss 0.037319
[epoch15, step6]: loss 0.039243
[epoch15, step7]: loss 0.034629
[epoch15, step8]: loss 0.038671
[epoch15, step9]: loss 0.035522
[epoch15, step10]: loss 0.037053
[epoch15, step11]: loss 0.039568
[epoch15, step12]: loss 0.038115
[epoch15, step13]: loss 0.035283
[epoch15, step14]: loss 0.035222
[epoch15, step15]: loss 0.037200
[epoch15, step16]: loss 0.035666
[epoch15, step17]: loss 0.037789
[epoch15, step18]: loss 0.035049
[epoch15, step19]: loss 0.034876
[epoch15, step20]: loss 0.038323
[epoch15, step21]: loss 0.036590
[epoch15, step22]: loss 0.034417
[epoch15, step23]: loss 0.034015
[epoch15, step24]: loss 0.036645
[epoch15, step25]: loss 0.034249
[epoch15, step26]: loss 0.036468
[epoch15, step27]: loss 0.033640
[epoch15, step28]: loss 0.034823
[epoch15, step29]: loss 0.037245
[epoch15, step30]: loss 0.037227
[epoch15, step31]: loss 0.033873
[epoch15, step32]: loss 0.035124
[epoch15, step33]: loss 0.037094
[epoch15, step34]: loss 0.034901
[epoch15, step35]: loss 0.037756
[epoch15, step36]: loss 0.033824
[epoch15, step37]: loss 0.034564
[epoch15, step38]: loss 0.037201
[epoch15, step39]: loss 0.036262
[epoch15, step40]: loss 0.034290
[epoch15, step41]: loss 0.033716
[epoch15, step42]: loss 0.036719
[epoch15, step43]: loss 0.034399
[epoch15, step44]: loss 0.037519
[epoch15, step45]: loss 0.034125
[epoch15, step46]: loss 0.034538
[epoch15, step47]: loss 0.036794
[epoch15, step48]: loss 0.036669
[epoch15, step49]: loss 0.032590
[epoch15, step50]: loss 0.034346
[epoch15, step51]: loss 0.036651
[epoch15, step52]: loss 0.034628
[epoch15, step53]: loss 0.037140
[epoch15, step54]: loss 0.033515
[epoch15, step55]: loss 0.035159
[epoch15, step56]: loss 0.037769
[epoch15, step57]: loss 0.036758
[epoch15, step58]: loss 0.034093
[epoch15, step59]: loss 0.033165
[epoch15, step60]: loss 0.037053
[epoch15, step61]: loss 0.033793
[epoch15, step62]: loss 0.036079
[epoch15, step63]: loss 0.033341
[epoch15, step64]: loss 0.034004
[epoch15, step65]: loss 0.036891
[epoch15, step66]: loss 0.036571
[epoch15, step67]: loss 0.034185
[epoch15, step68]: loss 0.034095
[epoch15, step69]: loss 0.036247
[epoch15, step70]: loss 0.034293
[epoch15, step71]: loss 0.036738
[epoch15, step72]: loss 0.034007
[epoch15, step73]: loss 0.034596
[epoch15, step74]: loss 0.036197
[epoch15, step75]: loss 0.036829
[epoch15, step76]: loss 0.034652
[epoch15, step77]: loss 0.034581
[epoch15, step78]: loss 0.036876
[epoch15, step79]: loss 0.033960
[epoch15, step80]: loss 0.037594
[epoch15, step81]: loss 0.033924
[epoch15, step82]: loss 0.034000
[epoch15, step83]: loss 0.036400
[epoch15, step84]: loss 0.036640
[epoch15, step85]: loss 0.034614
[epoch15, step86]: loss 0.034700
[epoch15, step87]: loss 0.037437
[epoch15, step88]: loss 0.033749
[epoch15, step89]: loss 0.036542
[epoch15, step90]: loss 0.034603
[epoch15, step91]: loss 0.034025
[epoch15, step92]: loss 0.036886
[epoch15, step93]: loss 0.036593
[epoch15, step94]: loss 0.033509
[epoch15, step95]: loss 0.034554
[epoch15, step96]: loss 0.036512
[epoch15, step97]: loss 0.034954
[epoch15, step98]: loss 0.036944
[epoch15, step99]: loss 0.033883
[epoch15, step100]: loss 0.033326
[epoch15, step101]: loss 0.037444
[epoch15, step102]: loss 0.036355
[epoch15, step103]: loss 0.034206
[epoch15, step104]: loss 0.034086
[epoch15, step105]: loss 0.036848
[epoch15, step106]: loss 0.034548
[epoch15, step107]: loss 0.036779
[epoch15, step108]: loss 0.034258
[epoch15, step109]: loss 0.033996
[epoch15, step110]: loss 0.037265
[epoch15, step111]: loss 0.036290
[epoch15, step112]: loss 0.034094
[epoch15, step113]: loss 0.035237
[epoch15, step114]: loss 0.036597
[epoch15, step115]: loss 0.034394
[epoch15, step116]: loss 0.037785
[epoch15, step117]: loss 0.033483
[epoch15, step118]: loss 0.035318
[epoch15, step119]: loss 0.037071
[epoch15, step120]: loss 0.036923
[epoch15, step121]: loss 0.034017
[epoch15, step122]: loss 0.034057
[epoch15, step123]: loss 0.036970
[epoch15, step124]: loss 0.034715
[epoch15, step125]: loss 0.037102
[epoch15, step126]: loss 0.033953
[epoch15, step127]: loss 0.033968
[epoch15, step128]: loss 0.036784
[epoch15, step129]: loss 0.036318
[epoch15, step130]: loss 0.034208
[epoch15, step131]: loss 0.033940
[epoch15, step132]: loss 0.036575
[epoch15, step133]: loss 0.034549
[epoch15, step134]: loss 0.036166
[epoch15, step135]: loss 0.034284
[epoch15, step136]: loss 0.035414
[epoch15, step137]: loss 0.036557
[epoch15, step138]: loss 0.036633
[epoch15, step139]: loss 0.033973
[epoch15, step140]: loss 0.034465
[epoch15, step141]: loss 0.036994
[epoch15, step142]: loss 0.034520
[epoch15, step143]: loss 0.036230
[epoch15, step144]: loss 0.034095
[epoch15, step145]: loss 0.034478
[epoch15, step146]: loss 0.037126
[epoch15, step147]: loss 0.037428
[epoch15, step148]: loss 0.033797
[epoch15, step149]: loss 0.033692
[epoch15, step150]: loss 0.036080
[epoch15, step151]: loss 0.034362
[epoch15, step152]: loss 0.036238
[epoch15, step153]: loss 0.033782
[epoch15, step154]: loss 0.034060
[epoch15, step155]: loss 0.036492
[epoch15, step156]: loss 0.035893
[epoch15, step157]: loss 0.034101
[epoch15, step158]: loss 0.034497
[epoch15, step159]: loss 0.036434
[epoch15, step160]: loss 0.034630
[epoch15, step161]: loss 0.036869
[epoch15, step162]: loss 0.034247
[epoch15, step163]: loss 0.034472
[epoch15, step164]: loss 0.036795
[epoch15, step165]: loss 0.036307
[epoch15, step166]: loss 0.034751
[epoch15, step167]: loss 0.033806
[epoch15, step168]: loss 0.037099
[epoch15, step169]: loss 0.034206
[epoch15, step170]: loss 0.037001
[epoch15, step171]: loss 0.034367
[epoch15, step172]: loss 0.034570
[epoch15, step173]: loss 0.037070
[epoch15, step174]: loss 0.036551
[epoch15, step175]: loss 0.034678
[epoch15, step176]: loss 0.034287
[epoch15, step177]: loss 0.036870
[epoch15, step178]: loss 0.034565
[epoch15, step179]: loss 0.035925
[epoch15, step180]: loss 0.034021
[epoch15, step181]: loss 0.034387
[epoch15, step182]: loss 0.037096
[epoch15, step183]: loss 0.036898
[epoch15, step184]: loss 0.035382
[epoch15, step185]: loss 0.034224
[epoch15, step186]: loss 0.036567
[epoch15, step187]: loss 0.034425
[epoch15, step188]: loss 0.036375
[epoch15, step189]: loss 0.034172
[epoch15, step190]: loss 0.033690
[epoch15, step191]: loss 0.036725
[epoch15, step192]: loss 0.036994
[epoch15, step193]: loss 0.032434
[epoch15, step194]: loss 0.033122
[epoch15, step195]: loss 0.036618
[epoch15, step196]: loss 0.034545
[epoch15, step197]: loss 0.036639
[epoch15, step198]: loss 0.033035
[epoch15, step199]: loss 0.034305
[epoch15, step200]: loss 0.037150
[epoch15, step201]: loss 0.036728
[epoch15, step202]: loss 0.033584
[epoch15, step203]: loss 0.034218
[epoch15, step204]: loss 0.036975
[epoch15, step205]: loss 0.034048
[epoch15, step206]: loss 0.036544
[epoch15, step207]: loss 0.033953
[epoch15, step208]: loss 0.034476
[epoch15, step209]: loss 0.037017
[epoch15, step210]: loss 0.037293
[epoch15, step211]: loss 0.034437
[epoch15, step212]: loss 0.034431
[epoch15, step213]: loss 0.036387
[epoch15, step214]: loss 0.033941
[epoch15, step215]: loss 0.036707
[epoch15, step216]: loss 0.034129
[epoch15, step217]: loss 0.033626
[epoch15, step218]: loss 0.037145
[epoch15, step219]: loss 0.036143
[epoch15, step220]: loss 0.034381
[epoch15, step221]: loss 0.034338
[epoch15, step222]: loss 0.036821
[epoch15, step223]: loss 0.034499
[epoch15, step224]: loss 0.036144
[epoch15, step225]: loss 0.034171
[epoch15, step226]: loss 0.034142
[epoch15, step227]: loss 0.035694
[epoch15, step228]: loss 0.037170
[epoch15, step229]: loss 0.033500
[epoch15, step230]: loss 0.034258
[epoch15, step231]: loss 0.037252
[epoch15, step232]: loss 0.034142
[epoch15, step233]: loss 0.036123
[epoch15, step234]: loss 0.033265
[epoch15, step235]: loss 0.034620
[epoch15, step236]: loss 0.036417
[epoch15, step237]: loss 0.036184
[epoch15, step238]: loss 0.034157
[epoch15, step239]: loss 0.033505
[epoch15, step240]: loss 0.035799
[epoch15, step241]: loss 0.034659
[epoch15, step242]: loss 0.036565
[epoch15, step243]: loss 0.034664
[epoch15, step244]: loss 0.034523
[epoch15, step245]: loss 0.036426
[epoch15, step246]: loss 0.036636
[epoch15, step247]: loss 0.034471
[epoch15, step248]: loss 0.033426
[epoch15, step249]: loss 0.035882
[epoch15, step250]: loss 0.034476
[epoch15, step251]: loss 0.036712
[epoch15, step252]: loss 0.034701
[epoch15, step253]: loss 0.033638
[epoch15, step254]: loss 0.036225
[epoch15, step255]: loss 0.036315
[epoch15, step256]: loss 0.034099
[epoch15, step257]: loss 0.034101
[epoch15, step258]: loss 0.036941
[epoch15, step259]: loss 0.034870
[epoch15, step260]: loss 0.036454
[epoch15, step261]: loss 0.034383
[epoch15, step262]: loss 0.034889
[epoch15, step263]: loss 0.036518
[epoch15, step264]: loss 0.036230
[epoch15, step265]: loss 0.034215
[epoch15, step266]: loss 0.033825
[epoch15, step267]: loss 0.036077
[epoch15, step268]: loss 0.034456
[epoch15, step269]: loss 0.036443
[epoch15, step270]: loss 0.033680
[epoch15, step271]: loss 0.034008
[epoch15, step272]: loss 0.036588
[epoch15, step273]: loss 0.035991
[epoch15, step274]: loss 0.034793
[epoch15, step275]: loss 0.033536
[epoch15, step276]: loss 0.036546
[epoch15, step277]: loss 0.035194
[epoch15, step278]: loss 0.036659
[epoch15, step279]: loss 0.033774
[epoch15, step280]: loss 0.034880
[epoch15, step281]: loss 0.036781
[epoch15, step282]: loss 0.036837
[epoch15, step283]: loss 0.033876
[epoch15, step284]: loss 0.033468
[epoch15, step285]: loss 0.037215
[epoch15, step286]: loss 0.033619
[epoch15, step287]: loss 0.036559
[epoch15, step288]: loss 0.033259
[epoch15, step289]: loss 0.034834
[epoch15, step290]: loss 0.036772
[epoch15, step291]: loss 0.036399
[epoch15, step292]: loss 0.033267
[epoch15, step293]: loss 0.033744
[epoch15, step294]: loss 0.036099
[epoch15, step295]: loss 0.033781
[epoch15, step296]: loss 0.037088
[epoch15, step297]: loss 0.033865
[epoch15, step298]: loss 0.034150
[epoch15, step299]: loss 0.036152
[epoch15, step300]: loss 0.036823
[epoch15, step301]: loss 0.034221
[epoch15, step302]: loss 0.034596
[epoch15, step303]: loss 0.036880
[epoch15, step304]: loss 0.034029
[epoch15, step305]: loss 0.036028
[epoch15, step306]: loss 0.034228
[epoch15, step307]: loss 0.033707
[epoch15, step308]: loss 0.037432
[epoch15, step309]: loss 0.036757
[epoch15, step310]: loss 0.034023
[epoch15, step311]: loss 0.034501
[epoch15, step312]: loss 0.036282
[epoch15, step313]: loss 0.034254
[epoch15, step314]: loss 0.036289
[epoch15, step315]: loss 0.034750
[epoch15, step316]: loss 0.033861
[epoch15, step317]: loss 0.037300
[epoch15, step318]: loss 0.036726
[epoch15, step319]: loss 0.033433
[epoch15, step320]: loss 0.033292
[epoch15, step321]: loss 0.036192
[epoch15, step322]: loss 0.034183
[epoch15, step323]: loss 0.036098
[epoch15, step324]: loss 0.034587
[epoch15, step325]: loss 0.034215
[epoch15, step326]: loss 0.036265
[epoch15, step327]: loss 0.035563
[epoch15, step328]: loss 0.034307
[epoch15, step329]: loss 0.033707
[epoch15, step330]: loss 0.035497
[epoch15, step331]: loss 0.034393
[epoch15, step332]: loss 0.035750
[epoch15, step333]: loss 0.033880
[epoch15, step334]: loss 0.034049
[epoch15, step335]: loss 0.037290
[epoch15, step336]: loss 0.038160
[epoch15, step337]: loss 0.034883
[epoch15, step338]: loss 0.033440
[epoch15, step339]: loss 0.036932
[epoch15, step340]: loss 0.034850
[epoch15, step341]: loss 0.036086
[epoch15, step342]: loss 0.033629
[epoch15, step343]: loss 0.034054
[epoch15, step344]: loss 0.035950
[epoch15, step345]: loss 0.035663
[epoch15, step346]: loss 0.033574
[epoch15, step347]: loss 0.033832
[epoch15, step348]: loss 0.036424
[epoch15, step349]: loss 0.034845
[epoch15, step350]: loss 0.035745
[epoch15, step351]: loss 0.032964
[epoch15, step352]: loss 0.033468
[epoch15, step353]: loss 0.036521
[epoch15, step354]: loss 0.035240
[epoch15, step355]: loss 0.032940
[epoch15, step356]: loss 0.034332
[epoch15, step357]: loss 0.036330
[epoch15, step358]: loss 0.032656
[epoch15, step359]: loss 0.037954
[epoch15, step360]: loss 0.033133
[epoch15, step361]: loss 0.034053
[epoch15, step362]: loss 0.037153
[epoch15, step363]: loss 0.035721
[epoch15, step364]: loss 0.033783
[epoch15, step365]: loss 0.033576
[epoch15, step366]: loss 0.036489
[epoch15, step367]: loss 0.034422
[epoch15, step368]: loss 0.035753
[epoch15, step369]: loss 0.033650
[epoch15, step370]: loss 0.034896
[epoch15, step371]: loss 0.037157
[epoch15, step372]: loss 0.036032
[epoch15, step373]: loss 0.033618
[epoch15, step374]: loss 0.033037
[epoch15, step375]: loss 0.037204
[epoch15, step376]: loss 0.034193
[epoch15, step377]: loss 0.036575
[epoch15, step378]: loss 0.033947
[epoch15, step379]: loss 0.034388
[epoch15, step380]: loss 0.036997
[epoch15, step381]: loss 0.035599
[epoch15, step382]: loss 0.033910
[epoch15, step383]: loss 0.032580
[epoch15, step384]: loss 0.035685
[epoch15, step385]: loss 0.033897
[epoch15, step386]: loss 0.036242
[epoch15, step387]: loss 0.034081
[epoch15, step388]: loss 0.034947
[epoch15, step389]: loss 0.036012
[epoch15, step390]: loss 0.037516
[epoch15, step391]: loss 0.033337
[epoch15, step392]: loss 0.034620
[epoch15, step393]: loss 0.036491
[epoch15, step394]: loss 0.034116
[epoch15, step395]: loss 0.036274
[epoch15, step396]: loss 0.033417
[epoch15, step397]: loss 0.033698
[epoch15, step398]: loss 0.036437
[epoch15, step399]: loss 0.036020
[epoch15, step400]: loss 0.033807
[epoch15, step401]: loss 0.033599
[epoch15, step402]: loss 0.036277
[epoch15, step403]: loss 0.034365
[epoch15, step404]: loss 0.037057
[epoch15, step405]: loss 0.034239
[epoch15, step406]: loss 0.034629
[epoch15, step407]: loss 0.036626
[epoch15, step408]: loss 0.036538
[epoch15, step409]: loss 0.035346
[epoch15, step410]: loss 0.034017
[epoch15, step411]: loss 0.036072
[epoch15, step412]: loss 0.033714
[epoch15, step413]: loss 0.036194
[epoch15, step414]: loss 0.033539
[epoch15, step415]: loss 0.034089
[epoch15, step416]: loss 0.035877
[epoch15, step417]: loss 0.036330
[epoch15, step418]: loss 0.034144
[epoch15, step419]: loss 0.033418
[epoch15, step420]: loss 0.036366
[epoch15, step421]: loss 0.034234
[epoch15, step422]: loss 0.036694
[epoch15, step423]: loss 0.033820
[epoch15, step424]: loss 0.034165
[epoch15, step425]: loss 0.037883
[epoch15, step426]: loss 0.036787
[epoch15, step427]: loss 0.034346
[epoch15, step428]: loss 0.034019
[epoch15, step429]: loss 0.036765
[epoch15, step430]: loss 0.034102
[epoch15, step431]: loss 0.036353
[epoch15, step432]: loss 0.033369
[epoch15, step433]: loss 0.034498
[epoch15, step434]: loss 0.036520
[epoch15, step435]: loss 0.036977
[epoch15, step436]: loss 0.033696
[epoch15, step437]: loss 0.033751
[epoch15, step438]: loss 0.036659
[epoch15, step439]: loss 0.034717
[epoch15, step440]: loss 0.036483
[epoch15, step441]: loss 0.033729
[epoch15, step442]: loss 0.033928
[epoch15, step443]: loss 0.037476
[epoch15, step444]: loss 0.036157
[epoch15, step445]: loss 0.034321
[epoch15, step446]: loss 0.034258
[epoch15, step447]: loss 0.037236
[epoch15, step448]: loss 0.034199
[epoch15, step449]: loss 0.036303
[epoch15, step450]: loss 0.033337
[epoch15, step451]: loss 0.033851
[epoch15, step452]: loss 0.035704
[epoch15, step453]: loss 0.035952
[epoch15, step454]: loss 0.033517
[epoch15, step455]: loss 0.033790
[epoch15, step456]: loss 0.035563
[epoch15, step457]: loss 0.034421
[epoch15, step458]: loss 0.035836
[epoch15, step459]: loss 0.034130
[epoch15, step460]: loss 0.034198
[epoch15, step461]: loss 0.037362
[epoch15, step462]: loss 0.035311
[epoch15, step463]: loss 0.034076
[epoch15, step464]: loss 0.033359
[epoch15, step465]: loss 0.037549
[epoch15, step466]: loss 0.034123
[epoch15, step467]: loss 0.035885
[epoch15, step468]: loss 0.033620
[epoch15, step469]: loss 0.033746
[epoch15, step470]: loss 0.036870
[epoch15, step471]: loss 0.035740
[epoch15, step472]: loss 0.034408
[epoch15, step473]: loss 0.034307
[epoch15, step474]: loss 0.035693
[epoch15, step475]: loss 0.034423
[epoch15, step476]: loss 0.037149
[epoch15, step477]: loss 0.033651
[epoch15, step478]: loss 0.033255
[epoch15, step479]: loss 0.036166
[epoch15, step480]: loss 0.035291
[epoch15, step481]: loss 0.033366
[epoch15, step482]: loss 0.033243
[epoch15, step483]: loss 0.036381
[epoch15, step484]: loss 0.034692
[epoch15, step485]: loss 0.036817
[epoch15, step486]: loss 0.033636
[epoch15, step487]: loss 0.033302
[epoch15, step488]: loss 0.036914
[epoch15, step489]: loss 0.035195
[epoch15, step490]: loss 0.034453
[epoch15, step491]: loss 0.033942
[epoch15, step492]: loss 0.036104
[epoch15, step493]: loss 0.034115
[epoch15, step494]: loss 0.035453
[epoch15, step495]: loss 0.035059
[epoch15, step496]: loss 0.034282
[epoch15, step497]: loss 0.036615
[epoch15, step498]: loss 0.036259
[epoch15, step499]: loss 0.033854
[epoch15, step500]: loss 0.034054
[epoch15, step501]: loss 0.036182
[epoch15, step502]: loss 0.034307
[epoch15, step503]: loss 0.037038
[epoch15, step504]: loss 0.033085
[epoch15, step505]: loss 0.032772
[epoch15, step506]: loss 0.036942
[epoch15, step507]: loss 0.036689
[epoch15, step508]: loss 0.034130
[epoch15, step509]: loss 0.033625
[epoch15, step510]: loss 0.036309
[epoch15, step511]: loss 0.034727
[epoch15, step512]: loss 0.036851
[epoch15, step513]: loss 0.033680
[epoch15, step514]: loss 0.033839
[epoch15, step515]: loss 0.036386
[epoch15, step516]: loss 0.036232
[epoch15, step517]: loss 0.033779
[epoch15, step518]: loss 0.033893
[epoch15, step519]: loss 0.036230
[epoch15, step520]: loss 0.033537
[epoch15, step521]: loss 0.036236
[epoch15, step522]: loss 0.033473
[epoch15, step523]: loss 0.033522
[epoch15, step524]: loss 0.036648
[epoch15, step525]: loss 0.037947
[epoch15, step526]: loss 0.034407
[epoch15, step527]: loss 0.033171
[epoch15, step528]: loss 0.036612
[epoch15, step529]: loss 0.034037
[epoch15, step530]: loss 0.037405
[epoch15, step531]: loss 0.033643
[epoch15, step532]: loss 0.033711
[epoch15, step533]: loss 0.037129
[epoch15, step534]: loss 0.035669
[epoch15, step535]: loss 0.034198
[epoch15, step536]: loss 0.033774
[epoch15, step537]: loss 0.036011
[epoch15, step538]: loss 0.034320
[epoch15, step539]: loss 0.035862
[epoch15, step540]: loss 0.032890
[epoch15, step541]: loss 0.033254
[epoch15, step542]: loss 0.036334
[epoch15, step543]: loss 0.035778
[epoch15, step544]: loss 0.034011
[epoch15, step545]: loss 0.032985
[epoch15, step546]: loss 0.036947
[epoch15, step547]: loss 0.034547
[epoch15, step548]: loss 0.036978
[epoch15, step549]: loss 0.033849
[epoch15, step550]: loss 0.034345
[epoch15, step551]: loss 0.035935
[epoch15, step552]: loss 0.036177
[epoch15, step553]: loss 0.034795
[epoch15, step554]: loss 0.033371
[epoch15, step555]: loss 0.035489
[epoch15, step556]: loss 0.034541
[epoch15, step557]: loss 0.036167
[epoch15, step558]: loss 0.034546
[epoch15, step559]: loss 0.034010
[epoch15, step560]: loss 0.037007
[epoch15, step561]: loss 0.036134
[epoch15, step562]: loss 0.034403
[epoch15, step563]: loss 0.037228
[epoch15, step564]: loss 0.042589
[epoch15, step565]: loss 0.041969
[epoch15, step566]: loss 0.048952
[epoch15, step567]: loss 0.041740
[epoch15, step568]: loss 0.041951
[epoch15, step569]: loss 0.036824
[epoch15, step570]: loss 0.042955
[epoch15, step571]: loss 0.040573
[epoch15, step572]: loss 0.038161
[epoch15, step573]: loss 0.038210
[epoch15, step574]: loss 0.041113
[epoch15, step575]: loss 0.032262
[epoch15, step576]: loss 0.033920
[epoch15, step577]: loss 0.037172
[epoch15, step578]: loss 0.030590
[epoch15, step579]: loss 0.039506
[epoch15, step580]: loss 0.030786
[epoch15, step581]: loss 0.035794
[epoch15, step582]: loss 0.035833
[epoch15, step583]: loss 0.035922
[epoch15, step584]: loss 0.034286
[epoch15, step585]: loss 0.036972
[epoch15, step586]: loss 0.034420
[epoch15, step587]: loss 0.040967
[epoch15, step588]: loss 0.034661
[epoch15, step589]: loss 0.035354
[epoch15, step590]: loss 0.039185
[epoch15, step591]: loss 0.031942
[epoch15, step592]: loss 0.037228
[epoch15, step593]: loss 0.033227
[epoch15, step594]: loss 0.037585
[epoch15, step595]: loss 0.038692
[epoch15, step596]: loss 0.037092
[epoch15, step597]: loss 0.036775
[epoch15, step598]: loss 0.038525
[epoch15, step599]: loss 0.036359
[epoch15, step600]: loss 0.038600
[epoch15, step601]: loss 0.030686
[epoch15, step602]: loss 0.033279
[epoch15, step603]: loss 0.036565
[epoch15, step604]: loss 0.038082
[epoch15, step605]: loss 0.036053
[epoch15, step606]: loss 0.035234
[epoch15, step607]: loss 0.037568
[epoch15, step608]: loss 0.037422
[epoch15, step609]: loss 0.036707
[epoch15, step610]: loss 0.039279
[epoch15, step611]: loss 0.037868
[epoch15, step612]: loss 0.035197
[epoch15, step613]: loss 0.029931
[epoch15, step614]: loss 0.035194
[epoch15, step615]: loss 0.040741
[epoch15, step616]: loss 0.033946
[epoch15, step617]: loss 0.033273
[epoch15, step618]: loss 0.037671
[epoch15, step619]: loss 0.038668
[epoch15, step620]: loss 0.034956
[epoch15, step621]: loss 0.037190
[epoch15, step622]: loss 0.031229
[epoch15, step623]: loss 0.033378
[epoch15, step624]: loss 0.037548
[epoch15, step625]: loss 0.036258
[epoch15, step626]: loss 0.038657
[epoch15, step627]: loss 0.033155
[epoch15, step628]: loss 0.035479
[epoch15, step629]: loss 0.030836
[epoch15, step630]: loss 0.032372
[epoch15, step631]: loss 0.042214
[epoch15, step632]: loss 0.034380
[epoch15, step633]: loss 0.034909
[epoch15, step634]: loss 0.037628
[epoch15, step635]: loss 0.037191
[epoch15, step636]: loss 0.031770
[epoch15, step637]: loss 0.038519
[epoch15, step638]: loss 0.038695
[epoch15, step639]: loss 0.032570
[epoch15, step640]: loss 0.040538
[epoch15, step641]: loss 0.040136
[epoch15, step642]: loss 0.035267
[epoch15, step643]: loss 0.035241
[epoch15, step644]: loss 0.036593
[epoch15, step645]: loss 0.034299
[epoch15, step646]: loss 0.035976
[epoch15, step647]: loss 0.034293
[epoch15, step648]: loss 0.034650
[epoch15, step649]: loss 0.038027
[epoch15, step650]: loss 0.033122
[epoch15, step651]: loss 0.037723
[epoch15, step652]: loss 0.038130
[epoch15, step653]: loss 0.037675
[epoch15, step654]: loss 0.033090
[epoch15, step655]: loss 0.034839
[epoch15, step656]: loss 0.033266
[epoch15, step657]: loss 0.038539
[epoch15, step658]: loss 0.035471
[epoch15, step659]: loss 0.037387
[epoch15, step660]: loss 0.033363
[epoch15, step661]: loss 0.036672
[epoch15, step662]: loss 0.033847
[epoch15, step663]: loss 0.032352
[epoch15, step664]: loss 0.036587
[epoch15, step665]: loss 0.037440
[epoch15, step666]: loss 0.037244
[epoch15, step667]: loss 0.037273
[epoch15, step668]: loss 0.033843
[epoch15, step669]: loss 0.037314
[epoch15, step670]: loss 0.037624
[epoch15, step671]: loss 0.032245
[epoch15, step672]: loss 0.035187
[epoch15, step673]: loss 0.032947
[epoch15, step674]: loss 0.031496
[epoch15, step675]: loss 0.031180
[epoch15, step676]: loss 0.033820
[epoch15, step677]: loss 0.035318
[epoch15, step678]: loss 0.033187
[epoch15, step679]: loss 0.035235
[epoch15, step680]: loss 0.041554
[epoch15, step681]: loss 0.031957
[epoch15, step682]: loss 0.036425
[epoch15, step683]: loss 0.035419
[epoch15, step684]: loss 0.035859
[epoch15, step685]: loss 0.035115
[epoch15, step686]: loss 0.038608
[epoch15, step687]: loss 0.036184
[epoch15, step688]: loss 0.034820
[epoch15, step689]: loss 0.035742
[epoch15, step690]: loss 0.035788
[epoch15, step691]: loss 0.035385
[epoch15, step692]: loss 0.033879
[epoch15, step693]: loss 0.038411
[epoch15, step694]: loss 0.032784
[epoch15, step695]: loss 0.038129
[epoch15, step696]: loss 0.035208
[epoch15, step697]: loss 0.037703
[epoch15, step698]: loss 0.035151
[epoch15, step699]: loss 0.033872
[epoch15, step700]: loss 0.031558
[epoch15, step701]: loss 0.036298
[epoch15, step702]: loss 0.031813
[epoch15, step703]: loss 0.034100
[epoch15, step704]: loss 0.036797
[epoch15, step705]: loss 0.035925
[epoch15, step706]: loss 0.033796
[epoch15, step707]: loss 0.033669
[epoch15, step708]: loss 0.035183
[epoch15, step709]: loss 0.037363
[epoch15, step710]: loss 0.033086
[epoch15, step711]: loss 0.036863
[epoch15, step712]: loss 0.037019
[epoch15, step713]: loss 0.037596
[epoch15, step714]: loss 0.032063
[epoch15, step715]: loss 0.033886
[epoch15, step716]: loss 0.036102
[epoch15, step717]: loss 0.033399
[epoch15, step718]: loss 0.035899
[epoch15, step719]: loss 0.044884
[epoch15, step720]: loss 0.034963
[epoch15, step721]: loss 0.033323
[epoch15, step722]: loss 0.041317
[epoch15, step723]: loss 0.037722
[epoch15, step724]: loss 0.032912
[epoch15, step725]: loss 0.037432
[epoch15, step726]: loss 0.032094
[epoch15, step727]: loss 0.034549
[epoch15, step728]: loss 0.036993
[epoch15, step729]: loss 0.032553
[epoch15, step730]: loss 0.033083
[epoch15, step731]: loss 0.036421
[epoch15, step732]: loss 0.036284
[epoch15, step733]: loss 0.034226
[epoch15, step734]: loss 0.034250
[epoch15, step735]: loss 0.038041
[epoch15, step736]: loss 0.036441
[epoch15, step737]: loss 0.037492
[epoch15, step738]: loss 0.030709
[epoch15, step739]: loss 0.036700
[epoch15, step740]: loss 0.033125
[epoch15, step741]: loss 0.036321
[epoch15, step742]: loss 0.033603
[epoch15, step743]: loss 0.034358
[epoch15, step744]: loss 0.033677
[epoch15, step745]: loss 0.033921
[epoch15, step746]: loss 0.036950
[epoch15, step747]: loss 0.039145
[epoch15, step748]: loss 0.036970
[epoch15, step749]: loss 0.035916
[epoch15, step750]: loss 0.038471
[epoch15, step751]: loss 0.033510
[epoch15, step752]: loss 0.035680
[epoch15, step753]: loss 0.035524
[epoch15, step754]: loss 0.034026
[epoch15, step755]: loss 0.036135
[epoch15, step756]: loss 0.033790
[epoch15, step757]: loss 0.030153
[epoch15, step758]: loss 0.034262
[epoch15, step759]: loss 0.033249
[epoch15, step760]: loss 0.034669
[epoch15, step761]: loss 0.037423
[epoch15, step762]: loss 0.031235
[epoch15, step763]: loss 0.035517
[epoch15, step764]: loss 0.034993
[epoch15, step765]: loss 0.036795
[epoch15, step766]: loss 0.036114
[epoch15, step767]: loss 0.038576
[epoch15, step768]: loss 0.031092
[epoch15, step769]: loss 0.035864
[epoch15, step770]: loss 0.034974
[epoch15, step771]: loss 0.033377
[epoch15, step772]: loss 0.038401
[epoch15, step773]: loss 0.036051
[epoch15, step774]: loss 0.035522
[epoch15, step775]: loss 0.029751
[epoch15, step776]: loss 0.037402
[epoch15, step777]: loss 0.033714
[epoch15, step778]: loss 0.037349
[epoch15, step779]: loss 0.035060
[epoch15, step780]: loss 0.030051
[epoch15, step781]: loss 0.034950
[epoch15, step782]: loss 0.032456
[epoch15, step783]: loss 0.030336
[epoch15, step784]: loss 0.031215
[epoch15, step785]: loss 0.031849
[epoch15, step786]: loss 0.034669
[epoch15, step787]: loss 0.034732
[epoch15, step788]: loss 0.036551
[epoch15, step789]: loss 0.035139
[epoch15, step790]: loss 0.034794
[epoch15, step791]: loss 0.038059
[epoch15, step792]: loss 0.035638
[epoch15, step793]: loss 0.037359
[epoch15, step794]: loss 0.030432
[epoch15, step795]: loss 0.035154
[epoch15, step796]: loss 0.037805
[epoch15, step797]: loss 0.036984
[epoch15, step798]: loss 0.037107
[epoch15, step799]: loss 0.037430
[epoch15, step800]: loss 0.031461
[epoch15, step801]: loss 0.033927
[epoch15, step802]: loss 0.033478
[epoch15, step803]: loss 0.037498
[epoch15, step804]: loss 0.037597
[epoch15, step805]: loss 0.038191
[epoch15, step806]: loss 0.032799
[epoch15, step807]: loss 0.031483
[epoch15, step808]: loss 0.034127
[epoch15, step809]: loss 0.032226
[epoch15, step810]: loss 0.036685
[epoch15, step811]: loss 0.035229
[epoch15, step812]: loss 0.033447
[epoch15, step813]: loss 0.034005
[epoch15, step814]: loss 0.036763
[epoch15, step815]: loss 0.033920
[epoch15, step816]: loss 0.034349
[epoch15, step817]: loss 0.035427
[epoch15, step818]: loss 0.032858
[epoch15, step819]: loss 0.031266
[epoch15, step820]: loss 0.034429
[epoch15, step821]: loss 0.031894
[epoch15, step822]: loss 0.039894
[epoch15, step823]: loss 0.033945
[epoch15, step824]: loss 0.036500
[epoch15, step825]: loss 0.036523
[epoch15, step826]: loss 0.035128
[epoch15, step827]: loss 0.037661
[epoch15, step828]: loss 0.039882
[epoch15, step829]: loss 0.038784
[epoch15, step830]: loss 0.033505
[epoch15, step831]: loss 0.037027
[epoch15, step832]: loss 0.031492
[epoch15, step833]: loss 0.038706
[epoch15, step834]: loss 0.036993
[epoch15, step835]: loss 0.031240
[epoch15, step836]: loss 0.039176
[epoch15, step837]: loss 0.036327
[epoch15, step838]: loss 0.035012
[epoch15, step839]: loss 0.039322
[epoch15, step840]: loss 0.031385
[epoch15, step841]: loss 0.035446
[epoch15, step842]: loss 0.037383
[epoch15, step843]: loss 0.035982
[epoch15, step844]: loss 0.035999
[epoch15, step845]: loss 0.031892
[epoch15, step846]: loss 0.039227
[epoch15, step847]: loss 0.036821
[epoch15, step848]: loss 0.035792
[epoch15, step849]: loss 0.033932
[epoch15, step850]: loss 0.033665
[epoch15, step851]: loss 0.035388
[epoch15, step852]: loss 0.033215
[epoch15, step853]: loss 0.040353
[epoch15, step854]: loss 0.033858
[epoch15, step855]: loss 0.037650
[epoch15, step856]: loss 0.031653
[epoch15, step857]: loss 0.034591
[epoch15, step858]: loss 0.034594
[epoch15, step859]: loss 0.034331
[epoch15, step860]: loss 0.032610
[epoch15, step861]: loss 0.032872
[epoch15, step862]: loss 0.032863
[epoch15, step863]: loss 0.031618
[epoch15, step864]: loss 0.037094
[epoch15, step865]: loss 0.034030
[epoch15, step866]: loss 0.035528
[epoch15, step867]: loss 0.036749
[epoch15, step868]: loss 0.036563
[epoch15, step869]: loss 0.034484
[epoch15, step870]: loss 0.041332
[epoch15, step871]: loss 0.033457
[epoch15, step872]: loss 0.035785
[epoch15, step873]: loss 0.035790
[epoch15, step874]: loss 0.034743
[epoch15, step875]: loss 0.034435
[epoch15, step876]: loss 0.036721
[epoch15, step877]: loss 0.030032
[epoch15, step878]: loss 0.033525
[epoch15, step879]: loss 0.037861
[epoch15, step880]: loss 0.036506
[epoch15, step881]: loss 0.032718
[epoch15, step882]: loss 0.034053
[epoch15, step883]: loss 0.034130
[epoch15, step884]: loss 0.037317
[epoch15, step885]: loss 0.035359
[epoch15, step886]: loss 0.035733
[epoch15, step887]: loss 0.035032
[epoch15, step888]: loss 0.035258
[epoch15, step889]: loss 0.034750
[epoch15, step890]: loss 0.034163
[epoch15, step891]: loss 0.036178
[epoch15, step892]: loss 0.030546
[epoch15, step893]: loss 0.034529
[epoch15, step894]: loss 0.035533
[epoch15, step895]: loss 0.032351
[epoch15, step896]: loss 0.032953
[epoch15, step897]: loss 0.035802
[epoch15, step898]: loss 0.036919
[epoch15, step899]: loss 0.039087
[epoch15, step900]: loss 0.036163
[epoch15, step901]: loss 0.036768
[epoch15, step902]: loss 0.034413
[epoch15, step903]: loss 0.035616
[epoch15, step904]: loss 0.037466
[epoch15, step905]: loss 0.037888
[epoch15, step906]: loss 0.031733
[epoch15, step907]: loss 0.033851
[epoch15, step908]: loss 0.031582
[epoch15, step909]: loss 0.037349
[epoch15, step910]: loss 0.033324
[epoch15, step911]: loss 0.035360
[epoch15, step912]: loss 0.033226
[epoch15, step913]: loss 0.034778
[epoch15, step914]: loss 0.039402
[epoch15, step915]: loss 0.033906
[epoch15, step916]: loss 0.033445
[epoch15, step917]: loss 0.035199
[epoch15, step918]: loss 0.039329
[epoch15, step919]: loss 0.035226
[epoch15, step920]: loss 0.037823
[epoch15, step921]: loss 0.033897
[epoch15, step922]: loss 0.034681
[epoch15, step923]: loss 0.033103
[epoch15, step924]: loss 0.030187
[epoch15, step925]: loss 0.035656
[epoch15, step926]: loss 0.034770
[epoch15, step927]: loss 0.035383
[epoch15, step928]: loss 0.034931
[epoch15, step929]: loss 0.037906
[epoch15, step930]: loss 0.036050
[epoch15, step931]: loss 0.037143
[epoch15, step932]: loss 0.031603
[epoch15, step933]: loss 0.038994
[epoch15, step934]: loss 0.032520
[epoch15, step935]: loss 0.034003
[epoch15, step936]: loss 0.032532
[epoch15, step937]: loss 0.036625
[epoch15, step938]: loss 0.038031
[epoch15, step939]: loss 0.031241
[epoch15, step940]: loss 0.033970
[epoch15, step941]: loss 0.037896
[epoch15, step942]: loss 0.035931
[epoch15, step943]: loss 0.033609
[epoch15, step944]: loss 0.038088
[epoch15, step945]: loss 0.031298
[epoch15, step946]: loss 0.035475
[epoch15, step947]: loss 0.038919
[epoch15, step948]: loss 0.030227
[epoch15, step949]: loss 0.033875
[epoch15, step950]: loss 0.038348
[epoch15, step951]: loss 0.039406
[epoch15, step952]: loss 0.034740
[epoch15, step953]: loss 0.037172
[epoch15, step954]: loss 0.033243
[epoch15, step955]: loss 0.041594
[epoch15, step956]: loss 0.051031
[epoch15, step957]: loss 0.047456
[epoch15, step958]: loss 0.045154
[epoch15, step959]: loss 0.047134
[epoch15, step960]: loss 0.044323
[epoch15, step961]: loss 0.044352
[epoch15, step962]: loss 0.043544
[epoch15, step963]: loss 0.043053
[epoch15, step964]: loss 0.043598
[epoch15, step965]: loss 0.043937
[epoch15, step966]: loss 0.043481
[epoch15, step967]: loss 0.043406
[epoch15, step968]: loss 0.044647
[epoch15, step969]: loss 0.044281
[epoch15, step970]: loss 0.043395
[epoch15, step971]: loss 0.042586
[epoch15, step972]: loss 0.042972
[epoch15, step973]: loss 0.042994
[epoch15, step974]: loss 0.044301
[epoch15, step975]: loss 0.042233
[epoch15, step976]: loss 0.041300
[epoch15, step977]: loss 0.043585
[epoch15, step978]: loss 0.042798
[epoch15, step979]: loss 0.042234
[epoch15, step980]: loss 0.041934
[epoch15, step981]: loss 0.042678
[epoch15, step982]: loss 0.042551
[epoch15, step983]: loss 0.043439
[epoch15, step984]: loss 0.041690
[epoch15, step985]: loss 0.041534
[epoch15, step986]: loss 0.043497
[epoch15, step987]: loss 0.042896
[epoch15, step988]: loss 0.042771
[epoch15, step989]: loss 0.041936
[epoch15, step990]: loss 0.042074
[epoch15, step991]: loss 0.042560
[epoch15, step992]: loss 0.042890
[epoch15, step993]: loss 0.041466
[epoch15, step994]: loss 0.040757
[epoch15, step995]: loss 0.043307
[epoch15, step996]: loss 0.042467
[epoch15, step997]: loss 0.042052
[epoch15, step998]: loss 0.042207
[epoch15, step999]: loss 0.041823
[epoch15, step1000]: loss 0.042236
[epoch15, step1001]: loss 0.042743
[epoch15, step1002]: loss 0.041420
[epoch15, step1003]: loss 0.040930
[epoch15, step1004]: loss 0.043083
[epoch15, step1005]: loss 0.041821
[epoch15, step1006]: loss 0.041586
[epoch15, step1007]: loss 0.041080
[epoch15, step1008]: loss 0.041666
[epoch15, step1009]: loss 0.042285
[epoch15, step1010]: loss 0.042922
[epoch15, step1011]: loss 0.041351
[epoch15, step1012]: loss 0.041039
[epoch15, step1013]: loss 0.042688
[epoch15, step1014]: loss 0.042624
[epoch15, step1015]: loss 0.042172
[epoch15, step1016]: loss 0.041153
[epoch15, step1017]: loss 0.041823
[epoch15, step1018]: loss 0.041909
[epoch15, step1019]: loss 0.043163
[epoch15, step1020]: loss 0.041261
[epoch15, step1021]: loss 0.040413
[epoch15, step1022]: loss 0.042571
[epoch15, step1023]: loss 0.041853
[epoch15, step1024]: loss 0.042447
[epoch15, step1025]: loss 0.040538
[epoch15, step1026]: loss 0.041249
[epoch15, step1027]: loss 0.041873
[epoch15, step1028]: loss 0.042207
[epoch15, step1029]: loss 0.041175
[epoch15, step1030]: loss 0.040253
[epoch15, step1031]: loss 0.042197
[epoch15, step1032]: loss 0.042033
[epoch15, step1033]: loss 0.041540
[epoch15, step1034]: loss 0.041076
[epoch15, step1035]: loss 0.041461
[epoch15, step1036]: loss 0.041905
[epoch15, step1037]: loss 0.042358
[epoch15, step1038]: loss 0.040786
[epoch15, step1039]: loss 0.040944
[epoch15, step1040]: loss 0.042359
[epoch15, step1041]: loss 0.041505
[epoch15, step1042]: loss 0.041462
[epoch15, step1043]: loss 0.040788
[epoch15, step1044]: loss 0.041650
[epoch15, step1045]: loss 0.042009
[epoch15, step1046]: loss 0.042616
[epoch15, step1047]: loss 0.041246
[epoch15, step1048]: loss 0.040739
[epoch15, step1049]: loss 0.043056
[epoch15, step1050]: loss 0.042333
[epoch15, step1051]: loss 0.041929
[epoch15, step1052]: loss 0.041111
[epoch15, step1053]: loss 0.041986
[epoch15, step1054]: loss 0.041826
[epoch15, step1055]: loss 0.042005
[epoch15, step1056]: loss 0.040393
[epoch15, step1057]: loss 0.040655
[epoch15, step1058]: loss 0.042999
[epoch15, step1059]: loss 0.042075
[epoch15, step1060]: loss 0.041513
[epoch15, step1061]: loss 0.040200
[epoch15, step1062]: loss 0.042100
[epoch15, step1063]: loss 0.042172
[epoch15, step1064]: loss 0.042101
[epoch15, step1065]: loss 0.041087
[epoch15, step1066]: loss 0.040216
[epoch15, step1067]: loss 0.042561
[epoch15, step1068]: loss 0.040956
[epoch15, step1069]: loss 0.040985
[epoch15, step1070]: loss 0.040894
[epoch15, step1071]: loss 0.041674
[epoch15, step1072]: loss 0.041908
[epoch15, step1073]: loss 0.042002
[epoch15, step1074]: loss 0.040600
[epoch15, step1075]: loss 0.040565
[epoch15, step1076]: loss 0.042340
[epoch15, step1077]: loss 0.041696
[epoch15, step1078]: loss 0.041694
[epoch15, step1079]: loss 0.041492
[epoch15, step1080]: loss 0.041733
[epoch15, step1081]: loss 0.041385
[epoch15, step1082]: loss 0.042000
[epoch15, step1083]: loss 0.041252
[epoch15, step1084]: loss 0.040450
[epoch15, step1085]: loss 0.041872
[epoch15, step1086]: loss 0.040991
[epoch15, step1087]: loss 0.041365
[epoch15, step1088]: loss 0.040380
[epoch15, step1089]: loss 0.041224
[epoch15, step1090]: loss 0.041737
[epoch15, step1091]: loss 0.042445
[epoch15, step1092]: loss 0.040612
[epoch15, step1093]: loss 0.040133
[epoch15, step1094]: loss 0.041598
[epoch15, step1095]: loss 0.041158
[epoch15, step1096]: loss 0.040912
[epoch15, step1097]: loss 0.041049
[epoch15, step1098]: loss 0.041099
[epoch15, step1099]: loss 0.041957
[epoch15, step1100]: loss 0.042714
[epoch15, step1101]: loss 0.041158
[epoch15, step1102]: loss 0.040233
[epoch15, step1103]: loss 0.042435
[epoch15, step1104]: loss 0.041320
[epoch15, step1105]: loss 0.041908
[epoch15, step1106]: loss 0.040087
[epoch15, step1107]: loss 0.041057
[epoch15, step1108]: loss 0.041017
[epoch15, step1109]: loss 0.041884
[epoch15, step1110]: loss 0.041057
[epoch15, step1111]: loss 0.040263
[epoch15, step1112]: loss 0.042233
[epoch15, step1113]: loss 0.041102
[epoch15, step1114]: loss 0.041219
[epoch15, step1115]: loss 0.040708
[epoch15, step1116]: loss 0.041254
[epoch15, step1117]: loss 0.041530
[epoch15, step1118]: loss 0.042099
[epoch15, step1119]: loss 0.040402
[epoch15, step1120]: loss 0.040054
[epoch15, step1121]: loss 0.041919
[epoch15, step1122]: loss 0.042278
[epoch15, step1123]: loss 0.040660
[epoch15, step1124]: loss 0.041224
[epoch15, step1125]: loss 0.041577
[epoch15, step1126]: loss 0.042119
[epoch15, step1127]: loss 0.042007
[epoch15, step1128]: loss 0.041189
[epoch15, step1129]: loss 0.039805
[epoch15, step1130]: loss 0.042471
[epoch15, step1131]: loss 0.041599
[epoch15, step1132]: loss 0.041188
[epoch15, step1133]: loss 0.039878
[epoch15, step1134]: loss 0.040716
[epoch15, step1135]: loss 0.042105
[epoch15, step1136]: loss 0.042459
[epoch15, step1137]: loss 0.040865
[epoch15, step1138]: loss 0.040326
[epoch15, step1139]: loss 0.042945
[epoch15, step1140]: loss 0.041873
[epoch15, step1141]: loss 0.041352
[epoch15, step1142]: loss 0.041459
[epoch15, step1143]: loss 0.041707
[epoch15, step1144]: loss 0.041646
[epoch15, step1145]: loss 0.042002
[epoch15, step1146]: loss 0.041020
[epoch15, step1147]: loss 0.040603
[epoch15, step1148]: loss 0.042671
[epoch15, step1149]: loss 0.041387
[epoch15, step1150]: loss 0.040928
[epoch15, step1151]: loss 0.040728
[epoch15, step1152]: loss 0.041477
[epoch15, step1153]: loss 0.040973
[epoch15, step1154]: loss 0.041639
[epoch15, step1155]: loss 0.040554
[epoch15, step1156]: loss 0.039763
[epoch15, step1157]: loss 0.042701
[epoch15, step1158]: loss 0.041235
[epoch15, step1159]: loss 0.040907
[epoch15, step1160]: loss 0.040749
[epoch15, step1161]: loss 0.041830
[epoch15, step1162]: loss 0.041563
[epoch15, step1163]: loss 0.041046
[epoch15, step1164]: loss 0.040912
[epoch15, step1165]: loss 0.041535
[epoch15, step1166]: loss 0.042464
[epoch15, step1167]: loss 0.041276
[epoch15, step1168]: loss 0.041478
[epoch15, step1169]: loss 0.040136
[epoch15, step1170]: loss 0.040900
[epoch15, step1171]: loss 0.041324
[epoch15, step1172]: loss 0.042334
[epoch15, step1173]: loss 0.040625
[epoch15, step1174]: loss 0.040443
[epoch15, step1175]: loss 0.041628
[epoch15, step1176]: loss 0.041171
[epoch15, step1177]: loss 0.041384
[epoch15, step1178]: loss 0.040744
[epoch15, step1179]: loss 0.040695
[epoch15, step1180]: loss 0.041140
[epoch15, step1181]: loss 0.043272
[epoch15, step1182]: loss 0.040592
[epoch15, step1183]: loss 0.040482
[epoch15, step1184]: loss 0.041892
[epoch15, step1185]: loss 0.041458
[epoch15, step1186]: loss 0.041292
[epoch15, step1187]: loss 0.039681
[epoch15, step1188]: loss 0.040598
[epoch15, step1189]: loss 0.041480
[epoch15, step1190]: loss 0.040979
[epoch15, step1191]: loss 0.041013
[epoch15, step1192]: loss 0.039811
[epoch15, step1193]: loss 0.041953
[epoch15, step1194]: loss 0.041735
[epoch15, step1195]: loss 0.040384
[epoch15, step1196]: loss 0.039847
[epoch15, step1197]: loss 0.041355
[epoch15, step1198]: loss 0.041142
[epoch15, step1199]: loss 0.041023
[epoch15, step1200]: loss 0.040862
[epoch15, step1201]: loss 0.040309
[epoch15, step1202]: loss 0.042734
[epoch15, step1203]: loss 0.041344
[epoch15, step1204]: loss 0.040966
[epoch15, step1205]: loss 0.040599
[epoch15, step1206]: loss 0.040739
[epoch15, step1207]: loss 0.041437
[epoch15, step1208]: loss 0.042411
[epoch15, step1209]: loss 0.040411
[epoch15, step1210]: loss 0.040402
[epoch15, step1211]: loss 0.042275
[epoch15, step1212]: loss 0.041009
[epoch15, step1213]: loss 0.040831
[epoch15, step1214]: loss 0.040370
[epoch15, step1215]: loss 0.041563
[epoch15, step1216]: loss 0.041827
[epoch15, step1217]: loss 0.041545
[epoch15, step1218]: loss 0.040221
[epoch15, step1219]: loss 0.040399
[epoch15, step1220]: loss 0.042242
[epoch15, step1221]: loss 0.040658
[epoch15, step1222]: loss 0.041102
[epoch15, step1223]: loss 0.040386
[epoch15, step1224]: loss 0.040991
[epoch15, step1225]: loss 0.041332
[epoch15, step1226]: loss 0.041520
[epoch15, step1227]: loss 0.040904
[epoch15, step1228]: loss 0.040164
[epoch15, step1229]: loss 0.042070
[epoch15, step1230]: loss 0.041265
[epoch15, step1231]: loss 0.040858
[epoch15, step1232]: loss 0.040991
[epoch15, step1233]: loss 0.040903
[epoch15, step1234]: loss 0.040987
[epoch15, step1235]: loss 0.042263
[epoch15, step1236]: loss 0.040806
[epoch15, step1237]: loss 0.039882
[epoch15, step1238]: loss 0.041435
[epoch15, step1239]: loss 0.041356
[epoch15, step1240]: loss 0.041290
[epoch15, step1241]: loss 0.040373
[epoch15, step1242]: loss 0.041258
[epoch15, step1243]: loss 0.041698
[epoch15, step1244]: loss 0.041637
[epoch15, step1245]: loss 0.040633
[epoch15, step1246]: loss 0.040146
[epoch15, step1247]: loss 0.041349
[epoch15, step1248]: loss 0.041243
[epoch15, step1249]: loss 0.041105
[epoch15, step1250]: loss 0.040344
[epoch15, step1251]: loss 0.040595
[epoch15, step1252]: loss 0.042807
[epoch15, step1253]: loss 0.041924
[epoch15, step1254]: loss 0.040543
[epoch15, step1255]: loss 0.040805
[epoch15, step1256]: loss 0.042133
[epoch15, step1257]: loss 0.040681
[epoch15, step1258]: loss 0.040938
[epoch15, step1259]: loss 0.040305
[epoch15, step1260]: loss 0.041253
[epoch15, step1261]: loss 0.040919
[epoch15, step1262]: loss 0.040809
[epoch15, step1263]: loss 0.040694
[epoch15, step1264]: loss 0.041367
[epoch15, step1265]: loss 0.041314
[epoch15, step1266]: loss 0.040739
[epoch15, step1267]: loss 0.041162
[epoch15, step1268]: loss 0.040232
[epoch15, step1269]: loss 0.041028
[epoch15, step1270]: loss 0.041116
[epoch15, step1271]: loss 0.041510
[epoch15, step1272]: loss 0.040618
[epoch15, step1273]: loss 0.039943
[epoch15, step1274]: loss 0.042156
[epoch15, step1275]: loss 0.041254
[epoch15, step1276]: loss 0.040973
[epoch15, step1277]: loss 0.040489
[epoch15, step1278]: loss 0.041056
[epoch15, step1279]: loss 0.041537
[epoch15, step1280]: loss 0.042316
[epoch15, step1281]: loss 0.040648
[epoch15, step1282]: loss 0.040577
[epoch15, step1283]: loss 0.041478
[epoch15, step1284]: loss 0.041182
[epoch15, step1285]: loss 0.041366
[epoch15, step1286]: loss 0.039782
[epoch15, step1287]: loss 0.041574
[epoch15, step1288]: loss 0.041568
[epoch15, step1289]: loss 0.042126
[epoch15, step1290]: loss 0.040797
[epoch15, step1291]: loss 0.039883
[epoch15, step1292]: loss 0.042127
[epoch15, step1293]: loss 0.040643
[epoch15, step1294]: loss 0.040826
[epoch15, step1295]: loss 0.040982
[epoch15, step1296]: loss 0.041241
[epoch15, step1297]: loss 0.041213
[epoch15, step1298]: loss 0.042373
[epoch15, step1299]: loss 0.041667
[epoch15, step1300]: loss 0.040990
[epoch15, step1301]: loss 0.041561
[epoch15, step1302]: loss 0.041589
[epoch15, step1303]: loss 0.040625
[epoch15, step1304]: loss 0.040031
[epoch15, step1305]: loss 0.040679
[epoch15, step1306]: loss 0.040839
[epoch15, step1307]: loss 0.041445
[epoch15, step1308]: loss 0.040849
[epoch15, step1309]: loss 0.039649
[epoch15, step1310]: loss 0.042478
[epoch15, step1311]: loss 0.040492
[epoch15, step1312]: loss 0.040890
[epoch15, step1313]: loss 0.040533
[epoch15, step1314]: loss 0.041336
[epoch15, step1315]: loss 0.041477
[epoch15, step1316]: loss 0.042363
[epoch15, step1317]: loss 0.040349
[epoch15, step1318]: loss 0.039769
[epoch15, step1319]: loss 0.041797
[epoch15, step1320]: loss 0.041758
[epoch15, step1321]: loss 0.041884
[epoch15, step1322]: loss 0.040214
[epoch15, step1323]: loss 0.041602
[epoch15, step1324]: loss 0.041753
[epoch15, step1325]: loss 0.041245
[epoch15, step1326]: loss 0.040280
[epoch15, step1327]: loss 0.040487
[epoch15, step1328]: loss 0.042994
[epoch15, step1329]: loss 0.041238
[epoch15, step1330]: loss 0.040991
[epoch15, step1331]: loss 0.040221
[epoch15, step1332]: loss 0.040584
[epoch15, step1333]: loss 0.041020
[epoch15, step1334]: loss 0.041708
[epoch15, step1335]: loss 0.041086
[epoch15, step1336]: loss 0.040076
[epoch15, step1337]: loss 0.041639
[epoch15, step1338]: loss 0.040950
[epoch15, step1339]: loss 0.041080
[epoch15, step1340]: loss 0.040061
[epoch15, step1341]: loss 0.041152
[epoch15, step1342]: loss 0.040891
[epoch15, step1343]: loss 0.041426
[epoch15, step1344]: loss 0.040400
[epoch15, step1345]: loss 0.039895
[epoch15, step1346]: loss 0.041848
[epoch15, step1347]: loss 0.040903
[epoch15, step1348]: loss 0.040816
[epoch15, step1349]: loss 0.040544
[epoch15, step1350]: loss 0.040620
[epoch15, step1351]: loss 0.041051
[epoch15, step1352]: loss 0.042005
[epoch15, step1353]: loss 0.040678
[epoch15, step1354]: loss 0.039878
[epoch15, step1355]: loss 0.042683
[epoch15, step1356]: loss 0.040761
[epoch15, step1357]: loss 0.040542
[epoch15, step1358]: loss 0.040048
[epoch15, step1359]: loss 0.040569
[epoch15, step1360]: loss 0.041162
[epoch15, step1361]: loss 0.042252
[epoch15, step1362]: loss 0.040420
[epoch15, step1363]: loss 0.039749
[epoch15, step1364]: loss 0.041104
[epoch15, step1365]: loss 0.040713
[epoch15, step1366]: loss 0.040574
[epoch15, step1367]: loss 0.039838
[epoch15, step1368]: loss 0.040900
[epoch15, step1369]: loss 0.041213
[epoch15, step1370]: loss 0.041285
[epoch15, step1371]: loss 0.040827
[epoch15, step1372]: loss 0.040123
[epoch15, step1373]: loss 0.041424
[epoch15, step1374]: loss 0.041667
[epoch15, step1375]: loss 0.042074
[epoch15, step1376]: loss 0.039784
[epoch15, step1377]: loss 0.040604
[epoch15, step1378]: loss 0.041792
[epoch15, step1379]: loss 0.041550
[epoch15, step1380]: loss 0.041004
[epoch15, step1381]: loss 0.039838
[epoch15, step1382]: loss 0.042118
[epoch15, step1383]: loss 0.040382
[epoch15, step1384]: loss 0.041107
[epoch15, step1385]: loss 0.040067
[epoch15, step1386]: loss 0.040986
[epoch15, step1387]: loss 0.041221
[epoch15, step1388]: loss 0.041115
[epoch15, step1389]: loss 0.039954
[epoch15, step1390]: loss 0.039967
[epoch15, step1391]: loss 0.041937
[epoch15, step1392]: loss 0.040900
[epoch15, step1393]: loss 0.040444
[epoch15, step1394]: loss 0.041613
[epoch15, step1395]: loss 0.041465
[epoch15, step1396]: loss 0.041032
[epoch15, step1397]: loss 0.041737
[epoch15, step1398]: loss 0.040966
[epoch15, step1399]: loss 0.040518
[epoch15, step1400]: loss 0.043413
[epoch15, step1401]: loss 0.041523
[epoch15, step1402]: loss 0.040701
[epoch15, step1403]: loss 0.039396
[epoch15, step1404]: loss 0.040961
[epoch15, step1405]: loss 0.041231
[epoch15, step1406]: loss 0.041514
[epoch15, step1407]: loss 0.041545
[epoch15, step1408]: loss 0.039730
[epoch15, step1409]: loss 0.041757
[epoch15, step1410]: loss 0.041481
[epoch15, step1411]: loss 0.040763
[epoch15, step1412]: loss 0.040458
[epoch15, step1413]: loss 0.041442
[epoch15, step1414]: loss 0.041310
[epoch15, step1415]: loss 0.041316
[epoch15, step1416]: loss 0.040471
[epoch15, step1417]: loss 0.039696
[epoch15, step1418]: loss 0.041462
[epoch15, step1419]: loss 0.041469
[epoch15, step1420]: loss 0.040862
[epoch15, step1421]: loss 0.040429
[epoch15, step1422]: loss 0.040657
[epoch15, step1423]: loss 0.041201
[epoch15, step1424]: loss 0.041965
[epoch15, step1425]: loss 0.040187
[epoch15, step1426]: loss 0.040488
[epoch15, step1427]: loss 0.041713
[epoch15, step1428]: loss 0.041587
[epoch15, step1429]: loss 0.042405
[epoch15, step1430]: loss 0.039996
[epoch15, step1431]: loss 0.041432
[epoch15, step1432]: loss 0.042536
[epoch15, step1433]: loss 0.042185
[epoch15, step1434]: loss 0.040028
[epoch15, step1435]: loss 0.040057
[epoch15, step1436]: loss 0.042611
[epoch15, step1437]: loss 0.040990
[epoch15, step1438]: loss 0.040891
[epoch15, step1439]: loss 0.039938
[epoch15, step1440]: loss 0.040754
[epoch15, step1441]: loss 0.043042
[epoch15, step1442]: loss 0.042067
[epoch15, step1443]: loss 0.040260
[epoch15, step1444]: loss 0.039910
[epoch15, step1445]: loss 0.043121
[epoch15, step1446]: loss 0.040748
[epoch15, step1447]: loss 0.040954
[epoch15, step1448]: loss 0.040007
[epoch15, step1449]: loss 0.040550
[epoch15, step1450]: loss 0.040795
[epoch15, step1451]: loss 0.041516
[epoch15, step1452]: loss 0.040474
[epoch15, step1453]: loss 0.040529
[epoch15, step1454]: loss 0.041730
[epoch15, step1455]: loss 0.041409
[epoch15, step1456]: loss 0.041711
[epoch15, step1457]: loss 0.040011
[epoch15, step1458]: loss 0.040778
[epoch15, step1459]: loss 0.040613
[epoch15, step1460]: loss 0.042215
[epoch15, step1461]: loss 0.040644
[epoch15, step1462]: loss 0.040049
[epoch15, step1463]: loss 0.041455
[epoch15, step1464]: loss 0.040671
[epoch15, step1465]: loss 0.040645
[epoch15, step1466]: loss 0.039801
[epoch15, step1467]: loss 0.041492
[epoch15, step1468]: loss 0.040398
[epoch15, step1469]: loss 0.041155
[epoch15, step1470]: loss 0.040801
[epoch15, step1471]: loss 0.039971
[epoch15, step1472]: loss 0.041298
[epoch15, step1473]: loss 0.041578
[epoch15, step1474]: loss 0.043142
[epoch15, step1475]: loss 0.040210
[epoch15, step1476]: loss 0.040970
[epoch15, step1477]: loss 0.041448
[epoch15, step1478]: loss 0.041457
[epoch15, step1479]: loss 0.040433
[epoch15, step1480]: loss 0.040136
[epoch15, step1481]: loss 0.041953
[epoch15, step1482]: loss 0.041580
[epoch15, step1483]: loss 0.041014
[epoch15, step1484]: loss 0.041189
[epoch15, step1485]: loss 0.041583
[epoch15, step1486]: loss 0.040244
[epoch15, step1487]: loss 0.041913
[epoch15, step1488]: loss 0.042457
[epoch15, step1489]: loss 0.040809
[epoch15, step1490]: loss 0.041792
[epoch15, step1491]: loss 0.041330
[epoch15, step1492]: loss 0.041731
[epoch15, step1493]: loss 0.041998
[epoch15, step1494]: loss 0.041068
[epoch15, step1495]: loss 0.040776
[epoch15, step1496]: loss 0.041920
[epoch15, step1497]: loss 0.041219
[epoch15, step1498]: loss 0.039927
[epoch15, step1499]: loss 0.042406
[epoch15, step1500]: loss 0.041242
[epoch15, step1501]: loss 0.040820
[epoch15, step1502]: loss 0.040003
[epoch15, step1503]: loss 0.040565
[epoch15, step1504]: loss 0.040829
[epoch15, step1505]: loss 0.042004
[epoch15, step1506]: loss 0.040122
[epoch15, step1507]: loss 0.039932
[epoch15, step1508]: loss 0.042528
[epoch15, step1509]: loss 0.041075
[epoch15, step1510]: loss 0.041101
[epoch15, step1511]: loss 0.040468
[epoch15, step1512]: loss 0.040818
[epoch15, step1513]: loss 0.041076
[epoch15, step1514]: loss 0.041755
[epoch15, step1515]: loss 0.041032
[epoch15, step1516]: loss 0.041234

[epoch15]: avg loss 0.037588

[epoch16, step1]: loss 0.042674
[epoch16, step2]: loss 0.037614
[epoch16, step3]: loss 0.037671
[epoch16, step4]: loss 0.035274
[epoch16, step5]: loss 0.035321
[epoch16, step6]: loss 0.037763
[epoch16, step7]: loss 0.035536
[epoch16, step8]: loss 0.037189
[epoch16, step9]: loss 0.034093
[epoch16, step10]: loss 0.035911
[epoch16, step11]: loss 0.038500
[epoch16, step12]: loss 0.037934
[epoch16, step13]: loss 0.034435
[epoch16, step14]: loss 0.034428
[epoch16, step15]: loss 0.036926
[epoch16, step16]: loss 0.035385
[epoch16, step17]: loss 0.037305
[epoch16, step18]: loss 0.035057
[epoch16, step19]: loss 0.033910
[epoch16, step20]: loss 0.037678
[epoch16, step21]: loss 0.036068
[epoch16, step22]: loss 0.033574
[epoch16, step23]: loss 0.033407
[epoch16, step24]: loss 0.036175
[epoch16, step25]: loss 0.034024
[epoch16, step26]: loss 0.036195
[epoch16, step27]: loss 0.033208
[epoch16, step28]: loss 0.034532
[epoch16, step29]: loss 0.036898
[epoch16, step30]: loss 0.036358
[epoch16, step31]: loss 0.033664
[epoch16, step32]: loss 0.034574
[epoch16, step33]: loss 0.036607
[epoch16, step34]: loss 0.034417
[epoch16, step35]: loss 0.037243
[epoch16, step36]: loss 0.033681
[epoch16, step37]: loss 0.035529
[epoch16, step38]: loss 0.037009
[epoch16, step39]: loss 0.036668
[epoch16, step40]: loss 0.035037
[epoch16, step41]: loss 0.033985
[epoch16, step42]: loss 0.036626
[epoch16, step43]: loss 0.034570
[epoch16, step44]: loss 0.037650
[epoch16, step45]: loss 0.034474
[epoch16, step46]: loss 0.034242
[epoch16, step47]: loss 0.036229
[epoch16, step48]: loss 0.036268
[epoch16, step49]: loss 0.032581
[epoch16, step50]: loss 0.033570
[epoch16, step51]: loss 0.036254
[epoch16, step52]: loss 0.034438
[epoch16, step53]: loss 0.036749
[epoch16, step54]: loss 0.033403
[epoch16, step55]: loss 0.034577
[epoch16, step56]: loss 0.037956
[epoch16, step57]: loss 0.036945
[epoch16, step58]: loss 0.033980
[epoch16, step59]: loss 0.033208
[epoch16, step60]: loss 0.037624
[epoch16, step61]: loss 0.033603
[epoch16, step62]: loss 0.036585
[epoch16, step63]: loss 0.033847
[epoch16, step64]: loss 0.033440
[epoch16, step65]: loss 0.037131
[epoch16, step66]: loss 0.036671
[epoch16, step67]: loss 0.034082
[epoch16, step68]: loss 0.033899
[epoch16, step69]: loss 0.036517
[epoch16, step70]: loss 0.033997
[epoch16, step71]: loss 0.036700
[epoch16, step72]: loss 0.033567
[epoch16, step73]: loss 0.034377
[epoch16, step74]: loss 0.036392
[epoch16, step75]: loss 0.036909
[epoch16, step76]: loss 0.035072
[epoch16, step77]: loss 0.035181
[epoch16, step78]: loss 0.037085
[epoch16, step79]: loss 0.033412
[epoch16, step80]: loss 0.037608
[epoch16, step81]: loss 0.033816
[epoch16, step82]: loss 0.033918
[epoch16, step83]: loss 0.036251
[epoch16, step84]: loss 0.036181
[epoch16, step85]: loss 0.034531
[epoch16, step86]: loss 0.034682
[epoch16, step87]: loss 0.038112
[epoch16, step88]: loss 0.034175
[epoch16, step89]: loss 0.036982
[epoch16, step90]: loss 0.034473
[epoch16, step91]: loss 0.034109
[epoch16, step92]: loss 0.037215
[epoch16, step93]: loss 0.036478
[epoch16, step94]: loss 0.034126
[epoch16, step95]: loss 0.034489
[epoch16, step96]: loss 0.036734
[epoch16, step97]: loss 0.035296
[epoch16, step98]: loss 0.037168
[epoch16, step99]: loss 0.034122
[epoch16, step100]: loss 0.033648
[epoch16, step101]: loss 0.038149
[epoch16, step102]: loss 0.036767
[epoch16, step103]: loss 0.034393
[epoch16, step104]: loss 0.034145
[epoch16, step105]: loss 0.037248
[epoch16, step106]: loss 0.034539
[epoch16, step107]: loss 0.037067
[epoch16, step108]: loss 0.033962
[epoch16, step109]: loss 0.034189
[epoch16, step110]: loss 0.037200
[epoch16, step111]: loss 0.036192
[epoch16, step112]: loss 0.034174
[epoch16, step113]: loss 0.034709
[epoch16, step114]: loss 0.036600
[epoch16, step115]: loss 0.034140
[epoch16, step116]: loss 0.037632
[epoch16, step117]: loss 0.033296
[epoch16, step118]: loss 0.034992
[epoch16, step119]: loss 0.037168
[epoch16, step120]: loss 0.036746
[epoch16, step121]: loss 0.034296
[epoch16, step122]: loss 0.034158
[epoch16, step123]: loss 0.036954
[epoch16, step124]: loss 0.034897
[epoch16, step125]: loss 0.037840
[epoch16, step126]: loss 0.033916
[epoch16, step127]: loss 0.034228
[epoch16, step128]: loss 0.036922
[epoch16, step129]: loss 0.035742
[epoch16, step130]: loss 0.034291
[epoch16, step131]: loss 0.033567
[epoch16, step132]: loss 0.036700
[epoch16, step133]: loss 0.034213
[epoch16, step134]: loss 0.035909
[epoch16, step135]: loss 0.034092
[epoch16, step136]: loss 0.035236
[epoch16, step137]: loss 0.036372
[epoch16, step138]: loss 0.036501
[epoch16, step139]: loss 0.033853
[epoch16, step140]: loss 0.034209
[epoch16, step141]: loss 0.036740
[epoch16, step142]: loss 0.034336
[epoch16, step143]: loss 0.036182
[epoch16, step144]: loss 0.033972
[epoch16, step145]: loss 0.034226
[epoch16, step146]: loss 0.037469
[epoch16, step147]: loss 0.037082
[epoch16, step148]: loss 0.033793
[epoch16, step149]: loss 0.033660
[epoch16, step150]: loss 0.035958
[epoch16, step151]: loss 0.034409
[epoch16, step152]: loss 0.036228
[epoch16, step153]: loss 0.033408
[epoch16, step154]: loss 0.033822
[epoch16, step155]: loss 0.036323
[epoch16, step156]: loss 0.035728
[epoch16, step157]: loss 0.034026
[epoch16, step158]: loss 0.034030
[epoch16, step159]: loss 0.036232
[epoch16, step160]: loss 0.034424
[epoch16, step161]: loss 0.036762
[epoch16, step162]: loss 0.034165
[epoch16, step163]: loss 0.034563
[epoch16, step164]: loss 0.036808
[epoch16, step165]: loss 0.036364
[epoch16, step166]: loss 0.035036
[epoch16, step167]: loss 0.033915
[epoch16, step168]: loss 0.037356
[epoch16, step169]: loss 0.034411
[epoch16, step170]: loss 0.037220
[epoch16, step171]: loss 0.034250
[epoch16, step172]: loss 0.034602
[epoch16, step173]: loss 0.037156
[epoch16, step174]: loss 0.036217
[epoch16, step175]: loss 0.035279
[epoch16, step176]: loss 0.034147
[epoch16, step177]: loss 0.036824
[epoch16, step178]: loss 0.034229
[epoch16, step179]: loss 0.035655
[epoch16, step180]: loss 0.033956
[epoch16, step181]: loss 0.034086
[epoch16, step182]: loss 0.036838
[epoch16, step183]: loss 0.036695
[epoch16, step184]: loss 0.035028
[epoch16, step185]: loss 0.033833
[epoch16, step186]: loss 0.036313
[epoch16, step187]: loss 0.034275
[epoch16, step188]: loss 0.036183
[epoch16, step189]: loss 0.033816
[epoch16, step190]: loss 0.033198
[epoch16, step191]: loss 0.036333
[epoch16, step192]: loss 0.036503
[epoch16, step193]: loss 0.032219
[epoch16, step194]: loss 0.033054
[epoch16, step195]: loss 0.036343
[epoch16, step196]: loss 0.034519
[epoch16, step197]: loss 0.036338
[epoch16, step198]: loss 0.033178
[epoch16, step199]: loss 0.034424
[epoch16, step200]: loss 0.036295
[epoch16, step201]: loss 0.037077
[epoch16, step202]: loss 0.034109
[epoch16, step203]: loss 0.033903
[epoch16, step204]: loss 0.037547
[epoch16, step205]: loss 0.035174
[epoch16, step206]: loss 0.037048
[epoch16, step207]: loss 0.034044
[epoch16, step208]: loss 0.034587
[epoch16, step209]: loss 0.037232
[epoch16, step210]: loss 0.037511
[epoch16, step211]: loss 0.034666
[epoch16, step212]: loss 0.034232
[epoch16, step213]: loss 0.036992
[epoch16, step214]: loss 0.034837
[epoch16, step215]: loss 0.037189
[epoch16, step216]: loss 0.034100
[epoch16, step217]: loss 0.034173
[epoch16, step218]: loss 0.036721
[epoch16, step219]: loss 0.036221
[epoch16, step220]: loss 0.034529
[epoch16, step221]: loss 0.033953
[epoch16, step222]: loss 0.037003
[epoch16, step223]: loss 0.034747
[epoch16, step224]: loss 0.035950
[epoch16, step225]: loss 0.033756
[epoch16, step226]: loss 0.033346
[epoch16, step227]: loss 0.035417
[epoch16, step228]: loss 0.036750
[epoch16, step229]: loss 0.033220
[epoch16, step230]: loss 0.033969
[epoch16, step231]: loss 0.036866
[epoch16, step232]: loss 0.034062
[epoch16, step233]: loss 0.036021
[epoch16, step234]: loss 0.033450
[epoch16, step235]: loss 0.034356
[epoch16, step236]: loss 0.036653
[epoch16, step237]: loss 0.036428
[epoch16, step238]: loss 0.034049
[epoch16, step239]: loss 0.033467
[epoch16, step240]: loss 0.035701
[epoch16, step241]: loss 0.034358
[epoch16, step242]: loss 0.036700
[epoch16, step243]: loss 0.034196
[epoch16, step244]: loss 0.034119
[epoch16, step245]: loss 0.036310
[epoch16, step246]: loss 0.036242
[epoch16, step247]: loss 0.034362
[epoch16, step248]: loss 0.033241
[epoch16, step249]: loss 0.035730
[epoch16, step250]: loss 0.034186
[epoch16, step251]: loss 0.036781
[epoch16, step252]: loss 0.034336
[epoch16, step253]: loss 0.033378
[epoch16, step254]: loss 0.036008
[epoch16, step255]: loss 0.036222
[epoch16, step256]: loss 0.033945
[epoch16, step257]: loss 0.033799
[epoch16, step258]: loss 0.036604
[epoch16, step259]: loss 0.034564
[epoch16, step260]: loss 0.036075
[epoch16, step261]: loss 0.034467
[epoch16, step262]: loss 0.034343
[epoch16, step263]: loss 0.035860
[epoch16, step264]: loss 0.036101
[epoch16, step265]: loss 0.034040
[epoch16, step266]: loss 0.033524
[epoch16, step267]: loss 0.036215
[epoch16, step268]: loss 0.034138
[epoch16, step269]: loss 0.036120
[epoch16, step270]: loss 0.033537
[epoch16, step271]: loss 0.034072
[epoch16, step272]: loss 0.036406
[epoch16, step273]: loss 0.035866
[epoch16, step274]: loss 0.034800
[epoch16, step275]: loss 0.033583
[epoch16, step276]: loss 0.036053
[epoch16, step277]: loss 0.034781
[epoch16, step278]: loss 0.037037
[epoch16, step279]: loss 0.033284
[epoch16, step280]: loss 0.034448
[epoch16, step281]: loss 0.037045
[epoch16, step282]: loss 0.036633
[epoch16, step283]: loss 0.033882
[epoch16, step284]: loss 0.033827
[epoch16, step285]: loss 0.037170
[epoch16, step286]: loss 0.033677
[epoch16, step287]: loss 0.036948
[epoch16, step288]: loss 0.033337
[epoch16, step289]: loss 0.034499
[epoch16, step290]: loss 0.036688
[epoch16, step291]: loss 0.036284
[epoch16, step292]: loss 0.033577
[epoch16, step293]: loss 0.034773
[epoch16, step294]: loss 0.036391
[epoch16, step295]: loss 0.033606
[epoch16, step296]: loss 0.037350
[epoch16, step297]: loss 0.033520
[epoch16, step298]: loss 0.034047
[epoch16, step299]: loss 0.035399
[epoch16, step300]: loss 0.036262
[epoch16, step301]: loss 0.034038
[epoch16, step302]: loss 0.034188
[epoch16, step303]: loss 0.036771
[epoch16, step304]: loss 0.033725
[epoch16, step305]: loss 0.035815
[epoch16, step306]: loss 0.034259
[epoch16, step307]: loss 0.033442
[epoch16, step308]: loss 0.037419
[epoch16, step309]: loss 0.036664
[epoch16, step310]: loss 0.034027
[epoch16, step311]: loss 0.034512
[epoch16, step312]: loss 0.036166
[epoch16, step313]: loss 0.033997
[epoch16, step314]: loss 0.036177
[epoch16, step315]: loss 0.034563
[epoch16, step316]: loss 0.034017
[epoch16, step317]: loss 0.037053
[epoch16, step318]: loss 0.036728
[epoch16, step319]: loss 0.033364
[epoch16, step320]: loss 0.032893
[epoch16, step321]: loss 0.036087
[epoch16, step322]: loss 0.033910
[epoch16, step323]: loss 0.035959
[epoch16, step324]: loss 0.034296
[epoch16, step325]: loss 0.034021
[epoch16, step326]: loss 0.036250
[epoch16, step327]: loss 0.035534
[epoch16, step328]: loss 0.034425
[epoch16, step329]: loss 0.033793
[epoch16, step330]: loss 0.035640
[epoch16, step331]: loss 0.034444
[epoch16, step332]: loss 0.035747
[epoch16, step333]: loss 0.033928
[epoch16, step334]: loss 0.034169
[epoch16, step335]: loss 0.036665
[epoch16, step336]: loss 0.037169
[epoch16, step337]: loss 0.034608
[epoch16, step338]: loss 0.033375
[epoch16, step339]: loss 0.036418
[epoch16, step340]: loss 0.034595
[epoch16, step341]: loss 0.035884
[epoch16, step342]: loss 0.033351
[epoch16, step343]: loss 0.034329
[epoch16, step344]: loss 0.035750
[epoch16, step345]: loss 0.035504
[epoch16, step346]: loss 0.033963
[epoch16, step347]: loss 0.033372
[epoch16, step348]: loss 0.036494
[epoch16, step349]: loss 0.034607
[epoch16, step350]: loss 0.035684
[epoch16, step351]: loss 0.033212
[epoch16, step352]: loss 0.033484
[epoch16, step353]: loss 0.036641
[epoch16, step354]: loss 0.035593
[epoch16, step355]: loss 0.032890
[epoch16, step356]: loss 0.034773
[epoch16, step357]: loss 0.037033
[epoch16, step358]: loss 0.032698
[epoch16, step359]: loss 0.038537
[epoch16, step360]: loss 0.033410
[epoch16, step361]: loss 0.033607
[epoch16, step362]: loss 0.037192
[epoch16, step363]: loss 0.035847
[epoch16, step364]: loss 0.033742
[epoch16, step365]: loss 0.033366
[epoch16, step366]: loss 0.036499
[epoch16, step367]: loss 0.033984
[epoch16, step368]: loss 0.035642
[epoch16, step369]: loss 0.033403
[epoch16, step370]: loss 0.034378
[epoch16, step371]: loss 0.037409
[epoch16, step372]: loss 0.035475
[epoch16, step373]: loss 0.033487
[epoch16, step374]: loss 0.033647
[epoch16, step375]: loss 0.036959
[epoch16, step376]: loss 0.034389
[epoch16, step377]: loss 0.037385
[epoch16, step378]: loss 0.034092
[epoch16, step379]: loss 0.034333
[epoch16, step380]: loss 0.037131
[epoch16, step381]: loss 0.035473
[epoch16, step382]: loss 0.033833
[epoch16, step383]: loss 0.032484
[epoch16, step384]: loss 0.035230
[epoch16, step385]: loss 0.033719
[epoch16, step386]: loss 0.036179
[epoch16, step387]: loss 0.033387
[epoch16, step388]: loss 0.034196
[epoch16, step389]: loss 0.035734
[epoch16, step390]: loss 0.037305
[epoch16, step391]: loss 0.033244
[epoch16, step392]: loss 0.034253
[epoch16, step393]: loss 0.036338
[epoch16, step394]: loss 0.034195
[epoch16, step395]: loss 0.035945
[epoch16, step396]: loss 0.034377
[epoch16, step397]: loss 0.034042
[epoch16, step398]: loss 0.037069
[epoch16, step399]: loss 0.036551
[epoch16, step400]: loss 0.034270
[epoch16, step401]: loss 0.033923
[epoch16, step402]: loss 0.036692
[epoch16, step403]: loss 0.034151
[epoch16, step404]: loss 0.037009
[epoch16, step405]: loss 0.034414
[epoch16, step406]: loss 0.034783
[epoch16, step407]: loss 0.037124
[epoch16, step408]: loss 0.036442
[epoch16, step409]: loss 0.035165
[epoch16, step410]: loss 0.034029
[epoch16, step411]: loss 0.035836
[epoch16, step412]: loss 0.033801
[epoch16, step413]: loss 0.036254
[epoch16, step414]: loss 0.034002
[epoch16, step415]: loss 0.034403
[epoch16, step416]: loss 0.035836
[epoch16, step417]: loss 0.036760
[epoch16, step418]: loss 0.034850
[epoch16, step419]: loss 0.033075
[epoch16, step420]: loss 0.036660
[epoch16, step421]: loss 0.034144
[epoch16, step422]: loss 0.036036
[epoch16, step423]: loss 0.033683
[epoch16, step424]: loss 0.033624
[epoch16, step425]: loss 0.036314
[epoch16, step426]: loss 0.036553
[epoch16, step427]: loss 0.034443
[epoch16, step428]: loss 0.033941
[epoch16, step429]: loss 0.036647
[epoch16, step430]: loss 0.034511
[epoch16, step431]: loss 0.036974
[epoch16, step432]: loss 0.033455
[epoch16, step433]: loss 0.035199
[epoch16, step434]: loss 0.036115
[epoch16, step435]: loss 0.036563
[epoch16, step436]: loss 0.033642
[epoch16, step437]: loss 0.033793
[epoch16, step438]: loss 0.036643
[epoch16, step439]: loss 0.034462
[epoch16, step440]: loss 0.036264
[epoch16, step441]: loss 0.033620
[epoch16, step442]: loss 0.033826
[epoch16, step443]: loss 0.036923
[epoch16, step444]: loss 0.035353
[epoch16, step445]: loss 0.034164
[epoch16, step446]: loss 0.033754
[epoch16, step447]: loss 0.036524
[epoch16, step448]: loss 0.033952
[epoch16, step449]: loss 0.035913
[epoch16, step450]: loss 0.033516
[epoch16, step451]: loss 0.033927
[epoch16, step452]: loss 0.036145
[epoch16, step453]: loss 0.036594
[epoch16, step454]: loss 0.033599
[epoch16, step455]: loss 0.033997
[epoch16, step456]: loss 0.035958
[epoch16, step457]: loss 0.034352
[epoch16, step458]: loss 0.036021
[epoch16, step459]: loss 0.034107
[epoch16, step460]: loss 0.034160
[epoch16, step461]: loss 0.037251
[epoch16, step462]: loss 0.035185
[epoch16, step463]: loss 0.034162
[epoch16, step464]: loss 0.033407
[epoch16, step465]: loss 0.037256
[epoch16, step466]: loss 0.033983
[epoch16, step467]: loss 0.035857
[epoch16, step468]: loss 0.033544
[epoch16, step469]: loss 0.033670
[epoch16, step470]: loss 0.036587
[epoch16, step471]: loss 0.035865
[epoch16, step472]: loss 0.034297
[epoch16, step473]: loss 0.034002
[epoch16, step474]: loss 0.035759
[epoch16, step475]: loss 0.034105
[epoch16, step476]: loss 0.036945
[epoch16, step477]: loss 0.033476
[epoch16, step478]: loss 0.033241
[epoch16, step479]: loss 0.036095
[epoch16, step480]: loss 0.035395
[epoch16, step481]: loss 0.033554
[epoch16, step482]: loss 0.033026
[epoch16, step483]: loss 0.036254
[epoch16, step484]: loss 0.034539
[epoch16, step485]: loss 0.036506
[epoch16, step486]: loss 0.033854
[epoch16, step487]: loss 0.033205
[epoch16, step488]: loss 0.037066
[epoch16, step489]: loss 0.035472
[epoch16, step490]: loss 0.034314
[epoch16, step491]: loss 0.034165
[epoch16, step492]: loss 0.036141
[epoch16, step493]: loss 0.033878
[epoch16, step494]: loss 0.035710
[epoch16, step495]: loss 0.034639
[epoch16, step496]: loss 0.034062
[epoch16, step497]: loss 0.036296
[epoch16, step498]: loss 0.035867
[epoch16, step499]: loss 0.033877
[epoch16, step500]: loss 0.033553
[epoch16, step501]: loss 0.035792
[epoch16, step502]: loss 0.033880
[epoch16, step503]: loss 0.036446
[epoch16, step504]: loss 0.033475
[epoch16, step505]: loss 0.032956
[epoch16, step506]: loss 0.036924
[epoch16, step507]: loss 0.036764
[epoch16, step508]: loss 0.034379
[epoch16, step509]: loss 0.033836
[epoch16, step510]: loss 0.036658
[epoch16, step511]: loss 0.034734
[epoch16, step512]: loss 0.036804
[epoch16, step513]: loss 0.033838
[epoch16, step514]: loss 0.034200
[epoch16, step515]: loss 0.036433
[epoch16, step516]: loss 0.036140
[epoch16, step517]: loss 0.033936
[epoch16, step518]: loss 0.034179
[epoch16, step519]: loss 0.036142
[epoch16, step520]: loss 0.033608
[epoch16, step521]: loss 0.036220
[epoch16, step522]: loss 0.033350
[epoch16, step523]: loss 0.033630
[epoch16, step524]: loss 0.035788
[epoch16, step525]: loss 0.036447
[epoch16, step526]: loss 0.034234
[epoch16, step527]: loss 0.033341
[epoch16, step528]: loss 0.036737
[epoch16, step529]: loss 0.034958
[epoch16, step530]: loss 0.037592
[epoch16, step531]: loss 0.033707
[epoch16, step532]: loss 0.035075
[epoch16, step533]: loss 0.037528
[epoch16, step534]: loss 0.036122
[epoch16, step535]: loss 0.035354
[epoch16, step536]: loss 0.033996
[epoch16, step537]: loss 0.036777
[epoch16, step538]: loss 0.034694
[epoch16, step539]: loss 0.036069
[epoch16, step540]: loss 0.033043
[epoch16, step541]: loss 0.033784
[epoch16, step542]: loss 0.036360
[epoch16, step543]: loss 0.036052
[epoch16, step544]: loss 0.033861
[epoch16, step545]: loss 0.033207
[epoch16, step546]: loss 0.036587
[epoch16, step547]: loss 0.034132
[epoch16, step548]: loss 0.036682
[epoch16, step549]: loss 0.034430
[epoch16, step550]: loss 0.034049
[epoch16, step551]: loss 0.036313
[epoch16, step552]: loss 0.036698
[epoch16, step553]: loss 0.034992
[epoch16, step554]: loss 0.033534
[epoch16, step555]: loss 0.035994
[epoch16, step556]: loss 0.033711
[epoch16, step557]: loss 0.035802
[epoch16, step558]: loss 0.033984
[epoch16, step559]: loss 0.033247
[epoch16, step560]: loss 0.036523
[epoch16, step561]: loss 0.035619
[epoch16, step562]: loss 0.033771
[epoch16, step563]: loss 0.035642
[epoch16, step564]: loss 0.041080
[epoch16, step565]: loss 0.039011
[epoch16, step566]: loss 0.046969
[epoch16, step567]: loss 0.040131
[epoch16, step568]: loss 0.040109
[epoch16, step569]: loss 0.035678
[epoch16, step570]: loss 0.045144
[epoch16, step571]: loss 0.039535
[epoch16, step572]: loss 0.037237
[epoch16, step573]: loss 0.040218
[epoch16, step574]: loss 0.040960
[epoch16, step575]: loss 0.031965
[epoch16, step576]: loss 0.033997
[epoch16, step577]: loss 0.036944
[epoch16, step578]: loss 0.030709
[epoch16, step579]: loss 0.039586
[epoch16, step580]: loss 0.030497
[epoch16, step581]: loss 0.036025
[epoch16, step582]: loss 0.036061
[epoch16, step583]: loss 0.036112
[epoch16, step584]: loss 0.033818
[epoch16, step585]: loss 0.036783
[epoch16, step586]: loss 0.034823
[epoch16, step587]: loss 0.040082
[epoch16, step588]: loss 0.034575
[epoch16, step589]: loss 0.034977
[epoch16, step590]: loss 0.039146
[epoch16, step591]: loss 0.032082
[epoch16, step592]: loss 0.037080
[epoch16, step593]: loss 0.032953
[epoch16, step594]: loss 0.037826
[epoch16, step595]: loss 0.038642
[epoch16, step596]: loss 0.037178
[epoch16, step597]: loss 0.036019
[epoch16, step598]: loss 0.037188
[epoch16, step599]: loss 0.035292
[epoch16, step600]: loss 0.037373
[epoch16, step601]: loss 0.030698
[epoch16, step602]: loss 0.033383
[epoch16, step603]: loss 0.036525
[epoch16, step604]: loss 0.038242
[epoch16, step605]: loss 0.036715
[epoch16, step606]: loss 0.034555
[epoch16, step607]: loss 0.038795
[epoch16, step608]: loss 0.037791
[epoch16, step609]: loss 0.037259
[epoch16, step610]: loss 0.039526
[epoch16, step611]: loss 0.039788
[epoch16, step612]: loss 0.034911
[epoch16, step613]: loss 0.030421
[epoch16, step614]: loss 0.036065
[epoch16, step615]: loss 0.041167
[epoch16, step616]: loss 0.033992
[epoch16, step617]: loss 0.033710
[epoch16, step618]: loss 0.037416
[epoch16, step619]: loss 0.039133
[epoch16, step620]: loss 0.035617
[epoch16, step621]: loss 0.037909
[epoch16, step622]: loss 0.031400
[epoch16, step623]: loss 0.033387
[epoch16, step624]: loss 0.037797
[epoch16, step625]: loss 0.035960
[epoch16, step626]: loss 0.038975
[epoch16, step627]: loss 0.033345
[epoch16, step628]: loss 0.035156
[epoch16, step629]: loss 0.030941
[epoch16, step630]: loss 0.032418
[epoch16, step631]: loss 0.042519
[epoch16, step632]: loss 0.035018
[epoch16, step633]: loss 0.034822
[epoch16, step634]: loss 0.037673
[epoch16, step635]: loss 0.036998
[epoch16, step636]: loss 0.032149
[epoch16, step637]: loss 0.038678
[epoch16, step638]: loss 0.038847
[epoch16, step639]: loss 0.032729
[epoch16, step640]: loss 0.040095
[epoch16, step641]: loss 0.040254
[epoch16, step642]: loss 0.035441
[epoch16, step643]: loss 0.035276
[epoch16, step644]: loss 0.036178
[epoch16, step645]: loss 0.034183
[epoch16, step646]: loss 0.035985
[epoch16, step647]: loss 0.034859
[epoch16, step648]: loss 0.034525
[epoch16, step649]: loss 0.037544
[epoch16, step650]: loss 0.032795
[epoch16, step651]: loss 0.037547
[epoch16, step652]: loss 0.038040
[epoch16, step653]: loss 0.038350
[epoch16, step654]: loss 0.033457
[epoch16, step655]: loss 0.035551
[epoch16, step656]: loss 0.033315
[epoch16, step657]: loss 0.038414
[epoch16, step658]: loss 0.035502
[epoch16, step659]: loss 0.037353
[epoch16, step660]: loss 0.033221
[epoch16, step661]: loss 0.036552
[epoch16, step662]: loss 0.034005
[epoch16, step663]: loss 0.032289
[epoch16, step664]: loss 0.036435
[epoch16, step665]: loss 0.037542
[epoch16, step666]: loss 0.037322
[epoch16, step667]: loss 0.037229
[epoch16, step668]: loss 0.033909
[epoch16, step669]: loss 0.038064
[epoch16, step670]: loss 0.037689
[epoch16, step671]: loss 0.032164
[epoch16, step672]: loss 0.035079
[epoch16, step673]: loss 0.032924
[epoch16, step674]: loss 0.031761
[epoch16, step675]: loss 0.030931
[epoch16, step676]: loss 0.033925
[epoch16, step677]: loss 0.035484
[epoch16, step678]: loss 0.033266
[epoch16, step679]: loss 0.035019
[epoch16, step680]: loss 0.040905
[epoch16, step681]: loss 0.032159
[epoch16, step682]: loss 0.036189
[epoch16, step683]: loss 0.035931
[epoch16, step684]: loss 0.035600
[epoch16, step685]: loss 0.034935
[epoch16, step686]: loss 0.039354
[epoch16, step687]: loss 0.036376
[epoch16, step688]: loss 0.035243
[epoch16, step689]: loss 0.036587
[epoch16, step690]: loss 0.036022
[epoch16, step691]: loss 0.035265
[epoch16, step692]: loss 0.034160
[epoch16, step693]: loss 0.038535
[epoch16, step694]: loss 0.032481
[epoch16, step695]: loss 0.037840
[epoch16, step696]: loss 0.035299
[epoch16, step697]: loss 0.037909
[epoch16, step698]: loss 0.035219
[epoch16, step699]: loss 0.034120
[epoch16, step700]: loss 0.031534
[epoch16, step701]: loss 0.036711
[epoch16, step702]: loss 0.031960
[epoch16, step703]: loss 0.034230
[epoch16, step704]: loss 0.036411
[epoch16, step705]: loss 0.036416
[epoch16, step706]: loss 0.034010
[epoch16, step707]: loss 0.033508
[epoch16, step708]: loss 0.034926
[epoch16, step709]: loss 0.037200
[epoch16, step710]: loss 0.033139
[epoch16, step711]: loss 0.036881
[epoch16, step712]: loss 0.037609
[epoch16, step713]: loss 0.038110
[epoch16, step714]: loss 0.032123
[epoch16, step715]: loss 0.033779
[epoch16, step716]: loss 0.035829
[epoch16, step717]: loss 0.033799
[epoch16, step718]: loss 0.035947
[epoch16, step719]: loss 0.045535
[epoch16, step720]: loss 0.034759
[epoch16, step721]: loss 0.033320
[epoch16, step722]: loss 0.041526
[epoch16, step723]: loss 0.038200
[epoch16, step724]: loss 0.032832
[epoch16, step725]: loss 0.037218
[epoch16, step726]: loss 0.032297
[epoch16, step727]: loss 0.034322
[epoch16, step728]: loss 0.037761
[epoch16, step729]: loss 0.032353
[epoch16, step730]: loss 0.033204
[epoch16, step731]: loss 0.036369
[epoch16, step732]: loss 0.036197
[epoch16, step733]: loss 0.034332
[epoch16, step734]: loss 0.034165
[epoch16, step735]: loss 0.038104
[epoch16, step736]: loss 0.036378
[epoch16, step737]: loss 0.037276
[epoch16, step738]: loss 0.030629
[epoch16, step739]: loss 0.036461
[epoch16, step740]: loss 0.033522
[epoch16, step741]: loss 0.036432
[epoch16, step742]: loss 0.033550
[epoch16, step743]: loss 0.034383
[epoch16, step744]: loss 0.033927
[epoch16, step745]: loss 0.034168
[epoch16, step746]: loss 0.036705
[epoch16, step747]: loss 0.039093
[epoch16, step748]: loss 0.036432
[epoch16, step749]: loss 0.036007
[epoch16, step750]: loss 0.038888
[epoch16, step751]: loss 0.033536
[epoch16, step752]: loss 0.035275
[epoch16, step753]: loss 0.035475
[epoch16, step754]: loss 0.034021
[epoch16, step755]: loss 0.036082
[epoch16, step756]: loss 0.033552
[epoch16, step757]: loss 0.030272
[epoch16, step758]: loss 0.034036
[epoch16, step759]: loss 0.033317
[epoch16, step760]: loss 0.034893
[epoch16, step761]: loss 0.037484
[epoch16, step762]: loss 0.031488
[epoch16, step763]: loss 0.035444
[epoch16, step764]: loss 0.034930
[epoch16, step765]: loss 0.036885
[epoch16, step766]: loss 0.036624
[epoch16, step767]: loss 0.038790
[epoch16, step768]: loss 0.031098
[epoch16, step769]: loss 0.036334
[epoch16, step770]: loss 0.035003
[epoch16, step771]: loss 0.033510
[epoch16, step772]: loss 0.038100
[epoch16, step773]: loss 0.035964
[epoch16, step774]: loss 0.035372
[epoch16, step775]: loss 0.029613
[epoch16, step776]: loss 0.038100
[epoch16, step777]: loss 0.033875
[epoch16, step778]: loss 0.037057
[epoch16, step779]: loss 0.035330
[epoch16, step780]: loss 0.029952
[epoch16, step781]: loss 0.035152
[epoch16, step782]: loss 0.032427
[epoch16, step783]: loss 0.030542
[epoch16, step784]: loss 0.031152
[epoch16, step785]: loss 0.031841
[epoch16, step786]: loss 0.034319
[epoch16, step787]: loss 0.034723
[epoch16, step788]: loss 0.036619
[epoch16, step789]: loss 0.034836
[epoch16, step790]: loss 0.034532
[epoch16, step791]: loss 0.037840
[epoch16, step792]: loss 0.035463
[epoch16, step793]: loss 0.037184
[epoch16, step794]: loss 0.030960
[epoch16, step795]: loss 0.035337
[epoch16, step796]: loss 0.038419
[epoch16, step797]: loss 0.037494
[epoch16, step798]: loss 0.037509
[epoch16, step799]: loss 0.037199
[epoch16, step800]: loss 0.031806
[epoch16, step801]: loss 0.034227
[epoch16, step802]: loss 0.033273
[epoch16, step803]: loss 0.037262
[epoch16, step804]: loss 0.037780
[epoch16, step805]: loss 0.038364
[epoch16, step806]: loss 0.032514
[epoch16, step807]: loss 0.031475
[epoch16, step808]: loss 0.033995
[epoch16, step809]: loss 0.032313
[epoch16, step810]: loss 0.036265
[epoch16, step811]: loss 0.035360
[epoch16, step812]: loss 0.033534
[epoch16, step813]: loss 0.033788
[epoch16, step814]: loss 0.036662
[epoch16, step815]: loss 0.034151
[epoch16, step816]: loss 0.034315
[epoch16, step817]: loss 0.035503
[epoch16, step818]: loss 0.032667
[epoch16, step819]: loss 0.031387
[epoch16, step820]: loss 0.034097
[epoch16, step821]: loss 0.031894
[epoch16, step822]: loss 0.039864
[epoch16, step823]: loss 0.033858
[epoch16, step824]: loss 0.036174
[epoch16, step825]: loss 0.036309
[epoch16, step826]: loss 0.035272
[epoch16, step827]: loss 0.037647
[epoch16, step828]: loss 0.039570
[epoch16, step829]: loss 0.038677
[epoch16, step830]: loss 0.033517
[epoch16, step831]: loss 0.037016
[epoch16, step832]: loss 0.031638
[epoch16, step833]: loss 0.038593
[epoch16, step834]: loss 0.037131
[epoch16, step835]: loss 0.031121
[epoch16, step836]: loss 0.039398
[epoch16, step837]: loss 0.036142
[epoch16, step838]: loss 0.034799
[epoch16, step839]: loss 0.039402
[epoch16, step840]: loss 0.031485
[epoch16, step841]: loss 0.035272
[epoch16, step842]: loss 0.037097
[epoch16, step843]: loss 0.035948
[epoch16, step844]: loss 0.035898
[epoch16, step845]: loss 0.031835
[epoch16, step846]: loss 0.038880
[epoch16, step847]: loss 0.036869
[epoch16, step848]: loss 0.035548
[epoch16, step849]: loss 0.033788
[epoch16, step850]: loss 0.033495
[epoch16, step851]: loss 0.035053
[epoch16, step852]: loss 0.032996
[epoch16, step853]: loss 0.040354
[epoch16, step854]: loss 0.034233
[epoch16, step855]: loss 0.037876
[epoch16, step856]: loss 0.031645
[epoch16, step857]: loss 0.034500
[epoch16, step858]: loss 0.034557
[epoch16, step859]: loss 0.034348
[epoch16, step860]: loss 0.032536
[epoch16, step861]: loss 0.032543
[epoch16, step862]: loss 0.032974
[epoch16, step863]: loss 0.031556
[epoch16, step864]: loss 0.037056
[epoch16, step865]: loss 0.034117
[epoch16, step866]: loss 0.035481
[epoch16, step867]: loss 0.036733
[epoch16, step868]: loss 0.036672
[epoch16, step869]: loss 0.034081
[epoch16, step870]: loss 0.041700
[epoch16, step871]: loss 0.033487
[epoch16, step872]: loss 0.035989
[epoch16, step873]: loss 0.035522
[epoch16, step874]: loss 0.034592
[epoch16, step875]: loss 0.034371
[epoch16, step876]: loss 0.036901
[epoch16, step877]: loss 0.030023
[epoch16, step878]: loss 0.033486
[epoch16, step879]: loss 0.037764
[epoch16, step880]: loss 0.036560
[epoch16, step881]: loss 0.032758
[epoch16, step882]: loss 0.033958
[epoch16, step883]: loss 0.033998
[epoch16, step884]: loss 0.036989
[epoch16, step885]: loss 0.035211
[epoch16, step886]: loss 0.035906
[epoch16, step887]: loss 0.034987
[epoch16, step888]: loss 0.035381
[epoch16, step889]: loss 0.034675
[epoch16, step890]: loss 0.033992
[epoch16, step891]: loss 0.035842
[epoch16, step892]: loss 0.030628
[epoch16, step893]: loss 0.034130
[epoch16, step894]: loss 0.035589
[epoch16, step895]: loss 0.032467
[epoch16, step896]: loss 0.032929
[epoch16, step897]: loss 0.035672
[epoch16, step898]: loss 0.036736
[epoch16, step899]: loss 0.039077
[epoch16, step900]: loss 0.036280
[epoch16, step901]: loss 0.036697
[epoch16, step902]: loss 0.034041
[epoch16, step903]: loss 0.035145
[epoch16, step904]: loss 0.037515
[epoch16, step905]: loss 0.037957
[epoch16, step906]: loss 0.031648
[epoch16, step907]: loss 0.033770
[epoch16, step908]: loss 0.031384
[epoch16, step909]: loss 0.037357
[epoch16, step910]: loss 0.033408
[epoch16, step911]: loss 0.035372
[epoch16, step912]: loss 0.033076
[epoch16, step913]: loss 0.034740
[epoch16, step914]: loss 0.039605
[epoch16, step915]: loss 0.033830
[epoch16, step916]: loss 0.033418
[epoch16, step917]: loss 0.035559
[epoch16, step918]: loss 0.039360
[epoch16, step919]: loss 0.035123
[epoch16, step920]: loss 0.037640
[epoch16, step921]: loss 0.034076
[epoch16, step922]: loss 0.034475
[epoch16, step923]: loss 0.033214
[epoch16, step924]: loss 0.030172
[epoch16, step925]: loss 0.035587
[epoch16, step926]: loss 0.034564
[epoch16, step927]: loss 0.035115
[epoch16, step928]: loss 0.034727
[epoch16, step929]: loss 0.037936
[epoch16, step930]: loss 0.035945
[epoch16, step931]: loss 0.037014
[epoch16, step932]: loss 0.031276
[epoch16, step933]: loss 0.038664
[epoch16, step934]: loss 0.032740
[epoch16, step935]: loss 0.034075
[epoch16, step936]: loss 0.032150
[epoch16, step937]: loss 0.036163
[epoch16, step938]: loss 0.038533
[epoch16, step939]: loss 0.031334
[epoch16, step940]: loss 0.033646
[epoch16, step941]: loss 0.038225
[epoch16, step942]: loss 0.036187
[epoch16, step943]: loss 0.033539
[epoch16, step944]: loss 0.037962
[epoch16, step945]: loss 0.031320
[epoch16, step946]: loss 0.035604
[epoch16, step947]: loss 0.038496
[epoch16, step948]: loss 0.030079
[epoch16, step949]: loss 0.033799
[epoch16, step950]: loss 0.038381
[epoch16, step951]: loss 0.039084
[epoch16, step952]: loss 0.034546
[epoch16, step953]: loss 0.037020
[epoch16, step954]: loss 0.033057
[epoch16, step955]: loss 0.041429
[epoch16, step956]: loss 0.050434
[epoch16, step957]: loss 0.046915
[epoch16, step958]: loss 0.045479
[epoch16, step959]: loss 0.048472
[epoch16, step960]: loss 0.045337
[epoch16, step961]: loss 0.046254
[epoch16, step962]: loss 0.044955
[epoch16, step963]: loss 0.043562
[epoch16, step964]: loss 0.043614
[epoch16, step965]: loss 0.045404
[epoch16, step966]: loss 0.043320
[epoch16, step967]: loss 0.042819
[epoch16, step968]: loss 0.044010
[epoch16, step969]: loss 0.044224
[epoch16, step970]: loss 0.042576
[epoch16, step971]: loss 0.042129
[epoch16, step972]: loss 0.042795
[epoch16, step973]: loss 0.042795
[epoch16, step974]: loss 0.043717
[epoch16, step975]: loss 0.042323
[epoch16, step976]: loss 0.040754
[epoch16, step977]: loss 0.042743
[epoch16, step978]: loss 0.042870
[epoch16, step979]: loss 0.041647
[epoch16, step980]: loss 0.041187
[epoch16, step981]: loss 0.042234
[epoch16, step982]: loss 0.041819
[epoch16, step983]: loss 0.043469
[epoch16, step984]: loss 0.041577
[epoch16, step985]: loss 0.041547
[epoch16, step986]: loss 0.043635
[epoch16, step987]: loss 0.042558
[epoch16, step988]: loss 0.042485
[epoch16, step989]: loss 0.041663
[epoch16, step990]: loss 0.042002
[epoch16, step991]: loss 0.041734
[epoch16, step992]: loss 0.042354
[epoch16, step993]: loss 0.041623
[epoch16, step994]: loss 0.040323
[epoch16, step995]: loss 0.042820
[epoch16, step996]: loss 0.041978
[epoch16, step997]: loss 0.041348
[epoch16, step998]: loss 0.042106
[epoch16, step999]: loss 0.041566
[epoch16, step1000]: loss 0.042031
[epoch16, step1001]: loss 0.042431
[epoch16, step1002]: loss 0.041418
[epoch16, step1003]: loss 0.040984
[epoch16, step1004]: loss 0.042579
[epoch16, step1005]: loss 0.041572
[epoch16, step1006]: loss 0.041842
[epoch16, step1007]: loss 0.040459
[epoch16, step1008]: loss 0.041469
[epoch16, step1009]: loss 0.041928
[epoch16, step1010]: loss 0.042389
[epoch16, step1011]: loss 0.040913
[epoch16, step1012]: loss 0.040296
[epoch16, step1013]: loss 0.042352
[epoch16, step1014]: loss 0.041988
[epoch16, step1015]: loss 0.041536
[epoch16, step1016]: loss 0.040526
[epoch16, step1017]: loss 0.040836
[epoch16, step1018]: loss 0.041727
[epoch16, step1019]: loss 0.042309
[epoch16, step1020]: loss 0.041112
[epoch16, step1021]: loss 0.040625
[epoch16, step1022]: loss 0.042154
[epoch16, step1023]: loss 0.041991
[epoch16, step1024]: loss 0.043073
[epoch16, step1025]: loss 0.040571
[epoch16, step1026]: loss 0.040913
[epoch16, step1027]: loss 0.041949
[epoch16, step1028]: loss 0.041581
[epoch16, step1029]: loss 0.040912
[epoch16, step1030]: loss 0.039900
[epoch16, step1031]: loss 0.041831
[epoch16, step1032]: loss 0.041433
[epoch16, step1033]: loss 0.041150
[epoch16, step1034]: loss 0.040109
[epoch16, step1035]: loss 0.040929
[epoch16, step1036]: loss 0.041894
[epoch16, step1037]: loss 0.041626
[epoch16, step1038]: loss 0.040834
[epoch16, step1039]: loss 0.040957
[epoch16, step1040]: loss 0.042171
[epoch16, step1041]: loss 0.041474
[epoch16, step1042]: loss 0.041302
[epoch16, step1043]: loss 0.040867
[epoch16, step1044]: loss 0.042017
[epoch16, step1045]: loss 0.041703
[epoch16, step1046]: loss 0.042200
[epoch16, step1047]: loss 0.041316
[epoch16, step1048]: loss 0.040282
[epoch16, step1049]: loss 0.043021
[epoch16, step1050]: loss 0.041947
[epoch16, step1051]: loss 0.041082
[epoch16, step1052]: loss 0.040669
[epoch16, step1053]: loss 0.041334
[epoch16, step1054]: loss 0.041485
[epoch16, step1055]: loss 0.041291
[epoch16, step1056]: loss 0.039875
[epoch16, step1057]: loss 0.040287
[epoch16, step1058]: loss 0.042452
[epoch16, step1059]: loss 0.041816
[epoch16, step1060]: loss 0.041221
[epoch16, step1061]: loss 0.039712
[epoch16, step1062]: loss 0.041682
[epoch16, step1063]: loss 0.042202
[epoch16, step1064]: loss 0.041842
[epoch16, step1065]: loss 0.040707
[epoch16, step1066]: loss 0.039788
[epoch16, step1067]: loss 0.042443
[epoch16, step1068]: loss 0.040659
[epoch16, step1069]: loss 0.040904
[epoch16, step1070]: loss 0.040274
[epoch16, step1071]: loss 0.041415
[epoch16, step1072]: loss 0.041502
[epoch16, step1073]: loss 0.041745
[epoch16, step1074]: loss 0.040331
[epoch16, step1075]: loss 0.040024
[epoch16, step1076]: loss 0.041962
[epoch16, step1077]: loss 0.041187
[epoch16, step1078]: loss 0.041567
[epoch16, step1079]: loss 0.040939
[epoch16, step1080]: loss 0.041059
[epoch16, step1081]: loss 0.041159
[epoch16, step1082]: loss 0.041209
[epoch16, step1083]: loss 0.040826
[epoch16, step1084]: loss 0.039802
[epoch16, step1085]: loss 0.041497
[epoch16, step1086]: loss 0.041303
[epoch16, step1087]: loss 0.041364
[epoch16, step1088]: loss 0.040822
[epoch16, step1089]: loss 0.041634
[epoch16, step1090]: loss 0.042029
[epoch16, step1091]: loss 0.042543
[epoch16, step1092]: loss 0.040910
[epoch16, step1093]: loss 0.040046
[epoch16, step1094]: loss 0.041721
[epoch16, step1095]: loss 0.040836
[epoch16, step1096]: loss 0.040391
[epoch16, step1097]: loss 0.041075
[epoch16, step1098]: loss 0.040697
[epoch16, step1099]: loss 0.041701
[epoch16, step1100]: loss 0.042740
[epoch16, step1101]: loss 0.041283
[epoch16, step1102]: loss 0.040634
[epoch16, step1103]: loss 0.042095
[epoch16, step1104]: loss 0.041084
[epoch16, step1105]: loss 0.041814
[epoch16, step1106]: loss 0.039976
[epoch16, step1107]: loss 0.040826
[epoch16, step1108]: loss 0.040450
[epoch16, step1109]: loss 0.041437
[epoch16, step1110]: loss 0.041518
[epoch16, step1111]: loss 0.040082
[epoch16, step1112]: loss 0.041895
[epoch16, step1113]: loss 0.040929
[epoch16, step1114]: loss 0.041004
[epoch16, step1115]: loss 0.040586
[epoch16, step1116]: loss 0.040875
[epoch16, step1117]: loss 0.041396
[epoch16, step1118]: loss 0.041997
[epoch16, step1119]: loss 0.040558
[epoch16, step1120]: loss 0.040113
[epoch16, step1121]: loss 0.041807
[epoch16, step1122]: loss 0.042178
[epoch16, step1123]: loss 0.040424
[epoch16, step1124]: loss 0.040998
[epoch16, step1125]: loss 0.041393
[epoch16, step1126]: loss 0.041953
[epoch16, step1127]: loss 0.041836
[epoch16, step1128]: loss 0.041185
[epoch16, step1129]: loss 0.039729
[epoch16, step1130]: loss 0.042174
[epoch16, step1131]: loss 0.041871
[epoch16, step1132]: loss 0.041030
[epoch16, step1133]: loss 0.040117
[epoch16, step1134]: loss 0.040929
[epoch16, step1135]: loss 0.042173
[epoch16, step1136]: loss 0.042855
[epoch16, step1137]: loss 0.040686
[epoch16, step1138]: loss 0.040030
[epoch16, step1139]: loss 0.042050
[epoch16, step1140]: loss 0.041112
[epoch16, step1141]: loss 0.040943
[epoch16, step1142]: loss 0.041509
[epoch16, step1143]: loss 0.041313
[epoch16, step1144]: loss 0.040993
[epoch16, step1145]: loss 0.042052
[epoch16, step1146]: loss 0.041219
[epoch16, step1147]: loss 0.040262
[epoch16, step1148]: loss 0.042821
[epoch16, step1149]: loss 0.041240
[epoch16, step1150]: loss 0.040669
[epoch16, step1151]: loss 0.040617
[epoch16, step1152]: loss 0.041483
[epoch16, step1153]: loss 0.040982
[epoch16, step1154]: loss 0.041575
[epoch16, step1155]: loss 0.040667
[epoch16, step1156]: loss 0.039664
[epoch16, step1157]: loss 0.042483
[epoch16, step1158]: loss 0.040983
[epoch16, step1159]: loss 0.040824
[epoch16, step1160]: loss 0.040797
[epoch16, step1161]: loss 0.041583
[epoch16, step1162]: loss 0.041023
[epoch16, step1163]: loss 0.040895
[epoch16, step1164]: loss 0.040372
[epoch16, step1165]: loss 0.040838
[epoch16, step1166]: loss 0.042003
[epoch16, step1167]: loss 0.041605
[epoch16, step1168]: loss 0.042032
[epoch16, step1169]: loss 0.040365
[epoch16, step1170]: loss 0.040161
[epoch16, step1171]: loss 0.041508
[epoch16, step1172]: loss 0.042310
[epoch16, step1173]: loss 0.040608
[epoch16, step1174]: loss 0.040296
[epoch16, step1175]: loss 0.041437
[epoch16, step1176]: loss 0.041023
[epoch16, step1177]: loss 0.040690
[epoch16, step1178]: loss 0.041320
[epoch16, step1179]: loss 0.041705
[epoch16, step1180]: loss 0.041317
[epoch16, step1181]: loss 0.043167
[epoch16, step1182]: loss 0.042032
[epoch16, step1183]: loss 0.040989
[epoch16, step1184]: loss 0.041603
[epoch16, step1185]: loss 0.041643
[epoch16, step1186]: loss 0.042270
[epoch16, step1187]: loss 0.040336
[epoch16, step1188]: loss 0.040985
[epoch16, step1189]: loss 0.042050
[epoch16, step1190]: loss 0.043414
[epoch16, step1191]: loss 0.042236
[epoch16, step1192]: loss 0.039596
[epoch16, step1193]: loss 0.042214
[epoch16, step1194]: loss 0.042457
[epoch16, step1195]: loss 0.040435
[epoch16, step1196]: loss 0.039390
[epoch16, step1197]: loss 0.041584
[epoch16, step1198]: loss 0.041232
[epoch16, step1199]: loss 0.040954
[epoch16, step1200]: loss 0.040994
[epoch16, step1201]: loss 0.040798
[epoch16, step1202]: loss 0.042615
[epoch16, step1203]: loss 0.041490
[epoch16, step1204]: loss 0.041544
[epoch16, step1205]: loss 0.040127
[epoch16, step1206]: loss 0.040204
[epoch16, step1207]: loss 0.041730
[epoch16, step1208]: loss 0.041426
[epoch16, step1209]: loss 0.039986
[epoch16, step1210]: loss 0.040020
[epoch16, step1211]: loss 0.041984
[epoch16, step1212]: loss 0.040943
[epoch16, step1213]: loss 0.040444
[epoch16, step1214]: loss 0.040178
[epoch16, step1215]: loss 0.041120
[epoch16, step1216]: loss 0.041572
[epoch16, step1217]: loss 0.041527
[epoch16, step1218]: loss 0.040129
[epoch16, step1219]: loss 0.040313
[epoch16, step1220]: loss 0.042169
[epoch16, step1221]: loss 0.040667
[epoch16, step1222]: loss 0.040730
[epoch16, step1223]: loss 0.040404
[epoch16, step1224]: loss 0.040974
[epoch16, step1225]: loss 0.041200
[epoch16, step1226]: loss 0.041996
[epoch16, step1227]: loss 0.040482
[epoch16, step1228]: loss 0.039616
[epoch16, step1229]: loss 0.041979
[epoch16, step1230]: loss 0.040749
[epoch16, step1231]: loss 0.040579
[epoch16, step1232]: loss 0.040506
[epoch16, step1233]: loss 0.040366
[epoch16, step1234]: loss 0.041276
[epoch16, step1235]: loss 0.042228
[epoch16, step1236]: loss 0.041177
[epoch16, step1237]: loss 0.040318
[epoch16, step1238]: loss 0.041203
[epoch16, step1239]: loss 0.041850
[epoch16, step1240]: loss 0.041776
[epoch16, step1241]: loss 0.040468
[epoch16, step1242]: loss 0.041641
[epoch16, step1243]: loss 0.041813
[epoch16, step1244]: loss 0.042366
[epoch16, step1245]: loss 0.041237
[epoch16, step1246]: loss 0.040157
[epoch16, step1247]: loss 0.041805
[epoch16, step1248]: loss 0.041304
[epoch16, step1249]: loss 0.041231
[epoch16, step1250]: loss 0.040222
[epoch16, step1251]: loss 0.040477
[epoch16, step1252]: loss 0.042346
[epoch16, step1253]: loss 0.042086
[epoch16, step1254]: loss 0.040671
[epoch16, step1255]: loss 0.040647
[epoch16, step1256]: loss 0.042063
[epoch16, step1257]: loss 0.040279
[epoch16, step1258]: loss 0.040774
[epoch16, step1259]: loss 0.040231
[epoch16, step1260]: loss 0.041349
[epoch16, step1261]: loss 0.040715
[epoch16, step1262]: loss 0.040676
[epoch16, step1263]: loss 0.040811
[epoch16, step1264]: loss 0.041286
[epoch16, step1265]: loss 0.041093
[epoch16, step1266]: loss 0.040537
[epoch16, step1267]: loss 0.040761
[epoch16, step1268]: loss 0.040559
[epoch16, step1269]: loss 0.041257
[epoch16, step1270]: loss 0.041372
[epoch16, step1271]: loss 0.041697
[epoch16, step1272]: loss 0.040392
[epoch16, step1273]: loss 0.039848
[epoch16, step1274]: loss 0.042020
[epoch16, step1275]: loss 0.041086
[epoch16, step1276]: loss 0.041086
[epoch16, step1277]: loss 0.040188
[epoch16, step1278]: loss 0.040853
[epoch16, step1279]: loss 0.040937
[epoch16, step1280]: loss 0.042065
[epoch16, step1281]: loss 0.040385
[epoch16, step1282]: loss 0.040244
[epoch16, step1283]: loss 0.041204
[epoch16, step1284]: loss 0.041416
[epoch16, step1285]: loss 0.040838
[epoch16, step1286]: loss 0.039957
[epoch16, step1287]: loss 0.041766
[epoch16, step1288]: loss 0.041479
[epoch16, step1289]: loss 0.042297
[epoch16, step1290]: loss 0.040574
[epoch16, step1291]: loss 0.039814
[epoch16, step1292]: loss 0.041719
[epoch16, step1293]: loss 0.040488
[epoch16, step1294]: loss 0.040942
[epoch16, step1295]: loss 0.040070
[epoch16, step1296]: loss 0.040874
[epoch16, step1297]: loss 0.041120
[epoch16, step1298]: loss 0.041948
[epoch16, step1299]: loss 0.041107
[epoch16, step1300]: loss 0.040657
[epoch16, step1301]: loss 0.041253
[epoch16, step1302]: loss 0.041221
[epoch16, step1303]: loss 0.040336
[epoch16, step1304]: loss 0.039230
[epoch16, step1305]: loss 0.040243
[epoch16, step1306]: loss 0.040444
[epoch16, step1307]: loss 0.041480
[epoch16, step1308]: loss 0.039755
[epoch16, step1309]: loss 0.041110
[epoch16, step1310]: loss 0.042858
[epoch16, step1311]: loss 0.040939
[epoch16, step1312]: loss 0.041033
[epoch16, step1313]: loss 0.039623
[epoch16, step1314]: loss 0.041073
[epoch16, step1315]: loss 0.041395
[epoch16, step1316]: loss 0.042501
[epoch16, step1317]: loss 0.039800
[epoch16, step1318]: loss 0.039438
[epoch16, step1319]: loss 0.041976
[epoch16, step1320]: loss 0.041212
[epoch16, step1321]: loss 0.040904
[epoch16, step1322]: loss 0.039808
[epoch16, step1323]: loss 0.041339
[epoch16, step1324]: loss 0.040902
[epoch16, step1325]: loss 0.040943
[epoch16, step1326]: loss 0.040052
[epoch16, step1327]: loss 0.039968
[epoch16, step1328]: loss 0.042810
[epoch16, step1329]: loss 0.041444
[epoch16, step1330]: loss 0.041023
[epoch16, step1331]: loss 0.040476
[epoch16, step1332]: loss 0.041188
[epoch16, step1333]: loss 0.041181
[epoch16, step1334]: loss 0.042114
[epoch16, step1335]: loss 0.041699
[epoch16, step1336]: loss 0.039949
[epoch16, step1337]: loss 0.041523
[epoch16, step1338]: loss 0.041076
[epoch16, step1339]: loss 0.040739
[epoch16, step1340]: loss 0.040111
[epoch16, step1341]: loss 0.041178
[epoch16, step1342]: loss 0.040925
[epoch16, step1343]: loss 0.041401
[epoch16, step1344]: loss 0.040649
[epoch16, step1345]: loss 0.039527
[epoch16, step1346]: loss 0.042127
[epoch16, step1347]: loss 0.041799
[epoch16, step1348]: loss 0.041666
[epoch16, step1349]: loss 0.040542
[epoch16, step1350]: loss 0.040501
[epoch16, step1351]: loss 0.040535
[epoch16, step1352]: loss 0.041507
[epoch16, step1353]: loss 0.040457
[epoch16, step1354]: loss 0.039581
[epoch16, step1355]: loss 0.041594
[epoch16, step1356]: loss 0.040251
[epoch16, step1357]: loss 0.040456
[epoch16, step1358]: loss 0.039860
[epoch16, step1359]: loss 0.040302
[epoch16, step1360]: loss 0.040718
[epoch16, step1361]: loss 0.041919
[epoch16, step1362]: loss 0.040646
[epoch16, step1363]: loss 0.039509
[epoch16, step1364]: loss 0.041338
[epoch16, step1365]: loss 0.040808
[epoch16, step1366]: loss 0.040453
[epoch16, step1367]: loss 0.040053
[epoch16, step1368]: loss 0.040843
[epoch16, step1369]: loss 0.041287
[epoch16, step1370]: loss 0.042103
[epoch16, step1371]: loss 0.040582
[epoch16, step1372]: loss 0.039530
[epoch16, step1373]: loss 0.041507
[epoch16, step1374]: loss 0.041353
[epoch16, step1375]: loss 0.041505
[epoch16, step1376]: loss 0.039965
[epoch16, step1377]: loss 0.040248
[epoch16, step1378]: loss 0.041743
[epoch16, step1379]: loss 0.041388
[epoch16, step1380]: loss 0.040666
[epoch16, step1381]: loss 0.039514
[epoch16, step1382]: loss 0.042108
[epoch16, step1383]: loss 0.039872
[epoch16, step1384]: loss 0.040467
[epoch16, step1385]: loss 0.040684
[epoch16, step1386]: loss 0.041618
[epoch16, step1387]: loss 0.042183
[epoch16, step1388]: loss 0.041566
[epoch16, step1389]: loss 0.039424
[epoch16, step1390]: loss 0.039816
[epoch16, step1391]: loss 0.041466
[epoch16, step1392]: loss 0.040771
[epoch16, step1393]: loss 0.039933
[epoch16, step1394]: loss 0.040992
[epoch16, step1395]: loss 0.040830
[epoch16, step1396]: loss 0.040725
[epoch16, step1397]: loss 0.040951
[epoch16, step1398]: loss 0.040082
[epoch16, step1399]: loss 0.040408
[epoch16, step1400]: loss 0.043272
[epoch16, step1401]: loss 0.040867
[epoch16, step1402]: loss 0.040284
[epoch16, step1403]: loss 0.039149
[epoch16, step1404]: loss 0.040155
[epoch16, step1405]: loss 0.040670
[epoch16, step1406]: loss 0.041154
[epoch16, step1407]: loss 0.040759
[epoch16, step1408]: loss 0.038581
[epoch16, step1409]: loss 0.041844
[epoch16, step1410]: loss 0.041387
[epoch16, step1411]: loss 0.040651
[epoch16, step1412]: loss 0.040501
[epoch16, step1413]: loss 0.040683
[epoch16, step1414]: loss 0.041213
[epoch16, step1415]: loss 0.041135
[epoch16, step1416]: loss 0.040460
[epoch16, step1417]: loss 0.039688
[epoch16, step1418]: loss 0.040848
[epoch16, step1419]: loss 0.041744
[epoch16, step1420]: loss 0.040895
[epoch16, step1421]: loss 0.040026
[epoch16, step1422]: loss 0.042957
[epoch16, step1423]: loss 0.042902
[epoch16, step1424]: loss 0.043377
[epoch16, step1425]: loss 0.041007
[epoch16, step1426]: loss 0.041034
[epoch16, step1427]: loss 0.042316
[epoch16, step1428]: loss 0.041166
[epoch16, step1429]: loss 0.041164
[epoch16, step1430]: loss 0.040174
[epoch16, step1431]: loss 0.040962
[epoch16, step1432]: loss 0.041900
[epoch16, step1433]: loss 0.042548
[epoch16, step1434]: loss 0.040350
[epoch16, step1435]: loss 0.040036
[epoch16, step1436]: loss 0.042614
[epoch16, step1437]: loss 0.040928
[epoch16, step1438]: loss 0.040847
[epoch16, step1439]: loss 0.039874
[epoch16, step1440]: loss 0.040300
[epoch16, step1441]: loss 0.042228
[epoch16, step1442]: loss 0.041695
[epoch16, step1443]: loss 0.040645
[epoch16, step1444]: loss 0.040137
[epoch16, step1445]: loss 0.043447
[epoch16, step1446]: loss 0.041012
[epoch16, step1447]: loss 0.041310
[epoch16, step1448]: loss 0.039721
[epoch16, step1449]: loss 0.040320
[epoch16, step1450]: loss 0.040553
[epoch16, step1451]: loss 0.041156
[epoch16, step1452]: loss 0.040592
[epoch16, step1453]: loss 0.040492
[epoch16, step1454]: loss 0.041450
[epoch16, step1455]: loss 0.041034
[epoch16, step1456]: loss 0.041430
[epoch16, step1457]: loss 0.039855
[epoch16, step1458]: loss 0.040580
[epoch16, step1459]: loss 0.040403
[epoch16, step1460]: loss 0.042282
[epoch16, step1461]: loss 0.040537
[epoch16, step1462]: loss 0.040034
[epoch16, step1463]: loss 0.041246
[epoch16, step1464]: loss 0.040387
[epoch16, step1465]: loss 0.040576
[epoch16, step1466]: loss 0.039641
[epoch16, step1467]: loss 0.041324
[epoch16, step1468]: loss 0.040137
[epoch16, step1469]: loss 0.041079
[epoch16, step1470]: loss 0.040059
[epoch16, step1471]: loss 0.039231
[epoch16, step1472]: loss 0.040651
[epoch16, step1473]: loss 0.040739
[epoch16, step1474]: loss 0.042663
[epoch16, step1475]: loss 0.039944
[epoch16, step1476]: loss 0.041556
[epoch16, step1477]: loss 0.041715
[epoch16, step1478]: loss 0.041378
[epoch16, step1479]: loss 0.040573
[epoch16, step1480]: loss 0.040093
[epoch16, step1481]: loss 0.041137
[epoch16, step1482]: loss 0.041256
[epoch16, step1483]: loss 0.041036
[epoch16, step1484]: loss 0.040302
[epoch16, step1485]: loss 0.040706
[epoch16, step1486]: loss 0.040003
[epoch16, step1487]: loss 0.041552
[epoch16, step1488]: loss 0.041650
[epoch16, step1489]: loss 0.040192
[epoch16, step1490]: loss 0.041401
[epoch16, step1491]: loss 0.041054
[epoch16, step1492]: loss 0.041325
[epoch16, step1493]: loss 0.040111
[epoch16, step1494]: loss 0.040900
[epoch16, step1495]: loss 0.041253
[epoch16, step1496]: loss 0.040923
[epoch16, step1497]: loss 0.041214
[epoch16, step1498]: loss 0.040232
[epoch16, step1499]: loss 0.043227
[epoch16, step1500]: loss 0.041824
[epoch16, step1501]: loss 0.041772
[epoch16, step1502]: loss 0.040833
[epoch16, step1503]: loss 0.041198
[epoch16, step1504]: loss 0.040750
[epoch16, step1505]: loss 0.042621
[epoch16, step1506]: loss 0.040279
[epoch16, step1507]: loss 0.040413
[epoch16, step1508]: loss 0.042330
[epoch16, step1509]: loss 0.041419
[epoch16, step1510]: loss 0.041622
[epoch16, step1511]: loss 0.040705
[epoch16, step1512]: loss 0.040938
[epoch16, step1513]: loss 0.040604
[epoch16, step1514]: loss 0.041866
[epoch16, step1515]: loss 0.040446
[epoch16, step1516]: loss 0.039971

[epoch16]: avg loss 0.037501

[epoch17, step1]: loss 0.037050
[epoch17, step2]: loss 0.038411
[epoch17, step3]: loss 0.037527
[epoch17, step4]: loss 0.034414
[epoch17, step5]: loss 0.034600
[epoch17, step6]: loss 0.038033
[epoch17, step7]: loss 0.035067
[epoch17, step8]: loss 0.037059
[epoch17, step9]: loss 0.033678
[epoch17, step10]: loss 0.035928
[epoch17, step11]: loss 0.037509
[epoch17, step12]: loss 0.036750
[epoch17, step13]: loss 0.034554
[epoch17, step14]: loss 0.034373
[epoch17, step15]: loss 0.036392
[epoch17, step16]: loss 0.034925
[epoch17, step17]: loss 0.036944
[epoch17, step18]: loss 0.034146
[epoch17, step19]: loss 0.033854
[epoch17, step20]: loss 0.037058
[epoch17, step21]: loss 0.035504
[epoch17, step22]: loss 0.033841
[epoch17, step23]: loss 0.033373
[epoch17, step24]: loss 0.036153
[epoch17, step25]: loss 0.033689
[epoch17, step26]: loss 0.036046
[epoch17, step27]: loss 0.033024
[epoch17, step28]: loss 0.034645
[epoch17, step29]: loss 0.036792
[epoch17, step30]: loss 0.036587
[epoch17, step31]: loss 0.033739
[epoch17, step32]: loss 0.034559
[epoch17, step33]: loss 0.036559
[epoch17, step34]: loss 0.034654
[epoch17, step35]: loss 0.037396
[epoch17, step36]: loss 0.033239
[epoch17, step37]: loss 0.034619
[epoch17, step38]: loss 0.037003
[epoch17, step39]: loss 0.036294
[epoch17, step40]: loss 0.034291
[epoch17, step41]: loss 0.033448
[epoch17, step42]: loss 0.036459
[epoch17, step43]: loss 0.034261
[epoch17, step44]: loss 0.037283
[epoch17, step45]: loss 0.034073
[epoch17, step46]: loss 0.034370
[epoch17, step47]: loss 0.035929
[epoch17, step48]: loss 0.036257
[epoch17, step49]: loss 0.032886
[epoch17, step50]: loss 0.033615
[epoch17, step51]: loss 0.036257
[epoch17, step52]: loss 0.033998
[epoch17, step53]: loss 0.036662
[epoch17, step54]: loss 0.033001
[epoch17, step55]: loss 0.034539
[epoch17, step56]: loss 0.037145
[epoch17, step57]: loss 0.036317
[epoch17, step58]: loss 0.033737
[epoch17, step59]: loss 0.032782
[epoch17, step60]: loss 0.036799
[epoch17, step61]: loss 0.033607
[epoch17, step62]: loss 0.035699
[epoch17, step63]: loss 0.033190
[epoch17, step64]: loss 0.033637
[epoch17, step65]: loss 0.036636
[epoch17, step66]: loss 0.036318
[epoch17, step67]: loss 0.033817
[epoch17, step68]: loss 0.033887
[epoch17, step69]: loss 0.035803
[epoch17, step70]: loss 0.034063
[epoch17, step71]: loss 0.036649
[epoch17, step72]: loss 0.033515
[epoch17, step73]: loss 0.034282
[epoch17, step74]: loss 0.035931
[epoch17, step75]: loss 0.036438
[epoch17, step76]: loss 0.034519
[epoch17, step77]: loss 0.034130
[epoch17, step78]: loss 0.036337
[epoch17, step79]: loss 0.033678
[epoch17, step80]: loss 0.036978
[epoch17, step81]: loss 0.033781
[epoch17, step82]: loss 0.034046
[epoch17, step83]: loss 0.036090
[epoch17, step84]: loss 0.036304
[epoch17, step85]: loss 0.034686
[epoch17, step86]: loss 0.034375
[epoch17, step87]: loss 0.037002
[epoch17, step88]: loss 0.033472
[epoch17, step89]: loss 0.036351
[epoch17, step90]: loss 0.034059
[epoch17, step91]: loss 0.033657
[epoch17, step92]: loss 0.036589
[epoch17, step93]: loss 0.036004
[epoch17, step94]: loss 0.033475
[epoch17, step95]: loss 0.034264
[epoch17, step96]: loss 0.035944
[epoch17, step97]: loss 0.034791
[epoch17, step98]: loss 0.036476
[epoch17, step99]: loss 0.033843
[epoch17, step100]: loss 0.033152
[epoch17, step101]: loss 0.037630
[epoch17, step102]: loss 0.035975
[epoch17, step103]: loss 0.034025
[epoch17, step104]: loss 0.033682
[epoch17, step105]: loss 0.036532
[epoch17, step106]: loss 0.034399
[epoch17, step107]: loss 0.036592
[epoch17, step108]: loss 0.034076
[epoch17, step109]: loss 0.033808
[epoch17, step110]: loss 0.036869
[epoch17, step111]: loss 0.036053
[epoch17, step112]: loss 0.034001
[epoch17, step113]: loss 0.034919
[epoch17, step114]: loss 0.036173
[epoch17, step115]: loss 0.033877
[epoch17, step116]: loss 0.037441
[epoch17, step117]: loss 0.033348
[epoch17, step118]: loss 0.035187
[epoch17, step119]: loss 0.037150
[epoch17, step120]: loss 0.036900
[epoch17, step121]: loss 0.034468
[epoch17, step122]: loss 0.034075
[epoch17, step123]: loss 0.036366
[epoch17, step124]: loss 0.034893
[epoch17, step125]: loss 0.036920
[epoch17, step126]: loss 0.033440
[epoch17, step127]: loss 0.033611
[epoch17, step128]: loss 0.036285
[epoch17, step129]: loss 0.036197
[epoch17, step130]: loss 0.034361
[epoch17, step131]: loss 0.033667
[epoch17, step132]: loss 0.036397
[epoch17, step133]: loss 0.034193
[epoch17, step134]: loss 0.035675
[epoch17, step135]: loss 0.034303
[epoch17, step136]: loss 0.035151
[epoch17, step137]: loss 0.036809
[epoch17, step138]: loss 0.036656
[epoch17, step139]: loss 0.034339
[epoch17, step140]: loss 0.034373
[epoch17, step141]: loss 0.036894
[epoch17, step142]: loss 0.034288
[epoch17, step143]: loss 0.036336
[epoch17, step144]: loss 0.033836
[epoch17, step145]: loss 0.034201
[epoch17, step146]: loss 0.036686
[epoch17, step147]: loss 0.037138
[epoch17, step148]: loss 0.033699
[epoch17, step149]: loss 0.033262
[epoch17, step150]: loss 0.036157
[epoch17, step151]: loss 0.034023
[epoch17, step152]: loss 0.035993
[epoch17, step153]: loss 0.033358
[epoch17, step154]: loss 0.033528
[epoch17, step155]: loss 0.036105
[epoch17, step156]: loss 0.035390
[epoch17, step157]: loss 0.033720
[epoch17, step158]: loss 0.034103
[epoch17, step159]: loss 0.035933
[epoch17, step160]: loss 0.034027
[epoch17, step161]: loss 0.036325
[epoch17, step162]: loss 0.033917
[epoch17, step163]: loss 0.034232
[epoch17, step164]: loss 0.036198
[epoch17, step165]: loss 0.035961
[epoch17, step166]: loss 0.034931
[epoch17, step167]: loss 0.033934
[epoch17, step168]: loss 0.037205
[epoch17, step169]: loss 0.033967
[epoch17, step170]: loss 0.037123
[epoch17, step171]: loss 0.034411
[epoch17, step172]: loss 0.034266
[epoch17, step173]: loss 0.036764
[epoch17, step174]: loss 0.035847
[epoch17, step175]: loss 0.035130
[epoch17, step176]: loss 0.033776
[epoch17, step177]: loss 0.036344
[epoch17, step178]: loss 0.034027
[epoch17, step179]: loss 0.035562
[epoch17, step180]: loss 0.033611
[epoch17, step181]: loss 0.033981
[epoch17, step182]: loss 0.036621
[epoch17, step183]: loss 0.036454
[epoch17, step184]: loss 0.034971
[epoch17, step185]: loss 0.033864
[epoch17, step186]: loss 0.036151
[epoch17, step187]: loss 0.034345
[epoch17, step188]: loss 0.036076
[epoch17, step189]: loss 0.033736
[epoch17, step190]: loss 0.033131
[epoch17, step191]: loss 0.036431
[epoch17, step192]: loss 0.036673
[epoch17, step193]: loss 0.032085
[epoch17, step194]: loss 0.033002
[epoch17, step195]: loss 0.036216
[epoch17, step196]: loss 0.034183
[epoch17, step197]: loss 0.036323
[epoch17, step198]: loss 0.033007
[epoch17, step199]: loss 0.034190
[epoch17, step200]: loss 0.036472
[epoch17, step201]: loss 0.036820
[epoch17, step202]: loss 0.033236
[epoch17, step203]: loss 0.033670
[epoch17, step204]: loss 0.036820
[epoch17, step205]: loss 0.033758
[epoch17, step206]: loss 0.036382
[epoch17, step207]: loss 0.033500
[epoch17, step208]: loss 0.034192
[epoch17, step209]: loss 0.036388
[epoch17, step210]: loss 0.036618
[epoch17, step211]: loss 0.034217
[epoch17, step212]: loss 0.033903
[epoch17, step213]: loss 0.036236
[epoch17, step214]: loss 0.033382
[epoch17, step215]: loss 0.036409
[epoch17, step216]: loss 0.033649
[epoch17, step217]: loss 0.033459
[epoch17, step218]: loss 0.036733
[epoch17, step219]: loss 0.035777
[epoch17, step220]: loss 0.034068
[epoch17, step221]: loss 0.033910
[epoch17, step222]: loss 0.036707
[epoch17, step223]: loss 0.034710
[epoch17, step224]: loss 0.035752
[epoch17, step225]: loss 0.033645
[epoch17, step226]: loss 0.033180
[epoch17, step227]: loss 0.035726
[epoch17, step228]: loss 0.037035
[epoch17, step229]: loss 0.032951
[epoch17, step230]: loss 0.034350
[epoch17, step231]: loss 0.037244
[epoch17, step232]: loss 0.033705
[epoch17, step233]: loss 0.036177
[epoch17, step234]: loss 0.032986
[epoch17, step235]: loss 0.034279
[epoch17, step236]: loss 0.036349
[epoch17, step237]: loss 0.035577
[epoch17, step238]: loss 0.034122
[epoch17, step239]: loss 0.033075
[epoch17, step240]: loss 0.035631
[epoch17, step241]: loss 0.034139
[epoch17, step242]: loss 0.036154
[epoch17, step243]: loss 0.034269
[epoch17, step244]: loss 0.033577
[epoch17, step245]: loss 0.035979
[epoch17, step246]: loss 0.036076
[epoch17, step247]: loss 0.033813
[epoch17, step248]: loss 0.033462
[epoch17, step249]: loss 0.035354
[epoch17, step250]: loss 0.034564
[epoch17, step251]: loss 0.036720
[epoch17, step252]: loss 0.034415
[epoch17, step253]: loss 0.033626
[epoch17, step254]: loss 0.036399
[epoch17, step255]: loss 0.035835
[epoch17, step256]: loss 0.034373
[epoch17, step257]: loss 0.034156
[epoch17, step258]: loss 0.036729
[epoch17, step259]: loss 0.034360
[epoch17, step260]: loss 0.035955
[epoch17, step261]: loss 0.034298
[epoch17, step262]: loss 0.034126
[epoch17, step263]: loss 0.035922
[epoch17, step264]: loss 0.035911
[epoch17, step265]: loss 0.034192
[epoch17, step266]: loss 0.033607
[epoch17, step267]: loss 0.036502
[epoch17, step268]: loss 0.033800
[epoch17, step269]: loss 0.036296
[epoch17, step270]: loss 0.033420
[epoch17, step271]: loss 0.033865
[epoch17, step272]: loss 0.036522
[epoch17, step273]: loss 0.035850
[epoch17, step274]: loss 0.034724
[epoch17, step275]: loss 0.033901
[epoch17, step276]: loss 0.036256
[epoch17, step277]: loss 0.034813
[epoch17, step278]: loss 0.037134
[epoch17, step279]: loss 0.033519
[epoch17, step280]: loss 0.034151
[epoch17, step281]: loss 0.036592
[epoch17, step282]: loss 0.036541
[epoch17, step283]: loss 0.033559
[epoch17, step284]: loss 0.033374
[epoch17, step285]: loss 0.036871
[epoch17, step286]: loss 0.033444
[epoch17, step287]: loss 0.036449
[epoch17, step288]: loss 0.033076
[epoch17, step289]: loss 0.034395
[epoch17, step290]: loss 0.036471
[epoch17, step291]: loss 0.036016
[epoch17, step292]: loss 0.033127
[epoch17, step293]: loss 0.033449
[epoch17, step294]: loss 0.035993
[epoch17, step295]: loss 0.033715
[epoch17, step296]: loss 0.036970
[epoch17, step297]: loss 0.033415
[epoch17, step298]: loss 0.033867
[epoch17, step299]: loss 0.035641
[epoch17, step300]: loss 0.036068
[epoch17, step301]: loss 0.034316
[epoch17, step302]: loss 0.034583
[epoch17, step303]: loss 0.036540
[epoch17, step304]: loss 0.034113
[epoch17, step305]: loss 0.036582
[epoch17, step306]: loss 0.034850
[epoch17, step307]: loss 0.033812
[epoch17, step308]: loss 0.037172
[epoch17, step309]: loss 0.036522
[epoch17, step310]: loss 0.033968
[epoch17, step311]: loss 0.034598
[epoch17, step312]: loss 0.035751
[epoch17, step313]: loss 0.034515
[epoch17, step314]: loss 0.036548
[epoch17, step315]: loss 0.034662
[epoch17, step316]: loss 0.033669
[epoch17, step317]: loss 0.037260
[epoch17, step318]: loss 0.036173
[epoch17, step319]: loss 0.033528
[epoch17, step320]: loss 0.033408
[epoch17, step321]: loss 0.036021
[epoch17, step322]: loss 0.034304
[epoch17, step323]: loss 0.036471
[epoch17, step324]: loss 0.034858
[epoch17, step325]: loss 0.033985
[epoch17, step326]: loss 0.036152
[epoch17, step327]: loss 0.035244
[epoch17, step328]: loss 0.034091
[epoch17, step329]: loss 0.033331
[epoch17, step330]: loss 0.035184
[epoch17, step331]: loss 0.034048
[epoch17, step332]: loss 0.035682
[epoch17, step333]: loss 0.033438
[epoch17, step334]: loss 0.033931
[epoch17, step335]: loss 0.036588
[epoch17, step336]: loss 0.036754
[epoch17, step337]: loss 0.034652
[epoch17, step338]: loss 0.033439
[epoch17, step339]: loss 0.036254
[epoch17, step340]: loss 0.034828
[epoch17, step341]: loss 0.035630
[epoch17, step342]: loss 0.033747
[epoch17, step343]: loss 0.034409
[epoch17, step344]: loss 0.035703
[epoch17, step345]: loss 0.035866
[epoch17, step346]: loss 0.033685
[epoch17, step347]: loss 0.033345
[epoch17, step348]: loss 0.036617
[epoch17, step349]: loss 0.034635
[epoch17, step350]: loss 0.035628
[epoch17, step351]: loss 0.032957
[epoch17, step352]: loss 0.033342
[epoch17, step353]: loss 0.036130
[epoch17, step354]: loss 0.035044
[epoch17, step355]: loss 0.032633
[epoch17, step356]: loss 0.034150
[epoch17, step357]: loss 0.036009
[epoch17, step358]: loss 0.032439
[epoch17, step359]: loss 0.038255
[epoch17, step360]: loss 0.032991
[epoch17, step361]: loss 0.033986
[epoch17, step362]: loss 0.036767
[epoch17, step363]: loss 0.035827
[epoch17, step364]: loss 0.034227
[epoch17, step365]: loss 0.033356
[epoch17, step366]: loss 0.036541
[epoch17, step367]: loss 0.034524
[epoch17, step368]: loss 0.035498
[epoch17, step369]: loss 0.033486
[epoch17, step370]: loss 0.034168
[epoch17, step371]: loss 0.036850
[epoch17, step372]: loss 0.035552
[epoch17, step373]: loss 0.033114
[epoch17, step374]: loss 0.033074
[epoch17, step375]: loss 0.036965
[epoch17, step376]: loss 0.033935
[epoch17, step377]: loss 0.036502
[epoch17, step378]: loss 0.033984
[epoch17, step379]: loss 0.034118
[epoch17, step380]: loss 0.036728
[epoch17, step381]: loss 0.035412
[epoch17, step382]: loss 0.034046
[epoch17, step383]: loss 0.032641
[epoch17, step384]: loss 0.035285
[epoch17, step385]: loss 0.033992
[epoch17, step386]: loss 0.036128
[epoch17, step387]: loss 0.034137
[epoch17, step388]: loss 0.035666
[epoch17, step389]: loss 0.036289
[epoch17, step390]: loss 0.037228
[epoch17, step391]: loss 0.033391
[epoch17, step392]: loss 0.034110
[epoch17, step393]: loss 0.036028
[epoch17, step394]: loss 0.033838
[epoch17, step395]: loss 0.036017
[epoch17, step396]: loss 0.033451
[epoch17, step397]: loss 0.033442
[epoch17, step398]: loss 0.036307
[epoch17, step399]: loss 0.035656
[epoch17, step400]: loss 0.033619
[epoch17, step401]: loss 0.033558
[epoch17, step402]: loss 0.036175
[epoch17, step403]: loss 0.034008
[epoch17, step404]: loss 0.036619
[epoch17, step405]: loss 0.034448
[epoch17, step406]: loss 0.034292
[epoch17, step407]: loss 0.036328
[epoch17, step408]: loss 0.036157
[epoch17, step409]: loss 0.035213
[epoch17, step410]: loss 0.034477
[epoch17, step411]: loss 0.035990
[epoch17, step412]: loss 0.033868
[epoch17, step413]: loss 0.036352
[epoch17, step414]: loss 0.033245
[epoch17, step415]: loss 0.034094
[epoch17, step416]: loss 0.035739
[epoch17, step417]: loss 0.035900
[epoch17, step418]: loss 0.034081
[epoch17, step419]: loss 0.032939
[epoch17, step420]: loss 0.036181
[epoch17, step421]: loss 0.033974
[epoch17, step422]: loss 0.036028
[epoch17, step423]: loss 0.033473
[epoch17, step424]: loss 0.033572
[epoch17, step425]: loss 0.036316
[epoch17, step426]: loss 0.036478
[epoch17, step427]: loss 0.034159
[epoch17, step428]: loss 0.033867
[epoch17, step429]: loss 0.036592
[epoch17, step430]: loss 0.034191
[epoch17, step431]: loss 0.036221
[epoch17, step432]: loss 0.033839
[epoch17, step433]: loss 0.035435
[epoch17, step434]: loss 0.035896
[epoch17, step435]: loss 0.036811
[epoch17, step436]: loss 0.034028
[epoch17, step437]: loss 0.033604
[epoch17, step438]: loss 0.037087
[epoch17, step439]: loss 0.034606
[epoch17, step440]: loss 0.036304
[epoch17, step441]: loss 0.033877
[epoch17, step442]: loss 0.033920
[epoch17, step443]: loss 0.036928
[epoch17, step444]: loss 0.035612
[epoch17, step445]: loss 0.034672
[epoch17, step446]: loss 0.034065
[epoch17, step447]: loss 0.036502
[epoch17, step448]: loss 0.034169
[epoch17, step449]: loss 0.036034
[epoch17, step450]: loss 0.033657
[epoch17, step451]: loss 0.034787
[epoch17, step452]: loss 0.036102
[epoch17, step453]: loss 0.036047
[epoch17, step454]: loss 0.033939
[epoch17, step455]: loss 0.033745
[epoch17, step456]: loss 0.035766
[epoch17, step457]: loss 0.034341
[epoch17, step458]: loss 0.035878
[epoch17, step459]: loss 0.034258
[epoch17, step460]: loss 0.034180
[epoch17, step461]: loss 0.036944
[epoch17, step462]: loss 0.035216
[epoch17, step463]: loss 0.033739
[epoch17, step464]: loss 0.033295
[epoch17, step465]: loss 0.037324
[epoch17, step466]: loss 0.033964
[epoch17, step467]: loss 0.035984
[epoch17, step468]: loss 0.033614
[epoch17, step469]: loss 0.033652
[epoch17, step470]: loss 0.036391
[epoch17, step471]: loss 0.035418
[epoch17, step472]: loss 0.034410
[epoch17, step473]: loss 0.033773
[epoch17, step474]: loss 0.035689
[epoch17, step475]: loss 0.034071
[epoch17, step476]: loss 0.036413
[epoch17, step477]: loss 0.033874
[epoch17, step478]: loss 0.033331
[epoch17, step479]: loss 0.035989
[epoch17, step480]: loss 0.035501
[epoch17, step481]: loss 0.033368
[epoch17, step482]: loss 0.033298
[epoch17, step483]: loss 0.036373
[epoch17, step484]: loss 0.034220
[epoch17, step485]: loss 0.036548
[epoch17, step486]: loss 0.033718
[epoch17, step487]: loss 0.033327
[epoch17, step488]: loss 0.036816
[epoch17, step489]: loss 0.035163
[epoch17, step490]: loss 0.034426
[epoch17, step491]: loss 0.033967
[epoch17, step492]: loss 0.035879
[epoch17, step493]: loss 0.034026
[epoch17, step494]: loss 0.035494
[epoch17, step495]: loss 0.034937
[epoch17, step496]: loss 0.034304
[epoch17, step497]: loss 0.036253
[epoch17, step498]: loss 0.036005
[epoch17, step499]: loss 0.033929
[epoch17, step500]: loss 0.033800
[epoch17, step501]: loss 0.035802
[epoch17, step502]: loss 0.033799
[epoch17, step503]: loss 0.036549
[epoch17, step504]: loss 0.033307
[epoch17, step505]: loss 0.032840
[epoch17, step506]: loss 0.036932
[epoch17, step507]: loss 0.037131
[epoch17, step508]: loss 0.034182
[epoch17, step509]: loss 0.033723
[epoch17, step510]: loss 0.036334
[epoch17, step511]: loss 0.034733
[epoch17, step512]: loss 0.037079
[epoch17, step513]: loss 0.033825
[epoch17, step514]: loss 0.034254
[epoch17, step515]: loss 0.036529
[epoch17, step516]: loss 0.036275
[epoch17, step517]: loss 0.033907
[epoch17, step518]: loss 0.033817
[epoch17, step519]: loss 0.036094
[epoch17, step520]: loss 0.033597
[epoch17, step521]: loss 0.036147
[epoch17, step522]: loss 0.033355
[epoch17, step523]: loss 0.033560
[epoch17, step524]: loss 0.035482
[epoch17, step525]: loss 0.036179
[epoch17, step526]: loss 0.033933
[epoch17, step527]: loss 0.033089
[epoch17, step528]: loss 0.036375
[epoch17, step529]: loss 0.034231
[epoch17, step530]: loss 0.036380
[epoch17, step531]: loss 0.033787
[epoch17, step532]: loss 0.034402
[epoch17, step533]: loss 0.037145
[epoch17, step534]: loss 0.036171
[epoch17, step535]: loss 0.034437
[epoch17, step536]: loss 0.033771
[epoch17, step537]: loss 0.036256
[epoch17, step538]: loss 0.034258
[epoch17, step539]: loss 0.035776
[epoch17, step540]: loss 0.033082
[epoch17, step541]: loss 0.033325
[epoch17, step542]: loss 0.036229
[epoch17, step543]: loss 0.035806
[epoch17, step544]: loss 0.033782
[epoch17, step545]: loss 0.032883
[epoch17, step546]: loss 0.036497
[epoch17, step547]: loss 0.033842
[epoch17, step548]: loss 0.036359
[epoch17, step549]: loss 0.034510
[epoch17, step550]: loss 0.034174
[epoch17, step551]: loss 0.035938
[epoch17, step552]: loss 0.035744
[epoch17, step553]: loss 0.034847
[epoch17, step554]: loss 0.033339
[epoch17, step555]: loss 0.035926
[epoch17, step556]: loss 0.033817
[epoch17, step557]: loss 0.035530
[epoch17, step558]: loss 0.033804
[epoch17, step559]: loss 0.033190
[epoch17, step560]: loss 0.036456
[epoch17, step561]: loss 0.035557
[epoch17, step562]: loss 0.033669
[epoch17, step563]: loss 0.036094
[epoch17, step564]: loss 0.041450
[epoch17, step565]: loss 0.040077
[epoch17, step566]: loss 0.047937
[epoch17, step567]: loss 0.040329
[epoch17, step568]: loss 0.040975
[epoch17, step569]: loss 0.036697
[epoch17, step570]: loss 0.043289
[epoch17, step571]: loss 0.041197
[epoch17, step572]: loss 0.038615
[epoch17, step573]: loss 0.038186
[epoch17, step574]: loss 0.041351
[epoch17, step575]: loss 0.034311
[epoch17, step576]: loss 0.040774
[epoch17, step577]: loss 0.037663
[epoch17, step578]: loss 0.030230
[epoch17, step579]: loss 0.039819
[epoch17, step580]: loss 0.031959
[epoch17, step581]: loss 0.036349
[epoch17, step582]: loss 0.037157
[epoch17, step583]: loss 0.037460
[epoch17, step584]: loss 0.036001
[epoch17, step585]: loss 0.038515
[epoch17, step586]: loss 0.035334
[epoch17, step587]: loss 0.042593
[epoch17, step588]: loss 0.035446
[epoch17, step589]: loss 0.035381
[epoch17, step590]: loss 0.039326
[epoch17, step591]: loss 0.033479
[epoch17, step592]: loss 0.038310
[epoch17, step593]: loss 0.032085
[epoch17, step594]: loss 0.038152
[epoch17, step595]: loss 0.038755
[epoch17, step596]: loss 0.038324
[epoch17, step597]: loss 0.036910
[epoch17, step598]: loss 0.038116
[epoch17, step599]: loss 0.036053
[epoch17, step600]: loss 0.038174
[epoch17, step601]: loss 0.031305
[epoch17, step602]: loss 0.033094
[epoch17, step603]: loss 0.036824
[epoch17, step604]: loss 0.038554
[epoch17, step605]: loss 0.036813
[epoch17, step606]: loss 0.034835
[epoch17, step607]: loss 0.038865
[epoch17, step608]: loss 0.038130
[epoch17, step609]: loss 0.036639
[epoch17, step610]: loss 0.040672
[epoch17, step611]: loss 0.039451
[epoch17, step612]: loss 0.035125
[epoch17, step613]: loss 0.029933
[epoch17, step614]: loss 0.035528
[epoch17, step615]: loss 0.040549
[epoch17, step616]: loss 0.034194
[epoch17, step617]: loss 0.033226
[epoch17, step618]: loss 0.037475
[epoch17, step619]: loss 0.039199
[epoch17, step620]: loss 0.035864
[epoch17, step621]: loss 0.037785
[epoch17, step622]: loss 0.031677
[epoch17, step623]: loss 0.033560
[epoch17, step624]: loss 0.038579
[epoch17, step625]: loss 0.036909
[epoch17, step626]: loss 0.039534
[epoch17, step627]: loss 0.033590
[epoch17, step628]: loss 0.035420
[epoch17, step629]: loss 0.031511
[epoch17, step630]: loss 0.032685
[epoch17, step631]: loss 0.042479
[epoch17, step632]: loss 0.034933
[epoch17, step633]: loss 0.034564
[epoch17, step634]: loss 0.036832
[epoch17, step635]: loss 0.037114
[epoch17, step636]: loss 0.032329
[epoch17, step637]: loss 0.038623
[epoch17, step638]: loss 0.039172
[epoch17, step639]: loss 0.032957
[epoch17, step640]: loss 0.040061
[epoch17, step641]: loss 0.040208
[epoch17, step642]: loss 0.035442
[epoch17, step643]: loss 0.035265
[epoch17, step644]: loss 0.036858
[epoch17, step645]: loss 0.034002
[epoch17, step646]: loss 0.036271
[epoch17, step647]: loss 0.034779
[epoch17, step648]: loss 0.034505
[epoch17, step649]: loss 0.037565
[epoch17, step650]: loss 0.032667
[epoch17, step651]: loss 0.037136
[epoch17, step652]: loss 0.037589
[epoch17, step653]: loss 0.038125
[epoch17, step654]: loss 0.033355
[epoch17, step655]: loss 0.035135
[epoch17, step656]: loss 0.033668
[epoch17, step657]: loss 0.038439
[epoch17, step658]: loss 0.035850
[epoch17, step659]: loss 0.037531
[epoch17, step660]: loss 0.033125
[epoch17, step661]: loss 0.036380
[epoch17, step662]: loss 0.034110
[epoch17, step663]: loss 0.032298
[epoch17, step664]: loss 0.036693
[epoch17, step665]: loss 0.037690
[epoch17, step666]: loss 0.037755
[epoch17, step667]: loss 0.037042
[epoch17, step668]: loss 0.033837
[epoch17, step669]: loss 0.037772
[epoch17, step670]: loss 0.037811
[epoch17, step671]: loss 0.032156
[epoch17, step672]: loss 0.035001
[epoch17, step673]: loss 0.033079
[epoch17, step674]: loss 0.031879
[epoch17, step675]: loss 0.031079
[epoch17, step676]: loss 0.034201
[epoch17, step677]: loss 0.035637
[epoch17, step678]: loss 0.033258
[epoch17, step679]: loss 0.035141
[epoch17, step680]: loss 0.041026
[epoch17, step681]: loss 0.032072
[epoch17, step682]: loss 0.036589
[epoch17, step683]: loss 0.035884
[epoch17, step684]: loss 0.035747
[epoch17, step685]: loss 0.034911
[epoch17, step686]: loss 0.039155
[epoch17, step687]: loss 0.036257
[epoch17, step688]: loss 0.035399
[epoch17, step689]: loss 0.036574
[epoch17, step690]: loss 0.036122
[epoch17, step691]: loss 0.035319
[epoch17, step692]: loss 0.033976
[epoch17, step693]: loss 0.038266
[epoch17, step694]: loss 0.032713
[epoch17, step695]: loss 0.038110
[epoch17, step696]: loss 0.035424
[epoch17, step697]: loss 0.037776
[epoch17, step698]: loss 0.034963
[epoch17, step699]: loss 0.034009
[epoch17, step700]: loss 0.031633
[epoch17, step701]: loss 0.036717
[epoch17, step702]: loss 0.031775
[epoch17, step703]: loss 0.034544
[epoch17, step704]: loss 0.036311
[epoch17, step705]: loss 0.036293
[epoch17, step706]: loss 0.033995
[epoch17, step707]: loss 0.034014
[epoch17, step708]: loss 0.034855
[epoch17, step709]: loss 0.037309
[epoch17, step710]: loss 0.032847
[epoch17, step711]: loss 0.036701
[epoch17, step712]: loss 0.037413
[epoch17, step713]: loss 0.037621
[epoch17, step714]: loss 0.032226
[epoch17, step715]: loss 0.033885
[epoch17, step716]: loss 0.035947
[epoch17, step717]: loss 0.033910
[epoch17, step718]: loss 0.035835
[epoch17, step719]: loss 0.044971
[epoch17, step720]: loss 0.034960
[epoch17, step721]: loss 0.033213
[epoch17, step722]: loss 0.041419
[epoch17, step723]: loss 0.038371
[epoch17, step724]: loss 0.033033
[epoch17, step725]: loss 0.037021
[epoch17, step726]: loss 0.032215
[epoch17, step727]: loss 0.034550
[epoch17, step728]: loss 0.037444
[epoch17, step729]: loss 0.032370
[epoch17, step730]: loss 0.032977
[epoch17, step731]: loss 0.036164
[epoch17, step732]: loss 0.036448
[epoch17, step733]: loss 0.034490
[epoch17, step734]: loss 0.034051
[epoch17, step735]: loss 0.038337
[epoch17, step736]: loss 0.036218
[epoch17, step737]: loss 0.037264
[epoch17, step738]: loss 0.030809
[epoch17, step739]: loss 0.036439
[epoch17, step740]: loss 0.033264
[epoch17, step741]: loss 0.036681
[epoch17, step742]: loss 0.033383
[epoch17, step743]: loss 0.034252
[epoch17, step744]: loss 0.033704
[epoch17, step745]: loss 0.034305
[epoch17, step746]: loss 0.036919
[epoch17, step747]: loss 0.039376
[epoch17, step748]: loss 0.036691
[epoch17, step749]: loss 0.036034
[epoch17, step750]: loss 0.038760
[epoch17, step751]: loss 0.033551
[epoch17, step752]: loss 0.035720
[epoch17, step753]: loss 0.035574
[epoch17, step754]: loss 0.034120
[epoch17, step755]: loss 0.035802
[epoch17, step756]: loss 0.033839
[epoch17, step757]: loss 0.030062
[epoch17, step758]: loss 0.034086
[epoch17, step759]: loss 0.032907
[epoch17, step760]: loss 0.034961
[epoch17, step761]: loss 0.037272
[epoch17, step762]: loss 0.031552
[epoch17, step763]: loss 0.035456
[epoch17, step764]: loss 0.034906
[epoch17, step765]: loss 0.036803
[epoch17, step766]: loss 0.036896
[epoch17, step767]: loss 0.039090
[epoch17, step768]: loss 0.031145
[epoch17, step769]: loss 0.035756
[epoch17, step770]: loss 0.034781
[epoch17, step771]: loss 0.033422
[epoch17, step772]: loss 0.038053
[epoch17, step773]: loss 0.036008
[epoch17, step774]: loss 0.035072
[epoch17, step775]: loss 0.029576
[epoch17, step776]: loss 0.037591
[epoch17, step777]: loss 0.033889
[epoch17, step778]: loss 0.037043
[epoch17, step779]: loss 0.035413
[epoch17, step780]: loss 0.029915
[epoch17, step781]: loss 0.035333
[epoch17, step782]: loss 0.032430
[epoch17, step783]: loss 0.030428
[epoch17, step784]: loss 0.031076
[epoch17, step785]: loss 0.031501
[epoch17, step786]: loss 0.034355
[epoch17, step787]: loss 0.034678
[epoch17, step788]: loss 0.036336
[epoch17, step789]: loss 0.034697
[epoch17, step790]: loss 0.034472
[epoch17, step791]: loss 0.037806
[epoch17, step792]: loss 0.035588
[epoch17, step793]: loss 0.037223
[epoch17, step794]: loss 0.030534
[epoch17, step795]: loss 0.035133
[epoch17, step796]: loss 0.038431
[epoch17, step797]: loss 0.036917
[epoch17, step798]: loss 0.037328
[epoch17, step799]: loss 0.037541
[epoch17, step800]: loss 0.031766
[epoch17, step801]: loss 0.034011
[epoch17, step802]: loss 0.033543
[epoch17, step803]: loss 0.037299
[epoch17, step804]: loss 0.037306
[epoch17, step805]: loss 0.038015
[epoch17, step806]: loss 0.032238
[epoch17, step807]: loss 0.031316
[epoch17, step808]: loss 0.034017
[epoch17, step809]: loss 0.032340
[epoch17, step810]: loss 0.036162
[epoch17, step811]: loss 0.035270
[epoch17, step812]: loss 0.033839
[epoch17, step813]: loss 0.033889
[epoch17, step814]: loss 0.036671
[epoch17, step815]: loss 0.033688
[epoch17, step816]: loss 0.034743
[epoch17, step817]: loss 0.035425
[epoch17, step818]: loss 0.032445
[epoch17, step819]: loss 0.031132
[epoch17, step820]: loss 0.034210
[epoch17, step821]: loss 0.032073
[epoch17, step822]: loss 0.039831
[epoch17, step823]: loss 0.034058
[epoch17, step824]: loss 0.036245
[epoch17, step825]: loss 0.036474
[epoch17, step826]: loss 0.035045
[epoch17, step827]: loss 0.037708
[epoch17, step828]: loss 0.039802
[epoch17, step829]: loss 0.038781
[epoch17, step830]: loss 0.033622
[epoch17, step831]: loss 0.036902
[epoch17, step832]: loss 0.031766
[epoch17, step833]: loss 0.038847
[epoch17, step834]: loss 0.036986
[epoch17, step835]: loss 0.031113
[epoch17, step836]: loss 0.039413
[epoch17, step837]: loss 0.036103
[epoch17, step838]: loss 0.034976
[epoch17, step839]: loss 0.038998
[epoch17, step840]: loss 0.031475
[epoch17, step841]: loss 0.035284
[epoch17, step842]: loss 0.037177
[epoch17, step843]: loss 0.035802
[epoch17, step844]: loss 0.035941
[epoch17, step845]: loss 0.031855
[epoch17, step846]: loss 0.038855
[epoch17, step847]: loss 0.036790
[epoch17, step848]: loss 0.035456
[epoch17, step849]: loss 0.033702
[epoch17, step850]: loss 0.033779
[epoch17, step851]: loss 0.035308
[epoch17, step852]: loss 0.033008
[epoch17, step853]: loss 0.040231
[epoch17, step854]: loss 0.034370
[epoch17, step855]: loss 0.038034
[epoch17, step856]: loss 0.031745
[epoch17, step857]: loss 0.034404
[epoch17, step858]: loss 0.034656
[epoch17, step859]: loss 0.034248
[epoch17, step860]: loss 0.032513
[epoch17, step861]: loss 0.032709
[epoch17, step862]: loss 0.033073
[epoch17, step863]: loss 0.031643
[epoch17, step864]: loss 0.036926
[epoch17, step865]: loss 0.033976
[epoch17, step866]: loss 0.035249
[epoch17, step867]: loss 0.036785
[epoch17, step868]: loss 0.036789
[epoch17, step869]: loss 0.034132
[epoch17, step870]: loss 0.041641
[epoch17, step871]: loss 0.033237
[epoch17, step872]: loss 0.035909
[epoch17, step873]: loss 0.035417
[epoch17, step874]: loss 0.034766
[epoch17, step875]: loss 0.034397
[epoch17, step876]: loss 0.037196
[epoch17, step877]: loss 0.030125
[epoch17, step878]: loss 0.033487
[epoch17, step879]: loss 0.037750
[epoch17, step880]: loss 0.036393
[epoch17, step881]: loss 0.032524
[epoch17, step882]: loss 0.034126
[epoch17, step883]: loss 0.033935
[epoch17, step884]: loss 0.037190
[epoch17, step885]: loss 0.035135
[epoch17, step886]: loss 0.035954
[epoch17, step887]: loss 0.034956
[epoch17, step888]: loss 0.035387
[epoch17, step889]: loss 0.034954
[epoch17, step890]: loss 0.034212
[epoch17, step891]: loss 0.036327
[epoch17, step892]: loss 0.030826
[epoch17, step893]: loss 0.034553
[epoch17, step894]: loss 0.035820
[epoch17, step895]: loss 0.032336
[epoch17, step896]: loss 0.032848
[epoch17, step897]: loss 0.035649
[epoch17, step898]: loss 0.037100
[epoch17, step899]: loss 0.038886
[epoch17, step900]: loss 0.036172
[epoch17, step901]: loss 0.036708
[epoch17, step902]: loss 0.034190
[epoch17, step903]: loss 0.035371
[epoch17, step904]: loss 0.037559
[epoch17, step905]: loss 0.037583
[epoch17, step906]: loss 0.031679
[epoch17, step907]: loss 0.033572
[epoch17, step908]: loss 0.031516
[epoch17, step909]: loss 0.037271
[epoch17, step910]: loss 0.033487
[epoch17, step911]: loss 0.035254
[epoch17, step912]: loss 0.033295
[epoch17, step913]: loss 0.034595
[epoch17, step914]: loss 0.039419
[epoch17, step915]: loss 0.033826
[epoch17, step916]: loss 0.033259
[epoch17, step917]: loss 0.035554
[epoch17, step918]: loss 0.039403
[epoch17, step919]: loss 0.035025
[epoch17, step920]: loss 0.037865
[epoch17, step921]: loss 0.034033
[epoch17, step922]: loss 0.034596
[epoch17, step923]: loss 0.033257
[epoch17, step924]: loss 0.030217
[epoch17, step925]: loss 0.035764
[epoch17, step926]: loss 0.034754
[epoch17, step927]: loss 0.035404
[epoch17, step928]: loss 0.035176
[epoch17, step929]: loss 0.038138
[epoch17, step930]: loss 0.035833
[epoch17, step931]: loss 0.037117
[epoch17, step932]: loss 0.031657
[epoch17, step933]: loss 0.039116
[epoch17, step934]: loss 0.032617
[epoch17, step935]: loss 0.033385
[epoch17, step936]: loss 0.032181
[epoch17, step937]: loss 0.036360
[epoch17, step938]: loss 0.038256
[epoch17, step939]: loss 0.031404
[epoch17, step940]: loss 0.033807
[epoch17, step941]: loss 0.038052
[epoch17, step942]: loss 0.036478
[epoch17, step943]: loss 0.033513
[epoch17, step944]: loss 0.038143
[epoch17, step945]: loss 0.031441
[epoch17, step946]: loss 0.035577
[epoch17, step947]: loss 0.039065
[epoch17, step948]: loss 0.029908
[epoch17, step949]: loss 0.033814
[epoch17, step950]: loss 0.037990
[epoch17, step951]: loss 0.039585
[epoch17, step952]: loss 0.034756
[epoch17, step953]: loss 0.037567
[epoch17, step954]: loss 0.033119
[epoch17, step955]: loss 0.041291
[epoch17, step956]: loss 0.050816
[epoch17, step957]: loss 0.047292
[epoch17, step958]: loss 0.044615
[epoch17, step959]: loss 0.046456
[epoch17, step960]: loss 0.043696
[epoch17, step961]: loss 0.044345
[epoch17, step962]: loss 0.043274
[epoch17, step963]: loss 0.043035
[epoch17, step964]: loss 0.043352
[epoch17, step965]: loss 0.042936
[epoch17, step966]: loss 0.042302
[epoch17, step967]: loss 0.041365
[epoch17, step968]: loss 0.043154
[epoch17, step969]: loss 0.043290
[epoch17, step970]: loss 0.042339
[epoch17, step971]: loss 0.041989
[epoch17, step972]: loss 0.042680
[epoch17, step973]: loss 0.042267
[epoch17, step974]: loss 0.044232
[epoch17, step975]: loss 0.041706
[epoch17, step976]: loss 0.040949
[epoch17, step977]: loss 0.042906
[epoch17, step978]: loss 0.042475
[epoch17, step979]: loss 0.041793
[epoch17, step980]: loss 0.040926
[epoch17, step981]: loss 0.041952
[epoch17, step982]: loss 0.041943
[epoch17, step983]: loss 0.042448
[epoch17, step984]: loss 0.041063
[epoch17, step985]: loss 0.040617
[epoch17, step986]: loss 0.042960
[epoch17, step987]: loss 0.041976
[epoch17, step988]: loss 0.042108
[epoch17, step989]: loss 0.040991
[epoch17, step990]: loss 0.041431
[epoch17, step991]: loss 0.041819
[epoch17, step992]: loss 0.041811
[epoch17, step993]: loss 0.040945
[epoch17, step994]: loss 0.039983
[epoch17, step995]: loss 0.042450
[epoch17, step996]: loss 0.041706
[epoch17, step997]: loss 0.041457
[epoch17, step998]: loss 0.041573
[epoch17, step999]: loss 0.041258
[epoch17, step1000]: loss 0.041641
[epoch17, step1001]: loss 0.042300
[epoch17, step1002]: loss 0.040971
[epoch17, step1003]: loss 0.040446
[epoch17, step1004]: loss 0.042484
[epoch17, step1005]: loss 0.041108
[epoch17, step1006]: loss 0.041325
[epoch17, step1007]: loss 0.040180
[epoch17, step1008]: loss 0.041202
[epoch17, step1009]: loss 0.041507
[epoch17, step1010]: loss 0.042106
[epoch17, step1011]: loss 0.040696
[epoch17, step1012]: loss 0.040160
[epoch17, step1013]: loss 0.042078
[epoch17, step1014]: loss 0.041700
[epoch17, step1015]: loss 0.041393
[epoch17, step1016]: loss 0.040411
[epoch17, step1017]: loss 0.041013
[epoch17, step1018]: loss 0.041324
[epoch17, step1019]: loss 0.042406
[epoch17, step1020]: loss 0.040620
[epoch17, step1021]: loss 0.040029
[epoch17, step1022]: loss 0.041959
[epoch17, step1023]: loss 0.041277
[epoch17, step1024]: loss 0.042166
[epoch17, step1025]: loss 0.039925
[epoch17, step1026]: loss 0.040761
[epoch17, step1027]: loss 0.041370
[epoch17, step1028]: loss 0.041456
[epoch17, step1029]: loss 0.040586
[epoch17, step1030]: loss 0.039571
[epoch17, step1031]: loss 0.041572
[epoch17, step1032]: loss 0.041143
[epoch17, step1033]: loss 0.041011
[epoch17, step1034]: loss 0.039966
[epoch17, step1035]: loss 0.040692
[epoch17, step1036]: loss 0.041443
[epoch17, step1037]: loss 0.041442
[epoch17, step1038]: loss 0.040473
[epoch17, step1039]: loss 0.040497
[epoch17, step1040]: loss 0.041804
[epoch17, step1041]: loss 0.041141
[epoch17, step1042]: loss 0.041331
[epoch17, step1043]: loss 0.040393
[epoch17, step1044]: loss 0.041467
[epoch17, step1045]: loss 0.041291
[epoch17, step1046]: loss 0.041821
[epoch17, step1047]: loss 0.040722
[epoch17, step1048]: loss 0.040079
[epoch17, step1049]: loss 0.042512
[epoch17, step1050]: loss 0.041026
[epoch17, step1051]: loss 0.040909
[epoch17, step1052]: loss 0.040225
[epoch17, step1053]: loss 0.041030
[epoch17, step1054]: loss 0.041468
[epoch17, step1055]: loss 0.041615
[epoch17, step1056]: loss 0.040413
[epoch17, step1057]: loss 0.040589
[epoch17, step1058]: loss 0.042656
[epoch17, step1059]: loss 0.041354
[epoch17, step1060]: loss 0.040642
[epoch17, step1061]: loss 0.039908
[epoch17, step1062]: loss 0.042461
[epoch17, step1063]: loss 0.042500
[epoch17, step1064]: loss 0.042183
[epoch17, step1065]: loss 0.041365
[epoch17, step1066]: loss 0.040550
[epoch17, step1067]: loss 0.042406
[epoch17, step1068]: loss 0.041007
[epoch17, step1069]: loss 0.041450
[epoch17, step1070]: loss 0.040528
[epoch17, step1071]: loss 0.041936
[epoch17, step1072]: loss 0.041844
[epoch17, step1073]: loss 0.042161
[epoch17, step1074]: loss 0.041175
[epoch17, step1075]: loss 0.040373
[epoch17, step1076]: loss 0.042522
[epoch17, step1077]: loss 0.041344
[epoch17, step1078]: loss 0.041886
[epoch17, step1079]: loss 0.040889
[epoch17, step1080]: loss 0.041442
[epoch17, step1081]: loss 0.040950
[epoch17, step1082]: loss 0.041338
[epoch17, step1083]: loss 0.040973
[epoch17, step1084]: loss 0.039915
[epoch17, step1085]: loss 0.041194
[epoch17, step1086]: loss 0.040683
[epoch17, step1087]: loss 0.040926
[epoch17, step1088]: loss 0.040273
[epoch17, step1089]: loss 0.040790
[epoch17, step1090]: loss 0.041475
[epoch17, step1091]: loss 0.042401
[epoch17, step1092]: loss 0.040351
[epoch17, step1093]: loss 0.040005
[epoch17, step1094]: loss 0.041952
[epoch17, step1095]: loss 0.040677
[epoch17, step1096]: loss 0.040523
[epoch17, step1097]: loss 0.040906
[epoch17, step1098]: loss 0.040430
[epoch17, step1099]: loss 0.041514
[epoch17, step1100]: loss 0.042233
[epoch17, step1101]: loss 0.040637
[epoch17, step1102]: loss 0.039618
[epoch17, step1103]: loss 0.041917
[epoch17, step1104]: loss 0.040698
[epoch17, step1105]: loss 0.041056
[epoch17, step1106]: loss 0.039710
[epoch17, step1107]: loss 0.040620
[epoch17, step1108]: loss 0.040491
[epoch17, step1109]: loss 0.041337
[epoch17, step1110]: loss 0.041023
[epoch17, step1111]: loss 0.039790
[epoch17, step1112]: loss 0.041718
[epoch17, step1113]: loss 0.040406
[epoch17, step1114]: loss 0.040622
[epoch17, step1115]: loss 0.039674
[epoch17, step1116]: loss 0.041544
[epoch17, step1117]: loss 0.041096
[epoch17, step1118]: loss 0.041623
[epoch17, step1119]: loss 0.040469
[epoch17, step1120]: loss 0.039729
[epoch17, step1121]: loss 0.041810
[epoch17, step1122]: loss 0.041965
[epoch17, step1123]: loss 0.040096
[epoch17, step1124]: loss 0.040953
[epoch17, step1125]: loss 0.041143
[epoch17, step1126]: loss 0.041946
[epoch17, step1127]: loss 0.041424
[epoch17, step1128]: loss 0.040813
[epoch17, step1129]: loss 0.039660
[epoch17, step1130]: loss 0.041963
[epoch17, step1131]: loss 0.042175
[epoch17, step1132]: loss 0.041474
[epoch17, step1133]: loss 0.039401
[epoch17, step1134]: loss 0.040869
[epoch17, step1135]: loss 0.042054
[epoch17, step1136]: loss 0.042627
[epoch17, step1137]: loss 0.040472
[epoch17, step1138]: loss 0.039576
[epoch17, step1139]: loss 0.042112
[epoch17, step1140]: loss 0.040696
[epoch17, step1141]: loss 0.040815
[epoch17, step1142]: loss 0.041010
[epoch17, step1143]: loss 0.040666
[epoch17, step1144]: loss 0.040829
[epoch17, step1145]: loss 0.041465
[epoch17, step1146]: loss 0.040692
[epoch17, step1147]: loss 0.039986
[epoch17, step1148]: loss 0.042453
[epoch17, step1149]: loss 0.042060
[epoch17, step1150]: loss 0.040460
[epoch17, step1151]: loss 0.040353
[epoch17, step1152]: loss 0.041403
[epoch17, step1153]: loss 0.041222
[epoch17, step1154]: loss 0.041689
[epoch17, step1155]: loss 0.041269
[epoch17, step1156]: loss 0.040017
[epoch17, step1157]: loss 0.041842
[epoch17, step1158]: loss 0.041243
[epoch17, step1159]: loss 0.041121
[epoch17, step1160]: loss 0.040689
[epoch17, step1161]: loss 0.041447
[epoch17, step1162]: loss 0.040949
[epoch17, step1163]: loss 0.041395
[epoch17, step1164]: loss 0.039932
[epoch17, step1165]: loss 0.040364
[epoch17, step1166]: loss 0.042167
[epoch17, step1167]: loss 0.041167
[epoch17, step1168]: loss 0.040344
[epoch17, step1169]: loss 0.039282
[epoch17, step1170]: loss 0.040031
[epoch17, step1171]: loss 0.041185
[epoch17, step1172]: loss 0.042407
[epoch17, step1173]: loss 0.040177
[epoch17, step1174]: loss 0.040366
[epoch17, step1175]: loss 0.041297
[epoch17, step1176]: loss 0.040727
[epoch17, step1177]: loss 0.041188
[epoch17, step1178]: loss 0.039966
[epoch17, step1179]: loss 0.039925
[epoch17, step1180]: loss 0.040531
[epoch17, step1181]: loss 0.042447
[epoch17, step1182]: loss 0.040261
[epoch17, step1183]: loss 0.039775
[epoch17, step1184]: loss 0.041244
[epoch17, step1185]: loss 0.040794
[epoch17, step1186]: loss 0.040833
[epoch17, step1187]: loss 0.039097
[epoch17, step1188]: loss 0.040146
[epoch17, step1189]: loss 0.040852
[epoch17, step1190]: loss 0.040839
[epoch17, step1191]: loss 0.040569
[epoch17, step1192]: loss 0.039402
[epoch17, step1193]: loss 0.041525
[epoch17, step1194]: loss 0.041302
[epoch17, step1195]: loss 0.040103
[epoch17, step1196]: loss 0.039090
[epoch17, step1197]: loss 0.040398
[epoch17, step1198]: loss 0.040152
[epoch17, step1199]: loss 0.040550
[epoch17, step1200]: loss 0.039727
[epoch17, step1201]: loss 0.039107
[epoch17, step1202]: loss 0.041616
[epoch17, step1203]: loss 0.040724
[epoch17, step1204]: loss 0.040469
[epoch17, step1205]: loss 0.039668
[epoch17, step1206]: loss 0.039819
[epoch17, step1207]: loss 0.040491
[epoch17, step1208]: loss 0.041374
[epoch17, step1209]: loss 0.039073
[epoch17, step1210]: loss 0.039691
[epoch17, step1211]: loss 0.041700
[epoch17, step1212]: loss 0.040646
[epoch17, step1213]: loss 0.040393
[epoch17, step1214]: loss 0.039650
[epoch17, step1215]: loss 0.040843
[epoch17, step1216]: loss 0.041325
[epoch17, step1217]: loss 0.041026
[epoch17, step1218]: loss 0.039599
[epoch17, step1219]: loss 0.039598
[epoch17, step1220]: loss 0.041467
[epoch17, step1221]: loss 0.039807
[epoch17, step1222]: loss 0.039944
[epoch17, step1223]: loss 0.039104
[epoch17, step1224]: loss 0.040009
[epoch17, step1225]: loss 0.040498
[epoch17, step1226]: loss 0.041290
[epoch17, step1227]: loss 0.039613
[epoch17, step1228]: loss 0.039045
[epoch17, step1229]: loss 0.041375
[epoch17, step1230]: loss 0.039812
[epoch17, step1231]: loss 0.039923
[epoch17, step1232]: loss 0.040923
[epoch17, step1233]: loss 0.040444
[epoch17, step1234]: loss 0.040007
[epoch17, step1235]: loss 0.040845
[epoch17, step1236]: loss 0.039575
[epoch17, step1237]: loss 0.038836
[epoch17, step1238]: loss 0.040084
[epoch17, step1239]: loss 0.039876
[epoch17, step1240]: loss 0.040055
[epoch17, step1241]: loss 0.038706
[epoch17, step1242]: loss 0.039696
[epoch17, step1243]: loss 0.040200
[epoch17, step1244]: loss 0.040246
[epoch17, step1245]: loss 0.039654
[epoch17, step1246]: loss 0.038602
[epoch17, step1247]: loss 0.040580
[epoch17, step1248]: loss 0.040182
[epoch17, step1249]: loss 0.039931
[epoch17, step1250]: loss 0.038729
[epoch17, step1251]: loss 0.039410
[epoch17, step1252]: loss 0.042017
[epoch17, step1253]: loss 0.040801
[epoch17, step1254]: loss 0.039013
[epoch17, step1255]: loss 0.039011
[epoch17, step1256]: loss 0.040724
[epoch17, step1257]: loss 0.039181
[epoch17, step1258]: loss 0.039338
[epoch17, step1259]: loss 0.038762
[epoch17, step1260]: loss 0.039804
[epoch17, step1261]: loss 0.039352
[epoch17, step1262]: loss 0.039990
[epoch17, step1263]: loss 0.038984
[epoch17, step1264]: loss 0.039890
[epoch17, step1265]: loss 0.040080
[epoch17, step1266]: loss 0.038950
[epoch17, step1267]: loss 0.039599
[epoch17, step1268]: loss 0.038391
[epoch17, step1269]: loss 0.039476
[epoch17, step1270]: loss 0.039454
[epoch17, step1271]: loss 0.040694
[epoch17, step1272]: loss 0.038503
[epoch17, step1273]: loss 0.038060
[epoch17, step1274]: loss 0.040640
[epoch17, step1275]: loss 0.039371
[epoch17, step1276]: loss 0.039202
[epoch17, step1277]: loss 0.038428
[epoch17, step1278]: loss 0.039330
[epoch17, step1279]: loss 0.039460
[epoch17, step1280]: loss 0.040243
[epoch17, step1281]: loss 0.038927
[epoch17, step1282]: loss 0.038762
[epoch17, step1283]: loss 0.039627
[epoch17, step1284]: loss 0.040400
[epoch17, step1285]: loss 0.041527
[epoch17, step1286]: loss 0.037927
[epoch17, step1287]: loss 0.039764
[epoch17, step1288]: loss 0.040187
[epoch17, step1289]: loss 0.040788
[epoch17, step1290]: loss 0.039950
[epoch17, step1291]: loss 0.038936
[epoch17, step1292]: loss 0.040093
[epoch17, step1293]: loss 0.038281
[epoch17, step1294]: loss 0.040215
[epoch17, step1295]: loss 0.040597
[epoch17, step1296]: loss 0.040884
[epoch17, step1297]: loss 0.040038
[epoch17, step1298]: loss 0.040040
[epoch17, step1299]: loss 0.040124
[epoch17, step1300]: loss 0.040166
[epoch17, step1301]: loss 0.041237
[epoch17, step1302]: loss 0.041086
[epoch17, step1303]: loss 0.040626
[epoch17, step1304]: loss 0.039199
[epoch17, step1305]: loss 0.039517
[epoch17, step1306]: loss 0.039339
[epoch17, step1307]: loss 0.040236
[epoch17, step1308]: loss 0.039307
[epoch17, step1309]: loss 0.037934
[epoch17, step1310]: loss 0.041204
[epoch17, step1311]: loss 0.038956
[epoch17, step1312]: loss 0.038790
[epoch17, step1313]: loss 0.037880
[epoch17, step1314]: loss 0.039287
[epoch17, step1315]: loss 0.039395
[epoch17, step1316]: loss 0.041604
[epoch17, step1317]: loss 0.037901
[epoch17, step1318]: loss 0.037526
[epoch17, step1319]: loss 0.039900
[epoch17, step1320]: loss 0.040142
[epoch17, step1321]: loss 0.040471
[epoch17, step1322]: loss 0.038172
[epoch17, step1323]: loss 0.039993
[epoch17, step1324]: loss 0.040490
[epoch17, step1325]: loss 0.040413
[epoch17, step1326]: loss 0.039630
[epoch17, step1327]: loss 0.039040
[epoch17, step1328]: loss 0.041738
[epoch17, step1329]: loss 0.039652
[epoch17, step1330]: loss 0.038794
[epoch17, step1331]: loss 0.038330
[epoch17, step1332]: loss 0.039349
[epoch17, step1333]: loss 0.039226
[epoch17, step1334]: loss 0.039969
[epoch17, step1335]: loss 0.038935
[epoch17, step1336]: loss 0.038209
[epoch17, step1337]: loss 0.040739
[epoch17, step1338]: loss 0.040179
[epoch17, step1339]: loss 0.039931
[epoch17, step1340]: loss 0.038972
[epoch17, step1341]: loss 0.040167
[epoch17, step1342]: loss 0.039773
[epoch17, step1343]: loss 0.040232
[epoch17, step1344]: loss 0.038630
[epoch17, step1345]: loss 0.037594
[epoch17, step1346]: loss 0.040154
[epoch17, step1347]: loss 0.040275
[epoch17, step1348]: loss 0.039942
[epoch17, step1349]: loss 0.038954
[epoch17, step1350]: loss 0.038964
[epoch17, step1351]: loss 0.038872
[epoch17, step1352]: loss 0.039885
[epoch17, step1353]: loss 0.038647
[epoch17, step1354]: loss 0.037997
[epoch17, step1355]: loss 0.040264
[epoch17, step1356]: loss 0.038744
[epoch17, step1357]: loss 0.038875
[epoch17, step1358]: loss 0.037833
[epoch17, step1359]: loss 0.038823
[epoch17, step1360]: loss 0.039306
[epoch17, step1361]: loss 0.040713
[epoch17, step1362]: loss 0.038262
[epoch17, step1363]: loss 0.037705
[epoch17, step1364]: loss 0.039918
[epoch17, step1365]: loss 0.039431
[epoch17, step1366]: loss 0.039520
[epoch17, step1367]: loss 0.038711
[epoch17, step1368]: loss 0.039221
[epoch17, step1369]: loss 0.039034
[epoch17, step1370]: loss 0.040272
[epoch17, step1371]: loss 0.038848
[epoch17, step1372]: loss 0.037141
[epoch17, step1373]: loss 0.039945
[epoch17, step1374]: loss 0.039187
[epoch17, step1375]: loss 0.039026
[epoch17, step1376]: loss 0.038148
[epoch17, step1377]: loss 0.039094
[epoch17, step1378]: loss 0.039873
[epoch17, step1379]: loss 0.039772
[epoch17, step1380]: loss 0.038972
[epoch17, step1381]: loss 0.037184
[epoch17, step1382]: loss 0.040449
[epoch17, step1383]: loss 0.038356
[epoch17, step1384]: loss 0.038632
[epoch17, step1385]: loss 0.038405
[epoch17, step1386]: loss 0.039785
[epoch17, step1387]: loss 0.039371
[epoch17, step1388]: loss 0.040094
[epoch17, step1389]: loss 0.038888
[epoch17, step1390]: loss 0.038488
[epoch17, step1391]: loss 0.039749
[epoch17, step1392]: loss 0.039516
[epoch17, step1393]: loss 0.039230
[epoch17, step1394]: loss 0.039465
[epoch17, step1395]: loss 0.038501
[epoch17, step1396]: loss 0.039611
[epoch17, step1397]: loss 0.039959
[epoch17, step1398]: loss 0.037965
[epoch17, step1399]: loss 0.038211
[epoch17, step1400]: loss 0.041468
[epoch17, step1401]: loss 0.038930
[epoch17, step1402]: loss 0.038093
[epoch17, step1403]: loss 0.037224
[epoch17, step1404]: loss 0.038642
[epoch17, step1405]: loss 0.039792
[epoch17, step1406]: loss 0.039980
[epoch17, step1407]: loss 0.040715
[epoch17, step1408]: loss 0.037301
[epoch17, step1409]: loss 0.040175
[epoch17, step1410]: loss 0.038760
[epoch17, step1411]: loss 0.039058
[epoch17, step1412]: loss 0.037374
[epoch17, step1413]: loss 0.038077
[epoch17, step1414]: loss 0.038427
[epoch17, step1415]: loss 0.039235
[epoch17, step1416]: loss 0.038859
[epoch17, step1417]: loss 0.037471
[epoch17, step1418]: loss 0.039702
[epoch17, step1419]: loss 0.039214
[epoch17, step1420]: loss 0.038652
[epoch17, step1421]: loss 0.037810
[epoch17, step1422]: loss 0.038164
[epoch17, step1423]: loss 0.039239
[epoch17, step1424]: loss 0.041271
[epoch17, step1425]: loss 0.038080
[epoch17, step1426]: loss 0.038188
[epoch17, step1427]: loss 0.040563
[epoch17, step1428]: loss 0.039411
[epoch17, step1429]: loss 0.039637
[epoch17, step1430]: loss 0.037667
[epoch17, step1431]: loss 0.038739
[epoch17, step1432]: loss 0.039004
[epoch17, step1433]: loss 0.039556
[epoch17, step1434]: loss 0.037587
[epoch17, step1435]: loss 0.037814
[epoch17, step1436]: loss 0.040816
[epoch17, step1437]: loss 0.038244
[epoch17, step1438]: loss 0.038304
[epoch17, step1439]: loss 0.037414
[epoch17, step1440]: loss 0.038249
[epoch17, step1441]: loss 0.040340
[epoch17, step1442]: loss 0.039224
[epoch17, step1443]: loss 0.038014
[epoch17, step1444]: loss 0.036826
[epoch17, step1445]: loss 0.040705
[epoch17, step1446]: loss 0.038559
[epoch17, step1447]: loss 0.038484
[epoch17, step1448]: loss 0.038972
[epoch17, step1449]: loss 0.040969
[epoch17, step1450]: loss 0.039957
[epoch17, step1451]: loss 0.039385
[epoch17, step1452]: loss 0.038567
[epoch17, step1453]: loss 0.038524
[epoch17, step1454]: loss 0.040039
[epoch17, step1455]: loss 0.039301
[epoch17, step1456]: loss 0.039274
[epoch17, step1457]: loss 0.037319
[epoch17, step1458]: loss 0.038058
[epoch17, step1459]: loss 0.039207
[epoch17, step1460]: loss 0.040357
[epoch17, step1461]: loss 0.037534
[epoch17, step1462]: loss 0.037917
[epoch17, step1463]: loss 0.040572
[epoch17, step1464]: loss 0.038198
[epoch17, step1465]: loss 0.038590
[epoch17, step1466]: loss 0.036712
[epoch17, step1467]: loss 0.039720
[epoch17, step1468]: loss 0.038618
[epoch17, step1469]: loss 0.038986
[epoch17, step1470]: loss 0.037414
[epoch17, step1471]: loss 0.037704
[epoch17, step1472]: loss 0.039324
[epoch17, step1473]: loss 0.038592
[epoch17, step1474]: loss 0.039539
[epoch17, step1475]: loss 0.036643
[epoch17, step1476]: loss 0.039375
[epoch17, step1477]: loss 0.038767
[epoch17, step1478]: loss 0.038769
[epoch17, step1479]: loss 0.037983
[epoch17, step1480]: loss 0.037284
[epoch17, step1481]: loss 0.039421
[epoch17, step1482]: loss 0.039328
[epoch17, step1483]: loss 0.038994
[epoch17, step1484]: loss 0.039053
[epoch17, step1485]: loss 0.039225
[epoch17, step1486]: loss 0.038413
[epoch17, step1487]: loss 0.039411
[epoch17, step1488]: loss 0.038318
[epoch17, step1489]: loss 0.037457
[epoch17, step1490]: loss 0.040106
[epoch17, step1491]: loss 0.038675
[epoch17, step1492]: loss 0.038524
[epoch17, step1493]: loss 0.037978
[epoch17, step1494]: loss 0.038412
[epoch17, step1495]: loss 0.038384
[epoch17, step1496]: loss 0.039443
[epoch17, step1497]: loss 0.038469
[epoch17, step1498]: loss 0.037171
[epoch17, step1499]: loss 0.040989
[epoch17, step1500]: loss 0.038424
[epoch17, step1501]: loss 0.038221
[epoch17, step1502]: loss 0.037154
[epoch17, step1503]: loss 0.038466
[epoch17, step1504]: loss 0.038416
[epoch17, step1505]: loss 0.040314
[epoch17, step1506]: loss 0.037179
[epoch17, step1507]: loss 0.037689
[epoch17, step1508]: loss 0.040493
[epoch17, step1509]: loss 0.038891
[epoch17, step1510]: loss 0.039210
[epoch17, step1511]: loss 0.037705
[epoch17, step1512]: loss 0.038161
[epoch17, step1513]: loss 0.039571
[epoch17, step1514]: loss 0.039386
[epoch17, step1515]: loss 0.038358
[epoch17, step1516]: loss 0.037599

[epoch17]: avg loss 0.037065

[epoch18, step1]: loss 0.043325
[epoch18, step2]: loss 0.044279
[epoch18, step3]: loss 0.041849
[epoch18, step4]: loss 0.047333
[epoch18, step5]: loss 0.043077
[epoch18, step6]: loss 0.040373
[epoch18, step7]: loss 0.034943
[epoch18, step8]: loss 0.038865
[epoch18, step9]: loss 0.037470
[epoch18, step10]: loss 0.038083
[epoch18, step11]: loss 0.041334
[epoch18, step12]: loss 0.038274
[epoch18, step13]: loss 0.036105
[epoch18, step14]: loss 0.036081
[epoch18, step15]: loss 0.038496
[epoch18, step16]: loss 0.036399
[epoch18, step17]: loss 0.038506
[epoch18, step18]: loss 0.036153
[epoch18, step19]: loss 0.036011
[epoch18, step20]: loss 0.040000
[epoch18, step21]: loss 0.037193
[epoch18, step22]: loss 0.035003
[epoch18, step23]: loss 0.034579
[epoch18, step24]: loss 0.037341
[epoch18, step25]: loss 0.034894
[epoch18, step26]: loss 0.037294
[epoch18, step27]: loss 0.033834
[epoch18, step28]: loss 0.036252
[epoch18, step29]: loss 0.037351
[epoch18, step30]: loss 0.037553
[epoch18, step31]: loss 0.034235
[epoch18, step32]: loss 0.035055
[epoch18, step33]: loss 0.037237
[epoch18, step34]: loss 0.035259
[epoch18, step35]: loss 0.037326
[epoch18, step36]: loss 0.033360
[epoch18, step37]: loss 0.035411
[epoch18, step38]: loss 0.037169
[epoch18, step39]: loss 0.036421
[epoch18, step40]: loss 0.034455
[epoch18, step41]: loss 0.033856
[epoch18, step42]: loss 0.036683
[epoch18, step43]: loss 0.034248
[epoch18, step44]: loss 0.037333
[epoch18, step45]: loss 0.034095
[epoch18, step46]: loss 0.034610
[epoch18, step47]: loss 0.036319
[epoch18, step48]: loss 0.036555
[epoch18, step49]: loss 0.032505
[epoch18, step50]: loss 0.033845
[epoch18, step51]: loss 0.036319
[epoch18, step52]: loss 0.034557
[epoch18, step53]: loss 0.037085
[epoch18, step54]: loss 0.032990
[epoch18, step55]: loss 0.035142
[epoch18, step56]: loss 0.037472
[epoch18, step57]: loss 0.036761
[epoch18, step58]: loss 0.034030
[epoch18, step59]: loss 0.032743
[epoch18, step60]: loss 0.037410
[epoch18, step61]: loss 0.033533
[epoch18, step62]: loss 0.035861
[epoch18, step63]: loss 0.032792
[epoch18, step64]: loss 0.033572
[epoch18, step65]: loss 0.036773
[epoch18, step66]: loss 0.036469
[epoch18, step67]: loss 0.034116
[epoch18, step68]: loss 0.033712
[epoch18, step69]: loss 0.035874
[epoch18, step70]: loss 0.034360
[epoch18, step71]: loss 0.036865
[epoch18, step72]: loss 0.033600
[epoch18, step73]: loss 0.034312
[epoch18, step74]: loss 0.035528
[epoch18, step75]: loss 0.036718
[epoch18, step76]: loss 0.034510
[epoch18, step77]: loss 0.034209
[epoch18, step78]: loss 0.036546
[epoch18, step79]: loss 0.033842
[epoch18, step80]: loss 0.037587
[epoch18, step81]: loss 0.033562
[epoch18, step82]: loss 0.034291
[epoch18, step83]: loss 0.036157
[epoch18, step84]: loss 0.036159
[epoch18, step85]: loss 0.034791
[epoch18, step86]: loss 0.034237
[epoch18, step87]: loss 0.037001
[epoch18, step88]: loss 0.033556
[epoch18, step89]: loss 0.036005
[epoch18, step90]: loss 0.033965
[epoch18, step91]: loss 0.033267
[epoch18, step92]: loss 0.036760
[epoch18, step93]: loss 0.035992
[epoch18, step94]: loss 0.033340
[epoch18, step95]: loss 0.033968
[epoch18, step96]: loss 0.035897
[epoch18, step97]: loss 0.034671
[epoch18, step98]: loss 0.036726
[epoch18, step99]: loss 0.033826
[epoch18, step100]: loss 0.032890
[epoch18, step101]: loss 0.038187
[epoch18, step102]: loss 0.036288
[epoch18, step103]: loss 0.034011
[epoch18, step104]: loss 0.034183
[epoch18, step105]: loss 0.037314
[epoch18, step106]: loss 0.034371
[epoch18, step107]: loss 0.036586
[epoch18, step108]: loss 0.034477
[epoch18, step109]: loss 0.033488
[epoch18, step110]: loss 0.037042
[epoch18, step111]: loss 0.035741
[epoch18, step112]: loss 0.033848
[epoch18, step113]: loss 0.034616
[epoch18, step114]: loss 0.036107
[epoch18, step115]: loss 0.033821
[epoch18, step116]: loss 0.037305
[epoch18, step117]: loss 0.033216
[epoch18, step118]: loss 0.034581
[epoch18, step119]: loss 0.036854
[epoch18, step120]: loss 0.036448
[epoch18, step121]: loss 0.034123
[epoch18, step122]: loss 0.034077
[epoch18, step123]: loss 0.036547
[epoch18, step124]: loss 0.035034
[epoch18, step125]: loss 0.037563
[epoch18, step126]: loss 0.033349
[epoch18, step127]: loss 0.033902
[epoch18, step128]: loss 0.036897
[epoch18, step129]: loss 0.035661
[epoch18, step130]: loss 0.034449
[epoch18, step131]: loss 0.033887
[epoch18, step132]: loss 0.036394
[epoch18, step133]: loss 0.034402
[epoch18, step134]: loss 0.035796
[epoch18, step135]: loss 0.033958
[epoch18, step136]: loss 0.034790
[epoch18, step137]: loss 0.036257
[epoch18, step138]: loss 0.036431
[epoch18, step139]: loss 0.033777
[epoch18, step140]: loss 0.034072
[epoch18, step141]: loss 0.036719
[epoch18, step142]: loss 0.034039
[epoch18, step143]: loss 0.035758
[epoch18, step144]: loss 0.033602
[epoch18, step145]: loss 0.033879
[epoch18, step146]: loss 0.036978
[epoch18, step147]: loss 0.036975
[epoch18, step148]: loss 0.033642
[epoch18, step149]: loss 0.033115
[epoch18, step150]: loss 0.035988
[epoch18, step151]: loss 0.033883
[epoch18, step152]: loss 0.035670
[epoch18, step153]: loss 0.033614
[epoch18, step154]: loss 0.033198
[epoch18, step155]: loss 0.036588
[epoch18, step156]: loss 0.036122
[epoch18, step157]: loss 0.033770
[epoch18, step158]: loss 0.034898
[epoch18, step159]: loss 0.037080
[epoch18, step160]: loss 0.034357
[epoch18, step161]: loss 0.036660
[epoch18, step162]: loss 0.034664
[epoch18, step163]: loss 0.034459
[epoch18, step164]: loss 0.036334
[epoch18, step165]: loss 0.035868
[epoch18, step166]: loss 0.034675
[epoch18, step167]: loss 0.033391
[epoch18, step168]: loss 0.037180
[epoch18, step169]: loss 0.033719
[epoch18, step170]: loss 0.036279
[epoch18, step171]: loss 0.034113
[epoch18, step172]: loss 0.034208
[epoch18, step173]: loss 0.036675
[epoch18, step174]: loss 0.035866
[epoch18, step175]: loss 0.034751
[epoch18, step176]: loss 0.033822
[epoch18, step177]: loss 0.036480
[epoch18, step178]: loss 0.034038
[epoch18, step179]: loss 0.035526
[epoch18, step180]: loss 0.033617
[epoch18, step181]: loss 0.033850
[epoch18, step182]: loss 0.036769
[epoch18, step183]: loss 0.036321
[epoch18, step184]: loss 0.035106
[epoch18, step185]: loss 0.033923
[epoch18, step186]: loss 0.036153
[epoch18, step187]: loss 0.034345
[epoch18, step188]: loss 0.036213
[epoch18, step189]: loss 0.033563
[epoch18, step190]: loss 0.033247
[epoch18, step191]: loss 0.036192
[epoch18, step192]: loss 0.036931
[epoch18, step193]: loss 0.032482
[epoch18, step194]: loss 0.032821
[epoch18, step195]: loss 0.036636
[epoch18, step196]: loss 0.034490
[epoch18, step197]: loss 0.036022
[epoch18, step198]: loss 0.032819
[epoch18, step199]: loss 0.033887
[epoch18, step200]: loss 0.036526
[epoch18, step201]: loss 0.036167
[epoch18, step202]: loss 0.033124
[epoch18, step203]: loss 0.033443
[epoch18, step204]: loss 0.036710
[epoch18, step205]: loss 0.033596
[epoch18, step206]: loss 0.036024
[epoch18, step207]: loss 0.033469
[epoch18, step208]: loss 0.033903
[epoch18, step209]: loss 0.036680
[epoch18, step210]: loss 0.036455
[epoch18, step211]: loss 0.034374
[epoch18, step212]: loss 0.034265
[epoch18, step213]: loss 0.036119
[epoch18, step214]: loss 0.033515
[epoch18, step215]: loss 0.036288
[epoch18, step216]: loss 0.033874
[epoch18, step217]: loss 0.033360
[epoch18, step218]: loss 0.036696
[epoch18, step219]: loss 0.035986
[epoch18, step220]: loss 0.033933
[epoch18, step221]: loss 0.034057
[epoch18, step222]: loss 0.036506
[epoch18, step223]: loss 0.034839
[epoch18, step224]: loss 0.036101
[epoch18, step225]: loss 0.033285
[epoch18, step226]: loss 0.033525
[epoch18, step227]: loss 0.035209
[epoch18, step228]: loss 0.036642
[epoch18, step229]: loss 0.032924
[epoch18, step230]: loss 0.034067
[epoch18, step231]: loss 0.036919
[epoch18, step232]: loss 0.033529
[epoch18, step233]: loss 0.035824
[epoch18, step234]: loss 0.033044
[epoch18, step235]: loss 0.034369
[epoch18, step236]: loss 0.036040
[epoch18, step237]: loss 0.035767
[epoch18, step238]: loss 0.033901
[epoch18, step239]: loss 0.033232
[epoch18, step240]: loss 0.035477
[epoch18, step241]: loss 0.034375
[epoch18, step242]: loss 0.036449
[epoch18, step243]: loss 0.034128
[epoch18, step244]: loss 0.033814
[epoch18, step245]: loss 0.035734
[epoch18, step246]: loss 0.035839
[epoch18, step247]: loss 0.033895
[epoch18, step248]: loss 0.033352
[epoch18, step249]: loss 0.035289
[epoch18, step250]: loss 0.034201
[epoch18, step251]: loss 0.036125
[epoch18, step252]: loss 0.034626
[epoch18, step253]: loss 0.033254
[epoch18, step254]: loss 0.036211
[epoch18, step255]: loss 0.036390
[epoch18, step256]: loss 0.033760
[epoch18, step257]: loss 0.034334
[epoch18, step258]: loss 0.038028
[epoch18, step259]: loss 0.034666
[epoch18, step260]: loss 0.036153
[epoch18, step261]: loss 0.034571
[epoch18, step262]: loss 0.034015
[epoch18, step263]: loss 0.035705
[epoch18, step264]: loss 0.035734
[epoch18, step265]: loss 0.033788
[epoch18, step266]: loss 0.033499
[epoch18, step267]: loss 0.036657
[epoch18, step268]: loss 0.033986
[epoch18, step269]: loss 0.036040
[epoch18, step270]: loss 0.033598
[epoch18, step271]: loss 0.033683
[epoch18, step272]: loss 0.036038
[epoch18, step273]: loss 0.035619
[epoch18, step274]: loss 0.034360
[epoch18, step275]: loss 0.033094
[epoch18, step276]: loss 0.036028
[epoch18, step277]: loss 0.034334
[epoch18, step278]: loss 0.036203
[epoch18, step279]: loss 0.033176
[epoch18, step280]: loss 0.033792
[epoch18, step281]: loss 0.036343
[epoch18, step282]: loss 0.036291
[epoch18, step283]: loss 0.033458
[epoch18, step284]: loss 0.033104
[epoch18, step285]: loss 0.036953
[epoch18, step286]: loss 0.033354
[epoch18, step287]: loss 0.036295
[epoch18, step288]: loss 0.033211
[epoch18, step289]: loss 0.034310
[epoch18, step290]: loss 0.036833
[epoch18, step291]: loss 0.036127
[epoch18, step292]: loss 0.033042
[epoch18, step293]: loss 0.033655
[epoch18, step294]: loss 0.035831
[epoch18, step295]: loss 0.034028
[epoch18, step296]: loss 0.037347
[epoch18, step297]: loss 0.033179
[epoch18, step298]: loss 0.034101
[epoch18, step299]: loss 0.035253
[epoch18, step300]: loss 0.036239
[epoch18, step301]: loss 0.033869
[epoch18, step302]: loss 0.033889
[epoch18, step303]: loss 0.036783
[epoch18, step304]: loss 0.033533
[epoch18, step305]: loss 0.035745
[epoch18, step306]: loss 0.034404
[epoch18, step307]: loss 0.033756
[epoch18, step308]: loss 0.037014
[epoch18, step309]: loss 0.036264
[epoch18, step310]: loss 0.033673
[epoch18, step311]: loss 0.034035
[epoch18, step312]: loss 0.035698
[epoch18, step313]: loss 0.033870
[epoch18, step314]: loss 0.036042
[epoch18, step315]: loss 0.034317
[epoch18, step316]: loss 0.033484
[epoch18, step317]: loss 0.036907
[epoch18, step318]: loss 0.036155
[epoch18, step319]: loss 0.033190
[epoch18, step320]: loss 0.032909
[epoch18, step321]: loss 0.035606
[epoch18, step322]: loss 0.033925
[epoch18, step323]: loss 0.035640
[epoch18, step324]: loss 0.034495
[epoch18, step325]: loss 0.033925
[epoch18, step326]: loss 0.035889
[epoch18, step327]: loss 0.035136
[epoch18, step328]: loss 0.034041
[epoch18, step329]: loss 0.033458
[epoch18, step330]: loss 0.035045
[epoch18, step331]: loss 0.034137
[epoch18, step332]: loss 0.035610
[epoch18, step333]: loss 0.033698
[epoch18, step334]: loss 0.034301
[epoch18, step335]: loss 0.036354
[epoch18, step336]: loss 0.037077
[epoch18, step337]: loss 0.034592
[epoch18, step338]: loss 0.033063
[epoch18, step339]: loss 0.036261
[epoch18, step340]: loss 0.034474
[epoch18, step341]: loss 0.035556
[epoch18, step342]: loss 0.033067
[epoch18, step343]: loss 0.034050
[epoch18, step344]: loss 0.035591
[epoch18, step345]: loss 0.035294
[epoch18, step346]: loss 0.033444
[epoch18, step347]: loss 0.033235
[epoch18, step348]: loss 0.036174
[epoch18, step349]: loss 0.034499
[epoch18, step350]: loss 0.035414
[epoch18, step351]: loss 0.032989
[epoch18, step352]: loss 0.033200
[epoch18, step353]: loss 0.036388
[epoch18, step354]: loss 0.035319
[epoch18, step355]: loss 0.032600
[epoch18, step356]: loss 0.034434
[epoch18, step357]: loss 0.036202
[epoch18, step358]: loss 0.032296
[epoch18, step359]: loss 0.038856
[epoch18, step360]: loss 0.032566
[epoch18, step361]: loss 0.033748
[epoch18, step362]: loss 0.037011
[epoch18, step363]: loss 0.035163
[epoch18, step364]: loss 0.033588
[epoch18, step365]: loss 0.033085
[epoch18, step366]: loss 0.036180
[epoch18, step367]: loss 0.033959
[epoch18, step368]: loss 0.035370
[epoch18, step369]: loss 0.033161
[epoch18, step370]: loss 0.034136
[epoch18, step371]: loss 0.036973
[epoch18, step372]: loss 0.035544
[epoch18, step373]: loss 0.033006
[epoch18, step374]: loss 0.033028
[epoch18, step375]: loss 0.036821
[epoch18, step376]: loss 0.033829
[epoch18, step377]: loss 0.036181
[epoch18, step378]: loss 0.033935
[epoch18, step379]: loss 0.034014
[epoch18, step380]: loss 0.037022
[epoch18, step381]: loss 0.036114
[epoch18, step382]: loss 0.033794
[epoch18, step383]: loss 0.032991
[epoch18, step384]: loss 0.036180
[epoch18, step385]: loss 0.033772
[epoch18, step386]: loss 0.036128
[epoch18, step387]: loss 0.033678
[epoch18, step388]: loss 0.034119
[epoch18, step389]: loss 0.035681
[epoch18, step390]: loss 0.036778
[epoch18, step391]: loss 0.033146
[epoch18, step392]: loss 0.033898
[epoch18, step393]: loss 0.035803
[epoch18, step394]: loss 0.033602
[epoch18, step395]: loss 0.035626
[epoch18, step396]: loss 0.033308
[epoch18, step397]: loss 0.033098
[epoch18, step398]: loss 0.036178
[epoch18, step399]: loss 0.035391
[epoch18, step400]: loss 0.033628
[epoch18, step401]: loss 0.033370
[epoch18, step402]: loss 0.036119
[epoch18, step403]: loss 0.033869
[epoch18, step404]: loss 0.036289
[epoch18, step405]: loss 0.034571
[epoch18, step406]: loss 0.034508
[epoch18, step407]: loss 0.036146
[epoch18, step408]: loss 0.036456
[epoch18, step409]: loss 0.035275
[epoch18, step410]: loss 0.033846
[epoch18, step411]: loss 0.036063
[epoch18, step412]: loss 0.033512
[epoch18, step413]: loss 0.035963
[epoch18, step414]: loss 0.033545
[epoch18, step415]: loss 0.033900
[epoch18, step416]: loss 0.035352
[epoch18, step417]: loss 0.035828
[epoch18, step418]: loss 0.034169
[epoch18, step419]: loss 0.032910
[epoch18, step420]: loss 0.036079
[epoch18, step421]: loss 0.033788
[epoch18, step422]: loss 0.036140
[epoch18, step423]: loss 0.033490
[epoch18, step424]: loss 0.033480
[epoch18, step425]: loss 0.036244
[epoch18, step426]: loss 0.036327
[epoch18, step427]: loss 0.034004
[epoch18, step428]: loss 0.033817
[epoch18, step429]: loss 0.036558
[epoch18, step430]: loss 0.034051
[epoch18, step431]: loss 0.036433
[epoch18, step432]: loss 0.033130
[epoch18, step433]: loss 0.034624
[epoch18, step434]: loss 0.035985
[epoch18, step435]: loss 0.036694
[epoch18, step436]: loss 0.033484
[epoch18, step437]: loss 0.033445
[epoch18, step438]: loss 0.036453
[epoch18, step439]: loss 0.034170
[epoch18, step440]: loss 0.036105
[epoch18, step441]: loss 0.033312
[epoch18, step442]: loss 0.033528
[epoch18, step443]: loss 0.036877
[epoch18, step444]: loss 0.035506
[epoch18, step445]: loss 0.033942
[epoch18, step446]: loss 0.034009
[epoch18, step447]: loss 0.036314
[epoch18, step448]: loss 0.033934
[epoch18, step449]: loss 0.036274
[epoch18, step450]: loss 0.032837
[epoch18, step451]: loss 0.034092
[epoch18, step452]: loss 0.035575
[epoch18, step453]: loss 0.035748
[epoch18, step454]: loss 0.033396
[epoch18, step455]: loss 0.033568
[epoch18, step456]: loss 0.035603
[epoch18, step457]: loss 0.034127
[epoch18, step458]: loss 0.035553
[epoch18, step459]: loss 0.033982
[epoch18, step460]: loss 0.034185
[epoch18, step461]: loss 0.037081
[epoch18, step462]: loss 0.034898
[epoch18, step463]: loss 0.033787
[epoch18, step464]: loss 0.033296
[epoch18, step465]: loss 0.037257
[epoch18, step466]: loss 0.033837
[epoch18, step467]: loss 0.035692
[epoch18, step468]: loss 0.033694
[epoch18, step469]: loss 0.033719
[epoch18, step470]: loss 0.036629
[epoch18, step471]: loss 0.036211
[epoch18, step472]: loss 0.034090
[epoch18, step473]: loss 0.033675
[epoch18, step474]: loss 0.036348
[epoch18, step475]: loss 0.033928
[epoch18, step476]: loss 0.036494
[epoch18, step477]: loss 0.033703
[epoch18, step478]: loss 0.032860
[epoch18, step479]: loss 0.035882
[epoch18, step480]: loss 0.034899
[epoch18, step481]: loss 0.033173
[epoch18, step482]: loss 0.032888
[epoch18, step483]: loss 0.036026
[epoch18, step484]: loss 0.033836
[epoch18, step485]: loss 0.036164
[epoch18, step486]: loss 0.033518
[epoch18, step487]: loss 0.032927
[epoch18, step488]: loss 0.036965
[epoch18, step489]: loss 0.034865
[epoch18, step490]: loss 0.034650
[epoch18, step491]: loss 0.034550
[epoch18, step492]: loss 0.036067
[epoch18, step493]: loss 0.033795
[epoch18, step494]: loss 0.035891
[epoch18, step495]: loss 0.034612
[epoch18, step496]: loss 0.034271
[epoch18, step497]: loss 0.036417
[epoch18, step498]: loss 0.035638
[epoch18, step499]: loss 0.033881
[epoch18, step500]: loss 0.033958
[epoch18, step501]: loss 0.035802
[epoch18, step502]: loss 0.033781
[epoch18, step503]: loss 0.036224
[epoch18, step504]: loss 0.033037
[epoch18, step505]: loss 0.032673
[epoch18, step506]: loss 0.036555
[epoch18, step507]: loss 0.036589
[epoch18, step508]: loss 0.034015
[epoch18, step509]: loss 0.033211
[epoch18, step510]: loss 0.036110
[epoch18, step511]: loss 0.034366
[epoch18, step512]: loss 0.036257
[epoch18, step513]: loss 0.033630
[epoch18, step514]: loss 0.033618
[epoch18, step515]: loss 0.036232
[epoch18, step516]: loss 0.035909
[epoch18, step517]: loss 0.033822
[epoch18, step518]: loss 0.034040
[epoch18, step519]: loss 0.036092
[epoch18, step520]: loss 0.034179
[epoch18, step521]: loss 0.037659
[epoch18, step522]: loss 0.033756
[epoch18, step523]: loss 0.033398
[epoch18, step524]: loss 0.035668
[epoch18, step525]: loss 0.036156
[epoch18, step526]: loss 0.033812
[epoch18, step527]: loss 0.032924
[epoch18, step528]: loss 0.036019
[epoch18, step529]: loss 0.033925
[epoch18, step530]: loss 0.036356
[epoch18, step531]: loss 0.033211
[epoch18, step532]: loss 0.034346
[epoch18, step533]: loss 0.037065
[epoch18, step534]: loss 0.035690
[epoch18, step535]: loss 0.034355
[epoch18, step536]: loss 0.033537
[epoch18, step537]: loss 0.035971
[epoch18, step538]: loss 0.034086
[epoch18, step539]: loss 0.035675
[epoch18, step540]: loss 0.033005
[epoch18, step541]: loss 0.033147
[epoch18, step542]: loss 0.036323
[epoch18, step543]: loss 0.035470
[epoch18, step544]: loss 0.033765
[epoch18, step545]: loss 0.033139
[epoch18, step546]: loss 0.036244
[epoch18, step547]: loss 0.034200
[epoch18, step548]: loss 0.036882
[epoch18, step549]: loss 0.033796
[epoch18, step550]: loss 0.033744
[epoch18, step551]: loss 0.035562
[epoch18, step552]: loss 0.035153
[epoch18, step553]: loss 0.034174
[epoch18, step554]: loss 0.033375
[epoch18, step555]: loss 0.035584
[epoch18, step556]: loss 0.033673
[epoch18, step557]: loss 0.035508
[epoch18, step558]: loss 0.033542
[epoch18, step559]: loss 0.033277
[epoch18, step560]: loss 0.036133
[epoch18, step561]: loss 0.035518
[epoch18, step562]: loss 0.033527
[epoch18, step563]: loss 0.036189
[epoch18, step564]: loss 0.042051
[epoch18, step565]: loss 0.040281
[epoch18, step566]: loss 0.048328
[epoch18, step567]: loss 0.040952
[epoch18, step568]: loss 0.041692
[epoch18, step569]: loss 0.037262
[epoch18, step570]: loss 0.046055
[epoch18, step571]: loss 0.040416
[epoch18, step572]: loss 0.037324
[epoch18, step573]: loss 0.039190
[epoch18, step574]: loss 0.041609
[epoch18, step575]: loss 0.032239
[epoch18, step576]: loss 0.033537
[epoch18, step577]: loss 0.037674
[epoch18, step578]: loss 0.030330
[epoch18, step579]: loss 0.040124
[epoch18, step580]: loss 0.031049
[epoch18, step581]: loss 0.036068
[epoch18, step582]: loss 0.036290
[epoch18, step583]: loss 0.036336
[epoch18, step584]: loss 0.033963
[epoch18, step585]: loss 0.036361
[epoch18, step586]: loss 0.034649
[epoch18, step587]: loss 0.040648
[epoch18, step588]: loss 0.035158
[epoch18, step589]: loss 0.035137
[epoch18, step590]: loss 0.039417
[epoch18, step591]: loss 0.031865
[epoch18, step592]: loss 0.037763
[epoch18, step593]: loss 0.033093
[epoch18, step594]: loss 0.038091
[epoch18, step595]: loss 0.039765
[epoch18, step596]: loss 0.037361
[epoch18, step597]: loss 0.036647
[epoch18, step598]: loss 0.036900
[epoch18, step599]: loss 0.034628
[epoch18, step600]: loss 0.038389
[epoch18, step601]: loss 0.031038
[epoch18, step602]: loss 0.033751
[epoch18, step603]: loss 0.036470
[epoch18, step604]: loss 0.039706
[epoch18, step605]: loss 0.036401
[epoch18, step606]: loss 0.034838
[epoch18, step607]: loss 0.037571
[epoch18, step608]: loss 0.037421
[epoch18, step609]: loss 0.038243
[epoch18, step610]: loss 0.039409
[epoch18, step611]: loss 0.038279
[epoch18, step612]: loss 0.035175
[epoch18, step613]: loss 0.030696
[epoch18, step614]: loss 0.035621
[epoch18, step615]: loss 0.041092
[epoch18, step616]: loss 0.034205
[epoch18, step617]: loss 0.033743
[epoch18, step618]: loss 0.037353
[epoch18, step619]: loss 0.039242
[epoch18, step620]: loss 0.035349
[epoch18, step621]: loss 0.037646
[epoch18, step622]: loss 0.031221
[epoch18, step623]: loss 0.033354
[epoch18, step624]: loss 0.038101
[epoch18, step625]: loss 0.036250
[epoch18, step626]: loss 0.039235
[epoch18, step627]: loss 0.033257
[epoch18, step628]: loss 0.035670
[epoch18, step629]: loss 0.030583
[epoch18, step630]: loss 0.032909
[epoch18, step631]: loss 0.041589
[epoch18, step632]: loss 0.034377
[epoch18, step633]: loss 0.035186
[epoch18, step634]: loss 0.037235
[epoch18, step635]: loss 0.036748
[epoch18, step636]: loss 0.032202
[epoch18, step637]: loss 0.038005
[epoch18, step638]: loss 0.038293
[epoch18, step639]: loss 0.032312
[epoch18, step640]: loss 0.040048
[epoch18, step641]: loss 0.039703
[epoch18, step642]: loss 0.035037
[epoch18, step643]: loss 0.035229
[epoch18, step644]: loss 0.035969
[epoch18, step645]: loss 0.034037
[epoch18, step646]: loss 0.034949
[epoch18, step647]: loss 0.034476
[epoch18, step648]: loss 0.034364
[epoch18, step649]: loss 0.037699
[epoch18, step650]: loss 0.032675
[epoch18, step651]: loss 0.037387
[epoch18, step652]: loss 0.037587
[epoch18, step653]: loss 0.038204
[epoch18, step654]: loss 0.033727
[epoch18, step655]: loss 0.034711
[epoch18, step656]: loss 0.033235
[epoch18, step657]: loss 0.038288
[epoch18, step658]: loss 0.035847
[epoch18, step659]: loss 0.038084
[epoch18, step660]: loss 0.033132
[epoch18, step661]: loss 0.036894
[epoch18, step662]: loss 0.033926
[epoch18, step663]: loss 0.032623
[epoch18, step664]: loss 0.036490
[epoch18, step665]: loss 0.037673
[epoch18, step666]: loss 0.037813
[epoch18, step667]: loss 0.036845
[epoch18, step668]: loss 0.033437
[epoch18, step669]: loss 0.037298
[epoch18, step670]: loss 0.037609
[epoch18, step671]: loss 0.032281
[epoch18, step672]: loss 0.034788
[epoch18, step673]: loss 0.033032
[epoch18, step674]: loss 0.031447
[epoch18, step675]: loss 0.030929
[epoch18, step676]: loss 0.034067
[epoch18, step677]: loss 0.035140
[epoch18, step678]: loss 0.033073
[epoch18, step679]: loss 0.034711
[epoch18, step680]: loss 0.041325
[epoch18, step681]: loss 0.032098
[epoch18, step682]: loss 0.036113
[epoch18, step683]: loss 0.035317
[epoch18, step684]: loss 0.035553
[epoch18, step685]: loss 0.035527
[epoch18, step686]: loss 0.039188
[epoch18, step687]: loss 0.036212
[epoch18, step688]: loss 0.035024
[epoch18, step689]: loss 0.035612
[epoch18, step690]: loss 0.035835
[epoch18, step691]: loss 0.035183
[epoch18, step692]: loss 0.034574
[epoch18, step693]: loss 0.039032
[epoch18, step694]: loss 0.032694
[epoch18, step695]: loss 0.038361
[epoch18, step696]: loss 0.035143
[epoch18, step697]: loss 0.037623
[epoch18, step698]: loss 0.035291
[epoch18, step699]: loss 0.034140
[epoch18, step700]: loss 0.031865
[epoch18, step701]: loss 0.036159
[epoch18, step702]: loss 0.031705
[epoch18, step703]: loss 0.034250
[epoch18, step704]: loss 0.036217
[epoch18, step705]: loss 0.036085
[epoch18, step706]: loss 0.033964
[epoch18, step707]: loss 0.033601
[epoch18, step708]: loss 0.034978
[epoch18, step709]: loss 0.037167
[epoch18, step710]: loss 0.033186
[epoch18, step711]: loss 0.037152
[epoch18, step712]: loss 0.037187
[epoch18, step713]: loss 0.037266
[epoch18, step714]: loss 0.032073
[epoch18, step715]: loss 0.034167
[epoch18, step716]: loss 0.035859
[epoch18, step717]: loss 0.033635
[epoch18, step718]: loss 0.035789
[epoch18, step719]: loss 0.044614
[epoch18, step720]: loss 0.034990
[epoch18, step721]: loss 0.033217
[epoch18, step722]: loss 0.040989
[epoch18, step723]: loss 0.037434
[epoch18, step724]: loss 0.033089
[epoch18, step725]: loss 0.037101
[epoch18, step726]: loss 0.032164
[epoch18, step727]: loss 0.034447
[epoch18, step728]: loss 0.037343
[epoch18, step729]: loss 0.032384
[epoch18, step730]: loss 0.032980
[epoch18, step731]: loss 0.036328
[epoch18, step732]: loss 0.035899
[epoch18, step733]: loss 0.034314
[epoch18, step734]: loss 0.034287
[epoch18, step735]: loss 0.037946
[epoch18, step736]: loss 0.036195
[epoch18, step737]: loss 0.037124
[epoch18, step738]: loss 0.030988
[epoch18, step739]: loss 0.036749
[epoch18, step740]: loss 0.033166
[epoch18, step741]: loss 0.036567
[epoch18, step742]: loss 0.033157
[epoch18, step743]: loss 0.034103
[epoch18, step744]: loss 0.033624
[epoch18, step745]: loss 0.033818
[epoch18, step746]: loss 0.036658
[epoch18, step747]: loss 0.039032
[epoch18, step748]: loss 0.036683
[epoch18, step749]: loss 0.035821
[epoch18, step750]: loss 0.038170
[epoch18, step751]: loss 0.033416
[epoch18, step752]: loss 0.035146
[epoch18, step753]: loss 0.035589
[epoch18, step754]: loss 0.034073
[epoch18, step755]: loss 0.035959
[epoch18, step756]: loss 0.033635
[epoch18, step757]: loss 0.030469
[epoch18, step758]: loss 0.034223
[epoch18, step759]: loss 0.033083
[epoch18, step760]: loss 0.034894
[epoch18, step761]: loss 0.037073
[epoch18, step762]: loss 0.031336
[epoch18, step763]: loss 0.035260
[epoch18, step764]: loss 0.034625
[epoch18, step765]: loss 0.036896
[epoch18, step766]: loss 0.036506
[epoch18, step767]: loss 0.038554
[epoch18, step768]: loss 0.031257
[epoch18, step769]: loss 0.035870
[epoch18, step770]: loss 0.034740
[epoch18, step771]: loss 0.033312
[epoch18, step772]: loss 0.037985
[epoch18, step773]: loss 0.035880
[epoch18, step774]: loss 0.035338
[epoch18, step775]: loss 0.029904
[epoch18, step776]: loss 0.037574
[epoch18, step777]: loss 0.033378
[epoch18, step778]: loss 0.037388
[epoch18, step779]: loss 0.035281
[epoch18, step780]: loss 0.029815
[epoch18, step781]: loss 0.034833
[epoch18, step782]: loss 0.032340
[epoch18, step783]: loss 0.030355
[epoch18, step784]: loss 0.030874
[epoch18, step785]: loss 0.031488
[epoch18, step786]: loss 0.034538
[epoch18, step787]: loss 0.034593
[epoch18, step788]: loss 0.036545
[epoch18, step789]: loss 0.034786
[epoch18, step790]: loss 0.034644
[epoch18, step791]: loss 0.037943
[epoch18, step792]: loss 0.035430
[epoch18, step793]: loss 0.036953
[epoch18, step794]: loss 0.030126
[epoch18, step795]: loss 0.034801
[epoch18, step796]: loss 0.037753
[epoch18, step797]: loss 0.037021
[epoch18, step798]: loss 0.037450
[epoch18, step799]: loss 0.037555
[epoch18, step800]: loss 0.031425
[epoch18, step801]: loss 0.034044
[epoch18, step802]: loss 0.033475
[epoch18, step803]: loss 0.037023
[epoch18, step804]: loss 0.037003
[epoch18, step805]: loss 0.038209
[epoch18, step806]: loss 0.032851
[epoch18, step807]: loss 0.031231
[epoch18, step808]: loss 0.034165
[epoch18, step809]: loss 0.032470
[epoch18, step810]: loss 0.036483
[epoch18, step811]: loss 0.035226
[epoch18, step812]: loss 0.033571
[epoch18, step813]: loss 0.033981
[epoch18, step814]: loss 0.036509
[epoch18, step815]: loss 0.033983
[epoch18, step816]: loss 0.034360
[epoch18, step817]: loss 0.035201
[epoch18, step818]: loss 0.032504
[epoch18, step819]: loss 0.031323
[epoch18, step820]: loss 0.034257
[epoch18, step821]: loss 0.031712
[epoch18, step822]: loss 0.040192
[epoch18, step823]: loss 0.033792
[epoch18, step824]: loss 0.036247
[epoch18, step825]: loss 0.036333
[epoch18, step826]: loss 0.035126
[epoch18, step827]: loss 0.037529
[epoch18, step828]: loss 0.039555
[epoch18, step829]: loss 0.038458
[epoch18, step830]: loss 0.033261
[epoch18, step831]: loss 0.036771
[epoch18, step832]: loss 0.031502
[epoch18, step833]: loss 0.038252
[epoch18, step834]: loss 0.036981
[epoch18, step835]: loss 0.031009
[epoch18, step836]: loss 0.039133
[epoch18, step837]: loss 0.036221
[epoch18, step838]: loss 0.035370
[epoch18, step839]: loss 0.039031
[epoch18, step840]: loss 0.030957
[epoch18, step841]: loss 0.035390
[epoch18, step842]: loss 0.037953
[epoch18, step843]: loss 0.036141
[epoch18, step844]: loss 0.035501
[epoch18, step845]: loss 0.031793
[epoch18, step846]: loss 0.038292
[epoch18, step847]: loss 0.036913
[epoch18, step848]: loss 0.035452
[epoch18, step849]: loss 0.033797
[epoch18, step850]: loss 0.033773
[epoch18, step851]: loss 0.034575
[epoch18, step852]: loss 0.032703
[epoch18, step853]: loss 0.040017
[epoch18, step854]: loss 0.034083
[epoch18, step855]: loss 0.037446
[epoch18, step856]: loss 0.031604
[epoch18, step857]: loss 0.034703
[epoch18, step858]: loss 0.034370
[epoch18, step859]: loss 0.033866
[epoch18, step860]: loss 0.032723
[epoch18, step861]: loss 0.032332
[epoch18, step862]: loss 0.032849
[epoch18, step863]: loss 0.031315
[epoch18, step864]: loss 0.037039
[epoch18, step865]: loss 0.034071
[epoch18, step866]: loss 0.035179
[epoch18, step867]: loss 0.037105
[epoch18, step868]: loss 0.036251
[epoch18, step869]: loss 0.033382
[epoch18, step870]: loss 0.041672
[epoch18, step871]: loss 0.033576
[epoch18, step872]: loss 0.035803
[epoch18, step873]: loss 0.035776
[epoch18, step874]: loss 0.034747
[epoch18, step875]: loss 0.034131
[epoch18, step876]: loss 0.036789
[epoch18, step877]: loss 0.030000
[epoch18, step878]: loss 0.033727
[epoch18, step879]: loss 0.037370
[epoch18, step880]: loss 0.036600
[epoch18, step881]: loss 0.032588
[epoch18, step882]: loss 0.033925
[epoch18, step883]: loss 0.034126
[epoch18, step884]: loss 0.036916
[epoch18, step885]: loss 0.035238
[epoch18, step886]: loss 0.035673
[epoch18, step887]: loss 0.034999
[epoch18, step888]: loss 0.035294
[epoch18, step889]: loss 0.034666
[epoch18, step890]: loss 0.033980
[epoch18, step891]: loss 0.036055
[epoch18, step892]: loss 0.030611
[epoch18, step893]: loss 0.034145
[epoch18, step894]: loss 0.035598
[epoch18, step895]: loss 0.032349
[epoch18, step896]: loss 0.032947
[epoch18, step897]: loss 0.035653
[epoch18, step898]: loss 0.036466
[epoch18, step899]: loss 0.039069
[epoch18, step900]: loss 0.036170
[epoch18, step901]: loss 0.036794
[epoch18, step902]: loss 0.034259
[epoch18, step903]: loss 0.034962
[epoch18, step904]: loss 0.037483
[epoch18, step905]: loss 0.037941
[epoch18, step906]: loss 0.031729
[epoch18, step907]: loss 0.033709
[epoch18, step908]: loss 0.031603
[epoch18, step909]: loss 0.037416
[epoch18, step910]: loss 0.033550
[epoch18, step911]: loss 0.035228
[epoch18, step912]: loss 0.033006
[epoch18, step913]: loss 0.034521
[epoch18, step914]: loss 0.039537
[epoch18, step915]: loss 0.033694
[epoch18, step916]: loss 0.033198
[epoch18, step917]: loss 0.035664
[epoch18, step918]: loss 0.039416
[epoch18, step919]: loss 0.034701
[epoch18, step920]: loss 0.037867
[epoch18, step921]: loss 0.033978
[epoch18, step922]: loss 0.034547
[epoch18, step923]: loss 0.033153
[epoch18, step924]: loss 0.030089
[epoch18, step925]: loss 0.035546
[epoch18, step926]: loss 0.034710
[epoch18, step927]: loss 0.035203
[epoch18, step928]: loss 0.034931
[epoch18, step929]: loss 0.038062
[epoch18, step930]: loss 0.035793
[epoch18, step931]: loss 0.037122
[epoch18, step932]: loss 0.031438
[epoch18, step933]: loss 0.038712
[epoch18, step934]: loss 0.032666
[epoch18, step935]: loss 0.034296
[epoch18, step936]: loss 0.032435
[epoch18, step937]: loss 0.036059
[epoch18, step938]: loss 0.038536
[epoch18, step939]: loss 0.031211
[epoch18, step940]: loss 0.033841
[epoch18, step941]: loss 0.038295
[epoch18, step942]: loss 0.035714
[epoch18, step943]: loss 0.033550
[epoch18, step944]: loss 0.038008
[epoch18, step945]: loss 0.030934
[epoch18, step946]: loss 0.035353
[epoch18, step947]: loss 0.038793
[epoch18, step948]: loss 0.030154
[epoch18, step949]: loss 0.033729
[epoch18, step950]: loss 0.038281
[epoch18, step951]: loss 0.039473
[epoch18, step952]: loss 0.034524
[epoch18, step953]: loss 0.036686
[epoch18, step954]: loss 0.033111
[epoch18, step955]: loss 0.041794
[epoch18, step956]: loss 0.051818
[epoch18, step957]: loss 0.048134
[epoch18, step958]: loss 0.045729
[epoch18, step959]: loss 0.048041
[epoch18, step960]: loss 0.045218
[epoch18, step961]: loss 0.045271
[epoch18, step962]: loss 0.044367
[epoch18, step963]: loss 0.042100
[epoch18, step964]: loss 0.043022
[epoch18, step965]: loss 0.043565
[epoch18, step966]: loss 0.042771
[epoch18, step967]: loss 0.042058
[epoch18, step968]: loss 0.043405
[epoch18, step969]: loss 0.043515
[epoch18, step970]: loss 0.042434
[epoch18, step971]: loss 0.042349
[epoch18, step972]: loss 0.042469
[epoch18, step973]: loss 0.042322
[epoch18, step974]: loss 0.043800
[epoch18, step975]: loss 0.042227
[epoch18, step976]: loss 0.041591
[epoch18, step977]: loss 0.043295
[epoch18, step978]: loss 0.042503
[epoch18, step979]: loss 0.041581
[epoch18, step980]: loss 0.041096
[epoch18, step981]: loss 0.042118
[epoch18, step982]: loss 0.041851
[epoch18, step983]: loss 0.042868
[epoch18, step984]: loss 0.041110
[epoch18, step985]: loss 0.040904
[epoch18, step986]: loss 0.042920
[epoch18, step987]: loss 0.042042
[epoch18, step988]: loss 0.042208
[epoch18, step989]: loss 0.041480
[epoch18, step990]: loss 0.041359
[epoch18, step991]: loss 0.041424
[epoch18, step992]: loss 0.041873
[epoch18, step993]: loss 0.041266
[epoch18, step994]: loss 0.040065
[epoch18, step995]: loss 0.042549
[epoch18, step996]: loss 0.041595
[epoch18, step997]: loss 0.041000
[epoch18, step998]: loss 0.041674
[epoch18, step999]: loss 0.041060
[epoch18, step1000]: loss 0.041477
[epoch18, step1001]: loss 0.041613
[epoch18, step1002]: loss 0.041469
[epoch18, step1003]: loss 0.040257
[epoch18, step1004]: loss 0.042745
[epoch18, step1005]: loss 0.041527
[epoch18, step1006]: loss 0.040931
[epoch18, step1007]: loss 0.041088
[epoch18, step1008]: loss 0.042336
[epoch18, step1009]: loss 0.041839
[epoch18, step1010]: loss 0.042066
[epoch18, step1011]: loss 0.040951
[epoch18, step1012]: loss 0.040056
[epoch18, step1013]: loss 0.041938
[epoch18, step1014]: loss 0.041387
[epoch18, step1015]: loss 0.041177
[epoch18, step1016]: loss 0.040085
[epoch18, step1017]: loss 0.040427
[epoch18, step1018]: loss 0.040933
[epoch18, step1019]: loss 0.041449
[epoch18, step1020]: loss 0.040831
[epoch18, step1021]: loss 0.039677
[epoch18, step1022]: loss 0.041871
[epoch18, step1023]: loss 0.041327
[epoch18, step1024]: loss 0.041675
[epoch18, step1025]: loss 0.040932
[epoch18, step1026]: loss 0.040784
[epoch18, step1027]: loss 0.041413
[epoch18, step1028]: loss 0.041619
[epoch18, step1029]: loss 0.040811
[epoch18, step1030]: loss 0.039928
[epoch18, step1031]: loss 0.041911
[epoch18, step1032]: loss 0.041020
[epoch18, step1033]: loss 0.041063
[epoch18, step1034]: loss 0.039653
[epoch18, step1035]: loss 0.040726
[epoch18, step1036]: loss 0.041137
[epoch18, step1037]: loss 0.041453
[epoch18, step1038]: loss 0.040257
[epoch18, step1039]: loss 0.040468
[epoch18, step1040]: loss 0.041900
[epoch18, step1041]: loss 0.040739
[epoch18, step1042]: loss 0.040891
[epoch18, step1043]: loss 0.040022
[epoch18, step1044]: loss 0.041027
[epoch18, step1045]: loss 0.041531
[epoch18, step1046]: loss 0.041527
[epoch18, step1047]: loss 0.040875
[epoch18, step1048]: loss 0.040204
[epoch18, step1049]: loss 0.042584
[epoch18, step1050]: loss 0.041699
[epoch18, step1051]: loss 0.040711
[epoch18, step1052]: loss 0.040794
[epoch18, step1053]: loss 0.041580
[epoch18, step1054]: loss 0.041042
[epoch18, step1055]: loss 0.041709
[epoch18, step1056]: loss 0.039750
[epoch18, step1057]: loss 0.040194
[epoch18, step1058]: loss 0.042287
[epoch18, step1059]: loss 0.041446
[epoch18, step1060]: loss 0.040934
[epoch18, step1061]: loss 0.039762
[epoch18, step1062]: loss 0.041860
[epoch18, step1063]: loss 0.041612
[epoch18, step1064]: loss 0.041439
[epoch18, step1065]: loss 0.040679
[epoch18, step1066]: loss 0.039838
[epoch18, step1067]: loss 0.042070
[epoch18, step1068]: loss 0.040326
[epoch18, step1069]: loss 0.040576
[epoch18, step1070]: loss 0.040551
[epoch18, step1071]: loss 0.041220
[epoch18, step1072]: loss 0.041345
[epoch18, step1073]: loss 0.041725
[epoch18, step1074]: loss 0.040151
[epoch18, step1075]: loss 0.040054
[epoch18, step1076]: loss 0.041721
[epoch18, step1077]: loss 0.041207
[epoch18, step1078]: loss 0.041607
[epoch18, step1079]: loss 0.040808
[epoch18, step1080]: loss 0.041095
[epoch18, step1081]: loss 0.040823
[epoch18, step1082]: loss 0.041199
[epoch18, step1083]: loss 0.040765
[epoch18, step1084]: loss 0.039772
[epoch18, step1085]: loss 0.041157
[epoch18, step1086]: loss 0.040815
[epoch18, step1087]: loss 0.040614
[epoch18, step1088]: loss 0.040553
[epoch18, step1089]: loss 0.041303
[epoch18, step1090]: loss 0.041273
[epoch18, step1091]: loss 0.042403
[epoch18, step1092]: loss 0.040875
[epoch18, step1093]: loss 0.039548
[epoch18, step1094]: loss 0.041409
[epoch18, step1095]: loss 0.040784
[epoch18, step1096]: loss 0.039920
[epoch18, step1097]: loss 0.040655
[epoch18, step1098]: loss 0.040135
[epoch18, step1099]: loss 0.041243
[epoch18, step1100]: loss 0.042037
[epoch18, step1101]: loss 0.040547
[epoch18, step1102]: loss 0.039708
[epoch18, step1103]: loss 0.041591
[epoch18, step1104]: loss 0.040490
[epoch18, step1105]: loss 0.040884
[epoch18, step1106]: loss 0.039671
[epoch18, step1107]: loss 0.040428
[epoch18, step1108]: loss 0.040352
[epoch18, step1109]: loss 0.040934
[epoch18, step1110]: loss 0.041189
[epoch18, step1111]: loss 0.039605
[epoch18, step1112]: loss 0.041575
[epoch18, step1113]: loss 0.040274
[epoch18, step1114]: loss 0.040489
[epoch18, step1115]: loss 0.040268
[epoch18, step1116]: loss 0.040578
[epoch18, step1117]: loss 0.041121
[epoch18, step1118]: loss 0.041485
[epoch18, step1119]: loss 0.040532
[epoch18, step1120]: loss 0.040035
[epoch18, step1121]: loss 0.041451
[epoch18, step1122]: loss 0.042279
[epoch18, step1123]: loss 0.040400
[epoch18, step1124]: loss 0.040562
[epoch18, step1125]: loss 0.040624
[epoch18, step1126]: loss 0.041771
[epoch18, step1127]: loss 0.041195
[epoch18, step1128]: loss 0.040934
[epoch18, step1129]: loss 0.039634
[epoch18, step1130]: loss 0.041634
[epoch18, step1131]: loss 0.041647
[epoch18, step1132]: loss 0.040650
[epoch18, step1133]: loss 0.040006
[epoch18, step1134]: loss 0.040967
[epoch18, step1135]: loss 0.041602
[epoch18, step1136]: loss 0.042774
[epoch18, step1137]: loss 0.040591
[epoch18, step1138]: loss 0.039496
[epoch18, step1139]: loss 0.041912
[epoch18, step1140]: loss 0.040445
[epoch18, step1141]: loss 0.040965
[epoch18, step1142]: loss 0.041036
[epoch18, step1143]: loss 0.040373
[epoch18, step1144]: loss 0.040744
[epoch18, step1145]: loss 0.041369
[epoch18, step1146]: loss 0.040472
[epoch18, step1147]: loss 0.039888
[epoch18, step1148]: loss 0.042282
[epoch18, step1149]: loss 0.040845
[epoch18, step1150]: loss 0.040244
[epoch18, step1151]: loss 0.040103
[epoch18, step1152]: loss 0.041395
[epoch18, step1153]: loss 0.040980
[epoch18, step1154]: loss 0.041237
[epoch18, step1155]: loss 0.040843
[epoch18, step1156]: loss 0.039682
[epoch18, step1157]: loss 0.041871
[epoch18, step1158]: loss 0.041023
[epoch18, step1159]: loss 0.040618
[epoch18, step1160]: loss 0.040770
[epoch18, step1161]: loss 0.041500
[epoch18, step1162]: loss 0.040507
[epoch18, step1163]: loss 0.041542
[epoch18, step1164]: loss 0.040021
[epoch18, step1165]: loss 0.040048
[epoch18, step1166]: loss 0.042029
[epoch18, step1167]: loss 0.040684
[epoch18, step1168]: loss 0.040498
[epoch18, step1169]: loss 0.039463
[epoch18, step1170]: loss 0.039952
[epoch18, step1171]: loss 0.041070
[epoch18, step1172]: loss 0.041751
[epoch18, step1173]: loss 0.040472
[epoch18, step1174]: loss 0.040100
[epoch18, step1175]: loss 0.040849
[epoch18, step1176]: loss 0.040625
[epoch18, step1177]: loss 0.040578
[epoch18, step1178]: loss 0.040275
[epoch18, step1179]: loss 0.039586
[epoch18, step1180]: loss 0.040884
[epoch18, step1181]: loss 0.043059
[epoch18, step1182]: loss 0.040307
[epoch18, step1183]: loss 0.040581
[epoch18, step1184]: loss 0.041835
[epoch18, step1185]: loss 0.041118
[epoch18, step1186]: loss 0.041177
[epoch18, step1187]: loss 0.039195
[epoch18, step1188]: loss 0.040186
[epoch18, step1189]: loss 0.041163
[epoch18, step1190]: loss 0.040563
[epoch18, step1191]: loss 0.040867
[epoch18, step1192]: loss 0.039556
[epoch18, step1193]: loss 0.041588
[epoch18, step1194]: loss 0.041095
[epoch18, step1195]: loss 0.040166
[epoch18, step1196]: loss 0.039580
[epoch18, step1197]: loss 0.040611
[epoch18, step1198]: loss 0.040956
[epoch18, step1199]: loss 0.040909
[epoch18, step1200]: loss 0.040352
[epoch18, step1201]: loss 0.039869
[epoch18, step1202]: loss 0.041693
[epoch18, step1203]: loss 0.041121
[epoch18, step1204]: loss 0.040597
[epoch18, step1205]: loss 0.039979
[epoch18, step1206]: loss 0.040233
[epoch18, step1207]: loss 0.040947
[epoch18, step1208]: loss 0.041730
[epoch18, step1209]: loss 0.039709
[epoch18, step1210]: loss 0.040153
[epoch18, step1211]: loss 0.041765
[epoch18, step1212]: loss 0.040743
[epoch18, step1213]: loss 0.040889
[epoch18, step1214]: loss 0.039840
[epoch18, step1215]: loss 0.041199
[epoch18, step1216]: loss 0.041427
[epoch18, step1217]: loss 0.041235
[epoch18, step1218]: loss 0.039954
[epoch18, step1219]: loss 0.039885
[epoch18, step1220]: loss 0.041798
[epoch18, step1221]: loss 0.040399
[epoch18, step1222]: loss 0.040744
[epoch18, step1223]: loss 0.040186
[epoch18, step1224]: loss 0.040673
[epoch18, step1225]: loss 0.041224
[epoch18, step1226]: loss 0.041173
[epoch18, step1227]: loss 0.040502
[epoch18, step1228]: loss 0.039940
[epoch18, step1229]: loss 0.041639
[epoch18, step1230]: loss 0.041119
[epoch18, step1231]: loss 0.040888
[epoch18, step1232]: loss 0.040373
[epoch18, step1233]: loss 0.040671
[epoch18, step1234]: loss 0.040698
[epoch18, step1235]: loss 0.041708
[epoch18, step1236]: loss 0.040447
[epoch18, step1237]: loss 0.039617
[epoch18, step1238]: loss 0.040827
[epoch18, step1239]: loss 0.040754
[epoch18, step1240]: loss 0.041032
[epoch18, step1241]: loss 0.039960
[epoch18, step1242]: loss 0.040694
[epoch18, step1243]: loss 0.041201
[epoch18, step1244]: loss 0.041557
[epoch18, step1245]: loss 0.040107
[epoch18, step1246]: loss 0.039657
[epoch18, step1247]: loss 0.041085
[epoch18, step1248]: loss 0.040802
[epoch18, step1249]: loss 0.040720
[epoch18, step1250]: loss 0.039830
[epoch18, step1251]: loss 0.040071
[epoch18, step1252]: loss 0.042085
[epoch18, step1253]: loss 0.041532
[epoch18, step1254]: loss 0.040341
[epoch18, step1255]: loss 0.040146
[epoch18, step1256]: loss 0.041558
[epoch18, step1257]: loss 0.039898
[epoch18, step1258]: loss 0.040414
[epoch18, step1259]: loss 0.039754
[epoch18, step1260]: loss 0.041124
[epoch18, step1261]: loss 0.040254
[epoch18, step1262]: loss 0.040298
[epoch18, step1263]: loss 0.040458
[epoch18, step1264]: loss 0.041283
[epoch18, step1265]: loss 0.040934
[epoch18, step1266]: loss 0.040032
[epoch18, step1267]: loss 0.040433
[epoch18, step1268]: loss 0.039919
[epoch18, step1269]: loss 0.040677
[epoch18, step1270]: loss 0.040873
[epoch18, step1271]: loss 0.041095
[epoch18, step1272]: loss 0.040222
[epoch18, step1273]: loss 0.039475
[epoch18, step1274]: loss 0.041965
[epoch18, step1275]: loss 0.040798
[epoch18, step1276]: loss 0.040692
[epoch18, step1277]: loss 0.040064
[epoch18, step1278]: loss 0.040766
[epoch18, step1279]: loss 0.040880
[epoch18, step1280]: loss 0.041191
[epoch18, step1281]: loss 0.040471
[epoch18, step1282]: loss 0.040178
[epoch18, step1283]: loss 0.040862
[epoch18, step1284]: loss 0.041213
[epoch18, step1285]: loss 0.040785
[epoch18, step1286]: loss 0.039521
[epoch18, step1287]: loss 0.041159
[epoch18, step1288]: loss 0.041214
[epoch18, step1289]: loss 0.041540
[epoch18, step1290]: loss 0.040294
[epoch18, step1291]: loss 0.039246
[epoch18, step1292]: loss 0.041576
[epoch18, step1293]: loss 0.040013
[epoch18, step1294]: loss 0.040517
[epoch18, step1295]: loss 0.040733
[epoch18, step1296]: loss 0.040603
[epoch18, step1297]: loss 0.041241
[epoch18, step1298]: loss 0.042201
[epoch18, step1299]: loss 0.041043
[epoch18, step1300]: loss 0.040901
[epoch18, step1301]: loss 0.041421
[epoch18, step1302]: loss 0.041055
[epoch18, step1303]: loss 0.040671
[epoch18, step1304]: loss 0.039767
[epoch18, step1305]: loss 0.040487
[epoch18, step1306]: loss 0.040980
[epoch18, step1307]: loss 0.041184
[epoch18, step1308]: loss 0.040479
[epoch18, step1309]: loss 0.039493
[epoch18, step1310]: loss 0.041829
[epoch18, step1311]: loss 0.040283
[epoch18, step1312]: loss 0.040553
[epoch18, step1313]: loss 0.039993
[epoch18, step1314]: loss 0.041152
[epoch18, step1315]: loss 0.040860
[epoch18, step1316]: loss 0.041521
[epoch18, step1317]: loss 0.039788
[epoch18, step1318]: loss 0.039582
[epoch18, step1319]: loss 0.041255
[epoch18, step1320]: loss 0.040801
[epoch18, step1321]: loss 0.040764
[epoch18, step1322]: loss 0.040004
[epoch18, step1323]: loss 0.040725
[epoch18, step1324]: loss 0.041018
[epoch18, step1325]: loss 0.041348
[epoch18, step1326]: loss 0.039934
[epoch18, step1327]: loss 0.039966
[epoch18, step1328]: loss 0.042837
[epoch18, step1329]: loss 0.040770
[epoch18, step1330]: loss 0.040653
[epoch18, step1331]: loss 0.039643
[epoch18, step1332]: loss 0.040038
[epoch18, step1333]: loss 0.040405
[epoch18, step1334]: loss 0.041156
[epoch18, step1335]: loss 0.040494
[epoch18, step1336]: loss 0.039253
[epoch18, step1337]: loss 0.040982
[epoch18, step1338]: loss 0.040651
[epoch18, step1339]: loss 0.040755
[epoch18, step1340]: loss 0.040185
[epoch18, step1341]: loss 0.041342
[epoch18, step1342]: loss 0.041322
[epoch18, step1343]: loss 0.041558
[epoch18, step1344]: loss 0.040993
[epoch18, step1345]: loss 0.040097
[epoch18, step1346]: loss 0.042075
[epoch18, step1347]: loss 0.041932
[epoch18, step1348]: loss 0.041469
[epoch18, step1349]: loss 0.040443
[epoch18, step1350]: loss 0.040977
[epoch18, step1351]: loss 0.040316
[epoch18, step1352]: loss 0.041301
[epoch18, step1353]: loss 0.040787
[epoch18, step1354]: loss 0.039235
[epoch18, step1355]: loss 0.041929
[epoch18, step1356]: loss 0.040760
[epoch18, step1357]: loss 0.040448
[epoch18, step1358]: loss 0.039710
[epoch18, step1359]: loss 0.040679
[epoch18, step1360]: loss 0.040565
[epoch18, step1361]: loss 0.041606
[epoch18, step1362]: loss 0.040534
[epoch18, step1363]: loss 0.039336
[epoch18, step1364]: loss 0.041348
[epoch18, step1365]: loss 0.041471
[epoch18, step1366]: loss 0.041024
[epoch18, step1367]: loss 0.039778
[epoch18, step1368]: loss 0.040797
[epoch18, step1369]: loss 0.040909
[epoch18, step1370]: loss 0.041646
[epoch18, step1371]: loss 0.040733
[epoch18, step1372]: loss 0.039256
[epoch18, step1373]: loss 0.041057
[epoch18, step1374]: loss 0.041233
[epoch18, step1375]: loss 0.040718
[epoch18, step1376]: loss 0.039454
[epoch18, step1377]: loss 0.039917
[epoch18, step1378]: loss 0.041111
[epoch18, step1379]: loss 0.040556
[epoch18, step1380]: loss 0.040277
[epoch18, step1381]: loss 0.039225
[epoch18, step1382]: loss 0.041855
[epoch18, step1383]: loss 0.039802
[epoch18, step1384]: loss 0.040431
[epoch18, step1385]: loss 0.039635
[epoch18, step1386]: loss 0.040744
[epoch18, step1387]: loss 0.040928
[epoch18, step1388]: loss 0.040660
[epoch18, step1389]: loss 0.039424
[epoch18, step1390]: loss 0.039402
[epoch18, step1391]: loss 0.041876
[epoch18, step1392]: loss 0.040578
[epoch18, step1393]: loss 0.040206
[epoch18, step1394]: loss 0.041068
[epoch18, step1395]: loss 0.041585
[epoch18, step1396]: loss 0.040824
[epoch18, step1397]: loss 0.041062
[epoch18, step1398]: loss 0.040656
[epoch18, step1399]: loss 0.040180
[epoch18, step1400]: loss 0.042374
[epoch18, step1401]: loss 0.040978
[epoch18, step1402]: loss 0.040321
[epoch18, step1403]: loss 0.038911
[epoch18, step1404]: loss 0.040438
[epoch18, step1405]: loss 0.040795
[epoch18, step1406]: loss 0.041044
[epoch18, step1407]: loss 0.041134
[epoch18, step1408]: loss 0.039253
[epoch18, step1409]: loss 0.041568
[epoch18, step1410]: loss 0.041165
[epoch18, step1411]: loss 0.039991
[epoch18, step1412]: loss 0.040080
[epoch18, step1413]: loss 0.041096
[epoch18, step1414]: loss 0.040556
[epoch18, step1415]: loss 0.041103
[epoch18, step1416]: loss 0.040536
[epoch18, step1417]: loss 0.039513
[epoch18, step1418]: loss 0.040848
[epoch18, step1419]: loss 0.041175
[epoch18, step1420]: loss 0.040565
[epoch18, step1421]: loss 0.039994
[epoch18, step1422]: loss 0.040083
[epoch18, step1423]: loss 0.040478
[epoch18, step1424]: loss 0.041477
[epoch18, step1425]: loss 0.039682
[epoch18, step1426]: loss 0.039657
[epoch18, step1427]: loss 0.041582
[epoch18, step1428]: loss 0.040692
[epoch18, step1429]: loss 0.040785
[epoch18, step1430]: loss 0.040435
[epoch18, step1431]: loss 0.041122
[epoch18, step1432]: loss 0.040534
[epoch18, step1433]: loss 0.042512
[epoch18, step1434]: loss 0.040478
[epoch18, step1435]: loss 0.039719
[epoch18, step1436]: loss 0.041999
[epoch18, step1437]: loss 0.040792
[epoch18, step1438]: loss 0.040392
[epoch18, step1439]: loss 0.039429
[epoch18, step1440]: loss 0.040358
[epoch18, step1441]: loss 0.041455
[epoch18, step1442]: loss 0.041105
[epoch18, step1443]: loss 0.040447
[epoch18, step1444]: loss 0.039236
[epoch18, step1445]: loss 0.042613
[epoch18, step1446]: loss 0.041335
[epoch18, step1447]: loss 0.040977
[epoch18, step1448]: loss 0.039675
[epoch18, step1449]: loss 0.040277
[epoch18, step1450]: loss 0.040279
[epoch18, step1451]: loss 0.041036
[epoch18, step1452]: loss 0.040368
[epoch18, step1453]: loss 0.039954
[epoch18, step1454]: loss 0.041336
[epoch18, step1455]: loss 0.040411
[epoch18, step1456]: loss 0.040653
[epoch18, step1457]: loss 0.039524
[epoch18, step1458]: loss 0.040290
[epoch18, step1459]: loss 0.040267
[epoch18, step1460]: loss 0.041619
[epoch18, step1461]: loss 0.040844
[epoch18, step1462]: loss 0.040304
[epoch18, step1463]: loss 0.041059
[epoch18, step1464]: loss 0.040631
[epoch18, step1465]: loss 0.041048
[epoch18, step1466]: loss 0.039219
[epoch18, step1467]: loss 0.041347
[epoch18, step1468]: loss 0.040397
[epoch18, step1469]: loss 0.040759
[epoch18, step1470]: loss 0.039919
[epoch18, step1471]: loss 0.038902
[epoch18, step1472]: loss 0.040879
[epoch18, step1473]: loss 0.040444
[epoch18, step1474]: loss 0.040741
[epoch18, step1475]: loss 0.039005
[epoch18, step1476]: loss 0.040570
[epoch18, step1477]: loss 0.040342
[epoch18, step1478]: loss 0.040652
[epoch18, step1479]: loss 0.039980
[epoch18, step1480]: loss 0.039131
[epoch18, step1481]: loss 0.040931
[epoch18, step1482]: loss 0.040433
[epoch18, step1483]: loss 0.040530
[epoch18, step1484]: loss 0.040412
[epoch18, step1485]: loss 0.040607
[epoch18, step1486]: loss 0.040190
[epoch18, step1487]: loss 0.041308
[epoch18, step1488]: loss 0.040270
[epoch18, step1489]: loss 0.039805
[epoch18, step1490]: loss 0.041678
[epoch18, step1491]: loss 0.040203
[epoch18, step1492]: loss 0.040316
[epoch18, step1493]: loss 0.039695
[epoch18, step1494]: loss 0.039863
[epoch18, step1495]: loss 0.040075
[epoch18, step1496]: loss 0.040333
[epoch18, step1497]: loss 0.040299
[epoch18, step1498]: loss 0.039861
[epoch18, step1499]: loss 0.041810
[epoch18, step1500]: loss 0.041205
[epoch18, step1501]: loss 0.040628
[epoch18, step1502]: loss 0.039742
[epoch18, step1503]: loss 0.040655
[epoch18, step1504]: loss 0.041074
[epoch18, step1505]: loss 0.041920
[epoch18, step1506]: loss 0.039716
[epoch18, step1507]: loss 0.040218
[epoch18, step1508]: loss 0.041947
[epoch18, step1509]: loss 0.040768
[epoch18, step1510]: loss 0.041004
[epoch18, step1511]: loss 0.039970
[epoch18, step1512]: loss 0.040534
[epoch18, step1513]: loss 0.040511
[epoch18, step1514]: loss 0.041079
[epoch18, step1515]: loss 0.039821
[epoch18, step1516]: loss 0.039586

[epoch18]: avg loss 0.037328

[epoch19, step1]: loss 0.040301
[epoch19, step2]: loss 0.039346
[epoch19, step3]: loss 0.037487
[epoch19, step4]: loss 0.034779
[epoch19, step5]: loss 0.034645
[epoch19, step6]: loss 0.039049
[epoch19, step7]: loss 0.035927
[epoch19, step8]: loss 0.036947
[epoch19, step9]: loss 0.034164
[epoch19, step10]: loss 0.037405
[epoch19, step11]: loss 0.038583
[epoch19, step12]: loss 0.037545
[epoch19, step13]: loss 0.035021
[epoch19, step14]: loss 0.034255
[epoch19, step15]: loss 0.036699
[epoch19, step16]: loss 0.035458
[epoch19, step17]: loss 0.036515
[epoch19, step18]: loss 0.034188
[epoch19, step19]: loss 0.034521
[epoch19, step20]: loss 0.037531
[epoch19, step21]: loss 0.035638
[epoch19, step22]: loss 0.033837
[epoch19, step23]: loss 0.033483
[epoch19, step24]: loss 0.036112
[epoch19, step25]: loss 0.033522
[epoch19, step26]: loss 0.036301
[epoch19, step27]: loss 0.032825
[epoch19, step28]: loss 0.034577
[epoch19, step29]: loss 0.036749
[epoch19, step30]: loss 0.037372
[epoch19, step31]: loss 0.034316
[epoch19, step32]: loss 0.035217
[epoch19, step33]: loss 0.037167
[epoch19, step34]: loss 0.034528
[epoch19, step35]: loss 0.037985
[epoch19, step36]: loss 0.034345
[epoch19, step37]: loss 0.038396
[epoch19, step38]: loss 0.038764
[epoch19, step39]: loss 0.038248
[epoch19, step40]: loss 0.037668
[epoch19, step41]: loss 0.035471
[epoch19, step42]: loss 0.036790
[epoch19, step43]: loss 0.034350
[epoch19, step44]: loss 0.038212
[epoch19, step45]: loss 0.034855
[epoch19, step46]: loss 0.034780
[epoch19, step47]: loss 0.037423
[epoch19, step48]: loss 0.037113
[epoch19, step49]: loss 0.032978
[epoch19, step50]: loss 0.034402
[epoch19, step51]: loss 0.036850
[epoch19, step52]: loss 0.035060
[epoch19, step53]: loss 0.038323
[epoch19, step54]: loss 0.033389
[epoch19, step55]: loss 0.035328
[epoch19, step56]: loss 0.038082
[epoch19, step57]: loss 0.036946
[epoch19, step58]: loss 0.034531
[epoch19, step59]: loss 0.033121
[epoch19, step60]: loss 0.037116
[epoch19, step61]: loss 0.034212
[epoch19, step62]: loss 0.036440
[epoch19, step63]: loss 0.032908
[epoch19, step64]: loss 0.034055
[epoch19, step65]: loss 0.037013
[epoch19, step66]: loss 0.036476
[epoch19, step67]: loss 0.034318
[epoch19, step68]: loss 0.033969
[epoch19, step69]: loss 0.036660
[epoch19, step70]: loss 0.034424
[epoch19, step71]: loss 0.036676
[epoch19, step72]: loss 0.033758
[epoch19, step73]: loss 0.034117
[epoch19, step74]: loss 0.036953
[epoch19, step75]: loss 0.036613
[epoch19, step76]: loss 0.034664
[epoch19, step77]: loss 0.034531
[epoch19, step78]: loss 0.036874
[epoch19, step79]: loss 0.034156
[epoch19, step80]: loss 0.037949
[epoch19, step81]: loss 0.033354
[epoch19, step82]: loss 0.034452
[epoch19, step83]: loss 0.035910
[epoch19, step84]: loss 0.036592
[epoch19, step85]: loss 0.034525
[epoch19, step86]: loss 0.033763
[epoch19, step87]: loss 0.037445
[epoch19, step88]: loss 0.033337
[epoch19, step89]: loss 0.036276
[epoch19, step90]: loss 0.033793
[epoch19, step91]: loss 0.033645
[epoch19, step92]: loss 0.036740
[epoch19, step93]: loss 0.036047
[epoch19, step94]: loss 0.033564
[epoch19, step95]: loss 0.034030
[epoch19, step96]: loss 0.035905
[epoch19, step97]: loss 0.034952
[epoch19, step98]: loss 0.036678
[epoch19, step99]: loss 0.033666
[epoch19, step100]: loss 0.033608
[epoch19, step101]: loss 0.037576
[epoch19, step102]: loss 0.035940
[epoch19, step103]: loss 0.034061
[epoch19, step104]: loss 0.033401
[epoch19, step105]: loss 0.036633
[epoch19, step106]: loss 0.034169
[epoch19, step107]: loss 0.036271
[epoch19, step108]: loss 0.033617
[epoch19, step109]: loss 0.033494
[epoch19, step110]: loss 0.036699
[epoch19, step111]: loss 0.035516
[epoch19, step112]: loss 0.033688
[epoch19, step113]: loss 0.034371
[epoch19, step114]: loss 0.035803
[epoch19, step115]: loss 0.033618
[epoch19, step116]: loss 0.036968
[epoch19, step117]: loss 0.033019
[epoch19, step118]: loss 0.034627
[epoch19, step119]: loss 0.036807
[epoch19, step120]: loss 0.036587
[epoch19, step121]: loss 0.033900
[epoch19, step122]: loss 0.033836
[epoch19, step123]: loss 0.036374
[epoch19, step124]: loss 0.034555
[epoch19, step125]: loss 0.036944
[epoch19, step126]: loss 0.033076
[epoch19, step127]: loss 0.033646
[epoch19, step128]: loss 0.036083
[epoch19, step129]: loss 0.035761
[epoch19, step130]: loss 0.033971
[epoch19, step131]: loss 0.033142
[epoch19, step132]: loss 0.036131
[epoch19, step133]: loss 0.033803
[epoch19, step134]: loss 0.035537
[epoch19, step135]: loss 0.033739
[epoch19, step136]: loss 0.034533
[epoch19, step137]: loss 0.036224
[epoch19, step138]: loss 0.036107
[epoch19, step139]: loss 0.033855
[epoch19, step140]: loss 0.034010
[epoch19, step141]: loss 0.036458
[epoch19, step142]: loss 0.034063
[epoch19, step143]: loss 0.035759
[epoch19, step144]: loss 0.033525
[epoch19, step145]: loss 0.034219
[epoch19, step146]: loss 0.036311
[epoch19, step147]: loss 0.036838
[epoch19, step148]: loss 0.033181
[epoch19, step149]: loss 0.033040
[epoch19, step150]: loss 0.035609
[epoch19, step151]: loss 0.033724
[epoch19, step152]: loss 0.035637
[epoch19, step153]: loss 0.033239
[epoch19, step154]: loss 0.033273
[epoch19, step155]: loss 0.036279
[epoch19, step156]: loss 0.035284
[epoch19, step157]: loss 0.033534
[epoch19, step158]: loss 0.034254
[epoch19, step159]: loss 0.035713
[epoch19, step160]: loss 0.034054
[epoch19, step161]: loss 0.036349
[epoch19, step162]: loss 0.033661
[epoch19, step163]: loss 0.034090
[epoch19, step164]: loss 0.035985
[epoch19, step165]: loss 0.035755
[epoch19, step166]: loss 0.034480
[epoch19, step167]: loss 0.033303
[epoch19, step168]: loss 0.036765
[epoch19, step169]: loss 0.033723
[epoch19, step170]: loss 0.036500
[epoch19, step171]: loss 0.033933
[epoch19, step172]: loss 0.034126
[epoch19, step173]: loss 0.036258
[epoch19, step174]: loss 0.035834
[epoch19, step175]: loss 0.034870
[epoch19, step176]: loss 0.033775
[epoch19, step177]: loss 0.036315
[epoch19, step178]: loss 0.034089
[epoch19, step179]: loss 0.035523
[epoch19, step180]: loss 0.033457
[epoch19, step181]: loss 0.034091
[epoch19, step182]: loss 0.036491
[epoch19, step183]: loss 0.036266
[epoch19, step184]: loss 0.034694
[epoch19, step185]: loss 0.033466
[epoch19, step186]: loss 0.035997
[epoch19, step187]: loss 0.033888
[epoch19, step188]: loss 0.035757
[epoch19, step189]: loss 0.033328
[epoch19, step190]: loss 0.032872
[epoch19, step191]: loss 0.036161
[epoch19, step192]: loss 0.036268
[epoch19, step193]: loss 0.032015
[epoch19, step194]: loss 0.032947
[epoch19, step195]: loss 0.036091
[epoch19, step196]: loss 0.034095
[epoch19, step197]: loss 0.036026
[epoch19, step198]: loss 0.032744
[epoch19, step199]: loss 0.034143
[epoch19, step200]: loss 0.036305
[epoch19, step201]: loss 0.036623
[epoch19, step202]: loss 0.033376
[epoch19, step203]: loss 0.033259
[epoch19, step204]: loss 0.036580
[epoch19, step205]: loss 0.033516
[epoch19, step206]: loss 0.035958
[epoch19, step207]: loss 0.033254
[epoch19, step208]: loss 0.033909
[epoch19, step209]: loss 0.036214
[epoch19, step210]: loss 0.036360
[epoch19, step211]: loss 0.033966
[epoch19, step212]: loss 0.033774
[epoch19, step213]: loss 0.035795
[epoch19, step214]: loss 0.033123
[epoch19, step215]: loss 0.036215
[epoch19, step216]: loss 0.033474
[epoch19, step217]: loss 0.033114
[epoch19, step218]: loss 0.036345
[epoch19, step219]: loss 0.035441
[epoch19, step220]: loss 0.033823
[epoch19, step221]: loss 0.033726
[epoch19, step222]: loss 0.036436
[epoch19, step223]: loss 0.034545
[epoch19, step224]: loss 0.035637
[epoch19, step225]: loss 0.033385
[epoch19, step226]: loss 0.033047
[epoch19, step227]: loss 0.035513
[epoch19, step228]: loss 0.036550
[epoch19, step229]: loss 0.032816
[epoch19, step230]: loss 0.034184
[epoch19, step231]: loss 0.036557
[epoch19, step232]: loss 0.033617
[epoch19, step233]: loss 0.035877
[epoch19, step234]: loss 0.032742
[epoch19, step235]: loss 0.034266
[epoch19, step236]: loss 0.035917
[epoch19, step237]: loss 0.035617
[epoch19, step238]: loss 0.033808
[epoch19, step239]: loss 0.032910
[epoch19, step240]: loss 0.035166
[epoch19, step241]: loss 0.034030
[epoch19, step242]: loss 0.036051
[epoch19, step243]: loss 0.034067
[epoch19, step244]: loss 0.033675
[epoch19, step245]: loss 0.035708
[epoch19, step246]: loss 0.035705
[epoch19, step247]: loss 0.033780
[epoch19, step248]: loss 0.033241
[epoch19, step249]: loss 0.035123
[epoch19, step250]: loss 0.034159
[epoch19, step251]: loss 0.036118
[epoch19, step252]: loss 0.034169
[epoch19, step253]: loss 0.033148
[epoch19, step254]: loss 0.035889
[epoch19, step255]: loss 0.035855
[epoch19, step256]: loss 0.033522
[epoch19, step257]: loss 0.033671
[epoch19, step258]: loss 0.036376
[epoch19, step259]: loss 0.034307
[epoch19, step260]: loss 0.035886
[epoch19, step261]: loss 0.034039
[epoch19, step262]: loss 0.034411
[epoch19, step263]: loss 0.036015
[epoch19, step264]: loss 0.035550
[epoch19, step265]: loss 0.033859
[epoch19, step266]: loss 0.033643
[epoch19, step267]: loss 0.036484
[epoch19, step268]: loss 0.034007
[epoch19, step269]: loss 0.036465
[epoch19, step270]: loss 0.033325
[epoch19, step271]: loss 0.033666
[epoch19, step272]: loss 0.036694
[epoch19, step273]: loss 0.035913
[epoch19, step274]: loss 0.034239
[epoch19, step275]: loss 0.033354
[epoch19, step276]: loss 0.035934
[epoch19, step277]: loss 0.034515
[epoch19, step278]: loss 0.036720
[epoch19, step279]: loss 0.033041
[epoch19, step280]: loss 0.034121
[epoch19, step281]: loss 0.036655
[epoch19, step282]: loss 0.036395
[epoch19, step283]: loss 0.033318
[epoch19, step284]: loss 0.033471
[epoch19, step285]: loss 0.036715
[epoch19, step286]: loss 0.033432
[epoch19, step287]: loss 0.036836
[epoch19, step288]: loss 0.033084
[epoch19, step289]: loss 0.034325
[epoch19, step290]: loss 0.036708
[epoch19, step291]: loss 0.035886
[epoch19, step292]: loss 0.033198
[epoch19, step293]: loss 0.034298
[epoch19, step294]: loss 0.036063
[epoch19, step295]: loss 0.033725
[epoch19, step296]: loss 0.037658
[epoch19, step297]: loss 0.033208
[epoch19, step298]: loss 0.033971
[epoch19, step299]: loss 0.035338
[epoch19, step300]: loss 0.035993
[epoch19, step301]: loss 0.033752
[epoch19, step302]: loss 0.034072
[epoch19, step303]: loss 0.036327
[epoch19, step304]: loss 0.033625
[epoch19, step305]: loss 0.035544
[epoch19, step306]: loss 0.034396
[epoch19, step307]: loss 0.033342
[epoch19, step308]: loss 0.036673
[epoch19, step309]: loss 0.035987
[epoch19, step310]: loss 0.033736
[epoch19, step311]: loss 0.034091
[epoch19, step312]: loss 0.035681
[epoch19, step313]: loss 0.033781
[epoch19, step314]: loss 0.035904
[epoch19, step315]: loss 0.034181
[epoch19, step316]: loss 0.033436
[epoch19, step317]: loss 0.036841
[epoch19, step318]: loss 0.035813
[epoch19, step319]: loss 0.033111
[epoch19, step320]: loss 0.032627
[epoch19, step321]: loss 0.035649
[epoch19, step322]: loss 0.033785
[epoch19, step323]: loss 0.035367
[epoch19, step324]: loss 0.034440
[epoch19, step325]: loss 0.033709
[epoch19, step326]: loss 0.035979
[epoch19, step327]: loss 0.035128
[epoch19, step328]: loss 0.034071
[epoch19, step329]: loss 0.033533
[epoch19, step330]: loss 0.035062
[epoch19, step331]: loss 0.034279
[epoch19, step332]: loss 0.036222
[epoch19, step333]: loss 0.033300
[epoch19, step334]: loss 0.034073
[epoch19, step335]: loss 0.036826
[epoch19, step336]: loss 0.036503
[epoch19, step337]: loss 0.034422
[epoch19, step338]: loss 0.033343
[epoch19, step339]: loss 0.035915
[epoch19, step340]: loss 0.034589
[epoch19, step341]: loss 0.035420
[epoch19, step342]: loss 0.032966
[epoch19, step343]: loss 0.033984
[epoch19, step344]: loss 0.035766
[epoch19, step345]: loss 0.035002
[epoch19, step346]: loss 0.033817
[epoch19, step347]: loss 0.033363
[epoch19, step348]: loss 0.036027
[epoch19, step349]: loss 0.034910
[epoch19, step350]: loss 0.035581
[epoch19, step351]: loss 0.032733
[epoch19, step352]: loss 0.033287
[epoch19, step353]: loss 0.035679
[epoch19, step354]: loss 0.034825
[epoch19, step355]: loss 0.032549
[epoch19, step356]: loss 0.034129
[epoch19, step357]: loss 0.035671
[epoch19, step358]: loss 0.032207
[epoch19, step359]: loss 0.038603
[epoch19, step360]: loss 0.032451
[epoch19, step361]: loss 0.033499
[epoch19, step362]: loss 0.036610
[epoch19, step363]: loss 0.035286
[epoch19, step364]: loss 0.033450
[epoch19, step365]: loss 0.033119
[epoch19, step366]: loss 0.036045
[epoch19, step367]: loss 0.033944
[epoch19, step368]: loss 0.035286
[epoch19, step369]: loss 0.033109
[epoch19, step370]: loss 0.034129
[epoch19, step371]: loss 0.036718
[epoch19, step372]: loss 0.035315
[epoch19, step373]: loss 0.032968
[epoch19, step374]: loss 0.032855
[epoch19, step375]: loss 0.036672
[epoch19, step376]: loss 0.033761
[epoch19, step377]: loss 0.036083
[epoch19, step378]: loss 0.033808
[epoch19, step379]: loss 0.033840
[epoch19, step380]: loss 0.036747
[epoch19, step381]: loss 0.035305
[epoch19, step382]: loss 0.033864
[epoch19, step383]: loss 0.032837
[epoch19, step384]: loss 0.034992
[epoch19, step385]: loss 0.033765
[epoch19, step386]: loss 0.036856
[epoch19, step387]: loss 0.033402
[epoch19, step388]: loss 0.034571
[epoch19, step389]: loss 0.036215
[epoch19, step390]: loss 0.036958
[epoch19, step391]: loss 0.033104
[epoch19, step392]: loss 0.034095
[epoch19, step393]: loss 0.035757
[epoch19, step394]: loss 0.033693
[epoch19, step395]: loss 0.035695
[epoch19, step396]: loss 0.033158
[epoch19, step397]: loss 0.033277
[epoch19, step398]: loss 0.036089
[epoch19, step399]: loss 0.035434
[epoch19, step400]: loss 0.033464
[epoch19, step401]: loss 0.033099
[epoch19, step402]: loss 0.036088
[epoch19, step403]: loss 0.033740
[epoch19, step404]: loss 0.036301
[epoch19, step405]: loss 0.034413
[epoch19, step406]: loss 0.034021
[epoch19, step407]: loss 0.036168
[epoch19, step408]: loss 0.036092
[epoch19, step409]: loss 0.034918
[epoch19, step410]: loss 0.034166
[epoch19, step411]: loss 0.036189
[epoch19, step412]: loss 0.033345
[epoch19, step413]: loss 0.036009
[epoch19, step414]: loss 0.033379
[epoch19, step415]: loss 0.033711
[epoch19, step416]: loss 0.035247
[epoch19, step417]: loss 0.035693
[epoch19, step418]: loss 0.033699
[epoch19, step419]: loss 0.032747
[epoch19, step420]: loss 0.035816
[epoch19, step421]: loss 0.033732
[epoch19, step422]: loss 0.035797
[epoch19, step423]: loss 0.033482
[epoch19, step424]: loss 0.033359
[epoch19, step425]: loss 0.036288
[epoch19, step426]: loss 0.036235
[epoch19, step427]: loss 0.033885
[epoch19, step428]: loss 0.033698
[epoch19, step429]: loss 0.036434
[epoch19, step430]: loss 0.033980
[epoch19, step431]: loss 0.036434
[epoch19, step432]: loss 0.033157
[epoch19, step433]: loss 0.034532
[epoch19, step434]: loss 0.036085
[epoch19, step435]: loss 0.036294
[epoch19, step436]: loss 0.033302
[epoch19, step437]: loss 0.033330
[epoch19, step438]: loss 0.036314
[epoch19, step439]: loss 0.033985
[epoch19, step440]: loss 0.036056
[epoch19, step441]: loss 0.033169
[epoch19, step442]: loss 0.033422
[epoch19, step443]: loss 0.036560
[epoch19, step444]: loss 0.035210
[epoch19, step445]: loss 0.034061
[epoch19, step446]: loss 0.033727
[epoch19, step447]: loss 0.036328
[epoch19, step448]: loss 0.033721
[epoch19, step449]: loss 0.035701
[epoch19, step450]: loss 0.033073
[epoch19, step451]: loss 0.033562
[epoch19, step452]: loss 0.035629
[epoch19, step453]: loss 0.036307
[epoch19, step454]: loss 0.033391
[epoch19, step455]: loss 0.033825
[epoch19, step456]: loss 0.035767
[epoch19, step457]: loss 0.033998
[epoch19, step458]: loss 0.035794
[epoch19, step459]: loss 0.034315
[epoch19, step460]: loss 0.033987
[epoch19, step461]: loss 0.036841
[epoch19, step462]: loss 0.034993
[epoch19, step463]: loss 0.033669
[epoch19, step464]: loss 0.033185
[epoch19, step465]: loss 0.037070
[epoch19, step466]: loss 0.033661
[epoch19, step467]: loss 0.035555
[epoch19, step468]: loss 0.033255
[epoch19, step469]: loss 0.033520
[epoch19, step470]: loss 0.036028
[epoch19, step471]: loss 0.035201
[epoch19, step472]: loss 0.033958
[epoch19, step473]: loss 0.033133
[epoch19, step474]: loss 0.035776
[epoch19, step475]: loss 0.033753
[epoch19, step476]: loss 0.036171
[epoch19, step477]: loss 0.033763
[epoch19, step478]: loss 0.032966
[epoch19, step479]: loss 0.036003
[epoch19, step480]: loss 0.035492
[epoch19, step481]: loss 0.033063
[epoch19, step482]: loss 0.033241
[epoch19, step483]: loss 0.036417
[epoch19, step484]: loss 0.033657
[epoch19, step485]: loss 0.036208
[epoch19, step486]: loss 0.033425
[epoch19, step487]: loss 0.033069
[epoch19, step488]: loss 0.036596
[epoch19, step489]: loss 0.034916
[epoch19, step490]: loss 0.034122
[epoch19, step491]: loss 0.033585
[epoch19, step492]: loss 0.035740
[epoch19, step493]: loss 0.033534
[epoch19, step494]: loss 0.035221
[epoch19, step495]: loss 0.034268
[epoch19, step496]: loss 0.033868
[epoch19, step497]: loss 0.036009
[epoch19, step498]: loss 0.035444
[epoch19, step499]: loss 0.033802
[epoch19, step500]: loss 0.033560
[epoch19, step501]: loss 0.035479
[epoch19, step502]: loss 0.033544
[epoch19, step503]: loss 0.036180
[epoch19, step504]: loss 0.033288
[epoch19, step505]: loss 0.032638
[epoch19, step506]: loss 0.036887
[epoch19, step507]: loss 0.037114
[epoch19, step508]: loss 0.033999
[epoch19, step509]: loss 0.033679
[epoch19, step510]: loss 0.036933
[epoch19, step511]: loss 0.034544
[epoch19, step512]: loss 0.036814
[epoch19, step513]: loss 0.034541
[epoch19, step514]: loss 0.033912
[epoch19, step515]: loss 0.035943
[epoch19, step516]: loss 0.036329
[epoch19, step517]: loss 0.033991
[epoch19, step518]: loss 0.033378
[epoch19, step519]: loss 0.036378
[epoch19, step520]: loss 0.033469
[epoch19, step521]: loss 0.035873
[epoch19, step522]: loss 0.033483
[epoch19, step523]: loss 0.033690
[epoch19, step524]: loss 0.035203
[epoch19, step525]: loss 0.036156
[epoch19, step526]: loss 0.033644
[epoch19, step527]: loss 0.033151
[epoch19, step528]: loss 0.036021
[epoch19, step529]: loss 0.033833
[epoch19, step530]: loss 0.036810
[epoch19, step531]: loss 0.033007
[epoch19, step532]: loss 0.034018
[epoch19, step533]: loss 0.037056
[epoch19, step534]: loss 0.035305
[epoch19, step535]: loss 0.034193
[epoch19, step536]: loss 0.033519
[epoch19, step537]: loss 0.036001
[epoch19, step538]: loss 0.033906
[epoch19, step539]: loss 0.035453
[epoch19, step540]: loss 0.032804
[epoch19, step541]: loss 0.033088
[epoch19, step542]: loss 0.035915
[epoch19, step543]: loss 0.035386
[epoch19, step544]: loss 0.033553
[epoch19, step545]: loss 0.032723
[epoch19, step546]: loss 0.036315
[epoch19, step547]: loss 0.033584
[epoch19, step548]: loss 0.036070
[epoch19, step549]: loss 0.034187
[epoch19, step550]: loss 0.033881
[epoch19, step551]: loss 0.035608
[epoch19, step552]: loss 0.035143
[epoch19, step553]: loss 0.034137
[epoch19, step554]: loss 0.033345
[epoch19, step555]: loss 0.035624
[epoch19, step556]: loss 0.033498
[epoch19, step557]: loss 0.035240
[epoch19, step558]: loss 0.033579
[epoch19, step559]: loss 0.033079
[epoch19, step560]: loss 0.036085
[epoch19, step561]: loss 0.035322
[epoch19, step562]: loss 0.033534
[epoch19, step563]: loss 0.035961
[epoch19, step564]: loss 0.041752
[epoch19, step565]: loss 0.040153
[epoch19, step566]: loss 0.048895
[epoch19, step567]: loss 0.040791
[epoch19, step568]: loss 0.041616
[epoch19, step569]: loss 0.037372
[epoch19, step570]: loss 0.045232
[epoch19, step571]: loss 0.040848
[epoch19, step572]: loss 0.037547
[epoch19, step573]: loss 0.038755
[epoch19, step574]: loss 0.041634
[epoch19, step575]: loss 0.032532
[epoch19, step576]: loss 0.033838
[epoch19, step577]: loss 0.037779
[epoch19, step578]: loss 0.030913
[epoch19, step579]: loss 0.040678
[epoch19, step580]: loss 0.031206
[epoch19, step581]: loss 0.037034
[epoch19, step582]: loss 0.037289
[epoch19, step583]: loss 0.036573
[epoch19, step584]: loss 0.034097
[epoch19, step585]: loss 0.036587
[epoch19, step586]: loss 0.034621
[epoch19, step587]: loss 0.041190
[epoch19, step588]: loss 0.035257
[epoch19, step589]: loss 0.036081
[epoch19, step590]: loss 0.040243
[epoch19, step591]: loss 0.031261
[epoch19, step592]: loss 0.037735
[epoch19, step593]: loss 0.033415
[epoch19, step594]: loss 0.038364
[epoch19, step595]: loss 0.039540
[epoch19, step596]: loss 0.037359
[epoch19, step597]: loss 0.036476
[epoch19, step598]: loss 0.036683
[epoch19, step599]: loss 0.034487
[epoch19, step600]: loss 0.038122
[epoch19, step601]: loss 0.030764
[epoch19, step602]: loss 0.033894
[epoch19, step603]: loss 0.036577
[epoch19, step604]: loss 0.039692
[epoch19, step605]: loss 0.035763
[epoch19, step606]: loss 0.034301
[epoch19, step607]: loss 0.038026
[epoch19, step608]: loss 0.037408
[epoch19, step609]: loss 0.037432
[epoch19, step610]: loss 0.039519
[epoch19, step611]: loss 0.039098
[epoch19, step612]: loss 0.035205
[epoch19, step613]: loss 0.030143
[epoch19, step614]: loss 0.035602
[epoch19, step615]: loss 0.040365
[epoch19, step616]: loss 0.033907
[epoch19, step617]: loss 0.033669
[epoch19, step618]: loss 0.037649
[epoch19, step619]: loss 0.038674
[epoch19, step620]: loss 0.035401
[epoch19, step621]: loss 0.037475
[epoch19, step622]: loss 0.031260
[epoch19, step623]: loss 0.032889
[epoch19, step624]: loss 0.037944
[epoch19, step625]: loss 0.036560
[epoch19, step626]: loss 0.039484
[epoch19, step627]: loss 0.032944
[epoch19, step628]: loss 0.035541
[epoch19, step629]: loss 0.030633
[epoch19, step630]: loss 0.032565
[epoch19, step631]: loss 0.041768
[epoch19, step632]: loss 0.034709
[epoch19, step633]: loss 0.034939
[epoch19, step634]: loss 0.037114
[epoch19, step635]: loss 0.036956
[epoch19, step636]: loss 0.032206
[epoch19, step637]: loss 0.038105
[epoch19, step638]: loss 0.038451
[epoch19, step639]: loss 0.032311
[epoch19, step640]: loss 0.040085
[epoch19, step641]: loss 0.039639
[epoch19, step642]: loss 0.034968
[epoch19, step643]: loss 0.035053
[epoch19, step644]: loss 0.036252
[epoch19, step645]: loss 0.034106
[epoch19, step646]: loss 0.035407
[epoch19, step647]: loss 0.034439
[epoch19, step648]: loss 0.034332
[epoch19, step649]: loss 0.037319
[epoch19, step650]: loss 0.032804
[epoch19, step651]: loss 0.037404
[epoch19, step652]: loss 0.037699
[epoch19, step653]: loss 0.037829
[epoch19, step654]: loss 0.033132
[epoch19, step655]: loss 0.034789
[epoch19, step656]: loss 0.033414
[epoch19, step657]: loss 0.038560
[epoch19, step658]: loss 0.035560
[epoch19, step659]: loss 0.037567
[epoch19, step660]: loss 0.033087
[epoch19, step661]: loss 0.036421
[epoch19, step662]: loss 0.033906
[epoch19, step663]: loss 0.032711
[epoch19, step664]: loss 0.036647
[epoch19, step665]: loss 0.037397
[epoch19, step666]: loss 0.037360
[epoch19, step667]: loss 0.036989
[epoch19, step668]: loss 0.033385
[epoch19, step669]: loss 0.037433
[epoch19, step670]: loss 0.037742
[epoch19, step671]: loss 0.031795
[epoch19, step672]: loss 0.034786
[epoch19, step673]: loss 0.032921
[epoch19, step674]: loss 0.031640
[epoch19, step675]: loss 0.031085
[epoch19, step676]: loss 0.033805
[epoch19, step677]: loss 0.035489
[epoch19, step678]: loss 0.032866
[epoch19, step679]: loss 0.034907
[epoch19, step680]: loss 0.040629
[epoch19, step681]: loss 0.031978
[epoch19, step682]: loss 0.036333
[epoch19, step683]: loss 0.035251
[epoch19, step684]: loss 0.035740
[epoch19, step685]: loss 0.035316
[epoch19, step686]: loss 0.039442
[epoch19, step687]: loss 0.036105
[epoch19, step688]: loss 0.034946
[epoch19, step689]: loss 0.035842
[epoch19, step690]: loss 0.035845
[epoch19, step691]: loss 0.034953
[epoch19, step692]: loss 0.034599
[epoch19, step693]: loss 0.038130
[epoch19, step694]: loss 0.032578
[epoch19, step695]: loss 0.038316
[epoch19, step696]: loss 0.035273
[epoch19, step697]: loss 0.037797
[epoch19, step698]: loss 0.035377
[epoch19, step699]: loss 0.034103
[epoch19, step700]: loss 0.031557
[epoch19, step701]: loss 0.036087
[epoch19, step702]: loss 0.031717
[epoch19, step703]: loss 0.033950
[epoch19, step704]: loss 0.036233
[epoch19, step705]: loss 0.036083
[epoch19, step706]: loss 0.033915
[epoch19, step707]: loss 0.033523
[epoch19, step708]: loss 0.035097
[epoch19, step709]: loss 0.037407
[epoch19, step710]: loss 0.032739
[epoch19, step711]: loss 0.037521
[epoch19, step712]: loss 0.037339
[epoch19, step713]: loss 0.037375
[epoch19, step714]: loss 0.031923
[epoch19, step715]: loss 0.033718
[epoch19, step716]: loss 0.035878
[epoch19, step717]: loss 0.033311
[epoch19, step718]: loss 0.035879
[epoch19, step719]: loss 0.045015
[epoch19, step720]: loss 0.035021
[epoch19, step721]: loss 0.033032
[epoch19, step722]: loss 0.040650
[epoch19, step723]: loss 0.037346
[epoch19, step724]: loss 0.033048
[epoch19, step725]: loss 0.036688
[epoch19, step726]: loss 0.032336
[epoch19, step727]: loss 0.034661
[epoch19, step728]: loss 0.037381
[epoch19, step729]: loss 0.032543
[epoch19, step730]: loss 0.032983
[epoch19, step731]: loss 0.036290
[epoch19, step732]: loss 0.035718
[epoch19, step733]: loss 0.034482
[epoch19, step734]: loss 0.034271
[epoch19, step735]: loss 0.038264
[epoch19, step736]: loss 0.036000
[epoch19, step737]: loss 0.037240
[epoch19, step738]: loss 0.030680
[epoch19, step739]: loss 0.036649
[epoch19, step740]: loss 0.032869
[epoch19, step741]: loss 0.036622
[epoch19, step742]: loss 0.032910
[epoch19, step743]: loss 0.034089
[epoch19, step744]: loss 0.033756
[epoch19, step745]: loss 0.033842
[epoch19, step746]: loss 0.036549
[epoch19, step747]: loss 0.038938
[epoch19, step748]: loss 0.036849
[epoch19, step749]: loss 0.035733
[epoch19, step750]: loss 0.038016
[epoch19, step751]: loss 0.033315
[epoch19, step752]: loss 0.035332
[epoch19, step753]: loss 0.035794
[epoch19, step754]: loss 0.034224
[epoch19, step755]: loss 0.036100
[epoch19, step756]: loss 0.033739
[epoch19, step757]: loss 0.030322
[epoch19, step758]: loss 0.034214
[epoch19, step759]: loss 0.032975
[epoch19, step760]: loss 0.034739
[epoch19, step761]: loss 0.037098
[epoch19, step762]: loss 0.031589
[epoch19, step763]: loss 0.035302
[epoch19, step764]: loss 0.034855
[epoch19, step765]: loss 0.036765
[epoch19, step766]: loss 0.036550
[epoch19, step767]: loss 0.038548
[epoch19, step768]: loss 0.031011
[epoch19, step769]: loss 0.035670
[epoch19, step770]: loss 0.034877
[epoch19, step771]: loss 0.033071
[epoch19, step772]: loss 0.038189
[epoch19, step773]: loss 0.035812
[epoch19, step774]: loss 0.035259
[epoch19, step775]: loss 0.029824
[epoch19, step776]: loss 0.037568
[epoch19, step777]: loss 0.033720
[epoch19, step778]: loss 0.037202
[epoch19, step779]: loss 0.035220
[epoch19, step780]: loss 0.029930
[epoch19, step781]: loss 0.034935
[epoch19, step782]: loss 0.032264
[epoch19, step783]: loss 0.030513
[epoch19, step784]: loss 0.031024
[epoch19, step785]: loss 0.031271
[epoch19, step786]: loss 0.034604
[epoch19, step787]: loss 0.034773
[epoch19, step788]: loss 0.036435
[epoch19, step789]: loss 0.035067
[epoch19, step790]: loss 0.034691
[epoch19, step791]: loss 0.037941
[epoch19, step792]: loss 0.035476
[epoch19, step793]: loss 0.037063
[epoch19, step794]: loss 0.030274
[epoch19, step795]: loss 0.034934
[epoch19, step796]: loss 0.037737
[epoch19, step797]: loss 0.037000
[epoch19, step798]: loss 0.037547
[epoch19, step799]: loss 0.037423
[epoch19, step800]: loss 0.031737
[epoch19, step801]: loss 0.034126
[epoch19, step802]: loss 0.033343
[epoch19, step803]: loss 0.037249
[epoch19, step804]: loss 0.037247
[epoch19, step805]: loss 0.037990
[epoch19, step806]: loss 0.032869
[epoch19, step807]: loss 0.031508
[epoch19, step808]: loss 0.034137
[epoch19, step809]: loss 0.032496
[epoch19, step810]: loss 0.035981
[epoch19, step811]: loss 0.034996
[epoch19, step812]: loss 0.033547
[epoch19, step813]: loss 0.034196
[epoch19, step814]: loss 0.036688
[epoch19, step815]: loss 0.033799
[epoch19, step816]: loss 0.034424
[epoch19, step817]: loss 0.035391
[epoch19, step818]: loss 0.032665
[epoch19, step819]: loss 0.031211
[epoch19, step820]: loss 0.034453
[epoch19, step821]: loss 0.031759
[epoch19, step822]: loss 0.039738
[epoch19, step823]: loss 0.033745
[epoch19, step824]: loss 0.036001
[epoch19, step825]: loss 0.036112
[epoch19, step826]: loss 0.035166
[epoch19, step827]: loss 0.037522
[epoch19, step828]: loss 0.039467
[epoch19, step829]: loss 0.038728
[epoch19, step830]: loss 0.033414
[epoch19, step831]: loss 0.037019
[epoch19, step832]: loss 0.031489
[epoch19, step833]: loss 0.038611
[epoch19, step834]: loss 0.037061
[epoch19, step835]: loss 0.030999
[epoch19, step836]: loss 0.039006
[epoch19, step837]: loss 0.036246
[epoch19, step838]: loss 0.034864
[epoch19, step839]: loss 0.039069
[epoch19, step840]: loss 0.031298
[epoch19, step841]: loss 0.035107
[epoch19, step842]: loss 0.037658
[epoch19, step843]: loss 0.036054
[epoch19, step844]: loss 0.036079
[epoch19, step845]: loss 0.032015
[epoch19, step846]: loss 0.039033
[epoch19, step847]: loss 0.036784
[epoch19, step848]: loss 0.035701
[epoch19, step849]: loss 0.033905
[epoch19, step850]: loss 0.033414
[epoch19, step851]: loss 0.035133
[epoch19, step852]: loss 0.033308
[epoch19, step853]: loss 0.040386
[epoch19, step854]: loss 0.034248
[epoch19, step855]: loss 0.037916
[epoch19, step856]: loss 0.031609
[epoch19, step857]: loss 0.034522
[epoch19, step858]: loss 0.034718
[epoch19, step859]: loss 0.034273
[epoch19, step860]: loss 0.032582
[epoch19, step861]: loss 0.032644
[epoch19, step862]: loss 0.033053
[epoch19, step863]: loss 0.031396
[epoch19, step864]: loss 0.037110
[epoch19, step865]: loss 0.033944
[epoch19, step866]: loss 0.035366
[epoch19, step867]: loss 0.036842
[epoch19, step868]: loss 0.036380
[epoch19, step869]: loss 0.033990
[epoch19, step870]: loss 0.041426
[epoch19, step871]: loss 0.033621
[epoch19, step872]: loss 0.035938
[epoch19, step873]: loss 0.035859
[epoch19, step874]: loss 0.034683
[epoch19, step875]: loss 0.034041
[epoch19, step876]: loss 0.036558
[epoch19, step877]: loss 0.029951
[epoch19, step878]: loss 0.033479
[epoch19, step879]: loss 0.037687
[epoch19, step880]: loss 0.036481
[epoch19, step881]: loss 0.032532
[epoch19, step882]: loss 0.033886
[epoch19, step883]: loss 0.033983
[epoch19, step884]: loss 0.037167
[epoch19, step885]: loss 0.035110
[epoch19, step886]: loss 0.035982
[epoch19, step887]: loss 0.034828
[epoch19, step888]: loss 0.035163
[epoch19, step889]: loss 0.034645
[epoch19, step890]: loss 0.034126
[epoch19, step891]: loss 0.036100
[epoch19, step892]: loss 0.030610
[epoch19, step893]: loss 0.034371
[epoch19, step894]: loss 0.035452
[epoch19, step895]: loss 0.032265
[epoch19, step896]: loss 0.032768
[epoch19, step897]: loss 0.035942
[epoch19, step898]: loss 0.036763
[epoch19, step899]: loss 0.039054
[epoch19, step900]: loss 0.036110
[epoch19, step901]: loss 0.036908
[epoch19, step902]: loss 0.034004
[epoch19, step903]: loss 0.035237
[epoch19, step904]: loss 0.037308
[epoch19, step905]: loss 0.037885
[epoch19, step906]: loss 0.031839
[epoch19, step907]: loss 0.033658
[epoch19, step908]: loss 0.031475
[epoch19, step909]: loss 0.036933
[epoch19, step910]: loss 0.033350
[epoch19, step911]: loss 0.035234
[epoch19, step912]: loss 0.033065
[epoch19, step913]: loss 0.034400
[epoch19, step914]: loss 0.039280
[epoch19, step915]: loss 0.033716
[epoch19, step916]: loss 0.033222
[epoch19, step917]: loss 0.035489
[epoch19, step918]: loss 0.039510
[epoch19, step919]: loss 0.034905
[epoch19, step920]: loss 0.037792
[epoch19, step921]: loss 0.033915
[epoch19, step922]: loss 0.034436
[epoch19, step923]: loss 0.033036
[epoch19, step924]: loss 0.029827
[epoch19, step925]: loss 0.035774
[epoch19, step926]: loss 0.034796
[epoch19, step927]: loss 0.035128
[epoch19, step928]: loss 0.034739
[epoch19, step929]: loss 0.038158
[epoch19, step930]: loss 0.035761
[epoch19, step931]: loss 0.036970
[epoch19, step932]: loss 0.031243
[epoch19, step933]: loss 0.038769
[epoch19, step934]: loss 0.032953
[epoch19, step935]: loss 0.034309
[epoch19, step936]: loss 0.032256
[epoch19, step937]: loss 0.036139
[epoch19, step938]: loss 0.038612
[epoch19, step939]: loss 0.031112
[epoch19, step940]: loss 0.033831
[epoch19, step941]: loss 0.038409
[epoch19, step942]: loss 0.036042
[epoch19, step943]: loss 0.033547
[epoch19, step944]: loss 0.037946
[epoch19, step945]: loss 0.031030
[epoch19, step946]: loss 0.035490
[epoch19, step947]: loss 0.038865
[epoch19, step948]: loss 0.030020
[epoch19, step949]: loss 0.033967
[epoch19, step950]: loss 0.038073
[epoch19, step951]: loss 0.039329
[epoch19, step952]: loss 0.034412
[epoch19, step953]: loss 0.036712
[epoch19, step954]: loss 0.033281
[epoch19, step955]: loss 0.041705
[epoch19, step956]: loss 0.051498
[epoch19, step957]: loss 0.047769
[epoch19, step958]: loss 0.045616
[epoch19, step959]: loss 0.048280
[epoch19, step960]: loss 0.045820
[epoch19, step961]: loss 0.046064
[epoch19, step962]: loss 0.044583
[epoch19, step963]: loss 0.042450
[epoch19, step964]: loss 0.042773
[epoch19, step965]: loss 0.042389
[epoch19, step966]: loss 0.042488
[epoch19, step967]: loss 0.041609
[epoch19, step968]: loss 0.043388
[epoch19, step969]: loss 0.043779
[epoch19, step970]: loss 0.042449
[epoch19, step971]: loss 0.042137
[epoch19, step972]: loss 0.042784
[epoch19, step973]: loss 0.042080
[epoch19, step974]: loss 0.043479
[epoch19, step975]: loss 0.041572
[epoch19, step976]: loss 0.040738
[epoch19, step977]: loss 0.042702
[epoch19, step978]: loss 0.042126
[epoch19, step979]: loss 0.041081
[epoch19, step980]: loss 0.040541
[epoch19, step981]: loss 0.041816
[epoch19, step982]: loss 0.041522
[epoch19, step983]: loss 0.042022
[epoch19, step984]: loss 0.040885
[epoch19, step985]: loss 0.040673
[epoch19, step986]: loss 0.042781
[epoch19, step987]: loss 0.041598
[epoch19, step988]: loss 0.041667
[epoch19, step989]: loss 0.041177
[epoch19, step990]: loss 0.040846
[epoch19, step991]: loss 0.041704
[epoch19, step992]: loss 0.041079
[epoch19, step993]: loss 0.040896
[epoch19, step994]: loss 0.039921
[epoch19, step995]: loss 0.042062
[epoch19, step996]: loss 0.041267
[epoch19, step997]: loss 0.040807
[epoch19, step998]: loss 0.041750
[epoch19, step999]: loss 0.041059
[epoch19, step1000]: loss 0.041083
[epoch19, step1001]: loss 0.041934
[epoch19, step1002]: loss 0.040844
[epoch19, step1003]: loss 0.039753
[epoch19, step1004]: loss 0.042311
[epoch19, step1005]: loss 0.040298
[epoch19, step1006]: loss 0.041025
[epoch19, step1007]: loss 0.039959
[epoch19, step1008]: loss 0.040569
[epoch19, step1009]: loss 0.040883
[epoch19, step1010]: loss 0.041490
[epoch19, step1011]: loss 0.040205
[epoch19, step1012]: loss 0.039496
[epoch19, step1013]: loss 0.041617
[epoch19, step1014]: loss 0.041086
[epoch19, step1015]: loss 0.040825
[epoch19, step1016]: loss 0.039907
[epoch19, step1017]: loss 0.040023
[epoch19, step1018]: loss 0.041019
[epoch19, step1019]: loss 0.041420
[epoch19, step1020]: loss 0.040756
[epoch19, step1021]: loss 0.040411
[epoch19, step1022]: loss 0.041655
[epoch19, step1023]: loss 0.041267
[epoch19, step1024]: loss 0.043093
[epoch19, step1025]: loss 0.040116
[epoch19, step1026]: loss 0.040230
[epoch19, step1027]: loss 0.041074
[epoch19, step1028]: loss 0.040844
[epoch19, step1029]: loss 0.040044
[epoch19, step1030]: loss 0.039238
[epoch19, step1031]: loss 0.040926
[epoch19, step1032]: loss 0.040515
[epoch19, step1033]: loss 0.040556
[epoch19, step1034]: loss 0.039400
[epoch19, step1035]: loss 0.040058
[epoch19, step1036]: loss 0.040934
[epoch19, step1037]: loss 0.040887
[epoch19, step1038]: loss 0.039837
[epoch19, step1039]: loss 0.040322
[epoch19, step1040]: loss 0.041394
[epoch19, step1041]: loss 0.040555
[epoch19, step1042]: loss 0.040738
[epoch19, step1043]: loss 0.039746
[epoch19, step1044]: loss 0.041035
[epoch19, step1045]: loss 0.041800
[epoch19, step1046]: loss 0.041330
[epoch19, step1047]: loss 0.040321
[epoch19, step1048]: loss 0.040424
[epoch19, step1049]: loss 0.042359
[epoch19, step1050]: loss 0.040839
[epoch19, step1051]: loss 0.040816
[epoch19, step1052]: loss 0.039945
[epoch19, step1053]: loss 0.040648
[epoch19, step1054]: loss 0.041813
[epoch19, step1055]: loss 0.041410
[epoch19, step1056]: loss 0.040409
[epoch19, step1057]: loss 0.039987
[epoch19, step1058]: loss 0.041968
[epoch19, step1059]: loss 0.041165
[epoch19, step1060]: loss 0.041157
[epoch19, step1061]: loss 0.039785
[epoch19, step1062]: loss 0.041765
[epoch19, step1063]: loss 0.041698
[epoch19, step1064]: loss 0.041446
[epoch19, step1065]: loss 0.040878
[epoch19, step1066]: loss 0.039359
[epoch19, step1067]: loss 0.042240
[epoch19, step1068]: loss 0.040479
[epoch19, step1069]: loss 0.040525
[epoch19, step1070]: loss 0.040802
[epoch19, step1071]: loss 0.041844
[epoch19, step1072]: loss 0.041366
[epoch19, step1073]: loss 0.041558
[epoch19, step1074]: loss 0.040603
[epoch19, step1075]: loss 0.039974
[epoch19, step1076]: loss 0.041812
[epoch19, step1077]: loss 0.040896
[epoch19, step1078]: loss 0.041106
[epoch19, step1079]: loss 0.040313
[epoch19, step1080]: loss 0.040634
[epoch19, step1081]: loss 0.040771
[epoch19, step1082]: loss 0.040795
[epoch19, step1083]: loss 0.040440
[epoch19, step1084]: loss 0.039732
[epoch19, step1085]: loss 0.041009
[epoch19, step1086]: loss 0.040305
[epoch19, step1087]: loss 0.040433
[epoch19, step1088]: loss 0.039767
[epoch19, step1089]: loss 0.040099
[epoch19, step1090]: loss 0.041050
[epoch19, step1091]: loss 0.041198
[epoch19, step1092]: loss 0.040233
[epoch19, step1093]: loss 0.039615
[epoch19, step1094]: loss 0.040624
[epoch19, step1095]: loss 0.040641
[epoch19, step1096]: loss 0.040300
[epoch19, step1097]: loss 0.040238
[epoch19, step1098]: loss 0.040423
[epoch19, step1099]: loss 0.041377
[epoch19, step1100]: loss 0.041949
[epoch19, step1101]: loss 0.040533
[epoch19, step1102]: loss 0.039361
[epoch19, step1103]: loss 0.041619
[epoch19, step1104]: loss 0.040388
[epoch19, step1105]: loss 0.040752
[epoch19, step1106]: loss 0.039194
[epoch19, step1107]: loss 0.040254
[epoch19, step1108]: loss 0.040157
[epoch19, step1109]: loss 0.040549
[epoch19, step1110]: loss 0.040817
[epoch19, step1111]: loss 0.039226
[epoch19, step1112]: loss 0.041209
[epoch19, step1113]: loss 0.040054
[epoch19, step1114]: loss 0.040021
[epoch19, step1115]: loss 0.039984
[epoch19, step1116]: loss 0.039909
[epoch19, step1117]: loss 0.040898
[epoch19, step1118]: loss 0.041296
[epoch19, step1119]: loss 0.039397
[epoch19, step1120]: loss 0.039047
[epoch19, step1121]: loss 0.040967
[epoch19, step1122]: loss 0.041788
[epoch19, step1123]: loss 0.040086
[epoch19, step1124]: loss 0.039764
[epoch19, step1125]: loss 0.039860
[epoch19, step1126]: loss 0.041559
[epoch19, step1127]: loss 0.040362
[epoch19, step1128]: loss 0.040846
[epoch19, step1129]: loss 0.039275
[epoch19, step1130]: loss 0.041465
[epoch19, step1131]: loss 0.040778
[epoch19, step1132]: loss 0.040560
[epoch19, step1133]: loss 0.038888
[epoch19, step1134]: loss 0.039329
[epoch19, step1135]: loss 0.042639
[epoch19, step1136]: loss 0.043294
[epoch19, step1137]: loss 0.041423
[epoch19, step1138]: loss 0.040462
[epoch19, step1139]: loss 0.043148
[epoch19, step1140]: loss 0.041217
[epoch19, step1141]: loss 0.040917
[epoch19, step1142]: loss 0.042474
[epoch19, step1143]: loss 0.041515
[epoch19, step1144]: loss 0.041337
[epoch19, step1145]: loss 0.042108
[epoch19, step1146]: loss 0.041498
[epoch19, step1147]: loss 0.039940
[epoch19, step1148]: loss 0.042637
[epoch19, step1149]: loss 0.041114
[epoch19, step1150]: loss 0.040511
[epoch19, step1151]: loss 0.040504
[epoch19, step1152]: loss 0.041310
[epoch19, step1153]: loss 0.040949
[epoch19, step1154]: loss 0.041482
[epoch19, step1155]: loss 0.040642
[epoch19, step1156]: loss 0.039343
[epoch19, step1157]: loss 0.041969
[epoch19, step1158]: loss 0.040888
[epoch19, step1159]: loss 0.040978
[epoch19, step1160]: loss 0.040538
[epoch19, step1161]: loss 0.040784
[epoch19, step1162]: loss 0.040990
[epoch19, step1163]: loss 0.041255
[epoch19, step1164]: loss 0.039942
[epoch19, step1165]: loss 0.040188
[epoch19, step1166]: loss 0.042082
[epoch19, step1167]: loss 0.041036
[epoch19, step1168]: loss 0.040343
[epoch19, step1169]: loss 0.039692
[epoch19, step1170]: loss 0.039975
[epoch19, step1171]: loss 0.041644
[epoch19, step1172]: loss 0.042226
[epoch19, step1173]: loss 0.040179
[epoch19, step1174]: loss 0.040184
[epoch19, step1175]: loss 0.041193
[epoch19, step1176]: loss 0.040623
[epoch19, step1177]: loss 0.040918
[epoch19, step1178]: loss 0.040597
[epoch19, step1179]: loss 0.040575
[epoch19, step1180]: loss 0.040687
[epoch19, step1181]: loss 0.043348
[epoch19, step1182]: loss 0.041293
[epoch19, step1183]: loss 0.040754
[epoch19, step1184]: loss 0.041308
[epoch19, step1185]: loss 0.041421
[epoch19, step1186]: loss 0.041133
[epoch19, step1187]: loss 0.039597
[epoch19, step1188]: loss 0.040043
[epoch19, step1189]: loss 0.041770
[epoch19, step1190]: loss 0.040904
[epoch19, step1191]: loss 0.040832
[epoch19, step1192]: loss 0.040120
[epoch19, step1193]: loss 0.041677
[epoch19, step1194]: loss 0.041743
[epoch19, step1195]: loss 0.040933
[epoch19, step1196]: loss 0.039314
[epoch19, step1197]: loss 0.040757
[epoch19, step1198]: loss 0.041056
[epoch19, step1199]: loss 0.040618
[epoch19, step1200]: loss 0.040301
[epoch19, step1201]: loss 0.039612
[epoch19, step1202]: loss 0.041832
[epoch19, step1203]: loss 0.040998
[epoch19, step1204]: loss 0.040490
[epoch19, step1205]: loss 0.039478
[epoch19, step1206]: loss 0.039967
[epoch19, step1207]: loss 0.041187
[epoch19, step1208]: loss 0.041140
[epoch19, step1209]: loss 0.040125
[epoch19, step1210]: loss 0.040180
[epoch19, step1211]: loss 0.041547
[epoch19, step1212]: loss 0.040922
[epoch19, step1213]: loss 0.040469
[epoch19, step1214]: loss 0.040127
[epoch19, step1215]: loss 0.041497
[epoch19, step1216]: loss 0.041598
[epoch19, step1217]: loss 0.041267
[epoch19, step1218]: loss 0.039905
[epoch19, step1219]: loss 0.039890
[epoch19, step1220]: loss 0.041843
[epoch19, step1221]: loss 0.040242
[epoch19, step1222]: loss 0.040660
[epoch19, step1223]: loss 0.040159
[epoch19, step1224]: loss 0.040675
[epoch19, step1225]: loss 0.041105
[epoch19, step1226]: loss 0.041210
[epoch19, step1227]: loss 0.040079
[epoch19, step1228]: loss 0.039474
[epoch19, step1229]: loss 0.041453
[epoch19, step1230]: loss 0.040521
[epoch19, step1231]: loss 0.040422
[epoch19, step1232]: loss 0.040455
[epoch19, step1233]: loss 0.040409
[epoch19, step1234]: loss 0.040778
[epoch19, step1235]: loss 0.041539
[epoch19, step1236]: loss 0.040735
[epoch19, step1237]: loss 0.040019
[epoch19, step1238]: loss 0.040721
[epoch19, step1239]: loss 0.041096
[epoch19, step1240]: loss 0.041827
[epoch19, step1241]: loss 0.039653
[epoch19, step1242]: loss 0.040928
[epoch19, step1243]: loss 0.041674
[epoch19, step1244]: loss 0.041413
[epoch19, step1245]: loss 0.040090
[epoch19, step1246]: loss 0.039805
[epoch19, step1247]: loss 0.041094
[epoch19, step1248]: loss 0.040599
[epoch19, step1249]: loss 0.040823
[epoch19, step1250]: loss 0.039659
[epoch19, step1251]: loss 0.040207
[epoch19, step1252]: loss 0.042582
[epoch19, step1253]: loss 0.041166
[epoch19, step1254]: loss 0.040517
[epoch19, step1255]: loss 0.040653
[epoch19, step1256]: loss 0.041703
[epoch19, step1257]: loss 0.040306
[epoch19, step1258]: loss 0.041529
[epoch19, step1259]: loss 0.040086
[epoch19, step1260]: loss 0.040694
[epoch19, step1261]: loss 0.041072
[epoch19, step1262]: loss 0.040904
[epoch19, step1263]: loss 0.040487
[epoch19, step1264]: loss 0.041269
[epoch19, step1265]: loss 0.041597
[epoch19, step1266]: loss 0.040415
[epoch19, step1267]: loss 0.040454
[epoch19, step1268]: loss 0.040528
[epoch19, step1269]: loss 0.041235
[epoch19, step1270]: loss 0.040654
[epoch19, step1271]: loss 0.041309
[epoch19, step1272]: loss 0.040381
[epoch19, step1273]: loss 0.039345
[epoch19, step1274]: loss 0.042171
[epoch19, step1275]: loss 0.040936
[epoch19, step1276]: loss 0.040627
[epoch19, step1277]: loss 0.039887
[epoch19, step1278]: loss 0.040800
[epoch19, step1279]: loss 0.040784
[epoch19, step1280]: loss 0.041338
[epoch19, step1281]: loss 0.040427
[epoch19, step1282]: loss 0.039596
[epoch19, step1283]: loss 0.041611
[epoch19, step1284]: loss 0.042176
[epoch19, step1285]: loss 0.041224
[epoch19, step1286]: loss 0.039432
[epoch19, step1287]: loss 0.041355
[epoch19, step1288]: loss 0.041317
[epoch19, step1289]: loss 0.041740
[epoch19, step1290]: loss 0.040307
[epoch19, step1291]: loss 0.039138
[epoch19, step1292]: loss 0.041536
[epoch19, step1293]: loss 0.039988
[epoch19, step1294]: loss 0.040669
[epoch19, step1295]: loss 0.040165
[epoch19, step1296]: loss 0.040499
[epoch19, step1297]: loss 0.040857
[epoch19, step1298]: loss 0.041651
[epoch19, step1299]: loss 0.040970
[epoch19, step1300]: loss 0.040681
[epoch19, step1301]: loss 0.040769
[epoch19, step1302]: loss 0.040942
[epoch19, step1303]: loss 0.040223
[epoch19, step1304]: loss 0.039507
[epoch19, step1305]: loss 0.040177
[epoch19, step1306]: loss 0.040336
[epoch19, step1307]: loss 0.041213
[epoch19, step1308]: loss 0.040286
[epoch19, step1309]: loss 0.039458
[epoch19, step1310]: loss 0.042009
[epoch19, step1311]: loss 0.040000
[epoch19, step1312]: loss 0.040470
[epoch19, step1313]: loss 0.039965
[epoch19, step1314]: loss 0.041148
[epoch19, step1315]: loss 0.040550
[epoch19, step1316]: loss 0.041829
[epoch19, step1317]: loss 0.039441
[epoch19, step1318]: loss 0.039373
[epoch19, step1319]: loss 0.041506
[epoch19, step1320]: loss 0.040672
[epoch19, step1321]: loss 0.040843
[epoch19, step1322]: loss 0.039514
[epoch19, step1323]: loss 0.040740
[epoch19, step1324]: loss 0.040830
[epoch19, step1325]: loss 0.040336
[epoch19, step1326]: loss 0.039881
[epoch19, step1327]: loss 0.039548
[epoch19, step1328]: loss 0.042890
[epoch19, step1329]: loss 0.041036
[epoch19, step1330]: loss 0.040073
[epoch19, step1331]: loss 0.040184
[epoch19, step1332]: loss 0.040653
[epoch19, step1333]: loss 0.040577
[epoch19, step1334]: loss 0.041464
[epoch19, step1335]: loss 0.041364
[epoch19, step1336]: loss 0.039381
[epoch19, step1337]: loss 0.041097
[epoch19, step1338]: loss 0.040830
[epoch19, step1339]: loss 0.040471
[epoch19, step1340]: loss 0.039718
[epoch19, step1341]: loss 0.041207
[epoch19, step1342]: loss 0.041385
[epoch19, step1343]: loss 0.041388
[epoch19, step1344]: loss 0.040055
[epoch19, step1345]: loss 0.039758
[epoch19, step1346]: loss 0.041499
[epoch19, step1347]: loss 0.040453
[epoch19, step1348]: loss 0.041094
[epoch19, step1349]: loss 0.039679
[epoch19, step1350]: loss 0.039995
[epoch19, step1351]: loss 0.040051
[epoch19, step1352]: loss 0.040543
[epoch19, step1353]: loss 0.039903
[epoch19, step1354]: loss 0.039106
[epoch19, step1355]: loss 0.041392
[epoch19, step1356]: loss 0.039738
[epoch19, step1357]: loss 0.040011
[epoch19, step1358]: loss 0.039471
[epoch19, step1359]: loss 0.040000
[epoch19, step1360]: loss 0.040586
[epoch19, step1361]: loss 0.041956
[epoch19, step1362]: loss 0.040217
[epoch19, step1363]: loss 0.039451
[epoch19, step1364]: loss 0.040674
[epoch19, step1365]: loss 0.040634
[epoch19, step1366]: loss 0.040831
[epoch19, step1367]: loss 0.039391
[epoch19, step1368]: loss 0.040687
[epoch19, step1369]: loss 0.040924
[epoch19, step1370]: loss 0.041021
[epoch19, step1371]: loss 0.039952
[epoch19, step1372]: loss 0.039205
[epoch19, step1373]: loss 0.040916
[epoch19, step1374]: loss 0.040685
[epoch19, step1375]: loss 0.040825
[epoch19, step1376]: loss 0.039199
[epoch19, step1377]: loss 0.039932
[epoch19, step1378]: loss 0.041390
[epoch19, step1379]: loss 0.041047
[epoch19, step1380]: loss 0.040509
[epoch19, step1381]: loss 0.039289
[epoch19, step1382]: loss 0.041674
[epoch19, step1383]: loss 0.039645
[epoch19, step1384]: loss 0.040507
[epoch19, step1385]: loss 0.039932
[epoch19, step1386]: loss 0.040898
[epoch19, step1387]: loss 0.040800
[epoch19, step1388]: loss 0.041146
[epoch19, step1389]: loss 0.039462
[epoch19, step1390]: loss 0.039381
[epoch19, step1391]: loss 0.041363
[epoch19, step1392]: loss 0.040148
[epoch19, step1393]: loss 0.040114
[epoch19, step1394]: loss 0.040339
[epoch19, step1395]: loss 0.040484
[epoch19, step1396]: loss 0.040483
[epoch19, step1397]: loss 0.040466
[epoch19, step1398]: loss 0.039645
[epoch19, step1399]: loss 0.039735
[epoch19, step1400]: loss 0.042927
[epoch19, step1401]: loss 0.040419
[epoch19, step1402]: loss 0.039959
[epoch19, step1403]: loss 0.038883
[epoch19, step1404]: loss 0.040096
[epoch19, step1405]: loss 0.041030
[epoch19, step1406]: loss 0.041041
[epoch19, step1407]: loss 0.041413
[epoch19, step1408]: loss 0.040096
[epoch19, step1409]: loss 0.041636
[epoch19, step1410]: loss 0.040656
[epoch19, step1411]: loss 0.040515
[epoch19, step1412]: loss 0.039396
[epoch19, step1413]: loss 0.040158
[epoch19, step1414]: loss 0.040683
[epoch19, step1415]: loss 0.040386
[epoch19, step1416]: loss 0.040003
[epoch19, step1417]: loss 0.038852
[epoch19, step1418]: loss 0.040575
[epoch19, step1419]: loss 0.040741
[epoch19, step1420]: loss 0.040280
[epoch19, step1421]: loss 0.039834
[epoch19, step1422]: loss 0.039814
[epoch19, step1423]: loss 0.040829
[epoch19, step1424]: loss 0.041585
[epoch19, step1425]: loss 0.039601
[epoch19, step1426]: loss 0.039904
[epoch19, step1427]: loss 0.041174
[epoch19, step1428]: loss 0.040529
[epoch19, step1429]: loss 0.041450
[epoch19, step1430]: loss 0.039431
[epoch19, step1431]: loss 0.040510
[epoch19, step1432]: loss 0.040277
[epoch19, step1433]: loss 0.041875
[epoch19, step1434]: loss 0.039314
[epoch19, step1435]: loss 0.039157
[epoch19, step1436]: loss 0.042119
[epoch19, step1437]: loss 0.039837
[epoch19, step1438]: loss 0.039850
[epoch19, step1439]: loss 0.039053
[epoch19, step1440]: loss 0.039686
[epoch19, step1441]: loss 0.041235
[epoch19, step1442]: loss 0.040598
[epoch19, step1443]: loss 0.039478
[epoch19, step1444]: loss 0.038899
[epoch19, step1445]: loss 0.042522
[epoch19, step1446]: loss 0.039912
[epoch19, step1447]: loss 0.040135
[epoch19, step1448]: loss 0.039786
[epoch19, step1449]: loss 0.040271
[epoch19, step1450]: loss 0.040296
[epoch19, step1451]: loss 0.041068
[epoch19, step1452]: loss 0.039835
[epoch19, step1453]: loss 0.039907
[epoch19, step1454]: loss 0.041442
[epoch19, step1455]: loss 0.040564
[epoch19, step1456]: loss 0.040884
[epoch19, step1457]: loss 0.039533
[epoch19, step1458]: loss 0.040029
[epoch19, step1459]: loss 0.039987
[epoch19, step1460]: loss 0.041398
[epoch19, step1461]: loss 0.039939
[epoch19, step1462]: loss 0.039505
[epoch19, step1463]: loss 0.040885
[epoch19, step1464]: loss 0.040093
[epoch19, step1465]: loss 0.039942
[epoch19, step1466]: loss 0.038973
[epoch19, step1467]: loss 0.040631
[epoch19, step1468]: loss 0.039330
[epoch19, step1469]: loss 0.040587
[epoch19, step1470]: loss 0.038909
[epoch19, step1471]: loss 0.038225
[epoch19, step1472]: loss 0.039904
[epoch19, step1473]: loss 0.040532
[epoch19, step1474]: loss 0.040273
[epoch19, step1475]: loss 0.038847
[epoch19, step1476]: loss 0.040440
[epoch19, step1477]: loss 0.040762
[epoch19, step1478]: loss 0.040730
[epoch19, step1479]: loss 0.040158
[epoch19, step1480]: loss 0.039602
[epoch19, step1481]: loss 0.040881
[epoch19, step1482]: loss 0.040663
[epoch19, step1483]: loss 0.040337
[epoch19, step1484]: loss 0.039866
[epoch19, step1485]: loss 0.040167
[epoch19, step1486]: loss 0.039764
[epoch19, step1487]: loss 0.040776
[epoch19, step1488]: loss 0.040257
[epoch19, step1489]: loss 0.039302
[epoch19, step1490]: loss 0.041268
[epoch19, step1491]: loss 0.040167
[epoch19, step1492]: loss 0.040079
[epoch19, step1493]: loss 0.039306
[epoch19, step1494]: loss 0.039767
[epoch19, step1495]: loss 0.039696
[epoch19, step1496]: loss 0.039883
[epoch19, step1497]: loss 0.039990
[epoch19, step1498]: loss 0.038847
[epoch19, step1499]: loss 0.042201
[epoch19, step1500]: loss 0.039661
[epoch19, step1501]: loss 0.039950
[epoch19, step1502]: loss 0.039076
[epoch19, step1503]: loss 0.039965
[epoch19, step1504]: loss 0.039384
[epoch19, step1505]: loss 0.041209
[epoch19, step1506]: loss 0.038710
[epoch19, step1507]: loss 0.038626
[epoch19, step1508]: loss 0.041691
[epoch19, step1509]: loss 0.039619
[epoch19, step1510]: loss 0.039900
[epoch19, step1511]: loss 0.039048
[epoch19, step1512]: loss 0.039078
[epoch19, step1513]: loss 0.039408
[epoch19, step1514]: loss 0.040624
[epoch19, step1515]: loss 0.038793
[epoch19, step1516]: loss 0.038654

[epoch19]: avg loss 0.037199

[epoch20, step1]: loss 0.039846
[epoch20, step2]: loss 0.040534
[epoch20, step3]: loss 0.039009
[epoch20, step4]: loss 0.036176
[epoch20, step5]: loss 0.035440
[epoch20, step6]: loss 0.039342
[epoch20, step7]: loss 0.036268
[epoch20, step8]: loss 0.037958
[epoch20, step9]: loss 0.034555
[epoch20, step10]: loss 0.036886
[epoch20, step11]: loss 0.039070
[epoch20, step12]: loss 0.038055
[epoch20, step13]: loss 0.035169
[epoch20, step14]: loss 0.033923
[epoch20, step15]: loss 0.036806
[epoch20, step16]: loss 0.036011
[epoch20, step17]: loss 0.035964
[epoch20, step18]: loss 0.033802
[epoch20, step19]: loss 0.033183
[epoch20, step20]: loss 0.037619
[epoch20, step21]: loss 0.035234
[epoch20, step22]: loss 0.035320
[epoch20, step23]: loss 0.034563
[epoch20, step24]: loss 0.037681
[epoch20, step25]: loss 0.033808
[epoch20, step26]: loss 0.037627
[epoch20, step27]: loss 0.032965
[epoch20, step28]: loss 0.035571
[epoch20, step29]: loss 0.037274
[epoch20, step30]: loss 0.037039
[epoch20, step31]: loss 0.034285
[epoch20, step32]: loss 0.034992
[epoch20, step33]: loss 0.036297
[epoch20, step34]: loss 0.034477
[epoch20, step35]: loss 0.036959
[epoch20, step36]: loss 0.033139
[epoch20, step37]: loss 0.034835
[epoch20, step38]: loss 0.037091
[epoch20, step39]: loss 0.036494
[epoch20, step40]: loss 0.034097
[epoch20, step41]: loss 0.033631
[epoch20, step42]: loss 0.036680
[epoch20, step43]: loss 0.034291
[epoch20, step44]: loss 0.037121
[epoch20, step45]: loss 0.033933
[epoch20, step46]: loss 0.034650
[epoch20, step47]: loss 0.036260
[epoch20, step48]: loss 0.036211
[epoch20, step49]: loss 0.032332
[epoch20, step50]: loss 0.033685
[epoch20, step51]: loss 0.036430
[epoch20, step52]: loss 0.034326
[epoch20, step53]: loss 0.036408
[epoch20, step54]: loss 0.032931
[epoch20, step55]: loss 0.034910
[epoch20, step56]: loss 0.037391
[epoch20, step57]: loss 0.036239
[epoch20, step58]: loss 0.033799
[epoch20, step59]: loss 0.032623
[epoch20, step60]: loss 0.036875
[epoch20, step61]: loss 0.033384
[epoch20, step62]: loss 0.035596
[epoch20, step63]: loss 0.032996
[epoch20, step64]: loss 0.033560
[epoch20, step65]: loss 0.036511
[epoch20, step66]: loss 0.035987
[epoch20, step67]: loss 0.033629
[epoch20, step68]: loss 0.033549
[epoch20, step69]: loss 0.035552
[epoch20, step70]: loss 0.033636
[epoch20, step71]: loss 0.036219
[epoch20, step72]: loss 0.033246
[epoch20, step73]: loss 0.033921
[epoch20, step74]: loss 0.036073
[epoch20, step75]: loss 0.036562
[epoch20, step76]: loss 0.034300
[epoch20, step77]: loss 0.033888
[epoch20, step78]: loss 0.036182
[epoch20, step79]: loss 0.033510
[epoch20, step80]: loss 0.036794
[epoch20, step81]: loss 0.033438
[epoch20, step82]: loss 0.033834
[epoch20, step83]: loss 0.036137
[epoch20, step84]: loss 0.036073
[epoch20, step85]: loss 0.034506
[epoch20, step86]: loss 0.034230
[epoch20, step87]: loss 0.036910
[epoch20, step88]: loss 0.033062
[epoch20, step89]: loss 0.036350
[epoch20, step90]: loss 0.033715
[epoch20, step91]: loss 0.033664
[epoch20, step92]: loss 0.036295
[epoch20, step93]: loss 0.036201
[epoch20, step94]: loss 0.033332
[epoch20, step95]: loss 0.033728
[epoch20, step96]: loss 0.035444
[epoch20, step97]: loss 0.034416
[epoch20, step98]: loss 0.036255
[epoch20, step99]: loss 0.033369
[epoch20, step100]: loss 0.032728
[epoch20, step101]: loss 0.036941
[epoch20, step102]: loss 0.035554
[epoch20, step103]: loss 0.033655
[epoch20, step104]: loss 0.033383
[epoch20, step105]: loss 0.036423
[epoch20, step106]: loss 0.033998
[epoch20, step107]: loss 0.036241
[epoch20, step108]: loss 0.033674
[epoch20, step109]: loss 0.033562
[epoch20, step110]: loss 0.036431
[epoch20, step111]: loss 0.035494
[epoch20, step112]: loss 0.033540
[epoch20, step113]: loss 0.034225
[epoch20, step114]: loss 0.035685
[epoch20, step115]: loss 0.033758
[epoch20, step116]: loss 0.036622
[epoch20, step117]: loss 0.033071
[epoch20, step118]: loss 0.034547
[epoch20, step119]: loss 0.036517
[epoch20, step120]: loss 0.036456
[epoch20, step121]: loss 0.033564
[epoch20, step122]: loss 0.033682
[epoch20, step123]: loss 0.036393
[epoch20, step124]: loss 0.034045
[epoch20, step125]: loss 0.036526
[epoch20, step126]: loss 0.033208
[epoch20, step127]: loss 0.033579
[epoch20, step128]: loss 0.036088
[epoch20, step129]: loss 0.035750
[epoch20, step130]: loss 0.033894
[epoch20, step131]: loss 0.033188
[epoch20, step132]: loss 0.035794
[epoch20, step133]: loss 0.033862
[epoch20, step134]: loss 0.035537
[epoch20, step135]: loss 0.033969
[epoch20, step136]: loss 0.034545
[epoch20, step137]: loss 0.036163
[epoch20, step138]: loss 0.035831
[epoch20, step139]: loss 0.033668
[epoch20, step140]: loss 0.033881
[epoch20, step141]: loss 0.036284
[epoch20, step142]: loss 0.033833
[epoch20, step143]: loss 0.035761
[epoch20, step144]: loss 0.033490
[epoch20, step145]: loss 0.033995
[epoch20, step146]: loss 0.036196
[epoch20, step147]: loss 0.036748
[epoch20, step148]: loss 0.033281
[epoch20, step149]: loss 0.033030
[epoch20, step150]: loss 0.035595
[epoch20, step151]: loss 0.033688
[epoch20, step152]: loss 0.035820
[epoch20, step153]: loss 0.033432
[epoch20, step154]: loss 0.033605
[epoch20, step155]: loss 0.036118
[epoch20, step156]: loss 0.035160
[epoch20, step157]: loss 0.033536
[epoch20, step158]: loss 0.033927
[epoch20, step159]: loss 0.035822
[epoch20, step160]: loss 0.033995
[epoch20, step161]: loss 0.036309
[epoch20, step162]: loss 0.033862
[epoch20, step163]: loss 0.034067
[epoch20, step164]: loss 0.036121
[epoch20, step165]: loss 0.035673
[epoch20, step166]: loss 0.034115
[epoch20, step167]: loss 0.033170
[epoch20, step168]: loss 0.036738
[epoch20, step169]: loss 0.033826
[epoch20, step170]: loss 0.036080
[epoch20, step171]: loss 0.033965
[epoch20, step172]: loss 0.034150
[epoch20, step173]: loss 0.036266
[epoch20, step174]: loss 0.035652
[epoch20, step175]: loss 0.034644
[epoch20, step176]: loss 0.033911
[epoch20, step177]: loss 0.036362
[epoch20, step178]: loss 0.033876
[epoch20, step179]: loss 0.035440
[epoch20, step180]: loss 0.033477
[epoch20, step181]: loss 0.033883
[epoch20, step182]: loss 0.036455
[epoch20, step183]: loss 0.036053
[epoch20, step184]: loss 0.034626
[epoch20, step185]: loss 0.033547
[epoch20, step186]: loss 0.035857
[epoch20, step187]: loss 0.033768
[epoch20, step188]: loss 0.035575
[epoch20, step189]: loss 0.033345
[epoch20, step190]: loss 0.033077
[epoch20, step191]: loss 0.036093
[epoch20, step192]: loss 0.036083
[epoch20, step193]: loss 0.031894
[epoch20, step194]: loss 0.032612
[epoch20, step195]: loss 0.036015
[epoch20, step196]: loss 0.033955
[epoch20, step197]: loss 0.035857
[epoch20, step198]: loss 0.032823
[epoch20, step199]: loss 0.033722
[epoch20, step200]: loss 0.036655
[epoch20, step201]: loss 0.036811
[epoch20, step202]: loss 0.033261
[epoch20, step203]: loss 0.033640
[epoch20, step204]: loss 0.036674
[epoch20, step205]: loss 0.033467
[epoch20, step206]: loss 0.036113
[epoch20, step207]: loss 0.033412
[epoch20, step208]: loss 0.034126
[epoch20, step209]: loss 0.036368
[epoch20, step210]: loss 0.036411
[epoch20, step211]: loss 0.034036
[epoch20, step212]: loss 0.033886
[epoch20, step213]: loss 0.035663
[epoch20, step214]: loss 0.033255
[epoch20, step215]: loss 0.036251
[epoch20, step216]: loss 0.033490
[epoch20, step217]: loss 0.033237
[epoch20, step218]: loss 0.036209
[epoch20, step219]: loss 0.035343
[epoch20, step220]: loss 0.033794
[epoch20, step221]: loss 0.033592
[epoch20, step222]: loss 0.036564
[epoch20, step223]: loss 0.034279
[epoch20, step224]: loss 0.035680
[epoch20, step225]: loss 0.033538
[epoch20, step226]: loss 0.033056
[epoch20, step227]: loss 0.035525
[epoch20, step228]: loss 0.036446
[epoch20, step229]: loss 0.032754
[epoch20, step230]: loss 0.034038
[epoch20, step231]: loss 0.036728
[epoch20, step232]: loss 0.033800
[epoch20, step233]: loss 0.035727
[epoch20, step234]: loss 0.032767
[epoch20, step235]: loss 0.034371
[epoch20, step236]: loss 0.035897
[epoch20, step237]: loss 0.035588
[epoch20, step238]: loss 0.033700
[epoch20, step239]: loss 0.032708
[epoch20, step240]: loss 0.035412
[epoch20, step241]: loss 0.033882
[epoch20, step242]: loss 0.035864
[epoch20, step243]: loss 0.034120
[epoch20, step244]: loss 0.033279
[epoch20, step245]: loss 0.035713
[epoch20, step246]: loss 0.035354
[epoch20, step247]: loss 0.033974
[epoch20, step248]: loss 0.033306
[epoch20, step249]: loss 0.035133
[epoch20, step250]: loss 0.034363
[epoch20, step251]: loss 0.036502
[epoch20, step252]: loss 0.034008
[epoch20, step253]: loss 0.033038
[epoch20, step254]: loss 0.035900
[epoch20, step255]: loss 0.035975
[epoch20, step256]: loss 0.033548
[epoch20, step257]: loss 0.033398
[epoch20, step258]: loss 0.036222
[epoch20, step259]: loss 0.034160
[epoch20, step260]: loss 0.035473
[epoch20, step261]: loss 0.034101
[epoch20, step262]: loss 0.033867
[epoch20, step263]: loss 0.035737
[epoch20, step264]: loss 0.035525
[epoch20, step265]: loss 0.033687
[epoch20, step266]: loss 0.033251
[epoch20, step267]: loss 0.036142
[epoch20, step268]: loss 0.033703
[epoch20, step269]: loss 0.035623
[epoch20, step270]: loss 0.033209
[epoch20, step271]: loss 0.033543
[epoch20, step272]: loss 0.036290
[epoch20, step273]: loss 0.035749
[epoch20, step274]: loss 0.034127
[epoch20, step275]: loss 0.033184
[epoch20, step276]: loss 0.036069
[epoch20, step277]: loss 0.034099
[epoch20, step278]: loss 0.036179
[epoch20, step279]: loss 0.032893
[epoch20, step280]: loss 0.033965
[epoch20, step281]: loss 0.036288
[epoch20, step282]: loss 0.036420
[epoch20, step283]: loss 0.033298
[epoch20, step284]: loss 0.032984
[epoch20, step285]: loss 0.036612
[epoch20, step286]: loss 0.033086
[epoch20, step287]: loss 0.036099
[epoch20, step288]: loss 0.032860
[epoch20, step289]: loss 0.034300
[epoch20, step290]: loss 0.036290
[epoch20, step291]: loss 0.035901
[epoch20, step292]: loss 0.033002
[epoch20, step293]: loss 0.033463
[epoch20, step294]: loss 0.035370
[epoch20, step295]: loss 0.033700
[epoch20, step296]: loss 0.036903
[epoch20, step297]: loss 0.032888
[epoch20, step298]: loss 0.033933
[epoch20, step299]: loss 0.035020
[epoch20, step300]: loss 0.035832
[epoch20, step301]: loss 0.033409
[epoch20, step302]: loss 0.033713
[epoch20, step303]: loss 0.036228
[epoch20, step304]: loss 0.033379
[epoch20, step305]: loss 0.035419
[epoch20, step306]: loss 0.034032
[epoch20, step307]: loss 0.033373
[epoch20, step308]: loss 0.036471
[epoch20, step309]: loss 0.036187
[epoch20, step310]: loss 0.033583
[epoch20, step311]: loss 0.033844
[epoch20, step312]: loss 0.035403
[epoch20, step313]: loss 0.033858
[epoch20, step314]: loss 0.035807
[epoch20, step315]: loss 0.034168
[epoch20, step316]: loss 0.033422
[epoch20, step317]: loss 0.036436
[epoch20, step318]: loss 0.035942
[epoch20, step319]: loss 0.032915
[epoch20, step320]: loss 0.032331
[epoch20, step321]: loss 0.035418
[epoch20, step322]: loss 0.033431
[epoch20, step323]: loss 0.035299
[epoch20, step324]: loss 0.033999
[epoch20, step325]: loss 0.033446
[epoch20, step326]: loss 0.035535
[epoch20, step327]: loss 0.034698
[epoch20, step328]: loss 0.033573
[epoch20, step329]: loss 0.033043
[epoch20, step330]: loss 0.035235
[epoch20, step331]: loss 0.033790
[epoch20, step332]: loss 0.035048
[epoch20, step333]: loss 0.033170
[epoch20, step334]: loss 0.033700
[epoch20, step335]: loss 0.035792
[epoch20, step336]: loss 0.036736
[epoch20, step337]: loss 0.034532
[epoch20, step338]: loss 0.032917
[epoch20, step339]: loss 0.036212
[epoch20, step340]: loss 0.034499
[epoch20, step341]: loss 0.035535
[epoch20, step342]: loss 0.033430
[epoch20, step343]: loss 0.033942
[epoch20, step344]: loss 0.035627
[epoch20, step345]: loss 0.035127
[epoch20, step346]: loss 0.033419
[epoch20, step347]: loss 0.033419
[epoch20, step348]: loss 0.036380
[epoch20, step349]: loss 0.034496
[epoch20, step350]: loss 0.035438
[epoch20, step351]: loss 0.032454
[epoch20, step352]: loss 0.033171
[epoch20, step353]: loss 0.035902
[epoch20, step354]: loss 0.034422
[epoch20, step355]: loss 0.032674
[epoch20, step356]: loss 0.033829
[epoch20, step357]: loss 0.035915
[epoch20, step358]: loss 0.032262
[epoch20, step359]: loss 0.037505
[epoch20, step360]: loss 0.032968
[epoch20, step361]: loss 0.034298
[epoch20, step362]: loss 0.036819
[epoch20, step363]: loss 0.035863
[epoch20, step364]: loss 0.034464
[epoch20, step365]: loss 0.033595
[epoch20, step366]: loss 0.035930
[epoch20, step367]: loss 0.034291
[epoch20, step368]: loss 0.035440
[epoch20, step369]: loss 0.032950
[epoch20, step370]: loss 0.034033
[epoch20, step371]: loss 0.037148
[epoch20, step372]: loss 0.035082
[epoch20, step373]: loss 0.033364
[epoch20, step374]: loss 0.033850
[epoch20, step375]: loss 0.037063
[epoch20, step376]: loss 0.033748
[epoch20, step377]: loss 0.036649
[epoch20, step378]: loss 0.034151
[epoch20, step379]: loss 0.033812
[epoch20, step380]: loss 0.036535
[epoch20, step381]: loss 0.035113
[epoch20, step382]: loss 0.033654
[epoch20, step383]: loss 0.032266
[epoch20, step384]: loss 0.034849
[epoch20, step385]: loss 0.033298
[epoch20, step386]: loss 0.035738
[epoch20, step387]: loss 0.033114
[epoch20, step388]: loss 0.033985
[epoch20, step389]: loss 0.035756
[epoch20, step390]: loss 0.036791
[epoch20, step391]: loss 0.033017
[epoch20, step392]: loss 0.033767
[epoch20, step393]: loss 0.036068
[epoch20, step394]: loss 0.033580
[epoch20, step395]: loss 0.035432
[epoch20, step396]: loss 0.033422
[epoch20, step397]: loss 0.033252
[epoch20, step398]: loss 0.036011
[epoch20, step399]: loss 0.035437
[epoch20, step400]: loss 0.033351
[epoch20, step401]: loss 0.033248
[epoch20, step402]: loss 0.035883
[epoch20, step403]: loss 0.033699
[epoch20, step404]: loss 0.036516
[epoch20, step405]: loss 0.033764
[epoch20, step406]: loss 0.033799
[epoch20, step407]: loss 0.035871
[epoch20, step408]: loss 0.035532
[epoch20, step409]: loss 0.034798
[epoch20, step410]: loss 0.033717
[epoch20, step411]: loss 0.035518
[epoch20, step412]: loss 0.033195
[epoch20, step413]: loss 0.035599
[epoch20, step414]: loss 0.032982
[epoch20, step415]: loss 0.033382
[epoch20, step416]: loss 0.035270
[epoch20, step417]: loss 0.035672
[epoch20, step418]: loss 0.033462
[epoch20, step419]: loss 0.032890
[epoch20, step420]: loss 0.035698
[epoch20, step421]: loss 0.033491
[epoch20, step422]: loss 0.035850
[epoch20, step423]: loss 0.032920
[epoch20, step424]: loss 0.033210
[epoch20, step425]: loss 0.035914
[epoch20, step426]: loss 0.035356
[epoch20, step427]: loss 0.033581
[epoch20, step428]: loss 0.033108
[epoch20, step429]: loss 0.035497
[epoch20, step430]: loss 0.033753
[epoch20, step431]: loss 0.036097
[epoch20, step432]: loss 0.033209
[epoch20, step433]: loss 0.033274
[epoch20, step434]: loss 0.035778
[epoch20, step435]: loss 0.036091
[epoch20, step436]: loss 0.033951
[epoch20, step437]: loss 0.033799
[epoch20, step438]: loss 0.036964
[epoch20, step439]: loss 0.034785
[epoch20, step440]: loss 0.036114
[epoch20, step441]: loss 0.034007
[epoch20, step442]: loss 0.033914
[epoch20, step443]: loss 0.036705
[epoch20, step444]: loss 0.035513
[epoch20, step445]: loss 0.034053
[epoch20, step446]: loss 0.033703
[epoch20, step447]: loss 0.036538
[epoch20, step448]: loss 0.033678
[epoch20, step449]: loss 0.035783
[epoch20, step450]: loss 0.032839
[epoch20, step451]: loss 0.033638
[epoch20, step452]: loss 0.035246
[epoch20, step453]: loss 0.035989
[epoch20, step454]: loss 0.033249
[epoch20, step455]: loss 0.033528
[epoch20, step456]: loss 0.035467
[epoch20, step457]: loss 0.034054
[epoch20, step458]: loss 0.035764
[epoch20, step459]: loss 0.033666
[epoch20, step460]: loss 0.033713
[epoch20, step461]: loss 0.036615
[epoch20, step462]: loss 0.035023
[epoch20, step463]: loss 0.033810
[epoch20, step464]: loss 0.033005
[epoch20, step465]: loss 0.036799
[epoch20, step466]: loss 0.033375
[epoch20, step467]: loss 0.035333
[epoch20, step468]: loss 0.033264
[epoch20, step469]: loss 0.033503
[epoch20, step470]: loss 0.036140
[epoch20, step471]: loss 0.035086
[epoch20, step472]: loss 0.033745
[epoch20, step473]: loss 0.033150
[epoch20, step474]: loss 0.035287
[epoch20, step475]: loss 0.033324
[epoch20, step476]: loss 0.035851
[epoch20, step477]: loss 0.032775
[epoch20, step478]: loss 0.032442
[epoch20, step479]: loss 0.035094
[epoch20, step480]: loss 0.034336
[epoch20, step481]: loss 0.032328
[epoch20, step482]: loss 0.033188
[epoch20, step483]: loss 0.036210
[epoch20, step484]: loss 0.032953
[epoch20, step485]: loss 0.035464
[epoch20, step486]: loss 0.032797
[epoch20, step487]: loss 0.032561
[epoch20, step488]: loss 0.036382
[epoch20, step489]: loss 0.034627
[epoch20, step490]: loss 0.034236
[epoch20, step491]: loss 0.033636
[epoch20, step492]: loss 0.035389
[epoch20, step493]: loss 0.033439
[epoch20, step494]: loss 0.035581
[epoch20, step495]: loss 0.034274
[epoch20, step496]: loss 0.034229
[epoch20, step497]: loss 0.036375
[epoch20, step498]: loss 0.035473
[epoch20, step499]: loss 0.033769
[epoch20, step500]: loss 0.033683
[epoch20, step501]: loss 0.035521
[epoch20, step502]: loss 0.033564
[epoch20, step503]: loss 0.036487
[epoch20, step504]: loss 0.032950
[epoch20, step505]: loss 0.032386
[epoch20, step506]: loss 0.036688
[epoch20, step507]: loss 0.036033
[epoch20, step508]: loss 0.033902
[epoch20, step509]: loss 0.033477
[epoch20, step510]: loss 0.035916
[epoch20, step511]: loss 0.034238
[epoch20, step512]: loss 0.036907
[epoch20, step513]: loss 0.033406
[epoch20, step514]: loss 0.033404
[epoch20, step515]: loss 0.035841
[epoch20, step516]: loss 0.035373
[epoch20, step517]: loss 0.033134
[epoch20, step518]: loss 0.033394
[epoch20, step519]: loss 0.035709
[epoch20, step520]: loss 0.032759
[epoch20, step521]: loss 0.035621
[epoch20, step522]: loss 0.032835
[epoch20, step523]: loss 0.032951
[epoch20, step524]: loss 0.034975
[epoch20, step525]: loss 0.035514
[epoch20, step526]: loss 0.033174
[epoch20, step527]: loss 0.032854
[epoch20, step528]: loss 0.035570
[epoch20, step529]: loss 0.033045
[epoch20, step530]: loss 0.035776
[epoch20, step531]: loss 0.032922
[epoch20, step532]: loss 0.033473
[epoch20, step533]: loss 0.037098
[epoch20, step534]: loss 0.036068
[epoch20, step535]: loss 0.033866
[epoch20, step536]: loss 0.033513
[epoch20, step537]: loss 0.036028
[epoch20, step538]: loss 0.033119
[epoch20, step539]: loss 0.034994
[epoch20, step540]: loss 0.032192
[epoch20, step541]: loss 0.033461
[epoch20, step542]: loss 0.036319
[epoch20, step543]: loss 0.035473
[epoch20, step544]: loss 0.033763
[epoch20, step545]: loss 0.033074
[epoch20, step546]: loss 0.036797
[epoch20, step547]: loss 0.033922
[epoch20, step548]: loss 0.036231
[epoch20, step549]: loss 0.034398
[epoch20, step550]: loss 0.034313
[epoch20, step551]: loss 0.036051
[epoch20, step552]: loss 0.035422
[epoch20, step553]: loss 0.034189
[epoch20, step554]: loss 0.033463
[epoch20, step555]: loss 0.035631
[epoch20, step556]: loss 0.033549
[epoch20, step557]: loss 0.035322
[epoch20, step558]: loss 0.033558
[epoch20, step559]: loss 0.033247
[epoch20, step560]: loss 0.035863
[epoch20, step561]: loss 0.035613
[epoch20, step562]: loss 0.033744
[epoch20, step563]: loss 0.035521
[epoch20, step564]: loss 0.040844
[epoch20, step565]: loss 0.039545
[epoch20, step566]: loss 0.047331
[epoch20, step567]: loss 0.039863
[epoch20, step568]: loss 0.041048
[epoch20, step569]: loss 0.037060
[epoch20, step570]: loss 0.044675
[epoch20, step571]: loss 0.040977
[epoch20, step572]: loss 0.038013
[epoch20, step573]: loss 0.038497
[epoch20, step574]: loss 0.042172
[epoch20, step575]: loss 0.032552
[epoch20, step576]: loss 0.033494
[epoch20, step577]: loss 0.038165
[epoch20, step578]: loss 0.031401
[epoch20, step579]: loss 0.040348
[epoch20, step580]: loss 0.031598
[epoch20, step581]: loss 0.036369
[epoch20, step582]: loss 0.036929
[epoch20, step583]: loss 0.036553
[epoch20, step584]: loss 0.034032
[epoch20, step585]: loss 0.036802
[epoch20, step586]: loss 0.034462
[epoch20, step587]: loss 0.041093
[epoch20, step588]: loss 0.034820
[epoch20, step589]: loss 0.035247
[epoch20, step590]: loss 0.039510
[epoch20, step591]: loss 0.031485
[epoch20, step592]: loss 0.036869
[epoch20, step593]: loss 0.033550
[epoch20, step594]: loss 0.038205
[epoch20, step595]: loss 0.039311
[epoch20, step596]: loss 0.037071
[epoch20, step597]: loss 0.036054
[epoch20, step598]: loss 0.036102
[epoch20, step599]: loss 0.034834
[epoch20, step600]: loss 0.038206
[epoch20, step601]: loss 0.030352
[epoch20, step602]: loss 0.033224
[epoch20, step603]: loss 0.036321
[epoch20, step604]: loss 0.038867
[epoch20, step605]: loss 0.035914
[epoch20, step606]: loss 0.034400
[epoch20, step607]: loss 0.038162
[epoch20, step608]: loss 0.037209
[epoch20, step609]: loss 0.037679
[epoch20, step610]: loss 0.038897
[epoch20, step611]: loss 0.038186
[epoch20, step612]: loss 0.034955
[epoch20, step613]: loss 0.030499
[epoch20, step614]: loss 0.035452
[epoch20, step615]: loss 0.040291
[epoch20, step616]: loss 0.034180
[epoch20, step617]: loss 0.033623
[epoch20, step618]: loss 0.037171
[epoch20, step619]: loss 0.038357
[epoch20, step620]: loss 0.035462
[epoch20, step621]: loss 0.037551
[epoch20, step622]: loss 0.031099
[epoch20, step623]: loss 0.033088
[epoch20, step624]: loss 0.037765
[epoch20, step625]: loss 0.036108
[epoch20, step626]: loss 0.039225
[epoch20, step627]: loss 0.033028
[epoch20, step628]: loss 0.035293
[epoch20, step629]: loss 0.030656
[epoch20, step630]: loss 0.032616
[epoch20, step631]: loss 0.041531
[epoch20, step632]: loss 0.034417
[epoch20, step633]: loss 0.035232
[epoch20, step634]: loss 0.036726
[epoch20, step635]: loss 0.036661
[epoch20, step636]: loss 0.032193
[epoch20, step637]: loss 0.038267
[epoch20, step638]: loss 0.037941
[epoch20, step639]: loss 0.032301
[epoch20, step640]: loss 0.040241
[epoch20, step641]: loss 0.039886
[epoch20, step642]: loss 0.035069
[epoch20, step643]: loss 0.035134
[epoch20, step644]: loss 0.035942
[epoch20, step645]: loss 0.033949
[epoch20, step646]: loss 0.035204
[epoch20, step647]: loss 0.034216
[epoch20, step648]: loss 0.034431
[epoch20, step649]: loss 0.037500
[epoch20, step650]: loss 0.032660
[epoch20, step651]: loss 0.037078
[epoch20, step652]: loss 0.037679
[epoch20, step653]: loss 0.038202
[epoch20, step654]: loss 0.033168
[epoch20, step655]: loss 0.034529
[epoch20, step656]: loss 0.033447
[epoch20, step657]: loss 0.038003
[epoch20, step658]: loss 0.035226
[epoch20, step659]: loss 0.037811
[epoch20, step660]: loss 0.033063
[epoch20, step661]: loss 0.036446
[epoch20, step662]: loss 0.033987
[epoch20, step663]: loss 0.032582
[epoch20, step664]: loss 0.036662
[epoch20, step665]: loss 0.037435
[epoch20, step666]: loss 0.037175
[epoch20, step667]: loss 0.037056
[epoch20, step668]: loss 0.033346
[epoch20, step669]: loss 0.037529
[epoch20, step670]: loss 0.037576
[epoch20, step671]: loss 0.031831
[epoch20, step672]: loss 0.034986
[epoch20, step673]: loss 0.032877
[epoch20, step674]: loss 0.031509
[epoch20, step675]: loss 0.030938
[epoch20, step676]: loss 0.033937
[epoch20, step677]: loss 0.035086
[epoch20, step678]: loss 0.032896
[epoch20, step679]: loss 0.034833
[epoch20, step680]: loss 0.040715
[epoch20, step681]: loss 0.031929
[epoch20, step682]: loss 0.036242
[epoch20, step683]: loss 0.035331
[epoch20, step684]: loss 0.035500
[epoch20, step685]: loss 0.035185
[epoch20, step686]: loss 0.039519
[epoch20, step687]: loss 0.036153
[epoch20, step688]: loss 0.034569
[epoch20, step689]: loss 0.035448
[epoch20, step690]: loss 0.035800
[epoch20, step691]: loss 0.035080
[epoch20, step692]: loss 0.034292
[epoch20, step693]: loss 0.037942
[epoch20, step694]: loss 0.032592
[epoch20, step695]: loss 0.038452
[epoch20, step696]: loss 0.035395
[epoch20, step697]: loss 0.037927
[epoch20, step698]: loss 0.035335
[epoch20, step699]: loss 0.034013
[epoch20, step700]: loss 0.031246
[epoch20, step701]: loss 0.036022
[epoch20, step702]: loss 0.031777
[epoch20, step703]: loss 0.033916
[epoch20, step704]: loss 0.036576
[epoch20, step705]: loss 0.035729
[epoch20, step706]: loss 0.033801
[epoch20, step707]: loss 0.033550
[epoch20, step708]: loss 0.035254
[epoch20, step709]: loss 0.037382
[epoch20, step710]: loss 0.032765
[epoch20, step711]: loss 0.037108
[epoch20, step712]: loss 0.037450
[epoch20, step713]: loss 0.037321
[epoch20, step714]: loss 0.031900
[epoch20, step715]: loss 0.033837
[epoch20, step716]: loss 0.035911
[epoch20, step717]: loss 0.032962
[epoch20, step718]: loss 0.035796
[epoch20, step719]: loss 0.045089
[epoch20, step720]: loss 0.034972
[epoch20, step721]: loss 0.032926
[epoch20, step722]: loss 0.040525
[epoch20, step723]: loss 0.037154
[epoch20, step724]: loss 0.033027
[epoch20, step725]: loss 0.037039
[epoch20, step726]: loss 0.032247
[epoch20, step727]: loss 0.034435
[epoch20, step728]: loss 0.037358
[epoch20, step729]: loss 0.032324
[epoch20, step730]: loss 0.032929
[epoch20, step731]: loss 0.036222
[epoch20, step732]: loss 0.035706
[epoch20, step733]: loss 0.034368
[epoch20, step734]: loss 0.034110
[epoch20, step735]: loss 0.038267
[epoch20, step736]: loss 0.035956
[epoch20, step737]: loss 0.037156
[epoch20, step738]: loss 0.030558
[epoch20, step739]: loss 0.036546
[epoch20, step740]: loss 0.032801
[epoch20, step741]: loss 0.036413
[epoch20, step742]: loss 0.033028
[epoch20, step743]: loss 0.033830
[epoch20, step744]: loss 0.033780
[epoch20, step745]: loss 0.033954
[epoch20, step746]: loss 0.036636
[epoch20, step747]: loss 0.038744
[epoch20, step748]: loss 0.036575
[epoch20, step749]: loss 0.035666
[epoch20, step750]: loss 0.038063
[epoch20, step751]: loss 0.033185
[epoch20, step752]: loss 0.035377
[epoch20, step753]: loss 0.035801
[epoch20, step754]: loss 0.033938
[epoch20, step755]: loss 0.036185
[epoch20, step756]: loss 0.033711
[epoch20, step757]: loss 0.030383
[epoch20, step758]: loss 0.034168
[epoch20, step759]: loss 0.032970
[epoch20, step760]: loss 0.034654
[epoch20, step761]: loss 0.036739
[epoch20, step762]: loss 0.031391
[epoch20, step763]: loss 0.035212
[epoch20, step764]: loss 0.034699
[epoch20, step765]: loss 0.036669
[epoch20, step766]: loss 0.036366
[epoch20, step767]: loss 0.038095
[epoch20, step768]: loss 0.031020
[epoch20, step769]: loss 0.035618
[epoch20, step770]: loss 0.034675
[epoch20, step771]: loss 0.033023
[epoch20, step772]: loss 0.037857
[epoch20, step773]: loss 0.035765
[epoch20, step774]: loss 0.035252
[epoch20, step775]: loss 0.030036
[epoch20, step776]: loss 0.037432
[epoch20, step777]: loss 0.033639
[epoch20, step778]: loss 0.037306
[epoch20, step779]: loss 0.035014
[epoch20, step780]: loss 0.029873
[epoch20, step781]: loss 0.034856
[epoch20, step782]: loss 0.032310
[epoch20, step783]: loss 0.030372
[epoch20, step784]: loss 0.030824
[epoch20, step785]: loss 0.031329
[epoch20, step786]: loss 0.034522
[epoch20, step787]: loss 0.034610
[epoch20, step788]: loss 0.036323
[epoch20, step789]: loss 0.034806
[epoch20, step790]: loss 0.034567
[epoch20, step791]: loss 0.037932
[epoch20, step792]: loss 0.035456
[epoch20, step793]: loss 0.037077
[epoch20, step794]: loss 0.030128
[epoch20, step795]: loss 0.034894
[epoch20, step796]: loss 0.037683
[epoch20, step797]: loss 0.037065
[epoch20, step798]: loss 0.037340
[epoch20, step799]: loss 0.037304
[epoch20, step800]: loss 0.031340
[epoch20, step801]: loss 0.033709
[epoch20, step802]: loss 0.033210
[epoch20, step803]: loss 0.037065
[epoch20, step804]: loss 0.037058
[epoch20, step805]: loss 0.037850
[epoch20, step806]: loss 0.032832
[epoch20, step807]: loss 0.031439
[epoch20, step808]: loss 0.034113
[epoch20, step809]: loss 0.032429
[epoch20, step810]: loss 0.036030
[epoch20, step811]: loss 0.034907
[epoch20, step812]: loss 0.033402
[epoch20, step813]: loss 0.033890
[epoch20, step814]: loss 0.036551
[epoch20, step815]: loss 0.033806
[epoch20, step816]: loss 0.034266
[epoch20, step817]: loss 0.035304
[epoch20, step818]: loss 0.032495
[epoch20, step819]: loss 0.031114
[epoch20, step820]: loss 0.034076
[epoch20, step821]: loss 0.031521
[epoch20, step822]: loss 0.039993
[epoch20, step823]: loss 0.033825
[epoch20, step824]: loss 0.036015
[epoch20, step825]: loss 0.036165
[epoch20, step826]: loss 0.035259
[epoch20, step827]: loss 0.037143
[epoch20, step828]: loss 0.039168
[epoch20, step829]: loss 0.038240
[epoch20, step830]: loss 0.033208
[epoch20, step831]: loss 0.036987
[epoch20, step832]: loss 0.031493
[epoch20, step833]: loss 0.038513
[epoch20, step834]: loss 0.036704
[epoch20, step835]: loss 0.030840
[epoch20, step836]: loss 0.038991
[epoch20, step837]: loss 0.036159
[epoch20, step838]: loss 0.035054
[epoch20, step839]: loss 0.038784
[epoch20, step840]: loss 0.031280
[epoch20, step841]: loss 0.035350
[epoch20, step842]: loss 0.037694
[epoch20, step843]: loss 0.035853
[epoch20, step844]: loss 0.035458
[epoch20, step845]: loss 0.031899
[epoch20, step846]: loss 0.038382
[epoch20, step847]: loss 0.036819
[epoch20, step848]: loss 0.035438
[epoch20, step849]: loss 0.034070
[epoch20, step850]: loss 0.033546
[epoch20, step851]: loss 0.034574
[epoch20, step852]: loss 0.032806
[epoch20, step853]: loss 0.040068
[epoch20, step854]: loss 0.034009
[epoch20, step855]: loss 0.037363
[epoch20, step856]: loss 0.031559
[epoch20, step857]: loss 0.034309
[epoch20, step858]: loss 0.034267
[epoch20, step859]: loss 0.033954
[epoch20, step860]: loss 0.032447
[epoch20, step861]: loss 0.032114
[epoch20, step862]: loss 0.032728
[epoch20, step863]: loss 0.031326
[epoch20, step864]: loss 0.037105
[epoch20, step865]: loss 0.033849
[epoch20, step866]: loss 0.035281
[epoch20, step867]: loss 0.036920
[epoch20, step868]: loss 0.036135
[epoch20, step869]: loss 0.033634
[epoch20, step870]: loss 0.041223
[epoch20, step871]: loss 0.033480
[epoch20, step872]: loss 0.035662
[epoch20, step873]: loss 0.035772
[epoch20, step874]: loss 0.035059
[epoch20, step875]: loss 0.034076
[epoch20, step876]: loss 0.036136
[epoch20, step877]: loss 0.030035
[epoch20, step878]: loss 0.033443
[epoch20, step879]: loss 0.037284
[epoch20, step880]: loss 0.036605
[epoch20, step881]: loss 0.032596
[epoch20, step882]: loss 0.033835
[epoch20, step883]: loss 0.034138
[epoch20, step884]: loss 0.036809
[epoch20, step885]: loss 0.035210
[epoch20, step886]: loss 0.035658
[epoch20, step887]: loss 0.034970
[epoch20, step888]: loss 0.034978
[epoch20, step889]: loss 0.034413
[epoch20, step890]: loss 0.033941
[epoch20, step891]: loss 0.035868
[epoch20, step892]: loss 0.030473
[epoch20, step893]: loss 0.034175
[epoch20, step894]: loss 0.035258
[epoch20, step895]: loss 0.032172
[epoch20, step896]: loss 0.033023
[epoch20, step897]: loss 0.035773
[epoch20, step898]: loss 0.036503
[epoch20, step899]: loss 0.039041
[epoch20, step900]: loss 0.036020
[epoch20, step901]: loss 0.036607
[epoch20, step902]: loss 0.034238
[epoch20, step903]: loss 0.034838
[epoch20, step904]: loss 0.037249
[epoch20, step905]: loss 0.037873
[epoch20, step906]: loss 0.031754
[epoch20, step907]: loss 0.033687
[epoch20, step908]: loss 0.031452
[epoch20, step909]: loss 0.037044
[epoch20, step910]: loss 0.033309
[epoch20, step911]: loss 0.035237
[epoch20, step912]: loss 0.033044
[epoch20, step913]: loss 0.034506
[epoch20, step914]: loss 0.039260
[epoch20, step915]: loss 0.033612
[epoch20, step916]: loss 0.033047
[epoch20, step917]: loss 0.035320
[epoch20, step918]: loss 0.039346
[epoch20, step919]: loss 0.034696
[epoch20, step920]: loss 0.037580
[epoch20, step921]: loss 0.034007
[epoch20, step922]: loss 0.034257
[epoch20, step923]: loss 0.033223
[epoch20, step924]: loss 0.029860
[epoch20, step925]: loss 0.035741
[epoch20, step926]: loss 0.034685
[epoch20, step927]: loss 0.035216
[epoch20, step928]: loss 0.034701
[epoch20, step929]: loss 0.038059
[epoch20, step930]: loss 0.035716
[epoch20, step931]: loss 0.036847
[epoch20, step932]: loss 0.031090
[epoch20, step933]: loss 0.038771
[epoch20, step934]: loss 0.032691
[epoch20, step935]: loss 0.034175
[epoch20, step936]: loss 0.032210
[epoch20, step937]: loss 0.036235
[epoch20, step938]: loss 0.038424
[epoch20, step939]: loss 0.031291
[epoch20, step940]: loss 0.033982
[epoch20, step941]: loss 0.037939
[epoch20, step942]: loss 0.035997
[epoch20, step943]: loss 0.033526
[epoch20, step944]: loss 0.037836
[epoch20, step945]: loss 0.030973
[epoch20, step946]: loss 0.035217
[epoch20, step947]: loss 0.038813
[epoch20, step948]: loss 0.029795
[epoch20, step949]: loss 0.033836
[epoch20, step950]: loss 0.037973
[epoch20, step951]: loss 0.039359
[epoch20, step952]: loss 0.034339
[epoch20, step953]: loss 0.036685
[epoch20, step954]: loss 0.033162
[epoch20, step955]: loss 0.041564
[epoch20, step956]: loss 0.051135
[epoch20, step957]: loss 0.047650
[epoch20, step958]: loss 0.045261
[epoch20, step959]: loss 0.047281
[epoch20, step960]: loss 0.044305
[epoch20, step961]: loss 0.044419
[epoch20, step962]: loss 0.043189
[epoch20, step963]: loss 0.041868
[epoch20, step964]: loss 0.042729
[epoch20, step965]: loss 0.042616
[epoch20, step966]: loss 0.042243
[epoch20, step967]: loss 0.041671
[epoch20, step968]: loss 0.043446
[epoch20, step969]: loss 0.043265
[epoch20, step970]: loss 0.042360
[epoch20, step971]: loss 0.042470
[epoch20, step972]: loss 0.042653
[epoch20, step973]: loss 0.042224
[epoch20, step974]: loss 0.043805
[epoch20, step975]: loss 0.041710
[epoch20, step976]: loss 0.040929
[epoch20, step977]: loss 0.043025
[epoch20, step978]: loss 0.042006
[epoch20, step979]: loss 0.041481
[epoch20, step980]: loss 0.040556
[epoch20, step981]: loss 0.041792
[epoch20, step982]: loss 0.041669
[epoch20, step983]: loss 0.042201
[epoch20, step984]: loss 0.040918
[epoch20, step985]: loss 0.040715
[epoch20, step986]: loss 0.042645
[epoch20, step987]: loss 0.041848
[epoch20, step988]: loss 0.041779
[epoch20, step989]: loss 0.040823
[epoch20, step990]: loss 0.041327
[epoch20, step991]: loss 0.041621
[epoch20, step992]: loss 0.041225
[epoch20, step993]: loss 0.040973
[epoch20, step994]: loss 0.039617
[epoch20, step995]: loss 0.042440
[epoch20, step996]: loss 0.041086
[epoch20, step997]: loss 0.040827
[epoch20, step998]: loss 0.041530
[epoch20, step999]: loss 0.040681
[epoch20, step1000]: loss 0.041628
[epoch20, step1001]: loss 0.043076
[epoch20, step1002]: loss 0.041087
[epoch20, step1003]: loss 0.039953
[epoch20, step1004]: loss 0.042308
[epoch20, step1005]: loss 0.040374
[epoch20, step1006]: loss 0.040890
[epoch20, step1007]: loss 0.039959
[epoch20, step1008]: loss 0.040445
[epoch20, step1009]: loss 0.040935
[epoch20, step1010]: loss 0.041374
[epoch20, step1011]: loss 0.040163
[epoch20, step1012]: loss 0.039439
[epoch20, step1013]: loss 0.041534
[epoch20, step1014]: loss 0.041061
[epoch20, step1015]: loss 0.040707
[epoch20, step1016]: loss 0.039689
[epoch20, step1017]: loss 0.039999
[epoch20, step1018]: loss 0.040791
[epoch20, step1019]: loss 0.041112
[epoch20, step1020]: loss 0.040466
[epoch20, step1021]: loss 0.039352
[epoch20, step1022]: loss 0.041771
[epoch20, step1023]: loss 0.041650
[epoch20, step1024]: loss 0.041716
[epoch20, step1025]: loss 0.039740
[epoch20, step1026]: loss 0.040829
[epoch20, step1027]: loss 0.040752
[epoch20, step1028]: loss 0.040956
[epoch20, step1029]: loss 0.040498
[epoch20, step1030]: loss 0.039148
[epoch20, step1031]: loss 0.041315
[epoch20, step1032]: loss 0.040528
[epoch20, step1033]: loss 0.040548
[epoch20, step1034]: loss 0.039347
[epoch20, step1035]: loss 0.039997
[epoch20, step1036]: loss 0.040838
[epoch20, step1037]: loss 0.040618
[epoch20, step1038]: loss 0.039795
[epoch20, step1039]: loss 0.039911
[epoch20, step1040]: loss 0.041182
[epoch20, step1041]: loss 0.040449
[epoch20, step1042]: loss 0.040375
[epoch20, step1043]: loss 0.039539
[epoch20, step1044]: loss 0.040707
[epoch20, step1045]: loss 0.040931
[epoch20, step1046]: loss 0.040970
[epoch20, step1047]: loss 0.040409
[epoch20, step1048]: loss 0.039442
[epoch20, step1049]: loss 0.041968
[epoch20, step1050]: loss 0.040335
[epoch20, step1051]: loss 0.040135
[epoch20, step1052]: loss 0.039966
[epoch20, step1053]: loss 0.040817
[epoch20, step1054]: loss 0.040236
[epoch20, step1055]: loss 0.040158
[epoch20, step1056]: loss 0.039435
[epoch20, step1057]: loss 0.039375
[epoch20, step1058]: loss 0.042146
[epoch20, step1059]: loss 0.040814
[epoch20, step1060]: loss 0.040197
[epoch20, step1061]: loss 0.039625
[epoch20, step1062]: loss 0.041340
[epoch20, step1063]: loss 0.040803
[epoch20, step1064]: loss 0.041299
[epoch20, step1065]: loss 0.040062
[epoch20, step1066]: loss 0.038969
[epoch20, step1067]: loss 0.041371
[epoch20, step1068]: loss 0.039659
[epoch20, step1069]: loss 0.040009
[epoch20, step1070]: loss 0.039615
[epoch20, step1071]: loss 0.040302
[epoch20, step1072]: loss 0.040499
[epoch20, step1073]: loss 0.040447
[epoch20, step1074]: loss 0.039635
[epoch20, step1075]: loss 0.039371
[epoch20, step1076]: loss 0.040956
[epoch20, step1077]: loss 0.040311
[epoch20, step1078]: loss 0.040452
[epoch20, step1079]: loss 0.040550
[epoch20, step1080]: loss 0.040758
[epoch20, step1081]: loss 0.040172
[epoch20, step1082]: loss 0.039944
[epoch20, step1083]: loss 0.040890
[epoch20, step1084]: loss 0.039033
[epoch20, step1085]: loss 0.040286
[epoch20, step1086]: loss 0.039733
[epoch20, step1087]: loss 0.039791
[epoch20, step1088]: loss 0.039387
[epoch20, step1089]: loss 0.039596
[epoch20, step1090]: loss 0.040478
[epoch20, step1091]: loss 0.040923
[epoch20, step1092]: loss 0.039591
[epoch20, step1093]: loss 0.038943
[epoch20, step1094]: loss 0.040510
[epoch20, step1095]: loss 0.040067
[epoch20, step1096]: loss 0.039320
[epoch20, step1097]: loss 0.040323
[epoch20, step1098]: loss 0.040002
[epoch20, step1099]: loss 0.040689
[epoch20, step1100]: loss 0.041418
[epoch20, step1101]: loss 0.040166
[epoch20, step1102]: loss 0.038518
[epoch20, step1103]: loss 0.040948
[epoch20, step1104]: loss 0.039211
[epoch20, step1105]: loss 0.039805
[epoch20, step1106]: loss 0.038248
[epoch20, step1107]: loss 0.039039
[epoch20, step1108]: loss 0.039185
[epoch20, step1109]: loss 0.039624
[epoch20, step1110]: loss 0.039434
[epoch20, step1111]: loss 0.038241
[epoch20, step1112]: loss 0.040310
[epoch20, step1113]: loss 0.038923
[epoch20, step1114]: loss 0.039216
[epoch20, step1115]: loss 0.038915
[epoch20, step1116]: loss 0.039004
[epoch20, step1117]: loss 0.040029
[epoch20, step1118]: loss 0.040830
[epoch20, step1119]: loss 0.038260
[epoch20, step1120]: loss 0.038276
[epoch20, step1121]: loss 0.040559
[epoch20, step1122]: loss 0.040528
[epoch20, step1123]: loss 0.039350
[epoch20, step1124]: loss 0.040049
[epoch20, step1125]: loss 0.038801
[epoch20, step1126]: loss 0.040167
[epoch20, step1127]: loss 0.040381
[epoch20, step1128]: loss 0.039515
[epoch20, step1129]: loss 0.037920
[epoch20, step1130]: loss 0.040578
[epoch20, step1131]: loss 0.040611
[epoch20, step1132]: loss 0.039466
[epoch20, step1133]: loss 0.037744
[epoch20, step1134]: loss 0.039370
[epoch20, step1135]: loss 0.039896
[epoch20, step1136]: loss 0.040980
[epoch20, step1137]: loss 0.038376
[epoch20, step1138]: loss 0.037629
[epoch20, step1139]: loss 0.041063
[epoch20, step1140]: loss 0.038571
[epoch20, step1141]: loss 0.039052
[epoch20, step1142]: loss 0.039385
[epoch20, step1143]: loss 0.038927
[epoch20, step1144]: loss 0.039633
[epoch20, step1145]: loss 0.039284
[epoch20, step1146]: loss 0.038368
[epoch20, step1147]: loss 0.038232
[epoch20, step1148]: loss 0.040770
[epoch20, step1149]: loss 0.039266
[epoch20, step1150]: loss 0.038758
[epoch20, step1151]: loss 0.038199
[epoch20, step1152]: loss 0.039716
[epoch20, step1153]: loss 0.039220
[epoch20, step1154]: loss 0.039572
[epoch20, step1155]: loss 0.038431
[epoch20, step1156]: loss 0.037456
[epoch20, step1157]: loss 0.040934
[epoch20, step1158]: loss 0.041161
[epoch20, step1159]: loss 0.040140
[epoch20, step1160]: loss 0.039471
[epoch20, step1161]: loss 0.040055
[epoch20, step1162]: loss 0.039361
[epoch20, step1163]: loss 0.040587
[epoch20, step1164]: loss 0.039874
[epoch20, step1165]: loss 0.039063
[epoch20, step1166]: loss 0.040609
[epoch20, step1167]: loss 0.040124
[epoch20, step1168]: loss 0.039191
[epoch20, step1169]: loss 0.037803
[epoch20, step1170]: loss 0.038620
[epoch20, step1171]: loss 0.039215
[epoch20, step1172]: loss 0.040498
[epoch20, step1173]: loss 0.038615
[epoch20, step1174]: loss 0.037985
[epoch20, step1175]: loss 0.039820
[epoch20, step1176]: loss 0.039563
[epoch20, step1177]: loss 0.039121
[epoch20, step1178]: loss 0.038659
[epoch20, step1179]: loss 0.038056
[epoch20, step1180]: loss 0.039259
[epoch20, step1181]: loss 0.043663
[epoch20, step1182]: loss 0.040224
[epoch20, step1183]: loss 0.039057
[epoch20, step1184]: loss 0.040440
[epoch20, step1185]: loss 0.039889
[epoch20, step1186]: loss 0.039972
[epoch20, step1187]: loss 0.037752
[epoch20, step1188]: loss 0.038792
[epoch20, step1189]: loss 0.039851
[epoch20, step1190]: loss 0.039280
[epoch20, step1191]: loss 0.039534
[epoch20, step1192]: loss 0.037522
[epoch20, step1193]: loss 0.040073
[epoch20, step1194]: loss 0.039540
[epoch20, step1195]: loss 0.038558
[epoch20, step1196]: loss 0.037970
[epoch20, step1197]: loss 0.040076
[epoch20, step1198]: loss 0.039221
[epoch20, step1199]: loss 0.039757
[epoch20, step1200]: loss 0.039030
[epoch20, step1201]: loss 0.038243
[epoch20, step1202]: loss 0.040636
[epoch20, step1203]: loss 0.039144
[epoch20, step1204]: loss 0.039003
[epoch20, step1205]: loss 0.037868
[epoch20, step1206]: loss 0.038722
[epoch20, step1207]: loss 0.039606
[epoch20, step1208]: loss 0.039690
[epoch20, step1209]: loss 0.038400
[epoch20, step1210]: loss 0.038138
[epoch20, step1211]: loss 0.040473
[epoch20, step1212]: loss 0.039182
[epoch20, step1213]: loss 0.038724
[epoch20, step1214]: loss 0.038024
[epoch20, step1215]: loss 0.040141
[epoch20, step1216]: loss 0.039227
[epoch20, step1217]: loss 0.039501
[epoch20, step1218]: loss 0.037897
[epoch20, step1219]: loss 0.038052
[epoch20, step1220]: loss 0.039917
[epoch20, step1221]: loss 0.038854
[epoch20, step1222]: loss 0.038326
[epoch20, step1223]: loss 0.037450
[epoch20, step1224]: loss 0.038357
[epoch20, step1225]: loss 0.038801
[epoch20, step1226]: loss 0.039576
[epoch20, step1227]: loss 0.038022
[epoch20, step1228]: loss 0.036798
[epoch20, step1229]: loss 0.040250
[epoch20, step1230]: loss 0.040660
[epoch20, step1231]: loss 0.038963
[epoch20, step1232]: loss 0.039838
[epoch20, step1233]: loss 0.039028
[epoch20, step1234]: loss 0.039047
[epoch20, step1235]: loss 0.040628
[epoch20, step1236]: loss 0.038963
[epoch20, step1237]: loss 0.038004
[epoch20, step1238]: loss 0.039534
[epoch20, step1239]: loss 0.039014
[epoch20, step1240]: loss 0.039176
[epoch20, step1241]: loss 0.038000
[epoch20, step1242]: loss 0.038751
[epoch20, step1243]: loss 0.039074
[epoch20, step1244]: loss 0.038912
[epoch20, step1245]: loss 0.037575
[epoch20, step1246]: loss 0.036976
[epoch20, step1247]: loss 0.039165
[epoch20, step1248]: loss 0.039290
[epoch20, step1249]: loss 0.041032
[epoch20, step1250]: loss 0.038262
[epoch20, step1251]: loss 0.038014
[epoch20, step1252]: loss 0.039941
[epoch20, step1253]: loss 0.040226
[epoch20, step1254]: loss 0.039262
[epoch20, step1255]: loss 0.038408
[epoch20, step1256]: loss 0.039477
[epoch20, step1257]: loss 0.038390
[epoch20, step1258]: loss 0.038318
[epoch20, step1259]: loss 0.037463
[epoch20, step1260]: loss 0.038536
[epoch20, step1261]: loss 0.038591
[epoch20, step1262]: loss 0.039195
[epoch20, step1263]: loss 0.038068
[epoch20, step1264]: loss 0.039185
[epoch20, step1265]: loss 0.038833
[epoch20, step1266]: loss 0.038166
[epoch20, step1267]: loss 0.038735
[epoch20, step1268]: loss 0.037710
[epoch20, step1269]: loss 0.038812
[epoch20, step1270]: loss 0.038338
[epoch20, step1271]: loss 0.039351
[epoch20, step1272]: loss 0.037673
[epoch20, step1273]: loss 0.037301
[epoch20, step1274]: loss 0.039611
[epoch20, step1275]: loss 0.039108
[epoch20, step1276]: loss 0.037826
[epoch20, step1277]: loss 0.037456
[epoch20, step1278]: loss 0.039130
[epoch20, step1279]: loss 0.038575
[epoch20, step1280]: loss 0.039141
[epoch20, step1281]: loss 0.037821
[epoch20, step1282]: loss 0.037426
[epoch20, step1283]: loss 0.038795
[epoch20, step1284]: loss 0.038930
[epoch20, step1285]: loss 0.041221
[epoch20, step1286]: loss 0.037522
[epoch20, step1287]: loss 0.040636
[epoch20, step1288]: loss 0.038626
[epoch20, step1289]: loss 0.039909
[epoch20, step1290]: loss 0.040272
[epoch20, step1291]: loss 0.040255
[epoch20, step1292]: loss 0.040100
[epoch20, step1293]: loss 0.039263
[epoch20, step1294]: loss 0.037935
[epoch20, step1295]: loss 0.038666
[epoch20, step1296]: loss 0.039895
[epoch20, step1297]: loss 0.040062
[epoch20, step1298]: loss 0.040923
[epoch20, step1299]: loss 0.039300
[epoch20, step1300]: loss 0.038521
[epoch20, step1301]: loss 0.039661
[epoch20, step1302]: loss 0.039164
[epoch20, step1303]: loss 0.038894
[epoch20, step1304]: loss 0.038208
[epoch20, step1305]: loss 0.038877
[epoch20, step1306]: loss 0.038900
[epoch20, step1307]: loss 0.039743
[epoch20, step1308]: loss 0.039881
[epoch20, step1309]: loss 0.037027
[epoch20, step1310]: loss 0.040011
[epoch20, step1311]: loss 0.038301
[epoch20, step1312]: loss 0.038279
[epoch20, step1313]: loss 0.037548
[epoch20, step1314]: loss 0.039186
[epoch20, step1315]: loss 0.038505
[epoch20, step1316]: loss 0.041005
[epoch20, step1317]: loss 0.037159
[epoch20, step1318]: loss 0.037450
[epoch20, step1319]: loss 0.039346
[epoch20, step1320]: loss 0.038289
[epoch20, step1321]: loss 0.038619
[epoch20, step1322]: loss 0.037956
[epoch20, step1323]: loss 0.038747
[epoch20, step1324]: loss 0.038906
[epoch20, step1325]: loss 0.039131
[epoch20, step1326]: loss 0.037694
[epoch20, step1327]: loss 0.037184
[epoch20, step1328]: loss 0.040689
[epoch20, step1329]: loss 0.038448
[epoch20, step1330]: loss 0.038131
[epoch20, step1331]: loss 0.037703
[epoch20, step1332]: loss 0.037881
[epoch20, step1333]: loss 0.038702
[epoch20, step1334]: loss 0.039096
[epoch20, step1335]: loss 0.038160
[epoch20, step1336]: loss 0.037477
[epoch20, step1337]: loss 0.039926
[epoch20, step1338]: loss 0.038494
[epoch20, step1339]: loss 0.038348
[epoch20, step1340]: loss 0.037398
[epoch20, step1341]: loss 0.038147
[epoch20, step1342]: loss 0.037967
[epoch20, step1343]: loss 0.038772
[epoch20, step1344]: loss 0.037261
[epoch20, step1345]: loss 0.036323
[epoch20, step1346]: loss 0.039725
[epoch20, step1347]: loss 0.037764
[epoch20, step1348]: loss 0.038182
[epoch20, step1349]: loss 0.037674
[epoch20, step1350]: loss 0.037855
[epoch20, step1351]: loss 0.038206
[epoch20, step1352]: loss 0.038934
[epoch20, step1353]: loss 0.038031
[epoch20, step1354]: loss 0.037235
[epoch20, step1355]: loss 0.040217
[epoch20, step1356]: loss 0.038447
[epoch20, step1357]: loss 0.038125
[epoch20, step1358]: loss 0.036901
[epoch20, step1359]: loss 0.037535
[epoch20, step1360]: loss 0.038818
[epoch20, step1361]: loss 0.039710
[epoch20, step1362]: loss 0.036910
[epoch20, step1363]: loss 0.037322
[epoch20, step1364]: loss 0.040088
[epoch20, step1365]: loss 0.038647
[epoch20, step1366]: loss 0.038511
[epoch20, step1367]: loss 0.037423
[epoch20, step1368]: loss 0.039892
[epoch20, step1369]: loss 0.039876
[epoch20, step1370]: loss 0.039223
[epoch20, step1371]: loss 0.037145
[epoch20, step1372]: loss 0.037070
[epoch20, step1373]: loss 0.039458
[epoch20, step1374]: loss 0.038054
[epoch20, step1375]: loss 0.039548
[epoch20, step1376]: loss 0.038852
[epoch20, step1377]: loss 0.039046
[epoch20, step1378]: loss 0.039105
[epoch20, step1379]: loss 0.039751
[epoch20, step1380]: loss 0.039343
[epoch20, step1381]: loss 0.037252
[epoch20, step1382]: loss 0.039785
[epoch20, step1383]: loss 0.038140
[epoch20, step1384]: loss 0.038266
[epoch20, step1385]: loss 0.036977
[epoch20, step1386]: loss 0.039120
[epoch20, step1387]: loss 0.038895
[epoch20, step1388]: loss 0.039002
[epoch20, step1389]: loss 0.037451
[epoch20, step1390]: loss 0.037107
[epoch20, step1391]: loss 0.039330
[epoch20, step1392]: loss 0.038109
[epoch20, step1393]: loss 0.038245
[epoch20, step1394]: loss 0.038237
[epoch20, step1395]: loss 0.038044
[epoch20, step1396]: loss 0.038422
[epoch20, step1397]: loss 0.038128
[epoch20, step1398]: loss 0.037049
[epoch20, step1399]: loss 0.037692
[epoch20, step1400]: loss 0.040321
[epoch20, step1401]: loss 0.038232
[epoch20, step1402]: loss 0.037600
[epoch20, step1403]: loss 0.036826
[epoch20, step1404]: loss 0.038460
[epoch20, step1405]: loss 0.039091
[epoch20, step1406]: loss 0.039446
[epoch20, step1407]: loss 0.040237
[epoch20, step1408]: loss 0.036699
[epoch20, step1409]: loss 0.039377
[epoch20, step1410]: loss 0.038133
[epoch20, step1411]: loss 0.038590
[epoch20, step1412]: loss 0.036914
[epoch20, step1413]: loss 0.037775
[epoch20, step1414]: loss 0.038084
[epoch20, step1415]: loss 0.038719
[epoch20, step1416]: loss 0.038258
[epoch20, step1417]: loss 0.037031
[epoch20, step1418]: loss 0.039586
[epoch20, step1419]: loss 0.038473
[epoch20, step1420]: loss 0.038060
[epoch20, step1421]: loss 0.037115
[epoch20, step1422]: loss 0.037439
[epoch20, step1423]: loss 0.038764
[epoch20, step1424]: loss 0.040460
[epoch20, step1425]: loss 0.037622
[epoch20, step1426]: loss 0.038512
[epoch20, step1427]: loss 0.041272
[epoch20, step1428]: loss 0.039898
[epoch20, step1429]: loss 0.038851
[epoch20, step1430]: loss 0.037279
[epoch20, step1431]: loss 0.039113
[epoch20, step1432]: loss 0.038684
[epoch20, step1433]: loss 0.039399
[epoch20, step1434]: loss 0.038366
[epoch20, step1435]: loss 0.037265
[epoch20, step1436]: loss 0.040224
[epoch20, step1437]: loss 0.037968
[epoch20, step1438]: loss 0.037852
[epoch20, step1439]: loss 0.037106
[epoch20, step1440]: loss 0.038376
[epoch20, step1441]: loss 0.038830
[epoch20, step1442]: loss 0.039562
[epoch20, step1443]: loss 0.037686
[epoch20, step1444]: loss 0.036627
[epoch20, step1445]: loss 0.040131
[epoch20, step1446]: loss 0.039052
[epoch20, step1447]: loss 0.039873
[epoch20, step1448]: loss 0.037688
[epoch20, step1449]: loss 0.038483
[epoch20, step1450]: loss 0.038099
[epoch20, step1451]: loss 0.039259
[epoch20, step1452]: loss 0.038094
[epoch20, step1453]: loss 0.037193
[epoch20, step1454]: loss 0.039696
[epoch20, step1455]: loss 0.038428
[epoch20, step1456]: loss 0.038523
[epoch20, step1457]: loss 0.036951
[epoch20, step1458]: loss 0.037875
[epoch20, step1459]: loss 0.038403
[epoch20, step1460]: loss 0.039710
[epoch20, step1461]: loss 0.037508
[epoch20, step1462]: loss 0.037490
[epoch20, step1463]: loss 0.039786
[epoch20, step1464]: loss 0.038096
[epoch20, step1465]: loss 0.038660
[epoch20, step1466]: loss 0.036595
[epoch20, step1467]: loss 0.038500
[epoch20, step1468]: loss 0.037626
[epoch20, step1469]: loss 0.039274
[epoch20, step1470]: loss 0.038335
[epoch20, step1471]: loss 0.036669
[epoch20, step1472]: loss 0.038420
[epoch20, step1473]: loss 0.038136
[epoch20, step1474]: loss 0.038415
[epoch20, step1475]: loss 0.037054
[epoch20, step1476]: loss 0.038479
[epoch20, step1477]: loss 0.038617
[epoch20, step1478]: loss 0.038768
[epoch20, step1479]: loss 0.037163
[epoch20, step1480]: loss 0.036727
[epoch20, step1481]: loss 0.038646
[epoch20, step1482]: loss 0.038848
[epoch20, step1483]: loss 0.038322
[epoch20, step1484]: loss 0.038096
[epoch20, step1485]: loss 0.038655
[epoch20, step1486]: loss 0.038040
[epoch20, step1487]: loss 0.039098
[epoch20, step1488]: loss 0.038277
[epoch20, step1489]: loss 0.037295
[epoch20, step1490]: loss 0.039231
[epoch20, step1491]: loss 0.037856
[epoch20, step1492]: loss 0.037743
[epoch20, step1493]: loss 0.038151
[epoch20, step1494]: loss 0.038134
[epoch20, step1495]: loss 0.037716
[epoch20, step1496]: loss 0.039410
[epoch20, step1497]: loss 0.038068
[epoch20, step1498]: loss 0.036539
[epoch20, step1499]: loss 0.041210
[epoch20, step1500]: loss 0.037711
[epoch20, step1501]: loss 0.037563
[epoch20, step1502]: loss 0.036560
[epoch20, step1503]: loss 0.038339
[epoch20, step1504]: loss 0.037690
[epoch20, step1505]: loss 0.040214
[epoch20, step1506]: loss 0.036765
[epoch20, step1507]: loss 0.036923
[epoch20, step1508]: loss 0.040270
[epoch20, step1509]: loss 0.038685
[epoch20, step1510]: loss 0.039020
[epoch20, step1511]: loss 0.037297
[epoch20, step1512]: loss 0.037691
[epoch20, step1513]: loss 0.038880
[epoch20, step1514]: loss 0.038714
[epoch20, step1515]: loss 0.037997
[epoch20, step1516]: loss 0.037039

[epoch20]: avg loss 0.036601

