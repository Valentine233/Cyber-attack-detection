[epoch1, step1]: loss 2080.635010
[epoch1, step2]: loss 2061.895752
[epoch1, step3]: loss 2014.295166
[epoch1, step4]: loss 2017.115479
[epoch1, step5]: loss 2013.555176
[epoch1, step6]: loss 2027.710327
[epoch1, step7]: loss 1984.293945
[epoch1, step8]: loss 1971.801514
[epoch1, step9]: loss 1984.933472
[epoch1, step10]: loss 1983.828491
[epoch1, step11]: loss 2003.110596
[epoch1, step12]: loss 1973.294922
[epoch1, step13]: loss 1930.485596
[epoch1, step14]: loss 1914.412720
[epoch1, step15]: loss 1920.281738
[epoch1, step16]: loss 1944.908813
[epoch1, step17]: loss 1918.635986
[epoch1, step18]: loss 1916.300903
[epoch1, step19]: loss 1895.415039
[epoch1, step20]: loss 1898.548340
[epoch1, step21]: loss 1920.356934
[epoch1, step22]: loss 1906.986206
[epoch1, step23]: loss 1880.432861
[epoch1, step24]: loss 1910.312012
[epoch1, step25]: loss 1872.133057
[epoch1, step26]: loss 1870.815918
[epoch1, step27]: loss 1854.550903
[epoch1, step28]: loss 1819.950684
[epoch1, step29]: loss 1884.752197
[epoch1, step30]: loss 1825.035889
[epoch1, step31]: loss 1797.957886
[epoch1, step32]: loss 1805.384399
[epoch1, step33]: loss 1820.490845
[epoch1, step34]: loss 1801.058350
[epoch1, step35]: loss 1756.052002
[epoch1, step36]: loss 1800.737793
[epoch1, step37]: loss 1759.723145
[epoch1, step38]: loss 1767.568848
[epoch1, step39]: loss 1761.166748
[epoch1, step40]: loss 1756.796143
[epoch1, step41]: loss 1739.533936
[epoch1, step42]: loss 1746.199951
[epoch1, step43]: loss 1700.841553
[epoch1, step44]: loss 1744.021851
[epoch1, step45]: loss 1681.194580
[epoch1, step46]: loss 1690.737305
[epoch1, step47]: loss 1703.031982
[epoch1, step48]: loss 1708.346924
[epoch1, step49]: loss 1653.038940
[epoch1, step50]: loss 1689.223511
[epoch1, step51]: loss 1624.419067
[epoch1, step52]: loss 1561.169312
[epoch1, step53]: loss 1616.875977
[epoch1, step54]: loss 1633.062744
[epoch1, step55]: loss 1635.358765
[epoch1, step56]: loss 1593.157104
[epoch1, step57]: loss 1593.193237
[epoch1, step58]: loss 1611.396729
[epoch1, step59]: loss 1561.001831
[epoch1, step60]: loss 1541.571899
[epoch1, step61]: loss 1504.209351
[epoch1, step62]: loss 1567.931885
[epoch1, step63]: loss 1574.547974
[epoch1, step64]: loss 1569.035645
[epoch1, step65]: loss 1482.136719
[epoch1, step66]: loss 1474.034180
[epoch1, step67]: loss 1480.781616
[epoch1, step68]: loss 1456.268311
[epoch1, step69]: loss 1492.119873
[epoch1, step70]: loss 1393.269043
[epoch1, step71]: loss 1390.768799
[epoch1, step72]: loss 1492.611816
[epoch1, step73]: loss 1379.115479
[epoch1, step74]: loss 1416.218018
[epoch1, step75]: loss 1396.797607
[epoch1, step76]: loss 1409.488647
[epoch1, step77]: loss 1328.425537
[epoch1, step78]: loss 1411.245483
[epoch1, step79]: loss 1318.616943
[epoch1, step80]: loss 1325.948730
[epoch1, step81]: loss 1282.144897
[epoch1, step82]: loss 1366.312378
[epoch1, step83]: loss 1336.184692
[epoch1, step84]: loss 1216.610107
[epoch1, step85]: loss 1326.441162
[epoch1, step86]: loss 1227.755371
[epoch1, step87]: loss 1306.892334
[epoch1, step88]: loss 1219.614746
[epoch1, step89]: loss 1310.715088
[epoch1, step90]: loss 1184.821655
[epoch1, step91]: loss 1228.279785
[epoch1, step92]: loss 1175.760498
[epoch1, step93]: loss 1111.501953
[epoch1, step94]: loss 1190.296021
[epoch1, step95]: loss 1171.291870
[epoch1, step96]: loss 1199.759399
[epoch1, step97]: loss 1176.787109
[epoch1, step98]: loss 1062.532227
[epoch1, step99]: loss 1083.464233
[epoch1, step100]: loss 1113.151001
[epoch1, step101]: loss 1107.969238
[epoch1, step102]: loss 991.402222
[epoch1, step103]: loss 1069.314453
[epoch1, step104]: loss 1020.925598
[epoch1, step105]: loss 903.442566
[epoch1, step106]: loss 891.640930
[epoch1, step107]: loss 930.447510
[epoch1, step108]: loss 960.237244
[epoch1, step109]: loss 994.721008
[epoch1, step110]: loss 953.579224
[epoch1, step111]: loss 1000.222290
[epoch1, step112]: loss 968.032349
[epoch1, step113]: loss 984.552368
[epoch1, step114]: loss 1042.707642
[epoch1, step115]: loss 922.111328
[epoch1, step116]: loss 991.673828
[epoch1, step117]: loss 789.907776
[epoch1, step118]: loss 894.265747
[epoch1, step119]: loss 1028.280518
[epoch1, step120]: loss 852.783264
[epoch1, step121]: loss 840.151367
[epoch1, step122]: loss 876.908203
[epoch1, step123]: loss 777.377563
[epoch1, step124]: loss 981.301514
[epoch1, step125]: loss 897.036987
[epoch1, step126]: loss 720.051941
[epoch1, step127]: loss 800.566589
[epoch1, step128]: loss 824.793823
[epoch1, step129]: loss 943.108643
[epoch1, step130]: loss 652.898682
[epoch1, step131]: loss 856.331787
[epoch1, step132]: loss 909.798950
[epoch1, step133]: loss 795.665222
[epoch1, step134]: loss 814.698853
[epoch1, step135]: loss 695.037964
[epoch1, step136]: loss 851.956055
[epoch1, step137]: loss 587.938965
[epoch1, step138]: loss 690.503967
[epoch1, step139]: loss 781.742432
[epoch1, step140]: loss 630.018921
[epoch1, step141]: loss 618.991760
[epoch1, step142]: loss 699.656494
[epoch1, step143]: loss 875.688232
[epoch1, step144]: loss 659.036560
[epoch1, step145]: loss 525.935852
[epoch1, step146]: loss 687.472229
[epoch1, step147]: loss 644.115234
[epoch1, step148]: loss 645.942322
[epoch1, step149]: loss 785.542969
[epoch1, step150]: loss 574.041321
[epoch1, step151]: loss 639.286377
[epoch1, step152]: loss 538.548340
[epoch1, step153]: loss 537.468567
[epoch1, step154]: loss 481.984314
[epoch1, step155]: loss 569.944458
[epoch1, step156]: loss 620.123352
[epoch1, step157]: loss 468.882812
[epoch1, step158]: loss 496.826233
[epoch1, step159]: loss 542.247131
[epoch1, step160]: loss 365.055664
[epoch1, step161]: loss 488.129120
[epoch1, step162]: loss 581.596497
[epoch1, step163]: loss 609.685120
[epoch1, step164]: loss 769.575806
[epoch1, step165]: loss 461.778259
[epoch1, step166]: loss 492.129333
[epoch1, step167]: loss 411.232422
[epoch1, step168]: loss 555.457336
[epoch1, step169]: loss 468.096771
[epoch1, step170]: loss 567.503906
[epoch1, step171]: loss 657.338074
[epoch1, step172]: loss 721.286560
[epoch1, step173]: loss 549.184692
[epoch1, step174]: loss 233.413315
[epoch1, step175]: loss 357.132050
[epoch1, step176]: loss 313.980988
[epoch1, step177]: loss 485.138733
[epoch1, step178]: loss 391.460266
[epoch1, step179]: loss 390.684967
[epoch1, step180]: loss 502.936798
[epoch1, step181]: loss 521.578918
[epoch1, step182]: loss 322.020508
[epoch1, step183]: loss 489.623840
[epoch1, step184]: loss 537.124390
[epoch1, step185]: loss 363.895142
[epoch1, step186]: loss 491.037750
[epoch1, step187]: loss 391.197601
[epoch1, step188]: loss 531.104797
[epoch1, step189]: loss 501.070374
[epoch1, step190]: loss 518.031189
[epoch1, step191]: loss 418.340881
[epoch1, step192]: loss 501.957733
[epoch1, step193]: loss 228.133453
[epoch1, step194]: loss 242.062500
[epoch1, step195]: loss 368.133148
[epoch1, step196]: loss 404.265167
[epoch1, step197]: loss 223.678421
[epoch1, step198]: loss 395.994812
[epoch1, step199]: loss 406.096893
[epoch1, step200]: loss 409.525269
[epoch1, step201]: loss 295.486816
[epoch1, step202]: loss 341.295746
[epoch1, step203]: loss 496.789093
[epoch1, step204]: loss 342.979797
[epoch1, step205]: loss 411.110596
[epoch1, step206]: loss 296.535217
[epoch1, step207]: loss 516.821716
[epoch1, step208]: loss 114.389725
[epoch1, step209]: loss 338.061890
[epoch1, step210]: loss 427.937378
[epoch1, step211]: loss 478.227173
[epoch1, step212]: loss 415.451080
[epoch1, step213]: loss 345.208038
[epoch1, step214]: loss 217.398560
[epoch1, step215]: loss 455.987976
[epoch1, step216]: loss 225.874405
[epoch1, step217]: loss 310.382446
[epoch1, step218]: loss 270.220459
[epoch1, step219]: loss 389.373016
[epoch1, step220]: loss 458.257660
[epoch1, step221]: loss 175.733978
[epoch1, step222]: loss 340.337646
[epoch1, step223]: loss 296.345428
[epoch1, step224]: loss 266.582642
[epoch1, step225]: loss 519.877319
[epoch1, step226]: loss 392.338196
[epoch1, step227]: loss 503.495972
[epoch1, step228]: loss 190.672821
[epoch1, step229]: loss 368.481964
[epoch1, step230]: loss 459.160400
[epoch1, step231]: loss 551.149902
[epoch1, step232]: loss 192.883041
[epoch1, step233]: loss 328.413696
[epoch1, step234]: loss 339.205933
[epoch1, step235]: loss 200.417267
[epoch1, step236]: loss 421.964203
[epoch1, step237]: loss 210.883911
[epoch1, step238]: loss 279.327148
[epoch1, step239]: loss 240.282104
[epoch1, step240]: loss 154.238495
[epoch1, step241]: loss 350.367859
[epoch1, step242]: loss 372.356628
[epoch1, step243]: loss 260.622986
[epoch1, step244]: loss 304.286804
[epoch1, step245]: loss 301.736725
[epoch1, step246]: loss 215.583618
[epoch1, step247]: loss 347.897522
[epoch1, step248]: loss 263.884399
[epoch1, step249]: loss 299.747223
[epoch1, step250]: loss 138.222733
[epoch1, step251]: loss 317.424591
[epoch1, step252]: loss 187.714691
[epoch1, step253]: loss 430.299683
[epoch1, step254]: loss 220.587387
[epoch1, step255]: loss 225.777771
[epoch1, step256]: loss 490.674988
[epoch1, step257]: loss 217.284348
[epoch1, step258]: loss 518.089722
[epoch1, step259]: loss 269.666412
[epoch1, step260]: loss 234.074951
[epoch1, step261]: loss 337.840271
[epoch1, step262]: loss 432.676575
[epoch1, step263]: loss 232.552185
[epoch1, step264]: loss 305.437317
[epoch1, step265]: loss 134.931519
[epoch1, step266]: loss 183.883316
[epoch1, step267]: loss 180.896896
[epoch1, step268]: loss 225.634308
[epoch1, step269]: loss 115.146851
[epoch1, step270]: loss 263.853424
[epoch1, step271]: loss 219.529297
[epoch1, step272]: loss 178.086639
[epoch1, step273]: loss 203.277832
[epoch1, step274]: loss 244.583862
[epoch1, step275]: loss 176.083298
[epoch1, step276]: loss 212.364594
[epoch1, step277]: loss 118.611732
[epoch1, step278]: loss 236.474869
[epoch1, step279]: loss 138.629700
[epoch1, step280]: loss 280.583618
[epoch1, step281]: loss 341.462036
[epoch1, step282]: loss 403.899353
[epoch1, step283]: loss 359.398071
[epoch1, step284]: loss 205.379745
[epoch1, step285]: loss 250.248749
[epoch1, step286]: loss 162.719376
[epoch1, step287]: loss 197.038177
[epoch1, step288]: loss 133.883759
[epoch1, step289]: loss 221.521805
[epoch1, step290]: loss 211.342651
[epoch1, step291]: loss 197.386337
[epoch1, step292]: loss 283.415497
[epoch1, step293]: loss 178.948883
[epoch1, step294]: loss 217.922729
[epoch1, step295]: loss 140.444244
[epoch1, step296]: loss 168.761475
[epoch1, step297]: loss 384.234558
[epoch1, step298]: loss 268.998383
[epoch1, step299]: loss 208.814240
[epoch1, step300]: loss 262.000671
[epoch1, step301]: loss 333.752197
[epoch1, step302]: loss 239.618011
[epoch1, step303]: loss 298.092773
[epoch1, step304]: loss 142.751999
[epoch1, step305]: loss 137.247009
[epoch1, step306]: loss 239.226883
[epoch1, step307]: loss 218.268097
[epoch1, step308]: loss 130.308151
[epoch1, step309]: loss 159.298416
[epoch1, step310]: loss 289.940948
[epoch1, step311]: loss 258.183105
[epoch1, step312]: loss 201.825302
[epoch1, step313]: loss 122.296280
[epoch1, step314]: loss 311.077393
[epoch1, step315]: loss 162.623230
[epoch1, step316]: loss 235.725677
[epoch1, step317]: loss 127.860947
[epoch1, step318]: loss 222.156296
[epoch1, step319]: loss 209.354187
[epoch1, step320]: loss 284.092987
[epoch1, step321]: loss 240.234055
[epoch1, step322]: loss 284.118683
[epoch1, step323]: loss 167.287598
[epoch1, step324]: loss 238.110901
[epoch1, step325]: loss 120.382050
[epoch1, step326]: loss 149.890915
[epoch1, step327]: loss 213.321259
[epoch1, step328]: loss 210.349442
[epoch1, step329]: loss 194.606750
[epoch1, step330]: loss 69.975754
[epoch1, step331]: loss 222.980637
[epoch1, step332]: loss 171.706482
[epoch1, step333]: loss 144.889175
[epoch1, step334]: loss 156.094147
[epoch1, step335]: loss 86.194733
[epoch1, step336]: loss 119.214836
[epoch1, step337]: loss 181.740479
[epoch1, step338]: loss 123.684906
[epoch1, step339]: loss 160.121353
[epoch1, step340]: loss 205.924500
[epoch1, step341]: loss 201.906418
[epoch1, step342]: loss 186.863831
[epoch1, step343]: loss 133.056641
[epoch1, step344]: loss 190.153198
[epoch1, step345]: loss 201.440353
[epoch1, step346]: loss 168.943726
[epoch1, step347]: loss 272.469788
[epoch1, step348]: loss 44.131226
[epoch1, step349]: loss 103.913193
[epoch1, step350]: loss 165.605515
[epoch1, step351]: loss 133.558640
[epoch1, step352]: loss 149.245468
[epoch1, step353]: loss 115.622604
[epoch1, step354]: loss 194.152954
[epoch1, step355]: loss 166.713654
[epoch1, step356]: loss 209.924896
[epoch1, step357]: loss 201.867035
[epoch1, step358]: loss 86.778870
[epoch1, step359]: loss 114.258842
[epoch1, step360]: loss 251.946762
[epoch1, step361]: loss 200.429535
[epoch1, step362]: loss 78.307533
[epoch1, step363]: loss 105.512642
[epoch1, step364]: loss 87.992203
[epoch1, step365]: loss 176.880722
[epoch1, step366]: loss 129.109314
[epoch1, step367]: loss 34.475937
[epoch1, step368]: loss 147.269043
[epoch1, step369]: loss 95.138542
[epoch1, step370]: loss 95.477379
[epoch1, step371]: loss 104.350174
[epoch1, step372]: loss 116.644897
[epoch1, step373]: loss 126.576706
[epoch1, step374]: loss 109.863106
[epoch1, step375]: loss 207.105499
[epoch1, step376]: loss 74.754532
[epoch1, step377]: loss 141.237579
[epoch1, step378]: loss 64.167671
[epoch1, step379]: loss 46.783501
[epoch1, step380]: loss 100.536484
[epoch1, step381]: loss 117.577858
[epoch1, step382]: loss 118.633690
[epoch1, step383]: loss 232.841583
[epoch1, step384]: loss 145.777603
[epoch1, step385]: loss 118.385544
[epoch1, step386]: loss 174.321472
[epoch1, step387]: loss 209.403442
[epoch1, step388]: loss 69.017708
[epoch1, step389]: loss 327.279633
[epoch1, step390]: loss 206.638672
[epoch1, step391]: loss 153.973358
[epoch1, step392]: loss 128.816330
[epoch1, step393]: loss 114.553444
[epoch1, step394]: loss 194.523254
[epoch1, step395]: loss 67.582710
[epoch1, step396]: loss 81.065506
[epoch1, step397]: loss 222.150436
[epoch1, step398]: loss 133.549774
[epoch1, step399]: loss 99.335808
[epoch1, step400]: loss 205.477264
[epoch1, step401]: loss 186.882202
[epoch1, step402]: loss 59.007652
[epoch1, step403]: loss 133.840347
[epoch1, step404]: loss 190.543671
[epoch1, step405]: loss 41.950577
[epoch1, step406]: loss 124.998489
[epoch1, step407]: loss 53.813240
[epoch1, step408]: loss 54.513203
[epoch1, step409]: loss 137.498840
[epoch1, step410]: loss 97.922195
[epoch1, step411]: loss 172.145493
[epoch1, step412]: loss 176.174637
[epoch1, step413]: loss 129.407608
[epoch1, step414]: loss 70.644699
[epoch1, step415]: loss 59.837997
[epoch1, step416]: loss 67.284088
[epoch1, step417]: loss 125.192421
[epoch1, step418]: loss 174.663147
[epoch1, step419]: loss 156.592606
[epoch1, step420]: loss 204.869385
[epoch1, step421]: loss 145.227081
[epoch1, step422]: loss 98.056053
[epoch1, step423]: loss 96.080795
[epoch1, step424]: loss 156.560974
[epoch1, step425]: loss 110.558990
[epoch1, step426]: loss 129.245682
[epoch1, step427]: loss 195.899902
[epoch1, step428]: loss 76.492149
[epoch1, step429]: loss 173.480759
[epoch1, step430]: loss 149.607697
[epoch1, step431]: loss 70.265755
[epoch1, step432]: loss 153.090134
[epoch1, step433]: loss 179.653946
[epoch1, step434]: loss 198.957184
[epoch1, step435]: loss 127.922752
[epoch1, step436]: loss 106.336075
[epoch1, step437]: loss 55.557556
[epoch1, step438]: loss 103.293121
[epoch1, step439]: loss 146.005249
[epoch1, step440]: loss 172.562729
[epoch1, step441]: loss 162.232483
[epoch1, step442]: loss 152.116699
[epoch1, step443]: loss 108.076614
[epoch1, step444]: loss 72.534821
[epoch1, step445]: loss 177.169525
[epoch1, step446]: loss 51.778355
[epoch1, step447]: loss 55.201679
[epoch1, step448]: loss 129.913727
[epoch1, step449]: loss 138.375168
[epoch1, step450]: loss 122.329926
[epoch1, step451]: loss 180.078461
[epoch1, step452]: loss 127.506035
[epoch1, step453]: loss 90.608391
[epoch1, step454]: loss 240.549789
[epoch1, step455]: loss 67.978012
[epoch1, step456]: loss 144.723816
[epoch1, step457]: loss 106.367851
[epoch1, step458]: loss 122.377419
[epoch1, step459]: loss 140.503326
[epoch1, step460]: loss 121.672516
[epoch1, step461]: loss 164.518982
[epoch1, step462]: loss 270.232361
[epoch1, step463]: loss 119.937744
[epoch1, step464]: loss 59.692593
[epoch1, step465]: loss 122.037552
[epoch1, step466]: loss 123.939011
[epoch1, step467]: loss 179.996643
[epoch1, step468]: loss 131.197052
[epoch1, step469]: loss 147.937149
[epoch1, step470]: loss 82.662376
[epoch1, step471]: loss 115.322113
[epoch1, step472]: loss 101.161362
[epoch1, step473]: loss 151.162109
[epoch1, step474]: loss 68.313293
[epoch1, step475]: loss 37.060535
[epoch1, step476]: loss 147.974838
[epoch1, step477]: loss 112.503319
[epoch1, step478]: loss 42.492821
[epoch1, step479]: loss 99.886169
[epoch1, step480]: loss 180.821304
[epoch1, step481]: loss 120.575775
[epoch1, step482]: loss 191.805374
[epoch1, step483]: loss 175.095871
[epoch1, step484]: loss 115.915352
[epoch1, step485]: loss 99.501312
[epoch1, step486]: loss 86.067085
[epoch1, step487]: loss 76.078667
[epoch1, step488]: loss 156.060028
[epoch1, step489]: loss 80.626167
[epoch1, step490]: loss 147.994766
[epoch1, step491]: loss 84.849541
[epoch1, step492]: loss 124.124146
[epoch1, step493]: loss 99.841110
[epoch1, step494]: loss 120.257843
[epoch1, step495]: loss 71.719803
[epoch1, step496]: loss 85.730408
[epoch1, step497]: loss 78.105499
[epoch1, step498]: loss 157.289139
[epoch1, step499]: loss 110.086685
[epoch1, step500]: loss 147.218933
[epoch1, step501]: loss 84.037933
[epoch1, step502]: loss 202.459152
[epoch1, step503]: loss 122.986092
[epoch1, step504]: loss 161.003235
[epoch1, step505]: loss 129.822403
[epoch1, step506]: loss 74.625633
[epoch1, step507]: loss 104.681808
[epoch1, step508]: loss 57.143829
[epoch1, step509]: loss 76.760971
[epoch1, step510]: loss 66.103516
[epoch1, step511]: loss 150.064026
[epoch1, step512]: loss 114.718193
[epoch1, step513]: loss 67.750000
[epoch1, step514]: loss 95.408646
[epoch1, step515]: loss 58.032413
[epoch1, step516]: loss 39.116230
[epoch1, step517]: loss 170.868423
[epoch1, step518]: loss 101.614632
[epoch1, step519]: loss 151.894501
[epoch1, step520]: loss 68.827911
[epoch1, step521]: loss 88.004814
[epoch1, step522]: loss 134.069443
[epoch1, step523]: loss 140.602341
[epoch1, step524]: loss 123.434090
[epoch1, step525]: loss 186.370300
[epoch1, step526]: loss 138.803329
[epoch1, step527]: loss 106.199158
[epoch1, step528]: loss 169.864655
[epoch1, step529]: loss 138.880920
[epoch1, step530]: loss 122.260620
[epoch1, step531]: loss 102.710541
[epoch1, step532]: loss 134.353973
[epoch1, step533]: loss 74.686714
[epoch1, step534]: loss 98.014908
[epoch1, step535]: loss 61.368164
[epoch1, step536]: loss 165.583328
[epoch1, step537]: loss 128.152924
[epoch1, step538]: loss 53.736847
[epoch1, step539]: loss 141.843933
[epoch1, step540]: loss 92.492691
[epoch1, step541]: loss 77.321060
[epoch1, step542]: loss 61.695683
[epoch1, step543]: loss 127.459061
[epoch1, step544]: loss 209.070847
[epoch1, step545]: loss 77.034760
[epoch1, step546]: loss 85.955673
[epoch1, step547]: loss 107.717155
[epoch1, step548]: loss 160.939240
[epoch1, step549]: loss 112.696854
[epoch1, step550]: loss 129.921844
[epoch1, step551]: loss 161.168488
[epoch1, step552]: loss 87.289780
[epoch1, step553]: loss 54.687782
[epoch1, step554]: loss 88.070305
[epoch1, step555]: loss 168.986511
[epoch1, step556]: loss 158.984070
[epoch1, step557]: loss 93.064484
[epoch1, step558]: loss 94.459381
[epoch1, step559]: loss 101.806442
[epoch1, step560]: loss 107.963120
[epoch1, step561]: loss 167.517517
[epoch1, step562]: loss 88.543358
[epoch1, step563]: loss 117.466148
[epoch1, step564]: loss 41.341320
[epoch1, step565]: loss 131.322571
[epoch1, step566]: loss 96.967392
[epoch1, step567]: loss 123.117790
[epoch1, step568]: loss 120.487511
[epoch1, step569]: loss 103.058250
[epoch1, step570]: loss 102.848358
[epoch1, step571]: loss 94.698090
[epoch1, step572]: loss 74.091431
[epoch1, step573]: loss 150.932739
[epoch1, step574]: loss 45.388359
[epoch1, step575]: loss 97.630074
[epoch1, step576]: loss 125.557175
[epoch1, step577]: loss 127.044685
[epoch1, step578]: loss 97.617043
[epoch1, step579]: loss 95.621140
[epoch1, step580]: loss 113.723083
[epoch1, step581]: loss 102.741478
[epoch1, step582]: loss 105.161247
[epoch1, step583]: loss 86.336365
[epoch1, step584]: loss 106.608490
[epoch1, step585]: loss 118.065849
[epoch1, step586]: loss 163.389694
[epoch1, step587]: loss 75.809669
[epoch1, step588]: loss 69.945686
[epoch1, step589]: loss 79.363831
[epoch1, step590]: loss 130.372253
[epoch1, step591]: loss 227.329163
[epoch1, step592]: loss 45.026627
[epoch1, step593]: loss 54.633896
[epoch1, step594]: loss 198.315094
[epoch1, step595]: loss 112.465561
[epoch1, step596]: loss 58.953053
[epoch1, step597]: loss 81.400803
[epoch1, step598]: loss 72.953690
[epoch1, step599]: loss 173.986252
[epoch1, step600]: loss 116.482018
[epoch1, step601]: loss 119.285065
[epoch1, step602]: loss 57.244453
[epoch1, step603]: loss 194.085678
[epoch1, step604]: loss 97.922874
[epoch1, step605]: loss 144.099960
[epoch1, step606]: loss 86.642365
[epoch1, step607]: loss 93.142265
[epoch1, step608]: loss 165.882416
[epoch1, step609]: loss 195.553040
[epoch1, step610]: loss 106.777100
[epoch1, step611]: loss 86.815765
[epoch1, step612]: loss 163.629517
[epoch1, step613]: loss 147.082443
[epoch1, step614]: loss 94.255722
[epoch1, step615]: loss 178.878357
[epoch1, step616]: loss 98.319412
[epoch1, step617]: loss 98.222397
[epoch1, step618]: loss 75.389610
[epoch1, step619]: loss 125.813667
[epoch1, step620]: loss 86.364883
[epoch1, step621]: loss 115.388771
[epoch1, step622]: loss 145.085007
[epoch1, step623]: loss 62.502743
[epoch1, step624]: loss 84.426636
[epoch1, step625]: loss 235.351028
[epoch1, step626]: loss 100.631393
[epoch1, step627]: loss 127.896774
[epoch1, step628]: loss 140.639267
[epoch1, step629]: loss 66.324051
[epoch1, step630]: loss 58.972603
[epoch1, step631]: loss 169.633133
[epoch1, step632]: loss 118.138931
[epoch1, step633]: loss 79.986115
[epoch1, step634]: loss 86.119301
[epoch1, step635]: loss 70.988831
[epoch1, step636]: loss 250.884537
[epoch1, step637]: loss 143.472107
[epoch1, step638]: loss 185.757919
[epoch1, step639]: loss 101.005997
[epoch1, step640]: loss 155.467422
[epoch1, step641]: loss 112.480972
[epoch1, step642]: loss 13.589676
[epoch1, step643]: loss 70.601715
[epoch1, step644]: loss 139.266022
[epoch1, step645]: loss 86.550949
[epoch1, step646]: loss 142.413712
[epoch1, step647]: loss 60.267040
[epoch1, step648]: loss 79.269135
[epoch1, step649]: loss 115.334518
[epoch1, step650]: loss 170.416016
[epoch1, step651]: loss 109.500381
[epoch1, step652]: loss 83.771187
[epoch1, step653]: loss 166.784943
[epoch1, step654]: loss 55.900307
[epoch1, step655]: loss 90.828033
[epoch1, step656]: loss 158.180222
[epoch1, step657]: loss 138.459106
[epoch1, step658]: loss 145.936859
[epoch1, step659]: loss 108.494690
[epoch1, step660]: loss 70.298813
[epoch1, step661]: loss 112.519882
[epoch1, step662]: loss 160.590851
[epoch1, step663]: loss 133.546555
[epoch1, step664]: loss 69.691940
[epoch1, step665]: loss 111.023590
[epoch1, step666]: loss 206.848267
[epoch1, step667]: loss 137.319733
[epoch1, step668]: loss 39.791267
[epoch1, step669]: loss 62.122707
[epoch1, step670]: loss 83.485840
[epoch1, step671]: loss 135.427460
[epoch1, step672]: loss 41.009533
[epoch1, step673]: loss 68.116493
[epoch1, step674]: loss 139.520889
[epoch1, step675]: loss 149.060608
[epoch1, step676]: loss 170.501007
[epoch1, step677]: loss 135.290619
[epoch1, step678]: loss 102.062752
[epoch1, step679]: loss 74.259506
[epoch1, step680]: loss 200.729065
[epoch1, step681]: loss 220.142136
[epoch1, step682]: loss 157.353271
[epoch1, step683]: loss 172.113831
[epoch1, step684]: loss 200.479126
[epoch1, step685]: loss 65.230942
[epoch1, step686]: loss 125.351646
[epoch1, step687]: loss 136.698669
[epoch1, step688]: loss 126.441521
[epoch1, step689]: loss 74.279190
[epoch1, step690]: loss 73.463821
[epoch1, step691]: loss 70.515594
[epoch1, step692]: loss 88.318901
[epoch1, step693]: loss 115.332703
[epoch1, step694]: loss 86.367203
[epoch1, step695]: loss 31.461639
[epoch1, step696]: loss 185.173523
[epoch1, step697]: loss 53.742119
[epoch1, step698]: loss 81.848267
[epoch1, step699]: loss 144.395752
[epoch1, step700]: loss 94.480896
[epoch1, step701]: loss 189.139908
[epoch1, step702]: loss 111.906387
[epoch1, step703]: loss 76.212074
[epoch1, step704]: loss 118.027451
[epoch1, step705]: loss 104.329971
[epoch1, step706]: loss 54.222065
[epoch1, step707]: loss 117.569397
[epoch1, step708]: loss 91.115738
[epoch1, step709]: loss 43.717979
[epoch1, step710]: loss 171.398773
[epoch1, step711]: loss 139.459900
[epoch1, step712]: loss 98.829216
[epoch1, step713]: loss 68.201698
[epoch1, step714]: loss 80.914673
[epoch1, step715]: loss 66.308281
[epoch1, step716]: loss 89.072807
[epoch1, step717]: loss 168.435944
[epoch1, step718]: loss 96.362541
[epoch1, step719]: loss 139.464584
[epoch1, step720]: loss 135.537964
[epoch1, step721]: loss 28.461403
[epoch1, step722]: loss 80.476898
[epoch1, step723]: loss 92.133171
[epoch1, step724]: loss 63.275391
[epoch1, step725]: loss 167.658325
[epoch1, step726]: loss 86.169205
[epoch1, step727]: loss 130.138123
[epoch1, step728]: loss 121.392105
[epoch1, step729]: loss 104.228935
[epoch1, step730]: loss 118.693123
[epoch1, step731]: loss 74.499031
[epoch1, step732]: loss 103.315292
[epoch1, step733]: loss 30.831617
[epoch1, step734]: loss 135.739624
[epoch1, step735]: loss 195.247162
[epoch1, step736]: loss 127.007431
[epoch1, step737]: loss 145.737808
[epoch1, step738]: loss 99.414406
[epoch1, step739]: loss 94.244423
[epoch1, step740]: loss 113.201012
[epoch1, step741]: loss 71.557770
[epoch1, step742]: loss 99.337013
[epoch1, step743]: loss 183.682068
[epoch1, step744]: loss 67.684525
[epoch1, step745]: loss 89.943871
[epoch1, step746]: loss 50.284447
[epoch1, step747]: loss 114.231293
[epoch1, step748]: loss 68.650589
[epoch1, step749]: loss 114.151016
[epoch1, step750]: loss 92.496727
[epoch1, step751]: loss 134.325500
[epoch1, step752]: loss 186.530792
[epoch1, step753]: loss 127.907684
[epoch1, step754]: loss 149.496826
[epoch1, step755]: loss 132.084686
[epoch1, step756]: loss 80.313248
[epoch1, step757]: loss 199.990204
[epoch1, step758]: loss 82.356750
[epoch1, step759]: loss 149.887650
[epoch1, step760]: loss 54.577644
[epoch1, step761]: loss 59.617432
[epoch1, step762]: loss 96.077332
[epoch1, step763]: loss 49.434029
[epoch1, step764]: loss 133.709244
[epoch1, step765]: loss 103.713608
[epoch1, step766]: loss 149.863663
[epoch1, step767]: loss 90.279823
[epoch1, step768]: loss 85.593399
[epoch1, step769]: loss 152.394623
[epoch1, step770]: loss 75.355347
[epoch1, step771]: loss 117.899536
[epoch1, step772]: loss 57.667553
[epoch1, step773]: loss 97.645485
[epoch1, step774]: loss 46.675690
[epoch1, step775]: loss 103.510780
[epoch1, step776]: loss 114.007195
[epoch1, step777]: loss 87.672966
[epoch1, step778]: loss 159.722137
[epoch1, step779]: loss 72.237869
[epoch1, step780]: loss 229.376053
[epoch1, step781]: loss 52.306969
[epoch1, step782]: loss 33.550480
[epoch1, step783]: loss 88.395691
[epoch1, step784]: loss 125.980980
[epoch1, step785]: loss 94.363373
[epoch1, step786]: loss 184.198792
[epoch1, step787]: loss 56.923489
[epoch1, step788]: loss 146.726959
[epoch1, step789]: loss 42.537853
[epoch1, step790]: loss 89.092743
[epoch1, step791]: loss 170.981964
[epoch1, step792]: loss 78.223869
[epoch1, step793]: loss 119.520752
[epoch1, step794]: loss 87.389946
[epoch1, step795]: loss 105.947617
[epoch1, step796]: loss 52.882309
[epoch1, step797]: loss 120.726875
[epoch1, step798]: loss 159.453339
[epoch1, step799]: loss 74.543396
[epoch1, step800]: loss 119.934799
[epoch1, step801]: loss 136.296844
[epoch1, step802]: loss 195.481873
[epoch1, step803]: loss 165.438354
[epoch1, step804]: loss 207.235779
[epoch1, step805]: loss 104.372032
[epoch1, step806]: loss 86.372345
[epoch1, step807]: loss 45.496395
[epoch1, step808]: loss 133.841492
[epoch1, step809]: loss 53.410744
[epoch1, step810]: loss 81.069420
[epoch1, step811]: loss 101.805016
[epoch1, step812]: loss 35.299374
[epoch1, step813]: loss 69.729294
[epoch1, step814]: loss 62.237999
[epoch1, step815]: loss 125.877693
[epoch1, step816]: loss 194.952240
[epoch1, step817]: loss 124.985634
[epoch1, step818]: loss 88.278969
[epoch1, step819]: loss 124.956787
[epoch1, step820]: loss 90.080353
[epoch1, step821]: loss 98.544266
[epoch1, step822]: loss 77.634399
[epoch1, step823]: loss 143.824142
[epoch1, step824]: loss 105.020851
[epoch1, step825]: loss 78.439491
[epoch1, step826]: loss 82.912949
[epoch1, step827]: loss 78.473137
[epoch1, step828]: loss 103.534073
[epoch1, step829]: loss 61.966026
[epoch1, step830]: loss 151.221100
[epoch1, step831]: loss 95.340866
[epoch1, step832]: loss 98.413315
[epoch1, step833]: loss 117.809502
[epoch1, step834]: loss 160.932602
[epoch1, step835]: loss 67.389175
[epoch1, step836]: loss 38.562275
[epoch1, step837]: loss 57.053078
[epoch1, step838]: loss 86.397552
[epoch1, step839]: loss 126.819168
[epoch1, step840]: loss 103.151703
[epoch1, step841]: loss 104.482620
[epoch1, step842]: loss 61.757004
[epoch1, step843]: loss 81.604370
[epoch1, step844]: loss 59.146236
[epoch1, step845]: loss 92.274933
[epoch1, step846]: loss 149.330551
[epoch1, step847]: loss 121.054688
[epoch1, step848]: loss 50.055534
[epoch1, step849]: loss 78.249168
[epoch1, step850]: loss 96.322533
[epoch1, step851]: loss 164.699066
[epoch1, step852]: loss 49.953217
[epoch1, step853]: loss 68.195709
[epoch1, step854]: loss 95.963547
[epoch1, step855]: loss 86.838829
[epoch1, step856]: loss 127.999985
[epoch1, step857]: loss 157.897522
[epoch1, step858]: loss 51.181538
[epoch1, step859]: loss 156.243683
[epoch1, step860]: loss 54.094063
[epoch1, step861]: loss 49.239143
[epoch1, step862]: loss 51.595795
[epoch1, step863]: loss 105.310387
[epoch1, step864]: loss 142.044769
[epoch1, step865]: loss 71.277840
[epoch1, step866]: loss 165.472565
[epoch1, step867]: loss 140.645798
[epoch1, step868]: loss 58.008083
[epoch1, step869]: loss 141.612793
[epoch1, step870]: loss 174.203278
[epoch1, step871]: loss 106.833229
[epoch1, step872]: loss 19.648945
[epoch1, step873]: loss 77.889038
[epoch1, step874]: loss 69.060966
[epoch1, step875]: loss 65.087219
[epoch1, step876]: loss 108.259338
[epoch1, step877]: loss 41.905552
[epoch1, step878]: loss 98.903915
[epoch1, step879]: loss 61.482895
[epoch1, step880]: loss 131.558197
[epoch1, step881]: loss 171.067963
[epoch1, step882]: loss 65.249786
[epoch1, step883]: loss 60.376537
[epoch1, step884]: loss 32.608669
[epoch1, step885]: loss 42.982887
[epoch1, step886]: loss 149.196198
[epoch1, step887]: loss 120.633965
[epoch1, step888]: loss 54.131691
[epoch1, step889]: loss 110.571136
[epoch1, step890]: loss 139.818542
[epoch1, step891]: loss 74.184547
[epoch1, step892]: loss 89.470619
[epoch1, step893]: loss 161.524155
[epoch1, step894]: loss 65.347496
[epoch1, step895]: loss 133.968048
[epoch1, step896]: loss 101.946259
[epoch1, step897]: loss 94.178749
[epoch1, step898]: loss 54.970772
[epoch1, step899]: loss 106.666779
[epoch1, step900]: loss 93.225395
[epoch1, step901]: loss 60.657028
[epoch1, step902]: loss 83.049644
[epoch1, step903]: loss 127.520432
[epoch1, step904]: loss 46.072525
[epoch1, step905]: loss 102.026886
[epoch1, step906]: loss 80.532028
[epoch1, step907]: loss 114.533936
[epoch1, step908]: loss 48.521313
[epoch1, step909]: loss 100.482948
[epoch1, step910]: loss 127.213181
[epoch1, step911]: loss 101.762115
[epoch1, step912]: loss 71.781303
[epoch1, step913]: loss 104.185471
[epoch1, step914]: loss 81.750786
[epoch1, step915]: loss 61.902016
[epoch1, step916]: loss 104.689178
[epoch1, step917]: loss 95.330925
[epoch1, step918]: loss 113.531136
[epoch1, step919]: loss 63.228119
[epoch1, step920]: loss 175.040802
[epoch1, step921]: loss 97.347176
[epoch1, step922]: loss 110.034676
[epoch1, step923]: loss 74.394226
[epoch1, step924]: loss 7.608725
[epoch1, step925]: loss 105.701576
[epoch1, step926]: loss 54.652164
[epoch1, step927]: loss 149.400345
[epoch1, step928]: loss 125.857056
[epoch1, step929]: loss 61.640022
[epoch1, step930]: loss 103.177597
[epoch1, step931]: loss 171.359589
[epoch1, step932]: loss 84.688309
[epoch1, step933]: loss 78.302368
[epoch1, step934]: loss 138.422623
[epoch1, step935]: loss 89.457359
[epoch1, step936]: loss 86.338730
[epoch1, step937]: loss 93.411758
[epoch1, step938]: loss 44.628494
[epoch1, step939]: loss 22.467817
[epoch1, step940]: loss 61.636761
[epoch1, step941]: loss 130.068130
[epoch1, step942]: loss 157.722122
[epoch1, step943]: loss 124.323532
[epoch1, step944]: loss 110.203094
[epoch1, step945]: loss 47.464558
[epoch1, step946]: loss 54.784679
[epoch1, step947]: loss 96.483498
[epoch1, step948]: loss 186.357498
[epoch1, step949]: loss 75.851913
[epoch1, step950]: loss 67.883705
[epoch1, step951]: loss 162.177399
[epoch1, step952]: loss 141.641724
[epoch1, step953]: loss 24.454453
[epoch1, step954]: loss 111.523987
[epoch1, step955]: loss 69.454720
[epoch1, step956]: loss 115.585312
[epoch1, step957]: loss 194.966614
[epoch1, step958]: loss 73.772217
[epoch1, step959]: loss 93.201698
[epoch1, step960]: loss 58.074245
[epoch1, step961]: loss 30.814823
[epoch1, step962]: loss 121.099342
[epoch1, step963]: loss 58.973709
[epoch1, step964]: loss 59.069733
[epoch1, step965]: loss 87.237190
[epoch1, step966]: loss 117.591141
[epoch1, step967]: loss 106.895836
[epoch1, step968]: loss 58.687557
[epoch1, step969]: loss 31.698214
[epoch1, step970]: loss 67.637688
[epoch1, step971]: loss 167.451385
[epoch1, step972]: loss 41.815002
[epoch1, step973]: loss 68.388451
[epoch1, step974]: loss 80.693680
[epoch1, step975]: loss 74.729523
[epoch1, step976]: loss 68.741463
[epoch1, step977]: loss 166.419617
[epoch1, step978]: loss 140.435852
[epoch1, step979]: loss 93.517708
[epoch1, step980]: loss 89.099731
[epoch1, step981]: loss 78.367775
[epoch1, step982]: loss 88.096947
[epoch1, step983]: loss 61.290291
[epoch1, step984]: loss 74.913635
[epoch1, step985]: loss 83.185463
[epoch1, step986]: loss 88.457077
[epoch1, step987]: loss 179.295929
[epoch1, step988]: loss 100.330521
[epoch1, step989]: loss 189.927963
[epoch1, step990]: loss 101.662331
[epoch1, step991]: loss 94.081551
[epoch1, step992]: loss 80.979073
[epoch1, step993]: loss 64.708664
[epoch1, step994]: loss 89.039757
[epoch1, step995]: loss 134.888367
[epoch1, step996]: loss 130.463654
[epoch1, step997]: loss 65.826782
[epoch1, step998]: loss 37.373650
[epoch1, step999]: loss 118.255936
[epoch1, step1000]: loss 79.361328
[epoch1, step1001]: loss 52.934990
[epoch1, step1002]: loss 47.081581
[epoch1, step1003]: loss 108.608398
[epoch1, step1004]: loss 118.767593
[epoch1, step1005]: loss 121.248024
[epoch1, step1006]: loss 125.396255
[epoch1, step1007]: loss 50.783966
[epoch1, step1008]: loss 97.554794
[epoch1, step1009]: loss 82.713432
[epoch1, step1010]: loss 143.954376
[epoch1, step1011]: loss 28.073364
[epoch1, step1012]: loss 51.983829
[epoch1, step1013]: loss 97.900711
[epoch1, step1014]: loss 80.424706
[epoch1, step1015]: loss 71.865196
[epoch1, step1016]: loss 60.638260
[epoch1, step1017]: loss 176.340302
[epoch1, step1018]: loss 72.670708
[epoch1, step1019]: loss 56.970757
[epoch1, step1020]: loss 46.417133
[epoch1, step1021]: loss 77.741966
[epoch1, step1022]: loss 134.484314
[epoch1, step1023]: loss 92.077896
[epoch1, step1024]: loss 122.853561
[epoch1, step1025]: loss 108.685959
[epoch1, step1026]: loss 81.521194
[epoch1, step1027]: loss 60.386784
[epoch1, step1028]: loss 151.021515
[epoch1, step1029]: loss 13.631465
[epoch1, step1030]: loss 127.222649
[epoch1, step1031]: loss 140.058701
[epoch1, step1032]: loss 139.310638
[epoch1, step1033]: loss 76.734085
[epoch1, step1034]: loss 134.905365
[epoch1, step1035]: loss 71.867004
[epoch1, step1036]: loss 110.843903
[epoch1, step1037]: loss 130.642227
[epoch1, step1038]: loss 79.848938
[epoch1, step1039]: loss 49.529800
[epoch1, step1040]: loss 99.417343
[epoch1, step1041]: loss 38.941254
[epoch1, step1042]: loss 78.615356
[epoch1, step1043]: loss 170.615036
[epoch1, step1044]: loss 127.132477
[epoch1, step1045]: loss 143.254486
[epoch1, step1046]: loss 85.662743
[epoch1, step1047]: loss 99.566269
[epoch1, step1048]: loss 71.217773
[epoch1, step1049]: loss 124.257950
[epoch1, step1050]: loss 134.758270
[epoch1, step1051]: loss 78.911453
[epoch1, step1052]: loss 32.194595
[epoch1, step1053]: loss 49.874054
[epoch1, step1054]: loss 90.222649
[epoch1, step1055]: loss 89.237465
[epoch1, step1056]: loss 60.688755
[epoch1, step1057]: loss 28.572678
[epoch1, step1058]: loss 44.955128
[epoch1, step1059]: loss 159.020859
[epoch1, step1060]: loss 45.107937
[epoch1, step1061]: loss 101.574158
[epoch1, step1062]: loss 55.856232
[epoch1, step1063]: loss 87.686401
[epoch1, step1064]: loss 89.896271
[epoch1, step1065]: loss 190.565277
[epoch1, step1066]: loss 128.863205
[epoch1, step1067]: loss 131.105484
[epoch1, step1068]: loss 94.509621
[epoch1, step1069]: loss 123.151215
[epoch1, step1070]: loss 70.233131
[epoch1, step1071]: loss 92.962662
[epoch1, step1072]: loss 44.957111
[epoch1, step1073]: loss 85.356499
[epoch1, step1074]: loss 87.574638
[epoch1, step1075]: loss 44.868755
[epoch1, step1076]: loss 79.639328
[epoch1, step1077]: loss 47.383453
[epoch1, step1078]: loss 153.612320
[epoch1, step1079]: loss 38.973648
[epoch1, step1080]: loss 60.784874
[epoch1, step1081]: loss 143.794754
[epoch1, step1082]: loss 57.200333
[epoch1, step1083]: loss 88.956947
[epoch1, step1084]: loss 110.381142
[epoch1, step1085]: loss 107.034180
[epoch1, step1086]: loss 64.667023
[epoch1, step1087]: loss 73.321457
[epoch1, step1088]: loss 79.687943
[epoch1, step1089]: loss 140.616470
[epoch1, step1090]: loss 110.110062
[epoch1, step1091]: loss 59.811516
[epoch1, step1092]: loss 36.264446
[epoch1, step1093]: loss 99.706558
[epoch1, step1094]: loss 107.763702
[epoch1, step1095]: loss 109.397911
[epoch1, step1096]: loss 95.238174
[epoch1, step1097]: loss 134.400970
[epoch1, step1098]: loss 35.478531
[epoch1, step1099]: loss 38.891850
[epoch1, step1100]: loss 68.131302
[epoch1, step1101]: loss 71.470222
[epoch1, step1102]: loss 73.341522
[epoch1, step1103]: loss 101.712181
[epoch1, step1104]: loss 175.576218
[epoch1, step1105]: loss 118.697891
[epoch1, step1106]: loss 64.481766
[epoch1, step1107]: loss 82.902298
[epoch1, step1108]: loss 84.024078
[epoch1, step1109]: loss 93.049103
[epoch1, step1110]: loss 103.136551
[epoch1, step1111]: loss 18.993950
[epoch1, step1112]: loss 58.628876
[epoch1, step1113]: loss 97.355995
[epoch1, step1114]: loss 63.246620
[epoch1, step1115]: loss 38.383327
[epoch1, step1116]: loss 55.014992
[epoch1, step1117]: loss 79.059975
[epoch1, step1118]: loss 31.222898
[epoch1, step1119]: loss 85.266449
[epoch1, step1120]: loss 134.272034
[epoch1, step1121]: loss 64.446121
[epoch1, step1122]: loss 115.537964
[epoch1, step1123]: loss 14.286478
[epoch1, step1124]: loss 47.705158
[epoch1, step1125]: loss 65.600578
[epoch1, step1126]: loss 82.690521
[epoch1, step1127]: loss 84.617821
[epoch1, step1128]: loss 25.769047
[epoch1, step1129]: loss 139.434906
[epoch1, step1130]: loss 128.136963
[epoch1, step1131]: loss 53.504982
[epoch1, step1132]: loss 42.864487
[epoch1, step1133]: loss 94.645691
[epoch1, step1134]: loss 100.144623
[epoch1, step1135]: loss 29.755663
[epoch1, step1136]: loss 45.607185
[epoch1, step1137]: loss 133.873840
[epoch1, step1138]: loss 48.077843
[epoch1, step1139]: loss 185.496246
[epoch1, step1140]: loss 81.049492
[epoch1, step1141]: loss 32.464039
[epoch1, step1142]: loss 77.640358
[epoch1, step1143]: loss 52.436218
[epoch1, step1144]: loss 61.347378
[epoch1, step1145]: loss 104.348366
[epoch1, step1146]: loss 67.472122
[epoch1, step1147]: loss 73.545082
[epoch1, step1148]: loss 87.202179
[epoch1, step1149]: loss 101.846252
[epoch1, step1150]: loss 93.491173
[epoch1, step1151]: loss 63.620914
[epoch1, step1152]: loss 82.252335
[epoch1, step1153]: loss 120.534233
[epoch1, step1154]: loss 18.022999
[epoch1, step1155]: loss 55.053566
[epoch1, step1156]: loss 109.116486
[epoch1, step1157]: loss 118.359901
[epoch1, step1158]: loss 146.904755
[epoch1, step1159]: loss 11.140493
[epoch1, step1160]: loss 68.274666
[epoch1, step1161]: loss 63.122520
[epoch1, step1162]: loss 97.361526
[epoch1, step1163]: loss 92.286133
[epoch1, step1164]: loss 77.387512
[epoch1, step1165]: loss 25.595201
[epoch1, step1166]: loss 193.950165
[epoch1, step1167]: loss 50.172619
[epoch1, step1168]: loss 86.184349
[epoch1, step1169]: loss 103.621231
[epoch1, step1170]: loss 37.753632
[epoch1, step1171]: loss 41.762836
[epoch1, step1172]: loss 49.055302
[epoch1, step1173]: loss 104.489594
[epoch1, step1174]: loss 83.713516
[epoch1, step1175]: loss 59.639305
[epoch1, step1176]: loss 77.818222
[epoch1, step1177]: loss 111.597870
[epoch1, step1178]: loss 146.881805
[epoch1, step1179]: loss 19.560526
[epoch1, step1180]: loss 25.527399
[epoch1, step1181]: loss 26.668194
[epoch1, step1182]: loss 44.288544
[epoch1, step1183]: loss 73.536797
[epoch1, step1184]: loss 143.188522
[epoch1, step1185]: loss 65.885506
[epoch1, step1186]: loss 75.219833
[epoch1, step1187]: loss 142.770477
[epoch1, step1188]: loss 63.682785
[epoch1, step1189]: loss 72.758888
[epoch1, step1190]: loss 122.090263
[epoch1, step1191]: loss 107.290390
[epoch1, step1192]: loss 62.930954
[epoch1, step1193]: loss 142.547394
[epoch1, step1194]: loss 120.656364
[epoch1, step1195]: loss 138.924332
[epoch1, step1196]: loss 64.946899
[epoch1, step1197]: loss 98.263229
[epoch1, step1198]: loss 133.061798
[epoch1, step1199]: loss 43.212967
[epoch1, step1200]: loss 88.822227
[epoch1, step1201]: loss 123.002762
[epoch1, step1202]: loss 95.975143
[epoch1, step1203]: loss 44.313015
[epoch1, step1204]: loss 70.901009
[epoch1, step1205]: loss 75.985764
[epoch1, step1206]: loss 43.964222
[epoch1, step1207]: loss 192.701675
[epoch1, step1208]: loss 96.667717
[epoch1, step1209]: loss 111.404572
[epoch1, step1210]: loss 86.577393
[epoch1, step1211]: loss 68.121765
[epoch1, step1212]: loss 74.560089
[epoch1, step1213]: loss 122.078522
[epoch1, step1214]: loss 123.821655
[epoch1, step1215]: loss 71.356827
[epoch1, step1216]: loss 85.424469
[epoch1, step1217]: loss 126.607178
[epoch1, step1218]: loss 171.138763
[epoch1, step1219]: loss 84.068718
[epoch1, step1220]: loss 76.495804
[epoch1, step1221]: loss 87.571953
[epoch1, step1222]: loss 82.384384
[epoch1, step1223]: loss 53.422905
[epoch1, step1224]: loss 74.774750
[epoch1, step1225]: loss 61.663326
[epoch1, step1226]: loss 113.376579
[epoch1, step1227]: loss 113.628387
[epoch1, step1228]: loss 58.335003
[epoch1, step1229]: loss 33.830940
[epoch1, step1230]: loss 76.038803
[epoch1, step1231]: loss 110.469116
[epoch1, step1232]: loss 109.603432
[epoch1, step1233]: loss 135.585632
[epoch1, step1234]: loss 95.070602
[epoch1, step1235]: loss 64.332405
[epoch1, step1236]: loss 85.914680
[epoch1, step1237]: loss 54.573372
[epoch1, step1238]: loss 61.516914
[epoch1, step1239]: loss 74.636597
[epoch1, step1240]: loss 14.384861
[epoch1, step1241]: loss 71.208839
[epoch1, step1242]: loss 61.386429
[epoch1, step1243]: loss 27.442604
[epoch1, step1244]: loss 74.578400
[epoch1, step1245]: loss 78.314522
[epoch1, step1246]: loss 94.878365
[epoch1, step1247]: loss 64.122810
[epoch1, step1248]: loss 45.707100
[epoch1, step1249]: loss 63.187714
[epoch1, step1250]: loss 65.988358
[epoch1, step1251]: loss 120.858810
[epoch1, step1252]: loss 100.307388
[epoch1, step1253]: loss 102.973793
[epoch1, step1254]: loss 78.480118
[epoch1, step1255]: loss 74.685135
[epoch1, step1256]: loss 72.748520
[epoch1, step1257]: loss 78.746948
[epoch1, step1258]: loss 91.600883
[epoch1, step1259]: loss 77.994980
[epoch1, step1260]: loss 65.768791
[epoch1, step1261]: loss 107.721741
[epoch1, step1262]: loss 69.945229
[epoch1, step1263]: loss 82.135452
[epoch1, step1264]: loss 51.591328
[epoch1, step1265]: loss 88.575989
[epoch1, step1266]: loss 79.590607
[epoch1, step1267]: loss 77.079712
[epoch1, step1268]: loss 78.504707
[epoch1, step1269]: loss 95.931488
[epoch1, step1270]: loss 30.849342
[epoch1, step1271]: loss 53.611069
[epoch1, step1272]: loss 40.344273
[epoch1, step1273]: loss 60.674351
[epoch1, step1274]: loss 116.190666
[epoch1, step1275]: loss 28.434713
[epoch1, step1276]: loss 101.328697
[epoch1, step1277]: loss 88.384575
[epoch1, step1278]: loss 113.891853
[epoch1, step1279]: loss 102.761658
[epoch1, step1280]: loss 67.431992
[epoch1, step1281]: loss 58.783913
[epoch1, step1282]: loss 66.795319
[epoch1, step1283]: loss 89.543686
[epoch1, step1284]: loss 55.692394
[epoch1, step1285]: loss 39.154133
[epoch1, step1286]: loss 175.325272
[epoch1, step1287]: loss 189.147720
[epoch1, step1288]: loss 64.232513
[epoch1, step1289]: loss 52.831253
[epoch1, step1290]: loss 24.664871
[epoch1, step1291]: loss 23.838562
[epoch1, step1292]: loss 57.951450
[epoch1, step1293]: loss 81.843666
[epoch1, step1294]: loss 79.305717
[epoch1, step1295]: loss 85.582916
[epoch1, step1296]: loss 92.084793
[epoch1, step1297]: loss 42.847977
[epoch1, step1298]: loss 68.942322
[epoch1, step1299]: loss 48.499035
[epoch1, step1300]: loss 59.608707
[epoch1, step1301]: loss 49.953682
[epoch1, step1302]: loss 36.257004
[epoch1, step1303]: loss 31.043663
[epoch1, step1304]: loss 60.931335
[epoch1, step1305]: loss 58.025860
[epoch1, step1306]: loss 53.452934
[epoch1, step1307]: loss 65.031921
[epoch1, step1308]: loss 59.556461
[epoch1, step1309]: loss 83.014671
[epoch1, step1310]: loss 51.854881
[epoch1, step1311]: loss 34.415535
[epoch1, step1312]: loss 44.807777
[epoch1, step1313]: loss 48.395653
[epoch1, step1314]: loss 36.970249
[epoch1, step1315]: loss 150.516174
[epoch1, step1316]: loss 93.057297
[epoch1, step1317]: loss 70.533707
[epoch1, step1318]: loss 42.160721
[epoch1, step1319]: loss 45.215603
[epoch1, step1320]: loss 143.082550
[epoch1, step1321]: loss 79.109528
[epoch1, step1322]: loss 33.294067
[epoch1, step1323]: loss 142.585266
[epoch1, step1324]: loss 177.814529
[epoch1, step1325]: loss 123.624260
[epoch1, step1326]: loss 69.264740
[epoch1, step1327]: loss 77.461205
[epoch1, step1328]: loss 51.202095
[epoch1, step1329]: loss 52.883953
[epoch1, step1330]: loss 67.941017
[epoch1, step1331]: loss 54.374161
[epoch1, step1332]: loss 100.658661
[epoch1, step1333]: loss 100.242157
[epoch1, step1334]: loss 54.535568
[epoch1, step1335]: loss 57.964470
[epoch1, step1336]: loss 61.966564
[epoch1, step1337]: loss 51.320724
[epoch1, step1338]: loss 102.121849
[epoch1, step1339]: loss 72.435463
[epoch1, step1340]: loss 75.960045
[epoch1, step1341]: loss 136.256424
[epoch1, step1342]: loss 132.211075
[epoch1, step1343]: loss 57.462227
[epoch1, step1344]: loss 79.492554
[epoch1, step1345]: loss 119.528358
[epoch1, step1346]: loss 61.640503
[epoch1, step1347]: loss 61.083706
[epoch1, step1348]: loss 16.813576
[epoch1, step1349]: loss 87.871948
[epoch1, step1350]: loss 87.470810
[epoch1, step1351]: loss 48.153248
[epoch1, step1352]: loss 52.694485
[epoch1, step1353]: loss 87.664551
[epoch1, step1354]: loss 52.818344
[epoch1, step1355]: loss 37.455635
[epoch1, step1356]: loss 38.282845
[epoch1, step1357]: loss 37.088863
[epoch1, step1358]: loss 81.796570
[epoch1, step1359]: loss 143.770538
[epoch1, step1360]: loss 25.427279
[epoch1, step1361]: loss 71.593399
[epoch1, step1362]: loss 66.358513
[epoch1, step1363]: loss 39.006550
[epoch1, step1364]: loss 148.009705
[epoch1, step1365]: loss 87.440521
[epoch1, step1366]: loss 60.524559
[epoch1, step1367]: loss 99.611511
[epoch1, step1368]: loss 144.115295
[epoch1, step1369]: loss 79.362541
[epoch1, step1370]: loss 102.946663
[epoch1, step1371]: loss 36.645691
[epoch1, step1372]: loss 94.412216
[epoch1, step1373]: loss 98.702301
[epoch1, step1374]: loss 52.749805
[epoch1, step1375]: loss 83.595535
[epoch1, step1376]: loss 50.119339
[epoch1, step1377]: loss 79.710915
[epoch1, step1378]: loss 13.776225
[epoch1, step1379]: loss 70.212502
[epoch1, step1380]: loss 67.638016
[epoch1, step1381]: loss 127.825531
[epoch1, step1382]: loss 75.586716
[epoch1, step1383]: loss 82.389153
[epoch1, step1384]: loss 102.509720
[epoch1, step1385]: loss 57.079754
[epoch1, step1386]: loss 26.304844
[epoch1, step1387]: loss 30.886782
[epoch1, step1388]: loss 93.266434
[epoch1, step1389]: loss 109.650734
[epoch1, step1390]: loss 66.488167
[epoch1, step1391]: loss 34.796803
[epoch1, step1392]: loss 93.415062
[epoch1, step1393]: loss 28.951689
[epoch1, step1394]: loss 63.643208
[epoch1, step1395]: loss 23.547817
[epoch1, step1396]: loss 105.398361
[epoch1, step1397]: loss 76.541489
[epoch1, step1398]: loss 42.763908
[epoch1, step1399]: loss 31.045763
[epoch1, step1400]: loss 15.000847
[epoch1, step1401]: loss 27.056931
[epoch1, step1402]: loss 64.597855
[epoch1, step1403]: loss 98.355995
[epoch1, step1404]: loss 62.873768
[epoch1, step1405]: loss 95.509651
[epoch1, step1406]: loss 28.107031
[epoch1, step1407]: loss 101.573471
[epoch1, step1408]: loss 104.472076
[epoch1, step1409]: loss 8.627702
[epoch1, step1410]: loss 31.245565
[epoch1, step1411]: loss 77.563622
[epoch1, step1412]: loss 101.841537
[epoch1, step1413]: loss 41.827652
[epoch1, step1414]: loss 58.784309
[epoch1, step1415]: loss 69.186073
[epoch1, step1416]: loss 63.775818
[epoch1, step1417]: loss 100.249794
[epoch1, step1418]: loss 76.540863
[epoch1, step1419]: loss 33.863262
[epoch1, step1420]: loss 45.027016
[epoch1, step1421]: loss 17.015133
[epoch1, step1422]: loss 71.514282
[epoch1, step1423]: loss 12.506652
[epoch1, step1424]: loss 29.626560
[epoch1, step1425]: loss 145.622025
[epoch1, step1426]: loss 66.193642
[epoch1, step1427]: loss 39.786785
[epoch1, step1428]: loss 61.548553
[epoch1, step1429]: loss 44.687786
[epoch1, step1430]: loss 11.174141
[epoch1, step1431]: loss 79.361542
[epoch1, step1432]: loss 88.666656
[epoch1, step1433]: loss 123.954208
[epoch1, step1434]: loss 50.156090
[epoch1, step1435]: loss 64.728859
[epoch1, step1436]: loss 27.677992
[epoch1, step1437]: loss 32.405037
[epoch1, step1438]: loss 33.935802
[epoch1, step1439]: loss 34.995392
[epoch1, step1440]: loss 55.844803
[epoch1, step1441]: loss 22.710737
[epoch1, step1442]: loss 174.538879
[epoch1, step1443]: loss 75.736427
[epoch1, step1444]: loss 71.732864
[epoch1, step1445]: loss 58.008900
[epoch1, step1446]: loss 60.341606
[epoch1, step1447]: loss 103.021378
[epoch1, step1448]: loss 100.188545
[epoch1, step1449]: loss 88.613098
[epoch1, step1450]: loss 37.992069
[epoch1, step1451]: loss 65.559868
[epoch1, step1452]: loss 71.370354
[epoch1, step1453]: loss 121.784912
[epoch1, step1454]: loss 104.801651
[epoch1, step1455]: loss 57.061619
[epoch1, step1456]: loss 51.166626
[epoch1, step1457]: loss 46.999748
[epoch1, step1458]: loss 76.111404
[epoch1, step1459]: loss 94.839142
[epoch1, step1460]: loss 38.452385
[epoch1, step1461]: loss 24.107483
[epoch1, step1462]: loss 89.554131
[epoch1, step1463]: loss 18.760506
[epoch1, step1464]: loss 29.249456
[epoch1, step1465]: loss 99.834991
[epoch1, step1466]: loss 43.344406
[epoch1, step1467]: loss 39.955658
[epoch1, step1468]: loss 42.279686
[epoch1, step1469]: loss 90.674500
[epoch1, step1470]: loss 88.676735
[epoch1, step1471]: loss 119.296074
[epoch1, step1472]: loss 95.798424
[epoch1, step1473]: loss 88.745026
[epoch1, step1474]: loss 105.178009
[epoch1, step1475]: loss 46.231079
[epoch1, step1476]: loss 100.846451
[epoch1, step1477]: loss 48.508434
[epoch1, step1478]: loss 45.097618
[epoch1, step1479]: loss 44.259766
[epoch1, step1480]: loss 18.523624
[epoch1, step1481]: loss 47.165184
[epoch1, step1482]: loss 22.705173
[epoch1, step1483]: loss 55.493603
[epoch1, step1484]: loss 43.462105
[epoch1, step1485]: loss 32.554283
[epoch1, step1486]: loss 104.977707
[epoch1, step1487]: loss 67.360779
[epoch1, step1488]: loss 43.159534
[epoch1, step1489]: loss 124.185020
[epoch1, step1490]: loss 84.413696
[epoch1, step1491]: loss 58.870720
[epoch1, step1492]: loss 57.114880
[epoch1, step1493]: loss 24.176819
[epoch1, step1494]: loss 77.299721
[epoch1, step1495]: loss 95.012985
[epoch1, step1496]: loss 22.930672
[epoch1, step1497]: loss 77.711288
[epoch1, step1498]: loss 26.368191
[epoch1, step1499]: loss 72.273415
[epoch1, step1500]: loss 87.910187
[epoch1, step1501]: loss 67.517540
[epoch1, step1502]: loss 54.597157
[epoch1, step1503]: loss 81.241432
[epoch1, step1504]: loss 64.075546
[epoch1, step1505]: loss 69.093124
[epoch1, step1506]: loss 59.219688
[epoch1, step1507]: loss 62.020447
[epoch1, step1508]: loss 35.286682
[epoch1, step1509]: loss 77.205727
[epoch1, step1510]: loss 72.543335
[epoch1, step1511]: loss 40.468895
[epoch1, step1512]: loss 65.520554
[epoch1, step1513]: loss 53.048409
[epoch1, step1514]: loss 37.867645
[epoch1, step1515]: loss 107.786919
[epoch1, step1516]: loss 86.683830
[epoch1, step1517]: loss 72.363106
[epoch1, step1518]: loss 97.779068
[epoch1, step1519]: loss 55.297874
[epoch1, step1520]: loss 48.679813
[epoch1, step1521]: loss 39.569012
[epoch1, step1522]: loss 57.894753
[epoch1, step1523]: loss 80.269386
[epoch1, step1524]: loss 99.765083
[epoch1, step1525]: loss 50.281452
[epoch1, step1526]: loss 50.548763
[epoch1, step1527]: loss 59.051819
[epoch1, step1528]: loss 27.063293
[epoch1, step1529]: loss 29.803139
[epoch1, step1530]: loss 22.894070
[epoch1, step1531]: loss 55.372395
[epoch1, step1532]: loss 69.067764
[epoch1, step1533]: loss 41.503597
[epoch1, step1534]: loss 60.393608
[epoch1, step1535]: loss 58.890640
[epoch1, step1536]: loss 14.710864
[epoch1, step1537]: loss 15.351176
[epoch1, step1538]: loss 59.271919
[epoch1, step1539]: loss 119.813698
[epoch1, step1540]: loss 9.297215
[epoch1, step1541]: loss 26.437935
[epoch1, step1542]: loss 67.650772
[epoch1, step1543]: loss 50.249107
[epoch1, step1544]: loss 26.692675
[epoch1, step1545]: loss 54.774895
[epoch1, step1546]: loss 4.829516
[epoch1, step1547]: loss 49.148361
[epoch1, step1548]: loss 63.169727
[epoch1, step1549]: loss 57.903713
[epoch1, step1550]: loss 35.836891
[epoch1, step1551]: loss 32.240471
[epoch1, step1552]: loss 46.722172
[epoch1, step1553]: loss 51.305714
[epoch1, step1554]: loss 89.646271
[epoch1, step1555]: loss 40.829727
[epoch1, step1556]: loss 87.424637
[epoch1, step1557]: loss 67.484802
[epoch1, step1558]: loss 94.139893
[epoch1, step1559]: loss 113.768585
[epoch1, step1560]: loss 61.482124
[epoch1, step1561]: loss 74.388000
[epoch1, step1562]: loss 18.385241
[epoch1, step1563]: loss 44.832230
[epoch1, step1564]: loss 38.918373
[epoch1, step1565]: loss 49.281754
[epoch1, step1566]: loss 45.779083
[epoch1, step1567]: loss 66.760979
[epoch1, step1568]: loss 72.585068
[epoch1, step1569]: loss 39.613003
[epoch1, step1570]: loss 116.469696
[epoch1, step1571]: loss 89.333443
[epoch1, step1572]: loss 59.286980
[epoch1, step1573]: loss 79.299927
[epoch1, step1574]: loss 74.926086
[epoch1, step1575]: loss 19.301624
[epoch1, step1576]: loss 36.286930
[epoch1, step1577]: loss 70.928696
[epoch1, step1578]: loss 65.096642
[epoch1, step1579]: loss 123.744659
[epoch1, step1580]: loss 85.768997
[epoch1, step1581]: loss 87.818626
[epoch1, step1582]: loss 59.146355
[epoch1, step1583]: loss 32.404842
[epoch1, step1584]: loss 60.884880
[epoch1, step1585]: loss 67.612617
[epoch1, step1586]: loss 78.071480
[epoch1, step1587]: loss 152.764618
[epoch1, step1588]: loss 78.190796
[epoch1, step1589]: loss 55.043358
[epoch1, step1590]: loss 35.415531
[epoch1, step1591]: loss 52.102104
[epoch1, step1592]: loss 51.251904
[epoch1, step1593]: loss 48.925468
[epoch1, step1594]: loss 47.939178
[epoch1, step1595]: loss 36.770302
[epoch1, step1596]: loss 64.627449
[epoch1, step1597]: loss 46.904556
[epoch1, step1598]: loss 71.681679
[epoch1, step1599]: loss 46.703056
[epoch1, step1600]: loss 57.859867
[epoch1, step1601]: loss 48.359276
[epoch1, step1602]: loss 51.199623
[epoch1, step1603]: loss 32.704094
[epoch1, step1604]: loss 28.325687
[epoch1, step1605]: loss 63.563286
[epoch1, step1606]: loss 50.618698
[epoch1, step1607]: loss 69.575623
[epoch1, step1608]: loss 23.207935
[epoch1, step1609]: loss 16.155220
[epoch1, step1610]: loss 38.767044
[epoch1, step1611]: loss 103.183281
[epoch1, step1612]: loss 68.935616
[epoch1, step1613]: loss 95.913132
[epoch1, step1614]: loss 24.240273
[epoch1, step1615]: loss 81.862900
[epoch1, step1616]: loss 41.352154
[epoch1, step1617]: loss 47.919437
[epoch1, step1618]: loss 59.979279
[epoch1, step1619]: loss 83.768448
[epoch1, step1620]: loss 39.873016
[epoch1, step1621]: loss 22.968449
[epoch1, step1622]: loss 39.051712
[epoch1, step1623]: loss 36.811989
[epoch1, step1624]: loss 54.500595
[epoch1, step1625]: loss 20.051414
[epoch1, step1626]: loss 12.609062
[epoch1, step1627]: loss 38.080349
[epoch1, step1628]: loss 96.660049
[epoch1, step1629]: loss 20.147072
[epoch1, step1630]: loss 77.925560
[epoch1, step1631]: loss 56.524696
[epoch1, step1632]: loss 25.464489
[epoch1, step1633]: loss 63.445705
[epoch1, step1634]: loss 40.342369
[epoch1, step1635]: loss 31.564705
[epoch1, step1636]: loss 64.554047
[epoch1, step1637]: loss 61.626850
[epoch1, step1638]: loss 99.689140
[epoch1, step1639]: loss 65.177254
[epoch1, step1640]: loss 85.377220
[epoch1, step1641]: loss 93.920593
[epoch1, step1642]: loss 179.183533
[epoch1, step1643]: loss 46.617390
[epoch1, step1644]: loss 75.241035
[epoch1, step1645]: loss 74.987091
[epoch1, step1646]: loss 160.489700
[epoch1, step1647]: loss 66.522629
[epoch1, step1648]: loss 76.100304
[epoch1, step1649]: loss 103.961723
[epoch1, step1650]: loss 35.760685
[epoch1, step1651]: loss 50.215675
[epoch1, step1652]: loss 47.682995
[epoch1, step1653]: loss 47.923302
[epoch1, step1654]: loss 32.991028
[epoch1, step1655]: loss 96.360229
[epoch1, step1656]: loss 66.125977
[epoch1, step1657]: loss 115.928360
[epoch1, step1658]: loss 9.853365
[epoch1, step1659]: loss 68.682381
[epoch1, step1660]: loss 21.543856
[epoch1, step1661]: loss 50.035503
[epoch1, step1662]: loss 54.671822
[epoch1, step1663]: loss 93.242348
[epoch1, step1664]: loss 73.798660
[epoch1, step1665]: loss 78.770142
[epoch1, step1666]: loss 79.919464
[epoch1, step1667]: loss 29.982538
[epoch1, step1668]: loss 19.601130
[epoch1, step1669]: loss 57.493568
[epoch1, step1670]: loss 69.119820
[epoch1, step1671]: loss 76.016678
[epoch1, step1672]: loss 51.645645
[epoch1, step1673]: loss 33.247669
[epoch1, step1674]: loss 58.314713
[epoch1, step1675]: loss 80.642624
[epoch1, step1676]: loss 54.000389
[epoch1, step1677]: loss 36.755295
[epoch1, step1678]: loss 72.801323
[epoch1, step1679]: loss 103.505280
[epoch1, step1680]: loss 64.119034
[epoch1, step1681]: loss 26.770451
[epoch1, step1682]: loss 53.715302
[epoch1, step1683]: loss 38.324860
[epoch1, step1684]: loss 50.189629
[epoch1, step1685]: loss 10.933764
[epoch1, step1686]: loss 60.085312
[epoch1, step1687]: loss 27.727617
[epoch1, step1688]: loss 22.073988
[epoch1, step1689]: loss 80.797974
[epoch1, step1690]: loss 38.449615
[epoch1, step1691]: loss 91.161682
[epoch1, step1692]: loss 68.579636
[epoch1, step1693]: loss 74.628136
[epoch1, step1694]: loss 28.447138
[epoch1, step1695]: loss 25.912619
[epoch1, step1696]: loss 22.535915
[epoch1, step1697]: loss 74.831070
[epoch1, step1698]: loss 17.946226
[epoch1, step1699]: loss 100.550545
[epoch1, step1700]: loss 91.112167
[epoch1, step1701]: loss 75.575089
[epoch1, step1702]: loss 72.210144
[epoch1, step1703]: loss 65.697418
[epoch1, step1704]: loss 29.672146
[epoch1, step1705]: loss 104.244110
[epoch1, step1706]: loss 52.063015
[epoch1, step1707]: loss 45.766827
[epoch1, step1708]: loss 54.461567
[epoch1, step1709]: loss 62.215469
[epoch1, step1710]: loss 37.230553
[epoch1, step1711]: loss 73.624237
[epoch1, step1712]: loss 31.904055
[epoch1, step1713]: loss 53.948895
[epoch1, step1714]: loss 45.374794
[epoch1, step1715]: loss 65.947121
[epoch1, step1716]: loss 33.245598
[epoch1, step1717]: loss 42.151489
[epoch1, step1718]: loss 94.172424
[epoch1, step1719]: loss 50.273659
[epoch1, step1720]: loss 59.022614
[epoch1, step1721]: loss 65.586693
[epoch1, step1722]: loss 91.128258
[epoch1, step1723]: loss 92.102692
[epoch1, step1724]: loss 43.672974
[epoch1, step1725]: loss 72.711914
[epoch1, step1726]: loss 58.050072
[epoch1, step1727]: loss 16.808136
[epoch1, step1728]: loss 43.297470
[epoch1, step1729]: loss 36.424549
[epoch1, step1730]: loss 51.821659
[epoch1, step1731]: loss 71.021721
[epoch1, step1732]: loss 72.302795
[epoch1, step1733]: loss 53.462914
[epoch1, step1734]: loss 39.640816
[epoch1, step1735]: loss 57.233860
[epoch1, step1736]: loss 68.999580
[epoch1, step1737]: loss 37.036839
[epoch1, step1738]: loss 31.624111
[epoch1, step1739]: loss 87.770775
[epoch1, step1740]: loss 56.787777
[epoch1, step1741]: loss 45.282993
[epoch1, step1742]: loss 30.863842
[epoch1, step1743]: loss 36.139984
[epoch1, step1744]: loss 76.606400
[epoch1, step1745]: loss 30.468166
[epoch1, step1746]: loss 43.971905
[epoch1, step1747]: loss 26.633854
[epoch1, step1748]: loss 24.378572
[epoch1, step1749]: loss 87.562271
[epoch1, step1750]: loss 88.318840
[epoch1, step1751]: loss 42.270187
[epoch1, step1752]: loss 75.383560
[epoch1, step1753]: loss 52.939705
[epoch1, step1754]: loss 11.693640
[epoch1, step1755]: loss 21.618643
[epoch1, step1756]: loss 55.967323
[epoch1, step1757]: loss 56.242104
[epoch1, step1758]: loss 61.211380
[epoch1, step1759]: loss 87.610641
[epoch1, step1760]: loss 78.294540
[epoch1, step1761]: loss 29.973732
[epoch1, step1762]: loss 42.742611
[epoch1, step1763]: loss 63.282028
[epoch1, step1764]: loss 87.710014
[epoch1, step1765]: loss 76.462090
[epoch1, step1766]: loss 84.145119
[epoch1, step1767]: loss 40.609131
[epoch1, step1768]: loss 41.186371
[epoch1, step1769]: loss 28.516865
[epoch1, step1770]: loss 48.146603
[epoch1, step1771]: loss 47.183929
[epoch1, step1772]: loss 23.296715
[epoch1, step1773]: loss 46.676262
[epoch1, step1774]: loss 53.201454
[epoch1, step1775]: loss 38.958622
[epoch1, step1776]: loss 84.085037
[epoch1, step1777]: loss 34.043640
[epoch1, step1778]: loss 69.211899
[epoch1, step1779]: loss 44.445908
[epoch1, step1780]: loss 31.183710
[epoch1, step1781]: loss 40.421883
[epoch1, step1782]: loss 21.085251
[epoch1, step1783]: loss 37.753197
[epoch1, step1784]: loss 57.552021
[epoch1, step1785]: loss 41.491615
[epoch1, step1786]: loss 16.299826
[epoch1, step1787]: loss 47.701591
[epoch1, step1788]: loss 54.348709
[epoch1, step1789]: loss 42.631027
[epoch1, step1790]: loss 42.043064
[epoch1, step1791]: loss 79.142555
[epoch1, step1792]: loss 34.577400
[epoch1, step1793]: loss 68.000343
[epoch1, step1794]: loss 48.906124
[epoch1, step1795]: loss 14.731977
[epoch1, step1796]: loss 34.881519
[epoch1, step1797]: loss 68.133957
[epoch1, step1798]: loss 51.433456
[epoch1, step1799]: loss 90.715889
[epoch1, step1800]: loss 60.019623
[epoch1, step1801]: loss 25.838766
[epoch1, step1802]: loss 29.515686
[epoch1, step1803]: loss 96.337631
[epoch1, step1804]: loss 119.505722
[epoch1, step1805]: loss 30.858681
[epoch1, step1806]: loss 32.000980
[epoch1, step1807]: loss 53.656715
[epoch1, step1808]: loss 30.766769
[epoch1, step1809]: loss 69.932487
[epoch1, step1810]: loss 40.260101
[epoch1, step1811]: loss 91.117470
[epoch1, step1812]: loss 51.315994
[epoch1, step1813]: loss 68.432709
[epoch1, step1814]: loss 98.306030
[epoch1, step1815]: loss 59.248009
[epoch1, step1816]: loss 57.133743
[epoch1, step1817]: loss 23.596262
[epoch1, step1818]: loss 67.769653
[epoch1, step1819]: loss 69.113617
[epoch1, step1820]: loss 69.072601
[epoch1, step1821]: loss 57.660469
[epoch1, step1822]: loss 42.929111
[epoch1, step1823]: loss 96.321976
[epoch1, step1824]: loss 71.443108
[epoch1, step1825]: loss 36.912621
[epoch1, step1826]: loss 36.268276
[epoch1, step1827]: loss 29.535049
[epoch1, step1828]: loss 52.046227
[epoch1, step1829]: loss 21.118837
[epoch1, step1830]: loss 35.694317
[epoch1, step1831]: loss 66.151558
[epoch1, step1832]: loss 46.311787
[epoch1, step1833]: loss 16.072594
[epoch1, step1834]: loss 62.381317
[epoch1, step1835]: loss 27.866058
[epoch1, step1836]: loss 33.169514
[epoch1, step1837]: loss 31.977398
[epoch1, step1838]: loss 91.850349
[epoch1, step1839]: loss 80.284203
[epoch1, step1840]: loss 12.798922
[epoch1, step1841]: loss 60.498276
[epoch1, step1842]: loss 17.824696
[epoch1, step1843]: loss 24.365028
[epoch1, step1844]: loss 87.096855
[epoch1, step1845]: loss 42.588871
[epoch1, step1846]: loss 48.098293
[epoch1, step1847]: loss 38.710251
[epoch1, step1848]: loss 84.174637
[epoch1, step1849]: loss 40.352978
[epoch1, step1850]: loss 49.799278
[epoch1, step1851]: loss 69.439301
[epoch1, step1852]: loss 42.219898
[epoch1, step1853]: loss 22.584974
[epoch1, step1854]: loss 8.535667
[epoch1, step1855]: loss 80.644867
[epoch1, step1856]: loss 57.005478
[epoch1, step1857]: loss 9.326016
[epoch1, step1858]: loss 63.649628
[epoch1, step1859]: loss 81.221817
[epoch1, step1860]: loss 39.956833
[epoch1, step1861]: loss 26.302986
[epoch1, step1862]: loss 41.600109
[epoch1, step1863]: loss 79.941216
[epoch1, step1864]: loss 91.923347
[epoch1, step1865]: loss 49.602036
[epoch1, step1866]: loss 50.698395
[epoch1, step1867]: loss 52.747505
[epoch1, step1868]: loss 26.691765
[epoch1, step1869]: loss 101.126579
[epoch1, step1870]: loss 41.481110
[epoch1, step1871]: loss 120.489777
[epoch1, step1872]: loss 41.539158
[epoch1, step1873]: loss 41.414513
[epoch1, step1874]: loss 49.382992
[epoch1, step1875]: loss 67.972542
[epoch1, step1876]: loss 38.913643
[epoch1, step1877]: loss 53.650349
[epoch1, step1878]: loss 31.258566
[epoch1, step1879]: loss 60.966496
[epoch1, step1880]: loss 40.598354
[epoch1, step1881]: loss 55.739296
[epoch1, step1882]: loss 37.992310
[epoch1, step1883]: loss 58.512123
[epoch1, step1884]: loss 8.298745
[epoch1, step1885]: loss 70.948532
[epoch1, step1886]: loss 11.285069
[epoch1, step1887]: loss 68.275818
[epoch1, step1888]: loss 34.939816
[epoch1, step1889]: loss 37.516941
[epoch1, step1890]: loss 50.871529
[epoch1, step1891]: loss 77.002396
[epoch1, step1892]: loss 30.445873
[epoch1, step1893]: loss 33.404163
[epoch1, step1894]: loss 14.631570
[epoch1, step1895]: loss 102.855202
[epoch1, step1896]: loss 55.197895
[epoch1, step1897]: loss 65.696243
[epoch1, step1898]: loss 90.782806
[epoch1, step1899]: loss 28.015829
[epoch1, step1900]: loss 68.917786
[epoch1, step1901]: loss 82.339409
[epoch1, step1902]: loss 36.588196
[epoch1, step1903]: loss 91.220154
[epoch1, step1904]: loss 41.017181
[epoch1, step1905]: loss 89.923286
[epoch1, step1906]: loss 30.148720
[epoch1, step1907]: loss 48.419743
[epoch1, step1908]: loss 13.380026
[epoch1, step1909]: loss 28.652439
[epoch1, step1910]: loss 21.327610
[epoch1, step1911]: loss 23.098669
[epoch1, step1912]: loss 27.605406
[epoch1, step1913]: loss 31.472923
[epoch1, step1914]: loss 119.682472
[epoch1, step1915]: loss 86.091400
[epoch1, step1916]: loss 48.410091
[epoch1, step1917]: loss 71.968094
[epoch1, step1918]: loss 46.360592
[epoch1, step1919]: loss 23.486450
[epoch1, step1920]: loss 37.718842
[epoch1, step1921]: loss 72.476746
[epoch1, step1922]: loss 79.615280
[epoch1, step1923]: loss 55.163353
[epoch1, step1924]: loss 17.457432
[epoch1, step1925]: loss 48.218590
[epoch1, step1926]: loss 37.400948
[epoch1, step1927]: loss 84.586700
[epoch1, step1928]: loss 17.493591
[epoch1, step1929]: loss 74.582153
[epoch1, step1930]: loss 79.778572
[epoch1, step1931]: loss 45.482513
[epoch1, step1932]: loss 42.018585
[epoch1, step1933]: loss 9.938993
[epoch1, step1934]: loss 47.042271
[epoch1, step1935]: loss 53.687649
[epoch1, step1936]: loss 61.221939
[epoch1, step1937]: loss 64.315567
[epoch1, step1938]: loss 18.979897
[epoch1, step1939]: loss 30.256668
[epoch1, step1940]: loss 52.092930
[epoch1, step1941]: loss 31.779072
[epoch1, step1942]: loss 56.695812
[epoch1, step1943]: loss 28.753250
[epoch1, step1944]: loss 81.809906
[epoch1, step1945]: loss 19.699736
[epoch1, step1946]: loss 35.031944
[epoch1, step1947]: loss 50.854546
[epoch1, step1948]: loss 27.629608
[epoch1, step1949]: loss 67.555679
[epoch1, step1950]: loss 51.913437
[epoch1, step1951]: loss 69.364944
[epoch1, step1952]: loss 66.939423
[epoch1, step1953]: loss 38.725536
[epoch1, step1954]: loss 41.470070
[epoch1, step1955]: loss 59.502827
[epoch1, step1956]: loss 62.138176
[epoch1, step1957]: loss 35.059582
[epoch1, step1958]: loss 32.216599
[epoch1, step1959]: loss 21.698011
[epoch1, step1960]: loss 30.219336
[epoch1, step1961]: loss 65.830620
[epoch1, step1962]: loss 71.776962
[epoch1, step1963]: loss 53.465714
[epoch1, step1964]: loss 31.336851
[epoch1, step1965]: loss 13.197710
[epoch1, step1966]: loss 26.590788
[epoch1, step1967]: loss 36.632725
[epoch1, step1968]: loss 65.602173
[epoch1, step1969]: loss 39.494858
[epoch1, step1970]: loss 63.779224
[epoch1, step1971]: loss 61.014435
[epoch1, step1972]: loss 76.978912
[epoch1, step1973]: loss 25.655596
[epoch1, step1974]: loss 61.355297
[epoch1, step1975]: loss 24.980598
[epoch1, step1976]: loss 52.717350
[epoch1, step1977]: loss 83.483208
[epoch1, step1978]: loss 109.258583
[epoch1, step1979]: loss 87.063881
[epoch1, step1980]: loss 45.518719
[epoch1, step1981]: loss 35.881798
[epoch1, step1982]: loss 35.220654
[epoch1, step1983]: loss 87.817513
[epoch1, step1984]: loss 22.134092
[epoch1, step1985]: loss 63.197853
[epoch1, step1986]: loss 28.843765
[epoch1, step1987]: loss 54.235767
[epoch1, step1988]: loss 32.529270
[epoch1, step1989]: loss 97.239594
[epoch1, step1990]: loss 50.745022
[epoch1, step1991]: loss 61.099304
[epoch1, step1992]: loss 71.523315
[epoch1, step1993]: loss 78.293961
[epoch1, step1994]: loss 113.663452
[epoch1, step1995]: loss 61.121529
[epoch1, step1996]: loss 24.476536
[epoch1, step1997]: loss 59.458481
[epoch1, step1998]: loss 95.251816
[epoch1, step1999]: loss 20.877123
[epoch1, step2000]: loss 46.276207
[epoch1, step2001]: loss 69.160789
[epoch1, step2002]: loss 32.040359
[epoch1, step2003]: loss 32.141094
[epoch1, step2004]: loss 21.483734
[epoch1, step2005]: loss 79.747467
[epoch1, step2006]: loss 109.761993
[epoch1, step2007]: loss 58.453064
[epoch1, step2008]: loss 45.013714
[epoch1, step2009]: loss 119.567879
[epoch1, step2010]: loss 41.560822
[epoch1, step2011]: loss 49.193466
[epoch1, step2012]: loss 61.214790
[epoch1, step2013]: loss 37.283764
[epoch1, step2014]: loss 89.209785
[epoch1, step2015]: loss 34.632271
[epoch1, step2016]: loss 75.231041
[epoch1, step2017]: loss 46.777916
[epoch1, step2018]: loss 61.084778
[epoch1, step2019]: loss 35.734661
[epoch1, step2020]: loss 52.748486
[epoch1, step2021]: loss 34.269501
[epoch1, step2022]: loss 48.154846
[epoch1, step2023]: loss 62.900211
[epoch1, step2024]: loss 47.497089
[epoch1, step2025]: loss 43.494171
[epoch1, step2026]: loss 80.580666
[epoch1, step2027]: loss 46.330643
[epoch1, step2028]: loss 66.906425
[epoch1, step2029]: loss 48.212429
[epoch1, step2030]: loss 69.892334
[epoch1, step2031]: loss 51.336220
[epoch1, step2032]: loss 59.167225
[epoch1, step2033]: loss 64.435974
[epoch1, step2034]: loss 22.366552
[epoch1, step2035]: loss 21.175814
[epoch1, step2036]: loss 70.311676
[epoch1, step2037]: loss 52.566345
[epoch1, step2038]: loss 24.126457
[epoch1, step2039]: loss 22.670511
[epoch1, step2040]: loss 25.799953
[epoch1, step2041]: loss 14.951147
[epoch1, step2042]: loss 18.606695
[epoch1, step2043]: loss 88.074814
[epoch1, step2044]: loss 42.674877
[epoch1, step2045]: loss 31.055473
[epoch1, step2046]: loss 49.724945
[epoch1, step2047]: loss 48.713013
[epoch1, step2048]: loss 31.796368
[epoch1, step2049]: loss 22.322464
[epoch1, step2050]: loss 29.510990
[epoch1, step2051]: loss 19.828131
[epoch1, step2052]: loss 119.233437
[epoch1, step2053]: loss 18.809681
[epoch1, step2054]: loss 23.062708
[epoch1, step2055]: loss 31.700527
[epoch1, step2056]: loss 50.092484
[epoch1, step2057]: loss 27.639172
[epoch1, step2058]: loss 26.080364
[epoch1, step2059]: loss 9.470339
[epoch1, step2060]: loss 54.127029
[epoch1, step2061]: loss 50.870712
[epoch1, step2062]: loss 88.602142
[epoch1, step2063]: loss 85.801285
[epoch1, step2064]: loss 36.603088
[epoch1, step2065]: loss 88.716393
[epoch1, step2066]: loss 44.914566
[epoch1, step2067]: loss 33.025387
[epoch1, step2068]: loss 22.682743
[epoch1, step2069]: loss 12.254410
[epoch1, step2070]: loss 35.169201
[epoch1, step2071]: loss 38.104637
[epoch1, step2072]: loss 39.341091
[epoch1, step2073]: loss 26.266911
[epoch1, step2074]: loss 13.543175
[epoch1, step2075]: loss 49.123459
[epoch1, step2076]: loss 27.153976
[epoch1, step2077]: loss 52.313103
[epoch1, step2078]: loss 55.906250
[epoch1, step2079]: loss 71.149109
[epoch1, step2080]: loss 58.482323
[epoch1, step2081]: loss 28.368481
[epoch1, step2082]: loss 34.483727
[epoch1, step2083]: loss 25.618219
[epoch1, step2084]: loss 74.572678
[epoch1, step2085]: loss 27.776064
[epoch1, step2086]: loss 71.002213
[epoch1, step2087]: loss 81.093483
[epoch1, step2088]: loss 34.582012
[epoch1, step2089]: loss 22.252655
[epoch1, step2090]: loss 67.124878
[epoch1, step2091]: loss 36.991776
[epoch1, step2092]: loss 82.991394
[epoch1, step2093]: loss 14.028326
[epoch1, step2094]: loss 6.777170
[epoch1, step2095]: loss 22.217712
[epoch1, step2096]: loss 60.168678
[epoch1, step2097]: loss 52.918312
[epoch1, step2098]: loss 36.443958
[epoch1, step2099]: loss 19.455242
[epoch1, step2100]: loss 25.895712
[epoch1, step2101]: loss 22.835449
[epoch1, step2102]: loss 44.184280
[epoch1, step2103]: loss 51.021240
[epoch1, step2104]: loss 57.619934
[epoch1, step2105]: loss 89.714355
[epoch1, step2106]: loss 49.669849
[epoch1, step2107]: loss 48.553535
[epoch1, step2108]: loss 35.300892
[epoch1, step2109]: loss 81.927933
[epoch1, step2110]: loss 37.750790
[epoch1, step2111]: loss 55.304440
[epoch1, step2112]: loss 19.366234
[epoch1, step2113]: loss 32.602051
[epoch1, step2114]: loss 62.356277
[epoch1, step2115]: loss 50.361427
[epoch1, step2116]: loss 13.188704
[epoch1, step2117]: loss 23.629210
[epoch1, step2118]: loss 30.428616
[epoch1, step2119]: loss 61.774895
[epoch1, step2120]: loss 45.256359
[epoch1, step2121]: loss 32.134476
[epoch1, step2122]: loss 47.020111
[epoch1, step2123]: loss 18.240522
[epoch1, step2124]: loss 31.075344
[epoch1, step2125]: loss 47.489952
[epoch1, step2126]: loss 53.597057
[epoch1, step2127]: loss 66.097900
[epoch1, step2128]: loss 27.651096
[epoch1, step2129]: loss 68.467079
[epoch1, step2130]: loss 17.315529
[epoch1, step2131]: loss 21.363636
[epoch1, step2132]: loss 20.056480
[epoch1, step2133]: loss 55.058800
[epoch1, step2134]: loss 47.110550
[epoch1, step2135]: loss 55.886314
[epoch1, step2136]: loss 57.969913
[epoch1, step2137]: loss 28.773775
[epoch1, step2138]: loss 7.661265
[epoch1, step2139]: loss 65.339752
[epoch1, step2140]: loss 73.397285
[epoch1, step2141]: loss 48.792091
[epoch1, step2142]: loss 65.232986
[epoch1, step2143]: loss 24.939266
[epoch1, step2144]: loss 69.575470
[epoch1, step2145]: loss 18.560030
[epoch1, step2146]: loss 25.420887
[epoch1, step2147]: loss 9.247688
[epoch1, step2148]: loss 34.282730
[epoch1, step2149]: loss 15.014379
[epoch1, step2150]: loss 9.673645
[epoch1, step2151]: loss 44.760571
[epoch1, step2152]: loss 37.925476
[epoch1, step2153]: loss 48.409229
[epoch1, step2154]: loss 13.804073
[epoch1, step2155]: loss 27.481001
[epoch1, step2156]: loss 58.508205
[epoch1, step2157]: loss 13.998074
[epoch1, step2158]: loss 47.970963
[epoch1, step2159]: loss 31.544968
[epoch1, step2160]: loss 19.342710
[epoch1, step2161]: loss 9.147986
[epoch1, step2162]: loss 54.404865
[epoch1, step2163]: loss 76.586983
[epoch1, step2164]: loss 36.989754
[epoch1, step2165]: loss 38.632912
[epoch1, step2166]: loss 47.410282
[epoch1, step2167]: loss 66.929428
[epoch1, step2168]: loss 23.971769
[epoch1, step2169]: loss 20.498114
[epoch1, step2170]: loss 21.479544
[epoch1, step2171]: loss 63.214886
[epoch1, step2172]: loss 17.463737
[epoch1, step2173]: loss 62.340435
[epoch1, step2174]: loss 23.972450
[epoch1, step2175]: loss 78.266869
[epoch1, step2176]: loss 54.405006
[epoch1, step2177]: loss 16.952461
[epoch1, step2178]: loss 44.896439
[epoch1, step2179]: loss 26.062735
[epoch1, step2180]: loss 11.787769
[epoch1, step2181]: loss 48.499645
[epoch1, step2182]: loss 45.194305
[epoch1, step2183]: loss 57.656460
[epoch1, step2184]: loss 72.679611
[epoch1, step2185]: loss 32.917465
[epoch1, step2186]: loss 15.480394
[epoch1, step2187]: loss 39.912739
[epoch1, step2188]: loss 33.710285
[epoch1, step2189]: loss 39.587132
[epoch1, step2190]: loss 28.516615
[epoch1, step2191]: loss 65.924034
[epoch1, step2192]: loss 25.890697
[epoch1, step2193]: loss 26.845539
[epoch1, step2194]: loss 26.779879
[epoch1, step2195]: loss 53.624481
[epoch1, step2196]: loss 32.513702
[epoch1, step2197]: loss 27.286999
[epoch1, step2198]: loss 89.114044
[epoch1, step2199]: loss 32.512630
[epoch1, step2200]: loss 33.063503
[epoch1, step2201]: loss 19.259031
[epoch1, step2202]: loss 5.333050
[epoch1, step2203]: loss 51.806759
[epoch1, step2204]: loss 72.361313
[epoch1, step2205]: loss 49.862953
[epoch1, step2206]: loss 17.062729
[epoch1, step2207]: loss 96.282730
[epoch1, step2208]: loss 58.641064
[epoch1, step2209]: loss 53.064758
[epoch1, step2210]: loss 25.396608
[epoch1, step2211]: loss 21.176859
[epoch1, step2212]: loss 116.381210
[epoch1, step2213]: loss 25.026785
[epoch1, step2214]: loss 9.650176
[epoch1, step2215]: loss 30.844431
[epoch1, step2216]: loss 6.887060
[epoch1, step2217]: loss 39.336456
[epoch1, step2218]: loss 9.292759
[epoch1, step2219]: loss 24.986691
[epoch1, step2220]: loss 63.739727
[epoch1, step2221]: loss 47.676083
[epoch1, step2222]: loss 71.037834
[epoch1, step2223]: loss 18.351477
[epoch1, step2224]: loss 23.402254
[epoch1, step2225]: loss 49.453201
[epoch1, step2226]: loss 66.339775
[epoch1, step2227]: loss 42.929832
[epoch1, step2228]: loss 52.076675
[epoch1, step2229]: loss 40.001648
[epoch1, step2230]: loss 43.393772
[epoch1, step2231]: loss 11.084631
[epoch1, step2232]: loss 99.352768
[epoch1, step2233]: loss 48.585159
[epoch1, step2234]: loss 69.952194
[epoch1, step2235]: loss 42.706879
[epoch1, step2236]: loss 43.931660
[epoch1, step2237]: loss 48.388306
[epoch1, step2238]: loss 33.073242
[epoch1, step2239]: loss 16.335781
[epoch1, step2240]: loss 24.271324
[epoch1, step2241]: loss 54.800022
[epoch1, step2242]: loss 17.073418
[epoch1, step2243]: loss 79.391747
[epoch1, step2244]: loss 31.327019
[epoch1, step2245]: loss 9.057718
[epoch1, step2246]: loss 38.808495
[epoch1, step2247]: loss 40.210094
[epoch1, step2248]: loss 10.235695
[epoch1, step2249]: loss 34.241879
[epoch1, step2250]: loss 51.511890
[epoch1, step2251]: loss 40.989815
[epoch1, step2252]: loss 27.066332
[epoch1, step2253]: loss 26.132267
[epoch1, step2254]: loss 19.985941
[epoch1, step2255]: loss 53.080643
[epoch1, step2256]: loss 44.137825
[epoch1, step2257]: loss 33.481071
[epoch1, step2258]: loss 13.334694
[epoch1, step2259]: loss 23.754658
[epoch1, step2260]: loss 30.050201
[epoch1, step2261]: loss 27.264952
[epoch1, step2262]: loss 51.121830
[epoch1, step2263]: loss 108.305710
[epoch1, step2264]: loss 40.976109
[epoch1, step2265]: loss 12.512310
[epoch1, step2266]: loss 78.334732
[epoch1, step2267]: loss 32.891155
[epoch1, step2268]: loss 11.137484
[epoch1, step2269]: loss 33.938873
[epoch1, step2270]: loss 74.553299
[epoch1, step2271]: loss 20.727274
[epoch1, step2272]: loss 30.933556
[epoch1, step2273]: loss 53.989986
[epoch1, step2274]: loss 17.444700
[epoch1, step2275]: loss 42.366234
[epoch1, step2276]: loss 23.337883
[epoch1, step2277]: loss 71.446854
[epoch1, step2278]: loss 37.822556
[epoch1, step2279]: loss 20.446259
[epoch1, step2280]: loss 27.886854
[epoch1, step2281]: loss 6.472474
[epoch1, step2282]: loss 35.732777
[epoch1, step2283]: loss 47.831085
[epoch1, step2284]: loss 64.759911
[epoch1, step2285]: loss 34.418800
[epoch1, step2286]: loss 32.135429
[epoch1, step2287]: loss 29.975607
[epoch1, step2288]: loss 68.009079
[epoch1, step2289]: loss 69.868042
[epoch1, step2290]: loss 56.044250
[epoch1, step2291]: loss 73.751579
[epoch1, step2292]: loss 20.448200
[epoch1, step2293]: loss 8.308672
[epoch1, step2294]: loss 92.301239
[epoch1, step2295]: loss 20.589882
[epoch1, step2296]: loss 40.884338
[epoch1, step2297]: loss 108.204590
[epoch1, step2298]: loss 21.469862
[epoch1, step2299]: loss 70.212204
[epoch1, step2300]: loss 15.750293
[epoch1, step2301]: loss 29.842117
[epoch1, step2302]: loss 57.933205
[epoch1, step2303]: loss 42.224487
[epoch1, step2304]: loss 29.516567
[epoch1, step2305]: loss 15.987247
[epoch1, step2306]: loss 6.322185
[epoch1, step2307]: loss 38.754868
[epoch1, step2308]: loss 23.555237
[epoch1, step2309]: loss 30.777687
[epoch1, step2310]: loss 33.413555
[epoch1, step2311]: loss 52.793518
[epoch1, step2312]: loss 32.541119
[epoch1, step2313]: loss 15.843267
[epoch1, step2314]: loss 25.332769
[epoch1, step2315]: loss 20.267963
[epoch1, step2316]: loss 55.307312
[epoch1, step2317]: loss 11.659491
[epoch1, step2318]: loss 60.456104
[epoch1, step2319]: loss 38.599323
[epoch1, step2320]: loss 90.725998
[epoch1, step2321]: loss 18.232323
[epoch1, step2322]: loss 15.540688
[epoch1, step2323]: loss 16.943138
[epoch1, step2324]: loss 34.021656
[epoch1, step2325]: loss 20.655807
[epoch1, step2326]: loss 46.750565
[epoch1, step2327]: loss 61.819168
[epoch1, step2328]: loss 17.926785
[epoch1, step2329]: loss 31.162384
[epoch1, step2330]: loss 28.445511
[epoch1, step2331]: loss 45.880135
[epoch1, step2332]: loss 59.443737
[epoch1, step2333]: loss 99.670044
[epoch1, step2334]: loss 32.751694
[epoch1, step2335]: loss 52.728825
[epoch1, step2336]: loss 11.182691
[epoch1, step2337]: loss 22.101185
[epoch1, step2338]: loss 25.942039
[epoch1, step2339]: loss 57.512611
[epoch1, step2340]: loss 47.781189
[epoch1, step2341]: loss 54.003937
[epoch1, step2342]: loss 77.988853
[epoch1, step2343]: loss 31.221603
[epoch1, step2344]: loss 62.976604
[epoch1, step2345]: loss 34.237324
[epoch1, step2346]: loss 17.285646
[epoch1, step2347]: loss 47.331970
[epoch1, step2348]: loss 42.530319
[epoch1, step2349]: loss 68.124954
[epoch1, step2350]: loss 16.178728
[epoch1, step2351]: loss 35.401176
[epoch1, step2352]: loss 73.220406
[epoch1, step2353]: loss 20.487801
[epoch1, step2354]: loss 22.356968
[epoch1, step2355]: loss 58.343777
[epoch1, step2356]: loss 40.337280
[epoch1, step2357]: loss 25.721325
[epoch1, step2358]: loss 9.214275
[epoch1, step2359]: loss 19.045952
[epoch1, step2360]: loss 42.320526
[epoch1, step2361]: loss 16.173214
[epoch1, step2362]: loss 15.009982
[epoch1, step2363]: loss 41.802364
[epoch1, step2364]: loss 40.607315
[epoch1, step2365]: loss 26.136509
[epoch1, step2366]: loss 71.595978
[epoch1, step2367]: loss 29.848007
[epoch1, step2368]: loss 35.382473
[epoch1, step2369]: loss 45.722969
[epoch1, step2370]: loss 42.177036
[epoch1, step2371]: loss 56.983620
[epoch1, step2372]: loss 14.212307
[epoch1, step2373]: loss 25.052197
[epoch1, step2374]: loss 18.475637
[epoch1, step2375]: loss 26.480034
[epoch1, step2376]: loss 32.709373
[epoch1, step2377]: loss 24.830532
[epoch1, step2378]: loss 16.315695
[epoch1, step2379]: loss 15.601986
[epoch1, step2380]: loss 29.309593
[epoch1, step2381]: loss 43.312923
[epoch1, step2382]: loss 21.873810
[epoch1, step2383]: loss 22.106339
[epoch1, step2384]: loss 61.966908
[epoch1, step2385]: loss 65.752426
[epoch1, step2386]: loss 45.593491
[epoch1, step2387]: loss 45.490463
[epoch1, step2388]: loss 19.761097
[epoch1, step2389]: loss 22.360588
[epoch1, step2390]: loss 76.395912
[epoch1, step2391]: loss 49.284992
[epoch1, step2392]: loss 30.367764
[epoch1, step2393]: loss 16.815283
[epoch1, step2394]: loss 66.406090
[epoch1, step2395]: loss 24.559895
[epoch1, step2396]: loss 11.182952
[epoch1, step2397]: loss 19.980793
[epoch1, step2398]: loss 36.311729
[epoch1, step2399]: loss 51.624165
[epoch1, step2400]: loss 17.966270
[epoch1, step2401]: loss 54.885460
[epoch1, step2402]: loss 48.042931
[epoch1, step2403]: loss 38.984520
[epoch1, step2404]: loss 13.080926
[epoch1, step2405]: loss 20.702768
[epoch1, step2406]: loss 17.649162
[epoch1, step2407]: loss 65.903511
[epoch1, step2408]: loss 19.792793
[epoch1, step2409]: loss 46.134274
[epoch1, step2410]: loss 53.383064
[epoch1, step2411]: loss 14.937988
[epoch1, step2412]: loss 19.786095
[epoch1, step2413]: loss 37.835258
[epoch1, step2414]: loss 40.130249
[epoch1, step2415]: loss 20.750732
[epoch1, step2416]: loss 28.702385
[epoch1, step2417]: loss 21.581730
[epoch1, step2418]: loss 17.264809
[epoch1, step2419]: loss 29.734327
[epoch1, step2420]: loss 15.318043
[epoch1, step2421]: loss 29.702082
[epoch1, step2422]: loss 30.331352
[epoch1, step2423]: loss 39.593597
[epoch1, step2424]: loss 57.170502
[epoch1, step2425]: loss 55.596130
[epoch1, step2426]: loss 39.538147
[epoch1, step2427]: loss 51.418015
[epoch1, step2428]: loss 65.345764
[epoch1, step2429]: loss 32.826630
[epoch1, step2430]: loss 18.964268
[epoch1, step2431]: loss 51.667347
[epoch1, step2432]: loss 19.961967
[epoch1, step2433]: loss 58.157608
[epoch1, step2434]: loss 15.152529
[epoch1, step2435]: loss 36.809635
[epoch1, step2436]: loss 10.324138
[epoch1, step2437]: loss 39.012436
[epoch1, step2438]: loss 25.893070
[epoch1, step2439]: loss 28.504545
[epoch1, step2440]: loss 23.698654
[epoch1, step2441]: loss 21.901157
[epoch1, step2442]: loss 37.674145
[epoch1, step2443]: loss 58.000614
[epoch1, step2444]: loss 16.779886
[epoch1, step2445]: loss 32.484238
[epoch1, step2446]: loss 27.682379
[epoch1, step2447]: loss 78.206970
[epoch1, step2448]: loss 22.214367
[epoch1, step2449]: loss 11.439726
[epoch1, step2450]: loss 9.080086
[epoch1, step2451]: loss 19.474882
[epoch1, step2452]: loss 17.125830
[epoch1, step2453]: loss 61.008465
[epoch1, step2454]: loss 20.736881
[epoch1, step2455]: loss 15.242755
[epoch1, step2456]: loss 41.952335
[epoch1, step2457]: loss 38.892586
[epoch1, step2458]: loss 33.891777
[epoch1, step2459]: loss 50.547253
[epoch1, step2460]: loss 29.156301
[epoch1, step2461]: loss 47.166355
[epoch1, step2462]: loss 21.308479
[epoch1, step2463]: loss 39.366894
[epoch1, step2464]: loss 46.333778
[epoch1, step2465]: loss 42.577976
[epoch1, step2466]: loss 10.325502
[epoch1, step2467]: loss 42.475143
[epoch1, step2468]: loss 54.386856
[epoch1, step2469]: loss 19.066881
[epoch1, step2470]: loss 41.614223
[epoch1, step2471]: loss 13.899333
[epoch1, step2472]: loss 77.129532
[epoch1, step2473]: loss 35.993641
[epoch1, step2474]: loss 81.746223
[epoch1, step2475]: loss 10.474137
[epoch1, step2476]: loss 30.095915
[epoch1, step2477]: loss 17.782097
[epoch1, step2478]: loss 77.248444
[epoch1, step2479]: loss 40.042599
[epoch1, step2480]: loss 39.658230
[epoch1, step2481]: loss 15.421879
[epoch1, step2482]: loss 50.974606
[epoch1, step2483]: loss 32.986996
[epoch1, step2484]: loss 34.697578
[epoch1, step2485]: loss 44.260529
[epoch1, step2486]: loss 38.748463
[epoch1, step2487]: loss 24.683260
[epoch1, step2488]: loss 27.346287
[epoch1, step2489]: loss 30.816805
[epoch1, step2490]: loss 38.859528
[epoch1, step2491]: loss 9.271514
[epoch1, step2492]: loss 47.113838
[epoch1, step2493]: loss 32.636456
[epoch1, step2494]: loss 42.959450
[epoch1, step2495]: loss 60.769047
[epoch1, step2496]: loss 33.385284
[epoch1, step2497]: loss 55.224075
[epoch1, step2498]: loss 58.520164
[epoch1, step2499]: loss 134.682144
[epoch1, step2500]: loss 13.770841
[epoch1, step2501]: loss 39.257576
[epoch1, step2502]: loss 42.861294
[epoch1, step2503]: loss 31.484432
[epoch1, step2504]: loss 18.236795
[epoch1, step2505]: loss 11.984020
[epoch1, step2506]: loss 11.724815
[epoch1, step2507]: loss 22.726000
[epoch1, step2508]: loss 100.076302
[epoch1, step2509]: loss 21.782177
[epoch1, step2510]: loss 11.412207
[epoch1, step2511]: loss 24.985140
[epoch1, step2512]: loss 37.325504
[epoch1, step2513]: loss 45.590221
[epoch1, step2514]: loss 8.113178
[epoch1, step2515]: loss 27.934498
[epoch1, step2516]: loss 17.486195
[epoch1, step2517]: loss 11.134378
[epoch1, step2518]: loss 36.692490
[epoch1, step2519]: loss 39.036007
[epoch1, step2520]: loss 47.480888
[epoch1, step2521]: loss 17.631174
[epoch1, step2522]: loss 29.206589
[epoch1, step2523]: loss 19.206795
[epoch1, step2524]: loss 51.716503
[epoch1, step2525]: loss 20.713129
[epoch1, step2526]: loss 46.583164
[epoch1, step2527]: loss 78.122757
[epoch1, step2528]: loss 25.440886
[epoch1, step2529]: loss 70.771881
[epoch1, step2530]: loss 38.518402
[epoch1, step2531]: loss 22.570621
[epoch1, step2532]: loss 21.339180
[epoch1, step2533]: loss 27.775875
[epoch1, step2534]: loss 28.048916
[epoch1, step2535]: loss 49.986774
[epoch1, step2536]: loss 33.416794
[epoch1, step2537]: loss 16.644382
[epoch1, step2538]: loss 8.564306
[epoch1, step2539]: loss 35.431313
[epoch1, step2540]: loss 35.875282
[epoch1, step2541]: loss 15.114368
[epoch1, step2542]: loss 96.394051
[epoch1, step2543]: loss 40.373360
[epoch1, step2544]: loss 46.848488
[epoch1, step2545]: loss 22.850582
[epoch1, step2546]: loss 22.161453
[epoch1, step2547]: loss 44.998169
[epoch1, step2548]: loss 13.201050
[epoch1, step2549]: loss 26.837994
[epoch1, step2550]: loss 7.806195
[epoch1, step2551]: loss 31.502949
[epoch1, step2552]: loss 28.416885
[epoch1, step2553]: loss 21.126999
[epoch1, step2554]: loss 28.972874
[epoch1, step2555]: loss 66.758797
[epoch1, step2556]: loss 38.438793
[epoch1, step2557]: loss 38.660278
[epoch1, step2558]: loss 30.706730
[epoch1, step2559]: loss 13.394322
[epoch1, step2560]: loss 16.859840
[epoch1, step2561]: loss 35.624973
[epoch1, step2562]: loss 20.320595
[epoch1, step2563]: loss 43.046196
[epoch1, step2564]: loss 14.291058
[epoch1, step2565]: loss 22.913111
[epoch1, step2566]: loss 32.169621
[epoch1, step2567]: loss 81.662628
[epoch1, step2568]: loss 44.440830
[epoch1, step2569]: loss 18.043503
[epoch1, step2570]: loss 38.333195
[epoch1, step2571]: loss 35.071869
[epoch1, step2572]: loss 14.818687
[epoch1, step2573]: loss 37.550907
[epoch1, step2574]: loss 19.181814
[epoch1, step2575]: loss 37.405357
[epoch1, step2576]: loss 22.896240
[epoch1, step2577]: loss 73.767189
[epoch1, step2578]: loss 20.221794
[epoch1, step2579]: loss 23.603033
[epoch1, step2580]: loss 60.982635
[epoch1, step2581]: loss 32.230370
[epoch1, step2582]: loss 43.683777
[epoch1, step2583]: loss 44.145546
[epoch1, step2584]: loss 64.132423
[epoch1, step2585]: loss 44.599209
[epoch1, step2586]: loss 27.605597
[epoch1, step2587]: loss 14.463427
[epoch1, step2588]: loss 20.237089
[epoch1, step2589]: loss 87.192215
[epoch1, step2590]: loss 21.873070
[epoch1, step2591]: loss 56.687412
[epoch1, step2592]: loss 23.088537
[epoch1, step2593]: loss 24.746788
[epoch1, step2594]: loss 8.947254
[epoch1, step2595]: loss 73.517830
[epoch1, step2596]: loss 19.753578
[epoch1, step2597]: loss 65.376434
[epoch1, step2598]: loss 19.807777
[epoch1, step2599]: loss 14.661140
[epoch1, step2600]: loss 33.535492
[epoch1, step2601]: loss 85.739120
[epoch1, step2602]: loss 12.519890
[epoch1, step2603]: loss 36.732189
[epoch1, step2604]: loss 5.495349
[epoch1, step2605]: loss 37.913879
[epoch1, step2606]: loss 33.805981
[epoch1, step2607]: loss 7.253306
[epoch1, step2608]: loss 18.624039
[epoch1, step2609]: loss 19.074133
[epoch1, step2610]: loss 75.081650
[epoch1, step2611]: loss 15.535122
[epoch1, step2612]: loss 27.310923
[epoch1, step2613]: loss 27.044308
[epoch1, step2614]: loss 15.399663
[epoch1, step2615]: loss 24.224119
[epoch1, step2616]: loss 13.307252
[epoch1, step2617]: loss 49.152542
[epoch1, step2618]: loss 46.358166
[epoch1, step2619]: loss 74.713211
[epoch1, step2620]: loss 24.383766
[epoch1, step2621]: loss 33.470921
[epoch1, step2622]: loss 33.512943
[epoch1, step2623]: loss 21.084953
[epoch1, step2624]: loss 22.510544
[epoch1, step2625]: loss 39.902843
[epoch1, step2626]: loss 52.513222
[epoch1, step2627]: loss 17.484556
[epoch1, step2628]: loss 15.425429
[epoch1, step2629]: loss 29.808126
[epoch1, step2630]: loss 33.079887
[epoch1, step2631]: loss 33.274624
[epoch1, step2632]: loss 86.702278
[epoch1, step2633]: loss 73.247063
[epoch1, step2634]: loss 101.092377
[epoch1, step2635]: loss 19.324024
[epoch1, step2636]: loss 62.900822
[epoch1, step2637]: loss 40.291725
[epoch1, step2638]: loss 17.385517
[epoch1, step2639]: loss 19.730465
[epoch1, step2640]: loss 64.399849
[epoch1, step2641]: loss 22.694527
[epoch1, step2642]: loss 24.334656
[epoch1, step2643]: loss 14.701543
[epoch1, step2644]: loss 16.224483
[epoch1, step2645]: loss 21.756718
[epoch1, step2646]: loss 17.404289
[epoch1, step2647]: loss 35.514488
[epoch1, step2648]: loss 8.595547
[epoch1, step2649]: loss 59.016502
[epoch1, step2650]: loss 49.148331
[epoch1, step2651]: loss 17.162123
[epoch1, step2652]: loss 26.006004
[epoch1, step2653]: loss 55.586182
[epoch1, step2654]: loss 23.405609
[epoch1, step2655]: loss 29.791702
[epoch1, step2656]: loss 62.501041
[epoch1, step2657]: loss 25.471006
[epoch1, step2658]: loss 33.067089
[epoch1, step2659]: loss 26.083649
[epoch1, step2660]: loss 33.118919
[epoch1, step2661]: loss 14.197709
[epoch1, step2662]: loss 37.323727
[epoch1, step2663]: loss 79.164749
[epoch1, step2664]: loss 67.579697
[epoch1, step2665]: loss 28.938219
[epoch1, step2666]: loss 50.889759
[epoch1, step2667]: loss 30.564062
[epoch1, step2668]: loss 75.768364
[epoch1, step2669]: loss 15.029628
[epoch1, step2670]: loss 59.862602
[epoch1, step2671]: loss 25.030773
[epoch1, step2672]: loss 15.243334
[epoch1, step2673]: loss 19.834600
[epoch1, step2674]: loss 51.247398
[epoch1, step2675]: loss 10.529791
[epoch1, step2676]: loss 38.105232
[epoch1, step2677]: loss 27.439825
[epoch1, step2678]: loss 9.327699
[epoch1, step2679]: loss 44.030109
[epoch1, step2680]: loss 11.628445
[epoch1, step2681]: loss 12.034886
[epoch1, step2682]: loss 23.344494
[epoch1, step2683]: loss 55.865280
[epoch1, step2684]: loss 13.421238
[epoch1, step2685]: loss 16.506908
[epoch1, step2686]: loss 25.619867
[epoch1, step2687]: loss 30.764425
[epoch1, step2688]: loss 71.895782
[epoch1, step2689]: loss 49.715618
[epoch1, step2690]: loss 41.454849
[epoch1, step2691]: loss 34.620785
[epoch1, step2692]: loss 49.733055
[epoch1, step2693]: loss 57.996315
[epoch1, step2694]: loss 36.315632
[epoch1, step2695]: loss 16.513456
[epoch1, step2696]: loss 15.277026
[epoch1, step2697]: loss 25.087818
[epoch1, step2698]: loss 7.885360
[epoch1, step2699]: loss 17.180958
[epoch1, step2700]: loss 12.233153
[epoch1, step2701]: loss 62.113064
[epoch1, step2702]: loss 57.727558
[epoch1, step2703]: loss 28.850933
[epoch1, step2704]: loss 21.790438
[epoch1, step2705]: loss 72.393417
[epoch1, step2706]: loss 15.789097
[epoch1, step2707]: loss 55.291656
[epoch1, step2708]: loss 10.708712
[epoch1, step2709]: loss 24.618740
[epoch1, step2710]: loss 7.063174
[epoch1, step2711]: loss 36.623047
[epoch1, step2712]: loss 36.318954
[epoch1, step2713]: loss 12.742727
[epoch1, step2714]: loss 54.024197
[epoch1, step2715]: loss 45.141796
[epoch1, step2716]: loss 28.693935
[epoch1, step2717]: loss 58.139965
[epoch1, step2718]: loss 36.716022
[epoch1, step2719]: loss 16.737663
[epoch1, step2720]: loss 67.186722
[epoch1, step2721]: loss 22.308434
[epoch1, step2722]: loss 43.674801
[epoch1, step2723]: loss 19.689651
[epoch1, step2724]: loss 37.989002
[epoch1, step2725]: loss 36.550102
[epoch1, step2726]: loss 29.783360
[epoch1, step2727]: loss 14.484265
[epoch1, step2728]: loss 26.910648
[epoch1, step2729]: loss 28.155416
[epoch1, step2730]: loss 15.226464
[epoch1, step2731]: loss 37.094044
[epoch1, step2732]: loss 28.898552
[epoch1, step2733]: loss 18.387779
[epoch1, step2734]: loss 16.709808
[epoch1, step2735]: loss 38.767006
[epoch1, step2736]: loss 48.341755
[epoch1, step2737]: loss 31.809216
[epoch1, step2738]: loss 41.349133
[epoch1, step2739]: loss 8.701325
[epoch1, step2740]: loss 17.174934
[epoch1, step2741]: loss 9.711522
[epoch1, step2742]: loss 79.396431
[epoch1, step2743]: loss 12.176397
[epoch1, step2744]: loss 43.875256
[epoch1, step2745]: loss 18.415682
[epoch1, step2746]: loss 16.893991
[epoch1, step2747]: loss 36.692223
[epoch1, step2748]: loss 51.801426
[epoch1, step2749]: loss 15.541773
[epoch1, step2750]: loss 64.198822
[epoch1, step2751]: loss 38.002182
[epoch1, step2752]: loss 17.812210
[epoch1, step2753]: loss 47.862434
[epoch1, step2754]: loss 47.674450
[epoch1, step2755]: loss 24.719315
[epoch1, step2756]: loss 16.654633
[epoch1, step2757]: loss 105.974869
[epoch1, step2758]: loss 42.228615
[epoch1, step2759]: loss 17.746319
[epoch1, step2760]: loss 31.783056
[epoch1, step2761]: loss 46.680573
[epoch1, step2762]: loss 22.343704
[epoch1, step2763]: loss 18.199343
[epoch1, step2764]: loss 44.666225
[epoch1, step2765]: loss 17.783726
[epoch1, step2766]: loss 47.289745
[epoch1, step2767]: loss 25.504183
[epoch1, step2768]: loss 40.068512
[epoch1, step2769]: loss 13.023529
[epoch1, step2770]: loss 12.443175
[epoch1, step2771]: loss 31.188576
[epoch1, step2772]: loss 15.757412
[epoch1, step2773]: loss 82.820251
[epoch1, step2774]: loss 23.490641
[epoch1, step2775]: loss 30.357048
[epoch1, step2776]: loss 14.478297
[epoch1, step2777]: loss 48.586552
[epoch1, step2778]: loss 18.706181
[epoch1, step2779]: loss 23.406441
[epoch1, step2780]: loss 39.726906
[epoch1, step2781]: loss 53.516567
[epoch1, step2782]: loss 28.368694
[epoch1, step2783]: loss 24.484371
[epoch1, step2784]: loss 7.312716
[epoch1, step2785]: loss 20.396072
[epoch1, step2786]: loss 57.254509
[epoch1, step2787]: loss 61.482613
[epoch1, step2788]: loss 54.808250
[epoch1, step2789]: loss 36.496700
[epoch1, step2790]: loss 40.839394
[epoch1, step2791]: loss 21.303017
[epoch1, step2792]: loss 8.122098
[epoch1, step2793]: loss 13.101671
[epoch1, step2794]: loss 38.728386
[epoch1, step2795]: loss 72.129715
[epoch1, step2796]: loss 59.747856
[epoch1, step2797]: loss 104.641701
[epoch1, step2798]: loss 16.430147
[epoch1, step2799]: loss 26.554062
[epoch1, step2800]: loss 28.670679
[epoch1, step2801]: loss 18.384802
[epoch1, step2802]: loss 41.368885
[epoch1, step2803]: loss 19.600300
[epoch1, step2804]: loss 31.116528
[epoch1, step2805]: loss 14.304561
[epoch1, step2806]: loss 74.005127
[epoch1, step2807]: loss 40.421207
[epoch1, step2808]: loss 53.103264
[epoch1, step2809]: loss 42.011192
[epoch1, step2810]: loss 21.869421
[epoch1, step2811]: loss 34.740040
[epoch1, step2812]: loss 16.048977
[epoch1, step2813]: loss 18.410997
[epoch1, step2814]: loss 62.742691
[epoch1, step2815]: loss 8.831211
[epoch1, step2816]: loss 17.555281
[epoch1, step2817]: loss 23.803833
[epoch1, step2818]: loss 70.041290
[epoch1, step2819]: loss 28.279257
[epoch1, step2820]: loss 13.088070
[epoch1, step2821]: loss 13.660227
[epoch1, step2822]: loss 30.412983
[epoch1, step2823]: loss 36.196877
[epoch1, step2824]: loss 12.101376
[epoch1, step2825]: loss 19.522429
[epoch1, step2826]: loss 22.179007
[epoch1, step2827]: loss 16.370621
[epoch1, step2828]: loss 25.084618
[epoch1, step2829]: loss 42.485889
[epoch1, step2830]: loss 22.630350
[epoch1, step2831]: loss 37.037678
[epoch1, step2832]: loss 58.347305
[epoch1, step2833]: loss 25.250965
[epoch1, step2834]: loss 17.694815
[epoch1, step2835]: loss 41.398315
[epoch1, step2836]: loss 32.684456
[epoch1, step2837]: loss 24.325748
[epoch1, step2838]: loss 8.998935
[epoch1, step2839]: loss 15.467665
[epoch1, step2840]: loss 18.654854
[epoch1, step2841]: loss 43.327255
[epoch1, step2842]: loss 23.236475
[epoch1, step2843]: loss 85.406601
[epoch1, step2844]: loss 27.322060
[epoch1, step2845]: loss 18.032923
[epoch1, step2846]: loss 17.345680
[epoch1, step2847]: loss 21.520645
[epoch1, step2848]: loss 52.988468
[epoch1, step2849]: loss 9.217533
[epoch1, step2850]: loss 23.721003
[epoch1, step2851]: loss 16.330475
[epoch1, step2852]: loss 16.552780
[epoch1, step2853]: loss 53.641243
[epoch1, step2854]: loss 16.128826
[epoch1, step2855]: loss 47.426117
[epoch1, step2856]: loss 23.376877
[epoch1, step2857]: loss 29.806080
[epoch1, step2858]: loss 50.717010
[epoch1, step2859]: loss 30.963005
[epoch1, step2860]: loss 51.245735
[epoch1, step2861]: loss 13.619694
[epoch1, step2862]: loss 58.357128
[epoch1, step2863]: loss 20.806011
[epoch1, step2864]: loss 64.915154
[epoch1, step2865]: loss 67.454147
[epoch1, step2866]: loss 55.239868
[epoch1, step2867]: loss 19.535875
[epoch1, step2868]: loss 78.337914
[epoch1, step2869]: loss 64.684196
[epoch1, step2870]: loss 21.957888
[epoch1, step2871]: loss 53.085625
[epoch1, step2872]: loss 38.727051
[epoch1, step2873]: loss 16.371292
[epoch1, step2874]: loss 32.035339
[epoch1, step2875]: loss 11.070427
[epoch1, step2876]: loss 10.680625
[epoch1, step2877]: loss 48.454975
[epoch1, step2878]: loss 30.976122
[epoch1, step2879]: loss 63.710251
[epoch1, step2880]: loss 30.587994
[epoch1, step2881]: loss 33.236221
[epoch1, step2882]: loss 19.701464
[epoch1, step2883]: loss 16.075771
[epoch1, step2884]: loss 62.812618
[epoch1, step2885]: loss 16.283863
[epoch1, step2886]: loss 26.747402
[epoch1, step2887]: loss 35.097649
[epoch1, step2888]: loss 36.008469
[epoch1, step2889]: loss 64.278839
[epoch1, step2890]: loss 32.194065
[epoch1, step2891]: loss 35.924545
[epoch1, step2892]: loss 18.872711
[epoch1, step2893]: loss 14.816758
[epoch1, step2894]: loss 47.123413
[epoch1, step2895]: loss 48.798225
[epoch1, step2896]: loss 5.917987
[epoch1, step2897]: loss 15.344808
[epoch1, step2898]: loss 56.510590
[epoch1, step2899]: loss 44.304668
[epoch1, step2900]: loss 21.906252
[epoch1, step2901]: loss 21.437229
[epoch1, step2902]: loss 9.115222
[epoch1, step2903]: loss 37.408455
[epoch1, step2904]: loss 11.309064
[epoch1, step2905]: loss 29.799274
[epoch1, step2906]: loss 47.802750
[epoch1, step2907]: loss 22.073219
[epoch1, step2908]: loss 36.281044
[epoch1, step2909]: loss 6.413059
[epoch1, step2910]: loss 15.065203
[epoch1, step2911]: loss 14.900047
[epoch1, step2912]: loss 39.485191
[epoch1, step2913]: loss 55.722084
[epoch1, step2914]: loss 41.401821
[epoch1, step2915]: loss 26.226856
[epoch1, step2916]: loss 39.068504
[epoch1, step2917]: loss 17.947515
[epoch1, step2918]: loss 24.745430
[epoch1, step2919]: loss 39.155365
[epoch1, step2920]: loss 8.168955
[epoch1, step2921]: loss 5.830831
[epoch1, step2922]: loss 29.251301
[epoch1, step2923]: loss 38.187405
[epoch1, step2924]: loss 79.160126
[epoch1, step2925]: loss 42.326771
[epoch1, step2926]: loss 7.057501
[epoch1, step2927]: loss 20.106007
[epoch1, step2928]: loss 27.513628
[epoch1, step2929]: loss 28.589657
[epoch1, step2930]: loss 25.741243
[epoch1, step2931]: loss 21.477993
[epoch1, step2932]: loss 73.115837
[epoch1, step2933]: loss 14.883943
[epoch1, step2934]: loss 34.217545
[epoch1, step2935]: loss 58.396610
[epoch1, step2936]: loss 17.414879
[epoch1, step2937]: loss 32.200375
[epoch1, step2938]: loss 24.822706
[epoch1, step2939]: loss 37.817474
[epoch1, step2940]: loss 33.644085
[epoch1, step2941]: loss 24.846643
[epoch1, step2942]: loss 32.028240
[epoch1, step2943]: loss 95.900902
[epoch1, step2944]: loss 27.524967
[epoch1, step2945]: loss 15.150977
[epoch1, step2946]: loss 15.582625
[epoch1, step2947]: loss 35.941719
[epoch1, step2948]: loss 24.589430
[epoch1, step2949]: loss 19.795242
[epoch1, step2950]: loss 35.363468
[epoch1, step2951]: loss 83.030739
[epoch1, step2952]: loss 18.109030
[epoch1, step2953]: loss 14.521950
[epoch1, step2954]: loss 52.133842
[epoch1, step2955]: loss 68.064835
[epoch1, step2956]: loss 27.768188
[epoch1, step2957]: loss 15.892099
[epoch1, step2958]: loss 64.858765
[epoch1, step2959]: loss 13.961187
[epoch1, step2960]: loss 9.837397
[epoch1, step2961]: loss 45.154907
[epoch1, step2962]: loss 69.993698
[epoch1, step2963]: loss 43.107323
[epoch1, step2964]: loss 63.706760
[epoch1, step2965]: loss 24.230438
[epoch1, step2966]: loss 28.532736
[epoch1, step2967]: loss 7.399331
[epoch1, step2968]: loss 51.867779
[epoch1, step2969]: loss 51.621418
[epoch1, step2970]: loss 14.479459
[epoch1, step2971]: loss 26.927462
[epoch1, step2972]: loss 60.794350
[epoch1, step2973]: loss 22.227957
[epoch1, step2974]: loss 53.050045
[epoch1, step2975]: loss 41.332260
[epoch1, step2976]: loss 8.204859
[epoch1, step2977]: loss 10.313749
[epoch1, step2978]: loss 39.363880
[epoch1, step2979]: loss 15.992322
[epoch1, step2980]: loss 63.706310
[epoch1, step2981]: loss 34.661560
[epoch1, step2982]: loss 43.636192
[epoch1, step2983]: loss 10.546547
[epoch1, step2984]: loss 20.648252
[epoch1, step2985]: loss 59.082195
[epoch1, step2986]: loss 54.301434
[epoch1, step2987]: loss 54.658920
[epoch1, step2988]: loss 25.936512
[epoch1, step2989]: loss 25.379166
[epoch1, step2990]: loss 48.085567
[epoch1, step2991]: loss 26.222263
[epoch1, step2992]: loss 40.426670
[epoch1, step2993]: loss 12.220686
[epoch1, step2994]: loss 29.850384
[epoch1, step2995]: loss 37.598824
[epoch1, step2996]: loss 19.121893
[epoch1, step2997]: loss 38.961945
[epoch1, step2998]: loss 20.249790
[epoch1, step2999]: loss 8.870918
[epoch1, step3000]: loss 10.247460
[epoch1, step3001]: loss 16.705479
[epoch1, step3002]: loss 30.315992
[epoch1, step3003]: loss 27.013113
[epoch1, step3004]: loss 37.752491
[epoch1, step3005]: loss 29.618402
[epoch1, step3006]: loss 35.719860
[epoch1, step3007]: loss 52.302345
[epoch1, step3008]: loss 54.235394
[epoch1, step3009]: loss 80.783997
[epoch1, step3010]: loss 37.843632
[epoch1, step3011]: loss 33.491714
[epoch1, step3012]: loss 20.877586
[epoch1, step3013]: loss 49.925316
[epoch1, step3014]: loss 15.135654
[epoch1, step3015]: loss 34.987522
[epoch1, step3016]: loss 18.543608
[epoch1, step3017]: loss 33.521782
[epoch1, step3018]: loss 50.720650
[epoch1, step3019]: loss 13.209424
[epoch1, step3020]: loss 42.764168
[epoch1, step3021]: loss 14.344963
[epoch1, step3022]: loss 60.308735
[epoch1, step3023]: loss 21.804554
[epoch1, step3024]: loss 10.723907
[epoch1, step3025]: loss 28.575779
[epoch1, step3026]: loss 37.869949
[epoch1, step3027]: loss 31.338966
[epoch1, step3028]: loss 66.870689
[epoch1, step3029]: loss 31.760105
[epoch1, step3030]: loss 14.882299
[epoch1, step3031]: loss 28.709137
[epoch1, step3032]: loss 6.375104
[epoch1, step3033]: loss 36.004124
[epoch1, step3034]: loss 26.861744
[epoch1, step3035]: loss 20.041382
[epoch1, step3036]: loss 18.504545
[epoch1, step3037]: loss 39.543510
[epoch1, step3038]: loss 19.861160
[epoch1, step3039]: loss 7.315903
[epoch1, step3040]: loss 29.519907
[epoch1, step3041]: loss 32.998207
[epoch1, step3042]: loss 40.773064
[epoch1, step3043]: loss 8.602658
[epoch1, step3044]: loss 33.894157
[epoch1, step3045]: loss 11.280189
[epoch1, step3046]: loss 39.144794
[epoch1, step3047]: loss 26.008629
[epoch1, step3048]: loss 25.078848
[epoch1, step3049]: loss 25.840740
[epoch1, step3050]: loss 39.231236
[epoch1, step3051]: loss 40.722263
[epoch1, step3052]: loss 18.678850
[epoch1, step3053]: loss 35.230457
[epoch1, step3054]: loss 61.090706
[epoch1, step3055]: loss 72.129089
[epoch1, step3056]: loss 12.707556
[epoch1, step3057]: loss 26.895267
[epoch1, step3058]: loss 12.791940
[epoch1, step3059]: loss 27.876949
[epoch1, step3060]: loss 20.179268
[epoch1, step3061]: loss 29.559578
[epoch1, step3062]: loss 41.174019
[epoch1, step3063]: loss 33.118851
[epoch1, step3064]: loss 12.687157
[epoch1, step3065]: loss 14.213465
[epoch1, step3066]: loss 20.891182
[epoch1, step3067]: loss 12.560543
[epoch1, step3068]: loss 30.037666
[epoch1, step3069]: loss 33.092098
[epoch1, step3070]: loss 44.580658
[epoch1, step3071]: loss 6.329407
[epoch1, step3072]: loss 20.687126
[epoch1, step3073]: loss 19.354275
[epoch1, step3074]: loss 20.447039
[epoch1, step3075]: loss 7.665704
[epoch1, step3076]: loss 39.357861

[epoch1]: avg loss 39.357861

[epoch2, step1]: loss 18.137482
[epoch2, step2]: loss 8.130642
[epoch2, step3]: loss 35.149963
[epoch2, step4]: loss 41.009857
[epoch2, step5]: loss 43.012993
[epoch2, step6]: loss 30.230577
[epoch2, step7]: loss 11.808327
[epoch2, step8]: loss 19.406853
[epoch2, step9]: loss 20.336332
[epoch2, step10]: loss 67.389191
[epoch2, step11]: loss 30.210526
[epoch2, step12]: loss 48.464386
[epoch2, step13]: loss 13.417934
[epoch2, step14]: loss 26.834230
[epoch2, step15]: loss 31.543331
[epoch2, step16]: loss 78.270111
[epoch2, step17]: loss 26.152599
[epoch2, step18]: loss 10.025766
[epoch2, step19]: loss 40.738674
[epoch2, step20]: loss 9.235756
[epoch2, step21]: loss 40.883228
[epoch2, step22]: loss 35.813400
[epoch2, step23]: loss 52.024658
[epoch2, step24]: loss 17.971470
[epoch2, step25]: loss 11.483644
[epoch2, step26]: loss 39.514191
[epoch2, step27]: loss 19.419395
[epoch2, step28]: loss 70.283234
[epoch2, step29]: loss 7.173213
[epoch2, step30]: loss 12.618341
[epoch2, step31]: loss 15.569988
[epoch2, step32]: loss 41.849533
[epoch2, step33]: loss 14.961149
[epoch2, step34]: loss 17.435869
[epoch2, step35]: loss 62.644482
[epoch2, step36]: loss 22.669992
[epoch2, step37]: loss 31.175661
[epoch2, step38]: loss 13.196004
[epoch2, step39]: loss 9.148779
[epoch2, step40]: loss 13.130820
[epoch2, step41]: loss 43.030529
[epoch2, step42]: loss 65.529602
[epoch2, step43]: loss 41.936981
[epoch2, step44]: loss 47.949364
[epoch2, step45]: loss 69.890976
[epoch2, step46]: loss 67.956406
[epoch2, step47]: loss 26.050562
[epoch2, step48]: loss 6.844441
[epoch2, step49]: loss 37.565994
[epoch2, step50]: loss 43.198212
[epoch2, step51]: loss 24.172600
[epoch2, step52]: loss 30.393650
[epoch2, step53]: loss 48.023609
[epoch2, step54]: loss 65.782730
[epoch2, step55]: loss 21.352854
[epoch2, step56]: loss 27.955681
[epoch2, step57]: loss 14.870420
[epoch2, step58]: loss 31.453720
[epoch2, step59]: loss 43.363518
[epoch2, step60]: loss 23.806572
[epoch2, step61]: loss 13.402658
[epoch2, step62]: loss 7.269582
[epoch2, step63]: loss 10.507228
[epoch2, step64]: loss 15.210934
[epoch2, step65]: loss 9.697824
[epoch2, step66]: loss 9.680147
[epoch2, step67]: loss 11.488683
[epoch2, step68]: loss 47.585445
[epoch2, step69]: loss 39.303314
[epoch2, step70]: loss 22.934847
[epoch2, step71]: loss 6.028299
[epoch2, step72]: loss 39.771004
[epoch2, step73]: loss 25.331491
[epoch2, step74]: loss 40.851036
[epoch2, step75]: loss 33.744617
[epoch2, step76]: loss 25.684208
[epoch2, step77]: loss 18.112011
[epoch2, step78]: loss 14.585240
[epoch2, step79]: loss 14.255930
[epoch2, step80]: loss 21.120672
[epoch2, step81]: loss 15.187037
[epoch2, step82]: loss 11.508461
[epoch2, step83]: loss 55.714859
[epoch2, step84]: loss 22.393139
[epoch2, step85]: loss 11.091120
[epoch2, step86]: loss 28.555647
[epoch2, step87]: loss 11.263919
[epoch2, step88]: loss 36.143005
[epoch2, step89]: loss 64.976341
[epoch2, step90]: loss 36.138355
[epoch2, step91]: loss 17.708342
[epoch2, step92]: loss 13.577427
[epoch2, step93]: loss 33.487930
[epoch2, step94]: loss 25.956236
[epoch2, step95]: loss 18.818542
[epoch2, step96]: loss 23.724684
[epoch2, step97]: loss 19.338999
[epoch2, step98]: loss 44.603722
[epoch2, step99]: loss 35.011169
[epoch2, step100]: loss 26.644279
[epoch2, step101]: loss 9.787255
[epoch2, step102]: loss 33.134541
[epoch2, step103]: loss 69.501656
[epoch2, step104]: loss 14.813549
[epoch2, step105]: loss 29.722897
[epoch2, step106]: loss 50.375717
[epoch2, step107]: loss 13.894154
[epoch2, step108]: loss 24.273952
[epoch2, step109]: loss 19.549868
[epoch2, step110]: loss 42.628456
[epoch2, step111]: loss 34.108185
[epoch2, step112]: loss 37.006924
[epoch2, step113]: loss 45.805557
[epoch2, step114]: loss 28.169149
[epoch2, step115]: loss 9.704294
[epoch2, step116]: loss 29.270819
[epoch2, step117]: loss 24.387192
[epoch2, step118]: loss 48.247318
[epoch2, step119]: loss 19.784464
[epoch2, step120]: loss 12.392975
[epoch2, step121]: loss 16.602505
[epoch2, step122]: loss 37.228279
[epoch2, step123]: loss 21.806698
[epoch2, step124]: loss 38.548645
[epoch2, step125]: loss 77.594391
[epoch2, step126]: loss 16.852602
[epoch2, step127]: loss 45.893032
[epoch2, step128]: loss 50.742153
[epoch2, step129]: loss 63.072334
[epoch2, step130]: loss 6.611825
[epoch2, step131]: loss 7.733919
[epoch2, step132]: loss 23.941628
[epoch2, step133]: loss 16.780706
[epoch2, step134]: loss 42.687866
[epoch2, step135]: loss 24.894188
[epoch2, step136]: loss 35.224342
[epoch2, step137]: loss 14.456586
[epoch2, step138]: loss 42.554756
[epoch2, step139]: loss 54.418930
[epoch2, step140]: loss 29.676939
[epoch2, step141]: loss 56.315819
[epoch2, step142]: loss 10.682967
[epoch2, step143]: loss 31.362801
[epoch2, step144]: loss 72.057663
[epoch2, step145]: loss 49.904846
[epoch2, step146]: loss 9.989166
[epoch2, step147]: loss 26.741844
[epoch2, step148]: loss 7.338855
[epoch2, step149]: loss 8.549243
[epoch2, step150]: loss 25.643946
[epoch2, step151]: loss 15.681642
[epoch2, step152]: loss 19.565487
[epoch2, step153]: loss 11.430704
[epoch2, step154]: loss 41.509365
[epoch2, step155]: loss 44.600235
[epoch2, step156]: loss 15.325994
[epoch2, step157]: loss 7.744026
[epoch2, step158]: loss 39.279026
[epoch2, step159]: loss 18.897234
[epoch2, step160]: loss 31.457687
[epoch2, step161]: loss 12.851744
[epoch2, step162]: loss 22.235765
[epoch2, step163]: loss 27.711538
[epoch2, step164]: loss 43.548218
[epoch2, step165]: loss 40.106514
[epoch2, step166]: loss 11.991695
[epoch2, step167]: loss 50.014168
[epoch2, step168]: loss 42.603241
[epoch2, step169]: loss 4.245759
[epoch2, step170]: loss 23.359581
[epoch2, step171]: loss 42.838852
[epoch2, step172]: loss 11.262280
[epoch2, step173]: loss 28.669270
[epoch2, step174]: loss 12.634670
[epoch2, step175]: loss 14.102125
[epoch2, step176]: loss 24.925385
[epoch2, step177]: loss 10.547931
[epoch2, step178]: loss 26.349939
[epoch2, step179]: loss 12.256423
[epoch2, step180]: loss 35.887905
[epoch2, step181]: loss 17.664349
[epoch2, step182]: loss 34.151665
[epoch2, step183]: loss 34.076538
[epoch2, step184]: loss 68.479950
[epoch2, step185]: loss 19.818287
[epoch2, step186]: loss 23.033558
[epoch2, step187]: loss 43.489902
[epoch2, step188]: loss 39.019821
[epoch2, step189]: loss 15.972002
[epoch2, step190]: loss 22.656803
[epoch2, step191]: loss 45.791973
[epoch2, step192]: loss 21.919813
[epoch2, step193]: loss 20.317106
[epoch2, step194]: loss 46.224632
[epoch2, step195]: loss 25.117510
[epoch2, step196]: loss 29.658916
[epoch2, step197]: loss 21.853649
[epoch2, step198]: loss 21.654095
[epoch2, step199]: loss 46.672192
[epoch2, step200]: loss 9.874021
[epoch2, step201]: loss 14.060544
[epoch2, step202]: loss 15.490441
[epoch2, step203]: loss 16.003965
[epoch2, step204]: loss 8.597932
[epoch2, step205]: loss 14.560274
[epoch2, step206]: loss 43.807571
[epoch2, step207]: loss 10.058025
[epoch2, step208]: loss 10.197891
[epoch2, step209]: loss 15.149405
[epoch2, step210]: loss 17.738571
[epoch2, step211]: loss 10.834846
[epoch2, step212]: loss 5.208241
[epoch2, step213]: loss 6.601404
[epoch2, step214]: loss 33.973774
[epoch2, step215]: loss 27.944742
[epoch2, step216]: loss 44.940857
[epoch2, step217]: loss 17.918842
[epoch2, step218]: loss 46.323387
[epoch2, step219]: loss 16.863562
[epoch2, step220]: loss 13.252708
[epoch2, step221]: loss 17.972956
[epoch2, step222]: loss 15.898745
[epoch2, step223]: loss 40.245972
[epoch2, step224]: loss 26.316370
[epoch2, step225]: loss 17.753288
[epoch2, step226]: loss 19.572840
[epoch2, step227]: loss 12.739349
[epoch2, step228]: loss 20.994671
[epoch2, step229]: loss 20.387913
[epoch2, step230]: loss 56.687447
[epoch2, step231]: loss 31.925220
[epoch2, step232]: loss 12.645157
[epoch2, step233]: loss 9.567023
[epoch2, step234]: loss 26.983088
[epoch2, step235]: loss 46.900074
[epoch2, step236]: loss 36.819077
[epoch2, step237]: loss 30.428421
[epoch2, step238]: loss 12.655834
[epoch2, step239]: loss 67.814270
[epoch2, step240]: loss 39.855476
[epoch2, step241]: loss 9.574717
[epoch2, step242]: loss 21.071018
[epoch2, step243]: loss 53.980270
[epoch2, step244]: loss 42.832336
[epoch2, step245]: loss 19.360783
[epoch2, step246]: loss 32.452324
[epoch2, step247]: loss 32.684319
[epoch2, step248]: loss 27.927731
[epoch2, step249]: loss 47.106930
[epoch2, step250]: loss 20.005802
[epoch2, step251]: loss 13.880309
[epoch2, step252]: loss 58.990753
[epoch2, step253]: loss 30.781536
[epoch2, step254]: loss 15.388038
[epoch2, step255]: loss 20.142067
[epoch2, step256]: loss 57.567841
[epoch2, step257]: loss 26.154613
[epoch2, step258]: loss 24.518932
[epoch2, step259]: loss 18.884411
[epoch2, step260]: loss 37.342411
[epoch2, step261]: loss 14.159447
[epoch2, step262]: loss 24.484856
[epoch2, step263]: loss 17.788612
[epoch2, step264]: loss 39.609581
[epoch2, step265]: loss 19.290623
[epoch2, step266]: loss 18.421783
[epoch2, step267]: loss 19.666557
[epoch2, step268]: loss 16.404226
[epoch2, step269]: loss 26.009027
[epoch2, step270]: loss 34.398300
[epoch2, step271]: loss 68.485809
[epoch2, step272]: loss 21.290829
[epoch2, step273]: loss 17.408115
[epoch2, step274]: loss 12.899507
[epoch2, step275]: loss 24.541477
[epoch2, step276]: loss 19.428663
[epoch2, step277]: loss 24.342785
[epoch2, step278]: loss 9.002382
[epoch2, step279]: loss 16.669548
[epoch2, step280]: loss 16.948092
[epoch2, step281]: loss 35.096916
[epoch2, step282]: loss 7.539692
[epoch2, step283]: loss 29.132177
[epoch2, step284]: loss 34.739471
[epoch2, step285]: loss 15.244070
[epoch2, step286]: loss 10.575972
[epoch2, step287]: loss 62.657776
[epoch2, step288]: loss 32.436214
[epoch2, step289]: loss 38.149715
[epoch2, step290]: loss 21.431343
[epoch2, step291]: loss 62.544594
[epoch2, step292]: loss 13.255141
[epoch2, step293]: loss 68.347359
[epoch2, step294]: loss 11.842815
[epoch2, step295]: loss 31.201843
[epoch2, step296]: loss 25.210524
[epoch2, step297]: loss 33.191654
[epoch2, step298]: loss 15.135571
[epoch2, step299]: loss 80.043716
[epoch2, step300]: loss 8.193751
[epoch2, step301]: loss 12.660834
[epoch2, step302]: loss 22.637701
[epoch2, step303]: loss 12.188879
[epoch2, step304]: loss 53.802635
[epoch2, step305]: loss 24.668724
[epoch2, step306]: loss 12.410946
[epoch2, step307]: loss 57.723347
[epoch2, step308]: loss 11.612692
[epoch2, step309]: loss 31.262072
[epoch2, step310]: loss 8.747217
[epoch2, step311]: loss 28.053173
[epoch2, step312]: loss 25.946976
[epoch2, step313]: loss 81.994675
[epoch2, step314]: loss 24.965450
[epoch2, step315]: loss 13.075484
[epoch2, step316]: loss 16.518360
[epoch2, step317]: loss 61.550072
[epoch2, step318]: loss 11.847822
[epoch2, step319]: loss 19.788059
[epoch2, step320]: loss 20.597702
[epoch2, step321]: loss 13.951962
[epoch2, step322]: loss 40.867516
[epoch2, step323]: loss 29.781681
[epoch2, step324]: loss 29.180279
[epoch2, step325]: loss 44.651196
[epoch2, step326]: loss 6.478096
[epoch2, step327]: loss 38.525890
[epoch2, step328]: loss 37.035950
[epoch2, step329]: loss 40.994133
[epoch2, step330]: loss 29.143566
[epoch2, step331]: loss 42.126083
[epoch2, step332]: loss 15.596199
[epoch2, step333]: loss 9.686770
[epoch2, step334]: loss 40.710194
[epoch2, step335]: loss 6.474356
[epoch2, step336]: loss 24.995131
[epoch2, step337]: loss 20.756922
[epoch2, step338]: loss 33.488125
[epoch2, step339]: loss 23.008366
[epoch2, step340]: loss 52.689827
[epoch2, step341]: loss 23.202608
[epoch2, step342]: loss 14.233147
[epoch2, step343]: loss 18.889301
[epoch2, step344]: loss 10.675304
[epoch2, step345]: loss 42.495438
[epoch2, step346]: loss 36.861801
[epoch2, step347]: loss 18.138033
[epoch2, step348]: loss 35.019897
[epoch2, step349]: loss 31.219931
[epoch2, step350]: loss 85.617950
[epoch2, step351]: loss 47.434196
[epoch2, step352]: loss 14.191441
[epoch2, step353]: loss 18.017559
[epoch2, step354]: loss 17.543095
[epoch2, step355]: loss 44.205978
[epoch2, step356]: loss 62.830566
[epoch2, step357]: loss 31.376698
[epoch2, step358]: loss 17.685759
[epoch2, step359]: loss 14.917963
[epoch2, step360]: loss 43.768089
[epoch2, step361]: loss 8.499199
[epoch2, step362]: loss 22.096933
[epoch2, step363]: loss 31.277836
[epoch2, step364]: loss 17.856213
[epoch2, step365]: loss 27.870260
[epoch2, step366]: loss 10.774086
[epoch2, step367]: loss 32.749432
[epoch2, step368]: loss 19.837524
[epoch2, step369]: loss 7.092965
[epoch2, step370]: loss 63.207245
[epoch2, step371]: loss 31.304249
[epoch2, step372]: loss 14.492747
[epoch2, step373]: loss 46.379795
[epoch2, step374]: loss 49.127357
[epoch2, step375]: loss 18.946865
[epoch2, step376]: loss 11.664187
[epoch2, step377]: loss 29.645548
[epoch2, step378]: loss 9.944125
[epoch2, step379]: loss 5.140959
[epoch2, step380]: loss 58.410194
[epoch2, step381]: loss 25.422703
[epoch2, step382]: loss 42.851429
[epoch2, step383]: loss 13.855235
[epoch2, step384]: loss 35.204144
[epoch2, step385]: loss 8.930235
[epoch2, step386]: loss 35.977348
[epoch2, step387]: loss 10.686968
[epoch2, step388]: loss 56.407871
[epoch2, step389]: loss 27.753227
[epoch2, step390]: loss 76.929115
[epoch2, step391]: loss 16.669319
[epoch2, step392]: loss 37.171776
[epoch2, step393]: loss 17.112167
[epoch2, step394]: loss 15.152752
[epoch2, step395]: loss 15.974796
[epoch2, step396]: loss 35.114990
[epoch2, step397]: loss 17.609938
[epoch2, step398]: loss 39.439072
[epoch2, step399]: loss 53.413307
[epoch2, step400]: loss 20.767546
[epoch2, step401]: loss 24.492722
[epoch2, step402]: loss 26.643030
[epoch2, step403]: loss 13.824578
[epoch2, step404]: loss 32.973534
[epoch2, step405]: loss 44.926765
[epoch2, step406]: loss 35.354073
[epoch2, step407]: loss 45.278748
[epoch2, step408]: loss 7.450856
[epoch2, step409]: loss 19.383865
[epoch2, step410]: loss 85.631760
[epoch2, step411]: loss 34.167931
[epoch2, step412]: loss 6.852549
[epoch2, step413]: loss 51.993996
[epoch2, step414]: loss 12.692020
[epoch2, step415]: loss 7.494158
[epoch2, step416]: loss 28.041145
[epoch2, step417]: loss 77.247475
[epoch2, step418]: loss 8.976251
[epoch2, step419]: loss 12.640966
[epoch2, step420]: loss 6.827224
[epoch2, step421]: loss 17.615614
[epoch2, step422]: loss 33.351799
[epoch2, step423]: loss 27.803482
[epoch2, step424]: loss 63.442291
[epoch2, step425]: loss 58.478729
[epoch2, step426]: loss 17.231663
[epoch2, step427]: loss 15.518208
[epoch2, step428]: loss 10.412365
[epoch2, step429]: loss 16.563032
[epoch2, step430]: loss 27.966785
[epoch2, step431]: loss 27.441307
[epoch2, step432]: loss 44.127285
[epoch2, step433]: loss 19.279108
[epoch2, step434]: loss 26.336624
[epoch2, step435]: loss 68.894119
[epoch2, step436]: loss 87.217834
[epoch2, step437]: loss 35.314987
[epoch2, step438]: loss 18.793051
[epoch2, step439]: loss 31.878998
[epoch2, step440]: loss 12.009472
[epoch2, step441]: loss 40.183510
[epoch2, step442]: loss 17.466043
[epoch2, step443]: loss 49.659481
[epoch2, step444]: loss 61.335701
[epoch2, step445]: loss 14.460714
[epoch2, step446]: loss 66.779083
[epoch2, step447]: loss 47.149044
[epoch2, step448]: loss 13.311190
[epoch2, step449]: loss 26.147335
[epoch2, step450]: loss 35.807907
[epoch2, step451]: loss 10.516399
[epoch2, step452]: loss 20.816204
[epoch2, step453]: loss 57.701275
[epoch2, step454]: loss 20.792887
[epoch2, step455]: loss 8.096478
[epoch2, step456]: loss 41.581936
[epoch2, step457]: loss 14.146806
[epoch2, step458]: loss 36.949451
[epoch2, step459]: loss 59.398632
[epoch2, step460]: loss 15.036571
[epoch2, step461]: loss 25.082212
[epoch2, step462]: loss 15.167411
[epoch2, step463]: loss 11.036012
[epoch2, step464]: loss 18.262054
[epoch2, step465]: loss 19.445927
[epoch2, step466]: loss 19.926510
[epoch2, step467]: loss 28.788210
[epoch2, step468]: loss 28.688663
[epoch2, step469]: loss 10.172251
[epoch2, step470]: loss 34.916233
[epoch2, step471]: loss 29.424746
[epoch2, step472]: loss 45.668060
[epoch2, step473]: loss 11.451063
[epoch2, step474]: loss 33.782982
[epoch2, step475]: loss 46.031509
[epoch2, step476]: loss 24.262161
[epoch2, step477]: loss 21.890617
[epoch2, step478]: loss 12.279144
[epoch2, step479]: loss 33.345253
[epoch2, step480]: loss 26.682346
[epoch2, step481]: loss 55.082577
[epoch2, step482]: loss 33.471107
[epoch2, step483]: loss 38.278584
[epoch2, step484]: loss 23.263790
[epoch2, step485]: loss 12.329586
[epoch2, step486]: loss 44.812424
[epoch2, step487]: loss 23.072477
[epoch2, step488]: loss 26.778685
[epoch2, step489]: loss 36.063457
[epoch2, step490]: loss 66.475571
[epoch2, step491]: loss 38.313141
[epoch2, step492]: loss 45.602959
[epoch2, step493]: loss 21.733376
[epoch2, step494]: loss 26.703897
[epoch2, step495]: loss 15.199279
[epoch2, step496]: loss 44.228893
[epoch2, step497]: loss 17.218342
[epoch2, step498]: loss 35.608315
[epoch2, step499]: loss 13.552561
[epoch2, step500]: loss 40.247326
[epoch2, step501]: loss 6.672602
[epoch2, step502]: loss 28.433186
[epoch2, step503]: loss 10.203444
[epoch2, step504]: loss 9.282667
[epoch2, step505]: loss 19.338959
[epoch2, step506]: loss 18.473278
[epoch2, step507]: loss 16.979965
[epoch2, step508]: loss 35.617733
[epoch2, step509]: loss 23.331026
[epoch2, step510]: loss 19.757261
[epoch2, step511]: loss 44.133247
[epoch2, step512]: loss 4.636113
[epoch2, step513]: loss 85.085106
[epoch2, step514]: loss 40.766018
[epoch2, step515]: loss 8.204706
[epoch2, step516]: loss 57.691113
[epoch2, step517]: loss 32.147430
[epoch2, step518]: loss 39.251385
[epoch2, step519]: loss 13.755462
[epoch2, step520]: loss 39.952141
[epoch2, step521]: loss 15.964629
[epoch2, step522]: loss 13.813649
[epoch2, step523]: loss 43.880535
[epoch2, step524]: loss 25.125340
[epoch2, step525]: loss 50.384079
[epoch2, step526]: loss 18.704576
[epoch2, step527]: loss 18.324957
[epoch2, step528]: loss 13.678421
[epoch2, step529]: loss 19.074783
[epoch2, step530]: loss 4.601485
[epoch2, step531]: loss 9.313742
[epoch2, step532]: loss 5.590594
[epoch2, step533]: loss 39.784626
[epoch2, step534]: loss 53.298019
[epoch2, step535]: loss 49.794720
[epoch2, step536]: loss 8.503573
[epoch2, step537]: loss 21.292192
[epoch2, step538]: loss 14.589893
[epoch2, step539]: loss 32.890667
[epoch2, step540]: loss 13.780918
[epoch2, step541]: loss 42.403763
[epoch2, step542]: loss 36.876003
[epoch2, step543]: loss 11.738141
[epoch2, step544]: loss 36.890362
[epoch2, step545]: loss 20.153112
[epoch2, step546]: loss 26.040628
[epoch2, step547]: loss 14.121894
[epoch2, step548]: loss 42.405060
[epoch2, step549]: loss 12.082304
[epoch2, step550]: loss 39.363487
[epoch2, step551]: loss 41.029156
[epoch2, step552]: loss 15.329110
[epoch2, step553]: loss 34.760368
[epoch2, step554]: loss 6.459105
[epoch2, step555]: loss 55.284073
[epoch2, step556]: loss 38.156433
[epoch2, step557]: loss 10.119086
[epoch2, step558]: loss 18.190617
[epoch2, step559]: loss 17.480791
[epoch2, step560]: loss 52.771946
[epoch2, step561]: loss 16.270639
[epoch2, step562]: loss 10.158485
[epoch2, step563]: loss 41.035065
[epoch2, step564]: loss 13.490095
[epoch2, step565]: loss 46.083767
[epoch2, step566]: loss 9.870841
[epoch2, step567]: loss 21.493553
[epoch2, step568]: loss 34.202156
[epoch2, step569]: loss 20.610470
[epoch2, step570]: loss 10.582385
[epoch2, step571]: loss 14.408562
[epoch2, step572]: loss 33.341599
[epoch2, step573]: loss 72.119308
[epoch2, step574]: loss 21.109983
[epoch2, step575]: loss 18.649370
[epoch2, step576]: loss 14.092733
[epoch2, step577]: loss 18.233107
[epoch2, step578]: loss 12.689228
[epoch2, step579]: loss 19.217356
[epoch2, step580]: loss 7.399006
[epoch2, step581]: loss 37.242622
[epoch2, step582]: loss 63.607677
[epoch2, step583]: loss 13.978960
[epoch2, step584]: loss 21.652262
[epoch2, step585]: loss 28.502964
[epoch2, step586]: loss 22.793863
[epoch2, step587]: loss 41.132870
[epoch2, step588]: loss 15.462502
[epoch2, step589]: loss 17.442806
[epoch2, step590]: loss 12.477634
[epoch2, step591]: loss 18.735596
[epoch2, step592]: loss 19.066338
[epoch2, step593]: loss 37.466064
[epoch2, step594]: loss 11.835823
[epoch2, step595]: loss 12.972374
[epoch2, step596]: loss 27.659824
[epoch2, step597]: loss 13.985649
[epoch2, step598]: loss 34.474941
[epoch2, step599]: loss 18.675627
[epoch2, step600]: loss 33.028133
[epoch2, step601]: loss 42.374172
[epoch2, step602]: loss 13.982824
[epoch2, step603]: loss 16.478064
[epoch2, step604]: loss 12.594343
[epoch2, step605]: loss 20.198259
[epoch2, step606]: loss 30.409710
[epoch2, step607]: loss 32.053185
[epoch2, step608]: loss 33.020401
[epoch2, step609]: loss 18.114677
[epoch2, step610]: loss 35.889664
[epoch2, step611]: loss 13.381456
[epoch2, step612]: loss 18.259457
[epoch2, step613]: loss 43.553303
[epoch2, step614]: loss 33.552647
[epoch2, step615]: loss 18.938869
[epoch2, step616]: loss 20.905102
[epoch2, step617]: loss 28.140957
[epoch2, step618]: loss 11.907547
[epoch2, step619]: loss 37.318275
[epoch2, step620]: loss 13.091180
[epoch2, step621]: loss 76.996841
[epoch2, step622]: loss 9.259542
[epoch2, step623]: loss 11.497148
[epoch2, step624]: loss 18.210114
[epoch2, step625]: loss 29.899527
[epoch2, step626]: loss 8.410036
[epoch2, step627]: loss 28.750013
[epoch2, step628]: loss 18.650202
[epoch2, step629]: loss 13.092042
[epoch2, step630]: loss 12.315853
[epoch2, step631]: loss 26.948374
[epoch2, step632]: loss 12.802286
[epoch2, step633]: loss 23.002533
[epoch2, step634]: loss 13.691332
[epoch2, step635]: loss 40.986210
[epoch2, step636]: loss 20.772551
[epoch2, step637]: loss 36.886723
[epoch2, step638]: loss 15.897563
[epoch2, step639]: loss 52.857094
[epoch2, step640]: loss 45.340988
[epoch2, step641]: loss 18.725584
[epoch2, step642]: loss 26.729670
[epoch2, step643]: loss 25.955025
[epoch2, step644]: loss 32.072346
[epoch2, step645]: loss 75.758377
[epoch2, step646]: loss 31.405787
[epoch2, step647]: loss 27.650890
[epoch2, step648]: loss 12.798592
[epoch2, step649]: loss 20.716078
[epoch2, step650]: loss 18.476051
[epoch2, step651]: loss 26.975197
[epoch2, step652]: loss 27.447012
[epoch2, step653]: loss 13.790255
[epoch2, step654]: loss 11.804777
[epoch2, step655]: loss 29.174374
[epoch2, step656]: loss 46.387669
[epoch2, step657]: loss 33.959190
[epoch2, step658]: loss 33.309509
[epoch2, step659]: loss 27.814108
[epoch2, step660]: loss 11.205170
[epoch2, step661]: loss 16.448307
[epoch2, step662]: loss 12.684107
[epoch2, step663]: loss 15.555365
[epoch2, step664]: loss 14.314360
[epoch2, step665]: loss 13.147224
[epoch2, step666]: loss 47.904297
[epoch2, step667]: loss 43.579689
[epoch2, step668]: loss 46.846390
[epoch2, step669]: loss 24.143286
[epoch2, step670]: loss 51.207172
[epoch2, step671]: loss 4.620063
[epoch2, step672]: loss 42.435860
[epoch2, step673]: loss 46.330814
[epoch2, step674]: loss 29.758392
[epoch2, step675]: loss 10.833705
[epoch2, step676]: loss 22.537041
[epoch2, step677]: loss 61.267612
[epoch2, step678]: loss 17.887129
[epoch2, step679]: loss 49.273525
[epoch2, step680]: loss 22.824703
[epoch2, step681]: loss 26.697239
[epoch2, step682]: loss 9.978605
[epoch2, step683]: loss 21.419722
[epoch2, step684]: loss 11.177027
[epoch2, step685]: loss 34.592388
[epoch2, step686]: loss 18.488863
[epoch2, step687]: loss 13.915878
[epoch2, step688]: loss 17.651577
[epoch2, step689]: loss 14.427449
[epoch2, step690]: loss 31.876850
[epoch2, step691]: loss 52.871174
[epoch2, step692]: loss 105.257828
[epoch2, step693]: loss 39.293274
[epoch2, step694]: loss 36.543591
[epoch2, step695]: loss 7.758477
[epoch2, step696]: loss 7.384653
[epoch2, step697]: loss 14.591990
[epoch2, step698]: loss 41.339714
[epoch2, step699]: loss 45.818317
[epoch2, step700]: loss 82.140900
[epoch2, step701]: loss 6.023968
[epoch2, step702]: loss 18.497309
[epoch2, step703]: loss 21.514191
[epoch2, step704]: loss 17.334753
[epoch2, step705]: loss 20.150526
[epoch2, step706]: loss 10.162869
[epoch2, step707]: loss 29.246950
[epoch2, step708]: loss 14.678280
[epoch2, step709]: loss 9.498029
[epoch2, step710]: loss 38.634598
[epoch2, step711]: loss 28.905090
[epoch2, step712]: loss 10.601334
[epoch2, step713]: loss 42.571857
[epoch2, step714]: loss 13.283278
[epoch2, step715]: loss 51.826595
[epoch2, step716]: loss 34.074493
[epoch2, step717]: loss 29.087978
[epoch2, step718]: loss 10.163570
[epoch2, step719]: loss 8.172610
[epoch2, step720]: loss 17.527126
[epoch2, step721]: loss 42.456070
[epoch2, step722]: loss 32.955475
[epoch2, step723]: loss 29.349354
[epoch2, step724]: loss 23.385679
[epoch2, step725]: loss 6.783664
[epoch2, step726]: loss 9.523162
[epoch2, step727]: loss 7.145416
[epoch2, step728]: loss 10.909434
[epoch2, step729]: loss 31.865143
[epoch2, step730]: loss 25.784622
[epoch2, step731]: loss 16.794916
[epoch2, step732]: loss 72.824753
[epoch2, step733]: loss 12.801096
[epoch2, step734]: loss 11.000317
[epoch2, step735]: loss 32.108482
[epoch2, step736]: loss 51.106678
[epoch2, step737]: loss 8.829431
[epoch2, step738]: loss 17.138107
[epoch2, step739]: loss 23.882725
[epoch2, step740]: loss 32.199860
[epoch2, step741]: loss 30.493214
[epoch2, step742]: loss 21.884459
[epoch2, step743]: loss 31.526310
[epoch2, step744]: loss 15.590628
[epoch2, step745]: loss 25.413914
[epoch2, step746]: loss 53.213512
[epoch2, step747]: loss 83.952072
[epoch2, step748]: loss 19.022558
[epoch2, step749]: loss 13.887674
[epoch2, step750]: loss 82.637611
[epoch2, step751]: loss 10.971902
[epoch2, step752]: loss 41.791431
[epoch2, step753]: loss 60.178047
[epoch2, step754]: loss 8.915211
[epoch2, step755]: loss 45.951450
[epoch2, step756]: loss 33.853065
[epoch2, step757]: loss 18.228348
[epoch2, step758]: loss 13.208284
[epoch2, step759]: loss 10.350165
[epoch2, step760]: loss 20.014776
[epoch2, step761]: loss 12.887582
[epoch2, step762]: loss 8.754132
[epoch2, step763]: loss 49.219231
[epoch2, step764]: loss 34.146023
[epoch2, step765]: loss 22.210739
[epoch2, step766]: loss 14.247478
[epoch2, step767]: loss 21.659033
[epoch2, step768]: loss 22.788750
[epoch2, step769]: loss 33.911388
[epoch2, step770]: loss 19.858093
[epoch2, step771]: loss 38.431923
[epoch2, step772]: loss 9.047535
[epoch2, step773]: loss 8.000991
[epoch2, step774]: loss 42.055256
[epoch2, step775]: loss 20.580441
[epoch2, step776]: loss 8.739944
[epoch2, step777]: loss 52.593018
[epoch2, step778]: loss 42.498924
[epoch2, step779]: loss 46.933380
[epoch2, step780]: loss 12.673204
[epoch2, step781]: loss 14.311495
[epoch2, step782]: loss 42.497494
[epoch2, step783]: loss 12.322690
[epoch2, step784]: loss 44.204922
[epoch2, step785]: loss 35.072800
[epoch2, step786]: loss 22.042681
[epoch2, step787]: loss 41.718876
[epoch2, step788]: loss 11.327499
[epoch2, step789]: loss 10.438823
[epoch2, step790]: loss 46.427139
[epoch2, step791]: loss 55.715309
[epoch2, step792]: loss 49.162167
[epoch2, step793]: loss 36.106300
[epoch2, step794]: loss 15.636831
[epoch2, step795]: loss 22.730984
[epoch2, step796]: loss 11.715734
[epoch2, step797]: loss 97.952545
[epoch2, step798]: loss 9.471056
[epoch2, step799]: loss 21.072929
[epoch2, step800]: loss 29.797878
[epoch2, step801]: loss 11.301153
[epoch2, step802]: loss 17.423977
[epoch2, step803]: loss 10.082490
[epoch2, step804]: loss 51.671585
[epoch2, step805]: loss 23.254133
[epoch2, step806]: loss 40.534348
[epoch2, step807]: loss 7.828566
[epoch2, step808]: loss 20.062820
[epoch2, step809]: loss 15.187910
[epoch2, step810]: loss 14.833429
[epoch2, step811]: loss 44.516247
[epoch2, step812]: loss 13.549413
[epoch2, step813]: loss 15.517343
[epoch2, step814]: loss 9.257410
[epoch2, step815]: loss 15.906755
[epoch2, step816]: loss 55.156147
[epoch2, step817]: loss 5.367627
[epoch2, step818]: loss 14.710072
[epoch2, step819]: loss 16.762222
[epoch2, step820]: loss 109.236824
[epoch2, step821]: loss 15.214368
[epoch2, step822]: loss 16.358738
[epoch2, step823]: loss 12.920666
[epoch2, step824]: loss 38.341827
[epoch2, step825]: loss 41.397217
[epoch2, step826]: loss 29.494534
[epoch2, step827]: loss 8.604166
[epoch2, step828]: loss 13.689438
[epoch2, step829]: loss 8.582447
[epoch2, step830]: loss 6.924868
[epoch2, step831]: loss 37.540066
[epoch2, step832]: loss 7.310059
[epoch2, step833]: loss 34.541588
[epoch2, step834]: loss 25.386688
[epoch2, step835]: loss 25.559689
[epoch2, step836]: loss 6.854326
[epoch2, step837]: loss 18.325764
[epoch2, step838]: loss 15.797275
[epoch2, step839]: loss 45.694607
[epoch2, step840]: loss 37.071587
[epoch2, step841]: loss 54.869972
[epoch2, step842]: loss 4.296906
[epoch2, step843]: loss 13.245981
[epoch2, step844]: loss 12.227173
[epoch2, step845]: loss 29.265486
[epoch2, step846]: loss 33.122334
[epoch2, step847]: loss 35.574253
[epoch2, step848]: loss 16.560841
[epoch2, step849]: loss 94.658302
[epoch2, step850]: loss 17.486805
[epoch2, step851]: loss 15.769547
[epoch2, step852]: loss 10.151183
[epoch2, step853]: loss 28.909889
[epoch2, step854]: loss 28.617374
[epoch2, step855]: loss 25.470776
[epoch2, step856]: loss 66.566284
[epoch2, step857]: loss 18.832586
[epoch2, step858]: loss 14.232919
[epoch2, step859]: loss 25.243843
[epoch2, step860]: loss 23.611919
[epoch2, step861]: loss 34.494022
[epoch2, step862]: loss 10.768559
[epoch2, step863]: loss 10.077971
[epoch2, step864]: loss 3.723528
[epoch2, step865]: loss 51.428047
[epoch2, step866]: loss 13.788853
[epoch2, step867]: loss 31.117331
[epoch2, step868]: loss 25.485617
[epoch2, step869]: loss 51.393459
[epoch2, step870]: loss 51.820667
[epoch2, step871]: loss 20.305008
[epoch2, step872]: loss 8.779582
[epoch2, step873]: loss 56.494164
[epoch2, step874]: loss 7.336412
[epoch2, step875]: loss 33.595825
[epoch2, step876]: loss 13.546822
[epoch2, step877]: loss 16.101736
[epoch2, step878]: loss 33.278137
[epoch2, step879]: loss 36.544151
[epoch2, step880]: loss 30.476778
[epoch2, step881]: loss 26.706467
[epoch2, step882]: loss 16.087618
[epoch2, step883]: loss 70.740387
[epoch2, step884]: loss 29.703156
[epoch2, step885]: loss 32.717323
[epoch2, step886]: loss 51.730206
[epoch2, step887]: loss 14.894281
[epoch2, step888]: loss 41.597160
[epoch2, step889]: loss 35.826267
[epoch2, step890]: loss 60.150543
[epoch2, step891]: loss 36.052872
[epoch2, step892]: loss 8.935271
[epoch2, step893]: loss 21.234140
[epoch2, step894]: loss 19.488121
[epoch2, step895]: loss 19.454994
[epoch2, step896]: loss 11.554159
[epoch2, step897]: loss 18.506790
[epoch2, step898]: loss 16.915356
[epoch2, step899]: loss 14.119670
[epoch2, step900]: loss 42.911682
[epoch2, step901]: loss 22.649565
[epoch2, step902]: loss 13.565387
[epoch2, step903]: loss 14.299825
[epoch2, step904]: loss 16.987246
[epoch2, step905]: loss 22.472887
[epoch2, step906]: loss 18.230953
[epoch2, step907]: loss 13.260937
[epoch2, step908]: loss 34.723640
[epoch2, step909]: loss 20.264248
[epoch2, step910]: loss 10.267290
[epoch2, step911]: loss 13.519825
[epoch2, step912]: loss 7.991491
[epoch2, step913]: loss 11.606897
[epoch2, step914]: loss 18.111851
[epoch2, step915]: loss 22.961781
[epoch2, step916]: loss 13.010707
[epoch2, step917]: loss 59.329903
[epoch2, step918]: loss 32.714943
[epoch2, step919]: loss 39.923187
[epoch2, step920]: loss 10.761324
[epoch2, step921]: loss 10.831761
[epoch2, step922]: loss 13.618616
[epoch2, step923]: loss 15.342074
[epoch2, step924]: loss 36.378578
[epoch2, step925]: loss 8.058661
[epoch2, step926]: loss 9.912195
[epoch2, step927]: loss 11.862407
[epoch2, step928]: loss 19.709217
[epoch2, step929]: loss 19.889658
[epoch2, step930]: loss 15.369145
[epoch2, step931]: loss 17.822853
[epoch2, step932]: loss 28.993826
[epoch2, step933]: loss 28.952877
[epoch2, step934]: loss 16.668736
[epoch2, step935]: loss 13.389092
[epoch2, step936]: loss 6.016071
[epoch2, step937]: loss 16.587076
[epoch2, step938]: loss 22.659290
[epoch2, step939]: loss 27.304192
[epoch2, step940]: loss 22.362263
[epoch2, step941]: loss 21.123030
[epoch2, step942]: loss 53.117088
[epoch2, step943]: loss 16.469328
[epoch2, step944]: loss 18.901772
[epoch2, step945]: loss 20.733860
[epoch2, step946]: loss 41.406021
[epoch2, step947]: loss 38.924950
[epoch2, step948]: loss 16.820889
[epoch2, step949]: loss 26.117332
[epoch2, step950]: loss 9.310317
[epoch2, step951]: loss 26.337385
[epoch2, step952]: loss 4.309726
[epoch2, step953]: loss 13.376036
[epoch2, step954]: loss 14.330239
[epoch2, step955]: loss 31.656687
[epoch2, step956]: loss 7.962383
[epoch2, step957]: loss 29.234627
[epoch2, step958]: loss 43.149147
[epoch2, step959]: loss 18.200317
[epoch2, step960]: loss 12.525846
[epoch2, step961]: loss 14.716862
[epoch2, step962]: loss 9.550510
[epoch2, step963]: loss 13.859011
[epoch2, step964]: loss 34.792919
[epoch2, step965]: loss 8.978994
[epoch2, step966]: loss 6.755522
[epoch2, step967]: loss 32.357864
[epoch2, step968]: loss 18.475178
[epoch2, step969]: loss 24.514467
[epoch2, step970]: loss 9.559017
[epoch2, step971]: loss 45.496555
[epoch2, step972]: loss 8.111310
[epoch2, step973]: loss 19.977680
[epoch2, step974]: loss 6.504599
[epoch2, step975]: loss 13.514773
[epoch2, step976]: loss 13.591755
[epoch2, step977]: loss 41.612061
[epoch2, step978]: loss 17.639622
[epoch2, step979]: loss 14.776996
[epoch2, step980]: loss 10.921333
[epoch2, step981]: loss 4.117452
[epoch2, step982]: loss 17.457787
[epoch2, step983]: loss 34.721050
[epoch2, step984]: loss 8.424778
[epoch2, step985]: loss 8.695251
[epoch2, step986]: loss 38.347607
[epoch2, step987]: loss 20.093191
[epoch2, step988]: loss 16.465614
[epoch2, step989]: loss 34.138817
[epoch2, step990]: loss 25.948832
[epoch2, step991]: loss 13.956985
[epoch2, step992]: loss 9.416277
[epoch2, step993]: loss 33.532017
[epoch2, step994]: loss 17.120085
[epoch2, step995]: loss 36.413300
[epoch2, step996]: loss 35.183243
[epoch2, step997]: loss 45.997143
[epoch2, step998]: loss 43.094109
[epoch2, step999]: loss 6.163483
[epoch2, step1000]: loss 15.652969
[epoch2, step1001]: loss 45.905418
[epoch2, step1002]: loss 8.726164
[epoch2, step1003]: loss 34.595184
[epoch2, step1004]: loss 17.479937
[epoch2, step1005]: loss 8.892483
[epoch2, step1006]: loss 10.882235
[epoch2, step1007]: loss 33.444027
[epoch2, step1008]: loss 12.154206
[epoch2, step1009]: loss 45.814320
[epoch2, step1010]: loss 20.921089
[epoch2, step1011]: loss 33.697247
[epoch2, step1012]: loss 32.857262
[epoch2, step1013]: loss 13.435472
[epoch2, step1014]: loss 41.085976
[epoch2, step1015]: loss 26.818066
[epoch2, step1016]: loss 14.105284
[epoch2, step1017]: loss 10.144783
[epoch2, step1018]: loss 30.342833
[epoch2, step1019]: loss 12.504916
[epoch2, step1020]: loss 33.234119
[epoch2, step1021]: loss 11.577709
[epoch2, step1022]: loss 23.332260
[epoch2, step1023]: loss 43.757683
[epoch2, step1024]: loss 6.155827
[epoch2, step1025]: loss 8.720265
[epoch2, step1026]: loss 26.265810
[epoch2, step1027]: loss 39.086376
[epoch2, step1028]: loss 31.319794
[epoch2, step1029]: loss 12.989792
[epoch2, step1030]: loss 40.765358
[epoch2, step1031]: loss 8.866008
[epoch2, step1032]: loss 6.826550
[epoch2, step1033]: loss 8.864127
[epoch2, step1034]: loss 6.899046
[epoch2, step1035]: loss 26.441792
[epoch2, step1036]: loss 18.662413
[epoch2, step1037]: loss 11.519999
[epoch2, step1038]: loss 29.340862
[epoch2, step1039]: loss 16.757906
[epoch2, step1040]: loss 9.670249
[epoch2, step1041]: loss 26.081852
[epoch2, step1042]: loss 8.762813
[epoch2, step1043]: loss 6.448580
[epoch2, step1044]: loss 31.040432
[epoch2, step1045]: loss 20.973982
[epoch2, step1046]: loss 9.447677
[epoch2, step1047]: loss 61.994244
[epoch2, step1048]: loss 7.685180
[epoch2, step1049]: loss 9.299398
[epoch2, step1050]: loss 18.186350
[epoch2, step1051]: loss 7.046548
[epoch2, step1052]: loss 19.911606
[epoch2, step1053]: loss 48.514702
[epoch2, step1054]: loss 13.374372
[epoch2, step1055]: loss 39.903713
[epoch2, step1056]: loss 32.923294
[epoch2, step1057]: loss 4.683382
[epoch2, step1058]: loss 25.913416
[epoch2, step1059]: loss 6.368325
[epoch2, step1060]: loss 66.560951
[epoch2, step1061]: loss 13.156000
[epoch2, step1062]: loss 27.061529
[epoch2, step1063]: loss 15.832250
[epoch2, step1064]: loss 11.580448
[epoch2, step1065]: loss 36.043098
[epoch2, step1066]: loss 9.140027
[epoch2, step1067]: loss 22.168652
[epoch2, step1068]: loss 38.028000
[epoch2, step1069]: loss 15.923010
[epoch2, step1070]: loss 29.739056
[epoch2, step1071]: loss 40.008553
[epoch2, step1072]: loss 26.962482
[epoch2, step1073]: loss 6.866891
[epoch2, step1074]: loss 35.573936
[epoch2, step1075]: loss 10.372197
[epoch2, step1076]: loss 10.761299
[epoch2, step1077]: loss 26.992323
[epoch2, step1078]: loss 23.421850
[epoch2, step1079]: loss 4.752614
[epoch2, step1080]: loss 11.879667
[epoch2, step1081]: loss 44.174408
[epoch2, step1082]: loss 35.029743
[epoch2, step1083]: loss 58.681541
[epoch2, step1084]: loss 44.408596
[epoch2, step1085]: loss 7.896593
[epoch2, step1086]: loss 6.435991
[epoch2, step1087]: loss 30.440014
[epoch2, step1088]: loss 9.137001
[epoch2, step1089]: loss 38.144852
[epoch2, step1090]: loss 13.165958
[epoch2, step1091]: loss 31.624786
[epoch2, step1092]: loss 36.606651
[epoch2, step1093]: loss 7.787010
[epoch2, step1094]: loss 15.245773
[epoch2, step1095]: loss 13.802992
[epoch2, step1096]: loss 19.909952
[epoch2, step1097]: loss 65.537994
[epoch2, step1098]: loss 13.335770
[epoch2, step1099]: loss 14.875171
[epoch2, step1100]: loss 14.002010
[epoch2, step1101]: loss 20.336004
[epoch2, step1102]: loss 27.230824
[epoch2, step1103]: loss 14.778685
[epoch2, step1104]: loss 30.585707
[epoch2, step1105]: loss 32.981449
[epoch2, step1106]: loss 9.778034
[epoch2, step1107]: loss 38.204483
[epoch2, step1108]: loss 43.360394
[epoch2, step1109]: loss 9.766668
[epoch2, step1110]: loss 7.516593
[epoch2, step1111]: loss 8.166554
[epoch2, step1112]: loss 8.787215
[epoch2, step1113]: loss 36.899014
[epoch2, step1114]: loss 44.865124
[epoch2, step1115]: loss 9.033793
[epoch2, step1116]: loss 34.063892
[epoch2, step1117]: loss 14.529888
[epoch2, step1118]: loss 7.246644
[epoch2, step1119]: loss 10.994955
[epoch2, step1120]: loss 6.923357
[epoch2, step1121]: loss 8.415599
[epoch2, step1122]: loss 31.349379
[epoch2, step1123]: loss 5.789557
[epoch2, step1124]: loss 11.878736
[epoch2, step1125]: loss 21.342472
[epoch2, step1126]: loss 18.184759
[epoch2, step1127]: loss 17.105028
[epoch2, step1128]: loss 30.462721
[epoch2, step1129]: loss 21.680849
[epoch2, step1130]: loss 14.325041
[epoch2, step1131]: loss 12.765799
[epoch2, step1132]: loss 14.095592
[epoch2, step1133]: loss 26.775927
[epoch2, step1134]: loss 35.240311
[epoch2, step1135]: loss 13.676689
[epoch2, step1136]: loss 23.121634
[epoch2, step1137]: loss 13.780094
[epoch2, step1138]: loss 26.127392
[epoch2, step1139]: loss 22.296497
[epoch2, step1140]: loss 14.395099
[epoch2, step1141]: loss 54.806999
[epoch2, step1142]: loss 10.985804
[epoch2, step1143]: loss 10.643797
[epoch2, step1144]: loss 41.818245
[epoch2, step1145]: loss 36.665295
[epoch2, step1146]: loss 4.947230
[epoch2, step1147]: loss 12.898007
[epoch2, step1148]: loss 10.987501
[epoch2, step1149]: loss 14.758574
[epoch2, step1150]: loss 21.267271
[epoch2, step1151]: loss 6.563801
[epoch2, step1152]: loss 23.702215
[epoch2, step1153]: loss 68.094940
[epoch2, step1154]: loss 31.628288
[epoch2, step1155]: loss 18.196308
[epoch2, step1156]: loss 39.268238
[epoch2, step1157]: loss 36.619534
[epoch2, step1158]: loss 55.207100
[epoch2, step1159]: loss 20.997385
[epoch2, step1160]: loss 7.126411
[epoch2, step1161]: loss 13.473839
[epoch2, step1162]: loss 21.307983
[epoch2, step1163]: loss 45.265747
[epoch2, step1164]: loss 26.242994
[epoch2, step1165]: loss 12.690110
[epoch2, step1166]: loss 26.636854
[epoch2, step1167]: loss 14.151720
[epoch2, step1168]: loss 35.683350
[epoch2, step1169]: loss 15.327691
[epoch2, step1170]: loss 16.864935
[epoch2, step1171]: loss 52.911968
[epoch2, step1172]: loss 53.752159
[epoch2, step1173]: loss 88.249786
[epoch2, step1174]: loss 29.718897
[epoch2, step1175]: loss 36.318935
[epoch2, step1176]: loss 14.299458
[epoch2, step1177]: loss 32.407890
[epoch2, step1178]: loss 14.936182
[epoch2, step1179]: loss 59.713799
[epoch2, step1180]: loss 38.001038
[epoch2, step1181]: loss 6.627666
[epoch2, step1182]: loss 28.487984
[epoch2, step1183]: loss 7.259606
[epoch2, step1184]: loss 31.049576
[epoch2, step1185]: loss 17.871891
[epoch2, step1186]: loss 15.363544
[epoch2, step1187]: loss 23.638302
[epoch2, step1188]: loss 51.455639
[epoch2, step1189]: loss 6.489777
[epoch2, step1190]: loss 14.612995
[epoch2, step1191]: loss 69.298050
[epoch2, step1192]: loss 34.109203
[epoch2, step1193]: loss 17.779514
[epoch2, step1194]: loss 20.796528
[epoch2, step1195]: loss 10.374934
[epoch2, step1196]: loss 17.531422
[epoch2, step1197]: loss 31.843456
[epoch2, step1198]: loss 47.257816
[epoch2, step1199]: loss 28.246758
[epoch2, step1200]: loss 6.890483
[epoch2, step1201]: loss 16.098316
[epoch2, step1202]: loss 28.123518
[epoch2, step1203]: loss 26.927269
[epoch2, step1204]: loss 23.762360
[epoch2, step1205]: loss 27.676123
[epoch2, step1206]: loss 8.112265
[epoch2, step1207]: loss 15.314309
[epoch2, step1208]: loss 48.987946
[epoch2, step1209]: loss 41.694630
[epoch2, step1210]: loss 28.110729
[epoch2, step1211]: loss 24.721483
[epoch2, step1212]: loss 21.330088
[epoch2, step1213]: loss 34.375336
[epoch2, step1214]: loss 11.624744
[epoch2, step1215]: loss 28.508701
[epoch2, step1216]: loss 9.161141
[epoch2, step1217]: loss 26.113968
[epoch2, step1218]: loss 13.452558
[epoch2, step1219]: loss 11.645943
[epoch2, step1220]: loss 13.692393
[epoch2, step1221]: loss 13.127553
[epoch2, step1222]: loss 24.388313
[epoch2, step1223]: loss 43.461540
[epoch2, step1224]: loss 16.107353
[epoch2, step1225]: loss 20.040398
[epoch2, step1226]: loss 6.768549
[epoch2, step1227]: loss 9.539287
[epoch2, step1228]: loss 14.792645
[epoch2, step1229]: loss 11.526101
[epoch2, step1230]: loss 3.317143
[epoch2, step1231]: loss 52.297264
[epoch2, step1232]: loss 39.629150
[epoch2, step1233]: loss 20.796682
[epoch2, step1234]: loss 23.616213
[epoch2, step1235]: loss 9.368910
[epoch2, step1236]: loss 5.215728
[epoch2, step1237]: loss 18.646711
[epoch2, step1238]: loss 43.741089
[epoch2, step1239]: loss 8.110612
[epoch2, step1240]: loss 8.103688
[epoch2, step1241]: loss 39.978924
[epoch2, step1242]: loss 11.981383
[epoch2, step1243]: loss 30.910782
[epoch2, step1244]: loss 36.790646
[epoch2, step1245]: loss 41.164478
[epoch2, step1246]: loss 41.352272
[epoch2, step1247]: loss 4.832021
[epoch2, step1248]: loss 19.410999
[epoch2, step1249]: loss 32.747540
[epoch2, step1250]: loss 11.697092
[epoch2, step1251]: loss 16.400948
[epoch2, step1252]: loss 22.941635
[epoch2, step1253]: loss 39.137062
[epoch2, step1254]: loss 33.880810
[epoch2, step1255]: loss 8.354612
[epoch2, step1256]: loss 7.595583
[epoch2, step1257]: loss 61.857063
[epoch2, step1258]: loss 14.398660
[epoch2, step1259]: loss 22.925268
[epoch2, step1260]: loss 22.369591
[epoch2, step1261]: loss 22.282860
[epoch2, step1262]: loss 18.185686
[epoch2, step1263]: loss 72.992790
[epoch2, step1264]: loss 34.152958
[epoch2, step1265]: loss 28.660877
[epoch2, step1266]: loss 9.059879
[epoch2, step1267]: loss 13.157996
[epoch2, step1268]: loss 17.212292
[epoch2, step1269]: loss 18.326019
[epoch2, step1270]: loss 24.616817
[epoch2, step1271]: loss 23.418636
[epoch2, step1272]: loss 9.533903
[epoch2, step1273]: loss 10.568477
[epoch2, step1274]: loss 8.142257
[epoch2, step1275]: loss 30.227718
[epoch2, step1276]: loss 13.725704
[epoch2, step1277]: loss 35.002235
[epoch2, step1278]: loss 57.682156
[epoch2, step1279]: loss 41.230190
[epoch2, step1280]: loss 17.062637
[epoch2, step1281]: loss 18.819153
[epoch2, step1282]: loss 9.427330
[epoch2, step1283]: loss 16.428411
[epoch2, step1284]: loss 15.101748
[epoch2, step1285]: loss 5.508708
[epoch2, step1286]: loss 10.574081
[epoch2, step1287]: loss 29.414612
[epoch2, step1288]: loss 52.558960
[epoch2, step1289]: loss 14.680823
[epoch2, step1290]: loss 25.969553
[epoch2, step1291]: loss 13.521124
[epoch2, step1292]: loss 11.917875
[epoch2, step1293]: loss 4.910094
[epoch2, step1294]: loss 7.817096
[epoch2, step1295]: loss 6.394575
[epoch2, step1296]: loss 5.821579
[epoch2, step1297]: loss 6.677046
[epoch2, step1298]: loss 7.211949
[epoch2, step1299]: loss 25.240891
[epoch2, step1300]: loss 6.971509
[epoch2, step1301]: loss 13.823580
[epoch2, step1302]: loss 29.128418
[epoch2, step1303]: loss 24.785545
[epoch2, step1304]: loss 43.713249
[epoch2, step1305]: loss 20.334866
[epoch2, step1306]: loss 12.022216
[epoch2, step1307]: loss 36.673824
[epoch2, step1308]: loss 13.900348
[epoch2, step1309]: loss 6.494176
[epoch2, step1310]: loss 43.584896
[epoch2, step1311]: loss 12.017517
[epoch2, step1312]: loss 14.701101
[epoch2, step1313]: loss 7.377598
[epoch2, step1314]: loss 33.157742
[epoch2, step1315]: loss 5.785553
[epoch2, step1316]: loss 31.611637
[epoch2, step1317]: loss 35.321659
[epoch2, step1318]: loss 32.237141
[epoch2, step1319]: loss 69.573784
[epoch2, step1320]: loss 24.656406
[epoch2, step1321]: loss 19.486824
[epoch2, step1322]: loss 17.218428
[epoch2, step1323]: loss 59.681122
[epoch2, step1324]: loss 13.630083
[epoch2, step1325]: loss 21.278931
[epoch2, step1326]: loss 20.380402
[epoch2, step1327]: loss 30.654564
[epoch2, step1328]: loss 50.339851
[epoch2, step1329]: loss 40.152725
[epoch2, step1330]: loss 21.596724
[epoch2, step1331]: loss 12.242606
[epoch2, step1332]: loss 55.817093
[epoch2, step1333]: loss 36.961349
[epoch2, step1334]: loss 26.774801
[epoch2, step1335]: loss 30.713507
[epoch2, step1336]: loss 25.483112
[epoch2, step1337]: loss 41.279644
[epoch2, step1338]: loss 25.530582
[epoch2, step1339]: loss 15.812011
[epoch2, step1340]: loss 15.236308
[epoch2, step1341]: loss 11.054320
[epoch2, step1342]: loss 20.478851
[epoch2, step1343]: loss 12.149460
[epoch2, step1344]: loss 6.357135
[epoch2, step1345]: loss 7.874212
[epoch2, step1346]: loss 9.608185
[epoch2, step1347]: loss 16.466564
[epoch2, step1348]: loss 36.750954
[epoch2, step1349]: loss 24.289623
[epoch2, step1350]: loss 45.687519
[epoch2, step1351]: loss 14.689089
[epoch2, step1352]: loss 27.690050
[epoch2, step1353]: loss 13.045018
[epoch2, step1354]: loss 23.337761
[epoch2, step1355]: loss 7.055423
[epoch2, step1356]: loss 4.022958
[epoch2, step1357]: loss 40.038914
[epoch2, step1358]: loss 11.579312
[epoch2, step1359]: loss 34.243450
[epoch2, step1360]: loss 21.424122
[epoch2, step1361]: loss 40.095654
[epoch2, step1362]: loss 14.819523
[epoch2, step1363]: loss 11.249249
[epoch2, step1364]: loss 38.476521
[epoch2, step1365]: loss 19.296852
[epoch2, step1366]: loss 27.362316
[epoch2, step1367]: loss 14.448841
[epoch2, step1368]: loss 30.025368
[epoch2, step1369]: loss 35.868778
[epoch2, step1370]: loss 14.517734
[epoch2, step1371]: loss 11.897334
[epoch2, step1372]: loss 10.259766
[epoch2, step1373]: loss 42.547348
[epoch2, step1374]: loss 53.657597
[epoch2, step1375]: loss 40.255215
[epoch2, step1376]: loss 16.398630
[epoch2, step1377]: loss 12.352575
[epoch2, step1378]: loss 40.179962
[epoch2, step1379]: loss 39.130589
[epoch2, step1380]: loss 9.065808
[epoch2, step1381]: loss 8.882668
[epoch2, step1382]: loss 31.849773
[epoch2, step1383]: loss 24.029488
[epoch2, step1384]: loss 33.721561
[epoch2, step1385]: loss 18.851889
[epoch2, step1386]: loss 8.963539
[epoch2, step1387]: loss 26.889523
[epoch2, step1388]: loss 25.690090
[epoch2, step1389]: loss 31.210609
[epoch2, step1390]: loss 16.130854
[epoch2, step1391]: loss 7.462118
[epoch2, step1392]: loss 11.757799
[epoch2, step1393]: loss 42.543205
[epoch2, step1394]: loss 6.497946
[epoch2, step1395]: loss 13.435741
[epoch2, step1396]: loss 7.738144
[epoch2, step1397]: loss 51.941170
[epoch2, step1398]: loss 25.864388
[epoch2, step1399]: loss 12.737883
[epoch2, step1400]: loss 27.386021
[epoch2, step1401]: loss 6.606905
[epoch2, step1402]: loss 16.380238
[epoch2, step1403]: loss 8.546593
[epoch2, step1404]: loss 11.520492
[epoch2, step1405]: loss 83.735893
[epoch2, step1406]: loss 7.917290
[epoch2, step1407]: loss 16.234991
[epoch2, step1408]: loss 53.972763
[epoch2, step1409]: loss 33.582703
[epoch2, step1410]: loss 26.088554
[epoch2, step1411]: loss 18.562855
[epoch2, step1412]: loss 29.005081
[epoch2, step1413]: loss 7.598617
[epoch2, step1414]: loss 15.670662
[epoch2, step1415]: loss 18.197601
[epoch2, step1416]: loss 29.567207
[epoch2, step1417]: loss 14.276786
[epoch2, step1418]: loss 29.653118
[epoch2, step1419]: loss 11.650690
[epoch2, step1420]: loss 16.186382
[epoch2, step1421]: loss 24.585052
[epoch2, step1422]: loss 35.598206
[epoch2, step1423]: loss 26.411560
[epoch2, step1424]: loss 7.338624
[epoch2, step1425]: loss 4.108438
[epoch2, step1426]: loss 44.787266
[epoch2, step1427]: loss 19.225279
[epoch2, step1428]: loss 47.678139
[epoch2, step1429]: loss 8.102839
[epoch2, step1430]: loss 42.411144
[epoch2, step1431]: loss 8.421947
[epoch2, step1432]: loss 44.200954
[epoch2, step1433]: loss 34.235104
[epoch2, step1434]: loss 11.067727
[epoch2, step1435]: loss 60.566673
[epoch2, step1436]: loss 13.963327
[epoch2, step1437]: loss 40.204197
[epoch2, step1438]: loss 8.522863
[epoch2, step1439]: loss 13.914948
[epoch2, step1440]: loss 9.744661
[epoch2, step1441]: loss 21.930647
[epoch2, step1442]: loss 24.364555
[epoch2, step1443]: loss 39.512478
[epoch2, step1444]: loss 10.913086
[epoch2, step1445]: loss 7.202448
[epoch2, step1446]: loss 45.149582
[epoch2, step1447]: loss 27.119318
[epoch2, step1448]: loss 36.565418
[epoch2, step1449]: loss 29.409796
[epoch2, step1450]: loss 37.947624
[epoch2, step1451]: loss 5.154860
[epoch2, step1452]: loss 13.569342
[epoch2, step1453]: loss 8.171965
[epoch2, step1454]: loss 29.546068
[epoch2, step1455]: loss 17.852983
[epoch2, step1456]: loss 8.332979
[epoch2, step1457]: loss 70.734726
[epoch2, step1458]: loss 56.479065
[epoch2, step1459]: loss 61.007233
[epoch2, step1460]: loss 25.436317
[epoch2, step1461]: loss 12.224363
[epoch2, step1462]: loss 51.927303
[epoch2, step1463]: loss 10.927321
[epoch2, step1464]: loss 44.557396
[epoch2, step1465]: loss 6.402189
[epoch2, step1466]: loss 4.383277
[epoch2, step1467]: loss 52.161793
[epoch2, step1468]: loss 91.613747
[epoch2, step1469]: loss 7.862023
[epoch2, step1470]: loss 11.710993
[epoch2, step1471]: loss 12.160894
[epoch2, step1472]: loss 8.595900
[epoch2, step1473]: loss 24.969299
[epoch2, step1474]: loss 43.419155
[epoch2, step1475]: loss 29.911432
[epoch2, step1476]: loss 47.738491
[epoch2, step1477]: loss 23.073524
[epoch2, step1478]: loss 35.798889
[epoch2, step1479]: loss 54.443512
[epoch2, step1480]: loss 8.976866
[epoch2, step1481]: loss 65.413727
[epoch2, step1482]: loss 9.692297
[epoch2, step1483]: loss 11.020370
[epoch2, step1484]: loss 9.481594
[epoch2, step1485]: loss 15.338899
[epoch2, step1486]: loss 22.350843
[epoch2, step1487]: loss 6.661623
[epoch2, step1488]: loss 10.770144
[epoch2, step1489]: loss 9.288260
[epoch2, step1490]: loss 72.674492
[epoch2, step1491]: loss 21.149891
[epoch2, step1492]: loss 31.139767
[epoch2, step1493]: loss 21.843204
[epoch2, step1494]: loss 4.399759
[epoch2, step1495]: loss 4.726498
[epoch2, step1496]: loss 34.993912
[epoch2, step1497]: loss 14.730250
[epoch2, step1498]: loss 18.385031
[epoch2, step1499]: loss 47.011848
[epoch2, step1500]: loss 29.157972
[epoch2, step1501]: loss 21.399620
[epoch2, step1502]: loss 53.851788
[epoch2, step1503]: loss 7.470455
[epoch2, step1504]: loss 8.705739
[epoch2, step1505]: loss 54.163177
[epoch2, step1506]: loss 21.105362
[epoch2, step1507]: loss 16.453875
[epoch2, step1508]: loss 10.633020
[epoch2, step1509]: loss 45.045990
[epoch2, step1510]: loss 6.706819
[epoch2, step1511]: loss 10.577162
[epoch2, step1512]: loss 12.907825
[epoch2, step1513]: loss 17.431528
[epoch2, step1514]: loss 27.401640
[epoch2, step1515]: loss 10.572775
[epoch2, step1516]: loss 9.488411
[epoch2, step1517]: loss 21.564640
[epoch2, step1518]: loss 9.527416
[epoch2, step1519]: loss 21.544167
[epoch2, step1520]: loss 34.914963
[epoch2, step1521]: loss 33.103622
[epoch2, step1522]: loss 18.260281
[epoch2, step1523]: loss 9.716219
[epoch2, step1524]: loss 9.791894
[epoch2, step1525]: loss 9.730375
[epoch2, step1526]: loss 6.712914
[epoch2, step1527]: loss 4.419366
[epoch2, step1528]: loss 8.828423
[epoch2, step1529]: loss 6.214583
[epoch2, step1530]: loss 25.748243
[epoch2, step1531]: loss 25.522156
[epoch2, step1532]: loss 14.964260
[epoch2, step1533]: loss 35.843678
[epoch2, step1534]: loss 4.859197
[epoch2, step1535]: loss 15.439634
[epoch2, step1536]: loss 12.164228
[epoch2, step1537]: loss 11.221684
[epoch2, step1538]: loss 8.910509
[epoch2, step1539]: loss 13.473909
[epoch2, step1540]: loss 9.426983
[epoch2, step1541]: loss 13.115000
[epoch2, step1542]: loss 37.663532
[epoch2, step1543]: loss 19.422453
[epoch2, step1544]: loss 28.006090
[epoch2, step1545]: loss 4.352521
[epoch2, step1546]: loss 7.509282
[epoch2, step1547]: loss 6.365533
[epoch2, step1548]: loss 11.695777
[epoch2, step1549]: loss 41.020004
[epoch2, step1550]: loss 9.002443
[epoch2, step1551]: loss 7.876038
[epoch2, step1552]: loss 7.384064
[epoch2, step1553]: loss 45.898811
[epoch2, step1554]: loss 7.497469
[epoch2, step1555]: loss 52.175205
[epoch2, step1556]: loss 74.997467
[epoch2, step1557]: loss 11.689149
[epoch2, step1558]: loss 26.603157
[epoch2, step1559]: loss 38.780537
[epoch2, step1560]: loss 21.817879
[epoch2, step1561]: loss 13.592035
[epoch2, step1562]: loss 8.790660
[epoch2, step1563]: loss 11.923426
[epoch2, step1564]: loss 9.666875
[epoch2, step1565]: loss 51.909882
[epoch2, step1566]: loss 9.176123
[epoch2, step1567]: loss 15.041088
[epoch2, step1568]: loss 13.418745
[epoch2, step1569]: loss 25.537046
[epoch2, step1570]: loss 20.470161
[epoch2, step1571]: loss 21.334032
[epoch2, step1572]: loss 4.859415
[epoch2, step1573]: loss 23.027756
[epoch2, step1574]: loss 31.637123
[epoch2, step1575]: loss 11.364708
[epoch2, step1576]: loss 25.978861
[epoch2, step1577]: loss 21.277681
[epoch2, step1578]: loss 37.976112
[epoch2, step1579]: loss 11.573696
[epoch2, step1580]: loss 34.960915
[epoch2, step1581]: loss 74.084572
[epoch2, step1582]: loss 21.637247
[epoch2, step1583]: loss 30.176130
[epoch2, step1584]: loss 17.141706
[epoch2, step1585]: loss 12.371264
[epoch2, step1586]: loss 7.257825
[epoch2, step1587]: loss 6.750372
[epoch2, step1588]: loss 2.895081
[epoch2, step1589]: loss 11.377176
[epoch2, step1590]: loss 10.457684
[epoch2, step1591]: loss 85.357658
[epoch2, step1592]: loss 5.929879
[epoch2, step1593]: loss 49.803108
[epoch2, step1594]: loss 32.744846
[epoch2, step1595]: loss 39.565178
[epoch2, step1596]: loss 58.290085
[epoch2, step1597]: loss 13.198423
[epoch2, step1598]: loss 9.415747
[epoch2, step1599]: loss 43.258949
[epoch2, step1600]: loss 51.709938
[epoch2, step1601]: loss 71.828438
[epoch2, step1602]: loss 15.125574
[epoch2, step1603]: loss 40.968758
[epoch2, step1604]: loss 16.052490
[epoch2, step1605]: loss 12.695761
[epoch2, step1606]: loss 10.802986
[epoch2, step1607]: loss 12.073091
[epoch2, step1608]: loss 33.650486
[epoch2, step1609]: loss 19.776602
[epoch2, step1610]: loss 41.160702
[epoch2, step1611]: loss 7.422292
[epoch2, step1612]: loss 12.003342
[epoch2, step1613]: loss 5.767447
[epoch2, step1614]: loss 34.202152
[epoch2, step1615]: loss 3.879488
[epoch2, step1616]: loss 41.658073
[epoch2, step1617]: loss 27.190046
[epoch2, step1618]: loss 39.839275
[epoch2, step1619]: loss 8.200357
[epoch2, step1620]: loss 38.679142
[epoch2, step1621]: loss 14.714682
[epoch2, step1622]: loss 8.324642
[epoch2, step1623]: loss 37.650387
[epoch2, step1624]: loss 39.242928
[epoch2, step1625]: loss 7.504883
[epoch2, step1626]: loss 30.693626
[epoch2, step1627]: loss 13.266527
[epoch2, step1628]: loss 24.270058
[epoch2, step1629]: loss 16.668140
[epoch2, step1630]: loss 42.841827
[epoch2, step1631]: loss 27.003719
[epoch2, step1632]: loss 9.858090
[epoch2, step1633]: loss 17.684902
[epoch2, step1634]: loss 9.882106
[epoch2, step1635]: loss 24.750511
[epoch2, step1636]: loss 7.094689
[epoch2, step1637]: loss 29.306904
[epoch2, step1638]: loss 6.564112
[epoch2, step1639]: loss 3.955962
[epoch2, step1640]: loss 5.081382
[epoch2, step1641]: loss 4.216294
[epoch2, step1642]: loss 8.077868
[epoch2, step1643]: loss 48.246368
[epoch2, step1644]: loss 29.940601
[epoch2, step1645]: loss 12.835075
[epoch2, step1646]: loss 34.922073
[epoch2, step1647]: loss 3.693538
[epoch2, step1648]: loss 57.651840
[epoch2, step1649]: loss 14.424025
[epoch2, step1650]: loss 9.669533
[epoch2, step1651]: loss 20.544653
[epoch2, step1652]: loss 4.032512
[epoch2, step1653]: loss 23.251396
[epoch2, step1654]: loss 22.415852
[epoch2, step1655]: loss 22.912960
[epoch2, step1656]: loss 48.726414
[epoch2, step1657]: loss 10.758360
[epoch2, step1658]: loss 5.963638
[epoch2, step1659]: loss 70.696144
[epoch2, step1660]: loss 18.663748
[epoch2, step1661]: loss 8.926453
[epoch2, step1662]: loss 14.211395
[epoch2, step1663]: loss 7.776314
[epoch2, step1664]: loss 31.280926
[epoch2, step1665]: loss 19.352947
[epoch2, step1666]: loss 2.818731
[epoch2, step1667]: loss 34.612785
[epoch2, step1668]: loss 3.756260
[epoch2, step1669]: loss 44.715252
[epoch2, step1670]: loss 11.688020
[epoch2, step1671]: loss 48.330158
[epoch2, step1672]: loss 12.338535
[epoch2, step1673]: loss 15.328911
[epoch2, step1674]: loss 8.159056
[epoch2, step1675]: loss 6.872798
[epoch2, step1676]: loss 6.740516
[epoch2, step1677]: loss 36.451149
[epoch2, step1678]: loss 15.126963
[epoch2, step1679]: loss 21.118866
[epoch2, step1680]: loss 18.240158
[epoch2, step1681]: loss 32.980556
[epoch2, step1682]: loss 8.087177
[epoch2, step1683]: loss 21.612164
[epoch2, step1684]: loss 36.145767
[epoch2, step1685]: loss 29.076309
[epoch2, step1686]: loss 38.100449
[epoch2, step1687]: loss 37.377930
[epoch2, step1688]: loss 9.023123
[epoch2, step1689]: loss 38.526215
[epoch2, step1690]: loss 47.312683
[epoch2, step1691]: loss 13.099729
[epoch2, step1692]: loss 4.390239
[epoch2, step1693]: loss 6.537199
[epoch2, step1694]: loss 34.841412
[epoch2, step1695]: loss 7.766210
[epoch2, step1696]: loss 7.667017
[epoch2, step1697]: loss 10.009315
[epoch2, step1698]: loss 24.565046
[epoch2, step1699]: loss 9.116454
[epoch2, step1700]: loss 26.367758
[epoch2, step1701]: loss 31.677721
[epoch2, step1702]: loss 11.030493
[epoch2, step1703]: loss 16.869213
[epoch2, step1704]: loss 39.673801
[epoch2, step1705]: loss 43.391010
[epoch2, step1706]: loss 6.752580
[epoch2, step1707]: loss 16.000582
[epoch2, step1708]: loss 6.461029
[epoch2, step1709]: loss 71.067841
[epoch2, step1710]: loss 9.896946
[epoch2, step1711]: loss 19.947538
[epoch2, step1712]: loss 6.304132
[epoch2, step1713]: loss 17.018280
[epoch2, step1714]: loss 6.913908
[epoch2, step1715]: loss 7.207557
[epoch2, step1716]: loss 5.661211
[epoch2, step1717]: loss 8.924012
[epoch2, step1718]: loss 32.917809
[epoch2, step1719]: loss 13.361869
[epoch2, step1720]: loss 9.718395
[epoch2, step1721]: loss 6.899803
[epoch2, step1722]: loss 10.457111
[epoch2, step1723]: loss 13.391859
[epoch2, step1724]: loss 57.212898
[epoch2, step1725]: loss 16.251192
[epoch2, step1726]: loss 18.195272
[epoch2, step1727]: loss 65.061058
[epoch2, step1728]: loss 26.951984
[epoch2, step1729]: loss 5.952852
[epoch2, step1730]: loss 7.244593
[epoch2, step1731]: loss 4.588298
[epoch2, step1732]: loss 10.347118
[epoch2, step1733]: loss 45.436508
[epoch2, step1734]: loss 9.745742
[epoch2, step1735]: loss 8.886904
[epoch2, step1736]: loss 11.150508
[epoch2, step1737]: loss 9.239545
[epoch2, step1738]: loss 26.910280
[epoch2, step1739]: loss 40.346008
[epoch2, step1740]: loss 47.129585
[epoch2, step1741]: loss 14.433929
[epoch2, step1742]: loss 8.365242
[epoch2, step1743]: loss 8.301684
[epoch2, step1744]: loss 22.080551
[epoch2, step1745]: loss 6.775871
[epoch2, step1746]: loss 9.480144
[epoch2, step1747]: loss 8.286543
[epoch2, step1748]: loss 36.731255
[epoch2, step1749]: loss 25.467569
[epoch2, step1750]: loss 10.397121
[epoch2, step1751]: loss 21.014050
[epoch2, step1752]: loss 5.928432
[epoch2, step1753]: loss 7.655366
[epoch2, step1754]: loss 11.054369
[epoch2, step1755]: loss 15.493576
[epoch2, step1756]: loss 5.262544
[epoch2, step1757]: loss 40.530293
[epoch2, step1758]: loss 59.353157
[epoch2, step1759]: loss 32.461933
[epoch2, step1760]: loss 7.787243
[epoch2, step1761]: loss 19.500704
[epoch2, step1762]: loss 8.170969
[epoch2, step1763]: loss 4.860083
[epoch2, step1764]: loss 72.532318
[epoch2, step1765]: loss 5.044473
[epoch2, step1766]: loss 4.862756
[epoch2, step1767]: loss 8.643597
[epoch2, step1768]: loss 31.559999
[epoch2, step1769]: loss 6.136001
[epoch2, step1770]: loss 27.446726
[epoch2, step1771]: loss 37.816280
[epoch2, step1772]: loss 9.304485
[epoch2, step1773]: loss 39.373859
[epoch2, step1774]: loss 5.355140
[epoch2, step1775]: loss 10.051660
[epoch2, step1776]: loss 32.272690
[epoch2, step1777]: loss 6.093719
[epoch2, step1778]: loss 32.870689
[epoch2, step1779]: loss 12.611968
[epoch2, step1780]: loss 6.006464
[epoch2, step1781]: loss 4.967043
[epoch2, step1782]: loss 11.976759
[epoch2, step1783]: loss 13.514900
[epoch2, step1784]: loss 11.908593
[epoch2, step1785]: loss 9.604007
[epoch2, step1786]: loss 10.377540
[epoch2, step1787]: loss 6.499547
[epoch2, step1788]: loss 16.379799
[epoch2, step1789]: loss 11.058340
[epoch2, step1790]: loss 18.728745
[epoch2, step1791]: loss 9.014740
[epoch2, step1792]: loss 9.140182
[epoch2, step1793]: loss 6.042547
[epoch2, step1794]: loss 20.429897
[epoch2, step1795]: loss 9.422206
[epoch2, step1796]: loss 46.044415
[epoch2, step1797]: loss 17.100052
[epoch2, step1798]: loss 7.778358
[epoch2, step1799]: loss 10.852943
[epoch2, step1800]: loss 17.152418
[epoch2, step1801]: loss 14.804805
[epoch2, step1802]: loss 13.056412
[epoch2, step1803]: loss 26.872395
[epoch2, step1804]: loss 9.052340
[epoch2, step1805]: loss 8.866665
[epoch2, step1806]: loss 13.664500
[epoch2, step1807]: loss 9.061540
[epoch2, step1808]: loss 7.627990
[epoch2, step1809]: loss 5.920170
[epoch2, step1810]: loss 48.145847
[epoch2, step1811]: loss 24.691675
[epoch2, step1812]: loss 7.670765
[epoch2, step1813]: loss 10.725014
[epoch2, step1814]: loss 5.516691
[epoch2, step1815]: loss 15.011671
[epoch2, step1816]: loss 14.497792
[epoch2, step1817]: loss 40.779633
[epoch2, step1818]: loss 22.431822
[epoch2, step1819]: loss 7.203427
[epoch2, step1820]: loss 7.976533
[epoch2, step1821]: loss 14.143797
[epoch2, step1822]: loss 15.442251
[epoch2, step1823]: loss 15.661139
[epoch2, step1824]: loss 44.256317
[epoch2, step1825]: loss 9.770704
[epoch2, step1826]: loss 30.165829
[epoch2, step1827]: loss 8.462294
[epoch2, step1828]: loss 15.723698
[epoch2, step1829]: loss 41.224991
[epoch2, step1830]: loss 8.905527
[epoch2, step1831]: loss 37.927753
[epoch2, step1832]: loss 12.979982
[epoch2, step1833]: loss 23.496773
[epoch2, step1834]: loss 4.278656
[epoch2, step1835]: loss 33.136463
[epoch2, step1836]: loss 8.160250
[epoch2, step1837]: loss 34.291203
[epoch2, step1838]: loss 9.056005
[epoch2, step1839]: loss 39.985481
[epoch2, step1840]: loss 13.741605
[epoch2, step1841]: loss 15.329103
[epoch2, step1842]: loss 12.926985
[epoch2, step1843]: loss 38.524460
[epoch2, step1844]: loss 9.270081
[epoch2, step1845]: loss 10.335474
[epoch2, step1846]: loss 12.642023
[epoch2, step1847]: loss 11.634899
[epoch2, step1848]: loss 5.156757
[epoch2, step1849]: loss 46.336811
[epoch2, step1850]: loss 5.095232
[epoch2, step1851]: loss 8.689166
[epoch2, step1852]: loss 29.874868
[epoch2, step1853]: loss 25.511475
[epoch2, step1854]: loss 14.796541
[epoch2, step1855]: loss 20.628223
[epoch2, step1856]: loss 14.391631
[epoch2, step1857]: loss 50.036877
[epoch2, step1858]: loss 26.467533
[epoch2, step1859]: loss 12.074228
[epoch2, step1860]: loss 25.690744
[epoch2, step1861]: loss 27.256664
[epoch2, step1862]: loss 34.808750
[epoch2, step1863]: loss 59.236717
[epoch2, step1864]: loss 44.927319
[epoch2, step1865]: loss 35.735752
[epoch2, step1866]: loss 5.505972
[epoch2, step1867]: loss 25.936296
[epoch2, step1868]: loss 38.911652
[epoch2, step1869]: loss 32.580925
[epoch2, step1870]: loss 20.623619
[epoch2, step1871]: loss 37.231213
[epoch2, step1872]: loss 31.928782
[epoch2, step1873]: loss 4.045008
[epoch2, step1874]: loss 39.192627
[epoch2, step1875]: loss 10.946093
[epoch2, step1876]: loss 26.338448
[epoch2, step1877]: loss 14.628904
[epoch2, step1878]: loss 26.842449
[epoch2, step1879]: loss 9.590036
[epoch2, step1880]: loss 14.657167
[epoch2, step1881]: loss 8.449953
[epoch2, step1882]: loss 8.831862
[epoch2, step1883]: loss 3.838526
[epoch2, step1884]: loss 29.704819
[epoch2, step1885]: loss 23.883318
[epoch2, step1886]: loss 29.285667
[epoch2, step1887]: loss 17.547892
[epoch2, step1888]: loss 12.424389
[epoch2, step1889]: loss 18.408962
[epoch2, step1890]: loss 12.225512
[epoch2, step1891]: loss 33.800266
[epoch2, step1892]: loss 31.601852
[epoch2, step1893]: loss 5.324403
[epoch2, step1894]: loss 5.281112
[epoch2, step1895]: loss 9.768303
[epoch2, step1896]: loss 13.698803
[epoch2, step1897]: loss 7.670110
[epoch2, step1898]: loss 54.866135
[epoch2, step1899]: loss 10.776775
[epoch2, step1900]: loss 6.414704
[epoch2, step1901]: loss 42.135685
[epoch2, step1902]: loss 27.211172
[epoch2, step1903]: loss 4.437000
[epoch2, step1904]: loss 3.775639
[epoch2, step1905]: loss 15.429900
[epoch2, step1906]: loss 55.374794
[epoch2, step1907]: loss 30.712387
[epoch2, step1908]: loss 18.462639
[epoch2, step1909]: loss 6.544328
[epoch2, step1910]: loss 7.835899
[epoch2, step1911]: loss 8.568247
[epoch2, step1912]: loss 16.486252
[epoch2, step1913]: loss 14.167748
[epoch2, step1914]: loss 41.620110
[epoch2, step1915]: loss 4.963618
[epoch2, step1916]: loss 35.367523
[epoch2, step1917]: loss 10.912132
[epoch2, step1918]: loss 17.001371
[epoch2, step1919]: loss 52.433395
[epoch2, step1920]: loss 27.370193
[epoch2, step1921]: loss 8.295792
[epoch2, step1922]: loss 24.742504
[epoch2, step1923]: loss 4.604198
[epoch2, step1924]: loss 23.647167
[epoch2, step1925]: loss 30.207241
[epoch2, step1926]: loss 11.191871
[epoch2, step1927]: loss 48.640484
[epoch2, step1928]: loss 32.940041
[epoch2, step1929]: loss 10.617111
[epoch2, step1930]: loss 11.741401
[epoch2, step1931]: loss 32.781273
[epoch2, step1932]: loss 6.233545
[epoch2, step1933]: loss 12.387255
[epoch2, step1934]: loss 12.143336
[epoch2, step1935]: loss 30.343212
[epoch2, step1936]: loss 42.429497
[epoch2, step1937]: loss 22.273504
[epoch2, step1938]: loss 47.733994
[epoch2, step1939]: loss 16.748665
[epoch2, step1940]: loss 9.763055
[epoch2, step1941]: loss 20.169809
[epoch2, step1942]: loss 27.295860
[epoch2, step1943]: loss 49.593094
[epoch2, step1944]: loss 31.974220
[epoch2, step1945]: loss 9.780221
[epoch2, step1946]: loss 31.636545
[epoch2, step1947]: loss 45.153469
[epoch2, step1948]: loss 8.509205
[epoch2, step1949]: loss 15.322100
[epoch2, step1950]: loss 4.377206
[epoch2, step1951]: loss 4.368315
[epoch2, step1952]: loss 5.200429
[epoch2, step1953]: loss 6.701390
[epoch2, step1954]: loss 28.294102
[epoch2, step1955]: loss 55.422943
[epoch2, step1956]: loss 34.662258
[epoch2, step1957]: loss 5.771818
[epoch2, step1958]: loss 33.889610
[epoch2, step1959]: loss 25.956875
[epoch2, step1960]: loss 38.637253
[epoch2, step1961]: loss 49.483955
[epoch2, step1962]: loss 35.941650
[epoch2, step1963]: loss 20.709688
[epoch2, step1964]: loss 31.679831
[epoch2, step1965]: loss 30.181709
[epoch2, step1966]: loss 12.445076
[epoch2, step1967]: loss 10.952375
[epoch2, step1968]: loss 6.602453
[epoch2, step1969]: loss 5.715115
[epoch2, step1970]: loss 39.528870
[epoch2, step1971]: loss 15.374921
[epoch2, step1972]: loss 14.505001
[epoch2, step1973]: loss 47.201881
[epoch2, step1974]: loss 11.182312
[epoch2, step1975]: loss 32.237564
[epoch2, step1976]: loss 7.275881
[epoch2, step1977]: loss 26.947212
[epoch2, step1978]: loss 21.033609
[epoch2, step1979]: loss 10.403553
[epoch2, step1980]: loss 26.375637
[epoch2, step1981]: loss 15.311146
[epoch2, step1982]: loss 6.614097
[epoch2, step1983]: loss 4.694137
[epoch2, step1984]: loss 4.527731
[epoch2, step1985]: loss 8.121528
[epoch2, step1986]: loss 31.837543
[epoch2, step1987]: loss 31.528732
[epoch2, step1988]: loss 44.821442
[epoch2, step1989]: loss 9.923724
[epoch2, step1990]: loss 5.350758
[epoch2, step1991]: loss 31.836678
[epoch2, step1992]: loss 20.837379
[epoch2, step1993]: loss 25.181332
[epoch2, step1994]: loss 4.730011
[epoch2, step1995]: loss 54.977779
[epoch2, step1996]: loss 47.226906
[epoch2, step1997]: loss 9.135548
[epoch2, step1998]: loss 23.343231
[epoch2, step1999]: loss 18.615534
[epoch2, step2000]: loss 3.812376
[epoch2, step2001]: loss 23.059956
[epoch2, step2002]: loss 61.206772
[epoch2, step2003]: loss 16.595058
[epoch2, step2004]: loss 12.378368
[epoch2, step2005]: loss 7.030448
[epoch2, step2006]: loss 4.372353
[epoch2, step2007]: loss 37.429718
[epoch2, step2008]: loss 20.936352
[epoch2, step2009]: loss 30.804850
[epoch2, step2010]: loss 34.410576
[epoch2, step2011]: loss 25.815290
[epoch2, step2012]: loss 10.099241
[epoch2, step2013]: loss 21.605017
[epoch2, step2014]: loss 9.802820
[epoch2, step2015]: loss 16.612503
[epoch2, step2016]: loss 56.244095
[epoch2, step2017]: loss 28.954105
[epoch2, step2018]: loss 12.547656
[epoch2, step2019]: loss 30.500219
[epoch2, step2020]: loss 15.115356
[epoch2, step2021]: loss 27.382233
[epoch2, step2022]: loss 15.981450
[epoch2, step2023]: loss 9.668173
[epoch2, step2024]: loss 14.970796
[epoch2, step2025]: loss 35.430225
[epoch2, step2026]: loss 31.760078
[epoch2, step2027]: loss 43.216328
[epoch2, step2028]: loss 7.824772
[epoch2, step2029]: loss 24.798569
[epoch2, step2030]: loss 4.366635
[epoch2, step2031]: loss 3.219627
[epoch2, step2032]: loss 32.134026
[epoch2, step2033]: loss 5.741461
[epoch2, step2034]: loss 19.917860
[epoch2, step2035]: loss 19.729874
[epoch2, step2036]: loss 39.305302
[epoch2, step2037]: loss 9.466957
[epoch2, step2038]: loss 7.149434
[epoch2, step2039]: loss 7.421732
[epoch2, step2040]: loss 11.788128
[epoch2, step2041]: loss 13.818762
[epoch2, step2042]: loss 9.001204
[epoch2, step2043]: loss 6.634895
[epoch2, step2044]: loss 4.520420
[epoch2, step2045]: loss 29.093061
[epoch2, step2046]: loss 55.471779
[epoch2, step2047]: loss 46.703442
[epoch2, step2048]: loss 69.364655
[epoch2, step2049]: loss 28.746563
[epoch2, step2050]: loss 11.427976
[epoch2, step2051]: loss 8.143115
[epoch2, step2052]: loss 4.652352
[epoch2, step2053]: loss 27.587942
[epoch2, step2054]: loss 22.365936
[epoch2, step2055]: loss 33.005207
[epoch2, step2056]: loss 7.784827
[epoch2, step2057]: loss 57.593697
[epoch2, step2058]: loss 15.056144
[epoch2, step2059]: loss 5.281549
[epoch2, step2060]: loss 23.327135
[epoch2, step2061]: loss 8.509422
[epoch2, step2062]: loss 5.377854
[epoch2, step2063]: loss 4.314907
[epoch2, step2064]: loss 11.145094
[epoch2, step2065]: loss 30.631430
[epoch2, step2066]: loss 10.406716
[epoch2, step2067]: loss 42.490639
[epoch2, step2068]: loss 26.975826
[epoch2, step2069]: loss 31.783281
[epoch2, step2070]: loss 34.783310
[epoch2, step2071]: loss 29.197130
[epoch2, step2072]: loss 13.487570
[epoch2, step2073]: loss 7.789186
[epoch2, step2074]: loss 28.775129
[epoch2, step2075]: loss 35.047810
[epoch2, step2076]: loss 64.060234
[epoch2, step2077]: loss 5.259734
[epoch2, step2078]: loss 9.161832
[epoch2, step2079]: loss 39.625038
[epoch2, step2080]: loss 13.141783
[epoch2, step2081]: loss 6.265002
[epoch2, step2082]: loss 15.822832
[epoch2, step2083]: loss 34.715347
[epoch2, step2084]: loss 68.146362
[epoch2, step2085]: loss 82.057274
[epoch2, step2086]: loss 14.031205
[epoch2, step2087]: loss 14.922923
[epoch2, step2088]: loss 4.891346
[epoch2, step2089]: loss 11.267070
[epoch2, step2090]: loss 8.019117
[epoch2, step2091]: loss 24.131126
[epoch2, step2092]: loss 11.482781
[epoch2, step2093]: loss 8.786511
[epoch2, step2094]: loss 23.983908
[epoch2, step2095]: loss 32.022251
[epoch2, step2096]: loss 32.839657
[epoch2, step2097]: loss 22.057653
[epoch2, step2098]: loss 10.914213
[epoch2, step2099]: loss 9.486118
[epoch2, step2100]: loss 12.004570
[epoch2, step2101]: loss 8.970471
[epoch2, step2102]: loss 31.044735
[epoch2, step2103]: loss 65.410309
[epoch2, step2104]: loss 7.905543
[epoch2, step2105]: loss 8.684085
[epoch2, step2106]: loss 30.919584
[epoch2, step2107]: loss 24.047302
[epoch2, step2108]: loss 15.051271
[epoch2, step2109]: loss 29.191109
[epoch2, step2110]: loss 23.693747
[epoch2, step2111]: loss 26.286018
[epoch2, step2112]: loss 33.941849
[epoch2, step2113]: loss 15.110960
[epoch2, step2114]: loss 4.034373
[epoch2, step2115]: loss 5.572923
[epoch2, step2116]: loss 26.606712
[epoch2, step2117]: loss 15.764959
[epoch2, step2118]: loss 25.798536
[epoch2, step2119]: loss 45.679424
[epoch2, step2120]: loss 21.686264
[epoch2, step2121]: loss 10.758369
[epoch2, step2122]: loss 9.549841
[epoch2, step2123]: loss 49.336365
[epoch2, step2124]: loss 49.734142
[epoch2, step2125]: loss 75.656731
[epoch2, step2126]: loss 25.441645
[epoch2, step2127]: loss 8.098470
[epoch2, step2128]: loss 7.331919
[epoch2, step2129]: loss 20.800116
[epoch2, step2130]: loss 21.849308
[epoch2, step2131]: loss 43.757526
[epoch2, step2132]: loss 28.552174
[epoch2, step2133]: loss 4.659505
[epoch2, step2134]: loss 31.357380
[epoch2, step2135]: loss 10.967825
[epoch2, step2136]: loss 38.055336
[epoch2, step2137]: loss 19.750957
[epoch2, step2138]: loss 4.849554
[epoch2, step2139]: loss 6.122960
[epoch2, step2140]: loss 23.813297
[epoch2, step2141]: loss 7.961145
[epoch2, step2142]: loss 7.488569
[epoch2, step2143]: loss 11.693005
[epoch2, step2144]: loss 21.060299
[epoch2, step2145]: loss 25.855791
[epoch2, step2146]: loss 4.706652
[epoch2, step2147]: loss 45.100185
[epoch2, step2148]: loss 4.678890
[epoch2, step2149]: loss 26.091583
[epoch2, step2150]: loss 4.085850
[epoch2, step2151]: loss 10.256294
[epoch2, step2152]: loss 8.545973
[epoch2, step2153]: loss 4.911885
[epoch2, step2154]: loss 9.282083
[epoch2, step2155]: loss 10.496060
[epoch2, step2156]: loss 22.656500
[epoch2, step2157]: loss 3.105585
[epoch2, step2158]: loss 40.678364
[epoch2, step2159]: loss 7.432140
[epoch2, step2160]: loss 10.543685
[epoch2, step2161]: loss 13.820789
[epoch2, step2162]: loss 5.848446
[epoch2, step2163]: loss 5.684177
[epoch2, step2164]: loss 5.942085
[epoch2, step2165]: loss 13.412358
[epoch2, step2166]: loss 9.243231
[epoch2, step2167]: loss 17.668304
[epoch2, step2168]: loss 4.908819
[epoch2, step2169]: loss 15.355289
[epoch2, step2170]: loss 22.307339
[epoch2, step2171]: loss 7.120414
[epoch2, step2172]: loss 6.704234
[epoch2, step2173]: loss 10.290635
[epoch2, step2174]: loss 60.631432
[epoch2, step2175]: loss 8.667171
[epoch2, step2176]: loss 53.115982
[epoch2, step2177]: loss 8.730680
[epoch2, step2178]: loss 4.673026
[epoch2, step2179]: loss 12.489899
[epoch2, step2180]: loss 69.961647
[epoch2, step2181]: loss 58.230938
[epoch2, step2182]: loss 46.124542
[epoch2, step2183]: loss 36.815002
[epoch2, step2184]: loss 8.477791
[epoch2, step2185]: loss 6.776080
[epoch2, step2186]: loss 33.467590
[epoch2, step2187]: loss 53.080013
[epoch2, step2188]: loss 17.017899
[epoch2, step2189]: loss 36.210625
[epoch2, step2190]: loss 46.997734
[epoch2, step2191]: loss 6.191609
[epoch2, step2192]: loss 8.722629
[epoch2, step2193]: loss 18.760237
[epoch2, step2194]: loss 27.782434
[epoch2, step2195]: loss 21.601738
[epoch2, step2196]: loss 40.252075
[epoch2, step2197]: loss 8.314758
[epoch2, step2198]: loss 4.121095
[epoch2, step2199]: loss 6.492004
[epoch2, step2200]: loss 53.660927
[epoch2, step2201]: loss 52.647095
[epoch2, step2202]: loss 5.670561
[epoch2, step2203]: loss 11.284531
[epoch2, step2204]: loss 24.807865
[epoch2, step2205]: loss 6.397154
[epoch2, step2206]: loss 5.608568
[epoch2, step2207]: loss 47.252983
[epoch2, step2208]: loss 11.299062
[epoch2, step2209]: loss 50.544456
[epoch2, step2210]: loss 6.188168
[epoch2, step2211]: loss 37.890465
[epoch2, step2212]: loss 45.428940
[epoch2, step2213]: loss 13.409938
[epoch2, step2214]: loss 21.300032
[epoch2, step2215]: loss 77.444885
[epoch2, step2216]: loss 30.006912
[epoch2, step2217]: loss 11.987944
[epoch2, step2218]: loss 26.032167
[epoch2, step2219]: loss 22.520391
[epoch2, step2220]: loss 9.324757
[epoch2, step2221]: loss 26.303530
[epoch2, step2222]: loss 25.259579
[epoch2, step2223]: loss 11.358992
[epoch2, step2224]: loss 6.493427
[epoch2, step2225]: loss 22.180397
[epoch2, step2226]: loss 31.190613
[epoch2, step2227]: loss 18.569626
[epoch2, step2228]: loss 38.311291
[epoch2, step2229]: loss 22.450161
[epoch2, step2230]: loss 11.221544
[epoch2, step2231]: loss 9.839195
[epoch2, step2232]: loss 6.284058
[epoch2, step2233]: loss 6.412500
[epoch2, step2234]: loss 41.436512
[epoch2, step2235]: loss 10.001505
[epoch2, step2236]: loss 32.733200
[epoch2, step2237]: loss 30.299728
[epoch2, step2238]: loss 15.765107
[epoch2, step2239]: loss 23.685125
[epoch2, step2240]: loss 9.434219
[epoch2, step2241]: loss 25.385971
[epoch2, step2242]: loss 5.094742
[epoch2, step2243]: loss 15.104706
[epoch2, step2244]: loss 29.610662
[epoch2, step2245]: loss 19.305965
[epoch2, step2246]: loss 7.535708
[epoch2, step2247]: loss 15.460047
[epoch2, step2248]: loss 16.792236
[epoch2, step2249]: loss 40.979252
[epoch2, step2250]: loss 15.822680
[epoch2, step2251]: loss 5.237204
[epoch2, step2252]: loss 12.661449
[epoch2, step2253]: loss 8.863529
[epoch2, step2254]: loss 10.590773
[epoch2, step2255]: loss 4.662786
[epoch2, step2256]: loss 19.525597
[epoch2, step2257]: loss 12.013581
[epoch2, step2258]: loss 17.385506
[epoch2, step2259]: loss 33.036430
[epoch2, step2260]: loss 5.029667
[epoch2, step2261]: loss 2.992619
[epoch2, step2262]: loss 10.159582
[epoch2, step2263]: loss 8.509133
[epoch2, step2264]: loss 22.408979
[epoch2, step2265]: loss 7.656245
[epoch2, step2266]: loss 3.059843
[epoch2, step2267]: loss 31.879040
[epoch2, step2268]: loss 15.508884
[epoch2, step2269]: loss 25.439659
[epoch2, step2270]: loss 6.467589
[epoch2, step2271]: loss 7.274266
[epoch2, step2272]: loss 11.628870
[epoch2, step2273]: loss 23.081989
[epoch2, step2274]: loss 14.277132
[epoch2, step2275]: loss 6.429420
[epoch2, step2276]: loss 12.789584
[epoch2, step2277]: loss 7.077170
[epoch2, step2278]: loss 11.791047
[epoch2, step2279]: loss 8.268003
[epoch2, step2280]: loss 8.254613
[epoch2, step2281]: loss 5.656683
[epoch2, step2282]: loss 10.475218
[epoch2, step2283]: loss 35.704487
[epoch2, step2284]: loss 33.956898
[epoch2, step2285]: loss 5.171801
[epoch2, step2286]: loss 7.086979
[epoch2, step2287]: loss 14.974401
[epoch2, step2288]: loss 28.434685
[epoch2, step2289]: loss 35.470825
[epoch2, step2290]: loss 23.825682
[epoch2, step2291]: loss 28.103386
[epoch2, step2292]: loss 12.267372
[epoch2, step2293]: loss 6.215048
[epoch2, step2294]: loss 10.405194
[epoch2, step2295]: loss 26.857361
[epoch2, step2296]: loss 4.498153
[epoch2, step2297]: loss 8.888947
[epoch2, step2298]: loss 39.852749
[epoch2, step2299]: loss 37.513458
[epoch2, step2300]: loss 31.792637
[epoch2, step2301]: loss 9.112246
[epoch2, step2302]: loss 10.199732
[epoch2, step2303]: loss 22.378763
[epoch2, step2304]: loss 21.427197
[epoch2, step2305]: loss 13.937366
[epoch2, step2306]: loss 3.702093
[epoch2, step2307]: loss 45.079918
[epoch2, step2308]: loss 24.550270
[epoch2, step2309]: loss 11.065772
[epoch2, step2310]: loss 15.958442
[epoch2, step2311]: loss 23.713005
[epoch2, step2312]: loss 5.534613
[epoch2, step2313]: loss 21.538776
[epoch2, step2314]: loss 16.627121
[epoch2, step2315]: loss 52.122066
[epoch2, step2316]: loss 9.785113
[epoch2, step2317]: loss 25.959938
[epoch2, step2318]: loss 34.549202
[epoch2, step2319]: loss 11.635675
[epoch2, step2320]: loss 34.396355
[epoch2, step2321]: loss 9.878512
[epoch2, step2322]: loss 4.787520
[epoch2, step2323]: loss 27.341660
[epoch2, step2324]: loss 11.264621
[epoch2, step2325]: loss 48.915295
[epoch2, step2326]: loss 11.764151
[epoch2, step2327]: loss 55.423313
[epoch2, step2328]: loss 5.449956
[epoch2, step2329]: loss 30.076391
[epoch2, step2330]: loss 46.410717
[epoch2, step2331]: loss 6.889445
[epoch2, step2332]: loss 8.623289
[epoch2, step2333]: loss 9.119917
[epoch2, step2334]: loss 40.169899
[epoch2, step2335]: loss 5.403861
[epoch2, step2336]: loss 24.016706
[epoch2, step2337]: loss 32.432724
[epoch2, step2338]: loss 13.185418
[epoch2, step2339]: loss 13.905571
[epoch2, step2340]: loss 5.299358
[epoch2, step2341]: loss 40.492020
[epoch2, step2342]: loss 25.281178
[epoch2, step2343]: loss 8.448339
[epoch2, step2344]: loss 27.651426
[epoch2, step2345]: loss 5.302817
[epoch2, step2346]: loss 6.496158
[epoch2, step2347]: loss 29.230791
[epoch2, step2348]: loss 19.457947
[epoch2, step2349]: loss 37.279995
[epoch2, step2350]: loss 10.606105
[epoch2, step2351]: loss 3.595206
[epoch2, step2352]: loss 38.623749
[epoch2, step2353]: loss 26.203161
[epoch2, step2354]: loss 41.099766
[epoch2, step2355]: loss 32.415936
[epoch2, step2356]: loss 18.389473
[epoch2, step2357]: loss 11.469440
[epoch2, step2358]: loss 6.019855
[epoch2, step2359]: loss 8.972427
[epoch2, step2360]: loss 20.991417
[epoch2, step2361]: loss 40.473877
[epoch2, step2362]: loss 9.436385
[epoch2, step2363]: loss 7.249137
[epoch2, step2364]: loss 24.658005
[epoch2, step2365]: loss 19.882023
[epoch2, step2366]: loss 51.971313
[epoch2, step2367]: loss 10.886518
[epoch2, step2368]: loss 7.265130
[epoch2, step2369]: loss 15.851945
[epoch2, step2370]: loss 22.216103
[epoch2, step2371]: loss 8.016728
[epoch2, step2372]: loss 11.164555
[epoch2, step2373]: loss 72.204208
[epoch2, step2374]: loss 4.545152
[epoch2, step2375]: loss 8.544377
[epoch2, step2376]: loss 16.138920
[epoch2, step2377]: loss 31.221798
[epoch2, step2378]: loss 29.845776
[epoch2, step2379]: loss 14.655755
[epoch2, step2380]: loss 21.657238
[epoch2, step2381]: loss 8.422892
[epoch2, step2382]: loss 31.380043
[epoch2, step2383]: loss 14.426075
[epoch2, step2384]: loss 23.957834
[epoch2, step2385]: loss 19.383114
[epoch2, step2386]: loss 6.774152
[epoch2, step2387]: loss 27.299446
[epoch2, step2388]: loss 11.877642
[epoch2, step2389]: loss 28.553253
[epoch2, step2390]: loss 11.124490
[epoch2, step2391]: loss 26.081987
[epoch2, step2392]: loss 3.608801
[epoch2, step2393]: loss 3.863601
[epoch2, step2394]: loss 7.975592
[epoch2, step2395]: loss 32.413982
[epoch2, step2396]: loss 24.255758
[epoch2, step2397]: loss 10.030308
[epoch2, step2398]: loss 21.948654
[epoch2, step2399]: loss 9.110651
[epoch2, step2400]: loss 45.585426
[epoch2, step2401]: loss 9.574593
[epoch2, step2402]: loss 29.458412
[epoch2, step2403]: loss 23.558216
[epoch2, step2404]: loss 8.378115
[epoch2, step2405]: loss 40.640896
[epoch2, step2406]: loss 18.901039
[epoch2, step2407]: loss 25.413092
[epoch2, step2408]: loss 19.475180
[epoch2, step2409]: loss 11.888147
[epoch2, step2410]: loss 47.610222
[epoch2, step2411]: loss 8.820123
[epoch2, step2412]: loss 28.618601
[epoch2, step2413]: loss 8.228610
[epoch2, step2414]: loss 8.327504
[epoch2, step2415]: loss 22.169125
[epoch2, step2416]: loss 5.094624
[epoch2, step2417]: loss 6.370304
[epoch2, step2418]: loss 37.190525
[epoch2, step2419]: loss 20.899916
[epoch2, step2420]: loss 16.680305
[epoch2, step2421]: loss 5.583761
[epoch2, step2422]: loss 9.937108
[epoch2, step2423]: loss 26.154404
[epoch2, step2424]: loss 18.993225
[epoch2, step2425]: loss 7.564670
[epoch2, step2426]: loss 6.526206
[epoch2, step2427]: loss 7.669156
[epoch2, step2428]: loss 27.985699
[epoch2, step2429]: loss 6.890341
[epoch2, step2430]: loss 25.670422
[epoch2, step2431]: loss 39.507133
[epoch2, step2432]: loss 24.263670
[epoch2, step2433]: loss 16.865192
[epoch2, step2434]: loss 31.165497
[epoch2, step2435]: loss 14.734311
[epoch2, step2436]: loss 6.882478
[epoch2, step2437]: loss 6.671526
[epoch2, step2438]: loss 11.866322
[epoch2, step2439]: loss 7.005798
[epoch2, step2440]: loss 14.113743
[epoch2, step2441]: loss 24.303333
[epoch2, step2442]: loss 7.783952
[epoch2, step2443]: loss 8.095570
[epoch2, step2444]: loss 18.390816
[epoch2, step2445]: loss 5.720558
[epoch2, step2446]: loss 23.411547
[epoch2, step2447]: loss 2.733829
[epoch2, step2448]: loss 10.814129
[epoch2, step2449]: loss 35.285118
[epoch2, step2450]: loss 6.229630
[epoch2, step2451]: loss 43.994286
[epoch2, step2452]: loss 4.199322
[epoch2, step2453]: loss 22.754051
[epoch2, step2454]: loss 8.011341
[epoch2, step2455]: loss 12.582596
[epoch2, step2456]: loss 20.346327
[epoch2, step2457]: loss 28.134167
[epoch2, step2458]: loss 42.225029
[epoch2, step2459]: loss 5.363094
[epoch2, step2460]: loss 9.763266
[epoch2, step2461]: loss 15.944304
[epoch2, step2462]: loss 23.906862
[epoch2, step2463]: loss 6.913274
[epoch2, step2464]: loss 4.437593
[epoch2, step2465]: loss 45.649487
[epoch2, step2466]: loss 4.181856
[epoch2, step2467]: loss 3.122952
[epoch2, step2468]: loss 7.620405
[epoch2, step2469]: loss 5.153842
[epoch2, step2470]: loss 6.058904
[epoch2, step2471]: loss 26.968275
[epoch2, step2472]: loss 30.806673
[epoch2, step2473]: loss 44.051273
[epoch2, step2474]: loss 5.048739
[epoch2, step2475]: loss 10.440508
[epoch2, step2476]: loss 10.992100
[epoch2, step2477]: loss 4.639187
[epoch2, step2478]: loss 4.969253
[epoch2, step2479]: loss 9.563428
[epoch2, step2480]: loss 11.996137
[epoch2, step2481]: loss 10.844761
[epoch2, step2482]: loss 18.017574
[epoch2, step2483]: loss 13.353954
[epoch2, step2484]: loss 14.174418
[epoch2, step2485]: loss 8.886387
[epoch2, step2486]: loss 25.690264
[epoch2, step2487]: loss 38.434574
[epoch2, step2488]: loss 9.996433
[epoch2, step2489]: loss 10.117991
[epoch2, step2490]: loss 10.071100
[epoch2, step2491]: loss 4.233379
[epoch2, step2492]: loss 4.621254
[epoch2, step2493]: loss 4.156467
[epoch2, step2494]: loss 6.213625
[epoch2, step2495]: loss 32.072227
[epoch2, step2496]: loss 25.192415
[epoch2, step2497]: loss 16.437424
[epoch2, step2498]: loss 4.275809
[epoch2, step2499]: loss 11.850674
[epoch2, step2500]: loss 3.221691
[epoch2, step2501]: loss 16.413357
[epoch2, step2502]: loss 12.018509
[epoch2, step2503]: loss 8.659857
[epoch2, step2504]: loss 16.261616
[epoch2, step2505]: loss 10.996249
[epoch2, step2506]: loss 8.583394
[epoch2, step2507]: loss 3.433738
[epoch2, step2508]: loss 4.540187
[epoch2, step2509]: loss 8.958121
[epoch2, step2510]: loss 4.444638
[epoch2, step2511]: loss 22.451637
[epoch2, step2512]: loss 12.450201
[epoch2, step2513]: loss 16.121609
[epoch2, step2514]: loss 12.213806
[epoch2, step2515]: loss 30.651131
[epoch2, step2516]: loss 8.064210
[epoch2, step2517]: loss 62.117950
[epoch2, step2518]: loss 6.571578
[epoch2, step2519]: loss 4.450792
[epoch2, step2520]: loss 26.142254
[epoch2, step2521]: loss 20.887270
[epoch2, step2522]: loss 45.850498
[epoch2, step2523]: loss 3.429763
[epoch2, step2524]: loss 8.363595
[epoch2, step2525]: loss 5.329692
[epoch2, step2526]: loss 20.922514
[epoch2, step2527]: loss 9.333973
[epoch2, step2528]: loss 35.097694
[epoch2, step2529]: loss 36.322048
[epoch2, step2530]: loss 4.596191
[epoch2, step2531]: loss 22.726292
[epoch2, step2532]: loss 40.450821
[epoch2, step2533]: loss 5.414805
[epoch2, step2534]: loss 39.373966
[epoch2, step2535]: loss 14.052979
[epoch2, step2536]: loss 7.269642
[epoch2, step2537]: loss 43.129272
[epoch2, step2538]: loss 9.166753
[epoch2, step2539]: loss 3.775971
[epoch2, step2540]: loss 6.208727
[epoch2, step2541]: loss 8.231356
[epoch2, step2542]: loss 9.641325
[epoch2, step2543]: loss 35.871555
[epoch2, step2544]: loss 53.272034
[epoch2, step2545]: loss 57.423531
[epoch2, step2546]: loss 56.517326
[epoch2, step2547]: loss 12.217038
[epoch2, step2548]: loss 43.851219
[epoch2, step2549]: loss 13.284636
[epoch2, step2550]: loss 16.196829
[epoch2, step2551]: loss 12.732475
[epoch2, step2552]: loss 42.773293
[epoch2, step2553]: loss 6.218450
[epoch2, step2554]: loss 28.938408
[epoch2, step2555]: loss 12.698463
[epoch2, step2556]: loss 5.915583
[epoch2, step2557]: loss 6.646947
[epoch2, step2558]: loss 28.282143
[epoch2, step2559]: loss 9.046727
[epoch2, step2560]: loss 8.428049
[epoch2, step2561]: loss 6.962071
[epoch2, step2562]: loss 12.959944
[epoch2, step2563]: loss 15.705828
[epoch2, step2564]: loss 11.258918
[epoch2, step2565]: loss 9.400289
[epoch2, step2566]: loss 21.030138
[epoch2, step2567]: loss 51.821293
[epoch2, step2568]: loss 5.959281
[epoch2, step2569]: loss 33.455681
[epoch2, step2570]: loss 27.581820
[epoch2, step2571]: loss 14.759542
[epoch2, step2572]: loss 33.743702
[epoch2, step2573]: loss 34.158073
[epoch2, step2574]: loss 46.683769
[epoch2, step2575]: loss 4.233687
[epoch2, step2576]: loss 7.923679
[epoch2, step2577]: loss 22.753614
[epoch2, step2578]: loss 32.010578
[epoch2, step2579]: loss 33.581749
[epoch2, step2580]: loss 13.471104
[epoch2, step2581]: loss 21.370564
[epoch2, step2582]: loss 6.887038
[epoch2, step2583]: loss 6.124879
[epoch2, step2584]: loss 35.351105
[epoch2, step2585]: loss 14.611471
[epoch2, step2586]: loss 9.877321
[epoch2, step2587]: loss 3.409786
[epoch2, step2588]: loss 11.869187
[epoch2, step2589]: loss 5.903073
[epoch2, step2590]: loss 24.439983
[epoch2, step2591]: loss 27.174706
[epoch2, step2592]: loss 33.522339
[epoch2, step2593]: loss 31.423628
[epoch2, step2594]: loss 9.764875
[epoch2, step2595]: loss 33.271198
[epoch2, step2596]: loss 27.851547
[epoch2, step2597]: loss 8.182278
[epoch2, step2598]: loss 13.464511
[epoch2, step2599]: loss 60.438560
[epoch2, step2600]: loss 10.095065
[epoch2, step2601]: loss 6.801656
[epoch2, step2602]: loss 7.445043
[epoch2, step2603]: loss 9.029753
[epoch2, step2604]: loss 26.693298
[epoch2, step2605]: loss 15.306818
[epoch2, step2606]: loss 25.993343
[epoch2, step2607]: loss 40.030243
[epoch2, step2608]: loss 49.047756
[epoch2, step2609]: loss 26.257097
[epoch2, step2610]: loss 5.426393
[epoch2, step2611]: loss 5.051995
[epoch2, step2612]: loss 29.096664
[epoch2, step2613]: loss 9.506438
[epoch2, step2614]: loss 43.840702
[epoch2, step2615]: loss 5.428420
[epoch2, step2616]: loss 19.963663
[epoch2, step2617]: loss 20.586678
[epoch2, step2618]: loss 10.564005
[epoch2, step2619]: loss 5.541288
[epoch2, step2620]: loss 11.598634
[epoch2, step2621]: loss 4.413519
[epoch2, step2622]: loss 8.267444
[epoch2, step2623]: loss 22.364952
[epoch2, step2624]: loss 10.509762
[epoch2, step2625]: loss 46.429066
[epoch2, step2626]: loss 15.050430
[epoch2, step2627]: loss 28.315693
[epoch2, step2628]: loss 18.990116
[epoch2, step2629]: loss 27.774160
[epoch2, step2630]: loss 12.148495
[epoch2, step2631]: loss 24.369518
[epoch2, step2632]: loss 7.299391
[epoch2, step2633]: loss 6.477978
[epoch2, step2634]: loss 7.124500
[epoch2, step2635]: loss 16.229624
[epoch2, step2636]: loss 28.935574
[epoch2, step2637]: loss 9.022407
[epoch2, step2638]: loss 4.192633
[epoch2, step2639]: loss 6.945980
[epoch2, step2640]: loss 4.892012
[epoch2, step2641]: loss 13.075796
[epoch2, step2642]: loss 6.599576
[epoch2, step2643]: loss 16.347170
[epoch2, step2644]: loss 18.316952
[epoch2, step2645]: loss 33.054924
[epoch2, step2646]: loss 6.187219
[epoch2, step2647]: loss 7.156930
[epoch2, step2648]: loss 29.900002
[epoch2, step2649]: loss 37.012997
[epoch2, step2650]: loss 31.927702
[epoch2, step2651]: loss 29.164616
[epoch2, step2652]: loss 6.572837
[epoch2, step2653]: loss 21.636110
[epoch2, step2654]: loss 31.706600
[epoch2, step2655]: loss 30.454672
[epoch2, step2656]: loss 5.956040
[epoch2, step2657]: loss 55.625961
[epoch2, step2658]: loss 7.948771
[epoch2, step2659]: loss 21.638775
[epoch2, step2660]: loss 43.829353
[epoch2, step2661]: loss 3.024769
[epoch2, step2662]: loss 7.211119
[epoch2, step2663]: loss 5.734725
[epoch2, step2664]: loss 5.405042
[epoch2, step2665]: loss 67.035492
[epoch2, step2666]: loss 6.495588
[epoch2, step2667]: loss 9.528701
[epoch2, step2668]: loss 4.865888
[epoch2, step2669]: loss 7.001680
[epoch2, step2670]: loss 10.808055
[epoch2, step2671]: loss 19.647539
[epoch2, step2672]: loss 39.961185
[epoch2, step2673]: loss 6.464236
[epoch2, step2674]: loss 34.443588
[epoch2, step2675]: loss 4.916919
[epoch2, step2676]: loss 8.050564
[epoch2, step2677]: loss 8.787097
[epoch2, step2678]: loss 8.536554
[epoch2, step2679]: loss 12.505024
[epoch2, step2680]: loss 18.434475
[epoch2, step2681]: loss 50.444847
[epoch2, step2682]: loss 29.839931
[epoch2, step2683]: loss 22.939066
[epoch2, step2684]: loss 6.949543
[epoch2, step2685]: loss 4.047977
[epoch2, step2686]: loss 14.776781
[epoch2, step2687]: loss 21.945904
[epoch2, step2688]: loss 67.233177
[epoch2, step2689]: loss 23.223042
[epoch2, step2690]: loss 6.524581
[epoch2, step2691]: loss 5.828175
[epoch2, step2692]: loss 3.862026
[epoch2, step2693]: loss 39.030411
[epoch2, step2694]: loss 9.308910
[epoch2, step2695]: loss 27.008240
[epoch2, step2696]: loss 43.061569
[epoch2, step2697]: loss 13.640938
[epoch2, step2698]: loss 13.550910
[epoch2, step2699]: loss 10.306696
[epoch2, step2700]: loss 24.643381
[epoch2, step2701]: loss 6.418832
[epoch2, step2702]: loss 11.598372
[epoch2, step2703]: loss 6.077141
[epoch2, step2704]: loss 37.099548
[epoch2, step2705]: loss 25.689316
[epoch2, step2706]: loss 19.526522
[epoch2, step2707]: loss 33.937908
[epoch2, step2708]: loss 7.562819
[epoch2, step2709]: loss 11.842952
[epoch2, step2710]: loss 4.466639
[epoch2, step2711]: loss 22.450743
[epoch2, step2712]: loss 24.407780
[epoch2, step2713]: loss 25.580667
[epoch2, step2714]: loss 6.448290
[epoch2, step2715]: loss 34.592888
[epoch2, step2716]: loss 5.371784
[epoch2, step2717]: loss 27.182392
[epoch2, step2718]: loss 13.967100
[epoch2, step2719]: loss 16.477249
[epoch2, step2720]: loss 55.989761
[epoch2, step2721]: loss 13.075704
[epoch2, step2722]: loss 56.500370
[epoch2, step2723]: loss 10.359019
[epoch2, step2724]: loss 8.865978
[epoch2, step2725]: loss 10.519877
[epoch2, step2726]: loss 29.139482
[epoch2, step2727]: loss 7.078078
[epoch2, step2728]: loss 8.909482
[epoch2, step2729]: loss 7.021636
[epoch2, step2730]: loss 14.670251
[epoch2, step2731]: loss 3.545099
[epoch2, step2732]: loss 13.713401
[epoch2, step2733]: loss 4.099527
[epoch2, step2734]: loss 12.687659
[epoch2, step2735]: loss 12.787659
[epoch2, step2736]: loss 5.563406
[epoch2, step2737]: loss 25.165998
[epoch2, step2738]: loss 7.388328
[epoch2, step2739]: loss 25.292953
[epoch2, step2740]: loss 23.636187
[epoch2, step2741]: loss 21.479435
[epoch2, step2742]: loss 67.118126
[epoch2, step2743]: loss 9.609616
[epoch2, step2744]: loss 24.655449
[epoch2, step2745]: loss 3.939506
[epoch2, step2746]: loss 10.122470
[epoch2, step2747]: loss 28.836197
[epoch2, step2748]: loss 66.154007
[epoch2, step2749]: loss 7.070277
[epoch2, step2750]: loss 7.748214
[epoch2, step2751]: loss 35.759415
[epoch2, step2752]: loss 15.509907
[epoch2, step2753]: loss 5.020802
[epoch2, step2754]: loss 4.769523
[epoch2, step2755]: loss 7.788480
[epoch2, step2756]: loss 18.062040
[epoch2, step2757]: loss 38.960205
[epoch2, step2758]: loss 7.191423
[epoch2, step2759]: loss 24.730116
[epoch2, step2760]: loss 5.843822
[epoch2, step2761]: loss 27.622429
[epoch2, step2762]: loss 15.629347
[epoch2, step2763]: loss 4.941457
[epoch2, step2764]: loss 60.362019
[epoch2, step2765]: loss 29.807468
[epoch2, step2766]: loss 21.047470
[epoch2, step2767]: loss 23.402781
[epoch2, step2768]: loss 62.531876
[epoch2, step2769]: loss 7.285257
[epoch2, step2770]: loss 52.700298
[epoch2, step2771]: loss 11.338116
[epoch2, step2772]: loss 58.034958
[epoch2, step2773]: loss 4.473563
[epoch2, step2774]: loss 25.598455
[epoch2, step2775]: loss 24.869377
[epoch2, step2776]: loss 26.868658
[epoch2, step2777]: loss 8.560952
[epoch2, step2778]: loss 6.441541
[epoch2, step2779]: loss 71.053680
[epoch2, step2780]: loss 6.914662
[epoch2, step2781]: loss 3.425184
[epoch2, step2782]: loss 4.903691
[epoch2, step2783]: loss 6.939106
[epoch2, step2784]: loss 33.454563
[epoch2, step2785]: loss 2.789629
[epoch2, step2786]: loss 35.314987
[epoch2, step2787]: loss 75.874054
[epoch2, step2788]: loss 3.527829
[epoch2, step2789]: loss 8.686472
[epoch2, step2790]: loss 8.630440
[epoch2, step2791]: loss 5.079212
[epoch2, step2792]: loss 26.123804
[epoch2, step2793]: loss 9.596525
[epoch2, step2794]: loss 24.669249
[epoch2, step2795]: loss 7.522839
[epoch2, step2796]: loss 9.684644
[epoch2, step2797]: loss 7.537512
[epoch2, step2798]: loss 9.269430
[epoch2, step2799]: loss 28.173611
[epoch2, step2800]: loss 5.846642
[epoch2, step2801]: loss 12.254847
[epoch2, step2802]: loss 4.582277
[epoch2, step2803]: loss 9.560845
[epoch2, step2804]: loss 13.116135
[epoch2, step2805]: loss 4.559336
[epoch2, step2806]: loss 13.553369
[epoch2, step2807]: loss 9.014091
[epoch2, step2808]: loss 40.278099
[epoch2, step2809]: loss 22.122072
[epoch2, step2810]: loss 25.806351
[epoch2, step2811]: loss 12.139864
[epoch2, step2812]: loss 4.708502
[epoch2, step2813]: loss 11.499888
[epoch2, step2814]: loss 11.617284
[epoch2, step2815]: loss 8.434863
[epoch2, step2816]: loss 7.782470
[epoch2, step2817]: loss 31.846928
[epoch2, step2818]: loss 40.618641
[epoch2, step2819]: loss 39.891979
[epoch2, step2820]: loss 12.553627
[epoch2, step2821]: loss 22.693600
[epoch2, step2822]: loss 30.338308
[epoch2, step2823]: loss 5.454781
[epoch2, step2824]: loss 3.058728
[epoch2, step2825]: loss 21.450733
[epoch2, step2826]: loss 7.394437
[epoch2, step2827]: loss 9.933591
[epoch2, step2828]: loss 12.066755
[epoch2, step2829]: loss 8.504762
[epoch2, step2830]: loss 8.483375
[epoch2, step2831]: loss 6.436881
[epoch2, step2832]: loss 17.909704
[epoch2, step2833]: loss 3.023569
[epoch2, step2834]: loss 18.107239
[epoch2, step2835]: loss 12.984671
[epoch2, step2836]: loss 9.316383
[epoch2, step2837]: loss 32.128868
[epoch2, step2838]: loss 37.210106
[epoch2, step2839]: loss 8.381384
[epoch2, step2840]: loss 8.929408
[epoch2, step2841]: loss 5.691020
[epoch2, step2842]: loss 2.323389
[epoch2, step2843]: loss 10.297282
[epoch2, step2844]: loss 14.195579
[epoch2, step2845]: loss 24.269535
[epoch2, step2846]: loss 48.642532
[epoch2, step2847]: loss 24.547489
[epoch2, step2848]: loss 23.814331
[epoch2, step2849]: loss 24.411692
[epoch2, step2850]: loss 9.390372
[epoch2, step2851]: loss 4.877571
[epoch2, step2852]: loss 14.310394
[epoch2, step2853]: loss 35.322067
[epoch2, step2854]: loss 28.750408
[epoch2, step2855]: loss 6.045523
[epoch2, step2856]: loss 22.841053
[epoch2, step2857]: loss 7.346185
[epoch2, step2858]: loss 25.302704
[epoch2, step2859]: loss 9.071585
[epoch2, step2860]: loss 29.564285
[epoch2, step2861]: loss 32.685551
[epoch2, step2862]: loss 19.000280
[epoch2, step2863]: loss 27.750687
[epoch2, step2864]: loss 8.081962
[epoch2, step2865]: loss 28.712112
[epoch2, step2866]: loss 5.384096
[epoch2, step2867]: loss 19.151588
[epoch2, step2868]: loss 47.017227
[epoch2, step2869]: loss 9.203837
[epoch2, step2870]: loss 5.876991
[epoch2, step2871]: loss 24.332006
[epoch2, step2872]: loss 14.175798
[epoch2, step2873]: loss 14.775923
[epoch2, step2874]: loss 7.514471
[epoch2, step2875]: loss 3.809027
[epoch2, step2876]: loss 24.231480
[epoch2, step2877]: loss 19.803303
[epoch2, step2878]: loss 31.276958
[epoch2, step2879]: loss 10.453604
[epoch2, step2880]: loss 3.905929
[epoch2, step2881]: loss 7.607467
[epoch2, step2882]: loss 42.296242
[epoch2, step2883]: loss 7.969587
[epoch2, step2884]: loss 21.814564
[epoch2, step2885]: loss 11.107465
[epoch2, step2886]: loss 7.966864
[epoch2, step2887]: loss 7.150693
[epoch2, step2888]: loss 40.868484
[epoch2, step2889]: loss 40.870247
[epoch2, step2890]: loss 5.973049
[epoch2, step2891]: loss 14.244037
[epoch2, step2892]: loss 10.519625
[epoch2, step2893]: loss 48.765961
[epoch2, step2894]: loss 5.217198
[epoch2, step2895]: loss 28.605742
[epoch2, step2896]: loss 32.600395
[epoch2, step2897]: loss 3.816398
[epoch2, step2898]: loss 5.530341
[epoch2, step2899]: loss 9.207668
[epoch2, step2900]: loss 25.079035
[epoch2, step2901]: loss 48.634563
[epoch2, step2902]: loss 14.065184
[epoch2, step2903]: loss 15.205588
[epoch2, step2904]: loss 27.750763
[epoch2, step2905]: loss 2.575801
[epoch2, step2906]: loss 20.294889
[epoch2, step2907]: loss 4.358865
[epoch2, step2908]: loss 30.288925
[epoch2, step2909]: loss 8.170938
[epoch2, step2910]: loss 8.164546
[epoch2, step2911]: loss 6.235520
[epoch2, step2912]: loss 14.128201
[epoch2, step2913]: loss 12.153462
[epoch2, step2914]: loss 35.490040
[epoch2, step2915]: loss 13.035856
[epoch2, step2916]: loss 18.050079
[epoch2, step2917]: loss 17.077812
[epoch2, step2918]: loss 4.733568
[epoch2, step2919]: loss 14.328417
[epoch2, step2920]: loss 29.368988
[epoch2, step2921]: loss 25.367153
[epoch2, step2922]: loss 7.290691
[epoch2, step2923]: loss 9.826261
[epoch2, step2924]: loss 6.714656
[epoch2, step2925]: loss 35.395874
[epoch2, step2926]: loss 54.377258
[epoch2, step2927]: loss 28.088549
[epoch2, step2928]: loss 12.629047
[epoch2, step2929]: loss 14.209905
[epoch2, step2930]: loss 27.571976
[epoch2, step2931]: loss 30.282427
[epoch2, step2932]: loss 9.256007
[epoch2, step2933]: loss 16.961012
[epoch2, step2934]: loss 3.649170
[epoch2, step2935]: loss 6.888947
[epoch2, step2936]: loss 22.664385
[epoch2, step2937]: loss 31.750954
[epoch2, step2938]: loss 49.891441
[epoch2, step2939]: loss 8.888859
[epoch2, step2940]: loss 12.336031
[epoch2, step2941]: loss 6.948280
[epoch2, step2942]: loss 30.229275
[epoch2, step2943]: loss 11.891596
[epoch2, step2944]: loss 6.704602
[epoch2, step2945]: loss 26.072174
[epoch2, step2946]: loss 47.372303
[epoch2, step2947]: loss 8.316166
[epoch2, step2948]: loss 5.233768
[epoch2, step2949]: loss 23.560099
[epoch2, step2950]: loss 41.319229
[epoch2, step2951]: loss 5.918326
[epoch2, step2952]: loss 6.093636
[epoch2, step2953]: loss 9.547268
[epoch2, step2954]: loss 26.336369
[epoch2, step2955]: loss 26.505861
[epoch2, step2956]: loss 36.515667
[epoch2, step2957]: loss 62.234039
[epoch2, step2958]: loss 8.424356
[epoch2, step2959]: loss 35.166943
[epoch2, step2960]: loss 34.001900
[epoch2, step2961]: loss 6.481163
[epoch2, step2962]: loss 33.144272
[epoch2, step2963]: loss 34.977886
[epoch2, step2964]: loss 6.979458
[epoch2, step2965]: loss 5.160467
[epoch2, step2966]: loss 6.889652
[epoch2, step2967]: loss 34.947220
[epoch2, step2968]: loss 50.572655
[epoch2, step2969]: loss 21.834602
[epoch2, step2970]: loss 6.800894
[epoch2, step2971]: loss 7.698592
[epoch2, step2972]: loss 22.631638
[epoch2, step2973]: loss 6.805787
[epoch2, step2974]: loss 5.279099
[epoch2, step2975]: loss 8.070229
[epoch2, step2976]: loss 51.862270
[epoch2, step2977]: loss 16.129658
[epoch2, step2978]: loss 5.905396
[epoch2, step2979]: loss 28.390839
[epoch2, step2980]: loss 24.639776
[epoch2, step2981]: loss 7.453603
[epoch2, step2982]: loss 7.926018
[epoch2, step2983]: loss 38.472443
[epoch2, step2984]: loss 10.671514
[epoch2, step2985]: loss 12.356073
[epoch2, step2986]: loss 5.061037
[epoch2, step2987]: loss 24.673143
[epoch2, step2988]: loss 6.532177
[epoch2, step2989]: loss 35.525375
[epoch2, step2990]: loss 25.389036
[epoch2, step2991]: loss 13.192834
[epoch2, step2992]: loss 14.608522
[epoch2, step2993]: loss 12.714009
[epoch2, step2994]: loss 27.858974
[epoch2, step2995]: loss 2.355704
[epoch2, step2996]: loss 18.839867
[epoch2, step2997]: loss 5.977590
[epoch2, step2998]: loss 8.241703
[epoch2, step2999]: loss 13.591041
[epoch2, step3000]: loss 3.227949
[epoch2, step3001]: loss 32.231846
[epoch2, step3002]: loss 8.894514
[epoch2, step3003]: loss 17.099512
[epoch2, step3004]: loss 64.742790
[epoch2, step3005]: loss 28.172087
[epoch2, step3006]: loss 24.314873
[epoch2, step3007]: loss 12.351646
[epoch2, step3008]: loss 29.286253
[epoch2, step3009]: loss 14.591468
[epoch2, step3010]: loss 26.202053
[epoch2, step3011]: loss 17.941063
[epoch2, step3012]: loss 14.062804
[epoch2, step3013]: loss 6.462460
[epoch2, step3014]: loss 24.679096
[epoch2, step3015]: loss 22.323954
[epoch2, step3016]: loss 7.152193
[epoch2, step3017]: loss 4.395212
[epoch2, step3018]: loss 6.310397
[epoch2, step3019]: loss 6.942423
[epoch2, step3020]: loss 8.613544
[epoch2, step3021]: loss 11.745259
[epoch2, step3022]: loss 25.033352
[epoch2, step3023]: loss 8.020966
[epoch2, step3024]: loss 14.535968
[epoch2, step3025]: loss 21.701229
[epoch2, step3026]: loss 10.171689
[epoch2, step3027]: loss 13.987020
[epoch2, step3028]: loss 23.227068
[epoch2, step3029]: loss 41.827801
[epoch2, step3030]: loss 4.204279
[epoch2, step3031]: loss 8.805692
[epoch2, step3032]: loss 18.403790
[epoch2, step3033]: loss 58.385864
[epoch2, step3034]: loss 32.436062
[epoch2, step3035]: loss 29.771004
[epoch2, step3036]: loss 6.734562
[epoch2, step3037]: loss 29.631403
[epoch2, step3038]: loss 10.434518
[epoch2, step3039]: loss 44.521805
[epoch2, step3040]: loss 26.611546
[epoch2, step3041]: loss 29.723122
[epoch2, step3042]: loss 36.227619
[epoch2, step3043]: loss 2.794319
[epoch2, step3044]: loss 7.381218
[epoch2, step3045]: loss 32.599773
[epoch2, step3046]: loss 33.246250
[epoch2, step3047]: loss 29.617840
[epoch2, step3048]: loss 36.147694
[epoch2, step3049]: loss 3.527069
[epoch2, step3050]: loss 9.617088
[epoch2, step3051]: loss 16.299103
[epoch2, step3052]: loss 39.049007
[epoch2, step3053]: loss 17.060602
[epoch2, step3054]: loss 3.126100
[epoch2, step3055]: loss 5.980103
[epoch2, step3056]: loss 9.971928
[epoch2, step3057]: loss 10.715912
[epoch2, step3058]: loss 39.194229
[epoch2, step3059]: loss 10.172445
[epoch2, step3060]: loss 6.773540
[epoch2, step3061]: loss 2.913040
[epoch2, step3062]: loss 41.659149
[epoch2, step3063]: loss 8.948518
[epoch2, step3064]: loss 30.837326
[epoch2, step3065]: loss 29.105446
[epoch2, step3066]: loss 6.675689
[epoch2, step3067]: loss 29.022003
[epoch2, step3068]: loss 14.302780
[epoch2, step3069]: loss 8.910115
[epoch2, step3070]: loss 4.499426
[epoch2, step3071]: loss 3.779769
[epoch2, step3072]: loss 4.805649
[epoch2, step3073]: loss 6.846108
[epoch2, step3074]: loss 5.561150
[epoch2, step3075]: loss 12.170272
[epoch2, step3076]: loss 36.349979

[epoch2]: avg loss 36.349979

[epoch3, step1]: loss 7.756479
[epoch3, step2]: loss 15.903885
[epoch3, step3]: loss 11.072789
[epoch3, step4]: loss 18.001232
[epoch3, step5]: loss 12.559462
[epoch3, step6]: loss 4.516696
[epoch3, step7]: loss 3.286379
[epoch3, step8]: loss 6.112426
[epoch3, step9]: loss 19.040878
[epoch3, step10]: loss 25.874680
[epoch3, step11]: loss 54.775574
[epoch3, step12]: loss 6.644930
[epoch3, step13]: loss 13.762880
[epoch3, step14]: loss 27.534479
[epoch3, step15]: loss 43.426872
[epoch3, step16]: loss 2.896198
[epoch3, step17]: loss 7.011341
[epoch3, step18]: loss 28.591995
[epoch3, step19]: loss 31.686543
[epoch3, step20]: loss 30.349049
[epoch3, step21]: loss 25.764517
[epoch3, step22]: loss 21.771843
[epoch3, step23]: loss 7.551282
[epoch3, step24]: loss 8.977722
[epoch3, step25]: loss 5.936025
[epoch3, step26]: loss 6.504752
[epoch3, step27]: loss 32.073448
[epoch3, step28]: loss 2.739852
[epoch3, step29]: loss 6.696315
[epoch3, step30]: loss 26.978119
[epoch3, step31]: loss 38.968746
[epoch3, step32]: loss 7.134675
[epoch3, step33]: loss 8.018505
[epoch3, step34]: loss 9.027735
[epoch3, step35]: loss 17.162399
[epoch3, step36]: loss 8.045134
[epoch3, step37]: loss 29.098196
[epoch3, step38]: loss 3.572307
[epoch3, step39]: loss 8.482601
[epoch3, step40]: loss 7.328046
[epoch3, step41]: loss 14.938601
[epoch3, step42]: loss 52.146812
[epoch3, step43]: loss 11.573888
[epoch3, step44]: loss 12.041526
[epoch3, step45]: loss 47.679314
[epoch3, step46]: loss 15.003639
[epoch3, step47]: loss 47.178463
[epoch3, step48]: loss 7.412875
[epoch3, step49]: loss 36.381245
[epoch3, step50]: loss 13.120857
[epoch3, step51]: loss 4.964406
[epoch3, step52]: loss 3.348494
[epoch3, step53]: loss 5.239960
[epoch3, step54]: loss 5.589047
[epoch3, step55]: loss 4.193157
[epoch3, step56]: loss 6.677193
[epoch3, step57]: loss 27.676973
[epoch3, step58]: loss 28.032207
[epoch3, step59]: loss 6.052710
[epoch3, step60]: loss 9.586733
[epoch3, step61]: loss 24.205311
[epoch3, step62]: loss 25.268024
[epoch3, step63]: loss 13.233966
[epoch3, step64]: loss 10.174987
[epoch3, step65]: loss 5.856823
[epoch3, step66]: loss 5.121010
[epoch3, step67]: loss 7.928294
[epoch3, step68]: loss 25.122505
[epoch3, step69]: loss 12.464954
[epoch3, step70]: loss 20.011444
[epoch3, step71]: loss 28.011902
[epoch3, step72]: loss 25.073572
[epoch3, step73]: loss 12.062807
[epoch3, step74]: loss 35.709549
[epoch3, step75]: loss 8.353845
[epoch3, step76]: loss 14.121886
[epoch3, step77]: loss 45.188740
[epoch3, step78]: loss 6.848767
[epoch3, step79]: loss 19.836634
[epoch3, step80]: loss 27.532898
[epoch3, step81]: loss 8.734760
[epoch3, step82]: loss 5.854955
[epoch3, step83]: loss 6.458156
[epoch3, step84]: loss 7.020607
[epoch3, step85]: loss 14.716738
[epoch3, step86]: loss 12.712160
[epoch3, step87]: loss 19.251135
[epoch3, step88]: loss 40.360619
[epoch3, step89]: loss 7.396115
[epoch3, step90]: loss 6.141570
[epoch3, step91]: loss 16.405525
[epoch3, step92]: loss 5.538927
[epoch3, step93]: loss 10.788229
[epoch3, step94]: loss 11.749066
[epoch3, step95]: loss 28.929583
[epoch3, step96]: loss 45.013035
[epoch3, step97]: loss 5.017386
[epoch3, step98]: loss 5.717301
[epoch3, step99]: loss 36.769951
[epoch3, step100]: loss 33.672958
[epoch3, step101]: loss 7.252965
[epoch3, step102]: loss 4.598943
[epoch3, step103]: loss 18.998549
[epoch3, step104]: loss 11.910704
[epoch3, step105]: loss 18.736547
[epoch3, step106]: loss 20.101942
[epoch3, step107]: loss 3.920858
[epoch3, step108]: loss 10.446922
[epoch3, step109]: loss 3.057247
[epoch3, step110]: loss 21.232967
[epoch3, step111]: loss 3.513523
[epoch3, step112]: loss 15.079926
[epoch3, step113]: loss 12.564777
[epoch3, step114]: loss 38.519592
[epoch3, step115]: loss 16.761429
[epoch3, step116]: loss 8.092955
[epoch3, step117]: loss 4.440972
[epoch3, step118]: loss 5.401504
[epoch3, step119]: loss 21.737698
[epoch3, step120]: loss 23.084255
[epoch3, step121]: loss 27.480755
[epoch3, step122]: loss 9.285614
[epoch3, step123]: loss 18.232805
[epoch3, step124]: loss 38.461872
[epoch3, step125]: loss 22.419640
[epoch3, step126]: loss 17.171114
[epoch3, step127]: loss 23.607574
[epoch3, step128]: loss 18.107279
[epoch3, step129]: loss 5.158323
[epoch3, step130]: loss 13.970713
[epoch3, step131]: loss 4.311374
[epoch3, step132]: loss 9.660247
[epoch3, step133]: loss 10.473010
[epoch3, step134]: loss 4.501581
[epoch3, step135]: loss 31.475637
[epoch3, step136]: loss 12.956167
[epoch3, step137]: loss 7.534412
[epoch3, step138]: loss 28.714922
[epoch3, step139]: loss 5.981659
[epoch3, step140]: loss 8.993923
[epoch3, step141]: loss 36.515198
[epoch3, step142]: loss 5.398680
[epoch3, step143]: loss 26.937948
[epoch3, step144]: loss 27.173645
[epoch3, step145]: loss 9.568661
[epoch3, step146]: loss 5.236722
[epoch3, step147]: loss 29.834362
[epoch3, step148]: loss 27.693710
[epoch3, step149]: loss 4.304121
[epoch3, step150]: loss 2.964170
[epoch3, step151]: loss 46.723568
[epoch3, step152]: loss 19.545216
[epoch3, step153]: loss 25.823669
[epoch3, step154]: loss 2.826406
[epoch3, step155]: loss 8.080785
[epoch3, step156]: loss 25.229763
[epoch3, step157]: loss 5.652923
[epoch3, step158]: loss 10.137356
[epoch3, step159]: loss 38.075687
[epoch3, step160]: loss 2.911448
[epoch3, step161]: loss 3.945580
[epoch3, step162]: loss 16.677822
[epoch3, step163]: loss 38.231007
[epoch3, step164]: loss 9.655084
[epoch3, step165]: loss 10.727892
[epoch3, step166]: loss 12.974076
[epoch3, step167]: loss 28.918116
[epoch3, step168]: loss 9.103455
[epoch3, step169]: loss 32.676815
[epoch3, step170]: loss 25.103174
[epoch3, step171]: loss 11.574888
[epoch3, step172]: loss 27.473331
[epoch3, step173]: loss 44.283562
[epoch3, step174]: loss 64.068588
[epoch3, step175]: loss 5.597844
[epoch3, step176]: loss 7.538494
[epoch3, step177]: loss 21.121153
[epoch3, step178]: loss 21.951984
[epoch3, step179]: loss 4.116797
[epoch3, step180]: loss 49.415657
[epoch3, step181]: loss 9.689443
[epoch3, step182]: loss 12.269335
[epoch3, step183]: loss 9.380727
[epoch3, step184]: loss 7.409289
[epoch3, step185]: loss 5.759458
[epoch3, step186]: loss 15.146530
[epoch3, step187]: loss 33.591328
[epoch3, step188]: loss 6.616554
[epoch3, step189]: loss 3.898971
[epoch3, step190]: loss 13.284753
[epoch3, step191]: loss 7.315762
[epoch3, step192]: loss 24.435833
[epoch3, step193]: loss 28.613317
[epoch3, step194]: loss 11.551996
[epoch3, step195]: loss 6.361716
[epoch3, step196]: loss 21.465097
[epoch3, step197]: loss 21.066704
[epoch3, step198]: loss 34.316238
[epoch3, step199]: loss 16.213884
[epoch3, step200]: loss 30.874907
[epoch3, step201]: loss 25.174980
[epoch3, step202]: loss 16.608160
[epoch3, step203]: loss 11.271965
[epoch3, step204]: loss 31.229998
[epoch3, step205]: loss 52.497223
[epoch3, step206]: loss 10.706407
[epoch3, step207]: loss 6.119817
[epoch3, step208]: loss 5.602685
[epoch3, step209]: loss 19.702526
[epoch3, step210]: loss 25.230854
[epoch3, step211]: loss 5.658985
[epoch3, step212]: loss 5.404334
[epoch3, step213]: loss 7.003516
[epoch3, step214]: loss 17.233683
[epoch3, step215]: loss 20.776787
[epoch3, step216]: loss 27.643227
[epoch3, step217]: loss 4.118248
[epoch3, step218]: loss 4.105371
[epoch3, step219]: loss 12.021380
[epoch3, step220]: loss 5.789442
[epoch3, step221]: loss 8.522738
[epoch3, step222]: loss 7.342556
[epoch3, step223]: loss 21.882341
[epoch3, step224]: loss 4.818574
[epoch3, step225]: loss 9.406544
[epoch3, step226]: loss 9.848509
[epoch3, step227]: loss 65.683372
[epoch3, step228]: loss 4.634117
[epoch3, step229]: loss 40.891712
[epoch3, step230]: loss 11.878674
[epoch3, step231]: loss 6.594222
[epoch3, step232]: loss 27.793240
[epoch3, step233]: loss 11.204663
[epoch3, step234]: loss 36.921875
[epoch3, step235]: loss 5.150142
[epoch3, step236]: loss 16.514648
[epoch3, step237]: loss 9.914738
[epoch3, step238]: loss 10.902205
[epoch3, step239]: loss 6.111099
[epoch3, step240]: loss 57.075100
[epoch3, step241]: loss 5.483228
[epoch3, step242]: loss 4.847867
[epoch3, step243]: loss 42.132412
[epoch3, step244]: loss 7.802937
[epoch3, step245]: loss 28.493250
[epoch3, step246]: loss 5.547119
[epoch3, step247]: loss 6.301844
[epoch3, step248]: loss 10.745512
[epoch3, step249]: loss 33.758987
[epoch3, step250]: loss 11.631065
[epoch3, step251]: loss 8.337754
[epoch3, step252]: loss 44.564972
[epoch3, step253]: loss 6.634880
[epoch3, step254]: loss 10.433401
[epoch3, step255]: loss 47.759987
[epoch3, step256]: loss 8.955834
[epoch3, step257]: loss 9.841914
[epoch3, step258]: loss 5.448563
[epoch3, step259]: loss 3.672625
[epoch3, step260]: loss 30.654747
[epoch3, step261]: loss 8.311056
[epoch3, step262]: loss 8.887124
[epoch3, step263]: loss 14.191298
[epoch3, step264]: loss 26.382191
[epoch3, step265]: loss 3.956907
[epoch3, step266]: loss 9.535980
[epoch3, step267]: loss 30.990799
[epoch3, step268]: loss 80.732048
[epoch3, step269]: loss 3.117721
[epoch3, step270]: loss 29.902678
[epoch3, step271]: loss 11.678405
[epoch3, step272]: loss 23.822117
[epoch3, step273]: loss 15.192446
[epoch3, step274]: loss 18.859894
[epoch3, step275]: loss 7.435294
[epoch3, step276]: loss 5.575354
[epoch3, step277]: loss 3.511296
[epoch3, step278]: loss 11.527302
[epoch3, step279]: loss 16.397373
[epoch3, step280]: loss 22.885183
[epoch3, step281]: loss 22.156225
[epoch3, step282]: loss 24.706085
[epoch3, step283]: loss 19.128992
[epoch3, step284]: loss 38.355244
[epoch3, step285]: loss 30.928671
[epoch3, step286]: loss 5.360918
[epoch3, step287]: loss 51.190010
[epoch3, step288]: loss 5.053318
[epoch3, step289]: loss 39.990936
[epoch3, step290]: loss 9.807560
[epoch3, step291]: loss 9.119419
[epoch3, step292]: loss 3.369659
[epoch3, step293]: loss 18.661180
[epoch3, step294]: loss 7.877988
[epoch3, step295]: loss 28.309048
[epoch3, step296]: loss 9.380919
[epoch3, step297]: loss 6.873963
[epoch3, step298]: loss 17.385765
[epoch3, step299]: loss 10.716763
[epoch3, step300]: loss 18.323267
[epoch3, step301]: loss 8.750636
[epoch3, step302]: loss 28.063110
[epoch3, step303]: loss 20.755997
[epoch3, step304]: loss 12.672729
[epoch3, step305]: loss 10.172712
[epoch3, step306]: loss 13.819679
[epoch3, step307]: loss 7.876580
[epoch3, step308]: loss 5.283954
[epoch3, step309]: loss 4.955540
[epoch3, step310]: loss 35.932758
[epoch3, step311]: loss 7.325301
[epoch3, step312]: loss 3.464013
[epoch3, step313]: loss 6.511805
[epoch3, step314]: loss 66.876198
[epoch3, step315]: loss 25.458496
[epoch3, step316]: loss 5.899386
[epoch3, step317]: loss 7.123115
[epoch3, step318]: loss 28.762175
[epoch3, step319]: loss 5.766282
[epoch3, step320]: loss 12.029449
[epoch3, step321]: loss 39.645569
[epoch3, step322]: loss 7.542439
[epoch3, step323]: loss 6.750617
[epoch3, step324]: loss 6.632080
[epoch3, step325]: loss 5.788265
[epoch3, step326]: loss 8.667106
[epoch3, step327]: loss 51.060940
[epoch3, step328]: loss 25.676216
[epoch3, step329]: loss 18.453415
[epoch3, step330]: loss 6.778882
[epoch3, step331]: loss 9.787194
[epoch3, step332]: loss 21.900557
[epoch3, step333]: loss 6.774389
[epoch3, step334]: loss 26.168686
[epoch3, step335]: loss 4.436149
[epoch3, step336]: loss 11.094297
[epoch3, step337]: loss 8.713936
[epoch3, step338]: loss 6.134161
[epoch3, step339]: loss 13.775923
[epoch3, step340]: loss 43.734879
[epoch3, step341]: loss 7.294608
[epoch3, step342]: loss 8.012307
[epoch3, step343]: loss 24.783258
[epoch3, step344]: loss 12.681558
[epoch3, step345]: loss 27.991379
[epoch3, step346]: loss 4.295242
[epoch3, step347]: loss 55.060455
[epoch3, step348]: loss 6.472514
[epoch3, step349]: loss 27.564314
[epoch3, step350]: loss 19.870415
[epoch3, step351]: loss 47.912163
[epoch3, step352]: loss 2.896841
[epoch3, step353]: loss 25.934788
[epoch3, step354]: loss 16.854206
[epoch3, step355]: loss 6.045799
[epoch3, step356]: loss 6.863487
[epoch3, step357]: loss 35.709808
[epoch3, step358]: loss 25.648514
[epoch3, step359]: loss 28.618332
[epoch3, step360]: loss 8.725204
[epoch3, step361]: loss 40.394135
[epoch3, step362]: loss 39.476032
[epoch3, step363]: loss 10.115588
[epoch3, step364]: loss 46.225128
[epoch3, step365]: loss 3.718083
[epoch3, step366]: loss 4.132675
[epoch3, step367]: loss 22.456125
[epoch3, step368]: loss 20.633566
[epoch3, step369]: loss 29.965067
[epoch3, step370]: loss 11.006571
[epoch3, step371]: loss 30.766916
[epoch3, step372]: loss 5.510274
[epoch3, step373]: loss 4.855560
[epoch3, step374]: loss 13.894326
[epoch3, step375]: loss 6.137232
[epoch3, step376]: loss 8.490458
[epoch3, step377]: loss 7.941442
[epoch3, step378]: loss 3.962771
[epoch3, step379]: loss 10.690238
[epoch3, step380]: loss 13.578381
[epoch3, step381]: loss 2.697368
[epoch3, step382]: loss 8.000462
[epoch3, step383]: loss 8.067499
[epoch3, step384]: loss 7.192905
[epoch3, step385]: loss 6.492490
[epoch3, step386]: loss 14.783803
[epoch3, step387]: loss 29.097906
[epoch3, step388]: loss 5.123203
[epoch3, step389]: loss 6.819477
[epoch3, step390]: loss 39.630421
[epoch3, step391]: loss 8.768994
[epoch3, step392]: loss 6.538813
[epoch3, step393]: loss 5.964472
[epoch3, step394]: loss 16.605803
[epoch3, step395]: loss 9.605600
[epoch3, step396]: loss 2.719520
[epoch3, step397]: loss 26.559261
[epoch3, step398]: loss 3.971400
[epoch3, step399]: loss 28.047831
[epoch3, step400]: loss 33.222633
[epoch3, step401]: loss 22.179794
[epoch3, step402]: loss 2.361973
[epoch3, step403]: loss 16.540443
[epoch3, step404]: loss 10.707844
[epoch3, step405]: loss 19.607815
[epoch3, step406]: loss 21.113035
[epoch3, step407]: loss 6.591671
[epoch3, step408]: loss 8.256512
[epoch3, step409]: loss 8.351213
[epoch3, step410]: loss 55.460991
[epoch3, step411]: loss 18.474125
[epoch3, step412]: loss 24.308735
[epoch3, step413]: loss 9.011865
[epoch3, step414]: loss 5.782322
[epoch3, step415]: loss 5.173669
[epoch3, step416]: loss 9.557869
[epoch3, step417]: loss 20.542948
[epoch3, step418]: loss 6.021260
[epoch3, step419]: loss 7.420640
[epoch3, step420]: loss 22.119287
[epoch3, step421]: loss 26.182638
[epoch3, step422]: loss 3.423957
[epoch3, step423]: loss 30.784416
[epoch3, step424]: loss 10.338433
[epoch3, step425]: loss 23.306427
[epoch3, step426]: loss 5.676559
[epoch3, step427]: loss 5.742232
[epoch3, step428]: loss 24.724947
[epoch3, step429]: loss 36.364170
[epoch3, step430]: loss 9.309305
[epoch3, step431]: loss 26.697708
[epoch3, step432]: loss 20.183594
[epoch3, step433]: loss 6.180739
[epoch3, step434]: loss 3.548377
[epoch3, step435]: loss 10.016932
[epoch3, step436]: loss 9.940809
[epoch3, step437]: loss 21.043976
[epoch3, step438]: loss 3.982403
[epoch3, step439]: loss 23.370090
[epoch3, step440]: loss 7.849439
[epoch3, step441]: loss 24.978893
[epoch3, step442]: loss 24.448360
[epoch3, step443]: loss 31.904020
[epoch3, step444]: loss 31.064754
[epoch3, step445]: loss 28.698296
[epoch3, step446]: loss 16.037449
[epoch3, step447]: loss 28.236904
[epoch3, step448]: loss 7.830739
[epoch3, step449]: loss 38.312798
[epoch3, step450]: loss 14.084761
[epoch3, step451]: loss 3.333648
[epoch3, step452]: loss 40.451126
[epoch3, step453]: loss 3.849104
[epoch3, step454]: loss 47.090759
[epoch3, step455]: loss 6.400662
[epoch3, step456]: loss 2.768606
[epoch3, step457]: loss 2.641755
[epoch3, step458]: loss 9.633842
[epoch3, step459]: loss 4.989365
[epoch3, step460]: loss 9.866613
[epoch3, step461]: loss 18.780754
[epoch3, step462]: loss 8.106674
[epoch3, step463]: loss 6.704541
[epoch3, step464]: loss 36.930676
[epoch3, step465]: loss 34.063793
[epoch3, step466]: loss 9.054530
[epoch3, step467]: loss 7.878137
[epoch3, step468]: loss 8.601122
[epoch3, step469]: loss 7.723258
[epoch3, step470]: loss 6.850117
[epoch3, step471]: loss 14.045518
[epoch3, step472]: loss 4.033378
[epoch3, step473]: loss 8.646584
[epoch3, step474]: loss 18.726851
[epoch3, step475]: loss 16.455681
[epoch3, step476]: loss 26.243176
[epoch3, step477]: loss 44.303261
[epoch3, step478]: loss 5.578917
[epoch3, step479]: loss 32.685165
[epoch3, step480]: loss 6.322834
[epoch3, step481]: loss 2.638237
[epoch3, step482]: loss 25.264088
[epoch3, step483]: loss 35.002186
[epoch3, step484]: loss 3.587498
[epoch3, step485]: loss 39.654613
[epoch3, step486]: loss 10.819143
[epoch3, step487]: loss 4.738801
[epoch3, step488]: loss 19.276470
[epoch3, step489]: loss 9.693705
[epoch3, step490]: loss 22.259361
[epoch3, step491]: loss 3.540835
[epoch3, step492]: loss 11.939373
[epoch3, step493]: loss 2.292692
[epoch3, step494]: loss 24.698717
[epoch3, step495]: loss 30.217197
[epoch3, step496]: loss 26.732208
[epoch3, step497]: loss 2.924532
[epoch3, step498]: loss 11.519405
[epoch3, step499]: loss 58.297676
[epoch3, step500]: loss 14.182839
[epoch3, step501]: loss 31.226715
[epoch3, step502]: loss 19.104786
[epoch3, step503]: loss 28.425152
[epoch3, step504]: loss 6.538727
[epoch3, step505]: loss 28.036507
[epoch3, step506]: loss 2.534604
[epoch3, step507]: loss 8.626552
[epoch3, step508]: loss 16.336475
[epoch3, step509]: loss 10.232106
[epoch3, step510]: loss 3.816275
[epoch3, step511]: loss 7.009294
[epoch3, step512]: loss 7.300400
[epoch3, step513]: loss 12.599510
[epoch3, step514]: loss 11.060565
[epoch3, step515]: loss 5.962977
[epoch3, step516]: loss 3.545697
[epoch3, step517]: loss 3.015172
[epoch3, step518]: loss 3.175637
[epoch3, step519]: loss 7.368180
[epoch3, step520]: loss 20.834663
[epoch3, step521]: loss 7.125997
[epoch3, step522]: loss 7.342561
[epoch3, step523]: loss 21.881840
[epoch3, step524]: loss 27.981525
[epoch3, step525]: loss 22.026257
[epoch3, step526]: loss 7.192094
[epoch3, step527]: loss 3.798294
[epoch3, step528]: loss 10.168129
[epoch3, step529]: loss 3.949545
[epoch3, step530]: loss 2.435488
[epoch3, step531]: loss 9.826081
[epoch3, step532]: loss 14.944311
[epoch3, step533]: loss 29.865749
[epoch3, step534]: loss 9.483788
[epoch3, step535]: loss 27.123217
[epoch3, step536]: loss 15.775053
[epoch3, step537]: loss 4.396491
[epoch3, step538]: loss 24.285753
[epoch3, step539]: loss 31.106333
[epoch3, step540]: loss 9.963574
[epoch3, step541]: loss 12.131924
[epoch3, step542]: loss 15.553112
[epoch3, step543]: loss 7.980581
[epoch3, step544]: loss 6.817854
[epoch3, step545]: loss 8.021908
[epoch3, step546]: loss 25.420950
[epoch3, step547]: loss 40.643112
[epoch3, step548]: loss 24.188646
[epoch3, step549]: loss 30.681820
[epoch3, step550]: loss 25.370878
[epoch3, step551]: loss 4.825792
[epoch3, step552]: loss 24.720665
[epoch3, step553]: loss 24.479446
[epoch3, step554]: loss 3.270497
[epoch3, step555]: loss 30.416113
[epoch3, step556]: loss 2.560644
[epoch3, step557]: loss 3.304173
[epoch3, step558]: loss 2.439680
[epoch3, step559]: loss 29.569592
[epoch3, step560]: loss 8.221190
[epoch3, step561]: loss 6.417906
[epoch3, step562]: loss 5.725220
[epoch3, step563]: loss 22.809525
[epoch3, step564]: loss 46.674576
[epoch3, step565]: loss 22.803782
[epoch3, step566]: loss 43.537125
[epoch3, step567]: loss 16.566988
[epoch3, step568]: loss 23.569792
[epoch3, step569]: loss 27.299122
[epoch3, step570]: loss 13.341121
[epoch3, step571]: loss 10.960114
[epoch3, step572]: loss 21.427038
[epoch3, step573]: loss 34.768753
[epoch3, step574]: loss 11.848572
[epoch3, step575]: loss 10.817528
[epoch3, step576]: loss 10.555130
[epoch3, step577]: loss 23.420254
[epoch3, step578]: loss 22.627102
[epoch3, step579]: loss 8.852385
[epoch3, step580]: loss 5.524652
[epoch3, step581]: loss 13.172429
[epoch3, step582]: loss 4.973475
[epoch3, step583]: loss 18.417902
[epoch3, step584]: loss 28.650698
[epoch3, step585]: loss 2.759805
[epoch3, step586]: loss 8.044452
[epoch3, step587]: loss 8.301252
[epoch3, step588]: loss 5.798518
[epoch3, step589]: loss 20.115726
[epoch3, step590]: loss 22.567286
[epoch3, step591]: loss 11.742897
[epoch3, step592]: loss 33.337505
[epoch3, step593]: loss 70.215782
[epoch3, step594]: loss 62.928669
[epoch3, step595]: loss 22.617153
[epoch3, step596]: loss 12.611660
[epoch3, step597]: loss 47.086205
[epoch3, step598]: loss 8.284157
[epoch3, step599]: loss 4.999585
[epoch3, step600]: loss 76.926384
[epoch3, step601]: loss 2.518732
[epoch3, step602]: loss 2.939616
[epoch3, step603]: loss 18.012836
[epoch3, step604]: loss 5.661792
[epoch3, step605]: loss 25.787266
[epoch3, step606]: loss 4.232691
[epoch3, step607]: loss 5.269684
[epoch3, step608]: loss 24.780924
[epoch3, step609]: loss 7.177373
[epoch3, step610]: loss 17.989206
[epoch3, step611]: loss 15.225056
[epoch3, step612]: loss 27.463528
[epoch3, step613]: loss 29.661926
[epoch3, step614]: loss 23.952957
[epoch3, step615]: loss 3.831998
[epoch3, step616]: loss 5.156176
[epoch3, step617]: loss 33.844994
[epoch3, step618]: loss 29.132015
[epoch3, step619]: loss 7.921954
[epoch3, step620]: loss 2.915738
[epoch3, step621]: loss 20.991940
[epoch3, step622]: loss 29.964308
[epoch3, step623]: loss 53.927902
[epoch3, step624]: loss 3.225925
[epoch3, step625]: loss 15.451207
[epoch3, step626]: loss 8.793799
[epoch3, step627]: loss 7.447381
[epoch3, step628]: loss 24.735678
[epoch3, step629]: loss 18.367760
[epoch3, step630]: loss 2.247840
[epoch3, step631]: loss 3.026133
[epoch3, step632]: loss 42.211811
[epoch3, step633]: loss 54.571678
[epoch3, step634]: loss 3.000801
[epoch3, step635]: loss 3.766776
[epoch3, step636]: loss 12.298613
[epoch3, step637]: loss 4.617207
[epoch3, step638]: loss 3.587424
[epoch3, step639]: loss 10.319523
[epoch3, step640]: loss 7.402501
[epoch3, step641]: loss 54.463200
[epoch3, step642]: loss 7.628441
[epoch3, step643]: loss 4.532668
[epoch3, step644]: loss 3.060091
[epoch3, step645]: loss 13.172501
[epoch3, step646]: loss 8.855743
[epoch3, step647]: loss 2.640623
[epoch3, step648]: loss 5.453784
[epoch3, step649]: loss 14.097680
[epoch3, step650]: loss 40.274933
[epoch3, step651]: loss 14.476082
[epoch3, step652]: loss 25.725182
[epoch3, step653]: loss 6.704745
[epoch3, step654]: loss 5.934391
[epoch3, step655]: loss 32.166878
[epoch3, step656]: loss 4.735367
[epoch3, step657]: loss 6.876168
[epoch3, step658]: loss 9.307547
[epoch3, step659]: loss 18.739998
[epoch3, step660]: loss 9.324748
[epoch3, step661]: loss 7.951893
[epoch3, step662]: loss 4.976447
[epoch3, step663]: loss 4.312891
[epoch3, step664]: loss 7.213110
[epoch3, step665]: loss 8.240580
[epoch3, step666]: loss 12.867218
[epoch3, step667]: loss 13.602798
[epoch3, step668]: loss 5.294523
[epoch3, step669]: loss 38.509102
[epoch3, step670]: loss 30.654337
[epoch3, step671]: loss 6.089355
[epoch3, step672]: loss 30.622665
[epoch3, step673]: loss 7.703025
[epoch3, step674]: loss 5.059257
[epoch3, step675]: loss 12.824839
[epoch3, step676]: loss 5.451550
[epoch3, step677]: loss 23.773256
[epoch3, step678]: loss 24.693712
[epoch3, step679]: loss 19.969276
[epoch3, step680]: loss 13.576391
[epoch3, step681]: loss 27.551409
[epoch3, step682]: loss 18.445694
[epoch3, step683]: loss 19.811634
[epoch3, step684]: loss 9.988806
[epoch3, step685]: loss 75.437561
[epoch3, step686]: loss 9.388658
[epoch3, step687]: loss 7.386793
[epoch3, step688]: loss 12.985726
[epoch3, step689]: loss 51.449127
[epoch3, step690]: loss 17.226822
[epoch3, step691]: loss 33.938538
[epoch3, step692]: loss 5.564302
[epoch3, step693]: loss 21.726086
[epoch3, step694]: loss 9.335159
[epoch3, step695]: loss 20.012558
[epoch3, step696]: loss 52.036682
[epoch3, step697]: loss 28.283726
[epoch3, step698]: loss 20.859463
[epoch3, step699]: loss 8.443340
[epoch3, step700]: loss 10.205709
[epoch3, step701]: loss 18.699757
[epoch3, step702]: loss 6.366611
[epoch3, step703]: loss 11.723807
[epoch3, step704]: loss 17.370661
[epoch3, step705]: loss 29.298672
[epoch3, step706]: loss 7.124578
[epoch3, step707]: loss 7.414021
[epoch3, step708]: loss 26.112286
[epoch3, step709]: loss 3.222821
[epoch3, step710]: loss 25.763401
[epoch3, step711]: loss 2.994811
[epoch3, step712]: loss 9.441565
[epoch3, step713]: loss 3.953221
[epoch3, step714]: loss 9.598524
[epoch3, step715]: loss 8.654140
[epoch3, step716]: loss 20.281315
[epoch3, step717]: loss 5.262271
[epoch3, step718]: loss 6.318577
[epoch3, step719]: loss 30.201670
[epoch3, step720]: loss 12.322469
[epoch3, step721]: loss 7.652555
[epoch3, step722]: loss 19.726412
[epoch3, step723]: loss 11.958760
[epoch3, step724]: loss 4.668941
[epoch3, step725]: loss 15.929641
[epoch3, step726]: loss 21.028290
[epoch3, step727]: loss 17.464760
[epoch3, step728]: loss 10.031392
[epoch3, step729]: loss 6.556801
[epoch3, step730]: loss 6.324238
[epoch3, step731]: loss 26.366222
[epoch3, step732]: loss 14.217601
[epoch3, step733]: loss 5.123993
[epoch3, step734]: loss 8.201159
[epoch3, step735]: loss 6.109498
[epoch3, step736]: loss 40.597931
[epoch3, step737]: loss 11.094923
[epoch3, step738]: loss 8.630837
[epoch3, step739]: loss 4.096103
[epoch3, step740]: loss 22.681372
[epoch3, step741]: loss 2.367136
[epoch3, step742]: loss 4.155135
[epoch3, step743]: loss 24.141375
[epoch3, step744]: loss 5.260278
[epoch3, step745]: loss 22.500319
[epoch3, step746]: loss 24.398443
[epoch3, step747]: loss 6.721143
[epoch3, step748]: loss 5.017583
[epoch3, step749]: loss 23.329512
[epoch3, step750]: loss 38.991524
[epoch3, step751]: loss 22.903431
[epoch3, step752]: loss 5.382728
[epoch3, step753]: loss 20.238947
[epoch3, step754]: loss 19.696114
[epoch3, step755]: loss 7.425776
[epoch3, step756]: loss 9.545406
[epoch3, step757]: loss 4.921508
[epoch3, step758]: loss 12.273296
[epoch3, step759]: loss 6.538507
[epoch3, step760]: loss 4.926092
[epoch3, step761]: loss 4.172987
[epoch3, step762]: loss 18.837448
[epoch3, step763]: loss 42.074684
[epoch3, step764]: loss 7.014615
[epoch3, step765]: loss 36.228016
[epoch3, step766]: loss 3.134136
[epoch3, step767]: loss 10.268394
[epoch3, step768]: loss 4.127270
[epoch3, step769]: loss 28.904194
[epoch3, step770]: loss 26.410883
[epoch3, step771]: loss 28.472242
[epoch3, step772]: loss 46.446724
[epoch3, step773]: loss 4.722755
[epoch3, step774]: loss 10.719927
[epoch3, step775]: loss 5.439021
[epoch3, step776]: loss 31.138281
[epoch3, step777]: loss 7.651779
[epoch3, step778]: loss 6.203308
[epoch3, step779]: loss 8.157248
[epoch3, step780]: loss 6.498021
[epoch3, step781]: loss 23.061651
[epoch3, step782]: loss 4.558949
[epoch3, step783]: loss 4.537282
[epoch3, step784]: loss 12.621653
[epoch3, step785]: loss 6.307920
[epoch3, step786]: loss 6.503428
[epoch3, step787]: loss 16.444254
[epoch3, step788]: loss 30.396030
[epoch3, step789]: loss 11.965450
[epoch3, step790]: loss 9.551069
[epoch3, step791]: loss 41.675777
[epoch3, step792]: loss 29.838509
[epoch3, step793]: loss 34.442406
[epoch3, step794]: loss 4.471892
[epoch3, step795]: loss 8.369174
[epoch3, step796]: loss 3.796628
[epoch3, step797]: loss 16.347963
[epoch3, step798]: loss 24.925108
[epoch3, step799]: loss 5.823977
[epoch3, step800]: loss 56.905975
[epoch3, step801]: loss 13.796377
[epoch3, step802]: loss 30.608389
[epoch3, step803]: loss 23.380810
[epoch3, step804]: loss 14.583914
[epoch3, step805]: loss 2.778960
[epoch3, step806]: loss 26.100422
[epoch3, step807]: loss 40.793839
[epoch3, step808]: loss 3.525363
[epoch3, step809]: loss 19.614037
[epoch3, step810]: loss 9.894803
[epoch3, step811]: loss 11.629499
[epoch3, step812]: loss 23.554628
[epoch3, step813]: loss 33.618534
[epoch3, step814]: loss 11.901153
[epoch3, step815]: loss 4.996418
[epoch3, step816]: loss 19.017572
[epoch3, step817]: loss 23.381136
[epoch3, step818]: loss 5.537181
[epoch3, step819]: loss 43.541687
[epoch3, step820]: loss 28.536842
[epoch3, step821]: loss 23.167280
[epoch3, step822]: loss 40.582626
[epoch3, step823]: loss 17.819475
[epoch3, step824]: loss 4.992311
[epoch3, step825]: loss 6.053133
[epoch3, step826]: loss 3.630941
[epoch3, step827]: loss 21.752182
[epoch3, step828]: loss 18.576721
[epoch3, step829]: loss 3.871258
[epoch3, step830]: loss 2.440876
[epoch3, step831]: loss 8.025362
[epoch3, step832]: loss 36.048500
[epoch3, step833]: loss 21.122238
[epoch3, step834]: loss 5.239242
[epoch3, step835]: loss 8.403962
[epoch3, step836]: loss 13.977636
[epoch3, step837]: loss 22.054779
[epoch3, step838]: loss 23.116327
[epoch3, step839]: loss 25.605307
[epoch3, step840]: loss 2.438541
[epoch3, step841]: loss 28.371204
[epoch3, step842]: loss 10.233059
[epoch3, step843]: loss 7.507799
[epoch3, step844]: loss 3.830572
[epoch3, step845]: loss 8.875251
[epoch3, step846]: loss 19.065405
[epoch3, step847]: loss 2.431649
[epoch3, step848]: loss 8.007071
[epoch3, step849]: loss 48.735992
[epoch3, step850]: loss 15.607717
[epoch3, step851]: loss 6.779343
[epoch3, step852]: loss 9.068333
[epoch3, step853]: loss 26.238174
[epoch3, step854]: loss 10.209539
[epoch3, step855]: loss 11.683423
[epoch3, step856]: loss 20.758625
[epoch3, step857]: loss 4.811880
[epoch3, step858]: loss 24.451168
[epoch3, step859]: loss 21.595655
[epoch3, step860]: loss 49.227608
[epoch3, step861]: loss 14.137934
[epoch3, step862]: loss 6.431547
[epoch3, step863]: loss 19.483679
[epoch3, step864]: loss 24.151276
[epoch3, step865]: loss 20.820938
[epoch3, step866]: loss 3.482155
[epoch3, step867]: loss 7.879173
[epoch3, step868]: loss 35.980793
[epoch3, step869]: loss 2.822002
[epoch3, step870]: loss 69.807091
[epoch3, step871]: loss 4.859290
[epoch3, step872]: loss 4.678538
[epoch3, step873]: loss 7.965401
[epoch3, step874]: loss 11.810158
[epoch3, step875]: loss 26.677500
[epoch3, step876]: loss 11.940142
[epoch3, step877]: loss 4.711760
[epoch3, step878]: loss 2.966992
[epoch3, step879]: loss 36.262222
[epoch3, step880]: loss 33.466148
[epoch3, step881]: loss 11.913971
[epoch3, step882]: loss 28.238770
[epoch3, step883]: loss 5.635734
[epoch3, step884]: loss 44.262875
[epoch3, step885]: loss 36.334057
[epoch3, step886]: loss 12.632086
[epoch3, step887]: loss 12.435265
[epoch3, step888]: loss 4.048338
[epoch3, step889]: loss 4.830852
[epoch3, step890]: loss 65.565422
[epoch3, step891]: loss 42.165604
[epoch3, step892]: loss 6.312765
[epoch3, step893]: loss 20.390968
[epoch3, step894]: loss 11.906199
[epoch3, step895]: loss 12.188541
[epoch3, step896]: loss 4.981369
[epoch3, step897]: loss 8.237582
[epoch3, step898]: loss 10.666928
[epoch3, step899]: loss 10.944611
[epoch3, step900]: loss 5.406752
[epoch3, step901]: loss 5.790359
[epoch3, step902]: loss 6.969902
[epoch3, step903]: loss 22.773689
[epoch3, step904]: loss 11.694485
[epoch3, step905]: loss 9.078444
[epoch3, step906]: loss 3.091778
[epoch3, step907]: loss 9.592923
[epoch3, step908]: loss 27.868122
[epoch3, step909]: loss 23.016602
[epoch3, step910]: loss 11.409645
[epoch3, step911]: loss 6.372581
[epoch3, step912]: loss 4.662736
[epoch3, step913]: loss 38.798950
[epoch3, step914]: loss 7.450856
[epoch3, step915]: loss 11.260698
[epoch3, step916]: loss 6.353252
[epoch3, step917]: loss 32.620979
[epoch3, step918]: loss 3.209136
[epoch3, step919]: loss 4.896073
[epoch3, step920]: loss 1.999627
[epoch3, step921]: loss 17.007862
[epoch3, step922]: loss 59.211582
[epoch3, step923]: loss 5.702064
[epoch3, step924]: loss 5.417675
[epoch3, step925]: loss 26.301376
[epoch3, step926]: loss 13.847507
[epoch3, step927]: loss 8.432495
[epoch3, step928]: loss 12.501014
[epoch3, step929]: loss 29.888220
[epoch3, step930]: loss 25.540520
[epoch3, step931]: loss 25.296236
[epoch3, step932]: loss 11.129861
[epoch3, step933]: loss 4.609612
[epoch3, step934]: loss 16.649660
[epoch3, step935]: loss 5.803952
[epoch3, step936]: loss 2.929931
[epoch3, step937]: loss 5.286031
[epoch3, step938]: loss 49.232979
[epoch3, step939]: loss 5.476559
[epoch3, step940]: loss 8.043708
[epoch3, step941]: loss 3.229777
[epoch3, step942]: loss 36.189175
[epoch3, step943]: loss 4.121737
[epoch3, step944]: loss 49.869972
[epoch3, step945]: loss 8.224513
[epoch3, step946]: loss 5.432215
[epoch3, step947]: loss 23.100765
[epoch3, step948]: loss 28.072479
[epoch3, step949]: loss 9.662802
[epoch3, step950]: loss 40.709274
[epoch3, step951]: loss 27.984100
[epoch3, step952]: loss 14.956391
[epoch3, step953]: loss 26.059780
[epoch3, step954]: loss 3.242744
[epoch3, step955]: loss 7.859327
[epoch3, step956]: loss 6.211432
[epoch3, step957]: loss 28.983984
[epoch3, step958]: loss 24.697031
[epoch3, step959]: loss 13.207362
[epoch3, step960]: loss 15.529084
[epoch3, step961]: loss 12.681304
[epoch3, step962]: loss 5.637343
[epoch3, step963]: loss 30.507854
[epoch3, step964]: loss 25.344189
[epoch3, step965]: loss 6.876093
[epoch3, step966]: loss 32.847862
[epoch3, step967]: loss 6.999505
[epoch3, step968]: loss 18.819210
[epoch3, step969]: loss 23.950638
[epoch3, step970]: loss 4.457026
[epoch3, step971]: loss 11.816847
[epoch3, step972]: loss 25.766409
[epoch3, step973]: loss 50.152081
[epoch3, step974]: loss 11.036094
[epoch3, step975]: loss 12.448100
[epoch3, step976]: loss 2.771708
[epoch3, step977]: loss 59.810257
[epoch3, step978]: loss 27.394394
[epoch3, step979]: loss 2.632503
[epoch3, step980]: loss 10.041159
[epoch3, step981]: loss 6.239817
[epoch3, step982]: loss 15.069254
[epoch3, step983]: loss 45.815727
[epoch3, step984]: loss 4.015892
[epoch3, step985]: loss 16.163651
[epoch3, step986]: loss 6.254580
[epoch3, step987]: loss 2.633804
[epoch3, step988]: loss 4.698883
[epoch3, step989]: loss 10.918133
[epoch3, step990]: loss 11.830565
[epoch3, step991]: loss 24.852402
[epoch3, step992]: loss 6.065688
[epoch3, step993]: loss 34.735806
[epoch3, step994]: loss 17.156321
[epoch3, step995]: loss 18.269156
[epoch3, step996]: loss 3.554925
[epoch3, step997]: loss 5.708012
[epoch3, step998]: loss 13.247229
[epoch3, step999]: loss 6.861682
[epoch3, step1000]: loss 5.181114
[epoch3, step1001]: loss 30.331385
[epoch3, step1002]: loss 8.398750
[epoch3, step1003]: loss 12.261562
[epoch3, step1004]: loss 13.013235
[epoch3, step1005]: loss 8.597244
[epoch3, step1006]: loss 25.134352
[epoch3, step1007]: loss 56.751678
[epoch3, step1008]: loss 4.122444
[epoch3, step1009]: loss 27.465965
[epoch3, step1010]: loss 9.863222
[epoch3, step1011]: loss 6.328136
[epoch3, step1012]: loss 39.657974
[epoch3, step1013]: loss 8.729356
[epoch3, step1014]: loss 31.068707
[epoch3, step1015]: loss 2.710200
[epoch3, step1016]: loss 6.562653
[epoch3, step1017]: loss 21.424370
[epoch3, step1018]: loss 7.126621
[epoch3, step1019]: loss 20.783865
[epoch3, step1020]: loss 4.521506
[epoch3, step1021]: loss 12.599953
[epoch3, step1022]: loss 38.484959
[epoch3, step1023]: loss 5.351240
[epoch3, step1024]: loss 8.206470
[epoch3, step1025]: loss 36.035774
[epoch3, step1026]: loss 3.472260
[epoch3, step1027]: loss 21.994352
[epoch3, step1028]: loss 20.263100
[epoch3, step1029]: loss 22.767193
[epoch3, step1030]: loss 2.443344
[epoch3, step1031]: loss 2.925718
[epoch3, step1032]: loss 6.723369
[epoch3, step1033]: loss 5.966961
[epoch3, step1034]: loss 34.164711
[epoch3, step1035]: loss 17.542917
[epoch3, step1036]: loss 11.494328
[epoch3, step1037]: loss 3.657398
[epoch3, step1038]: loss 19.384903
[epoch3, step1039]: loss 4.316877
[epoch3, step1040]: loss 43.423328
[epoch3, step1041]: loss 24.734167
[epoch3, step1042]: loss 30.195705
[epoch3, step1043]: loss 5.455759
[epoch3, step1044]: loss 6.155269
[epoch3, step1045]: loss 38.235134
[epoch3, step1046]: loss 13.100967
[epoch3, step1047]: loss 82.443169
[epoch3, step1048]: loss 4.289059
[epoch3, step1049]: loss 2.635044
[epoch3, step1050]: loss 2.529140
[epoch3, step1051]: loss 2.678633
[epoch3, step1052]: loss 11.614442
[epoch3, step1053]: loss 12.502082
[epoch3, step1054]: loss 31.903471
[epoch3, step1055]: loss 5.776251
[epoch3, step1056]: loss 9.856429
[epoch3, step1057]: loss 37.061668
[epoch3, step1058]: loss 20.180761
[epoch3, step1059]: loss 35.672855
[epoch3, step1060]: loss 14.485321
[epoch3, step1061]: loss 5.995732
[epoch3, step1062]: loss 35.814445
[epoch3, step1063]: loss 6.360435
[epoch3, step1064]: loss 9.504851
[epoch3, step1065]: loss 13.191516
[epoch3, step1066]: loss 9.858317
[epoch3, step1067]: loss 42.113194
[epoch3, step1068]: loss 6.551954
[epoch3, step1069]: loss 4.813711
[epoch3, step1070]: loss 8.861972
[epoch3, step1071]: loss 13.521768
[epoch3, step1072]: loss 27.300274
[epoch3, step1073]: loss 4.704676
[epoch3, step1074]: loss 22.185575
[epoch3, step1075]: loss 9.030186
[epoch3, step1076]: loss 10.090942
[epoch3, step1077]: loss 4.891696
[epoch3, step1078]: loss 4.493947
[epoch3, step1079]: loss 23.430285
[epoch3, step1080]: loss 7.648675
[epoch3, step1081]: loss 47.625320
[epoch3, step1082]: loss 6.800278
[epoch3, step1083]: loss 3.558106
[epoch3, step1084]: loss 12.048178
[epoch3, step1085]: loss 3.362895
[epoch3, step1086]: loss 10.795988
[epoch3, step1087]: loss 24.548512
[epoch3, step1088]: loss 3.358841
[epoch3, step1089]: loss 20.523922
[epoch3, step1090]: loss 18.306667
[epoch3, step1091]: loss 7.321487
[epoch3, step1092]: loss 3.730435
[epoch3, step1093]: loss 21.853922
[epoch3, step1094]: loss 12.106714
[epoch3, step1095]: loss 51.109840
[epoch3, step1096]: loss 18.244114
[epoch3, step1097]: loss 9.338949
[epoch3, step1098]: loss 23.100910
[epoch3, step1099]: loss 9.034874
[epoch3, step1100]: loss 9.166431
[epoch3, step1101]: loss 25.056768
[epoch3, step1102]: loss 28.346859
[epoch3, step1103]: loss 22.382452
[epoch3, step1104]: loss 10.969612
[epoch3, step1105]: loss 34.052959
[epoch3, step1106]: loss 5.537680
[epoch3, step1107]: loss 22.441879
[epoch3, step1108]: loss 4.770169
[epoch3, step1109]: loss 7.808772
[epoch3, step1110]: loss 25.053877
[epoch3, step1111]: loss 7.379776
[epoch3, step1112]: loss 3.270358
[epoch3, step1113]: loss 10.301826
[epoch3, step1114]: loss 3.428225
[epoch3, step1115]: loss 24.839848
[epoch3, step1116]: loss 21.243826
[epoch3, step1117]: loss 25.518501
[epoch3, step1118]: loss 26.726288
[epoch3, step1119]: loss 5.286194
[epoch3, step1120]: loss 57.668751
[epoch3, step1121]: loss 9.788723
[epoch3, step1122]: loss 2.779297
[epoch3, step1123]: loss 9.600908
[epoch3, step1124]: loss 45.744591
[epoch3, step1125]: loss 5.038941
[epoch3, step1126]: loss 9.212669
[epoch3, step1127]: loss 5.276121
[epoch3, step1128]: loss 6.827433
[epoch3, step1129]: loss 22.959454
[epoch3, step1130]: loss 5.198601
[epoch3, step1131]: loss 5.243924
[epoch3, step1132]: loss 18.833344
[epoch3, step1133]: loss 23.535046
[epoch3, step1134]: loss 22.239998
[epoch3, step1135]: loss 4.868028
[epoch3, step1136]: loss 24.532932
[epoch3, step1137]: loss 2.767986
[epoch3, step1138]: loss 10.537930
[epoch3, step1139]: loss 20.899414
[epoch3, step1140]: loss 4.170345
[epoch3, step1141]: loss 9.813408
[epoch3, step1142]: loss 17.254564
[epoch3, step1143]: loss 11.742296
[epoch3, step1144]: loss 2.076644
[epoch3, step1145]: loss 23.862421
[epoch3, step1146]: loss 16.856358
[epoch3, step1147]: loss 11.323357
[epoch3, step1148]: loss 24.929039
[epoch3, step1149]: loss 26.606522
[epoch3, step1150]: loss 34.833649
[epoch3, step1151]: loss 8.558533
[epoch3, step1152]: loss 39.629219
[epoch3, step1153]: loss 28.312340
[epoch3, step1154]: loss 35.213139
[epoch3, step1155]: loss 25.997141
[epoch3, step1156]: loss 43.719009
[epoch3, step1157]: loss 9.351476
[epoch3, step1158]: loss 36.663567
[epoch3, step1159]: loss 33.685741
[epoch3, step1160]: loss 7.622812
[epoch3, step1161]: loss 9.021873
[epoch3, step1162]: loss 21.681667
[epoch3, step1163]: loss 5.690578
[epoch3, step1164]: loss 4.133919
[epoch3, step1165]: loss 8.849413
[epoch3, step1166]: loss 4.630851
[epoch3, step1167]: loss 4.707779
[epoch3, step1168]: loss 6.392271
[epoch3, step1169]: loss 31.080563
[epoch3, step1170]: loss 7.495242
[epoch3, step1171]: loss 23.059696
[epoch3, step1172]: loss 19.369537
[epoch3, step1173]: loss 8.020533
[epoch3, step1174]: loss 3.272092
[epoch3, step1175]: loss 9.607836
[epoch3, step1176]: loss 11.154694
[epoch3, step1177]: loss 33.537727
[epoch3, step1178]: loss 17.024069
[epoch3, step1179]: loss 9.651665
[epoch3, step1180]: loss 21.221478
[epoch3, step1181]: loss 9.575827
[epoch3, step1182]: loss 31.225969
[epoch3, step1183]: loss 23.570843
[epoch3, step1184]: loss 53.819111
[epoch3, step1185]: loss 11.236616
[epoch3, step1186]: loss 6.523947
[epoch3, step1187]: loss 20.849030
[epoch3, step1188]: loss 42.902374
[epoch3, step1189]: loss 7.815853
[epoch3, step1190]: loss 6.000386
[epoch3, step1191]: loss 3.953462
[epoch3, step1192]: loss 9.732064
[epoch3, step1193]: loss 2.918864
[epoch3, step1194]: loss 6.584168
[epoch3, step1195]: loss 6.572434
[epoch3, step1196]: loss 37.147713
[epoch3, step1197]: loss 24.388741
[epoch3, step1198]: loss 35.965229
[epoch3, step1199]: loss 7.731978
[epoch3, step1200]: loss 18.657669
[epoch3, step1201]: loss 22.980156
[epoch3, step1202]: loss 7.714335
[epoch3, step1203]: loss 13.450808
[epoch3, step1204]: loss 25.380817
[epoch3, step1205]: loss 3.474852
[epoch3, step1206]: loss 17.977486
[epoch3, step1207]: loss 3.139559
[epoch3, step1208]: loss 21.705353
[epoch3, step1209]: loss 10.323188
[epoch3, step1210]: loss 9.619602
[epoch3, step1211]: loss 12.064120
[epoch3, step1212]: loss 4.508491
[epoch3, step1213]: loss 22.733046
[epoch3, step1214]: loss 19.469160
[epoch3, step1215]: loss 7.581195
[epoch3, step1216]: loss 5.525758
[epoch3, step1217]: loss 20.082470
[epoch3, step1218]: loss 29.051929
[epoch3, step1219]: loss 15.716022
[epoch3, step1220]: loss 23.105661
[epoch3, step1221]: loss 7.247448
[epoch3, step1222]: loss 4.049482
[epoch3, step1223]: loss 10.715913
[epoch3, step1224]: loss 10.125147
[epoch3, step1225]: loss 29.905369
[epoch3, step1226]: loss 14.705823
[epoch3, step1227]: loss 8.636208
[epoch3, step1228]: loss 22.590982
[epoch3, step1229]: loss 17.515339
[epoch3, step1230]: loss 26.231070
[epoch3, step1231]: loss 7.176549
[epoch3, step1232]: loss 8.290877
[epoch3, step1233]: loss 3.193529
[epoch3, step1234]: loss 45.920849
[epoch3, step1235]: loss 12.759307
[epoch3, step1236]: loss 3.781101
[epoch3, step1237]: loss 7.005671
[epoch3, step1238]: loss 5.106134
[epoch3, step1239]: loss 2.966792
[epoch3, step1240]: loss 37.192299
[epoch3, step1241]: loss 8.878695
[epoch3, step1242]: loss 6.330297
[epoch3, step1243]: loss 22.190964
[epoch3, step1244]: loss 47.730640
[epoch3, step1245]: loss 11.783574
[epoch3, step1246]: loss 21.795975
[epoch3, step1247]: loss 21.569803
[epoch3, step1248]: loss 24.608570
[epoch3, step1249]: loss 3.688855
[epoch3, step1250]: loss 67.152451
[epoch3, step1251]: loss 5.185744
[epoch3, step1252]: loss 19.960096
[epoch3, step1253]: loss 11.565451
[epoch3, step1254]: loss 6.288371
[epoch3, step1255]: loss 25.704647
[epoch3, step1256]: loss 11.805733
[epoch3, step1257]: loss 11.998353
[epoch3, step1258]: loss 12.893829
[epoch3, step1259]: loss 15.874176
[epoch3, step1260]: loss 6.821406
[epoch3, step1261]: loss 32.014648
[epoch3, step1262]: loss 4.053410
[epoch3, step1263]: loss 23.333694
[epoch3, step1264]: loss 4.707121
[epoch3, step1265]: loss 12.141352
[epoch3, step1266]: loss 36.276146
[epoch3, step1267]: loss 6.526581
[epoch3, step1268]: loss 9.026045
[epoch3, step1269]: loss 3.790467
[epoch3, step1270]: loss 9.110248
[epoch3, step1271]: loss 17.235720
[epoch3, step1272]: loss 25.499920
[epoch3, step1273]: loss 4.801431
[epoch3, step1274]: loss 57.806774
[epoch3, step1275]: loss 4.666098
[epoch3, step1276]: loss 11.526466
[epoch3, step1277]: loss 4.413865
[epoch3, step1278]: loss 16.105261
[epoch3, step1279]: loss 8.263794
[epoch3, step1280]: loss 22.801121
[epoch3, step1281]: loss 21.835270
[epoch3, step1282]: loss 10.424853
[epoch3, step1283]: loss 4.517095
[epoch3, step1284]: loss 5.735287
[epoch3, step1285]: loss 45.911701
[epoch3, step1286]: loss 9.561705
[epoch3, step1287]: loss 10.738728
[epoch3, step1288]: loss 4.907248
[epoch3, step1289]: loss 32.096107
[epoch3, step1290]: loss 9.179352
[epoch3, step1291]: loss 18.518127
[epoch3, step1292]: loss 7.675636
[epoch3, step1293]: loss 25.526237
[epoch3, step1294]: loss 28.689577
[epoch3, step1295]: loss 9.810921
[epoch3, step1296]: loss 5.392531
[epoch3, step1297]: loss 6.861816
[epoch3, step1298]: loss 34.403545
[epoch3, step1299]: loss 64.343506
[epoch3, step1300]: loss 19.022198
[epoch3, step1301]: loss 4.948010
[epoch3, step1302]: loss 10.480783
[epoch3, step1303]: loss 34.063637
[epoch3, step1304]: loss 4.534210
[epoch3, step1305]: loss 19.488855
[epoch3, step1306]: loss 19.861418
[epoch3, step1307]: loss 6.111407
[epoch3, step1308]: loss 5.116169
[epoch3, step1309]: loss 3.975177
[epoch3, step1310]: loss 21.442116
[epoch3, step1311]: loss 28.253077
[epoch3, step1312]: loss 3.569373
[epoch3, step1313]: loss 25.343922
[epoch3, step1314]: loss 4.606748
[epoch3, step1315]: loss 24.936459
[epoch3, step1316]: loss 5.268300
[epoch3, step1317]: loss 20.148693
[epoch3, step1318]: loss 25.483454
[epoch3, step1319]: loss 4.881008
[epoch3, step1320]: loss 7.605830
[epoch3, step1321]: loss 9.519702
[epoch3, step1322]: loss 4.401322
[epoch3, step1323]: loss 25.333298
[epoch3, step1324]: loss 27.023073
[epoch3, step1325]: loss 21.630310
[epoch3, step1326]: loss 12.843705
[epoch3, step1327]: loss 5.645179
[epoch3, step1328]: loss 2.333512
[epoch3, step1329]: loss 20.481676
[epoch3, step1330]: loss 7.748142
[epoch3, step1331]: loss 19.777452
[epoch3, step1332]: loss 33.717541
[epoch3, step1333]: loss 7.226231
[epoch3, step1334]: loss 20.986490
[epoch3, step1335]: loss 63.786903
[epoch3, step1336]: loss 20.696993
[epoch3, step1337]: loss 25.308458
[epoch3, step1338]: loss 3.647468
[epoch3, step1339]: loss 22.592228
[epoch3, step1340]: loss 16.310499
[epoch3, step1341]: loss 9.949943
[epoch3, step1342]: loss 10.405042
[epoch3, step1343]: loss 5.513445
[epoch3, step1344]: loss 45.915455
[epoch3, step1345]: loss 8.492382
[epoch3, step1346]: loss 16.316439
[epoch3, step1347]: loss 6.164174
[epoch3, step1348]: loss 29.374754
[epoch3, step1349]: loss 6.427713
[epoch3, step1350]: loss 6.631852
[epoch3, step1351]: loss 27.211351
[epoch3, step1352]: loss 5.628410
[epoch3, step1353]: loss 21.879833
[epoch3, step1354]: loss 24.104832
[epoch3, step1355]: loss 4.680264
[epoch3, step1356]: loss 21.602673
[epoch3, step1357]: loss 20.525169
[epoch3, step1358]: loss 30.124937
[epoch3, step1359]: loss 12.310623
[epoch3, step1360]: loss 26.598253
[epoch3, step1361]: loss 9.364675
[epoch3, step1362]: loss 7.993389
[epoch3, step1363]: loss 6.787660
[epoch3, step1364]: loss 21.407635
[epoch3, step1365]: loss 28.171219
[epoch3, step1366]: loss 29.526131
[epoch3, step1367]: loss 35.640541
[epoch3, step1368]: loss 5.964264
[epoch3, step1369]: loss 7.871914
[epoch3, step1370]: loss 22.594004
[epoch3, step1371]: loss 25.311926
[epoch3, step1372]: loss 15.807477
[epoch3, step1373]: loss 40.606804
[epoch3, step1374]: loss 34.239346
[epoch3, step1375]: loss 8.510066
[epoch3, step1376]: loss 19.759157
[epoch3, step1377]: loss 15.044096
[epoch3, step1378]: loss 14.847172
[epoch3, step1379]: loss 4.550177
[epoch3, step1380]: loss 7.269065
[epoch3, step1381]: loss 36.979492
[epoch3, step1382]: loss 4.284501
[epoch3, step1383]: loss 2.886534
[epoch3, step1384]: loss 6.742682
[epoch3, step1385]: loss 8.862828
[epoch3, step1386]: loss 4.449926
[epoch3, step1387]: loss 2.989625
[epoch3, step1388]: loss 3.125489
[epoch3, step1389]: loss 9.491842
[epoch3, step1390]: loss 14.602735
[epoch3, step1391]: loss 7.070490
[epoch3, step1392]: loss 18.451727
[epoch3, step1393]: loss 27.926916
[epoch3, step1394]: loss 33.314991
[epoch3, step1395]: loss 10.194322
[epoch3, step1396]: loss 6.416034
[epoch3, step1397]: loss 26.716774
[epoch3, step1398]: loss 25.630997
[epoch3, step1399]: loss 18.325148
[epoch3, step1400]: loss 32.335976
[epoch3, step1401]: loss 5.979489
[epoch3, step1402]: loss 3.523420
[epoch3, step1403]: loss 13.969662
[epoch3, step1404]: loss 11.018768
[epoch3, step1405]: loss 11.343620
[epoch3, step1406]: loss 4.101060
[epoch3, step1407]: loss 9.411932
[epoch3, step1408]: loss 2.483346
[epoch3, step1409]: loss 10.782874
[epoch3, step1410]: loss 23.405886
[epoch3, step1411]: loss 32.096790
[epoch3, step1412]: loss 9.541389
[epoch3, step1413]: loss 2.504178
[epoch3, step1414]: loss 9.295623
[epoch3, step1415]: loss 10.015467
[epoch3, step1416]: loss 7.535230
[epoch3, step1417]: loss 16.400700
[epoch3, step1418]: loss 3.082895
[epoch3, step1419]: loss 8.287333
[epoch3, step1420]: loss 19.862179
[epoch3, step1421]: loss 9.369754
[epoch3, step1422]: loss 6.661537
[epoch3, step1423]: loss 17.535477
[epoch3, step1424]: loss 13.789311
[epoch3, step1425]: loss 3.741754
[epoch3, step1426]: loss 23.881819
[epoch3, step1427]: loss 28.612831
[epoch3, step1428]: loss 32.082626
[epoch3, step1429]: loss 3.510893
[epoch3, step1430]: loss 33.177933
[epoch3, step1431]: loss 10.619572
[epoch3, step1432]: loss 29.294518
[epoch3, step1433]: loss 30.261406
[epoch3, step1434]: loss 3.485458
[epoch3, step1435]: loss 33.817017
[epoch3, step1436]: loss 17.932869
[epoch3, step1437]: loss 7.911934
[epoch3, step1438]: loss 37.399754
[epoch3, step1439]: loss 22.163822
[epoch3, step1440]: loss 17.546234
[epoch3, step1441]: loss 17.499405
[epoch3, step1442]: loss 24.106529
[epoch3, step1443]: loss 3.999179
[epoch3, step1444]: loss 3.640731
[epoch3, step1445]: loss 41.586906
[epoch3, step1446]: loss 40.941833
[epoch3, step1447]: loss 2.736911
[epoch3, step1448]: loss 35.278305
[epoch3, step1449]: loss 68.996902
[epoch3, step1450]: loss 25.022396
[epoch3, step1451]: loss 3.920360
[epoch3, step1452]: loss 5.264916
[epoch3, step1453]: loss 18.100647
[epoch3, step1454]: loss 15.717464
[epoch3, step1455]: loss 13.036285
[epoch3, step1456]: loss 6.477984
[epoch3, step1457]: loss 25.229071
[epoch3, step1458]: loss 25.629486
[epoch3, step1459]: loss 12.452993
[epoch3, step1460]: loss 22.543442
[epoch3, step1461]: loss 20.585749
[epoch3, step1462]: loss 4.838029
[epoch3, step1463]: loss 20.436386
[epoch3, step1464]: loss 49.941845
[epoch3, step1465]: loss 25.065491
[epoch3, step1466]: loss 5.346555
[epoch3, step1467]: loss 2.763993
[epoch3, step1468]: loss 8.301656
[epoch3, step1469]: loss 27.846695
[epoch3, step1470]: loss 12.666779
[epoch3, step1471]: loss 10.310587
[epoch3, step1472]: loss 9.793934
[epoch3, step1473]: loss 3.492977
[epoch3, step1474]: loss 7.723217
[epoch3, step1475]: loss 4.494212
[epoch3, step1476]: loss 51.921833
[epoch3, step1477]: loss 10.869663
[epoch3, step1478]: loss 25.933241
[epoch3, step1479]: loss 3.927196
[epoch3, step1480]: loss 30.102171
[epoch3, step1481]: loss 23.686161
[epoch3, step1482]: loss 9.024889
[epoch3, step1483]: loss 5.741064
[epoch3, step1484]: loss 19.737679
[epoch3, step1485]: loss 16.280918
[epoch3, step1486]: loss 5.816038
[epoch3, step1487]: loss 12.692385
[epoch3, step1488]: loss 9.779091
[epoch3, step1489]: loss 16.913658
[epoch3, step1490]: loss 48.939041
[epoch3, step1491]: loss 9.935869
[epoch3, step1492]: loss 4.676710
[epoch3, step1493]: loss 9.717595
[epoch3, step1494]: loss 4.745993
[epoch3, step1495]: loss 8.380627
[epoch3, step1496]: loss 8.611440
[epoch3, step1497]: loss 5.565943
[epoch3, step1498]: loss 27.322441
[epoch3, step1499]: loss 4.464017
[epoch3, step1500]: loss 7.029761
[epoch3, step1501]: loss 20.677763
[epoch3, step1502]: loss 24.343058
[epoch3, step1503]: loss 49.349586
[epoch3, step1504]: loss 6.519636
[epoch3, step1505]: loss 24.461163
[epoch3, step1506]: loss 23.501486
[epoch3, step1507]: loss 4.848808
[epoch3, step1508]: loss 4.434780
[epoch3, step1509]: loss 6.705383
[epoch3, step1510]: loss 11.239612
[epoch3, step1511]: loss 45.271206
[epoch3, step1512]: loss 7.014809
[epoch3, step1513]: loss 33.100719
[epoch3, step1514]: loss 7.517623
[epoch3, step1515]: loss 9.717901
[epoch3, step1516]: loss 20.252552
[epoch3, step1517]: loss 4.782958
[epoch3, step1518]: loss 22.659472
[epoch3, step1519]: loss 8.821437
[epoch3, step1520]: loss 7.214427
[epoch3, step1521]: loss 4.344837
[epoch3, step1522]: loss 50.950821
[epoch3, step1523]: loss 7.475625
[epoch3, step1524]: loss 8.473812
[epoch3, step1525]: loss 7.294059
[epoch3, step1526]: loss 3.050706
[epoch3, step1527]: loss 25.704952
[epoch3, step1528]: loss 42.445652
[epoch3, step1529]: loss 4.300429
[epoch3, step1530]: loss 3.774968
[epoch3, step1531]: loss 11.285732
[epoch3, step1532]: loss 10.850525
[epoch3, step1533]: loss 26.281343
[epoch3, step1534]: loss 16.913170
[epoch3, step1535]: loss 31.367228
[epoch3, step1536]: loss 7.475330
[epoch3, step1537]: loss 6.767394
[epoch3, step1538]: loss 2.488862
[epoch3, step1539]: loss 2.892396
[epoch3, step1540]: loss 4.627994
[epoch3, step1541]: loss 42.561649
[epoch3, step1542]: loss 25.876110
[epoch3, step1543]: loss 3.906482
[epoch3, step1544]: loss 12.595940
[epoch3, step1545]: loss 13.612247
[epoch3, step1546]: loss 21.535635
[epoch3, step1547]: loss 5.975382
[epoch3, step1548]: loss 8.927222
[epoch3, step1549]: loss 8.641181
[epoch3, step1550]: loss 13.430190
[epoch3, step1551]: loss 13.567985
[epoch3, step1552]: loss 28.269390
[epoch3, step1553]: loss 4.010745
[epoch3, step1554]: loss 5.727920
[epoch3, step1555]: loss 7.693067
[epoch3, step1556]: loss 17.851324
[epoch3, step1557]: loss 6.293667
[epoch3, step1558]: loss 4.388323
[epoch3, step1559]: loss 19.485706
[epoch3, step1560]: loss 10.137858
[epoch3, step1561]: loss 22.855148
[epoch3, step1562]: loss 3.895941
[epoch3, step1563]: loss 6.209113
[epoch3, step1564]: loss 16.334515
[epoch3, step1565]: loss 8.721297
[epoch3, step1566]: loss 3.624157
[epoch3, step1567]: loss 24.081957
[epoch3, step1568]: loss 16.652002
[epoch3, step1569]: loss 3.080503
[epoch3, step1570]: loss 3.474023
[epoch3, step1571]: loss 33.365635
[epoch3, step1572]: loss 3.935136
[epoch3, step1573]: loss 2.956628
[epoch3, step1574]: loss 23.555389
[epoch3, step1575]: loss 21.141106
[epoch3, step1576]: loss 7.722634
[epoch3, step1577]: loss 17.056753
[epoch3, step1578]: loss 2.695563
[epoch3, step1579]: loss 7.592201
[epoch3, step1580]: loss 66.001892
[epoch3, step1581]: loss 5.723611
[epoch3, step1582]: loss 7.380623
[epoch3, step1583]: loss 3.491653
[epoch3, step1584]: loss 6.744831
[epoch3, step1585]: loss 4.273112
[epoch3, step1586]: loss 28.295477
[epoch3, step1587]: loss 17.765163
[epoch3, step1588]: loss 21.367167
[epoch3, step1589]: loss 34.032654
[epoch3, step1590]: loss 16.259182
[epoch3, step1591]: loss 43.346840
[epoch3, step1592]: loss 17.771326
[epoch3, step1593]: loss 18.125795
[epoch3, step1594]: loss 22.313065
[epoch3, step1595]: loss 14.081338
[epoch3, step1596]: loss 37.148151
[epoch3, step1597]: loss 42.927460
[epoch3, step1598]: loss 24.126644
[epoch3, step1599]: loss 24.520386
[epoch3, step1600]: loss 1.983660
[epoch3, step1601]: loss 7.221966
[epoch3, step1602]: loss 6.561697
[epoch3, step1603]: loss 3.467863
[epoch3, step1604]: loss 37.395241
[epoch3, step1605]: loss 9.354274
[epoch3, step1606]: loss 7.351200
[epoch3, step1607]: loss 20.332981
[epoch3, step1608]: loss 4.291280
[epoch3, step1609]: loss 8.847382
[epoch3, step1610]: loss 3.089843
[epoch3, step1611]: loss 21.686750
[epoch3, step1612]: loss 6.814706
[epoch3, step1613]: loss 9.920117
[epoch3, step1614]: loss 26.135263
[epoch3, step1615]: loss 10.532963
[epoch3, step1616]: loss 6.884082
[epoch3, step1617]: loss 5.093247
[epoch3, step1618]: loss 26.265982
[epoch3, step1619]: loss 8.405742
[epoch3, step1620]: loss 5.465850
[epoch3, step1621]: loss 8.803617
[epoch3, step1622]: loss 20.659262
[epoch3, step1623]: loss 13.339899
[epoch3, step1624]: loss 16.333809
[epoch3, step1625]: loss 5.957925
[epoch3, step1626]: loss 42.616344
[epoch3, step1627]: loss 24.692673
[epoch3, step1628]: loss 7.028714
[epoch3, step1629]: loss 5.885596
[epoch3, step1630]: loss 7.464441
[epoch3, step1631]: loss 44.872780
[epoch3, step1632]: loss 6.459240
[epoch3, step1633]: loss 12.012418
[epoch3, step1634]: loss 7.681876
[epoch3, step1635]: loss 29.071812
[epoch3, step1636]: loss 21.107267
[epoch3, step1637]: loss 23.731899
[epoch3, step1638]: loss 27.549465
[epoch3, step1639]: loss 6.587776
[epoch3, step1640]: loss 6.223039
[epoch3, step1641]: loss 4.663364
[epoch3, step1642]: loss 8.221839
[epoch3, step1643]: loss 39.418335
[epoch3, step1644]: loss 3.112075
[epoch3, step1645]: loss 9.720840
[epoch3, step1646]: loss 55.948467
[epoch3, step1647]: loss 11.166100
[epoch3, step1648]: loss 6.659353
[epoch3, step1649]: loss 35.332859
[epoch3, step1650]: loss 16.586832
[epoch3, step1651]: loss 2.149199
[epoch3, step1652]: loss 6.398752
[epoch3, step1653]: loss 26.303778
[epoch3, step1654]: loss 7.611534
[epoch3, step1655]: loss 12.992935
[epoch3, step1656]: loss 5.587213
[epoch3, step1657]: loss 8.803427
[epoch3, step1658]: loss 19.924143
[epoch3, step1659]: loss 23.607979
[epoch3, step1660]: loss 17.384989
[epoch3, step1661]: loss 4.367713
[epoch3, step1662]: loss 8.001577
[epoch3, step1663]: loss 4.339789
[epoch3, step1664]: loss 26.343029
[epoch3, step1665]: loss 4.991388
[epoch3, step1666]: loss 6.616760
[epoch3, step1667]: loss 23.770761
[epoch3, step1668]: loss 10.301620
[epoch3, step1669]: loss 15.399037
[epoch3, step1670]: loss 24.722292
[epoch3, step1671]: loss 7.716817
[epoch3, step1672]: loss 25.273174
[epoch3, step1673]: loss 11.057024
[epoch3, step1674]: loss 7.873296
[epoch3, step1675]: loss 6.206689
[epoch3, step1676]: loss 10.607147
[epoch3, step1677]: loss 70.801735
[epoch3, step1678]: loss 8.156909
[epoch3, step1679]: loss 9.026865
[epoch3, step1680]: loss 6.598165
[epoch3, step1681]: loss 29.333921
[epoch3, step1682]: loss 26.070667
[epoch3, step1683]: loss 29.893810
[epoch3, step1684]: loss 14.596886
[epoch3, step1685]: loss 16.532768
[epoch3, step1686]: loss 5.266481
[epoch3, step1687]: loss 5.590409
[epoch3, step1688]: loss 20.840998
[epoch3, step1689]: loss 21.974201
[epoch3, step1690]: loss 12.435312
[epoch3, step1691]: loss 2.967604
[epoch3, step1692]: loss 21.823759
[epoch3, step1693]: loss 19.716665
[epoch3, step1694]: loss 8.158641
[epoch3, step1695]: loss 18.287876
[epoch3, step1696]: loss 3.805021
[epoch3, step1697]: loss 6.534771
[epoch3, step1698]: loss 6.455726
[epoch3, step1699]: loss 43.850079
[epoch3, step1700]: loss 2.358776
[epoch3, step1701]: loss 29.285557
[epoch3, step1702]: loss 6.587022
[epoch3, step1703]: loss 16.759043
[epoch3, step1704]: loss 9.703744
[epoch3, step1705]: loss 3.382367
[epoch3, step1706]: loss 10.863873
[epoch3, step1707]: loss 47.182659
[epoch3, step1708]: loss 18.078911
[epoch3, step1709]: loss 5.096082
[epoch3, step1710]: loss 4.954298
[epoch3, step1711]: loss 5.349925
[epoch3, step1712]: loss 5.768832
[epoch3, step1713]: loss 6.347808
[epoch3, step1714]: loss 8.159103
[epoch3, step1715]: loss 26.893026
[epoch3, step1716]: loss 23.540852
[epoch3, step1717]: loss 6.207462
[epoch3, step1718]: loss 27.664110
[epoch3, step1719]: loss 20.051197
[epoch3, step1720]: loss 17.687162
[epoch3, step1721]: loss 16.374186
[epoch3, step1722]: loss 9.232975
[epoch3, step1723]: loss 8.274104
[epoch3, step1724]: loss 6.210223
[epoch3, step1725]: loss 7.026483
[epoch3, step1726]: loss 4.979740
[epoch3, step1727]: loss 4.089951
[epoch3, step1728]: loss 3.995228
[epoch3, step1729]: loss 19.926252
[epoch3, step1730]: loss 32.635395
[epoch3, step1731]: loss 5.586902
[epoch3, step1732]: loss 9.154601
[epoch3, step1733]: loss 19.052769
[epoch3, step1734]: loss 9.895617
[epoch3, step1735]: loss 5.166701
[epoch3, step1736]: loss 24.865486
[epoch3, step1737]: loss 6.587523
[epoch3, step1738]: loss 31.365040
[epoch3, step1739]: loss 23.807016
[epoch3, step1740]: loss 2.839419
[epoch3, step1741]: loss 7.345585
[epoch3, step1742]: loss 41.933407
[epoch3, step1743]: loss 11.540016
[epoch3, step1744]: loss 22.789488
[epoch3, step1745]: loss 3.382785
[epoch3, step1746]: loss 23.898972
[epoch3, step1747]: loss 30.842928
[epoch3, step1748]: loss 19.351124
[epoch3, step1749]: loss 24.566074
[epoch3, step1750]: loss 5.471780
[epoch3, step1751]: loss 4.872262
[epoch3, step1752]: loss 4.832017
[epoch3, step1753]: loss 8.086535
[epoch3, step1754]: loss 11.217901
[epoch3, step1755]: loss 16.009432
[epoch3, step1756]: loss 3.166138
[epoch3, step1757]: loss 10.674296
[epoch3, step1758]: loss 40.997543
[epoch3, step1759]: loss 5.150064
[epoch3, step1760]: loss 3.497946
[epoch3, step1761]: loss 5.644134
[epoch3, step1762]: loss 5.734416
[epoch3, step1763]: loss 4.585614
[epoch3, step1764]: loss 5.473802
[epoch3, step1765]: loss 22.386660
[epoch3, step1766]: loss 20.215340
[epoch3, step1767]: loss 19.767776
[epoch3, step1768]: loss 28.692335
[epoch3, step1769]: loss 17.854492
[epoch3, step1770]: loss 5.860091
[epoch3, step1771]: loss 6.940721
[epoch3, step1772]: loss 14.238953
[epoch3, step1773]: loss 6.415368
[epoch3, step1774]: loss 34.577648
[epoch3, step1775]: loss 44.051075
[epoch3, step1776]: loss 9.463600
[epoch3, step1777]: loss 10.445847
[epoch3, step1778]: loss 5.379121
[epoch3, step1779]: loss 6.658473
[epoch3, step1780]: loss 27.300777
[epoch3, step1781]: loss 7.596637
[epoch3, step1782]: loss 5.830247
[epoch3, step1783]: loss 7.086742
[epoch3, step1784]: loss 2.923557
[epoch3, step1785]: loss 5.835985
[epoch3, step1786]: loss 18.726250
[epoch3, step1787]: loss 8.829424
[epoch3, step1788]: loss 26.798599
[epoch3, step1789]: loss 3.925718
[epoch3, step1790]: loss 3.534886
[epoch3, step1791]: loss 6.034096
[epoch3, step1792]: loss 17.689913
[epoch3, step1793]: loss 14.500170
[epoch3, step1794]: loss 10.275088
[epoch3, step1795]: loss 2.567295
[epoch3, step1796]: loss 6.417054
[epoch3, step1797]: loss 5.693032
[epoch3, step1798]: loss 24.096842
[epoch3, step1799]: loss 13.716012
[epoch3, step1800]: loss 1.941331
[epoch3, step1801]: loss 3.833790
[epoch3, step1802]: loss 21.309309
[epoch3, step1803]: loss 5.151823
[epoch3, step1804]: loss 5.366602
[epoch3, step1805]: loss 5.425891
[epoch3, step1806]: loss 25.733511
[epoch3, step1807]: loss 25.974743
[epoch3, step1808]: loss 26.031916
[epoch3, step1809]: loss 6.504226
[epoch3, step1810]: loss 3.550208
[epoch3, step1811]: loss 8.252289
[epoch3, step1812]: loss 18.141830
[epoch3, step1813]: loss 11.495903
[epoch3, step1814]: loss 24.441669
[epoch3, step1815]: loss 10.639120
[epoch3, step1816]: loss 6.554159
[epoch3, step1817]: loss 17.340038
[epoch3, step1818]: loss 7.424182
[epoch3, step1819]: loss 33.198299
[epoch3, step1820]: loss 24.237658
[epoch3, step1821]: loss 2.955622
[epoch3, step1822]: loss 4.770687
[epoch3, step1823]: loss 4.916737
[epoch3, step1824]: loss 10.001183
[epoch3, step1825]: loss 33.649223
[epoch3, step1826]: loss 28.072927
[epoch3, step1827]: loss 2.649086
[epoch3, step1828]: loss 20.756258
[epoch3, step1829]: loss 36.796803
[epoch3, step1830]: loss 3.770583
[epoch3, step1831]: loss 7.113653
[epoch3, step1832]: loss 26.124187
[epoch3, step1833]: loss 8.458460
[epoch3, step1834]: loss 6.518591
[epoch3, step1835]: loss 13.713690
[epoch3, step1836]: loss 6.238451
[epoch3, step1837]: loss 7.578679
[epoch3, step1838]: loss 6.974633
[epoch3, step1839]: loss 3.346677
[epoch3, step1840]: loss 3.146610
[epoch3, step1841]: loss 17.709236
[epoch3, step1842]: loss 5.658301
[epoch3, step1843]: loss 6.204023
[epoch3, step1844]: loss 21.405207
[epoch3, step1845]: loss 7.829635
[epoch3, step1846]: loss 17.059494
[epoch3, step1847]: loss 29.573250
[epoch3, step1848]: loss 11.780664
[epoch3, step1849]: loss 16.417099
[epoch3, step1850]: loss 5.507580
[epoch3, step1851]: loss 3.520597
[epoch3, step1852]: loss 8.505524
[epoch3, step1853]: loss 36.702545
[epoch3, step1854]: loss 10.104483
[epoch3, step1855]: loss 7.211164
[epoch3, step1856]: loss 2.530456
[epoch3, step1857]: loss 7.528432
[epoch3, step1858]: loss 7.287000
[epoch3, step1859]: loss 5.936424
[epoch3, step1860]: loss 26.578836
[epoch3, step1861]: loss 9.208831
[epoch3, step1862]: loss 13.117912
[epoch3, step1863]: loss 17.685452
[epoch3, step1864]: loss 37.352646
[epoch3, step1865]: loss 12.712749
[epoch3, step1866]: loss 8.131605
[epoch3, step1867]: loss 5.474486
[epoch3, step1868]: loss 39.271587
[epoch3, step1869]: loss 39.823261
[epoch3, step1870]: loss 6.667740
[epoch3, step1871]: loss 6.626955
[epoch3, step1872]: loss 15.819625
[epoch3, step1873]: loss 6.801218
[epoch3, step1874]: loss 7.434139
[epoch3, step1875]: loss 9.013517
[epoch3, step1876]: loss 32.287022
[epoch3, step1877]: loss 6.486356
[epoch3, step1878]: loss 7.782835
[epoch3, step1879]: loss 5.906498
[epoch3, step1880]: loss 7.633836
[epoch3, step1881]: loss 8.809275
[epoch3, step1882]: loss 30.126852
[epoch3, step1883]: loss 16.490005
[epoch3, step1884]: loss 3.545037
[epoch3, step1885]: loss 4.964222
[epoch3, step1886]: loss 4.144410
[epoch3, step1887]: loss 9.636339
[epoch3, step1888]: loss 15.768781
[epoch3, step1889]: loss 17.411531
[epoch3, step1890]: loss 3.351102
[epoch3, step1891]: loss 4.306836
[epoch3, step1892]: loss 45.107723
[epoch3, step1893]: loss 25.965467
[epoch3, step1894]: loss 32.291218
[epoch3, step1895]: loss 24.174644
[epoch3, step1896]: loss 17.471619
[epoch3, step1897]: loss 7.459991
[epoch3, step1898]: loss 8.013297
[epoch3, step1899]: loss 2.523634
[epoch3, step1900]: loss 22.249538
[epoch3, step1901]: loss 10.903344
[epoch3, step1902]: loss 8.942234
[epoch3, step1903]: loss 2.955010
[epoch3, step1904]: loss 52.440739
[epoch3, step1905]: loss 5.993583
[epoch3, step1906]: loss 11.461872
[epoch3, step1907]: loss 4.002187
[epoch3, step1908]: loss 9.099917
[epoch3, step1909]: loss 6.317424
[epoch3, step1910]: loss 15.868081
[epoch3, step1911]: loss 10.946067
[epoch3, step1912]: loss 6.359719
[epoch3, step1913]: loss 5.013070
[epoch3, step1914]: loss 26.240070
[epoch3, step1915]: loss 19.418903
[epoch3, step1916]: loss 4.211226
[epoch3, step1917]: loss 5.920753
[epoch3, step1918]: loss 30.933794
[epoch3, step1919]: loss 4.727769
[epoch3, step1920]: loss 14.923262
[epoch3, step1921]: loss 4.118872
[epoch3, step1922]: loss 4.030282
[epoch3, step1923]: loss 3.196414
[epoch3, step1924]: loss 24.181261
[epoch3, step1925]: loss 17.164516
[epoch3, step1926]: loss 18.095922
[epoch3, step1927]: loss 19.738379
[epoch3, step1928]: loss 2.744427
[epoch3, step1929]: loss 7.355602
[epoch3, step1930]: loss 26.419466
[epoch3, step1931]: loss 41.031902
[epoch3, step1932]: loss 41.294193
[epoch3, step1933]: loss 18.742355
[epoch3, step1934]: loss 7.484320
[epoch3, step1935]: loss 20.056303
[epoch3, step1936]: loss 57.873165
[epoch3, step1937]: loss 2.354724
[epoch3, step1938]: loss 21.723503
[epoch3, step1939]: loss 18.141199
[epoch3, step1940]: loss 5.231043
[epoch3, step1941]: loss 8.143512
[epoch3, step1942]: loss 8.188930
[epoch3, step1943]: loss 4.807269
[epoch3, step1944]: loss 10.002954
[epoch3, step1945]: loss 4.701679
[epoch3, step1946]: loss 13.731672
[epoch3, step1947]: loss 3.778670
[epoch3, step1948]: loss 2.581253
[epoch3, step1949]: loss 3.850065
[epoch3, step1950]: loss 10.855738
[epoch3, step1951]: loss 17.582184
[epoch3, step1952]: loss 7.607610
[epoch3, step1953]: loss 2.895388
[epoch3, step1954]: loss 36.714264
[epoch3, step1955]: loss 17.100548
[epoch3, step1956]: loss 28.762020
[epoch3, step1957]: loss 4.771531
[epoch3, step1958]: loss 10.489009
[epoch3, step1959]: loss 28.001091
[epoch3, step1960]: loss 25.149324
[epoch3, step1961]: loss 6.801377
[epoch3, step1962]: loss 25.538822
[epoch3, step1963]: loss 4.728930
[epoch3, step1964]: loss 8.495003
[epoch3, step1965]: loss 10.791033
[epoch3, step1966]: loss 7.004357
[epoch3, step1967]: loss 14.665494
[epoch3, step1968]: loss 2.674309
[epoch3, step1969]: loss 30.640139
[epoch3, step1970]: loss 22.395634
[epoch3, step1971]: loss 3.870705
[epoch3, step1972]: loss 27.535639
[epoch3, step1973]: loss 53.602905
[epoch3, step1974]: loss 46.082821
[epoch3, step1975]: loss 6.360378
[epoch3, step1976]: loss 6.191460
[epoch3, step1977]: loss 4.719229
[epoch3, step1978]: loss 23.057611
[epoch3, step1979]: loss 6.945882
[epoch3, step1980]: loss 26.738371
[epoch3, step1981]: loss 7.812559
[epoch3, step1982]: loss 2.787537
[epoch3, step1983]: loss 59.679440
[epoch3, step1984]: loss 16.286245
[epoch3, step1985]: loss 7.664903
[epoch3, step1986]: loss 32.645626
[epoch3, step1987]: loss 24.545528
[epoch3, step1988]: loss 6.940684
[epoch3, step1989]: loss 26.887409
[epoch3, step1990]: loss 43.867561
[epoch3, step1991]: loss 38.546394
[epoch3, step1992]: loss 5.211052
[epoch3, step1993]: loss 6.870076
[epoch3, step1994]: loss 11.123781
[epoch3, step1995]: loss 17.264162
[epoch3, step1996]: loss 13.356392
[epoch3, step1997]: loss 7.902205
[epoch3, step1998]: loss 5.682919
[epoch3, step1999]: loss 18.132137
[epoch3, step2000]: loss 6.783350
[epoch3, step2001]: loss 12.240955
[epoch3, step2002]: loss 27.895132
[epoch3, step2003]: loss 5.580403
[epoch3, step2004]: loss 4.520613
[epoch3, step2005]: loss 5.573146
[epoch3, step2006]: loss 9.925845
[epoch3, step2007]: loss 34.212570
[epoch3, step2008]: loss 11.987524
[epoch3, step2009]: loss 20.430054
[epoch3, step2010]: loss 6.645663
[epoch3, step2011]: loss 5.896170
[epoch3, step2012]: loss 7.937457
[epoch3, step2013]: loss 16.162682
[epoch3, step2014]: loss 24.082127
[epoch3, step2015]: loss 14.557907
[epoch3, step2016]: loss 16.898407
[epoch3, step2017]: loss 32.128067
[epoch3, step2018]: loss 5.972311
[epoch3, step2019]: loss 12.971107
[epoch3, step2020]: loss 15.211537
[epoch3, step2021]: loss 24.132647
[epoch3, step2022]: loss 22.294540
[epoch3, step2023]: loss 5.193668
[epoch3, step2024]: loss 7.273354
[epoch3, step2025]: loss 10.039543
[epoch3, step2026]: loss 6.420587
[epoch3, step2027]: loss 6.655407
[epoch3, step2028]: loss 6.126871
[epoch3, step2029]: loss 6.551145
[epoch3, step2030]: loss 7.025743
[epoch3, step2031]: loss 5.213752
[epoch3, step2032]: loss 29.659227
[epoch3, step2033]: loss 30.435318
[epoch3, step2034]: loss 8.923312
[epoch3, step2035]: loss 7.272743
[epoch3, step2036]: loss 3.050589
[epoch3, step2037]: loss 40.368500
[epoch3, step2038]: loss 28.885307
[epoch3, step2039]: loss 6.738890
[epoch3, step2040]: loss 9.162025
[epoch3, step2041]: loss 2.625175
[epoch3, step2042]: loss 4.091145
[epoch3, step2043]: loss 60.703804
[epoch3, step2044]: loss 4.682156
[epoch3, step2045]: loss 24.891745
[epoch3, step2046]: loss 26.699070
[epoch3, step2047]: loss 11.656907
[epoch3, step2048]: loss 38.203056
[epoch3, step2049]: loss 35.178829
[epoch3, step2050]: loss 19.850164
[epoch3, step2051]: loss 26.198614
[epoch3, step2052]: loss 11.841730
[epoch3, step2053]: loss 2.339785
[epoch3, step2054]: loss 6.434690
[epoch3, step2055]: loss 6.223916
[epoch3, step2056]: loss 7.718691
[epoch3, step2057]: loss 30.656754
[epoch3, step2058]: loss 3.277828
[epoch3, step2059]: loss 24.064014
[epoch3, step2060]: loss 4.302190
[epoch3, step2061]: loss 4.894783
[epoch3, step2062]: loss 30.146511
[epoch3, step2063]: loss 8.465104
[epoch3, step2064]: loss 5.768255
[epoch3, step2065]: loss 30.927225
[epoch3, step2066]: loss 13.643686
[epoch3, step2067]: loss 5.476887
[epoch3, step2068]: loss 6.061776
[epoch3, step2069]: loss 35.776791
[epoch3, step2070]: loss 43.141174
[epoch3, step2071]: loss 5.167061
[epoch3, step2072]: loss 8.889500
[epoch3, step2073]: loss 2.063322
[epoch3, step2074]: loss 44.534836
[epoch3, step2075]: loss 37.803696
[epoch3, step2076]: loss 4.830298
[epoch3, step2077]: loss 2.366510
[epoch3, step2078]: loss 21.873169
[epoch3, step2079]: loss 25.757416
[epoch3, step2080]: loss 20.242302
[epoch3, step2081]: loss 26.080666
[epoch3, step2082]: loss 5.314591
[epoch3, step2083]: loss 13.413705
[epoch3, step2084]: loss 8.427118
[epoch3, step2085]: loss 26.842369
[epoch3, step2086]: loss 6.234037
[epoch3, step2087]: loss 7.373567
[epoch3, step2088]: loss 10.937504
[epoch3, step2089]: loss 3.836727
[epoch3, step2090]: loss 4.754235
[epoch3, step2091]: loss 4.662484
[epoch3, step2092]: loss 2.522909
[epoch3, step2093]: loss 22.378731
[epoch3, step2094]: loss 3.613149
[epoch3, step2095]: loss 4.407332
[epoch3, step2096]: loss 13.020834
[epoch3, step2097]: loss 4.698004
[epoch3, step2098]: loss 6.476852
[epoch3, step2099]: loss 8.223917
[epoch3, step2100]: loss 15.805990
[epoch3, step2101]: loss 20.822435
[epoch3, step2102]: loss 6.003736
[epoch3, step2103]: loss 18.751404
[epoch3, step2104]: loss 5.544756
[epoch3, step2105]: loss 4.604129
[epoch3, step2106]: loss 8.213774
[epoch3, step2107]: loss 3.949029
[epoch3, step2108]: loss 4.762913
[epoch3, step2109]: loss 15.080919
[epoch3, step2110]: loss 18.716764
[epoch3, step2111]: loss 12.435724
[epoch3, step2112]: loss 7.463130
[epoch3, step2113]: loss 2.154186
[epoch3, step2114]: loss 21.967987
[epoch3, step2115]: loss 17.371359
[epoch3, step2116]: loss 6.339981
[epoch3, step2117]: loss 7.411428
[epoch3, step2118]: loss 25.559130
[epoch3, step2119]: loss 36.067696
[epoch3, step2120]: loss 5.832380
[epoch3, step2121]: loss 26.478556
[epoch3, step2122]: loss 23.872759
[epoch3, step2123]: loss 33.265282
[epoch3, step2124]: loss 34.647793
[epoch3, step2125]: loss 32.874245
[epoch3, step2126]: loss 9.069155
[epoch3, step2127]: loss 23.281504
[epoch3, step2128]: loss 6.124462
[epoch3, step2129]: loss 19.199768
[epoch3, step2130]: loss 19.619707
[epoch3, step2131]: loss 8.008354
[epoch3, step2132]: loss 19.207386
[epoch3, step2133]: loss 2.702482
[epoch3, step2134]: loss 74.107941
[epoch3, step2135]: loss 11.719840
[epoch3, step2136]: loss 15.921792
[epoch3, step2137]: loss 4.980286
[epoch3, step2138]: loss 6.180352
[epoch3, step2139]: loss 18.667570
[epoch3, step2140]: loss 10.956064
[epoch3, step2141]: loss 5.257826
[epoch3, step2142]: loss 5.831168
[epoch3, step2143]: loss 20.416468
[epoch3, step2144]: loss 20.251619
[epoch3, step2145]: loss 4.517469
[epoch3, step2146]: loss 23.766186
[epoch3, step2147]: loss 7.843088
[epoch3, step2148]: loss 3.727207
[epoch3, step2149]: loss 4.183803
[epoch3, step2150]: loss 8.753947
[epoch3, step2151]: loss 4.623415
[epoch3, step2152]: loss 21.568678
[epoch3, step2153]: loss 26.671776
[epoch3, step2154]: loss 8.221940
[epoch3, step2155]: loss 5.334892
[epoch3, step2156]: loss 19.006796
[epoch3, step2157]: loss 11.079429
[epoch3, step2158]: loss 2.376945
[epoch3, step2159]: loss 3.816530
[epoch3, step2160]: loss 33.631992
[epoch3, step2161]: loss 19.476997
[epoch3, step2162]: loss 3.161831
[epoch3, step2163]: loss 7.735571
[epoch3, step2164]: loss 23.027420
[epoch3, step2165]: loss 4.014309
[epoch3, step2166]: loss 4.231392
[epoch3, step2167]: loss 4.875479
[epoch3, step2168]: loss 3.551436
[epoch3, step2169]: loss 6.597732
[epoch3, step2170]: loss 13.548772
[epoch3, step2171]: loss 16.016115
[epoch3, step2172]: loss 30.537016
[epoch3, step2173]: loss 8.504893
[epoch3, step2174]: loss 4.329682
[epoch3, step2175]: loss 6.069359
[epoch3, step2176]: loss 7.939917
[epoch3, step2177]: loss 29.180414
[epoch3, step2178]: loss 15.955920
[epoch3, step2179]: loss 3.173587
[epoch3, step2180]: loss 10.626351
[epoch3, step2181]: loss 32.676868
[epoch3, step2182]: loss 6.982552
[epoch3, step2183]: loss 16.438511
[epoch3, step2184]: loss 42.146248
[epoch3, step2185]: loss 9.345350
[epoch3, step2186]: loss 24.922859
[epoch3, step2187]: loss 3.404631
[epoch3, step2188]: loss 7.552055
[epoch3, step2189]: loss 32.614578
[epoch3, step2190]: loss 8.319351
[epoch3, step2191]: loss 6.193170
[epoch3, step2192]: loss 24.929850
[epoch3, step2193]: loss 5.076992
[epoch3, step2194]: loss 4.717603
[epoch3, step2195]: loss 8.380657
[epoch3, step2196]: loss 6.751056
[epoch3, step2197]: loss 5.078840
[epoch3, step2198]: loss 6.972633
[epoch3, step2199]: loss 3.724572
[epoch3, step2200]: loss 4.265455
[epoch3, step2201]: loss 8.607648
[epoch3, step2202]: loss 2.190207
[epoch3, step2203]: loss 21.320395
[epoch3, step2204]: loss 5.550092
[epoch3, step2205]: loss 24.417484
[epoch3, step2206]: loss 9.603769
[epoch3, step2207]: loss 10.551757
[epoch3, step2208]: loss 13.339899
[epoch3, step2209]: loss 23.344244
[epoch3, step2210]: loss 4.286844
[epoch3, step2211]: loss 4.120197
[epoch3, step2212]: loss 34.271370
[epoch3, step2213]: loss 3.660159
[epoch3, step2214]: loss 7.250975
[epoch3, step2215]: loss 23.529261
[epoch3, step2216]: loss 3.428481
[epoch3, step2217]: loss 60.754013
[epoch3, step2218]: loss 17.185509
[epoch3, step2219]: loss 21.337986
[epoch3, step2220]: loss 5.232641
[epoch3, step2221]: loss 24.932053
[epoch3, step2222]: loss 28.880142
[epoch3, step2223]: loss 8.777605
[epoch3, step2224]: loss 4.673711
[epoch3, step2225]: loss 9.969208
[epoch3, step2226]: loss 35.583725
[epoch3, step2227]: loss 36.730110
[epoch3, step2228]: loss 21.672436
[epoch3, step2229]: loss 41.948547
[epoch3, step2230]: loss 22.324333
[epoch3, step2231]: loss 19.569130
[epoch3, step2232]: loss 53.535591
[epoch3, step2233]: loss 16.734480
[epoch3, step2234]: loss 17.964195
[epoch3, step2235]: loss 4.275534
[epoch3, step2236]: loss 21.891157
[epoch3, step2237]: loss 58.344696
[epoch3, step2238]: loss 2.792064
[epoch3, step2239]: loss 20.427357
[epoch3, step2240]: loss 38.950581
[epoch3, step2241]: loss 17.446119
[epoch3, step2242]: loss 19.576982
[epoch3, step2243]: loss 4.009064
[epoch3, step2244]: loss 5.945644
[epoch3, step2245]: loss 5.493858
[epoch3, step2246]: loss 3.757008
[epoch3, step2247]: loss 4.799486
[epoch3, step2248]: loss 9.323496
[epoch3, step2249]: loss 7.631591
[epoch3, step2250]: loss 2.840372
[epoch3, step2251]: loss 21.421070
[epoch3, step2252]: loss 19.554277
[epoch3, step2253]: loss 2.215559
[epoch3, step2254]: loss 8.655497
[epoch3, step2255]: loss 5.672488
[epoch3, step2256]: loss 4.052780
[epoch3, step2257]: loss 3.864364
[epoch3, step2258]: loss 2.977890
[epoch3, step2259]: loss 26.576645
[epoch3, step2260]: loss 25.231167
[epoch3, step2261]: loss 17.140617
[epoch3, step2262]: loss 8.827119
[epoch3, step2263]: loss 8.758553
[epoch3, step2264]: loss 4.602598
[epoch3, step2265]: loss 53.308964
[epoch3, step2266]: loss 2.237986
[epoch3, step2267]: loss 3.696368
[epoch3, step2268]: loss 4.846798
[epoch3, step2269]: loss 11.845568
[epoch3, step2270]: loss 3.374604
[epoch3, step2271]: loss 10.621922
[epoch3, step2272]: loss 6.581313
[epoch3, step2273]: loss 46.074924
[epoch3, step2274]: loss 8.435533
[epoch3, step2275]: loss 10.168827
[epoch3, step2276]: loss 22.563141
[epoch3, step2277]: loss 34.650768
[epoch3, step2278]: loss 5.370435
[epoch3, step2279]: loss 4.940274
[epoch3, step2280]: loss 12.163067
[epoch3, step2281]: loss 3.461758
[epoch3, step2282]: loss 7.883817
[epoch3, step2283]: loss 3.527284
[epoch3, step2284]: loss 2.464947
[epoch3, step2285]: loss 6.347304
[epoch3, step2286]: loss 9.806287
[epoch3, step2287]: loss 8.931792
[epoch3, step2288]: loss 7.072389
[epoch3, step2289]: loss 51.251965
[epoch3, step2290]: loss 36.677494
[epoch3, step2291]: loss 9.333009
[epoch3, step2292]: loss 5.785878
[epoch3, step2293]: loss 17.262867
[epoch3, step2294]: loss 15.173205
[epoch3, step2295]: loss 7.864458
[epoch3, step2296]: loss 5.524715
[epoch3, step2297]: loss 11.288912
[epoch3, step2298]: loss 4.156254
[epoch3, step2299]: loss 3.782026
[epoch3, step2300]: loss 23.736629
[epoch3, step2301]: loss 9.537370
[epoch3, step2302]: loss 4.330450
[epoch3, step2303]: loss 6.689500
[epoch3, step2304]: loss 16.342588
[epoch3, step2305]: loss 17.626896
[epoch3, step2306]: loss 5.758963
[epoch3, step2307]: loss 3.970279
[epoch3, step2308]: loss 39.550400
[epoch3, step2309]: loss 24.693295
[epoch3, step2310]: loss 6.030944
[epoch3, step2311]: loss 20.554825
[epoch3, step2312]: loss 6.604543
[epoch3, step2313]: loss 27.708569
[epoch3, step2314]: loss 4.864774
[epoch3, step2315]: loss 20.547697
[epoch3, step2316]: loss 6.584590
[epoch3, step2317]: loss 18.270552
[epoch3, step2318]: loss 8.865400
[epoch3, step2319]: loss 33.129440
[epoch3, step2320]: loss 8.011649
[epoch3, step2321]: loss 23.469679
[epoch3, step2322]: loss 11.565966
[epoch3, step2323]: loss 22.478439
[epoch3, step2324]: loss 23.735003
[epoch3, step2325]: loss 18.092999
[epoch3, step2326]: loss 4.088575
[epoch3, step2327]: loss 39.538147
[epoch3, step2328]: loss 22.546904
[epoch3, step2329]: loss 51.625793
[epoch3, step2330]: loss 52.683083
[epoch3, step2331]: loss 21.242605
[epoch3, step2332]: loss 3.520979
[epoch3, step2333]: loss 8.279311
[epoch3, step2334]: loss 27.936415
[epoch3, step2335]: loss 3.682231
[epoch3, step2336]: loss 4.915586
[epoch3, step2337]: loss 48.325966
[epoch3, step2338]: loss 15.916713
[epoch3, step2339]: loss 20.196802
[epoch3, step2340]: loss 27.949612
[epoch3, step2341]: loss 5.669353
[epoch3, step2342]: loss 4.835169
[epoch3, step2343]: loss 4.103290
[epoch3, step2344]: loss 6.013042
[epoch3, step2345]: loss 8.737563
[epoch3, step2346]: loss 27.667273
[epoch3, step2347]: loss 35.383064
[epoch3, step2348]: loss 4.593009
[epoch3, step2349]: loss 21.940908
[epoch3, step2350]: loss 4.245955
[epoch3, step2351]: loss 7.774978
[epoch3, step2352]: loss 6.190063
[epoch3, step2353]: loss 16.870850
[epoch3, step2354]: loss 2.193606
[epoch3, step2355]: loss 32.357235
[epoch3, step2356]: loss 4.220451
[epoch3, step2357]: loss 44.332474
[epoch3, step2358]: loss 43.481750
[epoch3, step2359]: loss 26.068079
[epoch3, step2360]: loss 5.425854
[epoch3, step2361]: loss 3.245099
[epoch3, step2362]: loss 4.446273
[epoch3, step2363]: loss 8.128503
[epoch3, step2364]: loss 24.275070
[epoch3, step2365]: loss 22.784714
[epoch3, step2366]: loss 22.051056
[epoch3, step2367]: loss 25.270905
[epoch3, step2368]: loss 5.204430
[epoch3, step2369]: loss 7.956321
[epoch3, step2370]: loss 3.819910
[epoch3, step2371]: loss 2.374124
[epoch3, step2372]: loss 5.342627
[epoch3, step2373]: loss 28.016054
[epoch3, step2374]: loss 5.075413
[epoch3, step2375]: loss 4.220804
[epoch3, step2376]: loss 8.407104
[epoch3, step2377]: loss 5.332816
[epoch3, step2378]: loss 19.480995
[epoch3, step2379]: loss 16.741123
[epoch3, step2380]: loss 33.693401
[epoch3, step2381]: loss 6.653920
[epoch3, step2382]: loss 46.858879
[epoch3, step2383]: loss 23.260550
[epoch3, step2384]: loss 5.763927
[epoch3, step2385]: loss 4.016241
[epoch3, step2386]: loss 21.643970
[epoch3, step2387]: loss 4.687714
[epoch3, step2388]: loss 25.841488
[epoch3, step2389]: loss 33.088051
[epoch3, step2390]: loss 15.148865
[epoch3, step2391]: loss 10.039981
[epoch3, step2392]: loss 18.380756
[epoch3, step2393]: loss 42.972977
[epoch3, step2394]: loss 5.828959
[epoch3, step2395]: loss 5.666427
[epoch3, step2396]: loss 4.428958
[epoch3, step2397]: loss 15.877226
[epoch3, step2398]: loss 7.901750
[epoch3, step2399]: loss 8.096188
[epoch3, step2400]: loss 11.686230
[epoch3, step2401]: loss 6.089318
[epoch3, step2402]: loss 19.222176
[epoch3, step2403]: loss 8.947097
[epoch3, step2404]: loss 9.096449
[epoch3, step2405]: loss 9.094119
[epoch3, step2406]: loss 22.168533
[epoch3, step2407]: loss 18.270687
[epoch3, step2408]: loss 3.666226
[epoch3, step2409]: loss 15.438055
[epoch3, step2410]: loss 31.087643
[epoch3, step2411]: loss 44.188454
[epoch3, step2412]: loss 4.409410
[epoch3, step2413]: loss 4.725711
[epoch3, step2414]: loss 9.335665
[epoch3, step2415]: loss 3.975104
[epoch3, step2416]: loss 11.606633
[epoch3, step2417]: loss 20.180294
[epoch3, step2418]: loss 17.394260
[epoch3, step2419]: loss 4.974905
[epoch3, step2420]: loss 38.023270
[epoch3, step2421]: loss 7.038158
[epoch3, step2422]: loss 19.263765
[epoch3, step2423]: loss 14.540598
[epoch3, step2424]: loss 2.755323
[epoch3, step2425]: loss 24.017361
[epoch3, step2426]: loss 3.899613
[epoch3, step2427]: loss 16.741791
[epoch3, step2428]: loss 2.069556
[epoch3, step2429]: loss 25.461224
[epoch3, step2430]: loss 4.784121
[epoch3, step2431]: loss 9.808122
[epoch3, step2432]: loss 25.407934
[epoch3, step2433]: loss 4.931084
[epoch3, step2434]: loss 11.669413
[epoch3, step2435]: loss 9.181993
[epoch3, step2436]: loss 8.337414
[epoch3, step2437]: loss 19.719826
[epoch3, step2438]: loss 20.516722
[epoch3, step2439]: loss 48.706093
[epoch3, step2440]: loss 37.747219
[epoch3, step2441]: loss 21.417902
[epoch3, step2442]: loss 9.448694
[epoch3, step2443]: loss 3.961697
[epoch3, step2444]: loss 4.599926
[epoch3, step2445]: loss 25.839895
[epoch3, step2446]: loss 8.427238
[epoch3, step2447]: loss 26.851652
[epoch3, step2448]: loss 3.332566
[epoch3, step2449]: loss 4.348154
[epoch3, step2450]: loss 27.248463
[epoch3, step2451]: loss 21.556089
[epoch3, step2452]: loss 4.952004
[epoch3, step2453]: loss 3.506465
[epoch3, step2454]: loss 23.345089
[epoch3, step2455]: loss 37.718285
[epoch3, step2456]: loss 8.730206
[epoch3, step2457]: loss 3.246599
[epoch3, step2458]: loss 12.526014
[epoch3, step2459]: loss 4.506239
[epoch3, step2460]: loss 6.608858
[epoch3, step2461]: loss 3.086859
[epoch3, step2462]: loss 21.942760
[epoch3, step2463]: loss 6.317492
[epoch3, step2464]: loss 36.033226
[epoch3, step2465]: loss 9.795273
[epoch3, step2466]: loss 34.559147
[epoch3, step2467]: loss 13.167715
[epoch3, step2468]: loss 5.220747
[epoch3, step2469]: loss 7.079446
[epoch3, step2470]: loss 4.241430
[epoch3, step2471]: loss 1.960263
[epoch3, step2472]: loss 36.316940
[epoch3, step2473]: loss 2.716214
[epoch3, step2474]: loss 23.730785
[epoch3, step2475]: loss 2.209554
[epoch3, step2476]: loss 5.582095
[epoch3, step2477]: loss 14.462470
[epoch3, step2478]: loss 8.968254
[epoch3, step2479]: loss 5.601413
[epoch3, step2480]: loss 5.780985
[epoch3, step2481]: loss 13.798879
[epoch3, step2482]: loss 2.361902
[epoch3, step2483]: loss 21.760645
[epoch3, step2484]: loss 31.780107
[epoch3, step2485]: loss 16.887051
[epoch3, step2486]: loss 7.685511
[epoch3, step2487]: loss 23.112848
[epoch3, step2488]: loss 38.292786
[epoch3, step2489]: loss 4.224252
[epoch3, step2490]: loss 13.937269
[epoch3, step2491]: loss 25.333288
[epoch3, step2492]: loss 4.146799
[epoch3, step2493]: loss 18.408789
[epoch3, step2494]: loss 6.991316
[epoch3, step2495]: loss 20.226006
[epoch3, step2496]: loss 20.108429
[epoch3, step2497]: loss 20.014839
[epoch3, step2498]: loss 2.285484
[epoch3, step2499]: loss 6.409494
[epoch3, step2500]: loss 7.457503
[epoch3, step2501]: loss 18.631763
[epoch3, step2502]: loss 28.160154
[epoch3, step2503]: loss 4.460474
[epoch3, step2504]: loss 5.343606
[epoch3, step2505]: loss 6.777101
[epoch3, step2506]: loss 5.815693
[epoch3, step2507]: loss 38.160156
[epoch3, step2508]: loss 29.700979
[epoch3, step2509]: loss 8.563768
[epoch3, step2510]: loss 9.775331
[epoch3, step2511]: loss 7.206750
[epoch3, step2512]: loss 3.017685
[epoch3, step2513]: loss 22.911736
[epoch3, step2514]: loss 7.721441
[epoch3, step2515]: loss 18.059612
[epoch3, step2516]: loss 4.925296
[epoch3, step2517]: loss 6.587820
[epoch3, step2518]: loss 18.570919
[epoch3, step2519]: loss 3.040453
[epoch3, step2520]: loss 8.191157
[epoch3, step2521]: loss 4.036933
[epoch3, step2522]: loss 5.568984
[epoch3, step2523]: loss 10.985181
[epoch3, step2524]: loss 8.465155
[epoch3, step2525]: loss 40.165241
[epoch3, step2526]: loss 28.304403
[epoch3, step2527]: loss 16.133156
[epoch3, step2528]: loss 5.802227
[epoch3, step2529]: loss 66.436745
[epoch3, step2530]: loss 23.214191
[epoch3, step2531]: loss 15.994382
[epoch3, step2532]: loss 7.113198
[epoch3, step2533]: loss 6.140718
[epoch3, step2534]: loss 5.430727
[epoch3, step2535]: loss 6.424084
[epoch3, step2536]: loss 3.528501
[epoch3, step2537]: loss 4.884636
[epoch3, step2538]: loss 2.856183
[epoch3, step2539]: loss 2.484744
[epoch3, step2540]: loss 2.857871
[epoch3, step2541]: loss 8.544065
[epoch3, step2542]: loss 50.306145
[epoch3, step2543]: loss 9.078235
[epoch3, step2544]: loss 5.016959
[epoch3, step2545]: loss 6.378835
[epoch3, step2546]: loss 18.187681
[epoch3, step2547]: loss 2.894710
[epoch3, step2548]: loss 22.938047
[epoch3, step2549]: loss 18.542437
[epoch3, step2550]: loss 14.529465
[epoch3, step2551]: loss 5.219331
[epoch3, step2552]: loss 37.571671
[epoch3, step2553]: loss 24.497711
[epoch3, step2554]: loss 8.424495
[epoch3, step2555]: loss 10.684927
[epoch3, step2556]: loss 7.715457
[epoch3, step2557]: loss 4.809999
[epoch3, step2558]: loss 6.852505
[epoch3, step2559]: loss 18.318172
[epoch3, step2560]: loss 8.190267
[epoch3, step2561]: loss 8.343739
[epoch3, step2562]: loss 4.881675
[epoch3, step2563]: loss 43.736927
[epoch3, step2564]: loss 21.533504
[epoch3, step2565]: loss 8.896676
[epoch3, step2566]: loss 4.583475
[epoch3, step2567]: loss 24.790947
[epoch3, step2568]: loss 3.082157
[epoch3, step2569]: loss 23.497482
[epoch3, step2570]: loss 26.224167
[epoch3, step2571]: loss 37.742950
[epoch3, step2572]: loss 5.068619
[epoch3, step2573]: loss 4.373801
[epoch3, step2574]: loss 24.514997
[epoch3, step2575]: loss 3.758700
[epoch3, step2576]: loss 20.363363
[epoch3, step2577]: loss 20.496006
[epoch3, step2578]: loss 6.256840
[epoch3, step2579]: loss 5.965461
[epoch3, step2580]: loss 4.872259
[epoch3, step2581]: loss 3.631553
[epoch3, step2582]: loss 3.811237
[epoch3, step2583]: loss 4.540287
[epoch3, step2584]: loss 3.515767
[epoch3, step2585]: loss 4.398772
[epoch3, step2586]: loss 7.343592
[epoch3, step2587]: loss 2.580925
[epoch3, step2588]: loss 10.124269
[epoch3, step2589]: loss 7.392118
[epoch3, step2590]: loss 60.467987
[epoch3, step2591]: loss 6.867379
[epoch3, step2592]: loss 4.450916
[epoch3, step2593]: loss 5.800416
[epoch3, step2594]: loss 7.844430
[epoch3, step2595]: loss 28.796318
[epoch3, step2596]: loss 44.037807
[epoch3, step2597]: loss 28.190481
[epoch3, step2598]: loss 48.362068
[epoch3, step2599]: loss 4.451045
[epoch3, step2600]: loss 6.240599
[epoch3, step2601]: loss 3.961592
[epoch3, step2602]: loss 21.898193
[epoch3, step2603]: loss 11.458173
[epoch3, step2604]: loss 6.362362
[epoch3, step2605]: loss 3.956592
[epoch3, step2606]: loss 37.228249
[epoch3, step2607]: loss 17.439260
[epoch3, step2608]: loss 12.516626
[epoch3, step2609]: loss 3.439236
[epoch3, step2610]: loss 38.736870
[epoch3, step2611]: loss 29.295156
[epoch3, step2612]: loss 4.175561
[epoch3, step2613]: loss 10.133635
[epoch3, step2614]: loss 9.272492
[epoch3, step2615]: loss 41.584171
[epoch3, step2616]: loss 20.506821
[epoch3, step2617]: loss 3.629241
[epoch3, step2618]: loss 4.803553
[epoch3, step2619]: loss 32.265106
[epoch3, step2620]: loss 23.772928
[epoch3, step2621]: loss 15.221043
[epoch3, step2622]: loss 12.983461
[epoch3, step2623]: loss 5.382845
[epoch3, step2624]: loss 7.431222
[epoch3, step2625]: loss 18.878756
[epoch3, step2626]: loss 14.558333
[epoch3, step2627]: loss 12.775293
[epoch3, step2628]: loss 27.266872
[epoch3, step2629]: loss 4.068195
[epoch3, step2630]: loss 5.205133
[epoch3, step2631]: loss 6.660197
[epoch3, step2632]: loss 6.178358
[epoch3, step2633]: loss 7.137547
[epoch3, step2634]: loss 20.208523
[epoch3, step2635]: loss 40.836594
[epoch3, step2636]: loss 6.843036
[epoch3, step2637]: loss 5.318697
[epoch3, step2638]: loss 4.617842
[epoch3, step2639]: loss 9.302548
[epoch3, step2640]: loss 6.025147
[epoch3, step2641]: loss 2.766288
[epoch3, step2642]: loss 20.139565
[epoch3, step2643]: loss 4.663488
[epoch3, step2644]: loss 21.032087
[epoch3, step2645]: loss 8.527466
[epoch3, step2646]: loss 5.544941
[epoch3, step2647]: loss 13.148229
[epoch3, step2648]: loss 18.680517
[epoch3, step2649]: loss 7.824876
[epoch3, step2650]: loss 19.771347
[epoch3, step2651]: loss 5.473669
[epoch3, step2652]: loss 22.008675
[epoch3, step2653]: loss 5.915798
[epoch3, step2654]: loss 7.322423
[epoch3, step2655]: loss 23.639809
[epoch3, step2656]: loss 7.827351
[epoch3, step2657]: loss 9.367807
[epoch3, step2658]: loss 2.330439
[epoch3, step2659]: loss 15.418905
[epoch3, step2660]: loss 28.198254
[epoch3, step2661]: loss 7.101067
[epoch3, step2662]: loss 5.933012
[epoch3, step2663]: loss 5.929094
[epoch3, step2664]: loss 4.139172
[epoch3, step2665]: loss 4.884962
[epoch3, step2666]: loss 4.573986
[epoch3, step2667]: loss 4.129110
[epoch3, step2668]: loss 25.849995
[epoch3, step2669]: loss 5.199535
[epoch3, step2670]: loss 4.650905
[epoch3, step2671]: loss 15.270207
[epoch3, step2672]: loss 20.273703
[epoch3, step2673]: loss 2.671206
[epoch3, step2674]: loss 32.934601
[epoch3, step2675]: loss 23.155571
[epoch3, step2676]: loss 3.061940
[epoch3, step2677]: loss 23.795399
[epoch3, step2678]: loss 36.438366
[epoch3, step2679]: loss 6.748013
[epoch3, step2680]: loss 4.000451
[epoch3, step2681]: loss 7.914664
[epoch3, step2682]: loss 6.260441
[epoch3, step2683]: loss 3.032845
[epoch3, step2684]: loss 4.445579
[epoch3, step2685]: loss 9.578420
[epoch3, step2686]: loss 18.604446
[epoch3, step2687]: loss 3.164273
[epoch3, step2688]: loss 42.886452
[epoch3, step2689]: loss 8.588175
[epoch3, step2690]: loss 30.241478
[epoch3, step2691]: loss 4.205413
[epoch3, step2692]: loss 20.844414
[epoch3, step2693]: loss 24.223898
[epoch3, step2694]: loss 6.347720
[epoch3, step2695]: loss 18.666527
[epoch3, step2696]: loss 6.188140
[epoch3, step2697]: loss 29.753500
[epoch3, step2698]: loss 4.471308
[epoch3, step2699]: loss 8.134392
[epoch3, step2700]: loss 2.560390
[epoch3, step2701]: loss 7.270364
[epoch3, step2702]: loss 9.610270
[epoch3, step2703]: loss 27.982372
[epoch3, step2704]: loss 6.224017
[epoch3, step2705]: loss 4.852399
[epoch3, step2706]: loss 6.632895
[epoch3, step2707]: loss 27.789948
[epoch3, step2708]: loss 5.492499
[epoch3, step2709]: loss 4.627120
[epoch3, step2710]: loss 16.179125
[epoch3, step2711]: loss 14.808858
[epoch3, step2712]: loss 2.837731
[epoch3, step2713]: loss 53.299408
[epoch3, step2714]: loss 6.428859
[epoch3, step2715]: loss 19.167982
[epoch3, step2716]: loss 18.771549
[epoch3, step2717]: loss 6.345671
[epoch3, step2718]: loss 3.528154
[epoch3, step2719]: loss 5.146266
[epoch3, step2720]: loss 9.533184
[epoch3, step2721]: loss 19.920204
[epoch3, step2722]: loss 4.141434
[epoch3, step2723]: loss 3.370348
[epoch3, step2724]: loss 27.482180
[epoch3, step2725]: loss 14.568173
[epoch3, step2726]: loss 2.804338
[epoch3, step2727]: loss 2.928115
[epoch3, step2728]: loss 3.515275
[epoch3, step2729]: loss 33.047512
[epoch3, step2730]: loss 4.087711
[epoch3, step2731]: loss 5.151494
[epoch3, step2732]: loss 5.344158
[epoch3, step2733]: loss 4.325700
[epoch3, step2734]: loss 6.256883
[epoch3, step2735]: loss 57.173374
[epoch3, step2736]: loss 3.064082
[epoch3, step2737]: loss 18.102240
[epoch3, step2738]: loss 30.007004
[epoch3, step2739]: loss 41.530025
[epoch3, step2740]: loss 2.519335
[epoch3, step2741]: loss 6.229515
[epoch3, step2742]: loss 3.878490
[epoch3, step2743]: loss 27.301645
[epoch3, step2744]: loss 5.717528
[epoch3, step2745]: loss 18.588844
[epoch3, step2746]: loss 8.703410
[epoch3, step2747]: loss 5.251540
[epoch3, step2748]: loss 7.732229
[epoch3, step2749]: loss 52.085365
[epoch3, step2750]: loss 3.088013
[epoch3, step2751]: loss 39.463196
[epoch3, step2752]: loss 5.386778
[epoch3, step2753]: loss 6.834961
[epoch3, step2754]: loss 28.964382
[epoch3, step2755]: loss 8.606399
[epoch3, step2756]: loss 4.937358
[epoch3, step2757]: loss 4.217865
[epoch3, step2758]: loss 5.635038
[epoch3, step2759]: loss 3.686157
[epoch3, step2760]: loss 17.256153
[epoch3, step2761]: loss 3.412183
[epoch3, step2762]: loss 4.545041
[epoch3, step2763]: loss 28.878771
[epoch3, step2764]: loss 6.120753
[epoch3, step2765]: loss 2.333802
[epoch3, step2766]: loss 3.665914
[epoch3, step2767]: loss 2.599827
[epoch3, step2768]: loss 15.903227
[epoch3, step2769]: loss 4.439845
[epoch3, step2770]: loss 9.411827
[epoch3, step2771]: loss 23.708197
[epoch3, step2772]: loss 22.574158
[epoch3, step2773]: loss 53.638760
[epoch3, step2774]: loss 3.897486
[epoch3, step2775]: loss 6.109482
[epoch3, step2776]: loss 3.313518
[epoch3, step2777]: loss 11.420790
[epoch3, step2778]: loss 22.395168
[epoch3, step2779]: loss 85.855888
[epoch3, step2780]: loss 10.657884
[epoch3, step2781]: loss 6.750149
[epoch3, step2782]: loss 6.548639
[epoch3, step2783]: loss 6.691664
[epoch3, step2784]: loss 16.094624
[epoch3, step2785]: loss 3.443128
[epoch3, step2786]: loss 5.184900
[epoch3, step2787]: loss 27.072079
[epoch3, step2788]: loss 6.371933
[epoch3, step2789]: loss 5.702192
[epoch3, step2790]: loss 19.706385
[epoch3, step2791]: loss 23.415428
[epoch3, step2792]: loss 4.394268
[epoch3, step2793]: loss 8.807879
[epoch3, step2794]: loss 7.014165
[epoch3, step2795]: loss 23.353127
[epoch3, step2796]: loss 17.230518
[epoch3, step2797]: loss 17.574203
[epoch3, step2798]: loss 8.555149
[epoch3, step2799]: loss 23.720608
[epoch3, step2800]: loss 8.850919
[epoch3, step2801]: loss 7.438874
[epoch3, step2802]: loss 6.643390
[epoch3, step2803]: loss 8.105516
[epoch3, step2804]: loss 3.158466
[epoch3, step2805]: loss 4.845695
[epoch3, step2806]: loss 7.323906
[epoch3, step2807]: loss 3.657624
[epoch3, step2808]: loss 5.537898
[epoch3, step2809]: loss 15.672931
[epoch3, step2810]: loss 5.188920
[epoch3, step2811]: loss 4.133791
[epoch3, step2812]: loss 5.829439
[epoch3, step2813]: loss 31.532227
[epoch3, step2814]: loss 22.964857
[epoch3, step2815]: loss 22.271360
[epoch3, step2816]: loss 20.052032
[epoch3, step2817]: loss 5.465182
[epoch3, step2818]: loss 4.445361
[epoch3, step2819]: loss 2.821852
[epoch3, step2820]: loss 4.057380
[epoch3, step2821]: loss 5.944304
[epoch3, step2822]: loss 3.259369
[epoch3, step2823]: loss 9.862999
[epoch3, step2824]: loss 6.557034
[epoch3, step2825]: loss 10.255834
[epoch3, step2826]: loss 40.968658
[epoch3, step2827]: loss 15.922808
[epoch3, step2828]: loss 2.664927
[epoch3, step2829]: loss 22.592897
[epoch3, step2830]: loss 3.097430
[epoch3, step2831]: loss 10.547455
[epoch3, step2832]: loss 4.026452
[epoch3, step2833]: loss 2.790347
[epoch3, step2834]: loss 33.490673
[epoch3, step2835]: loss 22.500591
[epoch3, step2836]: loss 7.626933
[epoch3, step2837]: loss 25.713129
[epoch3, step2838]: loss 5.946939
[epoch3, step2839]: loss 7.464446
[epoch3, step2840]: loss 4.269337
[epoch3, step2841]: loss 48.167900
[epoch3, step2842]: loss 31.655180
[epoch3, step2843]: loss 4.690853
[epoch3, step2844]: loss 2.452834
[epoch3, step2845]: loss 18.975716
[epoch3, step2846]: loss 7.322475
[epoch3, step2847]: loss 2.406286
[epoch3, step2848]: loss 20.290995
[epoch3, step2849]: loss 6.035962
[epoch3, step2850]: loss 17.943718
[epoch3, step2851]: loss 2.517559
[epoch3, step2852]: loss 17.673389
[epoch3, step2853]: loss 10.498623
[epoch3, step2854]: loss 15.739154
[epoch3, step2855]: loss 4.033966
[epoch3, step2856]: loss 18.772310
[epoch3, step2857]: loss 13.809362
[epoch3, step2858]: loss 25.560324
[epoch3, step2859]: loss 5.110832
[epoch3, step2860]: loss 7.609636
[epoch3, step2861]: loss 7.871147
[epoch3, step2862]: loss 16.073929
[epoch3, step2863]: loss 21.166574
[epoch3, step2864]: loss 9.992189
[epoch3, step2865]: loss 6.660826
[epoch3, step2866]: loss 8.723763
[epoch3, step2867]: loss 15.628713
[epoch3, step2868]: loss 7.210781
[epoch3, step2869]: loss 4.929888
[epoch3, step2870]: loss 21.258293
[epoch3, step2871]: loss 10.098850
[epoch3, step2872]: loss 7.257587
[epoch3, step2873]: loss 28.336788
[epoch3, step2874]: loss 45.297592
[epoch3, step2875]: loss 30.480642
[epoch3, step2876]: loss 4.941842
[epoch3, step2877]: loss 8.661860
[epoch3, step2878]: loss 5.273561
[epoch3, step2879]: loss 10.954926
[epoch3, step2880]: loss 6.980899
[epoch3, step2881]: loss 2.923250
[epoch3, step2882]: loss 18.839930
[epoch3, step2883]: loss 10.587166
[epoch3, step2884]: loss 5.194710
[epoch3, step2885]: loss 20.914572
[epoch3, step2886]: loss 11.611261
[epoch3, step2887]: loss 2.885723
[epoch3, step2888]: loss 28.158895
[epoch3, step2889]: loss 5.621553
[epoch3, step2890]: loss 7.580489
[epoch3, step2891]: loss 20.902637
[epoch3, step2892]: loss 25.051716
[epoch3, step2893]: loss 4.364436
[epoch3, step2894]: loss 5.674932
[epoch3, step2895]: loss 16.367846
[epoch3, step2896]: loss 7.172108
[epoch3, step2897]: loss 15.674387
[epoch3, step2898]: loss 6.717184
[epoch3, step2899]: loss 7.033263
[epoch3, step2900]: loss 26.286489
[epoch3, step2901]: loss 3.053753
[epoch3, step2902]: loss 30.386257
[epoch3, step2903]: loss 2.909738
[epoch3, step2904]: loss 4.154854
[epoch3, step2905]: loss 4.062119
[epoch3, step2906]: loss 2.589689
[epoch3, step2907]: loss 2.948358
[epoch3, step2908]: loss 11.306437
[epoch3, step2909]: loss 2.939651
[epoch3, step2910]: loss 29.522316
[epoch3, step2911]: loss 5.500761
[epoch3, step2912]: loss 13.886924
[epoch3, step2913]: loss 5.392375
[epoch3, step2914]: loss 45.089123
[epoch3, step2915]: loss 3.079014
[epoch3, step2916]: loss 10.451201
[epoch3, step2917]: loss 17.277136
[epoch3, step2918]: loss 4.436425
[epoch3, step2919]: loss 3.021580
[epoch3, step2920]: loss 6.557674
[epoch3, step2921]: loss 35.252937
[epoch3, step2922]: loss 13.448648
[epoch3, step2923]: loss 6.976073
[epoch3, step2924]: loss 7.113073
[epoch3, step2925]: loss 24.252005
[epoch3, step2926]: loss 9.049301
[epoch3, step2927]: loss 18.265951
[epoch3, step2928]: loss 2.241887
[epoch3, step2929]: loss 20.491524
[epoch3, step2930]: loss 25.147404
[epoch3, step2931]: loss 46.972431
[epoch3, step2932]: loss 39.558609
[epoch3, step2933]: loss 3.881834
[epoch3, step2934]: loss 17.210323
[epoch3, step2935]: loss 2.023292
[epoch3, step2936]: loss 75.084503
[epoch3, step2937]: loss 2.117014
[epoch3, step2938]: loss 5.979646
[epoch3, step2939]: loss 49.078636
[epoch3, step2940]: loss 17.573992
[epoch3, step2941]: loss 9.479495
[epoch3, step2942]: loss 5.433795
[epoch3, step2943]: loss 24.055140
[epoch3, step2944]: loss 3.199576
[epoch3, step2945]: loss 46.722862
[epoch3, step2946]: loss 28.485540
[epoch3, step2947]: loss 5.348105
[epoch3, step2948]: loss 2.810550
[epoch3, step2949]: loss 6.215860
[epoch3, step2950]: loss 3.663478
[epoch3, step2951]: loss 16.288370
[epoch3, step2952]: loss 2.590129
[epoch3, step2953]: loss 2.872263
[epoch3, step2954]: loss 6.566254
[epoch3, step2955]: loss 6.360837
[epoch3, step2956]: loss 20.119520
[epoch3, step2957]: loss 18.460278
[epoch3, step2958]: loss 25.449306
[epoch3, step2959]: loss 9.734256
[epoch3, step2960]: loss 6.998102
[epoch3, step2961]: loss 4.036149
[epoch3, step2962]: loss 10.523198
[epoch3, step2963]: loss 33.505917
[epoch3, step2964]: loss 18.999332
[epoch3, step2965]: loss 10.451628
[epoch3, step2966]: loss 10.230030
[epoch3, step2967]: loss 31.198795
[epoch3, step2968]: loss 25.341600
[epoch3, step2969]: loss 16.776079
[epoch3, step2970]: loss 24.329533
[epoch3, step2971]: loss 5.383485
[epoch3, step2972]: loss 6.309917
[epoch3, step2973]: loss 26.942503
[epoch3, step2974]: loss 19.604309
[epoch3, step2975]: loss 23.219215
[epoch3, step2976]: loss 36.429272
[epoch3, step2977]: loss 3.051195
[epoch3, step2978]: loss 26.754772
[epoch3, step2979]: loss 28.713947
[epoch3, step2980]: loss 3.562694
[epoch3, step2981]: loss 8.522865
[epoch3, step2982]: loss 16.334024
[epoch3, step2983]: loss 3.064944
[epoch3, step2984]: loss 6.258643
[epoch3, step2985]: loss 7.598449
[epoch3, step2986]: loss 6.041329
[epoch3, step2987]: loss 3.973570
[epoch3, step2988]: loss 4.972857
[epoch3, step2989]: loss 11.524509
[epoch3, step2990]: loss 7.311878
[epoch3, step2991]: loss 32.697098
[epoch3, step2992]: loss 5.196999
[epoch3, step2993]: loss 3.532372
[epoch3, step2994]: loss 33.366341
[epoch3, step2995]: loss 3.698258
[epoch3, step2996]: loss 26.211142
[epoch3, step2997]: loss 29.968494
[epoch3, step2998]: loss 2.423593
[epoch3, step2999]: loss 8.452144
[epoch3, step3000]: loss 25.441721
[epoch3, step3001]: loss 10.987511
[epoch3, step3002]: loss 10.915207
[epoch3, step3003]: loss 24.155737
[epoch3, step3004]: loss 19.455418
[epoch3, step3005]: loss 7.623014
[epoch3, step3006]: loss 21.436848
[epoch3, step3007]: loss 16.188200
[epoch3, step3008]: loss 15.257475
[epoch3, step3009]: loss 18.112259
[epoch3, step3010]: loss 3.433065
[epoch3, step3011]: loss 5.150337
[epoch3, step3012]: loss 16.467505
[epoch3, step3013]: loss 3.300021
[epoch3, step3014]: loss 12.064818
[epoch3, step3015]: loss 14.227117
[epoch3, step3016]: loss 10.568228
[epoch3, step3017]: loss 2.551917
[epoch3, step3018]: loss 44.981163
[epoch3, step3019]: loss 16.401409
[epoch3, step3020]: loss 17.562386
[epoch3, step3021]: loss 14.865291
[epoch3, step3022]: loss 4.835985
[epoch3, step3023]: loss 2.658569
[epoch3, step3024]: loss 2.573957
[epoch3, step3025]: loss 22.216726
[epoch3, step3026]: loss 9.251948
[epoch3, step3027]: loss 7.416303
[epoch3, step3028]: loss 29.574154
[epoch3, step3029]: loss 3.233345
[epoch3, step3030]: loss 2.125051
[epoch3, step3031]: loss 5.889336
[epoch3, step3032]: loss 47.982479
[epoch3, step3033]: loss 24.401989
[epoch3, step3034]: loss 2.675199
[epoch3, step3035]: loss 24.672455
[epoch3, step3036]: loss 16.416468
[epoch3, step3037]: loss 6.327663
[epoch3, step3038]: loss 8.342428
[epoch3, step3039]: loss 22.718367
[epoch3, step3040]: loss 34.477303
[epoch3, step3041]: loss 17.388605
[epoch3, step3042]: loss 18.755215
[epoch3, step3043]: loss 7.622312
[epoch3, step3044]: loss 47.176243
[epoch3, step3045]: loss 8.605941
[epoch3, step3046]: loss 3.330989
[epoch3, step3047]: loss 29.719940
[epoch3, step3048]: loss 4.344258
[epoch3, step3049]: loss 16.974268
[epoch3, step3050]: loss 5.569346
[epoch3, step3051]: loss 3.616756
[epoch3, step3052]: loss 3.802722
[epoch3, step3053]: loss 3.975295
[epoch3, step3054]: loss 8.120284
[epoch3, step3055]: loss 5.717612
[epoch3, step3056]: loss 32.879604
[epoch3, step3057]: loss 21.363861
[epoch3, step3058]: loss 10.065321
[epoch3, step3059]: loss 4.896856
[epoch3, step3060]: loss 5.354045
[epoch3, step3061]: loss 48.960060
[epoch3, step3062]: loss 7.845224
[epoch3, step3063]: loss 3.240422
[epoch3, step3064]: loss 3.511403
[epoch3, step3065]: loss 35.657475
[epoch3, step3066]: loss 4.759612
[epoch3, step3067]: loss 47.115601
[epoch3, step3068]: loss 18.762657
[epoch3, step3069]: loss 5.826381
[epoch3, step3070]: loss 23.095638
[epoch3, step3071]: loss 7.118202
[epoch3, step3072]: loss 4.250509
[epoch3, step3073]: loss 6.484555
[epoch3, step3074]: loss 7.901384
[epoch3, step3075]: loss 22.896248
[epoch3, step3076]: loss 5.615309

[epoch3]: avg loss 5.615309

[epoch4, step1]: loss 24.263893
[epoch4, step2]: loss 8.761655
[epoch4, step3]: loss 2.384346
[epoch4, step4]: loss 23.105549
[epoch4, step5]: loss 8.106769
[epoch4, step6]: loss 18.998831
[epoch4, step7]: loss 5.434931
[epoch4, step8]: loss 5.461721
[epoch4, step9]: loss 6.218179
[epoch4, step10]: loss 4.161425
[epoch4, step11]: loss 25.633850
[epoch4, step12]: loss 3.514982
[epoch4, step13]: loss 9.677845
[epoch4, step14]: loss 10.592126
[epoch4, step15]: loss 5.725253
[epoch4, step16]: loss 22.056152
[epoch4, step17]: loss 7.550146
[epoch4, step18]: loss 12.675106
[epoch4, step19]: loss 15.778077
[epoch4, step20]: loss 1.938633
[epoch4, step21]: loss 19.647341
[epoch4, step22]: loss 12.743247
[epoch4, step23]: loss 21.352568
[epoch4, step24]: loss 1.775694
[epoch4, step25]: loss 6.205960
[epoch4, step26]: loss 45.258759
[epoch4, step27]: loss 38.973328
[epoch4, step28]: loss 3.655164
[epoch4, step29]: loss 25.615656
[epoch4, step30]: loss 12.918537
[epoch4, step31]: loss 26.120457
[epoch4, step32]: loss 28.578440
[epoch4, step33]: loss 6.350979
[epoch4, step34]: loss 7.254847
[epoch4, step35]: loss 2.824503
[epoch4, step36]: loss 22.507868
[epoch4, step37]: loss 17.265310
[epoch4, step38]: loss 24.060759
[epoch4, step39]: loss 6.033003
[epoch4, step40]: loss 6.241502
[epoch4, step41]: loss 4.116632
[epoch4, step42]: loss 4.516701
[epoch4, step43]: loss 21.671434
[epoch4, step44]: loss 3.617786
[epoch4, step45]: loss 28.591307
[epoch4, step46]: loss 2.632826
[epoch4, step47]: loss 9.060642
[epoch4, step48]: loss 7.801464
[epoch4, step49]: loss 29.401030
[epoch4, step50]: loss 2.919534
[epoch4, step51]: loss 2.987044
[epoch4, step52]: loss 23.082220
[epoch4, step53]: loss 5.531990
[epoch4, step54]: loss 35.181065
[epoch4, step55]: loss 16.151867
[epoch4, step56]: loss 4.683168
[epoch4, step57]: loss 25.974304
[epoch4, step58]: loss 22.377573
[epoch4, step59]: loss 16.375408
[epoch4, step60]: loss 8.503471
[epoch4, step61]: loss 3.591342
[epoch4, step62]: loss 5.000672
[epoch4, step63]: loss 3.789709
[epoch4, step64]: loss 8.016176
[epoch4, step65]: loss 19.634796
[epoch4, step66]: loss 14.762022
[epoch4, step67]: loss 25.123325
[epoch4, step68]: loss 2.400604
[epoch4, step69]: loss 18.656414
[epoch4, step70]: loss 5.850369
[epoch4, step71]: loss 22.307346
[epoch4, step72]: loss 5.444444
[epoch4, step73]: loss 4.179528
[epoch4, step74]: loss 3.781588
[epoch4, step75]: loss 15.999621
[epoch4, step76]: loss 3.953913
[epoch4, step77]: loss 5.127323
[epoch4, step78]: loss 19.658840
[epoch4, step79]: loss 6.861454
[epoch4, step80]: loss 3.806845
[epoch4, step81]: loss 4.084569
[epoch4, step82]: loss 20.192591
[epoch4, step83]: loss 7.630745
[epoch4, step84]: loss 6.118292
[epoch4, step85]: loss 25.876835
[epoch4, step86]: loss 43.133770
[epoch4, step87]: loss 37.557240
[epoch4, step88]: loss 4.751577
[epoch4, step89]: loss 6.599491
[epoch4, step90]: loss 12.470051
[epoch4, step91]: loss 53.634499
[epoch4, step92]: loss 7.675476
[epoch4, step93]: loss 5.770716
[epoch4, step94]: loss 18.341280
[epoch4, step95]: loss 49.354145
[epoch4, step96]: loss 3.117322
[epoch4, step97]: loss 25.411781
[epoch4, step98]: loss 2.950794
[epoch4, step99]: loss 28.477451
[epoch4, step100]: loss 7.489044
[epoch4, step101]: loss 5.251070
[epoch4, step102]: loss 3.199753
[epoch4, step103]: loss 6.025838
[epoch4, step104]: loss 6.738284
[epoch4, step105]: loss 33.018356
[epoch4, step106]: loss 17.044952
[epoch4, step107]: loss 4.572486
[epoch4, step108]: loss 24.745481
[epoch4, step109]: loss 2.151850
[epoch4, step110]: loss 4.134574
[epoch4, step111]: loss 21.592949
[epoch4, step112]: loss 20.064560
[epoch4, step113]: loss 8.661533
[epoch4, step114]: loss 15.205597
[epoch4, step115]: loss 19.150288
[epoch4, step116]: loss 17.206158
[epoch4, step117]: loss 8.133703
[epoch4, step118]: loss 57.872601
[epoch4, step119]: loss 16.267384
[epoch4, step120]: loss 3.921777
[epoch4, step121]: loss 20.871420
[epoch4, step122]: loss 3.744465
[epoch4, step123]: loss 25.389778
[epoch4, step124]: loss 3.312808
[epoch4, step125]: loss 7.083360
[epoch4, step126]: loss 4.274858
[epoch4, step127]: loss 27.876122
[epoch4, step128]: loss 29.014408
[epoch4, step129]: loss 4.020571
[epoch4, step130]: loss 2.175127
[epoch4, step131]: loss 6.056791
[epoch4, step132]: loss 20.271421
[epoch4, step133]: loss 15.629218
[epoch4, step134]: loss 25.526352
[epoch4, step135]: loss 31.046160
[epoch4, step136]: loss 9.670609
[epoch4, step137]: loss 3.655565
[epoch4, step138]: loss 16.575459
[epoch4, step139]: loss 3.187775
[epoch4, step140]: loss 29.739202
[epoch4, step141]: loss 5.029264
[epoch4, step142]: loss 5.595455
[epoch4, step143]: loss 6.140625
[epoch4, step144]: loss 2.806790
[epoch4, step145]: loss 2.688215
[epoch4, step146]: loss 4.385961
[epoch4, step147]: loss 18.672548
[epoch4, step148]: loss 28.832186
[epoch4, step149]: loss 25.036491
[epoch4, step150]: loss 6.332193
[epoch4, step151]: loss 13.812878
[epoch4, step152]: loss 3.415220
[epoch4, step153]: loss 4.245202
[epoch4, step154]: loss 23.427475
[epoch4, step155]: loss 3.867236
[epoch4, step156]: loss 5.938803
[epoch4, step157]: loss 9.654523
[epoch4, step158]: loss 6.564414
[epoch4, step159]: loss 2.459820
[epoch4, step160]: loss 64.116371
[epoch4, step161]: loss 11.657350
[epoch4, step162]: loss 16.432663
[epoch4, step163]: loss 4.787165
[epoch4, step164]: loss 22.312357
[epoch4, step165]: loss 14.385674
[epoch4, step166]: loss 52.271561
[epoch4, step167]: loss 8.313869
[epoch4, step168]: loss 17.172960
[epoch4, step169]: loss 18.419746
[epoch4, step170]: loss 4.862652
[epoch4, step171]: loss 63.581993
[epoch4, step172]: loss 9.234542
[epoch4, step173]: loss 11.813093
[epoch4, step174]: loss 3.865340
[epoch4, step175]: loss 2.887524
[epoch4, step176]: loss 23.784954
[epoch4, step177]: loss 3.850355
[epoch4, step178]: loss 32.485516
[epoch4, step179]: loss 28.926626
[epoch4, step180]: loss 42.900539
[epoch4, step181]: loss 4.384614
[epoch4, step182]: loss 4.776787
[epoch4, step183]: loss 5.333620
[epoch4, step184]: loss 3.638116
[epoch4, step185]: loss 3.324928
[epoch4, step186]: loss 16.660801
[epoch4, step187]: loss 7.230466
[epoch4, step188]: loss 20.377296
[epoch4, step189]: loss 2.132376
[epoch4, step190]: loss 4.968820
[epoch4, step191]: loss 2.551521
[epoch4, step192]: loss 15.684297
[epoch4, step193]: loss 3.920042
[epoch4, step194]: loss 7.212201
[epoch4, step195]: loss 25.847303
[epoch4, step196]: loss 25.890215
[epoch4, step197]: loss 35.457333
[epoch4, step198]: loss 3.666706
[epoch4, step199]: loss 7.226317
[epoch4, step200]: loss 28.997665
[epoch4, step201]: loss 2.520530
[epoch4, step202]: loss 3.494746
[epoch4, step203]: loss 3.849590
[epoch4, step204]: loss 2.788168
[epoch4, step205]: loss 8.200984
[epoch4, step206]: loss 7.237948
[epoch4, step207]: loss 8.165597
[epoch4, step208]: loss 39.328472
[epoch4, step209]: loss 22.889757
[epoch4, step210]: loss 16.353212
[epoch4, step211]: loss 19.638201
[epoch4, step212]: loss 2.584360
[epoch4, step213]: loss 16.403513
[epoch4, step214]: loss 30.044510
[epoch4, step215]: loss 11.532537
[epoch4, step216]: loss 4.402320
[epoch4, step217]: loss 44.261383
[epoch4, step218]: loss 3.631310
[epoch4, step219]: loss 13.907897
[epoch4, step220]: loss 38.939392
[epoch4, step221]: loss 3.169616
[epoch4, step222]: loss 3.189239
[epoch4, step223]: loss 14.208022
[epoch4, step224]: loss 5.132625
[epoch4, step225]: loss 37.553154
[epoch4, step226]: loss 4.112548
[epoch4, step227]: loss 3.107821
[epoch4, step228]: loss 13.889740
[epoch4, step229]: loss 4.321555
[epoch4, step230]: loss 30.320713
[epoch4, step231]: loss 3.626824
[epoch4, step232]: loss 11.439432
[epoch4, step233]: loss 18.082409
[epoch4, step234]: loss 4.050344
[epoch4, step235]: loss 2.514189
[epoch4, step236]: loss 6.173284
[epoch4, step237]: loss 3.865030
[epoch4, step238]: loss 10.835574
[epoch4, step239]: loss 22.113680
[epoch4, step240]: loss 4.698426
[epoch4, step241]: loss 4.577472
[epoch4, step242]: loss 5.836167
[epoch4, step243]: loss 2.639538
[epoch4, step244]: loss 14.079587
[epoch4, step245]: loss 24.586023
[epoch4, step246]: loss 3.457668
[epoch4, step247]: loss 2.639311
[epoch4, step248]: loss 4.180310
[epoch4, step249]: loss 23.925245
[epoch4, step250]: loss 4.486419
[epoch4, step251]: loss 7.747806
[epoch4, step252]: loss 7.417200
[epoch4, step253]: loss 23.192533
[epoch4, step254]: loss 4.946994
[epoch4, step255]: loss 4.172253
[epoch4, step256]: loss 2.540779
[epoch4, step257]: loss 5.172967
[epoch4, step258]: loss 2.937924
[epoch4, step259]: loss 6.053693
[epoch4, step260]: loss 4.523760
[epoch4, step261]: loss 15.401503
[epoch4, step262]: loss 26.595245
[epoch4, step263]: loss 18.546030
[epoch4, step264]: loss 5.060016
[epoch4, step265]: loss 3.758880
[epoch4, step266]: loss 8.924481
[epoch4, step267]: loss 11.518221
[epoch4, step268]: loss 13.881385
[epoch4, step269]: loss 16.217752
[epoch4, step270]: loss 5.482731
[epoch4, step271]: loss 9.510929
[epoch4, step272]: loss 25.116766
[epoch4, step273]: loss 25.116447
[epoch4, step274]: loss 3.618056
[epoch4, step275]: loss 25.449711
[epoch4, step276]: loss 6.705179
[epoch4, step277]: loss 6.895489
[epoch4, step278]: loss 42.059193
[epoch4, step279]: loss 2.867243
[epoch4, step280]: loss 6.294224
[epoch4, step281]: loss 6.935291
[epoch4, step282]: loss 40.206291
[epoch4, step283]: loss 14.393377
[epoch4, step284]: loss 3.974529
[epoch4, step285]: loss 23.049047
[epoch4, step286]: loss 7.798700
[epoch4, step287]: loss 9.135673
[epoch4, step288]: loss 4.250160
[epoch4, step289]: loss 30.987808
[epoch4, step290]: loss 24.750084
[epoch4, step291]: loss 4.392707
[epoch4, step292]: loss 2.386146
[epoch4, step293]: loss 6.729398
[epoch4, step294]: loss 6.786529
[epoch4, step295]: loss 8.409063
[epoch4, step296]: loss 3.812077
[epoch4, step297]: loss 5.590343
[epoch4, step298]: loss 5.234091
[epoch4, step299]: loss 3.605047
[epoch4, step300]: loss 4.158454
[epoch4, step301]: loss 3.417566
[epoch4, step302]: loss 5.218662
[epoch4, step303]: loss 4.038905
[epoch4, step304]: loss 24.962072
[epoch4, step305]: loss 12.792000
[epoch4, step306]: loss 22.229656
[epoch4, step307]: loss 35.801636
[epoch4, step308]: loss 5.959895
[epoch4, step309]: loss 4.824277
[epoch4, step310]: loss 5.811207
[epoch4, step311]: loss 21.794901
[epoch4, step312]: loss 4.398495
[epoch4, step313]: loss 5.552016
[epoch4, step314]: loss 6.678586
[epoch4, step315]: loss 8.444308
[epoch4, step316]: loss 6.467845
[epoch4, step317]: loss 11.357263
[epoch4, step318]: loss 8.220416
[epoch4, step319]: loss 12.346827
[epoch4, step320]: loss 3.435063
[epoch4, step321]: loss 5.776809
[epoch4, step322]: loss 7.603913
[epoch4, step323]: loss 4.411664
[epoch4, step324]: loss 1.898819
[epoch4, step325]: loss 5.748230
[epoch4, step326]: loss 50.278816
[epoch4, step327]: loss 26.242720
[epoch4, step328]: loss 2.485151
[epoch4, step329]: loss 4.445970
[epoch4, step330]: loss 6.017944
[epoch4, step331]: loss 36.032677
[epoch4, step332]: loss 2.600975
[epoch4, step333]: loss 6.768687
[epoch4, step334]: loss 7.939044
[epoch4, step335]: loss 3.637744
[epoch4, step336]: loss 5.201730
[epoch4, step337]: loss 53.904358
[epoch4, step338]: loss 19.764563
[epoch4, step339]: loss 7.929745
[epoch4, step340]: loss 19.333248
[epoch4, step341]: loss 12.216356
[epoch4, step342]: loss 57.773628
[epoch4, step343]: loss 4.610927
[epoch4, step344]: loss 2.410338
[epoch4, step345]: loss 5.437956
[epoch4, step346]: loss 17.127768
[epoch4, step347]: loss 3.051657
[epoch4, step348]: loss 25.676893
[epoch4, step349]: loss 18.020271
[epoch4, step350]: loss 24.089886
[epoch4, step351]: loss 15.084098
[epoch4, step352]: loss 2.629126
[epoch4, step353]: loss 20.962368
[epoch4, step354]: loss 23.939409
[epoch4, step355]: loss 5.444763
[epoch4, step356]: loss 19.473206
[epoch4, step357]: loss 22.408241
[epoch4, step358]: loss 3.603975
[epoch4, step359]: loss 8.975266
[epoch4, step360]: loss 6.199299
[epoch4, step361]: loss 30.614222
[epoch4, step362]: loss 12.505360
[epoch4, step363]: loss 3.820539
[epoch4, step364]: loss 5.924539
[epoch4, step365]: loss 16.632565
[epoch4, step366]: loss 29.036707
[epoch4, step367]: loss 27.143787
[epoch4, step368]: loss 4.448026
[epoch4, step369]: loss 4.873006
[epoch4, step370]: loss 19.393503
[epoch4, step371]: loss 18.994175
[epoch4, step372]: loss 5.337730
[epoch4, step373]: loss 5.767597
[epoch4, step374]: loss 29.681211
[epoch4, step375]: loss 10.686264
[epoch4, step376]: loss 4.563482
[epoch4, step377]: loss 13.912427
[epoch4, step378]: loss 9.332427
[epoch4, step379]: loss 3.762192
[epoch4, step380]: loss 24.744280
[epoch4, step381]: loss 21.311127
[epoch4, step382]: loss 2.858487
[epoch4, step383]: loss 18.192896
[epoch4, step384]: loss 18.339306
[epoch4, step385]: loss 9.768274
[epoch4, step386]: loss 4.340868
[epoch4, step387]: loss 7.542505
[epoch4, step388]: loss 2.728575
[epoch4, step389]: loss 2.712317
[epoch4, step390]: loss 3.214118
[epoch4, step391]: loss 30.852474
[epoch4, step392]: loss 3.179534
[epoch4, step393]: loss 7.450651
[epoch4, step394]: loss 7.906717
[epoch4, step395]: loss 5.564778
[epoch4, step396]: loss 15.890673
[epoch4, step397]: loss 29.840656
[epoch4, step398]: loss 7.615881
[epoch4, step399]: loss 1.812086
[epoch4, step400]: loss 3.953172
[epoch4, step401]: loss 26.489342
[epoch4, step402]: loss 4.680376
[epoch4, step403]: loss 2.670163
[epoch4, step404]: loss 9.494786
[epoch4, step405]: loss 5.827162
[epoch4, step406]: loss 4.887295
[epoch4, step407]: loss 51.299049
[epoch4, step408]: loss 41.616730
[epoch4, step409]: loss 5.938401
[epoch4, step410]: loss 2.397196
[epoch4, step411]: loss 23.808359
[epoch4, step412]: loss 14.986925
[epoch4, step413]: loss 18.140369
[epoch4, step414]: loss 16.885544
[epoch4, step415]: loss 8.477510
[epoch4, step416]: loss 12.495117
[epoch4, step417]: loss 2.609431
[epoch4, step418]: loss 21.099844
[epoch4, step419]: loss 6.751512
[epoch4, step420]: loss 36.536301
[epoch4, step421]: loss 3.239318
[epoch4, step422]: loss 5.717017
[epoch4, step423]: loss 2.739755
[epoch4, step424]: loss 3.960597
[epoch4, step425]: loss 32.270535
[epoch4, step426]: loss 4.418612
[epoch4, step427]: loss 37.106167
[epoch4, step428]: loss 27.882280
[epoch4, step429]: loss 3.130397
[epoch4, step430]: loss 3.061329
[epoch4, step431]: loss 15.824752
[epoch4, step432]: loss 4.368142
[epoch4, step433]: loss 24.390442
[epoch4, step434]: loss 4.554377
[epoch4, step435]: loss 6.130240
[epoch4, step436]: loss 44.363140
[epoch4, step437]: loss 4.237549
[epoch4, step438]: loss 1.990051
[epoch4, step439]: loss 3.293012
[epoch4, step440]: loss 8.044147
[epoch4, step441]: loss 4.119345
[epoch4, step442]: loss 2.898865
[epoch4, step443]: loss 6.816732
[epoch4, step444]: loss 24.494637
[epoch4, step445]: loss 33.918030
[epoch4, step446]: loss 3.526646
[epoch4, step447]: loss 6.329984
[epoch4, step448]: loss 22.964552
[epoch4, step449]: loss 27.397449
[epoch4, step450]: loss 3.603591
[epoch4, step451]: loss 2.754409
[epoch4, step452]: loss 19.446728
[epoch4, step453]: loss 53.278664
[epoch4, step454]: loss 47.176392
[epoch4, step455]: loss 23.514814
[epoch4, step456]: loss 29.288952
[epoch4, step457]: loss 40.214638
[epoch4, step458]: loss 11.093711
[epoch4, step459]: loss 2.841234
[epoch4, step460]: loss 4.764458
[epoch4, step461]: loss 41.330833
[epoch4, step462]: loss 8.012648
[epoch4, step463]: loss 7.193249
[epoch4, step464]: loss 16.684130
[epoch4, step465]: loss 26.202364
[epoch4, step466]: loss 17.327982
[epoch4, step467]: loss 35.977764
[epoch4, step468]: loss 3.924723
[epoch4, step469]: loss 3.272137
[epoch4, step470]: loss 4.308520
[epoch4, step471]: loss 9.309083
[epoch4, step472]: loss 4.641775
[epoch4, step473]: loss 7.731945
[epoch4, step474]: loss 2.956955
[epoch4, step475]: loss 36.677666
[epoch4, step476]: loss 2.142056
[epoch4, step477]: loss 24.481560
[epoch4, step478]: loss 3.048051
[epoch4, step479]: loss 19.228092
[epoch4, step480]: loss 6.712733
[epoch4, step481]: loss 14.470866
[epoch4, step482]: loss 10.481502
[epoch4, step483]: loss 3.012186
[epoch4, step484]: loss 4.296405
[epoch4, step485]: loss 32.474041
[epoch4, step486]: loss 2.946005
[epoch4, step487]: loss 2.006176
[epoch4, step488]: loss 33.016975
[epoch4, step489]: loss 4.077093
[epoch4, step490]: loss 4.325874
[epoch4, step491]: loss 6.445079
[epoch4, step492]: loss 33.066673
[epoch4, step493]: loss 7.766664
[epoch4, step494]: loss 2.946091
[epoch4, step495]: loss 6.270427
[epoch4, step496]: loss 5.339159
[epoch4, step497]: loss 7.539948
[epoch4, step498]: loss 4.794706
[epoch4, step499]: loss 34.653702
[epoch4, step500]: loss 4.528930
[epoch4, step501]: loss 3.597475
[epoch4, step502]: loss 36.222187
[epoch4, step503]: loss 6.339403
[epoch4, step504]: loss 19.489145
[epoch4, step505]: loss 3.179964
[epoch4, step506]: loss 21.295265
[epoch4, step507]: loss 2.358485
[epoch4, step508]: loss 11.491109
[epoch4, step509]: loss 7.262685
[epoch4, step510]: loss 17.727312
[epoch4, step511]: loss 6.890759
[epoch4, step512]: loss 8.276812
[epoch4, step513]: loss 33.786617
[epoch4, step514]: loss 6.024919
[epoch4, step515]: loss 4.240479
[epoch4, step516]: loss 6.038784
[epoch4, step517]: loss 47.533646
[epoch4, step518]: loss 6.468966
[epoch4, step519]: loss 6.527445
[epoch4, step520]: loss 3.656093
[epoch4, step521]: loss 5.961845
[epoch4, step522]: loss 28.174902
[epoch4, step523]: loss 22.457645
[epoch4, step524]: loss 17.986355
[epoch4, step525]: loss 15.536921
[epoch4, step526]: loss 4.073345
[epoch4, step527]: loss 4.508188
[epoch4, step528]: loss 15.126000
[epoch4, step529]: loss 4.076797
[epoch4, step530]: loss 3.379645
[epoch4, step531]: loss 7.629789
[epoch4, step532]: loss 8.163765
[epoch4, step533]: loss 7.953943
[epoch4, step534]: loss 3.174000
[epoch4, step535]: loss 2.959239
[epoch4, step536]: loss 7.001075
[epoch4, step537]: loss 6.758047
[epoch4, step538]: loss 3.271796
[epoch4, step539]: loss 7.317443
[epoch4, step540]: loss 48.342762
[epoch4, step541]: loss 2.817397
[epoch4, step542]: loss 7.582912
[epoch4, step543]: loss 2.890996
[epoch4, step544]: loss 2.206683
[epoch4, step545]: loss 7.038924
[epoch4, step546]: loss 36.756798
[epoch4, step547]: loss 4.859706
[epoch4, step548]: loss 2.034287
[epoch4, step549]: loss 4.440756
[epoch4, step550]: loss 20.371355
[epoch4, step551]: loss 21.858704
[epoch4, step552]: loss 34.728302
[epoch4, step553]: loss 12.018328
[epoch4, step554]: loss 4.172169
[epoch4, step555]: loss 7.573456
[epoch4, step556]: loss 23.443800
[epoch4, step557]: loss 2.830209
[epoch4, step558]: loss 3.281549
[epoch4, step559]: loss 7.254748
[epoch4, step560]: loss 10.694490
[epoch4, step561]: loss 5.476988
[epoch4, step562]: loss 11.947191
[epoch4, step563]: loss 15.501690
[epoch4, step564]: loss 18.607615
[epoch4, step565]: loss 26.150537
[epoch4, step566]: loss 16.678368
[epoch4, step567]: loss 31.017588
[epoch4, step568]: loss 32.915131
[epoch4, step569]: loss 2.080820
[epoch4, step570]: loss 4.493948
[epoch4, step571]: loss 2.090562
[epoch4, step572]: loss 2.383980
[epoch4, step573]: loss 14.599765
[epoch4, step574]: loss 7.765595
[epoch4, step575]: loss 3.720026
[epoch4, step576]: loss 32.182842
[epoch4, step577]: loss 38.326702
[epoch4, step578]: loss 2.733824
[epoch4, step579]: loss 2.703198
[epoch4, step580]: loss 18.063471
[epoch4, step581]: loss 25.101004
[epoch4, step582]: loss 4.095142
[epoch4, step583]: loss 16.725586
[epoch4, step584]: loss 4.062737
[epoch4, step585]: loss 5.878508
[epoch4, step586]: loss 9.375624
[epoch4, step587]: loss 19.946650
[epoch4, step588]: loss 3.518503
[epoch4, step589]: loss 3.671764
[epoch4, step590]: loss 3.223100
[epoch4, step591]: loss 2.067299
[epoch4, step592]: loss 15.651674
[epoch4, step593]: loss 6.439742
[epoch4, step594]: loss 8.383211
[epoch4, step595]: loss 17.745668
[epoch4, step596]: loss 8.681608
[epoch4, step597]: loss 24.500834
[epoch4, step598]: loss 3.946338
[epoch4, step599]: loss 18.534540
[epoch4, step600]: loss 17.343271
[epoch4, step601]: loss 41.595009
[epoch4, step602]: loss 30.369591
[epoch4, step603]: loss 3.798828
[epoch4, step604]: loss 26.584303
[epoch4, step605]: loss 4.308128
[epoch4, step606]: loss 17.999952
[epoch4, step607]: loss 2.875088
[epoch4, step608]: loss 6.313219
[epoch4, step609]: loss 6.706720
[epoch4, step610]: loss 3.881853
[epoch4, step611]: loss 32.439289
[epoch4, step612]: loss 7.715949
[epoch4, step613]: loss 2.778655
[epoch4, step614]: loss 26.424881
[epoch4, step615]: loss 2.287367
[epoch4, step616]: loss 26.591171
[epoch4, step617]: loss 15.594642
[epoch4, step618]: loss 19.564352
[epoch4, step619]: loss 16.996811
[epoch4, step620]: loss 37.605522
[epoch4, step621]: loss 41.252678
[epoch4, step622]: loss 9.793189
[epoch4, step623]: loss 2.522250
[epoch4, step624]: loss 12.625502
[epoch4, step625]: loss 3.200397
[epoch4, step626]: loss 18.599857
[epoch4, step627]: loss 3.149220
[epoch4, step628]: loss 11.493961
[epoch4, step629]: loss 5.328644
[epoch4, step630]: loss 27.844360
[epoch4, step631]: loss 3.164725
[epoch4, step632]: loss 13.182533
[epoch4, step633]: loss 23.264275
[epoch4, step634]: loss 2.669306
[epoch4, step635]: loss 2.876558
[epoch4, step636]: loss 3.789144
[epoch4, step637]: loss 33.928745
[epoch4, step638]: loss 4.726078
[epoch4, step639]: loss 2.542521
[epoch4, step640]: loss 2.382280
[epoch4, step641]: loss 2.498113
[epoch4, step642]: loss 14.879440
[epoch4, step643]: loss 18.822918
[epoch4, step644]: loss 4.123778
[epoch4, step645]: loss 29.877666
[epoch4, step646]: loss 6.863106
[epoch4, step647]: loss 20.374594
[epoch4, step648]: loss 7.368192
[epoch4, step649]: loss 7.893275
[epoch4, step650]: loss 4.231115
[epoch4, step651]: loss 25.728264
[epoch4, step652]: loss 23.452503
[epoch4, step653]: loss 6.465733
[epoch4, step654]: loss 3.876612
[epoch4, step655]: loss 3.290355
[epoch4, step656]: loss 20.609104
[epoch4, step657]: loss 23.585691
[epoch4, step658]: loss 3.639969
[epoch4, step659]: loss 3.940836
[epoch4, step660]: loss 4.829218
[epoch4, step661]: loss 17.972933
[epoch4, step662]: loss 7.330611
[epoch4, step663]: loss 14.456182
[epoch4, step664]: loss 4.142379
[epoch4, step665]: loss 38.652836
[epoch4, step666]: loss 5.593916
[epoch4, step667]: loss 3.976081
[epoch4, step668]: loss 3.341372
[epoch4, step669]: loss 24.687832
[epoch4, step670]: loss 3.101915
[epoch4, step671]: loss 2.431586
[epoch4, step672]: loss 24.956522
[epoch4, step673]: loss 24.550745
[epoch4, step674]: loss 27.422960
[epoch4, step675]: loss 6.083457
[epoch4, step676]: loss 18.764118
[epoch4, step677]: loss 7.065413
[epoch4, step678]: loss 8.285503
[epoch4, step679]: loss 5.339270
[epoch4, step680]: loss 16.351116
[epoch4, step681]: loss 2.137383
[epoch4, step682]: loss 23.221909
[epoch4, step683]: loss 20.505884
[epoch4, step684]: loss 19.481203
[epoch4, step685]: loss 10.928082
[epoch4, step686]: loss 4.314448
[epoch4, step687]: loss 5.248692
[epoch4, step688]: loss 11.727648
[epoch4, step689]: loss 8.125865
[epoch4, step690]: loss 6.098341
[epoch4, step691]: loss 2.883223
[epoch4, step692]: loss 3.177465
[epoch4, step693]: loss 3.545926
[epoch4, step694]: loss 21.272732
[epoch4, step695]: loss 2.273069
[epoch4, step696]: loss 8.489565
[epoch4, step697]: loss 3.401433
[epoch4, step698]: loss 30.336514
[epoch4, step699]: loss 2.566505
[epoch4, step700]: loss 4.451903
[epoch4, step701]: loss 5.516213
[epoch4, step702]: loss 42.749535
[epoch4, step703]: loss 2.726737
[epoch4, step704]: loss 18.162939
[epoch4, step705]: loss 2.161718
[epoch4, step706]: loss 15.606656
[epoch4, step707]: loss 3.597336
[epoch4, step708]: loss 4.457693
[epoch4, step709]: loss 4.867910
[epoch4, step710]: loss 3.226365
[epoch4, step711]: loss 15.081065
[epoch4, step712]: loss 4.983242
[epoch4, step713]: loss 17.033020
[epoch4, step714]: loss 8.178570
[epoch4, step715]: loss 2.773562
[epoch4, step716]: loss 12.118478
[epoch4, step717]: loss 29.596113
[epoch4, step718]: loss 7.420560
[epoch4, step719]: loss 10.430990
[epoch4, step720]: loss 2.775316
[epoch4, step721]: loss 27.588123
[epoch4, step722]: loss 3.842370
[epoch4, step723]: loss 4.085591
[epoch4, step724]: loss 24.319702
[epoch4, step725]: loss 23.531235
[epoch4, step726]: loss 3.754481
[epoch4, step727]: loss 6.093472
[epoch4, step728]: loss 2.705025
[epoch4, step729]: loss 4.697641
[epoch4, step730]: loss 6.058634
[epoch4, step731]: loss 17.166721
[epoch4, step732]: loss 15.049313
[epoch4, step733]: loss 22.674440
[epoch4, step734]: loss 19.624611
[epoch4, step735]: loss 9.364945
[epoch4, step736]: loss 6.378059
[epoch4, step737]: loss 4.536144
[epoch4, step738]: loss 3.175021
[epoch4, step739]: loss 2.916502
[epoch4, step740]: loss 5.752857
[epoch4, step741]: loss 5.679242
[epoch4, step742]: loss 4.745640
[epoch4, step743]: loss 6.046160
[epoch4, step744]: loss 9.459089
[epoch4, step745]: loss 3.126341
[epoch4, step746]: loss 3.883914
[epoch4, step747]: loss 9.999668
[epoch4, step748]: loss 30.774368
[epoch4, step749]: loss 18.223122
[epoch4, step750]: loss 3.132348
[epoch4, step751]: loss 10.435634
[epoch4, step752]: loss 18.134329
[epoch4, step753]: loss 5.935093
[epoch4, step754]: loss 2.896684
[epoch4, step755]: loss 27.568798
[epoch4, step756]: loss 5.208172
[epoch4, step757]: loss 26.605476
[epoch4, step758]: loss 2.780009
[epoch4, step759]: loss 5.240142
[epoch4, step760]: loss 6.981760
[epoch4, step761]: loss 6.422662
[epoch4, step762]: loss 6.378175
[epoch4, step763]: loss 3.614719
[epoch4, step764]: loss 5.438930
[epoch4, step765]: loss 19.460455
[epoch4, step766]: loss 18.279478
[epoch4, step767]: loss 19.103218
[epoch4, step768]: loss 8.321997
[epoch4, step769]: loss 23.057640
[epoch4, step770]: loss 3.447088
[epoch4, step771]: loss 28.429293
[epoch4, step772]: loss 21.419518
[epoch4, step773]: loss 2.719806
[epoch4, step774]: loss 15.199978
[epoch4, step775]: loss 26.001360
[epoch4, step776]: loss 4.569104
[epoch4, step777]: loss 3.418861
[epoch4, step778]: loss 4.172436
[epoch4, step779]: loss 5.861248
[epoch4, step780]: loss 18.476765
[epoch4, step781]: loss 8.205655
[epoch4, step782]: loss 18.059402
[epoch4, step783]: loss 21.514854
[epoch4, step784]: loss 25.173584
[epoch4, step785]: loss 14.923975
[epoch4, step786]: loss 33.234383
[epoch4, step787]: loss 15.510095
[epoch4, step788]: loss 4.379039
[epoch4, step789]: loss 43.630230
[epoch4, step790]: loss 3.747190
[epoch4, step791]: loss 7.873186
[epoch4, step792]: loss 7.206010
[epoch4, step793]: loss 4.102836
[epoch4, step794]: loss 4.291429
[epoch4, step795]: loss 29.808716
[epoch4, step796]: loss 5.691457
[epoch4, step797]: loss 19.795231
[epoch4, step798]: loss 5.104936
[epoch4, step799]: loss 32.923798
[epoch4, step800]: loss 7.424672
[epoch4, step801]: loss 7.600358
[epoch4, step802]: loss 3.117975
[epoch4, step803]: loss 4.135189
[epoch4, step804]: loss 6.636587
[epoch4, step805]: loss 21.229740
[epoch4, step806]: loss 2.961560
[epoch4, step807]: loss 22.371614
[epoch4, step808]: loss 5.414785
[epoch4, step809]: loss 24.636038
[epoch4, step810]: loss 20.661156
[epoch4, step811]: loss 5.508708
[epoch4, step812]: loss 20.431654
[epoch4, step813]: loss 5.261616
[epoch4, step814]: loss 36.491959
[epoch4, step815]: loss 3.044169
[epoch4, step816]: loss 4.262297
[epoch4, step817]: loss 2.824255
[epoch4, step818]: loss 14.883101
[epoch4, step819]: loss 2.075924
[epoch4, step820]: loss 4.680771
[epoch4, step821]: loss 27.569252
[epoch4, step822]: loss 7.889062
[epoch4, step823]: loss 6.903221
[epoch4, step824]: loss 3.581062
[epoch4, step825]: loss 28.978952
[epoch4, step826]: loss 4.208658
[epoch4, step827]: loss 14.074241
[epoch4, step828]: loss 15.337572
[epoch4, step829]: loss 5.713977
[epoch4, step830]: loss 7.221511
[epoch4, step831]: loss 7.405122
[epoch4, step832]: loss 16.136341
[epoch4, step833]: loss 21.286812
[epoch4, step834]: loss 19.963970
[epoch4, step835]: loss 31.261059
[epoch4, step836]: loss 23.016346
[epoch4, step837]: loss 3.501136
[epoch4, step838]: loss 7.610507
[epoch4, step839]: loss 15.085146
[epoch4, step840]: loss 32.731575
[epoch4, step841]: loss 19.790474
[epoch4, step842]: loss 10.870628
[epoch4, step843]: loss 17.922215
[epoch4, step844]: loss 20.428673
[epoch4, step845]: loss 23.145107
[epoch4, step846]: loss 3.295076
[epoch4, step847]: loss 37.863174
[epoch4, step848]: loss 18.847172
[epoch4, step849]: loss 16.201183
[epoch4, step850]: loss 22.615389
[epoch4, step851]: loss 13.176268
[epoch4, step852]: loss 14.800525
[epoch4, step853]: loss 5.169185
[epoch4, step854]: loss 3.825060
[epoch4, step855]: loss 50.701744
[epoch4, step856]: loss 3.196828
[epoch4, step857]: loss 29.400072
[epoch4, step858]: loss 17.314520
[epoch4, step859]: loss 5.643421
[epoch4, step860]: loss 10.382357
[epoch4, step861]: loss 33.710491
[epoch4, step862]: loss 29.524942
[epoch4, step863]: loss 26.053585
[epoch4, step864]: loss 20.764009
[epoch4, step865]: loss 9.670513
[epoch4, step866]: loss 2.821647
[epoch4, step867]: loss 31.763414
[epoch4, step868]: loss 4.153275
[epoch4, step869]: loss 8.257010
[epoch4, step870]: loss 65.092216
[epoch4, step871]: loss 3.383868
[epoch4, step872]: loss 10.610407
[epoch4, step873]: loss 2.302882
[epoch4, step874]: loss 2.967098
[epoch4, step875]: loss 5.254849
[epoch4, step876]: loss 5.124809
[epoch4, step877]: loss 5.223139
[epoch4, step878]: loss 7.181073
[epoch4, step879]: loss 2.689311
[epoch4, step880]: loss 26.180248
[epoch4, step881]: loss 27.884247
[epoch4, step882]: loss 36.251251
[epoch4, step883]: loss 18.921597
[epoch4, step884]: loss 17.668512
[epoch4, step885]: loss 4.880191
[epoch4, step886]: loss 17.051212
[epoch4, step887]: loss 7.643694
[epoch4, step888]: loss 2.266428
[epoch4, step889]: loss 22.692465
[epoch4, step890]: loss 8.631508
[epoch4, step891]: loss 6.451438
[epoch4, step892]: loss 5.692718
[epoch4, step893]: loss 6.293802
[epoch4, step894]: loss 16.342855
[epoch4, step895]: loss 5.240623
[epoch4, step896]: loss 5.560771
[epoch4, step897]: loss 5.005490
[epoch4, step898]: loss 12.203197
[epoch4, step899]: loss 21.658173
[epoch4, step900]: loss 18.025505
[epoch4, step901]: loss 3.888735
[epoch4, step902]: loss 6.106901
[epoch4, step903]: loss 23.276642
[epoch4, step904]: loss 4.669618
[epoch4, step905]: loss 10.245016
[epoch4, step906]: loss 4.518127
[epoch4, step907]: loss 4.720921
[epoch4, step908]: loss 4.164225
[epoch4, step909]: loss 25.820528
[epoch4, step910]: loss 2.434318
[epoch4, step911]: loss 4.923190
[epoch4, step912]: loss 2.855377
[epoch4, step913]: loss 16.196346
[epoch4, step914]: loss 7.567844
[epoch4, step915]: loss 23.125086
[epoch4, step916]: loss 7.016164
[epoch4, step917]: loss 3.387900
[epoch4, step918]: loss 6.361895
[epoch4, step919]: loss 6.558205
[epoch4, step920]: loss 6.668307
[epoch4, step921]: loss 4.373545
[epoch4, step922]: loss 16.359438
[epoch4, step923]: loss 6.459822
[epoch4, step924]: loss 23.194403
[epoch4, step925]: loss 3.742291
[epoch4, step926]: loss 4.301165
[epoch4, step927]: loss 2.462299
[epoch4, step928]: loss 2.812178
[epoch4, step929]: loss 32.695000
[epoch4, step930]: loss 8.219700
[epoch4, step931]: loss 2.507121
[epoch4, step932]: loss 6.008714
[epoch4, step933]: loss 6.911285
[epoch4, step934]: loss 14.294401
[epoch4, step935]: loss 2.272289
[epoch4, step936]: loss 16.120966
[epoch4, step937]: loss 7.155170
[epoch4, step938]: loss 23.017313
[epoch4, step939]: loss 3.590614
[epoch4, step940]: loss 4.122127
[epoch4, step941]: loss 2.737118
[epoch4, step942]: loss 14.980657
[epoch4, step943]: loss 15.452806
[epoch4, step944]: loss 24.384483
[epoch4, step945]: loss 18.956722
[epoch4, step946]: loss 5.747608
[epoch4, step947]: loss 19.507841
[epoch4, step948]: loss 19.918818
[epoch4, step949]: loss 2.718309
[epoch4, step950]: loss 5.769900
[epoch4, step951]: loss 58.007042
[epoch4, step952]: loss 7.005882
[epoch4, step953]: loss 7.281243
[epoch4, step954]: loss 6.756180
[epoch4, step955]: loss 23.752010
[epoch4, step956]: loss 17.721508
[epoch4, step957]: loss 6.001726
[epoch4, step958]: loss 6.135095
[epoch4, step959]: loss 8.577873
[epoch4, step960]: loss 6.167936
[epoch4, step961]: loss 2.367671
[epoch4, step962]: loss 5.663938
[epoch4, step963]: loss 13.838360
[epoch4, step964]: loss 16.667809
[epoch4, step965]: loss 4.104843
[epoch4, step966]: loss 23.842171
[epoch4, step967]: loss 20.994835
[epoch4, step968]: loss 19.503904
[epoch4, step969]: loss 3.256409
[epoch4, step970]: loss 3.192197
[epoch4, step971]: loss 17.839991
[epoch4, step972]: loss 19.560947
[epoch4, step973]: loss 4.564556
[epoch4, step974]: loss 24.555763
[epoch4, step975]: loss 1.803042
[epoch4, step976]: loss 4.830061
[epoch4, step977]: loss 3.049091
[epoch4, step978]: loss 36.833496
[epoch4, step979]: loss 6.707167
[epoch4, step980]: loss 5.298956
[epoch4, step981]: loss 20.905396
[epoch4, step982]: loss 4.033270
[epoch4, step983]: loss 2.635575
[epoch4, step984]: loss 9.053492
[epoch4, step985]: loss 24.774141
[epoch4, step986]: loss 2.833391
[epoch4, step987]: loss 32.743683
[epoch4, step988]: loss 7.765238
[epoch4, step989]: loss 2.449599
[epoch4, step990]: loss 2.245221
[epoch4, step991]: loss 2.118624
[epoch4, step992]: loss 14.745131
[epoch4, step993]: loss 7.203243
[epoch4, step994]: loss 42.826656
[epoch4, step995]: loss 2.241347
[epoch4, step996]: loss 23.072168
[epoch4, step997]: loss 20.895746
[epoch4, step998]: loss 5.014001
[epoch4, step999]: loss 14.161885
[epoch4, step1000]: loss 22.637619
[epoch4, step1001]: loss 3.072949
[epoch4, step1002]: loss 22.690535
[epoch4, step1003]: loss 16.796719
[epoch4, step1004]: loss 3.266022
[epoch4, step1005]: loss 5.494948
[epoch4, step1006]: loss 3.988927
[epoch4, step1007]: loss 10.244724
[epoch4, step1008]: loss 3.683820
[epoch4, step1009]: loss 2.997694
[epoch4, step1010]: loss 5.161560
[epoch4, step1011]: loss 3.420712
[epoch4, step1012]: loss 44.744682
[epoch4, step1013]: loss 4.245471
[epoch4, step1014]: loss 4.009214
[epoch4, step1015]: loss 8.574574
[epoch4, step1016]: loss 2.837607
[epoch4, step1017]: loss 2.259959
[epoch4, step1018]: loss 8.870802
[epoch4, step1019]: loss 3.576005
[epoch4, step1020]: loss 2.009617
[epoch4, step1021]: loss 26.915991
[epoch4, step1022]: loss 22.555294
[epoch4, step1023]: loss 8.558027
[epoch4, step1024]: loss 3.377355
[epoch4, step1025]: loss 5.967299
[epoch4, step1026]: loss 35.304924
[epoch4, step1027]: loss 6.198210
[epoch4, step1028]: loss 22.996721
[epoch4, step1029]: loss 2.667752
[epoch4, step1030]: loss 3.477595
[epoch4, step1031]: loss 5.513270
[epoch4, step1032]: loss 3.181427
[epoch4, step1033]: loss 7.443039
[epoch4, step1034]: loss 3.149763
[epoch4, step1035]: loss 13.846926
[epoch4, step1036]: loss 2.501985
[epoch4, step1037]: loss 5.205585
[epoch4, step1038]: loss 2.320108
[epoch4, step1039]: loss 3.560530
[epoch4, step1040]: loss 8.686630
[epoch4, step1041]: loss 22.999544
[epoch4, step1042]: loss 22.578962
[epoch4, step1043]: loss 4.111133
[epoch4, step1044]: loss 2.725615
[epoch4, step1045]: loss 3.589815
[epoch4, step1046]: loss 4.626409
[epoch4, step1047]: loss 19.546434
[epoch4, step1048]: loss 2.458356
[epoch4, step1049]: loss 14.988436
[epoch4, step1050]: loss 4.964523
[epoch4, step1051]: loss 16.693188
[epoch4, step1052]: loss 13.324140
[epoch4, step1053]: loss 17.765343
[epoch4, step1054]: loss 6.414231
[epoch4, step1055]: loss 6.760317
[epoch4, step1056]: loss 9.072532
[epoch4, step1057]: loss 5.125692
[epoch4, step1058]: loss 16.265717
[epoch4, step1059]: loss 4.123872
[epoch4, step1060]: loss 7.464760
[epoch4, step1061]: loss 2.593598
[epoch4, step1062]: loss 4.811139
[epoch4, step1063]: loss 4.646470
[epoch4, step1064]: loss 2.180721
[epoch4, step1065]: loss 3.751434
[epoch4, step1066]: loss 3.915448
[epoch4, step1067]: loss 9.395672
[epoch4, step1068]: loss 3.790225
[epoch4, step1069]: loss 22.259106
[epoch4, step1070]: loss 3.797441
[epoch4, step1071]: loss 5.507163
[epoch4, step1072]: loss 4.641065
[epoch4, step1073]: loss 2.331730
[epoch4, step1074]: loss 3.586779
[epoch4, step1075]: loss 13.775142
[epoch4, step1076]: loss 2.288254
[epoch4, step1077]: loss 18.245934
[epoch4, step1078]: loss 7.674351
[epoch4, step1079]: loss 1.994453
[epoch4, step1080]: loss 15.303828
[epoch4, step1081]: loss 24.714527
[epoch4, step1082]: loss 3.316190
[epoch4, step1083]: loss 29.271225
[epoch4, step1084]: loss 7.861501
[epoch4, step1085]: loss 2.741598
[epoch4, step1086]: loss 4.237159
[epoch4, step1087]: loss 7.978613
[epoch4, step1088]: loss 20.627106
[epoch4, step1089]: loss 5.262221
[epoch4, step1090]: loss 26.476891
[epoch4, step1091]: loss 6.058027
[epoch4, step1092]: loss 18.642996
[epoch4, step1093]: loss 7.193460
[epoch4, step1094]: loss 6.511084
[epoch4, step1095]: loss 4.847762
[epoch4, step1096]: loss 4.378596
[epoch4, step1097]: loss 2.545866
[epoch4, step1098]: loss 19.122065
[epoch4, step1099]: loss 24.621971
[epoch4, step1100]: loss 35.382206
[epoch4, step1101]: loss 2.649584
[epoch4, step1102]: loss 2.174280
[epoch4, step1103]: loss 3.186818
[epoch4, step1104]: loss 7.327674
[epoch4, step1105]: loss 4.124104
[epoch4, step1106]: loss 3.039754
[epoch4, step1107]: loss 3.510938
[epoch4, step1108]: loss 6.062887
[epoch4, step1109]: loss 3.261465
[epoch4, step1110]: loss 3.683640
[epoch4, step1111]: loss 2.699897
[epoch4, step1112]: loss 4.431575
[epoch4, step1113]: loss 30.037041
[epoch4, step1114]: loss 14.994638
[epoch4, step1115]: loss 4.712496
[epoch4, step1116]: loss 1.759791
[epoch4, step1117]: loss 20.832676
[epoch4, step1118]: loss 8.181915
[epoch4, step1119]: loss 11.574772
[epoch4, step1120]: loss 29.623558
[epoch4, step1121]: loss 8.066244
[epoch4, step1122]: loss 17.262943
[epoch4, step1123]: loss 2.456250
[epoch4, step1124]: loss 4.254089
[epoch4, step1125]: loss 31.344418
[epoch4, step1126]: loss 29.329124
[epoch4, step1127]: loss 12.834695
[epoch4, step1128]: loss 3.273802
[epoch4, step1129]: loss 3.348623
[epoch4, step1130]: loss 6.631905
[epoch4, step1131]: loss 2.428138
[epoch4, step1132]: loss 33.709255
[epoch4, step1133]: loss 19.340242
[epoch4, step1134]: loss 4.309444
[epoch4, step1135]: loss 3.285826
[epoch4, step1136]: loss 3.113748
[epoch4, step1137]: loss 32.764587
[epoch4, step1138]: loss 4.663838
[epoch4, step1139]: loss 9.282629
[epoch4, step1140]: loss 3.117385
[epoch4, step1141]: loss 2.169767
[epoch4, step1142]: loss 36.924442
[epoch4, step1143]: loss 33.539753
[epoch4, step1144]: loss 5.526597
[epoch4, step1145]: loss 13.586500
[epoch4, step1146]: loss 4.126477
[epoch4, step1147]: loss 3.268715
[epoch4, step1148]: loss 29.327885
[epoch4, step1149]: loss 26.030312
[epoch4, step1150]: loss 21.958027
[epoch4, step1151]: loss 3.736079
[epoch4, step1152]: loss 18.889236
[epoch4, step1153]: loss 6.276322
[epoch4, step1154]: loss 6.413478
[epoch4, step1155]: loss 22.287399
[epoch4, step1156]: loss 7.876645
[epoch4, step1157]: loss 11.812496
[epoch4, step1158]: loss 29.728569
[epoch4, step1159]: loss 15.540051
[epoch4, step1160]: loss 4.707207
[epoch4, step1161]: loss 5.876020
[epoch4, step1162]: loss 44.993362
[epoch4, step1163]: loss 19.236732
[epoch4, step1164]: loss 3.218801
[epoch4, step1165]: loss 11.395799
[epoch4, step1166]: loss 6.141511
[epoch4, step1167]: loss 39.662689
[epoch4, step1168]: loss 17.184950
[epoch4, step1169]: loss 27.091494
[epoch4, step1170]: loss 26.001575
[epoch4, step1171]: loss 3.539342
[epoch4, step1172]: loss 16.064518
[epoch4, step1173]: loss 3.199432
[epoch4, step1174]: loss 3.325681
[epoch4, step1175]: loss 22.397133
[epoch4, step1176]: loss 2.577194
[epoch4, step1177]: loss 28.671923
[epoch4, step1178]: loss 3.172864
[epoch4, step1179]: loss 2.985756
[epoch4, step1180]: loss 33.580692
[epoch4, step1181]: loss 2.674637
[epoch4, step1182]: loss 35.343346
[epoch4, step1183]: loss 13.089328
[epoch4, step1184]: loss 3.253988
[epoch4, step1185]: loss 23.647745
[epoch4, step1186]: loss 2.630306
[epoch4, step1187]: loss 22.128872
[epoch4, step1188]: loss 2.147127
[epoch4, step1189]: loss 2.893949
[epoch4, step1190]: loss 26.168570
[epoch4, step1191]: loss 4.866544
[epoch4, step1192]: loss 3.298249
[epoch4, step1193]: loss 4.105362
[epoch4, step1194]: loss 2.610469
[epoch4, step1195]: loss 2.944557
[epoch4, step1196]: loss 11.731555
[epoch4, step1197]: loss 37.939751
[epoch4, step1198]: loss 6.027139
[epoch4, step1199]: loss 21.608986
[epoch4, step1200]: loss 23.858456
[epoch4, step1201]: loss 24.407576
[epoch4, step1202]: loss 1.776029
[epoch4, step1203]: loss 3.156407
[epoch4, step1204]: loss 4.922631
[epoch4, step1205]: loss 32.981266
[epoch4, step1206]: loss 7.023032
[epoch4, step1207]: loss 10.907935
[epoch4, step1208]: loss 17.096605
[epoch4, step1209]: loss 6.700868
[epoch4, step1210]: loss 13.449218
[epoch4, step1211]: loss 28.152332
[epoch4, step1212]: loss 2.623870
[epoch4, step1213]: loss 23.621994
[epoch4, step1214]: loss 6.636164
[epoch4, step1215]: loss 22.956739
[epoch4, step1216]: loss 6.185270
[epoch4, step1217]: loss 1.817384
[epoch4, step1218]: loss 2.623308
[epoch4, step1219]: loss 28.788006
[epoch4, step1220]: loss 2.033220
[epoch4, step1221]: loss 2.438389
[epoch4, step1222]: loss 10.792146
[epoch4, step1223]: loss 2.483292
[epoch4, step1224]: loss 6.163759
[epoch4, step1225]: loss 5.608244
[epoch4, step1226]: loss 23.847719
[epoch4, step1227]: loss 11.190375
[epoch4, step1228]: loss 8.405810
[epoch4, step1229]: loss 12.310513
[epoch4, step1230]: loss 12.171614
[epoch4, step1231]: loss 9.525955
[epoch4, step1232]: loss 3.640003
[epoch4, step1233]: loss 4.814654
[epoch4, step1234]: loss 3.169219
[epoch4, step1235]: loss 24.899635
[epoch4, step1236]: loss 8.921456
[epoch4, step1237]: loss 2.713205
[epoch4, step1238]: loss 8.671959
[epoch4, step1239]: loss 13.635590
[epoch4, step1240]: loss 3.915860
[epoch4, step1241]: loss 18.320187
[epoch4, step1242]: loss 4.473662
[epoch4, step1243]: loss 5.345986
[epoch4, step1244]: loss 2.792895
[epoch4, step1245]: loss 5.832665
[epoch4, step1246]: loss 4.622099
[epoch4, step1247]: loss 15.993429
[epoch4, step1248]: loss 5.803966
[epoch4, step1249]: loss 22.404211
[epoch4, step1250]: loss 5.104507
[epoch4, step1251]: loss 19.524225
[epoch4, step1252]: loss 7.193788
[epoch4, step1253]: loss 3.287239
[epoch4, step1254]: loss 3.089265
[epoch4, step1255]: loss 12.932624
[epoch4, step1256]: loss 6.302937
[epoch4, step1257]: loss 16.893799
[epoch4, step1258]: loss 30.636990
[epoch4, step1259]: loss 2.740693
[epoch4, step1260]: loss 16.329575
[epoch4, step1261]: loss 7.247376
[epoch4, step1262]: loss 32.828480
[epoch4, step1263]: loss 5.922551
[epoch4, step1264]: loss 2.813156
[epoch4, step1265]: loss 12.135395
[epoch4, step1266]: loss 5.669324
[epoch4, step1267]: loss 16.698507
[epoch4, step1268]: loss 4.082492
[epoch4, step1269]: loss 2.611970
[epoch4, step1270]: loss 31.644825
[epoch4, step1271]: loss 33.993340
[epoch4, step1272]: loss 14.002173
[epoch4, step1273]: loss 3.101540
[epoch4, step1274]: loss 3.886260
[epoch4, step1275]: loss 6.702930
[epoch4, step1276]: loss 5.126954
[epoch4, step1277]: loss 8.923819
[epoch4, step1278]: loss 8.044300
[epoch4, step1279]: loss 2.090029
[epoch4, step1280]: loss 18.324186
[epoch4, step1281]: loss 2.808179
[epoch4, step1282]: loss 29.514994
[epoch4, step1283]: loss 5.523567
[epoch4, step1284]: loss 7.968542
[epoch4, step1285]: loss 4.878791
[epoch4, step1286]: loss 2.825708
[epoch4, step1287]: loss 3.873175
[epoch4, step1288]: loss 3.901150
[epoch4, step1289]: loss 56.276989
[epoch4, step1290]: loss 4.109935
[epoch4, step1291]: loss 4.656848
[epoch4, step1292]: loss 2.120886
[epoch4, step1293]: loss 12.252662
[epoch4, step1294]: loss 11.986280
[epoch4, step1295]: loss 14.586773
[epoch4, step1296]: loss 22.266319
[epoch4, step1297]: loss 6.755379
[epoch4, step1298]: loss 11.916371
[epoch4, step1299]: loss 21.582628
[epoch4, step1300]: loss 18.795630
[epoch4, step1301]: loss 4.587148
[epoch4, step1302]: loss 17.653442
[epoch4, step1303]: loss 5.384763
[epoch4, step1304]: loss 3.279253
[epoch4, step1305]: loss 23.011751
[epoch4, step1306]: loss 4.822716
[epoch4, step1307]: loss 3.967118
[epoch4, step1308]: loss 24.770947
[epoch4, step1309]: loss 22.379536
[epoch4, step1310]: loss 4.656105
[epoch4, step1311]: loss 3.100284
[epoch4, step1312]: loss 23.158848
[epoch4, step1313]: loss 18.170509
[epoch4, step1314]: loss 17.130796
[epoch4, step1315]: loss 4.410776
[epoch4, step1316]: loss 2.958748
[epoch4, step1317]: loss 6.143899
[epoch4, step1318]: loss 6.563681
[epoch4, step1319]: loss 4.999278
[epoch4, step1320]: loss 24.423433
[epoch4, step1321]: loss 9.418952
[epoch4, step1322]: loss 17.781395
[epoch4, step1323]: loss 27.811493
[epoch4, step1324]: loss 6.874820
[epoch4, step1325]: loss 18.033604
[epoch4, step1326]: loss 16.834732
[epoch4, step1327]: loss 2.472509
[epoch4, step1328]: loss 10.533646
[epoch4, step1329]: loss 28.455288
[epoch4, step1330]: loss 3.598887
[epoch4, step1331]: loss 13.185310
[epoch4, step1332]: loss 16.345211
[epoch4, step1333]: loss 12.825491
[epoch4, step1334]: loss 3.775749
[epoch4, step1335]: loss 3.830170
[epoch4, step1336]: loss 4.659136
[epoch4, step1337]: loss 1.943230
[epoch4, step1338]: loss 6.178990
[epoch4, step1339]: loss 29.557516
[epoch4, step1340]: loss 3.229635
[epoch4, step1341]: loss 13.286612
[epoch4, step1342]: loss 30.626793
[epoch4, step1343]: loss 3.110319
[epoch4, step1344]: loss 3.075526
[epoch4, step1345]: loss 15.531049
[epoch4, step1346]: loss 22.446760
[epoch4, step1347]: loss 4.841290
[epoch4, step1348]: loss 17.893414
[epoch4, step1349]: loss 4.037543
[epoch4, step1350]: loss 4.032880
[epoch4, step1351]: loss 1.995373
[epoch4, step1352]: loss 20.264395
[epoch4, step1353]: loss 25.112095
[epoch4, step1354]: loss 15.801409
[epoch4, step1355]: loss 20.191757
[epoch4, step1356]: loss 12.331619
[epoch4, step1357]: loss 12.184258
[epoch4, step1358]: loss 33.080215
[epoch4, step1359]: loss 8.345518
[epoch4, step1360]: loss 18.966719
[epoch4, step1361]: loss 16.507204
[epoch4, step1362]: loss 10.387281
[epoch4, step1363]: loss 8.205788
[epoch4, step1364]: loss 12.059762
[epoch4, step1365]: loss 7.603682
[epoch4, step1366]: loss 37.281418
[epoch4, step1367]: loss 14.135443
[epoch4, step1368]: loss 2.487207
[epoch4, step1369]: loss 1.861433
[epoch4, step1370]: loss 2.475659
[epoch4, step1371]: loss 7.216945
[epoch4, step1372]: loss 29.690533
[epoch4, step1373]: loss 48.872520
[epoch4, step1374]: loss 7.029359
[epoch4, step1375]: loss 3.482079
[epoch4, step1376]: loss 8.123233
[epoch4, step1377]: loss 18.186073
[epoch4, step1378]: loss 6.261976
[epoch4, step1379]: loss 17.129059
[epoch4, step1380]: loss 7.589283
[epoch4, step1381]: loss 4.126369
[epoch4, step1382]: loss 19.252710
[epoch4, step1383]: loss 24.945147
[epoch4, step1384]: loss 8.074139
[epoch4, step1385]: loss 11.896793
[epoch4, step1386]: loss 18.389151
[epoch4, step1387]: loss 7.759017
[epoch4, step1388]: loss 5.887312
[epoch4, step1389]: loss 52.175484
[epoch4, step1390]: loss 8.459364
[epoch4, step1391]: loss 15.287600
[epoch4, step1392]: loss 2.809161
[epoch4, step1393]: loss 5.528326
[epoch4, step1394]: loss 3.672170
[epoch4, step1395]: loss 3.263974
[epoch4, step1396]: loss 26.997944
[epoch4, step1397]: loss 18.756086
[epoch4, step1398]: loss 7.461239
[epoch4, step1399]: loss 16.326715
[epoch4, step1400]: loss 9.840668
[epoch4, step1401]: loss 10.226036
[epoch4, step1402]: loss 18.300852
[epoch4, step1403]: loss 2.889280
[epoch4, step1404]: loss 3.061194
[epoch4, step1405]: loss 6.190487
[epoch4, step1406]: loss 3.154131
[epoch4, step1407]: loss 10.746122
[epoch4, step1408]: loss 5.611394
[epoch4, step1409]: loss 4.534164
[epoch4, step1410]: loss 2.729497
[epoch4, step1411]: loss 16.777956
[epoch4, step1412]: loss 9.371819
[epoch4, step1413]: loss 4.381837
[epoch4, step1414]: loss 4.678655
[epoch4, step1415]: loss 20.525812
[epoch4, step1416]: loss 4.826713
[epoch4, step1417]: loss 2.637425
[epoch4, step1418]: loss 6.008072
[epoch4, step1419]: loss 30.767359
[epoch4, step1420]: loss 7.866484
[epoch4, step1421]: loss 25.772968
[epoch4, step1422]: loss 50.495995
[epoch4, step1423]: loss 2.949026
[epoch4, step1424]: loss 5.192482
[epoch4, step1425]: loss 5.908929
[epoch4, step1426]: loss 49.907207
[epoch4, step1427]: loss 14.941732
[epoch4, step1428]: loss 3.019501
[epoch4, step1429]: loss 5.249318
[epoch4, step1430]: loss 23.873695
[epoch4, step1431]: loss 8.546475
[epoch4, step1432]: loss 5.200907
[epoch4, step1433]: loss 43.735207
[epoch4, step1434]: loss 43.531849
[epoch4, step1435]: loss 3.612350
[epoch4, step1436]: loss 25.547817
[epoch4, step1437]: loss 2.970274
[epoch4, step1438]: loss 36.466255
[epoch4, step1439]: loss 2.884455
[epoch4, step1440]: loss 20.536448
[epoch4, step1441]: loss 3.962652
[epoch4, step1442]: loss 4.192154
[epoch4, step1443]: loss 2.640702
[epoch4, step1444]: loss 25.371027
[epoch4, step1445]: loss 5.400267
[epoch4, step1446]: loss 6.517841
[epoch4, step1447]: loss 3.777609
[epoch4, step1448]: loss 2.393320
[epoch4, step1449]: loss 5.084168
[epoch4, step1450]: loss 12.297441
[epoch4, step1451]: loss 20.211197
[epoch4, step1452]: loss 3.798303
[epoch4, step1453]: loss 41.700504
[epoch4, step1454]: loss 2.611714
[epoch4, step1455]: loss 2.200688
[epoch4, step1456]: loss 3.650977
[epoch4, step1457]: loss 12.290871
[epoch4, step1458]: loss 29.949120
[epoch4, step1459]: loss 4.000711
[epoch4, step1460]: loss 4.214874
[epoch4, step1461]: loss 2.628087
[epoch4, step1462]: loss 22.424118
[epoch4, step1463]: loss 16.257206
[epoch4, step1464]: loss 1.951638
[epoch4, step1465]: loss 1.969587
[epoch4, step1466]: loss 32.928242
[epoch4, step1467]: loss 22.275364
[epoch4, step1468]: loss 15.362350
[epoch4, step1469]: loss 16.896599
[epoch4, step1470]: loss 17.415924
[epoch4, step1471]: loss 22.679108
[epoch4, step1472]: loss 16.478340
[epoch4, step1473]: loss 6.092723
[epoch4, step1474]: loss 2.086756
[epoch4, step1475]: loss 22.107159
[epoch4, step1476]: loss 2.522079
[epoch4, step1477]: loss 16.172747
[epoch4, step1478]: loss 22.606764
[epoch4, step1479]: loss 25.817389
[epoch4, step1480]: loss 6.349906
[epoch4, step1481]: loss 15.515837
[epoch4, step1482]: loss 8.567531
[epoch4, step1483]: loss 3.270889
[epoch4, step1484]: loss 3.882131
[epoch4, step1485]: loss 7.308538
[epoch4, step1486]: loss 26.660864
[epoch4, step1487]: loss 1.916455
[epoch4, step1488]: loss 5.721805
[epoch4, step1489]: loss 3.734374
[epoch4, step1490]: loss 3.942904
[epoch4, step1491]: loss 2.971501
[epoch4, step1492]: loss 5.041718
[epoch4, step1493]: loss 18.959574
[epoch4, step1494]: loss 9.954085
[epoch4, step1495]: loss 10.373169
[epoch4, step1496]: loss 4.554046
[epoch4, step1497]: loss 3.554344
[epoch4, step1498]: loss 7.478161
[epoch4, step1499]: loss 11.150136
[epoch4, step1500]: loss 9.700640
[epoch4, step1501]: loss 11.913654
[epoch4, step1502]: loss 10.615309
[epoch4, step1503]: loss 3.516197
[epoch4, step1504]: loss 5.275131
[epoch4, step1505]: loss 18.583252
[epoch4, step1506]: loss 17.448620
[epoch4, step1507]: loss 3.014385
[epoch4, step1508]: loss 2.383071
[epoch4, step1509]: loss 14.847238
[epoch4, step1510]: loss 4.314841
[epoch4, step1511]: loss 27.113987
[epoch4, step1512]: loss 10.803262
[epoch4, step1513]: loss 17.230858
[epoch4, step1514]: loss 3.156526
[epoch4, step1515]: loss 5.895900
[epoch4, step1516]: loss 30.481800
[epoch4, step1517]: loss 2.743171
[epoch4, step1518]: loss 4.553163
[epoch4, step1519]: loss 11.781135
[epoch4, step1520]: loss 3.056649
[epoch4, step1521]: loss 5.006835
[epoch4, step1522]: loss 2.228775
[epoch4, step1523]: loss 2.777255
[epoch4, step1524]: loss 2.843076
[epoch4, step1525]: loss 5.253568
[epoch4, step1526]: loss 8.200742
[epoch4, step1527]: loss 5.245522
[epoch4, step1528]: loss 19.953815
[epoch4, step1529]: loss 4.486234
[epoch4, step1530]: loss 39.418232
[epoch4, step1531]: loss 17.330276
[epoch4, step1532]: loss 5.576582
[epoch4, step1533]: loss 25.419216
[epoch4, step1534]: loss 10.952282
[epoch4, step1535]: loss 32.934490
[epoch4, step1536]: loss 6.085285
[epoch4, step1537]: loss 49.394283
[epoch4, step1538]: loss 5.930073
[epoch4, step1539]: loss 13.667822
[epoch4, step1540]: loss 2.553389
[epoch4, step1541]: loss 14.910227
[epoch4, step1542]: loss 3.726388
[epoch4, step1543]: loss 2.149197
[epoch4, step1544]: loss 14.464501
[epoch4, step1545]: loss 5.902087
[epoch4, step1546]: loss 2.090417
[epoch4, step1547]: loss 2.219978
[epoch4, step1548]: loss 7.895689
[epoch4, step1549]: loss 3.038974
[epoch4, step1550]: loss 20.846375
[epoch4, step1551]: loss 19.815828
[epoch4, step1552]: loss 3.635720
[epoch4, step1553]: loss 4.714548
[epoch4, step1554]: loss 1.998934
[epoch4, step1555]: loss 3.381808
[epoch4, step1556]: loss 3.917970
[epoch4, step1557]: loss 12.833684
[epoch4, step1558]: loss 3.233083
[epoch4, step1559]: loss 2.457433
[epoch4, step1560]: loss 25.303062
[epoch4, step1561]: loss 23.068615
[epoch4, step1562]: loss 6.052726
[epoch4, step1563]: loss 4.449959
[epoch4, step1564]: loss 2.606767
[epoch4, step1565]: loss 19.157656
[epoch4, step1566]: loss 7.833111
[epoch4, step1567]: loss 26.928940
[epoch4, step1568]: loss 12.421874
[epoch4, step1569]: loss 2.702736
[epoch4, step1570]: loss 15.792884
[epoch4, step1571]: loss 13.300093
[epoch4, step1572]: loss 11.943993
[epoch4, step1573]: loss 18.255081
[epoch4, step1574]: loss 2.551192
[epoch4, step1575]: loss 2.943572
[epoch4, step1576]: loss 13.094508
[epoch4, step1577]: loss 5.616175
[epoch4, step1578]: loss 41.291222
[epoch4, step1579]: loss 2.319747
[epoch4, step1580]: loss 2.496458
[epoch4, step1581]: loss 2.899774
[epoch4, step1582]: loss 30.375734
[epoch4, step1583]: loss 25.136909
[epoch4, step1584]: loss 7.482330
[epoch4, step1585]: loss 21.386602
[epoch4, step1586]: loss 6.080867
[epoch4, step1587]: loss 5.534113
[epoch4, step1588]: loss 4.851922
[epoch4, step1589]: loss 2.407404
[epoch4, step1590]: loss 53.152473
[epoch4, step1591]: loss 4.667161
[epoch4, step1592]: loss 19.123783
[epoch4, step1593]: loss 2.259806
[epoch4, step1594]: loss 14.150483
[epoch4, step1595]: loss 3.513380
[epoch4, step1596]: loss 25.485107
[epoch4, step1597]: loss 2.208966
[epoch4, step1598]: loss 15.308491
[epoch4, step1599]: loss 4.566285
[epoch4, step1600]: loss 2.684188
[epoch4, step1601]: loss 7.515214
[epoch4, step1602]: loss 1.953699
[epoch4, step1603]: loss 19.698999
[epoch4, step1604]: loss 7.353836
[epoch4, step1605]: loss 6.921712
[epoch4, step1606]: loss 4.465093
[epoch4, step1607]: loss 41.352592
[epoch4, step1608]: loss 2.234695
[epoch4, step1609]: loss 5.584096
[epoch4, step1610]: loss 25.764500
[epoch4, step1611]: loss 7.446253
[epoch4, step1612]: loss 21.978098
[epoch4, step1613]: loss 6.294850
[epoch4, step1614]: loss 3.967039
[epoch4, step1615]: loss 12.098632
[epoch4, step1616]: loss 44.664413
[epoch4, step1617]: loss 15.014987
[epoch4, step1618]: loss 2.014374
[epoch4, step1619]: loss 17.355762
[epoch4, step1620]: loss 3.956270
[epoch4, step1621]: loss 6.123472
[epoch4, step1622]: loss 4.035771
[epoch4, step1623]: loss 19.842100
[epoch4, step1624]: loss 4.577937
[epoch4, step1625]: loss 5.716883
[epoch4, step1626]: loss 3.295266
[epoch4, step1627]: loss 4.806968
[epoch4, step1628]: loss 43.929337
[epoch4, step1629]: loss 24.195433
[epoch4, step1630]: loss 13.747787
[epoch4, step1631]: loss 3.343368
[epoch4, step1632]: loss 34.536678
[epoch4, step1633]: loss 3.630867
[epoch4, step1634]: loss 3.191677
[epoch4, step1635]: loss 1.987108
[epoch4, step1636]: loss 5.284923
[epoch4, step1637]: loss 3.970183
[epoch4, step1638]: loss 7.119361
[epoch4, step1639]: loss 41.772011
[epoch4, step1640]: loss 3.256729
[epoch4, step1641]: loss 4.144446
[epoch4, step1642]: loss 4.880523
[epoch4, step1643]: loss 20.113914
[epoch4, step1644]: loss 22.308321
[epoch4, step1645]: loss 2.255841
[epoch4, step1646]: loss 19.110525
[epoch4, step1647]: loss 71.413033
[epoch4, step1648]: loss 28.790478
[epoch4, step1649]: loss 2.582912
[epoch4, step1650]: loss 33.302155
[epoch4, step1651]: loss 13.834620
[epoch4, step1652]: loss 26.317757
[epoch4, step1653]: loss 15.394644
[epoch4, step1654]: loss 5.157018
[epoch4, step1655]: loss 25.033897
[epoch4, step1656]: loss 19.227829
[epoch4, step1657]: loss 3.512467
[epoch4, step1658]: loss 8.296644
[epoch4, step1659]: loss 19.989342
[epoch4, step1660]: loss 7.837520
[epoch4, step1661]: loss 10.066223
[epoch4, step1662]: loss 15.999624
[epoch4, step1663]: loss 2.175726
[epoch4, step1664]: loss 4.466780
[epoch4, step1665]: loss 19.585255
[epoch4, step1666]: loss 3.207688
[epoch4, step1667]: loss 37.408447
[epoch4, step1668]: loss 8.229434
[epoch4, step1669]: loss 17.820988
[epoch4, step1670]: loss 16.968872
[epoch4, step1671]: loss 21.034842
[epoch4, step1672]: loss 2.398821
[epoch4, step1673]: loss 2.675281
[epoch4, step1674]: loss 4.245629
[epoch4, step1675]: loss 4.418791
[epoch4, step1676]: loss 18.622639
[epoch4, step1677]: loss 5.713888
[epoch4, step1678]: loss 6.571073
[epoch4, step1679]: loss 40.539356
[epoch4, step1680]: loss 5.102449
[epoch4, step1681]: loss 22.425251
[epoch4, step1682]: loss 53.615990
[epoch4, step1683]: loss 25.160700
[epoch4, step1684]: loss 3.139627
[epoch4, step1685]: loss 3.138889
[epoch4, step1686]: loss 5.118368
[epoch4, step1687]: loss 20.646738
[epoch4, step1688]: loss 2.229881
[epoch4, step1689]: loss 31.108744
[epoch4, step1690]: loss 2.948193
[epoch4, step1691]: loss 2.308464
[epoch4, step1692]: loss 3.538715
[epoch4, step1693]: loss 4.925674
[epoch4, step1694]: loss 7.135280
[epoch4, step1695]: loss 17.752094
[epoch4, step1696]: loss 4.242879
[epoch4, step1697]: loss 33.572197
[epoch4, step1698]: loss 3.631530
[epoch4, step1699]: loss 2.836848
[epoch4, step1700]: loss 10.387683
[epoch4, step1701]: loss 2.564874
[epoch4, step1702]: loss 2.924112
[epoch4, step1703]: loss 17.017363
[epoch4, step1704]: loss 25.128349
[epoch4, step1705]: loss 4.615579
[epoch4, step1706]: loss 2.662616
[epoch4, step1707]: loss 4.049317
[epoch4, step1708]: loss 8.621250
[epoch4, step1709]: loss 4.759759
[epoch4, step1710]: loss 7.363646
[epoch4, step1711]: loss 5.445942
[epoch4, step1712]: loss 28.261837
[epoch4, step1713]: loss 4.362033
[epoch4, step1714]: loss 5.051827
[epoch4, step1715]: loss 5.899192
[epoch4, step1716]: loss 22.460503
[epoch4, step1717]: loss 4.903321
[epoch4, step1718]: loss 17.977198
[epoch4, step1719]: loss 4.146577
[epoch4, step1720]: loss 26.975689
[epoch4, step1721]: loss 22.511608
[epoch4, step1722]: loss 7.042591
[epoch4, step1723]: loss 31.774462
[epoch4, step1724]: loss 20.044827
[epoch4, step1725]: loss 3.581291
[epoch4, step1726]: loss 33.213623
[epoch4, step1727]: loss 5.484992
[epoch4, step1728]: loss 6.654988
[epoch4, step1729]: loss 4.540755
[epoch4, step1730]: loss 6.571224
[epoch4, step1731]: loss 5.784582
[epoch4, step1732]: loss 3.418637
[epoch4, step1733]: loss 3.047000
[epoch4, step1734]: loss 11.750045
[epoch4, step1735]: loss 21.421795
[epoch4, step1736]: loss 30.429935
[epoch4, step1737]: loss 19.666748
[epoch4, step1738]: loss 10.263151
[epoch4, step1739]: loss 3.707022
[epoch4, step1740]: loss 19.413689
[epoch4, step1741]: loss 2.370301
[epoch4, step1742]: loss 7.025008
[epoch4, step1743]: loss 4.160946
[epoch4, step1744]: loss 10.472404
[epoch4, step1745]: loss 62.702011
[epoch4, step1746]: loss 4.344628
[epoch4, step1747]: loss 34.333153
[epoch4, step1748]: loss 4.030453
[epoch4, step1749]: loss 3.898932
[epoch4, step1750]: loss 5.883136
[epoch4, step1751]: loss 3.698197
[epoch4, step1752]: loss 2.934281
[epoch4, step1753]: loss 24.707708
[epoch4, step1754]: loss 22.999292
[epoch4, step1755]: loss 2.889961
[epoch4, step1756]: loss 30.442198
[epoch4, step1757]: loss 2.609650
[epoch4, step1758]: loss 3.081998
[epoch4, step1759]: loss 14.795023
[epoch4, step1760]: loss 2.166752
[epoch4, step1761]: loss 4.941442
[epoch4, step1762]: loss 23.077419
[epoch4, step1763]: loss 25.903902
[epoch4, step1764]: loss 23.032831
[epoch4, step1765]: loss 25.346817
[epoch4, step1766]: loss 23.143454
[epoch4, step1767]: loss 40.205105
[epoch4, step1768]: loss 3.947391
[epoch4, step1769]: loss 2.588237
[epoch4, step1770]: loss 5.372911
[epoch4, step1771]: loss 2.892898
[epoch4, step1772]: loss 8.855079
[epoch4, step1773]: loss 6.001883
[epoch4, step1774]: loss 32.449036
[epoch4, step1775]: loss 19.551653
[epoch4, step1776]: loss 24.130581
[epoch4, step1777]: loss 2.091656
[epoch4, step1778]: loss 4.822223
[epoch4, step1779]: loss 24.125921
[epoch4, step1780]: loss 8.526002
[epoch4, step1781]: loss 17.758593
[epoch4, step1782]: loss 13.925186
[epoch4, step1783]: loss 35.623116
[epoch4, step1784]: loss 21.714613
[epoch4, step1785]: loss 19.760387
[epoch4, step1786]: loss 22.222214
[epoch4, step1787]: loss 5.422051
[epoch4, step1788]: loss 39.785759
[epoch4, step1789]: loss 48.021801
[epoch4, step1790]: loss 3.317596
[epoch4, step1791]: loss 5.921168
[epoch4, step1792]: loss 35.823822
[epoch4, step1793]: loss 11.288691
[epoch4, step1794]: loss 12.843771
[epoch4, step1795]: loss 32.345581
[epoch4, step1796]: loss 32.247059
[epoch4, step1797]: loss 19.925449
[epoch4, step1798]: loss 37.135597
[epoch4, step1799]: loss 27.211391
[epoch4, step1800]: loss 19.908396
[epoch4, step1801]: loss 17.976658
[epoch4, step1802]: loss 6.173052
[epoch4, step1803]: loss 4.807607
[epoch4, step1804]: loss 5.322478
[epoch4, step1805]: loss 2.746961
[epoch4, step1806]: loss 5.996371
[epoch4, step1807]: loss 50.154518
[epoch4, step1808]: loss 24.448776
[epoch4, step1809]: loss 5.965858
[epoch4, step1810]: loss 2.979685
[epoch4, step1811]: loss 3.539467
[epoch4, step1812]: loss 43.187725
[epoch4, step1813]: loss 6.506621
[epoch4, step1814]: loss 6.266680
[epoch4, step1815]: loss 60.811668
[epoch4, step1816]: loss 3.647556
[epoch4, step1817]: loss 2.832161
[epoch4, step1818]: loss 29.138527
[epoch4, step1819]: loss 23.798782
[epoch4, step1820]: loss 4.584453
[epoch4, step1821]: loss 1.918297
[epoch4, step1822]: loss 7.689585
[epoch4, step1823]: loss 3.895158
[epoch4, step1824]: loss 2.884745
[epoch4, step1825]: loss 11.287710
[epoch4, step1826]: loss 9.356755
[epoch4, step1827]: loss 16.300327
[epoch4, step1828]: loss 12.328373
[epoch4, step1829]: loss 5.039304
[epoch4, step1830]: loss 3.438936
[epoch4, step1831]: loss 4.356910
[epoch4, step1832]: loss 31.909420
[epoch4, step1833]: loss 16.026636
[epoch4, step1834]: loss 5.503823
[epoch4, step1835]: loss 8.112028
[epoch4, step1836]: loss 13.911905
[epoch4, step1837]: loss 24.118172
[epoch4, step1838]: loss 6.167533
[epoch4, step1839]: loss 2.352525
[epoch4, step1840]: loss 3.412034
[epoch4, step1841]: loss 27.786232
[epoch4, step1842]: loss 5.809547
[epoch4, step1843]: loss 3.587819
[epoch4, step1844]: loss 3.517037
[epoch4, step1845]: loss 19.501690
[epoch4, step1846]: loss 11.489501
[epoch4, step1847]: loss 2.286758
[epoch4, step1848]: loss 3.495312
[epoch4, step1849]: loss 8.990781
[epoch4, step1850]: loss 3.477005
[epoch4, step1851]: loss 21.907629
[epoch4, step1852]: loss 5.941251
[epoch4, step1853]: loss 3.051254
[epoch4, step1854]: loss 4.455438
[epoch4, step1855]: loss 2.374605
[epoch4, step1856]: loss 49.822666
[epoch4, step1857]: loss 11.554617
[epoch4, step1858]: loss 3.212839
[epoch4, step1859]: loss 3.980115
[epoch4, step1860]: loss 3.462493
[epoch4, step1861]: loss 3.533464
[epoch4, step1862]: loss 41.999695
[epoch4, step1863]: loss 3.387099
[epoch4, step1864]: loss 3.804378
[epoch4, step1865]: loss 20.263906
[epoch4, step1866]: loss 22.275192
[epoch4, step1867]: loss 3.642206
[epoch4, step1868]: loss 23.517040
[epoch4, step1869]: loss 17.507406
[epoch4, step1870]: loss 5.777972
[epoch4, step1871]: loss 27.253956
[epoch4, step1872]: loss 32.902569
[epoch4, step1873]: loss 37.913063
[epoch4, step1874]: loss 30.211168
[epoch4, step1875]: loss 30.030092
[epoch4, step1876]: loss 26.484245
[epoch4, step1877]: loss 13.549549
[epoch4, step1878]: loss 12.804869
[epoch4, step1879]: loss 3.925927
[epoch4, step1880]: loss 4.360666
[epoch4, step1881]: loss 15.093998
[epoch4, step1882]: loss 15.750540
[epoch4, step1883]: loss 4.176909
[epoch4, step1884]: loss 7.202446
[epoch4, step1885]: loss 2.432358
[epoch4, step1886]: loss 5.651939
[epoch4, step1887]: loss 2.034973
[epoch4, step1888]: loss 22.781935
[epoch4, step1889]: loss 2.339864
[epoch4, step1890]: loss 2.100067
[epoch4, step1891]: loss 5.139390
[epoch4, step1892]: loss 6.881473
[epoch4, step1893]: loss 7.102382
[epoch4, step1894]: loss 4.759393
[epoch4, step1895]: loss 4.891878
[epoch4, step1896]: loss 17.826227
[epoch4, step1897]: loss 4.581463
[epoch4, step1898]: loss 22.483042
[epoch4, step1899]: loss 3.758952
[epoch4, step1900]: loss 2.210251
[epoch4, step1901]: loss 3.330626
[epoch4, step1902]: loss 10.913354
[epoch4, step1903]: loss 30.430801
[epoch4, step1904]: loss 11.509851
[epoch4, step1905]: loss 2.738425
[epoch4, step1906]: loss 3.184815
[epoch4, step1907]: loss 24.368523
[epoch4, step1908]: loss 7.025878
[epoch4, step1909]: loss 13.219370
[epoch4, step1910]: loss 8.131064
[epoch4, step1911]: loss 37.174625
[epoch4, step1912]: loss 2.188885
[epoch4, step1913]: loss 2.620492
[epoch4, step1914]: loss 2.844913
[epoch4, step1915]: loss 1.828305
[epoch4, step1916]: loss 16.066225
[epoch4, step1917]: loss 20.221607
[epoch4, step1918]: loss 3.261886
[epoch4, step1919]: loss 31.673832
[epoch4, step1920]: loss 2.283640
[epoch4, step1921]: loss 14.895747
[epoch4, step1922]: loss 3.253514
[epoch4, step1923]: loss 17.839088
[epoch4, step1924]: loss 21.932707
[epoch4, step1925]: loss 22.562292
[epoch4, step1926]: loss 52.306290
[epoch4, step1927]: loss 15.047893
[epoch4, step1928]: loss 33.287266
[epoch4, step1929]: loss 2.329514
[epoch4, step1930]: loss 2.247166
[epoch4, step1931]: loss 4.093665
[epoch4, step1932]: loss 6.939028
[epoch4, step1933]: loss 3.038239
[epoch4, step1934]: loss 42.698956
[epoch4, step1935]: loss 2.527384
[epoch4, step1936]: loss 3.787508
[epoch4, step1937]: loss 35.580051
[epoch4, step1938]: loss 7.222417
[epoch4, step1939]: loss 3.089950
[epoch4, step1940]: loss 3.460868
[epoch4, step1941]: loss 2.514997
[epoch4, step1942]: loss 4.124795
[epoch4, step1943]: loss 5.213026
[epoch4, step1944]: loss 4.102699
[epoch4, step1945]: loss 17.885490
[epoch4, step1946]: loss 7.425217
[epoch4, step1947]: loss 14.212021
[epoch4, step1948]: loss 3.135967
[epoch4, step1949]: loss 28.409492
[epoch4, step1950]: loss 5.405760
[epoch4, step1951]: loss 8.516861
[epoch4, step1952]: loss 32.149559
[epoch4, step1953]: loss 12.573045
[epoch4, step1954]: loss 15.607543
[epoch4, step1955]: loss 3.451077
[epoch4, step1956]: loss 11.975207
[epoch4, step1957]: loss 3.038970
[epoch4, step1958]: loss 2.494226
[epoch4, step1959]: loss 5.359394
[epoch4, step1960]: loss 3.170460
[epoch4, step1961]: loss 24.311768
[epoch4, step1962]: loss 2.146311
[epoch4, step1963]: loss 7.987497
[epoch4, step1964]: loss 13.471067
[epoch4, step1965]: loss 4.156782
[epoch4, step1966]: loss 6.209298
[epoch4, step1967]: loss 1.813745
[epoch4, step1968]: loss 10.871507
[epoch4, step1969]: loss 13.466713
[epoch4, step1970]: loss 3.765695
[epoch4, step1971]: loss 4.278129
[epoch4, step1972]: loss 28.223904
[epoch4, step1973]: loss 4.269567
[epoch4, step1974]: loss 37.390884
[epoch4, step1975]: loss 4.920639
[epoch4, step1976]: loss 23.815628
[epoch4, step1977]: loss 2.334211
[epoch4, step1978]: loss 12.508406
[epoch4, step1979]: loss 4.275429
[epoch4, step1980]: loss 7.035367
[epoch4, step1981]: loss 9.636050
[epoch4, step1982]: loss 2.054943
[epoch4, step1983]: loss 7.124896
[epoch4, step1984]: loss 3.506977
[epoch4, step1985]: loss 3.075944
[epoch4, step1986]: loss 3.652479
[epoch4, step1987]: loss 23.576883
[epoch4, step1988]: loss 3.786586
[epoch4, step1989]: loss 16.489546
[epoch4, step1990]: loss 11.205403
[epoch4, step1991]: loss 17.428453
[epoch4, step1992]: loss 4.167831
[epoch4, step1993]: loss 7.650782
[epoch4, step1994]: loss 2.865576
[epoch4, step1995]: loss 23.641207
[epoch4, step1996]: loss 15.775198
[epoch4, step1997]: loss 1.682122
[epoch4, step1998]: loss 3.209972
[epoch4, step1999]: loss 30.467926
[epoch4, step2000]: loss 20.197168
[epoch4, step2001]: loss 22.202290
[epoch4, step2002]: loss 3.521661
[epoch4, step2003]: loss 2.698225
[epoch4, step2004]: loss 3.046239
[epoch4, step2005]: loss 9.177331
[epoch4, step2006]: loss 4.385670
[epoch4, step2007]: loss 3.914799
[epoch4, step2008]: loss 27.421810
[epoch4, step2009]: loss 2.700931
[epoch4, step2010]: loss 5.153713
[epoch4, step2011]: loss 6.042716
[epoch4, step2012]: loss 9.543309
[epoch4, step2013]: loss 3.015746
[epoch4, step2014]: loss 3.927345
[epoch4, step2015]: loss 30.963791
[epoch4, step2016]: loss 14.167979
[epoch4, step2017]: loss 4.145284
[epoch4, step2018]: loss 25.892628
[epoch4, step2019]: loss 17.786339
[epoch4, step2020]: loss 2.718107
[epoch4, step2021]: loss 25.323654
[epoch4, step2022]: loss 6.476886
[epoch4, step2023]: loss 13.770694
[epoch4, step2024]: loss 3.019050
[epoch4, step2025]: loss 5.230896
[epoch4, step2026]: loss 29.870338
[epoch4, step2027]: loss 28.166069
[epoch4, step2028]: loss 3.667724
[epoch4, step2029]: loss 7.803321
[epoch4, step2030]: loss 2.739327
[epoch4, step2031]: loss 18.686220
[epoch4, step2032]: loss 32.244774
[epoch4, step2033]: loss 4.028876
[epoch4, step2034]: loss 15.195235
[epoch4, step2035]: loss 8.137167
[epoch4, step2036]: loss 28.180553
[epoch4, step2037]: loss 3.353529
[epoch4, step2038]: loss 6.022686
[epoch4, step2039]: loss 5.884864
[epoch4, step2040]: loss 5.050317
[epoch4, step2041]: loss 5.993889
[epoch4, step2042]: loss 35.597313
[epoch4, step2043]: loss 4.086588
[epoch4, step2044]: loss 19.573479
[epoch4, step2045]: loss 16.216236
[epoch4, step2046]: loss 15.615991
[epoch4, step2047]: loss 5.978208
[epoch4, step2048]: loss 40.130447
[epoch4, step2049]: loss 7.717204
[epoch4, step2050]: loss 3.271115
[epoch4, step2051]: loss 22.676651
[epoch4, step2052]: loss 2.221146
[epoch4, step2053]: loss 2.545009
[epoch4, step2054]: loss 2.621790
[epoch4, step2055]: loss 17.736746
[epoch4, step2056]: loss 17.401779
[epoch4, step2057]: loss 18.589365
[epoch4, step2058]: loss 12.725143
[epoch4, step2059]: loss 10.850766
[epoch4, step2060]: loss 20.783691
[epoch4, step2061]: loss 9.841249
[epoch4, step2062]: loss 15.762873
[epoch4, step2063]: loss 6.555663
[epoch4, step2064]: loss 2.798440
[epoch4, step2065]: loss 6.508487
[epoch4, step2066]: loss 23.433750
[epoch4, step2067]: loss 7.574310
[epoch4, step2068]: loss 25.447588
[epoch4, step2069]: loss 27.935770
[epoch4, step2070]: loss 5.125742
[epoch4, step2071]: loss 4.612727
[epoch4, step2072]: loss 3.299959
[epoch4, step2073]: loss 4.025228
[epoch4, step2074]: loss 2.092040
[epoch4, step2075]: loss 31.387505
[epoch4, step2076]: loss 5.379147
[epoch4, step2077]: loss 3.652949
[epoch4, step2078]: loss 22.037739
[epoch4, step2079]: loss 5.242765
[epoch4, step2080]: loss 16.059895
[epoch4, step2081]: loss 11.398911
[epoch4, step2082]: loss 22.505608
[epoch4, step2083]: loss 13.867341
[epoch4, step2084]: loss 13.831612
[epoch4, step2085]: loss 14.481871
[epoch4, step2086]: loss 22.329966
[epoch4, step2087]: loss 6.669086
[epoch4, step2088]: loss 4.405855
[epoch4, step2089]: loss 2.325047
[epoch4, step2090]: loss 5.813819
[epoch4, step2091]: loss 16.593084
[epoch4, step2092]: loss 4.463296
[epoch4, step2093]: loss 5.118351
[epoch4, step2094]: loss 10.725747
[epoch4, step2095]: loss 16.391710
[epoch4, step2096]: loss 19.677265
[epoch4, step2097]: loss 2.356510
[epoch4, step2098]: loss 40.857376
[epoch4, step2099]: loss 3.163372
[epoch4, step2100]: loss 8.927524
[epoch4, step2101]: loss 7.812016
[epoch4, step2102]: loss 22.547672
[epoch4, step2103]: loss 9.747210
[epoch4, step2104]: loss 16.481037
[epoch4, step2105]: loss 23.391247
[epoch4, step2106]: loss 2.812316
[epoch4, step2107]: loss 17.758615
[epoch4, step2108]: loss 15.428444
[epoch4, step2109]: loss 2.693315
[epoch4, step2110]: loss 2.850447
[epoch4, step2111]: loss 6.203298
[epoch4, step2112]: loss 6.073443
[epoch4, step2113]: loss 14.160022
[epoch4, step2114]: loss 3.020768
[epoch4, step2115]: loss 21.292833
[epoch4, step2116]: loss 6.319654
[epoch4, step2117]: loss 3.261286
[epoch4, step2118]: loss 2.505775
[epoch4, step2119]: loss 14.064426
[epoch4, step2120]: loss 4.669380
[epoch4, step2121]: loss 8.023848
[epoch4, step2122]: loss 15.740112
[epoch4, step2123]: loss 3.369691
[epoch4, step2124]: loss 2.424055
[epoch4, step2125]: loss 5.323448
[epoch4, step2126]: loss 20.397928
[epoch4, step2127]: loss 3.025543
[epoch4, step2128]: loss 21.047934
[epoch4, step2129]: loss 2.880844
[epoch4, step2130]: loss 2.214278
[epoch4, step2131]: loss 17.790203
[epoch4, step2132]: loss 6.927646
[epoch4, step2133]: loss 22.464260
[epoch4, step2134]: loss 3.106688
[epoch4, step2135]: loss 4.583972
[epoch4, step2136]: loss 5.929934
[epoch4, step2137]: loss 2.739435
[epoch4, step2138]: loss 3.745062
[epoch4, step2139]: loss 2.898962
[epoch4, step2140]: loss 14.571606
[epoch4, step2141]: loss 6.627561
[epoch4, step2142]: loss 4.864258
[epoch4, step2143]: loss 4.460515
[epoch4, step2144]: loss 14.056832
[epoch4, step2145]: loss 17.763390
[epoch4, step2146]: loss 5.206680
[epoch4, step2147]: loss 27.314171
[epoch4, step2148]: loss 5.324592
[epoch4, step2149]: loss 7.865159
[epoch4, step2150]: loss 4.516258
[epoch4, step2151]: loss 2.344509
[epoch4, step2152]: loss 29.095509
[epoch4, step2153]: loss 17.850616
[epoch4, step2154]: loss 10.937927
[epoch4, step2155]: loss 3.635686
[epoch4, step2156]: loss 25.587990
[epoch4, step2157]: loss 5.031797
[epoch4, step2158]: loss 25.615671
[epoch4, step2159]: loss 2.325825
[epoch4, step2160]: loss 4.962251
[epoch4, step2161]: loss 22.113544
[epoch4, step2162]: loss 6.374757
[epoch4, step2163]: loss 11.009124
[epoch4, step2164]: loss 4.219953
[epoch4, step2165]: loss 20.625412
[epoch4, step2166]: loss 9.609293
[epoch4, step2167]: loss 3.058325
[epoch4, step2168]: loss 4.101372
[epoch4, step2169]: loss 6.099781
[epoch4, step2170]: loss 5.080214
[epoch4, step2171]: loss 27.761675
[epoch4, step2172]: loss 13.971040
[epoch4, step2173]: loss 6.262397
[epoch4, step2174]: loss 17.880814
[epoch4, step2175]: loss 4.329674
[epoch4, step2176]: loss 4.997623
[epoch4, step2177]: loss 10.617804
[epoch4, step2178]: loss 16.307512
[epoch4, step2179]: loss 7.623316
[epoch4, step2180]: loss 2.504406
[epoch4, step2181]: loss 16.141548
[epoch4, step2182]: loss 7.216199
[epoch4, step2183]: loss 15.468964
[epoch4, step2184]: loss 19.244507
[epoch4, step2185]: loss 4.620451
[epoch4, step2186]: loss 14.935132
[epoch4, step2187]: loss 5.462285
[epoch4, step2188]: loss 4.636222
[epoch4, step2189]: loss 36.015141
[epoch4, step2190]: loss 3.403884
[epoch4, step2191]: loss 2.886846
[epoch4, step2192]: loss 11.031914
[epoch4, step2193]: loss 12.172359
[epoch4, step2194]: loss 24.004160
[epoch4, step2195]: loss 10.234102
[epoch4, step2196]: loss 7.239367
[epoch4, step2197]: loss 16.582468
[epoch4, step2198]: loss 7.737124
[epoch4, step2199]: loss 8.533989
[epoch4, step2200]: loss 9.430564
[epoch4, step2201]: loss 6.954121
[epoch4, step2202]: loss 10.437189
[epoch4, step2203]: loss 10.185767
[epoch4, step2204]: loss 4.218583
[epoch4, step2205]: loss 3.426858
[epoch4, step2206]: loss 2.193621
[epoch4, step2207]: loss 15.197008
[epoch4, step2208]: loss 3.398576
[epoch4, step2209]: loss 6.297957
[epoch4, step2210]: loss 24.941912
[epoch4, step2211]: loss 21.619133
[epoch4, step2212]: loss 13.545869
[epoch4, step2213]: loss 3.054080
[epoch4, step2214]: loss 13.515489
[epoch4, step2215]: loss 1.960692
[epoch4, step2216]: loss 3.438677
[epoch4, step2217]: loss 2.503897
[epoch4, step2218]: loss 45.086456
[epoch4, step2219]: loss 6.461615
[epoch4, step2220]: loss 20.764704
[epoch4, step2221]: loss 3.208979
[epoch4, step2222]: loss 4.201046
[epoch4, step2223]: loss 2.017192
[epoch4, step2224]: loss 2.353463
[epoch4, step2225]: loss 26.361471
[epoch4, step2226]: loss 16.129807
[epoch4, step2227]: loss 10.921240
[epoch4, step2228]: loss 22.774317
[epoch4, step2229]: loss 25.647133
[epoch4, step2230]: loss 34.800060
[epoch4, step2231]: loss 4.327971
[epoch4, step2232]: loss 3.372851
[epoch4, step2233]: loss 4.931957
[epoch4, step2234]: loss 4.949318
[epoch4, step2235]: loss 33.770142
[epoch4, step2236]: loss 3.161368
[epoch4, step2237]: loss 2.021756
[epoch4, step2238]: loss 3.110583
[epoch4, step2239]: loss 9.852396
[epoch4, step2240]: loss 23.833376
[epoch4, step2241]: loss 11.067131
[epoch4, step2242]: loss 2.468883
[epoch4, step2243]: loss 8.178022
[epoch4, step2244]: loss 24.937485
[epoch4, step2245]: loss 3.274925
[epoch4, step2246]: loss 21.029356
[epoch4, step2247]: loss 9.980432
[epoch4, step2248]: loss 33.880890
[epoch4, step2249]: loss 5.119710
[epoch4, step2250]: loss 14.836201
[epoch4, step2251]: loss 29.423483
[epoch4, step2252]: loss 12.921852
[epoch4, step2253]: loss 7.950458
[epoch4, step2254]: loss 3.564547
[epoch4, step2255]: loss 6.574451
[epoch4, step2256]: loss 14.756710
[epoch4, step2257]: loss 5.992498
[epoch4, step2258]: loss 13.584598
[epoch4, step2259]: loss 12.787889
[epoch4, step2260]: loss 13.991086
[epoch4, step2261]: loss 9.356849
[epoch4, step2262]: loss 10.154650
[epoch4, step2263]: loss 26.623466
[epoch4, step2264]: loss 21.429821
[epoch4, step2265]: loss 5.775970
[epoch4, step2266]: loss 3.804621
[epoch4, step2267]: loss 1.803630
[epoch4, step2268]: loss 4.297799
[epoch4, step2269]: loss 24.010998
[epoch4, step2270]: loss 22.752134
[epoch4, step2271]: loss 3.830657
[epoch4, step2272]: loss 5.954327
[epoch4, step2273]: loss 25.494232
[epoch4, step2274]: loss 28.847925
[epoch4, step2275]: loss 9.543598
[epoch4, step2276]: loss 13.058039
[epoch4, step2277]: loss 2.135061
[epoch4, step2278]: loss 4.575691
[epoch4, step2279]: loss 3.437971
[epoch4, step2280]: loss 7.024034
[epoch4, step2281]: loss 9.782317
[epoch4, step2282]: loss 27.445065
[epoch4, step2283]: loss 5.496527
[epoch4, step2284]: loss 3.745334
[epoch4, step2285]: loss 10.964846
[epoch4, step2286]: loss 36.899963
[epoch4, step2287]: loss 6.794872
[epoch4, step2288]: loss 19.264044
[epoch4, step2289]: loss 15.480819
[epoch4, step2290]: loss 33.356003
[epoch4, step2291]: loss 28.780405
[epoch4, step2292]: loss 38.703259
[epoch4, step2293]: loss 2.354372
[epoch4, step2294]: loss 15.004915
[epoch4, step2295]: loss 34.148899
[epoch4, step2296]: loss 2.218997
[epoch4, step2297]: loss 13.069857
[epoch4, step2298]: loss 11.669888
[epoch4, step2299]: loss 22.485756
[epoch4, step2300]: loss 20.102627
[epoch4, step2301]: loss 18.061893
[epoch4, step2302]: loss 26.381340
[epoch4, step2303]: loss 5.474958
[epoch4, step2304]: loss 5.594453
[epoch4, step2305]: loss 25.297739
[epoch4, step2306]: loss 3.433723
[epoch4, step2307]: loss 44.919785
[epoch4, step2308]: loss 3.071209
[epoch4, step2309]: loss 5.476239
[epoch4, step2310]: loss 8.216125
[epoch4, step2311]: loss 3.512679
[epoch4, step2312]: loss 67.709229
[epoch4, step2313]: loss 3.079820
[epoch4, step2314]: loss 3.904452
[epoch4, step2315]: loss 3.477469
[epoch4, step2316]: loss 6.540364
[epoch4, step2317]: loss 5.852006
[epoch4, step2318]: loss 2.552847
[epoch4, step2319]: loss 2.554137
[epoch4, step2320]: loss 7.235939
[epoch4, step2321]: loss 4.895512
[epoch4, step2322]: loss 18.465612
[epoch4, step2323]: loss 23.678310
[epoch4, step2324]: loss 5.647474
[epoch4, step2325]: loss 5.602948
[epoch4, step2326]: loss 4.549258
[epoch4, step2327]: loss 19.791927
[epoch4, step2328]: loss 7.427073
[epoch4, step2329]: loss 5.196961
[epoch4, step2330]: loss 6.008846
[epoch4, step2331]: loss 20.910627
[epoch4, step2332]: loss 19.687563
[epoch4, step2333]: loss 4.768984
[epoch4, step2334]: loss 22.820553
[epoch4, step2335]: loss 4.445278
[epoch4, step2336]: loss 1.531527
[epoch4, step2337]: loss 4.554032
[epoch4, step2338]: loss 12.645677
[epoch4, step2339]: loss 3.760691
[epoch4, step2340]: loss 3.021336
[epoch4, step2341]: loss 41.724312
[epoch4, step2342]: loss 4.128571
[epoch4, step2343]: loss 5.935363
[epoch4, step2344]: loss 3.448487
[epoch4, step2345]: loss 40.424965
[epoch4, step2346]: loss 27.535234
[epoch4, step2347]: loss 1.776554
[epoch4, step2348]: loss 17.495384
[epoch4, step2349]: loss 3.134930
[epoch4, step2350]: loss 15.503495
[epoch4, step2351]: loss 10.206409
[epoch4, step2352]: loss 5.667213
[epoch4, step2353]: loss 15.874398
[epoch4, step2354]: loss 18.600645
[epoch4, step2355]: loss 9.702817
[epoch4, step2356]: loss 13.461969
[epoch4, step2357]: loss 5.901947
[epoch4, step2358]: loss 21.590618
[epoch4, step2359]: loss 2.762034
[epoch4, step2360]: loss 23.123335
[epoch4, step2361]: loss 4.780106
[epoch4, step2362]: loss 13.237345
[epoch4, step2363]: loss 4.235084
[epoch4, step2364]: loss 2.847030
[epoch4, step2365]: loss 25.566656
[epoch4, step2366]: loss 16.433537
[epoch4, step2367]: loss 14.981412
[epoch4, step2368]: loss 22.018166
[epoch4, step2369]: loss 2.065459
[epoch4, step2370]: loss 4.015184
[epoch4, step2371]: loss 4.361208
[epoch4, step2372]: loss 5.634132
[epoch4, step2373]: loss 3.884240
[epoch4, step2374]: loss 7.437398
[epoch4, step2375]: loss 6.238528
[epoch4, step2376]: loss 22.235519
[epoch4, step2377]: loss 31.920044
[epoch4, step2378]: loss 2.767784
[epoch4, step2379]: loss 38.960197
[epoch4, step2380]: loss 8.056401
[epoch4, step2381]: loss 22.476473
[epoch4, step2382]: loss 5.118434
[epoch4, step2383]: loss 5.270133
[epoch4, step2384]: loss 2.924337
[epoch4, step2385]: loss 16.195004
[epoch4, step2386]: loss 13.194693
[epoch4, step2387]: loss 30.665962
[epoch4, step2388]: loss 2.390706
[epoch4, step2389]: loss 5.608211
[epoch4, step2390]: loss 3.922766
[epoch4, step2391]: loss 8.896940
[epoch4, step2392]: loss 20.859005
[epoch4, step2393]: loss 16.900703
[epoch4, step2394]: loss 10.100117
[epoch4, step2395]: loss 11.341796
[epoch4, step2396]: loss 29.353943
[epoch4, step2397]: loss 26.814980
[epoch4, step2398]: loss 5.304601
[epoch4, step2399]: loss 2.436256
[epoch4, step2400]: loss 6.769940
[epoch4, step2401]: loss 13.369201
[epoch4, step2402]: loss 2.038443
[epoch4, step2403]: loss 6.361411
[epoch4, step2404]: loss 2.176941
[epoch4, step2405]: loss 3.254213
[epoch4, step2406]: loss 21.701160
[epoch4, step2407]: loss 5.928554
[epoch4, step2408]: loss 3.239912
[epoch4, step2409]: loss 9.227331
[epoch4, step2410]: loss 2.685823
[epoch4, step2411]: loss 3.031475
[epoch4, step2412]: loss 16.752211
[epoch4, step2413]: loss 5.388033
[epoch4, step2414]: loss 8.134458
[epoch4, step2415]: loss 2.267848
[epoch4, step2416]: loss 17.391001
[epoch4, step2417]: loss 22.351835
[epoch4, step2418]: loss 3.192274
[epoch4, step2419]: loss 2.958841
[epoch4, step2420]: loss 3.403572
[epoch4, step2421]: loss 2.985107
[epoch4, step2422]: loss 3.688744
[epoch4, step2423]: loss 48.915627
[epoch4, step2424]: loss 4.447914
[epoch4, step2425]: loss 5.603985
[epoch4, step2426]: loss 19.256994
[epoch4, step2427]: loss 39.006184
[epoch4, step2428]: loss 26.066565
[epoch4, step2429]: loss 7.163693
[epoch4, step2430]: loss 22.702486
[epoch4, step2431]: loss 6.779275
[epoch4, step2432]: loss 25.297092
[epoch4, step2433]: loss 16.488289
[epoch4, step2434]: loss 2.605488
[epoch4, step2435]: loss 5.418971
[epoch4, step2436]: loss 3.147029
[epoch4, step2437]: loss 9.300976
[epoch4, step2438]: loss 2.089545
[epoch4, step2439]: loss 34.687527
[epoch4, step2440]: loss 3.831334
[epoch4, step2441]: loss 36.739174
[epoch4, step2442]: loss 5.341630
[epoch4, step2443]: loss 38.771454
[epoch4, step2444]: loss 5.081204
[epoch4, step2445]: loss 4.135215
[epoch4, step2446]: loss 20.656906
[epoch4, step2447]: loss 3.233066
[epoch4, step2448]: loss 27.685757
[epoch4, step2449]: loss 3.839972
[epoch4, step2450]: loss 7.861726
[epoch4, step2451]: loss 16.558048
[epoch4, step2452]: loss 33.920334
[epoch4, step2453]: loss 13.809033
[epoch4, step2454]: loss 3.639071
[epoch4, step2455]: loss 5.771110
[epoch4, step2456]: loss 6.269526
[epoch4, step2457]: loss 24.892559
[epoch4, step2458]: loss 5.122315
[epoch4, step2459]: loss 9.884096
[epoch4, step2460]: loss 5.633331
[epoch4, step2461]: loss 2.988444
[epoch4, step2462]: loss 2.015112
[epoch4, step2463]: loss 21.837616
[epoch4, step2464]: loss 4.983980
[epoch4, step2465]: loss 13.839161
[epoch4, step2466]: loss 4.006611
[epoch4, step2467]: loss 14.744669
[epoch4, step2468]: loss 1.994851
[epoch4, step2469]: loss 4.568535
[epoch4, step2470]: loss 20.228041
[epoch4, step2471]: loss 3.134923
[epoch4, step2472]: loss 2.649038
[epoch4, step2473]: loss 4.439311
[epoch4, step2474]: loss 10.666037
[epoch4, step2475]: loss 5.678763
[epoch4, step2476]: loss 3.226017
[epoch4, step2477]: loss 3.725330
[epoch4, step2478]: loss 34.408306
[epoch4, step2479]: loss 3.408182
[epoch4, step2480]: loss 20.098406
[epoch4, step2481]: loss 12.628342
[epoch4, step2482]: loss 8.028448
[epoch4, step2483]: loss 15.443433
[epoch4, step2484]: loss 26.601662
[epoch4, step2485]: loss 6.496358
[epoch4, step2486]: loss 3.546405
[epoch4, step2487]: loss 3.502139
[epoch4, step2488]: loss 36.278625
[epoch4, step2489]: loss 3.974887
[epoch4, step2490]: loss 17.318420
[epoch4, step2491]: loss 19.695812
[epoch4, step2492]: loss 4.566404
[epoch4, step2493]: loss 3.522845
[epoch4, step2494]: loss 6.519080
[epoch4, step2495]: loss 2.916906
[epoch4, step2496]: loss 3.318671
[epoch4, step2497]: loss 13.631066
[epoch4, step2498]: loss 8.617702
[epoch4, step2499]: loss 3.589067
[epoch4, step2500]: loss 5.683739
[epoch4, step2501]: loss 18.124619
[epoch4, step2502]: loss 2.242845
[epoch4, step2503]: loss 4.063345
[epoch4, step2504]: loss 5.206618
[epoch4, step2505]: loss 4.648884
[epoch4, step2506]: loss 7.335596
[epoch4, step2507]: loss 11.546614
[epoch4, step2508]: loss 3.220369
[epoch4, step2509]: loss 19.994982
[epoch4, step2510]: loss 3.378394
[epoch4, step2511]: loss 15.073833
[epoch4, step2512]: loss 2.564517
[epoch4, step2513]: loss 5.067504
[epoch4, step2514]: loss 3.156690
[epoch4, step2515]: loss 2.285817
[epoch4, step2516]: loss 23.376154
[epoch4, step2517]: loss 7.278396
[epoch4, step2518]: loss 2.453903
[epoch4, step2519]: loss 5.078606
[epoch4, step2520]: loss 6.795839
[epoch4, step2521]: loss 3.062068
[epoch4, step2522]: loss 24.411480
[epoch4, step2523]: loss 1.878715
[epoch4, step2524]: loss 2.792370
[epoch4, step2525]: loss 4.152961
[epoch4, step2526]: loss 35.136410
[epoch4, step2527]: loss 4.208114
[epoch4, step2528]: loss 4.514762
[epoch4, step2529]: loss 7.770085
[epoch4, step2530]: loss 4.119417
[epoch4, step2531]: loss 2.519285
[epoch4, step2532]: loss 18.448767
[epoch4, step2533]: loss 2.594852
[epoch4, step2534]: loss 10.797909
[epoch4, step2535]: loss 2.709601
[epoch4, step2536]: loss 25.389030
[epoch4, step2537]: loss 3.689121
[epoch4, step2538]: loss 42.537663
[epoch4, step2539]: loss 2.371124
[epoch4, step2540]: loss 4.832783
[epoch4, step2541]: loss 18.146660
[epoch4, step2542]: loss 6.847379
[epoch4, step2543]: loss 7.126919
[epoch4, step2544]: loss 18.069422
[epoch4, step2545]: loss 2.906141
[epoch4, step2546]: loss 5.209770
[epoch4, step2547]: loss 6.142048
[epoch4, step2548]: loss 6.445797
[epoch4, step2549]: loss 47.861000
[epoch4, step2550]: loss 14.316355
[epoch4, step2551]: loss 3.372235
[epoch4, step2552]: loss 1.583941
[epoch4, step2553]: loss 12.981441
[epoch4, step2554]: loss 31.843180
[epoch4, step2555]: loss 17.212025
[epoch4, step2556]: loss 9.187500
[epoch4, step2557]: loss 19.496214
[epoch4, step2558]: loss 3.308277
[epoch4, step2559]: loss 5.063291
[epoch4, step2560]: loss 8.428715
[epoch4, step2561]: loss 4.536854
[epoch4, step2562]: loss 28.337263
[epoch4, step2563]: loss 3.760761
[epoch4, step2564]: loss 4.632718
[epoch4, step2565]: loss 14.642440
[epoch4, step2566]: loss 23.292917
[epoch4, step2567]: loss 21.511801
[epoch4, step2568]: loss 14.696618
[epoch4, step2569]: loss 8.710142
[epoch4, step2570]: loss 3.013847
[epoch4, step2571]: loss 21.579224
[epoch4, step2572]: loss 3.478277
[epoch4, step2573]: loss 23.633160
[epoch4, step2574]: loss 14.360293
[epoch4, step2575]: loss 18.311787
[epoch4, step2576]: loss 5.316353
[epoch4, step2577]: loss 3.176384
[epoch4, step2578]: loss 7.955755
[epoch4, step2579]: loss 14.617855
[epoch4, step2580]: loss 2.346620
[epoch4, step2581]: loss 10.591797
[epoch4, step2582]: loss 1.967469
[epoch4, step2583]: loss 13.200459
[epoch4, step2584]: loss 7.587138
[epoch4, step2585]: loss 4.310447
[epoch4, step2586]: loss 4.054772
[epoch4, step2587]: loss 25.389036
[epoch4, step2588]: loss 2.732773
[epoch4, step2589]: loss 44.286999
[epoch4, step2590]: loss 5.344977
[epoch4, step2591]: loss 6.159515
[epoch4, step2592]: loss 3.447475
[epoch4, step2593]: loss 5.115641
[epoch4, step2594]: loss 3.601373
[epoch4, step2595]: loss 3.563519
[epoch4, step2596]: loss 24.326609
[epoch4, step2597]: loss 29.555679
[epoch4, step2598]: loss 4.256219
[epoch4, step2599]: loss 6.140256
[epoch4, step2600]: loss 5.444494
[epoch4, step2601]: loss 5.158410
[epoch4, step2602]: loss 15.006897
[epoch4, step2603]: loss 3.103929
[epoch4, step2604]: loss 3.072997
[epoch4, step2605]: loss 19.675724
[epoch4, step2606]: loss 9.635571
[epoch4, step2607]: loss 2.603234
[epoch4, step2608]: loss 2.877252
[epoch4, step2609]: loss 6.528704
[epoch4, step2610]: loss 41.082737
[epoch4, step2611]: loss 4.041008
[epoch4, step2612]: loss 33.446796
[epoch4, step2613]: loss 15.171898
[epoch4, step2614]: loss 39.076813
[epoch4, step2615]: loss 2.731302
[epoch4, step2616]: loss 4.791773
[epoch4, step2617]: loss 3.444134
[epoch4, step2618]: loss 1.773912
[epoch4, step2619]: loss 3.272628
[epoch4, step2620]: loss 1.990340
[epoch4, step2621]: loss 16.913332
[epoch4, step2622]: loss 7.898485
[epoch4, step2623]: loss 13.935303
[epoch4, step2624]: loss 3.839779
[epoch4, step2625]: loss 2.030507
[epoch4, step2626]: loss 28.077845
[epoch4, step2627]: loss 4.654355
[epoch4, step2628]: loss 4.407943
[epoch4, step2629]: loss 5.225598
[epoch4, step2630]: loss 3.223695
[epoch4, step2631]: loss 14.693033
[epoch4, step2632]: loss 32.310688
[epoch4, step2633]: loss 3.005795
[epoch4, step2634]: loss 2.260910
[epoch4, step2635]: loss 38.940090
[epoch4, step2636]: loss 3.933997
[epoch4, step2637]: loss 11.266674
[epoch4, step2638]: loss 2.050136
[epoch4, step2639]: loss 15.590385
[epoch4, step2640]: loss 16.343754
[epoch4, step2641]: loss 7.565363
[epoch4, step2642]: loss 32.159363
[epoch4, step2643]: loss 2.087233
[epoch4, step2644]: loss 3.675179
[epoch4, step2645]: loss 5.804566
[epoch4, step2646]: loss 12.149776
[epoch4, step2647]: loss 2.751114
[epoch4, step2648]: loss 5.803495
[epoch4, step2649]: loss 4.370540
[epoch4, step2650]: loss 6.548592
[epoch4, step2651]: loss 7.832177
[epoch4, step2652]: loss 9.813456
[epoch4, step2653]: loss 6.342094
[epoch4, step2654]: loss 3.317483
[epoch4, step2655]: loss 3.092769
[epoch4, step2656]: loss 21.685137
[epoch4, step2657]: loss 5.409267
[epoch4, step2658]: loss 23.172548
[epoch4, step2659]: loss 35.048515
[epoch4, step2660]: loss 23.256678
[epoch4, step2661]: loss 2.220638
[epoch4, step2662]: loss 24.284725
[epoch4, step2663]: loss 6.776668
[epoch4, step2664]: loss 6.022627
[epoch4, step2665]: loss 21.745274
[epoch4, step2666]: loss 2.735045
[epoch4, step2667]: loss 22.987705
[epoch4, step2668]: loss 3.445905
[epoch4, step2669]: loss 28.812960
[epoch4, step2670]: loss 3.344914
[epoch4, step2671]: loss 3.951254
[epoch4, step2672]: loss 34.754868
[epoch4, step2673]: loss 12.772197
[epoch4, step2674]: loss 4.893874
[epoch4, step2675]: loss 2.653205
[epoch4, step2676]: loss 12.119715
[epoch4, step2677]: loss 6.531595
[epoch4, step2678]: loss 3.458387
[epoch4, step2679]: loss 4.256823
[epoch4, step2680]: loss 2.381425
[epoch4, step2681]: loss 8.591256
[epoch4, step2682]: loss 2.123111
[epoch4, step2683]: loss 2.551751
[epoch4, step2684]: loss 28.627954
[epoch4, step2685]: loss 2.516606
[epoch4, step2686]: loss 3.619549
[epoch4, step2687]: loss 10.729595
[epoch4, step2688]: loss 2.732355
[epoch4, step2689]: loss 20.958857
[epoch4, step2690]: loss 20.870405
[epoch4, step2691]: loss 22.592945
[epoch4, step2692]: loss 14.609040
[epoch4, step2693]: loss 3.929040
[epoch4, step2694]: loss 13.212901
[epoch4, step2695]: loss 10.029038
[epoch4, step2696]: loss 15.296041
[epoch4, step2697]: loss 5.101490
[epoch4, step2698]: loss 2.792224
[epoch4, step2699]: loss 4.007217
[epoch4, step2700]: loss 28.496756
[epoch4, step2701]: loss 3.552298
[epoch4, step2702]: loss 7.357605
[epoch4, step2703]: loss 21.273010
[epoch4, step2704]: loss 5.784241
[epoch4, step2705]: loss 2.600008
[epoch4, step2706]: loss 7.299110
[epoch4, step2707]: loss 17.965891
[epoch4, step2708]: loss 3.835639
[epoch4, step2709]: loss 6.339693
[epoch4, step2710]: loss 15.737616
[epoch4, step2711]: loss 2.098382
[epoch4, step2712]: loss 7.150850
[epoch4, step2713]: loss 21.717339
[epoch4, step2714]: loss 3.126126
[epoch4, step2715]: loss 30.108606
[epoch4, step2716]: loss 9.305771
[epoch4, step2717]: loss 3.497749
[epoch4, step2718]: loss 2.940445
[epoch4, step2719]: loss 5.383074
[epoch4, step2720]: loss 18.226120
[epoch4, step2721]: loss 3.124272
[epoch4, step2722]: loss 4.351944
[epoch4, step2723]: loss 4.775549
[epoch4, step2724]: loss 21.510803
[epoch4, step2725]: loss 53.135059
[epoch4, step2726]: loss 29.685062
[epoch4, step2727]: loss 6.820138
[epoch4, step2728]: loss 7.180715
[epoch4, step2729]: loss 17.167036
[epoch4, step2730]: loss 2.804035
[epoch4, step2731]: loss 5.740808
[epoch4, step2732]: loss 2.915431
[epoch4, step2733]: loss 14.090598
[epoch4, step2734]: loss 6.085778
[epoch4, step2735]: loss 2.750937
[epoch4, step2736]: loss 26.777817
[epoch4, step2737]: loss 30.159018
[epoch4, step2738]: loss 5.753479
[epoch4, step2739]: loss 6.409632
[epoch4, step2740]: loss 3.068504
[epoch4, step2741]: loss 4.183195
[epoch4, step2742]: loss 25.219275
[epoch4, step2743]: loss 55.797382
[epoch4, step2744]: loss 3.437392
[epoch4, step2745]: loss 24.666019
[epoch4, step2746]: loss 20.183670
[epoch4, step2747]: loss 31.104519
[epoch4, step2748]: loss 9.916143
[epoch4, step2749]: loss 5.799467
[epoch4, step2750]: loss 3.723632
[epoch4, step2751]: loss 3.787527
[epoch4, step2752]: loss 14.168635
[epoch4, step2753]: loss 4.074624
[epoch4, step2754]: loss 11.956430
[epoch4, step2755]: loss 2.277132
[epoch4, step2756]: loss 15.253925
[epoch4, step2757]: loss 21.607389
[epoch4, step2758]: loss 9.795444
[epoch4, step2759]: loss 2.283655
[epoch4, step2760]: loss 25.138838
[epoch4, step2761]: loss 4.024030
[epoch4, step2762]: loss 4.432936
[epoch4, step2763]: loss 23.196943
[epoch4, step2764]: loss 2.170966
[epoch4, step2765]: loss 3.246086
[epoch4, step2766]: loss 10.874595
[epoch4, step2767]: loss 4.776934
[epoch4, step2768]: loss 5.998211
[epoch4, step2769]: loss 1.984870
[epoch4, step2770]: loss 5.346531
[epoch4, step2771]: loss 3.310109
[epoch4, step2772]: loss 20.285368
[epoch4, step2773]: loss 3.651370
[epoch4, step2774]: loss 5.815392
[epoch4, step2775]: loss 2.651782
[epoch4, step2776]: loss 16.330765
[epoch4, step2777]: loss 2.510045
[epoch4, step2778]: loss 3.215070
[epoch4, step2779]: loss 29.519751
[epoch4, step2780]: loss 2.972018
[epoch4, step2781]: loss 21.626064
[epoch4, step2782]: loss 4.138714
[epoch4, step2783]: loss 18.640661
[epoch4, step2784]: loss 20.879606
[epoch4, step2785]: loss 6.369507
[epoch4, step2786]: loss 23.646355
[epoch4, step2787]: loss 3.625688
[epoch4, step2788]: loss 32.549309
[epoch4, step2789]: loss 4.413730
[epoch4, step2790]: loss 5.769250
[epoch4, step2791]: loss 12.502439
[epoch4, step2792]: loss 4.861242
[epoch4, step2793]: loss 33.464622
[epoch4, step2794]: loss 4.105644
[epoch4, step2795]: loss 5.026883
[epoch4, step2796]: loss 4.015322
[epoch4, step2797]: loss 16.155739
[epoch4, step2798]: loss 10.950536
[epoch4, step2799]: loss 7.902060
[epoch4, step2800]: loss 7.931949
[epoch4, step2801]: loss 11.199581
[epoch4, step2802]: loss 12.424503
[epoch4, step2803]: loss 35.895901
[epoch4, step2804]: loss 18.555571
[epoch4, step2805]: loss 4.849785
[epoch4, step2806]: loss 6.164143
[epoch4, step2807]: loss 24.096241
[epoch4, step2808]: loss 32.215046
[epoch4, step2809]: loss 1.825725
[epoch4, step2810]: loss 6.674913
[epoch4, step2811]: loss 15.627548
[epoch4, step2812]: loss 4.199593
[epoch4, step2813]: loss 18.589895
[epoch4, step2814]: loss 2.462146
[epoch4, step2815]: loss 23.711184
[epoch4, step2816]: loss 2.308867
[epoch4, step2817]: loss 2.199626
[epoch4, step2818]: loss 4.643551
[epoch4, step2819]: loss 3.947594
[epoch4, step2820]: loss 4.671729
[epoch4, step2821]: loss 2.188340
[epoch4, step2822]: loss 11.435012
[epoch4, step2823]: loss 3.540126
[epoch4, step2824]: loss 3.447378
[epoch4, step2825]: loss 18.423269
[epoch4, step2826]: loss 4.972907
[epoch4, step2827]: loss 2.653287
[epoch4, step2828]: loss 2.535153
[epoch4, step2829]: loss 23.455423
[epoch4, step2830]: loss 3.975596
[epoch4, step2831]: loss 2.797868
[epoch4, step2832]: loss 30.830730
[epoch4, step2833]: loss 11.637896
[epoch4, step2834]: loss 8.232100
[epoch4, step2835]: loss 2.300542
[epoch4, step2836]: loss 25.126303
[epoch4, step2837]: loss 2.596766
[epoch4, step2838]: loss 20.019299
[epoch4, step2839]: loss 13.888659
[epoch4, step2840]: loss 25.235485
[epoch4, step2841]: loss 6.645846
[epoch4, step2842]: loss 4.342777
[epoch4, step2843]: loss 4.633289
[epoch4, step2844]: loss 4.998705
[epoch4, step2845]: loss 13.860878
[epoch4, step2846]: loss 7.180046
[epoch4, step2847]: loss 16.474888
[epoch4, step2848]: loss 3.244405
[epoch4, step2849]: loss 4.498230
[epoch4, step2850]: loss 22.538601
[epoch4, step2851]: loss 2.676080
[epoch4, step2852]: loss 17.453211
[epoch4, step2853]: loss 30.786026
[epoch4, step2854]: loss 3.960065
[epoch4, step2855]: loss 17.942608
[epoch4, step2856]: loss 3.952822
[epoch4, step2857]: loss 3.614321
[epoch4, step2858]: loss 6.706960
[epoch4, step2859]: loss 1.829631
[epoch4, step2860]: loss 13.731879
[epoch4, step2861]: loss 6.255082
[epoch4, step2862]: loss 14.368757
[epoch4, step2863]: loss 3.349208
[epoch4, step2864]: loss 3.306880
[epoch4, step2865]: loss 6.640426
[epoch4, step2866]: loss 6.223768
[epoch4, step2867]: loss 5.424688
[epoch4, step2868]: loss 9.865734
[epoch4, step2869]: loss 2.226610
[epoch4, step2870]: loss 21.686005
[epoch4, step2871]: loss 3.766560
[epoch4, step2872]: loss 20.437038
[epoch4, step2873]: loss 4.019976
[epoch4, step2874]: loss 6.867011
[epoch4, step2875]: loss 6.156588
[epoch4, step2876]: loss 5.535041
[epoch4, step2877]: loss 2.685193
[epoch4, step2878]: loss 13.688386
[epoch4, step2879]: loss 6.159761
[epoch4, step2880]: loss 3.225458
[epoch4, step2881]: loss 1.821124
[epoch4, step2882]: loss 46.592846
[epoch4, step2883]: loss 7.372564
[epoch4, step2884]: loss 1.924622
[epoch4, step2885]: loss 5.423793
[epoch4, step2886]: loss 6.593147
[epoch4, step2887]: loss 3.338723
[epoch4, step2888]: loss 4.537902
[epoch4, step2889]: loss 6.840694
[epoch4, step2890]: loss 3.840176
[epoch4, step2891]: loss 1.984306
[epoch4, step2892]: loss 21.395794
[epoch4, step2893]: loss 20.700378
[epoch4, step2894]: loss 14.897135
[epoch4, step2895]: loss 19.357922
[epoch4, step2896]: loss 3.732010
[epoch4, step2897]: loss 3.872355
[epoch4, step2898]: loss 1.635753
[epoch4, step2899]: loss 3.767584
[epoch4, step2900]: loss 1.980641
[epoch4, step2901]: loss 2.324765
[epoch4, step2902]: loss 7.798746
[epoch4, step2903]: loss 13.039263
[epoch4, step2904]: loss 2.216678
[epoch4, step2905]: loss 1.897947
[epoch4, step2906]: loss 8.456619
[epoch4, step2907]: loss 13.951207
[epoch4, step2908]: loss 21.980204
[epoch4, step2909]: loss 35.596241
[epoch4, step2910]: loss 4.249556
[epoch4, step2911]: loss 32.533867
[epoch4, step2912]: loss 4.527565
[epoch4, step2913]: loss 15.620528
[epoch4, step2914]: loss 4.163315
[epoch4, step2915]: loss 22.423410
[epoch4, step2916]: loss 16.503437
[epoch4, step2917]: loss 24.537424
[epoch4, step2918]: loss 2.771688
[epoch4, step2919]: loss 8.246920
[epoch4, step2920]: loss 3.299387
[epoch4, step2921]: loss 17.835024
[epoch4, step2922]: loss 9.162789
[epoch4, step2923]: loss 11.584676
[epoch4, step2924]: loss 2.130711
[epoch4, step2925]: loss 6.672122
[epoch4, step2926]: loss 22.091713
[epoch4, step2927]: loss 4.975096
[epoch4, step2928]: loss 22.563629
[epoch4, step2929]: loss 31.213936
[epoch4, step2930]: loss 5.475813
[epoch4, step2931]: loss 20.850536
[epoch4, step2932]: loss 8.225201
[epoch4, step2933]: loss 8.379254
[epoch4, step2934]: loss 1.726278
[epoch4, step2935]: loss 18.637800
[epoch4, step2936]: loss 5.489941
[epoch4, step2937]: loss 3.702809
[epoch4, step2938]: loss 5.859971
[epoch4, step2939]: loss 33.053154
[epoch4, step2940]: loss 21.346407
[epoch4, step2941]: loss 19.313433
[epoch4, step2942]: loss 16.696314
[epoch4, step2943]: loss 21.125381
[epoch4, step2944]: loss 15.113032
[epoch4, step2945]: loss 3.023428
[epoch4, step2946]: loss 11.988009
[epoch4, step2947]: loss 19.388510
[epoch4, step2948]: loss 14.897143
[epoch4, step2949]: loss 11.362684
[epoch4, step2950]: loss 45.279743
[epoch4, step2951]: loss 4.723717
[epoch4, step2952]: loss 2.660866
[epoch4, step2953]: loss 7.110674
[epoch4, step2954]: loss 56.570724
[epoch4, step2955]: loss 31.071728
[epoch4, step2956]: loss 3.046830
[epoch4, step2957]: loss 8.359599
[epoch4, step2958]: loss 11.191459
[epoch4, step2959]: loss 26.705414
[epoch4, step2960]: loss 3.042152
[epoch4, step2961]: loss 7.029564
[epoch4, step2962]: loss 9.581566
[epoch4, step2963]: loss 2.493405
[epoch4, step2964]: loss 61.971111
[epoch4, step2965]: loss 3.569782
[epoch4, step2966]: loss 24.404306
[epoch4, step2967]: loss 10.263111
[epoch4, step2968]: loss 6.013187
[epoch4, step2969]: loss 30.941347
[epoch4, step2970]: loss 6.115805
[epoch4, step2971]: loss 17.148674
[epoch4, step2972]: loss 5.395406
[epoch4, step2973]: loss 22.922626
[epoch4, step2974]: loss 5.135322
[epoch4, step2975]: loss 13.862189
[epoch4, step2976]: loss 2.897494
[epoch4, step2977]: loss 34.376869
[epoch4, step2978]: loss 14.689486
[epoch4, step2979]: loss 2.749539
[epoch4, step2980]: loss 14.082912
[epoch4, step2981]: loss 5.961712
[epoch4, step2982]: loss 11.858898
[epoch4, step2983]: loss 19.530956
[epoch4, step2984]: loss 4.946302
[epoch4, step2985]: loss 10.425220
[epoch4, step2986]: loss 14.195044
[epoch4, step2987]: loss 3.954484
[epoch4, step2988]: loss 3.210628
[epoch4, step2989]: loss 4.418218
[epoch4, step2990]: loss 4.126300
[epoch4, step2991]: loss 12.393486
[epoch4, step2992]: loss 23.738884
[epoch4, step2993]: loss 4.042895
[epoch4, step2994]: loss 12.061302
[epoch4, step2995]: loss 4.345949
[epoch4, step2996]: loss 23.521097
[epoch4, step2997]: loss 2.945900
[epoch4, step2998]: loss 18.604733
[epoch4, step2999]: loss 13.035855
[epoch4, step3000]: loss 23.949261
[epoch4, step3001]: loss 16.017679
[epoch4, step3002]: loss 2.557674
[epoch4, step3003]: loss 3.215442
[epoch4, step3004]: loss 13.991849
[epoch4, step3005]: loss 2.162894
[epoch4, step3006]: loss 15.112491
[epoch4, step3007]: loss 1.882190
[epoch4, step3008]: loss 19.554913
[epoch4, step3009]: loss 5.483017
[epoch4, step3010]: loss 8.458888
[epoch4, step3011]: loss 5.424292
[epoch4, step3012]: loss 8.566283
[epoch4, step3013]: loss 30.401529
[epoch4, step3014]: loss 14.157138
[epoch4, step3015]: loss 2.592294
[epoch4, step3016]: loss 9.627737
[epoch4, step3017]: loss 2.632186
[epoch4, step3018]: loss 2.091778
[epoch4, step3019]: loss 8.920738
[epoch4, step3020]: loss 23.518127
[epoch4, step3021]: loss 2.708914
[epoch4, step3022]: loss 21.748615
[epoch4, step3023]: loss 3.312684
[epoch4, step3024]: loss 9.885350
[epoch4, step3025]: loss 4.464042
[epoch4, step3026]: loss 6.149934
[epoch4, step3027]: loss 5.265809
[epoch4, step3028]: loss 19.030869
[epoch4, step3029]: loss 15.205574
[epoch4, step3030]: loss 12.560625
[epoch4, step3031]: loss 34.739658
[epoch4, step3032]: loss 5.426248
[epoch4, step3033]: loss 9.567992
[epoch4, step3034]: loss 3.471311
[epoch4, step3035]: loss 3.131759
[epoch4, step3036]: loss 6.673150
[epoch4, step3037]: loss 6.000524
[epoch4, step3038]: loss 2.681250
[epoch4, step3039]: loss 6.351648
[epoch4, step3040]: loss 17.926298
[epoch4, step3041]: loss 8.812389
[epoch4, step3042]: loss 17.702616
[epoch4, step3043]: loss 12.068480
[epoch4, step3044]: loss 20.241053
[epoch4, step3045]: loss 17.043798
[epoch4, step3046]: loss 12.257189
[epoch4, step3047]: loss 50.035854
[epoch4, step3048]: loss 1.989588
[epoch4, step3049]: loss 9.317316
[epoch4, step3050]: loss 2.966901
[epoch4, step3051]: loss 32.818550
[epoch4, step3052]: loss 2.395928
[epoch4, step3053]: loss 12.038067
[epoch4, step3054]: loss 3.614004
[epoch4, step3055]: loss 2.566459
[epoch4, step3056]: loss 21.114809
[epoch4, step3057]: loss 5.558088
[epoch4, step3058]: loss 22.541868
[epoch4, step3059]: loss 6.887909
[epoch4, step3060]: loss 2.997109
[epoch4, step3061]: loss 5.253223
[epoch4, step3062]: loss 2.761353
[epoch4, step3063]: loss 46.681030
[epoch4, step3064]: loss 2.464265
[epoch4, step3065]: loss 2.282943
[epoch4, step3066]: loss 6.173215
[epoch4, step3067]: loss 22.876364
[epoch4, step3068]: loss 4.520322
[epoch4, step3069]: loss 6.252919
[epoch4, step3070]: loss 2.301614
[epoch4, step3071]: loss 5.253717
[epoch4, step3072]: loss 4.899452
[epoch4, step3073]: loss 3.717659
[epoch4, step3074]: loss 4.147551
[epoch4, step3075]: loss 2.117767
[epoch4, step3076]: loss 6.716164

[epoch4]: avg loss 6.716164

[epoch5, step1]: loss 4.856718
[epoch5, step2]: loss 9.427942
[epoch5, step3]: loss 15.662223
[epoch5, step4]: loss 12.911175
[epoch5, step5]: loss 5.061895
[epoch5, step6]: loss 7.975394
[epoch5, step7]: loss 8.585613
[epoch5, step8]: loss 2.412723
[epoch5, step9]: loss 2.834603
[epoch5, step10]: loss 9.073291
[epoch5, step11]: loss 6.377762
[epoch5, step12]: loss 23.711000
[epoch5, step13]: loss 4.149310
[epoch5, step14]: loss 5.867434
[epoch5, step15]: loss 3.717888
[epoch5, step16]: loss 4.875833
[epoch5, step17]: loss 21.454556
[epoch5, step18]: loss 2.593708
[epoch5, step19]: loss 3.324092
[epoch5, step20]: loss 13.395327
[epoch5, step21]: loss 1.598658
[epoch5, step22]: loss 3.771249
[epoch5, step23]: loss 5.606338
[epoch5, step24]: loss 4.012871
[epoch5, step25]: loss 4.639492
[epoch5, step26]: loss 5.514916
[epoch5, step27]: loss 3.358976
[epoch5, step28]: loss 33.540771
[epoch5, step29]: loss 4.664374
[epoch5, step30]: loss 2.172906
[epoch5, step31]: loss 11.042858
[epoch5, step32]: loss 3.239288
[epoch5, step33]: loss 2.225343
[epoch5, step34]: loss 15.452006
[epoch5, step35]: loss 3.495195
[epoch5, step36]: loss 4.292057
[epoch5, step37]: loss 14.600503
[epoch5, step38]: loss 4.135173
[epoch5, step39]: loss 22.957481
[epoch5, step40]: loss 4.118014
[epoch5, step41]: loss 13.520338
[epoch5, step42]: loss 2.287487
[epoch5, step43]: loss 50.033970
[epoch5, step44]: loss 2.550658
[epoch5, step45]: loss 3.712441
[epoch5, step46]: loss 1.879193
[epoch5, step47]: loss 2.265817
[epoch5, step48]: loss 16.200747
[epoch5, step49]: loss 4.660617
[epoch5, step50]: loss 2.510921
[epoch5, step51]: loss 3.036675
[epoch5, step52]: loss 3.122245
[epoch5, step53]: loss 3.128583
[epoch5, step54]: loss 26.938538
[epoch5, step55]: loss 5.953156
[epoch5, step56]: loss 5.466437
[epoch5, step57]: loss 26.147976
[epoch5, step58]: loss 21.947376
[epoch5, step59]: loss 22.200544
[epoch5, step60]: loss 4.276653
[epoch5, step61]: loss 9.288304
[epoch5, step62]: loss 25.308123
[epoch5, step63]: loss 4.654127
[epoch5, step64]: loss 2.172879
[epoch5, step65]: loss 12.679098
[epoch5, step66]: loss 2.544083
[epoch5, step67]: loss 5.778221
[epoch5, step68]: loss 5.124588
[epoch5, step69]: loss 2.252975
[epoch5, step70]: loss 2.522298
[epoch5, step71]: loss 7.177748
[epoch5, step72]: loss 20.431393
[epoch5, step73]: loss 29.287504
[epoch5, step74]: loss 11.703930
[epoch5, step75]: loss 18.664867
[epoch5, step76]: loss 1.655515
[epoch5, step77]: loss 21.604532
[epoch5, step78]: loss 43.658520
[epoch5, step79]: loss 4.709545
[epoch5, step80]: loss 3.658621
[epoch5, step81]: loss 2.298454
[epoch5, step82]: loss 9.530331
[epoch5, step83]: loss 6.840487
[epoch5, step84]: loss 4.277846
[epoch5, step85]: loss 5.259938
[epoch5, step86]: loss 3.944299
[epoch5, step87]: loss 3.139385
[epoch5, step88]: loss 8.558007
[epoch5, step89]: loss 4.916921
[epoch5, step90]: loss 23.950500
[epoch5, step91]: loss 2.509980
[epoch5, step92]: loss 23.448414
[epoch5, step93]: loss 11.818547
[epoch5, step94]: loss 1.578563
[epoch5, step95]: loss 8.504912
[epoch5, step96]: loss 9.014678
[epoch5, step97]: loss 24.802607
[epoch5, step98]: loss 23.366676
[epoch5, step99]: loss 26.167236
[epoch5, step100]: loss 5.574870
[epoch5, step101]: loss 13.339495
[epoch5, step102]: loss 6.624398
[epoch5, step103]: loss 6.518630
[epoch5, step104]: loss 2.643956
[epoch5, step105]: loss 13.470603
[epoch5, step106]: loss 6.210810
[epoch5, step107]: loss 3.185145
[epoch5, step108]: loss 30.974804
[epoch5, step109]: loss 17.662926
[epoch5, step110]: loss 21.996216
[epoch5, step111]: loss 6.544985
[epoch5, step112]: loss 35.551037
[epoch5, step113]: loss 2.091302
[epoch5, step114]: loss 5.342071
[epoch5, step115]: loss 1.805942
[epoch5, step116]: loss 2.937052
[epoch5, step117]: loss 4.080445
[epoch5, step118]: loss 5.567063
[epoch5, step119]: loss 15.778217
[epoch5, step120]: loss 53.321159
[epoch5, step121]: loss 18.183056
[epoch5, step122]: loss 5.058473
[epoch5, step123]: loss 2.202146
[epoch5, step124]: loss 18.309849
[epoch5, step125]: loss 5.621624
[epoch5, step126]: loss 2.666077
[epoch5, step127]: loss 2.427993
[epoch5, step128]: loss 4.355633
[epoch5, step129]: loss 5.646945
[epoch5, step130]: loss 4.137205
[epoch5, step131]: loss 2.395242
[epoch5, step132]: loss 3.749043
[epoch5, step133]: loss 13.119655
[epoch5, step134]: loss 5.020730
[epoch5, step135]: loss 7.363894
[epoch5, step136]: loss 8.367583
[epoch5, step137]: loss 22.542208
[epoch5, step138]: loss 2.088116
[epoch5, step139]: loss 2.696637
[epoch5, step140]: loss 7.106384
[epoch5, step141]: loss 11.499366
[epoch5, step142]: loss 5.610081
[epoch5, step143]: loss 15.598583
[epoch5, step144]: loss 49.848942
[epoch5, step145]: loss 4.291682
[epoch5, step146]: loss 2.867416
[epoch5, step147]: loss 32.807491
[epoch5, step148]: loss 22.376282
[epoch5, step149]: loss 31.388897
[epoch5, step150]: loss 20.642673
[epoch5, step151]: loss 2.490571
[epoch5, step152]: loss 5.134514
[epoch5, step153]: loss 4.325133
[epoch5, step154]: loss 5.256691
[epoch5, step155]: loss 6.506174
[epoch5, step156]: loss 14.481106
[epoch5, step157]: loss 23.258450
[epoch5, step158]: loss 2.291900
[epoch5, step159]: loss 2.480301
[epoch5, step160]: loss 33.399139
[epoch5, step161]: loss 2.436544
[epoch5, step162]: loss 1.931490
[epoch5, step163]: loss 5.224139
[epoch5, step164]: loss 3.005161
[epoch5, step165]: loss 21.557579
[epoch5, step166]: loss 6.812030
[epoch5, step167]: loss 7.857234
[epoch5, step168]: loss 8.313695
[epoch5, step169]: loss 10.800556
[epoch5, step170]: loss 42.014252
[epoch5, step171]: loss 3.585050
[epoch5, step172]: loss 7.374379
[epoch5, step173]: loss 5.230373
[epoch5, step174]: loss 21.898191
[epoch5, step175]: loss 4.004986
[epoch5, step176]: loss 2.646920
[epoch5, step177]: loss 2.553200
[epoch5, step178]: loss 49.805241
[epoch5, step179]: loss 3.809233
[epoch5, step180]: loss 3.736290
[epoch5, step181]: loss 12.372017
[epoch5, step182]: loss 2.551935
[epoch5, step183]: loss 6.218792
[epoch5, step184]: loss 10.999590
[epoch5, step185]: loss 5.455331
[epoch5, step186]: loss 5.916101
[epoch5, step187]: loss 20.044970
[epoch5, step188]: loss 6.573634
[epoch5, step189]: loss 4.746538
[epoch5, step190]: loss 2.726045
[epoch5, step191]: loss 2.828332
[epoch5, step192]: loss 4.757171
[epoch5, step193]: loss 3.060694
[epoch5, step194]: loss 5.565258
[epoch5, step195]: loss 7.235451
[epoch5, step196]: loss 3.882351
[epoch5, step197]: loss 2.099347
[epoch5, step198]: loss 32.484585
[epoch5, step199]: loss 5.238815
[epoch5, step200]: loss 23.736389
[epoch5, step201]: loss 16.722599
[epoch5, step202]: loss 14.569597
[epoch5, step203]: loss 19.846441
[epoch5, step204]: loss 2.763138
[epoch5, step205]: loss 26.531992
[epoch5, step206]: loss 5.307534
[epoch5, step207]: loss 4.365885
[epoch5, step208]: loss 14.332794
[epoch5, step209]: loss 2.672186
[epoch5, step210]: loss 27.861622
[epoch5, step211]: loss 4.365679
[epoch5, step212]: loss 2.944286
[epoch5, step213]: loss 5.610245
[epoch5, step214]: loss 3.350466
[epoch5, step215]: loss 2.176327
[epoch5, step216]: loss 23.359726
[epoch5, step217]: loss 30.963764
[epoch5, step218]: loss 7.025521
[epoch5, step219]: loss 3.945885
[epoch5, step220]: loss 17.278790
[epoch5, step221]: loss 1.959462
[epoch5, step222]: loss 20.556772
[epoch5, step223]: loss 3.463012
[epoch5, step224]: loss 4.420528
[epoch5, step225]: loss 19.454792
[epoch5, step226]: loss 5.201068
[epoch5, step227]: loss 22.153408
[epoch5, step228]: loss 6.552764
[epoch5, step229]: loss 3.869976
[epoch5, step230]: loss 12.295292
[epoch5, step231]: loss 5.590882
[epoch5, step232]: loss 2.753460
[epoch5, step233]: loss 9.975021
[epoch5, step234]: loss 3.589178
[epoch5, step235]: loss 19.124815
[epoch5, step236]: loss 27.066864
[epoch5, step237]: loss 1.622261
[epoch5, step238]: loss 2.419988
[epoch5, step239]: loss 21.962540
[epoch5, step240]: loss 5.749803
[epoch5, step241]: loss 5.451105
[epoch5, step242]: loss 2.495800
[epoch5, step243]: loss 4.557042
[epoch5, step244]: loss 2.366198
[epoch5, step245]: loss 4.768673
[epoch5, step246]: loss 13.471636
[epoch5, step247]: loss 33.361187
[epoch5, step248]: loss 1.949198
[epoch5, step249]: loss 20.913597
[epoch5, step250]: loss 4.734334
[epoch5, step251]: loss 26.463032
[epoch5, step252]: loss 3.032361
[epoch5, step253]: loss 23.850117
[epoch5, step254]: loss 2.667591
[epoch5, step255]: loss 3.140604
[epoch5, step256]: loss 3.966629
[epoch5, step257]: loss 2.401198
[epoch5, step258]: loss 27.217413
[epoch5, step259]: loss 4.799439
[epoch5, step260]: loss 2.200148
[epoch5, step261]: loss 15.526268
[epoch5, step262]: loss 3.155668
[epoch5, step263]: loss 3.780200
[epoch5, step264]: loss 24.004782
[epoch5, step265]: loss 1.594633
[epoch5, step266]: loss 4.396623
[epoch5, step267]: loss 21.148516
[epoch5, step268]: loss 3.575724
[epoch5, step269]: loss 4.274960
[epoch5, step270]: loss 23.509872
[epoch5, step271]: loss 5.315249
[epoch5, step272]: loss 8.188834
[epoch5, step273]: loss 4.351152
[epoch5, step274]: loss 15.315514
[epoch5, step275]: loss 9.572888
[epoch5, step276]: loss 3.268256
[epoch5, step277]: loss 22.610830
[epoch5, step278]: loss 14.998943
[epoch5, step279]: loss 2.266744
[epoch5, step280]: loss 3.070057
[epoch5, step281]: loss 2.939777
[epoch5, step282]: loss 11.750412
[epoch5, step283]: loss 6.692190
[epoch5, step284]: loss 10.676289
[epoch5, step285]: loss 1.954600
[epoch5, step286]: loss 31.591833
[epoch5, step287]: loss 3.638178
[epoch5, step288]: loss 3.403127
[epoch5, step289]: loss 5.168854
[epoch5, step290]: loss 3.827478
[epoch5, step291]: loss 17.374851
[epoch5, step292]: loss 4.945560
[epoch5, step293]: loss 8.541096
[epoch5, step294]: loss 5.958598
[epoch5, step295]: loss 22.479195
[epoch5, step296]: loss 18.686522
[epoch5, step297]: loss 36.525791
[epoch5, step298]: loss 25.628115
[epoch5, step299]: loss 3.605456
[epoch5, step300]: loss 3.003588
[epoch5, step301]: loss 36.589752
[epoch5, step302]: loss 17.537117
[epoch5, step303]: loss 3.043915
[epoch5, step304]: loss 23.330429
[epoch5, step305]: loss 5.304749
[epoch5, step306]: loss 15.440694
[epoch5, step307]: loss 7.171432
[epoch5, step308]: loss 25.103775
[epoch5, step309]: loss 8.480109
[epoch5, step310]: loss 3.646984
[epoch5, step311]: loss 23.796057
[epoch5, step312]: loss 13.808027
[epoch5, step313]: loss 31.198822
[epoch5, step314]: loss 3.369044
[epoch5, step315]: loss 21.877760
[epoch5, step316]: loss 5.752690
[epoch5, step317]: loss 13.664625
[epoch5, step318]: loss 17.627342
[epoch5, step319]: loss 19.321970
[epoch5, step320]: loss 5.791066
[epoch5, step321]: loss 22.687912
[epoch5, step322]: loss 1.780373
[epoch5, step323]: loss 33.122608
[epoch5, step324]: loss 2.458719
[epoch5, step325]: loss 40.151215
[epoch5, step326]: loss 2.796742
[epoch5, step327]: loss 5.318754
[epoch5, step328]: loss 19.570875
[epoch5, step329]: loss 7.977778
[epoch5, step330]: loss 6.397102
[epoch5, step331]: loss 4.247525
[epoch5, step332]: loss 3.020320
[epoch5, step333]: loss 5.489090
[epoch5, step334]: loss 21.695194
[epoch5, step335]: loss 11.958424
[epoch5, step336]: loss 2.068539
[epoch5, step337]: loss 4.339491
[epoch5, step338]: loss 35.781429
[epoch5, step339]: loss 10.559506
[epoch5, step340]: loss 1.918836
[epoch5, step341]: loss 3.004097
[epoch5, step342]: loss 23.312132
[epoch5, step343]: loss 10.892447
[epoch5, step344]: loss 4.588475
[epoch5, step345]: loss 11.280323
[epoch5, step346]: loss 33.873646
[epoch5, step347]: loss 5.134471
[epoch5, step348]: loss 3.375992
[epoch5, step349]: loss 22.357706
[epoch5, step350]: loss 10.149016
[epoch5, step351]: loss 2.277333
[epoch5, step352]: loss 3.550155
[epoch5, step353]: loss 15.090095
[epoch5, step354]: loss 2.168442
[epoch5, step355]: loss 20.230534
[epoch5, step356]: loss 2.844517
[epoch5, step357]: loss 2.530260
[epoch5, step358]: loss 9.332991
[epoch5, step359]: loss 6.573168
[epoch5, step360]: loss 6.554120
[epoch5, step361]: loss 5.844271
[epoch5, step362]: loss 2.244393
[epoch5, step363]: loss 39.673218
[epoch5, step364]: loss 3.975699
[epoch5, step365]: loss 28.075869
[epoch5, step366]: loss 2.413025
[epoch5, step367]: loss 9.408810
[epoch5, step368]: loss 3.683130
[epoch5, step369]: loss 10.831698
[epoch5, step370]: loss 17.526184
[epoch5, step371]: loss 3.784091
[epoch5, step372]: loss 5.575833
[epoch5, step373]: loss 6.695448
[epoch5, step374]: loss 2.402558
[epoch5, step375]: loss 5.846733
[epoch5, step376]: loss 1.872898
[epoch5, step377]: loss 2.212125
[epoch5, step378]: loss 24.789705
[epoch5, step379]: loss 21.362747
[epoch5, step380]: loss 16.681866
[epoch5, step381]: loss 2.280004
[epoch5, step382]: loss 5.277040
[epoch5, step383]: loss 8.845984
[epoch5, step384]: loss 7.830520
[epoch5, step385]: loss 22.661152
[epoch5, step386]: loss 6.762924
[epoch5, step387]: loss 23.775196
[epoch5, step388]: loss 5.162429
[epoch5, step389]: loss 12.301320
[epoch5, step390]: loss 5.180648
[epoch5, step391]: loss 3.021132
[epoch5, step392]: loss 26.955610
[epoch5, step393]: loss 12.985605
[epoch5, step394]: loss 23.176195
[epoch5, step395]: loss 14.650833
[epoch5, step396]: loss 2.365755
[epoch5, step397]: loss 7.432123
[epoch5, step398]: loss 24.069023
[epoch5, step399]: loss 22.679497
[epoch5, step400]: loss 21.818600
[epoch5, step401]: loss 26.638056
[epoch5, step402]: loss 4.913836
[epoch5, step403]: loss 6.189721
[epoch5, step404]: loss 3.456869
[epoch5, step405]: loss 2.386988
[epoch5, step406]: loss 8.886110
[epoch5, step407]: loss 2.144527
[epoch5, step408]: loss 2.585150
[epoch5, step409]: loss 3.319537
[epoch5, step410]: loss 41.321289
[epoch5, step411]: loss 3.781946
[epoch5, step412]: loss 12.082636
[epoch5, step413]: loss 12.276147
[epoch5, step414]: loss 3.111156
[epoch5, step415]: loss 1.452511
[epoch5, step416]: loss 22.630718
[epoch5, step417]: loss 46.390697
[epoch5, step418]: loss 3.703290
[epoch5, step419]: loss 3.358382
[epoch5, step420]: loss 3.586342
[epoch5, step421]: loss 4.406553
[epoch5, step422]: loss 3.852902
[epoch5, step423]: loss 7.117087
[epoch5, step424]: loss 11.708268
[epoch5, step425]: loss 8.472245
[epoch5, step426]: loss 19.145670
[epoch5, step427]: loss 5.085423
[epoch5, step428]: loss 3.846581
[epoch5, step429]: loss 12.126730
[epoch5, step430]: loss 6.767738
[epoch5, step431]: loss 25.724512
[epoch5, step432]: loss 2.759171
[epoch5, step433]: loss 1.893411
[epoch5, step434]: loss 41.865509
[epoch5, step435]: loss 5.334680
[epoch5, step436]: loss 4.447918
[epoch5, step437]: loss 16.889660
[epoch5, step438]: loss 4.377615
[epoch5, step439]: loss 3.843217
[epoch5, step440]: loss 2.485096
[epoch5, step441]: loss 13.105526
[epoch5, step442]: loss 24.380056
[epoch5, step443]: loss 21.307438
[epoch5, step444]: loss 2.549775
[epoch5, step445]: loss 2.260412
[epoch5, step446]: loss 10.685745
[epoch5, step447]: loss 13.923614
[epoch5, step448]: loss 6.591980
[epoch5, step449]: loss 4.547069
[epoch5, step450]: loss 6.728967
[epoch5, step451]: loss 13.735970
[epoch5, step452]: loss 2.681463
[epoch5, step453]: loss 4.707100
[epoch5, step454]: loss 4.614138
[epoch5, step455]: loss 3.499733
[epoch5, step456]: loss 10.568908
[epoch5, step457]: loss 13.909464
[epoch5, step458]: loss 2.388624
[epoch5, step459]: loss 2.621447
[epoch5, step460]: loss 39.558365
[epoch5, step461]: loss 38.231304
[epoch5, step462]: loss 18.169083
[epoch5, step463]: loss 4.416975
[epoch5, step464]: loss 12.644672
[epoch5, step465]: loss 3.022763
[epoch5, step466]: loss 29.252497
[epoch5, step467]: loss 4.552256
[epoch5, step468]: loss 4.924392
[epoch5, step469]: loss 5.651853
[epoch5, step470]: loss 40.317112
[epoch5, step471]: loss 2.457710
[epoch5, step472]: loss 5.953521
[epoch5, step473]: loss 3.769504
[epoch5, step474]: loss 3.903857
[epoch5, step475]: loss 15.549816
[epoch5, step476]: loss 7.288593
[epoch5, step477]: loss 10.616201
[epoch5, step478]: loss 13.931862
[epoch5, step479]: loss 6.313088
[epoch5, step480]: loss 25.021475
[epoch5, step481]: loss 2.986973
[epoch5, step482]: loss 15.627588
[epoch5, step483]: loss 3.347940
[epoch5, step484]: loss 24.748646
[epoch5, step485]: loss 20.620640
[epoch5, step486]: loss 20.009214
[epoch5, step487]: loss 21.811012
[epoch5, step488]: loss 4.115096
[epoch5, step489]: loss 3.368589
[epoch5, step490]: loss 4.432050
[epoch5, step491]: loss 3.402762
[epoch5, step492]: loss 18.729342
[epoch5, step493]: loss 24.454987
[epoch5, step494]: loss 9.149683
[epoch5, step495]: loss 15.999545
[epoch5, step496]: loss 28.762527
[epoch5, step497]: loss 28.421524
[epoch5, step498]: loss 3.405421
[epoch5, step499]: loss 2.961060
[epoch5, step500]: loss 15.878162
[epoch5, step501]: loss 3.676876
[epoch5, step502]: loss 16.436428
[epoch5, step503]: loss 12.588783
[epoch5, step504]: loss 17.857904
[epoch5, step505]: loss 2.388598
[epoch5, step506]: loss 12.304298
[epoch5, step507]: loss 3.409438
[epoch5, step508]: loss 4.873487
[epoch5, step509]: loss 43.443657
[epoch5, step510]: loss 3.410413
[epoch5, step511]: loss 3.110040
[epoch5, step512]: loss 21.052671
[epoch5, step513]: loss 12.924356
[epoch5, step514]: loss 5.356624
[epoch5, step515]: loss 15.186087
[epoch5, step516]: loss 5.361027
[epoch5, step517]: loss 11.660605
[epoch5, step518]: loss 33.598396
[epoch5, step519]: loss 6.004821
[epoch5, step520]: loss 8.159470
[epoch5, step521]: loss 11.694856
[epoch5, step522]: loss 3.806915
[epoch5, step523]: loss 2.728472
[epoch5, step524]: loss 3.419535
[epoch5, step525]: loss 4.205047
[epoch5, step526]: loss 2.061306
[epoch5, step527]: loss 3.279709
[epoch5, step528]: loss 4.562247
[epoch5, step529]: loss 7.835918
[epoch5, step530]: loss 2.841488
[epoch5, step531]: loss 4.503779
[epoch5, step532]: loss 2.838345
[epoch5, step533]: loss 19.675661
[epoch5, step534]: loss 7.010155
[epoch5, step535]: loss 7.966044
[epoch5, step536]: loss 9.151655
[epoch5, step537]: loss 25.948265
[epoch5, step538]: loss 4.375812
[epoch5, step539]: loss 3.944993
[epoch5, step540]: loss 7.607630
[epoch5, step541]: loss 5.953180
[epoch5, step542]: loss 19.043436
[epoch5, step543]: loss 20.080935
[epoch5, step544]: loss 4.698187
[epoch5, step545]: loss 5.443967
[epoch5, step546]: loss 16.354750
[epoch5, step547]: loss 21.875380
[epoch5, step548]: loss 2.442796
[epoch5, step549]: loss 21.574429
[epoch5, step550]: loss 17.774542
[epoch5, step551]: loss 13.915738
[epoch5, step552]: loss 4.797700
[epoch5, step553]: loss 2.675642
[epoch5, step554]: loss 3.749957
[epoch5, step555]: loss 39.129818
[epoch5, step556]: loss 3.173482
[epoch5, step557]: loss 12.162699
[epoch5, step558]: loss 20.889711
[epoch5, step559]: loss 2.132536
[epoch5, step560]: loss 4.428478
[epoch5, step561]: loss 34.276161
[epoch5, step562]: loss 5.617452
[epoch5, step563]: loss 7.551196
[epoch5, step564]: loss 27.596563
[epoch5, step565]: loss 15.973851
[epoch5, step566]: loss 6.034397
[epoch5, step567]: loss 13.850728
[epoch5, step568]: loss 2.376582
[epoch5, step569]: loss 15.462290
[epoch5, step570]: loss 22.561424
[epoch5, step571]: loss 15.056858
[epoch5, step572]: loss 2.840347
[epoch5, step573]: loss 4.929904
[epoch5, step574]: loss 4.923183
[epoch5, step575]: loss 2.767415
[epoch5, step576]: loss 5.239438
[epoch5, step577]: loss 28.691908
[epoch5, step578]: loss 19.544128
[epoch5, step579]: loss 4.705398
[epoch5, step580]: loss 30.063837
[epoch5, step581]: loss 15.853263
[epoch5, step582]: loss 23.680080
[epoch5, step583]: loss 21.910769
[epoch5, step584]: loss 5.201011
[epoch5, step585]: loss 7.988455
[epoch5, step586]: loss 6.776134
[epoch5, step587]: loss 21.578356
[epoch5, step588]: loss 12.496076
[epoch5, step589]: loss 4.817450
[epoch5, step590]: loss 3.846007
[epoch5, step591]: loss 5.686160
[epoch5, step592]: loss 2.918083
[epoch5, step593]: loss 22.756916
[epoch5, step594]: loss 5.567860
[epoch5, step595]: loss 2.734444
[epoch5, step596]: loss 7.803437
[epoch5, step597]: loss 3.929123
[epoch5, step598]: loss 5.016588
[epoch5, step599]: loss 9.935211
[epoch5, step600]: loss 11.171645
[epoch5, step601]: loss 1.995217
[epoch5, step602]: loss 13.602969
[epoch5, step603]: loss 2.475796
[epoch5, step604]: loss 8.776869
[epoch5, step605]: loss 46.676582
[epoch5, step606]: loss 49.503296
[epoch5, step607]: loss 9.037393
[epoch5, step608]: loss 3.221811
[epoch5, step609]: loss 25.644661
[epoch5, step610]: loss 12.274430
[epoch5, step611]: loss 16.587900
[epoch5, step612]: loss 4.162990
[epoch5, step613]: loss 12.167487
[epoch5, step614]: loss 3.465841
[epoch5, step615]: loss 4.257621
[epoch5, step616]: loss 2.639376
[epoch5, step617]: loss 4.816452
[epoch5, step618]: loss 1.845572
[epoch5, step619]: loss 19.579643
[epoch5, step620]: loss 1.929227
[epoch5, step621]: loss 20.640539
[epoch5, step622]: loss 2.181492
[epoch5, step623]: loss 5.598491
[epoch5, step624]: loss 4.426264
[epoch5, step625]: loss 4.392099
[epoch5, step626]: loss 10.319571
[epoch5, step627]: loss 17.793495
[epoch5, step628]: loss 2.309560
[epoch5, step629]: loss 2.780558
[epoch5, step630]: loss 6.409954
[epoch5, step631]: loss 4.402642
[epoch5, step632]: loss 12.166980
[epoch5, step633]: loss 24.032377
[epoch5, step634]: loss 22.104137
[epoch5, step635]: loss 11.749887
[epoch5, step636]: loss 3.751741
[epoch5, step637]: loss 7.216487
[epoch5, step638]: loss 2.826958
[epoch5, step639]: loss 3.347051
[epoch5, step640]: loss 22.102583
[epoch5, step641]: loss 53.522575
[epoch5, step642]: loss 2.909606
[epoch5, step643]: loss 7.871418
[epoch5, step644]: loss 22.803680
[epoch5, step645]: loss 10.259887
[epoch5, step646]: loss 2.616633
[epoch5, step647]: loss 3.231181
[epoch5, step648]: loss 5.361845
[epoch5, step649]: loss 5.461952
[epoch5, step650]: loss 2.144724
[epoch5, step651]: loss 16.391232
[epoch5, step652]: loss 20.252398
[epoch5, step653]: loss 3.723796
[epoch5, step654]: loss 4.868664
[epoch5, step655]: loss 7.802527
[epoch5, step656]: loss 14.012601
[epoch5, step657]: loss 1.992187
[epoch5, step658]: loss 12.280219
[epoch5, step659]: loss 21.181078
[epoch5, step660]: loss 6.150916
[epoch5, step661]: loss 8.067016
[epoch5, step662]: loss 14.983062
[epoch5, step663]: loss 2.465537
[epoch5, step664]: loss 8.748864
[epoch5, step665]: loss 2.206210
[epoch5, step666]: loss 24.835026
[epoch5, step667]: loss 3.607141
[epoch5, step668]: loss 27.751404
[epoch5, step669]: loss 4.924447
[epoch5, step670]: loss 13.376615
[epoch5, step671]: loss 11.212228
[epoch5, step672]: loss 4.300571
[epoch5, step673]: loss 6.485146
[epoch5, step674]: loss 33.192596
[epoch5, step675]: loss 2.195867
[epoch5, step676]: loss 2.104766
[epoch5, step677]: loss 3.583246
[epoch5, step678]: loss 20.438913
[epoch5, step679]: loss 5.963120
[epoch5, step680]: loss 4.425026
[epoch5, step681]: loss 24.730618
[epoch5, step682]: loss 2.537612
[epoch5, step683]: loss 6.099469
[epoch5, step684]: loss 2.439572
[epoch5, step685]: loss 2.405400
[epoch5, step686]: loss 8.418859
[epoch5, step687]: loss 5.040527
[epoch5, step688]: loss 4.259621
[epoch5, step689]: loss 5.360066
[epoch5, step690]: loss 6.852071
[epoch5, step691]: loss 24.570927
[epoch5, step692]: loss 6.463273
[epoch5, step693]: loss 13.362375
[epoch5, step694]: loss 3.787524
[epoch5, step695]: loss 45.336479
[epoch5, step696]: loss 8.649329
[epoch5, step697]: loss 13.833158
[epoch5, step698]: loss 5.370540
[epoch5, step699]: loss 21.518852
[epoch5, step700]: loss 19.670889
[epoch5, step701]: loss 13.968611
[epoch5, step702]: loss 3.140712
[epoch5, step703]: loss 22.159115
[epoch5, step704]: loss 2.790924
[epoch5, step705]: loss 18.701296
[epoch5, step706]: loss 19.255421
[epoch5, step707]: loss 10.268349
[epoch5, step708]: loss 1.583642
[epoch5, step709]: loss 4.875526
[epoch5, step710]: loss 27.177135
[epoch5, step711]: loss 6.779847
[epoch5, step712]: loss 2.203889
[epoch5, step713]: loss 2.490589
[epoch5, step714]: loss 4.186392
[epoch5, step715]: loss 2.906447
[epoch5, step716]: loss 20.461523
[epoch5, step717]: loss 4.786818
[epoch5, step718]: loss 3.713861
[epoch5, step719]: loss 26.260349
[epoch5, step720]: loss 25.625969
[epoch5, step721]: loss 28.498516
[epoch5, step722]: loss 21.083433
[epoch5, step723]: loss 2.937177
[epoch5, step724]: loss 3.642731
[epoch5, step725]: loss 13.403348
[epoch5, step726]: loss 3.520976
[epoch5, step727]: loss 2.502144
[epoch5, step728]: loss 6.202670
[epoch5, step729]: loss 5.406292
[epoch5, step730]: loss 4.758467
[epoch5, step731]: loss 24.782888
[epoch5, step732]: loss 2.558916
[epoch5, step733]: loss 3.482844
[epoch5, step734]: loss 3.926350
[epoch5, step735]: loss 13.211424
[epoch5, step736]: loss 3.287192
[epoch5, step737]: loss 4.016838
[epoch5, step738]: loss 3.006216
[epoch5, step739]: loss 2.936043
[epoch5, step740]: loss 6.769610
[epoch5, step741]: loss 19.835970
[epoch5, step742]: loss 8.134465
[epoch5, step743]: loss 3.614827
[epoch5, step744]: loss 6.290731
[epoch5, step745]: loss 8.719430
[epoch5, step746]: loss 11.354332
[epoch5, step747]: loss 15.460125
[epoch5, step748]: loss 11.277985
[epoch5, step749]: loss 6.628460
[epoch5, step750]: loss 35.496502
[epoch5, step751]: loss 3.444525
[epoch5, step752]: loss 3.097888
[epoch5, step753]: loss 4.560213
[epoch5, step754]: loss 1.990476
[epoch5, step755]: loss 4.154470
[epoch5, step756]: loss 3.738569
[epoch5, step757]: loss 2.765098
[epoch5, step758]: loss 4.206015
[epoch5, step759]: loss 9.102645
[epoch5, step760]: loss 5.405881
[epoch5, step761]: loss 2.686569
[epoch5, step762]: loss 10.753857
[epoch5, step763]: loss 3.119347
[epoch5, step764]: loss 2.256013
[epoch5, step765]: loss 3.229352
[epoch5, step766]: loss 22.149220
[epoch5, step767]: loss 3.836869
[epoch5, step768]: loss 3.678910
[epoch5, step769]: loss 2.482968
[epoch5, step770]: loss 11.990122
[epoch5, step771]: loss 3.518178
[epoch5, step772]: loss 6.091250
[epoch5, step773]: loss 1.781816
[epoch5, step774]: loss 3.757688
[epoch5, step775]: loss 2.046198
[epoch5, step776]: loss 11.334824
[epoch5, step777]: loss 26.055023
[epoch5, step778]: loss 2.662589
[epoch5, step779]: loss 25.070971
[epoch5, step780]: loss 5.416241
[epoch5, step781]: loss 14.302564
[epoch5, step782]: loss 4.493853
[epoch5, step783]: loss 2.759611
[epoch5, step784]: loss 2.896423
[epoch5, step785]: loss 3.207153
[epoch5, step786]: loss 2.588654
[epoch5, step787]: loss 3.254805
[epoch5, step788]: loss 34.093029
[epoch5, step789]: loss 2.346978
[epoch5, step790]: loss 3.996654
[epoch5, step791]: loss 3.982128
[epoch5, step792]: loss 5.908700
[epoch5, step793]: loss 6.310503
[epoch5, step794]: loss 21.267086
[epoch5, step795]: loss 9.196980
[epoch5, step796]: loss 6.731308
[epoch5, step797]: loss 34.913628
[epoch5, step798]: loss 22.700726
[epoch5, step799]: loss 3.023669
[epoch5, step800]: loss 1.621813
[epoch5, step801]: loss 13.082091
[epoch5, step802]: loss 32.154076
[epoch5, step803]: loss 22.911131
[epoch5, step804]: loss 2.603204
[epoch5, step805]: loss 19.965328
[epoch5, step806]: loss 6.604304
[epoch5, step807]: loss 12.651100
[epoch5, step808]: loss 24.181900
[epoch5, step809]: loss 4.179440
[epoch5, step810]: loss 45.283012
[epoch5, step811]: loss 2.782567
[epoch5, step812]: loss 2.461035
[epoch5, step813]: loss 2.382132
[epoch5, step814]: loss 13.906143
[epoch5, step815]: loss 1.791045
[epoch5, step816]: loss 6.909329
[epoch5, step817]: loss 3.769004
[epoch5, step818]: loss 9.849319
[epoch5, step819]: loss 3.406307
[epoch5, step820]: loss 9.454555
[epoch5, step821]: loss 4.106841
[epoch5, step822]: loss 46.195641
[epoch5, step823]: loss 2.929395
[epoch5, step824]: loss 4.898801
[epoch5, step825]: loss 5.048812
[epoch5, step826]: loss 2.037448
[epoch5, step827]: loss 5.597972
[epoch5, step828]: loss 10.221494
[epoch5, step829]: loss 5.191695
[epoch5, step830]: loss 7.673787
[epoch5, step831]: loss 12.588636
[epoch5, step832]: loss 10.246453
[epoch5, step833]: loss 2.718712
[epoch5, step834]: loss 4.050711
[epoch5, step835]: loss 3.042972
[epoch5, step836]: loss 3.428040
[epoch5, step837]: loss 9.939857
[epoch5, step838]: loss 4.188183
[epoch5, step839]: loss 3.478760
[epoch5, step840]: loss 2.496984
[epoch5, step841]: loss 2.760141
[epoch5, step842]: loss 16.537420
[epoch5, step843]: loss 2.871759
[epoch5, step844]: loss 19.369034
[epoch5, step845]: loss 2.681381
[epoch5, step846]: loss 10.504961
[epoch5, step847]: loss 23.325243
[epoch5, step848]: loss 2.690117
[epoch5, step849]: loss 6.665839
[epoch5, step850]: loss 4.261750
[epoch5, step851]: loss 7.278306
[epoch5, step852]: loss 28.613947
[epoch5, step853]: loss 2.189094
[epoch5, step854]: loss 3.149881
[epoch5, step855]: loss 2.731962
[epoch5, step856]: loss 2.370877
[epoch5, step857]: loss 21.450188
[epoch5, step858]: loss 14.884204
[epoch5, step859]: loss 10.616530
[epoch5, step860]: loss 3.162116
[epoch5, step861]: loss 22.022793
[epoch5, step862]: loss 10.595345
[epoch5, step863]: loss 29.093277
[epoch5, step864]: loss 3.684388
[epoch5, step865]: loss 26.022472
[epoch5, step866]: loss 3.497898
[epoch5, step867]: loss 2.124651
[epoch5, step868]: loss 19.817745
[epoch5, step869]: loss 8.317389
[epoch5, step870]: loss 2.268744
[epoch5, step871]: loss 9.737540
[epoch5, step872]: loss 19.836828
[epoch5, step873]: loss 6.032196
[epoch5, step874]: loss 3.671625
[epoch5, step875]: loss 7.047319
[epoch5, step876]: loss 6.436963
[epoch5, step877]: loss 4.925885
[epoch5, step878]: loss 11.221848
[epoch5, step879]: loss 35.511703
[epoch5, step880]: loss 18.990877
[epoch5, step881]: loss 26.135464
[epoch5, step882]: loss 7.898610
[epoch5, step883]: loss 2.962536
[epoch5, step884]: loss 3.253165
[epoch5, step885]: loss 4.934374
[epoch5, step886]: loss 2.260439
[epoch5, step887]: loss 2.168027
[epoch5, step888]: loss 12.465939
[epoch5, step889]: loss 3.532341
[epoch5, step890]: loss 2.322285
[epoch5, step891]: loss 4.224124
[epoch5, step892]: loss 19.836838
[epoch5, step893]: loss 2.974604
[epoch5, step894]: loss 24.553871
[epoch5, step895]: loss 2.654827
[epoch5, step896]: loss 10.567349
[epoch5, step897]: loss 10.305701
[epoch5, step898]: loss 1.582458
[epoch5, step899]: loss 23.134180
[epoch5, step900]: loss 2.173975
[epoch5, step901]: loss 21.715693
[epoch5, step902]: loss 6.322025
[epoch5, step903]: loss 2.230947
[epoch5, step904]: loss 10.007370
[epoch5, step905]: loss 1.822750
[epoch5, step906]: loss 4.424895
[epoch5, step907]: loss 22.720798
[epoch5, step908]: loss 7.138432
[epoch5, step909]: loss 2.516151
[epoch5, step910]: loss 3.745919
[epoch5, step911]: loss 64.658516
[epoch5, step912]: loss 10.972614
[epoch5, step913]: loss 4.812080
[epoch5, step914]: loss 2.328040
[epoch5, step915]: loss 3.242781
[epoch5, step916]: loss 18.479410
[epoch5, step917]: loss 17.472733
[epoch5, step918]: loss 3.170577
[epoch5, step919]: loss 4.637458
[epoch5, step920]: loss 14.340730
[epoch5, step921]: loss 22.995945
[epoch5, step922]: loss 2.408661
[epoch5, step923]: loss 4.313345
[epoch5, step924]: loss 3.424838
[epoch5, step925]: loss 9.266389
[epoch5, step926]: loss 3.028996
[epoch5, step927]: loss 51.095993
[epoch5, step928]: loss 12.014554
[epoch5, step929]: loss 3.444541
[epoch5, step930]: loss 26.644051
[epoch5, step931]: loss 6.132976
[epoch5, step932]: loss 43.315044
[epoch5, step933]: loss 6.240307
[epoch5, step934]: loss 3.778368
[epoch5, step935]: loss 2.371721
[epoch5, step936]: loss 6.914539
[epoch5, step937]: loss 3.396710
[epoch5, step938]: loss 6.004920
[epoch5, step939]: loss 5.696311
[epoch5, step940]: loss 1.560167
[epoch5, step941]: loss 3.042436
[epoch5, step942]: loss 12.900392
[epoch5, step943]: loss 3.633711
[epoch5, step944]: loss 3.383222
[epoch5, step945]: loss 21.137129
[epoch5, step946]: loss 5.985571
[epoch5, step947]: loss 2.360609
[epoch5, step948]: loss 5.709356
[epoch5, step949]: loss 2.317227
[epoch5, step950]: loss 4.852128
[epoch5, step951]: loss 6.055418
[epoch5, step952]: loss 11.092429
[epoch5, step953]: loss 3.971945
[epoch5, step954]: loss 35.291653
[epoch5, step955]: loss 2.967013
[epoch5, step956]: loss 3.391954
[epoch5, step957]: loss 5.452240
[epoch5, step958]: loss 20.385244
[epoch5, step959]: loss 3.814997
[epoch5, step960]: loss 3.883260
[epoch5, step961]: loss 4.058953
[epoch5, step962]: loss 2.476862
[epoch5, step963]: loss 7.342594
[epoch5, step964]: loss 4.277446
[epoch5, step965]: loss 6.015306
[epoch5, step966]: loss 3.839006
[epoch5, step967]: loss 42.224445
[epoch5, step968]: loss 3.376433
[epoch5, step969]: loss 4.696129
[epoch5, step970]: loss 2.104156
[epoch5, step971]: loss 4.287379
[epoch5, step972]: loss 11.100654
[epoch5, step973]: loss 21.166857
[epoch5, step974]: loss 7.034948
[epoch5, step975]: loss 11.941054
[epoch5, step976]: loss 2.572072
[epoch5, step977]: loss 58.905609
[epoch5, step978]: loss 4.943142
[epoch5, step979]: loss 4.352645
[epoch5, step980]: loss 15.416005
[epoch5, step981]: loss 2.147696
[epoch5, step982]: loss 29.195900
[epoch5, step983]: loss 4.056272
[epoch5, step984]: loss 7.542611
[epoch5, step985]: loss 3.517334
[epoch5, step986]: loss 9.958352
[epoch5, step987]: loss 2.858862
[epoch5, step988]: loss 4.948898
[epoch5, step989]: loss 2.813039
[epoch5, step990]: loss 9.186211
[epoch5, step991]: loss 29.815550
[epoch5, step992]: loss 16.802120
[epoch5, step993]: loss 3.803576
[epoch5, step994]: loss 9.994493
[epoch5, step995]: loss 3.986812
[epoch5, step996]: loss 2.570242
[epoch5, step997]: loss 13.115459
[epoch5, step998]: loss 7.394689
[epoch5, step999]: loss 3.954477
[epoch5, step1000]: loss 9.697470
[epoch5, step1001]: loss 18.119642
[epoch5, step1002]: loss 55.352295
[epoch5, step1003]: loss 3.780922
[epoch5, step1004]: loss 4.224604
[epoch5, step1005]: loss 4.377644
[epoch5, step1006]: loss 20.672932
[epoch5, step1007]: loss 3.087337
[epoch5, step1008]: loss 6.943165
[epoch5, step1009]: loss 3.622157
[epoch5, step1010]: loss 3.963125
[epoch5, step1011]: loss 6.329741
[epoch5, step1012]: loss 5.195635
[epoch5, step1013]: loss 8.760964
[epoch5, step1014]: loss 3.133455
[epoch5, step1015]: loss 4.384601
[epoch5, step1016]: loss 15.798569
[epoch5, step1017]: loss 5.368379
[epoch5, step1018]: loss 7.692287
[epoch5, step1019]: loss 8.433401
[epoch5, step1020]: loss 2.946276
[epoch5, step1021]: loss 4.872731
[epoch5, step1022]: loss 5.741657
[epoch5, step1023]: loss 2.520954
[epoch5, step1024]: loss 56.077393
[epoch5, step1025]: loss 17.689766
[epoch5, step1026]: loss 10.993296
[epoch5, step1027]: loss 6.238162
[epoch5, step1028]: loss 5.640915
[epoch5, step1029]: loss 6.357642
[epoch5, step1030]: loss 21.824575
[epoch5, step1031]: loss 59.104134
[epoch5, step1032]: loss 2.464926
[epoch5, step1033]: loss 11.946809
[epoch5, step1034]: loss 3.198549
[epoch5, step1035]: loss 2.072402
[epoch5, step1036]: loss 12.529342
[epoch5, step1037]: loss 2.804966
[epoch5, step1038]: loss 3.594496
[epoch5, step1039]: loss 7.213628
[epoch5, step1040]: loss 7.599041
[epoch5, step1041]: loss 5.624321
[epoch5, step1042]: loss 3.457305
[epoch5, step1043]: loss 4.048701
[epoch5, step1044]: loss 1.419977
[epoch5, step1045]: loss 2.435554
[epoch5, step1046]: loss 4.865870
[epoch5, step1047]: loss 3.170788
[epoch5, step1048]: loss 3.707923
[epoch5, step1049]: loss 8.584634
[epoch5, step1050]: loss 3.095272
[epoch5, step1051]: loss 22.318613
[epoch5, step1052]: loss 4.096839
[epoch5, step1053]: loss 4.093121
[epoch5, step1054]: loss 19.664673
[epoch5, step1055]: loss 5.613561
[epoch5, step1056]: loss 26.394432
[epoch5, step1057]: loss 8.754543
[epoch5, step1058]: loss 6.027548
[epoch5, step1059]: loss 22.010880
[epoch5, step1060]: loss 2.614428
[epoch5, step1061]: loss 5.603893
[epoch5, step1062]: loss 3.234167
[epoch5, step1063]: loss 15.017277
[epoch5, step1064]: loss 10.577123
[epoch5, step1065]: loss 4.209826
[epoch5, step1066]: loss 8.008653
[epoch5, step1067]: loss 29.262234
[epoch5, step1068]: loss 7.538260
[epoch5, step1069]: loss 23.231937
[epoch5, step1070]: loss 1.679085
[epoch5, step1071]: loss 4.194284
[epoch5, step1072]: loss 5.097171
[epoch5, step1073]: loss 7.081642
[epoch5, step1074]: loss 2.091902
[epoch5, step1075]: loss 15.976063
[epoch5, step1076]: loss 4.703338
[epoch5, step1077]: loss 2.645703
[epoch5, step1078]: loss 2.519327
[epoch5, step1079]: loss 32.367916
[epoch5, step1080]: loss 9.513156
[epoch5, step1081]: loss 19.151823
[epoch5, step1082]: loss 10.999068
[epoch5, step1083]: loss 4.337776
[epoch5, step1084]: loss 19.280113
[epoch5, step1085]: loss 4.232821
[epoch5, step1086]: loss 2.919176
[epoch5, step1087]: loss 3.503507
[epoch5, step1088]: loss 3.569855
[epoch5, step1089]: loss 7.449249
[epoch5, step1090]: loss 18.598602
[epoch5, step1091]: loss 5.464920
[epoch5, step1092]: loss 35.128685
[epoch5, step1093]: loss 2.179974
[epoch5, step1094]: loss 15.328289
[epoch5, step1095]: loss 3.510333
[epoch5, step1096]: loss 2.257747
[epoch5, step1097]: loss 17.655495
[epoch5, step1098]: loss 6.694700
[epoch5, step1099]: loss 2.286350
[epoch5, step1100]: loss 3.774417
[epoch5, step1101]: loss 6.216859
[epoch5, step1102]: loss 12.654037
[epoch5, step1103]: loss 5.435989
[epoch5, step1104]: loss 8.277279
[epoch5, step1105]: loss 5.163920
[epoch5, step1106]: loss 2.172729
[epoch5, step1107]: loss 1.533454
[epoch5, step1108]: loss 12.247181
[epoch5, step1109]: loss 6.147759
[epoch5, step1110]: loss 3.933827
[epoch5, step1111]: loss 9.205593
[epoch5, step1112]: loss 5.151137
[epoch5, step1113]: loss 3.913297
[epoch5, step1114]: loss 3.163029
[epoch5, step1115]: loss 4.797897
[epoch5, step1116]: loss 3.133813
[epoch5, step1117]: loss 4.659030
[epoch5, step1118]: loss 20.211985
[epoch5, step1119]: loss 10.692372
[epoch5, step1120]: loss 2.722077
[epoch5, step1121]: loss 26.695446
[epoch5, step1122]: loss 1.863543
[epoch5, step1123]: loss 6.662408
[epoch5, step1124]: loss 46.886837
[epoch5, step1125]: loss 42.553181
[epoch5, step1126]: loss 18.053967
[epoch5, step1127]: loss 9.731434
[epoch5, step1128]: loss 4.617384
[epoch5, step1129]: loss 2.115180
[epoch5, step1130]: loss 2.736408
[epoch5, step1131]: loss 3.618788
[epoch5, step1132]: loss 8.693191
[epoch5, step1133]: loss 2.581394
[epoch5, step1134]: loss 4.364049
[epoch5, step1135]: loss 9.349170
[epoch5, step1136]: loss 20.239212
[epoch5, step1137]: loss 15.948981
[epoch5, step1138]: loss 31.206562
[epoch5, step1139]: loss 10.439957
[epoch5, step1140]: loss 4.419073
[epoch5, step1141]: loss 2.227250
[epoch5, step1142]: loss 17.948511
[epoch5, step1143]: loss 15.755233
[epoch5, step1144]: loss 1.759688
[epoch5, step1145]: loss 4.505789
[epoch5, step1146]: loss 3.074872
[epoch5, step1147]: loss 21.680000
[epoch5, step1148]: loss 3.514478
[epoch5, step1149]: loss 16.831348
[epoch5, step1150]: loss 5.874997
[epoch5, step1151]: loss 13.981277
[epoch5, step1152]: loss 1.767069
[epoch5, step1153]: loss 20.549431
[epoch5, step1154]: loss 9.867025
[epoch5, step1155]: loss 3.400916
[epoch5, step1156]: loss 19.631121
[epoch5, step1157]: loss 7.168032
[epoch5, step1158]: loss 4.343402
[epoch5, step1159]: loss 3.367559
[epoch5, step1160]: loss 2.809922
[epoch5, step1161]: loss 8.311642
[epoch5, step1162]: loss 3.030334
[epoch5, step1163]: loss 3.625549
[epoch5, step1164]: loss 4.160648
[epoch5, step1165]: loss 19.905874
[epoch5, step1166]: loss 18.170364
[epoch5, step1167]: loss 39.460052
[epoch5, step1168]: loss 23.816027
[epoch5, step1169]: loss 25.931005
[epoch5, step1170]: loss 5.634898
[epoch5, step1171]: loss 10.296539
[epoch5, step1172]: loss 3.797048
[epoch5, step1173]: loss 8.948193
[epoch5, step1174]: loss 10.458566
[epoch5, step1175]: loss 5.335470
[epoch5, step1176]: loss 2.200749
[epoch5, step1177]: loss 3.310701
[epoch5, step1178]: loss 3.451928
[epoch5, step1179]: loss 42.641781
[epoch5, step1180]: loss 2.518714
[epoch5, step1181]: loss 38.500378
[epoch5, step1182]: loss 4.870503
[epoch5, step1183]: loss 2.310245
[epoch5, step1184]: loss 2.922739
[epoch5, step1185]: loss 9.225323
[epoch5, step1186]: loss 1.598703
[epoch5, step1187]: loss 2.960636
[epoch5, step1188]: loss 22.440132
[epoch5, step1189]: loss 15.314567
[epoch5, step1190]: loss 9.325713
[epoch5, step1191]: loss 2.770081
[epoch5, step1192]: loss 29.339197
[epoch5, step1193]: loss 13.394817
[epoch5, step1194]: loss 8.812094
[epoch5, step1195]: loss 18.001566
[epoch5, step1196]: loss 2.339920
[epoch5, step1197]: loss 7.749959
[epoch5, step1198]: loss 1.966697
[epoch5, step1199]: loss 9.843691
[epoch5, step1200]: loss 10.467100
[epoch5, step1201]: loss 2.554728
[epoch5, step1202]: loss 26.650232
[epoch5, step1203]: loss 29.466003
[epoch5, step1204]: loss 17.046011
[epoch5, step1205]: loss 10.272882
[epoch5, step1206]: loss 3.699712
[epoch5, step1207]: loss 3.502369
[epoch5, step1208]: loss 3.629223
[epoch5, step1209]: loss 11.375370
[epoch5, step1210]: loss 2.484545
[epoch5, step1211]: loss 5.518279
[epoch5, step1212]: loss 35.987724
[epoch5, step1213]: loss 38.644833
[epoch5, step1214]: loss 9.898857
[epoch5, step1215]: loss 5.963935
[epoch5, step1216]: loss 4.793141
[epoch5, step1217]: loss 3.513616
[epoch5, step1218]: loss 18.235209
[epoch5, step1219]: loss 35.135742
[epoch5, step1220]: loss 1.862479
[epoch5, step1221]: loss 20.168875
[epoch5, step1222]: loss 24.036263
[epoch5, step1223]: loss 6.190300
[epoch5, step1224]: loss 6.718755
[epoch5, step1225]: loss 4.728690
[epoch5, step1226]: loss 25.271526
[epoch5, step1227]: loss 2.787671
[epoch5, step1228]: loss 3.034470
[epoch5, step1229]: loss 2.989426
[epoch5, step1230]: loss 8.009942
[epoch5, step1231]: loss 8.598888
[epoch5, step1232]: loss 20.866198
[epoch5, step1233]: loss 2.885151
[epoch5, step1234]: loss 1.984700
[epoch5, step1235]: loss 18.834761
[epoch5, step1236]: loss 2.244781
[epoch5, step1237]: loss 5.445197
[epoch5, step1238]: loss 2.764420
[epoch5, step1239]: loss 6.235206
[epoch5, step1240]: loss 2.771528
[epoch5, step1241]: loss 9.885184
[epoch5, step1242]: loss 10.557057
[epoch5, step1243]: loss 10.877440
[epoch5, step1244]: loss 3.554391
[epoch5, step1245]: loss 19.908649
[epoch5, step1246]: loss 1.749740
[epoch5, step1247]: loss 3.510310
[epoch5, step1248]: loss 4.178694
[epoch5, step1249]: loss 30.159779
[epoch5, step1250]: loss 20.418789
[epoch5, step1251]: loss 6.292648
[epoch5, step1252]: loss 3.141971
[epoch5, step1253]: loss 4.391474
[epoch5, step1254]: loss 3.252886
[epoch5, step1255]: loss 21.780670
[epoch5, step1256]: loss 2.240273
[epoch5, step1257]: loss 2.726504
[epoch5, step1258]: loss 13.490209
[epoch5, step1259]: loss 2.701310
[epoch5, step1260]: loss 14.657111
[epoch5, step1261]: loss 4.531867
[epoch5, step1262]: loss 21.845022
[epoch5, step1263]: loss 11.333254
[epoch5, step1264]: loss 3.454955
[epoch5, step1265]: loss 4.290184
[epoch5, step1266]: loss 5.965616
[epoch5, step1267]: loss 26.189301
[epoch5, step1268]: loss 1.952791
[epoch5, step1269]: loss 7.545308
[epoch5, step1270]: loss 2.680159
[epoch5, step1271]: loss 20.451023
[epoch5, step1272]: loss 2.480737
[epoch5, step1273]: loss 10.969474
[epoch5, step1274]: loss 2.218165
[epoch5, step1275]: loss 20.029490
[epoch5, step1276]: loss 34.122368
[epoch5, step1277]: loss 13.464326
[epoch5, step1278]: loss 27.534008
[epoch5, step1279]: loss 11.561284
[epoch5, step1280]: loss 24.689053
[epoch5, step1281]: loss 11.824739
[epoch5, step1282]: loss 2.295514
[epoch5, step1283]: loss 5.184255
[epoch5, step1284]: loss 2.622713
[epoch5, step1285]: loss 20.717712
[epoch5, step1286]: loss 2.755311
[epoch5, step1287]: loss 14.465849
[epoch5, step1288]: loss 2.818854
[epoch5, step1289]: loss 18.040348
[epoch5, step1290]: loss 38.126019
[epoch5, step1291]: loss 5.418770
[epoch5, step1292]: loss 3.727939
[epoch5, step1293]: loss 20.808231
[epoch5, step1294]: loss 4.627088
[epoch5, step1295]: loss 5.221000
[epoch5, step1296]: loss 8.187593
[epoch5, step1297]: loss 9.687757
[epoch5, step1298]: loss 3.487597
[epoch5, step1299]: loss 2.040759
[epoch5, step1300]: loss 2.270394
[epoch5, step1301]: loss 6.150373
[epoch5, step1302]: loss 30.722607
[epoch5, step1303]: loss 1.979450
[epoch5, step1304]: loss 11.305397
[epoch5, step1305]: loss 11.974075
[epoch5, step1306]: loss 25.381622
[epoch5, step1307]: loss 6.431838
[epoch5, step1308]: loss 22.061832
[epoch5, step1309]: loss 8.954917
[epoch5, step1310]: loss 17.305819
[epoch5, step1311]: loss 6.216491
[epoch5, step1312]: loss 3.414157
[epoch5, step1313]: loss 3.064387
[epoch5, step1314]: loss 6.270464
[epoch5, step1315]: loss 13.438323
[epoch5, step1316]: loss 22.186485
[epoch5, step1317]: loss 40.333153
[epoch5, step1318]: loss 7.627136
[epoch5, step1319]: loss 3.298217
[epoch5, step1320]: loss 18.080338
[epoch5, step1321]: loss 10.980581
[epoch5, step1322]: loss 5.591455
[epoch5, step1323]: loss 20.241505
[epoch5, step1324]: loss 6.454584
[epoch5, step1325]: loss 10.769630
[epoch5, step1326]: loss 6.339248
[epoch5, step1327]: loss 11.461325
[epoch5, step1328]: loss 11.326148
[epoch5, step1329]: loss 36.269234
[epoch5, step1330]: loss 1.742534
[epoch5, step1331]: loss 3.103971
[epoch5, step1332]: loss 3.436660
[epoch5, step1333]: loss 3.835918
[epoch5, step1334]: loss 24.832529
[epoch5, step1335]: loss 2.611061
[epoch5, step1336]: loss 2.772392
[epoch5, step1337]: loss 2.360426
[epoch5, step1338]: loss 17.293892
[epoch5, step1339]: loss 4.495972
[epoch5, step1340]: loss 4.265034
[epoch5, step1341]: loss 2.268644
[epoch5, step1342]: loss 9.120672
[epoch5, step1343]: loss 1.916707
[epoch5, step1344]: loss 1.615624
[epoch5, step1345]: loss 10.154384
[epoch5, step1346]: loss 20.941071
[epoch5, step1347]: loss 2.487026
[epoch5, step1348]: loss 2.729342
[epoch5, step1349]: loss 3.911270
[epoch5, step1350]: loss 21.504152
[epoch5, step1351]: loss 21.412931
[epoch5, step1352]: loss 61.008141
[epoch5, step1353]: loss 2.486651
[epoch5, step1354]: loss 4.854180
[epoch5, step1355]: loss 11.566606
[epoch5, step1356]: loss 39.695274
[epoch5, step1357]: loss 3.134516
[epoch5, step1358]: loss 4.623427
[epoch5, step1359]: loss 23.924860
[epoch5, step1360]: loss 2.284925
[epoch5, step1361]: loss 11.982084
[epoch5, step1362]: loss 4.023967
[epoch5, step1363]: loss 7.452941
[epoch5, step1364]: loss 1.763804
[epoch5, step1365]: loss 3.261742
[epoch5, step1366]: loss 1.986557
[epoch5, step1367]: loss 33.643917
[epoch5, step1368]: loss 12.352338
[epoch5, step1369]: loss 2.060580
[epoch5, step1370]: loss 1.979811
[epoch5, step1371]: loss 10.519035
[epoch5, step1372]: loss 2.293023
[epoch5, step1373]: loss 4.042911
[epoch5, step1374]: loss 30.162407
[epoch5, step1375]: loss 39.046249
[epoch5, step1376]: loss 13.094482
[epoch5, step1377]: loss 3.735962
[epoch5, step1378]: loss 4.666496
[epoch5, step1379]: loss 9.209955
[epoch5, step1380]: loss 16.873470
[epoch5, step1381]: loss 7.726772
[epoch5, step1382]: loss 17.844307
[epoch5, step1383]: loss 29.739738
[epoch5, step1384]: loss 6.376643
[epoch5, step1385]: loss 39.793301
[epoch5, step1386]: loss 2.205834
[epoch5, step1387]: loss 31.000809
[epoch5, step1388]: loss 1.808253
[epoch5, step1389]: loss 24.095613
[epoch5, step1390]: loss 7.246987
[epoch5, step1391]: loss 4.510614
[epoch5, step1392]: loss 25.218979
[epoch5, step1393]: loss 37.904621
[epoch5, step1394]: loss 1.841750
[epoch5, step1395]: loss 19.411179
[epoch5, step1396]: loss 2.254970
[epoch5, step1397]: loss 46.663460
[epoch5, step1398]: loss 5.475811
[epoch5, step1399]: loss 3.298993
[epoch5, step1400]: loss 28.223280
[epoch5, step1401]: loss 32.930317
[epoch5, step1402]: loss 3.559765
[epoch5, step1403]: loss 11.501158
[epoch5, step1404]: loss 10.676250
[epoch5, step1405]: loss 6.131159
[epoch5, step1406]: loss 8.945462
[epoch5, step1407]: loss 8.808108
[epoch5, step1408]: loss 2.598807
[epoch5, step1409]: loss 11.210632
[epoch5, step1410]: loss 6.024557
[epoch5, step1411]: loss 18.793926
[epoch5, step1412]: loss 37.583164
[epoch5, step1413]: loss 4.502937
[epoch5, step1414]: loss 1.860492
[epoch5, step1415]: loss 20.746412
[epoch5, step1416]: loss 2.581776
[epoch5, step1417]: loss 12.341201
[epoch5, step1418]: loss 50.027706
[epoch5, step1419]: loss 23.504086
[epoch5, step1420]: loss 3.921815
[epoch5, step1421]: loss 15.474083
[epoch5, step1422]: loss 26.679239
[epoch5, step1423]: loss 5.173287
[epoch5, step1424]: loss 4.275878
[epoch5, step1425]: loss 2.155102
[epoch5, step1426]: loss 10.977727
[epoch5, step1427]: loss 2.646496
[epoch5, step1428]: loss 12.006357
[epoch5, step1429]: loss 4.019617
[epoch5, step1430]: loss 21.069221
[epoch5, step1431]: loss 16.442051
[epoch5, step1432]: loss 26.096390
[epoch5, step1433]: loss 2.974537
[epoch5, step1434]: loss 20.054512
[epoch5, step1435]: loss 30.126339
[epoch5, step1436]: loss 21.089502
[epoch5, step1437]: loss 9.226351
[epoch5, step1438]: loss 2.235594
[epoch5, step1439]: loss 9.491078
[epoch5, step1440]: loss 42.989307
[epoch5, step1441]: loss 10.471849
[epoch5, step1442]: loss 10.415146
[epoch5, step1443]: loss 7.591874
[epoch5, step1444]: loss 3.691540
[epoch5, step1445]: loss 19.127932
[epoch5, step1446]: loss 4.704442
[epoch5, step1447]: loss 21.742706
[epoch5, step1448]: loss 1.902537
[epoch5, step1449]: loss 2.591703
[epoch5, step1450]: loss 2.039936
[epoch5, step1451]: loss 4.209756
[epoch5, step1452]: loss 4.684580
[epoch5, step1453]: loss 19.409504
[epoch5, step1454]: loss 2.047174
[epoch5, step1455]: loss 2.860809
[epoch5, step1456]: loss 12.519753
[epoch5, step1457]: loss 6.019326
[epoch5, step1458]: loss 3.183572
[epoch5, step1459]: loss 4.321858
[epoch5, step1460]: loss 4.216426
[epoch5, step1461]: loss 3.904631
[epoch5, step1462]: loss 4.282455
[epoch5, step1463]: loss 20.038263
[epoch5, step1464]: loss 1.801879
[epoch5, step1465]: loss 3.758632
[epoch5, step1466]: loss 6.895744
[epoch5, step1467]: loss 5.465203
[epoch5, step1468]: loss 17.520618
[epoch5, step1469]: loss 5.398187
[epoch5, step1470]: loss 2.754111
[epoch5, step1471]: loss 5.731949
[epoch5, step1472]: loss 4.778781
[epoch5, step1473]: loss 44.803490
[epoch5, step1474]: loss 1.663172
[epoch5, step1475]: loss 3.307818
[epoch5, step1476]: loss 18.065451
[epoch5, step1477]: loss 1.879939
[epoch5, step1478]: loss 6.192069
[epoch5, step1479]: loss 22.683805
[epoch5, step1480]: loss 29.073807
[epoch5, step1481]: loss 9.239538
[epoch5, step1482]: loss 8.539110
[epoch5, step1483]: loss 7.733634
[epoch5, step1484]: loss 3.617041
[epoch5, step1485]: loss 2.590088
[epoch5, step1486]: loss 19.335701
[epoch5, step1487]: loss 16.686687
[epoch5, step1488]: loss 4.600832
[epoch5, step1489]: loss 4.001366
[epoch5, step1490]: loss 29.482897
[epoch5, step1491]: loss 3.806431
[epoch5, step1492]: loss 18.332800
[epoch5, step1493]: loss 2.034844
[epoch5, step1494]: loss 1.984281
[epoch5, step1495]: loss 9.035096
[epoch5, step1496]: loss 9.911375
[epoch5, step1497]: loss 9.540350
[epoch5, step1498]: loss 8.690252
[epoch5, step1499]: loss 24.610546
[epoch5, step1500]: loss 10.850121
[epoch5, step1501]: loss 12.570160
[epoch5, step1502]: loss 1.598754
[epoch5, step1503]: loss 4.132667
[epoch5, step1504]: loss 4.313551
[epoch5, step1505]: loss 3.989632
[epoch5, step1506]: loss 4.639142
[epoch5, step1507]: loss 3.391860
[epoch5, step1508]: loss 4.501380
[epoch5, step1509]: loss 3.935071
[epoch5, step1510]: loss 29.574841
[epoch5, step1511]: loss 21.567654
[epoch5, step1512]: loss 4.775588
[epoch5, step1513]: loss 23.465445
[epoch5, step1514]: loss 7.611560
[epoch5, step1515]: loss 27.847839
[epoch5, step1516]: loss 6.041890
[epoch5, step1517]: loss 30.044893
[epoch5, step1518]: loss 4.254416
[epoch5, step1519]: loss 20.478041
[epoch5, step1520]: loss 28.208878
[epoch5, step1521]: loss 2.482967
[epoch5, step1522]: loss 4.780023
[epoch5, step1523]: loss 10.326633
[epoch5, step1524]: loss 21.005238
[epoch5, step1525]: loss 3.114067
[epoch5, step1526]: loss 16.702324
[epoch5, step1527]: loss 18.894320
[epoch5, step1528]: loss 7.210648
[epoch5, step1529]: loss 4.299238
[epoch5, step1530]: loss 6.593801
[epoch5, step1531]: loss 27.437933
[epoch5, step1532]: loss 5.585739
[epoch5, step1533]: loss 4.504922
[epoch5, step1534]: loss 17.757881
[epoch5, step1535]: loss 6.525360
[epoch5, step1536]: loss 30.052925
[epoch5, step1537]: loss 15.106589
[epoch5, step1538]: loss 39.033688
[epoch5, step1539]: loss 4.407022
[epoch5, step1540]: loss 6.984213
[epoch5, step1541]: loss 3.272398
[epoch5, step1542]: loss 34.593155
[epoch5, step1543]: loss 8.347015
[epoch5, step1544]: loss 23.129938
[epoch5, step1545]: loss 2.654237
[epoch5, step1546]: loss 4.166267
[epoch5, step1547]: loss 6.903791
[epoch5, step1548]: loss 4.099285
[epoch5, step1549]: loss 2.239611
[epoch5, step1550]: loss 2.863469
[epoch5, step1551]: loss 18.974422
[epoch5, step1552]: loss 4.452911
[epoch5, step1553]: loss 36.106575
[epoch5, step1554]: loss 22.054342
[epoch5, step1555]: loss 1.784307
[epoch5, step1556]: loss 4.086900
[epoch5, step1557]: loss 16.960629
[epoch5, step1558]: loss 5.767423
[epoch5, step1559]: loss 1.660526
[epoch5, step1560]: loss 3.637779
[epoch5, step1561]: loss 15.958691
[epoch5, step1562]: loss 2.502343
[epoch5, step1563]: loss 3.912560
[epoch5, step1564]: loss 4.801366
[epoch5, step1565]: loss 3.143404
[epoch5, step1566]: loss 3.369708
[epoch5, step1567]: loss 3.236190
[epoch5, step1568]: loss 12.934226
[epoch5, step1569]: loss 28.372046
[epoch5, step1570]: loss 19.672028
[epoch5, step1571]: loss 24.144226
[epoch5, step1572]: loss 11.761923
[epoch5, step1573]: loss 3.195079
[epoch5, step1574]: loss 5.022635
[epoch5, step1575]: loss 2.560694
[epoch5, step1576]: loss 3.117507
[epoch5, step1577]: loss 18.476620
[epoch5, step1578]: loss 20.849352
[epoch5, step1579]: loss 1.701285
[epoch5, step1580]: loss 22.945076
[epoch5, step1581]: loss 23.034786
[epoch5, step1582]: loss 4.525703
[epoch5, step1583]: loss 4.715307
[epoch5, step1584]: loss 5.041053
[epoch5, step1585]: loss 20.780376
[epoch5, step1586]: loss 11.098618
[epoch5, step1587]: loss 2.931675
[epoch5, step1588]: loss 2.278049
[epoch5, step1589]: loss 4.316812
[epoch5, step1590]: loss 1.910942
[epoch5, step1591]: loss 5.726017
[epoch5, step1592]: loss 10.207454
[epoch5, step1593]: loss 2.730434
[epoch5, step1594]: loss 8.057144
[epoch5, step1595]: loss 11.680342
[epoch5, step1596]: loss 3.937637
[epoch5, step1597]: loss 3.083728
[epoch5, step1598]: loss 5.801195
[epoch5, step1599]: loss 3.630042
[epoch5, step1600]: loss 23.916592
[epoch5, step1601]: loss 11.365962
[epoch5, step1602]: loss 14.001739
[epoch5, step1603]: loss 3.018251
[epoch5, step1604]: loss 4.318297
[epoch5, step1605]: loss 2.130771
[epoch5, step1606]: loss 19.514486
[epoch5, step1607]: loss 4.427293
[epoch5, step1608]: loss 11.140068
[epoch5, step1609]: loss 13.093110
[epoch5, step1610]: loss 7.025140
[epoch5, step1611]: loss 4.271194
[epoch5, step1612]: loss 3.900244
[epoch5, step1613]: loss 19.236650
[epoch5, step1614]: loss 5.159220
[epoch5, step1615]: loss 2.452447
[epoch5, step1616]: loss 5.138187
[epoch5, step1617]: loss 5.364208
[epoch5, step1618]: loss 2.231085
[epoch5, step1619]: loss 23.312946
[epoch5, step1620]: loss 22.624956
[epoch5, step1621]: loss 3.969128
[epoch5, step1622]: loss 2.148205
[epoch5, step1623]: loss 1.712091
[epoch5, step1624]: loss 5.796794
[epoch5, step1625]: loss 19.034561
[epoch5, step1626]: loss 5.630743
[epoch5, step1627]: loss 4.761274
[epoch5, step1628]: loss 1.524499
[epoch5, step1629]: loss 4.310072
[epoch5, step1630]: loss 2.844675
[epoch5, step1631]: loss 7.662165
[epoch5, step1632]: loss 2.178329
[epoch5, step1633]: loss 2.548947
[epoch5, step1634]: loss 2.403521
[epoch5, step1635]: loss 13.327255
[epoch5, step1636]: loss 2.189012
[epoch5, step1637]: loss 11.073565
[epoch5, step1638]: loss 28.809124
[epoch5, step1639]: loss 6.827240
[epoch5, step1640]: loss 15.061371
[epoch5, step1641]: loss 12.791623
[epoch5, step1642]: loss 2.994030
[epoch5, step1643]: loss 9.836926
[epoch5, step1644]: loss 1.683581
[epoch5, step1645]: loss 2.361842
[epoch5, step1646]: loss 9.456755
[epoch5, step1647]: loss 15.912257
[epoch5, step1648]: loss 3.539085
[epoch5, step1649]: loss 3.638276
[epoch5, step1650]: loss 3.752984
[epoch5, step1651]: loss 2.173846
[epoch5, step1652]: loss 33.394032
[epoch5, step1653]: loss 16.485138
[epoch5, step1654]: loss 4.627052
[epoch5, step1655]: loss 3.950966
[epoch5, step1656]: loss 2.640997
[epoch5, step1657]: loss 5.937640
[epoch5, step1658]: loss 47.101749
[epoch5, step1659]: loss 3.800452
[epoch5, step1660]: loss 11.805117
[epoch5, step1661]: loss 17.959614
[epoch5, step1662]: loss 18.372356
[epoch5, step1663]: loss 3.405824
[epoch5, step1664]: loss 6.539496
[epoch5, step1665]: loss 2.702340
[epoch5, step1666]: loss 29.972162
[epoch5, step1667]: loss 4.397969
[epoch5, step1668]: loss 3.811069
[epoch5, step1669]: loss 9.586820
[epoch5, step1670]: loss 21.967062
[epoch5, step1671]: loss 38.890545
[epoch5, step1672]: loss 5.308405
[epoch5, step1673]: loss 5.018137
[epoch5, step1674]: loss 3.449908
[epoch5, step1675]: loss 23.084213
[epoch5, step1676]: loss 2.055827
[epoch5, step1677]: loss 12.872129
[epoch5, step1678]: loss 2.417432
[epoch5, step1679]: loss 2.180275
[epoch5, step1680]: loss 9.710331
[epoch5, step1681]: loss 3.842874
[epoch5, step1682]: loss 7.660994
[epoch5, step1683]: loss 2.885562
[epoch5, step1684]: loss 7.143392
[epoch5, step1685]: loss 6.815980
[epoch5, step1686]: loss 10.132768
[epoch5, step1687]: loss 16.196905
[epoch5, step1688]: loss 3.166432
[epoch5, step1689]: loss 4.087568
[epoch5, step1690]: loss 2.653911
[epoch5, step1691]: loss 1.739192
[epoch5, step1692]: loss 1.940882
[epoch5, step1693]: loss 2.578326
[epoch5, step1694]: loss 19.615948
[epoch5, step1695]: loss 3.271705
[epoch5, step1696]: loss 5.276688
[epoch5, step1697]: loss 24.709414
[epoch5, step1698]: loss 10.426139
[epoch5, step1699]: loss 2.559227
[epoch5, step1700]: loss 2.133121
[epoch5, step1701]: loss 1.820406
[epoch5, step1702]: loss 19.586885
[epoch5, step1703]: loss 42.517406
[epoch5, step1704]: loss 3.182031
[epoch5, step1705]: loss 2.950233
[epoch5, step1706]: loss 13.100804
[epoch5, step1707]: loss 2.575716
[epoch5, step1708]: loss 19.843937
[epoch5, step1709]: loss 4.399762
[epoch5, step1710]: loss 19.867300
[epoch5, step1711]: loss 1.762715
[epoch5, step1712]: loss 1.930714
[epoch5, step1713]: loss 11.830389
[epoch5, step1714]: loss 9.671329
[epoch5, step1715]: loss 2.718463
[epoch5, step1716]: loss 10.574897
[epoch5, step1717]: loss 5.244118
[epoch5, step1718]: loss 8.250946
[epoch5, step1719]: loss 2.753544
[epoch5, step1720]: loss 7.586952
[epoch5, step1721]: loss 4.231077
[epoch5, step1722]: loss 25.047668
[epoch5, step1723]: loss 4.891950
[epoch5, step1724]: loss 2.002848
[epoch5, step1725]: loss 2.693638
[epoch5, step1726]: loss 5.364660
[epoch5, step1727]: loss 3.035772
[epoch5, step1728]: loss 18.005743
[epoch5, step1729]: loss 19.519674
[epoch5, step1730]: loss 9.604489
[epoch5, step1731]: loss 9.774291
[epoch5, step1732]: loss 48.351959
[epoch5, step1733]: loss 14.283149
[epoch5, step1734]: loss 12.043019
[epoch5, step1735]: loss 1.888138
[epoch5, step1736]: loss 20.206675
[epoch5, step1737]: loss 25.781319
[epoch5, step1738]: loss 20.389509
[epoch5, step1739]: loss 25.794468
[epoch5, step1740]: loss 37.447014
[epoch5, step1741]: loss 2.379080
[epoch5, step1742]: loss 5.413468
[epoch5, step1743]: loss 14.423819
[epoch5, step1744]: loss 20.570505
[epoch5, step1745]: loss 1.289555
[epoch5, step1746]: loss 27.649397
[epoch5, step1747]: loss 3.598500
[epoch5, step1748]: loss 3.170705
[epoch5, step1749]: loss 2.580524
[epoch5, step1750]: loss 3.031924
[epoch5, step1751]: loss 18.160070
[epoch5, step1752]: loss 26.130974
[epoch5, step1753]: loss 2.630341
[epoch5, step1754]: loss 2.053108
[epoch5, step1755]: loss 3.344613
[epoch5, step1756]: loss 3.437351
[epoch5, step1757]: loss 27.484734
[epoch5, step1758]: loss 3.323581
[epoch5, step1759]: loss 19.820841
[epoch5, step1760]: loss 2.963315
[epoch5, step1761]: loss 10.378662
[epoch5, step1762]: loss 17.870863
[epoch5, step1763]: loss 10.395464
[epoch5, step1764]: loss 26.217854
[epoch5, step1765]: loss 1.866727
[epoch5, step1766]: loss 19.687099
[epoch5, step1767]: loss 3.391313
[epoch5, step1768]: loss 2.482648
[epoch5, step1769]: loss 5.430236
[epoch5, step1770]: loss 6.052886
[epoch5, step1771]: loss 8.173628
[epoch5, step1772]: loss 1.996145
[epoch5, step1773]: loss 11.051126
[epoch5, step1774]: loss 5.188134
[epoch5, step1775]: loss 3.867032
[epoch5, step1776]: loss 10.188177
[epoch5, step1777]: loss 2.131909
[epoch5, step1778]: loss 4.403432
[epoch5, step1779]: loss 5.438298
[epoch5, step1780]: loss 29.543173
[epoch5, step1781]: loss 3.889496
[epoch5, step1782]: loss 7.258628
[epoch5, step1783]: loss 9.139420
[epoch5, step1784]: loss 4.994419
[epoch5, step1785]: loss 11.931554
[epoch5, step1786]: loss 17.131031
[epoch5, step1787]: loss 2.893152
[epoch5, step1788]: loss 17.057608
[epoch5, step1789]: loss 10.939308
[epoch5, step1790]: loss 2.197931
[epoch5, step1791]: loss 2.222059
[epoch5, step1792]: loss 22.106995
[epoch5, step1793]: loss 2.929409
[epoch5, step1794]: loss 19.977262
[epoch5, step1795]: loss 9.405445
[epoch5, step1796]: loss 5.979785
[epoch5, step1797]: loss 6.475547
[epoch5, step1798]: loss 2.900909
[epoch5, step1799]: loss 4.898762
[epoch5, step1800]: loss 3.096622
[epoch5, step1801]: loss 24.688787
[epoch5, step1802]: loss 5.277845
[epoch5, step1803]: loss 24.557947
[epoch5, step1804]: loss 5.992471
[epoch5, step1805]: loss 56.220818
[epoch5, step1806]: loss 6.592712
[epoch5, step1807]: loss 15.846146
[epoch5, step1808]: loss 2.586136
[epoch5, step1809]: loss 4.852386
[epoch5, step1810]: loss 8.291790
[epoch5, step1811]: loss 9.721400
[epoch5, step1812]: loss 8.001715
[epoch5, step1813]: loss 2.481376
[epoch5, step1814]: loss 2.837706
[epoch5, step1815]: loss 2.425494
[epoch5, step1816]: loss 5.333015
[epoch5, step1817]: loss 3.234690
[epoch5, step1818]: loss 4.878319
[epoch5, step1819]: loss 12.348346
[epoch5, step1820]: loss 9.395549
[epoch5, step1821]: loss 12.515555
[epoch5, step1822]: loss 24.410137
[epoch5, step1823]: loss 22.245005
[epoch5, step1824]: loss 17.165241
[epoch5, step1825]: loss 22.358673
[epoch5, step1826]: loss 20.651417
[epoch5, step1827]: loss 3.703539
[epoch5, step1828]: loss 10.156378
[epoch5, step1829]: loss 4.263736
[epoch5, step1830]: loss 16.472662
[epoch5, step1831]: loss 1.709866
[epoch5, step1832]: loss 13.300475
[epoch5, step1833]: loss 34.973934
[epoch5, step1834]: loss 3.146432
[epoch5, step1835]: loss 6.657667
[epoch5, step1836]: loss 11.308595
[epoch5, step1837]: loss 26.218130
[epoch5, step1838]: loss 3.736756
[epoch5, step1839]: loss 2.264864
[epoch5, step1840]: loss 5.231061
[epoch5, step1841]: loss 41.856670
[epoch5, step1842]: loss 27.214661
[epoch5, step1843]: loss 34.008945
[epoch5, step1844]: loss 18.356598
[epoch5, step1845]: loss 3.737977
[epoch5, step1846]: loss 2.420264
[epoch5, step1847]: loss 19.064276
[epoch5, step1848]: loss 3.352488
[epoch5, step1849]: loss 4.418372
[epoch5, step1850]: loss 5.066493
[epoch5, step1851]: loss 9.620437
[epoch5, step1852]: loss 24.067429
[epoch5, step1853]: loss 3.103666
[epoch5, step1854]: loss 2.398304
[epoch5, step1855]: loss 5.924011
[epoch5, step1856]: loss 6.749867
[epoch5, step1857]: loss 7.793267
[epoch5, step1858]: loss 1.983531
[epoch5, step1859]: loss 30.553799
[epoch5, step1860]: loss 9.937745
[epoch5, step1861]: loss 3.212912
[epoch5, step1862]: loss 2.403558
[epoch5, step1863]: loss 29.003208
[epoch5, step1864]: loss 13.075233
[epoch5, step1865]: loss 4.904336
[epoch5, step1866]: loss 25.705784
[epoch5, step1867]: loss 5.890357
[epoch5, step1868]: loss 25.672659
[epoch5, step1869]: loss 8.609255
[epoch5, step1870]: loss 4.150204
[epoch5, step1871]: loss 6.538205
[epoch5, step1872]: loss 25.766541
[epoch5, step1873]: loss 6.341558
[epoch5, step1874]: loss 11.776707
[epoch5, step1875]: loss 9.633719
[epoch5, step1876]: loss 2.502576
[epoch5, step1877]: loss 3.279016
[epoch5, step1878]: loss 2.238183
[epoch5, step1879]: loss 2.495551
[epoch5, step1880]: loss 10.002913
[epoch5, step1881]: loss 6.793405
[epoch5, step1882]: loss 8.181685
[epoch5, step1883]: loss 3.695417
[epoch5, step1884]: loss 2.557580
[epoch5, step1885]: loss 1.787060
[epoch5, step1886]: loss 5.474748
[epoch5, step1887]: loss 37.021889
[epoch5, step1888]: loss 8.467108
[epoch5, step1889]: loss 10.908457
[epoch5, step1890]: loss 3.429677
[epoch5, step1891]: loss 4.234356
[epoch5, step1892]: loss 2.336932
[epoch5, step1893]: loss 1.804374
[epoch5, step1894]: loss 9.715356
[epoch5, step1895]: loss 6.523829
[epoch5, step1896]: loss 28.222460
[epoch5, step1897]: loss 2.531182
[epoch5, step1898]: loss 7.230215
[epoch5, step1899]: loss 16.684494
[epoch5, step1900]: loss 1.954727
[epoch5, step1901]: loss 12.724193
[epoch5, step1902]: loss 18.023090
[epoch5, step1903]: loss 4.295567
[epoch5, step1904]: loss 3.070900
[epoch5, step1905]: loss 2.694100
[epoch5, step1906]: loss 34.396488
[epoch5, step1907]: loss 21.262104
[epoch5, step1908]: loss 9.747791
[epoch5, step1909]: loss 1.738404
[epoch5, step1910]: loss 12.757630
[epoch5, step1911]: loss 21.923227
[epoch5, step1912]: loss 8.216219
[epoch5, step1913]: loss 13.504431
[epoch5, step1914]: loss 7.486101
[epoch5, step1915]: loss 2.465853
[epoch5, step1916]: loss 10.149257
[epoch5, step1917]: loss 25.709183
[epoch5, step1918]: loss 28.955601
[epoch5, step1919]: loss 20.738247
[epoch5, step1920]: loss 23.869415
[epoch5, step1921]: loss 2.006844
[epoch5, step1922]: loss 5.661654
[epoch5, step1923]: loss 27.813574
[epoch5, step1924]: loss 5.757606
[epoch5, step1925]: loss 3.740155
[epoch5, step1926]: loss 19.996609
[epoch5, step1927]: loss 4.464943
[epoch5, step1928]: loss 5.895350
[epoch5, step1929]: loss 5.594759
[epoch5, step1930]: loss 15.985572
[epoch5, step1931]: loss 4.581632
[epoch5, step1932]: loss 5.077144
[epoch5, step1933]: loss 15.158366
[epoch5, step1934]: loss 10.484425
[epoch5, step1935]: loss 29.454458
[epoch5, step1936]: loss 2.542903
[epoch5, step1937]: loss 4.426504
[epoch5, step1938]: loss 2.332962
[epoch5, step1939]: loss 8.182234
[epoch5, step1940]: loss 17.746395
[epoch5, step1941]: loss 3.557465
[epoch5, step1942]: loss 19.629463
[epoch5, step1943]: loss 5.845248
[epoch5, step1944]: loss 2.855994
[epoch5, step1945]: loss 3.900719
[epoch5, step1946]: loss 45.538265
[epoch5, step1947]: loss 20.352901
[epoch5, step1948]: loss 2.388870
[epoch5, step1949]: loss 11.699995
[epoch5, step1950]: loss 2.004009
[epoch5, step1951]: loss 6.983876
[epoch5, step1952]: loss 2.357411
[epoch5, step1953]: loss 8.566621
[epoch5, step1954]: loss 1.863149
[epoch5, step1955]: loss 2.729139
[epoch5, step1956]: loss 6.257401
[epoch5, step1957]: loss 5.171031
[epoch5, step1958]: loss 3.155779
[epoch5, step1959]: loss 5.740705
[epoch5, step1960]: loss 3.492979
[epoch5, step1961]: loss 22.163477
[epoch5, step1962]: loss 6.929619
[epoch5, step1963]: loss 13.379466
[epoch5, step1964]: loss 4.727444
[epoch5, step1965]: loss 7.174527
[epoch5, step1966]: loss 35.972717
[epoch5, step1967]: loss 3.271236
[epoch5, step1968]: loss 3.920096
[epoch5, step1969]: loss 11.561795
[epoch5, step1970]: loss 21.842365
[epoch5, step1971]: loss 3.521364
[epoch5, step1972]: loss 22.177605
[epoch5, step1973]: loss 1.992764
[epoch5, step1974]: loss 29.299574
[epoch5, step1975]: loss 4.059535
[epoch5, step1976]: loss 3.849111
[epoch5, step1977]: loss 44.598213
[epoch5, step1978]: loss 2.282768
[epoch5, step1979]: loss 13.212977
[epoch5, step1980]: loss 5.678138
[epoch5, step1981]: loss 2.318060
[epoch5, step1982]: loss 3.546105
[epoch5, step1983]: loss 17.862934
[epoch5, step1984]: loss 4.160575
[epoch5, step1985]: loss 2.328888
[epoch5, step1986]: loss 9.058376
[epoch5, step1987]: loss 5.819404
[epoch5, step1988]: loss 2.077315
[epoch5, step1989]: loss 5.477553
[epoch5, step1990]: loss 4.111657
[epoch5, step1991]: loss 5.975663
[epoch5, step1992]: loss 2.325287
[epoch5, step1993]: loss 16.401436
[epoch5, step1994]: loss 9.063863
[epoch5, step1995]: loss 1.440725
[epoch5, step1996]: loss 11.634039
[epoch5, step1997]: loss 1.675547
[epoch5, step1998]: loss 32.260300
[epoch5, step1999]: loss 31.663889
[epoch5, step2000]: loss 23.498554
[epoch5, step2001]: loss 2.539774
[epoch5, step2002]: loss 19.664549
[epoch5, step2003]: loss 3.169661
[epoch5, step2004]: loss 2.759271
[epoch5, step2005]: loss 10.825843
[epoch5, step2006]: loss 3.579786
[epoch5, step2007]: loss 8.698639
[epoch5, step2008]: loss 20.758673
[epoch5, step2009]: loss 9.293857
[epoch5, step2010]: loss 23.583565
[epoch5, step2011]: loss 3.734653
[epoch5, step2012]: loss 42.553734
[epoch5, step2013]: loss 26.726526
[epoch5, step2014]: loss 27.609520
[epoch5, step2015]: loss 4.542726
[epoch5, step2016]: loss 30.558048
[epoch5, step2017]: loss 2.456605
[epoch5, step2018]: loss 1.952381
[epoch5, step2019]: loss 4.782322
[epoch5, step2020]: loss 23.343971
[epoch5, step2021]: loss 3.209143
[epoch5, step2022]: loss 2.662224
[epoch5, step2023]: loss 13.956337
[epoch5, step2024]: loss 6.369973
[epoch5, step2025]: loss 6.537085
[epoch5, step2026]: loss 35.343369
[epoch5, step2027]: loss 2.076678
[epoch5, step2028]: loss 20.559698
[epoch5, step2029]: loss 3.115095
[epoch5, step2030]: loss 2.159870
[epoch5, step2031]: loss 4.481490
[epoch5, step2032]: loss 1.732495
[epoch5, step2033]: loss 3.796282
[epoch5, step2034]: loss 14.701149
[epoch5, step2035]: loss 22.063101
[epoch5, step2036]: loss 1.614438
[epoch5, step2037]: loss 2.285712
[epoch5, step2038]: loss 27.559340
[epoch5, step2039]: loss 7.681716
[epoch5, step2040]: loss 3.012774
[epoch5, step2041]: loss 13.959687
[epoch5, step2042]: loss 25.514814
[epoch5, step2043]: loss 3.141047
[epoch5, step2044]: loss 4.088525
[epoch5, step2045]: loss 6.002877
[epoch5, step2046]: loss 7.903477
[epoch5, step2047]: loss 4.011802
[epoch5, step2048]: loss 7.525827
[epoch5, step2049]: loss 4.944273
[epoch5, step2050]: loss 31.436911
[epoch5, step2051]: loss 1.392947
[epoch5, step2052]: loss 2.199322
[epoch5, step2053]: loss 3.501064
[epoch5, step2054]: loss 7.633191
[epoch5, step2055]: loss 42.488266
[epoch5, step2056]: loss 3.372329
[epoch5, step2057]: loss 15.040257
[epoch5, step2058]: loss 2.706651
[epoch5, step2059]: loss 1.855152
[epoch5, step2060]: loss 3.630563
[epoch5, step2061]: loss 2.133629
[epoch5, step2062]: loss 4.142955
[epoch5, step2063]: loss 13.630136
[epoch5, step2064]: loss 3.223662
[epoch5, step2065]: loss 5.603519
[epoch5, step2066]: loss 4.152522
[epoch5, step2067]: loss 18.214497
[epoch5, step2068]: loss 20.695234
[epoch5, step2069]: loss 24.183683
[epoch5, step2070]: loss 30.958059
[epoch5, step2071]: loss 4.127092
[epoch5, step2072]: loss 6.605790
[epoch5, step2073]: loss 1.923232
[epoch5, step2074]: loss 3.891798
[epoch5, step2075]: loss 3.894551
[epoch5, step2076]: loss 2.604615
[epoch5, step2077]: loss 2.338645
[epoch5, step2078]: loss 2.502573
[epoch5, step2079]: loss 5.478971
[epoch5, step2080]: loss 6.068604
[epoch5, step2081]: loss 39.498501
[epoch5, step2082]: loss 17.802649
[epoch5, step2083]: loss 2.835914
[epoch5, step2084]: loss 3.444985
[epoch5, step2085]: loss 1.781008
[epoch5, step2086]: loss 1.767458
[epoch5, step2087]: loss 2.907430
[epoch5, step2088]: loss 2.470989
[epoch5, step2089]: loss 32.585934
[epoch5, step2090]: loss 2.467464
[epoch5, step2091]: loss 3.584400
[epoch5, step2092]: loss 19.275812
[epoch5, step2093]: loss 4.093926
[epoch5, step2094]: loss 8.485611
[epoch5, step2095]: loss 16.808271
[epoch5, step2096]: loss 11.399406
[epoch5, step2097]: loss 1.457092
[epoch5, step2098]: loss 37.065948
[epoch5, step2099]: loss 2.880455
[epoch5, step2100]: loss 4.579803
[epoch5, step2101]: loss 44.679909
[epoch5, step2102]: loss 3.310876
[epoch5, step2103]: loss 12.401065
[epoch5, step2104]: loss 2.831031
[epoch5, step2105]: loss 3.050748
[epoch5, step2106]: loss 5.928144
[epoch5, step2107]: loss 27.800058
[epoch5, step2108]: loss 22.458370
[epoch5, step2109]: loss 11.284978
[epoch5, step2110]: loss 32.247089
[epoch5, step2111]: loss 6.805273
[epoch5, step2112]: loss 1.783939
[epoch5, step2113]: loss 2.718071
[epoch5, step2114]: loss 11.835044
[epoch5, step2115]: loss 2.964338
[epoch5, step2116]: loss 6.884945
[epoch5, step2117]: loss 11.055849
[epoch5, step2118]: loss 16.228027
[epoch5, step2119]: loss 3.365472
[epoch5, step2120]: loss 4.436114
[epoch5, step2121]: loss 6.072158
[epoch5, step2122]: loss 19.494408
[epoch5, step2123]: loss 23.913963
[epoch5, step2124]: loss 60.202694
[epoch5, step2125]: loss 34.747002
[epoch5, step2126]: loss 4.702443
[epoch5, step2127]: loss 2.592322
[epoch5, step2128]: loss 1.780521
[epoch5, step2129]: loss 30.996092
[epoch5, step2130]: loss 6.180031
[epoch5, step2131]: loss 20.108522
[epoch5, step2132]: loss 29.102730
[epoch5, step2133]: loss 2.560674
[epoch5, step2134]: loss 17.008287
[epoch5, step2135]: loss 9.269912
[epoch5, step2136]: loss 10.584363
[epoch5, step2137]: loss 6.120939
[epoch5, step2138]: loss 22.240705
[epoch5, step2139]: loss 8.334906
[epoch5, step2140]: loss 22.733759
[epoch5, step2141]: loss 1.878457
[epoch5, step2142]: loss 8.082220
[epoch5, step2143]: loss 2.875228
[epoch5, step2144]: loss 4.858745
[epoch5, step2145]: loss 2.619573
[epoch5, step2146]: loss 10.496949
[epoch5, step2147]: loss 2.303529
[epoch5, step2148]: loss 3.379208
[epoch5, step2149]: loss 2.848428
[epoch5, step2150]: loss 21.165419
[epoch5, step2151]: loss 18.267458
[epoch5, step2152]: loss 4.686539
[epoch5, step2153]: loss 22.242712
[epoch5, step2154]: loss 3.965718
[epoch5, step2155]: loss 3.128317
[epoch5, step2156]: loss 3.019919
[epoch5, step2157]: loss 10.926545
[epoch5, step2158]: loss 24.031647
[epoch5, step2159]: loss 27.590441
[epoch5, step2160]: loss 1.974176
[epoch5, step2161]: loss 2.487573
[epoch5, step2162]: loss 7.400048
[epoch5, step2163]: loss 5.613290
[epoch5, step2164]: loss 3.729484
[epoch5, step2165]: loss 19.244469
[epoch5, step2166]: loss 29.534277
[epoch5, step2167]: loss 2.909570
[epoch5, step2168]: loss 32.828049
[epoch5, step2169]: loss 20.471558
[epoch5, step2170]: loss 24.308195
[epoch5, step2171]: loss 3.019347
[epoch5, step2172]: loss 26.069244
[epoch5, step2173]: loss 8.235035
[epoch5, step2174]: loss 2.648651
[epoch5, step2175]: loss 2.630767
[epoch5, step2176]: loss 3.014211
[epoch5, step2177]: loss 3.311144
[epoch5, step2178]: loss 4.456342
[epoch5, step2179]: loss 20.836695
[epoch5, step2180]: loss 3.414080
[epoch5, step2181]: loss 3.313448
[epoch5, step2182]: loss 18.913780
[epoch5, step2183]: loss 26.826576
[epoch5, step2184]: loss 11.331141
[epoch5, step2185]: loss 1.906026
[epoch5, step2186]: loss 1.893461
[epoch5, step2187]: loss 5.575867
[epoch5, step2188]: loss 1.962772
[epoch5, step2189]: loss 7.520072
[epoch5, step2190]: loss 4.823234
[epoch5, step2191]: loss 22.378651
[epoch5, step2192]: loss 22.052237
[epoch5, step2193]: loss 3.093441
[epoch5, step2194]: loss 4.481461
[epoch5, step2195]: loss 4.196275
[epoch5, step2196]: loss 26.245401
[epoch5, step2197]: loss 5.263577
[epoch5, step2198]: loss 1.480892
[epoch5, step2199]: loss 5.842339
[epoch5, step2200]: loss 6.254711
[epoch5, step2201]: loss 4.142234
[epoch5, step2202]: loss 7.932169
[epoch5, step2203]: loss 10.033245
[epoch5, step2204]: loss 3.188146
[epoch5, step2205]: loss 7.410385
[epoch5, step2206]: loss 16.066319
[epoch5, step2207]: loss 1.969913
[epoch5, step2208]: loss 25.790598
[epoch5, step2209]: loss 7.475918
[epoch5, step2210]: loss 3.704310
[epoch5, step2211]: loss 3.189703
[epoch5, step2212]: loss 6.118467
[epoch5, step2213]: loss 23.638897
[epoch5, step2214]: loss 2.568065
[epoch5, step2215]: loss 1.158387
[epoch5, step2216]: loss 27.375971
[epoch5, step2217]: loss 19.327477
[epoch5, step2218]: loss 2.061241
[epoch5, step2219]: loss 6.330774
[epoch5, step2220]: loss 19.695862
[epoch5, step2221]: loss 14.409883
[epoch5, step2222]: loss 7.676821
[epoch5, step2223]: loss 7.554576
[epoch5, step2224]: loss 2.590297
[epoch5, step2225]: loss 19.004505
[epoch5, step2226]: loss 2.845309
[epoch5, step2227]: loss 11.411475
[epoch5, step2228]: loss 7.687945
[epoch5, step2229]: loss 14.151004
[epoch5, step2230]: loss 9.849600
[epoch5, step2231]: loss 3.700570
[epoch5, step2232]: loss 5.013272
[epoch5, step2233]: loss 8.139297
[epoch5, step2234]: loss 22.529272
[epoch5, step2235]: loss 5.871249
[epoch5, step2236]: loss 15.386143
[epoch5, step2237]: loss 1.708944
[epoch5, step2238]: loss 2.589731
[epoch5, step2239]: loss 5.432687
[epoch5, step2240]: loss 4.797232
[epoch5, step2241]: loss 3.771241
[epoch5, step2242]: loss 6.410129
[epoch5, step2243]: loss 2.640830
[epoch5, step2244]: loss 38.926838
[epoch5, step2245]: loss 3.379916
[epoch5, step2246]: loss 3.424673
[epoch5, step2247]: loss 12.703180
[epoch5, step2248]: loss 2.081175
[epoch5, step2249]: loss 2.455935
[epoch5, step2250]: loss 12.377740
[epoch5, step2251]: loss 26.795771
[epoch5, step2252]: loss 9.793983
[epoch5, step2253]: loss 18.913023
[epoch5, step2254]: loss 32.463959
[epoch5, step2255]: loss 32.100029
[epoch5, step2256]: loss 3.461714
[epoch5, step2257]: loss 4.453260
[epoch5, step2258]: loss 10.119617
[epoch5, step2259]: loss 4.904329
[epoch5, step2260]: loss 1.623707
[epoch5, step2261]: loss 9.278913
[epoch5, step2262]: loss 34.493092
[epoch5, step2263]: loss 2.569714
[epoch5, step2264]: loss 3.754647
[epoch5, step2265]: loss 1.729913
[epoch5, step2266]: loss 1.556860
[epoch5, step2267]: loss 10.306498
[epoch5, step2268]: loss 23.416931
[epoch5, step2269]: loss 2.402479
[epoch5, step2270]: loss 3.080155
[epoch5, step2271]: loss 4.233906
[epoch5, step2272]: loss 11.413582
[epoch5, step2273]: loss 2.073228
[epoch5, step2274]: loss 5.071289
[epoch5, step2275]: loss 3.206403
[epoch5, step2276]: loss 15.507030
[epoch5, step2277]: loss 22.611385
[epoch5, step2278]: loss 1.692830
[epoch5, step2279]: loss 3.381213
[epoch5, step2280]: loss 6.789383
[epoch5, step2281]: loss 2.759768
[epoch5, step2282]: loss 1.490731
[epoch5, step2283]: loss 2.235991
[epoch5, step2284]: loss 19.046223
[epoch5, step2285]: loss 5.427209
[epoch5, step2286]: loss 28.917255
[epoch5, step2287]: loss 6.455001
[epoch5, step2288]: loss 6.224008
[epoch5, step2289]: loss 8.300058
[epoch5, step2290]: loss 40.174961
[epoch5, step2291]: loss 5.323775
[epoch5, step2292]: loss 8.799427
[epoch5, step2293]: loss 10.450571
[epoch5, step2294]: loss 8.942516
[epoch5, step2295]: loss 8.829449
[epoch5, step2296]: loss 5.892379
[epoch5, step2297]: loss 1.707185
[epoch5, step2298]: loss 4.125996
[epoch5, step2299]: loss 6.417007
[epoch5, step2300]: loss 13.276169
[epoch5, step2301]: loss 5.625731
[epoch5, step2302]: loss 5.174441
[epoch5, step2303]: loss 3.021389
[epoch5, step2304]: loss 4.856937
[epoch5, step2305]: loss 6.713353
[epoch5, step2306]: loss 17.283913
[epoch5, step2307]: loss 8.818588
[epoch5, step2308]: loss 4.380673
[epoch5, step2309]: loss 3.150880
[epoch5, step2310]: loss 3.904250
[epoch5, step2311]: loss 19.839401
[epoch5, step2312]: loss 11.174400
[epoch5, step2313]: loss 9.292428
[epoch5, step2314]: loss 4.419578
[epoch5, step2315]: loss 18.249994
[epoch5, step2316]: loss 3.980075
[epoch5, step2317]: loss 2.315922
[epoch5, step2318]: loss 57.945915
[epoch5, step2319]: loss 23.014551
[epoch5, step2320]: loss 6.728393
[epoch5, step2321]: loss 13.541147
[epoch5, step2322]: loss 3.024276
[epoch5, step2323]: loss 29.108410
[epoch5, step2324]: loss 1.997474
[epoch5, step2325]: loss 8.723257
[epoch5, step2326]: loss 9.630629
[epoch5, step2327]: loss 13.991379
[epoch5, step2328]: loss 2.750750
[epoch5, step2329]: loss 3.452871
[epoch5, step2330]: loss 2.676450
[epoch5, step2331]: loss 3.191720
[epoch5, step2332]: loss 2.336401
[epoch5, step2333]: loss 2.925896
[epoch5, step2334]: loss 27.389774
[epoch5, step2335]: loss 1.853994
[epoch5, step2336]: loss 10.163757
[epoch5, step2337]: loss 2.408788
[epoch5, step2338]: loss 2.384030
[epoch5, step2339]: loss 3.587100
[epoch5, step2340]: loss 19.393459
[epoch5, step2341]: loss 3.083081
[epoch5, step2342]: loss 18.966536
[epoch5, step2343]: loss 1.794442
[epoch5, step2344]: loss 9.454119
[epoch5, step2345]: loss 10.067760
[epoch5, step2346]: loss 20.657013
[epoch5, step2347]: loss 25.215218
[epoch5, step2348]: loss 4.643229
[epoch5, step2349]: loss 7.332444
[epoch5, step2350]: loss 25.250916
[epoch5, step2351]: loss 5.434698
[epoch5, step2352]: loss 3.899787
[epoch5, step2353]: loss 4.701952
[epoch5, step2354]: loss 34.752319
[epoch5, step2355]: loss 2.609394
[epoch5, step2356]: loss 17.064938
[epoch5, step2357]: loss 17.555552
[epoch5, step2358]: loss 17.544985
[epoch5, step2359]: loss 7.394100
[epoch5, step2360]: loss 4.059702
[epoch5, step2361]: loss 23.954580
[epoch5, step2362]: loss 26.386597
[epoch5, step2363]: loss 11.724328
[epoch5, step2364]: loss 1.504618
[epoch5, step2365]: loss 8.401192
[epoch5, step2366]: loss 3.072320
[epoch5, step2367]: loss 2.501518
[epoch5, step2368]: loss 4.019414
[epoch5, step2369]: loss 3.139182
[epoch5, step2370]: loss 2.003408
[epoch5, step2371]: loss 2.170189
[epoch5, step2372]: loss 1.911783
[epoch5, step2373]: loss 2.571606
[epoch5, step2374]: loss 4.080686
[epoch5, step2375]: loss 7.478574
[epoch5, step2376]: loss 4.931797
[epoch5, step2377]: loss 10.629554
[epoch5, step2378]: loss 18.609915
[epoch5, step2379]: loss 5.159074
[epoch5, step2380]: loss 5.501947
[epoch5, step2381]: loss 5.742044
[epoch5, step2382]: loss 3.751908
[epoch5, step2383]: loss 9.031867
[epoch5, step2384]: loss 4.254509
[epoch5, step2385]: loss 2.548843
[epoch5, step2386]: loss 5.578221
[epoch5, step2387]: loss 22.289825
[epoch5, step2388]: loss 2.107140
[epoch5, step2389]: loss 3.736031
[epoch5, step2390]: loss 4.129906
[epoch5, step2391]: loss 20.046827
[epoch5, step2392]: loss 22.751122
[epoch5, step2393]: loss 3.950195
[epoch5, step2394]: loss 11.803966
[epoch5, step2395]: loss 3.707784
[epoch5, step2396]: loss 3.394825
[epoch5, step2397]: loss 16.524920
[epoch5, step2398]: loss 5.701969
[epoch5, step2399]: loss 32.427959
[epoch5, step2400]: loss 2.528079
[epoch5, step2401]: loss 2.518997
[epoch5, step2402]: loss 3.925611
[epoch5, step2403]: loss 2.905555
[epoch5, step2404]: loss 7.654982
[epoch5, step2405]: loss 18.505487
[epoch5, step2406]: loss 18.170233
[epoch5, step2407]: loss 21.511366
[epoch5, step2408]: loss 5.464668
[epoch5, step2409]: loss 5.372339
[epoch5, step2410]: loss 9.215068
[epoch5, step2411]: loss 5.229526
[epoch5, step2412]: loss 8.779545
[epoch5, step2413]: loss 4.024750
[epoch5, step2414]: loss 14.106394
[epoch5, step2415]: loss 3.215069
[epoch5, step2416]: loss 6.157229
[epoch5, step2417]: loss 5.502337
[epoch5, step2418]: loss 17.823483
[epoch5, step2419]: loss 2.895998
[epoch5, step2420]: loss 30.343590
[epoch5, step2421]: loss 5.582839
[epoch5, step2422]: loss 4.220285
[epoch5, step2423]: loss 19.932161
[epoch5, step2424]: loss 8.865380
[epoch5, step2425]: loss 2.484450
[epoch5, step2426]: loss 1.901823
[epoch5, step2427]: loss 40.266441
[epoch5, step2428]: loss 8.321625
[epoch5, step2429]: loss 1.980059
[epoch5, step2430]: loss 13.485009
[epoch5, step2431]: loss 1.826249
[epoch5, step2432]: loss 17.779285
[epoch5, step2433]: loss 4.375622
[epoch5, step2434]: loss 22.480957
[epoch5, step2435]: loss 11.718344
[epoch5, step2436]: loss 9.073104
[epoch5, step2437]: loss 30.430635
[epoch5, step2438]: loss 9.960851
[epoch5, step2439]: loss 2.979373
[epoch5, step2440]: loss 17.540525
[epoch5, step2441]: loss 2.320276
[epoch5, step2442]: loss 11.987905
[epoch5, step2443]: loss 1.738979
[epoch5, step2444]: loss 2.824289
[epoch5, step2445]: loss 2.148444
[epoch5, step2446]: loss 4.252530
[epoch5, step2447]: loss 2.918835
[epoch5, step2448]: loss 2.447839
[epoch5, step2449]: loss 7.177238
[epoch5, step2450]: loss 2.883445
[epoch5, step2451]: loss 7.176598
[epoch5, step2452]: loss 7.055484
[epoch5, step2453]: loss 2.377798
[epoch5, step2454]: loss 2.642562
[epoch5, step2455]: loss 19.160509
[epoch5, step2456]: loss 5.037162
[epoch5, step2457]: loss 1.988533
[epoch5, step2458]: loss 3.832665
[epoch5, step2459]: loss 12.077685
[epoch5, step2460]: loss 3.096318
[epoch5, step2461]: loss 11.642172
[epoch5, step2462]: loss 7.166803
[epoch5, step2463]: loss 9.400940
[epoch5, step2464]: loss 4.917760
[epoch5, step2465]: loss 1.861034
[epoch5, step2466]: loss 3.480101
[epoch5, step2467]: loss 22.836367
[epoch5, step2468]: loss 7.135676
[epoch5, step2469]: loss 16.815044
[epoch5, step2470]: loss 3.939823
[epoch5, step2471]: loss 9.164576
[epoch5, step2472]: loss 2.982929
[epoch5, step2473]: loss 7.672276
[epoch5, step2474]: loss 26.165436
[epoch5, step2475]: loss 27.887171
[epoch5, step2476]: loss 5.069136
[epoch5, step2477]: loss 19.645414
[epoch5, step2478]: loss 8.369583
[epoch5, step2479]: loss 4.217890
[epoch5, step2480]: loss 2.646718
[epoch5, step2481]: loss 2.579643
[epoch5, step2482]: loss 6.702032
[epoch5, step2483]: loss 2.158970
[epoch5, step2484]: loss 3.959123
[epoch5, step2485]: loss 18.467781
[epoch5, step2486]: loss 25.615536
[epoch5, step2487]: loss 7.029137
[epoch5, step2488]: loss 9.172901
[epoch5, step2489]: loss 8.630702
[epoch5, step2490]: loss 5.521454
[epoch5, step2491]: loss 2.171043
[epoch5, step2492]: loss 3.640973
[epoch5, step2493]: loss 5.151175
[epoch5, step2494]: loss 2.801283
[epoch5, step2495]: loss 18.829180
[epoch5, step2496]: loss 24.998432
[epoch5, step2497]: loss 34.638905
[epoch5, step2498]: loss 2.914042
[epoch5, step2499]: loss 5.128274
[epoch5, step2500]: loss 3.893527
[epoch5, step2501]: loss 8.281937
[epoch5, step2502]: loss 6.974259
[epoch5, step2503]: loss 3.096248
[epoch5, step2504]: loss 9.578126
[epoch5, step2505]: loss 9.548067
[epoch5, step2506]: loss 4.390267
[epoch5, step2507]: loss 3.304628
[epoch5, step2508]: loss 1.529412
[epoch5, step2509]: loss 57.352055
[epoch5, step2510]: loss 3.524653
[epoch5, step2511]: loss 30.464241
[epoch5, step2512]: loss 2.200557
[epoch5, step2513]: loss 3.377462
[epoch5, step2514]: loss 1.905104
[epoch5, step2515]: loss 2.584264
[epoch5, step2516]: loss 24.077599
[epoch5, step2517]: loss 1.832088
[epoch5, step2518]: loss 7.484244
[epoch5, step2519]: loss 1.441302
[epoch5, step2520]: loss 1.930319
[epoch5, step2521]: loss 17.175743
[epoch5, step2522]: loss 37.618965
[epoch5, step2523]: loss 7.980314
[epoch5, step2524]: loss 7.643314
[epoch5, step2525]: loss 28.089619
[epoch5, step2526]: loss 2.254042
[epoch5, step2527]: loss 10.084551
[epoch5, step2528]: loss 19.047264
[epoch5, step2529]: loss 2.676790
[epoch5, step2530]: loss 4.458502
[epoch5, step2531]: loss 2.557858
[epoch5, step2532]: loss 10.224456
[epoch5, step2533]: loss 3.770413
[epoch5, step2534]: loss 34.630711
[epoch5, step2535]: loss 5.580986
[epoch5, step2536]: loss 25.624857
[epoch5, step2537]: loss 4.463534
[epoch5, step2538]: loss 7.913890
[epoch5, step2539]: loss 49.720764
[epoch5, step2540]: loss 4.545438
[epoch5, step2541]: loss 7.350902
[epoch5, step2542]: loss 31.100475
[epoch5, step2543]: loss 19.004835
[epoch5, step2544]: loss 16.166384
[epoch5, step2545]: loss 1.482552
[epoch5, step2546]: loss 1.458596
[epoch5, step2547]: loss 2.652546
[epoch5, step2548]: loss 7.870449
[epoch5, step2549]: loss 2.151769
[epoch5, step2550]: loss 16.927561
[epoch5, step2551]: loss 9.868576
[epoch5, step2552]: loss 2.027734
[epoch5, step2553]: loss 8.575498
[epoch5, step2554]: loss 3.435570
[epoch5, step2555]: loss 3.049186
[epoch5, step2556]: loss 30.325220
[epoch5, step2557]: loss 3.002875
[epoch5, step2558]: loss 15.119221
[epoch5, step2559]: loss 3.773392
[epoch5, step2560]: loss 3.928196
[epoch5, step2561]: loss 1.652276
[epoch5, step2562]: loss 7.699316
[epoch5, step2563]: loss 6.790715
[epoch5, step2564]: loss 5.021332
[epoch5, step2565]: loss 1.973632
[epoch5, step2566]: loss 3.653172
[epoch5, step2567]: loss 18.354153
[epoch5, step2568]: loss 2.864820
[epoch5, step2569]: loss 18.015625
[epoch5, step2570]: loss 46.025146
[epoch5, step2571]: loss 6.369517
[epoch5, step2572]: loss 3.563472
[epoch5, step2573]: loss 2.491229
[epoch5, step2574]: loss 5.883636
[epoch5, step2575]: loss 7.133856
[epoch5, step2576]: loss 19.020506
[epoch5, step2577]: loss 9.842898
[epoch5, step2578]: loss 3.464121
[epoch5, step2579]: loss 25.352646
[epoch5, step2580]: loss 12.743973
[epoch5, step2581]: loss 8.112251
[epoch5, step2582]: loss 21.068554
[epoch5, step2583]: loss 3.118109
[epoch5, step2584]: loss 17.633966
[epoch5, step2585]: loss 10.057543
[epoch5, step2586]: loss 27.887980
[epoch5, step2587]: loss 2.850306
[epoch5, step2588]: loss 6.307113
[epoch5, step2589]: loss 4.849575
[epoch5, step2590]: loss 9.344483
[epoch5, step2591]: loss 24.095140
[epoch5, step2592]: loss 24.871861
[epoch5, step2593]: loss 10.955043
[epoch5, step2594]: loss 5.334606
[epoch5, step2595]: loss 8.359220
[epoch5, step2596]: loss 7.367116
[epoch5, step2597]: loss 3.302069
[epoch5, step2598]: loss 3.430049
[epoch5, step2599]: loss 5.251355
[epoch5, step2600]: loss 1.690285
[epoch5, step2601]: loss 5.755397
[epoch5, step2602]: loss 14.656416
[epoch5, step2603]: loss 2.532754
[epoch5, step2604]: loss 2.349946
[epoch5, step2605]: loss 1.878150
[epoch5, step2606]: loss 7.493386
[epoch5, step2607]: loss 17.656303
[epoch5, step2608]: loss 2.713199
[epoch5, step2609]: loss 2.229227
[epoch5, step2610]: loss 11.059723
[epoch5, step2611]: loss 14.804364
[epoch5, step2612]: loss 3.057066
[epoch5, step2613]: loss 29.215729
[epoch5, step2614]: loss 3.416664
[epoch5, step2615]: loss 2.710746
[epoch5, step2616]: loss 16.494171
[epoch5, step2617]: loss 4.653357
[epoch5, step2618]: loss 3.646163
[epoch5, step2619]: loss 17.891438
[epoch5, step2620]: loss 5.235085
[epoch5, step2621]: loss 2.242885
[epoch5, step2622]: loss 1.541184
[epoch5, step2623]: loss 4.930370
[epoch5, step2624]: loss 7.299614
[epoch5, step2625]: loss 2.345537
[epoch5, step2626]: loss 3.579284
[epoch5, step2627]: loss 2.524545
[epoch5, step2628]: loss 4.120433
[epoch5, step2629]: loss 3.261457
[epoch5, step2630]: loss 2.584415
[epoch5, step2631]: loss 23.920765
[epoch5, step2632]: loss 5.151058
[epoch5, step2633]: loss 8.127362
[epoch5, step2634]: loss 1.831699
[epoch5, step2635]: loss 6.253435
[epoch5, step2636]: loss 9.277851
[epoch5, step2637]: loss 2.750288
[epoch5, step2638]: loss 2.414166
[epoch5, step2639]: loss 2.817487
[epoch5, step2640]: loss 19.466372
[epoch5, step2641]: loss 5.473518
[epoch5, step2642]: loss 2.096681
[epoch5, step2643]: loss 24.834511
[epoch5, step2644]: loss 10.244747
[epoch5, step2645]: loss 23.881678
[epoch5, step2646]: loss 39.452366
[epoch5, step2647]: loss 24.824343
[epoch5, step2648]: loss 4.868431
[epoch5, step2649]: loss 3.615085
[epoch5, step2650]: loss 3.623880
[epoch5, step2651]: loss 5.106657
[epoch5, step2652]: loss 8.156866
[epoch5, step2653]: loss 23.692385
[epoch5, step2654]: loss 3.754200
[epoch5, step2655]: loss 21.535227
[epoch5, step2656]: loss 5.344378
[epoch5, step2657]: loss 1.982557
[epoch5, step2658]: loss 1.528661
[epoch5, step2659]: loss 1.455177
[epoch5, step2660]: loss 4.573987
[epoch5, step2661]: loss 3.356310
[epoch5, step2662]: loss 5.453346
[epoch5, step2663]: loss 5.271154
[epoch5, step2664]: loss 3.131567
[epoch5, step2665]: loss 9.625381
[epoch5, step2666]: loss 3.367024
[epoch5, step2667]: loss 24.129164
[epoch5, step2668]: loss 2.579971
[epoch5, step2669]: loss 8.133211
[epoch5, step2670]: loss 1.912842
[epoch5, step2671]: loss 2.106175
[epoch5, step2672]: loss 25.345522
[epoch5, step2673]: loss 19.841896
[epoch5, step2674]: loss 2.954678
[epoch5, step2675]: loss 9.136603
[epoch5, step2676]: loss 13.539318
[epoch5, step2677]: loss 2.105142
[epoch5, step2678]: loss 9.857487
[epoch5, step2679]: loss 20.631620
[epoch5, step2680]: loss 2.234492
[epoch5, step2681]: loss 16.308987
[epoch5, step2682]: loss 15.744141
[epoch5, step2683]: loss 2.524569
[epoch5, step2684]: loss 18.384979
[epoch5, step2685]: loss 14.796007
[epoch5, step2686]: loss 34.562389
[epoch5, step2687]: loss 7.410077
[epoch5, step2688]: loss 4.230375
[epoch5, step2689]: loss 9.701244
[epoch5, step2690]: loss 11.925615
[epoch5, step2691]: loss 10.029594
[epoch5, step2692]: loss 1.813271
[epoch5, step2693]: loss 36.899731
[epoch5, step2694]: loss 2.304024
[epoch5, step2695]: loss 12.155512
[epoch5, step2696]: loss 12.467767
[epoch5, step2697]: loss 9.562841
[epoch5, step2698]: loss 12.458128
[epoch5, step2699]: loss 8.256076
[epoch5, step2700]: loss 7.986907
[epoch5, step2701]: loss 4.136166
[epoch5, step2702]: loss 2.850720
[epoch5, step2703]: loss 17.360508
[epoch5, step2704]: loss 5.792289
[epoch5, step2705]: loss 3.238404
[epoch5, step2706]: loss 3.234343
[epoch5, step2707]: loss 5.069525
[epoch5, step2708]: loss 32.071236
[epoch5, step2709]: loss 35.626541
[epoch5, step2710]: loss 30.576504
[epoch5, step2711]: loss 9.726133
[epoch5, step2712]: loss 4.881584
[epoch5, step2713]: loss 3.760366
[epoch5, step2714]: loss 6.548573
[epoch5, step2715]: loss 7.247032
[epoch5, step2716]: loss 5.364853
[epoch5, step2717]: loss 2.169722
[epoch5, step2718]: loss 2.633516
[epoch5, step2719]: loss 4.319223
[epoch5, step2720]: loss 7.835851
[epoch5, step2721]: loss 5.153738
[epoch5, step2722]: loss 1.995223
[epoch5, step2723]: loss 3.137765
[epoch5, step2724]: loss 2.814419
[epoch5, step2725]: loss 5.258488
[epoch5, step2726]: loss 8.217213
[epoch5, step2727]: loss 3.584008
[epoch5, step2728]: loss 4.542574
[epoch5, step2729]: loss 11.552036
[epoch5, step2730]: loss 2.760763
[epoch5, step2731]: loss 23.998566
[epoch5, step2732]: loss 3.409519
[epoch5, step2733]: loss 3.456996
[epoch5, step2734]: loss 25.170963
[epoch5, step2735]: loss 2.770512
[epoch5, step2736]: loss 2.256002
[epoch5, step2737]: loss 13.264517
[epoch5, step2738]: loss 2.779860
[epoch5, step2739]: loss 3.337539
[epoch5, step2740]: loss 2.915559
[epoch5, step2741]: loss 9.431610
[epoch5, step2742]: loss 4.284770
[epoch5, step2743]: loss 2.865949
[epoch5, step2744]: loss 2.396424
[epoch5, step2745]: loss 5.136611
[epoch5, step2746]: loss 2.177615
[epoch5, step2747]: loss 32.704853
[epoch5, step2748]: loss 6.892764
[epoch5, step2749]: loss 28.602440
[epoch5, step2750]: loss 18.497866
[epoch5, step2751]: loss 21.254452
[epoch5, step2752]: loss 2.089478
[epoch5, step2753]: loss 23.544828
[epoch5, step2754]: loss 2.372091
[epoch5, step2755]: loss 11.080626
[epoch5, step2756]: loss 2.076083
[epoch5, step2757]: loss 6.479613
[epoch5, step2758]: loss 26.542950
[epoch5, step2759]: loss 9.980390
[epoch5, step2760]: loss 24.435917
[epoch5, step2761]: loss 3.574669
[epoch5, step2762]: loss 2.524402
[epoch5, step2763]: loss 4.833212
[epoch5, step2764]: loss 2.896674
[epoch5, step2765]: loss 1.699405
[epoch5, step2766]: loss 3.132589
[epoch5, step2767]: loss 4.231236
[epoch5, step2768]: loss 19.972313
[epoch5, step2769]: loss 8.953279
[epoch5, step2770]: loss 3.875698
[epoch5, step2771]: loss 2.971872
[epoch5, step2772]: loss 24.646183
[epoch5, step2773]: loss 2.323686
[epoch5, step2774]: loss 18.822290
[epoch5, step2775]: loss 5.293900
[epoch5, step2776]: loss 16.156723
[epoch5, step2777]: loss 2.905110
[epoch5, step2778]: loss 34.212212
[epoch5, step2779]: loss 30.381378
[epoch5, step2780]: loss 2.967221
[epoch5, step2781]: loss 4.321334
[epoch5, step2782]: loss 2.868087
[epoch5, step2783]: loss 8.118024
[epoch5, step2784]: loss 5.052203
[epoch5, step2785]: loss 5.198760
[epoch5, step2786]: loss 21.380520
[epoch5, step2787]: loss 4.130576
[epoch5, step2788]: loss 22.570759
[epoch5, step2789]: loss 1.869997
[epoch5, step2790]: loss 3.898793
[epoch5, step2791]: loss 4.973370
[epoch5, step2792]: loss 10.306869
[epoch5, step2793]: loss 22.366405
[epoch5, step2794]: loss 6.806919
[epoch5, step2795]: loss 7.252885
[epoch5, step2796]: loss 2.423504
[epoch5, step2797]: loss 17.483347
[epoch5, step2798]: loss 3.196307
[epoch5, step2799]: loss 12.628361
[epoch5, step2800]: loss 19.456060
[epoch5, step2801]: loss 11.205005
[epoch5, step2802]: loss 2.805751
[epoch5, step2803]: loss 12.855275
[epoch5, step2804]: loss 1.792566
[epoch5, step2805]: loss 25.933849
[epoch5, step2806]: loss 9.223969
[epoch5, step2807]: loss 28.893894
[epoch5, step2808]: loss 6.854744
[epoch5, step2809]: loss 6.613243
[epoch5, step2810]: loss 16.003119
[epoch5, step2811]: loss 39.350498
[epoch5, step2812]: loss 3.175577
[epoch5, step2813]: loss 2.775649
[epoch5, step2814]: loss 32.744846
[epoch5, step2815]: loss 5.241923
[epoch5, step2816]: loss 8.458680
[epoch5, step2817]: loss 14.157387
[epoch5, step2818]: loss 4.311760
[epoch5, step2819]: loss 2.356599
[epoch5, step2820]: loss 16.730350
[epoch5, step2821]: loss 14.163309
[epoch5, step2822]: loss 5.746209
[epoch5, step2823]: loss 3.052722
[epoch5, step2824]: loss 17.884668
[epoch5, step2825]: loss 2.787164
[epoch5, step2826]: loss 11.108408
[epoch5, step2827]: loss 5.437842
[epoch5, step2828]: loss 5.814005
[epoch5, step2829]: loss 3.412171
[epoch5, step2830]: loss 18.036467
[epoch5, step2831]: loss 8.082238
[epoch5, step2832]: loss 4.222868
[epoch5, step2833]: loss 21.891329
[epoch5, step2834]: loss 2.546910
[epoch5, step2835]: loss 2.148282
[epoch5, step2836]: loss 8.011114
[epoch5, step2837]: loss 4.168448
[epoch5, step2838]: loss 6.015911
[epoch5, step2839]: loss 3.669143
[epoch5, step2840]: loss 3.300596
[epoch5, step2841]: loss 5.352036
[epoch5, step2842]: loss 1.688722
[epoch5, step2843]: loss 4.293854
[epoch5, step2844]: loss 6.462375
[epoch5, step2845]: loss 22.085648
[epoch5, step2846]: loss 6.469749
[epoch5, step2847]: loss 8.951557
[epoch5, step2848]: loss 1.968217
[epoch5, step2849]: loss 3.334017
[epoch5, step2850]: loss 33.000298
[epoch5, step2851]: loss 6.863969
[epoch5, step2852]: loss 2.864294
[epoch5, step2853]: loss 7.098001
[epoch5, step2854]: loss 25.268105
[epoch5, step2855]: loss 6.212851
[epoch5, step2856]: loss 6.585728
[epoch5, step2857]: loss 19.080137
[epoch5, step2858]: loss 4.139384
[epoch5, step2859]: loss 4.968228
[epoch5, step2860]: loss 11.944376
[epoch5, step2861]: loss 18.415859
[epoch5, step2862]: loss 4.779054
[epoch5, step2863]: loss 15.302687
[epoch5, step2864]: loss 9.713202
[epoch5, step2865]: loss 2.302788
[epoch5, step2866]: loss 2.494171
[epoch5, step2867]: loss 6.149781
[epoch5, step2868]: loss 20.488007
[epoch5, step2869]: loss 8.678932
[epoch5, step2870]: loss 5.638113
[epoch5, step2871]: loss 4.122205
[epoch5, step2872]: loss 2.712337
[epoch5, step2873]: loss 6.846367
[epoch5, step2874]: loss 8.689534
[epoch5, step2875]: loss 2.466244
[epoch5, step2876]: loss 15.251395
[epoch5, step2877]: loss 30.933477
[epoch5, step2878]: loss 3.712923
[epoch5, step2879]: loss 38.772705
[epoch5, step2880]: loss 7.491711
[epoch5, step2881]: loss 3.568765
[epoch5, step2882]: loss 26.990206
[epoch5, step2883]: loss 12.933123
[epoch5, step2884]: loss 2.317849
[epoch5, step2885]: loss 3.101083
[epoch5, step2886]: loss 47.336052
[epoch5, step2887]: loss 4.612675
[epoch5, step2888]: loss 1.686109
[epoch5, step2889]: loss 6.104686
[epoch5, step2890]: loss 3.683363
[epoch5, step2891]: loss 10.062315
[epoch5, step2892]: loss 2.126046
[epoch5, step2893]: loss 14.466412
[epoch5, step2894]: loss 2.450774
[epoch5, step2895]: loss 18.733248
[epoch5, step2896]: loss 4.394213
[epoch5, step2897]: loss 1.707364
[epoch5, step2898]: loss 29.990700
[epoch5, step2899]: loss 1.940979
[epoch5, step2900]: loss 5.483589
[epoch5, step2901]: loss 10.009624
[epoch5, step2902]: loss 11.535236
[epoch5, step2903]: loss 4.258291
[epoch5, step2904]: loss 6.925820
[epoch5, step2905]: loss 2.009018
[epoch5, step2906]: loss 8.953746
[epoch5, step2907]: loss 4.142266
[epoch5, step2908]: loss 8.166750
[epoch5, step2909]: loss 36.032101
[epoch5, step2910]: loss 3.279700
[epoch5, step2911]: loss 17.717417
[epoch5, step2912]: loss 3.402872
[epoch5, step2913]: loss 1.999925
[epoch5, step2914]: loss 4.420580
[epoch5, step2915]: loss 37.016922
[epoch5, step2916]: loss 10.975709
[epoch5, step2917]: loss 3.187002
[epoch5, step2918]: loss 10.913421
[epoch5, step2919]: loss 2.384576
[epoch5, step2920]: loss 28.020527
[epoch5, step2921]: loss 10.373376
[epoch5, step2922]: loss 3.652656
[epoch5, step2923]: loss 2.778520
[epoch5, step2924]: loss 10.082957
[epoch5, step2925]: loss 6.902217
[epoch5, step2926]: loss 2.491693
[epoch5, step2927]: loss 48.576576
[epoch5, step2928]: loss 5.143649
[epoch5, step2929]: loss 4.305750
[epoch5, step2930]: loss 32.402607
[epoch5, step2931]: loss 2.195167
[epoch5, step2932]: loss 12.254704
[epoch5, step2933]: loss 2.034831
[epoch5, step2934]: loss 1.558727
[epoch5, step2935]: loss 24.914230
[epoch5, step2936]: loss 4.145174
[epoch5, step2937]: loss 5.924588
[epoch5, step2938]: loss 2.000473
[epoch5, step2939]: loss 10.565112
[epoch5, step2940]: loss 6.253607
[epoch5, step2941]: loss 8.959828
[epoch5, step2942]: loss 12.850169
[epoch5, step2943]: loss 46.152355
[epoch5, step2944]: loss 3.719614
[epoch5, step2945]: loss 1.604608
[epoch5, step2946]: loss 2.068481
[epoch5, step2947]: loss 1.638163
[epoch5, step2948]: loss 6.710836
[epoch5, step2949]: loss 25.590099
[epoch5, step2950]: loss 3.132352
[epoch5, step2951]: loss 12.648546
[epoch5, step2952]: loss 32.877712
[epoch5, step2953]: loss 17.692951
[epoch5, step2954]: loss 48.374146
[epoch5, step2955]: loss 19.947403
[epoch5, step2956]: loss 38.470627
[epoch5, step2957]: loss 7.925139
[epoch5, step2958]: loss 3.529660
[epoch5, step2959]: loss 5.422640
[epoch5, step2960]: loss 20.653994
[epoch5, step2961]: loss 8.072137
[epoch5, step2962]: loss 2.439687
[epoch5, step2963]: loss 18.042826
[epoch5, step2964]: loss 24.984959
[epoch5, step2965]: loss 3.019810
[epoch5, step2966]: loss 10.911026
[epoch5, step2967]: loss 5.233336
[epoch5, step2968]: loss 2.693940
[epoch5, step2969]: loss 15.464041
[epoch5, step2970]: loss 2.247472
[epoch5, step2971]: loss 6.819317
[epoch5, step2972]: loss 18.282120
[epoch5, step2973]: loss 18.615837
[epoch5, step2974]: loss 4.619431
[epoch5, step2975]: loss 9.188782
[epoch5, step2976]: loss 6.225057
[epoch5, step2977]: loss 1.297707
[epoch5, step2978]: loss 3.010848
[epoch5, step2979]: loss 20.246002
[epoch5, step2980]: loss 3.608465
[epoch5, step2981]: loss 3.664119
[epoch5, step2982]: loss 4.454415
[epoch5, step2983]: loss 2.205961
[epoch5, step2984]: loss 27.124760
[epoch5, step2985]: loss 17.998058
[epoch5, step2986]: loss 3.560366
[epoch5, step2987]: loss 3.040276
[epoch5, step2988]: loss 2.741265
[epoch5, step2989]: loss 12.326521
[epoch5, step2990]: loss 4.205769
[epoch5, step2991]: loss 23.385792
[epoch5, step2992]: loss 20.964514
[epoch5, step2993]: loss 24.206207
[epoch5, step2994]: loss 2.652181
[epoch5, step2995]: loss 3.677835
[epoch5, step2996]: loss 18.909061
[epoch5, step2997]: loss 3.097096
[epoch5, step2998]: loss 6.933626
[epoch5, step2999]: loss 4.248888
[epoch5, step3000]: loss 45.350197
[epoch5, step3001]: loss 5.162091
[epoch5, step3002]: loss 3.925764
[epoch5, step3003]: loss 3.637603
[epoch5, step3004]: loss 3.212383
[epoch5, step3005]: loss 3.015894
[epoch5, step3006]: loss 22.627020
[epoch5, step3007]: loss 4.416873
[epoch5, step3008]: loss 9.134701
[epoch5, step3009]: loss 3.233458
[epoch5, step3010]: loss 19.568077
[epoch5, step3011]: loss 7.068781
[epoch5, step3012]: loss 25.675081
[epoch5, step3013]: loss 3.734313
[epoch5, step3014]: loss 1.815204
[epoch5, step3015]: loss 9.995136
[epoch5, step3016]: loss 7.843939
[epoch5, step3017]: loss 17.075077
[epoch5, step3018]: loss 6.541568
[epoch5, step3019]: loss 9.362658
[epoch5, step3020]: loss 7.029209
[epoch5, step3021]: loss 3.765965
[epoch5, step3022]: loss 22.510462
[epoch5, step3023]: loss 7.502136
[epoch5, step3024]: loss 9.029481
[epoch5, step3025]: loss 15.965902
[epoch5, step3026]: loss 9.805591
[epoch5, step3027]: loss 4.670185
[epoch5, step3028]: loss 32.818298
[epoch5, step3029]: loss 18.141779
[epoch5, step3030]: loss 18.768824
[epoch5, step3031]: loss 2.666836
[epoch5, step3032]: loss 17.238117
[epoch5, step3033]: loss 11.301831
[epoch5, step3034]: loss 19.278156
[epoch5, step3035]: loss 27.399872
[epoch5, step3036]: loss 18.603531
[epoch5, step3037]: loss 19.753700
[epoch5, step3038]: loss 19.859438
[epoch5, step3039]: loss 2.806409
[epoch5, step3040]: loss 2.890871
[epoch5, step3041]: loss 6.055027
[epoch5, step3042]: loss 26.859400
[epoch5, step3043]: loss 8.169712
[epoch5, step3044]: loss 3.383803
[epoch5, step3045]: loss 6.951261
[epoch5, step3046]: loss 26.981699
[epoch5, step3047]: loss 34.912380
[epoch5, step3048]: loss 21.936049
[epoch5, step3049]: loss 8.247982
[epoch5, step3050]: loss 4.605379
[epoch5, step3051]: loss 25.004419
[epoch5, step3052]: loss 2.116531
[epoch5, step3053]: loss 21.070410
[epoch5, step3054]: loss 2.646464
[epoch5, step3055]: loss 33.089153
[epoch5, step3056]: loss 8.293273
[epoch5, step3057]: loss 3.312255
[epoch5, step3058]: loss 21.677124
[epoch5, step3059]: loss 10.394994
[epoch5, step3060]: loss 7.707046
[epoch5, step3061]: loss 20.960150
[epoch5, step3062]: loss 20.445520
[epoch5, step3063]: loss 1.858692
[epoch5, step3064]: loss 5.269999
[epoch5, step3065]: loss 6.417814
[epoch5, step3066]: loss 6.348992
[epoch5, step3067]: loss 15.082643
[epoch5, step3068]: loss 2.461257
[epoch5, step3069]: loss 1.863896
[epoch5, step3070]: loss 14.090847
[epoch5, step3071]: loss 11.633821
[epoch5, step3072]: loss 35.848976
[epoch5, step3073]: loss 1.859640
[epoch5, step3074]: loss 2.592619
[epoch5, step3075]: loss 3.050606
[epoch5, step3076]: loss 1.952820

[epoch5]: avg loss 1.952820

[epoch6, step1]: loss 17.062525
[epoch6, step2]: loss 18.366112
[epoch6, step3]: loss 3.474977
[epoch6, step4]: loss 5.363661
[epoch6, step5]: loss 22.880392
[epoch6, step6]: loss 6.658204
[epoch6, step7]: loss 2.072616
[epoch6, step8]: loss 40.294304
[epoch6, step9]: loss 2.900687
[epoch6, step10]: loss 16.597685
[epoch6, step11]: loss 1.967591
[epoch6, step12]: loss 18.213350
[epoch6, step13]: loss 3.081892
[epoch6, step14]: loss 4.194879
[epoch6, step15]: loss 3.152735
[epoch6, step16]: loss 4.509370
[epoch6, step17]: loss 4.855500
[epoch6, step18]: loss 7.872537
[epoch6, step19]: loss 7.676290
[epoch6, step20]: loss 10.050076
[epoch6, step21]: loss 3.203134
[epoch6, step22]: loss 3.847687
[epoch6, step23]: loss 4.448836
[epoch6, step24]: loss 2.291011
[epoch6, step25]: loss 2.640257
[epoch6, step26]: loss 1.765162
[epoch6, step27]: loss 1.806275
[epoch6, step28]: loss 5.411958
[epoch6, step29]: loss 22.444229
[epoch6, step30]: loss 3.606780
[epoch6, step31]: loss 3.057036
[epoch6, step32]: loss 3.754687
[epoch6, step33]: loss 3.484847
[epoch6, step34]: loss 12.837333
[epoch6, step35]: loss 5.158255
[epoch6, step36]: loss 8.087933
[epoch6, step37]: loss 7.225741
[epoch6, step38]: loss 4.498390
[epoch6, step39]: loss 22.299704
[epoch6, step40]: loss 14.012161
[epoch6, step41]: loss 5.036803
[epoch6, step42]: loss 5.003235
[epoch6, step43]: loss 5.171749
[epoch6, step44]: loss 8.943131
[epoch6, step45]: loss 18.698853
[epoch6, step46]: loss 1.858644
[epoch6, step47]: loss 8.942713
[epoch6, step48]: loss 13.463255
[epoch6, step49]: loss 25.976040
[epoch6, step50]: loss 2.048903
[epoch6, step51]: loss 8.939600
[epoch6, step52]: loss 6.140154
[epoch6, step53]: loss 2.637216
[epoch6, step54]: loss 2.301006
[epoch6, step55]: loss 3.658695
[epoch6, step56]: loss 3.030478
[epoch6, step57]: loss 2.322510
[epoch6, step58]: loss 28.097647
[epoch6, step59]: loss 1.913995
[epoch6, step60]: loss 4.358143
[epoch6, step61]: loss 10.144999
[epoch6, step62]: loss 41.326660
[epoch6, step63]: loss 26.603790
[epoch6, step64]: loss 4.239824
[epoch6, step65]: loss 6.835245
[epoch6, step66]: loss 4.183737
[epoch6, step67]: loss 1.983011
[epoch6, step68]: loss 29.511887
[epoch6, step69]: loss 13.161236
[epoch6, step70]: loss 7.629022
[epoch6, step71]: loss 6.956597
[epoch6, step72]: loss 26.698210
[epoch6, step73]: loss 5.004987
[epoch6, step74]: loss 26.342241
[epoch6, step75]: loss 4.040159
[epoch6, step76]: loss 2.708237
[epoch6, step77]: loss 25.628353
[epoch6, step78]: loss 22.448259
[epoch6, step79]: loss 7.366998
[epoch6, step80]: loss 4.010790
[epoch6, step81]: loss 4.257498
[epoch6, step82]: loss 9.095310
[epoch6, step83]: loss 11.440676
[epoch6, step84]: loss 9.750339
[epoch6, step85]: loss 3.523933
[epoch6, step86]: loss 7.818333
[epoch6, step87]: loss 2.274245
[epoch6, step88]: loss 18.336195
[epoch6, step89]: loss 5.633712
[epoch6, step90]: loss 9.083547
[epoch6, step91]: loss 34.608166
[epoch6, step92]: loss 19.838703
[epoch6, step93]: loss 14.013458
[epoch6, step94]: loss 30.874264
[epoch6, step95]: loss 48.903580
[epoch6, step96]: loss 30.704779
[epoch6, step97]: loss 2.345252
[epoch6, step98]: loss 2.883220
[epoch6, step99]: loss 22.135225
[epoch6, step100]: loss 1.979802
[epoch6, step101]: loss 5.409308
[epoch6, step102]: loss 1.907489
[epoch6, step103]: loss 2.535944
[epoch6, step104]: loss 25.001953
[epoch6, step105]: loss 18.048527
[epoch6, step106]: loss 30.747681
[epoch6, step107]: loss 4.858719
[epoch6, step108]: loss 2.299255
[epoch6, step109]: loss 9.499102
[epoch6, step110]: loss 2.635727
[epoch6, step111]: loss 11.074044
[epoch6, step112]: loss 3.722924
[epoch6, step113]: loss 19.486279
[epoch6, step114]: loss 17.430202
[epoch6, step115]: loss 10.283683
[epoch6, step116]: loss 19.876875
[epoch6, step117]: loss 3.065355
[epoch6, step118]: loss 2.893759
[epoch6, step119]: loss 20.209076
[epoch6, step120]: loss 8.025743
[epoch6, step121]: loss 10.537360
[epoch6, step122]: loss 3.321478
[epoch6, step123]: loss 2.587936
[epoch6, step124]: loss 3.867991
[epoch6, step125]: loss 2.009593
[epoch6, step126]: loss 3.568468
[epoch6, step127]: loss 2.685062
[epoch6, step128]: loss 6.066927
[epoch6, step129]: loss 9.727710
[epoch6, step130]: loss 4.233153
[epoch6, step131]: loss 3.161069
[epoch6, step132]: loss 27.901772
[epoch6, step133]: loss 5.103385
[epoch6, step134]: loss 5.592022
[epoch6, step135]: loss 3.743681
[epoch6, step136]: loss 2.338494
[epoch6, step137]: loss 6.118053
[epoch6, step138]: loss 2.470224
[epoch6, step139]: loss 8.084839
[epoch6, step140]: loss 1.733126
[epoch6, step141]: loss 7.294179
[epoch6, step142]: loss 4.831503
[epoch6, step143]: loss 10.973063
[epoch6, step144]: loss 12.183762
[epoch6, step145]: loss 43.856762
[epoch6, step146]: loss 3.173141
[epoch6, step147]: loss 25.935297
[epoch6, step148]: loss 4.492698
[epoch6, step149]: loss 3.038823
[epoch6, step150]: loss 9.080515
[epoch6, step151]: loss 2.804819
[epoch6, step152]: loss 25.147011
[epoch6, step153]: loss 8.908300
[epoch6, step154]: loss 16.100849
[epoch6, step155]: loss 4.373465
[epoch6, step156]: loss 13.305097
[epoch6, step157]: loss 1.639806
[epoch6, step158]: loss 1.843940
[epoch6, step159]: loss 3.102569
[epoch6, step160]: loss 2.598996
[epoch6, step161]: loss 5.606981
[epoch6, step162]: loss 1.853426
[epoch6, step163]: loss 4.133982
[epoch6, step164]: loss 2.017662
[epoch6, step165]: loss 16.907495
[epoch6, step166]: loss 3.443307
[epoch6, step167]: loss 7.046652
[epoch6, step168]: loss 3.097556
[epoch6, step169]: loss 29.778753
[epoch6, step170]: loss 3.827617
[epoch6, step171]: loss 9.978440
[epoch6, step172]: loss 2.147722
[epoch6, step173]: loss 9.084888
[epoch6, step174]: loss 10.608351
[epoch6, step175]: loss 1.940131
[epoch6, step176]: loss 4.566357
[epoch6, step177]: loss 1.383209
[epoch6, step178]: loss 5.323848
[epoch6, step179]: loss 6.518709
[epoch6, step180]: loss 19.774710
[epoch6, step181]: loss 2.659635
[epoch6, step182]: loss 4.845323
[epoch6, step183]: loss 3.575410
[epoch6, step184]: loss 18.844252
[epoch6, step185]: loss 25.857603
[epoch6, step186]: loss 9.235638
[epoch6, step187]: loss 28.357313
[epoch6, step188]: loss 3.207106
[epoch6, step189]: loss 5.038857
[epoch6, step190]: loss 26.379303
[epoch6, step191]: loss 2.527908
[epoch6, step192]: loss 2.699498
[epoch6, step193]: loss 1.788620
[epoch6, step194]: loss 3.567345
[epoch6, step195]: loss 24.993696
[epoch6, step196]: loss 8.827499
[epoch6, step197]: loss 48.034424
[epoch6, step198]: loss 3.789964
[epoch6, step199]: loss 5.469126
[epoch6, step200]: loss 5.440999
[epoch6, step201]: loss 4.018342
[epoch6, step202]: loss 3.678049
[epoch6, step203]: loss 6.447556
[epoch6, step204]: loss 34.133961
[epoch6, step205]: loss 8.124820
[epoch6, step206]: loss 3.638275
[epoch6, step207]: loss 12.507580
[epoch6, step208]: loss 10.893381
[epoch6, step209]: loss 3.462974
[epoch6, step210]: loss 1.850548
[epoch6, step211]: loss 2.305559
[epoch6, step212]: loss 1.847145
[epoch6, step213]: loss 19.649340
[epoch6, step214]: loss 25.339380
[epoch6, step215]: loss 4.848340
[epoch6, step216]: loss 4.552030
[epoch6, step217]: loss 10.284636
[epoch6, step218]: loss 3.346215
[epoch6, step219]: loss 24.736315
[epoch6, step220]: loss 53.229004
[epoch6, step221]: loss 5.113232
[epoch6, step222]: loss 19.110903
[epoch6, step223]: loss 14.255800
[epoch6, step224]: loss 27.789562
[epoch6, step225]: loss 5.368218
[epoch6, step226]: loss 4.891071
[epoch6, step227]: loss 22.133488
[epoch6, step228]: loss 4.159768
[epoch6, step229]: loss 2.264367
[epoch6, step230]: loss 3.685502
[epoch6, step231]: loss 2.253527
[epoch6, step232]: loss 4.478527
[epoch6, step233]: loss 3.427778
[epoch6, step234]: loss 3.620676
[epoch6, step235]: loss 8.288514
[epoch6, step236]: loss 3.821505
[epoch6, step237]: loss 12.684259
[epoch6, step238]: loss 2.046826
[epoch6, step239]: loss 8.523308
[epoch6, step240]: loss 2.299349
[epoch6, step241]: loss 2.662803
[epoch6, step242]: loss 2.095016
[epoch6, step243]: loss 2.141284
[epoch6, step244]: loss 1.603938
[epoch6, step245]: loss 6.488277
[epoch6, step246]: loss 22.001709
[epoch6, step247]: loss 4.235993
[epoch6, step248]: loss 7.705490
[epoch6, step249]: loss 2.315213
[epoch6, step250]: loss 17.434898
[epoch6, step251]: loss 2.252231
[epoch6, step252]: loss 20.626045
[epoch6, step253]: loss 16.565723
[epoch6, step254]: loss 2.790355
[epoch6, step255]: loss 19.868681
[epoch6, step256]: loss 1.448563
[epoch6, step257]: loss 7.189909
[epoch6, step258]: loss 8.296006
[epoch6, step259]: loss 27.663088
[epoch6, step260]: loss 68.834389
[epoch6, step261]: loss 4.219597
[epoch6, step262]: loss 11.204236
[epoch6, step263]: loss 16.394060
[epoch6, step264]: loss 19.050253
[epoch6, step265]: loss 1.929482
[epoch6, step266]: loss 2.701112
[epoch6, step267]: loss 2.151979
[epoch6, step268]: loss 33.796101
[epoch6, step269]: loss 43.118248
[epoch6, step270]: loss 10.759035
[epoch6, step271]: loss 1.265409
[epoch6, step272]: loss 8.548922
[epoch6, step273]: loss 62.248798
[epoch6, step274]: loss 17.232489
[epoch6, step275]: loss 2.676600
[epoch6, step276]: loss 3.334304
[epoch6, step277]: loss 2.686286
[epoch6, step278]: loss 39.776424
[epoch6, step279]: loss 2.778539
[epoch6, step280]: loss 3.717767
[epoch6, step281]: loss 4.126846
[epoch6, step282]: loss 16.365511
[epoch6, step283]: loss 2.353132
[epoch6, step284]: loss 3.177087
[epoch6, step285]: loss 3.051545
[epoch6, step286]: loss 18.352730
[epoch6, step287]: loss 1.824063
[epoch6, step288]: loss 4.876369
[epoch6, step289]: loss 19.907375
[epoch6, step290]: loss 18.069895
[epoch6, step291]: loss 12.404221
[epoch6, step292]: loss 7.008415
[epoch6, step293]: loss 4.419429
[epoch6, step294]: loss 9.051998
[epoch6, step295]: loss 19.136726
[epoch6, step296]: loss 17.903297
[epoch6, step297]: loss 25.925083
[epoch6, step298]: loss 6.584720
[epoch6, step299]: loss 33.615379
[epoch6, step300]: loss 20.594528
[epoch6, step301]: loss 5.876849
[epoch6, step302]: loss 9.446140
[epoch6, step303]: loss 26.766459
[epoch6, step304]: loss 34.555325
[epoch6, step305]: loss 1.649063
[epoch6, step306]: loss 3.398577
[epoch6, step307]: loss 2.276400
[epoch6, step308]: loss 37.971611
[epoch6, step309]: loss 5.713003
[epoch6, step310]: loss 2.009393
[epoch6, step311]: loss 20.133928
[epoch6, step312]: loss 4.584427
[epoch6, step313]: loss 15.684328
[epoch6, step314]: loss 4.678788
[epoch6, step315]: loss 4.438752
[epoch6, step316]: loss 3.701939
[epoch6, step317]: loss 24.698839
[epoch6, step318]: loss 3.847801
[epoch6, step319]: loss 2.812260
[epoch6, step320]: loss 13.313869
[epoch6, step321]: loss 3.855771
[epoch6, step322]: loss 37.896671
[epoch6, step323]: loss 23.986267
[epoch6, step324]: loss 5.151750
[epoch6, step325]: loss 7.484233
[epoch6, step326]: loss 23.585588
[epoch6, step327]: loss 19.218447
[epoch6, step328]: loss 35.660633
[epoch6, step329]: loss 7.457345
[epoch6, step330]: loss 2.264119
[epoch6, step331]: loss 31.259735
[epoch6, step332]: loss 2.652554
[epoch6, step333]: loss 31.312603
[epoch6, step334]: loss 18.226618
[epoch6, step335]: loss 36.771957
[epoch6, step336]: loss 23.008614
[epoch6, step337]: loss 4.056320
[epoch6, step338]: loss 5.011158
[epoch6, step339]: loss 4.217838
[epoch6, step340]: loss 1.971696
[epoch6, step341]: loss 3.187907
[epoch6, step342]: loss 2.779174
[epoch6, step343]: loss 1.888415
[epoch6, step344]: loss 2.115009
[epoch6, step345]: loss 4.725112
[epoch6, step346]: loss 18.898682
[epoch6, step347]: loss 2.373069
[epoch6, step348]: loss 2.787341
[epoch6, step349]: loss 41.029194
[epoch6, step350]: loss 1.327372
[epoch6, step351]: loss 2.573000
[epoch6, step352]: loss 4.016212
[epoch6, step353]: loss 4.693071
[epoch6, step354]: loss 3.079835
[epoch6, step355]: loss 24.459761
[epoch6, step356]: loss 3.187411
[epoch6, step357]: loss 6.436802
[epoch6, step358]: loss 13.650977
[epoch6, step359]: loss 18.352045
[epoch6, step360]: loss 3.283313
[epoch6, step361]: loss 20.861778
[epoch6, step362]: loss 3.343724
[epoch6, step363]: loss 24.802334
[epoch6, step364]: loss 4.178501
[epoch6, step365]: loss 2.528133
[epoch6, step366]: loss 2.164788
[epoch6, step367]: loss 5.722625
[epoch6, step368]: loss 30.833015
[epoch6, step369]: loss 20.513098
[epoch6, step370]: loss 9.080099
[epoch6, step371]: loss 5.076315
[epoch6, step372]: loss 5.706306
[epoch6, step373]: loss 2.149063
[epoch6, step374]: loss 29.192347
[epoch6, step375]: loss 12.679797
[epoch6, step376]: loss 2.220942
[epoch6, step377]: loss 18.585363
[epoch6, step378]: loss 3.505953
[epoch6, step379]: loss 6.708363
[epoch6, step380]: loss 5.754887
[epoch6, step381]: loss 11.094089
[epoch6, step382]: loss 3.738684
[epoch6, step383]: loss 13.969895
[epoch6, step384]: loss 16.872425
[epoch6, step385]: loss 3.186063
[epoch6, step386]: loss 1.846222
[epoch6, step387]: loss 4.208379
[epoch6, step388]: loss 23.642817
[epoch6, step389]: loss 5.368573
[epoch6, step390]: loss 4.114709
[epoch6, step391]: loss 2.759711
[epoch6, step392]: loss 3.126822
[epoch6, step393]: loss 3.927252
[epoch6, step394]: loss 1.779877
[epoch6, step395]: loss 4.707078
[epoch6, step396]: loss 2.716609
[epoch6, step397]: loss 4.884570
[epoch6, step398]: loss 44.382339
[epoch6, step399]: loss 1.721664
[epoch6, step400]: loss 5.639517
[epoch6, step401]: loss 5.656219
[epoch6, step402]: loss 4.457637
[epoch6, step403]: loss 15.950147
[epoch6, step404]: loss 2.582951
[epoch6, step405]: loss 28.478020
[epoch6, step406]: loss 3.385609
[epoch6, step407]: loss 3.758400
[epoch6, step408]: loss 4.304544
[epoch6, step409]: loss 3.484682
[epoch6, step410]: loss 24.725227
[epoch6, step411]: loss 8.437923
[epoch6, step412]: loss 4.117690
[epoch6, step413]: loss 4.745470
[epoch6, step414]: loss 4.085158
[epoch6, step415]: loss 5.285411
[epoch6, step416]: loss 9.865128
[epoch6, step417]: loss 2.489750
[epoch6, step418]: loss 15.451411
[epoch6, step419]: loss 1.693043
[epoch6, step420]: loss 5.605074
[epoch6, step421]: loss 2.452945
[epoch6, step422]: loss 2.032762
[epoch6, step423]: loss 2.831645
[epoch6, step424]: loss 22.126398
[epoch6, step425]: loss 4.463732
[epoch6, step426]: loss 2.170260
[epoch6, step427]: loss 18.497450
[epoch6, step428]: loss 4.504684
[epoch6, step429]: loss 6.649616
[epoch6, step430]: loss 26.641296
[epoch6, step431]: loss 6.828370
[epoch6, step432]: loss 20.229694
[epoch6, step433]: loss 4.851068
[epoch6, step434]: loss 2.422627
[epoch6, step435]: loss 7.679492
[epoch6, step436]: loss 19.188637
[epoch6, step437]: loss 3.424339
[epoch6, step438]: loss 3.052398
[epoch6, step439]: loss 5.865027
[epoch6, step440]: loss 18.582291
[epoch6, step441]: loss 3.637660
[epoch6, step442]: loss 3.916242
[epoch6, step443]: loss 16.773273
[epoch6, step444]: loss 6.687298
[epoch6, step445]: loss 6.913768
[epoch6, step446]: loss 1.921329
[epoch6, step447]: loss 7.802457
[epoch6, step448]: loss 29.438156
[epoch6, step449]: loss 24.978809
[epoch6, step450]: loss 9.269575
[epoch6, step451]: loss 4.268712
[epoch6, step452]: loss 7.998159
[epoch6, step453]: loss 30.520721
[epoch6, step454]: loss 4.064378
[epoch6, step455]: loss 18.678600
[epoch6, step456]: loss 4.323485
[epoch6, step457]: loss 5.995093
[epoch6, step458]: loss 2.045045
[epoch6, step459]: loss 7.146703
[epoch6, step460]: loss 22.605120
[epoch6, step461]: loss 12.136907
[epoch6, step462]: loss 2.007764
[epoch6, step463]: loss 4.747367
[epoch6, step464]: loss 2.375004
[epoch6, step465]: loss 18.477806
[epoch6, step466]: loss 23.305161
[epoch6, step467]: loss 2.349384
[epoch6, step468]: loss 2.603348
[epoch6, step469]: loss 5.019257
[epoch6, step470]: loss 5.631201
[epoch6, step471]: loss 6.316333
[epoch6, step472]: loss 11.289698
[epoch6, step473]: loss 28.621357
[epoch6, step474]: loss 5.509119
[epoch6, step475]: loss 6.449647
[epoch6, step476]: loss 6.362011
[epoch6, step477]: loss 37.634895
[epoch6, step478]: loss 4.797523
[epoch6, step479]: loss 3.632093
[epoch6, step480]: loss 1.866373
[epoch6, step481]: loss 10.951442
[epoch6, step482]: loss 2.616628
[epoch6, step483]: loss 5.516005
[epoch6, step484]: loss 12.529938
[epoch6, step485]: loss 24.357050
[epoch6, step486]: loss 35.794933
[epoch6, step487]: loss 30.554718
[epoch6, step488]: loss 3.901454
[epoch6, step489]: loss 3.991131
[epoch6, step490]: loss 27.413729
[epoch6, step491]: loss 24.473955
[epoch6, step492]: loss 6.006694
[epoch6, step493]: loss 4.062267
[epoch6, step494]: loss 4.083069
[epoch6, step495]: loss 37.926525
[epoch6, step496]: loss 3.905227
[epoch6, step497]: loss 27.829861
[epoch6, step498]: loss 1.753648
[epoch6, step499]: loss 20.366598
[epoch6, step500]: loss 4.859223
[epoch6, step501]: loss 2.656333
[epoch6, step502]: loss 3.051792
[epoch6, step503]: loss 3.606897
[epoch6, step504]: loss 1.859753
[epoch6, step505]: loss 4.217526
[epoch6, step506]: loss 2.294118
[epoch6, step507]: loss 2.580871
[epoch6, step508]: loss 5.116467
[epoch6, step509]: loss 2.116677
[epoch6, step510]: loss 25.254436
[epoch6, step511]: loss 2.590116
[epoch6, step512]: loss 1.759004
[epoch6, step513]: loss 2.730915
[epoch6, step514]: loss 6.135189
[epoch6, step515]: loss 2.266459
[epoch6, step516]: loss 28.834757
[epoch6, step517]: loss 12.076090
[epoch6, step518]: loss 10.485451
[epoch6, step519]: loss 5.352441
[epoch6, step520]: loss 8.336850
[epoch6, step521]: loss 3.513577
[epoch6, step522]: loss 10.989955
[epoch6, step523]: loss 18.596375
[epoch6, step524]: loss 20.896032
[epoch6, step525]: loss 3.133587
[epoch6, step526]: loss 4.657174
[epoch6, step527]: loss 9.375010
[epoch6, step528]: loss 3.172770
[epoch6, step529]: loss 2.129015
[epoch6, step530]: loss 6.580908
[epoch6, step531]: loss 4.284820
[epoch6, step532]: loss 9.587100
[epoch6, step533]: loss 2.326314
[epoch6, step534]: loss 8.171913
[epoch6, step535]: loss 12.488120
[epoch6, step536]: loss 35.128208
[epoch6, step537]: loss 20.308653
[epoch6, step538]: loss 3.732551
[epoch6, step539]: loss 7.325545
[epoch6, step540]: loss 3.499789
[epoch6, step541]: loss 9.032571
[epoch6, step542]: loss 11.907123
[epoch6, step543]: loss 3.320042
[epoch6, step544]: loss 5.904815
[epoch6, step545]: loss 24.253023
[epoch6, step546]: loss 15.505585
[epoch6, step547]: loss 21.703129
[epoch6, step548]: loss 34.059486
[epoch6, step549]: loss 13.293922
[epoch6, step550]: loss 10.305880
[epoch6, step551]: loss 3.863586
[epoch6, step552]: loss 9.717048
[epoch6, step553]: loss 1.585583
[epoch6, step554]: loss 10.699837
[epoch6, step555]: loss 24.633177
[epoch6, step556]: loss 9.883379
[epoch6, step557]: loss 3.067915
[epoch6, step558]: loss 24.972370
[epoch6, step559]: loss 4.230181
[epoch6, step560]: loss 3.355925
[epoch6, step561]: loss 4.864256
[epoch6, step562]: loss 6.362137
[epoch6, step563]: loss 5.236760
[epoch6, step564]: loss 2.123503
[epoch6, step565]: loss 6.995061
[epoch6, step566]: loss 21.187832
[epoch6, step567]: loss 20.767883
[epoch6, step568]: loss 16.411533
[epoch6, step569]: loss 3.110719
[epoch6, step570]: loss 6.119020
[epoch6, step571]: loss 6.547114
[epoch6, step572]: loss 4.302319
[epoch6, step573]: loss 2.824792
[epoch6, step574]: loss 3.268683
[epoch6, step575]: loss 7.581789
[epoch6, step576]: loss 12.368952
[epoch6, step577]: loss 1.309915
[epoch6, step578]: loss 5.653498
[epoch6, step579]: loss 2.407588
[epoch6, step580]: loss 6.655862
[epoch6, step581]: loss 4.849526
[epoch6, step582]: loss 7.045661
[epoch6, step583]: loss 2.404383
[epoch6, step584]: loss 8.871161
[epoch6, step585]: loss 2.670544
[epoch6, step586]: loss 3.591743
[epoch6, step587]: loss 18.335773
[epoch6, step588]: loss 1.417820
[epoch6, step589]: loss 2.222418
[epoch6, step590]: loss 2.106639
[epoch6, step591]: loss 2.854208
[epoch6, step592]: loss 2.618351
[epoch6, step593]: loss 3.059068
[epoch6, step594]: loss 3.474127
[epoch6, step595]: loss 2.568349
[epoch6, step596]: loss 6.228668
[epoch6, step597]: loss 8.985396
[epoch6, step598]: loss 1.936523
[epoch6, step599]: loss 1.726803
[epoch6, step600]: loss 2.298046
[epoch6, step601]: loss 1.778770
[epoch6, step602]: loss 6.240648
[epoch6, step603]: loss 8.738976
[epoch6, step604]: loss 40.205357
[epoch6, step605]: loss 4.998128
[epoch6, step606]: loss 4.557352
[epoch6, step607]: loss 2.156208
[epoch6, step608]: loss 1.703765
[epoch6, step609]: loss 3.151197
[epoch6, step610]: loss 2.693403
[epoch6, step611]: loss 19.125605
[epoch6, step612]: loss 24.089041
[epoch6, step613]: loss 25.878109
[epoch6, step614]: loss 4.226935
[epoch6, step615]: loss 2.447052
[epoch6, step616]: loss 4.067434
[epoch6, step617]: loss 2.613305
[epoch6, step618]: loss 12.517383
[epoch6, step619]: loss 8.277429
[epoch6, step620]: loss 21.801579
[epoch6, step621]: loss 40.744457
[epoch6, step622]: loss 4.535144
[epoch6, step623]: loss 24.921993
[epoch6, step624]: loss 2.669980
[epoch6, step625]: loss 3.550461
[epoch6, step626]: loss 10.507858
[epoch6, step627]: loss 4.384180
[epoch6, step628]: loss 23.773775
[epoch6, step629]: loss 2.095064
[epoch6, step630]: loss 2.775934
[epoch6, step631]: loss 3.023187
[epoch6, step632]: loss 3.148520
[epoch6, step633]: loss 27.088936
[epoch6, step634]: loss 39.189224
[epoch6, step635]: loss 1.888992
[epoch6, step636]: loss 15.268555
[epoch6, step637]: loss 3.205846
[epoch6, step638]: loss 4.416635
[epoch6, step639]: loss 1.845493
[epoch6, step640]: loss 7.895856
[epoch6, step641]: loss 2.260368
[epoch6, step642]: loss 2.755773
[epoch6, step643]: loss 3.934443
[epoch6, step644]: loss 9.951336
[epoch6, step645]: loss 3.955596
[epoch6, step646]: loss 3.211360
[epoch6, step647]: loss 21.870098
[epoch6, step648]: loss 4.035758
[epoch6, step649]: loss 8.946666
[epoch6, step650]: loss 3.011829
[epoch6, step651]: loss 3.314034
[epoch6, step652]: loss 18.116827
[epoch6, step653]: loss 13.957661
[epoch6, step654]: loss 1.695790
[epoch6, step655]: loss 2.172664
[epoch6, step656]: loss 7.970172
[epoch6, step657]: loss 21.030077
[epoch6, step658]: loss 7.447411
[epoch6, step659]: loss 4.232663
[epoch6, step660]: loss 11.302794
[epoch6, step661]: loss 4.870934
[epoch6, step662]: loss 5.220449
[epoch6, step663]: loss 1.573418
[epoch6, step664]: loss 11.871586
[epoch6, step665]: loss 8.856439
[epoch6, step666]: loss 2.917617
[epoch6, step667]: loss 15.342841
[epoch6, step668]: loss 14.778893
[epoch6, step669]: loss 4.371757
[epoch6, step670]: loss 11.591047
[epoch6, step671]: loss 27.669453
[epoch6, step672]: loss 5.835419
[epoch6, step673]: loss 4.633278
[epoch6, step674]: loss 10.185082
[epoch6, step675]: loss 6.279146
[epoch6, step676]: loss 11.881261
[epoch6, step677]: loss 1.943270
[epoch6, step678]: loss 4.270100
[epoch6, step679]: loss 4.208210
[epoch6, step680]: loss 1.989386
[epoch6, step681]: loss 4.306572
[epoch6, step682]: loss 28.640661
[epoch6, step683]: loss 2.982008
[epoch6, step684]: loss 1.551664
[epoch6, step685]: loss 2.989306
[epoch6, step686]: loss 6.162202
[epoch6, step687]: loss 2.939379
[epoch6, step688]: loss 5.437865
[epoch6, step689]: loss 20.818903
[epoch6, step690]: loss 3.321375
[epoch6, step691]: loss 21.373819
[epoch6, step692]: loss 5.271480
[epoch6, step693]: loss 2.166484
[epoch6, step694]: loss 4.113925
[epoch6, step695]: loss 4.399178
[epoch6, step696]: loss 5.563859
[epoch6, step697]: loss 27.767656
[epoch6, step698]: loss 7.537018
[epoch6, step699]: loss 25.607998
[epoch6, step700]: loss 3.071026
[epoch6, step701]: loss 2.133680
[epoch6, step702]: loss 2.217949
[epoch6, step703]: loss 7.738718
[epoch6, step704]: loss 4.965369
[epoch6, step705]: loss 3.368000
[epoch6, step706]: loss 12.982962
[epoch6, step707]: loss 4.481890
[epoch6, step708]: loss 4.940978
[epoch6, step709]: loss 2.963397
[epoch6, step710]: loss 5.103459
[epoch6, step711]: loss 12.280508
[epoch6, step712]: loss 1.409385
[epoch6, step713]: loss 10.617821
[epoch6, step714]: loss 30.136312
[epoch6, step715]: loss 4.820501
[epoch6, step716]: loss 20.962736
[epoch6, step717]: loss 4.663557
[epoch6, step718]: loss 1.327574
[epoch6, step719]: loss 2.300850
[epoch6, step720]: loss 2.889722
[epoch6, step721]: loss 2.093847
[epoch6, step722]: loss 5.741664
[epoch6, step723]: loss 4.858540
[epoch6, step724]: loss 7.058849
[epoch6, step725]: loss 5.186273
[epoch6, step726]: loss 3.073291
[epoch6, step727]: loss 19.972404
[epoch6, step728]: loss 3.123598
[epoch6, step729]: loss 27.378223
[epoch6, step730]: loss 2.724131
[epoch6, step731]: loss 3.754888
[epoch6, step732]: loss 3.513293
[epoch6, step733]: loss 4.236472
[epoch6, step734]: loss 4.217966
[epoch6, step735]: loss 3.461598
[epoch6, step736]: loss 1.931732
[epoch6, step737]: loss 8.797405
[epoch6, step738]: loss 2.876269
[epoch6, step739]: loss 1.665088
[epoch6, step740]: loss 6.244046
[epoch6, step741]: loss 2.650378
[epoch6, step742]: loss 2.726521
[epoch6, step743]: loss 2.099247
[epoch6, step744]: loss 2.264583
[epoch6, step745]: loss 3.024766
[epoch6, step746]: loss 5.144492
[epoch6, step747]: loss 48.998970
[epoch6, step748]: loss 2.724835
[epoch6, step749]: loss 3.866856
[epoch6, step750]: loss 9.836614
[epoch6, step751]: loss 2.729030
[epoch6, step752]: loss 17.961441
[epoch6, step753]: loss 3.321857
[epoch6, step754]: loss 4.132983
[epoch6, step755]: loss 3.238691
[epoch6, step756]: loss 17.345631
[epoch6, step757]: loss 6.844585
[epoch6, step758]: loss 5.249536
[epoch6, step759]: loss 4.049688
[epoch6, step760]: loss 3.738467
[epoch6, step761]: loss 10.226581
[epoch6, step762]: loss 5.648146
[epoch6, step763]: loss 2.706588
[epoch6, step764]: loss 5.794091
[epoch6, step765]: loss 2.509394
[epoch6, step766]: loss 2.140283
[epoch6, step767]: loss 4.724177
[epoch6, step768]: loss 5.290362
[epoch6, step769]: loss 2.033603
[epoch6, step770]: loss 44.559704
[epoch6, step771]: loss 3.477826
[epoch6, step772]: loss 2.475721
[epoch6, step773]: loss 1.321484
[epoch6, step774]: loss 4.397556
[epoch6, step775]: loss 6.028663
[epoch6, step776]: loss 20.560829
[epoch6, step777]: loss 20.356068
[epoch6, step778]: loss 2.725377
[epoch6, step779]: loss 8.950478
[epoch6, step780]: loss 4.728742
[epoch6, step781]: loss 2.689016
[epoch6, step782]: loss 8.448948
[epoch6, step783]: loss 7.242014
[epoch6, step784]: loss 10.406116
[epoch6, step785]: loss 3.542348
[epoch6, step786]: loss 7.775343
[epoch6, step787]: loss 2.467188
[epoch6, step788]: loss 1.902440
[epoch6, step789]: loss 3.738207
[epoch6, step790]: loss 17.796017
[epoch6, step791]: loss 5.652532
[epoch6, step792]: loss 19.531393
[epoch6, step793]: loss 4.816419
[epoch6, step794]: loss 4.007980
[epoch6, step795]: loss 2.135824
[epoch6, step796]: loss 10.589936
[epoch6, step797]: loss 2.435657
[epoch6, step798]: loss 4.125161
[epoch6, step799]: loss 2.091291
[epoch6, step800]: loss 34.487526
[epoch6, step801]: loss 9.183964
[epoch6, step802]: loss 3.334340
[epoch6, step803]: loss 9.173198
[epoch6, step804]: loss 17.209284
[epoch6, step805]: loss 1.868040
[epoch6, step806]: loss 1.516313
[epoch6, step807]: loss 3.741524
[epoch6, step808]: loss 6.570385
[epoch6, step809]: loss 49.546135
[epoch6, step810]: loss 5.431041
[epoch6, step811]: loss 13.027243
[epoch6, step812]: loss 28.193541
[epoch6, step813]: loss 5.231455
[epoch6, step814]: loss 20.852650
[epoch6, step815]: loss 4.425103
[epoch6, step816]: loss 2.579237
[epoch6, step817]: loss 4.032856
[epoch6, step818]: loss 2.302548
[epoch6, step819]: loss 1.872866
[epoch6, step820]: loss 13.987358
[epoch6, step821]: loss 12.599461
[epoch6, step822]: loss 6.553180
[epoch6, step823]: loss 2.328891
[epoch6, step824]: loss 1.607001
[epoch6, step825]: loss 1.732532
[epoch6, step826]: loss 8.303665
[epoch6, step827]: loss 6.760354
[epoch6, step828]: loss 8.288414
[epoch6, step829]: loss 2.664366
[epoch6, step830]: loss 2.982109
[epoch6, step831]: loss 5.226105
[epoch6, step832]: loss 2.869316
[epoch6, step833]: loss 9.510315
[epoch6, step834]: loss 18.022429
[epoch6, step835]: loss 2.776885
[epoch6, step836]: loss 2.195544
[epoch6, step837]: loss 3.328625
[epoch6, step838]: loss 1.378844
[epoch6, step839]: loss 2.589804
[epoch6, step840]: loss 1.615354
[epoch6, step841]: loss 3.144007
[epoch6, step842]: loss 6.586061
[epoch6, step843]: loss 3.724140
[epoch6, step844]: loss 1.994056
[epoch6, step845]: loss 4.236940
[epoch6, step846]: loss 12.470927
[epoch6, step847]: loss 4.354681
[epoch6, step848]: loss 38.056267
[epoch6, step849]: loss 24.247520
[epoch6, step850]: loss 7.260713
[epoch6, step851]: loss 3.021461
[epoch6, step852]: loss 2.335421
[epoch6, step853]: loss 1.789181
[epoch6, step854]: loss 11.012457
[epoch6, step855]: loss 5.719692
[epoch6, step856]: loss 21.264332
[epoch6, step857]: loss 2.785245
[epoch6, step858]: loss 4.093770
[epoch6, step859]: loss 2.548013
[epoch6, step860]: loss 3.990383
[epoch6, step861]: loss 30.013861
[epoch6, step862]: loss 4.687276
[epoch6, step863]: loss 10.672014
[epoch6, step864]: loss 3.180763
[epoch6, step865]: loss 28.556936
[epoch6, step866]: loss 2.169933
[epoch6, step867]: loss 2.614352
[epoch6, step868]: loss 3.779195
[epoch6, step869]: loss 24.928041
[epoch6, step870]: loss 3.207766
[epoch6, step871]: loss 2.033625
[epoch6, step872]: loss 2.977497
[epoch6, step873]: loss 1.914169
[epoch6, step874]: loss 62.344910
[epoch6, step875]: loss 3.318957
[epoch6, step876]: loss 35.288269
[epoch6, step877]: loss 26.214535
[epoch6, step878]: loss 9.868552
[epoch6, step879]: loss 4.294539
[epoch6, step880]: loss 3.699571
[epoch6, step881]: loss 1.236994
[epoch6, step882]: loss 10.198996
[epoch6, step883]: loss 26.866085
[epoch6, step884]: loss 17.646925
[epoch6, step885]: loss 8.847889
[epoch6, step886]: loss 9.047795
[epoch6, step887]: loss 18.441236
[epoch6, step888]: loss 3.786206
[epoch6, step889]: loss 4.813622
[epoch6, step890]: loss 3.629824
[epoch6, step891]: loss 21.281116
[epoch6, step892]: loss 2.331893
[epoch6, step893]: loss 26.500347
[epoch6, step894]: loss 3.401745
[epoch6, step895]: loss 9.122475
[epoch6, step896]: loss 1.815118
[epoch6, step897]: loss 9.127360
[epoch6, step898]: loss 23.284761
[epoch6, step899]: loss 2.584154
[epoch6, step900]: loss 2.757122
[epoch6, step901]: loss 3.385657
[epoch6, step902]: loss 1.694263
[epoch6, step903]: loss 2.645311
[epoch6, step904]: loss 4.843657
[epoch6, step905]: loss 4.224072
[epoch6, step906]: loss 25.345839
[epoch6, step907]: loss 7.635386
[epoch6, step908]: loss 3.047313
[epoch6, step909]: loss 3.009338
[epoch6, step910]: loss 2.862572
[epoch6, step911]: loss 3.675328
[epoch6, step912]: loss 23.121546
[epoch6, step913]: loss 4.799173
[epoch6, step914]: loss 3.891989
[epoch6, step915]: loss 6.539693
[epoch6, step916]: loss 4.226189
[epoch6, step917]: loss 6.553185
[epoch6, step918]: loss 2.432418
[epoch6, step919]: loss 23.774624
[epoch6, step920]: loss 6.283505
[epoch6, step921]: loss 4.560210
[epoch6, step922]: loss 3.398050
[epoch6, step923]: loss 2.163105
[epoch6, step924]: loss 5.569150
[epoch6, step925]: loss 1.754305
[epoch6, step926]: loss 2.750350
[epoch6, step927]: loss 3.249205
[epoch6, step928]: loss 2.924069
[epoch6, step929]: loss 9.752136
[epoch6, step930]: loss 19.425797
[epoch6, step931]: loss 2.404125
[epoch6, step932]: loss 26.070864
[epoch6, step933]: loss 21.734617
[epoch6, step934]: loss 10.690501
[epoch6, step935]: loss 4.390808
[epoch6, step936]: loss 3.160534
[epoch6, step937]: loss 24.491131
[epoch6, step938]: loss 14.484241
[epoch6, step939]: loss 2.313075
[epoch6, step940]: loss 8.254012
[epoch6, step941]: loss 5.132836
[epoch6, step942]: loss 19.882692
[epoch6, step943]: loss 3.193742
[epoch6, step944]: loss 2.524665
[epoch6, step945]: loss 16.608027
[epoch6, step946]: loss 2.438090
[epoch6, step947]: loss 24.747772
[epoch6, step948]: loss 25.639816
[epoch6, step949]: loss 4.955026
[epoch6, step950]: loss 2.215780
[epoch6, step951]: loss 9.331573
[epoch6, step952]: loss 41.680298
[epoch6, step953]: loss 22.260122
[epoch6, step954]: loss 3.548296
[epoch6, step955]: loss 27.345695
[epoch6, step956]: loss 3.669127
[epoch6, step957]: loss 6.229811
[epoch6, step958]: loss 20.932983
[epoch6, step959]: loss 2.620753
[epoch6, step960]: loss 39.516087
[epoch6, step961]: loss 2.775349
[epoch6, step962]: loss 10.940778
[epoch6, step963]: loss 1.755543
[epoch6, step964]: loss 1.848954
[epoch6, step965]: loss 3.041251
[epoch6, step966]: loss 23.223976
[epoch6, step967]: loss 4.957491
[epoch6, step968]: loss 10.057165
[epoch6, step969]: loss 8.106684
[epoch6, step970]: loss 4.494025
[epoch6, step971]: loss 4.741146
[epoch6, step972]: loss 1.870609
[epoch6, step973]: loss 3.305635
[epoch6, step974]: loss 18.507610
[epoch6, step975]: loss 9.431894
[epoch6, step976]: loss 2.652020
[epoch6, step977]: loss 2.376069
[epoch6, step978]: loss 2.566669
[epoch6, step979]: loss 16.461872
[epoch6, step980]: loss 5.606406
[epoch6, step981]: loss 2.784383
[epoch6, step982]: loss 23.183123
[epoch6, step983]: loss 6.961391
[epoch6, step984]: loss 7.202243
[epoch6, step985]: loss 1.916582
[epoch6, step986]: loss 24.649586
[epoch6, step987]: loss 23.358389
[epoch6, step988]: loss 13.845890
[epoch6, step989]: loss 10.283721
[epoch6, step990]: loss 3.638814
[epoch6, step991]: loss 4.702929
[epoch6, step992]: loss 3.472205
[epoch6, step993]: loss 4.064883
[epoch6, step994]: loss 1.675764
[epoch6, step995]: loss 18.425707
[epoch6, step996]: loss 2.494000
[epoch6, step997]: loss 8.867258
[epoch6, step998]: loss 11.153515
[epoch6, step999]: loss 10.066998
[epoch6, step1000]: loss 3.934943
[epoch6, step1001]: loss 1.299373
[epoch6, step1002]: loss 11.891413
[epoch6, step1003]: loss 2.485600
[epoch6, step1004]: loss 22.348986
[epoch6, step1005]: loss 8.158329
[epoch6, step1006]: loss 2.837718
[epoch6, step1007]: loss 3.335752
[epoch6, step1008]: loss 19.919842
[epoch6, step1009]: loss 17.329506
[epoch6, step1010]: loss 2.246489
[epoch6, step1011]: loss 6.043662
[epoch6, step1012]: loss 3.762381
[epoch6, step1013]: loss 6.671400
[epoch6, step1014]: loss 2.888368
[epoch6, step1015]: loss 12.086809
[epoch6, step1016]: loss 18.744406
[epoch6, step1017]: loss 6.548678
[epoch6, step1018]: loss 4.314863
[epoch6, step1019]: loss 4.727778
[epoch6, step1020]: loss 12.394186
[epoch6, step1021]: loss 2.963630
[epoch6, step1022]: loss 4.549715
[epoch6, step1023]: loss 2.810243
[epoch6, step1024]: loss 2.501028
[epoch6, step1025]: loss 3.218207
[epoch6, step1026]: loss 3.740765
[epoch6, step1027]: loss 19.466122
[epoch6, step1028]: loss 4.096945
[epoch6, step1029]: loss 2.754114
[epoch6, step1030]: loss 4.933153
[epoch6, step1031]: loss 9.780076
[epoch6, step1032]: loss 2.550354
[epoch6, step1033]: loss 2.246401
[epoch6, step1034]: loss 3.402595
[epoch6, step1035]: loss 4.653932
[epoch6, step1036]: loss 2.724958
[epoch6, step1037]: loss 2.228302
[epoch6, step1038]: loss 19.431763
[epoch6, step1039]: loss 3.621375
[epoch6, step1040]: loss 6.957899
[epoch6, step1041]: loss 8.093997
[epoch6, step1042]: loss 2.593115
[epoch6, step1043]: loss 2.392865
[epoch6, step1044]: loss 2.326339
[epoch6, step1045]: loss 2.866608
[epoch6, step1046]: loss 2.733974
[epoch6, step1047]: loss 2.865633
[epoch6, step1048]: loss 11.846328
[epoch6, step1049]: loss 1.443614
[epoch6, step1050]: loss 1.939214
[epoch6, step1051]: loss 18.381668
[epoch6, step1052]: loss 24.115734
[epoch6, step1053]: loss 4.338158
[epoch6, step1054]: loss 10.332029
[epoch6, step1055]: loss 6.028171
[epoch6, step1056]: loss 14.427293
[epoch6, step1057]: loss 2.038261
[epoch6, step1058]: loss 1.947282
[epoch6, step1059]: loss 13.014559
[epoch6, step1060]: loss 5.132640
[epoch6, step1061]: loss 3.158143
[epoch6, step1062]: loss 16.767469
[epoch6, step1063]: loss 7.728741
[epoch6, step1064]: loss 8.123791
[epoch6, step1065]: loss 7.254955
[epoch6, step1066]: loss 12.140005
[epoch6, step1067]: loss 13.092852
[epoch6, step1068]: loss 6.817478
[epoch6, step1069]: loss 1.451559
[epoch6, step1070]: loss 30.936569
[epoch6, step1071]: loss 9.028189
[epoch6, step1072]: loss 11.958829
[epoch6, step1073]: loss 2.067055
[epoch6, step1074]: loss 2.660952
[epoch6, step1075]: loss 7.636209
[epoch6, step1076]: loss 11.185437
[epoch6, step1077]: loss 7.828731
[epoch6, step1078]: loss 6.280277
[epoch6, step1079]: loss 4.827209
[epoch6, step1080]: loss 2.423711
[epoch6, step1081]: loss 1.670542
[epoch6, step1082]: loss 3.052818
[epoch6, step1083]: loss 8.015284
[epoch6, step1084]: loss 3.360831
[epoch6, step1085]: loss 29.477783
[epoch6, step1086]: loss 16.019014
[epoch6, step1087]: loss 11.808081
[epoch6, step1088]: loss 3.129745
[epoch6, step1089]: loss 25.657303
[epoch6, step1090]: loss 1.845609
[epoch6, step1091]: loss 2.116682
[epoch6, step1092]: loss 2.298649
[epoch6, step1093]: loss 2.604093
[epoch6, step1094]: loss 5.743693
[epoch6, step1095]: loss 2.190656
[epoch6, step1096]: loss 2.791053
[epoch6, step1097]: loss 2.109704
[epoch6, step1098]: loss 20.550119
[epoch6, step1099]: loss 5.383791
[epoch6, step1100]: loss 1.730902
[epoch6, step1101]: loss 1.854500
[epoch6, step1102]: loss 1.461548
[epoch6, step1103]: loss 2.583660
[epoch6, step1104]: loss 8.258129
[epoch6, step1105]: loss 2.363651
[epoch6, step1106]: loss 20.892561
[epoch6, step1107]: loss 5.026916
[epoch6, step1108]: loss 8.829205
[epoch6, step1109]: loss 4.281744
[epoch6, step1110]: loss 1.778798
[epoch6, step1111]: loss 7.222805
[epoch6, step1112]: loss 45.096821
[epoch6, step1113]: loss 3.627145
[epoch6, step1114]: loss 19.659519
[epoch6, step1115]: loss 4.558779
[epoch6, step1116]: loss 19.069580
[epoch6, step1117]: loss 2.503361
[epoch6, step1118]: loss 1.693931
[epoch6, step1119]: loss 2.698764
[epoch6, step1120]: loss 5.154645
[epoch6, step1121]: loss 2.859198
[epoch6, step1122]: loss 4.494751
[epoch6, step1123]: loss 2.751155
[epoch6, step1124]: loss 6.269442
[epoch6, step1125]: loss 17.700785
[epoch6, step1126]: loss 5.174268
[epoch6, step1127]: loss 6.690232
[epoch6, step1128]: loss 1.455348
[epoch6, step1129]: loss 7.673163
[epoch6, step1130]: loss 4.490682
[epoch6, step1131]: loss 17.878342
[epoch6, step1132]: loss 16.535042
[epoch6, step1133]: loss 3.090204
[epoch6, step1134]: loss 5.106886
[epoch6, step1135]: loss 2.335451
[epoch6, step1136]: loss 5.003775
[epoch6, step1137]: loss 7.858712
[epoch6, step1138]: loss 18.625526
[epoch6, step1139]: loss 2.241371
[epoch6, step1140]: loss 6.551230
[epoch6, step1141]: loss 7.212517
[epoch6, step1142]: loss 5.598065
[epoch6, step1143]: loss 2.364220
[epoch6, step1144]: loss 2.098956
[epoch6, step1145]: loss 25.471844
[epoch6, step1146]: loss 36.994858
[epoch6, step1147]: loss 4.458913
[epoch6, step1148]: loss 4.361736
[epoch6, step1149]: loss 3.236596
[epoch6, step1150]: loss 5.300660
[epoch6, step1151]: loss 9.069681
[epoch6, step1152]: loss 2.975152
[epoch6, step1153]: loss 5.553417
[epoch6, step1154]: loss 3.729203
[epoch6, step1155]: loss 20.854525
[epoch6, step1156]: loss 31.440928
[epoch6, step1157]: loss 21.941286
[epoch6, step1158]: loss 1.822101
[epoch6, step1159]: loss 9.232898
[epoch6, step1160]: loss 3.317124
[epoch6, step1161]: loss 21.459770
[epoch6, step1162]: loss 23.555027
[epoch6, step1163]: loss 2.133233
[epoch6, step1164]: loss 3.556758
[epoch6, step1165]: loss 4.665108
[epoch6, step1166]: loss 2.019543
[epoch6, step1167]: loss 22.399105
[epoch6, step1168]: loss 5.978996
[epoch6, step1169]: loss 6.406807
[epoch6, step1170]: loss 6.020963
[epoch6, step1171]: loss 3.518028
[epoch6, step1172]: loss 7.693627
[epoch6, step1173]: loss 4.378569
[epoch6, step1174]: loss 3.027385
[epoch6, step1175]: loss 11.765035
[epoch6, step1176]: loss 17.878489
[epoch6, step1177]: loss 4.131212
[epoch6, step1178]: loss 3.450068
[epoch6, step1179]: loss 8.632776
[epoch6, step1180]: loss 4.534866
[epoch6, step1181]: loss 2.671258
[epoch6, step1182]: loss 2.749346
[epoch6, step1183]: loss 17.296246
[epoch6, step1184]: loss 4.511295
[epoch6, step1185]: loss 18.855145
[epoch6, step1186]: loss 6.776253
[epoch6, step1187]: loss 1.618180
[epoch6, step1188]: loss 1.411447
[epoch6, step1189]: loss 4.947155
[epoch6, step1190]: loss 4.298965
[epoch6, step1191]: loss 7.348171
[epoch6, step1192]: loss 3.382867
[epoch6, step1193]: loss 6.483586
[epoch6, step1194]: loss 5.305765
[epoch6, step1195]: loss 1.257702
[epoch6, step1196]: loss 8.942413
[epoch6, step1197]: loss 2.457508
[epoch6, step1198]: loss 10.523664
[epoch6, step1199]: loss 10.815058
[epoch6, step1200]: loss 2.134657
[epoch6, step1201]: loss 2.409304
[epoch6, step1202]: loss 1.421241
[epoch6, step1203]: loss 5.853587
[epoch6, step1204]: loss 24.952839
[epoch6, step1205]: loss 4.505582
[epoch6, step1206]: loss 31.564148
[epoch6, step1207]: loss 2.891501
[epoch6, step1208]: loss 2.840672
[epoch6, step1209]: loss 5.352853
[epoch6, step1210]: loss 2.678038
[epoch6, step1211]: loss 2.009019
[epoch6, step1212]: loss 18.475451
[epoch6, step1213]: loss 3.784700
[epoch6, step1214]: loss 3.524894
[epoch6, step1215]: loss 2.429355
[epoch6, step1216]: loss 4.065571
[epoch6, step1217]: loss 2.885228
[epoch6, step1218]: loss 2.523503
[epoch6, step1219]: loss 4.785291
[epoch6, step1220]: loss 2.639298
[epoch6, step1221]: loss 3.364045
[epoch6, step1222]: loss 3.748745
[epoch6, step1223]: loss 6.010867
[epoch6, step1224]: loss 5.034328
[epoch6, step1225]: loss 3.199657
[epoch6, step1226]: loss 5.142932
[epoch6, step1227]: loss 3.671003
[epoch6, step1228]: loss 3.879279
[epoch6, step1229]: loss 5.130120
[epoch6, step1230]: loss 27.684498
[epoch6, step1231]: loss 2.953720
[epoch6, step1232]: loss 1.648774
[epoch6, step1233]: loss 30.915342
[epoch6, step1234]: loss 19.937218
[epoch6, step1235]: loss 1.809355
[epoch6, step1236]: loss 8.148650
[epoch6, step1237]: loss 7.349674
[epoch6, step1238]: loss 26.979858
[epoch6, step1239]: loss 2.250831
[epoch6, step1240]: loss 6.029459
[epoch6, step1241]: loss 15.003652
[epoch6, step1242]: loss 2.177969
[epoch6, step1243]: loss 8.976147
[epoch6, step1244]: loss 3.552593
[epoch6, step1245]: loss 7.556823
[epoch6, step1246]: loss 17.094303
[epoch6, step1247]: loss 32.447094
[epoch6, step1248]: loss 21.822966
[epoch6, step1249]: loss 9.917322
[epoch6, step1250]: loss 2.546914
[epoch6, step1251]: loss 34.109623
[epoch6, step1252]: loss 2.891018
[epoch6, step1253]: loss 1.725637
[epoch6, step1254]: loss 25.155275
[epoch6, step1255]: loss 3.546252
[epoch6, step1256]: loss 38.952213
[epoch6, step1257]: loss 3.655398
[epoch6, step1258]: loss 21.149630
[epoch6, step1259]: loss 5.574417
[epoch6, step1260]: loss 22.893415
[epoch6, step1261]: loss 4.601680
[epoch6, step1262]: loss 8.859204
[epoch6, step1263]: loss 3.314852
[epoch6, step1264]: loss 1.743255
[epoch6, step1265]: loss 4.655700
[epoch6, step1266]: loss 29.153679
[epoch6, step1267]: loss 3.624770
[epoch6, step1268]: loss 6.002316
[epoch6, step1269]: loss 25.419153
[epoch6, step1270]: loss 21.105095
[epoch6, step1271]: loss 2.249840
[epoch6, step1272]: loss 6.206894
[epoch6, step1273]: loss 19.786566
[epoch6, step1274]: loss 1.927949
[epoch6, step1275]: loss 1.640608
[epoch6, step1276]: loss 17.811232
[epoch6, step1277]: loss 3.497921
[epoch6, step1278]: loss 2.262778
[epoch6, step1279]: loss 4.346728
[epoch6, step1280]: loss 3.438759
[epoch6, step1281]: loss 1.698001
[epoch6, step1282]: loss 6.778912
[epoch6, step1283]: loss 2.221119
[epoch6, step1284]: loss 49.546333
[epoch6, step1285]: loss 31.504505
[epoch6, step1286]: loss 10.863965
[epoch6, step1287]: loss 4.000875
[epoch6, step1288]: loss 15.844858
[epoch6, step1289]: loss 17.000811
[epoch6, step1290]: loss 48.368092
[epoch6, step1291]: loss 4.293435
[epoch6, step1292]: loss 3.984322
[epoch6, step1293]: loss 28.051437
[epoch6, step1294]: loss 19.303131
[epoch6, step1295]: loss 23.728954
[epoch6, step1296]: loss 10.687872
[epoch6, step1297]: loss 7.788222
[epoch6, step1298]: loss 10.306372
[epoch6, step1299]: loss 2.443206
[epoch6, step1300]: loss 2.565293
[epoch6, step1301]: loss 5.847320
[epoch6, step1302]: loss 6.121094
[epoch6, step1303]: loss 3.610905
[epoch6, step1304]: loss 3.103060
[epoch6, step1305]: loss 3.927827
[epoch6, step1306]: loss 2.805987
[epoch6, step1307]: loss 19.250387
[epoch6, step1308]: loss 30.125843
[epoch6, step1309]: loss 25.566006
[epoch6, step1310]: loss 7.676938
[epoch6, step1311]: loss 4.764946
[epoch6, step1312]: loss 5.058016
[epoch6, step1313]: loss 24.543276
[epoch6, step1314]: loss 33.222988
[epoch6, step1315]: loss 5.304166
[epoch6, step1316]: loss 2.782201
[epoch6, step1317]: loss 2.920393
[epoch6, step1318]: loss 16.920008
[epoch6, step1319]: loss 3.147389
[epoch6, step1320]: loss 1.283129
[epoch6, step1321]: loss 1.864812
[epoch6, step1322]: loss 14.125205
[epoch6, step1323]: loss 2.501103
[epoch6, step1324]: loss 4.166466
[epoch6, step1325]: loss 4.425404
[epoch6, step1326]: loss 33.354881
[epoch6, step1327]: loss 2.303869
[epoch6, step1328]: loss 6.901076
[epoch6, step1329]: loss 1.840208
[epoch6, step1330]: loss 5.617693
[epoch6, step1331]: loss 7.953598
[epoch6, step1332]: loss 24.096556
[epoch6, step1333]: loss 2.793192
[epoch6, step1334]: loss 36.156193
[epoch6, step1335]: loss 2.546708
[epoch6, step1336]: loss 2.319359
[epoch6, step1337]: loss 4.051942
[epoch6, step1338]: loss 19.920258
[epoch6, step1339]: loss 6.751326
[epoch6, step1340]: loss 27.425297
[epoch6, step1341]: loss 3.594521
[epoch6, step1342]: loss 4.583655
[epoch6, step1343]: loss 15.319654
[epoch6, step1344]: loss 18.048414
[epoch6, step1345]: loss 1.673167
[epoch6, step1346]: loss 3.501213
[epoch6, step1347]: loss 1.682873
[epoch6, step1348]: loss 22.576483
[epoch6, step1349]: loss 5.878903
[epoch6, step1350]: loss 17.223440
[epoch6, step1351]: loss 19.262136
[epoch6, step1352]: loss 2.286910
[epoch6, step1353]: loss 8.737049
[epoch6, step1354]: loss 3.106746
[epoch6, step1355]: loss 1.453812
[epoch6, step1356]: loss 4.705674
[epoch6, step1357]: loss 5.426992
[epoch6, step1358]: loss 3.220242
[epoch6, step1359]: loss 4.597659
[epoch6, step1360]: loss 5.163502
[epoch6, step1361]: loss 8.496723
[epoch6, step1362]: loss 34.177753
[epoch6, step1363]: loss 17.750607
[epoch6, step1364]: loss 2.952115
[epoch6, step1365]: loss 4.389173
[epoch6, step1366]: loss 9.246856
[epoch6, step1367]: loss 1.941743
[epoch6, step1368]: loss 18.817289
[epoch6, step1369]: loss 1.125283
[epoch6, step1370]: loss 10.345217
[epoch6, step1371]: loss 4.345754
[epoch6, step1372]: loss 1.796381
[epoch6, step1373]: loss 3.771919
[epoch6, step1374]: loss 6.363725
[epoch6, step1375]: loss 19.630232
[epoch6, step1376]: loss 3.063082
[epoch6, step1377]: loss 2.451659
[epoch6, step1378]: loss 14.846265
[epoch6, step1379]: loss 5.409284
[epoch6, step1380]: loss 5.108182
[epoch6, step1381]: loss 4.587446
[epoch6, step1382]: loss 12.240461
[epoch6, step1383]: loss 19.469759
[epoch6, step1384]: loss 1.895565
[epoch6, step1385]: loss 1.692226
[epoch6, step1386]: loss 2.856834
[epoch6, step1387]: loss 24.492315
[epoch6, step1388]: loss 5.411463
[epoch6, step1389]: loss 4.315026
[epoch6, step1390]: loss 3.702461
[epoch6, step1391]: loss 11.625584
[epoch6, step1392]: loss 13.011889
[epoch6, step1393]: loss 25.630167
[epoch6, step1394]: loss 1.562671
[epoch6, step1395]: loss 11.218866
[epoch6, step1396]: loss 2.697443
[epoch6, step1397]: loss 3.828089
[epoch6, step1398]: loss 26.886137
[epoch6, step1399]: loss 5.248213
[epoch6, step1400]: loss 1.672180
[epoch6, step1401]: loss 13.759683
[epoch6, step1402]: loss 4.043859
[epoch6, step1403]: loss 7.653615
[epoch6, step1404]: loss 16.440269
[epoch6, step1405]: loss 4.822948
[epoch6, step1406]: loss 3.629923
[epoch6, step1407]: loss 5.600451
[epoch6, step1408]: loss 6.687599
[epoch6, step1409]: loss 2.835501
[epoch6, step1410]: loss 4.286215
[epoch6, step1411]: loss 1.935807
[epoch6, step1412]: loss 23.623018
[epoch6, step1413]: loss 4.804087
[epoch6, step1414]: loss 1.947510
[epoch6, step1415]: loss 34.154083
[epoch6, step1416]: loss 3.341001
[epoch6, step1417]: loss 1.661404
[epoch6, step1418]: loss 3.060740
[epoch6, step1419]: loss 6.678338
[epoch6, step1420]: loss 16.274376
[epoch6, step1421]: loss 7.383008
[epoch6, step1422]: loss 2.878833
[epoch6, step1423]: loss 4.125494
[epoch6, step1424]: loss 25.135727
[epoch6, step1425]: loss 1.348775
[epoch6, step1426]: loss 1.625590
[epoch6, step1427]: loss 3.646379
[epoch6, step1428]: loss 1.880322
[epoch6, step1429]: loss 2.069600
[epoch6, step1430]: loss 3.043344
[epoch6, step1431]: loss 3.044906
[epoch6, step1432]: loss 18.420773
[epoch6, step1433]: loss 16.797886
[epoch6, step1434]: loss 2.202664
[epoch6, step1435]: loss 2.852861
[epoch6, step1436]: loss 3.788080
[epoch6, step1437]: loss 1.800603
[epoch6, step1438]: loss 7.700558
[epoch6, step1439]: loss 5.307845
[epoch6, step1440]: loss 2.071988
[epoch6, step1441]: loss 27.757801
[epoch6, step1442]: loss 1.384227
[epoch6, step1443]: loss 2.850710
[epoch6, step1444]: loss 9.150736
[epoch6, step1445]: loss 3.496617
[epoch6, step1446]: loss 41.266499
[epoch6, step1447]: loss 5.051646
[epoch6, step1448]: loss 1.253546
[epoch6, step1449]: loss 1.969919
[epoch6, step1450]: loss 6.918958
[epoch6, step1451]: loss 36.738312
[epoch6, step1452]: loss 2.515747
[epoch6, step1453]: loss 16.569122
[epoch6, step1454]: loss 1.856222
[epoch6, step1455]: loss 1.676082
[epoch6, step1456]: loss 32.095123
[epoch6, step1457]: loss 2.558849
[epoch6, step1458]: loss 3.155824
[epoch6, step1459]: loss 17.572763
[epoch6, step1460]: loss 16.637363
[epoch6, step1461]: loss 2.272218
[epoch6, step1462]: loss 6.286314
[epoch6, step1463]: loss 3.503674
[epoch6, step1464]: loss 4.001682
[epoch6, step1465]: loss 8.241486
[epoch6, step1466]: loss 3.379975
[epoch6, step1467]: loss 2.890484
[epoch6, step1468]: loss 13.273485
[epoch6, step1469]: loss 13.453398
[epoch6, step1470]: loss 3.116138
[epoch6, step1471]: loss 5.119489
[epoch6, step1472]: loss 2.140108
[epoch6, step1473]: loss 26.078554
[epoch6, step1474]: loss 13.049979
[epoch6, step1475]: loss 22.755062
[epoch6, step1476]: loss 2.416734
[epoch6, step1477]: loss 4.477770
[epoch6, step1478]: loss 2.176940
[epoch6, step1479]: loss 2.963163
[epoch6, step1480]: loss 2.918077
[epoch6, step1481]: loss 2.390166
[epoch6, step1482]: loss 1.318996
[epoch6, step1483]: loss 2.795297
[epoch6, step1484]: loss 3.774296
[epoch6, step1485]: loss 22.845629
[epoch6, step1486]: loss 2.974330
[epoch6, step1487]: loss 21.689438
[epoch6, step1488]: loss 2.778499
[epoch6, step1489]: loss 31.279268
[epoch6, step1490]: loss 1.804660
[epoch6, step1491]: loss 3.076014
[epoch6, step1492]: loss 10.641922
[epoch6, step1493]: loss 2.301537
[epoch6, step1494]: loss 2.865621
[epoch6, step1495]: loss 16.666344
[epoch6, step1496]: loss 6.991362
[epoch6, step1497]: loss 2.396471
[epoch6, step1498]: loss 17.379831
[epoch6, step1499]: loss 6.457945
[epoch6, step1500]: loss 27.233368
[epoch6, step1501]: loss 2.767186
[epoch6, step1502]: loss 5.219075
[epoch6, step1503]: loss 10.473335
[epoch6, step1504]: loss 17.612385
[epoch6, step1505]: loss 3.706791
[epoch6, step1506]: loss 14.955584
[epoch6, step1507]: loss 39.452751
[epoch6, step1508]: loss 19.739862
[epoch6, step1509]: loss 7.341934
[epoch6, step1510]: loss 11.932425
[epoch6, step1511]: loss 3.865042
[epoch6, step1512]: loss 22.057566
[epoch6, step1513]: loss 37.686291
[epoch6, step1514]: loss 7.250175
[epoch6, step1515]: loss 24.339741
[epoch6, step1516]: loss 4.029348
[epoch6, step1517]: loss 9.452855
[epoch6, step1518]: loss 2.462018
[epoch6, step1519]: loss 3.517068
[epoch6, step1520]: loss 3.440285
[epoch6, step1521]: loss 2.836743
[epoch6, step1522]: loss 7.709418
[epoch6, step1523]: loss 3.884457
[epoch6, step1524]: loss 14.759849
[epoch6, step1525]: loss 10.676834
[epoch6, step1526]: loss 4.725619
[epoch6, step1527]: loss 3.357428
[epoch6, step1528]: loss 8.117473
[epoch6, step1529]: loss 7.102293
[epoch6, step1530]: loss 6.511506
[epoch6, step1531]: loss 8.378925
[epoch6, step1532]: loss 15.882664
[epoch6, step1533]: loss 16.901884
[epoch6, step1534]: loss 3.525747
[epoch6, step1535]: loss 8.435185
[epoch6, step1536]: loss 9.285969
[epoch6, step1537]: loss 2.943984
[epoch6, step1538]: loss 42.020508
[epoch6, step1539]: loss 22.329750
[epoch6, step1540]: loss 3.503594
[epoch6, step1541]: loss 10.290162
[epoch6, step1542]: loss 21.461218
[epoch6, step1543]: loss 3.384285
[epoch6, step1544]: loss 8.306683
[epoch6, step1545]: loss 21.819004
[epoch6, step1546]: loss 2.017006
[epoch6, step1547]: loss 6.361552
[epoch6, step1548]: loss 17.273575
[epoch6, step1549]: loss 4.574620
[epoch6, step1550]: loss 20.765774
[epoch6, step1551]: loss 2.983721
[epoch6, step1552]: loss 2.939471
[epoch6, step1553]: loss 1.522865
[epoch6, step1554]: loss 2.313090
[epoch6, step1555]: loss 8.831277
[epoch6, step1556]: loss 2.545687
[epoch6, step1557]: loss 3.567473
[epoch6, step1558]: loss 25.333569
[epoch6, step1559]: loss 17.980072
[epoch6, step1560]: loss 6.107967
[epoch6, step1561]: loss 8.321443
[epoch6, step1562]: loss 3.731994
[epoch6, step1563]: loss 3.269315
[epoch6, step1564]: loss 8.079172
[epoch6, step1565]: loss 1.817619
[epoch6, step1566]: loss 6.648768
[epoch6, step1567]: loss 22.177601
[epoch6, step1568]: loss 1.715460
[epoch6, step1569]: loss 2.018813
[epoch6, step1570]: loss 2.216399
[epoch6, step1571]: loss 8.609917
[epoch6, step1572]: loss 3.142073
[epoch6, step1573]: loss 4.214064
[epoch6, step1574]: loss 22.163097
[epoch6, step1575]: loss 3.413311
[epoch6, step1576]: loss 22.305237
[epoch6, step1577]: loss 13.122811
[epoch6, step1578]: loss 10.727283
[epoch6, step1579]: loss 53.460758
[epoch6, step1580]: loss 2.453605
[epoch6, step1581]: loss 2.342296
[epoch6, step1582]: loss 9.666428
[epoch6, step1583]: loss 7.464681
[epoch6, step1584]: loss 4.381121
[epoch6, step1585]: loss 32.922394
[epoch6, step1586]: loss 8.340802
[epoch6, step1587]: loss 2.817556
[epoch6, step1588]: loss 6.376102
[epoch6, step1589]: loss 3.913627
[epoch6, step1590]: loss 9.590930
[epoch6, step1591]: loss 19.074522
[epoch6, step1592]: loss 5.021100
[epoch6, step1593]: loss 1.644018
[epoch6, step1594]: loss 4.158784
[epoch6, step1595]: loss 5.563182
[epoch6, step1596]: loss 5.113212
[epoch6, step1597]: loss 4.314004
[epoch6, step1598]: loss 18.213541
[epoch6, step1599]: loss 5.918867
[epoch6, step1600]: loss 25.543182
[epoch6, step1601]: loss 20.023201
[epoch6, step1602]: loss 6.626238
[epoch6, step1603]: loss 2.521711
[epoch6, step1604]: loss 18.913036
[epoch6, step1605]: loss 2.104103
[epoch6, step1606]: loss 1.503429
[epoch6, step1607]: loss 2.371054
[epoch6, step1608]: loss 2.164455
[epoch6, step1609]: loss 2.275761
[epoch6, step1610]: loss 1.642955
[epoch6, step1611]: loss 2.781705
[epoch6, step1612]: loss 1.656491
[epoch6, step1613]: loss 2.686842
[epoch6, step1614]: loss 10.297529
[epoch6, step1615]: loss 2.050200
[epoch6, step1616]: loss 3.346847
[epoch6, step1617]: loss 1.834310
[epoch6, step1618]: loss 28.866486
[epoch6, step1619]: loss 2.309359
[epoch6, step1620]: loss 18.420612
[epoch6, step1621]: loss 5.721936
[epoch6, step1622]: loss 8.366158
[epoch6, step1623]: loss 3.211839
[epoch6, step1624]: loss 2.012039
[epoch6, step1625]: loss 3.336771
[epoch6, step1626]: loss 32.190132
[epoch6, step1627]: loss 3.235605
[epoch6, step1628]: loss 1.262441
[epoch6, step1629]: loss 4.911933
[epoch6, step1630]: loss 17.024078
[epoch6, step1631]: loss 27.186811
[epoch6, step1632]: loss 25.640116
[epoch6, step1633]: loss 3.607369
[epoch6, step1634]: loss 3.601017
[epoch6, step1635]: loss 39.241684
[epoch6, step1636]: loss 1.762236
[epoch6, step1637]: loss 2.256424
[epoch6, step1638]: loss 2.036463
[epoch6, step1639]: loss 1.595148
[epoch6, step1640]: loss 4.060511
[epoch6, step1641]: loss 5.647449
[epoch6, step1642]: loss 6.329481
[epoch6, step1643]: loss 8.305000
[epoch6, step1644]: loss 25.204626
[epoch6, step1645]: loss 1.845273
[epoch6, step1646]: loss 5.018073
[epoch6, step1647]: loss 6.007908
[epoch6, step1648]: loss 21.928757
[epoch6, step1649]: loss 2.063734
[epoch6, step1650]: loss 3.222378
[epoch6, step1651]: loss 2.066715
[epoch6, step1652]: loss 4.653687
[epoch6, step1653]: loss 1.144791
[epoch6, step1654]: loss 5.500032
[epoch6, step1655]: loss 1.079217
[epoch6, step1656]: loss 10.426773
[epoch6, step1657]: loss 4.204813
[epoch6, step1658]: loss 3.773361
[epoch6, step1659]: loss 3.029394
[epoch6, step1660]: loss 2.741159
[epoch6, step1661]: loss 2.067442
[epoch6, step1662]: loss 7.515341
[epoch6, step1663]: loss 2.259035
[epoch6, step1664]: loss 18.152893
[epoch6, step1665]: loss 7.671329
[epoch6, step1666]: loss 3.253141
[epoch6, step1667]: loss 29.038517
[epoch6, step1668]: loss 18.853472
[epoch6, step1669]: loss 14.683643
[epoch6, step1670]: loss 6.190040
[epoch6, step1671]: loss 4.029888
[epoch6, step1672]: loss 6.290071
[epoch6, step1673]: loss 6.783118
[epoch6, step1674]: loss 14.793359
[epoch6, step1675]: loss 3.292355
[epoch6, step1676]: loss 1.617013
[epoch6, step1677]: loss 5.374083
[epoch6, step1678]: loss 3.860172
[epoch6, step1679]: loss 17.184130
[epoch6, step1680]: loss 1.867499
[epoch6, step1681]: loss 4.392585
[epoch6, step1682]: loss 4.319658
[epoch6, step1683]: loss 2.704320
[epoch6, step1684]: loss 30.224817
[epoch6, step1685]: loss 3.415264
[epoch6, step1686]: loss 21.330711
[epoch6, step1687]: loss 3.180267
[epoch6, step1688]: loss 4.814472
[epoch6, step1689]: loss 46.344017
[epoch6, step1690]: loss 7.956960
[epoch6, step1691]: loss 2.873508
[epoch6, step1692]: loss 32.336937
[epoch6, step1693]: loss 7.194043
[epoch6, step1694]: loss 5.673277
[epoch6, step1695]: loss 2.986077
[epoch6, step1696]: loss 3.234236
[epoch6, step1697]: loss 1.159822
[epoch6, step1698]: loss 2.020706
[epoch6, step1699]: loss 14.520350
[epoch6, step1700]: loss 3.126694
[epoch6, step1701]: loss 9.172632
[epoch6, step1702]: loss 1.728145
[epoch6, step1703]: loss 27.926476
[epoch6, step1704]: loss 3.126620
[epoch6, step1705]: loss 13.404991
[epoch6, step1706]: loss 25.922907
[epoch6, step1707]: loss 2.039242
[epoch6, step1708]: loss 2.768496
[epoch6, step1709]: loss 1.634497
[epoch6, step1710]: loss 3.228832
[epoch6, step1711]: loss 3.936269
[epoch6, step1712]: loss 31.074579
[epoch6, step1713]: loss 11.060939
[epoch6, step1714]: loss 6.018851
[epoch6, step1715]: loss 3.272019
[epoch6, step1716]: loss 7.282731
[epoch6, step1717]: loss 2.688555
[epoch6, step1718]: loss 2.889352
[epoch6, step1719]: loss 7.137011
[epoch6, step1720]: loss 1.391270
[epoch6, step1721]: loss 1.905858
[epoch6, step1722]: loss 3.468771
[epoch6, step1723]: loss 3.953161
[epoch6, step1724]: loss 2.683755
[epoch6, step1725]: loss 3.528273
[epoch6, step1726]: loss 2.465370
[epoch6, step1727]: loss 7.542231
[epoch6, step1728]: loss 21.208242
[epoch6, step1729]: loss 2.233315
[epoch6, step1730]: loss 6.672335
[epoch6, step1731]: loss 15.035499
[epoch6, step1732]: loss 5.176439
[epoch6, step1733]: loss 5.049546
[epoch6, step1734]: loss 2.081289
[epoch6, step1735]: loss 11.393725
[epoch6, step1736]: loss 5.465592
[epoch6, step1737]: loss 30.563128
[epoch6, step1738]: loss 3.194587
[epoch6, step1739]: loss 3.465347
[epoch6, step1740]: loss 1.659439
[epoch6, step1741]: loss 17.232365
[epoch6, step1742]: loss 2.250150
[epoch6, step1743]: loss 7.688046
[epoch6, step1744]: loss 1.860613
[epoch6, step1745]: loss 1.745313
[epoch6, step1746]: loss 4.327556
[epoch6, step1747]: loss 3.137191
[epoch6, step1748]: loss 4.758792
[epoch6, step1749]: loss 3.302843
[epoch6, step1750]: loss 9.500916
[epoch6, step1751]: loss 30.952841
[epoch6, step1752]: loss 1.954196
[epoch6, step1753]: loss 23.499037
[epoch6, step1754]: loss 4.119618
[epoch6, step1755]: loss 12.101267
[epoch6, step1756]: loss 27.211094
[epoch6, step1757]: loss 32.150959
[epoch6, step1758]: loss 18.374929
[epoch6, step1759]: loss 2.929450
[epoch6, step1760]: loss 6.758121
[epoch6, step1761]: loss 1.896123
[epoch6, step1762]: loss 5.105339
[epoch6, step1763]: loss 6.103261
[epoch6, step1764]: loss 19.979061
[epoch6, step1765]: loss 8.870174
[epoch6, step1766]: loss 8.010386
[epoch6, step1767]: loss 4.553953
[epoch6, step1768]: loss 7.569893
[epoch6, step1769]: loss 19.654291
[epoch6, step1770]: loss 20.427967
[epoch6, step1771]: loss 6.851179
[epoch6, step1772]: loss 2.854134
[epoch6, step1773]: loss 32.497349
[epoch6, step1774]: loss 24.623739
[epoch6, step1775]: loss 8.362655
[epoch6, step1776]: loss 29.504070
[epoch6, step1777]: loss 5.505711
[epoch6, step1778]: loss 9.209867
[epoch6, step1779]: loss 1.704510
[epoch6, step1780]: loss 2.448035
[epoch6, step1781]: loss 9.618471
[epoch6, step1782]: loss 3.298417
[epoch6, step1783]: loss 1.486874
[epoch6, step1784]: loss 6.520035
[epoch6, step1785]: loss 1.118432
[epoch6, step1786]: loss 5.087726
[epoch6, step1787]: loss 3.753450
[epoch6, step1788]: loss 14.187913
[epoch6, step1789]: loss 2.729849
[epoch6, step1790]: loss 7.287804
[epoch6, step1791]: loss 4.217381
[epoch6, step1792]: loss 2.880361
[epoch6, step1793]: loss 4.431487
[epoch6, step1794]: loss 5.784297
[epoch6, step1795]: loss 5.318008
[epoch6, step1796]: loss 10.318805
[epoch6, step1797]: loss 26.995525
[epoch6, step1798]: loss 18.941101
[epoch6, step1799]: loss 6.537453
[epoch6, step1800]: loss 2.599122
[epoch6, step1801]: loss 19.535902
[epoch6, step1802]: loss 2.803113
[epoch6, step1803]: loss 21.526236
[epoch6, step1804]: loss 4.984658
[epoch6, step1805]: loss 7.383517
[epoch6, step1806]: loss 7.648592
[epoch6, step1807]: loss 4.967791
[epoch6, step1808]: loss 24.655979
[epoch6, step1809]: loss 1.664078
[epoch6, step1810]: loss 8.896091
[epoch6, step1811]: loss 2.391866
[epoch6, step1812]: loss 1.170300
[epoch6, step1813]: loss 3.551017
[epoch6, step1814]: loss 7.324574
[epoch6, step1815]: loss 43.542046
[epoch6, step1816]: loss 2.220097
[epoch6, step1817]: loss 3.677711
[epoch6, step1818]: loss 13.170146
[epoch6, step1819]: loss 10.844647
[epoch6, step1820]: loss 3.871337
[epoch6, step1821]: loss 24.272646
[epoch6, step1822]: loss 3.345315
[epoch6, step1823]: loss 17.959435
[epoch6, step1824]: loss 2.227940
[epoch6, step1825]: loss 6.459512
[epoch6, step1826]: loss 2.335244
[epoch6, step1827]: loss 8.741103
[epoch6, step1828]: loss 2.606784
[epoch6, step1829]: loss 8.803138
[epoch6, step1830]: loss 2.635297
[epoch6, step1831]: loss 8.330631
[epoch6, step1832]: loss 1.313298
[epoch6, step1833]: loss 23.235853
[epoch6, step1834]: loss 12.086583
[epoch6, step1835]: loss 1.559434
[epoch6, step1836]: loss 24.193783
[epoch6, step1837]: loss 11.198752
[epoch6, step1838]: loss 35.868450
[epoch6, step1839]: loss 30.811117
[epoch6, step1840]: loss 2.128930
[epoch6, step1841]: loss 19.391768
[epoch6, step1842]: loss 6.230929
[epoch6, step1843]: loss 4.435914
[epoch6, step1844]: loss 5.474180
[epoch6, step1845]: loss 2.681538
[epoch6, step1846]: loss 1.266879
[epoch6, step1847]: loss 26.803801
[epoch6, step1848]: loss 20.921015
[epoch6, step1849]: loss 5.883450
[epoch6, step1850]: loss 2.320505
[epoch6, step1851]: loss 28.693748
[epoch6, step1852]: loss 6.066132
[epoch6, step1853]: loss 6.672816
[epoch6, step1854]: loss 6.084749
[epoch6, step1855]: loss 2.821594
[epoch6, step1856]: loss 7.435789
[epoch6, step1857]: loss 4.208049
[epoch6, step1858]: loss 2.194480
[epoch6, step1859]: loss 2.840114
[epoch6, step1860]: loss 4.478983
[epoch6, step1861]: loss 1.811437
[epoch6, step1862]: loss 3.015122
[epoch6, step1863]: loss 4.912229
[epoch6, step1864]: loss 3.019636
[epoch6, step1865]: loss 4.752226
[epoch6, step1866]: loss 5.145045
[epoch6, step1867]: loss 1.504804
[epoch6, step1868]: loss 3.512817
[epoch6, step1869]: loss 3.566864
[epoch6, step1870]: loss 2.755323
[epoch6, step1871]: loss 2.995863
[epoch6, step1872]: loss 3.302911
[epoch6, step1873]: loss 6.781610
[epoch6, step1874]: loss 5.756842
[epoch6, step1875]: loss 18.131889
[epoch6, step1876]: loss 2.435478
[epoch6, step1877]: loss 8.696166
[epoch6, step1878]: loss 22.852884
[epoch6, step1879]: loss 2.310407
[epoch6, step1880]: loss 24.887337
[epoch6, step1881]: loss 22.838453
[epoch6, step1882]: loss 1.754758
[epoch6, step1883]: loss 12.319459
[epoch6, step1884]: loss 7.720040
[epoch6, step1885]: loss 1.817132
[epoch6, step1886]: loss 36.364288
[epoch6, step1887]: loss 2.533636
[epoch6, step1888]: loss 1.613400
[epoch6, step1889]: loss 2.407338
[epoch6, step1890]: loss 4.776106
[epoch6, step1891]: loss 3.674520
[epoch6, step1892]: loss 2.774591
[epoch6, step1893]: loss 2.171142
[epoch6, step1894]: loss 23.020802
[epoch6, step1895]: loss 17.722788
[epoch6, step1896]: loss 8.933529
[epoch6, step1897]: loss 19.725979
[epoch6, step1898]: loss 1.490570
[epoch6, step1899]: loss 18.269096
[epoch6, step1900]: loss 19.004484
[epoch6, step1901]: loss 1.997744
[epoch6, step1902]: loss 2.370100
[epoch6, step1903]: loss 24.956219
[epoch6, step1904]: loss 2.824156
[epoch6, step1905]: loss 5.134192
[epoch6, step1906]: loss 18.972067
[epoch6, step1907]: loss 2.878561
[epoch6, step1908]: loss 3.112062
[epoch6, step1909]: loss 12.699230
[epoch6, step1910]: loss 23.543571
[epoch6, step1911]: loss 5.012903
[epoch6, step1912]: loss 1.917047
[epoch6, step1913]: loss 3.075852
[epoch6, step1914]: loss 8.026727
[epoch6, step1915]: loss 9.043641
[epoch6, step1916]: loss 3.137582
[epoch6, step1917]: loss 20.983398
[epoch6, step1918]: loss 14.262591
[epoch6, step1919]: loss 7.022946
[epoch6, step1920]: loss 1.774199
[epoch6, step1921]: loss 1.972057
[epoch6, step1922]: loss 7.893590
[epoch6, step1923]: loss 2.765270
[epoch6, step1924]: loss 5.181715
[epoch6, step1925]: loss 3.067765
[epoch6, step1926]: loss 2.282907
[epoch6, step1927]: loss 3.277544
[epoch6, step1928]: loss 19.488623
[epoch6, step1929]: loss 2.250420
[epoch6, step1930]: loss 8.521114
[epoch6, step1931]: loss 15.941194
[epoch6, step1932]: loss 3.174193
[epoch6, step1933]: loss 1.981102
[epoch6, step1934]: loss 4.976310
[epoch6, step1935]: loss 5.801641
[epoch6, step1936]: loss 3.730722
[epoch6, step1937]: loss 16.194052
[epoch6, step1938]: loss 7.393008
[epoch6, step1939]: loss 4.100842
[epoch6, step1940]: loss 15.268842
[epoch6, step1941]: loss 2.362260
[epoch6, step1942]: loss 1.723893
[epoch6, step1943]: loss 6.751618
[epoch6, step1944]: loss 5.344547
[epoch6, step1945]: loss 18.666138
[epoch6, step1946]: loss 2.733553
[epoch6, step1947]: loss 7.754369
[epoch6, step1948]: loss 18.434315
[epoch6, step1949]: loss 5.123500
[epoch6, step1950]: loss 19.564947
[epoch6, step1951]: loss 9.377886
[epoch6, step1952]: loss 15.886453
[epoch6, step1953]: loss 5.382345
[epoch6, step1954]: loss 2.592386
[epoch6, step1955]: loss 10.302664
[epoch6, step1956]: loss 1.690473
[epoch6, step1957]: loss 4.063814
[epoch6, step1958]: loss 6.530069
[epoch6, step1959]: loss 4.921732
[epoch6, step1960]: loss 17.485355
[epoch6, step1961]: loss 22.174271
[epoch6, step1962]: loss 2.582444
[epoch6, step1963]: loss 19.647835
[epoch6, step1964]: loss 8.421434
[epoch6, step1965]: loss 23.999744
[epoch6, step1966]: loss 2.715518
[epoch6, step1967]: loss 2.075051
[epoch6, step1968]: loss 1.790775
[epoch6, step1969]: loss 4.635542
[epoch6, step1970]: loss 4.230210
[epoch6, step1971]: loss 3.518295
[epoch6, step1972]: loss 1.824522
[epoch6, step1973]: loss 2.972703
[epoch6, step1974]: loss 3.986543
[epoch6, step1975]: loss 7.328473
[epoch6, step1976]: loss 12.512986
[epoch6, step1977]: loss 17.400064
[epoch6, step1978]: loss 5.071769
[epoch6, step1979]: loss 22.870729
[epoch6, step1980]: loss 24.078259
[epoch6, step1981]: loss 33.364624
[epoch6, step1982]: loss 17.147263
[epoch6, step1983]: loss 3.959082
[epoch6, step1984]: loss 3.697929
[epoch6, step1985]: loss 4.040084
[epoch6, step1986]: loss 3.441757
[epoch6, step1987]: loss 2.658790
[epoch6, step1988]: loss 11.840196
[epoch6, step1989]: loss 20.164497
[epoch6, step1990]: loss 6.159384
[epoch6, step1991]: loss 5.422855
[epoch6, step1992]: loss 1.659453
[epoch6, step1993]: loss 5.164185
[epoch6, step1994]: loss 3.112065
[epoch6, step1995]: loss 15.078895
[epoch6, step1996]: loss 28.591984
[epoch6, step1997]: loss 7.369408
[epoch6, step1998]: loss 30.560875
[epoch6, step1999]: loss 7.742610
[epoch6, step2000]: loss 23.035004
[epoch6, step2001]: loss 13.293775
[epoch6, step2002]: loss 21.667622
[epoch6, step2003]: loss 46.205692
[epoch6, step2004]: loss 4.897424
[epoch6, step2005]: loss 2.141041
[epoch6, step2006]: loss 15.301507
[epoch6, step2007]: loss 16.316399
[epoch6, step2008]: loss 5.317521
[epoch6, step2009]: loss 20.330618
[epoch6, step2010]: loss 25.966164
[epoch6, step2011]: loss 17.767494
[epoch6, step2012]: loss 17.543755
[epoch6, step2013]: loss 51.657356
[epoch6, step2014]: loss 13.313626
[epoch6, step2015]: loss 9.175406
[epoch6, step2016]: loss 3.639952
[epoch6, step2017]: loss 2.814052
[epoch6, step2018]: loss 12.937151
[epoch6, step2019]: loss 3.775986
[epoch6, step2020]: loss 2.783507
[epoch6, step2021]: loss 2.715775
[epoch6, step2022]: loss 5.355009
[epoch6, step2023]: loss 14.312197
[epoch6, step2024]: loss 2.901263
[epoch6, step2025]: loss 3.987269
[epoch6, step2026]: loss 3.118974
[epoch6, step2027]: loss 10.125124
[epoch6, step2028]: loss 10.243533
[epoch6, step2029]: loss 4.116295
[epoch6, step2030]: loss 8.146696
[epoch6, step2031]: loss 6.625311
[epoch6, step2032]: loss 3.442529
[epoch6, step2033]: loss 11.667103
[epoch6, step2034]: loss 4.608705
[epoch6, step2035]: loss 1.441844
[epoch6, step2036]: loss 2.471344
[epoch6, step2037]: loss 24.764639
[epoch6, step2038]: loss 15.822219
[epoch6, step2039]: loss 3.077796
[epoch6, step2040]: loss 2.448300
[epoch6, step2041]: loss 27.407207
[epoch6, step2042]: loss 12.328279
[epoch6, step2043]: loss 30.783001
[epoch6, step2044]: loss 3.012920
[epoch6, step2045]: loss 1.655685
[epoch6, step2046]: loss 2.083211
[epoch6, step2047]: loss 2.291486
[epoch6, step2048]: loss 2.425649
[epoch6, step2049]: loss 1.678081
[epoch6, step2050]: loss 19.846088
[epoch6, step2051]: loss 27.557743
[epoch6, step2052]: loss 2.153744
[epoch6, step2053]: loss 8.362561
[epoch6, step2054]: loss 4.024294
[epoch6, step2055]: loss 1.791864
[epoch6, step2056]: loss 19.576675
[epoch6, step2057]: loss 5.332569
[epoch6, step2058]: loss 6.624193
[epoch6, step2059]: loss 3.067260
[epoch6, step2060]: loss 7.092295
[epoch6, step2061]: loss 4.815933
[epoch6, step2062]: loss 24.346544
[epoch6, step2063]: loss 10.592216
[epoch6, step2064]: loss 17.312048
[epoch6, step2065]: loss 17.804434
[epoch6, step2066]: loss 33.015739
[epoch6, step2067]: loss 1.438615
[epoch6, step2068]: loss 31.277327
[epoch6, step2069]: loss 12.909357
[epoch6, step2070]: loss 20.375505
[epoch6, step2071]: loss 2.362061
[epoch6, step2072]: loss 6.517857
[epoch6, step2073]: loss 8.590101
[epoch6, step2074]: loss 10.691511
[epoch6, step2075]: loss 2.468254
[epoch6, step2076]: loss 20.702618
[epoch6, step2077]: loss 17.324169
[epoch6, step2078]: loss 3.363216
[epoch6, step2079]: loss 2.689360
[epoch6, step2080]: loss 8.782061
[epoch6, step2081]: loss 2.624768
[epoch6, step2082]: loss 19.375975
[epoch6, step2083]: loss 2.175909
[epoch6, step2084]: loss 2.272905
[epoch6, step2085]: loss 2.818992
[epoch6, step2086]: loss 3.159825
[epoch6, step2087]: loss 2.605841
[epoch6, step2088]: loss 3.574995
[epoch6, step2089]: loss 3.907083
[epoch6, step2090]: loss 1.614240
[epoch6, step2091]: loss 2.903603
[epoch6, step2092]: loss 1.287149
[epoch6, step2093]: loss 7.928733
[epoch6, step2094]: loss 15.111259
[epoch6, step2095]: loss 1.120929
[epoch6, step2096]: loss 1.909050
[epoch6, step2097]: loss 4.582764
[epoch6, step2098]: loss 6.233675
[epoch6, step2099]: loss 4.866699
[epoch6, step2100]: loss 1.260620
[epoch6, step2101]: loss 4.092465
[epoch6, step2102]: loss 4.245261
[epoch6, step2103]: loss 23.380022
[epoch6, step2104]: loss 3.112774
[epoch6, step2105]: loss 4.584062
[epoch6, step2106]: loss 18.751774
[epoch6, step2107]: loss 19.019348
[epoch6, step2108]: loss 1.814357
[epoch6, step2109]: loss 6.138223
[epoch6, step2110]: loss 8.627926
[epoch6, step2111]: loss 4.152588
[epoch6, step2112]: loss 1.782448
[epoch6, step2113]: loss 1.251291
[epoch6, step2114]: loss 2.344813
[epoch6, step2115]: loss 4.920541
[epoch6, step2116]: loss 2.709283
[epoch6, step2117]: loss 4.724896
[epoch6, step2118]: loss 2.795141
[epoch6, step2119]: loss 4.679873
[epoch6, step2120]: loss 8.605506
[epoch6, step2121]: loss 3.339512
[epoch6, step2122]: loss 8.541213
[epoch6, step2123]: loss 2.441351
[epoch6, step2124]: loss 2.117444
[epoch6, step2125]: loss 6.530159
[epoch6, step2126]: loss 25.763029
[epoch6, step2127]: loss 1.341878
[epoch6, step2128]: loss 4.212650
[epoch6, step2129]: loss 4.135386
[epoch6, step2130]: loss 2.349097
[epoch6, step2131]: loss 2.473733
[epoch6, step2132]: loss 4.739713
[epoch6, step2133]: loss 1.882671
[epoch6, step2134]: loss 23.276127
[epoch6, step2135]: loss 2.289591
[epoch6, step2136]: loss 1.916579
[epoch6, step2137]: loss 8.051548
[epoch6, step2138]: loss 11.204393
[epoch6, step2139]: loss 20.187681
[epoch6, step2140]: loss 2.130563
[epoch6, step2141]: loss 5.797531
[epoch6, step2142]: loss 22.209116
[epoch6, step2143]: loss 18.050682
[epoch6, step2144]: loss 9.471648
[epoch6, step2145]: loss 3.060929
[epoch6, step2146]: loss 3.332296
[epoch6, step2147]: loss 4.892824
[epoch6, step2148]: loss 4.226079
[epoch6, step2149]: loss 7.819489
[epoch6, step2150]: loss 2.301547
[epoch6, step2151]: loss 13.694116
[epoch6, step2152]: loss 2.894645
[epoch6, step2153]: loss 6.818370
[epoch6, step2154]: loss 3.331291
[epoch6, step2155]: loss 7.568109
[epoch6, step2156]: loss 3.951553
[epoch6, step2157]: loss 4.894913
[epoch6, step2158]: loss 4.368051
[epoch6, step2159]: loss 3.158616
[epoch6, step2160]: loss 10.259442
[epoch6, step2161]: loss 8.414641
[epoch6, step2162]: loss 3.638994
[epoch6, step2163]: loss 2.263815
[epoch6, step2164]: loss 5.741705
[epoch6, step2165]: loss 30.850689
[epoch6, step2166]: loss 2.058718
[epoch6, step2167]: loss 16.192627
[epoch6, step2168]: loss 1.727669
[epoch6, step2169]: loss 5.528094
[epoch6, step2170]: loss 3.152632
[epoch6, step2171]: loss 2.648834
[epoch6, step2172]: loss 5.216125
[epoch6, step2173]: loss 21.650620
[epoch6, step2174]: loss 6.170287
[epoch6, step2175]: loss 3.548945
[epoch6, step2176]: loss 17.952740
[epoch6, step2177]: loss 2.619455
[epoch6, step2178]: loss 6.236112
[epoch6, step2179]: loss 17.057966
[epoch6, step2180]: loss 6.779038
[epoch6, step2181]: loss 4.224070
[epoch6, step2182]: loss 1.719754
[epoch6, step2183]: loss 5.039706
[epoch6, step2184]: loss 2.062262
[epoch6, step2185]: loss 7.082085
[epoch6, step2186]: loss 17.507910
[epoch6, step2187]: loss 19.491032
[epoch6, step2188]: loss 1.736055
[epoch6, step2189]: loss 33.190407
[epoch6, step2190]: loss 2.086181
[epoch6, step2191]: loss 3.025123
[epoch6, step2192]: loss 4.284771
[epoch6, step2193]: loss 2.276860
[epoch6, step2194]: loss 15.360034
[epoch6, step2195]: loss 4.278368
[epoch6, step2196]: loss 1.225445
[epoch6, step2197]: loss 17.888494
[epoch6, step2198]: loss 7.654705
[epoch6, step2199]: loss 5.855469
[epoch6, step2200]: loss 3.134980
[epoch6, step2201]: loss 2.561357
[epoch6, step2202]: loss 3.616499
[epoch6, step2203]: loss 27.492573
[epoch6, step2204]: loss 3.504075
[epoch6, step2205]: loss 17.825268
[epoch6, step2206]: loss 3.426774
[epoch6, step2207]: loss 6.409607
[epoch6, step2208]: loss 13.656302
[epoch6, step2209]: loss 27.556969
[epoch6, step2210]: loss 20.618298
[epoch6, step2211]: loss 5.420893
[epoch6, step2212]: loss 1.387949
[epoch6, step2213]: loss 2.280527
[epoch6, step2214]: loss 4.254483
[epoch6, step2215]: loss 4.058622
[epoch6, step2216]: loss 3.762027
[epoch6, step2217]: loss 20.135262
[epoch6, step2218]: loss 4.582532
[epoch6, step2219]: loss 18.734816
[epoch6, step2220]: loss 1.552164
[epoch6, step2221]: loss 8.159901
[epoch6, step2222]: loss 18.774796
[epoch6, step2223]: loss 3.453854
[epoch6, step2224]: loss 22.853535
[epoch6, step2225]: loss 8.517886
[epoch6, step2226]: loss 26.134605
[epoch6, step2227]: loss 2.908290
[epoch6, step2228]: loss 3.672390
[epoch6, step2229]: loss 4.313190
[epoch6, step2230]: loss 7.150719
[epoch6, step2231]: loss 4.267856
[epoch6, step2232]: loss 1.511365
[epoch6, step2233]: loss 1.124451
[epoch6, step2234]: loss 3.527706
[epoch6, step2235]: loss 3.454391
[epoch6, step2236]: loss 4.098585
[epoch6, step2237]: loss 5.056142
[epoch6, step2238]: loss 4.084711
[epoch6, step2239]: loss 3.072986
[epoch6, step2240]: loss 2.088003
[epoch6, step2241]: loss 34.918785
[epoch6, step2242]: loss 9.593649
[epoch6, step2243]: loss 3.233248
[epoch6, step2244]: loss 3.528249
[epoch6, step2245]: loss 15.991344
[epoch6, step2246]: loss 2.457802
[epoch6, step2247]: loss 2.973845
[epoch6, step2248]: loss 2.955014
[epoch6, step2249]: loss 5.226295
[epoch6, step2250]: loss 20.291567
[epoch6, step2251]: loss 24.122099
[epoch6, step2252]: loss 2.591917
[epoch6, step2253]: loss 24.721731
[epoch6, step2254]: loss 19.405283
[epoch6, step2255]: loss 2.845712
[epoch6, step2256]: loss 16.527605
[epoch6, step2257]: loss 20.355604
[epoch6, step2258]: loss 18.839401
[epoch6, step2259]: loss 4.986660
[epoch6, step2260]: loss 2.094256
[epoch6, step2261]: loss 5.034940
[epoch6, step2262]: loss 2.573856
[epoch6, step2263]: loss 1.437184
[epoch6, step2264]: loss 5.559898
[epoch6, step2265]: loss 2.497033
[epoch6, step2266]: loss 3.266572
[epoch6, step2267]: loss 3.185560
[epoch6, step2268]: loss 4.480241
[epoch6, step2269]: loss 40.132393
[epoch6, step2270]: loss 4.401256
[epoch6, step2271]: loss 17.228235
[epoch6, step2272]: loss 30.014336
[epoch6, step2273]: loss 1.349488
[epoch6, step2274]: loss 7.270092
[epoch6, step2275]: loss 6.215505
[epoch6, step2276]: loss 3.243303
[epoch6, step2277]: loss 7.451053
[epoch6, step2278]: loss 20.908075
[epoch6, step2279]: loss 2.261075
[epoch6, step2280]: loss 3.915076
[epoch6, step2281]: loss 13.432086
[epoch6, step2282]: loss 7.848800
[epoch6, step2283]: loss 4.381994
[epoch6, step2284]: loss 8.529078
[epoch6, step2285]: loss 1.005794
[epoch6, step2286]: loss 20.948488
[epoch6, step2287]: loss 2.590726
[epoch6, step2288]: loss 9.885436
[epoch6, step2289]: loss 2.313090
[epoch6, step2290]: loss 4.107357
[epoch6, step2291]: loss 27.760784
[epoch6, step2292]: loss 2.212518
[epoch6, step2293]: loss 2.974227
[epoch6, step2294]: loss 26.980232
[epoch6, step2295]: loss 3.719747
[epoch6, step2296]: loss 2.286357
[epoch6, step2297]: loss 2.059442
[epoch6, step2298]: loss 5.998368
[epoch6, step2299]: loss 34.869476
[epoch6, step2300]: loss 2.646442
[epoch6, step2301]: loss 23.218212
[epoch6, step2302]: loss 6.331020
[epoch6, step2303]: loss 4.704405
[epoch6, step2304]: loss 3.344007
[epoch6, step2305]: loss 1.630079
[epoch6, step2306]: loss 16.606157
[epoch6, step2307]: loss 3.618385
[epoch6, step2308]: loss 1.888491
[epoch6, step2309]: loss 25.144030
[epoch6, step2310]: loss 2.762333
[epoch6, step2311]: loss 2.783857
[epoch6, step2312]: loss 3.049589
[epoch6, step2313]: loss 2.771787
[epoch6, step2314]: loss 4.104382
[epoch6, step2315]: loss 1.510893
[epoch6, step2316]: loss 15.813352
[epoch6, step2317]: loss 3.560018
[epoch6, step2318]: loss 9.181033
[epoch6, step2319]: loss 22.548578
[epoch6, step2320]: loss 20.594784
[epoch6, step2321]: loss 3.586410
[epoch6, step2322]: loss 3.321853
[epoch6, step2323]: loss 12.898494
[epoch6, step2324]: loss 2.163828
[epoch6, step2325]: loss 8.727367
[epoch6, step2326]: loss 15.368038
[epoch6, step2327]: loss 4.294400
[epoch6, step2328]: loss 6.904338
[epoch6, step2329]: loss 1.285710
[epoch6, step2330]: loss 1.798151
[epoch6, step2331]: loss 8.426410
[epoch6, step2332]: loss 3.914054
[epoch6, step2333]: loss 14.223365
[epoch6, step2334]: loss 1.895174
[epoch6, step2335]: loss 6.066656
[epoch6, step2336]: loss 14.801088
[epoch6, step2337]: loss 3.913791
[epoch6, step2338]: loss 2.515901
[epoch6, step2339]: loss 18.959148
[epoch6, step2340]: loss 2.368821
[epoch6, step2341]: loss 4.136760
[epoch6, step2342]: loss 2.425685
[epoch6, step2343]: loss 1.704329
[epoch6, step2344]: loss 2.936987
[epoch6, step2345]: loss 3.759229
[epoch6, step2346]: loss 2.335521
[epoch6, step2347]: loss 32.418991
[epoch6, step2348]: loss 5.837953
[epoch6, step2349]: loss 1.278073
[epoch6, step2350]: loss 14.998649
[epoch6, step2351]: loss 19.579920
[epoch6, step2352]: loss 5.655186
[epoch6, step2353]: loss 23.038795
[epoch6, step2354]: loss 22.435841
[epoch6, step2355]: loss 1.748126
[epoch6, step2356]: loss 10.051452
[epoch6, step2357]: loss 2.312169
[epoch6, step2358]: loss 4.100904
[epoch6, step2359]: loss 13.126584
[epoch6, step2360]: loss 2.540888
[epoch6, step2361]: loss 1.429107
[epoch6, step2362]: loss 1.449768
[epoch6, step2363]: loss 17.416636
[epoch6, step2364]: loss 4.398879
[epoch6, step2365]: loss 21.313257
[epoch6, step2366]: loss 23.340780
[epoch6, step2367]: loss 3.837249
[epoch6, step2368]: loss 17.877970
[epoch6, step2369]: loss 12.462603
[epoch6, step2370]: loss 3.563844
[epoch6, step2371]: loss 3.603981
[epoch6, step2372]: loss 22.491261
[epoch6, step2373]: loss 4.343820
[epoch6, step2374]: loss 1.947209
[epoch6, step2375]: loss 9.022375
[epoch6, step2376]: loss 10.136704
[epoch6, step2377]: loss 1.931112
[epoch6, step2378]: loss 17.715336
[epoch6, step2379]: loss 5.153525
[epoch6, step2380]: loss 20.589268
[epoch6, step2381]: loss 6.869966
[epoch6, step2382]: loss 1.976829
[epoch6, step2383]: loss 3.262192
[epoch6, step2384]: loss 5.023934
[epoch6, step2385]: loss 1.582621
[epoch6, step2386]: loss 21.395672
[epoch6, step2387]: loss 4.770940
[epoch6, step2388]: loss 5.989564
[epoch6, step2389]: loss 10.865412
[epoch6, step2390]: loss 1.548946
[epoch6, step2391]: loss 39.556389
[epoch6, step2392]: loss 1.843359
[epoch6, step2393]: loss 21.157211
[epoch6, step2394]: loss 2.835367
[epoch6, step2395]: loss 1.793111
[epoch6, step2396]: loss 6.646920
[epoch6, step2397]: loss 13.200821
[epoch6, step2398]: loss 21.550585
[epoch6, step2399]: loss 13.037906
[epoch6, step2400]: loss 3.882115
[epoch6, step2401]: loss 37.728287
[epoch6, step2402]: loss 14.999567
[epoch6, step2403]: loss 4.877736
[epoch6, step2404]: loss 2.428463
[epoch6, step2405]: loss 7.302573
[epoch6, step2406]: loss 2.352681
[epoch6, step2407]: loss 2.736012
[epoch6, step2408]: loss 12.418659
[epoch6, step2409]: loss 3.463774
[epoch6, step2410]: loss 4.175358
[epoch6, step2411]: loss 2.470158
[epoch6, step2412]: loss 2.349951
[epoch6, step2413]: loss 2.008054
[epoch6, step2414]: loss 1.819189
[epoch6, step2415]: loss 7.636445
[epoch6, step2416]: loss 1.373231
[epoch6, step2417]: loss 28.211582
[epoch6, step2418]: loss 9.182977
[epoch6, step2419]: loss 2.586232
[epoch6, step2420]: loss 1.511430
[epoch6, step2421]: loss 2.994482
[epoch6, step2422]: loss 4.326858
[epoch6, step2423]: loss 3.123362
[epoch6, step2424]: loss 5.202558
[epoch6, step2425]: loss 1.308000
[epoch6, step2426]: loss 2.101873
[epoch6, step2427]: loss 2.818595
[epoch6, step2428]: loss 10.168656
[epoch6, step2429]: loss 1.427459
[epoch6, step2430]: loss 3.794340
[epoch6, step2431]: loss 11.847923
[epoch6, step2432]: loss 1.784993
[epoch6, step2433]: loss 4.083373
[epoch6, step2434]: loss 3.588668
[epoch6, step2435]: loss 27.041702
[epoch6, step2436]: loss 10.817784
[epoch6, step2437]: loss 4.212675
[epoch6, step2438]: loss 9.918546
[epoch6, step2439]: loss 1.357769
[epoch6, step2440]: loss 21.679392
[epoch6, step2441]: loss 3.353296
[epoch6, step2442]: loss 21.606169
[epoch6, step2443]: loss 2.035140
[epoch6, step2444]: loss 34.671158
[epoch6, step2445]: loss 1.619132
[epoch6, step2446]: loss 5.069455
[epoch6, step2447]: loss 2.667298
[epoch6, step2448]: loss 1.669634
[epoch6, step2449]: loss 4.401776
[epoch6, step2450]: loss 3.222914
[epoch6, step2451]: loss 19.303331
[epoch6, step2452]: loss 3.711398
[epoch6, step2453]: loss 4.248304
[epoch6, step2454]: loss 4.211863
[epoch6, step2455]: loss 8.713072
[epoch6, step2456]: loss 34.939137
[epoch6, step2457]: loss 20.844088
[epoch6, step2458]: loss 22.287834
[epoch6, step2459]: loss 2.733253
[epoch6, step2460]: loss 8.139800
[epoch6, step2461]: loss 17.882164
[epoch6, step2462]: loss 9.960436
[epoch6, step2463]: loss 5.314071
[epoch6, step2464]: loss 17.151688
[epoch6, step2465]: loss 2.059116
[epoch6, step2466]: loss 5.816943
[epoch6, step2467]: loss 3.816533
[epoch6, step2468]: loss 3.134883
[epoch6, step2469]: loss 18.062357
[epoch6, step2470]: loss 17.547453
[epoch6, step2471]: loss 16.563753
[epoch6, step2472]: loss 3.126970
[epoch6, step2473]: loss 22.027222
[epoch6, step2474]: loss 2.595015
[epoch6, step2475]: loss 3.725331
[epoch6, step2476]: loss 2.805895
[epoch6, step2477]: loss 24.114395
[epoch6, step2478]: loss 27.116421
[epoch6, step2479]: loss 2.088012
[epoch6, step2480]: loss 1.829648
[epoch6, step2481]: loss 17.193335
[epoch6, step2482]: loss 6.248934
[epoch6, step2483]: loss 5.870593
[epoch6, step2484]: loss 3.456281
[epoch6, step2485]: loss 3.598779
[epoch6, step2486]: loss 1.939614
[epoch6, step2487]: loss 18.866550
[epoch6, step2488]: loss 4.805415
[epoch6, step2489]: loss 11.881673
[epoch6, step2490]: loss 2.725106
[epoch6, step2491]: loss 6.859024
[epoch6, step2492]: loss 18.852383
[epoch6, step2493]: loss 18.927116
[epoch6, step2494]: loss 4.509089
[epoch6, step2495]: loss 5.584588
[epoch6, step2496]: loss 3.012738
[epoch6, step2497]: loss 2.124996
[epoch6, step2498]: loss 28.395784
[epoch6, step2499]: loss 3.597530
[epoch6, step2500]: loss 7.207600
[epoch6, step2501]: loss 1.747349
[epoch6, step2502]: loss 1.398986
[epoch6, step2503]: loss 1.615851
[epoch6, step2504]: loss 4.063979
[epoch6, step2505]: loss 24.785387
[epoch6, step2506]: loss 6.102359
[epoch6, step2507]: loss 1.769712
[epoch6, step2508]: loss 1.970335
[epoch6, step2509]: loss 2.610384
[epoch6, step2510]: loss 2.378562
[epoch6, step2511]: loss 5.228351
[epoch6, step2512]: loss 17.976240
[epoch6, step2513]: loss 7.567868
[epoch6, step2514]: loss 2.335415
[epoch6, step2515]: loss 14.452666
[epoch6, step2516]: loss 1.927092
[epoch6, step2517]: loss 2.834228
[epoch6, step2518]: loss 7.169712
[epoch6, step2519]: loss 2.819173
[epoch6, step2520]: loss 5.387985
[epoch6, step2521]: loss 19.517040
[epoch6, step2522]: loss 7.167213
[epoch6, step2523]: loss 28.132679
[epoch6, step2524]: loss 13.798762
[epoch6, step2525]: loss 10.831524
[epoch6, step2526]: loss 7.945056
[epoch6, step2527]: loss 8.976341
[epoch6, step2528]: loss 3.412513
[epoch6, step2529]: loss 6.603735
[epoch6, step2530]: loss 8.525866
[epoch6, step2531]: loss 13.407308
[epoch6, step2532]: loss 1.888696
[epoch6, step2533]: loss 3.756234
[epoch6, step2534]: loss 6.625199
[epoch6, step2535]: loss 4.147861
[epoch6, step2536]: loss 14.580667
[epoch6, step2537]: loss 3.832614
[epoch6, step2538]: loss 3.374703
[epoch6, step2539]: loss 3.214321
[epoch6, step2540]: loss 7.928701
[epoch6, step2541]: loss 2.235639
[epoch6, step2542]: loss 4.799173
[epoch6, step2543]: loss 1.843922
[epoch6, step2544]: loss 12.336330
[epoch6, step2545]: loss 28.186319
[epoch6, step2546]: loss 12.175025
[epoch6, step2547]: loss 6.260401
[epoch6, step2548]: loss 25.701452
[epoch6, step2549]: loss 3.009500
[epoch6, step2550]: loss 4.314614
[epoch6, step2551]: loss 1.299878
[epoch6, step2552]: loss 2.577045
[epoch6, step2553]: loss 4.274537
[epoch6, step2554]: loss 3.629599
[epoch6, step2555]: loss 6.617015
[epoch6, step2556]: loss 7.399451
[epoch6, step2557]: loss 5.105008
[epoch6, step2558]: loss 1.757843
[epoch6, step2559]: loss 4.401358
[epoch6, step2560]: loss 7.282066
[epoch6, step2561]: loss 31.995003
[epoch6, step2562]: loss 1.854025
[epoch6, step2563]: loss 2.022980
[epoch6, step2564]: loss 2.890355
[epoch6, step2565]: loss 6.852146
[epoch6, step2566]: loss 1.606313
[epoch6, step2567]: loss 23.965244
[epoch6, step2568]: loss 2.763978
[epoch6, step2569]: loss 1.348469
[epoch6, step2570]: loss 18.924793
[epoch6, step2571]: loss 2.180270
[epoch6, step2572]: loss 22.839394
[epoch6, step2573]: loss 3.256668
[epoch6, step2574]: loss 3.127235
[epoch6, step2575]: loss 38.000248
[epoch6, step2576]: loss 2.980609
[epoch6, step2577]: loss 1.681340
[epoch6, step2578]: loss 1.172341
[epoch6, step2579]: loss 2.109672
[epoch6, step2580]: loss 3.349401
[epoch6, step2581]: loss 1.827603
[epoch6, step2582]: loss 24.739212
[epoch6, step2583]: loss 4.189105
[epoch6, step2584]: loss 5.538659
[epoch6, step2585]: loss 5.513393
[epoch6, step2586]: loss 20.998093
[epoch6, step2587]: loss 20.408796
[epoch6, step2588]: loss 2.863467
[epoch6, step2589]: loss 3.374731
[epoch6, step2590]: loss 2.943208
[epoch6, step2591]: loss 5.305993
[epoch6, step2592]: loss 4.377767
[epoch6, step2593]: loss 3.987678
[epoch6, step2594]: loss 4.782115
[epoch6, step2595]: loss 6.802884
[epoch6, step2596]: loss 4.293836
[epoch6, step2597]: loss 5.513985
[epoch6, step2598]: loss 3.407113
[epoch6, step2599]: loss 5.486388
[epoch6, step2600]: loss 19.865791
[epoch6, step2601]: loss 17.211761
[epoch6, step2602]: loss 2.873729
[epoch6, step2603]: loss 23.941179
[epoch6, step2604]: loss 28.030664
[epoch6, step2605]: loss 4.963290
[epoch6, step2606]: loss 5.639985
[epoch6, step2607]: loss 35.570736
[epoch6, step2608]: loss 9.280386
[epoch6, step2609]: loss 9.724010
[epoch6, step2610]: loss 34.604980
[epoch6, step2611]: loss 8.939780
[epoch6, step2612]: loss 1.457340
[epoch6, step2613]: loss 4.295670
[epoch6, step2614]: loss 1.724333
[epoch6, step2615]: loss 30.739494
[epoch6, step2616]: loss 33.123459
[epoch6, step2617]: loss 2.881410
[epoch6, step2618]: loss 21.073877
[epoch6, step2619]: loss 21.048027
[epoch6, step2620]: loss 3.558581
[epoch6, step2621]: loss 3.627409
[epoch6, step2622]: loss 27.396687
[epoch6, step2623]: loss 8.499175
[epoch6, step2624]: loss 6.495413
[epoch6, step2625]: loss 3.527062
[epoch6, step2626]: loss 2.913188
[epoch6, step2627]: loss 1.457379
[epoch6, step2628]: loss 3.744173
[epoch6, step2629]: loss 4.847083
[epoch6, step2630]: loss 4.017926
[epoch6, step2631]: loss 1.815525
[epoch6, step2632]: loss 2.845452
[epoch6, step2633]: loss 1.915404
[epoch6, step2634]: loss 10.493315
[epoch6, step2635]: loss 3.248905
[epoch6, step2636]: loss 18.353333
[epoch6, step2637]: loss 5.811345
[epoch6, step2638]: loss 20.061785
[epoch6, step2639]: loss 5.829628
[epoch6, step2640]: loss 3.532138
[epoch6, step2641]: loss 18.401913
[epoch6, step2642]: loss 2.772793
[epoch6, step2643]: loss 20.321661
[epoch6, step2644]: loss 4.421887
[epoch6, step2645]: loss 4.411821
[epoch6, step2646]: loss 4.525737
[epoch6, step2647]: loss 1.934711
[epoch6, step2648]: loss 6.062675
[epoch6, step2649]: loss 4.742060
[epoch6, step2650]: loss 3.404604
[epoch6, step2651]: loss 2.171681
[epoch6, step2652]: loss 21.507114
[epoch6, step2653]: loss 17.131821
[epoch6, step2654]: loss 4.346901
[epoch6, step2655]: loss 1.518542
[epoch6, step2656]: loss 4.847835
[epoch6, step2657]: loss 6.552905
[epoch6, step2658]: loss 33.336044
[epoch6, step2659]: loss 2.762201
[epoch6, step2660]: loss 3.128967
[epoch6, step2661]: loss 7.230821
[epoch6, step2662]: loss 18.247709
[epoch6, step2663]: loss 9.980869
[epoch6, step2664]: loss 44.992165
[epoch6, step2665]: loss 2.283682
[epoch6, step2666]: loss 3.778509
[epoch6, step2667]: loss 2.689108
[epoch6, step2668]: loss 3.887495
[epoch6, step2669]: loss 3.050014
[epoch6, step2670]: loss 7.116138
[epoch6, step2671]: loss 4.514594
[epoch6, step2672]: loss 2.738886
[epoch6, step2673]: loss 7.373271
[epoch6, step2674]: loss 4.196864
[epoch6, step2675]: loss 18.915134
[epoch6, step2676]: loss 9.031502
[epoch6, step2677]: loss 5.154139
[epoch6, step2678]: loss 18.069492
[epoch6, step2679]: loss 2.201797
[epoch6, step2680]: loss 2.002591
[epoch6, step2681]: loss 8.113385
[epoch6, step2682]: loss 2.673851
[epoch6, step2683]: loss 3.577179
[epoch6, step2684]: loss 2.233407
[epoch6, step2685]: loss 1.463061
[epoch6, step2686]: loss 3.791827
[epoch6, step2687]: loss 2.244151
[epoch6, step2688]: loss 1.901772
[epoch6, step2689]: loss 0.902905
[epoch6, step2690]: loss 5.195344
[epoch6, step2691]: loss 1.546814
[epoch6, step2692]: loss 18.328611
[epoch6, step2693]: loss 2.878070
[epoch6, step2694]: loss 1.495506
[epoch6, step2695]: loss 24.941195
[epoch6, step2696]: loss 1.552184
[epoch6, step2697]: loss 21.563072
[epoch6, step2698]: loss 3.350604
[epoch6, step2699]: loss 1.873420
[epoch6, step2700]: loss 7.231605
[epoch6, step2701]: loss 6.024708
[epoch6, step2702]: loss 12.698442
[epoch6, step2703]: loss 2.891575
[epoch6, step2704]: loss 4.097718
[epoch6, step2705]: loss 4.568372
[epoch6, step2706]: loss 2.880100
[epoch6, step2707]: loss 2.591254
[epoch6, step2708]: loss 8.196680
[epoch6, step2709]: loss 2.144611
[epoch6, step2710]: loss 1.909624
[epoch6, step2711]: loss 3.230828
[epoch6, step2712]: loss 16.682604
[epoch6, step2713]: loss 25.644478
[epoch6, step2714]: loss 3.233330
[epoch6, step2715]: loss 4.357571
[epoch6, step2716]: loss 2.104496
[epoch6, step2717]: loss 12.570502
[epoch6, step2718]: loss 3.446560
[epoch6, step2719]: loss 4.915806
[epoch6, step2720]: loss 10.293406
[epoch6, step2721]: loss 4.477438
[epoch6, step2722]: loss 4.585084
[epoch6, step2723]: loss 6.089449
[epoch6, step2724]: loss 2.248321
[epoch6, step2725]: loss 3.124647
[epoch6, step2726]: loss 2.623358
[epoch6, step2727]: loss 4.023661
[epoch6, step2728]: loss 2.213849
[epoch6, step2729]: loss 1.192648
[epoch6, step2730]: loss 7.925056
[epoch6, step2731]: loss 3.682735
[epoch6, step2732]: loss 8.606586
[epoch6, step2733]: loss 5.084373
[epoch6, step2734]: loss 2.616504
[epoch6, step2735]: loss 5.511086
[epoch6, step2736]: loss 3.963158
[epoch6, step2737]: loss 2.709192
[epoch6, step2738]: loss 14.643805
[epoch6, step2739]: loss 18.921078
[epoch6, step2740]: loss 1.404899
[epoch6, step2741]: loss 1.941163
[epoch6, step2742]: loss 3.400058
[epoch6, step2743]: loss 35.748173
[epoch6, step2744]: loss 2.006799
[epoch6, step2745]: loss 1.612979
[epoch6, step2746]: loss 3.264821
[epoch6, step2747]: loss 24.361567
[epoch6, step2748]: loss 21.329998
[epoch6, step2749]: loss 19.573709
[epoch6, step2750]: loss 2.342476
[epoch6, step2751]: loss 22.905800
[epoch6, step2752]: loss 13.276617
[epoch6, step2753]: loss 1.583192
[epoch6, step2754]: loss 21.338690
[epoch6, step2755]: loss 5.082987
[epoch6, step2756]: loss 1.994615
[epoch6, step2757]: loss 23.546112
[epoch6, step2758]: loss 1.449151
[epoch6, step2759]: loss 3.494413
[epoch6, step2760]: loss 8.191668
[epoch6, step2761]: loss 4.712977
[epoch6, step2762]: loss 8.761237
[epoch6, step2763]: loss 6.796268
[epoch6, step2764]: loss 2.374151
[epoch6, step2765]: loss 1.522921
[epoch6, step2766]: loss 2.846966
[epoch6, step2767]: loss 26.797468
[epoch6, step2768]: loss 18.276102
[epoch6, step2769]: loss 18.007223
[epoch6, step2770]: loss 19.742332
[epoch6, step2771]: loss 2.489811
[epoch6, step2772]: loss 1.677871
[epoch6, step2773]: loss 1.958527
[epoch6, step2774]: loss 30.040768
[epoch6, step2775]: loss 4.565094
[epoch6, step2776]: loss 4.935676
[epoch6, step2777]: loss 1.878301
[epoch6, step2778]: loss 6.991980
[epoch6, step2779]: loss 6.526607
[epoch6, step2780]: loss 1.924135
[epoch6, step2781]: loss 6.197567
[epoch6, step2782]: loss 7.229420
[epoch6, step2783]: loss 6.505622
[epoch6, step2784]: loss 15.717000
[epoch6, step2785]: loss 1.863571
[epoch6, step2786]: loss 34.419014
[epoch6, step2787]: loss 20.034651
[epoch6, step2788]: loss 2.046200
[epoch6, step2789]: loss 37.176933
[epoch6, step2790]: loss 1.855329
[epoch6, step2791]: loss 1.387314
[epoch6, step2792]: loss 2.941104
[epoch6, step2793]: loss 10.826569
[epoch6, step2794]: loss 18.618959
[epoch6, step2795]: loss 3.587837
[epoch6, step2796]: loss 3.599479
[epoch6, step2797]: loss 2.479842
[epoch6, step2798]: loss 4.016367
[epoch6, step2799]: loss 2.612388
[epoch6, step2800]: loss 2.571675
[epoch6, step2801]: loss 29.771854
[epoch6, step2802]: loss 16.486254
[epoch6, step2803]: loss 26.087524
[epoch6, step2804]: loss 2.729943
[epoch6, step2805]: loss 2.125685
[epoch6, step2806]: loss 2.456496
[epoch6, step2807]: loss 1.372507
[epoch6, step2808]: loss 24.214361
[epoch6, step2809]: loss 37.405209
[epoch6, step2810]: loss 9.256577
[epoch6, step2811]: loss 2.506373
[epoch6, step2812]: loss 3.449516
[epoch6, step2813]: loss 18.554270
[epoch6, step2814]: loss 1.716175
[epoch6, step2815]: loss 3.267462
[epoch6, step2816]: loss 15.509871
[epoch6, step2817]: loss 6.262284
[epoch6, step2818]: loss 2.012712
[epoch6, step2819]: loss 3.058061
[epoch6, step2820]: loss 15.776643
[epoch6, step2821]: loss 16.101828
[epoch6, step2822]: loss 15.398881
[epoch6, step2823]: loss 19.730644
[epoch6, step2824]: loss 1.837012
[epoch6, step2825]: loss 19.727211
[epoch6, step2826]: loss 6.626262
[epoch6, step2827]: loss 3.433441
[epoch6, step2828]: loss 1.281691
[epoch6, step2829]: loss 36.265697
[epoch6, step2830]: loss 1.588938
[epoch6, step2831]: loss 1.692737
[epoch6, step2832]: loss 4.286869
[epoch6, step2833]: loss 4.116170
[epoch6, step2834]: loss 3.780299
[epoch6, step2835]: loss 25.463326
[epoch6, step2836]: loss 22.414124
[epoch6, step2837]: loss 2.101687
[epoch6, step2838]: loss 3.254790
[epoch6, step2839]: loss 3.681288
[epoch6, step2840]: loss 4.712379
[epoch6, step2841]: loss 3.508384
[epoch6, step2842]: loss 7.204671
[epoch6, step2843]: loss 1.722366
[epoch6, step2844]: loss 20.024687
[epoch6, step2845]: loss 3.864806
[epoch6, step2846]: loss 6.914262
[epoch6, step2847]: loss 17.228325
[epoch6, step2848]: loss 3.336694
[epoch6, step2849]: loss 21.151695
[epoch6, step2850]: loss 17.600714
[epoch6, step2851]: loss 19.090584
[epoch6, step2852]: loss 2.976678
[epoch6, step2853]: loss 15.727966
[epoch6, step2854]: loss 2.691192
[epoch6, step2855]: loss 31.660151
[epoch6, step2856]: loss 18.217871
[epoch6, step2857]: loss 2.968672
[epoch6, step2858]: loss 1.783978
[epoch6, step2859]: loss 3.007193
[epoch6, step2860]: loss 15.124988
[epoch6, step2861]: loss 10.537896
[epoch6, step2862]: loss 18.905926
[epoch6, step2863]: loss 33.466125
[epoch6, step2864]: loss 3.791713
[epoch6, step2865]: loss 38.985607
[epoch6, step2866]: loss 1.652593
[epoch6, step2867]: loss 40.747883
[epoch6, step2868]: loss 6.658376
[epoch6, step2869]: loss 2.214976
[epoch6, step2870]: loss 6.301125
[epoch6, step2871]: loss 1.502233
[epoch6, step2872]: loss 3.189588
[epoch6, step2873]: loss 1.365246
[epoch6, step2874]: loss 2.762423
[epoch6, step2875]: loss 3.684713
[epoch6, step2876]: loss 26.856295
[epoch6, step2877]: loss 3.491644
[epoch6, step2878]: loss 3.669422
[epoch6, step2879]: loss 8.304229
[epoch6, step2880]: loss 7.117265
[epoch6, step2881]: loss 4.201006
[epoch6, step2882]: loss 11.965401
[epoch6, step2883]: loss 6.620412
[epoch6, step2884]: loss 19.057257
[epoch6, step2885]: loss 24.421577
[epoch6, step2886]: loss 5.905328
[epoch6, step2887]: loss 19.297068
[epoch6, step2888]: loss 4.084879
[epoch6, step2889]: loss 3.429420
[epoch6, step2890]: loss 2.319072
[epoch6, step2891]: loss 42.059566
[epoch6, step2892]: loss 5.826407
[epoch6, step2893]: loss 8.989361
[epoch6, step2894]: loss 22.302729
[epoch6, step2895]: loss 37.485695
[epoch6, step2896]: loss 3.556599
[epoch6, step2897]: loss 22.031878
[epoch6, step2898]: loss 5.085330
[epoch6, step2899]: loss 2.448549
[epoch6, step2900]: loss 5.680073
[epoch6, step2901]: loss 3.348607
[epoch6, step2902]: loss 6.327575
[epoch6, step2903]: loss 1.943577
[epoch6, step2904]: loss 6.487422
[epoch6, step2905]: loss 3.106653
[epoch6, step2906]: loss 18.682940
[epoch6, step2907]: loss 2.282514
[epoch6, step2908]: loss 2.179636
[epoch6, step2909]: loss 2.646410
[epoch6, step2910]: loss 18.176695
[epoch6, step2911]: loss 4.116881
[epoch6, step2912]: loss 2.186444
[epoch6, step2913]: loss 2.562562
[epoch6, step2914]: loss 7.473938
[epoch6, step2915]: loss 28.645845
[epoch6, step2916]: loss 2.248386
[epoch6, step2917]: loss 1.437467
[epoch6, step2918]: loss 1.663928
[epoch6, step2919]: loss 6.543337
[epoch6, step2920]: loss 3.660364
[epoch6, step2921]: loss 4.031301
[epoch6, step2922]: loss 1.538244
[epoch6, step2923]: loss 6.350139
[epoch6, step2924]: loss 2.166588
[epoch6, step2925]: loss 30.195501
[epoch6, step2926]: loss 3.292882
[epoch6, step2927]: loss 39.613564
[epoch6, step2928]: loss 2.251005
[epoch6, step2929]: loss 8.123616
[epoch6, step2930]: loss 11.310135
[epoch6, step2931]: loss 3.975188
[epoch6, step2932]: loss 5.359932
[epoch6, step2933]: loss 21.425072
[epoch6, step2934]: loss 2.233650
[epoch6, step2935]: loss 19.817312
[epoch6, step2936]: loss 9.745519
[epoch6, step2937]: loss 1.335385
[epoch6, step2938]: loss 2.801419
[epoch6, step2939]: loss 4.266191
[epoch6, step2940]: loss 2.903653
[epoch6, step2941]: loss 4.120794
[epoch6, step2942]: loss 5.152278
[epoch6, step2943]: loss 8.876061
[epoch6, step2944]: loss 1.918027
[epoch6, step2945]: loss 2.359318
[epoch6, step2946]: loss 4.314404
[epoch6, step2947]: loss 19.752512
[epoch6, step2948]: loss 1.806291
[epoch6, step2949]: loss 1.355996
[epoch6, step2950]: loss 1.051349
[epoch6, step2951]: loss 7.090537
[epoch6, step2952]: loss 2.503960
[epoch6, step2953]: loss 2.325560
[epoch6, step2954]: loss 17.219925
[epoch6, step2955]: loss 2.738054
[epoch6, step2956]: loss 3.567091
[epoch6, step2957]: loss 6.799228
[epoch6, step2958]: loss 19.048391
[epoch6, step2959]: loss 1.232487
[epoch6, step2960]: loss 7.172776
[epoch6, step2961]: loss 5.923433
[epoch6, step2962]: loss 3.079595
[epoch6, step2963]: loss 6.835626
[epoch6, step2964]: loss 2.054677
[epoch6, step2965]: loss 3.800921
[epoch6, step2966]: loss 7.807832
[epoch6, step2967]: loss 1.332530
[epoch6, step2968]: loss 40.473419
[epoch6, step2969]: loss 4.595933
[epoch6, step2970]: loss 17.572647
[epoch6, step2971]: loss 4.401237
[epoch6, step2972]: loss 7.993130
[epoch6, step2973]: loss 1.730106
[epoch6, step2974]: loss 17.895248
[epoch6, step2975]: loss 1.691423
[epoch6, step2976]: loss 2.917798
[epoch6, step2977]: loss 7.329604
[epoch6, step2978]: loss 10.147600
[epoch6, step2979]: loss 3.826643
[epoch6, step2980]: loss 1.679274
[epoch6, step2981]: loss 2.381216
[epoch6, step2982]: loss 3.153625
[epoch6, step2983]: loss 20.919285
[epoch6, step2984]: loss 1.796951
[epoch6, step2985]: loss 3.266493
[epoch6, step2986]: loss 4.931875
[epoch6, step2987]: loss 3.505561
[epoch6, step2988]: loss 19.350321
[epoch6, step2989]: loss 2.446116
[epoch6, step2990]: loss 16.404175
[epoch6, step2991]: loss 6.140367
[epoch6, step2992]: loss 3.233642
[epoch6, step2993]: loss 10.798306
[epoch6, step2994]: loss 7.426438
[epoch6, step2995]: loss 6.561667
[epoch6, step2996]: loss 1.187956
[epoch6, step2997]: loss 4.141593
[epoch6, step2998]: loss 2.057241
[epoch6, step2999]: loss 2.833605
[epoch6, step3000]: loss 2.420822
[epoch6, step3001]: loss 29.959650
[epoch6, step3002]: loss 9.043230
[epoch6, step3003]: loss 6.217492
[epoch6, step3004]: loss 2.754302
[epoch6, step3005]: loss 1.734085
[epoch6, step3006]: loss 2.032138
[epoch6, step3007]: loss 15.936060
[epoch6, step3008]: loss 12.076349
[epoch6, step3009]: loss 15.862832
[epoch6, step3010]: loss 21.617268
[epoch6, step3011]: loss 3.141327
[epoch6, step3012]: loss 1.913520
[epoch6, step3013]: loss 2.861421
[epoch6, step3014]: loss 23.140392
[epoch6, step3015]: loss 1.532899
[epoch6, step3016]: loss 2.189115
[epoch6, step3017]: loss 1.709722
[epoch6, step3018]: loss 9.373100
[epoch6, step3019]: loss 2.569462
[epoch6, step3020]: loss 3.174198
[epoch6, step3021]: loss 1.287993
[epoch6, step3022]: loss 2.742555
[epoch6, step3023]: loss 21.720795
[epoch6, step3024]: loss 2.010198
[epoch6, step3025]: loss 19.012369
[epoch6, step3026]: loss 3.241880
[epoch6, step3027]: loss 41.791801
[epoch6, step3028]: loss 3.960980
[epoch6, step3029]: loss 3.102943
[epoch6, step3030]: loss 1.969284
[epoch6, step3031]: loss 8.090394
[epoch6, step3032]: loss 26.025455
[epoch6, step3033]: loss 14.081354
[epoch6, step3034]: loss 2.953143
[epoch6, step3035]: loss 10.176448
[epoch6, step3036]: loss 3.109717
[epoch6, step3037]: loss 26.024157
[epoch6, step3038]: loss 1.685951
[epoch6, step3039]: loss 3.306237
[epoch6, step3040]: loss 19.688501
[epoch6, step3041]: loss 10.827300
[epoch6, step3042]: loss 9.593246
[epoch6, step3043]: loss 3.541425
[epoch6, step3044]: loss 7.416989
[epoch6, step3045]: loss 21.741629
[epoch6, step3046]: loss 2.994427
[epoch6, step3047]: loss 15.484204
[epoch6, step3048]: loss 3.343868
[epoch6, step3049]: loss 7.011675
[epoch6, step3050]: loss 1.178284
[epoch6, step3051]: loss 4.425854
[epoch6, step3052]: loss 1.672297
[epoch6, step3053]: loss 1.803119
[epoch6, step3054]: loss 15.040778
[epoch6, step3055]: loss 14.900394
[epoch6, step3056]: loss 7.966656
[epoch6, step3057]: loss 8.591148
[epoch6, step3058]: loss 24.457533
[epoch6, step3059]: loss 7.466622
[epoch6, step3060]: loss 3.743639
[epoch6, step3061]: loss 1.832284
[epoch6, step3062]: loss 3.442566
[epoch6, step3063]: loss 1.605281
[epoch6, step3064]: loss 6.785138
[epoch6, step3065]: loss 1.555496
[epoch6, step3066]: loss 23.106375
[epoch6, step3067]: loss 4.555599
[epoch6, step3068]: loss 2.864511
[epoch6, step3069]: loss 1.342163
[epoch6, step3070]: loss 22.940811
[epoch6, step3071]: loss 6.963508
[epoch6, step3072]: loss 32.188896
[epoch6, step3073]: loss 3.455251
[epoch6, step3074]: loss 1.722638
[epoch6, step3075]: loss 20.376087
[epoch6, step3076]: loss 1.843708

[epoch6]: avg loss 1.843708

[epoch7, step1]: loss 4.049652
[epoch7, step2]: loss 3.549626
[epoch7, step3]: loss 16.373144
[epoch7, step4]: loss 1.480155
[epoch7, step5]: loss 4.353700
[epoch7, step6]: loss 5.967570
[epoch7, step7]: loss 2.923381
[epoch7, step8]: loss 35.509537
[epoch7, step9]: loss 1.804310
[epoch7, step10]: loss 3.360860
[epoch7, step11]: loss 2.232560
[epoch7, step12]: loss 2.527805
[epoch7, step13]: loss 1.999074
[epoch7, step14]: loss 2.262493
[epoch7, step15]: loss 4.840622
[epoch7, step16]: loss 2.210890
[epoch7, step17]: loss 16.509027
[epoch7, step18]: loss 4.263719
[epoch7, step19]: loss 6.363398
[epoch7, step20]: loss 1.252992
[epoch7, step21]: loss 15.800076
[epoch7, step22]: loss 4.361474
[epoch7, step23]: loss 7.550413
[epoch7, step24]: loss 42.551613
[epoch7, step25]: loss 2.487882
[epoch7, step26]: loss 1.991213
[epoch7, step27]: loss 2.561595
[epoch7, step28]: loss 17.272434
[epoch7, step29]: loss 4.780660
[epoch7, step30]: loss 5.296009
[epoch7, step31]: loss 2.331177
[epoch7, step32]: loss 18.156946
[epoch7, step33]: loss 1.082345
[epoch7, step34]: loss 2.697247
[epoch7, step35]: loss 5.176815
[epoch7, step36]: loss 2.900571
[epoch7, step37]: loss 12.162493
[epoch7, step38]: loss 1.553675
[epoch7, step39]: loss 5.288180
[epoch7, step40]: loss 4.970262
[epoch7, step41]: loss 19.169344
[epoch7, step42]: loss 4.528901
[epoch7, step43]: loss 2.769115
[epoch7, step44]: loss 5.228795
[epoch7, step45]: loss 6.441330
[epoch7, step46]: loss 4.912998
[epoch7, step47]: loss 2.790574
[epoch7, step48]: loss 2.297867
[epoch7, step49]: loss 11.426295
[epoch7, step50]: loss 5.825550
[epoch7, step51]: loss 30.300694
[epoch7, step52]: loss 7.708810
[epoch7, step53]: loss 2.058969
[epoch7, step54]: loss 2.392430
[epoch7, step55]: loss 18.510704
[epoch7, step56]: loss 1.875700
[epoch7, step57]: loss 30.102324
[epoch7, step58]: loss 21.493990
[epoch7, step59]: loss 1.937957
[epoch7, step60]: loss 6.495567
[epoch7, step61]: loss 11.882543
[epoch7, step62]: loss 18.269432
[epoch7, step63]: loss 2.193635
[epoch7, step64]: loss 41.157631
[epoch7, step65]: loss 8.713023
[epoch7, step66]: loss 3.198715
[epoch7, step67]: loss 3.084879
[epoch7, step68]: loss 6.059274
[epoch7, step69]: loss 1.765099
[epoch7, step70]: loss 3.208239
[epoch7, step71]: loss 11.503255
[epoch7, step72]: loss 3.104831
[epoch7, step73]: loss 2.167006
[epoch7, step74]: loss 1.093744
[epoch7, step75]: loss 20.615726
[epoch7, step76]: loss 7.309718
[epoch7, step77]: loss 2.843949
[epoch7, step78]: loss 33.569439
[epoch7, step79]: loss 2.584721
[epoch7, step80]: loss 6.338819
[epoch7, step81]: loss 3.936489
[epoch7, step82]: loss 2.735644
[epoch7, step83]: loss 1.767681
[epoch7, step84]: loss 9.683119
[epoch7, step85]: loss 2.682108
[epoch7, step86]: loss 4.093152
[epoch7, step87]: loss 21.278543
[epoch7, step88]: loss 7.302322
[epoch7, step89]: loss 2.775403
[epoch7, step90]: loss 4.839798
[epoch7, step91]: loss 8.914721
[epoch7, step92]: loss 5.301782
[epoch7, step93]: loss 1.823109
[epoch7, step94]: loss 13.363909
[epoch7, step95]: loss 1.510800
[epoch7, step96]: loss 5.862933
[epoch7, step97]: loss 3.065768
[epoch7, step98]: loss 6.395634
[epoch7, step99]: loss 18.103760
[epoch7, step100]: loss 1.311989
[epoch7, step101]: loss 17.792568
[epoch7, step102]: loss 5.054647
[epoch7, step103]: loss 5.048456
[epoch7, step104]: loss 2.588978
[epoch7, step105]: loss 21.539206
[epoch7, step106]: loss 3.441814
[epoch7, step107]: loss 18.383150
[epoch7, step108]: loss 9.938907
[epoch7, step109]: loss 2.055507
[epoch7, step110]: loss 26.662544
[epoch7, step111]: loss 2.416784
[epoch7, step112]: loss 6.760547
[epoch7, step113]: loss 1.777853
[epoch7, step114]: loss 5.458817
[epoch7, step115]: loss 16.827581
[epoch7, step116]: loss 23.577591
[epoch7, step117]: loss 28.143250
[epoch7, step118]: loss 4.667624
[epoch7, step119]: loss 1.734871
[epoch7, step120]: loss 1.372565
[epoch7, step121]: loss 2.726324
[epoch7, step122]: loss 5.291416
[epoch7, step123]: loss 1.601497
[epoch7, step124]: loss 35.411816
[epoch7, step125]: loss 4.944032
[epoch7, step126]: loss 26.958103
[epoch7, step127]: loss 1.647732
[epoch7, step128]: loss 36.582935
[epoch7, step129]: loss 10.386124
[epoch7, step130]: loss 5.844771
[epoch7, step131]: loss 4.078202
[epoch7, step132]: loss 2.117172
[epoch7, step133]: loss 1.333888
[epoch7, step134]: loss 3.889334
[epoch7, step135]: loss 3.501363
[epoch7, step136]: loss 1.518197
[epoch7, step137]: loss 27.717279
[epoch7, step138]: loss 1.278064
[epoch7, step139]: loss 1.941746
[epoch7, step140]: loss 2.425332
[epoch7, step141]: loss 11.424367
[epoch7, step142]: loss 2.915010
[epoch7, step143]: loss 15.074682
[epoch7, step144]: loss 2.159980
[epoch7, step145]: loss 2.843561
[epoch7, step146]: loss 7.030484
[epoch7, step147]: loss 3.592817
[epoch7, step148]: loss 20.233210
[epoch7, step149]: loss 7.822317
[epoch7, step150]: loss 3.714012
[epoch7, step151]: loss 21.877993
[epoch7, step152]: loss 1.955758
[epoch7, step153]: loss 8.294725
[epoch7, step154]: loss 5.819098
[epoch7, step155]: loss 4.144472
[epoch7, step156]: loss 3.524039
[epoch7, step157]: loss 4.686978
[epoch7, step158]: loss 16.027843
[epoch7, step159]: loss 4.160306
[epoch7, step160]: loss 6.377543
[epoch7, step161]: loss 2.772387
[epoch7, step162]: loss 2.533795
[epoch7, step163]: loss 4.349663
[epoch7, step164]: loss 2.445130
[epoch7, step165]: loss 2.135026
[epoch7, step166]: loss 23.105909
[epoch7, step167]: loss 2.938905
[epoch7, step168]: loss 19.774206
[epoch7, step169]: loss 2.698839
[epoch7, step170]: loss 2.965683
[epoch7, step171]: loss 3.493307
[epoch7, step172]: loss 2.896693
[epoch7, step173]: loss 18.751913
[epoch7, step174]: loss 23.797077
[epoch7, step175]: loss 30.384933
[epoch7, step176]: loss 3.592339
[epoch7, step177]: loss 5.593726
[epoch7, step178]: loss 3.467604
[epoch7, step179]: loss 3.663002
[epoch7, step180]: loss 2.867270
[epoch7, step181]: loss 3.487535
[epoch7, step182]: loss 23.491419
[epoch7, step183]: loss 20.135117
[epoch7, step184]: loss 5.582147
[epoch7, step185]: loss 1.207232
[epoch7, step186]: loss 18.682476
[epoch7, step187]: loss 6.885709
[epoch7, step188]: loss 23.712940
[epoch7, step189]: loss 29.600956
[epoch7, step190]: loss 2.823653
[epoch7, step191]: loss 15.805599
[epoch7, step192]: loss 6.692389
[epoch7, step193]: loss 15.267582
[epoch7, step194]: loss 2.615390
[epoch7, step195]: loss 25.415211
[epoch7, step196]: loss 17.588858
[epoch7, step197]: loss 3.891447
[epoch7, step198]: loss 8.128643
[epoch7, step199]: loss 7.340840
[epoch7, step200]: loss 19.198463
[epoch7, step201]: loss 4.448436
[epoch7, step202]: loss 4.126605
[epoch7, step203]: loss 7.316349
[epoch7, step204]: loss 16.762299
[epoch7, step205]: loss 7.219794
[epoch7, step206]: loss 4.589946
[epoch7, step207]: loss 19.626579
[epoch7, step208]: loss 2.926844
[epoch7, step209]: loss 12.799999
[epoch7, step210]: loss 3.804274
[epoch7, step211]: loss 6.346247
[epoch7, step212]: loss 7.141933
[epoch7, step213]: loss 1.677588
[epoch7, step214]: loss 24.878866
[epoch7, step215]: loss 24.264946
[epoch7, step216]: loss 3.100767
[epoch7, step217]: loss 1.676361
[epoch7, step218]: loss 12.666745
[epoch7, step219]: loss 1.115039
[epoch7, step220]: loss 20.347542
[epoch7, step221]: loss 18.101212
[epoch7, step222]: loss 7.403606
[epoch7, step223]: loss 27.430119
[epoch7, step224]: loss 2.908998
[epoch7, step225]: loss 1.602188
[epoch7, step226]: loss 22.323822
[epoch7, step227]: loss 4.700358
[epoch7, step228]: loss 22.503736
[epoch7, step229]: loss 3.275078
[epoch7, step230]: loss 7.919150
[epoch7, step231]: loss 1.701831
[epoch7, step232]: loss 3.204790
[epoch7, step233]: loss 2.480841
[epoch7, step234]: loss 1.751736
[epoch7, step235]: loss 35.086109
[epoch7, step236]: loss 5.046755
[epoch7, step237]: loss 15.594041
[epoch7, step238]: loss 5.299228
[epoch7, step239]: loss 17.767464
[epoch7, step240]: loss 6.826975
[epoch7, step241]: loss 2.184821
[epoch7, step242]: loss 3.240055
[epoch7, step243]: loss 2.915132
[epoch7, step244]: loss 2.588656
[epoch7, step245]: loss 4.427104
[epoch7, step246]: loss 10.016914
[epoch7, step247]: loss 1.932794
[epoch7, step248]: loss 5.738405
[epoch7, step249]: loss 2.770551
[epoch7, step250]: loss 4.250966
[epoch7, step251]: loss 13.861914
[epoch7, step252]: loss 3.257928
[epoch7, step253]: loss 4.159543
[epoch7, step254]: loss 1.355570
[epoch7, step255]: loss 5.449637
[epoch7, step256]: loss 2.564505
[epoch7, step257]: loss 1.832316
[epoch7, step258]: loss 24.519424
[epoch7, step259]: loss 2.131843
[epoch7, step260]: loss 20.732529
[epoch7, step261]: loss 18.916943
[epoch7, step262]: loss 2.848700
[epoch7, step263]: loss 2.300593
[epoch7, step264]: loss 4.778251
[epoch7, step265]: loss 20.353628
[epoch7, step266]: loss 6.339494
[epoch7, step267]: loss 3.594983
[epoch7, step268]: loss 10.063517
[epoch7, step269]: loss 8.625533
[epoch7, step270]: loss 18.062519
[epoch7, step271]: loss 4.358437
[epoch7, step272]: loss 4.657219
[epoch7, step273]: loss 2.557864
[epoch7, step274]: loss 25.615122
[epoch7, step275]: loss 9.417688
[epoch7, step276]: loss 20.404039
[epoch7, step277]: loss 4.955811
[epoch7, step278]: loss 16.619854
[epoch7, step279]: loss 2.413404
[epoch7, step280]: loss 6.734337
[epoch7, step281]: loss 4.499035
[epoch7, step282]: loss 1.389940
[epoch7, step283]: loss 7.753716
[epoch7, step284]: loss 4.327307
[epoch7, step285]: loss 1.468895
[epoch7, step286]: loss 2.470810
[epoch7, step287]: loss 19.444002
[epoch7, step288]: loss 5.984978
[epoch7, step289]: loss 40.297585
[epoch7, step290]: loss 3.574966
[epoch7, step291]: loss 18.597336
[epoch7, step292]: loss 2.044930
[epoch7, step293]: loss 4.038439
[epoch7, step294]: loss 7.303903
[epoch7, step295]: loss 20.653719
[epoch7, step296]: loss 11.490618
[epoch7, step297]: loss 8.014696
[epoch7, step298]: loss 20.907249
[epoch7, step299]: loss 3.381252
[epoch7, step300]: loss 2.513404
[epoch7, step301]: loss 33.830647
[epoch7, step302]: loss 2.968849
[epoch7, step303]: loss 3.493020
[epoch7, step304]: loss 4.204073
[epoch7, step305]: loss 1.931792
[epoch7, step306]: loss 9.588758
[epoch7, step307]: loss 6.189589
[epoch7, step308]: loss 5.548806
[epoch7, step309]: loss 2.432249
[epoch7, step310]: loss 16.784561
[epoch7, step311]: loss 18.588163
[epoch7, step312]: loss 9.185322
[epoch7, step313]: loss 1.820164
[epoch7, step314]: loss 4.635969
[epoch7, step315]: loss 2.798937
[epoch7, step316]: loss 3.679204
[epoch7, step317]: loss 8.481160
[epoch7, step318]: loss 4.234583
[epoch7, step319]: loss 1.681823
[epoch7, step320]: loss 3.392950
[epoch7, step321]: loss 2.903482
[epoch7, step322]: loss 17.869843
[epoch7, step323]: loss 5.210880
[epoch7, step324]: loss 3.439492
[epoch7, step325]: loss 12.205353
[epoch7, step326]: loss 5.378782
[epoch7, step327]: loss 10.983634
[epoch7, step328]: loss 1.738454
[epoch7, step329]: loss 6.860262
[epoch7, step330]: loss 3.042316
[epoch7, step331]: loss 5.101376
[epoch7, step332]: loss 2.017489
[epoch7, step333]: loss 2.803571
[epoch7, step334]: loss 1.100853
[epoch7, step335]: loss 2.338620
[epoch7, step336]: loss 25.319973
[epoch7, step337]: loss 2.391758
[epoch7, step338]: loss 5.184306
[epoch7, step339]: loss 1.744299
[epoch7, step340]: loss 17.012280
[epoch7, step341]: loss 2.241098
[epoch7, step342]: loss 5.976638
[epoch7, step343]: loss 6.820551
[epoch7, step344]: loss 7.331963
[epoch7, step345]: loss 29.744938
[epoch7, step346]: loss 18.222841
[epoch7, step347]: loss 18.865259
[epoch7, step348]: loss 2.027435
[epoch7, step349]: loss 2.334527
[epoch7, step350]: loss 2.334314
[epoch7, step351]: loss 16.851646
[epoch7, step352]: loss 2.664896
[epoch7, step353]: loss 2.699005
[epoch7, step354]: loss 1.333642
[epoch7, step355]: loss 6.044264
[epoch7, step356]: loss 3.740059
[epoch7, step357]: loss 5.176940
[epoch7, step358]: loss 9.711466
[epoch7, step359]: loss 6.044435
[epoch7, step360]: loss 3.234803
[epoch7, step361]: loss 13.926394
[epoch7, step362]: loss 4.246834
[epoch7, step363]: loss 6.855123
[epoch7, step364]: loss 3.982342
[epoch7, step365]: loss 21.158422
[epoch7, step366]: loss 2.234468
[epoch7, step367]: loss 3.498937
[epoch7, step368]: loss 2.410678
[epoch7, step369]: loss 3.313293
[epoch7, step370]: loss 6.850260
[epoch7, step371]: loss 2.084562
[epoch7, step372]: loss 1.662151
[epoch7, step373]: loss 2.372430
[epoch7, step374]: loss 3.753362
[epoch7, step375]: loss 1.794154
[epoch7, step376]: loss 5.143802
[epoch7, step377]: loss 7.358000
[epoch7, step378]: loss 1.101669
[epoch7, step379]: loss 21.542295
[epoch7, step380]: loss 3.030703
[epoch7, step381]: loss 3.516296
[epoch7, step382]: loss 6.777175
[epoch7, step383]: loss 2.204283
[epoch7, step384]: loss 4.098231
[epoch7, step385]: loss 3.420033
[epoch7, step386]: loss 9.810472
[epoch7, step387]: loss 1.540236
[epoch7, step388]: loss 3.544017
[epoch7, step389]: loss 16.482277
[epoch7, step390]: loss 15.767613
[epoch7, step391]: loss 3.490973
[epoch7, step392]: loss 8.940435
[epoch7, step393]: loss 2.693842
[epoch7, step394]: loss 3.892292
[epoch7, step395]: loss 1.164465
[epoch7, step396]: loss 6.887113
[epoch7, step397]: loss 24.499144
[epoch7, step398]: loss 4.916242
[epoch7, step399]: loss 2.267141
[epoch7, step400]: loss 6.009288
[epoch7, step401]: loss 2.431847
[epoch7, step402]: loss 2.974692
[epoch7, step403]: loss 34.728577
[epoch7, step404]: loss 3.088335
[epoch7, step405]: loss 1.410372
[epoch7, step406]: loss 2.148842
[epoch7, step407]: loss 30.765408
[epoch7, step408]: loss 29.031315
[epoch7, step409]: loss 4.121860
[epoch7, step410]: loss 3.082567
[epoch7, step411]: loss 23.236332
[epoch7, step412]: loss 1.372771
[epoch7, step413]: loss 1.524529
[epoch7, step414]: loss 1.283615
[epoch7, step415]: loss 3.776102
[epoch7, step416]: loss 2.458986
[epoch7, step417]: loss 16.038157
[epoch7, step418]: loss 4.589542
[epoch7, step419]: loss 1.476713
[epoch7, step420]: loss 3.145602
[epoch7, step421]: loss 2.762001
[epoch7, step422]: loss 13.674010
[epoch7, step423]: loss 1.030640
[epoch7, step424]: loss 20.286976
[epoch7, step425]: loss 2.988963
[epoch7, step426]: loss 2.144552
[epoch7, step427]: loss 14.105103
[epoch7, step428]: loss 7.095973
[epoch7, step429]: loss 5.149665
[epoch7, step430]: loss 2.301255
[epoch7, step431]: loss 2.047197
[epoch7, step432]: loss 1.854242
[epoch7, step433]: loss 4.965070
[epoch7, step434]: loss 21.724249
[epoch7, step435]: loss 2.099001
[epoch7, step436]: loss 6.152053
[epoch7, step437]: loss 1.880132
[epoch7, step438]: loss 3.331019
[epoch7, step439]: loss 1.806839
[epoch7, step440]: loss 5.403390
[epoch7, step441]: loss 1.871133
[epoch7, step442]: loss 4.265020
[epoch7, step443]: loss 32.820045
[epoch7, step444]: loss 4.239101
[epoch7, step445]: loss 4.219017
[epoch7, step446]: loss 2.321530
[epoch7, step447]: loss 1.304583
[epoch7, step448]: loss 2.499790
[epoch7, step449]: loss 2.682719
[epoch7, step450]: loss 1.496668
[epoch7, step451]: loss 5.256938
[epoch7, step452]: loss 20.459938
[epoch7, step453]: loss 3.482963
[epoch7, step454]: loss 2.744506
[epoch7, step455]: loss 4.831175
[epoch7, step456]: loss 20.772322
[epoch7, step457]: loss 4.900816
[epoch7, step458]: loss 2.398494
[epoch7, step459]: loss 2.664105
[epoch7, step460]: loss 2.375197
[epoch7, step461]: loss 5.448090
[epoch7, step462]: loss 33.697945
[epoch7, step463]: loss 15.069290
[epoch7, step464]: loss 1.428332
[epoch7, step465]: loss 7.258820
[epoch7, step466]: loss 4.165214
[epoch7, step467]: loss 1.015027
[epoch7, step468]: loss 7.874413
[epoch7, step469]: loss 2.194770
[epoch7, step470]: loss 6.901815
[epoch7, step471]: loss 15.717358
[epoch7, step472]: loss 3.298396
[epoch7, step473]: loss 4.717724
[epoch7, step474]: loss 2.124320
[epoch7, step475]: loss 3.340858
[epoch7, step476]: loss 1.859730
[epoch7, step477]: loss 1.648922
[epoch7, step478]: loss 2.440355
[epoch7, step479]: loss 1.988285
[epoch7, step480]: loss 2.904221
[epoch7, step481]: loss 2.435304
[epoch7, step482]: loss 1.857741
[epoch7, step483]: loss 12.066940
[epoch7, step484]: loss 2.111666
[epoch7, step485]: loss 24.507545
[epoch7, step486]: loss 2.297439
[epoch7, step487]: loss 4.041475
[epoch7, step488]: loss 0.812025
[epoch7, step489]: loss 5.571327
[epoch7, step490]: loss 4.017562
[epoch7, step491]: loss 2.509831
[epoch7, step492]: loss 4.777077
[epoch7, step493]: loss 4.105762
[epoch7, step494]: loss 3.257751
[epoch7, step495]: loss 10.422281
[epoch7, step496]: loss 1.842207
[epoch7, step497]: loss 17.096909
[epoch7, step498]: loss 18.092987
[epoch7, step499]: loss 5.102324
[epoch7, step500]: loss 4.012636
[epoch7, step501]: loss 3.847201
[epoch7, step502]: loss 1.771149
[epoch7, step503]: loss 15.655201
[epoch7, step504]: loss 2.531366
[epoch7, step505]: loss 4.096747
[epoch7, step506]: loss 2.094851
[epoch7, step507]: loss 9.000031
[epoch7, step508]: loss 6.794735
[epoch7, step509]: loss 2.611001
[epoch7, step510]: loss 1.438955
[epoch7, step511]: loss 40.770088
[epoch7, step512]: loss 5.481534
[epoch7, step513]: loss 3.949911
[epoch7, step514]: loss 24.726851
[epoch7, step515]: loss 2.067991
[epoch7, step516]: loss 4.261743
[epoch7, step517]: loss 6.958477
[epoch7, step518]: loss 3.709001
[epoch7, step519]: loss 1.626639
[epoch7, step520]: loss 4.732817
[epoch7, step521]: loss 1.929524
[epoch7, step522]: loss 16.214434
[epoch7, step523]: loss 4.430256
[epoch7, step524]: loss 3.597346
[epoch7, step525]: loss 2.784202
[epoch7, step526]: loss 1.306177
[epoch7, step527]: loss 35.906601
[epoch7, step528]: loss 14.254316
[epoch7, step529]: loss 2.878827
[epoch7, step530]: loss 1.508983
[epoch7, step531]: loss 2.872036
[epoch7, step532]: loss 1.541308
[epoch7, step533]: loss 6.380518
[epoch7, step534]: loss 3.913483
[epoch7, step535]: loss 19.825480
[epoch7, step536]: loss 18.517895
[epoch7, step537]: loss 4.178833
[epoch7, step538]: loss 1.416550
[epoch7, step539]: loss 15.927998
[epoch7, step540]: loss 9.994305
[epoch7, step541]: loss 4.054969
[epoch7, step542]: loss 10.601364
[epoch7, step543]: loss 2.903478
[epoch7, step544]: loss 7.341681
[epoch7, step545]: loss 2.322395
[epoch7, step546]: loss 2.639210
[epoch7, step547]: loss 46.824917
[epoch7, step548]: loss 2.822377
[epoch7, step549]: loss 3.757786
[epoch7, step550]: loss 3.034833
[epoch7, step551]: loss 21.250904
[epoch7, step552]: loss 2.356492
[epoch7, step553]: loss 3.350858
[epoch7, step554]: loss 1.679587
[epoch7, step555]: loss 1.317537
[epoch7, step556]: loss 3.986197
[epoch7, step557]: loss 2.880004
[epoch7, step558]: loss 7.709671
[epoch7, step559]: loss 4.379904
[epoch7, step560]: loss 9.294192
[epoch7, step561]: loss 2.405402
[epoch7, step562]: loss 11.382095
[epoch7, step563]: loss 1.848823
[epoch7, step564]: loss 5.483824
[epoch7, step565]: loss 5.103185
[epoch7, step566]: loss 6.116549
[epoch7, step567]: loss 20.761925
[epoch7, step568]: loss 2.145803
[epoch7, step569]: loss 18.157780
[epoch7, step570]: loss 12.171702
[epoch7, step571]: loss 27.307934
[epoch7, step572]: loss 17.638931
[epoch7, step573]: loss 4.560653
[epoch7, step574]: loss 1.973939
[epoch7, step575]: loss 49.543892
[epoch7, step576]: loss 1.548275
[epoch7, step577]: loss 16.238342
[epoch7, step578]: loss 4.900128
[epoch7, step579]: loss 7.383771
[epoch7, step580]: loss 1.489146
[epoch7, step581]: loss 6.520410
[epoch7, step582]: loss 25.480253
[epoch7, step583]: loss 3.680365
[epoch7, step584]: loss 2.441842
[epoch7, step585]: loss 26.702946
[epoch7, step586]: loss 2.018272
[epoch7, step587]: loss 3.988714
[epoch7, step588]: loss 5.089785
[epoch7, step589]: loss 29.991268
[epoch7, step590]: loss 19.192247
[epoch7, step591]: loss 2.239527
[epoch7, step592]: loss 24.649359
[epoch7, step593]: loss 1.945098
[epoch7, step594]: loss 2.364227
[epoch7, step595]: loss 3.348103
[epoch7, step596]: loss 5.271308
[epoch7, step597]: loss 1.353117
[epoch7, step598]: loss 7.942871
[epoch7, step599]: loss 3.131726
[epoch7, step600]: loss 33.836296
[epoch7, step601]: loss 5.486511
[epoch7, step602]: loss 8.965325
[epoch7, step603]: loss 18.405312
[epoch7, step604]: loss 3.966212
[epoch7, step605]: loss 19.111965
[epoch7, step606]: loss 4.023273
[epoch7, step607]: loss 3.195038
[epoch7, step608]: loss 7.392783
[epoch7, step609]: loss 3.922021
[epoch7, step610]: loss 1.647382
[epoch7, step611]: loss 2.488938
[epoch7, step612]: loss 2.350905
[epoch7, step613]: loss 3.039767
[epoch7, step614]: loss 15.062977
[epoch7, step615]: loss 11.727029
[epoch7, step616]: loss 3.717480
[epoch7, step617]: loss 33.017506
[epoch7, step618]: loss 2.710625
[epoch7, step619]: loss 3.479137
[epoch7, step620]: loss 1.901055
[epoch7, step621]: loss 2.065912
[epoch7, step622]: loss 3.184262
[epoch7, step623]: loss 2.996312
[epoch7, step624]: loss 24.752340
[epoch7, step625]: loss 6.557668
[epoch7, step626]: loss 1.972882
[epoch7, step627]: loss 1.669468
[epoch7, step628]: loss 21.653961
[epoch7, step629]: loss 2.833211
[epoch7, step630]: loss 2.162802
[epoch7, step631]: loss 2.603292
[epoch7, step632]: loss 50.024666
[epoch7, step633]: loss 2.161681
[epoch7, step634]: loss 3.720092
[epoch7, step635]: loss 2.761417
[epoch7, step636]: loss 2.051305
[epoch7, step637]: loss 12.902293
[epoch7, step638]: loss 30.892448
[epoch7, step639]: loss 8.648523
[epoch7, step640]: loss 9.658756
[epoch7, step641]: loss 4.822256
[epoch7, step642]: loss 9.911715
[epoch7, step643]: loss 11.226906
[epoch7, step644]: loss 2.393655
[epoch7, step645]: loss 9.460239
[epoch7, step646]: loss 15.421228
[epoch7, step647]: loss 1.938477
[epoch7, step648]: loss 25.785561
[epoch7, step649]: loss 3.062731
[epoch7, step650]: loss 6.055789
[epoch7, step651]: loss 1.820430
[epoch7, step652]: loss 22.443378
[epoch7, step653]: loss 2.912502
[epoch7, step654]: loss 2.586798
[epoch7, step655]: loss 2.847814
[epoch7, step656]: loss 1.158762
[epoch7, step657]: loss 1.659211
[epoch7, step658]: loss 2.475028
[epoch7, step659]: loss 2.577247
[epoch7, step660]: loss 5.808309
[epoch7, step661]: loss 26.888918
[epoch7, step662]: loss 3.398208
[epoch7, step663]: loss 2.432729
[epoch7, step664]: loss 3.277866
[epoch7, step665]: loss 19.008509
[epoch7, step666]: loss 1.781785
[epoch7, step667]: loss 1.179761
[epoch7, step668]: loss 3.141222
[epoch7, step669]: loss 3.819059
[epoch7, step670]: loss 2.039018
[epoch7, step671]: loss 1.580069
[epoch7, step672]: loss 6.051033
[epoch7, step673]: loss 26.279976
[epoch7, step674]: loss 8.114684
[epoch7, step675]: loss 18.236559
[epoch7, step676]: loss 2.306564
[epoch7, step677]: loss 3.531732
[epoch7, step678]: loss 10.056024
[epoch7, step679]: loss 3.004194
[epoch7, step680]: loss 3.005149
[epoch7, step681]: loss 1.211278
[epoch7, step682]: loss 23.945227
[epoch7, step683]: loss 27.013247
[epoch7, step684]: loss 4.251840
[epoch7, step685]: loss 9.622479
[epoch7, step686]: loss 4.226231
[epoch7, step687]: loss 6.992782
[epoch7, step688]: loss 17.566320
[epoch7, step689]: loss 30.397436
[epoch7, step690]: loss 1.862290
[epoch7, step691]: loss 4.894705
[epoch7, step692]: loss 10.695000
[epoch7, step693]: loss 5.767918
[epoch7, step694]: loss 1.910038
[epoch7, step695]: loss 25.215097
[epoch7, step696]: loss 3.891623
[epoch7, step697]: loss 3.260820
[epoch7, step698]: loss 1.532421
[epoch7, step699]: loss 17.540478
[epoch7, step700]: loss 2.227042
[epoch7, step701]: loss 4.473181
[epoch7, step702]: loss 3.045552
[epoch7, step703]: loss 31.161716
[epoch7, step704]: loss 3.541829
[epoch7, step705]: loss 0.910880
[epoch7, step706]: loss 6.472252
[epoch7, step707]: loss 1.795410
[epoch7, step708]: loss 2.577327
[epoch7, step709]: loss 17.139715
[epoch7, step710]: loss 2.020617
[epoch7, step711]: loss 6.400154
[epoch7, step712]: loss 1.870368
[epoch7, step713]: loss 4.479889
[epoch7, step714]: loss 2.452258
[epoch7, step715]: loss 5.106096
[epoch7, step716]: loss 12.385403
[epoch7, step717]: loss 15.308229
[epoch7, step718]: loss 7.122177
[epoch7, step719]: loss 23.037025
[epoch7, step720]: loss 1.046158
[epoch7, step721]: loss 2.033163
[epoch7, step722]: loss 2.308288
[epoch7, step723]: loss 5.228813
[epoch7, step724]: loss 5.760265
[epoch7, step725]: loss 1.641125
[epoch7, step726]: loss 4.193428
[epoch7, step727]: loss 6.342907
[epoch7, step728]: loss 3.788593
[epoch7, step729]: loss 19.639784
[epoch7, step730]: loss 9.450084
[epoch7, step731]: loss 1.685938
[epoch7, step732]: loss 4.668231
[epoch7, step733]: loss 1.828336
[epoch7, step734]: loss 1.895234
[epoch7, step735]: loss 3.110016
[epoch7, step736]: loss 3.394440
[epoch7, step737]: loss 11.453353
[epoch7, step738]: loss 12.294514
[epoch7, step739]: loss 2.530107
[epoch7, step740]: loss 4.674895
[epoch7, step741]: loss 4.109526
[epoch7, step742]: loss 23.232231
[epoch7, step743]: loss 40.191528
[epoch7, step744]: loss 16.466875
[epoch7, step745]: loss 7.015319
[epoch7, step746]: loss 17.447952
[epoch7, step747]: loss 1.416445
[epoch7, step748]: loss 1.931638
[epoch7, step749]: loss 8.426731
[epoch7, step750]: loss 17.554188
[epoch7, step751]: loss 3.587150
[epoch7, step752]: loss 3.513588
[epoch7, step753]: loss 21.902069
[epoch7, step754]: loss 3.048123
[epoch7, step755]: loss 9.416116
[epoch7, step756]: loss 1.815222
[epoch7, step757]: loss 2.507898
[epoch7, step758]: loss 3.768796
[epoch7, step759]: loss 5.013555
[epoch7, step760]: loss 23.602728
[epoch7, step761]: loss 20.450796
[epoch7, step762]: loss 32.899231
[epoch7, step763]: loss 1.952500
[epoch7, step764]: loss 5.706864
[epoch7, step765]: loss 2.058326
[epoch7, step766]: loss 1.601818
[epoch7, step767]: loss 3.348333
[epoch7, step768]: loss 21.046352
[epoch7, step769]: loss 3.846306
[epoch7, step770]: loss 2.830514
[epoch7, step771]: loss 3.660372
[epoch7, step772]: loss 2.333117
[epoch7, step773]: loss 1.906689
[epoch7, step774]: loss 7.800408
[epoch7, step775]: loss 2.915351
[epoch7, step776]: loss 1.511153
[epoch7, step777]: loss 1.654061
[epoch7, step778]: loss 14.389191
[epoch7, step779]: loss 16.490793
[epoch7, step780]: loss 2.386537
[epoch7, step781]: loss 20.802242
[epoch7, step782]: loss 2.795719
[epoch7, step783]: loss 2.575220
[epoch7, step784]: loss 1.561745
[epoch7, step785]: loss 3.952415
[epoch7, step786]: loss 17.348799
[epoch7, step787]: loss 4.158630
[epoch7, step788]: loss 2.786476
[epoch7, step789]: loss 13.580575
[epoch7, step790]: loss 18.176193
[epoch7, step791]: loss 20.981035
[epoch7, step792]: loss 8.008774
[epoch7, step793]: loss 3.087846
[epoch7, step794]: loss 7.332349
[epoch7, step795]: loss 5.710449
[epoch7, step796]: loss 9.809996
[epoch7, step797]: loss 4.275761
[epoch7, step798]: loss 24.371162
[epoch7, step799]: loss 2.541276
[epoch7, step800]: loss 27.448698
[epoch7, step801]: loss 2.600821
[epoch7, step802]: loss 4.439488
[epoch7, step803]: loss 44.896320
[epoch7, step804]: loss 6.364328
[epoch7, step805]: loss 1.501922
[epoch7, step806]: loss 2.494205
[epoch7, step807]: loss 34.751148
[epoch7, step808]: loss 4.273784
[epoch7, step809]: loss 8.122395
[epoch7, step810]: loss 4.984933
[epoch7, step811]: loss 2.022485
[epoch7, step812]: loss 18.523355
[epoch7, step813]: loss 6.468883
[epoch7, step814]: loss 1.944942
[epoch7, step815]: loss 8.226501
[epoch7, step816]: loss 4.073087
[epoch7, step817]: loss 1.454501
[epoch7, step818]: loss 3.775458
[epoch7, step819]: loss 2.486984
[epoch7, step820]: loss 7.926005
[epoch7, step821]: loss 2.549350
[epoch7, step822]: loss 11.518316
[epoch7, step823]: loss 2.075299
[epoch7, step824]: loss 5.394680
[epoch7, step825]: loss 21.243231
[epoch7, step826]: loss 1.373230
[epoch7, step827]: loss 1.575520
[epoch7, step828]: loss 2.915489
[epoch7, step829]: loss 22.250193
[epoch7, step830]: loss 1.540624
[epoch7, step831]: loss 1.874130
[epoch7, step832]: loss 1.255096
[epoch7, step833]: loss 5.256980
[epoch7, step834]: loss 3.339896
[epoch7, step835]: loss 1.595691
[epoch7, step836]: loss 1.564893
[epoch7, step837]: loss 3.570615
[epoch7, step838]: loss 26.027464
[epoch7, step839]: loss 22.819347
[epoch7, step840]: loss 1.483920
[epoch7, step841]: loss 6.507550
[epoch7, step842]: loss 2.222560
[epoch7, step843]: loss 1.469697
[epoch7, step844]: loss 11.237375
[epoch7, step845]: loss 3.679720
[epoch7, step846]: loss 1.394972
[epoch7, step847]: loss 6.534550
[epoch7, step848]: loss 1.434731
[epoch7, step849]: loss 3.976515
[epoch7, step850]: loss 20.683500
[epoch7, step851]: loss 1.635185
[epoch7, step852]: loss 3.469443
[epoch7, step853]: loss 15.216051
[epoch7, step854]: loss 17.924509
[epoch7, step855]: loss 1.769864
[epoch7, step856]: loss 32.000694
[epoch7, step857]: loss 4.585604
[epoch7, step858]: loss 34.612698
[epoch7, step859]: loss 20.491669
[epoch7, step860]: loss 3.751335
[epoch7, step861]: loss 2.728229
[epoch7, step862]: loss 6.577936
[epoch7, step863]: loss 8.596998
[epoch7, step864]: loss 17.334106
[epoch7, step865]: loss 5.807421
[epoch7, step866]: loss 2.293527
[epoch7, step867]: loss 17.429966
[epoch7, step868]: loss 1.598137
[epoch7, step869]: loss 1.675437
[epoch7, step870]: loss 3.029119
[epoch7, step871]: loss 1.873265
[epoch7, step872]: loss 2.326040
[epoch7, step873]: loss 2.728535
[epoch7, step874]: loss 3.870641
[epoch7, step875]: loss 22.567911
[epoch7, step876]: loss 6.729748
[epoch7, step877]: loss 4.093697
[epoch7, step878]: loss 1.441038
[epoch7, step879]: loss 15.035682
[epoch7, step880]: loss 4.347565
[epoch7, step881]: loss 1.785119
[epoch7, step882]: loss 7.485168
[epoch7, step883]: loss 1.493767
[epoch7, step884]: loss 3.901412
[epoch7, step885]: loss 1.084718
[epoch7, step886]: loss 5.278762
[epoch7, step887]: loss 35.766171
[epoch7, step888]: loss 4.789718
[epoch7, step889]: loss 2.181700
[epoch7, step890]: loss 3.863173
[epoch7, step891]: loss 2.500153
[epoch7, step892]: loss 18.352844
[epoch7, step893]: loss 33.439915
[epoch7, step894]: loss 2.542963
[epoch7, step895]: loss 1.513672
[epoch7, step896]: loss 19.467773
[epoch7, step897]: loss 4.789361
[epoch7, step898]: loss 1.684868
[epoch7, step899]: loss 5.667543
[epoch7, step900]: loss 1.658722
[epoch7, step901]: loss 4.025201
[epoch7, step902]: loss 5.497706
[epoch7, step903]: loss 2.504432
[epoch7, step904]: loss 1.297606
[epoch7, step905]: loss 2.104225
[epoch7, step906]: loss 15.083777
[epoch7, step907]: loss 5.675422
[epoch7, step908]: loss 27.192738
[epoch7, step909]: loss 16.479130
[epoch7, step910]: loss 25.880402
[epoch7, step911]: loss 4.617758
[epoch7, step912]: loss 10.559188
[epoch7, step913]: loss 5.705198
[epoch7, step914]: loss 4.762321
[epoch7, step915]: loss 32.192257
[epoch7, step916]: loss 2.412846
[epoch7, step917]: loss 11.136374
[epoch7, step918]: loss 6.021959
[epoch7, step919]: loss 14.439426
[epoch7, step920]: loss 1.361163
[epoch7, step921]: loss 3.849495
[epoch7, step922]: loss 40.442886
[epoch7, step923]: loss 14.352756
[epoch7, step924]: loss 32.397156
[epoch7, step925]: loss 1.862657
[epoch7, step926]: loss 5.061670
[epoch7, step927]: loss 1.771052
[epoch7, step928]: loss 37.123653
[epoch7, step929]: loss 6.283408
[epoch7, step930]: loss 2.612065
[epoch7, step931]: loss 21.032379
[epoch7, step932]: loss 2.795036
[epoch7, step933]: loss 1.291624
[epoch7, step934]: loss 14.775917
[epoch7, step935]: loss 5.922992
[epoch7, step936]: loss 20.560062
[epoch7, step937]: loss 2.913149
[epoch7, step938]: loss 22.477467
[epoch7, step939]: loss 4.731460
[epoch7, step940]: loss 22.732010
[epoch7, step941]: loss 7.101786
[epoch7, step942]: loss 16.178238
[epoch7, step943]: loss 28.436550
[epoch7, step944]: loss 1.417894
[epoch7, step945]: loss 2.171293
[epoch7, step946]: loss 2.981034
[epoch7, step947]: loss 3.482929
[epoch7, step948]: loss 9.580187
[epoch7, step949]: loss 20.039946
[epoch7, step950]: loss 16.738241
[epoch7, step951]: loss 3.831080
[epoch7, step952]: loss 6.774722
[epoch7, step953]: loss 2.933135
[epoch7, step954]: loss 2.759832
[epoch7, step955]: loss 8.196408
[epoch7, step956]: loss 2.153609
[epoch7, step957]: loss 7.444942
[epoch7, step958]: loss 24.127199
[epoch7, step959]: loss 16.983402
[epoch7, step960]: loss 1.878185
[epoch7, step961]: loss 2.017571
[epoch7, step962]: loss 1.877016
[epoch7, step963]: loss 2.416956
[epoch7, step964]: loss 4.524858
[epoch7, step965]: loss 3.320816
[epoch7, step966]: loss 2.320561
[epoch7, step967]: loss 20.615299
[epoch7, step968]: loss 1.628584
[epoch7, step969]: loss 2.737341
[epoch7, step970]: loss 1.614129
[epoch7, step971]: loss 1.949298
[epoch7, step972]: loss 1.335110
[epoch7, step973]: loss 5.253401
[epoch7, step974]: loss 1.932765
[epoch7, step975]: loss 4.236903
[epoch7, step976]: loss 4.749938
[epoch7, step977]: loss 3.112532
[epoch7, step978]: loss 5.142067
[epoch7, step979]: loss 3.448689
[epoch7, step980]: loss 4.173897
[epoch7, step981]: loss 4.173665
[epoch7, step982]: loss 2.600038
[epoch7, step983]: loss 1.601193
[epoch7, step984]: loss 21.050850
[epoch7, step985]: loss 12.472592
[epoch7, step986]: loss 2.487154
[epoch7, step987]: loss 3.008924
[epoch7, step988]: loss 3.153371
[epoch7, step989]: loss 1.302772
[epoch7, step990]: loss 14.212740
[epoch7, step991]: loss 1.646256
[epoch7, step992]: loss 19.676449
[epoch7, step993]: loss 11.200084
[epoch7, step994]: loss 2.731438
[epoch7, step995]: loss 1.898054
[epoch7, step996]: loss 1.653732
[epoch7, step997]: loss 1.549675
[epoch7, step998]: loss 19.288740
[epoch7, step999]: loss 1.572793
[epoch7, step1000]: loss 2.987530
[epoch7, step1001]: loss 2.733597
[epoch7, step1002]: loss 5.745812
[epoch7, step1003]: loss 6.700511
[epoch7, step1004]: loss 2.213656
[epoch7, step1005]: loss 1.813663
[epoch7, step1006]: loss 33.948471
[epoch7, step1007]: loss 1.431626
[epoch7, step1008]: loss 17.993580
[epoch7, step1009]: loss 5.306332
[epoch7, step1010]: loss 3.201082
[epoch7, step1011]: loss 22.002159
[epoch7, step1012]: loss 5.779615
[epoch7, step1013]: loss 1.558340
[epoch7, step1014]: loss 5.198530
[epoch7, step1015]: loss 15.297520
[epoch7, step1016]: loss 1.956391
[epoch7, step1017]: loss 5.377547
[epoch7, step1018]: loss 24.065664
[epoch7, step1019]: loss 1.560130
[epoch7, step1020]: loss 2.176998
[epoch7, step1021]: loss 11.728628
[epoch7, step1022]: loss 2.812959
[epoch7, step1023]: loss 23.072298
[epoch7, step1024]: loss 15.711649
[epoch7, step1025]: loss 3.422743
[epoch7, step1026]: loss 1.388107
[epoch7, step1027]: loss 4.890677
[epoch7, step1028]: loss 7.142797
[epoch7, step1029]: loss 21.488579
[epoch7, step1030]: loss 4.404537
[epoch7, step1031]: loss 6.615448
[epoch7, step1032]: loss 4.205114
[epoch7, step1033]: loss 2.451045
[epoch7, step1034]: loss 2.091698
[epoch7, step1035]: loss 15.415445
[epoch7, step1036]: loss 13.896380
[epoch7, step1037]: loss 8.717010
[epoch7, step1038]: loss 3.997036
[epoch7, step1039]: loss 4.557864
[epoch7, step1040]: loss 1.084080
[epoch7, step1041]: loss 19.880644
[epoch7, step1042]: loss 21.782652
[epoch7, step1043]: loss 18.361296
[epoch7, step1044]: loss 1.634706
[epoch7, step1045]: loss 1.966790
[epoch7, step1046]: loss 3.343367
[epoch7, step1047]: loss 7.248891
[epoch7, step1048]: loss 4.524269
[epoch7, step1049]: loss 1.343921
[epoch7, step1050]: loss 3.651146
[epoch7, step1051]: loss 6.985315
[epoch7, step1052]: loss 3.991644
[epoch7, step1053]: loss 4.165691
[epoch7, step1054]: loss 2.240735
[epoch7, step1055]: loss 2.206397
[epoch7, step1056]: loss 2.751212
[epoch7, step1057]: loss 14.871717
[epoch7, step1058]: loss 6.142502
[epoch7, step1059]: loss 2.713197
[epoch7, step1060]: loss 1.527806
[epoch7, step1061]: loss 10.736408
[epoch7, step1062]: loss 1.009447
[epoch7, step1063]: loss 2.459639
[epoch7, step1064]: loss 19.319374
[epoch7, step1065]: loss 1.754277
[epoch7, step1066]: loss 3.744321
[epoch7, step1067]: loss 3.408652
[epoch7, step1068]: loss 11.409291
[epoch7, step1069]: loss 3.463325
[epoch7, step1070]: loss 23.324871
[epoch7, step1071]: loss 21.922380
[epoch7, step1072]: loss 2.576246
[epoch7, step1073]: loss 29.671263
[epoch7, step1074]: loss 3.300514
[epoch7, step1075]: loss 2.124852
[epoch7, step1076]: loss 20.038887
[epoch7, step1077]: loss 2.686800
[epoch7, step1078]: loss 8.407883
[epoch7, step1079]: loss 4.057697
[epoch7, step1080]: loss 16.006704
[epoch7, step1081]: loss 3.569259
[epoch7, step1082]: loss 7.559896
[epoch7, step1083]: loss 2.084608
[epoch7, step1084]: loss 4.109840
[epoch7, step1085]: loss 2.141978
[epoch7, step1086]: loss 3.686997
[epoch7, step1087]: loss 1.329387
[epoch7, step1088]: loss 5.779888
[epoch7, step1089]: loss 1.706434
[epoch7, step1090]: loss 7.496547
[epoch7, step1091]: loss 1.505557
[epoch7, step1092]: loss 15.956077
[epoch7, step1093]: loss 6.708630
[epoch7, step1094]: loss 2.408214
[epoch7, step1095]: loss 3.829498
[epoch7, step1096]: loss 5.500829
[epoch7, step1097]: loss 2.531404
[epoch7, step1098]: loss 1.902588
[epoch7, step1099]: loss 10.143565
[epoch7, step1100]: loss 24.377504
[epoch7, step1101]: loss 2.268257
[epoch7, step1102]: loss 22.079668
[epoch7, step1103]: loss 2.500951
[epoch7, step1104]: loss 2.050661
[epoch7, step1105]: loss 2.422613
[epoch7, step1106]: loss 3.067799
[epoch7, step1107]: loss 4.723828
[epoch7, step1108]: loss 2.123778
[epoch7, step1109]: loss 7.261490
[epoch7, step1110]: loss 7.381286
[epoch7, step1111]: loss 7.232127
[epoch7, step1112]: loss 2.293814
[epoch7, step1113]: loss 2.524961
[epoch7, step1114]: loss 4.203568
[epoch7, step1115]: loss 10.227017
[epoch7, step1116]: loss 1.707577
[epoch7, step1117]: loss 3.600520
[epoch7, step1118]: loss 16.289740
[epoch7, step1119]: loss 4.749402
[epoch7, step1120]: loss 13.304436
[epoch7, step1121]: loss 1.527392
[epoch7, step1122]: loss 2.619652
[epoch7, step1123]: loss 3.502523
[epoch7, step1124]: loss 21.880787
[epoch7, step1125]: loss 4.975858
[epoch7, step1126]: loss 16.856405
[epoch7, step1127]: loss 26.967983
[epoch7, step1128]: loss 3.549927
[epoch7, step1129]: loss 4.838006
[epoch7, step1130]: loss 3.670721
[epoch7, step1131]: loss 3.127552
[epoch7, step1132]: loss 45.539322
[epoch7, step1133]: loss 2.895349
[epoch7, step1134]: loss 3.202667
[epoch7, step1135]: loss 2.262124
[epoch7, step1136]: loss 7.888691
[epoch7, step1137]: loss 24.667622
[epoch7, step1138]: loss 24.568003
[epoch7, step1139]: loss 1.940377
[epoch7, step1140]: loss 1.717895
[epoch7, step1141]: loss 4.455178
[epoch7, step1142]: loss 24.264210
[epoch7, step1143]: loss 1.364856
[epoch7, step1144]: loss 2.983944
[epoch7, step1145]: loss 1.096489
[epoch7, step1146]: loss 3.074895
[epoch7, step1147]: loss 1.273453
[epoch7, step1148]: loss 19.680420
[epoch7, step1149]: loss 3.514893
[epoch7, step1150]: loss 5.275853
[epoch7, step1151]: loss 6.687261
[epoch7, step1152]: loss 13.591062
[epoch7, step1153]: loss 2.471807
[epoch7, step1154]: loss 4.080118
[epoch7, step1155]: loss 7.416119
[epoch7, step1156]: loss 18.559961
[epoch7, step1157]: loss 7.911421
[epoch7, step1158]: loss 21.266119
[epoch7, step1159]: loss 4.367248
[epoch7, step1160]: loss 4.017208
[epoch7, step1161]: loss 2.333552
[epoch7, step1162]: loss 2.902093
[epoch7, step1163]: loss 15.513399
[epoch7, step1164]: loss 2.407643
[epoch7, step1165]: loss 4.911610
[epoch7, step1166]: loss 5.610375
[epoch7, step1167]: loss 6.508294
[epoch7, step1168]: loss 8.309532
[epoch7, step1169]: loss 7.814262
[epoch7, step1170]: loss 3.604895
[epoch7, step1171]: loss 2.098703
[epoch7, step1172]: loss 8.473749
[epoch7, step1173]: loss 1.227853
[epoch7, step1174]: loss 5.143269
[epoch7, step1175]: loss 1.508690
[epoch7, step1176]: loss 3.107011
[epoch7, step1177]: loss 3.627395
[epoch7, step1178]: loss 5.228086
[epoch7, step1179]: loss 18.991541
[epoch7, step1180]: loss 2.041279
[epoch7, step1181]: loss 1.498173
[epoch7, step1182]: loss 7.257106
[epoch7, step1183]: loss 4.068727
[epoch7, step1184]: loss 23.295168
[epoch7, step1185]: loss 2.927553
[epoch7, step1186]: loss 1.824991
[epoch7, step1187]: loss 6.614190
[epoch7, step1188]: loss 2.110399
[epoch7, step1189]: loss 34.633911
[epoch7, step1190]: loss 18.064913
[epoch7, step1191]: loss 3.906971
[epoch7, step1192]: loss 2.216790
[epoch7, step1193]: loss 1.865292
[epoch7, step1194]: loss 8.811263
[epoch7, step1195]: loss 7.660108
[epoch7, step1196]: loss 3.826761
[epoch7, step1197]: loss 35.967102
[epoch7, step1198]: loss 3.743383
[epoch7, step1199]: loss 12.192119
[epoch7, step1200]: loss 1.217913
[epoch7, step1201]: loss 5.407487
[epoch7, step1202]: loss 2.981457
[epoch7, step1203]: loss 24.558661
[epoch7, step1204]: loss 16.493086
[epoch7, step1205]: loss 4.318881
[epoch7, step1206]: loss 3.221210
[epoch7, step1207]: loss 3.936885
[epoch7, step1208]: loss 48.440750
[epoch7, step1209]: loss 1.799328
[epoch7, step1210]: loss 7.009161
[epoch7, step1211]: loss 1.140484
[epoch7, step1212]: loss 3.140345
[epoch7, step1213]: loss 1.772452
[epoch7, step1214]: loss 2.207018
[epoch7, step1215]: loss 5.295261
[epoch7, step1216]: loss 1.144553
[epoch7, step1217]: loss 2.543009
[epoch7, step1218]: loss 16.360876
[epoch7, step1219]: loss 14.924284
[epoch7, step1220]: loss 18.175810
[epoch7, step1221]: loss 2.256974
[epoch7, step1222]: loss 37.551170
[epoch7, step1223]: loss 8.245374
[epoch7, step1224]: loss 28.319857
[epoch7, step1225]: loss 1.493599
[epoch7, step1226]: loss 4.956527
[epoch7, step1227]: loss 3.151582
[epoch7, step1228]: loss 6.793377
[epoch7, step1229]: loss 1.869309
[epoch7, step1230]: loss 2.448948
[epoch7, step1231]: loss 2.527685
[epoch7, step1232]: loss 2.962363
[epoch7, step1233]: loss 3.504755
[epoch7, step1234]: loss 4.209565
[epoch7, step1235]: loss 2.492803
[epoch7, step1236]: loss 21.564362
[epoch7, step1237]: loss 14.120420
[epoch7, step1238]: loss 17.177593
[epoch7, step1239]: loss 1.444104
[epoch7, step1240]: loss 18.694241
[epoch7, step1241]: loss 2.318124
[epoch7, step1242]: loss 2.156583
[epoch7, step1243]: loss 3.262775
[epoch7, step1244]: loss 3.539109
[epoch7, step1245]: loss 16.250011
[epoch7, step1246]: loss 4.020888
[epoch7, step1247]: loss 15.325982
[epoch7, step1248]: loss 18.180376
[epoch7, step1249]: loss 18.599535
[epoch7, step1250]: loss 2.366355
[epoch7, step1251]: loss 2.013890
[epoch7, step1252]: loss 21.486189
[epoch7, step1253]: loss 1.588597
[epoch7, step1254]: loss 1.510326
[epoch7, step1255]: loss 1.146393
[epoch7, step1256]: loss 10.582775
[epoch7, step1257]: loss 32.303223
[epoch7, step1258]: loss 16.371912
[epoch7, step1259]: loss 2.751469
[epoch7, step1260]: loss 1.883722
[epoch7, step1261]: loss 2.537863
[epoch7, step1262]: loss 8.227279
[epoch7, step1263]: loss 2.489561
[epoch7, step1264]: loss 11.536882
[epoch7, step1265]: loss 20.953865
[epoch7, step1266]: loss 2.547732
[epoch7, step1267]: loss 2.027462
[epoch7, step1268]: loss 3.041801
[epoch7, step1269]: loss 17.314716
[epoch7, step1270]: loss 2.549712
[epoch7, step1271]: loss 4.261669
[epoch7, step1272]: loss 1.918790
[epoch7, step1273]: loss 44.490128
[epoch7, step1274]: loss 13.140475
[epoch7, step1275]: loss 5.450651
[epoch7, step1276]: loss 3.698838
[epoch7, step1277]: loss 7.998170
[epoch7, step1278]: loss 1.866010
[epoch7, step1279]: loss 14.355179
[epoch7, step1280]: loss 6.125676
[epoch7, step1281]: loss 2.056431
[epoch7, step1282]: loss 13.431477
[epoch7, step1283]: loss 2.186178
[epoch7, step1284]: loss 1.459353
[epoch7, step1285]: loss 3.474508
[epoch7, step1286]: loss 1.427296
[epoch7, step1287]: loss 2.842959
[epoch7, step1288]: loss 2.087625
[epoch7, step1289]: loss 2.706689
[epoch7, step1290]: loss 9.571290
[epoch7, step1291]: loss 5.179165
[epoch7, step1292]: loss 1.515092
[epoch7, step1293]: loss 3.902944
[epoch7, step1294]: loss 1.934690
[epoch7, step1295]: loss 2.018500
[epoch7, step1296]: loss 3.008297
[epoch7, step1297]: loss 1.905613
[epoch7, step1298]: loss 2.647657
[epoch7, step1299]: loss 9.631146
[epoch7, step1300]: loss 19.335903
[epoch7, step1301]: loss 2.941723
[epoch7, step1302]: loss 1.776306
[epoch7, step1303]: loss 7.551615
[epoch7, step1304]: loss 2.832615
[epoch7, step1305]: loss 2.057730
[epoch7, step1306]: loss 3.138035
[epoch7, step1307]: loss 1.073300
[epoch7, step1308]: loss 26.001083
[epoch7, step1309]: loss 3.638078
[epoch7, step1310]: loss 13.579198
[epoch7, step1311]: loss 8.757958
[epoch7, step1312]: loss 7.434130
[epoch7, step1313]: loss 2.446306
[epoch7, step1314]: loss 3.333395
[epoch7, step1315]: loss 37.432079
[epoch7, step1316]: loss 2.405168
[epoch7, step1317]: loss 3.604072
[epoch7, step1318]: loss 1.453064
[epoch7, step1319]: loss 2.693401
[epoch7, step1320]: loss 3.557097
[epoch7, step1321]: loss 1.430683
[epoch7, step1322]: loss 1.102725
[epoch7, step1323]: loss 15.554077
[epoch7, step1324]: loss 6.743677
[epoch7, step1325]: loss 3.406224
[epoch7, step1326]: loss 37.216347
[epoch7, step1327]: loss 7.053533
[epoch7, step1328]: loss 7.012619
[epoch7, step1329]: loss 9.513546
[epoch7, step1330]: loss 11.727772
[epoch7, step1331]: loss 7.038914
[epoch7, step1332]: loss 17.943401
[epoch7, step1333]: loss 20.510643
[epoch7, step1334]: loss 4.169740
[epoch7, step1335]: loss 26.155861
[epoch7, step1336]: loss 1.772224
[epoch7, step1337]: loss 3.702122
[epoch7, step1338]: loss 20.085390
[epoch7, step1339]: loss 1.913295
[epoch7, step1340]: loss 9.951610
[epoch7, step1341]: loss 8.637113
[epoch7, step1342]: loss 36.823063
[epoch7, step1343]: loss 22.302662
[epoch7, step1344]: loss 1.310063
[epoch7, step1345]: loss 6.833560
[epoch7, step1346]: loss 11.391860
[epoch7, step1347]: loss 1.810535
[epoch7, step1348]: loss 2.440876
[epoch7, step1349]: loss 2.850192
[epoch7, step1350]: loss 4.465304
[epoch7, step1351]: loss 2.528625
[epoch7, step1352]: loss 2.809085
[epoch7, step1353]: loss 1.690733
[epoch7, step1354]: loss 1.928549
[epoch7, step1355]: loss 1.856296
[epoch7, step1356]: loss 1.841924
[epoch7, step1357]: loss 5.676795
[epoch7, step1358]: loss 5.771298
[epoch7, step1359]: loss 4.694423
[epoch7, step1360]: loss 14.187136
[epoch7, step1361]: loss 3.062798
[epoch7, step1362]: loss 1.018870
[epoch7, step1363]: loss 19.390856
[epoch7, step1364]: loss 24.865835
[epoch7, step1365]: loss 1.922010
[epoch7, step1366]: loss 3.694481
[epoch7, step1367]: loss 3.379811
[epoch7, step1368]: loss 3.041308
[epoch7, step1369]: loss 4.570964
[epoch7, step1370]: loss 2.584597
[epoch7, step1371]: loss 16.306637
[epoch7, step1372]: loss 1.573704
[epoch7, step1373]: loss 3.534893
[epoch7, step1374]: loss 5.448370
[epoch7, step1375]: loss 19.065912
[epoch7, step1376]: loss 9.557473
[epoch7, step1377]: loss 1.729160
[epoch7, step1378]: loss 2.285707
[epoch7, step1379]: loss 39.315636
[epoch7, step1380]: loss 2.221908
[epoch7, step1381]: loss 4.420477
[epoch7, step1382]: loss 1.829154
[epoch7, step1383]: loss 4.626443
[epoch7, step1384]: loss 7.841232
[epoch7, step1385]: loss 33.561459
[epoch7, step1386]: loss 2.343833
[epoch7, step1387]: loss 17.972933
[epoch7, step1388]: loss 34.284557
[epoch7, step1389]: loss 8.203611
[epoch7, step1390]: loss 1.980702
[epoch7, step1391]: loss 18.568399
[epoch7, step1392]: loss 2.122793
[epoch7, step1393]: loss 4.336808
[epoch7, step1394]: loss 3.527608
[epoch7, step1395]: loss 18.434208
[epoch7, step1396]: loss 2.787930
[epoch7, step1397]: loss 7.319596
[epoch7, step1398]: loss 2.302403
[epoch7, step1399]: loss 1.757402
[epoch7, step1400]: loss 3.508943
[epoch7, step1401]: loss 2.515698
[epoch7, step1402]: loss 9.032784
[epoch7, step1403]: loss 3.787255
[epoch7, step1404]: loss 5.332698
[epoch7, step1405]: loss 3.389169
[epoch7, step1406]: loss 6.765256
[epoch7, step1407]: loss 22.739868
[epoch7, step1408]: loss 7.912186
[epoch7, step1409]: loss 2.531349
[epoch7, step1410]: loss 20.067005
[epoch7, step1411]: loss 17.461786
[epoch7, step1412]: loss 10.766869
[epoch7, step1413]: loss 5.225764
[epoch7, step1414]: loss 2.345555
[epoch7, step1415]: loss 5.158873
[epoch7, step1416]: loss 4.029985
[epoch7, step1417]: loss 23.443619
[epoch7, step1418]: loss 7.131472
[epoch7, step1419]: loss 5.271844
[epoch7, step1420]: loss 6.159225
[epoch7, step1421]: loss 3.520789
[epoch7, step1422]: loss 1.096317
[epoch7, step1423]: loss 1.850083
[epoch7, step1424]: loss 4.256555
[epoch7, step1425]: loss 3.554365
[epoch7, step1426]: loss 22.574738
[epoch7, step1427]: loss 6.794988
[epoch7, step1428]: loss 4.008018
[epoch7, step1429]: loss 2.163514
[epoch7, step1430]: loss 3.586680
[epoch7, step1431]: loss 16.861652
[epoch7, step1432]: loss 8.413765
[epoch7, step1433]: loss 2.410408
[epoch7, step1434]: loss 2.890379
[epoch7, step1435]: loss 4.134083
[epoch7, step1436]: loss 37.075100
[epoch7, step1437]: loss 3.879240
[epoch7, step1438]: loss 2.381367
[epoch7, step1439]: loss 5.828708
[epoch7, step1440]: loss 7.500776
[epoch7, step1441]: loss 4.480205
[epoch7, step1442]: loss 2.802277
[epoch7, step1443]: loss 2.247527
[epoch7, step1444]: loss 7.855081
[epoch7, step1445]: loss 5.245136
[epoch7, step1446]: loss 27.660732
[epoch7, step1447]: loss 1.340905
[epoch7, step1448]: loss 31.828968
[epoch7, step1449]: loss 30.168316
[epoch7, step1450]: loss 7.502162
[epoch7, step1451]: loss 5.344160
[epoch7, step1452]: loss 5.060265
[epoch7, step1453]: loss 1.566536
[epoch7, step1454]: loss 2.029522
[epoch7, step1455]: loss 3.723407
[epoch7, step1456]: loss 1.023139
[epoch7, step1457]: loss 1.958662
[epoch7, step1458]: loss 12.396128
[epoch7, step1459]: loss 1.730357
[epoch7, step1460]: loss 2.358869
[epoch7, step1461]: loss 2.656481
[epoch7, step1462]: loss 3.474293
[epoch7, step1463]: loss 3.017585
[epoch7, step1464]: loss 26.302912
[epoch7, step1465]: loss 8.401482
[epoch7, step1466]: loss 31.018259
[epoch7, step1467]: loss 19.485746
[epoch7, step1468]: loss 3.826600
[epoch7, step1469]: loss 2.004643
[epoch7, step1470]: loss 2.390695
[epoch7, step1471]: loss 1.708704
[epoch7, step1472]: loss 1.401986
[epoch7, step1473]: loss 9.242548
[epoch7, step1474]: loss 1.806824
[epoch7, step1475]: loss 4.881821
[epoch7, step1476]: loss 6.324390
[epoch7, step1477]: loss 4.175034
[epoch7, step1478]: loss 5.811564
[epoch7, step1479]: loss 29.479334
[epoch7, step1480]: loss 2.034587
[epoch7, step1481]: loss 1.266796
[epoch7, step1482]: loss 19.754528
[epoch7, step1483]: loss 1.103153
[epoch7, step1484]: loss 12.401607
[epoch7, step1485]: loss 0.897570
[epoch7, step1486]: loss 2.230787
[epoch7, step1487]: loss 2.797718
[epoch7, step1488]: loss 16.816206
[epoch7, step1489]: loss 1.884669
[epoch7, step1490]: loss 1.862706
[epoch7, step1491]: loss 1.417295
[epoch7, step1492]: loss 5.646216
[epoch7, step1493]: loss 3.976405
[epoch7, step1494]: loss 1.708757
[epoch7, step1495]: loss 19.160892
[epoch7, step1496]: loss 2.527717
[epoch7, step1497]: loss 30.957491
[epoch7, step1498]: loss 20.307076
[epoch7, step1499]: loss 2.753974
[epoch7, step1500]: loss 2.854402
[epoch7, step1501]: loss 15.755328
[epoch7, step1502]: loss 9.185287
[epoch7, step1503]: loss 1.518708
[epoch7, step1504]: loss 4.023949
[epoch7, step1505]: loss 2.558383
[epoch7, step1506]: loss 5.214378
[epoch7, step1507]: loss 2.600400
[epoch7, step1508]: loss 2.887395
[epoch7, step1509]: loss 1.143806
[epoch7, step1510]: loss 2.638593
[epoch7, step1511]: loss 3.341830
[epoch7, step1512]: loss 13.891127
[epoch7, step1513]: loss 3.061936
[epoch7, step1514]: loss 2.315917
[epoch7, step1515]: loss 15.547944
[epoch7, step1516]: loss 4.222678
[epoch7, step1517]: loss 9.372925
[epoch7, step1518]: loss 2.163732
[epoch7, step1519]: loss 1.654617
[epoch7, step1520]: loss 2.160914
[epoch7, step1521]: loss 7.399134
[epoch7, step1522]: loss 5.238393
[epoch7, step1523]: loss 6.930830
[epoch7, step1524]: loss 12.825674
[epoch7, step1525]: loss 15.745597
[epoch7, step1526]: loss 2.246680
[epoch7, step1527]: loss 23.851915
[epoch7, step1528]: loss 18.420042
[epoch7, step1529]: loss 23.983459
[epoch7, step1530]: loss 1.911165
[epoch7, step1531]: loss 37.619438
[epoch7, step1532]: loss 10.587775
[epoch7, step1533]: loss 1.594340
[epoch7, step1534]: loss 1.843844
[epoch7, step1535]: loss 14.380419
[epoch7, step1536]: loss 10.998106
[epoch7, step1537]: loss 2.256226
[epoch7, step1538]: loss 2.058567
[epoch7, step1539]: loss 5.579261
[epoch7, step1540]: loss 2.772512
[epoch7, step1541]: loss 3.726909
[epoch7, step1542]: loss 35.500954
[epoch7, step1543]: loss 8.379719
[epoch7, step1544]: loss 3.785629
[epoch7, step1545]: loss 27.139755
[epoch7, step1546]: loss 2.897889
[epoch7, step1547]: loss 4.358910
[epoch7, step1548]: loss 5.202430
[epoch7, step1549]: loss 15.893024
[epoch7, step1550]: loss 15.230480
[epoch7, step1551]: loss 15.371089
[epoch7, step1552]: loss 3.021171
[epoch7, step1553]: loss 3.158967
[epoch7, step1554]: loss 6.205734
[epoch7, step1555]: loss 4.612926
[epoch7, step1556]: loss 1.603803
[epoch7, step1557]: loss 2.461596
[epoch7, step1558]: loss 19.937300
[epoch7, step1559]: loss 1.714093
[epoch7, step1560]: loss 10.293251
[epoch7, step1561]: loss 14.186285
[epoch7, step1562]: loss 2.243904
[epoch7, step1563]: loss 5.794937
[epoch7, step1564]: loss 17.435472
[epoch7, step1565]: loss 3.374078
[epoch7, step1566]: loss 1.626869
[epoch7, step1567]: loss 1.126325
[epoch7, step1568]: loss 16.023697
[epoch7, step1569]: loss 7.981502
[epoch7, step1570]: loss 4.445894
[epoch7, step1571]: loss 22.274050
[epoch7, step1572]: loss 1.615131
[epoch7, step1573]: loss 1.706075
[epoch7, step1574]: loss 41.313805
[epoch7, step1575]: loss 3.417111
[epoch7, step1576]: loss 3.857205
[epoch7, step1577]: loss 3.327814
[epoch7, step1578]: loss 23.072496
[epoch7, step1579]: loss 2.028761
[epoch7, step1580]: loss 6.846894
[epoch7, step1581]: loss 13.729997
[epoch7, step1582]: loss 2.316606
[epoch7, step1583]: loss 16.292185
[epoch7, step1584]: loss 5.693815
[epoch7, step1585]: loss 29.323050
[epoch7, step1586]: loss 4.924876
[epoch7, step1587]: loss 20.340282
[epoch7, step1588]: loss 5.986246
[epoch7, step1589]: loss 3.431732
[epoch7, step1590]: loss 3.588636
[epoch7, step1591]: loss 4.460819
[epoch7, step1592]: loss 3.104804
[epoch7, step1593]: loss 11.104535
[epoch7, step1594]: loss 8.763816
[epoch7, step1595]: loss 1.854247
[epoch7, step1596]: loss 2.037454
[epoch7, step1597]: loss 6.329681
[epoch7, step1598]: loss 1.439878
[epoch7, step1599]: loss 6.849039
[epoch7, step1600]: loss 6.282288
[epoch7, step1601]: loss 4.948395
[epoch7, step1602]: loss 2.509978
[epoch7, step1603]: loss 4.206896
[epoch7, step1604]: loss 17.033352
[epoch7, step1605]: loss 19.129660
[epoch7, step1606]: loss 3.192371
[epoch7, step1607]: loss 16.289648
[epoch7, step1608]: loss 2.023388
[epoch7, step1609]: loss 19.843374
[epoch7, step1610]: loss 2.141643
[epoch7, step1611]: loss 2.364418
[epoch7, step1612]: loss 7.157024
[epoch7, step1613]: loss 6.070294
[epoch7, step1614]: loss 3.970798
[epoch7, step1615]: loss 2.022222
[epoch7, step1616]: loss 1.978612
[epoch7, step1617]: loss 1.125653
[epoch7, step1618]: loss 7.957136
[epoch7, step1619]: loss 2.382047
[epoch7, step1620]: loss 4.007772
[epoch7, step1621]: loss 6.563764
[epoch7, step1622]: loss 2.769407
[epoch7, step1623]: loss 1.878009
[epoch7, step1624]: loss 1.990953
[epoch7, step1625]: loss 23.097015
[epoch7, step1626]: loss 15.008273
[epoch7, step1627]: loss 3.416669
[epoch7, step1628]: loss 4.314031
[epoch7, step1629]: loss 5.256957
[epoch7, step1630]: loss 1.615224
[epoch7, step1631]: loss 2.093134
[epoch7, step1632]: loss 2.432887
[epoch7, step1633]: loss 3.087623
[epoch7, step1634]: loss 15.056625
[epoch7, step1635]: loss 20.762888
[epoch7, step1636]: loss 18.874828
[epoch7, step1637]: loss 10.095829
[epoch7, step1638]: loss 4.097307
[epoch7, step1639]: loss 1.479539
[epoch7, step1640]: loss 20.540354
[epoch7, step1641]: loss 23.058811
[epoch7, step1642]: loss 2.422862
[epoch7, step1643]: loss 4.463273
[epoch7, step1644]: loss 2.167604
[epoch7, step1645]: loss 2.379601
[epoch7, step1646]: loss 9.400418
[epoch7, step1647]: loss 1.328504
[epoch7, step1648]: loss 3.682173
[epoch7, step1649]: loss 6.150007
[epoch7, step1650]: loss 5.235023
[epoch7, step1651]: loss 6.129522
[epoch7, step1652]: loss 22.116856
[epoch7, step1653]: loss 22.095432
[epoch7, step1654]: loss 5.161880
[epoch7, step1655]: loss 1.793309
[epoch7, step1656]: loss 2.182694
[epoch7, step1657]: loss 17.638098
[epoch7, step1658]: loss 2.644039
[epoch7, step1659]: loss 37.535313
[epoch7, step1660]: loss 4.612653
[epoch7, step1661]: loss 1.800293
[epoch7, step1662]: loss 14.641110
[epoch7, step1663]: loss 1.373844
[epoch7, step1664]: loss 1.789535
[epoch7, step1665]: loss 2.961692
[epoch7, step1666]: loss 19.058956
[epoch7, step1667]: loss 3.853023
[epoch7, step1668]: loss 16.664661
[epoch7, step1669]: loss 5.666344
[epoch7, step1670]: loss 5.586711
[epoch7, step1671]: loss 19.862589
[epoch7, step1672]: loss 12.466950
[epoch7, step1673]: loss 14.995966
[epoch7, step1674]: loss 1.909175
[epoch7, step1675]: loss 4.902676
[epoch7, step1676]: loss 4.612097
[epoch7, step1677]: loss 1.663280
[epoch7, step1678]: loss 18.934586
[epoch7, step1679]: loss 2.095585
[epoch7, step1680]: loss 2.443168
[epoch7, step1681]: loss 2.911722
[epoch7, step1682]: loss 2.302491
[epoch7, step1683]: loss 2.050315
[epoch7, step1684]: loss 22.453587
[epoch7, step1685]: loss 1.877075
[epoch7, step1686]: loss 4.751289
[epoch7, step1687]: loss 1.971362
[epoch7, step1688]: loss 1.542195
[epoch7, step1689]: loss 1.829668
[epoch7, step1690]: loss 1.055172
[epoch7, step1691]: loss 1.649316
[epoch7, step1692]: loss 11.748573
[epoch7, step1693]: loss 4.088927
[epoch7, step1694]: loss 17.692801
[epoch7, step1695]: loss 20.383469
[epoch7, step1696]: loss 2.082354
[epoch7, step1697]: loss 2.270344
[epoch7, step1698]: loss 3.521783
[epoch7, step1699]: loss 2.633435
[epoch7, step1700]: loss 3.770183
[epoch7, step1701]: loss 4.415588
[epoch7, step1702]: loss 2.574794
[epoch7, step1703]: loss 19.515980
[epoch7, step1704]: loss 2.098582
[epoch7, step1705]: loss 3.033413
[epoch7, step1706]: loss 2.193018
[epoch7, step1707]: loss 22.821541
[epoch7, step1708]: loss 1.597239
[epoch7, step1709]: loss 7.126148
[epoch7, step1710]: loss 38.154617
[epoch7, step1711]: loss 4.316715
[epoch7, step1712]: loss 3.237780
[epoch7, step1713]: loss 35.683147
[epoch7, step1714]: loss 15.425412
[epoch7, step1715]: loss 8.655544
[epoch7, step1716]: loss 10.184069
[epoch7, step1717]: loss 35.998291
[epoch7, step1718]: loss 4.891153
[epoch7, step1719]: loss 17.779341
[epoch7, step1720]: loss 1.669528
[epoch7, step1721]: loss 8.750295
[epoch7, step1722]: loss 5.522978
[epoch7, step1723]: loss 3.578932
[epoch7, step1724]: loss 15.446297
[epoch7, step1725]: loss 6.042523
[epoch7, step1726]: loss 3.675835
[epoch7, step1727]: loss 1.937697
[epoch7, step1728]: loss 1.366170
[epoch7, step1729]: loss 3.290411
[epoch7, step1730]: loss 1.734212
[epoch7, step1731]: loss 4.721741
[epoch7, step1732]: loss 3.370390
[epoch7, step1733]: loss 13.334951
[epoch7, step1734]: loss 2.121878
[epoch7, step1735]: loss 1.738241
[epoch7, step1736]: loss 7.086094
[epoch7, step1737]: loss 12.783495
[epoch7, step1738]: loss 10.968873
[epoch7, step1739]: loss 17.868181
[epoch7, step1740]: loss 4.729581
[epoch7, step1741]: loss 3.058814
[epoch7, step1742]: loss 1.814364
[epoch7, step1743]: loss 2.259774
[epoch7, step1744]: loss 3.119453
[epoch7, step1745]: loss 4.744682
[epoch7, step1746]: loss 2.160567
[epoch7, step1747]: loss 3.499153
[epoch7, step1748]: loss 1.625134
[epoch7, step1749]: loss 2.419135
[epoch7, step1750]: loss 16.173050
[epoch7, step1751]: loss 9.187260
[epoch7, step1752]: loss 11.825102
[epoch7, step1753]: loss 10.712532
[epoch7, step1754]: loss 14.651086
[epoch7, step1755]: loss 2.054230
[epoch7, step1756]: loss 35.978806
[epoch7, step1757]: loss 2.047608
[epoch7, step1758]: loss 3.995343
[epoch7, step1759]: loss 1.295909
[epoch7, step1760]: loss 2.334708
[epoch7, step1761]: loss 1.793469
[epoch7, step1762]: loss 20.649874
[epoch7, step1763]: loss 1.983974
[epoch7, step1764]: loss 2.896298
[epoch7, step1765]: loss 1.958339
[epoch7, step1766]: loss 1.396825
[epoch7, step1767]: loss 3.191469
[epoch7, step1768]: loss 2.307579
[epoch7, step1769]: loss 2.006953
[epoch7, step1770]: loss 1.216045
[epoch7, step1771]: loss 23.482395
[epoch7, step1772]: loss 15.364979
[epoch7, step1773]: loss 11.508216
[epoch7, step1774]: loss 19.957611
[epoch7, step1775]: loss 1.613704
[epoch7, step1776]: loss 4.536585
[epoch7, step1777]: loss 1.661332
[epoch7, step1778]: loss 2.476614
[epoch7, step1779]: loss 1.542144
[epoch7, step1780]: loss 7.845111
[epoch7, step1781]: loss 4.356968
[epoch7, step1782]: loss 5.624905
[epoch7, step1783]: loss 21.663689
[epoch7, step1784]: loss 17.376112
[epoch7, step1785]: loss 20.643717
[epoch7, step1786]: loss 3.483271
[epoch7, step1787]: loss 2.520757
[epoch7, step1788]: loss 1.823978
[epoch7, step1789]: loss 5.570667
[epoch7, step1790]: loss 4.400975
[epoch7, step1791]: loss 16.150942
[epoch7, step1792]: loss 24.584415
[epoch7, step1793]: loss 11.155454
[epoch7, step1794]: loss 5.095707
[epoch7, step1795]: loss 2.078605
[epoch7, step1796]: loss 4.394391
[epoch7, step1797]: loss 8.231497
[epoch7, step1798]: loss 2.311554
[epoch7, step1799]: loss 22.799746
[epoch7, step1800]: loss 3.287868
[epoch7, step1801]: loss 3.202566
[epoch7, step1802]: loss 13.344688
[epoch7, step1803]: loss 6.733652
[epoch7, step1804]: loss 2.944390
[epoch7, step1805]: loss 4.861734
[epoch7, step1806]: loss 3.659315
[epoch7, step1807]: loss 17.365717
[epoch7, step1808]: loss 3.725320
[epoch7, step1809]: loss 8.734267
[epoch7, step1810]: loss 4.640181
[epoch7, step1811]: loss 30.955959
[epoch7, step1812]: loss 3.423866
[epoch7, step1813]: loss 5.036734
[epoch7, step1814]: loss 4.590664
[epoch7, step1815]: loss 15.997181
[epoch7, step1816]: loss 3.223289
[epoch7, step1817]: loss 1.879080
[epoch7, step1818]: loss 1.580960
[epoch7, step1819]: loss 37.700787
[epoch7, step1820]: loss 8.140061
[epoch7, step1821]: loss 6.706994
[epoch7, step1822]: loss 24.050724
[epoch7, step1823]: loss 5.869796
[epoch7, step1824]: loss 20.734465
[epoch7, step1825]: loss 11.791553
[epoch7, step1826]: loss 5.035604
[epoch7, step1827]: loss 2.144300
[epoch7, step1828]: loss 44.180283
[epoch7, step1829]: loss 2.275254
[epoch7, step1830]: loss 1.685465
[epoch7, step1831]: loss 2.652362
[epoch7, step1832]: loss 4.583099
[epoch7, step1833]: loss 25.947416
[epoch7, step1834]: loss 10.425357
[epoch7, step1835]: loss 6.615787
[epoch7, step1836]: loss 3.894363
[epoch7, step1837]: loss 25.764061
[epoch7, step1838]: loss 8.376952
[epoch7, step1839]: loss 2.423431
[epoch7, step1840]: loss 19.830868
[epoch7, step1841]: loss 15.083611
[epoch7, step1842]: loss 3.496613
[epoch7, step1843]: loss 2.435228
[epoch7, step1844]: loss 3.568105
[epoch7, step1845]: loss 36.946228
[epoch7, step1846]: loss 1.600626
[epoch7, step1847]: loss 1.019443
[epoch7, step1848]: loss 2.466536
[epoch7, step1849]: loss 10.301637
[epoch7, step1850]: loss 15.078212
[epoch7, step1851]: loss 5.475677
[epoch7, step1852]: loss 6.387398
[epoch7, step1853]: loss 4.018018
[epoch7, step1854]: loss 6.458058
[epoch7, step1855]: loss 2.945857
[epoch7, step1856]: loss 1.817183
[epoch7, step1857]: loss 8.506809
[epoch7, step1858]: loss 2.375511
[epoch7, step1859]: loss 3.621397
[epoch7, step1860]: loss 4.848947
[epoch7, step1861]: loss 1.795034
[epoch7, step1862]: loss 5.041725
[epoch7, step1863]: loss 1.344013
[epoch7, step1864]: loss 1.264348
[epoch7, step1865]: loss 3.057138
[epoch7, step1866]: loss 2.257705
[epoch7, step1867]: loss 2.653471
[epoch7, step1868]: loss 1.626963
[epoch7, step1869]: loss 5.702747
[epoch7, step1870]: loss 5.222404
[epoch7, step1871]: loss 14.494028
[epoch7, step1872]: loss 1.336784
[epoch7, step1873]: loss 4.232381
[epoch7, step1874]: loss 1.800759
[epoch7, step1875]: loss 2.853692
[epoch7, step1876]: loss 2.164016
[epoch7, step1877]: loss 15.899693
[epoch7, step1878]: loss 16.982063
[epoch7, step1879]: loss 1.624529
[epoch7, step1880]: loss 4.997989
[epoch7, step1881]: loss 4.545959
[epoch7, step1882]: loss 3.800845
[epoch7, step1883]: loss 11.007652
[epoch7, step1884]: loss 2.752256
[epoch7, step1885]: loss 4.257284
[epoch7, step1886]: loss 7.135174
[epoch7, step1887]: loss 1.777963
[epoch7, step1888]: loss 8.442154
[epoch7, step1889]: loss 8.258551
[epoch7, step1890]: loss 1.374673
[epoch7, step1891]: loss 3.401408
[epoch7, step1892]: loss 16.609018
[epoch7, step1893]: loss 22.739481
[epoch7, step1894]: loss 2.674742
[epoch7, step1895]: loss 2.965636
[epoch7, step1896]: loss 1.509665
[epoch7, step1897]: loss 3.133156
[epoch7, step1898]: loss 1.385980
[epoch7, step1899]: loss 36.288578
[epoch7, step1900]: loss 1.492529
[epoch7, step1901]: loss 1.915686
[epoch7, step1902]: loss 11.068162
[epoch7, step1903]: loss 1.728930
[epoch7, step1904]: loss 5.884655
[epoch7, step1905]: loss 8.733107
[epoch7, step1906]: loss 3.393374
[epoch7, step1907]: loss 3.060102
[epoch7, step1908]: loss 5.448150
[epoch7, step1909]: loss 9.407371
[epoch7, step1910]: loss 12.152672
[epoch7, step1911]: loss 19.572706
[epoch7, step1912]: loss 2.912335
[epoch7, step1913]: loss 3.468643
[epoch7, step1914]: loss 25.961294
[epoch7, step1915]: loss 2.023483
[epoch7, step1916]: loss 3.060752
[epoch7, step1917]: loss 1.789164
[epoch7, step1918]: loss 3.115347
[epoch7, step1919]: loss 15.295213
[epoch7, step1920]: loss 22.898209
[epoch7, step1921]: loss 6.638181
[epoch7, step1922]: loss 10.554331
[epoch7, step1923]: loss 18.794706
[epoch7, step1924]: loss 2.357751
[epoch7, step1925]: loss 24.551924
[epoch7, step1926]: loss 26.124889
[epoch7, step1927]: loss 3.006097
[epoch7, step1928]: loss 2.471129
[epoch7, step1929]: loss 5.178451
[epoch7, step1930]: loss 2.361493
[epoch7, step1931]: loss 8.401809
[epoch7, step1932]: loss 4.478235
[epoch7, step1933]: loss 5.481344
[epoch7, step1934]: loss 20.656507
[epoch7, step1935]: loss 2.927104
[epoch7, step1936]: loss 13.040379
[epoch7, step1937]: loss 1.686285
[epoch7, step1938]: loss 2.521642
[epoch7, step1939]: loss 1.569623
[epoch7, step1940]: loss 2.950058
[epoch7, step1941]: loss 65.835701
[epoch7, step1942]: loss 2.804529
[epoch7, step1943]: loss 5.117408
[epoch7, step1944]: loss 7.774775
[epoch7, step1945]: loss 1.402008
[epoch7, step1946]: loss 2.922579
[epoch7, step1947]: loss 65.579872
[epoch7, step1948]: loss 0.983483
[epoch7, step1949]: loss 3.898026
[epoch7, step1950]: loss 2.717640
[epoch7, step1951]: loss 4.258597
[epoch7, step1952]: loss 1.820858
[epoch7, step1953]: loss 3.492533
[epoch7, step1954]: loss 2.394558
[epoch7, step1955]: loss 2.777994
[epoch7, step1956]: loss 1.799007
[epoch7, step1957]: loss 5.165359
[epoch7, step1958]: loss 15.559142
[epoch7, step1959]: loss 16.064304
[epoch7, step1960]: loss 4.085243
[epoch7, step1961]: loss 3.294740
[epoch7, step1962]: loss 1.862988
[epoch7, step1963]: loss 18.560785
[epoch7, step1964]: loss 6.788688
[epoch7, step1965]: loss 3.348053
[epoch7, step1966]: loss 7.743762
[epoch7, step1967]: loss 21.671810
[epoch7, step1968]: loss 9.989355
[epoch7, step1969]: loss 2.861799
[epoch7, step1970]: loss 17.157986
[epoch7, step1971]: loss 1.139231
[epoch7, step1972]: loss 4.853128
[epoch7, step1973]: loss 4.524743
[epoch7, step1974]: loss 1.014288
[epoch7, step1975]: loss 20.059055
[epoch7, step1976]: loss 2.147808
[epoch7, step1977]: loss 5.739286
[epoch7, step1978]: loss 9.278641
[epoch7, step1979]: loss 19.040596
[epoch7, step1980]: loss 1.099053
[epoch7, step1981]: loss 1.876812
[epoch7, step1982]: loss 5.498971
[epoch7, step1983]: loss 3.290884
[epoch7, step1984]: loss 6.540218
[epoch7, step1985]: loss 4.563137
[epoch7, step1986]: loss 5.141893
[epoch7, step1987]: loss 11.800291
[epoch7, step1988]: loss 16.863110
[epoch7, step1989]: loss 2.046150
[epoch7, step1990]: loss 1.522530
[epoch7, step1991]: loss 4.156203
[epoch7, step1992]: loss 2.378544
[epoch7, step1993]: loss 18.691235
[epoch7, step1994]: loss 6.733150
[epoch7, step1995]: loss 16.874069
[epoch7, step1996]: loss 10.208693
[epoch7, step1997]: loss 28.869106
[epoch7, step1998]: loss 1.311274
[epoch7, step1999]: loss 17.877974
[epoch7, step2000]: loss 44.105007
[epoch7, step2001]: loss 2.908529
[epoch7, step2002]: loss 1.443252
[epoch7, step2003]: loss 3.453118
[epoch7, step2004]: loss 6.455975
[epoch7, step2005]: loss 9.378942
[epoch7, step2006]: loss 3.923868
[epoch7, step2007]: loss 7.383246
[epoch7, step2008]: loss 12.686525
[epoch7, step2009]: loss 2.243832
[epoch7, step2010]: loss 3.208278
[epoch7, step2011]: loss 35.232624
[epoch7, step2012]: loss 9.461499
[epoch7, step2013]: loss 3.689358
[epoch7, step2014]: loss 5.743482
[epoch7, step2015]: loss 16.773954
[epoch7, step2016]: loss 5.084671
[epoch7, step2017]: loss 1.443250
[epoch7, step2018]: loss 1.529295
[epoch7, step2019]: loss 3.091476
[epoch7, step2020]: loss 43.318401
[epoch7, step2021]: loss 2.007895
[epoch7, step2022]: loss 14.935786
[epoch7, step2023]: loss 21.696318
[epoch7, step2024]: loss 3.692545
[epoch7, step2025]: loss 3.469074
[epoch7, step2026]: loss 12.436543
[epoch7, step2027]: loss 1.457015
[epoch7, step2028]: loss 3.572291
[epoch7, step2029]: loss 2.934758
[epoch7, step2030]: loss 2.596879
[epoch7, step2031]: loss 21.878433
[epoch7, step2032]: loss 3.968242
[epoch7, step2033]: loss 7.061617
[epoch7, step2034]: loss 2.589886
[epoch7, step2035]: loss 7.210371
[epoch7, step2036]: loss 3.911539
[epoch7, step2037]: loss 2.126544
[epoch7, step2038]: loss 6.134433
[epoch7, step2039]: loss 1.688641
[epoch7, step2040]: loss 3.353328
[epoch7, step2041]: loss 4.513077
[epoch7, step2042]: loss 22.824541
[epoch7, step2043]: loss 11.756374
[epoch7, step2044]: loss 1.793521
[epoch7, step2045]: loss 18.286541
[epoch7, step2046]: loss 4.232631
[epoch7, step2047]: loss 17.512285
[epoch7, step2048]: loss 1.223066
[epoch7, step2049]: loss 5.288993
[epoch7, step2050]: loss 7.402218
[epoch7, step2051]: loss 7.061539
[epoch7, step2052]: loss 1.499464
[epoch7, step2053]: loss 4.789392
[epoch7, step2054]: loss 3.188484
[epoch7, step2055]: loss 2.633905
[epoch7, step2056]: loss 20.588955
[epoch7, step2057]: loss 21.372097
[epoch7, step2058]: loss 1.129709
[epoch7, step2059]: loss 1.113676
[epoch7, step2060]: loss 1.784645
[epoch7, step2061]: loss 20.025105
[epoch7, step2062]: loss 3.453853
[epoch7, step2063]: loss 5.517787
[epoch7, step2064]: loss 3.067881
[epoch7, step2065]: loss 5.795444
[epoch7, step2066]: loss 2.983385
[epoch7, step2067]: loss 4.819154
[epoch7, step2068]: loss 2.300181
[epoch7, step2069]: loss 16.784483
[epoch7, step2070]: loss 4.285385
[epoch7, step2071]: loss 17.673531
[epoch7, step2072]: loss 1.663381
[epoch7, step2073]: loss 1.834205
[epoch7, step2074]: loss 1.511154
[epoch7, step2075]: loss 11.445646
[epoch7, step2076]: loss 3.727475
[epoch7, step2077]: loss 2.193009
[epoch7, step2078]: loss 25.479454
[epoch7, step2079]: loss 1.737336
[epoch7, step2080]: loss 17.559792
[epoch7, step2081]: loss 8.242288
[epoch7, step2082]: loss 4.228819
[epoch7, step2083]: loss 15.485204
[epoch7, step2084]: loss 1.211532
[epoch7, step2085]: loss 17.441927
[epoch7, step2086]: loss 3.931220
[epoch7, step2087]: loss 39.010693
[epoch7, step2088]: loss 4.407155
[epoch7, step2089]: loss 3.557684
[epoch7, step2090]: loss 22.521738
[epoch7, step2091]: loss 6.086702
[epoch7, step2092]: loss 12.841387
[epoch7, step2093]: loss 3.325620
[epoch7, step2094]: loss 2.373367
[epoch7, step2095]: loss 2.339247
[epoch7, step2096]: loss 2.104019
[epoch7, step2097]: loss 1.443996
[epoch7, step2098]: loss 1.668411
[epoch7, step2099]: loss 7.754019
[epoch7, step2100]: loss 4.547594
[epoch7, step2101]: loss 1.157037
[epoch7, step2102]: loss 17.013199
[epoch7, step2103]: loss 5.854796
[epoch7, step2104]: loss 2.315951
[epoch7, step2105]: loss 1.463605
[epoch7, step2106]: loss 3.148637
[epoch7, step2107]: loss 1.947118
[epoch7, step2108]: loss 1.444874
[epoch7, step2109]: loss 14.141212
[epoch7, step2110]: loss 32.419735
[epoch7, step2111]: loss 10.555226
[epoch7, step2112]: loss 3.459583
[epoch7, step2113]: loss 15.595445
[epoch7, step2114]: loss 9.199768
[epoch7, step2115]: loss 4.959174
[epoch7, step2116]: loss 2.545727
[epoch7, step2117]: loss 2.944479
[epoch7, step2118]: loss 2.443987
[epoch7, step2119]: loss 1.771339
[epoch7, step2120]: loss 3.469903
[epoch7, step2121]: loss 2.137049
[epoch7, step2122]: loss 23.450375
[epoch7, step2123]: loss 6.372758
[epoch7, step2124]: loss 4.797589
[epoch7, step2125]: loss 23.364965
[epoch7, step2126]: loss 23.702755
[epoch7, step2127]: loss 4.883397
[epoch7, step2128]: loss 1.732054
[epoch7, step2129]: loss 6.858838
[epoch7, step2130]: loss 4.284491
[epoch7, step2131]: loss 2.513062
[epoch7, step2132]: loss 4.400575
[epoch7, step2133]: loss 1.867227
[epoch7, step2134]: loss 5.333057
[epoch7, step2135]: loss 2.902593
[epoch7, step2136]: loss 18.127701
[epoch7, step2137]: loss 3.132893
[epoch7, step2138]: loss 1.661068
[epoch7, step2139]: loss 18.974760
[epoch7, step2140]: loss 9.981300
[epoch7, step2141]: loss 22.847696
[epoch7, step2142]: loss 6.212468
[epoch7, step2143]: loss 3.485471
[epoch7, step2144]: loss 11.641855
[epoch7, step2145]: loss 2.275469
[epoch7, step2146]: loss 3.829720
[epoch7, step2147]: loss 1.216777
[epoch7, step2148]: loss 1.468608
[epoch7, step2149]: loss 1.608314
[epoch7, step2150]: loss 1.169863
[epoch7, step2151]: loss 5.660897
[epoch7, step2152]: loss 13.199720
[epoch7, step2153]: loss 6.694816
[epoch7, step2154]: loss 2.529217
[epoch7, step2155]: loss 2.259954
[epoch7, step2156]: loss 5.031088
[epoch7, step2157]: loss 0.847236
[epoch7, step2158]: loss 3.980916
[epoch7, step2159]: loss 9.244087
[epoch7, step2160]: loss 24.911030
[epoch7, step2161]: loss 18.993830
[epoch7, step2162]: loss 2.918924
[epoch7, step2163]: loss 14.371031
[epoch7, step2164]: loss 17.309315
[epoch7, step2165]: loss 3.086022
[epoch7, step2166]: loss 3.614468
[epoch7, step2167]: loss 3.954796
[epoch7, step2168]: loss 4.966858
[epoch7, step2169]: loss 19.976704
[epoch7, step2170]: loss 24.413975
[epoch7, step2171]: loss 25.059118
[epoch7, step2172]: loss 2.586750
[epoch7, step2173]: loss 16.108803
[epoch7, step2174]: loss 1.130409
[epoch7, step2175]: loss 8.673338
[epoch7, step2176]: loss 4.491635
[epoch7, step2177]: loss 1.889297
[epoch7, step2178]: loss 3.106095
[epoch7, step2179]: loss 5.335954
[epoch7, step2180]: loss 20.902107
[epoch7, step2181]: loss 17.655993
[epoch7, step2182]: loss 3.789305
[epoch7, step2183]: loss 41.563484
[epoch7, step2184]: loss 3.362174
[epoch7, step2185]: loss 1.764630
[epoch7, step2186]: loss 34.077656
[epoch7, step2187]: loss 2.775033
[epoch7, step2188]: loss 32.958595
[epoch7, step2189]: loss 2.314136
[epoch7, step2190]: loss 35.950436
[epoch7, step2191]: loss 7.456571
[epoch7, step2192]: loss 2.887136
[epoch7, step2193]: loss 2.118738
[epoch7, step2194]: loss 10.295534
[epoch7, step2195]: loss 2.088148
[epoch7, step2196]: loss 3.941210
[epoch7, step2197]: loss 1.380361
[epoch7, step2198]: loss 53.391434
[epoch7, step2199]: loss 7.337178
[epoch7, step2200]: loss 4.531888
[epoch7, step2201]: loss 4.203620
[epoch7, step2202]: loss 7.884665
[epoch7, step2203]: loss 3.570770
[epoch7, step2204]: loss 2.967583
[epoch7, step2205]: loss 3.786708
[epoch7, step2206]: loss 1.114021
[epoch7, step2207]: loss 1.870523
[epoch7, step2208]: loss 4.848941
[epoch7, step2209]: loss 2.538245
[epoch7, step2210]: loss 18.701599
[epoch7, step2211]: loss 2.003146
[epoch7, step2212]: loss 16.950367
[epoch7, step2213]: loss 21.627571
[epoch7, step2214]: loss 1.779469
[epoch7, step2215]: loss 3.272294
[epoch7, step2216]: loss 26.863491
[epoch7, step2217]: loss 3.016279
[epoch7, step2218]: loss 3.467164
[epoch7, step2219]: loss 16.296803
[epoch7, step2220]: loss 3.105161
[epoch7, step2221]: loss 7.992532
[epoch7, step2222]: loss 4.494417
[epoch7, step2223]: loss 17.188774
[epoch7, step2224]: loss 2.678719
[epoch7, step2225]: loss 12.880275
[epoch7, step2226]: loss 15.955585
[epoch7, step2227]: loss 3.067408
[epoch7, step2228]: loss 3.925457
[epoch7, step2229]: loss 1.532820
[epoch7, step2230]: loss 3.190064
[epoch7, step2231]: loss 1.232884
[epoch7, step2232]: loss 1.654770
[epoch7, step2233]: loss 2.013570
[epoch7, step2234]: loss 18.294336
[epoch7, step2235]: loss 3.267855
[epoch7, step2236]: loss 20.134361
[epoch7, step2237]: loss 6.345287
[epoch7, step2238]: loss 3.240997
[epoch7, step2239]: loss 20.040274
[epoch7, step2240]: loss 2.285569
[epoch7, step2241]: loss 24.670559
[epoch7, step2242]: loss 2.009746
[epoch7, step2243]: loss 4.497058
[epoch7, step2244]: loss 14.184272
[epoch7, step2245]: loss 2.561401
[epoch7, step2246]: loss 3.992832
[epoch7, step2247]: loss 10.994356
[epoch7, step2248]: loss 8.279639
[epoch7, step2249]: loss 2.504332
[epoch7, step2250]: loss 4.544158
[epoch7, step2251]: loss 22.211170
[epoch7, step2252]: loss 21.619358
[epoch7, step2253]: loss 1.439433
[epoch7, step2254]: loss 8.652429
[epoch7, step2255]: loss 2.597247
[epoch7, step2256]: loss 1.942244
[epoch7, step2257]: loss 8.787216
[epoch7, step2258]: loss 5.688237
[epoch7, step2259]: loss 2.069176
[epoch7, step2260]: loss 3.945295
[epoch7, step2261]: loss 1.021587
[epoch7, step2262]: loss 3.336234
[epoch7, step2263]: loss 2.176317
[epoch7, step2264]: loss 24.053612
[epoch7, step2265]: loss 8.676761
[epoch7, step2266]: loss 2.750825
[epoch7, step2267]: loss 8.818995
[epoch7, step2268]: loss 1.523846
[epoch7, step2269]: loss 2.783003
[epoch7, step2270]: loss 4.125100
[epoch7, step2271]: loss 3.508460
[epoch7, step2272]: loss 8.209559
[epoch7, step2273]: loss 1.319293
[epoch7, step2274]: loss 4.164518
[epoch7, step2275]: loss 2.180059
[epoch7, step2276]: loss 1.824422
[epoch7, step2277]: loss 2.299332
[epoch7, step2278]: loss 2.818707
[epoch7, step2279]: loss 4.787029
[epoch7, step2280]: loss 10.386707
[epoch7, step2281]: loss 17.208208
[epoch7, step2282]: loss 6.478147
[epoch7, step2283]: loss 2.875804
[epoch7, step2284]: loss 5.503189
[epoch7, step2285]: loss 6.942740
[epoch7, step2286]: loss 1.884809
[epoch7, step2287]: loss 1.409743
[epoch7, step2288]: loss 4.163118
[epoch7, step2289]: loss 1.462388
[epoch7, step2290]: loss 3.325970
[epoch7, step2291]: loss 6.180897
[epoch7, step2292]: loss 14.097111
[epoch7, step2293]: loss 23.898760
[epoch7, step2294]: loss 9.807214
[epoch7, step2295]: loss 8.297007
[epoch7, step2296]: loss 4.626092
[epoch7, step2297]: loss 7.361431
[epoch7, step2298]: loss 9.252571
[epoch7, step2299]: loss 5.636894
[epoch7, step2300]: loss 2.041336
[epoch7, step2301]: loss 1.281470
[epoch7, step2302]: loss 6.316409
[epoch7, step2303]: loss 4.960037
[epoch7, step2304]: loss 7.175404
[epoch7, step2305]: loss 4.152211
[epoch7, step2306]: loss 6.149915
[epoch7, step2307]: loss 8.407598
[epoch7, step2308]: loss 19.985792
[epoch7, step2309]: loss 5.032841
[epoch7, step2310]: loss 2.745723
[epoch7, step2311]: loss 2.295003
[epoch7, step2312]: loss 3.494661
[epoch7, step2313]: loss 16.813049
[epoch7, step2314]: loss 14.105804
[epoch7, step2315]: loss 15.098704
[epoch7, step2316]: loss 12.725424
[epoch7, step2317]: loss 7.880490
[epoch7, step2318]: loss 17.595947
[epoch7, step2319]: loss 3.191280
[epoch7, step2320]: loss 4.694576
[epoch7, step2321]: loss 3.404915
[epoch7, step2322]: loss 2.439999
[epoch7, step2323]: loss 3.278251
[epoch7, step2324]: loss 3.721584
[epoch7, step2325]: loss 1.710052
[epoch7, step2326]: loss 13.861799
[epoch7, step2327]: loss 2.546631
[epoch7, step2328]: loss 4.580351
[epoch7, step2329]: loss 1.683335
[epoch7, step2330]: loss 1.616794
[epoch7, step2331]: loss 2.472589
[epoch7, step2332]: loss 3.023675
[epoch7, step2333]: loss 2.259279
[epoch7, step2334]: loss 5.296116
[epoch7, step2335]: loss 2.093022
[epoch7, step2336]: loss 1.944343
[epoch7, step2337]: loss 2.151151
[epoch7, step2338]: loss 15.830615
[epoch7, step2339]: loss 19.449564
[epoch7, step2340]: loss 5.876690
[epoch7, step2341]: loss 2.744525
[epoch7, step2342]: loss 5.707637
[epoch7, step2343]: loss 4.407808
[epoch7, step2344]: loss 1.622302
[epoch7, step2345]: loss 16.305315
[epoch7, step2346]: loss 48.502567
[epoch7, step2347]: loss 6.169479
[epoch7, step2348]: loss 2.500960
[epoch7, step2349]: loss 2.597921
[epoch7, step2350]: loss 2.213841
[epoch7, step2351]: loss 5.178883
[epoch7, step2352]: loss 7.875552
[epoch7, step2353]: loss 1.055565
[epoch7, step2354]: loss 5.681727
[epoch7, step2355]: loss 7.995579
[epoch7, step2356]: loss 3.300680
[epoch7, step2357]: loss 1.687567
[epoch7, step2358]: loss 0.994601
[epoch7, step2359]: loss 1.231133
[epoch7, step2360]: loss 5.394616
[epoch7, step2361]: loss 2.472221
[epoch7, step2362]: loss 2.190999
[epoch7, step2363]: loss 15.779708
[epoch7, step2364]: loss 33.692955
[epoch7, step2365]: loss 16.460934
[epoch7, step2366]: loss 2.418706
[epoch7, step2367]: loss 16.876490
[epoch7, step2368]: loss 2.818460
[epoch7, step2369]: loss 4.341911
[epoch7, step2370]: loss 25.242266
[epoch7, step2371]: loss 2.354362
[epoch7, step2372]: loss 5.393692
[epoch7, step2373]: loss 3.091608
[epoch7, step2374]: loss 1.916707
[epoch7, step2375]: loss 6.666864
[epoch7, step2376]: loss 3.040731
[epoch7, step2377]: loss 1.343801
[epoch7, step2378]: loss 2.079591
[epoch7, step2379]: loss 2.133054
[epoch7, step2380]: loss 3.155893
[epoch7, step2381]: loss 31.655928
[epoch7, step2382]: loss 1.473238
[epoch7, step2383]: loss 29.245224
[epoch7, step2384]: loss 3.271873
[epoch7, step2385]: loss 7.274121
[epoch7, step2386]: loss 4.153269
[epoch7, step2387]: loss 19.772934
[epoch7, step2388]: loss 18.527147
[epoch7, step2389]: loss 19.698950
[epoch7, step2390]: loss 1.857005
[epoch7, step2391]: loss 6.412666
[epoch7, step2392]: loss 2.235775
[epoch7, step2393]: loss 1.808202
[epoch7, step2394]: loss 23.357208
[epoch7, step2395]: loss 22.209236
[epoch7, step2396]: loss 2.288867
[epoch7, step2397]: loss 1.782434
[epoch7, step2398]: loss 19.898136
[epoch7, step2399]: loss 1.969273
[epoch7, step2400]: loss 13.767395
[epoch7, step2401]: loss 2.374780
[epoch7, step2402]: loss 1.587581
[epoch7, step2403]: loss 2.904294
[epoch7, step2404]: loss 2.290475
[epoch7, step2405]: loss 5.308010
[epoch7, step2406]: loss 19.918518
[epoch7, step2407]: loss 23.937412
[epoch7, step2408]: loss 2.938536
[epoch7, step2409]: loss 2.736117
[epoch7, step2410]: loss 8.304335
[epoch7, step2411]: loss 6.747988
[epoch7, step2412]: loss 2.177622
[epoch7, step2413]: loss 1.763281
[epoch7, step2414]: loss 4.286938
[epoch7, step2415]: loss 6.922271
[epoch7, step2416]: loss 5.620725
[epoch7, step2417]: loss 2.773345
[epoch7, step2418]: loss 3.051079
[epoch7, step2419]: loss 13.568903
[epoch7, step2420]: loss 3.230623
[epoch7, step2421]: loss 15.990496
[epoch7, step2422]: loss 0.977991
[epoch7, step2423]: loss 19.726227
[epoch7, step2424]: loss 27.196178
[epoch7, step2425]: loss 4.165579
[epoch7, step2426]: loss 16.919434
[epoch7, step2427]: loss 3.489832
[epoch7, step2428]: loss 3.075439
[epoch7, step2429]: loss 1.570338
[epoch7, step2430]: loss 3.868763
[epoch7, step2431]: loss 16.396902
[epoch7, step2432]: loss 14.896164
[epoch7, step2433]: loss 21.202248
[epoch7, step2434]: loss 13.546114
[epoch7, step2435]: loss 3.211709
[epoch7, step2436]: loss 4.204776
[epoch7, step2437]: loss 3.644287
[epoch7, step2438]: loss 6.188485
[epoch7, step2439]: loss 7.463043
[epoch7, step2440]: loss 16.245605
[epoch7, step2441]: loss 6.374640
[epoch7, step2442]: loss 17.744549
[epoch7, step2443]: loss 4.090914
[epoch7, step2444]: loss 2.162432
[epoch7, step2445]: loss 6.036795
[epoch7, step2446]: loss 3.492959
[epoch7, step2447]: loss 1.194701
[epoch7, step2448]: loss 12.838864
[epoch7, step2449]: loss 1.831204
[epoch7, step2450]: loss 11.353621
[epoch7, step2451]: loss 1.801332
[epoch7, step2452]: loss 2.001944
[epoch7, step2453]: loss 6.123685
[epoch7, step2454]: loss 5.092782
[epoch7, step2455]: loss 2.269449
[epoch7, step2456]: loss 16.910976
[epoch7, step2457]: loss 32.150642
[epoch7, step2458]: loss 20.964121
[epoch7, step2459]: loss 6.963649
[epoch7, step2460]: loss 2.995111
[epoch7, step2461]: loss 2.340591
[epoch7, step2462]: loss 19.608829
[epoch7, step2463]: loss 17.002748
[epoch7, step2464]: loss 19.147974
[epoch7, step2465]: loss 2.499557
[epoch7, step2466]: loss 1.418292
[epoch7, step2467]: loss 3.918483
[epoch7, step2468]: loss 5.491459
[epoch7, step2469]: loss 3.697500
[epoch7, step2470]: loss 1.444392
[epoch7, step2471]: loss 3.701072
[epoch7, step2472]: loss 1.866030
[epoch7, step2473]: loss 1.646597
[epoch7, step2474]: loss 7.157550
[epoch7, step2475]: loss 8.143610
[epoch7, step2476]: loss 1.556663
[epoch7, step2477]: loss 1.529796
[epoch7, step2478]: loss 21.149759
[epoch7, step2479]: loss 8.075130
[epoch7, step2480]: loss 2.226430
[epoch7, step2481]: loss 2.532090
[epoch7, step2482]: loss 4.522032
[epoch7, step2483]: loss 19.874050
[epoch7, step2484]: loss 2.938839
[epoch7, step2485]: loss 2.360237
[epoch7, step2486]: loss 4.324103
[epoch7, step2487]: loss 2.610598
[epoch7, step2488]: loss 1.121399
[epoch7, step2489]: loss 1.310904
[epoch7, step2490]: loss 1.664577
[epoch7, step2491]: loss 1.945798
[epoch7, step2492]: loss 1.685251
[epoch7, step2493]: loss 3.053210
[epoch7, step2494]: loss 5.327260
[epoch7, step2495]: loss 2.197471
[epoch7, step2496]: loss 2.160225
[epoch7, step2497]: loss 9.181430
[epoch7, step2498]: loss 18.864279
[epoch7, step2499]: loss 1.688374
[epoch7, step2500]: loss 1.182635
[epoch7, step2501]: loss 32.206497
[epoch7, step2502]: loss 3.009618
[epoch7, step2503]: loss 6.132189
[epoch7, step2504]: loss 1.485822
[epoch7, step2505]: loss 14.934645
[epoch7, step2506]: loss 3.149895
[epoch7, step2507]: loss 10.486522
[epoch7, step2508]: loss 48.018242
[epoch7, step2509]: loss 4.678447
[epoch7, step2510]: loss 23.553658
[epoch7, step2511]: loss 5.208060
[epoch7, step2512]: loss 4.839598
[epoch7, step2513]: loss 27.869261
[epoch7, step2514]: loss 1.691066
[epoch7, step2515]: loss 2.534194
[epoch7, step2516]: loss 10.546579
[epoch7, step2517]: loss 4.090346
[epoch7, step2518]: loss 4.075796
[epoch7, step2519]: loss 2.022687
[epoch7, step2520]: loss 30.371979
[epoch7, step2521]: loss 5.283092
[epoch7, step2522]: loss 1.829192
[epoch7, step2523]: loss 20.763309
[epoch7, step2524]: loss 2.734017
[epoch7, step2525]: loss 17.938408
[epoch7, step2526]: loss 16.069094
[epoch7, step2527]: loss 3.042275
[epoch7, step2528]: loss 22.817186
[epoch7, step2529]: loss 10.313482
[epoch7, step2530]: loss 2.074588
[epoch7, step2531]: loss 2.089234
[epoch7, step2532]: loss 3.611329
[epoch7, step2533]: loss 19.116411
[epoch7, step2534]: loss 6.852122
[epoch7, step2535]: loss 1.892310
[epoch7, step2536]: loss 5.434921
[epoch7, step2537]: loss 5.628767
[epoch7, step2538]: loss 2.217896
[epoch7, step2539]: loss 11.634993
[epoch7, step2540]: loss 15.182628
[epoch7, step2541]: loss 4.731320
[epoch7, step2542]: loss 6.434532
[epoch7, step2543]: loss 2.420871
[epoch7, step2544]: loss 6.676208
[epoch7, step2545]: loss 7.309843
[epoch7, step2546]: loss 10.049391
[epoch7, step2547]: loss 30.246284
[epoch7, step2548]: loss 1.381679
[epoch7, step2549]: loss 1.463813
[epoch7, step2550]: loss 8.743476
[epoch7, step2551]: loss 2.528496
[epoch7, step2552]: loss 2.631217
[epoch7, step2553]: loss 14.648434
[epoch7, step2554]: loss 19.034094
[epoch7, step2555]: loss 1.946887
[epoch7, step2556]: loss 18.619183
[epoch7, step2557]: loss 1.116647
[epoch7, step2558]: loss 2.389187
[epoch7, step2559]: loss 18.870033
[epoch7, step2560]: loss 3.617797
[epoch7, step2561]: loss 1.648456
[epoch7, step2562]: loss 2.180604
[epoch7, step2563]: loss 11.922586
[epoch7, step2564]: loss 1.303703
[epoch7, step2565]: loss 4.737839
[epoch7, step2566]: loss 16.299227
[epoch7, step2567]: loss 20.210024
[epoch7, step2568]: loss 1.556957
[epoch7, step2569]: loss 23.225456
[epoch7, step2570]: loss 9.826111
[epoch7, step2571]: loss 18.096243
[epoch7, step2572]: loss 3.080563
[epoch7, step2573]: loss 2.191222
[epoch7, step2574]: loss 3.570028
[epoch7, step2575]: loss 5.998494
[epoch7, step2576]: loss 5.166249
[epoch7, step2577]: loss 2.028543
[epoch7, step2578]: loss 1.605646
[epoch7, step2579]: loss 1.753895
[epoch7, step2580]: loss 3.281109
[epoch7, step2581]: loss 4.950834
[epoch7, step2582]: loss 13.344967
[epoch7, step2583]: loss 1.947997
[epoch7, step2584]: loss 5.790491
[epoch7, step2585]: loss 7.101554
[epoch7, step2586]: loss 14.641636
[epoch7, step2587]: loss 19.969545
[epoch7, step2588]: loss 7.269509
[epoch7, step2589]: loss 20.632051
[epoch7, step2590]: loss 7.564867
[epoch7, step2591]: loss 1.093133
[epoch7, step2592]: loss 2.847586
[epoch7, step2593]: loss 2.007913
[epoch7, step2594]: loss 3.061808
[epoch7, step2595]: loss 3.760130
[epoch7, step2596]: loss 18.031040
[epoch7, step2597]: loss 4.511559
[epoch7, step2598]: loss 7.792982
[epoch7, step2599]: loss 11.724694
[epoch7, step2600]: loss 7.125815
[epoch7, step2601]: loss 13.042959
[epoch7, step2602]: loss 1.855708
[epoch7, step2603]: loss 19.604053
[epoch7, step2604]: loss 2.368955
[epoch7, step2605]: loss 22.873215
[epoch7, step2606]: loss 1.824333
[epoch7, step2607]: loss 3.707494
[epoch7, step2608]: loss 3.921769
[epoch7, step2609]: loss 7.514081
[epoch7, step2610]: loss 2.116675
[epoch7, step2611]: loss 16.290064
[epoch7, step2612]: loss 1.977667
[epoch7, step2613]: loss 15.870229
[epoch7, step2614]: loss 2.800056
[epoch7, step2615]: loss 5.194516
[epoch7, step2616]: loss 4.726559
[epoch7, step2617]: loss 18.673010
[epoch7, step2618]: loss 1.311136
[epoch7, step2619]: loss 1.886295
[epoch7, step2620]: loss 1.582475
[epoch7, step2621]: loss 4.573679
[epoch7, step2622]: loss 2.402859
[epoch7, step2623]: loss 1.700052
[epoch7, step2624]: loss 3.324983
[epoch7, step2625]: loss 4.325319
[epoch7, step2626]: loss 17.826990
[epoch7, step2627]: loss 12.592007
[epoch7, step2628]: loss 4.907139
[epoch7, step2629]: loss 1.960797
[epoch7, step2630]: loss 30.938709
[epoch7, step2631]: loss 2.625117
[epoch7, step2632]: loss 2.490585
[epoch7, step2633]: loss 5.232764
[epoch7, step2634]: loss 1.922891
[epoch7, step2635]: loss 2.200556
[epoch7, step2636]: loss 3.932594
[epoch7, step2637]: loss 5.822814
[epoch7, step2638]: loss 15.572314
[epoch7, step2639]: loss 3.763896
[epoch7, step2640]: loss 6.004486
[epoch7, step2641]: loss 2.031612
[epoch7, step2642]: loss 32.901844
[epoch7, step2643]: loss 9.015738
[epoch7, step2644]: loss 3.972990
[epoch7, step2645]: loss 1.365959
[epoch7, step2646]: loss 2.396250
[epoch7, step2647]: loss 6.997165
[epoch7, step2648]: loss 3.241999
[epoch7, step2649]: loss 2.735356
[epoch7, step2650]: loss 5.268220
[epoch7, step2651]: loss 5.640646
[epoch7, step2652]: loss 3.956394
[epoch7, step2653]: loss 5.921499
[epoch7, step2654]: loss 20.993786
[epoch7, step2655]: loss 1.037387
[epoch7, step2656]: loss 2.451158
[epoch7, step2657]: loss 11.496717
[epoch7, step2658]: loss 2.289738
[epoch7, step2659]: loss 6.417381
[epoch7, step2660]: loss 2.301844
[epoch7, step2661]: loss 2.439372
[epoch7, step2662]: loss 17.997139
[epoch7, step2663]: loss 2.866929
[epoch7, step2664]: loss 1.092574
[epoch7, step2665]: loss 10.477300
[epoch7, step2666]: loss 34.387119
[epoch7, step2667]: loss 2.022991
[epoch7, step2668]: loss 2.070265
[epoch7, step2669]: loss 3.314611
[epoch7, step2670]: loss 2.102968
[epoch7, step2671]: loss 1.959383
[epoch7, step2672]: loss 6.477862
[epoch7, step2673]: loss 21.322857
[epoch7, step2674]: loss 6.132032
[epoch7, step2675]: loss 2.987588
[epoch7, step2676]: loss 14.933816
[epoch7, step2677]: loss 25.067696
[epoch7, step2678]: loss 3.677216
[epoch7, step2679]: loss 19.274549
[epoch7, step2680]: loss 3.785488
[epoch7, step2681]: loss 3.387988
[epoch7, step2682]: loss 14.982202
[epoch7, step2683]: loss 4.197713
[epoch7, step2684]: loss 13.222577
[epoch7, step2685]: loss 6.516601
[epoch7, step2686]: loss 1.508938
[epoch7, step2687]: loss 2.090233
[epoch7, step2688]: loss 1.504273
[epoch7, step2689]: loss 1.297198
[epoch7, step2690]: loss 13.290323
[epoch7, step2691]: loss 8.103079
[epoch7, step2692]: loss 1.430717
[epoch7, step2693]: loss 5.564665
[epoch7, step2694]: loss 4.620619
[epoch7, step2695]: loss 3.067651
[epoch7, step2696]: loss 34.173717
[epoch7, step2697]: loss 2.255778
[epoch7, step2698]: loss 2.192124
[epoch7, step2699]: loss 5.391734
[epoch7, step2700]: loss 5.262401
[epoch7, step2701]: loss 4.565363
[epoch7, step2702]: loss 1.088792
[epoch7, step2703]: loss 5.622321
[epoch7, step2704]: loss 3.661705
[epoch7, step2705]: loss 1.856084
[epoch7, step2706]: loss 22.711802
[epoch7, step2707]: loss 7.491342
[epoch7, step2708]: loss 1.394414
[epoch7, step2709]: loss 6.178989
[epoch7, step2710]: loss 2.356824
[epoch7, step2711]: loss 22.649351
[epoch7, step2712]: loss 27.958870
[epoch7, step2713]: loss 2.414553
[epoch7, step2714]: loss 4.909081
[epoch7, step2715]: loss 1.737402
[epoch7, step2716]: loss 1.343547
[epoch7, step2717]: loss 1.983220
[epoch7, step2718]: loss 21.645548
[epoch7, step2719]: loss 22.777582
[epoch7, step2720]: loss 13.834328
[epoch7, step2721]: loss 2.051177
[epoch7, step2722]: loss 4.018933
[epoch7, step2723]: loss 7.211659
[epoch7, step2724]: loss 1.342139
[epoch7, step2725]: loss 1.153851
[epoch7, step2726]: loss 22.218554
[epoch7, step2727]: loss 14.898205
[epoch7, step2728]: loss 1.528196
[epoch7, step2729]: loss 4.088495
[epoch7, step2730]: loss 2.041940
[epoch7, step2731]: loss 1.144760
[epoch7, step2732]: loss 5.631021
[epoch7, step2733]: loss 2.641914
[epoch7, step2734]: loss 12.878710
[epoch7, step2735]: loss 1.764648
[epoch7, step2736]: loss 1.260593
[epoch7, step2737]: loss 1.267232
[epoch7, step2738]: loss 14.464343
[epoch7, step2739]: loss 4.557611
[epoch7, step2740]: loss 1.185479
[epoch7, step2741]: loss 9.319727
[epoch7, step2742]: loss 16.428045
[epoch7, step2743]: loss 5.752400
[epoch7, step2744]: loss 1.252319
[epoch7, step2745]: loss 4.704857
[epoch7, step2746]: loss 7.218070
[epoch7, step2747]: loss 2.115326
[epoch7, step2748]: loss 2.869143
[epoch7, step2749]: loss 16.436687
[epoch7, step2750]: loss 1.570789
[epoch7, step2751]: loss 4.976277
[epoch7, step2752]: loss 2.330268
[epoch7, step2753]: loss 1.126829
[epoch7, step2754]: loss 6.356283
[epoch7, step2755]: loss 18.868290
[epoch7, step2756]: loss 5.282364
[epoch7, step2757]: loss 4.402865
[epoch7, step2758]: loss 1.606855
[epoch7, step2759]: loss 44.561695
[epoch7, step2760]: loss 2.021540
[epoch7, step2761]: loss 14.754191
[epoch7, step2762]: loss 4.810566
[epoch7, step2763]: loss 4.815700
[epoch7, step2764]: loss 3.551184
[epoch7, step2765]: loss 17.193880
[epoch7, step2766]: loss 1.093730
[epoch7, step2767]: loss 2.733562
[epoch7, step2768]: loss 4.737154
[epoch7, step2769]: loss 15.357903
[epoch7, step2770]: loss 1.263086
[epoch7, step2771]: loss 6.132454
[epoch7, step2772]: loss 2.026090
[epoch7, step2773]: loss 14.710640
[epoch7, step2774]: loss 2.586438
[epoch7, step2775]: loss 17.922762
[epoch7, step2776]: loss 6.283022
[epoch7, step2777]: loss 3.798373
[epoch7, step2778]: loss 3.587571
[epoch7, step2779]: loss 2.136299
[epoch7, step2780]: loss 1.258358
[epoch7, step2781]: loss 1.933944
[epoch7, step2782]: loss 2.525248
[epoch7, step2783]: loss 1.340911
[epoch7, step2784]: loss 3.096155
[epoch7, step2785]: loss 7.096589
[epoch7, step2786]: loss 9.326298
[epoch7, step2787]: loss 16.612526
[epoch7, step2788]: loss 3.875603
[epoch7, step2789]: loss 6.122487
[epoch7, step2790]: loss 26.162613
[epoch7, step2791]: loss 8.078498
[epoch7, step2792]: loss 12.259167
[epoch7, step2793]: loss 2.311975
[epoch7, step2794]: loss 3.089889
[epoch7, step2795]: loss 2.592897
[epoch7, step2796]: loss 1.494827
[epoch7, step2797]: loss 2.467982
[epoch7, step2798]: loss 5.130730
[epoch7, step2799]: loss 14.558928
[epoch7, step2800]: loss 12.361374
[epoch7, step2801]: loss 1.166792
[epoch7, step2802]: loss 2.070421
[epoch7, step2803]: loss 5.808534
[epoch7, step2804]: loss 4.272000
[epoch7, step2805]: loss 5.416213
[epoch7, step2806]: loss 1.251924
[epoch7, step2807]: loss 1.955981
[epoch7, step2808]: loss 22.840282
[epoch7, step2809]: loss 17.332623
[epoch7, step2810]: loss 12.681024
[epoch7, step2811]: loss 3.545137
[epoch7, step2812]: loss 3.534969
[epoch7, step2813]: loss 5.910393
[epoch7, step2814]: loss 2.909618
[epoch7, step2815]: loss 4.624749
[epoch7, step2816]: loss 6.125032
[epoch7, step2817]: loss 1.489192
[epoch7, step2818]: loss 4.350293
[epoch7, step2819]: loss 14.426696
[epoch7, step2820]: loss 39.507774
[epoch7, step2821]: loss 1.755671
[epoch7, step2822]: loss 24.674871
[epoch7, step2823]: loss 14.792850
[epoch7, step2824]: loss 2.273151
[epoch7, step2825]: loss 23.913826
[epoch7, step2826]: loss 2.144794
[epoch7, step2827]: loss 44.846279
[epoch7, step2828]: loss 16.629128
[epoch7, step2829]: loss 1.355625
[epoch7, step2830]: loss 2.313873
[epoch7, step2831]: loss 9.725428
[epoch7, step2832]: loss 2.146866
[epoch7, step2833]: loss 2.932781
[epoch7, step2834]: loss 1.244803
[epoch7, step2835]: loss 14.156269
[epoch7, step2836]: loss 34.485584
[epoch7, step2837]: loss 14.152965
[epoch7, step2838]: loss 1.617294
[epoch7, step2839]: loss 13.214506
[epoch7, step2840]: loss 1.438933
[epoch7, step2841]: loss 4.097115
[epoch7, step2842]: loss 2.840214
[epoch7, step2843]: loss 5.971596
[epoch7, step2844]: loss 30.882427
[epoch7, step2845]: loss 9.190163
[epoch7, step2846]: loss 1.430384
[epoch7, step2847]: loss 2.671771
[epoch7, step2848]: loss 8.072969
[epoch7, step2849]: loss 3.249892
[epoch7, step2850]: loss 3.311516
[epoch7, step2851]: loss 2.000048
[epoch7, step2852]: loss 2.282759
[epoch7, step2853]: loss 2.573461
[epoch7, step2854]: loss 6.515194
[epoch7, step2855]: loss 16.341917
[epoch7, step2856]: loss 2.739158
[epoch7, step2857]: loss 7.605150
[epoch7, step2858]: loss 2.998972
[epoch7, step2859]: loss 19.546198
[epoch7, step2860]: loss 14.722233
[epoch7, step2861]: loss 1.652013
[epoch7, step2862]: loss 2.489419
[epoch7, step2863]: loss 5.395394
[epoch7, step2864]: loss 2.349136
[epoch7, step2865]: loss 4.215246
[epoch7, step2866]: loss 1.080808
[epoch7, step2867]: loss 1.618232
[epoch7, step2868]: loss 2.882321
[epoch7, step2869]: loss 17.846693
[epoch7, step2870]: loss 8.249660
[epoch7, step2871]: loss 7.192179
[epoch7, step2872]: loss 3.547206
[epoch7, step2873]: loss 3.077851
[epoch7, step2874]: loss 1.161585
[epoch7, step2875]: loss 4.998945
[epoch7, step2876]: loss 2.589779
[epoch7, step2877]: loss 3.175048
[epoch7, step2878]: loss 7.775081
[epoch7, step2879]: loss 6.329872
[epoch7, step2880]: loss 13.448893
[epoch7, step2881]: loss 2.669154
[epoch7, step2882]: loss 7.308933
[epoch7, step2883]: loss 1.813384
[epoch7, step2884]: loss 4.945767
[epoch7, step2885]: loss 1.703114
[epoch7, step2886]: loss 21.056126
[epoch7, step2887]: loss 2.285632
[epoch7, step2888]: loss 1.725032
[epoch7, step2889]: loss 28.802624
[epoch7, step2890]: loss 29.431973
[epoch7, step2891]: loss 21.973484
[epoch7, step2892]: loss 20.691233
[epoch7, step2893]: loss 5.770969
[epoch7, step2894]: loss 19.197418
[epoch7, step2895]: loss 1.857928
[epoch7, step2896]: loss 9.584919
[epoch7, step2897]: loss 1.576439
[epoch7, step2898]: loss 7.735414
[epoch7, step2899]: loss 8.610447
[epoch7, step2900]: loss 2.242762
[epoch7, step2901]: loss 13.626265
[epoch7, step2902]: loss 1.978650
[epoch7, step2903]: loss 5.105935
[epoch7, step2904]: loss 4.828135
[epoch7, step2905]: loss 1.984880
[epoch7, step2906]: loss 17.979389
[epoch7, step2907]: loss 10.203058
[epoch7, step2908]: loss 3.314896
[epoch7, step2909]: loss 17.083658
[epoch7, step2910]: loss 2.526362
[epoch7, step2911]: loss 24.678150
[epoch7, step2912]: loss 18.411247
[epoch7, step2913]: loss 10.230865
[epoch7, step2914]: loss 4.242326
[epoch7, step2915]: loss 6.754293
[epoch7, step2916]: loss 1.529552
[epoch7, step2917]: loss 7.283956
[epoch7, step2918]: loss 1.777840
[epoch7, step2919]: loss 2.927182
[epoch7, step2920]: loss 2.682048
[epoch7, step2921]: loss 15.492815
[epoch7, step2922]: loss 3.914239
[epoch7, step2923]: loss 2.793849
[epoch7, step2924]: loss 22.328577
[epoch7, step2925]: loss 3.947772
[epoch7, step2926]: loss 4.057340
[epoch7, step2927]: loss 2.295860
[epoch7, step2928]: loss 1.979623
[epoch7, step2929]: loss 16.979668
[epoch7, step2930]: loss 1.230912
[epoch7, step2931]: loss 3.206713
[epoch7, step2932]: loss 1.927829
[epoch7, step2933]: loss 8.936369
[epoch7, step2934]: loss 30.326490
[epoch7, step2935]: loss 6.878168
[epoch7, step2936]: loss 1.799281
[epoch7, step2937]: loss 1.431582
[epoch7, step2938]: loss 13.538831
[epoch7, step2939]: loss 10.051064
[epoch7, step2940]: loss 1.341095
[epoch7, step2941]: loss 2.465679
[epoch7, step2942]: loss 15.719626
[epoch7, step2943]: loss 7.801222
[epoch7, step2944]: loss 3.364834
[epoch7, step2945]: loss 10.439140
[epoch7, step2946]: loss 14.698835
[epoch7, step2947]: loss 35.533363
[epoch7, step2948]: loss 1.978317
[epoch7, step2949]: loss 18.617876
[epoch7, step2950]: loss 3.966826
[epoch7, step2951]: loss 4.545268
[epoch7, step2952]: loss 12.965888
[epoch7, step2953]: loss 5.410340
[epoch7, step2954]: loss 2.434564
[epoch7, step2955]: loss 7.330264
[epoch7, step2956]: loss 3.232180
[epoch7, step2957]: loss 3.013609
[epoch7, step2958]: loss 4.922476
[epoch7, step2959]: loss 20.902061
[epoch7, step2960]: loss 14.876178
[epoch7, step2961]: loss 5.840581
[epoch7, step2962]: loss 6.001740
[epoch7, step2963]: loss 9.078627
[epoch7, step2964]: loss 5.871540
[epoch7, step2965]: loss 3.247562
[epoch7, step2966]: loss 1.496931
[epoch7, step2967]: loss 3.081536
[epoch7, step2968]: loss 4.326293
[epoch7, step2969]: loss 1.929988
[epoch7, step2970]: loss 15.595279
[epoch7, step2971]: loss 15.955065
[epoch7, step2972]: loss 6.387387
[epoch7, step2973]: loss 2.430827
[epoch7, step2974]: loss 2.874680
[epoch7, step2975]: loss 3.031959
[epoch7, step2976]: loss 14.917971
[epoch7, step2977]: loss 2.324729
[epoch7, step2978]: loss 21.841156
[epoch7, step2979]: loss 10.406206
[epoch7, step2980]: loss 3.306825
[epoch7, step2981]: loss 1.916253
[epoch7, step2982]: loss 5.639619
[epoch7, step2983]: loss 3.112799
[epoch7, step2984]: loss 1.595417
[epoch7, step2985]: loss 1.564444
[epoch7, step2986]: loss 2.027816
[epoch7, step2987]: loss 7.216382
[epoch7, step2988]: loss 17.156525
[epoch7, step2989]: loss 2.916052
[epoch7, step2990]: loss 3.917911
[epoch7, step2991]: loss 1.850958
[epoch7, step2992]: loss 2.792700
[epoch7, step2993]: loss 21.518007
[epoch7, step2994]: loss 1.904845
[epoch7, step2995]: loss 20.206352
[epoch7, step2996]: loss 6.059636
[epoch7, step2997]: loss 1.142416
[epoch7, step2998]: loss 1.934398
[epoch7, step2999]: loss 2.534879
[epoch7, step3000]: loss 15.708239
[epoch7, step3001]: loss 23.343327
[epoch7, step3002]: loss 21.346844
[epoch7, step3003]: loss 2.556783
[epoch7, step3004]: loss 16.395380
[epoch7, step3005]: loss 1.910572
[epoch7, step3006]: loss 5.398262
[epoch7, step3007]: loss 17.757917
[epoch7, step3008]: loss 25.971359
[epoch7, step3009]: loss 2.060236
[epoch7, step3010]: loss 6.876487
[epoch7, step3011]: loss 5.339822
[epoch7, step3012]: loss 9.020486
[epoch7, step3013]: loss 4.392901
[epoch7, step3014]: loss 14.290710
[epoch7, step3015]: loss 19.452749
[epoch7, step3016]: loss 2.068002
[epoch7, step3017]: loss 1.579269
[epoch7, step3018]: loss 5.589068
[epoch7, step3019]: loss 2.727252
[epoch7, step3020]: loss 19.296734
[epoch7, step3021]: loss 2.343078
[epoch7, step3022]: loss 2.019471
[epoch7, step3023]: loss 2.384060
[epoch7, step3024]: loss 5.884336
[epoch7, step3025]: loss 24.130676
[epoch7, step3026]: loss 6.449564
[epoch7, step3027]: loss 6.316435
[epoch7, step3028]: loss 1.194783
[epoch7, step3029]: loss 15.670473
[epoch7, step3030]: loss 3.913425
[epoch7, step3031]: loss 14.568938
[epoch7, step3032]: loss 2.931917
[epoch7, step3033]: loss 3.593810
[epoch7, step3034]: loss 2.071837
[epoch7, step3035]: loss 2.808991
[epoch7, step3036]: loss 6.778670
[epoch7, step3037]: loss 16.244591
[epoch7, step3038]: loss 19.672842
[epoch7, step3039]: loss 22.917824
[epoch7, step3040]: loss 2.708369
[epoch7, step3041]: loss 38.749546
[epoch7, step3042]: loss 2.339043
[epoch7, step3043]: loss 3.382482
[epoch7, step3044]: loss 2.139860
[epoch7, step3045]: loss 4.106655
[epoch7, step3046]: loss 5.789477
[epoch7, step3047]: loss 1.924699
[epoch7, step3048]: loss 18.414171
[epoch7, step3049]: loss 1.528641
[epoch7, step3050]: loss 15.249437
[epoch7, step3051]: loss 4.014078
[epoch7, step3052]: loss 1.241469
[epoch7, step3053]: loss 5.669859
[epoch7, step3054]: loss 1.473385
[epoch7, step3055]: loss 2.581759
[epoch7, step3056]: loss 32.137062
[epoch7, step3057]: loss 1.221906
[epoch7, step3058]: loss 4.184626
[epoch7, step3059]: loss 1.184137
[epoch7, step3060]: loss 19.911697
[epoch7, step3061]: loss 16.398697
[epoch7, step3062]: loss 2.300314
[epoch7, step3063]: loss 12.796301
[epoch7, step3064]: loss 2.567838
[epoch7, step3065]: loss 1.342541
[epoch7, step3066]: loss 13.974649
[epoch7, step3067]: loss 20.404100
[epoch7, step3068]: loss 21.651188
[epoch7, step3069]: loss 3.251767
[epoch7, step3070]: loss 4.399763
[epoch7, step3071]: loss 1.047680
[epoch7, step3072]: loss 2.311884
[epoch7, step3073]: loss 25.168945
[epoch7, step3074]: loss 17.213768
[epoch7, step3075]: loss 1.613055
[epoch7, step3076]: loss 2.348377

[epoch7]: avg loss 2.348377

[epoch8, step1]: loss 10.504234
[epoch8, step2]: loss 1.142416
[epoch8, step3]: loss 13.564574
[epoch8, step4]: loss 4.610889
[epoch8, step5]: loss 7.230107
[epoch8, step6]: loss 2.971116
[epoch8, step7]: loss 6.754932
[epoch8, step8]: loss 2.642994
[epoch8, step9]: loss 3.738718
[epoch8, step10]: loss 24.820562
[epoch8, step11]: loss 3.193670
[epoch8, step12]: loss 4.410211
[epoch8, step13]: loss 24.471981
[epoch8, step14]: loss 12.622337
[epoch8, step15]: loss 19.237316
[epoch8, step16]: loss 12.190207
[epoch8, step17]: loss 5.208610
[epoch8, step18]: loss 6.163869
[epoch8, step19]: loss 2.358268
[epoch8, step20]: loss 3.530388
[epoch8, step21]: loss 14.314825
[epoch8, step22]: loss 46.755630
[epoch8, step23]: loss 15.071301
[epoch8, step24]: loss 3.054009
[epoch8, step25]: loss 5.005271
[epoch8, step26]: loss 4.533655
[epoch8, step27]: loss 3.609117
[epoch8, step28]: loss 1.526920
[epoch8, step29]: loss 26.007740
[epoch8, step30]: loss 2.044692
[epoch8, step31]: loss 5.251591
[epoch8, step32]: loss 2.131075
[epoch8, step33]: loss 4.843029
[epoch8, step34]: loss 1.766494
[epoch8, step35]: loss 18.289602
[epoch8, step36]: loss 4.727309
[epoch8, step37]: loss 2.875303
[epoch8, step38]: loss 16.755236
[epoch8, step39]: loss 4.643880
[epoch8, step40]: loss 7.361217
[epoch8, step41]: loss 4.757535
[epoch8, step42]: loss 13.789713
[epoch8, step43]: loss 12.871778
[epoch8, step44]: loss 9.482593
[epoch8, step45]: loss 20.263672
[epoch8, step46]: loss 1.702122
[epoch8, step47]: loss 14.215578
[epoch8, step48]: loss 2.931437
[epoch8, step49]: loss 19.953121
[epoch8, step50]: loss 8.599495
[epoch8, step51]: loss 6.821634
[epoch8, step52]: loss 28.745699
[epoch8, step53]: loss 31.666813
[epoch8, step54]: loss 5.795095
[epoch8, step55]: loss 21.215015
[epoch8, step56]: loss 5.012000
[epoch8, step57]: loss 1.340643
[epoch8, step58]: loss 19.265530
[epoch8, step59]: loss 4.021489
[epoch8, step60]: loss 2.331406
[epoch8, step61]: loss 24.543901
[epoch8, step62]: loss 7.717785
[epoch8, step63]: loss 1.952720
[epoch8, step64]: loss 9.414818
[epoch8, step65]: loss 2.739502
[epoch8, step66]: loss 17.180052
[epoch8, step67]: loss 25.328119
[epoch8, step68]: loss 4.736062
[epoch8, step69]: loss 13.228126
[epoch8, step70]: loss 19.651423
[epoch8, step71]: loss 1.557560
[epoch8, step72]: loss 1.082603
[epoch8, step73]: loss 2.852540
[epoch8, step74]: loss 3.659431
[epoch8, step75]: loss 13.725534
[epoch8, step76]: loss 7.202005
[epoch8, step77]: loss 0.942562
[epoch8, step78]: loss 1.677988
[epoch8, step79]: loss 1.603652
[epoch8, step80]: loss 18.806049
[epoch8, step81]: loss 1.365515
[epoch8, step82]: loss 17.965931
[epoch8, step83]: loss 3.118747
[epoch8, step84]: loss 6.345409
[epoch8, step85]: loss 12.313882
[epoch8, step86]: loss 3.778056
[epoch8, step87]: loss 2.121083
[epoch8, step88]: loss 2.941821
[epoch8, step89]: loss 3.203738
[epoch8, step90]: loss 17.904385
[epoch8, step91]: loss 6.777568
[epoch8, step92]: loss 1.992740
[epoch8, step93]: loss 1.528587
[epoch8, step94]: loss 6.491220
[epoch8, step95]: loss 21.730795
[epoch8, step96]: loss 16.710594
[epoch8, step97]: loss 14.909704
[epoch8, step98]: loss 2.646820
[epoch8, step99]: loss 6.034580
[epoch8, step100]: loss 2.358857
[epoch8, step101]: loss 4.708723
[epoch8, step102]: loss 3.054391
[epoch8, step103]: loss 18.748175
[epoch8, step104]: loss 6.003928
[epoch8, step105]: loss 4.473080
[epoch8, step106]: loss 3.225425
[epoch8, step107]: loss 5.506200
[epoch8, step108]: loss 4.241319
[epoch8, step109]: loss 29.351170
[epoch8, step110]: loss 4.941636
[epoch8, step111]: loss 16.834557
[epoch8, step112]: loss 1.405794
[epoch8, step113]: loss 6.551326
[epoch8, step114]: loss 6.216119
[epoch8, step115]: loss 11.063917
[epoch8, step116]: loss 2.003679
[epoch8, step117]: loss 13.736577
[epoch8, step118]: loss 1.765607
[epoch8, step119]: loss 1.978365
[epoch8, step120]: loss 14.634042
[epoch8, step121]: loss 15.848942
[epoch8, step122]: loss 19.732780
[epoch8, step123]: loss 1.048296
[epoch8, step124]: loss 23.331308
[epoch8, step125]: loss 20.145784
[epoch8, step126]: loss 4.154799
[epoch8, step127]: loss 2.654660
[epoch8, step128]: loss 1.481065
[epoch8, step129]: loss 1.601130
[epoch8, step130]: loss 1.121982
[epoch8, step131]: loss 2.539821
[epoch8, step132]: loss 1.838259
[epoch8, step133]: loss 1.566010
[epoch8, step134]: loss 1.973707
[epoch8, step135]: loss 14.025530
[epoch8, step136]: loss 12.286278
[epoch8, step137]: loss 17.429132
[epoch8, step138]: loss 3.863573
[epoch8, step139]: loss 12.817505
[epoch8, step140]: loss 20.635578
[epoch8, step141]: loss 9.210039
[epoch8, step142]: loss 4.896969
[epoch8, step143]: loss 1.829819
[epoch8, step144]: loss 10.077081
[epoch8, step145]: loss 2.258597
[epoch8, step146]: loss 8.625670
[epoch8, step147]: loss 4.064608
[epoch8, step148]: loss 21.873880
[epoch8, step149]: loss 38.784729
[epoch8, step150]: loss 15.380501
[epoch8, step151]: loss 7.374943
[epoch8, step152]: loss 8.992305
[epoch8, step153]: loss 1.705875
[epoch8, step154]: loss 17.152832
[epoch8, step155]: loss 2.053732
[epoch8, step156]: loss 19.821501
[epoch8, step157]: loss 4.733880
[epoch8, step158]: loss 2.857096
[epoch8, step159]: loss 48.497345
[epoch8, step160]: loss 33.701439
[epoch8, step161]: loss 2.035614
[epoch8, step162]: loss 2.118031
[epoch8, step163]: loss 22.354548
[epoch8, step164]: loss 1.903640
[epoch8, step165]: loss 1.996086
[epoch8, step166]: loss 20.150984
[epoch8, step167]: loss 14.678738
[epoch8, step168]: loss 12.529263
[epoch8, step169]: loss 1.003304
[epoch8, step170]: loss 2.083027
[epoch8, step171]: loss 2.834177
[epoch8, step172]: loss 16.871418
[epoch8, step173]: loss 1.376389
[epoch8, step174]: loss 7.684831
[epoch8, step175]: loss 15.398969
[epoch8, step176]: loss 5.172269
[epoch8, step177]: loss 4.077532
[epoch8, step178]: loss 19.750383
[epoch8, step179]: loss 2.904526
[epoch8, step180]: loss 23.488026
[epoch8, step181]: loss 2.168000
[epoch8, step182]: loss 5.182528
[epoch8, step183]: loss 4.736623
[epoch8, step184]: loss 6.829542
[epoch8, step185]: loss 5.835187
[epoch8, step186]: loss 2.424596
[epoch8, step187]: loss 14.578496
[epoch8, step188]: loss 16.728281
[epoch8, step189]: loss 3.110830
[epoch8, step190]: loss 5.977677
[epoch8, step191]: loss 2.472416
[epoch8, step192]: loss 23.657993
[epoch8, step193]: loss 14.408931
[epoch8, step194]: loss 7.788906
[epoch8, step195]: loss 44.892231
[epoch8, step196]: loss 8.212652
[epoch8, step197]: loss 10.674472
[epoch8, step198]: loss 3.418181
[epoch8, step199]: loss 14.381721
[epoch8, step200]: loss 22.023556
[epoch8, step201]: loss 2.038695
[epoch8, step202]: loss 3.084729
[epoch8, step203]: loss 8.964760
[epoch8, step204]: loss 2.561845
[epoch8, step205]: loss 3.899935
[epoch8, step206]: loss 2.304100
[epoch8, step207]: loss 17.997263
[epoch8, step208]: loss 3.456020
[epoch8, step209]: loss 15.928594
[epoch8, step210]: loss 1.483440
[epoch8, step211]: loss 5.410660
[epoch8, step212]: loss 1.273042
[epoch8, step213]: loss 6.543848
[epoch8, step214]: loss 12.222114
[epoch8, step215]: loss 15.034432
[epoch8, step216]: loss 7.654563
[epoch8, step217]: loss 1.891348
[epoch8, step218]: loss 7.660738
[epoch8, step219]: loss 1.793428
[epoch8, step220]: loss 5.431027
[epoch8, step221]: loss 3.731160
[epoch8, step222]: loss 1.998501
[epoch8, step223]: loss 2.558682
[epoch8, step224]: loss 2.058445
[epoch8, step225]: loss 6.240878
[epoch8, step226]: loss 1.148256
[epoch8, step227]: loss 13.176564
[epoch8, step228]: loss 2.055746
[epoch8, step229]: loss 3.675027
[epoch8, step230]: loss 1.571306
[epoch8, step231]: loss 1.430858
[epoch8, step232]: loss 1.396795
[epoch8, step233]: loss 1.931914
[epoch8, step234]: loss 2.911956
[epoch8, step235]: loss 1.515187
[epoch8, step236]: loss 9.584833
[epoch8, step237]: loss 1.927667
[epoch8, step238]: loss 2.072833
[epoch8, step239]: loss 47.782085
[epoch8, step240]: loss 2.112606
[epoch8, step241]: loss 2.964633
[epoch8, step242]: loss 16.744720
[epoch8, step243]: loss 1.759853
[epoch8, step244]: loss 6.895720
[epoch8, step245]: loss 4.401615
[epoch8, step246]: loss 26.453905
[epoch8, step247]: loss 2.672162
[epoch8, step248]: loss 3.322371
[epoch8, step249]: loss 1.201116
[epoch8, step250]: loss 7.734693
[epoch8, step251]: loss 2.939828
[epoch8, step252]: loss 1.085787
[epoch8, step253]: loss 1.896042
[epoch8, step254]: loss 13.603740
[epoch8, step255]: loss 1.976257
[epoch8, step256]: loss 1.945454
[epoch8, step257]: loss 1.330198
[epoch8, step258]: loss 4.272524
[epoch8, step259]: loss 2.777835
[epoch8, step260]: loss 5.271327
[epoch8, step261]: loss 2.192130
[epoch8, step262]: loss 4.221072
[epoch8, step263]: loss 3.785851
[epoch8, step264]: loss 3.564054
[epoch8, step265]: loss 27.128330
[epoch8, step266]: loss 5.571764
[epoch8, step267]: loss 23.156939
[epoch8, step268]: loss 1.755017
[epoch8, step269]: loss 5.701649
[epoch8, step270]: loss 7.508174
[epoch8, step271]: loss 3.633567
[epoch8, step272]: loss 2.783583
[epoch8, step273]: loss 1.079417
[epoch8, step274]: loss 16.234972
[epoch8, step275]: loss 22.574366
[epoch8, step276]: loss 7.384254
[epoch8, step277]: loss 2.954018
[epoch8, step278]: loss 3.891227
[epoch8, step279]: loss 3.087135
[epoch8, step280]: loss 0.848213
[epoch8, step281]: loss 4.587755
[epoch8, step282]: loss 1.774004
[epoch8, step283]: loss 3.981123
[epoch8, step284]: loss 15.205091
[epoch8, step285]: loss 1.399807
[epoch8, step286]: loss 1.882882
[epoch8, step287]: loss 2.588824
[epoch8, step288]: loss 4.334454
[epoch8, step289]: loss 11.446687
[epoch8, step290]: loss 13.536913
[epoch8, step291]: loss 1.384357
[epoch8, step292]: loss 3.581281
[epoch8, step293]: loss 6.166356
[epoch8, step294]: loss 0.910693
[epoch8, step295]: loss 2.366751
[epoch8, step296]: loss 0.961867
[epoch8, step297]: loss 2.983734
[epoch8, step298]: loss 19.486403
[epoch8, step299]: loss 15.790302
[epoch8, step300]: loss 5.496407
[epoch8, step301]: loss 10.618061
[epoch8, step302]: loss 3.338941
[epoch8, step303]: loss 9.077230
[epoch8, step304]: loss 1.055260
[epoch8, step305]: loss 14.603743
[epoch8, step306]: loss 16.706823
[epoch8, step307]: loss 2.773483
[epoch8, step308]: loss 1.294765
[epoch8, step309]: loss 6.234461
[epoch8, step310]: loss 3.134400
[epoch8, step311]: loss 7.284782
[epoch8, step312]: loss 6.162968
[epoch8, step313]: loss 1.315914
[epoch8, step314]: loss 1.534106
[epoch8, step315]: loss 15.723678
[epoch8, step316]: loss 5.454238
[epoch8, step317]: loss 11.585691
[epoch8, step318]: loss 4.174073
[epoch8, step319]: loss 1.984076
[epoch8, step320]: loss 3.263147
[epoch8, step321]: loss 9.204124
[epoch8, step322]: loss 5.263520
[epoch8, step323]: loss 10.879399
[epoch8, step324]: loss 2.478375
[epoch8, step325]: loss 3.070905
[epoch8, step326]: loss 3.145401
[epoch8, step327]: loss 18.848885
[epoch8, step328]: loss 34.585140
[epoch8, step329]: loss 1.253815
[epoch8, step330]: loss 8.099736
[epoch8, step331]: loss 19.506018
[epoch8, step332]: loss 2.195602
[epoch8, step333]: loss 1.325471
[epoch8, step334]: loss 6.859465
[epoch8, step335]: loss 14.603514
[epoch8, step336]: loss 4.105083
[epoch8, step337]: loss 8.755319
[epoch8, step338]: loss 1.479136
[epoch8, step339]: loss 2.469597
[epoch8, step340]: loss 2.867341
[epoch8, step341]: loss 12.961218
[epoch8, step342]: loss 1.844097
[epoch8, step343]: loss 7.753340
[epoch8, step344]: loss 22.143652
[epoch8, step345]: loss 1.643826
[epoch8, step346]: loss 1.289682
[epoch8, step347]: loss 2.435420
[epoch8, step348]: loss 1.427437
[epoch8, step349]: loss 3.820427
[epoch8, step350]: loss 13.363947
[epoch8, step351]: loss 10.555690
[epoch8, step352]: loss 2.377401
[epoch8, step353]: loss 12.321728
[epoch8, step354]: loss 17.386316
[epoch8, step355]: loss 3.824959
[epoch8, step356]: loss 18.073502
[epoch8, step357]: loss 6.031727
[epoch8, step358]: loss 16.020857
[epoch8, step359]: loss 5.985847
[epoch8, step360]: loss 3.493815
[epoch8, step361]: loss 15.165610
[epoch8, step362]: loss 1.566324
[epoch8, step363]: loss 2.028229
[epoch8, step364]: loss 10.755651
[epoch8, step365]: loss 3.440991
[epoch8, step366]: loss 4.197842
[epoch8, step367]: loss 21.964104
[epoch8, step368]: loss 5.159286
[epoch8, step369]: loss 18.284933
[epoch8, step370]: loss 10.591461
[epoch8, step371]: loss 15.710898
[epoch8, step372]: loss 1.395501
[epoch8, step373]: loss 1.716523
[epoch8, step374]: loss 2.680902
[epoch8, step375]: loss 7.228279
[epoch8, step376]: loss 21.109169
[epoch8, step377]: loss 2.874596
[epoch8, step378]: loss 2.796199
[epoch8, step379]: loss 1.415121
[epoch8, step380]: loss 1.678216
[epoch8, step381]: loss 1.268561
[epoch8, step382]: loss 2.540980
[epoch8, step383]: loss 2.023462
[epoch8, step384]: loss 18.035337
[epoch8, step385]: loss 2.287287
[epoch8, step386]: loss 2.461170
[epoch8, step387]: loss 23.133070
[epoch8, step388]: loss 3.118253
[epoch8, step389]: loss 43.881340
[epoch8, step390]: loss 2.995886
[epoch8, step391]: loss 18.710922
[epoch8, step392]: loss 1.911971
[epoch8, step393]: loss 4.559662
[epoch8, step394]: loss 15.269230
[epoch8, step395]: loss 9.263486
[epoch8, step396]: loss 9.312838
[epoch8, step397]: loss 3.885204
[epoch8, step398]: loss 48.111465
[epoch8, step399]: loss 2.497518
[epoch8, step400]: loss 4.537464
[epoch8, step401]: loss 2.232801
[epoch8, step402]: loss 2.766042
[epoch8, step403]: loss 2.029090
[epoch8, step404]: loss 1.162600
[epoch8, step405]: loss 1.446212
[epoch8, step406]: loss 14.713248
[epoch8, step407]: loss 4.226115
[epoch8, step408]: loss 5.350266
[epoch8, step409]: loss 1.568713
[epoch8, step410]: loss 2.492835
[epoch8, step411]: loss 4.471685
[epoch8, step412]: loss 2.291250
[epoch8, step413]: loss 11.658986
[epoch8, step414]: loss 4.862753
[epoch8, step415]: loss 5.971590
[epoch8, step416]: loss 17.395561
[epoch8, step417]: loss 3.230818
[epoch8, step418]: loss 20.101006
[epoch8, step419]: loss 10.586348
[epoch8, step420]: loss 2.529559
[epoch8, step421]: loss 33.849396
[epoch8, step422]: loss 18.013870
[epoch8, step423]: loss 36.665764
[epoch8, step424]: loss 3.787191
[epoch8, step425]: loss 1.672247
[epoch8, step426]: loss 3.276017
[epoch8, step427]: loss 21.020535
[epoch8, step428]: loss 19.448259
[epoch8, step429]: loss 18.854527
[epoch8, step430]: loss 17.976933
[epoch8, step431]: loss 5.511332
[epoch8, step432]: loss 19.823288
[epoch8, step433]: loss 1.527518
[epoch8, step434]: loss 18.551422
[epoch8, step435]: loss 2.166683
[epoch8, step436]: loss 5.894841
[epoch8, step437]: loss 5.171248
[epoch8, step438]: loss 3.725412
[epoch8, step439]: loss 12.303091
[epoch8, step440]: loss 28.145348
[epoch8, step441]: loss 15.166699
[epoch8, step442]: loss 19.507618
[epoch8, step443]: loss 3.982248
[epoch8, step444]: loss 15.001078
[epoch8, step445]: loss 16.843536
[epoch8, step446]: loss 1.800442
[epoch8, step447]: loss 2.306774
[epoch8, step448]: loss 3.222717
[epoch8, step449]: loss 2.460106
[epoch8, step450]: loss 8.596763
[epoch8, step451]: loss 4.259391
[epoch8, step452]: loss 3.032254
[epoch8, step453]: loss 12.496178
[epoch8, step454]: loss 1.972419
[epoch8, step455]: loss 3.200401
[epoch8, step456]: loss 1.229198
[epoch8, step457]: loss 1.390157
[epoch8, step458]: loss 6.497502
[epoch8, step459]: loss 3.707202
[epoch8, step460]: loss 3.726616
[epoch8, step461]: loss 3.279136
[epoch8, step462]: loss 1.890964
[epoch8, step463]: loss 2.270007
[epoch8, step464]: loss 1.917794
[epoch8, step465]: loss 21.432188
[epoch8, step466]: loss 2.299619
[epoch8, step467]: loss 2.177202
[epoch8, step468]: loss 8.212030
[epoch8, step469]: loss 2.047101
[epoch8, step470]: loss 4.707321
[epoch8, step471]: loss 13.407583
[epoch8, step472]: loss 13.952004
[epoch8, step473]: loss 1.575743
[epoch8, step474]: loss 11.189869
[epoch8, step475]: loss 5.517123
[epoch8, step476]: loss 1.201768
[epoch8, step477]: loss 2.663393
[epoch8, step478]: loss 5.610021
[epoch8, step479]: loss 52.564888
[epoch8, step480]: loss 22.150360
[epoch8, step481]: loss 7.278206
[epoch8, step482]: loss 11.555592
[epoch8, step483]: loss 1.977533
[epoch8, step484]: loss 2.411188
[epoch8, step485]: loss 2.070496
[epoch8, step486]: loss 18.322073
[epoch8, step487]: loss 1.702907
[epoch8, step488]: loss 21.820183
[epoch8, step489]: loss 0.971552
[epoch8, step490]: loss 2.819836
[epoch8, step491]: loss 16.093567
[epoch8, step492]: loss 1.996454
[epoch8, step493]: loss 1.884550
[epoch8, step494]: loss 1.087138
[epoch8, step495]: loss 2.579741
[epoch8, step496]: loss 4.525858
[epoch8, step497]: loss 3.256414
[epoch8, step498]: loss 1.977500
[epoch8, step499]: loss 1.741318
[epoch8, step500]: loss 1.911203
[epoch8, step501]: loss 2.714294
[epoch8, step502]: loss 15.669971
[epoch8, step503]: loss 4.702755
[epoch8, step504]: loss 17.273401
[epoch8, step505]: loss 2.496799
[epoch8, step506]: loss 15.204817
[epoch8, step507]: loss 16.399075
[epoch8, step508]: loss 2.016165
[epoch8, step509]: loss 14.523837
[epoch8, step510]: loss 14.999646
[epoch8, step511]: loss 14.733120
[epoch8, step512]: loss 2.127095
[epoch8, step513]: loss 2.510374
[epoch8, step514]: loss 1.666290
[epoch8, step515]: loss 2.373791
[epoch8, step516]: loss 1.417379
[epoch8, step517]: loss 12.538288
[epoch8, step518]: loss 12.617089
[epoch8, step519]: loss 4.092218
[epoch8, step520]: loss 3.676787
[epoch8, step521]: loss 6.834958
[epoch8, step522]: loss 27.945589
[epoch8, step523]: loss 1.495880
[epoch8, step524]: loss 5.889411
[epoch8, step525]: loss 1.940835
[epoch8, step526]: loss 2.602181
[epoch8, step527]: loss 8.300104
[epoch8, step528]: loss 2.837153
[epoch8, step529]: loss 17.448851
[epoch8, step530]: loss 2.230437
[epoch8, step531]: loss 7.050770
[epoch8, step532]: loss 14.586992
[epoch8, step533]: loss 1.862883
[epoch8, step534]: loss 1.819901
[epoch8, step535]: loss 5.270263
[epoch8, step536]: loss 26.975315
[epoch8, step537]: loss 1.190718
[epoch8, step538]: loss 1.359697
[epoch8, step539]: loss 3.324331
[epoch8, step540]: loss 16.903557
[epoch8, step541]: loss 3.275488
[epoch8, step542]: loss 1.793445
[epoch8, step543]: loss 10.692473
[epoch8, step544]: loss 3.584947
[epoch8, step545]: loss 6.884841
[epoch8, step546]: loss 1.124480
[epoch8, step547]: loss 20.426348
[epoch8, step548]: loss 5.022971
[epoch8, step549]: loss 1.845245
[epoch8, step550]: loss 2.673693
[epoch8, step551]: loss 6.354956
[epoch8, step552]: loss 7.005178
[epoch8, step553]: loss 1.367088
[epoch8, step554]: loss 2.840616
[epoch8, step555]: loss 1.419526
[epoch8, step556]: loss 2.236396
[epoch8, step557]: loss 1.813313
[epoch8, step558]: loss 3.772513
[epoch8, step559]: loss 3.229693
[epoch8, step560]: loss 16.987600
[epoch8, step561]: loss 3.089105
[epoch8, step562]: loss 5.187763
[epoch8, step563]: loss 6.802437
[epoch8, step564]: loss 1.595045
[epoch8, step565]: loss 7.288761
[epoch8, step566]: loss 20.279833
[epoch8, step567]: loss 6.662781
[epoch8, step568]: loss 1.375665
[epoch8, step569]: loss 0.802274
[epoch8, step570]: loss 2.776190
[epoch8, step571]: loss 3.960132
[epoch8, step572]: loss 2.339500
[epoch8, step573]: loss 1.322358
[epoch8, step574]: loss 29.352175
[epoch8, step575]: loss 2.259467
[epoch8, step576]: loss 3.909171
[epoch8, step577]: loss 1.406637
[epoch8, step578]: loss 1.229767
[epoch8, step579]: loss 2.860948
[epoch8, step580]: loss 21.894371
[epoch8, step581]: loss 1.060701
[epoch8, step582]: loss 7.450961
[epoch8, step583]: loss 4.266185
[epoch8, step584]: loss 6.348958
[epoch8, step585]: loss 4.974979
[epoch8, step586]: loss 2.291969
[epoch8, step587]: loss 2.898141
[epoch8, step588]: loss 1.505879
[epoch8, step589]: loss 2.201016
[epoch8, step590]: loss 2.047559
[epoch8, step591]: loss 1.815783
[epoch8, step592]: loss 1.441478
[epoch8, step593]: loss 21.513201
[epoch8, step594]: loss 17.519772
[epoch8, step595]: loss 1.919075
[epoch8, step596]: loss 12.306539
[epoch8, step597]: loss 1.998634
[epoch8, step598]: loss 17.118870
[epoch8, step599]: loss 56.106529
[epoch8, step600]: loss 2.818018
[epoch8, step601]: loss 1.874453
[epoch8, step602]: loss 8.341407
[epoch8, step603]: loss 2.763160
[epoch8, step604]: loss 4.970018
[epoch8, step605]: loss 3.466589
[epoch8, step606]: loss 5.821396
[epoch8, step607]: loss 2.801639
[epoch8, step608]: loss 9.684500
[epoch8, step609]: loss 10.204215
[epoch8, step610]: loss 17.159969
[epoch8, step611]: loss 4.827445
[epoch8, step612]: loss 2.113255
[epoch8, step613]: loss 1.580489
[epoch8, step614]: loss 6.072248
[epoch8, step615]: loss 3.333051
[epoch8, step616]: loss 1.956949
[epoch8, step617]: loss 3.908702
[epoch8, step618]: loss 22.478294
[epoch8, step619]: loss 2.291607
[epoch8, step620]: loss 1.182564
[epoch8, step621]: loss 19.481079
[epoch8, step622]: loss 26.969767
[epoch8, step623]: loss 8.045005
[epoch8, step624]: loss 5.047153
[epoch8, step625]: loss 7.235028
[epoch8, step626]: loss 13.721633
[epoch8, step627]: loss 2.683750
[epoch8, step628]: loss 4.336165
[epoch8, step629]: loss 5.252936
[epoch8, step630]: loss 16.687319
[epoch8, step631]: loss 36.830833
[epoch8, step632]: loss 1.767384
[epoch8, step633]: loss 1.790061
[epoch8, step634]: loss 7.365953
[epoch8, step635]: loss 15.252172
[epoch8, step636]: loss 1.329279
[epoch8, step637]: loss 1.932683
[epoch8, step638]: loss 18.980179
[epoch8, step639]: loss 1.520486
[epoch8, step640]: loss 4.518316
[epoch8, step641]: loss 4.158517
[epoch8, step642]: loss 1.322206
[epoch8, step643]: loss 4.619472
[epoch8, step644]: loss 2.871035
[epoch8, step645]: loss 5.014727
[epoch8, step646]: loss 1.630171
[epoch8, step647]: loss 17.787821
[epoch8, step648]: loss 1.080812
[epoch8, step649]: loss 15.659439
[epoch8, step650]: loss 1.096968
[epoch8, step651]: loss 1.111152
[epoch8, step652]: loss 6.966082
[epoch8, step653]: loss 1.924252
[epoch8, step654]: loss 1.815202
[epoch8, step655]: loss 1.896156
[epoch8, step656]: loss 2.997322
[epoch8, step657]: loss 1.692244
[epoch8, step658]: loss 3.878395
[epoch8, step659]: loss 3.249778
[epoch8, step660]: loss 1.680071
[epoch8, step661]: loss 7.255021
[epoch8, step662]: loss 1.734960
[epoch8, step663]: loss 4.895038
[epoch8, step664]: loss 14.960040
[epoch8, step665]: loss 1.776836
[epoch8, step666]: loss 3.952649
[epoch8, step667]: loss 2.056345
[epoch8, step668]: loss 2.230356
[epoch8, step669]: loss 1.491638
[epoch8, step670]: loss 1.587662
[epoch8, step671]: loss 3.352757
[epoch8, step672]: loss 1.213796
[epoch8, step673]: loss 4.219034
[epoch8, step674]: loss 1.597627
[epoch8, step675]: loss 1.744573
[epoch8, step676]: loss 1.691844
[epoch8, step677]: loss 2.757252
[epoch8, step678]: loss 3.167150
[epoch8, step679]: loss 4.998366
[epoch8, step680]: loss 4.592186
[epoch8, step681]: loss 21.657795
[epoch8, step682]: loss 11.896329
[epoch8, step683]: loss 1.625206
[epoch8, step684]: loss 20.323593
[epoch8, step685]: loss 1.652056
[epoch8, step686]: loss 7.052401
[epoch8, step687]: loss 1.092284
[epoch8, step688]: loss 19.045681
[epoch8, step689]: loss 2.691244
[epoch8, step690]: loss 25.717562
[epoch8, step691]: loss 1.749204
[epoch8, step692]: loss 2.403470
[epoch8, step693]: loss 3.247266
[epoch8, step694]: loss 23.962990
[epoch8, step695]: loss 4.908112
[epoch8, step696]: loss 13.216425
[epoch8, step697]: loss 5.218669
[epoch8, step698]: loss 1.905697
[epoch8, step699]: loss 1.454423
[epoch8, step700]: loss 1.277574
[epoch8, step701]: loss 1.697991
[epoch8, step702]: loss 3.290068
[epoch8, step703]: loss 1.998747
[epoch8, step704]: loss 2.799853
[epoch8, step705]: loss 2.303535
[epoch8, step706]: loss 1.175851
[epoch8, step707]: loss 7.456753
[epoch8, step708]: loss 16.348143
[epoch8, step709]: loss 1.518315
[epoch8, step710]: loss 2.977449
[epoch8, step711]: loss 1.591585
[epoch8, step712]: loss 2.195488
[epoch8, step713]: loss 2.925652
[epoch8, step714]: loss 4.579021
[epoch8, step715]: loss 7.614358
[epoch8, step716]: loss 5.973807
[epoch8, step717]: loss 31.254730
[epoch8, step718]: loss 1.666428
[epoch8, step719]: loss 2.660176
[epoch8, step720]: loss 4.588473
[epoch8, step721]: loss 4.587893
[epoch8, step722]: loss 39.682884
[epoch8, step723]: loss 2.099928
[epoch8, step724]: loss 20.024010
[epoch8, step725]: loss 2.477527
[epoch8, step726]: loss 6.160462
[epoch8, step727]: loss 18.960558
[epoch8, step728]: loss 3.307517
[epoch8, step729]: loss 10.897564
[epoch8, step730]: loss 2.043613
[epoch8, step731]: loss 22.080011
[epoch8, step732]: loss 1.378038
[epoch8, step733]: loss 1.526261
[epoch8, step734]: loss 1.148700
[epoch8, step735]: loss 1.781277
[epoch8, step736]: loss 3.121121
[epoch8, step737]: loss 8.470562
[epoch8, step738]: loss 18.172842
[epoch8, step739]: loss 1.807442
[epoch8, step740]: loss 13.959783
[epoch8, step741]: loss 1.961274
[epoch8, step742]: loss 6.668010
[epoch8, step743]: loss 1.991682
[epoch8, step744]: loss 27.050262
[epoch8, step745]: loss 17.579395
[epoch8, step746]: loss 12.685717
[epoch8, step747]: loss 2.028948
[epoch8, step748]: loss 3.269280
[epoch8, step749]: loss 1.594424
[epoch8, step750]: loss 3.439263
[epoch8, step751]: loss 1.048270
[epoch8, step752]: loss 6.320211
[epoch8, step753]: loss 2.818025
[epoch8, step754]: loss 1.266812
[epoch8, step755]: loss 2.559483
[epoch8, step756]: loss 11.734201
[epoch8, step757]: loss 4.172315
[epoch8, step758]: loss 6.836543
[epoch8, step759]: loss 4.530630
[epoch8, step760]: loss 1.765520
[epoch8, step761]: loss 1.900229
[epoch8, step762]: loss 22.896093
[epoch8, step763]: loss 6.232849
[epoch8, step764]: loss 16.705173
[epoch8, step765]: loss 1.320268
[epoch8, step766]: loss 4.241311
[epoch8, step767]: loss 16.257895
[epoch8, step768]: loss 11.438663
[epoch8, step769]: loss 2.766865
[epoch8, step770]: loss 4.392771
[epoch8, step771]: loss 8.391815
[epoch8, step772]: loss 28.317556
[epoch8, step773]: loss 6.692282
[epoch8, step774]: loss 1.871994
[epoch8, step775]: loss 9.570266
[epoch8, step776]: loss 14.923612
[epoch8, step777]: loss 22.781956
[epoch8, step778]: loss 4.451655
[epoch8, step779]: loss 5.408785
[epoch8, step780]: loss 2.187083
[epoch8, step781]: loss 2.280700
[epoch8, step782]: loss 2.695346
[epoch8, step783]: loss 1.847021
[epoch8, step784]: loss 6.252563
[epoch8, step785]: loss 1.699003
[epoch8, step786]: loss 20.679266
[epoch8, step787]: loss 18.134983
[epoch8, step788]: loss 1.995411
[epoch8, step789]: loss 2.968235
[epoch8, step790]: loss 2.086712
[epoch8, step791]: loss 2.732835
[epoch8, step792]: loss 2.441484
[epoch8, step793]: loss 1.449587
[epoch8, step794]: loss 1.698478
[epoch8, step795]: loss 6.084737
[epoch8, step796]: loss 35.248726
[epoch8, step797]: loss 1.539760
[epoch8, step798]: loss 2.181675
[epoch8, step799]: loss 1.501087
[epoch8, step800]: loss 16.767853
[epoch8, step801]: loss 6.353697
[epoch8, step802]: loss 6.922046
[epoch8, step803]: loss 2.578936
[epoch8, step804]: loss 2.082450
[epoch8, step805]: loss 6.476475
[epoch8, step806]: loss 13.597028
[epoch8, step807]: loss 3.615060
[epoch8, step808]: loss 28.179321
[epoch8, step809]: loss 3.159639
[epoch8, step810]: loss 6.430814
[epoch8, step811]: loss 14.337532
[epoch8, step812]: loss 2.574267
[epoch8, step813]: loss 3.413178
[epoch8, step814]: loss 11.979837
[epoch8, step815]: loss 1.774621
[epoch8, step816]: loss 4.415363
[epoch8, step817]: loss 1.368629
[epoch8, step818]: loss 7.173182
[epoch8, step819]: loss 18.618143
[epoch8, step820]: loss 12.404699
[epoch8, step821]: loss 1.889322
[epoch8, step822]: loss 1.467424
[epoch8, step823]: loss 2.042413
[epoch8, step824]: loss 5.744313
[epoch8, step825]: loss 4.368827
[epoch8, step826]: loss 44.112038
[epoch8, step827]: loss 3.467460
[epoch8, step828]: loss 3.877372
[epoch8, step829]: loss 1.465462
[epoch8, step830]: loss 1.142317
[epoch8, step831]: loss 7.347468
[epoch8, step832]: loss 6.863820
[epoch8, step833]: loss 2.851130
[epoch8, step834]: loss 0.995729
[epoch8, step835]: loss 5.620335
[epoch8, step836]: loss 1.169788
[epoch8, step837]: loss 18.886564
[epoch8, step838]: loss 7.781299
[epoch8, step839]: loss 1.583303
[epoch8, step840]: loss 12.264064
[epoch8, step841]: loss 2.923903
[epoch8, step842]: loss 34.978264
[epoch8, step843]: loss 3.800808
[epoch8, step844]: loss 20.805561
[epoch8, step845]: loss 9.098203
[epoch8, step846]: loss 14.135484
[epoch8, step847]: loss 2.944226
[epoch8, step848]: loss 6.428369
[epoch8, step849]: loss 4.133978
[epoch8, step850]: loss 2.836172
[epoch8, step851]: loss 1.668920
[epoch8, step852]: loss 2.169230
[epoch8, step853]: loss 9.224626
[epoch8, step854]: loss 1.908593
[epoch8, step855]: loss 1.923523
[epoch8, step856]: loss 2.949241
[epoch8, step857]: loss 2.074508
[epoch8, step858]: loss 4.251936
[epoch8, step859]: loss 13.294978
[epoch8, step860]: loss 1.174890
[epoch8, step861]: loss 2.820362
[epoch8, step862]: loss 3.077061
[epoch8, step863]: loss 5.456336
[epoch8, step864]: loss 1.023013
[epoch8, step865]: loss 8.367509
[epoch8, step866]: loss 4.249477
[epoch8, step867]: loss 1.183319
[epoch8, step868]: loss 12.374428
[epoch8, step869]: loss 3.929199
[epoch8, step870]: loss 1.996543
[epoch8, step871]: loss 12.136324
[epoch8, step872]: loss 1.922520
[epoch8, step873]: loss 15.044506
[epoch8, step874]: loss 4.974971
[epoch8, step875]: loss 3.740234
[epoch8, step876]: loss 34.627743
[epoch8, step877]: loss 19.096193
[epoch8, step878]: loss 11.823508
[epoch8, step879]: loss 7.518686
[epoch8, step880]: loss 1.726687
[epoch8, step881]: loss 14.343797
[epoch8, step882]: loss 2.173838
[epoch8, step883]: loss 7.206664
[epoch8, step884]: loss 1.770703
[epoch8, step885]: loss 3.447343
[epoch8, step886]: loss 3.865917
[epoch8, step887]: loss 7.540491
[epoch8, step888]: loss 7.824933
[epoch8, step889]: loss 2.147919
[epoch8, step890]: loss 16.178890
[epoch8, step891]: loss 1.211309
[epoch8, step892]: loss 1.705473
[epoch8, step893]: loss 2.430213
[epoch8, step894]: loss 1.599301
[epoch8, step895]: loss 19.995914
[epoch8, step896]: loss 3.102437
[epoch8, step897]: loss 4.836123
[epoch8, step898]: loss 21.436817
[epoch8, step899]: loss 2.714995
[epoch8, step900]: loss 13.523478
[epoch8, step901]: loss 21.721783
[epoch8, step902]: loss 6.259118
[epoch8, step903]: loss 28.762741
[epoch8, step904]: loss 1.224535
[epoch8, step905]: loss 2.073801
[epoch8, step906]: loss 2.342753
[epoch8, step907]: loss 2.497521
[epoch8, step908]: loss 3.653571
[epoch8, step909]: loss 1.028085
[epoch8, step910]: loss 14.015901
[epoch8, step911]: loss 2.464172
[epoch8, step912]: loss 1.432702
[epoch8, step913]: loss 9.869053
[epoch8, step914]: loss 5.893224
[epoch8, step915]: loss 0.793024
[epoch8, step916]: loss 6.557551
[epoch8, step917]: loss 1.552377
[epoch8, step918]: loss 6.211351
[epoch8, step919]: loss 3.343104
[epoch8, step920]: loss 6.136590
[epoch8, step921]: loss 4.992604
[epoch8, step922]: loss 10.833379
[epoch8, step923]: loss 1.592904
[epoch8, step924]: loss 6.019121
[epoch8, step925]: loss 3.098563
[epoch8, step926]: loss 3.033651
[epoch8, step927]: loss 35.227367
[epoch8, step928]: loss 2.135788
[epoch8, step929]: loss 17.244427
[epoch8, step930]: loss 0.886368
[epoch8, step931]: loss 3.672193
[epoch8, step932]: loss 2.535442
[epoch8, step933]: loss 3.531686
[epoch8, step934]: loss 2.836016
[epoch8, step935]: loss 3.022628
[epoch8, step936]: loss 3.282656
[epoch8, step937]: loss 36.450699
[epoch8, step938]: loss 20.200399
[epoch8, step939]: loss 4.995087
[epoch8, step940]: loss 2.998904
[epoch8, step941]: loss 5.284046
[epoch8, step942]: loss 2.934908
[epoch8, step943]: loss 4.667928
[epoch8, step944]: loss 5.854903
[epoch8, step945]: loss 4.017942
[epoch8, step946]: loss 1.209175
[epoch8, step947]: loss 3.843842
[epoch8, step948]: loss 13.612139
[epoch8, step949]: loss 30.485588
[epoch8, step950]: loss 22.247070
[epoch8, step951]: loss 3.044087
[epoch8, step952]: loss 6.413276
[epoch8, step953]: loss 5.051282
[epoch8, step954]: loss 19.075237
[epoch8, step955]: loss 1.347964
[epoch8, step956]: loss 6.747318
[epoch8, step957]: loss 7.634717
[epoch8, step958]: loss 4.360483
[epoch8, step959]: loss 5.547288
[epoch8, step960]: loss 3.349748
[epoch8, step961]: loss 6.110166
[epoch8, step962]: loss 23.334995
[epoch8, step963]: loss 6.776193
[epoch8, step964]: loss 12.564695
[epoch8, step965]: loss 3.600817
[epoch8, step966]: loss 14.067430
[epoch8, step967]: loss 7.181629
[epoch8, step968]: loss 1.472568
[epoch8, step969]: loss 3.418068
[epoch8, step970]: loss 5.864807
[epoch8, step971]: loss 1.444054
[epoch8, step972]: loss 1.449621
[epoch8, step973]: loss 1.575088
[epoch8, step974]: loss 3.278538
[epoch8, step975]: loss 3.476964
[epoch8, step976]: loss 3.977256
[epoch8, step977]: loss 14.476704
[epoch8, step978]: loss 1.925435
[epoch8, step979]: loss 1.188080
[epoch8, step980]: loss 7.714004
[epoch8, step981]: loss 3.243577
[epoch8, step982]: loss 6.025374
[epoch8, step983]: loss 11.582366
[epoch8, step984]: loss 2.362751
[epoch8, step985]: loss 2.884264
[epoch8, step986]: loss 5.692423
[epoch8, step987]: loss 23.650793
[epoch8, step988]: loss 15.149645
[epoch8, step989]: loss 3.123142
[epoch8, step990]: loss 2.503175
[epoch8, step991]: loss 2.167441
[epoch8, step992]: loss 33.494308
[epoch8, step993]: loss 5.954785
[epoch8, step994]: loss 1.301974
[epoch8, step995]: loss 1.270320
[epoch8, step996]: loss 1.151084
[epoch8, step997]: loss 3.545370
[epoch8, step998]: loss 5.026235
[epoch8, step999]: loss 2.937391
[epoch8, step1000]: loss 1.499904
[epoch8, step1001]: loss 2.032923
[epoch8, step1002]: loss 4.344571
[epoch8, step1003]: loss 2.712786
[epoch8, step1004]: loss 4.160965
[epoch8, step1005]: loss 9.918511
[epoch8, step1006]: loss 3.606927
[epoch8, step1007]: loss 1.883612
[epoch8, step1008]: loss 1.224147
[epoch8, step1009]: loss 3.993097
[epoch8, step1010]: loss 3.287638
[epoch8, step1011]: loss 3.277064
[epoch8, step1012]: loss 3.758125
[epoch8, step1013]: loss 1.357222
[epoch8, step1014]: loss 15.949862
[epoch8, step1015]: loss 13.574693
[epoch8, step1016]: loss 8.677659
[epoch8, step1017]: loss 23.868353
[epoch8, step1018]: loss 21.988136
[epoch8, step1019]: loss 2.232915
[epoch8, step1020]: loss 3.147419
[epoch8, step1021]: loss 14.948899
[epoch8, step1022]: loss 4.021696
[epoch8, step1023]: loss 3.211101
[epoch8, step1024]: loss 2.470589
[epoch8, step1025]: loss 3.049941
[epoch8, step1026]: loss 15.589437
[epoch8, step1027]: loss 19.567062
[epoch8, step1028]: loss 2.704374
[epoch8, step1029]: loss 1.969640
[epoch8, step1030]: loss 3.415229
[epoch8, step1031]: loss 0.881658
[epoch8, step1032]: loss 1.436483
[epoch8, step1033]: loss 23.850382
[epoch8, step1034]: loss 6.744323
[epoch8, step1035]: loss 14.602018
[epoch8, step1036]: loss 2.557491
[epoch8, step1037]: loss 2.509287
[epoch8, step1038]: loss 1.169165
[epoch8, step1039]: loss 32.097279
[epoch8, step1040]: loss 3.372011
[epoch8, step1041]: loss 5.138164
[epoch8, step1042]: loss 4.432255
[epoch8, step1043]: loss 3.281667
[epoch8, step1044]: loss 2.241079
[epoch8, step1045]: loss 13.669892
[epoch8, step1046]: loss 2.238726
[epoch8, step1047]: loss 13.207619
[epoch8, step1048]: loss 7.617781
[epoch8, step1049]: loss 2.491200
[epoch8, step1050]: loss 1.497119
[epoch8, step1051]: loss 1.482056
[epoch8, step1052]: loss 15.896248
[epoch8, step1053]: loss 7.638841
[epoch8, step1054]: loss 1.684122
[epoch8, step1055]: loss 2.711416
[epoch8, step1056]: loss 2.185019
[epoch8, step1057]: loss 8.709057
[epoch8, step1058]: loss 7.338600
[epoch8, step1059]: loss 22.971977
[epoch8, step1060]: loss 2.056249
[epoch8, step1061]: loss 25.442057
[epoch8, step1062]: loss 2.496395
[epoch8, step1063]: loss 1.257725
[epoch8, step1064]: loss 38.692657
[epoch8, step1065]: loss 6.403942
[epoch8, step1066]: loss 3.309945
[epoch8, step1067]: loss 33.685604
[epoch8, step1068]: loss 9.367554
[epoch8, step1069]: loss 8.817872
[epoch8, step1070]: loss 2.180336
[epoch8, step1071]: loss 6.378338
[epoch8, step1072]: loss 5.417421
[epoch8, step1073]: loss 6.545362
[epoch8, step1074]: loss 4.012248
[epoch8, step1075]: loss 4.471380
[epoch8, step1076]: loss 8.842299
[epoch8, step1077]: loss 2.098051
[epoch8, step1078]: loss 18.814991
[epoch8, step1079]: loss 3.677080
[epoch8, step1080]: loss 4.548778
[epoch8, step1081]: loss 4.037157
[epoch8, step1082]: loss 1.959436
[epoch8, step1083]: loss 1.654416
[epoch8, step1084]: loss 25.305752
[epoch8, step1085]: loss 13.861045
[epoch8, step1086]: loss 10.930433
[epoch8, step1087]: loss 5.691117
[epoch8, step1088]: loss 18.032322
[epoch8, step1089]: loss 13.888375
[epoch8, step1090]: loss 8.583551
[epoch8, step1091]: loss 5.933098
[epoch8, step1092]: loss 1.383964
[epoch8, step1093]: loss 1.693615
[epoch8, step1094]: loss 1.523057
[epoch8, step1095]: loss 2.229087
[epoch8, step1096]: loss 3.172791
[epoch8, step1097]: loss 21.020542
[epoch8, step1098]: loss 2.821129
[epoch8, step1099]: loss 4.834206
[epoch8, step1100]: loss 1.668685
[epoch8, step1101]: loss 24.002954
[epoch8, step1102]: loss 2.354528
[epoch8, step1103]: loss 22.714424
[epoch8, step1104]: loss 2.956739
[epoch8, step1105]: loss 9.196741
[epoch8, step1106]: loss 1.899519
[epoch8, step1107]: loss 1.581725
[epoch8, step1108]: loss 4.342753
[epoch8, step1109]: loss 21.590799
[epoch8, step1110]: loss 2.250108
[epoch8, step1111]: loss 2.252209
[epoch8, step1112]: loss 5.897783
[epoch8, step1113]: loss 1.682021
[epoch8, step1114]: loss 1.288664
[epoch8, step1115]: loss 1.599436
[epoch8, step1116]: loss 4.534530
[epoch8, step1117]: loss 3.248393
[epoch8, step1118]: loss 1.027630
[epoch8, step1119]: loss 1.552000
[epoch8, step1120]: loss 6.411476
[epoch8, step1121]: loss 8.843819
[epoch8, step1122]: loss 17.256714
[epoch8, step1123]: loss 19.911783
[epoch8, step1124]: loss 2.123577
[epoch8, step1125]: loss 8.702881
[epoch8, step1126]: loss 1.620966
[epoch8, step1127]: loss 18.371719
[epoch8, step1128]: loss 18.873297
[epoch8, step1129]: loss 15.606506
[epoch8, step1130]: loss 1.997551
[epoch8, step1131]: loss 5.609203
[epoch8, step1132]: loss 1.951442
[epoch8, step1133]: loss 8.704610
[epoch8, step1134]: loss 3.361934
[epoch8, step1135]: loss 6.836951
[epoch8, step1136]: loss 3.117478
[epoch8, step1137]: loss 1.117687
[epoch8, step1138]: loss 1.450017
[epoch8, step1139]: loss 2.337886
[epoch8, step1140]: loss 4.310709
[epoch8, step1141]: loss 15.403731
[epoch8, step1142]: loss 3.061463
[epoch8, step1143]: loss 10.258919
[epoch8, step1144]: loss 17.024092
[epoch8, step1145]: loss 1.594846
[epoch8, step1146]: loss 1.303757
[epoch8, step1147]: loss 3.441450
[epoch8, step1148]: loss 2.756949
[epoch8, step1149]: loss 1.143700
[epoch8, step1150]: loss 19.748217
[epoch8, step1151]: loss 4.578186
[epoch8, step1152]: loss 3.669760
[epoch8, step1153]: loss 4.794776
[epoch8, step1154]: loss 2.259367
[epoch8, step1155]: loss 11.130781
[epoch8, step1156]: loss 2.836889
[epoch8, step1157]: loss 14.804869
[epoch8, step1158]: loss 2.962092
[epoch8, step1159]: loss 2.150050
[epoch8, step1160]: loss 1.853045
[epoch8, step1161]: loss 2.074326
[epoch8, step1162]: loss 4.462667
[epoch8, step1163]: loss 1.754718
[epoch8, step1164]: loss 12.722985
[epoch8, step1165]: loss 8.433839
[epoch8, step1166]: loss 3.387502
[epoch8, step1167]: loss 1.824318
[epoch8, step1168]: loss 7.544909
[epoch8, step1169]: loss 5.115282
[epoch8, step1170]: loss 1.294726
[epoch8, step1171]: loss 5.634429
[epoch8, step1172]: loss 22.063150
[epoch8, step1173]: loss 22.078665
[epoch8, step1174]: loss 5.476385
[epoch8, step1175]: loss 3.717238
[epoch8, step1176]: loss 16.869244
[epoch8, step1177]: loss 7.540927
[epoch8, step1178]: loss 2.846941
[epoch8, step1179]: loss 10.426644
[epoch8, step1180]: loss 6.550114
[epoch8, step1181]: loss 1.496433
[epoch8, step1182]: loss 3.269295
[epoch8, step1183]: loss 19.015142
[epoch8, step1184]: loss 2.638019
[epoch8, step1185]: loss 2.265753
[epoch8, step1186]: loss 2.973672
[epoch8, step1187]: loss 1.611738
[epoch8, step1188]: loss 4.353653
[epoch8, step1189]: loss 3.241553
[epoch8, step1190]: loss 35.455883
[epoch8, step1191]: loss 19.324869
[epoch8, step1192]: loss 15.105309
[epoch8, step1193]: loss 8.217511
[epoch8, step1194]: loss 3.005150
[epoch8, step1195]: loss 2.977355
[epoch8, step1196]: loss 43.029091
[epoch8, step1197]: loss 2.246185
[epoch8, step1198]: loss 1.680651
[epoch8, step1199]: loss 2.499399
[epoch8, step1200]: loss 7.492670
[epoch8, step1201]: loss 2.860579
[epoch8, step1202]: loss 1.991682
[epoch8, step1203]: loss 1.674941
[epoch8, step1204]: loss 1.363520
[epoch8, step1205]: loss 3.106472
[epoch8, step1206]: loss 2.296832
[epoch8, step1207]: loss 2.947676
[epoch8, step1208]: loss 12.754664
[epoch8, step1209]: loss 6.262766
[epoch8, step1210]: loss 2.524221
[epoch8, step1211]: loss 7.202774
[epoch8, step1212]: loss 2.290696
[epoch8, step1213]: loss 1.736217
[epoch8, step1214]: loss 2.556442
[epoch8, step1215]: loss 5.319999
[epoch8, step1216]: loss 1.646654
[epoch8, step1217]: loss 1.996707
[epoch8, step1218]: loss 39.203720
[epoch8, step1219]: loss 3.661811
[epoch8, step1220]: loss 3.590803
[epoch8, step1221]: loss 2.138233
[epoch8, step1222]: loss 3.048758
[epoch8, step1223]: loss 1.853186
[epoch8, step1224]: loss 3.973939
[epoch8, step1225]: loss 1.041005
[epoch8, step1226]: loss 3.805740
[epoch8, step1227]: loss 4.030771
[epoch8, step1228]: loss 2.849357
[epoch8, step1229]: loss 1.613093
[epoch8, step1230]: loss 2.202385
[epoch8, step1231]: loss 2.871644
[epoch8, step1232]: loss 2.233373
[epoch8, step1233]: loss 14.688574
[epoch8, step1234]: loss 1.145660
[epoch8, step1235]: loss 10.729946
[epoch8, step1236]: loss 3.567093
[epoch8, step1237]: loss 1.204314
[epoch8, step1238]: loss 4.349599
[epoch8, step1239]: loss 2.466933
[epoch8, step1240]: loss 1.393326
[epoch8, step1241]: loss 3.115220
[epoch8, step1242]: loss 6.968252
[epoch8, step1243]: loss 17.790615
[epoch8, step1244]: loss 12.789968
[epoch8, step1245]: loss 6.188237
[epoch8, step1246]: loss 1.639185
[epoch8, step1247]: loss 1.564099
[epoch8, step1248]: loss 1.502492
[epoch8, step1249]: loss 1.655768
[epoch8, step1250]: loss 5.783789
[epoch8, step1251]: loss 1.489506
[epoch8, step1252]: loss 2.249236
[epoch8, step1253]: loss 1.845360
[epoch8, step1254]: loss 3.156163
[epoch8, step1255]: loss 9.239127
[epoch8, step1256]: loss 11.806244
[epoch8, step1257]: loss 1.777543
[epoch8, step1258]: loss 15.103599
[epoch8, step1259]: loss 15.836501
[epoch8, step1260]: loss 1.300038
[epoch8, step1261]: loss 1.341246
[epoch8, step1262]: loss 2.347789
[epoch8, step1263]: loss 12.091960
[epoch8, step1264]: loss 1.231786
[epoch8, step1265]: loss 5.823878
[epoch8, step1266]: loss 17.762066
[epoch8, step1267]: loss 3.632212
[epoch8, step1268]: loss 1.534339
[epoch8, step1269]: loss 5.853057
[epoch8, step1270]: loss 3.318413
[epoch8, step1271]: loss 23.107141
[epoch8, step1272]: loss 1.887534
[epoch8, step1273]: loss 9.289759
[epoch8, step1274]: loss 16.095745
[epoch8, step1275]: loss 2.151861
[epoch8, step1276]: loss 5.993223
[epoch8, step1277]: loss 6.098267
[epoch8, step1278]: loss 7.237770
[epoch8, step1279]: loss 1.486141
[epoch8, step1280]: loss 1.310783
[epoch8, step1281]: loss 2.919414
[epoch8, step1282]: loss 1.792795
[epoch8, step1283]: loss 3.746338
[epoch8, step1284]: loss 2.171445
[epoch8, step1285]: loss 1.244556
[epoch8, step1286]: loss 18.842304
[epoch8, step1287]: loss 2.745729
[epoch8, step1288]: loss 17.312386
[epoch8, step1289]: loss 18.899790
[epoch8, step1290]: loss 2.294979
[epoch8, step1291]: loss 6.256282
[epoch8, step1292]: loss 4.360398
[epoch8, step1293]: loss 1.370584
[epoch8, step1294]: loss 3.317691
[epoch8, step1295]: loss 6.324687
[epoch8, step1296]: loss 1.524153
[epoch8, step1297]: loss 3.887199
[epoch8, step1298]: loss 20.409380
[epoch8, step1299]: loss 2.506836
[epoch8, step1300]: loss 3.496954
[epoch8, step1301]: loss 2.459645
[epoch8, step1302]: loss 10.493917
[epoch8, step1303]: loss 2.140142
[epoch8, step1304]: loss 2.837062
[epoch8, step1305]: loss 4.471215
[epoch8, step1306]: loss 3.463445
[epoch8, step1307]: loss 1.843009
[epoch8, step1308]: loss 23.389690
[epoch8, step1309]: loss 21.161476
[epoch8, step1310]: loss 1.864775
[epoch8, step1311]: loss 17.959156
[epoch8, step1312]: loss 7.018176
[epoch8, step1313]: loss 1.666981
[epoch8, step1314]: loss 19.425016
[epoch8, step1315]: loss 1.676619
[epoch8, step1316]: loss 15.075153
[epoch8, step1317]: loss 2.076917
[epoch8, step1318]: loss 2.595505
[epoch8, step1319]: loss 9.683278
[epoch8, step1320]: loss 9.134473
[epoch8, step1321]: loss 3.838118
[epoch8, step1322]: loss 10.432467
[epoch8, step1323]: loss 11.364876
[epoch8, step1324]: loss 3.038945
[epoch8, step1325]: loss 3.082368
[epoch8, step1326]: loss 27.627451
[epoch8, step1327]: loss 3.410590
[epoch8, step1328]: loss 18.089884
[epoch8, step1329]: loss 3.769941
[epoch8, step1330]: loss 3.186797
[epoch8, step1331]: loss 16.343931
[epoch8, step1332]: loss 17.662161
[epoch8, step1333]: loss 3.104920
[epoch8, step1334]: loss 2.966461
[epoch8, step1335]: loss 3.522755
[epoch8, step1336]: loss 5.252062
[epoch8, step1337]: loss 14.975883
[epoch8, step1338]: loss 1.713790
[epoch8, step1339]: loss 2.482147
[epoch8, step1340]: loss 14.100223
[epoch8, step1341]: loss 1.868937
[epoch8, step1342]: loss 2.732322
[epoch8, step1343]: loss 2.340457
[epoch8, step1344]: loss 1.146257
[epoch8, step1345]: loss 2.222308
[epoch8, step1346]: loss 2.022804
[epoch8, step1347]: loss 2.703760
[epoch8, step1348]: loss 1.467165
[epoch8, step1349]: loss 1.895699
[epoch8, step1350]: loss 3.713791
[epoch8, step1351]: loss 7.304635
[epoch8, step1352]: loss 1.423943
[epoch8, step1353]: loss 1.389321
[epoch8, step1354]: loss 2.887882
[epoch8, step1355]: loss 6.092161
[epoch8, step1356]: loss 5.963005
[epoch8, step1357]: loss 40.758686
[epoch8, step1358]: loss 19.429565
[epoch8, step1359]: loss 1.975684
[epoch8, step1360]: loss 2.592302
[epoch8, step1361]: loss 24.821007
[epoch8, step1362]: loss 1.642035
[epoch8, step1363]: loss 6.263986
[epoch8, step1364]: loss 1.186632
[epoch8, step1365]: loss 15.762524
[epoch8, step1366]: loss 3.845096
[epoch8, step1367]: loss 1.303630
[epoch8, step1368]: loss 2.089755
[epoch8, step1369]: loss 18.756010
[epoch8, step1370]: loss 29.175018
[epoch8, step1371]: loss 1.612800
[epoch8, step1372]: loss 17.030855
[epoch8, step1373]: loss 7.554979
[epoch8, step1374]: loss 4.728478
[epoch8, step1375]: loss 9.818022
[epoch8, step1376]: loss 1.337689
[epoch8, step1377]: loss 2.296889
[epoch8, step1378]: loss 3.678348
[epoch8, step1379]: loss 2.360942
[epoch8, step1380]: loss 9.976422
[epoch8, step1381]: loss 9.301682
[epoch8, step1382]: loss 29.747648
[epoch8, step1383]: loss 2.289985
[epoch8, step1384]: loss 16.659239
[epoch8, step1385]: loss 2.663351
[epoch8, step1386]: loss 2.770975
[epoch8, step1387]: loss 4.322188
[epoch8, step1388]: loss 3.533981
[epoch8, step1389]: loss 19.807529
[epoch8, step1390]: loss 2.516968
[epoch8, step1391]: loss 5.105478
[epoch8, step1392]: loss 23.334230
[epoch8, step1393]: loss 26.231016
[epoch8, step1394]: loss 1.136791
[epoch8, step1395]: loss 30.761412
[epoch8, step1396]: loss 7.204237
[epoch8, step1397]: loss 3.913910
[epoch8, step1398]: loss 2.245668
[epoch8, step1399]: loss 6.042089
[epoch8, step1400]: loss 16.538557
[epoch8, step1401]: loss 2.281595
[epoch8, step1402]: loss 21.393766
[epoch8, step1403]: loss 2.073411
[epoch8, step1404]: loss 1.791844
[epoch8, step1405]: loss 21.279484
[epoch8, step1406]: loss 6.635219
[epoch8, step1407]: loss 6.388856
[epoch8, step1408]: loss 12.650826
[epoch8, step1409]: loss 31.581747
[epoch8, step1410]: loss 11.298338
[epoch8, step1411]: loss 7.227919
[epoch8, step1412]: loss 1.738393
[epoch8, step1413]: loss 1.408113
[epoch8, step1414]: loss 4.036434
[epoch8, step1415]: loss 15.511692
[epoch8, step1416]: loss 1.635410
[epoch8, step1417]: loss 2.160536
[epoch8, step1418]: loss 1.563873
[epoch8, step1419]: loss 1.316572
[epoch8, step1420]: loss 1.082071
[epoch8, step1421]: loss 2.721686
[epoch8, step1422]: loss 3.263911
[epoch8, step1423]: loss 1.607952
[epoch8, step1424]: loss 2.131126
[epoch8, step1425]: loss 16.101963
[epoch8, step1426]: loss 1.588433
[epoch8, step1427]: loss 22.341198
[epoch8, step1428]: loss 35.341999
[epoch8, step1429]: loss 2.301420
[epoch8, step1430]: loss 20.072336
[epoch8, step1431]: loss 1.624082
[epoch8, step1432]: loss 1.215748
[epoch8, step1433]: loss 1.423941
[epoch8, step1434]: loss 1.871781
[epoch8, step1435]: loss 19.428009
[epoch8, step1436]: loss 3.355579
[epoch8, step1437]: loss 2.356793
[epoch8, step1438]: loss 3.198980
[epoch8, step1439]: loss 2.622454
[epoch8, step1440]: loss 1.229865
[epoch8, step1441]: loss 3.791757
[epoch8, step1442]: loss 1.874219
[epoch8, step1443]: loss 8.192719
[epoch8, step1444]: loss 2.855251
[epoch8, step1445]: loss 10.786142
[epoch8, step1446]: loss 2.995979
[epoch8, step1447]: loss 4.132115
[epoch8, step1448]: loss 21.225657
[epoch8, step1449]: loss 1.931244
[epoch8, step1450]: loss 14.147991
[epoch8, step1451]: loss 3.359621
[epoch8, step1452]: loss 1.109388
[epoch8, step1453]: loss 7.498872
[epoch8, step1454]: loss 44.679604
[epoch8, step1455]: loss 2.240019
[epoch8, step1456]: loss 16.747351
[epoch8, step1457]: loss 1.846485
[epoch8, step1458]: loss 4.201607
[epoch8, step1459]: loss 3.014839
[epoch8, step1460]: loss 2.802619
[epoch8, step1461]: loss 2.187537
[epoch8, step1462]: loss 17.597305
[epoch8, step1463]: loss 16.702597
[epoch8, step1464]: loss 23.315214
[epoch8, step1465]: loss 7.640277
[epoch8, step1466]: loss 14.691925
[epoch8, step1467]: loss 2.274370
[epoch8, step1468]: loss 1.440778
[epoch8, step1469]: loss 1.302352
[epoch8, step1470]: loss 1.619936
[epoch8, step1471]: loss 1.237203
[epoch8, step1472]: loss 2.371118
[epoch8, step1473]: loss 2.994908
[epoch8, step1474]: loss 15.565276
[epoch8, step1475]: loss 3.796196
[epoch8, step1476]: loss 1.788907
[epoch8, step1477]: loss 11.845936
[epoch8, step1478]: loss 1.084515
[epoch8, step1479]: loss 7.614027
[epoch8, step1480]: loss 3.497405
[epoch8, step1481]: loss 4.273607
[epoch8, step1482]: loss 1.725388
[epoch8, step1483]: loss 3.206688
[epoch8, step1484]: loss 6.732132
[epoch8, step1485]: loss 22.734844
[epoch8, step1486]: loss 2.524215
[epoch8, step1487]: loss 1.335332
[epoch8, step1488]: loss 16.766378
[epoch8, step1489]: loss 2.277308
[epoch8, step1490]: loss 18.706961
[epoch8, step1491]: loss 15.484570
[epoch8, step1492]: loss 31.157173
[epoch8, step1493]: loss 2.352667
[epoch8, step1494]: loss 21.910624
[epoch8, step1495]: loss 11.329231
[epoch8, step1496]: loss 1.600560
[epoch8, step1497]: loss 3.095991
[epoch8, step1498]: loss 6.477784
[epoch8, step1499]: loss 3.290032
[epoch8, step1500]: loss 3.052845
[epoch8, step1501]: loss 2.851764
[epoch8, step1502]: loss 3.798909
[epoch8, step1503]: loss 22.499849
[epoch8, step1504]: loss 3.596862
[epoch8, step1505]: loss 5.493713
[epoch8, step1506]: loss 6.553202
[epoch8, step1507]: loss 12.968280
[epoch8, step1508]: loss 2.009190
[epoch8, step1509]: loss 18.211113
[epoch8, step1510]: loss 24.273846
[epoch8, step1511]: loss 2.725067
[epoch8, step1512]: loss 2.024431
[epoch8, step1513]: loss 26.888052
[epoch8, step1514]: loss 2.578593
[epoch8, step1515]: loss 18.466227
[epoch8, step1516]: loss 19.113140
[epoch8, step1517]: loss 2.037269
[epoch8, step1518]: loss 14.088405
[epoch8, step1519]: loss 8.437945
[epoch8, step1520]: loss 14.937931
[epoch8, step1521]: loss 1.621871
[epoch8, step1522]: loss 2.640635
[epoch8, step1523]: loss 21.858662
[epoch8, step1524]: loss 2.253527
[epoch8, step1525]: loss 1.534324
[epoch8, step1526]: loss 4.098838
[epoch8, step1527]: loss 6.739884
[epoch8, step1528]: loss 31.194485
[epoch8, step1529]: loss 17.509598
[epoch8, step1530]: loss 16.475119
[epoch8, step1531]: loss 1.639549
[epoch8, step1532]: loss 7.067827
[epoch8, step1533]: loss 1.854293
[epoch8, step1534]: loss 20.283176
[epoch8, step1535]: loss 13.523670
[epoch8, step1536]: loss 7.101139
[epoch8, step1537]: loss 14.660597
[epoch8, step1538]: loss 20.473606
[epoch8, step1539]: loss 7.591961
[epoch8, step1540]: loss 8.942171
[epoch8, step1541]: loss 4.299018
[epoch8, step1542]: loss 2.176445
[epoch8, step1543]: loss 3.127616
[epoch8, step1544]: loss 16.289917
[epoch8, step1545]: loss 3.423560
[epoch8, step1546]: loss 1.838031
[epoch8, step1547]: loss 29.688692
[epoch8, step1548]: loss 7.061030
[epoch8, step1549]: loss 2.637783
[epoch8, step1550]: loss 3.463467
[epoch8, step1551]: loss 17.566416
[epoch8, step1552]: loss 8.291021
[epoch8, step1553]: loss 5.048590
[epoch8, step1554]: loss 2.281459
[epoch8, step1555]: loss 13.758978
[epoch8, step1556]: loss 16.742773
[epoch8, step1557]: loss 3.249263
[epoch8, step1558]: loss 21.314371
[epoch8, step1559]: loss 3.078115
[epoch8, step1560]: loss 28.814320
[epoch8, step1561]: loss 2.904272
[epoch8, step1562]: loss 5.189500
[epoch8, step1563]: loss 23.866783
[epoch8, step1564]: loss 2.855721
[epoch8, step1565]: loss 2.658456
[epoch8, step1566]: loss 1.901222
[epoch8, step1567]: loss 4.340245
[epoch8, step1568]: loss 3.056964
[epoch8, step1569]: loss 1.633660
[epoch8, step1570]: loss 1.445309
[epoch8, step1571]: loss 2.270904
[epoch8, step1572]: loss 23.455956
[epoch8, step1573]: loss 1.546668
[epoch8, step1574]: loss 3.151043
[epoch8, step1575]: loss 1.548988
[epoch8, step1576]: loss 2.933586
[epoch8, step1577]: loss 5.596340
[epoch8, step1578]: loss 2.201055
[epoch8, step1579]: loss 12.112623
[epoch8, step1580]: loss 2.555983
[epoch8, step1581]: loss 2.366118
[epoch8, step1582]: loss 1.346900
[epoch8, step1583]: loss 4.938296
[epoch8, step1584]: loss 16.685360
[epoch8, step1585]: loss 13.214450
[epoch8, step1586]: loss 18.177057
[epoch8, step1587]: loss 13.277168
[epoch8, step1588]: loss 2.285201
[epoch8, step1589]: loss 1.952224
[epoch8, step1590]: loss 4.754688
[epoch8, step1591]: loss 2.206131
[epoch8, step1592]: loss 3.271050
[epoch8, step1593]: loss 4.253672
[epoch8, step1594]: loss 3.267773
[epoch8, step1595]: loss 6.101254
[epoch8, step1596]: loss 1.881020
[epoch8, step1597]: loss 3.168541
[epoch8, step1598]: loss 1.410666
[epoch8, step1599]: loss 1.398800
[epoch8, step1600]: loss 17.596027
[epoch8, step1601]: loss 15.358877
[epoch8, step1602]: loss 2.159171
[epoch8, step1603]: loss 2.217105
[epoch8, step1604]: loss 4.018762
[epoch8, step1605]: loss 11.698821
[epoch8, step1606]: loss 1.679939
[epoch8, step1607]: loss 2.660704
[epoch8, step1608]: loss 2.622483
[epoch8, step1609]: loss 1.883165
[epoch8, step1610]: loss 3.183644
[epoch8, step1611]: loss 6.450304
[epoch8, step1612]: loss 14.060886
[epoch8, step1613]: loss 1.246233
[epoch8, step1614]: loss 2.025620
[epoch8, step1615]: loss 14.997770
[epoch8, step1616]: loss 2.097390
[epoch8, step1617]: loss 17.800333
[epoch8, step1618]: loss 20.484404
[epoch8, step1619]: loss 2.177036
[epoch8, step1620]: loss 16.653271
[epoch8, step1621]: loss 2.668813
[epoch8, step1622]: loss 3.921210
[epoch8, step1623]: loss 1.376097
[epoch8, step1624]: loss 4.575195
[epoch8, step1625]: loss 3.776552
[epoch8, step1626]: loss 3.323002
[epoch8, step1627]: loss 1.830724
[epoch8, step1628]: loss 20.052090
[epoch8, step1629]: loss 1.202032
[epoch8, step1630]: loss 11.497302
[epoch8, step1631]: loss 15.676259
[epoch8, step1632]: loss 1.324259
[epoch8, step1633]: loss 2.540607
[epoch8, step1634]: loss 7.108438
[epoch8, step1635]: loss 1.229122
[epoch8, step1636]: loss 1.794343
[epoch8, step1637]: loss 1.367612
[epoch8, step1638]: loss 3.634186
[epoch8, step1639]: loss 19.407616
[epoch8, step1640]: loss 3.937967
[epoch8, step1641]: loss 8.094551
[epoch8, step1642]: loss 2.292873
[epoch8, step1643]: loss 1.994018
[epoch8, step1644]: loss 6.626141
[epoch8, step1645]: loss 5.502054
[epoch8, step1646]: loss 2.499527
[epoch8, step1647]: loss 19.164267
[epoch8, step1648]: loss 2.359984
[epoch8, step1649]: loss 2.935786
[epoch8, step1650]: loss 4.053362
[epoch8, step1651]: loss 1.976425
[epoch8, step1652]: loss 20.589931
[epoch8, step1653]: loss 1.823863
[epoch8, step1654]: loss 2.013314
[epoch8, step1655]: loss 4.139151
[epoch8, step1656]: loss 7.654869
[epoch8, step1657]: loss 24.175077
[epoch8, step1658]: loss 21.189405
[epoch8, step1659]: loss 10.643996
[epoch8, step1660]: loss 7.426021
[epoch8, step1661]: loss 8.512803
[epoch8, step1662]: loss 5.672228
[epoch8, step1663]: loss 23.161602
[epoch8, step1664]: loss 6.347052
[epoch8, step1665]: loss 20.743109
[epoch8, step1666]: loss 3.789004
[epoch8, step1667]: loss 2.855746
[epoch8, step1668]: loss 10.213305
[epoch8, step1669]: loss 8.183308
[epoch8, step1670]: loss 2.250776
[epoch8, step1671]: loss 10.996743
[epoch8, step1672]: loss 16.359684
[epoch8, step1673]: loss 2.628762
[epoch8, step1674]: loss 3.850661
[epoch8, step1675]: loss 14.338314
[epoch8, step1676]: loss 30.344536
[epoch8, step1677]: loss 2.013040
[epoch8, step1678]: loss 4.396928
[epoch8, step1679]: loss 2.068238
[epoch8, step1680]: loss 6.715799
[epoch8, step1681]: loss 3.847542
[epoch8, step1682]: loss 2.309038
[epoch8, step1683]: loss 9.975472
[epoch8, step1684]: loss 5.456871
[epoch8, step1685]: loss 8.419022
[epoch8, step1686]: loss 3.371454
[epoch8, step1687]: loss 1.263824
[epoch8, step1688]: loss 1.769574
[epoch8, step1689]: loss 1.604890
[epoch8, step1690]: loss 3.526024
[epoch8, step1691]: loss 3.105030
[epoch8, step1692]: loss 1.083469
[epoch8, step1693]: loss 2.393975
[epoch8, step1694]: loss 2.440323
[epoch8, step1695]: loss 1.283643
[epoch8, step1696]: loss 8.511467
[epoch8, step1697]: loss 1.621231
[epoch8, step1698]: loss 15.726975
[epoch8, step1699]: loss 2.802643
[epoch8, step1700]: loss 1.541350
[epoch8, step1701]: loss 3.837244
[epoch8, step1702]: loss 1.375262
[epoch8, step1703]: loss 20.862648
[epoch8, step1704]: loss 23.651588
[epoch8, step1705]: loss 16.630672
[epoch8, step1706]: loss 1.346420
[epoch8, step1707]: loss 3.063792
[epoch8, step1708]: loss 4.099566
[epoch8, step1709]: loss 6.567900
[epoch8, step1710]: loss 5.144794
[epoch8, step1711]: loss 1.493226
[epoch8, step1712]: loss 1.364421
[epoch8, step1713]: loss 3.283039
[epoch8, step1714]: loss 1.014821
[epoch8, step1715]: loss 3.493591
[epoch8, step1716]: loss 3.704720
[epoch8, step1717]: loss 4.919200
[epoch8, step1718]: loss 3.799245
[epoch8, step1719]: loss 4.526631
[epoch8, step1720]: loss 1.640493
[epoch8, step1721]: loss 2.037698
[epoch8, step1722]: loss 2.269550
[epoch8, step1723]: loss 7.653036
[epoch8, step1724]: loss 2.542823
[epoch8, step1725]: loss 1.934950
[epoch8, step1726]: loss 21.081570
[epoch8, step1727]: loss 23.503111
[epoch8, step1728]: loss 31.226826
[epoch8, step1729]: loss 1.992165
[epoch8, step1730]: loss 5.591006
[epoch8, step1731]: loss 3.378137
[epoch8, step1732]: loss 1.695371
[epoch8, step1733]: loss 2.024730
[epoch8, step1734]: loss 1.347057
[epoch8, step1735]: loss 3.755313
[epoch8, step1736]: loss 2.073684
[epoch8, step1737]: loss 15.056521
[epoch8, step1738]: loss 2.084302
[epoch8, step1739]: loss 1.145932
[epoch8, step1740]: loss 1.760725
[epoch8, step1741]: loss 4.549469
[epoch8, step1742]: loss 13.954808
[epoch8, step1743]: loss 25.982410
[epoch8, step1744]: loss 1.531447
[epoch8, step1745]: loss 1.608591
[epoch8, step1746]: loss 22.779724
[epoch8, step1747]: loss 5.312271
[epoch8, step1748]: loss 2.545159
[epoch8, step1749]: loss 14.987401
[epoch8, step1750]: loss 19.692402
[epoch8, step1751]: loss 27.647079
[epoch8, step1752]: loss 15.689662
[epoch8, step1753]: loss 2.927694
[epoch8, step1754]: loss 34.623848
[epoch8, step1755]: loss 5.414820
[epoch8, step1756]: loss 2.279053
[epoch8, step1757]: loss 6.576620
[epoch8, step1758]: loss 1.112212
[epoch8, step1759]: loss 0.909745
[epoch8, step1760]: loss 3.541026
[epoch8, step1761]: loss 17.014391
[epoch8, step1762]: loss 1.682722
[epoch8, step1763]: loss 2.956235
[epoch8, step1764]: loss 4.609826
[epoch8, step1765]: loss 3.350124
[epoch8, step1766]: loss 7.428073
[epoch8, step1767]: loss 2.906515
[epoch8, step1768]: loss 16.380465
[epoch8, step1769]: loss 7.365736
[epoch8, step1770]: loss 1.859323
[epoch8, step1771]: loss 4.620191
[epoch8, step1772]: loss 3.448019
[epoch8, step1773]: loss 1.355218
[epoch8, step1774]: loss 3.292724
[epoch8, step1775]: loss 8.064687
[epoch8, step1776]: loss 25.987465
[epoch8, step1777]: loss 2.535610
[epoch8, step1778]: loss 4.188280
[epoch8, step1779]: loss 3.784250
[epoch8, step1780]: loss 1.809148
[epoch8, step1781]: loss 5.092430
[epoch8, step1782]: loss 5.076353
[epoch8, step1783]: loss 4.025066
[epoch8, step1784]: loss 17.842566
[epoch8, step1785]: loss 2.863811
[epoch8, step1786]: loss 2.454323
[epoch8, step1787]: loss 4.135762
[epoch8, step1788]: loss 1.445714
[epoch8, step1789]: loss 2.181567
[epoch8, step1790]: loss 1.176044
[epoch8, step1791]: loss 16.428097
[epoch8, step1792]: loss 2.527790
[epoch8, step1793]: loss 3.695741
[epoch8, step1794]: loss 2.596060
[epoch8, step1795]: loss 1.708248
[epoch8, step1796]: loss 1.692816
[epoch8, step1797]: loss 2.152720
[epoch8, step1798]: loss 1.774703
[epoch8, step1799]: loss 1.559128
[epoch8, step1800]: loss 17.016756
[epoch8, step1801]: loss 3.149579
[epoch8, step1802]: loss 5.922289
[epoch8, step1803]: loss 15.219809
[epoch8, step1804]: loss 13.743189
[epoch8, step1805]: loss 12.771891
[epoch8, step1806]: loss 10.746078
[epoch8, step1807]: loss 4.416387
[epoch8, step1808]: loss 1.317642
[epoch8, step1809]: loss 2.762974
[epoch8, step1810]: loss 4.046661
[epoch8, step1811]: loss 2.127959
[epoch8, step1812]: loss 17.744144
[epoch8, step1813]: loss 1.757684
[epoch8, step1814]: loss 2.136219
[epoch8, step1815]: loss 13.117420
[epoch8, step1816]: loss 7.043262
[epoch8, step1817]: loss 2.841842
[epoch8, step1818]: loss 4.159893
[epoch8, step1819]: loss 25.762947
[epoch8, step1820]: loss 16.446413
[epoch8, step1821]: loss 2.790555
[epoch8, step1822]: loss 21.281170
[epoch8, step1823]: loss 6.602138
[epoch8, step1824]: loss 1.083119
[epoch8, step1825]: loss 2.834405
[epoch8, step1826]: loss 1.222901
[epoch8, step1827]: loss 22.090633
[epoch8, step1828]: loss 2.514281
[epoch8, step1829]: loss 1.812976
[epoch8, step1830]: loss 10.921884
[epoch8, step1831]: loss 2.606638
[epoch8, step1832]: loss 22.251158
[epoch8, step1833]: loss 2.922782
[epoch8, step1834]: loss 20.902426
[epoch8, step1835]: loss 16.458229
[epoch8, step1836]: loss 25.447775
[epoch8, step1837]: loss 3.014598
[epoch8, step1838]: loss 2.035007
[epoch8, step1839]: loss 20.376909
[epoch8, step1840]: loss 13.649014
[epoch8, step1841]: loss 14.896206
[epoch8, step1842]: loss 10.185740
[epoch8, step1843]: loss 3.538268
[epoch8, step1844]: loss 4.180351
[epoch8, step1845]: loss 18.330927
[epoch8, step1846]: loss 4.903389
[epoch8, step1847]: loss 1.466612
[epoch8, step1848]: loss 18.870609
[epoch8, step1849]: loss 4.176377
[epoch8, step1850]: loss 5.839742
[epoch8, step1851]: loss 4.625917
[epoch8, step1852]: loss 5.789589
[epoch8, step1853]: loss 4.941582
[epoch8, step1854]: loss 3.850517
[epoch8, step1855]: loss 6.550783
[epoch8, step1856]: loss 2.179905
[epoch8, step1857]: loss 4.816438
[epoch8, step1858]: loss 5.371484
[epoch8, step1859]: loss 3.808335
[epoch8, step1860]: loss 4.580796
[epoch8, step1861]: loss 19.086201
[epoch8, step1862]: loss 2.791780
[epoch8, step1863]: loss 2.533733
[epoch8, step1864]: loss 2.540569
[epoch8, step1865]: loss 1.702406
[epoch8, step1866]: loss 3.441308
[epoch8, step1867]: loss 3.461447
[epoch8, step1868]: loss 2.577663
[epoch8, step1869]: loss 8.034182
[epoch8, step1870]: loss 2.657116
[epoch8, step1871]: loss 17.776966
[epoch8, step1872]: loss 15.878591
[epoch8, step1873]: loss 1.995702
[epoch8, step1874]: loss 1.458684
[epoch8, step1875]: loss 8.103002
[epoch8, step1876]: loss 22.420603
[epoch8, step1877]: loss 3.449977
[epoch8, step1878]: loss 9.091174
[epoch8, step1879]: loss 9.805991
[epoch8, step1880]: loss 2.704467
[epoch8, step1881]: loss 1.172802
[epoch8, step1882]: loss 15.484831
[epoch8, step1883]: loss 2.066609
[epoch8, step1884]: loss 3.029546
[epoch8, step1885]: loss 17.342880
[epoch8, step1886]: loss 3.570076
[epoch8, step1887]: loss 4.493509
[epoch8, step1888]: loss 2.094029
[epoch8, step1889]: loss 1.525535
[epoch8, step1890]: loss 1.668869
[epoch8, step1891]: loss 5.416312
[epoch8, step1892]: loss 2.173235
[epoch8, step1893]: loss 2.594320
[epoch8, step1894]: loss 4.637507
[epoch8, step1895]: loss 3.367914
[epoch8, step1896]: loss 15.500021
[epoch8, step1897]: loss 4.199593
[epoch8, step1898]: loss 16.183451
[epoch8, step1899]: loss 1.231196
[epoch8, step1900]: loss 13.573977
[epoch8, step1901]: loss 21.847519
[epoch8, step1902]: loss 2.963721
[epoch8, step1903]: loss 6.152832
[epoch8, step1904]: loss 1.566909
[epoch8, step1905]: loss 22.712605
[epoch8, step1906]: loss 2.097962
[epoch8, step1907]: loss 14.227914
[epoch8, step1908]: loss 7.051069
[epoch8, step1909]: loss 17.299368
[epoch8, step1910]: loss 6.654955
[epoch8, step1911]: loss 14.943534
[epoch8, step1912]: loss 5.732092
[epoch8, step1913]: loss 1.539734
[epoch8, step1914]: loss 2.043758
[epoch8, step1915]: loss 1.744177
[epoch8, step1916]: loss 5.997087
[epoch8, step1917]: loss 6.978220
[epoch8, step1918]: loss 3.063505
[epoch8, step1919]: loss 8.161376
[epoch8, step1920]: loss 15.781373
[epoch8, step1921]: loss 18.289764
[epoch8, step1922]: loss 1.346702
[epoch8, step1923]: loss 1.411065
[epoch8, step1924]: loss 1.826901
[epoch8, step1925]: loss 1.475736
[epoch8, step1926]: loss 1.020597
[epoch8, step1927]: loss 2.148598
[epoch8, step1928]: loss 0.768344
[epoch8, step1929]: loss 5.178126
[epoch8, step1930]: loss 6.267161
[epoch8, step1931]: loss 1.404539
[epoch8, step1932]: loss 2.561345
[epoch8, step1933]: loss 1.608974
[epoch8, step1934]: loss 3.467715
[epoch8, step1935]: loss 3.286359
[epoch8, step1936]: loss 1.046940
[epoch8, step1937]: loss 1.415437
[epoch8, step1938]: loss 9.935894
[epoch8, step1939]: loss 2.346453
[epoch8, step1940]: loss 2.345990
[epoch8, step1941]: loss 6.805552
[epoch8, step1942]: loss 14.992070
[epoch8, step1943]: loss 1.791815
[epoch8, step1944]: loss 19.174017
[epoch8, step1945]: loss 10.022463
[epoch8, step1946]: loss 2.203254
[epoch8, step1947]: loss 3.107460
[epoch8, step1948]: loss 0.996190
[epoch8, step1949]: loss 1.603303
[epoch8, step1950]: loss 3.373145
[epoch8, step1951]: loss 3.868430
[epoch8, step1952]: loss 3.530892
[epoch8, step1953]: loss 6.799044
[epoch8, step1954]: loss 1.458027
[epoch8, step1955]: loss 1.604822
[epoch8, step1956]: loss 13.713236
[epoch8, step1957]: loss 2.986865
[epoch8, step1958]: loss 7.060352
[epoch8, step1959]: loss 7.823366
[epoch8, step1960]: loss 13.755522
[epoch8, step1961]: loss 2.893732
[epoch8, step1962]: loss 1.344956
[epoch8, step1963]: loss 17.391491
[epoch8, step1964]: loss 3.886087
[epoch8, step1965]: loss 14.399327
[epoch8, step1966]: loss 17.901327
[epoch8, step1967]: loss 1.847162
[epoch8, step1968]: loss 3.158429
[epoch8, step1969]: loss 4.819223
[epoch8, step1970]: loss 2.001200
[epoch8, step1971]: loss 21.658890
[epoch8, step1972]: loss 3.136095
[epoch8, step1973]: loss 23.749409
[epoch8, step1974]: loss 30.164450
[epoch8, step1975]: loss 1.874586
[epoch8, step1976]: loss 2.187098
[epoch8, step1977]: loss 1.437617
[epoch8, step1978]: loss 3.976232
[epoch8, step1979]: loss 4.384879
[epoch8, step1980]: loss 1.399930
[epoch8, step1981]: loss 3.790804
[epoch8, step1982]: loss 3.232530
[epoch8, step1983]: loss 2.511862
[epoch8, step1984]: loss 10.532186
[epoch8, step1985]: loss 24.977491
[epoch8, step1986]: loss 6.446151
[epoch8, step1987]: loss 3.760334
[epoch8, step1988]: loss 2.115617
[epoch8, step1989]: loss 2.277788
[epoch8, step1990]: loss 5.521405
[epoch8, step1991]: loss 5.337780
[epoch8, step1992]: loss 1.409747
[epoch8, step1993]: loss 1.151973
[epoch8, step1994]: loss 4.611636
[epoch8, step1995]: loss 4.142183
[epoch8, step1996]: loss 2.571147
[epoch8, step1997]: loss 2.758944
[epoch8, step1998]: loss 1.790624
[epoch8, step1999]: loss 0.954369
[epoch8, step2000]: loss 2.873024
[epoch8, step2001]: loss 19.727163
[epoch8, step2002]: loss 1.191474
[epoch8, step2003]: loss 1.556007
[epoch8, step2004]: loss 1.716317
[epoch8, step2005]: loss 5.778043
[epoch8, step2006]: loss 3.388008
[epoch8, step2007]: loss 5.362733
[epoch8, step2008]: loss 1.814452
[epoch8, step2009]: loss 16.682329
[epoch8, step2010]: loss 3.180048
[epoch8, step2011]: loss 2.045097
[epoch8, step2012]: loss 1.462031
[epoch8, step2013]: loss 4.835166
[epoch8, step2014]: loss 3.995301
[epoch8, step2015]: loss 5.903304
[epoch8, step2016]: loss 4.917196
[epoch8, step2017]: loss 2.804631
[epoch8, step2018]: loss 2.907891
[epoch8, step2019]: loss 7.623195
[epoch8, step2020]: loss 1.591933
[epoch8, step2021]: loss 19.227156
[epoch8, step2022]: loss 16.196377
[epoch8, step2023]: loss 16.819927
[epoch8, step2024]: loss 2.704319
[epoch8, step2025]: loss 4.247063
[epoch8, step2026]: loss 2.664804
[epoch8, step2027]: loss 0.853611
[epoch8, step2028]: loss 6.740275
[epoch8, step2029]: loss 5.343492
[epoch8, step2030]: loss 65.149017
[epoch8, step2031]: loss 1.688719
[epoch8, step2032]: loss 1.333668
[epoch8, step2033]: loss 2.114569
[epoch8, step2034]: loss 16.028105
[epoch8, step2035]: loss 1.867894
[epoch8, step2036]: loss 7.901269
[epoch8, step2037]: loss 17.214823
[epoch8, step2038]: loss 16.879084
[epoch8, step2039]: loss 2.175825
[epoch8, step2040]: loss 1.862716
[epoch8, step2041]: loss 1.052528
[epoch8, step2042]: loss 6.201281
[epoch8, step2043]: loss 5.920879
[epoch8, step2044]: loss 2.535297
[epoch8, step2045]: loss 1.116213
[epoch8, step2046]: loss 26.280575
[epoch8, step2047]: loss 2.204675
[epoch8, step2048]: loss 3.639771
[epoch8, step2049]: loss 16.470150
[epoch8, step2050]: loss 1.959486
[epoch8, step2051]: loss 1.255843
[epoch8, step2052]: loss 4.957924
[epoch8, step2053]: loss 13.120370
[epoch8, step2054]: loss 17.587978
[epoch8, step2055]: loss 1.922339
[epoch8, step2056]: loss 2.124496
[epoch8, step2057]: loss 2.087691
[epoch8, step2058]: loss 1.426711
[epoch8, step2059]: loss 29.232328
[epoch8, step2060]: loss 2.483417
[epoch8, step2061]: loss 1.320621
[epoch8, step2062]: loss 3.941245
[epoch8, step2063]: loss 3.016919
[epoch8, step2064]: loss 1.911914
[epoch8, step2065]: loss 1.580793
[epoch8, step2066]: loss 1.316918
[epoch8, step2067]: loss 6.499757
[epoch8, step2068]: loss 17.405933
[epoch8, step2069]: loss 1.246812
[epoch8, step2070]: loss 1.484832
[epoch8, step2071]: loss 1.529903
[epoch8, step2072]: loss 1.825517
[epoch8, step2073]: loss 3.146530
[epoch8, step2074]: loss 1.161631
[epoch8, step2075]: loss 15.381452
[epoch8, step2076]: loss 7.547946
[epoch8, step2077]: loss 2.169672
[epoch8, step2078]: loss 14.631552
[epoch8, step2079]: loss 4.035417
[epoch8, step2080]: loss 1.534243
[epoch8, step2081]: loss 13.026855
[epoch8, step2082]: loss 24.027058
[epoch8, step2083]: loss 3.024826
[epoch8, step2084]: loss 2.154866
[epoch8, step2085]: loss 4.931368
[epoch8, step2086]: loss 1.512731
[epoch8, step2087]: loss 17.587641
[epoch8, step2088]: loss 1.676041
[epoch8, step2089]: loss 6.313629
[epoch8, step2090]: loss 5.245777
[epoch8, step2091]: loss 27.856157
[epoch8, step2092]: loss 2.178685
[epoch8, step2093]: loss 2.601544
[epoch8, step2094]: loss 1.421992
[epoch8, step2095]: loss 9.093644
[epoch8, step2096]: loss 18.086414
[epoch8, step2097]: loss 18.814707
[epoch8, step2098]: loss 14.145188
[epoch8, step2099]: loss 3.457404
[epoch8, step2100]: loss 2.166898
[epoch8, step2101]: loss 1.610802
[epoch8, step2102]: loss 3.611548
[epoch8, step2103]: loss 2.221846
[epoch8, step2104]: loss 9.508699
[epoch8, step2105]: loss 2.296627
[epoch8, step2106]: loss 1.914684
[epoch8, step2107]: loss 5.419488
[epoch8, step2108]: loss 1.909955
[epoch8, step2109]: loss 3.775894
[epoch8, step2110]: loss 20.125065
[epoch8, step2111]: loss 2.809593
[epoch8, step2112]: loss 5.561001
[epoch8, step2113]: loss 1.993945
[epoch8, step2114]: loss 1.965715
[epoch8, step2115]: loss 7.078578
[epoch8, step2116]: loss 1.955021
[epoch8, step2117]: loss 1.694840
[epoch8, step2118]: loss 2.020319
[epoch8, step2119]: loss 1.675193
[epoch8, step2120]: loss 5.872016
[epoch8, step2121]: loss 5.055583
[epoch8, step2122]: loss 1.140333
[epoch8, step2123]: loss 7.554555
[epoch8, step2124]: loss 20.536451
[epoch8, step2125]: loss 20.256203
[epoch8, step2126]: loss 4.644339
[epoch8, step2127]: loss 23.445646
[epoch8, step2128]: loss 2.826324
[epoch8, step2129]: loss 5.550468
[epoch8, step2130]: loss 47.588852
[epoch8, step2131]: loss 19.084314
[epoch8, step2132]: loss 1.528026
[epoch8, step2133]: loss 11.833497
[epoch8, step2134]: loss 2.782223
[epoch8, step2135]: loss 17.777954
[epoch8, step2136]: loss 1.429953
[epoch8, step2137]: loss 1.509951
[epoch8, step2138]: loss 16.299282
[epoch8, step2139]: loss 1.169051
[epoch8, step2140]: loss 27.200356
[epoch8, step2141]: loss 3.445090
[epoch8, step2142]: loss 13.728607
[epoch8, step2143]: loss 14.438813
[epoch8, step2144]: loss 1.359862
[epoch8, step2145]: loss 1.354597
[epoch8, step2146]: loss 30.043489
[epoch8, step2147]: loss 2.461423
[epoch8, step2148]: loss 5.273580
[epoch8, step2149]: loss 4.296946
[epoch8, step2150]: loss 2.785261
[epoch8, step2151]: loss 3.219229
[epoch8, step2152]: loss 33.034866
[epoch8, step2153]: loss 1.934257
[epoch8, step2154]: loss 1.293002
[epoch8, step2155]: loss 4.229180
[epoch8, step2156]: loss 2.319925
[epoch8, step2157]: loss 2.399995
[epoch8, step2158]: loss 1.450126
[epoch8, step2159]: loss 2.306831
[epoch8, step2160]: loss 3.765723
[epoch8, step2161]: loss 1.715991
[epoch8, step2162]: loss 6.293294
[epoch8, step2163]: loss 21.676992
[epoch8, step2164]: loss 7.845942
[epoch8, step2165]: loss 5.945854
[epoch8, step2166]: loss 3.631001
[epoch8, step2167]: loss 1.356887
[epoch8, step2168]: loss 6.532138
[epoch8, step2169]: loss 2.959419
[epoch8, step2170]: loss 5.765007
[epoch8, step2171]: loss 11.086327
[epoch8, step2172]: loss 1.923416
[epoch8, step2173]: loss 1.175161
[epoch8, step2174]: loss 2.768079
[epoch8, step2175]: loss 6.893522
[epoch8, step2176]: loss 1.990066
[epoch8, step2177]: loss 5.368415
[epoch8, step2178]: loss 16.735401
[epoch8, step2179]: loss 3.516335
[epoch8, step2180]: loss 29.558933
[epoch8, step2181]: loss 4.134827
[epoch8, step2182]: loss 1.321973
[epoch8, step2183]: loss 1.956856
[epoch8, step2184]: loss 4.996203
[epoch8, step2185]: loss 1.654443
[epoch8, step2186]: loss 5.651873
[epoch8, step2187]: loss 26.183270
[epoch8, step2188]: loss 1.235459
[epoch8, step2189]: loss 1.002873
[epoch8, step2190]: loss 22.945154
[epoch8, step2191]: loss 2.187905
[epoch8, step2192]: loss 15.072506
[epoch8, step2193]: loss 5.496004
[epoch8, step2194]: loss 27.485033
[epoch8, step2195]: loss 4.820386
[epoch8, step2196]: loss 2.592838
[epoch8, step2197]: loss 6.438881
[epoch8, step2198]: loss 1.311764
[epoch8, step2199]: loss 1.743698
[epoch8, step2200]: loss 16.317450
[epoch8, step2201]: loss 4.682437
[epoch8, step2202]: loss 6.146250
[epoch8, step2203]: loss 3.771950
[epoch8, step2204]: loss 20.309814
[epoch8, step2205]: loss 9.066725
[epoch8, step2206]: loss 1.338854
[epoch8, step2207]: loss 1.864903
[epoch8, step2208]: loss 3.803030
[epoch8, step2209]: loss 3.515414
[epoch8, step2210]: loss 5.834726
[epoch8, step2211]: loss 1.876503
[epoch8, step2212]: loss 1.399129
[epoch8, step2213]: loss 5.271490
[epoch8, step2214]: loss 16.780102
[epoch8, step2215]: loss 17.139084
[epoch8, step2216]: loss 2.399430
[epoch8, step2217]: loss 1.855916
[epoch8, step2218]: loss 4.982267
[epoch8, step2219]: loss 3.151765
[epoch8, step2220]: loss 2.451833
[epoch8, step2221]: loss 23.979620
[epoch8, step2222]: loss 5.141176
[epoch8, step2223]: loss 1.266731
[epoch8, step2224]: loss 0.784160
[epoch8, step2225]: loss 22.512722
[epoch8, step2226]: loss 2.153662
[epoch8, step2227]: loss 2.206956
[epoch8, step2228]: loss 1.686169
[epoch8, step2229]: loss 18.201246
[epoch8, step2230]: loss 2.724313
[epoch8, step2231]: loss 4.163033
[epoch8, step2232]: loss 12.182149
[epoch8, step2233]: loss 1.708323
[epoch8, step2234]: loss 16.228975
[epoch8, step2235]: loss 1.351217
[epoch8, step2236]: loss 3.131548
[epoch8, step2237]: loss 4.955040
[epoch8, step2238]: loss 1.672419
[epoch8, step2239]: loss 2.490858
[epoch8, step2240]: loss 2.017117
[epoch8, step2241]: loss 6.727248
[epoch8, step2242]: loss 4.237994
[epoch8, step2243]: loss 1.455892
[epoch8, step2244]: loss 1.999054
[epoch8, step2245]: loss 1.881038
[epoch8, step2246]: loss 18.040403
[epoch8, step2247]: loss 32.370895
[epoch8, step2248]: loss 19.177214
[epoch8, step2249]: loss 1.987852
[epoch8, step2250]: loss 6.275975
[epoch8, step2251]: loss 17.362040
[epoch8, step2252]: loss 7.376727
[epoch8, step2253]: loss 2.695222
[epoch8, step2254]: loss 1.279774
[epoch8, step2255]: loss 3.428424
[epoch8, step2256]: loss 3.668507
[epoch8, step2257]: loss 8.632735
[epoch8, step2258]: loss 3.101811
[epoch8, step2259]: loss 2.043251
[epoch8, step2260]: loss 2.256258
[epoch8, step2261]: loss 4.348432
[epoch8, step2262]: loss 1.159857
[epoch8, step2263]: loss 1.466659
[epoch8, step2264]: loss 2.855524
[epoch8, step2265]: loss 3.197124
[epoch8, step2266]: loss 38.125301
[epoch8, step2267]: loss 3.778521
[epoch8, step2268]: loss 3.901470
[epoch8, step2269]: loss 1.081556
[epoch8, step2270]: loss 3.765538
[epoch8, step2271]: loss 2.265126
[epoch8, step2272]: loss 1.942844
[epoch8, step2273]: loss 2.199566
[epoch8, step2274]: loss 15.158018
[epoch8, step2275]: loss 8.953710
[epoch8, step2276]: loss 2.041702
[epoch8, step2277]: loss 6.538764
[epoch8, step2278]: loss 10.891406
[epoch8, step2279]: loss 3.599507
[epoch8, step2280]: loss 18.691040
[epoch8, step2281]: loss 2.776300
[epoch8, step2282]: loss 2.312536
[epoch8, step2283]: loss 1.761045
[epoch8, step2284]: loss 1.376484
[epoch8, step2285]: loss 10.161526
[epoch8, step2286]: loss 1.480033
[epoch8, step2287]: loss 5.279918
[epoch8, step2288]: loss 13.297879
[epoch8, step2289]: loss 1.149448
[epoch8, step2290]: loss 5.217056
[epoch8, step2291]: loss 3.918993
[epoch8, step2292]: loss 1.867381
[epoch8, step2293]: loss 22.338280
[epoch8, step2294]: loss 2.650785
[epoch8, step2295]: loss 3.535366
[epoch8, step2296]: loss 4.376978
[epoch8, step2297]: loss 2.685387
[epoch8, step2298]: loss 3.190298
[epoch8, step2299]: loss 16.855934
[epoch8, step2300]: loss 2.150244
[epoch8, step2301]: loss 3.960181
[epoch8, step2302]: loss 1.114722
[epoch8, step2303]: loss 5.211428
[epoch8, step2304]: loss 1.305213
[epoch8, step2305]: loss 5.615841
[epoch8, step2306]: loss 1.394253
[epoch8, step2307]: loss 17.831448
[epoch8, step2308]: loss 14.114716
[epoch8, step2309]: loss 2.880309
[epoch8, step2310]: loss 1.790568
[epoch8, step2311]: loss 5.249183
[epoch8, step2312]: loss 2.042801
[epoch8, step2313]: loss 2.300012
[epoch8, step2314]: loss 2.320332
[epoch8, step2315]: loss 15.599861
[epoch8, step2316]: loss 9.348986
[epoch8, step2317]: loss 2.343342
[epoch8, step2318]: loss 1.276307
[epoch8, step2319]: loss 8.541193
[epoch8, step2320]: loss 3.579727
[epoch8, step2321]: loss 4.192976
[epoch8, step2322]: loss 5.167981
[epoch8, step2323]: loss 18.459660
[epoch8, step2324]: loss 2.352168
[epoch8, step2325]: loss 19.179184
[epoch8, step2326]: loss 3.770777
[epoch8, step2327]: loss 1.417561
[epoch8, step2328]: loss 3.721208
[epoch8, step2329]: loss 1.726336
[epoch8, step2330]: loss 1.699892
[epoch8, step2331]: loss 1.942702
[epoch8, step2332]: loss 9.781500
[epoch8, step2333]: loss 1.724723
[epoch8, step2334]: loss 1.897883
[epoch8, step2335]: loss 1.875045
[epoch8, step2336]: loss 1.332388
[epoch8, step2337]: loss 21.595982
[epoch8, step2338]: loss 8.792958
[epoch8, step2339]: loss 37.102505
[epoch8, step2340]: loss 2.943075
[epoch8, step2341]: loss 2.496927
[epoch8, step2342]: loss 2.637691
[epoch8, step2343]: loss 13.913972
[epoch8, step2344]: loss 0.823262
[epoch8, step2345]: loss 1.595287
[epoch8, step2346]: loss 1.423404
[epoch8, step2347]: loss 28.795813
[epoch8, step2348]: loss 10.371490
[epoch8, step2349]: loss 1.440495
[epoch8, step2350]: loss 26.951704
[epoch8, step2351]: loss 2.195903
[epoch8, step2352]: loss 22.402834
[epoch8, step2353]: loss 27.273037
[epoch8, step2354]: loss 1.452601
[epoch8, step2355]: loss 1.418668
[epoch8, step2356]: loss 2.883840
[epoch8, step2357]: loss 1.209395
[epoch8, step2358]: loss 1.952722
[epoch8, step2359]: loss 1.924721
[epoch8, step2360]: loss 1.063349
[epoch8, step2361]: loss 4.042521
[epoch8, step2362]: loss 15.542066
[epoch8, step2363]: loss 7.052021
[epoch8, step2364]: loss 1.786644
[epoch8, step2365]: loss 2.252492
[epoch8, step2366]: loss 2.716677
[epoch8, step2367]: loss 24.511723
[epoch8, step2368]: loss 1.638645
[epoch8, step2369]: loss 18.176250
[epoch8, step2370]: loss 1.541223
[epoch8, step2371]: loss 3.591267
[epoch8, step2372]: loss 7.147101
[epoch8, step2373]: loss 3.384724
[epoch8, step2374]: loss 11.711159
[epoch8, step2375]: loss 3.983830
[epoch8, step2376]: loss 1.968137
[epoch8, step2377]: loss 17.139872
[epoch8, step2378]: loss 5.583847
[epoch8, step2379]: loss 1.512229
[epoch8, step2380]: loss 1.400320
[epoch8, step2381]: loss 25.703739
[epoch8, step2382]: loss 9.308749
[epoch8, step2383]: loss 11.267696
[epoch8, step2384]: loss 15.540929
[epoch8, step2385]: loss 2.759212
[epoch8, step2386]: loss 1.834841
[epoch8, step2387]: loss 2.007000
[epoch8, step2388]: loss 3.168841
[epoch8, step2389]: loss 4.243176
[epoch8, step2390]: loss 1.978117
[epoch8, step2391]: loss 4.999776
[epoch8, step2392]: loss 1.662053
[epoch8, step2393]: loss 4.747674
[epoch8, step2394]: loss 3.206175
[epoch8, step2395]: loss 2.629061
[epoch8, step2396]: loss 21.493023
[epoch8, step2397]: loss 1.162259
[epoch8, step2398]: loss 1.013925
[epoch8, step2399]: loss 14.034081
[epoch8, step2400]: loss 1.350741
[epoch8, step2401]: loss 1.207277
[epoch8, step2402]: loss 10.707264
[epoch8, step2403]: loss 3.502641
[epoch8, step2404]: loss 3.789565
[epoch8, step2405]: loss 2.609854
[epoch8, step2406]: loss 17.114340
[epoch8, step2407]: loss 3.127445
[epoch8, step2408]: loss 5.411212
[epoch8, step2409]: loss 3.262382
[epoch8, step2410]: loss 2.258324
[epoch8, step2411]: loss 1.704887
[epoch8, step2412]: loss 5.916335
[epoch8, step2413]: loss 17.947454
[epoch8, step2414]: loss 12.202518
[epoch8, step2415]: loss 1.225860
[epoch8, step2416]: loss 11.605352
[epoch8, step2417]: loss 3.072524
[epoch8, step2418]: loss 1.046031
[epoch8, step2419]: loss 4.586412
[epoch8, step2420]: loss 2.482275
[epoch8, step2421]: loss 6.290475
[epoch8, step2422]: loss 5.401682
[epoch8, step2423]: loss 3.501344
[epoch8, step2424]: loss 2.190972
[epoch8, step2425]: loss 1.698481
[epoch8, step2426]: loss 2.057734
[epoch8, step2427]: loss 4.346439
[epoch8, step2428]: loss 11.636969
[epoch8, step2429]: loss 15.527453
[epoch8, step2430]: loss 3.360872
[epoch8, step2431]: loss 18.315754
[epoch8, step2432]: loss 3.640803
[epoch8, step2433]: loss 16.062319
[epoch8, step2434]: loss 1.617835
[epoch8, step2435]: loss 16.141090
[epoch8, step2436]: loss 34.349670
[epoch8, step2437]: loss 6.968824
[epoch8, step2438]: loss 1.600519
[epoch8, step2439]: loss 3.217416
[epoch8, step2440]: loss 9.176828
[epoch8, step2441]: loss 1.748960
[epoch8, step2442]: loss 1.282151
[epoch8, step2443]: loss 2.976225
[epoch8, step2444]: loss 3.824002
[epoch8, step2445]: loss 2.023247
[epoch8, step2446]: loss 21.193638
[epoch8, step2447]: loss 3.149642
[epoch8, step2448]: loss 11.471952
[epoch8, step2449]: loss 1.439610
[epoch8, step2450]: loss 5.966897
[epoch8, step2451]: loss 1.986586
[epoch8, step2452]: loss 5.397641
[epoch8, step2453]: loss 26.196543
[epoch8, step2454]: loss 16.058498
[epoch8, step2455]: loss 4.352886
[epoch8, step2456]: loss 6.171165
[epoch8, step2457]: loss 3.626077
[epoch8, step2458]: loss 20.298178
[epoch8, step2459]: loss 14.869809
[epoch8, step2460]: loss 2.268470
[epoch8, step2461]: loss 49.176788
[epoch8, step2462]: loss 1.676312
[epoch8, step2463]: loss 14.606452
[epoch8, step2464]: loss 1.277479
[epoch8, step2465]: loss 7.823900
[epoch8, step2466]: loss 1.694194
[epoch8, step2467]: loss 2.904134
[epoch8, step2468]: loss 1.742567
[epoch8, step2469]: loss 1.314971
[epoch8, step2470]: loss 34.816235
[epoch8, step2471]: loss 14.650734
[epoch8, step2472]: loss 3.772188
[epoch8, step2473]: loss 1.257983
[epoch8, step2474]: loss 1.946830
[epoch8, step2475]: loss 18.294544
[epoch8, step2476]: loss 7.736804
[epoch8, step2477]: loss 1.795342
[epoch8, step2478]: loss 2.831690
[epoch8, step2479]: loss 12.661721
[epoch8, step2480]: loss 1.900429
[epoch8, step2481]: loss 1.237159
[epoch8, step2482]: loss 2.184881
[epoch8, step2483]: loss 14.321546
[epoch8, step2484]: loss 3.959016
[epoch8, step2485]: loss 8.603013
[epoch8, step2486]: loss 10.031923
[epoch8, step2487]: loss 16.570337
[epoch8, step2488]: loss 8.143852
[epoch8, step2489]: loss 17.660833
[epoch8, step2490]: loss 3.199905
[epoch8, step2491]: loss 6.165719
[epoch8, step2492]: loss 38.421970
[epoch8, step2493]: loss 4.913911
[epoch8, step2494]: loss 3.230901
[epoch8, step2495]: loss 5.549136
[epoch8, step2496]: loss 3.257780
[epoch8, step2497]: loss 2.159218
[epoch8, step2498]: loss 3.732539
[epoch8, step2499]: loss 20.721220
[epoch8, step2500]: loss 13.331779
[epoch8, step2501]: loss 2.553832
[epoch8, step2502]: loss 2.934454
[epoch8, step2503]: loss 1.153375
[epoch8, step2504]: loss 1.944654
[epoch8, step2505]: loss 15.284516
[epoch8, step2506]: loss 3.027241
[epoch8, step2507]: loss 2.870005
[epoch8, step2508]: loss 2.242062
[epoch8, step2509]: loss 11.996641
[epoch8, step2510]: loss 6.153369
[epoch8, step2511]: loss 0.952319
[epoch8, step2512]: loss 11.217589
[epoch8, step2513]: loss 1.779941
[epoch8, step2514]: loss 16.592850
[epoch8, step2515]: loss 7.367151
[epoch8, step2516]: loss 1.809586
[epoch8, step2517]: loss 20.293667
[epoch8, step2518]: loss 16.534914
[epoch8, step2519]: loss 1.999133
[epoch8, step2520]: loss 3.592732
[epoch8, step2521]: loss 1.796835
[epoch8, step2522]: loss 1.457541
[epoch8, step2523]: loss 1.969594
[epoch8, step2524]: loss 6.580308
[epoch8, step2525]: loss 30.613937
[epoch8, step2526]: loss 6.015857
[epoch8, step2527]: loss 10.032725
[epoch8, step2528]: loss 16.656984
[epoch8, step2529]: loss 1.485490
[epoch8, step2530]: loss 4.803018
[epoch8, step2531]: loss 6.733586
[epoch8, step2532]: loss 1.488027
[epoch8, step2533]: loss 5.739775
[epoch8, step2534]: loss 2.584599
[epoch8, step2535]: loss 2.266762
[epoch8, step2536]: loss 11.812775
[epoch8, step2537]: loss 29.646694
[epoch8, step2538]: loss 20.833807
[epoch8, step2539]: loss 1.339239
[epoch8, step2540]: loss 4.857410
[epoch8, step2541]: loss 1.014853
[epoch8, step2542]: loss 1.722306
[epoch8, step2543]: loss 7.599706
[epoch8, step2544]: loss 30.545139
[epoch8, step2545]: loss 1.337345
[epoch8, step2546]: loss 1.676687
[epoch8, step2547]: loss 19.690329
[epoch8, step2548]: loss 1.952706
[epoch8, step2549]: loss 11.818561
[epoch8, step2550]: loss 3.496984
[epoch8, step2551]: loss 3.174059
[epoch8, step2552]: loss 28.017794
[epoch8, step2553]: loss 3.151596
[epoch8, step2554]: loss 6.600069
[epoch8, step2555]: loss 2.016446
[epoch8, step2556]: loss 6.256705
[epoch8, step2557]: loss 3.510219
[epoch8, step2558]: loss 18.390568
[epoch8, step2559]: loss 13.875029
[epoch8, step2560]: loss 13.894438
[epoch8, step2561]: loss 5.202539
[epoch8, step2562]: loss 1.858779
[epoch8, step2563]: loss 1.543705
[epoch8, step2564]: loss 16.094904
[epoch8, step2565]: loss 4.919569
[epoch8, step2566]: loss 2.542903
[epoch8, step2567]: loss 5.008600
[epoch8, step2568]: loss 2.994144
[epoch8, step2569]: loss 19.132433
[epoch8, step2570]: loss 2.806759
[epoch8, step2571]: loss 3.564719
[epoch8, step2572]: loss 2.545295
[epoch8, step2573]: loss 17.574690
[epoch8, step2574]: loss 1.950566
[epoch8, step2575]: loss 1.298255
[epoch8, step2576]: loss 3.012224
[epoch8, step2577]: loss 14.877470
[epoch8, step2578]: loss 6.985596
[epoch8, step2579]: loss 6.193862
[epoch8, step2580]: loss 4.820693
[epoch8, step2581]: loss 2.975493
[epoch8, step2582]: loss 2.799243
[epoch8, step2583]: loss 2.952503
[epoch8, step2584]: loss 30.370222
[epoch8, step2585]: loss 13.555241
[epoch8, step2586]: loss 4.900731
[epoch8, step2587]: loss 2.415591
[epoch8, step2588]: loss 5.076726
[epoch8, step2589]: loss 16.323460
[epoch8, step2590]: loss 16.172350
[epoch8, step2591]: loss 1.393962
[epoch8, step2592]: loss 1.271821
[epoch8, step2593]: loss 4.143400
[epoch8, step2594]: loss 22.155073
[epoch8, step2595]: loss 28.125633
[epoch8, step2596]: loss 28.790485
[epoch8, step2597]: loss 16.029039
[epoch8, step2598]: loss 20.148310
[epoch8, step2599]: loss 1.257406
[epoch8, step2600]: loss 2.176167
[epoch8, step2601]: loss 1.376932
[epoch8, step2602]: loss 1.457034
[epoch8, step2603]: loss 1.435997
[epoch8, step2604]: loss 3.525539
[epoch8, step2605]: loss 15.956590
[epoch8, step2606]: loss 1.802969
[epoch8, step2607]: loss 9.485933
[epoch8, step2608]: loss 0.868015
[epoch8, step2609]: loss 2.260494
[epoch8, step2610]: loss 1.040268
[epoch8, step2611]: loss 27.875406
[epoch8, step2612]: loss 7.081123
[epoch8, step2613]: loss 1.700435
[epoch8, step2614]: loss 2.534365
[epoch8, step2615]: loss 6.618024
[epoch8, step2616]: loss 14.585733
[epoch8, step2617]: loss 1.661640
[epoch8, step2618]: loss 4.328030
[epoch8, step2619]: loss 21.468071
[epoch8, step2620]: loss 1.473783
[epoch8, step2621]: loss 21.640295
[epoch8, step2622]: loss 1.970702
[epoch8, step2623]: loss 1.660185
[epoch8, step2624]: loss 2.360163
[epoch8, step2625]: loss 3.541856
[epoch8, step2626]: loss 2.693256
[epoch8, step2627]: loss 12.938878
[epoch8, step2628]: loss 4.186583
[epoch8, step2629]: loss 1.808642
[epoch8, step2630]: loss 3.607463
[epoch8, step2631]: loss 1.969853
[epoch8, step2632]: loss 6.045028
[epoch8, step2633]: loss 1.618430
[epoch8, step2634]: loss 1.831838
[epoch8, step2635]: loss 2.641768
[epoch8, step2636]: loss 2.485973
[epoch8, step2637]: loss 1.715942
[epoch8, step2638]: loss 2.239848
[epoch8, step2639]: loss 1.384105
[epoch8, step2640]: loss 2.644068
[epoch8, step2641]: loss 8.281901
[epoch8, step2642]: loss 2.720328
[epoch8, step2643]: loss 4.447134
[epoch8, step2644]: loss 12.079651
[epoch8, step2645]: loss 1.750046
[epoch8, step2646]: loss 9.324049
[epoch8, step2647]: loss 1.448057
[epoch8, step2648]: loss 3.966405
[epoch8, step2649]: loss 5.616610
[epoch8, step2650]: loss 18.346489
[epoch8, step2651]: loss 1.676636
[epoch8, step2652]: loss 4.646489
[epoch8, step2653]: loss 14.275374
[epoch8, step2654]: loss 1.650396
[epoch8, step2655]: loss 5.824334
[epoch8, step2656]: loss 6.213244
[epoch8, step2657]: loss 2.446209
[epoch8, step2658]: loss 1.683686
[epoch8, step2659]: loss 1.756839
[epoch8, step2660]: loss 2.884484
[epoch8, step2661]: loss 1.316347
[epoch8, step2662]: loss 17.134132
[epoch8, step2663]: loss 1.113060
[epoch8, step2664]: loss 2.874424
[epoch8, step2665]: loss 1.717425
[epoch8, step2666]: loss 3.286801
[epoch8, step2667]: loss 4.974110
[epoch8, step2668]: loss 2.447600
[epoch8, step2669]: loss 4.544615
[epoch8, step2670]: loss 16.333685
[epoch8, step2671]: loss 9.267083
[epoch8, step2672]: loss 13.510962
[epoch8, step2673]: loss 6.199039
[epoch8, step2674]: loss 2.454214
[epoch8, step2675]: loss 2.525290
[epoch8, step2676]: loss 14.596026
[epoch8, step2677]: loss 0.754285
[epoch8, step2678]: loss 7.358324
[epoch8, step2679]: loss 1.277290
[epoch8, step2680]: loss 4.921578
[epoch8, step2681]: loss 3.261158
[epoch8, step2682]: loss 30.458660
[epoch8, step2683]: loss 3.310240
[epoch8, step2684]: loss 3.482583
[epoch8, step2685]: loss 1.966314
[epoch8, step2686]: loss 2.404628
[epoch8, step2687]: loss 4.087266
[epoch8, step2688]: loss 1.316078
[epoch8, step2689]: loss 1.598075
[epoch8, step2690]: loss 21.528589
[epoch8, step2691]: loss 4.192359
[epoch8, step2692]: loss 2.810928
[epoch8, step2693]: loss 2.157640
[epoch8, step2694]: loss 2.156755
[epoch8, step2695]: loss 1.095043
[epoch8, step2696]: loss 2.100056
[epoch8, step2697]: loss 6.821913
[epoch8, step2698]: loss 0.917672
[epoch8, step2699]: loss 2.253444
[epoch8, step2700]: loss 16.181778
[epoch8, step2701]: loss 3.442678
[epoch8, step2702]: loss 21.400002
[epoch8, step2703]: loss 10.579207
[epoch8, step2704]: loss 3.324749
[epoch8, step2705]: loss 2.278024
[epoch8, step2706]: loss 2.596419
[epoch8, step2707]: loss 2.589904
[epoch8, step2708]: loss 4.944587
[epoch8, step2709]: loss 15.518254
[epoch8, step2710]: loss 4.420432
[epoch8, step2711]: loss 2.456869
[epoch8, step2712]: loss 1.027444
[epoch8, step2713]: loss 14.975924
[epoch8, step2714]: loss 8.586440
[epoch8, step2715]: loss 6.001024
[epoch8, step2716]: loss 1.363696
[epoch8, step2717]: loss 2.103673
[epoch8, step2718]: loss 2.826912
[epoch8, step2719]: loss 11.129549
[epoch8, step2720]: loss 16.161108
[epoch8, step2721]: loss 3.849257
[epoch8, step2722]: loss 0.847452
[epoch8, step2723]: loss 4.312060
[epoch8, step2724]: loss 44.515327
[epoch8, step2725]: loss 13.515004
[epoch8, step2726]: loss 1.619297
[epoch8, step2727]: loss 6.296781
[epoch8, step2728]: loss 2.749033
[epoch8, step2729]: loss 3.532792
[epoch8, step2730]: loss 2.982323
[epoch8, step2731]: loss 1.584907
[epoch8, step2732]: loss 3.783661
[epoch8, step2733]: loss 5.878287
[epoch8, step2734]: loss 1.919326
[epoch8, step2735]: loss 1.592266
[epoch8, step2736]: loss 5.121160
[epoch8, step2737]: loss 1.927899
[epoch8, step2738]: loss 1.877349
[epoch8, step2739]: loss 1.442610
[epoch8, step2740]: loss 4.690486
[epoch8, step2741]: loss 1.303132
[epoch8, step2742]: loss 1.806608
[epoch8, step2743]: loss 3.002052
[epoch8, step2744]: loss 3.080031
[epoch8, step2745]: loss 1.853003
[epoch8, step2746]: loss 3.120858
[epoch8, step2747]: loss 2.777561
[epoch8, step2748]: loss 7.199494
[epoch8, step2749]: loss 30.338146
[epoch8, step2750]: loss 2.010032
[epoch8, step2751]: loss 3.361538
[epoch8, step2752]: loss 1.008621
[epoch8, step2753]: loss 14.792678
[epoch8, step2754]: loss 5.268085
[epoch8, step2755]: loss 8.118219
[epoch8, step2756]: loss 2.290431
[epoch8, step2757]: loss 5.037247
[epoch8, step2758]: loss 4.883598
[epoch8, step2759]: loss 30.116531
[epoch8, step2760]: loss 1.649635
[epoch8, step2761]: loss 18.141953
[epoch8, step2762]: loss 1.170058
[epoch8, step2763]: loss 3.215395
[epoch8, step2764]: loss 4.101536
[epoch8, step2765]: loss 6.345319
[epoch8, step2766]: loss 15.129768
[epoch8, step2767]: loss 5.219422
[epoch8, step2768]: loss 3.216758
[epoch8, step2769]: loss 2.673582
[epoch8, step2770]: loss 3.392816
[epoch8, step2771]: loss 2.387496
[epoch8, step2772]: loss 1.689543
[epoch8, step2773]: loss 5.882681
[epoch8, step2774]: loss 5.815045
[epoch8, step2775]: loss 2.376833
[epoch8, step2776]: loss 4.839159
[epoch8, step2777]: loss 4.439821
[epoch8, step2778]: loss 2.403366
[epoch8, step2779]: loss 19.317987
[epoch8, step2780]: loss 4.332098
[epoch8, step2781]: loss 3.351887
[epoch8, step2782]: loss 13.811480
[epoch8, step2783]: loss 1.009945
[epoch8, step2784]: loss 0.828887
[epoch8, step2785]: loss 6.733043
[epoch8, step2786]: loss 28.815983
[epoch8, step2787]: loss 1.281719
[epoch8, step2788]: loss 12.967742
[epoch8, step2789]: loss 3.152812
[epoch8, step2790]: loss 1.202295
[epoch8, step2791]: loss 1.217720
[epoch8, step2792]: loss 4.053129
[epoch8, step2793]: loss 4.961460
[epoch8, step2794]: loss 1.289854
[epoch8, step2795]: loss 3.183402
[epoch8, step2796]: loss 15.095263
[epoch8, step2797]: loss 6.637790
[epoch8, step2798]: loss 3.062430
[epoch8, step2799]: loss 1.043869
[epoch8, step2800]: loss 1.492145
[epoch8, step2801]: loss 2.402175
[epoch8, step2802]: loss 3.121722
[epoch8, step2803]: loss 3.703879
[epoch8, step2804]: loss 22.069794
[epoch8, step2805]: loss 3.485888
[epoch8, step2806]: loss 3.221898
[epoch8, step2807]: loss 1.908115
[epoch8, step2808]: loss 12.550314
[epoch8, step2809]: loss 16.440426
[epoch8, step2810]: loss 2.736876
[epoch8, step2811]: loss 4.557139
[epoch8, step2812]: loss 1.366799
[epoch8, step2813]: loss 3.622109
[epoch8, step2814]: loss 3.909583
[epoch8, step2815]: loss 2.903152
[epoch8, step2816]: loss 27.971106
[epoch8, step2817]: loss 2.978291
[epoch8, step2818]: loss 4.423952
[epoch8, step2819]: loss 5.888802
[epoch8, step2820]: loss 2.579862
[epoch8, step2821]: loss 2.405303
[epoch8, step2822]: loss 1.745978
[epoch8, step2823]: loss 4.413303
[epoch8, step2824]: loss 3.827168
[epoch8, step2825]: loss 4.907854
[epoch8, step2826]: loss 2.568596
[epoch8, step2827]: loss 1.613708
[epoch8, step2828]: loss 1.778629
[epoch8, step2829]: loss 33.214836
[epoch8, step2830]: loss 7.030933
[epoch8, step2831]: loss 1.755182
[epoch8, step2832]: loss 5.357215
[epoch8, step2833]: loss 5.110201
[epoch8, step2834]: loss 6.243708
[epoch8, step2835]: loss 6.560325
[epoch8, step2836]: loss 3.783504
[epoch8, step2837]: loss 1.894547
[epoch8, step2838]: loss 6.862376
[epoch8, step2839]: loss 13.445091
[epoch8, step2840]: loss 2.344995
[epoch8, step2841]: loss 3.086927
[epoch8, step2842]: loss 2.326452
[epoch8, step2843]: loss 8.208017
[epoch8, step2844]: loss 2.034859
[epoch8, step2845]: loss 2.541144
[epoch8, step2846]: loss 12.068144
[epoch8, step2847]: loss 4.385336
[epoch8, step2848]: loss 18.186630
[epoch8, step2849]: loss 5.365833
[epoch8, step2850]: loss 14.570189
[epoch8, step2851]: loss 2.775739
[epoch8, step2852]: loss 5.965387
[epoch8, step2853]: loss 9.507887
[epoch8, step2854]: loss 2.010482
[epoch8, step2855]: loss 17.346100
[epoch8, step2856]: loss 3.514689
[epoch8, step2857]: loss 15.801430
[epoch8, step2858]: loss 15.804760
[epoch8, step2859]: loss 15.551743
[epoch8, step2860]: loss 6.948432
[epoch8, step2861]: loss 2.526360
[epoch8, step2862]: loss 16.594038
[epoch8, step2863]: loss 4.672903
[epoch8, step2864]: loss 3.294790
[epoch8, step2865]: loss 2.961939
[epoch8, step2866]: loss 1.054634
[epoch8, step2867]: loss 1.306060
[epoch8, step2868]: loss 3.264954
[epoch8, step2869]: loss 4.314231
[epoch8, step2870]: loss 2.049315
[epoch8, step2871]: loss 3.246634
[epoch8, step2872]: loss 3.620136
[epoch8, step2873]: loss 2.062042
[epoch8, step2874]: loss 2.286355
[epoch8, step2875]: loss 2.593222
[epoch8, step2876]: loss 1.903924
[epoch8, step2877]: loss 1.519444
[epoch8, step2878]: loss 1.462479
[epoch8, step2879]: loss 1.459968
[epoch8, step2880]: loss 3.702433
[epoch8, step2881]: loss 3.426622
[epoch8, step2882]: loss 1.299769
[epoch8, step2883]: loss 5.372277
[epoch8, step2884]: loss 5.700835
[epoch8, step2885]: loss 13.965235
[epoch8, step2886]: loss 6.216163
[epoch8, step2887]: loss 4.409454
[epoch8, step2888]: loss 2.141245
[epoch8, step2889]: loss 2.550062
[epoch8, step2890]: loss 2.787611
[epoch8, step2891]: loss 1.674023
[epoch8, step2892]: loss 11.556861
[epoch8, step2893]: loss 22.851559
[epoch8, step2894]: loss 1.943444
[epoch8, step2895]: loss 1.242445
[epoch8, step2896]: loss 2.292142
[epoch8, step2897]: loss 28.641121
[epoch8, step2898]: loss 6.013747
[epoch8, step2899]: loss 1.505433
[epoch8, step2900]: loss 2.099185
[epoch8, step2901]: loss 7.474569
[epoch8, step2902]: loss 6.927636
[epoch8, step2903]: loss 2.469335
[epoch8, step2904]: loss 1.224100
[epoch8, step2905]: loss 17.517475
[epoch8, step2906]: loss 9.368565
[epoch8, step2907]: loss 16.859039
[epoch8, step2908]: loss 15.992958
[epoch8, step2909]: loss 2.920062
[epoch8, step2910]: loss 0.925158
[epoch8, step2911]: loss 6.274243
[epoch8, step2912]: loss 1.518725
[epoch8, step2913]: loss 21.041901
[epoch8, step2914]: loss 3.875184
[epoch8, step2915]: loss 1.685171
[epoch8, step2916]: loss 2.315959
[epoch8, step2917]: loss 15.666653
[epoch8, step2918]: loss 7.344524
[epoch8, step2919]: loss 1.306990
[epoch8, step2920]: loss 4.725070
[epoch8, step2921]: loss 1.929000
[epoch8, step2922]: loss 2.180547
[epoch8, step2923]: loss 3.040473
[epoch8, step2924]: loss 2.700566
[epoch8, step2925]: loss 18.065216
[epoch8, step2926]: loss 5.707158
[epoch8, step2927]: loss 5.286411
[epoch8, step2928]: loss 1.511019
[epoch8, step2929]: loss 5.373528
[epoch8, step2930]: loss 4.222010
[epoch8, step2931]: loss 2.750965
[epoch8, step2932]: loss 2.239659
[epoch8, step2933]: loss 2.379828
[epoch8, step2934]: loss 1.530090
[epoch8, step2935]: loss 20.301668
[epoch8, step2936]: loss 2.529842
[epoch8, step2937]: loss 4.098929
[epoch8, step2938]: loss 5.938515
[epoch8, step2939]: loss 1.014543
[epoch8, step2940]: loss 9.290909
[epoch8, step2941]: loss 4.426287
[epoch8, step2942]: loss 12.937691
[epoch8, step2943]: loss 2.609872
[epoch8, step2944]: loss 2.606480
[epoch8, step2945]: loss 6.375237
[epoch8, step2946]: loss 2.041926
[epoch8, step2947]: loss 14.967782
[epoch8, step2948]: loss 3.012460
[epoch8, step2949]: loss 22.515123
[epoch8, step2950]: loss 12.477247
[epoch8, step2951]: loss 1.748190
[epoch8, step2952]: loss 3.067332
[epoch8, step2953]: loss 1.420354
[epoch8, step2954]: loss 23.421480
[epoch8, step2955]: loss 1.146703
[epoch8, step2956]: loss 4.140822
[epoch8, step2957]: loss 3.198308
[epoch8, step2958]: loss 22.659309
[epoch8, step2959]: loss 2.080565
[epoch8, step2960]: loss 4.436397
[epoch8, step2961]: loss 2.616176
[epoch8, step2962]: loss 19.802782
[epoch8, step2963]: loss 1.581990
[epoch8, step2964]: loss 3.126891
[epoch8, step2965]: loss 3.023510
[epoch8, step2966]: loss 24.939882
[epoch8, step2967]: loss 2.722375
[epoch8, step2968]: loss 32.358963
[epoch8, step2969]: loss 2.039369
[epoch8, step2970]: loss 10.095800
[epoch8, step2971]: loss 4.618933
[epoch8, step2972]: loss 2.805058
[epoch8, step2973]: loss 8.678026
[epoch8, step2974]: loss 1.856504
[epoch8, step2975]: loss 15.317743
[epoch8, step2976]: loss 2.735564
[epoch8, step2977]: loss 17.946131
[epoch8, step2978]: loss 18.573256
[epoch8, step2979]: loss 8.574151
[epoch8, step2980]: loss 21.036879
[epoch8, step2981]: loss 5.219255
[epoch8, step2982]: loss 2.081047
[epoch8, step2983]: loss 1.710699
[epoch8, step2984]: loss 5.068573
[epoch8, step2985]: loss 14.705087
[epoch8, step2986]: loss 2.708797
[epoch8, step2987]: loss 5.140527
[epoch8, step2988]: loss 15.269795
[epoch8, step2989]: loss 11.597578
[epoch8, step2990]: loss 2.292823
[epoch8, step2991]: loss 7.210351
[epoch8, step2992]: loss 3.485723
[epoch8, step2993]: loss 1.977060
[epoch8, step2994]: loss 4.967746
[epoch8, step2995]: loss 2.978731
[epoch8, step2996]: loss 24.815371
[epoch8, step2997]: loss 15.371549
[epoch8, step2998]: loss 2.777203
[epoch8, step2999]: loss 1.206241
[epoch8, step3000]: loss 8.809923
[epoch8, step3001]: loss 9.466585
[epoch8, step3002]: loss 3.055592
[epoch8, step3003]: loss 3.113014
[epoch8, step3004]: loss 16.247688
[epoch8, step3005]: loss 2.842530
[epoch8, step3006]: loss 2.691626
[epoch8, step3007]: loss 1.419777
[epoch8, step3008]: loss 3.532817
[epoch8, step3009]: loss 1.001318
[epoch8, step3010]: loss 1.262393
[epoch8, step3011]: loss 1.540812
[epoch8, step3012]: loss 8.732139
[epoch8, step3013]: loss 15.699342
[epoch8, step3014]: loss 9.737514
[epoch8, step3015]: loss 4.165279
[epoch8, step3016]: loss 14.468354
[epoch8, step3017]: loss 9.634978
[epoch8, step3018]: loss 1.116519
[epoch8, step3019]: loss 3.335114
[epoch8, step3020]: loss 16.950804
[epoch8, step3021]: loss 15.873881
[epoch8, step3022]: loss 20.637222
[epoch8, step3023]: loss 15.184929
[epoch8, step3024]: loss 3.351953
[epoch8, step3025]: loss 23.614590
[epoch8, step3026]: loss 6.393673
[epoch8, step3027]: loss 3.372848
[epoch8, step3028]: loss 1.241382
[epoch8, step3029]: loss 1.188075
[epoch8, step3030]: loss 2.678225
[epoch8, step3031]: loss 0.907684
[epoch8, step3032]: loss 47.577473
[epoch8, step3033]: loss 6.092558
[epoch8, step3034]: loss 8.459825
[epoch8, step3035]: loss 11.195868
[epoch8, step3036]: loss 4.422494
[epoch8, step3037]: loss 4.801558
[epoch8, step3038]: loss 2.995484
[epoch8, step3039]: loss 5.413998
[epoch8, step3040]: loss 2.546091
[epoch8, step3041]: loss 25.189140
[epoch8, step3042]: loss 17.510002
[epoch8, step3043]: loss 1.575630
[epoch8, step3044]: loss 11.172022
[epoch8, step3045]: loss 3.617032
[epoch8, step3046]: loss 2.995400
[epoch8, step3047]: loss 15.787612
[epoch8, step3048]: loss 7.638370
[epoch8, step3049]: loss 5.862945
[epoch8, step3050]: loss 2.013267
[epoch8, step3051]: loss 4.458457
[epoch8, step3052]: loss 4.479845
[epoch8, step3053]: loss 2.178673
[epoch8, step3054]: loss 2.539769
[epoch8, step3055]: loss 4.380481
[epoch8, step3056]: loss 4.117096
[epoch8, step3057]: loss 2.688483
[epoch8, step3058]: loss 2.789647
[epoch8, step3059]: loss 1.343610
[epoch8, step3060]: loss 39.311775
[epoch8, step3061]: loss 2.211171
[epoch8, step3062]: loss 3.833756
[epoch8, step3063]: loss 2.210616
[epoch8, step3064]: loss 3.600831
[epoch8, step3065]: loss 2.733366
[epoch8, step3066]: loss 1.112194
[epoch8, step3067]: loss 3.389231
[epoch8, step3068]: loss 2.988288
[epoch8, step3069]: loss 4.977630
[epoch8, step3070]: loss 21.523237
[epoch8, step3071]: loss 1.060138
[epoch8, step3072]: loss 2.591209
[epoch8, step3073]: loss 1.235135
[epoch8, step3074]: loss 12.812162
[epoch8, step3075]: loss 1.906983
[epoch8, step3076]: loss 1.020530

[epoch8]: avg loss 1.020530

[epoch9, step1]: loss 2.770213
[epoch9, step2]: loss 1.456799
[epoch9, step3]: loss 3.213084
[epoch9, step4]: loss 30.491882
[epoch9, step5]: loss 2.087651
[epoch9, step6]: loss 2.716539
[epoch9, step7]: loss 0.911039
[epoch9, step8]: loss 1.593769
[epoch9, step9]: loss 2.228405
[epoch9, step10]: loss 11.214239
[epoch9, step11]: loss 1.758576
[epoch9, step12]: loss 5.486726
[epoch9, step13]: loss 2.398847
[epoch9, step14]: loss 2.573292
[epoch9, step15]: loss 21.666058
[epoch9, step16]: loss 24.388388
[epoch9, step17]: loss 1.164136
[epoch9, step18]: loss 4.974025
[epoch9, step19]: loss 2.598639
[epoch9, step20]: loss 2.908123
[epoch9, step21]: loss 1.563853
[epoch9, step22]: loss 6.513654
[epoch9, step23]: loss 1.702209
[epoch9, step24]: loss 8.214672
[epoch9, step25]: loss 1.796504
[epoch9, step26]: loss 4.890563
[epoch9, step27]: loss 1.589821
[epoch9, step28]: loss 19.922453
[epoch9, step29]: loss 2.452106
[epoch9, step30]: loss 2.393167
[epoch9, step31]: loss 2.511465
[epoch9, step32]: loss 15.954677
[epoch9, step33]: loss 2.209346
[epoch9, step34]: loss 1.520204
[epoch9, step35]: loss 1.396113
[epoch9, step36]: loss 20.780287
[epoch9, step37]: loss 20.094013
[epoch9, step38]: loss 4.527408
[epoch9, step39]: loss 17.326021
[epoch9, step40]: loss 17.692730
[epoch9, step41]: loss 12.275990
[epoch9, step42]: loss 1.159170
[epoch9, step43]: loss 3.187510
[epoch9, step44]: loss 14.207027
[epoch9, step45]: loss 2.564153
[epoch9, step46]: loss 2.256166
[epoch9, step47]: loss 13.295472
[epoch9, step48]: loss 15.800730
[epoch9, step49]: loss 15.151106
[epoch9, step50]: loss 7.074194
[epoch9, step51]: loss 2.827327
[epoch9, step52]: loss 2.084173
[epoch9, step53]: loss 14.597038
[epoch9, step54]: loss 19.299549
[epoch9, step55]: loss 14.571280
[epoch9, step56]: loss 1.382487
[epoch9, step57]: loss 13.780392
[epoch9, step58]: loss 13.620348
[epoch9, step59]: loss 12.677071
[epoch9, step60]: loss 5.804375
[epoch9, step61]: loss 2.804561
[epoch9, step62]: loss 4.623873
[epoch9, step63]: loss 14.811919
[epoch9, step64]: loss 13.350019
[epoch9, step65]: loss 3.981965
[epoch9, step66]: loss 11.773163
[epoch9, step67]: loss 2.071416
[epoch9, step68]: loss 1.174716
[epoch9, step69]: loss 5.109339
[epoch9, step70]: loss 1.712118
[epoch9, step71]: loss 2.692575
[epoch9, step72]: loss 2.319499
[epoch9, step73]: loss 2.703042
[epoch9, step74]: loss 10.048404
[epoch9, step75]: loss 1.853849
[epoch9, step76]: loss 1.188770
[epoch9, step77]: loss 1.707081
[epoch9, step78]: loss 10.101438
[epoch9, step79]: loss 23.327168
[epoch9, step80]: loss 8.930960
[epoch9, step81]: loss 6.043462
[epoch9, step82]: loss 1.282631
[epoch9, step83]: loss 0.680855
[epoch9, step84]: loss 18.754362
[epoch9, step85]: loss 6.264936
[epoch9, step86]: loss 3.448420
[epoch9, step87]: loss 3.653233
[epoch9, step88]: loss 4.120791
[epoch9, step89]: loss 12.223057
[epoch9, step90]: loss 3.224235
[epoch9, step91]: loss 20.786259
[epoch9, step92]: loss 5.598780
[epoch9, step93]: loss 15.111523
[epoch9, step94]: loss 33.231346
[epoch9, step95]: loss 6.647982
[epoch9, step96]: loss 2.843563
[epoch9, step97]: loss 21.870214
[epoch9, step98]: loss 1.209922
[epoch9, step99]: loss 2.547414
[epoch9, step100]: loss 10.636875
[epoch9, step101]: loss 3.498723
[epoch9, step102]: loss 2.503516
[epoch9, step103]: loss 1.492512
[epoch9, step104]: loss 2.235677
[epoch9, step105]: loss 1.896662
[epoch9, step106]: loss 2.204275
[epoch9, step107]: loss 18.686474
[epoch9, step108]: loss 1.527704
[epoch9, step109]: loss 15.205704
[epoch9, step110]: loss 17.227560
[epoch9, step111]: loss 20.314938
[epoch9, step112]: loss 13.545329
[epoch9, step113]: loss 1.832863
[epoch9, step114]: loss 2.040064
[epoch9, step115]: loss 1.227576
[epoch9, step116]: loss 1.368052
[epoch9, step117]: loss 6.420310
[epoch9, step118]: loss 1.399065
[epoch9, step119]: loss 17.306141
[epoch9, step120]: loss 2.099253
[epoch9, step121]: loss 2.635121
[epoch9, step122]: loss 15.651678
[epoch9, step123]: loss 21.169804
[epoch9, step124]: loss 17.021418
[epoch9, step125]: loss 1.903653
[epoch9, step126]: loss 6.826569
[epoch9, step127]: loss 10.913474
[epoch9, step128]: loss 3.904470
[epoch9, step129]: loss 25.303076
[epoch9, step130]: loss 1.499871
[epoch9, step131]: loss 5.244565
[epoch9, step132]: loss 6.249613
[epoch9, step133]: loss 35.734150
[epoch9, step134]: loss 18.090208
[epoch9, step135]: loss 2.627074
[epoch9, step136]: loss 4.504647
[epoch9, step137]: loss 14.854828
[epoch9, step138]: loss 13.236383
[epoch9, step139]: loss 2.458010
[epoch9, step140]: loss 4.491476
[epoch9, step141]: loss 3.620302
[epoch9, step142]: loss 1.530818
[epoch9, step143]: loss 2.246232
[epoch9, step144]: loss 13.141736
[epoch9, step145]: loss 7.918788
[epoch9, step146]: loss 11.853054
[epoch9, step147]: loss 1.467857
[epoch9, step148]: loss 2.359378
[epoch9, step149]: loss 1.083550
[epoch9, step150]: loss 15.197581
[epoch9, step151]: loss 23.826828
[epoch9, step152]: loss 2.945631
[epoch9, step153]: loss 2.149402
[epoch9, step154]: loss 1.484221
[epoch9, step155]: loss 1.334757
[epoch9, step156]: loss 5.775775
[epoch9, step157]: loss 10.656355
[epoch9, step158]: loss 1.579235
[epoch9, step159]: loss 10.669977
[epoch9, step160]: loss 7.489152
[epoch9, step161]: loss 14.936577
[epoch9, step162]: loss 3.829619
[epoch9, step163]: loss 3.744452
[epoch9, step164]: loss 16.860083
[epoch9, step165]: loss 5.182271
[epoch9, step166]: loss 2.235379
[epoch9, step167]: loss 18.067083
[epoch9, step168]: loss 1.598242
[epoch9, step169]: loss 3.055042
[epoch9, step170]: loss 2.223543
[epoch9, step171]: loss 3.161692
[epoch9, step172]: loss 8.619330
[epoch9, step173]: loss 1.523263
[epoch9, step174]: loss 1.230951
[epoch9, step175]: loss 2.756885
[epoch9, step176]: loss 2.717662
[epoch9, step177]: loss 10.511259
[epoch9, step178]: loss 3.378499
[epoch9, step179]: loss 2.023448
[epoch9, step180]: loss 2.652078
[epoch9, step181]: loss 2.974838
[epoch9, step182]: loss 7.573489
[epoch9, step183]: loss 2.769772
[epoch9, step184]: loss 3.802264
[epoch9, step185]: loss 3.773272
[epoch9, step186]: loss 2.717533
[epoch9, step187]: loss 2.960496
[epoch9, step188]: loss 1.819128
[epoch9, step189]: loss 18.198294
[epoch9, step190]: loss 4.906767
[epoch9, step191]: loss 1.371004
[epoch9, step192]: loss 3.340414
[epoch9, step193]: loss 1.116415
[epoch9, step194]: loss 19.079353
[epoch9, step195]: loss 19.032598
[epoch9, step196]: loss 3.898305
[epoch9, step197]: loss 17.592804
[epoch9, step198]: loss 1.427185
[epoch9, step199]: loss 2.872509
[epoch9, step200]: loss 3.241813
[epoch9, step201]: loss 1.232645
[epoch9, step202]: loss 1.784051
[epoch9, step203]: loss 2.250367
[epoch9, step204]: loss 2.853052
[epoch9, step205]: loss 16.442690
[epoch9, step206]: loss 2.880616
[epoch9, step207]: loss 1.435530
[epoch9, step208]: loss 1.330783
[epoch9, step209]: loss 16.914696
[epoch9, step210]: loss 7.329804
[epoch9, step211]: loss 3.036941
[epoch9, step212]: loss 4.946938
[epoch9, step213]: loss 3.595135
[epoch9, step214]: loss 15.252110
[epoch9, step215]: loss 2.360665
[epoch9, step216]: loss 13.974005
[epoch9, step217]: loss 8.302933
[epoch9, step218]: loss 3.318481
[epoch9, step219]: loss 1.544716
[epoch9, step220]: loss 2.243144
[epoch9, step221]: loss 6.029826
[epoch9, step222]: loss 6.158984
[epoch9, step223]: loss 14.588372
[epoch9, step224]: loss 1.320758
[epoch9, step225]: loss 7.619083
[epoch9, step226]: loss 10.233119
[epoch9, step227]: loss 22.112438
[epoch9, step228]: loss 3.795283
[epoch9, step229]: loss 2.728841
[epoch9, step230]: loss 25.846710
[epoch9, step231]: loss 3.561512
[epoch9, step232]: loss 1.512621
[epoch9, step233]: loss 5.512631
[epoch9, step234]: loss 4.911299
[epoch9, step235]: loss 15.773600
[epoch9, step236]: loss 20.903572
[epoch9, step237]: loss 14.614439
[epoch9, step238]: loss 1.248995
[epoch9, step239]: loss 1.837255
[epoch9, step240]: loss 1.676666
[epoch9, step241]: loss 15.838457
[epoch9, step242]: loss 10.661483
[epoch9, step243]: loss 17.704008
[epoch9, step244]: loss 1.603300
[epoch9, step245]: loss 14.342818
[epoch9, step246]: loss 2.046589
[epoch9, step247]: loss 1.103456
[epoch9, step248]: loss 17.760271
[epoch9, step249]: loss 0.961656
[epoch9, step250]: loss 4.554787
[epoch9, step251]: loss 1.442505
[epoch9, step252]: loss 2.328650
[epoch9, step253]: loss 1.690475
[epoch9, step254]: loss 21.846672
[epoch9, step255]: loss 1.214716
[epoch9, step256]: loss 2.233632
[epoch9, step257]: loss 1.691212
[epoch9, step258]: loss 1.311066
[epoch9, step259]: loss 4.780240
[epoch9, step260]: loss 3.521624
[epoch9, step261]: loss 44.948826
[epoch9, step262]: loss 2.174350
[epoch9, step263]: loss 2.693559
[epoch9, step264]: loss 1.007475
[epoch9, step265]: loss 4.653542
[epoch9, step266]: loss 1.801134
[epoch9, step267]: loss 3.625794
[epoch9, step268]: loss 3.902404
[epoch9, step269]: loss 13.186832
[epoch9, step270]: loss 2.028929
[epoch9, step271]: loss 12.934587
[epoch9, step272]: loss 1.212426
[epoch9, step273]: loss 1.432151
[epoch9, step274]: loss 1.916890
[epoch9, step275]: loss 4.924700
[epoch9, step276]: loss 2.540296
[epoch9, step277]: loss 1.550560
[epoch9, step278]: loss 25.197884
[epoch9, step279]: loss 1.569998
[epoch9, step280]: loss 2.317030
[epoch9, step281]: loss 13.557130
[epoch9, step282]: loss 9.122172
[epoch9, step283]: loss 16.061275
[epoch9, step284]: loss 2.814392
[epoch9, step285]: loss 17.998199
[epoch9, step286]: loss 1.411443
[epoch9, step287]: loss 9.585210
[epoch9, step288]: loss 4.098156
[epoch9, step289]: loss 6.676425
[epoch9, step290]: loss 28.970722
[epoch9, step291]: loss 14.394626
[epoch9, step292]: loss 13.153664
[epoch9, step293]: loss 16.377409
[epoch9, step294]: loss 3.226925
[epoch9, step295]: loss 14.536129
[epoch9, step296]: loss 6.067132
[epoch9, step297]: loss 2.833699
[epoch9, step298]: loss 13.720967
[epoch9, step299]: loss 1.443446
[epoch9, step300]: loss 15.351070
[epoch9, step301]: loss 12.282298
[epoch9, step302]: loss 1.183469
[epoch9, step303]: loss 5.001976
[epoch9, step304]: loss 2.054283
[epoch9, step305]: loss 2.496619
[epoch9, step306]: loss 13.814926
[epoch9, step307]: loss 2.604889
[epoch9, step308]: loss 2.921845
[epoch9, step309]: loss 2.594144
[epoch9, step310]: loss 11.162444
[epoch9, step311]: loss 1.170581
[epoch9, step312]: loss 18.056215
[epoch9, step313]: loss 17.731268
[epoch9, step314]: loss 3.057474
[epoch9, step315]: loss 5.157084
[epoch9, step316]: loss 3.575311
[epoch9, step317]: loss 2.059480
[epoch9, step318]: loss 4.636472
[epoch9, step319]: loss 1.778162
[epoch9, step320]: loss 9.984048
[epoch9, step321]: loss 1.521533
[epoch9, step322]: loss 2.294538
[epoch9, step323]: loss 5.466174
[epoch9, step324]: loss 15.735234
[epoch9, step325]: loss 3.501122
[epoch9, step326]: loss 1.390386
[epoch9, step327]: loss 37.407097
[epoch9, step328]: loss 6.375479
[epoch9, step329]: loss 13.804301
[epoch9, step330]: loss 2.471405
[epoch9, step331]: loss 3.372034
[epoch9, step332]: loss 1.810688
[epoch9, step333]: loss 1.531344
[epoch9, step334]: loss 16.731123
[epoch9, step335]: loss 2.343127
[epoch9, step336]: loss 3.950638
[epoch9, step337]: loss 2.089083
[epoch9, step338]: loss 1.363421
[epoch9, step339]: loss 22.490971
[epoch9, step340]: loss 1.626063
[epoch9, step341]: loss 3.584062
[epoch9, step342]: loss 14.001432
[epoch9, step343]: loss 1.158442
[epoch9, step344]: loss 1.656027
[epoch9, step345]: loss 1.472419
[epoch9, step346]: loss 17.844006
[epoch9, step347]: loss 1.827557
[epoch9, step348]: loss 2.630902
[epoch9, step349]: loss 1.760885
[epoch9, step350]: loss 1.419161
[epoch9, step351]: loss 4.784158
[epoch9, step352]: loss 1.473530
[epoch9, step353]: loss 10.393978
[epoch9, step354]: loss 8.011454
[epoch9, step355]: loss 2.060570
[epoch9, step356]: loss 12.113034
[epoch9, step357]: loss 6.121144
[epoch9, step358]: loss 3.117693
[epoch9, step359]: loss 2.635456
[epoch9, step360]: loss 23.326500
[epoch9, step361]: loss 4.002614
[epoch9, step362]: loss 23.262737
[epoch9, step363]: loss 1.400040
[epoch9, step364]: loss 3.526271
[epoch9, step365]: loss 2.453750
[epoch9, step366]: loss 1.222105
[epoch9, step367]: loss 1.946845
[epoch9, step368]: loss 2.630727
[epoch9, step369]: loss 4.327812
[epoch9, step370]: loss 2.589619
[epoch9, step371]: loss 4.902735
[epoch9, step372]: loss 14.652645
[epoch9, step373]: loss 7.358479
[epoch9, step374]: loss 4.338837
[epoch9, step375]: loss 1.161264
[epoch9, step376]: loss 1.564130
[epoch9, step377]: loss 7.455972
[epoch9, step378]: loss 1.631750
[epoch9, step379]: loss 1.975869
[epoch9, step380]: loss 11.156237
[epoch9, step381]: loss 5.374713
[epoch9, step382]: loss 2.203654
[epoch9, step383]: loss 1.187477
[epoch9, step384]: loss 6.150676
[epoch9, step385]: loss 11.529892
[epoch9, step386]: loss 0.896421
[epoch9, step387]: loss 0.668853
[epoch9, step388]: loss 1.984839
[epoch9, step389]: loss 2.010404
[epoch9, step390]: loss 22.138601
[epoch9, step391]: loss 12.587452
[epoch9, step392]: loss 22.059483
[epoch9, step393]: loss 17.770376
[epoch9, step394]: loss 1.636310
[epoch9, step395]: loss 3.277089
[epoch9, step396]: loss 3.155103
[epoch9, step397]: loss 1.920144
[epoch9, step398]: loss 8.731049
[epoch9, step399]: loss 11.360147
[epoch9, step400]: loss 1.736625
[epoch9, step401]: loss 1.279900
[epoch9, step402]: loss 2.314364
[epoch9, step403]: loss 1.704779
[epoch9, step404]: loss 15.511875
[epoch9, step405]: loss 8.243711
[epoch9, step406]: loss 4.368290
[epoch9, step407]: loss 1.997231
[epoch9, step408]: loss 1.551985
[epoch9, step409]: loss 36.551571
[epoch9, step410]: loss 14.102118
[epoch9, step411]: loss 3.851031
[epoch9, step412]: loss 6.172496
[epoch9, step413]: loss 3.491996
[epoch9, step414]: loss 9.749854
[epoch9, step415]: loss 2.794421
[epoch9, step416]: loss 2.455242
[epoch9, step417]: loss 1.703407
[epoch9, step418]: loss 43.557762
[epoch9, step419]: loss 1.806479
[epoch9, step420]: loss 44.241463
[epoch9, step421]: loss 2.880717
[epoch9, step422]: loss 1.940687
[epoch9, step423]: loss 16.390474
[epoch9, step424]: loss 7.359847
[epoch9, step425]: loss 1.448970
[epoch9, step426]: loss 1.150575
[epoch9, step427]: loss 13.960416
[epoch9, step428]: loss 15.363317
[epoch9, step429]: loss 17.917801
[epoch9, step430]: loss 1.738274
[epoch9, step431]: loss 2.506839
[epoch9, step432]: loss 4.642838
[epoch9, step433]: loss 1.722411
[epoch9, step434]: loss 1.161356
[epoch9, step435]: loss 2.717289
[epoch9, step436]: loss 3.854440
[epoch9, step437]: loss 1.453578
[epoch9, step438]: loss 1.050236
[epoch9, step439]: loss 2.151586
[epoch9, step440]: loss 4.156030
[epoch9, step441]: loss 6.893468
[epoch9, step442]: loss 3.639137
[epoch9, step443]: loss 2.190901
[epoch9, step444]: loss 21.948498
[epoch9, step445]: loss 14.136198
[epoch9, step446]: loss 11.277343
[epoch9, step447]: loss 13.506154
[epoch9, step448]: loss 1.593811
[epoch9, step449]: loss 1.524641
[epoch9, step450]: loss 4.197665
[epoch9, step451]: loss 1.829982
[epoch9, step452]: loss 13.037995
[epoch9, step453]: loss 2.395542
[epoch9, step454]: loss 3.591104
[epoch9, step455]: loss 12.041945
[epoch9, step456]: loss 1.725920
[epoch9, step457]: loss 13.922729
[epoch9, step458]: loss 3.050027
[epoch9, step459]: loss 1.901174
[epoch9, step460]: loss 10.807678
[epoch9, step461]: loss 2.102531
[epoch9, step462]: loss 1.366727
[epoch9, step463]: loss 3.714791
[epoch9, step464]: loss 12.316019
[epoch9, step465]: loss 2.317496
[epoch9, step466]: loss 14.465762
[epoch9, step467]: loss 34.098595
[epoch9, step468]: loss 1.820953
[epoch9, step469]: loss 1.178752
[epoch9, step470]: loss 1.732274
[epoch9, step471]: loss 2.927870
[epoch9, step472]: loss 1.450381
[epoch9, step473]: loss 17.599209
[epoch9, step474]: loss 32.176994
[epoch9, step475]: loss 2.995278
[epoch9, step476]: loss 2.200840
[epoch9, step477]: loss 12.931461
[epoch9, step478]: loss 7.367596
[epoch9, step479]: loss 13.296548
[epoch9, step480]: loss 2.472770
[epoch9, step481]: loss 1.561394
[epoch9, step482]: loss 21.366693
[epoch9, step483]: loss 3.431331
[epoch9, step484]: loss 6.396726
[epoch9, step485]: loss 1.372408
[epoch9, step486]: loss 1.244338
[epoch9, step487]: loss 13.370255
[epoch9, step488]: loss 2.781563
[epoch9, step489]: loss 2.717563
[epoch9, step490]: loss 1.866926
[epoch9, step491]: loss 1.273373
[epoch9, step492]: loss 2.245990
[epoch9, step493]: loss 6.911291
[epoch9, step494]: loss 1.923619
[epoch9, step495]: loss 2.892064
[epoch9, step496]: loss 3.143086
[epoch9, step497]: loss 1.809068
[epoch9, step498]: loss 22.990158
[epoch9, step499]: loss 13.622029
[epoch9, step500]: loss 2.858427
[epoch9, step501]: loss 1.104264
[epoch9, step502]: loss 2.472034
[epoch9, step503]: loss 3.501391
[epoch9, step504]: loss 3.790505
[epoch9, step505]: loss 1.531472
[epoch9, step506]: loss 1.421387
[epoch9, step507]: loss 2.250535
[epoch9, step508]: loss 20.685863
[epoch9, step509]: loss 2.779293
[epoch9, step510]: loss 1.571083
[epoch9, step511]: loss 18.286007
[epoch9, step512]: loss 2.268959
[epoch9, step513]: loss 5.866588
[epoch9, step514]: loss 2.058805
[epoch9, step515]: loss 1.917691
[epoch9, step516]: loss 2.024976
[epoch9, step517]: loss 3.519429
[epoch9, step518]: loss 2.503069
[epoch9, step519]: loss 1.995823
[epoch9, step520]: loss 3.204650
[epoch9, step521]: loss 8.552754
[epoch9, step522]: loss 24.967003
[epoch9, step523]: loss 2.064102
[epoch9, step524]: loss 21.788181
[epoch9, step525]: loss 11.876132
[epoch9, step526]: loss 4.510108
[epoch9, step527]: loss 4.757601
[epoch9, step528]: loss 15.204159
[epoch9, step529]: loss 10.291192
[epoch9, step530]: loss 1.894600
[epoch9, step531]: loss 4.023182
[epoch9, step532]: loss 1.475448
[epoch9, step533]: loss 1.288024
[epoch9, step534]: loss 2.076015
[epoch9, step535]: loss 1.197577
[epoch9, step536]: loss 1.586139
[epoch9, step537]: loss 2.310480
[epoch9, step538]: loss 7.131523
[epoch9, step539]: loss 1.130024
[epoch9, step540]: loss 1.449169
[epoch9, step541]: loss 2.246197
[epoch9, step542]: loss 4.143727
[epoch9, step543]: loss 0.978702
[epoch9, step544]: loss 23.985395
[epoch9, step545]: loss 2.334359
[epoch9, step546]: loss 2.282808
[epoch9, step547]: loss 1.838036
[epoch9, step548]: loss 8.596635
[epoch9, step549]: loss 2.770977
[epoch9, step550]: loss 3.880946
[epoch9, step551]: loss 3.499529
[epoch9, step552]: loss 25.105247
[epoch9, step553]: loss 6.298625
[epoch9, step554]: loss 12.847681
[epoch9, step555]: loss 5.724834
[epoch9, step556]: loss 25.174955
[epoch9, step557]: loss 5.602376
[epoch9, step558]: loss 1.732651
[epoch9, step559]: loss 15.760772
[epoch9, step560]: loss 2.257403
[epoch9, step561]: loss 8.468811
[epoch9, step562]: loss 8.923820
[epoch9, step563]: loss 7.117497
[epoch9, step564]: loss 1.108563
[epoch9, step565]: loss 2.592876
[epoch9, step566]: loss 5.938828
[epoch9, step567]: loss 4.776506
[epoch9, step568]: loss 2.389364
[epoch9, step569]: loss 18.358595
[epoch9, step570]: loss 1.745163
[epoch9, step571]: loss 23.305971
[epoch9, step572]: loss 2.552137
[epoch9, step573]: loss 1.689265
[epoch9, step574]: loss 1.488553
[epoch9, step575]: loss 2.912155
[epoch9, step576]: loss 1.691888
[epoch9, step577]: loss 1.531138
[epoch9, step578]: loss 16.676682
[epoch9, step579]: loss 6.882539
[epoch9, step580]: loss 1.316892
[epoch9, step581]: loss 7.120339
[epoch9, step582]: loss 2.904612
[epoch9, step583]: loss 2.378328
[epoch9, step584]: loss 4.077450
[epoch9, step585]: loss 2.949583
[epoch9, step586]: loss 14.925857
[epoch9, step587]: loss 3.244594
[epoch9, step588]: loss 6.951453
[epoch9, step589]: loss 1.050300
[epoch9, step590]: loss 21.676050
[epoch9, step591]: loss 3.343590
[epoch9, step592]: loss 7.913581
[epoch9, step593]: loss 32.221722
[epoch9, step594]: loss 4.292168
[epoch9, step595]: loss 13.902131
[epoch9, step596]: loss 1.645807
[epoch9, step597]: loss 3.651770
[epoch9, step598]: loss 11.990981
[epoch9, step599]: loss 1.341732
[epoch9, step600]: loss 1.772305
[epoch9, step601]: loss 1.359523
[epoch9, step602]: loss 19.804581
[epoch9, step603]: loss 24.988274
[epoch9, step604]: loss 13.667290
[epoch9, step605]: loss 17.700933
[epoch9, step606]: loss 1.034789
[epoch9, step607]: loss 4.474540
[epoch9, step608]: loss 1.570790
[epoch9, step609]: loss 7.458625
[epoch9, step610]: loss 2.652708
[epoch9, step611]: loss 4.425931
[epoch9, step612]: loss 1.443058
[epoch9, step613]: loss 16.552446
[epoch9, step614]: loss 2.427444
[epoch9, step615]: loss 15.500304
[epoch9, step616]: loss 1.678354
[epoch9, step617]: loss 2.085939
[epoch9, step618]: loss 6.773702
[epoch9, step619]: loss 1.761703
[epoch9, step620]: loss 11.937567
[epoch9, step621]: loss 12.326263
[epoch9, step622]: loss 1.073998
[epoch9, step623]: loss 2.912695
[epoch9, step624]: loss 2.099250
[epoch9, step625]: loss 1.400693
[epoch9, step626]: loss 13.708867
[epoch9, step627]: loss 1.782892
[epoch9, step628]: loss 2.570231
[epoch9, step629]: loss 34.015228
[epoch9, step630]: loss 2.074285
[epoch9, step631]: loss 2.019653
[epoch9, step632]: loss 1.699630
[epoch9, step633]: loss 1.789921
[epoch9, step634]: loss 1.570343
[epoch9, step635]: loss 2.403120
[epoch9, step636]: loss 20.894924
[epoch9, step637]: loss 2.644695
[epoch9, step638]: loss 2.788991
[epoch9, step639]: loss 4.128867
[epoch9, step640]: loss 2.980980
[epoch9, step641]: loss 9.588583
[epoch9, step642]: loss 2.248845
[epoch9, step643]: loss 2.409811
[epoch9, step644]: loss 2.865195
[epoch9, step645]: loss 15.169306
[epoch9, step646]: loss 20.789228
[epoch9, step647]: loss 1.412037
[epoch9, step648]: loss 3.207017
[epoch9, step649]: loss 3.372241
[epoch9, step650]: loss 3.444155
[epoch9, step651]: loss 3.054738
[epoch9, step652]: loss 6.518890
[epoch9, step653]: loss 1.291011
[epoch9, step654]: loss 2.255699
[epoch9, step655]: loss 1.846002
[epoch9, step656]: loss 4.081326
[epoch9, step657]: loss 30.874941
[epoch9, step658]: loss 14.318964
[epoch9, step659]: loss 2.031725
[epoch9, step660]: loss 15.496803
[epoch9, step661]: loss 5.005207
[epoch9, step662]: loss 2.642521
[epoch9, step663]: loss 8.780664
[epoch9, step664]: loss 3.091112
[epoch9, step665]: loss 2.166828
[epoch9, step666]: loss 1.585740
[epoch9, step667]: loss 1.034182
[epoch9, step668]: loss 1.138501
[epoch9, step669]: loss 42.899029
[epoch9, step670]: loss 3.467816
[epoch9, step671]: loss 3.288438
[epoch9, step672]: loss 1.449839
[epoch9, step673]: loss 19.048830
[epoch9, step674]: loss 1.047637
[epoch9, step675]: loss 32.438580
[epoch9, step676]: loss 1.128080
[epoch9, step677]: loss 14.363131
[epoch9, step678]: loss 3.531789
[epoch9, step679]: loss 6.265277
[epoch9, step680]: loss 4.163043
[epoch9, step681]: loss 3.704420
[epoch9, step682]: loss 2.176076
[epoch9, step683]: loss 3.989460
[epoch9, step684]: loss 1.196151
[epoch9, step685]: loss 2.166245
[epoch9, step686]: loss 2.979947
[epoch9, step687]: loss 13.463975
[epoch9, step688]: loss 2.629527
[epoch9, step689]: loss 5.578445
[epoch9, step690]: loss 2.788868
[epoch9, step691]: loss 2.349660
[epoch9, step692]: loss 2.318219
[epoch9, step693]: loss 13.867245
[epoch9, step694]: loss 8.776748
[epoch9, step695]: loss 27.905746
[epoch9, step696]: loss 1.357971
[epoch9, step697]: loss 7.518871
[epoch9, step698]: loss 12.990459
[epoch9, step699]: loss 4.230287
[epoch9, step700]: loss 2.303536
[epoch9, step701]: loss 1.835465
[epoch9, step702]: loss 13.823065
[epoch9, step703]: loss 1.761814
[epoch9, step704]: loss 2.364217
[epoch9, step705]: loss 2.243339
[epoch9, step706]: loss 5.130931
[epoch9, step707]: loss 3.665567
[epoch9, step708]: loss 13.507235
[epoch9, step709]: loss 6.795811
[epoch9, step710]: loss 1.016226
[epoch9, step711]: loss 2.790559
[epoch9, step712]: loss 0.914165
[epoch9, step713]: loss 3.468552
[epoch9, step714]: loss 11.592570
[epoch9, step715]: loss 1.460606
[epoch9, step716]: loss 4.113950
[epoch9, step717]: loss 10.220855
[epoch9, step718]: loss 13.224105
[epoch9, step719]: loss 18.602879
[epoch9, step720]: loss 8.984070
[epoch9, step721]: loss 2.458730
[epoch9, step722]: loss 3.550970
[epoch9, step723]: loss 20.747051
[epoch9, step724]: loss 3.398892
[epoch9, step725]: loss 5.277477
[epoch9, step726]: loss 6.787734
[epoch9, step727]: loss 14.066387
[epoch9, step728]: loss 6.569385
[epoch9, step729]: loss 1.728816
[epoch9, step730]: loss 14.034210
[epoch9, step731]: loss 7.273730
[epoch9, step732]: loss 2.626602
[epoch9, step733]: loss 9.618769
[epoch9, step734]: loss 13.070756
[epoch9, step735]: loss 3.008321
[epoch9, step736]: loss 9.274467
[epoch9, step737]: loss 12.977521
[epoch9, step738]: loss 1.754179
[epoch9, step739]: loss 15.238557
[epoch9, step740]: loss 16.213385
[epoch9, step741]: loss 2.133252
[epoch9, step742]: loss 8.904627
[epoch9, step743]: loss 4.809544
[epoch9, step744]: loss 2.494464
[epoch9, step745]: loss 3.688913
[epoch9, step746]: loss 17.100964
[epoch9, step747]: loss 6.025235
[epoch9, step748]: loss 3.176379
[epoch9, step749]: loss 17.515081
[epoch9, step750]: loss 10.793925
[epoch9, step751]: loss 4.588861
[epoch9, step752]: loss 2.935599
[epoch9, step753]: loss 1.598177
[epoch9, step754]: loss 3.236296
[epoch9, step755]: loss 0.934005
[epoch9, step756]: loss 2.743008
[epoch9, step757]: loss 2.915184
[epoch9, step758]: loss 1.881414
[epoch9, step759]: loss 4.263521
[epoch9, step760]: loss 7.492489
[epoch9, step761]: loss 22.337456
[epoch9, step762]: loss 1.361917
[epoch9, step763]: loss 4.612675
[epoch9, step764]: loss 1.573144
[epoch9, step765]: loss 1.657429
[epoch9, step766]: loss 7.394588
[epoch9, step767]: loss 20.824160
[epoch9, step768]: loss 0.883445
[epoch9, step769]: loss 9.707506
[epoch9, step770]: loss 2.845423
[epoch9, step771]: loss 1.278643
[epoch9, step772]: loss 1.569748
[epoch9, step773]: loss 1.927604
[epoch9, step774]: loss 1.530699
[epoch9, step775]: loss 8.995984
[epoch9, step776]: loss 2.911171
[epoch9, step777]: loss 3.461114
[epoch9, step778]: loss 18.542194
[epoch9, step779]: loss 1.598114
[epoch9, step780]: loss 1.885186
[epoch9, step781]: loss 2.433715
[epoch9, step782]: loss 2.571306
[epoch9, step783]: loss 1.892420
[epoch9, step784]: loss 4.620493
[epoch9, step785]: loss 7.753305
[epoch9, step786]: loss 1.502588
[epoch9, step787]: loss 9.880137
[epoch9, step788]: loss 2.656467
[epoch9, step789]: loss 3.077343
[epoch9, step790]: loss 2.343388
[epoch9, step791]: loss 28.587845
[epoch9, step792]: loss 2.561955
[epoch9, step793]: loss 1.533221
[epoch9, step794]: loss 3.701756
[epoch9, step795]: loss 15.829453
[epoch9, step796]: loss 2.575595
[epoch9, step797]: loss 1.840066
[epoch9, step798]: loss 1.295018
[epoch9, step799]: loss 42.420124
[epoch9, step800]: loss 4.046103
[epoch9, step801]: loss 3.042674
[epoch9, step802]: loss 2.475650
[epoch9, step803]: loss 16.034672
[epoch9, step804]: loss 2.798273
[epoch9, step805]: loss 1.614061
[epoch9, step806]: loss 3.570841
[epoch9, step807]: loss 1.207261
[epoch9, step808]: loss 15.179889
[epoch9, step809]: loss 5.587537
[epoch9, step810]: loss 2.045982
[epoch9, step811]: loss 24.794212
[epoch9, step812]: loss 2.222951
[epoch9, step813]: loss 0.921601
[epoch9, step814]: loss 2.178348
[epoch9, step815]: loss 18.454878
[epoch9, step816]: loss 2.474396
[epoch9, step817]: loss 2.452038
[epoch9, step818]: loss 6.711596
[epoch9, step819]: loss 11.748930
[epoch9, step820]: loss 12.302850
[epoch9, step821]: loss 1.713976
[epoch9, step822]: loss 1.546732
[epoch9, step823]: loss 2.676121
[epoch9, step824]: loss 6.352075
[epoch9, step825]: loss 2.210273
[epoch9, step826]: loss 20.015329
[epoch9, step827]: loss 2.560234
[epoch9, step828]: loss 2.443773
[epoch9, step829]: loss 1.883598
[epoch9, step830]: loss 6.235719
[epoch9, step831]: loss 2.837653
[epoch9, step832]: loss 16.175468
[epoch9, step833]: loss 3.760962
[epoch9, step834]: loss 2.690683
[epoch9, step835]: loss 13.023461
[epoch9, step836]: loss 3.317270
[epoch9, step837]: loss 2.637991
[epoch9, step838]: loss 2.356395
[epoch9, step839]: loss 4.847530
[epoch9, step840]: loss 12.455613
[epoch9, step841]: loss 9.229805
[epoch9, step842]: loss 7.774180
[epoch9, step843]: loss 2.847295
[epoch9, step844]: loss 2.806019
[epoch9, step845]: loss 15.081225
[epoch9, step846]: loss 1.503367
[epoch9, step847]: loss 4.209816
[epoch9, step848]: loss 17.684938
[epoch9, step849]: loss 7.717586
[epoch9, step850]: loss 9.947429
[epoch9, step851]: loss 6.180318
[epoch9, step852]: loss 0.974039
[epoch9, step853]: loss 17.765520
[epoch9, step854]: loss 12.564542
[epoch9, step855]: loss 4.286997
[epoch9, step856]: loss 4.671502
[epoch9, step857]: loss 0.874487
[epoch9, step858]: loss 3.217389
[epoch9, step859]: loss 17.418930
[epoch9, step860]: loss 5.470631
[epoch9, step861]: loss 1.660338
[epoch9, step862]: loss 35.448685
[epoch9, step863]: loss 6.101965
[epoch9, step864]: loss 2.512454
[epoch9, step865]: loss 3.041831
[epoch9, step866]: loss 2.552966
[epoch9, step867]: loss 2.523028
[epoch9, step868]: loss 34.690926
[epoch9, step869]: loss 4.021420
[epoch9, step870]: loss 2.095973
[epoch9, step871]: loss 1.789277
[epoch9, step872]: loss 31.222094
[epoch9, step873]: loss 2.920902
[epoch9, step874]: loss 2.516020
[epoch9, step875]: loss 17.581432
[epoch9, step876]: loss 1.572226
[epoch9, step877]: loss 5.584169
[epoch9, step878]: loss 3.327971
[epoch9, step879]: loss 8.685165
[epoch9, step880]: loss 2.201311
[epoch9, step881]: loss 1.319782
[epoch9, step882]: loss 1.887483
[epoch9, step883]: loss 1.480224
[epoch9, step884]: loss 2.278614
[epoch9, step885]: loss 3.304338
[epoch9, step886]: loss 2.336113
[epoch9, step887]: loss 4.905839
[epoch9, step888]: loss 3.182474
[epoch9, step889]: loss 1.636412
[epoch9, step890]: loss 1.315980
[epoch9, step891]: loss 1.878128
[epoch9, step892]: loss 1.428289
[epoch9, step893]: loss 3.892508
[epoch9, step894]: loss 4.064547
[epoch9, step895]: loss 3.231882
[epoch9, step896]: loss 2.368474
[epoch9, step897]: loss 13.983677
[epoch9, step898]: loss 2.103338
[epoch9, step899]: loss 4.774468
[epoch9, step900]: loss 15.083916
[epoch9, step901]: loss 16.635101
[epoch9, step902]: loss 3.211605
[epoch9, step903]: loss 3.662370
[epoch9, step904]: loss 3.080644
[epoch9, step905]: loss 3.512588
[epoch9, step906]: loss 6.852128
[epoch9, step907]: loss 1.068787
[epoch9, step908]: loss 7.223599
[epoch9, step909]: loss 1.814627
[epoch9, step910]: loss 5.678778
[epoch9, step911]: loss 7.477498
[epoch9, step912]: loss 2.167291
[epoch9, step913]: loss 22.230085
[epoch9, step914]: loss 13.319269
[epoch9, step915]: loss 18.650537
[epoch9, step916]: loss 30.495035
[epoch9, step917]: loss 17.248745
[epoch9, step918]: loss 6.976836
[epoch9, step919]: loss 2.533547
[epoch9, step920]: loss 1.294872
[epoch9, step921]: loss 2.394526
[epoch9, step922]: loss 35.003689
[epoch9, step923]: loss 1.650406
[epoch9, step924]: loss 5.172691
[epoch9, step925]: loss 1.522047
[epoch9, step926]: loss 20.139935
[epoch9, step927]: loss 2.974686
[epoch9, step928]: loss 2.805708
[epoch9, step929]: loss 5.331678
[epoch9, step930]: loss 2.533548
[epoch9, step931]: loss 4.151282
[epoch9, step932]: loss 16.913748
[epoch9, step933]: loss 4.958371
[epoch9, step934]: loss 12.998313
[epoch9, step935]: loss 22.569059
[epoch9, step936]: loss 2.417254
[epoch9, step937]: loss 6.715643
[epoch9, step938]: loss 14.930636
[epoch9, step939]: loss 1.713055
[epoch9, step940]: loss 3.131767
[epoch9, step941]: loss 1.211492
[epoch9, step942]: loss 16.706182
[epoch9, step943]: loss 1.509742
[epoch9, step944]: loss 1.582889
[epoch9, step945]: loss 3.103221
[epoch9, step946]: loss 4.359141
[epoch9, step947]: loss 3.679459
[epoch9, step948]: loss 13.464028
[epoch9, step949]: loss 2.608944
[epoch9, step950]: loss 2.271531
[epoch9, step951]: loss 14.453258
[epoch9, step952]: loss 3.861973
[epoch9, step953]: loss 1.686961
[epoch9, step954]: loss 33.134651
[epoch9, step955]: loss 3.137358
[epoch9, step956]: loss 2.947645
[epoch9, step957]: loss 6.739334
[epoch9, step958]: loss 6.715217
[epoch9, step959]: loss 2.311680
[epoch9, step960]: loss 15.033788
[epoch9, step961]: loss 1.919697
[epoch9, step962]: loss 2.235812
[epoch9, step963]: loss 3.092257
[epoch9, step964]: loss 1.641966
[epoch9, step965]: loss 2.099017
[epoch9, step966]: loss 9.517132
[epoch9, step967]: loss 1.429422
[epoch9, step968]: loss 3.215812
[epoch9, step969]: loss 2.126013
[epoch9, step970]: loss 1.310303
[epoch9, step971]: loss 1.437595
[epoch9, step972]: loss 1.887842
[epoch9, step973]: loss 16.905968
[epoch9, step974]: loss 4.838895
[epoch9, step975]: loss 16.618399
[epoch9, step976]: loss 8.104357
[epoch9, step977]: loss 15.363753
[epoch9, step978]: loss 1.493629
[epoch9, step979]: loss 3.342699
[epoch9, step980]: loss 1.267406
[epoch9, step981]: loss 4.936352
[epoch9, step982]: loss 1.768008
[epoch9, step983]: loss 1.806404
[epoch9, step984]: loss 5.239053
[epoch9, step985]: loss 11.572876
[epoch9, step986]: loss 26.025774
[epoch9, step987]: loss 33.445282
[epoch9, step988]: loss 2.066952
[epoch9, step989]: loss 1.248238
[epoch9, step990]: loss 4.690175
[epoch9, step991]: loss 2.131077
[epoch9, step992]: loss 6.575310
[epoch9, step993]: loss 14.697322
[epoch9, step994]: loss 7.387322
[epoch9, step995]: loss 55.621704
[epoch9, step996]: loss 5.784803
[epoch9, step997]: loss 9.885112
[epoch9, step998]: loss 2.895851
[epoch9, step999]: loss 4.142943
[epoch9, step1000]: loss 1.555693
[epoch9, step1001]: loss 1.466439
[epoch9, step1002]: loss 7.510345
[epoch9, step1003]: loss 6.775929
[epoch9, step1004]: loss 18.224913
[epoch9, step1005]: loss 2.430025
[epoch9, step1006]: loss 1.228110
[epoch9, step1007]: loss 13.182964
[epoch9, step1008]: loss 2.084972
[epoch9, step1009]: loss 17.176966
[epoch9, step1010]: loss 3.728776
[epoch9, step1011]: loss 8.267326
[epoch9, step1012]: loss 2.257176
[epoch9, step1013]: loss 17.948826
[epoch9, step1014]: loss 26.670235
[epoch9, step1015]: loss 1.190669
[epoch9, step1016]: loss 2.025397
[epoch9, step1017]: loss 21.471994
[epoch9, step1018]: loss 30.957178
[epoch9, step1019]: loss 15.869017
[epoch9, step1020]: loss 1.542559
[epoch9, step1021]: loss 2.974320
[epoch9, step1022]: loss 16.097767
[epoch9, step1023]: loss 3.459859
[epoch9, step1024]: loss 1.257188
[epoch9, step1025]: loss 1.772970
[epoch9, step1026]: loss 3.348391
[epoch9, step1027]: loss 3.737903
[epoch9, step1028]: loss 2.447782
[epoch9, step1029]: loss 2.838830
[epoch9, step1030]: loss 3.479480
[epoch9, step1031]: loss 1.044565
[epoch9, step1032]: loss 1.851216
[epoch9, step1033]: loss 22.492708
[epoch9, step1034]: loss 6.936603
[epoch9, step1035]: loss 3.656620
[epoch9, step1036]: loss 14.509275
[epoch9, step1037]: loss 1.618379
[epoch9, step1038]: loss 1.600613
[epoch9, step1039]: loss 1.972502
[epoch9, step1040]: loss 17.975208
[epoch9, step1041]: loss 3.041040
[epoch9, step1042]: loss 2.640365
[epoch9, step1043]: loss 1.621036
[epoch9, step1044]: loss 1.092806
[epoch9, step1045]: loss 5.041455
[epoch9, step1046]: loss 17.563732
[epoch9, step1047]: loss 4.873847
[epoch9, step1048]: loss 8.892220
[epoch9, step1049]: loss 2.492589
[epoch9, step1050]: loss 2.328629
[epoch9, step1051]: loss 1.758774
[epoch9, step1052]: loss 2.638788
[epoch9, step1053]: loss 1.066918
[epoch9, step1054]: loss 1.938637
[epoch9, step1055]: loss 1.229533
[epoch9, step1056]: loss 17.484413
[epoch9, step1057]: loss 4.013832
[epoch9, step1058]: loss 1.180797
[epoch9, step1059]: loss 1.519684
[epoch9, step1060]: loss 16.713167
[epoch9, step1061]: loss 13.867043
[epoch9, step1062]: loss 2.064563
[epoch9, step1063]: loss 3.447489
[epoch9, step1064]: loss 17.939161
[epoch9, step1065]: loss 4.282195
[epoch9, step1066]: loss 4.339562
[epoch9, step1067]: loss 2.275723
[epoch9, step1068]: loss 12.829565
[epoch9, step1069]: loss 14.115603
[epoch9, step1070]: loss 20.832102
[epoch9, step1071]: loss 3.127054
[epoch9, step1072]: loss 6.477612
[epoch9, step1073]: loss 2.379390
[epoch9, step1074]: loss 5.151735
[epoch9, step1075]: loss 1.630108
[epoch9, step1076]: loss 16.553144
[epoch9, step1077]: loss 1.486879
[epoch9, step1078]: loss 1.655122
[epoch9, step1079]: loss 2.885663
[epoch9, step1080]: loss 2.475932
[epoch9, step1081]: loss 13.867524
[epoch9, step1082]: loss 1.997591
[epoch9, step1083]: loss 3.516848
[epoch9, step1084]: loss 5.077694
[epoch9, step1085]: loss 1.699232
[epoch9, step1086]: loss 1.455058
[epoch9, step1087]: loss 1.097864
[epoch9, step1088]: loss 1.710418
[epoch9, step1089]: loss 1.757610
[epoch9, step1090]: loss 4.456386
[epoch9, step1091]: loss 3.001769
[epoch9, step1092]: loss 35.574394
[epoch9, step1093]: loss 13.377687
[epoch9, step1094]: loss 1.544068
[epoch9, step1095]: loss 1.037899
[epoch9, step1096]: loss 1.456451
[epoch9, step1097]: loss 4.596196
[epoch9, step1098]: loss 4.621043
[epoch9, step1099]: loss 2.328222
[epoch9, step1100]: loss 2.356357
[epoch9, step1101]: loss 38.039223
[epoch9, step1102]: loss 1.312154
[epoch9, step1103]: loss 5.452536
[epoch9, step1104]: loss 1.547757
[epoch9, step1105]: loss 1.353251
[epoch9, step1106]: loss 14.098364
[epoch9, step1107]: loss 1.817164
[epoch9, step1108]: loss 13.329960
[epoch9, step1109]: loss 18.265963
[epoch9, step1110]: loss 1.655535
[epoch9, step1111]: loss 12.258308
[epoch9, step1112]: loss 1.558424
[epoch9, step1113]: loss 5.266886
[epoch9, step1114]: loss 1.098943
[epoch9, step1115]: loss 2.141294
[epoch9, step1116]: loss 1.012565
[epoch9, step1117]: loss 12.936830
[epoch9, step1118]: loss 17.960032
[epoch9, step1119]: loss 4.583408
[epoch9, step1120]: loss 5.597236
[epoch9, step1121]: loss 9.211493
[epoch9, step1122]: loss 8.080708
[epoch9, step1123]: loss 2.903659
[epoch9, step1124]: loss 3.099892
[epoch9, step1125]: loss 6.361572
[epoch9, step1126]: loss 6.604344
[epoch9, step1127]: loss 10.120929
[epoch9, step1128]: loss 1.780398
[epoch9, step1129]: loss 21.937227
[epoch9, step1130]: loss 5.985357
[epoch9, step1131]: loss 3.763450
[epoch9, step1132]: loss 3.316842
[epoch9, step1133]: loss 2.950943
[epoch9, step1134]: loss 1.421103
[epoch9, step1135]: loss 5.297402
[epoch9, step1136]: loss 17.309126
[epoch9, step1137]: loss 7.619155
[epoch9, step1138]: loss 15.510743
[epoch9, step1139]: loss 3.117611
[epoch9, step1140]: loss 12.763348
[epoch9, step1141]: loss 2.806400
[epoch9, step1142]: loss 1.730857
[epoch9, step1143]: loss 20.922501
[epoch9, step1144]: loss 15.964025
[epoch9, step1145]: loss 7.152205
[epoch9, step1146]: loss 3.057673
[epoch9, step1147]: loss 2.364107
[epoch9, step1148]: loss 5.479955
[epoch9, step1149]: loss 20.390778
[epoch9, step1150]: loss 2.835901
[epoch9, step1151]: loss 1.933818
[epoch9, step1152]: loss 1.740179
[epoch9, step1153]: loss 1.809154
[epoch9, step1154]: loss 11.155350
[epoch9, step1155]: loss 5.813884
[epoch9, step1156]: loss 1.754938
[epoch9, step1157]: loss 2.197015
[epoch9, step1158]: loss 31.155382
[epoch9, step1159]: loss 5.203094
[epoch9, step1160]: loss 1.339509
[epoch9, step1161]: loss 3.426274
[epoch9, step1162]: loss 24.974854
[epoch9, step1163]: loss 3.885354
[epoch9, step1164]: loss 1.449288
[epoch9, step1165]: loss 3.050196
[epoch9, step1166]: loss 2.908007
[epoch9, step1167]: loss 3.727924
[epoch9, step1168]: loss 4.358299
[epoch9, step1169]: loss 2.961561
[epoch9, step1170]: loss 7.105182
[epoch9, step1171]: loss 1.590685
[epoch9, step1172]: loss 2.802454
[epoch9, step1173]: loss 11.550945
[epoch9, step1174]: loss 1.402406
[epoch9, step1175]: loss 0.747456
[epoch9, step1176]: loss 6.744565
[epoch9, step1177]: loss 10.250905
[epoch9, step1178]: loss 1.613178
[epoch9, step1179]: loss 14.533527
[epoch9, step1180]: loss 1.322570
[epoch9, step1181]: loss 10.685032
[epoch9, step1182]: loss 1.924491
[epoch9, step1183]: loss 4.891214
[epoch9, step1184]: loss 1.727656
[epoch9, step1185]: loss 15.842585
[epoch9, step1186]: loss 1.847827
[epoch9, step1187]: loss 1.904570
[epoch9, step1188]: loss 2.696721
[epoch9, step1189]: loss 2.258496
[epoch9, step1190]: loss 1.649367
[epoch9, step1191]: loss 2.423311
[epoch9, step1192]: loss 17.066771
[epoch9, step1193]: loss 2.066038
[epoch9, step1194]: loss 4.469690
[epoch9, step1195]: loss 12.132288
[epoch9, step1196]: loss 1.488249
[epoch9, step1197]: loss 16.200672
[epoch9, step1198]: loss 1.330346
[epoch9, step1199]: loss 1.461431
[epoch9, step1200]: loss 9.702901
[epoch9, step1201]: loss 17.391962
[epoch9, step1202]: loss 2.442494
[epoch9, step1203]: loss 9.821779
[epoch9, step1204]: loss 1.931578
[epoch9, step1205]: loss 1.450937
[epoch9, step1206]: loss 1.111216
[epoch9, step1207]: loss 1.243336
[epoch9, step1208]: loss 44.588463
[epoch9, step1209]: loss 14.898017
[epoch9, step1210]: loss 17.057081
[epoch9, step1211]: loss 1.264684
[epoch9, step1212]: loss 2.543936
[epoch9, step1213]: loss 2.391079
[epoch9, step1214]: loss 7.059602
[epoch9, step1215]: loss 22.371330
[epoch9, step1216]: loss 12.006859
[epoch9, step1217]: loss 3.409698
[epoch9, step1218]: loss 13.786828
[epoch9, step1219]: loss 4.406838
[epoch9, step1220]: loss 1.791455
[epoch9, step1221]: loss 4.067028
[epoch9, step1222]: loss 9.726016
[epoch9, step1223]: loss 0.894475
[epoch9, step1224]: loss 1.654149
[epoch9, step1225]: loss 1.485749
[epoch9, step1226]: loss 4.493731
[epoch9, step1227]: loss 3.953983
[epoch9, step1228]: loss 3.803212
[epoch9, step1229]: loss 1.124151
[epoch9, step1230]: loss 11.366024
[epoch9, step1231]: loss 2.631593
[epoch9, step1232]: loss 2.278695
[epoch9, step1233]: loss 12.722343
[epoch9, step1234]: loss 3.811498
[epoch9, step1235]: loss 1.668809
[epoch9, step1236]: loss 3.384541
[epoch9, step1237]: loss 7.831789
[epoch9, step1238]: loss 5.039588
[epoch9, step1239]: loss 2.303373
[epoch9, step1240]: loss 1.911296
[epoch9, step1241]: loss 1.962810
[epoch9, step1242]: loss 1.706738
[epoch9, step1243]: loss 2.832942
[epoch9, step1244]: loss 2.256744
[epoch9, step1245]: loss 1.194291
[epoch9, step1246]: loss 2.405701
[epoch9, step1247]: loss 2.257740
[epoch9, step1248]: loss 3.820034
[epoch9, step1249]: loss 1.293155
[epoch9, step1250]: loss 2.433191
[epoch9, step1251]: loss 2.489092
[epoch9, step1252]: loss 1.086319
[epoch9, step1253]: loss 13.428264
[epoch9, step1254]: loss 2.467420
[epoch9, step1255]: loss 14.441774
[epoch9, step1256]: loss 1.177373
[epoch9, step1257]: loss 4.800560
[epoch9, step1258]: loss 2.643764
[epoch9, step1259]: loss 3.168734
[epoch9, step1260]: loss 2.605971
[epoch9, step1261]: loss 27.254885
[epoch9, step1262]: loss 1.437336
[epoch9, step1263]: loss 2.414594
[epoch9, step1264]: loss 2.761300
[epoch9, step1265]: loss 11.112650
[epoch9, step1266]: loss 16.389286
[epoch9, step1267]: loss 1.589368
[epoch9, step1268]: loss 3.865507
[epoch9, step1269]: loss 2.229747
[epoch9, step1270]: loss 14.901208
[epoch9, step1271]: loss 2.324922
[epoch9, step1272]: loss 1.617018
[epoch9, step1273]: loss 1.440528
[epoch9, step1274]: loss 2.826399
[epoch9, step1275]: loss 1.976092
[epoch9, step1276]: loss 0.865621
[epoch9, step1277]: loss 1.293619
[epoch9, step1278]: loss 1.175196
[epoch9, step1279]: loss 2.068112
[epoch9, step1280]: loss 3.082255
[epoch9, step1281]: loss 2.889353
[epoch9, step1282]: loss 2.322030
[epoch9, step1283]: loss 20.315262
[epoch9, step1284]: loss 17.623978
[epoch9, step1285]: loss 4.185236
[epoch9, step1286]: loss 21.703524
[epoch9, step1287]: loss 18.427786
[epoch9, step1288]: loss 2.220840
[epoch9, step1289]: loss 6.225681
[epoch9, step1290]: loss 1.650085
[epoch9, step1291]: loss 1.803158
[epoch9, step1292]: loss 15.498571
[epoch9, step1293]: loss 3.013825
[epoch9, step1294]: loss 1.503086
[epoch9, step1295]: loss 4.023429
[epoch9, step1296]: loss 22.015514
[epoch9, step1297]: loss 1.883518
[epoch9, step1298]: loss 18.375525
[epoch9, step1299]: loss 28.935452
[epoch9, step1300]: loss 3.932742
[epoch9, step1301]: loss 14.299794
[epoch9, step1302]: loss 4.398448
[epoch9, step1303]: loss 1.868452
[epoch9, step1304]: loss 1.559905
[epoch9, step1305]: loss 2.112141
[epoch9, step1306]: loss 1.840164
[epoch9, step1307]: loss 2.533230
[epoch9, step1308]: loss 6.172523
[epoch9, step1309]: loss 1.434888
[epoch9, step1310]: loss 1.257728
[epoch9, step1311]: loss 13.724447
[epoch9, step1312]: loss 3.335804
[epoch9, step1313]: loss 1.392115
[epoch9, step1314]: loss 2.082377
[epoch9, step1315]: loss 1.568112
[epoch9, step1316]: loss 20.817900
[epoch9, step1317]: loss 3.456518
[epoch9, step1318]: loss 5.995684
[epoch9, step1319]: loss 1.013639
[epoch9, step1320]: loss 4.281527
[epoch9, step1321]: loss 20.762148
[epoch9, step1322]: loss 2.421694
[epoch9, step1323]: loss 1.769346
[epoch9, step1324]: loss 2.542850
[epoch9, step1325]: loss 2.132477
[epoch9, step1326]: loss 2.097928
[epoch9, step1327]: loss 2.350559
[epoch9, step1328]: loss 1.059969
[epoch9, step1329]: loss 2.100919
[epoch9, step1330]: loss 13.021427
[epoch9, step1331]: loss 1.754597
[epoch9, step1332]: loss 5.899772
[epoch9, step1333]: loss 1.286916
[epoch9, step1334]: loss 20.694599
[epoch9, step1335]: loss 6.582667
[epoch9, step1336]: loss 1.314067
[epoch9, step1337]: loss 13.463425
[epoch9, step1338]: loss 1.509311
[epoch9, step1339]: loss 1.452699
[epoch9, step1340]: loss 3.797566
[epoch9, step1341]: loss 2.174613
[epoch9, step1342]: loss 8.525797
[epoch9, step1343]: loss 1.393341
[epoch9, step1344]: loss 2.282763
[epoch9, step1345]: loss 1.598090
[epoch9, step1346]: loss 1.007083
[epoch9, step1347]: loss 1.694701
[epoch9, step1348]: loss 1.935555
[epoch9, step1349]: loss 34.722248
[epoch9, step1350]: loss 12.011810
[epoch9, step1351]: loss 20.508472
[epoch9, step1352]: loss 1.985116
[epoch9, step1353]: loss 3.949265
[epoch9, step1354]: loss 9.858692
[epoch9, step1355]: loss 1.375498
[epoch9, step1356]: loss 21.246761
[epoch9, step1357]: loss 16.197836
[epoch9, step1358]: loss 1.920606
[epoch9, step1359]: loss 16.307524
[epoch9, step1360]: loss 39.876728
[epoch9, step1361]: loss 15.373981
[epoch9, step1362]: loss 1.740127
[epoch9, step1363]: loss 23.371677
[epoch9, step1364]: loss 1.969197
[epoch9, step1365]: loss 12.483521
[epoch9, step1366]: loss 2.683652
[epoch9, step1367]: loss 1.549544
[epoch9, step1368]: loss 1.584207
[epoch9, step1369]: loss 2.830085
[epoch9, step1370]: loss 11.917156
[epoch9, step1371]: loss 4.508367
[epoch9, step1372]: loss 2.324894
[epoch9, step1373]: loss 2.238323
[epoch9, step1374]: loss 1.238932
[epoch9, step1375]: loss 1.137080
[epoch9, step1376]: loss 4.570066
[epoch9, step1377]: loss 1.029992
[epoch9, step1378]: loss 5.915995
[epoch9, step1379]: loss 2.029794
[epoch9, step1380]: loss 12.140872
[epoch9, step1381]: loss 1.770335
[epoch9, step1382]: loss 5.231330
[epoch9, step1383]: loss 3.602897
[epoch9, step1384]: loss 4.198507
[epoch9, step1385]: loss 4.885712
[epoch9, step1386]: loss 27.961626
[epoch9, step1387]: loss 1.797856
[epoch9, step1388]: loss 14.108047
[epoch9, step1389]: loss 17.195774
[epoch9, step1390]: loss 1.202438
[epoch9, step1391]: loss 2.875819
[epoch9, step1392]: loss 3.619448
[epoch9, step1393]: loss 9.927814
[epoch9, step1394]: loss 1.821489
[epoch9, step1395]: loss 0.970261
[epoch9, step1396]: loss 1.685674
[epoch9, step1397]: loss 43.037334
[epoch9, step1398]: loss 6.175605
[epoch9, step1399]: loss 7.574901
[epoch9, step1400]: loss 4.262310
[epoch9, step1401]: loss 2.119046
[epoch9, step1402]: loss 21.298605
[epoch9, step1403]: loss 7.089669
[epoch9, step1404]: loss 2.654759
[epoch9, step1405]: loss 2.339651
[epoch9, step1406]: loss 6.237576
[epoch9, step1407]: loss 2.962267
[epoch9, step1408]: loss 19.772314
[epoch9, step1409]: loss 4.614995
[epoch9, step1410]: loss 2.578938
[epoch9, step1411]: loss 2.716011
[epoch9, step1412]: loss 2.005626
[epoch9, step1413]: loss 3.318905
[epoch9, step1414]: loss 3.565242
[epoch9, step1415]: loss 12.495750
[epoch9, step1416]: loss 2.054585
[epoch9, step1417]: loss 2.595709
[epoch9, step1418]: loss 7.061863
[epoch9, step1419]: loss 3.966607
[epoch9, step1420]: loss 4.064480
[epoch9, step1421]: loss 2.891225
[epoch9, step1422]: loss 20.828749
[epoch9, step1423]: loss 4.577334
[epoch9, step1424]: loss 11.844317
[epoch9, step1425]: loss 0.890929
[epoch9, step1426]: loss 1.325857
[epoch9, step1427]: loss 1.614814
[epoch9, step1428]: loss 2.360030
[epoch9, step1429]: loss 1.913782
[epoch9, step1430]: loss 1.590845
[epoch9, step1431]: loss 3.198397
[epoch9, step1432]: loss 1.206927
[epoch9, step1433]: loss 30.711214
[epoch9, step1434]: loss 2.758857
[epoch9, step1435]: loss 1.399951
[epoch9, step1436]: loss 0.702313
[epoch9, step1437]: loss 12.774304
[epoch9, step1438]: loss 12.967678
[epoch9, step1439]: loss 3.870752
[epoch9, step1440]: loss 1.300366
[epoch9, step1441]: loss 2.922020
[epoch9, step1442]: loss 3.013076
[epoch9, step1443]: loss 28.567055
[epoch9, step1444]: loss 22.194012
[epoch9, step1445]: loss 1.798996
[epoch9, step1446]: loss 3.152435
[epoch9, step1447]: loss 1.573995
[epoch9, step1448]: loss 3.205093
[epoch9, step1449]: loss 1.173906
[epoch9, step1450]: loss 2.956197
[epoch9, step1451]: loss 2.330581
[epoch9, step1452]: loss 5.243609
[epoch9, step1453]: loss 11.733112
[epoch9, step1454]: loss 2.498318
[epoch9, step1455]: loss 2.965191
[epoch9, step1456]: loss 3.171430
[epoch9, step1457]: loss 26.791357
[epoch9, step1458]: loss 1.971841
[epoch9, step1459]: loss 1.752236
[epoch9, step1460]: loss 6.025659
[epoch9, step1461]: loss 3.172245
[epoch9, step1462]: loss 1.001572
[epoch9, step1463]: loss 4.326520
[epoch9, step1464]: loss 2.344213
[epoch9, step1465]: loss 3.486248
[epoch9, step1466]: loss 5.460488
[epoch9, step1467]: loss 2.453054
[epoch9, step1468]: loss 1.805437
[epoch9, step1469]: loss 16.065804
[epoch9, step1470]: loss 2.062186
[epoch9, step1471]: loss 3.931556
[epoch9, step1472]: loss 13.061743
[epoch9, step1473]: loss 2.347234
[epoch9, step1474]: loss 1.605975
[epoch9, step1475]: loss 3.427510
[epoch9, step1476]: loss 1.442989
[epoch9, step1477]: loss 24.126059
[epoch9, step1478]: loss 1.652984
[epoch9, step1479]: loss 2.136094
[epoch9, step1480]: loss 2.175732
[epoch9, step1481]: loss 4.807150
[epoch9, step1482]: loss 6.719793
[epoch9, step1483]: loss 13.870132
[epoch9, step1484]: loss 1.223628
[epoch9, step1485]: loss 16.672899
[epoch9, step1486]: loss 1.608783
[epoch9, step1487]: loss 1.258868
[epoch9, step1488]: loss 13.433890
[epoch9, step1489]: loss 15.587826
[epoch9, step1490]: loss 13.273805
[epoch9, step1491]: loss 2.097539
[epoch9, step1492]: loss 3.744173
[epoch9, step1493]: loss 2.072082
[epoch9, step1494]: loss 3.080138
[epoch9, step1495]: loss 4.061022
[epoch9, step1496]: loss 1.568826
[epoch9, step1497]: loss 5.011776
[epoch9, step1498]: loss 1.711625
[epoch9, step1499]: loss 7.548620
[epoch9, step1500]: loss 2.116997
[epoch9, step1501]: loss 8.437280
[epoch9, step1502]: loss 5.526507
[epoch9, step1503]: loss 13.441041
[epoch9, step1504]: loss 5.193604
[epoch9, step1505]: loss 2.023449
[epoch9, step1506]: loss 2.086926
[epoch9, step1507]: loss 10.463706
[epoch9, step1508]: loss 4.383018
[epoch9, step1509]: loss 1.646663
[epoch9, step1510]: loss 1.973007
[epoch9, step1511]: loss 18.076952
[epoch9, step1512]: loss 5.109151
[epoch9, step1513]: loss 16.096773
[epoch9, step1514]: loss 3.180005
[epoch9, step1515]: loss 2.697895
[epoch9, step1516]: loss 5.212315
[epoch9, step1517]: loss 3.159832
[epoch9, step1518]: loss 1.118916
[epoch9, step1519]: loss 9.615129
[epoch9, step1520]: loss 4.919201
[epoch9, step1521]: loss 32.215427
[epoch9, step1522]: loss 16.096567
[epoch9, step1523]: loss 20.357401
[epoch9, step1524]: loss 2.643300
[epoch9, step1525]: loss 1.294777
[epoch9, step1526]: loss 1.029881
[epoch9, step1527]: loss 1.191781
[epoch9, step1528]: loss 8.292290
[epoch9, step1529]: loss 6.545059
[epoch9, step1530]: loss 7.289006
[epoch9, step1531]: loss 1.322670
[epoch9, step1532]: loss 20.201956
[epoch9, step1533]: loss 3.086626
[epoch9, step1534]: loss 3.299958
[epoch9, step1535]: loss 4.340764
[epoch9, step1536]: loss 28.284584
[epoch9, step1537]: loss 2.671498
[epoch9, step1538]: loss 4.295375
[epoch9, step1539]: loss 3.083766
[epoch9, step1540]: loss 11.219171
[epoch9, step1541]: loss 2.224721
[epoch9, step1542]: loss 1.947624
[epoch9, step1543]: loss 0.891711
[epoch9, step1544]: loss 1.634587
[epoch9, step1545]: loss 26.016903
[epoch9, step1546]: loss 1.272826
[epoch9, step1547]: loss 4.343451
[epoch9, step1548]: loss 1.703803
[epoch9, step1549]: loss 5.577079
[epoch9, step1550]: loss 1.684015
[epoch9, step1551]: loss 1.615607
[epoch9, step1552]: loss 17.207888
[epoch9, step1553]: loss 4.845926
[epoch9, step1554]: loss 2.698729
[epoch9, step1555]: loss 16.470709
[epoch9, step1556]: loss 4.404316
[epoch9, step1557]: loss 14.754950
[epoch9, step1558]: loss 3.076867
[epoch9, step1559]: loss 1.809094
[epoch9, step1560]: loss 1.772954
[epoch9, step1561]: loss 4.319211
[epoch9, step1562]: loss 1.153553
[epoch9, step1563]: loss 7.998529
[epoch9, step1564]: loss 6.170524
[epoch9, step1565]: loss 0.686525
[epoch9, step1566]: loss 15.309516
[epoch9, step1567]: loss 2.517862
[epoch9, step1568]: loss 1.518142
[epoch9, step1569]: loss 2.638448
[epoch9, step1570]: loss 3.405772
[epoch9, step1571]: loss 7.870179
[epoch9, step1572]: loss 6.928282
[epoch9, step1573]: loss 3.100961
[epoch9, step1574]: loss 2.978756
[epoch9, step1575]: loss 2.058240
[epoch9, step1576]: loss 40.565395
[epoch9, step1577]: loss 10.492637
[epoch9, step1578]: loss 1.599219
[epoch9, step1579]: loss 3.620595
[epoch9, step1580]: loss 5.259167
[epoch9, step1581]: loss 1.601959
[epoch9, step1582]: loss 2.686154
[epoch9, step1583]: loss 2.568851
[epoch9, step1584]: loss 8.288347
[epoch9, step1585]: loss 7.138386
[epoch9, step1586]: loss 1.883245
[epoch9, step1587]: loss 32.788776
[epoch9, step1588]: loss 1.845258
[epoch9, step1589]: loss 2.864348
[epoch9, step1590]: loss 14.751898
[epoch9, step1591]: loss 2.436510
[epoch9, step1592]: loss 16.982601
[epoch9, step1593]: loss 15.980142
[epoch9, step1594]: loss 1.684115
[epoch9, step1595]: loss 19.754972
[epoch9, step1596]: loss 12.133121
[epoch9, step1597]: loss 4.762674
[epoch9, step1598]: loss 1.625875
[epoch9, step1599]: loss 1.425557
[epoch9, step1600]: loss 1.172903
[epoch9, step1601]: loss 11.222814
[epoch9, step1602]: loss 3.898538
[epoch9, step1603]: loss 3.108408
[epoch9, step1604]: loss 13.339967
[epoch9, step1605]: loss 11.807455
[epoch9, step1606]: loss 1.597794
[epoch9, step1607]: loss 1.925249
[epoch9, step1608]: loss 17.586863
[epoch9, step1609]: loss 4.008878
[epoch9, step1610]: loss 5.480995
[epoch9, step1611]: loss 3.366227
[epoch9, step1612]: loss 1.863750
[epoch9, step1613]: loss 7.734742
[epoch9, step1614]: loss 5.754264
[epoch9, step1615]: loss 2.495417
[epoch9, step1616]: loss 1.119091
[epoch9, step1617]: loss 1.356783
[epoch9, step1618]: loss 12.979886
[epoch9, step1619]: loss 5.859432
[epoch9, step1620]: loss 5.830704
[epoch9, step1621]: loss 8.064392
[epoch9, step1622]: loss 5.015387
[epoch9, step1623]: loss 21.239206
[epoch9, step1624]: loss 17.753170
[epoch9, step1625]: loss 4.035743
[epoch9, step1626]: loss 5.065403
[epoch9, step1627]: loss 18.283140
[epoch9, step1628]: loss 4.952327
[epoch9, step1629]: loss 1.893038
[epoch9, step1630]: loss 15.892819
[epoch9, step1631]: loss 2.079717
[epoch9, step1632]: loss 1.061835
[epoch9, step1633]: loss 5.845042
[epoch9, step1634]: loss 17.216059
[epoch9, step1635]: loss 1.325095
[epoch9, step1636]: loss 17.860161
[epoch9, step1637]: loss 2.811986
[epoch9, step1638]: loss 1.800685
[epoch9, step1639]: loss 3.849252
[epoch9, step1640]: loss 3.081549
[epoch9, step1641]: loss 4.894906
[epoch9, step1642]: loss 1.941308
[epoch9, step1643]: loss 1.730720
[epoch9, step1644]: loss 3.680254
[epoch9, step1645]: loss 2.608396
[epoch9, step1646]: loss 16.709787
[epoch9, step1647]: loss 3.370229
[epoch9, step1648]: loss 0.902642
[epoch9, step1649]: loss 6.222267
[epoch9, step1650]: loss 1.772266
[epoch9, step1651]: loss 2.031921
[epoch9, step1652]: loss 15.735984
[epoch9, step1653]: loss 22.945171
[epoch9, step1654]: loss 2.103652
[epoch9, step1655]: loss 1.551298
[epoch9, step1656]: loss 12.625080
[epoch9, step1657]: loss 6.796789
[epoch9, step1658]: loss 1.662555
[epoch9, step1659]: loss 2.061591
[epoch9, step1660]: loss 1.525730
[epoch9, step1661]: loss 2.225246
[epoch9, step1662]: loss 3.118223
[epoch9, step1663]: loss 17.912308
[epoch9, step1664]: loss 1.904010
[epoch9, step1665]: loss 7.737310
[epoch9, step1666]: loss 2.133788
[epoch9, step1667]: loss 5.985448
[epoch9, step1668]: loss 18.323483
[epoch9, step1669]: loss 2.195982
[epoch9, step1670]: loss 4.120481
[epoch9, step1671]: loss 2.723079
[epoch9, step1672]: loss 16.638004
[epoch9, step1673]: loss 1.738237
[epoch9, step1674]: loss 12.958008
[epoch9, step1675]: loss 19.615164
[epoch9, step1676]: loss 1.097802
[epoch9, step1677]: loss 1.346780
[epoch9, step1678]: loss 4.624975
[epoch9, step1679]: loss 20.741497
[epoch9, step1680]: loss 1.678051
[epoch9, step1681]: loss 4.364995
[epoch9, step1682]: loss 1.713243
[epoch9, step1683]: loss 12.453939
[epoch9, step1684]: loss 1.314235
[epoch9, step1685]: loss 3.723582
[epoch9, step1686]: loss 2.224592
[epoch9, step1687]: loss 1.565072
[epoch9, step1688]: loss 15.050653
[epoch9, step1689]: loss 2.034258
[epoch9, step1690]: loss 1.461023
[epoch9, step1691]: loss 6.037738
[epoch9, step1692]: loss 1.763206
[epoch9, step1693]: loss 3.028906
[epoch9, step1694]: loss 0.926075
[epoch9, step1695]: loss 2.054598
[epoch9, step1696]: loss 2.327726
[epoch9, step1697]: loss 1.515761
[epoch9, step1698]: loss 12.828105
[epoch9, step1699]: loss 2.331585
[epoch9, step1700]: loss 2.512660
[epoch9, step1701]: loss 15.777346
[epoch9, step1702]: loss 3.169895
[epoch9, step1703]: loss 31.345203
[epoch9, step1704]: loss 4.012012
[epoch9, step1705]: loss 3.522696
[epoch9, step1706]: loss 1.786670
[epoch9, step1707]: loss 12.753065
[epoch9, step1708]: loss 1.173428
[epoch9, step1709]: loss 1.810503
[epoch9, step1710]: loss 4.084875
[epoch9, step1711]: loss 5.438027
[epoch9, step1712]: loss 2.872117
[epoch9, step1713]: loss 5.084006
[epoch9, step1714]: loss 16.432552
[epoch9, step1715]: loss 1.765462
[epoch9, step1716]: loss 1.330128
[epoch9, step1717]: loss 48.186020
[epoch9, step1718]: loss 1.820916
[epoch9, step1719]: loss 2.978679
[epoch9, step1720]: loss 7.196099
[epoch9, step1721]: loss 5.112759
[epoch9, step1722]: loss 3.308688
[epoch9, step1723]: loss 6.856063
[epoch9, step1724]: loss 1.612275
[epoch9, step1725]: loss 1.966152
[epoch9, step1726]: loss 26.222721
[epoch9, step1727]: loss 3.133520
[epoch9, step1728]: loss 2.170828
[epoch9, step1729]: loss 13.306373
[epoch9, step1730]: loss 4.113098
[epoch9, step1731]: loss 13.037137
[epoch9, step1732]: loss 2.170417
[epoch9, step1733]: loss 10.697858
[epoch9, step1734]: loss 12.843086
[epoch9, step1735]: loss 14.384537
[epoch9, step1736]: loss 0.587812
[epoch9, step1737]: loss 1.136447
[epoch9, step1738]: loss 18.289932
[epoch9, step1739]: loss 5.650159
[epoch9, step1740]: loss 2.541281
[epoch9, step1741]: loss 5.896732
[epoch9, step1742]: loss 3.092706
[epoch9, step1743]: loss 3.326257
[epoch9, step1744]: loss 2.167042
[epoch9, step1745]: loss 1.743846
[epoch9, step1746]: loss 3.141405
[epoch9, step1747]: loss 3.410799
[epoch9, step1748]: loss 4.672935
[epoch9, step1749]: loss 7.003372
[epoch9, step1750]: loss 15.529624
[epoch9, step1751]: loss 2.541239
[epoch9, step1752]: loss 1.196815
[epoch9, step1753]: loss 25.630840
[epoch9, step1754]: loss 21.608923
[epoch9, step1755]: loss 1.639235
[epoch9, step1756]: loss 1.489919
[epoch9, step1757]: loss 17.484861
[epoch9, step1758]: loss 1.353221
[epoch9, step1759]: loss 3.780921
[epoch9, step1760]: loss 4.092512
[epoch9, step1761]: loss 4.530903
[epoch9, step1762]: loss 4.091599
[epoch9, step1763]: loss 1.623688
[epoch9, step1764]: loss 5.354313
[epoch9, step1765]: loss 16.958477
[epoch9, step1766]: loss 2.906740
[epoch9, step1767]: loss 2.270351
[epoch9, step1768]: loss 2.691693
[epoch9, step1769]: loss 4.904313
[epoch9, step1770]: loss 12.002834
[epoch9, step1771]: loss 2.482738
[epoch9, step1772]: loss 1.342891
[epoch9, step1773]: loss 1.197441
[epoch9, step1774]: loss 21.168711
[epoch9, step1775]: loss 1.397593
[epoch9, step1776]: loss 1.894578
[epoch9, step1777]: loss 0.968762
[epoch9, step1778]: loss 1.917931
[epoch9, step1779]: loss 15.643468
[epoch9, step1780]: loss 7.029048
[epoch9, step1781]: loss 10.673243
[epoch9, step1782]: loss 2.679977
[epoch9, step1783]: loss 0.785939
[epoch9, step1784]: loss 1.820432
[epoch9, step1785]: loss 2.219208
[epoch9, step1786]: loss 7.707383
[epoch9, step1787]: loss 1.144151
[epoch9, step1788]: loss 3.044171
[epoch9, step1789]: loss 11.948269
[epoch9, step1790]: loss 16.288073
[epoch9, step1791]: loss 2.803284
[epoch9, step1792]: loss 2.224188
[epoch9, step1793]: loss 1.235664
[epoch9, step1794]: loss 15.404349
[epoch9, step1795]: loss 1.952889
[epoch9, step1796]: loss 2.739007
[epoch9, step1797]: loss 18.680487
[epoch9, step1798]: loss 1.901164
[epoch9, step1799]: loss 2.112468
[epoch9, step1800]: loss 3.892620
[epoch9, step1801]: loss 1.735393
[epoch9, step1802]: loss 4.250271
[epoch9, step1803]: loss 2.758882
[epoch9, step1804]: loss 11.768872
[epoch9, step1805]: loss 1.412319
[epoch9, step1806]: loss 1.063258
[epoch9, step1807]: loss 1.609110
[epoch9, step1808]: loss 6.422954
[epoch9, step1809]: loss 9.735453
[epoch9, step1810]: loss 4.428893
[epoch9, step1811]: loss 3.175827
[epoch9, step1812]: loss 2.102089
[epoch9, step1813]: loss 1.102707
[epoch9, step1814]: loss 1.824014
[epoch9, step1815]: loss 18.592060
[epoch9, step1816]: loss 3.420118
[epoch9, step1817]: loss 1.920112
[epoch9, step1818]: loss 3.539685
[epoch9, step1819]: loss 2.264919
[epoch9, step1820]: loss 2.760095
[epoch9, step1821]: loss 17.639791
[epoch9, step1822]: loss 5.869804
[epoch9, step1823]: loss 4.064126
[epoch9, step1824]: loss 10.185951
[epoch9, step1825]: loss 1.768130
[epoch9, step1826]: loss 4.212806
[epoch9, step1827]: loss 21.175255
[epoch9, step1828]: loss 1.876490
[epoch9, step1829]: loss 1.463326
[epoch9, step1830]: loss 0.868633
[epoch9, step1831]: loss 4.155504
[epoch9, step1832]: loss 3.261824
[epoch9, step1833]: loss 8.028625
[epoch9, step1834]: loss 4.383571
[epoch9, step1835]: loss 17.189499
[epoch9, step1836]: loss 1.330394
[epoch9, step1837]: loss 5.076746
[epoch9, step1838]: loss 21.727419
[epoch9, step1839]: loss 11.620519
[epoch9, step1840]: loss 1.845367
[epoch9, step1841]: loss 4.762666
[epoch9, step1842]: loss 0.793195
[epoch9, step1843]: loss 1.808560
[epoch9, step1844]: loss 14.623715
[epoch9, step1845]: loss 6.610088
[epoch9, step1846]: loss 5.029298
[epoch9, step1847]: loss 2.498454
[epoch9, step1848]: loss 1.408384
[epoch9, step1849]: loss 18.710543
[epoch9, step1850]: loss 1.493765
[epoch9, step1851]: loss 12.655876
[epoch9, step1852]: loss 1.331372
[epoch9, step1853]: loss 0.841541
[epoch9, step1854]: loss 1.746489
[epoch9, step1855]: loss 4.781330
[epoch9, step1856]: loss 4.966326
[epoch9, step1857]: loss 2.611884
[epoch9, step1858]: loss 5.925531
[epoch9, step1859]: loss 2.285926
[epoch9, step1860]: loss 1.831796
[epoch9, step1861]: loss 3.266390
[epoch9, step1862]: loss 1.079500
[epoch9, step1863]: loss 3.485797
[epoch9, step1864]: loss 2.770151
[epoch9, step1865]: loss 5.802430
[epoch9, step1866]: loss 2.735697
[epoch9, step1867]: loss 4.841230
[epoch9, step1868]: loss 7.208766
[epoch9, step1869]: loss 13.895994
[epoch9, step1870]: loss 0.929061
[epoch9, step1871]: loss 40.768684
[epoch9, step1872]: loss 34.815395
[epoch9, step1873]: loss 15.814547
[epoch9, step1874]: loss 4.642284
[epoch9, step1875]: loss 14.549909
[epoch9, step1876]: loss 6.368188
[epoch9, step1877]: loss 3.698948
[epoch9, step1878]: loss 1.088518
[epoch9, step1879]: loss 7.135665
[epoch9, step1880]: loss 6.988788
[epoch9, step1881]: loss 4.588691
[epoch9, step1882]: loss 4.131660
[epoch9, step1883]: loss 3.826929
[epoch9, step1884]: loss 2.742859
[epoch9, step1885]: loss 0.831302
[epoch9, step1886]: loss 20.321457
[epoch9, step1887]: loss 0.856235
[epoch9, step1888]: loss 5.147210
[epoch9, step1889]: loss 1.296977
[epoch9, step1890]: loss 2.522677
[epoch9, step1891]: loss 1.218653
[epoch9, step1892]: loss 8.221963
[epoch9, step1893]: loss 16.435863
[epoch9, step1894]: loss 10.520384
[epoch9, step1895]: loss 19.310558
[epoch9, step1896]: loss 3.151222
[epoch9, step1897]: loss 12.276489
[epoch9, step1898]: loss 6.880071
[epoch9, step1899]: loss 4.092841
[epoch9, step1900]: loss 3.735955
[epoch9, step1901]: loss 3.235092
[epoch9, step1902]: loss 6.740907
[epoch9, step1903]: loss 13.011757
[epoch9, step1904]: loss 2.914379
[epoch9, step1905]: loss 2.666145
[epoch9, step1906]: loss 1.918559
[epoch9, step1907]: loss 2.675364
[epoch9, step1908]: loss 4.190836
[epoch9, step1909]: loss 20.760721
[epoch9, step1910]: loss 2.132570
[epoch9, step1911]: loss 3.663992
[epoch9, step1912]: loss 1.794910
[epoch9, step1913]: loss 1.767783
[epoch9, step1914]: loss 24.038330
[epoch9, step1915]: loss 1.063171
[epoch9, step1916]: loss 3.481546
[epoch9, step1917]: loss 13.160128
[epoch9, step1918]: loss 2.973873
[epoch9, step1919]: loss 2.189682
[epoch9, step1920]: loss 1.010765
[epoch9, step1921]: loss 13.061329
[epoch9, step1922]: loss 11.258956
[epoch9, step1923]: loss 16.170433
[epoch9, step1924]: loss 12.926413
[epoch9, step1925]: loss 2.739001
[epoch9, step1926]: loss 0.801527
[epoch9, step1927]: loss 2.053490
[epoch9, step1928]: loss 8.466084
[epoch9, step1929]: loss 1.027314
[epoch9, step1930]: loss 13.843567
[epoch9, step1931]: loss 6.521596
[epoch9, step1932]: loss 2.398199
[epoch9, step1933]: loss 2.536649
[epoch9, step1934]: loss 1.447866
[epoch9, step1935]: loss 2.355690
[epoch9, step1936]: loss 7.588078
[epoch9, step1937]: loss 3.894825
[epoch9, step1938]: loss 1.552148
[epoch9, step1939]: loss 2.856134
[epoch9, step1940]: loss 4.372370
[epoch9, step1941]: loss 4.952775
[epoch9, step1942]: loss 1.752237
[epoch9, step1943]: loss 20.568926
[epoch9, step1944]: loss 2.061079
[epoch9, step1945]: loss 2.759443
[epoch9, step1946]: loss 25.010826
[epoch9, step1947]: loss 2.514479
[epoch9, step1948]: loss 3.013917
[epoch9, step1949]: loss 29.094276
[epoch9, step1950]: loss 1.328348
[epoch9, step1951]: loss 6.486981
[epoch9, step1952]: loss 0.990459
[epoch9, step1953]: loss 3.091127
[epoch9, step1954]: loss 2.678736
[epoch9, step1955]: loss 3.720060
[epoch9, step1956]: loss 4.744296
[epoch9, step1957]: loss 3.816828
[epoch9, step1958]: loss 1.259267
[epoch9, step1959]: loss 14.915222
[epoch9, step1960]: loss 2.241787
[epoch9, step1961]: loss 2.170238
[epoch9, step1962]: loss 18.177216
[epoch9, step1963]: loss 1.079729
[epoch9, step1964]: loss 1.450159
[epoch9, step1965]: loss 16.543407
[epoch9, step1966]: loss 4.185824
[epoch9, step1967]: loss 1.984326
[epoch9, step1968]: loss 31.436249
[epoch9, step1969]: loss 4.229352
[epoch9, step1970]: loss 46.007195
[epoch9, step1971]: loss 14.083722
[epoch9, step1972]: loss 1.681783
[epoch9, step1973]: loss 1.563099
[epoch9, step1974]: loss 4.402575
[epoch9, step1975]: loss 3.022558
[epoch9, step1976]: loss 10.877192
[epoch9, step1977]: loss 10.523504
[epoch9, step1978]: loss 2.358306
[epoch9, step1979]: loss 1.595932
[epoch9, step1980]: loss 4.320751
[epoch9, step1981]: loss 1.132678
[epoch9, step1982]: loss 1.565371
[epoch9, step1983]: loss 2.350338
[epoch9, step1984]: loss 1.491315
[epoch9, step1985]: loss 2.782425
[epoch9, step1986]: loss 5.802977
[epoch9, step1987]: loss 1.390326
[epoch9, step1988]: loss 1.659084
[epoch9, step1989]: loss 20.138624
[epoch9, step1990]: loss 10.247690
[epoch9, step1991]: loss 3.026950
[epoch9, step1992]: loss 2.250423
[epoch9, step1993]: loss 33.576111
[epoch9, step1994]: loss 5.089273
[epoch9, step1995]: loss 2.825898
[epoch9, step1996]: loss 1.819763
[epoch9, step1997]: loss 1.149909
[epoch9, step1998]: loss 1.931690
[epoch9, step1999]: loss 6.893236
[epoch9, step2000]: loss 11.225301
[epoch9, step2001]: loss 4.427554
[epoch9, step2002]: loss 3.117829
[epoch9, step2003]: loss 1.274721
[epoch9, step2004]: loss 7.666465
[epoch9, step2005]: loss 11.047319
[epoch9, step2006]: loss 2.960912
[epoch9, step2007]: loss 3.593145
[epoch9, step2008]: loss 4.004789
[epoch9, step2009]: loss 12.906036
[epoch9, step2010]: loss 13.958753
[epoch9, step2011]: loss 6.097858
[epoch9, step2012]: loss 1.169314
[epoch9, step2013]: loss 6.871272
[epoch9, step2014]: loss 3.615659
[epoch9, step2015]: loss 9.690861
[epoch9, step2016]: loss 5.269122
[epoch9, step2017]: loss 28.292063
[epoch9, step2018]: loss 1.402186
[epoch9, step2019]: loss 1.790845
[epoch9, step2020]: loss 1.585463
[epoch9, step2021]: loss 9.042819
[epoch9, step2022]: loss 4.895205
[epoch9, step2023]: loss 6.557404
[epoch9, step2024]: loss 23.708080
[epoch9, step2025]: loss 16.667057
[epoch9, step2026]: loss 3.171830
[epoch9, step2027]: loss 21.420835
[epoch9, step2028]: loss 15.194570
[epoch9, step2029]: loss 19.271353
[epoch9, step2030]: loss 1.651308
[epoch9, step2031]: loss 3.731317
[epoch9, step2032]: loss 1.188811
[epoch9, step2033]: loss 2.749539
[epoch9, step2034]: loss 2.021482
[epoch9, step2035]: loss 1.717717
[epoch9, step2036]: loss 1.719748
[epoch9, step2037]: loss 2.028665
[epoch9, step2038]: loss 11.924938
[epoch9, step2039]: loss 16.043108
[epoch9, step2040]: loss 21.115551
[epoch9, step2041]: loss 7.743882
[epoch9, step2042]: loss 1.190282
[epoch9, step2043]: loss 7.950112
[epoch9, step2044]: loss 16.280214
[epoch9, step2045]: loss 14.311804
[epoch9, step2046]: loss 15.384886
[epoch9, step2047]: loss 3.554799
[epoch9, step2048]: loss 1.706640
[epoch9, step2049]: loss 1.946446
[epoch9, step2050]: loss 16.806652
[epoch9, step2051]: loss 5.574161
[epoch9, step2052]: loss 2.139493
[epoch9, step2053]: loss 3.820484
[epoch9, step2054]: loss 1.895172
[epoch9, step2055]: loss 1.141135
[epoch9, step2056]: loss 3.081635
[epoch9, step2057]: loss 1.844855
[epoch9, step2058]: loss 15.602502
[epoch9, step2059]: loss 1.301494
[epoch9, step2060]: loss 22.607843
[epoch9, step2061]: loss 2.086179
[epoch9, step2062]: loss 6.563713
[epoch9, step2063]: loss 1.723477
[epoch9, step2064]: loss 3.281760
[epoch9, step2065]: loss 1.441763
[epoch9, step2066]: loss 0.796852
[epoch9, step2067]: loss 1.660759
[epoch9, step2068]: loss 17.111647
[epoch9, step2069]: loss 2.880784
[epoch9, step2070]: loss 3.475508
[epoch9, step2071]: loss 3.291010
[epoch9, step2072]: loss 1.076527
[epoch9, step2073]: loss 1.516176
[epoch9, step2074]: loss 2.602695
[epoch9, step2075]: loss 1.239289
[epoch9, step2076]: loss 9.187428
[epoch9, step2077]: loss 15.194949
[epoch9, step2078]: loss 1.665164
[epoch9, step2079]: loss 3.145423
[epoch9, step2080]: loss 4.013240
[epoch9, step2081]: loss 1.581131
[epoch9, step2082]: loss 2.152930
[epoch9, step2083]: loss 7.810677
[epoch9, step2084]: loss 1.055595
[epoch9, step2085]: loss 3.508195
[epoch9, step2086]: loss 10.424416
[epoch9, step2087]: loss 3.633093
[epoch9, step2088]: loss 1.795940
[epoch9, step2089]: loss 2.289092
[epoch9, step2090]: loss 2.767414
[epoch9, step2091]: loss 2.517274
[epoch9, step2092]: loss 10.362063
[epoch9, step2093]: loss 2.208871
[epoch9, step2094]: loss 1.523910
[epoch9, step2095]: loss 0.897932
[epoch9, step2096]: loss 4.343472
[epoch9, step2097]: loss 1.484926
[epoch9, step2098]: loss 11.839851
[epoch9, step2099]: loss 1.325973
[epoch9, step2100]: loss 2.737701
[epoch9, step2101]: loss 1.201949
[epoch9, step2102]: loss 6.573774
[epoch9, step2103]: loss 1.489119
[epoch9, step2104]: loss 5.332133
[epoch9, step2105]: loss 1.742396
[epoch9, step2106]: loss 10.806393
[epoch9, step2107]: loss 1.548681
[epoch9, step2108]: loss 1.749666
[epoch9, step2109]: loss 2.193076
[epoch9, step2110]: loss 1.919612
[epoch9, step2111]: loss 3.716188
[epoch9, step2112]: loss 2.574501
[epoch9, step2113]: loss 5.432188
[epoch9, step2114]: loss 2.032266
[epoch9, step2115]: loss 5.335706
[epoch9, step2116]: loss 1.377108
[epoch9, step2117]: loss 1.172370
[epoch9, step2118]: loss 3.022358
[epoch9, step2119]: loss 2.153296
[epoch9, step2120]: loss 4.786521
[epoch9, step2121]: loss 2.865786
[epoch9, step2122]: loss 20.387806
[epoch9, step2123]: loss 12.718592
[epoch9, step2124]: loss 1.152370
[epoch9, step2125]: loss 2.635349
[epoch9, step2126]: loss 1.373681
[epoch9, step2127]: loss 1.644521
[epoch9, step2128]: loss 2.472798
[epoch9, step2129]: loss 8.271217
[epoch9, step2130]: loss 3.304473
[epoch9, step2131]: loss 1.688087
[epoch9, step2132]: loss 3.903748
[epoch9, step2133]: loss 3.393061
[epoch9, step2134]: loss 7.255925
[epoch9, step2135]: loss 2.919926
[epoch9, step2136]: loss 16.372431
[epoch9, step2137]: loss 2.347488
[epoch9, step2138]: loss 16.842787
[epoch9, step2139]: loss 14.017532
[epoch9, step2140]: loss 3.325699
[epoch9, step2141]: loss 1.938302
[epoch9, step2142]: loss 14.064638
[epoch9, step2143]: loss 14.572759
[epoch9, step2144]: loss 1.399222
[epoch9, step2145]: loss 1.666671
[epoch9, step2146]: loss 1.382901
[epoch9, step2147]: loss 6.427527
[epoch9, step2148]: loss 2.156202
[epoch9, step2149]: loss 4.711294
[epoch9, step2150]: loss 1.986833
[epoch9, step2151]: loss 12.585635
[epoch9, step2152]: loss 1.951216
[epoch9, step2153]: loss 1.493932
[epoch9, step2154]: loss 14.628698
[epoch9, step2155]: loss 2.674273
[epoch9, step2156]: loss 16.370523
[epoch9, step2157]: loss 2.335441
[epoch9, step2158]: loss 2.604762
[epoch9, step2159]: loss 3.847217
[epoch9, step2160]: loss 2.803224
[epoch9, step2161]: loss 2.287813
[epoch9, step2162]: loss 1.893504
[epoch9, step2163]: loss 1.598755
[epoch9, step2164]: loss 1.115050
[epoch9, step2165]: loss 14.465755
[epoch9, step2166]: loss 1.303105
[epoch9, step2167]: loss 1.515307
[epoch9, step2168]: loss 2.740593
[epoch9, step2169]: loss 15.412210
[epoch9, step2170]: loss 6.158693
[epoch9, step2171]: loss 15.441809
[epoch9, step2172]: loss 16.590162
[epoch9, step2173]: loss 2.036303
[epoch9, step2174]: loss 23.830067
[epoch9, step2175]: loss 15.465034
[epoch9, step2176]: loss 3.884648
[epoch9, step2177]: loss 21.739386
[epoch9, step2178]: loss 6.904566
[epoch9, step2179]: loss 5.340067
[epoch9, step2180]: loss 4.477490
[epoch9, step2181]: loss 5.661624
[epoch9, step2182]: loss 1.336526
[epoch9, step2183]: loss 2.304009
[epoch9, step2184]: loss 1.593748
[epoch9, step2185]: loss 3.000126
[epoch9, step2186]: loss 17.676302
[epoch9, step2187]: loss 16.799110
[epoch9, step2188]: loss 22.850189
[epoch9, step2189]: loss 18.496536
[epoch9, step2190]: loss 2.031513
[epoch9, step2191]: loss 2.616104
[epoch9, step2192]: loss 2.341263
[epoch9, step2193]: loss 2.086858
[epoch9, step2194]: loss 16.357550
[epoch9, step2195]: loss 2.264535
[epoch9, step2196]: loss 21.727608
[epoch9, step2197]: loss 28.206961
[epoch9, step2198]: loss 15.707640
[epoch9, step2199]: loss 2.115964
[epoch9, step2200]: loss 1.855681
[epoch9, step2201]: loss 9.073302
[epoch9, step2202]: loss 2.008610
[epoch9, step2203]: loss 9.758859
[epoch9, step2204]: loss 1.132566
[epoch9, step2205]: loss 7.015482
[epoch9, step2206]: loss 5.840507
[epoch9, step2207]: loss 1.770104
[epoch9, step2208]: loss 4.073531
[epoch9, step2209]: loss 1.659782
[epoch9, step2210]: loss 12.308508
[epoch9, step2211]: loss 4.221735
[epoch9, step2212]: loss 1.687317
[epoch9, step2213]: loss 6.839076
[epoch9, step2214]: loss 1.277758
[epoch9, step2215]: loss 19.084764
[epoch9, step2216]: loss 1.971972
[epoch9, step2217]: loss 3.472147
[epoch9, step2218]: loss 9.125350
[epoch9, step2219]: loss 3.458658
[epoch9, step2220]: loss 6.430603
[epoch9, step2221]: loss 13.821320
[epoch9, step2222]: loss 1.017814
[epoch9, step2223]: loss 4.722394
[epoch9, step2224]: loss 1.206009
[epoch9, step2225]: loss 16.356270
[epoch9, step2226]: loss 2.737238
[epoch9, step2227]: loss 1.147971
[epoch9, step2228]: loss 4.281738
[epoch9, step2229]: loss 1.960099
[epoch9, step2230]: loss 3.815083
[epoch9, step2231]: loss 2.798573
[epoch9, step2232]: loss 2.043676
[epoch9, step2233]: loss 4.106473
[epoch9, step2234]: loss 2.501244
[epoch9, step2235]: loss 1.288101
[epoch9, step2236]: loss 2.521939
[epoch9, step2237]: loss 1.444540
[epoch9, step2238]: loss 2.517200
[epoch9, step2239]: loss 3.317933
[epoch9, step2240]: loss 1.061604
[epoch9, step2241]: loss 16.245033
[epoch9, step2242]: loss 1.945629
[epoch9, step2243]: loss 9.138820
[epoch9, step2244]: loss 1.504220
[epoch9, step2245]: loss 1.583111
[epoch9, step2246]: loss 22.921225
[epoch9, step2247]: loss 1.895045
[epoch9, step2248]: loss 2.569776
[epoch9, step2249]: loss 4.234744
[epoch9, step2250]: loss 6.039122
[epoch9, step2251]: loss 1.262251
[epoch9, step2252]: loss 23.867502
[epoch9, step2253]: loss 2.683399
[epoch9, step2254]: loss 2.417207
[epoch9, step2255]: loss 13.696731
[epoch9, step2256]: loss 1.770929
[epoch9, step2257]: loss 2.181767
[epoch9, step2258]: loss 22.839451
[epoch9, step2259]: loss 3.071572
[epoch9, step2260]: loss 4.845293
[epoch9, step2261]: loss 2.534507
[epoch9, step2262]: loss 3.457097
[epoch9, step2263]: loss 6.995646
[epoch9, step2264]: loss 4.114182
[epoch9, step2265]: loss 3.657071
[epoch9, step2266]: loss 2.428890
[epoch9, step2267]: loss 14.257032
[epoch9, step2268]: loss 12.140971
[epoch9, step2269]: loss 1.689329
[epoch9, step2270]: loss 6.691473
[epoch9, step2271]: loss 1.645263
[epoch9, step2272]: loss 1.953609
[epoch9, step2273]: loss 2.949769
[epoch9, step2274]: loss 9.192017
[epoch9, step2275]: loss 4.074634
[epoch9, step2276]: loss 5.997891
[epoch9, step2277]: loss 2.008476
[epoch9, step2278]: loss 0.844594
[epoch9, step2279]: loss 1.291492
[epoch9, step2280]: loss 3.904309
[epoch9, step2281]: loss 15.715492
[epoch9, step2282]: loss 3.907837
[epoch9, step2283]: loss 1.965071
[epoch9, step2284]: loss 2.503214
[epoch9, step2285]: loss 2.080971
[epoch9, step2286]: loss 1.899414
[epoch9, step2287]: loss 2.350624
[epoch9, step2288]: loss 2.085324
[epoch9, step2289]: loss 5.315588
[epoch9, step2290]: loss 2.004889
[epoch9, step2291]: loss 4.652086
[epoch9, step2292]: loss 21.077314
[epoch9, step2293]: loss 1.962381
[epoch9, step2294]: loss 10.964609
[epoch9, step2295]: loss 19.007227
[epoch9, step2296]: loss 1.033716
[epoch9, step2297]: loss 1.665800
[epoch9, step2298]: loss 12.607485
[epoch9, step2299]: loss 2.380543
[epoch9, step2300]: loss 1.087601
[epoch9, step2301]: loss 2.163424
[epoch9, step2302]: loss 7.733079
[epoch9, step2303]: loss 9.937393
[epoch9, step2304]: loss 1.636580
[epoch9, step2305]: loss 3.644972
[epoch9, step2306]: loss 2.128916
[epoch9, step2307]: loss 4.676497
[epoch9, step2308]: loss 1.511441
[epoch9, step2309]: loss 1.967792
[epoch9, step2310]: loss 3.318979
[epoch9, step2311]: loss 1.532124
[epoch9, step2312]: loss 21.110807
[epoch9, step2313]: loss 38.134220
[epoch9, step2314]: loss 16.632654
[epoch9, step2315]: loss 1.269202
[epoch9, step2316]: loss 1.100167
[epoch9, step2317]: loss 0.774613
[epoch9, step2318]: loss 2.764124
[epoch9, step2319]: loss 15.649237
[epoch9, step2320]: loss 18.578444
[epoch9, step2321]: loss 1.363504
[epoch9, step2322]: loss 18.004135
[epoch9, step2323]: loss 1.690603
[epoch9, step2324]: loss 8.209668
[epoch9, step2325]: loss 4.167772
[epoch9, step2326]: loss 12.748126
[epoch9, step2327]: loss 20.492027
[epoch9, step2328]: loss 11.944512
[epoch9, step2329]: loss 18.539721
[epoch9, step2330]: loss 3.244777
[epoch9, step2331]: loss 1.049318
[epoch9, step2332]: loss 1.911129
[epoch9, step2333]: loss 4.162033
[epoch9, step2334]: loss 19.379986
[epoch9, step2335]: loss 2.818752
[epoch9, step2336]: loss 0.980837
[epoch9, step2337]: loss 1.270094
[epoch9, step2338]: loss 8.773051
[epoch9, step2339]: loss 7.640585
[epoch9, step2340]: loss 11.875042
[epoch9, step2341]: loss 4.703811
[epoch9, step2342]: loss 2.852979
[epoch9, step2343]: loss 7.862935
[epoch9, step2344]: loss 3.452469
[epoch9, step2345]: loss 3.525143
[epoch9, step2346]: loss 0.924598
[epoch9, step2347]: loss 1.590185
[epoch9, step2348]: loss 13.899181
[epoch9, step2349]: loss 13.402627
[epoch9, step2350]: loss 3.027658
[epoch9, step2351]: loss 1.790281
[epoch9, step2352]: loss 5.829506
[epoch9, step2353]: loss 8.083172
[epoch9, step2354]: loss 15.446433
[epoch9, step2355]: loss 6.423927
[epoch9, step2356]: loss 26.739017
[epoch9, step2357]: loss 1.579940
[epoch9, step2358]: loss 1.290381
[epoch9, step2359]: loss 17.811491
[epoch9, step2360]: loss 2.979434
[epoch9, step2361]: loss 2.255204
[epoch9, step2362]: loss 14.619274
[epoch9, step2363]: loss 16.061028
[epoch9, step2364]: loss 0.828547
[epoch9, step2365]: loss 3.000134
[epoch9, step2366]: loss 13.464376
[epoch9, step2367]: loss 4.110551
[epoch9, step2368]: loss 1.093889
[epoch9, step2369]: loss 15.154469
[epoch9, step2370]: loss 14.326616
[epoch9, step2371]: loss 2.964637
[epoch9, step2372]: loss 10.699764
[epoch9, step2373]: loss 18.149261
[epoch9, step2374]: loss 4.374637
[epoch9, step2375]: loss 4.334665
[epoch9, step2376]: loss 1.489246
[epoch9, step2377]: loss 1.713799
[epoch9, step2378]: loss 6.170873
[epoch9, step2379]: loss 4.355305
[epoch9, step2380]: loss 9.408401
[epoch9, step2381]: loss 4.043069
[epoch9, step2382]: loss 2.064554
[epoch9, step2383]: loss 1.276593
[epoch9, step2384]: loss 33.815140
[epoch9, step2385]: loss 2.213773
[epoch9, step2386]: loss 2.892267
[epoch9, step2387]: loss 12.010164
[epoch9, step2388]: loss 1.782275
[epoch9, step2389]: loss 2.128639
[epoch9, step2390]: loss 1.239715
[epoch9, step2391]: loss 13.263271
[epoch9, step2392]: loss 0.940394
[epoch9, step2393]: loss 2.655847
[epoch9, step2394]: loss 10.204497
[epoch9, step2395]: loss 5.965355
[epoch9, step2396]: loss 1.361132
[epoch9, step2397]: loss 6.527714
[epoch9, step2398]: loss 2.126027
[epoch9, step2399]: loss 2.286690
[epoch9, step2400]: loss 2.365618
[epoch9, step2401]: loss 2.627319
[epoch9, step2402]: loss 1.122257
[epoch9, step2403]: loss 3.096566
[epoch9, step2404]: loss 2.311909
[epoch9, step2405]: loss 1.901911
[epoch9, step2406]: loss 2.835295
[epoch9, step2407]: loss 6.633414
[epoch9, step2408]: loss 1.450143
[epoch9, step2409]: loss 21.983881
[epoch9, step2410]: loss 2.520852
[epoch9, step2411]: loss 2.398964
[epoch9, step2412]: loss 2.685897
[epoch9, step2413]: loss 4.970595
[epoch9, step2414]: loss 6.281897
[epoch9, step2415]: loss 3.093647
[epoch9, step2416]: loss 15.060594
[epoch9, step2417]: loss 1.012366
[epoch9, step2418]: loss 2.383112
[epoch9, step2419]: loss 2.978057
[epoch9, step2420]: loss 9.815714
[epoch9, step2421]: loss 1.280150
[epoch9, step2422]: loss 21.185217
[epoch9, step2423]: loss 1.898713
[epoch9, step2424]: loss 2.059130
[epoch9, step2425]: loss 4.228222
[epoch9, step2426]: loss 1.900197
[epoch9, step2427]: loss 6.834113
[epoch9, step2428]: loss 1.814620
[epoch9, step2429]: loss 3.545130
[epoch9, step2430]: loss 2.434485
[epoch9, step2431]: loss 4.286695
[epoch9, step2432]: loss 2.709701
[epoch9, step2433]: loss 11.879192
[epoch9, step2434]: loss 9.123191
[epoch9, step2435]: loss 1.862259
[epoch9, step2436]: loss 3.152558
[epoch9, step2437]: loss 7.098916
[epoch9, step2438]: loss 5.504245
[epoch9, step2439]: loss 5.441761
[epoch9, step2440]: loss 4.427676
[epoch9, step2441]: loss 2.037274
[epoch9, step2442]: loss 3.615546
[epoch9, step2443]: loss 18.660688
[epoch9, step2444]: loss 4.132740
[epoch9, step2445]: loss 12.391372
[epoch9, step2446]: loss 1.661812
[epoch9, step2447]: loss 16.765604
[epoch9, step2448]: loss 2.238098
[epoch9, step2449]: loss 3.584815
[epoch9, step2450]: loss 1.386391
[epoch9, step2451]: loss 5.480478
[epoch9, step2452]: loss 1.164489
[epoch9, step2453]: loss 30.178215
[epoch9, step2454]: loss 1.815036
[epoch9, step2455]: loss 3.029286
[epoch9, step2456]: loss 1.249260
[epoch9, step2457]: loss 2.053090
[epoch9, step2458]: loss 4.449060
[epoch9, step2459]: loss 16.901598
[epoch9, step2460]: loss 1.035816
[epoch9, step2461]: loss 20.578369
[epoch9, step2462]: loss 2.113171
[epoch9, step2463]: loss 33.281685
[epoch9, step2464]: loss 1.526545
[epoch9, step2465]: loss 1.426071
[epoch9, step2466]: loss 11.473320
[epoch9, step2467]: loss 2.508063
[epoch9, step2468]: loss 9.177998
[epoch9, step2469]: loss 1.282314
[epoch9, step2470]: loss 6.917224
[epoch9, step2471]: loss 2.341520
[epoch9, step2472]: loss 3.615753
[epoch9, step2473]: loss 5.302104
[epoch9, step2474]: loss 1.931402
[epoch9, step2475]: loss 5.780104
[epoch9, step2476]: loss 1.760963
[epoch9, step2477]: loss 2.019926
[epoch9, step2478]: loss 3.726470
[epoch9, step2479]: loss 2.897560
[epoch9, step2480]: loss 6.819356
[epoch9, step2481]: loss 2.900248
[epoch9, step2482]: loss 12.883385
[epoch9, step2483]: loss 5.333198
[epoch9, step2484]: loss 0.892308
[epoch9, step2485]: loss 17.067196
[epoch9, step2486]: loss 4.073778
[epoch9, step2487]: loss 4.246200
[epoch9, step2488]: loss 2.945776
[epoch9, step2489]: loss 2.903222
[epoch9, step2490]: loss 7.928999
[epoch9, step2491]: loss 5.790493
[epoch9, step2492]: loss 13.716009
[epoch9, step2493]: loss 1.488209
[epoch9, step2494]: loss 1.337914
[epoch9, step2495]: loss 1.914765
[epoch9, step2496]: loss 1.817300
[epoch9, step2497]: loss 2.031541
[epoch9, step2498]: loss 1.831959
[epoch9, step2499]: loss 1.393754
[epoch9, step2500]: loss 0.587659
[epoch9, step2501]: loss 7.801813
[epoch9, step2502]: loss 19.528093
[epoch9, step2503]: loss 15.043610
[epoch9, step2504]: loss 17.035173
[epoch9, step2505]: loss 2.340750
[epoch9, step2506]: loss 2.886204
[epoch9, step2507]: loss 2.680270
[epoch9, step2508]: loss 13.638869
[epoch9, step2509]: loss 12.191055
[epoch9, step2510]: loss 9.855384
[epoch9, step2511]: loss 3.738188
[epoch9, step2512]: loss 3.418455
[epoch9, step2513]: loss 1.419970
[epoch9, step2514]: loss 2.512282
[epoch9, step2515]: loss 14.723545
[epoch9, step2516]: loss 1.552875
[epoch9, step2517]: loss 2.768889
[epoch9, step2518]: loss 3.103056
[epoch9, step2519]: loss 1.621310
[epoch9, step2520]: loss 1.412604
[epoch9, step2521]: loss 13.845902
[epoch9, step2522]: loss 14.228468
[epoch9, step2523]: loss 4.900348
[epoch9, step2524]: loss 2.939849
[epoch9, step2525]: loss 3.186428
[epoch9, step2526]: loss 3.215225
[epoch9, step2527]: loss 2.677969
[epoch9, step2528]: loss 1.170728
[epoch9, step2529]: loss 16.069120
[epoch9, step2530]: loss 2.029462
[epoch9, step2531]: loss 2.257992
[epoch9, step2532]: loss 1.281179
[epoch9, step2533]: loss 0.997938
[epoch9, step2534]: loss 2.529033
[epoch9, step2535]: loss 1.012732
[epoch9, step2536]: loss 1.146688
[epoch9, step2537]: loss 22.331079
[epoch9, step2538]: loss 4.154805
[epoch9, step2539]: loss 17.425276
[epoch9, step2540]: loss 1.337666
[epoch9, step2541]: loss 4.220537
[epoch9, step2542]: loss 6.283769
[epoch9, step2543]: loss 3.111674
[epoch9, step2544]: loss 9.399551
[epoch9, step2545]: loss 3.241663
[epoch9, step2546]: loss 1.673223
[epoch9, step2547]: loss 1.942150
[epoch9, step2548]: loss 12.726863
[epoch9, step2549]: loss 16.531128
[epoch9, step2550]: loss 1.850733
[epoch9, step2551]: loss 1.236214
[epoch9, step2552]: loss 37.069561
[epoch9, step2553]: loss 3.521061
[epoch9, step2554]: loss 4.215482
[epoch9, step2555]: loss 2.355925
[epoch9, step2556]: loss 1.548084
[epoch9, step2557]: loss 1.557223
[epoch9, step2558]: loss 16.131638
[epoch9, step2559]: loss 3.828083
[epoch9, step2560]: loss 1.727058
[epoch9, step2561]: loss 12.168278
[epoch9, step2562]: loss 4.961354
[epoch9, step2563]: loss 12.730095
[epoch9, step2564]: loss 20.927544
[epoch9, step2565]: loss 4.556079
[epoch9, step2566]: loss 1.571309
[epoch9, step2567]: loss 16.673389
[epoch9, step2568]: loss 1.496183
[epoch9, step2569]: loss 20.459240
[epoch9, step2570]: loss 2.593483
[epoch9, step2571]: loss 6.286792
[epoch9, step2572]: loss 1.500966
[epoch9, step2573]: loss 3.813541
[epoch9, step2574]: loss 0.985669
[epoch9, step2575]: loss 3.119400
[epoch9, step2576]: loss 13.981382
[epoch9, step2577]: loss 8.381591
[epoch9, step2578]: loss 13.534614
[epoch9, step2579]: loss 1.595344
[epoch9, step2580]: loss 1.807825
[epoch9, step2581]: loss 18.483669
[epoch9, step2582]: loss 17.625612
[epoch9, step2583]: loss 5.585403
[epoch9, step2584]: loss 1.710916
[epoch9, step2585]: loss 10.343379
[epoch9, step2586]: loss 13.586558
[epoch9, step2587]: loss 3.361666
[epoch9, step2588]: loss 3.944738
[epoch9, step2589]: loss 3.919756
[epoch9, step2590]: loss 1.695622
[epoch9, step2591]: loss 2.010104
[epoch9, step2592]: loss 4.836557
[epoch9, step2593]: loss 3.115827
[epoch9, step2594]: loss 1.356474
[epoch9, step2595]: loss 2.832720
[epoch9, step2596]: loss 8.483000
[epoch9, step2597]: loss 2.493376
[epoch9, step2598]: loss 1.236625
[epoch9, step2599]: loss 2.136124
[epoch9, step2600]: loss 1.478404
[epoch9, step2601]: loss 3.046393
[epoch9, step2602]: loss 1.339519
[epoch9, step2603]: loss 2.811507
[epoch9, step2604]: loss 1.932716
[epoch9, step2605]: loss 10.730106
[epoch9, step2606]: loss 2.556300
[epoch9, step2607]: loss 1.484274
[epoch9, step2608]: loss 6.370235
[epoch9, step2609]: loss 2.523616
[epoch9, step2610]: loss 28.292793
[epoch9, step2611]: loss 1.382546
[epoch9, step2612]: loss 2.180834
[epoch9, step2613]: loss 2.326643
[epoch9, step2614]: loss 2.639268
[epoch9, step2615]: loss 6.028276
[epoch9, step2616]: loss 1.245834
[epoch9, step2617]: loss 4.992590
[epoch9, step2618]: loss 2.372394
[epoch9, step2619]: loss 35.023769
[epoch9, step2620]: loss 17.418964
[epoch9, step2621]: loss 20.029396
[epoch9, step2622]: loss 2.666199
[epoch9, step2623]: loss 1.148826
[epoch9, step2624]: loss 1.261756
[epoch9, step2625]: loss 2.061451
[epoch9, step2626]: loss 34.416424
[epoch9, step2627]: loss 2.101617
[epoch9, step2628]: loss 1.839262
[epoch9, step2629]: loss 1.831629
[epoch9, step2630]: loss 2.714796
[epoch9, step2631]: loss 2.849968
[epoch9, step2632]: loss 2.242945
[epoch9, step2633]: loss 2.414525
[epoch9, step2634]: loss 4.382671
[epoch9, step2635]: loss 1.316263
[epoch9, step2636]: loss 1.171164
[epoch9, step2637]: loss 3.408292
[epoch9, step2638]: loss 1.327198
[epoch9, step2639]: loss 14.615325
[epoch9, step2640]: loss 1.604847
[epoch9, step2641]: loss 1.469281
[epoch9, step2642]: loss 6.286515
[epoch9, step2643]: loss 2.934168
[epoch9, step2644]: loss 2.187121
[epoch9, step2645]: loss 1.659997
[epoch9, step2646]: loss 2.699992
[epoch9, step2647]: loss 10.523591
[epoch9, step2648]: loss 9.307744
[epoch9, step2649]: loss 2.923852
[epoch9, step2650]: loss 5.167495
[epoch9, step2651]: loss 7.105232
[epoch9, step2652]: loss 24.296827
[epoch9, step2653]: loss 1.327347
[epoch9, step2654]: loss 7.988904
[epoch9, step2655]: loss 0.924745
[epoch9, step2656]: loss 2.465979
[epoch9, step2657]: loss 3.326904
[epoch9, step2658]: loss 7.340417
[epoch9, step2659]: loss 2.039279
[epoch9, step2660]: loss 2.293537
[epoch9, step2661]: loss 1.824806
[epoch9, step2662]: loss 16.282633
[epoch9, step2663]: loss 1.369591
[epoch9, step2664]: loss 4.579898
[epoch9, step2665]: loss 1.262036
[epoch9, step2666]: loss 18.084223
[epoch9, step2667]: loss 2.659520
[epoch9, step2668]: loss 1.659346
[epoch9, step2669]: loss 12.646982
[epoch9, step2670]: loss 5.788438
[epoch9, step2671]: loss 16.597382
[epoch9, step2672]: loss 7.472835
[epoch9, step2673]: loss 19.095158
[epoch9, step2674]: loss 18.320679
[epoch9, step2675]: loss 1.848028
[epoch9, step2676]: loss 1.589749
[epoch9, step2677]: loss 2.090914
[epoch9, step2678]: loss 1.432443
[epoch9, step2679]: loss 2.757615
[epoch9, step2680]: loss 2.522802
[epoch9, step2681]: loss 5.083320
[epoch9, step2682]: loss 2.524457
[epoch9, step2683]: loss 21.276094
[epoch9, step2684]: loss 1.713402
[epoch9, step2685]: loss 1.171536
[epoch9, step2686]: loss 1.354401
[epoch9, step2687]: loss 2.286945
[epoch9, step2688]: loss 2.118751
[epoch9, step2689]: loss 1.683778
[epoch9, step2690]: loss 2.635561
[epoch9, step2691]: loss 1.859583
[epoch9, step2692]: loss 1.124709
[epoch9, step2693]: loss 4.288020
[epoch9, step2694]: loss 2.280864
[epoch9, step2695]: loss 1.177457
[epoch9, step2696]: loss 7.016515
[epoch9, step2697]: loss 0.943501
[epoch9, step2698]: loss 31.631844
[epoch9, step2699]: loss 2.915155
[epoch9, step2700]: loss 1.346832
[epoch9, step2701]: loss 2.020967
[epoch9, step2702]: loss 8.415569
[epoch9, step2703]: loss 3.391528
[epoch9, step2704]: loss 7.526970
[epoch9, step2705]: loss 32.161865
[epoch9, step2706]: loss 4.265727
[epoch9, step2707]: loss 11.699537
[epoch9, step2708]: loss 0.783705
[epoch9, step2709]: loss 1.269003
[epoch9, step2710]: loss 3.784364
[epoch9, step2711]: loss 14.596290
[epoch9, step2712]: loss 3.207525
[epoch9, step2713]: loss 30.936901
[epoch9, step2714]: loss 2.297736
[epoch9, step2715]: loss 2.366438
[epoch9, step2716]: loss 4.601126
[epoch9, step2717]: loss 1.146218
[epoch9, step2718]: loss 14.376054
[epoch9, step2719]: loss 7.475384
[epoch9, step2720]: loss 2.457834
[epoch9, step2721]: loss 20.883308
[epoch9, step2722]: loss 1.712762
[epoch9, step2723]: loss 4.506606
[epoch9, step2724]: loss 1.616764
[epoch9, step2725]: loss 16.351160
[epoch9, step2726]: loss 1.417168
[epoch9, step2727]: loss 22.945482
[epoch9, step2728]: loss 1.859798
[epoch9, step2729]: loss 9.317800
[epoch9, step2730]: loss 2.141089
[epoch9, step2731]: loss 16.062944
[epoch9, step2732]: loss 2.448647
[epoch9, step2733]: loss 6.386834
[epoch9, step2734]: loss 7.276576
[epoch9, step2735]: loss 1.295272
[epoch9, step2736]: loss 11.845694
[epoch9, step2737]: loss 6.261547
[epoch9, step2738]: loss 2.033057
[epoch9, step2739]: loss 1.430258
[epoch9, step2740]: loss 12.836013
[epoch9, step2741]: loss 1.613768
[epoch9, step2742]: loss 13.128268
[epoch9, step2743]: loss 3.074248
[epoch9, step2744]: loss 2.520540
[epoch9, step2745]: loss 3.690960
[epoch9, step2746]: loss 15.601071
[epoch9, step2747]: loss 5.137237
[epoch9, step2748]: loss 4.053110
[epoch9, step2749]: loss 1.288756
[epoch9, step2750]: loss 6.283638
[epoch9, step2751]: loss 1.771001
[epoch9, step2752]: loss 2.432516
[epoch9, step2753]: loss 9.024302
[epoch9, step2754]: loss 2.293150
[epoch9, step2755]: loss 1.173584
[epoch9, step2756]: loss 3.759491
[epoch9, step2757]: loss 2.011542
[epoch9, step2758]: loss 2.662863
[epoch9, step2759]: loss 1.224858
[epoch9, step2760]: loss 8.834202
[epoch9, step2761]: loss 5.456496
[epoch9, step2762]: loss 1.766726
[epoch9, step2763]: loss 1.413594
[epoch9, step2764]: loss 2.397416
[epoch9, step2765]: loss 8.270184
[epoch9, step2766]: loss 24.495066
[epoch9, step2767]: loss 16.830656
[epoch9, step2768]: loss 22.205978
[epoch9, step2769]: loss 1.574867
[epoch9, step2770]: loss 2.140166
[epoch9, step2771]: loss 1.424772
[epoch9, step2772]: loss 1.469240
[epoch9, step2773]: loss 1.117498
[epoch9, step2774]: loss 2.337975
[epoch9, step2775]: loss 2.162369
[epoch9, step2776]: loss 6.906277
[epoch9, step2777]: loss 11.596265
[epoch9, step2778]: loss 3.830698
[epoch9, step2779]: loss 3.887058
[epoch9, step2780]: loss 1.714163
[epoch9, step2781]: loss 2.213110
[epoch9, step2782]: loss 5.458681
[epoch9, step2783]: loss 2.337141
[epoch9, step2784]: loss 5.824884
[epoch9, step2785]: loss 3.588150
[epoch9, step2786]: loss 17.583359
[epoch9, step2787]: loss 20.304638
[epoch9, step2788]: loss 11.910136
[epoch9, step2789]: loss 2.147645
[epoch9, step2790]: loss 1.202430
[epoch9, step2791]: loss 7.297036
[epoch9, step2792]: loss 2.826695
[epoch9, step2793]: loss 13.100595
[epoch9, step2794]: loss 18.942406
[epoch9, step2795]: loss 2.118543
[epoch9, step2796]: loss 3.741758
[epoch9, step2797]: loss 3.142621
[epoch9, step2798]: loss 4.877292
[epoch9, step2799]: loss 1.692780
[epoch9, step2800]: loss 1.874573
[epoch9, step2801]: loss 1.540620
[epoch9, step2802]: loss 2.843128
[epoch9, step2803]: loss 22.840969
[epoch9, step2804]: loss 7.572413
[epoch9, step2805]: loss 4.274875
[epoch9, step2806]: loss 3.673164
[epoch9, step2807]: loss 9.456138
[epoch9, step2808]: loss 10.025565
[epoch9, step2809]: loss 22.247410
[epoch9, step2810]: loss 1.102590
[epoch9, step2811]: loss 12.872298
[epoch9, step2812]: loss 16.023323
[epoch9, step2813]: loss 11.337496
[epoch9, step2814]: loss 3.675870
[epoch9, step2815]: loss 2.242290
[epoch9, step2816]: loss 3.431683
[epoch9, step2817]: loss 2.280391
[epoch9, step2818]: loss 1.337007
[epoch9, step2819]: loss 7.007380
[epoch9, step2820]: loss 2.174658
[epoch9, step2821]: loss 14.847121
[epoch9, step2822]: loss 1.026886
[epoch9, step2823]: loss 3.071480
[epoch9, step2824]: loss 2.524200
[epoch9, step2825]: loss 1.764216
[epoch9, step2826]: loss 23.122021
[epoch9, step2827]: loss 15.494936
[epoch9, step2828]: loss 1.266638
[epoch9, step2829]: loss 0.962491
[epoch9, step2830]: loss 1.419081
[epoch9, step2831]: loss 6.158924
[epoch9, step2832]: loss 2.284019
[epoch9, step2833]: loss 1.642393
[epoch9, step2834]: loss 3.749593
[epoch9, step2835]: loss 1.457523
[epoch9, step2836]: loss 19.360897
[epoch9, step2837]: loss 2.849145
[epoch9, step2838]: loss 5.123106
[epoch9, step2839]: loss 2.619814
[epoch9, step2840]: loss 14.962345
[epoch9, step2841]: loss 1.041805
[epoch9, step2842]: loss 2.450746
[epoch9, step2843]: loss 1.869542
[epoch9, step2844]: loss 4.425211
[epoch9, step2845]: loss 6.624008
[epoch9, step2846]: loss 30.821363
[epoch9, step2847]: loss 1.643573
[epoch9, step2848]: loss 2.671110
[epoch9, step2849]: loss 1.880765
[epoch9, step2850]: loss 7.182796
[epoch9, step2851]: loss 2.154188
[epoch9, step2852]: loss 1.844246
[epoch9, step2853]: loss 2.304289
[epoch9, step2854]: loss 2.324885
[epoch9, step2855]: loss 1.657234
[epoch9, step2856]: loss 1.244298
[epoch9, step2857]: loss 1.034556
[epoch9, step2858]: loss 19.581280
[epoch9, step2859]: loss 5.168482
[epoch9, step2860]: loss 4.463987
[epoch9, step2861]: loss 1.504273
[epoch9, step2862]: loss 1.728466
[epoch9, step2863]: loss 3.548805
[epoch9, step2864]: loss 1.803801
[epoch9, step2865]: loss 3.371130
[epoch9, step2866]: loss 11.896495
[epoch9, step2867]: loss 13.850189
[epoch9, step2868]: loss 13.027876
[epoch9, step2869]: loss 1.643046
[epoch9, step2870]: loss 15.297125
[epoch9, step2871]: loss 2.371844
[epoch9, step2872]: loss 1.795079
[epoch9, step2873]: loss 1.849912
[epoch9, step2874]: loss 2.025640
[epoch9, step2875]: loss 5.260189
[epoch9, step2876]: loss 2.592473
[epoch9, step2877]: loss 6.004549
[epoch9, step2878]: loss 1.022605
[epoch9, step2879]: loss 6.982167
[epoch9, step2880]: loss 4.014366
[epoch9, step2881]: loss 2.136580
[epoch9, step2882]: loss 3.243048
[epoch9, step2883]: loss 2.484929
[epoch9, step2884]: loss 21.170511
[epoch9, step2885]: loss 1.348559
[epoch9, step2886]: loss 14.472149
[epoch9, step2887]: loss 22.786472
[epoch9, step2888]: loss 1.407786
[epoch9, step2889]: loss 4.791863
[epoch9, step2890]: loss 15.387462
[epoch9, step2891]: loss 0.997728
[epoch9, step2892]: loss 3.902477
[epoch9, step2893]: loss 2.134986
[epoch9, step2894]: loss 3.101337
[epoch9, step2895]: loss 1.099695
[epoch9, step2896]: loss 0.905832
[epoch9, step2897]: loss 4.670062
[epoch9, step2898]: loss 1.581699
[epoch9, step2899]: loss 1.845293
[epoch9, step2900]: loss 9.951788
[epoch9, step2901]: loss 1.610510
[epoch9, step2902]: loss 0.642621
[epoch9, step2903]: loss 5.476411
[epoch9, step2904]: loss 2.053304
[epoch9, step2905]: loss 5.384129
[epoch9, step2906]: loss 12.581005
[epoch9, step2907]: loss 3.619504
[epoch9, step2908]: loss 4.755594
[epoch9, step2909]: loss 1.489410
[epoch9, step2910]: loss 1.544012
[epoch9, step2911]: loss 18.125919
[epoch9, step2912]: loss 0.864261
[epoch9, step2913]: loss 3.051571
[epoch9, step2914]: loss 1.845656
[epoch9, step2915]: loss 31.159082
[epoch9, step2916]: loss 1.941744
[epoch9, step2917]: loss 4.984430
[epoch9, step2918]: loss 22.708420
[epoch9, step2919]: loss 1.463885
[epoch9, step2920]: loss 0.887767
[epoch9, step2921]: loss 2.971356
[epoch9, step2922]: loss 5.217928
[epoch9, step2923]: loss 2.086190
[epoch9, step2924]: loss 8.992658
[epoch9, step2925]: loss 1.079190
[epoch9, step2926]: loss 2.754535
[epoch9, step2927]: loss 1.110722
[epoch9, step2928]: loss 1.833987
[epoch9, step2929]: loss 8.795615
[epoch9, step2930]: loss 2.442954
[epoch9, step2931]: loss 3.448883
[epoch9, step2932]: loss 7.066212
[epoch9, step2933]: loss 3.566944
[epoch9, step2934]: loss 2.471632
[epoch9, step2935]: loss 23.469635
[epoch9, step2936]: loss 4.954516
[epoch9, step2937]: loss 13.891458
[epoch9, step2938]: loss 16.714518
[epoch9, step2939]: loss 1.931403
[epoch9, step2940]: loss 1.733455
[epoch9, step2941]: loss 12.101462
[epoch9, step2942]: loss 2.475882
[epoch9, step2943]: loss 2.397855
[epoch9, step2944]: loss 2.210558
[epoch9, step2945]: loss 1.648020
[epoch9, step2946]: loss 7.718412
[epoch9, step2947]: loss 3.831445
[epoch9, step2948]: loss 1.700339
[epoch9, step2949]: loss 8.864252
[epoch9, step2950]: loss 3.200458
[epoch9, step2951]: loss 1.790128
[epoch9, step2952]: loss 2.725962
[epoch9, step2953]: loss 0.996917
[epoch9, step2954]: loss 2.508913
[epoch9, step2955]: loss 1.231552
[epoch9, step2956]: loss 11.061826
[epoch9, step2957]: loss 1.500450
[epoch9, step2958]: loss 1.965218
[epoch9, step2959]: loss 23.326818
[epoch9, step2960]: loss 3.132680
[epoch9, step2961]: loss 1.063666
[epoch9, step2962]: loss 2.928498
[epoch9, step2963]: loss 1.684578
[epoch9, step2964]: loss 1.337508
[epoch9, step2965]: loss 10.495744
[epoch9, step2966]: loss 10.188663
[epoch9, step2967]: loss 22.885078
[epoch9, step2968]: loss 2.927624
[epoch9, step2969]: loss 3.802435
[epoch9, step2970]: loss 26.828577
[epoch9, step2971]: loss 15.096390
[epoch9, step2972]: loss 3.881199
[epoch9, step2973]: loss 20.095053
[epoch9, step2974]: loss 9.332064
[epoch9, step2975]: loss 2.169228
[epoch9, step2976]: loss 33.162708
[epoch9, step2977]: loss 5.122970
[epoch9, step2978]: loss 2.376098
[epoch9, step2979]: loss 2.827366
[epoch9, step2980]: loss 17.952692
[epoch9, step2981]: loss 15.877462
[epoch9, step2982]: loss 16.759727
[epoch9, step2983]: loss 1.759232
[epoch9, step2984]: loss 17.266527
[epoch9, step2985]: loss 10.618405
[epoch9, step2986]: loss 1.501626
[epoch9, step2987]: loss 14.771869
[epoch9, step2988]: loss 0.935571
[epoch9, step2989]: loss 0.840170
[epoch9, step2990]: loss 1.720623
[epoch9, step2991]: loss 26.745316
[epoch9, step2992]: loss 1.618923
[epoch9, step2993]: loss 6.144967
[epoch9, step2994]: loss 3.247105
[epoch9, step2995]: loss 34.236248
[epoch9, step2996]: loss 1.182833
[epoch9, step2997]: loss 2.210153
[epoch9, step2998]: loss 12.802787
[epoch9, step2999]: loss 11.459222
[epoch9, step3000]: loss 5.269959
[epoch9, step3001]: loss 2.082245
[epoch9, step3002]: loss 2.863593
[epoch9, step3003]: loss 14.147211
[epoch9, step3004]: loss 16.788670
[epoch9, step3005]: loss 1.233616
[epoch9, step3006]: loss 1.392308
[epoch9, step3007]: loss 1.839233
[epoch9, step3008]: loss 5.120739
[epoch9, step3009]: loss 1.259161
[epoch9, step3010]: loss 2.862250
[epoch9, step3011]: loss 4.824151
[epoch9, step3012]: loss 3.608346
[epoch9, step3013]: loss 1.636877
[epoch9, step3014]: loss 3.285386
[epoch9, step3015]: loss 1.882641
[epoch9, step3016]: loss 13.291359
[epoch9, step3017]: loss 2.679213
[epoch9, step3018]: loss 8.882472
[epoch9, step3019]: loss 10.565346
[epoch9, step3020]: loss 1.075388
[epoch9, step3021]: loss 3.046279
[epoch9, step3022]: loss 39.985352
[epoch9, step3023]: loss 20.684587
[epoch9, step3024]: loss 1.479309
[epoch9, step3025]: loss 2.142943
[epoch9, step3026]: loss 3.527494
[epoch9, step3027]: loss 0.646104
[epoch9, step3028]: loss 3.718678
[epoch9, step3029]: loss 2.424169
[epoch9, step3030]: loss 32.891293
[epoch9, step3031]: loss 1.231296
[epoch9, step3032]: loss 12.962348
[epoch9, step3033]: loss 6.940671
[epoch9, step3034]: loss 3.224206
[epoch9, step3035]: loss 2.036661
[epoch9, step3036]: loss 2.534210
[epoch9, step3037]: loss 0.878833
[epoch9, step3038]: loss 2.504875
[epoch9, step3039]: loss 2.030081
[epoch9, step3040]: loss 1.834303
[epoch9, step3041]: loss 0.637130
[epoch9, step3042]: loss 21.905678
[epoch9, step3043]: loss 3.654589
[epoch9, step3044]: loss 1.794688
[epoch9, step3045]: loss 11.120017
[epoch9, step3046]: loss 5.283791
[epoch9, step3047]: loss 26.611444
[epoch9, step3048]: loss 2.350332
[epoch9, step3049]: loss 11.620282
[epoch9, step3050]: loss 2.698681
[epoch9, step3051]: loss 20.725044
[epoch9, step3052]: loss 12.816701
[epoch9, step3053]: loss 3.466457
[epoch9, step3054]: loss 15.276696
[epoch9, step3055]: loss 3.138301
[epoch9, step3056]: loss 7.696886
[epoch9, step3057]: loss 2.572614
[epoch9, step3058]: loss 7.433782
[epoch9, step3059]: loss 2.676230
[epoch9, step3060]: loss 1.715076
[epoch9, step3061]: loss 22.958246
[epoch9, step3062]: loss 1.460053
[epoch9, step3063]: loss 1.639244
[epoch9, step3064]: loss 1.964432
[epoch9, step3065]: loss 16.439497
[epoch9, step3066]: loss 1.917789
[epoch9, step3067]: loss 1.571759
[epoch9, step3068]: loss 2.421302
[epoch9, step3069]: loss 4.486462
[epoch9, step3070]: loss 4.585895
[epoch9, step3071]: loss 3.246868
[epoch9, step3072]: loss 1.092370
[epoch9, step3073]: loss 12.176397
[epoch9, step3074]: loss 2.208386
[epoch9, step3075]: loss 15.894861
[epoch9, step3076]: loss 8.448112

[epoch9]: avg loss 8.448112

[epoch10, step1]: loss 1.652112
[epoch10, step2]: loss 2.745495
[epoch10, step3]: loss 3.653382
[epoch10, step4]: loss 3.039465
[epoch10, step5]: loss 2.649479
[epoch10, step6]: loss 1.146743
[epoch10, step7]: loss 3.063971
[epoch10, step8]: loss 5.737354
[epoch10, step9]: loss 2.510506
[epoch10, step10]: loss 3.221318
[epoch10, step11]: loss 46.994793
[epoch10, step12]: loss 25.499542
[epoch10, step13]: loss 20.757565
[epoch10, step14]: loss 1.259899
[epoch10, step15]: loss 10.592437
[epoch10, step16]: loss 9.430960
[epoch10, step17]: loss 1.764246
[epoch10, step18]: loss 2.226545
[epoch10, step19]: loss 3.037073
[epoch10, step20]: loss 1.010507
[epoch10, step21]: loss 6.947564
[epoch10, step22]: loss 2.328460
[epoch10, step23]: loss 7.767669
[epoch10, step24]: loss 2.195782
[epoch10, step25]: loss 2.744953
[epoch10, step26]: loss 6.536371
[epoch10, step27]: loss 1.592539
[epoch10, step28]: loss 1.835513
[epoch10, step29]: loss 3.788915
[epoch10, step30]: loss 0.912900
[epoch10, step31]: loss 1.272509
[epoch10, step32]: loss 1.266848
[epoch10, step33]: loss 1.470745
[epoch10, step34]: loss 1.185841
[epoch10, step35]: loss 4.651838
[epoch10, step36]: loss 1.911068
[epoch10, step37]: loss 5.848685
[epoch10, step38]: loss 19.063919
[epoch10, step39]: loss 5.799586
[epoch10, step40]: loss 1.141013
[epoch10, step41]: loss 3.200620
[epoch10, step42]: loss 9.561829
[epoch10, step43]: loss 0.958541
[epoch10, step44]: loss 5.381765
[epoch10, step45]: loss 1.215150
[epoch10, step46]: loss 5.047188
[epoch10, step47]: loss 7.487957
[epoch10, step48]: loss 1.825472
[epoch10, step49]: loss 4.199488
[epoch10, step50]: loss 7.698247
[epoch10, step51]: loss 0.823518
[epoch10, step52]: loss 4.490700
[epoch10, step53]: loss 29.065933
[epoch10, step54]: loss 5.409286
[epoch10, step55]: loss 1.704669
[epoch10, step56]: loss 1.973103
[epoch10, step57]: loss 8.039415
[epoch10, step58]: loss 3.189293
[epoch10, step59]: loss 3.022427
[epoch10, step60]: loss 4.348760
[epoch10, step61]: loss 15.706642
[epoch10, step62]: loss 3.750939
[epoch10, step63]: loss 3.246804
[epoch10, step64]: loss 2.125905
[epoch10, step65]: loss 1.133340
[epoch10, step66]: loss 1.649783
[epoch10, step67]: loss 2.785694
[epoch10, step68]: loss 1.571080
[epoch10, step69]: loss 17.021591
[epoch10, step70]: loss 6.657015
[epoch10, step71]: loss 3.144668
[epoch10, step72]: loss 15.862530
[epoch10, step73]: loss 3.880290
[epoch10, step74]: loss 1.916523
[epoch10, step75]: loss 1.879936
[epoch10, step76]: loss 1.548421
[epoch10, step77]: loss 2.602278
[epoch10, step78]: loss 1.625958
[epoch10, step79]: loss 13.176148
[epoch10, step80]: loss 1.819042
[epoch10, step81]: loss 0.881801
[epoch10, step82]: loss 14.943912
[epoch10, step83]: loss 14.070450
[epoch10, step84]: loss 3.880082
[epoch10, step85]: loss 16.051992
[epoch10, step86]: loss 4.954264
[epoch10, step87]: loss 4.977026
[epoch10, step88]: loss 2.376191
[epoch10, step89]: loss 2.463746
[epoch10, step90]: loss 1.498423
[epoch10, step91]: loss 1.517310
[epoch10, step92]: loss 6.990504
[epoch10, step93]: loss 2.816968
[epoch10, step94]: loss 1.447453
[epoch10, step95]: loss 11.837178
[epoch10, step96]: loss 11.175068
[epoch10, step97]: loss 1.972564
[epoch10, step98]: loss 5.460824
[epoch10, step99]: loss 3.789464
[epoch10, step100]: loss 16.855202
[epoch10, step101]: loss 14.512568
[epoch10, step102]: loss 1.911377
[epoch10, step103]: loss 2.231799
[epoch10, step104]: loss 15.208364
[epoch10, step105]: loss 1.297795
[epoch10, step106]: loss 2.357508
[epoch10, step107]: loss 21.751040
[epoch10, step108]: loss 1.026371
[epoch10, step109]: loss 1.543509
[epoch10, step110]: loss 13.151146
[epoch10, step111]: loss 3.369799
[epoch10, step112]: loss 3.393527
[epoch10, step113]: loss 10.845501
[epoch10, step114]: loss 15.304101
[epoch10, step115]: loss 5.725714
[epoch10, step116]: loss 1.395683
[epoch10, step117]: loss 2.775745
[epoch10, step118]: loss 3.072712
[epoch10, step119]: loss 1.460627
[epoch10, step120]: loss 4.969655
[epoch10, step121]: loss 2.752459
[epoch10, step122]: loss 10.930316
[epoch10, step123]: loss 2.074566
[epoch10, step124]: loss 10.360446
[epoch10, step125]: loss 1.873788
[epoch10, step126]: loss 2.595021
[epoch10, step127]: loss 1.671670
[epoch10, step128]: loss 1.686589
[epoch10, step129]: loss 2.357671
[epoch10, step130]: loss 8.575483
[epoch10, step131]: loss 11.850245
[epoch10, step132]: loss 2.379805
[epoch10, step133]: loss 1.531829
[epoch10, step134]: loss 20.453661
[epoch10, step135]: loss 16.552197
[epoch10, step136]: loss 2.159079
[epoch10, step137]: loss 4.641920
[epoch10, step138]: loss 1.565035
[epoch10, step139]: loss 2.414611
[epoch10, step140]: loss 28.750631
[epoch10, step141]: loss 10.059185
[epoch10, step142]: loss 3.307590
[epoch10, step143]: loss 2.520622
[epoch10, step144]: loss 2.652301
[epoch10, step145]: loss 3.688578
[epoch10, step146]: loss 1.369353
[epoch10, step147]: loss 4.467627
[epoch10, step148]: loss 3.119963
[epoch10, step149]: loss 0.792136
[epoch10, step150]: loss 4.211960
[epoch10, step151]: loss 7.724679
[epoch10, step152]: loss 8.830360
[epoch10, step153]: loss 13.717920
[epoch10, step154]: loss 2.761011
[epoch10, step155]: loss 1.261085
[epoch10, step156]: loss 7.377138
[epoch10, step157]: loss 2.496104
[epoch10, step158]: loss 2.176635
[epoch10, step159]: loss 5.045583
[epoch10, step160]: loss 1.152426
[epoch10, step161]: loss 1.591333
[epoch10, step162]: loss 2.600632
[epoch10, step163]: loss 1.147490
[epoch10, step164]: loss 13.609045
[epoch10, step165]: loss 0.888536
[epoch10, step166]: loss 2.644290
[epoch10, step167]: loss 1.391599
[epoch10, step168]: loss 1.263694
[epoch10, step169]: loss 1.893431
[epoch10, step170]: loss 1.228453
[epoch10, step171]: loss 2.611882
[epoch10, step172]: loss 2.526794
[epoch10, step173]: loss 4.323126
[epoch10, step174]: loss 26.366259
[epoch10, step175]: loss 2.539517
[epoch10, step176]: loss 1.688351
[epoch10, step177]: loss 16.245237
[epoch10, step178]: loss 1.321689
[epoch10, step179]: loss 1.319453
[epoch10, step180]: loss 2.438895
[epoch10, step181]: loss 1.402505
[epoch10, step182]: loss 3.657333
[epoch10, step183]: loss 1.762618
[epoch10, step184]: loss 1.688963
[epoch10, step185]: loss 5.462237
[epoch10, step186]: loss 1.506434
[epoch10, step187]: loss 11.842059
[epoch10, step188]: loss 2.431157
[epoch10, step189]: loss 13.595955
[epoch10, step190]: loss 4.479695
[epoch10, step191]: loss 3.610375
[epoch10, step192]: loss 0.918597
[epoch10, step193]: loss 19.440216
[epoch10, step194]: loss 2.584761
[epoch10, step195]: loss 1.002449
[epoch10, step196]: loss 13.216707
[epoch10, step197]: loss 1.043066
[epoch10, step198]: loss 11.730906
[epoch10, step199]: loss 3.692959
[epoch10, step200]: loss 2.446856
[epoch10, step201]: loss 2.812377
[epoch10, step202]: loss 17.185986
[epoch10, step203]: loss 6.670020
[epoch10, step204]: loss 1.788847
[epoch10, step205]: loss 2.696831
[epoch10, step206]: loss 2.127911
[epoch10, step207]: loss 20.859657
[epoch10, step208]: loss 1.862905
[epoch10, step209]: loss 1.470134
[epoch10, step210]: loss 1.762378
[epoch10, step211]: loss 1.469000
[epoch10, step212]: loss 0.759632
[epoch10, step213]: loss 4.485679
[epoch10, step214]: loss 3.506045
[epoch10, step215]: loss 21.043594
[epoch10, step216]: loss 2.102769
[epoch10, step217]: loss 1.073350
[epoch10, step218]: loss 2.019221
[epoch10, step219]: loss 1.756101
[epoch10, step220]: loss 2.053318
[epoch10, step221]: loss 13.061497
[epoch10, step222]: loss 12.520360
[epoch10, step223]: loss 1.996054
[epoch10, step224]: loss 2.682051
[epoch10, step225]: loss 0.883781
[epoch10, step226]: loss 1.311284
[epoch10, step227]: loss 18.465916
[epoch10, step228]: loss 3.684045
[epoch10, step229]: loss 1.438444
[epoch10, step230]: loss 2.871641
[epoch10, step231]: loss 1.340095
[epoch10, step232]: loss 2.543462
[epoch10, step233]: loss 3.956676
[epoch10, step234]: loss 1.926880
[epoch10, step235]: loss 2.618363
[epoch10, step236]: loss 23.194210
[epoch10, step237]: loss 12.164204
[epoch10, step238]: loss 1.238388
[epoch10, step239]: loss 1.477984
[epoch10, step240]: loss 21.890224
[epoch10, step241]: loss 0.816837
[epoch10, step242]: loss 2.317943
[epoch10, step243]: loss 9.587873
[epoch10, step244]: loss 2.350356
[epoch10, step245]: loss 19.853104
[epoch10, step246]: loss 24.913723
[epoch10, step247]: loss 2.355325
[epoch10, step248]: loss 0.861798
[epoch10, step249]: loss 15.427951
[epoch10, step250]: loss 2.383210
[epoch10, step251]: loss 12.358895
[epoch10, step252]: loss 1.335034
[epoch10, step253]: loss 17.457401
[epoch10, step254]: loss 1.787791
[epoch10, step255]: loss 1.014423
[epoch10, step256]: loss 1.828359
[epoch10, step257]: loss 2.213228
[epoch10, step258]: loss 6.297179
[epoch10, step259]: loss 13.699423
[epoch10, step260]: loss 3.736732
[epoch10, step261]: loss 1.373177
[epoch10, step262]: loss 11.297557
[epoch10, step263]: loss 1.268015
[epoch10, step264]: loss 13.708472
[epoch10, step265]: loss 9.101893
[epoch10, step266]: loss 5.402642
[epoch10, step267]: loss 8.629784
[epoch10, step268]: loss 30.410105
[epoch10, step269]: loss 1.945594
[epoch10, step270]: loss 2.099463
[epoch10, step271]: loss 11.563491
[epoch10, step272]: loss 2.321382
[epoch10, step273]: loss 2.939277
[epoch10, step274]: loss 16.754772
[epoch10, step275]: loss 13.432192
[epoch10, step276]: loss 1.752981
[epoch10, step277]: loss 19.802868
[epoch10, step278]: loss 1.784369
[epoch10, step279]: loss 11.295889
[epoch10, step280]: loss 19.470154
[epoch10, step281]: loss 1.911685
[epoch10, step282]: loss 1.835593
[epoch10, step283]: loss 24.018490
[epoch10, step284]: loss 1.271263
[epoch10, step285]: loss 16.132174
[epoch10, step286]: loss 1.935692
[epoch10, step287]: loss 5.977643
[epoch10, step288]: loss 4.584531
[epoch10, step289]: loss 1.492081
[epoch10, step290]: loss 14.885733
[epoch10, step291]: loss 10.856545
[epoch10, step292]: loss 1.626750
[epoch10, step293]: loss 0.730893
[epoch10, step294]: loss 3.748645
[epoch10, step295]: loss 1.260054
[epoch10, step296]: loss 8.188819
[epoch10, step297]: loss 2.870743
[epoch10, step298]: loss 6.732747
[epoch10, step299]: loss 2.292651
[epoch10, step300]: loss 14.505911
[epoch10, step301]: loss 1.326385
[epoch10, step302]: loss 4.191446
[epoch10, step303]: loss 1.653616
[epoch10, step304]: loss 5.082015
[epoch10, step305]: loss 4.420302
[epoch10, step306]: loss 1.061820
[epoch10, step307]: loss 12.577991
[epoch10, step308]: loss 1.387336
[epoch10, step309]: loss 1.766406
[epoch10, step310]: loss 3.894258
[epoch10, step311]: loss 1.329566
[epoch10, step312]: loss 10.606911
[epoch10, step313]: loss 3.515349
[epoch10, step314]: loss 5.068967
[epoch10, step315]: loss 2.179993
[epoch10, step316]: loss 10.192013
[epoch10, step317]: loss 2.663386
[epoch10, step318]: loss 25.436741
[epoch10, step319]: loss 1.040921
[epoch10, step320]: loss 18.817675
[epoch10, step321]: loss 13.553507
[epoch10, step322]: loss 28.205921
[epoch10, step323]: loss 1.232358
[epoch10, step324]: loss 1.186365
[epoch10, step325]: loss 5.206667
[epoch10, step326]: loss 1.310453
[epoch10, step327]: loss 2.443437
[epoch10, step328]: loss 1.578136
[epoch10, step329]: loss 14.209561
[epoch10, step330]: loss 23.179991
[epoch10, step331]: loss 4.588555
[epoch10, step332]: loss 1.561222
[epoch10, step333]: loss 3.849682
[epoch10, step334]: loss 11.104746
[epoch10, step335]: loss 1.712326
[epoch10, step336]: loss 1.343364
[epoch10, step337]: loss 5.768082
[epoch10, step338]: loss 2.921436
[epoch10, step339]: loss 21.177839
[epoch10, step340]: loss 0.929880
[epoch10, step341]: loss 6.661582
[epoch10, step342]: loss 2.265457
[epoch10, step343]: loss 0.692392
[epoch10, step344]: loss 2.028419
[epoch10, step345]: loss 11.736074
[epoch10, step346]: loss 1.714187
[epoch10, step347]: loss 1.352361
[epoch10, step348]: loss 14.954328
[epoch10, step349]: loss 1.750247
[epoch10, step350]: loss 29.181583
[epoch10, step351]: loss 1.162635
[epoch10, step352]: loss 1.196950
[epoch10, step353]: loss 1.290064
[epoch10, step354]: loss 3.465760
[epoch10, step355]: loss 3.012774
[epoch10, step356]: loss 7.520520
[epoch10, step357]: loss 14.679066
[epoch10, step358]: loss 27.573765
[epoch10, step359]: loss 1.412370
[epoch10, step360]: loss 4.359852
[epoch10, step361]: loss 1.643819
[epoch10, step362]: loss 6.623069
[epoch10, step363]: loss 11.578940
[epoch10, step364]: loss 30.424643
[epoch10, step365]: loss 27.556200
[epoch10, step366]: loss 6.177879
[epoch10, step367]: loss 1.741121
[epoch10, step368]: loss 2.246488
[epoch10, step369]: loss 1.302323
[epoch10, step370]: loss 3.367110
[epoch10, step371]: loss 17.433352
[epoch10, step372]: loss 1.514751
[epoch10, step373]: loss 2.299272
[epoch10, step374]: loss 3.056730
[epoch10, step375]: loss 2.842519
[epoch10, step376]: loss 4.121306
[epoch10, step377]: loss 4.769870
[epoch10, step378]: loss 13.148942
[epoch10, step379]: loss 15.909916
[epoch10, step380]: loss 18.044630
[epoch10, step381]: loss 2.185936
[epoch10, step382]: loss 2.092496
[epoch10, step383]: loss 3.581495
[epoch10, step384]: loss 1.578716
[epoch10, step385]: loss 1.431103
[epoch10, step386]: loss 10.959542
[epoch10, step387]: loss 5.340741
[epoch10, step388]: loss 1.570181
[epoch10, step389]: loss 2.632732
[epoch10, step390]: loss 33.965828
[epoch10, step391]: loss 11.059029
[epoch10, step392]: loss 4.388982
[epoch10, step393]: loss 2.712614
[epoch10, step394]: loss 0.976142
[epoch10, step395]: loss 1.372123
[epoch10, step396]: loss 1.286186
[epoch10, step397]: loss 1.656048
[epoch10, step398]: loss 20.022749
[epoch10, step399]: loss 1.879160
[epoch10, step400]: loss 18.554947
[epoch10, step401]: loss 1.958546
[epoch10, step402]: loss 21.518536
[epoch10, step403]: loss 8.776953
[epoch10, step404]: loss 2.087803
[epoch10, step405]: loss 0.914773
[epoch10, step406]: loss 19.800365
[epoch10, step407]: loss 1.451885
[epoch10, step408]: loss 9.578009
[epoch10, step409]: loss 2.651008
[epoch10, step410]: loss 7.055571
[epoch10, step411]: loss 20.323978
[epoch10, step412]: loss 1.334335
[epoch10, step413]: loss 3.674176
[epoch10, step414]: loss 1.492657
[epoch10, step415]: loss 3.114382
[epoch10, step416]: loss 2.879064
[epoch10, step417]: loss 1.451862
[epoch10, step418]: loss 1.526027
[epoch10, step419]: loss 41.674332
[epoch10, step420]: loss 12.108673
[epoch10, step421]: loss 3.410801
[epoch10, step422]: loss 1.614409
[epoch10, step423]: loss 2.365012
[epoch10, step424]: loss 3.507419
[epoch10, step425]: loss 1.607656
[epoch10, step426]: loss 1.228193
[epoch10, step427]: loss 29.283510
[epoch10, step428]: loss 5.792695
[epoch10, step429]: loss 2.575506
[epoch10, step430]: loss 1.320181
[epoch10, step431]: loss 2.896751
[epoch10, step432]: loss 1.278175
[epoch10, step433]: loss 2.633742
[epoch10, step434]: loss 1.746873
[epoch10, step435]: loss 4.434267
[epoch10, step436]: loss 10.241919
[epoch10, step437]: loss 3.631014
[epoch10, step438]: loss 11.107347
[epoch10, step439]: loss 2.940954
[epoch10, step440]: loss 2.033066
[epoch10, step441]: loss 2.766733
[epoch10, step442]: loss 28.590210
[epoch10, step443]: loss 1.726688
[epoch10, step444]: loss 2.203570
[epoch10, step445]: loss 4.499758
[epoch10, step446]: loss 5.517511
[epoch10, step447]: loss 17.478252
[epoch10, step448]: loss 3.757532
[epoch10, step449]: loss 4.792341
[epoch10, step450]: loss 1.717540
[epoch10, step451]: loss 4.922165
[epoch10, step452]: loss 4.936568
[epoch10, step453]: loss 0.901076
[epoch10, step454]: loss 7.569271
[epoch10, step455]: loss 1.764423
[epoch10, step456]: loss 17.576681
[epoch10, step457]: loss 1.241881
[epoch10, step458]: loss 1.519423
[epoch10, step459]: loss 1.698830
[epoch10, step460]: loss 2.482631
[epoch10, step461]: loss 1.595458
[epoch10, step462]: loss 2.389636
[epoch10, step463]: loss 2.090358
[epoch10, step464]: loss 30.390497
[epoch10, step465]: loss 1.566822
[epoch10, step466]: loss 9.457335
[epoch10, step467]: loss 14.215930
[epoch10, step468]: loss 2.628995
[epoch10, step469]: loss 5.276932
[epoch10, step470]: loss 7.595586
[epoch10, step471]: loss 3.129463
[epoch10, step472]: loss 10.851099
[epoch10, step473]: loss 13.040804
[epoch10, step474]: loss 13.107532
[epoch10, step475]: loss 1.333138
[epoch10, step476]: loss 2.028139
[epoch10, step477]: loss 1.916435
[epoch10, step478]: loss 12.525353
[epoch10, step479]: loss 21.638474
[epoch10, step480]: loss 21.668375
[epoch10, step481]: loss 15.718242
[epoch10, step482]: loss 1.370754
[epoch10, step483]: loss 11.468026
[epoch10, step484]: loss 3.748360
[epoch10, step485]: loss 1.842721
[epoch10, step486]: loss 1.984660
[epoch10, step487]: loss 12.263548
[epoch10, step488]: loss 6.911141
[epoch10, step489]: loss 14.262629
[epoch10, step490]: loss 1.518914
[epoch10, step491]: loss 1.643948
[epoch10, step492]: loss 4.378088
[epoch10, step493]: loss 0.837284
[epoch10, step494]: loss 2.261657
[epoch10, step495]: loss 1.696523
[epoch10, step496]: loss 1.547009
[epoch10, step497]: loss 1.539356
[epoch10, step498]: loss 2.651464
[epoch10, step499]: loss 2.857754
[epoch10, step500]: loss 1.311475
[epoch10, step501]: loss 10.371054
[epoch10, step502]: loss 17.460533
[epoch10, step503]: loss 2.522495
[epoch10, step504]: loss 1.574866
[epoch10, step505]: loss 10.463020
[epoch10, step506]: loss 7.857517
[epoch10, step507]: loss 2.356656
[epoch10, step508]: loss 3.073403
[epoch10, step509]: loss 16.445309
[epoch10, step510]: loss 2.074966
[epoch10, step511]: loss 16.106005
[epoch10, step512]: loss 2.166620
[epoch10, step513]: loss 3.533280
[epoch10, step514]: loss 3.173788
[epoch10, step515]: loss 1.560395
[epoch10, step516]: loss 5.981816
[epoch10, step517]: loss 21.925781
[epoch10, step518]: loss 5.180945
[epoch10, step519]: loss 3.336228
[epoch10, step520]: loss 2.783441
[epoch10, step521]: loss 16.395515
[epoch10, step522]: loss 5.496287
[epoch10, step523]: loss 1.974137
[epoch10, step524]: loss 1.567838
[epoch10, step525]: loss 0.917827
[epoch10, step526]: loss 32.140209
[epoch10, step527]: loss 0.953086
[epoch10, step528]: loss 13.561031
[epoch10, step529]: loss 7.821979
[epoch10, step530]: loss 10.553270
[epoch10, step531]: loss 2.183289
[epoch10, step532]: loss 9.815820
[epoch10, step533]: loss 2.974028
[epoch10, step534]: loss 5.551335
[epoch10, step535]: loss 22.931984
[epoch10, step536]: loss 1.917651
[epoch10, step537]: loss 1.179989
[epoch10, step538]: loss 2.726411
[epoch10, step539]: loss 1.709273
[epoch10, step540]: loss 14.428896
[epoch10, step541]: loss 5.222166
[epoch10, step542]: loss 1.345741
[epoch10, step543]: loss 7.327180
[epoch10, step544]: loss 2.243465
[epoch10, step545]: loss 1.708669
[epoch10, step546]: loss 2.102762
[epoch10, step547]: loss 2.735863
[epoch10, step548]: loss 5.035117
[epoch10, step549]: loss 11.789279
[epoch10, step550]: loss 19.446186
[epoch10, step551]: loss 2.788526
[epoch10, step552]: loss 20.841097
[epoch10, step553]: loss 3.011551
[epoch10, step554]: loss 15.074292
[epoch10, step555]: loss 4.466140
[epoch10, step556]: loss 2.663515
[epoch10, step557]: loss 2.053459
[epoch10, step558]: loss 1.956314
[epoch10, step559]: loss 4.849165
[epoch10, step560]: loss 1.739583
[epoch10, step561]: loss 3.367078
[epoch10, step562]: loss 2.786835
[epoch10, step563]: loss 2.761989
[epoch10, step564]: loss 2.968275
[epoch10, step565]: loss 2.072093
[epoch10, step566]: loss 0.889525
[epoch10, step567]: loss 1.039888
[epoch10, step568]: loss 0.816555
[epoch10, step569]: loss 2.265788
[epoch10, step570]: loss 1.657636
[epoch10, step571]: loss 5.946569
[epoch10, step572]: loss 22.053772
[epoch10, step573]: loss 11.219553
[epoch10, step574]: loss 1.404222
[epoch10, step575]: loss 1.253412
[epoch10, step576]: loss 5.793509
[epoch10, step577]: loss 1.352834
[epoch10, step578]: loss 1.029352
[epoch10, step579]: loss 4.780040
[epoch10, step580]: loss 1.730937
[epoch10, step581]: loss 2.095996
[epoch10, step582]: loss 1.193841
[epoch10, step583]: loss 2.502116
[epoch10, step584]: loss 2.133170
[epoch10, step585]: loss 11.647644
[epoch10, step586]: loss 3.232744
[epoch10, step587]: loss 25.053169
[epoch10, step588]: loss 15.647816
[epoch10, step589]: loss 2.946605
[epoch10, step590]: loss 3.145865
[epoch10, step591]: loss 2.325419
[epoch10, step592]: loss 1.862092
[epoch10, step593]: loss 1.679929
[epoch10, step594]: loss 3.227036
[epoch10, step595]: loss 3.239008
[epoch10, step596]: loss 4.249750
[epoch10, step597]: loss 1.311475
[epoch10, step598]: loss 1.212828
[epoch10, step599]: loss 4.068992
[epoch10, step600]: loss 1.628771
[epoch10, step601]: loss 0.846325
[epoch10, step602]: loss 19.868364
[epoch10, step603]: loss 3.466443
[epoch10, step604]: loss 2.223950
[epoch10, step605]: loss 0.630657
[epoch10, step606]: loss 1.273201
[epoch10, step607]: loss 15.734921
[epoch10, step608]: loss 12.361269
[epoch10, step609]: loss 2.438382
[epoch10, step610]: loss 3.320899
[epoch10, step611]: loss 2.019272
[epoch10, step612]: loss 2.365868
[epoch10, step613]: loss 3.958054
[epoch10, step614]: loss 1.605796
[epoch10, step615]: loss 3.192613
[epoch10, step616]: loss 2.323568
[epoch10, step617]: loss 2.894694
[epoch10, step618]: loss 1.035579
[epoch10, step619]: loss 1.130297
[epoch10, step620]: loss 1.511057
[epoch10, step621]: loss 1.951874
[epoch10, step622]: loss 19.646734
[epoch10, step623]: loss 1.022736
[epoch10, step624]: loss 14.242570
[epoch10, step625]: loss 2.667851
[epoch10, step626]: loss 4.217479
[epoch10, step627]: loss 9.932405
[epoch10, step628]: loss 7.157826
[epoch10, step629]: loss 2.752503
[epoch10, step630]: loss 9.607524
[epoch10, step631]: loss 6.092960
[epoch10, step632]: loss 5.146153
[epoch10, step633]: loss 1.754970
[epoch10, step634]: loss 5.090715
[epoch10, step635]: loss 2.248214
[epoch10, step636]: loss 1.398841
[epoch10, step637]: loss 1.832036
[epoch10, step638]: loss 1.280538
[epoch10, step639]: loss 14.778666
[epoch10, step640]: loss 0.987213
[epoch10, step641]: loss 13.691377
[epoch10, step642]: loss 32.241066
[epoch10, step643]: loss 4.786563
[epoch10, step644]: loss 6.444283
[epoch10, step645]: loss 1.902494
[epoch10, step646]: loss 2.726830
[epoch10, step647]: loss 6.236380
[epoch10, step648]: loss 2.524810
[epoch10, step649]: loss 1.520100
[epoch10, step650]: loss 6.209701
[epoch10, step651]: loss 23.486387
[epoch10, step652]: loss 1.405717
[epoch10, step653]: loss 5.846701
[epoch10, step654]: loss 3.509202
[epoch10, step655]: loss 1.481836
[epoch10, step656]: loss 1.588867
[epoch10, step657]: loss 3.284408
[epoch10, step658]: loss 1.833982
[epoch10, step659]: loss 23.621887
[epoch10, step660]: loss 19.999899
[epoch10, step661]: loss 16.142794
[epoch10, step662]: loss 5.520463
[epoch10, step663]: loss 14.215410
[epoch10, step664]: loss 15.074968
[epoch10, step665]: loss 33.581333
[epoch10, step666]: loss 2.712106
[epoch10, step667]: loss 2.435287
[epoch10, step668]: loss 2.911396
[epoch10, step669]: loss 1.150993
[epoch10, step670]: loss 1.803767
[epoch10, step671]: loss 1.212181
[epoch10, step672]: loss 6.596216
[epoch10, step673]: loss 2.296442
[epoch10, step674]: loss 12.232608
[epoch10, step675]: loss 1.931324
[epoch10, step676]: loss 10.985462
[epoch10, step677]: loss 0.932165
[epoch10, step678]: loss 2.722834
[epoch10, step679]: loss 1.600859
[epoch10, step680]: loss 10.804821
[epoch10, step681]: loss 9.491442
[epoch10, step682]: loss 1.926488
[epoch10, step683]: loss 5.640040
[epoch10, step684]: loss 13.750377
[epoch10, step685]: loss 4.784533
[epoch10, step686]: loss 9.987266
[epoch10, step687]: loss 2.304135
[epoch10, step688]: loss 1.236007
[epoch10, step689]: loss 2.823720
[epoch10, step690]: loss 9.257710
[epoch10, step691]: loss 11.331326
[epoch10, step692]: loss 6.242108
[epoch10, step693]: loss 17.644117
[epoch10, step694]: loss 7.530138
[epoch10, step695]: loss 6.367700
[epoch10, step696]: loss 11.535968
[epoch10, step697]: loss 2.740385
[epoch10, step698]: loss 7.070605
[epoch10, step699]: loss 5.066947
[epoch10, step700]: loss 0.982886
[epoch10, step701]: loss 1.956108
[epoch10, step702]: loss 1.920266
[epoch10, step703]: loss 5.306071
[epoch10, step704]: loss 3.483404
[epoch10, step705]: loss 1.740890
[epoch10, step706]: loss 1.027531
[epoch10, step707]: loss 14.898594
[epoch10, step708]: loss 5.216511
[epoch10, step709]: loss 12.933722
[epoch10, step710]: loss 3.201434
[epoch10, step711]: loss 20.635923
[epoch10, step712]: loss 1.783179
[epoch10, step713]: loss 4.687078
[epoch10, step714]: loss 18.701746
[epoch10, step715]: loss 1.158372
[epoch10, step716]: loss 1.332198
[epoch10, step717]: loss 3.920917
[epoch10, step718]: loss 1.849559
[epoch10, step719]: loss 7.765972
[epoch10, step720]: loss 5.762810
[epoch10, step721]: loss 3.356948
[epoch10, step722]: loss 1.884636
[epoch10, step723]: loss 1.895448
[epoch10, step724]: loss 15.121248
[epoch10, step725]: loss 5.209263
[epoch10, step726]: loss 1.097150
[epoch10, step727]: loss 1.533189
[epoch10, step728]: loss 3.312539
[epoch10, step729]: loss 1.654301
[epoch10, step730]: loss 16.582111
[epoch10, step731]: loss 11.099737
[epoch10, step732]: loss 1.938486
[epoch10, step733]: loss 5.332123
[epoch10, step734]: loss 2.546641
[epoch10, step735]: loss 1.868770
[epoch10, step736]: loss 3.293931
[epoch10, step737]: loss 4.031677
[epoch10, step738]: loss 3.913266
[epoch10, step739]: loss 1.286731
[epoch10, step740]: loss 2.394279
[epoch10, step741]: loss 19.829168
[epoch10, step742]: loss 16.460711
[epoch10, step743]: loss 4.298642
[epoch10, step744]: loss 1.401921
[epoch10, step745]: loss 2.029551
[epoch10, step746]: loss 1.406169
[epoch10, step747]: loss 3.842270
[epoch10, step748]: loss 2.060016
[epoch10, step749]: loss 2.759378
[epoch10, step750]: loss 4.876127
[epoch10, step751]: loss 1.999752
[epoch10, step752]: loss 1.218307
[epoch10, step753]: loss 1.440166
[epoch10, step754]: loss 9.996916
[epoch10, step755]: loss 18.333393
[epoch10, step756]: loss 1.958757
[epoch10, step757]: loss 6.752692
[epoch10, step758]: loss 1.817109
[epoch10, step759]: loss 11.211255
[epoch10, step760]: loss 4.799591
[epoch10, step761]: loss 11.518252
[epoch10, step762]: loss 2.532800
[epoch10, step763]: loss 4.421244
[epoch10, step764]: loss 8.717550
[epoch10, step765]: loss 2.378815
[epoch10, step766]: loss 2.654340
[epoch10, step767]: loss 1.025238
[epoch10, step768]: loss 2.656749
[epoch10, step769]: loss 6.984981
[epoch10, step770]: loss 2.116025
[epoch10, step771]: loss 1.062410
[epoch10, step772]: loss 2.972289
[epoch10, step773]: loss 3.168913
[epoch10, step774]: loss 1.553200
[epoch10, step775]: loss 1.283172
[epoch10, step776]: loss 1.608593
[epoch10, step777]: loss 2.083704
[epoch10, step778]: loss 4.323292
[epoch10, step779]: loss 8.775008
[epoch10, step780]: loss 2.004936
[epoch10, step781]: loss 1.082680
[epoch10, step782]: loss 1.018599
[epoch10, step783]: loss 0.742885
[epoch10, step784]: loss 1.617595
[epoch10, step785]: loss 1.896547
[epoch10, step786]: loss 1.494496
[epoch10, step787]: loss 3.070684
[epoch10, step788]: loss 3.933790
[epoch10, step789]: loss 4.365020
[epoch10, step790]: loss 2.098879
[epoch10, step791]: loss 2.893361
[epoch10, step792]: loss 16.718657
[epoch10, step793]: loss 5.266129
[epoch10, step794]: loss 1.578707
[epoch10, step795]: loss 11.610859
[epoch10, step796]: loss 16.605034
[epoch10, step797]: loss 2.688454
[epoch10, step798]: loss 1.595308
[epoch10, step799]: loss 1.395590
[epoch10, step800]: loss 2.396783
[epoch10, step801]: loss 19.015734
[epoch10, step802]: loss 6.453943
[epoch10, step803]: loss 11.649239
[epoch10, step804]: loss 1.293179
[epoch10, step805]: loss 21.284821
[epoch10, step806]: loss 33.495003
[epoch10, step807]: loss 1.607790
[epoch10, step808]: loss 5.715456
[epoch10, step809]: loss 3.781568
[epoch10, step810]: loss 3.465638
[epoch10, step811]: loss 6.724829
[epoch10, step812]: loss 14.754204
[epoch10, step813]: loss 1.184842
[epoch10, step814]: loss 1.314749
[epoch10, step815]: loss 11.276177
[epoch10, step816]: loss 1.661691
[epoch10, step817]: loss 3.620184
[epoch10, step818]: loss 4.633235
[epoch10, step819]: loss 2.406317
[epoch10, step820]: loss 3.771359
[epoch10, step821]: loss 42.170101
[epoch10, step822]: loss 1.732626
[epoch10, step823]: loss 1.129375
[epoch10, step824]: loss 1.250573
[epoch10, step825]: loss 11.911119
[epoch10, step826]: loss 43.904858
[epoch10, step827]: loss 5.462470
[epoch10, step828]: loss 7.614629
[epoch10, step829]: loss 11.551282
[epoch10, step830]: loss 1.474170
[epoch10, step831]: loss 11.196380
[epoch10, step832]: loss 13.221280
[epoch10, step833]: loss 1.159498
[epoch10, step834]: loss 1.026858
[epoch10, step835]: loss 1.201065
[epoch10, step836]: loss 3.396267
[epoch10, step837]: loss 1.902511
[epoch10, step838]: loss 7.647721
[epoch10, step839]: loss 12.251757
[epoch10, step840]: loss 11.646761
[epoch10, step841]: loss 2.223576
[epoch10, step842]: loss 28.553728
[epoch10, step843]: loss 3.204727
[epoch10, step844]: loss 3.092918
[epoch10, step845]: loss 7.302000
[epoch10, step846]: loss 12.665359
[epoch10, step847]: loss 2.276597
[epoch10, step848]: loss 1.429906
[epoch10, step849]: loss 3.512051
[epoch10, step850]: loss 10.848570
[epoch10, step851]: loss 2.335017
[epoch10, step852]: loss 3.035973
[epoch10, step853]: loss 4.927057
[epoch10, step854]: loss 1.754499
[epoch10, step855]: loss 15.804706
[epoch10, step856]: loss 1.694351
[epoch10, step857]: loss 9.125971
[epoch10, step858]: loss 2.163287
[epoch10, step859]: loss 1.467499
[epoch10, step860]: loss 2.703474
[epoch10, step861]: loss 3.205798
[epoch10, step862]: loss 4.182217
[epoch10, step863]: loss 3.939190
[epoch10, step864]: loss 16.451590
[epoch10, step865]: loss 25.490894
[epoch10, step866]: loss 15.696775
[epoch10, step867]: loss 2.005028
[epoch10, step868]: loss 7.650224
[epoch10, step869]: loss 5.718502
[epoch10, step870]: loss 1.115412
[epoch10, step871]: loss 4.968518
[epoch10, step872]: loss 1.331691
[epoch10, step873]: loss 2.920657
[epoch10, step874]: loss 2.026136
[epoch10, step875]: loss 20.862545
[epoch10, step876]: loss 24.045763
[epoch10, step877]: loss 13.314826
[epoch10, step878]: loss 1.816255
[epoch10, step879]: loss 1.258699
[epoch10, step880]: loss 1.226275
[epoch10, step881]: loss 6.609805
[epoch10, step882]: loss 7.085275
[epoch10, step883]: loss 29.531956
[epoch10, step884]: loss 4.097301
[epoch10, step885]: loss 3.271535
[epoch10, step886]: loss 1.472263
[epoch10, step887]: loss 5.975707
[epoch10, step888]: loss 15.682819
[epoch10, step889]: loss 5.053143
[epoch10, step890]: loss 3.556941
[epoch10, step891]: loss 3.384155
[epoch10, step892]: loss 1.258571
[epoch10, step893]: loss 15.879158
[epoch10, step894]: loss 1.733659
[epoch10, step895]: loss 2.743974
[epoch10, step896]: loss 1.893832
[epoch10, step897]: loss 11.136209
[epoch10, step898]: loss 2.058292
[epoch10, step899]: loss 17.154503
[epoch10, step900]: loss 1.469486
[epoch10, step901]: loss 6.511068
[epoch10, step902]: loss 14.816017
[epoch10, step903]: loss 1.896888
[epoch10, step904]: loss 1.082676
[epoch10, step905]: loss 13.359527
[epoch10, step906]: loss 1.464355
[epoch10, step907]: loss 4.026769
[epoch10, step908]: loss 4.255946
[epoch10, step909]: loss 2.061512
[epoch10, step910]: loss 15.615489
[epoch10, step911]: loss 32.725983
[epoch10, step912]: loss 1.472013
[epoch10, step913]: loss 2.861929
[epoch10, step914]: loss 2.624541
[epoch10, step915]: loss 22.116695
[epoch10, step916]: loss 1.371375
[epoch10, step917]: loss 15.273559
[epoch10, step918]: loss 10.550040
[epoch10, step919]: loss 1.535368
[epoch10, step920]: loss 2.647598
[epoch10, step921]: loss 15.002979
[epoch10, step922]: loss 1.367325
[epoch10, step923]: loss 2.467343
[epoch10, step924]: loss 16.922770
[epoch10, step925]: loss 14.352907
[epoch10, step926]: loss 3.531406
[epoch10, step927]: loss 15.188516
[epoch10, step928]: loss 20.856136
[epoch10, step929]: loss 1.569695
[epoch10, step930]: loss 1.278558
[epoch10, step931]: loss 1.712535
[epoch10, step932]: loss 31.506186
[epoch10, step933]: loss 3.344549
[epoch10, step934]: loss 3.443472
[epoch10, step935]: loss 14.171786
[epoch10, step936]: loss 5.405176
[epoch10, step937]: loss 4.230605
[epoch10, step938]: loss 3.691852
[epoch10, step939]: loss 3.550099
[epoch10, step940]: loss 1.669885
[epoch10, step941]: loss 24.848570
[epoch10, step942]: loss 1.285258
[epoch10, step943]: loss 9.982560
[epoch10, step944]: loss 0.648455
[epoch10, step945]: loss 1.365683
[epoch10, step946]: loss 2.558539
[epoch10, step947]: loss 20.787663
[epoch10, step948]: loss 1.814216
[epoch10, step949]: loss 1.054667
[epoch10, step950]: loss 12.156619
[epoch10, step951]: loss 0.822503
[epoch10, step952]: loss 3.832107
[epoch10, step953]: loss 4.083271
[epoch10, step954]: loss 1.757934
[epoch10, step955]: loss 1.264866
[epoch10, step956]: loss 1.115944
[epoch10, step957]: loss 1.438137
[epoch10, step958]: loss 8.675020
[epoch10, step959]: loss 1.112868
[epoch10, step960]: loss 40.520004
[epoch10, step961]: loss 0.903480
[epoch10, step962]: loss 28.885683
[epoch10, step963]: loss 1.253852
[epoch10, step964]: loss 1.568773
[epoch10, step965]: loss 13.528995
[epoch10, step966]: loss 13.375912
[epoch10, step967]: loss 18.104143
[epoch10, step968]: loss 2.964623
[epoch10, step969]: loss 1.335840
[epoch10, step970]: loss 1.469585
[epoch10, step971]: loss 13.326530
[epoch10, step972]: loss 2.690526
[epoch10, step973]: loss 1.476260
[epoch10, step974]: loss 3.716448
[epoch10, step975]: loss 2.006683
[epoch10, step976]: loss 4.034056
[epoch10, step977]: loss 10.501352
[epoch10, step978]: loss 2.479255
[epoch10, step979]: loss 1.604607
[epoch10, step980]: loss 3.935993
[epoch10, step981]: loss 1.163793
[epoch10, step982]: loss 4.052484
[epoch10, step983]: loss 1.320050
[epoch10, step984]: loss 20.296574
[epoch10, step985]: loss 0.979284
[epoch10, step986]: loss 12.447936
[epoch10, step987]: loss 1.567929
[epoch10, step988]: loss 2.510409
[epoch10, step989]: loss 3.045011
[epoch10, step990]: loss 3.245130
[epoch10, step991]: loss 6.634337
[epoch10, step992]: loss 12.058440
[epoch10, step993]: loss 27.173420
[epoch10, step994]: loss 1.037517
[epoch10, step995]: loss 1.485715
[epoch10, step996]: loss 2.743636
[epoch10, step997]: loss 3.669005
[epoch10, step998]: loss 21.878477
[epoch10, step999]: loss 14.398643
[epoch10, step1000]: loss 2.419925
[epoch10, step1001]: loss 1.318443
[epoch10, step1002]: loss 2.855922
[epoch10, step1003]: loss 2.461523
[epoch10, step1004]: loss 13.752464
[epoch10, step1005]: loss 3.500831
[epoch10, step1006]: loss 11.579254
[epoch10, step1007]: loss 1.134341
[epoch10, step1008]: loss 2.515816
[epoch10, step1009]: loss 19.533329
[epoch10, step1010]: loss 2.054021
[epoch10, step1011]: loss 0.784448
[epoch10, step1012]: loss 20.210299
[epoch10, step1013]: loss 4.914417
[epoch10, step1014]: loss 14.491875
[epoch10, step1015]: loss 1.535392
[epoch10, step1016]: loss 2.885096
[epoch10, step1017]: loss 3.151158
[epoch10, step1018]: loss 15.423201
[epoch10, step1019]: loss 4.446354
[epoch10, step1020]: loss 4.235787
[epoch10, step1021]: loss 1.291692
[epoch10, step1022]: loss 6.705650
[epoch10, step1023]: loss 10.351157
[epoch10, step1024]: loss 10.240557
[epoch10, step1025]: loss 2.005387
[epoch10, step1026]: loss 1.419678
[epoch10, step1027]: loss 3.540397
[epoch10, step1028]: loss 12.821969
[epoch10, step1029]: loss 2.070804
[epoch10, step1030]: loss 15.431610
[epoch10, step1031]: loss 13.340639
[epoch10, step1032]: loss 1.833169
[epoch10, step1033]: loss 1.241037
[epoch10, step1034]: loss 2.266232
[epoch10, step1035]: loss 6.558227
[epoch10, step1036]: loss 1.693848
[epoch10, step1037]: loss 4.601559
[epoch10, step1038]: loss 15.001040
[epoch10, step1039]: loss 1.972525
[epoch10, step1040]: loss 4.158513
[epoch10, step1041]: loss 3.278525
[epoch10, step1042]: loss 1.831679
[epoch10, step1043]: loss 4.101852
[epoch10, step1044]: loss 1.582177
[epoch10, step1045]: loss 1.516176
[epoch10, step1046]: loss 2.668810
[epoch10, step1047]: loss 0.906838
[epoch10, step1048]: loss 1.022259
[epoch10, step1049]: loss 1.939163
[epoch10, step1050]: loss 2.494840
[epoch10, step1051]: loss 4.661140
[epoch10, step1052]: loss 3.083626
[epoch10, step1053]: loss 0.884905
[epoch10, step1054]: loss 1.535776
[epoch10, step1055]: loss 3.810549
[epoch10, step1056]: loss 10.781394
[epoch10, step1057]: loss 1.895080
[epoch10, step1058]: loss 2.868173
[epoch10, step1059]: loss 1.408671
[epoch10, step1060]: loss 14.529894
[epoch10, step1061]: loss 29.894903
[epoch10, step1062]: loss 6.089116
[epoch10, step1063]: loss 5.607993
[epoch10, step1064]: loss 1.553872
[epoch10, step1065]: loss 1.568102
[epoch10, step1066]: loss 11.829546
[epoch10, step1067]: loss 2.208019
[epoch10, step1068]: loss 3.200437
[epoch10, step1069]: loss 1.159932
[epoch10, step1070]: loss 13.838698
[epoch10, step1071]: loss 1.330092
[epoch10, step1072]: loss 11.990404
[epoch10, step1073]: loss 1.872990
[epoch10, step1074]: loss 1.002974
[epoch10, step1075]: loss 13.386238
[epoch10, step1076]: loss 25.723610
[epoch10, step1077]: loss 2.608433
[epoch10, step1078]: loss 2.159184
[epoch10, step1079]: loss 1.782473
[epoch10, step1080]: loss 9.663495
[epoch10, step1081]: loss 4.972727
[epoch10, step1082]: loss 7.610280
[epoch10, step1083]: loss 3.311353
[epoch10, step1084]: loss 1.737975
[epoch10, step1085]: loss 2.006448
[epoch10, step1086]: loss 21.054585
[epoch10, step1087]: loss 1.726809
[epoch10, step1088]: loss 3.910554
[epoch10, step1089]: loss 3.877458
[epoch10, step1090]: loss 0.949829
[epoch10, step1091]: loss 1.790362
[epoch10, step1092]: loss 2.003994
[epoch10, step1093]: loss 1.811747
[epoch10, step1094]: loss 2.165794
[epoch10, step1095]: loss 2.506295
[epoch10, step1096]: loss 15.639450
[epoch10, step1097]: loss 1.420444
[epoch10, step1098]: loss 13.284739
[epoch10, step1099]: loss 18.849613
[epoch10, step1100]: loss 22.065346
[epoch10, step1101]: loss 2.046090
[epoch10, step1102]: loss 4.738121
[epoch10, step1103]: loss 1.630817
[epoch10, step1104]: loss 2.340039
[epoch10, step1105]: loss 1.185990
[epoch10, step1106]: loss 2.313672
[epoch10, step1107]: loss 2.032627
[epoch10, step1108]: loss 14.907911
[epoch10, step1109]: loss 4.488846
[epoch10, step1110]: loss 1.973354
[epoch10, step1111]: loss 3.353389
[epoch10, step1112]: loss 6.057323
[epoch10, step1113]: loss 1.124366
[epoch10, step1114]: loss 1.262583
[epoch10, step1115]: loss 1.100375
[epoch10, step1116]: loss 14.279655
[epoch10, step1117]: loss 13.286281
[epoch10, step1118]: loss 1.842788
[epoch10, step1119]: loss 1.124271
[epoch10, step1120]: loss 4.169215
[epoch10, step1121]: loss 1.520553
[epoch10, step1122]: loss 29.018827
[epoch10, step1123]: loss 3.554332
[epoch10, step1124]: loss 0.661069
[epoch10, step1125]: loss 1.109162
[epoch10, step1126]: loss 1.693136
[epoch10, step1127]: loss 1.736642
[epoch10, step1128]: loss 6.767311
[epoch10, step1129]: loss 7.501137
[epoch10, step1130]: loss 1.586618
[epoch10, step1131]: loss 0.947994
[epoch10, step1132]: loss 15.504270
[epoch10, step1133]: loss 0.776857
[epoch10, step1134]: loss 1.361137
[epoch10, step1135]: loss 9.729845
[epoch10, step1136]: loss 3.371572
[epoch10, step1137]: loss 25.000376
[epoch10, step1138]: loss 2.129809
[epoch10, step1139]: loss 1.345936
[epoch10, step1140]: loss 2.516445
[epoch10, step1141]: loss 4.191225
[epoch10, step1142]: loss 1.907270
[epoch10, step1143]: loss 1.371952
[epoch10, step1144]: loss 1.247956
[epoch10, step1145]: loss 1.003995
[epoch10, step1146]: loss 2.649422
[epoch10, step1147]: loss 1.213220
[epoch10, step1148]: loss 1.441785
[epoch10, step1149]: loss 2.709278
[epoch10, step1150]: loss 0.861469
[epoch10, step1151]: loss 2.547198
[epoch10, step1152]: loss 2.336539
[epoch10, step1153]: loss 23.590637
[epoch10, step1154]: loss 0.812673
[epoch10, step1155]: loss 1.962397
[epoch10, step1156]: loss 1.400015
[epoch10, step1157]: loss 20.066311
[epoch10, step1158]: loss 1.355583
[epoch10, step1159]: loss 29.151493
[epoch10, step1160]: loss 1.229383
[epoch10, step1161]: loss 3.985328
[epoch10, step1162]: loss 21.477083
[epoch10, step1163]: loss 2.548462
[epoch10, step1164]: loss 11.988520
[epoch10, step1165]: loss 2.749490
[epoch10, step1166]: loss 15.238689
[epoch10, step1167]: loss 20.167875
[epoch10, step1168]: loss 5.392003
[epoch10, step1169]: loss 14.144770
[epoch10, step1170]: loss 3.084764
[epoch10, step1171]: loss 2.378633
[epoch10, step1172]: loss 13.190725
[epoch10, step1173]: loss 3.305697
[epoch10, step1174]: loss 2.862434
[epoch10, step1175]: loss 6.660001
[epoch10, step1176]: loss 18.946049
[epoch10, step1177]: loss 1.425156
[epoch10, step1178]: loss 2.289920
[epoch10, step1179]: loss 12.596589
[epoch10, step1180]: loss 0.999589
[epoch10, step1181]: loss 1.712158
[epoch10, step1182]: loss 3.314083
[epoch10, step1183]: loss 3.484201
[epoch10, step1184]: loss 1.944221
[epoch10, step1185]: loss 2.338264
[epoch10, step1186]: loss 8.782812
[epoch10, step1187]: loss 3.285826
[epoch10, step1188]: loss 21.546774
[epoch10, step1189]: loss 1.393378
[epoch10, step1190]: loss 1.014203
[epoch10, step1191]: loss 11.322307
[epoch10, step1192]: loss 2.533429
[epoch10, step1193]: loss 1.534505
[epoch10, step1194]: loss 8.186077
[epoch10, step1195]: loss 3.551597
[epoch10, step1196]: loss 2.442517
[epoch10, step1197]: loss 1.284099
[epoch10, step1198]: loss 2.358644
[epoch10, step1199]: loss 5.425948
[epoch10, step1200]: loss 13.321926
[epoch10, step1201]: loss 52.154133
[epoch10, step1202]: loss 2.344630
[epoch10, step1203]: loss 3.003541
[epoch10, step1204]: loss 0.815442
[epoch10, step1205]: loss 16.114317
[epoch10, step1206]: loss 1.778602
[epoch10, step1207]: loss 4.270727
[epoch10, step1208]: loss 1.866650
[epoch10, step1209]: loss 3.626076
[epoch10, step1210]: loss 2.702708
[epoch10, step1211]: loss 12.736313
[epoch10, step1212]: loss 1.772690
[epoch10, step1213]: loss 15.491176
[epoch10, step1214]: loss 1.604681
[epoch10, step1215]: loss 3.028078
[epoch10, step1216]: loss 2.143887
[epoch10, step1217]: loss 1.935586
[epoch10, step1218]: loss 1.001029
[epoch10, step1219]: loss 1.632211
[epoch10, step1220]: loss 1.393798
[epoch10, step1221]: loss 3.372254
[epoch10, step1222]: loss 2.016931
[epoch10, step1223]: loss 15.985125
[epoch10, step1224]: loss 6.075767
[epoch10, step1225]: loss 4.990037
[epoch10, step1226]: loss 2.758220
[epoch10, step1227]: loss 7.564219
[epoch10, step1228]: loss 2.427075
[epoch10, step1229]: loss 3.435162
[epoch10, step1230]: loss 21.522835
[epoch10, step1231]: loss 1.673059
[epoch10, step1232]: loss 2.694257
[epoch10, step1233]: loss 11.113292
[epoch10, step1234]: loss 14.947544
[epoch10, step1235]: loss 1.846525
[epoch10, step1236]: loss 15.461716
[epoch10, step1237]: loss 21.475929
[epoch10, step1238]: loss 49.212112
[epoch10, step1239]: loss 14.881547
[epoch10, step1240]: loss 12.989249
[epoch10, step1241]: loss 14.005273
[epoch10, step1242]: loss 14.137935
[epoch10, step1243]: loss 2.988241
[epoch10, step1244]: loss 1.813984
[epoch10, step1245]: loss 0.976460
[epoch10, step1246]: loss 3.268238
[epoch10, step1247]: loss 1.017234
[epoch10, step1248]: loss 19.837261
[epoch10, step1249]: loss 10.202028
[epoch10, step1250]: loss 2.884147
[epoch10, step1251]: loss 10.920460
[epoch10, step1252]: loss 5.674401
[epoch10, step1253]: loss 6.057986
[epoch10, step1254]: loss 2.441959
[epoch10, step1255]: loss 1.210314
[epoch10, step1256]: loss 23.992622
[epoch10, step1257]: loss 8.104891
[epoch10, step1258]: loss 1.500913
[epoch10, step1259]: loss 0.770936
[epoch10, step1260]: loss 20.870636
[epoch10, step1261]: loss 32.133522
[epoch10, step1262]: loss 11.055512
[epoch10, step1263]: loss 2.750680
[epoch10, step1264]: loss 3.539861
[epoch10, step1265]: loss 2.115267
[epoch10, step1266]: loss 13.263281
[epoch10, step1267]: loss 1.828560
[epoch10, step1268]: loss 2.481144
[epoch10, step1269]: loss 4.163888
[epoch10, step1270]: loss 0.990435
[epoch10, step1271]: loss 1.124361
[epoch10, step1272]: loss 1.256618
[epoch10, step1273]: loss 14.749384
[epoch10, step1274]: loss 1.190122
[epoch10, step1275]: loss 2.617364
[epoch10, step1276]: loss 3.271640
[epoch10, step1277]: loss 15.750999
[epoch10, step1278]: loss 1.916661
[epoch10, step1279]: loss 1.096674
[epoch10, step1280]: loss 1.703467
[epoch10, step1281]: loss 23.081205
[epoch10, step1282]: loss 2.231912
[epoch10, step1283]: loss 1.691342
[epoch10, step1284]: loss 2.169723
[epoch10, step1285]: loss 6.851793
[epoch10, step1286]: loss 3.163257
[epoch10, step1287]: loss 15.809934
[epoch10, step1288]: loss 2.959251
[epoch10, step1289]: loss 2.549911
[epoch10, step1290]: loss 10.048968
[epoch10, step1291]: loss 1.570486
[epoch10, step1292]: loss 9.719845
[epoch10, step1293]: loss 2.882426
[epoch10, step1294]: loss 11.358687
[epoch10, step1295]: loss 1.944021
[epoch10, step1296]: loss 5.640108
[epoch10, step1297]: loss 2.005445
[epoch10, step1298]: loss 1.560227
[epoch10, step1299]: loss 1.291598
[epoch10, step1300]: loss 12.842972
[epoch10, step1301]: loss 1.505933
[epoch10, step1302]: loss 25.481464
[epoch10, step1303]: loss 4.271128
[epoch10, step1304]: loss 19.130096
[epoch10, step1305]: loss 2.281837
[epoch10, step1306]: loss 8.486444
[epoch10, step1307]: loss 30.869905
[epoch10, step1308]: loss 1.557791
[epoch10, step1309]: loss 3.631655
[epoch10, step1310]: loss 17.563881
[epoch10, step1311]: loss 14.931307
[epoch10, step1312]: loss 1.405302
[epoch10, step1313]: loss 3.079050
[epoch10, step1314]: loss 0.693522
[epoch10, step1315]: loss 1.801999
[epoch10, step1316]: loss 2.395497
[epoch10, step1317]: loss 4.152431
[epoch10, step1318]: loss 0.817746
[epoch10, step1319]: loss 12.737989
[epoch10, step1320]: loss 1.824929
[epoch10, step1321]: loss 7.377296
[epoch10, step1322]: loss 3.227234
[epoch10, step1323]: loss 5.806830
[epoch10, step1324]: loss 1.442063
[epoch10, step1325]: loss 2.335216
[epoch10, step1326]: loss 1.405646
[epoch10, step1327]: loss 4.154610
[epoch10, step1328]: loss 12.126873
[epoch10, step1329]: loss 2.128817
[epoch10, step1330]: loss 1.699995
[epoch10, step1331]: loss 3.811455
[epoch10, step1332]: loss 1.432380
[epoch10, step1333]: loss 8.835206
[epoch10, step1334]: loss 22.954365
[epoch10, step1335]: loss 7.275467
[epoch10, step1336]: loss 1.599024
[epoch10, step1337]: loss 13.682930
[epoch10, step1338]: loss 3.566030
[epoch10, step1339]: loss 2.239441
[epoch10, step1340]: loss 2.176170
[epoch10, step1341]: loss 7.512570
[epoch10, step1342]: loss 3.667860
[epoch10, step1343]: loss 13.736673
[epoch10, step1344]: loss 2.714238
[epoch10, step1345]: loss 0.709639
[epoch10, step1346]: loss 1.012654
[epoch10, step1347]: loss 2.843057
[epoch10, step1348]: loss 12.050651
[epoch10, step1349]: loss 16.263216
[epoch10, step1350]: loss 7.593595
[epoch10, step1351]: loss 9.686296
[epoch10, step1352]: loss 3.542525
[epoch10, step1353]: loss 2.169416
[epoch10, step1354]: loss 1.561076
[epoch10, step1355]: loss 1.915809
[epoch10, step1356]: loss 1.682633
[epoch10, step1357]: loss 16.017496
[epoch10, step1358]: loss 20.888693
[epoch10, step1359]: loss 2.510536
[epoch10, step1360]: loss 1.781070
[epoch10, step1361]: loss 1.307924
[epoch10, step1362]: loss 2.227211
[epoch10, step1363]: loss 1.596702
[epoch10, step1364]: loss 2.048848
[epoch10, step1365]: loss 21.162979
[epoch10, step1366]: loss 12.828199
[epoch10, step1367]: loss 13.796601
[epoch10, step1368]: loss 0.866636
[epoch10, step1369]: loss 3.423114
[epoch10, step1370]: loss 3.234853
[epoch10, step1371]: loss 15.043390
[epoch10, step1372]: loss 1.216060
[epoch10, step1373]: loss 1.342300
[epoch10, step1374]: loss 1.623112
[epoch10, step1375]: loss 1.566323
[epoch10, step1376]: loss 1.996953
[epoch10, step1377]: loss 1.263287
[epoch10, step1378]: loss 0.854974
[epoch10, step1379]: loss 1.048678
[epoch10, step1380]: loss 1.281659
[epoch10, step1381]: loss 2.568643
[epoch10, step1382]: loss 1.467148
[epoch10, step1383]: loss 2.855209
[epoch10, step1384]: loss 2.333148
[epoch10, step1385]: loss 2.617066
[epoch10, step1386]: loss 6.697750
[epoch10, step1387]: loss 7.423764
[epoch10, step1388]: loss 1.422413
[epoch10, step1389]: loss 27.205919
[epoch10, step1390]: loss 12.097267
[epoch10, step1391]: loss 1.594700
[epoch10, step1392]: loss 2.271207
[epoch10, step1393]: loss 2.262577
[epoch10, step1394]: loss 1.809799
[epoch10, step1395]: loss 1.618508
[epoch10, step1396]: loss 2.372972
[epoch10, step1397]: loss 0.894128
[epoch10, step1398]: loss 5.859426
[epoch10, step1399]: loss 6.293060
[epoch10, step1400]: loss 1.828766
[epoch10, step1401]: loss 13.117614
[epoch10, step1402]: loss 15.943646
[epoch10, step1403]: loss 1.661842
[epoch10, step1404]: loss 1.182758
[epoch10, step1405]: loss 1.448046
[epoch10, step1406]: loss 14.174010
[epoch10, step1407]: loss 2.463413
[epoch10, step1408]: loss 1.694922
[epoch10, step1409]: loss 13.093321
[epoch10, step1410]: loss 1.849527
[epoch10, step1411]: loss 4.489963
[epoch10, step1412]: loss 0.847560
[epoch10, step1413]: loss 5.064622
[epoch10, step1414]: loss 1.600201
[epoch10, step1415]: loss 1.027191
[epoch10, step1416]: loss 8.073881
[epoch10, step1417]: loss 3.591034
[epoch10, step1418]: loss 6.335939
[epoch10, step1419]: loss 1.659554
[epoch10, step1420]: loss 34.447292
[epoch10, step1421]: loss 3.076602
[epoch10, step1422]: loss 1.056140
[epoch10, step1423]: loss 9.380547
[epoch10, step1424]: loss 5.353885
[epoch10, step1425]: loss 32.903492
[epoch10, step1426]: loss 1.195884
[epoch10, step1427]: loss 1.694369
[epoch10, step1428]: loss 8.346349
[epoch10, step1429]: loss 1.198104
[epoch10, step1430]: loss 2.327703
[epoch10, step1431]: loss 1.702518
[epoch10, step1432]: loss 0.755539
[epoch10, step1433]: loss 14.965811
[epoch10, step1434]: loss 20.167118
[epoch10, step1435]: loss 1.084271
[epoch10, step1436]: loss 2.478261
[epoch10, step1437]: loss 3.410308
[epoch10, step1438]: loss 3.664548
[epoch10, step1439]: loss 2.706852
[epoch10, step1440]: loss 3.410212
[epoch10, step1441]: loss 1.654880
[epoch10, step1442]: loss 12.283655
[epoch10, step1443]: loss 21.582109
[epoch10, step1444]: loss 5.407771
[epoch10, step1445]: loss 1.080263
[epoch10, step1446]: loss 1.489244
[epoch10, step1447]: loss 1.011058
[epoch10, step1448]: loss 3.347141
[epoch10, step1449]: loss 1.016676
[epoch10, step1450]: loss 2.686511
[epoch10, step1451]: loss 5.019948
[epoch10, step1452]: loss 0.977679
[epoch10, step1453]: loss 2.080400
[epoch10, step1454]: loss 3.794048
[epoch10, step1455]: loss 2.329620
[epoch10, step1456]: loss 6.363468
[epoch10, step1457]: loss 3.929099
[epoch10, step1458]: loss 2.194910
[epoch10, step1459]: loss 2.001847
[epoch10, step1460]: loss 26.855644
[epoch10, step1461]: loss 1.861247
[epoch10, step1462]: loss 15.369526
[epoch10, step1463]: loss 2.944873
[epoch10, step1464]: loss 1.023688
[epoch10, step1465]: loss 1.861583
[epoch10, step1466]: loss 1.947142
[epoch10, step1467]: loss 3.551910
[epoch10, step1468]: loss 1.638833
[epoch10, step1469]: loss 1.506261
[epoch10, step1470]: loss 1.283467
[epoch10, step1471]: loss 19.578665
[epoch10, step1472]: loss 14.515048
[epoch10, step1473]: loss 11.063531
[epoch10, step1474]: loss 5.111517
[epoch10, step1475]: loss 14.643995
[epoch10, step1476]: loss 30.441898
[epoch10, step1477]: loss 4.421794
[epoch10, step1478]: loss 2.259675
[epoch10, step1479]: loss 1.627635
[epoch10, step1480]: loss 1.680064
[epoch10, step1481]: loss 5.865210
[epoch10, step1482]: loss 0.882858
[epoch10, step1483]: loss 0.935284
[epoch10, step1484]: loss 7.283698
[epoch10, step1485]: loss 6.223614
[epoch10, step1486]: loss 1.585307
[epoch10, step1487]: loss 1.560702
[epoch10, step1488]: loss 1.754858
[epoch10, step1489]: loss 0.816302
[epoch10, step1490]: loss 3.332350
[epoch10, step1491]: loss 1.221802
[epoch10, step1492]: loss 1.003664
[epoch10, step1493]: loss 4.393972
[epoch10, step1494]: loss 5.663561
[epoch10, step1495]: loss 11.912237
[epoch10, step1496]: loss 20.054790
[epoch10, step1497]: loss 6.176959
[epoch10, step1498]: loss 2.223776
[epoch10, step1499]: loss 1.082932
[epoch10, step1500]: loss 3.585745
[epoch10, step1501]: loss 14.229911
[epoch10, step1502]: loss 1.349049
[epoch10, step1503]: loss 2.419590
[epoch10, step1504]: loss 2.347980
[epoch10, step1505]: loss 3.189355
[epoch10, step1506]: loss 1.863983
[epoch10, step1507]: loss 1.365379
[epoch10, step1508]: loss 27.060440
[epoch10, step1509]: loss 15.693653
[epoch10, step1510]: loss 4.998466
[epoch10, step1511]: loss 4.744071
[epoch10, step1512]: loss 20.274284
[epoch10, step1513]: loss 1.312019
[epoch10, step1514]: loss 4.428108
[epoch10, step1515]: loss 3.090642
[epoch10, step1516]: loss 1.110611
[epoch10, step1517]: loss 1.138099
[epoch10, step1518]: loss 7.837729
[epoch10, step1519]: loss 1.748587
[epoch10, step1520]: loss 0.789811
[epoch10, step1521]: loss 7.202353
[epoch10, step1522]: loss 3.667278
[epoch10, step1523]: loss 2.797977
[epoch10, step1524]: loss 1.586639
[epoch10, step1525]: loss 8.725348
[epoch10, step1526]: loss 2.531700
[epoch10, step1527]: loss 2.606092
[epoch10, step1528]: loss 13.818214
[epoch10, step1529]: loss 17.947086
[epoch10, step1530]: loss 13.003059
[epoch10, step1531]: loss 1.949781
[epoch10, step1532]: loss 2.537307
[epoch10, step1533]: loss 2.563686
[epoch10, step1534]: loss 2.068064
[epoch10, step1535]: loss 3.566845
[epoch10, step1536]: loss 3.712795
[epoch10, step1537]: loss 2.408954
[epoch10, step1538]: loss 1.224589
[epoch10, step1539]: loss 1.827570
[epoch10, step1540]: loss 2.704159
[epoch10, step1541]: loss 16.003181
[epoch10, step1542]: loss 24.166862
[epoch10, step1543]: loss 14.784110
[epoch10, step1544]: loss 11.759207
[epoch10, step1545]: loss 16.697729
[epoch10, step1546]: loss 16.066751
[epoch10, step1547]: loss 13.168649
[epoch10, step1548]: loss 1.580058
[epoch10, step1549]: loss 6.957207
[epoch10, step1550]: loss 1.746160
[epoch10, step1551]: loss 1.150169
[epoch10, step1552]: loss 11.727173
[epoch10, step1553]: loss 1.375586
[epoch10, step1554]: loss 2.517834
[epoch10, step1555]: loss 3.715396
[epoch10, step1556]: loss 1.235346
[epoch10, step1557]: loss 5.528658
[epoch10, step1558]: loss 13.022064
[epoch10, step1559]: loss 20.495005
[epoch10, step1560]: loss 1.632668
[epoch10, step1561]: loss 1.521200
[epoch10, step1562]: loss 1.140173
[epoch10, step1563]: loss 2.288546
[epoch10, step1564]: loss 1.759900
[epoch10, step1565]: loss 2.200944
[epoch10, step1566]: loss 15.701045
[epoch10, step1567]: loss 17.258059
[epoch10, step1568]: loss 1.007021
[epoch10, step1569]: loss 15.478601
[epoch10, step1570]: loss 1.290012
[epoch10, step1571]: loss 1.494918
[epoch10, step1572]: loss 19.260151
[epoch10, step1573]: loss 3.363718
[epoch10, step1574]: loss 12.542796
[epoch10, step1575]: loss 5.011291
[epoch10, step1576]: loss 2.716978
[epoch10, step1577]: loss 6.364061
[epoch10, step1578]: loss 4.507280
[epoch10, step1579]: loss 3.957579
[epoch10, step1580]: loss 2.920807
[epoch10, step1581]: loss 1.553380
[epoch10, step1582]: loss 1.426107
[epoch10, step1583]: loss 24.100941
[epoch10, step1584]: loss 6.537819
[epoch10, step1585]: loss 1.563805
[epoch10, step1586]: loss 1.707790
[epoch10, step1587]: loss 1.928470
[epoch10, step1588]: loss 14.264975
[epoch10, step1589]: loss 3.002080
[epoch10, step1590]: loss 0.971035
[epoch10, step1591]: loss 1.201525
[epoch10, step1592]: loss 1.727773
[epoch10, step1593]: loss 2.896489
[epoch10, step1594]: loss 9.737154
[epoch10, step1595]: loss 1.335852
[epoch10, step1596]: loss 2.948793
[epoch10, step1597]: loss 2.417984
[epoch10, step1598]: loss 1.267852
[epoch10, step1599]: loss 2.202970
[epoch10, step1600]: loss 15.034001
[epoch10, step1601]: loss 4.302367
[epoch10, step1602]: loss 1.474508
[epoch10, step1603]: loss 1.093158
[epoch10, step1604]: loss 4.183522
[epoch10, step1605]: loss 1.182099
[epoch10, step1606]: loss 16.955692
[epoch10, step1607]: loss 3.578060
[epoch10, step1608]: loss 2.565631
[epoch10, step1609]: loss 13.756340
[epoch10, step1610]: loss 17.171427
[epoch10, step1611]: loss 1.231015
[epoch10, step1612]: loss 3.151945
[epoch10, step1613]: loss 4.382602
[epoch10, step1614]: loss 14.476728
[epoch10, step1615]: loss 2.217117
[epoch10, step1616]: loss 0.725509
[epoch10, step1617]: loss 4.347213
[epoch10, step1618]: loss 1.658344
[epoch10, step1619]: loss 1.624705
[epoch10, step1620]: loss 11.558549
[epoch10, step1621]: loss 1.592149
[epoch10, step1622]: loss 16.170635
[epoch10, step1623]: loss 5.023603
[epoch10, step1624]: loss 1.405162
[epoch10, step1625]: loss 1.570087
[epoch10, step1626]: loss 3.953730
[epoch10, step1627]: loss 0.991883
[epoch10, step1628]: loss 5.131032
[epoch10, step1629]: loss 5.199970
[epoch10, step1630]: loss 2.124221
[epoch10, step1631]: loss 3.164776
[epoch10, step1632]: loss 2.473496
[epoch10, step1633]: loss 2.079168
[epoch10, step1634]: loss 1.475311
[epoch10, step1635]: loss 1.787874
[epoch10, step1636]: loss 2.416513
[epoch10, step1637]: loss 1.204011
[epoch10, step1638]: loss 2.278280
[epoch10, step1639]: loss 2.461545
[epoch10, step1640]: loss 7.235000
[epoch10, step1641]: loss 18.135984
[epoch10, step1642]: loss 1.609034
[epoch10, step1643]: loss 13.484873
[epoch10, step1644]: loss 2.386755
[epoch10, step1645]: loss 6.700082
[epoch10, step1646]: loss 2.609857
[epoch10, step1647]: loss 7.048812
[epoch10, step1648]: loss 1.772155
[epoch10, step1649]: loss 4.035797
[epoch10, step1650]: loss 5.414881
[epoch10, step1651]: loss 6.786088
[epoch10, step1652]: loss 1.555274
[epoch10, step1653]: loss 2.058357
[epoch10, step1654]: loss 4.079782
[epoch10, step1655]: loss 2.305460
[epoch10, step1656]: loss 1.192705
[epoch10, step1657]: loss 1.446888
[epoch10, step1658]: loss 1.373840
[epoch10, step1659]: loss 4.987690
[epoch10, step1660]: loss 15.130347
[epoch10, step1661]: loss 1.487476
[epoch10, step1662]: loss 3.630952
[epoch10, step1663]: loss 4.214692
[epoch10, step1664]: loss 19.404539
[epoch10, step1665]: loss 16.283159
[epoch10, step1666]: loss 1.276427
[epoch10, step1667]: loss 1.154913
[epoch10, step1668]: loss 11.380816
[epoch10, step1669]: loss 17.655714
[epoch10, step1670]: loss 2.273667
[epoch10, step1671]: loss 1.443699
[epoch10, step1672]: loss 15.975852
[epoch10, step1673]: loss 12.425136
[epoch10, step1674]: loss 2.220780
[epoch10, step1675]: loss 1.181137
[epoch10, step1676]: loss 8.960937
[epoch10, step1677]: loss 2.523689
[epoch10, step1678]: loss 3.310804
[epoch10, step1679]: loss 2.986919
[epoch10, step1680]: loss 1.669501
[epoch10, step1681]: loss 1.955123
[epoch10, step1682]: loss 1.379728
[epoch10, step1683]: loss 10.054609
[epoch10, step1684]: loss 13.662666
[epoch10, step1685]: loss 1.395590
[epoch10, step1686]: loss 2.138550
[epoch10, step1687]: loss 3.275826
[epoch10, step1688]: loss 1.293890
[epoch10, step1689]: loss 10.793059
[epoch10, step1690]: loss 1.761715
[epoch10, step1691]: loss 1.259276
[epoch10, step1692]: loss 2.442563
[epoch10, step1693]: loss 2.176664
[epoch10, step1694]: loss 19.889534
[epoch10, step1695]: loss 12.815088
[epoch10, step1696]: loss 7.022929
[epoch10, step1697]: loss 5.161187
[epoch10, step1698]: loss 4.925364
[epoch10, step1699]: loss 3.550232
[epoch10, step1700]: loss 3.563252
[epoch10, step1701]: loss 1.613755
[epoch10, step1702]: loss 2.659025
[epoch10, step1703]: loss 5.588135
[epoch10, step1704]: loss 31.456724
[epoch10, step1705]: loss 25.736296
[epoch10, step1706]: loss 2.033429
[epoch10, step1707]: loss 2.691571
[epoch10, step1708]: loss 10.748318
[epoch10, step1709]: loss 1.386815
[epoch10, step1710]: loss 4.177955
[epoch10, step1711]: loss 7.775381
[epoch10, step1712]: loss 3.432949
[epoch10, step1713]: loss 1.612899
[epoch10, step1714]: loss 14.000776
[epoch10, step1715]: loss 1.409892
[epoch10, step1716]: loss 3.816234
[epoch10, step1717]: loss 3.774406
[epoch10, step1718]: loss 1.843518
[epoch10, step1719]: loss 2.461853
[epoch10, step1720]: loss 1.244455
[epoch10, step1721]: loss 1.869705
[epoch10, step1722]: loss 3.832265
[epoch10, step1723]: loss 2.688316
[epoch10, step1724]: loss 1.452849
[epoch10, step1725]: loss 13.953270
[epoch10, step1726]: loss 1.442902
[epoch10, step1727]: loss 1.604186
[epoch10, step1728]: loss 1.261502
[epoch10, step1729]: loss 1.614122
[epoch10, step1730]: loss 15.567756
[epoch10, step1731]: loss 13.154756
[epoch10, step1732]: loss 20.770477
[epoch10, step1733]: loss 3.106480
[epoch10, step1734]: loss 1.460819
[epoch10, step1735]: loss 3.361166
[epoch10, step1736]: loss 9.409985
[epoch10, step1737]: loss 1.206526
[epoch10, step1738]: loss 2.320982
[epoch10, step1739]: loss 2.871527
[epoch10, step1740]: loss 16.282879
[epoch10, step1741]: loss 1.886612
[epoch10, step1742]: loss 1.208663
[epoch10, step1743]: loss 1.055265
[epoch10, step1744]: loss 14.400715
[epoch10, step1745]: loss 2.634721
[epoch10, step1746]: loss 1.516024
[epoch10, step1747]: loss 1.530415
[epoch10, step1748]: loss 3.260594
[epoch10, step1749]: loss 4.837471
[epoch10, step1750]: loss 2.842258
[epoch10, step1751]: loss 12.988605
[epoch10, step1752]: loss 1.874525
[epoch10, step1753]: loss 2.113390
[epoch10, step1754]: loss 12.454924
[epoch10, step1755]: loss 4.923170
[epoch10, step1756]: loss 1.941809
[epoch10, step1757]: loss 1.676836
[epoch10, step1758]: loss 4.345749
[epoch10, step1759]: loss 15.347078
[epoch10, step1760]: loss 1.214353
[epoch10, step1761]: loss 0.912950
[epoch10, step1762]: loss 2.702783
[epoch10, step1763]: loss 1.968610
[epoch10, step1764]: loss 2.924489
[epoch10, step1765]: loss 2.163635
[epoch10, step1766]: loss 1.376699
[epoch10, step1767]: loss 1.548727
[epoch10, step1768]: loss 1.602387
[epoch10, step1769]: loss 4.059410
[epoch10, step1770]: loss 1.415217
[epoch10, step1771]: loss 1.713774
[epoch10, step1772]: loss 2.442667
[epoch10, step1773]: loss 2.825494
[epoch10, step1774]: loss 19.838121
[epoch10, step1775]: loss 0.977488
[epoch10, step1776]: loss 3.054309
[epoch10, step1777]: loss 2.417813
[epoch10, step1778]: loss 2.872250
[epoch10, step1779]: loss 1.097088
[epoch10, step1780]: loss 3.010324
[epoch10, step1781]: loss 6.843698
[epoch10, step1782]: loss 4.759476
[epoch10, step1783]: loss 1.165581
[epoch10, step1784]: loss 2.322608
[epoch10, step1785]: loss 13.670799
[epoch10, step1786]: loss 1.131904
[epoch10, step1787]: loss 1.359027
[epoch10, step1788]: loss 2.519135
[epoch10, step1789]: loss 7.541587
[epoch10, step1790]: loss 2.080171
[epoch10, step1791]: loss 1.564394
[epoch10, step1792]: loss 4.337756
[epoch10, step1793]: loss 21.735336
[epoch10, step1794]: loss 0.804841
[epoch10, step1795]: loss 24.586676
[epoch10, step1796]: loss 11.836452
[epoch10, step1797]: loss 19.226482
[epoch10, step1798]: loss 16.053961
[epoch10, step1799]: loss 2.100569
[epoch10, step1800]: loss 1.310133
[epoch10, step1801]: loss 4.167169
[epoch10, step1802]: loss 1.270602
[epoch10, step1803]: loss 15.923462
[epoch10, step1804]: loss 1.100980
[epoch10, step1805]: loss 5.305849
[epoch10, step1806]: loss 1.369010
[epoch10, step1807]: loss 2.365989
[epoch10, step1808]: loss 1.843323
[epoch10, step1809]: loss 2.925713
[epoch10, step1810]: loss 2.066563
[epoch10, step1811]: loss 27.242550
[epoch10, step1812]: loss 3.553198
[epoch10, step1813]: loss 29.755980
[epoch10, step1814]: loss 5.545525
[epoch10, step1815]: loss 1.640417
[epoch10, step1816]: loss 12.181481
[epoch10, step1817]: loss 1.280842
[epoch10, step1818]: loss 15.621741
[epoch10, step1819]: loss 1.980900
[epoch10, step1820]: loss 8.042200
[epoch10, step1821]: loss 3.374041
[epoch10, step1822]: loss 4.559357
[epoch10, step1823]: loss 11.031441
[epoch10, step1824]: loss 1.784760
[epoch10, step1825]: loss 2.137231
[epoch10, step1826]: loss 1.230910
[epoch10, step1827]: loss 2.181564
[epoch10, step1828]: loss 1.560735
[epoch10, step1829]: loss 1.776891
[epoch10, step1830]: loss 3.927685
[epoch10, step1831]: loss 1.839186
[epoch10, step1832]: loss 2.319506
[epoch10, step1833]: loss 12.541272
[epoch10, step1834]: loss 14.902349
[epoch10, step1835]: loss 2.518699
[epoch10, step1836]: loss 1.259449
[epoch10, step1837]: loss 1.038282
[epoch10, step1838]: loss 1.301519
[epoch10, step1839]: loss 1.661405
[epoch10, step1840]: loss 26.667900
[epoch10, step1841]: loss 11.021735
[epoch10, step1842]: loss 1.385681
[epoch10, step1843]: loss 18.059755
[epoch10, step1844]: loss 3.686965
[epoch10, step1845]: loss 3.338872
[epoch10, step1846]: loss 1.323838
[epoch10, step1847]: loss 2.140051
[epoch10, step1848]: loss 2.914768
[epoch10, step1849]: loss 6.154494
[epoch10, step1850]: loss 2.396759
[epoch10, step1851]: loss 1.494476
[epoch10, step1852]: loss 4.195324
[epoch10, step1853]: loss 35.529995
[epoch10, step1854]: loss 1.933435
[epoch10, step1855]: loss 9.035864
[epoch10, step1856]: loss 11.789771
[epoch10, step1857]: loss 2.762705
[epoch10, step1858]: loss 5.374108
[epoch10, step1859]: loss 1.889355
[epoch10, step1860]: loss 4.308401
[epoch10, step1861]: loss 20.848177
[epoch10, step1862]: loss 1.308886
[epoch10, step1863]: loss 2.012508
[epoch10, step1864]: loss 0.945529
[epoch10, step1865]: loss 6.473603
[epoch10, step1866]: loss 1.406115
[epoch10, step1867]: loss 1.227618
[epoch10, step1868]: loss 1.675016
[epoch10, step1869]: loss 2.926862
[epoch10, step1870]: loss 1.584088
[epoch10, step1871]: loss 1.604204
[epoch10, step1872]: loss 15.224971
[epoch10, step1873]: loss 3.011794
[epoch10, step1874]: loss 1.368629
[epoch10, step1875]: loss 13.412067
[epoch10, step1876]: loss 2.324277
[epoch10, step1877]: loss 11.637758
[epoch10, step1878]: loss 5.558973
[epoch10, step1879]: loss 19.678810
[epoch10, step1880]: loss 3.455935
[epoch10, step1881]: loss 2.886554
[epoch10, step1882]: loss 5.136951
[epoch10, step1883]: loss 9.445761
[epoch10, step1884]: loss 1.209321
[epoch10, step1885]: loss 12.329531
[epoch10, step1886]: loss 1.477513
[epoch10, step1887]: loss 13.257718
[epoch10, step1888]: loss 0.928729
[epoch10, step1889]: loss 2.803463
[epoch10, step1890]: loss 2.910428
[epoch10, step1891]: loss 2.047881
[epoch10, step1892]: loss 31.545898
[epoch10, step1893]: loss 1.837657
[epoch10, step1894]: loss 1.678904
[epoch10, step1895]: loss 12.418643
[epoch10, step1896]: loss 1.863611
[epoch10, step1897]: loss 14.545216
[epoch10, step1898]: loss 20.912201
[epoch10, step1899]: loss 1.570345
[epoch10, step1900]: loss 1.167143
[epoch10, step1901]: loss 3.523435
[epoch10, step1902]: loss 1.411288
[epoch10, step1903]: loss 2.772975
[epoch10, step1904]: loss 2.236305
[epoch10, step1905]: loss 1.226853
[epoch10, step1906]: loss 6.414458
[epoch10, step1907]: loss 3.005623
[epoch10, step1908]: loss 2.294422
[epoch10, step1909]: loss 3.262640
[epoch10, step1910]: loss 4.201148
[epoch10, step1911]: loss 12.112381
[epoch10, step1912]: loss 12.154394
[epoch10, step1913]: loss 2.592995
[epoch10, step1914]: loss 11.569424
[epoch10, step1915]: loss 5.031616
[epoch10, step1916]: loss 2.679513
[epoch10, step1917]: loss 1.643779
[epoch10, step1918]: loss 4.642560
[epoch10, step1919]: loss 10.866398
[epoch10, step1920]: loss 1.312223
[epoch10, step1921]: loss 1.065128
[epoch10, step1922]: loss 2.609188
[epoch10, step1923]: loss 1.374372
[epoch10, step1924]: loss 1.651646
[epoch10, step1925]: loss 3.977510
[epoch10, step1926]: loss 1.784589
[epoch10, step1927]: loss 0.675584
[epoch10, step1928]: loss 1.766009
[epoch10, step1929]: loss 1.135606
[epoch10, step1930]: loss 1.254176
[epoch10, step1931]: loss 29.473869
[epoch10, step1932]: loss 8.201852
[epoch10, step1933]: loss 4.484762
[epoch10, step1934]: loss 8.446926
[epoch10, step1935]: loss 15.760391
[epoch10, step1936]: loss 0.768540
[epoch10, step1937]: loss 6.494597
[epoch10, step1938]: loss 2.754616
[epoch10, step1939]: loss 13.283710
[epoch10, step1940]: loss 7.702400
[epoch10, step1941]: loss 3.260608
[epoch10, step1942]: loss 4.207888
[epoch10, step1943]: loss 17.376286
[epoch10, step1944]: loss 0.937494
[epoch10, step1945]: loss 19.548450
[epoch10, step1946]: loss 1.684755
[epoch10, step1947]: loss 14.153256
[epoch10, step1948]: loss 13.619076
[epoch10, step1949]: loss 4.458629
[epoch10, step1950]: loss 1.118148
[epoch10, step1951]: loss 2.412373
[epoch10, step1952]: loss 14.693761
[epoch10, step1953]: loss 1.394795
[epoch10, step1954]: loss 1.746964
[epoch10, step1955]: loss 6.781845
[epoch10, step1956]: loss 2.550977
[epoch10, step1957]: loss 1.198139
[epoch10, step1958]: loss 5.372338
[epoch10, step1959]: loss 26.161816
[epoch10, step1960]: loss 31.031183
[epoch10, step1961]: loss 4.245824
[epoch10, step1962]: loss 14.736561
[epoch10, step1963]: loss 4.803854
[epoch10, step1964]: loss 17.721718
[epoch10, step1965]: loss 0.749943
[epoch10, step1966]: loss 3.038618
[epoch10, step1967]: loss 3.037773
[epoch10, step1968]: loss 9.025782
[epoch10, step1969]: loss 14.544640
[epoch10, step1970]: loss 20.171968
[epoch10, step1971]: loss 1.176424
[epoch10, step1972]: loss 26.679947
[epoch10, step1973]: loss 1.330079
[epoch10, step1974]: loss 1.281733
[epoch10, step1975]: loss 3.848772
[epoch10, step1976]: loss 3.708120
[epoch10, step1977]: loss 7.318324
[epoch10, step1978]: loss 7.230193
[epoch10, step1979]: loss 20.063267
[epoch10, step1980]: loss 1.576644
[epoch10, step1981]: loss 1.770084
[epoch10, step1982]: loss 36.483978
[epoch10, step1983]: loss 13.247400
[epoch10, step1984]: loss 1.449641
[epoch10, step1985]: loss 1.614483
[epoch10, step1986]: loss 3.708861
[epoch10, step1987]: loss 5.170947
[epoch10, step1988]: loss 11.129905
[epoch10, step1989]: loss 14.367165
[epoch10, step1990]: loss 2.587948
[epoch10, step1991]: loss 4.498672
[epoch10, step1992]: loss 0.881106
[epoch10, step1993]: loss 21.103949
[epoch10, step1994]: loss 2.616287
[epoch10, step1995]: loss 4.164109
[epoch10, step1996]: loss 1.868402
[epoch10, step1997]: loss 38.348202
[epoch10, step1998]: loss 6.885598
[epoch10, step1999]: loss 4.377686
[epoch10, step2000]: loss 0.874786
[epoch10, step2001]: loss 2.916252
[epoch10, step2002]: loss 3.174634
[epoch10, step2003]: loss 27.046526
[epoch10, step2004]: loss 5.028982
[epoch10, step2005]: loss 3.804379
[epoch10, step2006]: loss 4.014502
[epoch10, step2007]: loss 1.550185
[epoch10, step2008]: loss 1.522924
[epoch10, step2009]: loss 7.915066
[epoch10, step2010]: loss 22.186646
[epoch10, step2011]: loss 2.585274
[epoch10, step2012]: loss 5.224977
[epoch10, step2013]: loss 4.133806
[epoch10, step2014]: loss 1.740184
[epoch10, step2015]: loss 3.194535
[epoch10, step2016]: loss 13.746788
[epoch10, step2017]: loss 1.989596
[epoch10, step2018]: loss 1.085117
[epoch10, step2019]: loss 19.410057
[epoch10, step2020]: loss 6.104486
[epoch10, step2021]: loss 5.368604
[epoch10, step2022]: loss 4.700785
[epoch10, step2023]: loss 2.456692
[epoch10, step2024]: loss 1.987187
[epoch10, step2025]: loss 7.555888
[epoch10, step2026]: loss 1.886485
[epoch10, step2027]: loss 13.640890
[epoch10, step2028]: loss 6.367089
[epoch10, step2029]: loss 1.618761
[epoch10, step2030]: loss 1.419140
[epoch10, step2031]: loss 8.479421
[epoch10, step2032]: loss 13.789215
[epoch10, step2033]: loss 0.901063
[epoch10, step2034]: loss 1.829929
[epoch10, step2035]: loss 3.909220
[epoch10, step2036]: loss 12.061196
[epoch10, step2037]: loss 1.470071
[epoch10, step2038]: loss 2.898272
[epoch10, step2039]: loss 2.331650
[epoch10, step2040]: loss 1.146976
[epoch10, step2041]: loss 2.088893
[epoch10, step2042]: loss 1.508932
[epoch10, step2043]: loss 1.507919
[epoch10, step2044]: loss 10.077536
[epoch10, step2045]: loss 1.883603
[epoch10, step2046]: loss 32.992882
[epoch10, step2047]: loss 6.456996
[epoch10, step2048]: loss 3.005168
[epoch10, step2049]: loss 39.390057
[epoch10, step2050]: loss 2.980521
[epoch10, step2051]: loss 2.350280
[epoch10, step2052]: loss 4.366353
[epoch10, step2053]: loss 2.794636
[epoch10, step2054]: loss 4.684525
[epoch10, step2055]: loss 4.023442
[epoch10, step2056]: loss 4.123239
[epoch10, step2057]: loss 3.055125
[epoch10, step2058]: loss 1.377896
[epoch10, step2059]: loss 13.378319
[epoch10, step2060]: loss 0.951505
[epoch10, step2061]: loss 19.639675
[epoch10, step2062]: loss 1.497044
[epoch10, step2063]: loss 2.630893
[epoch10, step2064]: loss 1.706249
[epoch10, step2065]: loss 3.817865
[epoch10, step2066]: loss 2.781703
[epoch10, step2067]: loss 2.473752
[epoch10, step2068]: loss 2.677712
[epoch10, step2069]: loss 2.722662
[epoch10, step2070]: loss 2.704417
[epoch10, step2071]: loss 12.731761
[epoch10, step2072]: loss 1.644458
[epoch10, step2073]: loss 15.727276
[epoch10, step2074]: loss 5.690131
[epoch10, step2075]: loss 2.015106
[epoch10, step2076]: loss 2.346816
[epoch10, step2077]: loss 4.557199
[epoch10, step2078]: loss 1.516243
[epoch10, step2079]: loss 2.329729
[epoch10, step2080]: loss 3.147645
[epoch10, step2081]: loss 1.634704
[epoch10, step2082]: loss 4.182428
[epoch10, step2083]: loss 22.167973
[epoch10, step2084]: loss 8.891687
[epoch10, step2085]: loss 3.495863
[epoch10, step2086]: loss 6.611721
[epoch10, step2087]: loss 2.650166
[epoch10, step2088]: loss 2.548240
[epoch10, step2089]: loss 1.187234
[epoch10, step2090]: loss 12.261202
[epoch10, step2091]: loss 2.388602
[epoch10, step2092]: loss 1.178722
[epoch10, step2093]: loss 11.409901
[epoch10, step2094]: loss 4.572989
[epoch10, step2095]: loss 4.967428
[epoch10, step2096]: loss 44.522499
[epoch10, step2097]: loss 15.200739
[epoch10, step2098]: loss 1.439489
[epoch10, step2099]: loss 2.651086
[epoch10, step2100]: loss 3.703838
[epoch10, step2101]: loss 3.491938
[epoch10, step2102]: loss 1.531920
[epoch10, step2103]: loss 10.620624
[epoch10, step2104]: loss 3.147483
[epoch10, step2105]: loss 2.147274
[epoch10, step2106]: loss 14.994190
[epoch10, step2107]: loss 1.039688
[epoch10, step2108]: loss 5.589467
[epoch10, step2109]: loss 1.228664
[epoch10, step2110]: loss 1.170402
[epoch10, step2111]: loss 1.212794
[epoch10, step2112]: loss 2.608588
[epoch10, step2113]: loss 13.653002
[epoch10, step2114]: loss 19.710180
[epoch10, step2115]: loss 6.845987
[epoch10, step2116]: loss 3.934970
[epoch10, step2117]: loss 1.978538
[epoch10, step2118]: loss 1.449313
[epoch10, step2119]: loss 6.032128
[epoch10, step2120]: loss 1.003708
[epoch10, step2121]: loss 4.602345
[epoch10, step2122]: loss 10.636063
[epoch10, step2123]: loss 1.905606
[epoch10, step2124]: loss 2.446367
[epoch10, step2125]: loss 11.861896
[epoch10, step2126]: loss 1.404012
[epoch10, step2127]: loss 2.356578
[epoch10, step2128]: loss 13.968735
[epoch10, step2129]: loss 1.679147
[epoch10, step2130]: loss 5.982557
[epoch10, step2131]: loss 1.917222
[epoch10, step2132]: loss 20.110567
[epoch10, step2133]: loss 13.888564
[epoch10, step2134]: loss 20.426468
[epoch10, step2135]: loss 2.091139
[epoch10, step2136]: loss 13.630095
[epoch10, step2137]: loss 3.062890
[epoch10, step2138]: loss 4.221285
[epoch10, step2139]: loss 12.233264
[epoch10, step2140]: loss 0.825735
[epoch10, step2141]: loss 39.298431
[epoch10, step2142]: loss 4.071119
[epoch10, step2143]: loss 2.210414
[epoch10, step2144]: loss 1.586284
[epoch10, step2145]: loss 3.906640
[epoch10, step2146]: loss 12.228102
[epoch10, step2147]: loss 10.836847
[epoch10, step2148]: loss 3.401130
[epoch10, step2149]: loss 1.192956
[epoch10, step2150]: loss 5.910641
[epoch10, step2151]: loss 13.135854
[epoch10, step2152]: loss 7.045836
[epoch10, step2153]: loss 2.707769
[epoch10, step2154]: loss 1.119390
[epoch10, step2155]: loss 0.928774
[epoch10, step2156]: loss 2.070147
[epoch10, step2157]: loss 4.027170
[epoch10, step2158]: loss 1.214123
[epoch10, step2159]: loss 0.928903
[epoch10, step2160]: loss 2.246617
[epoch10, step2161]: loss 1.069259
[epoch10, step2162]: loss 14.835211
[epoch10, step2163]: loss 1.287578
[epoch10, step2164]: loss 1.236672
[epoch10, step2165]: loss 2.634527
[epoch10, step2166]: loss 0.928707
[epoch10, step2167]: loss 14.551642
[epoch10, step2168]: loss 3.099567
[epoch10, step2169]: loss 4.054094
[epoch10, step2170]: loss 2.765973
[epoch10, step2171]: loss 14.038153
[epoch10, step2172]: loss 1.164287
[epoch10, step2173]: loss 4.665597
[epoch10, step2174]: loss 1.754466
[epoch10, step2175]: loss 1.463573
[epoch10, step2176]: loss 1.469751
[epoch10, step2177]: loss 3.969790
[epoch10, step2178]: loss 1.819003
[epoch10, step2179]: loss 2.963325
[epoch10, step2180]: loss 14.250267
[epoch10, step2181]: loss 0.941390
[epoch10, step2182]: loss 13.001972
[epoch10, step2183]: loss 1.500673
[epoch10, step2184]: loss 1.768048
[epoch10, step2185]: loss 11.078502
[epoch10, step2186]: loss 1.519467
[epoch10, step2187]: loss 4.412589
[epoch10, step2188]: loss 2.598722
[epoch10, step2189]: loss 3.996271
[epoch10, step2190]: loss 0.663494
[epoch10, step2191]: loss 1.693394
[epoch10, step2192]: loss 11.474227
[epoch10, step2193]: loss 1.366114
[epoch10, step2194]: loss 10.077278
[epoch10, step2195]: loss 15.763109
[epoch10, step2196]: loss 2.012455
[epoch10, step2197]: loss 13.979347
[epoch10, step2198]: loss 1.340247
[epoch10, step2199]: loss 1.011955
[epoch10, step2200]: loss 1.432596
[epoch10, step2201]: loss 1.981079
[epoch10, step2202]: loss 10.417087
[epoch10, step2203]: loss 2.345650
[epoch10, step2204]: loss 19.025354
[epoch10, step2205]: loss 2.912302
[epoch10, step2206]: loss 2.031009
[epoch10, step2207]: loss 16.124456
[epoch10, step2208]: loss 1.629025
[epoch10, step2209]: loss 1.896903
[epoch10, step2210]: loss 1.866833
[epoch10, step2211]: loss 4.099230
[epoch10, step2212]: loss 3.719345
[epoch10, step2213]: loss 0.806969
[epoch10, step2214]: loss 2.509068
[epoch10, step2215]: loss 1.751022
[epoch10, step2216]: loss 1.123835
[epoch10, step2217]: loss 1.468623
[epoch10, step2218]: loss 28.110897
[epoch10, step2219]: loss 18.641157
[epoch10, step2220]: loss 2.075149
[epoch10, step2221]: loss 2.622736
[epoch10, step2222]: loss 1.015077
[epoch10, step2223]: loss 3.117172
[epoch10, step2224]: loss 1.768680
[epoch10, step2225]: loss 4.266896
[epoch10, step2226]: loss 1.291298
[epoch10, step2227]: loss 2.383729
[epoch10, step2228]: loss 15.995744
[epoch10, step2229]: loss 12.094127
[epoch10, step2230]: loss 1.995926
[epoch10, step2231]: loss 15.933887
[epoch10, step2232]: loss 3.972734
[epoch10, step2233]: loss 3.444986
[epoch10, step2234]: loss 16.874264
[epoch10, step2235]: loss 4.292462
[epoch10, step2236]: loss 24.530651
[epoch10, step2237]: loss 1.509921
[epoch10, step2238]: loss 13.682153
[epoch10, step2239]: loss 3.876335
[epoch10, step2240]: loss 0.641116
[epoch10, step2241]: loss 2.120058
[epoch10, step2242]: loss 14.967539
[epoch10, step2243]: loss 1.405688
[epoch10, step2244]: loss 1.031108
[epoch10, step2245]: loss 11.697987
[epoch10, step2246]: loss 9.337063
[epoch10, step2247]: loss 17.600189
[epoch10, step2248]: loss 17.772928
[epoch10, step2249]: loss 4.896734
[epoch10, step2250]: loss 3.834399
[epoch10, step2251]: loss 2.137117
[epoch10, step2252]: loss 2.039076
[epoch10, step2253]: loss 1.290968
[epoch10, step2254]: loss 11.130379
[epoch10, step2255]: loss 1.926882
[epoch10, step2256]: loss 17.355366
[epoch10, step2257]: loss 3.229187
[epoch10, step2258]: loss 4.834075
[epoch10, step2259]: loss 0.815876
[epoch10, step2260]: loss 5.478451
[epoch10, step2261]: loss 6.554414
[epoch10, step2262]: loss 2.497879
[epoch10, step2263]: loss 1.569065
[epoch10, step2264]: loss 19.613447
[epoch10, step2265]: loss 1.229623
[epoch10, step2266]: loss 1.888473
[epoch10, step2267]: loss 8.429830
[epoch10, step2268]: loss 3.375266
[epoch10, step2269]: loss 15.111973
[epoch10, step2270]: loss 12.764181
[epoch10, step2271]: loss 1.158737
[epoch10, step2272]: loss 1.467268
[epoch10, step2273]: loss 2.858108
[epoch10, step2274]: loss 10.107956
[epoch10, step2275]: loss 2.668618
[epoch10, step2276]: loss 1.047664
[epoch10, step2277]: loss 1.790869
[epoch10, step2278]: loss 2.333634
[epoch10, step2279]: loss 4.405494
[epoch10, step2280]: loss 3.608099
[epoch10, step2281]: loss 1.035761
[epoch10, step2282]: loss 2.403862
[epoch10, step2283]: loss 5.730377
[epoch10, step2284]: loss 2.550014
[epoch10, step2285]: loss 2.019288
[epoch10, step2286]: loss 2.545338
[epoch10, step2287]: loss 1.081485
[epoch10, step2288]: loss 6.822130
[epoch10, step2289]: loss 32.737156
[epoch10, step2290]: loss 3.812141
[epoch10, step2291]: loss 9.743317
[epoch10, step2292]: loss 8.854941
[epoch10, step2293]: loss 4.090632
[epoch10, step2294]: loss 2.873156
[epoch10, step2295]: loss 1.004908
[epoch10, step2296]: loss 2.414850
[epoch10, step2297]: loss 2.908500
[epoch10, step2298]: loss 1.738590
[epoch10, step2299]: loss 6.325574
[epoch10, step2300]: loss 1.581507
[epoch10, step2301]: loss 11.421028
[epoch10, step2302]: loss 10.755530
[epoch10, step2303]: loss 2.107416
[epoch10, step2304]: loss 10.364398
[epoch10, step2305]: loss 30.472107
[epoch10, step2306]: loss 3.835008
[epoch10, step2307]: loss 2.128947
[epoch10, step2308]: loss 1.166789
[epoch10, step2309]: loss 14.635643
[epoch10, step2310]: loss 1.501582
[epoch10, step2311]: loss 15.597672
[epoch10, step2312]: loss 2.588190
[epoch10, step2313]: loss 26.793989
[epoch10, step2314]: loss 1.684345
[epoch10, step2315]: loss 1.282685
[epoch10, step2316]: loss 3.173478
[epoch10, step2317]: loss 1.375770
[epoch10, step2318]: loss 2.099231
[epoch10, step2319]: loss 1.613998
[epoch10, step2320]: loss 4.429649
[epoch10, step2321]: loss 1.506124
[epoch10, step2322]: loss 1.917717
[epoch10, step2323]: loss 2.078138
[epoch10, step2324]: loss 19.004089
[epoch10, step2325]: loss 1.458828
[epoch10, step2326]: loss 0.964191
[epoch10, step2327]: loss 2.591357
[epoch10, step2328]: loss 3.608201
[epoch10, step2329]: loss 1.875558
[epoch10, step2330]: loss 6.062089
[epoch10, step2331]: loss 3.091599
[epoch10, step2332]: loss 2.472902
[epoch10, step2333]: loss 15.820075
[epoch10, step2334]: loss 1.062322
[epoch10, step2335]: loss 1.655961
[epoch10, step2336]: loss 6.234701
[epoch10, step2337]: loss 3.168143
[epoch10, step2338]: loss 0.963884
[epoch10, step2339]: loss 1.189557
[epoch10, step2340]: loss 1.278920
[epoch10, step2341]: loss 3.926558
[epoch10, step2342]: loss 1.318416
[epoch10, step2343]: loss 2.014413
[epoch10, step2344]: loss 3.541527
[epoch10, step2345]: loss 0.910659
[epoch10, step2346]: loss 4.223507
[epoch10, step2347]: loss 2.430842
[epoch10, step2348]: loss 1.411910
[epoch10, step2349]: loss 21.147230
[epoch10, step2350]: loss 2.049195
[epoch10, step2351]: loss 7.262992
[epoch10, step2352]: loss 1.979159
[epoch10, step2353]: loss 3.343524
[epoch10, step2354]: loss 11.262344
[epoch10, step2355]: loss 1.052107
[epoch10, step2356]: loss 2.439349
[epoch10, step2357]: loss 2.750475
[epoch10, step2358]: loss 7.852962
[epoch10, step2359]: loss 1.591527
[epoch10, step2360]: loss 31.613432
[epoch10, step2361]: loss 0.879904
[epoch10, step2362]: loss 9.134728
[epoch10, step2363]: loss 2.519787
[epoch10, step2364]: loss 25.380520
[epoch10, step2365]: loss 4.617259
[epoch10, step2366]: loss 1.185997
[epoch10, step2367]: loss 23.239481
[epoch10, step2368]: loss 3.808308
[epoch10, step2369]: loss 1.114627
[epoch10, step2370]: loss 12.913730
[epoch10, step2371]: loss 1.076367
[epoch10, step2372]: loss 1.134714
[epoch10, step2373]: loss 2.729415
[epoch10, step2374]: loss 10.306642
[epoch10, step2375]: loss 7.742702
[epoch10, step2376]: loss 1.153236
[epoch10, step2377]: loss 3.782734
[epoch10, step2378]: loss 2.302103
[epoch10, step2379]: loss 1.052175
[epoch10, step2380]: loss 6.072716
[epoch10, step2381]: loss 1.890232
[epoch10, step2382]: loss 20.676710
[epoch10, step2383]: loss 11.485085
[epoch10, step2384]: loss 0.904575
[epoch10, step2385]: loss 1.300983
[epoch10, step2386]: loss 4.163805
[epoch10, step2387]: loss 2.119198
[epoch10, step2388]: loss 3.159761
[epoch10, step2389]: loss 2.632685
[epoch10, step2390]: loss 9.640851
[epoch10, step2391]: loss 1.218641
[epoch10, step2392]: loss 1.309028
[epoch10, step2393]: loss 5.390949
[epoch10, step2394]: loss 5.962508
[epoch10, step2395]: loss 1.461600
[epoch10, step2396]: loss 1.417334
[epoch10, step2397]: loss 1.761218
[epoch10, step2398]: loss 8.756031
[epoch10, step2399]: loss 13.803376
[epoch10, step2400]: loss 10.636864
[epoch10, step2401]: loss 0.746984
[epoch10, step2402]: loss 2.002009
[epoch10, step2403]: loss 2.154756
[epoch10, step2404]: loss 3.706165
[epoch10, step2405]: loss 24.070728
[epoch10, step2406]: loss 1.586200
[epoch10, step2407]: loss 20.334932
[epoch10, step2408]: loss 4.106565
[epoch10, step2409]: loss 1.856706
[epoch10, step2410]: loss 2.286726
[epoch10, step2411]: loss 1.808241
[epoch10, step2412]: loss 1.505498
[epoch10, step2413]: loss 19.142540
[epoch10, step2414]: loss 1.734890
[epoch10, step2415]: loss 13.590442
[epoch10, step2416]: loss 37.991886
[epoch10, step2417]: loss 0.734781
[epoch10, step2418]: loss 11.271238
[epoch10, step2419]: loss 1.894045
[epoch10, step2420]: loss 1.756728
[epoch10, step2421]: loss 2.300534
[epoch10, step2422]: loss 2.044103
[epoch10, step2423]: loss 4.177295
[epoch10, step2424]: loss 2.278555
[epoch10, step2425]: loss 2.049658
[epoch10, step2426]: loss 1.446680
[epoch10, step2427]: loss 0.936444
[epoch10, step2428]: loss 3.016657
[epoch10, step2429]: loss 2.056361
[epoch10, step2430]: loss 3.260638
[epoch10, step2431]: loss 3.696312
[epoch10, step2432]: loss 2.410062
[epoch10, step2433]: loss 4.904632
[epoch10, step2434]: loss 1.417861
[epoch10, step2435]: loss 1.358678
[epoch10, step2436]: loss 11.197644
[epoch10, step2437]: loss 2.632967
[epoch10, step2438]: loss 5.213655
[epoch10, step2439]: loss 1.256460
[epoch10, step2440]: loss 4.026191
[epoch10, step2441]: loss 11.865224
[epoch10, step2442]: loss 0.948417
[epoch10, step2443]: loss 1.485503
[epoch10, step2444]: loss 3.213725
[epoch10, step2445]: loss 1.381572
[epoch10, step2446]: loss 1.911387
[epoch10, step2447]: loss 13.333454
[epoch10, step2448]: loss 1.216486
[epoch10, step2449]: loss 22.671865
[epoch10, step2450]: loss 1.558513
[epoch10, step2451]: loss 5.617722
[epoch10, step2452]: loss 1.359707
[epoch10, step2453]: loss 0.981595
[epoch10, step2454]: loss 2.745183
[epoch10, step2455]: loss 10.222980
[epoch10, step2456]: loss 4.786619
[epoch10, step2457]: loss 2.076732
[epoch10, step2458]: loss 5.358405
[epoch10, step2459]: loss 11.380404
[epoch10, step2460]: loss 0.917649
[epoch10, step2461]: loss 8.300936
[epoch10, step2462]: loss 1.804766
[epoch10, step2463]: loss 5.247157
[epoch10, step2464]: loss 3.091595
[epoch10, step2465]: loss 17.187794
[epoch10, step2466]: loss 1.477115
[epoch10, step2467]: loss 18.215899
[epoch10, step2468]: loss 2.619100
[epoch10, step2469]: loss 3.098681
[epoch10, step2470]: loss 3.215694
[epoch10, step2471]: loss 14.409166
[epoch10, step2472]: loss 4.089630
[epoch10, step2473]: loss 4.634999
[epoch10, step2474]: loss 0.807861
[epoch10, step2475]: loss 2.245298
[epoch10, step2476]: loss 1.334089
[epoch10, step2477]: loss 0.870497
[epoch10, step2478]: loss 10.837604
[epoch10, step2479]: loss 6.652930
[epoch10, step2480]: loss 12.601868
[epoch10, step2481]: loss 1.316566
[epoch10, step2482]: loss 11.498604
[epoch10, step2483]: loss 1.586795
[epoch10, step2484]: loss 1.800277
[epoch10, step2485]: loss 1.001078
[epoch10, step2486]: loss 4.334004
[epoch10, step2487]: loss 1.335877
[epoch10, step2488]: loss 3.217630
[epoch10, step2489]: loss 21.388788
[epoch10, step2490]: loss 3.464025
[epoch10, step2491]: loss 2.242226
[epoch10, step2492]: loss 19.611059
[epoch10, step2493]: loss 1.131883
[epoch10, step2494]: loss 9.895665
[epoch10, step2495]: loss 7.643067
[epoch10, step2496]: loss 1.509072
[epoch10, step2497]: loss 1.266423
[epoch10, step2498]: loss 14.894462
[epoch10, step2499]: loss 24.302378
[epoch10, step2500]: loss 9.985556
[epoch10, step2501]: loss 1.070235
[epoch10, step2502]: loss 1.460801
[epoch10, step2503]: loss 13.358482
[epoch10, step2504]: loss 1.804939
[epoch10, step2505]: loss 9.801488
[epoch10, step2506]: loss 1.060133
[epoch10, step2507]: loss 13.016659
[epoch10, step2508]: loss 1.136189
[epoch10, step2509]: loss 15.327105
[epoch10, step2510]: loss 9.729770
[epoch10, step2511]: loss 4.122076
[epoch10, step2512]: loss 5.358943
[epoch10, step2513]: loss 4.232020
[epoch10, step2514]: loss 29.749870
[epoch10, step2515]: loss 2.275354
[epoch10, step2516]: loss 6.374745
[epoch10, step2517]: loss 1.325083
[epoch10, step2518]: loss 2.252327
[epoch10, step2519]: loss 7.830633
[epoch10, step2520]: loss 1.280246
[epoch10, step2521]: loss 5.862339
[epoch10, step2522]: loss 1.727640
[epoch10, step2523]: loss 1.493633
[epoch10, step2524]: loss 11.172153
[epoch10, step2525]: loss 3.154614
[epoch10, step2526]: loss 0.810311
[epoch10, step2527]: loss 2.202637
[epoch10, step2528]: loss 2.075798
[epoch10, step2529]: loss 4.230486
[epoch10, step2530]: loss 25.254492
[epoch10, step2531]: loss 12.507105
[epoch10, step2532]: loss 2.204095
[epoch10, step2533]: loss 4.112621
[epoch10, step2534]: loss 10.058327
[epoch10, step2535]: loss 0.806794
[epoch10, step2536]: loss 3.294843
[epoch10, step2537]: loss 5.484977
[epoch10, step2538]: loss 1.048569
[epoch10, step2539]: loss 1.878021
[epoch10, step2540]: loss 1.044841
[epoch10, step2541]: loss 3.508348
[epoch10, step2542]: loss 1.663058
[epoch10, step2543]: loss 7.811157
[epoch10, step2544]: loss 9.769428
[epoch10, step2545]: loss 11.132608
[epoch10, step2546]: loss 3.643366
[epoch10, step2547]: loss 14.239550
[epoch10, step2548]: loss 7.607722
[epoch10, step2549]: loss 3.610769
[epoch10, step2550]: loss 3.948091
[epoch10, step2551]: loss 14.545059
[epoch10, step2552]: loss 25.911913
[epoch10, step2553]: loss 15.863132
[epoch10, step2554]: loss 1.941026
[epoch10, step2555]: loss 1.090822
[epoch10, step2556]: loss 13.759535
[epoch10, step2557]: loss 2.143815
[epoch10, step2558]: loss 2.788412
[epoch10, step2559]: loss 8.707550
[epoch10, step2560]: loss 14.083056
[epoch10, step2561]: loss 1.718959
[epoch10, step2562]: loss 5.535713
[epoch10, step2563]: loss 1.561114
[epoch10, step2564]: loss 20.766130
[epoch10, step2565]: loss 4.472360
[epoch10, step2566]: loss 12.534673
[epoch10, step2567]: loss 17.960142
[epoch10, step2568]: loss 8.249342
[epoch10, step2569]: loss 14.586092
[epoch10, step2570]: loss 2.077875
[epoch10, step2571]: loss 2.127529
[epoch10, step2572]: loss 1.760952
[epoch10, step2573]: loss 2.146238
[epoch10, step2574]: loss 1.345880
[epoch10, step2575]: loss 1.189785
[epoch10, step2576]: loss 7.372104
[epoch10, step2577]: loss 14.020981
[epoch10, step2578]: loss 5.517748
[epoch10, step2579]: loss 1.310406
[epoch10, step2580]: loss 1.847695
[epoch10, step2581]: loss 24.473888
[epoch10, step2582]: loss 1.437377
[epoch10, step2583]: loss 2.606451
[epoch10, step2584]: loss 15.101171
[epoch10, step2585]: loss 0.967291
[epoch10, step2586]: loss 11.554129
[epoch10, step2587]: loss 1.695774
[epoch10, step2588]: loss 1.209222
[epoch10, step2589]: loss 1.169336
[epoch10, step2590]: loss 6.384792
[epoch10, step2591]: loss 17.029783
[epoch10, step2592]: loss 1.287290
[epoch10, step2593]: loss 14.975328
[epoch10, step2594]: loss 1.037182
[epoch10, step2595]: loss 3.817593
[epoch10, step2596]: loss 0.815444
[epoch10, step2597]: loss 1.346959
[epoch10, step2598]: loss 2.215821
[epoch10, step2599]: loss 15.626768
[epoch10, step2600]: loss 4.233600
[epoch10, step2601]: loss 1.353857
[epoch10, step2602]: loss 3.921322
[epoch10, step2603]: loss 7.672996
[epoch10, step2604]: loss 3.786312
[epoch10, step2605]: loss 18.269156
[epoch10, step2606]: loss 7.212115
[epoch10, step2607]: loss 1.460355
[epoch10, step2608]: loss 16.352715
[epoch10, step2609]: loss 4.989646
[epoch10, step2610]: loss 3.149954
[epoch10, step2611]: loss 0.799168
[epoch10, step2612]: loss 1.434723
[epoch10, step2613]: loss 10.015376
[epoch10, step2614]: loss 2.012804
[epoch10, step2615]: loss 14.051193
[epoch10, step2616]: loss 2.972834
[epoch10, step2617]: loss 2.778555
[epoch10, step2618]: loss 3.056598
[epoch10, step2619]: loss 14.632791
[epoch10, step2620]: loss 3.157616
[epoch10, step2621]: loss 2.634480
[epoch10, step2622]: loss 1.759602
[epoch10, step2623]: loss 1.381661
[epoch10, step2624]: loss 1.063035
[epoch10, step2625]: loss 6.235967
[epoch10, step2626]: loss 1.206283
[epoch10, step2627]: loss 2.591865
[epoch10, step2628]: loss 1.903929
[epoch10, step2629]: loss 3.880311
[epoch10, step2630]: loss 8.742886
[epoch10, step2631]: loss 1.953696
[epoch10, step2632]: loss 0.848190
[epoch10, step2633]: loss 50.299309
[epoch10, step2634]: loss 3.520620
[epoch10, step2635]: loss 13.494472
[epoch10, step2636]: loss 1.621957
[epoch10, step2637]: loss 2.057353
[epoch10, step2638]: loss 2.973855
[epoch10, step2639]: loss 1.173714
[epoch10, step2640]: loss 1.561434
[epoch10, step2641]: loss 2.109711
[epoch10, step2642]: loss 1.415662
[epoch10, step2643]: loss 1.669319
[epoch10, step2644]: loss 1.547397
[epoch10, step2645]: loss 2.954945
[epoch10, step2646]: loss 1.065212
[epoch10, step2647]: loss 1.764753
[epoch10, step2648]: loss 1.905674
[epoch10, step2649]: loss 16.626270
[epoch10, step2650]: loss 32.748825
[epoch10, step2651]: loss 2.830909
[epoch10, step2652]: loss 4.672932
[epoch10, step2653]: loss 11.914994
[epoch10, step2654]: loss 11.294028
[epoch10, step2655]: loss 8.823693
[epoch10, step2656]: loss 1.551957
[epoch10, step2657]: loss 21.330967
[epoch10, step2658]: loss 1.719776
[epoch10, step2659]: loss 2.088660
[epoch10, step2660]: loss 1.433496
[epoch10, step2661]: loss 1.645596
[epoch10, step2662]: loss 2.171479
[epoch10, step2663]: loss 13.412167
[epoch10, step2664]: loss 2.245078
[epoch10, step2665]: loss 0.945720
[epoch10, step2666]: loss 4.348892
[epoch10, step2667]: loss 27.648602
[epoch10, step2668]: loss 1.866523
[epoch10, step2669]: loss 20.424215
[epoch10, step2670]: loss 13.578321
[epoch10, step2671]: loss 2.109670
[epoch10, step2672]: loss 2.826046
[epoch10, step2673]: loss 5.128913
[epoch10, step2674]: loss 1.763171
[epoch10, step2675]: loss 12.175404
[epoch10, step2676]: loss 14.586011
[epoch10, step2677]: loss 1.021173
[epoch10, step2678]: loss 3.358878
[epoch10, step2679]: loss 4.459598
[epoch10, step2680]: loss 0.827669
[epoch10, step2681]: loss 1.894222
[epoch10, step2682]: loss 9.727310
[epoch10, step2683]: loss 2.839062
[epoch10, step2684]: loss 1.258785
[epoch10, step2685]: loss 1.533130
[epoch10, step2686]: loss 4.537479
[epoch10, step2687]: loss 1.242528
[epoch10, step2688]: loss 11.937431
[epoch10, step2689]: loss 1.528533
[epoch10, step2690]: loss 15.934582
[epoch10, step2691]: loss 9.854411
[epoch10, step2692]: loss 0.827372
[epoch10, step2693]: loss 6.101255
[epoch10, step2694]: loss 1.883948
[epoch10, step2695]: loss 2.242526
[epoch10, step2696]: loss 15.176941
[epoch10, step2697]: loss 3.469710
[epoch10, step2698]: loss 4.651734
[epoch10, step2699]: loss 16.865448
[epoch10, step2700]: loss 5.141632
[epoch10, step2701]: loss 2.117892
[epoch10, step2702]: loss 10.785825
[epoch10, step2703]: loss 3.900011
[epoch10, step2704]: loss 0.669762
[epoch10, step2705]: loss 9.124858
[epoch10, step2706]: loss 1.021348
[epoch10, step2707]: loss 0.858006
[epoch10, step2708]: loss 3.288446
[epoch10, step2709]: loss 1.724955
[epoch10, step2710]: loss 1.666602
[epoch10, step2711]: loss 2.010757
[epoch10, step2712]: loss 1.641119
[epoch10, step2713]: loss 7.471413
[epoch10, step2714]: loss 6.844050
[epoch10, step2715]: loss 5.153457
[epoch10, step2716]: loss 1.767560
[epoch10, step2717]: loss 1.280622
[epoch10, step2718]: loss 1.312441
[epoch10, step2719]: loss 15.793611
[epoch10, step2720]: loss 9.927928
[epoch10, step2721]: loss 2.336142
[epoch10, step2722]: loss 2.558073
[epoch10, step2723]: loss 26.425808
[epoch10, step2724]: loss 11.326948
[epoch10, step2725]: loss 9.158787
[epoch10, step2726]: loss 9.879930
[epoch10, step2727]: loss 2.371126
[epoch10, step2728]: loss 1.013606
[epoch10, step2729]: loss 6.722468
[epoch10, step2730]: loss 4.237319
[epoch10, step2731]: loss 0.821354
[epoch10, step2732]: loss 0.897107
[epoch10, step2733]: loss 0.814363
[epoch10, step2734]: loss 0.887317
[epoch10, step2735]: loss 6.848874
[epoch10, step2736]: loss 1.932323
[epoch10, step2737]: loss 3.921328
[epoch10, step2738]: loss 1.983729
[epoch10, step2739]: loss 3.233989
[epoch10, step2740]: loss 0.905157
[epoch10, step2741]: loss 10.203609
[epoch10, step2742]: loss 1.067730
[epoch10, step2743]: loss 2.243750
[epoch10, step2744]: loss 2.609325
[epoch10, step2745]: loss 2.301921
[epoch10, step2746]: loss 6.464755
[epoch10, step2747]: loss 1.681963
[epoch10, step2748]: loss 3.569159
[epoch10, step2749]: loss 7.725879
[epoch10, step2750]: loss 2.994766
[epoch10, step2751]: loss 13.760813
[epoch10, step2752]: loss 2.825709
[epoch10, step2753]: loss 14.413865
[epoch10, step2754]: loss 4.395116
[epoch10, step2755]: loss 4.304791
[epoch10, step2756]: loss 1.770443
[epoch10, step2757]: loss 3.068838
[epoch10, step2758]: loss 1.136446
[epoch10, step2759]: loss 3.426582
[epoch10, step2760]: loss 2.818830
[epoch10, step2761]: loss 22.761520
[epoch10, step2762]: loss 12.165976
[epoch10, step2763]: loss 19.658865
[epoch10, step2764]: loss 3.910247
[epoch10, step2765]: loss 7.428288
[epoch10, step2766]: loss 2.989933
[epoch10, step2767]: loss 2.105203
[epoch10, step2768]: loss 2.049088
[epoch10, step2769]: loss 0.901370
[epoch10, step2770]: loss 1.487126
[epoch10, step2771]: loss 1.978571
[epoch10, step2772]: loss 6.845940
[epoch10, step2773]: loss 2.652158
[epoch10, step2774]: loss 1.301119
[epoch10, step2775]: loss 1.852369
[epoch10, step2776]: loss 2.057112
[epoch10, step2777]: loss 3.516104
[epoch10, step2778]: loss 1.626781
[epoch10, step2779]: loss 1.296347
[epoch10, step2780]: loss 8.833433
[epoch10, step2781]: loss 1.234828
[epoch10, step2782]: loss 1.173243
[epoch10, step2783]: loss 1.779724
[epoch10, step2784]: loss 1.966388
[epoch10, step2785]: loss 13.035495
[epoch10, step2786]: loss 12.488128
[epoch10, step2787]: loss 1.678756
[epoch10, step2788]: loss 6.043940
[epoch10, step2789]: loss 0.974665
[epoch10, step2790]: loss 3.011708
[epoch10, step2791]: loss 14.401710
[epoch10, step2792]: loss 2.533134
[epoch10, step2793]: loss 7.139038
[epoch10, step2794]: loss 4.265020
[epoch10, step2795]: loss 1.943263
[epoch10, step2796]: loss 2.171023
[epoch10, step2797]: loss 2.682872
[epoch10, step2798]: loss 3.229549
[epoch10, step2799]: loss 1.403688
[epoch10, step2800]: loss 11.329202
[epoch10, step2801]: loss 0.845644
[epoch10, step2802]: loss 2.194554
[epoch10, step2803]: loss 1.367190
[epoch10, step2804]: loss 4.171010
[epoch10, step2805]: loss 2.397631
[epoch10, step2806]: loss 1.983599
[epoch10, step2807]: loss 12.155075
[epoch10, step2808]: loss 2.200877
[epoch10, step2809]: loss 1.493717
[epoch10, step2810]: loss 3.837942
[epoch10, step2811]: loss 7.617754
[epoch10, step2812]: loss 4.263134
[epoch10, step2813]: loss 11.724537
[epoch10, step2814]: loss 23.131643
[epoch10, step2815]: loss 2.652577
[epoch10, step2816]: loss 1.906973
[epoch10, step2817]: loss 6.230247
[epoch10, step2818]: loss 1.490615
[epoch10, step2819]: loss 1.376411
[epoch10, step2820]: loss 12.482295
[epoch10, step2821]: loss 1.737478
[epoch10, step2822]: loss 4.614461
[epoch10, step2823]: loss 1.267113
[epoch10, step2824]: loss 2.226378
[epoch10, step2825]: loss 11.965680
[epoch10, step2826]: loss 3.433857
[epoch10, step2827]: loss 2.422950
[epoch10, step2828]: loss 0.804484
[epoch10, step2829]: loss 4.089988
[epoch10, step2830]: loss 24.726879
[epoch10, step2831]: loss 3.212597
[epoch10, step2832]: loss 0.849492
[epoch10, step2833]: loss 1.087336
[epoch10, step2834]: loss 1.348075
[epoch10, step2835]: loss 3.184164
[epoch10, step2836]: loss 19.996876
[epoch10, step2837]: loss 1.134819
[epoch10, step2838]: loss 1.157259
[epoch10, step2839]: loss 21.489841
[epoch10, step2840]: loss 1.294665
[epoch10, step2841]: loss 16.584465
[epoch10, step2842]: loss 1.213537
[epoch10, step2843]: loss 2.797918
[epoch10, step2844]: loss 1.208475
[epoch10, step2845]: loss 1.935098
[epoch10, step2846]: loss 1.389676
[epoch10, step2847]: loss 1.598133
[epoch10, step2848]: loss 3.524134
[epoch10, step2849]: loss 13.919753
[epoch10, step2850]: loss 8.700402
[epoch10, step2851]: loss 2.722747
[epoch10, step2852]: loss 1.172234
[epoch10, step2853]: loss 4.297193
[epoch10, step2854]: loss 1.327327
[epoch10, step2855]: loss 1.921679
[epoch10, step2856]: loss 13.835356
[epoch10, step2857]: loss 8.526816
[epoch10, step2858]: loss 14.047842
[epoch10, step2859]: loss 2.146572
[epoch10, step2860]: loss 1.243219
[epoch10, step2861]: loss 20.132332
[epoch10, step2862]: loss 2.312552
[epoch10, step2863]: loss 1.767593
[epoch10, step2864]: loss 0.982924
[epoch10, step2865]: loss 2.673856
[epoch10, step2866]: loss 31.103045
[epoch10, step2867]: loss 2.396633
[epoch10, step2868]: loss 1.458046
[epoch10, step2869]: loss 1.627871
[epoch10, step2870]: loss 1.236366
[epoch10, step2871]: loss 1.973167
[epoch10, step2872]: loss 1.261323
[epoch10, step2873]: loss 1.116185
[epoch10, step2874]: loss 2.318654
[epoch10, step2875]: loss 0.839754
[epoch10, step2876]: loss 1.095975
[epoch10, step2877]: loss 11.163349
[epoch10, step2878]: loss 2.621712
[epoch10, step2879]: loss 1.387031
[epoch10, step2880]: loss 1.638208
[epoch10, step2881]: loss 1.015990
[epoch10, step2882]: loss 2.434984
[epoch10, step2883]: loss 2.421371
[epoch10, step2884]: loss 11.564205
[epoch10, step2885]: loss 32.353775
[epoch10, step2886]: loss 1.482853
[epoch10, step2887]: loss 0.967962
[epoch10, step2888]: loss 2.028916
[epoch10, step2889]: loss 1.550821
[epoch10, step2890]: loss 9.780539
[epoch10, step2891]: loss 5.020420
[epoch10, step2892]: loss 2.494360
[epoch10, step2893]: loss 4.677411
[epoch10, step2894]: loss 13.760252
[epoch10, step2895]: loss 19.627609
[epoch10, step2896]: loss 1.658043
[epoch10, step2897]: loss 0.836919
[epoch10, step2898]: loss 2.605634
[epoch10, step2899]: loss 1.610333
[epoch10, step2900]: loss 16.481207
[epoch10, step2901]: loss 2.912940
[epoch10, step2902]: loss 3.053119
[epoch10, step2903]: loss 1.825616
[epoch10, step2904]: loss 10.374815
[epoch10, step2905]: loss 8.373477
[epoch10, step2906]: loss 0.980058
[epoch10, step2907]: loss 1.177094
[epoch10, step2908]: loss 1.515836
[epoch10, step2909]: loss 21.147198
[epoch10, step2910]: loss 19.165668
[epoch10, step2911]: loss 3.582945
[epoch10, step2912]: loss 2.097864
[epoch10, step2913]: loss 3.312895
[epoch10, step2914]: loss 13.554440
[epoch10, step2915]: loss 6.209335
[epoch10, step2916]: loss 1.455502
[epoch10, step2917]: loss 2.709209
[epoch10, step2918]: loss 2.964572
[epoch10, step2919]: loss 0.924514
[epoch10, step2920]: loss 1.643923
[epoch10, step2921]: loss 1.003509
[epoch10, step2922]: loss 0.854420
[epoch10, step2923]: loss 1.985456
[epoch10, step2924]: loss 5.142158
[epoch10, step2925]: loss 10.957243
[epoch10, step2926]: loss 1.367902
[epoch10, step2927]: loss 1.893971
[epoch10, step2928]: loss 11.439590
[epoch10, step2929]: loss 3.919636
[epoch10, step2930]: loss 1.576645
[epoch10, step2931]: loss 1.753525
[epoch10, step2932]: loss 3.244034
[epoch10, step2933]: loss 5.145893
[epoch10, step2934]: loss 1.515944
[epoch10, step2935]: loss 1.232738
[epoch10, step2936]: loss 2.141105
[epoch10, step2937]: loss 14.758632
[epoch10, step2938]: loss 4.829272
[epoch10, step2939]: loss 1.544080
[epoch10, step2940]: loss 10.873807
[epoch10, step2941]: loss 9.709934
[epoch10, step2942]: loss 0.953068
[epoch10, step2943]: loss 1.595100
[epoch10, step2944]: loss 1.924335
[epoch10, step2945]: loss 2.718167
[epoch10, step2946]: loss 2.724566
[epoch10, step2947]: loss 1.407325
[epoch10, step2948]: loss 5.488327
[epoch10, step2949]: loss 1.412421
[epoch10, step2950]: loss 1.602573
[epoch10, step2951]: loss 10.410015
[epoch10, step2952]: loss 1.161441
[epoch10, step2953]: loss 9.717187
[epoch10, step2954]: loss 1.324405
[epoch10, step2955]: loss 25.700016
[epoch10, step2956]: loss 1.347267
[epoch10, step2957]: loss 9.843211
[epoch10, step2958]: loss 13.406358
[epoch10, step2959]: loss 1.267969
[epoch10, step2960]: loss 27.629690
[epoch10, step2961]: loss 3.772328
[epoch10, step2962]: loss 1.988429
[epoch10, step2963]: loss 1.699068
[epoch10, step2964]: loss 2.669554
[epoch10, step2965]: loss 16.923994
[epoch10, step2966]: loss 1.088789
[epoch10, step2967]: loss 2.492060
[epoch10, step2968]: loss 11.029739
[epoch10, step2969]: loss 19.017855
[epoch10, step2970]: loss 4.168537
[epoch10, step2971]: loss 1.266643
[epoch10, step2972]: loss 0.881557
[epoch10, step2973]: loss 1.442503
[epoch10, step2974]: loss 1.723530
[epoch10, step2975]: loss 29.232307
[epoch10, step2976]: loss 2.202030
[epoch10, step2977]: loss 1.507549
[epoch10, step2978]: loss 15.386040
[epoch10, step2979]: loss 1.228127
[epoch10, step2980]: loss 3.063780
[epoch10, step2981]: loss 0.717244
[epoch10, step2982]: loss 1.536393
[epoch10, step2983]: loss 1.432676
[epoch10, step2984]: loss 1.544286
[epoch10, step2985]: loss 4.655438
[epoch10, step2986]: loss 2.156793
[epoch10, step2987]: loss 10.925903
[epoch10, step2988]: loss 2.951145
[epoch10, step2989]: loss 1.127307
[epoch10, step2990]: loss 14.054856
[epoch10, step2991]: loss 1.015726
[epoch10, step2992]: loss 1.924338
[epoch10, step2993]: loss 3.312707
[epoch10, step2994]: loss 2.016386
[epoch10, step2995]: loss 1.992186
[epoch10, step2996]: loss 2.157933
[epoch10, step2997]: loss 5.743915
[epoch10, step2998]: loss 3.963866
[epoch10, step2999]: loss 1.996356
[epoch10, step3000]: loss 2.450988
[epoch10, step3001]: loss 1.929187
[epoch10, step3002]: loss 8.107968
[epoch10, step3003]: loss 11.113011
[epoch10, step3004]: loss 1.487207
[epoch10, step3005]: loss 14.768202
[epoch10, step3006]: loss 0.992589
[epoch10, step3007]: loss 1.266343
[epoch10, step3008]: loss 2.508599
[epoch10, step3009]: loss 11.747703
[epoch10, step3010]: loss 2.499096
[epoch10, step3011]: loss 30.876726
[epoch10, step3012]: loss 4.395001
[epoch10, step3013]: loss 2.044767
[epoch10, step3014]: loss 1.372381
[epoch10, step3015]: loss 4.249446
[epoch10, step3016]: loss 1.581255
[epoch10, step3017]: loss 0.941401
[epoch10, step3018]: loss 6.601959
[epoch10, step3019]: loss 9.933882
[epoch10, step3020]: loss 0.990328
[epoch10, step3021]: loss 12.058964
[epoch10, step3022]: loss 6.562860
[epoch10, step3023]: loss 2.596410
[epoch10, step3024]: loss 3.955084
[epoch10, step3025]: loss 12.363370
[epoch10, step3026]: loss 1.170008
[epoch10, step3027]: loss 19.239912
[epoch10, step3028]: loss 11.375251
[epoch10, step3029]: loss 3.751813
[epoch10, step3030]: loss 2.040586
[epoch10, step3031]: loss 2.318273
[epoch10, step3032]: loss 6.845842
[epoch10, step3033]: loss 6.198528
[epoch10, step3034]: loss 4.662852
[epoch10, step3035]: loss 3.857042
[epoch10, step3036]: loss 10.779107
[epoch10, step3037]: loss 2.781990
[epoch10, step3038]: loss 20.099144
[epoch10, step3039]: loss 1.388640
[epoch10, step3040]: loss 14.103920
[epoch10, step3041]: loss 12.819843
[epoch10, step3042]: loss 2.022767
[epoch10, step3043]: loss 1.471273
[epoch10, step3044]: loss 32.753357
[epoch10, step3045]: loss 1.064904
[epoch10, step3046]: loss 1.664087
[epoch10, step3047]: loss 3.881137
[epoch10, step3048]: loss 3.439334
[epoch10, step3049]: loss 6.210416
[epoch10, step3050]: loss 1.309958
[epoch10, step3051]: loss 0.788319
[epoch10, step3052]: loss 1.999119
[epoch10, step3053]: loss 19.138247
[epoch10, step3054]: loss 21.577917
[epoch10, step3055]: loss 2.124384
[epoch10, step3056]: loss 1.843763
[epoch10, step3057]: loss 11.099673
[epoch10, step3058]: loss 2.061602
[epoch10, step3059]: loss 0.673834
[epoch10, step3060]: loss 0.932039
[epoch10, step3061]: loss 2.919570
[epoch10, step3062]: loss 1.991712
[epoch10, step3063]: loss 1.023086
[epoch10, step3064]: loss 1.251920
[epoch10, step3065]: loss 4.420384
[epoch10, step3066]: loss 5.361036
[epoch10, step3067]: loss 2.674053
[epoch10, step3068]: loss 2.332637
[epoch10, step3069]: loss 1.840420
[epoch10, step3070]: loss 4.793375
[epoch10, step3071]: loss 3.144168
[epoch10, step3072]: loss 2.101814
[epoch10, step3073]: loss 12.556050
[epoch10, step3074]: loss 2.765980
[epoch10, step3075]: loss 1.578728
[epoch10, step3076]: loss 0.695831

[epoch10]: avg loss 0.695831

[epoch11, step1]: loss 1.725511
[epoch11, step2]: loss 2.281959
[epoch11, step3]: loss 14.141340
[epoch11, step4]: loss 0.990654
[epoch11, step5]: loss 1.296676
[epoch11, step6]: loss 10.258668
[epoch11, step7]: loss 4.303864
[epoch11, step8]: loss 1.271844
[epoch11, step9]: loss 1.042278
[epoch11, step10]: loss 17.328556
[epoch11, step11]: loss 2.346855
[epoch11, step12]: loss 1.051660
[epoch11, step13]: loss 1.495890
[epoch11, step14]: loss 14.815583
[epoch11, step15]: loss 3.584225
[epoch11, step16]: loss 3.428320
[epoch11, step17]: loss 1.691247
[epoch11, step18]: loss 39.125252
[epoch11, step19]: loss 5.939588
[epoch11, step20]: loss 21.111128
[epoch11, step21]: loss 1.404278
[epoch11, step22]: loss 1.732072
[epoch11, step23]: loss 2.012736
[epoch11, step24]: loss 15.713244
[epoch11, step25]: loss 13.303284
[epoch11, step26]: loss 3.516577
[epoch11, step27]: loss 0.855411
[epoch11, step28]: loss 15.747998
[epoch11, step29]: loss 32.644089
[epoch11, step30]: loss 36.186558
[epoch11, step31]: loss 34.686878
[epoch11, step32]: loss 2.588013
[epoch11, step33]: loss 1.827838
[epoch11, step34]: loss 1.448616
[epoch11, step35]: loss 2.270992
[epoch11, step36]: loss 14.426303
[epoch11, step37]: loss 0.886228
[epoch11, step38]: loss 2.907874
[epoch11, step39]: loss 14.198404
[epoch11, step40]: loss 1.152761
[epoch11, step41]: loss 0.879587
[epoch11, step42]: loss 17.934343
[epoch11, step43]: loss 11.144683
[epoch11, step44]: loss 1.486591
[epoch11, step45]: loss 1.750921
[epoch11, step46]: loss 2.584781
[epoch11, step47]: loss 3.341285
[epoch11, step48]: loss 12.832355
[epoch11, step49]: loss 1.541390
[epoch11, step50]: loss 1.423307
[epoch11, step51]: loss 2.192443
[epoch11, step52]: loss 2.503360
[epoch11, step53]: loss 19.075579
[epoch11, step54]: loss 2.110978
[epoch11, step55]: loss 2.203388
[epoch11, step56]: loss 1.251195
[epoch11, step57]: loss 4.616518
[epoch11, step58]: loss 1.265674
[epoch11, step59]: loss 1.632748
[epoch11, step60]: loss 5.166179
[epoch11, step61]: loss 1.932841
[epoch11, step62]: loss 1.786066
[epoch11, step63]: loss 3.222561
[epoch11, step64]: loss 3.737877
[epoch11, step65]: loss 4.401122
[epoch11, step66]: loss 1.927185
[epoch11, step67]: loss 3.832249
[epoch11, step68]: loss 10.505040
[epoch11, step69]: loss 10.346578
[epoch11, step70]: loss 5.438266
[epoch11, step71]: loss 1.163639
[epoch11, step72]: loss 5.025181
[epoch11, step73]: loss 13.828398
[epoch11, step74]: loss 9.343924
[epoch11, step75]: loss 20.753347
[epoch11, step76]: loss 11.625012
[epoch11, step77]: loss 8.251674
[epoch11, step78]: loss 1.956667
[epoch11, step79]: loss 1.677656
[epoch11, step80]: loss 1.435514
[epoch11, step81]: loss 1.614501
[epoch11, step82]: loss 23.699539
[epoch11, step83]: loss 2.019305
[epoch11, step84]: loss 1.709190
[epoch11, step85]: loss 35.006752
[epoch11, step86]: loss 1.505907
[epoch11, step87]: loss 2.249010
[epoch11, step88]: loss 2.904227
[epoch11, step89]: loss 6.385975
[epoch11, step90]: loss 7.473116
[epoch11, step91]: loss 3.589845
[epoch11, step92]: loss 1.818915
[epoch11, step93]: loss 1.518022
[epoch11, step94]: loss 0.715076
[epoch11, step95]: loss 4.152291
[epoch11, step96]: loss 1.204121
[epoch11, step97]: loss 10.883197
[epoch11, step98]: loss 2.049941
[epoch11, step99]: loss 25.350479
[epoch11, step100]: loss 1.398987
[epoch11, step101]: loss 14.967501
[epoch11, step102]: loss 13.920591
[epoch11, step103]: loss 1.142675
[epoch11, step104]: loss 11.139076
[epoch11, step105]: loss 2.689318
[epoch11, step106]: loss 1.536718
[epoch11, step107]: loss 2.915622
[epoch11, step108]: loss 12.381580
[epoch11, step109]: loss 2.819139
[epoch11, step110]: loss 11.393748
[epoch11, step111]: loss 2.615806
[epoch11, step112]: loss 1.584895
[epoch11, step113]: loss 8.087199
[epoch11, step114]: loss 17.386192
[epoch11, step115]: loss 1.713005
[epoch11, step116]: loss 0.942685
[epoch11, step117]: loss 15.140217
[epoch11, step118]: loss 1.843777
[epoch11, step119]: loss 2.341060
[epoch11, step120]: loss 4.946877
[epoch11, step121]: loss 4.004513
[epoch11, step122]: loss 3.172933
[epoch11, step123]: loss 1.497379
[epoch11, step124]: loss 1.618566
[epoch11, step125]: loss 1.824666
[epoch11, step126]: loss 3.067565
[epoch11, step127]: loss 0.690887
[epoch11, step128]: loss 0.964936
[epoch11, step129]: loss 3.190267
[epoch11, step130]: loss 1.670786
[epoch11, step131]: loss 3.195198
[epoch11, step132]: loss 21.115833
[epoch11, step133]: loss 2.091316
[epoch11, step134]: loss 2.752558
[epoch11, step135]: loss 12.080332
[epoch11, step136]: loss 1.684495
[epoch11, step137]: loss 5.633183
[epoch11, step138]: loss 17.220654
[epoch11, step139]: loss 24.602682
[epoch11, step140]: loss 2.401424
[epoch11, step141]: loss 2.283984
[epoch11, step142]: loss 3.489927
[epoch11, step143]: loss 2.622791
[epoch11, step144]: loss 1.120354
[epoch11, step145]: loss 8.599113
[epoch11, step146]: loss 2.631386
[epoch11, step147]: loss 1.849045
[epoch11, step148]: loss 2.140846
[epoch11, step149]: loss 4.392006
[epoch11, step150]: loss 7.255999
[epoch11, step151]: loss 9.627579
[epoch11, step152]: loss 3.841605
[epoch11, step153]: loss 8.531705
[epoch11, step154]: loss 4.814588
[epoch11, step155]: loss 1.957435
[epoch11, step156]: loss 17.978085
[epoch11, step157]: loss 1.831818
[epoch11, step158]: loss 8.594541
[epoch11, step159]: loss 1.475945
[epoch11, step160]: loss 1.684118
[epoch11, step161]: loss 2.052178
[epoch11, step162]: loss 7.780193
[epoch11, step163]: loss 7.906113
[epoch11, step164]: loss 4.653977
[epoch11, step165]: loss 1.153583
[epoch11, step166]: loss 1.334609
[epoch11, step167]: loss 4.457547
[epoch11, step168]: loss 0.880663
[epoch11, step169]: loss 3.256874
[epoch11, step170]: loss 1.892416
[epoch11, step171]: loss 5.917047
[epoch11, step172]: loss 0.854537
[epoch11, step173]: loss 13.537180
[epoch11, step174]: loss 0.725947
[epoch11, step175]: loss 1.849205
[epoch11, step176]: loss 2.072581
[epoch11, step177]: loss 1.329091
[epoch11, step178]: loss 1.494977
[epoch11, step179]: loss 1.602532
[epoch11, step180]: loss 23.253130
[epoch11, step181]: loss 7.978844
[epoch11, step182]: loss 4.309094
[epoch11, step183]: loss 2.000362
[epoch11, step184]: loss 1.824129
[epoch11, step185]: loss 2.527673
[epoch11, step186]: loss 2.109082
[epoch11, step187]: loss 9.679981
[epoch11, step188]: loss 14.167405
[epoch11, step189]: loss 0.966208
[epoch11, step190]: loss 9.411959
[epoch11, step191]: loss 19.096899
[epoch11, step192]: loss 2.314039
[epoch11, step193]: loss 1.691995
[epoch11, step194]: loss 1.951843
[epoch11, step195]: loss 16.205667
[epoch11, step196]: loss 2.145781
[epoch11, step197]: loss 0.730844
[epoch11, step198]: loss 1.169384
[epoch11, step199]: loss 1.706754
[epoch11, step200]: loss 9.735085
[epoch11, step201]: loss 5.447085
[epoch11, step202]: loss 20.010244
[epoch11, step203]: loss 2.809222
[epoch11, step204]: loss 2.075305
[epoch11, step205]: loss 1.077036
[epoch11, step206]: loss 1.553872
[epoch11, step207]: loss 10.245883
[epoch11, step208]: loss 2.412159
[epoch11, step209]: loss 18.322163
[epoch11, step210]: loss 5.912457
[epoch11, step211]: loss 14.241376
[epoch11, step212]: loss 10.955196
[epoch11, step213]: loss 4.993700
[epoch11, step214]: loss 9.008487
[epoch11, step215]: loss 24.605801
[epoch11, step216]: loss 3.184960
[epoch11, step217]: loss 15.229861
[epoch11, step218]: loss 20.706026
[epoch11, step219]: loss 1.647848
[epoch11, step220]: loss 4.348301
[epoch11, step221]: loss 32.355721
[epoch11, step222]: loss 6.707014
[epoch11, step223]: loss 1.594335
[epoch11, step224]: loss 12.115932
[epoch11, step225]: loss 11.402770
[epoch11, step226]: loss 2.055792
[epoch11, step227]: loss 12.674264
[epoch11, step228]: loss 9.670637
[epoch11, step229]: loss 3.486790
[epoch11, step230]: loss 7.910070
[epoch11, step231]: loss 3.271815
[epoch11, step232]: loss 1.295514
[epoch11, step233]: loss 4.084119
[epoch11, step234]: loss 2.427514
[epoch11, step235]: loss 34.782227
[epoch11, step236]: loss 23.508312
[epoch11, step237]: loss 1.073568
[epoch11, step238]: loss 6.802934
[epoch11, step239]: loss 0.940016
[epoch11, step240]: loss 2.256222
[epoch11, step241]: loss 2.468752
[epoch11, step242]: loss 10.984463
[epoch11, step243]: loss 2.055974
[epoch11, step244]: loss 1.455852
[epoch11, step245]: loss 1.096275
[epoch11, step246]: loss 28.919575
[epoch11, step247]: loss 3.751337
[epoch11, step248]: loss 1.130249
[epoch11, step249]: loss 2.021542
[epoch11, step250]: loss 10.348312
[epoch11, step251]: loss 1.622175
[epoch11, step252]: loss 3.745235
[epoch11, step253]: loss 0.956240
[epoch11, step254]: loss 3.900120
[epoch11, step255]: loss 3.071408
[epoch11, step256]: loss 8.934777
[epoch11, step257]: loss 1.909594
[epoch11, step258]: loss 1.099934
[epoch11, step259]: loss 12.204429
[epoch11, step260]: loss 32.683525
[epoch11, step261]: loss 9.379253
[epoch11, step262]: loss 4.868941
[epoch11, step263]: loss 3.192489
[epoch11, step264]: loss 3.575871
[epoch11, step265]: loss 3.543697
[epoch11, step266]: loss 2.814996
[epoch11, step267]: loss 21.501087
[epoch11, step268]: loss 1.692796
[epoch11, step269]: loss 2.292715
[epoch11, step270]: loss 9.817157
[epoch11, step271]: loss 2.574776
[epoch11, step272]: loss 1.218433
[epoch11, step273]: loss 15.139353
[epoch11, step274]: loss 3.935881
[epoch11, step275]: loss 3.960259
[epoch11, step276]: loss 23.436365
[epoch11, step277]: loss 19.273872
[epoch11, step278]: loss 1.727088
[epoch11, step279]: loss 2.559990
[epoch11, step280]: loss 5.881208
[epoch11, step281]: loss 1.904516
[epoch11, step282]: loss 9.800314
[epoch11, step283]: loss 1.618909
[epoch11, step284]: loss 5.998763
[epoch11, step285]: loss 1.486902
[epoch11, step286]: loss 0.933298
[epoch11, step287]: loss 1.287134
[epoch11, step288]: loss 10.868945
[epoch11, step289]: loss 4.363100
[epoch11, step290]: loss 1.526021
[epoch11, step291]: loss 2.184409
[epoch11, step292]: loss 3.253239
[epoch11, step293]: loss 8.234900
[epoch11, step294]: loss 2.063915
[epoch11, step295]: loss 13.690029
[epoch11, step296]: loss 2.997820
[epoch11, step297]: loss 1.280313
[epoch11, step298]: loss 1.440142
[epoch11, step299]: loss 1.311472
[epoch11, step300]: loss 4.030250
[epoch11, step301]: loss 6.487288
[epoch11, step302]: loss 3.871727
[epoch11, step303]: loss 11.435004
[epoch11, step304]: loss 1.581326
[epoch11, step305]: loss 13.736644
[epoch11, step306]: loss 8.377443
[epoch11, step307]: loss 3.320607
[epoch11, step308]: loss 1.333549
[epoch11, step309]: loss 10.881524
[epoch11, step310]: loss 18.171368
[epoch11, step311]: loss 19.395685
[epoch11, step312]: loss 0.769396
[epoch11, step313]: loss 2.794658
[epoch11, step314]: loss 1.771611
[epoch11, step315]: loss 1.750928
[epoch11, step316]: loss 21.830126
[epoch11, step317]: loss 1.804864
[epoch11, step318]: loss 1.032238
[epoch11, step319]: loss 2.683576
[epoch11, step320]: loss 1.443151
[epoch11, step321]: loss 16.741655
[epoch11, step322]: loss 3.611806
[epoch11, step323]: loss 1.917803
[epoch11, step324]: loss 2.186892
[epoch11, step325]: loss 1.103492
[epoch11, step326]: loss 24.195213
[epoch11, step327]: loss 2.008880
[epoch11, step328]: loss 2.138923
[epoch11, step329]: loss 6.489468
[epoch11, step330]: loss 1.825638
[epoch11, step331]: loss 8.465281
[epoch11, step332]: loss 1.542364
[epoch11, step333]: loss 1.901218
[epoch11, step334]: loss 6.430457
[epoch11, step335]: loss 13.281546
[epoch11, step336]: loss 2.637640
[epoch11, step337]: loss 3.531091
[epoch11, step338]: loss 18.772058
[epoch11, step339]: loss 2.089143
[epoch11, step340]: loss 24.779011
[epoch11, step341]: loss 1.092413
[epoch11, step342]: loss 4.027051
[epoch11, step343]: loss 11.146132
[epoch11, step344]: loss 0.835213
[epoch11, step345]: loss 5.771272
[epoch11, step346]: loss 2.418387
[epoch11, step347]: loss 9.496361
[epoch11, step348]: loss 2.871218
[epoch11, step349]: loss 0.837511
[epoch11, step350]: loss 10.814577
[epoch11, step351]: loss 1.748495
[epoch11, step352]: loss 4.055534
[epoch11, step353]: loss 1.039390
[epoch11, step354]: loss 0.826147
[epoch11, step355]: loss 20.815586
[epoch11, step356]: loss 2.775524
[epoch11, step357]: loss 1.391000
[epoch11, step358]: loss 1.643304
[epoch11, step359]: loss 1.095595
[epoch11, step360]: loss 1.507320
[epoch11, step361]: loss 2.417696
[epoch11, step362]: loss 6.184492
[epoch11, step363]: loss 2.237647
[epoch11, step364]: loss 5.343709
[epoch11, step365]: loss 0.946124
[epoch11, step366]: loss 3.899024
[epoch11, step367]: loss 2.359940
[epoch11, step368]: loss 3.896279
[epoch11, step369]: loss 15.937160
[epoch11, step370]: loss 1.398615
[epoch11, step371]: loss 1.301585
[epoch11, step372]: loss 5.305913
[epoch11, step373]: loss 0.908794
[epoch11, step374]: loss 4.180040
[epoch11, step375]: loss 10.601162
[epoch11, step376]: loss 2.152878
[epoch11, step377]: loss 14.770751
[epoch11, step378]: loss 2.538682
[epoch11, step379]: loss 2.892135
[epoch11, step380]: loss 3.221411
[epoch11, step381]: loss 3.311541
[epoch11, step382]: loss 3.483481
[epoch11, step383]: loss 16.097071
[epoch11, step384]: loss 8.448578
[epoch11, step385]: loss 3.085718
[epoch11, step386]: loss 11.766279
[epoch11, step387]: loss 2.255872
[epoch11, step388]: loss 8.611988
[epoch11, step389]: loss 1.233687
[epoch11, step390]: loss 5.625917
[epoch11, step391]: loss 3.891305
[epoch11, step392]: loss 12.822820
[epoch11, step393]: loss 2.956435
[epoch11, step394]: loss 1.038652
[epoch11, step395]: loss 6.450047
[epoch11, step396]: loss 17.074438
[epoch11, step397]: loss 2.030215
[epoch11, step398]: loss 40.845779
[epoch11, step399]: loss 2.574393
[epoch11, step400]: loss 4.797594
[epoch11, step401]: loss 3.339051
[epoch11, step402]: loss 14.646835
[epoch11, step403]: loss 31.047178
[epoch11, step404]: loss 1.433060
[epoch11, step405]: loss 4.924501
[epoch11, step406]: loss 15.669154
[epoch11, step407]: loss 2.095863
[epoch11, step408]: loss 2.342076
[epoch11, step409]: loss 1.039719
[epoch11, step410]: loss 8.120529
[epoch11, step411]: loss 0.974754
[epoch11, step412]: loss 0.957483
[epoch11, step413]: loss 9.766574
[epoch11, step414]: loss 23.928463
[epoch11, step415]: loss 3.661932
[epoch11, step416]: loss 6.172044
[epoch11, step417]: loss 0.713772
[epoch11, step418]: loss 1.716322
[epoch11, step419]: loss 18.455147
[epoch11, step420]: loss 0.999909
[epoch11, step421]: loss 1.702583
[epoch11, step422]: loss 0.985898
[epoch11, step423]: loss 12.842561
[epoch11, step424]: loss 15.382479
[epoch11, step425]: loss 1.351844
[epoch11, step426]: loss 1.396112
[epoch11, step427]: loss 6.618333
[epoch11, step428]: loss 30.496975
[epoch11, step429]: loss 4.145269
[epoch11, step430]: loss 2.375858
[epoch11, step431]: loss 3.701080
[epoch11, step432]: loss 1.091156
[epoch11, step433]: loss 24.788328
[epoch11, step434]: loss 0.916362
[epoch11, step435]: loss 1.376435
[epoch11, step436]: loss 1.690946
[epoch11, step437]: loss 3.830487
[epoch11, step438]: loss 1.012815
[epoch11, step439]: loss 2.535082
[epoch11, step440]: loss 19.166019
[epoch11, step441]: loss 1.755942
[epoch11, step442]: loss 1.123053
[epoch11, step443]: loss 3.659207
[epoch11, step444]: loss 9.424596
[epoch11, step445]: loss 7.659934
[epoch11, step446]: loss 1.883598
[epoch11, step447]: loss 12.720492
[epoch11, step448]: loss 11.427425
[epoch11, step449]: loss 2.686342
[epoch11, step450]: loss 9.545745
[epoch11, step451]: loss 3.748945
[epoch11, step452]: loss 1.005046
[epoch11, step453]: loss 22.426767
[epoch11, step454]: loss 13.284931
[epoch11, step455]: loss 2.110667
[epoch11, step456]: loss 10.925779
[epoch11, step457]: loss 15.055912
[epoch11, step458]: loss 3.307570
[epoch11, step459]: loss 5.694314
[epoch11, step460]: loss 2.634168
[epoch11, step461]: loss 1.050665
[epoch11, step462]: loss 4.731812
[epoch11, step463]: loss 6.853508
[epoch11, step464]: loss 2.049443
[epoch11, step465]: loss 1.543262
[epoch11, step466]: loss 1.879260
[epoch11, step467]: loss 1.824387
[epoch11, step468]: loss 18.992308
[epoch11, step469]: loss 4.684925
[epoch11, step470]: loss 2.540283
[epoch11, step471]: loss 1.420929
[epoch11, step472]: loss 9.535218
[epoch11, step473]: loss 1.444197
[epoch11, step474]: loss 2.695529
[epoch11, step475]: loss 1.274774
[epoch11, step476]: loss 27.602781
[epoch11, step477]: loss 1.004879
[epoch11, step478]: loss 2.170403
[epoch11, step479]: loss 12.545206
[epoch11, step480]: loss 20.917612
[epoch11, step481]: loss 2.072071
[epoch11, step482]: loss 1.352387
[epoch11, step483]: loss 6.334208
[epoch11, step484]: loss 9.944269
[epoch11, step485]: loss 12.713594
[epoch11, step486]: loss 17.508678
[epoch11, step487]: loss 2.314872
[epoch11, step488]: loss 2.757378
[epoch11, step489]: loss 12.491040
[epoch11, step490]: loss 1.571921
[epoch11, step491]: loss 1.692824
[epoch11, step492]: loss 1.778854
[epoch11, step493]: loss 2.831012
[epoch11, step494]: loss 6.449405
[epoch11, step495]: loss 1.992833
[epoch11, step496]: loss 3.225917
[epoch11, step497]: loss 1.217209
[epoch11, step498]: loss 0.832845
[epoch11, step499]: loss 19.161373
[epoch11, step500]: loss 2.145943
[epoch11, step501]: loss 3.995735
[epoch11, step502]: loss 14.139771
[epoch11, step503]: loss 20.011127
[epoch11, step504]: loss 2.120632
[epoch11, step505]: loss 2.012034
[epoch11, step506]: loss 1.326876
[epoch11, step507]: loss 1.667038
[epoch11, step508]: loss 1.242583
[epoch11, step509]: loss 2.259989
[epoch11, step510]: loss 4.349343
[epoch11, step511]: loss 9.213106
[epoch11, step512]: loss 2.571793
[epoch11, step513]: loss 2.007815
[epoch11, step514]: loss 15.285928
[epoch11, step515]: loss 32.601604
[epoch11, step516]: loss 1.592305
[epoch11, step517]: loss 1.748520
[epoch11, step518]: loss 0.992784
[epoch11, step519]: loss 0.866370
[epoch11, step520]: loss 2.371848
[epoch11, step521]: loss 3.346586
[epoch11, step522]: loss 8.341228
[epoch11, step523]: loss 2.859047
[epoch11, step524]: loss 3.208120
[epoch11, step525]: loss 10.133627
[epoch11, step526]: loss 1.128618
[epoch11, step527]: loss 4.162089
[epoch11, step528]: loss 1.325934
[epoch11, step529]: loss 2.597415
[epoch11, step530]: loss 6.832115
[epoch11, step531]: loss 2.184289
[epoch11, step532]: loss 3.877583
[epoch11, step533]: loss 16.122501
[epoch11, step534]: loss 1.566402
[epoch11, step535]: loss 1.984269
[epoch11, step536]: loss 4.741288
[epoch11, step537]: loss 3.428512
[epoch11, step538]: loss 1.657759
[epoch11, step539]: loss 1.199418
[epoch11, step540]: loss 13.882044
[epoch11, step541]: loss 0.845374
[epoch11, step542]: loss 11.824288
[epoch11, step543]: loss 1.609492
[epoch11, step544]: loss 9.810562
[epoch11, step545]: loss 9.602359
[epoch11, step546]: loss 3.045888
[epoch11, step547]: loss 1.949579
[epoch11, step548]: loss 17.986910
[epoch11, step549]: loss 2.932297
[epoch11, step550]: loss 1.733292
[epoch11, step551]: loss 1.501292
[epoch11, step552]: loss 2.332471
[epoch11, step553]: loss 5.259137
[epoch11, step554]: loss 4.452762
[epoch11, step555]: loss 1.968792
[epoch11, step556]: loss 15.767884
[epoch11, step557]: loss 14.442026
[epoch11, step558]: loss 4.251250
[epoch11, step559]: loss 14.813018
[epoch11, step560]: loss 5.770157
[epoch11, step561]: loss 17.872631
[epoch11, step562]: loss 3.381229
[epoch11, step563]: loss 2.303736
[epoch11, step564]: loss 0.932817
[epoch11, step565]: loss 0.857272
[epoch11, step566]: loss 5.861558
[epoch11, step567]: loss 3.443292
[epoch11, step568]: loss 8.321057
[epoch11, step569]: loss 11.357606
[epoch11, step570]: loss 2.984859
[epoch11, step571]: loss 5.322039
[epoch11, step572]: loss 1.092283
[epoch11, step573]: loss 31.946453
[epoch11, step574]: loss 2.150818
[epoch11, step575]: loss 1.666033
[epoch11, step576]: loss 1.570543
[epoch11, step577]: loss 6.432755
[epoch11, step578]: loss 2.150296
[epoch11, step579]: loss 1.173765
[epoch11, step580]: loss 0.855052
[epoch11, step581]: loss 1.952052
[epoch11, step582]: loss 6.553026
[epoch11, step583]: loss 2.035814
[epoch11, step584]: loss 3.707516
[epoch11, step585]: loss 2.808772
[epoch11, step586]: loss 4.431545
[epoch11, step587]: loss 2.238100
[epoch11, step588]: loss 4.061537
[epoch11, step589]: loss 23.126137
[epoch11, step590]: loss 5.424786
[epoch11, step591]: loss 1.899002
[epoch11, step592]: loss 1.970109
[epoch11, step593]: loss 1.044689
[epoch11, step594]: loss 1.749549
[epoch11, step595]: loss 2.567114
[epoch11, step596]: loss 1.056387
[epoch11, step597]: loss 1.440673
[epoch11, step598]: loss 1.200493
[epoch11, step599]: loss 0.924138
[epoch11, step600]: loss 6.861685
[epoch11, step601]: loss 2.525492
[epoch11, step602]: loss 5.268245
[epoch11, step603]: loss 3.740355
[epoch11, step604]: loss 14.559368
[epoch11, step605]: loss 2.034414
[epoch11, step606]: loss 3.224486
[epoch11, step607]: loss 2.315037
[epoch11, step608]: loss 20.434532
[epoch11, step609]: loss 3.747180
[epoch11, step610]: loss 1.613977
[epoch11, step611]: loss 1.490843
[epoch11, step612]: loss 2.417961
[epoch11, step613]: loss 6.750579
[epoch11, step614]: loss 2.034246
[epoch11, step615]: loss 1.564077
[epoch11, step616]: loss 4.470432
[epoch11, step617]: loss 1.884629
[epoch11, step618]: loss 3.128040
[epoch11, step619]: loss 1.414973
[epoch11, step620]: loss 2.606640
[epoch11, step621]: loss 15.472777
[epoch11, step622]: loss 3.953489
[epoch11, step623]: loss 6.706214
[epoch11, step624]: loss 12.000533
[epoch11, step625]: loss 1.860406
[epoch11, step626]: loss 16.406715
[epoch11, step627]: loss 4.082748
[epoch11, step628]: loss 4.135589
[epoch11, step629]: loss 1.105585
[epoch11, step630]: loss 2.701121
[epoch11, step631]: loss 7.742460
[epoch11, step632]: loss 1.768183
[epoch11, step633]: loss 8.890379
[epoch11, step634]: loss 8.700259
[epoch11, step635]: loss 2.675731
[epoch11, step636]: loss 39.042088
[epoch11, step637]: loss 1.224357
[epoch11, step638]: loss 2.487212
[epoch11, step639]: loss 1.605636
[epoch11, step640]: loss 1.259685
[epoch11, step641]: loss 5.886030
[epoch11, step642]: loss 2.364085
[epoch11, step643]: loss 2.455878
[epoch11, step644]: loss 14.025280
[epoch11, step645]: loss 4.357066
[epoch11, step646]: loss 1.373134
[epoch11, step647]: loss 16.440201
[epoch11, step648]: loss 2.318026
[epoch11, step649]: loss 1.158934
[epoch11, step650]: loss 18.880686
[epoch11, step651]: loss 1.383239
[epoch11, step652]: loss 3.842579
[epoch11, step653]: loss 2.183153
[epoch11, step654]: loss 1.916352
[epoch11, step655]: loss 4.040916
[epoch11, step656]: loss 1.360139
[epoch11, step657]: loss 3.126890
[epoch11, step658]: loss 2.625190
[epoch11, step659]: loss 1.219454
[epoch11, step660]: loss 3.856481
[epoch11, step661]: loss 11.163630
[epoch11, step662]: loss 3.342178
[epoch11, step663]: loss 2.441937
[epoch11, step664]: loss 1.594381
[epoch11, step665]: loss 1.135380
[epoch11, step666]: loss 1.566386
[epoch11, step667]: loss 13.343434
[epoch11, step668]: loss 1.595426
[epoch11, step669]: loss 1.308775
[epoch11, step670]: loss 12.953472
[epoch11, step671]: loss 20.418880
[epoch11, step672]: loss 1.253024
[epoch11, step673]: loss 2.219386
[epoch11, step674]: loss 4.789196
[epoch11, step675]: loss 10.781364
[epoch11, step676]: loss 9.575251
[epoch11, step677]: loss 2.616713
[epoch11, step678]: loss 3.165703
[epoch11, step679]: loss 9.603247
[epoch11, step680]: loss 1.315509
[epoch11, step681]: loss 8.676261
[epoch11, step682]: loss 2.717831
[epoch11, step683]: loss 11.568148
[epoch11, step684]: loss 20.120831
[epoch11, step685]: loss 1.942534
[epoch11, step686]: loss 1.415736
[epoch11, step687]: loss 2.561391
[epoch11, step688]: loss 27.644516
[epoch11, step689]: loss 2.589485
[epoch11, step690]: loss 2.116350
[epoch11, step691]: loss 0.980092
[epoch11, step692]: loss 2.625155
[epoch11, step693]: loss 3.486462
[epoch11, step694]: loss 3.003405
[epoch11, step695]: loss 3.727190
[epoch11, step696]: loss 1.701432
[epoch11, step697]: loss 1.750055
[epoch11, step698]: loss 3.771627
[epoch11, step699]: loss 2.198610
[epoch11, step700]: loss 1.518819
[epoch11, step701]: loss 0.965809
[epoch11, step702]: loss 1.157364
[epoch11, step703]: loss 11.472439
[epoch11, step704]: loss 24.295908
[epoch11, step705]: loss 1.248439
[epoch11, step706]: loss 13.331048
[epoch11, step707]: loss 1.671120
[epoch11, step708]: loss 1.100506
[epoch11, step709]: loss 3.410634
[epoch11, step710]: loss 5.191376
[epoch11, step711]: loss 3.591875
[epoch11, step712]: loss 1.789016
[epoch11, step713]: loss 0.873273
[epoch11, step714]: loss 1.843715
[epoch11, step715]: loss 0.855244
[epoch11, step716]: loss 9.669720
[epoch11, step717]: loss 9.694521
[epoch11, step718]: loss 1.356275
[epoch11, step719]: loss 26.109701
[epoch11, step720]: loss 2.585678
[epoch11, step721]: loss 1.618513
[epoch11, step722]: loss 15.025076
[epoch11, step723]: loss 22.052563
[epoch11, step724]: loss 1.675403
[epoch11, step725]: loss 4.909669
[epoch11, step726]: loss 4.033970
[epoch11, step727]: loss 2.355990
[epoch11, step728]: loss 13.455250
[epoch11, step729]: loss 2.565363
[epoch11, step730]: loss 1.298912
[epoch11, step731]: loss 1.632734
[epoch11, step732]: loss 24.088001
[epoch11, step733]: loss 11.291905
[epoch11, step734]: loss 1.274163
[epoch11, step735]: loss 1.387980
[epoch11, step736]: loss 0.876758
[epoch11, step737]: loss 1.531102
[epoch11, step738]: loss 4.704169
[epoch11, step739]: loss 19.473785
[epoch11, step740]: loss 1.639864
[epoch11, step741]: loss 1.431571
[epoch11, step742]: loss 5.463385
[epoch11, step743]: loss 2.646284
[epoch11, step744]: loss 15.826612
[epoch11, step745]: loss 2.633667
[epoch11, step746]: loss 15.670040
[epoch11, step747]: loss 20.599291
[epoch11, step748]: loss 6.647596
[epoch11, step749]: loss 9.359178
[epoch11, step750]: loss 3.305624
[epoch11, step751]: loss 1.327967
[epoch11, step752]: loss 3.298335
[epoch11, step753]: loss 5.727966
[epoch11, step754]: loss 13.327554
[epoch11, step755]: loss 8.863008
[epoch11, step756]: loss 2.528536
[epoch11, step757]: loss 9.696677
[epoch11, step758]: loss 1.525658
[epoch11, step759]: loss 2.210541
[epoch11, step760]: loss 3.157186
[epoch11, step761]: loss 5.654754
[epoch11, step762]: loss 1.397491
[epoch11, step763]: loss 1.285963
[epoch11, step764]: loss 7.136405
[epoch11, step765]: loss 1.593224
[epoch11, step766]: loss 2.794684
[epoch11, step767]: loss 1.038042
[epoch11, step768]: loss 2.227892
[epoch11, step769]: loss 5.123030
[epoch11, step770]: loss 1.765889
[epoch11, step771]: loss 5.676292
[epoch11, step772]: loss 2.420079
[epoch11, step773]: loss 0.819999
[epoch11, step774]: loss 1.373412
[epoch11, step775]: loss 13.241474
[epoch11, step776]: loss 1.192830
[epoch11, step777]: loss 20.759506
[epoch11, step778]: loss 1.230989
[epoch11, step779]: loss 1.537307
[epoch11, step780]: loss 4.082983
[epoch11, step781]: loss 1.249198
[epoch11, step782]: loss 8.372406
[epoch11, step783]: loss 2.388192
[epoch11, step784]: loss 3.161259
[epoch11, step785]: loss 2.026842
[epoch11, step786]: loss 3.933108
[epoch11, step787]: loss 14.642023
[epoch11, step788]: loss 3.565432
[epoch11, step789]: loss 1.983588
[epoch11, step790]: loss 1.105846
[epoch11, step791]: loss 2.753980
[epoch11, step792]: loss 8.736324
[epoch11, step793]: loss 1.251044
[epoch11, step794]: loss 1.747763
[epoch11, step795]: loss 3.870638
[epoch11, step796]: loss 1.030625
[epoch11, step797]: loss 2.887396
[epoch11, step798]: loss 0.975680
[epoch11, step799]: loss 17.606371
[epoch11, step800]: loss 3.785825
[epoch11, step801]: loss 1.361908
[epoch11, step802]: loss 1.256762
[epoch11, step803]: loss 5.232732
[epoch11, step804]: loss 0.801510
[epoch11, step805]: loss 1.512739
[epoch11, step806]: loss 4.553077
[epoch11, step807]: loss 4.335657
[epoch11, step808]: loss 2.543305
[epoch11, step809]: loss 8.085991
[epoch11, step810]: loss 1.854420
[epoch11, step811]: loss 1.301695
[epoch11, step812]: loss 1.945326
[epoch11, step813]: loss 3.378722
[epoch11, step814]: loss 10.032972
[epoch11, step815]: loss 6.804843
[epoch11, step816]: loss 1.449975
[epoch11, step817]: loss 1.072556
[epoch11, step818]: loss 2.836159
[epoch11, step819]: loss 5.238613
[epoch11, step820]: loss 4.114422
[epoch11, step821]: loss 2.499453
[epoch11, step822]: loss 2.339133
[epoch11, step823]: loss 1.650262
[epoch11, step824]: loss 17.761251
[epoch11, step825]: loss 1.228944
[epoch11, step826]: loss 3.517234
[epoch11, step827]: loss 7.029593
[epoch11, step828]: loss 1.401588
[epoch11, step829]: loss 1.001713
[epoch11, step830]: loss 1.445886
[epoch11, step831]: loss 5.501136
[epoch11, step832]: loss 2.185239
[epoch11, step833]: loss 1.848684
[epoch11, step834]: loss 15.139063
[epoch11, step835]: loss 1.237263
[epoch11, step836]: loss 1.869982
[epoch11, step837]: loss 1.908543
[epoch11, step838]: loss 37.898994
[epoch11, step839]: loss 1.177870
[epoch11, step840]: loss 1.900943
[epoch11, step841]: loss 4.810576
[epoch11, step842]: loss 10.895445
[epoch11, step843]: loss 12.632657
[epoch11, step844]: loss 2.275792
[epoch11, step845]: loss 1.794453
[epoch11, step846]: loss 2.013647
[epoch11, step847]: loss 2.242183
[epoch11, step848]: loss 1.044153
[epoch11, step849]: loss 5.079138
[epoch11, step850]: loss 3.111930
[epoch11, step851]: loss 1.731814
[epoch11, step852]: loss 8.195716
[epoch11, step853]: loss 1.053159
[epoch11, step854]: loss 2.183388
[epoch11, step855]: loss 0.994142
[epoch11, step856]: loss 2.437451
[epoch11, step857]: loss 2.255456
[epoch11, step858]: loss 1.183250
[epoch11, step859]: loss 1.151514
[epoch11, step860]: loss 1.259515
[epoch11, step861]: loss 5.062128
[epoch11, step862]: loss 3.243232
[epoch11, step863]: loss 3.302920
[epoch11, step864]: loss 4.177979
[epoch11, step865]: loss 1.917562
[epoch11, step866]: loss 3.718160
[epoch11, step867]: loss 0.748780
[epoch11, step868]: loss 2.101231
[epoch11, step869]: loss 1.916150
[epoch11, step870]: loss 2.241592
[epoch11, step871]: loss 1.219146
[epoch11, step872]: loss 12.939109
[epoch11, step873]: loss 6.410276
[epoch11, step874]: loss 0.994505
[epoch11, step875]: loss 1.476184
[epoch11, step876]: loss 1.237090
[epoch11, step877]: loss 1.962826
[epoch11, step878]: loss 2.358641
[epoch11, step879]: loss 6.353776
[epoch11, step880]: loss 6.081777
[epoch11, step881]: loss 0.695853
[epoch11, step882]: loss 3.967790
[epoch11, step883]: loss 1.667876
[epoch11, step884]: loss 1.180350
[epoch11, step885]: loss 10.361257
[epoch11, step886]: loss 2.215099
[epoch11, step887]: loss 1.162707
[epoch11, step888]: loss 2.741010
[epoch11, step889]: loss 11.724152
[epoch11, step890]: loss 0.928206
[epoch11, step891]: loss 3.352251
[epoch11, step892]: loss 3.412880
[epoch11, step893]: loss 2.944867
[epoch11, step894]: loss 4.688116
[epoch11, step895]: loss 6.830738
[epoch11, step896]: loss 3.932724
[epoch11, step897]: loss 4.064364
[epoch11, step898]: loss 0.904561
[epoch11, step899]: loss 23.191896
[epoch11, step900]: loss 2.579373
[epoch11, step901]: loss 1.822432
[epoch11, step902]: loss 1.795635
[epoch11, step903]: loss 18.673809
[epoch11, step904]: loss 2.131362
[epoch11, step905]: loss 2.656314
[epoch11, step906]: loss 1.956372
[epoch11, step907]: loss 1.546853
[epoch11, step908]: loss 1.329218
[epoch11, step909]: loss 1.747515
[epoch11, step910]: loss 12.539645
[epoch11, step911]: loss 2.235377
[epoch11, step912]: loss 1.164820
[epoch11, step913]: loss 16.092594
[epoch11, step914]: loss 2.943578
[epoch11, step915]: loss 4.652030
[epoch11, step916]: loss 1.988927
[epoch11, step917]: loss 2.316532
[epoch11, step918]: loss 11.368481
[epoch11, step919]: loss 2.852803
[epoch11, step920]: loss 9.164660
[epoch11, step921]: loss 1.434164
[epoch11, step922]: loss 2.134218
[epoch11, step923]: loss 13.252884
[epoch11, step924]: loss 2.622066
[epoch11, step925]: loss 1.943399
[epoch11, step926]: loss 3.192816
[epoch11, step927]: loss 1.251000
[epoch11, step928]: loss 0.936808
[epoch11, step929]: loss 3.987753
[epoch11, step930]: loss 1.418721
[epoch11, step931]: loss 1.467692
[epoch11, step932]: loss 1.446991
[epoch11, step933]: loss 1.535318
[epoch11, step934]: loss 1.069036
[epoch11, step935]: loss 6.678017
[epoch11, step936]: loss 1.415906
[epoch11, step937]: loss 0.943057
[epoch11, step938]: loss 15.681611
[epoch11, step939]: loss 1.843737
[epoch11, step940]: loss 4.483327
[epoch11, step941]: loss 9.530809
[epoch11, step942]: loss 1.873044
[epoch11, step943]: loss 2.424403
[epoch11, step944]: loss 2.757600
[epoch11, step945]: loss 2.905762
[epoch11, step946]: loss 17.303511
[epoch11, step947]: loss 1.451558
[epoch11, step948]: loss 1.836699
[epoch11, step949]: loss 5.475263
[epoch11, step950]: loss 36.816273
[epoch11, step951]: loss 1.275727
[epoch11, step952]: loss 1.483142
[epoch11, step953]: loss 11.222906
[epoch11, step954]: loss 1.648239
[epoch11, step955]: loss 3.675364
[epoch11, step956]: loss 3.242676
[epoch11, step957]: loss 7.079997
[epoch11, step958]: loss 15.864284
[epoch11, step959]: loss 8.732195
[epoch11, step960]: loss 1.683633
[epoch11, step961]: loss 1.521961
[epoch11, step962]: loss 15.672915
[epoch11, step963]: loss 1.239449
[epoch11, step964]: loss 0.891555
[epoch11, step965]: loss 6.441109
[epoch11, step966]: loss 11.599111
[epoch11, step967]: loss 9.515057
[epoch11, step968]: loss 2.781214
[epoch11, step969]: loss 0.899024
[epoch11, step970]: loss 1.381105
[epoch11, step971]: loss 15.617678
[epoch11, step972]: loss 1.460374
[epoch11, step973]: loss 3.760781
[epoch11, step974]: loss 1.324307
[epoch11, step975]: loss 1.455193
[epoch11, step976]: loss 4.422981
[epoch11, step977]: loss 1.796964
[epoch11, step978]: loss 4.861772
[epoch11, step979]: loss 8.301767
[epoch11, step980]: loss 2.178401
[epoch11, step981]: loss 1.047693
[epoch11, step982]: loss 11.224586
[epoch11, step983]: loss 1.592707
[epoch11, step984]: loss 24.905569
[epoch11, step985]: loss 9.642871
[epoch11, step986]: loss 10.602224
[epoch11, step987]: loss 2.387190
[epoch11, step988]: loss 22.429665
[epoch11, step989]: loss 14.876549
[epoch11, step990]: loss 1.312336
[epoch11, step991]: loss 12.313070
[epoch11, step992]: loss 8.754607
[epoch11, step993]: loss 0.958954
[epoch11, step994]: loss 16.231236
[epoch11, step995]: loss 1.064421
[epoch11, step996]: loss 10.125918
[epoch11, step997]: loss 1.743163
[epoch11, step998]: loss 29.495907
[epoch11, step999]: loss 8.391967
[epoch11, step1000]: loss 1.936953
[epoch11, step1001]: loss 23.026129
[epoch11, step1002]: loss 2.765887
[epoch11, step1003]: loss 2.937350
[epoch11, step1004]: loss 1.802592
[epoch11, step1005]: loss 2.819341
[epoch11, step1006]: loss 12.114387
[epoch11, step1007]: loss 9.206960
[epoch11, step1008]: loss 2.290629
[epoch11, step1009]: loss 3.049518
[epoch11, step1010]: loss 12.380451
[epoch11, step1011]: loss 4.935535
[epoch11, step1012]: loss 2.385951
[epoch11, step1013]: loss 2.229833
[epoch11, step1014]: loss 29.596394
[epoch11, step1015]: loss 1.204362
[epoch11, step1016]: loss 8.899708
[epoch11, step1017]: loss 10.878377
[epoch11, step1018]: loss 2.962086
[epoch11, step1019]: loss 2.339678
[epoch11, step1020]: loss 7.448981
[epoch11, step1021]: loss 22.296745
[epoch11, step1022]: loss 24.354746
[epoch11, step1023]: loss 6.408491
[epoch11, step1024]: loss 1.790848
[epoch11, step1025]: loss 8.224816
[epoch11, step1026]: loss 27.634281
[epoch11, step1027]: loss 2.646053
[epoch11, step1028]: loss 4.233322
[epoch11, step1029]: loss 3.936966
[epoch11, step1030]: loss 3.669046
[epoch11, step1031]: loss 3.118276
[epoch11, step1032]: loss 1.237221
[epoch11, step1033]: loss 2.127813
[epoch11, step1034]: loss 2.131720
[epoch11, step1035]: loss 1.680648
[epoch11, step1036]: loss 2.422319
[epoch11, step1037]: loss 6.202713
[epoch11, step1038]: loss 10.249580
[epoch11, step1039]: loss 1.694329
[epoch11, step1040]: loss 1.336650
[epoch11, step1041]: loss 1.189098
[epoch11, step1042]: loss 1.518770
[epoch11, step1043]: loss 1.138569
[epoch11, step1044]: loss 4.928896
[epoch11, step1045]: loss 3.363766
[epoch11, step1046]: loss 1.087168
[epoch11, step1047]: loss 13.774087
[epoch11, step1048]: loss 9.038406
[epoch11, step1049]: loss 1.511960
[epoch11, step1050]: loss 11.774296
[epoch11, step1051]: loss 3.606939
[epoch11, step1052]: loss 3.863416
[epoch11, step1053]: loss 1.690989
[epoch11, step1054]: loss 13.041411
[epoch11, step1055]: loss 1.227051
[epoch11, step1056]: loss 2.451230
[epoch11, step1057]: loss 7.504095
[epoch11, step1058]: loss 3.112751
[epoch11, step1059]: loss 6.499605
[epoch11, step1060]: loss 1.804438
[epoch11, step1061]: loss 1.723283
[epoch11, step1062]: loss 2.970320
[epoch11, step1063]: loss 23.803717
[epoch11, step1064]: loss 1.540557
[epoch11, step1065]: loss 15.137821
[epoch11, step1066]: loss 2.140553
[epoch11, step1067]: loss 3.174959
[epoch11, step1068]: loss 13.348600
[epoch11, step1069]: loss 19.573957
[epoch11, step1070]: loss 3.120649
[epoch11, step1071]: loss 3.203203
[epoch11, step1072]: loss 11.396408
[epoch11, step1073]: loss 0.829883
[epoch11, step1074]: loss 2.071701
[epoch11, step1075]: loss 1.813340
[epoch11, step1076]: loss 0.766332
[epoch11, step1077]: loss 1.330621
[epoch11, step1078]: loss 11.941585
[epoch11, step1079]: loss 3.294292
[epoch11, step1080]: loss 1.569362
[epoch11, step1081]: loss 2.037998
[epoch11, step1082]: loss 1.243868
[epoch11, step1083]: loss 1.081791
[epoch11, step1084]: loss 13.652298
[epoch11, step1085]: loss 2.580058
[epoch11, step1086]: loss 0.815468
[epoch11, step1087]: loss 1.595829
[epoch11, step1088]: loss 1.945194
[epoch11, step1089]: loss 1.624442
[epoch11, step1090]: loss 2.076523
[epoch11, step1091]: loss 15.902370
[epoch11, step1092]: loss 1.524748
[epoch11, step1093]: loss 3.566551
[epoch11, step1094]: loss 0.881402
[epoch11, step1095]: loss 1.675946
[epoch11, step1096]: loss 4.008797
[epoch11, step1097]: loss 7.473252
[epoch11, step1098]: loss 3.082064
[epoch11, step1099]: loss 0.753623
[epoch11, step1100]: loss 2.651865
[epoch11, step1101]: loss 8.133896
[epoch11, step1102]: loss 5.608624
[epoch11, step1103]: loss 1.500777
[epoch11, step1104]: loss 4.315068
[epoch11, step1105]: loss 1.153196
[epoch11, step1106]: loss 19.985657
[epoch11, step1107]: loss 7.093531
[epoch11, step1108]: loss 1.439828
[epoch11, step1109]: loss 4.203497
[epoch11, step1110]: loss 1.015660
[epoch11, step1111]: loss 1.082641
[epoch11, step1112]: loss 1.807077
[epoch11, step1113]: loss 2.053056
[epoch11, step1114]: loss 23.649208
[epoch11, step1115]: loss 26.685759
[epoch11, step1116]: loss 0.838612
[epoch11, step1117]: loss 1.710217
[epoch11, step1118]: loss 2.560883
[epoch11, step1119]: loss 18.842115
[epoch11, step1120]: loss 2.858330
[epoch11, step1121]: loss 1.734532
[epoch11, step1122]: loss 6.345435
[epoch11, step1123]: loss 4.072090
[epoch11, step1124]: loss 3.675490
[epoch11, step1125]: loss 22.698303
[epoch11, step1126]: loss 6.384328
[epoch11, step1127]: loss 7.856022
[epoch11, step1128]: loss 11.004291
[epoch11, step1129]: loss 1.504975
[epoch11, step1130]: loss 6.230423
[epoch11, step1131]: loss 1.385009
[epoch11, step1132]: loss 5.233684
[epoch11, step1133]: loss 1.336823
[epoch11, step1134]: loss 2.229884
[epoch11, step1135]: loss 4.127123
[epoch11, step1136]: loss 1.505803
[epoch11, step1137]: loss 1.663483
[epoch11, step1138]: loss 5.644544
[epoch11, step1139]: loss 2.645995
[epoch11, step1140]: loss 1.222496
[epoch11, step1141]: loss 3.016306
[epoch11, step1142]: loss 3.891572
[epoch11, step1143]: loss 4.528955
[epoch11, step1144]: loss 3.782928
[epoch11, step1145]: loss 2.699361
[epoch11, step1146]: loss 3.972347
[epoch11, step1147]: loss 1.451638
[epoch11, step1148]: loss 7.824403
[epoch11, step1149]: loss 1.126200
[epoch11, step1150]: loss 3.201356
[epoch11, step1151]: loss 4.214522
[epoch11, step1152]: loss 1.610533
[epoch11, step1153]: loss 3.518353
[epoch11, step1154]: loss 11.494662
[epoch11, step1155]: loss 13.018830
[epoch11, step1156]: loss 1.986488
[epoch11, step1157]: loss 10.494407
[epoch11, step1158]: loss 19.685434
[epoch11, step1159]: loss 2.147412
[epoch11, step1160]: loss 1.478152
[epoch11, step1161]: loss 3.175189
[epoch11, step1162]: loss 3.209629
[epoch11, step1163]: loss 2.918198
[epoch11, step1164]: loss 2.964953
[epoch11, step1165]: loss 1.000464
[epoch11, step1166]: loss 10.621174
[epoch11, step1167]: loss 8.614734
[epoch11, step1168]: loss 9.958160
[epoch11, step1169]: loss 2.832771
[epoch11, step1170]: loss 0.951105
[epoch11, step1171]: loss 5.778600
[epoch11, step1172]: loss 0.981265
[epoch11, step1173]: loss 3.504119
[epoch11, step1174]: loss 1.129975
[epoch11, step1175]: loss 9.732445
[epoch11, step1176]: loss 0.748354
[epoch11, step1177]: loss 1.441392
[epoch11, step1178]: loss 6.771992
[epoch11, step1179]: loss 4.310267
[epoch11, step1180]: loss 13.895116
[epoch11, step1181]: loss 1.339675
[epoch11, step1182]: loss 2.624388
[epoch11, step1183]: loss 1.298517
[epoch11, step1184]: loss 10.227677
[epoch11, step1185]: loss 0.827641
[epoch11, step1186]: loss 19.406149
[epoch11, step1187]: loss 1.731072
[epoch11, step1188]: loss 20.451605
[epoch11, step1189]: loss 1.029862
[epoch11, step1190]: loss 1.020260
[epoch11, step1191]: loss 11.065448
[epoch11, step1192]: loss 14.683727
[epoch11, step1193]: loss 2.109651
[epoch11, step1194]: loss 3.103710
[epoch11, step1195]: loss 1.943661
[epoch11, step1196]: loss 1.486773
[epoch11, step1197]: loss 2.526257
[epoch11, step1198]: loss 1.265228
[epoch11, step1199]: loss 2.984096
[epoch11, step1200]: loss 2.741329
[epoch11, step1201]: loss 1.623995
[epoch11, step1202]: loss 1.871066
[epoch11, step1203]: loss 19.901627
[epoch11, step1204]: loss 10.524846
[epoch11, step1205]: loss 1.498195
[epoch11, step1206]: loss 2.244780
[epoch11, step1207]: loss 1.135437
[epoch11, step1208]: loss 1.059934
[epoch11, step1209]: loss 2.283606
[epoch11, step1210]: loss 1.031070
[epoch11, step1211]: loss 2.557266
[epoch11, step1212]: loss 4.790694
[epoch11, step1213]: loss 20.045675
[epoch11, step1214]: loss 1.894906
[epoch11, step1215]: loss 1.182912
[epoch11, step1216]: loss 3.976644
[epoch11, step1217]: loss 1.282683
[epoch11, step1218]: loss 9.798428
[epoch11, step1219]: loss 2.133427
[epoch11, step1220]: loss 5.691013
[epoch11, step1221]: loss 1.106647
[epoch11, step1222]: loss 11.389097
[epoch11, step1223]: loss 15.494299
[epoch11, step1224]: loss 1.670391
[epoch11, step1225]: loss 2.495947
[epoch11, step1226]: loss 6.771149
[epoch11, step1227]: loss 2.118902
[epoch11, step1228]: loss 2.565507
[epoch11, step1229]: loss 1.224693
[epoch11, step1230]: loss 20.590450
[epoch11, step1231]: loss 1.386775
[epoch11, step1232]: loss 9.119154
[epoch11, step1233]: loss 17.534662
[epoch11, step1234]: loss 13.260972
[epoch11, step1235]: loss 6.398587
[epoch11, step1236]: loss 1.371263
[epoch11, step1237]: loss 17.485691
[epoch11, step1238]: loss 0.944885
[epoch11, step1239]: loss 7.836477
[epoch11, step1240]: loss 25.022789
[epoch11, step1241]: loss 2.065904
[epoch11, step1242]: loss 1.578845
[epoch11, step1243]: loss 2.861400
[epoch11, step1244]: loss 20.248915
[epoch11, step1245]: loss 36.074081
[epoch11, step1246]: loss 1.361039
[epoch11, step1247]: loss 3.297104
[epoch11, step1248]: loss 2.366001
[epoch11, step1249]: loss 1.864390
[epoch11, step1250]: loss 19.014977
[epoch11, step1251]: loss 1.053032
[epoch11, step1252]: loss 3.097597
[epoch11, step1253]: loss 1.764678
[epoch11, step1254]: loss 5.928730
[epoch11, step1255]: loss 0.861668
[epoch11, step1256]: loss 1.306275
[epoch11, step1257]: loss 2.949023
[epoch11, step1258]: loss 0.872471
[epoch11, step1259]: loss 2.179141
[epoch11, step1260]: loss 2.041493
[epoch11, step1261]: loss 2.128574
[epoch11, step1262]: loss 13.115654
[epoch11, step1263]: loss 2.090622
[epoch11, step1264]: loss 5.580966
[epoch11, step1265]: loss 14.675186
[epoch11, step1266]: loss 11.078094
[epoch11, step1267]: loss 3.172378
[epoch11, step1268]: loss 3.546551
[epoch11, step1269]: loss 3.261161
[epoch11, step1270]: loss 15.388272
[epoch11, step1271]: loss 1.840688
[epoch11, step1272]: loss 4.489787
[epoch11, step1273]: loss 2.520830
[epoch11, step1274]: loss 20.296328
[epoch11, step1275]: loss 1.443577
[epoch11, step1276]: loss 4.384180
[epoch11, step1277]: loss 10.183408
[epoch11, step1278]: loss 3.008701
[epoch11, step1279]: loss 0.741611
[epoch11, step1280]: loss 1.167992
[epoch11, step1281]: loss 1.499919
[epoch11, step1282]: loss 11.571881
[epoch11, step1283]: loss 2.122743
[epoch11, step1284]: loss 1.199944
[epoch11, step1285]: loss 1.798164
[epoch11, step1286]: loss 0.726371
[epoch11, step1287]: loss 1.011994
[epoch11, step1288]: loss 1.514661
[epoch11, step1289]: loss 16.746914
[epoch11, step1290]: loss 19.872065
[epoch11, step1291]: loss 27.152731
[epoch11, step1292]: loss 3.859363
[epoch11, step1293]: loss 6.368626
[epoch11, step1294]: loss 3.981215
[epoch11, step1295]: loss 0.995094
[epoch11, step1296]: loss 10.294316
[epoch11, step1297]: loss 1.505737
[epoch11, step1298]: loss 1.849244
[epoch11, step1299]: loss 2.392754
[epoch11, step1300]: loss 1.979240
[epoch11, step1301]: loss 1.518417
[epoch11, step1302]: loss 16.949875
[epoch11, step1303]: loss 7.737648
[epoch11, step1304]: loss 1.654846
[epoch11, step1305]: loss 10.739149
[epoch11, step1306]: loss 1.292543
[epoch11, step1307]: loss 9.532176
[epoch11, step1308]: loss 1.513512
[epoch11, step1309]: loss 4.973508
[epoch11, step1310]: loss 2.351970
[epoch11, step1311]: loss 3.039430
[epoch11, step1312]: loss 1.519563
[epoch11, step1313]: loss 21.648144
[epoch11, step1314]: loss 21.783932
[epoch11, step1315]: loss 14.204498
[epoch11, step1316]: loss 3.788859
[epoch11, step1317]: loss 9.635644
[epoch11, step1318]: loss 1.081356
[epoch11, step1319]: loss 13.468325
[epoch11, step1320]: loss 1.810404
[epoch11, step1321]: loss 1.580031
[epoch11, step1322]: loss 1.768693
[epoch11, step1323]: loss 1.220853
[epoch11, step1324]: loss 1.833083
[epoch11, step1325]: loss 2.312743
[epoch11, step1326]: loss 3.044458
[epoch11, step1327]: loss 4.462547
[epoch11, step1328]: loss 1.581167
[epoch11, step1329]: loss 1.058966
[epoch11, step1330]: loss 3.823555
[epoch11, step1331]: loss 0.729784
[epoch11, step1332]: loss 2.834106
[epoch11, step1333]: loss 1.151607
[epoch11, step1334]: loss 10.657861
[epoch11, step1335]: loss 1.860491
[epoch11, step1336]: loss 1.349483
[epoch11, step1337]: loss 7.728959
[epoch11, step1338]: loss 3.408321
[epoch11, step1339]: loss 2.989972
[epoch11, step1340]: loss 2.820208
[epoch11, step1341]: loss 1.144374
[epoch11, step1342]: loss 1.579677
[epoch11, step1343]: loss 17.446892
[epoch11, step1344]: loss 1.526187
[epoch11, step1345]: loss 2.774277
[epoch11, step1346]: loss 16.184290
[epoch11, step1347]: loss 1.778097
[epoch11, step1348]: loss 29.646858
[epoch11, step1349]: loss 2.307710
[epoch11, step1350]: loss 3.757272
[epoch11, step1351]: loss 1.626103
[epoch11, step1352]: loss 1.863521
[epoch11, step1353]: loss 1.514779
[epoch11, step1354]: loss 12.414448
[epoch11, step1355]: loss 3.463246
[epoch11, step1356]: loss 9.791991
[epoch11, step1357]: loss 0.757530
[epoch11, step1358]: loss 1.464091
[epoch11, step1359]: loss 0.911328
[epoch11, step1360]: loss 1.439828
[epoch11, step1361]: loss 1.348961
[epoch11, step1362]: loss 12.547917
[epoch11, step1363]: loss 0.925844
[epoch11, step1364]: loss 3.143650
[epoch11, step1365]: loss 13.333675
[epoch11, step1366]: loss 10.098880
[epoch11, step1367]: loss 3.128020
[epoch11, step1368]: loss 8.830193
[epoch11, step1369]: loss 12.367371
[epoch11, step1370]: loss 1.636554
[epoch11, step1371]: loss 1.656307
[epoch11, step1372]: loss 1.205123
[epoch11, step1373]: loss 3.089165
[epoch11, step1374]: loss 1.654289
[epoch11, step1375]: loss 1.669338
[epoch11, step1376]: loss 16.058277
[epoch11, step1377]: loss 12.851633
[epoch11, step1378]: loss 4.577676
[epoch11, step1379]: loss 12.862388
[epoch11, step1380]: loss 1.660814
[epoch11, step1381]: loss 1.422972
[epoch11, step1382]: loss 2.267329
[epoch11, step1383]: loss 10.963961
[epoch11, step1384]: loss 2.215488
[epoch11, step1385]: loss 1.293860
[epoch11, step1386]: loss 31.424625
[epoch11, step1387]: loss 1.876453
[epoch11, step1388]: loss 0.855579
[epoch11, step1389]: loss 19.532465
[epoch11, step1390]: loss 7.080576
[epoch11, step1391]: loss 4.831985
[epoch11, step1392]: loss 1.159572
[epoch11, step1393]: loss 12.315805
[epoch11, step1394]: loss 1.284028
[epoch11, step1395]: loss 14.205206
[epoch11, step1396]: loss 10.583769
[epoch11, step1397]: loss 1.114097
[epoch11, step1398]: loss 1.706264
[epoch11, step1399]: loss 5.108239
[epoch11, step1400]: loss 1.489126
[epoch11, step1401]: loss 2.614372
[epoch11, step1402]: loss 4.027628
[epoch11, step1403]: loss 17.924906
[epoch11, step1404]: loss 0.978918
[epoch11, step1405]: loss 12.644680
[epoch11, step1406]: loss 15.941668
[epoch11, step1407]: loss 7.363738
[epoch11, step1408]: loss 1.508405
[epoch11, step1409]: loss 1.004025
[epoch11, step1410]: loss 2.826407
[epoch11, step1411]: loss 6.433652
[epoch11, step1412]: loss 2.000711
[epoch11, step1413]: loss 2.330752
[epoch11, step1414]: loss 7.844998
[epoch11, step1415]: loss 7.567697
[epoch11, step1416]: loss 31.071915
[epoch11, step1417]: loss 2.082725
[epoch11, step1418]: loss 14.282915
[epoch11, step1419]: loss 11.469735
[epoch11, step1420]: loss 1.793493
[epoch11, step1421]: loss 19.914843
[epoch11, step1422]: loss 31.663595
[epoch11, step1423]: loss 3.101374
[epoch11, step1424]: loss 10.002965
[epoch11, step1425]: loss 1.500609
[epoch11, step1426]: loss 1.156656
[epoch11, step1427]: loss 3.176135
[epoch11, step1428]: loss 9.926067
[epoch11, step1429]: loss 2.885026
[epoch11, step1430]: loss 13.903529
[epoch11, step1431]: loss 2.715742
[epoch11, step1432]: loss 1.477706
[epoch11, step1433]: loss 5.424631
[epoch11, step1434]: loss 1.450873
[epoch11, step1435]: loss 44.680031
[epoch11, step1436]: loss 2.634899
[epoch11, step1437]: loss 5.757523
[epoch11, step1438]: loss 15.940655
[epoch11, step1439]: loss 12.265264
[epoch11, step1440]: loss 2.199176
[epoch11, step1441]: loss 1.042937
[epoch11, step1442]: loss 18.492537
[epoch11, step1443]: loss 1.385576
[epoch11, step1444]: loss 8.016298
[epoch11, step1445]: loss 7.979450
[epoch11, step1446]: loss 1.167698
[epoch11, step1447]: loss 2.656219
[epoch11, step1448]: loss 27.647566
[epoch11, step1449]: loss 1.017341
[epoch11, step1450]: loss 1.964011
[epoch11, step1451]: loss 38.116562
[epoch11, step1452]: loss 0.969970
[epoch11, step1453]: loss 2.331028
[epoch11, step1454]: loss 1.756726
[epoch11, step1455]: loss 2.302413
[epoch11, step1456]: loss 1.300953
[epoch11, step1457]: loss 2.130938
[epoch11, step1458]: loss 2.991083
[epoch11, step1459]: loss 1.179396
[epoch11, step1460]: loss 1.020883
[epoch11, step1461]: loss 1.345389
[epoch11, step1462]: loss 13.064398
[epoch11, step1463]: loss 13.646761
[epoch11, step1464]: loss 6.739239
[epoch11, step1465]: loss 2.021555
[epoch11, step1466]: loss 13.355244
[epoch11, step1467]: loss 14.639220
[epoch11, step1468]: loss 2.429697
[epoch11, step1469]: loss 0.704079
[epoch11, step1470]: loss 2.009696
[epoch11, step1471]: loss 36.951786
[epoch11, step1472]: loss 1.060044
[epoch11, step1473]: loss 4.160958
[epoch11, step1474]: loss 3.938402
[epoch11, step1475]: loss 1.165767
[epoch11, step1476]: loss 8.514626
[epoch11, step1477]: loss 1.091911
[epoch11, step1478]: loss 1.370712
[epoch11, step1479]: loss 2.511793
[epoch11, step1480]: loss 13.107316
[epoch11, step1481]: loss 7.968932
[epoch11, step1482]: loss 2.915873
[epoch11, step1483]: loss 1.283990
[epoch11, step1484]: loss 2.777372
[epoch11, step1485]: loss 2.763593
[epoch11, step1486]: loss 12.013194
[epoch11, step1487]: loss 4.713315
[epoch11, step1488]: loss 3.053780
[epoch11, step1489]: loss 4.836906
[epoch11, step1490]: loss 14.279132
[epoch11, step1491]: loss 18.677471
[epoch11, step1492]: loss 2.429446
[epoch11, step1493]: loss 1.215723
[epoch11, step1494]: loss 2.735250
[epoch11, step1495]: loss 1.194572
[epoch11, step1496]: loss 1.782446
[epoch11, step1497]: loss 1.192241
[epoch11, step1498]: loss 1.177620
[epoch11, step1499]: loss 25.839407
[epoch11, step1500]: loss 1.856512
[epoch11, step1501]: loss 2.903526
[epoch11, step1502]: loss 21.774992
[epoch11, step1503]: loss 1.724339
[epoch11, step1504]: loss 2.354309
[epoch11, step1505]: loss 1.824714
[epoch11, step1506]: loss 11.370554
[epoch11, step1507]: loss 1.165804
[epoch11, step1508]: loss 10.459954
[epoch11, step1509]: loss 2.335798
[epoch11, step1510]: loss 3.083050
[epoch11, step1511]: loss 1.320048
[epoch11, step1512]: loss 1.039807
[epoch11, step1513]: loss 2.009858
[epoch11, step1514]: loss 12.484513
[epoch11, step1515]: loss 1.251274
[epoch11, step1516]: loss 2.214545
[epoch11, step1517]: loss 1.329301
[epoch11, step1518]: loss 12.517853
[epoch11, step1519]: loss 7.426503
[epoch11, step1520]: loss 1.736190
[epoch11, step1521]: loss 2.691361
[epoch11, step1522]: loss 2.161749
[epoch11, step1523]: loss 1.616576
[epoch11, step1524]: loss 2.949182
[epoch11, step1525]: loss 1.547287
[epoch11, step1526]: loss 1.111039
[epoch11, step1527]: loss 0.968101
[epoch11, step1528]: loss 2.954611
[epoch11, step1529]: loss 14.027995
[epoch11, step1530]: loss 4.283503
[epoch11, step1531]: loss 11.392773
[epoch11, step1532]: loss 10.920431
[epoch11, step1533]: loss 2.181771
[epoch11, step1534]: loss 4.062315
[epoch11, step1535]: loss 1.369488
[epoch11, step1536]: loss 1.777310
[epoch11, step1537]: loss 13.729041
[epoch11, step1538]: loss 1.312484
[epoch11, step1539]: loss 4.133239
[epoch11, step1540]: loss 1.087537
[epoch11, step1541]: loss 1.789985
[epoch11, step1542]: loss 1.449480
[epoch11, step1543]: loss 1.069920
[epoch11, step1544]: loss 14.353167
[epoch11, step1545]: loss 1.592381
[epoch11, step1546]: loss 2.278643
[epoch11, step1547]: loss 5.243845
[epoch11, step1548]: loss 3.540468
[epoch11, step1549]: loss 26.210888
[epoch11, step1550]: loss 2.453733
[epoch11, step1551]: loss 2.153440
[epoch11, step1552]: loss 0.984521
[epoch11, step1553]: loss 1.471300
[epoch11, step1554]: loss 0.858699
[epoch11, step1555]: loss 2.023989
[epoch11, step1556]: loss 3.302399
[epoch11, step1557]: loss 11.656084
[epoch11, step1558]: loss 6.557361
[epoch11, step1559]: loss 2.572611
[epoch11, step1560]: loss 2.883115
[epoch11, step1561]: loss 1.788581
[epoch11, step1562]: loss 0.945735
[epoch11, step1563]: loss 1.276157
[epoch11, step1564]: loss 1.263967
[epoch11, step1565]: loss 8.570391
[epoch11, step1566]: loss 11.724378
[epoch11, step1567]: loss 13.258415
[epoch11, step1568]: loss 1.756039
[epoch11, step1569]: loss 2.200596
[epoch11, step1570]: loss 5.712166
[epoch11, step1571]: loss 1.851885
[epoch11, step1572]: loss 5.200158
[epoch11, step1573]: loss 8.009050
[epoch11, step1574]: loss 1.807410
[epoch11, step1575]: loss 10.907049
[epoch11, step1576]: loss 12.435848
[epoch11, step1577]: loss 1.847900
[epoch11, step1578]: loss 2.026050
[epoch11, step1579]: loss 1.706487
[epoch11, step1580]: loss 1.096752
[epoch11, step1581]: loss 6.331540
[epoch11, step1582]: loss 1.979089
[epoch11, step1583]: loss 16.462250
[epoch11, step1584]: loss 1.482833
[epoch11, step1585]: loss 1.026757
[epoch11, step1586]: loss 3.708844
[epoch11, step1587]: loss 1.855560
[epoch11, step1588]: loss 3.583146
[epoch11, step1589]: loss 2.867147
[epoch11, step1590]: loss 9.489804
[epoch11, step1591]: loss 3.648144
[epoch11, step1592]: loss 3.703777
[epoch11, step1593]: loss 0.913642
[epoch11, step1594]: loss 0.977586
[epoch11, step1595]: loss 27.124239
[epoch11, step1596]: loss 2.873003
[epoch11, step1597]: loss 1.238632
[epoch11, step1598]: loss 11.390215
[epoch11, step1599]: loss 14.512485
[epoch11, step1600]: loss 1.784265
[epoch11, step1601]: loss 0.870249
[epoch11, step1602]: loss 13.175171
[epoch11, step1603]: loss 2.647996
[epoch11, step1604]: loss 14.317571
[epoch11, step1605]: loss 3.727813
[epoch11, step1606]: loss 2.861050
[epoch11, step1607]: loss 3.284157
[epoch11, step1608]: loss 14.065537
[epoch11, step1609]: loss 1.332312
[epoch11, step1610]: loss 2.222634
[epoch11, step1611]: loss 0.862464
[epoch11, step1612]: loss 1.124129
[epoch11, step1613]: loss 8.322117
[epoch11, step1614]: loss 2.010971
[epoch11, step1615]: loss 10.682779
[epoch11, step1616]: loss 1.276862
[epoch11, step1617]: loss 1.342278
[epoch11, step1618]: loss 0.661484
[epoch11, step1619]: loss 1.581677
[epoch11, step1620]: loss 24.118160
[epoch11, step1621]: loss 2.717705
[epoch11, step1622]: loss 3.288597
[epoch11, step1623]: loss 2.218183
[epoch11, step1624]: loss 3.217892
[epoch11, step1625]: loss 8.982731
[epoch11, step1626]: loss 4.478497
[epoch11, step1627]: loss 1.592732
[epoch11, step1628]: loss 1.272981
[epoch11, step1629]: loss 1.447474
[epoch11, step1630]: loss 19.503338
[epoch11, step1631]: loss 4.613622
[epoch11, step1632]: loss 18.615704
[epoch11, step1633]: loss 5.428611
[epoch11, step1634]: loss 19.894796
[epoch11, step1635]: loss 3.800521
[epoch11, step1636]: loss 2.353346
[epoch11, step1637]: loss 4.472089
[epoch11, step1638]: loss 2.327709
[epoch11, step1639]: loss 3.700164
[epoch11, step1640]: loss 7.788626
[epoch11, step1641]: loss 1.379311
[epoch11, step1642]: loss 7.878417
[epoch11, step1643]: loss 2.234957
[epoch11, step1644]: loss 5.857485
[epoch11, step1645]: loss 1.324020
[epoch11, step1646]: loss 10.700246
[epoch11, step1647]: loss 1.831964
[epoch11, step1648]: loss 1.909483
[epoch11, step1649]: loss 43.156170
[epoch11, step1650]: loss 1.938028
[epoch11, step1651]: loss 1.979795
[epoch11, step1652]: loss 1.415210
[epoch11, step1653]: loss 1.711278
[epoch11, step1654]: loss 11.054773
[epoch11, step1655]: loss 1.469204
[epoch11, step1656]: loss 1.671756
[epoch11, step1657]: loss 2.978250
[epoch11, step1658]: loss 1.225411
[epoch11, step1659]: loss 0.867369
[epoch11, step1660]: loss 0.598984
[epoch11, step1661]: loss 1.008878
[epoch11, step1662]: loss 10.216611
[epoch11, step1663]: loss 2.422750
[epoch11, step1664]: loss 1.135850
[epoch11, step1665]: loss 1.501844
[epoch11, step1666]: loss 10.016016
[epoch11, step1667]: loss 21.250586
[epoch11, step1668]: loss 7.368853
[epoch11, step1669]: loss 1.093123
[epoch11, step1670]: loss 1.144183
[epoch11, step1671]: loss 2.759850
[epoch11, step1672]: loss 1.039437
[epoch11, step1673]: loss 7.016970
[epoch11, step1674]: loss 1.511047
[epoch11, step1675]: loss 1.418051
[epoch11, step1676]: loss 14.198318
[epoch11, step1677]: loss 2.432577
[epoch11, step1678]: loss 4.105846
[epoch11, step1679]: loss 1.454976
[epoch11, step1680]: loss 5.932750
[epoch11, step1681]: loss 9.719641
[epoch11, step1682]: loss 1.844353
[epoch11, step1683]: loss 15.557437
[epoch11, step1684]: loss 1.394542
[epoch11, step1685]: loss 0.926962
[epoch11, step1686]: loss 1.343095
[epoch11, step1687]: loss 3.741039
[epoch11, step1688]: loss 1.997907
[epoch11, step1689]: loss 0.915293
[epoch11, step1690]: loss 17.229143
[epoch11, step1691]: loss 17.698568
[epoch11, step1692]: loss 2.766207
[epoch11, step1693]: loss 1.208618
[epoch11, step1694]: loss 2.670484
[epoch11, step1695]: loss 2.823663
[epoch11, step1696]: loss 10.135641
[epoch11, step1697]: loss 3.544878
[epoch11, step1698]: loss 1.172752
[epoch11, step1699]: loss 1.377995
[epoch11, step1700]: loss 1.964204
[epoch11, step1701]: loss 3.705609
[epoch11, step1702]: loss 14.714092
[epoch11, step1703]: loss 0.927923
[epoch11, step1704]: loss 2.406887
[epoch11, step1705]: loss 8.260186
[epoch11, step1706]: loss 2.753430
[epoch11, step1707]: loss 3.098070
[epoch11, step1708]: loss 1.102689
[epoch11, step1709]: loss 3.274922
[epoch11, step1710]: loss 3.655791
[epoch11, step1711]: loss 1.578213
[epoch11, step1712]: loss 2.849222
[epoch11, step1713]: loss 40.725483
[epoch11, step1714]: loss 9.027222
[epoch11, step1715]: loss 3.008430
[epoch11, step1716]: loss 1.473909
[epoch11, step1717]: loss 0.861975
[epoch11, step1718]: loss 5.331146
[epoch11, step1719]: loss 0.924020
[epoch11, step1720]: loss 0.882358
[epoch11, step1721]: loss 3.369681
[epoch11, step1722]: loss 6.364434
[epoch11, step1723]: loss 1.930011
[epoch11, step1724]: loss 16.022364
[epoch11, step1725]: loss 5.145536
[epoch11, step1726]: loss 19.975950
[epoch11, step1727]: loss 27.319340
[epoch11, step1728]: loss 1.697258
[epoch11, step1729]: loss 1.653791
[epoch11, step1730]: loss 1.442288
[epoch11, step1731]: loss 4.229489
[epoch11, step1732]: loss 8.676617
[epoch11, step1733]: loss 2.360578
[epoch11, step1734]: loss 1.046255
[epoch11, step1735]: loss 7.402370
[epoch11, step1736]: loss 0.799207
[epoch11, step1737]: loss 9.884562
[epoch11, step1738]: loss 1.052774
[epoch11, step1739]: loss 9.113916
[epoch11, step1740]: loss 11.485329
[epoch11, step1741]: loss 2.540041
[epoch11, step1742]: loss 1.863531
[epoch11, step1743]: loss 5.856722
[epoch11, step1744]: loss 6.151467
[epoch11, step1745]: loss 7.825577
[epoch11, step1746]: loss 41.949902
[epoch11, step1747]: loss 4.366794
[epoch11, step1748]: loss 4.275026
[epoch11, step1749]: loss 1.100074
[epoch11, step1750]: loss 1.377737
[epoch11, step1751]: loss 1.523592
[epoch11, step1752]: loss 17.878910
[epoch11, step1753]: loss 2.752412
[epoch11, step1754]: loss 1.521436
[epoch11, step1755]: loss 1.428809
[epoch11, step1756]: loss 1.750343
[epoch11, step1757]: loss 3.267334
[epoch11, step1758]: loss 1.925450
[epoch11, step1759]: loss 1.138492
[epoch11, step1760]: loss 7.504975
[epoch11, step1761]: loss 3.692366
[epoch11, step1762]: loss 10.287347
[epoch11, step1763]: loss 1.678249
[epoch11, step1764]: loss 37.950005
[epoch11, step1765]: loss 2.914315
[epoch11, step1766]: loss 1.264011
[epoch11, step1767]: loss 4.124207
[epoch11, step1768]: loss 2.780965
[epoch11, step1769]: loss 18.572334
[epoch11, step1770]: loss 2.755622
[epoch11, step1771]: loss 1.028861
[epoch11, step1772]: loss 3.031854
[epoch11, step1773]: loss 5.794380
[epoch11, step1774]: loss 1.481524
[epoch11, step1775]: loss 26.182804
[epoch11, step1776]: loss 1.492838
[epoch11, step1777]: loss 4.320610
[epoch11, step1778]: loss 14.923208
[epoch11, step1779]: loss 4.831461
[epoch11, step1780]: loss 10.551716
[epoch11, step1781]: loss 3.666944
[epoch11, step1782]: loss 1.685811
[epoch11, step1783]: loss 19.394167
[epoch11, step1784]: loss 8.860607
[epoch11, step1785]: loss 14.288533
[epoch11, step1786]: loss 9.131500
[epoch11, step1787]: loss 1.617259
[epoch11, step1788]: loss 1.532255
[epoch11, step1789]: loss 22.377813
[epoch11, step1790]: loss 3.085752
[epoch11, step1791]: loss 3.031718
[epoch11, step1792]: loss 2.266035
[epoch11, step1793]: loss 5.348840
[epoch11, step1794]: loss 1.914681
[epoch11, step1795]: loss 18.724749
[epoch11, step1796]: loss 2.115050
[epoch11, step1797]: loss 9.206018
[epoch11, step1798]: loss 1.139011
[epoch11, step1799]: loss 1.260646
[epoch11, step1800]: loss 1.140938
[epoch11, step1801]: loss 1.033143
[epoch11, step1802]: loss 1.253286
[epoch11, step1803]: loss 9.448962
[epoch11, step1804]: loss 2.497489
[epoch11, step1805]: loss 2.476919
[epoch11, step1806]: loss 4.829878
[epoch11, step1807]: loss 2.515508
[epoch11, step1808]: loss 2.299997
[epoch11, step1809]: loss 3.214981
[epoch11, step1810]: loss 10.148141
[epoch11, step1811]: loss 2.245765
[epoch11, step1812]: loss 1.609976
[epoch11, step1813]: loss 1.554818
[epoch11, step1814]: loss 1.824900
[epoch11, step1815]: loss 6.698818
[epoch11, step1816]: loss 8.547009
[epoch11, step1817]: loss 5.771324
[epoch11, step1818]: loss 1.423599
[epoch11, step1819]: loss 1.437089
[epoch11, step1820]: loss 5.255063
[epoch11, step1821]: loss 0.573795
[epoch11, step1822]: loss 2.937604
[epoch11, step1823]: loss 7.659800
[epoch11, step1824]: loss 4.616879
[epoch11, step1825]: loss 2.784635
[epoch11, step1826]: loss 1.448683
[epoch11, step1827]: loss 1.147038
[epoch11, step1828]: loss 1.085481
[epoch11, step1829]: loss 2.026081
[epoch11, step1830]: loss 5.955871
[epoch11, step1831]: loss 1.608079
[epoch11, step1832]: loss 3.265434
[epoch11, step1833]: loss 2.573124
[epoch11, step1834]: loss 2.066578
[epoch11, step1835]: loss 21.608664
[epoch11, step1836]: loss 17.702063
[epoch11, step1837]: loss 17.498394
[epoch11, step1838]: loss 1.733351
[epoch11, step1839]: loss 7.036231
[epoch11, step1840]: loss 2.463539
[epoch11, step1841]: loss 2.094467
[epoch11, step1842]: loss 7.700525
[epoch11, step1843]: loss 1.627047
[epoch11, step1844]: loss 6.846122
[epoch11, step1845]: loss 1.320185
[epoch11, step1846]: loss 22.209476
[epoch11, step1847]: loss 1.728057
[epoch11, step1848]: loss 7.527173
[epoch11, step1849]: loss 1.770153
[epoch11, step1850]: loss 5.380033
[epoch11, step1851]: loss 14.257928
[epoch11, step1852]: loss 1.497254
[epoch11, step1853]: loss 11.349028
[epoch11, step1854]: loss 5.093762
[epoch11, step1855]: loss 2.349190
[epoch11, step1856]: loss 25.470495
[epoch11, step1857]: loss 1.763420
[epoch11, step1858]: loss 10.724463
[epoch11, step1859]: loss 3.093541
[epoch11, step1860]: loss 1.745474
[epoch11, step1861]: loss 17.276115
[epoch11, step1862]: loss 1.281605
[epoch11, step1863]: loss 1.090716
[epoch11, step1864]: loss 1.540637
[epoch11, step1865]: loss 14.521289
[epoch11, step1866]: loss 2.400895
[epoch11, step1867]: loss 4.912875
[epoch11, step1868]: loss 0.989115
[epoch11, step1869]: loss 16.186563
[epoch11, step1870]: loss 5.100115
[epoch11, step1871]: loss 1.261560
[epoch11, step1872]: loss 1.614441
[epoch11, step1873]: loss 4.320591
[epoch11, step1874]: loss 1.149328
[epoch11, step1875]: loss 11.047920
[epoch11, step1876]: loss 4.375628
[epoch11, step1877]: loss 14.998223
[epoch11, step1878]: loss 1.501866
[epoch11, step1879]: loss 2.693018
[epoch11, step1880]: loss 2.011210
[epoch11, step1881]: loss 1.619231
[epoch11, step1882]: loss 6.004245
[epoch11, step1883]: loss 2.007350
[epoch11, step1884]: loss 1.143064
[epoch11, step1885]: loss 3.836696
[epoch11, step1886]: loss 14.360587
[epoch11, step1887]: loss 17.381451
[epoch11, step1888]: loss 1.147671
[epoch11, step1889]: loss 10.868793
[epoch11, step1890]: loss 24.292004
[epoch11, step1891]: loss 14.563896
[epoch11, step1892]: loss 3.953976
[epoch11, step1893]: loss 1.216069
[epoch11, step1894]: loss 2.573989
[epoch11, step1895]: loss 2.933788
[epoch11, step1896]: loss 19.343510
[epoch11, step1897]: loss 1.809354
[epoch11, step1898]: loss 1.262346
[epoch11, step1899]: loss 12.186121
[epoch11, step1900]: loss 1.324274
[epoch11, step1901]: loss 1.402657
[epoch11, step1902]: loss 1.281659
[epoch11, step1903]: loss 1.162817
[epoch11, step1904]: loss 3.259295
[epoch11, step1905]: loss 11.606563
[epoch11, step1906]: loss 10.912922
[epoch11, step1907]: loss 0.880008
[epoch11, step1908]: loss 12.333007
[epoch11, step1909]: loss 5.826980
[epoch11, step1910]: loss 27.093517
[epoch11, step1911]: loss 3.383358
[epoch11, step1912]: loss 1.224338
[epoch11, step1913]: loss 14.103564
[epoch11, step1914]: loss 1.698072
[epoch11, step1915]: loss 9.463975
[epoch11, step1916]: loss 0.838979
[epoch11, step1917]: loss 4.767078
[epoch11, step1918]: loss 1.505060
[epoch11, step1919]: loss 4.041395
[epoch11, step1920]: loss 21.915586
[epoch11, step1921]: loss 5.746508
[epoch11, step1922]: loss 10.647564
[epoch11, step1923]: loss 5.140557
[epoch11, step1924]: loss 2.613676
[epoch11, step1925]: loss 17.018782
[epoch11, step1926]: loss 3.342906
[epoch11, step1927]: loss 1.245817
[epoch11, step1928]: loss 1.481248
[epoch11, step1929]: loss 7.487947
[epoch11, step1930]: loss 15.350709
[epoch11, step1931]: loss 1.091420
[epoch11, step1932]: loss 1.441418
[epoch11, step1933]: loss 6.542822
[epoch11, step1934]: loss 1.225131
[epoch11, step1935]: loss 2.853958
[epoch11, step1936]: loss 1.274377
[epoch11, step1937]: loss 2.855665
[epoch11, step1938]: loss 14.999966
[epoch11, step1939]: loss 5.047207
[epoch11, step1940]: loss 12.339795
[epoch11, step1941]: loss 2.002263
[epoch11, step1942]: loss 1.421085
[epoch11, step1943]: loss 13.513899
[epoch11, step1944]: loss 2.653846
[epoch11, step1945]: loss 1.628695
[epoch11, step1946]: loss 6.167543
[epoch11, step1947]: loss 2.195741
[epoch11, step1948]: loss 4.434283
[epoch11, step1949]: loss 11.644248
[epoch11, step1950]: loss 9.534541
[epoch11, step1951]: loss 6.949666
[epoch11, step1952]: loss 12.396296
[epoch11, step1953]: loss 2.072186
[epoch11, step1954]: loss 2.050944
[epoch11, step1955]: loss 0.799787
[epoch11, step1956]: loss 1.569522
[epoch11, step1957]: loss 1.954014
[epoch11, step1958]: loss 7.938554
[epoch11, step1959]: loss 1.170389
[epoch11, step1960]: loss 1.254445
[epoch11, step1961]: loss 2.614644
[epoch11, step1962]: loss 1.434491
[epoch11, step1963]: loss 11.076738
[epoch11, step1964]: loss 3.404433
[epoch11, step1965]: loss 2.883924
[epoch11, step1966]: loss 5.851087
[epoch11, step1967]: loss 0.983228
[epoch11, step1968]: loss 2.649027
[epoch11, step1969]: loss 11.303690
[epoch11, step1970]: loss 19.140417
[epoch11, step1971]: loss 4.786247
[epoch11, step1972]: loss 1.317210
[epoch11, step1973]: loss 0.866961
[epoch11, step1974]: loss 1.258332
[epoch11, step1975]: loss 3.209086
[epoch11, step1976]: loss 12.149696
[epoch11, step1977]: loss 1.859354
[epoch11, step1978]: loss 1.838123
[epoch11, step1979]: loss 19.067919
[epoch11, step1980]: loss 1.311636
[epoch11, step1981]: loss 8.200954
[epoch11, step1982]: loss 1.429413
[epoch11, step1983]: loss 2.063044
[epoch11, step1984]: loss 3.752034
[epoch11, step1985]: loss 4.752011
[epoch11, step1986]: loss 2.440219
[epoch11, step1987]: loss 1.482953
[epoch11, step1988]: loss 8.439075
[epoch11, step1989]: loss 1.527674
[epoch11, step1990]: loss 1.708292
[epoch11, step1991]: loss 3.543234
[epoch11, step1992]: loss 2.514568
[epoch11, step1993]: loss 1.572177
[epoch11, step1994]: loss 2.515667
[epoch11, step1995]: loss 2.024014
[epoch11, step1996]: loss 3.191560
[epoch11, step1997]: loss 21.509886
[epoch11, step1998]: loss 0.837177
[epoch11, step1999]: loss 5.865841
[epoch11, step2000]: loss 31.932346
[epoch11, step2001]: loss 8.989065
[epoch11, step2002]: loss 1.915849
[epoch11, step2003]: loss 1.967833
[epoch11, step2004]: loss 10.946300
[epoch11, step2005]: loss 12.990945
[epoch11, step2006]: loss 1.799455
[epoch11, step2007]: loss 1.341463
[epoch11, step2008]: loss 1.948896
[epoch11, step2009]: loss 17.166355
[epoch11, step2010]: loss 1.186783
[epoch11, step2011]: loss 1.624799
[epoch11, step2012]: loss 2.205942
[epoch11, step2013]: loss 1.102865
[epoch11, step2014]: loss 16.476089
[epoch11, step2015]: loss 1.057792
[epoch11, step2016]: loss 3.396558
[epoch11, step2017]: loss 1.320722
[epoch11, step2018]: loss 0.988836
[epoch11, step2019]: loss 2.252189
[epoch11, step2020]: loss 11.436134
[epoch11, step2021]: loss 1.499237
[epoch11, step2022]: loss 3.225090
[epoch11, step2023]: loss 1.410462
[epoch11, step2024]: loss 2.062491
[epoch11, step2025]: loss 1.160701
[epoch11, step2026]: loss 1.510969
[epoch11, step2027]: loss 2.777356
[epoch11, step2028]: loss 0.844069
[epoch11, step2029]: loss 6.421413
[epoch11, step2030]: loss 13.005215
[epoch11, step2031]: loss 10.319998
[epoch11, step2032]: loss 12.954526
[epoch11, step2033]: loss 1.458161
[epoch11, step2034]: loss 1.502991
[epoch11, step2035]: loss 11.376346
[epoch11, step2036]: loss 12.942233
[epoch11, step2037]: loss 1.496947
[epoch11, step2038]: loss 10.623710
[epoch11, step2039]: loss 5.229311
[epoch11, step2040]: loss 5.770212
[epoch11, step2041]: loss 1.134230
[epoch11, step2042]: loss 3.772620
[epoch11, step2043]: loss 0.992438
[epoch11, step2044]: loss 3.765109
[epoch11, step2045]: loss 1.060142
[epoch11, step2046]: loss 2.441508
[epoch11, step2047]: loss 4.119761
[epoch11, step2048]: loss 3.148562
[epoch11, step2049]: loss 0.983574
[epoch11, step2050]: loss 5.284582
[epoch11, step2051]: loss 3.301801
[epoch11, step2052]: loss 3.506149
[epoch11, step2053]: loss 22.937878
[epoch11, step2054]: loss 27.486908
[epoch11, step2055]: loss 2.697257
[epoch11, step2056]: loss 3.764576
[epoch11, step2057]: loss 1.896215
[epoch11, step2058]: loss 1.054115
[epoch11, step2059]: loss 4.944457
[epoch11, step2060]: loss 1.326248
[epoch11, step2061]: loss 1.390055
[epoch11, step2062]: loss 1.619274
[epoch11, step2063]: loss 4.635182
[epoch11, step2064]: loss 5.202421
[epoch11, step2065]: loss 12.452657
[epoch11, step2066]: loss 3.330406
[epoch11, step2067]: loss 2.340149
[epoch11, step2068]: loss 2.040550
[epoch11, step2069]: loss 8.968503
[epoch11, step2070]: loss 3.096572
[epoch11, step2071]: loss 1.289913
[epoch11, step2072]: loss 1.752591
[epoch11, step2073]: loss 3.979716
[epoch11, step2074]: loss 11.579583
[epoch11, step2075]: loss 2.696013
[epoch11, step2076]: loss 10.072003
[epoch11, step2077]: loss 9.257495
[epoch11, step2078]: loss 1.436988
[epoch11, step2079]: loss 16.232456
[epoch11, step2080]: loss 12.713669
[epoch11, step2081]: loss 4.297404
[epoch11, step2082]: loss 1.146234
[epoch11, step2083]: loss 3.828081
[epoch11, step2084]: loss 15.674610
[epoch11, step2085]: loss 4.711800
[epoch11, step2086]: loss 0.944059
[epoch11, step2087]: loss 7.888467
[epoch11, step2088]: loss 4.838574
[epoch11, step2089]: loss 19.987906
[epoch11, step2090]: loss 18.665365
[epoch11, step2091]: loss 7.141167
[epoch11, step2092]: loss 1.598282
[epoch11, step2093]: loss 2.425356
[epoch11, step2094]: loss 1.682085
[epoch11, step2095]: loss 1.280454
[epoch11, step2096]: loss 1.422242
[epoch11, step2097]: loss 11.607191
[epoch11, step2098]: loss 5.608491
[epoch11, step2099]: loss 0.928443
[epoch11, step2100]: loss 3.241385
[epoch11, step2101]: loss 2.494008
[epoch11, step2102]: loss 10.905974
[epoch11, step2103]: loss 1.354495
[epoch11, step2104]: loss 0.838902
[epoch11, step2105]: loss 1.573103
[epoch11, step2106]: loss 17.522577
[epoch11, step2107]: loss 1.921709
[epoch11, step2108]: loss 4.918711
[epoch11, step2109]: loss 2.070545
[epoch11, step2110]: loss 1.561520
[epoch11, step2111]: loss 0.646753
[epoch11, step2112]: loss 1.144763
[epoch11, step2113]: loss 2.673682
[epoch11, step2114]: loss 27.480457
[epoch11, step2115]: loss 1.707625
[epoch11, step2116]: loss 1.730008
[epoch11, step2117]: loss 1.677970
[epoch11, step2118]: loss 1.800626
[epoch11, step2119]: loss 5.048057
[epoch11, step2120]: loss 2.999081
[epoch11, step2121]: loss 1.677850
[epoch11, step2122]: loss 0.988270
[epoch11, step2123]: loss 24.856012
[epoch11, step2124]: loss 1.169919
[epoch11, step2125]: loss 1.298344
[epoch11, step2126]: loss 10.326450
[epoch11, step2127]: loss 14.406192
[epoch11, step2128]: loss 0.711296
[epoch11, step2129]: loss 6.224995
[epoch11, step2130]: loss 1.157278
[epoch11, step2131]: loss 1.155109
[epoch11, step2132]: loss 1.289914
[epoch11, step2133]: loss 1.318286
[epoch11, step2134]: loss 1.771402
[epoch11, step2135]: loss 15.518200
[epoch11, step2136]: loss 1.842176
[epoch11, step2137]: loss 1.197319
[epoch11, step2138]: loss 7.810615
[epoch11, step2139]: loss 1.860735
[epoch11, step2140]: loss 1.787491
[epoch11, step2141]: loss 1.066682
[epoch11, step2142]: loss 4.490079
[epoch11, step2143]: loss 5.959978
[epoch11, step2144]: loss 9.678865
[epoch11, step2145]: loss 1.597480
[epoch11, step2146]: loss 1.166795
[epoch11, step2147]: loss 3.669840
[epoch11, step2148]: loss 2.960753
[epoch11, step2149]: loss 14.693315
[epoch11, step2150]: loss 4.425351
[epoch11, step2151]: loss 1.446545
[epoch11, step2152]: loss 11.309690
[epoch11, step2153]: loss 8.685154
[epoch11, step2154]: loss 2.530400
[epoch11, step2155]: loss 10.886600
[epoch11, step2156]: loss 1.802205
[epoch11, step2157]: loss 4.671796
[epoch11, step2158]: loss 1.373982
[epoch11, step2159]: loss 2.343675
[epoch11, step2160]: loss 5.167727
[epoch11, step2161]: loss 1.293646
[epoch11, step2162]: loss 0.963290
[epoch11, step2163]: loss 2.711218
[epoch11, step2164]: loss 2.397345
[epoch11, step2165]: loss 24.777565
[epoch11, step2166]: loss 2.388295
[epoch11, step2167]: loss 1.545961
[epoch11, step2168]: loss 5.332658
[epoch11, step2169]: loss 1.067135
[epoch11, step2170]: loss 1.969441
[epoch11, step2171]: loss 0.851640
[epoch11, step2172]: loss 3.821248
[epoch11, step2173]: loss 13.473995
[epoch11, step2174]: loss 5.252036
[epoch11, step2175]: loss 1.376142
[epoch11, step2176]: loss 9.803666
[epoch11, step2177]: loss 14.319144
[epoch11, step2178]: loss 5.230041
[epoch11, step2179]: loss 1.627745
[epoch11, step2180]: loss 0.947003
[epoch11, step2181]: loss 1.679562
[epoch11, step2182]: loss 2.624341
[epoch11, step2183]: loss 1.517557
[epoch11, step2184]: loss 23.105154
[epoch11, step2185]: loss 2.163527
[epoch11, step2186]: loss 9.292670
[epoch11, step2187]: loss 1.628280
[epoch11, step2188]: loss 0.949407
[epoch11, step2189]: loss 13.544176
[epoch11, step2190]: loss 1.937416
[epoch11, step2191]: loss 1.942909
[epoch11, step2192]: loss 2.969214
[epoch11, step2193]: loss 1.684884
[epoch11, step2194]: loss 6.849841
[epoch11, step2195]: loss 1.598671
[epoch11, step2196]: loss 4.559897
[epoch11, step2197]: loss 16.803633
[epoch11, step2198]: loss 1.769435
[epoch11, step2199]: loss 3.436419
[epoch11, step2200]: loss 1.103146
[epoch11, step2201]: loss 2.969575
[epoch11, step2202]: loss 11.360628
[epoch11, step2203]: loss 6.160551
[epoch11, step2204]: loss 5.250611
[epoch11, step2205]: loss 2.310703
[epoch11, step2206]: loss 6.195704
[epoch11, step2207]: loss 1.194680
[epoch11, step2208]: loss 1.839120
[epoch11, step2209]: loss 0.866653
[epoch11, step2210]: loss 2.939759
[epoch11, step2211]: loss 3.244052
[epoch11, step2212]: loss 8.521718
[epoch11, step2213]: loss 1.327917
[epoch11, step2214]: loss 1.705540
[epoch11, step2215]: loss 1.009500
[epoch11, step2216]: loss 8.449654
[epoch11, step2217]: loss 2.283600
[epoch11, step2218]: loss 11.936520
[epoch11, step2219]: loss 5.369277
[epoch11, step2220]: loss 9.057253
[epoch11, step2221]: loss 12.442426
[epoch11, step2222]: loss 19.613934
[epoch11, step2223]: loss 2.767638
[epoch11, step2224]: loss 3.073087
[epoch11, step2225]: loss 1.473571
[epoch11, step2226]: loss 20.204098
[epoch11, step2227]: loss 3.395504
[epoch11, step2228]: loss 1.581633
[epoch11, step2229]: loss 18.767044
[epoch11, step2230]: loss 1.517324
[epoch11, step2231]: loss 1.261847
[epoch11, step2232]: loss 2.840581
[epoch11, step2233]: loss 20.403637
[epoch11, step2234]: loss 0.849098
[epoch11, step2235]: loss 2.728151
[epoch11, step2236]: loss 2.378254
[epoch11, step2237]: loss 1.165486
[epoch11, step2238]: loss 10.265198
[epoch11, step2239]: loss 7.380843
[epoch11, step2240]: loss 16.119318
[epoch11, step2241]: loss 1.616047
[epoch11, step2242]: loss 9.196738
[epoch11, step2243]: loss 2.576589
[epoch11, step2244]: loss 1.812267
[epoch11, step2245]: loss 4.869969
[epoch11, step2246]: loss 1.377411
[epoch11, step2247]: loss 7.767970
[epoch11, step2248]: loss 8.120427
[epoch11, step2249]: loss 14.136327
[epoch11, step2250]: loss 13.018331
[epoch11, step2251]: loss 10.235475
[epoch11, step2252]: loss 1.952049
[epoch11, step2253]: loss 2.463733
[epoch11, step2254]: loss 33.825768
[epoch11, step2255]: loss 9.756465
[epoch11, step2256]: loss 2.227972
[epoch11, step2257]: loss 1.431750
[epoch11, step2258]: loss 2.261611
[epoch11, step2259]: loss 3.403948
[epoch11, step2260]: loss 2.868352
[epoch11, step2261]: loss 8.299848
[epoch11, step2262]: loss 1.092992
[epoch11, step2263]: loss 3.372391
[epoch11, step2264]: loss 10.315166
[epoch11, step2265]: loss 3.865181
[epoch11, step2266]: loss 4.013088
[epoch11, step2267]: loss 5.479451
[epoch11, step2268]: loss 6.132408
[epoch11, step2269]: loss 8.095095
[epoch11, step2270]: loss 1.256152
[epoch11, step2271]: loss 13.531540
[epoch11, step2272]: loss 3.620233
[epoch11, step2273]: loss 6.668898
[epoch11, step2274]: loss 1.568103
[epoch11, step2275]: loss 1.639851
[epoch11, step2276]: loss 1.014213
[epoch11, step2277]: loss 2.666066
[epoch11, step2278]: loss 2.352314
[epoch11, step2279]: loss 6.622764
[epoch11, step2280]: loss 2.364294
[epoch11, step2281]: loss 1.501413
[epoch11, step2282]: loss 2.115987
[epoch11, step2283]: loss 2.524305
[epoch11, step2284]: loss 2.543411
[epoch11, step2285]: loss 1.710965
[epoch11, step2286]: loss 1.368745
[epoch11, step2287]: loss 1.403628
[epoch11, step2288]: loss 15.531266
[epoch11, step2289]: loss 37.019806
[epoch11, step2290]: loss 1.715731
[epoch11, step2291]: loss 1.531298
[epoch11, step2292]: loss 1.522516
[epoch11, step2293]: loss 1.322754
[epoch11, step2294]: loss 7.788005
[epoch11, step2295]: loss 11.027799
[epoch11, step2296]: loss 8.694805
[epoch11, step2297]: loss 2.247209
[epoch11, step2298]: loss 2.538746
[epoch11, step2299]: loss 17.789444
[epoch11, step2300]: loss 3.551176
[epoch11, step2301]: loss 13.742096
[epoch11, step2302]: loss 1.095164
[epoch11, step2303]: loss 22.821323
[epoch11, step2304]: loss 1.261830
[epoch11, step2305]: loss 3.138304
[epoch11, step2306]: loss 1.802674
[epoch11, step2307]: loss 1.347493
[epoch11, step2308]: loss 9.380163
[epoch11, step2309]: loss 1.404520
[epoch11, step2310]: loss 5.817818
[epoch11, step2311]: loss 3.755355
[epoch11, step2312]: loss 1.373990
[epoch11, step2313]: loss 9.848511
[epoch11, step2314]: loss 0.983286
[epoch11, step2315]: loss 0.682166
[epoch11, step2316]: loss 3.262561
[epoch11, step2317]: loss 2.243547
[epoch11, step2318]: loss 1.044754
[epoch11, step2319]: loss 1.770303
[epoch11, step2320]: loss 2.131480
[epoch11, step2321]: loss 14.674405
[epoch11, step2322]: loss 4.051786
[epoch11, step2323]: loss 1.283748
[epoch11, step2324]: loss 2.666451
[epoch11, step2325]: loss 2.374741
[epoch11, step2326]: loss 1.444938
[epoch11, step2327]: loss 11.098246
[epoch11, step2328]: loss 1.288545
[epoch11, step2329]: loss 3.659531
[epoch11, step2330]: loss 2.590821
[epoch11, step2331]: loss 8.804076
[epoch11, step2332]: loss 2.647920
[epoch11, step2333]: loss 1.506079
[epoch11, step2334]: loss 2.503816
[epoch11, step2335]: loss 1.126058
[epoch11, step2336]: loss 16.864365
[epoch11, step2337]: loss 4.576663
[epoch11, step2338]: loss 5.331444
[epoch11, step2339]: loss 1.295381
[epoch11, step2340]: loss 2.674519
[epoch11, step2341]: loss 4.236048
[epoch11, step2342]: loss 1.020925
[epoch11, step2343]: loss 9.618350
[epoch11, step2344]: loss 14.839231
[epoch11, step2345]: loss 1.474470
[epoch11, step2346]: loss 6.173064
[epoch11, step2347]: loss 1.843759
[epoch11, step2348]: loss 1.786705
[epoch11, step2349]: loss 0.963908
[epoch11, step2350]: loss 11.235081
[epoch11, step2351]: loss 1.649423
[epoch11, step2352]: loss 14.808296
[epoch11, step2353]: loss 2.729857
[epoch11, step2354]: loss 1.649430
[epoch11, step2355]: loss 1.129985
[epoch11, step2356]: loss 14.864232
[epoch11, step2357]: loss 14.641970
[epoch11, step2358]: loss 6.802970
[epoch11, step2359]: loss 1.779230
[epoch11, step2360]: loss 0.989038
[epoch11, step2361]: loss 2.850784
[epoch11, step2362]: loss 2.252881
[epoch11, step2363]: loss 2.825294
[epoch11, step2364]: loss 2.694011
[epoch11, step2365]: loss 1.662792
[epoch11, step2366]: loss 1.119854
[epoch11, step2367]: loss 16.804436
[epoch11, step2368]: loss 1.353122
[epoch11, step2369]: loss 2.136849
[epoch11, step2370]: loss 23.078915
[epoch11, step2371]: loss 1.661447
[epoch11, step2372]: loss 24.637968
[epoch11, step2373]: loss 1.648397
[epoch11, step2374]: loss 3.239238
[epoch11, step2375]: loss 1.203290
[epoch11, step2376]: loss 1.570384
[epoch11, step2377]: loss 1.291566
[epoch11, step2378]: loss 1.986440
[epoch11, step2379]: loss 1.233234
[epoch11, step2380]: loss 12.008577
[epoch11, step2381]: loss 1.798583
[epoch11, step2382]: loss 3.640486
[epoch11, step2383]: loss 2.683836
[epoch11, step2384]: loss 5.410996
[epoch11, step2385]: loss 1.255932
[epoch11, step2386]: loss 4.635715
[epoch11, step2387]: loss 2.443030
[epoch11, step2388]: loss 11.855231
[epoch11, step2389]: loss 1.050277
[epoch11, step2390]: loss 14.975637
[epoch11, step2391]: loss 1.024582
[epoch11, step2392]: loss 18.911110
[epoch11, step2393]: loss 2.876832
[epoch11, step2394]: loss 4.015241
[epoch11, step2395]: loss 2.542088
[epoch11, step2396]: loss 1.197465
[epoch11, step2397]: loss 10.661667
[epoch11, step2398]: loss 1.964356
[epoch11, step2399]: loss 2.165929
[epoch11, step2400]: loss 2.051638
[epoch11, step2401]: loss 13.029271
[epoch11, step2402]: loss 3.675015
[epoch11, step2403]: loss 1.278323
[epoch11, step2404]: loss 0.643700
[epoch11, step2405]: loss 1.845385
[epoch11, step2406]: loss 5.157161
[epoch11, step2407]: loss 11.429038
[epoch11, step2408]: loss 13.299952
[epoch11, step2409]: loss 0.921381
[epoch11, step2410]: loss 5.403562
[epoch11, step2411]: loss 1.524173
[epoch11, step2412]: loss 1.549349
[epoch11, step2413]: loss 31.726412
[epoch11, step2414]: loss 1.894058
[epoch11, step2415]: loss 2.546822
[epoch11, step2416]: loss 0.864198
[epoch11, step2417]: loss 35.135330
[epoch11, step2418]: loss 3.090613
[epoch11, step2419]: loss 9.796645
[epoch11, step2420]: loss 1.674001
[epoch11, step2421]: loss 2.537554
[epoch11, step2422]: loss 2.184559
[epoch11, step2423]: loss 3.595096
[epoch11, step2424]: loss 1.011843
[epoch11, step2425]: loss 1.854410
[epoch11, step2426]: loss 9.523088
[epoch11, step2427]: loss 1.082002
[epoch11, step2428]: loss 2.443226
[epoch11, step2429]: loss 1.140422
[epoch11, step2430]: loss 0.980861
[epoch11, step2431]: loss 1.712849
[epoch11, step2432]: loss 2.112481
[epoch11, step2433]: loss 2.038153
[epoch11, step2434]: loss 1.370134
[epoch11, step2435]: loss 11.498959
[epoch11, step2436]: loss 1.714630
[epoch11, step2437]: loss 0.963105
[epoch11, step2438]: loss 1.267089
[epoch11, step2439]: loss 1.565998
[epoch11, step2440]: loss 2.366290
[epoch11, step2441]: loss 21.055931
[epoch11, step2442]: loss 0.992235
[epoch11, step2443]: loss 1.659045
[epoch11, step2444]: loss 1.176944
[epoch11, step2445]: loss 1.018921
[epoch11, step2446]: loss 4.239683
[epoch11, step2447]: loss 2.194988
[epoch11, step2448]: loss 1.391711
[epoch11, step2449]: loss 3.308143
[epoch11, step2450]: loss 6.214636
[epoch11, step2451]: loss 2.547605
[epoch11, step2452]: loss 2.886662
[epoch11, step2453]: loss 5.216803
[epoch11, step2454]: loss 10.048155
[epoch11, step2455]: loss 11.673646
[epoch11, step2456]: loss 2.667420
[epoch11, step2457]: loss 0.925107
[epoch11, step2458]: loss 1.313196
[epoch11, step2459]: loss 1.125834
[epoch11, step2460]: loss 1.481504
[epoch11, step2461]: loss 2.756143
[epoch11, step2462]: loss 0.939855
[epoch11, step2463]: loss 1.105454
[epoch11, step2464]: loss 2.540108
[epoch11, step2465]: loss 1.827245
[epoch11, step2466]: loss 2.316211
[epoch11, step2467]: loss 1.715580
[epoch11, step2468]: loss 20.074493
[epoch11, step2469]: loss 1.328468
[epoch11, step2470]: loss 9.670147
[epoch11, step2471]: loss 1.740921
[epoch11, step2472]: loss 25.944605
[epoch11, step2473]: loss 2.375244
[epoch11, step2474]: loss 13.029537
[epoch11, step2475]: loss 14.803225
[epoch11, step2476]: loss 2.200336
[epoch11, step2477]: loss 8.997313
[epoch11, step2478]: loss 2.147305
[epoch11, step2479]: loss 9.645096
[epoch11, step2480]: loss 1.250145
[epoch11, step2481]: loss 3.781478
[epoch11, step2482]: loss 1.554708
[epoch11, step2483]: loss 20.398306
[epoch11, step2484]: loss 1.230042
[epoch11, step2485]: loss 13.916113
[epoch11, step2486]: loss 1.409342
[epoch11, step2487]: loss 0.988500
[epoch11, step2488]: loss 5.196453
[epoch11, step2489]: loss 1.731923
[epoch11, step2490]: loss 2.704940
[epoch11, step2491]: loss 1.235009
[epoch11, step2492]: loss 4.320910
[epoch11, step2493]: loss 4.293332
[epoch11, step2494]: loss 5.220666
[epoch11, step2495]: loss 10.325888
[epoch11, step2496]: loss 1.631250
[epoch11, step2497]: loss 1.879745
[epoch11, step2498]: loss 1.189417
[epoch11, step2499]: loss 2.821477
[epoch11, step2500]: loss 2.342608
[epoch11, step2501]: loss 17.508568
[epoch11, step2502]: loss 1.853525
[epoch11, step2503]: loss 18.653587
[epoch11, step2504]: loss 2.293719
[epoch11, step2505]: loss 14.527012
[epoch11, step2506]: loss 6.205225
[epoch11, step2507]: loss 18.340611
[epoch11, step2508]: loss 2.136862
[epoch11, step2509]: loss 12.306399
[epoch11, step2510]: loss 3.700468
[epoch11, step2511]: loss 8.244857
[epoch11, step2512]: loss 1.605637
[epoch11, step2513]: loss 1.241151
[epoch11, step2514]: loss 1.224686
[epoch11, step2515]: loss 6.342305
[epoch11, step2516]: loss 1.432176
[epoch11, step2517]: loss 10.744678
[epoch11, step2518]: loss 14.351995
[epoch11, step2519]: loss 0.939081
[epoch11, step2520]: loss 14.203016
[epoch11, step2521]: loss 0.984860
[epoch11, step2522]: loss 10.990918
[epoch11, step2523]: loss 11.065589
[epoch11, step2524]: loss 1.112605
[epoch11, step2525]: loss 1.548527
[epoch11, step2526]: loss 1.606598
[epoch11, step2527]: loss 1.020799
[epoch11, step2528]: loss 5.380839
[epoch11, step2529]: loss 0.953475
[epoch11, step2530]: loss 1.113206
[epoch11, step2531]: loss 0.665609
[epoch11, step2532]: loss 1.030346
[epoch11, step2533]: loss 3.676606
[epoch11, step2534]: loss 1.215837
[epoch11, step2535]: loss 1.515201
[epoch11, step2536]: loss 0.992372
[epoch11, step2537]: loss 3.721511
[epoch11, step2538]: loss 2.160219
[epoch11, step2539]: loss 16.848345
[epoch11, step2540]: loss 9.275336
[epoch11, step2541]: loss 2.720816
[epoch11, step2542]: loss 4.716095
[epoch11, step2543]: loss 5.699377
[epoch11, step2544]: loss 15.180024
[epoch11, step2545]: loss 3.836276
[epoch11, step2546]: loss 8.295622
[epoch11, step2547]: loss 3.835824
[epoch11, step2548]: loss 1.994200
[epoch11, step2549]: loss 1.935575
[epoch11, step2550]: loss 2.749070
[epoch11, step2551]: loss 1.108027
[epoch11, step2552]: loss 1.980051
[epoch11, step2553]: loss 0.799934
[epoch11, step2554]: loss 1.548146
[epoch11, step2555]: loss 2.802760
[epoch11, step2556]: loss 0.905966
[epoch11, step2557]: loss 2.210320
[epoch11, step2558]: loss 0.956276
[epoch11, step2559]: loss 0.946039
[epoch11, step2560]: loss 2.812342
[epoch11, step2561]: loss 4.102319
[epoch11, step2562]: loss 4.029767
[epoch11, step2563]: loss 2.218552
[epoch11, step2564]: loss 8.371098
[epoch11, step2565]: loss 3.119988
[epoch11, step2566]: loss 5.807739
[epoch11, step2567]: loss 1.239757
[epoch11, step2568]: loss 1.131965
[epoch11, step2569]: loss 4.591941
[epoch11, step2570]: loss 1.324043
[epoch11, step2571]: loss 2.808489
[epoch11, step2572]: loss 11.710383
[epoch11, step2573]: loss 2.103086
[epoch11, step2574]: loss 1.337244
[epoch11, step2575]: loss 17.663988
[epoch11, step2576]: loss 5.729039
[epoch11, step2577]: loss 12.594053
[epoch11, step2578]: loss 13.188188
[epoch11, step2579]: loss 2.053167
[epoch11, step2580]: loss 26.368971
[epoch11, step2581]: loss 21.070490
[epoch11, step2582]: loss 0.878267
[epoch11, step2583]: loss 3.781642
[epoch11, step2584]: loss 1.025697
[epoch11, step2585]: loss 1.673365
[epoch11, step2586]: loss 0.831628
[epoch11, step2587]: loss 2.409060
[epoch11, step2588]: loss 1.167505
[epoch11, step2589]: loss 1.390523
[epoch11, step2590]: loss 3.849565
[epoch11, step2591]: loss 10.667580
[epoch11, step2592]: loss 2.194935
[epoch11, step2593]: loss 0.876006
[epoch11, step2594]: loss 0.800313
[epoch11, step2595]: loss 3.463212
[epoch11, step2596]: loss 2.862555
[epoch11, step2597]: loss 5.776148
[epoch11, step2598]: loss 1.817845
[epoch11, step2599]: loss 1.114064
[epoch11, step2600]: loss 22.300943
[epoch11, step2601]: loss 1.604361
[epoch11, step2602]: loss 4.877114
[epoch11, step2603]: loss 11.715285
[epoch11, step2604]: loss 1.201477
[epoch11, step2605]: loss 1.759501
[epoch11, step2606]: loss 1.092585
[epoch11, step2607]: loss 2.084436
[epoch11, step2608]: loss 1.376958
[epoch11, step2609]: loss 1.239287
[epoch11, step2610]: loss 2.676223
[epoch11, step2611]: loss 19.040220
[epoch11, step2612]: loss 1.229903
[epoch11, step2613]: loss 1.488173
[epoch11, step2614]: loss 4.788562
[epoch11, step2615]: loss 3.448310
[epoch11, step2616]: loss 1.391484
[epoch11, step2617]: loss 1.601839
[epoch11, step2618]: loss 1.363771
[epoch11, step2619]: loss 1.159399
[epoch11, step2620]: loss 1.336224
[epoch11, step2621]: loss 2.117758
[epoch11, step2622]: loss 5.105608
[epoch11, step2623]: loss 2.352811
[epoch11, step2624]: loss 1.182065
[epoch11, step2625]: loss 1.021933
[epoch11, step2626]: loss 1.549931
[epoch11, step2627]: loss 2.429399
[epoch11, step2628]: loss 1.032312
[epoch11, step2629]: loss 2.655838
[epoch11, step2630]: loss 16.161989
[epoch11, step2631]: loss 4.274150
[epoch11, step2632]: loss 0.798679
[epoch11, step2633]: loss 2.670674
[epoch11, step2634]: loss 20.456995
[epoch11, step2635]: loss 1.199842
[epoch11, step2636]: loss 1.329770
[epoch11, step2637]: loss 13.903483
[epoch11, step2638]: loss 1.392891
[epoch11, step2639]: loss 17.680412
[epoch11, step2640]: loss 1.137691
[epoch11, step2641]: loss 12.884333
[epoch11, step2642]: loss 7.678160
[epoch11, step2643]: loss 8.922869
[epoch11, step2644]: loss 3.835403
[epoch11, step2645]: loss 10.041364
[epoch11, step2646]: loss 1.966381
[epoch11, step2647]: loss 1.611825
[epoch11, step2648]: loss 11.319397
[epoch11, step2649]: loss 2.426183
[epoch11, step2650]: loss 1.117054
[epoch11, step2651]: loss 1.104869
[epoch11, step2652]: loss 1.278834
[epoch11, step2653]: loss 2.118973
[epoch11, step2654]: loss 6.765876
[epoch11, step2655]: loss 21.365646
[epoch11, step2656]: loss 2.220920
[epoch11, step2657]: loss 9.503478
[epoch11, step2658]: loss 3.144272
[epoch11, step2659]: loss 4.548268
[epoch11, step2660]: loss 0.878389
[epoch11, step2661]: loss 3.035303
[epoch11, step2662]: loss 1.984418
[epoch11, step2663]: loss 17.656681
[epoch11, step2664]: loss 1.139142
[epoch11, step2665]: loss 1.236009
[epoch11, step2666]: loss 3.632742
[epoch11, step2667]: loss 2.030409
[epoch11, step2668]: loss 1.594636
[epoch11, step2669]: loss 1.941154
[epoch11, step2670]: loss 5.843064
[epoch11, step2671]: loss 3.363085
[epoch11, step2672]: loss 2.458833
[epoch11, step2673]: loss 0.815654
[epoch11, step2674]: loss 0.948731
[epoch11, step2675]: loss 1.069746
[epoch11, step2676]: loss 1.174823
[epoch11, step2677]: loss 1.328240
[epoch11, step2678]: loss 21.603285
[epoch11, step2679]: loss 1.494062
[epoch11, step2680]: loss 10.282182
[epoch11, step2681]: loss 15.863767
[epoch11, step2682]: loss 1.078924
[epoch11, step2683]: loss 2.420900
[epoch11, step2684]: loss 4.861563
[epoch11, step2685]: loss 0.824296
[epoch11, step2686]: loss 1.711807
[epoch11, step2687]: loss 1.174599
[epoch11, step2688]: loss 4.950787
[epoch11, step2689]: loss 13.518168
[epoch11, step2690]: loss 2.245892
[epoch11, step2691]: loss 0.940323
[epoch11, step2692]: loss 15.772651
[epoch11, step2693]: loss 3.454807
[epoch11, step2694]: loss 3.182553
[epoch11, step2695]: loss 14.337395
[epoch11, step2696]: loss 3.358251
[epoch11, step2697]: loss 1.493020
[epoch11, step2698]: loss 2.520554
[epoch11, step2699]: loss 6.740233
[epoch11, step2700]: loss 2.371500
[epoch11, step2701]: loss 1.011013
[epoch11, step2702]: loss 2.159488
[epoch11, step2703]: loss 3.119762
[epoch11, step2704]: loss 5.953489
[epoch11, step2705]: loss 4.678493
[epoch11, step2706]: loss 3.198024
[epoch11, step2707]: loss 8.370964
[epoch11, step2708]: loss 1.824075
[epoch11, step2709]: loss 27.195675
[epoch11, step2710]: loss 1.958674
[epoch11, step2711]: loss 1.332022
[epoch11, step2712]: loss 8.473651
[epoch11, step2713]: loss 1.332280
[epoch11, step2714]: loss 13.215580
[epoch11, step2715]: loss 1.528361
[epoch11, step2716]: loss 1.837464
[epoch11, step2717]: loss 10.036906
[epoch11, step2718]: loss 12.729443
[epoch11, step2719]: loss 2.654932
[epoch11, step2720]: loss 2.511923
[epoch11, step2721]: loss 5.157657
[epoch11, step2722]: loss 3.459185
[epoch11, step2723]: loss 13.139046
[epoch11, step2724]: loss 7.492249
[epoch11, step2725]: loss 2.587306
[epoch11, step2726]: loss 2.254505
[epoch11, step2727]: loss 0.840093
[epoch11, step2728]: loss 2.441324
[epoch11, step2729]: loss 0.753318
[epoch11, step2730]: loss 4.497998
[epoch11, step2731]: loss 8.442569
[epoch11, step2732]: loss 1.620722
[epoch11, step2733]: loss 1.677643
[epoch11, step2734]: loss 1.310254
[epoch11, step2735]: loss 2.704807
[epoch11, step2736]: loss 1.136656
[epoch11, step2737]: loss 30.798391
[epoch11, step2738]: loss 1.259807
[epoch11, step2739]: loss 1.553821
[epoch11, step2740]: loss 1.059503
[epoch11, step2741]: loss 10.719084
[epoch11, step2742]: loss 1.634374
[epoch11, step2743]: loss 2.173560
[epoch11, step2744]: loss 3.431966
[epoch11, step2745]: loss 20.831388
[epoch11, step2746]: loss 11.653895
[epoch11, step2747]: loss 1.741345
[epoch11, step2748]: loss 2.527681
[epoch11, step2749]: loss 1.537682
[epoch11, step2750]: loss 2.226977
[epoch11, step2751]: loss 1.242513
[epoch11, step2752]: loss 0.837017
[epoch11, step2753]: loss 8.894881
[epoch11, step2754]: loss 1.921685
[epoch11, step2755]: loss 1.744920
[epoch11, step2756]: loss 1.997333
[epoch11, step2757]: loss 11.970209
[epoch11, step2758]: loss 2.072456
[epoch11, step2759]: loss 1.259187
[epoch11, step2760]: loss 2.099896
[epoch11, step2761]: loss 1.872619
[epoch11, step2762]: loss 1.771954
[epoch11, step2763]: loss 0.828438
[epoch11, step2764]: loss 1.590694
[epoch11, step2765]: loss 18.344080
[epoch11, step2766]: loss 10.519541
[epoch11, step2767]: loss 3.836480
[epoch11, step2768]: loss 10.739097
[epoch11, step2769]: loss 0.833585
[epoch11, step2770]: loss 2.333103
[epoch11, step2771]: loss 1.865423
[epoch11, step2772]: loss 2.570656
[epoch11, step2773]: loss 2.532506
[epoch11, step2774]: loss 12.954507
[epoch11, step2775]: loss 1.646173
[epoch11, step2776]: loss 4.297425
[epoch11, step2777]: loss 1.772285
[epoch11, step2778]: loss 4.115411
[epoch11, step2779]: loss 3.045351
[epoch11, step2780]: loss 10.685163
[epoch11, step2781]: loss 14.305715
[epoch11, step2782]: loss 8.202593
[epoch11, step2783]: loss 1.131164
[epoch11, step2784]: loss 2.625350
[epoch11, step2785]: loss 1.388909
[epoch11, step2786]: loss 1.202697
[epoch11, step2787]: loss 2.076126
[epoch11, step2788]: loss 11.758246
[epoch11, step2789]: loss 10.014259
[epoch11, step2790]: loss 1.103351
[epoch11, step2791]: loss 2.113754
[epoch11, step2792]: loss 5.908972
[epoch11, step2793]: loss 14.862081
[epoch11, step2794]: loss 3.382083
[epoch11, step2795]: loss 5.345613
[epoch11, step2796]: loss 0.910559
[epoch11, step2797]: loss 1.532438
[epoch11, step2798]: loss 4.961463
[epoch11, step2799]: loss 12.554413
[epoch11, step2800]: loss 1.454762
[epoch11, step2801]: loss 1.316350
[epoch11, step2802]: loss 9.966109
[epoch11, step2803]: loss 20.595976
[epoch11, step2804]: loss 1.405573
[epoch11, step2805]: loss 2.993380
[epoch11, step2806]: loss 1.891139
[epoch11, step2807]: loss 1.279436
[epoch11, step2808]: loss 4.406355
[epoch11, step2809]: loss 14.729236
[epoch11, step2810]: loss 2.814099
[epoch11, step2811]: loss 1.267717
[epoch11, step2812]: loss 0.833513
[epoch11, step2813]: loss 1.024296
[epoch11, step2814]: loss 1.103819
[epoch11, step2815]: loss 2.626585
[epoch11, step2816]: loss 2.824070
[epoch11, step2817]: loss 1.506138
[epoch11, step2818]: loss 1.233747
[epoch11, step2819]: loss 4.167852
[epoch11, step2820]: loss 2.737413
[epoch11, step2821]: loss 4.133580
[epoch11, step2822]: loss 3.671669
[epoch11, step2823]: loss 9.195335
[epoch11, step2824]: loss 0.845767
[epoch11, step2825]: loss 1.960850
[epoch11, step2826]: loss 1.784608
[epoch11, step2827]: loss 13.916332
[epoch11, step2828]: loss 2.028328
[epoch11, step2829]: loss 2.558864
[epoch11, step2830]: loss 9.620410
[epoch11, step2831]: loss 20.073858
[epoch11, step2832]: loss 14.274976
[epoch11, step2833]: loss 3.973842
[epoch11, step2834]: loss 4.243058
[epoch11, step2835]: loss 1.922884
[epoch11, step2836]: loss 1.307108
[epoch11, step2837]: loss 1.537312
[epoch11, step2838]: loss 1.204149
[epoch11, step2839]: loss 2.694219
[epoch11, step2840]: loss 3.485065
[epoch11, step2841]: loss 4.980104
[epoch11, step2842]: loss 0.854387
[epoch11, step2843]: loss 0.919680
[epoch11, step2844]: loss 5.651982
[epoch11, step2845]: loss 16.016596
[epoch11, step2846]: loss 8.858358
[epoch11, step2847]: loss 9.487725
[epoch11, step2848]: loss 1.524669
[epoch11, step2849]: loss 1.757648
[epoch11, step2850]: loss 2.034003
[epoch11, step2851]: loss 13.684811
[epoch11, step2852]: loss 0.970313
[epoch11, step2853]: loss 1.341019
[epoch11, step2854]: loss 4.516567
[epoch11, step2855]: loss 2.546510
[epoch11, step2856]: loss 8.847720
[epoch11, step2857]: loss 7.978748
[epoch11, step2858]: loss 3.479501
[epoch11, step2859]: loss 4.218501
[epoch11, step2860]: loss 10.411565
[epoch11, step2861]: loss 0.993694
[epoch11, step2862]: loss 2.763308
[epoch11, step2863]: loss 1.262210
[epoch11, step2864]: loss 22.386902
[epoch11, step2865]: loss 2.754516
[epoch11, step2866]: loss 5.158415
[epoch11, step2867]: loss 0.819140
[epoch11, step2868]: loss 1.222936
[epoch11, step2869]: loss 3.379514
[epoch11, step2870]: loss 8.523241
[epoch11, step2871]: loss 1.724474
[epoch11, step2872]: loss 2.071283
[epoch11, step2873]: loss 1.622518
[epoch11, step2874]: loss 3.812416
[epoch11, step2875]: loss 1.073106
[epoch11, step2876]: loss 1.220422
[epoch11, step2877]: loss 0.887155
[epoch11, step2878]: loss 2.461190
[epoch11, step2879]: loss 4.106156
[epoch11, step2880]: loss 1.612243
[epoch11, step2881]: loss 3.633416
[epoch11, step2882]: loss 1.509227
[epoch11, step2883]: loss 4.668137
[epoch11, step2884]: loss 1.047490
[epoch11, step2885]: loss 1.445831
[epoch11, step2886]: loss 3.135631
[epoch11, step2887]: loss 7.143450
[epoch11, step2888]: loss 1.319211
[epoch11, step2889]: loss 1.939377
[epoch11, step2890]: loss 5.826463
[epoch11, step2891]: loss 1.505135
[epoch11, step2892]: loss 3.353082
[epoch11, step2893]: loss 1.343143
[epoch11, step2894]: loss 2.400280
[epoch11, step2895]: loss 1.497729
[epoch11, step2896]: loss 13.419530
[epoch11, step2897]: loss 20.789770
[epoch11, step2898]: loss 5.789864
[epoch11, step2899]: loss 2.018131
[epoch11, step2900]: loss 1.757094
[epoch11, step2901]: loss 2.734066
[epoch11, step2902]: loss 1.290816
[epoch11, step2903]: loss 1.374161
[epoch11, step2904]: loss 2.363740
[epoch11, step2905]: loss 7.230544
[epoch11, step2906]: loss 21.472477
[epoch11, step2907]: loss 3.417024
[epoch11, step2908]: loss 1.414595
[epoch11, step2909]: loss 1.863364
[epoch11, step2910]: loss 1.425965
[epoch11, step2911]: loss 2.150046
[epoch11, step2912]: loss 20.019350
[epoch11, step2913]: loss 1.441715
[epoch11, step2914]: loss 1.979853
[epoch11, step2915]: loss 3.731697
[epoch11, step2916]: loss 1.329782
[epoch11, step2917]: loss 0.790549
[epoch11, step2918]: loss 6.295961
[epoch11, step2919]: loss 5.161956
[epoch11, step2920]: loss 1.849060
[epoch11, step2921]: loss 1.146556
[epoch11, step2922]: loss 1.493372
[epoch11, step2923]: loss 4.636826
[epoch11, step2924]: loss 0.807202
[epoch11, step2925]: loss 1.905841
[epoch11, step2926]: loss 3.969774
[epoch11, step2927]: loss 1.790309
[epoch11, step2928]: loss 3.963473
[epoch11, step2929]: loss 18.363792
[epoch11, step2930]: loss 1.845869
[epoch11, step2931]: loss 9.959823
[epoch11, step2932]: loss 1.870606
[epoch11, step2933]: loss 13.671111
[epoch11, step2934]: loss 4.543132
[epoch11, step2935]: loss 1.911386
[epoch11, step2936]: loss 9.535347
[epoch11, step2937]: loss 1.187353
[epoch11, step2938]: loss 1.126054
[epoch11, step2939]: loss 11.112373
[epoch11, step2940]: loss 1.110199
[epoch11, step2941]: loss 1.346510
[epoch11, step2942]: loss 2.825086
[epoch11, step2943]: loss 37.777748
[epoch11, step2944]: loss 3.232244
[epoch11, step2945]: loss 3.164210
[epoch11, step2946]: loss 1.782289
[epoch11, step2947]: loss 1.390095
[epoch11, step2948]: loss 1.780820
[epoch11, step2949]: loss 18.961477
[epoch11, step2950]: loss 2.254101
[epoch11, step2951]: loss 8.186263
[epoch11, step2952]: loss 0.808351
[epoch11, step2953]: loss 9.084793
[epoch11, step2954]: loss 9.996856
[epoch11, step2955]: loss 3.679707
[epoch11, step2956]: loss 10.899503
[epoch11, step2957]: loss 12.278205
[epoch11, step2958]: loss 1.071132
[epoch11, step2959]: loss 2.154768
[epoch11, step2960]: loss 15.442883
[epoch11, step2961]: loss 1.624113
[epoch11, step2962]: loss 5.521240
[epoch11, step2963]: loss 19.541210
[epoch11, step2964]: loss 3.185268
[epoch11, step2965]: loss 1.948018
[epoch11, step2966]: loss 1.011014
[epoch11, step2967]: loss 1.635357
[epoch11, step2968]: loss 1.749896
[epoch11, step2969]: loss 1.293800
[epoch11, step2970]: loss 6.678138
[epoch11, step2971]: loss 1.325439
[epoch11, step2972]: loss 1.429696
[epoch11, step2973]: loss 10.915983
[epoch11, step2974]: loss 2.538607
[epoch11, step2975]: loss 1.158355
[epoch11, step2976]: loss 2.068239
[epoch11, step2977]: loss 2.520535
[epoch11, step2978]: loss 1.054703
[epoch11, step2979]: loss 1.521384
[epoch11, step2980]: loss 1.680479
[epoch11, step2981]: loss 25.086130
[epoch11, step2982]: loss 1.942161
[epoch11, step2983]: loss 1.968486
[epoch11, step2984]: loss 0.997413
[epoch11, step2985]: loss 3.251266
[epoch11, step2986]: loss 3.125274
[epoch11, step2987]: loss 1.763606
[epoch11, step2988]: loss 1.599865
[epoch11, step2989]: loss 4.633923
[epoch11, step2990]: loss 33.497341
[epoch11, step2991]: loss 2.487760
[epoch11, step2992]: loss 9.840807
[epoch11, step2993]: loss 19.967054
[epoch11, step2994]: loss 1.458036
[epoch11, step2995]: loss 5.674973
[epoch11, step2996]: loss 2.364454
[epoch11, step2997]: loss 0.996849
[epoch11, step2998]: loss 3.640310
[epoch11, step2999]: loss 1.470163
[epoch11, step3000]: loss 0.804675
[epoch11, step3001]: loss 2.763411
[epoch11, step3002]: loss 4.178164
[epoch11, step3003]: loss 0.694148
[epoch11, step3004]: loss 9.446494
[epoch11, step3005]: loss 0.930399
[epoch11, step3006]: loss 1.657043
[epoch11, step3007]: loss 6.593365
[epoch11, step3008]: loss 2.118212
[epoch11, step3009]: loss 5.965710
[epoch11, step3010]: loss 2.029996
[epoch11, step3011]: loss 0.945803
[epoch11, step3012]: loss 10.901953
[epoch11, step3013]: loss 3.799081
[epoch11, step3014]: loss 0.751635
[epoch11, step3015]: loss 1.259459
[epoch11, step3016]: loss 0.989676
[epoch11, step3017]: loss 3.874952
[epoch11, step3018]: loss 0.871591
[epoch11, step3019]: loss 15.124497
[epoch11, step3020]: loss 13.521591
[epoch11, step3021]: loss 2.404487
[epoch11, step3022]: loss 40.961010
[epoch11, step3023]: loss 3.133589
[epoch11, step3024]: loss 7.143497
[epoch11, step3025]: loss 20.594387
[epoch11, step3026]: loss 2.815273
[epoch11, step3027]: loss 26.766300
[epoch11, step3028]: loss 1.135666
[epoch11, step3029]: loss 1.396642
[epoch11, step3030]: loss 14.084641
[epoch11, step3031]: loss 7.721820
[epoch11, step3032]: loss 3.294869
[epoch11, step3033]: loss 1.419232
[epoch11, step3034]: loss 18.287260
[epoch11, step3035]: loss 4.170049
[epoch11, step3036]: loss 10.364614
[epoch11, step3037]: loss 7.980707
[epoch11, step3038]: loss 20.958076
[epoch11, step3039]: loss 1.425632
[epoch11, step3040]: loss 4.005809
[epoch11, step3041]: loss 1.014942
[epoch11, step3042]: loss 13.937049
[epoch11, step3043]: loss 3.833478
[epoch11, step3044]: loss 13.991724
[epoch11, step3045]: loss 2.965382
[epoch11, step3046]: loss 1.540049
[epoch11, step3047]: loss 1.499199
[epoch11, step3048]: loss 1.537826
[epoch11, step3049]: loss 2.152895
[epoch11, step3050]: loss 14.478607
[epoch11, step3051]: loss 12.421082
[epoch11, step3052]: loss 3.160720
[epoch11, step3053]: loss 2.538782
[epoch11, step3054]: loss 1.511365
[epoch11, step3055]: loss 1.847358
[epoch11, step3056]: loss 1.923217
[epoch11, step3057]: loss 1.753911
[epoch11, step3058]: loss 13.275263
[epoch11, step3059]: loss 1.461452
[epoch11, step3060]: loss 3.637157
[epoch11, step3061]: loss 1.004770
[epoch11, step3062]: loss 2.231091
[epoch11, step3063]: loss 5.459477
[epoch11, step3064]: loss 24.745842
[epoch11, step3065]: loss 1.576823
[epoch11, step3066]: loss 0.858232
[epoch11, step3067]: loss 1.036802
[epoch11, step3068]: loss 1.642817
[epoch11, step3069]: loss 2.097773
[epoch11, step3070]: loss 10.827318
[epoch11, step3071]: loss 3.098972
[epoch11, step3072]: loss 1.244309
[epoch11, step3073]: loss 0.953469
[epoch11, step3074]: loss 5.573193
[epoch11, step3075]: loss 0.876492
[epoch11, step3076]: loss 0.939283

[epoch11]: avg loss 0.939283

[epoch12, step1]: loss 1.212371
[epoch12, step2]: loss 1.383641
[epoch12, step3]: loss 2.350436
[epoch12, step4]: loss 1.470926
[epoch12, step5]: loss 2.206136
[epoch12, step6]: loss 4.017002
[epoch12, step7]: loss 6.273393
[epoch12, step8]: loss 14.971926
[epoch12, step9]: loss 1.717571
[epoch12, step10]: loss 3.234318
[epoch12, step11]: loss 3.698999
[epoch12, step12]: loss 2.834954
[epoch12, step13]: loss 1.940338
[epoch12, step14]: loss 5.309681
[epoch12, step15]: loss 9.293710
[epoch12, step16]: loss 1.869280
[epoch12, step17]: loss 6.977230
[epoch12, step18]: loss 1.708777
[epoch12, step19]: loss 1.097180
[epoch12, step20]: loss 0.973561
[epoch12, step21]: loss 3.599643
[epoch12, step22]: loss 2.151216
[epoch12, step23]: loss 12.856236
[epoch12, step24]: loss 10.759567
[epoch12, step25]: loss 11.774824
[epoch12, step26]: loss 1.697877
[epoch12, step27]: loss 1.070376
[epoch12, step28]: loss 7.476141
[epoch12, step29]: loss 1.489775
[epoch12, step30]: loss 19.555132
[epoch12, step31]: loss 1.514212
[epoch12, step32]: loss 5.919962
[epoch12, step33]: loss 1.110086
[epoch12, step34]: loss 3.019830
[epoch12, step35]: loss 3.099031
[epoch12, step36]: loss 1.928569
[epoch12, step37]: loss 4.874666
[epoch12, step38]: loss 9.495241
[epoch12, step39]: loss 2.689637
[epoch12, step40]: loss 2.820912
[epoch12, step41]: loss 0.889093
[epoch12, step42]: loss 1.787292
[epoch12, step43]: loss 2.221092
[epoch12, step44]: loss 1.289092
[epoch12, step45]: loss 20.940231
[epoch12, step46]: loss 17.654272
[epoch12, step47]: loss 0.913543
[epoch12, step48]: loss 2.181557
[epoch12, step49]: loss 31.269943
[epoch12, step50]: loss 0.958267
[epoch12, step51]: loss 1.984938
[epoch12, step52]: loss 20.598785
[epoch12, step53]: loss 15.559422
[epoch12, step54]: loss 1.937150
[epoch12, step55]: loss 11.804060
[epoch12, step56]: loss 8.080515
[epoch12, step57]: loss 1.072820
[epoch12, step58]: loss 9.962962
[epoch12, step59]: loss 9.748583
[epoch12, step60]: loss 13.443165
[epoch12, step61]: loss 1.577218
[epoch12, step62]: loss 7.085927
[epoch12, step63]: loss 9.296876
[epoch12, step64]: loss 3.386061
[epoch12, step65]: loss 1.581720
[epoch12, step66]: loss 7.455903
[epoch12, step67]: loss 2.434897
[epoch12, step68]: loss 1.733671
[epoch12, step69]: loss 14.025157
[epoch12, step70]: loss 16.361727
[epoch12, step71]: loss 2.164585
[epoch12, step72]: loss 1.262079
[epoch12, step73]: loss 11.851481
[epoch12, step74]: loss 1.632694
[epoch12, step75]: loss 1.229176
[epoch12, step76]: loss 1.053144
[epoch12, step77]: loss 11.857652
[epoch12, step78]: loss 2.492042
[epoch12, step79]: loss 13.825572
[epoch12, step80]: loss 1.514363
[epoch12, step81]: loss 3.575618
[epoch12, step82]: loss 2.735117
[epoch12, step83]: loss 3.191619
[epoch12, step84]: loss 2.736062
[epoch12, step85]: loss 1.345983
[epoch12, step86]: loss 1.691278
[epoch12, step87]: loss 2.845517
[epoch12, step88]: loss 9.131409
[epoch12, step89]: loss 1.388813
[epoch12, step90]: loss 1.623132
[epoch12, step91]: loss 1.622493
[epoch12, step92]: loss 1.020211
[epoch12, step93]: loss 11.602494
[epoch12, step94]: loss 1.452748
[epoch12, step95]: loss 9.257724
[epoch12, step96]: loss 1.428576
[epoch12, step97]: loss 1.143808
[epoch12, step98]: loss 8.656265
[epoch12, step99]: loss 11.125538
[epoch12, step100]: loss 0.886482
[epoch12, step101]: loss 9.180874
[epoch12, step102]: loss 4.643290
[epoch12, step103]: loss 0.600498
[epoch12, step104]: loss 17.111376
[epoch12, step105]: loss 1.250055
[epoch12, step106]: loss 1.465845
[epoch12, step107]: loss 2.820162
[epoch12, step108]: loss 10.222634
[epoch12, step109]: loss 0.807196
[epoch12, step110]: loss 2.093149
[epoch12, step111]: loss 2.027671
[epoch12, step112]: loss 10.784360
[epoch12, step113]: loss 20.251781
[epoch12, step114]: loss 20.142330
[epoch12, step115]: loss 1.937880
[epoch12, step116]: loss 4.141159
[epoch12, step117]: loss 5.100577
[epoch12, step118]: loss 1.170247
[epoch12, step119]: loss 2.853251
[epoch12, step120]: loss 8.253551
[epoch12, step121]: loss 8.737776
[epoch12, step122]: loss 1.774803
[epoch12, step123]: loss 3.840729
[epoch12, step124]: loss 1.765893
[epoch12, step125]: loss 1.169513
[epoch12, step126]: loss 0.989698
[epoch12, step127]: loss 1.075292
[epoch12, step128]: loss 1.070282
[epoch12, step129]: loss 1.596513
[epoch12, step130]: loss 14.658751
[epoch12, step131]: loss 1.197171
[epoch12, step132]: loss 1.072747
[epoch12, step133]: loss 7.760838
[epoch12, step134]: loss 1.064512
[epoch12, step135]: loss 18.463356
[epoch12, step136]: loss 1.057618
[epoch12, step137]: loss 3.977945
[epoch12, step138]: loss 1.690361
[epoch12, step139]: loss 4.934061
[epoch12, step140]: loss 2.090651
[epoch12, step141]: loss 2.195182
[epoch12, step142]: loss 13.622858
[epoch12, step143]: loss 17.590771
[epoch12, step144]: loss 1.622415
[epoch12, step145]: loss 1.110885
[epoch12, step146]: loss 3.705222
[epoch12, step147]: loss 1.140235
[epoch12, step148]: loss 1.026861
[epoch12, step149]: loss 1.355488
[epoch12, step150]: loss 0.813925
[epoch12, step151]: loss 1.354350
[epoch12, step152]: loss 12.259433
[epoch12, step153]: loss 2.757200
[epoch12, step154]: loss 11.931637
[epoch12, step155]: loss 5.221323
[epoch12, step156]: loss 1.503013
[epoch12, step157]: loss 10.847959
[epoch12, step158]: loss 2.814648
[epoch12, step159]: loss 18.396212
[epoch12, step160]: loss 1.006489
[epoch12, step161]: loss 1.993167
[epoch12, step162]: loss 1.232224
[epoch12, step163]: loss 0.667110
[epoch12, step164]: loss 11.298960
[epoch12, step165]: loss 1.313707
[epoch12, step166]: loss 4.593118
[epoch12, step167]: loss 2.422894
[epoch12, step168]: loss 6.024665
[epoch12, step169]: loss 1.582545
[epoch12, step170]: loss 2.872171
[epoch12, step171]: loss 2.718274
[epoch12, step172]: loss 4.172956
[epoch12, step173]: loss 1.694925
[epoch12, step174]: loss 5.661613
[epoch12, step175]: loss 1.434809
[epoch12, step176]: loss 5.926523
[epoch12, step177]: loss 4.959152
[epoch12, step178]: loss 1.299322
[epoch12, step179]: loss 0.936467
[epoch12, step180]: loss 19.790476
[epoch12, step181]: loss 1.571276
[epoch12, step182]: loss 1.040383
[epoch12, step183]: loss 1.429500
[epoch12, step184]: loss 1.101498
[epoch12, step185]: loss 3.075357
[epoch12, step186]: loss 3.644800
[epoch12, step187]: loss 10.734584
[epoch12, step188]: loss 4.684124
[epoch12, step189]: loss 2.123174
[epoch12, step190]: loss 9.181253
[epoch12, step191]: loss 3.081699
[epoch12, step192]: loss 27.796192
[epoch12, step193]: loss 1.971280
[epoch12, step194]: loss 26.681932
[epoch12, step195]: loss 12.170383
[epoch12, step196]: loss 1.256505
[epoch12, step197]: loss 8.603574
[epoch12, step198]: loss 2.096382
[epoch12, step199]: loss 1.630640
[epoch12, step200]: loss 2.480681
[epoch12, step201]: loss 1.753361
[epoch12, step202]: loss 8.676459
[epoch12, step203]: loss 2.135435
[epoch12, step204]: loss 1.139316
[epoch12, step205]: loss 1.514025
[epoch12, step206]: loss 2.393872
[epoch12, step207]: loss 0.958884
[epoch12, step208]: loss 0.894683
[epoch12, step209]: loss 21.084469
[epoch12, step210]: loss 18.391727
[epoch12, step211]: loss 0.900893
[epoch12, step212]: loss 2.628805
[epoch12, step213]: loss 1.284264
[epoch12, step214]: loss 1.031335
[epoch12, step215]: loss 1.164059
[epoch12, step216]: loss 2.187127
[epoch12, step217]: loss 1.040383
[epoch12, step218]: loss 1.140813
[epoch12, step219]: loss 6.465909
[epoch12, step220]: loss 3.300894
[epoch12, step221]: loss 1.656881
[epoch12, step222]: loss 0.850557
[epoch12, step223]: loss 1.883447
[epoch12, step224]: loss 14.256922
[epoch12, step225]: loss 10.331880
[epoch12, step226]: loss 18.267389
[epoch12, step227]: loss 9.190325
[epoch12, step228]: loss 1.495364
[epoch12, step229]: loss 8.078851
[epoch12, step230]: loss 32.041458
[epoch12, step231]: loss 2.849135
[epoch12, step232]: loss 2.045264
[epoch12, step233]: loss 1.275441
[epoch12, step234]: loss 3.349539
[epoch12, step235]: loss 2.465063
[epoch12, step236]: loss 7.223887
[epoch12, step237]: loss 0.929482
[epoch12, step238]: loss 0.610403
[epoch12, step239]: loss 2.221595
[epoch12, step240]: loss 8.796654
[epoch12, step241]: loss 1.778800
[epoch12, step242]: loss 2.511737
[epoch12, step243]: loss 17.037613
[epoch12, step244]: loss 2.733430
[epoch12, step245]: loss 2.450333
[epoch12, step246]: loss 18.989616
[epoch12, step247]: loss 1.140228
[epoch12, step248]: loss 1.460638
[epoch12, step249]: loss 1.538223
[epoch12, step250]: loss 1.153178
[epoch12, step251]: loss 13.830839
[epoch12, step252]: loss 5.045438
[epoch12, step253]: loss 10.085496
[epoch12, step254]: loss 1.424605
[epoch12, step255]: loss 2.040655
[epoch12, step256]: loss 1.584282
[epoch12, step257]: loss 3.389067
[epoch12, step258]: loss 5.557133
[epoch12, step259]: loss 4.895435
[epoch12, step260]: loss 3.734823
[epoch12, step261]: loss 1.815198
[epoch12, step262]: loss 10.467068
[epoch12, step263]: loss 13.705860
[epoch12, step264]: loss 3.266979
[epoch12, step265]: loss 2.006466
[epoch12, step266]: loss 1.165475
[epoch12, step267]: loss 10.062618
[epoch12, step268]: loss 7.452146
[epoch12, step269]: loss 6.192626
[epoch12, step270]: loss 17.832706
[epoch12, step271]: loss 3.815933
[epoch12, step272]: loss 2.157021
[epoch12, step273]: loss 2.141460
[epoch12, step274]: loss 2.849319
[epoch12, step275]: loss 0.874463
[epoch12, step276]: loss 0.803103
[epoch12, step277]: loss 2.944157
[epoch12, step278]: loss 2.467512
[epoch12, step279]: loss 2.408696
[epoch12, step280]: loss 3.469052
[epoch12, step281]: loss 1.970956
[epoch12, step282]: loss 0.787720
[epoch12, step283]: loss 1.920443
[epoch12, step284]: loss 14.140202
[epoch12, step285]: loss 1.163883
[epoch12, step286]: loss 1.176332
[epoch12, step287]: loss 12.037865
[epoch12, step288]: loss 2.129790
[epoch12, step289]: loss 3.130708
[epoch12, step290]: loss 2.167680
[epoch12, step291]: loss 0.835243
[epoch12, step292]: loss 1.903923
[epoch12, step293]: loss 8.763788
[epoch12, step294]: loss 1.241911
[epoch12, step295]: loss 1.801270
[epoch12, step296]: loss 3.941551
[epoch12, step297]: loss 1.042331
[epoch12, step298]: loss 8.184941
[epoch12, step299]: loss 4.136730
[epoch12, step300]: loss 5.481342
[epoch12, step301]: loss 2.125426
[epoch12, step302]: loss 9.610818
[epoch12, step303]: loss 2.965953
[epoch12, step304]: loss 4.484419
[epoch12, step305]: loss 2.171253
[epoch12, step306]: loss 1.334254
[epoch12, step307]: loss 1.782734
[epoch12, step308]: loss 3.148841
[epoch12, step309]: loss 19.856167
[epoch12, step310]: loss 0.634695
[epoch12, step311]: loss 3.234238
[epoch12, step312]: loss 10.928354
[epoch12, step313]: loss 18.206059
[epoch12, step314]: loss 1.328655
[epoch12, step315]: loss 14.515441
[epoch12, step316]: loss 18.570974
[epoch12, step317]: loss 3.493163
[epoch12, step318]: loss 3.006144
[epoch12, step319]: loss 1.196673
[epoch12, step320]: loss 2.266749
[epoch12, step321]: loss 18.593468
[epoch12, step322]: loss 1.320275
[epoch12, step323]: loss 13.587694
[epoch12, step324]: loss 3.564290
[epoch12, step325]: loss 13.065203
[epoch12, step326]: loss 3.342791
[epoch12, step327]: loss 4.078443
[epoch12, step328]: loss 0.765280
[epoch12, step329]: loss 2.509866
[epoch12, step330]: loss 2.863477
[epoch12, step331]: loss 1.063856
[epoch12, step332]: loss 5.230597
[epoch12, step333]: loss 1.495008
[epoch12, step334]: loss 1.446223
[epoch12, step335]: loss 5.101549
[epoch12, step336]: loss 0.983521
[epoch12, step337]: loss 3.513747
[epoch12, step338]: loss 30.139914
[epoch12, step339]: loss 1.619028
[epoch12, step340]: loss 3.651362
[epoch12, step341]: loss 10.166768
[epoch12, step342]: loss 12.996474
[epoch12, step343]: loss 4.699314
[epoch12, step344]: loss 1.406313
[epoch12, step345]: loss 4.595028
[epoch12, step346]: loss 1.478236
[epoch12, step347]: loss 1.242783
[epoch12, step348]: loss 1.958714
[epoch12, step349]: loss 1.304625
[epoch12, step350]: loss 7.975778
[epoch12, step351]: loss 0.981118
[epoch12, step352]: loss 1.825688
[epoch12, step353]: loss 2.342640
[epoch12, step354]: loss 2.217297
[epoch12, step355]: loss 3.491157
[epoch12, step356]: loss 1.584213
[epoch12, step357]: loss 1.894784
[epoch12, step358]: loss 7.961061
[epoch12, step359]: loss 15.468967
[epoch12, step360]: loss 20.588503
[epoch12, step361]: loss 1.741297
[epoch12, step362]: loss 14.542013
[epoch12, step363]: loss 0.946529
[epoch12, step364]: loss 2.541960
[epoch12, step365]: loss 2.385267
[epoch12, step366]: loss 14.580242
[epoch12, step367]: loss 1.359566
[epoch12, step368]: loss 2.849034
[epoch12, step369]: loss 7.771438
[epoch12, step370]: loss 3.040468
[epoch12, step371]: loss 1.681668
[epoch12, step372]: loss 1.875386
[epoch12, step373]: loss 2.989937
[epoch12, step374]: loss 1.849085
[epoch12, step375]: loss 2.007593
[epoch12, step376]: loss 2.309246
[epoch12, step377]: loss 1.474988
[epoch12, step378]: loss 15.031219
[epoch12, step379]: loss 10.409583
[epoch12, step380]: loss 14.748981
[epoch12, step381]: loss 0.805274
[epoch12, step382]: loss 1.166008
[epoch12, step383]: loss 5.586651
[epoch12, step384]: loss 1.662528
[epoch12, step385]: loss 2.822472
[epoch12, step386]: loss 5.280384
[epoch12, step387]: loss 1.573720
[epoch12, step388]: loss 2.112309
[epoch12, step389]: loss 1.823132
[epoch12, step390]: loss 1.681810
[epoch12, step391]: loss 4.336242
[epoch12, step392]: loss 11.238194
[epoch12, step393]: loss 4.138756
[epoch12, step394]: loss 3.264721
[epoch12, step395]: loss 8.447088
[epoch12, step396]: loss 1.197630
[epoch12, step397]: loss 1.004519
[epoch12, step398]: loss 2.111387
[epoch12, step399]: loss 3.735077
[epoch12, step400]: loss 0.786287
[epoch12, step401]: loss 6.011883
[epoch12, step402]: loss 1.154758
[epoch12, step403]: loss 3.929316
[epoch12, step404]: loss 1.537200
[epoch12, step405]: loss 2.757797
[epoch12, step406]: loss 1.547925
[epoch12, step407]: loss 0.972535
[epoch12, step408]: loss 2.126524
[epoch12, step409]: loss 1.237394
[epoch12, step410]: loss 0.987282
[epoch12, step411]: loss 1.114968
[epoch12, step412]: loss 2.785746
[epoch12, step413]: loss 2.595805
[epoch12, step414]: loss 1.531918
[epoch12, step415]: loss 14.751616
[epoch12, step416]: loss 4.576206
[epoch12, step417]: loss 0.704418
[epoch12, step418]: loss 2.579372
[epoch12, step419]: loss 0.798028
[epoch12, step420]: loss 2.650418
[epoch12, step421]: loss 1.357812
[epoch12, step422]: loss 1.040270
[epoch12, step423]: loss 1.104025
[epoch12, step424]: loss 2.261006
[epoch12, step425]: loss 1.099611
[epoch12, step426]: loss 11.740635
[epoch12, step427]: loss 4.816415
[epoch12, step428]: loss 0.798488
[epoch12, step429]: loss 0.924994
[epoch12, step430]: loss 1.548389
[epoch12, step431]: loss 1.827055
[epoch12, step432]: loss 2.703595
[epoch12, step433]: loss 0.723865
[epoch12, step434]: loss 4.017566
[epoch12, step435]: loss 4.440523
[epoch12, step436]: loss 3.378499
[epoch12, step437]: loss 2.481120
[epoch12, step438]: loss 2.364669
[epoch12, step439]: loss 9.473886
[epoch12, step440]: loss 1.127588
[epoch12, step441]: loss 1.087091
[epoch12, step442]: loss 9.169389
[epoch12, step443]: loss 2.084129
[epoch12, step444]: loss 10.276472
[epoch12, step445]: loss 28.062582
[epoch12, step446]: loss 2.562797
[epoch12, step447]: loss 0.871018
[epoch12, step448]: loss 2.387337
[epoch12, step449]: loss 1.173941
[epoch12, step450]: loss 1.284006
[epoch12, step451]: loss 4.733129
[epoch12, step452]: loss 1.184432
[epoch12, step453]: loss 2.011856
[epoch12, step454]: loss 1.605934
[epoch12, step455]: loss 14.844918
[epoch12, step456]: loss 3.313132
[epoch12, step457]: loss 1.666548
[epoch12, step458]: loss 3.364111
[epoch12, step459]: loss 2.149538
[epoch12, step460]: loss 0.752362
[epoch12, step461]: loss 2.139263
[epoch12, step462]: loss 1.191541
[epoch12, step463]: loss 17.297762
[epoch12, step464]: loss 24.900547
[epoch12, step465]: loss 2.441356
[epoch12, step466]: loss 3.557801
[epoch12, step467]: loss 2.478089
[epoch12, step468]: loss 1.321813
[epoch12, step469]: loss 1.969692
[epoch12, step470]: loss 16.174572
[epoch12, step471]: loss 18.750179
[epoch12, step472]: loss 1.531181
[epoch12, step473]: loss 0.995585
[epoch12, step474]: loss 10.926767
[epoch12, step475]: loss 1.810071
[epoch12, step476]: loss 1.999506
[epoch12, step477]: loss 3.667744
[epoch12, step478]: loss 14.308310
[epoch12, step479]: loss 3.153153
[epoch12, step480]: loss 5.649879
[epoch12, step481]: loss 1.226967
[epoch12, step482]: loss 1.251975
[epoch12, step483]: loss 8.900531
[epoch12, step484]: loss 1.733229
[epoch12, step485]: loss 1.302556
[epoch12, step486]: loss 1.004432
[epoch12, step487]: loss 10.899776
[epoch12, step488]: loss 9.935474
[epoch12, step489]: loss 2.060984
[epoch12, step490]: loss 3.162580
[epoch12, step491]: loss 10.322896
[epoch12, step492]: loss 14.944118
[epoch12, step493]: loss 7.386178
[epoch12, step494]: loss 1.842918
[epoch12, step495]: loss 1.593995
[epoch12, step496]: loss 10.747820
[epoch12, step497]: loss 2.103244
[epoch12, step498]: loss 2.403022
[epoch12, step499]: loss 4.046051
[epoch12, step500]: loss 0.922122
[epoch12, step501]: loss 2.712777
[epoch12, step502]: loss 13.440607
[epoch12, step503]: loss 1.177845
[epoch12, step504]: loss 1.310388
[epoch12, step505]: loss 1.410993
[epoch12, step506]: loss 17.320124
[epoch12, step507]: loss 1.708375
[epoch12, step508]: loss 3.388986
[epoch12, step509]: loss 2.159023
[epoch12, step510]: loss 2.814041
[epoch12, step511]: loss 7.702187
[epoch12, step512]: loss 1.108422
[epoch12, step513]: loss 13.353193
[epoch12, step514]: loss 1.758562
[epoch12, step515]: loss 7.457336
[epoch12, step516]: loss 1.390664
[epoch12, step517]: loss 1.442474
[epoch12, step518]: loss 2.568997
[epoch12, step519]: loss 3.834237
[epoch12, step520]: loss 2.026911
[epoch12, step521]: loss 0.990439
[epoch12, step522]: loss 2.030758
[epoch12, step523]: loss 1.373860
[epoch12, step524]: loss 1.199859
[epoch12, step525]: loss 2.033997
[epoch12, step526]: loss 1.745670
[epoch12, step527]: loss 1.388784
[epoch12, step528]: loss 2.544897
[epoch12, step529]: loss 7.982505
[epoch12, step530]: loss 6.870581
[epoch12, step531]: loss 10.871473
[epoch12, step532]: loss 13.630681
[epoch12, step533]: loss 17.588984
[epoch12, step534]: loss 0.961047
[epoch12, step535]: loss 9.758976
[epoch12, step536]: loss 0.801189
[epoch12, step537]: loss 0.910595
[epoch12, step538]: loss 6.349234
[epoch12, step539]: loss 0.874174
[epoch12, step540]: loss 9.247364
[epoch12, step541]: loss 1.464418
[epoch12, step542]: loss 3.415135
[epoch12, step543]: loss 8.157224
[epoch12, step544]: loss 5.434747
[epoch12, step545]: loss 2.699607
[epoch12, step546]: loss 0.920438
[epoch12, step547]: loss 1.609744
[epoch12, step548]: loss 3.259748
[epoch12, step549]: loss 3.531707
[epoch12, step550]: loss 1.063704
[epoch12, step551]: loss 1.597929
[epoch12, step552]: loss 1.356752
[epoch12, step553]: loss 10.050077
[epoch12, step554]: loss 15.973915
[epoch12, step555]: loss 2.854817
[epoch12, step556]: loss 10.918285
[epoch12, step557]: loss 10.880180
[epoch12, step558]: loss 4.337974
[epoch12, step559]: loss 1.521031
[epoch12, step560]: loss 9.571630
[epoch12, step561]: loss 1.761958
[epoch12, step562]: loss 1.265217
[epoch12, step563]: loss 3.834422
[epoch12, step564]: loss 4.783065
[epoch12, step565]: loss 15.113915
[epoch12, step566]: loss 19.832926
[epoch12, step567]: loss 3.033748
[epoch12, step568]: loss 7.149418
[epoch12, step569]: loss 10.218591
[epoch12, step570]: loss 5.756793
[epoch12, step571]: loss 3.811715
[epoch12, step572]: loss 3.359369
[epoch12, step573]: loss 1.346306
[epoch12, step574]: loss 16.676855
[epoch12, step575]: loss 1.663800
[epoch12, step576]: loss 8.533857
[epoch12, step577]: loss 11.234693
[epoch12, step578]: loss 0.888077
[epoch12, step579]: loss 2.707736
[epoch12, step580]: loss 1.658961
[epoch12, step581]: loss 4.899826
[epoch12, step582]: loss 25.627460
[epoch12, step583]: loss 3.657538
[epoch12, step584]: loss 4.234995
[epoch12, step585]: loss 10.916479
[epoch12, step586]: loss 1.948119
[epoch12, step587]: loss 1.130522
[epoch12, step588]: loss 10.581775
[epoch12, step589]: loss 1.482661
[epoch12, step590]: loss 1.599257
[epoch12, step591]: loss 1.559303
[epoch12, step592]: loss 1.447620
[epoch12, step593]: loss 10.277283
[epoch12, step594]: loss 11.387258
[epoch12, step595]: loss 3.735807
[epoch12, step596]: loss 23.981075
[epoch12, step597]: loss 2.011560
[epoch12, step598]: loss 0.713419
[epoch12, step599]: loss 1.023040
[epoch12, step600]: loss 5.492598
[epoch12, step601]: loss 1.722132
[epoch12, step602]: loss 15.237278
[epoch12, step603]: loss 1.015486
[epoch12, step604]: loss 3.056473
[epoch12, step605]: loss 18.931879
[epoch12, step606]: loss 0.978964
[epoch12, step607]: loss 4.610543
[epoch12, step608]: loss 1.658095
[epoch12, step609]: loss 0.690017
[epoch12, step610]: loss 7.524194
[epoch12, step611]: loss 1.989941
[epoch12, step612]: loss 1.552505
[epoch12, step613]: loss 9.435760
[epoch12, step614]: loss 14.478934
[epoch12, step615]: loss 19.231113
[epoch12, step616]: loss 1.314058
[epoch12, step617]: loss 7.496167
[epoch12, step618]: loss 11.404382
[epoch12, step619]: loss 2.364305
[epoch12, step620]: loss 1.219510
[epoch12, step621]: loss 2.254560
[epoch12, step622]: loss 1.272083
[epoch12, step623]: loss 1.084256
[epoch12, step624]: loss 3.658271
[epoch12, step625]: loss 11.478775
[epoch12, step626]: loss 8.516455
[epoch12, step627]: loss 1.105172
[epoch12, step628]: loss 1.192006
[epoch12, step629]: loss 1.297304
[epoch12, step630]: loss 3.349427
[epoch12, step631]: loss 26.401501
[epoch12, step632]: loss 1.605531
[epoch12, step633]: loss 12.996615
[epoch12, step634]: loss 1.171909
[epoch12, step635]: loss 18.953146
[epoch12, step636]: loss 1.722586
[epoch12, step637]: loss 2.836328
[epoch12, step638]: loss 1.673535
[epoch12, step639]: loss 0.809468
[epoch12, step640]: loss 1.397390
[epoch12, step641]: loss 1.323155
[epoch12, step642]: loss 1.161997
[epoch12, step643]: loss 2.691048
[epoch12, step644]: loss 24.752192
[epoch12, step645]: loss 11.792398
[epoch12, step646]: loss 5.392492
[epoch12, step647]: loss 1.828943
[epoch12, step648]: loss 7.521033
[epoch12, step649]: loss 1.653462
[epoch12, step650]: loss 3.037716
[epoch12, step651]: loss 1.177764
[epoch12, step652]: loss 0.744190
[epoch12, step653]: loss 7.933312
[epoch12, step654]: loss 16.538761
[epoch12, step655]: loss 2.386319
[epoch12, step656]: loss 19.012043
[epoch12, step657]: loss 2.236058
[epoch12, step658]: loss 1.050680
[epoch12, step659]: loss 14.893963
[epoch12, step660]: loss 2.595189
[epoch12, step661]: loss 10.304586
[epoch12, step662]: loss 12.176378
[epoch12, step663]: loss 0.938592
[epoch12, step664]: loss 0.935465
[epoch12, step665]: loss 14.875966
[epoch12, step666]: loss 1.255081
[epoch12, step667]: loss 1.400852
[epoch12, step668]: loss 2.491811
[epoch12, step669]: loss 15.979815
[epoch12, step670]: loss 5.970490
[epoch12, step671]: loss 0.765626
[epoch12, step672]: loss 1.377309
[epoch12, step673]: loss 1.207340
[epoch12, step674]: loss 1.112556
[epoch12, step675]: loss 13.360126
[epoch12, step676]: loss 1.672098
[epoch12, step677]: loss 13.794903
[epoch12, step678]: loss 8.758745
[epoch12, step679]: loss 1.436092
[epoch12, step680]: loss 2.834525
[epoch12, step681]: loss 2.897328
[epoch12, step682]: loss 1.031297
[epoch12, step683]: loss 1.720724
[epoch12, step684]: loss 4.127819
[epoch12, step685]: loss 20.713133
[epoch12, step686]: loss 1.316071
[epoch12, step687]: loss 18.243698
[epoch12, step688]: loss 5.985640
[epoch12, step689]: loss 1.419358
[epoch12, step690]: loss 1.615089
[epoch12, step691]: loss 13.634651
[epoch12, step692]: loss 1.715482
[epoch12, step693]: loss 13.332603
[epoch12, step694]: loss 13.806602
[epoch12, step695]: loss 1.817624
[epoch12, step696]: loss 2.125539
[epoch12, step697]: loss 1.419779
[epoch12, step698]: loss 3.817321
[epoch12, step699]: loss 2.027905
[epoch12, step700]: loss 2.754616
[epoch12, step701]: loss 1.824140
[epoch12, step702]: loss 3.915125
[epoch12, step703]: loss 9.896019
[epoch12, step704]: loss 2.508097
[epoch12, step705]: loss 1.983442
[epoch12, step706]: loss 1.175509
[epoch12, step707]: loss 1.303593
[epoch12, step708]: loss 9.719181
[epoch12, step709]: loss 0.893344
[epoch12, step710]: loss 10.773958
[epoch12, step711]: loss 1.480282
[epoch12, step712]: loss 1.208040
[epoch12, step713]: loss 3.538128
[epoch12, step714]: loss 2.416926
[epoch12, step715]: loss 1.964185
[epoch12, step716]: loss 2.561413
[epoch12, step717]: loss 1.431070
[epoch12, step718]: loss 1.302682
[epoch12, step719]: loss 3.249538
[epoch12, step720]: loss 4.839200
[epoch12, step721]: loss 4.541736
[epoch12, step722]: loss 17.474644
[epoch12, step723]: loss 1.046581
[epoch12, step724]: loss 1.410805
[epoch12, step725]: loss 6.564918
[epoch12, step726]: loss 29.418682
[epoch12, step727]: loss 13.083323
[epoch12, step728]: loss 2.826589
[epoch12, step729]: loss 2.820655
[epoch12, step730]: loss 1.862166
[epoch12, step731]: loss 0.937348
[epoch12, step732]: loss 2.506137
[epoch12, step733]: loss 11.154070
[epoch12, step734]: loss 2.244574
[epoch12, step735]: loss 4.339693
[epoch12, step736]: loss 0.766728
[epoch12, step737]: loss 1.767935
[epoch12, step738]: loss 25.230968
[epoch12, step739]: loss 0.932629
[epoch12, step740]: loss 13.336239
[epoch12, step741]: loss 7.264342
[epoch12, step742]: loss 11.364319
[epoch12, step743]: loss 1.460093
[epoch12, step744]: loss 0.639569
[epoch12, step745]: loss 13.358489
[epoch12, step746]: loss 2.112249
[epoch12, step747]: loss 1.781630
[epoch12, step748]: loss 1.222227
[epoch12, step749]: loss 4.240784
[epoch12, step750]: loss 1.652435
[epoch12, step751]: loss 1.011284
[epoch12, step752]: loss 3.430285
[epoch12, step753]: loss 1.367707
[epoch12, step754]: loss 1.301553
[epoch12, step755]: loss 1.758269
[epoch12, step756]: loss 1.412300
[epoch12, step757]: loss 2.397448
[epoch12, step758]: loss 7.933108
[epoch12, step759]: loss 1.295639
[epoch12, step760]: loss 1.651478
[epoch12, step761]: loss 1.443408
[epoch12, step762]: loss 5.026490
[epoch12, step763]: loss 6.045434
[epoch12, step764]: loss 1.917581
[epoch12, step765]: loss 20.928041
[epoch12, step766]: loss 8.951080
[epoch12, step767]: loss 0.705026
[epoch12, step768]: loss 1.698699
[epoch12, step769]: loss 2.440917
[epoch12, step770]: loss 5.815428
[epoch12, step771]: loss 2.073166
[epoch12, step772]: loss 1.599600
[epoch12, step773]: loss 5.686019
[epoch12, step774]: loss 4.271092
[epoch12, step775]: loss 1.006587
[epoch12, step776]: loss 2.575567
[epoch12, step777]: loss 3.557935
[epoch12, step778]: loss 3.469207
[epoch12, step779]: loss 1.051530
[epoch12, step780]: loss 3.230667
[epoch12, step781]: loss 19.842150
[epoch12, step782]: loss 1.480011
[epoch12, step783]: loss 3.574713
[epoch12, step784]: loss 10.417912
[epoch12, step785]: loss 1.897592
[epoch12, step786]: loss 4.677910
[epoch12, step787]: loss 2.242441
[epoch12, step788]: loss 2.381026
[epoch12, step789]: loss 2.752733
[epoch12, step790]: loss 2.651637
[epoch12, step791]: loss 0.771312
[epoch12, step792]: loss 2.641555
[epoch12, step793]: loss 15.021340
[epoch12, step794]: loss 3.180687
[epoch12, step795]: loss 3.441778
[epoch12, step796]: loss 1.365211
[epoch12, step797]: loss 32.338276
[epoch12, step798]: loss 1.488767
[epoch12, step799]: loss 2.114787
[epoch12, step800]: loss 0.668600
[epoch12, step801]: loss 1.190818
[epoch12, step802]: loss 0.646073
[epoch12, step803]: loss 16.956858
[epoch12, step804]: loss 1.927572
[epoch12, step805]: loss 0.931612
[epoch12, step806]: loss 1.001486
[epoch12, step807]: loss 1.105089
[epoch12, step808]: loss 0.817745
[epoch12, step809]: loss 0.776179
[epoch12, step810]: loss 1.181547
[epoch12, step811]: loss 19.528547
[epoch12, step812]: loss 14.618946
[epoch12, step813]: loss 4.322633
[epoch12, step814]: loss 2.208622
[epoch12, step815]: loss 1.828410
[epoch12, step816]: loss 8.594862
[epoch12, step817]: loss 2.895943
[epoch12, step818]: loss 4.543077
[epoch12, step819]: loss 1.107413
[epoch12, step820]: loss 18.669069
[epoch12, step821]: loss 1.226877
[epoch12, step822]: loss 13.243767
[epoch12, step823]: loss 18.674940
[epoch12, step824]: loss 1.002244
[epoch12, step825]: loss 5.781978
[epoch12, step826]: loss 3.888352
[epoch12, step827]: loss 1.194730
[epoch12, step828]: loss 1.154301
[epoch12, step829]: loss 4.789496
[epoch12, step830]: loss 1.247072
[epoch12, step831]: loss 1.430704
[epoch12, step832]: loss 1.564681
[epoch12, step833]: loss 17.684525
[epoch12, step834]: loss 1.743428
[epoch12, step835]: loss 2.755262
[epoch12, step836]: loss 7.639585
[epoch12, step837]: loss 1.446555
[epoch12, step838]: loss 12.853649
[epoch12, step839]: loss 10.469392
[epoch12, step840]: loss 1.339991
[epoch12, step841]: loss 29.501095
[epoch12, step842]: loss 1.600721
[epoch12, step843]: loss 1.215816
[epoch12, step844]: loss 2.826095
[epoch12, step845]: loss 9.978515
[epoch12, step846]: loss 4.306323
[epoch12, step847]: loss 1.469587
[epoch12, step848]: loss 2.010291
[epoch12, step849]: loss 1.882787
[epoch12, step850]: loss 2.821816
[epoch12, step851]: loss 2.473130
[epoch12, step852]: loss 0.842492
[epoch12, step853]: loss 3.411637
[epoch12, step854]: loss 0.883916
[epoch12, step855]: loss 7.593241
[epoch12, step856]: loss 8.433370
[epoch12, step857]: loss 1.918964
[epoch12, step858]: loss 1.560558
[epoch12, step859]: loss 2.256842
[epoch12, step860]: loss 7.344421
[epoch12, step861]: loss 1.830229
[epoch12, step862]: loss 1.353244
[epoch12, step863]: loss 2.734098
[epoch12, step864]: loss 4.246875
[epoch12, step865]: loss 2.112921
[epoch12, step866]: loss 14.329816
[epoch12, step867]: loss 1.555276
[epoch12, step868]: loss 1.279128
[epoch12, step869]: loss 1.039990
[epoch12, step870]: loss 10.119222
[epoch12, step871]: loss 7.865870
[epoch12, step872]: loss 6.620959
[epoch12, step873]: loss 2.371744
[epoch12, step874]: loss 3.551540
[epoch12, step875]: loss 11.807941
[epoch12, step876]: loss 1.637490
[epoch12, step877]: loss 2.582404
[epoch12, step878]: loss 1.206353
[epoch12, step879]: loss 2.922842
[epoch12, step880]: loss 14.085346
[epoch12, step881]: loss 1.217895
[epoch12, step882]: loss 7.423212
[epoch12, step883]: loss 1.082964
[epoch12, step884]: loss 1.054325
[epoch12, step885]: loss 0.677284
[epoch12, step886]: loss 4.289012
[epoch12, step887]: loss 8.556477
[epoch12, step888]: loss 19.155169
[epoch12, step889]: loss 2.379825
[epoch12, step890]: loss 0.719621
[epoch12, step891]: loss 0.731052
[epoch12, step892]: loss 10.369792
[epoch12, step893]: loss 0.796473
[epoch12, step894]: loss 11.695646
[epoch12, step895]: loss 2.435748
[epoch12, step896]: loss 14.607716
[epoch12, step897]: loss 2.382017
[epoch12, step898]: loss 2.529427
[epoch12, step899]: loss 2.189000
[epoch12, step900]: loss 1.918206
[epoch12, step901]: loss 1.639507
[epoch12, step902]: loss 19.770247
[epoch12, step903]: loss 2.151993
[epoch12, step904]: loss 10.192909
[epoch12, step905]: loss 4.876659
[epoch12, step906]: loss 1.473024
[epoch12, step907]: loss 1.075112
[epoch12, step908]: loss 5.126336
[epoch12, step909]: loss 15.452332
[epoch12, step910]: loss 14.726414
[epoch12, step911]: loss 9.784033
[epoch12, step912]: loss 2.252827
[epoch12, step913]: loss 2.080640
[epoch12, step914]: loss 2.702357
[epoch12, step915]: loss 14.124114
[epoch12, step916]: loss 2.279828
[epoch12, step917]: loss 1.276255
[epoch12, step918]: loss 3.208142
[epoch12, step919]: loss 1.810255
[epoch12, step920]: loss 3.409394
[epoch12, step921]: loss 1.069537
[epoch12, step922]: loss 4.992190
[epoch12, step923]: loss 0.874033
[epoch12, step924]: loss 2.785590
[epoch12, step925]: loss 1.158342
[epoch12, step926]: loss 0.698885
[epoch12, step927]: loss 1.080241
[epoch12, step928]: loss 1.671225
[epoch12, step929]: loss 12.945230
[epoch12, step930]: loss 1.403028
[epoch12, step931]: loss 1.628932
[epoch12, step932]: loss 1.030638
[epoch12, step933]: loss 1.444894
[epoch12, step934]: loss 1.500415
[epoch12, step935]: loss 0.713011
[epoch12, step936]: loss 1.477817
[epoch12, step937]: loss 0.943829
[epoch12, step938]: loss 1.427014
[epoch12, step939]: loss 1.422845
[epoch12, step940]: loss 8.597931
[epoch12, step941]: loss 2.886826
[epoch12, step942]: loss 1.699683
[epoch12, step943]: loss 4.244776
[epoch12, step944]: loss 1.260067
[epoch12, step945]: loss 5.699697
[epoch12, step946]: loss 1.493295
[epoch12, step947]: loss 11.229705
[epoch12, step948]: loss 2.557496
[epoch12, step949]: loss 11.004473
[epoch12, step950]: loss 1.577852
[epoch12, step951]: loss 0.815218
[epoch12, step952]: loss 1.587968
[epoch12, step953]: loss 3.384553
[epoch12, step954]: loss 2.111135
[epoch12, step955]: loss 1.202574
[epoch12, step956]: loss 1.384115
[epoch12, step957]: loss 10.326277
[epoch12, step958]: loss 1.782401
[epoch12, step959]: loss 3.452697
[epoch12, step960]: loss 3.629681
[epoch12, step961]: loss 10.018433
[epoch12, step962]: loss 3.575328
[epoch12, step963]: loss 2.571185
[epoch12, step964]: loss 1.139564
[epoch12, step965]: loss 1.198536
[epoch12, step966]: loss 2.491651
[epoch12, step967]: loss 2.818310
[epoch12, step968]: loss 1.185796
[epoch12, step969]: loss 13.144617
[epoch12, step970]: loss 6.029123
[epoch12, step971]: loss 18.471897
[epoch12, step972]: loss 1.604906
[epoch12, step973]: loss 1.415184
[epoch12, step974]: loss 1.749151
[epoch12, step975]: loss 1.412985
[epoch12, step976]: loss 3.274079
[epoch12, step977]: loss 23.317642
[epoch12, step978]: loss 3.060583
[epoch12, step979]: loss 11.050031
[epoch12, step980]: loss 2.499012
[epoch12, step981]: loss 4.169416
[epoch12, step982]: loss 10.856710
[epoch12, step983]: loss 2.567972
[epoch12, step984]: loss 16.416950
[epoch12, step985]: loss 18.182280
[epoch12, step986]: loss 12.475408
[epoch12, step987]: loss 1.626762
[epoch12, step988]: loss 32.770489
[epoch12, step989]: loss 2.371439
[epoch12, step990]: loss 3.221999
[epoch12, step991]: loss 5.591093
[epoch12, step992]: loss 5.476287
[epoch12, step993]: loss 1.085222
[epoch12, step994]: loss 0.896664
[epoch12, step995]: loss 3.364235
[epoch12, step996]: loss 11.581724
[epoch12, step997]: loss 1.523466
[epoch12, step998]: loss 2.625314
[epoch12, step999]: loss 7.838242
[epoch12, step1000]: loss 12.360415
[epoch12, step1001]: loss 1.628272
[epoch12, step1002]: loss 16.961708
[epoch12, step1003]: loss 6.547425
[epoch12, step1004]: loss 1.327623
[epoch12, step1005]: loss 2.463239
[epoch12, step1006]: loss 2.893381
[epoch12, step1007]: loss 11.645258
[epoch12, step1008]: loss 1.032499
[epoch12, step1009]: loss 2.159024
[epoch12, step1010]: loss 1.389302
[epoch12, step1011]: loss 2.010223
[epoch12, step1012]: loss 9.618964
[epoch12, step1013]: loss 10.199837
[epoch12, step1014]: loss 10.521455
[epoch12, step1015]: loss 2.736897
[epoch12, step1016]: loss 8.884064
[epoch12, step1017]: loss 9.336864
[epoch12, step1018]: loss 3.694497
[epoch12, step1019]: loss 5.158526
[epoch12, step1020]: loss 0.836828
[epoch12, step1021]: loss 1.084876
[epoch12, step1022]: loss 3.668715
[epoch12, step1023]: loss 19.157326
[epoch12, step1024]: loss 1.218417
[epoch12, step1025]: loss 1.237987
[epoch12, step1026]: loss 13.366061
[epoch12, step1027]: loss 0.958618
[epoch12, step1028]: loss 1.143471
[epoch12, step1029]: loss 1.388263
[epoch12, step1030]: loss 7.110003
[epoch12, step1031]: loss 3.043911
[epoch12, step1032]: loss 2.408061
[epoch12, step1033]: loss 21.681290
[epoch12, step1034]: loss 1.681762
[epoch12, step1035]: loss 1.701149
[epoch12, step1036]: loss 9.606777
[epoch12, step1037]: loss 1.126366
[epoch12, step1038]: loss 2.515752
[epoch12, step1039]: loss 12.712593
[epoch12, step1040]: loss 0.791071
[epoch12, step1041]: loss 21.719833
[epoch12, step1042]: loss 2.220951
[epoch12, step1043]: loss 1.319640
[epoch12, step1044]: loss 3.752808
[epoch12, step1045]: loss 6.337702
[epoch12, step1046]: loss 13.008670
[epoch12, step1047]: loss 1.368692
[epoch12, step1048]: loss 2.160796
[epoch12, step1049]: loss 2.083183
[epoch12, step1050]: loss 3.771218
[epoch12, step1051]: loss 1.126872
[epoch12, step1052]: loss 8.108566
[epoch12, step1053]: loss 11.732278
[epoch12, step1054]: loss 6.327699
[epoch12, step1055]: loss 1.356414
[epoch12, step1056]: loss 2.059728
[epoch12, step1057]: loss 1.713310
[epoch12, step1058]: loss 1.262222
[epoch12, step1059]: loss 18.417871
[epoch12, step1060]: loss 10.445697
[epoch12, step1061]: loss 13.774889
[epoch12, step1062]: loss 2.487845
[epoch12, step1063]: loss 7.765152
[epoch12, step1064]: loss 1.214837
[epoch12, step1065]: loss 3.657123
[epoch12, step1066]: loss 2.073862
[epoch12, step1067]: loss 0.762807
[epoch12, step1068]: loss 1.305068
[epoch12, step1069]: loss 1.092046
[epoch12, step1070]: loss 1.178627
[epoch12, step1071]: loss 1.800135
[epoch12, step1072]: loss 2.824193
[epoch12, step1073]: loss 1.231932
[epoch12, step1074]: loss 2.849590
[epoch12, step1075]: loss 2.198700
[epoch12, step1076]: loss 2.519820
[epoch12, step1077]: loss 7.517094
[epoch12, step1078]: loss 2.308626
[epoch12, step1079]: loss 3.410097
[epoch12, step1080]: loss 0.750106
[epoch12, step1081]: loss 2.894928
[epoch12, step1082]: loss 0.693234
[epoch12, step1083]: loss 9.259786
[epoch12, step1084]: loss 19.839033
[epoch12, step1085]: loss 1.550354
[epoch12, step1086]: loss 2.179097
[epoch12, step1087]: loss 0.899485
[epoch12, step1088]: loss 1.096467
[epoch12, step1089]: loss 2.390172
[epoch12, step1090]: loss 1.367200
[epoch12, step1091]: loss 9.417169
[epoch12, step1092]: loss 5.194228
[epoch12, step1093]: loss 0.764967
[epoch12, step1094]: loss 18.454777
[epoch12, step1095]: loss 2.154874
[epoch12, step1096]: loss 1.644906
[epoch12, step1097]: loss 11.561405
[epoch12, step1098]: loss 1.108568
[epoch12, step1099]: loss 3.938941
[epoch12, step1100]: loss 0.966280
[epoch12, step1101]: loss 0.953907
[epoch12, step1102]: loss 2.738682
[epoch12, step1103]: loss 1.673175
[epoch12, step1104]: loss 13.046975
[epoch12, step1105]: loss 5.081496
[epoch12, step1106]: loss 1.400665
[epoch12, step1107]: loss 9.778046
[epoch12, step1108]: loss 1.267996
[epoch12, step1109]: loss 9.942519
[epoch12, step1110]: loss 0.993126
[epoch12, step1111]: loss 10.157599
[epoch12, step1112]: loss 2.865968
[epoch12, step1113]: loss 1.104433
[epoch12, step1114]: loss 5.028979
[epoch12, step1115]: loss 9.902697
[epoch12, step1116]: loss 5.515691
[epoch12, step1117]: loss 22.218895
[epoch12, step1118]: loss 2.313551
[epoch12, step1119]: loss 0.960206
[epoch12, step1120]: loss 1.453960
[epoch12, step1121]: loss 0.966772
[epoch12, step1122]: loss 0.892708
[epoch12, step1123]: loss 3.072195
[epoch12, step1124]: loss 10.213547
[epoch12, step1125]: loss 2.533029
[epoch12, step1126]: loss 31.281239
[epoch12, step1127]: loss 2.718696
[epoch12, step1128]: loss 2.307601
[epoch12, step1129]: loss 11.757165
[epoch12, step1130]: loss 0.960893
[epoch12, step1131]: loss 1.028805
[epoch12, step1132]: loss 0.955722
[epoch12, step1133]: loss 1.563432
[epoch12, step1134]: loss 0.707847
[epoch12, step1135]: loss 1.476814
[epoch12, step1136]: loss 1.545060
[epoch12, step1137]: loss 15.397554
[epoch12, step1138]: loss 2.102050
[epoch12, step1139]: loss 0.820479
[epoch12, step1140]: loss 9.112333
[epoch12, step1141]: loss 21.047955
[epoch12, step1142]: loss 19.247559
[epoch12, step1143]: loss 9.123414
[epoch12, step1144]: loss 11.914501
[epoch12, step1145]: loss 1.076237
[epoch12, step1146]: loss 2.566723
[epoch12, step1147]: loss 15.210347
[epoch12, step1148]: loss 13.279413
[epoch12, step1149]: loss 6.931150
[epoch12, step1150]: loss 0.960728
[epoch12, step1151]: loss 1.476761
[epoch12, step1152]: loss 1.060705
[epoch12, step1153]: loss 18.490128
[epoch12, step1154]: loss 5.371017
[epoch12, step1155]: loss 1.072754
[epoch12, step1156]: loss 0.945350
[epoch12, step1157]: loss 13.193924
[epoch12, step1158]: loss 14.478240
[epoch12, step1159]: loss 1.775061
[epoch12, step1160]: loss 5.959535
[epoch12, step1161]: loss 0.736586
[epoch12, step1162]: loss 8.799333
[epoch12, step1163]: loss 1.997358
[epoch12, step1164]: loss 1.440055
[epoch12, step1165]: loss 1.135732
[epoch12, step1166]: loss 18.037544
[epoch12, step1167]: loss 1.768446
[epoch12, step1168]: loss 13.929861
[epoch12, step1169]: loss 1.375024
[epoch12, step1170]: loss 9.268383
[epoch12, step1171]: loss 1.356362
[epoch12, step1172]: loss 2.827284
[epoch12, step1173]: loss 2.871407
[epoch12, step1174]: loss 0.868595
[epoch12, step1175]: loss 3.188357
[epoch12, step1176]: loss 1.312178
[epoch12, step1177]: loss 6.687176
[epoch12, step1178]: loss 4.852500
[epoch12, step1179]: loss 2.707249
[epoch12, step1180]: loss 3.596905
[epoch12, step1181]: loss 3.409777
[epoch12, step1182]: loss 3.680472
[epoch12, step1183]: loss 1.423354
[epoch12, step1184]: loss 1.190754
[epoch12, step1185]: loss 1.639055
[epoch12, step1186]: loss 1.539147
[epoch12, step1187]: loss 0.939367
[epoch12, step1188]: loss 27.491325
[epoch12, step1189]: loss 1.221615
[epoch12, step1190]: loss 3.073667
[epoch12, step1191]: loss 1.560980
[epoch12, step1192]: loss 8.249844
[epoch12, step1193]: loss 1.422252
[epoch12, step1194]: loss 1.055828
[epoch12, step1195]: loss 7.173493
[epoch12, step1196]: loss 2.415719
[epoch12, step1197]: loss 4.128117
[epoch12, step1198]: loss 2.103220
[epoch12, step1199]: loss 12.933073
[epoch12, step1200]: loss 9.567038
[epoch12, step1201]: loss 3.776010
[epoch12, step1202]: loss 2.295567
[epoch12, step1203]: loss 0.892027
[epoch12, step1204]: loss 6.569613
[epoch12, step1205]: loss 2.077264
[epoch12, step1206]: loss 4.012361
[epoch12, step1207]: loss 0.978785
[epoch12, step1208]: loss 2.887972
[epoch12, step1209]: loss 1.397688
[epoch12, step1210]: loss 1.410663
[epoch12, step1211]: loss 1.432025
[epoch12, step1212]: loss 4.389978
[epoch12, step1213]: loss 1.196561
[epoch12, step1214]: loss 12.238503
[epoch12, step1215]: loss 5.421927
[epoch12, step1216]: loss 0.943532
[epoch12, step1217]: loss 0.638366
[epoch12, step1218]: loss 1.266899
[epoch12, step1219]: loss 1.411503
[epoch12, step1220]: loss 2.528080
[epoch12, step1221]: loss 2.529855
[epoch12, step1222]: loss 1.461724
[epoch12, step1223]: loss 1.305853
[epoch12, step1224]: loss 1.552025
[epoch12, step1225]: loss 2.595951
[epoch12, step1226]: loss 1.348948
[epoch12, step1227]: loss 13.462072
[epoch12, step1228]: loss 14.087910
[epoch12, step1229]: loss 0.869753
[epoch12, step1230]: loss 11.928640
[epoch12, step1231]: loss 2.634436
[epoch12, step1232]: loss 1.116001
[epoch12, step1233]: loss 4.518791
[epoch12, step1234]: loss 2.178903
[epoch12, step1235]: loss 3.955420
[epoch12, step1236]: loss 1.827804
[epoch12, step1237]: loss 2.355302
[epoch12, step1238]: loss 2.959395
[epoch12, step1239]: loss 0.990744
[epoch12, step1240]: loss 19.242258
[epoch12, step1241]: loss 1.030358
[epoch12, step1242]: loss 2.207288
[epoch12, step1243]: loss 2.191496
[epoch12, step1244]: loss 1.453971
[epoch12, step1245]: loss 0.992217
[epoch12, step1246]: loss 1.765333
[epoch12, step1247]: loss 1.896085
[epoch12, step1248]: loss 4.604856
[epoch12, step1249]: loss 2.287283
[epoch12, step1250]: loss 1.733741
[epoch12, step1251]: loss 7.536082
[epoch12, step1252]: loss 7.099116
[epoch12, step1253]: loss 1.235372
[epoch12, step1254]: loss 1.400841
[epoch12, step1255]: loss 2.567598
[epoch12, step1256]: loss 13.326628
[epoch12, step1257]: loss 0.882696
[epoch12, step1258]: loss 0.952600
[epoch12, step1259]: loss 2.075094
[epoch12, step1260]: loss 1.105310
[epoch12, step1261]: loss 1.215971
[epoch12, step1262]: loss 2.652675
[epoch12, step1263]: loss 7.964863
[epoch12, step1264]: loss 2.946788
[epoch12, step1265]: loss 2.106489
[epoch12, step1266]: loss 1.750954
[epoch12, step1267]: loss 0.872345
[epoch12, step1268]: loss 2.240822
[epoch12, step1269]: loss 0.848023
[epoch12, step1270]: loss 9.657943
[epoch12, step1271]: loss 11.569103
[epoch12, step1272]: loss 4.479340
[epoch12, step1273]: loss 1.246677
[epoch12, step1274]: loss 1.357614
[epoch12, step1275]: loss 3.955868
[epoch12, step1276]: loss 7.138896
[epoch12, step1277]: loss 4.944141
[epoch12, step1278]: loss 2.432053
[epoch12, step1279]: loss 17.776932
[epoch12, step1280]: loss 1.312872
[epoch12, step1281]: loss 7.706515
[epoch12, step1282]: loss 49.957653
[epoch12, step1283]: loss 15.127272
[epoch12, step1284]: loss 0.659019
[epoch12, step1285]: loss 9.263306
[epoch12, step1286]: loss 1.304170
[epoch12, step1287]: loss 2.111424
[epoch12, step1288]: loss 7.397430
[epoch12, step1289]: loss 1.276933
[epoch12, step1290]: loss 0.870353
[epoch12, step1291]: loss 1.378919
[epoch12, step1292]: loss 3.257874
[epoch12, step1293]: loss 1.522874
[epoch12, step1294]: loss 11.952472
[epoch12, step1295]: loss 21.115742
[epoch12, step1296]: loss 1.317017
[epoch12, step1297]: loss 1.326877
[epoch12, step1298]: loss 7.157994
[epoch12, step1299]: loss 8.237074
[epoch12, step1300]: loss 18.489031
[epoch12, step1301]: loss 12.140090
[epoch12, step1302]: loss 1.015938
[epoch12, step1303]: loss 1.879987
[epoch12, step1304]: loss 0.946657
[epoch12, step1305]: loss 10.599096
[epoch12, step1306]: loss 2.100556
[epoch12, step1307]: loss 1.467791
[epoch12, step1308]: loss 2.475481
[epoch12, step1309]: loss 1.243351
[epoch12, step1310]: loss 1.924541
[epoch12, step1311]: loss 1.646117
[epoch12, step1312]: loss 6.270895
[epoch12, step1313]: loss 1.432928
[epoch12, step1314]: loss 18.248920
[epoch12, step1315]: loss 2.964659
[epoch12, step1316]: loss 18.570469
[epoch12, step1317]: loss 5.211336
[epoch12, step1318]: loss 1.915021
[epoch12, step1319]: loss 4.918339
[epoch12, step1320]: loss 3.264892
[epoch12, step1321]: loss 11.295686
[epoch12, step1322]: loss 0.706569
[epoch12, step1323]: loss 0.602526
[epoch12, step1324]: loss 0.837170
[epoch12, step1325]: loss 9.387041
[epoch12, step1326]: loss 1.222891
[epoch12, step1327]: loss 13.585207
[epoch12, step1328]: loss 2.027429
[epoch12, step1329]: loss 1.869761
[epoch12, step1330]: loss 1.551417
[epoch12, step1331]: loss 5.268960
[epoch12, step1332]: loss 11.797569
[epoch12, step1333]: loss 2.437837
[epoch12, step1334]: loss 0.938804
[epoch12, step1335]: loss 0.896929
[epoch12, step1336]: loss 6.186655
[epoch12, step1337]: loss 5.645048
[epoch12, step1338]: loss 1.693134
[epoch12, step1339]: loss 10.068445
[epoch12, step1340]: loss 2.001049
[epoch12, step1341]: loss 2.986709
[epoch12, step1342]: loss 13.549974
[epoch12, step1343]: loss 23.496367
[epoch12, step1344]: loss 2.365413
[epoch12, step1345]: loss 3.233919
[epoch12, step1346]: loss 8.881544
[epoch12, step1347]: loss 2.496734
[epoch12, step1348]: loss 0.910054
[epoch12, step1349]: loss 4.126515
[epoch12, step1350]: loss 1.008262
[epoch12, step1351]: loss 20.695791
[epoch12, step1352]: loss 3.426384
[epoch12, step1353]: loss 1.429762
[epoch12, step1354]: loss 14.188709
[epoch12, step1355]: loss 1.308089
[epoch12, step1356]: loss 0.857158
[epoch12, step1357]: loss 17.871952
[epoch12, step1358]: loss 0.724203
[epoch12, step1359]: loss 1.889214
[epoch12, step1360]: loss 12.895061
[epoch12, step1361]: loss 0.994222
[epoch12, step1362]: loss 3.754832
[epoch12, step1363]: loss 1.031435
[epoch12, step1364]: loss 12.428877
[epoch12, step1365]: loss 0.909015
[epoch12, step1366]: loss 1.678514
[epoch12, step1367]: loss 0.883665
[epoch12, step1368]: loss 6.533591
[epoch12, step1369]: loss 1.890543
[epoch12, step1370]: loss 6.065109
[epoch12, step1371]: loss 17.759663
[epoch12, step1372]: loss 2.598437
[epoch12, step1373]: loss 1.356699
[epoch12, step1374]: loss 6.646738
[epoch12, step1375]: loss 8.529493
[epoch12, step1376]: loss 1.462641
[epoch12, step1377]: loss 1.304531
[epoch12, step1378]: loss 4.189249
[epoch12, step1379]: loss 5.876163
[epoch12, step1380]: loss 7.591226
[epoch12, step1381]: loss 35.995979
[epoch12, step1382]: loss 10.662301
[epoch12, step1383]: loss 3.498971
[epoch12, step1384]: loss 3.947191
[epoch12, step1385]: loss 2.530454
[epoch12, step1386]: loss 19.132488
[epoch12, step1387]: loss 6.560765
[epoch12, step1388]: loss 1.349572
[epoch12, step1389]: loss 1.158783
[epoch12, step1390]: loss 4.246122
[epoch12, step1391]: loss 1.517276
[epoch12, step1392]: loss 1.042644
[epoch12, step1393]: loss 1.649734
[epoch12, step1394]: loss 3.651552
[epoch12, step1395]: loss 0.940214
[epoch12, step1396]: loss 2.780260
[epoch12, step1397]: loss 2.819642
[epoch12, step1398]: loss 2.626797
[epoch12, step1399]: loss 11.557626
[epoch12, step1400]: loss 4.529422
[epoch12, step1401]: loss 4.550148
[epoch12, step1402]: loss 16.817392
[epoch12, step1403]: loss 8.975113
[epoch12, step1404]: loss 1.503211
[epoch12, step1405]: loss 1.224306
[epoch12, step1406]: loss 9.396758
[epoch12, step1407]: loss 0.992244
[epoch12, step1408]: loss 1.049728
[epoch12, step1409]: loss 3.243724
[epoch12, step1410]: loss 3.774809
[epoch12, step1411]: loss 3.211085
[epoch12, step1412]: loss 3.299678
[epoch12, step1413]: loss 4.181266
[epoch12, step1414]: loss 2.305696
[epoch12, step1415]: loss 2.037116
[epoch12, step1416]: loss 3.236208
[epoch12, step1417]: loss 1.320869
[epoch12, step1418]: loss 2.194169
[epoch12, step1419]: loss 2.031514
[epoch12, step1420]: loss 0.764769
[epoch12, step1421]: loss 1.131952
[epoch12, step1422]: loss 5.847167
[epoch12, step1423]: loss 11.950793
[epoch12, step1424]: loss 2.721594
[epoch12, step1425]: loss 11.041458
[epoch12, step1426]: loss 1.111855
[epoch12, step1427]: loss 2.668725
[epoch12, step1428]: loss 2.990401
[epoch12, step1429]: loss 2.103141
[epoch12, step1430]: loss 9.608110
[epoch12, step1431]: loss 2.907561
[epoch12, step1432]: loss 1.302274
[epoch12, step1433]: loss 2.261040
[epoch12, step1434]: loss 2.985538
[epoch12, step1435]: loss 16.596153
[epoch12, step1436]: loss 1.775518
[epoch12, step1437]: loss 34.270988
[epoch12, step1438]: loss 1.488042
[epoch12, step1439]: loss 9.405432
[epoch12, step1440]: loss 25.481655
[epoch12, step1441]: loss 2.003066
[epoch12, step1442]: loss 3.004244
[epoch12, step1443]: loss 10.918837
[epoch12, step1444]: loss 3.369165
[epoch12, step1445]: loss 0.916620
[epoch12, step1446]: loss 3.412791
[epoch12, step1447]: loss 2.826836
[epoch12, step1448]: loss 3.989015
[epoch12, step1449]: loss 1.227179
[epoch12, step1450]: loss 1.049086
[epoch12, step1451]: loss 1.287045
[epoch12, step1452]: loss 9.096033
[epoch12, step1453]: loss 17.976938
[epoch12, step1454]: loss 11.711488
[epoch12, step1455]: loss 2.815957
[epoch12, step1456]: loss 13.473332
[epoch12, step1457]: loss 2.942687
[epoch12, step1458]: loss 3.094241
[epoch12, step1459]: loss 11.317274
[epoch12, step1460]: loss 1.320456
[epoch12, step1461]: loss 3.572821
[epoch12, step1462]: loss 2.025866
[epoch12, step1463]: loss 1.380483
[epoch12, step1464]: loss 1.549515
[epoch12, step1465]: loss 1.017191
[epoch12, step1466]: loss 6.109850
[epoch12, step1467]: loss 39.650272
[epoch12, step1468]: loss 4.328561
[epoch12, step1469]: loss 17.088984
[epoch12, step1470]: loss 1.867278
[epoch12, step1471]: loss 1.318365
[epoch12, step1472]: loss 1.093487
[epoch12, step1473]: loss 1.101350
[epoch12, step1474]: loss 1.813488
[epoch12, step1475]: loss 16.304728
[epoch12, step1476]: loss 5.545842
[epoch12, step1477]: loss 2.339007
[epoch12, step1478]: loss 15.613190
[epoch12, step1479]: loss 13.599914
[epoch12, step1480]: loss 10.445574
[epoch12, step1481]: loss 10.947525
[epoch12, step1482]: loss 2.074324
[epoch12, step1483]: loss 17.686693
[epoch12, step1484]: loss 1.680960
[epoch12, step1485]: loss 2.597224
[epoch12, step1486]: loss 1.665399
[epoch12, step1487]: loss 1.536384
[epoch12, step1488]: loss 1.575076
[epoch12, step1489]: loss 2.633868
[epoch12, step1490]: loss 13.224437
[epoch12, step1491]: loss 2.070111
[epoch12, step1492]: loss 1.958694
[epoch12, step1493]: loss 3.573586
[epoch12, step1494]: loss 21.613995
[epoch12, step1495]: loss 3.099973
[epoch12, step1496]: loss 2.860544
[epoch12, step1497]: loss 1.395675
[epoch12, step1498]: loss 9.550124
[epoch12, step1499]: loss 2.794666
[epoch12, step1500]: loss 13.454888
[epoch12, step1501]: loss 2.380018
[epoch12, step1502]: loss 1.819600
[epoch12, step1503]: loss 1.475856
[epoch12, step1504]: loss 1.241018
[epoch12, step1505]: loss 6.093203
[epoch12, step1506]: loss 0.456957
[epoch12, step1507]: loss 1.631964
[epoch12, step1508]: loss 0.949441
[epoch12, step1509]: loss 10.233162
[epoch12, step1510]: loss 2.945637
[epoch12, step1511]: loss 1.423677
[epoch12, step1512]: loss 10.362294
[epoch12, step1513]: loss 2.299610
[epoch12, step1514]: loss 1.274056
[epoch12, step1515]: loss 7.792253
[epoch12, step1516]: loss 1.035334
[epoch12, step1517]: loss 0.983511
[epoch12, step1518]: loss 1.902705
[epoch12, step1519]: loss 2.418781
[epoch12, step1520]: loss 1.626042
[epoch12, step1521]: loss 19.329042
[epoch12, step1522]: loss 2.133674
[epoch12, step1523]: loss 7.689463
[epoch12, step1524]: loss 29.015968
[epoch12, step1525]: loss 1.678123
[epoch12, step1526]: loss 1.015694
[epoch12, step1527]: loss 4.070194
[epoch12, step1528]: loss 1.429903
[epoch12, step1529]: loss 16.638752
[epoch12, step1530]: loss 1.412492
[epoch12, step1531]: loss 2.169518
[epoch12, step1532]: loss 2.307678
[epoch12, step1533]: loss 37.493904
[epoch12, step1534]: loss 2.200380
[epoch12, step1535]: loss 14.116343
[epoch12, step1536]: loss 1.080265
[epoch12, step1537]: loss 0.655754
[epoch12, step1538]: loss 2.338835
[epoch12, step1539]: loss 13.616000
[epoch12, step1540]: loss 2.004948
[epoch12, step1541]: loss 2.151267
[epoch12, step1542]: loss 3.257815
[epoch12, step1543]: loss 1.513221
[epoch12, step1544]: loss 1.389247
[epoch12, step1545]: loss 2.538913
[epoch12, step1546]: loss 13.247118
[epoch12, step1547]: loss 1.691553
[epoch12, step1548]: loss 1.032766
[epoch12, step1549]: loss 5.471722
[epoch12, step1550]: loss 2.937333
[epoch12, step1551]: loss 1.335333
[epoch12, step1552]: loss 2.341921
[epoch12, step1553]: loss 0.881993
[epoch12, step1554]: loss 13.726034
[epoch12, step1555]: loss 2.475129
[epoch12, step1556]: loss 1.196461
[epoch12, step1557]: loss 2.535921
[epoch12, step1558]: loss 4.424138
[epoch12, step1559]: loss 6.777880
[epoch12, step1560]: loss 0.913254
[epoch12, step1561]: loss 9.652953
[epoch12, step1562]: loss 15.905493
[epoch12, step1563]: loss 1.296571
[epoch12, step1564]: loss 1.590010
[epoch12, step1565]: loss 0.697295
[epoch12, step1566]: loss 1.754205
[epoch12, step1567]: loss 1.585622
[epoch12, step1568]: loss 1.359157
[epoch12, step1569]: loss 15.527443
[epoch12, step1570]: loss 20.201010
[epoch12, step1571]: loss 1.359425
[epoch12, step1572]: loss 1.390097
[epoch12, step1573]: loss 1.273652
[epoch12, step1574]: loss 0.691119
[epoch12, step1575]: loss 1.182240
[epoch12, step1576]: loss 2.676772
[epoch12, step1577]: loss 2.816875
[epoch12, step1578]: loss 18.073631
[epoch12, step1579]: loss 2.246759
[epoch12, step1580]: loss 14.531914
[epoch12, step1581]: loss 1.095272
[epoch12, step1582]: loss 1.948474
[epoch12, step1583]: loss 2.348900
[epoch12, step1584]: loss 2.411294
[epoch12, step1585]: loss 5.391381
[epoch12, step1586]: loss 1.528144
[epoch12, step1587]: loss 13.305651
[epoch12, step1588]: loss 1.426932
[epoch12, step1589]: loss 3.266532
[epoch12, step1590]: loss 2.593185
[epoch12, step1591]: loss 10.561104
[epoch12, step1592]: loss 1.307239
[epoch12, step1593]: loss 1.428736
[epoch12, step1594]: loss 6.483244
[epoch12, step1595]: loss 2.106401
[epoch12, step1596]: loss 0.801040
[epoch12, step1597]: loss 1.559053
[epoch12, step1598]: loss 1.442707
[epoch12, step1599]: loss 0.873633
[epoch12, step1600]: loss 4.674923
[epoch12, step1601]: loss 1.359980
[epoch12, step1602]: loss 11.128432
[epoch12, step1603]: loss 5.777787
[epoch12, step1604]: loss 2.987512
[epoch12, step1605]: loss 1.989884
[epoch12, step1606]: loss 1.643624
[epoch12, step1607]: loss 1.060091
[epoch12, step1608]: loss 0.982127
[epoch12, step1609]: loss 1.476157
[epoch12, step1610]: loss 1.852781
[epoch12, step1611]: loss 1.091475
[epoch12, step1612]: loss 15.563829
[epoch12, step1613]: loss 1.422661
[epoch12, step1614]: loss 16.792761
[epoch12, step1615]: loss 10.696434
[epoch12, step1616]: loss 18.441242
[epoch12, step1617]: loss 0.932555
[epoch12, step1618]: loss 1.752387
[epoch12, step1619]: loss 1.105038
[epoch12, step1620]: loss 3.159609
[epoch12, step1621]: loss 3.869932
[epoch12, step1622]: loss 1.271558
[epoch12, step1623]: loss 3.138839
[epoch12, step1624]: loss 1.140564
[epoch12, step1625]: loss 3.204443
[epoch12, step1626]: loss 13.606821
[epoch12, step1627]: loss 1.658716
[epoch12, step1628]: loss 1.974894
[epoch12, step1629]: loss 1.801349
[epoch12, step1630]: loss 17.357393
[epoch12, step1631]: loss 1.990449
[epoch12, step1632]: loss 3.108009
[epoch12, step1633]: loss 2.566198
[epoch12, step1634]: loss 0.760176
[epoch12, step1635]: loss 1.158024
[epoch12, step1636]: loss 0.830917
[epoch12, step1637]: loss 17.656406
[epoch12, step1638]: loss 9.805102
[epoch12, step1639]: loss 11.260437
[epoch12, step1640]: loss 1.186713
[epoch12, step1641]: loss 1.171919
[epoch12, step1642]: loss 1.035270
[epoch12, step1643]: loss 1.204406
[epoch12, step1644]: loss 3.347690
[epoch12, step1645]: loss 2.221386
[epoch12, step1646]: loss 1.399755
[epoch12, step1647]: loss 34.226974
[epoch12, step1648]: loss 0.698506
[epoch12, step1649]: loss 1.945647
[epoch12, step1650]: loss 0.793665
[epoch12, step1651]: loss 14.545259
[epoch12, step1652]: loss 8.541862
[epoch12, step1653]: loss 3.273115
[epoch12, step1654]: loss 2.148837
[epoch12, step1655]: loss 0.803495
[epoch12, step1656]: loss 1.768457
[epoch12, step1657]: loss 1.089373
[epoch12, step1658]: loss 1.533420
[epoch12, step1659]: loss 1.627006
[epoch12, step1660]: loss 1.950927
[epoch12, step1661]: loss 2.103080
[epoch12, step1662]: loss 2.859382
[epoch12, step1663]: loss 10.577288
[epoch12, step1664]: loss 4.041417
[epoch12, step1665]: loss 1.528729
[epoch12, step1666]: loss 1.642722
[epoch12, step1667]: loss 1.273766
[epoch12, step1668]: loss 1.303192
[epoch12, step1669]: loss 1.316220
[epoch12, step1670]: loss 9.275002
[epoch12, step1671]: loss 0.695695
[epoch12, step1672]: loss 1.341544
[epoch12, step1673]: loss 0.513313
[epoch12, step1674]: loss 0.941020
[epoch12, step1675]: loss 2.595314
[epoch12, step1676]: loss 10.289833
[epoch12, step1677]: loss 1.825367
[epoch12, step1678]: loss 12.363825
[epoch12, step1679]: loss 0.930940
[epoch12, step1680]: loss 3.310064
[epoch12, step1681]: loss 19.133072
[epoch12, step1682]: loss 20.219904
[epoch12, step1683]: loss 0.711466
[epoch12, step1684]: loss 0.978260
[epoch12, step1685]: loss 20.856808
[epoch12, step1686]: loss 0.645070
[epoch12, step1687]: loss 1.561190
[epoch12, step1688]: loss 1.575379
[epoch12, step1689]: loss 4.907818
[epoch12, step1690]: loss 7.949389
[epoch12, step1691]: loss 20.364639
[epoch12, step1692]: loss 3.321627
[epoch12, step1693]: loss 2.799694
[epoch12, step1694]: loss 1.310916
[epoch12, step1695]: loss 1.043686
[epoch12, step1696]: loss 1.041081
[epoch12, step1697]: loss 0.976516
[epoch12, step1698]: loss 0.804059
[epoch12, step1699]: loss 2.061068
[epoch12, step1700]: loss 13.630395
[epoch12, step1701]: loss 1.905007
[epoch12, step1702]: loss 1.240130
[epoch12, step1703]: loss 0.591033
[epoch12, step1704]: loss 2.441144
[epoch12, step1705]: loss 1.207038
[epoch12, step1706]: loss 1.134475
[epoch12, step1707]: loss 1.211929
[epoch12, step1708]: loss 3.446165
[epoch12, step1709]: loss 5.967716
[epoch12, step1710]: loss 0.953768
[epoch12, step1711]: loss 2.189332
[epoch12, step1712]: loss 0.816437
[epoch12, step1713]: loss 2.729845
[epoch12, step1714]: loss 8.207953
[epoch12, step1715]: loss 1.210761
[epoch12, step1716]: loss 1.509935
[epoch12, step1717]: loss 4.926530
[epoch12, step1718]: loss 8.047323
[epoch12, step1719]: loss 2.710839
[epoch12, step1720]: loss 0.846656
[epoch12, step1721]: loss 1.441920
[epoch12, step1722]: loss 2.832654
[epoch12, step1723]: loss 1.644384
[epoch12, step1724]: loss 1.837619
[epoch12, step1725]: loss 1.002812
[epoch12, step1726]: loss 0.912832
[epoch12, step1727]: loss 15.343803
[epoch12, step1728]: loss 4.967191
[epoch12, step1729]: loss 1.428281
[epoch12, step1730]: loss 2.251714
[epoch12, step1731]: loss 1.611646
[epoch12, step1732]: loss 3.532278
[epoch12, step1733]: loss 1.951388
[epoch12, step1734]: loss 1.174859
[epoch12, step1735]: loss 0.879677
[epoch12, step1736]: loss 3.786836
[epoch12, step1737]: loss 3.569290
[epoch12, step1738]: loss 1.527174
[epoch12, step1739]: loss 0.947763
[epoch12, step1740]: loss 1.340841
[epoch12, step1741]: loss 9.521633
[epoch12, step1742]: loss 1.566013
[epoch12, step1743]: loss 1.415032
[epoch12, step1744]: loss 1.456307
[epoch12, step1745]: loss 2.142790
[epoch12, step1746]: loss 9.410370
[epoch12, step1747]: loss 4.013270
[epoch12, step1748]: loss 1.580306
[epoch12, step1749]: loss 5.941508
[epoch12, step1750]: loss 4.677764
[epoch12, step1751]: loss 12.842664
[epoch12, step1752]: loss 1.348764
[epoch12, step1753]: loss 1.215796
[epoch12, step1754]: loss 7.542902
[epoch12, step1755]: loss 23.223543
[epoch12, step1756]: loss 18.614120
[epoch12, step1757]: loss 1.663564
[epoch12, step1758]: loss 1.001265
[epoch12, step1759]: loss 2.090792
[epoch12, step1760]: loss 1.319344
[epoch12, step1761]: loss 12.162844
[epoch12, step1762]: loss 1.400847
[epoch12, step1763]: loss 3.046238
[epoch12, step1764]: loss 1.429960
[epoch12, step1765]: loss 0.922700
[epoch12, step1766]: loss 4.508627
[epoch12, step1767]: loss 3.164275
[epoch12, step1768]: loss 5.302977
[epoch12, step1769]: loss 4.700172
[epoch12, step1770]: loss 1.132859
[epoch12, step1771]: loss 1.061742
[epoch12, step1772]: loss 1.598256
[epoch12, step1773]: loss 1.006842
[epoch12, step1774]: loss 2.098828
[epoch12, step1775]: loss 20.563000
[epoch12, step1776]: loss 6.064508
[epoch12, step1777]: loss 3.406478
[epoch12, step1778]: loss 22.499390
[epoch12, step1779]: loss 16.169573
[epoch12, step1780]: loss 19.597860
[epoch12, step1781]: loss 4.639071
[epoch12, step1782]: loss 1.731470
[epoch12, step1783]: loss 13.074425
[epoch12, step1784]: loss 2.677575
[epoch12, step1785]: loss 1.666316
[epoch12, step1786]: loss 2.649819
[epoch12, step1787]: loss 1.001938
[epoch12, step1788]: loss 1.955431
[epoch12, step1789]: loss 2.321194
[epoch12, step1790]: loss 9.895839
[epoch12, step1791]: loss 22.323656
[epoch12, step1792]: loss 3.607498
[epoch12, step1793]: loss 11.215036
[epoch12, step1794]: loss 8.793303
[epoch12, step1795]: loss 2.573598
[epoch12, step1796]: loss 7.629573
[epoch12, step1797]: loss 16.064327
[epoch12, step1798]: loss 6.144551
[epoch12, step1799]: loss 1.891001
[epoch12, step1800]: loss 1.737451
[epoch12, step1801]: loss 3.510940
[epoch12, step1802]: loss 3.086672
[epoch12, step1803]: loss 2.049520
[epoch12, step1804]: loss 23.961094
[epoch12, step1805]: loss 1.692937
[epoch12, step1806]: loss 7.821987
[epoch12, step1807]: loss 10.151734
[epoch12, step1808]: loss 3.825349
[epoch12, step1809]: loss 15.843622
[epoch12, step1810]: loss 1.708704
[epoch12, step1811]: loss 10.461123
[epoch12, step1812]: loss 1.795837
[epoch12, step1813]: loss 12.154367
[epoch12, step1814]: loss 3.788697
[epoch12, step1815]: loss 1.276461
[epoch12, step1816]: loss 3.113765
[epoch12, step1817]: loss 1.174272
[epoch12, step1818]: loss 1.492238
[epoch12, step1819]: loss 2.003298
[epoch12, step1820]: loss 1.365840
[epoch12, step1821]: loss 13.321539
[epoch12, step1822]: loss 8.346506
[epoch12, step1823]: loss 1.385045
[epoch12, step1824]: loss 19.386312
[epoch12, step1825]: loss 1.844734
[epoch12, step1826]: loss 1.241506
[epoch12, step1827]: loss 1.396918
[epoch12, step1828]: loss 4.294474
[epoch12, step1829]: loss 30.880327
[epoch12, step1830]: loss 5.554760
[epoch12, step1831]: loss 1.209608
[epoch12, step1832]: loss 1.843190
[epoch12, step1833]: loss 7.214100
[epoch12, step1834]: loss 23.009754
[epoch12, step1835]: loss 1.446911
[epoch12, step1836]: loss 1.709886
[epoch12, step1837]: loss 4.863060
[epoch12, step1838]: loss 6.542707
[epoch12, step1839]: loss 9.000506
[epoch12, step1840]: loss 2.263988
[epoch12, step1841]: loss 1.430450
[epoch12, step1842]: loss 6.967069
[epoch12, step1843]: loss 21.093714
[epoch12, step1844]: loss 1.738268
[epoch12, step1845]: loss 1.437319
[epoch12, step1846]: loss 1.861768
[epoch12, step1847]: loss 18.012964
[epoch12, step1848]: loss 6.109657
[epoch12, step1849]: loss 2.061810
[epoch12, step1850]: loss 3.656368
[epoch12, step1851]: loss 1.955613
[epoch12, step1852]: loss 1.635120
[epoch12, step1853]: loss 23.021729
[epoch12, step1854]: loss 1.123980
[epoch12, step1855]: loss 1.092360
[epoch12, step1856]: loss 1.251497
[epoch12, step1857]: loss 9.770621
[epoch12, step1858]: loss 3.957561
[epoch12, step1859]: loss 17.876524
[epoch12, step1860]: loss 2.738619
[epoch12, step1861]: loss 5.343287
[epoch12, step1862]: loss 7.292239
[epoch12, step1863]: loss 1.158451
[epoch12, step1864]: loss 1.680773
[epoch12, step1865]: loss 3.144378
[epoch12, step1866]: loss 1.877321
[epoch12, step1867]: loss 4.443902
[epoch12, step1868]: loss 3.568622
[epoch12, step1869]: loss 9.241502
[epoch12, step1870]: loss 1.123913
[epoch12, step1871]: loss 1.093277
[epoch12, step1872]: loss 2.814230
[epoch12, step1873]: loss 1.273583
[epoch12, step1874]: loss 2.489192
[epoch12, step1875]: loss 1.738447
[epoch12, step1876]: loss 3.395848
[epoch12, step1877]: loss 9.520731
[epoch12, step1878]: loss 4.819057
[epoch12, step1879]: loss 9.584601
[epoch12, step1880]: loss 0.748728
[epoch12, step1881]: loss 1.538435
[epoch12, step1882]: loss 1.294895
[epoch12, step1883]: loss 1.548445
[epoch12, step1884]: loss 2.389044
[epoch12, step1885]: loss 1.429154
[epoch12, step1886]: loss 9.131891
[epoch12, step1887]: loss 8.617348
[epoch12, step1888]: loss 3.624849
[epoch12, step1889]: loss 0.963702
[epoch12, step1890]: loss 11.922816
[epoch12, step1891]: loss 1.891576
[epoch12, step1892]: loss 2.473445
[epoch12, step1893]: loss 4.906144
[epoch12, step1894]: loss 1.674901
[epoch12, step1895]: loss 5.580644
[epoch12, step1896]: loss 2.377820
[epoch12, step1897]: loss 2.926717
[epoch12, step1898]: loss 2.368402
[epoch12, step1899]: loss 24.617498
[epoch12, step1900]: loss 0.967700
[epoch12, step1901]: loss 21.584444
[epoch12, step1902]: loss 21.274965
[epoch12, step1903]: loss 11.898396
[epoch12, step1904]: loss 1.295952
[epoch12, step1905]: loss 13.130018
[epoch12, step1906]: loss 3.707653
[epoch12, step1907]: loss 6.936235
[epoch12, step1908]: loss 1.672299
[epoch12, step1909]: loss 2.316224
[epoch12, step1910]: loss 10.545016
[epoch12, step1911]: loss 1.854974
[epoch12, step1912]: loss 5.557769
[epoch12, step1913]: loss 17.707264
[epoch12, step1914]: loss 1.165001
[epoch12, step1915]: loss 2.302456
[epoch12, step1916]: loss 1.712779
[epoch12, step1917]: loss 11.171251
[epoch12, step1918]: loss 0.778850
[epoch12, step1919]: loss 11.351719
[epoch12, step1920]: loss 1.388203
[epoch12, step1921]: loss 0.888584
[epoch12, step1922]: loss 2.776351
[epoch12, step1923]: loss 1.118223
[epoch12, step1924]: loss 3.385739
[epoch12, step1925]: loss 9.349526
[epoch12, step1926]: loss 1.687044
[epoch12, step1927]: loss 1.688053
[epoch12, step1928]: loss 2.200907
[epoch12, step1929]: loss 1.500953
[epoch12, step1930]: loss 2.742244
[epoch12, step1931]: loss 7.675583
[epoch12, step1932]: loss 0.819044
[epoch12, step1933]: loss 2.501907
[epoch12, step1934]: loss 4.271348
[epoch12, step1935]: loss 6.311879
[epoch12, step1936]: loss 8.734105
[epoch12, step1937]: loss 20.181885
[epoch12, step1938]: loss 4.213014
[epoch12, step1939]: loss 1.438000
[epoch12, step1940]: loss 1.258314
[epoch12, step1941]: loss 15.416859
[epoch12, step1942]: loss 6.312672
[epoch12, step1943]: loss 8.311479
[epoch12, step1944]: loss 1.034330
[epoch12, step1945]: loss 3.547336
[epoch12, step1946]: loss 1.442342
[epoch12, step1947]: loss 1.377705
[epoch12, step1948]: loss 0.715235
[epoch12, step1949]: loss 12.120000
[epoch12, step1950]: loss 1.228441
[epoch12, step1951]: loss 1.042378
[epoch12, step1952]: loss 16.392168
[epoch12, step1953]: loss 2.393514
[epoch12, step1954]: loss 13.479589
[epoch12, step1955]: loss 7.080781
[epoch12, step1956]: loss 23.482599
[epoch12, step1957]: loss 1.907827
[epoch12, step1958]: loss 20.051943
[epoch12, step1959]: loss 3.454840
[epoch12, step1960]: loss 10.740797
[epoch12, step1961]: loss 0.991998
[epoch12, step1962]: loss 0.858293
[epoch12, step1963]: loss 1.176732
[epoch12, step1964]: loss 2.163284
[epoch12, step1965]: loss 1.489365
[epoch12, step1966]: loss 0.978419
[epoch12, step1967]: loss 4.079363
[epoch12, step1968]: loss 3.181106
[epoch12, step1969]: loss 13.578333
[epoch12, step1970]: loss 1.394676
[epoch12, step1971]: loss 4.385559
[epoch12, step1972]: loss 3.699394
[epoch12, step1973]: loss 1.626008
[epoch12, step1974]: loss 1.483267
[epoch12, step1975]: loss 9.448118
[epoch12, step1976]: loss 1.475150
[epoch12, step1977]: loss 3.587075
[epoch12, step1978]: loss 2.223166
[epoch12, step1979]: loss 2.283512
[epoch12, step1980]: loss 1.494932
[epoch12, step1981]: loss 9.588419
[epoch12, step1982]: loss 2.971821
[epoch12, step1983]: loss 2.190373
[epoch12, step1984]: loss 9.154065
[epoch12, step1985]: loss 1.715094
[epoch12, step1986]: loss 2.212636
[epoch12, step1987]: loss 0.924138
[epoch12, step1988]: loss 3.319150
[epoch12, step1989]: loss 0.929666
[epoch12, step1990]: loss 2.657179
[epoch12, step1991]: loss 2.083647
[epoch12, step1992]: loss 0.942652
[epoch12, step1993]: loss 2.123414
[epoch12, step1994]: loss 17.354706
[epoch12, step1995]: loss 1.162326
[epoch12, step1996]: loss 17.223667
[epoch12, step1997]: loss 13.425484
[epoch12, step1998]: loss 2.892357
[epoch12, step1999]: loss 4.605443
[epoch12, step2000]: loss 1.716856
[epoch12, step2001]: loss 8.604140
[epoch12, step2002]: loss 4.154668
[epoch12, step2003]: loss 21.254179
[epoch12, step2004]: loss 1.905017
[epoch12, step2005]: loss 2.110768
[epoch12, step2006]: loss 19.290003
[epoch12, step2007]: loss 11.184021
[epoch12, step2008]: loss 1.434950
[epoch12, step2009]: loss 1.228710
[epoch12, step2010]: loss 3.008816
[epoch12, step2011]: loss 1.575350
[epoch12, step2012]: loss 4.998137
[epoch12, step2013]: loss 10.473693
[epoch12, step2014]: loss 1.986127
[epoch12, step2015]: loss 13.036880
[epoch12, step2016]: loss 3.189834
[epoch12, step2017]: loss 4.028997
[epoch12, step2018]: loss 1.260448
[epoch12, step2019]: loss 2.856277
[epoch12, step2020]: loss 11.521020
[epoch12, step2021]: loss 0.648752
[epoch12, step2022]: loss 3.268742
[epoch12, step2023]: loss 14.738203
[epoch12, step2024]: loss 10.133011
[epoch12, step2025]: loss 1.322983
[epoch12, step2026]: loss 1.987499
[epoch12, step2027]: loss 10.698746
[epoch12, step2028]: loss 6.186359
[epoch12, step2029]: loss 2.051673
[epoch12, step2030]: loss 1.589050
[epoch12, step2031]: loss 2.036984
[epoch12, step2032]: loss 12.583688
[epoch12, step2033]: loss 1.270940
[epoch12, step2034]: loss 0.607300
[epoch12, step2035]: loss 1.011260
[epoch12, step2036]: loss 2.440146
[epoch12, step2037]: loss 19.485172
[epoch12, step2038]: loss 1.022781
[epoch12, step2039]: loss 2.773022
[epoch12, step2040]: loss 1.240872
[epoch12, step2041]: loss 3.568788
[epoch12, step2042]: loss 9.739381
[epoch12, step2043]: loss 19.396484
[epoch12, step2044]: loss 2.167956
[epoch12, step2045]: loss 1.562917
[epoch12, step2046]: loss 1.014318
[epoch12, step2047]: loss 14.271741
[epoch12, step2048]: loss 2.178389
[epoch12, step2049]: loss 3.495756
[epoch12, step2050]: loss 0.958331
[epoch12, step2051]: loss 1.639460
[epoch12, step2052]: loss 2.497862
[epoch12, step2053]: loss 0.918279
[epoch12, step2054]: loss 2.371534
[epoch12, step2055]: loss 1.946485
[epoch12, step2056]: loss 0.660368
[epoch12, step2057]: loss 1.798668
[epoch12, step2058]: loss 3.023745
[epoch12, step2059]: loss 2.123948
[epoch12, step2060]: loss 1.724682
[epoch12, step2061]: loss 2.281864
[epoch12, step2062]: loss 2.061684
[epoch12, step2063]: loss 1.567792
[epoch12, step2064]: loss 2.037151
[epoch12, step2065]: loss 0.711129
[epoch12, step2066]: loss 2.968900
[epoch12, step2067]: loss 0.669036
[epoch12, step2068]: loss 14.927120
[epoch12, step2069]: loss 2.142901
[epoch12, step2070]: loss 23.334570
[epoch12, step2071]: loss 1.029521
[epoch12, step2072]: loss 2.227807
[epoch12, step2073]: loss 1.302335
[epoch12, step2074]: loss 8.997588
[epoch12, step2075]: loss 1.539502
[epoch12, step2076]: loss 4.347853
[epoch12, step2077]: loss 1.413307
[epoch12, step2078]: loss 2.834976
[epoch12, step2079]: loss 13.667640
[epoch12, step2080]: loss 1.833815
[epoch12, step2081]: loss 13.931814
[epoch12, step2082]: loss 12.561241
[epoch12, step2083]: loss 0.748647
[epoch12, step2084]: loss 2.543720
[epoch12, step2085]: loss 8.743310
[epoch12, step2086]: loss 1.149584
[epoch12, step2087]: loss 3.892472
[epoch12, step2088]: loss 20.694794
[epoch12, step2089]: loss 1.048609
[epoch12, step2090]: loss 1.240360
[epoch12, step2091]: loss 19.509407
[epoch12, step2092]: loss 2.726401
[epoch12, step2093]: loss 3.438529
[epoch12, step2094]: loss 1.009253
[epoch12, step2095]: loss 6.667131
[epoch12, step2096]: loss 1.431254
[epoch12, step2097]: loss 2.066701
[epoch12, step2098]: loss 1.001924
[epoch12, step2099]: loss 1.984612
[epoch12, step2100]: loss 4.092499
[epoch12, step2101]: loss 22.617228
[epoch12, step2102]: loss 10.759652
[epoch12, step2103]: loss 1.147257
[epoch12, step2104]: loss 3.464031
[epoch12, step2105]: loss 1.001681
[epoch12, step2106]: loss 1.401495
[epoch12, step2107]: loss 2.956968
[epoch12, step2108]: loss 9.178516
[epoch12, step2109]: loss 1.184853
[epoch12, step2110]: loss 0.749987
[epoch12, step2111]: loss 1.164024
[epoch12, step2112]: loss 2.854537
[epoch12, step2113]: loss 2.145250
[epoch12, step2114]: loss 1.456298
[epoch12, step2115]: loss 3.530570
[epoch12, step2116]: loss 1.927601
[epoch12, step2117]: loss 0.814386
[epoch12, step2118]: loss 17.228518
[epoch12, step2119]: loss 1.130548
[epoch12, step2120]: loss 2.760183
[epoch12, step2121]: loss 1.116903
[epoch12, step2122]: loss 6.523212
[epoch12, step2123]: loss 1.379972
[epoch12, step2124]: loss 6.416499
[epoch12, step2125]: loss 14.088115
[epoch12, step2126]: loss 5.049930
[epoch12, step2127]: loss 5.642392
[epoch12, step2128]: loss 1.560640
[epoch12, step2129]: loss 3.361175
[epoch12, step2130]: loss 1.472308
[epoch12, step2131]: loss 2.825175
[epoch12, step2132]: loss 3.046871
[epoch12, step2133]: loss 34.436951
[epoch12, step2134]: loss 0.582406
[epoch12, step2135]: loss 24.080597
[epoch12, step2136]: loss 11.072697
[epoch12, step2137]: loss 0.977820
[epoch12, step2138]: loss 0.845150
[epoch12, step2139]: loss 9.103856
[epoch12, step2140]: loss 0.902809
[epoch12, step2141]: loss 1.808457
[epoch12, step2142]: loss 1.021693
[epoch12, step2143]: loss 2.455814
[epoch12, step2144]: loss 17.556396
[epoch12, step2145]: loss 20.536934
[epoch12, step2146]: loss 1.552895
[epoch12, step2147]: loss 4.051159
[epoch12, step2148]: loss 1.089920
[epoch12, step2149]: loss 2.908980
[epoch12, step2150]: loss 2.716643
[epoch12, step2151]: loss 1.509714
[epoch12, step2152]: loss 1.800423
[epoch12, step2153]: loss 1.076008
[epoch12, step2154]: loss 7.549092
[epoch12, step2155]: loss 1.503066
[epoch12, step2156]: loss 6.393801
[epoch12, step2157]: loss 3.401308
[epoch12, step2158]: loss 7.901885
[epoch12, step2159]: loss 5.063529
[epoch12, step2160]: loss 2.922165
[epoch12, step2161]: loss 1.217063
[epoch12, step2162]: loss 4.191839
[epoch12, step2163]: loss 1.572435
[epoch12, step2164]: loss 1.929918
[epoch12, step2165]: loss 1.171300
[epoch12, step2166]: loss 0.930034
[epoch12, step2167]: loss 2.122186
[epoch12, step2168]: loss 1.943276
[epoch12, step2169]: loss 6.138766
[epoch12, step2170]: loss 11.104973
[epoch12, step2171]: loss 0.635694
[epoch12, step2172]: loss 0.971376
[epoch12, step2173]: loss 7.709911
[epoch12, step2174]: loss 0.866820
[epoch12, step2175]: loss 2.910501
[epoch12, step2176]: loss 1.712367
[epoch12, step2177]: loss 0.938144
[epoch12, step2178]: loss 1.074079
[epoch12, step2179]: loss 5.719800
[epoch12, step2180]: loss 1.267998
[epoch12, step2181]: loss 1.309337
[epoch12, step2182]: loss 13.803926
[epoch12, step2183]: loss 2.115517
[epoch12, step2184]: loss 11.893323
[epoch12, step2185]: loss 2.636825
[epoch12, step2186]: loss 4.068861
[epoch12, step2187]: loss 19.377697
[epoch12, step2188]: loss 3.490318
[epoch12, step2189]: loss 0.539939
[epoch12, step2190]: loss 9.013536
[epoch12, step2191]: loss 10.664870
[epoch12, step2192]: loss 10.677193
[epoch12, step2193]: loss 0.748843
[epoch12, step2194]: loss 6.253896
[epoch12, step2195]: loss 1.285762
[epoch12, step2196]: loss 1.512943
[epoch12, step2197]: loss 1.733288
[epoch12, step2198]: loss 2.789930
[epoch12, step2199]: loss 2.894094
[epoch12, step2200]: loss 2.154109
[epoch12, step2201]: loss 16.647816
[epoch12, step2202]: loss 1.287736
[epoch12, step2203]: loss 1.878964
[epoch12, step2204]: loss 4.369405
[epoch12, step2205]: loss 1.240135
[epoch12, step2206]: loss 10.062517
[epoch12, step2207]: loss 0.962894
[epoch12, step2208]: loss 10.482716
[epoch12, step2209]: loss 2.410068
[epoch12, step2210]: loss 13.295733
[epoch12, step2211]: loss 0.927294
[epoch12, step2212]: loss 0.929744
[epoch12, step2213]: loss 6.866404
[epoch12, step2214]: loss 9.694281
[epoch12, step2215]: loss 1.379184
[epoch12, step2216]: loss 1.000539
[epoch12, step2217]: loss 2.321364
[epoch12, step2218]: loss 0.649258
[epoch12, step2219]: loss 1.447521
[epoch12, step2220]: loss 3.774381
[epoch12, step2221]: loss 17.015753
[epoch12, step2222]: loss 4.535006
[epoch12, step2223]: loss 13.939177
[epoch12, step2224]: loss 1.882637
[epoch12, step2225]: loss 1.859783
[epoch12, step2226]: loss 0.978558
[epoch12, step2227]: loss 0.751718
[epoch12, step2228]: loss 13.426264
[epoch12, step2229]: loss 1.700530
[epoch12, step2230]: loss 19.241442
[epoch12, step2231]: loss 2.031074
[epoch12, step2232]: loss 1.443640
[epoch12, step2233]: loss 13.020343
[epoch12, step2234]: loss 1.325460
[epoch12, step2235]: loss 2.385025
[epoch12, step2236]: loss 5.554965
[epoch12, step2237]: loss 6.217877
[epoch12, step2238]: loss 1.937198
[epoch12, step2239]: loss 1.793068
[epoch12, step2240]: loss 13.073444
[epoch12, step2241]: loss 13.387037
[epoch12, step2242]: loss 14.608194
[epoch12, step2243]: loss 1.421446
[epoch12, step2244]: loss 0.603267
[epoch12, step2245]: loss 1.868204
[epoch12, step2246]: loss 2.582971
[epoch12, step2247]: loss 1.912906
[epoch12, step2248]: loss 4.462717
[epoch12, step2249]: loss 9.874590
[epoch12, step2250]: loss 2.075696
[epoch12, step2251]: loss 1.339881
[epoch12, step2252]: loss 3.843339
[epoch12, step2253]: loss 12.041183
[epoch12, step2254]: loss 7.830776
[epoch12, step2255]: loss 0.933556
[epoch12, step2256]: loss 9.081511
[epoch12, step2257]: loss 16.632671
[epoch12, step2258]: loss 10.746454
[epoch12, step2259]: loss 2.313498
[epoch12, step2260]: loss 22.638014
[epoch12, step2261]: loss 4.914986
[epoch12, step2262]: loss 2.938219
[epoch12, step2263]: loss 1.859760
[epoch12, step2264]: loss 1.699728
[epoch12, step2265]: loss 1.781599
[epoch12, step2266]: loss 0.988271
[epoch12, step2267]: loss 9.144784
[epoch12, step2268]: loss 1.041829
[epoch12, step2269]: loss 0.947275
[epoch12, step2270]: loss 9.429492
[epoch12, step2271]: loss 1.047148
[epoch12, step2272]: loss 1.762323
[epoch12, step2273]: loss 31.670759
[epoch12, step2274]: loss 3.887970
[epoch12, step2275]: loss 4.373170
[epoch12, step2276]: loss 14.170862
[epoch12, step2277]: loss 1.610137
[epoch12, step2278]: loss 0.895531
[epoch12, step2279]: loss 2.889851
[epoch12, step2280]: loss 1.374240
[epoch12, step2281]: loss 2.142713
[epoch12, step2282]: loss 3.649211
[epoch12, step2283]: loss 12.208212
[epoch12, step2284]: loss 3.533899
[epoch12, step2285]: loss 2.285932
[epoch12, step2286]: loss 1.232795
[epoch12, step2287]: loss 0.844666
[epoch12, step2288]: loss 4.484302
[epoch12, step2289]: loss 1.463663
[epoch12, step2290]: loss 1.620137
[epoch12, step2291]: loss 1.207236
[epoch12, step2292]: loss 27.669172
[epoch12, step2293]: loss 0.974588
[epoch12, step2294]: loss 1.068402
[epoch12, step2295]: loss 0.889713
[epoch12, step2296]: loss 2.487796
[epoch12, step2297]: loss 1.023546
[epoch12, step2298]: loss 1.194973
[epoch12, step2299]: loss 1.275907
[epoch12, step2300]: loss 3.342965
[epoch12, step2301]: loss 1.264198
[epoch12, step2302]: loss 6.295807
[epoch12, step2303]: loss 1.713893
[epoch12, step2304]: loss 3.120684
[epoch12, step2305]: loss 0.822717
[epoch12, step2306]: loss 2.049846
[epoch12, step2307]: loss 3.966092
[epoch12, step2308]: loss 1.967453
[epoch12, step2309]: loss 19.479771
[epoch12, step2310]: loss 1.300144
[epoch12, step2311]: loss 1.141355
[epoch12, step2312]: loss 9.128335
[epoch12, step2313]: loss 1.107928
[epoch12, step2314]: loss 1.234009
[epoch12, step2315]: loss 12.813553
[epoch12, step2316]: loss 1.023947
[epoch12, step2317]: loss 2.568521
[epoch12, step2318]: loss 2.004484
[epoch12, step2319]: loss 6.046960
[epoch12, step2320]: loss 1.335306
[epoch12, step2321]: loss 3.365377
[epoch12, step2322]: loss 1.767157
[epoch12, step2323]: loss 1.752395
[epoch12, step2324]: loss 12.296018
[epoch12, step2325]: loss 1.440204
[epoch12, step2326]: loss 1.672865
[epoch12, step2327]: loss 13.262115
[epoch12, step2328]: loss 9.629205
[epoch12, step2329]: loss 1.053607
[epoch12, step2330]: loss 2.262836
[epoch12, step2331]: loss 9.225167
[epoch12, step2332]: loss 2.867585
[epoch12, step2333]: loss 19.232325
[epoch12, step2334]: loss 0.894187
[epoch12, step2335]: loss 8.202666
[epoch12, step2336]: loss 0.866628
[epoch12, step2337]: loss 2.447443
[epoch12, step2338]: loss 4.054614
[epoch12, step2339]: loss 1.081270
[epoch12, step2340]: loss 7.904836
[epoch12, step2341]: loss 1.368524
[epoch12, step2342]: loss 16.078499
[epoch12, step2343]: loss 1.552131
[epoch12, step2344]: loss 18.481979
[epoch12, step2345]: loss 5.943193
[epoch12, step2346]: loss 11.930099
[epoch12, step2347]: loss 0.861591
[epoch12, step2348]: loss 0.794724
[epoch12, step2349]: loss 10.777327
[epoch12, step2350]: loss 4.563860
[epoch12, step2351]: loss 7.154274
[epoch12, step2352]: loss 11.764828
[epoch12, step2353]: loss 1.863684
[epoch12, step2354]: loss 2.755512
[epoch12, step2355]: loss 2.049138
[epoch12, step2356]: loss 1.509743
[epoch12, step2357]: loss 1.029261
[epoch12, step2358]: loss 3.940532
[epoch12, step2359]: loss 1.698527
[epoch12, step2360]: loss 4.675112
[epoch12, step2361]: loss 1.692763
[epoch12, step2362]: loss 8.013212
[epoch12, step2363]: loss 3.099427
[epoch12, step2364]: loss 18.354223
[epoch12, step2365]: loss 6.808906
[epoch12, step2366]: loss 11.729894
[epoch12, step2367]: loss 0.971081
[epoch12, step2368]: loss 1.390962
[epoch12, step2369]: loss 18.798983
[epoch12, step2370]: loss 2.239470
[epoch12, step2371]: loss 19.010216
[epoch12, step2372]: loss 1.592122
[epoch12, step2373]: loss 1.205810
[epoch12, step2374]: loss 8.566517
[epoch12, step2375]: loss 2.514774
[epoch12, step2376]: loss 3.527889
[epoch12, step2377]: loss 1.995981
[epoch12, step2378]: loss 1.173661
[epoch12, step2379]: loss 1.337273
[epoch12, step2380]: loss 2.832204
[epoch12, step2381]: loss 8.134039
[epoch12, step2382]: loss 11.176336
[epoch12, step2383]: loss 1.158865
[epoch12, step2384]: loss 17.535156
[epoch12, step2385]: loss 3.648972
[epoch12, step2386]: loss 3.402941
[epoch12, step2387]: loss 2.039379
[epoch12, step2388]: loss 1.482940
[epoch12, step2389]: loss 2.028741
[epoch12, step2390]: loss 1.106084
[epoch12, step2391]: loss 2.908950
[epoch12, step2392]: loss 23.217497
[epoch12, step2393]: loss 1.016550
[epoch12, step2394]: loss 20.777481
[epoch12, step2395]: loss 9.230147
[epoch12, step2396]: loss 13.532924
[epoch12, step2397]: loss 4.171169
[epoch12, step2398]: loss 1.195790
[epoch12, step2399]: loss 1.455888
[epoch12, step2400]: loss 2.443329
[epoch12, step2401]: loss 2.601966
[epoch12, step2402]: loss 1.579616
[epoch12, step2403]: loss 2.838112
[epoch12, step2404]: loss 1.209165
[epoch12, step2405]: loss 32.672714
[epoch12, step2406]: loss 9.992126
[epoch12, step2407]: loss 1.831489
[epoch12, step2408]: loss 4.511263
[epoch12, step2409]: loss 0.718591
[epoch12, step2410]: loss 2.375583
[epoch12, step2411]: loss 1.658424
[epoch12, step2412]: loss 3.371943
[epoch12, step2413]: loss 7.972299
[epoch12, step2414]: loss 3.686786
[epoch12, step2415]: loss 8.928340
[epoch12, step2416]: loss 1.727924
[epoch12, step2417]: loss 2.614341
[epoch12, step2418]: loss 1.956817
[epoch12, step2419]: loss 1.224479
[epoch12, step2420]: loss 1.135753
[epoch12, step2421]: loss 9.921335
[epoch12, step2422]: loss 1.196334
[epoch12, step2423]: loss 2.791497
[epoch12, step2424]: loss 7.050620
[epoch12, step2425]: loss 2.184692
[epoch12, step2426]: loss 6.174757
[epoch12, step2427]: loss 8.515512
[epoch12, step2428]: loss 2.186533
[epoch12, step2429]: loss 1.013029
[epoch12, step2430]: loss 19.242840
[epoch12, step2431]: loss 6.841679
[epoch12, step2432]: loss 7.653902
[epoch12, step2433]: loss 6.239574
[epoch12, step2434]: loss 1.951662
[epoch12, step2435]: loss 1.223831
[epoch12, step2436]: loss 1.447924
[epoch12, step2437]: loss 12.166660
[epoch12, step2438]: loss 1.407092
[epoch12, step2439]: loss 9.899012
[epoch12, step2440]: loss 25.172400
[epoch12, step2441]: loss 2.194521
[epoch12, step2442]: loss 1.311263
[epoch12, step2443]: loss 13.562189
[epoch12, step2444]: loss 2.205398
[epoch12, step2445]: loss 1.822572
[epoch12, step2446]: loss 4.377072
[epoch12, step2447]: loss 10.045354
[epoch12, step2448]: loss 3.852840
[epoch12, step2449]: loss 1.164303
[epoch12, step2450]: loss 3.479769
[epoch12, step2451]: loss 2.497104
[epoch12, step2452]: loss 6.503849
[epoch12, step2453]: loss 9.448257
[epoch12, step2454]: loss 1.017283
[epoch12, step2455]: loss 6.242027
[epoch12, step2456]: loss 1.660683
[epoch12, step2457]: loss 12.695088
[epoch12, step2458]: loss 3.011280
[epoch12, step2459]: loss 1.797887
[epoch12, step2460]: loss 1.286936
[epoch12, step2461]: loss 13.301762
[epoch12, step2462]: loss 7.404443
[epoch12, step2463]: loss 1.661316
[epoch12, step2464]: loss 1.380538
[epoch12, step2465]: loss 0.779956
[epoch12, step2466]: loss 2.017935
[epoch12, step2467]: loss 1.235427
[epoch12, step2468]: loss 0.973463
[epoch12, step2469]: loss 16.581337
[epoch12, step2470]: loss 2.592491
[epoch12, step2471]: loss 0.727230
[epoch12, step2472]: loss 1.827205
[epoch12, step2473]: loss 1.976056
[epoch12, step2474]: loss 1.792262
[epoch12, step2475]: loss 1.800126
[epoch12, step2476]: loss 4.680350
[epoch12, step2477]: loss 1.441998
[epoch12, step2478]: loss 3.269705
[epoch12, step2479]: loss 1.700380
[epoch12, step2480]: loss 0.965912
[epoch12, step2481]: loss 1.462579
[epoch12, step2482]: loss 3.246473
[epoch12, step2483]: loss 0.835356
[epoch12, step2484]: loss 3.710596
[epoch12, step2485]: loss 1.329914
[epoch12, step2486]: loss 31.445244
[epoch12, step2487]: loss 4.347964
[epoch12, step2488]: loss 12.886021
[epoch12, step2489]: loss 1.543859
[epoch12, step2490]: loss 13.016300
[epoch12, step2491]: loss 2.612212
[epoch12, step2492]: loss 1.222650
[epoch12, step2493]: loss 7.076874
[epoch12, step2494]: loss 16.077784
[epoch12, step2495]: loss 1.599538
[epoch12, step2496]: loss 14.621789
[epoch12, step2497]: loss 1.284750
[epoch12, step2498]: loss 3.096782
[epoch12, step2499]: loss 4.361683
[epoch12, step2500]: loss 1.844839
[epoch12, step2501]: loss 16.153282
[epoch12, step2502]: loss 0.988268
[epoch12, step2503]: loss 1.629916
[epoch12, step2504]: loss 4.424062
[epoch12, step2505]: loss 2.294987
[epoch12, step2506]: loss 3.302362
[epoch12, step2507]: loss 1.454926
[epoch12, step2508]: loss 8.238885
[epoch12, step2509]: loss 3.212748
[epoch12, step2510]: loss 2.925170
[epoch12, step2511]: loss 3.459808
[epoch12, step2512]: loss 4.989848
[epoch12, step2513]: loss 0.840067
[epoch12, step2514]: loss 2.127007
[epoch12, step2515]: loss 0.905833
[epoch12, step2516]: loss 8.777925
[epoch12, step2517]: loss 11.746110
[epoch12, step2518]: loss 2.274070
[epoch12, step2519]: loss 1.591601
[epoch12, step2520]: loss 1.511985
[epoch12, step2521]: loss 0.890282
[epoch12, step2522]: loss 1.064327
[epoch12, step2523]: loss 1.192621
[epoch12, step2524]: loss 1.034697
[epoch12, step2525]: loss 1.511142
[epoch12, step2526]: loss 0.944046
[epoch12, step2527]: loss 2.019155
[epoch12, step2528]: loss 10.741017
[epoch12, step2529]: loss 13.499338
[epoch12, step2530]: loss 1.019936
[epoch12, step2531]: loss 26.350792
[epoch12, step2532]: loss 9.085653
[epoch12, step2533]: loss 7.880476
[epoch12, step2534]: loss 11.211467
[epoch12, step2535]: loss 24.937843
[epoch12, step2536]: loss 3.458989
[epoch12, step2537]: loss 2.636814
[epoch12, step2538]: loss 18.327604
[epoch12, step2539]: loss 1.879621
[epoch12, step2540]: loss 19.170429
[epoch12, step2541]: loss 3.361448
[epoch12, step2542]: loss 14.792591
[epoch12, step2543]: loss 1.774022
[epoch12, step2544]: loss 0.923944
[epoch12, step2545]: loss 1.116332
[epoch12, step2546]: loss 1.098499
[epoch12, step2547]: loss 1.014139
[epoch12, step2548]: loss 1.380875
[epoch12, step2549]: loss 2.503855
[epoch12, step2550]: loss 18.162920
[epoch12, step2551]: loss 9.673512
[epoch12, step2552]: loss 1.090651
[epoch12, step2553]: loss 3.497934
[epoch12, step2554]: loss 2.331857
[epoch12, step2555]: loss 1.234673
[epoch12, step2556]: loss 1.178973
[epoch12, step2557]: loss 2.717824
[epoch12, step2558]: loss 1.913984
[epoch12, step2559]: loss 1.675813
[epoch12, step2560]: loss 11.018768
[epoch12, step2561]: loss 3.026293
[epoch12, step2562]: loss 11.908005
[epoch12, step2563]: loss 3.942481
[epoch12, step2564]: loss 2.719851
[epoch12, step2565]: loss 1.526335
[epoch12, step2566]: loss 5.148153
[epoch12, step2567]: loss 3.471493
[epoch12, step2568]: loss 1.792057
[epoch12, step2569]: loss 1.692001
[epoch12, step2570]: loss 1.567872
[epoch12, step2571]: loss 0.800113
[epoch12, step2572]: loss 2.185047
[epoch12, step2573]: loss 9.750863
[epoch12, step2574]: loss 4.911674
[epoch12, step2575]: loss 4.003641
[epoch12, step2576]: loss 1.118828
[epoch12, step2577]: loss 1.048659
[epoch12, step2578]: loss 8.913870
[epoch12, step2579]: loss 5.981274
[epoch12, step2580]: loss 14.042583
[epoch12, step2581]: loss 9.334939
[epoch12, step2582]: loss 13.979423
[epoch12, step2583]: loss 16.325562
[epoch12, step2584]: loss 10.041299
[epoch12, step2585]: loss 4.775586
[epoch12, step2586]: loss 2.684393
[epoch12, step2587]: loss 8.472039
[epoch12, step2588]: loss 7.399680
[epoch12, step2589]: loss 2.558716
[epoch12, step2590]: loss 19.237703
[epoch12, step2591]: loss 2.342705
[epoch12, step2592]: loss 1.423203
[epoch12, step2593]: loss 18.487341
[epoch12, step2594]: loss 1.930726
[epoch12, step2595]: loss 0.974430
[epoch12, step2596]: loss 1.624479
[epoch12, step2597]: loss 3.116499
[epoch12, step2598]: loss 1.291795
[epoch12, step2599]: loss 2.437612
[epoch12, step2600]: loss 1.805139
[epoch12, step2601]: loss 6.488142
[epoch12, step2602]: loss 2.019569
[epoch12, step2603]: loss 1.272210
[epoch12, step2604]: loss 9.424538
[epoch12, step2605]: loss 1.996124
[epoch12, step2606]: loss 9.322039
[epoch12, step2607]: loss 39.049301
[epoch12, step2608]: loss 2.194991
[epoch12, step2609]: loss 5.451884
[epoch12, step2610]: loss 5.890107
[epoch12, step2611]: loss 0.986490
[epoch12, step2612]: loss 1.908641
[epoch12, step2613]: loss 1.852724
[epoch12, step2614]: loss 1.268890
[epoch12, step2615]: loss 2.891556
[epoch12, step2616]: loss 1.658869
[epoch12, step2617]: loss 1.446850
[epoch12, step2618]: loss 9.899531
[epoch12, step2619]: loss 0.971496
[epoch12, step2620]: loss 9.990835
[epoch12, step2621]: loss 0.668002
[epoch12, step2622]: loss 1.164236
[epoch12, step2623]: loss 2.307732
[epoch12, step2624]: loss 1.134536
[epoch12, step2625]: loss 1.955581
[epoch12, step2626]: loss 6.932074
[epoch12, step2627]: loss 1.400265
[epoch12, step2628]: loss 9.852258
[epoch12, step2629]: loss 31.918262
[epoch12, step2630]: loss 0.792293
[epoch12, step2631]: loss 1.515507
[epoch12, step2632]: loss 2.277284
[epoch12, step2633]: loss 3.537297
[epoch12, step2634]: loss 1.927570
[epoch12, step2635]: loss 16.194283
[epoch12, step2636]: loss 2.223276
[epoch12, step2637]: loss 2.498113
[epoch12, step2638]: loss 1.900335
[epoch12, step2639]: loss 1.685976
[epoch12, step2640]: loss 6.333817
[epoch12, step2641]: loss 7.494113
[epoch12, step2642]: loss 13.001102
[epoch12, step2643]: loss 1.967985
[epoch12, step2644]: loss 5.489378
[epoch12, step2645]: loss 1.264181
[epoch12, step2646]: loss 11.288068
[epoch12, step2647]: loss 4.909867
[epoch12, step2648]: loss 15.530365
[epoch12, step2649]: loss 1.157003
[epoch12, step2650]: loss 3.555403
[epoch12, step2651]: loss 3.120888
[epoch12, step2652]: loss 10.011811
[epoch12, step2653]: loss 1.098356
[epoch12, step2654]: loss 1.051484
[epoch12, step2655]: loss 9.863457
[epoch12, step2656]: loss 22.182159
[epoch12, step2657]: loss 1.605285
[epoch12, step2658]: loss 0.910710
[epoch12, step2659]: loss 1.503406
[epoch12, step2660]: loss 1.290346
[epoch12, step2661]: loss 6.233555
[epoch12, step2662]: loss 1.406268
[epoch12, step2663]: loss 3.406962
[epoch12, step2664]: loss 1.240408
[epoch12, step2665]: loss 0.950180
[epoch12, step2666]: loss 1.466582
[epoch12, step2667]: loss 13.750139
[epoch12, step2668]: loss 2.418660
[epoch12, step2669]: loss 4.452316
[epoch12, step2670]: loss 1.372204
[epoch12, step2671]: loss 0.971558
[epoch12, step2672]: loss 1.053511
[epoch12, step2673]: loss 2.378269
[epoch12, step2674]: loss 0.725499
[epoch12, step2675]: loss 3.209282
[epoch12, step2676]: loss 6.276818
[epoch12, step2677]: loss 1.597579
[epoch12, step2678]: loss 1.768851
[epoch12, step2679]: loss 14.742791
[epoch12, step2680]: loss 4.581229
[epoch12, step2681]: loss 3.586504
[epoch12, step2682]: loss 7.664559
[epoch12, step2683]: loss 2.472235
[epoch12, step2684]: loss 9.628638
[epoch12, step2685]: loss 8.491018
[epoch12, step2686]: loss 9.721222
[epoch12, step2687]: loss 13.952254
[epoch12, step2688]: loss 3.257512
[epoch12, step2689]: loss 4.255840
[epoch12, step2690]: loss 1.187655
[epoch12, step2691]: loss 9.403301
[epoch12, step2692]: loss 2.533048
[epoch12, step2693]: loss 1.242900
[epoch12, step2694]: loss 1.712132
[epoch12, step2695]: loss 5.520059
[epoch12, step2696]: loss 16.497108
[epoch12, step2697]: loss 4.948952
[epoch12, step2698]: loss 2.650117
[epoch12, step2699]: loss 3.559847
[epoch12, step2700]: loss 0.882273
[epoch12, step2701]: loss 6.334857
[epoch12, step2702]: loss 0.902811
[epoch12, step2703]: loss 2.587066
[epoch12, step2704]: loss 9.328797
[epoch12, step2705]: loss 2.806878
[epoch12, step2706]: loss 2.559595
[epoch12, step2707]: loss 2.201323
[epoch12, step2708]: loss 10.550112
[epoch12, step2709]: loss 3.314642
[epoch12, step2710]: loss 11.066083
[epoch12, step2711]: loss 2.294961
[epoch12, step2712]: loss 14.821001
[epoch12, step2713]: loss 20.343351
[epoch12, step2714]: loss 3.632351
[epoch12, step2715]: loss 1.035571
[epoch12, step2716]: loss 2.617607
[epoch12, step2717]: loss 19.531195
[epoch12, step2718]: loss 1.056972
[epoch12, step2719]: loss 1.420954
[epoch12, step2720]: loss 13.519094
[epoch12, step2721]: loss 7.305244
[epoch12, step2722]: loss 1.575370
[epoch12, step2723]: loss 3.623688
[epoch12, step2724]: loss 18.736330
[epoch12, step2725]: loss 8.620212
[epoch12, step2726]: loss 5.847642
[epoch12, step2727]: loss 0.959400
[epoch12, step2728]: loss 3.040260
[epoch12, step2729]: loss 4.787054
[epoch12, step2730]: loss 1.780780
[epoch12, step2731]: loss 1.351780
[epoch12, step2732]: loss 0.913037
[epoch12, step2733]: loss 2.326490
[epoch12, step2734]: loss 0.944195
[epoch12, step2735]: loss 1.053777
[epoch12, step2736]: loss 2.600292
[epoch12, step2737]: loss 0.765254
[epoch12, step2738]: loss 2.417283
[epoch12, step2739]: loss 1.116341
[epoch12, step2740]: loss 1.808853
[epoch12, step2741]: loss 4.907262
[epoch12, step2742]: loss 1.760229
[epoch12, step2743]: loss 2.431326
[epoch12, step2744]: loss 18.059946
[epoch12, step2745]: loss 8.429326
[epoch12, step2746]: loss 2.495259
[epoch12, step2747]: loss 4.228838
[epoch12, step2748]: loss 10.139478
[epoch12, step2749]: loss 1.323738
[epoch12, step2750]: loss 23.256886
[epoch12, step2751]: loss 5.913937
[epoch12, step2752]: loss 2.504277
[epoch12, step2753]: loss 0.760292
[epoch12, step2754]: loss 1.972622
[epoch12, step2755]: loss 9.844293
[epoch12, step2756]: loss 1.548404
[epoch12, step2757]: loss 0.915381
[epoch12, step2758]: loss 17.984161
[epoch12, step2759]: loss 1.190961
[epoch12, step2760]: loss 1.509809
[epoch12, step2761]: loss 2.939228
[epoch12, step2762]: loss 19.688051
[epoch12, step2763]: loss 3.366043
[epoch12, step2764]: loss 1.742822
[epoch12, step2765]: loss 6.946917
[epoch12, step2766]: loss 0.975766
[epoch12, step2767]: loss 5.989983
[epoch12, step2768]: loss 0.860836
[epoch12, step2769]: loss 0.875346
[epoch12, step2770]: loss 1.135525
[epoch12, step2771]: loss 1.364366
[epoch12, step2772]: loss 3.967004
[epoch12, step2773]: loss 2.359503
[epoch12, step2774]: loss 10.262765
[epoch12, step2775]: loss 0.689294
[epoch12, step2776]: loss 0.874414
[epoch12, step2777]: loss 1.825935
[epoch12, step2778]: loss 14.756968
[epoch12, step2779]: loss 1.364776
[epoch12, step2780]: loss 32.927700
[epoch12, step2781]: loss 9.265445
[epoch12, step2782]: loss 1.179741
[epoch12, step2783]: loss 2.301845
[epoch12, step2784]: loss 5.315836
[epoch12, step2785]: loss 1.034353
[epoch12, step2786]: loss 1.973278
[epoch12, step2787]: loss 2.816583
[epoch12, step2788]: loss 1.434307
[epoch12, step2789]: loss 5.467069
[epoch12, step2790]: loss 2.342263
[epoch12, step2791]: loss 7.301090
[epoch12, step2792]: loss 0.959889
[epoch12, step2793]: loss 4.121900
[epoch12, step2794]: loss 1.763494
[epoch12, step2795]: loss 2.744761
[epoch12, step2796]: loss 1.010508
[epoch12, step2797]: loss 17.955004
[epoch12, step2798]: loss 2.531646
[epoch12, step2799]: loss 1.757841
[epoch12, step2800]: loss 1.944063
[epoch12, step2801]: loss 19.460917
[epoch12, step2802]: loss 4.267177
[epoch12, step2803]: loss 2.769858
[epoch12, step2804]: loss 8.628640
[epoch12, step2805]: loss 2.720779
[epoch12, step2806]: loss 2.073944
[epoch12, step2807]: loss 1.027525
[epoch12, step2808]: loss 1.280849
[epoch12, step2809]: loss 0.617438
[epoch12, step2810]: loss 0.707628
[epoch12, step2811]: loss 5.839153
[epoch12, step2812]: loss 14.449159
[epoch12, step2813]: loss 6.472319
[epoch12, step2814]: loss 10.049363
[epoch12, step2815]: loss 1.945555
[epoch12, step2816]: loss 1.840240
[epoch12, step2817]: loss 5.715851
[epoch12, step2818]: loss 56.984005
[epoch12, step2819]: loss 14.530866
[epoch12, step2820]: loss 9.116150
[epoch12, step2821]: loss 4.945564
[epoch12, step2822]: loss 9.901474
[epoch12, step2823]: loss 1.929985
[epoch12, step2824]: loss 2.566310
[epoch12, step2825]: loss 7.729972
[epoch12, step2826]: loss 1.058941
[epoch12, step2827]: loss 1.961012
[epoch12, step2828]: loss 23.632551
[epoch12, step2829]: loss 2.608441
[epoch12, step2830]: loss 19.149595
[epoch12, step2831]: loss 0.702572
[epoch12, step2832]: loss 1.615309
[epoch12, step2833]: loss 8.117072
[epoch12, step2834]: loss 2.227792
[epoch12, step2835]: loss 1.453676
[epoch12, step2836]: loss 1.496389
[epoch12, step2837]: loss 3.490995
[epoch12, step2838]: loss 0.725613
[epoch12, step2839]: loss 1.804959
[epoch12, step2840]: loss 2.423426
[epoch12, step2841]: loss 2.589824
[epoch12, step2842]: loss 2.479655
[epoch12, step2843]: loss 28.386311
[epoch12, step2844]: loss 16.678921
[epoch12, step2845]: loss 2.049722
[epoch12, step2846]: loss 2.556780
[epoch12, step2847]: loss 11.388305
[epoch12, step2848]: loss 14.563669
[epoch12, step2849]: loss 6.345119
[epoch12, step2850]: loss 2.380440
[epoch12, step2851]: loss 1.790071
[epoch12, step2852]: loss 0.952260
[epoch12, step2853]: loss 0.980207
[epoch12, step2854]: loss 0.860112
[epoch12, step2855]: loss 1.319165
[epoch12, step2856]: loss 0.642866
[epoch12, step2857]: loss 1.452170
[epoch12, step2858]: loss 1.654155
[epoch12, step2859]: loss 2.649180
[epoch12, step2860]: loss 1.524329
[epoch12, step2861]: loss 0.854394
[epoch12, step2862]: loss 2.853665
[epoch12, step2863]: loss 11.974406
[epoch12, step2864]: loss 2.560669
[epoch12, step2865]: loss 2.866843
[epoch12, step2866]: loss 19.273840
[epoch12, step2867]: loss 1.930048
[epoch12, step2868]: loss 2.608341
[epoch12, step2869]: loss 2.983730
[epoch12, step2870]: loss 6.189368
[epoch12, step2871]: loss 2.108004
[epoch12, step2872]: loss 11.538477
[epoch12, step2873]: loss 2.002357
[epoch12, step2874]: loss 31.224327
[epoch12, step2875]: loss 0.959759
[epoch12, step2876]: loss 1.353278
[epoch12, step2877]: loss 1.506731
[epoch12, step2878]: loss 0.914579
[epoch12, step2879]: loss 17.426010
[epoch12, step2880]: loss 8.867732
[epoch12, step2881]: loss 1.395943
[epoch12, step2882]: loss 11.840671
[epoch12, step2883]: loss 0.894739
[epoch12, step2884]: loss 1.228500
[epoch12, step2885]: loss 8.293337
[epoch12, step2886]: loss 3.984735
[epoch12, step2887]: loss 1.360384
[epoch12, step2888]: loss 0.952539
[epoch12, step2889]: loss 1.619896
[epoch12, step2890]: loss 14.446377
[epoch12, step2891]: loss 1.102618
[epoch12, step2892]: loss 2.736774
[epoch12, step2893]: loss 1.446679
[epoch12, step2894]: loss 2.073949
[epoch12, step2895]: loss 10.413022
[epoch12, step2896]: loss 2.059434
[epoch12, step2897]: loss 2.320607
[epoch12, step2898]: loss 1.375414
[epoch12, step2899]: loss 2.133821
[epoch12, step2900]: loss 7.034196
[epoch12, step2901]: loss 1.469072
[epoch12, step2902]: loss 1.253295
[epoch12, step2903]: loss 8.979710
[epoch12, step2904]: loss 1.187454
[epoch12, step2905]: loss 1.585588
[epoch12, step2906]: loss 2.038941
[epoch12, step2907]: loss 17.711313
[epoch12, step2908]: loss 0.824101
[epoch12, step2909]: loss 3.334573
[epoch12, step2910]: loss 0.754077
[epoch12, step2911]: loss 6.129615
[epoch12, step2912]: loss 2.103312
[epoch12, step2913]: loss 1.132764
[epoch12, step2914]: loss 3.763657
[epoch12, step2915]: loss 2.733542
[epoch12, step2916]: loss 13.965761
[epoch12, step2917]: loss 0.817312
[epoch12, step2918]: loss 1.443928
[epoch12, step2919]: loss 0.980460
[epoch12, step2920]: loss 6.253541
[epoch12, step2921]: loss 0.840979
[epoch12, step2922]: loss 1.057158
[epoch12, step2923]: loss 8.694229
[epoch12, step2924]: loss 13.645852
[epoch12, step2925]: loss 0.849832
[epoch12, step2926]: loss 1.348621
[epoch12, step2927]: loss 10.565761
[epoch12, step2928]: loss 3.484783
[epoch12, step2929]: loss 0.948419
[epoch12, step2930]: loss 1.136239
[epoch12, step2931]: loss 0.963180
[epoch12, step2932]: loss 10.754610
[epoch12, step2933]: loss 5.889274
[epoch12, step2934]: loss 0.691370
[epoch12, step2935]: loss 1.353100
[epoch12, step2936]: loss 1.692874
[epoch12, step2937]: loss 1.000166
[epoch12, step2938]: loss 1.477669
[epoch12, step2939]: loss 2.544179
[epoch12, step2940]: loss 0.667075
[epoch12, step2941]: loss 0.500681
[epoch12, step2942]: loss 1.589777
[epoch12, step2943]: loss 22.890965
[epoch12, step2944]: loss 32.196213
[epoch12, step2945]: loss 6.550115
[epoch12, step2946]: loss 0.779584
[epoch12, step2947]: loss 6.263744
[epoch12, step2948]: loss 7.025265
[epoch12, step2949]: loss 2.082834
[epoch12, step2950]: loss 1.453124
[epoch12, step2951]: loss 1.244096
[epoch12, step2952]: loss 23.686522
[epoch12, step2953]: loss 1.490319
[epoch12, step2954]: loss 14.524452
[epoch12, step2955]: loss 1.365235
[epoch12, step2956]: loss 1.726414
[epoch12, step2957]: loss 20.312284
[epoch12, step2958]: loss 3.299244
[epoch12, step2959]: loss 1.221043
[epoch12, step2960]: loss 32.736862
[epoch12, step2961]: loss 1.831633
[epoch12, step2962]: loss 1.927770
[epoch12, step2963]: loss 2.237243
[epoch12, step2964]: loss 1.136444
[epoch12, step2965]: loss 1.151182
[epoch12, step2966]: loss 3.982353
[epoch12, step2967]: loss 12.773065
[epoch12, step2968]: loss 5.286263
[epoch12, step2969]: loss 2.522927
[epoch12, step2970]: loss 4.472787
[epoch12, step2971]: loss 9.389643
[epoch12, step2972]: loss 1.884249
[epoch12, step2973]: loss 10.843174
[epoch12, step2974]: loss 0.990663
[epoch12, step2975]: loss 1.053459
[epoch12, step2976]: loss 1.328812
[epoch12, step2977]: loss 4.711521
[epoch12, step2978]: loss 2.359153
[epoch12, step2979]: loss 5.496417
[epoch12, step2980]: loss 12.745497
[epoch12, step2981]: loss 15.894759
[epoch12, step2982]: loss 2.174299
[epoch12, step2983]: loss 2.910921
[epoch12, step2984]: loss 1.468347
[epoch12, step2985]: loss 1.284615
[epoch12, step2986]: loss 2.426831
[epoch12, step2987]: loss 7.272252
[epoch12, step2988]: loss 31.289137
[epoch12, step2989]: loss 3.547687
[epoch12, step2990]: loss 1.490802
[epoch12, step2991]: loss 9.785746
[epoch12, step2992]: loss 4.336228
[epoch12, step2993]: loss 27.276520
[epoch12, step2994]: loss 1.643352
[epoch12, step2995]: loss 3.489794
[epoch12, step2996]: loss 1.145107
[epoch12, step2997]: loss 1.667092
[epoch12, step2998]: loss 2.131629
[epoch12, step2999]: loss 1.916038
[epoch12, step3000]: loss 1.524698
[epoch12, step3001]: loss 10.575857
[epoch12, step3002]: loss 3.617232
[epoch12, step3003]: loss 1.839234
[epoch12, step3004]: loss 0.951488
[epoch12, step3005]: loss 1.482317
[epoch12, step3006]: loss 11.809960
[epoch12, step3007]: loss 18.280819
[epoch12, step3008]: loss 2.719023
[epoch12, step3009]: loss 0.856275
[epoch12, step3010]: loss 2.652927
[epoch12, step3011]: loss 1.792612
[epoch12, step3012]: loss 1.902678
[epoch12, step3013]: loss 0.740020
[epoch12, step3014]: loss 5.363259
[epoch12, step3015]: loss 1.709155
[epoch12, step3016]: loss 11.926904
[epoch12, step3017]: loss 6.007731
[epoch12, step3018]: loss 1.092418
[epoch12, step3019]: loss 10.907671
[epoch12, step3020]: loss 1.783322
[epoch12, step3021]: loss 13.753352
[epoch12, step3022]: loss 14.653024
[epoch12, step3023]: loss 11.869854
[epoch12, step3024]: loss 8.691600
[epoch12, step3025]: loss 1.238016
[epoch12, step3026]: loss 1.586820
[epoch12, step3027]: loss 0.665659
[epoch12, step3028]: loss 0.607583
[epoch12, step3029]: loss 13.944456
[epoch12, step3030]: loss 1.404715
[epoch12, step3031]: loss 3.970089
[epoch12, step3032]: loss 10.613844
[epoch12, step3033]: loss 12.942074
[epoch12, step3034]: loss 9.630990
[epoch12, step3035]: loss 1.204154
[epoch12, step3036]: loss 1.401674
[epoch12, step3037]: loss 1.085837
[epoch12, step3038]: loss 14.276629
[epoch12, step3039]: loss 0.849124
[epoch12, step3040]: loss 0.705435
[epoch12, step3041]: loss 1.050530
[epoch12, step3042]: loss 2.988872
[epoch12, step3043]: loss 0.755597
[epoch12, step3044]: loss 1.943285
[epoch12, step3045]: loss 13.666047
[epoch12, step3046]: loss 2.176043
[epoch12, step3047]: loss 4.850386
[epoch12, step3048]: loss 3.186190
[epoch12, step3049]: loss 8.008279
[epoch12, step3050]: loss 18.178576
[epoch12, step3051]: loss 2.225040
[epoch12, step3052]: loss 1.582110
[epoch12, step3053]: loss 12.844590
[epoch12, step3054]: loss 1.443469
[epoch12, step3055]: loss 1.562892
[epoch12, step3056]: loss 1.513283
[epoch12, step3057]: loss 1.830870
[epoch12, step3058]: loss 19.205969
[epoch12, step3059]: loss 2.544385
[epoch12, step3060]: loss 3.318030
[epoch12, step3061]: loss 1.095481
[epoch12, step3062]: loss 6.923808
[epoch12, step3063]: loss 0.897642
[epoch12, step3064]: loss 1.830992
[epoch12, step3065]: loss 0.879948
[epoch12, step3066]: loss 24.736347
[epoch12, step3067]: loss 16.532871
[epoch12, step3068]: loss 8.680988
[epoch12, step3069]: loss 11.732012
[epoch12, step3070]: loss 9.158916
[epoch12, step3071]: loss 5.036848
[epoch12, step3072]: loss 1.604361
[epoch12, step3073]: loss 13.457666
[epoch12, step3074]: loss 1.068045
[epoch12, step3075]: loss 3.651702
[epoch12, step3076]: loss 2.995332

[epoch12]: avg loss 2.995332

[epoch13, step1]: loss 1.211985
[epoch13, step2]: loss 2.056548
[epoch13, step3]: loss 8.890238
[epoch13, step4]: loss 34.702461
[epoch13, step5]: loss 2.794528
[epoch13, step6]: loss 16.410326
[epoch13, step7]: loss 9.067389
[epoch13, step8]: loss 4.952791
[epoch13, step9]: loss 2.053401
[epoch13, step10]: loss 12.976854
[epoch13, step11]: loss 2.471773
[epoch13, step12]: loss 18.766205
[epoch13, step13]: loss 9.188524
[epoch13, step14]: loss 1.258115
[epoch13, step15]: loss 0.859029
[epoch13, step16]: loss 16.886141
[epoch13, step17]: loss 1.212537
[epoch13, step18]: loss 0.680154
[epoch13, step19]: loss 1.206300
[epoch13, step20]: loss 1.341371
[epoch13, step21]: loss 1.671733
[epoch13, step22]: loss 6.984813
[epoch13, step23]: loss 5.223894
[epoch13, step24]: loss 1.573640
[epoch13, step25]: loss 1.609022
[epoch13, step26]: loss 7.269112
[epoch13, step27]: loss 13.308221
[epoch13, step28]: loss 8.695719
[epoch13, step29]: loss 19.681839
[epoch13, step30]: loss 1.609695
[epoch13, step31]: loss 1.371388
[epoch13, step32]: loss 2.126811
[epoch13, step33]: loss 0.954135
[epoch13, step34]: loss 1.384883
[epoch13, step35]: loss 1.434007
[epoch13, step36]: loss 1.553764
[epoch13, step37]: loss 7.827939
[epoch13, step38]: loss 9.697285
[epoch13, step39]: loss 1.971461
[epoch13, step40]: loss 1.879544
[epoch13, step41]: loss 1.094209
[epoch13, step42]: loss 0.913349
[epoch13, step43]: loss 1.094268
[epoch13, step44]: loss 3.178464
[epoch13, step45]: loss 2.272743
[epoch13, step46]: loss 7.144385
[epoch13, step47]: loss 1.285097
[epoch13, step48]: loss 18.403406
[epoch13, step49]: loss 15.233835
[epoch13, step50]: loss 1.223387
[epoch13, step51]: loss 1.663860
[epoch13, step52]: loss 2.655823
[epoch13, step53]: loss 8.231182
[epoch13, step54]: loss 17.014299
[epoch13, step55]: loss 4.048978
[epoch13, step56]: loss 15.289084
[epoch13, step57]: loss 0.940337
[epoch13, step58]: loss 21.983528
[epoch13, step59]: loss 1.305263
[epoch13, step60]: loss 15.219994
[epoch13, step61]: loss 20.244295
[epoch13, step62]: loss 6.064003
[epoch13, step63]: loss 0.957597
[epoch13, step64]: loss 3.425051
[epoch13, step65]: loss 0.776594
[epoch13, step66]: loss 4.651686
[epoch13, step67]: loss 4.807826
[epoch13, step68]: loss 0.736885
[epoch13, step69]: loss 1.375737
[epoch13, step70]: loss 10.548296
[epoch13, step71]: loss 2.497708
[epoch13, step72]: loss 1.139229
[epoch13, step73]: loss 0.926872
[epoch13, step74]: loss 2.197325
[epoch13, step75]: loss 0.721342
[epoch13, step76]: loss 2.953606
[epoch13, step77]: loss 1.109697
[epoch13, step78]: loss 10.122234
[epoch13, step79]: loss 25.777243
[epoch13, step80]: loss 1.201015
[epoch13, step81]: loss 1.047938
[epoch13, step82]: loss 0.991650
[epoch13, step83]: loss 3.086300
[epoch13, step84]: loss 4.648988
[epoch13, step85]: loss 3.134736
[epoch13, step86]: loss 2.340704
[epoch13, step87]: loss 2.476889
[epoch13, step88]: loss 11.061487
[epoch13, step89]: loss 1.252434
[epoch13, step90]: loss 1.751018
[epoch13, step91]: loss 1.602817
[epoch13, step92]: loss 9.427713
[epoch13, step93]: loss 3.114483
[epoch13, step94]: loss 1.157410
[epoch13, step95]: loss 0.931042
[epoch13, step96]: loss 2.820165
[epoch13, step97]: loss 3.469373
[epoch13, step98]: loss 1.232588
[epoch13, step99]: loss 5.408318
[epoch13, step100]: loss 0.957968
[epoch13, step101]: loss 11.312245
[epoch13, step102]: loss 3.149700
[epoch13, step103]: loss 13.029620
[epoch13, step104]: loss 1.785691
[epoch13, step105]: loss 1.063389
[epoch13, step106]: loss 3.927954
[epoch13, step107]: loss 1.184210
[epoch13, step108]: loss 2.174700
[epoch13, step109]: loss 1.798468
[epoch13, step110]: loss 1.231683
[epoch13, step111]: loss 1.269262
[epoch13, step112]: loss 6.430405
[epoch13, step113]: loss 4.469114
[epoch13, step114]: loss 0.804539
[epoch13, step115]: loss 1.024075
[epoch13, step116]: loss 1.490599
[epoch13, step117]: loss 0.761731
[epoch13, step118]: loss 13.686499
[epoch13, step119]: loss 0.914559
[epoch13, step120]: loss 15.773389
[epoch13, step121]: loss 7.759379
[epoch13, step122]: loss 9.917812
[epoch13, step123]: loss 1.142280
[epoch13, step124]: loss 1.099529
[epoch13, step125]: loss 1.040539
[epoch13, step126]: loss 1.067927
[epoch13, step127]: loss 1.316907
[epoch13, step128]: loss 3.502448
[epoch13, step129]: loss 5.526490
[epoch13, step130]: loss 0.826880
[epoch13, step131]: loss 1.372524
[epoch13, step132]: loss 7.768267
[epoch13, step133]: loss 2.815725
[epoch13, step134]: loss 9.552011
[epoch13, step135]: loss 2.818840
[epoch13, step136]: loss 10.700692
[epoch13, step137]: loss 1.633097
[epoch13, step138]: loss 9.443981
[epoch13, step139]: loss 18.860588
[epoch13, step140]: loss 1.056899
[epoch13, step141]: loss 0.993597
[epoch13, step142]: loss 12.821237
[epoch13, step143]: loss 1.480812
[epoch13, step144]: loss 3.784401
[epoch13, step145]: loss 1.033510
[epoch13, step146]: loss 14.136536
[epoch13, step147]: loss 1.952778
[epoch13, step148]: loss 17.070198
[epoch13, step149]: loss 2.263100
[epoch13, step150]: loss 20.935780
[epoch13, step151]: loss 2.820734
[epoch13, step152]: loss 4.250365
[epoch13, step153]: loss 1.421740
[epoch13, step154]: loss 7.579340
[epoch13, step155]: loss 12.756363
[epoch13, step156]: loss 2.457269
[epoch13, step157]: loss 2.808430
[epoch13, step158]: loss 6.751361
[epoch13, step159]: loss 2.903856
[epoch13, step160]: loss 2.059905
[epoch13, step161]: loss 0.798991
[epoch13, step162]: loss 1.126894
[epoch13, step163]: loss 0.834285
[epoch13, step164]: loss 1.433284
[epoch13, step165]: loss 1.518126
[epoch13, step166]: loss 22.914162
[epoch13, step167]: loss 0.905724
[epoch13, step168]: loss 1.999525
[epoch13, step169]: loss 5.032557
[epoch13, step170]: loss 1.059608
[epoch13, step171]: loss 0.970713
[epoch13, step172]: loss 1.414122
[epoch13, step173]: loss 0.805959
[epoch13, step174]: loss 6.148731
[epoch13, step175]: loss 2.109535
[epoch13, step176]: loss 1.399765
[epoch13, step177]: loss 1.026323
[epoch13, step178]: loss 2.649533
[epoch13, step179]: loss 0.935403
[epoch13, step180]: loss 3.899134
[epoch13, step181]: loss 1.335958
[epoch13, step182]: loss 2.847353
[epoch13, step183]: loss 0.949591
[epoch13, step184]: loss 4.259753
[epoch13, step185]: loss 4.817785
[epoch13, step186]: loss 18.500759
[epoch13, step187]: loss 2.748313
[epoch13, step188]: loss 1.412141
[epoch13, step189]: loss 1.436646
[epoch13, step190]: loss 10.422772
[epoch13, step191]: loss 17.360155
[epoch13, step192]: loss 25.609083
[epoch13, step193]: loss 1.592865
[epoch13, step194]: loss 2.165901
[epoch13, step195]: loss 0.817438
[epoch13, step196]: loss 1.014994
[epoch13, step197]: loss 1.434556
[epoch13, step198]: loss 11.683320
[epoch13, step199]: loss 1.495671
[epoch13, step200]: loss 2.490842
[epoch13, step201]: loss 0.998684
[epoch13, step202]: loss 1.001756
[epoch13, step203]: loss 0.819049
[epoch13, step204]: loss 3.306810
[epoch13, step205]: loss 2.601893
[epoch13, step206]: loss 11.680380
[epoch13, step207]: loss 5.534116
[epoch13, step208]: loss 7.573153
[epoch13, step209]: loss 1.107017
[epoch13, step210]: loss 6.119990
[epoch13, step211]: loss 2.384968
[epoch13, step212]: loss 0.976591
[epoch13, step213]: loss 4.108782
[epoch13, step214]: loss 1.938891
[epoch13, step215]: loss 0.796609
[epoch13, step216]: loss 1.782627
[epoch13, step217]: loss 13.395259
[epoch13, step218]: loss 49.427208
[epoch13, step219]: loss 2.785424
[epoch13, step220]: loss 1.013601
[epoch13, step221]: loss 0.783781
[epoch13, step222]: loss 13.859241
[epoch13, step223]: loss 1.246551
[epoch13, step224]: loss 4.118836
[epoch13, step225]: loss 1.888143
[epoch13, step226]: loss 2.469229
[epoch13, step227]: loss 1.120314
[epoch13, step228]: loss 8.724347
[epoch13, step229]: loss 14.501545
[epoch13, step230]: loss 2.038107
[epoch13, step231]: loss 3.229757
[epoch13, step232]: loss 0.975574
[epoch13, step233]: loss 19.359970
[epoch13, step234]: loss 2.343253
[epoch13, step235]: loss 2.707713
[epoch13, step236]: loss 2.241054
[epoch13, step237]: loss 16.667969
[epoch13, step238]: loss 23.624250
[epoch13, step239]: loss 3.567364
[epoch13, step240]: loss 0.840659
[epoch13, step241]: loss 1.930778
[epoch13, step242]: loss 0.623460
[epoch13, step243]: loss 2.045309
[epoch13, step244]: loss 1.860990
[epoch13, step245]: loss 1.483153
[epoch13, step246]: loss 3.072868
[epoch13, step247]: loss 0.645293
[epoch13, step248]: loss 0.784377
[epoch13, step249]: loss 0.929305
[epoch13, step250]: loss 3.741791
[epoch13, step251]: loss 3.491395
[epoch13, step252]: loss 0.872525
[epoch13, step253]: loss 1.418799
[epoch13, step254]: loss 0.705357
[epoch13, step255]: loss 2.349377
[epoch13, step256]: loss 0.613713
[epoch13, step257]: loss 10.196509
[epoch13, step258]: loss 12.614971
[epoch13, step259]: loss 1.154473
[epoch13, step260]: loss 8.458532
[epoch13, step261]: loss 1.603524
[epoch13, step262]: loss 1.604379
[epoch13, step263]: loss 42.958462
[epoch13, step264]: loss 0.729061
[epoch13, step265]: loss 2.561510
[epoch13, step266]: loss 3.421443
[epoch13, step267]: loss 4.726764
[epoch13, step268]: loss 1.505459
[epoch13, step269]: loss 10.254295
[epoch13, step270]: loss 0.649050
[epoch13, step271]: loss 5.447260
[epoch13, step272]: loss 1.325081
[epoch13, step273]: loss 2.802408
[epoch13, step274]: loss 2.205377
[epoch13, step275]: loss 2.423973
[epoch13, step276]: loss 1.004868
[epoch13, step277]: loss 1.592995
[epoch13, step278]: loss 0.867495
[epoch13, step279]: loss 13.675048
[epoch13, step280]: loss 0.913564
[epoch13, step281]: loss 0.797209
[epoch13, step282]: loss 17.297194
[epoch13, step283]: loss 0.925794
[epoch13, step284]: loss 1.301358
[epoch13, step285]: loss 10.453189
[epoch13, step286]: loss 2.216287
[epoch13, step287]: loss 1.655501
[epoch13, step288]: loss 1.249981
[epoch13, step289]: loss 2.959075
[epoch13, step290]: loss 7.399129
[epoch13, step291]: loss 4.136816
[epoch13, step292]: loss 21.046856
[epoch13, step293]: loss 0.960328
[epoch13, step294]: loss 10.099365
[epoch13, step295]: loss 3.916881
[epoch13, step296]: loss 11.015464
[epoch13, step297]: loss 1.144837
[epoch13, step298]: loss 0.889009
[epoch13, step299]: loss 10.275395
[epoch13, step300]: loss 30.272058
[epoch13, step301]: loss 1.880393
[epoch13, step302]: loss 12.171480
[epoch13, step303]: loss 1.266580
[epoch13, step304]: loss 1.395246
[epoch13, step305]: loss 22.771767
[epoch13, step306]: loss 4.430343
[epoch13, step307]: loss 9.028913
[epoch13, step308]: loss 1.534310
[epoch13, step309]: loss 9.152996
[epoch13, step310]: loss 1.549374
[epoch13, step311]: loss 1.648564
[epoch13, step312]: loss 3.685777
[epoch13, step313]: loss 1.856322
[epoch13, step314]: loss 2.676480
[epoch13, step315]: loss 2.379712
[epoch13, step316]: loss 2.737123
[epoch13, step317]: loss 18.501291
[epoch13, step318]: loss 5.393440
[epoch13, step319]: loss 2.105161
[epoch13, step320]: loss 2.617550
[epoch13, step321]: loss 1.940944
[epoch13, step322]: loss 5.146106
[epoch13, step323]: loss 2.672981
[epoch13, step324]: loss 10.771439
[epoch13, step325]: loss 8.873716
[epoch13, step326]: loss 1.501706
[epoch13, step327]: loss 1.028101
[epoch13, step328]: loss 2.174105
[epoch13, step329]: loss 0.813850
[epoch13, step330]: loss 0.803373
[epoch13, step331]: loss 19.318748
[epoch13, step332]: loss 18.788794
[epoch13, step333]: loss 1.551301
[epoch13, step334]: loss 0.640517
[epoch13, step335]: loss 7.727291
[epoch13, step336]: loss 18.752272
[epoch13, step337]: loss 9.318113
[epoch13, step338]: loss 12.735643
[epoch13, step339]: loss 4.394637
[epoch13, step340]: loss 1.486196
[epoch13, step341]: loss 2.501718
[epoch13, step342]: loss 2.768090
[epoch13, step343]: loss 1.082414
[epoch13, step344]: loss 2.547050
[epoch13, step345]: loss 10.692136
[epoch13, step346]: loss 2.327549
[epoch13, step347]: loss 1.073344
[epoch13, step348]: loss 3.353103
[epoch13, step349]: loss 9.842998
[epoch13, step350]: loss 3.965278
[epoch13, step351]: loss 1.718698
[epoch13, step352]: loss 1.590309
[epoch13, step353]: loss 12.919355
[epoch13, step354]: loss 13.243114
[epoch13, step355]: loss 1.750029
[epoch13, step356]: loss 3.388482
[epoch13, step357]: loss 1.357323
[epoch13, step358]: loss 1.735510
[epoch13, step359]: loss 3.661986
[epoch13, step360]: loss 1.293764
[epoch13, step361]: loss 1.575380
[epoch13, step362]: loss 9.566665
[epoch13, step363]: loss 0.894574
[epoch13, step364]: loss 2.394720
[epoch13, step365]: loss 3.811176
[epoch13, step366]: loss 1.464125
[epoch13, step367]: loss 3.656706
[epoch13, step368]: loss 1.543133
[epoch13, step369]: loss 1.214091
[epoch13, step370]: loss 0.822334
[epoch13, step371]: loss 2.170239
[epoch13, step372]: loss 6.192693
[epoch13, step373]: loss 3.602748
[epoch13, step374]: loss 3.147648
[epoch13, step375]: loss 6.313537
[epoch13, step376]: loss 1.345649
[epoch13, step377]: loss 2.112569
[epoch13, step378]: loss 10.539305
[epoch13, step379]: loss 8.820572
[epoch13, step380]: loss 0.660176
[epoch13, step381]: loss 4.352000
[epoch13, step382]: loss 1.943655
[epoch13, step383]: loss 0.822416
[epoch13, step384]: loss 2.146337
[epoch13, step385]: loss 28.393871
[epoch13, step386]: loss 1.092989
[epoch13, step387]: loss 2.447400
[epoch13, step388]: loss 3.142203
[epoch13, step389]: loss 0.911186
[epoch13, step390]: loss 0.844416
[epoch13, step391]: loss 0.761766
[epoch13, step392]: loss 7.763900
[epoch13, step393]: loss 1.568091
[epoch13, step394]: loss 5.111490
[epoch13, step395]: loss 1.286912
[epoch13, step396]: loss 1.841238
[epoch13, step397]: loss 1.121127
[epoch13, step398]: loss 1.453914
[epoch13, step399]: loss 5.091611
[epoch13, step400]: loss 1.598315
[epoch13, step401]: loss 1.195883
[epoch13, step402]: loss 3.139961
[epoch13, step403]: loss 2.483934
[epoch13, step404]: loss 6.243237
[epoch13, step405]: loss 15.220847
[epoch13, step406]: loss 1.206556
[epoch13, step407]: loss 1.185551
[epoch13, step408]: loss 0.575942
[epoch13, step409]: loss 1.717383
[epoch13, step410]: loss 5.696146
[epoch13, step411]: loss 1.553496
[epoch13, step412]: loss 1.002054
[epoch13, step413]: loss 0.928281
[epoch13, step414]: loss 4.619708
[epoch13, step415]: loss 14.917437
[epoch13, step416]: loss 1.138278
[epoch13, step417]: loss 1.046922
[epoch13, step418]: loss 0.944467
[epoch13, step419]: loss 6.153499
[epoch13, step420]: loss 2.435131
[epoch13, step421]: loss 1.229910
[epoch13, step422]: loss 8.586143
[epoch13, step423]: loss 13.218341
[epoch13, step424]: loss 3.380059
[epoch13, step425]: loss 0.713907
[epoch13, step426]: loss 0.773806
[epoch13, step427]: loss 0.773168
[epoch13, step428]: loss 1.827069
[epoch13, step429]: loss 2.563401
[epoch13, step430]: loss 12.849664
[epoch13, step431]: loss 0.761070
[epoch13, step432]: loss 1.239583
[epoch13, step433]: loss 1.084434
[epoch13, step434]: loss 13.172058
[epoch13, step435]: loss 2.963351
[epoch13, step436]: loss 0.739136
[epoch13, step437]: loss 3.626275
[epoch13, step438]: loss 7.498359
[epoch13, step439]: loss 1.554438
[epoch13, step440]: loss 5.651694
[epoch13, step441]: loss 3.006815
[epoch13, step442]: loss 1.023075
[epoch13, step443]: loss 7.919359
[epoch13, step444]: loss 3.651988
[epoch13, step445]: loss 1.476323
[epoch13, step446]: loss 0.706831
[epoch13, step447]: loss 1.131336
[epoch13, step448]: loss 1.882302
[epoch13, step449]: loss 9.015602
[epoch13, step450]: loss 0.789354
[epoch13, step451]: loss 1.316272
[epoch13, step452]: loss 2.092696
[epoch13, step453]: loss 1.691780
[epoch13, step454]: loss 1.607222
[epoch13, step455]: loss 1.789584
[epoch13, step456]: loss 1.963959
[epoch13, step457]: loss 5.458286
[epoch13, step458]: loss 3.416914
[epoch13, step459]: loss 2.979498
[epoch13, step460]: loss 1.838250
[epoch13, step461]: loss 1.081990
[epoch13, step462]: loss 3.442857
[epoch13, step463]: loss 16.892710
[epoch13, step464]: loss 0.968252
[epoch13, step465]: loss 20.394440
[epoch13, step466]: loss 2.564979
[epoch13, step467]: loss 2.268808
[epoch13, step468]: loss 5.151972
[epoch13, step469]: loss 3.075218
[epoch13, step470]: loss 1.881196
[epoch13, step471]: loss 2.938885
[epoch13, step472]: loss 1.422708
[epoch13, step473]: loss 14.134302
[epoch13, step474]: loss 1.185022
[epoch13, step475]: loss 18.698936
[epoch13, step476]: loss 0.733887
[epoch13, step477]: loss 1.374410
[epoch13, step478]: loss 15.612303
[epoch13, step479]: loss 1.267529
[epoch13, step480]: loss 0.827009
[epoch13, step481]: loss 2.282444
[epoch13, step482]: loss 1.213655
[epoch13, step483]: loss 15.174776
[epoch13, step484]: loss 14.353726
[epoch13, step485]: loss 5.010277
[epoch13, step486]: loss 5.710271
[epoch13, step487]: loss 37.703911
[epoch13, step488]: loss 2.416003
[epoch13, step489]: loss 1.386256
[epoch13, step490]: loss 8.955709
[epoch13, step491]: loss 3.425068
[epoch13, step492]: loss 3.534847
[epoch13, step493]: loss 18.287043
[epoch13, step494]: loss 16.744078
[epoch13, step495]: loss 3.845355
[epoch13, step496]: loss 3.607465
[epoch13, step497]: loss 1.785602
[epoch13, step498]: loss 1.600302
[epoch13, step499]: loss 1.175785
[epoch13, step500]: loss 0.621043
[epoch13, step501]: loss 2.577248
[epoch13, step502]: loss 2.189616
[epoch13, step503]: loss 9.460366
[epoch13, step504]: loss 5.536039
[epoch13, step505]: loss 1.917138
[epoch13, step506]: loss 1.731680
[epoch13, step507]: loss 1.799178
[epoch13, step508]: loss 0.972088
[epoch13, step509]: loss 0.981925
[epoch13, step510]: loss 5.358578
[epoch13, step511]: loss 1.718981
[epoch13, step512]: loss 2.500504
[epoch13, step513]: loss 2.551126
[epoch13, step514]: loss 12.763521
[epoch13, step515]: loss 0.743155
[epoch13, step516]: loss 6.137491
[epoch13, step517]: loss 1.225548
[epoch13, step518]: loss 1.572797
[epoch13, step519]: loss 0.699161
[epoch13, step520]: loss 1.436364
[epoch13, step521]: loss 3.145522
[epoch13, step522]: loss 1.172577
[epoch13, step523]: loss 0.889511
[epoch13, step524]: loss 1.096065
[epoch13, step525]: loss 2.521688
[epoch13, step526]: loss 1.333930
[epoch13, step527]: loss 0.859669
[epoch13, step528]: loss 16.945219
[epoch13, step529]: loss 9.965683
[epoch13, step530]: loss 1.325106
[epoch13, step531]: loss 0.657560
[epoch13, step532]: loss 1.635538
[epoch13, step533]: loss 3.409844
[epoch13, step534]: loss 1.701797
[epoch13, step535]: loss 0.833630
[epoch13, step536]: loss 1.127559
[epoch13, step537]: loss 4.500344
[epoch13, step538]: loss 11.063829
[epoch13, step539]: loss 1.370967
[epoch13, step540]: loss 0.690191
[epoch13, step541]: loss 5.259689
[epoch13, step542]: loss 2.098278
[epoch13, step543]: loss 10.900296
[epoch13, step544]: loss 2.839988
[epoch13, step545]: loss 1.009290
[epoch13, step546]: loss 10.266459
[epoch13, step547]: loss 13.153897
[epoch13, step548]: loss 9.599886
[epoch13, step549]: loss 1.113033
[epoch13, step550]: loss 9.184180
[epoch13, step551]: loss 1.411856
[epoch13, step552]: loss 0.847667
[epoch13, step553]: loss 3.144592
[epoch13, step554]: loss 1.078380
[epoch13, step555]: loss 3.906604
[epoch13, step556]: loss 1.478796
[epoch13, step557]: loss 1.511672
[epoch13, step558]: loss 2.258492
[epoch13, step559]: loss 8.758069
[epoch13, step560]: loss 1.139537
[epoch13, step561]: loss 1.080812
[epoch13, step562]: loss 1.776672
[epoch13, step563]: loss 2.004206
[epoch13, step564]: loss 11.193379
[epoch13, step565]: loss 0.892629
[epoch13, step566]: loss 10.292937
[epoch13, step567]: loss 13.173306
[epoch13, step568]: loss 32.649632
[epoch13, step569]: loss 2.456342
[epoch13, step570]: loss 10.905324
[epoch13, step571]: loss 4.036869
[epoch13, step572]: loss 2.451361
[epoch13, step573]: loss 8.438869
[epoch13, step574]: loss 1.076389
[epoch13, step575]: loss 1.393451
[epoch13, step576]: loss 1.210444
[epoch13, step577]: loss 11.654684
[epoch13, step578]: loss 1.324013
[epoch13, step579]: loss 17.358889
[epoch13, step580]: loss 8.434522
[epoch13, step581]: loss 1.334407
[epoch13, step582]: loss 22.552725
[epoch13, step583]: loss 1.628354
[epoch13, step584]: loss 28.469536
[epoch13, step585]: loss 6.627001
[epoch13, step586]: loss 1.127064
[epoch13, step587]: loss 1.399261
[epoch13, step588]: loss 1.577094
[epoch13, step589]: loss 1.599401
[epoch13, step590]: loss 6.541319
[epoch13, step591]: loss 14.252801
[epoch13, step592]: loss 14.156721
[epoch13, step593]: loss 2.737596
[epoch13, step594]: loss 1.515180
[epoch13, step595]: loss 5.954643
[epoch13, step596]: loss 11.435321
[epoch13, step597]: loss 1.590689
[epoch13, step598]: loss 6.960776
[epoch13, step599]: loss 1.688844
[epoch13, step600]: loss 9.275823
[epoch13, step601]: loss 9.054511
[epoch13, step602]: loss 10.186404
[epoch13, step603]: loss 11.584488
[epoch13, step604]: loss 14.773695
[epoch13, step605]: loss 1.631179
[epoch13, step606]: loss 1.637641
[epoch13, step607]: loss 3.071583
[epoch13, step608]: loss 3.072934
[epoch13, step609]: loss 2.522352
[epoch13, step610]: loss 14.511859
[epoch13, step611]: loss 1.214255
[epoch13, step612]: loss 1.155847
[epoch13, step613]: loss 4.859418
[epoch13, step614]: loss 1.772344
[epoch13, step615]: loss 1.568156
[epoch13, step616]: loss 12.894786
[epoch13, step617]: loss 1.377890
[epoch13, step618]: loss 1.476717
[epoch13, step619]: loss 1.815088
[epoch13, step620]: loss 1.152894
[epoch13, step621]: loss 0.974112
[epoch13, step622]: loss 15.591504
[epoch13, step623]: loss 0.767133
[epoch13, step624]: loss 5.384956
[epoch13, step625]: loss 12.516816
[epoch13, step626]: loss 2.379060
[epoch13, step627]: loss 1.260989
[epoch13, step628]: loss 2.106193
[epoch13, step629]: loss 2.076753
[epoch13, step630]: loss 9.371828
[epoch13, step631]: loss 54.231384
[epoch13, step632]: loss 24.466911
[epoch13, step633]: loss 0.996316
[epoch13, step634]: loss 1.125556
[epoch13, step635]: loss 12.377491
[epoch13, step636]: loss 6.997609
[epoch13, step637]: loss 13.011138
[epoch13, step638]: loss 0.803880
[epoch13, step639]: loss 1.624423
[epoch13, step640]: loss 7.751571
[epoch13, step641]: loss 3.804716
[epoch13, step642]: loss 1.710476
[epoch13, step643]: loss 2.202796
[epoch13, step644]: loss 2.354930
[epoch13, step645]: loss 1.434159
[epoch13, step646]: loss 3.368289
[epoch13, step647]: loss 2.539860
[epoch13, step648]: loss 1.792609
[epoch13, step649]: loss 0.791251
[epoch13, step650]: loss 13.476421
[epoch13, step651]: loss 1.856262
[epoch13, step652]: loss 2.112837
[epoch13, step653]: loss 2.682944
[epoch13, step654]: loss 1.256475
[epoch13, step655]: loss 2.097371
[epoch13, step656]: loss 5.787253
[epoch13, step657]: loss 9.056553
[epoch13, step658]: loss 2.362342
[epoch13, step659]: loss 14.340529
[epoch13, step660]: loss 1.223360
[epoch13, step661]: loss 1.017783
[epoch13, step662]: loss 1.212009
[epoch13, step663]: loss 8.225616
[epoch13, step664]: loss 1.229468
[epoch13, step665]: loss 5.182803
[epoch13, step666]: loss 3.840162
[epoch13, step667]: loss 1.515009
[epoch13, step668]: loss 9.720261
[epoch13, step669]: loss 2.059890
[epoch13, step670]: loss 18.106129
[epoch13, step671]: loss 1.397639
[epoch13, step672]: loss 1.180628
[epoch13, step673]: loss 2.375786
[epoch13, step674]: loss 1.226155
[epoch13, step675]: loss 3.109289
[epoch13, step676]: loss 2.561923
[epoch13, step677]: loss 5.475200
[epoch13, step678]: loss 2.053699
[epoch13, step679]: loss 10.855799
[epoch13, step680]: loss 1.111226
[epoch13, step681]: loss 4.174528
[epoch13, step682]: loss 19.329615
[epoch13, step683]: loss 0.780294
[epoch13, step684]: loss 1.086678
[epoch13, step685]: loss 3.739689
[epoch13, step686]: loss 12.560047
[epoch13, step687]: loss 9.296379
[epoch13, step688]: loss 11.239225
[epoch13, step689]: loss 1.599943
[epoch13, step690]: loss 9.355730
[epoch13, step691]: loss 1.542884
[epoch13, step692]: loss 4.689280
[epoch13, step693]: loss 2.816808
[epoch13, step694]: loss 11.779156
[epoch13, step695]: loss 16.141356
[epoch13, step696]: loss 11.904189
[epoch13, step697]: loss 3.048457
[epoch13, step698]: loss 14.540923
[epoch13, step699]: loss 5.770165
[epoch13, step700]: loss 1.748605
[epoch13, step701]: loss 1.472918
[epoch13, step702]: loss 1.222259
[epoch13, step703]: loss 2.649325
[epoch13, step704]: loss 12.460376
[epoch13, step705]: loss 1.701575
[epoch13, step706]: loss 0.912645
[epoch13, step707]: loss 7.954001
[epoch13, step708]: loss 3.073661
[epoch13, step709]: loss 1.802944
[epoch13, step710]: loss 8.202583
[epoch13, step711]: loss 3.504587
[epoch13, step712]: loss 16.079285
[epoch13, step713]: loss 2.249136
[epoch13, step714]: loss 0.913136
[epoch13, step715]: loss 2.498982
[epoch13, step716]: loss 3.605614
[epoch13, step717]: loss 1.317409
[epoch13, step718]: loss 2.640933
[epoch13, step719]: loss 0.780131
[epoch13, step720]: loss 5.590684
[epoch13, step721]: loss 3.042747
[epoch13, step722]: loss 1.199668
[epoch13, step723]: loss 1.848105
[epoch13, step724]: loss 8.628177
[epoch13, step725]: loss 6.361409
[epoch13, step726]: loss 1.546638
[epoch13, step727]: loss 1.439031
[epoch13, step728]: loss 0.878942
[epoch13, step729]: loss 0.872775
[epoch13, step730]: loss 1.045476
[epoch13, step731]: loss 4.020008
[epoch13, step732]: loss 9.035178
[epoch13, step733]: loss 1.019719
[epoch13, step734]: loss 18.431898
[epoch13, step735]: loss 1.721542
[epoch13, step736]: loss 14.708421
[epoch13, step737]: loss 1.667470
[epoch13, step738]: loss 3.381076
[epoch13, step739]: loss 17.628218
[epoch13, step740]: loss 3.829375
[epoch13, step741]: loss 13.216970
[epoch13, step742]: loss 3.564596
[epoch13, step743]: loss 1.526222
[epoch13, step744]: loss 11.291694
[epoch13, step745]: loss 1.395672
[epoch13, step746]: loss 2.186128
[epoch13, step747]: loss 2.071737
[epoch13, step748]: loss 18.397200
[epoch13, step749]: loss 16.411730
[epoch13, step750]: loss 1.208611
[epoch13, step751]: loss 1.008696
[epoch13, step752]: loss 2.665044
[epoch13, step753]: loss 12.554664
[epoch13, step754]: loss 6.801071
[epoch13, step755]: loss 19.258083
[epoch13, step756]: loss 12.492845
[epoch13, step757]: loss 5.416521
[epoch13, step758]: loss 1.245079
[epoch13, step759]: loss 2.414847
[epoch13, step760]: loss 0.647801
[epoch13, step761]: loss 5.113361
[epoch13, step762]: loss 1.682607
[epoch13, step763]: loss 1.112810
[epoch13, step764]: loss 26.223452
[epoch13, step765]: loss 8.786412
[epoch13, step766]: loss 1.336345
[epoch13, step767]: loss 42.474884
[epoch13, step768]: loss 12.138950
[epoch13, step769]: loss 0.960481
[epoch13, step770]: loss 1.698300
[epoch13, step771]: loss 1.138729
[epoch13, step772]: loss 1.222033
[epoch13, step773]: loss 1.189541
[epoch13, step774]: loss 9.907078
[epoch13, step775]: loss 1.971123
[epoch13, step776]: loss 1.158477
[epoch13, step777]: loss 2.736268
[epoch13, step778]: loss 1.393886
[epoch13, step779]: loss 1.203853
[epoch13, step780]: loss 2.113270
[epoch13, step781]: loss 10.194860
[epoch13, step782]: loss 11.280149
[epoch13, step783]: loss 1.686400
[epoch13, step784]: loss 0.645860
[epoch13, step785]: loss 1.710861
[epoch13, step786]: loss 1.234624
[epoch13, step787]: loss 25.820639
[epoch13, step788]: loss 1.017832
[epoch13, step789]: loss 0.469753
[epoch13, step790]: loss 2.173494
[epoch13, step791]: loss 1.531169
[epoch13, step792]: loss 26.887297
[epoch13, step793]: loss 1.544746
[epoch13, step794]: loss 3.277535
[epoch13, step795]: loss 1.112227
[epoch13, step796]: loss 34.809540
[epoch13, step797]: loss 1.269412
[epoch13, step798]: loss 1.731685
[epoch13, step799]: loss 1.675888
[epoch13, step800]: loss 13.351878
[epoch13, step801]: loss 2.753505
[epoch13, step802]: loss 3.588619
[epoch13, step803]: loss 11.091757
[epoch13, step804]: loss 30.135418
[epoch13, step805]: loss 3.693930
[epoch13, step806]: loss 2.669517
[epoch13, step807]: loss 0.900919
[epoch13, step808]: loss 0.676350
[epoch13, step809]: loss 13.439602
[epoch13, step810]: loss 1.273099
[epoch13, step811]: loss 10.394891
[epoch13, step812]: loss 29.208302
[epoch13, step813]: loss 1.447373
[epoch13, step814]: loss 2.203407
[epoch13, step815]: loss 2.587663
[epoch13, step816]: loss 13.131854
[epoch13, step817]: loss 1.713465
[epoch13, step818]: loss 1.096772
[epoch13, step819]: loss 1.231803
[epoch13, step820]: loss 1.324911
[epoch13, step821]: loss 9.522708
[epoch13, step822]: loss 2.561215
[epoch13, step823]: loss 2.442573
[epoch13, step824]: loss 1.361927
[epoch13, step825]: loss 25.740688
[epoch13, step826]: loss 1.044749
[epoch13, step827]: loss 11.027220
[epoch13, step828]: loss 2.782571
[epoch13, step829]: loss 3.582829
[epoch13, step830]: loss 1.415801
[epoch13, step831]: loss 2.523280
[epoch13, step832]: loss 1.197434
[epoch13, step833]: loss 3.002338
[epoch13, step834]: loss 0.679000
[epoch13, step835]: loss 5.954371
[epoch13, step836]: loss 7.544477
[epoch13, step837]: loss 1.324389
[epoch13, step838]: loss 2.264520
[epoch13, step839]: loss 1.261748
[epoch13, step840]: loss 1.412909
[epoch13, step841]: loss 3.268613
[epoch13, step842]: loss 1.698956
[epoch13, step843]: loss 1.684018
[epoch13, step844]: loss 1.173021
[epoch13, step845]: loss 4.755772
[epoch13, step846]: loss 2.609236
[epoch13, step847]: loss 1.876577
[epoch13, step848]: loss 1.114783
[epoch13, step849]: loss 1.412923
[epoch13, step850]: loss 11.747877
[epoch13, step851]: loss 3.266655
[epoch13, step852]: loss 0.684486
[epoch13, step853]: loss 3.701049
[epoch13, step854]: loss 1.682597
[epoch13, step855]: loss 28.716900
[epoch13, step856]: loss 8.562110
[epoch13, step857]: loss 1.057212
[epoch13, step858]: loss 1.169631
[epoch13, step859]: loss 1.097461
[epoch13, step860]: loss 5.399889
[epoch13, step861]: loss 2.308672
[epoch13, step862]: loss 1.921831
[epoch13, step863]: loss 1.443213
[epoch13, step864]: loss 6.291132
[epoch13, step865]: loss 3.204019
[epoch13, step866]: loss 1.285969
[epoch13, step867]: loss 17.086399
[epoch13, step868]: loss 0.962823
[epoch13, step869]: loss 1.604829
[epoch13, step870]: loss 1.063951
[epoch13, step871]: loss 2.220343
[epoch13, step872]: loss 4.699029
[epoch13, step873]: loss 1.191438
[epoch13, step874]: loss 1.338260
[epoch13, step875]: loss 11.457390
[epoch13, step876]: loss 1.444048
[epoch13, step877]: loss 1.622067
[epoch13, step878]: loss 7.522250
[epoch13, step879]: loss 10.702536
[epoch13, step880]: loss 0.902587
[epoch13, step881]: loss 1.320120
[epoch13, step882]: loss 8.788745
[epoch13, step883]: loss 2.598175
[epoch13, step884]: loss 15.194538
[epoch13, step885]: loss 4.574084
[epoch13, step886]: loss 19.650402
[epoch13, step887]: loss 4.947809
[epoch13, step888]: loss 3.009052
[epoch13, step889]: loss 1.064969
[epoch13, step890]: loss 4.397277
[epoch13, step891]: loss 7.323051
[epoch13, step892]: loss 2.439933
[epoch13, step893]: loss 0.959814
[epoch13, step894]: loss 0.640519
[epoch13, step895]: loss 14.367108
[epoch13, step896]: loss 1.098504
[epoch13, step897]: loss 13.529711
[epoch13, step898]: loss 1.053208
[epoch13, step899]: loss 12.388499
[epoch13, step900]: loss 0.930499
[epoch13, step901]: loss 9.652405
[epoch13, step902]: loss 11.279575
[epoch13, step903]: loss 6.047693
[epoch13, step904]: loss 2.181509
[epoch13, step905]: loss 5.456583
[epoch13, step906]: loss 1.598195
[epoch13, step907]: loss 3.316134
[epoch13, step908]: loss 10.859395
[epoch13, step909]: loss 1.810176
[epoch13, step910]: loss 6.647888
[epoch13, step911]: loss 2.770653
[epoch13, step912]: loss 1.313911
[epoch13, step913]: loss 0.886081
[epoch13, step914]: loss 2.921861
[epoch13, step915]: loss 2.016800
[epoch13, step916]: loss 10.233953
[epoch13, step917]: loss 16.114838
[epoch13, step918]: loss 5.506598
[epoch13, step919]: loss 8.668784
[epoch13, step920]: loss 1.052091
[epoch13, step921]: loss 1.767288
[epoch13, step922]: loss 6.973841
[epoch13, step923]: loss 0.976063
[epoch13, step924]: loss 2.301812
[epoch13, step925]: loss 2.682992
[epoch13, step926]: loss 26.264143
[epoch13, step927]: loss 0.739465
[epoch13, step928]: loss 12.470091
[epoch13, step929]: loss 0.926751
[epoch13, step930]: loss 1.132777
[epoch13, step931]: loss 0.894710
[epoch13, step932]: loss 2.962430
[epoch13, step933]: loss 3.604684
[epoch13, step934]: loss 2.846052
[epoch13, step935]: loss 12.182425
[epoch13, step936]: loss 1.559447
[epoch13, step937]: loss 1.114582
[epoch13, step938]: loss 1.242529
[epoch13, step939]: loss 3.774726
[epoch13, step940]: loss 13.161329
[epoch13, step941]: loss 14.261978
[epoch13, step942]: loss 2.370745
[epoch13, step943]: loss 1.048172
[epoch13, step944]: loss 6.166093
[epoch13, step945]: loss 14.898811
[epoch13, step946]: loss 1.287990
[epoch13, step947]: loss 1.628725
[epoch13, step948]: loss 1.002389
[epoch13, step949]: loss 1.553206
[epoch13, step950]: loss 2.385975
[epoch13, step951]: loss 16.279091
[epoch13, step952]: loss 4.106531
[epoch13, step953]: loss 1.245627
[epoch13, step954]: loss 0.933824
[epoch13, step955]: loss 12.621979
[epoch13, step956]: loss 2.522869
[epoch13, step957]: loss 1.002120
[epoch13, step958]: loss 1.761884
[epoch13, step959]: loss 1.127536
[epoch13, step960]: loss 1.299320
[epoch13, step961]: loss 21.138956
[epoch13, step962]: loss 1.029891
[epoch13, step963]: loss 23.788998
[epoch13, step964]: loss 11.897967
[epoch13, step965]: loss 1.033636
[epoch13, step966]: loss 2.065273
[epoch13, step967]: loss 12.297264
[epoch13, step968]: loss 2.662372
[epoch13, step969]: loss 1.788327
[epoch13, step970]: loss 3.090111
[epoch13, step971]: loss 1.434666
[epoch13, step972]: loss 10.053389
[epoch13, step973]: loss 4.314349
[epoch13, step974]: loss 3.773588
[epoch13, step975]: loss 8.112829
[epoch13, step976]: loss 1.610952
[epoch13, step977]: loss 1.467114
[epoch13, step978]: loss 1.040473
[epoch13, step979]: loss 8.660924
[epoch13, step980]: loss 2.662580
[epoch13, step981]: loss 0.879345
[epoch13, step982]: loss 0.998747
[epoch13, step983]: loss 8.705611
[epoch13, step984]: loss 10.724916
[epoch13, step985]: loss 1.135452
[epoch13, step986]: loss 3.163337
[epoch13, step987]: loss 0.895377
[epoch13, step988]: loss 2.060617
[epoch13, step989]: loss 2.629266
[epoch13, step990]: loss 2.183155
[epoch13, step991]: loss 1.302820
[epoch13, step992]: loss 1.068545
[epoch13, step993]: loss 2.727486
[epoch13, step994]: loss 3.288902
[epoch13, step995]: loss 0.677909
[epoch13, step996]: loss 0.709136
[epoch13, step997]: loss 2.841271
[epoch13, step998]: loss 0.881225
[epoch13, step999]: loss 2.741494
[epoch13, step1000]: loss 1.257854
[epoch13, step1001]: loss 0.948234
[epoch13, step1002]: loss 4.198548
[epoch13, step1003]: loss 1.673115
[epoch13, step1004]: loss 14.576159
[epoch13, step1005]: loss 1.244942
[epoch13, step1006]: loss 1.010405
[epoch13, step1007]: loss 7.232278
[epoch13, step1008]: loss 1.969613
[epoch13, step1009]: loss 1.136212
[epoch13, step1010]: loss 10.353575
[epoch13, step1011]: loss 2.329342
[epoch13, step1012]: loss 1.078363
[epoch13, step1013]: loss 15.458352
[epoch13, step1014]: loss 2.202463
[epoch13, step1015]: loss 3.251632
[epoch13, step1016]: loss 2.602759
[epoch13, step1017]: loss 4.510277
[epoch13, step1018]: loss 9.937404
[epoch13, step1019]: loss 6.180160
[epoch13, step1020]: loss 11.648505
[epoch13, step1021]: loss 1.310392
[epoch13, step1022]: loss 14.004722
[epoch13, step1023]: loss 8.829456
[epoch13, step1024]: loss 11.478476
[epoch13, step1025]: loss 3.123894
[epoch13, step1026]: loss 1.904865
[epoch13, step1027]: loss 1.642783
[epoch13, step1028]: loss 10.832703
[epoch13, step1029]: loss 3.095065
[epoch13, step1030]: loss 3.244953
[epoch13, step1031]: loss 8.949491
[epoch13, step1032]: loss 1.755630
[epoch13, step1033]: loss 0.878680
[epoch13, step1034]: loss 9.094638
[epoch13, step1035]: loss 0.953235
[epoch13, step1036]: loss 1.034656
[epoch13, step1037]: loss 1.346689
[epoch13, step1038]: loss 1.355350
[epoch13, step1039]: loss 0.632929
[epoch13, step1040]: loss 1.371746
[epoch13, step1041]: loss 3.190505
[epoch13, step1042]: loss 0.940568
[epoch13, step1043]: loss 3.780347
[epoch13, step1044]: loss 1.279654
[epoch13, step1045]: loss 11.050024
[epoch13, step1046]: loss 1.152326
[epoch13, step1047]: loss 1.614695
[epoch13, step1048]: loss 29.517487
[epoch13, step1049]: loss 16.385536
[epoch13, step1050]: loss 1.169084
[epoch13, step1051]: loss 0.984258
[epoch13, step1052]: loss 12.829806
[epoch13, step1053]: loss 1.025303
[epoch13, step1054]: loss 2.545808
[epoch13, step1055]: loss 1.693112
[epoch13, step1056]: loss 18.451508
[epoch13, step1057]: loss 1.896924
[epoch13, step1058]: loss 0.960106
[epoch13, step1059]: loss 1.149670
[epoch13, step1060]: loss 1.743662
[epoch13, step1061]: loss 1.217503
[epoch13, step1062]: loss 10.657522
[epoch13, step1063]: loss 12.278985
[epoch13, step1064]: loss 12.636478
[epoch13, step1065]: loss 1.478306
[epoch13, step1066]: loss 4.286542
[epoch13, step1067]: loss 23.842964
[epoch13, step1068]: loss 2.656383
[epoch13, step1069]: loss 2.353383
[epoch13, step1070]: loss 1.374546
[epoch13, step1071]: loss 10.264503
[epoch13, step1072]: loss 0.716594
[epoch13, step1073]: loss 5.611700
[epoch13, step1074]: loss 1.167482
[epoch13, step1075]: loss 8.988963
[epoch13, step1076]: loss 1.457878
[epoch13, step1077]: loss 8.547719
[epoch13, step1078]: loss 18.640814
[epoch13, step1079]: loss 23.759468
[epoch13, step1080]: loss 19.065901
[epoch13, step1081]: loss 1.257776
[epoch13, step1082]: loss 1.963834
[epoch13, step1083]: loss 15.051368
[epoch13, step1084]: loss 1.153624
[epoch13, step1085]: loss 2.204356
[epoch13, step1086]: loss 1.762542
[epoch13, step1087]: loss 0.800023
[epoch13, step1088]: loss 1.613083
[epoch13, step1089]: loss 3.140210
[epoch13, step1090]: loss 6.410864
[epoch13, step1091]: loss 2.387648
[epoch13, step1092]: loss 8.429707
[epoch13, step1093]: loss 8.786074
[epoch13, step1094]: loss 0.785286
[epoch13, step1095]: loss 1.148662
[epoch13, step1096]: loss 0.835030
[epoch13, step1097]: loss 17.170824
[epoch13, step1098]: loss 1.094155
[epoch13, step1099]: loss 2.334934
[epoch13, step1100]: loss 17.233595
[epoch13, step1101]: loss 2.876878
[epoch13, step1102]: loss 10.465359
[epoch13, step1103]: loss 0.938122
[epoch13, step1104]: loss 3.041695
[epoch13, step1105]: loss 2.748618
[epoch13, step1106]: loss 14.009087
[epoch13, step1107]: loss 1.197927
[epoch13, step1108]: loss 25.057812
[epoch13, step1109]: loss 1.661003
[epoch13, step1110]: loss 12.768951
[epoch13, step1111]: loss 1.560134
[epoch13, step1112]: loss 11.022367
[epoch13, step1113]: loss 2.520420
[epoch13, step1114]: loss 1.056474
[epoch13, step1115]: loss 1.402288
[epoch13, step1116]: loss 8.976184
[epoch13, step1117]: loss 5.276794
[epoch13, step1118]: loss 0.631987
[epoch13, step1119]: loss 1.238000
[epoch13, step1120]: loss 21.933441
[epoch13, step1121]: loss 7.292305
[epoch13, step1122]: loss 13.345700
[epoch13, step1123]: loss 3.683399
[epoch13, step1124]: loss 8.508537
[epoch13, step1125]: loss 0.781854
[epoch13, step1126]: loss 19.420815
[epoch13, step1127]: loss 5.485289
[epoch13, step1128]: loss 3.045838
[epoch13, step1129]: loss 1.485739
[epoch13, step1130]: loss 15.130630
[epoch13, step1131]: loss 16.501339
[epoch13, step1132]: loss 3.208668
[epoch13, step1133]: loss 2.093495
[epoch13, step1134]: loss 4.473794
[epoch13, step1135]: loss 2.171763
[epoch13, step1136]: loss 1.572996
[epoch13, step1137]: loss 18.791090
[epoch13, step1138]: loss 0.670180
[epoch13, step1139]: loss 1.947993
[epoch13, step1140]: loss 4.422072
[epoch13, step1141]: loss 6.467666
[epoch13, step1142]: loss 1.110011
[epoch13, step1143]: loss 0.949274
[epoch13, step1144]: loss 1.053807
[epoch13, step1145]: loss 4.870315
[epoch13, step1146]: loss 1.255886
[epoch13, step1147]: loss 0.712930
[epoch13, step1148]: loss 2.426814
[epoch13, step1149]: loss 4.683742
[epoch13, step1150]: loss 3.355530
[epoch13, step1151]: loss 0.959401
[epoch13, step1152]: loss 2.816422
[epoch13, step1153]: loss 10.001556
[epoch13, step1154]: loss 1.248199
[epoch13, step1155]: loss 3.898535
[epoch13, step1156]: loss 2.489273
[epoch13, step1157]: loss 1.297888
[epoch13, step1158]: loss 3.118502
[epoch13, step1159]: loss 3.336426
[epoch13, step1160]: loss 5.150229
[epoch13, step1161]: loss 1.434744
[epoch13, step1162]: loss 10.504868
[epoch13, step1163]: loss 1.122036
[epoch13, step1164]: loss 1.297760
[epoch13, step1165]: loss 1.024796
[epoch13, step1166]: loss 2.117522
[epoch13, step1167]: loss 1.953790
[epoch13, step1168]: loss 2.839149
[epoch13, step1169]: loss 0.865362
[epoch13, step1170]: loss 1.272134
[epoch13, step1171]: loss 1.033348
[epoch13, step1172]: loss 9.506183
[epoch13, step1173]: loss 0.838767
[epoch13, step1174]: loss 18.643816
[epoch13, step1175]: loss 1.976679
[epoch13, step1176]: loss 0.685338
[epoch13, step1177]: loss 3.689323
[epoch13, step1178]: loss 3.623592
[epoch13, step1179]: loss 3.516727
[epoch13, step1180]: loss 2.380041
[epoch13, step1181]: loss 1.098581
[epoch13, step1182]: loss 1.593727
[epoch13, step1183]: loss 12.934855
[epoch13, step1184]: loss 0.812014
[epoch13, step1185]: loss 3.359552
[epoch13, step1186]: loss 8.933106
[epoch13, step1187]: loss 0.767490
[epoch13, step1188]: loss 1.458259
[epoch13, step1189]: loss 0.798396
[epoch13, step1190]: loss 23.464760
[epoch13, step1191]: loss 2.135063
[epoch13, step1192]: loss 10.761795
[epoch13, step1193]: loss 0.808779
[epoch13, step1194]: loss 1.142590
[epoch13, step1195]: loss 18.266918
[epoch13, step1196]: loss 15.591462
[epoch13, step1197]: loss 1.484662
[epoch13, step1198]: loss 11.983621
[epoch13, step1199]: loss 9.170396
[epoch13, step1200]: loss 2.053004
[epoch13, step1201]: loss 15.708614
[epoch13, step1202]: loss 2.333464
[epoch13, step1203]: loss 1.131857
[epoch13, step1204]: loss 1.618965
[epoch13, step1205]: loss 1.491369
[epoch13, step1206]: loss 1.432626
[epoch13, step1207]: loss 6.011234
[epoch13, step1208]: loss 1.437716
[epoch13, step1209]: loss 3.045688
[epoch13, step1210]: loss 1.112366
[epoch13, step1211]: loss 1.872954
[epoch13, step1212]: loss 2.330794
[epoch13, step1213]: loss 2.953737
[epoch13, step1214]: loss 1.698632
[epoch13, step1215]: loss 1.342063
[epoch13, step1216]: loss 0.832504
[epoch13, step1217]: loss 1.435127
[epoch13, step1218]: loss 6.000728
[epoch13, step1219]: loss 8.951373
[epoch13, step1220]: loss 2.051831
[epoch13, step1221]: loss 5.392770
[epoch13, step1222]: loss 1.313403
[epoch13, step1223]: loss 1.094788
[epoch13, step1224]: loss 1.439113
[epoch13, step1225]: loss 2.130543
[epoch13, step1226]: loss 2.515397
[epoch13, step1227]: loss 9.359870
[epoch13, step1228]: loss 0.982765
[epoch13, step1229]: loss 0.951914
[epoch13, step1230]: loss 3.620321
[epoch13, step1231]: loss 2.977889
[epoch13, step1232]: loss 1.347573
[epoch13, step1233]: loss 4.927854
[epoch13, step1234]: loss 1.241093
[epoch13, step1235]: loss 3.693349
[epoch13, step1236]: loss 1.262421
[epoch13, step1237]: loss 12.122953
[epoch13, step1238]: loss 0.904880
[epoch13, step1239]: loss 6.507915
[epoch13, step1240]: loss 1.125191
[epoch13, step1241]: loss 15.167014
[epoch13, step1242]: loss 8.395954
[epoch13, step1243]: loss 13.581987
[epoch13, step1244]: loss 1.283417
[epoch13, step1245]: loss 1.916072
[epoch13, step1246]: loss 3.196200
[epoch13, step1247]: loss 6.067427
[epoch13, step1248]: loss 1.516276
[epoch13, step1249]: loss 2.367024
[epoch13, step1250]: loss 6.736211
[epoch13, step1251]: loss 9.075313
[epoch13, step1252]: loss 2.184596
[epoch13, step1253]: loss 2.483744
[epoch13, step1254]: loss 13.791883
[epoch13, step1255]: loss 17.590425
[epoch13, step1256]: loss 11.117197
[epoch13, step1257]: loss 1.772969
[epoch13, step1258]: loss 4.555735
[epoch13, step1259]: loss 15.856844
[epoch13, step1260]: loss 3.216773
[epoch13, step1261]: loss 1.828879
[epoch13, step1262]: loss 2.631364
[epoch13, step1263]: loss 3.183560
[epoch13, step1264]: loss 1.264694
[epoch13, step1265]: loss 2.427728
[epoch13, step1266]: loss 1.051947
[epoch13, step1267]: loss 5.681102
[epoch13, step1268]: loss 11.282248
[epoch13, step1269]: loss 16.806488
[epoch13, step1270]: loss 1.223134
[epoch13, step1271]: loss 1.308716
[epoch13, step1272]: loss 1.563618
[epoch13, step1273]: loss 2.547780
[epoch13, step1274]: loss 2.869276
[epoch13, step1275]: loss 0.699191
[epoch13, step1276]: loss 3.013200
[epoch13, step1277]: loss 2.412683
[epoch13, step1278]: loss 13.504702
[epoch13, step1279]: loss 17.020370
[epoch13, step1280]: loss 1.590785
[epoch13, step1281]: loss 2.095393
[epoch13, step1282]: loss 15.847366
[epoch13, step1283]: loss 8.236975
[epoch13, step1284]: loss 1.821737
[epoch13, step1285]: loss 1.695039
[epoch13, step1286]: loss 3.630095
[epoch13, step1287]: loss 1.041290
[epoch13, step1288]: loss 1.491342
[epoch13, step1289]: loss 1.829633
[epoch13, step1290]: loss 1.139383
[epoch13, step1291]: loss 1.369302
[epoch13, step1292]: loss 0.776366
[epoch13, step1293]: loss 10.156371
[epoch13, step1294]: loss 0.926022
[epoch13, step1295]: loss 12.669052
[epoch13, step1296]: loss 0.971519
[epoch13, step1297]: loss 2.015482
[epoch13, step1298]: loss 1.190151
[epoch13, step1299]: loss 12.895899
[epoch13, step1300]: loss 12.542543
[epoch13, step1301]: loss 1.228262
[epoch13, step1302]: loss 0.865584
[epoch13, step1303]: loss 13.697716
[epoch13, step1304]: loss 26.969572
[epoch13, step1305]: loss 9.437410
[epoch13, step1306]: loss 1.184080
[epoch13, step1307]: loss 3.308933
[epoch13, step1308]: loss 1.588192
[epoch13, step1309]: loss 9.692425
[epoch13, step1310]: loss 3.247401
[epoch13, step1311]: loss 2.102307
[epoch13, step1312]: loss 1.811431
[epoch13, step1313]: loss 1.669255
[epoch13, step1314]: loss 0.744275
[epoch13, step1315]: loss 3.172396
[epoch13, step1316]: loss 12.479847
[epoch13, step1317]: loss 1.006145
[epoch13, step1318]: loss 13.686481
[epoch13, step1319]: loss 2.109400
[epoch13, step1320]: loss 0.627619
[epoch13, step1321]: loss 3.100055
[epoch13, step1322]: loss 1.915792
[epoch13, step1323]: loss 0.934893
[epoch13, step1324]: loss 3.668195
[epoch13, step1325]: loss 2.026960
[epoch13, step1326]: loss 31.054478
[epoch13, step1327]: loss 1.702480
[epoch13, step1328]: loss 1.773481
[epoch13, step1329]: loss 0.928983
[epoch13, step1330]: loss 2.276211
[epoch13, step1331]: loss 1.421869
[epoch13, step1332]: loss 12.081090
[epoch13, step1333]: loss 7.195739
[epoch13, step1334]: loss 1.356130
[epoch13, step1335]: loss 15.850780
[epoch13, step1336]: loss 2.780405
[epoch13, step1337]: loss 9.222264
[epoch13, step1338]: loss 0.865946
[epoch13, step1339]: loss 1.910319
[epoch13, step1340]: loss 7.173240
[epoch13, step1341]: loss 2.097008
[epoch13, step1342]: loss 1.302796
[epoch13, step1343]: loss 3.452055
[epoch13, step1344]: loss 2.022791
[epoch13, step1345]: loss 4.001369
[epoch13, step1346]: loss 0.841186
[epoch13, step1347]: loss 1.996274
[epoch13, step1348]: loss 3.690969
[epoch13, step1349]: loss 2.378209
[epoch13, step1350]: loss 3.940978
[epoch13, step1351]: loss 2.101106
[epoch13, step1352]: loss 1.127155
[epoch13, step1353]: loss 1.706008
[epoch13, step1354]: loss 11.361089
[epoch13, step1355]: loss 1.079635
[epoch13, step1356]: loss 1.508647
[epoch13, step1357]: loss 0.579553
[epoch13, step1358]: loss 3.817408
[epoch13, step1359]: loss 2.348158
[epoch13, step1360]: loss 1.334452
[epoch13, step1361]: loss 1.843248
[epoch13, step1362]: loss 2.434278
[epoch13, step1363]: loss 1.102066
[epoch13, step1364]: loss 1.537589
[epoch13, step1365]: loss 0.631750
[epoch13, step1366]: loss 1.179934
[epoch13, step1367]: loss 2.589517
[epoch13, step1368]: loss 5.159311
[epoch13, step1369]: loss 0.881375
[epoch13, step1370]: loss 2.249872
[epoch13, step1371]: loss 7.616699
[epoch13, step1372]: loss 1.376855
[epoch13, step1373]: loss 1.061874
[epoch13, step1374]: loss 3.725572
[epoch13, step1375]: loss 1.156042
[epoch13, step1376]: loss 2.212169
[epoch13, step1377]: loss 13.164021
[epoch13, step1378]: loss 11.556377
[epoch13, step1379]: loss 0.844253
[epoch13, step1380]: loss 1.503263
[epoch13, step1381]: loss 1.169477
[epoch13, step1382]: loss 1.950930
[epoch13, step1383]: loss 2.590764
[epoch13, step1384]: loss 11.136051
[epoch13, step1385]: loss 3.062289
[epoch13, step1386]: loss 1.947204
[epoch13, step1387]: loss 6.851198
[epoch13, step1388]: loss 1.353497
[epoch13, step1389]: loss 1.314524
[epoch13, step1390]: loss 2.180360
[epoch13, step1391]: loss 10.216058
[epoch13, step1392]: loss 13.175522
[epoch13, step1393]: loss 8.843572
[epoch13, step1394]: loss 3.124687
[epoch13, step1395]: loss 4.005766
[epoch13, step1396]: loss 2.396973
[epoch13, step1397]: loss 3.112631
[epoch13, step1398]: loss 4.614145
[epoch13, step1399]: loss 6.834685
[epoch13, step1400]: loss 1.688686
[epoch13, step1401]: loss 6.469191
[epoch13, step1402]: loss 1.247589
[epoch13, step1403]: loss 3.227198
[epoch13, step1404]: loss 11.690865
[epoch13, step1405]: loss 1.479509
[epoch13, step1406]: loss 1.002950
[epoch13, step1407]: loss 9.074285
[epoch13, step1408]: loss 1.545356
[epoch13, step1409]: loss 3.517812
[epoch13, step1410]: loss 3.818653
[epoch13, step1411]: loss 1.353267
[epoch13, step1412]: loss 6.085553
[epoch13, step1413]: loss 8.122646
[epoch13, step1414]: loss 0.706898
[epoch13, step1415]: loss 1.558194
[epoch13, step1416]: loss 1.049162
[epoch13, step1417]: loss 1.617179
[epoch13, step1418]: loss 8.142261
[epoch13, step1419]: loss 1.997322
[epoch13, step1420]: loss 9.372540
[epoch13, step1421]: loss 19.522299
[epoch13, step1422]: loss 4.580404
[epoch13, step1423]: loss 0.949339
[epoch13, step1424]: loss 12.383360
[epoch13, step1425]: loss 2.495434
[epoch13, step1426]: loss 1.657032
[epoch13, step1427]: loss 1.412118
[epoch13, step1428]: loss 1.027990
[epoch13, step1429]: loss 1.561760
[epoch13, step1430]: loss 9.819553
[epoch13, step1431]: loss 3.944050
[epoch13, step1432]: loss 1.079923
[epoch13, step1433]: loss 1.851462
[epoch13, step1434]: loss 1.152316
[epoch13, step1435]: loss 1.955166
[epoch13, step1436]: loss 6.894271
[epoch13, step1437]: loss 4.244521
[epoch13, step1438]: loss 1.572241
[epoch13, step1439]: loss 1.960663
[epoch13, step1440]: loss 1.011994
[epoch13, step1441]: loss 0.851586
[epoch13, step1442]: loss 3.473880
[epoch13, step1443]: loss 1.519875
[epoch13, step1444]: loss 1.149433
[epoch13, step1445]: loss 3.246604
[epoch13, step1446]: loss 1.058094
[epoch13, step1447]: loss 3.442677
[epoch13, step1448]: loss 5.043299
[epoch13, step1449]: loss 1.076655
[epoch13, step1450]: loss 13.624941
[epoch13, step1451]: loss 9.140929
[epoch13, step1452]: loss 1.376804
[epoch13, step1453]: loss 13.870709
[epoch13, step1454]: loss 3.466268
[epoch13, step1455]: loss 10.334438
[epoch13, step1456]: loss 17.731005
[epoch13, step1457]: loss 1.653410
[epoch13, step1458]: loss 1.065640
[epoch13, step1459]: loss 1.344582
[epoch13, step1460]: loss 1.171552
[epoch13, step1461]: loss 3.837138
[epoch13, step1462]: loss 2.985669
[epoch13, step1463]: loss 19.654150
[epoch13, step1464]: loss 15.473746
[epoch13, step1465]: loss 16.655706
[epoch13, step1466]: loss 1.614394
[epoch13, step1467]: loss 18.189837
[epoch13, step1468]: loss 1.928488
[epoch13, step1469]: loss 0.752851
[epoch13, step1470]: loss 2.470548
[epoch13, step1471]: loss 1.711721
[epoch13, step1472]: loss 2.068835
[epoch13, step1473]: loss 1.279099
[epoch13, step1474]: loss 2.015716
[epoch13, step1475]: loss 2.102502
[epoch13, step1476]: loss 0.933783
[epoch13, step1477]: loss 1.065454
[epoch13, step1478]: loss 1.409811
[epoch13, step1479]: loss 8.693048
[epoch13, step1480]: loss 2.645215
[epoch13, step1481]: loss 29.565561
[epoch13, step1482]: loss 7.516270
[epoch13, step1483]: loss 1.254498
[epoch13, step1484]: loss 1.149805
[epoch13, step1485]: loss 1.761262
[epoch13, step1486]: loss 1.565228
[epoch13, step1487]: loss 0.972254
[epoch13, step1488]: loss 3.088728
[epoch13, step1489]: loss 1.611215
[epoch13, step1490]: loss 1.126302
[epoch13, step1491]: loss 1.215979
[epoch13, step1492]: loss 6.712779
[epoch13, step1493]: loss 0.890043
[epoch13, step1494]: loss 1.329053
[epoch13, step1495]: loss 1.348861
[epoch13, step1496]: loss 1.570920
[epoch13, step1497]: loss 0.972650
[epoch13, step1498]: loss 0.782148
[epoch13, step1499]: loss 7.050859
[epoch13, step1500]: loss 5.029591
[epoch13, step1501]: loss 1.497015
[epoch13, step1502]: loss 1.773134
[epoch13, step1503]: loss 4.257106
[epoch13, step1504]: loss 1.782624
[epoch13, step1505]: loss 5.735165
[epoch13, step1506]: loss 1.234414
[epoch13, step1507]: loss 2.530591
[epoch13, step1508]: loss 8.177031
[epoch13, step1509]: loss 1.733532
[epoch13, step1510]: loss 1.315593
[epoch13, step1511]: loss 4.949943
[epoch13, step1512]: loss 1.138992
[epoch13, step1513]: loss 3.058151
[epoch13, step1514]: loss 0.899733
[epoch13, step1515]: loss 1.963032
[epoch13, step1516]: loss 7.197564
[epoch13, step1517]: loss 2.523931
[epoch13, step1518]: loss 0.836757
[epoch13, step1519]: loss 1.198204
[epoch13, step1520]: loss 1.961403
[epoch13, step1521]: loss 22.450882
[epoch13, step1522]: loss 0.820279
[epoch13, step1523]: loss 1.377463
[epoch13, step1524]: loss 2.939900
[epoch13, step1525]: loss 3.595607
[epoch13, step1526]: loss 1.307023
[epoch13, step1527]: loss 10.999320
[epoch13, step1528]: loss 0.852582
[epoch13, step1529]: loss 16.675756
[epoch13, step1530]: loss 9.082431
[epoch13, step1531]: loss 9.857957
[epoch13, step1532]: loss 25.205534
[epoch13, step1533]: loss 2.213225
[epoch13, step1534]: loss 1.169235
[epoch13, step1535]: loss 2.340101
[epoch13, step1536]: loss 1.163554
[epoch13, step1537]: loss 1.424227
[epoch13, step1538]: loss 1.724860
[epoch13, step1539]: loss 0.718928
[epoch13, step1540]: loss 2.272935
[epoch13, step1541]: loss 9.221251
[epoch13, step1542]: loss 0.692592
[epoch13, step1543]: loss 2.828383
[epoch13, step1544]: loss 7.882911
[epoch13, step1545]: loss 9.276302
[epoch13, step1546]: loss 0.732345
[epoch13, step1547]: loss 2.669478
[epoch13, step1548]: loss 12.977500
[epoch13, step1549]: loss 0.726957
[epoch13, step1550]: loss 2.484009
[epoch13, step1551]: loss 10.135712
[epoch13, step1552]: loss 1.023357
[epoch13, step1553]: loss 2.335213
[epoch13, step1554]: loss 7.914318
[epoch13, step1555]: loss 2.134279
[epoch13, step1556]: loss 5.095324
[epoch13, step1557]: loss 8.996765
[epoch13, step1558]: loss 1.299455
[epoch13, step1559]: loss 17.495998
[epoch13, step1560]: loss 1.295061
[epoch13, step1561]: loss 1.510531
[epoch13, step1562]: loss 4.561480
[epoch13, step1563]: loss 1.080332
[epoch13, step1564]: loss 1.182904
[epoch13, step1565]: loss 13.124390
[epoch13, step1566]: loss 5.146392
[epoch13, step1567]: loss 2.018826
[epoch13, step1568]: loss 0.694635
[epoch13, step1569]: loss 2.130976
[epoch13, step1570]: loss 9.990132
[epoch13, step1571]: loss 0.785210
[epoch13, step1572]: loss 12.838087
[epoch13, step1573]: loss 3.226366
[epoch13, step1574]: loss 0.761564
[epoch13, step1575]: loss 1.005408
[epoch13, step1576]: loss 3.194085
[epoch13, step1577]: loss 0.722091
[epoch13, step1578]: loss 0.593074
[epoch13, step1579]: loss 0.839029
[epoch13, step1580]: loss 1.397410
[epoch13, step1581]: loss 12.289232
[epoch13, step1582]: loss 2.028250
[epoch13, step1583]: loss 12.403495
[epoch13, step1584]: loss 10.427694
[epoch13, step1585]: loss 1.906504
[epoch13, step1586]: loss 6.777318
[epoch13, step1587]: loss 1.159533
[epoch13, step1588]: loss 0.955130
[epoch13, step1589]: loss 1.555467
[epoch13, step1590]: loss 2.948720
[epoch13, step1591]: loss 1.071803
[epoch13, step1592]: loss 4.208237
[epoch13, step1593]: loss 1.771799
[epoch13, step1594]: loss 0.980032
[epoch13, step1595]: loss 1.583373
[epoch13, step1596]: loss 2.456513
[epoch13, step1597]: loss 3.915807
[epoch13, step1598]: loss 3.815603
[epoch13, step1599]: loss 0.923855
[epoch13, step1600]: loss 6.664167
[epoch13, step1601]: loss 5.449643
[epoch13, step1602]: loss 1.279394
[epoch13, step1603]: loss 3.597353
[epoch13, step1604]: loss 20.704496
[epoch13, step1605]: loss 1.976282
[epoch13, step1606]: loss 1.405000
[epoch13, step1607]: loss 1.354385
[epoch13, step1608]: loss 9.448482
[epoch13, step1609]: loss 1.782868
[epoch13, step1610]: loss 1.056363
[epoch13, step1611]: loss 0.730039
[epoch13, step1612]: loss 2.735690
[epoch13, step1613]: loss 2.265219
[epoch13, step1614]: loss 1.805453
[epoch13, step1615]: loss 2.317913
[epoch13, step1616]: loss 3.287565
[epoch13, step1617]: loss 1.999771
[epoch13, step1618]: loss 1.342728
[epoch13, step1619]: loss 29.529373
[epoch13, step1620]: loss 0.880002
[epoch13, step1621]: loss 3.956674
[epoch13, step1622]: loss 13.164969
[epoch13, step1623]: loss 11.483480
[epoch13, step1624]: loss 19.301723
[epoch13, step1625]: loss 6.207520
[epoch13, step1626]: loss 1.828865
[epoch13, step1627]: loss 4.085867
[epoch13, step1628]: loss 0.832817
[epoch13, step1629]: loss 3.387586
[epoch13, step1630]: loss 1.143830
[epoch13, step1631]: loss 0.599364
[epoch13, step1632]: loss 1.313560
[epoch13, step1633]: loss 12.954935
[epoch13, step1634]: loss 1.172007
[epoch13, step1635]: loss 2.695344
[epoch13, step1636]: loss 1.889172
[epoch13, step1637]: loss 2.288608
[epoch13, step1638]: loss 6.793194
[epoch13, step1639]: loss 1.190844
[epoch13, step1640]: loss 1.560711
[epoch13, step1641]: loss 5.516683
[epoch13, step1642]: loss 3.362887
[epoch13, step1643]: loss 1.534271
[epoch13, step1644]: loss 1.485959
[epoch13, step1645]: loss 2.537754
[epoch13, step1646]: loss 0.681611
[epoch13, step1647]: loss 3.077447
[epoch13, step1648]: loss 1.322629
[epoch13, step1649]: loss 5.166875
[epoch13, step1650]: loss 3.910281
[epoch13, step1651]: loss 1.439141
[epoch13, step1652]: loss 2.724960
[epoch13, step1653]: loss 2.086565
[epoch13, step1654]: loss 1.987816
[epoch13, step1655]: loss 3.789396
[epoch13, step1656]: loss 0.813033
[epoch13, step1657]: loss 3.112413
[epoch13, step1658]: loss 9.857999
[epoch13, step1659]: loss 1.405436
[epoch13, step1660]: loss 1.612071
[epoch13, step1661]: loss 0.888920
[epoch13, step1662]: loss 6.308188
[epoch13, step1663]: loss 2.842742
[epoch13, step1664]: loss 1.408775
[epoch13, step1665]: loss 1.825589
[epoch13, step1666]: loss 5.888920
[epoch13, step1667]: loss 2.481178
[epoch13, step1668]: loss 1.330699
[epoch13, step1669]: loss 0.760398
[epoch13, step1670]: loss 3.750651
[epoch13, step1671]: loss 0.702547
[epoch13, step1672]: loss 9.798690
[epoch13, step1673]: loss 14.205213
[epoch13, step1674]: loss 2.283229
[epoch13, step1675]: loss 1.230046
[epoch13, step1676]: loss 1.302888
[epoch13, step1677]: loss 0.709324
[epoch13, step1678]: loss 1.839172
[epoch13, step1679]: loss 8.388529
[epoch13, step1680]: loss 0.904860
[epoch13, step1681]: loss 1.950665
[epoch13, step1682]: loss 1.052595
[epoch13, step1683]: loss 5.384198
[epoch13, step1684]: loss 2.671289
[epoch13, step1685]: loss 2.373895
[epoch13, step1686]: loss 1.204771
[epoch13, step1687]: loss 2.187286
[epoch13, step1688]: loss 24.449594
[epoch13, step1689]: loss 0.541821
[epoch13, step1690]: loss 1.905419
[epoch13, step1691]: loss 9.897256
[epoch13, step1692]: loss 1.200678
[epoch13, step1693]: loss 2.941240
[epoch13, step1694]: loss 1.035658
[epoch13, step1695]: loss 1.437684
[epoch13, step1696]: loss 9.974033
[epoch13, step1697]: loss 6.580664
[epoch13, step1698]: loss 1.026449
[epoch13, step1699]: loss 0.851129
[epoch13, step1700]: loss 8.332354
[epoch13, step1701]: loss 7.321187
[epoch13, step1702]: loss 3.106449
[epoch13, step1703]: loss 2.948122
[epoch13, step1704]: loss 19.844141
[epoch13, step1705]: loss 12.020846
[epoch13, step1706]: loss 0.651798
[epoch13, step1707]: loss 0.851117
[epoch13, step1708]: loss 22.711184
[epoch13, step1709]: loss 3.579479
[epoch13, step1710]: loss 1.076869
[epoch13, step1711]: loss 1.064672
[epoch13, step1712]: loss 1.177618
[epoch13, step1713]: loss 7.642246
[epoch13, step1714]: loss 0.750477
[epoch13, step1715]: loss 2.302305
[epoch13, step1716]: loss 1.204153
[epoch13, step1717]: loss 1.094916
[epoch13, step1718]: loss 14.170732
[epoch13, step1719]: loss 3.036648
[epoch13, step1720]: loss 0.512115
[epoch13, step1721]: loss 1.378220
[epoch13, step1722]: loss 1.086642
[epoch13, step1723]: loss 3.551002
[epoch13, step1724]: loss 3.766556
[epoch13, step1725]: loss 2.914220
[epoch13, step1726]: loss 0.777938
[epoch13, step1727]: loss 9.521167
[epoch13, step1728]: loss 1.112529
[epoch13, step1729]: loss 3.128653
[epoch13, step1730]: loss 0.677415
[epoch13, step1731]: loss 2.052510
[epoch13, step1732]: loss 1.375628
[epoch13, step1733]: loss 4.529070
[epoch13, step1734]: loss 0.984003
[epoch13, step1735]: loss 2.064613
[epoch13, step1736]: loss 8.683511
[epoch13, step1737]: loss 8.219488
[epoch13, step1738]: loss 1.883583
[epoch13, step1739]: loss 1.191898
[epoch13, step1740]: loss 2.502676
[epoch13, step1741]: loss 4.616777
[epoch13, step1742]: loss 2.942635
[epoch13, step1743]: loss 19.223778
[epoch13, step1744]: loss 7.513068
[epoch13, step1745]: loss 0.533887
[epoch13, step1746]: loss 0.942736
[epoch13, step1747]: loss 0.900374
[epoch13, step1748]: loss 2.988206
[epoch13, step1749]: loss 2.343507
[epoch13, step1750]: loss 12.862017
[epoch13, step1751]: loss 5.218074
[epoch13, step1752]: loss 1.221283
[epoch13, step1753]: loss 10.193476
[epoch13, step1754]: loss 0.775124
[epoch13, step1755]: loss 1.127440
[epoch13, step1756]: loss 10.820284
[epoch13, step1757]: loss 0.763916
[epoch13, step1758]: loss 0.931162
[epoch13, step1759]: loss 1.040687
[epoch13, step1760]: loss 0.885200
[epoch13, step1761]: loss 8.067948
[epoch13, step1762]: loss 1.435868
[epoch13, step1763]: loss 8.254689
[epoch13, step1764]: loss 1.131435
[epoch13, step1765]: loss 3.228058
[epoch13, step1766]: loss 1.616560
[epoch13, step1767]: loss 3.736983
[epoch13, step1768]: loss 2.010482
[epoch13, step1769]: loss 6.842512
[epoch13, step1770]: loss 11.045304
[epoch13, step1771]: loss 15.362679
[epoch13, step1772]: loss 1.581243
[epoch13, step1773]: loss 1.950325
[epoch13, step1774]: loss 1.604862
[epoch13, step1775]: loss 2.453966
[epoch13, step1776]: loss 1.602037
[epoch13, step1777]: loss 1.086329
[epoch13, step1778]: loss 6.703923
[epoch13, step1779]: loss 1.920479
[epoch13, step1780]: loss 1.076411
[epoch13, step1781]: loss 2.080109
[epoch13, step1782]: loss 0.866977
[epoch13, step1783]: loss 8.080156
[epoch13, step1784]: loss 2.329475
[epoch13, step1785]: loss 7.073819
[epoch13, step1786]: loss 2.131480
[epoch13, step1787]: loss 1.882238
[epoch13, step1788]: loss 1.101489
[epoch13, step1789]: loss 6.040507
[epoch13, step1790]: loss 1.735762
[epoch13, step1791]: loss 1.961918
[epoch13, step1792]: loss 18.862720
[epoch13, step1793]: loss 2.218158
[epoch13, step1794]: loss 16.627558
[epoch13, step1795]: loss 2.217097
[epoch13, step1796]: loss 1.721760
[epoch13, step1797]: loss 4.198878
[epoch13, step1798]: loss 2.484353
[epoch13, step1799]: loss 3.490465
[epoch13, step1800]: loss 3.737695
[epoch13, step1801]: loss 8.915650
[epoch13, step1802]: loss 1.572033
[epoch13, step1803]: loss 1.397007
[epoch13, step1804]: loss 32.280327
[epoch13, step1805]: loss 6.203198
[epoch13, step1806]: loss 0.705279
[epoch13, step1807]: loss 7.882360
[epoch13, step1808]: loss 1.853248
[epoch13, step1809]: loss 2.194667
[epoch13, step1810]: loss 2.052359
[epoch13, step1811]: loss 10.296309
[epoch13, step1812]: loss 2.313656
[epoch13, step1813]: loss 3.526340
[epoch13, step1814]: loss 3.526232
[epoch13, step1815]: loss 0.627916
[epoch13, step1816]: loss 4.361053
[epoch13, step1817]: loss 1.324293
[epoch13, step1818]: loss 5.144297
[epoch13, step1819]: loss 5.100289
[epoch13, step1820]: loss 9.193778
[epoch13, step1821]: loss 2.788969
[epoch13, step1822]: loss 0.621435
[epoch13, step1823]: loss 1.314086
[epoch13, step1824]: loss 1.437057
[epoch13, step1825]: loss 0.919024
[epoch13, step1826]: loss 1.600097
[epoch13, step1827]: loss 8.782106
[epoch13, step1828]: loss 1.710759
[epoch13, step1829]: loss 10.263478
[epoch13, step1830]: loss 4.973133
[epoch13, step1831]: loss 12.921724
[epoch13, step1832]: loss 2.384348
[epoch13, step1833]: loss 2.087757
[epoch13, step1834]: loss 9.712814
[epoch13, step1835]: loss 8.751627
[epoch13, step1836]: loss 1.016697
[epoch13, step1837]: loss 1.481356
[epoch13, step1838]: loss 38.643154
[epoch13, step1839]: loss 1.123309
[epoch13, step1840]: loss 10.465623
[epoch13, step1841]: loss 2.517876
[epoch13, step1842]: loss 0.957310
[epoch13, step1843]: loss 1.255336
[epoch13, step1844]: loss 3.671088
[epoch13, step1845]: loss 8.765146
[epoch13, step1846]: loss 1.125002
[epoch13, step1847]: loss 0.822427
[epoch13, step1848]: loss 1.193304
[epoch13, step1849]: loss 1.534992
[epoch13, step1850]: loss 1.190852
[epoch13, step1851]: loss 13.044518
[epoch13, step1852]: loss 27.864435
[epoch13, step1853]: loss 1.057237
[epoch13, step1854]: loss 2.203949
[epoch13, step1855]: loss 7.050586
[epoch13, step1856]: loss 0.920162
[epoch13, step1857]: loss 1.293299
[epoch13, step1858]: loss 2.049122
[epoch13, step1859]: loss 1.718789
[epoch13, step1860]: loss 18.188858
[epoch13, step1861]: loss 2.357461
[epoch13, step1862]: loss 0.770325
[epoch13, step1863]: loss 1.208913
[epoch13, step1864]: loss 1.603242
[epoch13, step1865]: loss 12.472542
[epoch13, step1866]: loss 15.588327
[epoch13, step1867]: loss 6.486279
[epoch13, step1868]: loss 11.037289
[epoch13, step1869]: loss 1.910026
[epoch13, step1870]: loss 8.369555
[epoch13, step1871]: loss 10.172967
[epoch13, step1872]: loss 2.408953
[epoch13, step1873]: loss 1.019274
[epoch13, step1874]: loss 12.354227
[epoch13, step1875]: loss 18.853977
[epoch13, step1876]: loss 2.437351
[epoch13, step1877]: loss 19.629736
[epoch13, step1878]: loss 15.519905
[epoch13, step1879]: loss 9.077336
[epoch13, step1880]: loss 15.116114
[epoch13, step1881]: loss 2.274670
[epoch13, step1882]: loss 1.294683
[epoch13, step1883]: loss 1.092695
[epoch13, step1884]: loss 0.713589
[epoch13, step1885]: loss 3.299517
[epoch13, step1886]: loss 1.173354
[epoch13, step1887]: loss 5.120027
[epoch13, step1888]: loss 1.310430
[epoch13, step1889]: loss 5.429931
[epoch13, step1890]: loss 3.092762
[epoch13, step1891]: loss 2.640372
[epoch13, step1892]: loss 3.469874
[epoch13, step1893]: loss 0.988235
[epoch13, step1894]: loss 1.863675
[epoch13, step1895]: loss 1.124040
[epoch13, step1896]: loss 2.610824
[epoch13, step1897]: loss 14.805126
[epoch13, step1898]: loss 16.934637
[epoch13, step1899]: loss 1.682994
[epoch13, step1900]: loss 1.258034
[epoch13, step1901]: loss 21.379978
[epoch13, step1902]: loss 4.021546
[epoch13, step1903]: loss 0.844926
[epoch13, step1904]: loss 0.670409
[epoch13, step1905]: loss 8.132313
[epoch13, step1906]: loss 1.948646
[epoch13, step1907]: loss 8.275628
[epoch13, step1908]: loss 3.642239
[epoch13, step1909]: loss 8.669782
[epoch13, step1910]: loss 9.201232
[epoch13, step1911]: loss 1.167542
[epoch13, step1912]: loss 7.488858
[epoch13, step1913]: loss 1.607773
[epoch13, step1914]: loss 12.403183
[epoch13, step1915]: loss 0.819059
[epoch13, step1916]: loss 1.714079
[epoch13, step1917]: loss 0.904026
[epoch13, step1918]: loss 1.023577
[epoch13, step1919]: loss 0.856656
[epoch13, step1920]: loss 1.091812
[epoch13, step1921]: loss 2.682088
[epoch13, step1922]: loss 1.524192
[epoch13, step1923]: loss 1.134129
[epoch13, step1924]: loss 0.851887
[epoch13, step1925]: loss 15.918953
[epoch13, step1926]: loss 7.274802
[epoch13, step1927]: loss 0.895472
[epoch13, step1928]: loss 2.935156
[epoch13, step1929]: loss 5.171884
[epoch13, step1930]: loss 3.698327
[epoch13, step1931]: loss 7.576800
[epoch13, step1932]: loss 20.217756
[epoch13, step1933]: loss 5.597562
[epoch13, step1934]: loss 4.816391
[epoch13, step1935]: loss 1.607853
[epoch13, step1936]: loss 7.654770
[epoch13, step1937]: loss 1.699346
[epoch13, step1938]: loss 3.083625
[epoch13, step1939]: loss 2.691791
[epoch13, step1940]: loss 1.035055
[epoch13, step1941]: loss 0.922096
[epoch13, step1942]: loss 8.810575
[epoch13, step1943]: loss 1.236157
[epoch13, step1944]: loss 1.432596
[epoch13, step1945]: loss 1.174599
[epoch13, step1946]: loss 0.852716
[epoch13, step1947]: loss 7.516418
[epoch13, step1948]: loss 1.218989
[epoch13, step1949]: loss 1.623550
[epoch13, step1950]: loss 1.385927
[epoch13, step1951]: loss 4.339852
[epoch13, step1952]: loss 0.816729
[epoch13, step1953]: loss 4.597699
[epoch13, step1954]: loss 2.050021
[epoch13, step1955]: loss 2.230813
[epoch13, step1956]: loss 9.972589
[epoch13, step1957]: loss 1.314902
[epoch13, step1958]: loss 0.863213
[epoch13, step1959]: loss 0.967442
[epoch13, step1960]: loss 4.604324
[epoch13, step1961]: loss 0.976110
[epoch13, step1962]: loss 1.331202
[epoch13, step1963]: loss 0.716753
[epoch13, step1964]: loss 1.953751
[epoch13, step1965]: loss 3.633837
[epoch13, step1966]: loss 3.804012
[epoch13, step1967]: loss 1.035675
[epoch13, step1968]: loss 1.904285
[epoch13, step1969]: loss 0.883003
[epoch13, step1970]: loss 4.669103
[epoch13, step1971]: loss 1.468175
[epoch13, step1972]: loss 1.889489
[epoch13, step1973]: loss 6.549595
[epoch13, step1974]: loss 7.553039
[epoch13, step1975]: loss 1.866604
[epoch13, step1976]: loss 1.009787
[epoch13, step1977]: loss 2.419613
[epoch13, step1978]: loss 1.835435
[epoch13, step1979]: loss 1.835204
[epoch13, step1980]: loss 1.211232
[epoch13, step1981]: loss 0.992247
[epoch13, step1982]: loss 11.990015
[epoch13, step1983]: loss 1.219901
[epoch13, step1984]: loss 1.677444
[epoch13, step1985]: loss 1.690112
[epoch13, step1986]: loss 10.585518
[epoch13, step1987]: loss 2.116732
[epoch13, step1988]: loss 2.158201
[epoch13, step1989]: loss 1.724411
[epoch13, step1990]: loss 1.104156
[epoch13, step1991]: loss 1.771016
[epoch13, step1992]: loss 11.873077
[epoch13, step1993]: loss 1.088270
[epoch13, step1994]: loss 1.391593
[epoch13, step1995]: loss 2.726367
[epoch13, step1996]: loss 1.872852
[epoch13, step1997]: loss 23.379047
[epoch13, step1998]: loss 3.667199
[epoch13, step1999]: loss 1.514194
[epoch13, step2000]: loss 4.056126
[epoch13, step2001]: loss 1.627613
[epoch13, step2002]: loss 0.991766
[epoch13, step2003]: loss 0.788150
[epoch13, step2004]: loss 4.541824
[epoch13, step2005]: loss 1.309285
[epoch13, step2006]: loss 5.255800
[epoch13, step2007]: loss 3.828928
[epoch13, step2008]: loss 2.505776
[epoch13, step2009]: loss 4.757694
[epoch13, step2010]: loss 2.123703
[epoch13, step2011]: loss 24.764511
[epoch13, step2012]: loss 1.142807
[epoch13, step2013]: loss 1.872547
[epoch13, step2014]: loss 1.355414
[epoch13, step2015]: loss 9.327034
[epoch13, step2016]: loss 2.598083
[epoch13, step2017]: loss 15.685142
[epoch13, step2018]: loss 0.887432
[epoch13, step2019]: loss 1.040540
[epoch13, step2020]: loss 1.790168
[epoch13, step2021]: loss 1.170283
[epoch13, step2022]: loss 7.294298
[epoch13, step2023]: loss 17.423431
[epoch13, step2024]: loss 3.773231
[epoch13, step2025]: loss 1.184455
[epoch13, step2026]: loss 5.664046
[epoch13, step2027]: loss 1.283257
[epoch13, step2028]: loss 1.450463
[epoch13, step2029]: loss 7.019034
[epoch13, step2030]: loss 1.737411
[epoch13, step2031]: loss 3.445874
[epoch13, step2032]: loss 2.338668
[epoch13, step2033]: loss 5.681046
[epoch13, step2034]: loss 1.249699
[epoch13, step2035]: loss 13.956655
[epoch13, step2036]: loss 2.592477
[epoch13, step2037]: loss 15.319655
[epoch13, step2038]: loss 1.445330
[epoch13, step2039]: loss 2.293435
[epoch13, step2040]: loss 1.043838
[epoch13, step2041]: loss 9.662050
[epoch13, step2042]: loss 3.044884
[epoch13, step2043]: loss 2.151225
[epoch13, step2044]: loss 0.953313
[epoch13, step2045]: loss 1.030861
[epoch13, step2046]: loss 2.131026
[epoch13, step2047]: loss 3.993695
[epoch13, step2048]: loss 1.404064
[epoch13, step2049]: loss 8.581265
[epoch13, step2050]: loss 18.818607
[epoch13, step2051]: loss 12.152205
[epoch13, step2052]: loss 1.307854
[epoch13, step2053]: loss 7.826287
[epoch13, step2054]: loss 0.956950
[epoch13, step2055]: loss 2.378273
[epoch13, step2056]: loss 3.508335
[epoch13, step2057]: loss 2.563185
[epoch13, step2058]: loss 3.749764
[epoch13, step2059]: loss 2.790040
[epoch13, step2060]: loss 9.307631
[epoch13, step2061]: loss 32.057438
[epoch13, step2062]: loss 9.082880
[epoch13, step2063]: loss 5.452064
[epoch13, step2064]: loss 1.209301
[epoch13, step2065]: loss 6.706378
[epoch13, step2066]: loss 1.126702
[epoch13, step2067]: loss 4.792019
[epoch13, step2068]: loss 1.583305
[epoch13, step2069]: loss 0.693349
[epoch13, step2070]: loss 1.419342
[epoch13, step2071]: loss 0.950278
[epoch13, step2072]: loss 0.906414
[epoch13, step2073]: loss 1.500140
[epoch13, step2074]: loss 9.537066
[epoch13, step2075]: loss 5.000748
[epoch13, step2076]: loss 1.875954
[epoch13, step2077]: loss 3.192854
[epoch13, step2078]: loss 1.206085
[epoch13, step2079]: loss 1.023849
[epoch13, step2080]: loss 1.137260
[epoch13, step2081]: loss 1.195060
[epoch13, step2082]: loss 0.768116
[epoch13, step2083]: loss 4.339600
[epoch13, step2084]: loss 0.835394
[epoch13, step2085]: loss 8.561648
[epoch13, step2086]: loss 1.368926
[epoch13, step2087]: loss 1.492102
[epoch13, step2088]: loss 1.281686
[epoch13, step2089]: loss 7.350750
[epoch13, step2090]: loss 2.272484
[epoch13, step2091]: loss 1.019853
[epoch13, step2092]: loss 17.752035
[epoch13, step2093]: loss 7.636973
[epoch13, step2094]: loss 0.626544
[epoch13, step2095]: loss 0.854701
[epoch13, step2096]: loss 6.043393
[epoch13, step2097]: loss 1.092117
[epoch13, step2098]: loss 3.031025
[epoch13, step2099]: loss 1.046098
[epoch13, step2100]: loss 0.696318
[epoch13, step2101]: loss 0.874875
[epoch13, step2102]: loss 18.148417
[epoch13, step2103]: loss 2.235234
[epoch13, step2104]: loss 2.170636
[epoch13, step2105]: loss 11.247179
[epoch13, step2106]: loss 2.358201
[epoch13, step2107]: loss 2.683448
[epoch13, step2108]: loss 2.422492
[epoch13, step2109]: loss 1.016049
[epoch13, step2110]: loss 6.806044
[epoch13, step2111]: loss 2.534884
[epoch13, step2112]: loss 1.093313
[epoch13, step2113]: loss 11.097340
[epoch13, step2114]: loss 1.927338
[epoch13, step2115]: loss 9.764324
[epoch13, step2116]: loss 14.115047
[epoch13, step2117]: loss 0.941398
[epoch13, step2118]: loss 1.345048
[epoch13, step2119]: loss 0.750841
[epoch13, step2120]: loss 1.400952
[epoch13, step2121]: loss 1.040976
[epoch13, step2122]: loss 17.142916
[epoch13, step2123]: loss 1.266131
[epoch13, step2124]: loss 2.527747
[epoch13, step2125]: loss 16.501257
[epoch13, step2126]: loss 2.441797
[epoch13, step2127]: loss 26.985870
[epoch13, step2128]: loss 1.506473
[epoch13, step2129]: loss 1.296068
[epoch13, step2130]: loss 10.760915
[epoch13, step2131]: loss 15.878253
[epoch13, step2132]: loss 1.536898
[epoch13, step2133]: loss 3.986070
[epoch13, step2134]: loss 1.383878
[epoch13, step2135]: loss 2.347493
[epoch13, step2136]: loss 7.057810
[epoch13, step2137]: loss 2.859701
[epoch13, step2138]: loss 1.426216
[epoch13, step2139]: loss 1.217095
[epoch13, step2140]: loss 27.136698
[epoch13, step2141]: loss 0.641467
[epoch13, step2142]: loss 0.930047
[epoch13, step2143]: loss 0.868205
[epoch13, step2144]: loss 5.058617
[epoch13, step2145]: loss 1.167119
[epoch13, step2146]: loss 5.174273
[epoch13, step2147]: loss 1.705405
[epoch13, step2148]: loss 1.821838
[epoch13, step2149]: loss 0.955275
[epoch13, step2150]: loss 0.722836
[epoch13, step2151]: loss 2.090607
[epoch13, step2152]: loss 2.326915
[epoch13, step2153]: loss 2.891624
[epoch13, step2154]: loss 1.335827
[epoch13, step2155]: loss 0.650768
[epoch13, step2156]: loss 1.580221
[epoch13, step2157]: loss 1.633377
[epoch13, step2158]: loss 18.454731
[epoch13, step2159]: loss 4.480807
[epoch13, step2160]: loss 5.699728
[epoch13, step2161]: loss 1.415648
[epoch13, step2162]: loss 1.170936
[epoch13, step2163]: loss 20.912344
[epoch13, step2164]: loss 1.516320
[epoch13, step2165]: loss 1.904207
[epoch13, step2166]: loss 4.488720
[epoch13, step2167]: loss 1.309884
[epoch13, step2168]: loss 19.633034
[epoch13, step2169]: loss 2.464385
[epoch13, step2170]: loss 7.204618
[epoch13, step2171]: loss 10.816774
[epoch13, step2172]: loss 6.907849
[epoch13, step2173]: loss 4.882235
[epoch13, step2174]: loss 1.996482
[epoch13, step2175]: loss 1.297563
[epoch13, step2176]: loss 1.869129
[epoch13, step2177]: loss 1.410325
[epoch13, step2178]: loss 2.515705
[epoch13, step2179]: loss 2.025034
[epoch13, step2180]: loss 0.941473
[epoch13, step2181]: loss 5.133822
[epoch13, step2182]: loss 0.993143
[epoch13, step2183]: loss 2.690158
[epoch13, step2184]: loss 2.405776
[epoch13, step2185]: loss 9.437279
[epoch13, step2186]: loss 12.770864
[epoch13, step2187]: loss 13.232393
[epoch13, step2188]: loss 1.015374
[epoch13, step2189]: loss 3.209192
[epoch13, step2190]: loss 2.007001
[epoch13, step2191]: loss 2.809152
[epoch13, step2192]: loss 2.028274
[epoch13, step2193]: loss 13.942108
[epoch13, step2194]: loss 0.907305
[epoch13, step2195]: loss 0.507035
[epoch13, step2196]: loss 3.635274
[epoch13, step2197]: loss 17.289339
[epoch13, step2198]: loss 1.704738
[epoch13, step2199]: loss 3.318764
[epoch13, step2200]: loss 5.524807
[epoch13, step2201]: loss 1.103012
[epoch13, step2202]: loss 1.903909
[epoch13, step2203]: loss 1.223367
[epoch13, step2204]: loss 2.115273
[epoch13, step2205]: loss 10.050688
[epoch13, step2206]: loss 1.583508
[epoch13, step2207]: loss 0.930133
[epoch13, step2208]: loss 2.331608
[epoch13, step2209]: loss 6.582015
[epoch13, step2210]: loss 1.477995
[epoch13, step2211]: loss 3.926068
[epoch13, step2212]: loss 2.013364
[epoch13, step2213]: loss 0.914381
[epoch13, step2214]: loss 0.665773
[epoch13, step2215]: loss 2.424949
[epoch13, step2216]: loss 1.069753
[epoch13, step2217]: loss 3.355535
[epoch13, step2218]: loss 4.959498
[epoch13, step2219]: loss 2.869742
[epoch13, step2220]: loss 1.205464
[epoch13, step2221]: loss 0.602281
[epoch13, step2222]: loss 1.242626
[epoch13, step2223]: loss 17.493305
[epoch13, step2224]: loss 5.348667
[epoch13, step2225]: loss 1.602491
[epoch13, step2226]: loss 0.947425
[epoch13, step2227]: loss 3.018546
[epoch13, step2228]: loss 0.922415
[epoch13, step2229]: loss 1.223548
[epoch13, step2230]: loss 1.051510
[epoch13, step2231]: loss 3.212240
[epoch13, step2232]: loss 2.278839
[epoch13, step2233]: loss 1.081464
[epoch13, step2234]: loss 4.100420
[epoch13, step2235]: loss 2.650905
[epoch13, step2236]: loss 1.704129
[epoch13, step2237]: loss 5.539991
[epoch13, step2238]: loss 2.153683
[epoch13, step2239]: loss 1.975015
[epoch13, step2240]: loss 0.975502
[epoch13, step2241]: loss 1.900548
[epoch13, step2242]: loss 18.090807
[epoch13, step2243]: loss 0.892954
[epoch13, step2244]: loss 0.972941
[epoch13, step2245]: loss 0.913855
[epoch13, step2246]: loss 3.604849
[epoch13, step2247]: loss 0.604895
[epoch13, step2248]: loss 6.354440
[epoch13, step2249]: loss 3.025662
[epoch13, step2250]: loss 7.591858
[epoch13, step2251]: loss 1.476595
[epoch13, step2252]: loss 3.593562
[epoch13, step2253]: loss 0.910593
[epoch13, step2254]: loss 3.408963
[epoch13, step2255]: loss 0.576471
[epoch13, step2256]: loss 9.023787
[epoch13, step2257]: loss 3.315171
[epoch13, step2258]: loss 1.045357
[epoch13, step2259]: loss 1.891370
[epoch13, step2260]: loss 3.410004
[epoch13, step2261]: loss 7.602429
[epoch13, step2262]: loss 6.748400
[epoch13, step2263]: loss 0.638945
[epoch13, step2264]: loss 0.954810
[epoch13, step2265]: loss 15.626157
[epoch13, step2266]: loss 2.472122
[epoch13, step2267]: loss 1.717468
[epoch13, step2268]: loss 2.987709
[epoch13, step2269]: loss 1.477704
[epoch13, step2270]: loss 4.541414
[epoch13, step2271]: loss 2.670665
[epoch13, step2272]: loss 12.567646
[epoch13, step2273]: loss 8.201973
[epoch13, step2274]: loss 1.350631
[epoch13, step2275]: loss 11.802840
[epoch13, step2276]: loss 2.518853
[epoch13, step2277]: loss 8.172289
[epoch13, step2278]: loss 10.991663
[epoch13, step2279]: loss 1.224575
[epoch13, step2280]: loss 3.636666
[epoch13, step2281]: loss 3.805248
[epoch13, step2282]: loss 3.771072
[epoch13, step2283]: loss 0.943952
[epoch13, step2284]: loss 3.956955
[epoch13, step2285]: loss 0.915413
[epoch13, step2286]: loss 0.750497
[epoch13, step2287]: loss 0.766482
[epoch13, step2288]: loss 6.711738
[epoch13, step2289]: loss 0.642808
[epoch13, step2290]: loss 4.052240
[epoch13, step2291]: loss 1.293730
[epoch13, step2292]: loss 3.641807
[epoch13, step2293]: loss 3.570953
[epoch13, step2294]: loss 1.731264
[epoch13, step2295]: loss 1.846107
[epoch13, step2296]: loss 1.148045
[epoch13, step2297]: loss 25.131960
[epoch13, step2298]: loss 1.647051
[epoch13, step2299]: loss 2.124437
[epoch13, step2300]: loss 1.780602
[epoch13, step2301]: loss 10.173167
[epoch13, step2302]: loss 1.863349
[epoch13, step2303]: loss 2.581873
[epoch13, step2304]: loss 2.358206
[epoch13, step2305]: loss 6.293022
[epoch13, step2306]: loss 3.004028
[epoch13, step2307]: loss 0.610258
[epoch13, step2308]: loss 1.049817
[epoch13, step2309]: loss 1.866731
[epoch13, step2310]: loss 1.150721
[epoch13, step2311]: loss 1.885896
[epoch13, step2312]: loss 1.090958
[epoch13, step2313]: loss 3.593587
[epoch13, step2314]: loss 5.472286
[epoch13, step2315]: loss 15.496939
[epoch13, step2316]: loss 8.187846
[epoch13, step2317]: loss 2.656751
[epoch13, step2318]: loss 0.933180
[epoch13, step2319]: loss 1.094106
[epoch13, step2320]: loss 0.803589
[epoch13, step2321]: loss 1.428086
[epoch13, step2322]: loss 2.262609
[epoch13, step2323]: loss 0.973431
[epoch13, step2324]: loss 0.717656
[epoch13, step2325]: loss 0.983867
[epoch13, step2326]: loss 0.976888
[epoch13, step2327]: loss 6.455606
[epoch13, step2328]: loss 0.908004
[epoch13, step2329]: loss 4.261508
[epoch13, step2330]: loss 0.649966
[epoch13, step2331]: loss 3.138331
[epoch13, step2332]: loss 6.156034
[epoch13, step2333]: loss 1.322747
[epoch13, step2334]: loss 3.152425
[epoch13, step2335]: loss 8.701072
[epoch13, step2336]: loss 1.055188
[epoch13, step2337]: loss 2.990157
[epoch13, step2338]: loss 1.096017
[epoch13, step2339]: loss 2.883594
[epoch13, step2340]: loss 2.053223
[epoch13, step2341]: loss 1.113065
[epoch13, step2342]: loss 8.751410
[epoch13, step2343]: loss 3.072756
[epoch13, step2344]: loss 4.345578
[epoch13, step2345]: loss 0.738324
[epoch13, step2346]: loss 11.944223
[epoch13, step2347]: loss 1.216795
[epoch13, step2348]: loss 3.369222
[epoch13, step2349]: loss 2.835144
[epoch13, step2350]: loss 0.802894
[epoch13, step2351]: loss 2.928667
[epoch13, step2352]: loss 8.576416
[epoch13, step2353]: loss 8.476028
[epoch13, step2354]: loss 8.360717
[epoch13, step2355]: loss 1.947924
[epoch13, step2356]: loss 6.033939
[epoch13, step2357]: loss 16.029768
[epoch13, step2358]: loss 15.681784
[epoch13, step2359]: loss 10.134748
[epoch13, step2360]: loss 1.312452
[epoch13, step2361]: loss 12.887568
[epoch13, step2362]: loss 1.018784
[epoch13, step2363]: loss 1.399627
[epoch13, step2364]: loss 2.155895
[epoch13, step2365]: loss 15.628972
[epoch13, step2366]: loss 1.983473
[epoch13, step2367]: loss 0.934739
[epoch13, step2368]: loss 1.158879
[epoch13, step2369]: loss 1.874776
[epoch13, step2370]: loss 2.393683
[epoch13, step2371]: loss 1.222317
[epoch13, step2372]: loss 4.930247
[epoch13, step2373]: loss 6.004821
[epoch13, step2374]: loss 23.187548
[epoch13, step2375]: loss 1.055904
[epoch13, step2376]: loss 16.451160
[epoch13, step2377]: loss 1.819983
[epoch13, step2378]: loss 0.680608
[epoch13, step2379]: loss 0.949207
[epoch13, step2380]: loss 3.526837
[epoch13, step2381]: loss 0.845921
[epoch13, step2382]: loss 1.144611
[epoch13, step2383]: loss 3.712659
[epoch13, step2384]: loss 0.952127
[epoch13, step2385]: loss 14.324074
[epoch13, step2386]: loss 0.822657
[epoch13, step2387]: loss 2.286010
[epoch13, step2388]: loss 0.863574
[epoch13, step2389]: loss 1.206213
[epoch13, step2390]: loss 19.382568
[epoch13, step2391]: loss 8.276767
[epoch13, step2392]: loss 1.380128
[epoch13, step2393]: loss 1.353346
[epoch13, step2394]: loss 7.436817
[epoch13, step2395]: loss 5.049994
[epoch13, step2396]: loss 3.570315
[epoch13, step2397]: loss 1.196563
[epoch13, step2398]: loss 1.621648
[epoch13, step2399]: loss 0.940452
[epoch13, step2400]: loss 12.137230
[epoch13, step2401]: loss 1.378957
[epoch13, step2402]: loss 4.507641
[epoch13, step2403]: loss 1.837371
[epoch13, step2404]: loss 2.034486
[epoch13, step2405]: loss 1.886156
[epoch13, step2406]: loss 5.302795
[epoch13, step2407]: loss 1.425566
[epoch13, step2408]: loss 0.937385
[epoch13, step2409]: loss 9.759499
[epoch13, step2410]: loss 2.510339
[epoch13, step2411]: loss 1.504450
[epoch13, step2412]: loss 0.715874
[epoch13, step2413]: loss 14.102625
[epoch13, step2414]: loss 0.870243
[epoch13, step2415]: loss 1.159728
[epoch13, step2416]: loss 0.986578
[epoch13, step2417]: loss 7.114998
[epoch13, step2418]: loss 8.402199
[epoch13, step2419]: loss 3.951327
[epoch13, step2420]: loss 1.958366
[epoch13, step2421]: loss 1.170934
[epoch13, step2422]: loss 3.575031
[epoch13, step2423]: loss 0.944414
[epoch13, step2424]: loss 7.660198
[epoch13, step2425]: loss 1.784967
[epoch13, step2426]: loss 3.808581
[epoch13, step2427]: loss 2.205553
[epoch13, step2428]: loss 2.864052
[epoch13, step2429]: loss 2.951129
[epoch13, step2430]: loss 1.483191
[epoch13, step2431]: loss 14.983760
[epoch13, step2432]: loss 4.316033
[epoch13, step2433]: loss 1.494760
[epoch13, step2434]: loss 8.737761
[epoch13, step2435]: loss 4.979285
[epoch13, step2436]: loss 1.768124
[epoch13, step2437]: loss 49.220356
[epoch13, step2438]: loss 2.627993
[epoch13, step2439]: loss 4.728180
[epoch13, step2440]: loss 2.511659
[epoch13, step2441]: loss 1.923651
[epoch13, step2442]: loss 0.867167
[epoch13, step2443]: loss 2.570943
[epoch13, step2444]: loss 0.677089
[epoch13, step2445]: loss 3.301750
[epoch13, step2446]: loss 1.608595
[epoch13, step2447]: loss 2.236887
[epoch13, step2448]: loss 8.404218
[epoch13, step2449]: loss 3.902638
[epoch13, step2450]: loss 1.477418
[epoch13, step2451]: loss 12.247823
[epoch13, step2452]: loss 2.731370
[epoch13, step2453]: loss 12.162118
[epoch13, step2454]: loss 11.406820
[epoch13, step2455]: loss 7.433956
[epoch13, step2456]: loss 8.832943
[epoch13, step2457]: loss 1.256261
[epoch13, step2458]: loss 17.629183
[epoch13, step2459]: loss 0.589543
[epoch13, step2460]: loss 4.231348
[epoch13, step2461]: loss 2.826293
[epoch13, step2462]: loss 1.289016
[epoch13, step2463]: loss 9.985182
[epoch13, step2464]: loss 0.945167
[epoch13, step2465]: loss 4.830916
[epoch13, step2466]: loss 0.800363
[epoch13, step2467]: loss 1.591987
[epoch13, step2468]: loss 0.933197
[epoch13, step2469]: loss 1.354245
[epoch13, step2470]: loss 3.777152
[epoch13, step2471]: loss 0.995068
[epoch13, step2472]: loss 1.107442
[epoch13, step2473]: loss 0.745966
[epoch13, step2474]: loss 18.291582
[epoch13, step2475]: loss 15.280250
[epoch13, step2476]: loss 5.838624
[epoch13, step2477]: loss 1.690181
[epoch13, step2478]: loss 1.325766
[epoch13, step2479]: loss 2.790882
[epoch13, step2480]: loss 7.618077
[epoch13, step2481]: loss 20.877691
[epoch13, step2482]: loss 30.406015
[epoch13, step2483]: loss 1.264900
[epoch13, step2484]: loss 19.424082
[epoch13, step2485]: loss 7.844169
[epoch13, step2486]: loss 0.964834
[epoch13, step2487]: loss 1.144633
[epoch13, step2488]: loss 2.629483
[epoch13, step2489]: loss 1.324728
[epoch13, step2490]: loss 7.860813
[epoch13, step2491]: loss 2.673662
[epoch13, step2492]: loss 1.204408
[epoch13, step2493]: loss 11.274155
[epoch13, step2494]: loss 13.772234
[epoch13, step2495]: loss 0.627942
[epoch13, step2496]: loss 13.292754
[epoch13, step2497]: loss 0.692809
[epoch13, step2498]: loss 11.218988
[epoch13, step2499]: loss 0.898093
[epoch13, step2500]: loss 1.817760
[epoch13, step2501]: loss 0.946752
[epoch13, step2502]: loss 10.801799
[epoch13, step2503]: loss 0.742705
[epoch13, step2504]: loss 9.030169
[epoch13, step2505]: loss 3.245827
[epoch13, step2506]: loss 6.841593
[epoch13, step2507]: loss 11.563749
[epoch13, step2508]: loss 2.558912
[epoch13, step2509]: loss 3.251506
[epoch13, step2510]: loss 5.384703
[epoch13, step2511]: loss 0.716168
[epoch13, step2512]: loss 9.220586
[epoch13, step2513]: loss 0.904226
[epoch13, step2514]: loss 0.846192
[epoch13, step2515]: loss 3.315530
[epoch13, step2516]: loss 12.962136
[epoch13, step2517]: loss 4.267025
[epoch13, step2518]: loss 5.038473
[epoch13, step2519]: loss 24.716619
[epoch13, step2520]: loss 2.182827
[epoch13, step2521]: loss 18.632366
[epoch13, step2522]: loss 1.340091
[epoch13, step2523]: loss 1.925623
[epoch13, step2524]: loss 1.838040
[epoch13, step2525]: loss 7.216637
[epoch13, step2526]: loss 2.520782
[epoch13, step2527]: loss 5.282337
[epoch13, step2528]: loss 1.261325
[epoch13, step2529]: loss 19.021599
[epoch13, step2530]: loss 13.146184
[epoch13, step2531]: loss 6.721143
[epoch13, step2532]: loss 7.018266
[epoch13, step2533]: loss 1.128692
[epoch13, step2534]: loss 1.538773
[epoch13, step2535]: loss 2.334444
[epoch13, step2536]: loss 9.529097
[epoch13, step2537]: loss 1.881746
[epoch13, step2538]: loss 0.649438
[epoch13, step2539]: loss 29.123220
[epoch13, step2540]: loss 15.408665
[epoch13, step2541]: loss 0.812831
[epoch13, step2542]: loss 14.681128
[epoch13, step2543]: loss 1.457370
[epoch13, step2544]: loss 8.754460
[epoch13, step2545]: loss 1.030448
[epoch13, step2546]: loss 1.882480
[epoch13, step2547]: loss 0.923159
[epoch13, step2548]: loss 18.363243
[epoch13, step2549]: loss 2.754236
[epoch13, step2550]: loss 1.063339
[epoch13, step2551]: loss 2.408418
[epoch13, step2552]: loss 1.428069
[epoch13, step2553]: loss 2.103132
[epoch13, step2554]: loss 3.508283
[epoch13, step2555]: loss 1.554636
[epoch13, step2556]: loss 34.680588
[epoch13, step2557]: loss 1.350191
[epoch13, step2558]: loss 1.217971
[epoch13, step2559]: loss 8.088196
[epoch13, step2560]: loss 13.103735
[epoch13, step2561]: loss 1.921272
[epoch13, step2562]: loss 1.965182
[epoch13, step2563]: loss 1.298140
[epoch13, step2564]: loss 1.529240
[epoch13, step2565]: loss 15.454589
[epoch13, step2566]: loss 5.012541
[epoch13, step2567]: loss 0.744102
[epoch13, step2568]: loss 1.506781
[epoch13, step2569]: loss 1.671442
[epoch13, step2570]: loss 3.617722
[epoch13, step2571]: loss 0.980317
[epoch13, step2572]: loss 1.028240
[epoch13, step2573]: loss 5.279317
[epoch13, step2574]: loss 19.510633
[epoch13, step2575]: loss 3.892057
[epoch13, step2576]: loss 1.116557
[epoch13, step2577]: loss 11.943111
[epoch13, step2578]: loss 2.871615
[epoch13, step2579]: loss 4.289978
[epoch13, step2580]: loss 2.396793
[epoch13, step2581]: loss 19.273361
[epoch13, step2582]: loss 2.970635
[epoch13, step2583]: loss 0.981432
[epoch13, step2584]: loss 1.202219
[epoch13, step2585]: loss 11.431211
[epoch13, step2586]: loss 2.995011
[epoch13, step2587]: loss 0.727800
[epoch13, step2588]: loss 9.795080
[epoch13, step2589]: loss 1.623565
[epoch13, step2590]: loss 1.739820
[epoch13, step2591]: loss 1.062096
[epoch13, step2592]: loss 1.271629
[epoch13, step2593]: loss 3.454853
[epoch13, step2594]: loss 2.859661
[epoch13, step2595]: loss 0.992521
[epoch13, step2596]: loss 0.972941
[epoch13, step2597]: loss 1.861965
[epoch13, step2598]: loss 1.158779
[epoch13, step2599]: loss 3.245075
[epoch13, step2600]: loss 2.868827
[epoch13, step2601]: loss 0.805902
[epoch13, step2602]: loss 10.865590
[epoch13, step2603]: loss 6.072337
[epoch13, step2604]: loss 8.889121
[epoch13, step2605]: loss 0.997414
[epoch13, step2606]: loss 6.019506
[epoch13, step2607]: loss 1.286900
[epoch13, step2608]: loss 9.550343
[epoch13, step2609]: loss 2.019585
[epoch13, step2610]: loss 2.246301
[epoch13, step2611]: loss 2.542621
[epoch13, step2612]: loss 7.078084
[epoch13, step2613]: loss 12.619466
[epoch13, step2614]: loss 16.398100
[epoch13, step2615]: loss 1.341262
[epoch13, step2616]: loss 8.404937
[epoch13, step2617]: loss 1.856493
[epoch13, step2618]: loss 0.713762
[epoch13, step2619]: loss 12.477170
[epoch13, step2620]: loss 3.391594
[epoch13, step2621]: loss 22.524000
[epoch13, step2622]: loss 6.528754
[epoch13, step2623]: loss 1.771180
[epoch13, step2624]: loss 9.698903
[epoch13, step2625]: loss 2.250798
[epoch13, step2626]: loss 1.226125
[epoch13, step2627]: loss 12.341469
[epoch13, step2628]: loss 4.660457
[epoch13, step2629]: loss 4.286104
[epoch13, step2630]: loss 1.106226
[epoch13, step2631]: loss 8.814276
[epoch13, step2632]: loss 2.380571
[epoch13, step2633]: loss 14.178947
[epoch13, step2634]: loss 10.501649
[epoch13, step2635]: loss 1.260178
[epoch13, step2636]: loss 5.215873
[epoch13, step2637]: loss 4.994448
[epoch13, step2638]: loss 1.876312
[epoch13, step2639]: loss 0.672075
[epoch13, step2640]: loss 7.457217
[epoch13, step2641]: loss 26.689863
[epoch13, step2642]: loss 3.717260
[epoch13, step2643]: loss 1.737551
[epoch13, step2644]: loss 9.545417
[epoch13, step2645]: loss 0.858619
[epoch13, step2646]: loss 3.114057
[epoch13, step2647]: loss 1.960379
[epoch13, step2648]: loss 7.944771
[epoch13, step2649]: loss 1.366488
[epoch13, step2650]: loss 1.040061
[epoch13, step2651]: loss 7.666926
[epoch13, step2652]: loss 3.315670
[epoch13, step2653]: loss 1.505490
[epoch13, step2654]: loss 2.283362
[epoch13, step2655]: loss 3.927140
[epoch13, step2656]: loss 1.461516
[epoch13, step2657]: loss 1.367434
[epoch13, step2658]: loss 0.913733
[epoch13, step2659]: loss 0.939544
[epoch13, step2660]: loss 1.490486
[epoch13, step2661]: loss 19.111893
[epoch13, step2662]: loss 17.974508
[epoch13, step2663]: loss 1.333922
[epoch13, step2664]: loss 1.013548
[epoch13, step2665]: loss 2.742970
[epoch13, step2666]: loss 0.682051
[epoch13, step2667]: loss 1.051838
[epoch13, step2668]: loss 9.409451
[epoch13, step2669]: loss 0.738955
[epoch13, step2670]: loss 1.474266
[epoch13, step2671]: loss 0.910171
[epoch13, step2672]: loss 13.160072
[epoch13, step2673]: loss 1.667073
[epoch13, step2674]: loss 17.845112
[epoch13, step2675]: loss 2.353264
[epoch13, step2676]: loss 1.463087
[epoch13, step2677]: loss 3.731571
[epoch13, step2678]: loss 1.436644
[epoch13, step2679]: loss 1.752329
[epoch13, step2680]: loss 5.382006
[epoch13, step2681]: loss 2.391145
[epoch13, step2682]: loss 2.235622
[epoch13, step2683]: loss 4.715629
[epoch13, step2684]: loss 2.471393
[epoch13, step2685]: loss 0.920864
[epoch13, step2686]: loss 3.505143
[epoch13, step2687]: loss 11.190551
[epoch13, step2688]: loss 2.878320
[epoch13, step2689]: loss 1.359931
[epoch13, step2690]: loss 1.609283
[epoch13, step2691]: loss 5.209579
[epoch13, step2692]: loss 1.464717
[epoch13, step2693]: loss 4.129056
[epoch13, step2694]: loss 1.395388
[epoch13, step2695]: loss 1.298377
[epoch13, step2696]: loss 14.102739
[epoch13, step2697]: loss 12.585745
[epoch13, step2698]: loss 1.228067
[epoch13, step2699]: loss 0.537956
[epoch13, step2700]: loss 0.979756
[epoch13, step2701]: loss 1.347842
[epoch13, step2702]: loss 1.051476
[epoch13, step2703]: loss 40.092598
[epoch13, step2704]: loss 4.864917
[epoch13, step2705]: loss 2.720191
[epoch13, step2706]: loss 3.406519
[epoch13, step2707]: loss 16.469259
[epoch13, step2708]: loss 1.495754
[epoch13, step2709]: loss 1.071308
[epoch13, step2710]: loss 0.619553
[epoch13, step2711]: loss 3.128588
[epoch13, step2712]: loss 8.008951
[epoch13, step2713]: loss 1.726514
[epoch13, step2714]: loss 0.565213
[epoch13, step2715]: loss 0.920251
[epoch13, step2716]: loss 4.360157
[epoch13, step2717]: loss 5.495901
[epoch13, step2718]: loss 6.174772
[epoch13, step2719]: loss 1.096543
[epoch13, step2720]: loss 1.679773
[epoch13, step2721]: loss 2.969787
[epoch13, step2722]: loss 5.440760
[epoch13, step2723]: loss 1.679821
[epoch13, step2724]: loss 2.239273
[epoch13, step2725]: loss 13.231050
[epoch13, step2726]: loss 12.294657
[epoch13, step2727]: loss 4.087116
[epoch13, step2728]: loss 0.703367
[epoch13, step2729]: loss 5.436709
[epoch13, step2730]: loss 4.979898
[epoch13, step2731]: loss 1.173040
[epoch13, step2732]: loss 1.013369
[epoch13, step2733]: loss 3.766624
[epoch13, step2734]: loss 0.815681
[epoch13, step2735]: loss 6.533649
[epoch13, step2736]: loss 1.684409
[epoch13, step2737]: loss 0.977444
[epoch13, step2738]: loss 10.036805
[epoch13, step2739]: loss 1.481780
[epoch13, step2740]: loss 4.099339
[epoch13, step2741]: loss 3.462500
[epoch13, step2742]: loss 1.367268
[epoch13, step2743]: loss 3.478858
[epoch13, step2744]: loss 3.775950
[epoch13, step2745]: loss 1.163437
[epoch13, step2746]: loss 2.278196
[epoch13, step2747]: loss 1.676498
[epoch13, step2748]: loss 2.314275
[epoch13, step2749]: loss 8.797526
[epoch13, step2750]: loss 6.694359
[epoch13, step2751]: loss 9.788244
[epoch13, step2752]: loss 3.595715
[epoch13, step2753]: loss 0.969191
[epoch13, step2754]: loss 1.034027
[epoch13, step2755]: loss 1.710760
[epoch13, step2756]: loss 1.286604
[epoch13, step2757]: loss 6.988286
[epoch13, step2758]: loss 2.501984
[epoch13, step2759]: loss 3.320435
[epoch13, step2760]: loss 1.975129
[epoch13, step2761]: loss 12.186693
[epoch13, step2762]: loss 0.837819
[epoch13, step2763]: loss 13.693369
[epoch13, step2764]: loss 1.286614
[epoch13, step2765]: loss 3.166893
[epoch13, step2766]: loss 10.910516
[epoch13, step2767]: loss 13.571856
[epoch13, step2768]: loss 2.345658
[epoch13, step2769]: loss 6.737967
[epoch13, step2770]: loss 3.139678
[epoch13, step2771]: loss 1.099183
[epoch13, step2772]: loss 1.261117
[epoch13, step2773]: loss 3.034434
[epoch13, step2774]: loss 8.310304
[epoch13, step2775]: loss 1.425073
[epoch13, step2776]: loss 32.559742
[epoch13, step2777]: loss 1.958457
[epoch13, step2778]: loss 2.131111
[epoch13, step2779]: loss 1.820735
[epoch13, step2780]: loss 1.131670
[epoch13, step2781]: loss 0.618372
[epoch13, step2782]: loss 2.876101
[epoch13, step2783]: loss 1.740038
[epoch13, step2784]: loss 1.241026
[epoch13, step2785]: loss 1.782126
[epoch13, step2786]: loss 12.142394
[epoch13, step2787]: loss 9.415182
[epoch13, step2788]: loss 1.704590
[epoch13, step2789]: loss 8.099033
[epoch13, step2790]: loss 2.332120
[epoch13, step2791]: loss 2.245645
[epoch13, step2792]: loss 1.159092
[epoch13, step2793]: loss 1.002204
[epoch13, step2794]: loss 1.381376
[epoch13, step2795]: loss 5.232736
[epoch13, step2796]: loss 0.913637
[epoch13, step2797]: loss 7.848039
[epoch13, step2798]: loss 6.623946
[epoch13, step2799]: loss 18.977636
[epoch13, step2800]: loss 3.278288
[epoch13, step2801]: loss 3.635893
[epoch13, step2802]: loss 1.348326
[epoch13, step2803]: loss 1.393809
[epoch13, step2804]: loss 0.879115
[epoch13, step2805]: loss 1.251702
[epoch13, step2806]: loss 1.428594
[epoch13, step2807]: loss 0.933682
[epoch13, step2808]: loss 2.696058
[epoch13, step2809]: loss 1.244243
[epoch13, step2810]: loss 1.904339
[epoch13, step2811]: loss 1.273929
[epoch13, step2812]: loss 0.877064
[epoch13, step2813]: loss 4.743925
[epoch13, step2814]: loss 1.957370
[epoch13, step2815]: loss 8.739679
[epoch13, step2816]: loss 8.275670
[epoch13, step2817]: loss 3.808377
[epoch13, step2818]: loss 4.146582
[epoch13, step2819]: loss 9.641143
[epoch13, step2820]: loss 8.793535
[epoch13, step2821]: loss 0.707552
[epoch13, step2822]: loss 4.801755
[epoch13, step2823]: loss 0.644597
[epoch13, step2824]: loss 1.545933
[epoch13, step2825]: loss 9.553165
[epoch13, step2826]: loss 3.620136
[epoch13, step2827]: loss 0.649866
[epoch13, step2828]: loss 0.854364
[epoch13, step2829]: loss 2.395804
[epoch13, step2830]: loss 3.046555
[epoch13, step2831]: loss 1.824359
[epoch13, step2832]: loss 1.062814
[epoch13, step2833]: loss 6.809535
[epoch13, step2834]: loss 3.448785
[epoch13, step2835]: loss 1.804616
[epoch13, step2836]: loss 2.269825
[epoch13, step2837]: loss 2.518490
[epoch13, step2838]: loss 7.296191
[epoch13, step2839]: loss 1.231569
[epoch13, step2840]: loss 6.408737
[epoch13, step2841]: loss 4.493577
[epoch13, step2842]: loss 1.740880
[epoch13, step2843]: loss 1.299716
[epoch13, step2844]: loss 2.028368
[epoch13, step2845]: loss 0.980505
[epoch13, step2846]: loss 1.261994
[epoch13, step2847]: loss 1.760666
[epoch13, step2848]: loss 34.959312
[epoch13, step2849]: loss 0.623669
[epoch13, step2850]: loss 13.961526
[epoch13, step2851]: loss 14.682730
[epoch13, step2852]: loss 3.303073
[epoch13, step2853]: loss 1.375476
[epoch13, step2854]: loss 2.545217
[epoch13, step2855]: loss 13.024660
[epoch13, step2856]: loss 0.993234
[epoch13, step2857]: loss 1.854545
[epoch13, step2858]: loss 2.275114
[epoch13, step2859]: loss 1.710001
[epoch13, step2860]: loss 9.574469
[epoch13, step2861]: loss 0.853942
[epoch13, step2862]: loss 1.043808
[epoch13, step2863]: loss 1.113919
[epoch13, step2864]: loss 1.070043
[epoch13, step2865]: loss 0.687954
[epoch13, step2866]: loss 28.059469
[epoch13, step2867]: loss 0.981416
[epoch13, step2868]: loss 1.670023
[epoch13, step2869]: loss 1.233808
[epoch13, step2870]: loss 0.950155
[epoch13, step2871]: loss 1.371386
[epoch13, step2872]: loss 0.562908
[epoch13, step2873]: loss 2.457461
[epoch13, step2874]: loss 1.086602
[epoch13, step2875]: loss 3.594313
[epoch13, step2876]: loss 8.714025
[epoch13, step2877]: loss 2.296388
[epoch13, step2878]: loss 4.070311
[epoch13, step2879]: loss 1.261480
[epoch13, step2880]: loss 0.937663
[epoch13, step2881]: loss 8.580015
[epoch13, step2882]: loss 2.129729
[epoch13, step2883]: loss 1.015640
[epoch13, step2884]: loss 0.830502
[epoch13, step2885]: loss 3.361079
[epoch13, step2886]: loss 2.236577
[epoch13, step2887]: loss 0.721091
[epoch13, step2888]: loss 2.483903
[epoch13, step2889]: loss 15.306848
[epoch13, step2890]: loss 1.203454
[epoch13, step2891]: loss 1.369769
[epoch13, step2892]: loss 1.436025
[epoch13, step2893]: loss 2.671288
[epoch13, step2894]: loss 0.687545
[epoch13, step2895]: loss 1.847721
[epoch13, step2896]: loss 9.955750
[epoch13, step2897]: loss 10.640791
[epoch13, step2898]: loss 9.037798
[epoch13, step2899]: loss 3.312660
[epoch13, step2900]: loss 6.277225
[epoch13, step2901]: loss 2.117470
[epoch13, step2902]: loss 1.117022
[epoch13, step2903]: loss 11.500213
[epoch13, step2904]: loss 10.315089
[epoch13, step2905]: loss 12.100584
[epoch13, step2906]: loss 2.417533
[epoch13, step2907]: loss 0.841149
[epoch13, step2908]: loss 1.175285
[epoch13, step2909]: loss 1.485692
[epoch13, step2910]: loss 2.500956
[epoch13, step2911]: loss 3.100035
[epoch13, step2912]: loss 5.727571
[epoch13, step2913]: loss 5.681685
[epoch13, step2914]: loss 8.580667
[epoch13, step2915]: loss 2.564015
[epoch13, step2916]: loss 3.262727
[epoch13, step2917]: loss 0.946119
[epoch13, step2918]: loss 17.169065
[epoch13, step2919]: loss 1.521090
[epoch13, step2920]: loss 2.039731
[epoch13, step2921]: loss 8.129230
[epoch13, step2922]: loss 17.675571
[epoch13, step2923]: loss 20.655302
[epoch13, step2924]: loss 1.037469
[epoch13, step2925]: loss 1.726326
[epoch13, step2926]: loss 15.179750
[epoch13, step2927]: loss 2.876761
[epoch13, step2928]: loss 9.377208
[epoch13, step2929]: loss 17.698902
[epoch13, step2930]: loss 1.135026
[epoch13, step2931]: loss 1.874500
[epoch13, step2932]: loss 1.524185
[epoch13, step2933]: loss 17.793764
[epoch13, step2934]: loss 7.260665
[epoch13, step2935]: loss 16.216900
[epoch13, step2936]: loss 1.264636
[epoch13, step2937]: loss 1.234584
[epoch13, step2938]: loss 7.141812
[epoch13, step2939]: loss 2.556513
[epoch13, step2940]: loss 1.951029
[epoch13, step2941]: loss 2.427942
[epoch13, step2942]: loss 2.450737
[epoch13, step2943]: loss 2.818147
[epoch13, step2944]: loss 11.180641
[epoch13, step2945]: loss 1.141977
[epoch13, step2946]: loss 4.479734
[epoch13, step2947]: loss 3.589549
[epoch13, step2948]: loss 1.074166
[epoch13, step2949]: loss 1.619342
[epoch13, step2950]: loss 8.490318
[epoch13, step2951]: loss 2.261463
[epoch13, step2952]: loss 13.986201
[epoch13, step2953]: loss 1.166652
[epoch13, step2954]: loss 8.067175
[epoch13, step2955]: loss 12.003292
[epoch13, step2956]: loss 15.226684
[epoch13, step2957]: loss 12.750723
[epoch13, step2958]: loss 0.916800
[epoch13, step2959]: loss 3.469037
[epoch13, step2960]: loss 2.623617
[epoch13, step2961]: loss 7.684834
[epoch13, step2962]: loss 1.128377
[epoch13, step2963]: loss 1.581248
[epoch13, step2964]: loss 18.857536
[epoch13, step2965]: loss 1.561376
[epoch13, step2966]: loss 0.878004
[epoch13, step2967]: loss 7.043794
[epoch13, step2968]: loss 11.799528
[epoch13, step2969]: loss 2.455271
[epoch13, step2970]: loss 1.149165
[epoch13, step2971]: loss 19.841496
[epoch13, step2972]: loss 1.073509
[epoch13, step2973]: loss 0.838465
[epoch13, step2974]: loss 1.737327
[epoch13, step2975]: loss 1.244225
[epoch13, step2976]: loss 13.567628
[epoch13, step2977]: loss 4.622543
[epoch13, step2978]: loss 3.082053
[epoch13, step2979]: loss 22.809544
[epoch13, step2980]: loss 2.142100
[epoch13, step2981]: loss 17.461836
[epoch13, step2982]: loss 0.917189
[epoch13, step2983]: loss 12.412361
[epoch13, step2984]: loss 3.288655
[epoch13, step2985]: loss 9.890985
[epoch13, step2986]: loss 4.605783
[epoch13, step2987]: loss 2.780089
[epoch13, step2988]: loss 1.294172
[epoch13, step2989]: loss 1.284725
[epoch13, step2990]: loss 1.033099
[epoch13, step2991]: loss 2.344498
[epoch13, step2992]: loss 11.467519
[epoch13, step2993]: loss 2.148850
[epoch13, step2994]: loss 1.827036
[epoch13, step2995]: loss 0.656757
[epoch13, step2996]: loss 0.998962
[epoch13, step2997]: loss 2.123893
[epoch13, step2998]: loss 1.489532
[epoch13, step2999]: loss 2.404506
[epoch13, step3000]: loss 1.209849
[epoch13, step3001]: loss 8.568621
[epoch13, step3002]: loss 1.161306
[epoch13, step3003]: loss 4.954924
[epoch13, step3004]: loss 1.416739
[epoch13, step3005]: loss 2.970709
[epoch13, step3006]: loss 2.157000
[epoch13, step3007]: loss 1.080507
[epoch13, step3008]: loss 15.283400
[epoch13, step3009]: loss 1.330978
[epoch13, step3010]: loss 1.123207
[epoch13, step3011]: loss 3.130359
[epoch13, step3012]: loss 1.063892
[epoch13, step3013]: loss 2.691120
[epoch13, step3014]: loss 33.346661
[epoch13, step3015]: loss 2.140188
[epoch13, step3016]: loss 4.790675
[epoch13, step3017]: loss 0.880551
[epoch13, step3018]: loss 4.736918
[epoch13, step3019]: loss 16.744762
[epoch13, step3020]: loss 12.654963
[epoch13, step3021]: loss 1.549483
[epoch13, step3022]: loss 0.703777
[epoch13, step3023]: loss 1.864405
[epoch13, step3024]: loss 8.900952
[epoch13, step3025]: loss 3.876998
[epoch13, step3026]: loss 11.549417
[epoch13, step3027]: loss 1.154652
[epoch13, step3028]: loss 2.281419
[epoch13, step3029]: loss 10.999404
[epoch13, step3030]: loss 1.167402
[epoch13, step3031]: loss 2.464533
[epoch13, step3032]: loss 17.165848
[epoch13, step3033]: loss 1.028471
[epoch13, step3034]: loss 1.194586
[epoch13, step3035]: loss 23.549835
[epoch13, step3036]: loss 8.390169
[epoch13, step3037]: loss 2.286769
[epoch13, step3038]: loss 17.196695
[epoch13, step3039]: loss 1.299187
[epoch13, step3040]: loss 3.984306
[epoch13, step3041]: loss 1.829296
[epoch13, step3042]: loss 1.853893
[epoch13, step3043]: loss 3.985636
[epoch13, step3044]: loss 3.773474
[epoch13, step3045]: loss 9.604927
[epoch13, step3046]: loss 5.926840
[epoch13, step3047]: loss 1.611089
[epoch13, step3048]: loss 0.856102
[epoch13, step3049]: loss 1.241871
[epoch13, step3050]: loss 2.060044
[epoch13, step3051]: loss 11.015485
[epoch13, step3052]: loss 6.342661
[epoch13, step3053]: loss 5.456481
[epoch13, step3054]: loss 0.849956
[epoch13, step3055]: loss 1.851818
[epoch13, step3056]: loss 2.771542
[epoch13, step3057]: loss 3.786925
[epoch13, step3058]: loss 3.673597
[epoch13, step3059]: loss 3.568634
[epoch13, step3060]: loss 2.015008
[epoch13, step3061]: loss 3.822046
[epoch13, step3062]: loss 1.552428
[epoch13, step3063]: loss 1.503037
[epoch13, step3064]: loss 2.395135
[epoch13, step3065]: loss 2.262271
[epoch13, step3066]: loss 1.243235
[epoch13, step3067]: loss 13.233090
[epoch13, step3068]: loss 1.407767
[epoch13, step3069]: loss 2.021544
[epoch13, step3070]: loss 2.024478
[epoch13, step3071]: loss 2.410450
[epoch13, step3072]: loss 2.456143
[epoch13, step3073]: loss 0.789287
[epoch13, step3074]: loss 1.057233
[epoch13, step3075]: loss 3.241406
[epoch13, step3076]: loss 2.373545

[epoch13]: avg loss 2.373545

[epoch14, step1]: loss 1.600359
[epoch14, step2]: loss 8.506014
[epoch14, step3]: loss 0.711580
[epoch14, step4]: loss 1.121784
[epoch14, step5]: loss 3.489991
[epoch14, step6]: loss 0.719889
[epoch14, step7]: loss 1.964212
[epoch14, step8]: loss 10.807433
[epoch14, step9]: loss 1.162849
[epoch14, step10]: loss 15.570312
[epoch14, step11]: loss 7.006453
[epoch14, step12]: loss 29.848024
[epoch14, step13]: loss 3.509957
[epoch14, step14]: loss 13.172977
[epoch14, step15]: loss 1.544705
[epoch14, step16]: loss 3.483942
[epoch14, step17]: loss 2.203830
[epoch14, step18]: loss 16.361414
[epoch14, step19]: loss 3.515168
[epoch14, step20]: loss 1.242270
[epoch14, step21]: loss 1.590905
[epoch14, step22]: loss 2.184906
[epoch14, step23]: loss 5.457127
[epoch14, step24]: loss 1.346068
[epoch14, step25]: loss 30.370161
[epoch14, step26]: loss 1.659575
[epoch14, step27]: loss 6.040564
[epoch14, step28]: loss 2.467363
[epoch14, step29]: loss 2.517375
[epoch14, step30]: loss 2.540030
[epoch14, step31]: loss 15.536019
[epoch14, step32]: loss 10.249027
[epoch14, step33]: loss 4.143147
[epoch14, step34]: loss 10.764711
[epoch14, step35]: loss 1.456537
[epoch14, step36]: loss 1.065036
[epoch14, step37]: loss 16.236584
[epoch14, step38]: loss 11.098078
[epoch14, step39]: loss 5.539699
[epoch14, step40]: loss 2.280543
[epoch14, step41]: loss 2.238737
[epoch14, step42]: loss 1.368371
[epoch14, step43]: loss 5.760171
[epoch14, step44]: loss 1.286076
[epoch14, step45]: loss 4.058696
[epoch14, step46]: loss 1.082085
[epoch14, step47]: loss 1.347523
[epoch14, step48]: loss 4.363815
[epoch14, step49]: loss 0.735386
[epoch14, step50]: loss 1.090440
[epoch14, step51]: loss 1.173360
[epoch14, step52]: loss 12.421461
[epoch14, step53]: loss 6.402287
[epoch14, step54]: loss 1.705673
[epoch14, step55]: loss 1.126835
[epoch14, step56]: loss 1.654977
[epoch14, step57]: loss 0.626129
[epoch14, step58]: loss 1.755949
[epoch14, step59]: loss 1.842884
[epoch14, step60]: loss 14.787471
[epoch14, step61]: loss 1.937186
[epoch14, step62]: loss 8.420082
[epoch14, step63]: loss 3.526032
[epoch14, step64]: loss 1.827994
[epoch14, step65]: loss 1.684646
[epoch14, step66]: loss 9.412402
[epoch14, step67]: loss 18.648766
[epoch14, step68]: loss 16.398111
[epoch14, step69]: loss 0.987445
[epoch14, step70]: loss 1.186250
[epoch14, step71]: loss 2.695048
[epoch14, step72]: loss 0.787852
[epoch14, step73]: loss 2.334619
[epoch14, step74]: loss 0.648911
[epoch14, step75]: loss 4.066499
[epoch14, step76]: loss 1.341727
[epoch14, step77]: loss 1.819654
[epoch14, step78]: loss 2.726130
[epoch14, step79]: loss 13.676374
[epoch14, step80]: loss 8.727640
[epoch14, step81]: loss 1.938520
[epoch14, step82]: loss 0.812103
[epoch14, step83]: loss 0.922090
[epoch14, step84]: loss 7.026987
[epoch14, step85]: loss 1.260582
[epoch14, step86]: loss 2.244915
[epoch14, step87]: loss 3.048259
[epoch14, step88]: loss 4.951107
[epoch14, step89]: loss 18.074625
[epoch14, step90]: loss 1.770211
[epoch14, step91]: loss 11.494341
[epoch14, step92]: loss 2.412560
[epoch14, step93]: loss 10.415790
[epoch14, step94]: loss 6.760421
[epoch14, step95]: loss 0.875865
[epoch14, step96]: loss 15.856291
[epoch14, step97]: loss 1.289481
[epoch14, step98]: loss 1.172792
[epoch14, step99]: loss 0.569918
[epoch14, step100]: loss 2.121379
[epoch14, step101]: loss 0.918999
[epoch14, step102]: loss 0.836823
[epoch14, step103]: loss 0.726703
[epoch14, step104]: loss 1.019054
[epoch14, step105]: loss 0.855359
[epoch14, step106]: loss 5.599130
[epoch14, step107]: loss 1.038583
[epoch14, step108]: loss 2.016147
[epoch14, step109]: loss 1.626102
[epoch14, step110]: loss 1.207398
[epoch14, step111]: loss 0.817790
[epoch14, step112]: loss 8.907532
[epoch14, step113]: loss 0.981048
[epoch14, step114]: loss 0.747302
[epoch14, step115]: loss 1.516423
[epoch14, step116]: loss 1.700606
[epoch14, step117]: loss 8.748762
[epoch14, step118]: loss 0.727184
[epoch14, step119]: loss 1.608007
[epoch14, step120]: loss 1.683699
[epoch14, step121]: loss 13.919819
[epoch14, step122]: loss 2.500519
[epoch14, step123]: loss 1.365278
[epoch14, step124]: loss 0.698613
[epoch14, step125]: loss 0.673986
[epoch14, step126]: loss 1.523573
[epoch14, step127]: loss 3.778331
[epoch14, step128]: loss 2.197491
[epoch14, step129]: loss 2.622914
[epoch14, step130]: loss 1.317247
[epoch14, step131]: loss 0.667733
[epoch14, step132]: loss 0.706859
[epoch14, step133]: loss 2.512790
[epoch14, step134]: loss 12.255226
[epoch14, step135]: loss 1.515702
[epoch14, step136]: loss 1.776505
[epoch14, step137]: loss 5.108564
[epoch14, step138]: loss 2.461970
[epoch14, step139]: loss 4.276074
[epoch14, step140]: loss 3.459056
[epoch14, step141]: loss 3.148633
[epoch14, step142]: loss 0.803017
[epoch14, step143]: loss 1.326170
[epoch14, step144]: loss 1.538208
[epoch14, step145]: loss 1.999184
[epoch14, step146]: loss 2.377308
[epoch14, step147]: loss 1.686106
[epoch14, step148]: loss 0.960383
[epoch14, step149]: loss 1.308275
[epoch14, step150]: loss 1.016462
[epoch14, step151]: loss 0.791649
[epoch14, step152]: loss 15.419094
[epoch14, step153]: loss 2.681568
[epoch14, step154]: loss 2.985689
[epoch14, step155]: loss 2.964032
[epoch14, step156]: loss 0.821393
[epoch14, step157]: loss 8.981828
[epoch14, step158]: loss 14.333848
[epoch14, step159]: loss 1.363031
[epoch14, step160]: loss 12.681093
[epoch14, step161]: loss 1.465862
[epoch14, step162]: loss 5.357700
[epoch14, step163]: loss 0.990138
[epoch14, step164]: loss 1.873457
[epoch14, step165]: loss 1.010585
[epoch14, step166]: loss 10.417011
[epoch14, step167]: loss 1.219476
[epoch14, step168]: loss 1.001400
[epoch14, step169]: loss 18.475430
[epoch14, step170]: loss 8.105852
[epoch14, step171]: loss 1.230064
[epoch14, step172]: loss 7.941926
[epoch14, step173]: loss 1.803913
[epoch14, step174]: loss 1.330035
[epoch14, step175]: loss 8.239218
[epoch14, step176]: loss 12.311851
[epoch14, step177]: loss 9.064522
[epoch14, step178]: loss 6.619527
[epoch14, step179]: loss 1.014489
[epoch14, step180]: loss 1.466022
[epoch14, step181]: loss 9.737844
[epoch14, step182]: loss 15.361774
[epoch14, step183]: loss 3.079132
[epoch14, step184]: loss 1.934885
[epoch14, step185]: loss 0.840862
[epoch14, step186]: loss 2.151603
[epoch14, step187]: loss 0.986571
[epoch14, step188]: loss 3.492939
[epoch14, step189]: loss 1.825488
[epoch14, step190]: loss 9.609097
[epoch14, step191]: loss 2.164932
[epoch14, step192]: loss 7.644966
[epoch14, step193]: loss 1.911227
[epoch14, step194]: loss 17.708515
[epoch14, step195]: loss 3.134692
[epoch14, step196]: loss 4.541361
[epoch14, step197]: loss 2.076980
[epoch14, step198]: loss 2.676447
[epoch14, step199]: loss 2.282174
[epoch14, step200]: loss 1.637893
[epoch14, step201]: loss 2.197770
[epoch14, step202]: loss 12.888336
[epoch14, step203]: loss 15.657823
[epoch14, step204]: loss 0.923426
[epoch14, step205]: loss 4.150448
[epoch14, step206]: loss 3.309594
[epoch14, step207]: loss 1.140154
[epoch14, step208]: loss 1.142057
[epoch14, step209]: loss 3.516640
[epoch14, step210]: loss 3.805856
[epoch14, step211]: loss 2.738243
[epoch14, step212]: loss 0.678731
[epoch14, step213]: loss 0.969973
[epoch14, step214]: loss 9.387974
[epoch14, step215]: loss 1.136409
[epoch14, step216]: loss 3.025567
[epoch14, step217]: loss 19.342955
[epoch14, step218]: loss 1.527607
[epoch14, step219]: loss 1.051332
[epoch14, step220]: loss 1.394228
[epoch14, step221]: loss 1.798902
[epoch14, step222]: loss 0.875039
[epoch14, step223]: loss 0.601482
[epoch14, step224]: loss 1.588960
[epoch14, step225]: loss 0.642045
[epoch14, step226]: loss 15.206337
[epoch14, step227]: loss 5.805580
[epoch14, step228]: loss 1.725744
[epoch14, step229]: loss 4.590966
[epoch14, step230]: loss 1.113210
[epoch14, step231]: loss 2.568659
[epoch14, step232]: loss 2.593267
[epoch14, step233]: loss 1.500942
[epoch14, step234]: loss 0.989998
[epoch14, step235]: loss 13.488277
[epoch14, step236]: loss 3.115388
[epoch14, step237]: loss 2.373189
[epoch14, step238]: loss 1.420948
[epoch14, step239]: loss 2.509321
[epoch14, step240]: loss 3.882689
[epoch14, step241]: loss 3.065785
[epoch14, step242]: loss 14.475744
[epoch14, step243]: loss 2.128357
[epoch14, step244]: loss 1.003102
[epoch14, step245]: loss 2.247286
[epoch14, step246]: loss 1.069010
[epoch14, step247]: loss 1.292810
[epoch14, step248]: loss 4.927685
[epoch14, step249]: loss 5.465816
[epoch14, step250]: loss 3.895007
[epoch14, step251]: loss 10.561728
[epoch14, step252]: loss 0.980428
[epoch14, step253]: loss 1.232063
[epoch14, step254]: loss 1.716866
[epoch14, step255]: loss 2.697537
[epoch14, step256]: loss 4.623013
[epoch14, step257]: loss 0.962260
[epoch14, step258]: loss 2.073222
[epoch14, step259]: loss 1.520396
[epoch14, step260]: loss 2.243903
[epoch14, step261]: loss 1.425662
[epoch14, step262]: loss 17.002249
[epoch14, step263]: loss 2.416656
[epoch14, step264]: loss 10.115080
[epoch14, step265]: loss 0.774430
[epoch14, step266]: loss 1.048350
[epoch14, step267]: loss 30.637436
[epoch14, step268]: loss 0.878702
[epoch14, step269]: loss 17.581135
[epoch14, step270]: loss 1.897945
[epoch14, step271]: loss 1.126481
[epoch14, step272]: loss 26.010160
[epoch14, step273]: loss 1.355063
[epoch14, step274]: loss 1.182743
[epoch14, step275]: loss 1.309652
[epoch14, step276]: loss 8.469690
[epoch14, step277]: loss 1.363850
[epoch14, step278]: loss 2.638421
[epoch14, step279]: loss 0.757441
[epoch14, step280]: loss 3.606929
[epoch14, step281]: loss 11.107951
[epoch14, step282]: loss 0.989768
[epoch14, step283]: loss 14.542100
[epoch14, step284]: loss 0.594228
[epoch14, step285]: loss 11.272265
[epoch14, step286]: loss 1.600874
[epoch14, step287]: loss 5.398165
[epoch14, step288]: loss 3.249239
[epoch14, step289]: loss 0.956351
[epoch14, step290]: loss 11.486328
[epoch14, step291]: loss 1.877330
[epoch14, step292]: loss 12.838621
[epoch14, step293]: loss 24.212328
[epoch14, step294]: loss 2.328549
[epoch14, step295]: loss 7.655118
[epoch14, step296]: loss 1.642453
[epoch14, step297]: loss 8.622996
[epoch14, step298]: loss 0.809486
[epoch14, step299]: loss 10.996151
[epoch14, step300]: loss 0.803031
[epoch14, step301]: loss 0.765864
[epoch14, step302]: loss 2.532098
[epoch14, step303]: loss 0.959421
[epoch14, step304]: loss 2.642425
[epoch14, step305]: loss 0.652268
[epoch14, step306]: loss 2.568591
[epoch14, step307]: loss 1.234941
[epoch14, step308]: loss 9.930789
[epoch14, step309]: loss 13.005156
[epoch14, step310]: loss 2.719055
[epoch14, step311]: loss 7.429467
[epoch14, step312]: loss 1.147659
[epoch14, step313]: loss 3.651353
[epoch14, step314]: loss 1.596670
[epoch14, step315]: loss 21.702972
[epoch14, step316]: loss 2.386849
[epoch14, step317]: loss 0.644663
[epoch14, step318]: loss 1.819666
[epoch14, step319]: loss 4.928674
[epoch14, step320]: loss 1.342870
[epoch14, step321]: loss 1.088108
[epoch14, step322]: loss 0.670918
[epoch14, step323]: loss 2.044664
[epoch14, step324]: loss 1.278476
[epoch14, step325]: loss 1.143919
[epoch14, step326]: loss 20.646830
[epoch14, step327]: loss 0.954162
[epoch14, step328]: loss 2.051171
[epoch14, step329]: loss 5.867159
[epoch14, step330]: loss 1.294856
[epoch14, step331]: loss 2.770358
[epoch14, step332]: loss 2.310945
[epoch14, step333]: loss 2.333797
[epoch14, step334]: loss 2.016374
[epoch14, step335]: loss 2.014046
[epoch14, step336]: loss 1.164949
[epoch14, step337]: loss 1.029625
[epoch14, step338]: loss 1.467856
[epoch14, step339]: loss 1.572964
[epoch14, step340]: loss 1.889507
[epoch14, step341]: loss 1.648017
[epoch14, step342]: loss 5.662847
[epoch14, step343]: loss 1.015636
[epoch14, step344]: loss 0.722667
[epoch14, step345]: loss 2.049300
[epoch14, step346]: loss 1.983533
[epoch14, step347]: loss 1.824530
[epoch14, step348]: loss 1.964547
[epoch14, step349]: loss 1.336227
[epoch14, step350]: loss 2.333296
[epoch14, step351]: loss 2.979171
[epoch14, step352]: loss 1.390450
[epoch14, step353]: loss 1.681730
[epoch14, step354]: loss 3.620898
[epoch14, step355]: loss 1.463828
[epoch14, step356]: loss 1.532136
[epoch14, step357]: loss 2.264290
[epoch14, step358]: loss 0.952355
[epoch14, step359]: loss 6.920578
[epoch14, step360]: loss 14.045035
[epoch14, step361]: loss 2.920450
[epoch14, step362]: loss 4.059221
[epoch14, step363]: loss 0.990340
[epoch14, step364]: loss 0.915934
[epoch14, step365]: loss 2.044855
[epoch14, step366]: loss 8.879331
[epoch14, step367]: loss 0.975897
[epoch14, step368]: loss 0.882884
[epoch14, step369]: loss 2.978753
[epoch14, step370]: loss 2.326116
[epoch14, step371]: loss 0.730015
[epoch14, step372]: loss 13.014179
[epoch14, step373]: loss 1.677121
[epoch14, step374]: loss 1.002666
[epoch14, step375]: loss 1.150091
[epoch14, step376]: loss 2.595607
[epoch14, step377]: loss 0.671284
[epoch14, step378]: loss 1.860890
[epoch14, step379]: loss 20.293196
[epoch14, step380]: loss 1.124058
[epoch14, step381]: loss 1.117053
[epoch14, step382]: loss 11.135180
[epoch14, step383]: loss 2.082948
[epoch14, step384]: loss 1.061612
[epoch14, step385]: loss 2.020974
[epoch14, step386]: loss 1.157594
[epoch14, step387]: loss 3.221433
[epoch14, step388]: loss 1.188410
[epoch14, step389]: loss 2.238814
[epoch14, step390]: loss 3.105999
[epoch14, step391]: loss 19.691210
[epoch14, step392]: loss 1.524425
[epoch14, step393]: loss 1.332432
[epoch14, step394]: loss 2.889401
[epoch14, step395]: loss 1.772441
[epoch14, step396]: loss 1.597733
[epoch14, step397]: loss 10.315432
[epoch14, step398]: loss 8.660357
[epoch14, step399]: loss 1.490170
[epoch14, step400]: loss 1.533044
[epoch14, step401]: loss 11.784978
[epoch14, step402]: loss 10.916700
[epoch14, step403]: loss 1.447677
[epoch14, step404]: loss 8.621940
[epoch14, step405]: loss 8.229194
[epoch14, step406]: loss 1.092016
[epoch14, step407]: loss 2.712798
[epoch14, step408]: loss 1.134894
[epoch14, step409]: loss 1.042179
[epoch14, step410]: loss 2.349304
[epoch14, step411]: loss 8.329168
[epoch14, step412]: loss 0.810213
[epoch14, step413]: loss 2.449951
[epoch14, step414]: loss 10.247271
[epoch14, step415]: loss 1.675349
[epoch14, step416]: loss 3.051415
[epoch14, step417]: loss 1.567757
[epoch14, step418]: loss 1.133363
[epoch14, step419]: loss 2.861753
[epoch14, step420]: loss 1.350683
[epoch14, step421]: loss 1.245642
[epoch14, step422]: loss 1.213126
[epoch14, step423]: loss 0.861933
[epoch14, step424]: loss 4.215314
[epoch14, step425]: loss 0.907301
[epoch14, step426]: loss 1.062328
[epoch14, step427]: loss 1.197021
[epoch14, step428]: loss 3.593586
[epoch14, step429]: loss 18.470215
[epoch14, step430]: loss 18.090071
[epoch14, step431]: loss 1.171666
[epoch14, step432]: loss 20.372585
[epoch14, step433]: loss 1.009719
[epoch14, step434]: loss 3.407275
[epoch14, step435]: loss 0.963457
[epoch14, step436]: loss 4.650784
[epoch14, step437]: loss 5.501265
[epoch14, step438]: loss 0.820502
[epoch14, step439]: loss 3.763268
[epoch14, step440]: loss 1.006258
[epoch14, step441]: loss 0.919879
[epoch14, step442]: loss 17.667917
[epoch14, step443]: loss 0.637408
[epoch14, step444]: loss 1.383681
[epoch14, step445]: loss 2.072190
[epoch14, step446]: loss 1.478548
[epoch14, step447]: loss 2.630922
[epoch14, step448]: loss 2.655761
[epoch14, step449]: loss 1.129824
[epoch14, step450]: loss 8.789282
[epoch14, step451]: loss 2.173877
[epoch14, step452]: loss 12.653629
[epoch14, step453]: loss 1.970181
[epoch14, step454]: loss 1.588297
[epoch14, step455]: loss 1.516813
[epoch14, step456]: loss 1.600467
[epoch14, step457]: loss 2.414636
[epoch14, step458]: loss 1.113530
[epoch14, step459]: loss 2.358303
[epoch14, step460]: loss 30.910025
[epoch14, step461]: loss 3.541937
[epoch14, step462]: loss 7.092955
[epoch14, step463]: loss 2.663049
[epoch14, step464]: loss 1.392823
[epoch14, step465]: loss 2.678086
[epoch14, step466]: loss 0.937468
[epoch14, step467]: loss 9.591080
[epoch14, step468]: loss 1.097668
[epoch14, step469]: loss 1.070748
[epoch14, step470]: loss 4.359586
[epoch14, step471]: loss 18.959278
[epoch14, step472]: loss 1.206217
[epoch14, step473]: loss 1.136136
[epoch14, step474]: loss 0.952817
[epoch14, step475]: loss 5.413118
[epoch14, step476]: loss 13.745850
[epoch14, step477]: loss 1.419930
[epoch14, step478]: loss 1.688470
[epoch14, step479]: loss 1.082507
[epoch14, step480]: loss 3.142593
[epoch14, step481]: loss 10.773220
[epoch14, step482]: loss 2.310205
[epoch14, step483]: loss 1.945961
[epoch14, step484]: loss 5.386402
[epoch14, step485]: loss 2.248212
[epoch14, step486]: loss 0.955842
[epoch14, step487]: loss 17.085445
[epoch14, step488]: loss 1.481103
[epoch14, step489]: loss 0.995595
[epoch14, step490]: loss 1.112301
[epoch14, step491]: loss 1.143146
[epoch14, step492]: loss 1.430918
[epoch14, step493]: loss 9.038468
[epoch14, step494]: loss 2.267138
[epoch14, step495]: loss 8.586293
[epoch14, step496]: loss 4.890379
[epoch14, step497]: loss 0.967694
[epoch14, step498]: loss 1.108535
[epoch14, step499]: loss 13.224994
[epoch14, step500]: loss 7.636708
[epoch14, step501]: loss 17.012484
[epoch14, step502]: loss 2.450722
[epoch14, step503]: loss 2.056128
[epoch14, step504]: loss 0.892021
[epoch14, step505]: loss 0.822766
[epoch14, step506]: loss 0.539012
[epoch14, step507]: loss 8.587949
[epoch14, step508]: loss 12.110380
[epoch14, step509]: loss 1.686358
[epoch14, step510]: loss 1.106983
[epoch14, step511]: loss 2.922864
[epoch14, step512]: loss 2.044740
[epoch14, step513]: loss 11.247267
[epoch14, step514]: loss 1.259941
[epoch14, step515]: loss 0.688196
[epoch14, step516]: loss 8.418078
[epoch14, step517]: loss 1.179240
[epoch14, step518]: loss 3.337767
[epoch14, step519]: loss 3.351821
[epoch14, step520]: loss 2.203121
[epoch14, step521]: loss 3.066576
[epoch14, step522]: loss 18.891621
[epoch14, step523]: loss 0.756874
[epoch14, step524]: loss 2.003200
[epoch14, step525]: loss 7.941272
[epoch14, step526]: loss 0.795798
[epoch14, step527]: loss 1.065761
[epoch14, step528]: loss 3.371873
[epoch14, step529]: loss 3.687170
[epoch14, step530]: loss 9.944398
[epoch14, step531]: loss 0.994814
[epoch14, step532]: loss 1.391169
[epoch14, step533]: loss 1.276964
[epoch14, step534]: loss 1.308764
[epoch14, step535]: loss 1.388854
[epoch14, step536]: loss 1.108126
[epoch14, step537]: loss 2.640207
[epoch14, step538]: loss 2.929875
[epoch14, step539]: loss 5.622353
[epoch14, step540]: loss 2.477067
[epoch14, step541]: loss 1.186283
[epoch14, step542]: loss 3.155327
[epoch14, step543]: loss 30.262983
[epoch14, step544]: loss 0.952079
[epoch14, step545]: loss 1.969693
[epoch14, step546]: loss 12.533890
[epoch14, step547]: loss 21.403015
[epoch14, step548]: loss 0.964266
[epoch14, step549]: loss 1.597873
[epoch14, step550]: loss 1.937550
[epoch14, step551]: loss 26.947474
[epoch14, step552]: loss 2.391295
[epoch14, step553]: loss 2.075712
[epoch14, step554]: loss 1.883576
[epoch14, step555]: loss 1.281780
[epoch14, step556]: loss 2.116081
[epoch14, step557]: loss 1.240639
[epoch14, step558]: loss 10.364512
[epoch14, step559]: loss 2.659009
[epoch14, step560]: loss 1.245586
[epoch14, step561]: loss 8.404563
[epoch14, step562]: loss 13.995600
[epoch14, step563]: loss 1.805169
[epoch14, step564]: loss 1.179113
[epoch14, step565]: loss 1.768391
[epoch14, step566]: loss 0.689195
[epoch14, step567]: loss 16.577877
[epoch14, step568]: loss 1.407763
[epoch14, step569]: loss 2.372112
[epoch14, step570]: loss 8.391789
[epoch14, step571]: loss 1.363630
[epoch14, step572]: loss 1.869712
[epoch14, step573]: loss 10.058039
[epoch14, step574]: loss 15.252098
[epoch14, step575]: loss 1.159602
[epoch14, step576]: loss 4.071784
[epoch14, step577]: loss 2.176931
[epoch14, step578]: loss 0.853235
[epoch14, step579]: loss 1.351839
[epoch14, step580]: loss 1.211670
[epoch14, step581]: loss 1.617681
[epoch14, step582]: loss 1.437235
[epoch14, step583]: loss 15.725837
[epoch14, step584]: loss 1.937608
[epoch14, step585]: loss 1.159313
[epoch14, step586]: loss 3.081785
[epoch14, step587]: loss 5.372171
[epoch14, step588]: loss 2.453326
[epoch14, step589]: loss 1.504332
[epoch14, step590]: loss 2.728189
[epoch14, step591]: loss 2.973984
[epoch14, step592]: loss 0.905795
[epoch14, step593]: loss 2.035037
[epoch14, step594]: loss 2.957190
[epoch14, step595]: loss 1.831190
[epoch14, step596]: loss 11.598242
[epoch14, step597]: loss 2.286366
[epoch14, step598]: loss 0.935060
[epoch14, step599]: loss 6.927524
[epoch14, step600]: loss 1.025561
[epoch14, step601]: loss 1.547037
[epoch14, step602]: loss 0.838266
[epoch14, step603]: loss 1.196886
[epoch14, step604]: loss 3.886928
[epoch14, step605]: loss 5.550026
[epoch14, step606]: loss 2.925176
[epoch14, step607]: loss 2.361844
[epoch14, step608]: loss 0.648943
[epoch14, step609]: loss 17.607368
[epoch14, step610]: loss 12.150707
[epoch14, step611]: loss 2.546796
[epoch14, step612]: loss 2.100089
[epoch14, step613]: loss 1.100422
[epoch14, step614]: loss 3.535596
[epoch14, step615]: loss 1.336731
[epoch14, step616]: loss 0.642290
[epoch14, step617]: loss 1.416147
[epoch14, step618]: loss 0.841421
[epoch14, step619]: loss 2.117196
[epoch14, step620]: loss 9.736280
[epoch14, step621]: loss 4.656077
[epoch14, step622]: loss 9.715656
[epoch14, step623]: loss 3.186746
[epoch14, step624]: loss 14.916471
[epoch14, step625]: loss 1.397358
[epoch14, step626]: loss 0.594520
[epoch14, step627]: loss 13.943457
[epoch14, step628]: loss 5.216145
[epoch14, step629]: loss 15.530410
[epoch14, step630]: loss 1.752670
[epoch14, step631]: loss 1.605436
[epoch14, step632]: loss 1.860507
[epoch14, step633]: loss 2.360257
[epoch14, step634]: loss 1.095088
[epoch14, step635]: loss 1.782570
[epoch14, step636]: loss 12.902948
[epoch14, step637]: loss 1.723348
[epoch14, step638]: loss 8.300675
[epoch14, step639]: loss 26.475292
[epoch14, step640]: loss 1.936568
[epoch14, step641]: loss 1.265806
[epoch14, step642]: loss 2.883310
[epoch14, step643]: loss 8.205654
[epoch14, step644]: loss 1.837886
[epoch14, step645]: loss 1.895089
[epoch14, step646]: loss 5.368695
[epoch14, step647]: loss 1.837781
[epoch14, step648]: loss 3.159384
[epoch14, step649]: loss 9.711810
[epoch14, step650]: loss 3.879089
[epoch14, step651]: loss 3.761958
[epoch14, step652]: loss 2.463009
[epoch14, step653]: loss 1.413870
[epoch14, step654]: loss 3.758628
[epoch14, step655]: loss 14.327497
[epoch14, step656]: loss 14.006189
[epoch14, step657]: loss 1.010331
[epoch14, step658]: loss 8.081003
[epoch14, step659]: loss 0.889839
[epoch14, step660]: loss 1.152762
[epoch14, step661]: loss 2.920732
[epoch14, step662]: loss 17.739519
[epoch14, step663]: loss 1.398401
[epoch14, step664]: loss 3.098124
[epoch14, step665]: loss 3.097941
[epoch14, step666]: loss 1.699261
[epoch14, step667]: loss 14.084628
[epoch14, step668]: loss 0.941071
[epoch14, step669]: loss 2.634629
[epoch14, step670]: loss 4.267862
[epoch14, step671]: loss 8.349191
[epoch14, step672]: loss 0.625459
[epoch14, step673]: loss 7.802529
[epoch14, step674]: loss 1.444426
[epoch14, step675]: loss 9.414812
[epoch14, step676]: loss 1.122455
[epoch14, step677]: loss 13.270531
[epoch14, step678]: loss 2.517559
[epoch14, step679]: loss 28.184994
[epoch14, step680]: loss 10.749824
[epoch14, step681]: loss 0.966687
[epoch14, step682]: loss 0.933752
[epoch14, step683]: loss 4.551893
[epoch14, step684]: loss 1.611289
[epoch14, step685]: loss 8.550716
[epoch14, step686]: loss 27.735134
[epoch14, step687]: loss 0.769882
[epoch14, step688]: loss 1.289591
[epoch14, step689]: loss 1.249408
[epoch14, step690]: loss 0.815067
[epoch14, step691]: loss 2.428632
[epoch14, step692]: loss 13.390877
[epoch14, step693]: loss 5.073274
[epoch14, step694]: loss 9.060741
[epoch14, step695]: loss 1.756898
[epoch14, step696]: loss 12.017845
[epoch14, step697]: loss 1.367983
[epoch14, step698]: loss 2.170454
[epoch14, step699]: loss 1.464902
[epoch14, step700]: loss 2.551289
[epoch14, step701]: loss 11.243410
[epoch14, step702]: loss 3.966739
[epoch14, step703]: loss 5.765937
[epoch14, step704]: loss 4.744471
[epoch14, step705]: loss 1.595349
[epoch14, step706]: loss 12.380711
[epoch14, step707]: loss 3.167966
[epoch14, step708]: loss 7.213209
[epoch14, step709]: loss 11.010348
[epoch14, step710]: loss 1.179864
[epoch14, step711]: loss 12.930438
[epoch14, step712]: loss 12.393934
[epoch14, step713]: loss 3.384220
[epoch14, step714]: loss 6.611801
[epoch14, step715]: loss 2.732578
[epoch14, step716]: loss 1.273454
[epoch14, step717]: loss 2.120810
[epoch14, step718]: loss 1.011058
[epoch14, step719]: loss 11.353438
[epoch14, step720]: loss 6.421887
[epoch14, step721]: loss 1.146230
[epoch14, step722]: loss 2.016964
[epoch14, step723]: loss 8.070860
[epoch14, step724]: loss 12.529400
[epoch14, step725]: loss 5.927427
[epoch14, step726]: loss 0.938883
[epoch14, step727]: loss 2.466200
[epoch14, step728]: loss 1.855502
[epoch14, step729]: loss 9.353467
[epoch14, step730]: loss 2.810542
[epoch14, step731]: loss 1.446839
[epoch14, step732]: loss 1.671985
[epoch14, step733]: loss 1.761123
[epoch14, step734]: loss 3.487180
[epoch14, step735]: loss 1.052968
[epoch14, step736]: loss 1.570019
[epoch14, step737]: loss 1.158925
[epoch14, step738]: loss 0.937290
[epoch14, step739]: loss 1.164413
[epoch14, step740]: loss 2.011931
[epoch14, step741]: loss 1.200819
[epoch14, step742]: loss 3.620358
[epoch14, step743]: loss 3.035868
[epoch14, step744]: loss 1.057095
[epoch14, step745]: loss 3.756885
[epoch14, step746]: loss 1.640342
[epoch14, step747]: loss 2.448494
[epoch14, step748]: loss 7.054737
[epoch14, step749]: loss 9.538619
[epoch14, step750]: loss 7.960729
[epoch14, step751]: loss 11.382159
[epoch14, step752]: loss 11.309708
[epoch14, step753]: loss 1.470739
[epoch14, step754]: loss 0.916434
[epoch14, step755]: loss 1.669079
[epoch14, step756]: loss 1.356344
[epoch14, step757]: loss 1.207075
[epoch14, step758]: loss 0.594851
[epoch14, step759]: loss 12.788053
[epoch14, step760]: loss 0.873926
[epoch14, step761]: loss 0.627401
[epoch14, step762]: loss 4.223661
[epoch14, step763]: loss 2.758241
[epoch14, step764]: loss 0.764428
[epoch14, step765]: loss 1.040823
[epoch14, step766]: loss 3.942083
[epoch14, step767]: loss 0.956675
[epoch14, step768]: loss 4.815807
[epoch14, step769]: loss 1.648788
[epoch14, step770]: loss 15.105126
[epoch14, step771]: loss 1.052232
[epoch14, step772]: loss 40.622032
[epoch14, step773]: loss 2.558113
[epoch14, step774]: loss 9.544948
[epoch14, step775]: loss 12.973097
[epoch14, step776]: loss 1.855406
[epoch14, step777]: loss 11.561572
[epoch14, step778]: loss 2.523709
[epoch14, step779]: loss 2.260066
[epoch14, step780]: loss 1.617208
[epoch14, step781]: loss 1.654827
[epoch14, step782]: loss 1.335763
[epoch14, step783]: loss 2.633117
[epoch14, step784]: loss 9.346262
[epoch14, step785]: loss 1.186538
[epoch14, step786]: loss 5.336140
[epoch14, step787]: loss 18.031513
[epoch14, step788]: loss 17.426008
[epoch14, step789]: loss 13.227897
[epoch14, step790]: loss 2.368265
[epoch14, step791]: loss 0.755078
[epoch14, step792]: loss 0.804379
[epoch14, step793]: loss 4.515129
[epoch14, step794]: loss 5.122413
[epoch14, step795]: loss 4.576100
[epoch14, step796]: loss 1.294408
[epoch14, step797]: loss 5.465221
[epoch14, step798]: loss 10.879825
[epoch14, step799]: loss 0.999750
[epoch14, step800]: loss 0.682897
[epoch14, step801]: loss 1.594240
[epoch14, step802]: loss 0.781184
[epoch14, step803]: loss 1.802507
[epoch14, step804]: loss 6.390971
[epoch14, step805]: loss 1.869829
[epoch14, step806]: loss 1.911572
[epoch14, step807]: loss 2.351221
[epoch14, step808]: loss 8.827239
[epoch14, step809]: loss 2.813861
[epoch14, step810]: loss 0.898062
[epoch14, step811]: loss 1.340784
[epoch14, step812]: loss 1.355887
[epoch14, step813]: loss 4.626544
[epoch14, step814]: loss 2.436651
[epoch14, step815]: loss 1.271126
[epoch14, step816]: loss 15.310832
[epoch14, step817]: loss 16.219570
[epoch14, step818]: loss 1.242397
[epoch14, step819]: loss 1.243963
[epoch14, step820]: loss 1.304162
[epoch14, step821]: loss 0.949101
[epoch14, step822]: loss 1.988584
[epoch14, step823]: loss 1.102313
[epoch14, step824]: loss 3.232126
[epoch14, step825]: loss 1.438248
[epoch14, step826]: loss 2.086707
[epoch14, step827]: loss 9.517293
[epoch14, step828]: loss 1.296594
[epoch14, step829]: loss 12.747929
[epoch14, step830]: loss 18.445429
[epoch14, step831]: loss 0.998427
[epoch14, step832]: loss 11.017731
[epoch14, step833]: loss 0.782217
[epoch14, step834]: loss 11.483150
[epoch14, step835]: loss 1.312947
[epoch14, step836]: loss 1.172892
[epoch14, step837]: loss 0.852756
[epoch14, step838]: loss 2.125943
[epoch14, step839]: loss 11.261631
[epoch14, step840]: loss 3.056088
[epoch14, step841]: loss 4.403264
[epoch14, step842]: loss 1.204814
[epoch14, step843]: loss 2.861253
[epoch14, step844]: loss 13.537124
[epoch14, step845]: loss 7.326853
[epoch14, step846]: loss 1.481776
[epoch14, step847]: loss 1.520096
[epoch14, step848]: loss 1.450463
[epoch14, step849]: loss 1.787097
[epoch14, step850]: loss 10.930630
[epoch14, step851]: loss 1.656737
[epoch14, step852]: loss 1.747599
[epoch14, step853]: loss 12.894560
[epoch14, step854]: loss 4.545396
[epoch14, step855]: loss 1.323999
[epoch14, step856]: loss 1.151772
[epoch14, step857]: loss 4.777231
[epoch14, step858]: loss 4.390800
[epoch14, step859]: loss 6.197695
[epoch14, step860]: loss 7.952372
[epoch14, step861]: loss 1.407309
[epoch14, step862]: loss 1.716013
[epoch14, step863]: loss 30.039328
[epoch14, step864]: loss 0.795864
[epoch14, step865]: loss 12.652411
[epoch14, step866]: loss 1.313961
[epoch14, step867]: loss 1.449453
[epoch14, step868]: loss 9.192794
[epoch14, step869]: loss 1.236966
[epoch14, step870]: loss 0.658983
[epoch14, step871]: loss 0.949236
[epoch14, step872]: loss 2.397734
[epoch14, step873]: loss 1.463132
[epoch14, step874]: loss 2.438601
[epoch14, step875]: loss 3.301460
[epoch14, step876]: loss 2.948576
[epoch14, step877]: loss 0.812310
[epoch14, step878]: loss 12.881802
[epoch14, step879]: loss 7.831968
[epoch14, step880]: loss 0.899920
[epoch14, step881]: loss 2.845757
[epoch14, step882]: loss 0.892434
[epoch14, step883]: loss 1.932374
[epoch14, step884]: loss 4.070224
[epoch14, step885]: loss 0.846937
[epoch14, step886]: loss 2.119494
[epoch14, step887]: loss 1.547986
[epoch14, step888]: loss 1.777772
[epoch14, step889]: loss 6.955056
[epoch14, step890]: loss 0.722468
[epoch14, step891]: loss 7.740636
[epoch14, step892]: loss 1.766526
[epoch14, step893]: loss 1.368475
[epoch14, step894]: loss 1.583943
[epoch14, step895]: loss 0.935207
[epoch14, step896]: loss 7.262056
[epoch14, step897]: loss 8.007757
[epoch14, step898]: loss 14.950216
[epoch14, step899]: loss 3.106622
[epoch14, step900]: loss 1.003399
[epoch14, step901]: loss 11.140643
[epoch14, step902]: loss 1.506456
[epoch14, step903]: loss 6.944423
[epoch14, step904]: loss 2.247153
[epoch14, step905]: loss 1.129311
[epoch14, step906]: loss 15.262709
[epoch14, step907]: loss 5.434518
[epoch14, step908]: loss 1.326438
[epoch14, step909]: loss 1.273884
[epoch14, step910]: loss 2.524945
[epoch14, step911]: loss 4.182516
[epoch14, step912]: loss 3.510166
[epoch14, step913]: loss 13.001737
[epoch14, step914]: loss 2.103607
[epoch14, step915]: loss 4.947732
[epoch14, step916]: loss 1.867271
[epoch14, step917]: loss 0.814959
[epoch14, step918]: loss 7.368459
[epoch14, step919]: loss 4.481054
[epoch14, step920]: loss 2.126597
[epoch14, step921]: loss 1.420153
[epoch14, step922]: loss 0.820712
[epoch14, step923]: loss 3.100909
[epoch14, step924]: loss 1.064290
[epoch14, step925]: loss 14.405034
[epoch14, step926]: loss 7.505708
[epoch14, step927]: loss 0.980108
[epoch14, step928]: loss 1.057228
[epoch14, step929]: loss 3.461708
[epoch14, step930]: loss 1.129523
[epoch14, step931]: loss 1.209138
[epoch14, step932]: loss 0.920625
[epoch14, step933]: loss 1.607705
[epoch14, step934]: loss 7.479822
[epoch14, step935]: loss 2.807338
[epoch14, step936]: loss 3.959237
[epoch14, step937]: loss 15.922842
[epoch14, step938]: loss 0.921898
[epoch14, step939]: loss 1.204109
[epoch14, step940]: loss 0.768466
[epoch14, step941]: loss 1.353990
[epoch14, step942]: loss 8.705347
[epoch14, step943]: loss 1.188362
[epoch14, step944]: loss 3.267653
[epoch14, step945]: loss 3.315920
[epoch14, step946]: loss 5.264419
[epoch14, step947]: loss 8.159948
[epoch14, step948]: loss 35.499588
[epoch14, step949]: loss 17.346170
[epoch14, step950]: loss 0.977166
[epoch14, step951]: loss 2.460811
[epoch14, step952]: loss 1.409888
[epoch14, step953]: loss 14.763093
[epoch14, step954]: loss 2.075822
[epoch14, step955]: loss 6.518807
[epoch14, step956]: loss 1.498783
[epoch14, step957]: loss 2.278753
[epoch14, step958]: loss 1.529968
[epoch14, step959]: loss 8.239046
[epoch14, step960]: loss 6.714852
[epoch14, step961]: loss 3.499856
[epoch14, step962]: loss 4.365821
[epoch14, step963]: loss 2.265701
[epoch14, step964]: loss 21.792459
[epoch14, step965]: loss 6.340869
[epoch14, step966]: loss 3.883640
[epoch14, step967]: loss 1.359648
[epoch14, step968]: loss 2.872253
[epoch14, step969]: loss 3.536571
[epoch14, step970]: loss 1.868859
[epoch14, step971]: loss 1.206854
[epoch14, step972]: loss 0.926417
[epoch14, step973]: loss 1.368431
[epoch14, step974]: loss 0.944986
[epoch14, step975]: loss 2.215169
[epoch14, step976]: loss 2.628263
[epoch14, step977]: loss 0.746633
[epoch14, step978]: loss 1.615093
[epoch14, step979]: loss 1.912902
[epoch14, step980]: loss 1.236406
[epoch14, step981]: loss 0.677388
[epoch14, step982]: loss 1.023546
[epoch14, step983]: loss 2.869291
[epoch14, step984]: loss 12.074120
[epoch14, step985]: loss 1.387245
[epoch14, step986]: loss 1.240393
[epoch14, step987]: loss 1.671160
[epoch14, step988]: loss 17.851465
[epoch14, step989]: loss 17.458193
[epoch14, step990]: loss 24.319778
[epoch14, step991]: loss 20.054003
[epoch14, step992]: loss 7.806688
[epoch14, step993]: loss 19.853313
[epoch14, step994]: loss 4.166997
[epoch14, step995]: loss 10.219026
[epoch14, step996]: loss 2.984332
[epoch14, step997]: loss 4.631519
[epoch14, step998]: loss 1.829052
[epoch14, step999]: loss 12.061524
[epoch14, step1000]: loss 1.513281
[epoch14, step1001]: loss 3.524506
[epoch14, step1002]: loss 2.599500
[epoch14, step1003]: loss 1.239381
[epoch14, step1004]: loss 0.968770
[epoch14, step1005]: loss 2.037750
[epoch14, step1006]: loss 15.781730
[epoch14, step1007]: loss 0.914490
[epoch14, step1008]: loss 8.935652
[epoch14, step1009]: loss 10.388683
[epoch14, step1010]: loss 0.730171
[epoch14, step1011]: loss 3.537669
[epoch14, step1012]: loss 2.900030
[epoch14, step1013]: loss 1.408647
[epoch14, step1014]: loss 2.827638
[epoch14, step1015]: loss 3.364589
[epoch14, step1016]: loss 4.947555
[epoch14, step1017]: loss 1.398027
[epoch14, step1018]: loss 2.731607
[epoch14, step1019]: loss 4.454070
[epoch14, step1020]: loss 1.589022
[epoch14, step1021]: loss 3.692597
[epoch14, step1022]: loss 0.910307
[epoch14, step1023]: loss 0.807060
[epoch14, step1024]: loss 0.760961
[epoch14, step1025]: loss 1.331573
[epoch14, step1026]: loss 1.138234
[epoch14, step1027]: loss 1.139065
[epoch14, step1028]: loss 1.532208
[epoch14, step1029]: loss 1.490317
[epoch14, step1030]: loss 19.594744
[epoch14, step1031]: loss 2.232692
[epoch14, step1032]: loss 11.445955
[epoch14, step1033]: loss 1.114964
[epoch14, step1034]: loss 0.703994
[epoch14, step1035]: loss 1.043482
[epoch14, step1036]: loss 3.145656
[epoch14, step1037]: loss 3.178310
[epoch14, step1038]: loss 1.705170
[epoch14, step1039]: loss 1.118045
[epoch14, step1040]: loss 0.719990
[epoch14, step1041]: loss 12.741966
[epoch14, step1042]: loss 1.820193
[epoch14, step1043]: loss 2.458854
[epoch14, step1044]: loss 1.042060
[epoch14, step1045]: loss 20.412802
[epoch14, step1046]: loss 8.436355
[epoch14, step1047]: loss 5.819477
[epoch14, step1048]: loss 2.060743
[epoch14, step1049]: loss 1.375602
[epoch14, step1050]: loss 1.472277
[epoch14, step1051]: loss 5.395274
[epoch14, step1052]: loss 0.754643
[epoch14, step1053]: loss 0.941500
[epoch14, step1054]: loss 5.309094
[epoch14, step1055]: loss 1.311630
[epoch14, step1056]: loss 8.702492
[epoch14, step1057]: loss 7.026625
[epoch14, step1058]: loss 1.520214
[epoch14, step1059]: loss 1.445603
[epoch14, step1060]: loss 0.889803
[epoch14, step1061]: loss 22.230209
[epoch14, step1062]: loss 1.408143
[epoch14, step1063]: loss 10.652358
[epoch14, step1064]: loss 1.202649
[epoch14, step1065]: loss 0.365575
[epoch14, step1066]: loss 0.971079
[epoch14, step1067]: loss 1.591934
[epoch14, step1068]: loss 8.841996
[epoch14, step1069]: loss 8.269656
[epoch14, step1070]: loss 0.870815
[epoch14, step1071]: loss 1.430305
[epoch14, step1072]: loss 1.453149
[epoch14, step1073]: loss 7.998845
[epoch14, step1074]: loss 0.993999
[epoch14, step1075]: loss 1.628217
[epoch14, step1076]: loss 0.745198
[epoch14, step1077]: loss 17.960249
[epoch14, step1078]: loss 2.318879
[epoch14, step1079]: loss 28.273970
[epoch14, step1080]: loss 1.117276
[epoch14, step1081]: loss 2.717148
[epoch14, step1082]: loss 0.474949
[epoch14, step1083]: loss 3.746040
[epoch14, step1084]: loss 1.066769
[epoch14, step1085]: loss 3.492246
[epoch14, step1086]: loss 9.948832
[epoch14, step1087]: loss 2.745642
[epoch14, step1088]: loss 2.342762
[epoch14, step1089]: loss 5.975254
[epoch14, step1090]: loss 3.486319
[epoch14, step1091]: loss 1.301414
[epoch14, step1092]: loss 1.816542
[epoch14, step1093]: loss 2.553716
[epoch14, step1094]: loss 0.941563
[epoch14, step1095]: loss 3.147372
[epoch14, step1096]: loss 1.296056
[epoch14, step1097]: loss 6.717318
[epoch14, step1098]: loss 14.788093
[epoch14, step1099]: loss 2.404333
[epoch14, step1100]: loss 8.268515
[epoch14, step1101]: loss 1.751380
[epoch14, step1102]: loss 1.280235
[epoch14, step1103]: loss 3.144522
[epoch14, step1104]: loss 3.452697
[epoch14, step1105]: loss 0.996139
[epoch14, step1106]: loss 4.343968
[epoch14, step1107]: loss 1.120564
[epoch14, step1108]: loss 1.830758
[epoch14, step1109]: loss 1.301874
[epoch14, step1110]: loss 1.581525
[epoch14, step1111]: loss 1.783762
[epoch14, step1112]: loss 1.461188
[epoch14, step1113]: loss 12.525452
[epoch14, step1114]: loss 24.041523
[epoch14, step1115]: loss 9.968475
[epoch14, step1116]: loss 0.771791
[epoch14, step1117]: loss 8.454065
[epoch14, step1118]: loss 3.202729
[epoch14, step1119]: loss 1.588404
[epoch14, step1120]: loss 3.905712
[epoch14, step1121]: loss 2.022245
[epoch14, step1122]: loss 11.404474
[epoch14, step1123]: loss 0.959008
[epoch14, step1124]: loss 0.895591
[epoch14, step1125]: loss 2.215335
[epoch14, step1126]: loss 1.143154
[epoch14, step1127]: loss 4.268536
[epoch14, step1128]: loss 1.692546
[epoch14, step1129]: loss 8.552789
[epoch14, step1130]: loss 21.797964
[epoch14, step1131]: loss 4.175251
[epoch14, step1132]: loss 10.939461
[epoch14, step1133]: loss 1.133740
[epoch14, step1134]: loss 8.046655
[epoch14, step1135]: loss 0.867492
[epoch14, step1136]: loss 2.059704
[epoch14, step1137]: loss 1.369119
[epoch14, step1138]: loss 2.175876
[epoch14, step1139]: loss 2.254743
[epoch14, step1140]: loss 1.757684
[epoch14, step1141]: loss 2.015798
[epoch14, step1142]: loss 14.338407
[epoch14, step1143]: loss 1.202772
[epoch14, step1144]: loss 2.315864
[epoch14, step1145]: loss 1.330469
[epoch14, step1146]: loss 0.988278
[epoch14, step1147]: loss 15.184915
[epoch14, step1148]: loss 1.157835
[epoch14, step1149]: loss 0.759569
[epoch14, step1150]: loss 17.303587
[epoch14, step1151]: loss 2.444754
[epoch14, step1152]: loss 1.603013
[epoch14, step1153]: loss 5.971944
[epoch14, step1154]: loss 1.353737
[epoch14, step1155]: loss 10.971918
[epoch14, step1156]: loss 1.014857
[epoch14, step1157]: loss 14.540437
[epoch14, step1158]: loss 0.811013
[epoch14, step1159]: loss 4.321600
[epoch14, step1160]: loss 0.649497
[epoch14, step1161]: loss 3.443827
[epoch14, step1162]: loss 1.033945
[epoch14, step1163]: loss 0.834318
[epoch14, step1164]: loss 1.032059
[epoch14, step1165]: loss 1.299872
[epoch14, step1166]: loss 9.662508
[epoch14, step1167]: loss 2.666528
[epoch14, step1168]: loss 1.156298
[epoch14, step1169]: loss 13.555503
[epoch14, step1170]: loss 1.108306
[epoch14, step1171]: loss 1.449524
[epoch14, step1172]: loss 1.262452
[epoch14, step1173]: loss 11.777761
[epoch14, step1174]: loss 7.306475
[epoch14, step1175]: loss 1.367182
[epoch14, step1176]: loss 2.184374
[epoch14, step1177]: loss 1.337283
[epoch14, step1178]: loss 5.531140
[epoch14, step1179]: loss 17.945482
[epoch14, step1180]: loss 1.325149
[epoch14, step1181]: loss 0.762537
[epoch14, step1182]: loss 0.902423
[epoch14, step1183]: loss 3.228259
[epoch14, step1184]: loss 2.879780
[epoch14, step1185]: loss 1.682827
[epoch14, step1186]: loss 2.025362
[epoch14, step1187]: loss 11.326636
[epoch14, step1188]: loss 1.970159
[epoch14, step1189]: loss 7.522467
[epoch14, step1190]: loss 0.991924
[epoch14, step1191]: loss 1.279398
[epoch14, step1192]: loss 0.901330
[epoch14, step1193]: loss 7.876982
[epoch14, step1194]: loss 1.279713
[epoch14, step1195]: loss 1.149035
[epoch14, step1196]: loss 1.159996
[epoch14, step1197]: loss 2.022997
[epoch14, step1198]: loss 4.384229
[epoch14, step1199]: loss 1.658393
[epoch14, step1200]: loss 16.973618
[epoch14, step1201]: loss 0.711951
[epoch14, step1202]: loss 4.269284
[epoch14, step1203]: loss 1.659735
[epoch14, step1204]: loss 1.234376
[epoch14, step1205]: loss 0.565844
[epoch14, step1206]: loss 13.062780
[epoch14, step1207]: loss 11.966773
[epoch14, step1208]: loss 11.176228
[epoch14, step1209]: loss 2.397902
[epoch14, step1210]: loss 1.146553
[epoch14, step1211]: loss 1.055609
[epoch14, step1212]: loss 1.940852
[epoch14, step1213]: loss 0.950595
[epoch14, step1214]: loss 7.021935
[epoch14, step1215]: loss 2.017617
[epoch14, step1216]: loss 7.491701
[epoch14, step1217]: loss 9.088652
[epoch14, step1218]: loss 1.055199
[epoch14, step1219]: loss 6.004302
[epoch14, step1220]: loss 6.072974
[epoch14, step1221]: loss 1.063435
[epoch14, step1222]: loss 1.210629
[epoch14, step1223]: loss 1.009942
[epoch14, step1224]: loss 4.289760
[epoch14, step1225]: loss 0.866876
[epoch14, step1226]: loss 5.049494
[epoch14, step1227]: loss 1.650764
[epoch14, step1228]: loss 1.684463
[epoch14, step1229]: loss 15.854559
[epoch14, step1230]: loss 1.478403
[epoch14, step1231]: loss 1.979111
[epoch14, step1232]: loss 0.685884
[epoch14, step1233]: loss 1.204200
[epoch14, step1234]: loss 2.317784
[epoch14, step1235]: loss 1.102952
[epoch14, step1236]: loss 8.331601
[epoch14, step1237]: loss 1.976564
[epoch14, step1238]: loss 29.810461
[epoch14, step1239]: loss 1.524492
[epoch14, step1240]: loss 1.028785
[epoch14, step1241]: loss 7.276247
[epoch14, step1242]: loss 4.275987
[epoch14, step1243]: loss 1.252891
[epoch14, step1244]: loss 8.252330
[epoch14, step1245]: loss 1.176853
[epoch14, step1246]: loss 1.826028
[epoch14, step1247]: loss 2.744587
[epoch14, step1248]: loss 4.860663
[epoch14, step1249]: loss 11.284268
[epoch14, step1250]: loss 6.527310
[epoch14, step1251]: loss 2.235167
[epoch14, step1252]: loss 1.012087
[epoch14, step1253]: loss 2.883228
[epoch14, step1254]: loss 11.187978
[epoch14, step1255]: loss 1.341841
[epoch14, step1256]: loss 19.698994
[epoch14, step1257]: loss 1.306897
[epoch14, step1258]: loss 4.987751
[epoch14, step1259]: loss 1.694540
[epoch14, step1260]: loss 1.125169
[epoch14, step1261]: loss 2.140691
[epoch14, step1262]: loss 3.971488
[epoch14, step1263]: loss 20.188316
[epoch14, step1264]: loss 2.306687
[epoch14, step1265]: loss 1.623691
[epoch14, step1266]: loss 8.888811
[epoch14, step1267]: loss 15.160961
[epoch14, step1268]: loss 2.706418
[epoch14, step1269]: loss 3.911129
[epoch14, step1270]: loss 1.355121
[epoch14, step1271]: loss 1.235202
[epoch14, step1272]: loss 2.093539
[epoch14, step1273]: loss 1.775609
[epoch14, step1274]: loss 0.960407
[epoch14, step1275]: loss 14.528621
[epoch14, step1276]: loss 1.672868
[epoch14, step1277]: loss 0.951484
[epoch14, step1278]: loss 0.758465
[epoch14, step1279]: loss 1.754067
[epoch14, step1280]: loss 3.524668
[epoch14, step1281]: loss 1.907017
[epoch14, step1282]: loss 0.751455
[epoch14, step1283]: loss 2.119898
[epoch14, step1284]: loss 1.345117
[epoch14, step1285]: loss 1.213038
[epoch14, step1286]: loss 1.380091
[epoch14, step1287]: loss 5.503489
[epoch14, step1288]: loss 0.709426
[epoch14, step1289]: loss 5.716556
[epoch14, step1290]: loss 4.407436
[epoch14, step1291]: loss 2.109577
[epoch14, step1292]: loss 2.756987
[epoch14, step1293]: loss 2.520354
[epoch14, step1294]: loss 2.690019
[epoch14, step1295]: loss 6.089220
[epoch14, step1296]: loss 2.795949
[epoch14, step1297]: loss 11.467510
[epoch14, step1298]: loss 8.582665
[epoch14, step1299]: loss 1.336307
[epoch14, step1300]: loss 9.485884
[epoch14, step1301]: loss 4.288153
[epoch14, step1302]: loss 0.842160
[epoch14, step1303]: loss 8.149469
[epoch14, step1304]: loss 2.031192
[epoch14, step1305]: loss 4.693602
[epoch14, step1306]: loss 3.910958
[epoch14, step1307]: loss 2.217759
[epoch14, step1308]: loss 2.245281
[epoch14, step1309]: loss 0.789507
[epoch14, step1310]: loss 3.659499
[epoch14, step1311]: loss 2.214517
[epoch14, step1312]: loss 0.778865
[epoch14, step1313]: loss 9.169480
[epoch14, step1314]: loss 2.204394
[epoch14, step1315]: loss 13.692266
[epoch14, step1316]: loss 1.137529
[epoch14, step1317]: loss 1.167558
[epoch14, step1318]: loss 9.222466
[epoch14, step1319]: loss 5.654631
[epoch14, step1320]: loss 0.453122
[epoch14, step1321]: loss 1.755637
[epoch14, step1322]: loss 1.158633
[epoch14, step1323]: loss 1.008432
[epoch14, step1324]: loss 0.922695
[epoch14, step1325]: loss 0.793955
[epoch14, step1326]: loss 1.761023
[epoch14, step1327]: loss 8.063675
[epoch14, step1328]: loss 15.853509
[epoch14, step1329]: loss 1.892989
[epoch14, step1330]: loss 12.695991
[epoch14, step1331]: loss 4.150483
[epoch14, step1332]: loss 2.491000
[epoch14, step1333]: loss 1.120204
[epoch14, step1334]: loss 3.459630
[epoch14, step1335]: loss 0.750669
[epoch14, step1336]: loss 2.563598
[epoch14, step1337]: loss 4.853900
[epoch14, step1338]: loss 1.880753
[epoch14, step1339]: loss 1.342659
[epoch14, step1340]: loss 1.574231
[epoch14, step1341]: loss 11.119533
[epoch14, step1342]: loss 5.733916
[epoch14, step1343]: loss 8.611879
[epoch14, step1344]: loss 2.925207
[epoch14, step1345]: loss 0.989196
[epoch14, step1346]: loss 0.928966
[epoch14, step1347]: loss 2.992442
[epoch14, step1348]: loss 11.227620
[epoch14, step1349]: loss 2.836136
[epoch14, step1350]: loss 11.932838
[epoch14, step1351]: loss 14.021089
[epoch14, step1352]: loss 0.971067
[epoch14, step1353]: loss 1.686700
[epoch14, step1354]: loss 4.718469
[epoch14, step1355]: loss 1.065972
[epoch14, step1356]: loss 5.817495
[epoch14, step1357]: loss 1.746122
[epoch14, step1358]: loss 12.455185
[epoch14, step1359]: loss 1.453935
[epoch14, step1360]: loss 0.857847
[epoch14, step1361]: loss 2.032372
[epoch14, step1362]: loss 2.167880
[epoch14, step1363]: loss 1.138997
[epoch14, step1364]: loss 2.504876
[epoch14, step1365]: loss 31.365669
[epoch14, step1366]: loss 2.360873
[epoch14, step1367]: loss 2.529907
[epoch14, step1368]: loss 2.742352
[epoch14, step1369]: loss 3.594218
[epoch14, step1370]: loss 1.435080
[epoch14, step1371]: loss 1.029078
[epoch14, step1372]: loss 12.031338
[epoch14, step1373]: loss 2.199851
[epoch14, step1374]: loss 1.160640
[epoch14, step1375]: loss 0.983898
[epoch14, step1376]: loss 13.240106
[epoch14, step1377]: loss 2.390651
[epoch14, step1378]: loss 1.978978
[epoch14, step1379]: loss 10.173343
[epoch14, step1380]: loss 5.124759
[epoch14, step1381]: loss 2.540070
[epoch14, step1382]: loss 1.367774
[epoch14, step1383]: loss 1.473534
[epoch14, step1384]: loss 3.999126
[epoch14, step1385]: loss 5.058630
[epoch14, step1386]: loss 3.274166
[epoch14, step1387]: loss 15.401723
[epoch14, step1388]: loss 1.740057
[epoch14, step1389]: loss 1.127727
[epoch14, step1390]: loss 7.392651
[epoch14, step1391]: loss 0.829062
[epoch14, step1392]: loss 2.298460
[epoch14, step1393]: loss 1.522794
[epoch14, step1394]: loss 2.143027
[epoch14, step1395]: loss 1.347430
[epoch14, step1396]: loss 0.662429
[epoch14, step1397]: loss 0.827138
[epoch14, step1398]: loss 2.026431
[epoch14, step1399]: loss 1.312802
[epoch14, step1400]: loss 0.911148
[epoch14, step1401]: loss 1.885406
[epoch14, step1402]: loss 4.494889
[epoch14, step1403]: loss 2.211532
[epoch14, step1404]: loss 0.861079
[epoch14, step1405]: loss 0.871974
[epoch14, step1406]: loss 0.823243
[epoch14, step1407]: loss 1.778268
[epoch14, step1408]: loss 1.055742
[epoch14, step1409]: loss 30.263250
[epoch14, step1410]: loss 14.218805
[epoch14, step1411]: loss 1.075889
[epoch14, step1412]: loss 1.259133
[epoch14, step1413]: loss 2.720867
[epoch14, step1414]: loss 1.508116
[epoch14, step1415]: loss 4.395285
[epoch14, step1416]: loss 21.164812
[epoch14, step1417]: loss 1.305590
[epoch14, step1418]: loss 4.821366
[epoch14, step1419]: loss 11.600281
[epoch14, step1420]: loss 0.867280
[epoch14, step1421]: loss 1.936354
[epoch14, step1422]: loss 2.120401
[epoch14, step1423]: loss 9.535221
[epoch14, step1424]: loss 12.167383
[epoch14, step1425]: loss 13.464044
[epoch14, step1426]: loss 1.464146
[epoch14, step1427]: loss 20.226261
[epoch14, step1428]: loss 2.229433
[epoch14, step1429]: loss 3.065028
[epoch14, step1430]: loss 12.053074
[epoch14, step1431]: loss 0.886576
[epoch14, step1432]: loss 12.337584
[epoch14, step1433]: loss 6.259161
[epoch14, step1434]: loss 0.533929
[epoch14, step1435]: loss 9.834780
[epoch14, step1436]: loss 1.211877
[epoch14, step1437]: loss 0.959669
[epoch14, step1438]: loss 2.518001
[epoch14, step1439]: loss 0.826129
[epoch14, step1440]: loss 2.749357
[epoch14, step1441]: loss 9.627075
[epoch14, step1442]: loss 1.296937
[epoch14, step1443]: loss 1.207289
[epoch14, step1444]: loss 2.164995
[epoch14, step1445]: loss 1.112152
[epoch14, step1446]: loss 1.497496
[epoch14, step1447]: loss 16.262320
[epoch14, step1448]: loss 1.040694
[epoch14, step1449]: loss 3.756018
[epoch14, step1450]: loss 2.073358
[epoch14, step1451]: loss 1.761832
[epoch14, step1452]: loss 0.612228
[epoch14, step1453]: loss 1.723425
[epoch14, step1454]: loss 0.963770
[epoch14, step1455]: loss 1.447087
[epoch14, step1456]: loss 13.838180
[epoch14, step1457]: loss 4.386347
[epoch14, step1458]: loss 10.463521
[epoch14, step1459]: loss 0.857080
[epoch14, step1460]: loss 1.738991
[epoch14, step1461]: loss 0.826014
[epoch14, step1462]: loss 11.741505
[epoch14, step1463]: loss 1.142678
[epoch14, step1464]: loss 1.488747
[epoch14, step1465]: loss 1.692645
[epoch14, step1466]: loss 5.974608
[epoch14, step1467]: loss 3.381724
[epoch14, step1468]: loss 0.934023
[epoch14, step1469]: loss 1.404538
[epoch14, step1470]: loss 1.769316
[epoch14, step1471]: loss 6.988754
[epoch14, step1472]: loss 2.960090
[epoch14, step1473]: loss 10.821744
[epoch14, step1474]: loss 1.278264
[epoch14, step1475]: loss 17.489836
[epoch14, step1476]: loss 3.000818
[epoch14, step1477]: loss 1.848716
[epoch14, step1478]: loss 3.911955
[epoch14, step1479]: loss 4.462547
[epoch14, step1480]: loss 5.080522
[epoch14, step1481]: loss 2.671130
[epoch14, step1482]: loss 8.657659
[epoch14, step1483]: loss 31.102448
[epoch14, step1484]: loss 1.711897
[epoch14, step1485]: loss 2.781534
[epoch14, step1486]: loss 1.863935
[epoch14, step1487]: loss 0.451822
[epoch14, step1488]: loss 1.247984
[epoch14, step1489]: loss 3.307618
[epoch14, step1490]: loss 0.976961
[epoch14, step1491]: loss 10.470464
[epoch14, step1492]: loss 16.100599
[epoch14, step1493]: loss 8.600621
[epoch14, step1494]: loss 4.634469
[epoch14, step1495]: loss 5.270879
[epoch14, step1496]: loss 4.564914
[epoch14, step1497]: loss 16.830488
[epoch14, step1498]: loss 9.443346
[epoch14, step1499]: loss 1.563643
[epoch14, step1500]: loss 4.193385
[epoch14, step1501]: loss 6.963002
[epoch14, step1502]: loss 6.984026
[epoch14, step1503]: loss 1.693135
[epoch14, step1504]: loss 2.737001
[epoch14, step1505]: loss 27.595798
[epoch14, step1506]: loss 1.371092
[epoch14, step1507]: loss 4.949137
[epoch14, step1508]: loss 7.351992
[epoch14, step1509]: loss 1.069627
[epoch14, step1510]: loss 15.543591
[epoch14, step1511]: loss 3.362081
[epoch14, step1512]: loss 1.639485
[epoch14, step1513]: loss 0.687436
[epoch14, step1514]: loss 6.781621
[epoch14, step1515]: loss 3.207270
[epoch14, step1516]: loss 1.005689
[epoch14, step1517]: loss 3.544344
[epoch14, step1518]: loss 1.922183
[epoch14, step1519]: loss 2.183424
[epoch14, step1520]: loss 8.930392
[epoch14, step1521]: loss 2.198596
[epoch14, step1522]: loss 1.981875
[epoch14, step1523]: loss 1.092618
[epoch14, step1524]: loss 8.263437
[epoch14, step1525]: loss 0.866015
[epoch14, step1526]: loss 2.178414
[epoch14, step1527]: loss 1.301307
[epoch14, step1528]: loss 0.734158
[epoch14, step1529]: loss 1.842121
[epoch14, step1530]: loss 0.950324
[epoch14, step1531]: loss 1.147476
[epoch14, step1532]: loss 2.528880
[epoch14, step1533]: loss 3.429545
[epoch14, step1534]: loss 0.520791
[epoch14, step1535]: loss 8.549826
[epoch14, step1536]: loss 1.842494
[epoch14, step1537]: loss 11.780280
[epoch14, step1538]: loss 4.256717
[epoch14, step1539]: loss 22.919640
[epoch14, step1540]: loss 0.759431
[epoch14, step1541]: loss 1.101822
[epoch14, step1542]: loss 6.825522
[epoch14, step1543]: loss 41.775898
[epoch14, step1544]: loss 5.820153
[epoch14, step1545]: loss 13.987211
[epoch14, step1546]: loss 12.890570
[epoch14, step1547]: loss 1.984851
[epoch14, step1548]: loss 2.094409
[epoch14, step1549]: loss 4.420624
[epoch14, step1550]: loss 1.781928
[epoch14, step1551]: loss 5.996285
[epoch14, step1552]: loss 1.588218
[epoch14, step1553]: loss 2.026091
[epoch14, step1554]: loss 0.999591
[epoch14, step1555]: loss 1.916513
[epoch14, step1556]: loss 1.087284
[epoch14, step1557]: loss 2.817091
[epoch14, step1558]: loss 15.653339
[epoch14, step1559]: loss 1.633159
[epoch14, step1560]: loss 16.779095
[epoch14, step1561]: loss 2.089635
[epoch14, step1562]: loss 6.767456
[epoch14, step1563]: loss 9.978589
[epoch14, step1564]: loss 10.208203
[epoch14, step1565]: loss 14.099429
[epoch14, step1566]: loss 2.720585
[epoch14, step1567]: loss 2.239540
[epoch14, step1568]: loss 5.158731
[epoch14, step1569]: loss 9.470402
[epoch14, step1570]: loss 1.457162
[epoch14, step1571]: loss 4.595759
[epoch14, step1572]: loss 11.267107
[epoch14, step1573]: loss 0.841595
[epoch14, step1574]: loss 3.267034
[epoch14, step1575]: loss 0.774839
[epoch14, step1576]: loss 2.648660
[epoch14, step1577]: loss 2.382613
[epoch14, step1578]: loss 0.994710
[epoch14, step1579]: loss 1.029026
[epoch14, step1580]: loss 1.120242
[epoch14, step1581]: loss 1.910344
[epoch14, step1582]: loss 0.732939
[epoch14, step1583]: loss 3.628446
[epoch14, step1584]: loss 8.003408
[epoch14, step1585]: loss 1.262623
[epoch14, step1586]: loss 0.635810
[epoch14, step1587]: loss 8.220619
[epoch14, step1588]: loss 1.320993
[epoch14, step1589]: loss 1.036306
[epoch14, step1590]: loss 1.644320
[epoch14, step1591]: loss 2.553886
[epoch14, step1592]: loss 8.514943
[epoch14, step1593]: loss 13.042267
[epoch14, step1594]: loss 0.947331
[epoch14, step1595]: loss 1.466270
[epoch14, step1596]: loss 11.088793
[epoch14, step1597]: loss 4.465347
[epoch14, step1598]: loss 2.512999
[epoch14, step1599]: loss 1.159550
[epoch14, step1600]: loss 2.758590
[epoch14, step1601]: loss 1.131235
[epoch14, step1602]: loss 1.171296
[epoch14, step1603]: loss 1.945623
[epoch14, step1604]: loss 1.618116
[epoch14, step1605]: loss 7.967266
[epoch14, step1606]: loss 1.204004
[epoch14, step1607]: loss 2.771475
[epoch14, step1608]: loss 0.869802
[epoch14, step1609]: loss 0.958585
[epoch14, step1610]: loss 1.057571
[epoch14, step1611]: loss 2.984371
[epoch14, step1612]: loss 9.154591
[epoch14, step1613]: loss 1.927072
[epoch14, step1614]: loss 0.877486
[epoch14, step1615]: loss 2.002051
[epoch14, step1616]: loss 0.861232
[epoch14, step1617]: loss 2.967135
[epoch14, step1618]: loss 1.872943
[epoch14, step1619]: loss 1.250733
[epoch14, step1620]: loss 1.464953
[epoch14, step1621]: loss 2.208843
[epoch14, step1622]: loss 0.670116
[epoch14, step1623]: loss 1.899920
[epoch14, step1624]: loss 12.719248
[epoch14, step1625]: loss 18.601093
[epoch14, step1626]: loss 2.056365
[epoch14, step1627]: loss 3.195434
[epoch14, step1628]: loss 4.214831
[epoch14, step1629]: loss 7.429535
[epoch14, step1630]: loss 0.942493
[epoch14, step1631]: loss 1.802176
[epoch14, step1632]: loss 0.897447
[epoch14, step1633]: loss 0.725486
[epoch14, step1634]: loss 0.941033
[epoch14, step1635]: loss 18.668289
[epoch14, step1636]: loss 2.786681
[epoch14, step1637]: loss 18.439993
[epoch14, step1638]: loss 1.821193
[epoch14, step1639]: loss 0.866102
[epoch14, step1640]: loss 0.846744
[epoch14, step1641]: loss 1.879180
[epoch14, step1642]: loss 4.409678
[epoch14, step1643]: loss 0.926302
[epoch14, step1644]: loss 1.548860
[epoch14, step1645]: loss 1.497782
[epoch14, step1646]: loss 0.718110
[epoch14, step1647]: loss 3.301519
[epoch14, step1648]: loss 1.393427
[epoch14, step1649]: loss 1.623214
[epoch14, step1650]: loss 6.706464
[epoch14, step1651]: loss 1.625903
[epoch14, step1652]: loss 11.126763
[epoch14, step1653]: loss 2.536966
[epoch14, step1654]: loss 4.773528
[epoch14, step1655]: loss 0.887545
[epoch14, step1656]: loss 11.122865
[epoch14, step1657]: loss 2.469432
[epoch14, step1658]: loss 1.205706
[epoch14, step1659]: loss 1.337091
[epoch14, step1660]: loss 3.861795
[epoch14, step1661]: loss 1.084121
[epoch14, step1662]: loss 15.066530
[epoch14, step1663]: loss 8.027699
[epoch14, step1664]: loss 6.922116
[epoch14, step1665]: loss 13.031277
[epoch14, step1666]: loss 0.680626
[epoch14, step1667]: loss 1.335541
[epoch14, step1668]: loss 4.832523
[epoch14, step1669]: loss 1.379537
[epoch14, step1670]: loss 2.274148
[epoch14, step1671]: loss 0.971699
[epoch14, step1672]: loss 1.864071
[epoch14, step1673]: loss 0.935251
[epoch14, step1674]: loss 0.781433
[epoch14, step1675]: loss 9.223375
[epoch14, step1676]: loss 2.361562
[epoch14, step1677]: loss 12.830284
[epoch14, step1678]: loss 0.748132
[epoch14, step1679]: loss 0.832967
[epoch14, step1680]: loss 9.202306
[epoch14, step1681]: loss 10.865005
[epoch14, step1682]: loss 0.522057
[epoch14, step1683]: loss 1.530601
[epoch14, step1684]: loss 2.258890
[epoch14, step1685]: loss 1.834921
[epoch14, step1686]: loss 2.316615
[epoch14, step1687]: loss 19.713934
[epoch14, step1688]: loss 11.212564
[epoch14, step1689]: loss 1.251967
[epoch14, step1690]: loss 1.714268
[epoch14, step1691]: loss 1.407529
[epoch14, step1692]: loss 2.290649
[epoch14, step1693]: loss 5.615671
[epoch14, step1694]: loss 1.279668
[epoch14, step1695]: loss 1.166781
[epoch14, step1696]: loss 1.621770
[epoch14, step1697]: loss 1.670486
[epoch14, step1698]: loss 7.888638
[epoch14, step1699]: loss 2.274566
[epoch14, step1700]: loss 14.719036
[epoch14, step1701]: loss 8.803045
[epoch14, step1702]: loss 3.168686
[epoch14, step1703]: loss 0.887924
[epoch14, step1704]: loss 1.802477
[epoch14, step1705]: loss 7.208257
[epoch14, step1706]: loss 2.572393
[epoch14, step1707]: loss 2.069486
[epoch14, step1708]: loss 2.993842
[epoch14, step1709]: loss 14.060350
[epoch14, step1710]: loss 15.598994
[epoch14, step1711]: loss 12.522848
[epoch14, step1712]: loss 1.038296
[epoch14, step1713]: loss 1.058849
[epoch14, step1714]: loss 3.037893
[epoch14, step1715]: loss 1.674198
[epoch14, step1716]: loss 2.878131
[epoch14, step1717]: loss 2.961133
[epoch14, step1718]: loss 1.105991
[epoch14, step1719]: loss 1.002542
[epoch14, step1720]: loss 7.688833
[epoch14, step1721]: loss 3.998873
[epoch14, step1722]: loss 1.336491
[epoch14, step1723]: loss 0.947691
[epoch14, step1724]: loss 1.954394
[epoch14, step1725]: loss 11.121563
[epoch14, step1726]: loss 3.488096
[epoch14, step1727]: loss 1.415137
[epoch14, step1728]: loss 1.277064
[epoch14, step1729]: loss 0.637833
[epoch14, step1730]: loss 2.922680
[epoch14, step1731]: loss 0.855069
[epoch14, step1732]: loss 1.713896
[epoch14, step1733]: loss 6.912742
[epoch14, step1734]: loss 4.813661
[epoch14, step1735]: loss 0.863718
[epoch14, step1736]: loss 0.767122
[epoch14, step1737]: loss 0.794759
[epoch14, step1738]: loss 1.270756
[epoch14, step1739]: loss 3.323742
[epoch14, step1740]: loss 4.277770
[epoch14, step1741]: loss 0.995366
[epoch14, step1742]: loss 2.627083
[epoch14, step1743]: loss 1.718428
[epoch14, step1744]: loss 4.592306
[epoch14, step1745]: loss 1.741286
[epoch14, step1746]: loss 3.681168
[epoch14, step1747]: loss 9.159735
[epoch14, step1748]: loss 1.888026
[epoch14, step1749]: loss 20.704576
[epoch14, step1750]: loss 0.550075
[epoch14, step1751]: loss 1.303017
[epoch14, step1752]: loss 3.325615
[epoch14, step1753]: loss 1.088126
[epoch14, step1754]: loss 1.131560
[epoch14, step1755]: loss 1.858141
[epoch14, step1756]: loss 1.574108
[epoch14, step1757]: loss 15.559341
[epoch14, step1758]: loss 2.322172
[epoch14, step1759]: loss 4.931921
[epoch14, step1760]: loss 7.631942
[epoch14, step1761]: loss 1.891809
[epoch14, step1762]: loss 0.917750
[epoch14, step1763]: loss 0.911575
[epoch14, step1764]: loss 1.421204
[epoch14, step1765]: loss 22.199009
[epoch14, step1766]: loss 1.559106
[epoch14, step1767]: loss 1.174556
[epoch14, step1768]: loss 2.273448
[epoch14, step1769]: loss 16.944448
[epoch14, step1770]: loss 3.320609
[epoch14, step1771]: loss 1.401472
[epoch14, step1772]: loss 0.966548
[epoch14, step1773]: loss 1.042538
[epoch14, step1774]: loss 15.416274
[epoch14, step1775]: loss 0.563065
[epoch14, step1776]: loss 3.777512
[epoch14, step1777]: loss 13.436770
[epoch14, step1778]: loss 4.062166
[epoch14, step1779]: loss 1.997675
[epoch14, step1780]: loss 23.203823
[epoch14, step1781]: loss 23.956287
[epoch14, step1782]: loss 1.145280
[epoch14, step1783]: loss 1.438289
[epoch14, step1784]: loss 1.954940
[epoch14, step1785]: loss 0.908900
[epoch14, step1786]: loss 0.814461
[epoch14, step1787]: loss 5.841345
[epoch14, step1788]: loss 3.147150
[epoch14, step1789]: loss 1.226183
[epoch14, step1790]: loss 38.272774
[epoch14, step1791]: loss 1.139213
[epoch14, step1792]: loss 4.615317
[epoch14, step1793]: loss 1.041972
[epoch14, step1794]: loss 0.980434
[epoch14, step1795]: loss 1.566892
[epoch14, step1796]: loss 1.150923
[epoch14, step1797]: loss 1.573825
[epoch14, step1798]: loss 0.865483
[epoch14, step1799]: loss 1.238356
[epoch14, step1800]: loss 18.271650
[epoch14, step1801]: loss 0.842431
[epoch14, step1802]: loss 1.341015
[epoch14, step1803]: loss 1.948671
[epoch14, step1804]: loss 15.720339
[epoch14, step1805]: loss 1.979023
[epoch14, step1806]: loss 0.851122
[epoch14, step1807]: loss 13.387744
[epoch14, step1808]: loss 3.689433
[epoch14, step1809]: loss 6.838920
[epoch14, step1810]: loss 2.037275
[epoch14, step1811]: loss 4.499123
[epoch14, step1812]: loss 2.408326
[epoch14, step1813]: loss 1.389644
[epoch14, step1814]: loss 1.002728
[epoch14, step1815]: loss 12.583611
[epoch14, step1816]: loss 4.107102
[epoch14, step1817]: loss 3.008883
[epoch14, step1818]: loss 2.735090
[epoch14, step1819]: loss 0.997349
[epoch14, step1820]: loss 0.831075
[epoch14, step1821]: loss 10.771811
[epoch14, step1822]: loss 2.919694
[epoch14, step1823]: loss 8.668758
[epoch14, step1824]: loss 17.289654
[epoch14, step1825]: loss 11.909274
[epoch14, step1826]: loss 5.043974
[epoch14, step1827]: loss 10.051395
[epoch14, step1828]: loss 1.432899
[epoch14, step1829]: loss 1.265196
[epoch14, step1830]: loss 0.720659
[epoch14, step1831]: loss 1.160955
[epoch14, step1832]: loss 1.955272
[epoch14, step1833]: loss 2.977636
[epoch14, step1834]: loss 4.316756
[epoch14, step1835]: loss 6.514279
[epoch14, step1836]: loss 1.869950
[epoch14, step1837]: loss 1.763360
[epoch14, step1838]: loss 1.267357
[epoch14, step1839]: loss 8.141983
[epoch14, step1840]: loss 0.929652
[epoch14, step1841]: loss 1.308282
[epoch14, step1842]: loss 0.993476
[epoch14, step1843]: loss 3.149667
[epoch14, step1844]: loss 1.286534
[epoch14, step1845]: loss 2.984509
[epoch14, step1846]: loss 12.550361
[epoch14, step1847]: loss 0.778539
[epoch14, step1848]: loss 2.188362
[epoch14, step1849]: loss 3.332700
[epoch14, step1850]: loss 9.266335
[epoch14, step1851]: loss 19.483509
[epoch14, step1852]: loss 3.746557
[epoch14, step1853]: loss 1.479278
[epoch14, step1854]: loss 0.592436
[epoch14, step1855]: loss 1.700541
[epoch14, step1856]: loss 2.118062
[epoch14, step1857]: loss 1.094741
[epoch14, step1858]: loss 1.405050
[epoch14, step1859]: loss 1.393814
[epoch14, step1860]: loss 4.811418
[epoch14, step1861]: loss 3.623578
[epoch14, step1862]: loss 14.592253
[epoch14, step1863]: loss 16.805645
[epoch14, step1864]: loss 1.053370
[epoch14, step1865]: loss 4.339899
[epoch14, step1866]: loss 1.289320
[epoch14, step1867]: loss 5.465166
[epoch14, step1868]: loss 21.728626
[epoch14, step1869]: loss 6.250003
[epoch14, step1870]: loss 0.896947
[epoch14, step1871]: loss 11.943770
[epoch14, step1872]: loss 0.451669
[epoch14, step1873]: loss 2.124198
[epoch14, step1874]: loss 0.863825
[epoch14, step1875]: loss 13.320492
[epoch14, step1876]: loss 1.673208
[epoch14, step1877]: loss 0.787227
[epoch14, step1878]: loss 2.999469
[epoch14, step1879]: loss 0.829235
[epoch14, step1880]: loss 1.252356
[epoch14, step1881]: loss 7.159529
[epoch14, step1882]: loss 4.422215
[epoch14, step1883]: loss 0.666300
[epoch14, step1884]: loss 10.487424
[epoch14, step1885]: loss 5.568781
[epoch14, step1886]: loss 12.852279
[epoch14, step1887]: loss 4.786772
[epoch14, step1888]: loss 2.001806
[epoch14, step1889]: loss 1.300338
[epoch14, step1890]: loss 1.024865
[epoch14, step1891]: loss 1.328677
[epoch14, step1892]: loss 4.959312
[epoch14, step1893]: loss 0.807359
[epoch14, step1894]: loss 1.627757
[epoch14, step1895]: loss 2.331846
[epoch14, step1896]: loss 1.132944
[epoch14, step1897]: loss 8.269311
[epoch14, step1898]: loss 2.120744
[epoch14, step1899]: loss 1.188069
[epoch14, step1900]: loss 8.779197
[epoch14, step1901]: loss 0.809505
[epoch14, step1902]: loss 1.395977
[epoch14, step1903]: loss 1.050115
[epoch14, step1904]: loss 1.023216
[epoch14, step1905]: loss 14.603572
[epoch14, step1906]: loss 16.742743
[epoch14, step1907]: loss 3.060318
[epoch14, step1908]: loss 9.543268
[epoch14, step1909]: loss 1.237306
[epoch14, step1910]: loss 0.775378
[epoch14, step1911]: loss 30.606865
[epoch14, step1912]: loss 10.538543
[epoch14, step1913]: loss 0.668770
[epoch14, step1914]: loss 1.057562
[epoch14, step1915]: loss 1.282693
[epoch14, step1916]: loss 0.670690
[epoch14, step1917]: loss 1.011487
[epoch14, step1918]: loss 23.908209
[epoch14, step1919]: loss 2.251708
[epoch14, step1920]: loss 5.554964
[epoch14, step1921]: loss 1.300428
[epoch14, step1922]: loss 0.673954
[epoch14, step1923]: loss 1.622507
[epoch14, step1924]: loss 1.310262
[epoch14, step1925]: loss 0.730343
[epoch14, step1926]: loss 2.455193
[epoch14, step1927]: loss 1.855285
[epoch14, step1928]: loss 1.083696
[epoch14, step1929]: loss 3.790371
[epoch14, step1930]: loss 2.898820
[epoch14, step1931]: loss 14.698262
[epoch14, step1932]: loss 1.214121
[epoch14, step1933]: loss 0.707386
[epoch14, step1934]: loss 2.376756
[epoch14, step1935]: loss 6.149294
[epoch14, step1936]: loss 0.929845
[epoch14, step1937]: loss 6.131063
[epoch14, step1938]: loss 7.547385
[epoch14, step1939]: loss 12.662717
[epoch14, step1940]: loss 27.571037
[epoch14, step1941]: loss 2.570698
[epoch14, step1942]: loss 1.027732
[epoch14, step1943]: loss 1.221844
[epoch14, step1944]: loss 0.946615
[epoch14, step1945]: loss 7.491744
[epoch14, step1946]: loss 0.738259
[epoch14, step1947]: loss 1.237849
[epoch14, step1948]: loss 0.693684
[epoch14, step1949]: loss 1.432763
[epoch14, step1950]: loss 1.129577
[epoch14, step1951]: loss 2.113136
[epoch14, step1952]: loss 0.858915
[epoch14, step1953]: loss 0.999700
[epoch14, step1954]: loss 6.591617
[epoch14, step1955]: loss 1.065478
[epoch14, step1956]: loss 0.769358
[epoch14, step1957]: loss 1.750344
[epoch14, step1958]: loss 1.521638
[epoch14, step1959]: loss 2.077392
[epoch14, step1960]: loss 5.031351
[epoch14, step1961]: loss 4.124663
[epoch14, step1962]: loss 2.821214
[epoch14, step1963]: loss 3.124157
[epoch14, step1964]: loss 0.819259
[epoch14, step1965]: loss 0.799943
[epoch14, step1966]: loss 2.876740
[epoch14, step1967]: loss 6.916282
[epoch14, step1968]: loss 2.659222
[epoch14, step1969]: loss 3.357649
[epoch14, step1970]: loss 1.558274
[epoch14, step1971]: loss 18.901291
[epoch14, step1972]: loss 3.241544
[epoch14, step1973]: loss 1.160448
[epoch14, step1974]: loss 0.764783
[epoch14, step1975]: loss 2.133875
[epoch14, step1976]: loss 2.100464
[epoch14, step1977]: loss 0.706298
[epoch14, step1978]: loss 2.502744
[epoch14, step1979]: loss 17.502211
[epoch14, step1980]: loss 1.629264
[epoch14, step1981]: loss 1.128234
[epoch14, step1982]: loss 1.324705
[epoch14, step1983]: loss 4.286829
[epoch14, step1984]: loss 0.545545
[epoch14, step1985]: loss 7.515577
[epoch14, step1986]: loss 1.404450
[epoch14, step1987]: loss 1.191276
[epoch14, step1988]: loss 0.926135
[epoch14, step1989]: loss 2.251308
[epoch14, step1990]: loss 10.824844
[epoch14, step1991]: loss 9.596712
[epoch14, step1992]: loss 2.443072
[epoch14, step1993]: loss 4.602785
[epoch14, step1994]: loss 4.611356
[epoch14, step1995]: loss 1.443043
[epoch14, step1996]: loss 4.901838
[epoch14, step1997]: loss 1.539212
[epoch14, step1998]: loss 2.002390
[epoch14, step1999]: loss 1.207250
[epoch14, step2000]: loss 4.937541
[epoch14, step2001]: loss 15.318303
[epoch14, step2002]: loss 3.654849
[epoch14, step2003]: loss 9.396180
[epoch14, step2004]: loss 1.805830
[epoch14, step2005]: loss 5.003683
[epoch14, step2006]: loss 0.823170
[epoch14, step2007]: loss 1.605795
[epoch14, step2008]: loss 1.637850
[epoch14, step2009]: loss 1.246878
[epoch14, step2010]: loss 11.851286
[epoch14, step2011]: loss 1.899870
[epoch14, step2012]: loss 7.650965
[epoch14, step2013]: loss 11.749692
[epoch14, step2014]: loss 0.905282
[epoch14, step2015]: loss 2.099717
[epoch14, step2016]: loss 2.665082
[epoch14, step2017]: loss 0.722211
[epoch14, step2018]: loss 1.850281
[epoch14, step2019]: loss 9.199645
[epoch14, step2020]: loss 3.298924
[epoch14, step2021]: loss 1.049001
[epoch14, step2022]: loss 16.753054
[epoch14, step2023]: loss 5.777392
[epoch14, step2024]: loss 7.801245
[epoch14, step2025]: loss 1.608151
[epoch14, step2026]: loss 1.505977
[epoch14, step2027]: loss 1.840003
[epoch14, step2028]: loss 1.634658
[epoch14, step2029]: loss 4.677138
[epoch14, step2030]: loss 1.792763
[epoch14, step2031]: loss 2.575706
[epoch14, step2032]: loss 1.173251
[epoch14, step2033]: loss 3.835431
[epoch14, step2034]: loss 1.928713
[epoch14, step2035]: loss 7.763383
[epoch14, step2036]: loss 13.655380
[epoch14, step2037]: loss 3.229076
[epoch14, step2038]: loss 4.778169
[epoch14, step2039]: loss 8.627436
[epoch14, step2040]: loss 3.298002
[epoch14, step2041]: loss 1.977835
[epoch14, step2042]: loss 14.047633
[epoch14, step2043]: loss 3.586620
[epoch14, step2044]: loss 23.381989
[epoch14, step2045]: loss 5.477125
[epoch14, step2046]: loss 9.261898
[epoch14, step2047]: loss 3.875257
[epoch14, step2048]: loss 0.940150
[epoch14, step2049]: loss 1.516506
[epoch14, step2050]: loss 3.241159
[epoch14, step2051]: loss 2.259283
[epoch14, step2052]: loss 0.964200
[epoch14, step2053]: loss 9.189153
[epoch14, step2054]: loss 0.987064
[epoch14, step2055]: loss 1.039003
[epoch14, step2056]: loss 1.068917
[epoch14, step2057]: loss 1.525840
[epoch14, step2058]: loss 3.395099
[epoch14, step2059]: loss 12.496643
[epoch14, step2060]: loss 1.618997
[epoch14, step2061]: loss 0.960132
[epoch14, step2062]: loss 1.016617
[epoch14, step2063]: loss 0.791401
[epoch14, step2064]: loss 2.026619
[epoch14, step2065]: loss 1.146474
[epoch14, step2066]: loss 6.958043
[epoch14, step2067]: loss 8.043594
[epoch14, step2068]: loss 1.160329
[epoch14, step2069]: loss 0.651550
[epoch14, step2070]: loss 1.083050
[epoch14, step2071]: loss 0.900641
[epoch14, step2072]: loss 10.876112
[epoch14, step2073]: loss 5.821092
[epoch14, step2074]: loss 3.717099
[epoch14, step2075]: loss 1.400238
[epoch14, step2076]: loss 2.569008
[epoch14, step2077]: loss 1.456882
[epoch14, step2078]: loss 4.043935
[epoch14, step2079]: loss 1.057432
[epoch14, step2080]: loss 2.401094
[epoch14, step2081]: loss 0.806602
[epoch14, step2082]: loss 0.763410
[epoch14, step2083]: loss 4.152935
[epoch14, step2084]: loss 11.186705
[epoch14, step2085]: loss 1.365270
[epoch14, step2086]: loss 0.611338
[epoch14, step2087]: loss 1.229644
[epoch14, step2088]: loss 1.476640
[epoch14, step2089]: loss 2.108294
[epoch14, step2090]: loss 0.798116
[epoch14, step2091]: loss 2.106663
[epoch14, step2092]: loss 0.805476
[epoch14, step2093]: loss 2.180269
[epoch14, step2094]: loss 1.198480
[epoch14, step2095]: loss 3.025637
[epoch14, step2096]: loss 1.024047
[epoch14, step2097]: loss 2.986328
[epoch14, step2098]: loss 1.502709
[epoch14, step2099]: loss 9.650571
[epoch14, step2100]: loss 9.474216
[epoch14, step2101]: loss 3.826387
[epoch14, step2102]: loss 0.982767
[epoch14, step2103]: loss 2.936090
[epoch14, step2104]: loss 8.735151
[epoch14, step2105]: loss 1.805749
[epoch14, step2106]: loss 11.291538
[epoch14, step2107]: loss 29.099270
[epoch14, step2108]: loss 5.567210
[epoch14, step2109]: loss 2.685578
[epoch14, step2110]: loss 4.864738
[epoch14, step2111]: loss 20.246065
[epoch14, step2112]: loss 13.780739
[epoch14, step2113]: loss 0.746935
[epoch14, step2114]: loss 1.598637
[epoch14, step2115]: loss 0.736332
[epoch14, step2116]: loss 1.742292
[epoch14, step2117]: loss 1.518297
[epoch14, step2118]: loss 2.119235
[epoch14, step2119]: loss 1.357114
[epoch14, step2120]: loss 1.272258
[epoch14, step2121]: loss 0.955277
[epoch14, step2122]: loss 19.455616
[epoch14, step2123]: loss 16.878658
[epoch14, step2124]: loss 12.800011
[epoch14, step2125]: loss 2.753983
[epoch14, step2126]: loss 1.167066
[epoch14, step2127]: loss 9.827510
[epoch14, step2128]: loss 0.866925
[epoch14, step2129]: loss 1.337643
[epoch14, step2130]: loss 4.328614
[epoch14, step2131]: loss 5.498631
[epoch14, step2132]: loss 13.453509
[epoch14, step2133]: loss 4.509077
[epoch14, step2134]: loss 4.778439
[epoch14, step2135]: loss 2.772911
[epoch14, step2136]: loss 1.163242
[epoch14, step2137]: loss 1.970000
[epoch14, step2138]: loss 0.697276
[epoch14, step2139]: loss 7.637633
[epoch14, step2140]: loss 1.456781
[epoch14, step2141]: loss 3.023079
[epoch14, step2142]: loss 6.788627
[epoch14, step2143]: loss 0.837228
[epoch14, step2144]: loss 1.672120
[epoch14, step2145]: loss 1.102814
[epoch14, step2146]: loss 1.953218
[epoch14, step2147]: loss 3.388083
[epoch14, step2148]: loss 4.089239
[epoch14, step2149]: loss 1.414327
[epoch14, step2150]: loss 9.318671
[epoch14, step2151]: loss 12.107312
[epoch14, step2152]: loss 0.891764
[epoch14, step2153]: loss 1.659258
[epoch14, step2154]: loss 5.272638
[epoch14, step2155]: loss 3.835762
[epoch14, step2156]: loss 0.580930
[epoch14, step2157]: loss 2.716238
[epoch14, step2158]: loss 1.967382
[epoch14, step2159]: loss 6.121459
[epoch14, step2160]: loss 3.392408
[epoch14, step2161]: loss 2.748959
[epoch14, step2162]: loss 9.468557
[epoch14, step2163]: loss 10.404724
[epoch14, step2164]: loss 2.913175
[epoch14, step2165]: loss 1.080595
[epoch14, step2166]: loss 0.738878
[epoch14, step2167]: loss 0.702806
[epoch14, step2168]: loss 1.865516
[epoch14, step2169]: loss 1.154983
[epoch14, step2170]: loss 1.115264
[epoch14, step2171]: loss 11.637539
[epoch14, step2172]: loss 1.409709
[epoch14, step2173]: loss 0.921104
[epoch14, step2174]: loss 14.136830
[epoch14, step2175]: loss 1.749235
[epoch14, step2176]: loss 10.100339
[epoch14, step2177]: loss 1.769546
[epoch14, step2178]: loss 5.240642
[epoch14, step2179]: loss 1.171410
[epoch14, step2180]: loss 1.794891
[epoch14, step2181]: loss 12.350842
[epoch14, step2182]: loss 0.785191
[epoch14, step2183]: loss 2.646144
[epoch14, step2184]: loss 8.954829
[epoch14, step2185]: loss 0.885684
[epoch14, step2186]: loss 2.269429
[epoch14, step2187]: loss 1.200058
[epoch14, step2188]: loss 1.024495
[epoch14, step2189]: loss 13.811655
[epoch14, step2190]: loss 10.510969
[epoch14, step2191]: loss 1.730607
[epoch14, step2192]: loss 9.683743
[epoch14, step2193]: loss 2.800143
[epoch14, step2194]: loss 2.270875
[epoch14, step2195]: loss 0.927044
[epoch14, step2196]: loss 15.415678
[epoch14, step2197]: loss 1.018480
[epoch14, step2198]: loss 3.417722
[epoch14, step2199]: loss 2.383029
[epoch14, step2200]: loss 7.209269
[epoch14, step2201]: loss 7.148149
[epoch14, step2202]: loss 0.938674
[epoch14, step2203]: loss 3.922840
[epoch14, step2204]: loss 1.978881
[epoch14, step2205]: loss 0.526766
[epoch14, step2206]: loss 2.694056
[epoch14, step2207]: loss 12.942360
[epoch14, step2208]: loss 0.706554
[epoch14, step2209]: loss 1.543278
[epoch14, step2210]: loss 1.421546
[epoch14, step2211]: loss 10.618319
[epoch14, step2212]: loss 0.813909
[epoch14, step2213]: loss 9.269056
[epoch14, step2214]: loss 1.043270
[epoch14, step2215]: loss 1.628286
[epoch14, step2216]: loss 1.114717
[epoch14, step2217]: loss 12.642150
[epoch14, step2218]: loss 2.276423
[epoch14, step2219]: loss 1.032355
[epoch14, step2220]: loss 1.417376
[epoch14, step2221]: loss 1.393202
[epoch14, step2222]: loss 2.349576
[epoch14, step2223]: loss 3.405156
[epoch14, step2224]: loss 8.019761
[epoch14, step2225]: loss 13.349206
[epoch14, step2226]: loss 0.621413
[epoch14, step2227]: loss 14.500136
[epoch14, step2228]: loss 7.624580
[epoch14, step2229]: loss 2.027725
[epoch14, step2230]: loss 5.421874
[epoch14, step2231]: loss 1.323026
[epoch14, step2232]: loss 7.069288
[epoch14, step2233]: loss 8.774915
[epoch14, step2234]: loss 15.042094
[epoch14, step2235]: loss 0.944513
[epoch14, step2236]: loss 12.342280
[epoch14, step2237]: loss 1.664527
[epoch14, step2238]: loss 0.921994
[epoch14, step2239]: loss 1.958672
[epoch14, step2240]: loss 2.189991
[epoch14, step2241]: loss 2.331978
[epoch14, step2242]: loss 1.096976
[epoch14, step2243]: loss 2.728916
[epoch14, step2244]: loss 1.112996
[epoch14, step2245]: loss 1.291293
[epoch14, step2246]: loss 2.575988
[epoch14, step2247]: loss 1.946165
[epoch14, step2248]: loss 6.672896
[epoch14, step2249]: loss 1.246775
[epoch14, step2250]: loss 3.733463
[epoch14, step2251]: loss 3.421812
[epoch14, step2252]: loss 1.679390
[epoch14, step2253]: loss 18.890766
[epoch14, step2254]: loss 1.395260
[epoch14, step2255]: loss 0.939930
[epoch14, step2256]: loss 8.923270
[epoch14, step2257]: loss 0.950619
[epoch14, step2258]: loss 3.532055
[epoch14, step2259]: loss 2.472373
[epoch14, step2260]: loss 15.517874
[epoch14, step2261]: loss 3.539147
[epoch14, step2262]: loss 3.158828
[epoch14, step2263]: loss 2.475136
[epoch14, step2264]: loss 0.880013
[epoch14, step2265]: loss 1.832564
[epoch14, step2266]: loss 9.640923
[epoch14, step2267]: loss 1.063287
[epoch14, step2268]: loss 1.130987
[epoch14, step2269]: loss 3.061177
[epoch14, step2270]: loss 16.835758
[epoch14, step2271]: loss 3.934327
[epoch14, step2272]: loss 13.571744
[epoch14, step2273]: loss 1.683499
[epoch14, step2274]: loss 3.503579
[epoch14, step2275]: loss 4.941864
[epoch14, step2276]: loss 0.802010
[epoch14, step2277]: loss 2.223266
[epoch14, step2278]: loss 4.027641
[epoch14, step2279]: loss 4.954640
[epoch14, step2280]: loss 1.543217
[epoch14, step2281]: loss 1.207486
[epoch14, step2282]: loss 3.605235
[epoch14, step2283]: loss 17.949821
[epoch14, step2284]: loss 1.391564
[epoch14, step2285]: loss 0.753035
[epoch14, step2286]: loss 9.002307
[epoch14, step2287]: loss 1.690550
[epoch14, step2288]: loss 1.492410
[epoch14, step2289]: loss 1.121724
[epoch14, step2290]: loss 11.922439
[epoch14, step2291]: loss 9.423700
[epoch14, step2292]: loss 3.653878
[epoch14, step2293]: loss 27.883282
[epoch14, step2294]: loss 3.303154
[epoch14, step2295]: loss 13.679492
[epoch14, step2296]: loss 3.392626
[epoch14, step2297]: loss 1.673198
[epoch14, step2298]: loss 2.411473
[epoch14, step2299]: loss 2.970951
[epoch14, step2300]: loss 3.325072
[epoch14, step2301]: loss 4.629124
[epoch14, step2302]: loss 18.487820
[epoch14, step2303]: loss 1.808049
[epoch14, step2304]: loss 1.080648
[epoch14, step2305]: loss 1.682866
[epoch14, step2306]: loss 10.584009
[epoch14, step2307]: loss 1.378846
[epoch14, step2308]: loss 2.581775
[epoch14, step2309]: loss 2.414662
[epoch14, step2310]: loss 3.777542
[epoch14, step2311]: loss 4.086750
[epoch14, step2312]: loss 3.219276
[epoch14, step2313]: loss 8.567698
[epoch14, step2314]: loss 2.254594
[epoch14, step2315]: loss 7.757622
[epoch14, step2316]: loss 0.754921
[epoch14, step2317]: loss 19.724661
[epoch14, step2318]: loss 1.659134
[epoch14, step2319]: loss 4.436654
[epoch14, step2320]: loss 2.262941
[epoch14, step2321]: loss 2.812601
[epoch14, step2322]: loss 21.064091
[epoch14, step2323]: loss 0.785088
[epoch14, step2324]: loss 13.138103
[epoch14, step2325]: loss 9.090385
[epoch14, step2326]: loss 1.841507
[epoch14, step2327]: loss 3.718665
[epoch14, step2328]: loss 0.901007
[epoch14, step2329]: loss 12.488542
[epoch14, step2330]: loss 1.961756
[epoch14, step2331]: loss 1.156575
[epoch14, step2332]: loss 0.924719
[epoch14, step2333]: loss 1.564033
[epoch14, step2334]: loss 1.517875
[epoch14, step2335]: loss 4.725112
[epoch14, step2336]: loss 0.691682
[epoch14, step2337]: loss 7.319935
[epoch14, step2338]: loss 0.704954
[epoch14, step2339]: loss 2.886648
[epoch14, step2340]: loss 2.334084
[epoch14, step2341]: loss 5.337185
[epoch14, step2342]: loss 3.418916
[epoch14, step2343]: loss 6.974880
[epoch14, step2344]: loss 11.642273
[epoch14, step2345]: loss 1.125525
[epoch14, step2346]: loss 1.260356
[epoch14, step2347]: loss 1.484963
[epoch14, step2348]: loss 1.045466
[epoch14, step2349]: loss 3.068569
[epoch14, step2350]: loss 3.921102
[epoch14, step2351]: loss 1.787694
[epoch14, step2352]: loss 12.408183
[epoch14, step2353]: loss 2.785990
[epoch14, step2354]: loss 1.576318
[epoch14, step2355]: loss 0.959354
[epoch14, step2356]: loss 4.857543
[epoch14, step2357]: loss 0.943817
[epoch14, step2358]: loss 4.283998
[epoch14, step2359]: loss 7.995116
[epoch14, step2360]: loss 1.285888
[epoch14, step2361]: loss 24.657192
[epoch14, step2362]: loss 2.350512
[epoch14, step2363]: loss 1.936844
[epoch14, step2364]: loss 0.771181
[epoch14, step2365]: loss 2.154036
[epoch14, step2366]: loss 6.286872
[epoch14, step2367]: loss 0.680676
[epoch14, step2368]: loss 18.281176
[epoch14, step2369]: loss 1.267180
[epoch14, step2370]: loss 1.002721
[epoch14, step2371]: loss 1.609867
[epoch14, step2372]: loss 1.023048
[epoch14, step2373]: loss 7.216346
[epoch14, step2374]: loss 28.752146
[epoch14, step2375]: loss 0.725260
[epoch14, step2376]: loss 2.184392
[epoch14, step2377]: loss 2.115444
[epoch14, step2378]: loss 1.029565
[epoch14, step2379]: loss 1.225434
[epoch14, step2380]: loss 0.600172
[epoch14, step2381]: loss 4.718270
[epoch14, step2382]: loss 12.284691
[epoch14, step2383]: loss 4.766568
[epoch14, step2384]: loss 4.580757
[epoch14, step2385]: loss 3.460131
[epoch14, step2386]: loss 0.833422
[epoch14, step2387]: loss 11.407074
[epoch14, step2388]: loss 7.909167
[epoch14, step2389]: loss 1.509129
[epoch14, step2390]: loss 9.786647
[epoch14, step2391]: loss 9.885861
[epoch14, step2392]: loss 1.941582
[epoch14, step2393]: loss 1.981283
[epoch14, step2394]: loss 1.592419
[epoch14, step2395]: loss 1.858193
[epoch14, step2396]: loss 1.221739
[epoch14, step2397]: loss 11.370657
[epoch14, step2398]: loss 7.894881
[epoch14, step2399]: loss 2.212560
[epoch14, step2400]: loss 3.440531
[epoch14, step2401]: loss 1.254137
[epoch14, step2402]: loss 14.220612
[epoch14, step2403]: loss 2.568858
[epoch14, step2404]: loss 3.076595
[epoch14, step2405]: loss 2.682592
[epoch14, step2406]: loss 9.704187
[epoch14, step2407]: loss 2.286587
[epoch14, step2408]: loss 2.481522
[epoch14, step2409]: loss 0.705400
[epoch14, step2410]: loss 1.140763
[epoch14, step2411]: loss 6.602825
[epoch14, step2412]: loss 5.053103
[epoch14, step2413]: loss 39.016228
[epoch14, step2414]: loss 12.101825
[epoch14, step2415]: loss 10.481853
[epoch14, step2416]: loss 6.723680
[epoch14, step2417]: loss 1.977751
[epoch14, step2418]: loss 20.812561
[epoch14, step2419]: loss 4.603355
[epoch14, step2420]: loss 7.323842
[epoch14, step2421]: loss 1.041043
[epoch14, step2422]: loss 0.709244
[epoch14, step2423]: loss 16.201878
[epoch14, step2424]: loss 1.833598
[epoch14, step2425]: loss 1.790060
[epoch14, step2426]: loss 1.892669
[epoch14, step2427]: loss 3.626072
[epoch14, step2428]: loss 5.671316
[epoch14, step2429]: loss 3.929183
[epoch14, step2430]: loss 1.254861
[epoch14, step2431]: loss 1.787578
[epoch14, step2432]: loss 1.267992
[epoch14, step2433]: loss 1.041385
[epoch14, step2434]: loss 18.740368
[epoch14, step2435]: loss 7.741337
[epoch14, step2436]: loss 9.949626
[epoch14, step2437]: loss 1.434455
[epoch14, step2438]: loss 2.248189
[epoch14, step2439]: loss 1.081081
[epoch14, step2440]: loss 8.350574
[epoch14, step2441]: loss 3.026258
[epoch14, step2442]: loss 3.514610
[epoch14, step2443]: loss 3.080810
[epoch14, step2444]: loss 1.024781
[epoch14, step2445]: loss 1.172640
[epoch14, step2446]: loss 14.984648
[epoch14, step2447]: loss 6.088290
[epoch14, step2448]: loss 1.708193
[epoch14, step2449]: loss 1.533451
[epoch14, step2450]: loss 4.615550
[epoch14, step2451]: loss 12.330907
[epoch14, step2452]: loss 3.723694
[epoch14, step2453]: loss 2.668162
[epoch14, step2454]: loss 2.355814
[epoch14, step2455]: loss 2.175004
[epoch14, step2456]: loss 13.011679
[epoch14, step2457]: loss 1.111481
[epoch14, step2458]: loss 5.127436
[epoch14, step2459]: loss 1.864186
[epoch14, step2460]: loss 1.586913
[epoch14, step2461]: loss 1.527193
[epoch14, step2462]: loss 2.102427
[epoch14, step2463]: loss 7.124841
[epoch14, step2464]: loss 2.223873
[epoch14, step2465]: loss 17.692930
[epoch14, step2466]: loss 11.865563
[epoch14, step2467]: loss 1.065307
[epoch14, step2468]: loss 2.044411
[epoch14, step2469]: loss 2.667530
[epoch14, step2470]: loss 3.085335
[epoch14, step2471]: loss 1.351035
[epoch14, step2472]: loss 1.271028
[epoch14, step2473]: loss 10.841564
[epoch14, step2474]: loss 1.430326
[epoch14, step2475]: loss 17.618937
[epoch14, step2476]: loss 21.730581
[epoch14, step2477]: loss 0.743243
[epoch14, step2478]: loss 11.466438
[epoch14, step2479]: loss 9.898226
[epoch14, step2480]: loss 2.786697
[epoch14, step2481]: loss 1.338326
[epoch14, step2482]: loss 9.580704
[epoch14, step2483]: loss 1.607645
[epoch14, step2484]: loss 8.189340
[epoch14, step2485]: loss 4.435727
[epoch14, step2486]: loss 2.305329
[epoch14, step2487]: loss 2.886477
[epoch14, step2488]: loss 6.553837
[epoch14, step2489]: loss 9.599224
[epoch14, step2490]: loss 2.858104
[epoch14, step2491]: loss 2.260982
[epoch14, step2492]: loss 2.174147
[epoch14, step2493]: loss 4.415922
[epoch14, step2494]: loss 0.866253
[epoch14, step2495]: loss 2.687509
[epoch14, step2496]: loss 8.338444
[epoch14, step2497]: loss 1.050948
[epoch14, step2498]: loss 0.670655
[epoch14, step2499]: loss 0.773046
[epoch14, step2500]: loss 0.673047
[epoch14, step2501]: loss 2.463622
[epoch14, step2502]: loss 0.920766
[epoch14, step2503]: loss 1.261452
[epoch14, step2504]: loss 3.132449
[epoch14, step2505]: loss 3.586884
[epoch14, step2506]: loss 1.500747
[epoch14, step2507]: loss 0.676574
[epoch14, step2508]: loss 1.735191
[epoch14, step2509]: loss 6.796903
[epoch14, step2510]: loss 1.628389
[epoch14, step2511]: loss 1.160638
[epoch14, step2512]: loss 1.030602
[epoch14, step2513]: loss 1.447997
[epoch14, step2514]: loss 2.506892
[epoch14, step2515]: loss 0.875658
[epoch14, step2516]: loss 0.876946
[epoch14, step2517]: loss 14.114489
[epoch14, step2518]: loss 17.210861
[epoch14, step2519]: loss 2.263052
[epoch14, step2520]: loss 6.635052
[epoch14, step2521]: loss 2.033859
[epoch14, step2522]: loss 2.170839
[epoch14, step2523]: loss 0.995223
[epoch14, step2524]: loss 2.786197
[epoch14, step2525]: loss 0.641057
[epoch14, step2526]: loss 4.112208
[epoch14, step2527]: loss 4.035012
[epoch14, step2528]: loss 1.366961
[epoch14, step2529]: loss 0.961442
[epoch14, step2530]: loss 11.365444
[epoch14, step2531]: loss 1.272272
[epoch14, step2532]: loss 0.952534
[epoch14, step2533]: loss 1.162125
[epoch14, step2534]: loss 7.731291
[epoch14, step2535]: loss 1.383051
[epoch14, step2536]: loss 15.404661
[epoch14, step2537]: loss 9.242074
[epoch14, step2538]: loss 1.101035
[epoch14, step2539]: loss 0.543594
[epoch14, step2540]: loss 0.520255
[epoch14, step2541]: loss 0.748560
[epoch14, step2542]: loss 0.447103
[epoch14, step2543]: loss 6.796342
[epoch14, step2544]: loss 10.756190
[epoch14, step2545]: loss 1.022154
[epoch14, step2546]: loss 1.571195
[epoch14, step2547]: loss 0.689129
[epoch14, step2548]: loss 10.938607
[epoch14, step2549]: loss 1.576060
[epoch14, step2550]: loss 2.187423
[epoch14, step2551]: loss 3.476648
[epoch14, step2552]: loss 4.032130
[epoch14, step2553]: loss 3.886419
[epoch14, step2554]: loss 2.421830
[epoch14, step2555]: loss 4.658993
[epoch14, step2556]: loss 2.157924
[epoch14, step2557]: loss 8.705624
[epoch14, step2558]: loss 3.591250
[epoch14, step2559]: loss 2.199335
[epoch14, step2560]: loss 0.832669
[epoch14, step2561]: loss 1.624916
[epoch14, step2562]: loss 1.033493
[epoch14, step2563]: loss 0.854065
[epoch14, step2564]: loss 0.975192
[epoch14, step2565]: loss 0.639950
[epoch14, step2566]: loss 2.176597
[epoch14, step2567]: loss 9.964522
[epoch14, step2568]: loss 0.927995
[epoch14, step2569]: loss 1.268778
[epoch14, step2570]: loss 3.134050
[epoch14, step2571]: loss 1.205860
[epoch14, step2572]: loss 0.961951
[epoch14, step2573]: loss 1.657257
[epoch14, step2574]: loss 5.880430
[epoch14, step2575]: loss 7.451047
[epoch14, step2576]: loss 1.071019
[epoch14, step2577]: loss 1.713664
[epoch14, step2578]: loss 1.447232
[epoch14, step2579]: loss 1.396655
[epoch14, step2580]: loss 6.452532
[epoch14, step2581]: loss 1.630514
[epoch14, step2582]: loss 1.619863
[epoch14, step2583]: loss 3.260863
[epoch14, step2584]: loss 14.990731
[epoch14, step2585]: loss 2.547110
[epoch14, step2586]: loss 10.713158
[epoch14, step2587]: loss 2.401036
[epoch14, step2588]: loss 1.266555
[epoch14, step2589]: loss 4.293788
[epoch14, step2590]: loss 3.589373
[epoch14, step2591]: loss 4.822379
[epoch14, step2592]: loss 2.354379
[epoch14, step2593]: loss 4.145499
[epoch14, step2594]: loss 0.670246
[epoch14, step2595]: loss 4.668549
[epoch14, step2596]: loss 1.982944
[epoch14, step2597]: loss 1.597235
[epoch14, step2598]: loss 7.742167
[epoch14, step2599]: loss 0.690636
[epoch14, step2600]: loss 16.085117
[epoch14, step2601]: loss 7.969254
[epoch14, step2602]: loss 14.998260
[epoch14, step2603]: loss 0.604415
[epoch14, step2604]: loss 1.288365
[epoch14, step2605]: loss 9.258402
[epoch14, step2606]: loss 3.440520
[epoch14, step2607]: loss 9.520341
[epoch14, step2608]: loss 0.677238
[epoch14, step2609]: loss 1.556425
[epoch14, step2610]: loss 21.667309
[epoch14, step2611]: loss 2.328542
[epoch14, step2612]: loss 1.271517
[epoch14, step2613]: loss 2.446663
[epoch14, step2614]: loss 3.747547
[epoch14, step2615]: loss 2.717483
[epoch14, step2616]: loss 2.691223
[epoch14, step2617]: loss 3.211127
[epoch14, step2618]: loss 9.287964
[epoch14, step2619]: loss 1.537148
[epoch14, step2620]: loss 3.144253
[epoch14, step2621]: loss 2.033034
[epoch14, step2622]: loss 2.335304
[epoch14, step2623]: loss 3.479028
[epoch14, step2624]: loss 0.571016
[epoch14, step2625]: loss 1.261537
[epoch14, step2626]: loss 16.020967
[epoch14, step2627]: loss 1.589005
[epoch14, step2628]: loss 7.423867
[epoch14, step2629]: loss 2.085682
[epoch14, step2630]: loss 4.399242
[epoch14, step2631]: loss 0.730149
[epoch14, step2632]: loss 2.459524
[epoch14, step2633]: loss 2.003069
[epoch14, step2634]: loss 2.801789
[epoch14, step2635]: loss 6.348673
[epoch14, step2636]: loss 0.763009
[epoch14, step2637]: loss 2.416522
[epoch14, step2638]: loss 1.718127
[epoch14, step2639]: loss 1.757825
[epoch14, step2640]: loss 0.885146
[epoch14, step2641]: loss 1.427645
[epoch14, step2642]: loss 7.616506
[epoch14, step2643]: loss 1.071156
[epoch14, step2644]: loss 1.116004
[epoch14, step2645]: loss 1.013271
[epoch14, step2646]: loss 1.201823
[epoch14, step2647]: loss 3.256744
[epoch14, step2648]: loss 6.430186
[epoch14, step2649]: loss 2.562973
[epoch14, step2650]: loss 0.505249
[epoch14, step2651]: loss 3.259325
[epoch14, step2652]: loss 1.642333
[epoch14, step2653]: loss 18.546383
[epoch14, step2654]: loss 0.621793
[epoch14, step2655]: loss 0.582952
[epoch14, step2656]: loss 8.782468
[epoch14, step2657]: loss 1.706088
[epoch14, step2658]: loss 4.086402
[epoch14, step2659]: loss 10.165194
[epoch14, step2660]: loss 1.535641
[epoch14, step2661]: loss 2.741930
[epoch14, step2662]: loss 2.021938
[epoch14, step2663]: loss 1.320203
[epoch14, step2664]: loss 2.423295
[epoch14, step2665]: loss 1.989256
[epoch14, step2666]: loss 1.341466
[epoch14, step2667]: loss 1.816049
[epoch14, step2668]: loss 0.905124
[epoch14, step2669]: loss 10.523883
[epoch14, step2670]: loss 10.172768
[epoch14, step2671]: loss 1.896729
[epoch14, step2672]: loss 1.089824
[epoch14, step2673]: loss 0.848335
[epoch14, step2674]: loss 1.638457
[epoch14, step2675]: loss 1.150495
[epoch14, step2676]: loss 1.015391
[epoch14, step2677]: loss 0.965925
[epoch14, step2678]: loss 1.097778
[epoch14, step2679]: loss 9.938704
[epoch14, step2680]: loss 2.913884
[epoch14, step2681]: loss 7.796407
[epoch14, step2682]: loss 3.110270
[epoch14, step2683]: loss 4.521266
[epoch14, step2684]: loss 1.250672
[epoch14, step2685]: loss 1.254548
[epoch14, step2686]: loss 1.895752
[epoch14, step2687]: loss 1.183169
[epoch14, step2688]: loss 1.908945
[epoch14, step2689]: loss 1.096664
[epoch14, step2690]: loss 1.090657
[epoch14, step2691]: loss 4.259115
[epoch14, step2692]: loss 5.330121
[epoch14, step2693]: loss 5.947704
[epoch14, step2694]: loss 1.474114
[epoch14, step2695]: loss 2.477066
[epoch14, step2696]: loss 7.193130
[epoch14, step2697]: loss 5.006763
[epoch14, step2698]: loss 10.311831
[epoch14, step2699]: loss 12.827647
[epoch14, step2700]: loss 4.725981
[epoch14, step2701]: loss 2.768509
[epoch14, step2702]: loss 2.751246
[epoch14, step2703]: loss 8.365647
[epoch14, step2704]: loss 1.994707
[epoch14, step2705]: loss 3.600384
[epoch14, step2706]: loss 13.055137
[epoch14, step2707]: loss 8.892491
[epoch14, step2708]: loss 1.518762
[epoch14, step2709]: loss 10.788735
[epoch14, step2710]: loss 8.536556
[epoch14, step2711]: loss 0.782519
[epoch14, step2712]: loss 0.667099
[epoch14, step2713]: loss 2.412345
[epoch14, step2714]: loss 0.701138
[epoch14, step2715]: loss 3.186363
[epoch14, step2716]: loss 1.607553
[epoch14, step2717]: loss 3.842546
[epoch14, step2718]: loss 1.099225
[epoch14, step2719]: loss 5.056932
[epoch14, step2720]: loss 1.116285
[epoch14, step2721]: loss 2.382277
[epoch14, step2722]: loss 12.179441
[epoch14, step2723]: loss 2.519942
[epoch14, step2724]: loss 2.269581
[epoch14, step2725]: loss 7.674653
[epoch14, step2726]: loss 2.335889
[epoch14, step2727]: loss 1.154755
[epoch14, step2728]: loss 2.816030
[epoch14, step2729]: loss 4.326981
[epoch14, step2730]: loss 4.395418
[epoch14, step2731]: loss 2.705343
[epoch14, step2732]: loss 1.525759
[epoch14, step2733]: loss 13.038010
[epoch14, step2734]: loss 1.046783
[epoch14, step2735]: loss 1.283782
[epoch14, step2736]: loss 0.945544
[epoch14, step2737]: loss 2.232063
[epoch14, step2738]: loss 13.982713
[epoch14, step2739]: loss 1.673456
[epoch14, step2740]: loss 4.532445
[epoch14, step2741]: loss 0.699208
[epoch14, step2742]: loss 0.951895
[epoch14, step2743]: loss 1.401405
[epoch14, step2744]: loss 1.957068
[epoch14, step2745]: loss 1.269347
[epoch14, step2746]: loss 6.298273
[epoch14, step2747]: loss 2.000753
[epoch14, step2748]: loss 0.474522
[epoch14, step2749]: loss 8.823915
[epoch14, step2750]: loss 0.929522
[epoch14, step2751]: loss 2.005872
[epoch14, step2752]: loss 7.993188
[epoch14, step2753]: loss 1.188147
[epoch14, step2754]: loss 1.407062
[epoch14, step2755]: loss 2.198909
[epoch14, step2756]: loss 17.911797
[epoch14, step2757]: loss 1.530509
[epoch14, step2758]: loss 3.598247
[epoch14, step2759]: loss 0.869851
[epoch14, step2760]: loss 0.994276
[epoch14, step2761]: loss 1.786989
[epoch14, step2762]: loss 7.249090
[epoch14, step2763]: loss 12.852194
[epoch14, step2764]: loss 1.996689
[epoch14, step2765]: loss 1.100724
[epoch14, step2766]: loss 3.981034
[epoch14, step2767]: loss 4.187813
[epoch14, step2768]: loss 10.069750
[epoch14, step2769]: loss 1.770866
[epoch14, step2770]: loss 0.959264
[epoch14, step2771]: loss 3.295666
[epoch14, step2772]: loss 2.202865
[epoch14, step2773]: loss 2.359040
[epoch14, step2774]: loss 1.678194
[epoch14, step2775]: loss 1.984482
[epoch14, step2776]: loss 4.517152
[epoch14, step2777]: loss 5.128178
[epoch14, step2778]: loss 14.768023
[epoch14, step2779]: loss 1.349851
[epoch14, step2780]: loss 4.581663
[epoch14, step2781]: loss 1.840737
[epoch14, step2782]: loss 2.859544
[epoch14, step2783]: loss 1.660357
[epoch14, step2784]: loss 1.438283
[epoch14, step2785]: loss 1.695201
[epoch14, step2786]: loss 1.592889
[epoch14, step2787]: loss 7.823400
[epoch14, step2788]: loss 0.925067
[epoch14, step2789]: loss 18.361790
[epoch14, step2790]: loss 0.738132
[epoch14, step2791]: loss 22.904722
[epoch14, step2792]: loss 1.269960
[epoch14, step2793]: loss 2.531561
[epoch14, step2794]: loss 1.969887
[epoch14, step2795]: loss 2.849925
[epoch14, step2796]: loss 1.840652
[epoch14, step2797]: loss 1.659621
[epoch14, step2798]: loss 12.612254
[epoch14, step2799]: loss 7.779227
[epoch14, step2800]: loss 11.522602
[epoch14, step2801]: loss 0.806287
[epoch14, step2802]: loss 1.466798
[epoch14, step2803]: loss 10.277184
[epoch14, step2804]: loss 2.615042
[epoch14, step2805]: loss 6.249753
[epoch14, step2806]: loss 13.179249
[epoch14, step2807]: loss 1.216336
[epoch14, step2808]: loss 1.016866
[epoch14, step2809]: loss 1.514550
[epoch14, step2810]: loss 6.657899
[epoch14, step2811]: loss 0.601573
[epoch14, step2812]: loss 1.586675
[epoch14, step2813]: loss 1.644998
[epoch14, step2814]: loss 5.855098
[epoch14, step2815]: loss 8.662317
[epoch14, step2816]: loss 17.798489
[epoch14, step2817]: loss 2.236991
[epoch14, step2818]: loss 7.025193
[epoch14, step2819]: loss 0.923838
[epoch14, step2820]: loss 4.672749
[epoch14, step2821]: loss 1.199925
[epoch14, step2822]: loss 1.656387
[epoch14, step2823]: loss 1.428809
[epoch14, step2824]: loss 8.562890
[epoch14, step2825]: loss 2.812034
[epoch14, step2826]: loss 15.778612
[epoch14, step2827]: loss 8.502789
[epoch14, step2828]: loss 21.586685
[epoch14, step2829]: loss 1.293486
[epoch14, step2830]: loss 1.244220
[epoch14, step2831]: loss 12.148067
[epoch14, step2832]: loss 0.925796
[epoch14, step2833]: loss 3.047468
[epoch14, step2834]: loss 18.639454
[epoch14, step2835]: loss 8.323363
[epoch14, step2836]: loss 8.545175
[epoch14, step2837]: loss 0.777618
[epoch14, step2838]: loss 3.731616
[epoch14, step2839]: loss 0.918809
[epoch14, step2840]: loss 16.442392
[epoch14, step2841]: loss 5.986877
[epoch14, step2842]: loss 6.270456
[epoch14, step2843]: loss 12.545174
[epoch14, step2844]: loss 0.934085
[epoch14, step2845]: loss 1.283582
[epoch14, step2846]: loss 1.876266
[epoch14, step2847]: loss 1.681615
[epoch14, step2848]: loss 0.852565
[epoch14, step2849]: loss 2.729069
[epoch14, step2850]: loss 3.305552
[epoch14, step2851]: loss 0.950287
[epoch14, step2852]: loss 8.369880
[epoch14, step2853]: loss 6.087456
[epoch14, step2854]: loss 0.712690
[epoch14, step2855]: loss 7.386551
[epoch14, step2856]: loss 1.637708
[epoch14, step2857]: loss 13.681228
[epoch14, step2858]: loss 0.757038
[epoch14, step2859]: loss 1.390182
[epoch14, step2860]: loss 10.988720
[epoch14, step2861]: loss 2.749131
[epoch14, step2862]: loss 1.524553
[epoch14, step2863]: loss 4.094899
[epoch14, step2864]: loss 6.715544
[epoch14, step2865]: loss 3.137842
[epoch14, step2866]: loss 8.293416
[epoch14, step2867]: loss 1.348812
[epoch14, step2868]: loss 1.675031
[epoch14, step2869]: loss 6.075926
[epoch14, step2870]: loss 11.017406
[epoch14, step2871]: loss 4.902287
[epoch14, step2872]: loss 14.899711
[epoch14, step2873]: loss 1.106842
[epoch14, step2874]: loss 7.351151
[epoch14, step2875]: loss 4.200563
[epoch14, step2876]: loss 14.827343
[epoch14, step2877]: loss 1.482606
[epoch14, step2878]: loss 3.125141
[epoch14, step2879]: loss 14.780699
[epoch14, step2880]: loss 8.751158
[epoch14, step2881]: loss 19.621611
[epoch14, step2882]: loss 2.397664
[epoch14, step2883]: loss 0.672164
[epoch14, step2884]: loss 0.859757
[epoch14, step2885]: loss 1.005429
[epoch14, step2886]: loss 0.911950
[epoch14, step2887]: loss 2.214950
[epoch14, step2888]: loss 2.241902
[epoch14, step2889]: loss 1.426567
[epoch14, step2890]: loss 3.359349
[epoch14, step2891]: loss 1.341722
[epoch14, step2892]: loss 1.144544
[epoch14, step2893]: loss 1.508149
[epoch14, step2894]: loss 0.821846
[epoch14, step2895]: loss 19.627279
[epoch14, step2896]: loss 0.998880
[epoch14, step2897]: loss 13.583088
[epoch14, step2898]: loss 10.789325
[epoch14, step2899]: loss 1.936426
[epoch14, step2900]: loss 9.876270
[epoch14, step2901]: loss 2.189035
[epoch14, step2902]: loss 0.762183
[epoch14, step2903]: loss 2.078939
[epoch14, step2904]: loss 2.693429
[epoch14, step2905]: loss 7.470902
[epoch14, step2906]: loss 1.041856
[epoch14, step2907]: loss 1.022881
[epoch14, step2908]: loss 1.465552
[epoch14, step2909]: loss 9.213431
[epoch14, step2910]: loss 15.302650
[epoch14, step2911]: loss 10.783761
[epoch14, step2912]: loss 1.218004
[epoch14, step2913]: loss 9.393158
[epoch14, step2914]: loss 7.758706
[epoch14, step2915]: loss 0.698219
[epoch14, step2916]: loss 1.196196
[epoch14, step2917]: loss 1.282547
[epoch14, step2918]: loss 1.289265
[epoch14, step2919]: loss 2.934334
[epoch14, step2920]: loss 3.268251
[epoch14, step2921]: loss 0.675349
[epoch14, step2922]: loss 4.890596
[epoch14, step2923]: loss 1.114075
[epoch14, step2924]: loss 5.054221
[epoch14, step2925]: loss 1.166820
[epoch14, step2926]: loss 1.840686
[epoch14, step2927]: loss 1.728408
[epoch14, step2928]: loss 10.310709
[epoch14, step2929]: loss 11.430030
[epoch14, step2930]: loss 2.964861
[epoch14, step2931]: loss 2.126675
[epoch14, step2932]: loss 1.313567
[epoch14, step2933]: loss 1.898018
[epoch14, step2934]: loss 0.939979
[epoch14, step2935]: loss 7.176978
[epoch14, step2936]: loss 1.172642
[epoch14, step2937]: loss 12.892566
[epoch14, step2938]: loss 6.354049
[epoch14, step2939]: loss 0.532633
[epoch14, step2940]: loss 2.002108
[epoch14, step2941]: loss 10.740741
[epoch14, step2942]: loss 2.916529
[epoch14, step2943]: loss 5.029763
[epoch14, step2944]: loss 3.924052
[epoch14, step2945]: loss 1.033349
[epoch14, step2946]: loss 1.684011
[epoch14, step2947]: loss 4.107221
[epoch14, step2948]: loss 11.351776
[epoch14, step2949]: loss 3.191871
[epoch14, step2950]: loss 1.677817
[epoch14, step2951]: loss 0.806425
[epoch14, step2952]: loss 1.372569
[epoch14, step2953]: loss 1.674049
[epoch14, step2954]: loss 1.240176
[epoch14, step2955]: loss 0.474297
[epoch14, step2956]: loss 7.754877
[epoch14, step2957]: loss 0.949146
[epoch14, step2958]: loss 15.270390
[epoch14, step2959]: loss 1.054679
[epoch14, step2960]: loss 5.790339
[epoch14, step2961]: loss 0.656411
[epoch14, step2962]: loss 0.897191
[epoch14, step2963]: loss 2.549339
[epoch14, step2964]: loss 3.582126
[epoch14, step2965]: loss 0.806598
[epoch14, step2966]: loss 1.099955
[epoch14, step2967]: loss 2.011550
[epoch14, step2968]: loss 1.408942
[epoch14, step2969]: loss 7.579071
[epoch14, step2970]: loss 7.755337
[epoch14, step2971]: loss 1.280504
[epoch14, step2972]: loss 0.834496
[epoch14, step2973]: loss 2.879113
[epoch14, step2974]: loss 1.181533
[epoch14, step2975]: loss 1.742980
[epoch14, step2976]: loss 1.034859
[epoch14, step2977]: loss 0.784972
[epoch14, step2978]: loss 6.439641
[epoch14, step2979]: loss 0.371350
[epoch14, step2980]: loss 2.054564
[epoch14, step2981]: loss 2.191202
[epoch14, step2982]: loss 5.328469
[epoch14, step2983]: loss 1.412594
[epoch14, step2984]: loss 12.273984
[epoch14, step2985]: loss 1.089234
[epoch14, step2986]: loss 1.740905
[epoch14, step2987]: loss 12.149013
[epoch14, step2988]: loss 2.414528
[epoch14, step2989]: loss 1.506791
[epoch14, step2990]: loss 10.406467
[epoch14, step2991]: loss 8.954318
[epoch14, step2992]: loss 0.751935
[epoch14, step2993]: loss 34.329212
[epoch14, step2994]: loss 10.159619
[epoch14, step2995]: loss 1.681835
[epoch14, step2996]: loss 0.792169
[epoch14, step2997]: loss 2.844050
[epoch14, step2998]: loss 1.200040
[epoch14, step2999]: loss 14.832860
[epoch14, step3000]: loss 1.128537
[epoch14, step3001]: loss 4.098519
[epoch14, step3002]: loss 3.456514
[epoch14, step3003]: loss 0.873405
[epoch14, step3004]: loss 6.387525
[epoch14, step3005]: loss 1.241000
[epoch14, step3006]: loss 1.273294
[epoch14, step3007]: loss 0.734338
[epoch14, step3008]: loss 2.281081
[epoch14, step3009]: loss 4.538550
[epoch14, step3010]: loss 1.713390
[epoch14, step3011]: loss 3.309382
[epoch14, step3012]: loss 11.068919
[epoch14, step3013]: loss 1.846074
[epoch14, step3014]: loss 1.713854
[epoch14, step3015]: loss 2.200020
[epoch14, step3016]: loss 0.999185
[epoch14, step3017]: loss 0.992560
[epoch14, step3018]: loss 1.885268
[epoch14, step3019]: loss 1.546431
[epoch14, step3020]: loss 0.896241
[epoch14, step3021]: loss 1.101501
[epoch14, step3022]: loss 1.763568
[epoch14, step3023]: loss 29.051174
[epoch14, step3024]: loss 19.948994
[epoch14, step3025]: loss 7.816993
[epoch14, step3026]: loss 0.788410
[epoch14, step3027]: loss 0.900510
[epoch14, step3028]: loss 10.854240
[epoch14, step3029]: loss 12.527598
[epoch14, step3030]: loss 3.168253
[epoch14, step3031]: loss 19.226971
[epoch14, step3032]: loss 2.015976
[epoch14, step3033]: loss 0.801149
[epoch14, step3034]: loss 0.825250
[epoch14, step3035]: loss 7.459976
[epoch14, step3036]: loss 0.702309
[epoch14, step3037]: loss 1.612525
[epoch14, step3038]: loss 3.164024
[epoch14, step3039]: loss 4.090854
[epoch14, step3040]: loss 1.621415
[epoch14, step3041]: loss 2.236678
[epoch14, step3042]: loss 0.871743
[epoch14, step3043]: loss 0.702909
[epoch14, step3044]: loss 0.884421
[epoch14, step3045]: loss 9.058808
[epoch14, step3046]: loss 15.610989
[epoch14, step3047]: loss 1.361681
[epoch14, step3048]: loss 1.013207
[epoch14, step3049]: loss 12.771542
[epoch14, step3050]: loss 1.302845
[epoch14, step3051]: loss 1.143867
[epoch14, step3052]: loss 11.622815
[epoch14, step3053]: loss 9.491228
[epoch14, step3054]: loss 1.365900
[epoch14, step3055]: loss 3.045943
[epoch14, step3056]: loss 1.364345
[epoch14, step3057]: loss 1.184435
[epoch14, step3058]: loss 2.817260
[epoch14, step3059]: loss 0.672048
[epoch14, step3060]: loss 1.088350
[epoch14, step3061]: loss 0.871123
[epoch14, step3062]: loss 1.242249
[epoch14, step3063]: loss 2.862115
[epoch14, step3064]: loss 3.403192
[epoch14, step3065]: loss 0.994107
[epoch14, step3066]: loss 1.304787
[epoch14, step3067]: loss 5.704500
[epoch14, step3068]: loss 18.264755
[epoch14, step3069]: loss 4.329538
[epoch14, step3070]: loss 1.195213
[epoch14, step3071]: loss 1.845878
[epoch14, step3072]: loss 2.942291
[epoch14, step3073]: loss 2.385716
[epoch14, step3074]: loss 1.011096
[epoch14, step3075]: loss 9.747417
[epoch14, step3076]: loss 13.078303

[epoch14]: avg loss 13.078303

[epoch15, step1]: loss 0.901007
[epoch15, step2]: loss 11.294466
[epoch15, step3]: loss 1.698091
[epoch15, step4]: loss 4.866217
[epoch15, step5]: loss 16.354465
[epoch15, step6]: loss 3.269300
[epoch15, step7]: loss 0.867515
[epoch15, step8]: loss 3.172209
[epoch15, step9]: loss 19.966806
[epoch15, step10]: loss 7.074702
[epoch15, step11]: loss 1.357467
[epoch15, step12]: loss 2.634207
[epoch15, step13]: loss 0.927336
[epoch15, step14]: loss 1.975331
[epoch15, step15]: loss 0.967695
[epoch15, step16]: loss 1.631456
[epoch15, step17]: loss 13.957452
[epoch15, step18]: loss 2.943850
[epoch15, step19]: loss 1.605596
[epoch15, step20]: loss 1.299935
[epoch15, step21]: loss 0.706016
[epoch15, step22]: loss 2.057165
[epoch15, step23]: loss 1.364719
[epoch15, step24]: loss 2.467741
[epoch15, step25]: loss 0.860653
[epoch15, step26]: loss 6.720325
[epoch15, step27]: loss 0.759660
[epoch15, step28]: loss 10.373618
[epoch15, step29]: loss 9.887510
[epoch15, step30]: loss 2.424808
[epoch15, step31]: loss 16.832878
[epoch15, step32]: loss 1.140104
[epoch15, step33]: loss 2.807548
[epoch15, step34]: loss 0.904549
[epoch15, step35]: loss 0.477704
[epoch15, step36]: loss 6.339557
[epoch15, step37]: loss 1.502508
[epoch15, step38]: loss 26.815815
[epoch15, step39]: loss 1.588502
[epoch15, step40]: loss 1.167364
[epoch15, step41]: loss 2.083724
[epoch15, step42]: loss 2.012663
[epoch15, step43]: loss 14.209066
[epoch15, step44]: loss 1.694753
[epoch15, step45]: loss 0.821305
[epoch15, step46]: loss 3.113254
[epoch15, step47]: loss 1.853124
[epoch15, step48]: loss 0.938402
[epoch15, step49]: loss 1.058084
[epoch15, step50]: loss 2.806673
[epoch15, step51]: loss 11.266837
[epoch15, step52]: loss 1.497158
[epoch15, step53]: loss 12.188869
[epoch15, step54]: loss 3.529104
[epoch15, step55]: loss 1.048732
[epoch15, step56]: loss 2.835399
[epoch15, step57]: loss 11.021391
[epoch15, step58]: loss 1.123644
[epoch15, step59]: loss 13.013711
[epoch15, step60]: loss 2.465163
[epoch15, step61]: loss 1.256702
[epoch15, step62]: loss 0.770579
[epoch15, step63]: loss 5.647033
[epoch15, step64]: loss 1.177116
[epoch15, step65]: loss 8.034429
[epoch15, step66]: loss 0.924962
[epoch15, step67]: loss 2.706143
[epoch15, step68]: loss 34.700428
[epoch15, step69]: loss 2.878007
[epoch15, step70]: loss 1.131061
[epoch15, step71]: loss 9.377811
[epoch15, step72]: loss 2.960265
[epoch15, step73]: loss 1.157137
[epoch15, step74]: loss 0.515573
[epoch15, step75]: loss 1.597602
[epoch15, step76]: loss 0.922209
[epoch15, step77]: loss 13.848772
[epoch15, step78]: loss 1.340610
[epoch15, step79]: loss 1.831882
[epoch15, step80]: loss 2.599376
[epoch15, step81]: loss 1.522632
[epoch15, step82]: loss 3.158356
[epoch15, step83]: loss 1.735395
[epoch15, step84]: loss 1.199870
[epoch15, step85]: loss 0.817456
[epoch15, step86]: loss 0.885143
[epoch15, step87]: loss 0.693427
[epoch15, step88]: loss 1.499348
[epoch15, step89]: loss 0.757388
[epoch15, step90]: loss 15.916373
[epoch15, step91]: loss 0.802103
[epoch15, step92]: loss 0.911036
[epoch15, step93]: loss 14.842255
[epoch15, step94]: loss 11.725185
[epoch15, step95]: loss 2.391879
[epoch15, step96]: loss 2.920574
[epoch15, step97]: loss 13.611231
[epoch15, step98]: loss 0.873039
[epoch15, step99]: loss 1.303082
[epoch15, step100]: loss 1.147636
[epoch15, step101]: loss 1.126153
[epoch15, step102]: loss 5.162696
[epoch15, step103]: loss 6.156913
[epoch15, step104]: loss 1.229545
[epoch15, step105]: loss 5.430499
[epoch15, step106]: loss 1.851853
[epoch15, step107]: loss 6.781109
[epoch15, step108]: loss 1.730508
[epoch15, step109]: loss 1.689405
[epoch15, step110]: loss 2.614662
[epoch15, step111]: loss 16.888878
[epoch15, step112]: loss 3.465653
[epoch15, step113]: loss 0.883747
[epoch15, step114]: loss 7.355674
[epoch15, step115]: loss 0.579427
[epoch15, step116]: loss 0.886856
[epoch15, step117]: loss 5.588223
[epoch15, step118]: loss 12.497827
[epoch15, step119]: loss 7.297968
[epoch15, step120]: loss 14.224848
[epoch15, step121]: loss 1.234190
[epoch15, step122]: loss 2.175790
[epoch15, step123]: loss 0.764672
[epoch15, step124]: loss 1.749668
[epoch15, step125]: loss 8.249882
[epoch15, step126]: loss 2.220510
[epoch15, step127]: loss 7.598653
[epoch15, step128]: loss 10.707819
[epoch15, step129]: loss 15.295103
[epoch15, step130]: loss 6.354575
[epoch15, step131]: loss 1.029978
[epoch15, step132]: loss 10.565596
[epoch15, step133]: loss 1.041004
[epoch15, step134]: loss 9.814248
[epoch15, step135]: loss 1.023601
[epoch15, step136]: loss 9.984455
[epoch15, step137]: loss 2.946373
[epoch15, step138]: loss 12.110970
[epoch15, step139]: loss 11.728539
[epoch15, step140]: loss 14.664796
[epoch15, step141]: loss 3.665094
[epoch15, step142]: loss 2.146341
[epoch15, step143]: loss 4.058081
[epoch15, step144]: loss 0.932908
[epoch15, step145]: loss 1.198224
[epoch15, step146]: loss 10.516727
[epoch15, step147]: loss 16.387468
[epoch15, step148]: loss 2.468189
[epoch15, step149]: loss 9.021422
[epoch15, step150]: loss 0.856246
[epoch15, step151]: loss 13.636496
[epoch15, step152]: loss 1.019529
[epoch15, step153]: loss 3.197401
[epoch15, step154]: loss 2.183388
[epoch15, step155]: loss 2.449460
[epoch15, step156]: loss 2.102967
[epoch15, step157]: loss 2.617007
[epoch15, step158]: loss 1.545715
[epoch15, step159]: loss 0.908886
[epoch15, step160]: loss 3.797044
[epoch15, step161]: loss 6.892648
[epoch15, step162]: loss 1.087209
[epoch15, step163]: loss 0.855307
[epoch15, step164]: loss 1.521554
[epoch15, step165]: loss 2.709894
[epoch15, step166]: loss 0.737534
[epoch15, step167]: loss 2.100101
[epoch15, step168]: loss 2.197846
[epoch15, step169]: loss 6.684026
[epoch15, step170]: loss 10.341063
[epoch15, step171]: loss 0.747554
[epoch15, step172]: loss 8.608556
[epoch15, step173]: loss 2.003052
[epoch15, step174]: loss 1.094897
[epoch15, step175]: loss 0.865697
[epoch15, step176]: loss 1.339810
[epoch15, step177]: loss 1.117719
[epoch15, step178]: loss 1.243016
[epoch15, step179]: loss 4.605619
[epoch15, step180]: loss 1.484319
[epoch15, step181]: loss 1.777710
[epoch15, step182]: loss 0.857689
[epoch15, step183]: loss 2.116362
[epoch15, step184]: loss 4.346101
[epoch15, step185]: loss 20.358820
[epoch15, step186]: loss 5.086229
[epoch15, step187]: loss 3.238615
[epoch15, step188]: loss 0.932767
[epoch15, step189]: loss 2.444550
[epoch15, step190]: loss 0.582527
[epoch15, step191]: loss 6.024334
[epoch15, step192]: loss 1.026857
[epoch15, step193]: loss 1.540786
[epoch15, step194]: loss 0.790863
[epoch15, step195]: loss 4.631641
[epoch15, step196]: loss 0.927866
[epoch15, step197]: loss 25.324633
[epoch15, step198]: loss 3.728573
[epoch15, step199]: loss 1.791701
[epoch15, step200]: loss 1.213284
[epoch15, step201]: loss 4.166413
[epoch15, step202]: loss 6.919388
[epoch15, step203]: loss 13.143950
[epoch15, step204]: loss 1.877415
[epoch15, step205]: loss 2.862727
[epoch15, step206]: loss 0.823215
[epoch15, step207]: loss 1.551103
[epoch15, step208]: loss 0.829270
[epoch15, step209]: loss 3.410879
[epoch15, step210]: loss 2.591308
[epoch15, step211]: loss 1.049484
[epoch15, step212]: loss 2.038527
[epoch15, step213]: loss 1.330544
[epoch15, step214]: loss 17.838301
[epoch15, step215]: loss 2.328328
[epoch15, step216]: loss 0.465860
[epoch15, step217]: loss 1.320578
[epoch15, step218]: loss 9.589808
[epoch15, step219]: loss 1.047598
[epoch15, step220]: loss 12.123454
[epoch15, step221]: loss 1.297316
[epoch15, step222]: loss 1.046048
[epoch15, step223]: loss 22.589521
[epoch15, step224]: loss 1.059884
[epoch15, step225]: loss 1.360783
[epoch15, step226]: loss 3.331921
[epoch15, step227]: loss 15.545539
[epoch15, step228]: loss 1.754941
[epoch15, step229]: loss 3.231000
[epoch15, step230]: loss 3.786848
[epoch15, step231]: loss 6.175941
[epoch15, step232]: loss 2.856092
[epoch15, step233]: loss 2.119350
[epoch15, step234]: loss 17.393921
[epoch15, step235]: loss 1.156904
[epoch15, step236]: loss 8.630079
[epoch15, step237]: loss 1.402046
[epoch15, step238]: loss 3.170484
[epoch15, step239]: loss 1.522496
[epoch15, step240]: loss 2.243695
[epoch15, step241]: loss 2.247670
[epoch15, step242]: loss 10.250032
[epoch15, step243]: loss 1.520134
[epoch15, step244]: loss 0.685154
[epoch15, step245]: loss 2.871344
[epoch15, step246]: loss 5.422498
[epoch15, step247]: loss 6.199155
[epoch15, step248]: loss 12.384633
[epoch15, step249]: loss 29.925247
[epoch15, step250]: loss 1.384714
[epoch15, step251]: loss 2.828097
[epoch15, step252]: loss 8.896899
[epoch15, step253]: loss 0.869924
[epoch15, step254]: loss 3.457209
[epoch15, step255]: loss 2.196529
[epoch15, step256]: loss 1.602295
[epoch15, step257]: loss 1.542441
[epoch15, step258]: loss 4.791375
[epoch15, step259]: loss 0.904694
[epoch15, step260]: loss 2.667190
[epoch15, step261]: loss 0.801781
[epoch15, step262]: loss 1.054770
[epoch15, step263]: loss 10.586740
[epoch15, step264]: loss 2.029748
[epoch15, step265]: loss 2.744932
[epoch15, step266]: loss 3.666339
[epoch15, step267]: loss 0.759606
[epoch15, step268]: loss 8.698109
[epoch15, step269]: loss 2.685535
[epoch15, step270]: loss 1.095014
[epoch15, step271]: loss 1.396478
[epoch15, step272]: loss 6.366821
[epoch15, step273]: loss 1.475858
[epoch15, step274]: loss 1.404876
[epoch15, step275]: loss 1.178601
[epoch15, step276]: loss 6.861466
[epoch15, step277]: loss 1.021077
[epoch15, step278]: loss 1.101092
[epoch15, step279]: loss 17.410049
[epoch15, step280]: loss 1.206520
[epoch15, step281]: loss 3.213158
[epoch15, step282]: loss 0.904723
[epoch15, step283]: loss 2.092930
[epoch15, step284]: loss 0.470637
[epoch15, step285]: loss 1.886377
[epoch15, step286]: loss 7.563232
[epoch15, step287]: loss 7.213101
[epoch15, step288]: loss 1.324631
[epoch15, step289]: loss 1.750796
[epoch15, step290]: loss 1.595733
[epoch15, step291]: loss 2.016372
[epoch15, step292]: loss 2.363262
[epoch15, step293]: loss 0.928357
[epoch15, step294]: loss 9.476432
[epoch15, step295]: loss 1.110505
[epoch15, step296]: loss 3.065364
[epoch15, step297]: loss 21.166897
[epoch15, step298]: loss 3.066687
[epoch15, step299]: loss 8.887576
[epoch15, step300]: loss 16.188099
[epoch15, step301]: loss 1.164408
[epoch15, step302]: loss 2.901261
[epoch15, step303]: loss 1.559456
[epoch15, step304]: loss 2.719225
[epoch15, step305]: loss 1.278157
[epoch15, step306]: loss 3.043437
[epoch15, step307]: loss 1.835461
[epoch15, step308]: loss 1.170485
[epoch15, step309]: loss 1.642033
[epoch15, step310]: loss 0.765292
[epoch15, step311]: loss 16.257620
[epoch15, step312]: loss 0.718251
[epoch15, step313]: loss 11.639146
[epoch15, step314]: loss 2.378135
[epoch15, step315]: loss 9.671361
[epoch15, step316]: loss 7.903521
[epoch15, step317]: loss 1.586337
[epoch15, step318]: loss 2.836690
[epoch15, step319]: loss 9.958913
[epoch15, step320]: loss 14.208311
[epoch15, step321]: loss 1.027458
[epoch15, step322]: loss 2.002844
[epoch15, step323]: loss 2.852031
[epoch15, step324]: loss 30.205805
[epoch15, step325]: loss 0.892231
[epoch15, step326]: loss 1.744162
[epoch15, step327]: loss 1.342088
[epoch15, step328]: loss 15.805728
[epoch15, step329]: loss 4.033039
[epoch15, step330]: loss 1.675810
[epoch15, step331]: loss 1.668276
[epoch15, step332]: loss 1.399762
[epoch15, step333]: loss 1.657555
[epoch15, step334]: loss 0.941030
[epoch15, step335]: loss 1.491229
[epoch15, step336]: loss 1.035563
[epoch15, step337]: loss 1.943845
[epoch15, step338]: loss 22.502800
[epoch15, step339]: loss 4.803104
[epoch15, step340]: loss 5.562360
[epoch15, step341]: loss 1.315008
[epoch15, step342]: loss 13.734310
[epoch15, step343]: loss 1.962733
[epoch15, step344]: loss 2.759990
[epoch15, step345]: loss 0.880459
[epoch15, step346]: loss 1.189697
[epoch15, step347]: loss 8.868793
[epoch15, step348]: loss 1.316747
[epoch15, step349]: loss 1.123224
[epoch15, step350]: loss 0.848713
[epoch15, step351]: loss 2.287417
[epoch15, step352]: loss 2.485539
[epoch15, step353]: loss 0.490640
[epoch15, step354]: loss 0.832993
[epoch15, step355]: loss 1.045700
[epoch15, step356]: loss 3.011821
[epoch15, step357]: loss 4.189683
[epoch15, step358]: loss 2.184554
[epoch15, step359]: loss 1.129461
[epoch15, step360]: loss 1.954165
[epoch15, step361]: loss 1.267389
[epoch15, step362]: loss 2.278436
[epoch15, step363]: loss 0.831611
[epoch15, step364]: loss 2.714915
[epoch15, step365]: loss 2.006710
[epoch15, step366]: loss 0.979273
[epoch15, step367]: loss 1.332671
[epoch15, step368]: loss 1.508926
[epoch15, step369]: loss 0.710983
[epoch15, step370]: loss 0.628774
[epoch15, step371]: loss 0.827686
[epoch15, step372]: loss 7.203253
[epoch15, step373]: loss 3.045996
[epoch15, step374]: loss 0.720814
[epoch15, step375]: loss 2.908368
[epoch15, step376]: loss 11.345203
[epoch15, step377]: loss 9.892047
[epoch15, step378]: loss 1.710025
[epoch15, step379]: loss 1.250013
[epoch15, step380]: loss 10.063062
[epoch15, step381]: loss 5.081451
[epoch15, step382]: loss 1.497507
[epoch15, step383]: loss 2.719022
[epoch15, step384]: loss 4.386284
[epoch15, step385]: loss 1.207589
[epoch15, step386]: loss 13.265147
[epoch15, step387]: loss 1.892576
[epoch15, step388]: loss 11.661522
[epoch15, step389]: loss 1.549638
[epoch15, step390]: loss 1.397647
[epoch15, step391]: loss 10.044965
[epoch15, step392]: loss 1.455207
[epoch15, step393]: loss 1.881504
[epoch15, step394]: loss 3.488439
[epoch15, step395]: loss 14.270357
[epoch15, step396]: loss 1.995206
[epoch15, step397]: loss 0.990326
[epoch15, step398]: loss 10.283534
[epoch15, step399]: loss 3.011500
[epoch15, step400]: loss 1.586359
[epoch15, step401]: loss 2.044796
[epoch15, step402]: loss 2.990604
[epoch15, step403]: loss 1.527238
[epoch15, step404]: loss 1.318728
[epoch15, step405]: loss 23.197792
[epoch15, step406]: loss 4.394033
[epoch15, step407]: loss 8.118000
[epoch15, step408]: loss 1.047677
[epoch15, step409]: loss 0.970464
[epoch15, step410]: loss 0.749295
[epoch15, step411]: loss 3.731170
[epoch15, step412]: loss 1.044805
[epoch15, step413]: loss 2.558395
[epoch15, step414]: loss 2.822972
[epoch15, step415]: loss 2.297405
[epoch15, step416]: loss 0.829786
[epoch15, step417]: loss 1.368593
[epoch15, step418]: loss 18.648338
[epoch15, step419]: loss 1.027619
[epoch15, step420]: loss 1.520497
[epoch15, step421]: loss 4.169977
[epoch15, step422]: loss 16.157112
[epoch15, step423]: loss 3.927368
[epoch15, step424]: loss 7.601397
[epoch15, step425]: loss 3.715469
[epoch15, step426]: loss 12.251369
[epoch15, step427]: loss 7.014526
[epoch15, step428]: loss 1.572688
[epoch15, step429]: loss 1.928158
[epoch15, step430]: loss 2.297425
[epoch15, step431]: loss 3.606491
[epoch15, step432]: loss 11.077728
[epoch15, step433]: loss 6.738291
[epoch15, step434]: loss 1.031966
[epoch15, step435]: loss 14.995018
[epoch15, step436]: loss 2.374933
[epoch15, step437]: loss 1.387020
[epoch15, step438]: loss 0.998250
[epoch15, step439]: loss 0.758893
[epoch15, step440]: loss 2.047790
[epoch15, step441]: loss 1.400016
[epoch15, step442]: loss 2.481867
[epoch15, step443]: loss 4.677665
[epoch15, step444]: loss 5.758465
[epoch15, step445]: loss 2.148971
[epoch15, step446]: loss 2.227689
[epoch15, step447]: loss 1.013652
[epoch15, step448]: loss 18.857489
[epoch15, step449]: loss 14.935607
[epoch15, step450]: loss 7.363060
[epoch15, step451]: loss 4.207599
[epoch15, step452]: loss 0.780112
[epoch15, step453]: loss 1.037522
[epoch15, step454]: loss 0.999637
[epoch15, step455]: loss 12.499166
[epoch15, step456]: loss 12.251092
[epoch15, step457]: loss 1.207870
[epoch15, step458]: loss 3.184485
[epoch15, step459]: loss 1.115122
[epoch15, step460]: loss 12.001223
[epoch15, step461]: loss 13.082139
[epoch15, step462]: loss 3.905876
[epoch15, step463]: loss 1.847669
[epoch15, step464]: loss 12.004134
[epoch15, step465]: loss 1.263158
[epoch15, step466]: loss 1.374701
[epoch15, step467]: loss 1.479244
[epoch15, step468]: loss 2.534331
[epoch15, step469]: loss 0.517562
[epoch15, step470]: loss 1.449866
[epoch15, step471]: loss 8.486791
[epoch15, step472]: loss 0.858045
[epoch15, step473]: loss 0.990970
[epoch15, step474]: loss 15.397294
[epoch15, step475]: loss 1.742854
[epoch15, step476]: loss 2.595700
[epoch15, step477]: loss 1.092511
[epoch15, step478]: loss 1.941054
[epoch15, step479]: loss 5.128531
[epoch15, step480]: loss 1.489518
[epoch15, step481]: loss 7.209599
[epoch15, step482]: loss 0.646233
[epoch15, step483]: loss 7.711304
[epoch15, step484]: loss 0.745311
[epoch15, step485]: loss 1.343388
[epoch15, step486]: loss 0.822804
[epoch15, step487]: loss 6.965797
[epoch15, step488]: loss 2.561002
[epoch15, step489]: loss 2.336186
[epoch15, step490]: loss 1.228254
[epoch15, step491]: loss 0.729002
[epoch15, step492]: loss 3.855606
[epoch15, step493]: loss 10.989837
[epoch15, step494]: loss 14.076686
[epoch15, step495]: loss 2.468498
[epoch15, step496]: loss 1.189587
[epoch15, step497]: loss 1.079589
[epoch15, step498]: loss 6.686894
[epoch15, step499]: loss 0.700090
[epoch15, step500]: loss 10.853896
[epoch15, step501]: loss 3.590720
[epoch15, step502]: loss 1.469471
[epoch15, step503]: loss 1.495869
[epoch15, step504]: loss 8.872284
[epoch15, step505]: loss 1.825315
[epoch15, step506]: loss 0.539389
[epoch15, step507]: loss 12.937243
[epoch15, step508]: loss 36.786831
[epoch15, step509]: loss 1.129913
[epoch15, step510]: loss 11.742978
[epoch15, step511]: loss 0.887915
[epoch15, step512]: loss 0.696260
[epoch15, step513]: loss 0.735336
[epoch15, step514]: loss 3.957538
[epoch15, step515]: loss 18.996717
[epoch15, step516]: loss 5.524343
[epoch15, step517]: loss 3.739136
[epoch15, step518]: loss 12.060045
[epoch15, step519]: loss 1.399829
[epoch15, step520]: loss 16.446829
[epoch15, step521]: loss 6.490087
[epoch15, step522]: loss 4.307211
[epoch15, step523]: loss 1.203372
[epoch15, step524]: loss 1.204190
[epoch15, step525]: loss 13.060883
[epoch15, step526]: loss 0.564319
[epoch15, step527]: loss 17.713074
[epoch15, step528]: loss 15.620747
[epoch15, step529]: loss 15.649790
[epoch15, step530]: loss 3.000942
[epoch15, step531]: loss 1.930763
[epoch15, step532]: loss 0.805358
[epoch15, step533]: loss 7.990491
[epoch15, step534]: loss 3.719649
[epoch15, step535]: loss 2.575515
[epoch15, step536]: loss 1.290374
[epoch15, step537]: loss 1.367150
[epoch15, step538]: loss 2.146142
[epoch15, step539]: loss 13.097451
[epoch15, step540]: loss 7.231308
[epoch15, step541]: loss 3.770016
[epoch15, step542]: loss 0.933491
[epoch15, step543]: loss 0.516836
[epoch15, step544]: loss 6.462263
[epoch15, step545]: loss 3.846154
[epoch15, step546]: loss 12.167811
[epoch15, step547]: loss 0.706985
[epoch15, step548]: loss 0.871113
[epoch15, step549]: loss 2.964284
[epoch15, step550]: loss 1.504476
[epoch15, step551]: loss 7.492783
[epoch15, step552]: loss 2.776186
[epoch15, step553]: loss 2.316723
[epoch15, step554]: loss 7.681589
[epoch15, step555]: loss 2.483539
[epoch15, step556]: loss 1.803325
[epoch15, step557]: loss 2.179154
[epoch15, step558]: loss 1.818951
[epoch15, step559]: loss 0.532803
[epoch15, step560]: loss 0.758918
[epoch15, step561]: loss 1.445810
[epoch15, step562]: loss 3.453947
[epoch15, step563]: loss 21.274601
[epoch15, step564]: loss 0.515648
[epoch15, step565]: loss 2.321613
[epoch15, step566]: loss 1.868970
[epoch15, step567]: loss 1.233966
[epoch15, step568]: loss 0.961529
[epoch15, step569]: loss 4.027454
[epoch15, step570]: loss 12.449378
[epoch15, step571]: loss 1.114442
[epoch15, step572]: loss 1.179429
[epoch15, step573]: loss 8.941164
[epoch15, step574]: loss 4.108452
[epoch15, step575]: loss 2.733294
[epoch15, step576]: loss 2.192145
[epoch15, step577]: loss 1.061112
[epoch15, step578]: loss 0.782970
[epoch15, step579]: loss 0.980719
[epoch15, step580]: loss 0.935757
[epoch15, step581]: loss 1.711066
[epoch15, step582]: loss 1.638251
[epoch15, step583]: loss 11.154134
[epoch15, step584]: loss 0.521153
[epoch15, step585]: loss 17.854326
[epoch15, step586]: loss 14.433487
[epoch15, step587]: loss 1.136156
[epoch15, step588]: loss 10.402666
[epoch15, step589]: loss 0.784197
[epoch15, step590]: loss 2.023501
[epoch15, step591]: loss 1.525616
[epoch15, step592]: loss 1.802779
[epoch15, step593]: loss 12.149479
[epoch15, step594]: loss 0.753820
[epoch15, step595]: loss 3.160461
[epoch15, step596]: loss 0.979678
[epoch15, step597]: loss 5.551876
[epoch15, step598]: loss 3.213799
[epoch15, step599]: loss 2.941915
[epoch15, step600]: loss 1.113480
[epoch15, step601]: loss 3.299891
[epoch15, step602]: loss 0.622352
[epoch15, step603]: loss 2.010418
[epoch15, step604]: loss 1.066712
[epoch15, step605]: loss 1.339578
[epoch15, step606]: loss 1.250918
[epoch15, step607]: loss 1.851061
[epoch15, step608]: loss 7.389284
[epoch15, step609]: loss 16.273787
[epoch15, step610]: loss 3.423422
[epoch15, step611]: loss 2.098824
[epoch15, step612]: loss 2.483972
[epoch15, step613]: loss 2.097914
[epoch15, step614]: loss 1.609051
[epoch15, step615]: loss 0.864644
[epoch15, step616]: loss 1.699056
[epoch15, step617]: loss 6.260916
[epoch15, step618]: loss 1.715179
[epoch15, step619]: loss 2.129264
[epoch15, step620]: loss 1.475672
[epoch15, step621]: loss 13.486594
[epoch15, step622]: loss 3.251158
[epoch15, step623]: loss 2.150385
[epoch15, step624]: loss 1.122588
[epoch15, step625]: loss 0.877560
[epoch15, step626]: loss 2.036977
[epoch15, step627]: loss 4.866461
[epoch15, step628]: loss 0.722276
[epoch15, step629]: loss 2.297801
[epoch15, step630]: loss 0.907393
[epoch15, step631]: loss 0.969109
[epoch15, step632]: loss 1.120780
[epoch15, step633]: loss 10.883965
[epoch15, step634]: loss 13.440402
[epoch15, step635]: loss 4.113568
[epoch15, step636]: loss 0.967650
[epoch15, step637]: loss 0.652172
[epoch15, step638]: loss 1.103518
[epoch15, step639]: loss 2.909873
[epoch15, step640]: loss 0.722871
[epoch15, step641]: loss 8.543850
[epoch15, step642]: loss 0.883602
[epoch15, step643]: loss 0.562088
[epoch15, step644]: loss 2.166442
[epoch15, step645]: loss 1.131679
[epoch15, step646]: loss 6.140030
[epoch15, step647]: loss 0.820977
[epoch15, step648]: loss 8.464772
[epoch15, step649]: loss 1.925767
[epoch15, step650]: loss 1.899924
[epoch15, step651]: loss 3.432284
[epoch15, step652]: loss 1.846169
[epoch15, step653]: loss 2.382617
[epoch15, step654]: loss 0.825707
[epoch15, step655]: loss 1.565324
[epoch15, step656]: loss 11.077313
[epoch15, step657]: loss 2.555074
[epoch15, step658]: loss 1.095258
[epoch15, step659]: loss 3.789155
[epoch15, step660]: loss 0.588188
[epoch15, step661]: loss 2.369604
[epoch15, step662]: loss 14.342628
[epoch15, step663]: loss 1.351341
[epoch15, step664]: loss 1.612939
[epoch15, step665]: loss 0.913363
[epoch15, step666]: loss 1.606664
[epoch15, step667]: loss 0.908922
[epoch15, step668]: loss 1.056871
[epoch15, step669]: loss 1.507513
[epoch15, step670]: loss 8.720445
[epoch15, step671]: loss 2.428522
[epoch15, step672]: loss 2.954506
[epoch15, step673]: loss 1.320471
[epoch15, step674]: loss 3.385993
[epoch15, step675]: loss 0.886172
[epoch15, step676]: loss 1.191380
[epoch15, step677]: loss 1.105822
[epoch15, step678]: loss 1.093706
[epoch15, step679]: loss 0.830086
[epoch15, step680]: loss 4.251107
[epoch15, step681]: loss 1.869599
[epoch15, step682]: loss 1.104257
[epoch15, step683]: loss 0.683092
[epoch15, step684]: loss 14.210011
[epoch15, step685]: loss 0.715440
[epoch15, step686]: loss 0.741556
[epoch15, step687]: loss 1.007330
[epoch15, step688]: loss 1.986952
[epoch15, step689]: loss 2.995304
[epoch15, step690]: loss 1.216411
[epoch15, step691]: loss 1.094311
[epoch15, step692]: loss 0.521873
[epoch15, step693]: loss 0.649230
[epoch15, step694]: loss 1.048734
[epoch15, step695]: loss 0.773035
[epoch15, step696]: loss 0.675481
[epoch15, step697]: loss 4.695623
[epoch15, step698]: loss 0.778967
[epoch15, step699]: loss 1.891749
[epoch15, step700]: loss 2.878993
[epoch15, step701]: loss 1.723078
[epoch15, step702]: loss 1.111694
[epoch15, step703]: loss 8.252522
[epoch15, step704]: loss 2.500471
[epoch15, step705]: loss 2.985239
[epoch15, step706]: loss 2.167976
[epoch15, step707]: loss 1.114774
[epoch15, step708]: loss 1.156544
[epoch15, step709]: loss 1.022732
[epoch15, step710]: loss 0.892407
[epoch15, step711]: loss 4.902546
[epoch15, step712]: loss 8.142111
[epoch15, step713]: loss 1.647868
[epoch15, step714]: loss 1.973573
[epoch15, step715]: loss 6.623185
[epoch15, step716]: loss 1.565968
[epoch15, step717]: loss 0.502757
[epoch15, step718]: loss 0.562143
[epoch15, step719]: loss 4.432038
[epoch15, step720]: loss 17.713083
[epoch15, step721]: loss 0.658411
[epoch15, step722]: loss 1.309939
[epoch15, step723]: loss 2.851685
[epoch15, step724]: loss 1.587329
[epoch15, step725]: loss 12.754668
[epoch15, step726]: loss 1.104320
[epoch15, step727]: loss 2.191282
[epoch15, step728]: loss 0.830926
[epoch15, step729]: loss 2.894161
[epoch15, step730]: loss 0.938495
[epoch15, step731]: loss 12.410860
[epoch15, step732]: loss 14.951900
[epoch15, step733]: loss 1.257951
[epoch15, step734]: loss 11.419103
[epoch15, step735]: loss 0.919065
[epoch15, step736]: loss 3.764044
[epoch15, step737]: loss 1.368267
[epoch15, step738]: loss 4.596991
[epoch15, step739]: loss 33.408852
[epoch15, step740]: loss 1.255548
[epoch15, step741]: loss 1.435580
[epoch15, step742]: loss 2.705496
[epoch15, step743]: loss 14.412437
[epoch15, step744]: loss 4.869084
[epoch15, step745]: loss 1.602733
[epoch15, step746]: loss 1.754735
[epoch15, step747]: loss 0.596348
[epoch15, step748]: loss 11.282512
[epoch15, step749]: loss 13.601213
[epoch15, step750]: loss 0.772024
[epoch15, step751]: loss 2.107483
[epoch15, step752]: loss 11.950171
[epoch15, step753]: loss 2.160637
[epoch15, step754]: loss 1.040427
[epoch15, step755]: loss 2.985774
[epoch15, step756]: loss 6.064722
[epoch15, step757]: loss 3.621178
[epoch15, step758]: loss 9.469264
[epoch15, step759]: loss 1.480937
[epoch15, step760]: loss 17.546789
[epoch15, step761]: loss 1.346881
[epoch15, step762]: loss 0.538165
[epoch15, step763]: loss 4.170613
[epoch15, step764]: loss 7.702136
[epoch15, step765]: loss 22.044853
[epoch15, step766]: loss 0.618551
[epoch15, step767]: loss 1.306739
[epoch15, step768]: loss 5.979307
[epoch15, step769]: loss 3.454975
[epoch15, step770]: loss 8.867902
[epoch15, step771]: loss 1.802448
[epoch15, step772]: loss 6.282518
[epoch15, step773]: loss 1.454448
[epoch15, step774]: loss 11.709316
[epoch15, step775]: loss 1.012105
[epoch15, step776]: loss 0.998254
[epoch15, step777]: loss 2.394913
[epoch15, step778]: loss 1.464498
[epoch15, step779]: loss 2.537585
[epoch15, step780]: loss 3.309090
[epoch15, step781]: loss 5.922970
[epoch15, step782]: loss 13.806399
[epoch15, step783]: loss 10.251734
[epoch15, step784]: loss 3.155465
[epoch15, step785]: loss 12.526773
[epoch15, step786]: loss 10.329961
[epoch15, step787]: loss 20.469358
[epoch15, step788]: loss 0.933604
[epoch15, step789]: loss 0.928115
[epoch15, step790]: loss 1.670823
[epoch15, step791]: loss 1.550257
[epoch15, step792]: loss 2.654564
[epoch15, step793]: loss 0.977089
[epoch15, step794]: loss 1.925686
[epoch15, step795]: loss 1.288492
[epoch15, step796]: loss 3.388206
[epoch15, step797]: loss 6.380741
[epoch15, step798]: loss 2.608822
[epoch15, step799]: loss 2.419417
[epoch15, step800]: loss 2.183670
[epoch15, step801]: loss 1.742381
[epoch15, step802]: loss 1.368854
[epoch15, step803]: loss 7.314195
[epoch15, step804]: loss 1.698986
[epoch15, step805]: loss 1.123477
[epoch15, step806]: loss 12.425737
[epoch15, step807]: loss 0.812631
[epoch15, step808]: loss 10.440438
[epoch15, step809]: loss 1.493392
[epoch15, step810]: loss 1.101588
[epoch15, step811]: loss 9.059347
[epoch15, step812]: loss 1.446275
[epoch15, step813]: loss 4.691138
[epoch15, step814]: loss 1.977804
[epoch15, step815]: loss 13.918690
[epoch15, step816]: loss 0.699933
[epoch15, step817]: loss 0.720439
[epoch15, step818]: loss 9.941431
[epoch15, step819]: loss 9.103071
[epoch15, step820]: loss 0.798834
[epoch15, step821]: loss 2.459317
[epoch15, step822]: loss 11.986724
[epoch15, step823]: loss 0.719438
[epoch15, step824]: loss 1.849901
[epoch15, step825]: loss 1.024340
[epoch15, step826]: loss 8.601171
[epoch15, step827]: loss 1.212867
[epoch15, step828]: loss 1.067919
[epoch15, step829]: loss 1.737725
[epoch15, step830]: loss 2.320148
[epoch15, step831]: loss 5.821548
[epoch15, step832]: loss 1.849737
[epoch15, step833]: loss 12.426974
[epoch15, step834]: loss 1.006815
[epoch15, step835]: loss 1.221367
[epoch15, step836]: loss 4.729506
[epoch15, step837]: loss 6.813360
[epoch15, step838]: loss 0.751031
[epoch15, step839]: loss 1.114408
[epoch15, step840]: loss 6.552032
[epoch15, step841]: loss 1.350365
[epoch15, step842]: loss 0.961724
[epoch15, step843]: loss 1.671713
[epoch15, step844]: loss 1.355971
[epoch15, step845]: loss 1.806900
[epoch15, step846]: loss 10.858177
[epoch15, step847]: loss 2.046411
[epoch15, step848]: loss 5.216854
[epoch15, step849]: loss 2.384958
[epoch15, step850]: loss 15.548035
[epoch15, step851]: loss 14.332189
[epoch15, step852]: loss 4.899575
[epoch15, step853]: loss 2.043292
[epoch15, step854]: loss 11.417850
[epoch15, step855]: loss 1.242774
[epoch15, step856]: loss 1.002570
[epoch15, step857]: loss 6.442214
[epoch15, step858]: loss 4.855920
[epoch15, step859]: loss 5.963419
[epoch15, step860]: loss 1.157796
[epoch15, step861]: loss 0.833606
[epoch15, step862]: loss 9.045104
[epoch15, step863]: loss 1.596332
[epoch15, step864]: loss 13.882831
[epoch15, step865]: loss 0.723581
[epoch15, step866]: loss 1.293684
[epoch15, step867]: loss 9.049184
[epoch15, step868]: loss 5.943925
[epoch15, step869]: loss 1.125986
[epoch15, step870]: loss 10.323574
[epoch15, step871]: loss 11.163676
[epoch15, step872]: loss 4.156884
[epoch15, step873]: loss 1.020537
[epoch15, step874]: loss 1.814514
[epoch15, step875]: loss 1.184363
[epoch15, step876]: loss 2.003479
[epoch15, step877]: loss 0.856371
[epoch15, step878]: loss 9.488466
[epoch15, step879]: loss 4.139006
[epoch15, step880]: loss 9.393733
[epoch15, step881]: loss 0.867248
[epoch15, step882]: loss 0.773421
[epoch15, step883]: loss 1.210826
[epoch15, step884]: loss 0.709093
[epoch15, step885]: loss 1.360415
[epoch15, step886]: loss 1.590064
[epoch15, step887]: loss 1.856506
[epoch15, step888]: loss 1.124740
[epoch15, step889]: loss 5.302510
[epoch15, step890]: loss 2.568369
[epoch15, step891]: loss 7.697469
[epoch15, step892]: loss 0.976232
[epoch15, step893]: loss 2.182344
[epoch15, step894]: loss 0.771339
[epoch15, step895]: loss 1.974513
[epoch15, step896]: loss 1.390383
[epoch15, step897]: loss 2.239223
[epoch15, step898]: loss 1.147275
[epoch15, step899]: loss 2.713982
[epoch15, step900]: loss 2.466329
[epoch15, step901]: loss 2.727867
[epoch15, step902]: loss 4.009985
[epoch15, step903]: loss 3.168434
[epoch15, step904]: loss 0.751441
[epoch15, step905]: loss 2.643786
[epoch15, step906]: loss 1.616339
[epoch15, step907]: loss 1.354194
[epoch15, step908]: loss 1.055856
[epoch15, step909]: loss 9.457587
[epoch15, step910]: loss 4.924176
[epoch15, step911]: loss 0.612158
[epoch15, step912]: loss 1.311684
[epoch15, step913]: loss 3.570637
[epoch15, step914]: loss 6.803866
[epoch15, step915]: loss 4.369065
[epoch15, step916]: loss 2.691311
[epoch15, step917]: loss 4.548506
[epoch15, step918]: loss 0.734625
[epoch15, step919]: loss 14.788726
[epoch15, step920]: loss 1.453717
[epoch15, step921]: loss 3.194499
[epoch15, step922]: loss 9.051017
[epoch15, step923]: loss 15.471525
[epoch15, step924]: loss 9.834100
[epoch15, step925]: loss 13.428466
[epoch15, step926]: loss 10.620363
[epoch15, step927]: loss 1.222188
[epoch15, step928]: loss 1.851655
[epoch15, step929]: loss 2.864971
[epoch15, step930]: loss 2.089117
[epoch15, step931]: loss 5.171275
[epoch15, step932]: loss 5.162845
[epoch15, step933]: loss 8.768377
[epoch15, step934]: loss 1.255625
[epoch15, step935]: loss 13.266130
[epoch15, step936]: loss 1.695508
[epoch15, step937]: loss 15.647696
[epoch15, step938]: loss 5.757958
[epoch15, step939]: loss 2.350288
[epoch15, step940]: loss 0.852869
[epoch15, step941]: loss 1.293289
[epoch15, step942]: loss 1.420784
[epoch15, step943]: loss 0.524537
[epoch15, step944]: loss 1.182267
[epoch15, step945]: loss 9.643641
[epoch15, step946]: loss 1.960994
[epoch15, step947]: loss 2.027051
[epoch15, step948]: loss 2.051455
[epoch15, step949]: loss 10.935025
[epoch15, step950]: loss 1.571060
[epoch15, step951]: loss 7.820620
[epoch15, step952]: loss 4.062960
[epoch15, step953]: loss 0.875309
[epoch15, step954]: loss 3.559878
[epoch15, step955]: loss 3.912935
[epoch15, step956]: loss 4.677631
[epoch15, step957]: loss 17.526598
[epoch15, step958]: loss 1.894056
[epoch15, step959]: loss 19.994129
[epoch15, step960]: loss 0.749911
[epoch15, step961]: loss 1.042455
[epoch15, step962]: loss 1.262734
[epoch15, step963]: loss 8.813245
[epoch15, step964]: loss 1.208517
[epoch15, step965]: loss 0.652962
[epoch15, step966]: loss 0.546865
[epoch15, step967]: loss 0.807095
[epoch15, step968]: loss 8.493911
[epoch15, step969]: loss 4.612404
[epoch15, step970]: loss 2.502314
[epoch15, step971]: loss 13.451628
[epoch15, step972]: loss 2.992401
[epoch15, step973]: loss 3.359835
[epoch15, step974]: loss 4.962099
[epoch15, step975]: loss 1.215402
[epoch15, step976]: loss 3.337426
[epoch15, step977]: loss 2.925284
[epoch15, step978]: loss 2.019346
[epoch15, step979]: loss 0.776463
[epoch15, step980]: loss 1.403577
[epoch15, step981]: loss 12.490240
[epoch15, step982]: loss 1.057670
[epoch15, step983]: loss 2.599165
[epoch15, step984]: loss 1.241112
[epoch15, step985]: loss 7.822018
[epoch15, step986]: loss 2.383272
[epoch15, step987]: loss 3.511966
[epoch15, step988]: loss 0.750920
[epoch15, step989]: loss 1.814299
[epoch15, step990]: loss 1.489789
[epoch15, step991]: loss 1.553956
[epoch15, step992]: loss 1.337427
[epoch15, step993]: loss 0.960016
[epoch15, step994]: loss 10.302879
[epoch15, step995]: loss 0.723734
[epoch15, step996]: loss 2.243557
[epoch15, step997]: loss 1.741119
[epoch15, step998]: loss 17.279367
[epoch15, step999]: loss 2.027670
[epoch15, step1000]: loss 8.279008
[epoch15, step1001]: loss 0.540522
[epoch15, step1002]: loss 2.469141
[epoch15, step1003]: loss 0.987608
[epoch15, step1004]: loss 3.704272
[epoch15, step1005]: loss 1.435756
[epoch15, step1006]: loss 6.235807
[epoch15, step1007]: loss 1.834970
[epoch15, step1008]: loss 0.940390
[epoch15, step1009]: loss 0.992780
[epoch15, step1010]: loss 7.938745
[epoch15, step1011]: loss 2.495771
[epoch15, step1012]: loss 4.668982
[epoch15, step1013]: loss 1.377009
[epoch15, step1014]: loss 2.456098
[epoch15, step1015]: loss 7.866420
[epoch15, step1016]: loss 2.260597
[epoch15, step1017]: loss 0.866137
[epoch15, step1018]: loss 14.406670
[epoch15, step1019]: loss 1.029296
[epoch15, step1020]: loss 0.989851
[epoch15, step1021]: loss 1.980743
[epoch15, step1022]: loss 7.714053
[epoch15, step1023]: loss 2.755111
[epoch15, step1024]: loss 1.375253
[epoch15, step1025]: loss 3.519611
[epoch15, step1026]: loss 1.930625
[epoch15, step1027]: loss 1.335422
[epoch15, step1028]: loss 3.495252
[epoch15, step1029]: loss 2.194177
[epoch15, step1030]: loss 3.755834
[epoch15, step1031]: loss 2.699840
[epoch15, step1032]: loss 3.936824
[epoch15, step1033]: loss 0.909634
[epoch15, step1034]: loss 14.130985
[epoch15, step1035]: loss 14.221166
[epoch15, step1036]: loss 0.768447
[epoch15, step1037]: loss 1.151029
[epoch15, step1038]: loss 0.930752
[epoch15, step1039]: loss 1.065283
[epoch15, step1040]: loss 13.065261
[epoch15, step1041]: loss 0.960741
[epoch15, step1042]: loss 1.179674
[epoch15, step1043]: loss 11.856625
[epoch15, step1044]: loss 9.483756
[epoch15, step1045]: loss 10.679811
[epoch15, step1046]: loss 0.848804
[epoch15, step1047]: loss 2.449313
[epoch15, step1048]: loss 4.498090
[epoch15, step1049]: loss 2.195774
[epoch15, step1050]: loss 28.834467
[epoch15, step1051]: loss 15.109921
[epoch15, step1052]: loss 4.582690
[epoch15, step1053]: loss 2.347050
[epoch15, step1054]: loss 4.749265
[epoch15, step1055]: loss 3.412535
[epoch15, step1056]: loss 1.789293
[epoch15, step1057]: loss 0.685447
[epoch15, step1058]: loss 0.870081
[epoch15, step1059]: loss 0.510722
[epoch15, step1060]: loss 1.006556
[epoch15, step1061]: loss 11.138537
[epoch15, step1062]: loss 1.228545
[epoch15, step1063]: loss 4.660470
[epoch15, step1064]: loss 4.225923
[epoch15, step1065]: loss 0.780473
[epoch15, step1066]: loss 1.704559
[epoch15, step1067]: loss 4.866449
[epoch15, step1068]: loss 1.328184
[epoch15, step1069]: loss 3.875649
[epoch15, step1070]: loss 1.875430
[epoch15, step1071]: loss 4.284838
[epoch15, step1072]: loss 2.943751
[epoch15, step1073]: loss 1.417491
[epoch15, step1074]: loss 1.850679
[epoch15, step1075]: loss 3.121988
[epoch15, step1076]: loss 0.972047
[epoch15, step1077]: loss 3.363731
[epoch15, step1078]: loss 7.546825
[epoch15, step1079]: loss 11.926408
[epoch15, step1080]: loss 8.585043
[epoch15, step1081]: loss 2.895233
[epoch15, step1082]: loss 0.686625
[epoch15, step1083]: loss 4.109350
[epoch15, step1084]: loss 2.053051
[epoch15, step1085]: loss 0.741962
[epoch15, step1086]: loss 1.294698
[epoch15, step1087]: loss 16.317455
[epoch15, step1088]: loss 12.300102
[epoch15, step1089]: loss 0.591992
[epoch15, step1090]: loss 1.418867
[epoch15, step1091]: loss 1.011290
[epoch15, step1092]: loss 1.379158
[epoch15, step1093]: loss 0.883650
[epoch15, step1094]: loss 1.222659
[epoch15, step1095]: loss 0.827929
[epoch15, step1096]: loss 0.774616
[epoch15, step1097]: loss 1.015824
[epoch15, step1098]: loss 3.008023
[epoch15, step1099]: loss 1.073704
[epoch15, step1100]: loss 1.613756
[epoch15, step1101]: loss 2.818615
[epoch15, step1102]: loss 3.140675
[epoch15, step1103]: loss 1.486938
[epoch15, step1104]: loss 14.602908
[epoch15, step1105]: loss 2.525166
[epoch15, step1106]: loss 6.780120
[epoch15, step1107]: loss 0.921633
[epoch15, step1108]: loss 0.949837
[epoch15, step1109]: loss 0.642447
[epoch15, step1110]: loss 1.478737
[epoch15, step1111]: loss 1.951647
[epoch15, step1112]: loss 0.928650
[epoch15, step1113]: loss 1.496891
[epoch15, step1114]: loss 0.447717
[epoch15, step1115]: loss 17.999424
[epoch15, step1116]: loss 1.050479
[epoch15, step1117]: loss 0.637479
[epoch15, step1118]: loss 0.901205
[epoch15, step1119]: loss 3.175971
[epoch15, step1120]: loss 5.984204
[epoch15, step1121]: loss 7.449136
[epoch15, step1122]: loss 0.922052
[epoch15, step1123]: loss 3.192306
[epoch15, step1124]: loss 0.678331
[epoch15, step1125]: loss 6.679345
[epoch15, step1126]: loss 10.780546
[epoch15, step1127]: loss 7.644766
[epoch15, step1128]: loss 8.617061
[epoch15, step1129]: loss 7.113021
[epoch15, step1130]: loss 3.947742
[epoch15, step1131]: loss 1.497938
[epoch15, step1132]: loss 12.772250
[epoch15, step1133]: loss 2.287612
[epoch15, step1134]: loss 12.583920
[epoch15, step1135]: loss 2.280871
[epoch15, step1136]: loss 2.657902
[epoch15, step1137]: loss 0.806601
[epoch15, step1138]: loss 0.760555
[epoch15, step1139]: loss 1.899697
[epoch15, step1140]: loss 1.661021
[epoch15, step1141]: loss 1.525771
[epoch15, step1142]: loss 6.353751
[epoch15, step1143]: loss 0.970549
[epoch15, step1144]: loss 11.089709
[epoch15, step1145]: loss 1.018625
[epoch15, step1146]: loss 1.284223
[epoch15, step1147]: loss 1.019072
[epoch15, step1148]: loss 13.320954
[epoch15, step1149]: loss 10.129349
[epoch15, step1150]: loss 1.401362
[epoch15, step1151]: loss 0.635712
[epoch15, step1152]: loss 3.895039
[epoch15, step1153]: loss 1.409811
[epoch15, step1154]: loss 0.905499
[epoch15, step1155]: loss 7.359855
[epoch15, step1156]: loss 1.166070
[epoch15, step1157]: loss 1.355227
[epoch15, step1158]: loss 1.996746
[epoch15, step1159]: loss 0.831367
[epoch15, step1160]: loss 1.046861
[epoch15, step1161]: loss 4.675767
[epoch15, step1162]: loss 1.096628
[epoch15, step1163]: loss 1.693825
[epoch15, step1164]: loss 0.782409
[epoch15, step1165]: loss 0.736918
[epoch15, step1166]: loss 1.227931
[epoch15, step1167]: loss 3.356244
[epoch15, step1168]: loss 7.953447
[epoch15, step1169]: loss 2.218724
[epoch15, step1170]: loss 2.369964
[epoch15, step1171]: loss 2.394565
[epoch15, step1172]: loss 11.951781
[epoch15, step1173]: loss 1.138712
[epoch15, step1174]: loss 21.948410
[epoch15, step1175]: loss 2.814602
[epoch15, step1176]: loss 5.053547
[epoch15, step1177]: loss 13.799724
[epoch15, step1178]: loss 2.368684
[epoch15, step1179]: loss 1.688356
[epoch15, step1180]: loss 2.173882
[epoch15, step1181]: loss 8.227193
[epoch15, step1182]: loss 2.338697
[epoch15, step1183]: loss 0.661547
[epoch15, step1184]: loss 0.572112
[epoch15, step1185]: loss 17.873550
[epoch15, step1186]: loss 1.520519
[epoch15, step1187]: loss 8.202604
[epoch15, step1188]: loss 0.900936
[epoch15, step1189]: loss 3.015345
[epoch15, step1190]: loss 0.652054
[epoch15, step1191]: loss 0.799901
[epoch15, step1192]: loss 0.894860
[epoch15, step1193]: loss 1.054848
[epoch15, step1194]: loss 1.738888
[epoch15, step1195]: loss 12.921593
[epoch15, step1196]: loss 8.572940
[epoch15, step1197]: loss 0.966568
[epoch15, step1198]: loss 1.430395
[epoch15, step1199]: loss 7.061394
[epoch15, step1200]: loss 3.639190
[epoch15, step1201]: loss 0.916959
[epoch15, step1202]: loss 12.086380
[epoch15, step1203]: loss 1.525419
[epoch15, step1204]: loss 0.896896
[epoch15, step1205]: loss 1.098583
[epoch15, step1206]: loss 4.427584
[epoch15, step1207]: loss 0.919417
[epoch15, step1208]: loss 2.835327
[epoch15, step1209]: loss 0.999792
[epoch15, step1210]: loss 3.050766
[epoch15, step1211]: loss 1.179877
[epoch15, step1212]: loss 1.124450
[epoch15, step1213]: loss 2.013405
[epoch15, step1214]: loss 1.528643
[epoch15, step1215]: loss 0.800646
[epoch15, step1216]: loss 16.000368
[epoch15, step1217]: loss 3.678404
[epoch15, step1218]: loss 0.706041
[epoch15, step1219]: loss 2.572214
[epoch15, step1220]: loss 0.829196
[epoch15, step1221]: loss 1.583001
[epoch15, step1222]: loss 7.044101
[epoch15, step1223]: loss 3.575758
[epoch15, step1224]: loss 1.679152
[epoch15, step1225]: loss 2.464394
[epoch15, step1226]: loss 0.832328
[epoch15, step1227]: loss 2.376447
[epoch15, step1228]: loss 3.883058
[epoch15, step1229]: loss 13.604546
[epoch15, step1230]: loss 1.189362
[epoch15, step1231]: loss 1.303092
[epoch15, step1232]: loss 2.701293
[epoch15, step1233]: loss 11.602183
[epoch15, step1234]: loss 0.730751
[epoch15, step1235]: loss 0.739783
[epoch15, step1236]: loss 10.227763
[epoch15, step1237]: loss 16.756187
[epoch15, step1238]: loss 2.102868
[epoch15, step1239]: loss 0.792247
[epoch15, step1240]: loss 12.080325
[epoch15, step1241]: loss 2.033247
[epoch15, step1242]: loss 4.763587
[epoch15, step1243]: loss 3.100271
[epoch15, step1244]: loss 0.885849
[epoch15, step1245]: loss 6.227584
[epoch15, step1246]: loss 1.090944
[epoch15, step1247]: loss 2.246536
[epoch15, step1248]: loss 6.281004
[epoch15, step1249]: loss 25.225760
[epoch15, step1250]: loss 29.674761
[epoch15, step1251]: loss 12.795912
[epoch15, step1252]: loss 1.002660
[epoch15, step1253]: loss 3.352128
[epoch15, step1254]: loss 1.042972
[epoch15, step1255]: loss 1.330167
[epoch15, step1256]: loss 14.255048
[epoch15, step1257]: loss 2.720642
[epoch15, step1258]: loss 2.513259
[epoch15, step1259]: loss 1.765599
[epoch15, step1260]: loss 2.006989
[epoch15, step1261]: loss 1.353503
[epoch15, step1262]: loss 1.017814
[epoch15, step1263]: loss 0.980765
[epoch15, step1264]: loss 4.459836
[epoch15, step1265]: loss 16.559437
[epoch15, step1266]: loss 2.547755
[epoch15, step1267]: loss 1.311361
[epoch15, step1268]: loss 1.146927
[epoch15, step1269]: loss 3.483495
[epoch15, step1270]: loss 0.734548
[epoch15, step1271]: loss 25.742226
[epoch15, step1272]: loss 7.443753
[epoch15, step1273]: loss 3.527319
[epoch15, step1274]: loss 0.872916
[epoch15, step1275]: loss 1.083683
[epoch15, step1276]: loss 3.455731
[epoch15, step1277]: loss 1.471746
[epoch15, step1278]: loss 0.499677
[epoch15, step1279]: loss 1.077962
[epoch15, step1280]: loss 1.209004
[epoch15, step1281]: loss 1.174858
[epoch15, step1282]: loss 13.587114
[epoch15, step1283]: loss 0.674682
[epoch15, step1284]: loss 1.128296
[epoch15, step1285]: loss 7.641659
[epoch15, step1286]: loss 1.186316
[epoch15, step1287]: loss 1.701695
[epoch15, step1288]: loss 6.795254
[epoch15, step1289]: loss 0.953958
[epoch15, step1290]: loss 0.635586
[epoch15, step1291]: loss 1.252110
[epoch15, step1292]: loss 6.630310
[epoch15, step1293]: loss 1.351664
[epoch15, step1294]: loss 1.388253
[epoch15, step1295]: loss 2.410804
[epoch15, step1296]: loss 1.328786
[epoch15, step1297]: loss 7.233793
[epoch15, step1298]: loss 12.978443
[epoch15, step1299]: loss 1.755523
[epoch15, step1300]: loss 3.088208
[epoch15, step1301]: loss 1.521090
[epoch15, step1302]: loss 0.691374
[epoch15, step1303]: loss 2.699115
[epoch15, step1304]: loss 3.849577
[epoch15, step1305]: loss 0.979760
[epoch15, step1306]: loss 1.141073
[epoch15, step1307]: loss 8.752502
[epoch15, step1308]: loss 2.709153
[epoch15, step1309]: loss 7.417285
[epoch15, step1310]: loss 1.411035
[epoch15, step1311]: loss 1.029832
[epoch15, step1312]: loss 5.988595
[epoch15, step1313]: loss 15.365448
[epoch15, step1314]: loss 2.169860
[epoch15, step1315]: loss 1.740299
[epoch15, step1316]: loss 1.463065
[epoch15, step1317]: loss 8.170395
[epoch15, step1318]: loss 18.536697
[epoch15, step1319]: loss 1.879576
[epoch15, step1320]: loss 18.058437
[epoch15, step1321]: loss 5.802117
[epoch15, step1322]: loss 3.757452
[epoch15, step1323]: loss 0.832663
[epoch15, step1324]: loss 1.740532
[epoch15, step1325]: loss 10.741577
[epoch15, step1326]: loss 0.719276
[epoch15, step1327]: loss 1.581544
[epoch15, step1328]: loss 8.623897
[epoch15, step1329]: loss 1.400131
[epoch15, step1330]: loss 14.379524
[epoch15, step1331]: loss 12.141793
[epoch15, step1332]: loss 1.356171
[epoch15, step1333]: loss 0.871816
[epoch15, step1334]: loss 0.948899
[epoch15, step1335]: loss 2.402081
[epoch15, step1336]: loss 2.879727
[epoch15, step1337]: loss 5.414322
[epoch15, step1338]: loss 0.830806
[epoch15, step1339]: loss 11.777009
[epoch15, step1340]: loss 1.487073
[epoch15, step1341]: loss 0.896246
[epoch15, step1342]: loss 2.003482
[epoch15, step1343]: loss 8.497277
[epoch15, step1344]: loss 0.797216
[epoch15, step1345]: loss 0.958683
[epoch15, step1346]: loss 5.214034
[epoch15, step1347]: loss 0.485342
[epoch15, step1348]: loss 6.287148
[epoch15, step1349]: loss 1.057239
[epoch15, step1350]: loss 3.098380
[epoch15, step1351]: loss 2.714756
[epoch15, step1352]: loss 1.953824
[epoch15, step1353]: loss 0.819091
[epoch15, step1354]: loss 1.301332
[epoch15, step1355]: loss 9.587127
[epoch15, step1356]: loss 7.360264
[epoch15, step1357]: loss 13.804404
[epoch15, step1358]: loss 0.936519
[epoch15, step1359]: loss 1.479391
[epoch15, step1360]: loss 6.356031
[epoch15, step1361]: loss 2.733714
[epoch15, step1362]: loss 0.531999
[epoch15, step1363]: loss 11.789198
[epoch15, step1364]: loss 3.344844
[epoch15, step1365]: loss 4.253092
[epoch15, step1366]: loss 3.951340
[epoch15, step1367]: loss 2.933686
[epoch15, step1368]: loss 1.596882
[epoch15, step1369]: loss 1.262700
[epoch15, step1370]: loss 0.741688
[epoch15, step1371]: loss 3.666441
[epoch15, step1372]: loss 1.039817
[epoch15, step1373]: loss 12.121920
[epoch15, step1374]: loss 24.820900
[epoch15, step1375]: loss 0.951613
[epoch15, step1376]: loss 0.926304
[epoch15, step1377]: loss 8.045221
[epoch15, step1378]: loss 4.061316
[epoch15, step1379]: loss 0.673630
[epoch15, step1380]: loss 1.648074
[epoch15, step1381]: loss 0.805990
[epoch15, step1382]: loss 10.520285
[epoch15, step1383]: loss 3.535342
[epoch15, step1384]: loss 1.171631
[epoch15, step1385]: loss 1.251563
[epoch15, step1386]: loss 2.384538
[epoch15, step1387]: loss 2.837178
[epoch15, step1388]: loss 0.546760
[epoch15, step1389]: loss 13.626174
[epoch15, step1390]: loss 0.943992
[epoch15, step1391]: loss 6.627920
[epoch15, step1392]: loss 1.580819
[epoch15, step1393]: loss 3.709684
[epoch15, step1394]: loss 3.423079
[epoch15, step1395]: loss 2.147443
[epoch15, step1396]: loss 2.509896
[epoch15, step1397]: loss 6.321648
[epoch15, step1398]: loss 0.723278
[epoch15, step1399]: loss 0.997209
[epoch15, step1400]: loss 0.907849
[epoch15, step1401]: loss 5.595753
[epoch15, step1402]: loss 0.952248
[epoch15, step1403]: loss 12.445810
[epoch15, step1404]: loss 1.358216
[epoch15, step1405]: loss 0.548790
[epoch15, step1406]: loss 14.405484
[epoch15, step1407]: loss 4.043196
[epoch15, step1408]: loss 3.376671
[epoch15, step1409]: loss 11.657305
[epoch15, step1410]: loss 1.448353
[epoch15, step1411]: loss 0.534700
[epoch15, step1412]: loss 1.073745
[epoch15, step1413]: loss 2.179597
[epoch15, step1414]: loss 2.103864
[epoch15, step1415]: loss 14.036114
[epoch15, step1416]: loss 0.821077
[epoch15, step1417]: loss 2.395926
[epoch15, step1418]: loss 1.138301
[epoch15, step1419]: loss 0.809542
[epoch15, step1420]: loss 2.551646
[epoch15, step1421]: loss 2.452004
[epoch15, step1422]: loss 0.976158
[epoch15, step1423]: loss 1.187526
[epoch15, step1424]: loss 1.940286
[epoch15, step1425]: loss 1.055448
[epoch15, step1426]: loss 1.729887
[epoch15, step1427]: loss 9.312560
[epoch15, step1428]: loss 3.250756
[epoch15, step1429]: loss 1.130641
[epoch15, step1430]: loss 1.667277
[epoch15, step1431]: loss 3.023713
[epoch15, step1432]: loss 3.584967
[epoch15, step1433]: loss 8.197936
[epoch15, step1434]: loss 1.531159
[epoch15, step1435]: loss 10.171905
[epoch15, step1436]: loss 1.618886
[epoch15, step1437]: loss 6.846203
[epoch15, step1438]: loss 1.360629
[epoch15, step1439]: loss 9.980685
[epoch15, step1440]: loss 1.398777
[epoch15, step1441]: loss 8.044493
[epoch15, step1442]: loss 4.215326
[epoch15, step1443]: loss 1.637404
[epoch15, step1444]: loss 2.141470
[epoch15, step1445]: loss 10.378069
[epoch15, step1446]: loss 1.150210
[epoch15, step1447]: loss 1.456477
[epoch15, step1448]: loss 0.801411
[epoch15, step1449]: loss 0.629038
[epoch15, step1450]: loss 8.134764
[epoch15, step1451]: loss 0.976153
[epoch15, step1452]: loss 3.583515
[epoch15, step1453]: loss 1.471863
[epoch15, step1454]: loss 0.887251
[epoch15, step1455]: loss 6.494083
[epoch15, step1456]: loss 4.178755
[epoch15, step1457]: loss 2.584312
[epoch15, step1458]: loss 9.581255
[epoch15, step1459]: loss 0.690176
[epoch15, step1460]: loss 2.485994
[epoch15, step1461]: loss 1.509441
[epoch15, step1462]: loss 0.908675
[epoch15, step1463]: loss 3.419247
[epoch15, step1464]: loss 1.451271
[epoch15, step1465]: loss 14.250320
[epoch15, step1466]: loss 11.910412
[epoch15, step1467]: loss 1.219774
[epoch15, step1468]: loss 5.930268
[epoch15, step1469]: loss 9.412448
[epoch15, step1470]: loss 3.420327
[epoch15, step1471]: loss 12.208143
[epoch15, step1472]: loss 0.532084
[epoch15, step1473]: loss 12.443053
[epoch15, step1474]: loss 5.694159
[epoch15, step1475]: loss 3.336509
[epoch15, step1476]: loss 2.655138
[epoch15, step1477]: loss 1.035840
[epoch15, step1478]: loss 5.559396
[epoch15, step1479]: loss 1.281449
[epoch15, step1480]: loss 8.448960
[epoch15, step1481]: loss 1.204695
[epoch15, step1482]: loss 0.930034
[epoch15, step1483]: loss 0.842656
[epoch15, step1484]: loss 2.376420
[epoch15, step1485]: loss 1.226205
[epoch15, step1486]: loss 10.234816
[epoch15, step1487]: loss 3.792901
[epoch15, step1488]: loss 2.037489
[epoch15, step1489]: loss 9.217628
[epoch15, step1490]: loss 1.848038
[epoch15, step1491]: loss 5.206113
[epoch15, step1492]: loss 3.214193
[epoch15, step1493]: loss 1.698442
[epoch15, step1494]: loss 17.845814
[epoch15, step1495]: loss 3.709217
[epoch15, step1496]: loss 5.788725
[epoch15, step1497]: loss 2.526453
[epoch15, step1498]: loss 1.852200
[epoch15, step1499]: loss 3.160407
[epoch15, step1500]: loss 13.403935
[epoch15, step1501]: loss 1.941912
[epoch15, step1502]: loss 1.292446
[epoch15, step1503]: loss 1.246380
[epoch15, step1504]: loss 0.945706
[epoch15, step1505]: loss 4.853291
[epoch15, step1506]: loss 3.388873
[epoch15, step1507]: loss 1.703977
[epoch15, step1508]: loss 0.917479
[epoch15, step1509]: loss 5.572579
[epoch15, step1510]: loss 2.014567
[epoch15, step1511]: loss 0.864809
[epoch15, step1512]: loss 1.175227
[epoch15, step1513]: loss 23.125025
[epoch15, step1514]: loss 1.195090
[epoch15, step1515]: loss 1.705252
[epoch15, step1516]: loss 0.996478
[epoch15, step1517]: loss 0.836298
[epoch15, step1518]: loss 1.819884
[epoch15, step1519]: loss 9.580568
[epoch15, step1520]: loss 19.039873
[epoch15, step1521]: loss 4.824271
[epoch15, step1522]: loss 3.153105
[epoch15, step1523]: loss 1.794416
[epoch15, step1524]: loss 3.842839
[epoch15, step1525]: loss 1.431727
[epoch15, step1526]: loss 1.595064
[epoch15, step1527]: loss 1.283256
[epoch15, step1528]: loss 0.972485
[epoch15, step1529]: loss 7.843848
[epoch15, step1530]: loss 0.762829
[epoch15, step1531]: loss 1.826903
[epoch15, step1532]: loss 0.936076
[epoch15, step1533]: loss 17.057850
[epoch15, step1534]: loss 10.022939
[epoch15, step1535]: loss 9.807290
[epoch15, step1536]: loss 1.323770
[epoch15, step1537]: loss 1.263693
[epoch15, step1538]: loss 0.706856
[epoch15, step1539]: loss 0.728620
[epoch15, step1540]: loss 0.506447
[epoch15, step1541]: loss 0.511271
[epoch15, step1542]: loss 2.111552
[epoch15, step1543]: loss 7.745514
[epoch15, step1544]: loss 0.962475
[epoch15, step1545]: loss 1.382037
[epoch15, step1546]: loss 3.801991
[epoch15, step1547]: loss 1.148143
[epoch15, step1548]: loss 0.488894
[epoch15, step1549]: loss 1.285647
[epoch15, step1550]: loss 2.977020
[epoch15, step1551]: loss 1.231754
[epoch15, step1552]: loss 1.469914
[epoch15, step1553]: loss 24.993271
[epoch15, step1554]: loss 1.807614
[epoch15, step1555]: loss 6.442245
[epoch15, step1556]: loss 1.879813
[epoch15, step1557]: loss 0.790671
[epoch15, step1558]: loss 3.295250
[epoch15, step1559]: loss 7.609451
[epoch15, step1560]: loss 2.248705
[epoch15, step1561]: loss 1.037007
[epoch15, step1562]: loss 0.978610
[epoch15, step1563]: loss 2.163185
[epoch15, step1564]: loss 2.071213
[epoch15, step1565]: loss 1.997505
[epoch15, step1566]: loss 5.015222
[epoch15, step1567]: loss 0.793499
[epoch15, step1568]: loss 12.133728
[epoch15, step1569]: loss 1.525436
[epoch15, step1570]: loss 3.022892
[epoch15, step1571]: loss 1.569545
[epoch15, step1572]: loss 3.452506
[epoch15, step1573]: loss 3.764254
[epoch15, step1574]: loss 1.684360
[epoch15, step1575]: loss 1.518705
[epoch15, step1576]: loss 1.278726
[epoch15, step1577]: loss 1.132778
[epoch15, step1578]: loss 1.804447
[epoch15, step1579]: loss 3.457982
[epoch15, step1580]: loss 1.113311
[epoch15, step1581]: loss 1.405527
[epoch15, step1582]: loss 1.057622
[epoch15, step1583]: loss 2.304446
[epoch15, step1584]: loss 4.540681
[epoch15, step1585]: loss 1.455315
[epoch15, step1586]: loss 1.731944
[epoch15, step1587]: loss 1.622215
[epoch15, step1588]: loss 9.832212
[epoch15, step1589]: loss 9.253212
[epoch15, step1590]: loss 12.639755
[epoch15, step1591]: loss 0.775828
[epoch15, step1592]: loss 7.666530
[epoch15, step1593]: loss 2.466501
[epoch15, step1594]: loss 1.440119
[epoch15, step1595]: loss 1.127808
[epoch15, step1596]: loss 2.733534
[epoch15, step1597]: loss 17.389397
[epoch15, step1598]: loss 5.988361
[epoch15, step1599]: loss 9.239326
[epoch15, step1600]: loss 0.528669
[epoch15, step1601]: loss 0.989166
[epoch15, step1602]: loss 1.086291
[epoch15, step1603]: loss 1.546299
[epoch15, step1604]: loss 20.781914
[epoch15, step1605]: loss 6.443291
[epoch15, step1606]: loss 1.327208
[epoch15, step1607]: loss 1.309029
[epoch15, step1608]: loss 1.048031
[epoch15, step1609]: loss 2.794520
[epoch15, step1610]: loss 13.790941
[epoch15, step1611]: loss 0.786220
[epoch15, step1612]: loss 11.972577
[epoch15, step1613]: loss 6.810050
[epoch15, step1614]: loss 2.498191
[epoch15, step1615]: loss 12.882668
[epoch15, step1616]: loss 2.216790
[epoch15, step1617]: loss 5.534845
[epoch15, step1618]: loss 2.229002
[epoch15, step1619]: loss 5.953418
[epoch15, step1620]: loss 1.563355
[epoch15, step1621]: loss 9.560673
[epoch15, step1622]: loss 1.784029
[epoch15, step1623]: loss 0.908740
[epoch15, step1624]: loss 10.003050
[epoch15, step1625]: loss 9.389110
[epoch15, step1626]: loss 11.362536
[epoch15, step1627]: loss 2.134128
[epoch15, step1628]: loss 0.962600
[epoch15, step1629]: loss 2.894728
[epoch15, step1630]: loss 0.984620
[epoch15, step1631]: loss 1.099011
[epoch15, step1632]: loss 1.083344
[epoch15, step1633]: loss 0.834843
[epoch15, step1634]: loss 0.860797
[epoch15, step1635]: loss 1.170899
[epoch15, step1636]: loss 1.253916
[epoch15, step1637]: loss 3.505075
[epoch15, step1638]: loss 1.554238
[epoch15, step1639]: loss 0.540991
[epoch15, step1640]: loss 8.000280
[epoch15, step1641]: loss 14.937248
[epoch15, step1642]: loss 8.180946
[epoch15, step1643]: loss 2.055495
[epoch15, step1644]: loss 1.185026
[epoch15, step1645]: loss 1.192474
[epoch15, step1646]: loss 2.617328
[epoch15, step1647]: loss 12.191717
[epoch15, step1648]: loss 3.714692
[epoch15, step1649]: loss 4.365267
[epoch15, step1650]: loss 10.681291
[epoch15, step1651]: loss 1.561170
[epoch15, step1652]: loss 1.661849
[epoch15, step1653]: loss 2.972704
[epoch15, step1654]: loss 2.466015
[epoch15, step1655]: loss 1.104681
[epoch15, step1656]: loss 2.511839
[epoch15, step1657]: loss 0.848245
[epoch15, step1658]: loss 1.523133
[epoch15, step1659]: loss 1.076140
[epoch15, step1660]: loss 11.501143
[epoch15, step1661]: loss 3.807927
[epoch15, step1662]: loss 0.934108
[epoch15, step1663]: loss 5.176829
[epoch15, step1664]: loss 0.640129
[epoch15, step1665]: loss 4.097321
[epoch15, step1666]: loss 16.443623
[epoch15, step1667]: loss 14.820210
[epoch15, step1668]: loss 7.570942
[epoch15, step1669]: loss 2.148586
[epoch15, step1670]: loss 12.353495
[epoch15, step1671]: loss 10.613399
[epoch15, step1672]: loss 3.007115
[epoch15, step1673]: loss 1.236580
[epoch15, step1674]: loss 0.855469
[epoch15, step1675]: loss 8.334291
[epoch15, step1676]: loss 0.842487
[epoch15, step1677]: loss 1.015448
[epoch15, step1678]: loss 1.396055
[epoch15, step1679]: loss 0.523621
[epoch15, step1680]: loss 7.863747
[epoch15, step1681]: loss 1.047712
[epoch15, step1682]: loss 0.895574
[epoch15, step1683]: loss 2.423020
[epoch15, step1684]: loss 1.283036
[epoch15, step1685]: loss 1.733815
[epoch15, step1686]: loss 0.663411
[epoch15, step1687]: loss 2.043207
[epoch15, step1688]: loss 1.504460
[epoch15, step1689]: loss 1.546411
[epoch15, step1690]: loss 1.078783
[epoch15, step1691]: loss 1.986924
[epoch15, step1692]: loss 8.752064
[epoch15, step1693]: loss 10.253575
[epoch15, step1694]: loss 7.943029
[epoch15, step1695]: loss 0.689419
[epoch15, step1696]: loss 0.559038
[epoch15, step1697]: loss 1.594404
[epoch15, step1698]: loss 6.079196
[epoch15, step1699]: loss 1.047597
[epoch15, step1700]: loss 0.809365
[epoch15, step1701]: loss 2.764562
[epoch15, step1702]: loss 1.210587
[epoch15, step1703]: loss 0.893359
[epoch15, step1704]: loss 0.699344
[epoch15, step1705]: loss 4.609357
[epoch15, step1706]: loss 14.142694
[epoch15, step1707]: loss 1.201419
[epoch15, step1708]: loss 1.962953
[epoch15, step1709]: loss 3.145776
[epoch15, step1710]: loss 3.087605
[epoch15, step1711]: loss 1.673479
[epoch15, step1712]: loss 1.296295
[epoch15, step1713]: loss 5.746527
[epoch15, step1714]: loss 2.243101
[epoch15, step1715]: loss 0.985840
[epoch15, step1716]: loss 0.819958
[epoch15, step1717]: loss 1.355595
[epoch15, step1718]: loss 0.630725
[epoch15, step1719]: loss 2.459339
[epoch15, step1720]: loss 6.926192
[epoch15, step1721]: loss 2.076799
[epoch15, step1722]: loss 0.840334
[epoch15, step1723]: loss 2.565589
[epoch15, step1724]: loss 0.996731
[epoch15, step1725]: loss 2.795943
[epoch15, step1726]: loss 8.317281
[epoch15, step1727]: loss 1.181138
[epoch15, step1728]: loss 3.564372
[epoch15, step1729]: loss 2.588611
[epoch15, step1730]: loss 4.865460
[epoch15, step1731]: loss 11.876297
[epoch15, step1732]: loss 12.991747
[epoch15, step1733]: loss 1.127869
[epoch15, step1734]: loss 5.436935
[epoch15, step1735]: loss 11.858004
[epoch15, step1736]: loss 1.268714
[epoch15, step1737]: loss 4.731579
[epoch15, step1738]: loss 8.920120
[epoch15, step1739]: loss 3.026517
[epoch15, step1740]: loss 2.052652
[epoch15, step1741]: loss 1.099792
[epoch15, step1742]: loss 9.552304
[epoch15, step1743]: loss 0.856877
[epoch15, step1744]: loss 4.741530
[epoch15, step1745]: loss 0.882856
[epoch15, step1746]: loss 1.109056
[epoch15, step1747]: loss 10.525861
[epoch15, step1748]: loss 0.766889
[epoch15, step1749]: loss 9.379890
[epoch15, step1750]: loss 1.716263
[epoch15, step1751]: loss 31.622459
[epoch15, step1752]: loss 1.576445
[epoch15, step1753]: loss 4.022884
[epoch15, step1754]: loss 7.249792
[epoch15, step1755]: loss 6.746243
[epoch15, step1756]: loss 8.510056
[epoch15, step1757]: loss 2.057781
[epoch15, step1758]: loss 1.958309
[epoch15, step1759]: loss 0.668509
[epoch15, step1760]: loss 1.633945
[epoch15, step1761]: loss 0.780896
[epoch15, step1762]: loss 0.857199
[epoch15, step1763]: loss 0.876397
[epoch15, step1764]: loss 4.702192
[epoch15, step1765]: loss 2.820474
[epoch15, step1766]: loss 1.979899
[epoch15, step1767]: loss 9.394477
[epoch15, step1768]: loss 1.179673
[epoch15, step1769]: loss 0.945938
[epoch15, step1770]: loss 14.114815
[epoch15, step1771]: loss 1.263880
[epoch15, step1772]: loss 1.297609
[epoch15, step1773]: loss 1.169536
[epoch15, step1774]: loss 0.652171
[epoch15, step1775]: loss 1.046958
[epoch15, step1776]: loss 1.490245
[epoch15, step1777]: loss 1.702115
[epoch15, step1778]: loss 1.909528
[epoch15, step1779]: loss 3.428498
[epoch15, step1780]: loss 9.007800
[epoch15, step1781]: loss 1.963735
[epoch15, step1782]: loss 1.103353
[epoch15, step1783]: loss 4.124657
[epoch15, step1784]: loss 12.301023
[epoch15, step1785]: loss 0.803954
[epoch15, step1786]: loss 6.450027
[epoch15, step1787]: loss 14.179554
[epoch15, step1788]: loss 3.633357
[epoch15, step1789]: loss 2.436889
[epoch15, step1790]: loss 4.963154
[epoch15, step1791]: loss 22.326317
[epoch15, step1792]: loss 12.804851
[epoch15, step1793]: loss 1.032351
[epoch15, step1794]: loss 1.297973
[epoch15, step1795]: loss 1.078013
[epoch15, step1796]: loss 1.252029
[epoch15, step1797]: loss 2.019804
[epoch15, step1798]: loss 4.011595
[epoch15, step1799]: loss 1.689731
[epoch15, step1800]: loss 8.130155
[epoch15, step1801]: loss 3.234382
[epoch15, step1802]: loss 3.531515
[epoch15, step1803]: loss 0.990394
[epoch15, step1804]: loss 1.809393
[epoch15, step1805]: loss 0.872893
[epoch15, step1806]: loss 0.752364
[epoch15, step1807]: loss 17.914536
[epoch15, step1808]: loss 0.801878
[epoch15, step1809]: loss 1.659967
[epoch15, step1810]: loss 1.279701
[epoch15, step1811]: loss 5.906753
[epoch15, step1812]: loss 2.429546
[epoch15, step1813]: loss 1.016212
[epoch15, step1814]: loss 12.855305
[epoch15, step1815]: loss 2.819858
[epoch15, step1816]: loss 3.474467
[epoch15, step1817]: loss 5.284769
[epoch15, step1818]: loss 18.778183
[epoch15, step1819]: loss 1.907557
[epoch15, step1820]: loss 1.030973
[epoch15, step1821]: loss 0.989792
[epoch15, step1822]: loss 0.934837
[epoch15, step1823]: loss 1.631112
[epoch15, step1824]: loss 2.924399
[epoch15, step1825]: loss 2.177891
[epoch15, step1826]: loss 2.128363
[epoch15, step1827]: loss 1.043334
[epoch15, step1828]: loss 5.510736
[epoch15, step1829]: loss 2.525269
[epoch15, step1830]: loss 13.547329
[epoch15, step1831]: loss 10.067165
[epoch15, step1832]: loss 8.630329
[epoch15, step1833]: loss 2.741609
[epoch15, step1834]: loss 1.420153
[epoch15, step1835]: loss 4.094504
[epoch15, step1836]: loss 0.519901
[epoch15, step1837]: loss 4.052278
[epoch15, step1838]: loss 1.525495
[epoch15, step1839]: loss 2.354792
[epoch15, step1840]: loss 13.149634
[epoch15, step1841]: loss 1.344887
[epoch15, step1842]: loss 4.785281
[epoch15, step1843]: loss 1.394991
[epoch15, step1844]: loss 1.404707
[epoch15, step1845]: loss 1.221644
[epoch15, step1846]: loss 0.767041
[epoch15, step1847]: loss 2.289364
[epoch15, step1848]: loss 4.746689
[epoch15, step1849]: loss 13.048867
[epoch15, step1850]: loss 6.338300
[epoch15, step1851]: loss 1.555618
[epoch15, step1852]: loss 8.946032
[epoch15, step1853]: loss 5.746722
[epoch15, step1854]: loss 2.114440
[epoch15, step1855]: loss 0.855055
[epoch15, step1856]: loss 0.747858
[epoch15, step1857]: loss 1.164233
[epoch15, step1858]: loss 2.665677
[epoch15, step1859]: loss 1.172370
[epoch15, step1860]: loss 1.954577
[epoch15, step1861]: loss 2.234929
[epoch15, step1862]: loss 3.503117
[epoch15, step1863]: loss 1.088605
[epoch15, step1864]: loss 15.352938
[epoch15, step1865]: loss 10.874965
[epoch15, step1866]: loss 2.395584
[epoch15, step1867]: loss 34.969433
[epoch15, step1868]: loss 1.906947
[epoch15, step1869]: loss 1.896572
[epoch15, step1870]: loss 17.553207
[epoch15, step1871]: loss 1.430939
[epoch15, step1872]: loss 2.306025
[epoch15, step1873]: loss 2.374008
[epoch15, step1874]: loss 0.879182
[epoch15, step1875]: loss 1.428327
[epoch15, step1876]: loss 1.850941
[epoch15, step1877]: loss 28.746222
[epoch15, step1878]: loss 15.141667
[epoch15, step1879]: loss 5.136581
[epoch15, step1880]: loss 0.882628
[epoch15, step1881]: loss 1.235616
[epoch15, step1882]: loss 0.969970
[epoch15, step1883]: loss 11.433171
[epoch15, step1884]: loss 0.603943
[epoch15, step1885]: loss 7.606349
[epoch15, step1886]: loss 3.641064
[epoch15, step1887]: loss 12.499285
[epoch15, step1888]: loss 4.732655
[epoch15, step1889]: loss 2.366358
[epoch15, step1890]: loss 1.681727
[epoch15, step1891]: loss 6.680173
[epoch15, step1892]: loss 1.182717
[epoch15, step1893]: loss 4.303328
[epoch15, step1894]: loss 16.962988
[epoch15, step1895]: loss 27.985138
[epoch15, step1896]: loss 11.978730
[epoch15, step1897]: loss 18.519867
[epoch15, step1898]: loss 4.773016
[epoch15, step1899]: loss 1.600469
[epoch15, step1900]: loss 9.436367
[epoch15, step1901]: loss 0.991885
[epoch15, step1902]: loss 12.033215
[epoch15, step1903]: loss 1.966082
[epoch15, step1904]: loss 1.449515
[epoch15, step1905]: loss 1.619939
[epoch15, step1906]: loss 0.803543
[epoch15, step1907]: loss 0.670011
[epoch15, step1908]: loss 28.774317
[epoch15, step1909]: loss 8.376687
[epoch15, step1910]: loss 0.887835
[epoch15, step1911]: loss 1.833740
[epoch15, step1912]: loss 2.812136
[epoch15, step1913]: loss 1.217207
[epoch15, step1914]: loss 1.481773
[epoch15, step1915]: loss 5.635116
[epoch15, step1916]: loss 1.405912
[epoch15, step1917]: loss 2.923980
[epoch15, step1918]: loss 1.188149
[epoch15, step1919]: loss 1.106491
[epoch15, step1920]: loss 1.413771
[epoch15, step1921]: loss 0.804329
[epoch15, step1922]: loss 3.182343
[epoch15, step1923]: loss 9.471373
[epoch15, step1924]: loss 0.906862
[epoch15, step1925]: loss 8.737340
[epoch15, step1926]: loss 13.382799
[epoch15, step1927]: loss 12.893516
[epoch15, step1928]: loss 12.502470
[epoch15, step1929]: loss 9.504475
[epoch15, step1930]: loss 1.844640
[epoch15, step1931]: loss 0.677570
[epoch15, step1932]: loss 2.914196
[epoch15, step1933]: loss 9.466550
[epoch15, step1934]: loss 2.304240
[epoch15, step1935]: loss 21.862810
[epoch15, step1936]: loss 4.565095
[epoch15, step1937]: loss 2.113162
[epoch15, step1938]: loss 14.755075
[epoch15, step1939]: loss 13.264703
[epoch15, step1940]: loss 1.292531
[epoch15, step1941]: loss 1.202370
[epoch15, step1942]: loss 18.362257
[epoch15, step1943]: loss 1.443310
[epoch15, step1944]: loss 7.910083
[epoch15, step1945]: loss 0.688253
[epoch15, step1946]: loss 1.209776
[epoch15, step1947]: loss 3.384891
[epoch15, step1948]: loss 5.943565
[epoch15, step1949]: loss 4.729728
[epoch15, step1950]: loss 2.248468
[epoch15, step1951]: loss 8.699754
[epoch15, step1952]: loss 0.944338
[epoch15, step1953]: loss 0.667911
[epoch15, step1954]: loss 16.739363
[epoch15, step1955]: loss 8.686687
[epoch15, step1956]: loss 7.553966
[epoch15, step1957]: loss 1.785816
[epoch15, step1958]: loss 2.088509
[epoch15, step1959]: loss 0.905483
[epoch15, step1960]: loss 1.502818
[epoch15, step1961]: loss 5.938537
[epoch15, step1962]: loss 13.588086
[epoch15, step1963]: loss 3.287730
[epoch15, step1964]: loss 1.066190
[epoch15, step1965]: loss 16.003983
[epoch15, step1966]: loss 2.550675
[epoch15, step1967]: loss 9.808273
[epoch15, step1968]: loss 3.236756
[epoch15, step1969]: loss 1.844328
[epoch15, step1970]: loss 14.099115
[epoch15, step1971]: loss 1.878695
[epoch15, step1972]: loss 1.163175
[epoch15, step1973]: loss 1.664177
[epoch15, step1974]: loss 0.932776
[epoch15, step1975]: loss 1.303558
[epoch15, step1976]: loss 0.870641
[epoch15, step1977]: loss 8.376895
[epoch15, step1978]: loss 0.754970
[epoch15, step1979]: loss 0.853083
[epoch15, step1980]: loss 4.601817
[epoch15, step1981]: loss 7.208884
[epoch15, step1982]: loss 0.480088
[epoch15, step1983]: loss 0.698569
[epoch15, step1984]: loss 2.016155
[epoch15, step1985]: loss 1.263209
[epoch15, step1986]: loss 5.195986
[epoch15, step1987]: loss 1.537726
[epoch15, step1988]: loss 2.104130
[epoch15, step1989]: loss 0.894746
[epoch15, step1990]: loss 4.321914
[epoch15, step1991]: loss 1.353195
[epoch15, step1992]: loss 1.784071
[epoch15, step1993]: loss 6.273956
[epoch15, step1994]: loss 2.077442
[epoch15, step1995]: loss 2.162753
[epoch15, step1996]: loss 1.056156
[epoch15, step1997]: loss 1.380866
[epoch15, step1998]: loss 9.180406
[epoch15, step1999]: loss 0.956810
[epoch15, step2000]: loss 1.143369
[epoch15, step2001]: loss 0.756358
[epoch15, step2002]: loss 2.651742
[epoch15, step2003]: loss 1.545117
[epoch15, step2004]: loss 1.384470
[epoch15, step2005]: loss 1.564724
[epoch15, step2006]: loss 6.532260
[epoch15, step2007]: loss 6.683430
[epoch15, step2008]: loss 1.146070
[epoch15, step2009]: loss 0.556323
[epoch15, step2010]: loss 2.437291
[epoch15, step2011]: loss 1.202929
[epoch15, step2012]: loss 19.095690
[epoch15, step2013]: loss 2.415257
[epoch15, step2014]: loss 1.401227
[epoch15, step2015]: loss 11.795434
[epoch15, step2016]: loss 7.164162
[epoch15, step2017]: loss 1.304153
[epoch15, step2018]: loss 1.538320
[epoch15, step2019]: loss 0.796507
[epoch15, step2020]: loss 1.177046
[epoch15, step2021]: loss 1.600470
[epoch15, step2022]: loss 2.924303
[epoch15, step2023]: loss 1.355236
[epoch15, step2024]: loss 1.669292
[epoch15, step2025]: loss 2.689537
[epoch15, step2026]: loss 1.254920
[epoch15, step2027]: loss 3.129582
[epoch15, step2028]: loss 1.154784
[epoch15, step2029]: loss 7.281838
[epoch15, step2030]: loss 1.403123
[epoch15, step2031]: loss 9.923469
[epoch15, step2032]: loss 3.031569
[epoch15, step2033]: loss 0.724906
[epoch15, step2034]: loss 1.567945
[epoch15, step2035]: loss 3.695258
[epoch15, step2036]: loss 9.214912
[epoch15, step2037]: loss 1.801992
[epoch15, step2038]: loss 13.713021
[epoch15, step2039]: loss 1.075116
[epoch15, step2040]: loss 2.416230
[epoch15, step2041]: loss 1.821540
[epoch15, step2042]: loss 0.484126
[epoch15, step2043]: loss 8.694246
[epoch15, step2044]: loss 2.248272
[epoch15, step2045]: loss 4.796390
[epoch15, step2046]: loss 1.548298
[epoch15, step2047]: loss 11.805915
[epoch15, step2048]: loss 2.515365
[epoch15, step2049]: loss 1.373547
[epoch15, step2050]: loss 14.226453
[epoch15, step2051]: loss 8.102213
[epoch15, step2052]: loss 0.726320
[epoch15, step2053]: loss 1.030692
[epoch15, step2054]: loss 6.283973
[epoch15, step2055]: loss 12.463970
[epoch15, step2056]: loss 7.987730
[epoch15, step2057]: loss 1.561903
[epoch15, step2058]: loss 1.608056
[epoch15, step2059]: loss 4.620667
[epoch15, step2060]: loss 0.665160
[epoch15, step2061]: loss 4.387877
[epoch15, step2062]: loss 0.627928
[epoch15, step2063]: loss 2.001276
[epoch15, step2064]: loss 1.960531
[epoch15, step2065]: loss 2.566032
[epoch15, step2066]: loss 11.707415
[epoch15, step2067]: loss 1.385487
[epoch15, step2068]: loss 6.317939
[epoch15, step2069]: loss 1.177283
[epoch15, step2070]: loss 0.900343
[epoch15, step2071]: loss 1.492574
[epoch15, step2072]: loss 5.665873
[epoch15, step2073]: loss 3.478849
[epoch15, step2074]: loss 0.660096
[epoch15, step2075]: loss 1.526041
[epoch15, step2076]: loss 1.416398
[epoch15, step2077]: loss 1.252558
[epoch15, step2078]: loss 0.903923
[epoch15, step2079]: loss 1.321061
[epoch15, step2080]: loss 8.731331
[epoch15, step2081]: loss 0.977564
[epoch15, step2082]: loss 1.444835
[epoch15, step2083]: loss 4.387341
[epoch15, step2084]: loss 1.584836
[epoch15, step2085]: loss 0.742794
[epoch15, step2086]: loss 2.439152
[epoch15, step2087]: loss 11.509137
[epoch15, step2088]: loss 1.143659
[epoch15, step2089]: loss 2.277093
[epoch15, step2090]: loss 11.968150
[epoch15, step2091]: loss 1.046263
[epoch15, step2092]: loss 1.839948
[epoch15, step2093]: loss 5.188468
[epoch15, step2094]: loss 5.347460
[epoch15, step2095]: loss 2.324294
[epoch15, step2096]: loss 6.449642
[epoch15, step2097]: loss 1.220029
[epoch15, step2098]: loss 2.050314
[epoch15, step2099]: loss 17.333563
[epoch15, step2100]: loss 6.486953
[epoch15, step2101]: loss 13.803298
[epoch15, step2102]: loss 3.726209
[epoch15, step2103]: loss 1.636100
[epoch15, step2104]: loss 3.507805
[epoch15, step2105]: loss 2.556279
[epoch15, step2106]: loss 12.882198
[epoch15, step2107]: loss 0.860651
[epoch15, step2108]: loss 1.157312
[epoch15, step2109]: loss 1.298054
[epoch15, step2110]: loss 1.859949
[epoch15, step2111]: loss 2.686557
[epoch15, step2112]: loss 0.961069
[epoch15, step2113]: loss 16.979355
[epoch15, step2114]: loss 1.523314
[epoch15, step2115]: loss 1.349900
[epoch15, step2116]: loss 7.465986
[epoch15, step2117]: loss 1.402632
[epoch15, step2118]: loss 11.823046
[epoch15, step2119]: loss 1.062623
[epoch15, step2120]: loss 2.342933
[epoch15, step2121]: loss 1.911542
[epoch15, step2122]: loss 1.889918
[epoch15, step2123]: loss 2.362180
[epoch15, step2124]: loss 0.952692
[epoch15, step2125]: loss 1.278670
[epoch15, step2126]: loss 1.588653
[epoch15, step2127]: loss 0.844819
[epoch15, step2128]: loss 3.201805
[epoch15, step2129]: loss 5.674299
[epoch15, step2130]: loss 7.501482
[epoch15, step2131]: loss 3.515432
[epoch15, step2132]: loss 1.970971
[epoch15, step2133]: loss 1.349145
[epoch15, step2134]: loss 5.237154
[epoch15, step2135]: loss 1.398268
[epoch15, step2136]: loss 3.477431
[epoch15, step2137]: loss 0.703374
[epoch15, step2138]: loss 1.075378
[epoch15, step2139]: loss 1.136213
[epoch15, step2140]: loss 16.040770
[epoch15, step2141]: loss 4.861293
[epoch15, step2142]: loss 0.867098
[epoch15, step2143]: loss 4.548872
[epoch15, step2144]: loss 0.970737
[epoch15, step2145]: loss 40.230682
[epoch15, step2146]: loss 1.559688
[epoch15, step2147]: loss 0.759812
[epoch15, step2148]: loss 1.037877
[epoch15, step2149]: loss 0.605631
[epoch15, step2150]: loss 1.067808
[epoch15, step2151]: loss 5.451216
[epoch15, step2152]: loss 2.381745
[epoch15, step2153]: loss 0.589395
[epoch15, step2154]: loss 8.582664
[epoch15, step2155]: loss 4.459002
[epoch15, step2156]: loss 9.154945
[epoch15, step2157]: loss 4.351590
[epoch15, step2158]: loss 3.888114
[epoch15, step2159]: loss 11.623787
[epoch15, step2160]: loss 0.696866
[epoch15, step2161]: loss 7.642646
[epoch15, step2162]: loss 11.591100
[epoch15, step2163]: loss 1.914297
[epoch15, step2164]: loss 5.825503
[epoch15, step2165]: loss 0.682711
[epoch15, step2166]: loss 2.241740
[epoch15, step2167]: loss 3.154556
[epoch15, step2168]: loss 0.996697
[epoch15, step2169]: loss 7.996485
[epoch15, step2170]: loss 9.154100
[epoch15, step2171]: loss 1.374635
[epoch15, step2172]: loss 16.670553
[epoch15, step2173]: loss 4.792339
[epoch15, step2174]: loss 1.983834
[epoch15, step2175]: loss 7.437135
[epoch15, step2176]: loss 2.034880
[epoch15, step2177]: loss 1.588979
[epoch15, step2178]: loss 3.770795
[epoch15, step2179]: loss 0.687053
[epoch15, step2180]: loss 0.642332
[epoch15, step2181]: loss 2.326860
[epoch15, step2182]: loss 4.238994
[epoch15, step2183]: loss 3.178209
[epoch15, step2184]: loss 0.515491
[epoch15, step2185]: loss 2.557107
[epoch15, step2186]: loss 10.583616
[epoch15, step2187]: loss 5.500180
[epoch15, step2188]: loss 4.326682
[epoch15, step2189]: loss 1.418998
[epoch15, step2190]: loss 1.434249
[epoch15, step2191]: loss 18.994154
[epoch15, step2192]: loss 0.927037
[epoch15, step2193]: loss 6.981743
[epoch15, step2194]: loss 1.984862
[epoch15, step2195]: loss 2.354849
[epoch15, step2196]: loss 2.129059
[epoch15, step2197]: loss 2.913233
[epoch15, step2198]: loss 1.616002
[epoch15, step2199]: loss 0.930866
[epoch15, step2200]: loss 3.864807
[epoch15, step2201]: loss 1.635163
[epoch15, step2202]: loss 4.839024
[epoch15, step2203]: loss 2.440795
[epoch15, step2204]: loss 2.828082
[epoch15, step2205]: loss 1.585262
[epoch15, step2206]: loss 1.333866
[epoch15, step2207]: loss 3.763762
[epoch15, step2208]: loss 3.275422
[epoch15, step2209]: loss 1.814648
[epoch15, step2210]: loss 2.890859
[epoch15, step2211]: loss 10.160504
[epoch15, step2212]: loss 2.176690
[epoch15, step2213]: loss 9.505853
[epoch15, step2214]: loss 1.213030
[epoch15, step2215]: loss 0.849784
[epoch15, step2216]: loss 1.597905
[epoch15, step2217]: loss 3.960561
[epoch15, step2218]: loss 1.917624
[epoch15, step2219]: loss 1.895898
[epoch15, step2220]: loss 8.078071
[epoch15, step2221]: loss 1.365800
[epoch15, step2222]: loss 11.501994
[epoch15, step2223]: loss 25.762405
[epoch15, step2224]: loss 2.582046
[epoch15, step2225]: loss 25.453537
[epoch15, step2226]: loss 2.165910
[epoch15, step2227]: loss 11.872982
[epoch15, step2228]: loss 2.241412
[epoch15, step2229]: loss 1.100832
[epoch15, step2230]: loss 1.688059
[epoch15, step2231]: loss 1.724765
[epoch15, step2232]: loss 13.380919
[epoch15, step2233]: loss 5.169545
[epoch15, step2234]: loss 1.251003
[epoch15, step2235]: loss 8.394858
[epoch15, step2236]: loss 1.641918
[epoch15, step2237]: loss 0.970512
[epoch15, step2238]: loss 29.039492
[epoch15, step2239]: loss 6.296288
[epoch15, step2240]: loss 1.476093
[epoch15, step2241]: loss 13.405209
[epoch15, step2242]: loss 1.027810
[epoch15, step2243]: loss 0.589134
[epoch15, step2244]: loss 1.968907
[epoch15, step2245]: loss 0.912932
[epoch15, step2246]: loss 5.865891
[epoch15, step2247]: loss 0.686865
[epoch15, step2248]: loss 2.555244
[epoch15, step2249]: loss 10.250863
[epoch15, step2250]: loss 1.291136
[epoch15, step2251]: loss 0.956668
[epoch15, step2252]: loss 1.025698
[epoch15, step2253]: loss 4.162590
[epoch15, step2254]: loss 2.192145
[epoch15, step2255]: loss 2.350867
[epoch15, step2256]: loss 0.572620
[epoch15, step2257]: loss 1.407746
[epoch15, step2258]: loss 4.566638
[epoch15, step2259]: loss 2.110922
[epoch15, step2260]: loss 7.691516
[epoch15, step2261]: loss 2.015233
[epoch15, step2262]: loss 3.982766
[epoch15, step2263]: loss 1.148590
[epoch15, step2264]: loss 1.040815
[epoch15, step2265]: loss 2.801010
[epoch15, step2266]: loss 1.970693
[epoch15, step2267]: loss 8.939639
[epoch15, step2268]: loss 1.941231
[epoch15, step2269]: loss 3.013752
[epoch15, step2270]: loss 1.994750
[epoch15, step2271]: loss 2.468535
[epoch15, step2272]: loss 1.245776
[epoch15, step2273]: loss 1.024340
[epoch15, step2274]: loss 7.998546
[epoch15, step2275]: loss 8.238910
[epoch15, step2276]: loss 9.074110
[epoch15, step2277]: loss 1.179302
[epoch15, step2278]: loss 1.018557
[epoch15, step2279]: loss 18.062357
[epoch15, step2280]: loss 1.228136
[epoch15, step2281]: loss 1.295876
[epoch15, step2282]: loss 14.476942
[epoch15, step2283]: loss 2.256286
[epoch15, step2284]: loss 1.685295
[epoch15, step2285]: loss 4.665318
[epoch15, step2286]: loss 0.632974
[epoch15, step2287]: loss 0.668341
[epoch15, step2288]: loss 0.649086
[epoch15, step2289]: loss 1.391723
[epoch15, step2290]: loss 6.722198
[epoch15, step2291]: loss 1.097048
[epoch15, step2292]: loss 1.402662
[epoch15, step2293]: loss 2.398474
[epoch15, step2294]: loss 0.586251
[epoch15, step2295]: loss 6.794084
[epoch15, step2296]: loss 1.083601
[epoch15, step2297]: loss 3.646384
[epoch15, step2298]: loss 1.267371
[epoch15, step2299]: loss 1.671479
[epoch15, step2300]: loss 8.494965
[epoch15, step2301]: loss 2.544342
[epoch15, step2302]: loss 2.684325
[epoch15, step2303]: loss 1.466646
[epoch15, step2304]: loss 1.180104
[epoch15, step2305]: loss 0.848025
[epoch15, step2306]: loss 2.922672
[epoch15, step2307]: loss 0.756125
[epoch15, step2308]: loss 2.908059
[epoch15, step2309]: loss 3.215299
[epoch15, step2310]: loss 1.151185
[epoch15, step2311]: loss 0.683523
[epoch15, step2312]: loss 1.256929
[epoch15, step2313]: loss 1.296300
[epoch15, step2314]: loss 7.778765
[epoch15, step2315]: loss 5.708373
[epoch15, step2316]: loss 24.900503
[epoch15, step2317]: loss 4.652398
[epoch15, step2318]: loss 1.220068
[epoch15, step2319]: loss 2.903870
[epoch15, step2320]: loss 0.989692
[epoch15, step2321]: loss 0.939533
[epoch15, step2322]: loss 1.421328
[epoch15, step2323]: loss 6.293020
[epoch15, step2324]: loss 4.440439
[epoch15, step2325]: loss 2.209415
[epoch15, step2326]: loss 2.207236
[epoch15, step2327]: loss 6.647533
[epoch15, step2328]: loss 14.328093
[epoch15, step2329]: loss 18.877785
[epoch15, step2330]: loss 9.831774
[epoch15, step2331]: loss 2.203507
[epoch15, step2332]: loss 1.730332
[epoch15, step2333]: loss 1.177573
[epoch15, step2334]: loss 1.614310
[epoch15, step2335]: loss 0.766827
[epoch15, step2336]: loss 0.583692
[epoch15, step2337]: loss 1.075419
[epoch15, step2338]: loss 3.113399
[epoch15, step2339]: loss 1.704958
[epoch15, step2340]: loss 1.317075
[epoch15, step2341]: loss 4.090888
[epoch15, step2342]: loss 2.268745
[epoch15, step2343]: loss 0.990617
[epoch15, step2344]: loss 1.748620
[epoch15, step2345]: loss 4.051713
[epoch15, step2346]: loss 2.166589
[epoch15, step2347]: loss 0.491431
[epoch15, step2348]: loss 1.984001
[epoch15, step2349]: loss 1.514675
[epoch15, step2350]: loss 6.322241
[epoch15, step2351]: loss 4.024858
[epoch15, step2352]: loss 9.614275
[epoch15, step2353]: loss 1.546620
[epoch15, step2354]: loss 4.869142
[epoch15, step2355]: loss 1.020727
[epoch15, step2356]: loss 1.219816
[epoch15, step2357]: loss 3.323043
[epoch15, step2358]: loss 2.678593
[epoch15, step2359]: loss 8.432089
[epoch15, step2360]: loss 1.082100
[epoch15, step2361]: loss 0.914966
[epoch15, step2362]: loss 6.553879
[epoch15, step2363]: loss 2.546498
[epoch15, step2364]: loss 6.295557
[epoch15, step2365]: loss 0.918161
[epoch15, step2366]: loss 0.758562
[epoch15, step2367]: loss 1.406899
[epoch15, step2368]: loss 42.871277
[epoch15, step2369]: loss 0.759867
[epoch15, step2370]: loss 5.943584
[epoch15, step2371]: loss 1.721888
[epoch15, step2372]: loss 29.039764
[epoch15, step2373]: loss 1.319391
[epoch15, step2374]: loss 7.370612
[epoch15, step2375]: loss 38.177547
[epoch15, step2376]: loss 4.652672
[epoch15, step2377]: loss 1.027805
[epoch15, step2378]: loss 0.842502
[epoch15, step2379]: loss 1.128147
[epoch15, step2380]: loss 0.887050
[epoch15, step2381]: loss 3.083182
[epoch15, step2382]: loss 7.633644
[epoch15, step2383]: loss 0.893364
[epoch15, step2384]: loss 1.434358
[epoch15, step2385]: loss 3.205657
[epoch15, step2386]: loss 0.635462
[epoch15, step2387]: loss 0.916690
[epoch15, step2388]: loss 0.503233
[epoch15, step2389]: loss 8.650676
[epoch15, step2390]: loss 0.526289
[epoch15, step2391]: loss 3.590202
[epoch15, step2392]: loss 2.878894
[epoch15, step2393]: loss 1.599538
[epoch15, step2394]: loss 2.094068
[epoch15, step2395]: loss 5.473670
[epoch15, step2396]: loss 7.384544
[epoch15, step2397]: loss 1.223651
[epoch15, step2398]: loss 1.570471
[epoch15, step2399]: loss 2.288860
[epoch15, step2400]: loss 0.760770
[epoch15, step2401]: loss 3.023636
[epoch15, step2402]: loss 3.646875
[epoch15, step2403]: loss 0.739797
[epoch15, step2404]: loss 1.653152
[epoch15, step2405]: loss 0.946291
[epoch15, step2406]: loss 1.543378
[epoch15, step2407]: loss 1.740484
[epoch15, step2408]: loss 1.725882
[epoch15, step2409]: loss 0.614800
[epoch15, step2410]: loss 0.750565
[epoch15, step2411]: loss 13.402925
[epoch15, step2412]: loss 1.232390
[epoch15, step2413]: loss 2.685010
[epoch15, step2414]: loss 1.141354
[epoch15, step2415]: loss 1.259898
[epoch15, step2416]: loss 0.994285
[epoch15, step2417]: loss 0.518492
[epoch15, step2418]: loss 2.066240
[epoch15, step2419]: loss 8.423702
[epoch15, step2420]: loss 2.256766
[epoch15, step2421]: loss 1.177090
[epoch15, step2422]: loss 4.488254
[epoch15, step2423]: loss 1.450644
[epoch15, step2424]: loss 1.796174
[epoch15, step2425]: loss 1.101250
[epoch15, step2426]: loss 3.787400
[epoch15, step2427]: loss 2.507095
[epoch15, step2428]: loss 1.441733
[epoch15, step2429]: loss 2.539929
[epoch15, step2430]: loss 8.565411
[epoch15, step2431]: loss 6.618559
[epoch15, step2432]: loss 1.221371
[epoch15, step2433]: loss 14.392823
[epoch15, step2434]: loss 0.971400
[epoch15, step2435]: loss 1.221149
[epoch15, step2436]: loss 1.988198
[epoch15, step2437]: loss 1.130368
[epoch15, step2438]: loss 1.441945
[epoch15, step2439]: loss 0.498242
[epoch15, step2440]: loss 1.137785
[epoch15, step2441]: loss 12.398865
[epoch15, step2442]: loss 1.741075
[epoch15, step2443]: loss 0.784955
[epoch15, step2444]: loss 7.361631
[epoch15, step2445]: loss 2.095024
[epoch15, step2446]: loss 1.156622
[epoch15, step2447]: loss 1.935443
[epoch15, step2448]: loss 0.871406
[epoch15, step2449]: loss 5.603343
[epoch15, step2450]: loss 3.261283
[epoch15, step2451]: loss 2.119198
[epoch15, step2452]: loss 2.691270
[epoch15, step2453]: loss 11.427516
[epoch15, step2454]: loss 7.457330
[epoch15, step2455]: loss 2.275862
[epoch15, step2456]: loss 2.212922
[epoch15, step2457]: loss 1.331656
[epoch15, step2458]: loss 1.025216
[epoch15, step2459]: loss 2.759179
[epoch15, step2460]: loss 1.475067
[epoch15, step2461]: loss 0.660638
[epoch15, step2462]: loss 10.354368
[epoch15, step2463]: loss 2.197737
[epoch15, step2464]: loss 2.127535
[epoch15, step2465]: loss 1.306851
[epoch15, step2466]: loss 0.823830
[epoch15, step2467]: loss 12.713563
[epoch15, step2468]: loss 1.314729
[epoch15, step2469]: loss 11.127182
[epoch15, step2470]: loss 1.568120
[epoch15, step2471]: loss 2.083810
[epoch15, step2472]: loss 1.143262
[epoch15, step2473]: loss 3.682769
[epoch15, step2474]: loss 2.974587
[epoch15, step2475]: loss 1.174652
[epoch15, step2476]: loss 2.029881
[epoch15, step2477]: loss 4.883067
[epoch15, step2478]: loss 2.125985
[epoch15, step2479]: loss 1.445594
[epoch15, step2480]: loss 1.318757
[epoch15, step2481]: loss 5.226609
[epoch15, step2482]: loss 6.751617
[epoch15, step2483]: loss 3.313272
[epoch15, step2484]: loss 6.830552
[epoch15, step2485]: loss 2.768505
[epoch15, step2486]: loss 12.806392
[epoch15, step2487]: loss 6.686739
[epoch15, step2488]: loss 1.497991
[epoch15, step2489]: loss 0.501362
[epoch15, step2490]: loss 1.139997
[epoch15, step2491]: loss 7.805867
[epoch15, step2492]: loss 1.218465
[epoch15, step2493]: loss 9.086430
[epoch15, step2494]: loss 4.583761
[epoch15, step2495]: loss 1.353245
[epoch15, step2496]: loss 4.692907
[epoch15, step2497]: loss 1.736509
[epoch15, step2498]: loss 1.424562
[epoch15, step2499]: loss 1.241776
[epoch15, step2500]: loss 2.207549
[epoch15, step2501]: loss 0.648347
[epoch15, step2502]: loss 8.902872
[epoch15, step2503]: loss 2.439689
[epoch15, step2504]: loss 1.526688
[epoch15, step2505]: loss 1.571395
[epoch15, step2506]: loss 0.744006
[epoch15, step2507]: loss 1.018834
[epoch15, step2508]: loss 1.399818
[epoch15, step2509]: loss 6.111900
[epoch15, step2510]: loss 3.215156
[epoch15, step2511]: loss 1.150463
[epoch15, step2512]: loss 1.080987
[epoch15, step2513]: loss 7.935899
[epoch15, step2514]: loss 3.345470
[epoch15, step2515]: loss 2.071182
[epoch15, step2516]: loss 10.034228
[epoch15, step2517]: loss 3.008718
[epoch15, step2518]: loss 1.129961
[epoch15, step2519]: loss 4.753728
[epoch15, step2520]: loss 7.140714
[epoch15, step2521]: loss 1.093310
[epoch15, step2522]: loss 11.158483
[epoch15, step2523]: loss 7.859849
[epoch15, step2524]: loss 1.296130
[epoch15, step2525]: loss 1.158118
[epoch15, step2526]: loss 1.808855
[epoch15, step2527]: loss 15.632187
[epoch15, step2528]: loss 9.862333
[epoch15, step2529]: loss 14.284557
[epoch15, step2530]: loss 4.090502
[epoch15, step2531]: loss 0.878650
[epoch15, step2532]: loss 0.692935
[epoch15, step2533]: loss 0.707096
[epoch15, step2534]: loss 12.221409
[epoch15, step2535]: loss 12.937377
[epoch15, step2536]: loss 1.275798
[epoch15, step2537]: loss 0.604803
[epoch15, step2538]: loss 0.932856
[epoch15, step2539]: loss 1.994759
[epoch15, step2540]: loss 1.283150
[epoch15, step2541]: loss 2.755738
[epoch15, step2542]: loss 2.015695
[epoch15, step2543]: loss 6.889558
[epoch15, step2544]: loss 2.849526
[epoch15, step2545]: loss 2.915138
[epoch15, step2546]: loss 2.136237
[epoch15, step2547]: loss 1.703574
[epoch15, step2548]: loss 19.474413
[epoch15, step2549]: loss 4.599657
[epoch15, step2550]: loss 5.805713
[epoch15, step2551]: loss 0.875300
[epoch15, step2552]: loss 1.764841
[epoch15, step2553]: loss 0.912036
[epoch15, step2554]: loss 1.097285
[epoch15, step2555]: loss 2.906804
[epoch15, step2556]: loss 1.325431
[epoch15, step2557]: loss 1.127799
[epoch15, step2558]: loss 13.001925
[epoch15, step2559]: loss 2.679883
[epoch15, step2560]: loss 2.337510
[epoch15, step2561]: loss 1.417902
[epoch15, step2562]: loss 9.053125
[epoch15, step2563]: loss 1.863404
[epoch15, step2564]: loss 0.729487
[epoch15, step2565]: loss 1.520298
[epoch15, step2566]: loss 0.952846
[epoch15, step2567]: loss 1.266867
[epoch15, step2568]: loss 0.721480
[epoch15, step2569]: loss 2.815272
[epoch15, step2570]: loss 1.370311
[epoch15, step2571]: loss 1.108466
[epoch15, step2572]: loss 2.526640
[epoch15, step2573]: loss 6.326993
[epoch15, step2574]: loss 1.754308
[epoch15, step2575]: loss 1.313135
[epoch15, step2576]: loss 1.320031
[epoch15, step2577]: loss 1.344301
[epoch15, step2578]: loss 1.392329
[epoch15, step2579]: loss 16.899986
[epoch15, step2580]: loss 4.457047
[epoch15, step2581]: loss 7.953945
[epoch15, step2582]: loss 9.482594
[epoch15, step2583]: loss 1.477609
[epoch15, step2584]: loss 3.573469
[epoch15, step2585]: loss 0.502164
[epoch15, step2586]: loss 7.118995
[epoch15, step2587]: loss 0.949912
[epoch15, step2588]: loss 0.872335
[epoch15, step2589]: loss 0.926817
[epoch15, step2590]: loss 2.498224
[epoch15, step2591]: loss 9.873634
[epoch15, step2592]: loss 1.364068
[epoch15, step2593]: loss 0.770890
[epoch15, step2594]: loss 1.109872
[epoch15, step2595]: loss 1.621469
[epoch15, step2596]: loss 1.237357
[epoch15, step2597]: loss 0.848345
[epoch15, step2598]: loss 0.868630
[epoch15, step2599]: loss 9.875746
[epoch15, step2600]: loss 1.747559
[epoch15, step2601]: loss 1.446604
[epoch15, step2602]: loss 4.642087
[epoch15, step2603]: loss 8.022497
[epoch15, step2604]: loss 1.314691
[epoch15, step2605]: loss 1.054112
[epoch15, step2606]: loss 6.147245
[epoch15, step2607]: loss 0.678688
[epoch15, step2608]: loss 2.233491
[epoch15, step2609]: loss 1.611455
[epoch15, step2610]: loss 1.338678
[epoch15, step2611]: loss 0.936274
[epoch15, step2612]: loss 8.586417
[epoch15, step2613]: loss 1.524697
[epoch15, step2614]: loss 2.241445
[epoch15, step2615]: loss 2.051028
[epoch15, step2616]: loss 3.480840
[epoch15, step2617]: loss 1.358380
[epoch15, step2618]: loss 2.292034
[epoch15, step2619]: loss 5.336738
[epoch15, step2620]: loss 10.085608
[epoch15, step2621]: loss 1.641726
[epoch15, step2622]: loss 18.567625
[epoch15, step2623]: loss 1.121601
[epoch15, step2624]: loss 1.919245
[epoch15, step2625]: loss 2.805792
[epoch15, step2626]: loss 1.079071
[epoch15, step2627]: loss 0.861854
[epoch15, step2628]: loss 1.307334
[epoch15, step2629]: loss 0.951783
[epoch15, step2630]: loss 1.696521
[epoch15, step2631]: loss 1.796911
[epoch15, step2632]: loss 7.065323
[epoch15, step2633]: loss 12.440134
[epoch15, step2634]: loss 1.114658
[epoch15, step2635]: loss 0.904211
[epoch15, step2636]: loss 16.343126
[epoch15, step2637]: loss 2.106931
[epoch15, step2638]: loss 6.129268
[epoch15, step2639]: loss 9.598557
[epoch15, step2640]: loss 4.008074
[epoch15, step2641]: loss 1.541777
[epoch15, step2642]: loss 6.335621
[epoch15, step2643]: loss 0.775827
[epoch15, step2644]: loss 1.344609
[epoch15, step2645]: loss 1.123370
[epoch15, step2646]: loss 1.187809
[epoch15, step2647]: loss 8.477766
[epoch15, step2648]: loss 0.534216
[epoch15, step2649]: loss 1.715811
[epoch15, step2650]: loss 1.071183
[epoch15, step2651]: loss 3.689157
[epoch15, step2652]: loss 6.591864
[epoch15, step2653]: loss 0.627392
[epoch15, step2654]: loss 3.874738
[epoch15, step2655]: loss 1.291779
[epoch15, step2656]: loss 1.698043
[epoch15, step2657]: loss 13.055808
[epoch15, step2658]: loss 1.100371
[epoch15, step2659]: loss 5.339496
[epoch15, step2660]: loss 1.308429
[epoch15, step2661]: loss 1.651394
[epoch15, step2662]: loss 10.104028
[epoch15, step2663]: loss 7.172830
[epoch15, step2664]: loss 15.914465
[epoch15, step2665]: loss 1.200459
[epoch15, step2666]: loss 2.153580
[epoch15, step2667]: loss 0.987614
[epoch15, step2668]: loss 1.013119
[epoch15, step2669]: loss 0.810332
[epoch15, step2670]: loss 2.578131
[epoch15, step2671]: loss 4.460804
[epoch15, step2672]: loss 0.825357
[epoch15, step2673]: loss 3.933239
[epoch15, step2674]: loss 5.982795
[epoch15, step2675]: loss 12.711524
[epoch15, step2676]: loss 5.700775
[epoch15, step2677]: loss 1.622230
[epoch15, step2678]: loss 1.127434
[epoch15, step2679]: loss 1.613629
[epoch15, step2680]: loss 12.761309
[epoch15, step2681]: loss 2.423060
[epoch15, step2682]: loss 2.388267
[epoch15, step2683]: loss 1.764869
[epoch15, step2684]: loss 5.639372
[epoch15, step2685]: loss 1.515460
[epoch15, step2686]: loss 1.756060
[epoch15, step2687]: loss 5.040060
[epoch15, step2688]: loss 2.078522
[epoch15, step2689]: loss 2.715289
[epoch15, step2690]: loss 2.089310
[epoch15, step2691]: loss 1.327619
[epoch15, step2692]: loss 1.099453
[epoch15, step2693]: loss 1.086966
[epoch15, step2694]: loss 0.635188
[epoch15, step2695]: loss 0.773638
[epoch15, step2696]: loss 14.553667
[epoch15, step2697]: loss 1.262996
[epoch15, step2698]: loss 1.346807
[epoch15, step2699]: loss 3.335886
[epoch15, step2700]: loss 1.176748
[epoch15, step2701]: loss 1.039808
[epoch15, step2702]: loss 1.000538
[epoch15, step2703]: loss 1.533524
[epoch15, step2704]: loss 1.734193
[epoch15, step2705]: loss 0.888812
[epoch15, step2706]: loss 1.332424
[epoch15, step2707]: loss 3.711988
[epoch15, step2708]: loss 2.369898
[epoch15, step2709]: loss 2.126941
[epoch15, step2710]: loss 0.643145
[epoch15, step2711]: loss 1.322369
[epoch15, step2712]: loss 1.868314
[epoch15, step2713]: loss 0.655772
[epoch15, step2714]: loss 0.579037
[epoch15, step2715]: loss 3.236063
[epoch15, step2716]: loss 0.579103
[epoch15, step2717]: loss 2.744629
[epoch15, step2718]: loss 3.531826
[epoch15, step2719]: loss 0.975832
[epoch15, step2720]: loss 0.841740
[epoch15, step2721]: loss 59.406410
[epoch15, step2722]: loss 1.678072
[epoch15, step2723]: loss 0.856211
[epoch15, step2724]: loss 2.338728
[epoch15, step2725]: loss 1.379815
[epoch15, step2726]: loss 2.719599
[epoch15, step2727]: loss 1.080073
[epoch15, step2728]: loss 0.855772
[epoch15, step2729]: loss 0.801019
[epoch15, step2730]: loss 0.880243
[epoch15, step2731]: loss 9.511036
[epoch15, step2732]: loss 1.467042
[epoch15, step2733]: loss 2.439095
[epoch15, step2734]: loss 2.621154
[epoch15, step2735]: loss 1.971354
[epoch15, step2736]: loss 3.264486
[epoch15, step2737]: loss 2.484002
[epoch15, step2738]: loss 14.227464
[epoch15, step2739]: loss 2.697321
[epoch15, step2740]: loss 1.515761
[epoch15, step2741]: loss 1.101664
[epoch15, step2742]: loss 3.385363
[epoch15, step2743]: loss 1.151391
[epoch15, step2744]: loss 10.295778
[epoch15, step2745]: loss 0.942891
[epoch15, step2746]: loss 1.072434
[epoch15, step2747]: loss 14.138950
[epoch15, step2748]: loss 1.927273
[epoch15, step2749]: loss 0.801184
[epoch15, step2750]: loss 0.970401
[epoch15, step2751]: loss 1.119400
[epoch15, step2752]: loss 28.593039
[epoch15, step2753]: loss 2.157387
[epoch15, step2754]: loss 4.397908
[epoch15, step2755]: loss 12.312850
[epoch15, step2756]: loss 1.012357
[epoch15, step2757]: loss 2.509831
[epoch15, step2758]: loss 8.910744
[epoch15, step2759]: loss 3.212027
[epoch15, step2760]: loss 8.584249
[epoch15, step2761]: loss 3.517253
[epoch15, step2762]: loss 11.551087
[epoch15, step2763]: loss 0.612931
[epoch15, step2764]: loss 6.431980
[epoch15, step2765]: loss 2.545304
[epoch15, step2766]: loss 21.816986
[epoch15, step2767]: loss 11.378240
[epoch15, step2768]: loss 5.072589
[epoch15, step2769]: loss 1.249346
[epoch15, step2770]: loss 6.544628
[epoch15, step2771]: loss 0.949583
[epoch15, step2772]: loss 1.233323
[epoch15, step2773]: loss 2.473475
[epoch15, step2774]: loss 1.568776
[epoch15, step2775]: loss 5.839537
[epoch15, step2776]: loss 3.405858
[epoch15, step2777]: loss 0.515439
[epoch15, step2778]: loss 7.178030
[epoch15, step2779]: loss 15.020649
[epoch15, step2780]: loss 1.615542
[epoch15, step2781]: loss 1.178898
[epoch15, step2782]: loss 2.601959
[epoch15, step2783]: loss 19.870148
[epoch15, step2784]: loss 2.062552
[epoch15, step2785]: loss 16.156631
[epoch15, step2786]: loss 2.310480
[epoch15, step2787]: loss 14.947630
[epoch15, step2788]: loss 0.931518
[epoch15, step2789]: loss 9.347326
[epoch15, step2790]: loss 1.423869
[epoch15, step2791]: loss 11.545103
[epoch15, step2792]: loss 1.191535
[epoch15, step2793]: loss 1.378347
[epoch15, step2794]: loss 2.465531
[epoch15, step2795]: loss 1.154302
[epoch15, step2796]: loss 7.733281
[epoch15, step2797]: loss 8.107646
[epoch15, step2798]: loss 9.126067
[epoch15, step2799]: loss 1.171309
[epoch15, step2800]: loss 1.602403
[epoch15, step2801]: loss 2.716635
[epoch15, step2802]: loss 3.152824
[epoch15, step2803]: loss 2.746014
[epoch15, step2804]: loss 0.860377
[epoch15, step2805]: loss 5.939296
[epoch15, step2806]: loss 3.388095
[epoch15, step2807]: loss 4.419276
[epoch15, step2808]: loss 3.994982
[epoch15, step2809]: loss 1.760561
[epoch15, step2810]: loss 3.009780
[epoch15, step2811]: loss 2.885067
[epoch15, step2812]: loss 1.411775
[epoch15, step2813]: loss 8.279142
[epoch15, step2814]: loss 1.116288
[epoch15, step2815]: loss 2.563647
[epoch15, step2816]: loss 0.761214
[epoch15, step2817]: loss 3.118146
[epoch15, step2818]: loss 1.561984
[epoch15, step2819]: loss 2.557598
[epoch15, step2820]: loss 7.601791
[epoch15, step2821]: loss 6.062600
[epoch15, step2822]: loss 1.895777
[epoch15, step2823]: loss 1.205804
[epoch15, step2824]: loss 10.528636
[epoch15, step2825]: loss 14.277963
[epoch15, step2826]: loss 1.419785
[epoch15, step2827]: loss 6.774889
[epoch15, step2828]: loss 4.289134
[epoch15, step2829]: loss 18.240459
[epoch15, step2830]: loss 1.732439
[epoch15, step2831]: loss 0.994347
[epoch15, step2832]: loss 0.637839
[epoch15, step2833]: loss 1.812020
[epoch15, step2834]: loss 0.790869
[epoch15, step2835]: loss 1.816370
[epoch15, step2836]: loss 1.877778
[epoch15, step2837]: loss 1.046540
[epoch15, step2838]: loss 9.813992
[epoch15, step2839]: loss 1.104435
[epoch15, step2840]: loss 1.060215
[epoch15, step2841]: loss 1.012636
[epoch15, step2842]: loss 2.394614
[epoch15, step2843]: loss 1.429557
[epoch15, step2844]: loss 7.663002
[epoch15, step2845]: loss 0.837729
[epoch15, step2846]: loss 0.891466
[epoch15, step2847]: loss 1.107351
[epoch15, step2848]: loss 8.411142
[epoch15, step2849]: loss 2.399333
[epoch15, step2850]: loss 1.829894
[epoch15, step2851]: loss 3.265455
[epoch15, step2852]: loss 14.711785
[epoch15, step2853]: loss 13.040632
[epoch15, step2854]: loss 8.852796
[epoch15, step2855]: loss 1.695108
[epoch15, step2856]: loss 2.034192
[epoch15, step2857]: loss 3.135221
[epoch15, step2858]: loss 5.463855
[epoch15, step2859]: loss 3.549659
[epoch15, step2860]: loss 7.251646
[epoch15, step2861]: loss 1.692770
[epoch15, step2862]: loss 0.629648
[epoch15, step2863]: loss 2.586506
[epoch15, step2864]: loss 3.383740
[epoch15, step2865]: loss 0.865387
[epoch15, step2866]: loss 1.998799
[epoch15, step2867]: loss 0.878667
[epoch15, step2868]: loss 1.975512
[epoch15, step2869]: loss 10.046141
[epoch15, step2870]: loss 1.082349
[epoch15, step2871]: loss 1.583922
[epoch15, step2872]: loss 1.258452
[epoch15, step2873]: loss 8.443555
[epoch15, step2874]: loss 1.899441
[epoch15, step2875]: loss 9.839284
[epoch15, step2876]: loss 3.564094
[epoch15, step2877]: loss 6.762096
[epoch15, step2878]: loss 2.003970
[epoch15, step2879]: loss 15.003309
[epoch15, step2880]: loss 1.510151
[epoch15, step2881]: loss 0.615829
[epoch15, step2882]: loss 0.849389
[epoch15, step2883]: loss 0.841102
[epoch15, step2884]: loss 0.891475
[epoch15, step2885]: loss 2.873416
[epoch15, step2886]: loss 1.867310
[epoch15, step2887]: loss 1.285435
[epoch15, step2888]: loss 3.923569
[epoch15, step2889]: loss 0.883585
[epoch15, step2890]: loss 1.201946
[epoch15, step2891]: loss 2.600748
[epoch15, step2892]: loss 0.900921
[epoch15, step2893]: loss 18.479652
[epoch15, step2894]: loss 13.168501
[epoch15, step2895]: loss 4.916123
[epoch15, step2896]: loss 2.622349
[epoch15, step2897]: loss 1.247650
[epoch15, step2898]: loss 0.912171
[epoch15, step2899]: loss 0.828971
[epoch15, step2900]: loss 0.850111
[epoch15, step2901]: loss 5.141807
[epoch15, step2902]: loss 2.984308
[epoch15, step2903]: loss 6.970429
[epoch15, step2904]: loss 6.553284
[epoch15, step2905]: loss 3.622359
[epoch15, step2906]: loss 1.702917
[epoch15, step2907]: loss 1.098322
[epoch15, step2908]: loss 4.906594
[epoch15, step2909]: loss 0.827203
[epoch15, step2910]: loss 1.016055
[epoch15, step2911]: loss 21.758001
[epoch15, step2912]: loss 2.022292
[epoch15, step2913]: loss 10.637152
[epoch15, step2914]: loss 1.777438
[epoch15, step2915]: loss 5.496683
[epoch15, step2916]: loss 8.277171
[epoch15, step2917]: loss 0.904814
[epoch15, step2918]: loss 1.240202
[epoch15, step2919]: loss 13.368266
[epoch15, step2920]: loss 2.082430
[epoch15, step2921]: loss 1.207572
[epoch15, step2922]: loss 1.031705
[epoch15, step2923]: loss 4.329970
[epoch15, step2924]: loss 2.571749
[epoch15, step2925]: loss 19.927402
[epoch15, step2926]: loss 0.786453
[epoch15, step2927]: loss 12.691056
[epoch15, step2928]: loss 9.780237
[epoch15, step2929]: loss 0.901256
[epoch15, step2930]: loss 1.979396
[epoch15, step2931]: loss 1.218109
[epoch15, step2932]: loss 8.527758
[epoch15, step2933]: loss 0.996387
[epoch15, step2934]: loss 3.122185
[epoch15, step2935]: loss 16.873779
[epoch15, step2936]: loss 0.949713
[epoch15, step2937]: loss 1.762094
[epoch15, step2938]: loss 4.094923
[epoch15, step2939]: loss 1.177419
[epoch15, step2940]: loss 2.187689
[epoch15, step2941]: loss 2.374786
[epoch15, step2942]: loss 3.188644
[epoch15, step2943]: loss 1.161371
[epoch15, step2944]: loss 2.585544
[epoch15, step2945]: loss 1.057595
[epoch15, step2946]: loss 0.901426
[epoch15, step2947]: loss 1.785400
[epoch15, step2948]: loss 17.941950
[epoch15, step2949]: loss 0.986724
[epoch15, step2950]: loss 0.664360
[epoch15, step2951]: loss 8.700373
[epoch15, step2952]: loss 4.600546
[epoch15, step2953]: loss 5.075474
[epoch15, step2954]: loss 1.069169
[epoch15, step2955]: loss 1.439910
[epoch15, step2956]: loss 1.497735
[epoch15, step2957]: loss 1.081201
[epoch15, step2958]: loss 15.367449
[epoch15, step2959]: loss 0.788217
[epoch15, step2960]: loss 0.787503
[epoch15, step2961]: loss 9.831055
[epoch15, step2962]: loss 4.060783
[epoch15, step2963]: loss 3.155869
[epoch15, step2964]: loss 2.150943
[epoch15, step2965]: loss 2.118618
[epoch15, step2966]: loss 3.081622
[epoch15, step2967]: loss 17.667118
[epoch15, step2968]: loss 0.710093
[epoch15, step2969]: loss 1.894522
[epoch15, step2970]: loss 13.788833
[epoch15, step2971]: loss 13.816946
[epoch15, step2972]: loss 0.750631
[epoch15, step2973]: loss 2.432232
[epoch15, step2974]: loss 1.356436
[epoch15, step2975]: loss 2.453000
[epoch15, step2976]: loss 23.219784
[epoch15, step2977]: loss 0.804393
[epoch15, step2978]: loss 2.222878
[epoch15, step2979]: loss 1.890995
[epoch15, step2980]: loss 2.537917
[epoch15, step2981]: loss 0.910451
[epoch15, step2982]: loss 1.423804
[epoch15, step2983]: loss 17.359028
[epoch15, step2984]: loss 4.361896
[epoch15, step2985]: loss 1.291445
[epoch15, step2986]: loss 1.056490
[epoch15, step2987]: loss 2.822310
[epoch15, step2988]: loss 1.626338
[epoch15, step2989]: loss 2.332649
[epoch15, step2990]: loss 12.949292
[epoch15, step2991]: loss 3.183737
[epoch15, step2992]: loss 12.550487
[epoch15, step2993]: loss 12.241489
[epoch15, step2994]: loss 0.928120
[epoch15, step2995]: loss 1.505059
[epoch15, step2996]: loss 6.951078
[epoch15, step2997]: loss 1.248782
[epoch15, step2998]: loss 1.580668
[epoch15, step2999]: loss 1.147841
[epoch15, step3000]: loss 1.597860
[epoch15, step3001]: loss 0.656113
[epoch15, step3002]: loss 1.236384
[epoch15, step3003]: loss 1.642666
[epoch15, step3004]: loss 2.022612
[epoch15, step3005]: loss 2.674149
[epoch15, step3006]: loss 6.634010
[epoch15, step3007]: loss 0.857817
[epoch15, step3008]: loss 1.831316
[epoch15, step3009]: loss 2.782310
[epoch15, step3010]: loss 10.317401
[epoch15, step3011]: loss 1.308811
[epoch15, step3012]: loss 0.919464
[epoch15, step3013]: loss 1.645000
[epoch15, step3014]: loss 1.912329
[epoch15, step3015]: loss 8.944294
[epoch15, step3016]: loss 0.903825
[epoch15, step3017]: loss 2.003614
[epoch15, step3018]: loss 0.959869
[epoch15, step3019]: loss 1.164256
[epoch15, step3020]: loss 1.179932
[epoch15, step3021]: loss 5.987304
[epoch15, step3022]: loss 1.669888
[epoch15, step3023]: loss 2.862847
[epoch15, step3024]: loss 1.560501
[epoch15, step3025]: loss 1.070133
[epoch15, step3026]: loss 1.421137
[epoch15, step3027]: loss 1.520411
[epoch15, step3028]: loss 1.037925
[epoch15, step3029]: loss 1.083264
[epoch15, step3030]: loss 13.548006
[epoch15, step3031]: loss 6.967174
[epoch15, step3032]: loss 1.164207
[epoch15, step3033]: loss 1.013631
[epoch15, step3034]: loss 5.052823
[epoch15, step3035]: loss 0.733920
[epoch15, step3036]: loss 9.653776
[epoch15, step3037]: loss 6.118355
[epoch15, step3038]: loss 2.965794
[epoch15, step3039]: loss 14.216418
[epoch15, step3040]: loss 1.195468
[epoch15, step3041]: loss 1.266161
[epoch15, step3042]: loss 1.427043
[epoch15, step3043]: loss 1.775031
[epoch15, step3044]: loss 4.324041
[epoch15, step3045]: loss 1.801829
[epoch15, step3046]: loss 1.610851
[epoch15, step3047]: loss 7.309031
[epoch15, step3048]: loss 0.766059
[epoch15, step3049]: loss 20.587944
[epoch15, step3050]: loss 1.925885
[epoch15, step3051]: loss 2.869201
[epoch15, step3052]: loss 2.566671
[epoch15, step3053]: loss 15.462523
[epoch15, step3054]: loss 1.414586
[epoch15, step3055]: loss 2.412901
[epoch15, step3056]: loss 1.618019
[epoch15, step3057]: loss 10.030661
[epoch15, step3058]: loss 1.906123
[epoch15, step3059]: loss 1.047994
[epoch15, step3060]: loss 1.002727
[epoch15, step3061]: loss 1.356711
[epoch15, step3062]: loss 1.959842
[epoch15, step3063]: loss 4.719881
[epoch15, step3064]: loss 13.469998
[epoch15, step3065]: loss 6.526157
[epoch15, step3066]: loss 7.556475
[epoch15, step3067]: loss 6.483615
[epoch15, step3068]: loss 2.169794
[epoch15, step3069]: loss 5.843606
[epoch15, step3070]: loss 9.686749
[epoch15, step3071]: loss 6.747979
[epoch15, step3072]: loss 2.695064
[epoch15, step3073]: loss 1.035837
[epoch15, step3074]: loss 1.899189
[epoch15, step3075]: loss 12.594032
[epoch15, step3076]: loss 4.038378

[epoch15]: avg loss 4.038378

[epoch16, step1]: loss 6.883969
[epoch16, step2]: loss 5.395657
[epoch16, step3]: loss 1.208236
[epoch16, step4]: loss 0.940105
[epoch16, step5]: loss 1.948679
[epoch16, step6]: loss 3.236298
[epoch16, step7]: loss 0.886378
[epoch16, step8]: loss 2.387901
[epoch16, step9]: loss 9.054068
[epoch16, step10]: loss 8.404946
[epoch16, step11]: loss 0.698645
[epoch16, step12]: loss 1.788193
[epoch16, step13]: loss 1.743227
[epoch16, step14]: loss 0.641334
[epoch16, step15]: loss 0.946212
[epoch16, step16]: loss 11.748755
[epoch16, step17]: loss 0.739611
[epoch16, step18]: loss 1.599271
[epoch16, step19]: loss 1.006449
[epoch16, step20]: loss 19.932434
[epoch16, step21]: loss 2.660158
[epoch16, step22]: loss 2.094383
[epoch16, step23]: loss 0.689394
[epoch16, step24]: loss 21.134247
[epoch16, step25]: loss 15.051902
[epoch16, step26]: loss 1.718098
[epoch16, step27]: loss 17.257542
[epoch16, step28]: loss 1.948292
[epoch16, step29]: loss 1.999632
[epoch16, step30]: loss 2.106654
[epoch16, step31]: loss 0.576468
[epoch16, step32]: loss 3.914007
[epoch16, step33]: loss 11.746369
[epoch16, step34]: loss 0.666280
[epoch16, step35]: loss 0.697347
[epoch16, step36]: loss 0.659114
[epoch16, step37]: loss 10.734365
[epoch16, step38]: loss 0.868303
[epoch16, step39]: loss 2.257870
[epoch16, step40]: loss 16.824787
[epoch16, step41]: loss 13.466910
[epoch16, step42]: loss 2.912942
[epoch16, step43]: loss 1.279786
[epoch16, step44]: loss 0.818406
[epoch16, step45]: loss 3.001002
[epoch16, step46]: loss 1.692115
[epoch16, step47]: loss 3.956558
[epoch16, step48]: loss 2.842180
[epoch16, step49]: loss 16.646875
[epoch16, step50]: loss 1.216527
[epoch16, step51]: loss 13.048988
[epoch16, step52]: loss 4.018350
[epoch16, step53]: loss 1.321252
[epoch16, step54]: loss 1.576715
[epoch16, step55]: loss 1.340784
[epoch16, step56]: loss 2.371172
[epoch16, step57]: loss 1.670788
[epoch16, step58]: loss 2.775184
[epoch16, step59]: loss 1.634749
[epoch16, step60]: loss 4.478621
[epoch16, step61]: loss 1.953028
[epoch16, step62]: loss 4.070544
[epoch16, step63]: loss 5.536345
[epoch16, step64]: loss 6.483360
[epoch16, step65]: loss 1.669039
[epoch16, step66]: loss 2.643940
[epoch16, step67]: loss 11.457799
[epoch16, step68]: loss 0.953298
[epoch16, step69]: loss 12.091462
[epoch16, step70]: loss 7.816837
[epoch16, step71]: loss 1.203562
[epoch16, step72]: loss 1.766062
[epoch16, step73]: loss 4.399688
[epoch16, step74]: loss 1.508140
[epoch16, step75]: loss 0.480366
[epoch16, step76]: loss 9.395967
[epoch16, step77]: loss 11.895541
[epoch16, step78]: loss 14.252584
[epoch16, step79]: loss 4.480685
[epoch16, step80]: loss 1.809193
[epoch16, step81]: loss 1.055994
[epoch16, step82]: loss 3.941031
[epoch16, step83]: loss 2.873988
[epoch16, step84]: loss 0.951578
[epoch16, step85]: loss 1.971890
[epoch16, step86]: loss 1.165721
[epoch16, step87]: loss 2.436801
[epoch16, step88]: loss 5.993658
[epoch16, step89]: loss 0.847809
[epoch16, step90]: loss 4.517229
[epoch16, step91]: loss 6.233377
[epoch16, step92]: loss 1.258991
[epoch16, step93]: loss 7.607853
[epoch16, step94]: loss 29.193005
[epoch16, step95]: loss 1.536756
[epoch16, step96]: loss 2.729693
[epoch16, step97]: loss 7.724645
[epoch16, step98]: loss 3.196088
[epoch16, step99]: loss 0.919852
[epoch16, step100]: loss 1.340353
[epoch16, step101]: loss 6.050372
[epoch16, step102]: loss 8.550061
[epoch16, step103]: loss 3.176246
[epoch16, step104]: loss 5.278206
[epoch16, step105]: loss 0.772123
[epoch16, step106]: loss 1.458222
[epoch16, step107]: loss 2.038265
[epoch16, step108]: loss 2.000397
[epoch16, step109]: loss 1.949206
[epoch16, step110]: loss 1.639295
[epoch16, step111]: loss 1.146549
[epoch16, step112]: loss 2.439663
[epoch16, step113]: loss 1.460783
[epoch16, step114]: loss 0.580577
[epoch16, step115]: loss 9.405336
[epoch16, step116]: loss 1.753454
[epoch16, step117]: loss 2.765670
[epoch16, step118]: loss 9.503850
[epoch16, step119]: loss 2.259919
[epoch16, step120]: loss 2.658989
[epoch16, step121]: loss 1.044798
[epoch16, step122]: loss 1.078346
[epoch16, step123]: loss 1.815413
[epoch16, step124]: loss 2.649317
[epoch16, step125]: loss 16.312450
[epoch16, step126]: loss 2.699749
[epoch16, step127]: loss 0.977118
[epoch16, step128]: loss 2.316879
[epoch16, step129]: loss 1.523852
[epoch16, step130]: loss 1.162798
[epoch16, step131]: loss 1.722002
[epoch16, step132]: loss 13.305705
[epoch16, step133]: loss 1.174925
[epoch16, step134]: loss 4.468747
[epoch16, step135]: loss 1.468328
[epoch16, step136]: loss 2.205691
[epoch16, step137]: loss 3.076169
[epoch16, step138]: loss 2.975802
[epoch16, step139]: loss 1.351339
[epoch16, step140]: loss 0.918225
[epoch16, step141]: loss 2.852615
[epoch16, step142]: loss 1.335737
[epoch16, step143]: loss 1.702479
[epoch16, step144]: loss 0.759204
[epoch16, step145]: loss 32.450562
[epoch16, step146]: loss 1.107930
[epoch16, step147]: loss 6.219467
[epoch16, step148]: loss 14.639729
[epoch16, step149]: loss 0.931652
[epoch16, step150]: loss 1.700623
[epoch16, step151]: loss 13.516445
[epoch16, step152]: loss 1.084317
[epoch16, step153]: loss 9.090103
[epoch16, step154]: loss 1.100885
[epoch16, step155]: loss 1.313230
[epoch16, step156]: loss 3.500350
[epoch16, step157]: loss 1.822808
[epoch16, step158]: loss 0.644357
[epoch16, step159]: loss 9.695592
[epoch16, step160]: loss 2.408976
[epoch16, step161]: loss 0.758127
[epoch16, step162]: loss 6.362125
[epoch16, step163]: loss 1.218559
[epoch16, step164]: loss 2.122081
[epoch16, step165]: loss 1.310500
[epoch16, step166]: loss 8.000387
[epoch16, step167]: loss 12.470221
[epoch16, step168]: loss 2.726669
[epoch16, step169]: loss 0.854478
[epoch16, step170]: loss 12.039557
[epoch16, step171]: loss 1.558292
[epoch16, step172]: loss 6.336545
[epoch16, step173]: loss 1.917238
[epoch16, step174]: loss 2.722672
[epoch16, step175]: loss 1.067158
[epoch16, step176]: loss 1.208236
[epoch16, step177]: loss 0.909457
[epoch16, step178]: loss 2.624106
[epoch16, step179]: loss 1.202895
[epoch16, step180]: loss 0.759529
[epoch16, step181]: loss 2.517947
[epoch16, step182]: loss 2.102115
[epoch16, step183]: loss 1.308472
[epoch16, step184]: loss 2.170454
[epoch16, step185]: loss 8.162212
[epoch16, step186]: loss 1.157874
[epoch16, step187]: loss 4.636335
[epoch16, step188]: loss 1.222802
[epoch16, step189]: loss 18.535633
[epoch16, step190]: loss 2.063138
[epoch16, step191]: loss 1.405022
[epoch16, step192]: loss 1.306883
[epoch16, step193]: loss 12.496731
[epoch16, step194]: loss 11.310950
[epoch16, step195]: loss 1.760857
[epoch16, step196]: loss 1.389760
[epoch16, step197]: loss 2.026819
[epoch16, step198]: loss 16.516254
[epoch16, step199]: loss 1.226056
[epoch16, step200]: loss 1.257645
[epoch16, step201]: loss 1.631023
[epoch16, step202]: loss 1.442971
[epoch16, step203]: loss 1.140031
[epoch16, step204]: loss 5.264791
[epoch16, step205]: loss 14.436897
[epoch16, step206]: loss 5.173308
[epoch16, step207]: loss 0.665684
[epoch16, step208]: loss 6.963941
[epoch16, step209]: loss 1.017027
[epoch16, step210]: loss 1.086220
[epoch16, step211]: loss 15.440128
[epoch16, step212]: loss 4.893776
[epoch16, step213]: loss 1.849846
[epoch16, step214]: loss 1.156617
[epoch16, step215]: loss 1.425517
[epoch16, step216]: loss 2.084424
[epoch16, step217]: loss 4.704040
[epoch16, step218]: loss 2.176660
[epoch16, step219]: loss 1.119648
[epoch16, step220]: loss 9.783037
[epoch16, step221]: loss 9.155615
[epoch16, step222]: loss 1.206982
[epoch16, step223]: loss 2.501778
[epoch16, step224]: loss 1.400783
[epoch16, step225]: loss 1.830775
[epoch16, step226]: loss 1.755034
[epoch16, step227]: loss 1.589378
[epoch16, step228]: loss 1.240199
[epoch16, step229]: loss 1.912854
[epoch16, step230]: loss 7.197524
[epoch16, step231]: loss 0.849523
[epoch16, step232]: loss 1.177361
[epoch16, step233]: loss 1.025823
[epoch16, step234]: loss 2.053339
[epoch16, step235]: loss 16.846558
[epoch16, step236]: loss 2.990987
[epoch16, step237]: loss 1.073987
[epoch16, step238]: loss 0.783924
[epoch16, step239]: loss 7.853339
[epoch16, step240]: loss 0.996782
[epoch16, step241]: loss 1.013847
[epoch16, step242]: loss 1.616349
[epoch16, step243]: loss 0.528007
[epoch16, step244]: loss 1.566406
[epoch16, step245]: loss 3.059551
[epoch16, step246]: loss 1.697257
[epoch16, step247]: loss 2.544534
[epoch16, step248]: loss 2.303571
[epoch16, step249]: loss 11.972824
[epoch16, step250]: loss 2.310953
[epoch16, step251]: loss 1.145555
[epoch16, step252]: loss 1.404009
[epoch16, step253]: loss 2.665484
[epoch16, step254]: loss 14.786864
[epoch16, step255]: loss 1.791008
[epoch16, step256]: loss 0.960058
[epoch16, step257]: loss 8.668419
[epoch16, step258]: loss 0.759040
[epoch16, step259]: loss 1.116621
[epoch16, step260]: loss 28.359270
[epoch16, step261]: loss 0.564503
[epoch16, step262]: loss 1.228099
[epoch16, step263]: loss 1.552509
[epoch16, step264]: loss 7.392583
[epoch16, step265]: loss 2.941855
[epoch16, step266]: loss 2.395472
[epoch16, step267]: loss 1.120837
[epoch16, step268]: loss 6.173511
[epoch16, step269]: loss 3.347083
[epoch16, step270]: loss 9.519163
[epoch16, step271]: loss 1.169784
[epoch16, step272]: loss 2.701270
[epoch16, step273]: loss 0.710924
[epoch16, step274]: loss 3.522176
[epoch16, step275]: loss 1.027075
[epoch16, step276]: loss 1.574510
[epoch16, step277]: loss 8.427279
[epoch16, step278]: loss 2.634531
[epoch16, step279]: loss 1.076797
[epoch16, step280]: loss 0.484516
[epoch16, step281]: loss 1.060981
[epoch16, step282]: loss 1.767790
[epoch16, step283]: loss 3.025066
[epoch16, step284]: loss 0.935434
[epoch16, step285]: loss 1.669612
[epoch16, step286]: loss 1.858352
[epoch16, step287]: loss 1.674140
[epoch16, step288]: loss 1.644062
[epoch16, step289]: loss 1.733343
[epoch16, step290]: loss 4.571394
[epoch16, step291]: loss 1.272988
[epoch16, step292]: loss 1.733446
[epoch16, step293]: loss 4.889339
[epoch16, step294]: loss 7.806586
[epoch16, step295]: loss 15.937236
[epoch16, step296]: loss 1.149631
[epoch16, step297]: loss 5.569236
[epoch16, step298]: loss 3.119367
[epoch16, step299]: loss 3.020800
[epoch16, step300]: loss 11.886859
[epoch16, step301]: loss 1.382265
[epoch16, step302]: loss 2.895320
[epoch16, step303]: loss 1.088067
[epoch16, step304]: loss 0.625625
[epoch16, step305]: loss 4.819866
[epoch16, step306]: loss 2.301811
[epoch16, step307]: loss 16.014139
[epoch16, step308]: loss 0.829266
[epoch16, step309]: loss 0.933258
[epoch16, step310]: loss 5.480498
[epoch16, step311]: loss 1.070879
[epoch16, step312]: loss 0.812153
[epoch16, step313]: loss 12.827953
[epoch16, step314]: loss 4.211012
[epoch16, step315]: loss 8.972696
[epoch16, step316]: loss 1.679063
[epoch16, step317]: loss 10.482444
[epoch16, step318]: loss 0.857972
[epoch16, step319]: loss 8.555511
[epoch16, step320]: loss 1.256655
[epoch16, step321]: loss 2.507518
[epoch16, step322]: loss 0.915676
[epoch16, step323]: loss 1.633584
[epoch16, step324]: loss 0.758868
[epoch16, step325]: loss 1.816752
[epoch16, step326]: loss 3.813314
[epoch16, step327]: loss 0.778221
[epoch16, step328]: loss 1.550558
[epoch16, step329]: loss 0.697291
[epoch16, step330]: loss 0.686060
[epoch16, step331]: loss 10.462706
[epoch16, step332]: loss 1.386276
[epoch16, step333]: loss 13.118613
[epoch16, step334]: loss 7.192356
[epoch16, step335]: loss 0.753430
[epoch16, step336]: loss 2.042476
[epoch16, step337]: loss 11.002683
[epoch16, step338]: loss 10.060160
[epoch16, step339]: loss 1.348534
[epoch16, step340]: loss 1.720217
[epoch16, step341]: loss 1.578090
[epoch16, step342]: loss 2.721693
[epoch16, step343]: loss 0.850543
[epoch16, step344]: loss 1.318073
[epoch16, step345]: loss 1.927361
[epoch16, step346]: loss 1.750409
[epoch16, step347]: loss 1.281078
[epoch16, step348]: loss 9.346608
[epoch16, step349]: loss 2.108561
[epoch16, step350]: loss 2.997869
[epoch16, step351]: loss 1.782709
[epoch16, step352]: loss 6.170927
[epoch16, step353]: loss 1.382108
[epoch16, step354]: loss 0.586720
[epoch16, step355]: loss 0.899246
[epoch16, step356]: loss 1.512017
[epoch16, step357]: loss 4.524305
[epoch16, step358]: loss 6.520586
[epoch16, step359]: loss 11.388813
[epoch16, step360]: loss 1.400897
[epoch16, step361]: loss 0.680287
[epoch16, step362]: loss 8.800286
[epoch16, step363]: loss 4.774991
[epoch16, step364]: loss 10.444074
[epoch16, step365]: loss 6.874478
[epoch16, step366]: loss 16.055611
[epoch16, step367]: loss 1.282972
[epoch16, step368]: loss 4.198678
[epoch16, step369]: loss 2.470183
[epoch16, step370]: loss 4.311056
[epoch16, step371]: loss 5.520005
[epoch16, step372]: loss 1.665455
[epoch16, step373]: loss 1.545822
[epoch16, step374]: loss 12.404138
[epoch16, step375]: loss 3.326005
[epoch16, step376]: loss 2.465307
[epoch16, step377]: loss 3.340029
[epoch16, step378]: loss 1.815207
[epoch16, step379]: loss 6.903272
[epoch16, step380]: loss 1.797811
[epoch16, step381]: loss 0.707800
[epoch16, step382]: loss 3.357514
[epoch16, step383]: loss 4.026608
[epoch16, step384]: loss 5.019069
[epoch16, step385]: loss 14.444315
[epoch16, step386]: loss 2.118378
[epoch16, step387]: loss 1.491007
[epoch16, step388]: loss 1.969064
[epoch16, step389]: loss 0.847935
[epoch16, step390]: loss 9.311626
[epoch16, step391]: loss 4.087192
[epoch16, step392]: loss 1.891054
[epoch16, step393]: loss 10.254250
[epoch16, step394]: loss 1.260017
[epoch16, step395]: loss 1.883345
[epoch16, step396]: loss 0.635084
[epoch16, step397]: loss 1.302791
[epoch16, step398]: loss 2.287390
[epoch16, step399]: loss 0.624073
[epoch16, step400]: loss 2.790889
[epoch16, step401]: loss 12.367174
[epoch16, step402]: loss 1.441602
[epoch16, step403]: loss 2.484479
[epoch16, step404]: loss 2.416156
[epoch16, step405]: loss 2.617934
[epoch16, step406]: loss 6.995280
[epoch16, step407]: loss 6.249537
[epoch16, step408]: loss 0.647043
[epoch16, step409]: loss 1.265060
[epoch16, step410]: loss 1.579298
[epoch16, step411]: loss 1.818297
[epoch16, step412]: loss 11.983889
[epoch16, step413]: loss 1.879527
[epoch16, step414]: loss 4.124691
[epoch16, step415]: loss 1.067873
[epoch16, step416]: loss 1.046832
[epoch16, step417]: loss 0.730986
[epoch16, step418]: loss 1.644465
[epoch16, step419]: loss 4.222077
[epoch16, step420]: loss 0.798864
[epoch16, step421]: loss 1.168877
[epoch16, step422]: loss 0.901990
[epoch16, step423]: loss 15.558340
[epoch16, step424]: loss 1.147364
[epoch16, step425]: loss 1.528875
[epoch16, step426]: loss 3.010385
[epoch16, step427]: loss 3.098651
[epoch16, step428]: loss 13.466330
[epoch16, step429]: loss 2.391217
[epoch16, step430]: loss 0.677466
[epoch16, step431]: loss 1.466269
[epoch16, step432]: loss 4.189836
[epoch16, step433]: loss 10.069246
[epoch16, step434]: loss 1.195493
[epoch16, step435]: loss 0.917131
[epoch16, step436]: loss 1.201977
[epoch16, step437]: loss 4.737258
[epoch16, step438]: loss 3.044254
[epoch16, step439]: loss 2.795211
[epoch16, step440]: loss 3.159652
[epoch16, step441]: loss 1.195056
[epoch16, step442]: loss 1.291463
[epoch16, step443]: loss 0.643873
[epoch16, step444]: loss 0.934442
[epoch16, step445]: loss 2.540687
[epoch16, step446]: loss 1.972848
[epoch16, step447]: loss 1.331212
[epoch16, step448]: loss 9.406209
[epoch16, step449]: loss 1.007542
[epoch16, step450]: loss 9.901364
[epoch16, step451]: loss 0.918726
[epoch16, step452]: loss 0.554822
[epoch16, step453]: loss 5.830312
[epoch16, step454]: loss 2.612099
[epoch16, step455]: loss 0.939142
[epoch16, step456]: loss 0.587136
[epoch16, step457]: loss 8.931366
[epoch16, step458]: loss 4.360656
[epoch16, step459]: loss 2.495803
[epoch16, step460]: loss 6.749810
[epoch16, step461]: loss 1.353122
[epoch16, step462]: loss 5.579225
[epoch16, step463]: loss 1.669973
[epoch16, step464]: loss 9.040511
[epoch16, step465]: loss 5.180707
[epoch16, step466]: loss 0.915604
[epoch16, step467]: loss 8.531738
[epoch16, step468]: loss 15.114340
[epoch16, step469]: loss 10.932391
[epoch16, step470]: loss 1.373185
[epoch16, step471]: loss 0.829379
[epoch16, step472]: loss 7.996220
[epoch16, step473]: loss 0.773458
[epoch16, step474]: loss 5.303348
[epoch16, step475]: loss 11.458263
[epoch16, step476]: loss 1.359159
[epoch16, step477]: loss 7.615874
[epoch16, step478]: loss 0.907355
[epoch16, step479]: loss 1.433043
[epoch16, step480]: loss 7.041265
[epoch16, step481]: loss 1.935576
[epoch16, step482]: loss 1.953895
[epoch16, step483]: loss 0.689148
[epoch16, step484]: loss 1.708298
[epoch16, step485]: loss 9.645605
[epoch16, step486]: loss 13.453617
[epoch16, step487]: loss 3.624820
[epoch16, step488]: loss 1.454986
[epoch16, step489]: loss 1.942892
[epoch16, step490]: loss 17.722672
[epoch16, step491]: loss 2.171197
[epoch16, step492]: loss 2.375339
[epoch16, step493]: loss 1.725452
[epoch16, step494]: loss 1.994595
[epoch16, step495]: loss 1.026058
[epoch16, step496]: loss 2.795452
[epoch16, step497]: loss 5.856097
[epoch16, step498]: loss 2.626251
[epoch16, step499]: loss 1.293475
[epoch16, step500]: loss 1.292845
[epoch16, step501]: loss 1.907282
[epoch16, step502]: loss 23.523510
[epoch16, step503]: loss 1.442817
[epoch16, step504]: loss 1.238591
[epoch16, step505]: loss 2.451455
[epoch16, step506]: loss 1.111474
[epoch16, step507]: loss 1.466972
[epoch16, step508]: loss 2.259151
[epoch16, step509]: loss 1.162894
[epoch16, step510]: loss 1.166690
[epoch16, step511]: loss 1.034605
[epoch16, step512]: loss 11.337822
[epoch16, step513]: loss 1.551296
[epoch16, step514]: loss 1.244757
[epoch16, step515]: loss 2.474395
[epoch16, step516]: loss 16.509047
[epoch16, step517]: loss 0.892326
[epoch16, step518]: loss 1.618048
[epoch16, step519]: loss 1.308393
[epoch16, step520]: loss 8.467779
[epoch16, step521]: loss 3.396727
[epoch16, step522]: loss 0.579583
[epoch16, step523]: loss 1.418200
[epoch16, step524]: loss 6.640506
[epoch16, step525]: loss 0.511869
[epoch16, step526]: loss 0.972202
[epoch16, step527]: loss 1.149962
[epoch16, step528]: loss 0.773081
[epoch16, step529]: loss 31.323109
[epoch16, step530]: loss 1.104978
[epoch16, step531]: loss 1.575113
[epoch16, step532]: loss 3.705567
[epoch16, step533]: loss 1.836576
[epoch16, step534]: loss 7.393220
[epoch16, step535]: loss 0.854315
[epoch16, step536]: loss 1.101679
[epoch16, step537]: loss 2.489067
[epoch16, step538]: loss 1.095215
[epoch16, step539]: loss 1.111130
[epoch16, step540]: loss 4.172493
[epoch16, step541]: loss 2.670077
[epoch16, step542]: loss 2.061180
[epoch16, step543]: loss 23.770023
[epoch16, step544]: loss 1.192152
[epoch16, step545]: loss 15.774489
[epoch16, step546]: loss 11.973747
[epoch16, step547]: loss 1.024618
[epoch16, step548]: loss 1.422727
[epoch16, step549]: loss 2.639576
[epoch16, step550]: loss 5.267841
[epoch16, step551]: loss 8.098679
[epoch16, step552]: loss 0.618394
[epoch16, step553]: loss 1.899942
[epoch16, step554]: loss 0.807329
[epoch16, step555]: loss 1.026270
[epoch16, step556]: loss 8.000246
[epoch16, step557]: loss 1.462649
[epoch16, step558]: loss 27.122309
[epoch16, step559]: loss 0.823654
[epoch16, step560]: loss 0.958196
[epoch16, step561]: loss 30.000097
[epoch16, step562]: loss 2.650484
[epoch16, step563]: loss 7.122641
[epoch16, step564]: loss 0.872225
[epoch16, step565]: loss 9.304960
[epoch16, step566]: loss 5.634451
[epoch16, step567]: loss 9.549337
[epoch16, step568]: loss 0.762960
[epoch16, step569]: loss 1.645049
[epoch16, step570]: loss 1.984200
[epoch16, step571]: loss 0.728491
[epoch16, step572]: loss 2.873586
[epoch16, step573]: loss 0.958189
[epoch16, step574]: loss 8.408159
[epoch16, step575]: loss 2.448815
[epoch16, step576]: loss 2.319816
[epoch16, step577]: loss 1.614245
[epoch16, step578]: loss 11.774358
[epoch16, step579]: loss 0.934476
[epoch16, step580]: loss 1.872848
[epoch16, step581]: loss 1.394282
[epoch16, step582]: loss 1.371209
[epoch16, step583]: loss 9.173202
[epoch16, step584]: loss 0.850038
[epoch16, step585]: loss 0.881373
[epoch16, step586]: loss 5.318244
[epoch16, step587]: loss 1.118006
[epoch16, step588]: loss 5.193808
[epoch16, step589]: loss 1.774270
[epoch16, step590]: loss 4.015149
[epoch16, step591]: loss 0.638522
[epoch16, step592]: loss 2.165888
[epoch16, step593]: loss 1.078423
[epoch16, step594]: loss 3.588624
[epoch16, step595]: loss 24.621735
[epoch16, step596]: loss 3.471238
[epoch16, step597]: loss 3.014729
[epoch16, step598]: loss 4.512764
[epoch16, step599]: loss 12.235101
[epoch16, step600]: loss 0.588353
[epoch16, step601]: loss 6.336607
[epoch16, step602]: loss 0.737150
[epoch16, step603]: loss 0.711362
[epoch16, step604]: loss 1.963557
[epoch16, step605]: loss 1.046869
[epoch16, step606]: loss 1.510312
[epoch16, step607]: loss 0.899732
[epoch16, step608]: loss 14.289428
[epoch16, step609]: loss 2.331352
[epoch16, step610]: loss 3.384252
[epoch16, step611]: loss 3.565444
[epoch16, step612]: loss 5.016280
[epoch16, step613]: loss 0.764814
[epoch16, step614]: loss 2.475874
[epoch16, step615]: loss 5.181199
[epoch16, step616]: loss 0.957189
[epoch16, step617]: loss 5.725644
[epoch16, step618]: loss 1.496612
[epoch16, step619]: loss 1.521091
[epoch16, step620]: loss 2.287191
[epoch16, step621]: loss 2.276276
[epoch16, step622]: loss 0.897482
[epoch16, step623]: loss 7.270027
[epoch16, step624]: loss 0.849170
[epoch16, step625]: loss 23.479109
[epoch16, step626]: loss 7.822587
[epoch16, step627]: loss 6.526431
[epoch16, step628]: loss 1.130110
[epoch16, step629]: loss 0.661127
[epoch16, step630]: loss 12.491489
[epoch16, step631]: loss 1.641037
[epoch16, step632]: loss 15.718962
[epoch16, step633]: loss 2.812707
[epoch16, step634]: loss 1.186932
[epoch16, step635]: loss 2.166649
[epoch16, step636]: loss 5.210195
[epoch16, step637]: loss 1.550556
[epoch16, step638]: loss 3.538984
[epoch16, step639]: loss 6.723139
[epoch16, step640]: loss 12.983598
[epoch16, step641]: loss 1.791635
[epoch16, step642]: loss 1.392910
[epoch16, step643]: loss 18.042141
[epoch16, step644]: loss 1.736844
[epoch16, step645]: loss 1.826409
[epoch16, step646]: loss 8.098749
[epoch16, step647]: loss 1.074489
[epoch16, step648]: loss 1.603707
[epoch16, step649]: loss 2.443173
[epoch16, step650]: loss 1.009858
[epoch16, step651]: loss 2.623677
[epoch16, step652]: loss 1.370775
[epoch16, step653]: loss 10.117299
[epoch16, step654]: loss 7.071979
[epoch16, step655]: loss 5.240790
[epoch16, step656]: loss 1.125022
[epoch16, step657]: loss 6.677098
[epoch16, step658]: loss 28.612707
[epoch16, step659]: loss 0.905334
[epoch16, step660]: loss 12.792719
[epoch16, step661]: loss 0.932377
[epoch16, step662]: loss 0.918979
[epoch16, step663]: loss 9.522330
[epoch16, step664]: loss 0.642256
[epoch16, step665]: loss 1.108944
[epoch16, step666]: loss 12.827900
[epoch16, step667]: loss 1.359745
[epoch16, step668]: loss 3.304798
[epoch16, step669]: loss 7.007477
[epoch16, step670]: loss 1.610107
[epoch16, step671]: loss 0.779326
[epoch16, step672]: loss 1.884818
[epoch16, step673]: loss 3.030097
[epoch16, step674]: loss 1.390785
[epoch16, step675]: loss 1.316243
[epoch16, step676]: loss 0.615019
[epoch16, step677]: loss 0.594999
[epoch16, step678]: loss 0.597568
[epoch16, step679]: loss 0.937101
[epoch16, step680]: loss 1.658236
[epoch16, step681]: loss 15.674755
[epoch16, step682]: loss 6.532460
[epoch16, step683]: loss 0.733705
[epoch16, step684]: loss 1.385732
[epoch16, step685]: loss 7.671031
[epoch16, step686]: loss 3.047086
[epoch16, step687]: loss 5.110527
[epoch16, step688]: loss 2.249197
[epoch16, step689]: loss 4.308520
[epoch16, step690]: loss 4.537064
[epoch16, step691]: loss 2.869610
[epoch16, step692]: loss 2.586241
[epoch16, step693]: loss 2.899786
[epoch16, step694]: loss 0.897438
[epoch16, step695]: loss 1.893992
[epoch16, step696]: loss 2.769219
[epoch16, step697]: loss 1.058364
[epoch16, step698]: loss 8.608306
[epoch16, step699]: loss 4.360747
[epoch16, step700]: loss 10.775219
[epoch16, step701]: loss 1.396894
[epoch16, step702]: loss 1.258464
[epoch16, step703]: loss 0.566182
[epoch16, step704]: loss 1.111266
[epoch16, step705]: loss 21.267662
[epoch16, step706]: loss 0.977508
[epoch16, step707]: loss 1.262656
[epoch16, step708]: loss 1.161984
[epoch16, step709]: loss 4.725994
[epoch16, step710]: loss 6.086713
[epoch16, step711]: loss 0.804448
[epoch16, step712]: loss 1.201668
[epoch16, step713]: loss 2.548837
[epoch16, step714]: loss 5.517731
[epoch16, step715]: loss 12.076654
[epoch16, step716]: loss 2.639864
[epoch16, step717]: loss 2.827299
[epoch16, step718]: loss 2.894465
[epoch16, step719]: loss 2.121332
[epoch16, step720]: loss 1.157645
[epoch16, step721]: loss 1.192284
[epoch16, step722]: loss 1.546441
[epoch16, step723]: loss 0.476434
[epoch16, step724]: loss 10.338039
[epoch16, step725]: loss 2.242851
[epoch16, step726]: loss 5.498922
[epoch16, step727]: loss 0.700653
[epoch16, step728]: loss 2.396421
[epoch16, step729]: loss 2.094401
[epoch16, step730]: loss 3.654416
[epoch16, step731]: loss 0.541428
[epoch16, step732]: loss 2.332043
[epoch16, step733]: loss 3.397422
[epoch16, step734]: loss 1.910246
[epoch16, step735]: loss 2.029082
[epoch16, step736]: loss 8.928745
[epoch16, step737]: loss 3.048016
[epoch16, step738]: loss 3.816933
[epoch16, step739]: loss 12.470663
[epoch16, step740]: loss 2.792120
[epoch16, step741]: loss 2.357143
[epoch16, step742]: loss 0.571386
[epoch16, step743]: loss 1.133022
[epoch16, step744]: loss 1.573060
[epoch16, step745]: loss 9.401844
[epoch16, step746]: loss 2.276329
[epoch16, step747]: loss 7.612296
[epoch16, step748]: loss 2.231008
[epoch16, step749]: loss 7.656155
[epoch16, step750]: loss 2.441044
[epoch16, step751]: loss 9.764804
[epoch16, step752]: loss 1.551502
[epoch16, step753]: loss 1.236328
[epoch16, step754]: loss 1.304933
[epoch16, step755]: loss 1.229049
[epoch16, step756]: loss 3.146491
[epoch16, step757]: loss 0.878836
[epoch16, step758]: loss 1.215559
[epoch16, step759]: loss 5.803351
[epoch16, step760]: loss 0.689907
[epoch16, step761]: loss 4.528906
[epoch16, step762]: loss 1.531926
[epoch16, step763]: loss 1.845072
[epoch16, step764]: loss 1.242925
[epoch16, step765]: loss 4.900566
[epoch16, step766]: loss 2.195189
[epoch16, step767]: loss 0.858906
[epoch16, step768]: loss 2.590801
[epoch16, step769]: loss 15.538064
[epoch16, step770]: loss 0.889820
[epoch16, step771]: loss 1.915229
[epoch16, step772]: loss 0.842942
[epoch16, step773]: loss 1.788844
[epoch16, step774]: loss 1.492462
[epoch16, step775]: loss 12.584345
[epoch16, step776]: loss 1.651631
[epoch16, step777]: loss 12.644493
[epoch16, step778]: loss 3.044584
[epoch16, step779]: loss 1.700253
[epoch16, step780]: loss 11.575400
[epoch16, step781]: loss 1.249908
[epoch16, step782]: loss 1.263147
[epoch16, step783]: loss 4.456923
[epoch16, step784]: loss 0.777976
[epoch16, step785]: loss 1.447365
[epoch16, step786]: loss 13.769974
[epoch16, step787]: loss 5.135118
[epoch16, step788]: loss 10.566155
[epoch16, step789]: loss 1.033103
[epoch16, step790]: loss 9.324019
[epoch16, step791]: loss 8.605035
[epoch16, step792]: loss 12.146044
[epoch16, step793]: loss 0.564159
[epoch16, step794]: loss 8.370774
[epoch16, step795]: loss 13.492187
[epoch16, step796]: loss 1.744630
[epoch16, step797]: loss 7.412246
[epoch16, step798]: loss 1.225765
[epoch16, step799]: loss 0.866929
[epoch16, step800]: loss 2.753078
[epoch16, step801]: loss 1.223849
[epoch16, step802]: loss 7.493228
[epoch16, step803]: loss 1.794890
[epoch16, step804]: loss 16.340416
[epoch16, step805]: loss 0.880712
[epoch16, step806]: loss 1.215929
[epoch16, step807]: loss 16.694815
[epoch16, step808]: loss 0.768038
[epoch16, step809]: loss 1.126715
[epoch16, step810]: loss 0.838031
[epoch16, step811]: loss 2.584897
[epoch16, step812]: loss 8.173180
[epoch16, step813]: loss 25.227570
[epoch16, step814]: loss 6.011056
[epoch16, step815]: loss 0.905783
[epoch16, step816]: loss 1.788705
[epoch16, step817]: loss 4.817776
[epoch16, step818]: loss 4.740500
[epoch16, step819]: loss 4.531040
[epoch16, step820]: loss 1.496719
[epoch16, step821]: loss 13.670715
[epoch16, step822]: loss 1.334153
[epoch16, step823]: loss 1.327992
[epoch16, step824]: loss 1.263255
[epoch16, step825]: loss 1.527495
[epoch16, step826]: loss 3.006725
[epoch16, step827]: loss 2.183833
[epoch16, step828]: loss 2.179565
[epoch16, step829]: loss 13.648034
[epoch16, step830]: loss 3.895714
[epoch16, step831]: loss 6.163524
[epoch16, step832]: loss 2.123955
[epoch16, step833]: loss 1.968134
[epoch16, step834]: loss 1.741474
[epoch16, step835]: loss 1.332147
[epoch16, step836]: loss 1.336509
[epoch16, step837]: loss 9.390007
[epoch16, step838]: loss 1.981845
[epoch16, step839]: loss 2.975455
[epoch16, step840]: loss 6.473341
[epoch16, step841]: loss 30.772057
[epoch16, step842]: loss 1.578393
[epoch16, step843]: loss 0.742507
[epoch16, step844]: loss 23.946476
[epoch16, step845]: loss 1.579015
[epoch16, step846]: loss 1.135612
[epoch16, step847]: loss 7.128051
[epoch16, step848]: loss 1.131638
[epoch16, step849]: loss 7.121680
[epoch16, step850]: loss 1.105888
[epoch16, step851]: loss 1.820628
[epoch16, step852]: loss 1.074236
[epoch16, step853]: loss 0.995800
[epoch16, step854]: loss 2.680348
[epoch16, step855]: loss 6.239966
[epoch16, step856]: loss 5.908342
[epoch16, step857]: loss 11.671739
[epoch16, step858]: loss 11.888909
[epoch16, step859]: loss 12.380655
[epoch16, step860]: loss 2.411437
[epoch16, step861]: loss 6.966855
[epoch16, step862]: loss 1.549008
[epoch16, step863]: loss 1.267132
[epoch16, step864]: loss 0.686591
[epoch16, step865]: loss 2.125044
[epoch16, step866]: loss 0.784385
[epoch16, step867]: loss 1.031669
[epoch16, step868]: loss 3.582408
[epoch16, step869]: loss 1.762297
[epoch16, step870]: loss 1.143832
[epoch16, step871]: loss 4.888148
[epoch16, step872]: loss 2.180388
[epoch16, step873]: loss 3.627688
[epoch16, step874]: loss 2.169085
[epoch16, step875]: loss 4.434765
[epoch16, step876]: loss 1.241634
[epoch16, step877]: loss 9.068995
[epoch16, step878]: loss 3.480008
[epoch16, step879]: loss 15.060472
[epoch16, step880]: loss 12.303822
[epoch16, step881]: loss 1.131462
[epoch16, step882]: loss 2.330749
[epoch16, step883]: loss 1.817975
[epoch16, step884]: loss 12.512506
[epoch16, step885]: loss 11.180780
[epoch16, step886]: loss 2.335201
[epoch16, step887]: loss 4.273792
[epoch16, step888]: loss 4.506184
[epoch16, step889]: loss 10.719866
[epoch16, step890]: loss 2.203660
[epoch16, step891]: loss 2.430078
[epoch16, step892]: loss 0.835560
[epoch16, step893]: loss 1.111019
[epoch16, step894]: loss 0.915363
[epoch16, step895]: loss 9.505219
[epoch16, step896]: loss 1.806472
[epoch16, step897]: loss 2.799188
[epoch16, step898]: loss 1.054496
[epoch16, step899]: loss 9.423948
[epoch16, step900]: loss 1.934680
[epoch16, step901]: loss 9.141891
[epoch16, step902]: loss 6.843421
[epoch16, step903]: loss 6.359398
[epoch16, step904]: loss 3.283029
[epoch16, step905]: loss 4.643832
[epoch16, step906]: loss 22.867861
[epoch16, step907]: loss 16.114723
[epoch16, step908]: loss 1.477473
[epoch16, step909]: loss 3.845069
[epoch16, step910]: loss 12.845974
[epoch16, step911]: loss 1.535617
[epoch16, step912]: loss 2.270774
[epoch16, step913]: loss 8.360813
[epoch16, step914]: loss 2.273062
[epoch16, step915]: loss 1.281694
[epoch16, step916]: loss 0.526779
[epoch16, step917]: loss 1.839206
[epoch16, step918]: loss 0.895960
[epoch16, step919]: loss 2.982533
[epoch16, step920]: loss 5.813258
[epoch16, step921]: loss 0.728497
[epoch16, step922]: loss 6.031122
[epoch16, step923]: loss 1.881925
[epoch16, step924]: loss 3.063150
[epoch16, step925]: loss 0.862864
[epoch16, step926]: loss 1.447161
[epoch16, step927]: loss 9.295763
[epoch16, step928]: loss 1.196738
[epoch16, step929]: loss 11.855244
[epoch16, step930]: loss 0.907910
[epoch16, step931]: loss 8.266013
[epoch16, step932]: loss 2.057091
[epoch16, step933]: loss 12.232323
[epoch16, step934]: loss 2.670887
[epoch16, step935]: loss 2.309181
[epoch16, step936]: loss 3.244830
[epoch16, step937]: loss 1.380847
[epoch16, step938]: loss 7.567404
[epoch16, step939]: loss 5.080335
[epoch16, step940]: loss 7.858733
[epoch16, step941]: loss 5.805218
[epoch16, step942]: loss 1.429449
[epoch16, step943]: loss 1.684428
[epoch16, step944]: loss 3.603812
[epoch16, step945]: loss 1.330035
[epoch16, step946]: loss 1.073899
[epoch16, step947]: loss 1.161710
[epoch16, step948]: loss 0.928691
[epoch16, step949]: loss 2.869184
[epoch16, step950]: loss 1.309597
[epoch16, step951]: loss 2.426644
[epoch16, step952]: loss 0.982895
[epoch16, step953]: loss 2.124461
[epoch16, step954]: loss 23.036188
[epoch16, step955]: loss 8.932703
[epoch16, step956]: loss 1.094487
[epoch16, step957]: loss 0.891101
[epoch16, step958]: loss 10.740920
[epoch16, step959]: loss 2.122911
[epoch16, step960]: loss 2.206042
[epoch16, step961]: loss 2.131528
[epoch16, step962]: loss 1.535054
[epoch16, step963]: loss 6.759456
[epoch16, step964]: loss 1.974608
[epoch16, step965]: loss 0.925106
[epoch16, step966]: loss 0.973439
[epoch16, step967]: loss 8.244179
[epoch16, step968]: loss 1.463335
[epoch16, step969]: loss 0.888253
[epoch16, step970]: loss 3.399078
[epoch16, step971]: loss 3.289964
[epoch16, step972]: loss 1.691438
[epoch16, step973]: loss 8.484429
[epoch16, step974]: loss 0.937821
[epoch16, step975]: loss 2.073336
[epoch16, step976]: loss 1.128340
[epoch16, step977]: loss 0.696923
[epoch16, step978]: loss 1.132149
[epoch16, step979]: loss 5.305394
[epoch16, step980]: loss 2.380787
[epoch16, step981]: loss 0.963212
[epoch16, step982]: loss 8.321369
[epoch16, step983]: loss 18.961830
[epoch16, step984]: loss 1.419710
[epoch16, step985]: loss 1.247336
[epoch16, step986]: loss 0.617029
[epoch16, step987]: loss 0.764136
[epoch16, step988]: loss 0.742853
[epoch16, step989]: loss 4.595768
[epoch16, step990]: loss 0.990606
[epoch16, step991]: loss 3.219364
[epoch16, step992]: loss 1.231612
[epoch16, step993]: loss 5.512191
[epoch16, step994]: loss 19.818445
[epoch16, step995]: loss 1.443330
[epoch16, step996]: loss 1.110062
[epoch16, step997]: loss 1.462940
[epoch16, step998]: loss 1.462419
[epoch16, step999]: loss 12.216024
[epoch16, step1000]: loss 4.748241
[epoch16, step1001]: loss 0.811641
[epoch16, step1002]: loss 2.244783
[epoch16, step1003]: loss 13.679350
[epoch16, step1004]: loss 4.088274
[epoch16, step1005]: loss 3.075247
[epoch16, step1006]: loss 1.503753
[epoch16, step1007]: loss 1.713501
[epoch16, step1008]: loss 1.622983
[epoch16, step1009]: loss 1.493702
[epoch16, step1010]: loss 1.685257
[epoch16, step1011]: loss 10.435621
[epoch16, step1012]: loss 0.564290
[epoch16, step1013]: loss 8.884259
[epoch16, step1014]: loss 1.019210
[epoch16, step1015]: loss 10.886267
[epoch16, step1016]: loss 0.996630
[epoch16, step1017]: loss 8.227447
[epoch16, step1018]: loss 8.992523
[epoch16, step1019]: loss 1.193144
[epoch16, step1020]: loss 1.025581
[epoch16, step1021]: loss 3.410352
[epoch16, step1022]: loss 11.307355
[epoch16, step1023]: loss 11.037290
[epoch16, step1024]: loss 2.576605
[epoch16, step1025]: loss 0.781896
[epoch16, step1026]: loss 0.948789
[epoch16, step1027]: loss 4.730626
[epoch16, step1028]: loss 3.155644
[epoch16, step1029]: loss 8.392316
[epoch16, step1030]: loss 1.276049
[epoch16, step1031]: loss 0.990980
[epoch16, step1032]: loss 0.962273
[epoch16, step1033]: loss 0.933321
[epoch16, step1034]: loss 3.045322
[epoch16, step1035]: loss 1.274291
[epoch16, step1036]: loss 10.423759
[epoch16, step1037]: loss 1.191177
[epoch16, step1038]: loss 1.220492
[epoch16, step1039]: loss 4.945818
[epoch16, step1040]: loss 2.347537
[epoch16, step1041]: loss 1.303477
[epoch16, step1042]: loss 0.910578
[epoch16, step1043]: loss 1.170676
[epoch16, step1044]: loss 2.722672
[epoch16, step1045]: loss 1.638824
[epoch16, step1046]: loss 0.967596
[epoch16, step1047]: loss 1.109125
[epoch16, step1048]: loss 3.302398
[epoch16, step1049]: loss 7.202130
[epoch16, step1050]: loss 2.167705
[epoch16, step1051]: loss 2.963794
[epoch16, step1052]: loss 2.249606
[epoch16, step1053]: loss 13.031666
[epoch16, step1054]: loss 2.503992
[epoch16, step1055]: loss 7.616296
[epoch16, step1056]: loss 3.069237
[epoch16, step1057]: loss 12.469028
[epoch16, step1058]: loss 5.329182
[epoch16, step1059]: loss 1.562420
[epoch16, step1060]: loss 2.060413
[epoch16, step1061]: loss 19.489054
[epoch16, step1062]: loss 5.890104
[epoch16, step1063]: loss 0.751375
[epoch16, step1064]: loss 1.147525
[epoch16, step1065]: loss 2.033416
[epoch16, step1066]: loss 6.053675
[epoch16, step1067]: loss 1.541549
[epoch16, step1068]: loss 13.499881
[epoch16, step1069]: loss 1.376294
[epoch16, step1070]: loss 5.971548
[epoch16, step1071]: loss 0.970477
[epoch16, step1072]: loss 1.030716
[epoch16, step1073]: loss 0.812735
[epoch16, step1074]: loss 4.236077
[epoch16, step1075]: loss 14.663013
[epoch16, step1076]: loss 7.971556
[epoch16, step1077]: loss 0.802117
[epoch16, step1078]: loss 1.576292
[epoch16, step1079]: loss 7.884809
[epoch16, step1080]: loss 7.092699
[epoch16, step1081]: loss 1.093795
[epoch16, step1082]: loss 1.717252
[epoch16, step1083]: loss 5.871438
[epoch16, step1084]: loss 1.145588
[epoch16, step1085]: loss 1.031141
[epoch16, step1086]: loss 0.626048
[epoch16, step1087]: loss 3.786129
[epoch16, step1088]: loss 22.709141
[epoch16, step1089]: loss 7.316196
[epoch16, step1090]: loss 4.184784
[epoch16, step1091]: loss 3.699065
[epoch16, step1092]: loss 3.116179
[epoch16, step1093]: loss 0.632598
[epoch16, step1094]: loss 1.013487
[epoch16, step1095]: loss 8.409825
[epoch16, step1096]: loss 1.246775
[epoch16, step1097]: loss 1.217390
[epoch16, step1098]: loss 7.677871
[epoch16, step1099]: loss 1.013471
[epoch16, step1100]: loss 1.458349
[epoch16, step1101]: loss 2.536093
[epoch16, step1102]: loss 2.945767
[epoch16, step1103]: loss 0.853088
[epoch16, step1104]: loss 9.007838
[epoch16, step1105]: loss 30.365482
[epoch16, step1106]: loss 1.432812
[epoch16, step1107]: loss 1.132668
[epoch16, step1108]: loss 3.696987
[epoch16, step1109]: loss 2.053456
[epoch16, step1110]: loss 11.457582
[epoch16, step1111]: loss 3.079503
[epoch16, step1112]: loss 4.120872
[epoch16, step1113]: loss 0.905897
[epoch16, step1114]: loss 24.997105
[epoch16, step1115]: loss 6.978132
[epoch16, step1116]: loss 13.003151
[epoch16, step1117]: loss 7.923811
[epoch16, step1118]: loss 1.588482
[epoch16, step1119]: loss 4.260737
[epoch16, step1120]: loss 2.088119
[epoch16, step1121]: loss 5.984885
[epoch16, step1122]: loss 8.084939
[epoch16, step1123]: loss 2.495590
[epoch16, step1124]: loss 0.648007
[epoch16, step1125]: loss 0.770328
[epoch16, step1126]: loss 5.095860
[epoch16, step1127]: loss 6.165935
[epoch16, step1128]: loss 5.965529
[epoch16, step1129]: loss 0.879030
[epoch16, step1130]: loss 3.695539
[epoch16, step1131]: loss 1.819038
[epoch16, step1132]: loss 1.177394
[epoch16, step1133]: loss 2.551582
[epoch16, step1134]: loss 1.829449
[epoch16, step1135]: loss 3.669447
[epoch16, step1136]: loss 0.996800
[epoch16, step1137]: loss 2.799581
[epoch16, step1138]: loss 0.738585
[epoch16, step1139]: loss 1.321755
[epoch16, step1140]: loss 1.229081
[epoch16, step1141]: loss 1.113374
[epoch16, step1142]: loss 1.151842
[epoch16, step1143]: loss 16.017715
[epoch16, step1144]: loss 2.528073
[epoch16, step1145]: loss 3.239732
[epoch16, step1146]: loss 22.821960
[epoch16, step1147]: loss 6.724231
[epoch16, step1148]: loss 2.441852
[epoch16, step1149]: loss 2.676201
[epoch16, step1150]: loss 9.378469
[epoch16, step1151]: loss 5.481694
[epoch16, step1152]: loss 2.156190
[epoch16, step1153]: loss 8.126862
[epoch16, step1154]: loss 4.583752
[epoch16, step1155]: loss 4.776286
[epoch16, step1156]: loss 1.534786
[epoch16, step1157]: loss 1.472401
[epoch16, step1158]: loss 5.647219
[epoch16, step1159]: loss 1.678573
[epoch16, step1160]: loss 2.500479
[epoch16, step1161]: loss 2.627473
[epoch16, step1162]: loss 13.129201
[epoch16, step1163]: loss 6.601361
[epoch16, step1164]: loss 1.518754
[epoch16, step1165]: loss 16.010519
[epoch16, step1166]: loss 0.751267
[epoch16, step1167]: loss 12.578265
[epoch16, step1168]: loss 1.138211
[epoch16, step1169]: loss 2.322650
[epoch16, step1170]: loss 4.513454
[epoch16, step1171]: loss 1.177946
[epoch16, step1172]: loss 0.926251
[epoch16, step1173]: loss 6.534495
[epoch16, step1174]: loss 1.245073
[epoch16, step1175]: loss 0.935349
[epoch16, step1176]: loss 9.635711
[epoch16, step1177]: loss 15.317224
[epoch16, step1178]: loss 1.974131
[epoch16, step1179]: loss 14.529202
[epoch16, step1180]: loss 4.760459
[epoch16, step1181]: loss 4.310052
[epoch16, step1182]: loss 7.630639
[epoch16, step1183]: loss 1.205992
[epoch16, step1184]: loss 12.360737
[epoch16, step1185]: loss 1.241211
[epoch16, step1186]: loss 0.785284
[epoch16, step1187]: loss 2.120990
[epoch16, step1188]: loss 1.360850
[epoch16, step1189]: loss 0.445847
[epoch16, step1190]: loss 8.641654
[epoch16, step1191]: loss 0.810001
[epoch16, step1192]: loss 1.067887
[epoch16, step1193]: loss 15.815981
[epoch16, step1194]: loss 2.060679
[epoch16, step1195]: loss 1.047504
[epoch16, step1196]: loss 0.777119
[epoch16, step1197]: loss 0.549844
[epoch16, step1198]: loss 1.153982
[epoch16, step1199]: loss 0.930239
[epoch16, step1200]: loss 1.608950
[epoch16, step1201]: loss 1.620930
[epoch16, step1202]: loss 1.596652
[epoch16, step1203]: loss 7.396768
[epoch16, step1204]: loss 1.951831
[epoch16, step1205]: loss 4.054799
[epoch16, step1206]: loss 5.844458
[epoch16, step1207]: loss 1.158068
[epoch16, step1208]: loss 4.346077
[epoch16, step1209]: loss 2.789266
[epoch16, step1210]: loss 1.391600
[epoch16, step1211]: loss 6.598393
[epoch16, step1212]: loss 1.656477
[epoch16, step1213]: loss 2.393565
[epoch16, step1214]: loss 0.492999
[epoch16, step1215]: loss 0.627255
[epoch16, step1216]: loss 0.739050
[epoch16, step1217]: loss 9.476281
[epoch16, step1218]: loss 1.445291
[epoch16, step1219]: loss 1.293335
[epoch16, step1220]: loss 1.817073
[epoch16, step1221]: loss 8.563917
[epoch16, step1222]: loss 1.382665
[epoch16, step1223]: loss 2.287791
[epoch16, step1224]: loss 3.520942
[epoch16, step1225]: loss 2.847238
[epoch16, step1226]: loss 9.511715
[epoch16, step1227]: loss 1.072526
[epoch16, step1228]: loss 1.070490
[epoch16, step1229]: loss 9.816888
[epoch16, step1230]: loss 5.283290
[epoch16, step1231]: loss 2.349097
[epoch16, step1232]: loss 4.799273
[epoch16, step1233]: loss 2.804769
[epoch16, step1234]: loss 0.812376
[epoch16, step1235]: loss 0.436910
[epoch16, step1236]: loss 11.960062
[epoch16, step1237]: loss 5.732148
[epoch16, step1238]: loss 1.403442
[epoch16, step1239]: loss 0.850150
[epoch16, step1240]: loss 1.399154
[epoch16, step1241]: loss 10.209238
[epoch16, step1242]: loss 1.956214
[epoch16, step1243]: loss 3.799109
[epoch16, step1244]: loss 2.336166
[epoch16, step1245]: loss 6.090686
[epoch16, step1246]: loss 3.869621
[epoch16, step1247]: loss 1.023838
[epoch16, step1248]: loss 2.080031
[epoch16, step1249]: loss 5.839156
[epoch16, step1250]: loss 0.555528
[epoch16, step1251]: loss 1.167729
[epoch16, step1252]: loss 0.673545
[epoch16, step1253]: loss 16.954769
[epoch16, step1254]: loss 4.393002
[epoch16, step1255]: loss 1.151719
[epoch16, step1256]: loss 0.873656
[epoch16, step1257]: loss 7.205956
[epoch16, step1258]: loss 1.371829
[epoch16, step1259]: loss 4.435896
[epoch16, step1260]: loss 12.288038
[epoch16, step1261]: loss 14.450363
[epoch16, step1262]: loss 13.673216
[epoch16, step1263]: loss 0.927425
[epoch16, step1264]: loss 10.538992
[epoch16, step1265]: loss 6.299143
[epoch16, step1266]: loss 0.729623
[epoch16, step1267]: loss 27.796139
[epoch16, step1268]: loss 2.356426
[epoch16, step1269]: loss 0.765688
[epoch16, step1270]: loss 1.285183
[epoch16, step1271]: loss 0.525660
[epoch16, step1272]: loss 11.883135
[epoch16, step1273]: loss 2.228995
[epoch16, step1274]: loss 2.016859
[epoch16, step1275]: loss 0.869850
[epoch16, step1276]: loss 1.128129
[epoch16, step1277]: loss 1.704571
[epoch16, step1278]: loss 2.544862
[epoch16, step1279]: loss 9.254253
[epoch16, step1280]: loss 0.758520
[epoch16, step1281]: loss 6.104358
[epoch16, step1282]: loss 8.605788
[epoch16, step1283]: loss 12.239653
[epoch16, step1284]: loss 1.215128
[epoch16, step1285]: loss 13.180077
[epoch16, step1286]: loss 2.746717
[epoch16, step1287]: loss 1.809527
[epoch16, step1288]: loss 1.724947
[epoch16, step1289]: loss 2.863386
[epoch16, step1290]: loss 0.543905
[epoch16, step1291]: loss 1.739652
[epoch16, step1292]: loss 1.409832
[epoch16, step1293]: loss 8.529287
[epoch16, step1294]: loss 1.284653
[epoch16, step1295]: loss 7.354850
[epoch16, step1296]: loss 9.937457
[epoch16, step1297]: loss 1.278603
[epoch16, step1298]: loss 8.131433
[epoch16, step1299]: loss 2.687665
[epoch16, step1300]: loss 1.305382
[epoch16, step1301]: loss 3.196470
[epoch16, step1302]: loss 7.755664
[epoch16, step1303]: loss 2.552378
[epoch16, step1304]: loss 6.313840
[epoch16, step1305]: loss 1.599161
[epoch16, step1306]: loss 2.426626
[epoch16, step1307]: loss 13.433859
[epoch16, step1308]: loss 2.226708
[epoch16, step1309]: loss 1.850557
[epoch16, step1310]: loss 3.170208
[epoch16, step1311]: loss 13.985525
[epoch16, step1312]: loss 2.142680
[epoch16, step1313]: loss 8.512457
[epoch16, step1314]: loss 1.827238
[epoch16, step1315]: loss 2.558867
[epoch16, step1316]: loss 1.393666
[epoch16, step1317]: loss 2.662627
[epoch16, step1318]: loss 3.210482
[epoch16, step1319]: loss 1.362317
[epoch16, step1320]: loss 2.780601
[epoch16, step1321]: loss 1.021930
[epoch16, step1322]: loss 3.732073
[epoch16, step1323]: loss 0.862959
[epoch16, step1324]: loss 11.791806
[epoch16, step1325]: loss 4.307016
[epoch16, step1326]: loss 2.504864
[epoch16, step1327]: loss 2.854062
[epoch16, step1328]: loss 1.149095
[epoch16, step1329]: loss 1.149903
[epoch16, step1330]: loss 1.993007
[epoch16, step1331]: loss 2.866994
[epoch16, step1332]: loss 4.375752
[epoch16, step1333]: loss 4.172261
[epoch16, step1334]: loss 1.226611
[epoch16, step1335]: loss 0.542305
[epoch16, step1336]: loss 1.650182
[epoch16, step1337]: loss 11.856796
[epoch16, step1338]: loss 0.735305
[epoch16, step1339]: loss 0.835131
[epoch16, step1340]: loss 1.377170
[epoch16, step1341]: loss 2.843067
[epoch16, step1342]: loss 1.141351
[epoch16, step1343]: loss 11.697918
[epoch16, step1344]: loss 0.718902
[epoch16, step1345]: loss 0.743547
[epoch16, step1346]: loss 1.788824
[epoch16, step1347]: loss 7.659863
[epoch16, step1348]: loss 6.330423
[epoch16, step1349]: loss 1.415308
[epoch16, step1350]: loss 1.949680
[epoch16, step1351]: loss 7.124072
[epoch16, step1352]: loss 8.231928
[epoch16, step1353]: loss 2.942873
[epoch16, step1354]: loss 2.809103
[epoch16, step1355]: loss 2.243075
[epoch16, step1356]: loss 12.392014
[epoch16, step1357]: loss 10.427091
[epoch16, step1358]: loss 23.893435
[epoch16, step1359]: loss 0.894727
[epoch16, step1360]: loss 7.487727
[epoch16, step1361]: loss 2.616220
[epoch16, step1362]: loss 1.319320
[epoch16, step1363]: loss 5.432809
[epoch16, step1364]: loss 1.004126
[epoch16, step1365]: loss 4.564822
[epoch16, step1366]: loss 1.317171
[epoch16, step1367]: loss 2.371154
[epoch16, step1368]: loss 1.215331
[epoch16, step1369]: loss 29.144266
[epoch16, step1370]: loss 2.096968
[epoch16, step1371]: loss 4.211868
[epoch16, step1372]: loss 2.042339
[epoch16, step1373]: loss 1.060954
[epoch16, step1374]: loss 0.934827
[epoch16, step1375]: loss 6.635561
[epoch16, step1376]: loss 8.020554
[epoch16, step1377]: loss 1.181871
[epoch16, step1378]: loss 5.459607
[epoch16, step1379]: loss 3.645814
[epoch16, step1380]: loss 1.885144
[epoch16, step1381]: loss 0.847322
[epoch16, step1382]: loss 6.414503
[epoch16, step1383]: loss 1.138793
[epoch16, step1384]: loss 0.878270
[epoch16, step1385]: loss 4.586980
[epoch16, step1386]: loss 0.982824
[epoch16, step1387]: loss 2.360482
[epoch16, step1388]: loss 4.170835
[epoch16, step1389]: loss 2.856674
[epoch16, step1390]: loss 1.427615
[epoch16, step1391]: loss 2.269809
[epoch16, step1392]: loss 6.887319
[epoch16, step1393]: loss 2.045125
[epoch16, step1394]: loss 9.120451
[epoch16, step1395]: loss 6.936992
[epoch16, step1396]: loss 2.663269
[epoch16, step1397]: loss 1.513611
[epoch16, step1398]: loss 1.301615
[epoch16, step1399]: loss 4.170047
[epoch16, step1400]: loss 0.711584
[epoch16, step1401]: loss 9.325752
[epoch16, step1402]: loss 1.724034
[epoch16, step1403]: loss 1.342827
[epoch16, step1404]: loss 1.553642
[epoch16, step1405]: loss 2.026888
[epoch16, step1406]: loss 1.605958
[epoch16, step1407]: loss 4.392753
[epoch16, step1408]: loss 3.065831
[epoch16, step1409]: loss 1.865148
[epoch16, step1410]: loss 1.056575
[epoch16, step1411]: loss 0.668610
[epoch16, step1412]: loss 4.255135
[epoch16, step1413]: loss 1.053465
[epoch16, step1414]: loss 0.670667
[epoch16, step1415]: loss 1.578256
[epoch16, step1416]: loss 0.834122
[epoch16, step1417]: loss 1.694171
[epoch16, step1418]: loss 0.893480
[epoch16, step1419]: loss 0.660624
[epoch16, step1420]: loss 1.933525
[epoch16, step1421]: loss 2.190672
[epoch16, step1422]: loss 1.985023
[epoch16, step1423]: loss 10.480680
[epoch16, step1424]: loss 3.792807
[epoch16, step1425]: loss 1.268467
[epoch16, step1426]: loss 1.042767
[epoch16, step1427]: loss 11.539378
[epoch16, step1428]: loss 1.312158
[epoch16, step1429]: loss 0.949041
[epoch16, step1430]: loss 6.498808
[epoch16, step1431]: loss 7.708430
[epoch16, step1432]: loss 3.499161
[epoch16, step1433]: loss 0.473741
[epoch16, step1434]: loss 1.918185
[epoch16, step1435]: loss 6.165226
[epoch16, step1436]: loss 0.749397
[epoch16, step1437]: loss 1.550428
[epoch16, step1438]: loss 4.372689
[epoch16, step1439]: loss 9.029110
[epoch16, step1440]: loss 17.529917
[epoch16, step1441]: loss 0.702756
[epoch16, step1442]: loss 0.903829
[epoch16, step1443]: loss 1.175101
[epoch16, step1444]: loss 4.701344
[epoch16, step1445]: loss 4.664498
[epoch16, step1446]: loss 2.275504
[epoch16, step1447]: loss 1.657902
[epoch16, step1448]: loss 2.304790
[epoch16, step1449]: loss 13.153286
[epoch16, step1450]: loss 3.120931
[epoch16, step1451]: loss 6.568869
[epoch16, step1452]: loss 2.242691
[epoch16, step1453]: loss 0.896881
[epoch16, step1454]: loss 4.567416
[epoch16, step1455]: loss 6.002004
[epoch16, step1456]: loss 1.162416
[epoch16, step1457]: loss 4.802040
[epoch16, step1458]: loss 7.212875
[epoch16, step1459]: loss 8.463152
[epoch16, step1460]: loss 1.899606
[epoch16, step1461]: loss 1.122746
[epoch16, step1462]: loss 1.066284
[epoch16, step1463]: loss 0.781309
[epoch16, step1464]: loss 1.334568
[epoch16, step1465]: loss 1.400535
[epoch16, step1466]: loss 1.858987
[epoch16, step1467]: loss 3.223973
[epoch16, step1468]: loss 0.883360
[epoch16, step1469]: loss 0.502793
[epoch16, step1470]: loss 1.031353
[epoch16, step1471]: loss 8.430869
[epoch16, step1472]: loss 1.369269
[epoch16, step1473]: loss 1.551235
[epoch16, step1474]: loss 1.051715
[epoch16, step1475]: loss 0.936851
[epoch16, step1476]: loss 11.425033
[epoch16, step1477]: loss 0.720243
[epoch16, step1478]: loss 0.481360
[epoch16, step1479]: loss 0.577915
[epoch16, step1480]: loss 2.126752
[epoch16, step1481]: loss 0.822998
[epoch16, step1482]: loss 2.058106
[epoch16, step1483]: loss 7.100669
[epoch16, step1484]: loss 6.014466
[epoch16, step1485]: loss 1.786978
[epoch16, step1486]: loss 1.286507
[epoch16, step1487]: loss 7.166154
[epoch16, step1488]: loss 1.288790
[epoch16, step1489]: loss 2.347641
[epoch16, step1490]: loss 1.094108
[epoch16, step1491]: loss 1.126164
[epoch16, step1492]: loss 0.576644
[epoch16, step1493]: loss 0.862519
[epoch16, step1494]: loss 1.035838
[epoch16, step1495]: loss 16.198759
[epoch16, step1496]: loss 0.920372
[epoch16, step1497]: loss 0.790278
[epoch16, step1498]: loss 1.143717
[epoch16, step1499]: loss 1.932325
[epoch16, step1500]: loss 1.026667
[epoch16, step1501]: loss 0.985542
[epoch16, step1502]: loss 0.761672
[epoch16, step1503]: loss 9.617435
[epoch16, step1504]: loss 0.857616
[epoch16, step1505]: loss 1.364437
[epoch16, step1506]: loss 1.181184
[epoch16, step1507]: loss 1.090868
[epoch16, step1508]: loss 8.505214
[epoch16, step1509]: loss 1.061181
[epoch16, step1510]: loss 2.805653
[epoch16, step1511]: loss 1.205586
[epoch16, step1512]: loss 1.009469
[epoch16, step1513]: loss 1.971390
[epoch16, step1514]: loss 1.450773
[epoch16, step1515]: loss 0.938457
[epoch16, step1516]: loss 1.029965
[epoch16, step1517]: loss 1.321763
[epoch16, step1518]: loss 1.025440
[epoch16, step1519]: loss 2.761869
[epoch16, step1520]: loss 1.567058
[epoch16, step1521]: loss 5.171712
[epoch16, step1522]: loss 2.784776
[epoch16, step1523]: loss 7.074609
[epoch16, step1524]: loss 1.008574
[epoch16, step1525]: loss 0.591008
[epoch16, step1526]: loss 0.444132
[epoch16, step1527]: loss 2.330071
[epoch16, step1528]: loss 15.375998
[epoch16, step1529]: loss 1.058405
[epoch16, step1530]: loss 1.197769
[epoch16, step1531]: loss 1.248080
[epoch16, step1532]: loss 8.029306
[epoch16, step1533]: loss 3.472477
[epoch16, step1534]: loss 0.623700
[epoch16, step1535]: loss 5.276155
[epoch16, step1536]: loss 1.254191
[epoch16, step1537]: loss 0.688697
[epoch16, step1538]: loss 0.923235
[epoch16, step1539]: loss 1.003408
[epoch16, step1540]: loss 0.624287
[epoch16, step1541]: loss 1.784854
[epoch16, step1542]: loss 1.513749
[epoch16, step1543]: loss 1.168154
[epoch16, step1544]: loss 12.937179
[epoch16, step1545]: loss 1.194888
[epoch16, step1546]: loss 1.667466
[epoch16, step1547]: loss 1.177434
[epoch16, step1548]: loss 13.079388
[epoch16, step1549]: loss 12.653519
[epoch16, step1550]: loss 0.795146
[epoch16, step1551]: loss 3.083291
[epoch16, step1552]: loss 0.909363
[epoch16, step1553]: loss 1.122245
[epoch16, step1554]: loss 1.076571
[epoch16, step1555]: loss 1.857065
[epoch16, step1556]: loss 2.211465
[epoch16, step1557]: loss 0.786230
[epoch16, step1558]: loss 1.348374
[epoch16, step1559]: loss 6.383452
[epoch16, step1560]: loss 0.651999
[epoch16, step1561]: loss 0.622125
[epoch16, step1562]: loss 1.239754
[epoch16, step1563]: loss 11.070801
[epoch16, step1564]: loss 1.943798
[epoch16, step1565]: loss 10.829924
[epoch16, step1566]: loss 0.825007
[epoch16, step1567]: loss 9.605693
[epoch16, step1568]: loss 2.718003
[epoch16, step1569]: loss 1.471478
[epoch16, step1570]: loss 3.407663
[epoch16, step1571]: loss 2.915297
[epoch16, step1572]: loss 1.422160
[epoch16, step1573]: loss 1.111104
[epoch16, step1574]: loss 2.939019
[epoch16, step1575]: loss 1.509728
[epoch16, step1576]: loss 10.459455
[epoch16, step1577]: loss 1.262649
[epoch16, step1578]: loss 2.088923
[epoch16, step1579]: loss 4.436286
[epoch16, step1580]: loss 2.772509
[epoch16, step1581]: loss 0.792533
[epoch16, step1582]: loss 0.885140
[epoch16, step1583]: loss 1.079423
[epoch16, step1584]: loss 2.404184
[epoch16, step1585]: loss 1.528480
[epoch16, step1586]: loss 12.156633
[epoch16, step1587]: loss 0.851829
[epoch16, step1588]: loss 1.320413
[epoch16, step1589]: loss 0.911830
[epoch16, step1590]: loss 1.824669
[epoch16, step1591]: loss 0.581500
[epoch16, step1592]: loss 2.168892
[epoch16, step1593]: loss 12.892724
[epoch16, step1594]: loss 10.397930
[epoch16, step1595]: loss 0.624533
[epoch16, step1596]: loss 3.475162
[epoch16, step1597]: loss 1.144802
[epoch16, step1598]: loss 7.836346
[epoch16, step1599]: loss 2.585777
[epoch16, step1600]: loss 1.540166
[epoch16, step1601]: loss 2.496969
[epoch16, step1602]: loss 6.746624
[epoch16, step1603]: loss 1.198534
[epoch16, step1604]: loss 26.457266
[epoch16, step1605]: loss 0.848073
[epoch16, step1606]: loss 1.493866
[epoch16, step1607]: loss 2.227818
[epoch16, step1608]: loss 1.360518
[epoch16, step1609]: loss 6.082564
[epoch16, step1610]: loss 1.850613
[epoch16, step1611]: loss 2.672677
[epoch16, step1612]: loss 0.894189
[epoch16, step1613]: loss 2.876053
[epoch16, step1614]: loss 0.770358
[epoch16, step1615]: loss 0.658924
[epoch16, step1616]: loss 0.860702
[epoch16, step1617]: loss 1.055618
[epoch16, step1618]: loss 1.049070
[epoch16, step1619]: loss 7.912151
[epoch16, step1620]: loss 7.055664
[epoch16, step1621]: loss 2.121296
[epoch16, step1622]: loss 14.139868
[epoch16, step1623]: loss 3.014113
[epoch16, step1624]: loss 2.485544
[epoch16, step1625]: loss 7.187136
[epoch16, step1626]: loss 9.649039
[epoch16, step1627]: loss 0.893536
[epoch16, step1628]: loss 1.465548
[epoch16, step1629]: loss 15.986674
[epoch16, step1630]: loss 0.761910
[epoch16, step1631]: loss 2.821311
[epoch16, step1632]: loss 2.321300
[epoch16, step1633]: loss 2.818018
[epoch16, step1634]: loss 1.012061
[epoch16, step1635]: loss 2.667402
[epoch16, step1636]: loss 1.155284
[epoch16, step1637]: loss 0.953710
[epoch16, step1638]: loss 2.733435
[epoch16, step1639]: loss 1.927060
[epoch16, step1640]: loss 0.615483
[epoch16, step1641]: loss 1.090829
[epoch16, step1642]: loss 11.520376
[epoch16, step1643]: loss 0.532067
[epoch16, step1644]: loss 3.966752
[epoch16, step1645]: loss 6.414162
[epoch16, step1646]: loss 0.642936
[epoch16, step1647]: loss 4.874139
[epoch16, step1648]: loss 5.849261
[epoch16, step1649]: loss 1.482082
[epoch16, step1650]: loss 0.736941
[epoch16, step1651]: loss 1.836427
[epoch16, step1652]: loss 3.608829
[epoch16, step1653]: loss 0.874176
[epoch16, step1654]: loss 5.922914
[epoch16, step1655]: loss 2.018494
[epoch16, step1656]: loss 10.842846
[epoch16, step1657]: loss 1.085951
[epoch16, step1658]: loss 3.014621
[epoch16, step1659]: loss 6.121353
[epoch16, step1660]: loss 2.772128
[epoch16, step1661]: loss 2.237823
[epoch16, step1662]: loss 1.555804
[epoch16, step1663]: loss 1.190610
[epoch16, step1664]: loss 2.329302
[epoch16, step1665]: loss 1.073744
[epoch16, step1666]: loss 1.000483
[epoch16, step1667]: loss 13.487637
[epoch16, step1668]: loss 18.511299
[epoch16, step1669]: loss 1.091479
[epoch16, step1670]: loss 2.257658
[epoch16, step1671]: loss 0.750873
[epoch16, step1672]: loss 0.905688
[epoch16, step1673]: loss 0.850176
[epoch16, step1674]: loss 1.784092
[epoch16, step1675]: loss 7.628975
[epoch16, step1676]: loss 5.427299
[epoch16, step1677]: loss 1.145212
[epoch16, step1678]: loss 3.211143
[epoch16, step1679]: loss 8.921840
[epoch16, step1680]: loss 2.141468
[epoch16, step1681]: loss 0.922471
[epoch16, step1682]: loss 6.037335
[epoch16, step1683]: loss 4.792875
[epoch16, step1684]: loss 0.921621
[epoch16, step1685]: loss 0.808487
[epoch16, step1686]: loss 1.415127
[epoch16, step1687]: loss 2.042367
[epoch16, step1688]: loss 1.425284
[epoch16, step1689]: loss 0.920645
[epoch16, step1690]: loss 0.898600
[epoch16, step1691]: loss 0.891063
[epoch16, step1692]: loss 3.025059
[epoch16, step1693]: loss 1.072508
[epoch16, step1694]: loss 2.131824
[epoch16, step1695]: loss 8.194726
[epoch16, step1696]: loss 0.751697
[epoch16, step1697]: loss 0.721264
[epoch16, step1698]: loss 2.979791
[epoch16, step1699]: loss 1.785504
[epoch16, step1700]: loss 7.502347
[epoch16, step1701]: loss 0.615361
[epoch16, step1702]: loss 1.700205
[epoch16, step1703]: loss 0.954235
[epoch16, step1704]: loss 0.700305
[epoch16, step1705]: loss 2.918654
[epoch16, step1706]: loss 1.289224
[epoch16, step1707]: loss 1.776407
[epoch16, step1708]: loss 5.568980
[epoch16, step1709]: loss 2.913503
[epoch16, step1710]: loss 2.808185
[epoch16, step1711]: loss 9.511048
[epoch16, step1712]: loss 1.421207
[epoch16, step1713]: loss 1.965009
[epoch16, step1714]: loss 6.618546
[epoch16, step1715]: loss 12.206854
[epoch16, step1716]: loss 5.023922
[epoch16, step1717]: loss 1.699615
[epoch16, step1718]: loss 8.830031
[epoch16, step1719]: loss 0.794759
[epoch16, step1720]: loss 1.005652
[epoch16, step1721]: loss 1.915645
[epoch16, step1722]: loss 1.102778
[epoch16, step1723]: loss 0.626481
[epoch16, step1724]: loss 3.145772
[epoch16, step1725]: loss 12.432058
[epoch16, step1726]: loss 3.372195
[epoch16, step1727]: loss 3.606028
[epoch16, step1728]: loss 3.038136
[epoch16, step1729]: loss 1.545436
[epoch16, step1730]: loss 0.904904
[epoch16, step1731]: loss 0.734941
[epoch16, step1732]: loss 1.087037
[epoch16, step1733]: loss 0.784061
[epoch16, step1734]: loss 1.010206
[epoch16, step1735]: loss 1.030695
[epoch16, step1736]: loss 0.694365
[epoch16, step1737]: loss 0.706278
[epoch16, step1738]: loss 13.593374
[epoch16, step1739]: loss 2.107204
[epoch16, step1740]: loss 1.432877
[epoch16, step1741]: loss 2.088293
[epoch16, step1742]: loss 9.543445
[epoch16, step1743]: loss 12.190241
[epoch16, step1744]: loss 1.616221
[epoch16, step1745]: loss 3.135380
[epoch16, step1746]: loss 1.186511
[epoch16, step1747]: loss 1.325476
[epoch16, step1748]: loss 1.188486
[epoch16, step1749]: loss 6.057916
[epoch16, step1750]: loss 1.944674
[epoch16, step1751]: loss 9.757297
[epoch16, step1752]: loss 5.560598
[epoch16, step1753]: loss 8.571306
[epoch16, step1754]: loss 1.423625
[epoch16, step1755]: loss 11.236506
[epoch16, step1756]: loss 12.927011
[epoch16, step1757]: loss 1.160421
[epoch16, step1758]: loss 2.352641
[epoch16, step1759]: loss 1.749374
[epoch16, step1760]: loss 1.048088
[epoch16, step1761]: loss 7.788589
[epoch16, step1762]: loss 11.757593
[epoch16, step1763]: loss 1.137633
[epoch16, step1764]: loss 9.346737
[epoch16, step1765]: loss 1.377618
[epoch16, step1766]: loss 1.260731
[epoch16, step1767]: loss 1.672675
[epoch16, step1768]: loss 3.869524
[epoch16, step1769]: loss 13.400126
[epoch16, step1770]: loss 11.803228
[epoch16, step1771]: loss 1.626738
[epoch16, step1772]: loss 6.491635
[epoch16, step1773]: loss 4.436125
[epoch16, step1774]: loss 2.333451
[epoch16, step1775]: loss 3.182861
[epoch16, step1776]: loss 4.359597
[epoch16, step1777]: loss 1.397905
[epoch16, step1778]: loss 1.679552
[epoch16, step1779]: loss 3.891552
[epoch16, step1780]: loss 6.875875
[epoch16, step1781]: loss 1.829718
[epoch16, step1782]: loss 12.599548
[epoch16, step1783]: loss 3.822649
[epoch16, step1784]: loss 1.059678
[epoch16, step1785]: loss 1.089415
[epoch16, step1786]: loss 1.193060
[epoch16, step1787]: loss 1.112514
[epoch16, step1788]: loss 2.152984
[epoch16, step1789]: loss 1.765717
[epoch16, step1790]: loss 17.621269
[epoch16, step1791]: loss 5.603404
[epoch16, step1792]: loss 3.156260
[epoch16, step1793]: loss 2.036929
[epoch16, step1794]: loss 0.830219
[epoch16, step1795]: loss 12.723938
[epoch16, step1796]: loss 0.965759
[epoch16, step1797]: loss 3.440284
[epoch16, step1798]: loss 5.435539
[epoch16, step1799]: loss 1.513928
[epoch16, step1800]: loss 7.889464
[epoch16, step1801]: loss 1.574422
[epoch16, step1802]: loss 3.362214
[epoch16, step1803]: loss 1.496159
[epoch16, step1804]: loss 6.243647
[epoch16, step1805]: loss 2.390541
[epoch16, step1806]: loss 2.793207
[epoch16, step1807]: loss 0.492015
[epoch16, step1808]: loss 1.416648
[epoch16, step1809]: loss 0.780067
[epoch16, step1810]: loss 1.244272
[epoch16, step1811]: loss 2.888253
[epoch16, step1812]: loss 10.033915
[epoch16, step1813]: loss 6.624648
[epoch16, step1814]: loss 1.842438
[epoch16, step1815]: loss 2.588585
[epoch16, step1816]: loss 5.307798
[epoch16, step1817]: loss 2.736597
[epoch16, step1818]: loss 10.073057
[epoch16, step1819]: loss 13.306694
[epoch16, step1820]: loss 0.846720
[epoch16, step1821]: loss 1.633241
[epoch16, step1822]: loss 11.640517
[epoch16, step1823]: loss 2.528391
[epoch16, step1824]: loss 5.306029
[epoch16, step1825]: loss 7.767844
[epoch16, step1826]: loss 0.632547
[epoch16, step1827]: loss 0.557970
[epoch16, step1828]: loss 4.753715
[epoch16, step1829]: loss 0.903249
[epoch16, step1830]: loss 9.696836
[epoch16, step1831]: loss 2.127127
[epoch16, step1832]: loss 0.836147
[epoch16, step1833]: loss 2.449282
[epoch16, step1834]: loss 3.195631
[epoch16, step1835]: loss 2.225402
[epoch16, step1836]: loss 0.785376
[epoch16, step1837]: loss 1.544819
[epoch16, step1838]: loss 3.462174
[epoch16, step1839]: loss 2.012506
[epoch16, step1840]: loss 12.170794
[epoch16, step1841]: loss 2.221148
[epoch16, step1842]: loss 1.428037
[epoch16, step1843]: loss 1.520331
[epoch16, step1844]: loss 0.890314
[epoch16, step1845]: loss 0.816034
[epoch16, step1846]: loss 1.006598
[epoch16, step1847]: loss 2.623025
[epoch16, step1848]: loss 1.332886
[epoch16, step1849]: loss 8.543755
[epoch16, step1850]: loss 0.959474
[epoch16, step1851]: loss 1.052162
[epoch16, step1852]: loss 1.120688
[epoch16, step1853]: loss 2.132924
[epoch16, step1854]: loss 1.119957
[epoch16, step1855]: loss 1.301651
[epoch16, step1856]: loss 5.162438
[epoch16, step1857]: loss 1.264530
[epoch16, step1858]: loss 6.105350
[epoch16, step1859]: loss 0.839160
[epoch16, step1860]: loss 4.578615
[epoch16, step1861]: loss 2.059825
[epoch16, step1862]: loss 2.555987
[epoch16, step1863]: loss 3.629021
[epoch16, step1864]: loss 10.208931
[epoch16, step1865]: loss 12.472858
[epoch16, step1866]: loss 1.128086
[epoch16, step1867]: loss 1.051206
[epoch16, step1868]: loss 0.821985
[epoch16, step1869]: loss 1.194034
[epoch16, step1870]: loss 0.721637
[epoch16, step1871]: loss 5.500504
[epoch16, step1872]: loss 1.216181
[epoch16, step1873]: loss 1.367030
[epoch16, step1874]: loss 9.077968
[epoch16, step1875]: loss 16.768528
[epoch16, step1876]: loss 2.941826
[epoch16, step1877]: loss 0.669300
[epoch16, step1878]: loss 2.618690
[epoch16, step1879]: loss 2.261215
[epoch16, step1880]: loss 7.844418
[epoch16, step1881]: loss 13.030740
[epoch16, step1882]: loss 4.008598
[epoch16, step1883]: loss 1.649309
[epoch16, step1884]: loss 1.087533
[epoch16, step1885]: loss 1.175483
[epoch16, step1886]: loss 1.361640
[epoch16, step1887]: loss 0.737664
[epoch16, step1888]: loss 1.045761
[epoch16, step1889]: loss 1.847216
[epoch16, step1890]: loss 1.029149
[epoch16, step1891]: loss 6.020642
[epoch16, step1892]: loss 1.155220
[epoch16, step1893]: loss 1.055038
[epoch16, step1894]: loss 21.297201
[epoch16, step1895]: loss 0.733437
[epoch16, step1896]: loss 4.242968
[epoch16, step1897]: loss 0.913620
[epoch16, step1898]: loss 8.359875
[epoch16, step1899]: loss 1.136367
[epoch16, step1900]: loss 5.201155
[epoch16, step1901]: loss 2.655467
[epoch16, step1902]: loss 2.149210
[epoch16, step1903]: loss 2.740691
[epoch16, step1904]: loss 0.758900
[epoch16, step1905]: loss 2.098864
[epoch16, step1906]: loss 1.763586
[epoch16, step1907]: loss 0.741453
[epoch16, step1908]: loss 2.575182
[epoch16, step1909]: loss 1.029743
[epoch16, step1910]: loss 1.949963
[epoch16, step1911]: loss 0.735798
[epoch16, step1912]: loss 11.445924
[epoch16, step1913]: loss 1.039723
[epoch16, step1914]: loss 5.243149
[epoch16, step1915]: loss 2.093333
[epoch16, step1916]: loss 0.757072
[epoch16, step1917]: loss 10.968872
[epoch16, step1918]: loss 1.056041
[epoch16, step1919]: loss 12.255371
[epoch16, step1920]: loss 1.461467
[epoch16, step1921]: loss 1.274911
[epoch16, step1922]: loss 1.343639
[epoch16, step1923]: loss 1.239764
[epoch16, step1924]: loss 6.503853
[epoch16, step1925]: loss 1.843955
[epoch16, step1926]: loss 10.178577
[epoch16, step1927]: loss 2.509759
[epoch16, step1928]: loss 0.539084
[epoch16, step1929]: loss 1.183417
[epoch16, step1930]: loss 13.449877
[epoch16, step1931]: loss 11.615984
[epoch16, step1932]: loss 5.711936
[epoch16, step1933]: loss 3.777411
[epoch16, step1934]: loss 5.790230
[epoch16, step1935]: loss 2.175112
[epoch16, step1936]: loss 1.572268
[epoch16, step1937]: loss 1.811829
[epoch16, step1938]: loss 0.905815
[epoch16, step1939]: loss 1.635780
[epoch16, step1940]: loss 9.961575
[epoch16, step1941]: loss 1.000675
[epoch16, step1942]: loss 9.554742
[epoch16, step1943]: loss 1.815507
[epoch16, step1944]: loss 2.911129
[epoch16, step1945]: loss 1.045112
[epoch16, step1946]: loss 1.947765
[epoch16, step1947]: loss 3.330029
[epoch16, step1948]: loss 11.805820
[epoch16, step1949]: loss 3.440963
[epoch16, step1950]: loss 3.358298
[epoch16, step1951]: loss 7.400175
[epoch16, step1952]: loss 0.535855
[epoch16, step1953]: loss 3.121469
[epoch16, step1954]: loss 12.861191
[epoch16, step1955]: loss 1.962690
[epoch16, step1956]: loss 3.758272
[epoch16, step1957]: loss 6.622499
[epoch16, step1958]: loss 2.067910
[epoch16, step1959]: loss 1.319641
[epoch16, step1960]: loss 2.065183
[epoch16, step1961]: loss 3.356167
[epoch16, step1962]: loss 7.920119
[epoch16, step1963]: loss 11.164770
[epoch16, step1964]: loss 11.919885
[epoch16, step1965]: loss 0.624145
[epoch16, step1966]: loss 3.336740
[epoch16, step1967]: loss 7.584960
[epoch16, step1968]: loss 1.240735
[epoch16, step1969]: loss 14.838665
[epoch16, step1970]: loss 2.453180
[epoch16, step1971]: loss 2.779511
[epoch16, step1972]: loss 1.837208
[epoch16, step1973]: loss 28.142639
[epoch16, step1974]: loss 3.508324
[epoch16, step1975]: loss 3.217228
[epoch16, step1976]: loss 0.758465
[epoch16, step1977]: loss 7.873386
[epoch16, step1978]: loss 10.539410
[epoch16, step1979]: loss 1.283468
[epoch16, step1980]: loss 3.097788
[epoch16, step1981]: loss 2.855605
[epoch16, step1982]: loss 1.417898
[epoch16, step1983]: loss 3.995714
[epoch16, step1984]: loss 1.736751
[epoch16, step1985]: loss 2.080832
[epoch16, step1986]: loss 2.114393
[epoch16, step1987]: loss 3.823950
[epoch16, step1988]: loss 9.870801
[epoch16, step1989]: loss 1.313094
[epoch16, step1990]: loss 4.855966
[epoch16, step1991]: loss 0.744226
[epoch16, step1992]: loss 1.200069
[epoch16, step1993]: loss 1.207063
[epoch16, step1994]: loss 0.693474
[epoch16, step1995]: loss 1.444955
[epoch16, step1996]: loss 2.739205
[epoch16, step1997]: loss 1.613152
[epoch16, step1998]: loss 17.492350
[epoch16, step1999]: loss 0.725708
[epoch16, step2000]: loss 1.153299
[epoch16, step2001]: loss 11.594799
[epoch16, step2002]: loss 2.356168
[epoch16, step2003]: loss 0.700509
[epoch16, step2004]: loss 3.176414
[epoch16, step2005]: loss 4.627292
[epoch16, step2006]: loss 1.251943
[epoch16, step2007]: loss 1.285910
[epoch16, step2008]: loss 14.699244
[epoch16, step2009]: loss 2.478943
[epoch16, step2010]: loss 8.912359
[epoch16, step2011]: loss 12.157541
[epoch16, step2012]: loss 1.478660
[epoch16, step2013]: loss 1.443396
[epoch16, step2014]: loss 3.067782
[epoch16, step2015]: loss 17.758333
[epoch16, step2016]: loss 13.768808
[epoch16, step2017]: loss 3.233819
[epoch16, step2018]: loss 11.045671
[epoch16, step2019]: loss 16.606077
[epoch16, step2020]: loss 6.513090
[epoch16, step2021]: loss 3.170553
[epoch16, step2022]: loss 2.266996
[epoch16, step2023]: loss 3.059491
[epoch16, step2024]: loss 3.332429
[epoch16, step2025]: loss 1.096885
[epoch16, step2026]: loss 23.204283
[epoch16, step2027]: loss 2.041095
[epoch16, step2028]: loss 1.222547
[epoch16, step2029]: loss 0.968516
[epoch16, step2030]: loss 1.832123
[epoch16, step2031]: loss 0.894454
[epoch16, step2032]: loss 0.949044
[epoch16, step2033]: loss 1.205043
[epoch16, step2034]: loss 1.093966
[epoch16, step2035]: loss 1.690425
[epoch16, step2036]: loss 1.057521
[epoch16, step2037]: loss 2.800080
[epoch16, step2038]: loss 2.029320
[epoch16, step2039]: loss 2.238077
[epoch16, step2040]: loss 1.697878
[epoch16, step2041]: loss 0.965123
[epoch16, step2042]: loss 1.035358
[epoch16, step2043]: loss 6.765050
[epoch16, step2044]: loss 0.958075
[epoch16, step2045]: loss 0.982214
[epoch16, step2046]: loss 0.766767
[epoch16, step2047]: loss 1.423582
[epoch16, step2048]: loss 1.228207
[epoch16, step2049]: loss 7.112313
[epoch16, step2050]: loss 1.427653
[epoch16, step2051]: loss 7.325776
[epoch16, step2052]: loss 2.492074
[epoch16, step2053]: loss 13.140608
[epoch16, step2054]: loss 0.787274
[epoch16, step2055]: loss 5.721046
[epoch16, step2056]: loss 2.969557
[epoch16, step2057]: loss 0.643952
[epoch16, step2058]: loss 1.498794
[epoch16, step2059]: loss 8.731621
[epoch16, step2060]: loss 1.247509
[epoch16, step2061]: loss 0.736211
[epoch16, step2062]: loss 2.276162
[epoch16, step2063]: loss 1.488872
[epoch16, step2064]: loss 8.493673
[epoch16, step2065]: loss 1.243941
[epoch16, step2066]: loss 2.608861
[epoch16, step2067]: loss 1.755520
[epoch16, step2068]: loss 1.563822
[epoch16, step2069]: loss 1.258619
[epoch16, step2070]: loss 5.039646
[epoch16, step2071]: loss 1.205612
[epoch16, step2072]: loss 5.560932
[epoch16, step2073]: loss 0.786847
[epoch16, step2074]: loss 0.670205
[epoch16, step2075]: loss 5.782938
[epoch16, step2076]: loss 1.345551
[epoch16, step2077]: loss 0.850847
[epoch16, step2078]: loss 0.703018
[epoch16, step2079]: loss 9.879204
[epoch16, step2080]: loss 1.231922
[epoch16, step2081]: loss 5.863872
[epoch16, step2082]: loss 3.483757
[epoch16, step2083]: loss 0.755620
[epoch16, step2084]: loss 3.081610
[epoch16, step2085]: loss 1.728450
[epoch16, step2086]: loss 6.285354
[epoch16, step2087]: loss 1.993084
[epoch16, step2088]: loss 1.115659
[epoch16, step2089]: loss 1.171603
[epoch16, step2090]: loss 4.159085
[epoch16, step2091]: loss 0.883520
[epoch16, step2092]: loss 1.750987
[epoch16, step2093]: loss 1.991943
[epoch16, step2094]: loss 1.775811
[epoch16, step2095]: loss 15.301675
[epoch16, step2096]: loss 8.708378
[epoch16, step2097]: loss 0.333431
[epoch16, step2098]: loss 10.834496
[epoch16, step2099]: loss 11.420666
[epoch16, step2100]: loss 1.915228
[epoch16, step2101]: loss 1.364653
[epoch16, step2102]: loss 0.934143
[epoch16, step2103]: loss 11.500890
[epoch16, step2104]: loss 3.074771
[epoch16, step2105]: loss 4.689910
[epoch16, step2106]: loss 3.246904
[epoch16, step2107]: loss 16.854404
[epoch16, step2108]: loss 1.936540
[epoch16, step2109]: loss 11.394832
[epoch16, step2110]: loss 0.739058
[epoch16, step2111]: loss 3.753454
[epoch16, step2112]: loss 1.239255
[epoch16, step2113]: loss 0.862217
[epoch16, step2114]: loss 0.964847
[epoch16, step2115]: loss 1.260484
[epoch16, step2116]: loss 16.028767
[epoch16, step2117]: loss 0.821655
[epoch16, step2118]: loss 0.954978
[epoch16, step2119]: loss 1.030325
[epoch16, step2120]: loss 1.697048
[epoch16, step2121]: loss 0.825163
[epoch16, step2122]: loss 0.964076
[epoch16, step2123]: loss 1.386341
[epoch16, step2124]: loss 2.340404
[epoch16, step2125]: loss 0.874369
[epoch16, step2126]: loss 1.406477
[epoch16, step2127]: loss 1.289158
[epoch16, step2128]: loss 0.675845
[epoch16, step2129]: loss 0.856581
[epoch16, step2130]: loss 1.984526
[epoch16, step2131]: loss 3.184515
[epoch16, step2132]: loss 6.786435
[epoch16, step2133]: loss 3.166847
[epoch16, step2134]: loss 2.542112
[epoch16, step2135]: loss 5.174053
[epoch16, step2136]: loss 1.019817
[epoch16, step2137]: loss 1.147340
[epoch16, step2138]: loss 3.882279
[epoch16, step2139]: loss 0.725870
[epoch16, step2140]: loss 1.353877
[epoch16, step2141]: loss 1.383533
[epoch16, step2142]: loss 2.087737
[epoch16, step2143]: loss 2.155806
[epoch16, step2144]: loss 6.203414
[epoch16, step2145]: loss 1.465758
[epoch16, step2146]: loss 0.551456
[epoch16, step2147]: loss 3.880263
[epoch16, step2148]: loss 11.241620
[epoch16, step2149]: loss 0.887504
[epoch16, step2150]: loss 0.599460
[epoch16, step2151]: loss 3.882001
[epoch16, step2152]: loss 2.292920
[epoch16, step2153]: loss 0.878525
[epoch16, step2154]: loss 4.371350
[epoch16, step2155]: loss 3.349647
[epoch16, step2156]: loss 11.866450
[epoch16, step2157]: loss 1.145654
[epoch16, step2158]: loss 2.358998
[epoch16, step2159]: loss 6.410926
[epoch16, step2160]: loss 0.755134
[epoch16, step2161]: loss 1.281730
[epoch16, step2162]: loss 0.881281
[epoch16, step2163]: loss 3.048997
[epoch16, step2164]: loss 2.637436
[epoch16, step2165]: loss 5.820934
[epoch16, step2166]: loss 1.321876
[epoch16, step2167]: loss 3.751667
[epoch16, step2168]: loss 0.916407
[epoch16, step2169]: loss 2.017163
[epoch16, step2170]: loss 2.924410
[epoch16, step2171]: loss 2.372202
[epoch16, step2172]: loss 0.822479
[epoch16, step2173]: loss 0.576260
[epoch16, step2174]: loss 0.966621
[epoch16, step2175]: loss 9.445802
[epoch16, step2176]: loss 3.374784
[epoch16, step2177]: loss 4.312941
[epoch16, step2178]: loss 0.771734
[epoch16, step2179]: loss 2.348329
[epoch16, step2180]: loss 3.510052
[epoch16, step2181]: loss 0.820431
[epoch16, step2182]: loss 1.315774
[epoch16, step2183]: loss 0.921530
[epoch16, step2184]: loss 1.014263
[epoch16, step2185]: loss 2.168857
[epoch16, step2186]: loss 9.175817
[epoch16, step2187]: loss 1.017396
[epoch16, step2188]: loss 1.630201
[epoch16, step2189]: loss 3.359198
[epoch16, step2190]: loss 1.597340
[epoch16, step2191]: loss 1.135655
[epoch16, step2192]: loss 1.351132
[epoch16, step2193]: loss 1.379502
[epoch16, step2194]: loss 3.503796
[epoch16, step2195]: loss 1.133835
[epoch16, step2196]: loss 1.636121
[epoch16, step2197]: loss 1.168258
[epoch16, step2198]: loss 6.345687
[epoch16, step2199]: loss 1.557657
[epoch16, step2200]: loss 2.703661
[epoch16, step2201]: loss 0.889154
[epoch16, step2202]: loss 5.015877
[epoch16, step2203]: loss 4.189137
[epoch16, step2204]: loss 1.377005
[epoch16, step2205]: loss 0.802022
[epoch16, step2206]: loss 1.926134
[epoch16, step2207]: loss 1.410223
[epoch16, step2208]: loss 9.534812
[epoch16, step2209]: loss 3.565390
[epoch16, step2210]: loss 1.502694
[epoch16, step2211]: loss 8.627504
[epoch16, step2212]: loss 1.164480
[epoch16, step2213]: loss 12.429515
[epoch16, step2214]: loss 1.374114
[epoch16, step2215]: loss 0.839064
[epoch16, step2216]: loss 1.076083
[epoch16, step2217]: loss 1.149483
[epoch16, step2218]: loss 5.510287
[epoch16, step2219]: loss 7.326159
[epoch16, step2220]: loss 1.124689
[epoch16, step2221]: loss 1.188028
[epoch16, step2222]: loss 0.410278
[epoch16, step2223]: loss 3.870716
[epoch16, step2224]: loss 21.639717
[epoch16, step2225]: loss 11.439439
[epoch16, step2226]: loss 0.641475
[epoch16, step2227]: loss 3.247005
[epoch16, step2228]: loss 0.542523
[epoch16, step2229]: loss 8.489440
[epoch16, step2230]: loss 1.900960
[epoch16, step2231]: loss 5.216120
[epoch16, step2232]: loss 1.089520
[epoch16, step2233]: loss 1.522989
[epoch16, step2234]: loss 0.911414
[epoch16, step2235]: loss 0.918648
[epoch16, step2236]: loss 1.032074
[epoch16, step2237]: loss 3.018402
[epoch16, step2238]: loss 8.930981
[epoch16, step2239]: loss 11.321002
[epoch16, step2240]: loss 1.363600
[epoch16, step2241]: loss 0.857467
[epoch16, step2242]: loss 1.380516
[epoch16, step2243]: loss 3.639338
[epoch16, step2244]: loss 5.884598
[epoch16, step2245]: loss 6.206767
[epoch16, step2246]: loss 0.678183
[epoch16, step2247]: loss 1.335322
[epoch16, step2248]: loss 0.861156
[epoch16, step2249]: loss 0.877870
[epoch16, step2250]: loss 1.991522
[epoch16, step2251]: loss 1.119424
[epoch16, step2252]: loss 1.027115
[epoch16, step2253]: loss 0.332258
[epoch16, step2254]: loss 6.155820
[epoch16, step2255]: loss 12.017387
[epoch16, step2256]: loss 7.333413
[epoch16, step2257]: loss 10.177990
[epoch16, step2258]: loss 6.122319
[epoch16, step2259]: loss 3.621774
[epoch16, step2260]: loss 1.128985
[epoch16, step2261]: loss 2.141568
[epoch16, step2262]: loss 1.067111
[epoch16, step2263]: loss 9.925356
[epoch16, step2264]: loss 1.118580
[epoch16, step2265]: loss 29.736288
[epoch16, step2266]: loss 1.105063
[epoch16, step2267]: loss 1.342329
[epoch16, step2268]: loss 0.621467
[epoch16, step2269]: loss 2.574142
[epoch16, step2270]: loss 1.627580
[epoch16, step2271]: loss 1.026324
[epoch16, step2272]: loss 0.809326
[epoch16, step2273]: loss 17.811314
[epoch16, step2274]: loss 2.956209
[epoch16, step2275]: loss 0.992648
[epoch16, step2276]: loss 3.624735
[epoch16, step2277]: loss 1.388979
[epoch16, step2278]: loss 14.033544
[epoch16, step2279]: loss 1.362496
[epoch16, step2280]: loss 2.144958
[epoch16, step2281]: loss 2.347191
[epoch16, step2282]: loss 0.597409
[epoch16, step2283]: loss 0.677905
[epoch16, step2284]: loss 6.702185
[epoch16, step2285]: loss 1.521742
[epoch16, step2286]: loss 0.833431
[epoch16, step2287]: loss 0.955931
[epoch16, step2288]: loss 1.101933
[epoch16, step2289]: loss 1.069305
[epoch16, step2290]: loss 1.377034
[epoch16, step2291]: loss 7.181325
[epoch16, step2292]: loss 2.148023
[epoch16, step2293]: loss 11.545926
[epoch16, step2294]: loss 8.968562
[epoch16, step2295]: loss 1.032428
[epoch16, step2296]: loss 1.548450
[epoch16, step2297]: loss 7.114801
[epoch16, step2298]: loss 2.211593
[epoch16, step2299]: loss 0.983107
[epoch16, step2300]: loss 3.464328
[epoch16, step2301]: loss 8.137581
[epoch16, step2302]: loss 1.620834
[epoch16, step2303]: loss 11.569755
[epoch16, step2304]: loss 1.312547
[epoch16, step2305]: loss 4.381797
[epoch16, step2306]: loss 1.375745
[epoch16, step2307]: loss 2.437428
[epoch16, step2308]: loss 16.465103
[epoch16, step2309]: loss 0.889257
[epoch16, step2310]: loss 0.598379
[epoch16, step2311]: loss 10.495355
[epoch16, step2312]: loss 3.658399
[epoch16, step2313]: loss 1.890729
[epoch16, step2314]: loss 9.594175
[epoch16, step2315]: loss 1.302566
[epoch16, step2316]: loss 1.212188
[epoch16, step2317]: loss 1.795199
[epoch16, step2318]: loss 3.217375
[epoch16, step2319]: loss 3.097143
[epoch16, step2320]: loss 9.966396
[epoch16, step2321]: loss 7.557463
[epoch16, step2322]: loss 1.207914
[epoch16, step2323]: loss 10.482604
[epoch16, step2324]: loss 2.604929
[epoch16, step2325]: loss 0.967547
[epoch16, step2326]: loss 0.702936
[epoch16, step2327]: loss 0.878200
[epoch16, step2328]: loss 7.717927
[epoch16, step2329]: loss 2.709526
[epoch16, step2330]: loss 0.814781
[epoch16, step2331]: loss 0.862152
[epoch16, step2332]: loss 10.229007
[epoch16, step2333]: loss 0.897502
[epoch16, step2334]: loss 1.030549
[epoch16, step2335]: loss 5.654673
[epoch16, step2336]: loss 5.359833
[epoch16, step2337]: loss 12.059616
[epoch16, step2338]: loss 3.700419
[epoch16, step2339]: loss 16.614941
[epoch16, step2340]: loss 0.818993
[epoch16, step2341]: loss 0.693010
[epoch16, step2342]: loss 1.550682
[epoch16, step2343]: loss 3.123278
[epoch16, step2344]: loss 1.437063
[epoch16, step2345]: loss 1.029692
[epoch16, step2346]: loss 0.774969
[epoch16, step2347]: loss 11.617912
[epoch16, step2348]: loss 1.621980
[epoch16, step2349]: loss 1.454517
[epoch16, step2350]: loss 9.008147
[epoch16, step2351]: loss 0.796351
[epoch16, step2352]: loss 9.707278
[epoch16, step2353]: loss 1.727010
[epoch16, step2354]: loss 7.575924
[epoch16, step2355]: loss 2.271851
[epoch16, step2356]: loss 1.764140
[epoch16, step2357]: loss 3.094688
[epoch16, step2358]: loss 0.876108
[epoch16, step2359]: loss 0.962993
[epoch16, step2360]: loss 1.169932
[epoch16, step2361]: loss 1.048718
[epoch16, step2362]: loss 16.249308
[epoch16, step2363]: loss 14.972354
[epoch16, step2364]: loss 1.740726
[epoch16, step2365]: loss 40.038948
[epoch16, step2366]: loss 0.549941
[epoch16, step2367]: loss 1.534572
[epoch16, step2368]: loss 0.883318
[epoch16, step2369]: loss 0.750570
[epoch16, step2370]: loss 0.627258
[epoch16, step2371]: loss 0.551221
[epoch16, step2372]: loss 0.581022
[epoch16, step2373]: loss 2.110934
[epoch16, step2374]: loss 28.829775
[epoch16, step2375]: loss 1.291625
[epoch16, step2376]: loss 1.700409
[epoch16, step2377]: loss 6.106034
[epoch16, step2378]: loss 8.134596
[epoch16, step2379]: loss 1.385451
[epoch16, step2380]: loss 0.814683
[epoch16, step2381]: loss 6.699336
[epoch16, step2382]: loss 13.623427
[epoch16, step2383]: loss 0.850709
[epoch16, step2384]: loss 0.905538
[epoch16, step2385]: loss 9.168163
[epoch16, step2386]: loss 1.343132
[epoch16, step2387]: loss 14.787474
[epoch16, step2388]: loss 0.975549
[epoch16, step2389]: loss 3.078637
[epoch16, step2390]: loss 4.301514
[epoch16, step2391]: loss 1.348129
[epoch16, step2392]: loss 1.530737
[epoch16, step2393]: loss 0.787329
[epoch16, step2394]: loss 1.882205
[epoch16, step2395]: loss 1.971286
[epoch16, step2396]: loss 3.176695
[epoch16, step2397]: loss 1.725428
[epoch16, step2398]: loss 1.876377
[epoch16, step2399]: loss 1.659660
[epoch16, step2400]: loss 1.720670
[epoch16, step2401]: loss 0.904838
[epoch16, step2402]: loss 1.570869
[epoch16, step2403]: loss 1.644585
[epoch16, step2404]: loss 1.714139
[epoch16, step2405]: loss 1.959026
[epoch16, step2406]: loss 1.697711
[epoch16, step2407]: loss 1.171737
[epoch16, step2408]: loss 2.552712
[epoch16, step2409]: loss 15.459066
[epoch16, step2410]: loss 2.167877
[epoch16, step2411]: loss 10.931217
[epoch16, step2412]: loss 9.448737
[epoch16, step2413]: loss 9.031878
[epoch16, step2414]: loss 2.522259
[epoch16, step2415]: loss 0.854872
[epoch16, step2416]: loss 3.320741
[epoch16, step2417]: loss 4.547487
[epoch16, step2418]: loss 1.130550
[epoch16, step2419]: loss 0.981672
[epoch16, step2420]: loss 1.327112
[epoch16, step2421]: loss 9.508168
[epoch16, step2422]: loss 3.845009
[epoch16, step2423]: loss 0.739852
[epoch16, step2424]: loss 1.106273
[epoch16, step2425]: loss 1.244262
[epoch16, step2426]: loss 0.966763
[epoch16, step2427]: loss 5.794307
[epoch16, step2428]: loss 2.188108
[epoch16, step2429]: loss 3.645635
[epoch16, step2430]: loss 2.247757
[epoch16, step2431]: loss 6.966644
[epoch16, step2432]: loss 1.126034
[epoch16, step2433]: loss 1.295019
[epoch16, step2434]: loss 2.264272
[epoch16, step2435]: loss 1.198769
[epoch16, step2436]: loss 4.154762
[epoch16, step2437]: loss 0.844369
[epoch16, step2438]: loss 0.525393
[epoch16, step2439]: loss 3.942887
[epoch16, step2440]: loss 1.896860
[epoch16, step2441]: loss 1.180107
[epoch16, step2442]: loss 8.139529
[epoch16, step2443]: loss 0.960216
[epoch16, step2444]: loss 0.906150
[epoch16, step2445]: loss 0.861363
[epoch16, step2446]: loss 0.599226
[epoch16, step2447]: loss 6.215626
[epoch16, step2448]: loss 1.620796
[epoch16, step2449]: loss 0.719653
[epoch16, step2450]: loss 1.230855
[epoch16, step2451]: loss 16.593971
[epoch16, step2452]: loss 2.025944
[epoch16, step2453]: loss 0.665379
[epoch16, step2454]: loss 0.974637
[epoch16, step2455]: loss 0.989184
[epoch16, step2456]: loss 13.118671
[epoch16, step2457]: loss 0.493401
[epoch16, step2458]: loss 1.808508
[epoch16, step2459]: loss 7.871310
[epoch16, step2460]: loss 3.348166
[epoch16, step2461]: loss 1.445534
[epoch16, step2462]: loss 0.825741
[epoch16, step2463]: loss 10.848205
[epoch16, step2464]: loss 2.815492
[epoch16, step2465]: loss 4.183524
[epoch16, step2466]: loss 22.269583
[epoch16, step2467]: loss 2.526245
[epoch16, step2468]: loss 2.279552
[epoch16, step2469]: loss 26.479147
[epoch16, step2470]: loss 1.253724
[epoch16, step2471]: loss 1.347975
[epoch16, step2472]: loss 0.671130
[epoch16, step2473]: loss 1.567454
[epoch16, step2474]: loss 0.999061
[epoch16, step2475]: loss 1.896208
[epoch16, step2476]: loss 3.438824
[epoch16, step2477]: loss 9.349413
[epoch16, step2478]: loss 0.570734
[epoch16, step2479]: loss 0.984413
[epoch16, step2480]: loss 0.731812
[epoch16, step2481]: loss 0.920891
[epoch16, step2482]: loss 1.100736
[epoch16, step2483]: loss 1.122827
[epoch16, step2484]: loss 0.695485
[epoch16, step2485]: loss 1.956702
[epoch16, step2486]: loss 2.096053
[epoch16, step2487]: loss 1.114017
[epoch16, step2488]: loss 0.819071
[epoch16, step2489]: loss 1.471279
[epoch16, step2490]: loss 1.096802
[epoch16, step2491]: loss 0.859859
[epoch16, step2492]: loss 0.947172
[epoch16, step2493]: loss 5.572507
[epoch16, step2494]: loss 1.041207
[epoch16, step2495]: loss 8.373196
[epoch16, step2496]: loss 2.987615
[epoch16, step2497]: loss 3.799456
[epoch16, step2498]: loss 1.779243
[epoch16, step2499]: loss 1.738481
[epoch16, step2500]: loss 1.086468
[epoch16, step2501]: loss 0.902221
[epoch16, step2502]: loss 0.680703
[epoch16, step2503]: loss 11.201008
[epoch16, step2504]: loss 1.241500
[epoch16, step2505]: loss 1.731287
[epoch16, step2506]: loss 10.771343
[epoch16, step2507]: loss 0.981145
[epoch16, step2508]: loss 5.997460
[epoch16, step2509]: loss 2.942614
[epoch16, step2510]: loss 5.125496
[epoch16, step2511]: loss 4.704460
[epoch16, step2512]: loss 8.138119
[epoch16, step2513]: loss 28.743496
[epoch16, step2514]: loss 0.922067
[epoch16, step2515]: loss 0.834976
[epoch16, step2516]: loss 0.851088
[epoch16, step2517]: loss 1.423151
[epoch16, step2518]: loss 0.747042
[epoch16, step2519]: loss 0.953021
[epoch16, step2520]: loss 4.659719
[epoch16, step2521]: loss 1.576760
[epoch16, step2522]: loss 1.742709
[epoch16, step2523]: loss 1.593270
[epoch16, step2524]: loss 1.038692
[epoch16, step2525]: loss 6.771366
[epoch16, step2526]: loss 1.439295
[epoch16, step2527]: loss 0.402584
[epoch16, step2528]: loss 2.279483
[epoch16, step2529]: loss 0.933010
[epoch16, step2530]: loss 1.015272
[epoch16, step2531]: loss 0.882423
[epoch16, step2532]: loss 2.211310
[epoch16, step2533]: loss 16.405006
[epoch16, step2534]: loss 1.521374
[epoch16, step2535]: loss 1.072411
[epoch16, step2536]: loss 0.765740
[epoch16, step2537]: loss 1.247065
[epoch16, step2538]: loss 4.536550
[epoch16, step2539]: loss 1.090585
[epoch16, step2540]: loss 16.856735
[epoch16, step2541]: loss 3.970092
[epoch16, step2542]: loss 0.787869
[epoch16, step2543]: loss 2.397927
[epoch16, step2544]: loss 1.609164
[epoch16, step2545]: loss 2.622921
[epoch16, step2546]: loss 1.319192
[epoch16, step2547]: loss 1.136907
[epoch16, step2548]: loss 2.611713
[epoch16, step2549]: loss 0.738791
[epoch16, step2550]: loss 3.771968
[epoch16, step2551]: loss 4.096929
[epoch16, step2552]: loss 1.339922
[epoch16, step2553]: loss 1.270531
[epoch16, step2554]: loss 0.888305
[epoch16, step2555]: loss 1.026527
[epoch16, step2556]: loss 0.732644
[epoch16, step2557]: loss 1.852313
[epoch16, step2558]: loss 8.565199
[epoch16, step2559]: loss 2.788719
[epoch16, step2560]: loss 0.910691
[epoch16, step2561]: loss 0.759724
[epoch16, step2562]: loss 6.005280
[epoch16, step2563]: loss 0.903719
[epoch16, step2564]: loss 1.006568
[epoch16, step2565]: loss 0.533887
[epoch16, step2566]: loss 2.443878
[epoch16, step2567]: loss 0.697964
[epoch16, step2568]: loss 1.790335
[epoch16, step2569]: loss 1.001395
[epoch16, step2570]: loss 6.715566
[epoch16, step2571]: loss 2.298748
[epoch16, step2572]: loss 1.031967
[epoch16, step2573]: loss 5.630017
[epoch16, step2574]: loss 0.817859
[epoch16, step2575]: loss 0.810898
[epoch16, step2576]: loss 1.317369
[epoch16, step2577]: loss 0.609863
[epoch16, step2578]: loss 10.874033
[epoch16, step2579]: loss 1.179392
[epoch16, step2580]: loss 1.813535
[epoch16, step2581]: loss 2.622578
[epoch16, step2582]: loss 1.350463
[epoch16, step2583]: loss 4.437331
[epoch16, step2584]: loss 1.165669
[epoch16, step2585]: loss 2.151290
[epoch16, step2586]: loss 0.944960
[epoch16, step2587]: loss 12.498723
[epoch16, step2588]: loss 7.398186
[epoch16, step2589]: loss 1.506249
[epoch16, step2590]: loss 0.984812
[epoch16, step2591]: loss 5.622971
[epoch16, step2592]: loss 1.792544
[epoch16, step2593]: loss 1.113394
[epoch16, step2594]: loss 0.541786
[epoch16, step2595]: loss 0.659461
[epoch16, step2596]: loss 0.622487
[epoch16, step2597]: loss 2.836805
[epoch16, step2598]: loss 1.336917
[epoch16, step2599]: loss 1.371397
[epoch16, step2600]: loss 1.035059
[epoch16, step2601]: loss 1.263385
[epoch16, step2602]: loss 15.296816
[epoch16, step2603]: loss 2.752516
[epoch16, step2604]: loss 12.014772
[epoch16, step2605]: loss 0.753508
[epoch16, step2606]: loss 7.903957
[epoch16, step2607]: loss 13.917703
[epoch16, step2608]: loss 1.170781
[epoch16, step2609]: loss 13.982665
[epoch16, step2610]: loss 1.782093
[epoch16, step2611]: loss 0.724830
[epoch16, step2612]: loss 0.927202
[epoch16, step2613]: loss 9.936284
[epoch16, step2614]: loss 0.818171
[epoch16, step2615]: loss 5.843509
[epoch16, step2616]: loss 0.892951
[epoch16, step2617]: loss 0.916245
[epoch16, step2618]: loss 1.437795
[epoch16, step2619]: loss 25.859474
[epoch16, step2620]: loss 23.962692
[epoch16, step2621]: loss 0.917616
[epoch16, step2622]: loss 1.866749
[epoch16, step2623]: loss 6.356798
[epoch16, step2624]: loss 1.380817
[epoch16, step2625]: loss 10.021875
[epoch16, step2626]: loss 1.224134
[epoch16, step2627]: loss 1.648530
[epoch16, step2628]: loss 17.886141
[epoch16, step2629]: loss 0.900082
[epoch16, step2630]: loss 10.544632
[epoch16, step2631]: loss 1.174950
[epoch16, step2632]: loss 1.434517
[epoch16, step2633]: loss 9.558414
[epoch16, step2634]: loss 7.073160
[epoch16, step2635]: loss 1.183993
[epoch16, step2636]: loss 10.457630
[epoch16, step2637]: loss 2.273970
[epoch16, step2638]: loss 4.036249
[epoch16, step2639]: loss 1.257005
[epoch16, step2640]: loss 6.001634
[epoch16, step2641]: loss 1.269848
[epoch16, step2642]: loss 1.195685
[epoch16, step2643]: loss 10.060525
[epoch16, step2644]: loss 1.532562
[epoch16, step2645]: loss 19.850800
[epoch16, step2646]: loss 0.944020
[epoch16, step2647]: loss 1.670391
[epoch16, step2648]: loss 2.497089
[epoch16, step2649]: loss 12.901572
[epoch16, step2650]: loss 7.377136
[epoch16, step2651]: loss 3.249799
[epoch16, step2652]: loss 1.439339
[epoch16, step2653]: loss 11.798007
[epoch16, step2654]: loss 0.992281
[epoch16, step2655]: loss 7.768017
[epoch16, step2656]: loss 2.152042
[epoch16, step2657]: loss 6.726143
[epoch16, step2658]: loss 1.246777
[epoch16, step2659]: loss 0.774888
[epoch16, step2660]: loss 20.193670
[epoch16, step2661]: loss 1.475475
[epoch16, step2662]: loss 0.701944
[epoch16, step2663]: loss 1.137309
[epoch16, step2664]: loss 1.389572
[epoch16, step2665]: loss 0.774108
[epoch16, step2666]: loss 2.396801
[epoch16, step2667]: loss 0.985984
[epoch16, step2668]: loss 1.325548
[epoch16, step2669]: loss 0.890504
[epoch16, step2670]: loss 1.753314
[epoch16, step2671]: loss 2.952469
[epoch16, step2672]: loss 4.647260
[epoch16, step2673]: loss 1.704857
[epoch16, step2674]: loss 2.308827
[epoch16, step2675]: loss 1.923911
[epoch16, step2676]: loss 3.917949
[epoch16, step2677]: loss 1.405656
[epoch16, step2678]: loss 1.358655
[epoch16, step2679]: loss 0.916547
[epoch16, step2680]: loss 1.080282
[epoch16, step2681]: loss 10.762078
[epoch16, step2682]: loss 1.094900
[epoch16, step2683]: loss 2.878583
[epoch16, step2684]: loss 39.922344
[epoch16, step2685]: loss 9.076027
[epoch16, step2686]: loss 0.851596
[epoch16, step2687]: loss 0.812934
[epoch16, step2688]: loss 1.119815
[epoch16, step2689]: loss 1.173935
[epoch16, step2690]: loss 0.547177
[epoch16, step2691]: loss 2.965266
[epoch16, step2692]: loss 1.175014
[epoch16, step2693]: loss 1.547933
[epoch16, step2694]: loss 1.199395
[epoch16, step2695]: loss 8.675639
[epoch16, step2696]: loss 1.827011
[epoch16, step2697]: loss 0.808139
[epoch16, step2698]: loss 3.791141
[epoch16, step2699]: loss 1.744028
[epoch16, step2700]: loss 9.390145
[epoch16, step2701]: loss 4.823008
[epoch16, step2702]: loss 1.564885
[epoch16, step2703]: loss 1.265575
[epoch16, step2704]: loss 2.573606
[epoch16, step2705]: loss 10.368692
[epoch16, step2706]: loss 2.714046
[epoch16, step2707]: loss 0.931158
[epoch16, step2708]: loss 0.928922
[epoch16, step2709]: loss 1.274475
[epoch16, step2710]: loss 0.906115
[epoch16, step2711]: loss 1.643436
[epoch16, step2712]: loss 3.134251
[epoch16, step2713]: loss 2.724182
[epoch16, step2714]: loss 1.303418
[epoch16, step2715]: loss 1.326206
[epoch16, step2716]: loss 22.646160
[epoch16, step2717]: loss 0.978150
[epoch16, step2718]: loss 9.043112
[epoch16, step2719]: loss 9.516646
[epoch16, step2720]: loss 4.101060
[epoch16, step2721]: loss 1.015320
[epoch16, step2722]: loss 4.665581
[epoch16, step2723]: loss 1.983109
[epoch16, step2724]: loss 6.201873
[epoch16, step2725]: loss 1.847970
[epoch16, step2726]: loss 1.216651
[epoch16, step2727]: loss 6.017798
[epoch16, step2728]: loss 14.677453
[epoch16, step2729]: loss 12.039198
[epoch16, step2730]: loss 3.670326
[epoch16, step2731]: loss 0.799988
[epoch16, step2732]: loss 0.727500
[epoch16, step2733]: loss 1.686695
[epoch16, step2734]: loss 1.471704
[epoch16, step2735]: loss 8.934624
[epoch16, step2736]: loss 1.789543
[epoch16, step2737]: loss 1.246412
[epoch16, step2738]: loss 1.262628
[epoch16, step2739]: loss 2.899777
[epoch16, step2740]: loss 1.203972
[epoch16, step2741]: loss 0.986221
[epoch16, step2742]: loss 0.878991
[epoch16, step2743]: loss 3.612941
[epoch16, step2744]: loss 4.125866
[epoch16, step2745]: loss 2.103108
[epoch16, step2746]: loss 0.885450
[epoch16, step2747]: loss 1.690456
[epoch16, step2748]: loss 1.236999
[epoch16, step2749]: loss 3.552645
[epoch16, step2750]: loss 2.102939
[epoch16, step2751]: loss 1.654763
[epoch16, step2752]: loss 0.879520
[epoch16, step2753]: loss 4.543272
[epoch16, step2754]: loss 8.152214
[epoch16, step2755]: loss 1.289237
[epoch16, step2756]: loss 1.534572
[epoch16, step2757]: loss 5.163430
[epoch16, step2758]: loss 0.783125
[epoch16, step2759]: loss 0.884225
[epoch16, step2760]: loss 1.064014
[epoch16, step2761]: loss 2.169146
[epoch16, step2762]: loss 0.925100
[epoch16, step2763]: loss 0.755467
[epoch16, step2764]: loss 10.157375
[epoch16, step2765]: loss 10.989121
[epoch16, step2766]: loss 0.640206
[epoch16, step2767]: loss 0.848796
[epoch16, step2768]: loss 18.592142
[epoch16, step2769]: loss 2.628906
[epoch16, step2770]: loss 1.289491
[epoch16, step2771]: loss 6.013609
[epoch16, step2772]: loss 1.263754
[epoch16, step2773]: loss 3.508369
[epoch16, step2774]: loss 17.338480
[epoch16, step2775]: loss 1.337534
[epoch16, step2776]: loss 1.321709
[epoch16, step2777]: loss 1.371008
[epoch16, step2778]: loss 1.564388
[epoch16, step2779]: loss 10.345219
[epoch16, step2780]: loss 9.920162
[epoch16, step2781]: loss 1.513515
[epoch16, step2782]: loss 5.414172
[epoch16, step2783]: loss 0.839783
[epoch16, step2784]: loss 2.219365
[epoch16, step2785]: loss 1.239422
[epoch16, step2786]: loss 2.164934
[epoch16, step2787]: loss 6.441959
[epoch16, step2788]: loss 2.279644
[epoch16, step2789]: loss 1.904912
[epoch16, step2790]: loss 1.380817
[epoch16, step2791]: loss 1.085092
[epoch16, step2792]: loss 2.403347
[epoch16, step2793]: loss 2.761108
[epoch16, step2794]: loss 8.207981
[epoch16, step2795]: loss 1.348005
[epoch16, step2796]: loss 1.049873
[epoch16, step2797]: loss 2.602440
[epoch16, step2798]: loss 0.478146
[epoch16, step2799]: loss 0.869337
[epoch16, step2800]: loss 1.451104
[epoch16, step2801]: loss 0.958098
[epoch16, step2802]: loss 1.810354
[epoch16, step2803]: loss 0.778092
[epoch16, step2804]: loss 10.013118
[epoch16, step2805]: loss 0.903490
[epoch16, step2806]: loss 4.664503
[epoch16, step2807]: loss 11.936976
[epoch16, step2808]: loss 5.321532
[epoch16, step2809]: loss 1.593075
[epoch16, step2810]: loss 9.661935
[epoch16, step2811]: loss 0.601663
[epoch16, step2812]: loss 7.511473
[epoch16, step2813]: loss 6.656099
[epoch16, step2814]: loss 1.488366
[epoch16, step2815]: loss 1.985603
[epoch16, step2816]: loss 0.669351
[epoch16, step2817]: loss 2.174413
[epoch16, step2818]: loss 1.569502
[epoch16, step2819]: loss 0.821372
[epoch16, step2820]: loss 1.680672
[epoch16, step2821]: loss 1.302273
[epoch16, step2822]: loss 10.156650
[epoch16, step2823]: loss 8.962687
[epoch16, step2824]: loss 2.549150
[epoch16, step2825]: loss 1.402892
[epoch16, step2826]: loss 1.974274
[epoch16, step2827]: loss 3.013811
[epoch16, step2828]: loss 1.071175
[epoch16, step2829]: loss 1.028738
[epoch16, step2830]: loss 4.977803
[epoch16, step2831]: loss 1.685926
[epoch16, step2832]: loss 1.137892
[epoch16, step2833]: loss 3.408015
[epoch16, step2834]: loss 12.742954
[epoch16, step2835]: loss 1.946728
[epoch16, step2836]: loss 1.116216
[epoch16, step2837]: loss 1.378493
[epoch16, step2838]: loss 0.981226
[epoch16, step2839]: loss 1.166408
[epoch16, step2840]: loss 0.935028
[epoch16, step2841]: loss 13.971337
[epoch16, step2842]: loss 1.290865
[epoch16, step2843]: loss 1.147766
[epoch16, step2844]: loss 2.932069
[epoch16, step2845]: loss 0.834488
[epoch16, step2846]: loss 1.179816
[epoch16, step2847]: loss 15.803317
[epoch16, step2848]: loss 1.425900
[epoch16, step2849]: loss 1.555563
[epoch16, step2850]: loss 10.170471
[epoch16, step2851]: loss 2.156834
[epoch16, step2852]: loss 1.724506
[epoch16, step2853]: loss 0.956998
[epoch16, step2854]: loss 0.964556
[epoch16, step2855]: loss 1.471696
[epoch16, step2856]: loss 1.472750
[epoch16, step2857]: loss 2.109911
[epoch16, step2858]: loss 1.578437
[epoch16, step2859]: loss 2.765917
[epoch16, step2860]: loss 0.726029
[epoch16, step2861]: loss 1.394977
[epoch16, step2862]: loss 0.789660
[epoch16, step2863]: loss 10.769760
[epoch16, step2864]: loss 4.529947
[epoch16, step2865]: loss 1.539119
[epoch16, step2866]: loss 3.042531
[epoch16, step2867]: loss 1.871903
[epoch16, step2868]: loss 0.661764
[epoch16, step2869]: loss 0.617575
[epoch16, step2870]: loss 1.172975
[epoch16, step2871]: loss 12.726082
[epoch16, step2872]: loss 0.876628
[epoch16, step2873]: loss 1.650473
[epoch16, step2874]: loss 2.459260
[epoch16, step2875]: loss 17.239996
[epoch16, step2876]: loss 0.960919
[epoch16, step2877]: loss 12.428144
[epoch16, step2878]: loss 3.271923
[epoch16, step2879]: loss 0.746874
[epoch16, step2880]: loss 11.879898
[epoch16, step2881]: loss 2.334352
[epoch16, step2882]: loss 2.210572
[epoch16, step2883]: loss 12.167633
[epoch16, step2884]: loss 2.134863
[epoch16, step2885]: loss 8.243466
[epoch16, step2886]: loss 4.945650
[epoch16, step2887]: loss 4.289186
[epoch16, step2888]: loss 2.582018
[epoch16, step2889]: loss 7.069926
[epoch16, step2890]: loss 1.318707
[epoch16, step2891]: loss 7.205616
[epoch16, step2892]: loss 0.794513
[epoch16, step2893]: loss 4.039662
[epoch16, step2894]: loss 1.648941
[epoch16, step2895]: loss 5.120299
[epoch16, step2896]: loss 1.431619
[epoch16, step2897]: loss 2.115623
[epoch16, step2898]: loss 1.739451
[epoch16, step2899]: loss 0.746969
[epoch16, step2900]: loss 17.828779
[epoch16, step2901]: loss 0.565392
[epoch16, step2902]: loss 1.286442
[epoch16, step2903]: loss 0.949779
[epoch16, step2904]: loss 1.280589
[epoch16, step2905]: loss 0.918443
[epoch16, step2906]: loss 6.933972
[epoch16, step2907]: loss 1.073818
[epoch16, step2908]: loss 0.807558
[epoch16, step2909]: loss 37.025764
[epoch16, step2910]: loss 6.083667
[epoch16, step2911]: loss 2.106492
[epoch16, step2912]: loss 1.326409
[epoch16, step2913]: loss 6.135290
[epoch16, step2914]: loss 2.267615
[epoch16, step2915]: loss 5.070623
[epoch16, step2916]: loss 24.528963
[epoch16, step2917]: loss 17.712265
[epoch16, step2918]: loss 10.821734
[epoch16, step2919]: loss 7.754932
[epoch16, step2920]: loss 2.758809
[epoch16, step2921]: loss 1.380055
[epoch16, step2922]: loss 17.471378
[epoch16, step2923]: loss 1.711920
[epoch16, step2924]: loss 1.203875
[epoch16, step2925]: loss 2.880594
[epoch16, step2926]: loss 14.548895
[epoch16, step2927]: loss 0.715239
[epoch16, step2928]: loss 0.690068
[epoch16, step2929]: loss 16.245663
[epoch16, step2930]: loss 1.847574
[epoch16, step2931]: loss 13.026135
[epoch16, step2932]: loss 6.703471
[epoch16, step2933]: loss 2.084355
[epoch16, step2934]: loss 0.597578
[epoch16, step2935]: loss 2.788506
[epoch16, step2936]: loss 1.013956
[epoch16, step2937]: loss 14.753693
[epoch16, step2938]: loss 1.381987
[epoch16, step2939]: loss 2.125699
[epoch16, step2940]: loss 6.123274
[epoch16, step2941]: loss 10.301185
[epoch16, step2942]: loss 1.037492
[epoch16, step2943]: loss 11.207129
[epoch16, step2944]: loss 0.950765
[epoch16, step2945]: loss 0.688037
[epoch16, step2946]: loss 1.101044
[epoch16, step2947]: loss 1.009677
[epoch16, step2948]: loss 11.521735
[epoch16, step2949]: loss 2.108249
[epoch16, step2950]: loss 1.132143
[epoch16, step2951]: loss 5.527896
[epoch16, step2952]: loss 1.743207
[epoch16, step2953]: loss 1.776159
[epoch16, step2954]: loss 11.337774
[epoch16, step2955]: loss 1.914397
[epoch16, step2956]: loss 1.055077
[epoch16, step2957]: loss 2.146332
[epoch16, step2958]: loss 0.604360
[epoch16, step2959]: loss 0.608318
[epoch16, step2960]: loss 15.597978
[epoch16, step2961]: loss 5.458259
[epoch16, step2962]: loss 11.991183
[epoch16, step2963]: loss 2.485071
[epoch16, step2964]: loss 1.823956
[epoch16, step2965]: loss 2.649836
[epoch16, step2966]: loss 8.444000
[epoch16, step2967]: loss 3.087598
[epoch16, step2968]: loss 11.866073
[epoch16, step2969]: loss 1.110363
[epoch16, step2970]: loss 1.377708
[epoch16, step2971]: loss 4.210959
[epoch16, step2972]: loss 17.341091
[epoch16, step2973]: loss 1.283065
[epoch16, step2974]: loss 2.390002
[epoch16, step2975]: loss 2.852808
[epoch16, step2976]: loss 0.742996
[epoch16, step2977]: loss 1.159316
[epoch16, step2978]: loss 1.606713
[epoch16, step2979]: loss 1.567099
[epoch16, step2980]: loss 1.857696
[epoch16, step2981]: loss 1.908408
[epoch16, step2982]: loss 12.670856
[epoch16, step2983]: loss 1.296438
[epoch16, step2984]: loss 1.311707
[epoch16, step2985]: loss 0.574173
[epoch16, step2986]: loss 1.374464
[epoch16, step2987]: loss 2.119465
[epoch16, step2988]: loss 0.624556
[epoch16, step2989]: loss 6.596474
[epoch16, step2990]: loss 0.659963
[epoch16, step2991]: loss 2.511656
[epoch16, step2992]: loss 4.286311
[epoch16, step2993]: loss 10.480397
[epoch16, step2994]: loss 2.539298
[epoch16, step2995]: loss 1.779511
[epoch16, step2996]: loss 1.812084
[epoch16, step2997]: loss 0.608309
[epoch16, step2998]: loss 1.556592
[epoch16, step2999]: loss 4.190042
[epoch16, step3000]: loss 1.405381
[epoch16, step3001]: loss 1.342857
[epoch16, step3002]: loss 2.604535
[epoch16, step3003]: loss 1.118055
[epoch16, step3004]: loss 0.734058
[epoch16, step3005]: loss 1.616563
[epoch16, step3006]: loss 7.636337
[epoch16, step3007]: loss 1.017146
[epoch16, step3008]: loss 11.553194
[epoch16, step3009]: loss 11.688082
[epoch16, step3010]: loss 4.909242
[epoch16, step3011]: loss 1.131773
[epoch16, step3012]: loss 1.944580
[epoch16, step3013]: loss 1.970720
[epoch16, step3014]: loss 12.099361
[epoch16, step3015]: loss 9.065718
[epoch16, step3016]: loss 3.250301
[epoch16, step3017]: loss 1.326760
[epoch16, step3018]: loss 4.396583
[epoch16, step3019]: loss 0.956511
[epoch16, step3020]: loss 1.760496
[epoch16, step3021]: loss 1.261288
[epoch16, step3022]: loss 9.594446
[epoch16, step3023]: loss 2.896222
[epoch16, step3024]: loss 0.948948
[epoch16, step3025]: loss 5.420018
[epoch16, step3026]: loss 1.712969
[epoch16, step3027]: loss 0.869948
[epoch16, step3028]: loss 3.548771
[epoch16, step3029]: loss 0.774475
[epoch16, step3030]: loss 2.484005
[epoch16, step3031]: loss 10.275441
[epoch16, step3032]: loss 0.862588
[epoch16, step3033]: loss 4.208618
[epoch16, step3034]: loss 0.958070
[epoch16, step3035]: loss 2.107199
[epoch16, step3036]: loss 1.579305
[epoch16, step3037]: loss 1.709504
[epoch16, step3038]: loss 3.345065
[epoch16, step3039]: loss 2.098987
[epoch16, step3040]: loss 0.864277
[epoch16, step3041]: loss 2.437751
[epoch16, step3042]: loss 6.808434
[epoch16, step3043]: loss 6.156352
[epoch16, step3044]: loss 0.682119
[epoch16, step3045]: loss 0.744504
[epoch16, step3046]: loss 0.911641
[epoch16, step3047]: loss 1.008350
[epoch16, step3048]: loss 1.461037
[epoch16, step3049]: loss 37.288055
[epoch16, step3050]: loss 11.340742
[epoch16, step3051]: loss 6.934681
[epoch16, step3052]: loss 5.316580
[epoch16, step3053]: loss 1.150781
[epoch16, step3054]: loss 1.678806
[epoch16, step3055]: loss 1.062037
[epoch16, step3056]: loss 1.000856
[epoch16, step3057]: loss 1.109122
[epoch16, step3058]: loss 1.604583
[epoch16, step3059]: loss 3.017312
[epoch16, step3060]: loss 1.661364
[epoch16, step3061]: loss 0.708473
[epoch16, step3062]: loss 1.947888
[epoch16, step3063]: loss 2.400399
[epoch16, step3064]: loss 9.012908
[epoch16, step3065]: loss 0.629430
[epoch16, step3066]: loss 1.346324
[epoch16, step3067]: loss 1.048941
[epoch16, step3068]: loss 1.534430
[epoch16, step3069]: loss 1.560893
[epoch16, step3070]: loss 2.938848
[epoch16, step3071]: loss 1.040894
[epoch16, step3072]: loss 5.182038
[epoch16, step3073]: loss 0.661735
[epoch16, step3074]: loss 0.758082
[epoch16, step3075]: loss 6.265058
[epoch16, step3076]: loss 1.049535

[epoch16]: avg loss 1.049535

[epoch17, step1]: loss 0.630420
[epoch17, step2]: loss 3.320332
[epoch17, step3]: loss 3.213352
[epoch17, step4]: loss 5.174617
[epoch17, step5]: loss 1.733705
[epoch17, step6]: loss 0.789295
[epoch17, step7]: loss 1.691914
[epoch17, step8]: loss 1.638489
[epoch17, step9]: loss 2.513071
[epoch17, step10]: loss 2.962605
[epoch17, step11]: loss 1.080903
[epoch17, step12]: loss 1.357659
[epoch17, step13]: loss 2.905722
[epoch17, step14]: loss 2.663644
[epoch17, step15]: loss 1.070368
[epoch17, step16]: loss 2.395584
[epoch17, step17]: loss 2.309435
[epoch17, step18]: loss 1.815542
[epoch17, step19]: loss 0.958119
[epoch17, step20]: loss 0.663721
[epoch17, step21]: loss 0.844424
[epoch17, step22]: loss 1.869894
[epoch17, step23]: loss 2.430572
[epoch17, step24]: loss 1.134474
[epoch17, step25]: loss 10.149292
[epoch17, step26]: loss 2.768437
[epoch17, step27]: loss 5.595182
[epoch17, step28]: loss 1.150195
[epoch17, step29]: loss 28.413092
[epoch17, step30]: loss 0.896356
[epoch17, step31]: loss 1.982392
[epoch17, step32]: loss 4.206462
[epoch17, step33]: loss 1.945180
[epoch17, step34]: loss 0.618872
[epoch17, step35]: loss 3.957518
[epoch17, step36]: loss 1.196849
[epoch17, step37]: loss 0.790535
[epoch17, step38]: loss 1.471146
[epoch17, step39]: loss 0.738987
[epoch17, step40]: loss 0.791887
[epoch17, step41]: loss 15.133631
[epoch17, step42]: loss 1.822528
[epoch17, step43]: loss 1.611072
[epoch17, step44]: loss 0.987296
[epoch17, step45]: loss 0.767493
[epoch17, step46]: loss 4.215731
[epoch17, step47]: loss 1.497562
[epoch17, step48]: loss 1.963708
[epoch17, step49]: loss 1.047998
[epoch17, step50]: loss 4.377760
[epoch17, step51]: loss 0.679386
[epoch17, step52]: loss 1.054217
[epoch17, step53]: loss 2.035145
[epoch17, step54]: loss 1.733661
[epoch17, step55]: loss 7.039839
[epoch17, step56]: loss 5.688246
[epoch17, step57]: loss 2.977642
[epoch17, step58]: loss 1.808101
[epoch17, step59]: loss 0.839804
[epoch17, step60]: loss 0.903173
[epoch17, step61]: loss 1.725235
[epoch17, step62]: loss 11.391282
[epoch17, step63]: loss 0.804173
[epoch17, step64]: loss 3.115949
[epoch17, step65]: loss 11.091616
[epoch17, step66]: loss 0.883604
[epoch17, step67]: loss 4.848060
[epoch17, step68]: loss 0.892286
[epoch17, step69]: loss 2.744303
[epoch17, step70]: loss 3.148381
[epoch17, step71]: loss 0.851086
[epoch17, step72]: loss 1.338409
[epoch17, step73]: loss 0.397539
[epoch17, step74]: loss 2.817661
[epoch17, step75]: loss 5.313594
[epoch17, step76]: loss 1.653923
[epoch17, step77]: loss 4.938859
[epoch17, step78]: loss 1.266496
[epoch17, step79]: loss 1.059715
[epoch17, step80]: loss 15.765928
[epoch17, step81]: loss 1.066957
[epoch17, step82]: loss 8.604845
[epoch17, step83]: loss 2.618802
[epoch17, step84]: loss 0.798714
[epoch17, step85]: loss 1.136035
[epoch17, step86]: loss 1.490915
[epoch17, step87]: loss 1.184790
[epoch17, step88]: loss 1.861358
[epoch17, step89]: loss 2.947811
[epoch17, step90]: loss 2.225332
[epoch17, step91]: loss 1.191780
[epoch17, step92]: loss 1.893754
[epoch17, step93]: loss 1.048410
[epoch17, step94]: loss 2.635449
[epoch17, step95]: loss 1.173958
[epoch17, step96]: loss 13.891406
[epoch17, step97]: loss 11.258951
[epoch17, step98]: loss 5.969777
[epoch17, step99]: loss 0.939434
[epoch17, step100]: loss 3.706640
[epoch17, step101]: loss 10.213436
[epoch17, step102]: loss 1.217298
[epoch17, step103]: loss 1.133607
[epoch17, step104]: loss 0.864461
[epoch17, step105]: loss 3.697277
[epoch17, step106]: loss 1.555955
[epoch17, step107]: loss 0.832634
[epoch17, step108]: loss 0.977487
[epoch17, step109]: loss 3.143847
[epoch17, step110]: loss 1.436826
[epoch17, step111]: loss 2.638102
[epoch17, step112]: loss 1.119356
[epoch17, step113]: loss 1.535341
[epoch17, step114]: loss 8.755718
[epoch17, step115]: loss 1.399111
[epoch17, step116]: loss 1.646660
[epoch17, step117]: loss 3.643616
[epoch17, step118]: loss 1.706952
[epoch17, step119]: loss 0.738595
[epoch17, step120]: loss 1.197707
[epoch17, step121]: loss 9.466823
[epoch17, step122]: loss 1.048251
[epoch17, step123]: loss 2.965207
[epoch17, step124]: loss 7.684785
[epoch17, step125]: loss 1.234218
[epoch17, step126]: loss 10.839535
[epoch17, step127]: loss 1.259963
[epoch17, step128]: loss 1.166724
[epoch17, step129]: loss 2.397258
[epoch17, step130]: loss 1.236177
[epoch17, step131]: loss 1.389738
[epoch17, step132]: loss 0.795017
[epoch17, step133]: loss 1.312189
[epoch17, step134]: loss 6.068378
[epoch17, step135]: loss 5.539947
[epoch17, step136]: loss 2.199703
[epoch17, step137]: loss 0.770459
[epoch17, step138]: loss 3.755900
[epoch17, step139]: loss 6.547495
[epoch17, step140]: loss 0.925181
[epoch17, step141]: loss 3.644178
[epoch17, step142]: loss 3.397869
[epoch17, step143]: loss 1.120006
[epoch17, step144]: loss 1.113604
[epoch17, step145]: loss 8.016802
[epoch17, step146]: loss 7.082322
[epoch17, step147]: loss 1.266047
[epoch17, step148]: loss 1.996207
[epoch17, step149]: loss 1.389637
[epoch17, step150]: loss 1.031730
[epoch17, step151]: loss 0.824240
[epoch17, step152]: loss 2.927811
[epoch17, step153]: loss 3.600919
[epoch17, step154]: loss 5.003233
[epoch17, step155]: loss 0.841674
[epoch17, step156]: loss 2.409149
[epoch17, step157]: loss 2.040501
[epoch17, step158]: loss 0.794531
[epoch17, step159]: loss 2.398469
[epoch17, step160]: loss 0.883746
[epoch17, step161]: loss 0.871880
[epoch17, step162]: loss 0.855300
[epoch17, step163]: loss 1.126467
[epoch17, step164]: loss 3.690512
[epoch17, step165]: loss 0.683462
[epoch17, step166]: loss 0.726129
[epoch17, step167]: loss 0.729073
[epoch17, step168]: loss 27.317463
[epoch17, step169]: loss 9.075919
[epoch17, step170]: loss 1.782091
[epoch17, step171]: loss 0.772813
[epoch17, step172]: loss 0.999443
[epoch17, step173]: loss 0.702773
[epoch17, step174]: loss 3.527857
[epoch17, step175]: loss 1.830400
[epoch17, step176]: loss 2.826276
[epoch17, step177]: loss 1.709440
[epoch17, step178]: loss 0.995108
[epoch17, step179]: loss 9.074707
[epoch17, step180]: loss 0.697720
[epoch17, step181]: loss 8.892838
[epoch17, step182]: loss 9.156228
[epoch17, step183]: loss 0.624581
[epoch17, step184]: loss 0.808126
[epoch17, step185]: loss 1.247454
[epoch17, step186]: loss 7.915281
[epoch17, step187]: loss 1.529280
[epoch17, step188]: loss 1.757434
[epoch17, step189]: loss 9.713386
[epoch17, step190]: loss 1.993754
[epoch17, step191]: loss 2.638452
[epoch17, step192]: loss 5.474924
[epoch17, step193]: loss 1.090230
[epoch17, step194]: loss 0.777406
[epoch17, step195]: loss 1.532679
[epoch17, step196]: loss 2.244427
[epoch17, step197]: loss 4.370511
[epoch17, step198]: loss 11.934561
[epoch17, step199]: loss 7.731822
[epoch17, step200]: loss 2.692412
[epoch17, step201]: loss 10.388245
[epoch17, step202]: loss 1.488425
[epoch17, step203]: loss 0.719200
[epoch17, step204]: loss 2.732310
[epoch17, step205]: loss 0.666543
[epoch17, step206]: loss 6.958865
[epoch17, step207]: loss 0.899228
[epoch17, step208]: loss 0.881766
[epoch17, step209]: loss 0.994599
[epoch17, step210]: loss 1.421458
[epoch17, step211]: loss 2.095424
[epoch17, step212]: loss 1.027996
[epoch17, step213]: loss 1.142779
[epoch17, step214]: loss 12.309157
[epoch17, step215]: loss 0.661291
[epoch17, step216]: loss 0.772463
[epoch17, step217]: loss 1.572912
[epoch17, step218]: loss 3.071864
[epoch17, step219]: loss 0.713771
[epoch17, step220]: loss 12.773672
[epoch17, step221]: loss 1.999057
[epoch17, step222]: loss 6.135144
[epoch17, step223]: loss 1.446521
[epoch17, step224]: loss 1.424857
[epoch17, step225]: loss 2.436553
[epoch17, step226]: loss 1.199598
[epoch17, step227]: loss 2.684421
[epoch17, step228]: loss 1.729599
[epoch17, step229]: loss 6.803676
[epoch17, step230]: loss 1.557177
[epoch17, step231]: loss 12.250149
[epoch17, step232]: loss 1.532996
[epoch17, step233]: loss 1.339630
[epoch17, step234]: loss 1.196433
[epoch17, step235]: loss 1.664100
[epoch17, step236]: loss 0.599562
[epoch17, step237]: loss 5.520522
[epoch17, step238]: loss 1.705857
[epoch17, step239]: loss 10.983655
[epoch17, step240]: loss 0.851096
[epoch17, step241]: loss 1.916888
[epoch17, step242]: loss 1.262753
[epoch17, step243]: loss 1.583178
[epoch17, step244]: loss 1.481049
[epoch17, step245]: loss 5.681786
[epoch17, step246]: loss 1.607418
[epoch17, step247]: loss 0.489012
[epoch17, step248]: loss 0.683288
[epoch17, step249]: loss 3.844738
[epoch17, step250]: loss 3.118685
[epoch17, step251]: loss 5.368298
[epoch17, step252]: loss 1.008033
[epoch17, step253]: loss 1.450744
[epoch17, step254]: loss 1.215603
[epoch17, step255]: loss 1.507585
[epoch17, step256]: loss 0.955082
[epoch17, step257]: loss 2.042185
[epoch17, step258]: loss 0.913967
[epoch17, step259]: loss 8.540495
[epoch17, step260]: loss 2.101360
[epoch17, step261]: loss 3.429589
[epoch17, step262]: loss 0.660100
[epoch17, step263]: loss 0.622961
[epoch17, step264]: loss 2.056124
[epoch17, step265]: loss 0.526275
[epoch17, step266]: loss 0.776758
[epoch17, step267]: loss 1.183730
[epoch17, step268]: loss 0.696539
[epoch17, step269]: loss 2.272910
[epoch17, step270]: loss 3.479533
[epoch17, step271]: loss 1.021781
[epoch17, step272]: loss 1.669652
[epoch17, step273]: loss 1.076272
[epoch17, step274]: loss 5.370827
[epoch17, step275]: loss 2.306055
[epoch17, step276]: loss 4.572695
[epoch17, step277]: loss 1.917718
[epoch17, step278]: loss 17.428734
[epoch17, step279]: loss 1.514686
[epoch17, step280]: loss 0.772449
[epoch17, step281]: loss 1.018005
[epoch17, step282]: loss 1.251340
[epoch17, step283]: loss 0.510945
[epoch17, step284]: loss 6.835393
[epoch17, step285]: loss 1.473624
[epoch17, step286]: loss 1.203324
[epoch17, step287]: loss 1.002834
[epoch17, step288]: loss 1.819032
[epoch17, step289]: loss 1.192407
[epoch17, step290]: loss 11.857605
[epoch17, step291]: loss 2.280234
[epoch17, step292]: loss 1.393891
[epoch17, step293]: loss 0.673571
[epoch17, step294]: loss 18.937065
[epoch17, step295]: loss 7.595474
[epoch17, step296]: loss 7.300727
[epoch17, step297]: loss 2.499195
[epoch17, step298]: loss 26.290226
[epoch17, step299]: loss 0.797449
[epoch17, step300]: loss 1.975706
[epoch17, step301]: loss 1.406405
[epoch17, step302]: loss 0.956879
[epoch17, step303]: loss 9.503389
[epoch17, step304]: loss 11.977680
[epoch17, step305]: loss 6.174951
[epoch17, step306]: loss 1.545765
[epoch17, step307]: loss 4.922536
[epoch17, step308]: loss 5.730062
[epoch17, step309]: loss 11.034032
[epoch17, step310]: loss 0.832834
[epoch17, step311]: loss 0.767758
[epoch17, step312]: loss 0.681129
[epoch17, step313]: loss 5.253530
[epoch17, step314]: loss 0.636181
[epoch17, step315]: loss 1.548477
[epoch17, step316]: loss 0.866838
[epoch17, step317]: loss 1.463973
[epoch17, step318]: loss 2.519248
[epoch17, step319]: loss 1.960202
[epoch17, step320]: loss 12.945157
[epoch17, step321]: loss 4.353749
[epoch17, step322]: loss 8.256847
[epoch17, step323]: loss 4.590989
[epoch17, step324]: loss 0.671476
[epoch17, step325]: loss 3.508104
[epoch17, step326]: loss 2.232902
[epoch17, step327]: loss 1.999224
[epoch17, step328]: loss 0.733723
[epoch17, step329]: loss 1.170273
[epoch17, step330]: loss 7.299749
[epoch17, step331]: loss 1.677605
[epoch17, step332]: loss 8.456200
[epoch17, step333]: loss 1.227756
[epoch17, step334]: loss 1.295689
[epoch17, step335]: loss 10.288152
[epoch17, step336]: loss 1.662772
[epoch17, step337]: loss 0.996040
[epoch17, step338]: loss 12.498748
[epoch17, step339]: loss 1.422237
[epoch17, step340]: loss 1.555438
[epoch17, step341]: loss 1.195881
[epoch17, step342]: loss 1.127742
[epoch17, step343]: loss 2.306466
[epoch17, step344]: loss 1.174511
[epoch17, step345]: loss 2.293735
[epoch17, step346]: loss 2.637331
[epoch17, step347]: loss 1.321960
[epoch17, step348]: loss 1.901333
[epoch17, step349]: loss 2.133357
[epoch17, step350]: loss 9.899727
[epoch17, step351]: loss 1.383795
[epoch17, step352]: loss 4.502092
[epoch17, step353]: loss 1.531388
[epoch17, step354]: loss 9.614648
[epoch17, step355]: loss 6.571716
[epoch17, step356]: loss 1.393528
[epoch17, step357]: loss 6.331312
[epoch17, step358]: loss 1.641184
[epoch17, step359]: loss 0.640786
[epoch17, step360]: loss 5.436295
[epoch17, step361]: loss 3.210879
[epoch17, step362]: loss 1.370394
[epoch17, step363]: loss 1.915765
[epoch17, step364]: loss 0.754737
[epoch17, step365]: loss 0.817985
[epoch17, step366]: loss 2.964464
[epoch17, step367]: loss 1.952607
[epoch17, step368]: loss 0.841893
[epoch17, step369]: loss 0.844293
[epoch17, step370]: loss 10.133172
[epoch17, step371]: loss 1.030023
[epoch17, step372]: loss 7.484149
[epoch17, step373]: loss 2.594058
[epoch17, step374]: loss 1.790953
[epoch17, step375]: loss 2.235050
[epoch17, step376]: loss 2.278988
[epoch17, step377]: loss 0.940281
[epoch17, step378]: loss 1.200516
[epoch17, step379]: loss 8.651170
[epoch17, step380]: loss 0.933166
[epoch17, step381]: loss 1.533006
[epoch17, step382]: loss 7.975311
[epoch17, step383]: loss 4.842199
[epoch17, step384]: loss 1.731338
[epoch17, step385]: loss 5.187624
[epoch17, step386]: loss 0.842624
[epoch17, step387]: loss 1.231766
[epoch17, step388]: loss 0.782569
[epoch17, step389]: loss 0.949806
[epoch17, step390]: loss 3.413576
[epoch17, step391]: loss 2.050891
[epoch17, step392]: loss 3.194882
[epoch17, step393]: loss 3.434109
[epoch17, step394]: loss 2.301130
[epoch17, step395]: loss 1.093498
[epoch17, step396]: loss 2.868118
[epoch17, step397]: loss 0.610139
[epoch17, step398]: loss 3.775401
[epoch17, step399]: loss 10.118705
[epoch17, step400]: loss 12.711793
[epoch17, step401]: loss 1.450215
[epoch17, step402]: loss 5.383859
[epoch17, step403]: loss 11.666583
[epoch17, step404]: loss 1.111201
[epoch17, step405]: loss 1.562992
[epoch17, step406]: loss 15.347794
[epoch17, step407]: loss 0.835746
[epoch17, step408]: loss 0.766043
[epoch17, step409]: loss 2.639482
[epoch17, step410]: loss 1.091350
[epoch17, step411]: loss 0.792994
[epoch17, step412]: loss 0.998062
[epoch17, step413]: loss 0.580956
[epoch17, step414]: loss 1.225701
[epoch17, step415]: loss 2.283196
[epoch17, step416]: loss 12.748053
[epoch17, step417]: loss 4.413480
[epoch17, step418]: loss 1.270943
[epoch17, step419]: loss 2.766937
[epoch17, step420]: loss 0.680729
[epoch17, step421]: loss 2.561591
[epoch17, step422]: loss 0.976526
[epoch17, step423]: loss 0.712291
[epoch17, step424]: loss 5.762681
[epoch17, step425]: loss 8.681993
[epoch17, step426]: loss 3.125975
[epoch17, step427]: loss 0.647766
[epoch17, step428]: loss 9.324838
[epoch17, step429]: loss 7.203313
[epoch17, step430]: loss 11.041887
[epoch17, step431]: loss 2.442488
[epoch17, step432]: loss 1.263699
[epoch17, step433]: loss 3.140641
[epoch17, step434]: loss 0.762180
[epoch17, step435]: loss 16.459661
[epoch17, step436]: loss 0.693838
[epoch17, step437]: loss 7.392313
[epoch17, step438]: loss 1.088469
[epoch17, step439]: loss 7.014615
[epoch17, step440]: loss 0.671716
[epoch17, step441]: loss 5.205046
[epoch17, step442]: loss 0.570695
[epoch17, step443]: loss 0.956189
[epoch17, step444]: loss 0.800759
[epoch17, step445]: loss 0.554332
[epoch17, step446]: loss 1.262100
[epoch17, step447]: loss 1.923755
[epoch17, step448]: loss 1.910583
[epoch17, step449]: loss 2.504566
[epoch17, step450]: loss 8.262930
[epoch17, step451]: loss 0.968820
[epoch17, step452]: loss 3.125180
[epoch17, step453]: loss 4.716696
[epoch17, step454]: loss 12.479255
[epoch17, step455]: loss 6.447031
[epoch17, step456]: loss 2.394737
[epoch17, step457]: loss 2.215993
[epoch17, step458]: loss 1.593409
[epoch17, step459]: loss 2.356909
[epoch17, step460]: loss 0.999758
[epoch17, step461]: loss 1.227452
[epoch17, step462]: loss 9.374635
[epoch17, step463]: loss 1.040032
[epoch17, step464]: loss 0.761710
[epoch17, step465]: loss 1.058997
[epoch17, step466]: loss 0.732849
[epoch17, step467]: loss 3.370271
[epoch17, step468]: loss 2.844287
[epoch17, step469]: loss 1.399527
[epoch17, step470]: loss 3.788627
[epoch17, step471]: loss 7.745365
[epoch17, step472]: loss 0.949484
[epoch17, step473]: loss 1.260775
[epoch17, step474]: loss 1.774186
[epoch17, step475]: loss 0.809249
[epoch17, step476]: loss 0.941987
[epoch17, step477]: loss 10.369884
[epoch17, step478]: loss 3.797669
[epoch17, step479]: loss 0.448673
[epoch17, step480]: loss 0.783347
[epoch17, step481]: loss 1.260274
[epoch17, step482]: loss 3.721549
[epoch17, step483]: loss 1.517967
[epoch17, step484]: loss 2.719054
[epoch17, step485]: loss 6.165667
[epoch17, step486]: loss 2.683267
[epoch17, step487]: loss 1.091485
[epoch17, step488]: loss 2.609678
[epoch17, step489]: loss 0.943369
[epoch17, step490]: loss 2.140840
[epoch17, step491]: loss 11.633581
[epoch17, step492]: loss 1.367062
[epoch17, step493]: loss 1.329129
[epoch17, step494]: loss 9.800982
[epoch17, step495]: loss 5.807954
[epoch17, step496]: loss 1.310508
[epoch17, step497]: loss 1.419382
[epoch17, step498]: loss 2.774484
[epoch17, step499]: loss 2.799631
[epoch17, step500]: loss 1.201238
[epoch17, step501]: loss 0.435659
[epoch17, step502]: loss 3.769889
[epoch17, step503]: loss 4.726893
[epoch17, step504]: loss 1.073816
[epoch17, step505]: loss 2.289894
[epoch17, step506]: loss 2.217847
[epoch17, step507]: loss 0.991893
[epoch17, step508]: loss 11.275111
[epoch17, step509]: loss 0.945205
[epoch17, step510]: loss 12.751082
[epoch17, step511]: loss 12.593196
[epoch17, step512]: loss 13.051589
[epoch17, step513]: loss 7.377462
[epoch17, step514]: loss 4.358757
[epoch17, step515]: loss 1.585090
[epoch17, step516]: loss 1.642830
[epoch17, step517]: loss 0.891641
[epoch17, step518]: loss 8.501586
[epoch17, step519]: loss 1.284595
[epoch17, step520]: loss 3.792010
[epoch17, step521]: loss 0.724800
[epoch17, step522]: loss 3.996634
[epoch17, step523]: loss 18.115805
[epoch17, step524]: loss 0.931337
[epoch17, step525]: loss 1.686200
[epoch17, step526]: loss 1.174500
[epoch17, step527]: loss 9.498498
[epoch17, step528]: loss 0.848544
[epoch17, step529]: loss 2.321632
[epoch17, step530]: loss 0.843120
[epoch17, step531]: loss 10.004878
[epoch17, step532]: loss 8.841103
[epoch17, step533]: loss 0.942941
[epoch17, step534]: loss 8.634026
[epoch17, step535]: loss 1.101565
[epoch17, step536]: loss 1.279529
[epoch17, step537]: loss 1.019702
[epoch17, step538]: loss 2.477745
[epoch17, step539]: loss 1.990506
[epoch17, step540]: loss 15.195747
[epoch17, step541]: loss 1.809895
[epoch17, step542]: loss 1.062978
[epoch17, step543]: loss 8.412141
[epoch17, step544]: loss 0.479807
[epoch17, step545]: loss 0.525883
[epoch17, step546]: loss 2.161562
[epoch17, step547]: loss 0.888681
[epoch17, step548]: loss 1.453236
[epoch17, step549]: loss 1.216347
[epoch17, step550]: loss 1.016815
[epoch17, step551]: loss 1.497403
[epoch17, step552]: loss 6.308817
[epoch17, step553]: loss 10.232885
[epoch17, step554]: loss 1.145653
[epoch17, step555]: loss 15.520109
[epoch17, step556]: loss 4.492292
[epoch17, step557]: loss 12.389588
[epoch17, step558]: loss 1.311322
[epoch17, step559]: loss 1.315297
[epoch17, step560]: loss 1.432010
[epoch17, step561]: loss 2.083651
[epoch17, step562]: loss 3.142914
[epoch17, step563]: loss 6.956926
[epoch17, step564]: loss 1.036250
[epoch17, step565]: loss 17.399786
[epoch17, step566]: loss 12.251535
[epoch17, step567]: loss 1.121919
[epoch17, step568]: loss 0.888680
[epoch17, step569]: loss 1.546274
[epoch17, step570]: loss 2.668850
[epoch17, step571]: loss 8.330601
[epoch17, step572]: loss 5.885450
[epoch17, step573]: loss 0.964349
[epoch17, step574]: loss 3.883750
[epoch17, step575]: loss 8.629190
[epoch17, step576]: loss 14.355657
[epoch17, step577]: loss 11.480122
[epoch17, step578]: loss 13.996789
[epoch17, step579]: loss 1.273603
[epoch17, step580]: loss 11.121727
[epoch17, step581]: loss 1.092416
[epoch17, step582]: loss 1.147614
[epoch17, step583]: loss 13.341154
[epoch17, step584]: loss 1.680534
[epoch17, step585]: loss 0.940186
[epoch17, step586]: loss 8.167428
[epoch17, step587]: loss 0.562326
[epoch17, step588]: loss 1.533864
[epoch17, step589]: loss 8.729309
[epoch17, step590]: loss 1.295203
[epoch17, step591]: loss 8.283209
[epoch17, step592]: loss 10.887541
[epoch17, step593]: loss 5.269391
[epoch17, step594]: loss 0.862025
[epoch17, step595]: loss 1.216645
[epoch17, step596]: loss 0.814472
[epoch17, step597]: loss 0.705854
[epoch17, step598]: loss 12.465075
[epoch17, step599]: loss 5.843702
[epoch17, step600]: loss 0.707264
[epoch17, step601]: loss 1.034450
[epoch17, step602]: loss 2.767776
[epoch17, step603]: loss 13.493392
[epoch17, step604]: loss 3.924652
[epoch17, step605]: loss 1.867866
[epoch17, step606]: loss 0.921849
[epoch17, step607]: loss 12.234799
[epoch17, step608]: loss 1.060263
[epoch17, step609]: loss 0.841478
[epoch17, step610]: loss 3.194675
[epoch17, step611]: loss 0.625391
[epoch17, step612]: loss 1.360659
[epoch17, step613]: loss 0.843127
[epoch17, step614]: loss 1.137597
[epoch17, step615]: loss 7.477446
[epoch17, step616]: loss 1.228688
[epoch17, step617]: loss 1.759214
[epoch17, step618]: loss 1.662320
[epoch17, step619]: loss 6.282985
[epoch17, step620]: loss 1.994897
[epoch17, step621]: loss 2.520760
[epoch17, step622]: loss 4.773486
[epoch17, step623]: loss 1.159015
[epoch17, step624]: loss 1.629504
[epoch17, step625]: loss 1.074875
[epoch17, step626]: loss 31.530554
[epoch17, step627]: loss 5.556147
[epoch17, step628]: loss 1.790929
[epoch17, step629]: loss 1.800519
[epoch17, step630]: loss 1.454199
[epoch17, step631]: loss 5.277792
[epoch17, step632]: loss 2.394382
[epoch17, step633]: loss 1.073472
[epoch17, step634]: loss 1.901314
[epoch17, step635]: loss 7.650828
[epoch17, step636]: loss 1.069164
[epoch17, step637]: loss 1.600409
[epoch17, step638]: loss 17.653473
[epoch17, step639]: loss 5.790588
[epoch17, step640]: loss 9.434994
[epoch17, step641]: loss 1.551294
[epoch17, step642]: loss 0.551683
[epoch17, step643]: loss 3.439573
[epoch17, step644]: loss 2.195610
[epoch17, step645]: loss 2.818133
[epoch17, step646]: loss 10.530815
[epoch17, step647]: loss 15.608002
[epoch17, step648]: loss 4.827959
[epoch17, step649]: loss 9.721219
[epoch17, step650]: loss 2.764814
[epoch17, step651]: loss 0.960985
[epoch17, step652]: loss 1.071348
[epoch17, step653]: loss 3.196438
[epoch17, step654]: loss 0.943783
[epoch17, step655]: loss 2.882615
[epoch17, step656]: loss 13.371408
[epoch17, step657]: loss 3.308910
[epoch17, step658]: loss 3.077738
[epoch17, step659]: loss 11.188699
[epoch17, step660]: loss 30.240488
[epoch17, step661]: loss 1.391177
[epoch17, step662]: loss 12.182920
[epoch17, step663]: loss 4.501975
[epoch17, step664]: loss 0.874189
[epoch17, step665]: loss 1.741181
[epoch17, step666]: loss 6.656019
[epoch17, step667]: loss 12.156361
[epoch17, step668]: loss 13.520098
[epoch17, step669]: loss 0.663481
[epoch17, step670]: loss 13.749975
[epoch17, step671]: loss 1.131617
[epoch17, step672]: loss 2.072248
[epoch17, step673]: loss 3.292403
[epoch17, step674]: loss 1.904471
[epoch17, step675]: loss 1.423332
[epoch17, step676]: loss 0.592374
[epoch17, step677]: loss 0.910764
[epoch17, step678]: loss 3.972928
[epoch17, step679]: loss 1.810652
[epoch17, step680]: loss 1.934503
[epoch17, step681]: loss 2.503866
[epoch17, step682]: loss 1.015394
[epoch17, step683]: loss 1.764508
[epoch17, step684]: loss 1.228984
[epoch17, step685]: loss 1.805495
[epoch17, step686]: loss 10.281501
[epoch17, step687]: loss 4.253851
[epoch17, step688]: loss 4.078419
[epoch17, step689]: loss 16.826271
[epoch17, step690]: loss 2.171180
[epoch17, step691]: loss 3.603621
[epoch17, step692]: loss 6.731730
[epoch17, step693]: loss 0.919400
[epoch17, step694]: loss 1.311614
[epoch17, step695]: loss 0.764943
[epoch17, step696]: loss 16.523214
[epoch17, step697]: loss 1.846886
[epoch17, step698]: loss 0.797013
[epoch17, step699]: loss 7.573715
[epoch17, step700]: loss 3.010711
[epoch17, step701]: loss 9.312992
[epoch17, step702]: loss 0.820014
[epoch17, step703]: loss 12.031116
[epoch17, step704]: loss 1.424830
[epoch17, step705]: loss 1.994892
[epoch17, step706]: loss 1.014419
[epoch17, step707]: loss 0.887379
[epoch17, step708]: loss 0.720239
[epoch17, step709]: loss 0.658441
[epoch17, step710]: loss 12.234876
[epoch17, step711]: loss 9.074118
[epoch17, step712]: loss 0.988379
[epoch17, step713]: loss 0.496539
[epoch17, step714]: loss 1.807267
[epoch17, step715]: loss 1.124020
[epoch17, step716]: loss 5.056268
[epoch17, step717]: loss 0.874578
[epoch17, step718]: loss 2.032156
[epoch17, step719]: loss 1.339375
[epoch17, step720]: loss 0.821796
[epoch17, step721]: loss 1.588394
[epoch17, step722]: loss 1.219570
[epoch17, step723]: loss 6.522539
[epoch17, step724]: loss 0.896584
[epoch17, step725]: loss 6.470488
[epoch17, step726]: loss 29.278770
[epoch17, step727]: loss 1.499065
[epoch17, step728]: loss 1.242996
[epoch17, step729]: loss 9.996707
[epoch17, step730]: loss 1.379483
[epoch17, step731]: loss 2.168375
[epoch17, step732]: loss 0.892270
[epoch17, step733]: loss 8.195287
[epoch17, step734]: loss 1.275079
[epoch17, step735]: loss 1.653012
[epoch17, step736]: loss 0.735375
[epoch17, step737]: loss 5.964845
[epoch17, step738]: loss 2.672125
[epoch17, step739]: loss 2.716468
[epoch17, step740]: loss 2.596717
[epoch17, step741]: loss 1.571644
[epoch17, step742]: loss 7.773511
[epoch17, step743]: loss 3.907014
[epoch17, step744]: loss 16.869669
[epoch17, step745]: loss 1.763574
[epoch17, step746]: loss 10.064818
[epoch17, step747]: loss 1.930702
[epoch17, step748]: loss 1.047768
[epoch17, step749]: loss 9.537422
[epoch17, step750]: loss 0.923474
[epoch17, step751]: loss 0.828407
[epoch17, step752]: loss 1.022958
[epoch17, step753]: loss 1.396975
[epoch17, step754]: loss 0.756230
[epoch17, step755]: loss 28.095312
[epoch17, step756]: loss 3.940230
[epoch17, step757]: loss 1.120548
[epoch17, step758]: loss 1.364854
[epoch17, step759]: loss 0.898788
[epoch17, step760]: loss 3.659627
[epoch17, step761]: loss 2.195617
[epoch17, step762]: loss 1.123523
[epoch17, step763]: loss 1.808691
[epoch17, step764]: loss 1.744833
[epoch17, step765]: loss 1.118051
[epoch17, step766]: loss 0.910544
[epoch17, step767]: loss 2.227065
[epoch17, step768]: loss 1.108393
[epoch17, step769]: loss 0.782957
[epoch17, step770]: loss 1.946023
[epoch17, step771]: loss 16.979700
[epoch17, step772]: loss 10.631038
[epoch17, step773]: loss 2.064033
[epoch17, step774]: loss 2.023041
[epoch17, step775]: loss 0.794215
[epoch17, step776]: loss 2.272232
[epoch17, step777]: loss 1.703430
[epoch17, step778]: loss 0.954879
[epoch17, step779]: loss 1.855119
[epoch17, step780]: loss 14.041071
[epoch17, step781]: loss 2.259150
[epoch17, step782]: loss 0.937242
[epoch17, step783]: loss 3.053200
[epoch17, step784]: loss 1.613363
[epoch17, step785]: loss 0.743965
[epoch17, step786]: loss 3.052833
[epoch17, step787]: loss 14.120543
[epoch17, step788]: loss 0.890625
[epoch17, step789]: loss 2.728185
[epoch17, step790]: loss 20.795597
[epoch17, step791]: loss 1.302197
[epoch17, step792]: loss 0.545383
[epoch17, step793]: loss 4.305801
[epoch17, step794]: loss 1.170318
[epoch17, step795]: loss 0.596345
[epoch17, step796]: loss 2.488465
[epoch17, step797]: loss 2.718397
[epoch17, step798]: loss 9.553934
[epoch17, step799]: loss 2.153150
[epoch17, step800]: loss 1.738662
[epoch17, step801]: loss 1.125633
[epoch17, step802]: loss 0.918194
[epoch17, step803]: loss 1.130985
[epoch17, step804]: loss 0.604743
[epoch17, step805]: loss 0.832679
[epoch17, step806]: loss 0.975412
[epoch17, step807]: loss 3.989570
[epoch17, step808]: loss 2.434186
[epoch17, step809]: loss 6.361894
[epoch17, step810]: loss 0.717245
[epoch17, step811]: loss 0.998823
[epoch17, step812]: loss 1.797864
[epoch17, step813]: loss 2.649266
[epoch17, step814]: loss 5.744997
[epoch17, step815]: loss 1.074202
[epoch17, step816]: loss 3.484337
[epoch17, step817]: loss 6.431178
[epoch17, step818]: loss 2.302767
[epoch17, step819]: loss 0.639428
[epoch17, step820]: loss 1.146074
[epoch17, step821]: loss 1.824661
[epoch17, step822]: loss 3.813370
[epoch17, step823]: loss 1.577273
[epoch17, step824]: loss 11.122817
[epoch17, step825]: loss 1.933222
[epoch17, step826]: loss 1.940824
[epoch17, step827]: loss 0.540190
[epoch17, step828]: loss 3.056752
[epoch17, step829]: loss 1.521414
[epoch17, step830]: loss 0.768416
[epoch17, step831]: loss 4.490023
[epoch17, step832]: loss 3.322998
[epoch17, step833]: loss 1.268206
[epoch17, step834]: loss 2.740867
[epoch17, step835]: loss 0.781231
[epoch17, step836]: loss 0.979149
[epoch17, step837]: loss 15.795664
[epoch17, step838]: loss 1.069684
[epoch17, step839]: loss 14.489160
[epoch17, step840]: loss 0.745536
[epoch17, step841]: loss 1.495638
[epoch17, step842]: loss 2.000025
[epoch17, step843]: loss 3.626543
[epoch17, step844]: loss 3.705814
[epoch17, step845]: loss 1.248084
[epoch17, step846]: loss 0.935823
[epoch17, step847]: loss 2.215835
[epoch17, step848]: loss 15.567615
[epoch17, step849]: loss 3.278695
[epoch17, step850]: loss 0.698684
[epoch17, step851]: loss 2.145259
[epoch17, step852]: loss 11.917735
[epoch17, step853]: loss 2.235722
[epoch17, step854]: loss 6.852325
[epoch17, step855]: loss 1.246204
[epoch17, step856]: loss 2.396505
[epoch17, step857]: loss 8.723333
[epoch17, step858]: loss 0.870774
[epoch17, step859]: loss 2.898055
[epoch17, step860]: loss 1.118675
[epoch17, step861]: loss 0.930219
[epoch17, step862]: loss 1.243301
[epoch17, step863]: loss 1.848514
[epoch17, step864]: loss 4.709321
[epoch17, step865]: loss 5.256688
[epoch17, step866]: loss 6.758539
[epoch17, step867]: loss 1.762633
[epoch17, step868]: loss 0.959322
[epoch17, step869]: loss 6.441915
[epoch17, step870]: loss 2.258693
[epoch17, step871]: loss 4.105156
[epoch17, step872]: loss 1.717296
[epoch17, step873]: loss 5.371458
[epoch17, step874]: loss 11.747122
[epoch17, step875]: loss 1.557233
[epoch17, step876]: loss 2.476462
[epoch17, step877]: loss 1.665872
[epoch17, step878]: loss 1.966417
[epoch17, step879]: loss 2.824169
[epoch17, step880]: loss 0.905913
[epoch17, step881]: loss 0.975249
[epoch17, step882]: loss 2.054960
[epoch17, step883]: loss 1.045267
[epoch17, step884]: loss 2.281065
[epoch17, step885]: loss 1.279202
[epoch17, step886]: loss 0.697704
[epoch17, step887]: loss 1.586496
[epoch17, step888]: loss 1.774978
[epoch17, step889]: loss 1.980149
[epoch17, step890]: loss 1.698768
[epoch17, step891]: loss 1.982337
[epoch17, step892]: loss 1.607069
[epoch17, step893]: loss 1.296764
[epoch17, step894]: loss 1.899450
[epoch17, step895]: loss 10.619203
[epoch17, step896]: loss 2.088146
[epoch17, step897]: loss 1.116557
[epoch17, step898]: loss 0.752002
[epoch17, step899]: loss 1.463397
[epoch17, step900]: loss 0.716118
[epoch17, step901]: loss 4.286116
[epoch17, step902]: loss 0.727407
[epoch17, step903]: loss 1.564457
[epoch17, step904]: loss 1.197017
[epoch17, step905]: loss 4.136446
[epoch17, step906]: loss 8.286985
[epoch17, step907]: loss 4.042140
[epoch17, step908]: loss 9.794894
[epoch17, step909]: loss 1.533088
[epoch17, step910]: loss 1.549264
[epoch17, step911]: loss 5.322907
[epoch17, step912]: loss 0.820592
[epoch17, step913]: loss 1.063962
[epoch17, step914]: loss 15.729587
[epoch17, step915]: loss 0.610576
[epoch17, step916]: loss 0.769523
[epoch17, step917]: loss 3.410801
[epoch17, step918]: loss 2.390955
[epoch17, step919]: loss 3.441842
[epoch17, step920]: loss 1.449308
[epoch17, step921]: loss 1.402448
[epoch17, step922]: loss 8.516803
[epoch17, step923]: loss 0.826173
[epoch17, step924]: loss 10.772460
[epoch17, step925]: loss 0.794120
[epoch17, step926]: loss 0.630233
[epoch17, step927]: loss 0.961475
[epoch17, step928]: loss 9.386776
[epoch17, step929]: loss 0.786141
[epoch17, step930]: loss 1.266730
[epoch17, step931]: loss 1.428130
[epoch17, step932]: loss 4.010141
[epoch17, step933]: loss 1.901489
[epoch17, step934]: loss 4.523955
[epoch17, step935]: loss 1.603598
[epoch17, step936]: loss 2.355716
[epoch17, step937]: loss 14.597440
[epoch17, step938]: loss 1.491782
[epoch17, step939]: loss 1.333727
[epoch17, step940]: loss 1.072540
[epoch17, step941]: loss 1.137894
[epoch17, step942]: loss 1.291335
[epoch17, step943]: loss 11.400684
[epoch17, step944]: loss 5.760258
[epoch17, step945]: loss 2.240652
[epoch17, step946]: loss 1.836215
[epoch17, step947]: loss 3.165165
[epoch17, step948]: loss 2.558574
[epoch17, step949]: loss 1.846962
[epoch17, step950]: loss 1.967729
[epoch17, step951]: loss 11.215078
[epoch17, step952]: loss 2.716730
[epoch17, step953]: loss 2.954303
[epoch17, step954]: loss 2.604631
[epoch17, step955]: loss 11.261250
[epoch17, step956]: loss 6.860557
[epoch17, step957]: loss 7.102447
[epoch17, step958]: loss 5.989813
[epoch17, step959]: loss 4.910233
[epoch17, step960]: loss 1.005275
[epoch17, step961]: loss 2.102021
[epoch17, step962]: loss 0.857264
[epoch17, step963]: loss 17.776005
[epoch17, step964]: loss 2.806296
[epoch17, step965]: loss 0.995585
[epoch17, step966]: loss 0.911097
[epoch17, step967]: loss 9.754123
[epoch17, step968]: loss 2.411546
[epoch17, step969]: loss 7.033789
[epoch17, step970]: loss 3.101232
[epoch17, step971]: loss 0.998500
[epoch17, step972]: loss 17.192068
[epoch17, step973]: loss 0.971101
[epoch17, step974]: loss 0.768084
[epoch17, step975]: loss 1.301789
[epoch17, step976]: loss 1.353142
[epoch17, step977]: loss 16.003616
[epoch17, step978]: loss 4.050200
[epoch17, step979]: loss 1.311770
[epoch17, step980]: loss 2.304051
[epoch17, step981]: loss 0.788826
[epoch17, step982]: loss 11.577707
[epoch17, step983]: loss 1.037700
[epoch17, step984]: loss 9.222864
[epoch17, step985]: loss 1.639678
[epoch17, step986]: loss 4.891077
[epoch17, step987]: loss 15.658636
[epoch17, step988]: loss 1.407890
[epoch17, step989]: loss 4.624678
[epoch17, step990]: loss 1.390167
[epoch17, step991]: loss 8.207860
[epoch17, step992]: loss 9.223940
[epoch17, step993]: loss 3.383826
[epoch17, step994]: loss 28.467037
[epoch17, step995]: loss 14.540621
[epoch17, step996]: loss 9.827539
[epoch17, step997]: loss 15.155771
[epoch17, step998]: loss 4.540102
[epoch17, step999]: loss 0.688237
[epoch17, step1000]: loss 2.816561
[epoch17, step1001]: loss 0.651855
[epoch17, step1002]: loss 6.967649
[epoch17, step1003]: loss 1.976911
[epoch17, step1004]: loss 11.534628
[epoch17, step1005]: loss 0.729197
[epoch17, step1006]: loss 9.563310
[epoch17, step1007]: loss 6.893926
[epoch17, step1008]: loss 0.951883
[epoch17, step1009]: loss 1.511057
[epoch17, step1010]: loss 1.498740
[epoch17, step1011]: loss 1.163216
[epoch17, step1012]: loss 0.485387
[epoch17, step1013]: loss 2.916838
[epoch17, step1014]: loss 6.894684
[epoch17, step1015]: loss 1.624844
[epoch17, step1016]: loss 2.131004
[epoch17, step1017]: loss 1.245402
[epoch17, step1018]: loss 1.197105
[epoch17, step1019]: loss 26.144503
[epoch17, step1020]: loss 2.874848
[epoch17, step1021]: loss 1.198043
[epoch17, step1022]: loss 1.201521
[epoch17, step1023]: loss 0.831832
[epoch17, step1024]: loss 1.328665
[epoch17, step1025]: loss 5.801981
[epoch17, step1026]: loss 1.173434
[epoch17, step1027]: loss 3.850201
[epoch17, step1028]: loss 0.904504
[epoch17, step1029]: loss 1.038298
[epoch17, step1030]: loss 0.884905
[epoch17, step1031]: loss 1.873713
[epoch17, step1032]: loss 1.755596
[epoch17, step1033]: loss 6.482686
[epoch17, step1034]: loss 1.350608
[epoch17, step1035]: loss 0.869411
[epoch17, step1036]: loss 8.046030
[epoch17, step1037]: loss 1.146021
[epoch17, step1038]: loss 0.884802
[epoch17, step1039]: loss 2.439905
[epoch17, step1040]: loss 1.674053
[epoch17, step1041]: loss 1.957204
[epoch17, step1042]: loss 1.725612
[epoch17, step1043]: loss 12.193417
[epoch17, step1044]: loss 1.675088
[epoch17, step1045]: loss 12.949166
[epoch17, step1046]: loss 0.539965
[epoch17, step1047]: loss 1.061873
[epoch17, step1048]: loss 2.168093
[epoch17, step1049]: loss 2.359761
[epoch17, step1050]: loss 8.185043
[epoch17, step1051]: loss 1.231826
[epoch17, step1052]: loss 0.797941
[epoch17, step1053]: loss 1.214327
[epoch17, step1054]: loss 11.434519
[epoch17, step1055]: loss 2.072974
[epoch17, step1056]: loss 1.305413
[epoch17, step1057]: loss 9.583924
[epoch17, step1058]: loss 1.990296
[epoch17, step1059]: loss 1.586214
[epoch17, step1060]: loss 1.256290
[epoch17, step1061]: loss 0.621060
[epoch17, step1062]: loss 1.735945
[epoch17, step1063]: loss 11.909709
[epoch17, step1064]: loss 1.779144
[epoch17, step1065]: loss 4.310927
[epoch17, step1066]: loss 11.442058
[epoch17, step1067]: loss 1.120945
[epoch17, step1068]: loss 1.274474
[epoch17, step1069]: loss 2.203900
[epoch17, step1070]: loss 4.133093
[epoch17, step1071]: loss 1.821877
[epoch17, step1072]: loss 6.463261
[epoch17, step1073]: loss 0.910937
[epoch17, step1074]: loss 1.516738
[epoch17, step1075]: loss 3.227157
[epoch17, step1076]: loss 10.976827
[epoch17, step1077]: loss 2.891296
[epoch17, step1078]: loss 0.861293
[epoch17, step1079]: loss 13.511150
[epoch17, step1080]: loss 2.579873
[epoch17, step1081]: loss 4.479856
[epoch17, step1082]: loss 1.237709
[epoch17, step1083]: loss 1.160832
[epoch17, step1084]: loss 2.247241
[epoch17, step1085]: loss 2.234623
[epoch17, step1086]: loss 3.963032
[epoch17, step1087]: loss 0.803751
[epoch17, step1088]: loss 0.906770
[epoch17, step1089]: loss 10.368453
[epoch17, step1090]: loss 1.168006
[epoch17, step1091]: loss 2.809235
[epoch17, step1092]: loss 0.639723
[epoch17, step1093]: loss 2.223522
[epoch17, step1094]: loss 11.964955
[epoch17, step1095]: loss 2.678800
[epoch17, step1096]: loss 1.554371
[epoch17, step1097]: loss 2.303336
[epoch17, step1098]: loss 8.074062
[epoch17, step1099]: loss 3.282722
[epoch17, step1100]: loss 6.719773
[epoch17, step1101]: loss 0.884273
[epoch17, step1102]: loss 1.971715
[epoch17, step1103]: loss 1.228042
[epoch17, step1104]: loss 2.607926
[epoch17, step1105]: loss 1.207779
[epoch17, step1106]: loss 3.837584
[epoch17, step1107]: loss 1.074473
[epoch17, step1108]: loss 1.501199
[epoch17, step1109]: loss 19.198725
[epoch17, step1110]: loss 4.351231
[epoch17, step1111]: loss 1.773823
[epoch17, step1112]: loss 1.242033
[epoch17, step1113]: loss 10.237411
[epoch17, step1114]: loss 18.630960
[epoch17, step1115]: loss 11.375621
[epoch17, step1116]: loss 1.132329
[epoch17, step1117]: loss 1.884040
[epoch17, step1118]: loss 3.686380
[epoch17, step1119]: loss 1.382601
[epoch17, step1120]: loss 1.219660
[epoch17, step1121]: loss 1.231916
[epoch17, step1122]: loss 2.362472
[epoch17, step1123]: loss 0.854999
[epoch17, step1124]: loss 0.891354
[epoch17, step1125]: loss 6.729456
[epoch17, step1126]: loss 0.865171
[epoch17, step1127]: loss 1.116112
[epoch17, step1128]: loss 1.080874
[epoch17, step1129]: loss 0.977977
[epoch17, step1130]: loss 12.525780
[epoch17, step1131]: loss 10.511812
[epoch17, step1132]: loss 4.858474
[epoch17, step1133]: loss 2.886295
[epoch17, step1134]: loss 13.223219
[epoch17, step1135]: loss 0.840908
[epoch17, step1136]: loss 3.855236
[epoch17, step1137]: loss 1.063933
[epoch17, step1138]: loss 1.753621
[epoch17, step1139]: loss 1.026601
[epoch17, step1140]: loss 11.949522
[epoch17, step1141]: loss 0.849870
[epoch17, step1142]: loss 0.849105
[epoch17, step1143]: loss 14.498865
[epoch17, step1144]: loss 1.738102
[epoch17, step1145]: loss 1.625955
[epoch17, step1146]: loss 4.343826
[epoch17, step1147]: loss 4.937006
[epoch17, step1148]: loss 0.993639
[epoch17, step1149]: loss 2.016742
[epoch17, step1150]: loss 0.999082
[epoch17, step1151]: loss 0.727780
[epoch17, step1152]: loss 2.599726
[epoch17, step1153]: loss 0.772430
[epoch17, step1154]: loss 3.344079
[epoch17, step1155]: loss 1.621007
[epoch17, step1156]: loss 0.975200
[epoch17, step1157]: loss 0.836079
[epoch17, step1158]: loss 2.214706
[epoch17, step1159]: loss 1.917478
[epoch17, step1160]: loss 0.837170
[epoch17, step1161]: loss 1.053066
[epoch17, step1162]: loss 4.189880
[epoch17, step1163]: loss 0.969863
[epoch17, step1164]: loss 1.212450
[epoch17, step1165]: loss 1.913519
[epoch17, step1166]: loss 5.426965
[epoch17, step1167]: loss 0.794153
[epoch17, step1168]: loss 2.400665
[epoch17, step1169]: loss 1.189670
[epoch17, step1170]: loss 1.243530
[epoch17, step1171]: loss 4.180125
[epoch17, step1172]: loss 0.800904
[epoch17, step1173]: loss 2.007940
[epoch17, step1174]: loss 1.443504
[epoch17, step1175]: loss 2.284335
[epoch17, step1176]: loss 7.485630
[epoch17, step1177]: loss 4.654741
[epoch17, step1178]: loss 12.312565
[epoch17, step1179]: loss 0.852774
[epoch17, step1180]: loss 1.379148
[epoch17, step1181]: loss 2.128797
[epoch17, step1182]: loss 1.294536
[epoch17, step1183]: loss 11.445014
[epoch17, step1184]: loss 0.969375
[epoch17, step1185]: loss 8.130180
[epoch17, step1186]: loss 12.196726
[epoch17, step1187]: loss 1.255816
[epoch17, step1188]: loss 3.117955
[epoch17, step1189]: loss 1.197993
[epoch17, step1190]: loss 1.438356
[epoch17, step1191]: loss 2.106802
[epoch17, step1192]: loss 2.124004
[epoch17, step1193]: loss 2.919451
[epoch17, step1194]: loss 1.538568
[epoch17, step1195]: loss 3.047536
[epoch17, step1196]: loss 6.157376
[epoch17, step1197]: loss 1.479299
[epoch17, step1198]: loss 0.715781
[epoch17, step1199]: loss 14.364406
[epoch17, step1200]: loss 6.066027
[epoch17, step1201]: loss 1.447632
[epoch17, step1202]: loss 3.422220
[epoch17, step1203]: loss 1.009546
[epoch17, step1204]: loss 1.526850
[epoch17, step1205]: loss 1.858478
[epoch17, step1206]: loss 5.170862
[epoch17, step1207]: loss 2.789879
[epoch17, step1208]: loss 1.482342
[epoch17, step1209]: loss 1.344250
[epoch17, step1210]: loss 1.241406
[epoch17, step1211]: loss 1.179527
[epoch17, step1212]: loss 3.029000
[epoch17, step1213]: loss 1.099069
[epoch17, step1214]: loss 0.827225
[epoch17, step1215]: loss 12.935766
[epoch17, step1216]: loss 1.836389
[epoch17, step1217]: loss 1.951504
[epoch17, step1218]: loss 0.896319
[epoch17, step1219]: loss 7.905630
[epoch17, step1220]: loss 11.202181
[epoch17, step1221]: loss 1.400488
[epoch17, step1222]: loss 7.169792
[epoch17, step1223]: loss 1.199046
[epoch17, step1224]: loss 2.771586
[epoch17, step1225]: loss 2.525596
[epoch17, step1226]: loss 1.563026
[epoch17, step1227]: loss 0.721113
[epoch17, step1228]: loss 1.862021
[epoch17, step1229]: loss 1.204772
[epoch17, step1230]: loss 10.255396
[epoch17, step1231]: loss 2.480083
[epoch17, step1232]: loss 5.461390
[epoch17, step1233]: loss 0.844224
[epoch17, step1234]: loss 16.997147
[epoch17, step1235]: loss 1.662567
[epoch17, step1236]: loss 0.749071
[epoch17, step1237]: loss 10.319245
[epoch17, step1238]: loss 5.209224
[epoch17, step1239]: loss 15.276510
[epoch17, step1240]: loss 1.891803
[epoch17, step1241]: loss 2.123779
[epoch17, step1242]: loss 5.650171
[epoch17, step1243]: loss 4.182309
[epoch17, step1244]: loss 7.980126
[epoch17, step1245]: loss 17.435848
[epoch17, step1246]: loss 8.665529
[epoch17, step1247]: loss 3.608108
[epoch17, step1248]: loss 1.197541
[epoch17, step1249]: loss 0.704648
[epoch17, step1250]: loss 2.275501
[epoch17, step1251]: loss 1.482706
[epoch17, step1252]: loss 8.114369
[epoch17, step1253]: loss 2.253838
[epoch17, step1254]: loss 0.789548
[epoch17, step1255]: loss 0.950136
[epoch17, step1256]: loss 0.906338
[epoch17, step1257]: loss 7.044201
[epoch17, step1258]: loss 16.342056
[epoch17, step1259]: loss 1.916428
[epoch17, step1260]: loss 2.577441
[epoch17, step1261]: loss 1.202532
[epoch17, step1262]: loss 1.968569
[epoch17, step1263]: loss 1.831759
[epoch17, step1264]: loss 7.113522
[epoch17, step1265]: loss 1.188222
[epoch17, step1266]: loss 1.382054
[epoch17, step1267]: loss 1.944271
[epoch17, step1268]: loss 8.034881
[epoch17, step1269]: loss 2.614538
[epoch17, step1270]: loss 10.274972
[epoch17, step1271]: loss 1.260578
[epoch17, step1272]: loss 4.935220
[epoch17, step1273]: loss 11.062939
[epoch17, step1274]: loss 1.294831
[epoch17, step1275]: loss 0.528804
[epoch17, step1276]: loss 1.252961
[epoch17, step1277]: loss 3.923987
[epoch17, step1278]: loss 3.992240
[epoch17, step1279]: loss 4.731458
[epoch17, step1280]: loss 13.146157
[epoch17, step1281]: loss 6.205127
[epoch17, step1282]: loss 1.257679
[epoch17, step1283]: loss 1.456193
[epoch17, step1284]: loss 0.504969
[epoch17, step1285]: loss 1.413583
[epoch17, step1286]: loss 7.237161
[epoch17, step1287]: loss 2.084955
[epoch17, step1288]: loss 2.948320
[epoch17, step1289]: loss 0.648006
[epoch17, step1290]: loss 1.704500
[epoch17, step1291]: loss 2.563886
[epoch17, step1292]: loss 0.640286
[epoch17, step1293]: loss 1.133151
[epoch17, step1294]: loss 2.343789
[epoch17, step1295]: loss 1.295125
[epoch17, step1296]: loss 10.708903
[epoch17, step1297]: loss 1.318969
[epoch17, step1298]: loss 1.691581
[epoch17, step1299]: loss 1.675021
[epoch17, step1300]: loss 4.096914
[epoch17, step1301]: loss 1.509254
[epoch17, step1302]: loss 1.313732
[epoch17, step1303]: loss 1.157381
[epoch17, step1304]: loss 2.175522
[epoch17, step1305]: loss 0.713561
[epoch17, step1306]: loss 6.031199
[epoch17, step1307]: loss 2.641155
[epoch17, step1308]: loss 0.664665
[epoch17, step1309]: loss 0.880720
[epoch17, step1310]: loss 3.904248
[epoch17, step1311]: loss 10.936206
[epoch17, step1312]: loss 0.745246
[epoch17, step1313]: loss 1.025314
[epoch17, step1314]: loss 1.355981
[epoch17, step1315]: loss 1.111443
[epoch17, step1316]: loss 7.851001
[epoch17, step1317]: loss 8.398542
[epoch17, step1318]: loss 1.748083
[epoch17, step1319]: loss 7.914251
[epoch17, step1320]: loss 4.469459
[epoch17, step1321]: loss 1.669884
[epoch17, step1322]: loss 3.893200
[epoch17, step1323]: loss 1.355875
[epoch17, step1324]: loss 14.261572
[epoch17, step1325]: loss 1.260307
[epoch17, step1326]: loss 5.578420
[epoch17, step1327]: loss 0.835270
[epoch17, step1328]: loss 0.855285
[epoch17, step1329]: loss 1.041877
[epoch17, step1330]: loss 3.734526
[epoch17, step1331]: loss 9.048353
[epoch17, step1332]: loss 10.249071
[epoch17, step1333]: loss 1.586032
[epoch17, step1334]: loss 0.996846
[epoch17, step1335]: loss 1.271984
[epoch17, step1336]: loss 0.918444
[epoch17, step1337]: loss 2.346021
[epoch17, step1338]: loss 1.264669
[epoch17, step1339]: loss 5.220850
[epoch17, step1340]: loss 1.148700
[epoch17, step1341]: loss 1.799754
[epoch17, step1342]: loss 2.962609
[epoch17, step1343]: loss 1.156566
[epoch17, step1344]: loss 1.934813
[epoch17, step1345]: loss 1.451937
[epoch17, step1346]: loss 4.762679
[epoch17, step1347]: loss 1.371624
[epoch17, step1348]: loss 10.676254
[epoch17, step1349]: loss 2.756130
[epoch17, step1350]: loss 0.796174
[epoch17, step1351]: loss 5.991549
[epoch17, step1352]: loss 3.215699
[epoch17, step1353]: loss 4.118960
[epoch17, step1354]: loss 5.045006
[epoch17, step1355]: loss 1.432603
[epoch17, step1356]: loss 0.527013
[epoch17, step1357]: loss 0.759751
[epoch17, step1358]: loss 6.496930
[epoch17, step1359]: loss 0.992953
[epoch17, step1360]: loss 16.995327
[epoch17, step1361]: loss 1.798107
[epoch17, step1362]: loss 1.587107
[epoch17, step1363]: loss 1.499709
[epoch17, step1364]: loss 2.029271
[epoch17, step1365]: loss 3.122255
[epoch17, step1366]: loss 3.000210
[epoch17, step1367]: loss 0.714470
[epoch17, step1368]: loss 2.890155
[epoch17, step1369]: loss 0.552290
[epoch17, step1370]: loss 1.216665
[epoch17, step1371]: loss 6.956757
[epoch17, step1372]: loss 2.010115
[epoch17, step1373]: loss 1.414533
[epoch17, step1374]: loss 0.842126
[epoch17, step1375]: loss 8.358854
[epoch17, step1376]: loss 21.278900
[epoch17, step1377]: loss 15.342571
[epoch17, step1378]: loss 9.901054
[epoch17, step1379]: loss 1.868225
[epoch17, step1380]: loss 4.836939
[epoch17, step1381]: loss 0.845910
[epoch17, step1382]: loss 0.972066
[epoch17, step1383]: loss 1.843234
[epoch17, step1384]: loss 0.859279
[epoch17, step1385]: loss 4.020161
[epoch17, step1386]: loss 1.364333
[epoch17, step1387]: loss 3.405744
[epoch17, step1388]: loss 15.141357
[epoch17, step1389]: loss 2.269385
[epoch17, step1390]: loss 7.038606
[epoch17, step1391]: loss 0.824730
[epoch17, step1392]: loss 1.507845
[epoch17, step1393]: loss 1.014593
[epoch17, step1394]: loss 1.794265
[epoch17, step1395]: loss 1.622856
[epoch17, step1396]: loss 2.011905
[epoch17, step1397]: loss 1.657148
[epoch17, step1398]: loss 1.402304
[epoch17, step1399]: loss 18.161312
[epoch17, step1400]: loss 1.008898
[epoch17, step1401]: loss 0.954073
[epoch17, step1402]: loss 0.654051
[epoch17, step1403]: loss 1.492894
[epoch17, step1404]: loss 1.138632
[epoch17, step1405]: loss 0.930872
[epoch17, step1406]: loss 6.993856
[epoch17, step1407]: loss 8.975670
[epoch17, step1408]: loss 1.832819
[epoch17, step1409]: loss 1.295297
[epoch17, step1410]: loss 1.387294
[epoch17, step1411]: loss 8.704688
[epoch17, step1412]: loss 6.365452
[epoch17, step1413]: loss 1.372747
[epoch17, step1414]: loss 0.735448
[epoch17, step1415]: loss 1.467358
[epoch17, step1416]: loss 6.789539
[epoch17, step1417]: loss 1.682870
[epoch17, step1418]: loss 0.971432
[epoch17, step1419]: loss 20.556520
[epoch17, step1420]: loss 1.617884
[epoch17, step1421]: loss 2.557570
[epoch17, step1422]: loss 0.676701
[epoch17, step1423]: loss 0.969066
[epoch17, step1424]: loss 0.691264
[epoch17, step1425]: loss 1.256425
[epoch17, step1426]: loss 0.739555
[epoch17, step1427]: loss 0.661605
[epoch17, step1428]: loss 31.013725
[epoch17, step1429]: loss 0.600282
[epoch17, step1430]: loss 1.795142
[epoch17, step1431]: loss 9.354858
[epoch17, step1432]: loss 15.125661
[epoch17, step1433]: loss 2.884147
[epoch17, step1434]: loss 3.114281
[epoch17, step1435]: loss 3.514243
[epoch17, step1436]: loss 10.735493
[epoch17, step1437]: loss 4.815807
[epoch17, step1438]: loss 1.334843
[epoch17, step1439]: loss 13.454722
[epoch17, step1440]: loss 1.390880
[epoch17, step1441]: loss 0.702859
[epoch17, step1442]: loss 0.829268
[epoch17, step1443]: loss 11.601029
[epoch17, step1444]: loss 1.022264
[epoch17, step1445]: loss 0.422491
[epoch17, step1446]: loss 2.097036
[epoch17, step1447]: loss 1.201625
[epoch17, step1448]: loss 0.757092
[epoch17, step1449]: loss 12.768316
[epoch17, step1450]: loss 0.523056
[epoch17, step1451]: loss 2.085485
[epoch17, step1452]: loss 2.606922
[epoch17, step1453]: loss 10.497801
[epoch17, step1454]: loss 0.619599
[epoch17, step1455]: loss 0.931693
[epoch17, step1456]: loss 2.031081
[epoch17, step1457]: loss 1.078842
[epoch17, step1458]: loss 0.923188
[epoch17, step1459]: loss 1.066593
[epoch17, step1460]: loss 2.512849
[epoch17, step1461]: loss 1.440003
[epoch17, step1462]: loss 5.808130
[epoch17, step1463]: loss 10.592296
[epoch17, step1464]: loss 3.485402
[epoch17, step1465]: loss 0.817200
[epoch17, step1466]: loss 0.954335
[epoch17, step1467]: loss 1.287313
[epoch17, step1468]: loss 0.854071
[epoch17, step1469]: loss 1.313500
[epoch17, step1470]: loss 11.260462
[epoch17, step1471]: loss 4.280005
[epoch17, step1472]: loss 2.260592
[epoch17, step1473]: loss 2.755780
[epoch17, step1474]: loss 28.580242
[epoch17, step1475]: loss 16.059429
[epoch17, step1476]: loss 1.340000
[epoch17, step1477]: loss 0.848614
[epoch17, step1478]: loss 12.537769
[epoch17, step1479]: loss 5.376584
[epoch17, step1480]: loss 0.814880
[epoch17, step1481]: loss 1.641282
[epoch17, step1482]: loss 0.804961
[epoch17, step1483]: loss 1.582087
[epoch17, step1484]: loss 4.948364
[epoch17, step1485]: loss 4.803267
[epoch17, step1486]: loss 3.881512
[epoch17, step1487]: loss 1.171066
[epoch17, step1488]: loss 5.527545
[epoch17, step1489]: loss 1.194369
[epoch17, step1490]: loss 1.049339
[epoch17, step1491]: loss 1.448833
[epoch17, step1492]: loss 3.695115
[epoch17, step1493]: loss 1.842527
[epoch17, step1494]: loss 1.512770
[epoch17, step1495]: loss 11.814129
[epoch17, step1496]: loss 2.035733
[epoch17, step1497]: loss 4.069074
[epoch17, step1498]: loss 3.622473
[epoch17, step1499]: loss 0.970429
[epoch17, step1500]: loss 6.672898
[epoch17, step1501]: loss 0.599032
[epoch17, step1502]: loss 10.947926
[epoch17, step1503]: loss 1.285780
[epoch17, step1504]: loss 0.718402
[epoch17, step1505]: loss 1.133571
[epoch17, step1506]: loss 2.142065
[epoch17, step1507]: loss 0.957453
[epoch17, step1508]: loss 17.807089
[epoch17, step1509]: loss 8.803340
[epoch17, step1510]: loss 0.692160
[epoch17, step1511]: loss 2.233188
[epoch17, step1512]: loss 0.756684
[epoch17, step1513]: loss 10.828598
[epoch17, step1514]: loss 1.036272
[epoch17, step1515]: loss 6.933168
[epoch17, step1516]: loss 2.050725
[epoch17, step1517]: loss 0.837747
[epoch17, step1518]: loss 0.833125
[epoch17, step1519]: loss 8.625628
[epoch17, step1520]: loss 2.410700
[epoch17, step1521]: loss 1.711481
[epoch17, step1522]: loss 1.734123
[epoch17, step1523]: loss 2.041280
[epoch17, step1524]: loss 10.592166
[epoch17, step1525]: loss 2.590810
[epoch17, step1526]: loss 0.790861
[epoch17, step1527]: loss 11.842864
[epoch17, step1528]: loss 0.659558
[epoch17, step1529]: loss 5.192816
[epoch17, step1530]: loss 5.604370
[epoch17, step1531]: loss 9.521889
[epoch17, step1532]: loss 1.591413
[epoch17, step1533]: loss 2.442934
[epoch17, step1534]: loss 16.883715
[epoch17, step1535]: loss 0.935290
[epoch17, step1536]: loss 0.845791
[epoch17, step1537]: loss 0.654441
[epoch17, step1538]: loss 5.329413
[epoch17, step1539]: loss 5.624941
[epoch17, step1540]: loss 12.467930
[epoch17, step1541]: loss 0.623773
[epoch17, step1542]: loss 8.985724
[epoch17, step1543]: loss 6.775420
[epoch17, step1544]: loss 0.927658
[epoch17, step1545]: loss 0.799489
[epoch17, step1546]: loss 1.131464
[epoch17, step1547]: loss 7.410585
[epoch17, step1548]: loss 13.613515
[epoch17, step1549]: loss 14.866586
[epoch17, step1550]: loss 8.322890
[epoch17, step1551]: loss 1.016636
[epoch17, step1552]: loss 10.457462
[epoch17, step1553]: loss 1.007415
[epoch17, step1554]: loss 1.217282
[epoch17, step1555]: loss 1.783018
[epoch17, step1556]: loss 7.157590
[epoch17, step1557]: loss 9.502707
[epoch17, step1558]: loss 0.671211
[epoch17, step1559]: loss 2.528078
[epoch17, step1560]: loss 1.239617
[epoch17, step1561]: loss 1.070543
[epoch17, step1562]: loss 1.802071
[epoch17, step1563]: loss 0.658190
[epoch17, step1564]: loss 0.930024
[epoch17, step1565]: loss 0.890587
[epoch17, step1566]: loss 1.213771
[epoch17, step1567]: loss 1.065057
[epoch17, step1568]: loss 1.640982
[epoch17, step1569]: loss 3.954897
[epoch17, step1570]: loss 1.157413
[epoch17, step1571]: loss 2.824290
[epoch17, step1572]: loss 1.933882
[epoch17, step1573]: loss 8.437901
[epoch17, step1574]: loss 0.857202
[epoch17, step1575]: loss 0.940655
[epoch17, step1576]: loss 1.613217
[epoch17, step1577]: loss 11.559299
[epoch17, step1578]: loss 3.756668
[epoch17, step1579]: loss 3.139927
[epoch17, step1580]: loss 1.479331
[epoch17, step1581]: loss 1.150466
[epoch17, step1582]: loss 1.933439
[epoch17, step1583]: loss 7.984355
[epoch17, step1584]: loss 1.023545
[epoch17, step1585]: loss 0.705675
[epoch17, step1586]: loss 10.265848
[epoch17, step1587]: loss 6.088022
[epoch17, step1588]: loss 1.206522
[epoch17, step1589]: loss 1.219375
[epoch17, step1590]: loss 20.381027
[epoch17, step1591]: loss 1.962223
[epoch17, step1592]: loss 1.801118
[epoch17, step1593]: loss 1.406306
[epoch17, step1594]: loss 1.400713
[epoch17, step1595]: loss 3.372873
[epoch17, step1596]: loss 5.829879
[epoch17, step1597]: loss 1.261603
[epoch17, step1598]: loss 2.497222
[epoch17, step1599]: loss 6.416221
[epoch17, step1600]: loss 3.610636
[epoch17, step1601]: loss 1.549321
[epoch17, step1602]: loss 1.609807
[epoch17, step1603]: loss 1.784615
[epoch17, step1604]: loss 0.791077
[epoch17, step1605]: loss 1.028756
[epoch17, step1606]: loss 1.379765
[epoch17, step1607]: loss 1.918418
[epoch17, step1608]: loss 2.772646
[epoch17, step1609]: loss 1.219859
[epoch17, step1610]: loss 14.901010
[epoch17, step1611]: loss 0.814653
[epoch17, step1612]: loss 0.994539
[epoch17, step1613]: loss 1.664085
[epoch17, step1614]: loss 0.990089
[epoch17, step1615]: loss 2.535865
[epoch17, step1616]: loss 1.732934
[epoch17, step1617]: loss 1.237392
[epoch17, step1618]: loss 0.600023
[epoch17, step1619]: loss 0.902415
[epoch17, step1620]: loss 1.494739
[epoch17, step1621]: loss 10.666220
[epoch17, step1622]: loss 3.845392
[epoch17, step1623]: loss 1.035734
[epoch17, step1624]: loss 3.188834
[epoch17, step1625]: loss 10.472548
[epoch17, step1626]: loss 3.081705
[epoch17, step1627]: loss 1.623043
[epoch17, step1628]: loss 0.941321
[epoch17, step1629]: loss 0.930355
[epoch17, step1630]: loss 1.205243
[epoch17, step1631]: loss 1.068702
[epoch17, step1632]: loss 0.588441
[epoch17, step1633]: loss 1.403407
[epoch17, step1634]: loss 2.138433
[epoch17, step1635]: loss 2.448188
[epoch17, step1636]: loss 0.771650
[epoch17, step1637]: loss 4.638817
[epoch17, step1638]: loss 1.497156
[epoch17, step1639]: loss 2.114506
[epoch17, step1640]: loss 13.241938
[epoch17, step1641]: loss 0.665403
[epoch17, step1642]: loss 8.530141
[epoch17, step1643]: loss 1.630724
[epoch17, step1644]: loss 9.555573
[epoch17, step1645]: loss 1.008826
[epoch17, step1646]: loss 0.949098
[epoch17, step1647]: loss 4.553607
[epoch17, step1648]: loss 1.521532
[epoch17, step1649]: loss 2.492375
[epoch17, step1650]: loss 6.111272
[epoch17, step1651]: loss 5.154528
[epoch17, step1652]: loss 1.336108
[epoch17, step1653]: loss 4.803750
[epoch17, step1654]: loss 1.218625
[epoch17, step1655]: loss 4.867512
[epoch17, step1656]: loss 5.704668
[epoch17, step1657]: loss 3.964549
[epoch17, step1658]: loss 0.749620
[epoch17, step1659]: loss 1.030380
[epoch17, step1660]: loss 0.876148
[epoch17, step1661]: loss 12.237947
[epoch17, step1662]: loss 1.160051
[epoch17, step1663]: loss 7.106805
[epoch17, step1664]: loss 1.133071
[epoch17, step1665]: loss 1.592493
[epoch17, step1666]: loss 0.603079
[epoch17, step1667]: loss 1.040752
[epoch17, step1668]: loss 0.683670
[epoch17, step1669]: loss 4.050680
[epoch17, step1670]: loss 6.724994
[epoch17, step1671]: loss 7.962320
[epoch17, step1672]: loss 1.389094
[epoch17, step1673]: loss 4.475379
[epoch17, step1674]: loss 9.898632
[epoch17, step1675]: loss 2.616762
[epoch17, step1676]: loss 2.996461
[epoch17, step1677]: loss 0.853679
[epoch17, step1678]: loss 1.415118
[epoch17, step1679]: loss 2.430843
[epoch17, step1680]: loss 1.323131
[epoch17, step1681]: loss 0.625500
[epoch17, step1682]: loss 1.796354
[epoch17, step1683]: loss 11.826418
[epoch17, step1684]: loss 0.830067
[epoch17, step1685]: loss 7.793736
[epoch17, step1686]: loss 5.678670
[epoch17, step1687]: loss 7.745197
[epoch17, step1688]: loss 6.913028
[epoch17, step1689]: loss 9.466443
[epoch17, step1690]: loss 1.055069
[epoch17, step1691]: loss 0.622690
[epoch17, step1692]: loss 1.660931
[epoch17, step1693]: loss 2.689927
[epoch17, step1694]: loss 0.948395
[epoch17, step1695]: loss 2.081552
[epoch17, step1696]: loss 1.351374
[epoch17, step1697]: loss 1.915374
[epoch17, step1698]: loss 0.891533
[epoch17, step1699]: loss 3.782040
[epoch17, step1700]: loss 17.182955
[epoch17, step1701]: loss 1.199809
[epoch17, step1702]: loss 0.856934
[epoch17, step1703]: loss 1.058818
[epoch17, step1704]: loss 1.378290
[epoch17, step1705]: loss 1.020719
[epoch17, step1706]: loss 2.057424
[epoch17, step1707]: loss 3.164037
[epoch17, step1708]: loss 1.572878
[epoch17, step1709]: loss 2.007703
[epoch17, step1710]: loss 1.719553
[epoch17, step1711]: loss 6.567006
[epoch17, step1712]: loss 21.436996
[epoch17, step1713]: loss 8.340811
[epoch17, step1714]: loss 15.295860
[epoch17, step1715]: loss 1.881705
[epoch17, step1716]: loss 1.381220
[epoch17, step1717]: loss 4.090295
[epoch17, step1718]: loss 5.427133
[epoch17, step1719]: loss 25.267647
[epoch17, step1720]: loss 1.846432
[epoch17, step1721]: loss 10.767700
[epoch17, step1722]: loss 0.778897
[epoch17, step1723]: loss 0.811463
[epoch17, step1724]: loss 3.068381
[epoch17, step1725]: loss 1.706505
[epoch17, step1726]: loss 2.072427
[epoch17, step1727]: loss 1.103988
[epoch17, step1728]: loss 2.602648
[epoch17, step1729]: loss 1.669715
[epoch17, step1730]: loss 1.906809
[epoch17, step1731]: loss 1.030306
[epoch17, step1732]: loss 2.553970
[epoch17, step1733]: loss 1.141659
[epoch17, step1734]: loss 12.147573
[epoch17, step1735]: loss 10.848629
[epoch17, step1736]: loss 5.958142
[epoch17, step1737]: loss 5.183106
[epoch17, step1738]: loss 0.949174
[epoch17, step1739]: loss 1.238698
[epoch17, step1740]: loss 4.771634
[epoch17, step1741]: loss 9.733706
[epoch17, step1742]: loss 6.273463
[epoch17, step1743]: loss 13.365337
[epoch17, step1744]: loss 2.604138
[epoch17, step1745]: loss 14.641126
[epoch17, step1746]: loss 6.389391
[epoch17, step1747]: loss 2.443666
[epoch17, step1748]: loss 3.072288
[epoch17, step1749]: loss 6.983689
[epoch17, step1750]: loss 11.787884
[epoch17, step1751]: loss 1.248224
[epoch17, step1752]: loss 7.998196
[epoch17, step1753]: loss 16.764328
[epoch17, step1754]: loss 6.327111
[epoch17, step1755]: loss 0.688824
[epoch17, step1756]: loss 5.221917
[epoch17, step1757]: loss 4.709637
[epoch17, step1758]: loss 1.318091
[epoch17, step1759]: loss 1.315538
[epoch17, step1760]: loss 11.291802
[epoch17, step1761]: loss 0.951819
[epoch17, step1762]: loss 4.966469
[epoch17, step1763]: loss 5.702368
[epoch17, step1764]: loss 1.034449
[epoch17, step1765]: loss 10.929470
[epoch17, step1766]: loss 5.016459
[epoch17, step1767]: loss 1.808400
[epoch17, step1768]: loss 1.706783
[epoch17, step1769]: loss 13.913565
[epoch17, step1770]: loss 1.430084
[epoch17, step1771]: loss 1.397487
[epoch17, step1772]: loss 0.956262
[epoch17, step1773]: loss 2.025772
[epoch17, step1774]: loss 0.934099
[epoch17, step1775]: loss 2.746448
[epoch17, step1776]: loss 1.155472
[epoch17, step1777]: loss 1.047957
[epoch17, step1778]: loss 1.431473
[epoch17, step1779]: loss 6.466082
[epoch17, step1780]: loss 0.811719
[epoch17, step1781]: loss 8.091662
[epoch17, step1782]: loss 1.238712
[epoch17, step1783]: loss 1.311815
[epoch17, step1784]: loss 0.820677
[epoch17, step1785]: loss 1.506215
[epoch17, step1786]: loss 1.355623
[epoch17, step1787]: loss 1.406235
[epoch17, step1788]: loss 1.656917
[epoch17, step1789]: loss 2.056351
[epoch17, step1790]: loss 6.547616
[epoch17, step1791]: loss 0.962570
[epoch17, step1792]: loss 10.888391
[epoch17, step1793]: loss 3.326029
[epoch17, step1794]: loss 0.952640
[epoch17, step1795]: loss 1.993125
[epoch17, step1796]: loss 0.956573
[epoch17, step1797]: loss 1.354481
[epoch17, step1798]: loss 1.353017
[epoch17, step1799]: loss 0.955344
[epoch17, step1800]: loss 1.358392
[epoch17, step1801]: loss 5.162495
[epoch17, step1802]: loss 3.449533
[epoch17, step1803]: loss 0.995955
[epoch17, step1804]: loss 16.405817
[epoch17, step1805]: loss 0.943154
[epoch17, step1806]: loss 2.112968
[epoch17, step1807]: loss 2.367959
[epoch17, step1808]: loss 9.220146
[epoch17, step1809]: loss 1.605983
[epoch17, step1810]: loss 1.411261
[epoch17, step1811]: loss 13.054838
[epoch17, step1812]: loss 2.085884
[epoch17, step1813]: loss 1.515845
[epoch17, step1814]: loss 19.061146
[epoch17, step1815]: loss 0.819043
[epoch17, step1816]: loss 1.511945
[epoch17, step1817]: loss 3.507627
[epoch17, step1818]: loss 0.544968
[epoch17, step1819]: loss 2.133651
[epoch17, step1820]: loss 1.783451
[epoch17, step1821]: loss 4.263934
[epoch17, step1822]: loss 6.074328
[epoch17, step1823]: loss 0.935099
[epoch17, step1824]: loss 0.903691
[epoch17, step1825]: loss 1.152742
[epoch17, step1826]: loss 1.412542
[epoch17, step1827]: loss 5.294853
[epoch17, step1828]: loss 0.633813
[epoch17, step1829]: loss 0.947774
[epoch17, step1830]: loss 4.177552
[epoch17, step1831]: loss 1.323491
[epoch17, step1832]: loss 2.327985
[epoch17, step1833]: loss 8.595922
[epoch17, step1834]: loss 1.239390
[epoch17, step1835]: loss 3.127784
[epoch17, step1836]: loss 1.293750
[epoch17, step1837]: loss 0.995035
[epoch17, step1838]: loss 1.126179
[epoch17, step1839]: loss 16.085194
[epoch17, step1840]: loss 2.349767
[epoch17, step1841]: loss 6.401664
[epoch17, step1842]: loss 1.801205
[epoch17, step1843]: loss 2.297384
[epoch17, step1844]: loss 3.175773
[epoch17, step1845]: loss 2.381312
[epoch17, step1846]: loss 0.930841
[epoch17, step1847]: loss 11.400923
[epoch17, step1848]: loss 1.359677
[epoch17, step1849]: loss 4.934894
[epoch17, step1850]: loss 1.394988
[epoch17, step1851]: loss 0.565232
[epoch17, step1852]: loss 1.181482
[epoch17, step1853]: loss 2.989772
[epoch17, step1854]: loss 0.948593
[epoch17, step1855]: loss 0.928552
[epoch17, step1856]: loss 5.736902
[epoch17, step1857]: loss 11.380056
[epoch17, step1858]: loss 12.151438
[epoch17, step1859]: loss 1.452270
[epoch17, step1860]: loss 0.824789
[epoch17, step1861]: loss 0.545083
[epoch17, step1862]: loss 0.849700
[epoch17, step1863]: loss 0.875215
[epoch17, step1864]: loss 2.588464
[epoch17, step1865]: loss 0.845402
[epoch17, step1866]: loss 0.904233
[epoch17, step1867]: loss 0.975652
[epoch17, step1868]: loss 0.970186
[epoch17, step1869]: loss 0.656615
[epoch17, step1870]: loss 2.080622
[epoch17, step1871]: loss 3.008268
[epoch17, step1872]: loss 5.060143
[epoch17, step1873]: loss 1.114548
[epoch17, step1874]: loss 2.128280
[epoch17, step1875]: loss 5.794585
[epoch17, step1876]: loss 9.534987
[epoch17, step1877]: loss 0.783666
[epoch17, step1878]: loss 1.453402
[epoch17, step1879]: loss 1.130094
[epoch17, step1880]: loss 1.146865
[epoch17, step1881]: loss 1.837735
[epoch17, step1882]: loss 1.798460
[epoch17, step1883]: loss 1.428756
[epoch17, step1884]: loss 0.709139
[epoch17, step1885]: loss 0.832933
[epoch17, step1886]: loss 3.108864
[epoch17, step1887]: loss 0.810603
[epoch17, step1888]: loss 24.595554
[epoch17, step1889]: loss 3.724085
[epoch17, step1890]: loss 1.088933
[epoch17, step1891]: loss 1.685105
[epoch17, step1892]: loss 11.333786
[epoch17, step1893]: loss 4.098318
[epoch17, step1894]: loss 3.566083
[epoch17, step1895]: loss 8.681555
[epoch17, step1896]: loss 3.677438
[epoch17, step1897]: loss 0.858151
[epoch17, step1898]: loss 1.743082
[epoch17, step1899]: loss 1.530617
[epoch17, step1900]: loss 7.273231
[epoch17, step1901]: loss 3.605114
[epoch17, step1902]: loss 1.344220
[epoch17, step1903]: loss 0.974799
[epoch17, step1904]: loss 1.103175
[epoch17, step1905]: loss 6.792774
[epoch17, step1906]: loss 2.028290
[epoch17, step1907]: loss 2.920446
[epoch17, step1908]: loss 1.896958
[epoch17, step1909]: loss 1.277789
[epoch17, step1910]: loss 1.333659
[epoch17, step1911]: loss 2.377096
[epoch17, step1912]: loss 2.032928
[epoch17, step1913]: loss 2.457620
[epoch17, step1914]: loss 3.073302
[epoch17, step1915]: loss 1.054443
[epoch17, step1916]: loss 9.684974
[epoch17, step1917]: loss 1.284274
[epoch17, step1918]: loss 1.352032
[epoch17, step1919]: loss 0.655263
[epoch17, step1920]: loss 0.678986
[epoch17, step1921]: loss 40.962227
[epoch17, step1922]: loss 11.399889
[epoch17, step1923]: loss 3.018633
[epoch17, step1924]: loss 1.806360
[epoch17, step1925]: loss 0.629935
[epoch17, step1926]: loss 2.214760
[epoch17, step1927]: loss 0.723887
[epoch17, step1928]: loss 1.058102
[epoch17, step1929]: loss 1.506807
[epoch17, step1930]: loss 1.458919
[epoch17, step1931]: loss 0.835005
[epoch17, step1932]: loss 3.907269
[epoch17, step1933]: loss 2.122728
[epoch17, step1934]: loss 7.688285
[epoch17, step1935]: loss 1.106549
[epoch17, step1936]: loss 2.154017
[epoch17, step1937]: loss 1.629208
[epoch17, step1938]: loss 1.468550
[epoch17, step1939]: loss 8.387793
[epoch17, step1940]: loss 0.865353
[epoch17, step1941]: loss 1.294100
[epoch17, step1942]: loss 1.273624
[epoch17, step1943]: loss 6.881659
[epoch17, step1944]: loss 1.302046
[epoch17, step1945]: loss 1.524976
[epoch17, step1946]: loss 1.874837
[epoch17, step1947]: loss 7.176933
[epoch17, step1948]: loss 1.392302
[epoch17, step1949]: loss 1.461041
[epoch17, step1950]: loss 7.383124
[epoch17, step1951]: loss 0.749015
[epoch17, step1952]: loss 5.481819
[epoch17, step1953]: loss 1.178703
[epoch17, step1954]: loss 0.931441
[epoch17, step1955]: loss 1.256700
[epoch17, step1956]: loss 2.371673
[epoch17, step1957]: loss 0.847527
[epoch17, step1958]: loss 2.261706
[epoch17, step1959]: loss 1.356451
[epoch17, step1960]: loss 0.715651
[epoch17, step1961]: loss 10.533405
[epoch17, step1962]: loss 1.747756
[epoch17, step1963]: loss 1.059006
[epoch17, step1964]: loss 6.204225
[epoch17, step1965]: loss 8.146910
[epoch17, step1966]: loss 1.198266
[epoch17, step1967]: loss 1.752264
[epoch17, step1968]: loss 2.298604
[epoch17, step1969]: loss 0.681475
[epoch17, step1970]: loss 1.028315
[epoch17, step1971]: loss 2.314109
[epoch17, step1972]: loss 8.610633
[epoch17, step1973]: loss 0.797459
[epoch17, step1974]: loss 5.141735
[epoch17, step1975]: loss 2.342831
[epoch17, step1976]: loss 1.209437
[epoch17, step1977]: loss 2.778820
[epoch17, step1978]: loss 10.593286
[epoch17, step1979]: loss 1.059947
[epoch17, step1980]: loss 13.641743
[epoch17, step1981]: loss 0.631186
[epoch17, step1982]: loss 1.007592
[epoch17, step1983]: loss 1.402342
[epoch17, step1984]: loss 2.010078
[epoch17, step1985]: loss 0.944297
[epoch17, step1986]: loss 1.127539
[epoch17, step1987]: loss 10.573452
[epoch17, step1988]: loss 1.113055
[epoch17, step1989]: loss 1.465499
[epoch17, step1990]: loss 1.392065
[epoch17, step1991]: loss 1.445138
[epoch17, step1992]: loss 8.375240
[epoch17, step1993]: loss 3.153895
[epoch17, step1994]: loss 6.551058
[epoch17, step1995]: loss 19.067688
[epoch17, step1996]: loss 1.382194
[epoch17, step1997]: loss 0.420315
[epoch17, step1998]: loss 0.767078
[epoch17, step1999]: loss 1.238336
[epoch17, step2000]: loss 11.905846
[epoch17, step2001]: loss 0.696475
[epoch17, step2002]: loss 2.658944
[epoch17, step2003]: loss 0.978321
[epoch17, step2004]: loss 3.691564
[epoch17, step2005]: loss 14.839826
[epoch17, step2006]: loss 0.831067
[epoch17, step2007]: loss 5.172164
[epoch17, step2008]: loss 3.949073
[epoch17, step2009]: loss 1.789192
[epoch17, step2010]: loss 5.124529
[epoch17, step2011]: loss 1.670076
[epoch17, step2012]: loss 10.900514
[epoch17, step2013]: loss 1.172188
[epoch17, step2014]: loss 1.508583
[epoch17, step2015]: loss 0.709383
[epoch17, step2016]: loss 1.831003
[epoch17, step2017]: loss 6.673374
[epoch17, step2018]: loss 1.009945
[epoch17, step2019]: loss 8.904241
[epoch17, step2020]: loss 5.022845
[epoch17, step2021]: loss 1.335692
[epoch17, step2022]: loss 2.285571
[epoch17, step2023]: loss 1.323161
[epoch17, step2024]: loss 1.880286
[epoch17, step2025]: loss 2.306390
[epoch17, step2026]: loss 1.116715
[epoch17, step2027]: loss 1.452617
[epoch17, step2028]: loss 8.384146
[epoch17, step2029]: loss 3.598818
[epoch17, step2030]: loss 1.748275
[epoch17, step2031]: loss 0.818807
[epoch17, step2032]: loss 1.590976
[epoch17, step2033]: loss 1.594370
[epoch17, step2034]: loss 23.192675
[epoch17, step2035]: loss 7.522836
[epoch17, step2036]: loss 0.663528
[epoch17, step2037]: loss 0.677914
[epoch17, step2038]: loss 0.600498
[epoch17, step2039]: loss 0.752723
[epoch17, step2040]: loss 13.302620
[epoch17, step2041]: loss 10.539171
[epoch17, step2042]: loss 3.029880
[epoch17, step2043]: loss 1.321023
[epoch17, step2044]: loss 2.503729
[epoch17, step2045]: loss 10.038625
[epoch17, step2046]: loss 0.857008
[epoch17, step2047]: loss 10.550076
[epoch17, step2048]: loss 1.036382
[epoch17, step2049]: loss 1.518712
[epoch17, step2050]: loss 3.867522
[epoch17, step2051]: loss 2.619209
[epoch17, step2052]: loss 0.805168
[epoch17, step2053]: loss 68.985092
[epoch17, step2054]: loss 5.498267
[epoch17, step2055]: loss 1.861108
[epoch17, step2056]: loss 0.964446
[epoch17, step2057]: loss 1.048477
[epoch17, step2058]: loss 1.627028
[epoch17, step2059]: loss 5.599300
[epoch17, step2060]: loss 10.583482
[epoch17, step2061]: loss 2.320727
[epoch17, step2062]: loss 0.849963
[epoch17, step2063]: loss 1.416031
[epoch17, step2064]: loss 0.718996
[epoch17, step2065]: loss 0.871542
[epoch17, step2066]: loss 1.641842
[epoch17, step2067]: loss 4.763141
[epoch17, step2068]: loss 14.314957
[epoch17, step2069]: loss 1.010015
[epoch17, step2070]: loss 1.566337
[epoch17, step2071]: loss 0.623883
[epoch17, step2072]: loss 2.526979
[epoch17, step2073]: loss 7.744707
[epoch17, step2074]: loss 0.837463
[epoch17, step2075]: loss 9.428882
[epoch17, step2076]: loss 1.629537
[epoch17, step2077]: loss 0.897666
[epoch17, step2078]: loss 3.399646
[epoch17, step2079]: loss 4.627385
[epoch17, step2080]: loss 2.062306
[epoch17, step2081]: loss 10.454901
[epoch17, step2082]: loss 24.281874
[epoch17, step2083]: loss 1.485931
[epoch17, step2084]: loss 2.813528
[epoch17, step2085]: loss 6.118563
[epoch17, step2086]: loss 3.658620
[epoch17, step2087]: loss 1.913591
[epoch17, step2088]: loss 0.999856
[epoch17, step2089]: loss 5.995525
[epoch17, step2090]: loss 0.638785
[epoch17, step2091]: loss 9.032919
[epoch17, step2092]: loss 1.456966
[epoch17, step2093]: loss 1.101682
[epoch17, step2094]: loss 2.292443
[epoch17, step2095]: loss 0.706826
[epoch17, step2096]: loss 16.442595
[epoch17, step2097]: loss 1.045151
[epoch17, step2098]: loss 4.242545
[epoch17, step2099]: loss 5.092716
[epoch17, step2100]: loss 1.782731
[epoch17, step2101]: loss 0.652109
[epoch17, step2102]: loss 0.930509
[epoch17, step2103]: loss 8.294114
[epoch17, step2104]: loss 3.058371
[epoch17, step2105]: loss 12.311422
[epoch17, step2106]: loss 6.660441
[epoch17, step2107]: loss 2.925852
[epoch17, step2108]: loss 1.732500
[epoch17, step2109]: loss 15.807196
[epoch17, step2110]: loss 1.031566
[epoch17, step2111]: loss 0.569699
[epoch17, step2112]: loss 9.136975
[epoch17, step2113]: loss 0.744759
[epoch17, step2114]: loss 1.127457
[epoch17, step2115]: loss 2.566591
[epoch17, step2116]: loss 2.903580
[epoch17, step2117]: loss 0.953597
[epoch17, step2118]: loss 1.035804
[epoch17, step2119]: loss 1.554171
[epoch17, step2120]: loss 13.493979
[epoch17, step2121]: loss 6.700024
[epoch17, step2122]: loss 0.851832
[epoch17, step2123]: loss 4.059894
[epoch17, step2124]: loss 1.153833
[epoch17, step2125]: loss 4.245703
[epoch17, step2126]: loss 9.220138
[epoch17, step2127]: loss 7.051062
[epoch17, step2128]: loss 1.380481
[epoch17, step2129]: loss 17.194122
[epoch17, step2130]: loss 8.827363
[epoch17, step2131]: loss 1.637213
[epoch17, step2132]: loss 3.657978
[epoch17, step2133]: loss 8.347355
[epoch17, step2134]: loss 2.992826
[epoch17, step2135]: loss 1.083088
[epoch17, step2136]: loss 0.744289
[epoch17, step2137]: loss 1.293287
[epoch17, step2138]: loss 10.638650
[epoch17, step2139]: loss 1.110586
[epoch17, step2140]: loss 10.326971
[epoch17, step2141]: loss 0.666845
[epoch17, step2142]: loss 18.779617
[epoch17, step2143]: loss 27.758766
[epoch17, step2144]: loss 3.539176
[epoch17, step2145]: loss 4.138187
[epoch17, step2146]: loss 1.080437
[epoch17, step2147]: loss 1.038374
[epoch17, step2148]: loss 0.957841
[epoch17, step2149]: loss 1.342337
[epoch17, step2150]: loss 0.964851
[epoch17, step2151]: loss 21.717030
[epoch17, step2152]: loss 4.103807
[epoch17, step2153]: loss 1.157785
[epoch17, step2154]: loss 1.418457
[epoch17, step2155]: loss 1.159363
[epoch17, step2156]: loss 3.761203
[epoch17, step2157]: loss 1.253739
[epoch17, step2158]: loss 1.457417
[epoch17, step2159]: loss 3.931117
[epoch17, step2160]: loss 4.086596
[epoch17, step2161]: loss 1.001675
[epoch17, step2162]: loss 6.540411
[epoch17, step2163]: loss 0.771783
[epoch17, step2164]: loss 0.666107
[epoch17, step2165]: loss 2.130985
[epoch17, step2166]: loss 0.653857
[epoch17, step2167]: loss 3.073374
[epoch17, step2168]: loss 0.687050
[epoch17, step2169]: loss 1.401994
[epoch17, step2170]: loss 1.725370
[epoch17, step2171]: loss 0.686398
[epoch17, step2172]: loss 0.481102
[epoch17, step2173]: loss 0.972054
[epoch17, step2174]: loss 0.709059
[epoch17, step2175]: loss 6.078400
[epoch17, step2176]: loss 2.528427
[epoch17, step2177]: loss 1.422904
[epoch17, step2178]: loss 9.793069
[epoch17, step2179]: loss 1.717429
[epoch17, step2180]: loss 1.541230
[epoch17, step2181]: loss 2.324943
[epoch17, step2182]: loss 1.427954
[epoch17, step2183]: loss 0.842647
[epoch17, step2184]: loss 3.953479
[epoch17, step2185]: loss 2.509249
[epoch17, step2186]: loss 1.051329
[epoch17, step2187]: loss 1.400636
[epoch17, step2188]: loss 1.256620
[epoch17, step2189]: loss 0.943861
[epoch17, step2190]: loss 4.587720
[epoch17, step2191]: loss 1.183378
[epoch17, step2192]: loss 1.900010
[epoch17, step2193]: loss 0.968259
[epoch17, step2194]: loss 2.257432
[epoch17, step2195]: loss 1.336495
[epoch17, step2196]: loss 10.275716
[epoch17, step2197]: loss 0.790730
[epoch17, step2198]: loss 6.594358
[epoch17, step2199]: loss 1.759820
[epoch17, step2200]: loss 1.358893
[epoch17, step2201]: loss 2.375615
[epoch17, step2202]: loss 3.270159
[epoch17, step2203]: loss 0.657459
[epoch17, step2204]: loss 1.402197
[epoch17, step2205]: loss 1.435704
[epoch17, step2206]: loss 1.324403
[epoch17, step2207]: loss 0.796862
[epoch17, step2208]: loss 1.193761
[epoch17, step2209]: loss 3.103209
[epoch17, step2210]: loss 1.290584
[epoch17, step2211]: loss 16.034639
[epoch17, step2212]: loss 6.738214
[epoch17, step2213]: loss 0.654725
[epoch17, step2214]: loss 0.613655
[epoch17, step2215]: loss 1.763833
[epoch17, step2216]: loss 1.192381
[epoch17, step2217]: loss 1.887960
[epoch17, step2218]: loss 2.069970
[epoch17, step2219]: loss 1.606924
[epoch17, step2220]: loss 1.711796
[epoch17, step2221]: loss 0.997114
[epoch17, step2222]: loss 10.622320
[epoch17, step2223]: loss 4.804795
[epoch17, step2224]: loss 17.579809
[epoch17, step2225]: loss 2.405210
[epoch17, step2226]: loss 9.742727
[epoch17, step2227]: loss 1.558082
[epoch17, step2228]: loss 1.315779
[epoch17, step2229]: loss 2.740858
[epoch17, step2230]: loss 2.382896
[epoch17, step2231]: loss 10.985703
[epoch17, step2232]: loss 1.092611
[epoch17, step2233]: loss 1.705146
[epoch17, step2234]: loss 1.088297
[epoch17, step2235]: loss 2.116320
[epoch17, step2236]: loss 1.064813
[epoch17, step2237]: loss 1.039519
[epoch17, step2238]: loss 6.973823
[epoch17, step2239]: loss 20.870705
[epoch17, step2240]: loss 1.015013
[epoch17, step2241]: loss 5.107837
[epoch17, step2242]: loss 10.306314
[epoch17, step2243]: loss 7.041624
[epoch17, step2244]: loss 1.849287
[epoch17, step2245]: loss 17.433483
[epoch17, step2246]: loss 0.852011
[epoch17, step2247]: loss 1.334323
[epoch17, step2248]: loss 0.535848
[epoch17, step2249]: loss 5.312689
[epoch17, step2250]: loss 0.848198
[epoch17, step2251]: loss 7.750192
[epoch17, step2252]: loss 2.254859
[epoch17, step2253]: loss 0.871727
[epoch17, step2254]: loss 7.489147
[epoch17, step2255]: loss 1.674234
[epoch17, step2256]: loss 2.183909
[epoch17, step2257]: loss 0.910711
[epoch17, step2258]: loss 2.918168
[epoch17, step2259]: loss 5.889235
[epoch17, step2260]: loss 1.429010
[epoch17, step2261]: loss 1.006871
[epoch17, step2262]: loss 2.875971
[epoch17, step2263]: loss 0.687489
[epoch17, step2264]: loss 9.276793
[epoch17, step2265]: loss 1.194996
[epoch17, step2266]: loss 0.730765
[epoch17, step2267]: loss 11.464466
[epoch17, step2268]: loss 1.182244
[epoch17, step2269]: loss 7.981043
[epoch17, step2270]: loss 2.432850
[epoch17, step2271]: loss 10.292998
[epoch17, step2272]: loss 1.006078
[epoch17, step2273]: loss 1.176775
[epoch17, step2274]: loss 2.460649
[epoch17, step2275]: loss 1.051879
[epoch17, step2276]: loss 2.254775
[epoch17, step2277]: loss 13.627588
[epoch17, step2278]: loss 11.064087
[epoch17, step2279]: loss 9.445385
[epoch17, step2280]: loss 13.443986
[epoch17, step2281]: loss 1.018738
[epoch17, step2282]: loss 3.411624
[epoch17, step2283]: loss 2.760591
[epoch17, step2284]: loss 10.896851
[epoch17, step2285]: loss 2.591654
[epoch17, step2286]: loss 1.369468
[epoch17, step2287]: loss 0.904757
[epoch17, step2288]: loss 0.625347
[epoch17, step2289]: loss 1.360318
[epoch17, step2290]: loss 1.617458
[epoch17, step2291]: loss 7.422339
[epoch17, step2292]: loss 2.470913
[epoch17, step2293]: loss 0.792992
[epoch17, step2294]: loss 7.505721
[epoch17, step2295]: loss 16.047235
[epoch17, step2296]: loss 13.967839
[epoch17, step2297]: loss 0.937319
[epoch17, step2298]: loss 11.689828
[epoch17, step2299]: loss 1.277089
[epoch17, step2300]: loss 2.641092
[epoch17, step2301]: loss 1.128165
[epoch17, step2302]: loss 1.609847
[epoch17, step2303]: loss 0.712641
[epoch17, step2304]: loss 0.580987
[epoch17, step2305]: loss 1.113249
[epoch17, step2306]: loss 0.913553
[epoch17, step2307]: loss 1.384428
[epoch17, step2308]: loss 1.184793
[epoch17, step2309]: loss 0.878746
[epoch17, step2310]: loss 0.907918
[epoch17, step2311]: loss 1.097079
[epoch17, step2312]: loss 2.848478
[epoch17, step2313]: loss 2.420841
[epoch17, step2314]: loss 2.067069
[epoch17, step2315]: loss 8.036043
[epoch17, step2316]: loss 2.632443
[epoch17, step2317]: loss 2.590967
[epoch17, step2318]: loss 1.515911
[epoch17, step2319]: loss 3.577306
[epoch17, step2320]: loss 1.723565
[epoch17, step2321]: loss 1.070700
[epoch17, step2322]: loss 1.468167
[epoch17, step2323]: loss 1.282492
[epoch17, step2324]: loss 8.599001
[epoch17, step2325]: loss 1.279538
[epoch17, step2326]: loss 3.941672
[epoch17, step2327]: loss 0.655855
[epoch17, step2328]: loss 2.072290
[epoch17, step2329]: loss 0.774255
[epoch17, step2330]: loss 1.560399
[epoch17, step2331]: loss 1.111618
[epoch17, step2332]: loss 4.809884
[epoch17, step2333]: loss 0.783110
[epoch17, step2334]: loss 0.767305
[epoch17, step2335]: loss 0.695876
[epoch17, step2336]: loss 0.856345
[epoch17, step2337]: loss 1.126930
[epoch17, step2338]: loss 0.809790
[epoch17, step2339]: loss 0.637114
[epoch17, step2340]: loss 5.667415
[epoch17, step2341]: loss 2.124769
[epoch17, step2342]: loss 0.565010
[epoch17, step2343]: loss 0.988842
[epoch17, step2344]: loss 1.323157
[epoch17, step2345]: loss 2.447583
[epoch17, step2346]: loss 1.020610
[epoch17, step2347]: loss 1.303762
[epoch17, step2348]: loss 1.101076
[epoch17, step2349]: loss 0.858150
[epoch17, step2350]: loss 0.805348
[epoch17, step2351]: loss 2.589748
[epoch17, step2352]: loss 1.866776
[epoch17, step2353]: loss 1.094892
[epoch17, step2354]: loss 0.706169
[epoch17, step2355]: loss 6.379852
[epoch17, step2356]: loss 2.397702
[epoch17, step2357]: loss 0.553454
[epoch17, step2358]: loss 4.293840
[epoch17, step2359]: loss 0.567544
[epoch17, step2360]: loss 11.633516
[epoch17, step2361]: loss 1.600387
[epoch17, step2362]: loss 3.690037
[epoch17, step2363]: loss 8.283164
[epoch17, step2364]: loss 6.460527
[epoch17, step2365]: loss 1.051116
[epoch17, step2366]: loss 2.262675
[epoch17, step2367]: loss 1.170274
[epoch17, step2368]: loss 1.637988
[epoch17, step2369]: loss 3.461357
[epoch17, step2370]: loss 1.173077
[epoch17, step2371]: loss 2.329093
[epoch17, step2372]: loss 1.871620
[epoch17, step2373]: loss 1.441080
[epoch17, step2374]: loss 1.365305
[epoch17, step2375]: loss 5.005903
[epoch17, step2376]: loss 0.799036
[epoch17, step2377]: loss 1.667256
[epoch17, step2378]: loss 0.787857
[epoch17, step2379]: loss 1.231910
[epoch17, step2380]: loss 1.559718
[epoch17, step2381]: loss 9.636496
[epoch17, step2382]: loss 1.585336
[epoch17, step2383]: loss 2.423769
[epoch17, step2384]: loss 0.718200
[epoch17, step2385]: loss 3.133929
[epoch17, step2386]: loss 1.187313
[epoch17, step2387]: loss 1.340806
[epoch17, step2388]: loss 0.744582
[epoch17, step2389]: loss 1.377921
[epoch17, step2390]: loss 0.804280
[epoch17, step2391]: loss 8.435582
[epoch17, step2392]: loss 3.056692
[epoch17, step2393]: loss 1.523577
[epoch17, step2394]: loss 2.418812
[epoch17, step2395]: loss 1.234313
[epoch17, step2396]: loss 1.124441
[epoch17, step2397]: loss 1.087515
[epoch17, step2398]: loss 4.040709
[epoch17, step2399]: loss 10.904282
[epoch17, step2400]: loss 1.493896
[epoch17, step2401]: loss 1.566654
[epoch17, step2402]: loss 0.949565
[epoch17, step2403]: loss 0.650461
[epoch17, step2404]: loss 1.868483
[epoch17, step2405]: loss 6.471129
[epoch17, step2406]: loss 4.613962
[epoch17, step2407]: loss 3.086369
[epoch17, step2408]: loss 2.194597
[epoch17, step2409]: loss 2.835934
[epoch17, step2410]: loss 3.723041
[epoch17, step2411]: loss 2.291810
[epoch17, step2412]: loss 1.220546
[epoch17, step2413]: loss 0.621438
[epoch17, step2414]: loss 0.773190
[epoch17, step2415]: loss 1.409434
[epoch17, step2416]: loss 7.500022
[epoch17, step2417]: loss 4.363171
[epoch17, step2418]: loss 1.726106
[epoch17, step2419]: loss 6.848267
[epoch17, step2420]: loss 1.975695
[epoch17, step2421]: loss 0.507135
[epoch17, step2422]: loss 1.208637
[epoch17, step2423]: loss 1.937080
[epoch17, step2424]: loss 7.549165
[epoch17, step2425]: loss 1.718073
[epoch17, step2426]: loss 1.386302
[epoch17, step2427]: loss 13.805347
[epoch17, step2428]: loss 0.559278
[epoch17, step2429]: loss 0.754162
[epoch17, step2430]: loss 1.267340
[epoch17, step2431]: loss 1.050655
[epoch17, step2432]: loss 1.041365
[epoch17, step2433]: loss 10.779432
[epoch17, step2434]: loss 37.738533
[epoch17, step2435]: loss 6.562113
[epoch17, step2436]: loss 1.840708
[epoch17, step2437]: loss 0.723389
[epoch17, step2438]: loss 2.524630
[epoch17, step2439]: loss 0.879502
[epoch17, step2440]: loss 1.965297
[epoch17, step2441]: loss 2.371981
[epoch17, step2442]: loss 4.856896
[epoch17, step2443]: loss 2.149301
[epoch17, step2444]: loss 2.106462
[epoch17, step2445]: loss 4.073524
[epoch17, step2446]: loss 2.513301
[epoch17, step2447]: loss 2.185552
[epoch17, step2448]: loss 0.834968
[epoch17, step2449]: loss 2.083806
[epoch17, step2450]: loss 1.273520
[epoch17, step2451]: loss 1.588306
[epoch17, step2452]: loss 0.622411
[epoch17, step2453]: loss 0.880846
[epoch17, step2454]: loss 0.871638
[epoch17, step2455]: loss 2.694893
[epoch17, step2456]: loss 1.644813
[epoch17, step2457]: loss 1.514951
[epoch17, step2458]: loss 6.992156
[epoch17, step2459]: loss 0.730649
[epoch17, step2460]: loss 1.510641
[epoch17, step2461]: loss 1.176350
[epoch17, step2462]: loss 1.354574
[epoch17, step2463]: loss 1.140451
[epoch17, step2464]: loss 1.063826
[epoch17, step2465]: loss 1.870663
[epoch17, step2466]: loss 1.985075
[epoch17, step2467]: loss 0.601022
[epoch17, step2468]: loss 3.281770
[epoch17, step2469]: loss 0.725800
[epoch17, step2470]: loss 9.330232
[epoch17, step2471]: loss 16.263721
[epoch17, step2472]: loss 10.614476
[epoch17, step2473]: loss 11.910124
[epoch17, step2474]: loss 11.713986
[epoch17, step2475]: loss 4.632518
[epoch17, step2476]: loss 2.238060
[epoch17, step2477]: loss 1.866778
[epoch17, step2478]: loss 8.518503
[epoch17, step2479]: loss 8.245988
[epoch17, step2480]: loss 6.597945
[epoch17, step2481]: loss 0.732331
[epoch17, step2482]: loss 3.011571
[epoch17, step2483]: loss 1.631207
[epoch17, step2484]: loss 1.654344
[epoch17, step2485]: loss 0.978738
[epoch17, step2486]: loss 0.757810
[epoch17, step2487]: loss 3.614571
[epoch17, step2488]: loss 2.033186
[epoch17, step2489]: loss 0.626090
[epoch17, step2490]: loss 3.837232
[epoch17, step2491]: loss 0.806964
[epoch17, step2492]: loss 1.213283
[epoch17, step2493]: loss 1.646363
[epoch17, step2494]: loss 1.003567
[epoch17, step2495]: loss 1.508284
[epoch17, step2496]: loss 2.483649
[epoch17, step2497]: loss 1.344557
[epoch17, step2498]: loss 2.027085
[epoch17, step2499]: loss 13.217689
[epoch17, step2500]: loss 1.807889
[epoch17, step2501]: loss 1.565692
[epoch17, step2502]: loss 1.090649
[epoch17, step2503]: loss 7.628375
[epoch17, step2504]: loss 10.362282
[epoch17, step2505]: loss 0.684360
[epoch17, step2506]: loss 11.821081
[epoch17, step2507]: loss 3.526698
[epoch17, step2508]: loss 1.296293
[epoch17, step2509]: loss 9.309614
[epoch17, step2510]: loss 4.245749
[epoch17, step2511]: loss 0.742673
[epoch17, step2512]: loss 1.291789
[epoch17, step2513]: loss 0.637629
[epoch17, step2514]: loss 1.317620
[epoch17, step2515]: loss 2.892471
[epoch17, step2516]: loss 6.714680
[epoch17, step2517]: loss 5.278935
[epoch17, step2518]: loss 12.158948
[epoch17, step2519]: loss 5.572026
[epoch17, step2520]: loss 1.452741
[epoch17, step2521]: loss 11.029852
[epoch17, step2522]: loss 1.788515
[epoch17, step2523]: loss 0.810045
[epoch17, step2524]: loss 5.733992
[epoch17, step2525]: loss 1.664598
[epoch17, step2526]: loss 26.032169
[epoch17, step2527]: loss 13.455763
[epoch17, step2528]: loss 2.680388
[epoch17, step2529]: loss 1.254999
[epoch17, step2530]: loss 1.992482
[epoch17, step2531]: loss 0.902097
[epoch17, step2532]: loss 3.003731
[epoch17, step2533]: loss 1.571704
[epoch17, step2534]: loss 2.868117
[epoch17, step2535]: loss 0.829999
[epoch17, step2536]: loss 1.098520
[epoch17, step2537]: loss 7.862239
[epoch17, step2538]: loss 2.072795
[epoch17, step2539]: loss 1.646847
[epoch17, step2540]: loss 2.583864
[epoch17, step2541]: loss 2.140486
[epoch17, step2542]: loss 7.602628
[epoch17, step2543]: loss 1.439564
[epoch17, step2544]: loss 6.431005
[epoch17, step2545]: loss 5.660618
[epoch17, step2546]: loss 0.556159
[epoch17, step2547]: loss 1.229404
[epoch17, step2548]: loss 1.053002
[epoch17, step2549]: loss 2.175209
[epoch17, step2550]: loss 22.381859
[epoch17, step2551]: loss 1.404258
[epoch17, step2552]: loss 2.099706
[epoch17, step2553]: loss 1.834210
[epoch17, step2554]: loss 1.807865
[epoch17, step2555]: loss 4.294564
[epoch17, step2556]: loss 0.813027
[epoch17, step2557]: loss 0.657871
[epoch17, step2558]: loss 1.566764
[epoch17, step2559]: loss 1.292137
[epoch17, step2560]: loss 0.851737
[epoch17, step2561]: loss 0.616968
[epoch17, step2562]: loss 1.063576
[epoch17, step2563]: loss 1.672759
[epoch17, step2564]: loss 3.184438
[epoch17, step2565]: loss 1.213230
[epoch17, step2566]: loss 1.967022
[epoch17, step2567]: loss 0.972442
[epoch17, step2568]: loss 20.874767
[epoch17, step2569]: loss 23.278053
[epoch17, step2570]: loss 1.156994
[epoch17, step2571]: loss 0.682449
[epoch17, step2572]: loss 2.535418
[epoch17, step2573]: loss 1.275071
[epoch17, step2574]: loss 0.917706
[epoch17, step2575]: loss 1.420496
[epoch17, step2576]: loss 0.991109
[epoch17, step2577]: loss 0.994535
[epoch17, step2578]: loss 0.348932
[epoch17, step2579]: loss 3.652822
[epoch17, step2580]: loss 0.936339
[epoch17, step2581]: loss 2.695282
[epoch17, step2582]: loss 1.062367
[epoch17, step2583]: loss 0.654310
[epoch17, step2584]: loss 2.389554
[epoch17, step2585]: loss 28.117804
[epoch17, step2586]: loss 1.887093
[epoch17, step2587]: loss 3.693329
[epoch17, step2588]: loss 0.788117
[epoch17, step2589]: loss 1.100039
[epoch17, step2590]: loss 2.791513
[epoch17, step2591]: loss 1.569628
[epoch17, step2592]: loss 10.497076
[epoch17, step2593]: loss 9.788641
[epoch17, step2594]: loss 6.551940
[epoch17, step2595]: loss 1.271381
[epoch17, step2596]: loss 1.914628
[epoch17, step2597]: loss 9.986255
[epoch17, step2598]: loss 7.289521
[epoch17, step2599]: loss 4.828273
[epoch17, step2600]: loss 1.243199
[epoch17, step2601]: loss 6.104793
[epoch17, step2602]: loss 2.205632
[epoch17, step2603]: loss 6.706517
[epoch17, step2604]: loss 1.921349
[epoch17, step2605]: loss 10.766947
[epoch17, step2606]: loss 1.003130
[epoch17, step2607]: loss 16.386389
[epoch17, step2608]: loss 4.076703
[epoch17, step2609]: loss 15.470565
[epoch17, step2610]: loss 6.878233
[epoch17, step2611]: loss 10.266707
[epoch17, step2612]: loss 6.687435
[epoch17, step2613]: loss 21.205517
[epoch17, step2614]: loss 0.982662
[epoch17, step2615]: loss 16.891554
[epoch17, step2616]: loss 0.904174
[epoch17, step2617]: loss 5.912761
[epoch17, step2618]: loss 1.662337
[epoch17, step2619]: loss 1.560004
[epoch17, step2620]: loss 0.667381
[epoch17, step2621]: loss 0.810197
[epoch17, step2622]: loss 6.295743
[epoch17, step2623]: loss 1.514308
[epoch17, step2624]: loss 1.290335
[epoch17, step2625]: loss 27.136530
[epoch17, step2626]: loss 5.225654
[epoch17, step2627]: loss 1.293073
[epoch17, step2628]: loss 0.931399
[epoch17, step2629]: loss 6.275582
[epoch17, step2630]: loss 5.261876
[epoch17, step2631]: loss 1.291742
[epoch17, step2632]: loss 1.493751
[epoch17, step2633]: loss 2.617876
[epoch17, step2634]: loss 1.073316
[epoch17, step2635]: loss 1.054891
[epoch17, step2636]: loss 1.338037
[epoch17, step2637]: loss 14.722444
[epoch17, step2638]: loss 2.551903
[epoch17, step2639]: loss 1.156251
[epoch17, step2640]: loss 0.705293
[epoch17, step2641]: loss 5.287154
[epoch17, step2642]: loss 1.863413
[epoch17, step2643]: loss 1.641293
[epoch17, step2644]: loss 0.854543
[epoch17, step2645]: loss 0.881780
[epoch17, step2646]: loss 6.332506
[epoch17, step2647]: loss 2.803503
[epoch17, step2648]: loss 1.595827
[epoch17, step2649]: loss 2.367798
[epoch17, step2650]: loss 1.665224
[epoch17, step2651]: loss 2.806195
[epoch17, step2652]: loss 2.661331
[epoch17, step2653]: loss 2.147128
[epoch17, step2654]: loss 1.530334
[epoch17, step2655]: loss 1.106618
[epoch17, step2656]: loss 0.530186
[epoch17, step2657]: loss 0.558220
[epoch17, step2658]: loss 1.443410
[epoch17, step2659]: loss 1.383432
[epoch17, step2660]: loss 8.704195
[epoch17, step2661]: loss 9.555170
[epoch17, step2662]: loss 1.191422
[epoch17, step2663]: loss 6.574856
[epoch17, step2664]: loss 0.947757
[epoch17, step2665]: loss 3.944887
[epoch17, step2666]: loss 1.726386
[epoch17, step2667]: loss 0.903453
[epoch17, step2668]: loss 1.798354
[epoch17, step2669]: loss 6.194899
[epoch17, step2670]: loss 10.978149
[epoch17, step2671]: loss 0.763191
[epoch17, step2672]: loss 0.822676
[epoch17, step2673]: loss 1.061469
[epoch17, step2674]: loss 1.338000
[epoch17, step2675]: loss 2.627746
[epoch17, step2676]: loss 5.416022
[epoch17, step2677]: loss 6.634572
[epoch17, step2678]: loss 0.508051
[epoch17, step2679]: loss 0.721903
[epoch17, step2680]: loss 1.866674
[epoch17, step2681]: loss 2.378726
[epoch17, step2682]: loss 8.870049
[epoch17, step2683]: loss 2.111797
[epoch17, step2684]: loss 1.344899
[epoch17, step2685]: loss 2.839833
[epoch17, step2686]: loss 0.692982
[epoch17, step2687]: loss 1.330959
[epoch17, step2688]: loss 0.838925
[epoch17, step2689]: loss 0.551576
[epoch17, step2690]: loss 12.289483
[epoch17, step2691]: loss 6.433883
[epoch17, step2692]: loss 2.338707
[epoch17, step2693]: loss 11.152587
[epoch17, step2694]: loss 2.255169
[epoch17, step2695]: loss 3.150810
[epoch17, step2696]: loss 9.181059
[epoch17, step2697]: loss 1.466076
[epoch17, step2698]: loss 1.026652
[epoch17, step2699]: loss 0.799630
[epoch17, step2700]: loss 0.973532
[epoch17, step2701]: loss 9.150712
[epoch17, step2702]: loss 9.376111
[epoch17, step2703]: loss 1.689928
[epoch17, step2704]: loss 1.989521
[epoch17, step2705]: loss 1.200057
[epoch17, step2706]: loss 1.432194
[epoch17, step2707]: loss 0.874038
[epoch17, step2708]: loss 1.016002
[epoch17, step2709]: loss 6.077635
[epoch17, step2710]: loss 1.904137
[epoch17, step2711]: loss 9.009891
[epoch17, step2712]: loss 10.011486
[epoch17, step2713]: loss 1.361083
[epoch17, step2714]: loss 0.615519
[epoch17, step2715]: loss 4.736670
[epoch17, step2716]: loss 4.543178
[epoch17, step2717]: loss 1.109007
[epoch17, step2718]: loss 4.385989
[epoch17, step2719]: loss 0.924232
[epoch17, step2720]: loss 7.619843
[epoch17, step2721]: loss 1.568715
[epoch17, step2722]: loss 1.300084
[epoch17, step2723]: loss 1.199332
[epoch17, step2724]: loss 10.110761
[epoch17, step2725]: loss 20.327204
[epoch17, step2726]: loss 1.291939
[epoch17, step2727]: loss 0.944223
[epoch17, step2728]: loss 6.545074
[epoch17, step2729]: loss 1.354413
[epoch17, step2730]: loss 1.931771
[epoch17, step2731]: loss 7.676548
[epoch17, step2732]: loss 1.553587
[epoch17, step2733]: loss 2.179907
[epoch17, step2734]: loss 0.812374
[epoch17, step2735]: loss 1.298854
[epoch17, step2736]: loss 0.954815
[epoch17, step2737]: loss 4.609932
[epoch17, step2738]: loss 11.813414
[epoch17, step2739]: loss 9.081878
[epoch17, step2740]: loss 1.206128
[epoch17, step2741]: loss 1.881073
[epoch17, step2742]: loss 10.932320
[epoch17, step2743]: loss 3.687425
[epoch17, step2744]: loss 3.132942
[epoch17, step2745]: loss 1.432557
[epoch17, step2746]: loss 1.315063
[epoch17, step2747]: loss 0.738313
[epoch17, step2748]: loss 2.147233
[epoch17, step2749]: loss 2.948332
[epoch17, step2750]: loss 0.739927
[epoch17, step2751]: loss 0.613934
[epoch17, step2752]: loss 1.286716
[epoch17, step2753]: loss 0.966391
[epoch17, step2754]: loss 1.207085
[epoch17, step2755]: loss 9.919115
[epoch17, step2756]: loss 4.258540
[epoch17, step2757]: loss 1.016089
[epoch17, step2758]: loss 2.174900
[epoch17, step2759]: loss 13.909566
[epoch17, step2760]: loss 1.315568
[epoch17, step2761]: loss 4.663408
[epoch17, step2762]: loss 4.633556
[epoch17, step2763]: loss 0.931582
[epoch17, step2764]: loss 12.845617
[epoch17, step2765]: loss 0.605554
[epoch17, step2766]: loss 2.584781
[epoch17, step2767]: loss 0.928921
[epoch17, step2768]: loss 3.597988
[epoch17, step2769]: loss 5.056898
[epoch17, step2770]: loss 10.854127
[epoch17, step2771]: loss 0.575489
[epoch17, step2772]: loss 5.587624
[epoch17, step2773]: loss 1.107120
[epoch17, step2774]: loss 5.578035
[epoch17, step2775]: loss 1.620807
[epoch17, step2776]: loss 0.598851
[epoch17, step2777]: loss 11.343999
[epoch17, step2778]: loss 2.526977
[epoch17, step2779]: loss 1.328469
[epoch17, step2780]: loss 1.983743
[epoch17, step2781]: loss 0.977302
[epoch17, step2782]: loss 1.250711
[epoch17, step2783]: loss 12.179513
[epoch17, step2784]: loss 1.134962
[epoch17, step2785]: loss 1.046144
[epoch17, step2786]: loss 3.837981
[epoch17, step2787]: loss 3.490052
[epoch17, step2788]: loss 15.868624
[epoch17, step2789]: loss 0.775980
[epoch17, step2790]: loss 1.285974
[epoch17, step2791]: loss 0.733657
[epoch17, step2792]: loss 2.305214
[epoch17, step2793]: loss 0.827526
[epoch17, step2794]: loss 3.442034
[epoch17, step2795]: loss 1.694825
[epoch17, step2796]: loss 6.702990
[epoch17, step2797]: loss 1.593211
[epoch17, step2798]: loss 0.766258
[epoch17, step2799]: loss 2.866406
[epoch17, step2800]: loss 6.602392
[epoch17, step2801]: loss 3.132864
[epoch17, step2802]: loss 6.666593
[epoch17, step2803]: loss 2.586967
[epoch17, step2804]: loss 5.336637
[epoch17, step2805]: loss 1.333059
[epoch17, step2806]: loss 1.052860
[epoch17, step2807]: loss 1.101112
[epoch17, step2808]: loss 1.092585
[epoch17, step2809]: loss 1.146305
[epoch17, step2810]: loss 3.102564
[epoch17, step2811]: loss 1.269485
[epoch17, step2812]: loss 0.687749
[epoch17, step2813]: loss 2.552772
[epoch17, step2814]: loss 2.243076
[epoch17, step2815]: loss 2.237519
[epoch17, step2816]: loss 1.085346
[epoch17, step2817]: loss 0.973325
[epoch17, step2818]: loss 6.113122
[epoch17, step2819]: loss 2.374857
[epoch17, step2820]: loss 0.568854
[epoch17, step2821]: loss 6.360625
[epoch17, step2822]: loss 24.492496
[epoch17, step2823]: loss 15.623675
[epoch17, step2824]: loss 1.997547
[epoch17, step2825]: loss 11.980201
[epoch17, step2826]: loss 1.822244
[epoch17, step2827]: loss 8.997810
[epoch17, step2828]: loss 4.136904
[epoch17, step2829]: loss 7.493588
[epoch17, step2830]: loss 1.314457
[epoch17, step2831]: loss 26.814289
[epoch17, step2832]: loss 1.819142
[epoch17, step2833]: loss 39.123680
[epoch17, step2834]: loss 0.933493
[epoch17, step2835]: loss 1.274922
[epoch17, step2836]: loss 3.844643
[epoch17, step2837]: loss 1.472742
[epoch17, step2838]: loss 1.020579
[epoch17, step2839]: loss 2.104495
[epoch17, step2840]: loss 2.206181
[epoch17, step2841]: loss 1.775214
[epoch17, step2842]: loss 5.041154
[epoch17, step2843]: loss 1.970415
[epoch17, step2844]: loss 8.203913
[epoch17, step2845]: loss 1.315485
[epoch17, step2846]: loss 1.516783
[epoch17, step2847]: loss 2.427464
[epoch17, step2848]: loss 1.106975
[epoch17, step2849]: loss 0.920821
[epoch17, step2850]: loss 7.584908
[epoch17, step2851]: loss 1.055013
[epoch17, step2852]: loss 1.308239
[epoch17, step2853]: loss 1.507730
[epoch17, step2854]: loss 0.958980
[epoch17, step2855]: loss 2.745133
[epoch17, step2856]: loss 0.769351
[epoch17, step2857]: loss 6.460764
[epoch17, step2858]: loss 1.718031
[epoch17, step2859]: loss 1.798976
[epoch17, step2860]: loss 1.332401
[epoch17, step2861]: loss 1.033723
[epoch17, step2862]: loss 2.478118
[epoch17, step2863]: loss 7.845108
[epoch17, step2864]: loss 8.772221
[epoch17, step2865]: loss 1.185587
[epoch17, step2866]: loss 1.312017
[epoch17, step2867]: loss 3.222779
[epoch17, step2868]: loss 2.595283
[epoch17, step2869]: loss 2.299082
[epoch17, step2870]: loss 15.674076
[epoch17, step2871]: loss 1.074035
[epoch17, step2872]: loss 0.722998
[epoch17, step2873]: loss 1.203210
[epoch17, step2874]: loss 1.137477
[epoch17, step2875]: loss 0.695796
[epoch17, step2876]: loss 0.844254
[epoch17, step2877]: loss 1.057165
[epoch17, step2878]: loss 9.646944
[epoch17, step2879]: loss 1.532565
[epoch17, step2880]: loss 5.976523
[epoch17, step2881]: loss 1.305806
[epoch17, step2882]: loss 0.764858
[epoch17, step2883]: loss 1.067996
[epoch17, step2884]: loss 3.508349
[epoch17, step2885]: loss 1.229397
[epoch17, step2886]: loss 1.052060
[epoch17, step2887]: loss 3.298770
[epoch17, step2888]: loss 2.308258
[epoch17, step2889]: loss 1.198665
[epoch17, step2890]: loss 7.537543
[epoch17, step2891]: loss 6.272987
[epoch17, step2892]: loss 0.549923
[epoch17, step2893]: loss 1.208945
[epoch17, step2894]: loss 3.556464
[epoch17, step2895]: loss 7.276353
[epoch17, step2896]: loss 9.072030
[epoch17, step2897]: loss 2.079771
[epoch17, step2898]: loss 2.315620
[epoch17, step2899]: loss 5.287157
[epoch17, step2900]: loss 5.075741
[epoch17, step2901]: loss 2.367018
[epoch17, step2902]: loss 0.612245
[epoch17, step2903]: loss 7.408536
[epoch17, step2904]: loss 9.258869
[epoch17, step2905]: loss 2.701508
[epoch17, step2906]: loss 0.844424
[epoch17, step2907]: loss 1.165354
[epoch17, step2908]: loss 1.130485
[epoch17, step2909]: loss 12.751867
[epoch17, step2910]: loss 6.095191
[epoch17, step2911]: loss 0.984517
[epoch17, step2912]: loss 0.696431
[epoch17, step2913]: loss 0.902752
[epoch17, step2914]: loss 0.692257
[epoch17, step2915]: loss 1.846410
[epoch17, step2916]: loss 1.463731
[epoch17, step2917]: loss 1.151809
[epoch17, step2918]: loss 2.481332
[epoch17, step2919]: loss 9.109229
[epoch17, step2920]: loss 2.042751
[epoch17, step2921]: loss 3.099958
[epoch17, step2922]: loss 3.052327
[epoch17, step2923]: loss 1.376969
[epoch17, step2924]: loss 2.139607
[epoch17, step2925]: loss 1.119242
[epoch17, step2926]: loss 1.127806
[epoch17, step2927]: loss 0.817636
[epoch17, step2928]: loss 0.983653
[epoch17, step2929]: loss 11.370399
[epoch17, step2930]: loss 2.189785
[epoch17, step2931]: loss 0.618115
[epoch17, step2932]: loss 5.221591
[epoch17, step2933]: loss 3.999246
[epoch17, step2934]: loss 1.992072
[epoch17, step2935]: loss 2.928741
[epoch17, step2936]: loss 2.331233
[epoch17, step2937]: loss 1.420492
[epoch17, step2938]: loss 1.322806
[epoch17, step2939]: loss 1.386742
[epoch17, step2940]: loss 1.331892
[epoch17, step2941]: loss 2.240399
[epoch17, step2942]: loss 2.048411
[epoch17, step2943]: loss 13.036318
[epoch17, step2944]: loss 0.931848
[epoch17, step2945]: loss 8.423560
[epoch17, step2946]: loss 1.058912
[epoch17, step2947]: loss 7.414167
[epoch17, step2948]: loss 1.560856
[epoch17, step2949]: loss 0.960383
[epoch17, step2950]: loss 1.320525
[epoch17, step2951]: loss 2.859678
[epoch17, step2952]: loss 3.137861
[epoch17, step2953]: loss 38.295441
[epoch17, step2954]: loss 1.257215
[epoch17, step2955]: loss 1.509581
[epoch17, step2956]: loss 1.444470
[epoch17, step2957]: loss 0.638203
[epoch17, step2958]: loss 1.837648
[epoch17, step2959]: loss 0.588621
[epoch17, step2960]: loss 0.709412
[epoch17, step2961]: loss 0.900432
[epoch17, step2962]: loss 1.689889
[epoch17, step2963]: loss 0.739881
[epoch17, step2964]: loss 3.815818
[epoch17, step2965]: loss 6.878739
[epoch17, step2966]: loss 3.197402
[epoch17, step2967]: loss 0.813003
[epoch17, step2968]: loss 0.838849
[epoch17, step2969]: loss 0.905854
[epoch17, step2970]: loss 0.586446
[epoch17, step2971]: loss 0.730486
[epoch17, step2972]: loss 0.857013
[epoch17, step2973]: loss 8.519094
[epoch17, step2974]: loss 0.844793
[epoch17, step2975]: loss 1.739376
[epoch17, step2976]: loss 1.079184
[epoch17, step2977]: loss 11.341992
[epoch17, step2978]: loss 17.678930
[epoch17, step2979]: loss 11.147899
[epoch17, step2980]: loss 1.474400
[epoch17, step2981]: loss 2.113894
[epoch17, step2982]: loss 0.706399
[epoch17, step2983]: loss 1.153992
[epoch17, step2984]: loss 0.980210
[epoch17, step2985]: loss 1.432137
[epoch17, step2986]: loss 11.508497
[epoch17, step2987]: loss 0.847453
[epoch17, step2988]: loss 3.971416
[epoch17, step2989]: loss 0.843280
[epoch17, step2990]: loss 6.229977
[epoch17, step2991]: loss 8.917713
[epoch17, step2992]: loss 0.988579
[epoch17, step2993]: loss 1.954220
[epoch17, step2994]: loss 1.594667
[epoch17, step2995]: loss 5.937272
[epoch17, step2996]: loss 1.206176
[epoch17, step2997]: loss 7.113623
[epoch17, step2998]: loss 1.825893
[epoch17, step2999]: loss 0.760497
[epoch17, step3000]: loss 1.856067
[epoch17, step3001]: loss 0.726718
[epoch17, step3002]: loss 0.568557
[epoch17, step3003]: loss 5.699145
[epoch17, step3004]: loss 1.633557
[epoch17, step3005]: loss 7.645143
[epoch17, step3006]: loss 2.781257
[epoch17, step3007]: loss 0.742270
[epoch17, step3008]: loss 12.227306
[epoch17, step3009]: loss 1.857997
[epoch17, step3010]: loss 10.214925
[epoch17, step3011]: loss 1.295529
[epoch17, step3012]: loss 0.987942
[epoch17, step3013]: loss 1.621905
[epoch17, step3014]: loss 13.060799
[epoch17, step3015]: loss 5.011765
[epoch17, step3016]: loss 2.040670
[epoch17, step3017]: loss 11.959040
[epoch17, step3018]: loss 1.317499
[epoch17, step3019]: loss 4.251044
[epoch17, step3020]: loss 0.974330
[epoch17, step3021]: loss 1.827782
[epoch17, step3022]: loss 1.110293
[epoch17, step3023]: loss 1.080604
[epoch17, step3024]: loss 0.519891
[epoch17, step3025]: loss 3.616711
[epoch17, step3026]: loss 2.382924
[epoch17, step3027]: loss 1.993808
[epoch17, step3028]: loss 0.933584
[epoch17, step3029]: loss 0.907582
[epoch17, step3030]: loss 2.010442
[epoch17, step3031]: loss 3.204689
[epoch17, step3032]: loss 2.618714
[epoch17, step3033]: loss 1.593317
[epoch17, step3034]: loss 2.376875
[epoch17, step3035]: loss 2.969770
[epoch17, step3036]: loss 4.075830
[epoch17, step3037]: loss 0.440000
[epoch17, step3038]: loss 4.481824
[epoch17, step3039]: loss 4.038930
[epoch17, step3040]: loss 1.505201
[epoch17, step3041]: loss 3.581100
[epoch17, step3042]: loss 12.770775
[epoch17, step3043]: loss 1.086493
[epoch17, step3044]: loss 0.876525
[epoch17, step3045]: loss 10.874743
[epoch17, step3046]: loss 1.190109
[epoch17, step3047]: loss 1.141930
[epoch17, step3048]: loss 6.177456
[epoch17, step3049]: loss 0.958002
[epoch17, step3050]: loss 1.739967
[epoch17, step3051]: loss 1.995574
[epoch17, step3052]: loss 1.538711
[epoch17, step3053]: loss 0.940281
[epoch17, step3054]: loss 1.207503
[epoch17, step3055]: loss 6.134830
[epoch17, step3056]: loss 3.206693
[epoch17, step3057]: loss 1.060985
[epoch17, step3058]: loss 1.866595
[epoch17, step3059]: loss 0.707591
[epoch17, step3060]: loss 1.854024
[epoch17, step3061]: loss 0.852179
[epoch17, step3062]: loss 2.720448
[epoch17, step3063]: loss 1.630717
[epoch17, step3064]: loss 2.104079
[epoch17, step3065]: loss 1.384422
[epoch17, step3066]: loss 1.462183
[epoch17, step3067]: loss 1.866395
[epoch17, step3068]: loss 3.255939
[epoch17, step3069]: loss 9.212053
[epoch17, step3070]: loss 7.508725
[epoch17, step3071]: loss 17.987143
[epoch17, step3072]: loss 4.461938
[epoch17, step3073]: loss 1.737570
[epoch17, step3074]: loss 12.866334
[epoch17, step3075]: loss 1.841243
[epoch17, step3076]: loss 1.133190

[epoch17]: avg loss 1.133190

[epoch18, step1]: loss 1.744384
[epoch18, step2]: loss 3.101256
[epoch18, step3]: loss 0.995712
[epoch18, step4]: loss 0.813953
[epoch18, step5]: loss 1.088454
[epoch18, step6]: loss 0.716926
[epoch18, step7]: loss 10.430331
[epoch18, step8]: loss 12.631270
[epoch18, step9]: loss 5.942344
[epoch18, step10]: loss 7.072780
[epoch18, step11]: loss 0.899585
[epoch18, step12]: loss 1.139542
[epoch18, step13]: loss 3.497134
[epoch18, step14]: loss 1.219188
[epoch18, step15]: loss 0.696310
[epoch18, step16]: loss 10.456584
[epoch18, step17]: loss 0.794525
[epoch18, step18]: loss 3.706183
[epoch18, step19]: loss 0.890129
[epoch18, step20]: loss 0.924391
[epoch18, step21]: loss 8.883097
[epoch18, step22]: loss 10.454755
[epoch18, step23]: loss 21.120750
[epoch18, step24]: loss 1.191857
[epoch18, step25]: loss 2.034373
[epoch18, step26]: loss 9.655215
[epoch18, step27]: loss 2.174748
[epoch18, step28]: loss 1.000884
[epoch18, step29]: loss 1.283993
[epoch18, step30]: loss 1.054818
[epoch18, step31]: loss 0.962952
[epoch18, step32]: loss 3.794346
[epoch18, step33]: loss 0.963668
[epoch18, step34]: loss 1.547763
[epoch18, step35]: loss 1.024817
[epoch18, step36]: loss 5.231615
[epoch18, step37]: loss 0.717272
[epoch18, step38]: loss 0.796784
[epoch18, step39]: loss 1.221146
[epoch18, step40]: loss 2.605217
[epoch18, step41]: loss 6.237824
[epoch18, step42]: loss 0.628986
[epoch18, step43]: loss 3.646528
[epoch18, step44]: loss 13.818618
[epoch18, step45]: loss 1.069417
[epoch18, step46]: loss 1.379243
[epoch18, step47]: loss 1.776642
[epoch18, step48]: loss 1.896020
[epoch18, step49]: loss 1.540866
[epoch18, step50]: loss 1.805076
[epoch18, step51]: loss 1.126773
[epoch18, step52]: loss 7.173965
[epoch18, step53]: loss 1.618267
[epoch18, step54]: loss 1.004624
[epoch18, step55]: loss 0.643325
[epoch18, step56]: loss 1.812246
[epoch18, step57]: loss 1.363698
[epoch18, step58]: loss 0.948895
[epoch18, step59]: loss 0.967409
[epoch18, step60]: loss 3.611406
[epoch18, step61]: loss 4.847379
[epoch18, step62]: loss 2.484538
[epoch18, step63]: loss 8.941896
[epoch18, step64]: loss 6.131605
[epoch18, step65]: loss 1.128818
[epoch18, step66]: loss 1.487823
[epoch18, step67]: loss 19.863491
[epoch18, step68]: loss 3.873975
[epoch18, step69]: loss 1.282324
[epoch18, step70]: loss 14.893797
[epoch18, step71]: loss 1.273639
[epoch18, step72]: loss 7.742490
[epoch18, step73]: loss 3.155296
[epoch18, step74]: loss 1.133641
[epoch18, step75]: loss 0.778188
[epoch18, step76]: loss 0.977369
[epoch18, step77]: loss 1.214186
[epoch18, step78]: loss 4.239131
[epoch18, step79]: loss 0.791343
[epoch18, step80]: loss 1.432812
[epoch18, step81]: loss 1.798004
[epoch18, step82]: loss 2.802675
[epoch18, step83]: loss 2.459922
[epoch18, step84]: loss 0.885179
[epoch18, step85]: loss 1.939403
[epoch18, step86]: loss 2.866265
[epoch18, step87]: loss 3.340152
[epoch18, step88]: loss 0.845727
[epoch18, step89]: loss 1.424386
[epoch18, step90]: loss 1.216332
[epoch18, step91]: loss 0.744254
[epoch18, step92]: loss 0.887475
[epoch18, step93]: loss 2.646114
[epoch18, step94]: loss 1.648811
[epoch18, step95]: loss 6.841366
[epoch18, step96]: loss 11.055473
[epoch18, step97]: loss 28.376011
[epoch18, step98]: loss 6.812536
[epoch18, step99]: loss 1.971002
[epoch18, step100]: loss 0.913386
[epoch18, step101]: loss 1.289055
[epoch18, step102]: loss 0.798075
[epoch18, step103]: loss 2.269919
[epoch18, step104]: loss 1.971314
[epoch18, step105]: loss 0.723902
[epoch18, step106]: loss 3.841192
[epoch18, step107]: loss 10.088437
[epoch18, step108]: loss 0.735414
[epoch18, step109]: loss 1.488018
[epoch18, step110]: loss 2.348009
[epoch18, step111]: loss 5.431016
[epoch18, step112]: loss 7.775831
[epoch18, step113]: loss 2.287098
[epoch18, step114]: loss 11.672710
[epoch18, step115]: loss 7.955525
[epoch18, step116]: loss 2.084762
[epoch18, step117]: loss 0.911128
[epoch18, step118]: loss 2.404326
[epoch18, step119]: loss 1.533797
[epoch18, step120]: loss 1.600059
[epoch18, step121]: loss 1.653322
[epoch18, step122]: loss 2.854351
[epoch18, step123]: loss 1.546921
[epoch18, step124]: loss 1.480585
[epoch18, step125]: loss 0.879768
[epoch18, step126]: loss 10.132668
[epoch18, step127]: loss 0.945812
[epoch18, step128]: loss 4.530933
[epoch18, step129]: loss 11.437755
[epoch18, step130]: loss 0.541917
[epoch18, step131]: loss 1.375747
[epoch18, step132]: loss 1.239782
[epoch18, step133]: loss 3.514636
[epoch18, step134]: loss 0.751196
[epoch18, step135]: loss 2.319729
[epoch18, step136]: loss 0.620408
[epoch18, step137]: loss 1.186049
[epoch18, step138]: loss 0.705140
[epoch18, step139]: loss 8.055065
[epoch18, step140]: loss 1.156147
[epoch18, step141]: loss 1.156263
[epoch18, step142]: loss 12.037559
[epoch18, step143]: loss 0.720942
[epoch18, step144]: loss 15.974417
[epoch18, step145]: loss 0.714697
[epoch18, step146]: loss 1.194496
[epoch18, step147]: loss 15.037904
[epoch18, step148]: loss 3.709634
[epoch18, step149]: loss 2.342556
[epoch18, step150]: loss 2.409312
[epoch18, step151]: loss 10.054239
[epoch18, step152]: loss 5.785213
[epoch18, step153]: loss 9.777075
[epoch18, step154]: loss 5.204976
[epoch18, step155]: loss 1.673599
[epoch18, step156]: loss 5.109004
[epoch18, step157]: loss 4.886493
[epoch18, step158]: loss 1.723304
[epoch18, step159]: loss 1.663697
[epoch18, step160]: loss 10.937698
[epoch18, step161]: loss 9.166398
[epoch18, step162]: loss 0.992148
[epoch18, step163]: loss 2.546508
[epoch18, step164]: loss 1.627263
[epoch18, step165]: loss 14.546329
[epoch18, step166]: loss 1.501673
[epoch18, step167]: loss 2.232019
[epoch18, step168]: loss 1.207000
[epoch18, step169]: loss 1.498082
[epoch18, step170]: loss 2.086498
[epoch18, step171]: loss 16.652891
[epoch18, step172]: loss 1.288037
[epoch18, step173]: loss 4.239452
[epoch18, step174]: loss 11.737432
[epoch18, step175]: loss 5.906896
[epoch18, step176]: loss 1.118688
[epoch18, step177]: loss 1.964118
[epoch18, step178]: loss 3.592660
[epoch18, step179]: loss 0.901647
[epoch18, step180]: loss 0.885349
[epoch18, step181]: loss 0.589899
[epoch18, step182]: loss 4.117327
[epoch18, step183]: loss 0.733307
[epoch18, step184]: loss 1.117023
[epoch18, step185]: loss 6.322168
[epoch18, step186]: loss 1.648693
[epoch18, step187]: loss 0.469606
[epoch18, step188]: loss 1.482716
[epoch18, step189]: loss 4.253582
[epoch18, step190]: loss 9.401605
[epoch18, step191]: loss 1.959975
[epoch18, step192]: loss 1.001571
[epoch18, step193]: loss 0.799362
[epoch18, step194]: loss 0.698713
[epoch18, step195]: loss 1.172999
[epoch18, step196]: loss 1.058833
[epoch18, step197]: loss 0.952516
[epoch18, step198]: loss 2.109160
[epoch18, step199]: loss 2.877507
[epoch18, step200]: loss 0.933359
[epoch18, step201]: loss 2.195312
[epoch18, step202]: loss 2.761169
[epoch18, step203]: loss 6.267120
[epoch18, step204]: loss 2.685391
[epoch18, step205]: loss 1.712216
[epoch18, step206]: loss 4.039589
[epoch18, step207]: loss 9.946020
[epoch18, step208]: loss 0.986059
[epoch18, step209]: loss 1.092650
[epoch18, step210]: loss 12.707547
[epoch18, step211]: loss 1.126272
[epoch18, step212]: loss 1.291248
[epoch18, step213]: loss 1.187511
[epoch18, step214]: loss 5.323075
[epoch18, step215]: loss 1.575224
[epoch18, step216]: loss 7.695387
[epoch18, step217]: loss 2.135629
[epoch18, step218]: loss 7.833026
[epoch18, step219]: loss 2.869406
[epoch18, step220]: loss 0.895781
[epoch18, step221]: loss 3.076638
[epoch18, step222]: loss 1.159378
[epoch18, step223]: loss 13.259487
[epoch18, step224]: loss 1.460658
[epoch18, step225]: loss 2.291996
[epoch18, step226]: loss 2.326774
[epoch18, step227]: loss 1.258531
[epoch18, step228]: loss 2.164430
[epoch18, step229]: loss 1.752167
[epoch18, step230]: loss 2.638996
[epoch18, step231]: loss 12.155024
[epoch18, step232]: loss 2.297418
[epoch18, step233]: loss 2.729151
[epoch18, step234]: loss 1.129071
[epoch18, step235]: loss 1.139657
[epoch18, step236]: loss 0.820762
[epoch18, step237]: loss 5.790480
[epoch18, step238]: loss 10.673232
[epoch18, step239]: loss 0.992810
[epoch18, step240]: loss 17.502161
[epoch18, step241]: loss 8.007906
[epoch18, step242]: loss 15.636446
[epoch18, step243]: loss 1.971092
[epoch18, step244]: loss 10.011028
[epoch18, step245]: loss 1.047512
[epoch18, step246]: loss 1.458513
[epoch18, step247]: loss 1.203630
[epoch18, step248]: loss 0.901576
[epoch18, step249]: loss 3.895974
[epoch18, step250]: loss 0.867751
[epoch18, step251]: loss 1.326304
[epoch18, step252]: loss 1.377139
[epoch18, step253]: loss 3.061349
[epoch18, step254]: loss 1.344609
[epoch18, step255]: loss 9.408062
[epoch18, step256]: loss 1.119764
[epoch18, step257]: loss 14.209464
[epoch18, step258]: loss 2.726919
[epoch18, step259]: loss 1.480601
[epoch18, step260]: loss 0.983626
[epoch18, step261]: loss 13.947254
[epoch18, step262]: loss 8.914899
[epoch18, step263]: loss 4.007872
[epoch18, step264]: loss 2.405412
[epoch18, step265]: loss 28.030579
[epoch18, step266]: loss 0.805205
[epoch18, step267]: loss 1.874918
[epoch18, step268]: loss 0.587025
[epoch18, step269]: loss 0.967905
[epoch18, step270]: loss 1.394474
[epoch18, step271]: loss 1.435374
[epoch18, step272]: loss 1.193775
[epoch18, step273]: loss 2.892451
[epoch18, step274]: loss 1.190555
[epoch18, step275]: loss 2.492414
[epoch18, step276]: loss 1.624795
[epoch18, step277]: loss 1.070323
[epoch18, step278]: loss 10.960481
[epoch18, step279]: loss 0.846266
[epoch18, step280]: loss 11.852210
[epoch18, step281]: loss 0.602306
[epoch18, step282]: loss 1.084554
[epoch18, step283]: loss 2.042619
[epoch18, step284]: loss 2.716763
[epoch18, step285]: loss 4.047057
[epoch18, step286]: loss 0.739382
[epoch18, step287]: loss 1.153200
[epoch18, step288]: loss 3.553732
[epoch18, step289]: loss 2.017924
[epoch18, step290]: loss 0.759055
[epoch18, step291]: loss 0.793323
[epoch18, step292]: loss 0.506530
[epoch18, step293]: loss 6.225764
[epoch18, step294]: loss 2.009459
[epoch18, step295]: loss 0.763689
[epoch18, step296]: loss 5.244415
[epoch18, step297]: loss 0.555724
[epoch18, step298]: loss 0.890904
[epoch18, step299]: loss 0.770497
[epoch18, step300]: loss 0.652971
[epoch18, step301]: loss 1.281670
[epoch18, step302]: loss 1.111141
[epoch18, step303]: loss 0.741131
[epoch18, step304]: loss 0.895211
[epoch18, step305]: loss 2.329816
[epoch18, step306]: loss 6.253055
[epoch18, step307]: loss 1.889508
[epoch18, step308]: loss 2.452845
[epoch18, step309]: loss 0.921632
[epoch18, step310]: loss 1.383181
[epoch18, step311]: loss 1.123413
[epoch18, step312]: loss 2.027569
[epoch18, step313]: loss 0.492649
[epoch18, step314]: loss 4.374902
[epoch18, step315]: loss 0.891014
[epoch18, step316]: loss 1.695180
[epoch18, step317]: loss 1.433521
[epoch18, step318]: loss 4.316010
[epoch18, step319]: loss 0.837093
[epoch18, step320]: loss 6.388795
[epoch18, step321]: loss 2.037984
[epoch18, step322]: loss 5.841700
[epoch18, step323]: loss 4.322168
[epoch18, step324]: loss 9.391651
[epoch18, step325]: loss 1.937795
[epoch18, step326]: loss 1.674336
[epoch18, step327]: loss 0.927317
[epoch18, step328]: loss 10.337696
[epoch18, step329]: loss 0.841515
[epoch18, step330]: loss 3.774549
[epoch18, step331]: loss 0.721568
[epoch18, step332]: loss 1.070066
[epoch18, step333]: loss 0.802831
[epoch18, step334]: loss 0.986134
[epoch18, step335]: loss 12.495306
[epoch18, step336]: loss 3.005105
[epoch18, step337]: loss 1.204173
[epoch18, step338]: loss 3.103674
[epoch18, step339]: loss 3.450628
[epoch18, step340]: loss 2.132014
[epoch18, step341]: loss 3.940258
[epoch18, step342]: loss 10.475924
[epoch18, step343]: loss 2.243075
[epoch18, step344]: loss 1.940873
[epoch18, step345]: loss 16.902229
[epoch18, step346]: loss 6.373489
[epoch18, step347]: loss 1.238288
[epoch18, step348]: loss 4.599155
[epoch18, step349]: loss 1.196745
[epoch18, step350]: loss 23.312269
[epoch18, step351]: loss 6.227602
[epoch18, step352]: loss 1.619894
[epoch18, step353]: loss 1.989587
[epoch18, step354]: loss 0.720050
[epoch18, step355]: loss 11.665618
[epoch18, step356]: loss 2.083127
[epoch18, step357]: loss 2.064824
[epoch18, step358]: loss 1.682520
[epoch18, step359]: loss 2.663861
[epoch18, step360]: loss 0.924534
[epoch18, step361]: loss 0.504558
[epoch18, step362]: loss 0.908052
[epoch18, step363]: loss 1.686846
[epoch18, step364]: loss 0.749399
[epoch18, step365]: loss 0.800604
[epoch18, step366]: loss 10.662578
[epoch18, step367]: loss 2.858681
[epoch18, step368]: loss 0.702875
[epoch18, step369]: loss 1.469281
[epoch18, step370]: loss 4.538212
[epoch18, step371]: loss 0.974400
[epoch18, step372]: loss 14.008811
[epoch18, step373]: loss 2.059365
[epoch18, step374]: loss 0.959202
[epoch18, step375]: loss 2.789393
[epoch18, step376]: loss 1.461981
[epoch18, step377]: loss 3.036241
[epoch18, step378]: loss 11.780715
[epoch18, step379]: loss 10.875142
[epoch18, step380]: loss 0.875641
[epoch18, step381]: loss 1.902845
[epoch18, step382]: loss 0.901871
[epoch18, step383]: loss 0.469875
[epoch18, step384]: loss 2.224040
[epoch18, step385]: loss 2.145085
[epoch18, step386]: loss 0.821096
[epoch18, step387]: loss 7.727539
[epoch18, step388]: loss 2.265912
[epoch18, step389]: loss 0.884041
[epoch18, step390]: loss 3.394140
[epoch18, step391]: loss 1.143406
[epoch18, step392]: loss 6.077434
[epoch18, step393]: loss 2.837560
[epoch18, step394]: loss 6.576835
[epoch18, step395]: loss 2.005282
[epoch18, step396]: loss 2.906271
[epoch18, step397]: loss 0.631621
[epoch18, step398]: loss 19.430433
[epoch18, step399]: loss 1.043560
[epoch18, step400]: loss 5.956651
[epoch18, step401]: loss 2.185573
[epoch18, step402]: loss 7.327599
[epoch18, step403]: loss 1.223146
[epoch18, step404]: loss 9.924834
[epoch18, step405]: loss 1.849289
[epoch18, step406]: loss 4.097225
[epoch18, step407]: loss 2.543575
[epoch18, step408]: loss 1.129938
[epoch18, step409]: loss 2.031418
[epoch18, step410]: loss 1.430026
[epoch18, step411]: loss 0.840216
[epoch18, step412]: loss 1.219529
[epoch18, step413]: loss 1.550018
[epoch18, step414]: loss 1.155898
[epoch18, step415]: loss 11.643114
[epoch18, step416]: loss 7.942274
[epoch18, step417]: loss 0.877834
[epoch18, step418]: loss 0.935025
[epoch18, step419]: loss 9.091669
[epoch18, step420]: loss 12.699978
[epoch18, step421]: loss 0.956317
[epoch18, step422]: loss 1.808571
[epoch18, step423]: loss 3.090330
[epoch18, step424]: loss 1.955208
[epoch18, step425]: loss 1.906100
[epoch18, step426]: loss 0.727706
[epoch18, step427]: loss 0.738414
[epoch18, step428]: loss 6.192204
[epoch18, step429]: loss 1.083906
[epoch18, step430]: loss 1.324576
[epoch18, step431]: loss 1.310048
[epoch18, step432]: loss 10.038762
[epoch18, step433]: loss 4.075279
[epoch18, step434]: loss 11.306447
[epoch18, step435]: loss 0.610565
[epoch18, step436]: loss 2.376818
[epoch18, step437]: loss 2.485918
[epoch18, step438]: loss 1.609341
[epoch18, step439]: loss 1.180684
[epoch18, step440]: loss 1.104432
[epoch18, step441]: loss 1.027541
[epoch18, step442]: loss 1.539043
[epoch18, step443]: loss 1.129295
[epoch18, step444]: loss 1.800324
[epoch18, step445]: loss 1.016251
[epoch18, step446]: loss 10.637195
[epoch18, step447]: loss 1.421597
[epoch18, step448]: loss 1.142881
[epoch18, step449]: loss 1.298494
[epoch18, step450]: loss 6.793688
[epoch18, step451]: loss 12.183112
[epoch18, step452]: loss 10.187757
[epoch18, step453]: loss 2.602453
[epoch18, step454]: loss 1.602841
[epoch18, step455]: loss 1.326330
[epoch18, step456]: loss 0.450515
[epoch18, step457]: loss 0.637037
[epoch18, step458]: loss 1.450551
[epoch18, step459]: loss 16.855011
[epoch18, step460]: loss 4.328083
[epoch18, step461]: loss 2.441872
[epoch18, step462]: loss 1.153433
[epoch18, step463]: loss 0.789117
[epoch18, step464]: loss 0.912348
[epoch18, step465]: loss 4.012087
[epoch18, step466]: loss 1.983089
[epoch18, step467]: loss 4.033140
[epoch18, step468]: loss 0.608144
[epoch18, step469]: loss 12.620228
[epoch18, step470]: loss 3.831067
[epoch18, step471]: loss 1.267097
[epoch18, step472]: loss 6.754367
[epoch18, step473]: loss 1.528771
[epoch18, step474]: loss 4.994973
[epoch18, step475]: loss 1.402936
[epoch18, step476]: loss 2.650753
[epoch18, step477]: loss 1.461320
[epoch18, step478]: loss 0.561163
[epoch18, step479]: loss 1.651041
[epoch18, step480]: loss 1.010466
[epoch18, step481]: loss 15.534378
[epoch18, step482]: loss 1.158618
[epoch18, step483]: loss 11.035600
[epoch18, step484]: loss 1.418869
[epoch18, step485]: loss 5.492506
[epoch18, step486]: loss 5.935671
[epoch18, step487]: loss 0.674666
[epoch18, step488]: loss 1.790105
[epoch18, step489]: loss 0.587245
[epoch18, step490]: loss 1.206417
[epoch18, step491]: loss 2.340425
[epoch18, step492]: loss 0.808359
[epoch18, step493]: loss 3.470751
[epoch18, step494]: loss 1.012466
[epoch18, step495]: loss 8.266462
[epoch18, step496]: loss 1.042371
[epoch18, step497]: loss 1.194543
[epoch18, step498]: loss 5.522015
[epoch18, step499]: loss 1.156482
[epoch18, step500]: loss 6.987370
[epoch18, step501]: loss 1.665491
[epoch18, step502]: loss 1.131235
[epoch18, step503]: loss 1.045456
[epoch18, step504]: loss 6.484256
[epoch18, step505]: loss 5.495760
[epoch18, step506]: loss 13.846015
[epoch18, step507]: loss 5.424407
[epoch18, step508]: loss 0.837044
[epoch18, step509]: loss 0.791336
[epoch18, step510]: loss 10.608114
[epoch18, step511]: loss 1.511229
[epoch18, step512]: loss 6.167237
[epoch18, step513]: loss 1.411360
[epoch18, step514]: loss 2.249542
[epoch18, step515]: loss 0.851610
[epoch18, step516]: loss 0.657837
[epoch18, step517]: loss 16.977924
[epoch18, step518]: loss 3.043180
[epoch18, step519]: loss 12.058361
[epoch18, step520]: loss 0.651476
[epoch18, step521]: loss 1.289276
[epoch18, step522]: loss 1.167944
[epoch18, step523]: loss 1.234859
[epoch18, step524]: loss 4.794984
[epoch18, step525]: loss 1.073811
[epoch18, step526]: loss 1.013053
[epoch18, step527]: loss 3.275115
[epoch18, step528]: loss 1.977039
[epoch18, step529]: loss 2.255557
[epoch18, step530]: loss 0.636476
[epoch18, step531]: loss 3.978306
[epoch18, step532]: loss 1.082054
[epoch18, step533]: loss 1.892354
[epoch18, step534]: loss 1.457062
[epoch18, step535]: loss 1.187764
[epoch18, step536]: loss 1.647529
[epoch18, step537]: loss 7.856974
[epoch18, step538]: loss 0.835728
[epoch18, step539]: loss 3.861961
[epoch18, step540]: loss 16.613617
[epoch18, step541]: loss 1.034984
[epoch18, step542]: loss 1.206746
[epoch18, step543]: loss 26.636822
[epoch18, step544]: loss 4.229888
[epoch18, step545]: loss 6.950717
[epoch18, step546]: loss 11.069849
[epoch18, step547]: loss 3.188821
[epoch18, step548]: loss 1.402687
[epoch18, step549]: loss 1.895022
[epoch18, step550]: loss 0.939006
[epoch18, step551]: loss 5.965185
[epoch18, step552]: loss 0.999092
[epoch18, step553]: loss 15.406075
[epoch18, step554]: loss 1.627824
[epoch18, step555]: loss 1.546443
[epoch18, step556]: loss 5.077339
[epoch18, step557]: loss 2.508367
[epoch18, step558]: loss 5.817352
[epoch18, step559]: loss 1.390086
[epoch18, step560]: loss 1.123959
[epoch18, step561]: loss 6.813067
[epoch18, step562]: loss 1.431979
[epoch18, step563]: loss 0.740104
[epoch18, step564]: loss 1.628312
[epoch18, step565]: loss 1.542392
[epoch18, step566]: loss 1.326250
[epoch18, step567]: loss 7.515081
[epoch18, step568]: loss 0.765760
[epoch18, step569]: loss 1.980936
[epoch18, step570]: loss 4.863971
[epoch18, step571]: loss 1.277345
[epoch18, step572]: loss 24.972567
[epoch18, step573]: loss 1.086343
[epoch18, step574]: loss 2.246084
[epoch18, step575]: loss 1.514673
[epoch18, step576]: loss 6.414477
[epoch18, step577]: loss 5.312885
[epoch18, step578]: loss 13.589746
[epoch18, step579]: loss 8.551508
[epoch18, step580]: loss 8.596006
[epoch18, step581]: loss 5.119765
[epoch18, step582]: loss 1.403917
[epoch18, step583]: loss 1.675663
[epoch18, step584]: loss 1.167196
[epoch18, step585]: loss 2.700460
[epoch18, step586]: loss 2.132813
[epoch18, step587]: loss 0.801754
[epoch18, step588]: loss 1.186628
[epoch18, step589]: loss 1.101996
[epoch18, step590]: loss 1.113533
[epoch18, step591]: loss 6.471976
[epoch18, step592]: loss 8.347523
[epoch18, step593]: loss 0.666123
[epoch18, step594]: loss 3.289605
[epoch18, step595]: loss 1.418324
[epoch18, step596]: loss 1.842638
[epoch18, step597]: loss 0.957338
[epoch18, step598]: loss 16.082487
[epoch18, step599]: loss 7.140819
[epoch18, step600]: loss 4.348341
[epoch18, step601]: loss 2.017037
[epoch18, step602]: loss 10.092699
[epoch18, step603]: loss 1.099745
[epoch18, step604]: loss 1.460829
[epoch18, step605]: loss 1.922773
[epoch18, step606]: loss 0.668766
[epoch18, step607]: loss 2.738199
[epoch18, step608]: loss 9.953930
[epoch18, step609]: loss 4.881242
[epoch18, step610]: loss 3.496864
[epoch18, step611]: loss 1.256330
[epoch18, step612]: loss 12.237551
[epoch18, step613]: loss 6.220870
[epoch18, step614]: loss 7.462924
[epoch18, step615]: loss 1.768191
[epoch18, step616]: loss 1.472935
[epoch18, step617]: loss 0.631964
[epoch18, step618]: loss 3.078461
[epoch18, step619]: loss 3.896369
[epoch18, step620]: loss 1.361347
[epoch18, step621]: loss 1.039966
[epoch18, step622]: loss 1.711795
[epoch18, step623]: loss 2.923723
[epoch18, step624]: loss 2.542514
[epoch18, step625]: loss 2.132041
[epoch18, step626]: loss 7.387189
[epoch18, step627]: loss 1.640258
[epoch18, step628]: loss 0.871966
[epoch18, step629]: loss 2.688282
[epoch18, step630]: loss 2.010062
[epoch18, step631]: loss 11.414563
[epoch18, step632]: loss 10.983477
[epoch18, step633]: loss 11.248492
[epoch18, step634]: loss 0.764915
[epoch18, step635]: loss 0.652296
[epoch18, step636]: loss 5.852766
[epoch18, step637]: loss 9.057037
[epoch18, step638]: loss 2.934548
[epoch18, step639]: loss 3.731346
[epoch18, step640]: loss 0.902463
[epoch18, step641]: loss 0.819943
[epoch18, step642]: loss 1.299777
[epoch18, step643]: loss 9.439077
[epoch18, step644]: loss 4.136183
[epoch18, step645]: loss 4.699701
[epoch18, step646]: loss 9.451453
[epoch18, step647]: loss 16.392977
[epoch18, step648]: loss 4.139192
[epoch18, step649]: loss 1.546833
[epoch18, step650]: loss 1.581812
[epoch18, step651]: loss 0.599332
[epoch18, step652]: loss 1.012140
[epoch18, step653]: loss 3.412251
[epoch18, step654]: loss 1.225571
[epoch18, step655]: loss 2.064055
[epoch18, step656]: loss 0.711593
[epoch18, step657]: loss 0.642953
[epoch18, step658]: loss 0.808764
[epoch18, step659]: loss 9.744943
[epoch18, step660]: loss 0.810231
[epoch18, step661]: loss 6.444324
[epoch18, step662]: loss 8.157219
[epoch18, step663]: loss 6.640086
[epoch18, step664]: loss 2.478550
[epoch18, step665]: loss 5.548179
[epoch18, step666]: loss 1.222221
[epoch18, step667]: loss 2.055344
[epoch18, step668]: loss 2.733179
[epoch18, step669]: loss 11.921130
[epoch18, step670]: loss 1.572468
[epoch18, step671]: loss 2.324968
[epoch18, step672]: loss 10.289606
[epoch18, step673]: loss 2.381216
[epoch18, step674]: loss 7.261105
[epoch18, step675]: loss 1.555055
[epoch18, step676]: loss 1.292128
[epoch18, step677]: loss 3.523856
[epoch18, step678]: loss 0.585903
[epoch18, step679]: loss 4.660471
[epoch18, step680]: loss 1.280168
[epoch18, step681]: loss 0.654696
[epoch18, step682]: loss 3.441329
[epoch18, step683]: loss 0.969038
[epoch18, step684]: loss 9.001973
[epoch18, step685]: loss 1.370452
[epoch18, step686]: loss 12.348866
[epoch18, step687]: loss 0.832124
[epoch18, step688]: loss 15.949848
[epoch18, step689]: loss 1.128896
[epoch18, step690]: loss 16.622440
[epoch18, step691]: loss 0.775368
[epoch18, step692]: loss 1.204708
[epoch18, step693]: loss 1.137862
[epoch18, step694]: loss 3.178232
[epoch18, step695]: loss 9.458891
[epoch18, step696]: loss 6.109297
[epoch18, step697]: loss 0.774111
[epoch18, step698]: loss 1.229969
[epoch18, step699]: loss 7.328832
[epoch18, step700]: loss 16.746471
[epoch18, step701]: loss 3.221313
[epoch18, step702]: loss 16.854725
[epoch18, step703]: loss 0.766995
[epoch18, step704]: loss 0.951349
[epoch18, step705]: loss 11.950070
[epoch18, step706]: loss 7.450232
[epoch18, step707]: loss 1.516973
[epoch18, step708]: loss 1.946325
[epoch18, step709]: loss 3.376344
[epoch18, step710]: loss 1.508248
[epoch18, step711]: loss 0.896569
[epoch18, step712]: loss 18.261164
[epoch18, step713]: loss 1.010891
[epoch18, step714]: loss 0.615271
[epoch18, step715]: loss 1.704511
[epoch18, step716]: loss 1.625750
[epoch18, step717]: loss 1.404078
[epoch18, step718]: loss 0.774400
[epoch18, step719]: loss 1.505363
[epoch18, step720]: loss 5.036424
[epoch18, step721]: loss 10.576839
[epoch18, step722]: loss 2.363769
[epoch18, step723]: loss 5.500027
[epoch18, step724]: loss 1.052333
[epoch18, step725]: loss 0.892804
[epoch18, step726]: loss 3.209619
[epoch18, step727]: loss 1.441940
[epoch18, step728]: loss 1.366172
[epoch18, step729]: loss 9.620757
[epoch18, step730]: loss 12.008459
[epoch18, step731]: loss 0.939565
[epoch18, step732]: loss 2.079998
[epoch18, step733]: loss 1.515476
[epoch18, step734]: loss 2.468238
[epoch18, step735]: loss 9.082282
[epoch18, step736]: loss 2.209856
[epoch18, step737]: loss 11.613874
[epoch18, step738]: loss 1.126413
[epoch18, step739]: loss 8.124817
[epoch18, step740]: loss 2.786614
[epoch18, step741]: loss 0.878185
[epoch18, step742]: loss 0.963402
[epoch18, step743]: loss 0.577191
[epoch18, step744]: loss 13.788879
[epoch18, step745]: loss 8.356759
[epoch18, step746]: loss 3.181918
[epoch18, step747]: loss 9.283686
[epoch18, step748]: loss 0.862990
[epoch18, step749]: loss 10.119794
[epoch18, step750]: loss 1.448794
[epoch18, step751]: loss 0.833281
[epoch18, step752]: loss 2.410426
[epoch18, step753]: loss 1.394026
[epoch18, step754]: loss 1.481833
[epoch18, step755]: loss 18.258892
[epoch18, step756]: loss 0.857069
[epoch18, step757]: loss 1.477686
[epoch18, step758]: loss 1.276968
[epoch18, step759]: loss 1.421999
[epoch18, step760]: loss 0.697037
[epoch18, step761]: loss 2.001184
[epoch18, step762]: loss 1.097038
[epoch18, step763]: loss 0.937267
[epoch18, step764]: loss 6.666393
[epoch18, step765]: loss 1.137414
[epoch18, step766]: loss 11.535872
[epoch18, step767]: loss 1.587923
[epoch18, step768]: loss 1.094925
[epoch18, step769]: loss 0.875493
[epoch18, step770]: loss 0.955620
[epoch18, step771]: loss 11.382061
[epoch18, step772]: loss 10.834442
[epoch18, step773]: loss 0.717188
[epoch18, step774]: loss 1.647982
[epoch18, step775]: loss 8.298897
[epoch18, step776]: loss 9.248586
[epoch18, step777]: loss 3.248935
[epoch18, step778]: loss 1.022240
[epoch18, step779]: loss 5.037336
[epoch18, step780]: loss 3.792595
[epoch18, step781]: loss 5.845377
[epoch18, step782]: loss 0.722533
[epoch18, step783]: loss 16.287191
[epoch18, step784]: loss 1.152899
[epoch18, step785]: loss 1.873453
[epoch18, step786]: loss 2.289510
[epoch18, step787]: loss 0.927192
[epoch18, step788]: loss 1.296816
[epoch18, step789]: loss 9.361465
[epoch18, step790]: loss 8.435353
[epoch18, step791]: loss 0.876855
[epoch18, step792]: loss 1.368723
[epoch18, step793]: loss 7.500326
[epoch18, step794]: loss 8.188220
[epoch18, step795]: loss 0.814717
[epoch18, step796]: loss 2.110315
[epoch18, step797]: loss 1.252636
[epoch18, step798]: loss 0.652660
[epoch18, step799]: loss 0.965871
[epoch18, step800]: loss 9.114229
[epoch18, step801]: loss 1.439630
[epoch18, step802]: loss 10.941209
[epoch18, step803]: loss 1.214350
[epoch18, step804]: loss 1.963392
[epoch18, step805]: loss 3.774932
[epoch18, step806]: loss 1.000399
[epoch18, step807]: loss 0.786275
[epoch18, step808]: loss 9.443765
[epoch18, step809]: loss 3.781407
[epoch18, step810]: loss 1.280463
[epoch18, step811]: loss 1.008644
[epoch18, step812]: loss 9.786039
[epoch18, step813]: loss 3.982274
[epoch18, step814]: loss 0.622182
[epoch18, step815]: loss 3.273757
[epoch18, step816]: loss 0.782614
[epoch18, step817]: loss 1.717029
[epoch18, step818]: loss 0.533394
[epoch18, step819]: loss 2.016161
[epoch18, step820]: loss 0.872803
[epoch18, step821]: loss 0.753507
[epoch18, step822]: loss 11.681513
[epoch18, step823]: loss 0.626222
[epoch18, step824]: loss 2.579701
[epoch18, step825]: loss 16.202374
[epoch18, step826]: loss 1.244662
[epoch18, step827]: loss 1.479331
[epoch18, step828]: loss 5.392697
[epoch18, step829]: loss 0.659880
[epoch18, step830]: loss 8.789907
[epoch18, step831]: loss 1.076841
[epoch18, step832]: loss 1.409415
[epoch18, step833]: loss 13.145554
[epoch18, step834]: loss 0.659030
[epoch18, step835]: loss 0.581708
[epoch18, step836]: loss 4.995666
[epoch18, step837]: loss 4.746752
[epoch18, step838]: loss 0.682271
[epoch18, step839]: loss 1.404684
[epoch18, step840]: loss 2.234948
[epoch18, step841]: loss 0.919101
[epoch18, step842]: loss 1.626066
[epoch18, step843]: loss 6.011963
[epoch18, step844]: loss 3.911377
[epoch18, step845]: loss 1.816049
[epoch18, step846]: loss 5.817336
[epoch18, step847]: loss 2.686932
[epoch18, step848]: loss 2.381907
[epoch18, step849]: loss 11.599543
[epoch18, step850]: loss 0.537426
[epoch18, step851]: loss 3.252647
[epoch18, step852]: loss 9.738582
[epoch18, step853]: loss 4.453948
[epoch18, step854]: loss 17.422852
[epoch18, step855]: loss 1.520862
[epoch18, step856]: loss 7.373983
[epoch18, step857]: loss 7.701085
[epoch18, step858]: loss 3.302440
[epoch18, step859]: loss 2.258055
[epoch18, step860]: loss 4.737449
[epoch18, step861]: loss 11.569510
[epoch18, step862]: loss 8.977098
[epoch18, step863]: loss 1.354203
[epoch18, step864]: loss 0.825215
[epoch18, step865]: loss 2.964027
[epoch18, step866]: loss 1.249464
[epoch18, step867]: loss 1.082255
[epoch18, step868]: loss 1.228162
[epoch18, step869]: loss 0.875234
[epoch18, step870]: loss 1.638249
[epoch18, step871]: loss 0.830284
[epoch18, step872]: loss 2.817960
[epoch18, step873]: loss 1.232709
[epoch18, step874]: loss 1.242756
[epoch18, step875]: loss 3.066394
[epoch18, step876]: loss 1.720786
[epoch18, step877]: loss 7.738114
[epoch18, step878]: loss 1.566219
[epoch18, step879]: loss 4.626698
[epoch18, step880]: loss 0.925421
[epoch18, step881]: loss 0.493134
[epoch18, step882]: loss 2.438087
[epoch18, step883]: loss 1.250486
[epoch18, step884]: loss 1.468943
[epoch18, step885]: loss 0.468255
[epoch18, step886]: loss 2.519543
[epoch18, step887]: loss 11.489905
[epoch18, step888]: loss 1.102886
[epoch18, step889]: loss 0.724672
[epoch18, step890]: loss 1.113094
[epoch18, step891]: loss 2.303106
[epoch18, step892]: loss 16.211409
[epoch18, step893]: loss 2.486317
[epoch18, step894]: loss 11.546851
[epoch18, step895]: loss 8.571134
[epoch18, step896]: loss 3.580671
[epoch18, step897]: loss 4.566451
[epoch18, step898]: loss 0.715433
[epoch18, step899]: loss 1.731574
[epoch18, step900]: loss 1.320064
[epoch18, step901]: loss 5.305118
[epoch18, step902]: loss 8.686772
[epoch18, step903]: loss 1.208394
[epoch18, step904]: loss 0.750604
[epoch18, step905]: loss 9.593142
[epoch18, step906]: loss 1.359147
[epoch18, step907]: loss 8.532849
[epoch18, step908]: loss 8.957099
[epoch18, step909]: loss 1.299576
[epoch18, step910]: loss 0.544519
[epoch18, step911]: loss 0.970136
[epoch18, step912]: loss 0.640213
[epoch18, step913]: loss 0.974617
[epoch18, step914]: loss 1.049592
[epoch18, step915]: loss 0.619063
[epoch18, step916]: loss 1.063203
[epoch18, step917]: loss 2.400223
[epoch18, step918]: loss 1.009054
[epoch18, step919]: loss 1.268506
[epoch18, step920]: loss 10.733169
[epoch18, step921]: loss 1.360581
[epoch18, step922]: loss 2.077268
[epoch18, step923]: loss 1.754841
[epoch18, step924]: loss 3.537741
[epoch18, step925]: loss 9.582094
[epoch18, step926]: loss 7.803447
[epoch18, step927]: loss 2.620121
[epoch18, step928]: loss 1.754720
[epoch18, step929]: loss 0.790974
[epoch18, step930]: loss 1.314432
[epoch18, step931]: loss 5.815931
[epoch18, step932]: loss 3.147523
[epoch18, step933]: loss 0.934859
[epoch18, step934]: loss 1.334734
[epoch18, step935]: loss 1.678498
[epoch18, step936]: loss 5.909250
[epoch18, step937]: loss 1.340133
[epoch18, step938]: loss 0.860999
[epoch18, step939]: loss 0.936814
[epoch18, step940]: loss 1.568382
[epoch18, step941]: loss 2.248158
[epoch18, step942]: loss 0.989006
[epoch18, step943]: loss 1.329272
[epoch18, step944]: loss 3.208979
[epoch18, step945]: loss 5.744525
[epoch18, step946]: loss 0.715321
[epoch18, step947]: loss 0.551319
[epoch18, step948]: loss 14.064250
[epoch18, step949]: loss 9.143099
[epoch18, step950]: loss 1.626068
[epoch18, step951]: loss 0.649583
[epoch18, step952]: loss 11.431681
[epoch18, step953]: loss 7.217369
[epoch18, step954]: loss 1.561882
[epoch18, step955]: loss 1.212247
[epoch18, step956]: loss 1.493371
[epoch18, step957]: loss 9.132495
[epoch18, step958]: loss 0.778123
[epoch18, step959]: loss 1.863043
[epoch18, step960]: loss 1.093107
[epoch18, step961]: loss 22.584599
[epoch18, step962]: loss 1.129922
[epoch18, step963]: loss 1.058840
[epoch18, step964]: loss 2.438519
[epoch18, step965]: loss 4.952369
[epoch18, step966]: loss 6.701893
[epoch18, step967]: loss 1.819809
[epoch18, step968]: loss 2.322870
[epoch18, step969]: loss 2.260444
[epoch18, step970]: loss 3.100710
[epoch18, step971]: loss 1.622046
[epoch18, step972]: loss 3.523578
[epoch18, step973]: loss 1.321551
[epoch18, step974]: loss 1.273023
[epoch18, step975]: loss 0.808777
[epoch18, step976]: loss 1.956292
[epoch18, step977]: loss 0.996367
[epoch18, step978]: loss 9.870706
[epoch18, step979]: loss 0.996431
[epoch18, step980]: loss 2.692188
[epoch18, step981]: loss 1.651737
[epoch18, step982]: loss 7.027307
[epoch18, step983]: loss 0.557357
[epoch18, step984]: loss 3.517127
[epoch18, step985]: loss 0.923693
[epoch18, step986]: loss 2.965047
[epoch18, step987]: loss 0.670761
[epoch18, step988]: loss 0.775540
[epoch18, step989]: loss 1.425274
[epoch18, step990]: loss 3.577920
[epoch18, step991]: loss 0.992270
[epoch18, step992]: loss 0.709151
[epoch18, step993]: loss 4.752350
[epoch18, step994]: loss 2.876710
[epoch18, step995]: loss 1.657744
[epoch18, step996]: loss 1.053073
[epoch18, step997]: loss 4.619608
[epoch18, step998]: loss 9.860062
[epoch18, step999]: loss 25.590191
[epoch18, step1000]: loss 1.087080
[epoch18, step1001]: loss 2.072613
[epoch18, step1002]: loss 0.655160
[epoch18, step1003]: loss 0.897212
[epoch18, step1004]: loss 1.504479
[epoch18, step1005]: loss 0.421195
[epoch18, step1006]: loss 10.900283
[epoch18, step1007]: loss 0.451243
[epoch18, step1008]: loss 12.798882
[epoch18, step1009]: loss 1.203808
[epoch18, step1010]: loss 1.106184
[epoch18, step1011]: loss 2.347790
[epoch18, step1012]: loss 1.388691
[epoch18, step1013]: loss 1.131336
[epoch18, step1014]: loss 1.015561
[epoch18, step1015]: loss 2.901571
[epoch18, step1016]: loss 15.614802
[epoch18, step1017]: loss 4.382166
[epoch18, step1018]: loss 5.559619
[epoch18, step1019]: loss 0.684337
[epoch18, step1020]: loss 0.919418
[epoch18, step1021]: loss 1.177905
[epoch18, step1022]: loss 1.243713
[epoch18, step1023]: loss 10.605712
[epoch18, step1024]: loss 0.945384
[epoch18, step1025]: loss 8.000532
[epoch18, step1026]: loss 21.478050
[epoch18, step1027]: loss 2.925197
[epoch18, step1028]: loss 0.903411
[epoch18, step1029]: loss 1.808738
[epoch18, step1030]: loss 1.977532
[epoch18, step1031]: loss 1.957198
[epoch18, step1032]: loss 1.264830
[epoch18, step1033]: loss 1.016515
[epoch18, step1034]: loss 1.916542
[epoch18, step1035]: loss 1.260824
[epoch18, step1036]: loss 8.954989
[epoch18, step1037]: loss 0.730621
[epoch18, step1038]: loss 1.795277
[epoch18, step1039]: loss 1.828195
[epoch18, step1040]: loss 0.903386
[epoch18, step1041]: loss 2.064821
[epoch18, step1042]: loss 2.835882
[epoch18, step1043]: loss 2.572486
[epoch18, step1044]: loss 2.213123
[epoch18, step1045]: loss 4.620620
[epoch18, step1046]: loss 1.084861
[epoch18, step1047]: loss 1.685857
[epoch18, step1048]: loss 0.803545
[epoch18, step1049]: loss 18.859272
[epoch18, step1050]: loss 1.442787
[epoch18, step1051]: loss 3.628258
[epoch18, step1052]: loss 0.944287
[epoch18, step1053]: loss 2.250902
[epoch18, step1054]: loss 0.837783
[epoch18, step1055]: loss 1.270295
[epoch18, step1056]: loss 1.008125
[epoch18, step1057]: loss 0.890573
[epoch18, step1058]: loss 2.100072
[epoch18, step1059]: loss 15.674985
[epoch18, step1060]: loss 2.735495
[epoch18, step1061]: loss 1.419228
[epoch18, step1062]: loss 7.663532
[epoch18, step1063]: loss 0.943521
[epoch18, step1064]: loss 3.417512
[epoch18, step1065]: loss 1.235100
[epoch18, step1066]: loss 0.566214
[epoch18, step1067]: loss 6.813825
[epoch18, step1068]: loss 4.153090
[epoch18, step1069]: loss 1.484175
[epoch18, step1070]: loss 1.660749
[epoch18, step1071]: loss 0.883198
[epoch18, step1072]: loss 3.275429
[epoch18, step1073]: loss 4.873550
[epoch18, step1074]: loss 0.735289
[epoch18, step1075]: loss 1.184450
[epoch18, step1076]: loss 2.159534
[epoch18, step1077]: loss 10.068761
[epoch18, step1078]: loss 1.988813
[epoch18, step1079]: loss 1.150638
[epoch18, step1080]: loss 9.170138
[epoch18, step1081]: loss 1.926386
[epoch18, step1082]: loss 0.791852
[epoch18, step1083]: loss 0.942096
[epoch18, step1084]: loss 7.340565
[epoch18, step1085]: loss 0.682715
[epoch18, step1086]: loss 1.134700
[epoch18, step1087]: loss 0.612672
[epoch18, step1088]: loss 2.128780
[epoch18, step1089]: loss 0.964449
[epoch18, step1090]: loss 12.618197
[epoch18, step1091]: loss 10.258907
[epoch18, step1092]: loss 2.231107
[epoch18, step1093]: loss 5.815697
[epoch18, step1094]: loss 20.296726
[epoch18, step1095]: loss 14.461310
[epoch18, step1096]: loss 10.923226
[epoch18, step1097]: loss 1.150251
[epoch18, step1098]: loss 9.877667
[epoch18, step1099]: loss 0.809036
[epoch18, step1100]: loss 2.849305
[epoch18, step1101]: loss 2.095863
[epoch18, step1102]: loss 2.074779
[epoch18, step1103]: loss 1.418654
[epoch18, step1104]: loss 5.647926
[epoch18, step1105]: loss 2.076066
[epoch18, step1106]: loss 1.164610
[epoch18, step1107]: loss 1.268924
[epoch18, step1108]: loss 1.908168
[epoch18, step1109]: loss 4.536947
[epoch18, step1110]: loss 1.320094
[epoch18, step1111]: loss 0.538015
[epoch18, step1112]: loss 1.466311
[epoch18, step1113]: loss 1.390954
[epoch18, step1114]: loss 3.454062
[epoch18, step1115]: loss 4.810822
[epoch18, step1116]: loss 0.865039
[epoch18, step1117]: loss 1.023419
[epoch18, step1118]: loss 0.680310
[epoch18, step1119]: loss 0.746906
[epoch18, step1120]: loss 0.829582
[epoch18, step1121]: loss 9.578152
[epoch18, step1122]: loss 2.038521
[epoch18, step1123]: loss 6.098784
[epoch18, step1124]: loss 0.814326
[epoch18, step1125]: loss 0.901586
[epoch18, step1126]: loss 1.631082
[epoch18, step1127]: loss 0.689606
[epoch18, step1128]: loss 2.472140
[epoch18, step1129]: loss 0.833496
[epoch18, step1130]: loss 5.136659
[epoch18, step1131]: loss 1.797989
[epoch18, step1132]: loss 2.785702
[epoch18, step1133]: loss 14.184660
[epoch18, step1134]: loss 2.033317
[epoch18, step1135]: loss 6.242279
[epoch18, step1136]: loss 0.995116
[epoch18, step1137]: loss 1.061541
[epoch18, step1138]: loss 6.919140
[epoch18, step1139]: loss 1.562362
[epoch18, step1140]: loss 0.711831
[epoch18, step1141]: loss 7.451432
[epoch18, step1142]: loss 4.911965
[epoch18, step1143]: loss 3.305479
[epoch18, step1144]: loss 1.132081
[epoch18, step1145]: loss 7.065259
[epoch18, step1146]: loss 5.732867
[epoch18, step1147]: loss 0.785954
[epoch18, step1148]: loss 3.649277
[epoch18, step1149]: loss 1.561538
[epoch18, step1150]: loss 1.145410
[epoch18, step1151]: loss 0.642935
[epoch18, step1152]: loss 9.238884
[epoch18, step1153]: loss 3.505571
[epoch18, step1154]: loss 1.169581
[epoch18, step1155]: loss 4.027036
[epoch18, step1156]: loss 1.081324
[epoch18, step1157]: loss 1.021392
[epoch18, step1158]: loss 0.769224
[epoch18, step1159]: loss 0.917577
[epoch18, step1160]: loss 1.286623
[epoch18, step1161]: loss 10.886239
[epoch18, step1162]: loss 2.089596
[epoch18, step1163]: loss 2.898093
[epoch18, step1164]: loss 11.779794
[epoch18, step1165]: loss 2.698388
[epoch18, step1166]: loss 1.016542
[epoch18, step1167]: loss 1.487542
[epoch18, step1168]: loss 2.464623
[epoch18, step1169]: loss 1.777796
[epoch18, step1170]: loss 0.708307
[epoch18, step1171]: loss 0.923986
[epoch18, step1172]: loss 6.499011
[epoch18, step1173]: loss 3.313774
[epoch18, step1174]: loss 3.118164
[epoch18, step1175]: loss 1.359813
[epoch18, step1176]: loss 2.119324
[epoch18, step1177]: loss 0.794650
[epoch18, step1178]: loss 4.569428
[epoch18, step1179]: loss 1.144410
[epoch18, step1180]: loss 1.516781
[epoch18, step1181]: loss 1.139799
[epoch18, step1182]: loss 0.739300
[epoch18, step1183]: loss 1.600154
[epoch18, step1184]: loss 1.482958
[epoch18, step1185]: loss 1.656435
[epoch18, step1186]: loss 6.613681
[epoch18, step1187]: loss 1.439047
[epoch18, step1188]: loss 0.676308
[epoch18, step1189]: loss 0.953912
[epoch18, step1190]: loss 2.907435
[epoch18, step1191]: loss 11.130798
[epoch18, step1192]: loss 1.331977
[epoch18, step1193]: loss 1.029037
[epoch18, step1194]: loss 0.911420
[epoch18, step1195]: loss 3.571164
[epoch18, step1196]: loss 0.871673
[epoch18, step1197]: loss 2.355386
[epoch18, step1198]: loss 0.728591
[epoch18, step1199]: loss 1.247792
[epoch18, step1200]: loss 1.477361
[epoch18, step1201]: loss 1.978723
[epoch18, step1202]: loss 2.031256
[epoch18, step1203]: loss 0.432412
[epoch18, step1204]: loss 2.301979
[epoch18, step1205]: loss 1.783178
[epoch18, step1206]: loss 1.065863
[epoch18, step1207]: loss 12.223510
[epoch18, step1208]: loss 1.428528
[epoch18, step1209]: loss 0.664485
[epoch18, step1210]: loss 1.573267
[epoch18, step1211]: loss 9.452419
[epoch18, step1212]: loss 0.787607
[epoch18, step1213]: loss 3.704093
[epoch18, step1214]: loss 0.854514
[epoch18, step1215]: loss 2.057754
[epoch18, step1216]: loss 6.873117
[epoch18, step1217]: loss 1.911180
[epoch18, step1218]: loss 2.929975
[epoch18, step1219]: loss 12.702163
[epoch18, step1220]: loss 1.140609
[epoch18, step1221]: loss 0.605036
[epoch18, step1222]: loss 2.552607
[epoch18, step1223]: loss 0.823060
[epoch18, step1224]: loss 3.151235
[epoch18, step1225]: loss 23.997208
[epoch18, step1226]: loss 2.254020
[epoch18, step1227]: loss 2.577690
[epoch18, step1228]: loss 3.144695
[epoch18, step1229]: loss 1.398946
[epoch18, step1230]: loss 1.207536
[epoch18, step1231]: loss 5.532890
[epoch18, step1232]: loss 1.068358
[epoch18, step1233]: loss 9.107823
[epoch18, step1234]: loss 1.375874
[epoch18, step1235]: loss 0.693151
[epoch18, step1236]: loss 2.335204
[epoch18, step1237]: loss 2.728525
[epoch18, step1238]: loss 0.906677
[epoch18, step1239]: loss 2.253697
[epoch18, step1240]: loss 0.761124
[epoch18, step1241]: loss 0.677214
[epoch18, step1242]: loss 5.013346
[epoch18, step1243]: loss 1.763534
[epoch18, step1244]: loss 16.610451
[epoch18, step1245]: loss 0.849315
[epoch18, step1246]: loss 1.386999
[epoch18, step1247]: loss 1.691728
[epoch18, step1248]: loss 0.963775
[epoch18, step1249]: loss 1.400905
[epoch18, step1250]: loss 1.516461
[epoch18, step1251]: loss 1.260968
[epoch18, step1252]: loss 0.692285
[epoch18, step1253]: loss 1.211041
[epoch18, step1254]: loss 0.536790
[epoch18, step1255]: loss 1.288971
[epoch18, step1256]: loss 14.436229
[epoch18, step1257]: loss 2.276999
[epoch18, step1258]: loss 10.900543
[epoch18, step1259]: loss 0.410128
[epoch18, step1260]: loss 7.406670
[epoch18, step1261]: loss 3.967772
[epoch18, step1262]: loss 1.486000
[epoch18, step1263]: loss 6.984157
[epoch18, step1264]: loss 8.742276
[epoch18, step1265]: loss 1.266628
[epoch18, step1266]: loss 1.302047
[epoch18, step1267]: loss 3.285112
[epoch18, step1268]: loss 1.212425
[epoch18, step1269]: loss 1.521931
[epoch18, step1270]: loss 0.829555
[epoch18, step1271]: loss 1.091454
[epoch18, step1272]: loss 1.433113
[epoch18, step1273]: loss 10.561955
[epoch18, step1274]: loss 3.710561
[epoch18, step1275]: loss 1.900069
[epoch18, step1276]: loss 6.528249
[epoch18, step1277]: loss 2.355695
[epoch18, step1278]: loss 1.460128
[epoch18, step1279]: loss 1.081896
[epoch18, step1280]: loss 0.952635
[epoch18, step1281]: loss 11.433974
[epoch18, step1282]: loss 4.258469
[epoch18, step1283]: loss 0.999894
[epoch18, step1284]: loss 2.590913
[epoch18, step1285]: loss 16.199478
[epoch18, step1286]: loss 1.333765
[epoch18, step1287]: loss 1.958060
[epoch18, step1288]: loss 1.968528
[epoch18, step1289]: loss 0.564355
[epoch18, step1290]: loss 1.496859
[epoch18, step1291]: loss 25.635292
[epoch18, step1292]: loss 1.005060
[epoch18, step1293]: loss 0.535520
[epoch18, step1294]: loss 2.357242
[epoch18, step1295]: loss 2.445280
[epoch18, step1296]: loss 2.789114
[epoch18, step1297]: loss 1.307267
[epoch18, step1298]: loss 13.580929
[epoch18, step1299]: loss 0.629081
[epoch18, step1300]: loss 0.792911
[epoch18, step1301]: loss 0.658252
[epoch18, step1302]: loss 1.899904
[epoch18, step1303]: loss 2.553838
[epoch18, step1304]: loss 0.857704
[epoch18, step1305]: loss 1.276141
[epoch18, step1306]: loss 3.538405
[epoch18, step1307]: loss 1.822760
[epoch18, step1308]: loss 1.267783
[epoch18, step1309]: loss 0.680001
[epoch18, step1310]: loss 1.901205
[epoch18, step1311]: loss 0.832791
[epoch18, step1312]: loss 14.977995
[epoch18, step1313]: loss 1.901220
[epoch18, step1314]: loss 0.969716
[epoch18, step1315]: loss 1.870972
[epoch18, step1316]: loss 5.004536
[epoch18, step1317]: loss 0.851277
[epoch18, step1318]: loss 3.443100
[epoch18, step1319]: loss 1.863024
[epoch18, step1320]: loss 1.539665
[epoch18, step1321]: loss 1.237296
[epoch18, step1322]: loss 4.668762
[epoch18, step1323]: loss 2.388474
[epoch18, step1324]: loss 1.685499
[epoch18, step1325]: loss 4.484087
[epoch18, step1326]: loss 1.347181
[epoch18, step1327]: loss 1.962288
[epoch18, step1328]: loss 4.213469
[epoch18, step1329]: loss 0.961372
[epoch18, step1330]: loss 2.819008
[epoch18, step1331]: loss 2.490859
[epoch18, step1332]: loss 0.865576
[epoch18, step1333]: loss 1.026870
[epoch18, step1334]: loss 8.818405
[epoch18, step1335]: loss 2.182236
[epoch18, step1336]: loss 0.650665
[epoch18, step1337]: loss 2.355486
[epoch18, step1338]: loss 0.794510
[epoch18, step1339]: loss 2.531271
[epoch18, step1340]: loss 2.305400
[epoch18, step1341]: loss 1.644730
[epoch18, step1342]: loss 0.664380
[epoch18, step1343]: loss 11.054117
[epoch18, step1344]: loss 1.691535
[epoch18, step1345]: loss 9.870961
[epoch18, step1346]: loss 1.021353
[epoch18, step1347]: loss 1.722992
[epoch18, step1348]: loss 4.004962
[epoch18, step1349]: loss 7.588593
[epoch18, step1350]: loss 1.359187
[epoch18, step1351]: loss 0.760966
[epoch18, step1352]: loss 4.193391
[epoch18, step1353]: loss 1.055147
[epoch18, step1354]: loss 1.485580
[epoch18, step1355]: loss 1.292898
[epoch18, step1356]: loss 1.369059
[epoch18, step1357]: loss 1.227834
[epoch18, step1358]: loss 0.745148
[epoch18, step1359]: loss 9.995432
[epoch18, step1360]: loss 1.573631
[epoch18, step1361]: loss 0.877794
[epoch18, step1362]: loss 2.035518
[epoch18, step1363]: loss 0.849259
[epoch18, step1364]: loss 0.955125
[epoch18, step1365]: loss 3.279406
[epoch18, step1366]: loss 1.453958
[epoch18, step1367]: loss 0.641969
[epoch18, step1368]: loss 10.924137
[epoch18, step1369]: loss 4.772320
[epoch18, step1370]: loss 0.828990
[epoch18, step1371]: loss 10.585797
[epoch18, step1372]: loss 2.400192
[epoch18, step1373]: loss 1.203200
[epoch18, step1374]: loss 0.973142
[epoch18, step1375]: loss 1.755963
[epoch18, step1376]: loss 1.109855
[epoch18, step1377]: loss 11.045703
[epoch18, step1378]: loss 0.717148
[epoch18, step1379]: loss 1.182684
[epoch18, step1380]: loss 5.003793
[epoch18, step1381]: loss 11.041893
[epoch18, step1382]: loss 0.613107
[epoch18, step1383]: loss 0.943529
[epoch18, step1384]: loss 1.312809
[epoch18, step1385]: loss 0.659081
[epoch18, step1386]: loss 6.843187
[epoch18, step1387]: loss 8.806499
[epoch18, step1388]: loss 5.028594
[epoch18, step1389]: loss 0.528861
[epoch18, step1390]: loss 3.311909
[epoch18, step1391]: loss 2.296206
[epoch18, step1392]: loss 7.091317
[epoch18, step1393]: loss 1.118386
[epoch18, step1394]: loss 1.075036
[epoch18, step1395]: loss 1.246328
[epoch18, step1396]: loss 1.087599
[epoch18, step1397]: loss 3.239981
[epoch18, step1398]: loss 0.996202
[epoch18, step1399]: loss 0.776597
[epoch18, step1400]: loss 2.208113
[epoch18, step1401]: loss 1.771845
[epoch18, step1402]: loss 1.309202
[epoch18, step1403]: loss 1.044079
[epoch18, step1404]: loss 3.290081
[epoch18, step1405]: loss 1.277128
[epoch18, step1406]: loss 0.861964
[epoch18, step1407]: loss 2.986018
[epoch18, step1408]: loss 0.980708
[epoch18, step1409]: loss 0.940648
[epoch18, step1410]: loss 1.192643
[epoch18, step1411]: loss 1.120703
[epoch18, step1412]: loss 5.596662
[epoch18, step1413]: loss 0.808960
[epoch18, step1414]: loss 1.204672
[epoch18, step1415]: loss 2.108984
[epoch18, step1416]: loss 1.150608
[epoch18, step1417]: loss 2.147226
[epoch18, step1418]: loss 1.416762
[epoch18, step1419]: loss 7.897802
[epoch18, step1420]: loss 1.095528
[epoch18, step1421]: loss 1.268381
[epoch18, step1422]: loss 0.904253
[epoch18, step1423]: loss 1.653929
[epoch18, step1424]: loss 0.585076
[epoch18, step1425]: loss 0.607048
[epoch18, step1426]: loss 0.585165
[epoch18, step1427]: loss 10.582232
[epoch18, step1428]: loss 1.040520
[epoch18, step1429]: loss 2.187627
[epoch18, step1430]: loss 3.944291
[epoch18, step1431]: loss 2.375660
[epoch18, step1432]: loss 6.281947
[epoch18, step1433]: loss 0.678362
[epoch18, step1434]: loss 6.872187
[epoch18, step1435]: loss 1.924952
[epoch18, step1436]: loss 2.317848
[epoch18, step1437]: loss 2.055176
[epoch18, step1438]: loss 19.563637
[epoch18, step1439]: loss 21.287502
[epoch18, step1440]: loss 1.772638
[epoch18, step1441]: loss 2.158335
[epoch18, step1442]: loss 3.772282
[epoch18, step1443]: loss 0.680614
[epoch18, step1444]: loss 2.286725
[epoch18, step1445]: loss 2.238221
[epoch18, step1446]: loss 1.428195
[epoch18, step1447]: loss 5.848764
[epoch18, step1448]: loss 0.843354
[epoch18, step1449]: loss 4.072145
[epoch18, step1450]: loss 4.456458
[epoch18, step1451]: loss 1.065818
[epoch18, step1452]: loss 8.724992
[epoch18, step1453]: loss 6.627885
[epoch18, step1454]: loss 1.777657
[epoch18, step1455]: loss 0.573971
[epoch18, step1456]: loss 1.393073
[epoch18, step1457]: loss 0.848508
[epoch18, step1458]: loss 1.375821
[epoch18, step1459]: loss 2.604340
[epoch18, step1460]: loss 6.315310
[epoch18, step1461]: loss 2.480979
[epoch18, step1462]: loss 2.345035
[epoch18, step1463]: loss 1.012619
[epoch18, step1464]: loss 1.343936
[epoch18, step1465]: loss 10.833029
[epoch18, step1466]: loss 2.197665
[epoch18, step1467]: loss 0.916026
[epoch18, step1468]: loss 0.620267
[epoch18, step1469]: loss 3.849796
[epoch18, step1470]: loss 7.928984
[epoch18, step1471]: loss 10.331315
[epoch18, step1472]: loss 1.159112
[epoch18, step1473]: loss 5.324251
[epoch18, step1474]: loss 0.799541
[epoch18, step1475]: loss 1.966460
[epoch18, step1476]: loss 0.993334
[epoch18, step1477]: loss 0.582610
[epoch18, step1478]: loss 0.774490
[epoch18, step1479]: loss 0.826782
[epoch18, step1480]: loss 0.706049
[epoch18, step1481]: loss 1.659389
[epoch18, step1482]: loss 7.557668
[epoch18, step1483]: loss 1.223963
[epoch18, step1484]: loss 1.036526
[epoch18, step1485]: loss 3.505165
[epoch18, step1486]: loss 1.778168
[epoch18, step1487]: loss 9.606312
[epoch18, step1488]: loss 9.656845
[epoch18, step1489]: loss 1.876895
[epoch18, step1490]: loss 1.043756
[epoch18, step1491]: loss 1.561100
[epoch18, step1492]: loss 1.480667
[epoch18, step1493]: loss 0.661828
[epoch18, step1494]: loss 0.612841
[epoch18, step1495]: loss 1.118193
[epoch18, step1496]: loss 1.559073
[epoch18, step1497]: loss 1.441342
[epoch18, step1498]: loss 1.092790
[epoch18, step1499]: loss 0.900956
[epoch18, step1500]: loss 0.650696
[epoch18, step1501]: loss 5.034575
[epoch18, step1502]: loss 0.568556
[epoch18, step1503]: loss 5.818273
[epoch18, step1504]: loss 1.443573
[epoch18, step1505]: loss 0.975428
[epoch18, step1506]: loss 4.923086
[epoch18, step1507]: loss 1.356742
[epoch18, step1508]: loss 10.341644
[epoch18, step1509]: loss 53.729694
[epoch18, step1510]: loss 1.860188
[epoch18, step1511]: loss 2.011967
[epoch18, step1512]: loss 1.512213
[epoch18, step1513]: loss 29.935177
[epoch18, step1514]: loss 0.885280
[epoch18, step1515]: loss 1.332234
[epoch18, step1516]: loss 9.728445
[epoch18, step1517]: loss 2.022317
[epoch18, step1518]: loss 2.310778
[epoch18, step1519]: loss 1.243657
[epoch18, step1520]: loss 1.350146
[epoch18, step1521]: loss 1.832157
[epoch18, step1522]: loss 1.405428
[epoch18, step1523]: loss 0.542124
[epoch18, step1524]: loss 0.538851
[epoch18, step1525]: loss 5.408593
[epoch18, step1526]: loss 3.021348
[epoch18, step1527]: loss 7.013794
[epoch18, step1528]: loss 0.894924
[epoch18, step1529]: loss 4.966254
[epoch18, step1530]: loss 1.211714
[epoch18, step1531]: loss 7.042227
[epoch18, step1532]: loss 10.254742
[epoch18, step1533]: loss 0.677357
[epoch18, step1534]: loss 1.592000
[epoch18, step1535]: loss 2.772218
[epoch18, step1536]: loss 0.917056
[epoch18, step1537]: loss 2.605328
[epoch18, step1538]: loss 8.284883
[epoch18, step1539]: loss 1.838657
[epoch18, step1540]: loss 7.223302
[epoch18, step1541]: loss 1.331926
[epoch18, step1542]: loss 3.284386
[epoch18, step1543]: loss 0.920674
[epoch18, step1544]: loss 1.199952
[epoch18, step1545]: loss 0.897353
[epoch18, step1546]: loss 2.677590
[epoch18, step1547]: loss 1.775199
[epoch18, step1548]: loss 10.718645
[epoch18, step1549]: loss 6.091158
[epoch18, step1550]: loss 0.550889
[epoch18, step1551]: loss 6.992301
[epoch18, step1552]: loss 1.290301
[epoch18, step1553]: loss 1.791279
[epoch18, step1554]: loss 8.060696
[epoch18, step1555]: loss 9.157417
[epoch18, step1556]: loss 0.635512
[epoch18, step1557]: loss 4.020238
[epoch18, step1558]: loss 10.191593
[epoch18, step1559]: loss 12.553946
[epoch18, step1560]: loss 3.521930
[epoch18, step1561]: loss 2.758277
[epoch18, step1562]: loss 1.839153
[epoch18, step1563]: loss 2.269717
[epoch18, step1564]: loss 3.518815
[epoch18, step1565]: loss 0.765229
[epoch18, step1566]: loss 1.960452
[epoch18, step1567]: loss 2.659082
[epoch18, step1568]: loss 6.709728
[epoch18, step1569]: loss 1.180699
[epoch18, step1570]: loss 6.132220
[epoch18, step1571]: loss 0.607380
[epoch18, step1572]: loss 1.126261
[epoch18, step1573]: loss 1.184237
[epoch18, step1574]: loss 1.940544
[epoch18, step1575]: loss 0.736658
[epoch18, step1576]: loss 8.209309
[epoch18, step1577]: loss 0.675366
[epoch18, step1578]: loss 11.715179
[epoch18, step1579]: loss 1.121230
[epoch18, step1580]: loss 1.649869
[epoch18, step1581]: loss 1.732006
[epoch18, step1582]: loss 4.060472
[epoch18, step1583]: loss 1.493096
[epoch18, step1584]: loss 1.471849
[epoch18, step1585]: loss 2.671563
[epoch18, step1586]: loss 1.183464
[epoch18, step1587]: loss 1.344445
[epoch18, step1588]: loss 1.326802
[epoch18, step1589]: loss 1.295243
[epoch18, step1590]: loss 0.515893
[epoch18, step1591]: loss 1.059518
[epoch18, step1592]: loss 0.623304
[epoch18, step1593]: loss 9.546389
[epoch18, step1594]: loss 13.669372
[epoch18, step1595]: loss 0.783282
[epoch18, step1596]: loss 1.493571
[epoch18, step1597]: loss 1.418112
[epoch18, step1598]: loss 1.002481
[epoch18, step1599]: loss 2.015568
[epoch18, step1600]: loss 1.463566
[epoch18, step1601]: loss 1.017872
[epoch18, step1602]: loss 2.204214
[epoch18, step1603]: loss 1.371988
[epoch18, step1604]: loss 0.970790
[epoch18, step1605]: loss 1.468627
[epoch18, step1606]: loss 8.287534
[epoch18, step1607]: loss 1.982410
[epoch18, step1608]: loss 0.979947
[epoch18, step1609]: loss 1.681871
[epoch18, step1610]: loss 4.278997
[epoch18, step1611]: loss 1.199867
[epoch18, step1612]: loss 0.840504
[epoch18, step1613]: loss 1.076272
[epoch18, step1614]: loss 1.088530
[epoch18, step1615]: loss 1.156870
[epoch18, step1616]: loss 1.254295
[epoch18, step1617]: loss 0.617534
[epoch18, step1618]: loss 6.304809
[epoch18, step1619]: loss 1.422118
[epoch18, step1620]: loss 0.905382
[epoch18, step1621]: loss 18.990353
[epoch18, step1622]: loss 1.275320
[epoch18, step1623]: loss 4.142449
[epoch18, step1624]: loss 1.729731
[epoch18, step1625]: loss 2.055577
[epoch18, step1626]: loss 1.550771
[epoch18, step1627]: loss 2.501062
[epoch18, step1628]: loss 0.902697
[epoch18, step1629]: loss 0.625603
[epoch18, step1630]: loss 1.207762
[epoch18, step1631]: loss 12.158432
[epoch18, step1632]: loss 1.100994
[epoch18, step1633]: loss 2.100678
[epoch18, step1634]: loss 0.595714
[epoch18, step1635]: loss 1.742577
[epoch18, step1636]: loss 0.964453
[epoch18, step1637]: loss 0.869169
[epoch18, step1638]: loss 2.355346
[epoch18, step1639]: loss 0.834125
[epoch18, step1640]: loss 4.000685
[epoch18, step1641]: loss 0.734008
[epoch18, step1642]: loss 1.056284
[epoch18, step1643]: loss 2.230151
[epoch18, step1644]: loss 0.843679
[epoch18, step1645]: loss 2.528660
[epoch18, step1646]: loss 0.598969
[epoch18, step1647]: loss 2.488780
[epoch18, step1648]: loss 15.814207
[epoch18, step1649]: loss 0.973114
[epoch18, step1650]: loss 12.185639
[epoch18, step1651]: loss 3.164219
[epoch18, step1652]: loss 6.923769
[epoch18, step1653]: loss 2.388819
[epoch18, step1654]: loss 2.232559
[epoch18, step1655]: loss 0.882218
[epoch18, step1656]: loss 1.320088
[epoch18, step1657]: loss 1.841547
[epoch18, step1658]: loss 0.932914
[epoch18, step1659]: loss 1.219707
[epoch18, step1660]: loss 1.888562
[epoch18, step1661]: loss 0.539867
[epoch18, step1662]: loss 1.250575
[epoch18, step1663]: loss 1.371097
[epoch18, step1664]: loss 2.070579
[epoch18, step1665]: loss 0.619503
[epoch18, step1666]: loss 0.894617
[epoch18, step1667]: loss 1.307351
[epoch18, step1668]: loss 7.349648
[epoch18, step1669]: loss 0.921551
[epoch18, step1670]: loss 0.861615
[epoch18, step1671]: loss 0.957825
[epoch18, step1672]: loss 11.841210
[epoch18, step1673]: loss 5.381795
[epoch18, step1674]: loss 2.371624
[epoch18, step1675]: loss 1.161951
[epoch18, step1676]: loss 10.531022
[epoch18, step1677]: loss 1.160817
[epoch18, step1678]: loss 2.875068
[epoch18, step1679]: loss 0.978549
[epoch18, step1680]: loss 4.553356
[epoch18, step1681]: loss 12.663815
[epoch18, step1682]: loss 0.638823
[epoch18, step1683]: loss 0.874167
[epoch18, step1684]: loss 4.045311
[epoch18, step1685]: loss 2.325181
[epoch18, step1686]: loss 1.075953
[epoch18, step1687]: loss 5.187697
[epoch18, step1688]: loss 1.260199
[epoch18, step1689]: loss 1.842940
[epoch18, step1690]: loss 2.632117
[epoch18, step1691]: loss 1.144650
[epoch18, step1692]: loss 1.147775
[epoch18, step1693]: loss 2.029823
[epoch18, step1694]: loss 3.603039
[epoch18, step1695]: loss 1.083598
[epoch18, step1696]: loss 8.724832
[epoch18, step1697]: loss 4.985570
[epoch18, step1698]: loss 3.584627
[epoch18, step1699]: loss 3.693049
[epoch18, step1700]: loss 0.935340
[epoch18, step1701]: loss 0.669039
[epoch18, step1702]: loss 1.180756
[epoch18, step1703]: loss 11.688055
[epoch18, step1704]: loss 9.951680
[epoch18, step1705]: loss 6.077736
[epoch18, step1706]: loss 0.723260
[epoch18, step1707]: loss 2.048752
[epoch18, step1708]: loss 7.657035
[epoch18, step1709]: loss 1.675722
[epoch18, step1710]: loss 2.628716
[epoch18, step1711]: loss 1.834248
[epoch18, step1712]: loss 1.926816
[epoch18, step1713]: loss 0.720840
[epoch18, step1714]: loss 0.477354
[epoch18, step1715]: loss 0.691106
[epoch18, step1716]: loss 0.989669
[epoch18, step1717]: loss 11.098430
[epoch18, step1718]: loss 0.973054
[epoch18, step1719]: loss 4.487778
[epoch18, step1720]: loss 1.225160
[epoch18, step1721]: loss 0.919301
[epoch18, step1722]: loss 2.937057
[epoch18, step1723]: loss 1.023108
[epoch18, step1724]: loss 1.531837
[epoch18, step1725]: loss 2.312488
[epoch18, step1726]: loss 14.091709
[epoch18, step1727]: loss 8.660126
[epoch18, step1728]: loss 0.523124
[epoch18, step1729]: loss 1.078007
[epoch18, step1730]: loss 1.862618
[epoch18, step1731]: loss 0.972275
[epoch18, step1732]: loss 3.031136
[epoch18, step1733]: loss 2.200962
[epoch18, step1734]: loss 16.663881
[epoch18, step1735]: loss 10.507383
[epoch18, step1736]: loss 1.049692
[epoch18, step1737]: loss 1.379788
[epoch18, step1738]: loss 1.666325
[epoch18, step1739]: loss 1.382605
[epoch18, step1740]: loss 9.987926
[epoch18, step1741]: loss 1.027665
[epoch18, step1742]: loss 5.403507
[epoch18, step1743]: loss 0.751705
[epoch18, step1744]: loss 1.725200
[epoch18, step1745]: loss 1.403555
[epoch18, step1746]: loss 1.270336
[epoch18, step1747]: loss 0.986261
[epoch18, step1748]: loss 12.628399
[epoch18, step1749]: loss 6.752728
[epoch18, step1750]: loss 0.900488
[epoch18, step1751]: loss 16.838787
[epoch18, step1752]: loss 0.881971
[epoch18, step1753]: loss 2.746074
[epoch18, step1754]: loss 1.262008
[epoch18, step1755]: loss 2.039530
[epoch18, step1756]: loss 0.799682
[epoch18, step1757]: loss 1.128797
[epoch18, step1758]: loss 1.371668
[epoch18, step1759]: loss 0.929358
[epoch18, step1760]: loss 1.754042
[epoch18, step1761]: loss 0.573480
[epoch18, step1762]: loss 1.021162
[epoch18, step1763]: loss 1.879228
[epoch18, step1764]: loss 1.785663
[epoch18, step1765]: loss 5.535857
[epoch18, step1766]: loss 3.176665
[epoch18, step1767]: loss 1.176397
[epoch18, step1768]: loss 1.455113
[epoch18, step1769]: loss 1.388503
[epoch18, step1770]: loss 1.231143
[epoch18, step1771]: loss 3.157327
[epoch18, step1772]: loss 9.458257
[epoch18, step1773]: loss 9.471160
[epoch18, step1774]: loss 1.732795
[epoch18, step1775]: loss 1.124249
[epoch18, step1776]: loss 1.549713
[epoch18, step1777]: loss 0.455861
[epoch18, step1778]: loss 0.488760
[epoch18, step1779]: loss 2.824350
[epoch18, step1780]: loss 0.540609
[epoch18, step1781]: loss 1.105087
[epoch18, step1782]: loss 0.834727
[epoch18, step1783]: loss 8.301334
[epoch18, step1784]: loss 0.453517
[epoch18, step1785]: loss 1.476372
[epoch18, step1786]: loss 7.565805
[epoch18, step1787]: loss 0.654274
[epoch18, step1788]: loss 0.596915
[epoch18, step1789]: loss 2.869660
[epoch18, step1790]: loss 5.039510
[epoch18, step1791]: loss 8.517087
[epoch18, step1792]: loss 12.277676
[epoch18, step1793]: loss 1.752293
[epoch18, step1794]: loss 1.943616
[epoch18, step1795]: loss 1.239618
[epoch18, step1796]: loss 1.607281
[epoch18, step1797]: loss 3.630640
[epoch18, step1798]: loss 0.934126
[epoch18, step1799]: loss 1.967468
[epoch18, step1800]: loss 9.728534
[epoch18, step1801]: loss 6.119492
[epoch18, step1802]: loss 7.230394
[epoch18, step1803]: loss 7.546545
[epoch18, step1804]: loss 15.404551
[epoch18, step1805]: loss 1.597406
[epoch18, step1806]: loss 2.044085
[epoch18, step1807]: loss 25.792194
[epoch18, step1808]: loss 1.809450
[epoch18, step1809]: loss 1.009429
[epoch18, step1810]: loss 0.606640
[epoch18, step1811]: loss 1.340544
[epoch18, step1812]: loss 1.488760
[epoch18, step1813]: loss 1.253311
[epoch18, step1814]: loss 1.582875
[epoch18, step1815]: loss 1.588065
[epoch18, step1816]: loss 1.754769
[epoch18, step1817]: loss 2.821506
[epoch18, step1818]: loss 0.728138
[epoch18, step1819]: loss 10.144837
[epoch18, step1820]: loss 2.537515
[epoch18, step1821]: loss 1.495308
[epoch18, step1822]: loss 1.836055
[epoch18, step1823]: loss 8.350217
[epoch18, step1824]: loss 0.622894
[epoch18, step1825]: loss 2.270455
[epoch18, step1826]: loss 0.627736
[epoch18, step1827]: loss 10.825007
[epoch18, step1828]: loss 0.604487
[epoch18, step1829]: loss 1.308615
[epoch18, step1830]: loss 1.034119
[epoch18, step1831]: loss 1.647568
[epoch18, step1832]: loss 1.057703
[epoch18, step1833]: loss 2.822735
[epoch18, step1834]: loss 0.583496
[epoch18, step1835]: loss 1.030136
[epoch18, step1836]: loss 2.446822
[epoch18, step1837]: loss 1.141590
[epoch18, step1838]: loss 6.627078
[epoch18, step1839]: loss 1.403697
[epoch18, step1840]: loss 1.194405
[epoch18, step1841]: loss 1.374101
[epoch18, step1842]: loss 1.950493
[epoch18, step1843]: loss 10.493701
[epoch18, step1844]: loss 1.633294
[epoch18, step1845]: loss 1.292559
[epoch18, step1846]: loss 40.715397
[epoch18, step1847]: loss 0.949817
[epoch18, step1848]: loss 1.006816
[epoch18, step1849]: loss 15.400892
[epoch18, step1850]: loss 0.656040
[epoch18, step1851]: loss 7.624812
[epoch18, step1852]: loss 10.288594
[epoch18, step1853]: loss 1.101623
[epoch18, step1854]: loss 7.851583
[epoch18, step1855]: loss 6.923062
[epoch18, step1856]: loss 12.216393
[epoch18, step1857]: loss 4.902197
[epoch18, step1858]: loss 5.524376
[epoch18, step1859]: loss 5.294463
[epoch18, step1860]: loss 2.559767
[epoch18, step1861]: loss 1.151968
[epoch18, step1862]: loss 1.739473
[epoch18, step1863]: loss 1.034586
[epoch18, step1864]: loss 1.542027
[epoch18, step1865]: loss 1.144203
[epoch18, step1866]: loss 3.275963
[epoch18, step1867]: loss 1.793318
[epoch18, step1868]: loss 1.069587
[epoch18, step1869]: loss 2.308678
[epoch18, step1870]: loss 2.906125
[epoch18, step1871]: loss 1.095736
[epoch18, step1872]: loss 3.346657
[epoch18, step1873]: loss 9.221759
[epoch18, step1874]: loss 4.302578
[epoch18, step1875]: loss 8.665060
[epoch18, step1876]: loss 1.046793
[epoch18, step1877]: loss 5.424483
[epoch18, step1878]: loss 1.412155
[epoch18, step1879]: loss 1.243516
[epoch18, step1880]: loss 2.881657
[epoch18, step1881]: loss 3.256717
[epoch18, step1882]: loss 1.509848
[epoch18, step1883]: loss 1.067418
[epoch18, step1884]: loss 1.239339
[epoch18, step1885]: loss 1.086058
[epoch18, step1886]: loss 1.717945
[epoch18, step1887]: loss 4.882453
[epoch18, step1888]: loss 1.109932
[epoch18, step1889]: loss 2.614859
[epoch18, step1890]: loss 4.016614
[epoch18, step1891]: loss 12.631928
[epoch18, step1892]: loss 5.370072
[epoch18, step1893]: loss 1.674210
[epoch18, step1894]: loss 12.019002
[epoch18, step1895]: loss 4.839415
[epoch18, step1896]: loss 0.883485
[epoch18, step1897]: loss 1.369748
[epoch18, step1898]: loss 3.000888
[epoch18, step1899]: loss 0.812982
[epoch18, step1900]: loss 0.562843
[epoch18, step1901]: loss 1.569489
[epoch18, step1902]: loss 0.533960
[epoch18, step1903]: loss 0.976637
[epoch18, step1904]: loss 5.346631
[epoch18, step1905]: loss 2.780167
[epoch18, step1906]: loss 1.109715
[epoch18, step1907]: loss 1.918971
[epoch18, step1908]: loss 6.526936
[epoch18, step1909]: loss 5.693644
[epoch18, step1910]: loss 4.453655
[epoch18, step1911]: loss 1.086446
[epoch18, step1912]: loss 2.246674
[epoch18, step1913]: loss 0.748435
[epoch18, step1914]: loss 1.195999
[epoch18, step1915]: loss 5.733836
[epoch18, step1916]: loss 0.908943
[epoch18, step1917]: loss 0.673308
[epoch18, step1918]: loss 10.252882
[epoch18, step1919]: loss 5.069241
[epoch18, step1920]: loss 1.277484
[epoch18, step1921]: loss 1.371087
[epoch18, step1922]: loss 2.013257
[epoch18, step1923]: loss 1.416851
[epoch18, step1924]: loss 0.971893
[epoch18, step1925]: loss 3.665000
[epoch18, step1926]: loss 1.743590
[epoch18, step1927]: loss 0.971463
[epoch18, step1928]: loss 2.196647
[epoch18, step1929]: loss 1.448469
[epoch18, step1930]: loss 0.594584
[epoch18, step1931]: loss 7.625478
[epoch18, step1932]: loss 1.300342
[epoch18, step1933]: loss 1.824755
[epoch18, step1934]: loss 9.073372
[epoch18, step1935]: loss 15.929962
[epoch18, step1936]: loss 1.090109
[epoch18, step1937]: loss 0.596659
[epoch18, step1938]: loss 1.170501
[epoch18, step1939]: loss 2.865893
[epoch18, step1940]: loss 0.762537
[epoch18, step1941]: loss 10.056067
[epoch18, step1942]: loss 0.700923
[epoch18, step1943]: loss 2.182148
[epoch18, step1944]: loss 9.407657
[epoch18, step1945]: loss 0.908462
[epoch18, step1946]: loss 1.179747
[epoch18, step1947]: loss 3.266769
[epoch18, step1948]: loss 4.669390
[epoch18, step1949]: loss 0.829638
[epoch18, step1950]: loss 6.718394
[epoch18, step1951]: loss 3.868222
[epoch18, step1952]: loss 1.047425
[epoch18, step1953]: loss 0.896167
[epoch18, step1954]: loss 0.638399
[epoch18, step1955]: loss 1.307772
[epoch18, step1956]: loss 1.079262
[epoch18, step1957]: loss 0.966358
[epoch18, step1958]: loss 1.616293
[epoch18, step1959]: loss 4.404024
[epoch18, step1960]: loss 0.926478
[epoch18, step1961]: loss 1.347534
[epoch18, step1962]: loss 0.728627
[epoch18, step1963]: loss 2.806721
[epoch18, step1964]: loss 0.987226
[epoch18, step1965]: loss 1.114773
[epoch18, step1966]: loss 37.661137
[epoch18, step1967]: loss 4.755800
[epoch18, step1968]: loss 1.378687
[epoch18, step1969]: loss 1.694739
[epoch18, step1970]: loss 0.886500
[epoch18, step1971]: loss 1.006032
[epoch18, step1972]: loss 0.808044
[epoch18, step1973]: loss 1.003130
[epoch18, step1974]: loss 2.145112
[epoch18, step1975]: loss 0.696400
[epoch18, step1976]: loss 6.514949
[epoch18, step1977]: loss 0.975312
[epoch18, step1978]: loss 7.957503
[epoch18, step1979]: loss 3.538279
[epoch18, step1980]: loss 0.789640
[epoch18, step1981]: loss 0.825983
[epoch18, step1982]: loss 8.983472
[epoch18, step1983]: loss 1.263538
[epoch18, step1984]: loss 0.471455
[epoch18, step1985]: loss 0.613284
[epoch18, step1986]: loss 1.587106
[epoch18, step1987]: loss 8.526837
[epoch18, step1988]: loss 0.584665
[epoch18, step1989]: loss 1.743778
[epoch18, step1990]: loss 8.514105
[epoch18, step1991]: loss 6.093953
[epoch18, step1992]: loss 0.750818
[epoch18, step1993]: loss 0.875000
[epoch18, step1994]: loss 2.234150
[epoch18, step1995]: loss 1.421149
[epoch18, step1996]: loss 1.105620
[epoch18, step1997]: loss 2.218334
[epoch18, step1998]: loss 0.772579
[epoch18, step1999]: loss 1.547688
[epoch18, step2000]: loss 1.999169
[epoch18, step2001]: loss 1.840803
[epoch18, step2002]: loss 0.811322
[epoch18, step2003]: loss 1.056321
[epoch18, step2004]: loss 3.700444
[epoch18, step2005]: loss 1.474195
[epoch18, step2006]: loss 0.905973
[epoch18, step2007]: loss 4.735627
[epoch18, step2008]: loss 4.946345
[epoch18, step2009]: loss 1.183000
[epoch18, step2010]: loss 1.121138
[epoch18, step2011]: loss 1.540608
[epoch18, step2012]: loss 0.825656
[epoch18, step2013]: loss 1.227164
[epoch18, step2014]: loss 1.566526
[epoch18, step2015]: loss 8.499243
[epoch18, step2016]: loss 0.943024
[epoch18, step2017]: loss 0.799556
[epoch18, step2018]: loss 1.404149
[epoch18, step2019]: loss 4.679691
[epoch18, step2020]: loss 3.343744
[epoch18, step2021]: loss 3.500209
[epoch18, step2022]: loss 0.795284
[epoch18, step2023]: loss 2.459913
[epoch18, step2024]: loss 2.736899
[epoch18, step2025]: loss 0.939864
[epoch18, step2026]: loss 2.170286
[epoch18, step2027]: loss 4.680533
[epoch18, step2028]: loss 1.485200
[epoch18, step2029]: loss 3.683727
[epoch18, step2030]: loss 0.829868
[epoch18, step2031]: loss 0.657367
[epoch18, step2032]: loss 1.361169
[epoch18, step2033]: loss 0.846700
[epoch18, step2034]: loss 1.857074
[epoch18, step2035]: loss 1.971804
[epoch18, step2036]: loss 0.843461
[epoch18, step2037]: loss 2.537580
[epoch18, step2038]: loss 5.327803
[epoch18, step2039]: loss 1.400794
[epoch18, step2040]: loss 11.057581
[epoch18, step2041]: loss 6.512656
[epoch18, step2042]: loss 1.625437
[epoch18, step2043]: loss 2.727426
[epoch18, step2044]: loss 4.654060
[epoch18, step2045]: loss 1.754931
[epoch18, step2046]: loss 1.273742
[epoch18, step2047]: loss 19.441256
[epoch18, step2048]: loss 5.822888
[epoch18, step2049]: loss 1.343089
[epoch18, step2050]: loss 0.843820
[epoch18, step2051]: loss 1.650860
[epoch18, step2052]: loss 0.794678
[epoch18, step2053]: loss 1.985843
[epoch18, step2054]: loss 1.746450
[epoch18, step2055]: loss 0.637909
[epoch18, step2056]: loss 7.255237
[epoch18, step2057]: loss 1.296259
[epoch18, step2058]: loss 13.582730
[epoch18, step2059]: loss 2.860861
[epoch18, step2060]: loss 1.130333
[epoch18, step2061]: loss 1.997435
[epoch18, step2062]: loss 1.169100
[epoch18, step2063]: loss 2.975121
[epoch18, step2064]: loss 2.390752
[epoch18, step2065]: loss 0.530702
[epoch18, step2066]: loss 1.175970
[epoch18, step2067]: loss 7.752024
[epoch18, step2068]: loss 2.975546
[epoch18, step2069]: loss 1.191399
[epoch18, step2070]: loss 0.824686
[epoch18, step2071]: loss 2.369511
[epoch18, step2072]: loss 16.232561
[epoch18, step2073]: loss 0.884011
[epoch18, step2074]: loss 3.121962
[epoch18, step2075]: loss 41.136257
[epoch18, step2076]: loss 2.783178
[epoch18, step2077]: loss 0.823508
[epoch18, step2078]: loss 12.305905
[epoch18, step2079]: loss 1.047096
[epoch18, step2080]: loss 14.175013
[epoch18, step2081]: loss 2.794261
[epoch18, step2082]: loss 1.457934
[epoch18, step2083]: loss 0.547600
[epoch18, step2084]: loss 1.487252
[epoch18, step2085]: loss 1.093193
[epoch18, step2086]: loss 1.026629
[epoch18, step2087]: loss 3.482732
[epoch18, step2088]: loss 1.390599
[epoch18, step2089]: loss 1.170642
[epoch18, step2090]: loss 1.453124
[epoch18, step2091]: loss 1.118949
[epoch18, step2092]: loss 17.026390
[epoch18, step2093]: loss 3.626631
[epoch18, step2094]: loss 9.180769
[epoch18, step2095]: loss 1.152097
[epoch18, step2096]: loss 17.414309
[epoch18, step2097]: loss 2.287944
[epoch18, step2098]: loss 3.862615
[epoch18, step2099]: loss 8.602085
[epoch18, step2100]: loss 4.643411
[epoch18, step2101]: loss 1.030219
[epoch18, step2102]: loss 0.984094
[epoch18, step2103]: loss 3.524537
[epoch18, step2104]: loss 1.876650
[epoch18, step2105]: loss 4.913672
[epoch18, step2106]: loss 1.400090
[epoch18, step2107]: loss 1.116874
[epoch18, step2108]: loss 0.613416
[epoch18, step2109]: loss 1.847498
[epoch18, step2110]: loss 0.852270
[epoch18, step2111]: loss 1.823309
[epoch18, step2112]: loss 1.390218
[epoch18, step2113]: loss 5.226410
[epoch18, step2114]: loss 1.601830
[epoch18, step2115]: loss 0.775862
[epoch18, step2116]: loss 7.318495
[epoch18, step2117]: loss 1.056157
[epoch18, step2118]: loss 9.584366
[epoch18, step2119]: loss 2.278896
[epoch18, step2120]: loss 11.806290
[epoch18, step2121]: loss 1.106779
[epoch18, step2122]: loss 4.773373
[epoch18, step2123]: loss 16.908531
[epoch18, step2124]: loss 7.333818
[epoch18, step2125]: loss 0.901434
[epoch18, step2126]: loss 0.683765
[epoch18, step2127]: loss 10.117723
[epoch18, step2128]: loss 0.651243
[epoch18, step2129]: loss 6.001296
[epoch18, step2130]: loss 11.742110
[epoch18, step2131]: loss 13.280369
[epoch18, step2132]: loss 9.826295
[epoch18, step2133]: loss 12.661974
[epoch18, step2134]: loss 0.788419
[epoch18, step2135]: loss 7.097671
[epoch18, step2136]: loss 8.183827
[epoch18, step2137]: loss 7.471863
[epoch18, step2138]: loss 1.029536
[epoch18, step2139]: loss 5.476689
[epoch18, step2140]: loss 0.844401
[epoch18, step2141]: loss 1.001080
[epoch18, step2142]: loss 3.586668
[epoch18, step2143]: loss 5.865925
[epoch18, step2144]: loss 1.597899
[epoch18, step2145]: loss 0.722993
[epoch18, step2146]: loss 5.103932
[epoch18, step2147]: loss 0.691877
[epoch18, step2148]: loss 0.866919
[epoch18, step2149]: loss 0.824522
[epoch18, step2150]: loss 5.785073
[epoch18, step2151]: loss 0.524170
[epoch18, step2152]: loss 22.973921
[epoch18, step2153]: loss 2.178270
[epoch18, step2154]: loss 1.023311
[epoch18, step2155]: loss 9.429621
[epoch18, step2156]: loss 3.542386
[epoch18, step2157]: loss 2.507981
[epoch18, step2158]: loss 0.652299
[epoch18, step2159]: loss 0.488123
[epoch18, step2160]: loss 1.400102
[epoch18, step2161]: loss 2.486421
[epoch18, step2162]: loss 9.216643
[epoch18, step2163]: loss 9.770464
[epoch18, step2164]: loss 3.586111
[epoch18, step2165]: loss 7.616997
[epoch18, step2166]: loss 3.713031
[epoch18, step2167]: loss 0.564976
[epoch18, step2168]: loss 0.868399
[epoch18, step2169]: loss 0.991618
[epoch18, step2170]: loss 0.650507
[epoch18, step2171]: loss 0.851032
[epoch18, step2172]: loss 1.305677
[epoch18, step2173]: loss 0.967641
[epoch18, step2174]: loss 0.841872
[epoch18, step2175]: loss 3.286813
[epoch18, step2176]: loss 2.499637
[epoch18, step2177]: loss 1.900541
[epoch18, step2178]: loss 1.555561
[epoch18, step2179]: loss 0.899428
[epoch18, step2180]: loss 9.243896
[epoch18, step2181]: loss 1.909855
[epoch18, step2182]: loss 0.829041
[epoch18, step2183]: loss 3.548282
[epoch18, step2184]: loss 1.831734
[epoch18, step2185]: loss 0.848106
[epoch18, step2186]: loss 1.268144
[epoch18, step2187]: loss 0.919170
[epoch18, step2188]: loss 0.709932
[epoch18, step2189]: loss 0.672947
[epoch18, step2190]: loss 1.148881
[epoch18, step2191]: loss 4.671603
[epoch18, step2192]: loss 1.077405
[epoch18, step2193]: loss 8.774206
[epoch18, step2194]: loss 9.836935
[epoch18, step2195]: loss 0.823317
[epoch18, step2196]: loss 0.962490
[epoch18, step2197]: loss 0.920080
[epoch18, step2198]: loss 1.090829
[epoch18, step2199]: loss 1.161687
[epoch18, step2200]: loss 12.732266
[epoch18, step2201]: loss 2.877449
[epoch18, step2202]: loss 3.837371
[epoch18, step2203]: loss 1.585383
[epoch18, step2204]: loss 0.526010
[epoch18, step2205]: loss 1.197173
[epoch18, step2206]: loss 1.745848
[epoch18, step2207]: loss 1.110625
[epoch18, step2208]: loss 2.736081
[epoch18, step2209]: loss 1.170167
[epoch18, step2210]: loss 11.257348
[epoch18, step2211]: loss 1.079943
[epoch18, step2212]: loss 4.968677
[epoch18, step2213]: loss 11.262142
[epoch18, step2214]: loss 2.153948
[epoch18, step2215]: loss 0.592654
[epoch18, step2216]: loss 4.175437
[epoch18, step2217]: loss 28.389465
[epoch18, step2218]: loss 1.700940
[epoch18, step2219]: loss 5.073755
[epoch18, step2220]: loss 1.565532
[epoch18, step2221]: loss 1.492183
[epoch18, step2222]: loss 0.650935
[epoch18, step2223]: loss 0.980650
[epoch18, step2224]: loss 0.812069
[epoch18, step2225]: loss 0.891986
[epoch18, step2226]: loss 20.993172
[epoch18, step2227]: loss 7.566368
[epoch18, step2228]: loss 8.210348
[epoch18, step2229]: loss 1.418794
[epoch18, step2230]: loss 1.836316
[epoch18, step2231]: loss 0.732245
[epoch18, step2232]: loss 1.527069
[epoch18, step2233]: loss 1.649206
[epoch18, step2234]: loss 5.699037
[epoch18, step2235]: loss 1.291140
[epoch18, step2236]: loss 2.202206
[epoch18, step2237]: loss 0.720449
[epoch18, step2238]: loss 0.767274
[epoch18, step2239]: loss 1.067891
[epoch18, step2240]: loss 2.834041
[epoch18, step2241]: loss 2.085793
[epoch18, step2242]: loss 4.316640
[epoch18, step2243]: loss 2.277337
[epoch18, step2244]: loss 1.496282
[epoch18, step2245]: loss 3.464565
[epoch18, step2246]: loss 6.317249
[epoch18, step2247]: loss 1.124026
[epoch18, step2248]: loss 0.996038
[epoch18, step2249]: loss 0.744843
[epoch18, step2250]: loss 1.561105
[epoch18, step2251]: loss 9.239503
[epoch18, step2252]: loss 1.495052
[epoch18, step2253]: loss 3.314660
[epoch18, step2254]: loss 1.174703
[epoch18, step2255]: loss 1.863740
[epoch18, step2256]: loss 9.868256
[epoch18, step2257]: loss 1.092425
[epoch18, step2258]: loss 13.164692
[epoch18, step2259]: loss 1.339114
[epoch18, step2260]: loss 1.318246
[epoch18, step2261]: loss 0.747951
[epoch18, step2262]: loss 0.849761
[epoch18, step2263]: loss 7.141973
[epoch18, step2264]: loss 0.846748
[epoch18, step2265]: loss 3.262038
[epoch18, step2266]: loss 1.974811
[epoch18, step2267]: loss 0.953708
[epoch18, step2268]: loss 4.985757
[epoch18, step2269]: loss 2.214848
[epoch18, step2270]: loss 4.482993
[epoch18, step2271]: loss 5.050330
[epoch18, step2272]: loss 2.365315
[epoch18, step2273]: loss 0.669296
[epoch18, step2274]: loss 1.068708
[epoch18, step2275]: loss 9.538057
[epoch18, step2276]: loss 0.719825
[epoch18, step2277]: loss 1.093237
[epoch18, step2278]: loss 0.686846
[epoch18, step2279]: loss 0.918584
[epoch18, step2280]: loss 10.633224
[epoch18, step2281]: loss 1.276991
[epoch18, step2282]: loss 1.348951
[epoch18, step2283]: loss 1.779139
[epoch18, step2284]: loss 1.056541
[epoch18, step2285]: loss 0.710239
[epoch18, step2286]: loss 3.089710
[epoch18, step2287]: loss 2.188091
[epoch18, step2288]: loss 2.211319
[epoch18, step2289]: loss 9.043069
[epoch18, step2290]: loss 0.960535
[epoch18, step2291]: loss 2.319456
[epoch18, step2292]: loss 11.115137
[epoch18, step2293]: loss 0.988967
[epoch18, step2294]: loss 3.134621
[epoch18, step2295]: loss 0.829823
[epoch18, step2296]: loss 17.005024
[epoch18, step2297]: loss 0.494296
[epoch18, step2298]: loss 1.138742
[epoch18, step2299]: loss 2.689785
[epoch18, step2300]: loss 1.822839
[epoch18, step2301]: loss 1.903617
[epoch18, step2302]: loss 0.950913
[epoch18, step2303]: loss 3.333800
[epoch18, step2304]: loss 2.125463
[epoch18, step2305]: loss 5.002743
[epoch18, step2306]: loss 1.702201
[epoch18, step2307]: loss 0.818762
[epoch18, step2308]: loss 6.972154
[epoch18, step2309]: loss 0.902649
[epoch18, step2310]: loss 9.848347
[epoch18, step2311]: loss 28.447945
[epoch18, step2312]: loss 11.059042
[epoch18, step2313]: loss 0.615376
[epoch18, step2314]: loss 3.039748
[epoch18, step2315]: loss 5.397352
[epoch18, step2316]: loss 2.155129
[epoch18, step2317]: loss 0.384174
[epoch18, step2318]: loss 0.653310
[epoch18, step2319]: loss 5.026335
[epoch18, step2320]: loss 0.873050
[epoch18, step2321]: loss 1.733039
[epoch18, step2322]: loss 6.516479
[epoch18, step2323]: loss 2.750063
[epoch18, step2324]: loss 3.647597
[epoch18, step2325]: loss 5.458277
[epoch18, step2326]: loss 0.793026
[epoch18, step2327]: loss 0.992749
[epoch18, step2328]: loss 4.036472
[epoch18, step2329]: loss 0.973610
[epoch18, step2330]: loss 0.581736
[epoch18, step2331]: loss 10.273767
[epoch18, step2332]: loss 1.342025
[epoch18, step2333]: loss 10.895188
[epoch18, step2334]: loss 4.009654
[epoch18, step2335]: loss 5.288292
[epoch18, step2336]: loss 1.668224
[epoch18, step2337]: loss 8.859961
[epoch18, step2338]: loss 10.994780
[epoch18, step2339]: loss 0.949483
[epoch18, step2340]: loss 1.432927
[epoch18, step2341]: loss 0.890611
[epoch18, step2342]: loss 2.036209
[epoch18, step2343]: loss 2.451284
[epoch18, step2344]: loss 1.781862
[epoch18, step2345]: loss 13.983033
[epoch18, step2346]: loss 1.090792
[epoch18, step2347]: loss 0.526021
[epoch18, step2348]: loss 1.447932
[epoch18, step2349]: loss 1.717613
[epoch18, step2350]: loss 1.294446
[epoch18, step2351]: loss 1.946126
[epoch18, step2352]: loss 16.854004
[epoch18, step2353]: loss 9.187568
[epoch18, step2354]: loss 0.837977
[epoch18, step2355]: loss 0.991709
[epoch18, step2356]: loss 0.918131
[epoch18, step2357]: loss 1.148846
[epoch18, step2358]: loss 24.768282
[epoch18, step2359]: loss 1.575022
[epoch18, step2360]: loss 2.924348
[epoch18, step2361]: loss 1.088720
[epoch18, step2362]: loss 3.332537
[epoch18, step2363]: loss 4.397139
[epoch18, step2364]: loss 1.467124
[epoch18, step2365]: loss 1.327301
[epoch18, step2366]: loss 2.168145
[epoch18, step2367]: loss 1.629112
[epoch18, step2368]: loss 1.253431
[epoch18, step2369]: loss 2.940322
[epoch18, step2370]: loss 2.946282
[epoch18, step2371]: loss 1.382163
[epoch18, step2372]: loss 1.110532
[epoch18, step2373]: loss 0.998058
[epoch18, step2374]: loss 1.460781
[epoch18, step2375]: loss 4.325077
[epoch18, step2376]: loss 1.953699
[epoch18, step2377]: loss 1.446953
[epoch18, step2378]: loss 13.539972
[epoch18, step2379]: loss 1.205369
[epoch18, step2380]: loss 2.340818
[epoch18, step2381]: loss 0.965161
[epoch18, step2382]: loss 1.332425
[epoch18, step2383]: loss 2.654410
[epoch18, step2384]: loss 2.056603
[epoch18, step2385]: loss 3.117959
[epoch18, step2386]: loss 1.428156
[epoch18, step2387]: loss 4.071812
[epoch18, step2388]: loss 1.738427
[epoch18, step2389]: loss 1.768988
[epoch18, step2390]: loss 9.866983
[epoch18, step2391]: loss 4.010447
[epoch18, step2392]: loss 1.685785
[epoch18, step2393]: loss 1.756258
[epoch18, step2394]: loss 0.635253
[epoch18, step2395]: loss 1.548377
[epoch18, step2396]: loss 1.872965
[epoch18, step2397]: loss 1.608570
[epoch18, step2398]: loss 1.462097
[epoch18, step2399]: loss 2.184346
[epoch18, step2400]: loss 4.481077
[epoch18, step2401]: loss 1.450359
[epoch18, step2402]: loss 29.951771
[epoch18, step2403]: loss 3.661572
[epoch18, step2404]: loss 1.273706
[epoch18, step2405]: loss 12.185679
[epoch18, step2406]: loss 0.659859
[epoch18, step2407]: loss 0.735267
[epoch18, step2408]: loss 0.810298
[epoch18, step2409]: loss 6.793180
[epoch18, step2410]: loss 0.785236
[epoch18, step2411]: loss 1.859024
[epoch18, step2412]: loss 0.689617
[epoch18, step2413]: loss 0.755381
[epoch18, step2414]: loss 1.087121
[epoch18, step2415]: loss 1.105276
[epoch18, step2416]: loss 1.173230
[epoch18, step2417]: loss 1.389385
[epoch18, step2418]: loss 11.212535
[epoch18, step2419]: loss 1.782921
[epoch18, step2420]: loss 1.917581
[epoch18, step2421]: loss 1.569689
[epoch18, step2422]: loss 3.645526
[epoch18, step2423]: loss 3.671587
[epoch18, step2424]: loss 0.657606
[epoch18, step2425]: loss 6.370782
[epoch18, step2426]: loss 1.505722
[epoch18, step2427]: loss 10.361135
[epoch18, step2428]: loss 13.698716
[epoch18, step2429]: loss 2.613199
[epoch18, step2430]: loss 7.052454
[epoch18, step2431]: loss 1.271310
[epoch18, step2432]: loss 0.720493
[epoch18, step2433]: loss 8.759004
[epoch18, step2434]: loss 7.634346
[epoch18, step2435]: loss 8.559818
[epoch18, step2436]: loss 0.852927
[epoch18, step2437]: loss 1.501597
[epoch18, step2438]: loss 1.281507
[epoch18, step2439]: loss 2.275041
[epoch18, step2440]: loss 1.551017
[epoch18, step2441]: loss 1.241777
[epoch18, step2442]: loss 0.743298
[epoch18, step2443]: loss 4.899648
[epoch18, step2444]: loss 1.125736
[epoch18, step2445]: loss 9.821079
[epoch18, step2446]: loss 2.175256
[epoch18, step2447]: loss 2.142178
[epoch18, step2448]: loss 3.839037
[epoch18, step2449]: loss 13.219635
[epoch18, step2450]: loss 0.992547
[epoch18, step2451]: loss 0.660878
[epoch18, step2452]: loss 2.362115
[epoch18, step2453]: loss 2.803329
[epoch18, step2454]: loss 1.349931
[epoch18, step2455]: loss 0.829495
[epoch18, step2456]: loss 2.764690
[epoch18, step2457]: loss 1.107969
[epoch18, step2458]: loss 3.052027
[epoch18, step2459]: loss 16.975561
[epoch18, step2460]: loss 14.109641
[epoch18, step2461]: loss 1.013441
[epoch18, step2462]: loss 4.128112
[epoch18, step2463]: loss 2.592057
[epoch18, step2464]: loss 6.876280
[epoch18, step2465]: loss 1.902924
[epoch18, step2466]: loss 4.233319
[epoch18, step2467]: loss 0.870095
[epoch18, step2468]: loss 2.066789
[epoch18, step2469]: loss 13.218630
[epoch18, step2470]: loss 9.349197
[epoch18, step2471]: loss 4.155189
[epoch18, step2472]: loss 2.187767
[epoch18, step2473]: loss 1.781168
[epoch18, step2474]: loss 1.974934
[epoch18, step2475]: loss 3.214342
[epoch18, step2476]: loss 3.627773
[epoch18, step2477]: loss 1.762409
[epoch18, step2478]: loss 0.495720
[epoch18, step2479]: loss 1.350300
[epoch18, step2480]: loss 0.661963
[epoch18, step2481]: loss 2.273043
[epoch18, step2482]: loss 1.092288
[epoch18, step2483]: loss 10.491522
[epoch18, step2484]: loss 1.948667
[epoch18, step2485]: loss 0.951073
[epoch18, step2486]: loss 1.503051
[epoch18, step2487]: loss 4.237177
[epoch18, step2488]: loss 0.994006
[epoch18, step2489]: loss 2.999406
[epoch18, step2490]: loss 0.611703
[epoch18, step2491]: loss 12.378088
[epoch18, step2492]: loss 5.869132
[epoch18, step2493]: loss 3.078795
[epoch18, step2494]: loss 2.161111
[epoch18, step2495]: loss 1.376655
[epoch18, step2496]: loss 2.507018
[epoch18, step2497]: loss 2.881853
[epoch18, step2498]: loss 0.740287
[epoch18, step2499]: loss 2.189647
[epoch18, step2500]: loss 0.828345
[epoch18, step2501]: loss 1.773437
[epoch18, step2502]: loss 1.615346
[epoch18, step2503]: loss 3.703570
[epoch18, step2504]: loss 1.175440
[epoch18, step2505]: loss 1.751324
[epoch18, step2506]: loss 8.753624
[epoch18, step2507]: loss 1.749960
[epoch18, step2508]: loss 0.953919
[epoch18, step2509]: loss 5.492533
[epoch18, step2510]: loss 1.387278
[epoch18, step2511]: loss 0.650752
[epoch18, step2512]: loss 1.143576
[epoch18, step2513]: loss 2.383367
[epoch18, step2514]: loss 1.545063
[epoch18, step2515]: loss 1.106161
[epoch18, step2516]: loss 11.350810
[epoch18, step2517]: loss 0.583001
[epoch18, step2518]: loss 0.685091
[epoch18, step2519]: loss 10.625538
[epoch18, step2520]: loss 0.947148
[epoch18, step2521]: loss 2.621481
[epoch18, step2522]: loss 2.942127
[epoch18, step2523]: loss 0.779293
[epoch18, step2524]: loss 7.779483
[epoch18, step2525]: loss 0.758577
[epoch18, step2526]: loss 11.367702
[epoch18, step2527]: loss 5.536285
[epoch18, step2528]: loss 2.727163
[epoch18, step2529]: loss 1.100020
[epoch18, step2530]: loss 1.066625
[epoch18, step2531]: loss 9.072858
[epoch18, step2532]: loss 1.889464
[epoch18, step2533]: loss 23.775352
[epoch18, step2534]: loss 2.211311
[epoch18, step2535]: loss 1.318856
[epoch18, step2536]: loss 3.938188
[epoch18, step2537]: loss 8.596509
[epoch18, step2538]: loss 11.209510
[epoch18, step2539]: loss 0.565493
[epoch18, step2540]: loss 0.880877
[epoch18, step2541]: loss 1.574844
[epoch18, step2542]: loss 6.651434
[epoch18, step2543]: loss 1.610013
[epoch18, step2544]: loss 6.451423
[epoch18, step2545]: loss 8.131860
[epoch18, step2546]: loss 0.541321
[epoch18, step2547]: loss 0.675662
[epoch18, step2548]: loss 4.288484
[epoch18, step2549]: loss 10.616907
[epoch18, step2550]: loss 1.197470
[epoch18, step2551]: loss 1.792402
[epoch18, step2552]: loss 0.892443
[epoch18, step2553]: loss 1.289987
[epoch18, step2554]: loss 0.723669
[epoch18, step2555]: loss 0.689871
[epoch18, step2556]: loss 0.696978
[epoch18, step2557]: loss 1.530085
[epoch18, step2558]: loss 0.624636
[epoch18, step2559]: loss 1.960838
[epoch18, step2560]: loss 14.286594
[epoch18, step2561]: loss 1.754370
[epoch18, step2562]: loss 0.928196
[epoch18, step2563]: loss 1.428899
[epoch18, step2564]: loss 1.636323
[epoch18, step2565]: loss 3.446403
[epoch18, step2566]: loss 1.661801
[epoch18, step2567]: loss 2.074750
[epoch18, step2568]: loss 1.537752
[epoch18, step2569]: loss 2.854907
[epoch18, step2570]: loss 0.972970
[epoch18, step2571]: loss 0.843980
[epoch18, step2572]: loss 1.026361
[epoch18, step2573]: loss 1.531166
[epoch18, step2574]: loss 3.251741
[epoch18, step2575]: loss 10.091093
[epoch18, step2576]: loss 1.471173
[epoch18, step2577]: loss 0.828656
[epoch18, step2578]: loss 9.372091
[epoch18, step2579]: loss 9.431667
[epoch18, step2580]: loss 0.751442
[epoch18, step2581]: loss 0.761508
[epoch18, step2582]: loss 11.647940
[epoch18, step2583]: loss 1.383698
[epoch18, step2584]: loss 4.536516
[epoch18, step2585]: loss 1.383793
[epoch18, step2586]: loss 1.679004
[epoch18, step2587]: loss 1.467805
[epoch18, step2588]: loss 1.033651
[epoch18, step2589]: loss 1.661656
[epoch18, step2590]: loss 0.910729
[epoch18, step2591]: loss 1.373910
[epoch18, step2592]: loss 14.703775
[epoch18, step2593]: loss 0.676223
[epoch18, step2594]: loss 3.397351
[epoch18, step2595]: loss 0.759469
[epoch18, step2596]: loss 0.851639
[epoch18, step2597]: loss 1.450639
[epoch18, step2598]: loss 1.049533
[epoch18, step2599]: loss 1.373713
[epoch18, step2600]: loss 1.665591
[epoch18, step2601]: loss 10.512718
[epoch18, step2602]: loss 0.545082
[epoch18, step2603]: loss 3.031304
[epoch18, step2604]: loss 2.431882
[epoch18, step2605]: loss 0.630844
[epoch18, step2606]: loss 0.995418
[epoch18, step2607]: loss 0.708108
[epoch18, step2608]: loss 15.099294
[epoch18, step2609]: loss 1.291288
[epoch18, step2610]: loss 13.691978
[epoch18, step2611]: loss 2.885574
[epoch18, step2612]: loss 2.103864
[epoch18, step2613]: loss 1.526557
[epoch18, step2614]: loss 1.143548
[epoch18, step2615]: loss 1.340717
[epoch18, step2616]: loss 1.941463
[epoch18, step2617]: loss 3.677837
[epoch18, step2618]: loss 12.773652
[epoch18, step2619]: loss 0.931935
[epoch18, step2620]: loss 7.414488
[epoch18, step2621]: loss 1.033498
[epoch18, step2622]: loss 0.408926
[epoch18, step2623]: loss 1.070274
[epoch18, step2624]: loss 5.442341
[epoch18, step2625]: loss 1.238388
[epoch18, step2626]: loss 2.350918
[epoch18, step2627]: loss 0.624896
[epoch18, step2628]: loss 11.425605
[epoch18, step2629]: loss 3.380196
[epoch18, step2630]: loss 0.597269
[epoch18, step2631]: loss 1.279797
[epoch18, step2632]: loss 1.453247
[epoch18, step2633]: loss 10.213476
[epoch18, step2634]: loss 1.311443
[epoch18, step2635]: loss 0.577586
[epoch18, step2636]: loss 1.042789
[epoch18, step2637]: loss 0.834532
[epoch18, step2638]: loss 6.611485
[epoch18, step2639]: loss 1.173757
[epoch18, step2640]: loss 0.721017
[epoch18, step2641]: loss 1.255894
[epoch18, step2642]: loss 0.767150
[epoch18, step2643]: loss 1.373609
[epoch18, step2644]: loss 7.253653
[epoch18, step2645]: loss 0.599602
[epoch18, step2646]: loss 13.749540
[epoch18, step2647]: loss 0.737098
[epoch18, step2648]: loss 2.383892
[epoch18, step2649]: loss 1.335474
[epoch18, step2650]: loss 0.975963
[epoch18, step2651]: loss 1.457338
[epoch18, step2652]: loss 1.209995
[epoch18, step2653]: loss 1.149495
[epoch18, step2654]: loss 1.005114
[epoch18, step2655]: loss 2.051088
[epoch18, step2656]: loss 0.689313
[epoch18, step2657]: loss 3.072933
[epoch18, step2658]: loss 5.777677
[epoch18, step2659]: loss 2.677077
[epoch18, step2660]: loss 1.685507
[epoch18, step2661]: loss 5.656966
[epoch18, step2662]: loss 0.974650
[epoch18, step2663]: loss 0.680619
[epoch18, step2664]: loss 0.512504
[epoch18, step2665]: loss 1.128780
[epoch18, step2666]: loss 0.986680
[epoch18, step2667]: loss 6.395570
[epoch18, step2668]: loss 1.921253
[epoch18, step2669]: loss 7.113719
[epoch18, step2670]: loss 0.703512
[epoch18, step2671]: loss 3.817384
[epoch18, step2672]: loss 0.953521
[epoch18, step2673]: loss 1.396877
[epoch18, step2674]: loss 4.348216
[epoch18, step2675]: loss 4.403612
[epoch18, step2676]: loss 2.750415
[epoch18, step2677]: loss 0.864208
[epoch18, step2678]: loss 0.558038
[epoch18, step2679]: loss 1.570250
[epoch18, step2680]: loss 1.507368
[epoch18, step2681]: loss 1.995484
[epoch18, step2682]: loss 23.942375
[epoch18, step2683]: loss 2.251081
[epoch18, step2684]: loss 2.659605
[epoch18, step2685]: loss 0.834394
[epoch18, step2686]: loss 0.934950
[epoch18, step2687]: loss 20.131639
[epoch18, step2688]: loss 1.624206
[epoch18, step2689]: loss 11.066391
[epoch18, step2690]: loss 0.846843
[epoch18, step2691]: loss 1.327514
[epoch18, step2692]: loss 0.897431
[epoch18, step2693]: loss 6.575920
[epoch18, step2694]: loss 0.459555
[epoch18, step2695]: loss 1.212431
[epoch18, step2696]: loss 2.059244
[epoch18, step2697]: loss 2.417029
[epoch18, step2698]: loss 2.148422
[epoch18, step2699]: loss 1.831514
[epoch18, step2700]: loss 0.607934
[epoch18, step2701]: loss 1.100421
[epoch18, step2702]: loss 5.271760
[epoch18, step2703]: loss 1.358212
[epoch18, step2704]: loss 2.700454
[epoch18, step2705]: loss 1.456406
[epoch18, step2706]: loss 0.783447
[epoch18, step2707]: loss 0.676066
[epoch18, step2708]: loss 9.472053
[epoch18, step2709]: loss 1.975944
[epoch18, step2710]: loss 1.003826
[epoch18, step2711]: loss 2.317207
[epoch18, step2712]: loss 2.157200
[epoch18, step2713]: loss 1.101745
[epoch18, step2714]: loss 1.112270
[epoch18, step2715]: loss 0.883719
[epoch18, step2716]: loss 1.271752
[epoch18, step2717]: loss 19.661163
[epoch18, step2718]: loss 1.024400
[epoch18, step2719]: loss 3.969643
[epoch18, step2720]: loss 0.925745
[epoch18, step2721]: loss 3.351298
[epoch18, step2722]: loss 0.575921
[epoch18, step2723]: loss 13.160095
[epoch18, step2724]: loss 0.641374
[epoch18, step2725]: loss 9.758310
[epoch18, step2726]: loss 10.355631
[epoch18, step2727]: loss 1.919727
[epoch18, step2728]: loss 2.654702
[epoch18, step2729]: loss 18.529230
[epoch18, step2730]: loss 3.780590
[epoch18, step2731]: loss 11.076612
[epoch18, step2732]: loss 0.892111
[epoch18, step2733]: loss 8.035197
[epoch18, step2734]: loss 2.371134
[epoch18, step2735]: loss 0.827250
[epoch18, step2736]: loss 11.165202
[epoch18, step2737]: loss 1.550932
[epoch18, step2738]: loss 2.464483
[epoch18, step2739]: loss 9.599237
[epoch18, step2740]: loss 1.072688
[epoch18, step2741]: loss 1.354755
[epoch18, step2742]: loss 1.021778
[epoch18, step2743]: loss 9.971730
[epoch18, step2744]: loss 2.068199
[epoch18, step2745]: loss 15.917840
[epoch18, step2746]: loss 2.970644
[epoch18, step2747]: loss 1.095733
[epoch18, step2748]: loss 2.896099
[epoch18, step2749]: loss 3.043805
[epoch18, step2750]: loss 3.509913
[epoch18, step2751]: loss 1.387441
[epoch18, step2752]: loss 1.230180
[epoch18, step2753]: loss 5.946786
[epoch18, step2754]: loss 16.645790
[epoch18, step2755]: loss 0.574822
[epoch18, step2756]: loss 0.634488
[epoch18, step2757]: loss 4.170251
[epoch18, step2758]: loss 1.460743
[epoch18, step2759]: loss 1.403045
[epoch18, step2760]: loss 7.701722
[epoch18, step2761]: loss 1.658448
[epoch18, step2762]: loss 1.503841
[epoch18, step2763]: loss 0.868720
[epoch18, step2764]: loss 1.655689
[epoch18, step2765]: loss 14.295505
[epoch18, step2766]: loss 0.739117
[epoch18, step2767]: loss 9.174396
[epoch18, step2768]: loss 0.953679
[epoch18, step2769]: loss 0.801317
[epoch18, step2770]: loss 3.635046
[epoch18, step2771]: loss 1.187397
[epoch18, step2772]: loss 0.704249
[epoch18, step2773]: loss 0.877041
[epoch18, step2774]: loss 0.799543
[epoch18, step2775]: loss 1.925832
[epoch18, step2776]: loss 0.914218
[epoch18, step2777]: loss 1.472591
[epoch18, step2778]: loss 2.010526
[epoch18, step2779]: loss 0.784532
[epoch18, step2780]: loss 5.311966
[epoch18, step2781]: loss 12.275724
[epoch18, step2782]: loss 1.107664
[epoch18, step2783]: loss 1.250712
[epoch18, step2784]: loss 0.721902
[epoch18, step2785]: loss 1.900142
[epoch18, step2786]: loss 0.559396
[epoch18, step2787]: loss 0.700016
[epoch18, step2788]: loss 9.263686
[epoch18, step2789]: loss 0.911985
[epoch18, step2790]: loss 3.632932
[epoch18, step2791]: loss 10.582570
[epoch18, step2792]: loss 4.671963
[epoch18, step2793]: loss 16.970648
[epoch18, step2794]: loss 0.623533
[epoch18, step2795]: loss 1.949887
[epoch18, step2796]: loss 1.971426
[epoch18, step2797]: loss 0.946073
[epoch18, step2798]: loss 6.528756
[epoch18, step2799]: loss 6.824463
[epoch18, step2800]: loss 1.942462
[epoch18, step2801]: loss 2.158047
[epoch18, step2802]: loss 6.645174
[epoch18, step2803]: loss 1.194483
[epoch18, step2804]: loss 0.898333
[epoch18, step2805]: loss 2.709503
[epoch18, step2806]: loss 0.747753
[epoch18, step2807]: loss 14.701674
[epoch18, step2808]: loss 4.028062
[epoch18, step2809]: loss 0.981507
[epoch18, step2810]: loss 1.072780
[epoch18, step2811]: loss 1.310217
[epoch18, step2812]: loss 2.608306
[epoch18, step2813]: loss 1.061885
[epoch18, step2814]: loss 16.205708
[epoch18, step2815]: loss 1.214214
[epoch18, step2816]: loss 1.234572
[epoch18, step2817]: loss 9.782186
[epoch18, step2818]: loss 6.040076
[epoch18, step2819]: loss 11.664035
[epoch18, step2820]: loss 3.356545
[epoch18, step2821]: loss 2.351559
[epoch18, step2822]: loss 6.394386
[epoch18, step2823]: loss 8.495329
[epoch18, step2824]: loss 0.827572
[epoch18, step2825]: loss 3.732388
[epoch18, step2826]: loss 0.797355
[epoch18, step2827]: loss 1.075311
[epoch18, step2828]: loss 0.831880
[epoch18, step2829]: loss 1.369938
[epoch18, step2830]: loss 1.868620
[epoch18, step2831]: loss 1.726054
[epoch18, step2832]: loss 1.430507
[epoch18, step2833]: loss 0.957682
[epoch18, step2834]: loss 1.570538
[epoch18, step2835]: loss 0.981776
[epoch18, step2836]: loss 0.673321
[epoch18, step2837]: loss 3.442041
[epoch18, step2838]: loss 3.813486
[epoch18, step2839]: loss 1.046091
[epoch18, step2840]: loss 1.539991
[epoch18, step2841]: loss 3.812015
[epoch18, step2842]: loss 1.217355
[epoch18, step2843]: loss 0.823690
[epoch18, step2844]: loss 11.155759
[epoch18, step2845]: loss 2.448195
[epoch18, step2846]: loss 0.508885
[epoch18, step2847]: loss 1.374934
[epoch18, step2848]: loss 3.401246
[epoch18, step2849]: loss 1.511505
[epoch18, step2850]: loss 1.531459
[epoch18, step2851]: loss 0.754776
[epoch18, step2852]: loss 8.129241
[epoch18, step2853]: loss 1.064247
[epoch18, step2854]: loss 1.562095
[epoch18, step2855]: loss 3.591581
[epoch18, step2856]: loss 3.712151
[epoch18, step2857]: loss 0.702355
[epoch18, step2858]: loss 0.948562
[epoch18, step2859]: loss 5.752863
[epoch18, step2860]: loss 0.934672
[epoch18, step2861]: loss 3.970150
[epoch18, step2862]: loss 1.234461
[epoch18, step2863]: loss 0.611545
[epoch18, step2864]: loss 0.744479
[epoch18, step2865]: loss 2.363221
[epoch18, step2866]: loss 1.254419
[epoch18, step2867]: loss 0.544367
[epoch18, step2868]: loss 1.777413
[epoch18, step2869]: loss 0.792068
[epoch18, step2870]: loss 2.057375
[epoch18, step2871]: loss 1.160903
[epoch18, step2872]: loss 2.576595
[epoch18, step2873]: loss 2.910001
[epoch18, step2874]: loss 21.023859
[epoch18, step2875]: loss 5.816296
[epoch18, step2876]: loss 5.827704
[epoch18, step2877]: loss 1.051519
[epoch18, step2878]: loss 2.754472
[epoch18, step2879]: loss 9.488097
[epoch18, step2880]: loss 3.108776
[epoch18, step2881]: loss 1.112714
[epoch18, step2882]: loss 1.382266
[epoch18, step2883]: loss 0.808032
[epoch18, step2884]: loss 15.160868
[epoch18, step2885]: loss 4.080113
[epoch18, step2886]: loss 10.728634
[epoch18, step2887]: loss 1.307568
[epoch18, step2888]: loss 0.687075
[epoch18, step2889]: loss 6.983755
[epoch18, step2890]: loss 0.612292
[epoch18, step2891]: loss 7.362105
[epoch18, step2892]: loss 0.709325
[epoch18, step2893]: loss 0.677907
[epoch18, step2894]: loss 4.142741
[epoch18, step2895]: loss 2.600699
[epoch18, step2896]: loss 0.716543
[epoch18, step2897]: loss 3.292690
[epoch18, step2898]: loss 2.416831
[epoch18, step2899]: loss 0.576263
[epoch18, step2900]: loss 1.447258
[epoch18, step2901]: loss 1.734566
[epoch18, step2902]: loss 11.568362
[epoch18, step2903]: loss 1.158482
[epoch18, step2904]: loss 1.508265
[epoch18, step2905]: loss 1.216631
[epoch18, step2906]: loss 0.959123
[epoch18, step2907]: loss 9.000247
[epoch18, step2908]: loss 8.751839
[epoch18, step2909]: loss 1.316766
[epoch18, step2910]: loss 8.976415
[epoch18, step2911]: loss 1.561760
[epoch18, step2912]: loss 2.213782
[epoch18, step2913]: loss 0.966351
[epoch18, step2914]: loss 9.234762
[epoch18, step2915]: loss 1.467205
[epoch18, step2916]: loss 4.586181
[epoch18, step2917]: loss 0.887979
[epoch18, step2918]: loss 1.476095
[epoch18, step2919]: loss 4.812973
[epoch18, step2920]: loss 0.992152
[epoch18, step2921]: loss 1.440336
[epoch18, step2922]: loss 1.627023
[epoch18, step2923]: loss 1.263284
[epoch18, step2924]: loss 1.288632
[epoch18, step2925]: loss 1.717842
[epoch18, step2926]: loss 2.954370
[epoch18, step2927]: loss 0.876899
[epoch18, step2928]: loss 16.741798
[epoch18, step2929]: loss 2.800194
[epoch18, step2930]: loss 1.010201
[epoch18, step2931]: loss 6.176367
[epoch18, step2932]: loss 2.262419
[epoch18, step2933]: loss 7.557387
[epoch18, step2934]: loss 9.476466
[epoch18, step2935]: loss 1.601967
[epoch18, step2936]: loss 0.716455
[epoch18, step2937]: loss 11.065636
[epoch18, step2938]: loss 1.029407
[epoch18, step2939]: loss 1.151592
[epoch18, step2940]: loss 4.452791
[epoch18, step2941]: loss 1.353250
[epoch18, step2942]: loss 0.654356
[epoch18, step2943]: loss 9.623955
[epoch18, step2944]: loss 4.314917
[epoch18, step2945]: loss 2.139271
[epoch18, step2946]: loss 2.029675
[epoch18, step2947]: loss 1.223607
[epoch18, step2948]: loss 0.814426
[epoch18, step2949]: loss 1.873518
[epoch18, step2950]: loss 8.310147
[epoch18, step2951]: loss 10.696263
[epoch18, step2952]: loss 1.010894
[epoch18, step2953]: loss 12.481079
[epoch18, step2954]: loss 6.122286
[epoch18, step2955]: loss 10.529863
[epoch18, step2956]: loss 2.412589
[epoch18, step2957]: loss 1.800226
[epoch18, step2958]: loss 3.158579
[epoch18, step2959]: loss 1.015495
[epoch18, step2960]: loss 1.004553
[epoch18, step2961]: loss 1.510021
[epoch18, step2962]: loss 7.469729
[epoch18, step2963]: loss 2.570563
[epoch18, step2964]: loss 2.487233
[epoch18, step2965]: loss 1.259975
[epoch18, step2966]: loss 0.734585
[epoch18, step2967]: loss 0.850355
[epoch18, step2968]: loss 6.446369
[epoch18, step2969]: loss 1.358428
[epoch18, step2970]: loss 1.858919
[epoch18, step2971]: loss 4.950244
[epoch18, step2972]: loss 0.862284
[epoch18, step2973]: loss 7.174745
[epoch18, step2974]: loss 1.557011
[epoch18, step2975]: loss 1.659482
[epoch18, step2976]: loss 11.478664
[epoch18, step2977]: loss 1.203219
[epoch18, step2978]: loss 8.812900
[epoch18, step2979]: loss 5.006247
[epoch18, step2980]: loss 0.870944
[epoch18, step2981]: loss 0.721566
[epoch18, step2982]: loss 3.592899
[epoch18, step2983]: loss 1.596343
[epoch18, step2984]: loss 0.812566
[epoch18, step2985]: loss 1.638065
[epoch18, step2986]: loss 3.639489
[epoch18, step2987]: loss 1.956079
[epoch18, step2988]: loss 9.402537
[epoch18, step2989]: loss 3.389417
[epoch18, step2990]: loss 4.119160
[epoch18, step2991]: loss 8.441564
[epoch18, step2992]: loss 0.614948
[epoch18, step2993]: loss 7.915849
[epoch18, step2994]: loss 0.623057
[epoch18, step2995]: loss 0.670730
[epoch18, step2996]: loss 1.474643
[epoch18, step2997]: loss 1.053053
[epoch18, step2998]: loss 0.489148
[epoch18, step2999]: loss 2.138007
[epoch18, step3000]: loss 6.901830
[epoch18, step3001]: loss 1.605073
[epoch18, step3002]: loss 1.943773
[epoch18, step3003]: loss 0.766396
[epoch18, step3004]: loss 1.747567
[epoch18, step3005]: loss 1.360405
[epoch18, step3006]: loss 3.159145
[epoch18, step3007]: loss 0.675058
[epoch18, step3008]: loss 1.316136
[epoch18, step3009]: loss 1.396858
[epoch18, step3010]: loss 5.195415
[epoch18, step3011]: loss 1.917223
[epoch18, step3012]: loss 0.719952
[epoch18, step3013]: loss 1.445541
[epoch18, step3014]: loss 15.863787
[epoch18, step3015]: loss 0.993681
[epoch18, step3016]: loss 7.839531
[epoch18, step3017]: loss 7.229388
[epoch18, step3018]: loss 0.690538
[epoch18, step3019]: loss 2.901645
[epoch18, step3020]: loss 3.168663
[epoch18, step3021]: loss 1.139259
[epoch18, step3022]: loss 1.260898
[epoch18, step3023]: loss 5.825191
[epoch18, step3024]: loss 0.794857
[epoch18, step3025]: loss 15.877543
[epoch18, step3026]: loss 12.764462
[epoch18, step3027]: loss 1.863400
[epoch18, step3028]: loss 1.414440
[epoch18, step3029]: loss 9.300445
[epoch18, step3030]: loss 0.869849
[epoch18, step3031]: loss 1.308346
[epoch18, step3032]: loss 8.503821
[epoch18, step3033]: loss 1.545460
[epoch18, step3034]: loss 0.722308
[epoch18, step3035]: loss 0.689280
[epoch18, step3036]: loss 5.740145
[epoch18, step3037]: loss 7.784314
[epoch18, step3038]: loss 1.604196
[epoch18, step3039]: loss 9.454531
[epoch18, step3040]: loss 4.608987
[epoch18, step3041]: loss 1.727371
[epoch18, step3042]: loss 1.826443
[epoch18, step3043]: loss 3.906737
[epoch18, step3044]: loss 2.355349
[epoch18, step3045]: loss 12.002501
[epoch18, step3046]: loss 1.053872
[epoch18, step3047]: loss 1.072837
[epoch18, step3048]: loss 2.413581
[epoch18, step3049]: loss 1.466314
[epoch18, step3050]: loss 1.393812
[epoch18, step3051]: loss 6.806085
[epoch18, step3052]: loss 1.137557
[epoch18, step3053]: loss 8.570141
[epoch18, step3054]: loss 1.769057
[epoch18, step3055]: loss 0.990238
[epoch18, step3056]: loss 27.661980
[epoch18, step3057]: loss 1.458078
[epoch18, step3058]: loss 4.601790
[epoch18, step3059]: loss 0.814180
[epoch18, step3060]: loss 4.170135
[epoch18, step3061]: loss 1.880210
[epoch18, step3062]: loss 1.136037
[epoch18, step3063]: loss 3.364293
[epoch18, step3064]: loss 0.879795
[epoch18, step3065]: loss 3.114806
[epoch18, step3066]: loss 2.027313
[epoch18, step3067]: loss 1.999891
[epoch18, step3068]: loss 1.936945
[epoch18, step3069]: loss 1.609151
[epoch18, step3070]: loss 12.988759
[epoch18, step3071]: loss 2.031438
[epoch18, step3072]: loss 2.441969
[epoch18, step3073]: loss 1.034088
[epoch18, step3074]: loss 0.983460
[epoch18, step3075]: loss 1.018758
[epoch18, step3076]: loss 0.832495

[epoch18]: avg loss 0.832495

[epoch19, step1]: loss 8.637421
[epoch19, step2]: loss 1.375048
[epoch19, step3]: loss 13.603699
[epoch19, step4]: loss 1.960774
[epoch19, step5]: loss 1.290410
[epoch19, step6]: loss 0.766105
[epoch19, step7]: loss 1.196798
[epoch19, step8]: loss 0.977612
[epoch19, step9]: loss 0.828238
[epoch19, step10]: loss 0.834262
[epoch19, step11]: loss 1.514778
[epoch19, step12]: loss 1.583055
[epoch19, step13]: loss 1.420217
[epoch19, step14]: loss 12.646467
[epoch19, step15]: loss 1.868412
[epoch19, step16]: loss 5.389152
[epoch19, step17]: loss 1.157270
[epoch19, step18]: loss 1.465567
[epoch19, step19]: loss 6.765511
[epoch19, step20]: loss 8.054510
[epoch19, step21]: loss 1.404921
[epoch19, step22]: loss 0.904778
[epoch19, step23]: loss 23.800451
[epoch19, step24]: loss 1.149089
[epoch19, step25]: loss 4.753263
[epoch19, step26]: loss 10.893800
[epoch19, step27]: loss 10.283372
[epoch19, step28]: loss 3.495501
[epoch19, step29]: loss 1.101796
[epoch19, step30]: loss 0.803068
[epoch19, step31]: loss 4.183149
[epoch19, step32]: loss 7.785840
[epoch19, step33]: loss 9.867855
[epoch19, step34]: loss 5.276927
[epoch19, step35]: loss 6.999522
[epoch19, step36]: loss 0.985259
[epoch19, step37]: loss 1.270746
[epoch19, step38]: loss 1.583827
[epoch19, step39]: loss 1.320415
[epoch19, step40]: loss 1.471120
[epoch19, step41]: loss 1.079068
[epoch19, step42]: loss 1.294830
[epoch19, step43]: loss 27.476982
[epoch19, step44]: loss 0.885635
[epoch19, step45]: loss 1.487116
[epoch19, step46]: loss 0.992324
[epoch19, step47]: loss 1.068166
[epoch19, step48]: loss 1.441020
[epoch19, step49]: loss 6.149334
[epoch19, step50]: loss 1.299307
[epoch19, step51]: loss 2.179612
[epoch19, step52]: loss 3.154812
[epoch19, step53]: loss 1.007330
[epoch19, step54]: loss 1.546592
[epoch19, step55]: loss 1.121693
[epoch19, step56]: loss 1.338971
[epoch19, step57]: loss 1.183243
[epoch19, step58]: loss 1.393440
[epoch19, step59]: loss 2.257368
[epoch19, step60]: loss 0.831218
[epoch19, step61]: loss 1.145255
[epoch19, step62]: loss 11.533189
[epoch19, step63]: loss 8.826173
[epoch19, step64]: loss 1.078366
[epoch19, step65]: loss 2.385759
[epoch19, step66]: loss 5.838789
[epoch19, step67]: loss 1.320459
[epoch19, step68]: loss 0.844750
[epoch19, step69]: loss 0.730350
[epoch19, step70]: loss 0.580076
[epoch19, step71]: loss 0.661777
[epoch19, step72]: loss 1.719365
[epoch19, step73]: loss 2.190242
[epoch19, step74]: loss 1.728283
[epoch19, step75]: loss 12.882590
[epoch19, step76]: loss 4.923335
[epoch19, step77]: loss 2.842216
[epoch19, step78]: loss 7.984643
[epoch19, step79]: loss 1.821249
[epoch19, step80]: loss 2.282395
[epoch19, step81]: loss 5.288858
[epoch19, step82]: loss 2.113319
[epoch19, step83]: loss 2.026803
[epoch19, step84]: loss 0.804568
[epoch19, step85]: loss 9.217728
[epoch19, step86]: loss 8.599896
[epoch19, step87]: loss 10.893002
[epoch19, step88]: loss 1.270953
[epoch19, step89]: loss 2.054960
[epoch19, step90]: loss 2.625874
[epoch19, step91]: loss 0.860045
[epoch19, step92]: loss 2.217370
[epoch19, step93]: loss 1.140636
[epoch19, step94]: loss 1.729349
[epoch19, step95]: loss 0.981557
[epoch19, step96]: loss 0.923781
[epoch19, step97]: loss 3.395052
[epoch19, step98]: loss 6.162892
[epoch19, step99]: loss 1.558051
[epoch19, step100]: loss 0.978746
[epoch19, step101]: loss 0.487108
[epoch19, step102]: loss 0.901140
[epoch19, step103]: loss 2.558343
[epoch19, step104]: loss 0.762365
[epoch19, step105]: loss 1.464764
[epoch19, step106]: loss 2.106572
[epoch19, step107]: loss 3.214435
[epoch19, step108]: loss 1.090412
[epoch19, step109]: loss 2.523490
[epoch19, step110]: loss 4.047915
[epoch19, step111]: loss 0.756497
[epoch19, step112]: loss 6.758202
[epoch19, step113]: loss 2.390072
[epoch19, step114]: loss 3.287804
[epoch19, step115]: loss 7.103427
[epoch19, step116]: loss 1.014634
[epoch19, step117]: loss 2.385610
[epoch19, step118]: loss 2.059614
[epoch19, step119]: loss 3.683404
[epoch19, step120]: loss 1.090158
[epoch19, step121]: loss 1.959931
[epoch19, step122]: loss 1.312731
[epoch19, step123]: loss 1.198424
[epoch19, step124]: loss 2.086339
[epoch19, step125]: loss 2.476269
[epoch19, step126]: loss 1.344377
[epoch19, step127]: loss 2.272733
[epoch19, step128]: loss 4.522561
[epoch19, step129]: loss 1.667515
[epoch19, step130]: loss 2.712070
[epoch19, step131]: loss 0.842723
[epoch19, step132]: loss 1.873571
[epoch19, step133]: loss 1.426718
[epoch19, step134]: loss 9.263547
[epoch19, step135]: loss 1.328610
[epoch19, step136]: loss 1.211446
[epoch19, step137]: loss 1.112865
[epoch19, step138]: loss 2.610333
[epoch19, step139]: loss 1.527068
[epoch19, step140]: loss 0.983517
[epoch19, step141]: loss 0.887929
[epoch19, step142]: loss 0.595634
[epoch19, step143]: loss 9.869634
[epoch19, step144]: loss 5.586338
[epoch19, step145]: loss 11.736575
[epoch19, step146]: loss 2.546550
[epoch19, step147]: loss 1.677146
[epoch19, step148]: loss 2.354662
[epoch19, step149]: loss 1.636393
[epoch19, step150]: loss 1.956885
[epoch19, step151]: loss 1.234077
[epoch19, step152]: loss 0.710212
[epoch19, step153]: loss 1.053905
[epoch19, step154]: loss 5.713322
[epoch19, step155]: loss 0.643766
[epoch19, step156]: loss 0.731728
[epoch19, step157]: loss 1.725967
[epoch19, step158]: loss 2.796387
[epoch19, step159]: loss 4.779918
[epoch19, step160]: loss 1.014824
[epoch19, step161]: loss 0.758171
[epoch19, step162]: loss 1.597562
[epoch19, step163]: loss 0.806484
[epoch19, step164]: loss 0.843230
[epoch19, step165]: loss 0.728118
[epoch19, step166]: loss 4.703287
[epoch19, step167]: loss 3.863816
[epoch19, step168]: loss 2.043624
[epoch19, step169]: loss 12.683969
[epoch19, step170]: loss 2.227803
[epoch19, step171]: loss 0.536950
[epoch19, step172]: loss 3.794556
[epoch19, step173]: loss 1.488309
[epoch19, step174]: loss 1.076384
[epoch19, step175]: loss 3.859553
[epoch19, step176]: loss 1.984458
[epoch19, step177]: loss 1.402412
[epoch19, step178]: loss 1.050162
[epoch19, step179]: loss 4.047486
[epoch19, step180]: loss 3.304778
[epoch19, step181]: loss 1.154766
[epoch19, step182]: loss 0.765120
[epoch19, step183]: loss 3.890027
[epoch19, step184]: loss 1.449252
[epoch19, step185]: loss 0.919212
[epoch19, step186]: loss 1.178604
[epoch19, step187]: loss 1.607253
[epoch19, step188]: loss 1.548745
[epoch19, step189]: loss 1.421603
[epoch19, step190]: loss 2.374631
[epoch19, step191]: loss 0.686541
[epoch19, step192]: loss 13.022211
[epoch19, step193]: loss 16.585785
[epoch19, step194]: loss 0.632100
[epoch19, step195]: loss 2.252688
[epoch19, step196]: loss 1.064139
[epoch19, step197]: loss 3.562925
[epoch19, step198]: loss 1.054022
[epoch19, step199]: loss 10.432471
[epoch19, step200]: loss 1.147148
[epoch19, step201]: loss 1.154212
[epoch19, step202]: loss 0.915734
[epoch19, step203]: loss 2.026872
[epoch19, step204]: loss 3.745427
[epoch19, step205]: loss 12.047579
[epoch19, step206]: loss 0.485793
[epoch19, step207]: loss 7.461841
[epoch19, step208]: loss 7.417763
[epoch19, step209]: loss 2.156079
[epoch19, step210]: loss 1.051488
[epoch19, step211]: loss 1.023909
[epoch19, step212]: loss 1.050502
[epoch19, step213]: loss 3.773285
[epoch19, step214]: loss 7.446584
[epoch19, step215]: loss 4.259654
[epoch19, step216]: loss 2.500836
[epoch19, step217]: loss 0.833506
[epoch19, step218]: loss 11.097725
[epoch19, step219]: loss 5.329006
[epoch19, step220]: loss 9.429122
[epoch19, step221]: loss 6.990057
[epoch19, step222]: loss 0.569607
[epoch19, step223]: loss 1.442045
[epoch19, step224]: loss 2.391572
[epoch19, step225]: loss 2.046207
[epoch19, step226]: loss 8.814150
[epoch19, step227]: loss 3.431969
[epoch19, step228]: loss 2.240542
[epoch19, step229]: loss 0.802604
[epoch19, step230]: loss 1.304823
[epoch19, step231]: loss 1.579844
[epoch19, step232]: loss 9.694726
[epoch19, step233]: loss 0.916501
[epoch19, step234]: loss 0.864170
[epoch19, step235]: loss 1.078759
[epoch19, step236]: loss 11.137506
[epoch19, step237]: loss 0.771185
[epoch19, step238]: loss 11.976192
[epoch19, step239]: loss 5.364860
[epoch19, step240]: loss 3.003630
[epoch19, step241]: loss 0.773387
[epoch19, step242]: loss 1.403754
[epoch19, step243]: loss 1.025610
[epoch19, step244]: loss 10.651786
[epoch19, step245]: loss 7.230824
[epoch19, step246]: loss 1.525403
[epoch19, step247]: loss 12.102175
[epoch19, step248]: loss 2.299909
[epoch19, step249]: loss 1.257963
[epoch19, step250]: loss 7.087575
[epoch19, step251]: loss 1.545327
[epoch19, step252]: loss 0.754285
[epoch19, step253]: loss 3.626199
[epoch19, step254]: loss 1.490395
[epoch19, step255]: loss 0.614775
[epoch19, step256]: loss 1.614081
[epoch19, step257]: loss 5.587095
[epoch19, step258]: loss 0.583209
[epoch19, step259]: loss 0.689938
[epoch19, step260]: loss 4.137135
[epoch19, step261]: loss 0.873973
[epoch19, step262]: loss 0.925040
[epoch19, step263]: loss 0.773233
[epoch19, step264]: loss 1.267780
[epoch19, step265]: loss 0.937402
[epoch19, step266]: loss 1.748281
[epoch19, step267]: loss 0.578456
[epoch19, step268]: loss 10.141580
[epoch19, step269]: loss 18.387863
[epoch19, step270]: loss 1.401194
[epoch19, step271]: loss 1.302492
[epoch19, step272]: loss 6.743217
[epoch19, step273]: loss 1.443090
[epoch19, step274]: loss 0.806983
[epoch19, step275]: loss 2.654146
[epoch19, step276]: loss 10.565585
[epoch19, step277]: loss 1.181710
[epoch19, step278]: loss 1.722317
[epoch19, step279]: loss 2.576600
[epoch19, step280]: loss 6.088693
[epoch19, step281]: loss 0.852584
[epoch19, step282]: loss 0.657607
[epoch19, step283]: loss 1.373032
[epoch19, step284]: loss 0.979706
[epoch19, step285]: loss 1.116593
[epoch19, step286]: loss 0.680786
[epoch19, step287]: loss 1.802198
[epoch19, step288]: loss 0.886159
[epoch19, step289]: loss 0.765621
[epoch19, step290]: loss 8.467916
[epoch19, step291]: loss 1.586023
[epoch19, step292]: loss 9.295693
[epoch19, step293]: loss 4.097603
[epoch19, step294]: loss 28.438433
[epoch19, step295]: loss 9.380291
[epoch19, step296]: loss 10.987688
[epoch19, step297]: loss 2.149477
[epoch19, step298]: loss 11.680540
[epoch19, step299]: loss 2.045094
[epoch19, step300]: loss 10.865693
[epoch19, step301]: loss 0.719696
[epoch19, step302]: loss 0.663417
[epoch19, step303]: loss 0.870139
[epoch19, step304]: loss 3.971830
[epoch19, step305]: loss 1.054527
[epoch19, step306]: loss 0.719597
[epoch19, step307]: loss 0.710711
[epoch19, step308]: loss 0.701294
[epoch19, step309]: loss 0.888443
[epoch19, step310]: loss 1.793737
[epoch19, step311]: loss 1.579925
[epoch19, step312]: loss 1.197014
[epoch19, step313]: loss 5.641098
[epoch19, step314]: loss 6.510147
[epoch19, step315]: loss 1.467763
[epoch19, step316]: loss 3.447083
[epoch19, step317]: loss 1.563594
[epoch19, step318]: loss 3.474530
[epoch19, step319]: loss 1.199085
[epoch19, step320]: loss 6.618519
[epoch19, step321]: loss 2.604413
[epoch19, step322]: loss 3.613816
[epoch19, step323]: loss 0.482687
[epoch19, step324]: loss 1.623846
[epoch19, step325]: loss 0.917181
[epoch19, step326]: loss 3.289015
[epoch19, step327]: loss 0.878719
[epoch19, step328]: loss 0.656260
[epoch19, step329]: loss 1.363253
[epoch19, step330]: loss 5.727591
[epoch19, step331]: loss 1.341492
[epoch19, step332]: loss 2.108388
[epoch19, step333]: loss 3.114637
[epoch19, step334]: loss 0.634964
[epoch19, step335]: loss 1.544348
[epoch19, step336]: loss 1.033870
[epoch19, step337]: loss 1.124894
[epoch19, step338]: loss 2.771837
[epoch19, step339]: loss 9.598252
[epoch19, step340]: loss 1.667035
[epoch19, step341]: loss 1.496701
[epoch19, step342]: loss 11.455128
[epoch19, step343]: loss 2.119676
[epoch19, step344]: loss 3.535020
[epoch19, step345]: loss 1.786453
[epoch19, step346]: loss 0.835581
[epoch19, step347]: loss 2.499626
[epoch19, step348]: loss 1.544541
[epoch19, step349]: loss 5.856725
[epoch19, step350]: loss 10.309834
[epoch19, step351]: loss 1.678576
[epoch19, step352]: loss 2.066681
[epoch19, step353]: loss 8.081628
[epoch19, step354]: loss 2.717196
[epoch19, step355]: loss 11.478399
[epoch19, step356]: loss 0.763475
[epoch19, step357]: loss 3.615098
[epoch19, step358]: loss 0.817786
[epoch19, step359]: loss 0.822734
[epoch19, step360]: loss 0.736982
[epoch19, step361]: loss 1.156354
[epoch19, step362]: loss 0.935140
[epoch19, step363]: loss 9.370683
[epoch19, step364]: loss 0.645399
[epoch19, step365]: loss 2.604258
[epoch19, step366]: loss 1.343392
[epoch19, step367]: loss 0.766110
[epoch19, step368]: loss 4.369907
[epoch19, step369]: loss 1.060675
[epoch19, step370]: loss 0.831831
[epoch19, step371]: loss 2.875000
[epoch19, step372]: loss 1.693059
[epoch19, step373]: loss 0.617368
[epoch19, step374]: loss 16.873915
[epoch19, step375]: loss 1.275366
[epoch19, step376]: loss 1.199346
[epoch19, step377]: loss 0.617436
[epoch19, step378]: loss 3.155137
[epoch19, step379]: loss 0.673581
[epoch19, step380]: loss 2.588473
[epoch19, step381]: loss 0.840767
[epoch19, step382]: loss 0.795761
[epoch19, step383]: loss 1.863393
[epoch19, step384]: loss 1.347263
[epoch19, step385]: loss 2.281519
[epoch19, step386]: loss 2.847219
[epoch19, step387]: loss 2.883066
[epoch19, step388]: loss 7.544388
[epoch19, step389]: loss 0.735968
[epoch19, step390]: loss 3.709173
[epoch19, step391]: loss 0.626073
[epoch19, step392]: loss 23.989794
[epoch19, step393]: loss 8.173139
[epoch19, step394]: loss 3.416963
[epoch19, step395]: loss 9.734407
[epoch19, step396]: loss 2.300787
[epoch19, step397]: loss 0.548640
[epoch19, step398]: loss 9.810422
[epoch19, step399]: loss 1.758486
[epoch19, step400]: loss 31.238712
[epoch19, step401]: loss 1.663941
[epoch19, step402]: loss 4.338387
[epoch19, step403]: loss 5.988395
[epoch19, step404]: loss 1.742298
[epoch19, step405]: loss 0.994807
[epoch19, step406]: loss 0.944262
[epoch19, step407]: loss 1.934059
[epoch19, step408]: loss 0.877439
[epoch19, step409]: loss 2.001602
[epoch19, step410]: loss 8.180689
[epoch19, step411]: loss 5.844758
[epoch19, step412]: loss 2.110960
[epoch19, step413]: loss 0.922043
[epoch19, step414]: loss 5.625717
[epoch19, step415]: loss 0.592271
[epoch19, step416]: loss 1.254789
[epoch19, step417]: loss 7.391312
[epoch19, step418]: loss 0.979929
[epoch19, step419]: loss 3.282816
[epoch19, step420]: loss 1.331109
[epoch19, step421]: loss 8.201471
[epoch19, step422]: loss 13.200781
[epoch19, step423]: loss 1.033333
[epoch19, step424]: loss 0.969114
[epoch19, step425]: loss 0.516725
[epoch19, step426]: loss 1.861866
[epoch19, step427]: loss 9.366048
[epoch19, step428]: loss 13.900881
[epoch19, step429]: loss 15.694965
[epoch19, step430]: loss 1.679916
[epoch19, step431]: loss 1.158203
[epoch19, step432]: loss 3.004641
[epoch19, step433]: loss 1.982630
[epoch19, step434]: loss 16.634453
[epoch19, step435]: loss 1.160674
[epoch19, step436]: loss 9.304508
[epoch19, step437]: loss 1.164983
[epoch19, step438]: loss 1.066337
[epoch19, step439]: loss 2.378828
[epoch19, step440]: loss 3.109638
[epoch19, step441]: loss 15.344537
[epoch19, step442]: loss 1.277640
[epoch19, step443]: loss 0.875224
[epoch19, step444]: loss 9.529938
[epoch19, step445]: loss 9.349595
[epoch19, step446]: loss 4.456769
[epoch19, step447]: loss 0.639886
[epoch19, step448]: loss 38.167313
[epoch19, step449]: loss 6.271695
[epoch19, step450]: loss 2.759615
[epoch19, step451]: loss 1.776868
[epoch19, step452]: loss 1.102950
[epoch19, step453]: loss 1.573834
[epoch19, step454]: loss 0.593308
[epoch19, step455]: loss 1.508060
[epoch19, step456]: loss 1.028980
[epoch19, step457]: loss 2.158731
[epoch19, step458]: loss 5.411782
[epoch19, step459]: loss 1.248761
[epoch19, step460]: loss 0.554730
[epoch19, step461]: loss 9.285781
[epoch19, step462]: loss 1.339843
[epoch19, step463]: loss 0.752277
[epoch19, step464]: loss 0.572919
[epoch19, step465]: loss 1.767319
[epoch19, step466]: loss 2.693217
[epoch19, step467]: loss 5.184222
[epoch19, step468]: loss 2.705226
[epoch19, step469]: loss 1.790507
[epoch19, step470]: loss 5.637022
[epoch19, step471]: loss 0.927041
[epoch19, step472]: loss 1.485392
[epoch19, step473]: loss 6.356572
[epoch19, step474]: loss 0.686561
[epoch19, step475]: loss 1.492505
[epoch19, step476]: loss 1.112396
[epoch19, step477]: loss 0.724386
[epoch19, step478]: loss 2.164196
[epoch19, step479]: loss 9.405470
[epoch19, step480]: loss 0.841852
[epoch19, step481]: loss 1.019363
[epoch19, step482]: loss 0.938795
[epoch19, step483]: loss 7.221486
[epoch19, step484]: loss 3.658047
[epoch19, step485]: loss 4.308018
[epoch19, step486]: loss 0.556800
[epoch19, step487]: loss 1.227691
[epoch19, step488]: loss 0.416789
[epoch19, step489]: loss 1.740649
[epoch19, step490]: loss 3.745160
[epoch19, step491]: loss 11.635426
[epoch19, step492]: loss 1.502262
[epoch19, step493]: loss 1.110963
[epoch19, step494]: loss 2.744273
[epoch19, step495]: loss 0.438076
[epoch19, step496]: loss 1.921166
[epoch19, step497]: loss 1.617497
[epoch19, step498]: loss 1.272416
[epoch19, step499]: loss 1.153684
[epoch19, step500]: loss 0.736086
[epoch19, step501]: loss 4.241317
[epoch19, step502]: loss 0.840099
[epoch19, step503]: loss 2.699103
[epoch19, step504]: loss 1.203131
[epoch19, step505]: loss 0.554029
[epoch19, step506]: loss 2.608645
[epoch19, step507]: loss 6.014268
[epoch19, step508]: loss 10.934921
[epoch19, step509]: loss 10.644773
[epoch19, step510]: loss 0.871783
[epoch19, step511]: loss 7.207739
[epoch19, step512]: loss 2.237949
[epoch19, step513]: loss 1.435121
[epoch19, step514]: loss 1.975676
[epoch19, step515]: loss 0.870245
[epoch19, step516]: loss 1.362996
[epoch19, step517]: loss 8.419575
[epoch19, step518]: loss 0.581013
[epoch19, step519]: loss 5.352958
[epoch19, step520]: loss 13.485887
[epoch19, step521]: loss 1.249104
[epoch19, step522]: loss 2.940507
[epoch19, step523]: loss 0.806041
[epoch19, step524]: loss 2.892079
[epoch19, step525]: loss 1.064788
[epoch19, step526]: loss 16.213724
[epoch19, step527]: loss 0.516916
[epoch19, step528]: loss 8.587990
[epoch19, step529]: loss 1.756762
[epoch19, step530]: loss 0.649706
[epoch19, step531]: loss 1.636570
[epoch19, step532]: loss 1.150768
[epoch19, step533]: loss 1.296864
[epoch19, step534]: loss 0.594377
[epoch19, step535]: loss 5.756619
[epoch19, step536]: loss 0.778751
[epoch19, step537]: loss 0.920739
[epoch19, step538]: loss 8.930864
[epoch19, step539]: loss 1.389874
[epoch19, step540]: loss 12.649671
[epoch19, step541]: loss 0.895034
[epoch19, step542]: loss 3.824442
[epoch19, step543]: loss 0.550010
[epoch19, step544]: loss 0.935512
[epoch19, step545]: loss 1.014584
[epoch19, step546]: loss 10.897420
[epoch19, step547]: loss 3.944025
[epoch19, step548]: loss 0.521618
[epoch19, step549]: loss 1.238390
[epoch19, step550]: loss 2.427145
[epoch19, step551]: loss 1.160760
[epoch19, step552]: loss 2.285048
[epoch19, step553]: loss 0.620133
[epoch19, step554]: loss 0.752649
[epoch19, step555]: loss 1.210496
[epoch19, step556]: loss 1.541463
[epoch19, step557]: loss 4.680178
[epoch19, step558]: loss 0.868204
[epoch19, step559]: loss 6.083678
[epoch19, step560]: loss 1.403946
[epoch19, step561]: loss 0.741373
[epoch19, step562]: loss 10.663301
[epoch19, step563]: loss 4.797647
[epoch19, step564]: loss 10.112471
[epoch19, step565]: loss 2.027487
[epoch19, step566]: loss 4.356544
[epoch19, step567]: loss 0.555434
[epoch19, step568]: loss 6.642559
[epoch19, step569]: loss 27.154858
[epoch19, step570]: loss 0.730481
[epoch19, step571]: loss 1.880470
[epoch19, step572]: loss 1.247821
[epoch19, step573]: loss 0.869239
[epoch19, step574]: loss 2.537123
[epoch19, step575]: loss 7.553918
[epoch19, step576]: loss 1.712066
[epoch19, step577]: loss 5.488331
[epoch19, step578]: loss 1.222567
[epoch19, step579]: loss 13.024060
[epoch19, step580]: loss 5.805996
[epoch19, step581]: loss 1.815794
[epoch19, step582]: loss 0.761643
[epoch19, step583]: loss 8.934219
[epoch19, step584]: loss 7.211631
[epoch19, step585]: loss 7.820097
[epoch19, step586]: loss 1.131214
[epoch19, step587]: loss 1.271652
[epoch19, step588]: loss 1.852527
[epoch19, step589]: loss 1.444571
[epoch19, step590]: loss 1.978638
[epoch19, step591]: loss 0.818788
[epoch19, step592]: loss 1.592823
[epoch19, step593]: loss 3.181293
[epoch19, step594]: loss 2.408641
[epoch19, step595]: loss 0.982511
[epoch19, step596]: loss 0.965000
[epoch19, step597]: loss 0.728372
[epoch19, step598]: loss 1.198700
[epoch19, step599]: loss 1.548651
[epoch19, step600]: loss 1.411841
[epoch19, step601]: loss 0.998412
[epoch19, step602]: loss 0.429595
[epoch19, step603]: loss 3.695737
[epoch19, step604]: loss 2.085193
[epoch19, step605]: loss 10.995098
[epoch19, step606]: loss 10.658010
[epoch19, step607]: loss 0.542620
[epoch19, step608]: loss 1.151440
[epoch19, step609]: loss 1.167335
[epoch19, step610]: loss 2.247537
[epoch19, step611]: loss 0.771896
[epoch19, step612]: loss 3.183072
[epoch19, step613]: loss 0.928667
[epoch19, step614]: loss 0.902265
[epoch19, step615]: loss 1.404411
[epoch19, step616]: loss 3.312054
[epoch19, step617]: loss 1.469064
[epoch19, step618]: loss 1.176391
[epoch19, step619]: loss 8.602846
[epoch19, step620]: loss 0.810607
[epoch19, step621]: loss 2.610755
[epoch19, step622]: loss 0.756308
[epoch19, step623]: loss 5.238874
[epoch19, step624]: loss 0.727681
[epoch19, step625]: loss 1.322979
[epoch19, step626]: loss 1.184562
[epoch19, step627]: loss 1.858335
[epoch19, step628]: loss 1.437969
[epoch19, step629]: loss 1.290236
[epoch19, step630]: loss 0.786559
[epoch19, step631]: loss 2.222836
[epoch19, step632]: loss 1.556089
[epoch19, step633]: loss 5.286678
[epoch19, step634]: loss 1.872586
[epoch19, step635]: loss 1.007233
[epoch19, step636]: loss 0.631122
[epoch19, step637]: loss 1.198416
[epoch19, step638]: loss 1.785483
[epoch19, step639]: loss 1.169545
[epoch19, step640]: loss 1.138745
[epoch19, step641]: loss 0.848679
[epoch19, step642]: loss 1.335020
[epoch19, step643]: loss 4.988910
[epoch19, step644]: loss 0.415725
[epoch19, step645]: loss 10.212451
[epoch19, step646]: loss 0.860500
[epoch19, step647]: loss 0.855698
[epoch19, step648]: loss 0.938007
[epoch19, step649]: loss 1.508775
[epoch19, step650]: loss 6.949030
[epoch19, step651]: loss 0.923183
[epoch19, step652]: loss 1.351397
[epoch19, step653]: loss 1.008307
[epoch19, step654]: loss 9.121880
[epoch19, step655]: loss 3.112626
[epoch19, step656]: loss 0.797109
[epoch19, step657]: loss 2.815131
[epoch19, step658]: loss 0.587028
[epoch19, step659]: loss 15.666016
[epoch19, step660]: loss 1.576638
[epoch19, step661]: loss 0.755904
[epoch19, step662]: loss 3.392454
[epoch19, step663]: loss 1.059925
[epoch19, step664]: loss 1.719776
[epoch19, step665]: loss 6.317163
[epoch19, step666]: loss 0.561791
[epoch19, step667]: loss 0.554591
[epoch19, step668]: loss 3.005086
[epoch19, step669]: loss 1.230434
[epoch19, step670]: loss 0.848365
[epoch19, step671]: loss 1.703124
[epoch19, step672]: loss 2.476261
[epoch19, step673]: loss 0.985888
[epoch19, step674]: loss 0.641842
[epoch19, step675]: loss 2.074085
[epoch19, step676]: loss 0.524787
[epoch19, step677]: loss 2.065943
[epoch19, step678]: loss 8.237380
[epoch19, step679]: loss 0.851964
[epoch19, step680]: loss 0.649506
[epoch19, step681]: loss 2.167244
[epoch19, step682]: loss 10.166438
[epoch19, step683]: loss 0.801522
[epoch19, step684]: loss 1.204751
[epoch19, step685]: loss 2.338206
[epoch19, step686]: loss 0.827352
[epoch19, step687]: loss 1.444134
[epoch19, step688]: loss 0.732431
[epoch19, step689]: loss 7.466094
[epoch19, step690]: loss 2.478916
[epoch19, step691]: loss 0.788133
[epoch19, step692]: loss 2.917677
[epoch19, step693]: loss 29.628067
[epoch19, step694]: loss 6.631339
[epoch19, step695]: loss 4.179974
[epoch19, step696]: loss 4.596552
[epoch19, step697]: loss 2.088239
[epoch19, step698]: loss 2.023489
[epoch19, step699]: loss 1.308205
[epoch19, step700]: loss 0.687997
[epoch19, step701]: loss 1.598714
[epoch19, step702]: loss 0.623881
[epoch19, step703]: loss 10.296385
[epoch19, step704]: loss 0.801475
[epoch19, step705]: loss 1.765793
[epoch19, step706]: loss 11.433779
[epoch19, step707]: loss 1.139348
[epoch19, step708]: loss 2.283661
[epoch19, step709]: loss 9.002288
[epoch19, step710]: loss 1.269194
[epoch19, step711]: loss 0.854820
[epoch19, step712]: loss 1.147578
[epoch19, step713]: loss 4.322909
[epoch19, step714]: loss 0.682773
[epoch19, step715]: loss 20.623997
[epoch19, step716]: loss 2.239543
[epoch19, step717]: loss 0.792577
[epoch19, step718]: loss 1.903260
[epoch19, step719]: loss 0.763088
[epoch19, step720]: loss 1.036457
[epoch19, step721]: loss 0.850525
[epoch19, step722]: loss 1.318524
[epoch19, step723]: loss 1.056455
[epoch19, step724]: loss 3.193903
[epoch19, step725]: loss 3.278524
[epoch19, step726]: loss 1.065328
[epoch19, step727]: loss 1.258386
[epoch19, step728]: loss 4.193783
[epoch19, step729]: loss 1.110662
[epoch19, step730]: loss 3.460281
[epoch19, step731]: loss 0.732806
[epoch19, step732]: loss 12.685299
[epoch19, step733]: loss 8.168384
[epoch19, step734]: loss 0.871789
[epoch19, step735]: loss 1.820776
[epoch19, step736]: loss 0.954261
[epoch19, step737]: loss 1.134644
[epoch19, step738]: loss 1.717975
[epoch19, step739]: loss 9.633432
[epoch19, step740]: loss 4.546463
[epoch19, step741]: loss 0.594436
[epoch19, step742]: loss 4.277860
[epoch19, step743]: loss 7.510788
[epoch19, step744]: loss 2.389819
[epoch19, step745]: loss 1.688702
[epoch19, step746]: loss 3.000885
[epoch19, step747]: loss 12.171329
[epoch19, step748]: loss 2.471000
[epoch19, step749]: loss 13.451975
[epoch19, step750]: loss 7.902338
[epoch19, step751]: loss 2.386514
[epoch19, step752]: loss 0.683288
[epoch19, step753]: loss 1.158993
[epoch19, step754]: loss 10.010906
[epoch19, step755]: loss 0.967559
[epoch19, step756]: loss 1.497182
[epoch19, step757]: loss 0.882105
[epoch19, step758]: loss 3.228896
[epoch19, step759]: loss 9.777241
[epoch19, step760]: loss 1.572869
[epoch19, step761]: loss 1.171923
[epoch19, step762]: loss 3.133357
[epoch19, step763]: loss 9.387541
[epoch19, step764]: loss 17.430120
[epoch19, step765]: loss 5.940591
[epoch19, step766]: loss 6.641285
[epoch19, step767]: loss 1.827944
[epoch19, step768]: loss 6.794266
[epoch19, step769]: loss 1.348259
[epoch19, step770]: loss 7.952516
[epoch19, step771]: loss 1.598700
[epoch19, step772]: loss 0.371658
[epoch19, step773]: loss 0.758782
[epoch19, step774]: loss 5.189395
[epoch19, step775]: loss 8.093564
[epoch19, step776]: loss 4.336357
[epoch19, step777]: loss 0.864463
[epoch19, step778]: loss 4.457887
[epoch19, step779]: loss 1.644392
[epoch19, step780]: loss 6.052515
[epoch19, step781]: loss 7.055037
[epoch19, step782]: loss 0.778421
[epoch19, step783]: loss 1.577195
[epoch19, step784]: loss 1.180474
[epoch19, step785]: loss 9.052778
[epoch19, step786]: loss 1.949082
[epoch19, step787]: loss 20.252132
[epoch19, step788]: loss 6.662262
[epoch19, step789]: loss 1.391413
[epoch19, step790]: loss 17.050911
[epoch19, step791]: loss 10.242561
[epoch19, step792]: loss 3.282830
[epoch19, step793]: loss 1.016734
[epoch19, step794]: loss 6.754999
[epoch19, step795]: loss 0.643754
[epoch19, step796]: loss 0.948570
[epoch19, step797]: loss 1.686674
[epoch19, step798]: loss 7.420348
[epoch19, step799]: loss 1.581993
[epoch19, step800]: loss 0.878189
[epoch19, step801]: loss 0.846088
[epoch19, step802]: loss 0.913130
[epoch19, step803]: loss 0.798319
[epoch19, step804]: loss 0.845333
[epoch19, step805]: loss 1.209389
[epoch19, step806]: loss 10.199263
[epoch19, step807]: loss 1.027818
[epoch19, step808]: loss 0.651983
[epoch19, step809]: loss 8.493988
[epoch19, step810]: loss 1.027051
[epoch19, step811]: loss 3.922085
[epoch19, step812]: loss 7.886385
[epoch19, step813]: loss 1.863127
[epoch19, step814]: loss 8.333193
[epoch19, step815]: loss 1.896715
[epoch19, step816]: loss 1.162252
[epoch19, step817]: loss 1.940104
[epoch19, step818]: loss 10.582626
[epoch19, step819]: loss 0.868369
[epoch19, step820]: loss 3.086204
[epoch19, step821]: loss 3.428384
[epoch19, step822]: loss 3.798422
[epoch19, step823]: loss 1.831480
[epoch19, step824]: loss 10.440583
[epoch19, step825]: loss 1.637787
[epoch19, step826]: loss 13.480160
[epoch19, step827]: loss 4.129529
[epoch19, step828]: loss 8.225106
[epoch19, step829]: loss 0.561637
[epoch19, step830]: loss 1.229685
[epoch19, step831]: loss 2.531561
[epoch19, step832]: loss 1.891723
[epoch19, step833]: loss 1.708656
[epoch19, step834]: loss 1.050209
[epoch19, step835]: loss 1.329862
[epoch19, step836]: loss 1.082737
[epoch19, step837]: loss 0.668478
[epoch19, step838]: loss 1.564674
[epoch19, step839]: loss 7.548515
[epoch19, step840]: loss 7.032085
[epoch19, step841]: loss 7.580042
[epoch19, step842]: loss 10.825012
[epoch19, step843]: loss 3.654308
[epoch19, step844]: loss 1.052925
[epoch19, step845]: loss 5.831697
[epoch19, step846]: loss 2.880660
[epoch19, step847]: loss 0.808336
[epoch19, step848]: loss 1.581386
[epoch19, step849]: loss 1.462852
[epoch19, step850]: loss 1.982958
[epoch19, step851]: loss 0.566287
[epoch19, step852]: loss 2.765567
[epoch19, step853]: loss 0.787176
[epoch19, step854]: loss 11.591132
[epoch19, step855]: loss 1.052032
[epoch19, step856]: loss 3.559009
[epoch19, step857]: loss 3.055253
[epoch19, step858]: loss 1.282200
[epoch19, step859]: loss 15.464461
[epoch19, step860]: loss 9.717065
[epoch19, step861]: loss 0.621167
[epoch19, step862]: loss 10.315358
[epoch19, step863]: loss 1.152050
[epoch19, step864]: loss 8.566099
[epoch19, step865]: loss 1.478257
[epoch19, step866]: loss 0.690767
[epoch19, step867]: loss 1.141137
[epoch19, step868]: loss 0.933685
[epoch19, step869]: loss 3.265018
[epoch19, step870]: loss 3.449371
[epoch19, step871]: loss 1.926557
[epoch19, step872]: loss 4.774355
[epoch19, step873]: loss 1.968531
[epoch19, step874]: loss 1.448194
[epoch19, step875]: loss 1.631657
[epoch19, step876]: loss 1.597502
[epoch19, step877]: loss 2.167230
[epoch19, step878]: loss 1.308816
[epoch19, step879]: loss 1.054047
[epoch19, step880]: loss 0.621071
[epoch19, step881]: loss 15.124170
[epoch19, step882]: loss 3.594555
[epoch19, step883]: loss 4.687462
[epoch19, step884]: loss 15.384562
[epoch19, step885]: loss 1.397398
[epoch19, step886]: loss 11.757578
[epoch19, step887]: loss 1.971373
[epoch19, step888]: loss 1.485336
[epoch19, step889]: loss 1.258135
[epoch19, step890]: loss 0.676133
[epoch19, step891]: loss 1.254011
[epoch19, step892]: loss 0.852113
[epoch19, step893]: loss 2.659882
[epoch19, step894]: loss 19.440430
[epoch19, step895]: loss 1.448517
[epoch19, step896]: loss 0.928977
[epoch19, step897]: loss 0.976936
[epoch19, step898]: loss 1.426763
[epoch19, step899]: loss 1.185734
[epoch19, step900]: loss 1.374020
[epoch19, step901]: loss 6.874483
[epoch19, step902]: loss 16.501425
[epoch19, step903]: loss 0.942536
[epoch19, step904]: loss 0.930476
[epoch19, step905]: loss 13.016863
[epoch19, step906]: loss 0.697609
[epoch19, step907]: loss 1.859578
[epoch19, step908]: loss 11.015848
[epoch19, step909]: loss 3.223213
[epoch19, step910]: loss 4.670261
[epoch19, step911]: loss 1.487910
[epoch19, step912]: loss 1.385111
[epoch19, step913]: loss 1.167931
[epoch19, step914]: loss 0.707480
[epoch19, step915]: loss 2.281303
[epoch19, step916]: loss 1.018556
[epoch19, step917]: loss 1.726512
[epoch19, step918]: loss 1.937757
[epoch19, step919]: loss 3.131716
[epoch19, step920]: loss 10.873195
[epoch19, step921]: loss 0.875605
[epoch19, step922]: loss 4.585385
[epoch19, step923]: loss 1.135841
[epoch19, step924]: loss 1.781921
[epoch19, step925]: loss 1.133351
[epoch19, step926]: loss 2.276435
[epoch19, step927]: loss 1.014823
[epoch19, step928]: loss 6.998561
[epoch19, step929]: loss 0.516881
[epoch19, step930]: loss 2.567325
[epoch19, step931]: loss 4.056474
[epoch19, step932]: loss 1.094594
[epoch19, step933]: loss 0.647315
[epoch19, step934]: loss 3.788604
[epoch19, step935]: loss 8.136993
[epoch19, step936]: loss 1.295200
[epoch19, step937]: loss 0.823713
[epoch19, step938]: loss 2.109361
[epoch19, step939]: loss 0.699644
[epoch19, step940]: loss 1.252438
[epoch19, step941]: loss 1.957041
[epoch19, step942]: loss 0.575383
[epoch19, step943]: loss 1.658995
[epoch19, step944]: loss 1.402467
[epoch19, step945]: loss 0.711841
[epoch19, step946]: loss 7.580502
[epoch19, step947]: loss 1.595339
[epoch19, step948]: loss 1.049878
[epoch19, step949]: loss 6.671558
[epoch19, step950]: loss 9.122257
[epoch19, step951]: loss 1.244174
[epoch19, step952]: loss 2.665286
[epoch19, step953]: loss 4.355521
[epoch19, step954]: loss 0.793694
[epoch19, step955]: loss 1.910833
[epoch19, step956]: loss 0.590165
[epoch19, step957]: loss 11.628356
[epoch19, step958]: loss 5.225247
[epoch19, step959]: loss 1.350052
[epoch19, step960]: loss 3.079168
[epoch19, step961]: loss 8.187278
[epoch19, step962]: loss 1.029769
[epoch19, step963]: loss 0.925180
[epoch19, step964]: loss 0.965484
[epoch19, step965]: loss 8.937130
[epoch19, step966]: loss 0.871525
[epoch19, step967]: loss 4.718563
[epoch19, step968]: loss 5.031230
[epoch19, step969]: loss 1.491724
[epoch19, step970]: loss 0.891572
[epoch19, step971]: loss 25.019064
[epoch19, step972]: loss 0.984465
[epoch19, step973]: loss 3.682431
[epoch19, step974]: loss 8.853621
[epoch19, step975]: loss 8.813840
[epoch19, step976]: loss 5.656445
[epoch19, step977]: loss 6.423573
[epoch19, step978]: loss 1.676463
[epoch19, step979]: loss 3.235142
[epoch19, step980]: loss 2.430343
[epoch19, step981]: loss 2.930602
[epoch19, step982]: loss 4.322499
[epoch19, step983]: loss 1.207638
[epoch19, step984]: loss 1.167990
[epoch19, step985]: loss 1.301792
[epoch19, step986]: loss 1.202625
[epoch19, step987]: loss 5.696428
[epoch19, step988]: loss 0.758565
[epoch19, step989]: loss 2.006773
[epoch19, step990]: loss 2.734652
[epoch19, step991]: loss 0.664297
[epoch19, step992]: loss 0.629606
[epoch19, step993]: loss 0.968790
[epoch19, step994]: loss 1.797382
[epoch19, step995]: loss 30.751537
[epoch19, step996]: loss 2.103434
[epoch19, step997]: loss 1.502139
[epoch19, step998]: loss 8.163918
[epoch19, step999]: loss 2.744201
[epoch19, step1000]: loss 4.469322
[epoch19, step1001]: loss 0.705552
[epoch19, step1002]: loss 1.586474
[epoch19, step1003]: loss 1.482192
[epoch19, step1004]: loss 0.726821
[epoch19, step1005]: loss 5.753637
[epoch19, step1006]: loss 12.285936
[epoch19, step1007]: loss 0.684002
[epoch19, step1008]: loss 1.911578
[epoch19, step1009]: loss 0.899211
[epoch19, step1010]: loss 1.846592
[epoch19, step1011]: loss 0.475151
[epoch19, step1012]: loss 1.749655
[epoch19, step1013]: loss 3.723591
[epoch19, step1014]: loss 0.857245
[epoch19, step1015]: loss 2.359097
[epoch19, step1016]: loss 0.721849
[epoch19, step1017]: loss 0.959865
[epoch19, step1018]: loss 0.679156
[epoch19, step1019]: loss 11.600199
[epoch19, step1020]: loss 1.170905
[epoch19, step1021]: loss 11.043593
[epoch19, step1022]: loss 0.782077
[epoch19, step1023]: loss 2.233303
[epoch19, step1024]: loss 2.696584
[epoch19, step1025]: loss 0.531403
[epoch19, step1026]: loss 11.690680
[epoch19, step1027]: loss 0.831382
[epoch19, step1028]: loss 7.953131
[epoch19, step1029]: loss 1.147244
[epoch19, step1030]: loss 3.138614
[epoch19, step1031]: loss 1.727046
[epoch19, step1032]: loss 3.480808
[epoch19, step1033]: loss 8.701071
[epoch19, step1034]: loss 0.995266
[epoch19, step1035]: loss 1.912558
[epoch19, step1036]: loss 3.010765
[epoch19, step1037]: loss 1.204753
[epoch19, step1038]: loss 4.353780
[epoch19, step1039]: loss 0.940318
[epoch19, step1040]: loss 5.111837
[epoch19, step1041]: loss 0.861559
[epoch19, step1042]: loss 1.161214
[epoch19, step1043]: loss 0.968257
[epoch19, step1044]: loss 0.912368
[epoch19, step1045]: loss 2.871865
[epoch19, step1046]: loss 0.592873
[epoch19, step1047]: loss 2.824439
[epoch19, step1048]: loss 0.649072
[epoch19, step1049]: loss 0.821728
[epoch19, step1050]: loss 5.139162
[epoch19, step1051]: loss 13.832354
[epoch19, step1052]: loss 1.302079
[epoch19, step1053]: loss 1.769675
[epoch19, step1054]: loss 2.870777
[epoch19, step1055]: loss 1.347412
[epoch19, step1056]: loss 4.191628
[epoch19, step1057]: loss 1.908601
[epoch19, step1058]: loss 0.603671
[epoch19, step1059]: loss 1.378090
[epoch19, step1060]: loss 5.928370
[epoch19, step1061]: loss 1.035092
[epoch19, step1062]: loss 1.707832
[epoch19, step1063]: loss 1.365793
[epoch19, step1064]: loss 2.031571
[epoch19, step1065]: loss 2.723981
[epoch19, step1066]: loss 2.920259
[epoch19, step1067]: loss 2.954149
[epoch19, step1068]: loss 0.695008
[epoch19, step1069]: loss 0.718887
[epoch19, step1070]: loss 1.007188
[epoch19, step1071]: loss 1.233148
[epoch19, step1072]: loss 0.500432
[epoch19, step1073]: loss 9.193787
[epoch19, step1074]: loss 8.195267
[epoch19, step1075]: loss 6.941455
[epoch19, step1076]: loss 0.799004
[epoch19, step1077]: loss 2.233845
[epoch19, step1078]: loss 1.063803
[epoch19, step1079]: loss 5.649822
[epoch19, step1080]: loss 0.824632
[epoch19, step1081]: loss 2.588559
[epoch19, step1082]: loss 1.044564
[epoch19, step1083]: loss 4.504953
[epoch19, step1084]: loss 3.780795
[epoch19, step1085]: loss 1.341545
[epoch19, step1086]: loss 0.630923
[epoch19, step1087]: loss 1.012121
[epoch19, step1088]: loss 0.951502
[epoch19, step1089]: loss 1.337619
[epoch19, step1090]: loss 1.571527
[epoch19, step1091]: loss 2.304026
[epoch19, step1092]: loss 0.867123
[epoch19, step1093]: loss 6.259821
[epoch19, step1094]: loss 6.378847
[epoch19, step1095]: loss 10.868624
[epoch19, step1096]: loss 2.105459
[epoch19, step1097]: loss 1.957463
[epoch19, step1098]: loss 7.507693
[epoch19, step1099]: loss 0.550824
[epoch19, step1100]: loss 1.087273
[epoch19, step1101]: loss 0.885911
[epoch19, step1102]: loss 1.096853
[epoch19, step1103]: loss 0.834212
[epoch19, step1104]: loss 2.438029
[epoch19, step1105]: loss 2.715468
[epoch19, step1106]: loss 0.793513
[epoch19, step1107]: loss 0.871224
[epoch19, step1108]: loss 2.810353
[epoch19, step1109]: loss 0.858339
[epoch19, step1110]: loss 1.142741
[epoch19, step1111]: loss 0.781764
[epoch19, step1112]: loss 4.115982
[epoch19, step1113]: loss 8.352935
[epoch19, step1114]: loss 2.392831
[epoch19, step1115]: loss 1.226508
[epoch19, step1116]: loss 1.082193
[epoch19, step1117]: loss 0.953756
[epoch19, step1118]: loss 2.553664
[epoch19, step1119]: loss 15.767159
[epoch19, step1120]: loss 0.893144
[epoch19, step1121]: loss 2.719480
[epoch19, step1122]: loss 1.345144
[epoch19, step1123]: loss 0.685662
[epoch19, step1124]: loss 1.210128
[epoch19, step1125]: loss 1.503776
[epoch19, step1126]: loss 4.222285
[epoch19, step1127]: loss 3.727402
[epoch19, step1128]: loss 0.958220
[epoch19, step1129]: loss 0.817446
[epoch19, step1130]: loss 5.936385
[epoch19, step1131]: loss 2.870383
[epoch19, step1132]: loss 0.924549
[epoch19, step1133]: loss 7.841925
[epoch19, step1134]: loss 12.065497
[epoch19, step1135]: loss 1.513285
[epoch19, step1136]: loss 0.831380
[epoch19, step1137]: loss 9.090748
[epoch19, step1138]: loss 1.695510
[epoch19, step1139]: loss 5.081044
[epoch19, step1140]: loss 0.782510
[epoch19, step1141]: loss 0.782003
[epoch19, step1142]: loss 2.153092
[epoch19, step1143]: loss 1.268269
[epoch19, step1144]: loss 1.021547
[epoch19, step1145]: loss 1.163561
[epoch19, step1146]: loss 1.708943
[epoch19, step1147]: loss 1.756459
[epoch19, step1148]: loss 1.914859
[epoch19, step1149]: loss 8.589452
[epoch19, step1150]: loss 0.901130
[epoch19, step1151]: loss 7.636648
[epoch19, step1152]: loss 4.267242
[epoch19, step1153]: loss 2.241248
[epoch19, step1154]: loss 4.807393
[epoch19, step1155]: loss 3.198963
[epoch19, step1156]: loss 3.986443
[epoch19, step1157]: loss 0.891927
[epoch19, step1158]: loss 0.708222
[epoch19, step1159]: loss 5.094337
[epoch19, step1160]: loss 0.762909
[epoch19, step1161]: loss 1.308056
[epoch19, step1162]: loss 1.019255
[epoch19, step1163]: loss 9.145670
[epoch19, step1164]: loss 7.198787
[epoch19, step1165]: loss 0.903185
[epoch19, step1166]: loss 11.440539
[epoch19, step1167]: loss 1.244078
[epoch19, step1168]: loss 0.942341
[epoch19, step1169]: loss 0.766013
[epoch19, step1170]: loss 1.314767
[epoch19, step1171]: loss 1.373582
[epoch19, step1172]: loss 0.916594
[epoch19, step1173]: loss 1.730260
[epoch19, step1174]: loss 3.087241
[epoch19, step1175]: loss 2.581860
[epoch19, step1176]: loss 8.498180
[epoch19, step1177]: loss 1.467811
[epoch19, step1178]: loss 1.933465
[epoch19, step1179]: loss 0.905951
[epoch19, step1180]: loss 0.989747
[epoch19, step1181]: loss 0.751435
[epoch19, step1182]: loss 0.698550
[epoch19, step1183]: loss 3.634037
[epoch19, step1184]: loss 12.313349
[epoch19, step1185]: loss 1.004572
[epoch19, step1186]: loss 1.402740
[epoch19, step1187]: loss 0.557313
[epoch19, step1188]: loss 1.552006
[epoch19, step1189]: loss 1.816632
[epoch19, step1190]: loss 0.739283
[epoch19, step1191]: loss 1.965783
[epoch19, step1192]: loss 1.149111
[epoch19, step1193]: loss 0.793800
[epoch19, step1194]: loss 5.958343
[epoch19, step1195]: loss 1.207135
[epoch19, step1196]: loss 5.371868
[epoch19, step1197]: loss 0.957606
[epoch19, step1198]: loss 1.418170
[epoch19, step1199]: loss 0.738980
[epoch19, step1200]: loss 1.383590
[epoch19, step1201]: loss 1.656366
[epoch19, step1202]: loss 3.091976
[epoch19, step1203]: loss 1.149961
[epoch19, step1204]: loss 3.332966
[epoch19, step1205]: loss 18.403624
[epoch19, step1206]: loss 6.610485
[epoch19, step1207]: loss 0.775712
[epoch19, step1208]: loss 1.345585
[epoch19, step1209]: loss 0.563037
[epoch19, step1210]: loss 0.655881
[epoch19, step1211]: loss 0.635408
[epoch19, step1212]: loss 7.130891
[epoch19, step1213]: loss 0.786531
[epoch19, step1214]: loss 9.173593
[epoch19, step1215]: loss 9.085895
[epoch19, step1216]: loss 0.654257
[epoch19, step1217]: loss 7.200813
[epoch19, step1218]: loss 1.413851
[epoch19, step1219]: loss 3.378708
[epoch19, step1220]: loss 1.260824
[epoch19, step1221]: loss 2.147072
[epoch19, step1222]: loss 0.764255
[epoch19, step1223]: loss 0.784411
[epoch19, step1224]: loss 1.186425
[epoch19, step1225]: loss 0.787707
[epoch19, step1226]: loss 1.143259
[epoch19, step1227]: loss 1.707113
[epoch19, step1228]: loss 8.475668
[epoch19, step1229]: loss 5.642245
[epoch19, step1230]: loss 0.497509
[epoch19, step1231]: loss 3.456735
[epoch19, step1232]: loss 1.128391
[epoch19, step1233]: loss 3.418809
[epoch19, step1234]: loss 1.825116
[epoch19, step1235]: loss 0.726729
[epoch19, step1236]: loss 0.829641
[epoch19, step1237]: loss 0.730573
[epoch19, step1238]: loss 0.948802
[epoch19, step1239]: loss 2.244563
[epoch19, step1240]: loss 4.472147
[epoch19, step1241]: loss 2.623879
[epoch19, step1242]: loss 1.484020
[epoch19, step1243]: loss 15.822559
[epoch19, step1244]: loss 2.625366
[epoch19, step1245]: loss 7.441111
[epoch19, step1246]: loss 1.381959
[epoch19, step1247]: loss 0.778801
[epoch19, step1248]: loss 5.033382
[epoch19, step1249]: loss 11.320154
[epoch19, step1250]: loss 3.460903
[epoch19, step1251]: loss 2.780444
[epoch19, step1252]: loss 2.344042
[epoch19, step1253]: loss 1.903173
[epoch19, step1254]: loss 4.681082
[epoch19, step1255]: loss 0.873947
[epoch19, step1256]: loss 1.180292
[epoch19, step1257]: loss 1.965249
[epoch19, step1258]: loss 1.806779
[epoch19, step1259]: loss 3.725642
[epoch19, step1260]: loss 1.213497
[epoch19, step1261]: loss 2.504931
[epoch19, step1262]: loss 4.239068
[epoch19, step1263]: loss 0.800882
[epoch19, step1264]: loss 5.878855
[epoch19, step1265]: loss 6.836189
[epoch19, step1266]: loss 1.475069
[epoch19, step1267]: loss 6.720713
[epoch19, step1268]: loss 0.706731
[epoch19, step1269]: loss 5.702586
[epoch19, step1270]: loss 1.658648
[epoch19, step1271]: loss 9.709818
[epoch19, step1272]: loss 1.980628
[epoch19, step1273]: loss 1.089985
[epoch19, step1274]: loss 1.204784
[epoch19, step1275]: loss 0.556173
[epoch19, step1276]: loss 9.469945
[epoch19, step1277]: loss 10.160636
[epoch19, step1278]: loss 1.825575
[epoch19, step1279]: loss 0.703847
[epoch19, step1280]: loss 1.042797
[epoch19, step1281]: loss 1.611411
[epoch19, step1282]: loss 8.117229
[epoch19, step1283]: loss 0.993473
[epoch19, step1284]: loss 6.838064
[epoch19, step1285]: loss 6.335154
[epoch19, step1286]: loss 1.624613
[epoch19, step1287]: loss 0.792536
[epoch19, step1288]: loss 4.021331
[epoch19, step1289]: loss 1.351889
[epoch19, step1290]: loss 1.225562
[epoch19, step1291]: loss 1.860065
[epoch19, step1292]: loss 1.287921
[epoch19, step1293]: loss 0.779523
[epoch19, step1294]: loss 3.908944
[epoch19, step1295]: loss 1.303034
[epoch19, step1296]: loss 1.032358
[epoch19, step1297]: loss 3.270472
[epoch19, step1298]: loss 0.529793
[epoch19, step1299]: loss 0.679625
[epoch19, step1300]: loss 0.938255
[epoch19, step1301]: loss 1.018528
[epoch19, step1302]: loss 2.136717
[epoch19, step1303]: loss 2.923482
[epoch19, step1304]: loss 0.878629
[epoch19, step1305]: loss 0.730507
[epoch19, step1306]: loss 1.500199
[epoch19, step1307]: loss 6.793080
[epoch19, step1308]: loss 6.244987
[epoch19, step1309]: loss 8.563606
[epoch19, step1310]: loss 3.019050
[epoch19, step1311]: loss 1.548679
[epoch19, step1312]: loss 0.639995
[epoch19, step1313]: loss 0.808700
[epoch19, step1314]: loss 1.180646
[epoch19, step1315]: loss 2.898332
[epoch19, step1316]: loss 0.950660
[epoch19, step1317]: loss 1.200377
[epoch19, step1318]: loss 1.010352
[epoch19, step1319]: loss 4.528778
[epoch19, step1320]: loss 0.926645
[epoch19, step1321]: loss 1.437267
[epoch19, step1322]: loss 1.864558
[epoch19, step1323]: loss 0.459033
[epoch19, step1324]: loss 0.822504
[epoch19, step1325]: loss 1.142979
[epoch19, step1326]: loss 3.393041
[epoch19, step1327]: loss 4.943876
[epoch19, step1328]: loss 1.320989
[epoch19, step1329]: loss 3.757734
[epoch19, step1330]: loss 0.928572
[epoch19, step1331]: loss 1.478218
[epoch19, step1332]: loss 7.782004
[epoch19, step1333]: loss 1.382398
[epoch19, step1334]: loss 3.863850
[epoch19, step1335]: loss 1.772171
[epoch19, step1336]: loss 1.369196
[epoch19, step1337]: loss 1.251540
[epoch19, step1338]: loss 1.011002
[epoch19, step1339]: loss 9.953240
[epoch19, step1340]: loss 4.356696
[epoch19, step1341]: loss 6.807660
[epoch19, step1342]: loss 1.299913
[epoch19, step1343]: loss 0.852820
[epoch19, step1344]: loss 13.480922
[epoch19, step1345]: loss 1.881534
[epoch19, step1346]: loss 16.080168
[epoch19, step1347]: loss 9.285891
[epoch19, step1348]: loss 6.199398
[epoch19, step1349]: loss 3.976822
[epoch19, step1350]: loss 8.464419
[epoch19, step1351]: loss 1.146918
[epoch19, step1352]: loss 3.209195
[epoch19, step1353]: loss 0.783855
[epoch19, step1354]: loss 1.103668
[epoch19, step1355]: loss 0.558708
[epoch19, step1356]: loss 7.885244
[epoch19, step1357]: loss 0.638487
[epoch19, step1358]: loss 0.550122
[epoch19, step1359]: loss 1.984030
[epoch19, step1360]: loss 1.183042
[epoch19, step1361]: loss 0.815100
[epoch19, step1362]: loss 2.084809
[epoch19, step1363]: loss 1.050382
[epoch19, step1364]: loss 1.268616
[epoch19, step1365]: loss 0.724406
[epoch19, step1366]: loss 2.239434
[epoch19, step1367]: loss 3.166399
[epoch19, step1368]: loss 1.139624
[epoch19, step1369]: loss 1.294157
[epoch19, step1370]: loss 3.232746
[epoch19, step1371]: loss 0.870652
[epoch19, step1372]: loss 1.284296
[epoch19, step1373]: loss 1.463886
[epoch19, step1374]: loss 1.606947
[epoch19, step1375]: loss 2.937081
[epoch19, step1376]: loss 2.750300
[epoch19, step1377]: loss 2.518090
[epoch19, step1378]: loss 0.774645
[epoch19, step1379]: loss 1.513673
[epoch19, step1380]: loss 1.189008
[epoch19, step1381]: loss 0.882592
[epoch19, step1382]: loss 0.850777
[epoch19, step1383]: loss 0.907947
[epoch19, step1384]: loss 1.551408
[epoch19, step1385]: loss 2.937360
[epoch19, step1386]: loss 1.292360
[epoch19, step1387]: loss 0.716454
[epoch19, step1388]: loss 0.759133
[epoch19, step1389]: loss 0.811432
[epoch19, step1390]: loss 0.642248
[epoch19, step1391]: loss 0.575645
[epoch19, step1392]: loss 1.534235
[epoch19, step1393]: loss 0.632151
[epoch19, step1394]: loss 3.337820
[epoch19, step1395]: loss 1.518174
[epoch19, step1396]: loss 1.535579
[epoch19, step1397]: loss 1.598406
[epoch19, step1398]: loss 9.443331
[epoch19, step1399]: loss 3.578457
[epoch19, step1400]: loss 3.306850
[epoch19, step1401]: loss 0.674975
[epoch19, step1402]: loss 2.738910
[epoch19, step1403]: loss 1.384828
[epoch19, step1404]: loss 1.322028
[epoch19, step1405]: loss 4.787283
[epoch19, step1406]: loss 1.163099
[epoch19, step1407]: loss 0.880016
[epoch19, step1408]: loss 0.731677
[epoch19, step1409]: loss 2.998719
[epoch19, step1410]: loss 1.769671
[epoch19, step1411]: loss 10.828981
[epoch19, step1412]: loss 0.885141
[epoch19, step1413]: loss 0.815675
[epoch19, step1414]: loss 0.951804
[epoch19, step1415]: loss 2.269808
[epoch19, step1416]: loss 1.199802
[epoch19, step1417]: loss 9.578359
[epoch19, step1418]: loss 2.769240
[epoch19, step1419]: loss 1.441397
[epoch19, step1420]: loss 1.410087
[epoch19, step1421]: loss 0.993753
[epoch19, step1422]: loss 6.230208
[epoch19, step1423]: loss 1.371317
[epoch19, step1424]: loss 2.948525
[epoch19, step1425]: loss 3.547028
[epoch19, step1426]: loss 11.850801
[epoch19, step1427]: loss 1.689049
[epoch19, step1428]: loss 1.262088
[epoch19, step1429]: loss 13.702102
[epoch19, step1430]: loss 3.807445
[epoch19, step1431]: loss 1.024738
[epoch19, step1432]: loss 5.860923
[epoch19, step1433]: loss 0.670004
[epoch19, step1434]: loss 9.234125
[epoch19, step1435]: loss 4.106378
[epoch19, step1436]: loss 0.905694
[epoch19, step1437]: loss 27.131750
[epoch19, step1438]: loss 1.688449
[epoch19, step1439]: loss 0.825797
[epoch19, step1440]: loss 0.874452
[epoch19, step1441]: loss 12.959967
[epoch19, step1442]: loss 1.903254
[epoch19, step1443]: loss 1.768379
[epoch19, step1444]: loss 1.823000
[epoch19, step1445]: loss 1.870107
[epoch19, step1446]: loss 2.618721
[epoch19, step1447]: loss 1.787289
[epoch19, step1448]: loss 0.918606
[epoch19, step1449]: loss 0.492314
[epoch19, step1450]: loss 3.564872
[epoch19, step1451]: loss 8.559003
[epoch19, step1452]: loss 10.024467
[epoch19, step1453]: loss 1.131323
[epoch19, step1454]: loss 2.280574
[epoch19, step1455]: loss 3.940523
[epoch19, step1456]: loss 2.118306
[epoch19, step1457]: loss 0.582522
[epoch19, step1458]: loss 3.424103
[epoch19, step1459]: loss 14.246617
[epoch19, step1460]: loss 5.661766
[epoch19, step1461]: loss 0.695736
[epoch19, step1462]: loss 16.072842
[epoch19, step1463]: loss 0.727872
[epoch19, step1464]: loss 16.134146
[epoch19, step1465]: loss 9.159572
[epoch19, step1466]: loss 0.924086
[epoch19, step1467]: loss 6.331142
[epoch19, step1468]: loss 9.281929
[epoch19, step1469]: loss 0.821469
[epoch19, step1470]: loss 2.495533
[epoch19, step1471]: loss 1.187804
[epoch19, step1472]: loss 0.632071
[epoch19, step1473]: loss 3.007796
[epoch19, step1474]: loss 15.973925
[epoch19, step1475]: loss 1.092398
[epoch19, step1476]: loss 1.337971
[epoch19, step1477]: loss 1.476766
[epoch19, step1478]: loss 2.427033
[epoch19, step1479]: loss 2.063616
[epoch19, step1480]: loss 0.558943
[epoch19, step1481]: loss 0.740035
[epoch19, step1482]: loss 2.499900
[epoch19, step1483]: loss 0.906467
[epoch19, step1484]: loss 8.985401
[epoch19, step1485]: loss 8.948766
[epoch19, step1486]: loss 0.817933
[epoch19, step1487]: loss 1.224928
[epoch19, step1488]: loss 0.923424
[epoch19, step1489]: loss 2.882919
[epoch19, step1490]: loss 1.045794
[epoch19, step1491]: loss 1.718170
[epoch19, step1492]: loss 10.555650
[epoch19, step1493]: loss 1.343987
[epoch19, step1494]: loss 0.741242
[epoch19, step1495]: loss 7.127027
[epoch19, step1496]: loss 0.555330
[epoch19, step1497]: loss 1.032858
[epoch19, step1498]: loss 8.033051
[epoch19, step1499]: loss 6.058700
[epoch19, step1500]: loss 2.043213
[epoch19, step1501]: loss 7.183231
[epoch19, step1502]: loss 1.782773
[epoch19, step1503]: loss 1.523847
[epoch19, step1504]: loss 0.708753
[epoch19, step1505]: loss 1.591892
[epoch19, step1506]: loss 6.319218
[epoch19, step1507]: loss 0.964252
[epoch19, step1508]: loss 1.202611
[epoch19, step1509]: loss 3.149501
[epoch19, step1510]: loss 4.010123
[epoch19, step1511]: loss 2.852335
[epoch19, step1512]: loss 5.177977
[epoch19, step1513]: loss 7.088306
[epoch19, step1514]: loss 0.835458
[epoch19, step1515]: loss 2.657136
[epoch19, step1516]: loss 1.973681
[epoch19, step1517]: loss 4.622292
[epoch19, step1518]: loss 2.146574
[epoch19, step1519]: loss 1.706354
[epoch19, step1520]: loss 1.224311
[epoch19, step1521]: loss 7.024901
[epoch19, step1522]: loss 0.670890
[epoch19, step1523]: loss 9.553688
[epoch19, step1524]: loss 1.909835
[epoch19, step1525]: loss 0.621397
[epoch19, step1526]: loss 2.639502
[epoch19, step1527]: loss 16.175814
[epoch19, step1528]: loss 0.871955
[epoch19, step1529]: loss 1.697631
[epoch19, step1530]: loss 1.511874
[epoch19, step1531]: loss 5.078450
[epoch19, step1532]: loss 0.642278
[epoch19, step1533]: loss 15.713719
[epoch19, step1534]: loss 2.560683
[epoch19, step1535]: loss 9.230189
[epoch19, step1536]: loss 3.963546
[epoch19, step1537]: loss 1.253485
[epoch19, step1538]: loss 2.987797
[epoch19, step1539]: loss 2.599111
[epoch19, step1540]: loss 0.542644
[epoch19, step1541]: loss 4.070152
[epoch19, step1542]: loss 1.122702
[epoch19, step1543]: loss 0.448133
[epoch19, step1544]: loss 8.169455
[epoch19, step1545]: loss 3.304522
[epoch19, step1546]: loss 3.690605
[epoch19, step1547]: loss 0.806855
[epoch19, step1548]: loss 2.647157
[epoch19, step1549]: loss 12.614052
[epoch19, step1550]: loss 9.546241
[epoch19, step1551]: loss 1.114104
[epoch19, step1552]: loss 0.823742
[epoch19, step1553]: loss 1.224653
[epoch19, step1554]: loss 13.385339
[epoch19, step1555]: loss 3.294129
[epoch19, step1556]: loss 1.111869
[epoch19, step1557]: loss 0.769329
[epoch19, step1558]: loss 0.652445
[epoch19, step1559]: loss 1.543155
[epoch19, step1560]: loss 1.372414
[epoch19, step1561]: loss 5.303293
[epoch19, step1562]: loss 4.813210
[epoch19, step1563]: loss 0.934243
[epoch19, step1564]: loss 2.364290
[epoch19, step1565]: loss 9.904451
[epoch19, step1566]: loss 0.754660
[epoch19, step1567]: loss 3.405907
[epoch19, step1568]: loss 0.669777
[epoch19, step1569]: loss 0.614984
[epoch19, step1570]: loss 1.460791
[epoch19, step1571]: loss 1.471460
[epoch19, step1572]: loss 1.804761
[epoch19, step1573]: loss 12.631237
[epoch19, step1574]: loss 2.051612
[epoch19, step1575]: loss 10.584737
[epoch19, step1576]: loss 0.808545
[epoch19, step1577]: loss 1.652682
[epoch19, step1578]: loss 2.105212
[epoch19, step1579]: loss 0.790918
[epoch19, step1580]: loss 2.209608
[epoch19, step1581]: loss 1.078626
[epoch19, step1582]: loss 7.508549
[epoch19, step1583]: loss 0.643804
[epoch19, step1584]: loss 10.832209
[epoch19, step1585]: loss 1.119301
[epoch19, step1586]: loss 1.804338
[epoch19, step1587]: loss 2.302911
[epoch19, step1588]: loss 1.160945
[epoch19, step1589]: loss 1.142168
[epoch19, step1590]: loss 18.946194
[epoch19, step1591]: loss 3.038376
[epoch19, step1592]: loss 1.007736
[epoch19, step1593]: loss 0.479336
[epoch19, step1594]: loss 1.716261
[epoch19, step1595]: loss 1.301175
[epoch19, step1596]: loss 5.765457
[epoch19, step1597]: loss 20.320816
[epoch19, step1598]: loss 0.961886
[epoch19, step1599]: loss 3.405704
[epoch19, step1600]: loss 4.281925
[epoch19, step1601]: loss 3.182560
[epoch19, step1602]: loss 11.167534
[epoch19, step1603]: loss 0.511507
[epoch19, step1604]: loss 9.409197
[epoch19, step1605]: loss 3.792701
[epoch19, step1606]: loss 1.133811
[epoch19, step1607]: loss 11.251410
[epoch19, step1608]: loss 1.510427
[epoch19, step1609]: loss 6.091696
[epoch19, step1610]: loss 1.623219
[epoch19, step1611]: loss 1.491672
[epoch19, step1612]: loss 3.236193
[epoch19, step1613]: loss 0.670571
[epoch19, step1614]: loss 8.734259
[epoch19, step1615]: loss 1.225058
[epoch19, step1616]: loss 2.068396
[epoch19, step1617]: loss 0.733069
[epoch19, step1618]: loss 0.752900
[epoch19, step1619]: loss 0.945547
[epoch19, step1620]: loss 0.984194
[epoch19, step1621]: loss 4.341323
[epoch19, step1622]: loss 6.894187
[epoch19, step1623]: loss 1.406306
[epoch19, step1624]: loss 1.017073
[epoch19, step1625]: loss 2.934088
[epoch19, step1626]: loss 0.778851
[epoch19, step1627]: loss 4.499701
[epoch19, step1628]: loss 2.594381
[epoch19, step1629]: loss 1.329602
[epoch19, step1630]: loss 1.103351
[epoch19, step1631]: loss 1.251740
[epoch19, step1632]: loss 6.210423
[epoch19, step1633]: loss 1.205792
[epoch19, step1634]: loss 4.196584
[epoch19, step1635]: loss 1.607549
[epoch19, step1636]: loss 1.971520
[epoch19, step1637]: loss 0.923362
[epoch19, step1638]: loss 6.490313
[epoch19, step1639]: loss 1.489588
[epoch19, step1640]: loss 4.935829
[epoch19, step1641]: loss 2.319378
[epoch19, step1642]: loss 1.093922
[epoch19, step1643]: loss 1.251221
[epoch19, step1644]: loss 4.940735
[epoch19, step1645]: loss 6.261990
[epoch19, step1646]: loss 4.611603
[epoch19, step1647]: loss 8.984928
[epoch19, step1648]: loss 11.122428
[epoch19, step1649]: loss 1.985853
[epoch19, step1650]: loss 2.312430
[epoch19, step1651]: loss 2.194875
[epoch19, step1652]: loss 1.898041
[epoch19, step1653]: loss 4.480233
[epoch19, step1654]: loss 17.679962
[epoch19, step1655]: loss 0.453088
[epoch19, step1656]: loss 3.676635
[epoch19, step1657]: loss 2.170633
[epoch19, step1658]: loss 1.623120
[epoch19, step1659]: loss 5.784106
[epoch19, step1660]: loss 2.066204
[epoch19, step1661]: loss 0.895528
[epoch19, step1662]: loss 1.719086
[epoch19, step1663]: loss 1.239517
[epoch19, step1664]: loss 2.430183
[epoch19, step1665]: loss 9.764267
[epoch19, step1666]: loss 2.215630
[epoch19, step1667]: loss 1.580246
[epoch19, step1668]: loss 0.739267
[epoch19, step1669]: loss 4.652125
[epoch19, step1670]: loss 12.433592
[epoch19, step1671]: loss 1.954309
[epoch19, step1672]: loss 0.986016
[epoch19, step1673]: loss 0.855545
[epoch19, step1674]: loss 1.015242
[epoch19, step1675]: loss 2.309563
[epoch19, step1676]: loss 1.111451
[epoch19, step1677]: loss 9.650039
[epoch19, step1678]: loss 1.001316
[epoch19, step1679]: loss 1.249675
[epoch19, step1680]: loss 1.096616
[epoch19, step1681]: loss 2.053919
[epoch19, step1682]: loss 0.733582
[epoch19, step1683]: loss 2.371870
[epoch19, step1684]: loss 1.204685
[epoch19, step1685]: loss 6.111395
[epoch19, step1686]: loss 1.266099
[epoch19, step1687]: loss 0.763500
[epoch19, step1688]: loss 0.882435
[epoch19, step1689]: loss 0.619491
[epoch19, step1690]: loss 0.490009
[epoch19, step1691]: loss 1.950003
[epoch19, step1692]: loss 1.433571
[epoch19, step1693]: loss 13.099155
[epoch19, step1694]: loss 1.485495
[epoch19, step1695]: loss 1.733364
[epoch19, step1696]: loss 1.168410
[epoch19, step1697]: loss 14.516670
[epoch19, step1698]: loss 0.897955
[epoch19, step1699]: loss 0.691150
[epoch19, step1700]: loss 9.970782
[epoch19, step1701]: loss 2.285561
[epoch19, step1702]: loss 7.300244
[epoch19, step1703]: loss 7.243707
[epoch19, step1704]: loss 0.484263
[epoch19, step1705]: loss 6.781996
[epoch19, step1706]: loss 1.080569
[epoch19, step1707]: loss 0.604850
[epoch19, step1708]: loss 1.439185
[epoch19, step1709]: loss 2.018903
[epoch19, step1710]: loss 0.793543
[epoch19, step1711]: loss 0.743018
[epoch19, step1712]: loss 3.029900
[epoch19, step1713]: loss 1.130701
[epoch19, step1714]: loss 0.710209
[epoch19, step1715]: loss 0.607690
[epoch19, step1716]: loss 4.045720
[epoch19, step1717]: loss 1.665064
[epoch19, step1718]: loss 0.941454
[epoch19, step1719]: loss 1.076856
[epoch19, step1720]: loss 0.635620
[epoch19, step1721]: loss 3.031240
[epoch19, step1722]: loss 1.310644
[epoch19, step1723]: loss 1.175946
[epoch19, step1724]: loss 1.686375
[epoch19, step1725]: loss 1.103797
[epoch19, step1726]: loss 0.876232
[epoch19, step1727]: loss 2.945852
[epoch19, step1728]: loss 5.351052
[epoch19, step1729]: loss 2.138743
[epoch19, step1730]: loss 0.605123
[epoch19, step1731]: loss 0.969981
[epoch19, step1732]: loss 6.499269
[epoch19, step1733]: loss 3.803609
[epoch19, step1734]: loss 1.267657
[epoch19, step1735]: loss 2.630499
[epoch19, step1736]: loss 1.261836
[epoch19, step1737]: loss 23.647547
[epoch19, step1738]: loss 1.207062
[epoch19, step1739]: loss 1.485183
[epoch19, step1740]: loss 14.413724
[epoch19, step1741]: loss 3.506063
[epoch19, step1742]: loss 8.477995
[epoch19, step1743]: loss 1.509796
[epoch19, step1744]: loss 1.012881
[epoch19, step1745]: loss 1.341740
[epoch19, step1746]: loss 1.451213
[epoch19, step1747]: loss 6.918982
[epoch19, step1748]: loss 0.928949
[epoch19, step1749]: loss 5.315804
[epoch19, step1750]: loss 2.478076
[epoch19, step1751]: loss 3.364764
[epoch19, step1752]: loss 1.148532
[epoch19, step1753]: loss 0.762811
[epoch19, step1754]: loss 2.469557
[epoch19, step1755]: loss 6.629089
[epoch19, step1756]: loss 24.958555
[epoch19, step1757]: loss 5.160602
[epoch19, step1758]: loss 1.030069
[epoch19, step1759]: loss 2.181640
[epoch19, step1760]: loss 0.769808
[epoch19, step1761]: loss 0.560099
[epoch19, step1762]: loss 1.526823
[epoch19, step1763]: loss 8.275978
[epoch19, step1764]: loss 15.884639
[epoch19, step1765]: loss 0.794105
[epoch19, step1766]: loss 1.297351
[epoch19, step1767]: loss 1.774461
[epoch19, step1768]: loss 2.113201
[epoch19, step1769]: loss 3.579609
[epoch19, step1770]: loss 1.249819
[epoch19, step1771]: loss 2.698859
[epoch19, step1772]: loss 1.147157
[epoch19, step1773]: loss 1.856651
[epoch19, step1774]: loss 0.665013
[epoch19, step1775]: loss 1.773400
[epoch19, step1776]: loss 1.106356
[epoch19, step1777]: loss 3.729166
[epoch19, step1778]: loss 0.885812
[epoch19, step1779]: loss 2.595661
[epoch19, step1780]: loss 2.133488
[epoch19, step1781]: loss 0.913860
[epoch19, step1782]: loss 0.579271
[epoch19, step1783]: loss 3.451283
[epoch19, step1784]: loss 1.252676
[epoch19, step1785]: loss 1.208281
[epoch19, step1786]: loss 1.917618
[epoch19, step1787]: loss 2.951134
[epoch19, step1788]: loss 0.496615
[epoch19, step1789]: loss 7.256044
[epoch19, step1790]: loss 0.992560
[epoch19, step1791]: loss 14.706166
[epoch19, step1792]: loss 3.939471
[epoch19, step1793]: loss 1.030582
[epoch19, step1794]: loss 0.823154
[epoch19, step1795]: loss 1.080607
[epoch19, step1796]: loss 2.484324
[epoch19, step1797]: loss 0.925414
[epoch19, step1798]: loss 1.295560
[epoch19, step1799]: loss 0.669932
[epoch19, step1800]: loss 1.475590
[epoch19, step1801]: loss 7.372513
[epoch19, step1802]: loss 5.462093
[epoch19, step1803]: loss 16.902163
[epoch19, step1804]: loss 7.668408
[epoch19, step1805]: loss 14.036583
[epoch19, step1806]: loss 2.352031
[epoch19, step1807]: loss 2.394426
[epoch19, step1808]: loss 2.191959
[epoch19, step1809]: loss 3.441862
[epoch19, step1810]: loss 0.640395
[epoch19, step1811]: loss 1.233066
[epoch19, step1812]: loss 1.370253
[epoch19, step1813]: loss 4.619029
[epoch19, step1814]: loss 1.007528
[epoch19, step1815]: loss 0.455472
[epoch19, step1816]: loss 1.083066
[epoch19, step1817]: loss 0.752081
[epoch19, step1818]: loss 0.846089
[epoch19, step1819]: loss 9.559116
[epoch19, step1820]: loss 1.985226
[epoch19, step1821]: loss 1.154876
[epoch19, step1822]: loss 1.793695
[epoch19, step1823]: loss 7.610326
[epoch19, step1824]: loss 5.746667
[epoch19, step1825]: loss 1.241455
[epoch19, step1826]: loss 1.931480
[epoch19, step1827]: loss 2.972916
[epoch19, step1828]: loss 1.059754
[epoch19, step1829]: loss 1.869617
[epoch19, step1830]: loss 8.605098
[epoch19, step1831]: loss 4.446379
[epoch19, step1832]: loss 2.437886
[epoch19, step1833]: loss 1.064723
[epoch19, step1834]: loss 0.829098
[epoch19, step1835]: loss 6.388933
[epoch19, step1836]: loss 0.928841
[epoch19, step1837]: loss 2.316172
[epoch19, step1838]: loss 2.979107
[epoch19, step1839]: loss 2.495075
[epoch19, step1840]: loss 1.049861
[epoch19, step1841]: loss 1.010113
[epoch19, step1842]: loss 8.288838
[epoch19, step1843]: loss 1.491882
[epoch19, step1844]: loss 12.221808
[epoch19, step1845]: loss 8.197297
[epoch19, step1846]: loss 0.742869
[epoch19, step1847]: loss 2.063548
[epoch19, step1848]: loss 0.807564
[epoch19, step1849]: loss 5.793381
[epoch19, step1850]: loss 6.686915
[epoch19, step1851]: loss 0.743192
[epoch19, step1852]: loss 0.559724
[epoch19, step1853]: loss 3.464313
[epoch19, step1854]: loss 0.802921
[epoch19, step1855]: loss 0.782783
[epoch19, step1856]: loss 1.044293
[epoch19, step1857]: loss 13.335337
[epoch19, step1858]: loss 1.055519
[epoch19, step1859]: loss 0.914156
[epoch19, step1860]: loss 0.725141
[epoch19, step1861]: loss 0.632142
[epoch19, step1862]: loss 13.715631
[epoch19, step1863]: loss 2.085542
[epoch19, step1864]: loss 10.768324
[epoch19, step1865]: loss 1.695269
[epoch19, step1866]: loss 1.454687
[epoch19, step1867]: loss 2.357687
[epoch19, step1868]: loss 2.159001
[epoch19, step1869]: loss 3.138193
[epoch19, step1870]: loss 1.848420
[epoch19, step1871]: loss 9.110329
[epoch19, step1872]: loss 2.795004
[epoch19, step1873]: loss 0.850412
[epoch19, step1874]: loss 0.583106
[epoch19, step1875]: loss 2.233921
[epoch19, step1876]: loss 1.332436
[epoch19, step1877]: loss 1.741665
[epoch19, step1878]: loss 3.324683
[epoch19, step1879]: loss 7.423694
[epoch19, step1880]: loss 4.913089
[epoch19, step1881]: loss 3.283041
[epoch19, step1882]: loss 2.389919
[epoch19, step1883]: loss 10.906370
[epoch19, step1884]: loss 4.613753
[epoch19, step1885]: loss 0.817450
[epoch19, step1886]: loss 4.752443
[epoch19, step1887]: loss 1.638466
[epoch19, step1888]: loss 1.668214
[epoch19, step1889]: loss 0.861330
[epoch19, step1890]: loss 0.670445
[epoch19, step1891]: loss 0.703320
[epoch19, step1892]: loss 9.151536
[epoch19, step1893]: loss 1.981108
[epoch19, step1894]: loss 4.897766
[epoch19, step1895]: loss 2.359693
[epoch19, step1896]: loss 3.482541
[epoch19, step1897]: loss 0.759534
[epoch19, step1898]: loss 4.028047
[epoch19, step1899]: loss 1.232432
[epoch19, step1900]: loss 4.259196
[epoch19, step1901]: loss 10.119181
[epoch19, step1902]: loss 1.596429
[epoch19, step1903]: loss 1.283665
[epoch19, step1904]: loss 16.189430
[epoch19, step1905]: loss 1.187680
[epoch19, step1906]: loss 2.568311
[epoch19, step1907]: loss 1.050468
[epoch19, step1908]: loss 7.019720
[epoch19, step1909]: loss 10.861818
[epoch19, step1910]: loss 1.150660
[epoch19, step1911]: loss 0.686745
[epoch19, step1912]: loss 7.467769
[epoch19, step1913]: loss 14.980376
[epoch19, step1914]: loss 0.801911
[epoch19, step1915]: loss 2.250256
[epoch19, step1916]: loss 1.394101
[epoch19, step1917]: loss 1.979576
[epoch19, step1918]: loss 0.741641
[epoch19, step1919]: loss 7.159386
[epoch19, step1920]: loss 8.440758
[epoch19, step1921]: loss 1.142783
[epoch19, step1922]: loss 0.652874
[epoch19, step1923]: loss 0.535389
[epoch19, step1924]: loss 1.335634
[epoch19, step1925]: loss 1.953695
[epoch19, step1926]: loss 1.427043
[epoch19, step1927]: loss 0.975449
[epoch19, step1928]: loss 1.546913
[epoch19, step1929]: loss 0.910708
[epoch19, step1930]: loss 0.676760
[epoch19, step1931]: loss 11.772925
[epoch19, step1932]: loss 2.392630
[epoch19, step1933]: loss 2.161763
[epoch19, step1934]: loss 5.542075
[epoch19, step1935]: loss 0.765868
[epoch19, step1936]: loss 1.412118
[epoch19, step1937]: loss 0.915394
[epoch19, step1938]: loss 2.827193
[epoch19, step1939]: loss 0.796551
[epoch19, step1940]: loss 5.361991
[epoch19, step1941]: loss 1.242338
[epoch19, step1942]: loss 1.590278
[epoch19, step1943]: loss 1.866366
[epoch19, step1944]: loss 7.737214
[epoch19, step1945]: loss 0.962850
[epoch19, step1946]: loss 5.689746
[epoch19, step1947]: loss 1.764513
[epoch19, step1948]: loss 2.452696
[epoch19, step1949]: loss 1.026343
[epoch19, step1950]: loss 5.317556
[epoch19, step1951]: loss 1.407820
[epoch19, step1952]: loss 9.248164
[epoch19, step1953]: loss 5.538251
[epoch19, step1954]: loss 8.775076
[epoch19, step1955]: loss 4.678632
[epoch19, step1956]: loss 10.607353
[epoch19, step1957]: loss 1.494542
[epoch19, step1958]: loss 1.937974
[epoch19, step1959]: loss 1.643008
[epoch19, step1960]: loss 2.140343
[epoch19, step1961]: loss 3.552547
[epoch19, step1962]: loss 2.904456
[epoch19, step1963]: loss 2.138569
[epoch19, step1964]: loss 1.818517
[epoch19, step1965]: loss 0.567141
[epoch19, step1966]: loss 3.347048
[epoch19, step1967]: loss 1.406061
[epoch19, step1968]: loss 15.673141
[epoch19, step1969]: loss 0.766986
[epoch19, step1970]: loss 1.471710
[epoch19, step1971]: loss 1.428239
[epoch19, step1972]: loss 8.987880
[epoch19, step1973]: loss 0.756449
[epoch19, step1974]: loss 0.569218
[epoch19, step1975]: loss 1.220591
[epoch19, step1976]: loss 2.152944
[epoch19, step1977]: loss 3.577171
[epoch19, step1978]: loss 4.311524
[epoch19, step1979]: loss 2.958635
[epoch19, step1980]: loss 0.710961
[epoch19, step1981]: loss 2.153843
[epoch19, step1982]: loss 1.462053
[epoch19, step1983]: loss 16.450136
[epoch19, step1984]: loss 2.125890
[epoch19, step1985]: loss 0.790496
[epoch19, step1986]: loss 3.588041
[epoch19, step1987]: loss 20.048613
[epoch19, step1988]: loss 9.837982
[epoch19, step1989]: loss 1.311445
[epoch19, step1990]: loss 0.928570
[epoch19, step1991]: loss 2.209481
[epoch19, step1992]: loss 7.945350
[epoch19, step1993]: loss 0.602332
[epoch19, step1994]: loss 1.661999
[epoch19, step1995]: loss 17.694550
[epoch19, step1996]: loss 1.593671
[epoch19, step1997]: loss 3.038801
[epoch19, step1998]: loss 2.003128
[epoch19, step1999]: loss 1.900771
[epoch19, step2000]: loss 7.104208
[epoch19, step2001]: loss 1.762787
[epoch19, step2002]: loss 0.796203
[epoch19, step2003]: loss 2.179332
[epoch19, step2004]: loss 18.811951
[epoch19, step2005]: loss 0.903789
[epoch19, step2006]: loss 1.372403
[epoch19, step2007]: loss 5.650676
[epoch19, step2008]: loss 24.355213
[epoch19, step2009]: loss 8.976460
[epoch19, step2010]: loss 0.877551
[epoch19, step2011]: loss 1.009920
[epoch19, step2012]: loss 0.566974
[epoch19, step2013]: loss 0.964076
[epoch19, step2014]: loss 7.197837
[epoch19, step2015]: loss 2.078764
[epoch19, step2016]: loss 15.992439
[epoch19, step2017]: loss 4.617435
[epoch19, step2018]: loss 0.841609
[epoch19, step2019]: loss 9.674923
[epoch19, step2020]: loss 1.155177
[epoch19, step2021]: loss 1.513853
[epoch19, step2022]: loss 1.037854
[epoch19, step2023]: loss 1.143785
[epoch19, step2024]: loss 8.652524
[epoch19, step2025]: loss 1.603870
[epoch19, step2026]: loss 5.531374
[epoch19, step2027]: loss 2.079915
[epoch19, step2028]: loss 8.998051
[epoch19, step2029]: loss 2.153820
[epoch19, step2030]: loss 1.474785
[epoch19, step2031]: loss 0.809761
[epoch19, step2032]: loss 0.527019
[epoch19, step2033]: loss 4.435264
[epoch19, step2034]: loss 2.185035
[epoch19, step2035]: loss 9.361144
[epoch19, step2036]: loss 5.291358
[epoch19, step2037]: loss 4.285612
[epoch19, step2038]: loss 2.617309
[epoch19, step2039]: loss 1.172808
[epoch19, step2040]: loss 1.390506
[epoch19, step2041]: loss 1.036808
[epoch19, step2042]: loss 2.931832
[epoch19, step2043]: loss 0.711291
[epoch19, step2044]: loss 1.130273
[epoch19, step2045]: loss 5.338239
[epoch19, step2046]: loss 1.271402
[epoch19, step2047]: loss 2.512123
[epoch19, step2048]: loss 2.639636
[epoch19, step2049]: loss 0.740494
[epoch19, step2050]: loss 1.474545
[epoch19, step2051]: loss 1.389931
[epoch19, step2052]: loss 0.355515
[epoch19, step2053]: loss 0.687538
[epoch19, step2054]: loss 11.433752
[epoch19, step2055]: loss 3.007268
[epoch19, step2056]: loss 0.805910
[epoch19, step2057]: loss 0.882578
[epoch19, step2058]: loss 3.416254
[epoch19, step2059]: loss 0.681623
[epoch19, step2060]: loss 8.315974
[epoch19, step2061]: loss 1.995094
[epoch19, step2062]: loss 1.518624
[epoch19, step2063]: loss 7.131723
[epoch19, step2064]: loss 0.738314
[epoch19, step2065]: loss 0.865710
[epoch19, step2066]: loss 1.422911
[epoch19, step2067]: loss 2.256499
[epoch19, step2068]: loss 7.999781
[epoch19, step2069]: loss 1.340317
[epoch19, step2070]: loss 6.648569
[epoch19, step2071]: loss 1.048757
[epoch19, step2072]: loss 2.032009
[epoch19, step2073]: loss 11.110927
[epoch19, step2074]: loss 1.942465
[epoch19, step2075]: loss 1.562979
[epoch19, step2076]: loss 1.318713
[epoch19, step2077]: loss 0.622343
[epoch19, step2078]: loss 1.509963
[epoch19, step2079]: loss 2.932672
[epoch19, step2080]: loss 0.736346
[epoch19, step2081]: loss 1.784677
[epoch19, step2082]: loss 0.609314
[epoch19, step2083]: loss 3.822694
[epoch19, step2084]: loss 0.715569
[epoch19, step2085]: loss 1.020070
[epoch19, step2086]: loss 0.961232
[epoch19, step2087]: loss 1.298226
[epoch19, step2088]: loss 0.880788
[epoch19, step2089]: loss 1.646621
[epoch19, step2090]: loss 6.191833
[epoch19, step2091]: loss 2.327310
[epoch19, step2092]: loss 1.604322
[epoch19, step2093]: loss 1.588075
[epoch19, step2094]: loss 4.315615
[epoch19, step2095]: loss 2.308174
[epoch19, step2096]: loss 3.430003
[epoch19, step2097]: loss 0.576477
[epoch19, step2098]: loss 1.955547
[epoch19, step2099]: loss 1.155877
[epoch19, step2100]: loss 1.337292
[epoch19, step2101]: loss 24.292114
[epoch19, step2102]: loss 1.470280
[epoch19, step2103]: loss 8.730831
[epoch19, step2104]: loss 4.332723
[epoch19, step2105]: loss 3.755541
[epoch19, step2106]: loss 1.771988
[epoch19, step2107]: loss 17.090250
[epoch19, step2108]: loss 1.015970
[epoch19, step2109]: loss 1.141990
[epoch19, step2110]: loss 0.691887
[epoch19, step2111]: loss 0.854895
[epoch19, step2112]: loss 1.345966
[epoch19, step2113]: loss 1.119693
[epoch19, step2114]: loss 5.475365
[epoch19, step2115]: loss 2.254091
[epoch19, step2116]: loss 2.717564
[epoch19, step2117]: loss 1.598803
[epoch19, step2118]: loss 4.732090
[epoch19, step2119]: loss 2.944846
[epoch19, step2120]: loss 9.645747
[epoch19, step2121]: loss 2.816200
[epoch19, step2122]: loss 1.256812
[epoch19, step2123]: loss 1.976865
[epoch19, step2124]: loss 0.644042
[epoch19, step2125]: loss 0.626577
[epoch19, step2126]: loss 0.854282
[epoch19, step2127]: loss 0.485010
[epoch19, step2128]: loss 1.323373
[epoch19, step2129]: loss 2.416627
[epoch19, step2130]: loss 0.897806
[epoch19, step2131]: loss 3.068495
[epoch19, step2132]: loss 4.093918
[epoch19, step2133]: loss 0.696692
[epoch19, step2134]: loss 19.931383
[epoch19, step2135]: loss 0.719391
[epoch19, step2136]: loss 5.412253
[epoch19, step2137]: loss 2.767462
[epoch19, step2138]: loss 14.625027
[epoch19, step2139]: loss 0.621881
[epoch19, step2140]: loss 2.004277
[epoch19, step2141]: loss 1.362710
[epoch19, step2142]: loss 3.661385
[epoch19, step2143]: loss 1.309176
[epoch19, step2144]: loss 12.531590
[epoch19, step2145]: loss 1.837841
[epoch19, step2146]: loss 2.017255
[epoch19, step2147]: loss 0.794286
[epoch19, step2148]: loss 1.144668
[epoch19, step2149]: loss 2.011625
[epoch19, step2150]: loss 4.202833
[epoch19, step2151]: loss 1.075299
[epoch19, step2152]: loss 1.022183
[epoch19, step2153]: loss 2.439862
[epoch19, step2154]: loss 1.059045
[epoch19, step2155]: loss 1.585572
[epoch19, step2156]: loss 2.139363
[epoch19, step2157]: loss 1.077363
[epoch19, step2158]: loss 2.230605
[epoch19, step2159]: loss 1.254355
[epoch19, step2160]: loss 1.562753
[epoch19, step2161]: loss 12.284370
[epoch19, step2162]: loss 10.637189
[epoch19, step2163]: loss 3.846954
[epoch19, step2164]: loss 2.108594
[epoch19, step2165]: loss 9.350408
[epoch19, step2166]: loss 1.712639
[epoch19, step2167]: loss 1.967211
[epoch19, step2168]: loss 3.307473
[epoch19, step2169]: loss 10.149650
[epoch19, step2170]: loss 1.932224
[epoch19, step2171]: loss 2.475703
[epoch19, step2172]: loss 0.805396
[epoch19, step2173]: loss 1.448158
[epoch19, step2174]: loss 1.292544
[epoch19, step2175]: loss 10.391816
[epoch19, step2176]: loss 1.053110
[epoch19, step2177]: loss 1.122111
[epoch19, step2178]: loss 0.762237
[epoch19, step2179]: loss 1.038718
[epoch19, step2180]: loss 1.042785
[epoch19, step2181]: loss 3.067640
[epoch19, step2182]: loss 3.137843
[epoch19, step2183]: loss 0.518565
[epoch19, step2184]: loss 1.449796
[epoch19, step2185]: loss 2.425485
[epoch19, step2186]: loss 7.158309
[epoch19, step2187]: loss 6.289551
[epoch19, step2188]: loss 12.488470
[epoch19, step2189]: loss 2.873857
[epoch19, step2190]: loss 1.016368
[epoch19, step2191]: loss 4.623832
[epoch19, step2192]: loss 3.773258
[epoch19, step2193]: loss 1.563816
[epoch19, step2194]: loss 1.004721
[epoch19, step2195]: loss 1.965521
[epoch19, step2196]: loss 1.227838
[epoch19, step2197]: loss 1.886048
[epoch19, step2198]: loss 0.845034
[epoch19, step2199]: loss 4.561089
[epoch19, step2200]: loss 1.511819
[epoch19, step2201]: loss 7.630034
[epoch19, step2202]: loss 1.655647
[epoch19, step2203]: loss 1.575034
[epoch19, step2204]: loss 3.709605
[epoch19, step2205]: loss 2.477970
[epoch19, step2206]: loss 9.165669
[epoch19, step2207]: loss 0.780962
[epoch19, step2208]: loss 0.912582
[epoch19, step2209]: loss 2.000581
[epoch19, step2210]: loss 0.725210
[epoch19, step2211]: loss 0.740671
[epoch19, step2212]: loss 3.051828
[epoch19, step2213]: loss 6.013351
[epoch19, step2214]: loss 5.524301
[epoch19, step2215]: loss 2.592295
[epoch19, step2216]: loss 1.196086
[epoch19, step2217]: loss 19.616961
[epoch19, step2218]: loss 3.523346
[epoch19, step2219]: loss 0.593152
[epoch19, step2220]: loss 3.552776
[epoch19, step2221]: loss 6.592165
[epoch19, step2222]: loss 0.775571
[epoch19, step2223]: loss 0.918439
[epoch19, step2224]: loss 5.996728
[epoch19, step2225]: loss 0.663063
[epoch19, step2226]: loss 4.102330
[epoch19, step2227]: loss 1.109880
[epoch19, step2228]: loss 1.038575
[epoch19, step2229]: loss 0.850690
[epoch19, step2230]: loss 15.339257
[epoch19, step2231]: loss 8.762415
[epoch19, step2232]: loss 13.145709
[epoch19, step2233]: loss 0.754512
[epoch19, step2234]: loss 2.615153
[epoch19, step2235]: loss 10.094591
[epoch19, step2236]: loss 0.510376
[epoch19, step2237]: loss 1.209451
[epoch19, step2238]: loss 2.982625
[epoch19, step2239]: loss 2.648024
[epoch19, step2240]: loss 4.513615
[epoch19, step2241]: loss 8.632883
[epoch19, step2242]: loss 9.766899
[epoch19, step2243]: loss 0.709918
[epoch19, step2244]: loss 16.973642
[epoch19, step2245]: loss 0.636370
[epoch19, step2246]: loss 0.779936
[epoch19, step2247]: loss 1.277622
[epoch19, step2248]: loss 6.251996
[epoch19, step2249]: loss 8.789419
[epoch19, step2250]: loss 1.292028
[epoch19, step2251]: loss 7.416408
[epoch19, step2252]: loss 4.569177
[epoch19, step2253]: loss 1.084375
[epoch19, step2254]: loss 3.251550
[epoch19, step2255]: loss 3.917874
[epoch19, step2256]: loss 0.749807
[epoch19, step2257]: loss 0.673551
[epoch19, step2258]: loss 0.744287
[epoch19, step2259]: loss 1.274354
[epoch19, step2260]: loss 1.960111
[epoch19, step2261]: loss 4.519754
[epoch19, step2262]: loss 1.058765
[epoch19, step2263]: loss 6.995754
[epoch19, step2264]: loss 2.354742
[epoch19, step2265]: loss 7.733454
[epoch19, step2266]: loss 1.036380
[epoch19, step2267]: loss 2.229925
[epoch19, step2268]: loss 0.789875
[epoch19, step2269]: loss 0.551404
[epoch19, step2270]: loss 2.056641
[epoch19, step2271]: loss 4.208913
[epoch19, step2272]: loss 1.632336
[epoch19, step2273]: loss 5.965482
[epoch19, step2274]: loss 3.090070
[epoch19, step2275]: loss 0.787326
[epoch19, step2276]: loss 1.677476
[epoch19, step2277]: loss 6.749402
[epoch19, step2278]: loss 2.947518
[epoch19, step2279]: loss 1.011941
[epoch19, step2280]: loss 1.541081
[epoch19, step2281]: loss 1.016005
[epoch19, step2282]: loss 0.930271
[epoch19, step2283]: loss 1.229631
[epoch19, step2284]: loss 7.892659
[epoch19, step2285]: loss 7.039643
[epoch19, step2286]: loss 3.486637
[epoch19, step2287]: loss 10.476451
[epoch19, step2288]: loss 5.378012
[epoch19, step2289]: loss 1.143262
[epoch19, step2290]: loss 1.296544
[epoch19, step2291]: loss 1.834122
[epoch19, step2292]: loss 2.706318
[epoch19, step2293]: loss 1.080576
[epoch19, step2294]: loss 3.028493
[epoch19, step2295]: loss 4.557520
[epoch19, step2296]: loss 1.579926
[epoch19, step2297]: loss 0.838636
[epoch19, step2298]: loss 26.787651
[epoch19, step2299]: loss 1.576375
[epoch19, step2300]: loss 1.790172
[epoch19, step2301]: loss 0.747612
[epoch19, step2302]: loss 1.431784
[epoch19, step2303]: loss 1.114564
[epoch19, step2304]: loss 1.084386
[epoch19, step2305]: loss 1.286041
[epoch19, step2306]: loss 2.786752
[epoch19, step2307]: loss 0.858648
[epoch19, step2308]: loss 0.868635
[epoch19, step2309]: loss 2.168563
[epoch19, step2310]: loss 0.953198
[epoch19, step2311]: loss 0.764266
[epoch19, step2312]: loss 1.027061
[epoch19, step2313]: loss 0.862800
[epoch19, step2314]: loss 9.318154
[epoch19, step2315]: loss 3.359597
[epoch19, step2316]: loss 15.771653
[epoch19, step2317]: loss 1.257235
[epoch19, step2318]: loss 1.511040
[epoch19, step2319]: loss 1.628205
[epoch19, step2320]: loss 2.372282
[epoch19, step2321]: loss 2.310217
[epoch19, step2322]: loss 0.805393
[epoch19, step2323]: loss 0.659890
[epoch19, step2324]: loss 0.815757
[epoch19, step2325]: loss 1.664329
[epoch19, step2326]: loss 1.675213
[epoch19, step2327]: loss 2.281395
[epoch19, step2328]: loss 0.778745
[epoch19, step2329]: loss 5.655887
[epoch19, step2330]: loss 0.550936
[epoch19, step2331]: loss 0.878536
[epoch19, step2332]: loss 0.675385
[epoch19, step2333]: loss 0.741719
[epoch19, step2334]: loss 0.642495
[epoch19, step2335]: loss 3.530552
[epoch19, step2336]: loss 0.864584
[epoch19, step2337]: loss 0.748054
[epoch19, step2338]: loss 5.511127
[epoch19, step2339]: loss 5.977551
[epoch19, step2340]: loss 1.138018
[epoch19, step2341]: loss 2.377258
[epoch19, step2342]: loss 2.424724
[epoch19, step2343]: loss 0.518480
[epoch19, step2344]: loss 1.213162
[epoch19, step2345]: loss 4.162973
[epoch19, step2346]: loss 0.608648
[epoch19, step2347]: loss 3.206213
[epoch19, step2348]: loss 2.239974
[epoch19, step2349]: loss 9.327276
[epoch19, step2350]: loss 1.001010
[epoch19, step2351]: loss 2.265567
[epoch19, step2352]: loss 1.222185
[epoch19, step2353]: loss 8.156456
[epoch19, step2354]: loss 0.865568
[epoch19, step2355]: loss 0.828258
[epoch19, step2356]: loss 0.802205
[epoch19, step2357]: loss 1.144623
[epoch19, step2358]: loss 0.576815
[epoch19, step2359]: loss 6.929397
[epoch19, step2360]: loss 2.290331
[epoch19, step2361]: loss 0.907946
[epoch19, step2362]: loss 0.693398
[epoch19, step2363]: loss 1.668972
[epoch19, step2364]: loss 4.332744
[epoch19, step2365]: loss 5.793907
[epoch19, step2366]: loss 3.608880
[epoch19, step2367]: loss 10.792863
[epoch19, step2368]: loss 3.422735
[epoch19, step2369]: loss 1.194029
[epoch19, step2370]: loss 1.268446
[epoch19, step2371]: loss 1.280832
[epoch19, step2372]: loss 2.087656
[epoch19, step2373]: loss 2.002560
[epoch19, step2374]: loss 0.855500
[epoch19, step2375]: loss 0.905599
[epoch19, step2376]: loss 1.794920
[epoch19, step2377]: loss 3.141419
[epoch19, step2378]: loss 1.548763
[epoch19, step2379]: loss 0.633676
[epoch19, step2380]: loss 1.822430
[epoch19, step2381]: loss 6.213997
[epoch19, step2382]: loss 1.285453
[epoch19, step2383]: loss 1.187786
[epoch19, step2384]: loss 20.741133
[epoch19, step2385]: loss 7.605387
[epoch19, step2386]: loss 0.501439
[epoch19, step2387]: loss 3.044957
[epoch19, step2388]: loss 2.148226
[epoch19, step2389]: loss 0.807701
[epoch19, step2390]: loss 0.596094
[epoch19, step2391]: loss 3.113116
[epoch19, step2392]: loss 16.840895
[epoch19, step2393]: loss 2.336596
[epoch19, step2394]: loss 15.725433
[epoch19, step2395]: loss 0.911240
[epoch19, step2396]: loss 1.248617
[epoch19, step2397]: loss 0.821687
[epoch19, step2398]: loss 1.507724
[epoch19, step2399]: loss 0.639234
[epoch19, step2400]: loss 2.091675
[epoch19, step2401]: loss 0.967394
[epoch19, step2402]: loss 1.029990
[epoch19, step2403]: loss 1.027369
[epoch19, step2404]: loss 0.701558
[epoch19, step2405]: loss 2.358416
[epoch19, step2406]: loss 3.031853
[epoch19, step2407]: loss 1.308179
[epoch19, step2408]: loss 1.046437
[epoch19, step2409]: loss 1.542655
[epoch19, step2410]: loss 0.951097
[epoch19, step2411]: loss 0.890068
[epoch19, step2412]: loss 1.119347
[epoch19, step2413]: loss 2.909212
[epoch19, step2414]: loss 6.167582
[epoch19, step2415]: loss 1.448839
[epoch19, step2416]: loss 1.934882
[epoch19, step2417]: loss 3.992021
[epoch19, step2418]: loss 0.664272
[epoch19, step2419]: loss 0.884154
[epoch19, step2420]: loss 0.702174
[epoch19, step2421]: loss 5.356569
[epoch19, step2422]: loss 1.167905
[epoch19, step2423]: loss 1.521286
[epoch19, step2424]: loss 1.085766
[epoch19, step2425]: loss 0.777110
[epoch19, step2426]: loss 12.615522
[epoch19, step2427]: loss 0.750126
[epoch19, step2428]: loss 2.311254
[epoch19, step2429]: loss 1.688991
[epoch19, step2430]: loss 0.455832
[epoch19, step2431]: loss 1.244366
[epoch19, step2432]: loss 1.066437
[epoch19, step2433]: loss 2.269594
[epoch19, step2434]: loss 2.611767
[epoch19, step2435]: loss 4.503564
[epoch19, step2436]: loss 0.999743
[epoch19, step2437]: loss 0.571647
[epoch19, step2438]: loss 0.759414
[epoch19, step2439]: loss 1.039841
[epoch19, step2440]: loss 0.981628
[epoch19, step2441]: loss 1.224637
[epoch19, step2442]: loss 2.762937
[epoch19, step2443]: loss 1.141282
[epoch19, step2444]: loss 0.563008
[epoch19, step2445]: loss 2.937867
[epoch19, step2446]: loss 7.314352
[epoch19, step2447]: loss 0.636781
[epoch19, step2448]: loss 7.798743
[epoch19, step2449]: loss 9.730145
[epoch19, step2450]: loss 0.781791
[epoch19, step2451]: loss 1.566325
[epoch19, step2452]: loss 2.503817
[epoch19, step2453]: loss 0.745242
[epoch19, step2454]: loss 1.565028
[epoch19, step2455]: loss 1.782592
[epoch19, step2456]: loss 4.607099
[epoch19, step2457]: loss 8.524846
[epoch19, step2458]: loss 0.794421
[epoch19, step2459]: loss 0.949143
[epoch19, step2460]: loss 0.922435
[epoch19, step2461]: loss 4.019616
[epoch19, step2462]: loss 0.966217
[epoch19, step2463]: loss 0.797831
[epoch19, step2464]: loss 3.865427
[epoch19, step2465]: loss 5.683184
[epoch19, step2466]: loss 1.026774
[epoch19, step2467]: loss 2.422073
[epoch19, step2468]: loss 3.910858
[epoch19, step2469]: loss 3.349805
[epoch19, step2470]: loss 1.816275
[epoch19, step2471]: loss 3.960728
[epoch19, step2472]: loss 6.344376
[epoch19, step2473]: loss 16.272358
[epoch19, step2474]: loss 0.911170
[epoch19, step2475]: loss 1.642150
[epoch19, step2476]: loss 3.441226
[epoch19, step2477]: loss 1.170472
[epoch19, step2478]: loss 7.764124
[epoch19, step2479]: loss 1.408531
[epoch19, step2480]: loss 2.589423
[epoch19, step2481]: loss 14.163668
[epoch19, step2482]: loss 1.965253
[epoch19, step2483]: loss 2.125459
[epoch19, step2484]: loss 2.081191
[epoch19, step2485]: loss 0.890581
[epoch19, step2486]: loss 0.510474
[epoch19, step2487]: loss 0.421665
[epoch19, step2488]: loss 1.222009
[epoch19, step2489]: loss 2.354942
[epoch19, step2490]: loss 1.462622
[epoch19, step2491]: loss 1.102519
[epoch19, step2492]: loss 6.573880
[epoch19, step2493]: loss 0.701292
[epoch19, step2494]: loss 1.183178
[epoch19, step2495]: loss 1.134749
[epoch19, step2496]: loss 1.131965
[epoch19, step2497]: loss 5.855404
[epoch19, step2498]: loss 0.694166
[epoch19, step2499]: loss 2.937333
[epoch19, step2500]: loss 2.633671
[epoch19, step2501]: loss 16.168402
[epoch19, step2502]: loss 8.678946
[epoch19, step2503]: loss 12.904227
[epoch19, step2504]: loss 5.431728
[epoch19, step2505]: loss 0.834166
[epoch19, step2506]: loss 0.820949
[epoch19, step2507]: loss 0.991840
[epoch19, step2508]: loss 0.597988
[epoch19, step2509]: loss 1.285172
[epoch19, step2510]: loss 0.766776
[epoch19, step2511]: loss 11.801200
[epoch19, step2512]: loss 1.000805
[epoch19, step2513]: loss 0.847402
[epoch19, step2514]: loss 1.033428
[epoch19, step2515]: loss 12.594519
[epoch19, step2516]: loss 0.865956
[epoch19, step2517]: loss 1.002262
[epoch19, step2518]: loss 1.061167
[epoch19, step2519]: loss 1.693258
[epoch19, step2520]: loss 0.987746
[epoch19, step2521]: loss 1.656045
[epoch19, step2522]: loss 1.821036
[epoch19, step2523]: loss 3.904588
[epoch19, step2524]: loss 1.627271
[epoch19, step2525]: loss 1.399356
[epoch19, step2526]: loss 0.746288
[epoch19, step2527]: loss 6.717575
[epoch19, step2528]: loss 1.376786
[epoch19, step2529]: loss 0.835096
[epoch19, step2530]: loss 1.031307
[epoch19, step2531]: loss 1.951787
[epoch19, step2532]: loss 2.666903
[epoch19, step2533]: loss 1.100071
[epoch19, step2534]: loss 7.486221
[epoch19, step2535]: loss 1.522982
[epoch19, step2536]: loss 0.778258
[epoch19, step2537]: loss 0.802826
[epoch19, step2538]: loss 0.909373
[epoch19, step2539]: loss 0.591178
[epoch19, step2540]: loss 0.806332
[epoch19, step2541]: loss 0.963090
[epoch19, step2542]: loss 1.940460
[epoch19, step2543]: loss 0.951093
[epoch19, step2544]: loss 10.472341
[epoch19, step2545]: loss 0.547550
[epoch19, step2546]: loss 1.652754
[epoch19, step2547]: loss 1.219679
[epoch19, step2548]: loss 1.161731
[epoch19, step2549]: loss 1.133169
[epoch19, step2550]: loss 1.592927
[epoch19, step2551]: loss 1.127581
[epoch19, step2552]: loss 0.845852
[epoch19, step2553]: loss 10.920712
[epoch19, step2554]: loss 2.104650
[epoch19, step2555]: loss 14.673985
[epoch19, step2556]: loss 0.686086
[epoch19, step2557]: loss 1.160069
[epoch19, step2558]: loss 1.290574
[epoch19, step2559]: loss 1.218872
[epoch19, step2560]: loss 0.925176
[epoch19, step2561]: loss 0.971001
[epoch19, step2562]: loss 1.213549
[epoch19, step2563]: loss 1.690611
[epoch19, step2564]: loss 0.916072
[epoch19, step2565]: loss 1.046583
[epoch19, step2566]: loss 1.792621
[epoch19, step2567]: loss 10.546680
[epoch19, step2568]: loss 0.488347
[epoch19, step2569]: loss 3.306637
[epoch19, step2570]: loss 17.962074
[epoch19, step2571]: loss 1.029507
[epoch19, step2572]: loss 1.359128
[epoch19, step2573]: loss 0.911403
[epoch19, step2574]: loss 2.060632
[epoch19, step2575]: loss 4.016580
[epoch19, step2576]: loss 0.654206
[epoch19, step2577]: loss 1.159178
[epoch19, step2578]: loss 1.322317
[epoch19, step2579]: loss 0.608713
[epoch19, step2580]: loss 8.590522
[epoch19, step2581]: loss 2.025509
[epoch19, step2582]: loss 2.236134
[epoch19, step2583]: loss 4.422600
[epoch19, step2584]: loss 0.630088
[epoch19, step2585]: loss 1.730316
[epoch19, step2586]: loss 3.373237
[epoch19, step2587]: loss 1.086863
[epoch19, step2588]: loss 9.718941
[epoch19, step2589]: loss 0.719219
[epoch19, step2590]: loss 4.628874
[epoch19, step2591]: loss 1.260294
[epoch19, step2592]: loss 1.361063
[epoch19, step2593]: loss 4.062303
[epoch19, step2594]: loss 1.680494
[epoch19, step2595]: loss 3.632672
[epoch19, step2596]: loss 4.121900
[epoch19, step2597]: loss 6.760996
[epoch19, step2598]: loss 1.807015
[epoch19, step2599]: loss 0.831277
[epoch19, step2600]: loss 1.694592
[epoch19, step2601]: loss 1.379698
[epoch19, step2602]: loss 1.955055
[epoch19, step2603]: loss 3.363833
[epoch19, step2604]: loss 6.087517
[epoch19, step2605]: loss 5.186829
[epoch19, step2606]: loss 7.745022
[epoch19, step2607]: loss 1.085754
[epoch19, step2608]: loss 1.729648
[epoch19, step2609]: loss 1.038256
[epoch19, step2610]: loss 1.095821
[epoch19, step2611]: loss 10.201540
[epoch19, step2612]: loss 0.867657
[epoch19, step2613]: loss 1.602958
[epoch19, step2614]: loss 4.411994
[epoch19, step2615]: loss 1.287725
[epoch19, step2616]: loss 1.547442
[epoch19, step2617]: loss 8.014903
[epoch19, step2618]: loss 1.628159
[epoch19, step2619]: loss 27.837278
[epoch19, step2620]: loss 3.189081
[epoch19, step2621]: loss 1.058700
[epoch19, step2622]: loss 1.090676
[epoch19, step2623]: loss 1.876790
[epoch19, step2624]: loss 8.033070
[epoch19, step2625]: loss 0.523480
[epoch19, step2626]: loss 7.747196
[epoch19, step2627]: loss 0.862529
[epoch19, step2628]: loss 0.934399
[epoch19, step2629]: loss 1.517305
[epoch19, step2630]: loss 0.667036
[epoch19, step2631]: loss 1.301021
[epoch19, step2632]: loss 0.676392
[epoch19, step2633]: loss 1.235570
[epoch19, step2634]: loss 1.011643
[epoch19, step2635]: loss 2.101433
[epoch19, step2636]: loss 8.205583
[epoch19, step2637]: loss 2.256791
[epoch19, step2638]: loss 2.731083
[epoch19, step2639]: loss 0.651316
[epoch19, step2640]: loss 3.103400
[epoch19, step2641]: loss 5.619318
[epoch19, step2642]: loss 3.347673
[epoch19, step2643]: loss 2.906297
[epoch19, step2644]: loss 1.118320
[epoch19, step2645]: loss 0.766125
[epoch19, step2646]: loss 3.229681
[epoch19, step2647]: loss 0.801268
[epoch19, step2648]: loss 4.156038
[epoch19, step2649]: loss 0.575362
[epoch19, step2650]: loss 3.609915
[epoch19, step2651]: loss 6.023792
[epoch19, step2652]: loss 1.552206
[epoch19, step2653]: loss 5.871736
[epoch19, step2654]: loss 0.840995
[epoch19, step2655]: loss 3.350619
[epoch19, step2656]: loss 5.713637
[epoch19, step2657]: loss 10.407808
[epoch19, step2658]: loss 2.335928
[epoch19, step2659]: loss 0.920662
[epoch19, step2660]: loss 13.898168
[epoch19, step2661]: loss 2.628318
[epoch19, step2662]: loss 1.201588
[epoch19, step2663]: loss 1.017079
[epoch19, step2664]: loss 8.608654
[epoch19, step2665]: loss 2.437725
[epoch19, step2666]: loss 8.359942
[epoch19, step2667]: loss 0.578280
[epoch19, step2668]: loss 2.593512
[epoch19, step2669]: loss 1.232708
[epoch19, step2670]: loss 3.011886
[epoch19, step2671]: loss 5.960888
[epoch19, step2672]: loss 9.131727
[epoch19, step2673]: loss 0.799219
[epoch19, step2674]: loss 6.891068
[epoch19, step2675]: loss 1.873265
[epoch19, step2676]: loss 3.391061
[epoch19, step2677]: loss 2.747309
[epoch19, step2678]: loss 0.670160
[epoch19, step2679]: loss 3.025874
[epoch19, step2680]: loss 1.650521
[epoch19, step2681]: loss 6.108506
[epoch19, step2682]: loss 0.548682
[epoch19, step2683]: loss 6.912560
[epoch19, step2684]: loss 12.202668
[epoch19, step2685]: loss 2.833631
[epoch19, step2686]: loss 2.271502
[epoch19, step2687]: loss 2.684875
[epoch19, step2688]: loss 0.568220
[epoch19, step2689]: loss 2.022701
[epoch19, step2690]: loss 7.598297
[epoch19, step2691]: loss 0.817200
[epoch19, step2692]: loss 6.508994
[epoch19, step2693]: loss 0.788893
[epoch19, step2694]: loss 0.691590
[epoch19, step2695]: loss 1.642669
[epoch19, step2696]: loss 5.592043
[epoch19, step2697]: loss 1.130262
[epoch19, step2698]: loss 0.567034
[epoch19, step2699]: loss 4.200768
[epoch19, step2700]: loss 1.198219
[epoch19, step2701]: loss 38.857124
[epoch19, step2702]: loss 1.195325
[epoch19, step2703]: loss 8.277514
[epoch19, step2704]: loss 3.192827
[epoch19, step2705]: loss 4.643773
[epoch19, step2706]: loss 1.008884
[epoch19, step2707]: loss 0.967829
[epoch19, step2708]: loss 1.042063
[epoch19, step2709]: loss 2.256859
[epoch19, step2710]: loss 0.992065
[epoch19, step2711]: loss 2.051726
[epoch19, step2712]: loss 1.247660
[epoch19, step2713]: loss 2.547420
[epoch19, step2714]: loss 0.763130
[epoch19, step2715]: loss 1.033120
[epoch19, step2716]: loss 3.384242
[epoch19, step2717]: loss 2.681743
[epoch19, step2718]: loss 1.115326
[epoch19, step2719]: loss 1.057566
[epoch19, step2720]: loss 7.159896
[epoch19, step2721]: loss 3.000881
[epoch19, step2722]: loss 0.757109
[epoch19, step2723]: loss 2.730646
[epoch19, step2724]: loss 1.395097
[epoch19, step2725]: loss 4.964643
[epoch19, step2726]: loss 1.904231
[epoch19, step2727]: loss 1.227784
[epoch19, step2728]: loss 0.773323
[epoch19, step2729]: loss 0.739184
[epoch19, step2730]: loss 2.583694
[epoch19, step2731]: loss 9.470984
[epoch19, step2732]: loss 3.814248
[epoch19, step2733]: loss 0.767916
[epoch19, step2734]: loss 1.736818
[epoch19, step2735]: loss 0.962411
[epoch19, step2736]: loss 1.925742
[epoch19, step2737]: loss 4.842701
[epoch19, step2738]: loss 8.289349
[epoch19, step2739]: loss 0.857383
[epoch19, step2740]: loss 0.776336
[epoch19, step2741]: loss 1.659888
[epoch19, step2742]: loss 4.828907
[epoch19, step2743]: loss 1.128139
[epoch19, step2744]: loss 1.907496
[epoch19, step2745]: loss 1.698614
[epoch19, step2746]: loss 0.590117
[epoch19, step2747]: loss 0.846768
[epoch19, step2748]: loss 9.163261
[epoch19, step2749]: loss 0.768745
[epoch19, step2750]: loss 2.556062
[epoch19, step2751]: loss 1.459380
[epoch19, step2752]: loss 8.585139
[epoch19, step2753]: loss 7.726600
[epoch19, step2754]: loss 1.280545
[epoch19, step2755]: loss 4.262797
[epoch19, step2756]: loss 0.833721
[epoch19, step2757]: loss 1.409371
[epoch19, step2758]: loss 4.731173
[epoch19, step2759]: loss 7.602510
[epoch19, step2760]: loss 2.909553
[epoch19, step2761]: loss 1.197080
[epoch19, step2762]: loss 4.527920
[epoch19, step2763]: loss 27.911472
[epoch19, step2764]: loss 0.746398
[epoch19, step2765]: loss 1.529617
[epoch19, step2766]: loss 0.832597
[epoch19, step2767]: loss 0.754666
[epoch19, step2768]: loss 1.282637
[epoch19, step2769]: loss 0.727430
[epoch19, step2770]: loss 5.205678
[epoch19, step2771]: loss 0.757211
[epoch19, step2772]: loss 1.301127
[epoch19, step2773]: loss 1.537581
[epoch19, step2774]: loss 1.011586
[epoch19, step2775]: loss 10.077040
[epoch19, step2776]: loss 0.587708
[epoch19, step2777]: loss 7.768215
[epoch19, step2778]: loss 13.244641
[epoch19, step2779]: loss 2.351599
[epoch19, step2780]: loss 1.596376
[epoch19, step2781]: loss 1.448336
[epoch19, step2782]: loss 0.592232
[epoch19, step2783]: loss 1.386954
[epoch19, step2784]: loss 0.688493
[epoch19, step2785]: loss 11.413019
[epoch19, step2786]: loss 4.639066
[epoch19, step2787]: loss 0.829616
[epoch19, step2788]: loss 1.297767
[epoch19, step2789]: loss 7.338463
[epoch19, step2790]: loss 3.205982
[epoch19, step2791]: loss 1.180161
[epoch19, step2792]: loss 12.695899
[epoch19, step2793]: loss 0.639332
[epoch19, step2794]: loss 3.579067
[epoch19, step2795]: loss 0.763512
[epoch19, step2796]: loss 0.897938
[epoch19, step2797]: loss 1.220184
[epoch19, step2798]: loss 2.912081
[epoch19, step2799]: loss 0.952318
[epoch19, step2800]: loss 0.960527
[epoch19, step2801]: loss 3.282256
[epoch19, step2802]: loss 8.429379
[epoch19, step2803]: loss 0.552857
[epoch19, step2804]: loss 1.051019
[epoch19, step2805]: loss 6.135736
[epoch19, step2806]: loss 13.170231
[epoch19, step2807]: loss 0.844416
[epoch19, step2808]: loss 1.135601
[epoch19, step2809]: loss 1.723191
[epoch19, step2810]: loss 0.764879
[epoch19, step2811]: loss 3.065943
[epoch19, step2812]: loss 0.960574
[epoch19, step2813]: loss 0.849271
[epoch19, step2814]: loss 11.117161
[epoch19, step2815]: loss 4.096973
[epoch19, step2816]: loss 1.811060
[epoch19, step2817]: loss 2.530648
[epoch19, step2818]: loss 8.772161
[epoch19, step2819]: loss 1.403192
[epoch19, step2820]: loss 1.927072
[epoch19, step2821]: loss 0.903922
[epoch19, step2822]: loss 1.822011
[epoch19, step2823]: loss 1.029226
[epoch19, step2824]: loss 1.349186
[epoch19, step2825]: loss 0.708856
[epoch19, step2826]: loss 1.411185
[epoch19, step2827]: loss 5.410022
[epoch19, step2828]: loss 0.796792
[epoch19, step2829]: loss 1.178232
[epoch19, step2830]: loss 9.848472
[epoch19, step2831]: loss 2.545151
[epoch19, step2832]: loss 0.902653
[epoch19, step2833]: loss 0.975732
[epoch19, step2834]: loss 0.870438
[epoch19, step2835]: loss 5.977349
[epoch19, step2836]: loss 1.108127
[epoch19, step2837]: loss 0.763856
[epoch19, step2838]: loss 2.445304
[epoch19, step2839]: loss 9.646951
[epoch19, step2840]: loss 0.900123
[epoch19, step2841]: loss 0.900380
[epoch19, step2842]: loss 5.198796
[epoch19, step2843]: loss 0.866995
[epoch19, step2844]: loss 0.957375
[epoch19, step2845]: loss 0.378968
[epoch19, step2846]: loss 7.465390
[epoch19, step2847]: loss 1.438723
[epoch19, step2848]: loss 2.575814
[epoch19, step2849]: loss 4.095000
[epoch19, step2850]: loss 8.160323
[epoch19, step2851]: loss 3.705788
[epoch19, step2852]: loss 5.649105
[epoch19, step2853]: loss 2.080520
[epoch19, step2854]: loss 0.611849
[epoch19, step2855]: loss 0.934064
[epoch19, step2856]: loss 16.075970
[epoch19, step2857]: loss 1.434391
[epoch19, step2858]: loss 3.555772
[epoch19, step2859]: loss 0.895997
[epoch19, step2860]: loss 10.907953
[epoch19, step2861]: loss 6.051362
[epoch19, step2862]: loss 0.827800
[epoch19, step2863]: loss 20.625311
[epoch19, step2864]: loss 1.803442
[epoch19, step2865]: loss 4.079414
[epoch19, step2866]: loss 1.153801
[epoch19, step2867]: loss 3.488944
[epoch19, step2868]: loss 2.448426
[epoch19, step2869]: loss 0.651017
[epoch19, step2870]: loss 1.649980
[epoch19, step2871]: loss 2.665963
[epoch19, step2872]: loss 0.972703
[epoch19, step2873]: loss 0.549508
[epoch19, step2874]: loss 2.684464
[epoch19, step2875]: loss 1.047932
[epoch19, step2876]: loss 11.008582
[epoch19, step2877]: loss 1.057418
[epoch19, step2878]: loss 3.992731
[epoch19, step2879]: loss 0.834825
[epoch19, step2880]: loss 0.821833
[epoch19, step2881]: loss 14.941206
[epoch19, step2882]: loss 10.304959
[epoch19, step2883]: loss 0.871537
[epoch19, step2884]: loss 0.486633
[epoch19, step2885]: loss 0.698317
[epoch19, step2886]: loss 0.630189
[epoch19, step2887]: loss 5.128634
[epoch19, step2888]: loss 0.756868
[epoch19, step2889]: loss 0.556106
[epoch19, step2890]: loss 0.989532
[epoch19, step2891]: loss 1.638675
[epoch19, step2892]: loss 2.278812
[epoch19, step2893]: loss 1.119581
[epoch19, step2894]: loss 0.651009
[epoch19, step2895]: loss 2.421477
[epoch19, step2896]: loss 9.864860
[epoch19, step2897]: loss 0.688274
[epoch19, step2898]: loss 0.977951
[epoch19, step2899]: loss 0.972306
[epoch19, step2900]: loss 2.560116
[epoch19, step2901]: loss 0.760800
[epoch19, step2902]: loss 2.533547
[epoch19, step2903]: loss 9.234596
[epoch19, step2904]: loss 2.846652
[epoch19, step2905]: loss 1.914742
[epoch19, step2906]: loss 1.292220
[epoch19, step2907]: loss 1.166115
[epoch19, step2908]: loss 5.488133
[epoch19, step2909]: loss 7.028701
[epoch19, step2910]: loss 3.376384
[epoch19, step2911]: loss 5.859972
[epoch19, step2912]: loss 1.182120
[epoch19, step2913]: loss 11.138583
[epoch19, step2914]: loss 0.950599
[epoch19, step2915]: loss 10.069525
[epoch19, step2916]: loss 1.722242
[epoch19, step2917]: loss 6.998153
[epoch19, step2918]: loss 3.283842
[epoch19, step2919]: loss 1.421610
[epoch19, step2920]: loss 1.791992
[epoch19, step2921]: loss 1.439013
[epoch19, step2922]: loss 0.806220
[epoch19, step2923]: loss 0.825030
[epoch19, step2924]: loss 1.747517
[epoch19, step2925]: loss 2.751237
[epoch19, step2926]: loss 18.717133
[epoch19, step2927]: loss 0.821521
[epoch19, step2928]: loss 1.081556
[epoch19, step2929]: loss 0.849784
[epoch19, step2930]: loss 2.308187
[epoch19, step2931]: loss 4.506067
[epoch19, step2932]: loss 1.366091
[epoch19, step2933]: loss 1.415688
[epoch19, step2934]: loss 6.565823
[epoch19, step2935]: loss 3.096994
[epoch19, step2936]: loss 2.144307
[epoch19, step2937]: loss 24.319170
[epoch19, step2938]: loss 17.473429
[epoch19, step2939]: loss 1.732866
[epoch19, step2940]: loss 0.937503
[epoch19, step2941]: loss 1.648081
[epoch19, step2942]: loss 4.335698
[epoch19, step2943]: loss 6.903154
[epoch19, step2944]: loss 1.069727
[epoch19, step2945]: loss 2.557417
[epoch19, step2946]: loss 14.289621
[epoch19, step2947]: loss 6.031302
[epoch19, step2948]: loss 0.968527
[epoch19, step2949]: loss 2.576291
[epoch19, step2950]: loss 2.316745
[epoch19, step2951]: loss 2.230628
[epoch19, step2952]: loss 0.867354
[epoch19, step2953]: loss 1.617661
[epoch19, step2954]: loss 7.605987
[epoch19, step2955]: loss 3.739215
[epoch19, step2956]: loss 1.581820
[epoch19, step2957]: loss 1.290177
[epoch19, step2958]: loss 1.866865
[epoch19, step2959]: loss 2.505560
[epoch19, step2960]: loss 4.021930
[epoch19, step2961]: loss 0.733938
[epoch19, step2962]: loss 6.301167
[epoch19, step2963]: loss 0.892373
[epoch19, step2964]: loss 1.824214
[epoch19, step2965]: loss 0.801868
[epoch19, step2966]: loss 1.032193
[epoch19, step2967]: loss 1.202079
[epoch19, step2968]: loss 5.683363
[epoch19, step2969]: loss 0.759311
[epoch19, step2970]: loss 10.103414
[epoch19, step2971]: loss 11.414798
[epoch19, step2972]: loss 1.501436
[epoch19, step2973]: loss 10.718339
[epoch19, step2974]: loss 4.270756
[epoch19, step2975]: loss 2.466829
[epoch19, step2976]: loss 1.213552
[epoch19, step2977]: loss 1.445068
[epoch19, step2978]: loss 13.718195
[epoch19, step2979]: loss 0.694309
[epoch19, step2980]: loss 3.324257
[epoch19, step2981]: loss 0.929681
[epoch19, step2982]: loss 0.607800
[epoch19, step2983]: loss 6.158042
[epoch19, step2984]: loss 0.712919
[epoch19, step2985]: loss 2.120106
[epoch19, step2986]: loss 0.849918
[epoch19, step2987]: loss 1.616275
[epoch19, step2988]: loss 2.332783
[epoch19, step2989]: loss 10.263485
[epoch19, step2990]: loss 15.169450
[epoch19, step2991]: loss 15.060113
[epoch19, step2992]: loss 0.898217
[epoch19, step2993]: loss 0.588872
[epoch19, step2994]: loss 2.994987
[epoch19, step2995]: loss 1.460833
[epoch19, step2996]: loss 1.046640
[epoch19, step2997]: loss 1.516895
[epoch19, step2998]: loss 0.677913
[epoch19, step2999]: loss 24.007832
[epoch19, step3000]: loss 1.455678
[epoch19, step3001]: loss 37.315548
[epoch19, step3002]: loss 1.976364
[epoch19, step3003]: loss 1.131444
[epoch19, step3004]: loss 1.728712
[epoch19, step3005]: loss 10.271531
[epoch19, step3006]: loss 7.834081
[epoch19, step3007]: loss 1.723352
[epoch19, step3008]: loss 1.478095
[epoch19, step3009]: loss 3.274978
[epoch19, step3010]: loss 4.740149
[epoch19, step3011]: loss 7.664657
[epoch19, step3012]: loss 9.640833
[epoch19, step3013]: loss 1.211820
[epoch19, step3014]: loss 19.275152
[epoch19, step3015]: loss 0.786144
[epoch19, step3016]: loss 0.930969
[epoch19, step3017]: loss 1.138924
[epoch19, step3018]: loss 1.074756
[epoch19, step3019]: loss 11.303001
[epoch19, step3020]: loss 15.687848
[epoch19, step3021]: loss 1.659094
[epoch19, step3022]: loss 1.170534
[epoch19, step3023]: loss 0.655301
[epoch19, step3024]: loss 0.806436
[epoch19, step3025]: loss 5.955809
[epoch19, step3026]: loss 1.204449
[epoch19, step3027]: loss 0.625459
[epoch19, step3028]: loss 1.427053
[epoch19, step3029]: loss 5.978640
[epoch19, step3030]: loss 1.195907
[epoch19, step3031]: loss 3.361125
[epoch19, step3032]: loss 1.687865
[epoch19, step3033]: loss 2.272352
[epoch19, step3034]: loss 0.851098
[epoch19, step3035]: loss 1.332300
[epoch19, step3036]: loss 16.056112
[epoch19, step3037]: loss 17.085659
[epoch19, step3038]: loss 1.368721
[epoch19, step3039]: loss 1.320554
[epoch19, step3040]: loss 1.204103
[epoch19, step3041]: loss 1.044876
[epoch19, step3042]: loss 1.794820
[epoch19, step3043]: loss 7.013072
[epoch19, step3044]: loss 1.185960
[epoch19, step3045]: loss 7.726913
[epoch19, step3046]: loss 1.279276
[epoch19, step3047]: loss 0.982299
[epoch19, step3048]: loss 1.249545
[epoch19, step3049]: loss 5.497710
[epoch19, step3050]: loss 2.470580
[epoch19, step3051]: loss 3.043711
[epoch19, step3052]: loss 0.647063
[epoch19, step3053]: loss 1.264669
[epoch19, step3054]: loss 0.904844
[epoch19, step3055]: loss 0.733992
[epoch19, step3056]: loss 0.527316
[epoch19, step3057]: loss 0.975193
[epoch19, step3058]: loss 1.102165
[epoch19, step3059]: loss 1.008705
[epoch19, step3060]: loss 1.074619
[epoch19, step3061]: loss 0.630875
[epoch19, step3062]: loss 0.974589
[epoch19, step3063]: loss 3.212492
[epoch19, step3064]: loss 1.007193
[epoch19, step3065]: loss 6.920840
[epoch19, step3066]: loss 4.543632
[epoch19, step3067]: loss 5.176058
[epoch19, step3068]: loss 0.999838
[epoch19, step3069]: loss 0.890852
[epoch19, step3070]: loss 1.981974
[epoch19, step3071]: loss 1.647139
[epoch19, step3072]: loss 1.046422
[epoch19, step3073]: loss 0.667098
[epoch19, step3074]: loss 15.464277
[epoch19, step3075]: loss 6.215128
[epoch19, step3076]: loss 0.568606

[epoch19]: avg loss 0.568606

[epoch20, step1]: loss 0.672925
[epoch20, step2]: loss 37.025333
[epoch20, step3]: loss 10.832982
[epoch20, step4]: loss 6.054244
[epoch20, step5]: loss 0.626672
[epoch20, step6]: loss 1.260407
[epoch20, step7]: loss 2.286835
[epoch20, step8]: loss 1.175035
[epoch20, step9]: loss 1.558000
[epoch20, step10]: loss 0.851130
[epoch20, step11]: loss 0.791617
[epoch20, step12]: loss 5.591629
[epoch20, step13]: loss 13.012070
[epoch20, step14]: loss 14.186030
[epoch20, step15]: loss 1.762744
[epoch20, step16]: loss 0.984018
[epoch20, step17]: loss 5.009598
[epoch20, step18]: loss 1.894938
[epoch20, step19]: loss 0.536885
[epoch20, step20]: loss 1.615699
[epoch20, step21]: loss 1.324645
[epoch20, step22]: loss 4.728576
[epoch20, step23]: loss 1.082694
[epoch20, step24]: loss 2.320823
[epoch20, step25]: loss 0.753438
[epoch20, step26]: loss 9.096121
[epoch20, step27]: loss 1.416393
[epoch20, step28]: loss 9.308941
[epoch20, step29]: loss 3.741598
[epoch20, step30]: loss 1.041347
[epoch20, step31]: loss 0.759944
[epoch20, step32]: loss 0.562896
[epoch20, step33]: loss 0.750490
[epoch20, step34]: loss 2.162138
[epoch20, step35]: loss 1.035626
[epoch20, step36]: loss 1.350953
[epoch20, step37]: loss 0.772507
[epoch20, step38]: loss 0.633010
[epoch20, step39]: loss 2.438497
[epoch20, step40]: loss 0.769442
[epoch20, step41]: loss 0.711295
[epoch20, step42]: loss 0.585962
[epoch20, step43]: loss 7.951039
[epoch20, step44]: loss 2.204897
[epoch20, step45]: loss 1.105989
[epoch20, step46]: loss 0.659454
[epoch20, step47]: loss 2.888966
[epoch20, step48]: loss 1.755657
[epoch20, step49]: loss 0.987465
[epoch20, step50]: loss 2.145272
[epoch20, step51]: loss 0.554416
[epoch20, step52]: loss 1.782331
[epoch20, step53]: loss 1.801280
[epoch20, step54]: loss 8.701951
[epoch20, step55]: loss 9.670894
[epoch20, step56]: loss 10.239787
[epoch20, step57]: loss 2.059699
[epoch20, step58]: loss 5.170446
[epoch20, step59]: loss 2.509369
[epoch20, step60]: loss 7.739938
[epoch20, step61]: loss 2.351352
[epoch20, step62]: loss 1.078738
[epoch20, step63]: loss 1.194863
[epoch20, step64]: loss 9.824924
[epoch20, step65]: loss 3.151941
[epoch20, step66]: loss 6.785913
[epoch20, step67]: loss 0.612790
[epoch20, step68]: loss 5.114228
[epoch20, step69]: loss 4.284627
[epoch20, step70]: loss 0.717426
[epoch20, step71]: loss 14.917145
[epoch20, step72]: loss 0.911496
[epoch20, step73]: loss 0.481820
[epoch20, step74]: loss 2.142359
[epoch20, step75]: loss 1.790433
[epoch20, step76]: loss 7.610147
[epoch20, step77]: loss 1.125464
[epoch20, step78]: loss 1.056861
[epoch20, step79]: loss 1.853720
[epoch20, step80]: loss 0.666251
[epoch20, step81]: loss 1.369348
[epoch20, step82]: loss 2.315809
[epoch20, step83]: loss 0.933396
[epoch20, step84]: loss 9.388943
[epoch20, step85]: loss 1.040515
[epoch20, step86]: loss 0.995873
[epoch20, step87]: loss 3.162807
[epoch20, step88]: loss 0.800795
[epoch20, step89]: loss 0.852192
[epoch20, step90]: loss 0.950369
[epoch20, step91]: loss 2.111849
[epoch20, step92]: loss 0.535882
[epoch20, step93]: loss 1.865417
[epoch20, step94]: loss 0.722115
[epoch20, step95]: loss 0.799113
[epoch20, step96]: loss 4.104671
[epoch20, step97]: loss 3.996743
[epoch20, step98]: loss 0.992764
[epoch20, step99]: loss 7.653074
[epoch20, step100]: loss 0.782964
[epoch20, step101]: loss 1.670805
[epoch20, step102]: loss 1.432474
[epoch20, step103]: loss 1.612277
[epoch20, step104]: loss 9.610766
[epoch20, step105]: loss 0.667598
[epoch20, step106]: loss 2.251376
[epoch20, step107]: loss 15.614031
[epoch20, step108]: loss 0.866093
[epoch20, step109]: loss 1.475843
[epoch20, step110]: loss 1.898092
[epoch20, step111]: loss 1.054833
[epoch20, step112]: loss 1.807754
[epoch20, step113]: loss 3.961019
[epoch20, step114]: loss 4.190105
[epoch20, step115]: loss 0.991951
[epoch20, step116]: loss 1.246005
[epoch20, step117]: loss 0.925465
[epoch20, step118]: loss 2.616717
[epoch20, step119]: loss 0.810004
[epoch20, step120]: loss 0.758949
[epoch20, step121]: loss 8.745783
[epoch20, step122]: loss 6.308208
[epoch20, step123]: loss 13.158148
[epoch20, step124]: loss 5.281666
[epoch20, step125]: loss 12.482126
[epoch20, step126]: loss 0.562800
[epoch20, step127]: loss 1.067749
[epoch20, step128]: loss 2.593771
[epoch20, step129]: loss 0.898442
[epoch20, step130]: loss 3.614901
[epoch20, step131]: loss 0.964689
[epoch20, step132]: loss 0.801085
[epoch20, step133]: loss 0.814427
[epoch20, step134]: loss 1.193678
[epoch20, step135]: loss 1.446040
[epoch20, step136]: loss 2.519121
[epoch20, step137]: loss 1.073586
[epoch20, step138]: loss 1.085776
[epoch20, step139]: loss 1.166357
[epoch20, step140]: loss 14.844999
[epoch20, step141]: loss 1.174754
[epoch20, step142]: loss 0.913399
[epoch20, step143]: loss 2.882936
[epoch20, step144]: loss 9.102139
[epoch20, step145]: loss 0.827562
[epoch20, step146]: loss 8.073603
[epoch20, step147]: loss 5.133754
[epoch20, step148]: loss 0.736190
[epoch20, step149]: loss 0.686090
[epoch20, step150]: loss 0.654043
[epoch20, step151]: loss 1.279012
[epoch20, step152]: loss 0.891541
[epoch20, step153]: loss 0.672597
[epoch20, step154]: loss 1.177881
[epoch20, step155]: loss 0.596236
[epoch20, step156]: loss 6.055128
[epoch20, step157]: loss 0.745467
[epoch20, step158]: loss 0.633298
[epoch20, step159]: loss 5.907014
[epoch20, step160]: loss 3.877779
[epoch20, step161]: loss 1.244889
[epoch20, step162]: loss 1.820172
[epoch20, step163]: loss 2.674210
[epoch20, step164]: loss 0.786043
[epoch20, step165]: loss 26.025091
[epoch20, step166]: loss 1.268969
[epoch20, step167]: loss 3.394387
[epoch20, step168]: loss 1.220077
[epoch20, step169]: loss 1.206353
[epoch20, step170]: loss 1.280627
[epoch20, step171]: loss 5.122493
[epoch20, step172]: loss 1.466529
[epoch20, step173]: loss 0.592055
[epoch20, step174]: loss 5.584650
[epoch20, step175]: loss 1.622913
[epoch20, step176]: loss 4.316286
[epoch20, step177]: loss 0.726398
[epoch20, step178]: loss 2.673382
[epoch20, step179]: loss 0.421911
[epoch20, step180]: loss 1.738451
[epoch20, step181]: loss 0.560352
[epoch20, step182]: loss 0.623386
[epoch20, step183]: loss 1.982440
[epoch20, step184]: loss 6.150206
[epoch20, step185]: loss 2.200663
[epoch20, step186]: loss 10.803166
[epoch20, step187]: loss 13.569111
[epoch20, step188]: loss 3.710102
[epoch20, step189]: loss 1.305560
[epoch20, step190]: loss 1.186935
[epoch20, step191]: loss 10.370337
[epoch20, step192]: loss 12.692990
[epoch20, step193]: loss 1.282196
[epoch20, step194]: loss 0.997266
[epoch20, step195]: loss 1.117467
[epoch20, step196]: loss 0.624510
[epoch20, step197]: loss 1.081866
[epoch20, step198]: loss 2.957375
[epoch20, step199]: loss 3.759559
[epoch20, step200]: loss 9.703432
[epoch20, step201]: loss 2.116725
[epoch20, step202]: loss 2.468834
[epoch20, step203]: loss 9.474689
[epoch20, step204]: loss 1.976151
[epoch20, step205]: loss 3.849743
[epoch20, step206]: loss 1.203015
[epoch20, step207]: loss 2.139301
[epoch20, step208]: loss 1.539561
[epoch20, step209]: loss 0.672366
[epoch20, step210]: loss 1.504592
[epoch20, step211]: loss 6.060927
[epoch20, step212]: loss 1.079450
[epoch20, step213]: loss 5.393624
[epoch20, step214]: loss 7.888071
[epoch20, step215]: loss 2.095563
[epoch20, step216]: loss 3.315531
[epoch20, step217]: loss 1.592139
[epoch20, step218]: loss 0.906623
[epoch20, step219]: loss 12.474699
[epoch20, step220]: loss 25.138149
[epoch20, step221]: loss 5.197433
[epoch20, step222]: loss 6.964783
[epoch20, step223]: loss 4.177997
[epoch20, step224]: loss 2.048712
[epoch20, step225]: loss 3.741110
[epoch20, step226]: loss 0.872671
[epoch20, step227]: loss 4.897728
[epoch20, step228]: loss 1.544348
[epoch20, step229]: loss 0.548622
[epoch20, step230]: loss 1.913755
[epoch20, step231]: loss 10.354674
[epoch20, step232]: loss 0.726906
[epoch20, step233]: loss 1.241065
[epoch20, step234]: loss 1.689811
[epoch20, step235]: loss 2.891184
[epoch20, step236]: loss 9.128458
[epoch20, step237]: loss 1.716348
[epoch20, step238]: loss 2.135545
[epoch20, step239]: loss 0.604620
[epoch20, step240]: loss 7.114707
[epoch20, step241]: loss 15.989614
[epoch20, step242]: loss 1.763507
[epoch20, step243]: loss 0.631345
[epoch20, step244]: loss 1.146531
[epoch20, step245]: loss 0.573238
[epoch20, step246]: loss 0.843365
[epoch20, step247]: loss 1.607277
[epoch20, step248]: loss 0.450703
[epoch20, step249]: loss 6.500323
[epoch20, step250]: loss 1.252786
[epoch20, step251]: loss 15.460760
[epoch20, step252]: loss 2.370423
[epoch20, step253]: loss 3.942084
[epoch20, step254]: loss 0.948058
[epoch20, step255]: loss 1.016225
[epoch20, step256]: loss 3.982014
[epoch20, step257]: loss 1.557605
[epoch20, step258]: loss 7.359289
[epoch20, step259]: loss 1.815123
[epoch20, step260]: loss 4.137770
[epoch20, step261]: loss 2.415071
[epoch20, step262]: loss 0.741196
[epoch20, step263]: loss 1.755573
[epoch20, step264]: loss 0.741053
[epoch20, step265]: loss 2.004831
[epoch20, step266]: loss 1.155381
[epoch20, step267]: loss 0.696160
[epoch20, step268]: loss 10.803167
[epoch20, step269]: loss 1.075057
[epoch20, step270]: loss 1.539403
[epoch20, step271]: loss 0.833825
[epoch20, step272]: loss 1.358533
[epoch20, step273]: loss 3.217537
[epoch20, step274]: loss 3.447814
[epoch20, step275]: loss 0.804609
[epoch20, step276]: loss 1.171920
[epoch20, step277]: loss 1.815820
[epoch20, step278]: loss 1.012377
[epoch20, step279]: loss 2.612102
[epoch20, step280]: loss 1.514768
[epoch20, step281]: loss 11.655221
[epoch20, step282]: loss 4.192134
[epoch20, step283]: loss 0.853362
[epoch20, step284]: loss 1.036304
[epoch20, step285]: loss 0.779979
[epoch20, step286]: loss 12.790242
[epoch20, step287]: loss 0.812004
[epoch20, step288]: loss 0.631850
[epoch20, step289]: loss 1.435126
[epoch20, step290]: loss 1.422437
[epoch20, step291]: loss 7.877649
[epoch20, step292]: loss 6.366882
[epoch20, step293]: loss 6.014213
[epoch20, step294]: loss 14.245046
[epoch20, step295]: loss 4.057582
[epoch20, step296]: loss 8.056620
[epoch20, step297]: loss 26.056393
[epoch20, step298]: loss 2.732055
[epoch20, step299]: loss 4.660015
[epoch20, step300]: loss 0.793176
[epoch20, step301]: loss 0.760824
[epoch20, step302]: loss 4.560939
[epoch20, step303]: loss 4.859450
[epoch20, step304]: loss 9.053366
[epoch20, step305]: loss 16.037472
[epoch20, step306]: loss 4.255343
[epoch20, step307]: loss 0.584505
[epoch20, step308]: loss 1.302084
[epoch20, step309]: loss 0.526655
[epoch20, step310]: loss 0.539887
[epoch20, step311]: loss 1.154549
[epoch20, step312]: loss 2.553406
[epoch20, step313]: loss 7.408156
[epoch20, step314]: loss 3.557488
[epoch20, step315]: loss 0.755630
[epoch20, step316]: loss 9.649811
[epoch20, step317]: loss 1.253219
[epoch20, step318]: loss 1.328677
[epoch20, step319]: loss 1.259823
[epoch20, step320]: loss 2.772336
[epoch20, step321]: loss 1.256649
[epoch20, step322]: loss 1.529985
[epoch20, step323]: loss 0.656217
[epoch20, step324]: loss 0.951717
[epoch20, step325]: loss 0.664527
[epoch20, step326]: loss 1.947870
[epoch20, step327]: loss 0.541596
[epoch20, step328]: loss 2.859393
[epoch20, step329]: loss 1.209286
[epoch20, step330]: loss 1.946199
[epoch20, step331]: loss 1.740517
[epoch20, step332]: loss 0.706311
[epoch20, step333]: loss 1.629750
[epoch20, step334]: loss 0.930268
[epoch20, step335]: loss 1.149385
[epoch20, step336]: loss 1.553041
[epoch20, step337]: loss 0.716880
[epoch20, step338]: loss 1.042110
[epoch20, step339]: loss 8.569629
[epoch20, step340]: loss 1.031935
[epoch20, step341]: loss 2.041390
[epoch20, step342]: loss 0.774983
[epoch20, step343]: loss 6.170870
[epoch20, step344]: loss 0.591594
[epoch20, step345]: loss 1.299744
[epoch20, step346]: loss 2.782444
[epoch20, step347]: loss 1.525268
[epoch20, step348]: loss 7.847068
[epoch20, step349]: loss 8.672411
[epoch20, step350]: loss 7.676980
[epoch20, step351]: loss 1.448498
[epoch20, step352]: loss 1.013718
[epoch20, step353]: loss 1.278898
[epoch20, step354]: loss 1.897993
[epoch20, step355]: loss 2.602250
[epoch20, step356]: loss 2.895032
[epoch20, step357]: loss 5.972510
[epoch20, step358]: loss 1.307933
[epoch20, step359]: loss 1.510051
[epoch20, step360]: loss 1.171687
[epoch20, step361]: loss 0.976787
[epoch20, step362]: loss 1.840430
[epoch20, step363]: loss 2.982515
[epoch20, step364]: loss 1.494945
[epoch20, step365]: loss 4.226378
[epoch20, step366]: loss 0.766684
[epoch20, step367]: loss 7.696339
[epoch20, step368]: loss 0.712881
[epoch20, step369]: loss 1.176352
[epoch20, step370]: loss 10.127248
[epoch20, step371]: loss 1.041115
[epoch20, step372]: loss 1.320122
[epoch20, step373]: loss 1.033682
[epoch20, step374]: loss 10.730987
[epoch20, step375]: loss 0.832070
[epoch20, step376]: loss 1.931407
[epoch20, step377]: loss 1.041104
[epoch20, step378]: loss 6.514956
[epoch20, step379]: loss 0.899514
[epoch20, step380]: loss 2.375720
[epoch20, step381]: loss 0.839473
[epoch20, step382]: loss 3.984998
[epoch20, step383]: loss 6.992431
[epoch20, step384]: loss 2.900748
[epoch20, step385]: loss 3.295865
[epoch20, step386]: loss 13.264784
[epoch20, step387]: loss 2.980285
[epoch20, step388]: loss 1.571936
[epoch20, step389]: loss 2.339458
[epoch20, step390]: loss 3.309131
[epoch20, step391]: loss 0.662713
[epoch20, step392]: loss 4.787758
[epoch20, step393]: loss 1.348711
[epoch20, step394]: loss 2.623691
[epoch20, step395]: loss 10.656755
[epoch20, step396]: loss 1.115011
[epoch20, step397]: loss 10.634635
[epoch20, step398]: loss 0.939304
[epoch20, step399]: loss 2.300310
[epoch20, step400]: loss 11.019913
[epoch20, step401]: loss 1.190058
[epoch20, step402]: loss 0.543777
[epoch20, step403]: loss 0.539802
[epoch20, step404]: loss 0.798139
[epoch20, step405]: loss 0.921418
[epoch20, step406]: loss 1.606486
[epoch20, step407]: loss 1.393916
[epoch20, step408]: loss 1.462877
[epoch20, step409]: loss 1.392656
[epoch20, step410]: loss 1.836204
[epoch20, step411]: loss 2.797620
[epoch20, step412]: loss 9.451577
[epoch20, step413]: loss 7.609281
[epoch20, step414]: loss 9.335090
[epoch20, step415]: loss 5.373720
[epoch20, step416]: loss 0.729577
[epoch20, step417]: loss 8.319163
[epoch20, step418]: loss 0.637659
[epoch20, step419]: loss 2.525217
[epoch20, step420]: loss 3.228566
[epoch20, step421]: loss 1.170294
[epoch20, step422]: loss 9.915514
[epoch20, step423]: loss 1.307150
[epoch20, step424]: loss 1.777213
[epoch20, step425]: loss 1.219139
[epoch20, step426]: loss 1.108896
[epoch20, step427]: loss 1.362832
[epoch20, step428]: loss 6.158943
[epoch20, step429]: loss 0.866010
[epoch20, step430]: loss 15.813199
[epoch20, step431]: loss 1.248280
[epoch20, step432]: loss 6.414230
[epoch20, step433]: loss 0.688533
[epoch20, step434]: loss 0.824136
[epoch20, step435]: loss 14.051424
[epoch20, step436]: loss 0.887802
[epoch20, step437]: loss 0.492269
[epoch20, step438]: loss 3.085555
[epoch20, step439]: loss 2.877357
[epoch20, step440]: loss 0.722707
[epoch20, step441]: loss 2.096824
[epoch20, step442]: loss 3.830806
[epoch20, step443]: loss 0.782353
[epoch20, step444]: loss 0.928790
[epoch20, step445]: loss 2.956627
[epoch20, step446]: loss 3.169337
[epoch20, step447]: loss 2.018571
[epoch20, step448]: loss 0.526286
[epoch20, step449]: loss 6.820702
[epoch20, step450]: loss 1.251370
[epoch20, step451]: loss 10.869755
[epoch20, step452]: loss 0.858474
[epoch20, step453]: loss 15.033942
[epoch20, step454]: loss 0.655031
[epoch20, step455]: loss 0.975951
[epoch20, step456]: loss 1.856738
[epoch20, step457]: loss 4.755394
[epoch20, step458]: loss 3.416249
[epoch20, step459]: loss 2.589680
[epoch20, step460]: loss 1.246447
[epoch20, step461]: loss 0.829344
[epoch20, step462]: loss 1.854852
[epoch20, step463]: loss 0.816312
[epoch20, step464]: loss 0.731215
[epoch20, step465]: loss 0.528128
[epoch20, step466]: loss 2.474006
[epoch20, step467]: loss 0.684183
[epoch20, step468]: loss 10.649351
[epoch20, step469]: loss 0.852295
[epoch20, step470]: loss 1.565899
[epoch20, step471]: loss 1.060260
[epoch20, step472]: loss 1.443662
[epoch20, step473]: loss 1.727214
[epoch20, step474]: loss 1.271690
[epoch20, step475]: loss 1.981358
[epoch20, step476]: loss 0.798746
[epoch20, step477]: loss 18.021709
[epoch20, step478]: loss 9.304625
[epoch20, step479]: loss 2.403664
[epoch20, step480]: loss 2.017964
[epoch20, step481]: loss 4.383935
[epoch20, step482]: loss 0.882089
[epoch20, step483]: loss 1.624427
[epoch20, step484]: loss 0.871116
[epoch20, step485]: loss 5.489230
[epoch20, step486]: loss 15.557291
[epoch20, step487]: loss 0.997976
[epoch20, step488]: loss 1.371397
[epoch20, step489]: loss 0.624188
[epoch20, step490]: loss 0.911611
[epoch20, step491]: loss 0.748777
[epoch20, step492]: loss 3.795144
[epoch20, step493]: loss 1.002960
[epoch20, step494]: loss 1.685309
[epoch20, step495]: loss 3.701112
[epoch20, step496]: loss 2.794533
[epoch20, step497]: loss 1.571703
[epoch20, step498]: loss 1.197768
[epoch20, step499]: loss 1.261778
[epoch20, step500]: loss 3.785221
[epoch20, step501]: loss 0.637892
[epoch20, step502]: loss 1.568200
[epoch20, step503]: loss 3.075987
[epoch20, step504]: loss 0.551286
[epoch20, step505]: loss 1.594528
[epoch20, step506]: loss 6.407798
[epoch20, step507]: loss 0.876511
[epoch20, step508]: loss 1.687872
[epoch20, step509]: loss 0.853031
[epoch20, step510]: loss 3.513299
[epoch20, step511]: loss 1.246175
[epoch20, step512]: loss 2.326388
[epoch20, step513]: loss 2.023816
[epoch20, step514]: loss 0.969185
[epoch20, step515]: loss 2.432222
[epoch20, step516]: loss 1.010993
[epoch20, step517]: loss 1.087070
[epoch20, step518]: loss 3.268028
[epoch20, step519]: loss 17.054007
[epoch20, step520]: loss 5.914122
[epoch20, step521]: loss 9.342256
[epoch20, step522]: loss 2.463421
[epoch20, step523]: loss 7.293606
[epoch20, step524]: loss 1.849937
[epoch20, step525]: loss 1.312898
[epoch20, step526]: loss 0.524313
[epoch20, step527]: loss 2.645146
[epoch20, step528]: loss 1.891805
[epoch20, step529]: loss 1.169738
[epoch20, step530]: loss 8.939541
[epoch20, step531]: loss 2.605637
[epoch20, step532]: loss 4.225027
[epoch20, step533]: loss 0.584668
[epoch20, step534]: loss 8.307795
[epoch20, step535]: loss 1.107356
[epoch20, step536]: loss 0.617250
[epoch20, step537]: loss 0.767096
[epoch20, step538]: loss 0.688535
[epoch20, step539]: loss 11.785923
[epoch20, step540]: loss 1.095925
[epoch20, step541]: loss 1.067728
[epoch20, step542]: loss 3.340210
[epoch20, step543]: loss 0.497278
[epoch20, step544]: loss 1.413743
[epoch20, step545]: loss 2.316850
[epoch20, step546]: loss 1.323943
[epoch20, step547]: loss 1.496984
[epoch20, step548]: loss 0.875440
[epoch20, step549]: loss 10.297528
[epoch20, step550]: loss 13.735956
[epoch20, step551]: loss 6.053923
[epoch20, step552]: loss 1.772254
[epoch20, step553]: loss 6.074452
[epoch20, step554]: loss 7.767999
[epoch20, step555]: loss 1.979169
[epoch20, step556]: loss 1.140910
[epoch20, step557]: loss 1.363846
[epoch20, step558]: loss 1.065236
[epoch20, step559]: loss 11.828103
[epoch20, step560]: loss 1.710146
[epoch20, step561]: loss 7.930975
[epoch20, step562]: loss 0.853074
[epoch20, step563]: loss 0.484263
[epoch20, step564]: loss 2.798269
[epoch20, step565]: loss 0.987053
[epoch20, step566]: loss 0.605464
[epoch20, step567]: loss 2.999443
[epoch20, step568]: loss 0.471234
[epoch20, step569]: loss 2.609083
[epoch20, step570]: loss 0.404533
[epoch20, step571]: loss 9.020732
[epoch20, step572]: loss 1.936087
[epoch20, step573]: loss 3.153576
[epoch20, step574]: loss 8.899136
[epoch20, step575]: loss 1.560018
[epoch20, step576]: loss 2.219868
[epoch20, step577]: loss 1.103845
[epoch20, step578]: loss 1.106689
[epoch20, step579]: loss 33.654938
[epoch20, step580]: loss 1.095168
[epoch20, step581]: loss 8.076668
[epoch20, step582]: loss 3.763633
[epoch20, step583]: loss 2.021324
[epoch20, step584]: loss 3.298899
[epoch20, step585]: loss 3.536675
[epoch20, step586]: loss 8.552814
[epoch20, step587]: loss 8.133264
[epoch20, step588]: loss 0.969412
[epoch20, step589]: loss 2.859186
[epoch20, step590]: loss 1.497201
[epoch20, step591]: loss 1.748462
[epoch20, step592]: loss 1.798966
[epoch20, step593]: loss 1.127024
[epoch20, step594]: loss 1.142996
[epoch20, step595]: loss 8.499012
[epoch20, step596]: loss 2.056400
[epoch20, step597]: loss 0.929196
[epoch20, step598]: loss 2.353414
[epoch20, step599]: loss 0.557012
[epoch20, step600]: loss 6.927711
[epoch20, step601]: loss 1.017624
[epoch20, step602]: loss 1.544447
[epoch20, step603]: loss 0.813343
[epoch20, step604]: loss 0.813043
[epoch20, step605]: loss 2.752987
[epoch20, step606]: loss 1.242695
[epoch20, step607]: loss 8.645579
[epoch20, step608]: loss 1.116192
[epoch20, step609]: loss 5.605115
[epoch20, step610]: loss 16.773685
[epoch20, step611]: loss 8.216177
[epoch20, step612]: loss 1.246300
[epoch20, step613]: loss 1.129510
[epoch20, step614]: loss 4.586117
[epoch20, step615]: loss 1.097395
[epoch20, step616]: loss 0.789316
[epoch20, step617]: loss 3.226229
[epoch20, step618]: loss 0.926697
[epoch20, step619]: loss 0.941176
[epoch20, step620]: loss 0.868352
[epoch20, step621]: loss 0.696749
[epoch20, step622]: loss 0.868027
[epoch20, step623]: loss 2.407924
[epoch20, step624]: loss 0.823376
[epoch20, step625]: loss 2.110025
[epoch20, step626]: loss 1.350712
[epoch20, step627]: loss 7.686918
[epoch20, step628]: loss 2.517299
[epoch20, step629]: loss 1.254513
[epoch20, step630]: loss 8.250846
[epoch20, step631]: loss 9.739935
[epoch20, step632]: loss 0.987313
[epoch20, step633]: loss 2.373008
[epoch20, step634]: loss 3.072814
[epoch20, step635]: loss 0.497746
[epoch20, step636]: loss 3.471410
[epoch20, step637]: loss 10.304745
[epoch20, step638]: loss 0.911390
[epoch20, step639]: loss 0.871303
[epoch20, step640]: loss 2.772590
[epoch20, step641]: loss 10.943329
[epoch20, step642]: loss 4.508904
[epoch20, step643]: loss 0.734740
[epoch20, step644]: loss 3.340393
[epoch20, step645]: loss 0.641429
[epoch20, step646]: loss 4.511919
[epoch20, step647]: loss 0.953605
[epoch20, step648]: loss 0.789576
[epoch20, step649]: loss 1.740073
[epoch20, step650]: loss 2.176269
[epoch20, step651]: loss 0.618300
[epoch20, step652]: loss 1.954387
[epoch20, step653]: loss 26.791378
[epoch20, step654]: loss 0.926713
[epoch20, step655]: loss 0.518743
[epoch20, step656]: loss 1.037352
[epoch20, step657]: loss 1.597328
[epoch20, step658]: loss 1.089672
[epoch20, step659]: loss 0.501892
[epoch20, step660]: loss 4.086441
[epoch20, step661]: loss 13.897377
[epoch20, step662]: loss 8.300580
[epoch20, step663]: loss 1.034223
[epoch20, step664]: loss 0.729919
[epoch20, step665]: loss 1.733922
[epoch20, step666]: loss 0.971073
[epoch20, step667]: loss 2.162965
[epoch20, step668]: loss 6.747379
[epoch20, step669]: loss 1.687750
[epoch20, step670]: loss 1.715791
[epoch20, step671]: loss 0.525271
[epoch20, step672]: loss 3.883657
[epoch20, step673]: loss 0.918618
[epoch20, step674]: loss 0.970782
[epoch20, step675]: loss 5.492626
[epoch20, step676]: loss 1.490607
[epoch20, step677]: loss 3.778003
[epoch20, step678]: loss 1.231794
[epoch20, step679]: loss 5.226202
[epoch20, step680]: loss 16.864111
[epoch20, step681]: loss 10.099785
[epoch20, step682]: loss 0.993173
[epoch20, step683]: loss 1.509364
[epoch20, step684]: loss 0.346431
[epoch20, step685]: loss 1.715087
[epoch20, step686]: loss 1.970578
[epoch20, step687]: loss 0.778492
[epoch20, step688]: loss 0.776905
[epoch20, step689]: loss 0.690583
[epoch20, step690]: loss 0.770303
[epoch20, step691]: loss 14.757353
[epoch20, step692]: loss 0.972399
[epoch20, step693]: loss 0.984047
[epoch20, step694]: loss 3.454789
[epoch20, step695]: loss 0.894138
[epoch20, step696]: loss 1.981538
[epoch20, step697]: loss 0.831288
[epoch20, step698]: loss 0.615243
[epoch20, step699]: loss 1.151661
[epoch20, step700]: loss 1.051247
[epoch20, step701]: loss 2.333430
[epoch20, step702]: loss 10.002492
[epoch20, step703]: loss 0.608478
[epoch20, step704]: loss 4.605392
[epoch20, step705]: loss 6.499817
[epoch20, step706]: loss 0.891072
[epoch20, step707]: loss 4.909822
[epoch20, step708]: loss 1.003117
[epoch20, step709]: loss 1.723136
[epoch20, step710]: loss 2.533860
[epoch20, step711]: loss 2.678164
[epoch20, step712]: loss 2.165859
[epoch20, step713]: loss 2.886676
[epoch20, step714]: loss 3.677687
[epoch20, step715]: loss 1.851091
[epoch20, step716]: loss 6.678471
[epoch20, step717]: loss 1.048564
[epoch20, step718]: loss 8.155307
[epoch20, step719]: loss 1.676453
[epoch20, step720]: loss 4.521939
[epoch20, step721]: loss 1.710940
[epoch20, step722]: loss 2.363198
[epoch20, step723]: loss 4.558569
[epoch20, step724]: loss 0.853175
[epoch20, step725]: loss 13.847094
[epoch20, step726]: loss 6.718551
[epoch20, step727]: loss 1.999886
[epoch20, step728]: loss 0.969162
[epoch20, step729]: loss 0.725522
[epoch20, step730]: loss 3.055359
[epoch20, step731]: loss 0.457002
[epoch20, step732]: loss 2.171754
[epoch20, step733]: loss 0.630795
[epoch20, step734]: loss 2.036890
[epoch20, step735]: loss 5.339142
[epoch20, step736]: loss 0.786458
[epoch20, step737]: loss 10.460874
[epoch20, step738]: loss 1.591535
[epoch20, step739]: loss 2.253306
[epoch20, step740]: loss 0.927899
[epoch20, step741]: loss 0.976504
[epoch20, step742]: loss 0.530987
[epoch20, step743]: loss 1.564607
[epoch20, step744]: loss 0.608148
[epoch20, step745]: loss 7.586066
[epoch20, step746]: loss 8.181920
[epoch20, step747]: loss 0.877589
[epoch20, step748]: loss 0.811499
[epoch20, step749]: loss 1.577369
[epoch20, step750]: loss 0.866110
[epoch20, step751]: loss 1.217536
[epoch20, step752]: loss 2.384375
[epoch20, step753]: loss 0.878596
[epoch20, step754]: loss 8.354014
[epoch20, step755]: loss 6.990920
[epoch20, step756]: loss 0.637962
[epoch20, step757]: loss 2.070023
[epoch20, step758]: loss 1.080061
[epoch20, step759]: loss 2.228747
[epoch20, step760]: loss 6.798481
[epoch20, step761]: loss 3.109477
[epoch20, step762]: loss 1.862226
[epoch20, step763]: loss 1.196838
[epoch20, step764]: loss 7.131540
[epoch20, step765]: loss 2.640216
[epoch20, step766]: loss 15.929831
[epoch20, step767]: loss 1.287807
[epoch20, step768]: loss 9.778201
[epoch20, step769]: loss 0.739481
[epoch20, step770]: loss 7.516054
[epoch20, step771]: loss 1.588966
[epoch20, step772]: loss 0.711856
[epoch20, step773]: loss 0.840381
[epoch20, step774]: loss 1.842591
[epoch20, step775]: loss 0.937603
[epoch20, step776]: loss 2.112173
[epoch20, step777]: loss 2.372011
[epoch20, step778]: loss 1.714713
[epoch20, step779]: loss 2.020978
[epoch20, step780]: loss 19.511885
[epoch20, step781]: loss 3.386230
[epoch20, step782]: loss 3.089172
[epoch20, step783]: loss 0.653346
[epoch20, step784]: loss 1.296613
[epoch20, step785]: loss 0.665857
[epoch20, step786]: loss 0.751059
[epoch20, step787]: loss 1.649345
[epoch20, step788]: loss 0.746019
[epoch20, step789]: loss 0.719305
[epoch20, step790]: loss 0.906030
[epoch20, step791]: loss 0.771162
[epoch20, step792]: loss 3.067606
[epoch20, step793]: loss 1.555043
[epoch20, step794]: loss 14.165465
[epoch20, step795]: loss 0.596859
[epoch20, step796]: loss 0.784967
[epoch20, step797]: loss 2.896489
[epoch20, step798]: loss 3.306386
[epoch20, step799]: loss 0.537059
[epoch20, step800]: loss 1.462247
[epoch20, step801]: loss 8.367232
[epoch20, step802]: loss 6.816964
[epoch20, step803]: loss 1.485765
[epoch20, step804]: loss 0.943421
[epoch20, step805]: loss 1.075188
[epoch20, step806]: loss 2.347300
[epoch20, step807]: loss 1.860532
[epoch20, step808]: loss 2.018587
[epoch20, step809]: loss 4.300150
[epoch20, step810]: loss 0.701974
[epoch20, step811]: loss 0.591483
[epoch20, step812]: loss 0.758773
[epoch20, step813]: loss 1.036483
[epoch20, step814]: loss 2.468910
[epoch20, step815]: loss 1.007161
[epoch20, step816]: loss 3.375141
[epoch20, step817]: loss 7.887652
[epoch20, step818]: loss 0.736005
[epoch20, step819]: loss 1.118806
[epoch20, step820]: loss 6.284089
[epoch20, step821]: loss 1.775948
[epoch20, step822]: loss 2.171715
[epoch20, step823]: loss 1.457384
[epoch20, step824]: loss 0.776148
[epoch20, step825]: loss 2.954037
[epoch20, step826]: loss 0.773076
[epoch20, step827]: loss 0.586379
[epoch20, step828]: loss 0.778832
[epoch20, step829]: loss 0.808886
[epoch20, step830]: loss 0.661154
[epoch20, step831]: loss 2.807097
[epoch20, step832]: loss 2.613188
[epoch20, step833]: loss 8.803818
[epoch20, step834]: loss 0.488704
[epoch20, step835]: loss 8.577698
[epoch20, step836]: loss 2.511173
[epoch20, step837]: loss 0.607799
[epoch20, step838]: loss 1.662016
[epoch20, step839]: loss 0.881050
[epoch20, step840]: loss 26.562824
[epoch20, step841]: loss 1.297167
[epoch20, step842]: loss 1.050601
[epoch20, step843]: loss 3.296642
[epoch20, step844]: loss 1.223118
[epoch20, step845]: loss 1.420685
[epoch20, step846]: loss 3.253362
[epoch20, step847]: loss 4.142308
[epoch20, step848]: loss 2.078237
[epoch20, step849]: loss 3.206070
[epoch20, step850]: loss 0.734690
[epoch20, step851]: loss 2.108127
[epoch20, step852]: loss 1.492174
[epoch20, step853]: loss 3.608976
[epoch20, step854]: loss 10.422659
[epoch20, step855]: loss 0.706610
[epoch20, step856]: loss 7.989828
[epoch20, step857]: loss 3.899727
[epoch20, step858]: loss 1.496927
[epoch20, step859]: loss 3.273445
[epoch20, step860]: loss 11.320818
[epoch20, step861]: loss 6.984346
[epoch20, step862]: loss 0.828147
[epoch20, step863]: loss 0.858671
[epoch20, step864]: loss 0.513831
[epoch20, step865]: loss 4.583075
[epoch20, step866]: loss 1.023357
[epoch20, step867]: loss 0.792712
[epoch20, step868]: loss 0.860512
[epoch20, step869]: loss 0.673274
[epoch20, step870]: loss 5.078860
[epoch20, step871]: loss 0.900079
[epoch20, step872]: loss 1.001266
[epoch20, step873]: loss 1.568059
[epoch20, step874]: loss 1.439619
[epoch20, step875]: loss 2.965899
[epoch20, step876]: loss 5.144454
[epoch20, step877]: loss 0.974354
[epoch20, step878]: loss 1.274422
[epoch20, step879]: loss 10.176149
[epoch20, step880]: loss 1.382647
[epoch20, step881]: loss 10.137290
[epoch20, step882]: loss 1.570071
[epoch20, step883]: loss 0.646885
[epoch20, step884]: loss 23.785595
[epoch20, step885]: loss 0.953916
[epoch20, step886]: loss 1.100063
[epoch20, step887]: loss 2.293902
[epoch20, step888]: loss 1.562338
[epoch20, step889]: loss 0.796773
[epoch20, step890]: loss 3.446972
[epoch20, step891]: loss 1.078590
[epoch20, step892]: loss 0.601564
[epoch20, step893]: loss 3.267026
[epoch20, step894]: loss 3.795474
[epoch20, step895]: loss 0.671379
[epoch20, step896]: loss 6.217405
[epoch20, step897]: loss 2.677373
[epoch20, step898]: loss 1.019454
[epoch20, step899]: loss 8.760221
[epoch20, step900]: loss 0.838081
[epoch20, step901]: loss 1.381473
[epoch20, step902]: loss 1.312502
[epoch20, step903]: loss 0.509536
[epoch20, step904]: loss 6.619039
[epoch20, step905]: loss 13.662913
[epoch20, step906]: loss 9.077212
[epoch20, step907]: loss 0.664599
[epoch20, step908]: loss 5.635696
[epoch20, step909]: loss 2.202994
[epoch20, step910]: loss 1.437167
[epoch20, step911]: loss 8.421316
[epoch20, step912]: loss 0.826937
[epoch20, step913]: loss 1.787416
[epoch20, step914]: loss 2.087171
[epoch20, step915]: loss 2.711467
[epoch20, step916]: loss 3.067456
[epoch20, step917]: loss 1.557088
[epoch20, step918]: loss 2.356465
[epoch20, step919]: loss 1.154783
[epoch20, step920]: loss 0.986187
[epoch20, step921]: loss 10.668486
[epoch20, step922]: loss 1.287460
[epoch20, step923]: loss 5.518711
[epoch20, step924]: loss 0.937603
[epoch20, step925]: loss 6.636130
[epoch20, step926]: loss 10.758693
[epoch20, step927]: loss 0.997047
[epoch20, step928]: loss 7.885597
[epoch20, step929]: loss 1.678726
[epoch20, step930]: loss 0.861192
[epoch20, step931]: loss 0.699708
[epoch20, step932]: loss 0.619562
[epoch20, step933]: loss 1.405515
[epoch20, step934]: loss 1.887097
[epoch20, step935]: loss 1.294680
[epoch20, step936]: loss 0.861835
[epoch20, step937]: loss 0.510511
[epoch20, step938]: loss 3.110121
[epoch20, step939]: loss 9.882983
[epoch20, step940]: loss 5.846345
[epoch20, step941]: loss 0.810399
[epoch20, step942]: loss 1.250803
[epoch20, step943]: loss 0.862614
[epoch20, step944]: loss 1.099937
[epoch20, step945]: loss 0.883621
[epoch20, step946]: loss 1.482465
[epoch20, step947]: loss 0.522594
[epoch20, step948]: loss 0.569377
[epoch20, step949]: loss 1.102271
[epoch20, step950]: loss 7.181147
[epoch20, step951]: loss 1.161153
[epoch20, step952]: loss 1.147837
[epoch20, step953]: loss 7.613296
[epoch20, step954]: loss 0.681105
[epoch20, step955]: loss 7.499279
[epoch20, step956]: loss 12.492540
[epoch20, step957]: loss 9.463852
[epoch20, step958]: loss 9.841269
[epoch20, step959]: loss 3.757050
[epoch20, step960]: loss 0.976026
[epoch20, step961]: loss 1.685339
[epoch20, step962]: loss 1.408975
[epoch20, step963]: loss 1.728521
[epoch20, step964]: loss 1.221935
[epoch20, step965]: loss 21.465416
[epoch20, step966]: loss 2.242400
[epoch20, step967]: loss 6.164949
[epoch20, step968]: loss 1.354913
[epoch20, step969]: loss 1.855708
[epoch20, step970]: loss 0.628874
[epoch20, step971]: loss 1.556455
[epoch20, step972]: loss 6.233665
[epoch20, step973]: loss 4.038306
[epoch20, step974]: loss 1.696417
[epoch20, step975]: loss 0.572415
[epoch20, step976]: loss 2.404705
[epoch20, step977]: loss 5.334463
[epoch20, step978]: loss 1.964736
[epoch20, step979]: loss 3.542198
[epoch20, step980]: loss 3.194418
[epoch20, step981]: loss 5.585881
[epoch20, step982]: loss 5.869060
[epoch20, step983]: loss 22.076509
[epoch20, step984]: loss 0.694126
[epoch20, step985]: loss 1.011882
[epoch20, step986]: loss 11.624775
[epoch20, step987]: loss 1.438311
[epoch20, step988]: loss 0.538998
[epoch20, step989]: loss 1.151973
[epoch20, step990]: loss 2.100372
[epoch20, step991]: loss 3.396942
[epoch20, step992]: loss 4.828216
[epoch20, step993]: loss 0.522731
[epoch20, step994]: loss 0.562611
[epoch20, step995]: loss 2.555204
[epoch20, step996]: loss 1.175000
[epoch20, step997]: loss 2.128631
[epoch20, step998]: loss 1.215447
[epoch20, step999]: loss 0.821421
[epoch20, step1000]: loss 0.994121
[epoch20, step1001]: loss 1.190282
[epoch20, step1002]: loss 14.538395
[epoch20, step1003]: loss 2.139752
[epoch20, step1004]: loss 6.050928
[epoch20, step1005]: loss 1.546063
[epoch20, step1006]: loss 1.034865
[epoch20, step1007]: loss 2.899084
[epoch20, step1008]: loss 1.773857
[epoch20, step1009]: loss 0.935149
[epoch20, step1010]: loss 0.639486
[epoch20, step1011]: loss 7.275251
[epoch20, step1012]: loss 2.732181
[epoch20, step1013]: loss 1.891881
[epoch20, step1014]: loss 30.039194
[epoch20, step1015]: loss 3.555385
[epoch20, step1016]: loss 0.844275
[epoch20, step1017]: loss 3.785532
[epoch20, step1018]: loss 1.405938
[epoch20, step1019]: loss 1.212248
[epoch20, step1020]: loss 1.334539
[epoch20, step1021]: loss 1.217601
[epoch20, step1022]: loss 5.117520
[epoch20, step1023]: loss 1.749695
[epoch20, step1024]: loss 2.327975
[epoch20, step1025]: loss 3.813339
[epoch20, step1026]: loss 6.016963
[epoch20, step1027]: loss 4.795779
[epoch20, step1028]: loss 3.952816
[epoch20, step1029]: loss 2.042011
[epoch20, step1030]: loss 1.751289
[epoch20, step1031]: loss 2.409648
[epoch20, step1032]: loss 0.498742
[epoch20, step1033]: loss 1.496341
[epoch20, step1034]: loss 1.667899
[epoch20, step1035]: loss 1.092128
[epoch20, step1036]: loss 0.796835
[epoch20, step1037]: loss 0.633263
[epoch20, step1038]: loss 0.571325
[epoch20, step1039]: loss 7.118089
[epoch20, step1040]: loss 7.904116
[epoch20, step1041]: loss 2.132175
[epoch20, step1042]: loss 1.912866
[epoch20, step1043]: loss 6.193371
[epoch20, step1044]: loss 0.747946
[epoch20, step1045]: loss 7.296671
[epoch20, step1046]: loss 0.691785
[epoch20, step1047]: loss 1.851617
[epoch20, step1048]: loss 2.685308
[epoch20, step1049]: loss 1.094767
[epoch20, step1050]: loss 1.599081
[epoch20, step1051]: loss 1.370675
[epoch20, step1052]: loss 9.899796
[epoch20, step1053]: loss 0.856875
[epoch20, step1054]: loss 0.910821
[epoch20, step1055]: loss 0.652768
[epoch20, step1056]: loss 1.182573
[epoch20, step1057]: loss 15.506963
[epoch20, step1058]: loss 7.661827
[epoch20, step1059]: loss 1.026331
[epoch20, step1060]: loss 5.879722
[epoch20, step1061]: loss 2.329595
[epoch20, step1062]: loss 3.956871
[epoch20, step1063]: loss 2.239267
[epoch20, step1064]: loss 0.703732
[epoch20, step1065]: loss 1.668364
[epoch20, step1066]: loss 0.866314
[epoch20, step1067]: loss 3.311604
[epoch20, step1068]: loss 0.476988
[epoch20, step1069]: loss 1.194714
[epoch20, step1070]: loss 2.733483
[epoch20, step1071]: loss 1.173117
[epoch20, step1072]: loss 1.460290
[epoch20, step1073]: loss 8.912980
[epoch20, step1074]: loss 0.522708
[epoch20, step1075]: loss 1.124534
[epoch20, step1076]: loss 0.975067
[epoch20, step1077]: loss 0.760577
[epoch20, step1078]: loss 0.822445
[epoch20, step1079]: loss 0.904576
[epoch20, step1080]: loss 0.990984
[epoch20, step1081]: loss 1.359753
[epoch20, step1082]: loss 0.712456
[epoch20, step1083]: loss 2.268648
[epoch20, step1084]: loss 0.912485
[epoch20, step1085]: loss 0.697290
[epoch20, step1086]: loss 10.359070
[epoch20, step1087]: loss 6.050905
[epoch20, step1088]: loss 1.256819
[epoch20, step1089]: loss 9.815174
[epoch20, step1090]: loss 8.037257
[epoch20, step1091]: loss 1.942947
[epoch20, step1092]: loss 0.897275
[epoch20, step1093]: loss 1.147281
[epoch20, step1094]: loss 7.751871
[epoch20, step1095]: loss 1.915745
[epoch20, step1096]: loss 0.721712
[epoch20, step1097]: loss 1.176112
[epoch20, step1098]: loss 6.643771
[epoch20, step1099]: loss 1.344034
[epoch20, step1100]: loss 3.535389
[epoch20, step1101]: loss 5.714216
[epoch20, step1102]: loss 0.499089
[epoch20, step1103]: loss 0.923170
[epoch20, step1104]: loss 2.621937
[epoch20, step1105]: loss 1.967181
[epoch20, step1106]: loss 0.603773
[epoch20, step1107]: loss 0.940709
[epoch20, step1108]: loss 0.826443
[epoch20, step1109]: loss 1.540234
[epoch20, step1110]: loss 2.234656
[epoch20, step1111]: loss 0.890228
[epoch20, step1112]: loss 0.945725
[epoch20, step1113]: loss 10.188666
[epoch20, step1114]: loss 2.001450
[epoch20, step1115]: loss 9.769160
[epoch20, step1116]: loss 0.543691
[epoch20, step1117]: loss 1.024334
[epoch20, step1118]: loss 1.090341
[epoch20, step1119]: loss 1.487578
[epoch20, step1120]: loss 2.403063
[epoch20, step1121]: loss 7.124443
[epoch20, step1122]: loss 1.890823
[epoch20, step1123]: loss 1.318432
[epoch20, step1124]: loss 4.222925
[epoch20, step1125]: loss 1.038039
[epoch20, step1126]: loss 1.889418
[epoch20, step1127]: loss 1.605137
[epoch20, step1128]: loss 4.123910
[epoch20, step1129]: loss 0.977342
[epoch20, step1130]: loss 0.908735
[epoch20, step1131]: loss 0.657287
[epoch20, step1132]: loss 2.750060
[epoch20, step1133]: loss 7.128405
[epoch20, step1134]: loss 0.987807
[epoch20, step1135]: loss 26.811703
[epoch20, step1136]: loss 1.068060
[epoch20, step1137]: loss 2.487986
[epoch20, step1138]: loss 1.082100
[epoch20, step1139]: loss 2.065674
[epoch20, step1140]: loss 2.154488
[epoch20, step1141]: loss 1.989979
[epoch20, step1142]: loss 0.738306
[epoch20, step1143]: loss 0.813468
[epoch20, step1144]: loss 2.603824
[epoch20, step1145]: loss 1.488703
[epoch20, step1146]: loss 0.483033
[epoch20, step1147]: loss 0.579621
[epoch20, step1148]: loss 0.783400
[epoch20, step1149]: loss 2.262967
[epoch20, step1150]: loss 2.788257
[epoch20, step1151]: loss 0.944728
[epoch20, step1152]: loss 0.944570
[epoch20, step1153]: loss 1.228936
[epoch20, step1154]: loss 5.580798
[epoch20, step1155]: loss 1.586012
[epoch20, step1156]: loss 1.435890
[epoch20, step1157]: loss 0.789454
[epoch20, step1158]: loss 0.573167
[epoch20, step1159]: loss 0.965019
[epoch20, step1160]: loss 1.570215
[epoch20, step1161]: loss 4.159551
[epoch20, step1162]: loss 0.756642
[epoch20, step1163]: loss 6.517130
[epoch20, step1164]: loss 7.927019
[epoch20, step1165]: loss 0.566998
[epoch20, step1166]: loss 1.323743
[epoch20, step1167]: loss 1.843034
[epoch20, step1168]: loss 0.819526
[epoch20, step1169]: loss 0.954010
[epoch20, step1170]: loss 2.382262
[epoch20, step1171]: loss 3.043153
[epoch20, step1172]: loss 0.861602
[epoch20, step1173]: loss 1.324646
[epoch20, step1174]: loss 1.357915
[epoch20, step1175]: loss 0.997779
[epoch20, step1176]: loss 1.867271
[epoch20, step1177]: loss 0.689539
[epoch20, step1178]: loss 1.069748
[epoch20, step1179]: loss 7.000807
[epoch20, step1180]: loss 0.875008
[epoch20, step1181]: loss 1.110597
[epoch20, step1182]: loss 2.709500
[epoch20, step1183]: loss 6.110985
[epoch20, step1184]: loss 1.722196
[epoch20, step1185]: loss 9.049167
[epoch20, step1186]: loss 1.417527
[epoch20, step1187]: loss 0.747120
[epoch20, step1188]: loss 3.159585
[epoch20, step1189]: loss 7.343479
[epoch20, step1190]: loss 5.865545
[epoch20, step1191]: loss 3.149826
[epoch20, step1192]: loss 1.785696
[epoch20, step1193]: loss 2.565165
[epoch20, step1194]: loss 0.712166
[epoch20, step1195]: loss 0.965176
[epoch20, step1196]: loss 0.702498
[epoch20, step1197]: loss 0.975313
[epoch20, step1198]: loss 23.727833
[epoch20, step1199]: loss 3.377717
[epoch20, step1200]: loss 1.187669
[epoch20, step1201]: loss 1.204099
[epoch20, step1202]: loss 0.753127
[epoch20, step1203]: loss 0.474515
[epoch20, step1204]: loss 5.375434
[epoch20, step1205]: loss 7.213590
[epoch20, step1206]: loss 0.827145
[epoch20, step1207]: loss 4.600994
[epoch20, step1208]: loss 5.469505
[epoch20, step1209]: loss 0.827510
[epoch20, step1210]: loss 0.945737
[epoch20, step1211]: loss 1.497057
[epoch20, step1212]: loss 1.522926
[epoch20, step1213]: loss 7.821204
[epoch20, step1214]: loss 0.515585
[epoch20, step1215]: loss 0.801694
[epoch20, step1216]: loss 2.010490
[epoch20, step1217]: loss 0.913036
[epoch20, step1218]: loss 2.298516
[epoch20, step1219]: loss 12.328134
[epoch20, step1220]: loss 1.889843
[epoch20, step1221]: loss 9.194094
[epoch20, step1222]: loss 31.596914
[epoch20, step1223]: loss 3.786046
[epoch20, step1224]: loss 0.817803
[epoch20, step1225]: loss 0.582617
[epoch20, step1226]: loss 5.091973
[epoch20, step1227]: loss 2.027715
[epoch20, step1228]: loss 0.759930
[epoch20, step1229]: loss 1.293685
[epoch20, step1230]: loss 3.262268
[epoch20, step1231]: loss 2.525574
[epoch20, step1232]: loss 14.610156
[epoch20, step1233]: loss 1.171772
[epoch20, step1234]: loss 0.577578
[epoch20, step1235]: loss 8.921737
[epoch20, step1236]: loss 2.521512
[epoch20, step1237]: loss 1.210468
[epoch20, step1238]: loss 0.583144
[epoch20, step1239]: loss 0.711231
[epoch20, step1240]: loss 1.355580
[epoch20, step1241]: loss 2.365828
[epoch20, step1242]: loss 0.848091
[epoch20, step1243]: loss 9.209848
[epoch20, step1244]: loss 0.838406
[epoch20, step1245]: loss 1.098789
[epoch20, step1246]: loss 0.634852
[epoch20, step1247]: loss 1.296703
[epoch20, step1248]: loss 0.954644
[epoch20, step1249]: loss 0.791606
[epoch20, step1250]: loss 2.511864
[epoch20, step1251]: loss 1.164149
[epoch20, step1252]: loss 8.520524
[epoch20, step1253]: loss 5.894333
[epoch20, step1254]: loss 2.326668
[epoch20, step1255]: loss 1.530087
[epoch20, step1256]: loss 9.357119
[epoch20, step1257]: loss 1.350355
[epoch20, step1258]: loss 1.321007
[epoch20, step1259]: loss 0.789663
[epoch20, step1260]: loss 1.582850
[epoch20, step1261]: loss 0.971463
[epoch20, step1262]: loss 0.960908
[epoch20, step1263]: loss 0.982854
[epoch20, step1264]: loss 5.870543
[epoch20, step1265]: loss 2.926792
[epoch20, step1266]: loss 1.206797
[epoch20, step1267]: loss 0.934991
[epoch20, step1268]: loss 0.730102
[epoch20, step1269]: loss 2.889945
[epoch20, step1270]: loss 0.762443
[epoch20, step1271]: loss 0.470057
[epoch20, step1272]: loss 8.108669
[epoch20, step1273]: loss 4.195339
[epoch20, step1274]: loss 10.921297
[epoch20, step1275]: loss 1.287847
[epoch20, step1276]: loss 2.105089
[epoch20, step1277]: loss 11.367903
[epoch20, step1278]: loss 7.121574
[epoch20, step1279]: loss 0.763751
[epoch20, step1280]: loss 12.139297
[epoch20, step1281]: loss 0.701286
[epoch20, step1282]: loss 1.889289
[epoch20, step1283]: loss 8.521909
[epoch20, step1284]: loss 0.733092
[epoch20, step1285]: loss 2.481921
[epoch20, step1286]: loss 6.860276
[epoch20, step1287]: loss 0.773555
[epoch20, step1288]: loss 0.826163
[epoch20, step1289]: loss 1.273501
[epoch20, step1290]: loss 5.660488
[epoch20, step1291]: loss 1.062443
[epoch20, step1292]: loss 2.926579
[epoch20, step1293]: loss 7.047709
[epoch20, step1294]: loss 0.716379
[epoch20, step1295]: loss 1.832294
[epoch20, step1296]: loss 3.543820
[epoch20, step1297]: loss 4.329345
[epoch20, step1298]: loss 0.841096
[epoch20, step1299]: loss 2.291715
[epoch20, step1300]: loss 0.750238
[epoch20, step1301]: loss 1.858587
[epoch20, step1302]: loss 0.729662
[epoch20, step1303]: loss 0.899793
[epoch20, step1304]: loss 2.423181
[epoch20, step1305]: loss 10.208496
[epoch20, step1306]: loss 2.422112
[epoch20, step1307]: loss 4.572711
[epoch20, step1308]: loss 0.693130
[epoch20, step1309]: loss 12.850855
[epoch20, step1310]: loss 4.776333
[epoch20, step1311]: loss 0.776015
[epoch20, step1312]: loss 1.986212
[epoch20, step1313]: loss 0.978015
[epoch20, step1314]: loss 4.636376
[epoch20, step1315]: loss 0.908340
[epoch20, step1316]: loss 1.549527
[epoch20, step1317]: loss 1.166551
[epoch20, step1318]: loss 0.758746
[epoch20, step1319]: loss 4.639645
[epoch20, step1320]: loss 1.478945
[epoch20, step1321]: loss 1.056195
[epoch20, step1322]: loss 0.628072
[epoch20, step1323]: loss 1.656607
[epoch20, step1324]: loss 1.526671
[epoch20, step1325]: loss 5.736197
[epoch20, step1326]: loss 2.352505
[epoch20, step1327]: loss 1.201066
[epoch20, step1328]: loss 1.541461
[epoch20, step1329]: loss 1.516598
[epoch20, step1330]: loss 2.261049
[epoch20, step1331]: loss 0.703787
[epoch20, step1332]: loss 2.423189
[epoch20, step1333]: loss 7.376624
[epoch20, step1334]: loss 0.931937
[epoch20, step1335]: loss 4.811272
[epoch20, step1336]: loss 0.923988
[epoch20, step1337]: loss 0.665868
[epoch20, step1338]: loss 0.495843
[epoch20, step1339]: loss 0.735126
[epoch20, step1340]: loss 8.985065
[epoch20, step1341]: loss 1.539977
[epoch20, step1342]: loss 2.049417
[epoch20, step1343]: loss 1.858303
[epoch20, step1344]: loss 13.329679
[epoch20, step1345]: loss 5.633812
[epoch20, step1346]: loss 1.455958
[epoch20, step1347]: loss 2.461295
[epoch20, step1348]: loss 0.714877
[epoch20, step1349]: loss 0.521756
[epoch20, step1350]: loss 18.393501
[epoch20, step1351]: loss 1.243415
[epoch20, step1352]: loss 12.437468
[epoch20, step1353]: loss 2.063903
[epoch20, step1354]: loss 4.990734
[epoch20, step1355]: loss 1.442656
[epoch20, step1356]: loss 4.558175
[epoch20, step1357]: loss 1.560470
[epoch20, step1358]: loss 13.340526
[epoch20, step1359]: loss 6.683505
[epoch20, step1360]: loss 0.832573
[epoch20, step1361]: loss 0.702934
[epoch20, step1362]: loss 3.045062
[epoch20, step1363]: loss 16.708174
[epoch20, step1364]: loss 1.849716
[epoch20, step1365]: loss 1.119812
[epoch20, step1366]: loss 0.626619
[epoch20, step1367]: loss 9.662652
[epoch20, step1368]: loss 0.394380
[epoch20, step1369]: loss 0.935156
[epoch20, step1370]: loss 1.029602
[epoch20, step1371]: loss 1.114441
[epoch20, step1372]: loss 1.623791
[epoch20, step1373]: loss 0.827488
[epoch20, step1374]: loss 0.870808
[epoch20, step1375]: loss 1.133472
[epoch20, step1376]: loss 8.378901
[epoch20, step1377]: loss 19.083075
[epoch20, step1378]: loss 0.968334
[epoch20, step1379]: loss 0.806861
[epoch20, step1380]: loss 2.078355
[epoch20, step1381]: loss 1.216290
[epoch20, step1382]: loss 1.195269
[epoch20, step1383]: loss 7.524914
[epoch20, step1384]: loss 12.708882
[epoch20, step1385]: loss 0.649066
[epoch20, step1386]: loss 1.024464
[epoch20, step1387]: loss 1.124622
[epoch20, step1388]: loss 14.893287
[epoch20, step1389]: loss 0.869979
[epoch20, step1390]: loss 0.864420
[epoch20, step1391]: loss 3.371201
[epoch20, step1392]: loss 6.345488
[epoch20, step1393]: loss 1.124895
[epoch20, step1394]: loss 1.310386
[epoch20, step1395]: loss 0.764712
[epoch20, step1396]: loss 0.975894
[epoch20, step1397]: loss 3.001180
[epoch20, step1398]: loss 1.938975
[epoch20, step1399]: loss 1.851980
[epoch20, step1400]: loss 0.791318
[epoch20, step1401]: loss 0.487682
[epoch20, step1402]: loss 0.774466
[epoch20, step1403]: loss 1.154227
[epoch20, step1404]: loss 15.517351
[epoch20, step1405]: loss 0.898564
[epoch20, step1406]: loss 5.008226
[epoch20, step1407]: loss 1.346810
[epoch20, step1408]: loss 7.239697
[epoch20, step1409]: loss 1.481922
[epoch20, step1410]: loss 9.591256
[epoch20, step1411]: loss 1.517771
[epoch20, step1412]: loss 1.139017
[epoch20, step1413]: loss 3.543467
[epoch20, step1414]: loss 2.154607
[epoch20, step1415]: loss 0.648266
[epoch20, step1416]: loss 1.766280
[epoch20, step1417]: loss 6.732613
[epoch20, step1418]: loss 9.484689
[epoch20, step1419]: loss 2.391848
[epoch20, step1420]: loss 0.877134
[epoch20, step1421]: loss 16.580416
[epoch20, step1422]: loss 1.444779
[epoch20, step1423]: loss 1.379708
[epoch20, step1424]: loss 0.961905
[epoch20, step1425]: loss 0.783068
[epoch20, step1426]: loss 9.571566
[epoch20, step1427]: loss 2.900838
[epoch20, step1428]: loss 0.706934
[epoch20, step1429]: loss 2.076305
[epoch20, step1430]: loss 6.007134
[epoch20, step1431]: loss 1.667083
[epoch20, step1432]: loss 1.938643
[epoch20, step1433]: loss 1.242259
[epoch20, step1434]: loss 3.666542
[epoch20, step1435]: loss 1.824621
[epoch20, step1436]: loss 2.134960
[epoch20, step1437]: loss 1.832729
[epoch20, step1438]: loss 0.541053
[epoch20, step1439]: loss 1.023092
[epoch20, step1440]: loss 1.303094
[epoch20, step1441]: loss 1.012839
[epoch20, step1442]: loss 8.391499
[epoch20, step1443]: loss 2.373713
[epoch20, step1444]: loss 0.687807
[epoch20, step1445]: loss 1.957232
[epoch20, step1446]: loss 7.455997
[epoch20, step1447]: loss 1.118890
[epoch20, step1448]: loss 1.731406
[epoch20, step1449]: loss 1.535611
[epoch20, step1450]: loss 2.393952
[epoch20, step1451]: loss 10.694172
[epoch20, step1452]: loss 1.596126
[epoch20, step1453]: loss 0.545765
[epoch20, step1454]: loss 2.557842
[epoch20, step1455]: loss 1.524255
[epoch20, step1456]: loss 2.198248
[epoch20, step1457]: loss 2.642208
[epoch20, step1458]: loss 0.731081
[epoch20, step1459]: loss 16.211264
[epoch20, step1460]: loss 8.197817
[epoch20, step1461]: loss 2.436400
[epoch20, step1462]: loss 1.696718
[epoch20, step1463]: loss 10.670945
[epoch20, step1464]: loss 6.830438
[epoch20, step1465]: loss 1.534056
[epoch20, step1466]: loss 0.616032
[epoch20, step1467]: loss 1.532347
[epoch20, step1468]: loss 0.934999
[epoch20, step1469]: loss 11.693359
[epoch20, step1470]: loss 1.983305
[epoch20, step1471]: loss 1.441390
[epoch20, step1472]: loss 0.877363
[epoch20, step1473]: loss 8.244720
[epoch20, step1474]: loss 2.548471
[epoch20, step1475]: loss 0.893914
[epoch20, step1476]: loss 2.976830
[epoch20, step1477]: loss 7.436391
[epoch20, step1478]: loss 1.105731
[epoch20, step1479]: loss 1.424527
[epoch20, step1480]: loss 3.255110
[epoch20, step1481]: loss 1.359788
[epoch20, step1482]: loss 3.724071
[epoch20, step1483]: loss 1.936305
[epoch20, step1484]: loss 0.554238
[epoch20, step1485]: loss 1.574078
[epoch20, step1486]: loss 1.473698
[epoch20, step1487]: loss 1.632055
[epoch20, step1488]: loss 0.743290
[epoch20, step1489]: loss 2.304634
[epoch20, step1490]: loss 2.287184
[epoch20, step1491]: loss 0.788417
[epoch20, step1492]: loss 2.763059
[epoch20, step1493]: loss 0.971942
[epoch20, step1494]: loss 7.666473
[epoch20, step1495]: loss 0.807976
[epoch20, step1496]: loss 2.594109
[epoch20, step1497]: loss 2.502710
[epoch20, step1498]: loss 8.905364
[epoch20, step1499]: loss 2.288646
[epoch20, step1500]: loss 7.372886
[epoch20, step1501]: loss 0.773762
[epoch20, step1502]: loss 2.299689
[epoch20, step1503]: loss 0.650406
[epoch20, step1504]: loss 2.043522
[epoch20, step1505]: loss 0.615573
[epoch20, step1506]: loss 1.386205
[epoch20, step1507]: loss 7.314813
[epoch20, step1508]: loss 2.068863
[epoch20, step1509]: loss 1.137027
[epoch20, step1510]: loss 0.550916
[epoch20, step1511]: loss 1.012060
[epoch20, step1512]: loss 7.991221
[epoch20, step1513]: loss 1.402714
[epoch20, step1514]: loss 1.593629
[epoch20, step1515]: loss 2.259995
[epoch20, step1516]: loss 0.533000
[epoch20, step1517]: loss 5.942237
[epoch20, step1518]: loss 3.996612
[epoch20, step1519]: loss 5.025007
[epoch20, step1520]: loss 0.944276
[epoch20, step1521]: loss 13.707482
[epoch20, step1522]: loss 5.589860
[epoch20, step1523]: loss 0.663873
[epoch20, step1524]: loss 0.930957
[epoch20, step1525]: loss 5.024279
[epoch20, step1526]: loss 0.911861
[epoch20, step1527]: loss 25.430698
[epoch20, step1528]: loss 9.205865
[epoch20, step1529]: loss 0.642957
[epoch20, step1530]: loss 1.043760
[epoch20, step1531]: loss 5.888372
[epoch20, step1532]: loss 8.050253
[epoch20, step1533]: loss 13.332700
[epoch20, step1534]: loss 8.612791
[epoch20, step1535]: loss 0.977715
[epoch20, step1536]: loss 0.730470
[epoch20, step1537]: loss 1.421890
[epoch20, step1538]: loss 19.956356
[epoch20, step1539]: loss 11.964489
[epoch20, step1540]: loss 1.734905
[epoch20, step1541]: loss 0.890454
[epoch20, step1542]: loss 0.595804
[epoch20, step1543]: loss 0.702924
[epoch20, step1544]: loss 1.358447
[epoch20, step1545]: loss 2.112921
[epoch20, step1546]: loss 1.071784
[epoch20, step1547]: loss 13.008856
[epoch20, step1548]: loss 5.851050
[epoch20, step1549]: loss 1.850156
[epoch20, step1550]: loss 1.731644
[epoch20, step1551]: loss 2.050657
[epoch20, step1552]: loss 0.868167
[epoch20, step1553]: loss 1.868586
[epoch20, step1554]: loss 1.513527
[epoch20, step1555]: loss 14.509230
[epoch20, step1556]: loss 0.619594
[epoch20, step1557]: loss 1.023361
[epoch20, step1558]: loss 1.460044
[epoch20, step1559]: loss 1.415970
[epoch20, step1560]: loss 8.158314
[epoch20, step1561]: loss 1.337352
[epoch20, step1562]: loss 0.828198
[epoch20, step1563]: loss 2.351819
[epoch20, step1564]: loss 1.293204
[epoch20, step1565]: loss 1.168991
[epoch20, step1566]: loss 1.055915
[epoch20, step1567]: loss 0.973979
[epoch20, step1568]: loss 47.401718
[epoch20, step1569]: loss 0.655617
[epoch20, step1570]: loss 0.708640
[epoch20, step1571]: loss 1.365967
[epoch20, step1572]: loss 1.346434
[epoch20, step1573]: loss 0.999250
[epoch20, step1574]: loss 8.390728
[epoch20, step1575]: loss 1.954354
[epoch20, step1576]: loss 2.065040
[epoch20, step1577]: loss 1.343284
[epoch20, step1578]: loss 0.915483
[epoch20, step1579]: loss 1.233270
[epoch20, step1580]: loss 1.787991
[epoch20, step1581]: loss 0.917662
[epoch20, step1582]: loss 0.780935
[epoch20, step1583]: loss 1.992358
[epoch20, step1584]: loss 0.842656
[epoch20, step1585]: loss 1.043232
[epoch20, step1586]: loss 3.753235
[epoch20, step1587]: loss 15.326605
[epoch20, step1588]: loss 0.679090
[epoch20, step1589]: loss 1.955176
[epoch20, step1590]: loss 1.574506
[epoch20, step1591]: loss 10.653831
[epoch20, step1592]: loss 0.801937
[epoch20, step1593]: loss 2.926215
[epoch20, step1594]: loss 9.208021
[epoch20, step1595]: loss 1.511135
[epoch20, step1596]: loss 1.583597
[epoch20, step1597]: loss 1.504730
[epoch20, step1598]: loss 7.941332
[epoch20, step1599]: loss 5.577857
[epoch20, step1600]: loss 8.991869
[epoch20, step1601]: loss 0.825543
[epoch20, step1602]: loss 1.024360
[epoch20, step1603]: loss 0.769578
[epoch20, step1604]: loss 0.992217
[epoch20, step1605]: loss 0.870483
[epoch20, step1606]: loss 6.797771
[epoch20, step1607]: loss 5.490636
[epoch20, step1608]: loss 1.287700
[epoch20, step1609]: loss 1.499093
[epoch20, step1610]: loss 1.114314
[epoch20, step1611]: loss 1.023897
[epoch20, step1612]: loss 10.083604
[epoch20, step1613]: loss 4.635957
[epoch20, step1614]: loss 2.963179
[epoch20, step1615]: loss 2.399504
[epoch20, step1616]: loss 0.578451
[epoch20, step1617]: loss 1.094864
[epoch20, step1618]: loss 3.801216
[epoch20, step1619]: loss 8.342234
[epoch20, step1620]: loss 1.465939
[epoch20, step1621]: loss 10.295850
[epoch20, step1622]: loss 1.509626
[epoch20, step1623]: loss 1.309037
[epoch20, step1624]: loss 2.053324
[epoch20, step1625]: loss 0.613546
[epoch20, step1626]: loss 1.423042
[epoch20, step1627]: loss 8.173059
[epoch20, step1628]: loss 9.970879
[epoch20, step1629]: loss 11.073004
[epoch20, step1630]: loss 1.645480
[epoch20, step1631]: loss 7.620431
[epoch20, step1632]: loss 0.635626
[epoch20, step1633]: loss 19.136850
[epoch20, step1634]: loss 1.337574
[epoch20, step1635]: loss 1.136645
[epoch20, step1636]: loss 19.068918
[epoch20, step1637]: loss 2.125398
[epoch20, step1638]: loss 4.249689
[epoch20, step1639]: loss 7.851308
[epoch20, step1640]: loss 4.847761
[epoch20, step1641]: loss 0.890017
[epoch20, step1642]: loss 6.118256
[epoch20, step1643]: loss 3.086221
[epoch20, step1644]: loss 2.706157
[epoch20, step1645]: loss 1.135673
[epoch20, step1646]: loss 0.857127
[epoch20, step1647]: loss 0.441324
[epoch20, step1648]: loss 1.106468
[epoch20, step1649]: loss 0.715694
[epoch20, step1650]: loss 0.866332
[epoch20, step1651]: loss 2.150733
[epoch20, step1652]: loss 3.780694
[epoch20, step1653]: loss 0.890234
[epoch20, step1654]: loss 1.275826
[epoch20, step1655]: loss 1.159835
[epoch20, step1656]: loss 1.038809
[epoch20, step1657]: loss 8.543704
[epoch20, step1658]: loss 19.184273
[epoch20, step1659]: loss 1.071221
[epoch20, step1660]: loss 0.753658
[epoch20, step1661]: loss 0.809572
[epoch20, step1662]: loss 0.585973
[epoch20, step1663]: loss 0.857892
[epoch20, step1664]: loss 4.140446
[epoch20, step1665]: loss 6.452493
[epoch20, step1666]: loss 0.613911
[epoch20, step1667]: loss 1.680821
[epoch20, step1668]: loss 0.976201
[epoch20, step1669]: loss 1.409967
[epoch20, step1670]: loss 3.095516
[epoch20, step1671]: loss 2.735664
[epoch20, step1672]: loss 3.947567
[epoch20, step1673]: loss 1.298587
[epoch20, step1674]: loss 4.038682
[epoch20, step1675]: loss 18.465794
[epoch20, step1676]: loss 4.313042
[epoch20, step1677]: loss 0.652487
[epoch20, step1678]: loss 1.390942
[epoch20, step1679]: loss 0.917251
[epoch20, step1680]: loss 5.756058
[epoch20, step1681]: loss 2.412676
[epoch20, step1682]: loss 0.944103
[epoch20, step1683]: loss 0.735201
[epoch20, step1684]: loss 1.507885
[epoch20, step1685]: loss 0.819001
[epoch20, step1686]: loss 1.845639
[epoch20, step1687]: loss 1.861308
[epoch20, step1688]: loss 3.517522
[epoch20, step1689]: loss 3.480173
[epoch20, step1690]: loss 1.187611
[epoch20, step1691]: loss 2.439653
[epoch20, step1692]: loss 1.734406
[epoch20, step1693]: loss 1.776210
[epoch20, step1694]: loss 2.737783
[epoch20, step1695]: loss 1.546474
[epoch20, step1696]: loss 1.223148
[epoch20, step1697]: loss 12.426260
[epoch20, step1698]: loss 2.332078
[epoch20, step1699]: loss 0.819403
[epoch20, step1700]: loss 7.313730
[epoch20, step1701]: loss 6.957593
[epoch20, step1702]: loss 7.689989
[epoch20, step1703]: loss 18.888508
[epoch20, step1704]: loss 4.195661
[epoch20, step1705]: loss 0.652825
[epoch20, step1706]: loss 3.917423
[epoch20, step1707]: loss 3.346165
[epoch20, step1708]: loss 9.242261
[epoch20, step1709]: loss 3.184560
[epoch20, step1710]: loss 2.325111
[epoch20, step1711]: loss 1.183276
[epoch20, step1712]: loss 1.608726
[epoch20, step1713]: loss 2.788694
[epoch20, step1714]: loss 1.563349
[epoch20, step1715]: loss 0.840490
[epoch20, step1716]: loss 0.614961
[epoch20, step1717]: loss 1.529341
[epoch20, step1718]: loss 4.346558
[epoch20, step1719]: loss 15.715400
[epoch20, step1720]: loss 1.107676
[epoch20, step1721]: loss 0.722426
[epoch20, step1722]: loss 1.950780
[epoch20, step1723]: loss 2.009493
[epoch20, step1724]: loss 1.463320
[epoch20, step1725]: loss 2.277617
[epoch20, step1726]: loss 1.663023
[epoch20, step1727]: loss 0.993351
[epoch20, step1728]: loss 1.221598
[epoch20, step1729]: loss 3.765719
[epoch20, step1730]: loss 0.464930
[epoch20, step1731]: loss 0.419511
[epoch20, step1732]: loss 1.353591
[epoch20, step1733]: loss 0.843170
[epoch20, step1734]: loss 1.483928
[epoch20, step1735]: loss 2.238690
[epoch20, step1736]: loss 1.272851
[epoch20, step1737]: loss 3.749576
[epoch20, step1738]: loss 0.689302
[epoch20, step1739]: loss 2.560659
[epoch20, step1740]: loss 5.698111
[epoch20, step1741]: loss 0.498610
[epoch20, step1742]: loss 2.788536
[epoch20, step1743]: loss 1.878312
[epoch20, step1744]: loss 6.423368
[epoch20, step1745]: loss 1.666328
[epoch20, step1746]: loss 14.854171
[epoch20, step1747]: loss 1.673639
[epoch20, step1748]: loss 0.929922
[epoch20, step1749]: loss 7.428536
[epoch20, step1750]: loss 14.699271
[epoch20, step1751]: loss 6.028014
[epoch20, step1752]: loss 9.275279
[epoch20, step1753]: loss 8.318087
[epoch20, step1754]: loss 3.107750
[epoch20, step1755]: loss 1.001634
[epoch20, step1756]: loss 1.043342
[epoch20, step1757]: loss 0.600532
[epoch20, step1758]: loss 2.041135
[epoch20, step1759]: loss 7.927096
[epoch20, step1760]: loss 11.566990
[epoch20, step1761]: loss 5.681233
[epoch20, step1762]: loss 7.348936
[epoch20, step1763]: loss 3.891931
[epoch20, step1764]: loss 0.981329
[epoch20, step1765]: loss 1.012338
[epoch20, step1766]: loss 1.158667
[epoch20, step1767]: loss 0.678024
[epoch20, step1768]: loss 0.621251
[epoch20, step1769]: loss 11.285635
[epoch20, step1770]: loss 2.282889
[epoch20, step1771]: loss 9.291510
[epoch20, step1772]: loss 0.645104
[epoch20, step1773]: loss 1.922568
[epoch20, step1774]: loss 1.988956
[epoch20, step1775]: loss 0.935565
[epoch20, step1776]: loss 2.265644
[epoch20, step1777]: loss 7.946913
[epoch20, step1778]: loss 0.859096
[epoch20, step1779]: loss 1.497275
[epoch20, step1780]: loss 2.731648
[epoch20, step1781]: loss 3.741531
[epoch20, step1782]: loss 1.284744
[epoch20, step1783]: loss 2.287213
[epoch20, step1784]: loss 2.293131
[epoch20, step1785]: loss 1.139024
[epoch20, step1786]: loss 2.199584
[epoch20, step1787]: loss 1.173425
[epoch20, step1788]: loss 0.732722
[epoch20, step1789]: loss 1.171202
[epoch20, step1790]: loss 3.613153
[epoch20, step1791]: loss 12.521687
[epoch20, step1792]: loss 0.830251
[epoch20, step1793]: loss 5.414934
[epoch20, step1794]: loss 0.960622
[epoch20, step1795]: loss 0.685480
[epoch20, step1796]: loss 1.300176
[epoch20, step1797]: loss 1.808807
[epoch20, step1798]: loss 1.039716
[epoch20, step1799]: loss 1.378625
[epoch20, step1800]: loss 0.746956
[epoch20, step1801]: loss 0.578220
[epoch20, step1802]: loss 0.545521
[epoch20, step1803]: loss 5.277059
[epoch20, step1804]: loss 3.425634
[epoch20, step1805]: loss 1.498938
[epoch20, step1806]: loss 0.666623
[epoch20, step1807]: loss 1.843839
[epoch20, step1808]: loss 4.093375
[epoch20, step1809]: loss 4.613766
[epoch20, step1810]: loss 2.216675
[epoch20, step1811]: loss 1.875979
[epoch20, step1812]: loss 0.947034
[epoch20, step1813]: loss 6.094493
[epoch20, step1814]: loss 4.965147
[epoch20, step1815]: loss 1.314272
[epoch20, step1816]: loss 0.728859
[epoch20, step1817]: loss 0.822918
[epoch20, step1818]: loss 0.679764
[epoch20, step1819]: loss 0.831620
[epoch20, step1820]: loss 14.859939
[epoch20, step1821]: loss 1.105239
[epoch20, step1822]: loss 1.241641
[epoch20, step1823]: loss 1.612024
[epoch20, step1824]: loss 1.510727
[epoch20, step1825]: loss 1.887835
[epoch20, step1826]: loss 0.811542
[epoch20, step1827]: loss 2.054246
[epoch20, step1828]: loss 1.254450
[epoch20, step1829]: loss 16.626810
[epoch20, step1830]: loss 3.319699
[epoch20, step1831]: loss 0.748392
[epoch20, step1832]: loss 1.327632
[epoch20, step1833]: loss 2.194593
[epoch20, step1834]: loss 1.011333
[epoch20, step1835]: loss 4.391136
[epoch20, step1836]: loss 0.579739
[epoch20, step1837]: loss 1.162216
[epoch20, step1838]: loss 4.272249
[epoch20, step1839]: loss 7.726773
[epoch20, step1840]: loss 1.208896
[epoch20, step1841]: loss 1.382673
[epoch20, step1842]: loss 0.999989
[epoch20, step1843]: loss 1.623282
[epoch20, step1844]: loss 1.987140
[epoch20, step1845]: loss 4.286918
[epoch20, step1846]: loss 1.909329
[epoch20, step1847]: loss 1.253232
[epoch20, step1848]: loss 1.701572
[epoch20, step1849]: loss 10.454432
[epoch20, step1850]: loss 0.620644
[epoch20, step1851]: loss 15.026196
[epoch20, step1852]: loss 1.082571
[epoch20, step1853]: loss 1.428950
[epoch20, step1854]: loss 2.006702
[epoch20, step1855]: loss 5.735556
[epoch20, step1856]: loss 0.905314
[epoch20, step1857]: loss 0.822696
[epoch20, step1858]: loss 1.833134
[epoch20, step1859]: loss 7.441807
[epoch20, step1860]: loss 1.586354
[epoch20, step1861]: loss 0.883118
[epoch20, step1862]: loss 1.280373
[epoch20, step1863]: loss 1.447043
[epoch20, step1864]: loss 9.655182
[epoch20, step1865]: loss 1.102539
[epoch20, step1866]: loss 1.052337
[epoch20, step1867]: loss 0.968065
[epoch20, step1868]: loss 1.750458
[epoch20, step1869]: loss 1.678550
[epoch20, step1870]: loss 5.421375
[epoch20, step1871]: loss 1.614327
[epoch20, step1872]: loss 7.731853
[epoch20, step1873]: loss 1.702995
[epoch20, step1874]: loss 1.753542
[epoch20, step1875]: loss 18.095137
[epoch20, step1876]: loss 2.824898
[epoch20, step1877]: loss 0.620466
[epoch20, step1878]: loss 5.232677
[epoch20, step1879]: loss 0.620955
[epoch20, step1880]: loss 8.557585
[epoch20, step1881]: loss 0.732905
[epoch20, step1882]: loss 8.013181
[epoch20, step1883]: loss 1.143245
[epoch20, step1884]: loss 4.362183
[epoch20, step1885]: loss 1.172749
[epoch20, step1886]: loss 1.619195
[epoch20, step1887]: loss 6.991793
[epoch20, step1888]: loss 1.713238
[epoch20, step1889]: loss 6.242034
[epoch20, step1890]: loss 0.698096
[epoch20, step1891]: loss 4.040281
[epoch20, step1892]: loss 0.650954
[epoch20, step1893]: loss 9.493010
[epoch20, step1894]: loss 1.406446
[epoch20, step1895]: loss 2.101336
[epoch20, step1896]: loss 1.028530
[epoch20, step1897]: loss 0.578553
[epoch20, step1898]: loss 2.572022
[epoch20, step1899]: loss 1.960933
[epoch20, step1900]: loss 0.952281
[epoch20, step1901]: loss 1.380346
[epoch20, step1902]: loss 6.257036
[epoch20, step1903]: loss 1.382052
[epoch20, step1904]: loss 4.543856
[epoch20, step1905]: loss 0.595097
[epoch20, step1906]: loss 2.262482
[epoch20, step1907]: loss 1.464434
[epoch20, step1908]: loss 1.875330
[epoch20, step1909]: loss 4.975454
[epoch20, step1910]: loss 1.023856
[epoch20, step1911]: loss 7.724993
[epoch20, step1912]: loss 4.030095
[epoch20, step1913]: loss 0.835757
[epoch20, step1914]: loss 1.045366
[epoch20, step1915]: loss 8.744062
[epoch20, step1916]: loss 1.292884
[epoch20, step1917]: loss 1.690986
[epoch20, step1918]: loss 1.160811
[epoch20, step1919]: loss 1.327986
[epoch20, step1920]: loss 5.417470
[epoch20, step1921]: loss 2.776141
[epoch20, step1922]: loss 0.804942
[epoch20, step1923]: loss 0.832901
[epoch20, step1924]: loss 2.828305
[epoch20, step1925]: loss 1.731319
[epoch20, step1926]: loss 1.403831
[epoch20, step1927]: loss 1.581990
[epoch20, step1928]: loss 0.633062
[epoch20, step1929]: loss 1.710344
[epoch20, step1930]: loss 0.699464
[epoch20, step1931]: loss 8.027959
[epoch20, step1932]: loss 0.664568
[epoch20, step1933]: loss 0.863140
[epoch20, step1934]: loss 3.604112
[epoch20, step1935]: loss 3.339654
[epoch20, step1936]: loss 1.790924
[epoch20, step1937]: loss 0.643762
[epoch20, step1938]: loss 0.493017
[epoch20, step1939]: loss 0.817802
[epoch20, step1940]: loss 2.464087
[epoch20, step1941]: loss 4.214695
[epoch20, step1942]: loss 6.612373
[epoch20, step1943]: loss 0.728531
[epoch20, step1944]: loss 10.421166
[epoch20, step1945]: loss 0.621557
[epoch20, step1946]: loss 2.550673
[epoch20, step1947]: loss 9.179905
[epoch20, step1948]: loss 1.823590
[epoch20, step1949]: loss 11.080505
[epoch20, step1950]: loss 2.640286
[epoch20, step1951]: loss 1.377242
[epoch20, step1952]: loss 1.694467
[epoch20, step1953]: loss 8.785574
[epoch20, step1954]: loss 2.303364
[epoch20, step1955]: loss 1.741323
[epoch20, step1956]: loss 13.331813
[epoch20, step1957]: loss 2.427591
[epoch20, step1958]: loss 1.657424
[epoch20, step1959]: loss 2.538032
[epoch20, step1960]: loss 3.345306
[epoch20, step1961]: loss 3.120796
[epoch20, step1962]: loss 0.961863
[epoch20, step1963]: loss 1.067404
[epoch20, step1964]: loss 0.869854
[epoch20, step1965]: loss 1.219753
[epoch20, step1966]: loss 0.627267
[epoch20, step1967]: loss 0.999631
[epoch20, step1968]: loss 0.781240
[epoch20, step1969]: loss 1.312624
[epoch20, step1970]: loss 2.330087
[epoch20, step1971]: loss 2.277760
[epoch20, step1972]: loss 5.929852
[epoch20, step1973]: loss 14.759566
[epoch20, step1974]: loss 6.044296
[epoch20, step1975]: loss 2.218331
[epoch20, step1976]: loss 0.949187
[epoch20, step1977]: loss 2.387356
[epoch20, step1978]: loss 0.474811
[epoch20, step1979]: loss 1.397196
[epoch20, step1980]: loss 8.600140
[epoch20, step1981]: loss 1.318227
[epoch20, step1982]: loss 0.918363
[epoch20, step1983]: loss 0.932930
[epoch20, step1984]: loss 2.481882
[epoch20, step1985]: loss 1.778262
[epoch20, step1986]: loss 1.029374
[epoch20, step1987]: loss 1.333739
[epoch20, step1988]: loss 0.724377
[epoch20, step1989]: loss 1.181770
[epoch20, step1990]: loss 3.385563
[epoch20, step1991]: loss 0.830644
[epoch20, step1992]: loss 9.070231
[epoch20, step1993]: loss 0.541926
[epoch20, step1994]: loss 1.332727
[epoch20, step1995]: loss 1.432266
[epoch20, step1996]: loss 8.136602
[epoch20, step1997]: loss 15.002413
[epoch20, step1998]: loss 1.519317
[epoch20, step1999]: loss 7.130987
[epoch20, step2000]: loss 1.749037
[epoch20, step2001]: loss 0.800942
[epoch20, step2002]: loss 0.848505
[epoch20, step2003]: loss 28.973955
[epoch20, step2004]: loss 0.567771
[epoch20, step2005]: loss 0.653918
[epoch20, step2006]: loss 4.866094
[epoch20, step2007]: loss 2.992914
[epoch20, step2008]: loss 0.932505
[epoch20, step2009]: loss 1.852176
[epoch20, step2010]: loss 43.636459
[epoch20, step2011]: loss 1.960162
[epoch20, step2012]: loss 6.500851
[epoch20, step2013]: loss 1.664724
[epoch20, step2014]: loss 1.542164
[epoch20, step2015]: loss 1.003950
[epoch20, step2016]: loss 0.859879
[epoch20, step2017]: loss 1.189265
[epoch20, step2018]: loss 2.966473
[epoch20, step2019]: loss 1.587368
[epoch20, step2020]: loss 13.548062
[epoch20, step2021]: loss 0.705916
[epoch20, step2022]: loss 1.050331
[epoch20, step2023]: loss 1.107893
[epoch20, step2024]: loss 0.571283
[epoch20, step2025]: loss 1.217419
[epoch20, step2026]: loss 16.246161
[epoch20, step2027]: loss 1.944334
[epoch20, step2028]: loss 6.817194
[epoch20, step2029]: loss 1.544358
[epoch20, step2030]: loss 1.613909
[epoch20, step2031]: loss 1.448933
[epoch20, step2032]: loss 0.922790
[epoch20, step2033]: loss 2.831496
[epoch20, step2034]: loss 0.817402
[epoch20, step2035]: loss 0.961409
[epoch20, step2036]: loss 0.972168
[epoch20, step2037]: loss 4.773649
[epoch20, step2038]: loss 1.855927
[epoch20, step2039]: loss 0.812006
[epoch20, step2040]: loss 2.582450
[epoch20, step2041]: loss 1.332504
[epoch20, step2042]: loss 0.899927
[epoch20, step2043]: loss 2.081840
[epoch20, step2044]: loss 4.228149
[epoch20, step2045]: loss 0.789750
[epoch20, step2046]: loss 2.030071
[epoch20, step2047]: loss 1.170106
[epoch20, step2048]: loss 9.459187
[epoch20, step2049]: loss 1.068755
[epoch20, step2050]: loss 0.777585
[epoch20, step2051]: loss 1.781551
[epoch20, step2052]: loss 4.095581
[epoch20, step2053]: loss 1.600644
[epoch20, step2054]: loss 4.964766
[epoch20, step2055]: loss 0.816594
[epoch20, step2056]: loss 3.637898
[epoch20, step2057]: loss 1.805286
[epoch20, step2058]: loss 2.613351
[epoch20, step2059]: loss 0.686264
[epoch20, step2060]: loss 1.109549
[epoch20, step2061]: loss 5.790875
[epoch20, step2062]: loss 2.638140
[epoch20, step2063]: loss 1.230573
[epoch20, step2064]: loss 1.626059
[epoch20, step2065]: loss 9.932456
[epoch20, step2066]: loss 9.642926
[epoch20, step2067]: loss 1.067355
[epoch20, step2068]: loss 14.362985
[epoch20, step2069]: loss 1.046096
[epoch20, step2070]: loss 0.881325
[epoch20, step2071]: loss 0.861705
[epoch20, step2072]: loss 0.515002
[epoch20, step2073]: loss 3.039366
[epoch20, step2074]: loss 1.520950
[epoch20, step2075]: loss 4.407930
[epoch20, step2076]: loss 2.785746
[epoch20, step2077]: loss 3.947809
[epoch20, step2078]: loss 2.212325
[epoch20, step2079]: loss 1.136486
[epoch20, step2080]: loss 7.124447
[epoch20, step2081]: loss 0.555269
[epoch20, step2082]: loss 0.526959
[epoch20, step2083]: loss 23.276157
[epoch20, step2084]: loss 0.921095
[epoch20, step2085]: loss 0.854189
[epoch20, step2086]: loss 1.075302
[epoch20, step2087]: loss 14.015054
[epoch20, step2088]: loss 2.983763
[epoch20, step2089]: loss 2.371487
[epoch20, step2090]: loss 3.501592
[epoch20, step2091]: loss 4.345924
[epoch20, step2092]: loss 0.873523
[epoch20, step2093]: loss 1.435413
[epoch20, step2094]: loss 1.699238
[epoch20, step2095]: loss 2.913023
[epoch20, step2096]: loss 1.846519
[epoch20, step2097]: loss 1.370100
[epoch20, step2098]: loss 2.826581
[epoch20, step2099]: loss 8.561749
[epoch20, step2100]: loss 1.062953
[epoch20, step2101]: loss 9.534363
[epoch20, step2102]: loss 2.846922
[epoch20, step2103]: loss 0.733312
[epoch20, step2104]: loss 2.957139
[epoch20, step2105]: loss 1.683812
[epoch20, step2106]: loss 26.267313
[epoch20, step2107]: loss 15.460593
[epoch20, step2108]: loss 1.125839
[epoch20, step2109]: loss 1.737178
[epoch20, step2110]: loss 2.961532
[epoch20, step2111]: loss 0.785087
[epoch20, step2112]: loss 0.845540
[epoch20, step2113]: loss 7.519113
[epoch20, step2114]: loss 2.826684
[epoch20, step2115]: loss 8.209257
[epoch20, step2116]: loss 6.288814
[epoch20, step2117]: loss 2.802367
[epoch20, step2118]: loss 2.230998
[epoch20, step2119]: loss 1.762824
[epoch20, step2120]: loss 0.580656
[epoch20, step2121]: loss 1.007635
[epoch20, step2122]: loss 0.862813
[epoch20, step2123]: loss 6.010019
[epoch20, step2124]: loss 1.110419
[epoch20, step2125]: loss 0.754068
[epoch20, step2126]: loss 3.913645
[epoch20, step2127]: loss 2.855676
[epoch20, step2128]: loss 1.414055
[epoch20, step2129]: loss 7.114868
[epoch20, step2130]: loss 2.674186
[epoch20, step2131]: loss 7.332338
[epoch20, step2132]: loss 1.734673
[epoch20, step2133]: loss 0.793284
[epoch20, step2134]: loss 2.836745
[epoch20, step2135]: loss 1.393111
[epoch20, step2136]: loss 1.250025
[epoch20, step2137]: loss 0.748318
[epoch20, step2138]: loss 9.897839
[epoch20, step2139]: loss 1.191430
[epoch20, step2140]: loss 2.348327
[epoch20, step2141]: loss 1.170573
[epoch20, step2142]: loss 3.167686
[epoch20, step2143]: loss 1.058853
[epoch20, step2144]: loss 0.878017
[epoch20, step2145]: loss 4.494792
[epoch20, step2146]: loss 7.346824
[epoch20, step2147]: loss 1.000779
[epoch20, step2148]: loss 10.288644
[epoch20, step2149]: loss 0.724602
[epoch20, step2150]: loss 2.551647
[epoch20, step2151]: loss 3.405119
[epoch20, step2152]: loss 1.464437
[epoch20, step2153]: loss 1.341984
[epoch20, step2154]: loss 1.517130
[epoch20, step2155]: loss 7.205760
[epoch20, step2156]: loss 2.733925
[epoch20, step2157]: loss 4.862271
[epoch20, step2158]: loss 1.349895
[epoch20, step2159]: loss 1.135946
[epoch20, step2160]: loss 1.120012
[epoch20, step2161]: loss 0.693628
[epoch20, step2162]: loss 1.423492
[epoch20, step2163]: loss 0.821979
[epoch20, step2164]: loss 0.411632
[epoch20, step2165]: loss 0.605788
[epoch20, step2166]: loss 0.834813
[epoch20, step2167]: loss 1.035160
[epoch20, step2168]: loss 1.613716
[epoch20, step2169]: loss 0.892104
[epoch20, step2170]: loss 1.337389
[epoch20, step2171]: loss 4.014168
[epoch20, step2172]: loss 2.657199
[epoch20, step2173]: loss 7.312268
[epoch20, step2174]: loss 0.617191
[epoch20, step2175]: loss 1.900268
[epoch20, step2176]: loss 5.170039
[epoch20, step2177]: loss 7.381828
[epoch20, step2178]: loss 1.828644
[epoch20, step2179]: loss 4.648190
[epoch20, step2180]: loss 1.757197
[epoch20, step2181]: loss 4.347410
[epoch20, step2182]: loss 1.213321
[epoch20, step2183]: loss 1.228622
[epoch20, step2184]: loss 3.220477
[epoch20, step2185]: loss 0.890505
[epoch20, step2186]: loss 5.665702
[epoch20, step2187]: loss 0.716909
[epoch20, step2188]: loss 1.282023
[epoch20, step2189]: loss 1.727566
[epoch20, step2190]: loss 1.212709
[epoch20, step2191]: loss 1.781887
[epoch20, step2192]: loss 2.466765
[epoch20, step2193]: loss 0.746568
[epoch20, step2194]: loss 1.255534
[epoch20, step2195]: loss 2.154773
[epoch20, step2196]: loss 1.320735
[epoch20, step2197]: loss 1.173254
[epoch20, step2198]: loss 11.277810
[epoch20, step2199]: loss 1.009563
[epoch20, step2200]: loss 0.714201
[epoch20, step2201]: loss 0.851852
[epoch20, step2202]: loss 5.988425
[epoch20, step2203]: loss 0.660705
[epoch20, step2204]: loss 1.253542
[epoch20, step2205]: loss 1.935968
[epoch20, step2206]: loss 2.377050
[epoch20, step2207]: loss 9.842313
[epoch20, step2208]: loss 0.524437
[epoch20, step2209]: loss 1.937603
[epoch20, step2210]: loss 1.318842
[epoch20, step2211]: loss 1.216575
[epoch20, step2212]: loss 1.957788
[epoch20, step2213]: loss 1.310819
[epoch20, step2214]: loss 0.809434
[epoch20, step2215]: loss 0.379210
[epoch20, step2216]: loss 5.029222
[epoch20, step2217]: loss 1.661308
[epoch20, step2218]: loss 1.409981
[epoch20, step2219]: loss 1.513397
[epoch20, step2220]: loss 0.953786
[epoch20, step2221]: loss 4.894862
[epoch20, step2222]: loss 2.388513
[epoch20, step2223]: loss 1.093937
[epoch20, step2224]: loss 1.043631
[epoch20, step2225]: loss 1.075455
[epoch20, step2226]: loss 1.434586
[epoch20, step2227]: loss 2.255251
[epoch20, step2228]: loss 3.223237
[epoch20, step2229]: loss 1.343094
[epoch20, step2230]: loss 1.546234
[epoch20, step2231]: loss 3.085736
[epoch20, step2232]: loss 1.116854
[epoch20, step2233]: loss 1.003607
[epoch20, step2234]: loss 0.648094
[epoch20, step2235]: loss 1.413578
[epoch20, step2236]: loss 2.368792
[epoch20, step2237]: loss 1.527600
[epoch20, step2238]: loss 2.039673
[epoch20, step2239]: loss 0.633191
[epoch20, step2240]: loss 1.616908
[epoch20, step2241]: loss 0.523300
[epoch20, step2242]: loss 10.579087
[epoch20, step2243]: loss 2.965337
[epoch20, step2244]: loss 17.367100
[epoch20, step2245]: loss 2.974801
[epoch20, step2246]: loss 1.535906
[epoch20, step2247]: loss 2.078582
[epoch20, step2248]: loss 0.705739
[epoch20, step2249]: loss 1.364124
[epoch20, step2250]: loss 2.371182
[epoch20, step2251]: loss 4.968422
[epoch20, step2252]: loss 2.932181
[epoch20, step2253]: loss 1.838203
[epoch20, step2254]: loss 4.183002
[epoch20, step2255]: loss 4.085851
[epoch20, step2256]: loss 1.467861
[epoch20, step2257]: loss 1.597530
[epoch20, step2258]: loss 0.985184
[epoch20, step2259]: loss 2.910854
[epoch20, step2260]: loss 1.399916
[epoch20, step2261]: loss 2.526750
[epoch20, step2262]: loss 3.239386
[epoch20, step2263]: loss 1.102694
[epoch20, step2264]: loss 0.996853
[epoch20, step2265]: loss 3.908032
[epoch20, step2266]: loss 17.824409
[epoch20, step2267]: loss 4.872943
[epoch20, step2268]: loss 4.466297
[epoch20, step2269]: loss 2.528922
[epoch20, step2270]: loss 5.453823
[epoch20, step2271]: loss 1.496394
[epoch20, step2272]: loss 0.696894
[epoch20, step2273]: loss 2.047840
[epoch20, step2274]: loss 1.341234
[epoch20, step2275]: loss 7.192294
[epoch20, step2276]: loss 1.455898
[epoch20, step2277]: loss 1.075852
[epoch20, step2278]: loss 6.939394
[epoch20, step2279]: loss 12.663441
[epoch20, step2280]: loss 8.407320
[epoch20, step2281]: loss 6.405008
[epoch20, step2282]: loss 1.043443
[epoch20, step2283]: loss 1.066847
[epoch20, step2284]: loss 0.669966
[epoch20, step2285]: loss 2.398005
[epoch20, step2286]: loss 0.542573
[epoch20, step2287]: loss 1.434039
[epoch20, step2288]: loss 4.900570
[epoch20, step2289]: loss 1.971905
[epoch20, step2290]: loss 1.395853
[epoch20, step2291]: loss 8.627682
[epoch20, step2292]: loss 0.433113
[epoch20, step2293]: loss 1.347701
[epoch20, step2294]: loss 0.638376
[epoch20, step2295]: loss 0.723066
[epoch20, step2296]: loss 1.900046
[epoch20, step2297]: loss 2.573851
[epoch20, step2298]: loss 0.414538
[epoch20, step2299]: loss 0.621923
[epoch20, step2300]: loss 1.602200
[epoch20, step2301]: loss 0.656259
[epoch20, step2302]: loss 6.444431
[epoch20, step2303]: loss 1.165671
[epoch20, step2304]: loss 1.773095
[epoch20, step2305]: loss 0.893932
[epoch20, step2306]: loss 1.807957
[epoch20, step2307]: loss 0.438276
[epoch20, step2308]: loss 1.844804
[epoch20, step2309]: loss 3.148722
[epoch20, step2310]: loss 2.769815
[epoch20, step2311]: loss 1.340337
[epoch20, step2312]: loss 1.568184
[epoch20, step2313]: loss 0.701814
[epoch20, step2314]: loss 5.780490
[epoch20, step2315]: loss 2.952036
[epoch20, step2316]: loss 0.730025
[epoch20, step2317]: loss 13.868923
[epoch20, step2318]: loss 4.673724
[epoch20, step2319]: loss 2.626317
[epoch20, step2320]: loss 0.605211
[epoch20, step2321]: loss 3.296014
[epoch20, step2322]: loss 0.765340
[epoch20, step2323]: loss 0.859452
[epoch20, step2324]: loss 0.773755
[epoch20, step2325]: loss 0.846580
[epoch20, step2326]: loss 8.117949
[epoch20, step2327]: loss 7.522662
[epoch20, step2328]: loss 13.353354
[epoch20, step2329]: loss 1.602899
[epoch20, step2330]: loss 1.147141
[epoch20, step2331]: loss 2.939440
[epoch20, step2332]: loss 1.661124
[epoch20, step2333]: loss 1.510659
[epoch20, step2334]: loss 1.184670
[epoch20, step2335]: loss 24.628166
[epoch20, step2336]: loss 0.634908
[epoch20, step2337]: loss 0.981908
[epoch20, step2338]: loss 2.280348
[epoch20, step2339]: loss 0.710591
[epoch20, step2340]: loss 2.816158
[epoch20, step2341]: loss 0.757278
[epoch20, step2342]: loss 1.135109
[epoch20, step2343]: loss 2.328453
[epoch20, step2344]: loss 8.536240
[epoch20, step2345]: loss 2.355565
[epoch20, step2346]: loss 1.603040
[epoch20, step2347]: loss 1.529115
[epoch20, step2348]: loss 2.139199
[epoch20, step2349]: loss 1.025200
[epoch20, step2350]: loss 2.381991
[epoch20, step2351]: loss 1.247717
[epoch20, step2352]: loss 8.135050
[epoch20, step2353]: loss 4.059689
[epoch20, step2354]: loss 1.310557
[epoch20, step2355]: loss 0.842295
[epoch20, step2356]: loss 1.750100
[epoch20, step2357]: loss 0.724836
[epoch20, step2358]: loss 15.210533
[epoch20, step2359]: loss 0.567936
[epoch20, step2360]: loss 0.674192
[epoch20, step2361]: loss 1.690390
[epoch20, step2362]: loss 9.219835
[epoch20, step2363]: loss 14.257699
[epoch20, step2364]: loss 0.716480
[epoch20, step2365]: loss 3.138775
[epoch20, step2366]: loss 1.415799
[epoch20, step2367]: loss 2.528051
[epoch20, step2368]: loss 3.696368
[epoch20, step2369]: loss 1.108086
[epoch20, step2370]: loss 1.002655
[epoch20, step2371]: loss 3.951823
[epoch20, step2372]: loss 1.125932
[epoch20, step2373]: loss 4.215618
[epoch20, step2374]: loss 1.425503
[epoch20, step2375]: loss 4.835135
[epoch20, step2376]: loss 0.962936
[epoch20, step2377]: loss 1.135512
[epoch20, step2378]: loss 0.724745
[epoch20, step2379]: loss 3.800821
[epoch20, step2380]: loss 1.919376
[epoch20, step2381]: loss 2.548747
[epoch20, step2382]: loss 1.473460
[epoch20, step2383]: loss 7.377511
[epoch20, step2384]: loss 2.040952
[epoch20, step2385]: loss 3.860256
[epoch20, step2386]: loss 2.543197
[epoch20, step2387]: loss 6.824915
[epoch20, step2388]: loss 4.498439
[epoch20, step2389]: loss 1.255781
[epoch20, step2390]: loss 1.812210
[epoch20, step2391]: loss 1.983374
[epoch20, step2392]: loss 10.030086
[epoch20, step2393]: loss 13.290809
[epoch20, step2394]: loss 1.140552
[epoch20, step2395]: loss 0.987776
[epoch20, step2396]: loss 2.079876
[epoch20, step2397]: loss 9.741940
[epoch20, step2398]: loss 1.198739
[epoch20, step2399]: loss 22.864338
[epoch20, step2400]: loss 0.641042
[epoch20, step2401]: loss 1.740361
[epoch20, step2402]: loss 1.197452
[epoch20, step2403]: loss 1.275662
[epoch20, step2404]: loss 1.170354
[epoch20, step2405]: loss 0.736520
[epoch20, step2406]: loss 8.847982
[epoch20, step2407]: loss 1.024465
[epoch20, step2408]: loss 11.580865
[epoch20, step2409]: loss 0.852490
[epoch20, step2410]: loss 1.615695
[epoch20, step2411]: loss 0.532301
[epoch20, step2412]: loss 1.098035
[epoch20, step2413]: loss 2.440778
[epoch20, step2414]: loss 2.197846
[epoch20, step2415]: loss 2.145451
[epoch20, step2416]: loss 2.434751
[epoch20, step2417]: loss 0.920591
[epoch20, step2418]: loss 9.319618
[epoch20, step2419]: loss 0.701596
[epoch20, step2420]: loss 4.098264
[epoch20, step2421]: loss 0.735008
[epoch20, step2422]: loss 0.621908
[epoch20, step2423]: loss 1.044041
[epoch20, step2424]: loss 7.087708
[epoch20, step2425]: loss 7.547132
[epoch20, step2426]: loss 0.833611
[epoch20, step2427]: loss 1.164145
[epoch20, step2428]: loss 1.094791
[epoch20, step2429]: loss 1.350854
[epoch20, step2430]: loss 2.489143
[epoch20, step2431]: loss 1.895355
[epoch20, step2432]: loss 2.121963
[epoch20, step2433]: loss 2.979939
[epoch20, step2434]: loss 2.980264
[epoch20, step2435]: loss 1.154127
[epoch20, step2436]: loss 0.573465
[epoch20, step2437]: loss 4.400051
[epoch20, step2438]: loss 0.586777
[epoch20, step2439]: loss 0.693928
[epoch20, step2440]: loss 7.873846
[epoch20, step2441]: loss 0.810429
[epoch20, step2442]: loss 0.934237
[epoch20, step2443]: loss 0.963323
[epoch20, step2444]: loss 0.822742
[epoch20, step2445]: loss 1.477907
[epoch20, step2446]: loss 2.802742
[epoch20, step2447]: loss 3.663624
[epoch20, step2448]: loss 1.622567
[epoch20, step2449]: loss 1.122041
[epoch20, step2450]: loss 2.741315
[epoch20, step2451]: loss 3.627497
[epoch20, step2452]: loss 4.501507
[epoch20, step2453]: loss 4.778290
[epoch20, step2454]: loss 1.396823
[epoch20, step2455]: loss 1.629083
[epoch20, step2456]: loss 8.527529
[epoch20, step2457]: loss 1.794592
[epoch20, step2458]: loss 1.192127
[epoch20, step2459]: loss 11.311505
[epoch20, step2460]: loss 4.197154
[epoch20, step2461]: loss 1.315242
[epoch20, step2462]: loss 1.148627
[epoch20, step2463]: loss 5.546452
[epoch20, step2464]: loss 1.138117
[epoch20, step2465]: loss 3.099914
[epoch20, step2466]: loss 0.843867
[epoch20, step2467]: loss 1.454252
[epoch20, step2468]: loss 3.427884
[epoch20, step2469]: loss 4.746809
[epoch20, step2470]: loss 10.677406
[epoch20, step2471]: loss 0.594612
[epoch20, step2472]: loss 8.950916
[epoch20, step2473]: loss 1.602939
[epoch20, step2474]: loss 1.050896
[epoch20, step2475]: loss 1.206759
[epoch20, step2476]: loss 0.944787
[epoch20, step2477]: loss 0.962302
[epoch20, step2478]: loss 1.069563
[epoch20, step2479]: loss 2.036767
[epoch20, step2480]: loss 0.763511
[epoch20, step2481]: loss 2.063813
[epoch20, step2482]: loss 2.712896
[epoch20, step2483]: loss 0.517184
[epoch20, step2484]: loss 15.581841
[epoch20, step2485]: loss 0.609290
[epoch20, step2486]: loss 1.976821
[epoch20, step2487]: loss 8.974285
[epoch20, step2488]: loss 1.989980
[epoch20, step2489]: loss 3.496410
[epoch20, step2490]: loss 1.506119
[epoch20, step2491]: loss 1.191370
[epoch20, step2492]: loss 5.908302
[epoch20, step2493]: loss 8.037322
[epoch20, step2494]: loss 0.788322
[epoch20, step2495]: loss 11.808957
[epoch20, step2496]: loss 1.124224
[epoch20, step2497]: loss 5.602646
[epoch20, step2498]: loss 0.988990
[epoch20, step2499]: loss 0.768612
[epoch20, step2500]: loss 1.549691
[epoch20, step2501]: loss 5.335632
[epoch20, step2502]: loss 2.571630
[epoch20, step2503]: loss 1.637374
[epoch20, step2504]: loss 0.640387
[epoch20, step2505]: loss 1.029878
[epoch20, step2506]: loss 1.622936
[epoch20, step2507]: loss 1.064005
[epoch20, step2508]: loss 0.656657
[epoch20, step2509]: loss 1.210849
[epoch20, step2510]: loss 1.296355
[epoch20, step2511]: loss 1.356693
[epoch20, step2512]: loss 3.573042
[epoch20, step2513]: loss 1.343814
[epoch20, step2514]: loss 4.255621
[epoch20, step2515]: loss 5.189939
[epoch20, step2516]: loss 7.992096
[epoch20, step2517]: loss 1.039321
[epoch20, step2518]: loss 0.726864
[epoch20, step2519]: loss 2.120824
[epoch20, step2520]: loss 0.687222
[epoch20, step2521]: loss 6.841748
[epoch20, step2522]: loss 1.839481
[epoch20, step2523]: loss 7.511496
[epoch20, step2524]: loss 0.671057
[epoch20, step2525]: loss 0.738884
[epoch20, step2526]: loss 1.038276
[epoch20, step2527]: loss 3.428843
[epoch20, step2528]: loss 1.973488
[epoch20, step2529]: loss 0.828858
[epoch20, step2530]: loss 0.828003
[epoch20, step2531]: loss 0.686809
[epoch20, step2532]: loss 8.071035
[epoch20, step2533]: loss 1.118607
[epoch20, step2534]: loss 9.585282
[epoch20, step2535]: loss 5.672357
[epoch20, step2536]: loss 1.388268
[epoch20, step2537]: loss 1.148601
[epoch20, step2538]: loss 1.351069
[epoch20, step2539]: loss 2.353978
[epoch20, step2540]: loss 8.085705
[epoch20, step2541]: loss 3.175353
[epoch20, step2542]: loss 0.569844
[epoch20, step2543]: loss 0.800313
[epoch20, step2544]: loss 0.572331
[epoch20, step2545]: loss 0.757705
[epoch20, step2546]: loss 1.349835
[epoch20, step2547]: loss 0.865225
[epoch20, step2548]: loss 2.474788
[epoch20, step2549]: loss 8.973025
[epoch20, step2550]: loss 3.881193
[epoch20, step2551]: loss 3.155689
[epoch20, step2552]: loss 0.712656
[epoch20, step2553]: loss 5.391944
[epoch20, step2554]: loss 1.708343
[epoch20, step2555]: loss 17.784739
[epoch20, step2556]: loss 11.123912
[epoch20, step2557]: loss 0.505456
[epoch20, step2558]: loss 0.873592
[epoch20, step2559]: loss 1.037756
[epoch20, step2560]: loss 1.242670
[epoch20, step2561]: loss 0.876495
[epoch20, step2562]: loss 0.462824
[epoch20, step2563]: loss 5.440333
[epoch20, step2564]: loss 1.494255
[epoch20, step2565]: loss 0.510886
[epoch20, step2566]: loss 1.492966
[epoch20, step2567]: loss 0.704140
[epoch20, step2568]: loss 0.919319
[epoch20, step2569]: loss 1.441399
[epoch20, step2570]: loss 0.925427
[epoch20, step2571]: loss 0.715092
[epoch20, step2572]: loss 0.914871
[epoch20, step2573]: loss 0.511371
[epoch20, step2574]: loss 1.532936
[epoch20, step2575]: loss 1.102621
[epoch20, step2576]: loss 6.090609
[epoch20, step2577]: loss 0.617600
[epoch20, step2578]: loss 1.430552
[epoch20, step2579]: loss 2.226005
[epoch20, step2580]: loss 1.412913
[epoch20, step2581]: loss 0.804544
[epoch20, step2582]: loss 2.745164
[epoch20, step2583]: loss 0.438261
[epoch20, step2584]: loss 2.993212
[epoch20, step2585]: loss 1.180995
[epoch20, step2586]: loss 2.252473
[epoch20, step2587]: loss 0.913199
[epoch20, step2588]: loss 1.072774
[epoch20, step2589]: loss 10.934312
[epoch20, step2590]: loss 3.474066
[epoch20, step2591]: loss 0.606770
[epoch20, step2592]: loss 10.425494
[epoch20, step2593]: loss 1.047174
[epoch20, step2594]: loss 1.811660
[epoch20, step2595]: loss 11.093092
[epoch20, step2596]: loss 0.590753
[epoch20, step2597]: loss 2.170193
[epoch20, step2598]: loss 1.001727
[epoch20, step2599]: loss 1.132903
[epoch20, step2600]: loss 4.229072
[epoch20, step2601]: loss 5.106987
[epoch20, step2602]: loss 2.381154
[epoch20, step2603]: loss 0.772485
[epoch20, step2604]: loss 1.064474
[epoch20, step2605]: loss 1.005802
[epoch20, step2606]: loss 0.917992
[epoch20, step2607]: loss 3.077312
[epoch20, step2608]: loss 0.773733
[epoch20, step2609]: loss 0.544912
[epoch20, step2610]: loss 0.943696
[epoch20, step2611]: loss 1.095860
[epoch20, step2612]: loss 4.692372
[epoch20, step2613]: loss 1.642411
[epoch20, step2614]: loss 3.941226
[epoch20, step2615]: loss 1.676984
[epoch20, step2616]: loss 0.947550
[epoch20, step2617]: loss 1.237485
[epoch20, step2618]: loss 1.353675
[epoch20, step2619]: loss 1.072198
[epoch20, step2620]: loss 4.724590
[epoch20, step2621]: loss 13.833526
[epoch20, step2622]: loss 1.323580
[epoch20, step2623]: loss 2.081609
[epoch20, step2624]: loss 0.861692
[epoch20, step2625]: loss 3.584065
[epoch20, step2626]: loss 2.207494
[epoch20, step2627]: loss 6.100206
[epoch20, step2628]: loss 0.784330
[epoch20, step2629]: loss 1.139902
[epoch20, step2630]: loss 1.478942
[epoch20, step2631]: loss 9.858452
[epoch20, step2632]: loss 1.083897
[epoch20, step2633]: loss 1.599610
[epoch20, step2634]: loss 0.684556
[epoch20, step2635]: loss 3.081228
[epoch20, step2636]: loss 3.745358
[epoch20, step2637]: loss 0.960546
[epoch20, step2638]: loss 3.146626
[epoch20, step2639]: loss 2.072575
[epoch20, step2640]: loss 1.609867
[epoch20, step2641]: loss 7.712052
[epoch20, step2642]: loss 3.208433
[epoch20, step2643]: loss 1.289148
[epoch20, step2644]: loss 3.571437
[epoch20, step2645]: loss 0.458903
[epoch20, step2646]: loss 1.568811
[epoch20, step2647]: loss 0.717894
[epoch20, step2648]: loss 5.635681
[epoch20, step2649]: loss 2.483060
[epoch20, step2650]: loss 1.749688
[epoch20, step2651]: loss 1.321320
[epoch20, step2652]: loss 2.027207
[epoch20, step2653]: loss 0.679995
[epoch20, step2654]: loss 0.742079
[epoch20, step2655]: loss 2.004605
[epoch20, step2656]: loss 0.783932
[epoch20, step2657]: loss 3.258167
[epoch20, step2658]: loss 0.877495
[epoch20, step2659]: loss 1.009408
[epoch20, step2660]: loss 5.853307
[epoch20, step2661]: loss 10.922661
[epoch20, step2662]: loss 7.631525
[epoch20, step2663]: loss 2.203789
[epoch20, step2664]: loss 6.718623
[epoch20, step2665]: loss 0.681343
[epoch20, step2666]: loss 0.517395
[epoch20, step2667]: loss 0.497891
[epoch20, step2668]: loss 1.027775
[epoch20, step2669]: loss 1.120929
[epoch20, step2670]: loss 5.238199
[epoch20, step2671]: loss 0.571018
[epoch20, step2672]: loss 0.610548
[epoch20, step2673]: loss 1.313696
[epoch20, step2674]: loss 0.775782
[epoch20, step2675]: loss 0.559171
[epoch20, step2676]: loss 1.005509
[epoch20, step2677]: loss 7.895479
[epoch20, step2678]: loss 3.100440
[epoch20, step2679]: loss 2.140276
[epoch20, step2680]: loss 0.762332
[epoch20, step2681]: loss 6.201555
[epoch20, step2682]: loss 1.754274
[epoch20, step2683]: loss 1.255046
[epoch20, step2684]: loss 1.391775
[epoch20, step2685]: loss 0.717442
[epoch20, step2686]: loss 1.622398
[epoch20, step2687]: loss 0.778098
[epoch20, step2688]: loss 1.438920
[epoch20, step2689]: loss 3.727895
[epoch20, step2690]: loss 7.161417
[epoch20, step2691]: loss 5.746818
[epoch20, step2692]: loss 2.558702
[epoch20, step2693]: loss 10.440016
[epoch20, step2694]: loss 6.486827
[epoch20, step2695]: loss 0.742351
[epoch20, step2696]: loss 1.566074
[epoch20, step2697]: loss 11.767780
[epoch20, step2698]: loss 9.766008
[epoch20, step2699]: loss 0.998424
[epoch20, step2700]: loss 2.306774
[epoch20, step2701]: loss 4.029625
[epoch20, step2702]: loss 1.055946
[epoch20, step2703]: loss 4.600515
[epoch20, step2704]: loss 2.083321
[epoch20, step2705]: loss 20.871389
[epoch20, step2706]: loss 9.533150
[epoch20, step2707]: loss 1.118855
[epoch20, step2708]: loss 15.911141
[epoch20, step2709]: loss 3.324857
[epoch20, step2710]: loss 1.187253
[epoch20, step2711]: loss 3.329296
[epoch20, step2712]: loss 1.094980
[epoch20, step2713]: loss 1.661196
[epoch20, step2714]: loss 0.577917
[epoch20, step2715]: loss 1.159474
[epoch20, step2716]: loss 0.934420
[epoch20, step2717]: loss 1.749299
[epoch20, step2718]: loss 0.753100
[epoch20, step2719]: loss 6.057319
[epoch20, step2720]: loss 5.436069
[epoch20, step2721]: loss 5.145164
[epoch20, step2722]: loss 1.118498
[epoch20, step2723]: loss 2.273984
[epoch20, step2724]: loss 0.915498
[epoch20, step2725]: loss 2.594171
[epoch20, step2726]: loss 0.977789
[epoch20, step2727]: loss 5.935017
[epoch20, step2728]: loss 11.410929
[epoch20, step2729]: loss 1.582142
[epoch20, step2730]: loss 1.663269
[epoch20, step2731]: loss 15.663563
[epoch20, step2732]: loss 3.333188
[epoch20, step2733]: loss 2.663189
[epoch20, step2734]: loss 6.522878
[epoch20, step2735]: loss 1.060482
[epoch20, step2736]: loss 14.080571
[epoch20, step2737]: loss 5.191215
[epoch20, step2738]: loss 0.466486
[epoch20, step2739]: loss 1.041204
[epoch20, step2740]: loss 1.074228
[epoch20, step2741]: loss 1.591904
[epoch20, step2742]: loss 1.075647
[epoch20, step2743]: loss 0.943476
[epoch20, step2744]: loss 0.896280
[epoch20, step2745]: loss 0.998360
[epoch20, step2746]: loss 3.347240
[epoch20, step2747]: loss 0.659439
[epoch20, step2748]: loss 0.851393
[epoch20, step2749]: loss 3.274782
[epoch20, step2750]: loss 2.034956
[epoch20, step2751]: loss 1.226789
[epoch20, step2752]: loss 2.505639
[epoch20, step2753]: loss 2.814534
[epoch20, step2754]: loss 5.409780
[epoch20, step2755]: loss 2.323439
[epoch20, step2756]: loss 0.924141
[epoch20, step2757]: loss 1.221865
[epoch20, step2758]: loss 1.680583
[epoch20, step2759]: loss 6.948582
[epoch20, step2760]: loss 1.906148
[epoch20, step2761]: loss 11.871161
[epoch20, step2762]: loss 5.624360
[epoch20, step2763]: loss 1.025560
[epoch20, step2764]: loss 1.657125
[epoch20, step2765]: loss 1.600793
[epoch20, step2766]: loss 10.134409
[epoch20, step2767]: loss 1.139056
[epoch20, step2768]: loss 1.883680
[epoch20, step2769]: loss 0.681632
[epoch20, step2770]: loss 2.346610
[epoch20, step2771]: loss 1.066798
[epoch20, step2772]: loss 3.058154
[epoch20, step2773]: loss 2.191908
[epoch20, step2774]: loss 0.624456
[epoch20, step2775]: loss 1.532884
[epoch20, step2776]: loss 5.814317
[epoch20, step2777]: loss 0.744091
[epoch20, step2778]: loss 1.295977
[epoch20, step2779]: loss 1.269684
[epoch20, step2780]: loss 1.867881
[epoch20, step2781]: loss 8.320296
[epoch20, step2782]: loss 0.865403
[epoch20, step2783]: loss 7.077152
[epoch20, step2784]: loss 0.700367
[epoch20, step2785]: loss 1.356876
[epoch20, step2786]: loss 0.623035
[epoch20, step2787]: loss 0.579245
[epoch20, step2788]: loss 2.065226
[epoch20, step2789]: loss 1.424511
[epoch20, step2790]: loss 1.478180
[epoch20, step2791]: loss 1.858434
[epoch20, step2792]: loss 1.400023
[epoch20, step2793]: loss 10.411846
[epoch20, step2794]: loss 1.241579
[epoch20, step2795]: loss 2.599796
[epoch20, step2796]: loss 0.539023
[epoch20, step2797]: loss 1.556904
[epoch20, step2798]: loss 1.463142
[epoch20, step2799]: loss 6.167819
[epoch20, step2800]: loss 1.422139
[epoch20, step2801]: loss 0.797291
[epoch20, step2802]: loss 2.471147
[epoch20, step2803]: loss 7.737494
[epoch20, step2804]: loss 5.678590
[epoch20, step2805]: loss 1.585589
[epoch20, step2806]: loss 1.848252
[epoch20, step2807]: loss 0.745824
[epoch20, step2808]: loss 7.098929
[epoch20, step2809]: loss 1.679442
[epoch20, step2810]: loss 0.714364
[epoch20, step2811]: loss 0.419265
[epoch20, step2812]: loss 6.893673
[epoch20, step2813]: loss 1.719949
[epoch20, step2814]: loss 2.792708
[epoch20, step2815]: loss 2.091567
[epoch20, step2816]: loss 0.780773
[epoch20, step2817]: loss 2.131036
[epoch20, step2818]: loss 6.132133
[epoch20, step2819]: loss 0.749114
[epoch20, step2820]: loss 0.678022
[epoch20, step2821]: loss 1.045326
[epoch20, step2822]: loss 0.952417
[epoch20, step2823]: loss 10.160826
[epoch20, step2824]: loss 1.174433
[epoch20, step2825]: loss 1.801270
[epoch20, step2826]: loss 6.859817
[epoch20, step2827]: loss 0.616760
[epoch20, step2828]: loss 9.928707
[epoch20, step2829]: loss 0.799574
[epoch20, step2830]: loss 7.439895
[epoch20, step2831]: loss 2.643215
[epoch20, step2832]: loss 10.779496
[epoch20, step2833]: loss 3.311609
[epoch20, step2834]: loss 0.978000
[epoch20, step2835]: loss 0.938381
[epoch20, step2836]: loss 1.301119
[epoch20, step2837]: loss 1.170076
[epoch20, step2838]: loss 7.228369
[epoch20, step2839]: loss 0.577637
[epoch20, step2840]: loss 9.081233
[epoch20, step2841]: loss 1.906885
[epoch20, step2842]: loss 2.760706
[epoch20, step2843]: loss 1.842614
[epoch20, step2844]: loss 1.231869
[epoch20, step2845]: loss 27.355036
[epoch20, step2846]: loss 2.409330
[epoch20, step2847]: loss 0.879626
[epoch20, step2848]: loss 2.381304
[epoch20, step2849]: loss 1.533963
[epoch20, step2850]: loss 6.660673
[epoch20, step2851]: loss 1.565866
[epoch20, step2852]: loss 13.056520
[epoch20, step2853]: loss 6.368171
[epoch20, step2854]: loss 1.023794
[epoch20, step2855]: loss 1.265278
[epoch20, step2856]: loss 1.468392
[epoch20, step2857]: loss 1.636494
[epoch20, step2858]: loss 16.532490
[epoch20, step2859]: loss 2.284300
[epoch20, step2860]: loss 0.520070
[epoch20, step2861]: loss 1.231895
[epoch20, step2862]: loss 2.839656
[epoch20, step2863]: loss 3.809277
[epoch20, step2864]: loss 6.922063
[epoch20, step2865]: loss 1.332790
[epoch20, step2866]: loss 8.069998
[epoch20, step2867]: loss 1.059643
[epoch20, step2868]: loss 1.120651
[epoch20, step2869]: loss 8.002161
[epoch20, step2870]: loss 0.664747
[epoch20, step2871]: loss 1.262408
[epoch20, step2872]: loss 1.046284
[epoch20, step2873]: loss 10.355953
[epoch20, step2874]: loss 8.543637
[epoch20, step2875]: loss 0.579740
[epoch20, step2876]: loss 2.477111
[epoch20, step2877]: loss 3.981700
[epoch20, step2878]: loss 2.844698
[epoch20, step2879]: loss 1.135257
[epoch20, step2880]: loss 0.624163
[epoch20, step2881]: loss 3.865891
[epoch20, step2882]: loss 3.714729
[epoch20, step2883]: loss 0.617816
[epoch20, step2884]: loss 2.418517
[epoch20, step2885]: loss 1.049938
[epoch20, step2886]: loss 1.575589
[epoch20, step2887]: loss 2.008607
[epoch20, step2888]: loss 0.882594
[epoch20, step2889]: loss 4.676959
[epoch20, step2890]: loss 3.871566
[epoch20, step2891]: loss 2.354573
[epoch20, step2892]: loss 0.414242
[epoch20, step2893]: loss 1.460840
[epoch20, step2894]: loss 2.558462
[epoch20, step2895]: loss 1.494523
[epoch20, step2896]: loss 0.567211
[epoch20, step2897]: loss 1.290205
[epoch20, step2898]: loss 10.166214
[epoch20, step2899]: loss 11.002958
[epoch20, step2900]: loss 3.557442
[epoch20, step2901]: loss 2.191175
[epoch20, step2902]: loss 0.659377
[epoch20, step2903]: loss 0.542674
[epoch20, step2904]: loss 0.600073
[epoch20, step2905]: loss 0.763855
[epoch20, step2906]: loss 3.058782
[epoch20, step2907]: loss 2.274346
[epoch20, step2908]: loss 3.770530
[epoch20, step2909]: loss 0.599836
[epoch20, step2910]: loss 0.624651
[epoch20, step2911]: loss 0.805443
[epoch20, step2912]: loss 0.945246
[epoch20, step2913]: loss 2.213353
[epoch20, step2914]: loss 1.752583
[epoch20, step2915]: loss 1.433071
[epoch20, step2916]: loss 1.500239
[epoch20, step2917]: loss 0.594529
[epoch20, step2918]: loss 1.266814
[epoch20, step2919]: loss 0.655028
[epoch20, step2920]: loss 10.984653
[epoch20, step2921]: loss 11.057847
[epoch20, step2922]: loss 0.671140
[epoch20, step2923]: loss 1.053193
[epoch20, step2924]: loss 0.655028
[epoch20, step2925]: loss 5.547139
[epoch20, step2926]: loss 2.695084
[epoch20, step2927]: loss 2.317939
[epoch20, step2928]: loss 1.990311
[epoch20, step2929]: loss 0.903520
[epoch20, step2930]: loss 1.589100
[epoch20, step2931]: loss 0.761720
[epoch20, step2932]: loss 1.910703
[epoch20, step2933]: loss 6.820439
[epoch20, step2934]: loss 16.108494
[epoch20, step2935]: loss 0.690510
[epoch20, step2936]: loss 1.154142
[epoch20, step2937]: loss 0.597859
[epoch20, step2938]: loss 1.425381
[epoch20, step2939]: loss 0.889130
[epoch20, step2940]: loss 5.881743
[epoch20, step2941]: loss 0.498596
[epoch20, step2942]: loss 1.360913
[epoch20, step2943]: loss 2.687946
[epoch20, step2944]: loss 0.924130
[epoch20, step2945]: loss 2.317033
[epoch20, step2946]: loss 2.300120
[epoch20, step2947]: loss 2.674104
[epoch20, step2948]: loss 3.320924
[epoch20, step2949]: loss 1.370328
[epoch20, step2950]: loss 1.385607
[epoch20, step2951]: loss 0.789761
[epoch20, step2952]: loss 0.603037
[epoch20, step2953]: loss 1.140200
[epoch20, step2954]: loss 1.756848
[epoch20, step2955]: loss 0.974318
[epoch20, step2956]: loss 8.682752
[epoch20, step2957]: loss 1.935475
[epoch20, step2958]: loss 1.466892
[epoch20, step2959]: loss 2.449465
[epoch20, step2960]: loss 0.544808
[epoch20, step2961]: loss 0.692367
[epoch20, step2962]: loss 0.624625
[epoch20, step2963]: loss 1.294867
[epoch20, step2964]: loss 0.979324
[epoch20, step2965]: loss 1.971212
[epoch20, step2966]: loss 1.089867
[epoch20, step2967]: loss 1.131941
[epoch20, step2968]: loss 6.993290
[epoch20, step2969]: loss 6.250476
[epoch20, step2970]: loss 0.949693
[epoch20, step2971]: loss 1.517788
[epoch20, step2972]: loss 0.648081
[epoch20, step2973]: loss 1.949509
[epoch20, step2974]: loss 0.763380
[epoch20, step2975]: loss 30.959581
[epoch20, step2976]: loss 0.412641
[epoch20, step2977]: loss 4.043665
[epoch20, step2978]: loss 5.311789
[epoch20, step2979]: loss 1.068009
[epoch20, step2980]: loss 11.820316
[epoch20, step2981]: loss 4.224615
[epoch20, step2982]: loss 0.836776
[epoch20, step2983]: loss 0.862050
[epoch20, step2984]: loss 7.436618
[epoch20, step2985]: loss 0.879200
[epoch20, step2986]: loss 15.273231
[epoch20, step2987]: loss 0.906837
[epoch20, step2988]: loss 1.488449
[epoch20, step2989]: loss 1.157384
[epoch20, step2990]: loss 11.398180
[epoch20, step2991]: loss 1.249878
[epoch20, step2992]: loss 6.007286
[epoch20, step2993]: loss 1.114450
[epoch20, step2994]: loss 0.617556
[epoch20, step2995]: loss 8.799414
[epoch20, step2996]: loss 0.789887
[epoch20, step2997]: loss 3.801311
[epoch20, step2998]: loss 4.817512
[epoch20, step2999]: loss 0.803091
[epoch20, step3000]: loss 6.011648
[epoch20, step3001]: loss 1.700994
[epoch20, step3002]: loss 1.239634
[epoch20, step3003]: loss 0.970997
[epoch20, step3004]: loss 14.333101
[epoch20, step3005]: loss 1.464394
[epoch20, step3006]: loss 13.887069
[epoch20, step3007]: loss 1.325853
[epoch20, step3008]: loss 0.860111
[epoch20, step3009]: loss 0.789810
[epoch20, step3010]: loss 0.849664
[epoch20, step3011]: loss 1.871578
[epoch20, step3012]: loss 3.618710
[epoch20, step3013]: loss 5.247163
[epoch20, step3014]: loss 0.947898
[epoch20, step3015]: loss 1.215556
[epoch20, step3016]: loss 1.292916
[epoch20, step3017]: loss 0.936117
[epoch20, step3018]: loss 0.884331
[epoch20, step3019]: loss 4.870644
[epoch20, step3020]: loss 5.410807
[epoch20, step3021]: loss 7.151839
[epoch20, step3022]: loss 0.837316
[epoch20, step3023]: loss 8.746132
[epoch20, step3024]: loss 3.662542
[epoch20, step3025]: loss 1.495087
[epoch20, step3026]: loss 4.422435
[epoch20, step3027]: loss 1.079192
[epoch20, step3028]: loss 1.675362
[epoch20, step3029]: loss 0.948598
[epoch20, step3030]: loss 0.731892
[epoch20, step3031]: loss 3.164717
[epoch20, step3032]: loss 0.925222
[epoch20, step3033]: loss 1.007704
[epoch20, step3034]: loss 37.851562
[epoch20, step3035]: loss 9.590913
[epoch20, step3036]: loss 0.422796
[epoch20, step3037]: loss 3.878063
[epoch20, step3038]: loss 0.981275
[epoch20, step3039]: loss 4.245758
[epoch20, step3040]: loss 2.506315
[epoch20, step3041]: loss 1.198307
[epoch20, step3042]: loss 0.609278
[epoch20, step3043]: loss 4.129785
[epoch20, step3044]: loss 0.562910
[epoch20, step3045]: loss 1.213323
[epoch20, step3046]: loss 5.551716
[epoch20, step3047]: loss 1.190310
[epoch20, step3048]: loss 0.814273
[epoch20, step3049]: loss 0.761552
[epoch20, step3050]: loss 5.514557
[epoch20, step3051]: loss 7.965617
[epoch20, step3052]: loss 1.693421
[epoch20, step3053]: loss 0.565401
[epoch20, step3054]: loss 0.969937
[epoch20, step3055]: loss 0.873630
[epoch20, step3056]: loss 1.065413
[epoch20, step3057]: loss 2.157083
[epoch20, step3058]: loss 2.224673
[epoch20, step3059]: loss 0.850242
[epoch20, step3060]: loss 1.650174
[epoch20, step3061]: loss 4.250051
[epoch20, step3062]: loss 1.340708
[epoch20, step3063]: loss 3.899963
[epoch20, step3064]: loss 0.530195
[epoch20, step3065]: loss 1.571198
[epoch20, step3066]: loss 1.211798
[epoch20, step3067]: loss 2.581852
[epoch20, step3068]: loss 1.590902
[epoch20, step3069]: loss 1.259597
[epoch20, step3070]: loss 1.637976
[epoch20, step3071]: loss 0.599338
[epoch20, step3072]: loss 1.958107
[epoch20, step3073]: loss 2.358975
[epoch20, step3074]: loss 1.142384
[epoch20, step3075]: loss 2.712433
[epoch20, step3076]: loss 1.251382

[epoch20]: avg loss 1.251382

[TEST step1]: loss 6.767644
[TEST step2]: loss 0.939954
[TEST step3]: loss 1.487687
[TEST step4]: loss 0.696277
[TEST step5]: loss 0.822634
[TEST step6]: loss 1.815867
[TEST step7]: loss 1.706134
[TEST step8]: loss 2.023154
[TEST step9]: loss 6.271794
[TEST step10]: loss 3.855072
[TEST step11]: loss 0.953589
[TEST step12]: loss 24.561205
[TEST step13]: loss 0.689157
[TEST step14]: loss 5.892087
[TEST step15]: loss 2.274934
[TEST step16]: loss 1.293730
[TEST step17]: loss 2.294520
[TEST step18]: loss 0.915135
[TEST step19]: loss 0.972061
[TEST step20]: loss 0.607831
[TEST step21]: loss 1.694941
[TEST step22]: loss 2.281472
[TEST step23]: loss 2.759468
[TEST step24]: loss 9.014396
[TEST step25]: loss 1.764401
[TEST step26]: loss 3.665816
[TEST step27]: loss 1.093477
[TEST step28]: loss 0.964433
[TEST step29]: loss 9.059747
[TEST step30]: loss 0.917437
[TEST step31]: loss 0.775313
[TEST step32]: loss 2.208202
[TEST step33]: loss 1.018720
[TEST step34]: loss 0.746097
[TEST step35]: loss 0.724840
[TEST step36]: loss 1.158325
[TEST step37]: loss 0.905818
[TEST step38]: loss 2.723230
[TEST step39]: loss 1.725329
[TEST step40]: loss 1.124605
[TEST step41]: loss 0.911972
[TEST step42]: loss 0.910244
[TEST step43]: loss 0.862073
[TEST step44]: loss 2.112093
[TEST step45]: loss 0.760692
[TEST step46]: loss 0.774910
[TEST step47]: loss 0.901273
[TEST step48]: loss 1.491258
[TEST step49]: loss 16.138515
[TEST step50]: loss 1.660821
[TEST step51]: loss 1.835582
[TEST step52]: loss 6.672420
[TEST step53]: loss 11.328358
[TEST step54]: loss 0.474102
[TEST step55]: loss 8.414202
[TEST step56]: loss 1.298758
[TEST step57]: loss 1.421436
[TEST step58]: loss 1.437777
[TEST step59]: loss 0.830562
[TEST step60]: loss 0.712118
[TEST step61]: loss 3.075894
[TEST step62]: loss 1.248464
[TEST step63]: loss 1.034475
[TEST step64]: loss 9.321815
[TEST step65]: loss 4.219063
[TEST step66]: loss 0.965859
[TEST step67]: loss 14.666961
[TEST step68]: loss 1.047310
[TEST step69]: loss 1.887956
[TEST step70]: loss 0.596271
[TEST step71]: loss 0.889912
[TEST step72]: loss 12.021332
[TEST step73]: loss 1.099775
[TEST step74]: loss 1.051994
[TEST step75]: loss 18.253586
[TEST step76]: loss 0.906457
[TEST step77]: loss 6.974244
[TEST step78]: loss 6.622986
[TEST step79]: loss 1.247637
[TEST step80]: loss 1.471357
[TEST step81]: loss 1.139151
[TEST step82]: loss 2.118588
[TEST step83]: loss 0.463947
[TEST step84]: loss 4.700436
[TEST step85]: loss 3.965807
[TEST step86]: loss 1.495616
[TEST step87]: loss 1.630310
[TEST step88]: loss 1.701849
[TEST step89]: loss 8.642756
[TEST step90]: loss 0.996857
[TEST step91]: loss 1.124809
[TEST step92]: loss 5.393211
[TEST step93]: loss 0.550089
[TEST step94]: loss 2.859279
[TEST step95]: loss 0.717168
[TEST step96]: loss 0.551414
[TEST step97]: loss 1.669750
[TEST step98]: loss 1.049518
[TEST step99]: loss 2.398250
[TEST step100]: loss 1.007625
[TEST step101]: loss 15.652008
[TEST step102]: loss 0.566475
[TEST step103]: loss 0.664905
[TEST step104]: loss 2.078884
[TEST step105]: loss 6.076871
[TEST step106]: loss 0.778563
[TEST step107]: loss 9.167422
[TEST step108]: loss 5.557017
[TEST step109]: loss 1.017453
[TEST step110]: loss 10.288866
[TEST step111]: loss 1.777227
[TEST step112]: loss 8.256233
[TEST step113]: loss 0.824180
[TEST step114]: loss 1.148586
[TEST step115]: loss 0.765815
[TEST step116]: loss 1.566409
[TEST step117]: loss 1.049453
[TEST step118]: loss 0.960316
[TEST step119]: loss 4.253572
[TEST step120]: loss 0.628634
[TEST step121]: loss 1.281726
[TEST step122]: loss 2.005259
[TEST step123]: loss 8.130434
[TEST step124]: loss 2.650253
[TEST step125]: loss 4.112915
[TEST step126]: loss 6.306736
[TEST step127]: loss 8.926199
[TEST step128]: loss 10.434750
[TEST step129]: loss 8.973186
[TEST step130]: loss 0.690394
[TEST step131]: loss 0.588652
[TEST step132]: loss 1.284111
[TEST step133]: loss 0.525727
[TEST step134]: loss 1.041836
[TEST step135]: loss 0.889197
[TEST step136]: loss 1.094925
[TEST step137]: loss 2.130086
[TEST step138]: loss 0.504017
[TEST step139]: loss 0.864707
[TEST step140]: loss 1.565267
[TEST step141]: loss 10.166539
[TEST step142]: loss 1.298265
[TEST step143]: loss 1.431176
[TEST step144]: loss 9.340397
[TEST step145]: loss 0.906243
[TEST step146]: loss 2.610862
[TEST step147]: loss 0.645352
[TEST step148]: loss 2.236159
[TEST step149]: loss 1.586256
[TEST step150]: loss 0.657102
[TEST step151]: loss 2.004799
[TEST step152]: loss 0.728726
[TEST step153]: loss 8.296956
[TEST step154]: loss 1.844428
[TEST step155]: loss 1.050836
[TEST step156]: loss 1.836704
[TEST step157]: loss 3.746418
[TEST step158]: loss 1.394742
[TEST step159]: loss 10.386147
[TEST step160]: loss 0.718428
[TEST step161]: loss 2.310256
[TEST step162]: loss 3.477695
[TEST step163]: loss 1.100682
[TEST step164]: loss 2.062357
[TEST step165]: loss 2.525448
[TEST step166]: loss 4.741069
[TEST step167]: loss 1.574295
[TEST step168]: loss 0.411940
[TEST step169]: loss 0.605756
[TEST step170]: loss 1.013807
[TEST step171]: loss 0.913726
[TEST step172]: loss 1.992957
[TEST step173]: loss 0.971645
[TEST step174]: loss 1.567962
[TEST step175]: loss 0.988262
[TEST step176]: loss 3.278323
[TEST step177]: loss 1.338282
[TEST step178]: loss 2.298625
[TEST step179]: loss 2.355469
[TEST step180]: loss 7.486584
[TEST step181]: loss 2.026406
[TEST step182]: loss 0.960618
[TEST step183]: loss 0.620656
[TEST step184]: loss 6.393983
[TEST step185]: loss 0.777552
[TEST step186]: loss 0.767634
[TEST step187]: loss 1.557108
[TEST step188]: loss 2.528520
[TEST step189]: loss 1.275076
[TEST step190]: loss 0.680100
[TEST step191]: loss 2.257882
[TEST step192]: loss 0.712206
[TEST step193]: loss 0.800493
[TEST step194]: loss 1.078786
[TEST step195]: loss 1.586216
[TEST step196]: loss 2.332665
[TEST step197]: loss 1.449082
[TEST step198]: loss 2.091795
[TEST step199]: loss 3.105484
[TEST step200]: loss 1.312680
[TEST step201]: loss 0.808211
[TEST step202]: loss 0.612081
[TEST step203]: loss 0.755820
[TEST step204]: loss 4.826888
[TEST step205]: loss 1.309097
[TEST step206]: loss 6.958305
[TEST step207]: loss 2.450068
[TEST step208]: loss 9.351038
[TEST step209]: loss 7.404563
[TEST step210]: loss 5.680986
[TEST step211]: loss 0.889737
[TEST step212]: loss 0.818396
[TEST step213]: loss 8.733491
[TEST step214]: loss 0.998592
[TEST step215]: loss 1.125295
[TEST step216]: loss 1.061015
[TEST step217]: loss 1.894868
[TEST step218]: loss 0.848641
[TEST step219]: loss 1.093994
[TEST step220]: loss 2.174710
[TEST step221]: loss 1.382756
[TEST step222]: loss 0.713199
[TEST step223]: loss 2.534448
[TEST step224]: loss 0.772851
[TEST step225]: loss 0.759597
[TEST step226]: loss 9.800793
[TEST step227]: loss 4.690041
[TEST step228]: loss 0.551936
[TEST step229]: loss 1.975663
[TEST step230]: loss 0.978922
[TEST step231]: loss 1.470074
[TEST step232]: loss 2.819737
[TEST step233]: loss 1.310952
[TEST step234]: loss 2.416385
[TEST step235]: loss 1.033286
[TEST step236]: loss 1.176135
[TEST step237]: loss 2.159250
[TEST step238]: loss 2.421627
[TEST step239]: loss 1.596220
[TEST step240]: loss 3.433428
[TEST step241]: loss 2.417498
[TEST step242]: loss 0.943741
[TEST step243]: loss 0.562165
[TEST step244]: loss 1.830345
[TEST step245]: loss 0.828460
[TEST step246]: loss 18.393919
[TEST step247]: loss 0.854844
[TEST step248]: loss 0.596045
[TEST step249]: loss 4.315424
[TEST step250]: loss 2.153553
[TEST step251]: loss 4.290800
[TEST step252]: loss 1.366946
[TEST step253]: loss 1.951017
[TEST step254]: loss 1.359358
[TEST step255]: loss 1.415691
[TEST step256]: loss 0.893474
[TEST step257]: loss 4.406549
[TEST step258]: loss 0.769889
[TEST step259]: loss 8.815815
[TEST step260]: loss 1.531976
[TEST step261]: loss 5.971754
[TEST step262]: loss 2.195251
[TEST step263]: loss 2.349090
[TEST step264]: loss 7.644753
[TEST step265]: loss 10.396062
[TEST step266]: loss 0.739795
[TEST step267]: loss 1.172640
[TEST step268]: loss 0.920732
[TEST step269]: loss 0.314264
[TEST step270]: loss 0.891532
[TEST step271]: loss 2.835422
[TEST step272]: loss 14.545380
[TEST step273]: loss 1.391275
[TEST step274]: loss 0.711390
[TEST step275]: loss 0.629896
[TEST step276]: loss 0.814590
[TEST step277]: loss 1.812918
[TEST step278]: loss 5.659398
[TEST step279]: loss 2.551694
[TEST step280]: loss 2.220562
[TEST step281]: loss 0.752647
[TEST step282]: loss 3.404194
[TEST step283]: loss 6.701881
[TEST step284]: loss 0.826778
[TEST step285]: loss 3.109602
[TEST step286]: loss 3.242390
[TEST step287]: loss 1.310436
[TEST step288]: loss 9.379964
[TEST step289]: loss 2.201871
[TEST step290]: loss 1.426189
[TEST step291]: loss 0.645446
[TEST step292]: loss 0.642169
[TEST step293]: loss 9.920049
[TEST step294]: loss 1.732438
[TEST step295]: loss 5.990650
[TEST step296]: loss 1.121529
[TEST step297]: loss 2.551377
[TEST step298]: loss 0.579271
[TEST step299]: loss 2.307780
[TEST step300]: loss 0.913237
[TEST step301]: loss 1.118255
[TEST step302]: loss 8.365188
[TEST step303]: loss 1.294995
[TEST step304]: loss 0.594772
[TEST step305]: loss 1.093684
[TEST step306]: loss 1.110152
[TEST step307]: loss 6.803233
[TEST step308]: loss 2.012794
[TEST step309]: loss 7.616380
[TEST step310]: loss 2.519705
[TEST step311]: loss 0.810747
[TEST step312]: loss 7.192791
[TEST step313]: loss 1.702927
[TEST step314]: loss 10.984700
[TEST step315]: loss 0.657794
[TEST step316]: loss 1.101140
[TEST step317]: loss 1.357033
[TEST step318]: loss 1.103331
[TEST step319]: loss 3.918014
[TEST step320]: loss 2.761845
[TEST step321]: loss 0.469379
[TEST step322]: loss 1.838543
[TEST step323]: loss 9.061874
[TEST step324]: loss 10.188580
[TEST step325]: loss 0.931725
[TEST step326]: loss 5.150030
[TEST step327]: loss 0.852578
[TEST step328]: loss 0.536241
[TEST step329]: loss 0.497851
[TEST step330]: loss 5.769412
[TEST step331]: loss 1.529370
[TEST step332]: loss 8.674076
[TEST step333]: loss 1.875031
[TEST step334]: loss 1.092860
[TEST step335]: loss 1.045535
[TEST step336]: loss 4.161213
[TEST step337]: loss 2.496307
[TEST step338]: loss 10.018188
[TEST step339]: loss 1.017158
[TEST step340]: loss 4.863469
[TEST step341]: loss 3.087672
[TEST step342]: loss 0.508826
[TEST step343]: loss 1.131501
[TEST step344]: loss 1.101459
[TEST step345]: loss 14.144933
[TEST step346]: loss 0.967826
[TEST step347]: loss 4.063347
[TEST step348]: loss 2.611234
[TEST step349]: loss 3.518257
[TEST step350]: loss 1.995766
[TEST step351]: loss 7.456590
[TEST step352]: loss 2.667095
[TEST step353]: loss 1.674296
[TEST step354]: loss 0.465040
[TEST step355]: loss 6.181487
[TEST step356]: loss 7.006697
[TEST step357]: loss 1.898589
[TEST step358]: loss 2.511498
[TEST step359]: loss 0.739175
[TEST step360]: loss 1.033532
[TEST step361]: loss 1.969952
[TEST step362]: loss 10.476570
[TEST step363]: loss 3.877757
[TEST step364]: loss 3.216939
[TEST step365]: loss 8.301827
[TEST step366]: loss 0.802559
[TEST step367]: loss 7.810915
[TEST step368]: loss 1.369781
[TEST step369]: loss 0.590121
[TEST step370]: loss 1.505583
[TEST step371]: loss 1.741724
[TEST step372]: loss 1.141078
[TEST step373]: loss 2.333254
[TEST step374]: loss 5.832504
[TEST step375]: loss 9.441171
[TEST step376]: loss 5.075680
[TEST step377]: loss 0.649994
[TEST step378]: loss 0.800843
[TEST step379]: loss 0.843981
[TEST step380]: loss 0.968086
[TEST step381]: loss 1.825173
[TEST step382]: loss 1.700128
[TEST step383]: loss 0.899246
[TEST step384]: loss 1.951483
[TEST step385]: loss 0.740608
[TEST step386]: loss 2.542367
[TEST step387]: loss 0.651832
[TEST step388]: loss 0.847256
[TEST step389]: loss 2.787649
[TEST step390]: loss 16.734541
[TEST step391]: loss 0.523938
[TEST step392]: loss 1.789545
[TEST step393]: loss 1.600528
[TEST step394]: loss 7.461430
[TEST step395]: loss 5.506984
[TEST step396]: loss 1.189254
[TEST step397]: loss 3.707070
[TEST step398]: loss 0.831118
[TEST step399]: loss 2.285383
[TEST step400]: loss 1.399953
[TEST step401]: loss 5.748108
[TEST step402]: loss 15.533095
[TEST step403]: loss 13.110757
[TEST step404]: loss 1.743041
[TEST step405]: loss 2.837849
[TEST step406]: loss 9.420727
[TEST step407]: loss 1.740552
[TEST step408]: loss 0.981454
[TEST step409]: loss 1.229943
[TEST step410]: loss 9.947853
[TEST step411]: loss 2.761863
[TEST step412]: loss 4.126032
[TEST step413]: loss 1.336899
[TEST step414]: loss 0.794603
[TEST step415]: loss 0.889365
[TEST step416]: loss 1.629488
[TEST step417]: loss 1.315405
[TEST step418]: loss 1.275354
[TEST step419]: loss 0.556358
[TEST step420]: loss 1.904819
[TEST step421]: loss 1.168111
[TEST step422]: loss 1.060536
[TEST step423]: loss 4.635786
[TEST step424]: loss 1.620104
[TEST step425]: loss 2.441660
[TEST step426]: loss 4.291034
[TEST step427]: loss 2.139735
[TEST step428]: loss 0.969815
[TEST step429]: loss 0.970526
[TEST step430]: loss 0.801695
[TEST step431]: loss 1.462431
[TEST step432]: loss 2.529687
[TEST step433]: loss 7.157115
[TEST step434]: loss 1.387639
[TEST step435]: loss 4.536029
[TEST step436]: loss 1.390076
[TEST step437]: loss 1.109998
[TEST step438]: loss 0.870810
[TEST step439]: loss 3.496825
[TEST step440]: loss 15.479767
[TEST step441]: loss 1.095351
[TEST step442]: loss 0.817193
[TEST step443]: loss 1.509612
[TEST step444]: loss 0.777746
[TEST step445]: loss 1.855089
[TEST step446]: loss 5.804987
[TEST step447]: loss 9.008482
[TEST step448]: loss 1.083112
[TEST step449]: loss 2.328842
[TEST step450]: loss 1.930410
[TEST step451]: loss 16.676054
[TEST step452]: loss 1.447380
[TEST step453]: loss 0.451697
[TEST step454]: loss 1.575163
[TEST step455]: loss 0.884332
[TEST step456]: loss 1.152364
[TEST step457]: loss 3.938058
[TEST step458]: loss 1.036859
[TEST step459]: loss 1.516300
[TEST step460]: loss 0.622673
[TEST step461]: loss 6.898028
[TEST step462]: loss 3.233701
[TEST step463]: loss 2.388506
[TEST step464]: loss 0.884363
[TEST step465]: loss 5.064229
[TEST step466]: loss 1.384770
[TEST step467]: loss 6.731369
[TEST step468]: loss 8.045578
[TEST step469]: loss 3.482165
[TEST step470]: loss 2.798430
[TEST step471]: loss 1.228625
[TEST step472]: loss 0.496215
[TEST step473]: loss 13.364651
[TEST step474]: loss 3.726699
[TEST step475]: loss 2.342878
[TEST step476]: loss 0.787182
[TEST step477]: loss 1.041713
[TEST step478]: loss 1.033908
[TEST step479]: loss 1.289708
[TEST step480]: loss 0.881445
[TEST step481]: loss 4.570118
[TEST step482]: loss 1.293486
[TEST step483]: loss 0.639423
[TEST step484]: loss 1.544814
[TEST step485]: loss 1.163261
[TEST step486]: loss 1.446148
[TEST step487]: loss 1.026400
[TEST step488]: loss 2.222197
[TEST step489]: loss 1.220963
[TEST step490]: loss 1.050709
[TEST step491]: loss 0.847587
[TEST step492]: loss 0.735808
[TEST step493]: loss 0.646361
[TEST step494]: loss 1.517828
[TEST step495]: loss 2.714072
[TEST step496]: loss 0.881324
[TEST step497]: loss 9.003779
[TEST step498]: loss 1.350377
[TEST step499]: loss 1.131737
[TEST step500]: loss 1.252923
[TEST step501]: loss 6.199590
[TEST step502]: loss 0.978548
[TEST step503]: loss 0.638131
[TEST step504]: loss 1.914976
[TEST step505]: loss 2.401370
[TEST step506]: loss 4.824634
[TEST step507]: loss 2.679644
[TEST step508]: loss 2.281528
[TEST step509]: loss 1.069465
[TEST step510]: loss 1.992250
[TEST step511]: loss 1.286131
[TEST step512]: loss 1.700783
[TEST step513]: loss 3.276603
[TEST step514]: loss 1.333919
[TEST step515]: loss 8.837036
[TEST step516]: loss 1.820006
[TEST step517]: loss 2.358185
[TEST step518]: loss 14.807966
[TEST step519]: loss 1.504116
[TEST step520]: loss 0.826394
[TEST step521]: loss 15.911692
[TEST step522]: loss 1.971488
[TEST step523]: loss 15.303749
[TEST step524]: loss 0.525599
[TEST step525]: loss 2.167695
[TEST step526]: loss 2.558981
[TEST step527]: loss 2.764758
[TEST step528]: loss 1.731921
[TEST step529]: loss 1.041147
[TEST step530]: loss 3.899003
[TEST step531]: loss 2.179615
[TEST step532]: loss 1.272073
[TEST step533]: loss 0.866217
[TEST step534]: loss 3.442626
[TEST step535]: loss 8.766304
[TEST step536]: loss 15.333020
[TEST step537]: loss 9.161302
[TEST step538]: loss 7.197884
[TEST step539]: loss 8.507309
[TEST step540]: loss 0.693217
[TEST step541]: loss 5.801984
[TEST step542]: loss 3.960736
[TEST step543]: loss 0.760372
[TEST step544]: loss 1.652868
[TEST step545]: loss 6.684754
[TEST step546]: loss 9.171160
[TEST step547]: loss 1.906073
[TEST step548]: loss 3.494771
[TEST step549]: loss 0.881293
[TEST step550]: loss 4.577265
[TEST step551]: loss 0.973986
[TEST step552]: loss 7.524786
[TEST step553]: loss 8.885690
[TEST step554]: loss 0.828085
[TEST step555]: loss 1.119746
[TEST step556]: loss 2.894050
[TEST step557]: loss 15.756702
[TEST step558]: loss 0.499512
[TEST step559]: loss 4.050176
[TEST step560]: loss 17.856045
[TEST step561]: loss 1.055734
[TEST step562]: loss 2.129521
[TEST step563]: loss 2.101911
[TEST step564]: loss 13.086672
[TEST step565]: loss 8.579778
[TEST step566]: loss 0.343008
[TEST step567]: loss 2.511935
[TEST step568]: loss 1.654728
[TEST step569]: loss 1.984398
[TEST step570]: loss 2.306340
[TEST step571]: loss 5.708032
[TEST step572]: loss 0.852292
[TEST step573]: loss 0.792055
[TEST step574]: loss 7.053005
[TEST step575]: loss 2.261736
[TEST step576]: loss 0.752329
[TEST step577]: loss 2.061587
[TEST step578]: loss 1.964185
[TEST step579]: loss 1.266806
[TEST step580]: loss 0.586775
[TEST step581]: loss 0.802833
[TEST step582]: loss 0.460812
[TEST step583]: loss 1.283923
[TEST step584]: loss 15.712912
[TEST step585]: loss 0.863378
[TEST step586]: loss 0.883137
[TEST step587]: loss 1.854514
[TEST step588]: loss 1.505862
[TEST step589]: loss 1.269458
[TEST step590]: loss 14.047266
[TEST step591]: loss 4.204970
[TEST step592]: loss 1.560362
[TEST step593]: loss 2.636486
[TEST step594]: loss 1.042091
[TEST step595]: loss 26.354595
[TEST step596]: loss 2.627535
[TEST step597]: loss 1.821301
[TEST step598]: loss 1.130729
[TEST step599]: loss 1.673139
[TEST step600]: loss 2.633887
[TEST step601]: loss 0.757902
[TEST step602]: loss 2.012145
[TEST step603]: loss 0.617278
[TEST step604]: loss 1.684222
[TEST step605]: loss 0.743937
[TEST step606]: loss 2.323013
[TEST step607]: loss 0.527947
[TEST step608]: loss 0.489276
[TEST step609]: loss 0.781784
[TEST step610]: loss 0.732717
[TEST step611]: loss 1.001951
[TEST step612]: loss 0.702330
[TEST step613]: loss 1.576650
[TEST step614]: loss 1.878612
[TEST step615]: loss 7.709424
[TEST step616]: loss 7.390442
[TEST step617]: loss 1.897903
[TEST step618]: loss 3.267765
[TEST step619]: loss 1.454570
[TEST step620]: loss 2.375855
[TEST step621]: loss 6.020287
[TEST step622]: loss 7.013529
[TEST step623]: loss 2.779039
[TEST step624]: loss 26.112736
[TEST step625]: loss 1.343099
[TEST step626]: loss 2.709039
[TEST step627]: loss 3.768080
[TEST step628]: loss 2.484633
[TEST step629]: loss 1.122311
[TEST step630]: loss 0.795410
[TEST step631]: loss 0.946500
[TEST step632]: loss 1.100808
[TEST step633]: loss 2.516824
[TEST step634]: loss 0.535508
[TEST step635]: loss 13.161773
[TEST step636]: loss 0.929035
[TEST step637]: loss 3.983747
[TEST step638]: loss 0.625595
[TEST step639]: loss 4.542470
[TEST step640]: loss 3.957246
[TEST step641]: loss 0.559436
[TEST step642]: loss 7.597274
[TEST step643]: loss 12.597112
[TEST step644]: loss 2.588539
[TEST step645]: loss 0.867477
[TEST step646]: loss 7.694673
[TEST step647]: loss 4.468886
[TEST step648]: loss 2.761365
[TEST step649]: loss 3.096314
[TEST step650]: loss 3.984921
[TEST step651]: loss 2.743793
[TEST step652]: loss 0.852851
[TEST step653]: loss 5.976930
[TEST step654]: loss 0.560476
[TEST step655]: loss 7.192945
[TEST step656]: loss 0.637029
[TEST step657]: loss 0.563207
[TEST step658]: loss 1.727686
[TEST step659]: loss 10.104164
[TEST step660]: loss 1.119547
[TEST step661]: loss 5.769624
[TEST step662]: loss 2.121626
[TEST step663]: loss 1.416810
[TEST step664]: loss 3.748854
[TEST step665]: loss 0.863418
[TEST step666]: loss 0.784600
[TEST step667]: loss 9.329241
[TEST step668]: loss 0.818236
[TEST step669]: loss 0.999740
[TEST step670]: loss 1.675976
[TEST step671]: loss 9.813878
[TEST step672]: loss 1.494591
[TEST step673]: loss 0.788714
[TEST step674]: loss 0.577942
[TEST step675]: loss 2.987328
[TEST step676]: loss 8.435157
[TEST step677]: loss 1.768171
[TEST step678]: loss 7.063704
[TEST step679]: loss 0.751177
[TEST step680]: loss 0.738150
[TEST step681]: loss 2.012195
[TEST step682]: loss 2.143326
[TEST step683]: loss 4.182340
[TEST step684]: loss 1.604153
[TEST step685]: loss 0.953451
[TEST step686]: loss 7.872720
[TEST step687]: loss 0.556573
[TEST step688]: loss 1.139519
[TEST step689]: loss 1.411684
[TEST step690]: loss 0.705142
[TEST step691]: loss 1.178054
[TEST step692]: loss 2.544992
[TEST step693]: loss 3.764684
[TEST step694]: loss 0.728000
[TEST step695]: loss 11.046351
[TEST step696]: loss 6.566316
[TEST step697]: loss 0.816472
[TEST step698]: loss 1.311004
[TEST step699]: loss 6.011090
[TEST step700]: loss 0.410888
[TEST step701]: loss 1.271107
[TEST step702]: loss 3.599378
[TEST step703]: loss 1.108132
[TEST step704]: loss 2.317375
[TEST step705]: loss 10.472063
[TEST step706]: loss 27.972776
[TEST step707]: loss 1.499121
[TEST step708]: loss 3.162810
[TEST step709]: loss 1.256010
[TEST step710]: loss 2.074131
[TEST step711]: loss 4.078382
[TEST step712]: loss 2.987977
[TEST step713]: loss 0.497235
[TEST step714]: loss 15.280630
[TEST step715]: loss 3.830257
[TEST step716]: loss 0.881618
[TEST step717]: loss 0.691830
[TEST step718]: loss 1.657228
[TEST step719]: loss 1.096191
[TEST step720]: loss 1.901785
[TEST step721]: loss 9.652158
[TEST step722]: loss 2.408823
[TEST step723]: loss 2.752822
[TEST step724]: loss 1.822334
[TEST step725]: loss 35.348347
[TEST step726]: loss 1.056651
[TEST step727]: loss 1.264249
[TEST step728]: loss 1.110431
[TEST step729]: loss 1.116700
[TEST step730]: loss 1.429107
[TEST step731]: loss 0.834572
[TEST step732]: loss 1.146567
[TEST step733]: loss 0.698808
[TEST step734]: loss 0.932462
[TEST step735]: loss 0.915905
[TEST step736]: loss 6.475039
[TEST step737]: loss 0.920867
[TEST step738]: loss 1.704899
[TEST step739]: loss 7.667349
[TEST step740]: loss 1.292788
[TEST step741]: loss 11.220565
[TEST step742]: loss 0.507516
[TEST step743]: loss 4.068010
[TEST step744]: loss 0.903677
[TEST step745]: loss 0.598114
[TEST step746]: loss 0.853521
[TEST step747]: loss 2.566128
[TEST step748]: loss 2.398031
[TEST step749]: loss 3.896809
[TEST step750]: loss 2.097015
[TEST step751]: loss 0.806748
[TEST step752]: loss 0.631882
[TEST step753]: loss 2.673387
[TEST step754]: loss 1.908861
[TEST step755]: loss 3.288956
[TEST step756]: loss 0.832227
[TEST step757]: loss 0.893129
[TEST step758]: loss 1.363259
[TEST step759]: loss 3.677832
[TEST step760]: loss 1.775342
[TEST step761]: loss 0.790820
[TEST step762]: loss 1.447863
[TEST step763]: loss 15.434084
[TEST step764]: loss 5.800118
[TEST step765]: loss 1.068555
[TEST step766]: loss 2.493976
[TEST step767]: loss 1.032673
[TEST step768]: loss 0.899983
[TEST step769]: loss 2.198178

[TEST]: avg loss 2.198178

