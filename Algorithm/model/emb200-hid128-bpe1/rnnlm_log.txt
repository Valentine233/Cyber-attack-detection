[epoch1, step1]: loss 1.387157
[epoch1, step2]: loss 1.383338
[epoch1, step3]: loss 1.379562
[epoch1, step4]: loss 1.375107
[epoch1, step5]: loss 1.372400
[epoch1, step6]: loss 1.367307
[epoch1, step7]: loss 1.361861
[epoch1, step8]: loss 1.360540
[epoch1, step9]: loss 1.354010
[epoch1, step10]: loss 1.352733
[epoch1, step11]: loss 1.348189
[epoch1, step12]: loss 1.344698
[epoch1, step13]: loss 1.336965
[epoch1, step14]: loss 1.338676
[epoch1, step15]: loss 1.330912
[epoch1, step16]: loss 1.322999
[epoch1, step17]: loss 1.324592
[epoch1, step18]: loss 1.313229
[epoch1, step19]: loss 1.317784
[epoch1, step20]: loss 1.309379
[epoch1, step21]: loss 1.308070
[epoch1, step22]: loss 1.298105
[epoch1, step23]: loss 1.305234
[epoch1, step24]: loss 1.290589
[epoch1, step25]: loss 1.281015
[epoch1, step26]: loss 1.288250
[epoch1, step27]: loss 1.272225
[epoch1, step28]: loss 1.277658
[epoch1, step29]: loss 1.268532
[epoch1, step30]: loss 1.263493
[epoch1, step31]: loss 1.251731
[epoch1, step32]: loss 1.259512
[epoch1, step33]: loss 1.242637
[epoch1, step34]: loss 1.228577
[epoch1, step35]: loss 1.238821
[epoch1, step36]: loss 1.220102
[epoch1, step37]: loss 1.230405
[epoch1, step38]: loss 1.218777
[epoch1, step39]: loss 1.214057
[epoch1, step40]: loss 1.191582
[epoch1, step41]: loss 1.211891
[epoch1, step42]: loss 1.184104
[epoch1, step43]: loss 1.167946
[epoch1, step44]: loss 1.179712
[epoch1, step45]: loss 1.152901
[epoch1, step46]: loss 1.167881
[epoch1, step47]: loss 1.153950
[epoch1, step48]: loss 1.147550
[epoch1, step49]: loss 1.123102
[epoch1, step50]: loss 1.138439
[epoch1, step51]: loss 1.107304
[epoch1, step52]: loss 1.081842
[epoch1, step53]: loss 1.094335
[epoch1, step54]: loss 1.056782
[epoch1, step55]: loss 1.076321
[epoch1, step56]: loss 1.046296
[epoch1, step57]: loss 1.044017
[epoch1, step58]: loss 1.004328
[epoch1, step59]: loss 1.047607
[epoch1, step60]: loss 0.983515
[epoch1, step61]: loss 0.955027
[epoch1, step62]: loss 0.985195
[epoch1, step63]: loss 0.926604
[epoch1, step64]: loss 0.959321
[epoch1, step65]: loss 0.911889
[epoch1, step66]: loss 0.903620
[epoch1, step67]: loss 0.845353
[epoch1, step68]: loss 0.890951
[epoch1, step69]: loss 0.824271
[epoch1, step70]: loss 0.772240
[epoch1, step71]: loss 0.824242
[epoch1, step72]: loss 0.734574
[epoch1, step73]: loss 0.792929
[epoch1, step74]: loss 0.748562
[epoch1, step75]: loss 0.744602
[epoch1, step76]: loss 0.681458
[epoch1, step77]: loss 0.745591
[epoch1, step78]: loss 0.686432
[epoch1, step79]: loss 0.649348
[epoch1, step80]: loss 0.698504
[epoch1, step81]: loss 0.629134
[epoch1, step82]: loss 0.722988
[epoch1, step83]: loss 0.695765
[epoch1, step84]: loss 0.683701
[epoch1, step85]: loss 0.616492
[epoch1, step86]: loss 0.707137
[epoch1, step87]: loss 0.633294
[epoch1, step88]: loss 0.640308
[epoch1, step89]: loss 0.694596
[epoch1, step90]: loss 0.613393
[epoch1, step91]: loss 0.712418
[epoch1, step92]: loss 0.657519
[epoch1, step93]: loss 0.666668
[epoch1, step94]: loss 0.618797
[epoch1, step95]: loss 0.692509
[epoch1, step96]: loss 0.644151
[epoch1, step97]: loss 0.586517
[epoch1, step98]: loss 0.676929
[epoch1, step99]: loss 0.602919
[epoch1, step100]: loss 0.705051
[epoch1, step101]: loss 0.639641
[epoch1, step102]: loss 0.666234
[epoch1, step103]: loss 0.610089
[epoch1, step104]: loss 0.696927
[epoch1, step105]: loss 0.625460
[epoch1, step106]: loss 0.594566
[epoch1, step107]: loss 0.674047
[epoch1, step108]: loss 0.592149
[epoch1, step109]: loss 0.687570
[epoch1, step110]: loss 0.636823
[epoch1, step111]: loss 0.663369
[epoch1, step112]: loss 0.608755
[epoch1, step113]: loss 0.676131
[epoch1, step114]: loss 0.634640
[epoch1, step115]: loss 0.590184
[epoch1, step116]: loss 0.653984
[epoch1, step117]: loss 0.590149
[epoch1, step118]: loss 0.662606
[epoch1, step119]: loss 0.637345
[epoch1, step120]: loss 0.650793
[epoch1, step121]: loss 0.604702
[epoch1, step122]: loss 0.690100
[epoch1, step123]: loss 0.619920
[epoch1, step124]: loss 0.586926
[epoch1, step125]: loss 0.656333
[epoch1, step126]: loss 0.595075
[epoch1, step127]: loss 0.681502
[epoch1, step128]: loss 0.645954
[epoch1, step129]: loss 0.653500
[epoch1, step130]: loss 0.590846
[epoch1, step131]: loss 0.699814
[epoch1, step132]: loss 0.621588
[epoch1, step133]: loss 0.583044
[epoch1, step134]: loss 0.677176
[epoch1, step135]: loss 0.579759
[epoch1, step136]: loss 0.650163
[epoch1, step137]: loss 0.647516
[epoch1, step138]: loss 0.652862
[epoch1, step139]: loss 0.595716
[epoch1, step140]: loss 0.676051
[epoch1, step141]: loss 0.616330
[epoch1, step142]: loss 0.582119
[epoch1, step143]: loss 0.670262
[epoch1, step144]: loss 0.596301
[epoch1, step145]: loss 0.673980
[epoch1, step146]: loss 0.639903
[epoch1, step147]: loss 0.625763
[epoch1, step148]: loss 0.592514
[epoch1, step149]: loss 0.695921
[epoch1, step150]: loss 0.628373
[epoch1, step151]: loss 0.572702
[epoch1, step152]: loss 0.659805
[epoch1, step153]: loss 0.578451
[epoch1, step154]: loss 0.683326
[epoch1, step155]: loss 0.636348
[epoch1, step156]: loss 0.657758
[epoch1, step157]: loss 0.586662
[epoch1, step158]: loss 0.674801
[epoch1, step159]: loss 0.614949
[epoch1, step160]: loss 0.571657
[epoch1, step161]: loss 0.645096
[epoch1, step162]: loss 0.578510
[epoch1, step163]: loss 0.672194
[epoch1, step164]: loss 0.626465
[epoch1, step165]: loss 0.645427
[epoch1, step166]: loss 0.580350
[epoch1, step167]: loss 0.689249
[epoch1, step168]: loss 0.600957
[epoch1, step169]: loss 0.583962
[epoch1, step170]: loss 0.649273
[epoch1, step171]: loss 0.576345
[epoch1, step172]: loss 0.666623
[epoch1, step173]: loss 0.627279
[epoch1, step174]: loss 0.649662
[epoch1, step175]: loss 0.570348
[epoch1, step176]: loss 0.675578
[epoch1, step177]: loss 0.607945
[epoch1, step178]: loss 0.563467
[epoch1, step179]: loss 0.669743
[epoch1, step180]: loss 0.565594
[epoch1, step181]: loss 0.661162
[epoch1, step182]: loss 0.623497
[epoch1, step183]: loss 0.629695
[epoch1, step184]: loss 0.569000
[epoch1, step185]: loss 0.672432
[epoch1, step186]: loss 0.606101
[epoch1, step187]: loss 0.575685
[epoch1, step188]: loss 0.656579
[epoch1, step189]: loss 0.570241
[epoch1, step190]: loss 0.677499
[epoch1, step191]: loss 0.632834
[epoch1, step192]: loss 0.628522
[epoch1, step193]: loss 0.617207
[epoch1, step194]: loss 0.690970
[epoch1, step195]: loss 0.603646
[epoch1, step196]: loss 0.566667
[epoch1, step197]: loss 0.653523
[epoch1, step198]: loss 0.587598
[epoch1, step199]: loss 0.661289
[epoch1, step200]: loss 0.614311
[epoch1, step201]: loss 0.628053
[epoch1, step202]: loss 0.585477
[epoch1, step203]: loss 0.673790
[epoch1, step204]: loss 0.598939
[epoch1, step205]: loss 0.583836
[epoch1, step206]: loss 0.654987
[epoch1, step207]: loss 0.570679
[epoch1, step208]: loss 0.650153
[epoch1, step209]: loss 0.617900
[epoch1, step210]: loss 0.618839
[epoch1, step211]: loss 0.576522
[epoch1, step212]: loss 0.666061
[epoch1, step213]: loss 0.612792
[epoch1, step214]: loss 0.586827
[epoch1, step215]: loss 0.642862
[epoch1, step216]: loss 0.568075
[epoch1, step217]: loss 0.676858
[epoch1, step218]: loss 0.615705
[epoch1, step219]: loss 0.639673
[epoch1, step220]: loss 0.586838
[epoch1, step221]: loss 0.664820
[epoch1, step222]: loss 0.597362
[epoch1, step223]: loss 0.554881
[epoch1, step224]: loss 0.651875
[epoch1, step225]: loss 0.567589
[epoch1, step226]: loss 0.666229
[epoch1, step227]: loss 0.640687
[epoch1, step228]: loss 0.622471
[epoch1, step229]: loss 0.593770
[epoch1, step230]: loss 0.660289
[epoch1, step231]: loss 0.593496
[epoch1, step232]: loss 0.572501
[epoch1, step233]: loss 0.659711
[epoch1, step234]: loss 0.576962
[epoch1, step235]: loss 0.658593
[epoch1, step236]: loss 0.618246
[epoch1, step237]: loss 0.631638
[epoch1, step238]: loss 0.577176
[epoch1, step239]: loss 0.680791
[epoch1, step240]: loss 0.618940
[epoch1, step241]: loss 0.560823
[epoch1, step242]: loss 0.646971
[epoch1, step243]: loss 0.562744
[epoch1, step244]: loss 0.661743
[epoch1, step245]: loss 0.628129
[epoch1, step246]: loss 0.631799
[epoch1, step247]: loss 0.576268
[epoch1, step248]: loss 0.673408
[epoch1, step249]: loss 0.611344
[epoch1, step250]: loss 0.562094
[epoch1, step251]: loss 0.630701
[epoch1, step252]: loss 0.558015
[epoch1, step253]: loss 0.666474
[epoch1, step254]: loss 0.632889
[epoch1, step255]: loss 0.624864
[epoch1, step256]: loss 0.585665
[epoch1, step257]: loss 0.669279
[epoch1, step258]: loss 0.588053
[epoch1, step259]: loss 0.557876
[epoch1, step260]: loss 0.652478
[epoch1, step261]: loss 0.547902
[epoch1, step262]: loss 0.644411
[epoch1, step263]: loss 0.632470
[epoch1, step264]: loss 0.632902
[epoch1, step265]: loss 0.574926
[epoch1, step266]: loss 0.665834
[epoch1, step267]: loss 0.615448
[epoch1, step268]: loss 0.561388
[epoch1, step269]: loss 0.637443
[epoch1, step270]: loss 0.570211
[epoch1, step271]: loss 0.649497
[epoch1, step272]: loss 0.617440
[epoch1, step273]: loss 0.632313
[epoch1, step274]: loss 0.561321
[epoch1, step275]: loss 0.676231
[epoch1, step276]: loss 0.608171
[epoch1, step277]: loss 0.554302
[epoch1, step278]: loss 0.634672
[epoch1, step279]: loss 0.559254
[epoch1, step280]: loss 0.648526
[epoch1, step281]: loss 0.619608
[epoch1, step282]: loss 0.615173
[epoch1, step283]: loss 0.580468
[epoch1, step284]: loss 0.671612
[epoch1, step285]: loss 0.581530
[epoch1, step286]: loss 0.590072
[epoch1, step287]: loss 0.633831
[epoch1, step288]: loss 0.571298
[epoch1, step289]: loss 0.641290
[epoch1, step290]: loss 0.614407
[epoch1, step291]: loss 0.619083
[epoch1, step292]: loss 0.585464
[epoch1, step293]: loss 0.665713
[epoch1, step294]: loss 0.606441
[epoch1, step295]: loss 0.565896
[epoch1, step296]: loss 0.621654
[epoch1, step297]: loss 0.568216
[epoch1, step298]: loss 0.647179
[epoch1, step299]: loss 0.630381
[epoch1, step300]: loss 0.616319
[epoch1, step301]: loss 0.579237
[epoch1, step302]: loss 0.651534
[epoch1, step303]: loss 0.587226
[epoch1, step304]: loss 0.557751
[epoch1, step305]: loss 0.641867
[epoch1, step306]: loss 0.559957
[epoch1, step307]: loss 0.659041
[epoch1, step308]: loss 0.601771
[epoch1, step309]: loss 0.612911
[epoch1, step310]: loss 0.570925
[epoch1, step311]: loss 0.649448
[epoch1, step312]: loss 0.599314
[epoch1, step313]: loss 0.557575
[epoch1, step314]: loss 0.632879
[epoch1, step315]: loss 0.550326
[epoch1, step316]: loss 0.654597
[epoch1, step317]: loss 0.607121
[epoch1, step318]: loss 0.619975
[epoch1, step319]: loss 0.581049
[epoch1, step320]: loss 0.677461
[epoch1, step321]: loss 0.601046
[epoch1, step322]: loss 0.572315
[epoch1, step323]: loss 0.646135
[epoch1, step324]: loss 0.547521
[epoch1, step325]: loss 0.644775
[epoch1, step326]: loss 0.615234
[epoch1, step327]: loss 0.632926
[epoch1, step328]: loss 0.570316
[epoch1, step329]: loss 0.664637
[epoch1, step330]: loss 0.605759
[epoch1, step331]: loss 0.560557
[epoch1, step332]: loss 0.643428
[epoch1, step333]: loss 0.564530
[epoch1, step334]: loss 0.642906
[epoch1, step335]: loss 0.607658
[epoch1, step336]: loss 0.603438
[epoch1, step337]: loss 0.559265
[epoch1, step338]: loss 0.666977
[epoch1, step339]: loss 0.597244
[epoch1, step340]: loss 0.555890
[epoch1, step341]: loss 0.639990
[epoch1, step342]: loss 0.557683
[epoch1, step343]: loss 0.640031
[epoch1, step344]: loss 0.613725
[epoch1, step345]: loss 0.631506
[epoch1, step346]: loss 0.576068
[epoch1, step347]: loss 0.662512
[epoch1, step348]: loss 0.586168
[epoch1, step349]: loss 0.547376
[epoch1, step350]: loss 0.640668
[epoch1, step351]: loss 0.562416
[epoch1, step352]: loss 0.645107
[epoch1, step353]: loss 0.610024
[epoch1, step354]: loss 0.637718
[epoch1, step355]: loss 0.579601
[epoch1, step356]: loss 0.642275
[epoch1, step357]: loss 0.588228
[epoch1, step358]: loss 0.581190
[epoch1, step359]: loss 0.613775
[epoch1, step360]: loss 0.561673
[epoch1, step361]: loss 0.653850
[epoch1, step362]: loss 0.596577
[epoch1, step363]: loss 0.623307
[epoch1, step364]: loss 0.568436
[epoch1, step365]: loss 0.657487
[epoch1, step366]: loss 0.582380
[epoch1, step367]: loss 0.559850
[epoch1, step368]: loss 0.639450
[epoch1, step369]: loss 0.559830
[epoch1, step370]: loss 0.632171
[epoch1, step371]: loss 0.589177
[epoch1, step372]: loss 0.622732
[epoch1, step373]: loss 0.567889
[epoch1, step374]: loss 0.665400
[epoch1, step375]: loss 0.575355
[epoch1, step376]: loss 0.542425
[epoch1, step377]: loss 0.623287
[epoch1, step378]: loss 0.553322
[epoch1, step379]: loss 0.630206
[epoch1, step380]: loss 0.594138
[epoch1, step381]: loss 0.620782
[epoch1, step382]: loss 0.575054
[epoch1, step383]: loss 0.673665
[epoch1, step384]: loss 0.600514
[epoch1, step385]: loss 0.544680
[epoch1, step386]: loss 0.622514
[epoch1, step387]: loss 0.546273
[epoch1, step388]: loss 0.624292
[epoch1, step389]: loss 0.602947
[epoch1, step390]: loss 0.593267
[epoch1, step391]: loss 0.564766
[epoch1, step392]: loss 0.637337
[epoch1, step393]: loss 0.595279
[epoch1, step394]: loss 0.557973
[epoch1, step395]: loss 0.630069
[epoch1, step396]: loss 0.548011
[epoch1, step397]: loss 0.651193
[epoch1, step398]: loss 0.599599
[epoch1, step399]: loss 0.613912
[epoch1, step400]: loss 0.561634
[epoch1, step401]: loss 0.652557
[epoch1, step402]: loss 0.588967
[epoch1, step403]: loss 0.546304
[epoch1, step404]: loss 0.618664
[epoch1, step405]: loss 0.543037
[epoch1, step406]: loss 0.629708
[epoch1, step407]: loss 0.606231
[epoch1, step408]: loss 0.609470
[epoch1, step409]: loss 0.533366
[epoch1, step410]: loss 0.635958
[epoch1, step411]: loss 0.584318
[epoch1, step412]: loss 0.551852
[epoch1, step413]: loss 0.623417
[epoch1, step414]: loss 0.564597
[epoch1, step415]: loss 0.633674
[epoch1, step416]: loss 0.611510
[epoch1, step417]: loss 0.606039
[epoch1, step418]: loss 0.557165
[epoch1, step419]: loss 0.660244
[epoch1, step420]: loss 0.575652
[epoch1, step421]: loss 0.550179
[epoch1, step422]: loss 0.621189
[epoch1, step423]: loss 0.546673
[epoch1, step424]: loss 0.630253
[epoch1, step425]: loss 0.595160
[epoch1, step426]: loss 0.602151
[epoch1, step427]: loss 0.563992
[epoch1, step428]: loss 0.648390
[epoch1, step429]: loss 0.564789
[epoch1, step430]: loss 0.546642
[epoch1, step431]: loss 0.613185
[epoch1, step432]: loss 0.543860
[epoch1, step433]: loss 0.616476
[epoch1, step434]: loss 0.599126
[epoch1, step435]: loss 0.599844
[epoch1, step436]: loss 0.571511
[epoch1, step437]: loss 0.640959
[epoch1, step438]: loss 0.565680
[epoch1, step439]: loss 0.547787
[epoch1, step440]: loss 0.618579
[epoch1, step441]: loss 0.538645
[epoch1, step442]: loss 0.632371
[epoch1, step443]: loss 0.585695
[epoch1, step444]: loss 0.614571
[epoch1, step445]: loss 0.551293
[epoch1, step446]: loss 0.635799
[epoch1, step447]: loss 0.565594
[epoch1, step448]: loss 0.536253
[epoch1, step449]: loss 0.621301
[epoch1, step450]: loss 0.559245
[epoch1, step451]: loss 0.634792
[epoch1, step452]: loss 0.617142
[epoch1, step453]: loss 0.601557
[epoch1, step454]: loss 0.561112
[epoch1, step455]: loss 0.637772
[epoch1, step456]: loss 0.592312
[epoch1, step457]: loss 0.535071
[epoch1, step458]: loss 0.621142
[epoch1, step459]: loss 0.530329
[epoch1, step460]: loss 0.632617
[epoch1, step461]: loss 0.580327
[epoch1, step462]: loss 0.617125
[epoch1, step463]: loss 0.553783
[epoch1, step464]: loss 0.644757
[epoch1, step465]: loss 0.549321
[epoch1, step466]: loss 0.538590
[epoch1, step467]: loss 0.621958
[epoch1, step468]: loss 0.547588
[epoch1, step469]: loss 0.627338
[epoch1, step470]: loss 0.588254
[epoch1, step471]: loss 0.610127
[epoch1, step472]: loss 0.555522
[epoch1, step473]: loss 0.647734
[epoch1, step474]: loss 0.580017
[epoch1, step475]: loss 0.539940
[epoch1, step476]: loss 0.604753
[epoch1, step477]: loss 0.543810
[epoch1, step478]: loss 0.637495
[epoch1, step479]: loss 0.592717
[epoch1, step480]: loss 0.618173
[epoch1, step481]: loss 0.557799
[epoch1, step482]: loss 0.652019
[epoch1, step483]: loss 0.565109
[epoch1, step484]: loss 0.526175
[epoch1, step485]: loss 0.610408
[epoch1, step486]: loss 0.534936
[epoch1, step487]: loss 0.638781
[epoch1, step488]: loss 0.583875
[epoch1, step489]: loss 0.617298
[epoch1, step490]: loss 0.551378
[epoch1, step491]: loss 0.632067
[epoch1, step492]: loss 0.577315
[epoch1, step493]: loss 0.538187
[epoch1, step494]: loss 0.623823
[epoch1, step495]: loss 0.515394
[epoch1, step496]: loss 0.629832
[epoch1, step497]: loss 0.586567
[epoch1, step498]: loss 0.601326
[epoch1, step499]: loss 0.551113
[epoch1, step500]: loss 0.647392
[epoch1, step501]: loss 0.584154
[epoch1, step502]: loss 0.538998
[epoch1, step503]: loss 0.608691
[epoch1, step504]: loss 0.555225
[epoch1, step505]: loss 0.645722
[epoch1, step506]: loss 0.576950
[epoch1, step507]: loss 0.592371
[epoch1, step508]: loss 0.543912
[epoch1, step509]: loss 0.642390
[epoch1, step510]: loss 0.569304
[epoch1, step511]: loss 0.542332
[epoch1, step512]: loss 0.603293
[epoch1, step513]: loss 0.540474
[epoch1, step514]: loss 0.621152
[epoch1, step515]: loss 0.588704
[epoch1, step516]: loss 0.590539
[epoch1, step517]: loss 0.554190
[epoch1, step518]: loss 0.634886
[epoch1, step519]: loss 0.569175
[epoch1, step520]: loss 0.536709
[epoch1, step521]: loss 0.617838
[epoch1, step522]: loss 0.544927
[epoch1, step523]: loss 0.624735
[epoch1, step524]: loss 0.602788
[epoch1, step525]: loss 0.590702
[epoch1, step526]: loss 0.538487
[epoch1, step527]: loss 0.643429
[epoch1, step528]: loss 0.563603
[epoch1, step529]: loss 0.546681
[epoch1, step530]: loss 0.602584
[epoch1, step531]: loss 0.537625
[epoch1, step532]: loss 0.632951
[epoch1, step533]: loss 0.566676
[epoch1, step534]: loss 0.598381
[epoch1, step535]: loss 0.543674
[epoch1, step536]: loss 0.630542
[epoch1, step537]: loss 0.566092
[epoch1, step538]: loss 0.545314
[epoch1, step539]: loss 0.611992
[epoch1, step540]: loss 0.554136
[epoch1, step541]: loss 0.632808
[epoch1, step542]: loss 0.587129
[epoch1, step543]: loss 0.599370
[epoch1, step544]: loss 0.538722
[epoch1, step545]: loss 0.650676
[epoch1, step546]: loss 0.558694
[epoch1, step547]: loss 0.549995
[epoch1, step548]: loss 0.610411
[epoch1, step549]: loss 0.533718
[epoch1, step550]: loss 0.621202
[epoch1, step551]: loss 0.585600
[epoch1, step552]: loss 0.605073
[epoch1, step553]: loss 0.543118
[epoch1, step554]: loss 0.640005
[epoch1, step555]: loss 0.575711
[epoch1, step556]: loss 0.530723
[epoch1, step557]: loss 0.617290
[epoch1, step558]: loss 0.532070
[epoch1, step559]: loss 0.632482
[epoch1, step560]: loss 0.582058
[epoch1, step561]: loss 0.598400
[epoch1, step562]: loss 0.540979
[epoch1, step563]: loss 0.756314
[epoch1, step564]: loss 0.564300
[epoch1, step565]: loss 0.439537
[epoch1, step566]: loss 0.462428
[epoch1, step567]: loss 0.457728
[epoch1, step568]: loss 0.524962
[epoch1, step569]: loss 0.628885
[epoch1, step570]: loss 0.527215
[epoch1, step571]: loss 0.366196
[epoch1, step572]: loss 0.523897
[epoch1, step573]: loss 0.545213
[epoch1, step574]: loss 0.673780
[epoch1, step575]: loss 0.587020
[epoch1, step576]: loss 0.601734
[epoch1, step577]: loss 0.503405
[epoch1, step578]: loss 0.605782
[epoch1, step579]: loss 0.469679
[epoch1, step580]: loss 0.687635
[epoch1, step581]: loss 0.597615
[epoch1, step582]: loss 0.580055
[epoch1, step583]: loss 0.590150
[epoch1, step584]: loss 0.548160
[epoch1, step585]: loss 0.653576
[epoch1, step586]: loss 0.578568
[epoch1, step587]: loss 0.402241
[epoch1, step588]: loss 0.580488
[epoch1, step589]: loss 0.769909
[epoch1, step590]: loss 0.431890
[epoch1, step591]: loss 0.567154
[epoch1, step592]: loss 0.620478
[epoch1, step593]: loss 0.761106
[epoch1, step594]: loss 0.442041
[epoch1, step595]: loss 0.444016
[epoch1, step596]: loss 0.634108
[epoch1, step597]: loss 0.654451
[epoch1, step598]: loss 0.475883
[epoch1, step599]: loss 0.442958
[epoch1, step600]: loss 0.427724
[epoch1, step601]: loss 0.572149
[epoch1, step602]: loss 0.685151
[epoch1, step603]: loss 0.496469
[epoch1, step604]: loss 0.484342
[epoch1, step605]: loss 0.425709
[epoch1, step606]: loss 0.548478
[epoch1, step607]: loss 0.602385
[epoch1, step608]: loss 0.369241
[epoch1, step609]: loss 0.564750
[epoch1, step610]: loss 0.493205
[epoch1, step611]: loss 0.626204
[epoch1, step612]: loss 0.572092
[epoch1, step613]: loss 0.638599
[epoch1, step614]: loss 0.552036
[epoch1, step615]: loss 0.565510
[epoch1, step616]: loss 0.449658
[epoch1, step617]: loss 0.522449
[epoch1, step618]: loss 0.616955
[epoch1, step619]: loss 0.458067
[epoch1, step620]: loss 0.425596
[epoch1, step621]: loss 0.412228
[epoch1, step622]: loss 0.606416
[epoch1, step623]: loss 0.580373
[epoch1, step624]: loss 0.578687
[epoch1, step625]: loss 0.422341
[epoch1, step626]: loss 0.580911
[epoch1, step627]: loss 0.678055
[epoch1, step628]: loss 0.615558
[epoch1, step629]: loss 0.332330
[epoch1, step630]: loss 0.481835
[epoch1, step631]: loss 0.467754
[epoch1, step632]: loss 0.584498
[epoch1, step633]: loss 0.471943
[epoch1, step634]: loss 0.542919
[epoch1, step635]: loss 0.521211
[epoch1, step636]: loss 0.459098
[epoch1, step637]: loss 0.612994
[epoch1, step638]: loss 0.564471
[epoch1, step639]: loss 0.433930
[epoch1, step640]: loss 0.580479
[epoch1, step641]: loss 0.441125
[epoch1, step642]: loss 0.437039
[epoch1, step643]: loss 0.591927
[epoch1, step644]: loss 0.516622
[epoch1, step645]: loss 0.395646
[epoch1, step646]: loss 0.532538
[epoch1, step647]: loss 0.408556
[epoch1, step648]: loss 0.678499
[epoch1, step649]: loss 0.567398
[epoch1, step650]: loss 0.618416
[epoch1, step651]: loss 0.506866
[epoch1, step652]: loss 0.645383
[epoch1, step653]: loss 0.617688
[epoch1, step654]: loss 0.601713
[epoch1, step655]: loss 0.449446
[epoch1, step656]: loss 0.635312
[epoch1, step657]: loss 0.621106
[epoch1, step658]: loss 0.476996
[epoch1, step659]: loss 0.404225
[epoch1, step660]: loss 0.538159
[epoch1, step661]: loss 0.575270
[epoch1, step662]: loss 0.413610
[epoch1, step663]: loss 0.530604
[epoch1, step664]: loss 0.506566
[epoch1, step665]: loss 0.650770
[epoch1, step666]: loss 0.427806
[epoch1, step667]: loss 0.568446
[epoch1, step668]: loss 0.668613
[epoch1, step669]: loss 0.434311
[epoch1, step670]: loss 0.546980
[epoch1, step671]: loss 0.571324
[epoch1, step672]: loss 0.690450
[epoch1, step673]: loss 0.637299
[epoch1, step674]: loss 0.525117
[epoch1, step675]: loss 0.614272
[epoch1, step676]: loss 0.588972
[epoch1, step677]: loss 0.498750
[epoch1, step678]: loss 0.430116
[epoch1, step679]: loss 0.530809
[epoch1, step680]: loss 0.414379
[epoch1, step681]: loss 0.437174
[epoch1, step682]: loss 0.445097
[epoch1, step683]: loss 0.544135
[epoch1, step684]: loss 0.447962
[epoch1, step685]: loss 0.450075
[epoch1, step686]: loss 0.428189
[epoch1, step687]: loss 0.473013
[epoch1, step688]: loss 0.590022
[epoch1, step689]: loss 0.450021
[epoch1, step690]: loss 0.609256
[epoch1, step691]: loss 0.636946
[epoch1, step692]: loss 0.616677
[epoch1, step693]: loss 0.554414
[epoch1, step694]: loss 0.416243
[epoch1, step695]: loss 0.487201
[epoch1, step696]: loss 0.446952
[epoch1, step697]: loss 0.553861
[epoch1, step698]: loss 0.493205
[epoch1, step699]: loss 0.504153
[epoch1, step700]: loss 0.684537
[epoch1, step701]: loss 0.578978
[epoch1, step702]: loss 0.493911
[epoch1, step703]: loss 0.666254
[epoch1, step704]: loss 0.610878
[epoch1, step705]: loss 0.452248
[epoch1, step706]: loss 0.470668
[epoch1, step707]: loss 0.487679
[epoch1, step708]: loss 0.539239
[epoch1, step709]: loss 0.459316
[epoch1, step710]: loss 0.558715
[epoch1, step711]: loss 0.615362
[epoch1, step712]: loss 0.405886
[epoch1, step713]: loss 0.479942
[epoch1, step714]: loss 0.583069
[epoch1, step715]: loss 0.473462
[epoch1, step716]: loss 0.553842
[epoch1, step717]: loss 0.461966
[epoch1, step718]: loss 0.515767
[epoch1, step719]: loss 0.512120
[epoch1, step720]: loss 0.458133
[epoch1, step721]: loss 0.508995
[epoch1, step722]: loss 0.528427
[epoch1, step723]: loss 0.513722
[epoch1, step724]: loss 0.565184
[epoch1, step725]: loss 0.553424
[epoch1, step726]: loss 0.383906
[epoch1, step727]: loss 0.546413
[epoch1, step728]: loss 0.557150
[epoch1, step729]: loss 0.448025
[epoch1, step730]: loss 0.558874
[epoch1, step731]: loss 0.607355
[epoch1, step732]: loss 0.504745
[epoch1, step733]: loss 0.407730
[epoch1, step734]: loss 0.469198
[epoch1, step735]: loss 0.458124
[epoch1, step736]: loss 0.494050
[epoch1, step737]: loss 0.429205
[epoch1, step738]: loss 0.473441
[epoch1, step739]: loss 0.667498
[epoch1, step740]: loss 0.721962
[epoch1, step741]: loss 0.540799
[epoch1, step742]: loss 0.630096
[epoch1, step743]: loss 0.532513
[epoch1, step744]: loss 0.513955
[epoch1, step745]: loss 0.522018
[epoch1, step746]: loss 0.568216
[epoch1, step747]: loss 0.503316
[epoch1, step748]: loss 0.450036
[epoch1, step749]: loss 0.672370
[epoch1, step750]: loss 0.560997
[epoch1, step751]: loss 0.496518
[epoch1, step752]: loss 0.433477
[epoch1, step753]: loss 0.448223
[epoch1, step754]: loss 0.622827
[epoch1, step755]: loss 0.554578
[epoch1, step756]: loss 0.407290
[epoch1, step757]: loss 0.523343
[epoch1, step758]: loss 0.576968
[epoch1, step759]: loss 0.454866
[epoch1, step760]: loss 0.554671
[epoch1, step761]: loss 0.495496
[epoch1, step762]: loss 0.475393
[epoch1, step763]: loss 0.472642
[epoch1, step764]: loss 0.548138
[epoch1, step765]: loss 0.467718
[epoch1, step766]: loss 0.432944
[epoch1, step767]: loss 0.565405
[epoch1, step768]: loss 0.526721
[epoch1, step769]: loss 0.518827
[epoch1, step770]: loss 0.657284
[epoch1, step771]: loss 0.432672
[epoch1, step772]: loss 0.424047
[epoch1, step773]: loss 0.497725
[epoch1, step774]: loss 0.523504
[epoch1, step775]: loss 0.650745
[epoch1, step776]: loss 0.554246
[epoch1, step777]: loss 0.482826
[epoch1, step778]: loss 0.587804
[epoch1, step779]: loss 0.501444
[epoch1, step780]: loss 0.576872
[epoch1, step781]: loss 0.656021
[epoch1, step782]: loss 0.622576
[epoch1, step783]: loss 0.539680
[epoch1, step784]: loss 0.616898
[epoch1, step785]: loss 0.597412
[epoch1, step786]: loss 0.515176
[epoch1, step787]: loss 0.648861
[epoch1, step788]: loss 0.533463
[epoch1, step789]: loss 0.621410
[epoch1, step790]: loss 0.429449
[epoch1, step791]: loss 0.554471
[epoch1, step792]: loss 0.564614
[epoch1, step793]: loss 0.569041
[epoch1, step794]: loss 0.542326
[epoch1, step795]: loss 0.511903
[epoch1, step796]: loss 0.488329
[epoch1, step797]: loss 0.443963
[epoch1, step798]: loss 0.445037
[epoch1, step799]: loss 0.376973
[epoch1, step800]: loss 0.685021
[epoch1, step801]: loss 0.636533
[epoch1, step802]: loss 0.514131
[epoch1, step803]: loss 0.465936
[epoch1, step804]: loss 0.552501
[epoch1, step805]: loss 0.487697
[epoch1, step806]: loss 0.534410
[epoch1, step807]: loss 0.589362
[epoch1, step808]: loss 0.651592
[epoch1, step809]: loss 0.477755
[epoch1, step810]: loss 0.394861
[epoch1, step811]: loss 0.512861
[epoch1, step812]: loss 0.569029
[epoch1, step813]: loss 0.474410
[epoch1, step814]: loss 0.535572
[epoch1, step815]: loss 0.505223
[epoch1, step816]: loss 0.524579
[epoch1, step817]: loss 0.447028
[epoch1, step818]: loss 0.492112
[epoch1, step819]: loss 0.770594
[epoch1, step820]: loss 0.463926
[epoch1, step821]: loss 0.452329
[epoch1, step822]: loss 0.527875
[epoch1, step823]: loss 0.446437
[epoch1, step824]: loss 0.513641
[epoch1, step825]: loss 0.547845
[epoch1, step826]: loss 0.368624
[epoch1, step827]: loss 0.457967
[epoch1, step828]: loss 0.503732
[epoch1, step829]: loss 0.468495
[epoch1, step830]: loss 0.354095
[epoch1, step831]: loss 0.440371
[epoch1, step832]: loss 0.656285
[epoch1, step833]: loss 0.526621
[epoch1, step834]: loss 0.520246
[epoch1, step835]: loss 0.548023
[epoch1, step836]: loss 0.450678
[epoch1, step837]: loss 0.419755
[epoch1, step838]: loss 0.585570
[epoch1, step839]: loss 0.508421
[epoch1, step840]: loss 0.473022
[epoch1, step841]: loss 0.506765
[epoch1, step842]: loss 0.498537
[epoch1, step843]: loss 0.578569
[epoch1, step844]: loss 0.582480
[epoch1, step845]: loss 0.556073
[epoch1, step846]: loss 0.687824
[epoch1, step847]: loss 0.513519
[epoch1, step848]: loss 0.272927
[epoch1, step849]: loss 0.467497
[epoch1, step850]: loss 0.587395
[epoch1, step851]: loss 0.494949
[epoch1, step852]: loss 0.511676
[epoch1, step853]: loss 0.550844
[epoch1, step854]: loss 0.586502
[epoch1, step855]: loss 0.455050
[epoch1, step856]: loss 0.414159
[epoch1, step857]: loss 0.543621
[epoch1, step858]: loss 0.566539
[epoch1, step859]: loss 0.461583
[epoch1, step860]: loss 0.593248
[epoch1, step861]: loss 0.532774
[epoch1, step862]: loss 0.414577
[epoch1, step863]: loss 0.584688
[epoch1, step864]: loss 0.594953
[epoch1, step865]: loss 0.550738
[epoch1, step866]: loss 0.577823
[epoch1, step867]: loss 0.476353
[epoch1, step868]: loss 0.532546
[epoch1, step869]: loss 0.451295
[epoch1, step870]: loss 0.407410
[epoch1, step871]: loss 0.655541
[epoch1, step872]: loss 0.561492
[epoch1, step873]: loss 0.425060
[epoch1, step874]: loss 0.505528
[epoch1, step875]: loss 0.665214
[epoch1, step876]: loss 0.597415
[epoch1, step877]: loss 0.322184
[epoch1, step878]: loss 0.457315
[epoch1, step879]: loss 0.483205
[epoch1, step880]: loss 0.467147
[epoch1, step881]: loss 0.601900
[epoch1, step882]: loss 0.459582
[epoch1, step883]: loss 0.481236
[epoch1, step884]: loss 0.634202
[epoch1, step885]: loss 0.641489
[epoch1, step886]: loss 0.606492
[epoch1, step887]: loss 0.651029
[epoch1, step888]: loss 0.485887
[epoch1, step889]: loss 0.567204
[epoch1, step890]: loss 0.574037
[epoch1, step891]: loss 0.479856
[epoch1, step892]: loss 0.580474
[epoch1, step893]: loss 0.551173
[epoch1, step894]: loss 0.559487
[epoch1, step895]: loss 0.429257
[epoch1, step896]: loss 0.712510
[epoch1, step897]: loss 0.702698
[epoch1, step898]: loss 0.445727
[epoch1, step899]: loss 0.307414
[epoch1, step900]: loss 0.509606
[epoch1, step901]: loss 0.605145
[epoch1, step902]: loss 0.458644
[epoch1, step903]: loss 0.623338
[epoch1, step904]: loss 0.440084
[epoch1, step905]: loss 0.417291
[epoch1, step906]: loss 0.406130
[epoch1, step907]: loss 0.569656
[epoch1, step908]: loss 0.630450
[epoch1, step909]: loss 0.495965
[epoch1, step910]: loss 0.415840
[epoch1, step911]: loss 0.391268
[epoch1, step912]: loss 0.577778
[epoch1, step913]: loss 0.590497
[epoch1, step914]: loss 0.499720
[epoch1, step915]: loss 0.459064
[epoch1, step916]: loss 0.538577
[epoch1, step917]: loss 0.517415
[epoch1, step918]: loss 0.579971
[epoch1, step919]: loss 0.423452
[epoch1, step920]: loss 0.595164
[epoch1, step921]: loss 0.469577
[epoch1, step922]: loss 0.487033
[epoch1, step923]: loss 0.624158
[epoch1, step924]: loss 0.480099
[epoch1, step925]: loss 0.469914
[epoch1, step926]: loss 0.476616
[epoch1, step927]: loss 0.609883
[epoch1, step928]: loss 0.461304
[epoch1, step929]: loss 0.485857
[epoch1, step930]: loss 0.509373
[epoch1, step931]: loss 0.564640
[epoch1, step932]: loss 0.465803
[epoch1, step933]: loss 0.468803
[epoch1, step934]: loss 0.634649
[epoch1, step935]: loss 0.535360
[epoch1, step936]: loss 0.462579
[epoch1, step937]: loss 0.402583
[epoch1, step938]: loss 0.655825
[epoch1, step939]: loss 0.484507
[epoch1, step940]: loss 0.584988
[epoch1, step941]: loss 0.530680
[epoch1, step942]: loss 0.525080
[epoch1, step943]: loss 0.617503
[epoch1, step944]: loss 0.523838
[epoch1, step945]: loss 0.601526
[epoch1, step946]: loss 0.511262
[epoch1, step947]: loss 0.449363
[epoch1, step948]: loss 0.748316
[epoch1, step949]: loss 0.526874
[epoch1, step950]: loss 0.493305
[epoch1, step951]: loss 0.537083
[epoch1, step952]: loss 0.573237
[epoch1, step953]: loss 0.505980
[epoch1, step954]: loss 0.563670
[epoch1, step955]: loss 0.379644
[epoch1, step956]: loss 0.569523
[epoch1, step957]: loss 0.521101
[epoch1, step958]: loss 0.622806
[epoch1, step959]: loss 0.552704
[epoch1, step960]: loss 0.506209
[epoch1, step961]: loss 0.557278
[epoch1, step962]: loss 0.563496
[epoch1, step963]: loss 0.587414
[epoch1, step964]: loss 0.529310
[epoch1, step965]: loss 0.600584
[epoch1, step966]: loss 0.523118
[epoch1, step967]: loss 0.608432
[epoch1, step968]: loss 0.557586
[epoch1, step969]: loss 0.485668
[epoch1, step970]: loss 0.559848
[epoch1, step971]: loss 0.565357
[epoch1, step972]: loss 0.567911
[epoch1, step973]: loss 0.548570
[epoch1, step974]: loss 0.571607
[epoch1, step975]: loss 0.517663
[epoch1, step976]: loss 0.611242
[epoch1, step977]: loss 0.538223
[epoch1, step978]: loss 0.486401
[epoch1, step979]: loss 0.570133
[epoch1, step980]: loss 0.568001
[epoch1, step981]: loss 0.577578
[epoch1, step982]: loss 0.529813
[epoch1, step983]: loss 0.577833
[epoch1, step984]: loss 0.524484
[epoch1, step985]: loss 0.610278
[epoch1, step986]: loss 0.531851
[epoch1, step987]: loss 0.474490
[epoch1, step988]: loss 0.545007
[epoch1, step989]: loss 0.553862
[epoch1, step990]: loss 0.576890
[epoch1, step991]: loss 0.518126
[epoch1, step992]: loss 0.580648
[epoch1, step993]: loss 0.523815
[epoch1, step994]: loss 0.617877
[epoch1, step995]: loss 0.543788
[epoch1, step996]: loss 0.487968
[epoch1, step997]: loss 0.551921
[epoch1, step998]: loss 0.550844
[epoch1, step999]: loss 0.569434
[epoch1, step1000]: loss 0.529798
[epoch1, step1001]: loss 0.576045
[epoch1, step1002]: loss 0.510132
[epoch1, step1003]: loss 0.608873
[epoch1, step1004]: loss 0.536074
[epoch1, step1005]: loss 0.494927
[epoch1, step1006]: loss 0.553998
[epoch1, step1007]: loss 0.564631
[epoch1, step1008]: loss 0.577832
[epoch1, step1009]: loss 0.528950
[epoch1, step1010]: loss 0.564665
[epoch1, step1011]: loss 0.514841
[epoch1, step1012]: loss 0.593573
[epoch1, step1013]: loss 0.538642
[epoch1, step1014]: loss 0.476881
[epoch1, step1015]: loss 0.546640
[epoch1, step1016]: loss 0.563347
[epoch1, step1017]: loss 0.578797
[epoch1, step1018]: loss 0.527203
[epoch1, step1019]: loss 0.574141
[epoch1, step1020]: loss 0.521646
[epoch1, step1021]: loss 0.605445
[epoch1, step1022]: loss 0.541655
[epoch1, step1023]: loss 0.485318
[epoch1, step1024]: loss 0.533756
[epoch1, step1025]: loss 0.569357
[epoch1, step1026]: loss 0.584075
[epoch1, step1027]: loss 0.523312
[epoch1, step1028]: loss 0.574897
[epoch1, step1029]: loss 0.515093
[epoch1, step1030]: loss 0.609110
[epoch1, step1031]: loss 0.567875
[epoch1, step1032]: loss 0.481400
[epoch1, step1033]: loss 0.565183
[epoch1, step1034]: loss 0.563224
[epoch1, step1035]: loss 0.584569
[epoch1, step1036]: loss 0.530374
[epoch1, step1037]: loss 0.579204
[epoch1, step1038]: loss 0.516693
[epoch1, step1039]: loss 0.597972
[epoch1, step1040]: loss 0.551091
[epoch1, step1041]: loss 0.489021
[epoch1, step1042]: loss 0.558501
[epoch1, step1043]: loss 0.560088
[epoch1, step1044]: loss 0.567261
[epoch1, step1045]: loss 0.521866
[epoch1, step1046]: loss 0.571622
[epoch1, step1047]: loss 0.509342
[epoch1, step1048]: loss 0.610895
[epoch1, step1049]: loss 0.539664
[epoch1, step1050]: loss 0.481499
[epoch1, step1051]: loss 0.548521
[epoch1, step1052]: loss 0.552181
[epoch1, step1053]: loss 0.570264
[epoch1, step1054]: loss 0.529339
[epoch1, step1055]: loss 0.583155
[epoch1, step1056]: loss 0.524547
[epoch1, step1057]: loss 0.587636
[epoch1, step1058]: loss 0.523361
[epoch1, step1059]: loss 0.481531
[epoch1, step1060]: loss 0.540431
[epoch1, step1061]: loss 0.572066
[epoch1, step1062]: loss 0.561637
[epoch1, step1063]: loss 0.526915
[epoch1, step1064]: loss 0.574423
[epoch1, step1065]: loss 0.520401
[epoch1, step1066]: loss 0.606481
[epoch1, step1067]: loss 0.538270
[epoch1, step1068]: loss 0.510452
[epoch1, step1069]: loss 0.543347
[epoch1, step1070]: loss 0.556284
[epoch1, step1071]: loss 0.557014
[epoch1, step1072]: loss 0.511082
[epoch1, step1073]: loss 0.574991
[epoch1, step1074]: loss 0.519641
[epoch1, step1075]: loss 0.592183
[epoch1, step1076]: loss 0.534620
[epoch1, step1077]: loss 0.480734
[epoch1, step1078]: loss 0.552703
[epoch1, step1079]: loss 0.538619
[epoch1, step1080]: loss 0.561384
[epoch1, step1081]: loss 0.533650
[epoch1, step1082]: loss 0.574466
[epoch1, step1083]: loss 0.504748
[epoch1, step1084]: loss 0.593026
[epoch1, step1085]: loss 0.547094
[epoch1, step1086]: loss 0.490651
[epoch1, step1087]: loss 0.548497
[epoch1, step1088]: loss 0.559995
[epoch1, step1089]: loss 0.559704
[epoch1, step1090]: loss 0.514141
[epoch1, step1091]: loss 0.566251
[epoch1, step1092]: loss 0.515077
[epoch1, step1093]: loss 0.595106
[epoch1, step1094]: loss 0.553925
[epoch1, step1095]: loss 0.484328
[epoch1, step1096]: loss 0.557029
[epoch1, step1097]: loss 0.551606
[epoch1, step1098]: loss 0.568961
[epoch1, step1099]: loss 0.530565
[epoch1, step1100]: loss 0.559088
[epoch1, step1101]: loss 0.514961
[epoch1, step1102]: loss 0.599982
[epoch1, step1103]: loss 0.545214
[epoch1, step1104]: loss 0.480628
[epoch1, step1105]: loss 0.539677
[epoch1, step1106]: loss 0.570010
[epoch1, step1107]: loss 0.563550
[epoch1, step1108]: loss 0.530103
[epoch1, step1109]: loss 0.560830
[epoch1, step1110]: loss 0.499197
[epoch1, step1111]: loss 0.591650
[epoch1, step1112]: loss 0.527583
[epoch1, step1113]: loss 0.481718
[epoch1, step1114]: loss 0.541155
[epoch1, step1115]: loss 0.547680
[epoch1, step1116]: loss 0.561724
[epoch1, step1117]: loss 0.519160
[epoch1, step1118]: loss 0.570648
[epoch1, step1119]: loss 0.521474
[epoch1, step1120]: loss 0.598650
[epoch1, step1121]: loss 0.535998
[epoch1, step1122]: loss 0.482672
[epoch1, step1123]: loss 0.554995
[epoch1, step1124]: loss 0.541507
[epoch1, step1125]: loss 0.557333
[epoch1, step1126]: loss 0.506536
[epoch1, step1127]: loss 0.565235
[epoch1, step1128]: loss 0.510948
[epoch1, step1129]: loss 0.596293
[epoch1, step1130]: loss 0.516757
[epoch1, step1131]: loss 0.471602
[epoch1, step1132]: loss 0.536240
[epoch1, step1133]: loss 0.560129
[epoch1, step1134]: loss 0.565920
[epoch1, step1135]: loss 0.498838
[epoch1, step1136]: loss 0.553906
[epoch1, step1137]: loss 0.503542
[epoch1, step1138]: loss 0.587332
[epoch1, step1139]: loss 0.536746
[epoch1, step1140]: loss 0.479943
[epoch1, step1141]: loss 0.538331
[epoch1, step1142]: loss 0.557951
[epoch1, step1143]: loss 0.571002
[epoch1, step1144]: loss 0.521607
[epoch1, step1145]: loss 0.575519
[epoch1, step1146]: loss 0.508386
[epoch1, step1147]: loss 0.575149
[epoch1, step1148]: loss 0.532830
[epoch1, step1149]: loss 0.477748
[epoch1, step1150]: loss 0.549313
[epoch1, step1151]: loss 0.546406
[epoch1, step1152]: loss 0.549524
[epoch1, step1153]: loss 0.527247
[epoch1, step1154]: loss 0.558475
[epoch1, step1155]: loss 0.503363
[epoch1, step1156]: loss 0.603643
[epoch1, step1157]: loss 0.538525
[epoch1, step1158]: loss 0.470442
[epoch1, step1159]: loss 0.535487
[epoch1, step1160]: loss 0.537147
[epoch1, step1161]: loss 0.549982
[epoch1, step1162]: loss 0.520562
[epoch1, step1163]: loss 0.576276
[epoch1, step1164]: loss 0.503272
[epoch1, step1165]: loss 0.569284
[epoch1, step1166]: loss 0.526809
[epoch1, step1167]: loss 0.481144
[epoch1, step1168]: loss 0.537085
[epoch1, step1169]: loss 0.551827
[epoch1, step1170]: loss 0.559365
[epoch1, step1171]: loss 0.520858
[epoch1, step1172]: loss 0.565496
[epoch1, step1173]: loss 0.506009
[epoch1, step1174]: loss 0.581172
[epoch1, step1175]: loss 0.534751
[epoch1, step1176]: loss 0.478091
[epoch1, step1177]: loss 0.530124
[epoch1, step1178]: loss 0.542744
[epoch1, step1179]: loss 0.560563
[epoch1, step1180]: loss 0.513777
[epoch1, step1181]: loss 0.552658
[epoch1, step1182]: loss 0.512729
[epoch1, step1183]: loss 0.576096
[epoch1, step1184]: loss 0.540733
[epoch1, step1185]: loss 0.478617
[epoch1, step1186]: loss 0.544349
[epoch1, step1187]: loss 0.563898
[epoch1, step1188]: loss 0.566739
[epoch1, step1189]: loss 0.517658
[epoch1, step1190]: loss 0.569409
[epoch1, step1191]: loss 0.500821
[epoch1, step1192]: loss 0.581326
[epoch1, step1193]: loss 0.528104
[epoch1, step1194]: loss 0.477435
[epoch1, step1195]: loss 0.561364
[epoch1, step1196]: loss 0.559714
[epoch1, step1197]: loss 0.554224
[epoch1, step1198]: loss 0.512872
[epoch1, step1199]: loss 0.567768
[epoch1, step1200]: loss 0.505170
[epoch1, step1201]: loss 0.577707
[epoch1, step1202]: loss 0.512641
[epoch1, step1203]: loss 0.480455
[epoch1, step1204]: loss 0.543330
[epoch1, step1205]: loss 0.550537
[epoch1, step1206]: loss 0.566450
[epoch1, step1207]: loss 0.503267
[epoch1, step1208]: loss 0.556255
[epoch1, step1209]: loss 0.515470
[epoch1, step1210]: loss 0.575342
[epoch1, step1211]: loss 0.538368
[epoch1, step1212]: loss 0.479883
[epoch1, step1213]: loss 0.548253
[epoch1, step1214]: loss 0.541952
[epoch1, step1215]: loss 0.543642
[epoch1, step1216]: loss 0.514945
[epoch1, step1217]: loss 0.549869
[epoch1, step1218]: loss 0.503341
[epoch1, step1219]: loss 0.573453
[epoch1, step1220]: loss 0.519249
[epoch1, step1221]: loss 0.482734
[epoch1, step1222]: loss 0.534641
[epoch1, step1223]: loss 0.545169
[epoch1, step1224]: loss 0.544410
[epoch1, step1225]: loss 0.512543
[epoch1, step1226]: loss 0.567295
[epoch1, step1227]: loss 0.497380
[epoch1, step1228]: loss 0.589211
[epoch1, step1229]: loss 0.536141
[epoch1, step1230]: loss 0.477325
[epoch1, step1231]: loss 0.542587
[epoch1, step1232]: loss 0.527960
[epoch1, step1233]: loss 0.557640
[epoch1, step1234]: loss 0.515763
[epoch1, step1235]: loss 0.550842
[epoch1, step1236]: loss 0.508051
[epoch1, step1237]: loss 0.591742
[epoch1, step1238]: loss 0.538474
[epoch1, step1239]: loss 0.464101
[epoch1, step1240]: loss 0.527359
[epoch1, step1241]: loss 0.556375
[epoch1, step1242]: loss 0.556387
[epoch1, step1243]: loss 0.508043
[epoch1, step1244]: loss 0.553856
[epoch1, step1245]: loss 0.491863
[epoch1, step1246]: loss 0.578109
[epoch1, step1247]: loss 0.542199
[epoch1, step1248]: loss 0.474693
[epoch1, step1249]: loss 0.525005
[epoch1, step1250]: loss 0.545329
[epoch1, step1251]: loss 0.550031
[epoch1, step1252]: loss 0.504172
[epoch1, step1253]: loss 0.552283
[epoch1, step1254]: loss 0.498237
[epoch1, step1255]: loss 0.580917
[epoch1, step1256]: loss 0.516447
[epoch1, step1257]: loss 0.467166
[epoch1, step1258]: loss 0.534238
[epoch1, step1259]: loss 0.546378
[epoch1, step1260]: loss 0.551367
[epoch1, step1261]: loss 0.515285
[epoch1, step1262]: loss 0.576504
[epoch1, step1263]: loss 0.486164
[epoch1, step1264]: loss 0.585523
[epoch1, step1265]: loss 0.549686
[epoch1, step1266]: loss 0.474342
[epoch1, step1267]: loss 0.533332
[epoch1, step1268]: loss 0.538934
[epoch1, step1269]: loss 0.548690
[epoch1, step1270]: loss 0.521827
[epoch1, step1271]: loss 0.548509
[epoch1, step1272]: loss 0.495699
[epoch1, step1273]: loss 0.587185
[epoch1, step1274]: loss 0.532268
[epoch1, step1275]: loss 0.470107
[epoch1, step1276]: loss 0.534542
[epoch1, step1277]: loss 0.543561
[epoch1, step1278]: loss 0.540161
[epoch1, step1279]: loss 0.506143
[epoch1, step1280]: loss 0.552477
[epoch1, step1281]: loss 0.499777
[epoch1, step1282]: loss 0.579463
[epoch1, step1283]: loss 0.534929
[epoch1, step1284]: loss 0.469273
[epoch1, step1285]: loss 0.529339
[epoch1, step1286]: loss 0.551343
[epoch1, step1287]: loss 0.535915
[epoch1, step1288]: loss 0.497499
[epoch1, step1289]: loss 0.538472
[epoch1, step1290]: loss 0.502479
[epoch1, step1291]: loss 0.583507
[epoch1, step1292]: loss 0.510271
[epoch1, step1293]: loss 0.475995
[epoch1, step1294]: loss 0.528744
[epoch1, step1295]: loss 0.530677
[epoch1, step1296]: loss 0.544820
[epoch1, step1297]: loss 0.503655
[epoch1, step1298]: loss 0.543603
[epoch1, step1299]: loss 0.497972
[epoch1, step1300]: loss 0.569570
[epoch1, step1301]: loss 0.543484
[epoch1, step1302]: loss 0.466592
[epoch1, step1303]: loss 0.535881
[epoch1, step1304]: loss 0.550300
[epoch1, step1305]: loss 0.539201
[epoch1, step1306]: loss 0.510546
[epoch1, step1307]: loss 0.563977
[epoch1, step1308]: loss 0.499457
[epoch1, step1309]: loss 0.590111
[epoch1, step1310]: loss 0.525208
[epoch1, step1311]: loss 0.480333
[epoch1, step1312]: loss 0.526666
[epoch1, step1313]: loss 0.537303
[epoch1, step1314]: loss 0.552704
[epoch1, step1315]: loss 0.509378
[epoch1, step1316]: loss 0.528269
[epoch1, step1317]: loss 0.505160
[epoch1, step1318]: loss 0.589288
[epoch1, step1319]: loss 0.529994
[epoch1, step1320]: loss 0.467032
[epoch1, step1321]: loss 0.518373
[epoch1, step1322]: loss 0.546792
[epoch1, step1323]: loss 0.540571
[epoch1, step1324]: loss 0.512872
[epoch1, step1325]: loss 0.553782
[epoch1, step1326]: loss 0.505784
[epoch1, step1327]: loss 0.577388
[epoch1, step1328]: loss 0.522957
[epoch1, step1329]: loss 0.468608
[epoch1, step1330]: loss 0.526855
[epoch1, step1331]: loss 0.545407
[epoch1, step1332]: loss 0.551760
[epoch1, step1333]: loss 0.527520
[epoch1, step1334]: loss 0.544651
[epoch1, step1335]: loss 0.493226
[epoch1, step1336]: loss 0.574160
[epoch1, step1337]: loss 0.535019
[epoch1, step1338]: loss 0.468630
[epoch1, step1339]: loss 0.534323
[epoch1, step1340]: loss 0.547053
[epoch1, step1341]: loss 0.546272
[epoch1, step1342]: loss 0.507535
[epoch1, step1343]: loss 0.546631
[epoch1, step1344]: loss 0.491786
[epoch1, step1345]: loss 0.574259
[epoch1, step1346]: loss 0.529158
[epoch1, step1347]: loss 0.458129
[epoch1, step1348]: loss 0.537630
[epoch1, step1349]: loss 0.537175
[epoch1, step1350]: loss 0.540737
[epoch1, step1351]: loss 0.521272
[epoch1, step1352]: loss 0.559035
[epoch1, step1353]: loss 0.505841
[epoch1, step1354]: loss 0.583148
[epoch1, step1355]: loss 0.520103
[epoch1, step1356]: loss 0.480152
[epoch1, step1357]: loss 0.540356
[epoch1, step1358]: loss 0.539306
[epoch1, step1359]: loss 0.551685
[epoch1, step1360]: loss 0.498294
[epoch1, step1361]: loss 0.544724
[epoch1, step1362]: loss 0.489669
[epoch1, step1363]: loss 0.563136
[epoch1, step1364]: loss 0.520200
[epoch1, step1365]: loss 0.467868
[epoch1, step1366]: loss 0.528881
[epoch1, step1367]: loss 0.548975
[epoch1, step1368]: loss 0.525455
[epoch1, step1369]: loss 0.507547
[epoch1, step1370]: loss 0.554853
[epoch1, step1371]: loss 0.489689
[epoch1, step1372]: loss 0.574291
[epoch1, step1373]: loss 0.520447
[epoch1, step1374]: loss 0.454801
[epoch1, step1375]: loss 0.517570
[epoch1, step1376]: loss 0.537538
[epoch1, step1377]: loss 0.561303
[epoch1, step1378]: loss 0.505713
[epoch1, step1379]: loss 0.556521
[epoch1, step1380]: loss 0.483496
[epoch1, step1381]: loss 0.571657
[epoch1, step1382]: loss 0.516122
[epoch1, step1383]: loss 0.467118
[epoch1, step1384]: loss 0.522826
[epoch1, step1385]: loss 0.543833
[epoch1, step1386]: loss 0.539144
[epoch1, step1387]: loss 0.492562
[epoch1, step1388]: loss 0.566906
[epoch1, step1389]: loss 0.502401
[epoch1, step1390]: loss 0.569699
[epoch1, step1391]: loss 0.521934
[epoch1, step1392]: loss 0.469401
[epoch1, step1393]: loss 0.518368
[epoch1, step1394]: loss 0.524060
[epoch1, step1395]: loss 0.540021
[epoch1, step1396]: loss 0.504609
[epoch1, step1397]: loss 0.552071
[epoch1, step1398]: loss 0.491076
[epoch1, step1399]: loss 0.552975
[epoch1, step1400]: loss 0.513878
[epoch1, step1401]: loss 0.461871
[epoch1, step1402]: loss 0.523987
[epoch1, step1403]: loss 0.551231
[epoch1, step1404]: loss 0.549461
[epoch1, step1405]: loss 0.496450
[epoch1, step1406]: loss 0.552968
[epoch1, step1407]: loss 0.475182
[epoch1, step1408]: loss 0.582757
[epoch1, step1409]: loss 0.526614
[epoch1, step1410]: loss 0.459729
[epoch1, step1411]: loss 0.544138
[epoch1, step1412]: loss 0.532366
[epoch1, step1413]: loss 0.541675
[epoch1, step1414]: loss 0.508926
[epoch1, step1415]: loss 0.552326
[epoch1, step1416]: loss 0.489187
[epoch1, step1417]: loss 0.574082
[epoch1, step1418]: loss 0.519554
[epoch1, step1419]: loss 0.453577
[epoch1, step1420]: loss 0.524850
[epoch1, step1421]: loss 0.526488
[epoch1, step1422]: loss 0.534291
[epoch1, step1423]: loss 0.507614
[epoch1, step1424]: loss 0.544970
[epoch1, step1425]: loss 0.499836
[epoch1, step1426]: loss 0.569883
[epoch1, step1427]: loss 0.504229
[epoch1, step1428]: loss 0.461223
[epoch1, step1429]: loss 0.519692
[epoch1, step1430]: loss 0.537164
[epoch1, step1431]: loss 0.538847
[epoch1, step1432]: loss 0.505120
[epoch1, step1433]: loss 0.544191
[epoch1, step1434]: loss 0.508695
[epoch1, step1435]: loss 0.560731
[epoch1, step1436]: loss 0.511604
[epoch1, step1437]: loss 0.458401
[epoch1, step1438]: loss 0.518794
[epoch1, step1439]: loss 0.537210
[epoch1, step1440]: loss 0.544367
[epoch1, step1441]: loss 0.490176
[epoch1, step1442]: loss 0.559897
[epoch1, step1443]: loss 0.505718
[epoch1, step1444]: loss 0.580805
[epoch1, step1445]: loss 0.510478
[epoch1, step1446]: loss 0.455723
[epoch1, step1447]: loss 0.514513
[epoch1, step1448]: loss 0.534941
[epoch1, step1449]: loss 0.547665
[epoch1, step1450]: loss 0.501760
[epoch1, step1451]: loss 0.539156
[epoch1, step1452]: loss 0.494931
[epoch1, step1453]: loss 0.550204
[epoch1, step1454]: loss 0.508222
[epoch1, step1455]: loss 0.447741
[epoch1, step1456]: loss 0.528654
[epoch1, step1457]: loss 0.519989
[epoch1, step1458]: loss 0.536994
[epoch1, step1459]: loss 0.507696
[epoch1, step1460]: loss 0.535763
[epoch1, step1461]: loss 0.479843
[epoch1, step1462]: loss 0.553157
[epoch1, step1463]: loss 0.518971
[epoch1, step1464]: loss 0.453700
[epoch1, step1465]: loss 0.532807
[epoch1, step1466]: loss 0.535365
[epoch1, step1467]: loss 0.545729
[epoch1, step1468]: loss 0.505419
[epoch1, step1469]: loss 0.545635
[epoch1, step1470]: loss 0.486328
[epoch1, step1471]: loss 0.576324
[epoch1, step1472]: loss 0.519246
[epoch1, step1473]: loss 0.457203
[epoch1, step1474]: loss 0.510427
[epoch1, step1475]: loss 0.536028
[epoch1, step1476]: loss 0.526518
[epoch1, step1477]: loss 0.508651
[epoch1, step1478]: loss 0.542368
[epoch1, step1479]: loss 0.489006
[epoch1, step1480]: loss 0.566111
[epoch1, step1481]: loss 0.533805
[epoch1, step1482]: loss 0.461377
[epoch1, step1483]: loss 0.521670
[epoch1, step1484]: loss 0.526229
[epoch1, step1485]: loss 0.537459
[epoch1, step1486]: loss 0.515420
[epoch1, step1487]: loss 0.544922
[epoch1, step1488]: loss 0.484764
[epoch1, step1489]: loss 0.568658
[epoch1, step1490]: loss 0.511025
[epoch1, step1491]: loss 0.462190
[epoch1, step1492]: loss 0.528713
[epoch1, step1493]: loss 0.530722
[epoch1, step1494]: loss 0.536440
[epoch1, step1495]: loss 0.510718
[epoch1, step1496]: loss 0.557352
[epoch1, step1497]: loss 0.483347
[epoch1, step1498]: loss 0.557067
[epoch1, step1499]: loss 0.525271
[epoch1, step1500]: loss 0.457241
[epoch1, step1501]: loss 0.520080
[epoch1, step1502]: loss 0.531784
[epoch1, step1503]: loss 0.541024
[epoch1, step1504]: loss 0.509521
[epoch1, step1505]: loss 0.537810
[epoch1, step1506]: loss 0.492999
[epoch1, step1507]: loss 0.557862
[epoch1, step1508]: loss 0.505542
[epoch1, step1509]: loss 0.464942
[epoch1, step1510]: loss 0.539791
[epoch1, step1511]: loss 0.517079
[epoch1, step1512]: loss 0.531095
[epoch1, step1513]: loss 0.520078
[epoch1, step1514]: loss 0.542470
[epoch1, step1515]: loss 0.484258
[epoch1, step1516]: loss 0.563334

[epoch1]: avg loss 0.587642

[epoch2, step1]: loss 0.548392
[epoch2, step2]: loss 0.531940
[epoch2, step3]: loss 0.540742
[epoch2, step4]: loss 0.505852
[epoch2, step5]: loss 0.564088
[epoch2, step6]: loss 0.513164
[epoch2, step7]: loss 0.472501
[epoch2, step8]: loss 0.542389
[epoch2, step9]: loss 0.486676
[epoch2, step10]: loss 0.543214
[epoch2, step11]: loss 0.528942
[epoch2, step12]: loss 0.535967
[epoch2, step13]: loss 0.484334
[epoch2, step14]: loss 0.562406
[epoch2, step15]: loss 0.514256
[epoch2, step16]: loss 0.474090
[epoch2, step17]: loss 0.534808
[epoch2, step18]: loss 0.465901
[epoch2, step19]: loss 0.552200
[epoch2, step20]: loss 0.511875
[epoch2, step21]: loss 0.537695
[epoch2, step22]: loss 0.496448
[epoch2, step23]: loss 0.583733
[epoch2, step24]: loss 0.508157
[epoch2, step25]: loss 0.478270
[epoch2, step26]: loss 0.554140
[epoch2, step27]: loss 0.486601
[epoch2, step28]: loss 0.549506
[epoch2, step29]: loss 0.522543
[epoch2, step30]: loss 0.522349
[epoch2, step31]: loss 0.492311
[epoch2, step32]: loss 0.557009
[epoch2, step33]: loss 0.500841
[epoch2, step34]: loss 0.465826
[epoch2, step35]: loss 0.535148
[epoch2, step36]: loss 0.484094
[epoch2, step37]: loss 0.552847
[epoch2, step38]: loss 0.528505
[epoch2, step39]: loss 0.534422
[epoch2, step40]: loss 0.479992
[epoch2, step41]: loss 0.575460
[epoch2, step42]: loss 0.503389
[epoch2, step43]: loss 0.479178
[epoch2, step44]: loss 0.536498
[epoch2, step45]: loss 0.483431
[epoch2, step46]: loss 0.552007
[epoch2, step47]: loss 0.533391
[epoch2, step48]: loss 0.539095
[epoch2, step49]: loss 0.503960
[epoch2, step50]: loss 0.563545
[epoch2, step51]: loss 0.511307
[epoch2, step52]: loss 0.480769
[epoch2, step53]: loss 0.528300
[epoch2, step54]: loss 0.477770
[epoch2, step55]: loss 0.543234
[epoch2, step56]: loss 0.504485
[epoch2, step57]: loss 0.525004
[epoch2, step58]: loss 0.482889
[epoch2, step59]: loss 0.582493
[epoch2, step60]: loss 0.496868
[epoch2, step61]: loss 0.482854
[epoch2, step62]: loss 0.548773
[epoch2, step63]: loss 0.492461
[epoch2, step64]: loss 0.564315
[epoch2, step65]: loss 0.519109
[epoch2, step66]: loss 0.532177
[epoch2, step67]: loss 0.488909
[epoch2, step68]: loss 0.565267
[epoch2, step69]: loss 0.508294
[epoch2, step70]: loss 0.478259
[epoch2, step71]: loss 0.546665
[epoch2, step72]: loss 0.477821
[epoch2, step73]: loss 0.554212
[epoch2, step74]: loss 0.519097
[epoch2, step75]: loss 0.527381
[epoch2, step76]: loss 0.483882
[epoch2, step77]: loss 0.551070
[epoch2, step78]: loss 0.502847
[epoch2, step79]: loss 0.482384
[epoch2, step80]: loss 0.523203
[epoch2, step81]: loss 0.473310
[epoch2, step82]: loss 0.561004
[epoch2, step83]: loss 0.536568
[epoch2, step84]: loss 0.527329
[epoch2, step85]: loss 0.475864
[epoch2, step86]: loss 0.555755
[epoch2, step87]: loss 0.489957
[epoch2, step88]: loss 0.504906
[epoch2, step89]: loss 0.545798
[epoch2, step90]: loss 0.481510
[epoch2, step91]: loss 0.568946
[epoch2, step92]: loss 0.518275
[epoch2, step93]: loss 0.527049
[epoch2, step94]: loss 0.491136
[epoch2, step95]: loss 0.552921
[epoch2, step96]: loss 0.510442
[epoch2, step97]: loss 0.465430
[epoch2, step98]: loss 0.537619
[epoch2, step99]: loss 0.479801
[epoch2, step100]: loss 0.568570
[epoch2, step101]: loss 0.508174
[epoch2, step102]: loss 0.531535
[epoch2, step103]: loss 0.488249
[epoch2, step104]: loss 0.561021
[epoch2, step105]: loss 0.498125
[epoch2, step106]: loss 0.476710
[epoch2, step107]: loss 0.538562
[epoch2, step108]: loss 0.473629
[epoch2, step109]: loss 0.555866
[epoch2, step110]: loss 0.508457
[epoch2, step111]: loss 0.531999
[epoch2, step112]: loss 0.489221
[epoch2, step113]: loss 0.544833
[epoch2, step114]: loss 0.508111
[epoch2, step115]: loss 0.474789
[epoch2, step116]: loss 0.522816
[epoch2, step117]: loss 0.474108
[epoch2, step118]: loss 0.535340
[epoch2, step119]: loss 0.510910
[epoch2, step120]: loss 0.522630
[epoch2, step121]: loss 0.487927
[epoch2, step122]: loss 0.559068
[epoch2, step123]: loss 0.496928
[epoch2, step124]: loss 0.473554
[epoch2, step125]: loss 0.526452
[epoch2, step126]: loss 0.479859
[epoch2, step127]: loss 0.553305
[epoch2, step128]: loss 0.520147
[epoch2, step129]: loss 0.526909
[epoch2, step130]: loss 0.477490
[epoch2, step131]: loss 0.569124
[epoch2, step132]: loss 0.499661
[epoch2, step133]: loss 0.472273
[epoch2, step134]: loss 0.546432
[epoch2, step135]: loss 0.467454
[epoch2, step136]: loss 0.526927
[epoch2, step137]: loss 0.522832
[epoch2, step138]: loss 0.527187
[epoch2, step139]: loss 0.482592
[epoch2, step140]: loss 0.548906
[epoch2, step141]: loss 0.496142
[epoch2, step142]: loss 0.471985
[epoch2, step143]: loss 0.541488
[epoch2, step144]: loss 0.482482
[epoch2, step145]: loss 0.548760
[epoch2, step146]: loss 0.516975
[epoch2, step147]: loss 0.503878
[epoch2, step148]: loss 0.480833
[epoch2, step149]: loss 0.567557
[epoch2, step150]: loss 0.508000
[epoch2, step151]: loss 0.465131
[epoch2, step152]: loss 0.533212
[epoch2, step153]: loss 0.468657
[epoch2, step154]: loss 0.558177
[epoch2, step155]: loss 0.515040
[epoch2, step156]: loss 0.533439
[epoch2, step157]: loss 0.476586
[epoch2, step158]: loss 0.549887
[epoch2, step159]: loss 0.497172
[epoch2, step160]: loss 0.464485
[epoch2, step161]: loss 0.521223
[epoch2, step162]: loss 0.469326
[epoch2, step163]: loss 0.549176
[epoch2, step164]: loss 0.507268
[epoch2, step165]: loss 0.523438
[epoch2, step166]: loss 0.472043
[epoch2, step167]: loss 0.563423
[epoch2, step168]: loss 0.485763
[epoch2, step169]: loss 0.476353
[epoch2, step170]: loss 0.525774
[epoch2, step171]: loss 0.468203
[epoch2, step172]: loss 0.545118
[epoch2, step173]: loss 0.508745
[epoch2, step174]: loss 0.528144
[epoch2, step175]: loss 0.463803
[epoch2, step176]: loss 0.551950
[epoch2, step177]: loss 0.492742
[epoch2, step178]: loss 0.459558
[epoch2, step179]: loss 0.544994
[epoch2, step180]: loss 0.459675
[epoch2, step181]: loss 0.541111
[epoch2, step182]: loss 0.506417
[epoch2, step183]: loss 0.511224
[epoch2, step184]: loss 0.463111
[epoch2, step185]: loss 0.549999
[epoch2, step186]: loss 0.492259
[epoch2, step187]: loss 0.470257
[epoch2, step188]: loss 0.534064
[epoch2, step189]: loss 0.464760
[epoch2, step190]: loss 0.556146
[epoch2, step191]: loss 0.515551
[epoch2, step192]: loss 0.511301
[epoch2, step193]: loss 0.506728
[epoch2, step194]: loss 0.567325
[epoch2, step195]: loss 0.490637
[epoch2, step196]: loss 0.463558
[epoch2, step197]: loss 0.532162
[epoch2, step198]: loss 0.480918
[epoch2, step199]: loss 0.542691
[epoch2, step200]: loss 0.499998
[epoch2, step201]: loss 0.511519
[epoch2, step202]: loss 0.479295
[epoch2, step203]: loss 0.552727
[epoch2, step204]: loss 0.487158
[epoch2, step205]: loss 0.479149
[epoch2, step206]: loss 0.534265
[epoch2, step207]: loss 0.466589
[epoch2, step208]: loss 0.533752
[epoch2, step209]: loss 0.503946
[epoch2, step210]: loss 0.504174
[epoch2, step211]: loss 0.471608
[epoch2, step212]: loss 0.546532
[epoch2, step213]: loss 0.500490
[epoch2, step214]: loss 0.481866
[epoch2, step215]: loss 0.524393
[epoch2, step216]: loss 0.464561
[epoch2, step217]: loss 0.557795
[epoch2, step218]: loss 0.502727
[epoch2, step219]: loss 0.523163
[epoch2, step220]: loss 0.481045
[epoch2, step221]: loss 0.546138
[epoch2, step222]: loss 0.487730
[epoch2, step223]: loss 0.455353
[epoch2, step224]: loss 0.532953
[epoch2, step225]: loss 0.465151
[epoch2, step226]: loss 0.548717
[epoch2, step227]: loss 0.525452
[epoch2, step228]: loss 0.508745
[epoch2, step229]: loss 0.488463
[epoch2, step230]: loss 0.543219
[epoch2, step231]: loss 0.484818
[epoch2, step232]: loss 0.471286
[epoch2, step233]: loss 0.540822
[epoch2, step234]: loss 0.473675
[epoch2, step235]: loss 0.542626
[epoch2, step236]: loss 0.506242
[epoch2, step237]: loss 0.517401
[epoch2, step238]: loss 0.474724
[epoch2, step239]: loss 0.561578
[epoch2, step240]: loss 0.507323
[epoch2, step241]: loss 0.460994
[epoch2, step242]: loss 0.529949
[epoch2, step243]: loss 0.461561
[epoch2, step244]: loss 0.546091
[epoch2, step245]: loss 0.515576
[epoch2, step246]: loss 0.518179
[epoch2, step247]: loss 0.473794
[epoch2, step248]: loss 0.555692
[epoch2, step249]: loss 0.501740
[epoch2, step250]: loss 0.463202
[epoch2, step251]: loss 0.516449
[epoch2, step252]: loss 0.458177
[epoch2, step253]: loss 0.550899
[epoch2, step254]: loss 0.520293
[epoch2, step255]: loss 0.512884
[epoch2, step256]: loss 0.482532
[epoch2, step257]: loss 0.552588
[epoch2, step258]: loss 0.481733
[epoch2, step259]: loss 0.459986
[epoch2, step260]: loss 0.536111
[epoch2, step261]: loss 0.449800
[epoch2, step262]: loss 0.532163
[epoch2, step263]: loss 0.520529
[epoch2, step264]: loss 0.520354
[epoch2, step265]: loss 0.473469
[epoch2, step266]: loss 0.550009
[epoch2, step267]: loss 0.506245
[epoch2, step268]: loss 0.463150
[epoch2, step269]: loss 0.523483
[epoch2, step270]: loss 0.469965
[epoch2, step271]: loss 0.537365
[epoch2, step272]: loss 0.507831
[epoch2, step273]: loss 0.520373
[epoch2, step274]: loss 0.462364
[epoch2, step275]: loss 0.559458
[epoch2, step276]: loss 0.500520
[epoch2, step277]: loss 0.456905
[epoch2, step278]: loss 0.521543
[epoch2, step279]: loss 0.460699
[epoch2, step280]: loss 0.536867
[epoch2, step281]: loss 0.510249
[epoch2, step282]: loss 0.505791
[epoch2, step283]: loss 0.479233
[epoch2, step284]: loss 0.556049
[epoch2, step285]: loss 0.477678
[epoch2, step286]: loss 0.488381
[epoch2, step287]: loss 0.521156
[epoch2, step288]: loss 0.471495
[epoch2, step289]: loss 0.530677
[epoch2, step290]: loss 0.506041
[epoch2, step291]: loss 0.509712
[epoch2, step292]: loss 0.484008
[epoch2, step293]: loss 0.551450
[epoch2, step294]: loss 0.500352
[epoch2, step295]: loss 0.468141
[epoch2, step296]: loss 0.510940
[epoch2, step297]: loss 0.469032
[epoch2, step298]: loss 0.536248
[epoch2, step299]: loss 0.520517
[epoch2, step300]: loss 0.507709
[epoch2, step301]: loss 0.478512
[epoch2, step302]: loss 0.539423
[epoch2, step303]: loss 0.483652
[epoch2, step304]: loss 0.461695
[epoch2, step305]: loss 0.529141
[epoch2, step306]: loss 0.462223
[epoch2, step307]: loss 0.547293
[epoch2, step308]: loss 0.495968
[epoch2, step309]: loss 0.505268
[epoch2, step310]: loss 0.471761
[epoch2, step311]: loss 0.538034
[epoch2, step312]: loss 0.494790
[epoch2, step313]: loss 0.461042
[epoch2, step314]: loss 0.521707
[epoch2, step315]: loss 0.453749
[epoch2, step316]: loss 0.543638
[epoch2, step317]: loss 0.501147
[epoch2, step318]: loss 0.511582
[epoch2, step319]: loss 0.480979
[epoch2, step320]: loss 0.562879
[epoch2, step321]: loss 0.496657
[epoch2, step322]: loss 0.474444
[epoch2, step323]: loss 0.533762
[epoch2, step324]: loss 0.451981
[epoch2, step325]: loss 0.535620
[epoch2, step326]: loss 0.508605
[epoch2, step327]: loss 0.523397
[epoch2, step328]: loss 0.471866
[epoch2, step329]: loss 0.551963
[epoch2, step330]: loss 0.501096
[epoch2, step331]: loss 0.464480
[epoch2, step332]: loss 0.531680
[epoch2, step333]: loss 0.467078
[epoch2, step334]: loss 0.534464
[epoch2, step335]: loss 0.502460
[epoch2, step336]: loss 0.497938
[epoch2, step337]: loss 0.462953
[epoch2, step338]: loss 0.554501
[epoch2, step339]: loss 0.494242
[epoch2, step340]: loss 0.461020
[epoch2, step341]: loss 0.529340
[epoch2, step342]: loss 0.461747
[epoch2, step343]: loss 0.532339
[epoch2, step344]: loss 0.508209
[epoch2, step345]: loss 0.522937
[epoch2, step346]: loss 0.477734
[epoch2, step347]: loss 0.550953
[epoch2, step348]: loss 0.485143
[epoch2, step349]: loss 0.453849
[epoch2, step350]: loss 0.530101
[epoch2, step351]: loss 0.466350
[epoch2, step352]: loss 0.537151
[epoch2, step353]: loss 0.505401
[epoch2, step354]: loss 0.528758
[epoch2, step355]: loss 0.481255
[epoch2, step356]: loss 0.533787
[epoch2, step357]: loss 0.487333
[epoch2, step358]: loss 0.483661
[epoch2, step359]: loss 0.507109
[epoch2, step360]: loss 0.466198
[epoch2, step361]: loss 0.545210
[epoch2, step362]: loss 0.494069
[epoch2, step363]: loss 0.516574
[epoch2, step364]: loss 0.471749
[epoch2, step365]: loss 0.547482
[epoch2, step366]: loss 0.482676
[epoch2, step367]: loss 0.465315
[epoch2, step368]: loss 0.529923
[epoch2, step369]: loss 0.464540
[epoch2, step370]: loss 0.526661
[epoch2, step371]: loss 0.488109
[epoch2, step372]: loss 0.516536
[epoch2, step373]: loss 0.471772
[epoch2, step374]: loss 0.554795
[epoch2, step375]: loss 0.477082
[epoch2, step376]: loss 0.450960
[epoch2, step377]: loss 0.516351
[epoch2, step378]: loss 0.459132
[epoch2, step379]: loss 0.525466
[epoch2, step380]: loss 0.492857
[epoch2, step381]: loss 0.515288
[epoch2, step382]: loss 0.478516
[epoch2, step383]: loss 0.562037
[epoch2, step384]: loss 0.499357
[epoch2, step385]: loss 0.452837
[epoch2, step386]: loss 0.516059
[epoch2, step387]: loss 0.453391
[epoch2, step388]: loss 0.520748
[epoch2, step389]: loss 0.501826
[epoch2, step390]: loss 0.492236
[epoch2, step391]: loss 0.469383
[epoch2, step392]: loss 0.531721
[epoch2, step393]: loss 0.495857
[epoch2, step394]: loss 0.465561
[epoch2, step395]: loss 0.523532
[epoch2, step396]: loss 0.455426
[epoch2, step397]: loss 0.544721
[epoch2, step398]: loss 0.498719
[epoch2, step399]: loss 0.510149
[epoch2, step400]: loss 0.467139
[epoch2, step401]: loss 0.545095
[epoch2, step402]: loss 0.490961
[epoch2, step403]: loss 0.455356
[epoch2, step404]: loss 0.513656
[epoch2, step405]: loss 0.451569
[epoch2, step406]: loss 0.526901
[epoch2, step407]: loss 0.504985
[epoch2, step408]: loss 0.507023
[epoch2, step409]: loss 0.443530
[epoch2, step410]: loss 0.531200
[epoch2, step411]: loss 0.487140
[epoch2, step412]: loss 0.460366
[epoch2, step413]: loss 0.518499
[epoch2, step414]: loss 0.470474
[epoch2, step415]: loss 0.530464
[epoch2, step416]: loss 0.510101
[epoch2, step417]: loss 0.504411
[epoch2, step418]: loss 0.464464
[epoch2, step419]: loss 0.552728
[epoch2, step420]: loss 0.480045
[epoch2, step421]: loss 0.459932
[epoch2, step422]: loss 0.517026
[epoch2, step423]: loss 0.455485
[epoch2, step424]: loss 0.528099
[epoch2, step425]: loss 0.496233
[epoch2, step426]: loss 0.501509
[epoch2, step427]: loss 0.471117
[epoch2, step428]: loss 0.542951
[epoch2, step429]: loss 0.471238
[epoch2, step430]: loss 0.456474
[epoch2, step431]: loss 0.510651
[epoch2, step432]: loss 0.453504
[epoch2, step433]: loss 0.516822
[epoch2, step434]: loss 0.500289
[epoch2, step435]: loss 0.499941
[epoch2, step436]: loss 0.477043
[epoch2, step437]: loss 0.537029
[epoch2, step438]: loss 0.472749
[epoch2, step439]: loss 0.457766
[epoch2, step440]: loss 0.515931
[epoch2, step441]: loss 0.449131
[epoch2, step442]: loss 0.530975
[epoch2, step443]: loss 0.489157
[epoch2, step444]: loss 0.513083
[epoch2, step445]: loss 0.460072
[epoch2, step446]: loss 0.532858
[epoch2, step447]: loss 0.472848
[epoch2, step448]: loss 0.448809
[epoch2, step449]: loss 0.518643
[epoch2, step450]: loss 0.467909
[epoch2, step451]: loss 0.534191
[epoch2, step452]: loss 0.516958
[epoch2, step453]: loss 0.502407
[epoch2, step454]: loss 0.469383
[epoch2, step455]: loss 0.535465
[epoch2, step456]: loss 0.496681
[epoch2, step457]: loss 0.448138
[epoch2, step458]: loss 0.518951
[epoch2, step459]: loss 0.443232
[epoch2, step460]: loss 0.532147
[epoch2, step461]: loss 0.485281
[epoch2, step462]: loss 0.516263
[epoch2, step463]: loss 0.463357
[epoch2, step464]: loss 0.541363
[epoch2, step465]: loss 0.459961
[epoch2, step466]: loss 0.451606
[epoch2, step467]: loss 0.519883
[epoch2, step468]: loss 0.458415
[epoch2, step469]: loss 0.527739
[epoch2, step470]: loss 0.492580
[epoch2, step471]: loss 0.510721
[epoch2, step472]: loss 0.465603
[epoch2, step473]: loss 0.544271
[epoch2, step474]: loss 0.486322
[epoch2, step475]: loss 0.452549
[epoch2, step476]: loss 0.505743
[epoch2, step477]: loss 0.455429
[epoch2, step478]: loss 0.536718
[epoch2, step479]: loss 0.496655
[epoch2, step480]: loss 0.518130
[epoch2, step481]: loss 0.467351
[epoch2, step482]: loss 0.548305
[epoch2, step483]: loss 0.474156
[epoch2, step484]: loss 0.440723
[epoch2, step485]: loss 0.510962
[epoch2, step486]: loss 0.447945
[epoch2, step487]: loss 0.537817
[epoch2, step488]: loss 0.489600
[epoch2, step489]: loss 0.517534
[epoch2, step490]: loss 0.462386
[epoch2, step491]: loss 0.531518
[epoch2, step492]: loss 0.484817
[epoch2, step493]: loss 0.452060
[epoch2, step494]: loss 0.523234
[epoch2, step495]: loss 0.431637
[epoch2, step496]: loss 0.530545
[epoch2, step497]: loss 0.491809
[epoch2, step498]: loss 0.504134
[epoch2, step499]: loss 0.462261
[epoch2, step500]: loss 0.544556
[epoch2, step501]: loss 0.490739
[epoch2, step502]: loss 0.452823
[epoch2, step503]: loss 0.509562
[epoch2, step504]: loss 0.466042
[epoch2, step505]: loss 0.544230
[epoch2, step506]: loss 0.483923
[epoch2, step507]: loss 0.496554
[epoch2, step508]: loss 0.456949
[epoch2, step509]: loss 0.540410
[epoch2, step510]: loss 0.478282
[epoch2, step511]: loss 0.456207
[epoch2, step512]: loss 0.505450
[epoch2, step513]: loss 0.453490
[epoch2, step514]: loss 0.523556
[epoch2, step515]: loss 0.494101
[epoch2, step516]: loss 0.495019
[epoch2, step517]: loss 0.466121
[epoch2, step518]: loss 0.534358
[epoch2, step519]: loss 0.478495
[epoch2, step520]: loss 0.451290
[epoch2, step521]: loss 0.518213
[epoch2, step522]: loss 0.457330
[epoch2, step523]: loss 0.526779
[epoch2, step524]: loss 0.506632
[epoch2, step525]: loss 0.495567
[epoch2, step526]: loss 0.451602
[epoch2, step527]: loss 0.542043
[epoch2, step528]: loss 0.474090
[epoch2, step529]: loss 0.460148
[epoch2, step530]: loss 0.505676
[epoch2, step531]: loss 0.451357
[epoch2, step532]: loss 0.534192
[epoch2, step533]: loss 0.476164
[epoch2, step534]: loss 0.502473
[epoch2, step535]: loss 0.457023
[epoch2, step536]: loss 0.531538
[epoch2, step537]: loss 0.476701
[epoch2, step538]: loss 0.459393
[epoch2, step539]: loss 0.514041
[epoch2, step540]: loss 0.466132
[epoch2, step541]: loss 0.534798
[epoch2, step542]: loss 0.493995
[epoch2, step543]: loss 0.503546
[epoch2, step544]: loss 0.452474
[epoch2, step545]: loss 0.549022
[epoch2, step546]: loss 0.470122
[epoch2, step547]: loss 0.461873
[epoch2, step548]: loss 0.512915
[epoch2, step549]: loss 0.448124
[epoch2, step550]: loss 0.524394
[epoch2, step551]: loss 0.492934
[epoch2, step552]: loss 0.508566
[epoch2, step553]: loss 0.456881
[epoch2, step554]: loss 0.539847
[epoch2, step555]: loss 0.485155
[epoch2, step556]: loss 0.446818
[epoch2, step557]: loss 0.519100
[epoch2, step558]: loss 0.447206
[epoch2, step559]: loss 0.534389
[epoch2, step560]: loss 0.490001
[epoch2, step561]: loss 0.503235
[epoch2, step562]: loss 0.454993
[epoch2, step563]: loss 0.640752
[epoch2, step564]: loss 0.480225
[epoch2, step565]: loss 0.374552
[epoch2, step566]: loss 0.393575
[epoch2, step567]: loss 0.389748
[epoch2, step568]: loss 0.444776
[epoch2, step569]: loss 0.533187
[epoch2, step570]: loss 0.447521
[epoch2, step571]: loss 0.312638
[epoch2, step572]: loss 0.445816
[epoch2, step573]: loss 0.463565
[epoch2, step574]: loss 0.572506
[epoch2, step575]: loss 0.498612
[epoch2, step576]: loss 0.511599
[epoch2, step577]: loss 0.426047
[epoch2, step578]: loss 0.513968
[epoch2, step579]: loss 0.397722
[epoch2, step580]: loss 0.582956
[epoch2, step581]: loss 0.506025
[epoch2, step582]: loss 0.490884
[epoch2, step583]: loss 0.501001
[epoch2, step584]: loss 0.465737
[epoch2, step585]: loss 0.554243
[epoch2, step586]: loss 0.491096
[epoch2, step587]: loss 0.340349
[epoch2, step588]: loss 0.492176
[epoch2, step589]: loss 0.652967
[epoch2, step590]: loss 0.365626
[epoch2, step591]: loss 0.480940
[epoch2, step592]: loss 0.525537
[epoch2, step593]: loss 0.645055
[epoch2, step594]: loss 0.374583
[epoch2, step595]: loss 0.375889
[epoch2, step596]: loss 0.538176
[epoch2, step597]: loss 0.555359
[epoch2, step598]: loss 0.403889
[epoch2, step599]: loss 0.375797
[epoch2, step600]: loss 0.361519
[epoch2, step601]: loss 0.486231
[epoch2, step602]: loss 0.581055
[epoch2, step603]: loss 0.420793
[epoch2, step604]: loss 0.410509
[epoch2, step605]: loss 0.361128
[epoch2, step606]: loss 0.465490
[epoch2, step607]: loss 0.510043
[epoch2, step608]: loss 0.313426
[epoch2, step609]: loss 0.477988
[epoch2, step610]: loss 0.418173
[epoch2, step611]: loss 0.530126
[epoch2, step612]: loss 0.484149
[epoch2, step613]: loss 0.542017
[epoch2, step614]: loss 0.467449
[epoch2, step615]: loss 0.478417
[epoch2, step616]: loss 0.381380
[epoch2, step617]: loss 0.442966
[epoch2, step618]: loss 0.522595
[epoch2, step619]: loss 0.388260
[epoch2, step620]: loss 0.360808
[epoch2, step621]: loss 0.349525
[epoch2, step622]: loss 0.514562
[epoch2, step623]: loss 0.491684
[epoch2, step624]: loss 0.490274
[epoch2, step625]: loss 0.357787
[epoch2, step626]: loss 0.491686
[epoch2, step627]: loss 0.574730
[epoch2, step628]: loss 0.521112
[epoch2, step629]: loss 0.282442
[epoch2, step630]: loss 0.408610
[epoch2, step631]: loss 0.395692
[epoch2, step632]: loss 0.495211
[epoch2, step633]: loss 0.399941
[epoch2, step634]: loss 0.459993
[epoch2, step635]: loss 0.441551
[epoch2, step636]: loss 0.390048
[epoch2, step637]: loss 0.518914
[epoch2, step638]: loss 0.477958
[epoch2, step639]: loss 0.367866
[epoch2, step640]: loss 0.491771
[epoch2, step641]: loss 0.373412
[epoch2, step642]: loss 0.370620
[epoch2, step643]: loss 0.501631
[epoch2, step644]: loss 0.437564
[epoch2, step645]: loss 0.335625
[epoch2, step646]: loss 0.451045
[epoch2, step647]: loss 0.346456
[epoch2, step648]: loss 0.575003
[epoch2, step649]: loss 0.480130
[epoch2, step650]: loss 0.524331
[epoch2, step651]: loss 0.429552
[epoch2, step652]: loss 0.546476
[epoch2, step653]: loss 0.523085
[epoch2, step654]: loss 0.509923
[epoch2, step655]: loss 0.380828
[epoch2, step656]: loss 0.538778
[epoch2, step657]: loss 0.525705
[epoch2, step658]: loss 0.404106
[epoch2, step659]: loss 0.342397
[epoch2, step660]: loss 0.456376
[epoch2, step661]: loss 0.486946
[epoch2, step662]: loss 0.350816
[epoch2, step663]: loss 0.449984
[epoch2, step664]: loss 0.429216
[epoch2, step665]: loss 0.551326
[epoch2, step666]: loss 0.362244
[epoch2, step667]: loss 0.481479
[epoch2, step668]: loss 0.566624
[epoch2, step669]: loss 0.368149
[epoch2, step670]: loss 0.463545
[epoch2, step671]: loss 0.484911
[epoch2, step672]: loss 0.585349
[epoch2, step673]: loss 0.540329
[epoch2, step674]: loss 0.445622
[epoch2, step675]: loss 0.521198
[epoch2, step676]: loss 0.499113
[epoch2, step677]: loss 0.422581
[epoch2, step678]: loss 0.364754
[epoch2, step679]: loss 0.450181
[epoch2, step680]: loss 0.350428
[epoch2, step681]: loss 0.370787
[epoch2, step682]: loss 0.377328
[epoch2, step683]: loss 0.460896
[epoch2, step684]: loss 0.379460
[epoch2, step685]: loss 0.382026
[epoch2, step686]: loss 0.362375
[epoch2, step687]: loss 0.400369
[epoch2, step688]: loss 0.500068
[epoch2, step689]: loss 0.381599
[epoch2, step690]: loss 0.516369
[epoch2, step691]: loss 0.539605
[epoch2, step692]: loss 0.522567
[epoch2, step693]: loss 0.469570
[epoch2, step694]: loss 0.352998
[epoch2, step695]: loss 0.412617
[epoch2, step696]: loss 0.378475
[epoch2, step697]: loss 0.469325
[epoch2, step698]: loss 0.418037
[epoch2, step699]: loss 0.427375
[epoch2, step700]: loss 0.580095
[epoch2, step701]: loss 0.490474
[epoch2, step702]: loss 0.418851
[epoch2, step703]: loss 0.564568
[epoch2, step704]: loss 0.517336
[epoch2, step705]: loss 0.383552
[epoch2, step706]: loss 0.398765
[epoch2, step707]: loss 0.413481
[epoch2, step708]: loss 0.456978
[epoch2, step709]: loss 0.389106
[epoch2, step710]: loss 0.473365
[epoch2, step711]: loss 0.521583
[epoch2, step712]: loss 0.344403
[epoch2, step713]: loss 0.406402
[epoch2, step714]: loss 0.494600
[epoch2, step715]: loss 0.401362
[epoch2, step716]: loss 0.468962
[epoch2, step717]: loss 0.391728
[epoch2, step718]: loss 0.437385
[epoch2, step719]: loss 0.433847
[epoch2, step720]: loss 0.388305
[epoch2, step721]: loss 0.431389
[epoch2, step722]: loss 0.446987
[epoch2, step723]: loss 0.434953
[epoch2, step724]: loss 0.479083
[epoch2, step725]: loss 0.468587
[epoch2, step726]: loss 0.325812
[epoch2, step727]: loss 0.463200
[epoch2, step728]: loss 0.472057
[epoch2, step729]: loss 0.380143
[epoch2, step730]: loss 0.473893
[epoch2, step731]: loss 0.514336
[epoch2, step732]: loss 0.427847
[epoch2, step733]: loss 0.345836
[epoch2, step734]: loss 0.397719
[epoch2, step735]: loss 0.388209
[epoch2, step736]: loss 0.418860
[epoch2, step737]: loss 0.363877
[epoch2, step738]: loss 0.401498
[epoch2, step739]: loss 0.565538
[epoch2, step740]: loss 0.611523
[epoch2, step741]: loss 0.458524
[epoch2, step742]: loss 0.533992
[epoch2, step743]: loss 0.451426
[epoch2, step744]: loss 0.435743
[epoch2, step745]: loss 0.442122
[epoch2, step746]: loss 0.481372
[epoch2, step747]: loss 0.426374
[epoch2, step748]: loss 0.381770
[epoch2, step749]: loss 0.569771
[epoch2, step750]: loss 0.475094
[epoch2, step751]: loss 0.421308
[epoch2, step752]: loss 0.367741
[epoch2, step753]: loss 0.379586
[epoch2, step754]: loss 0.527964
[epoch2, step755]: loss 0.469807
[epoch2, step756]: loss 0.345592
[epoch2, step757]: loss 0.443788
[epoch2, step758]: loss 0.488777
[epoch2, step759]: loss 0.385627
[epoch2, step760]: loss 0.469874
[epoch2, step761]: loss 0.420018
[epoch2, step762]: loss 0.403210
[epoch2, step763]: loss 0.400457
[epoch2, step764]: loss 0.464091
[epoch2, step765]: loss 0.396368
[epoch2, step766]: loss 0.367229
[epoch2, step767]: loss 0.478851
[epoch2, step768]: loss 0.446632
[epoch2, step769]: loss 0.439453
[epoch2, step770]: loss 0.556589
[epoch2, step771]: loss 0.367058
[epoch2, step772]: loss 0.359503
[epoch2, step773]: loss 0.421982
[epoch2, step774]: loss 0.443950
[epoch2, step775]: loss 0.551739
[epoch2, step776]: loss 0.469461
[epoch2, step777]: loss 0.409857
[epoch2, step778]: loss 0.497440
[epoch2, step779]: loss 0.424939
[epoch2, step780]: loss 0.489239
[epoch2, step781]: loss 0.555733
[epoch2, step782]: loss 0.527843
[epoch2, step783]: loss 0.457773
[epoch2, step784]: loss 0.523137
[epoch2, step785]: loss 0.506583
[epoch2, step786]: loss 0.436631
[epoch2, step787]: loss 0.549906
[epoch2, step788]: loss 0.452077
[epoch2, step789]: loss 0.526760
[epoch2, step790]: loss 0.364121
[epoch2, step791]: loss 0.469728
[epoch2, step792]: loss 0.478240
[epoch2, step793]: loss 0.481879
[epoch2, step794]: loss 0.459890
[epoch2, step795]: loss 0.433684
[epoch2, step796]: loss 0.413595
[epoch2, step797]: loss 0.376176
[epoch2, step798]: loss 0.377005
[epoch2, step799]: loss 0.319821
[epoch2, step800]: loss 0.580330
[epoch2, step801]: loss 0.539604
[epoch2, step802]: loss 0.435832
[epoch2, step803]: loss 0.394990
[epoch2, step804]: loss 0.467788
[epoch2, step805]: loss 0.412749
[epoch2, step806]: loss 0.453253
[epoch2, step807]: loss 0.499479
[epoch2, step808]: loss 0.552019
[epoch2, step809]: loss 0.405138
[epoch2, step810]: loss 0.334747
[epoch2, step811]: loss 0.434431
[epoch2, step812]: loss 0.481851
[epoch2, step813]: loss 0.402118
[epoch2, step814]: loss 0.453820
[epoch2, step815]: loss 0.427921
[epoch2, step816]: loss 0.444544
[epoch2, step817]: loss 0.378962
[epoch2, step818]: loss 0.417251
[epoch2, step819]: loss 0.652687
[epoch2, step820]: loss 0.393169
[epoch2, step821]: loss 0.383619
[epoch2, step822]: loss 0.446658
[epoch2, step823]: loss 0.378399
[epoch2, step824]: loss 0.435476
[epoch2, step825]: loss 0.464141
[epoch2, step826]: loss 0.312803
[epoch2, step827]: loss 0.388219
[epoch2, step828]: loss 0.426512
[epoch2, step829]: loss 0.397418
[epoch2, step830]: loss 0.300476
[epoch2, step831]: loss 0.373433
[epoch2, step832]: loss 0.556117
[epoch2, step833]: loss 0.445879
[epoch2, step834]: loss 0.440515
[epoch2, step835]: loss 0.464701
[epoch2, step836]: loss 0.381971
[epoch2, step837]: loss 0.356039
[epoch2, step838]: loss 0.495879
[epoch2, step839]: loss 0.430654
[epoch2, step840]: loss 0.401345
[epoch2, step841]: loss 0.429600
[epoch2, step842]: loss 0.422100
[epoch2, step843]: loss 0.489711
[epoch2, step844]: loss 0.493192
[epoch2, step845]: loss 0.471511
[epoch2, step846]: loss 0.582376
[epoch2, step847]: loss 0.434739
[epoch2, step848]: loss 0.231939
[epoch2, step849]: loss 0.396133
[epoch2, step850]: loss 0.497511
[epoch2, step851]: loss 0.419679
[epoch2, step852]: loss 0.433739
[epoch2, step853]: loss 0.466238
[epoch2, step854]: loss 0.497080
[epoch2, step855]: loss 0.385595
[epoch2, step856]: loss 0.351253
[epoch2, step857]: loss 0.460131
[epoch2, step858]: loss 0.480157
[epoch2, step859]: loss 0.391501
[epoch2, step860]: loss 0.502756
[epoch2, step861]: loss 0.451234
[epoch2, step862]: loss 0.351719
[epoch2, step863]: loss 0.495597
[epoch2, step864]: loss 0.503815
[epoch2, step865]: loss 0.466522
[epoch2, step866]: loss 0.489414
[epoch2, step867]: loss 0.403714
[epoch2, step868]: loss 0.451271
[epoch2, step869]: loss 0.382887
[epoch2, step870]: loss 0.345587
[epoch2, step871]: loss 0.555176
[epoch2, step872]: loss 0.475544
[epoch2, step873]: loss 0.360204
[epoch2, step874]: loss 0.428621
[epoch2, step875]: loss 0.563153
[epoch2, step876]: loss 0.505929
[epoch2, step877]: loss 0.274177
[epoch2, step878]: loss 0.387614
[epoch2, step879]: loss 0.409178
[epoch2, step880]: loss 0.395936
[epoch2, step881]: loss 0.509922
[epoch2, step882]: loss 0.389436
[epoch2, step883]: loss 0.407596
[epoch2, step884]: loss 0.537189
[epoch2, step885]: loss 0.543296
[epoch2, step886]: loss 0.513657
[epoch2, step887]: loss 0.551713
[epoch2, step888]: loss 0.411860
[epoch2, step889]: loss 0.480348
[epoch2, step890]: loss 0.486167
[epoch2, step891]: loss 0.406748
[epoch2, step892]: loss 0.491863
[epoch2, step893]: loss 0.467137
[epoch2, step894]: loss 0.474082
[epoch2, step895]: loss 0.363911
[epoch2, step896]: loss 0.603316
[epoch2, step897]: loss 0.594921
[epoch2, step898]: loss 0.377889
[epoch2, step899]: loss 0.260915
[epoch2, step900]: loss 0.431496
[epoch2, step901]: loss 0.512385
[epoch2, step902]: loss 0.388819
[epoch2, step903]: loss 0.527963
[epoch2, step904]: loss 0.372489
[epoch2, step905]: loss 0.353430
[epoch2, step906]: loss 0.344676
[epoch2, step907]: loss 0.482795
[epoch2, step908]: loss 0.533800
[epoch2, step909]: loss 0.420261
[epoch2, step910]: loss 0.352765
[epoch2, step911]: loss 0.331862
[epoch2, step912]: loss 0.489348
[epoch2, step913]: loss 0.500014
[epoch2, step914]: loss 0.422912
[epoch2, step915]: loss 0.389025
[epoch2, step916]: loss 0.456238
[epoch2, step917]: loss 0.438231
[epoch2, step918]: loss 0.491410
[epoch2, step919]: loss 0.359572
[epoch2, step920]: loss 0.504222
[epoch2, step921]: loss 0.397834
[epoch2, step922]: loss 0.412904
[epoch2, step923]: loss 0.528655
[epoch2, step924]: loss 0.406983
[epoch2, step925]: loss 0.398204
[epoch2, step926]: loss 0.403697
[epoch2, step927]: loss 0.516527
[epoch2, step928]: loss 0.390633
[epoch2, step929]: loss 0.411618
[epoch2, step930]: loss 0.431356
[epoch2, step931]: loss 0.477944
[epoch2, step932]: loss 0.394789
[epoch2, step933]: loss 0.396915
[epoch2, step934]: loss 0.537342
[epoch2, step935]: loss 0.453833
[epoch2, step936]: loss 0.392099
[epoch2, step937]: loss 0.341213
[epoch2, step938]: loss 0.555456
[epoch2, step939]: loss 0.410983
[epoch2, step940]: loss 0.495535
[epoch2, step941]: loss 0.449237
[epoch2, step942]: loss 0.444576
[epoch2, step943]: loss 0.522895
[epoch2, step944]: loss 0.443821
[epoch2, step945]: loss 0.509666
[epoch2, step946]: loss 0.432854
[epoch2, step947]: loss 0.380991
[epoch2, step948]: loss 0.633408
[epoch2, step949]: loss 0.446655
[epoch2, step950]: loss 0.417814
[epoch2, step951]: loss 0.454616
[epoch2, step952]: loss 0.485199
[epoch2, step953]: loss 0.428192
[epoch2, step954]: loss 0.477627
[epoch2, step955]: loss 0.323426
[epoch2, step956]: loss 0.484740
[epoch2, step957]: loss 0.441975
[epoch2, step958]: loss 0.525665
[epoch2, step959]: loss 0.464917
[epoch2, step960]: loss 0.426613
[epoch2, step961]: loss 0.469605
[epoch2, step962]: loss 0.475271
[epoch2, step963]: loss 0.495235
[epoch2, step964]: loss 0.445181
[epoch2, step965]: loss 0.504189
[epoch2, step966]: loss 0.440604
[epoch2, step967]: loss 0.512175
[epoch2, step968]: loss 0.468497
[epoch2, step969]: loss 0.408262
[epoch2, step970]: loss 0.470179
[epoch2, step971]: loss 0.475307
[epoch2, step972]: loss 0.477491
[epoch2, step973]: loss 0.461384
[epoch2, step974]: loss 0.479749
[epoch2, step975]: loss 0.435577
[epoch2, step976]: loss 0.514387
[epoch2, step977]: loss 0.452308
[epoch2, step978]: loss 0.409373
[epoch2, step979]: loss 0.478897
[epoch2, step980]: loss 0.477548
[epoch2, step981]: loss 0.485846
[epoch2, step982]: loss 0.445851
[epoch2, step983]: loss 0.484893
[epoch2, step984]: loss 0.441462
[epoch2, step985]: loss 0.513949
[epoch2, step986]: loss 0.447013
[epoch2, step987]: loss 0.398972
[epoch2, step988]: loss 0.457655
[epoch2, step989]: loss 0.465397
[epoch2, step990]: loss 0.485551
[epoch2, step991]: loss 0.435675
[epoch2, step992]: loss 0.487260
[epoch2, step993]: loss 0.440573
[epoch2, step994]: loss 0.520234
[epoch2, step995]: loss 0.457215
[epoch2, step996]: loss 0.410436
[epoch2, step997]: loss 0.463408
[epoch2, step998]: loss 0.463048
[epoch2, step999]: loss 0.479543
[epoch2, step1000]: loss 0.445614
[epoch2, step1001]: loss 0.483494
[epoch2, step1002]: loss 0.428980
[epoch2, step1003]: loss 0.512850
[epoch2, step1004]: loss 0.450801
[epoch2, step1005]: loss 0.416218
[epoch2, step1006]: loss 0.465253
[epoch2, step1007]: loss 0.474786
[epoch2, step1008]: loss 0.486787
[epoch2, step1009]: loss 0.445030
[epoch2, step1010]: loss 0.473817
[epoch2, step1011]: loss 0.433112
[epoch2, step1012]: loss 0.500038
[epoch2, step1013]: loss 0.453099
[epoch2, step1014]: loss 0.401067
[epoch2, step1015]: loss 0.459062
[epoch2, step1016]: loss 0.473878
[epoch2, step1017]: loss 0.487834
[epoch2, step1018]: loss 0.443693
[epoch2, step1019]: loss 0.482012
[epoch2, step1020]: loss 0.438995
[epoch2, step1021]: loss 0.510316
[epoch2, step1022]: loss 0.455880
[epoch2, step1023]: loss 0.408313
[epoch2, step1024]: loss 0.448292
[epoch2, step1025]: loss 0.479065
[epoch2, step1026]: loss 0.492495
[epoch2, step1027]: loss 0.440593
[epoch2, step1028]: loss 0.482843
[epoch2, step1029]: loss 0.433596
[epoch2, step1030]: loss 0.513658
[epoch2, step1031]: loss 0.478318
[epoch2, step1032]: loss 0.405119
[epoch2, step1033]: loss 0.475143
[epoch2, step1034]: loss 0.474144
[epoch2, step1035]: loss 0.493177
[epoch2, step1036]: loss 0.446697
[epoch2, step1037]: loss 0.486739
[epoch2, step1038]: loss 0.435112
[epoch2, step1039]: loss 0.504428
[epoch2, step1040]: loss 0.464353
[epoch2, step1041]: loss 0.411804
[epoch2, step1042]: loss 0.469762
[epoch2, step1043]: loss 0.471640
[epoch2, step1044]: loss 0.478804
[epoch2, step1045]: loss 0.439696
[epoch2, step1046]: loss 0.480458
[epoch2, step1047]: loss 0.428785
[epoch2, step1048]: loss 0.515411
[epoch2, step1049]: loss 0.454661
[epoch2, step1050]: loss 0.405498
[epoch2, step1051]: loss 0.461252
[epoch2, step1052]: loss 0.465106
[epoch2, step1053]: loss 0.481555
[epoch2, step1054]: loss 0.446214
[epoch2, step1055]: loss 0.490188
[epoch2, step1056]: loss 0.441732
[epoch2, step1057]: loss 0.495598
[epoch2, step1058]: loss 0.440784
[epoch2, step1059]: loss 0.405086
[epoch2, step1060]: loss 0.454216
[epoch2, step1061]: loss 0.481674
[epoch2, step1062]: loss 0.474116
[epoch2, step1063]: loss 0.444258
[epoch2, step1064]: loss 0.482569
[epoch2, step1065]: loss 0.438549
[epoch2, step1066]: loss 0.512110
[epoch2, step1067]: loss 0.453835
[epoch2, step1068]: loss 0.430171
[epoch2, step1069]: loss 0.457179
[epoch2, step1070]: loss 0.468628
[epoch2, step1071]: loss 0.470538
[epoch2, step1072]: loss 0.430769
[epoch2, step1073]: loss 0.483640
[epoch2, step1074]: loss 0.437968
[epoch2, step1075]: loss 0.500071
[epoch2, step1076]: loss 0.451069
[epoch2, step1077]: loss 0.404958
[epoch2, step1078]: loss 0.465438
[epoch2, step1079]: loss 0.453885
[epoch2, step1080]: loss 0.474558
[epoch2, step1081]: loss 0.450130
[epoch2, step1082]: loss 0.483406
[epoch2, step1083]: loss 0.425549
[epoch2, step1084]: loss 0.500935
[epoch2, step1085]: loss 0.461819
[epoch2, step1086]: loss 0.413751
[epoch2, step1087]: loss 0.462090
[epoch2, step1088]: loss 0.472147
[epoch2, step1089]: loss 0.473191
[epoch2, step1090]: loss 0.433730
[epoch2, step1091]: loss 0.476630
[epoch2, step1092]: loss 0.434439
[epoch2, step1093]: loss 0.502880
[epoch2, step1094]: loss 0.467730
[epoch2, step1095]: loss 0.408331
[epoch2, step1096]: loss 0.469280
[epoch2, step1097]: loss 0.465181
[epoch2, step1098]: loss 0.481351
[epoch2, step1099]: loss 0.448115
[epoch2, step1100]: loss 0.471718
[epoch2, step1101]: loss 0.435266
[epoch2, step1102]: loss 0.506930
[epoch2, step1103]: loss 0.460641
[epoch2, step1104]: loss 0.405515
[epoch2, step1105]: loss 0.454841
[epoch2, step1106]: loss 0.481040
[epoch2, step1107]: loss 0.476761
[epoch2, step1108]: loss 0.448099
[epoch2, step1109]: loss 0.472474
[epoch2, step1110]: loss 0.421566
[epoch2, step1111]: loss 0.500714
[epoch2, step1112]: loss 0.446107
[epoch2, step1113]: loss 0.407037
[epoch2, step1114]: loss 0.456718
[epoch2, step1115]: loss 0.462326
[epoch2, step1116]: loss 0.475732
[epoch2, step1117]: loss 0.438779
[epoch2, step1118]: loss 0.481147
[epoch2, step1119]: loss 0.440517
[epoch2, step1120]: loss 0.506576
[epoch2, step1121]: loss 0.453346
[epoch2, step1122]: loss 0.407704
[epoch2, step1123]: loss 0.468318
[epoch2, step1124]: loss 0.457419
[epoch2, step1125]: loss 0.472235
[epoch2, step1126]: loss 0.428173
[epoch2, step1127]: loss 0.476825
[epoch2, step1128]: loss 0.431637
[epoch2, step1129]: loss 0.504834
[epoch2, step1130]: loss 0.437277
[epoch2, step1131]: loss 0.398498
[epoch2, step1132]: loss 0.452760
[epoch2, step1133]: loss 0.473494
[epoch2, step1134]: loss 0.479695
[epoch2, step1135]: loss 0.421874
[epoch2, step1136]: loss 0.467464
[epoch2, step1137]: loss 0.425370
[epoch2, step1138]: loss 0.497407
[epoch2, step1139]: loss 0.454096
[epoch2, step1140]: loss 0.405505
[epoch2, step1141]: loss 0.454456
[epoch2, step1142]: loss 0.471704
[epoch2, step1143]: loss 0.483574
[epoch2, step1144]: loss 0.441228
[epoch2, step1145]: loss 0.485696
[epoch2, step1146]: loss 0.429213
[epoch2, step1147]: loss 0.486765
[epoch2, step1148]: loss 0.451003
[epoch2, step1149]: loss 0.403637
[epoch2, step1150]: loss 0.463820
[epoch2, step1151]: loss 0.461882
[epoch2, step1152]: loss 0.465611
[epoch2, step1153]: loss 0.445774
[epoch2, step1154]: loss 0.471502
[epoch2, step1155]: loss 0.425500
[epoch2, step1156]: loss 0.511238
[epoch2, step1157]: loss 0.456076
[epoch2, step1158]: loss 0.397546
[epoch2, step1159]: loss 0.452200
[epoch2, step1160]: loss 0.454208
[epoch2, step1161]: loss 0.466463
[epoch2, step1162]: loss 0.440432
[epoch2, step1163]: loss 0.486732
[epoch2, step1164]: loss 0.425226
[epoch2, step1165]: loss 0.482327
[epoch2, step1166]: loss 0.446166
[epoch2, step1167]: loss 0.406754
[epoch2, step1168]: loss 0.453660
[epoch2, step1169]: loss 0.466552
[epoch2, step1170]: loss 0.474526
[epoch2, step1171]: loss 0.440641
[epoch2, step1172]: loss 0.477678
[epoch2, step1173]: loss 0.427809
[epoch2, step1174]: loss 0.492209
[epoch2, step1175]: loss 0.453006
[epoch2, step1176]: loss 0.404249
[epoch2, step1177]: loss 0.447400
[epoch2, step1178]: loss 0.459119
[epoch2, step1179]: loss 0.475599
[epoch2, step1180]: loss 0.434886
[epoch2, step1181]: loss 0.467047
[epoch2, step1182]: loss 0.433417
[epoch2, step1183]: loss 0.488410
[epoch2, step1184]: loss 0.458365
[epoch2, step1185]: loss 0.404888
[epoch2, step1186]: loss 0.460007
[epoch2, step1187]: loss 0.477067
[epoch2, step1188]: loss 0.481075
[epoch2, step1189]: loss 0.438211
[epoch2, step1190]: loss 0.481364
[epoch2, step1191]: loss 0.423707
[epoch2, step1192]: loss 0.492913
[epoch2, step1193]: loss 0.447593
[epoch2, step1194]: loss 0.403507
[epoch2, step1195]: loss 0.474399
[epoch2, step1196]: loss 0.473321
[epoch2, step1197]: loss 0.470524
[epoch2, step1198]: loss 0.433832
[epoch2, step1199]: loss 0.479553
[epoch2, step1200]: loss 0.427141
[epoch2, step1201]: loss 0.489593
[epoch2, step1202]: loss 0.434553
[epoch2, step1203]: loss 0.406721
[epoch2, step1204]: loss 0.459228
[epoch2, step1205]: loss 0.465774
[epoch2, step1206]: loss 0.480821
[epoch2, step1207]: loss 0.426227
[epoch2, step1208]: loss 0.470091
[epoch2, step1209]: loss 0.435755
[epoch2, step1210]: loss 0.487840
[epoch2, step1211]: loss 0.456564
[epoch2, step1212]: loss 0.406168
[epoch2, step1213]: loss 0.463501
[epoch2, step1214]: loss 0.458806
[epoch2, step1215]: loss 0.461641
[epoch2, step1216]: loss 0.436222
[epoch2, step1217]: loss 0.464833
[epoch2, step1218]: loss 0.425781
[epoch2, step1219]: loss 0.486408
[epoch2, step1220]: loss 0.440558
[epoch2, step1221]: loss 0.408092
[epoch2, step1222]: loss 0.452220
[epoch2, step1223]: loss 0.461296
[epoch2, step1224]: loss 0.462418
[epoch2, step1225]: loss 0.434203
[epoch2, step1226]: loss 0.479844
[epoch2, step1227]: loss 0.420482
[epoch2, step1228]: loss 0.499581
[epoch2, step1229]: loss 0.454929
[epoch2, step1230]: loss 0.403755
[epoch2, step1231]: loss 0.458835
[epoch2, step1232]: loss 0.446997
[epoch2, step1233]: loss 0.473326
[epoch2, step1234]: loss 0.436866
[epoch2, step1235]: loss 0.465887
[epoch2, step1236]: loss 0.430020
[epoch2, step1237]: loss 0.501941
[epoch2, step1238]: loss 0.456637
[epoch2, step1239]: loss 0.392678
[epoch2, step1240]: loss 0.445888
[epoch2, step1241]: loss 0.471299
[epoch2, step1242]: loss 0.472670
[epoch2, step1243]: loss 0.430459
[epoch2, step1244]: loss 0.468610
[epoch2, step1245]: loss 0.416022
[epoch2, step1246]: loss 0.490505
[epoch2, step1247]: loss 0.460103
[epoch2, step1248]: loss 0.401575
[epoch2, step1249]: loss 0.444096
[epoch2, step1250]: loss 0.461641
[epoch2, step1251]: loss 0.467469
[epoch2, step1252]: loss 0.427022
[epoch2, step1253]: loss 0.467162
[epoch2, step1254]: loss 0.421689
[epoch2, step1255]: loss 0.492584
[epoch2, step1256]: loss 0.438284
[epoch2, step1257]: loss 0.395222
[epoch2, step1258]: loss 0.451846
[epoch2, step1259]: loss 0.462767
[epoch2, step1260]: loss 0.468422
[epoch2, step1261]: loss 0.436745
[epoch2, step1262]: loss 0.487652
[epoch2, step1263]: loss 0.411495
[epoch2, step1264]: loss 0.496815
[epoch2, step1265]: loss 0.466485
[epoch2, step1266]: loss 0.401708
[epoch2, step1267]: loss 0.451310
[epoch2, step1268]: loss 0.456559
[epoch2, step1269]: loss 0.466386
[epoch2, step1270]: loss 0.442115
[epoch2, step1271]: loss 0.464328
[epoch2, step1272]: loss 0.419650
[epoch2, step1273]: loss 0.498152
[epoch2, step1274]: loss 0.451957
[epoch2, step1275]: loss 0.397599
[epoch2, step1276]: loss 0.452213
[epoch2, step1277]: loss 0.460097
[epoch2, step1278]: loss 0.458772
[epoch2, step1279]: loss 0.428968
[epoch2, step1280]: loss 0.467422
[epoch2, step1281]: loss 0.423025
[epoch2, step1282]: loss 0.491798
[epoch2, step1283]: loss 0.453916
[epoch2, step1284]: loss 0.396961
[epoch2, step1285]: loss 0.447968
[epoch2, step1286]: loss 0.466914
[epoch2, step1287]: loss 0.455647
[epoch2, step1288]: loss 0.421823
[epoch2, step1289]: loss 0.455868
[epoch2, step1290]: loss 0.425524
[epoch2, step1291]: loss 0.495171
[epoch2, step1292]: loss 0.433265
[epoch2, step1293]: loss 0.402498
[epoch2, step1294]: loss 0.447469
[epoch2, step1295]: loss 0.449408
[epoch2, step1296]: loss 0.463163
[epoch2, step1297]: loss 0.426666
[epoch2, step1298]: loss 0.460183
[epoch2, step1299]: loss 0.421618
[epoch2, step1300]: loss 0.483256
[epoch2, step1301]: loss 0.461091
[epoch2, step1302]: loss 0.395030
[epoch2, step1303]: loss 0.453347
[epoch2, step1304]: loss 0.466069
[epoch2, step1305]: loss 0.458336
[epoch2, step1306]: loss 0.432797
[epoch2, step1307]: loss 0.477340
[epoch2, step1308]: loss 0.423066
[epoch2, step1309]: loss 0.500797
[epoch2, step1310]: loss 0.445797
[epoch2, step1311]: loss 0.406492
[epoch2, step1312]: loss 0.445929
[epoch2, step1313]: loss 0.455311
[epoch2, step1314]: loss 0.469880
[epoch2, step1315]: loss 0.431725
[epoch2, step1316]: loss 0.447404
[epoch2, step1317]: loss 0.427688
[epoch2, step1318]: loss 0.500084
[epoch2, step1319]: loss 0.449844
[epoch2, step1320]: loss 0.395274
[epoch2, step1321]: loss 0.438786
[epoch2, step1322]: loss 0.463003
[epoch2, step1323]: loss 0.459379
[epoch2, step1324]: loss 0.434747
[epoch2, step1325]: loss 0.468729
[epoch2, step1326]: loss 0.428213
[epoch2, step1327]: loss 0.490167
[epoch2, step1328]: loss 0.443925
[epoch2, step1329]: loss 0.397012
[epoch2, step1330]: loss 0.445951
[epoch2, step1331]: loss 0.462092
[epoch2, step1332]: loss 0.469118
[epoch2, step1333]: loss 0.447250
[epoch2, step1334]: loss 0.461256
[epoch2, step1335]: loss 0.417852
[epoch2, step1336]: loss 0.487442
[epoch2, step1337]: loss 0.454571
[epoch2, step1338]: loss 0.396476
[epoch2, step1339]: loss 0.452460
[epoch2, step1340]: loss 0.463580
[epoch2, step1341]: loss 0.464587
[epoch2, step1342]: loss 0.430149
[epoch2, step1343]: loss 0.462934
[epoch2, step1344]: loss 0.416016
[epoch2, step1345]: loss 0.487292
[epoch2, step1346]: loss 0.449204
[epoch2, step1347]: loss 0.387793
[epoch2, step1348]: loss 0.454890
[epoch2, step1349]: loss 0.455168
[epoch2, step1350]: loss 0.459748
[epoch2, step1351]: loss 0.442051
[epoch2, step1352]: loss 0.473309
[epoch2, step1353]: loss 0.428519
[epoch2, step1354]: loss 0.495067
[epoch2, step1355]: loss 0.441900
[epoch2, step1356]: loss 0.406804
[epoch2, step1357]: loss 0.457528
[epoch2, step1358]: loss 0.456869
[epoch2, step1359]: loss 0.469101
[epoch2, step1360]: loss 0.422432
[epoch2, step1361]: loss 0.461438
[epoch2, step1362]: loss 0.414844
[epoch2, step1363]: loss 0.478134
[epoch2, step1364]: loss 0.442007
[epoch2, step1365]: loss 0.396192
[epoch2, step1366]: loss 0.447791
[epoch2, step1367]: loss 0.464881
[epoch2, step1368]: loss 0.446841
[epoch2, step1369]: loss 0.430472
[epoch2, step1370]: loss 0.469765
[epoch2, step1371]: loss 0.414677
[epoch2, step1372]: loss 0.487607
[epoch2, step1373]: loss 0.442159
[epoch2, step1374]: loss 0.385047
[epoch2, step1375]: loss 0.438242
[epoch2, step1376]: loss 0.455518
[epoch2, step1377]: loss 0.477205
[epoch2, step1378]: loss 0.429002
[epoch2, step1379]: loss 0.471424
[epoch2, step1380]: loss 0.409181
[epoch2, step1381]: loss 0.485486
[epoch2, step1382]: loss 0.438598
[epoch2, step1383]: loss 0.395373
[epoch2, step1384]: loss 0.442672
[epoch2, step1385]: loss 0.460676
[epoch2, step1386]: loss 0.458718
[epoch2, step1387]: loss 0.417497
[epoch2, step1388]: loss 0.480112
[epoch2, step1389]: loss 0.425225
[epoch2, step1390]: loss 0.483524
[epoch2, step1391]: loss 0.443332
[epoch2, step1392]: loss 0.397540
[epoch2, step1393]: loss 0.438819
[epoch2, step1394]: loss 0.444145
[epoch2, step1395]: loss 0.459281
[epoch2, step1396]: loss 0.427975
[epoch2, step1397]: loss 0.467609
[epoch2, step1398]: loss 0.415827
[epoch2, step1399]: loss 0.469771
[epoch2, step1400]: loss 0.436953
[epoch2, step1401]: loss 0.390878
[epoch2, step1402]: loss 0.443824
[epoch2, step1403]: loss 0.466959
[epoch2, step1404]: loss 0.467333
[epoch2, step1405]: loss 0.420973
[epoch2, step1406]: loss 0.468517
[epoch2, step1407]: loss 0.402735
[epoch2, step1408]: loss 0.494773
[epoch2, step1409]: loss 0.447403
[epoch2, step1410]: loss 0.388910
[epoch2, step1411]: loss 0.460772
[epoch2, step1412]: loss 0.451286
[epoch2, step1413]: loss 0.460657
[epoch2, step1414]: loss 0.431734
[epoch2, step1415]: loss 0.467740
[epoch2, step1416]: loss 0.413991
[epoch2, step1417]: loss 0.487559
[epoch2, step1418]: loss 0.441529
[epoch2, step1419]: loss 0.384262
[epoch2, step1420]: loss 0.444574
[epoch2, step1421]: loss 0.446305
[epoch2, step1422]: loss 0.454644
[epoch2, step1423]: loss 0.430583
[epoch2, step1424]: loss 0.461865
[epoch2, step1425]: loss 0.423358
[epoch2, step1426]: loss 0.484057
[epoch2, step1427]: loss 0.428518
[epoch2, step1428]: loss 0.390868
[epoch2, step1429]: loss 0.440212
[epoch2, step1430]: loss 0.455259
[epoch2, step1431]: loss 0.458449
[epoch2, step1432]: loss 0.428501
[epoch2, step1433]: loss 0.461203
[epoch2, step1434]: loss 0.431038
[epoch2, step1435]: loss 0.476344
[epoch2, step1436]: loss 0.434736
[epoch2, step1437]: loss 0.387848
[epoch2, step1438]: loss 0.439576
[epoch2, step1439]: loss 0.455468
[epoch2, step1440]: loss 0.463006
[epoch2, step1441]: loss 0.415970
[epoch2, step1442]: loss 0.474352
[epoch2, step1443]: loss 0.428566
[epoch2, step1444]: loss 0.493242
[epoch2, step1445]: loss 0.433886
[epoch2, step1446]: loss 0.385859
[epoch2, step1447]: loss 0.435886
[epoch2, step1448]: loss 0.453546
[epoch2, step1449]: loss 0.465948
[epoch2, step1450]: loss 0.425785
[epoch2, step1451]: loss 0.457039
[epoch2, step1452]: loss 0.419431
[epoch2, step1453]: loss 0.467724
[epoch2, step1454]: loss 0.432021
[epoch2, step1455]: loss 0.379275
[epoch2, step1456]: loss 0.447888
[epoch2, step1457]: loss 0.440804
[epoch2, step1458]: loss 0.457042
[epoch2, step1459]: loss 0.430599
[epoch2, step1460]: loss 0.454111
[epoch2, step1461]: loss 0.406212
[epoch2, step1462]: loss 0.469820
[epoch2, step1463]: loss 0.441177
[epoch2, step1464]: loss 0.384052
[epoch2, step1465]: loss 0.451289
[epoch2, step1466]: loss 0.453863
[epoch2, step1467]: loss 0.464418
[epoch2, step1468]: loss 0.428755
[epoch2, step1469]: loss 0.462581
[epoch2, step1470]: loss 0.411967
[epoch2, step1471]: loss 0.489675
[epoch2, step1472]: loss 0.441546
[epoch2, step1473]: loss 0.387031
[epoch2, step1474]: loss 0.432578
[epoch2, step1475]: loss 0.454324
[epoch2, step1476]: loss 0.448289
[epoch2, step1477]: loss 0.431617
[epoch2, step1478]: loss 0.459815
[epoch2, step1479]: loss 0.414158
[epoch2, step1480]: loss 0.480891
[epoch2, step1481]: loss 0.453643
[epoch2, step1482]: loss 0.390926
[epoch2, step1483]: loss 0.442079
[epoch2, step1484]: loss 0.446227
[epoch2, step1485]: loss 0.457374
[epoch2, step1486]: loss 0.437257
[epoch2, step1487]: loss 0.461938
[epoch2, step1488]: loss 0.410935
[epoch2, step1489]: loss 0.483233
[epoch2, step1490]: loss 0.434494
[epoch2, step1491]: loss 0.391790
[epoch2, step1492]: loss 0.448133
[epoch2, step1493]: loss 0.450256
[epoch2, step1494]: loss 0.456660
[epoch2, step1495]: loss 0.433452
[epoch2, step1496]: loss 0.472499
[epoch2, step1497]: loss 0.409546
[epoch2, step1498]: loss 0.473432
[epoch2, step1499]: loss 0.446446
[epoch2, step1500]: loss 0.387272
[epoch2, step1501]: loss 0.440832
[epoch2, step1502]: loss 0.450851
[epoch2, step1503]: loss 0.460532
[epoch2, step1504]: loss 0.432464
[epoch2, step1505]: loss 0.456024
[epoch2, step1506]: loss 0.417589
[epoch2, step1507]: loss 0.474206
[epoch2, step1508]: loss 0.430063
[epoch2, step1509]: loss 0.394122
[epoch2, step1510]: loss 0.457499
[epoch2, step1511]: loss 0.438600
[epoch2, step1512]: loss 0.452188
[epoch2, step1513]: loss 0.441311
[epoch2, step1514]: loss 0.460057
[epoch2, step1515]: loss 0.410678
[epoch2, step1516]: loss 0.478816

[epoch2]: avg loss 0.470029

[epoch3, step1]: loss 0.518057
[epoch3, step2]: loss 0.451844
[epoch3, step3]: loss 0.458534
[epoch3, step4]: loss 0.428667
[epoch3, step5]: loss 0.479054
[epoch3, step6]: loss 0.436809
[epoch3, step7]: loss 0.400812
[epoch3, step8]: loss 0.460199
[epoch3, step9]: loss 0.412321
[epoch3, step10]: loss 0.462258
[epoch3, step11]: loss 0.449456
[epoch3, step12]: loss 0.454710
[epoch3, step13]: loss 0.410208
[epoch3, step14]: loss 0.477998
[epoch3, step15]: loss 0.437885
[epoch3, step16]: loss 0.401997
[epoch3, step17]: loss 0.453797
[epoch3, step18]: loss 0.395096
[epoch3, step19]: loss 0.469736
[epoch3, step20]: loss 0.435149
[epoch3, step21]: loss 0.456178
[epoch3, step22]: loss 0.420705
[epoch3, step23]: loss 0.495945
[epoch3, step24]: loss 0.432468
[epoch3, step25]: loss 0.405341
[epoch3, step26]: loss 0.470529
[epoch3, step27]: loss 0.412026
[epoch3, step28]: loss 0.467478
[epoch3, step29]: loss 0.444257
[epoch3, step30]: loss 0.443075
[epoch3, step31]: loss 0.417198
[epoch3, step32]: loss 0.473213
[epoch3, step33]: loss 0.426309
[epoch3, step34]: loss 0.395154
[epoch3, step35]: loss 0.454020
[epoch3, step36]: loss 0.410273
[epoch3, step37]: loss 0.470170
[epoch3, step38]: loss 0.449592
[epoch3, step39]: loss 0.453764
[epoch3, step40]: loss 0.406546
[epoch3, step41]: loss 0.489282
[epoch3, step42]: loss 0.428929
[epoch3, step43]: loss 0.406141
[epoch3, step44]: loss 0.455507
[epoch3, step45]: loss 0.409539
[epoch3, step46]: loss 0.469598
[epoch3, step47]: loss 0.453334
[epoch3, step48]: loss 0.457292
[epoch3, step49]: loss 0.426490
[epoch3, step50]: loss 0.478874
[epoch3, step51]: loss 0.435157
[epoch3, step52]: loss 0.407836
[epoch3, step53]: loss 0.448481
[epoch3, step54]: loss 0.404821
[epoch3, step55]: loss 0.462480
[epoch3, step56]: loss 0.429028
[epoch3, step57]: loss 0.445638
[epoch3, step58]: loss 0.409406
[epoch3, step59]: loss 0.494832
[epoch3, step60]: loss 0.423111
[epoch3, step61]: loss 0.409456
[epoch3, step62]: loss 0.465650
[epoch3, step63]: loss 0.417302
[epoch3, step64]: loss 0.480077
[epoch3, step65]: loss 0.441403
[epoch3, step66]: loss 0.451640
[epoch3, step67]: loss 0.414493
[epoch3, step68]: loss 0.480597
[epoch3, step69]: loss 0.432907
[epoch3, step70]: loss 0.405905
[epoch3, step71]: loss 0.464396
[epoch3, step72]: loss 0.404783
[epoch3, step73]: loss 0.471611
[epoch3, step74]: loss 0.441487
[epoch3, step75]: loss 0.447440
[epoch3, step76]: loss 0.410445
[epoch3, step77]: loss 0.468370
[epoch3, step78]: loss 0.428268
[epoch3, step79]: loss 0.409144
[epoch3, step80]: loss 0.444133
[epoch3, step81]: loss 0.401400
[epoch3, step82]: loss 0.477229
[epoch3, step83]: loss 0.456254
[epoch3, step84]: loss 0.447760
[epoch3, step85]: loss 0.402952
[epoch3, step86]: loss 0.472646
[epoch3, step87]: loss 0.417719
[epoch3, step88]: loss 0.428234
[epoch3, step89]: loss 0.463447
[epoch3, step90]: loss 0.408132
[epoch3, step91]: loss 0.483986
[epoch3, step92]: loss 0.440712
[epoch3, step93]: loss 0.447235
[epoch3, step94]: loss 0.416336
[epoch3, step95]: loss 0.470142
[epoch3, step96]: loss 0.434674
[epoch3, step97]: loss 0.395143
[epoch3, step98]: loss 0.456609
[epoch3, step99]: loss 0.406700
[epoch3, step100]: loss 0.483743
[epoch3, step101]: loss 0.432224
[epoch3, step102]: loss 0.451229
[epoch3, step103]: loss 0.413925
[epoch3, step104]: loss 0.477018
[epoch3, step105]: loss 0.424298
[epoch3, step106]: loss 0.404514
[epoch3, step107]: loss 0.457446
[epoch3, step108]: loss 0.401606
[epoch3, step109]: loss 0.472967
[epoch3, step110]: loss 0.432512
[epoch3, step111]: loss 0.451525
[epoch3, step112]: loss 0.414851
[epoch3, step113]: loss 0.463394
[epoch3, step114]: loss 0.432932
[epoch3, step115]: loss 0.403092
[epoch3, step116]: loss 0.444141
[epoch3, step117]: loss 0.401893
[epoch3, step118]: loss 0.455883
[epoch3, step119]: loss 0.434591
[epoch3, step120]: loss 0.443748
[epoch3, step121]: loss 0.413663
[epoch3, step122]: loss 0.475439
[epoch3, step123]: loss 0.423361
[epoch3, step124]: loss 0.401934
[epoch3, step125]: loss 0.447371
[epoch3, step126]: loss 0.406690
[epoch3, step127]: loss 0.470976
[epoch3, step128]: loss 0.442355
[epoch3, step129]: loss 0.447253
[epoch3, step130]: loss 0.404323
[epoch3, step131]: loss 0.483756
[epoch3, step132]: loss 0.425778
[epoch3, step133]: loss 0.400176
[epoch3, step134]: loss 0.464056
[epoch3, step135]: loss 0.396303
[epoch3, step136]: loss 0.448719
[epoch3, step137]: loss 0.444630
[epoch3, step138]: loss 0.447571
[epoch3, step139]: loss 0.409153
[epoch3, step140]: loss 0.466913
[epoch3, step141]: loss 0.422957
[epoch3, step142]: loss 0.400629
[epoch3, step143]: loss 0.460035
[epoch3, step144]: loss 0.409209
[epoch3, step145]: loss 0.467222
[epoch3, step146]: loss 0.439777
[epoch3, step147]: loss 0.428057
[epoch3, step148]: loss 0.407697
[epoch3, step149]: loss 0.482536
[epoch3, step150]: loss 0.432857
[epoch3, step151]: loss 0.394227
[epoch3, step152]: loss 0.452981
[epoch3, step153]: loss 0.397266
[epoch3, step154]: loss 0.474983
[epoch3, step155]: loss 0.438112
[epoch3, step156]: loss 0.452925
[epoch3, step157]: loss 0.403894
[epoch3, step158]: loss 0.467739
[epoch3, step159]: loss 0.423584
[epoch3, step160]: loss 0.394431
[epoch3, step161]: loss 0.442996
[epoch3, step162]: loss 0.397969
[epoch3, step163]: loss 0.467592
[epoch3, step164]: loss 0.431625
[epoch3, step165]: loss 0.444563
[epoch3, step166]: loss 0.399866
[epoch3, step167]: loss 0.479129
[epoch3, step168]: loss 0.414214
[epoch3, step169]: loss 0.404208
[epoch3, step170]: loss 0.446791
[epoch3, step171]: loss 0.397285
[epoch3, step172]: loss 0.464096
[epoch3, step173]: loss 0.432900
[epoch3, step174]: loss 0.448475
[epoch3, step175]: loss 0.393222
[epoch3, step176]: loss 0.469558
[epoch3, step177]: loss 0.420039
[epoch3, step178]: loss 0.389837
[epoch3, step179]: loss 0.463015
[epoch3, step180]: loss 0.390107
[epoch3, step181]: loss 0.460838
[epoch3, step182]: loss 0.430954
[epoch3, step183]: loss 0.434336
[epoch3, step184]: loss 0.392798
[epoch3, step185]: loss 0.467920
[epoch3, step186]: loss 0.419533
[epoch3, step187]: loss 0.399331
[epoch3, step188]: loss 0.453812
[epoch3, step189]: loss 0.394268
[epoch3, step190]: loss 0.473407
[epoch3, step191]: loss 0.438625
[epoch3, step192]: loss 0.434286
[epoch3, step193]: loss 0.429557
[epoch3, step194]: loss 0.482455
[epoch3, step195]: loss 0.418292
[epoch3, step196]: loss 0.393158
[epoch3, step197]: loss 0.452317
[epoch3, step198]: loss 0.407601
[epoch3, step199]: loss 0.462157
[epoch3, step200]: loss 0.425585
[epoch3, step201]: loss 0.434557
[epoch3, step202]: loss 0.406603
[epoch3, step203]: loss 0.470195
[epoch3, step204]: loss 0.415571
[epoch3, step205]: loss 0.406646
[epoch3, step206]: loss 0.453997
[epoch3, step207]: loss 0.395850
[epoch3, step208]: loss 0.454560
[epoch3, step209]: loss 0.428881
[epoch3, step210]: loss 0.428370
[epoch3, step211]: loss 0.400317
[epoch3, step212]: loss 0.465054
[epoch3, step213]: loss 0.426406
[epoch3, step214]: loss 0.409334
[epoch3, step215]: loss 0.445745
[epoch3, step216]: loss 0.394143
[epoch3, step217]: loss 0.474898
[epoch3, step218]: loss 0.427911
[epoch3, step219]: loss 0.444464
[epoch3, step220]: loss 0.408433
[epoch3, step221]: loss 0.464767
[epoch3, step222]: loss 0.415768
[epoch3, step223]: loss 0.386342
[epoch3, step224]: loss 0.452988
[epoch3, step225]: loss 0.394487
[epoch3, step226]: loss 0.467300
[epoch3, step227]: loss 0.446909
[epoch3, step228]: loss 0.432339
[epoch3, step229]: loss 0.414346
[epoch3, step230]: loss 0.462089
[epoch3, step231]: loss 0.413442
[epoch3, step232]: loss 0.399676
[epoch3, step233]: loss 0.459525
[epoch3, step234]: loss 0.402050
[epoch3, step235]: loss 0.462199
[epoch3, step236]: loss 0.430924
[epoch3, step237]: loss 0.439641
[epoch3, step238]: loss 0.402325
[epoch3, step239]: loss 0.477663
[epoch3, step240]: loss 0.432565
[epoch3, step241]: loss 0.391675
[epoch3, step242]: loss 0.450448
[epoch3, step243]: loss 0.391769
[epoch3, step244]: loss 0.465058
[epoch3, step245]: loss 0.438725
[epoch3, step246]: loss 0.440357
[epoch3, step247]: loss 0.402278
[epoch3, step248]: loss 0.472770
[epoch3, step249]: loss 0.427620
[epoch3, step250]: loss 0.392838
[epoch3, step251]: loss 0.439207
[epoch3, step252]: loss 0.388805
[epoch3, step253]: loss 0.469061
[epoch3, step254]: loss 0.442788
[epoch3, step255]: loss 0.435780
[epoch3, step256]: loss 0.409746
[epoch3, step257]: loss 0.470090
[epoch3, step258]: loss 0.411016
[epoch3, step259]: loss 0.390205
[epoch3, step260]: loss 0.455586
[epoch3, step261]: loss 0.381940
[epoch3, step262]: loss 0.453382
[epoch3, step263]: loss 0.442946
[epoch3, step264]: loss 0.442239
[epoch3, step265]: loss 0.402217
[epoch3, step266]: loss 0.468061
[epoch3, step267]: loss 0.431594
[epoch3, step268]: loss 0.393631
[epoch3, step269]: loss 0.445227
[epoch3, step270]: loss 0.398740
[epoch3, step271]: loss 0.457595
[epoch3, step272]: loss 0.432328
[epoch3, step273]: loss 0.442172
[epoch3, step274]: loss 0.392582
[epoch3, step275]: loss 0.475905
[epoch3, step276]: loss 0.426731
[epoch3, step277]: loss 0.388733
[epoch3, step278]: loss 0.443382
[epoch3, step279]: loss 0.391547
[epoch3, step280]: loss 0.457380
[epoch3, step281]: loss 0.434354
[epoch3, step282]: loss 0.430133
[epoch3, step283]: loss 0.407184
[epoch3, step284]: loss 0.473161
[epoch3, step285]: loss 0.407710
[epoch3, step286]: loss 0.415223
[epoch3, step287]: loss 0.443405
[epoch3, step288]: loss 0.400295
[epoch3, step289]: loss 0.452092
[epoch3, step290]: loss 0.430903
[epoch3, step291]: loss 0.433313
[epoch3, step292]: loss 0.411290
[epoch3, step293]: loss 0.469141
[epoch3, step294]: loss 0.426367
[epoch3, step295]: loss 0.397807
[epoch3, step296]: loss 0.434700
[epoch3, step297]: loss 0.398726
[epoch3, step298]: loss 0.456810
[epoch3, step299]: loss 0.443036
[epoch3, step300]: loss 0.431787
[epoch3, step301]: loss 0.406912
[epoch3, step302]: loss 0.459160
[epoch3, step303]: loss 0.412604
[epoch3, step304]: loss 0.392089
[epoch3, step305]: loss 0.450156
[epoch3, step306]: loss 0.392736
[epoch3, step307]: loss 0.466007
[epoch3, step308]: loss 0.422493
[epoch3, step309]: loss 0.429661
[epoch3, step310]: loss 0.401260
[epoch3, step311]: loss 0.457914
[epoch3, step312]: loss 0.421830
[epoch3, step313]: loss 0.392543
[epoch3, step314]: loss 0.443801
[epoch3, step315]: loss 0.386194
[epoch3, step316]: loss 0.463020
[epoch3, step317]: loss 0.426787
[epoch3, step318]: loss 0.435187
[epoch3, step319]: loss 0.408980
[epoch3, step320]: loss 0.478840
[epoch3, step321]: loss 0.423501
[epoch3, step322]: loss 0.403606
[epoch3, step323]: loss 0.454068
[epoch3, step324]: loss 0.384538
[epoch3, step325]: loss 0.456219
[epoch3, step326]: loss 0.433131
[epoch3, step327]: loss 0.445008
[epoch3, step328]: loss 0.401477
[epoch3, step329]: loss 0.469603
[epoch3, step330]: loss 0.427149
[epoch3, step331]: loss 0.395334
[epoch3, step332]: loss 0.452250
[epoch3, step333]: loss 0.397136
[epoch3, step334]: loss 0.455288
[epoch3, step335]: loss 0.427881
[epoch3, step336]: loss 0.423803
[epoch3, step337]: loss 0.393373
[epoch3, step338]: loss 0.471772
[epoch3, step339]: loss 0.421468
[epoch3, step340]: loss 0.392321
[epoch3, step341]: loss 0.450313
[epoch3, step342]: loss 0.392506
[epoch3, step343]: loss 0.453428
[epoch3, step344]: loss 0.432781
[epoch3, step345]: loss 0.444678
[epoch3, step346]: loss 0.406422
[epoch3, step347]: loss 0.468718
[epoch3, step348]: loss 0.413702
[epoch3, step349]: loss 0.386206
[epoch3, step350]: loss 0.450930
[epoch3, step351]: loss 0.396619
[epoch3, step352]: loss 0.457403
[epoch3, step353]: loss 0.430365
[epoch3, step354]: loss 0.449616
[epoch3, step355]: loss 0.409305
[epoch3, step356]: loss 0.454378
[epoch3, step357]: loss 0.415586
[epoch3, step358]: loss 0.411376
[epoch3, step359]: loss 0.431777
[epoch3, step360]: loss 0.396348
[epoch3, step361]: loss 0.464134
[epoch3, step362]: loss 0.420886
[epoch3, step363]: loss 0.439331
[epoch3, step364]: loss 0.401451
[epoch3, step365]: loss 0.465746
[epoch3, step366]: loss 0.411588
[epoch3, step367]: loss 0.396080
[epoch3, step368]: loss 0.450764
[epoch3, step369]: loss 0.395022
[epoch3, step370]: loss 0.448534
[epoch3, step371]: loss 0.415821
[epoch3, step372]: loss 0.439351
[epoch3, step373]: loss 0.401141
[epoch3, step374]: loss 0.471917
[epoch3, step375]: loss 0.406948
[epoch3, step376]: loss 0.383619
[epoch3, step377]: loss 0.439475
[epoch3, step378]: loss 0.390711
[epoch3, step379]: loss 0.447467
[epoch3, step380]: loss 0.419816
[epoch3, step381]: loss 0.438220
[epoch3, step382]: loss 0.406758
[epoch3, step383]: loss 0.478073
[epoch3, step384]: loss 0.425523
[epoch3, step385]: loss 0.385227
[epoch3, step386]: loss 0.439131
[epoch3, step387]: loss 0.385814
[epoch3, step388]: loss 0.443517
[epoch3, step389]: loss 0.426574
[epoch3, step390]: loss 0.418632
[epoch3, step391]: loss 0.399237
[epoch3, step392]: loss 0.452172
[epoch3, step393]: loss 0.422117
[epoch3, step394]: loss 0.395726
[epoch3, step395]: loss 0.445182
[epoch3, step396]: loss 0.387566
[epoch3, step397]: loss 0.463308
[epoch3, step398]: loss 0.424557
[epoch3, step399]: loss 0.433948
[epoch3, step400]: loss 0.397301
[epoch3, step401]: loss 0.463467
[epoch3, step402]: loss 0.417993
[epoch3, step403]: loss 0.387287
[epoch3, step404]: loss 0.437079
[epoch3, step405]: loss 0.384147
[epoch3, step406]: loss 0.448186
[epoch3, step407]: loss 0.429728
[epoch3, step408]: loss 0.431198
[epoch3, step409]: loss 0.377306
[epoch3, step410]: loss 0.451857
[epoch3, step411]: loss 0.414977
[epoch3, step412]: loss 0.391478
[epoch3, step413]: loss 0.441115
[epoch3, step414]: loss 0.400013
[epoch3, step415]: loss 0.451331
[epoch3, step416]: loss 0.433990
[epoch3, step417]: loss 0.428990
[epoch3, step418]: loss 0.394955
[epoch3, step419]: loss 0.469719
[epoch3, step420]: loss 0.408943
[epoch3, step421]: loss 0.391003
[epoch3, step422]: loss 0.439711
[epoch3, step423]: loss 0.387409
[epoch3, step424]: loss 0.449239
[epoch3, step425]: loss 0.422375
[epoch3, step426]: loss 0.426482
[epoch3, step427]: loss 0.400495
[epoch3, step428]: loss 0.461503
[epoch3, step429]: loss 0.401558
[epoch3, step430]: loss 0.388348
[epoch3, step431]: loss 0.434291
[epoch3, step432]: loss 0.385737
[epoch3, step433]: loss 0.439473
[epoch3, step434]: loss 0.425665
[epoch3, step435]: loss 0.425250
[epoch3, step436]: loss 0.406182
[epoch3, step437]: loss 0.456510
[epoch3, step438]: loss 0.402553
[epoch3, step439]: loss 0.389946
[epoch3, step440]: loss 0.438967
[epoch3, step441]: loss 0.382374
[epoch3, step442]: loss 0.451377
[epoch3, step443]: loss 0.416438
[epoch3, step444]: loss 0.436122
[epoch3, step445]: loss 0.391899
[epoch3, step446]: loss 0.452842
[epoch3, step447]: loss 0.402724
[epoch3, step448]: loss 0.381311
[epoch3, step449]: loss 0.440839
[epoch3, step450]: loss 0.397837
[epoch3, step451]: loss 0.453391
[epoch3, step452]: loss 0.439632
[epoch3, step453]: loss 0.427444
[epoch3, step454]: loss 0.399205
[epoch3, step455]: loss 0.455088
[epoch3, step456]: loss 0.422564
[epoch3, step457]: loss 0.381110
[epoch3, step458]: loss 0.441238
[epoch3, step459]: loss 0.376832
[epoch3, step460]: loss 0.452018
[epoch3, step461]: loss 0.412943
[epoch3, step462]: loss 0.438740
[epoch3, step463]: loss 0.394131
[epoch3, step464]: loss 0.459911
[epoch3, step465]: loss 0.391653
[epoch3, step466]: loss 0.383921
[epoch3, step467]: loss 0.441956
[epoch3, step468]: loss 0.389637
[epoch3, step469]: loss 0.448633
[epoch3, step470]: loss 0.419109
[epoch3, step471]: loss 0.434099
[epoch3, step472]: loss 0.395736
[epoch3, step473]: loss 0.462515
[epoch3, step474]: loss 0.414139
[epoch3, step475]: loss 0.385180
[epoch3, step476]: loss 0.430078
[epoch3, step477]: loss 0.387095
[epoch3, step478]: loss 0.456194
[epoch3, step479]: loss 0.422498
[epoch3, step480]: loss 0.440177
[epoch3, step481]: loss 0.397505
[epoch3, step482]: loss 0.465809
[epoch3, step483]: loss 0.403826
[epoch3, step484]: loss 0.374882
[epoch3, step485]: loss 0.434536
[epoch3, step486]: loss 0.380814
[epoch3, step487]: loss 0.457305
[epoch3, step488]: loss 0.416530
[epoch3, step489]: loss 0.439728
[epoch3, step490]: loss 0.393161
[epoch3, step491]: loss 0.451629
[epoch3, step492]: loss 0.412851
[epoch3, step493]: loss 0.383948
[epoch3, step494]: loss 0.444400
[epoch3, step495]: loss 0.367021
[epoch3, step496]: loss 0.451073
[epoch3, step497]: loss 0.418392
[epoch3, step498]: loss 0.428418
[epoch3, step499]: loss 0.393042
[epoch3, step500]: loss 0.462668
[epoch3, step501]: loss 0.417771
[epoch3, step502]: loss 0.384877
[epoch3, step503]: loss 0.433283
[epoch3, step504]: loss 0.395821
[epoch3, step505]: loss 0.462500
[epoch3, step506]: loss 0.411784
[epoch3, step507]: loss 0.422007
[epoch3, step508]: loss 0.388143
[epoch3, step509]: loss 0.459254
[epoch3, step510]: loss 0.407278
[epoch3, step511]: loss 0.387714
[epoch3, step512]: loss 0.429823
[epoch3, step513]: loss 0.385346
[epoch3, step514]: loss 0.445147
[epoch3, step515]: loss 0.420149
[epoch3, step516]: loss 0.420781
[epoch3, step517]: loss 0.395617
[epoch3, step518]: loss 0.454005
[epoch3, step519]: loss 0.407386
[epoch3, step520]: loss 0.383171
[epoch3, step521]: loss 0.440307
[epoch3, step522]: loss 0.388644
[epoch3, step523]: loss 0.447717
[epoch3, step524]: loss 0.430684
[epoch3, step525]: loss 0.421187
[epoch3, step526]: loss 0.384145
[epoch3, step527]: loss 0.460352
[epoch3, step528]: loss 0.403540
[epoch3, step529]: loss 0.391016
[epoch3, step530]: loss 0.429752
[epoch3, step531]: loss 0.383657
[epoch3, step532]: loss 0.453836
[epoch3, step533]: loss 0.405099
[epoch3, step534]: loss 0.426991
[epoch3, step535]: loss 0.388385
[epoch3, step536]: loss 0.451421
[epoch3, step537]: loss 0.405531
[epoch3, step538]: loss 0.390170
[epoch3, step539]: loss 0.436784
[epoch3, step540]: loss 0.395967
[epoch3, step541]: loss 0.453834
[epoch3, step542]: loss 0.419986
[epoch3, step543]: loss 0.427788
[epoch3, step544]: loss 0.384233
[epoch3, step545]: loss 0.465931
[epoch3, step546]: loss 0.399978
[epoch3, step547]: loss 0.393003
[epoch3, step548]: loss 0.435797
[epoch3, step549]: loss 0.380908
[epoch3, step550]: loss 0.445441
[epoch3, step551]: loss 0.419026
[epoch3, step552]: loss 0.432014
[epoch3, step553]: loss 0.388048
[epoch3, step554]: loss 0.458381
[epoch3, step555]: loss 0.412777
[epoch3, step556]: loss 0.379592
[epoch3, step557]: loss 0.440854
[epoch3, step558]: loss 0.380010
[epoch3, step559]: loss 0.453837
[epoch3, step560]: loss 0.416582
[epoch3, step561]: loss 0.427452
[epoch3, step562]: loss 0.386426
[epoch3, step563]: loss 0.542095
[epoch3, step564]: loss 0.407238
[epoch3, step565]: loss 0.318631
[epoch3, step566]: loss 0.335365
[epoch3, step567]: loss 0.331729
[epoch3, step568]: loss 0.378036
[epoch3, step569]: loss 0.453045
[epoch3, step570]: loss 0.379150
[epoch3, step571]: loss 0.263677
[epoch3, step572]: loss 0.376477
[epoch3, step573]: loss 0.391107
[epoch3, step574]: loss 0.484353
[epoch3, step575]: loss 0.421868
[epoch3, step576]: loss 0.432707
[epoch3, step577]: loss 0.361024
[epoch3, step578]: loss 0.434966
[epoch3, step579]: loss 0.336855
[epoch3, step580]: loss 0.493491
[epoch3, step581]: loss 0.428043
[epoch3, step582]: loss 0.415770
[epoch3, step583]: loss 0.424360
[epoch3, step584]: loss 0.393849
[epoch3, step585]: loss 0.469144
[epoch3, step586]: loss 0.415615
[epoch3, step587]: loss 0.289388
[epoch3, step588]: loss 0.417096
[epoch3, step589]: loss 0.552173
[epoch3, step590]: loss 0.310032
[epoch3, step591]: loss 0.407000
[epoch3, step592]: loss 0.445371
[epoch3, step593]: loss 0.545186
[epoch3, step594]: loss 0.317766
[epoch3, step595]: loss 0.318882
[epoch3, step596]: loss 0.455038
[epoch3, step597]: loss 0.469435
[epoch3, step598]: loss 0.342072
[epoch3, step599]: loss 0.318197
[epoch3, step600]: loss 0.307093
[epoch3, step601]: loss 0.410826
[epoch3, step602]: loss 0.491204
[epoch3, step603]: loss 0.356410
[epoch3, step604]: loss 0.348181
[epoch3, step605]: loss 0.306360
[epoch3, step606]: loss 0.393882
[epoch3, step607]: loss 0.431773
[epoch3, step608]: loss 0.265732
[epoch3, step609]: loss 0.404968
[epoch3, step610]: loss 0.355343
[epoch3, step611]: loss 0.449194
[epoch3, step612]: loss 0.410336
[epoch3, step613]: loss 0.458012
[epoch3, step614]: loss 0.396275
[epoch3, step615]: loss 0.405591
[epoch3, step616]: loss 0.323284
[epoch3, step617]: loss 0.375043
[epoch3, step618]: loss 0.442433
[epoch3, step619]: loss 0.329494
[epoch3, step620]: loss 0.305928
[epoch3, step621]: loss 0.296204
[epoch3, step622]: loss 0.435046
[epoch3, step623]: loss 0.416294
[epoch3, step624]: loss 0.415262
[epoch3, step625]: loss 0.302935
[epoch3, step626]: loss 0.416703
[epoch3, step627]: loss 0.486193
[epoch3, step628]: loss 0.440923
[epoch3, step629]: loss 0.239057
[epoch3, step630]: loss 0.346390
[epoch3, step631]: loss 0.336591
[epoch3, step632]: loss 0.418999
[epoch3, step633]: loss 0.338881
[epoch3, step634]: loss 0.390588
[epoch3, step635]: loss 0.373944
[epoch3, step636]: loss 0.330051
[epoch3, step637]: loss 0.439619
[epoch3, step638]: loss 0.405066
[epoch3, step639]: loss 0.312005
[epoch3, step640]: loss 0.416618
[epoch3, step641]: loss 0.317444
[epoch3, step642]: loss 0.314193
[epoch3, step643]: loss 0.424712
[epoch3, step644]: loss 0.370687
[epoch3, step645]: loss 0.284527
[epoch3, step646]: loss 0.382124
[epoch3, step647]: loss 0.293612
[epoch3, step648]: loss 0.486310
[epoch3, step649]: loss 0.406788
[epoch3, step650]: loss 0.442997
[epoch3, step651]: loss 0.363880
[epoch3, step652]: loss 0.462869
[epoch3, step653]: loss 0.443188
[epoch3, step654]: loss 0.431128
[epoch3, step655]: loss 0.323018
[epoch3, step656]: loss 0.455613
[epoch3, step657]: loss 0.445012
[epoch3, step658]: loss 0.342545
[epoch3, step659]: loss 0.290323
[epoch3, step660]: loss 0.386526
[epoch3, step661]: loss 0.412384
[epoch3, step662]: loss 0.297604
[epoch3, step663]: loss 0.380548
[epoch3, step664]: loss 0.363435
[epoch3, step665]: loss 0.466293
[epoch3, step666]: loss 0.307016
[epoch3, step667]: loss 0.407692
[epoch3, step668]: loss 0.478646
[epoch3, step669]: loss 0.312040
[epoch3, step670]: loss 0.392492
[epoch3, step671]: loss 0.410230
[epoch3, step672]: loss 0.494955
[epoch3, step673]: loss 0.456775
[epoch3, step674]: loss 0.376640
[epoch3, step675]: loss 0.440565
[epoch3, step676]: loss 0.422596
[epoch3, step677]: loss 0.357731
[epoch3, step678]: loss 0.308727
[epoch3, step679]: loss 0.381177
[epoch3, step680]: loss 0.298052
[epoch3, step681]: loss 0.314201
[epoch3, step682]: loss 0.320253
[epoch3, step683]: loss 0.390374
[epoch3, step684]: loss 0.321443
[epoch3, step685]: loss 0.323699
[epoch3, step686]: loss 0.307368
[epoch3, step687]: loss 0.339570
[epoch3, step688]: loss 0.422589
[epoch3, step689]: loss 0.323194
[epoch3, step690]: loss 0.436445
[epoch3, step691]: loss 0.456272
[epoch3, step692]: loss 0.441470
[epoch3, step693]: loss 0.397302
[epoch3, step694]: loss 0.299153
[epoch3, step695]: loss 0.349411
[epoch3, step696]: loss 0.321154
[epoch3, step697]: loss 0.396930
[epoch3, step698]: loss 0.353805
[epoch3, step699]: loss 0.362140
[epoch3, step700]: loss 0.489923
[epoch3, step701]: loss 0.414993
[epoch3, step702]: loss 0.354470
[epoch3, step703]: loss 0.477017
[epoch3, step704]: loss 0.437135
[epoch3, step705]: loss 0.324785
[epoch3, step706]: loss 0.337910
[epoch3, step707]: loss 0.350438
[epoch3, step708]: loss 0.386516
[epoch3, step709]: loss 0.330193
[epoch3, step710]: loss 0.399918
[epoch3, step711]: loss 0.440628
[epoch3, step712]: loss 0.292300
[epoch3, step713]: loss 0.344170
[epoch3, step714]: loss 0.417570
[epoch3, step715]: loss 0.339890
[epoch3, step716]: loss 0.396973
[epoch3, step717]: loss 0.331569
[epoch3, step718]: loss 0.370211
[epoch3, step719]: loss 0.368240
[epoch3, step720]: loss 0.328404
[epoch3, step721]: loss 0.364813
[epoch3, step722]: loss 0.379159
[epoch3, step723]: loss 0.368283
[epoch3, step724]: loss 0.404900
[epoch3, step725]: loss 0.396728
[epoch3, step726]: loss 0.276257
[epoch3, step727]: loss 0.392026
[epoch3, step728]: loss 0.399330
[epoch3, step729]: loss 0.321443
[epoch3, step730]: loss 0.400710
[epoch3, step731]: loss 0.434704
[epoch3, step732]: loss 0.362000
[epoch3, step733]: loss 0.292591
[epoch3, step734]: loss 0.336427
[epoch3, step735]: loss 0.329247
[epoch3, step736]: loss 0.354286
[epoch3, step737]: loss 0.308337
[epoch3, step738]: loss 0.339656
[epoch3, step739]: loss 0.478119
[epoch3, step740]: loss 0.516034
[epoch3, step741]: loss 0.387543
[epoch3, step742]: loss 0.450737
[epoch3, step743]: loss 0.381436
[epoch3, step744]: loss 0.369016
[epoch3, step745]: loss 0.374542
[epoch3, step746]: loss 0.406718
[epoch3, step747]: loss 0.360874
[epoch3, step748]: loss 0.323162
[epoch3, step749]: loss 0.481413
[epoch3, step750]: loss 0.402063
[epoch3, step751]: loss 0.355849
[epoch3, step752]: loss 0.311563
[epoch3, step753]: loss 0.321408
[epoch3, step754]: loss 0.445778
[epoch3, step755]: loss 0.397485
[epoch3, step756]: loss 0.292622
[epoch3, step757]: loss 0.375121
[epoch3, step758]: loss 0.413332
[epoch3, step759]: loss 0.325863
[epoch3, step760]: loss 0.397338
[epoch3, step761]: loss 0.355954
[epoch3, step762]: loss 0.340642
[epoch3, step763]: loss 0.339028
[epoch3, step764]: loss 0.392321
[epoch3, step765]: loss 0.335014
[epoch3, step766]: loss 0.310937
[epoch3, step767]: loss 0.404862
[epoch3, step768]: loss 0.377464
[epoch3, step769]: loss 0.372156
[epoch3, step770]: loss 0.469964
[epoch3, step771]: loss 0.310831
[epoch3, step772]: loss 0.305126
[epoch3, step773]: loss 0.357133
[epoch3, step774]: loss 0.375119
[epoch3, step775]: loss 0.465588
[epoch3, step776]: loss 0.396793
[epoch3, step777]: loss 0.346679
[epoch3, step778]: loss 0.420629
[epoch3, step779]: loss 0.359045
[epoch3, step780]: loss 0.412997
[epoch3, step781]: loss 0.469267
[epoch3, step782]: loss 0.445619
[epoch3, step783]: loss 0.386303
[epoch3, step784]: loss 0.441082
[epoch3, step785]: loss 0.427875
[epoch3, step786]: loss 0.369177
[epoch3, step787]: loss 0.463950
[epoch3, step788]: loss 0.382277
[epoch3, step789]: loss 0.444639
[epoch3, step790]: loss 0.308383
[epoch3, step791]: loss 0.397517
[epoch3, step792]: loss 0.404356
[epoch3, step793]: loss 0.407284
[epoch3, step794]: loss 0.388033
[epoch3, step795]: loss 0.366874
[epoch3, step796]: loss 0.349966
[epoch3, step797]: loss 0.318428
[epoch3, step798]: loss 0.319510
[epoch3, step799]: loss 0.271177
[epoch3, step800]: loss 0.489501
[epoch3, step801]: loss 0.455261
[epoch3, step802]: loss 0.368260
[epoch3, step803]: loss 0.334307
[epoch3, step804]: loss 0.395733
[epoch3, step805]: loss 0.349216
[epoch3, step806]: loss 0.382588
[epoch3, step807]: loss 0.421770
[epoch3, step808]: loss 0.465630
[epoch3, step809]: loss 0.342386
[epoch3, step810]: loss 0.283600
[epoch3, step811]: loss 0.367696
[epoch3, step812]: loss 0.407069
[epoch3, step813]: loss 0.339820
[epoch3, step814]: loss 0.383994
[epoch3, step815]: loss 0.362290
[epoch3, step816]: loss 0.375448
[epoch3, step817]: loss 0.320415
[epoch3, step818]: loss 0.352584
[epoch3, step819]: loss 0.550007
[epoch3, step820]: loss 0.332085
[epoch3, step821]: loss 0.324382
[epoch3, step822]: loss 0.378043
[epoch3, step823]: loss 0.319991
[epoch3, step824]: loss 0.368693
[epoch3, step825]: loss 0.392351
[epoch3, step826]: loss 0.264997
[epoch3, step827]: loss 0.328488
[epoch3, step828]: loss 0.361224
[epoch3, step829]: loss 0.336370
[epoch3, step830]: loss 0.254481
[epoch3, step831]: loss 0.315987
[epoch3, step832]: loss 0.468990
[epoch3, step833]: loss 0.377267
[epoch3, step834]: loss 0.372079
[epoch3, step835]: loss 0.391979
[epoch3, step836]: loss 0.323165
[epoch3, step837]: loss 0.301891
[epoch3, step838]: loss 0.419210
[epoch3, step839]: loss 0.364212
[epoch3, step840]: loss 0.339065
[epoch3, step841]: loss 0.363271
[epoch3, step842]: loss 0.357516
[epoch3, step843]: loss 0.413591
[epoch3, step844]: loss 0.416274
[epoch3, step845]: loss 0.397795
[epoch3, step846]: loss 0.491212
[epoch3, step847]: loss 0.367793
[epoch3, step848]: loss 0.196999
[epoch3, step849]: loss 0.335191
[epoch3, step850]: loss 0.419892
[epoch3, step851]: loss 0.354639
[epoch3, step852]: loss 0.366702
[epoch3, step853]: loss 0.394487
[epoch3, step854]: loss 0.419733
[epoch3, step855]: loss 0.326133
[epoch3, step856]: loss 0.296951
[epoch3, step857]: loss 0.389166
[epoch3, step858]: loss 0.405297
[epoch3, step859]: loss 0.330725
[epoch3, step860]: loss 0.424457
[epoch3, step861]: loss 0.380978
[epoch3, step862]: loss 0.297470
[epoch3, step863]: loss 0.418133
[epoch3, step864]: loss 0.425508
[epoch3, step865]: loss 0.393895
[epoch3, step866]: loss 0.413213
[epoch3, step867]: loss 0.341574
[epoch3, step868]: loss 0.381669
[epoch3, step869]: loss 0.323688
[epoch3, step870]: loss 0.293175
[epoch3, step871]: loss 0.467919
[epoch3, step872]: loss 0.401591
[epoch3, step873]: loss 0.304784
[epoch3, step874]: loss 0.362023
[epoch3, step875]: loss 0.474987
[epoch3, step876]: loss 0.426826
[epoch3, step877]: loss 0.231517
[epoch3, step878]: loss 0.327780
[epoch3, step879]: loss 0.346385
[epoch3, step880]: loss 0.334512
[epoch3, step881]: loss 0.430029
[epoch3, step882]: loss 0.328642
[epoch3, step883]: loss 0.344280
[epoch3, step884]: loss 0.453604
[epoch3, step885]: loss 0.458608
[epoch3, step886]: loss 0.434020
[epoch3, step887]: loss 0.465527
[epoch3, step888]: loss 0.347641
[epoch3, step889]: loss 0.405497
[epoch3, step890]: loss 0.410166
[epoch3, step891]: loss 0.343391
[epoch3, step892]: loss 0.415008
[epoch3, step893]: loss 0.394926
[epoch3, step894]: loss 0.400437
[epoch3, step895]: loss 0.307358
[epoch3, step896]: loss 0.508259
[epoch3, step897]: loss 0.501335
[epoch3, step898]: loss 0.319508
[epoch3, step899]: loss 0.221515
[epoch3, step900]: loss 0.364868
[epoch3, step901]: loss 0.432188
[epoch3, step902]: loss 0.328472
[epoch3, step903]: loss 0.445050
[epoch3, step904]: loss 0.315684
[epoch3, step905]: loss 0.299112
[epoch3, step906]: loss 0.291013
[epoch3, step907]: loss 0.407980
[epoch3, step908]: loss 0.450033
[epoch3, step909]: loss 0.354680
[epoch3, step910]: loss 0.297602
[epoch3, step911]: loss 0.280895
[epoch3, step912]: loss 0.413133
[epoch3, step913]: loss 0.421485
[epoch3, step914]: loss 0.358221
[epoch3, step915]: loss 0.328303
[epoch3, step916]: loss 0.385456
[epoch3, step917]: loss 0.370377
[epoch3, step918]: loss 0.415102
[epoch3, step919]: loss 0.303825
[epoch3, step920]: loss 0.425959
[epoch3, step921]: loss 0.335871
[epoch3, step922]: loss 0.348312
[epoch3, step923]: loss 0.445708
[epoch3, step924]: loss 0.342865
[epoch3, step925]: loss 0.336708
[epoch3, step926]: loss 0.341348
[epoch3, step927]: loss 0.435342
[epoch3, step928]: loss 0.330068
[epoch3, step929]: loss 0.347943
[epoch3, step930]: loss 0.364605
[epoch3, step931]: loss 0.403636
[epoch3, step932]: loss 0.333331
[epoch3, step933]: loss 0.335951
[epoch3, step934]: loss 0.452752
[epoch3, step935]: loss 0.382470
[epoch3, step936]: loss 0.330876
[epoch3, step937]: loss 0.289045
[epoch3, step938]: loss 0.468289
[epoch3, step939]: loss 0.346502
[epoch3, step940]: loss 0.417999
[epoch3, step941]: loss 0.379524
[epoch3, step942]: loss 0.375198
[epoch3, step943]: loss 0.440750
[epoch3, step944]: loss 0.374589
[epoch3, step945]: loss 0.429480
[epoch3, step946]: loss 0.365842
[epoch3, step947]: loss 0.321763
[epoch3, step948]: loss 0.533395
[epoch3, step949]: loss 0.376468
[epoch3, step950]: loss 0.353812
[epoch3, step951]: loss 0.384784
[epoch3, step952]: loss 0.409541
[epoch3, step953]: loss 0.362243
[epoch3, step954]: loss 0.402247
[epoch3, step955]: loss 0.275042
[epoch3, step956]: loss 0.412404
[epoch3, step957]: loss 0.375838
[epoch3, step958]: loss 0.446118
[epoch3, step959]: loss 0.395211
[epoch3, step960]: loss 0.362163
[epoch3, step961]: loss 0.398581
[epoch3, step962]: loss 0.403479
[epoch3, step963]: loss 0.420819
[epoch3, step964]: loss 0.379881
[epoch3, step965]: loss 0.429863
[epoch3, step966]: loss 0.375142
[epoch3, step967]: loss 0.435236
[epoch3, step968]: loss 0.398721
[epoch3, step969]: loss 0.347509
[epoch3, step970]: loss 0.399245
[epoch3, step971]: loss 0.403764
[epoch3, step972]: loss 0.405989
[epoch3, step973]: loss 0.392725
[epoch3, step974]: loss 0.407806
[epoch3, step975]: loss 0.369486
[epoch3, step976]: loss 0.435944
[epoch3, step977]: loss 0.384480
[epoch3, step978]: loss 0.347860
[epoch3, step979]: loss 0.406294
[epoch3, step980]: loss 0.404620
[epoch3, step981]: loss 0.411734
[epoch3, step982]: loss 0.378368
[epoch3, step983]: loss 0.412302
[epoch3, step984]: loss 0.374486
[epoch3, step985]: loss 0.434416
[epoch3, step986]: loss 0.379081
[epoch3, step987]: loss 0.338433
[epoch3, step988]: loss 0.387740
[epoch3, step989]: loss 0.394023
[epoch3, step990]: loss 0.411176
[epoch3, step991]: loss 0.369897
[epoch3, step992]: loss 0.413300
[epoch3, step993]: loss 0.373276
[epoch3, step994]: loss 0.440142
[epoch3, step995]: loss 0.387979
[epoch3, step996]: loss 0.348105
[epoch3, step997]: loss 0.392396
[epoch3, step998]: loss 0.391880
[epoch3, step999]: loss 0.406015
[epoch3, step1000]: loss 0.377872
[epoch3, step1001]: loss 0.409269
[epoch3, step1002]: loss 0.363530
[epoch3, step1003]: loss 0.433893
[epoch3, step1004]: loss 0.382207
[epoch3, step1005]: loss 0.352959
[epoch3, step1006]: loss 0.394267
[epoch3, step1007]: loss 0.401515
[epoch3, step1008]: loss 0.412366
[epoch3, step1009]: loss 0.377218
[epoch3, step1010]: loss 0.401313
[epoch3, step1011]: loss 0.366985
[epoch3, step1012]: loss 0.422850
[epoch3, step1013]: loss 0.384218
[epoch3, step1014]: loss 0.340324
[epoch3, step1015]: loss 0.388849
[epoch3, step1016]: loss 0.400821
[epoch3, step1017]: loss 0.412953
[epoch3, step1018]: loss 0.376172
[epoch3, step1019]: loss 0.408385
[epoch3, step1020]: loss 0.371770
[epoch3, step1021]: loss 0.431824
[epoch3, step1022]: loss 0.386676
[epoch3, step1023]: loss 0.346101
[epoch3, step1024]: loss 0.379963
[epoch3, step1025]: loss 0.405007
[epoch3, step1026]: loss 0.416929
[epoch3, step1027]: loss 0.373279
[epoch3, step1028]: loss 0.408793
[epoch3, step1029]: loss 0.367227
[epoch3, step1030]: loss 0.434209
[epoch3, step1031]: loss 0.405051
[epoch3, step1032]: loss 0.343359
[epoch3, step1033]: loss 0.402176
[epoch3, step1034]: loss 0.401208
[epoch3, step1035]: loss 0.417441
[epoch3, step1036]: loss 0.378571
[epoch3, step1037]: loss 0.412139
[epoch3, step1038]: loss 0.368481
[epoch3, step1039]: loss 0.426735
[epoch3, step1040]: loss 0.393556
[epoch3, step1041]: loss 0.349122
[epoch3, step1042]: loss 0.397619
[epoch3, step1043]: loss 0.398743
[epoch3, step1044]: loss 0.405543
[epoch3, step1045]: loss 0.372533
[epoch3, step1046]: loss 0.406735
[epoch3, step1047]: loss 0.363008
[epoch3, step1048]: loss 0.435595
[epoch3, step1049]: loss 0.385338
[epoch3, step1050]: loss 0.343756
[epoch3, step1051]: loss 0.390460
[epoch3, step1052]: loss 0.393542
[epoch3, step1053]: loss 0.407573
[epoch3, step1054]: loss 0.378024
[epoch3, step1055]: loss 0.414792
[epoch3, step1056]: loss 0.373717
[epoch3, step1057]: loss 0.419276
[epoch3, step1058]: loss 0.373801
[epoch3, step1059]: loss 0.343369
[epoch3, step1060]: loss 0.384593
[epoch3, step1061]: loss 0.407051
[epoch3, step1062]: loss 0.401509
[epoch3, step1063]: loss 0.376312
[epoch3, step1064]: loss 0.408386
[epoch3, step1065]: loss 0.371275
[epoch3, step1066]: loss 0.432842
[epoch3, step1067]: loss 0.384538
[epoch3, step1068]: loss 0.364250
[epoch3, step1069]: loss 0.386827
[epoch3, step1070]: loss 0.396182
[epoch3, step1071]: loss 0.398448
[epoch3, step1072]: loss 0.365061
[epoch3, step1073]: loss 0.409179
[epoch3, step1074]: loss 0.370785
[epoch3, step1075]: loss 0.422839
[epoch3, step1076]: loss 0.382244
[epoch3, step1077]: loss 0.343041
[epoch3, step1078]: loss 0.393779
[epoch3, step1079]: loss 0.383919
[epoch3, step1080]: loss 0.401792
[epoch3, step1081]: loss 0.380963
[epoch3, step1082]: loss 0.408992
[epoch3, step1083]: loss 0.360324
[epoch3, step1084]: loss 0.423414
[epoch3, step1085]: loss 0.390995
[epoch3, step1086]: loss 0.350049
[epoch3, step1087]: loss 0.390870
[epoch3, step1088]: loss 0.398980
[epoch3, step1089]: loss 0.400379
[epoch3, step1090]: loss 0.367350
[epoch3, step1091]: loss 0.403243
[epoch3, step1092]: loss 0.367628
[epoch3, step1093]: loss 0.425035
[epoch3, step1094]: loss 0.395878
[epoch3, step1095]: loss 0.345532
[epoch3, step1096]: loss 0.396870
[epoch3, step1097]: loss 0.393140
[epoch3, step1098]: loss 0.407183
[epoch3, step1099]: loss 0.378977
[epoch3, step1100]: loss 0.398417
[epoch3, step1101]: loss 0.367793
[epoch3, step1102]: loss 0.428505
[epoch3, step1103]: loss 0.389885
[epoch3, step1104]: loss 0.343337
[epoch3, step1105]: loss 0.385092
[epoch3, step1106]: loss 0.406454
[epoch3, step1107]: loss 0.403410
[epoch3, step1108]: loss 0.378864
[epoch3, step1109]: loss 0.399613
[epoch3, step1110]: loss 0.356952
[epoch3, step1111]: loss 0.422576
[epoch3, step1112]: loss 0.377864
[epoch3, step1113]: loss 0.344345
[epoch3, step1114]: loss 0.385879
[epoch3, step1115]: loss 0.390963
[epoch3, step1116]: loss 0.402430
[epoch3, step1117]: loss 0.371598
[epoch3, step1118]: loss 0.407203
[epoch3, step1119]: loss 0.372417
[epoch3, step1120]: loss 0.428141
[epoch3, step1121]: loss 0.384056
[epoch3, step1122]: loss 0.344995
[epoch3, step1123]: loss 0.395985
[epoch3, step1124]: loss 0.386647
[epoch3, step1125]: loss 0.399319
[epoch3, step1126]: loss 0.362883
[epoch3, step1127]: loss 0.402961
[epoch3, step1128]: loss 0.365742
[epoch3, step1129]: loss 0.426136
[epoch3, step1130]: loss 0.370446
[epoch3, step1131]: loss 0.337339
[epoch3, step1132]: loss 0.382597
[epoch3, step1133]: loss 0.399940
[epoch3, step1134]: loss 0.406007
[epoch3, step1135]: loss 0.357274
[epoch3, step1136]: loss 0.395140
[epoch3, step1137]: loss 0.359574
[epoch3, step1138]: loss 0.420448
[epoch3, step1139]: loss 0.384442
[epoch3, step1140]: loss 0.343141
[epoch3, step1141]: loss 0.384342
[epoch3, step1142]: loss 0.398251
[epoch3, step1143]: loss 0.408901
[epoch3, step1144]: loss 0.373430
[epoch3, step1145]: loss 0.410262
[epoch3, step1146]: loss 0.362662
[epoch3, step1147]: loss 0.411259
[epoch3, step1148]: loss 0.381745
[epoch3, step1149]: loss 0.341259
[epoch3, step1150]: loss 0.391872
[epoch3, step1151]: loss 0.390623
[epoch3, step1152]: loss 0.393933
[epoch3, step1153]: loss 0.376846
[epoch3, step1154]: loss 0.398428
[epoch3, step1155]: loss 0.359661
[epoch3, step1156]: loss 0.431704
[epoch3, step1157]: loss 0.385987
[epoch3, step1158]: loss 0.336331
[epoch3, step1159]: loss 0.382270
[epoch3, step1160]: loss 0.383707
[epoch3, step1161]: loss 0.394682
[epoch3, step1162]: loss 0.372333
[epoch3, step1163]: loss 0.411004
[epoch3, step1164]: loss 0.359408
[epoch3, step1165]: loss 0.407521
[epoch3, step1166]: loss 0.377557
[epoch3, step1167]: loss 0.343904
[epoch3, step1168]: loss 0.383257
[epoch3, step1169]: loss 0.394120
[epoch3, step1170]: loss 0.401104
[epoch3, step1171]: loss 0.372550
[epoch3, step1172]: loss 0.403465
[epoch3, step1173]: loss 0.361710
[epoch3, step1174]: loss 0.415662
[epoch3, step1175]: loss 0.383245
[epoch3, step1176]: loss 0.341876
[epoch3, step1177]: loss 0.378186
[epoch3, step1178]: loss 0.387719
[epoch3, step1179]: loss 0.402142
[epoch3, step1180]: loss 0.367644
[epoch3, step1181]: loss 0.394566
[epoch3, step1182]: loss 0.366152
[epoch3, step1183]: loss 0.412497
[epoch3, step1184]: loss 0.387601
[epoch3, step1185]: loss 0.342415
[epoch3, step1186]: loss 0.388465
[epoch3, step1187]: loss 0.402549
[epoch3, step1188]: loss 0.406392
[epoch3, step1189]: loss 0.370330
[epoch3, step1190]: loss 0.406353
[epoch3, step1191]: loss 0.358613
[epoch3, step1192]: loss 0.416163
[epoch3, step1193]: loss 0.378638
[epoch3, step1194]: loss 0.341185
[epoch3, step1195]: loss 0.400364
[epoch3, step1196]: loss 0.399433
[epoch3, step1197]: loss 0.397867
[epoch3, step1198]: loss 0.366890
[epoch3, step1199]: loss 0.404812
[epoch3, step1200]: loss 0.360946
[epoch3, step1201]: loss 0.413392
[epoch3, step1202]: loss 0.367789
[epoch3, step1203]: loss 0.343685
[epoch3, step1204]: loss 0.387832
[epoch3, step1205]: loss 0.393056
[epoch3, step1206]: loss 0.406047
[epoch3, step1207]: loss 0.360290
[epoch3, step1208]: loss 0.396900
[epoch3, step1209]: loss 0.367934
[epoch3, step1210]: loss 0.411722
[epoch3, step1211]: loss 0.385860
[epoch3, step1212]: loss 0.344063
[epoch3, step1213]: loss 0.391417
[epoch3, step1214]: loss 0.387371
[epoch3, step1215]: loss 0.390081
[epoch3, step1216]: loss 0.368554
[epoch3, step1217]: loss 0.392581
[epoch3, step1218]: loss 0.360061
[epoch3, step1219]: loss 0.410400
[epoch3, step1220]: loss 0.372552
[epoch3, step1221]: loss 0.345256
[epoch3, step1222]: loss 0.381991
[epoch3, step1223]: loss 0.389576
[epoch3, step1224]: loss 0.390600
[epoch3, step1225]: loss 0.367046
[epoch3, step1226]: loss 0.404950
[epoch3, step1227]: loss 0.355702
[epoch3, step1228]: loss 0.421313
[epoch3, step1229]: loss 0.384451
[epoch3, step1230]: loss 0.341601
[epoch3, step1231]: loss 0.387466
[epoch3, step1232]: loss 0.377596
[epoch3, step1233]: loss 0.399604
[epoch3, step1234]: loss 0.369173
[epoch3, step1235]: loss 0.393310
[epoch3, step1236]: loss 0.363485
[epoch3, step1237]: loss 0.423210
[epoch3, step1238]: loss 0.385779
[epoch3, step1239]: loss 0.332382
[epoch3, step1240]: loss 0.376626
[epoch3, step1241]: loss 0.397693
[epoch3, step1242]: loss 0.399054
[epoch3, step1243]: loss 0.363792
[epoch3, step1244]: loss 0.395488
[epoch3, step1245]: loss 0.351829
[epoch3, step1246]: loss 0.413673
[epoch3, step1247]: loss 0.388590
[epoch3, step1248]: loss 0.339675
[epoch3, step1249]: loss 0.375067
[epoch3, step1250]: loss 0.389604
[epoch3, step1251]: loss 0.394618
[epoch3, step1252]: loss 0.360969
[epoch3, step1253]: loss 0.394188
[epoch3, step1254]: loss 0.356394
[epoch3, step1255]: loss 0.415363
[epoch3, step1256]: loss 0.370460
[epoch3, step1257]: loss 0.334300
[epoch3, step1258]: loss 0.381426
[epoch3, step1259]: loss 0.390491
[epoch3, step1260]: loss 0.395465
[epoch3, step1261]: loss 0.368851
[epoch3, step1262]: loss 0.411113
[epoch3, step1263]: loss 0.347892
[epoch3, step1264]: loss 0.418746
[epoch3, step1265]: loss 0.393781
[epoch3, step1266]: loss 0.339520
[epoch3, step1267]: loss 0.380867
[epoch3, step1268]: loss 0.385243
[epoch3, step1269]: loss 0.393574
[epoch3, step1270]: loss 0.373266
[epoch3, step1271]: loss 0.391690
[epoch3, step1272]: loss 0.354547
[epoch3, step1273]: loss 0.419863
[epoch3, step1274]: loss 0.381677
[epoch3, step1275]: loss 0.336187
[epoch3, step1276]: loss 0.381566
[epoch3, step1277]: loss 0.388141
[epoch3, step1278]: loss 0.387366
[epoch3, step1279]: loss 0.362260
[epoch3, step1280]: loss 0.394226
[epoch3, step1281]: loss 0.357252
[epoch3, step1282]: loss 0.414392
[epoch3, step1283]: loss 0.383174
[epoch3, step1284]: loss 0.335365
[epoch3, step1285]: loss 0.377921
[epoch3, step1286]: loss 0.393686
[epoch3, step1287]: loss 0.384628
[epoch3, step1288]: loss 0.356330
[epoch3, step1289]: loss 0.384557
[epoch3, step1290]: loss 0.359316
[epoch3, step1291]: loss 0.417214
[epoch3, step1292]: loss 0.366010
[epoch3, step1293]: loss 0.339972
[epoch3, step1294]: loss 0.377499
[epoch3, step1295]: loss 0.379098
[epoch3, step1296]: loss 0.390809
[epoch3, step1297]: loss 0.360202
[epoch3, step1298]: loss 0.388025
[epoch3, step1299]: loss 0.355983
[epoch3, step1300]: loss 0.407267
[epoch3, step1301]: loss 0.388946
[epoch3, step1302]: loss 0.333759
[epoch3, step1303]: loss 0.382250
[epoch3, step1304]: loss 0.392882
[epoch3, step1305]: loss 0.386694
[epoch3, step1306]: loss 0.365260
[epoch3, step1307]: loss 0.402186
[epoch3, step1308]: loss 0.357123
[epoch3, step1309]: loss 0.421691
[epoch3, step1310]: loss 0.376217
[epoch3, step1311]: loss 0.343161
[epoch3, step1312]: loss 0.376090
[epoch3, step1313]: loss 0.383877
[epoch3, step1314]: loss 0.396254
[epoch3, step1315]: loss 0.364266
[epoch3, step1316]: loss 0.377338
[epoch3, step1317]: loss 0.360859
[epoch3, step1318]: loss 0.421052
[epoch3, step1319]: loss 0.379466
[epoch3, step1320]: loss 0.333778
[epoch3, step1321]: loss 0.370038
[epoch3, step1322]: loss 0.390172
[epoch3, step1323]: loss 0.387451
[epoch3, step1324]: loss 0.366713
[epoch3, step1325]: loss 0.394889
[epoch3, step1326]: loss 0.361231
[epoch3, step1327]: loss 0.412740
[epoch3, step1328]: loss 0.374532
[epoch3, step1329]: loss 0.335215
[epoch3, step1330]: loss 0.375911
[epoch3, step1331]: loss 0.389357
[epoch3, step1332]: loss 0.395477
[epoch3, step1333]: loss 0.376978
[epoch3, step1334]: loss 0.388649
[epoch3, step1335]: loss 0.352630
[epoch3, step1336]: loss 0.410400
[epoch3, step1337]: loss 0.383443
[epoch3, step1338]: loss 0.334688
[epoch3, step1339]: loss 0.381252
[epoch3, step1340]: loss 0.390506
[epoch3, step1341]: loss 0.391659
[epoch3, step1342]: loss 0.362791
[epoch3, step1343]: loss 0.389929
[epoch3, step1344]: loss 0.351030
[epoch3, step1345]: loss 0.410209
[epoch3, step1346]: loss 0.378737
[epoch3, step1347]: loss 0.327494
[epoch3, step1348]: loss 0.383151
[epoch3, step1349]: loss 0.383490
[epoch3, step1350]: loss 0.387503
[epoch3, step1351]: loss 0.372580
[epoch3, step1352]: loss 0.398447
[epoch3, step1353]: loss 0.361280
[epoch3, step1354]: loss 0.416609
[epoch3, step1355]: loss 0.372796
[epoch3, step1356]: loss 0.343093
[epoch3, step1357]: loss 0.385254
[epoch3, step1358]: loss 0.384809
[epoch3, step1359]: loss 0.395216
[epoch3, step1360]: loss 0.356275
[epoch3, step1361]: loss 0.388573
[epoch3, step1362]: loss 0.349925
[epoch3, step1363]: loss 0.402502
[epoch3, step1364]: loss 0.372779
[epoch3, step1365]: loss 0.334268
[epoch3, step1366]: loss 0.377126
[epoch3, step1367]: loss 0.391362
[epoch3, step1368]: loss 0.376724
[epoch3, step1369]: loss 0.362866
[epoch3, step1370]: loss 0.395373
[epoch3, step1371]: loss 0.349707
[epoch3, step1372]: loss 0.410241
[epoch3, step1373]: loss 0.372841
[epoch3, step1374]: loss 0.325019
[epoch3, step1375]: loss 0.369208
[epoch3, step1376]: loss 0.383551
[epoch3, step1377]: loss 0.401795
[epoch3, step1378]: loss 0.361584
[epoch3, step1379]: loss 0.396671
[epoch3, step1380]: loss 0.345034
[epoch3, step1381]: loss 0.408411
[epoch3, step1382]: loss 0.369874
[epoch3, step1383]: loss 0.333224
[epoch3, step1384]: loss 0.372624
[epoch3, step1385]: loss 0.387639
[epoch3, step1386]: loss 0.386441
[epoch3, step1387]: loss 0.351888
[epoch3, step1388]: loss 0.403749
[epoch3, step1389]: loss 0.358034
[epoch3, step1390]: loss 0.406750
[epoch3, step1391]: loss 0.373578
[epoch3, step1392]: loss 0.334903
[epoch3, step1393]: loss 0.369404
[epoch3, step1394]: loss 0.373959
[epoch3, step1395]: loss 0.386857
[epoch3, step1396]: loss 0.360442
[epoch3, step1397]: loss 0.393385
[epoch3, step1398]: loss 0.350197
[epoch3, step1399]: loss 0.395339
[epoch3, step1400]: loss 0.368485
[epoch3, step1401]: loss 0.329370
[epoch3, step1402]: loss 0.373455
[epoch3, step1403]: loss 0.392674
[epoch3, step1404]: loss 0.393386
[epoch3, step1405]: loss 0.354609
[epoch3, step1406]: loss 0.394015
[epoch3, step1407]: loss 0.340243
[epoch3, step1408]: loss 0.415758
[epoch3, step1409]: loss 0.376817
[epoch3, step1410]: loss 0.327818
[epoch3, step1411]: loss 0.387631
[epoch3, step1412]: loss 0.380064
[epoch3, step1413]: loss 0.388010
[epoch3, step1414]: loss 0.363846
[epoch3, step1415]: loss 0.393401
[epoch3, step1416]: loss 0.348410
[epoch3, step1417]: loss 0.409954
[epoch3, step1418]: loss 0.372127
[epoch3, step1419]: loss 0.323993
[epoch3, step1420]: loss 0.374258
[epoch3, step1421]: loss 0.375432
[epoch3, step1422]: loss 0.382930
[epoch3, step1423]: loss 0.362784
[epoch3, step1424]: loss 0.388426
[epoch3, step1425]: loss 0.356805
[epoch3, step1426]: loss 0.407061
[epoch3, step1427]: loss 0.361149
[epoch3, step1428]: loss 0.328547
[epoch3, step1429]: loss 0.370744
[epoch3, step1430]: loss 0.382907
[epoch3, step1431]: loss 0.385954
[epoch3, step1432]: loss 0.361024
[epoch3, step1433]: loss 0.387762
[epoch3, step1434]: loss 0.363056
[epoch3, step1435]: loss 0.400258
[epoch3, step1436]: loss 0.366239
[epoch3, step1437]: loss 0.326695
[epoch3, step1438]: loss 0.369667
[epoch3, step1439]: loss 0.383150
[epoch3, step1440]: loss 0.389553
[epoch3, step1441]: loss 0.350479
[epoch3, step1442]: loss 0.398850
[epoch3, step1443]: loss 0.360500
[epoch3, step1444]: loss 0.414449
[epoch3, step1445]: loss 0.365632
[epoch3, step1446]: loss 0.325019
[epoch3, step1447]: loss 0.367042
[epoch3, step1448]: loss 0.381461
[epoch3, step1449]: loss 0.391698
[epoch3, step1450]: loss 0.358420
[epoch3, step1451]: loss 0.384227
[epoch3, step1452]: loss 0.353214
[epoch3, step1453]: loss 0.393170
[epoch3, step1454]: loss 0.363961
[epoch3, step1455]: loss 0.319890
[epoch3, step1456]: loss 0.376712
[epoch3, step1457]: loss 0.370965
[epoch3, step1458]: loss 0.384848
[epoch3, step1459]: loss 0.362339
[epoch3, step1460]: loss 0.381930
[epoch3, step1461]: loss 0.342100
[epoch3, step1462]: loss 0.394727
[epoch3, step1463]: loss 0.371479
[epoch3, step1464]: loss 0.323372
[epoch3, step1465]: loss 0.379343
[epoch3, step1466]: loss 0.381446
[epoch3, step1467]: loss 0.390441
[epoch3, step1468]: loss 0.360866
[epoch3, step1469]: loss 0.388756
[epoch3, step1470]: loss 0.346715
[epoch3, step1471]: loss 0.411471
[epoch3, step1472]: loss 0.371739
[epoch3, step1473]: loss 0.325996
[epoch3, step1474]: loss 0.363979
[epoch3, step1475]: loss 0.381773
[epoch3, step1476]: loss 0.377357
[epoch3, step1477]: loss 0.363012
[epoch3, step1478]: loss 0.386411
[epoch3, step1479]: loss 0.348449
[epoch3, step1480]: loss 0.403811
[epoch3, step1481]: loss 0.381553
[epoch3, step1482]: loss 0.329072
[epoch3, step1483]: loss 0.371460
[epoch3, step1484]: loss 0.375142
[epoch3, step1485]: loss 0.384584
[epoch3, step1486]: loss 0.367650
[epoch3, step1487]: loss 0.388244
[epoch3, step1488]: loss 0.345568
[epoch3, step1489]: loss 0.405869
[epoch3, step1490]: loss 0.365785
[epoch3, step1491]: loss 0.329239
[epoch3, step1492]: loss 0.377837
[epoch3, step1493]: loss 0.379569
[epoch3, step1494]: loss 0.383871
[epoch3, step1495]: loss 0.365113
[epoch3, step1496]: loss 0.396847
[epoch3, step1497]: loss 0.344476
[epoch3, step1498]: loss 0.397384
[epoch3, step1499]: loss 0.375964
[epoch3, step1500]: loss 0.326884
[epoch3, step1501]: loss 0.370787
[epoch3, step1502]: loss 0.378992
[epoch3, step1503]: loss 0.387758
[epoch3, step1504]: loss 0.364009
[epoch3, step1505]: loss 0.383160
[epoch3, step1506]: loss 0.351817
[epoch3, step1507]: loss 0.398268
[epoch3, step1508]: loss 0.362193
[epoch3, step1509]: loss 0.332071
[epoch3, step1510]: loss 0.384280
[epoch3, step1511]: loss 0.368892
[epoch3, step1512]: loss 0.380402
[epoch3, step1513]: loss 0.371350
[epoch3, step1514]: loss 0.386848
[epoch3, step1515]: loss 0.345629
[epoch3, step1516]: loss 0.402283

[epoch3]: avg loss 0.398168

[epoch4, step1]: loss 0.374193
[epoch4, step2]: loss 0.379920
[epoch4, step3]: loss 0.385460
[epoch4, step4]: loss 0.360359
[epoch4, step5]: loss 0.402300
[epoch4, step6]: loss 0.367892
[epoch4, step7]: loss 0.336866
[epoch4, step8]: loss 0.386697
[epoch4, step9]: loss 0.346809
[epoch4, step10]: loss 0.388416
[epoch4, step11]: loss 0.378021
[epoch4, step12]: loss 0.382078
[epoch4, step13]: loss 0.345257
[epoch4, step14]: loss 0.401338
[epoch4, step15]: loss 0.368444
[epoch4, step16]: loss 0.338451
[epoch4, step17]: loss 0.381485
[epoch4, step18]: loss 0.332951
[epoch4, step19]: loss 0.394805
[epoch4, step20]: loss 0.366075
[epoch4, step21]: loss 0.383296
[epoch4, step22]: loss 0.353819
[epoch4, step23]: loss 0.416101
[epoch4, step24]: loss 0.364022
[epoch4, step25]: loss 0.340871
[epoch4, step26]: loss 0.394825
[epoch4, step27]: loss 0.346850
[epoch4, step28]: loss 0.392725
[epoch4, step29]: loss 0.373415
[epoch4, step30]: loss 0.372437
[epoch4, step31]: loss 0.350676
[epoch4, step32]: loss 0.397525
[epoch4, step33]: loss 0.358948
[epoch4, step34]: loss 0.333233
[epoch4, step35]: loss 0.382707
[epoch4, step36]: loss 0.345836
[epoch4, step37]: loss 0.395283
[epoch4, step38]: loss 0.377794
[epoch4, step39]: loss 0.381047
[epoch4, step40]: loss 0.342529
[epoch4, step41]: loss 0.410450
[epoch4, step42]: loss 0.361194
[epoch4, step43]: loss 0.341843
[epoch4, step44]: loss 0.383185
[epoch4, step45]: loss 0.344553
[epoch4, step46]: loss 0.395199
[epoch4, step47]: loss 0.381513
[epoch4, step48]: loss 0.384159
[epoch4, step49]: loss 0.358619
[epoch4, step50]: loss 0.402119
[epoch4, step51]: loss 0.366499
[epoch4, step52]: loss 0.342661
[epoch4, step53]: loss 0.376839
[epoch4, step54]: loss 0.340772
[epoch4, step55]: loss 0.389019
[epoch4, step56]: loss 0.361178
[epoch4, step57]: loss 0.374305
[epoch4, step58]: loss 0.344483
[epoch4, step59]: loss 0.415449
[epoch4, step60]: loss 0.356792
[epoch4, step61]: loss 0.344869
[epoch4, step62]: loss 0.390983
[epoch4, step63]: loss 0.350980
[epoch4, step64]: loss 0.403477
[epoch4, step65]: loss 0.371212
[epoch4, step66]: loss 0.379250
[epoch4, step67]: loss 0.348121
[epoch4, step68]: loss 0.403277
[epoch4, step69]: loss 0.364570
[epoch4, step70]: loss 0.341163
[epoch4, step71]: loss 0.389934
[epoch4, step72]: loss 0.340541
[epoch4, step73]: loss 0.396179
[epoch4, step74]: loss 0.371253
[epoch4, step75]: loss 0.375780
[epoch4, step76]: loss 0.344416
[epoch4, step77]: loss 0.393223
[epoch4, step78]: loss 0.360714
[epoch4, step79]: loss 0.344062
[epoch4, step80]: loss 0.373190
[epoch4, step81]: loss 0.337488
[epoch4, step82]: loss 0.400868
[epoch4, step83]: loss 0.383195
[epoch4, step84]: loss 0.376006
[epoch4, step85]: loss 0.338804
[epoch4, step86]: loss 0.396560
[epoch4, step87]: loss 0.351672
[epoch4, step88]: loss 0.359844
[epoch4, step89]: loss 0.388976
[epoch4, step90]: loss 0.343242
[epoch4, step91]: loss 0.406091
[epoch4, step92]: loss 0.370394
[epoch4, step93]: loss 0.375554
[epoch4, step94]: loss 0.350115
[epoch4, step95]: loss 0.394343
[epoch4, step96]: loss 0.365382
[epoch4, step97]: loss 0.332308
[epoch4, step98]: loss 0.383196
[epoch4, step99]: loss 0.342359
[epoch4, step100]: loss 0.405503
[epoch4, step101]: loss 0.363310
[epoch4, step102]: loss 0.378806
[epoch4, step103]: loss 0.347975
[epoch4, step104]: loss 0.400193
[epoch4, step105]: loss 0.356793
[epoch4, step106]: loss 0.340089
[epoch4, step107]: loss 0.383946
[epoch4, step108]: loss 0.337977
[epoch4, step109]: loss 0.396701
[epoch4, step110]: loss 0.363451
[epoch4, step111]: loss 0.378852
[epoch4, step112]: loss 0.348668
[epoch4, step113]: loss 0.388729
[epoch4, step114]: loss 0.363876
[epoch4, step115]: loss 0.338802
[epoch4, step116]: loss 0.372752
[epoch4, step117]: loss 0.338253
[epoch4, step118]: loss 0.382599
[epoch4, step119]: loss 0.365097
[epoch4, step120]: loss 0.372470
[epoch4, step121]: loss 0.347550
[epoch4, step122]: loss 0.398687
[epoch4, step123]: loss 0.355978
[epoch4, step124]: loss 0.337648
[epoch4, step125]: loss 0.375441
[epoch4, step126]: loss 0.342038
[epoch4, step127]: loss 0.394996
[epoch4, step128]: loss 0.371394
[epoch4, step129]: loss 0.375177
[epoch4, step130]: loss 0.339889
[epoch4, step131]: loss 0.405350
[epoch4, step132]: loss 0.357886
[epoch4, step133]: loss 0.336306
[epoch4, step134]: loss 0.389037
[epoch4, step135]: loss 0.333469
[epoch4, step136]: loss 0.376610
[epoch4, step137]: loss 0.373199
[epoch4, step138]: loss 0.375465
[epoch4, step139]: loss 0.343650
[epoch4, step140]: loss 0.391561
[epoch4, step141]: loss 0.355613
[epoch4, step142]: loss 0.336391
[epoch4, step143]: loss 0.385673
[epoch4, step144]: loss 0.343989
[epoch4, step145]: loss 0.391781
[epoch4, step146]: loss 0.369149
[epoch4, step147]: loss 0.359353
[epoch4, step148]: loss 0.342373
[epoch4, step149]: loss 0.404285
[epoch4, step150]: loss 0.363557
[epoch4, step151]: loss 0.331299
[epoch4, step152]: loss 0.379844
[epoch4, step153]: loss 0.334120
[epoch4, step154]: loss 0.398126
[epoch4, step155]: loss 0.367699
[epoch4, step156]: loss 0.379735
[epoch4, step157]: loss 0.339269
[epoch4, step158]: loss 0.392029
[epoch4, step159]: loss 0.355906
[epoch4, step160]: loss 0.331142
[epoch4, step161]: loss 0.371480
[epoch4, step162]: loss 0.334656
[epoch4, step163]: loss 0.391907
[epoch4, step164]: loss 0.362289
[epoch4, step165]: loss 0.372786
[epoch4, step166]: loss 0.335919
[epoch4, step167]: loss 0.401350
[epoch4, step168]: loss 0.348139
[epoch4, step169]: loss 0.339190
[epoch4, step170]: loss 0.374649
[epoch4, step171]: loss 0.333917
[epoch4, step172]: loss 0.389009
[epoch4, step173]: loss 0.363310
[epoch4, step174]: loss 0.375909
[epoch4, step175]: loss 0.330366
[epoch4, step176]: loss 0.393414
[epoch4, step177]: loss 0.352889
[epoch4, step178]: loss 0.327340
[epoch4, step179]: loss 0.387771
[epoch4, step180]: loss 0.328011
[epoch4, step181]: loss 0.386225
[epoch4, step182]: loss 0.361604
[epoch4, step183]: loss 0.364261
[epoch4, step184]: loss 0.329940
[epoch4, step185]: loss 0.392035
[epoch4, step186]: loss 0.352326
[epoch4, step187]: loss 0.335110
[epoch4, step188]: loss 0.380248
[epoch4, step189]: loss 0.331334
[epoch4, step190]: loss 0.396515
[epoch4, step191]: loss 0.367833
[epoch4, step192]: loss 0.364118
[epoch4, step193]: loss 0.359995
[epoch4, step194]: loss 0.403800
[epoch4, step195]: loss 0.351334
[epoch4, step196]: loss 0.330094
[epoch4, step197]: loss 0.378861
[epoch4, step198]: loss 0.342311
[epoch4, step199]: loss 0.387190
[epoch4, step200]: loss 0.357058
[epoch4, step201]: loss 0.364303
[epoch4, step202]: loss 0.341085
[epoch4, step203]: loss 0.393733
[epoch4, step204]: loss 0.349084
[epoch4, step205]: loss 0.340926
[epoch4, step206]: loss 0.380250
[epoch4, step207]: loss 0.332508
[epoch4, step208]: loss 0.380874
[epoch4, step209]: loss 0.359713
[epoch4, step210]: loss 0.359151
[epoch4, step211]: loss 0.335875
[epoch4, step212]: loss 0.389446
[epoch4, step213]: loss 0.357784
[epoch4, step214]: loss 0.343129
[epoch4, step215]: loss 0.373343
[epoch4, step216]: loss 0.331153
[epoch4, step217]: loss 0.397425
[epoch4, step218]: loss 0.358838
[epoch4, step219]: loss 0.372279
[epoch4, step220]: loss 0.342465
[epoch4, step221]: loss 0.389135
[epoch4, step222]: loss 0.348953
[epoch4, step223]: loss 0.324219
[epoch4, step224]: loss 0.379281
[epoch4, step225]: loss 0.331347
[epoch4, step226]: loss 0.391282
[epoch4, step227]: loss 0.374371
[epoch4, step228]: loss 0.362274
[epoch4, step229]: loss 0.347256
[epoch4, step230]: loss 0.386825
[epoch4, step231]: loss 0.347096
[epoch4, step232]: loss 0.335178
[epoch4, step233]: loss 0.384479
[epoch4, step234]: loss 0.337446
[epoch4, step235]: loss 0.387016
[epoch4, step236]: loss 0.361192
[epoch4, step237]: loss 0.368212
[epoch4, step238]: loss 0.337438
[epoch4, step239]: loss 0.399558
[epoch4, step240]: loss 0.362848
[epoch4, step241]: loss 0.328414
[epoch4, step242]: loss 0.377112
[epoch4, step243]: loss 0.328999
[epoch4, step244]: loss 0.389284
[epoch4, step245]: loss 0.367537
[epoch4, step246]: loss 0.368716
[epoch4, step247]: loss 0.337249
[epoch4, step248]: loss 0.395427
[epoch4, step249]: loss 0.358538
[epoch4, step250]: loss 0.329389
[epoch4, step251]: loss 0.367672
[epoch4, step252]: loss 0.326554
[epoch4, step253]: loss 0.392448
[epoch4, step254]: loss 0.370760
[epoch4, step255]: loss 0.364912
[epoch4, step256]: loss 0.343250
[epoch4, step257]: loss 0.393249
[epoch4, step258]: loss 0.345057
[epoch4, step259]: loss 0.327256
[epoch4, step260]: loss 0.381223
[epoch4, step261]: loss 0.320817
[epoch4, step262]: loss 0.379550
[epoch4, step263]: loss 0.370852
[epoch4, step264]: loss 0.370101
[epoch4, step265]: loss 0.337072
[epoch4, step266]: loss 0.391440
[epoch4, step267]: loss 0.361737
[epoch4, step268]: loss 0.329873
[epoch4, step269]: loss 0.372472
[epoch4, step270]: loss 0.334585
[epoch4, step271]: loss 0.382896
[epoch4, step272]: loss 0.362096
[epoch4, step273]: loss 0.370040
[epoch4, step274]: loss 0.329153
[epoch4, step275]: loss 0.397928
[epoch4, step276]: loss 0.357800
[epoch4, step277]: loss 0.325847
[epoch4, step278]: loss 0.371102
[epoch4, step279]: loss 0.328464
[epoch4, step280]: loss 0.382604
[epoch4, step281]: loss 0.363717
[epoch4, step282]: loss 0.360051
[epoch4, step283]: loss 0.341024
[epoch4, step284]: loss 0.395467
[epoch4, step285]: loss 0.342138
[epoch4, step286]: loss 0.347489
[epoch4, step287]: loss 0.370913
[epoch4, step288]: loss 0.335739
[epoch4, step289]: loss 0.378410
[epoch4, step290]: loss 0.360849
[epoch4, step291]: loss 0.362655
[epoch4, step292]: loss 0.344306
[epoch4, step293]: loss 0.392185
[epoch4, step294]: loss 0.357175
[epoch4, step295]: loss 0.333189
[epoch4, step296]: loss 0.363850
[epoch4, step297]: loss 0.334278
[epoch4, step298]: loss 0.382193
[epoch4, step299]: loss 0.370720
[epoch4, step300]: loss 0.361306
[epoch4, step301]: loss 0.340708
[epoch4, step302]: loss 0.383909
[epoch4, step303]: loss 0.345989
[epoch4, step304]: loss 0.328477
[epoch4, step305]: loss 0.376300
[epoch4, step306]: loss 0.329446
[epoch4, step307]: loss 0.389538
[epoch4, step308]: loss 0.353837
[epoch4, step309]: loss 0.359538
[epoch4, step310]: loss 0.335990
[epoch4, step311]: loss 0.382905
[epoch4, step312]: loss 0.353485
[epoch4, step313]: loss 0.328779
[epoch4, step314]: loss 0.371181
[epoch4, step315]: loss 0.323948
[epoch4, step316]: loss 0.387091
[epoch4, step317]: loss 0.357308
[epoch4, step318]: loss 0.363993
[epoch4, step319]: loss 0.342297
[epoch4, step320]: loss 0.399864
[epoch4, step321]: loss 0.354783
[epoch4, step322]: loss 0.337668
[epoch4, step323]: loss 0.379359
[epoch4, step324]: loss 0.322584
[epoch4, step325]: loss 0.381432
[epoch4, step326]: loss 0.362403
[epoch4, step327]: loss 0.372002
[epoch4, step328]: loss 0.336066
[epoch4, step329]: loss 0.392384
[epoch4, step330]: loss 0.357789
[epoch4, step331]: loss 0.330908
[epoch4, step332]: loss 0.377989
[epoch4, step333]: loss 0.332827
[epoch4, step334]: loss 0.380558
[epoch4, step335]: loss 0.358103
[epoch4, step336]: loss 0.354566
[epoch4, step337]: loss 0.329538
[epoch4, step338]: loss 0.393987
[epoch4, step339]: loss 0.352989
[epoch4, step340]: loss 0.328326
[epoch4, step341]: loss 0.376169
[epoch4, step342]: loss 0.329044
[epoch4, step343]: loss 0.379022
[epoch4, step344]: loss 0.361987
[epoch4, step345]: loss 0.371612
[epoch4, step346]: loss 0.339980
[epoch4, step347]: loss 0.391513
[epoch4, step348]: loss 0.346629
[epoch4, step349]: loss 0.323478
[epoch4, step350]: loss 0.376792
[epoch4, step351]: loss 0.332203
[epoch4, step352]: loss 0.382242
[epoch4, step353]: loss 0.360001
[epoch4, step354]: loss 0.375542
[epoch4, step355]: loss 0.342314
[epoch4, step356]: loss 0.379660
[epoch4, step357]: loss 0.348075
[epoch4, step358]: loss 0.343821
[epoch4, step359]: loss 0.360948
[epoch4, step360]: loss 0.331994
[epoch4, step361]: loss 0.387646
[epoch4, step362]: loss 0.352206
[epoch4, step363]: loss 0.367138
[epoch4, step364]: loss 0.335821
[epoch4, step365]: loss 0.388923
[epoch4, step366]: loss 0.344839
[epoch4, step367]: loss 0.331280
[epoch4, step368]: loss 0.376516
[epoch4, step369]: loss 0.330889
[epoch4, step370]: loss 0.374930
[epoch4, step371]: loss 0.348038
[epoch4, step372]: loss 0.367049
[epoch4, step373]: loss 0.335603
[epoch4, step374]: loss 0.393844
[epoch4, step375]: loss 0.340928
[epoch4, step376]: loss 0.321075
[epoch4, step377]: loss 0.367127
[epoch4, step378]: loss 0.327319
[epoch4, step379]: loss 0.373987
[epoch4, step380]: loss 0.351232
[epoch4, step381]: loss 0.366107
[epoch4, step382]: loss 0.340076
[epoch4, step383]: loss 0.398926
[epoch4, step384]: loss 0.356086
[epoch4, step385]: loss 0.322355
[epoch4, step386]: loss 0.366921
[epoch4, step387]: loss 0.323266
[epoch4, step388]: loss 0.370693
[epoch4, step389]: loss 0.356718
[epoch4, step390]: loss 0.350004
[epoch4, step391]: loss 0.334010
[epoch4, step392]: loss 0.377629
[epoch4, step393]: loss 0.353124
[epoch4, step394]: loss 0.330903
[epoch4, step395]: loss 0.371691
[epoch4, step396]: loss 0.324649
[epoch4, step397]: loss 0.386846
[epoch4, step398]: loss 0.355005
[epoch4, step399]: loss 0.362518
[epoch4, step400]: loss 0.332362
[epoch4, step401]: loss 0.386861
[epoch4, step402]: loss 0.349792
[epoch4, step403]: loss 0.323965
[epoch4, step404]: loss 0.365158
[epoch4, step405]: loss 0.321809
[epoch4, step406]: loss 0.374383
[epoch4, step407]: loss 0.359189
[epoch4, step408]: loss 0.360183
[epoch4, step409]: loss 0.315934
[epoch4, step410]: loss 0.377307
[epoch4, step411]: loss 0.347327
[epoch4, step412]: loss 0.327300
[epoch4, step413]: loss 0.368314
[epoch4, step414]: loss 0.334741
[epoch4, step415]: loss 0.376945
[epoch4, step416]: loss 0.362613
[epoch4, step417]: loss 0.358362
[epoch4, step418]: loss 0.330522
[epoch4, step419]: loss 0.391937
[epoch4, step420]: loss 0.342406
[epoch4, step421]: loss 0.326797
[epoch4, step422]: loss 0.367234
[epoch4, step423]: loss 0.324384
[epoch4, step424]: loss 0.375028
[epoch4, step425]: loss 0.353095
[epoch4, step426]: loss 0.356210
[epoch4, step427]: loss 0.334639
[epoch4, step428]: loss 0.385025
[epoch4, step429]: loss 0.336090
[epoch4, step430]: loss 0.324928
[epoch4, step431]: loss 0.362771
[epoch4, step432]: loss 0.323066
[epoch4, step433]: loss 0.367261
[epoch4, step434]: loss 0.355746
[epoch4, step435]: loss 0.355256
[epoch4, step436]: loss 0.339402
[epoch4, step437]: loss 0.380918
[epoch4, step438]: loss 0.337001
[epoch4, step439]: loss 0.325917
[epoch4, step440]: loss 0.366229
[epoch4, step441]: loss 0.320242
[epoch4, step442]: loss 0.376756
[epoch4, step443]: loss 0.348071
[epoch4, step444]: loss 0.364144
[epoch4, step445]: loss 0.327591
[epoch4, step446]: loss 0.378126
[epoch4, step447]: loss 0.337291
[epoch4, step448]: loss 0.319148
[epoch4, step449]: loss 0.368158
[epoch4, step450]: loss 0.332699
[epoch4, step451]: loss 0.378502
[epoch4, step452]: loss 0.366876
[epoch4, step453]: loss 0.356731
[epoch4, step454]: loss 0.333621
[epoch4, step455]: loss 0.379492
[epoch4, step456]: loss 0.353006
[epoch4, step457]: loss 0.318930
[epoch4, step458]: loss 0.368217
[epoch4, step459]: loss 0.315690
[epoch4, step460]: loss 0.377395
[epoch4, step461]: loss 0.345272
[epoch4, step462]: loss 0.366177
[epoch4, step463]: loss 0.329435
[epoch4, step464]: loss 0.383677
[epoch4, step465]: loss 0.328155
[epoch4, step466]: loss 0.320966
[epoch4, step467]: loss 0.368786
[epoch4, step468]: loss 0.326028
[epoch4, step469]: loss 0.374386
[epoch4, step470]: loss 0.350252
[epoch4, step471]: loss 0.362223
[epoch4, step472]: loss 0.330676
[epoch4, step473]: loss 0.385642
[epoch4, step474]: loss 0.346264
[epoch4, step475]: loss 0.322032
[epoch4, step476]: loss 0.359045
[epoch4, step477]: loss 0.323968
[epoch4, step478]: loss 0.380592
[epoch4, step479]: loss 0.352923
[epoch4, step480]: loss 0.367178
[epoch4, step481]: loss 0.332096
[epoch4, step482]: loss 0.388274
[epoch4, step483]: loss 0.337900
[epoch4, step484]: loss 0.313602
[epoch4, step485]: loss 0.362545
[epoch4, step486]: loss 0.318816
[epoch4, step487]: loss 0.381356
[epoch4, step488]: loss 0.348036
[epoch4, step489]: loss 0.366789
[epoch4, step490]: loss 0.328470
[epoch4, step491]: loss 0.376697
[epoch4, step492]: loss 0.345198
[epoch4, step493]: loss 0.320922
[epoch4, step494]: loss 0.370632
[epoch4, step495]: loss 0.307479
[epoch4, step496]: loss 0.376331
[epoch4, step497]: loss 0.349486
[epoch4, step498]: loss 0.357453
[epoch4, step499]: loss 0.328344
[epoch4, step500]: loss 0.385625
[epoch4, step501]: loss 0.349173
[epoch4, step502]: loss 0.321638
[epoch4, step503]: loss 0.361434
[epoch4, step504]: loss 0.330975
[epoch4, step505]: loss 0.385587
[epoch4, step506]: loss 0.344029
[epoch4, step507]: loss 0.352210
[epoch4, step508]: loss 0.324290
[epoch4, step509]: loss 0.382871
[epoch4, step510]: loss 0.340604
[epoch4, step511]: loss 0.323872
[epoch4, step512]: loss 0.358636
[epoch4, step513]: loss 0.322358
[epoch4, step514]: loss 0.371401
[epoch4, step515]: loss 0.350843
[epoch4, step516]: loss 0.351163
[epoch4, step517]: loss 0.330359
[epoch4, step518]: loss 0.378452
[epoch4, step519]: loss 0.340567
[epoch4, step520]: loss 0.320223
[epoch4, step521]: loss 0.367055
[epoch4, step522]: loss 0.325004
[epoch4, step523]: loss 0.373395
[epoch4, step524]: loss 0.359373
[epoch4, step525]: loss 0.351456
[epoch4, step526]: loss 0.320994
[epoch4, step527]: loss 0.383642
[epoch4, step528]: loss 0.337351
[epoch4, step529]: loss 0.326464
[epoch4, step530]: loss 0.358508
[epoch4, step531]: loss 0.320873
[epoch4, step532]: loss 0.378328
[epoch4, step533]: loss 0.338508
[epoch4, step534]: loss 0.356115
[epoch4, step535]: loss 0.324356
[epoch4, step536]: loss 0.376217
[epoch4, step537]: loss 0.338878
[epoch4, step538]: loss 0.325640
[epoch4, step539]: loss 0.364091
[epoch4, step540]: loss 0.330846
[epoch4, step541]: loss 0.378238
[epoch4, step542]: loss 0.350570
[epoch4, step543]: loss 0.356718
[epoch4, step544]: loss 0.321024
[epoch4, step545]: loss 0.388056
[epoch4, step546]: loss 0.334496
[epoch4, step547]: loss 0.327898
[epoch4, step548]: loss 0.363313
[epoch4, step549]: loss 0.318558
[epoch4, step550]: loss 0.371377
[epoch4, step551]: loss 0.349812
[epoch4, step552]: loss 0.360092
[epoch4, step553]: loss 0.323982
[epoch4, step554]: loss 0.381844
[epoch4, step555]: loss 0.344838
[epoch4, step556]: loss 0.317078
[epoch4, step557]: loss 0.367317
[epoch4, step558]: loss 0.317805
[epoch4, step559]: loss 0.378133
[epoch4, step560]: loss 0.347683
[epoch4, step561]: loss 0.356374
[epoch4, step562]: loss 0.322669
[epoch4, step563]: loss 0.449462
[epoch4, step564]: loss 0.338991
[epoch4, step565]: loss 0.266168
[epoch4, step566]: loss 0.280712
[epoch4, step567]: loss 0.276333
[epoch4, step568]: loss 0.314927
[epoch4, step569]: loss 0.375892
[epoch4, step570]: loss 0.316138
[epoch4, step571]: loss 0.221505
[epoch4, step572]: loss 0.313313
[epoch4, step573]: loss 0.325904
[epoch4, step574]: loss 0.401872
[epoch4, step575]: loss 0.349641
[epoch4, step576]: loss 0.359053
[epoch4, step577]: loss 0.300994
[epoch4, step578]: loss 0.360690
[epoch4, step579]: loss 0.281854
[epoch4, step580]: loss 0.408927
[epoch4, step581]: loss 0.355442
[epoch4, step582]: loss 0.345331
[epoch4, step583]: loss 0.352292
[epoch4, step584]: loss 0.327248
[epoch4, step585]: loss 0.389213
[epoch4, step586]: loss 0.344582
[epoch4, step587]: loss 0.241891
[epoch4, step588]: loss 0.346754
[epoch4, step589]: loss 0.457626
[epoch4, step590]: loss 0.258934
[epoch4, step591]: loss 0.337934
[epoch4, step592]: loss 0.370282
[epoch4, step593]: loss 0.451339
[epoch4, step594]: loss 0.264824
[epoch4, step595]: loss 0.265810
[epoch4, step596]: loss 0.377703
[epoch4, step597]: loss 0.389463
[epoch4, step598]: loss 0.284854
[epoch4, step599]: loss 0.264899
[epoch4, step600]: loss 0.256089
[epoch4, step601]: loss 0.340783
[epoch4, step602]: loss 0.407224
[epoch4, step603]: loss 0.296533
[epoch4, step604]: loss 0.289923
[epoch4, step605]: loss 0.256083
[epoch4, step606]: loss 0.327189
[epoch4, step607]: loss 0.358468
[epoch4, step608]: loss 0.221991
[epoch4, step609]: loss 0.337658
[epoch4, step610]: loss 0.296439
[epoch4, step611]: loss 0.373290
[epoch4, step612]: loss 0.340428
[epoch4, step613]: loss 0.379445
[epoch4, step614]: loss 0.329289
[epoch4, step615]: loss 0.337544
[epoch4, step616]: loss 0.269012
[epoch4, step617]: loss 0.311676
[epoch4, step618]: loss 0.367398
[epoch4, step619]: loss 0.274731
[epoch4, step620]: loss 0.254952
[epoch4, step621]: loss 0.247116
[epoch4, step622]: loss 0.360869
[epoch4, step623]: loss 0.345616
[epoch4, step624]: loss 0.344981
[epoch4, step625]: loss 0.252303
[epoch4, step626]: loss 0.345537
[epoch4, step627]: loss 0.403150
[epoch4, step628]: loss 0.365596
[epoch4, step629]: loss 0.199702
[epoch4, step630]: loss 0.287727
[epoch4, step631]: loss 0.281148
[epoch4, step632]: loss 0.347429
[epoch4, step633]: loss 0.281779
[epoch4, step634]: loss 0.325066
[epoch4, step635]: loss 0.310772
[epoch4, step636]: loss 0.274496
[epoch4, step637]: loss 0.365622
[epoch4, step638]: loss 0.336668
[epoch4, step639]: loss 0.259795
[epoch4, step640]: loss 0.347289
[epoch4, step641]: loss 0.265158
[epoch4, step642]: loss 0.261593
[epoch4, step643]: loss 0.353068
[epoch4, step644]: loss 0.307905
[epoch4, step645]: loss 0.237123
[epoch4, step646]: loss 0.318151
[epoch4, step647]: loss 0.244509
[epoch4, step648]: loss 0.402878
[epoch4, step649]: loss 0.338262
[epoch4, step650]: loss 0.367212
[epoch4, step651]: loss 0.302694
[epoch4, step652]: loss 0.383955
[epoch4, step653]: loss 0.368336
[epoch4, step654]: loss 0.357519
[epoch4, step655]: loss 0.268856
[epoch4, step656]: loss 0.377800
[epoch4, step657]: loss 0.369813
[epoch4, step658]: loss 0.284845
[epoch4, step659]: loss 0.242284
[epoch4, step660]: loss 0.321238
[epoch4, step661]: loss 0.342558
[epoch4, step662]: loss 0.247868
[epoch4, step663]: loss 0.315764
[epoch4, step664]: loss 0.302331
[epoch4, step665]: loss 0.386829
[epoch4, step666]: loss 0.255781
[epoch4, step667]: loss 0.338835
[epoch4, step668]: loss 0.396439
[epoch4, step669]: loss 0.259949
[epoch4, step670]: loss 0.326425
[epoch4, step671]: loss 0.340255
[epoch4, step672]: loss 0.410368
[epoch4, step673]: loss 0.378307
[epoch4, step674]: loss 0.312735
[epoch4, step675]: loss 0.365212
[epoch4, step676]: loss 0.350662
[epoch4, step677]: loss 0.297195
[epoch4, step678]: loss 0.257095
[epoch4, step679]: loss 0.316808
[epoch4, step680]: loss 0.249204
[epoch4, step681]: loss 0.261402
[epoch4, step682]: loss 0.267052
[epoch4, step683]: loss 0.324102
[epoch4, step684]: loss 0.267159
[epoch4, step685]: loss 0.269439
[epoch4, step686]: loss 0.256461
[epoch4, step687]: loss 0.282816
[epoch4, step688]: loss 0.350488
[epoch4, step689]: loss 0.268942
[epoch4, step690]: loss 0.362617
[epoch4, step691]: loss 0.378553
[epoch4, step692]: loss 0.365949
[epoch4, step693]: loss 0.330336
[epoch4, step694]: loss 0.248912
[epoch4, step695]: loss 0.291029
[epoch4, step696]: loss 0.267299
[epoch4, step697]: loss 0.329911
[epoch4, step698]: loss 0.294194
[epoch4, step699]: loss 0.300983
[epoch4, step700]: loss 0.405710
[epoch4, step701]: loss 0.344464
[epoch4, step702]: loss 0.294587
[epoch4, step703]: loss 0.395310
[epoch4, step704]: loss 0.362638
[epoch4, step705]: loss 0.270525
[epoch4, step706]: loss 0.281120
[epoch4, step707]: loss 0.291293
[epoch4, step708]: loss 0.321434
[epoch4, step709]: loss 0.275390
[epoch4, step710]: loss 0.331784
[epoch4, step711]: loss 0.365381
[epoch4, step712]: loss 0.244357
[epoch4, step713]: loss 0.286285
[epoch4, step714]: loss 0.346155
[epoch4, step715]: loss 0.282623
[epoch4, step716]: loss 0.329795
[epoch4, step717]: loss 0.275938
[epoch4, step718]: loss 0.308124
[epoch4, step719]: loss 0.307410
[epoch4, step720]: loss 0.273296
[epoch4, step721]: loss 0.303457
[epoch4, step722]: loss 0.316146
[epoch4, step723]: loss 0.306206
[epoch4, step724]: loss 0.336108
[epoch4, step725]: loss 0.329734
[epoch4, step726]: loss 0.230290
[epoch4, step727]: loss 0.325893
[epoch4, step728]: loss 0.331858
[epoch4, step729]: loss 0.267168
[epoch4, step730]: loss 0.332822
[epoch4, step731]: loss 0.360815
[epoch4, step732]: loss 0.300752
[epoch4, step733]: loss 0.243720
[epoch4, step734]: loss 0.279825
[epoch4, step735]: loss 0.274415
[epoch4, step736]: loss 0.294592
[epoch4, step737]: loss 0.256949
[epoch4, step738]: loss 0.282195
[epoch4, step739]: loss 0.396563
[epoch4, step740]: loss 0.427124
[epoch4, step741]: loss 0.322019
[epoch4, step742]: loss 0.373319
[epoch4, step743]: loss 0.316623
[epoch4, step744]: loss 0.306590
[epoch4, step745]: loss 0.311039
[epoch4, step746]: loss 0.337830
[epoch4, step747]: loss 0.300179
[epoch4, step748]: loss 0.269526
[epoch4, step749]: loss 0.399521
[epoch4, step750]: loss 0.334140
[epoch4, step751]: loss 0.295306
[epoch4, step752]: loss 0.259850
[epoch4, step753]: loss 0.267483
[epoch4, step754]: loss 0.369276
[epoch4, step755]: loss 0.330446
[epoch4, step756]: loss 0.243552
[epoch4, step757]: loss 0.311436
[epoch4, step758]: loss 0.342949
[epoch4, step759]: loss 0.271015
[epoch4, step760]: loss 0.330123
[epoch4, step761]: loss 0.295904
[epoch4, step762]: loss 0.282951
[epoch4, step763]: loss 0.282021
[epoch4, step764]: loss 0.325823
[epoch4, step765]: loss 0.278717
[epoch4, step766]: loss 0.259010
[epoch4, step767]: loss 0.336240
[epoch4, step768]: loss 0.313475
[epoch4, step769]: loss 0.309815
[epoch4, step770]: loss 0.389631
[epoch4, step771]: loss 0.258755
[epoch4, step772]: loss 0.255178
[epoch4, step773]: loss 0.297010
[epoch4, step774]: loss 0.311393
[epoch4, step775]: loss 0.385657
[epoch4, step776]: loss 0.329619
[epoch4, step777]: loss 0.288309
[epoch4, step778]: loss 0.349969
[epoch4, step779]: loss 0.298421
[epoch4, step780]: loss 0.342464
[epoch4, step781]: loss 0.389443
[epoch4, step782]: loss 0.369306
[epoch4, step783]: loss 0.320004
[epoch4, step784]: loss 0.365553
[epoch4, step785]: loss 0.354376
[epoch4, step786]: loss 0.306711
[epoch4, step787]: loss 0.384706
[epoch4, step788]: loss 0.317394
[epoch4, step789]: loss 0.368531
[epoch4, step790]: loss 0.256767
[epoch4, step791]: loss 0.330683
[epoch4, step792]: loss 0.335442
[epoch4, step793]: loss 0.338367
[epoch4, step794]: loss 0.321827
[epoch4, step795]: loss 0.305190
[epoch4, step796]: loss 0.291031
[epoch4, step797]: loss 0.265400
[epoch4, step798]: loss 0.266453
[epoch4, step799]: loss 0.226537
[epoch4, step800]: loss 0.405224
[epoch4, step801]: loss 0.377178
[epoch4, step802]: loss 0.305720
[epoch4, step803]: loss 0.278555
[epoch4, step804]: loss 0.328920
[epoch4, step805]: loss 0.290714
[epoch4, step806]: loss 0.317426
[epoch4, step807]: loss 0.349647
[epoch4, step808]: loss 0.385816
[epoch4, step809]: loss 0.284645
[epoch4, step810]: loss 0.236883
[epoch4, step811]: loss 0.306206
[epoch4, step812]: loss 0.337922
[epoch4, step813]: loss 0.282659
[epoch4, step814]: loss 0.319035
[epoch4, step815]: loss 0.300922
[epoch4, step816]: loss 0.311664
[epoch4, step817]: loss 0.266741
[epoch4, step818]: loss 0.293054
[epoch4, step819]: loss 0.454845
[epoch4, step820]: loss 0.276130
[epoch4, step821]: loss 0.270010
[epoch4, step822]: loss 0.314853
[epoch4, step823]: loss 0.266231
[epoch4, step824]: loss 0.307013
[epoch4, step825]: loss 0.325658
[epoch4, step826]: loss 0.221017
[epoch4, step827]: loss 0.273772
[epoch4, step828]: loss 0.300841
[epoch4, step829]: loss 0.279994
[epoch4, step830]: loss 0.212351
[epoch4, step831]: loss 0.263342
[epoch4, step832]: loss 0.388535
[epoch4, step833]: loss 0.313886
[epoch4, step834]: loss 0.309180
[epoch4, step835]: loss 0.325127
[epoch4, step836]: loss 0.269442
[epoch4, step837]: loss 0.251940
[epoch4, step838]: loss 0.347959
[epoch4, step839]: loss 0.302959
[epoch4, step840]: loss 0.281624
[epoch4, step841]: loss 0.302015
[epoch4, step842]: loss 0.297860
[epoch4, step843]: loss 0.343199
[epoch4, step844]: loss 0.345382
[epoch4, step845]: loss 0.329936
[epoch4, step846]: loss 0.407478
[epoch4, step847]: loss 0.305740
[epoch4, step848]: loss 0.165341
[epoch4, step849]: loss 0.279011
[epoch4, step850]: loss 0.347986
[epoch4, step851]: loss 0.294805
[epoch4, step852]: loss 0.304663
[epoch4, step853]: loss 0.328433
[epoch4, step854]: loss 0.347901
[epoch4, step855]: loss 0.271505
[epoch4, step856]: loss 0.247365
[epoch4, step857]: loss 0.323603
[epoch4, step858]: loss 0.336282
[epoch4, step859]: loss 0.275162
[epoch4, step860]: loss 0.352027
[epoch4, step861]: loss 0.315976
[epoch4, step862]: loss 0.247835
[epoch4, step863]: loss 0.346697
[epoch4, step864]: loss 0.353638
[epoch4, step865]: loss 0.326810
[epoch4, step866]: loss 0.342827
[epoch4, step867]: loss 0.284132
[epoch4, step868]: loss 0.317216
[epoch4, step869]: loss 0.269209
[epoch4, step870]: loss 0.245340
[epoch4, step871]: loss 0.387407
[epoch4, step872]: loss 0.333177
[epoch4, step873]: loss 0.253850
[epoch4, step874]: loss 0.301278
[epoch4, step875]: loss 0.393559
[epoch4, step876]: loss 0.353886
[epoch4, step877]: loss 0.193180
[epoch4, step878]: loss 0.273001
[epoch4, step879]: loss 0.288222
[epoch4, step880]: loss 0.278207
[epoch4, step881]: loss 0.356603
[epoch4, step882]: loss 0.273297
[epoch4, step883]: loss 0.286416
[epoch4, step884]: loss 0.376669
[epoch4, step885]: loss 0.380229
[epoch4, step886]: loss 0.359983
[epoch4, step887]: loss 0.385932
[epoch4, step888]: loss 0.289246
[epoch4, step889]: loss 0.336873
[epoch4, step890]: loss 0.340314
[epoch4, step891]: loss 0.285748
[epoch4, step892]: loss 0.344151
[epoch4, step893]: loss 0.327689
[epoch4, step894]: loss 0.332014
[epoch4, step895]: loss 0.255870
[epoch4, step896]: loss 0.421097
[epoch4, step897]: loss 0.415235
[epoch4, step898]: loss 0.266233
[epoch4, step899]: loss 0.186074
[epoch4, step900]: loss 0.303521
[epoch4, step901]: loss 0.358518
[epoch4, step902]: loss 0.273085
[epoch4, step903]: loss 0.369135
[epoch4, step904]: loss 0.263020
[epoch4, step905]: loss 0.249589
[epoch4, step906]: loss 0.242349
[epoch4, step907]: loss 0.338491
[epoch4, step908]: loss 0.372910
[epoch4, step909]: loss 0.294816
[epoch4, step910]: loss 0.247783
[epoch4, step911]: loss 0.234622
[epoch4, step912]: loss 0.342564
[epoch4, step913]: loss 0.349575
[epoch4, step914]: loss 0.298965
[epoch4, step915]: loss 0.272886
[epoch4, step916]: loss 0.319896
[epoch4, step917]: loss 0.307400
[epoch4, step918]: loss 0.344747
[epoch4, step919]: loss 0.253073
[epoch4, step920]: loss 0.353853
[epoch4, step921]: loss 0.279211
[epoch4, step922]: loss 0.289490
[epoch4, step923]: loss 0.369493
[epoch4, step924]: loss 0.284450
[epoch4, step925]: loss 0.280410
[epoch4, step926]: loss 0.284494
[epoch4, step927]: loss 0.361023
[epoch4, step928]: loss 0.274536
[epoch4, step929]: loss 0.289647
[epoch4, step930]: loss 0.303517
[epoch4, step931]: loss 0.335350
[epoch4, step932]: loss 0.277100
[epoch4, step933]: loss 0.280270
[epoch4, step934]: loss 0.375053
[epoch4, step935]: loss 0.317310
[epoch4, step936]: loss 0.275048
[epoch4, step937]: loss 0.241788
[epoch4, step938]: loss 0.388056
[epoch4, step939]: loss 0.287709
[epoch4, step940]: loss 0.346927
[epoch4, step941]: loss 0.315424
[epoch4, step942]: loss 0.311608
[epoch4, step943]: loss 0.365451
[epoch4, step944]: loss 0.311767
[epoch4, step945]: loss 0.355733
[epoch4, step946]: loss 0.303794
[epoch4, step947]: loss 0.268142
[epoch4, step948]: loss 0.440652
[epoch4, step949]: loss 0.312497
[epoch4, step950]: loss 0.294023
[epoch4, step951]: loss 0.320069
[epoch4, step952]: loss 0.339707
[epoch4, step953]: loss 0.301092
[epoch4, step954]: loss 0.333592
[epoch4, step955]: loss 0.231519
[epoch4, step956]: loss 0.346322
[epoch4, step957]: loss 0.315702
[epoch4, step958]: loss 0.373567
[epoch4, step959]: loss 0.333716
[epoch4, step960]: loss 0.305685
[epoch4, step961]: loss 0.333178
[epoch4, step962]: loss 0.335423
[epoch4, step963]: loss 0.350021
[epoch4, step964]: loss 0.316868
[epoch4, step965]: loss 0.358141
[epoch4, step966]: loss 0.313871
[epoch4, step967]: loss 0.363501
[epoch4, step968]: loss 0.334224
[epoch4, step969]: loss 0.292155
[epoch4, step970]: loss 0.334071
[epoch4, step971]: loss 0.337045
[epoch4, step972]: loss 0.338651
[epoch4, step973]: loss 0.327062
[epoch4, step974]: loss 0.340329
[epoch4, step975]: loss 0.309760
[epoch4, step976]: loss 0.363245
[epoch4, step977]: loss 0.321549
[epoch4, step978]: loss 0.291098
[epoch4, step979]: loss 0.339100
[epoch4, step980]: loss 0.338073
[epoch4, step981]: loss 0.344158
[epoch4, step982]: loss 0.316489
[epoch4, step983]: loss 0.343664
[epoch4, step984]: loss 0.312974
[epoch4, step985]: loss 0.362418
[epoch4, step986]: loss 0.317260
[epoch4, step987]: loss 0.283810
[epoch4, step988]: loss 0.324016
[epoch4, step989]: loss 0.329098
[epoch4, step990]: loss 0.343016
[epoch4, step991]: loss 0.308864
[epoch4, step992]: loss 0.344135
[epoch4, step993]: loss 0.311995
[epoch4, step994]: loss 0.366234
[epoch4, step995]: loss 0.323888
[epoch4, step996]: loss 0.291444
[epoch4, step997]: loss 0.327809
[epoch4, step998]: loss 0.327297
[epoch4, step999]: loss 0.338851
[epoch4, step1000]: loss 0.315519
[epoch4, step1001]: loss 0.341279
[epoch4, step1002]: loss 0.303944
[epoch4, step1003]: loss 0.360924
[epoch4, step1004]: loss 0.319173
[epoch4, step1005]: loss 0.295114
[epoch4, step1006]: loss 0.328660
[epoch4, step1007]: loss 0.335038
[epoch4, step1008]: loss 0.343633
[epoch4, step1009]: loss 0.314948
[epoch4, step1010]: loss 0.334672
[epoch4, step1011]: loss 0.306615
[epoch4, step1012]: loss 0.352266
[epoch4, step1013]: loss 0.320757
[epoch4, step1014]: loss 0.284864
[epoch4, step1015]: loss 0.324377
[epoch4, step1016]: loss 0.334275
[epoch4, step1017]: loss 0.344272
[epoch4, step1018]: loss 0.313881
[epoch4, step1019]: loss 0.340113
[epoch4, step1020]: loss 0.310472
[epoch4, step1021]: loss 0.359092
[epoch4, step1022]: loss 0.322534
[epoch4, step1023]: loss 0.289475
[epoch4, step1024]: loss 0.317026
[epoch4, step1025]: loss 0.337720
[epoch4, step1026]: loss 0.347380
[epoch4, step1027]: loss 0.311621
[epoch4, step1028]: loss 0.340572
[epoch4, step1029]: loss 0.306673
[epoch4, step1030]: loss 0.361266
[epoch4, step1031]: loss 0.337646
[epoch4, step1032]: loss 0.287133
[epoch4, step1033]: loss 0.335111
[epoch4, step1034]: loss 0.334369
[epoch4, step1035]: loss 0.347795
[epoch4, step1036]: loss 0.315797
[epoch4, step1037]: loss 0.343144
[epoch4, step1038]: loss 0.307690
[epoch4, step1039]: loss 0.355161
[epoch4, step1040]: loss 0.328199
[epoch4, step1041]: loss 0.291635
[epoch4, step1042]: loss 0.331363
[epoch4, step1043]: loss 0.332517
[epoch4, step1044]: loss 0.337988
[epoch4, step1045]: loss 0.310948
[epoch4, step1046]: loss 0.338800
[epoch4, step1047]: loss 0.303267
[epoch4, step1048]: loss 0.362316
[epoch4, step1049]: loss 0.321460
[epoch4, step1050]: loss 0.287414
[epoch4, step1051]: loss 0.325510
[epoch4, step1052]: loss 0.328235
[epoch4, step1053]: loss 0.339894
[epoch4, step1054]: loss 0.315382
[epoch4, step1055]: loss 0.345369
[epoch4, step1056]: loss 0.311951
[epoch4, step1057]: loss 0.349046
[epoch4, step1058]: loss 0.312198
[epoch4, step1059]: loss 0.286986
[epoch4, step1060]: loss 0.320731
[epoch4, step1061]: loss 0.339183
[epoch4, step1062]: loss 0.334738
[epoch4, step1063]: loss 0.313911
[epoch4, step1064]: loss 0.340084
[epoch4, step1065]: loss 0.309823
[epoch4, step1066]: loss 0.359929
[epoch4, step1067]: loss 0.320813
[epoch4, step1068]: loss 0.303865
[epoch4, step1069]: loss 0.322442
[epoch4, step1070]: loss 0.330332
[epoch4, step1071]: loss 0.332193
[epoch4, step1072]: loss 0.304778
[epoch4, step1073]: loss 0.340742
[epoch4, step1074]: loss 0.309368
[epoch4, step1075]: loss 0.351906
[epoch4, step1076]: loss 0.318873
[epoch4, step1077]: loss 0.286790
[epoch4, step1078]: loss 0.328087
[epoch4, step1079]: loss 0.320323
[epoch4, step1080]: loss 0.334826
[epoch4, step1081]: loss 0.317703
[epoch4, step1082]: loss 0.340520
[epoch4, step1083]: loss 0.300793
[epoch4, step1084]: loss 0.352310
[epoch4, step1085]: loss 0.326066
[epoch4, step1086]: loss 0.292329
[epoch4, step1087]: loss 0.325661
[epoch4, step1088]: loss 0.332512
[epoch4, step1089]: loss 0.333825
[epoch4, step1090]: loss 0.306568
[epoch4, step1091]: loss 0.335858
[epoch4, step1092]: loss 0.306687
[epoch4, step1093]: loss 0.353590
[epoch4, step1094]: loss 0.330051
[epoch4, step1095]: loss 0.288563
[epoch4, step1096]: loss 0.330504
[epoch4, step1097]: loss 0.327646
[epoch4, step1098]: loss 0.339323
[epoch4, step1099]: loss 0.315969
[epoch4, step1100]: loss 0.331850
[epoch4, step1101]: loss 0.306695
[epoch4, step1102]: loss 0.356507
[epoch4, step1103]: loss 0.325151
[epoch4, step1104]: loss 0.286644
[epoch4, step1105]: loss 0.320506
[epoch4, step1106]: loss 0.338277
[epoch4, step1107]: loss 0.336286
[epoch4, step1108]: loss 0.315855
[epoch4, step1109]: loss 0.332921
[epoch4, step1110]: loss 0.297557
[epoch4, step1111]: loss 0.351894
[epoch4, step1112]: loss 0.315380
[epoch4, step1113]: loss 0.287361
[epoch4, step1114]: loss 0.321594
[epoch4, step1115]: loss 0.325524
[epoch4, step1116]: loss 0.335339
[epoch4, step1117]: loss 0.309636
[epoch4, step1118]: loss 0.338550
[epoch4, step1119]: loss 0.310482
[epoch4, step1120]: loss 0.355849
[epoch4, step1121]: loss 0.320101
[epoch4, step1122]: loss 0.287884
[epoch4, step1123]: loss 0.329374
[epoch4, step1124]: loss 0.322117
[epoch4, step1125]: loss 0.333136
[epoch4, step1126]: loss 0.302568
[epoch4, step1127]: loss 0.335493
[epoch4, step1128]: loss 0.304353
[epoch4, step1129]: loss 0.354704
[epoch4, step1130]: loss 0.309228
[epoch4, step1131]: loss 0.281393
[epoch4, step1132]: loss 0.318827
[epoch4, step1133]: loss 0.332642
[epoch4, step1134]: loss 0.338030
[epoch4, step1135]: loss 0.298154
[epoch4, step1136]: loss 0.329007
[epoch4, step1137]: loss 0.299532
[epoch4, step1138]: loss 0.349494
[epoch4, step1139]: loss 0.320536
[epoch4, step1140]: loss 0.285989
[epoch4, step1141]: loss 0.319759
[epoch4, step1142]: loss 0.331508
[epoch4, step1143]: loss 0.340649
[epoch4, step1144]: loss 0.311139
[epoch4, step1145]: loss 0.341344
[epoch4, step1146]: loss 0.302063
[epoch4, step1147]: loss 0.342256
[epoch4, step1148]: loss 0.318518
[epoch4, step1149]: loss 0.284583
[epoch4, step1150]: loss 0.326108
[epoch4, step1151]: loss 0.325011
[epoch4, step1152]: loss 0.328408
[epoch4, step1153]: loss 0.314083
[epoch4, step1154]: loss 0.331672
[epoch4, step1155]: loss 0.299986
[epoch4, step1156]: loss 0.358673
[epoch4, step1157]: loss 0.321811
[epoch4, step1158]: loss 0.280629
[epoch4, step1159]: loss 0.318281
[epoch4, step1160]: loss 0.319627
[epoch4, step1161]: loss 0.328891
[epoch4, step1162]: loss 0.310448
[epoch4, step1163]: loss 0.341854
[epoch4, step1164]: loss 0.299562
[epoch4, step1165]: loss 0.339111
[epoch4, step1166]: loss 0.314888
[epoch4, step1167]: loss 0.286830
[epoch4, step1168]: loss 0.319176
[epoch4, step1169]: loss 0.327961
[epoch4, step1170]: loss 0.334205
[epoch4, step1171]: loss 0.310545
[epoch4, step1172]: loss 0.335711
[epoch4, step1173]: loss 0.301507
[epoch4, step1174]: loss 0.345676
[epoch4, step1175]: loss 0.319553
[epoch4, step1176]: loss 0.285207
[epoch4, step1177]: loss 0.314892
[epoch4, step1178]: loss 0.322733
[epoch4, step1179]: loss 0.334767
[epoch4, step1180]: loss 0.306594
[epoch4, step1181]: loss 0.328498
[epoch4, step1182]: loss 0.304972
[epoch4, step1183]: loss 0.343050
[epoch4, step1184]: loss 0.323066
[epoch4, step1185]: loss 0.285714
[epoch4, step1186]: loss 0.323227
[epoch4, step1187]: loss 0.334756
[epoch4, step1188]: loss 0.338327
[epoch4, step1189]: loss 0.308683
[epoch4, step1190]: loss 0.338009
[epoch4, step1191]: loss 0.298685
[epoch4, step1192]: loss 0.345966
[epoch4, step1193]: loss 0.315684
[epoch4, step1194]: loss 0.284369
[epoch4, step1195]: loss 0.332928
[epoch4, step1196]: loss 0.332137
[epoch4, step1197]: loss 0.331278
[epoch4, step1198]: loss 0.305668
[epoch4, step1199]: loss 0.336698
[epoch4, step1200]: loss 0.300591
[epoch4, step1201]: loss 0.343711
[epoch4, step1202]: loss 0.306861
[epoch4, step1203]: loss 0.286904
[epoch4, step1204]: loss 0.322518
[epoch4, step1205]: loss 0.326931
[epoch4, step1206]: loss 0.338077
[epoch4, step1207]: loss 0.300454
[epoch4, step1208]: loss 0.330220
[epoch4, step1209]: loss 0.306070
[epoch4, step1210]: loss 0.342472
[epoch4, step1211]: loss 0.321624
[epoch4, step1212]: loss 0.286425
[epoch4, step1213]: loss 0.325447
[epoch4, step1214]: loss 0.322420
[epoch4, step1215]: loss 0.325197
[epoch4, step1216]: loss 0.307063
[epoch4, step1217]: loss 0.326687
[epoch4, step1218]: loss 0.299511
[epoch4, step1219]: loss 0.341422
[epoch4, step1220]: loss 0.310816
[epoch4, step1221]: loss 0.287156
[epoch4, step1222]: loss 0.317737
[epoch4, step1223]: loss 0.323844
[epoch4, step1224]: loss 0.325618
[epoch4, step1225]: loss 0.305738
[epoch4, step1226]: loss 0.336673
[epoch4, step1227]: loss 0.295718
[epoch4, step1228]: loss 0.350181
[epoch4, step1229]: loss 0.320454
[epoch4, step1230]: loss 0.284742
[epoch4, step1231]: loss 0.322146
[epoch4, step1232]: loss 0.314421
[epoch4, step1233]: loss 0.332880
[epoch4, step1234]: loss 0.307459
[epoch4, step1235]: loss 0.327270
[epoch4, step1236]: loss 0.302619
[epoch4, step1237]: loss 0.351752
[epoch4, step1238]: loss 0.321395
[epoch4, step1239]: loss 0.276817
[epoch4, step1240]: loss 0.313372
[epoch4, step1241]: loss 0.330674
[epoch4, step1242]: loss 0.332405
[epoch4, step1243]: loss 0.303002
[epoch4, step1244]: loss 0.328973
[epoch4, step1245]: loss 0.292643
[epoch4, step1246]: loss 0.343964
[epoch4, step1247]: loss 0.323737
[epoch4, step1248]: loss 0.282771
[epoch4, step1249]: loss 0.312067
[epoch4, step1250]: loss 0.323890
[epoch4, step1251]: loss 0.328804
[epoch4, step1252]: loss 0.301007
[epoch4, step1253]: loss 0.327932
[epoch4, step1254]: loss 0.296754
[epoch4, step1255]: loss 0.345351
[epoch4, step1256]: loss 0.309059
[epoch4, step1257]: loss 0.278490
[epoch4, step1258]: loss 0.317304
[epoch4, step1259]: loss 0.324750
[epoch4, step1260]: loss 0.329435
[epoch4, step1261]: loss 0.307177
[epoch4, step1262]: loss 0.341622
[epoch4, step1263]: loss 0.289689
[epoch4, step1264]: loss 0.348032
[epoch4, step1265]: loss 0.327897
[epoch4, step1266]: loss 0.283039
[epoch4, step1267]: loss 0.316802
[epoch4, step1268]: loss 0.320545
[epoch4, step1269]: loss 0.327888
[epoch4, step1270]: loss 0.310761
[epoch4, step1271]: loss 0.325938
[epoch4, step1272]: loss 0.295269
[epoch4, step1273]: loss 0.348947
[epoch4, step1274]: loss 0.318112
[epoch4, step1275]: loss 0.280204
[epoch4, step1276]: loss 0.317342
[epoch4, step1277]: loss 0.322699
[epoch4, step1278]: loss 0.322849
[epoch4, step1279]: loss 0.301808
[epoch4, step1280]: loss 0.327979
[epoch4, step1281]: loss 0.297454
[epoch4, step1282]: loss 0.344472
[epoch4, step1283]: loss 0.319244
[epoch4, step1284]: loss 0.279133
[epoch4, step1285]: loss 0.314485
[epoch4, step1286]: loss 0.327162
[epoch4, step1287]: loss 0.320614
[epoch4, step1288]: loss 0.297073
[epoch4, step1289]: loss 0.320142
[epoch4, step1290]: loss 0.299185
[epoch4, step1291]: loss 0.346751
[epoch4, step1292]: loss 0.305308
[epoch4, step1293]: loss 0.282959
[epoch4, step1294]: loss 0.314026
[epoch4, step1295]: loss 0.315365
[epoch4, step1296]: loss 0.325588
[epoch4, step1297]: loss 0.300051
[epoch4, step1298]: loss 0.322961
[epoch4, step1299]: loss 0.296496
[epoch4, step1300]: loss 0.338709
[epoch4, step1301]: loss 0.323830
[epoch4, step1302]: loss 0.278315
[epoch4, step1303]: loss 0.318011
[epoch4, step1304]: loss 0.326495
[epoch4, step1305]: loss 0.322247
[epoch4, step1306]: loss 0.304218
[epoch4, step1307]: loss 0.334401
[epoch4, step1308]: loss 0.297423
[epoch4, step1309]: loss 0.350340
[epoch4, step1310]: loss 0.313505
[epoch4, step1311]: loss 0.285707
[epoch4, step1312]: loss 0.313028
[epoch4, step1313]: loss 0.319398
[epoch4, step1314]: loss 0.329984
[epoch4, step1315]: loss 0.303420
[epoch4, step1316]: loss 0.314305
[epoch4, step1317]: loss 0.300360
[epoch4, step1318]: loss 0.349821
[epoch4, step1319]: loss 0.316112
[epoch4, step1320]: loss 0.278321
[epoch4, step1321]: loss 0.307994
[epoch4, step1322]: loss 0.324337
[epoch4, step1323]: loss 0.322838
[epoch4, step1324]: loss 0.305423
[epoch4, step1325]: loss 0.328496
[epoch4, step1326]: loss 0.300735
[epoch4, step1327]: loss 0.343073
[epoch4, step1328]: loss 0.312138
[epoch4, step1329]: loss 0.279511
[epoch4, step1330]: loss 0.312809
[epoch4, step1331]: loss 0.323669
[epoch4, step1332]: loss 0.329318
[epoch4, step1333]: loss 0.313757
[epoch4, step1334]: loss 0.323427
[epoch4, step1335]: loss 0.293791
[epoch4, step1336]: loss 0.341148
[epoch4, step1337]: loss 0.319513
[epoch4, step1338]: loss 0.278701
[epoch4, step1339]: loss 0.317176
[epoch4, step1340]: loss 0.324744
[epoch4, step1341]: loss 0.326199
[epoch4, step1342]: loss 0.302195
[epoch4, step1343]: loss 0.324460
[epoch4, step1344]: loss 0.292047
[epoch4, step1345]: loss 0.340973
[epoch4, step1346]: loss 0.315508
[epoch4, step1347]: loss 0.273109
[epoch4, step1348]: loss 0.318613
[epoch4, step1349]: loss 0.318882
[epoch4, step1350]: loss 0.322856
[epoch4, step1351]: loss 0.310188
[epoch4, step1352]: loss 0.331320
[epoch4, step1353]: loss 0.300752
[epoch4, step1354]: loss 0.346162
[epoch4, step1355]: loss 0.310804
[epoch4, step1356]: loss 0.285928
[epoch4, step1357]: loss 0.320348
[epoch4, step1358]: loss 0.319915
[epoch4, step1359]: loss 0.329032
[epoch4, step1360]: loss 0.296858
[epoch4, step1361]: loss 0.323366
[epoch4, step1362]: loss 0.291584
[epoch4, step1363]: loss 0.334704
[epoch4, step1364]: loss 0.310759
[epoch4, step1365]: loss 0.278731
[epoch4, step1366]: loss 0.313736
[epoch4, step1367]: loss 0.325177
[epoch4, step1368]: loss 0.314046
[epoch4, step1369]: loss 0.302312
[epoch4, step1370]: loss 0.328854
[epoch4, step1371]: loss 0.291315
[epoch4, step1372]: loss 0.340944
[epoch4, step1373]: loss 0.310795
[epoch4, step1374]: loss 0.270952
[epoch4, step1375]: loss 0.307369
[epoch4, step1376]: loss 0.318872
[epoch4, step1377]: loss 0.334340
[epoch4, step1378]: loss 0.301258
[epoch4, step1379]: loss 0.329902
[epoch4, step1380]: loss 0.287186
[epoch4, step1381]: loss 0.339487
[epoch4, step1382]: loss 0.308407
[epoch4, step1383]: loss 0.277678
[epoch4, step1384]: loss 0.310127
[epoch4, step1385]: loss 0.322198
[epoch4, step1386]: loss 0.321881
[epoch4, step1387]: loss 0.293434
[epoch4, step1388]: loss 0.335602
[epoch4, step1389]: loss 0.297992
[epoch4, step1390]: loss 0.338098
[epoch4, step1391]: loss 0.311332
[epoch4, step1392]: loss 0.279393
[epoch4, step1393]: loss 0.307536
[epoch4, step1394]: loss 0.311158
[epoch4, step1395]: loss 0.322228
[epoch4, step1396]: loss 0.300299
[epoch4, step1397]: loss 0.327217
[epoch4, step1398]: loss 0.291684
[epoch4, step1399]: loss 0.328828
[epoch4, step1400]: loss 0.307315
[epoch4, step1401]: loss 0.274508
[epoch4, step1402]: loss 0.310847
[epoch4, step1403]: loss 0.326299
[epoch4, step1404]: loss 0.327468
[epoch4, step1405]: loss 0.295544
[epoch4, step1406]: loss 0.327727
[epoch4, step1407]: loss 0.283148
[epoch4, step1408]: loss 0.345455
[epoch4, step1409]: loss 0.313913
[epoch4, step1410]: loss 0.273210
[epoch4, step1411]: loss 0.322092
[epoch4, step1412]: loss 0.315972
[epoch4, step1413]: loss 0.323046
[epoch4, step1414]: loss 0.302745
[epoch4, step1415]: loss 0.327154
[epoch4, step1416]: loss 0.290133
[epoch4, step1417]: loss 0.340587
[epoch4, step1418]: loss 0.310077
[epoch4, step1419]: loss 0.270152
[epoch4, step1420]: loss 0.311266
[epoch4, step1421]: loss 0.312402
[epoch4, step1422]: loss 0.318853
[epoch4, step1423]: loss 0.301931
[epoch4, step1424]: loss 0.323186
[epoch4, step1425]: loss 0.296605
[epoch4, step1426]: loss 0.338184
[epoch4, step1427]: loss 0.301085
[epoch4, step1428]: loss 0.274891
[epoch4, step1429]: loss 0.308208
[epoch4, step1430]: loss 0.318399
[epoch4, step1431]: loss 0.321402
[epoch4, step1432]: loss 0.300455
[epoch4, step1433]: loss 0.322719
[epoch4, step1434]: loss 0.301875
[epoch4, step1435]: loss 0.332948
[epoch4, step1436]: loss 0.305234
[epoch4, step1437]: loss 0.272223
[epoch4, step1438]: loss 0.307801
[epoch4, step1439]: loss 0.318588
[epoch4, step1440]: loss 0.324372
[epoch4, step1441]: loss 0.292084
[epoch4, step1442]: loss 0.331377
[epoch4, step1443]: loss 0.300205
[epoch4, step1444]: loss 0.344102
[epoch4, step1445]: loss 0.304691
[epoch4, step1446]: loss 0.270959
[epoch4, step1447]: loss 0.305285
[epoch4, step1448]: loss 0.317051
[epoch4, step1449]: loss 0.326165
[epoch4, step1450]: loss 0.298591
[epoch4, step1451]: loss 0.319736
[epoch4, step1452]: loss 0.293943
[epoch4, step1453]: loss 0.327074
[epoch4, step1454]: loss 0.303352
[epoch4, step1455]: loss 0.266610
[epoch4, step1456]: loss 0.313165
[epoch4, step1457]: loss 0.308476
[epoch4, step1458]: loss 0.320243
[epoch4, step1459]: loss 0.301762
[epoch4, step1460]: loss 0.317766
[epoch4, step1461]: loss 0.284734
[epoch4, step1462]: loss 0.328355
[epoch4, step1463]: loss 0.309544
[epoch4, step1464]: loss 0.269527
[epoch4, step1465]: loss 0.315394
[epoch4, step1466]: loss 0.317062
[epoch4, step1467]: loss 0.325089
[epoch4, step1468]: loss 0.300335
[epoch4, step1469]: loss 0.323325
[epoch4, step1470]: loss 0.288634
[epoch4, step1471]: loss 0.341582
[epoch4, step1472]: loss 0.309663
[epoch4, step1473]: loss 0.271567
[epoch4, step1474]: loss 0.302846
[epoch4, step1475]: loss 0.317332
[epoch4, step1476]: loss 0.314340
[epoch4, step1477]: loss 0.302289
[epoch4, step1478]: loss 0.321443
[epoch4, step1479]: loss 0.290033
[epoch4, step1480]: loss 0.335604
[epoch4, step1481]: loss 0.317582
[epoch4, step1482]: loss 0.274301
[epoch4, step1483]: loss 0.309140
[epoch4, step1484]: loss 0.311942
[epoch4, step1485]: loss 0.320150
[epoch4, step1486]: loss 0.305882
[epoch4, step1487]: loss 0.322737
[epoch4, step1488]: loss 0.288024
[epoch4, step1489]: loss 0.337073
[epoch4, step1490]: loss 0.304682
[epoch4, step1491]: loss 0.274985
[epoch4, step1492]: loss 0.313146
[epoch4, step1493]: loss 0.314721
[epoch4, step1494]: loss 0.319734
[epoch4, step1495]: loss 0.303381
[epoch4, step1496]: loss 0.329728
[epoch4, step1497]: loss 0.286878
[epoch4, step1498]: loss 0.330444
[epoch4, step1499]: loss 0.312569
[epoch4, step1500]: loss 0.271629
[epoch4, step1501]: loss 0.308142
[epoch4, step1502]: loss 0.314813
[epoch4, step1503]: loss 0.322209
[epoch4, step1504]: loss 0.302651
[epoch4, step1505]: loss 0.318702
[epoch4, step1506]: loss 0.292092
[epoch4, step1507]: loss 0.330959
[epoch4, step1508]: loss 0.301714
[epoch4, step1509]: loss 0.276378
[epoch4, step1510]: loss 0.319232
[epoch4, step1511]: loss 0.306628
[epoch4, step1512]: loss 0.316559
[epoch4, step1513]: loss 0.308405
[epoch4, step1514]: loss 0.321318
[epoch4, step1515]: loss 0.287755
[epoch4, step1516]: loss 0.333892

[epoch4]: avg loss 0.332177

[epoch5, step1]: loss 0.379730
[epoch5, step2]: loss 0.316022
[epoch5, step3]: loss 0.320200
[epoch5, step4]: loss 0.299630
[epoch5, step5]: loss 0.334265
[epoch5, step6]: loss 0.306416
[epoch5, step7]: loss 0.280560
[epoch5, step8]: loss 0.321624
[epoch5, step9]: loss 0.288412
[epoch5, step10]: loss 0.322948
[epoch5, step11]: loss 0.314434
[epoch5, step12]: loss 0.317423
[epoch5, step13]: loss 0.286949
[epoch5, step14]: loss 0.333215
[epoch5, step15]: loss 0.306796
[epoch5, step16]: loss 0.281566
[epoch5, step17]: loss 0.317077
[epoch5, step18]: loss 0.277181
[epoch5, step19]: loss 0.327957
[epoch5, step20]: loss 0.304791
[epoch5, step21]: loss 0.318524
[epoch5, step22]: loss 0.294065
[epoch5, step23]: loss 0.345292
[epoch5, step24]: loss 0.303198
[epoch5, step25]: loss 0.283341
[epoch5, step26]: loss 0.328073
[epoch5, step27]: loss 0.288144
[epoch5, step28]: loss 0.326340
[epoch5, step29]: loss 0.310673
[epoch5, step30]: loss 0.309689
[epoch5, step31]: loss 0.291547
[epoch5, step32]: loss 0.330102
[epoch5, step33]: loss 0.299002
[epoch5, step34]: loss 0.277034
[epoch5, step35]: loss 0.317198
[epoch5, step36]: loss 0.287066
[epoch5, step37]: loss 0.328251
[epoch5, step38]: loss 0.313985
[epoch5, step39]: loss 0.316586
[epoch5, step40]: loss 0.284391
[epoch5, step41]: loss 0.340498
[epoch5, step42]: loss 0.300476
[epoch5, step43]: loss 0.284296
[epoch5, step44]: loss 0.318116
[epoch5, step45]: loss 0.286507
[epoch5, step46]: loss 0.327791
[epoch5, step47]: loss 0.316706
[epoch5, step48]: loss 0.319069
[epoch5, step49]: loss 0.297412
[epoch5, step50]: loss 0.333727
[epoch5, step51]: loss 0.304759
[epoch5, step52]: loss 0.285166
[epoch5, step53]: loss 0.313364
[epoch5, step54]: loss 0.283109
[epoch5, step55]: loss 0.322771
[epoch5, step56]: loss 0.300443
[epoch5, step57]: loss 0.311176
[epoch5, step58]: loss 0.286198
[epoch5, step59]: loss 0.344271
[epoch5, step60]: loss 0.296630
[epoch5, step61]: loss 0.286294
[epoch5, step62]: loss 0.324777
[epoch5, step63]: loss 0.291463
[epoch5, step64]: loss 0.334551
[epoch5, step65]: loss 0.308573
[epoch5, step66]: loss 0.315145
[epoch5, step67]: loss 0.289738
[epoch5, step68]: loss 0.334631
[epoch5, step69]: loss 0.303230
[epoch5, step70]: loss 0.283779
[epoch5, step71]: loss 0.323549
[epoch5, step72]: loss 0.283182
[epoch5, step73]: loss 0.328769
[epoch5, step74]: loss 0.308515
[epoch5, step75]: loss 0.312343
[epoch5, step76]: loss 0.286975
[epoch5, step77]: loss 0.326578
[epoch5, step78]: loss 0.300100
[epoch5, step79]: loss 0.285981
[epoch5, step80]: loss 0.310367
[epoch5, step81]: loss 0.280889
[epoch5, step82]: loss 0.332580
[epoch5, step83]: loss 0.318224
[epoch5, step84]: loss 0.312355
[epoch5, step85]: loss 0.281612
[epoch5, step86]: loss 0.329063
[epoch5, step87]: loss 0.292943
[epoch5, step88]: loss 0.298747
[epoch5, step89]: loss 0.322985
[epoch5, step90]: loss 0.285414
[epoch5, step91]: loss 0.336979
[epoch5, step92]: loss 0.307968
[epoch5, step93]: loss 0.312006
[epoch5, step94]: loss 0.290748
[epoch5, step95]: loss 0.327509
[epoch5, step96]: loss 0.304221
[epoch5, step97]: loss 0.276436
[epoch5, step98]: loss 0.318323
[epoch5, step99]: loss 0.284279
[epoch5, step100]: loss 0.336628
[epoch5, step101]: loss 0.302253
[epoch5, step102]: loss 0.314628
[epoch5, step103]: loss 0.289069
[epoch5, step104]: loss 0.331991
[epoch5, step105]: loss 0.297074
[epoch5, step106]: loss 0.282731
[epoch5, step107]: loss 0.318824
[epoch5, step108]: loss 0.281018
[epoch5, step109]: loss 0.329374
[epoch5, step110]: loss 0.302392
[epoch5, step111]: loss 0.314748
[epoch5, step112]: loss 0.289740
[epoch5, step113]: loss 0.322852
[epoch5, step114]: loss 0.302983
[epoch5, step115]: loss 0.281698
[epoch5, step116]: loss 0.309910
[epoch5, step117]: loss 0.280925
[epoch5, step118]: loss 0.317972
[epoch5, step119]: loss 0.303699
[epoch5, step120]: loss 0.309485
[epoch5, step121]: loss 0.288751
[epoch5, step122]: loss 0.330749
[epoch5, step123]: loss 0.296383
[epoch5, step124]: loss 0.280838
[epoch5, step125]: loss 0.311970
[epoch5, step126]: loss 0.284121
[epoch5, step127]: loss 0.327941
[epoch5, step128]: loss 0.308773
[epoch5, step129]: loss 0.311676
[epoch5, step130]: loss 0.282139
[epoch5, step131]: loss 0.336206
[epoch5, step132]: loss 0.298041
[epoch5, step133]: loss 0.279220
[epoch5, step134]: loss 0.323025
[epoch5, step135]: loss 0.277103
[epoch5, step136]: loss 0.313120
[epoch5, step137]: loss 0.310214
[epoch5, step138]: loss 0.311883
[epoch5, step139]: loss 0.285587
[epoch5, step140]: loss 0.324976
[epoch5, step141]: loss 0.296158
[epoch5, step142]: loss 0.279755
[epoch5, step143]: loss 0.320229
[epoch5, step144]: loss 0.285841
[epoch5, step145]: loss 0.325297
[epoch5, step146]: loss 0.306942
[epoch5, step147]: loss 0.298954
[epoch5, step148]: loss 0.284561
[epoch5, step149]: loss 0.335250
[epoch5, step150]: loss 0.302564
[epoch5, step151]: loss 0.275195
[epoch5, step152]: loss 0.315545
[epoch5, step153]: loss 0.277598
[epoch5, step154]: loss 0.330367
[epoch5, step155]: loss 0.305758
[epoch5, step156]: loss 0.315335
[epoch5, step157]: loss 0.281847
[epoch5, step158]: loss 0.325350
[epoch5, step159]: loss 0.296298
[epoch5, step160]: loss 0.275523
[epoch5, step161]: loss 0.308783
[epoch5, step162]: loss 0.278069
[epoch5, step163]: loss 0.325424
[epoch5, step164]: loss 0.301384
[epoch5, step165]: loss 0.309730
[epoch5, step166]: loss 0.278968
[epoch5, step167]: loss 0.332837
[epoch5, step168]: loss 0.290092
[epoch5, step169]: loss 0.281944
[epoch5, step170]: loss 0.311307
[epoch5, step171]: loss 0.277705
[epoch5, step172]: loss 0.322949
[epoch5, step173]: loss 0.302182
[epoch5, step174]: loss 0.312257
[epoch5, step175]: loss 0.274701
[epoch5, step176]: loss 0.326473
[epoch5, step177]: loss 0.293878
[epoch5, step178]: loss 0.272144
[epoch5, step179]: loss 0.321938
[epoch5, step180]: loss 0.272833
[epoch5, step181]: loss 0.320772
[epoch5, step182]: loss 0.300809
[epoch5, step183]: loss 0.302823
[epoch5, step184]: loss 0.274388
[epoch5, step185]: loss 0.325307
[epoch5, step186]: loss 0.293372
[epoch5, step187]: loss 0.278747
[epoch5, step188]: loss 0.315797
[epoch5, step189]: loss 0.275489
[epoch5, step190]: loss 0.329039
[epoch5, step191]: loss 0.305814
[epoch5, step192]: loss 0.302709
[epoch5, step193]: loss 0.298693
[epoch5, step194]: loss 0.334807
[epoch5, step195]: loss 0.292607
[epoch5, step196]: loss 0.274218
[epoch5, step197]: loss 0.314730
[epoch5, step198]: loss 0.284133
[epoch5, step199]: loss 0.321484
[epoch5, step200]: loss 0.297114
[epoch5, step201]: loss 0.302841
[epoch5, step202]: loss 0.283477
[epoch5, step203]: loss 0.326666
[epoch5, step204]: loss 0.290830
[epoch5, step205]: loss 0.283332
[epoch5, step206]: loss 0.315812
[epoch5, step207]: loss 0.276444
[epoch5, step208]: loss 0.316397
[epoch5, step209]: loss 0.299238
[epoch5, step210]: loss 0.298699
[epoch5, step211]: loss 0.279419
[epoch5, step212]: loss 0.323200
[epoch5, step213]: loss 0.297725
[epoch5, step214]: loss 0.285179
[epoch5, step215]: loss 0.310241
[epoch5, step216]: loss 0.275227
[epoch5, step217]: loss 0.329766
[epoch5, step218]: loss 0.298526
[epoch5, step219]: loss 0.309271
[epoch5, step220]: loss 0.284766
[epoch5, step221]: loss 0.322930
[epoch5, step222]: loss 0.290595
[epoch5, step223]: loss 0.269589
[epoch5, step224]: loss 0.315016
[epoch5, step225]: loss 0.275329
[epoch5, step226]: loss 0.324721
[epoch5, step227]: loss 0.311037
[epoch5, step228]: loss 0.301201
[epoch5, step229]: loss 0.288440
[epoch5, step230]: loss 0.321063
[epoch5, step231]: loss 0.289179
[epoch5, step232]: loss 0.278285
[epoch5, step233]: loss 0.319210
[epoch5, step234]: loss 0.280405
[epoch5, step235]: loss 0.321318
[epoch5, step236]: loss 0.300413
[epoch5, step237]: loss 0.305976
[epoch5, step238]: loss 0.280111
[epoch5, step239]: loss 0.331304
[epoch5, step240]: loss 0.301871
[epoch5, step241]: loss 0.273271
[epoch5, step242]: loss 0.313245
[epoch5, step243]: loss 0.273508
[epoch5, step244]: loss 0.323094
[epoch5, step245]: loss 0.305511
[epoch5, step246]: loss 0.306377
[epoch5, step247]: loss 0.280446
[epoch5, step248]: loss 0.327998
[epoch5, step249]: loss 0.298308
[epoch5, step250]: loss 0.273626
[epoch5, step251]: loss 0.305653
[epoch5, step252]: loss 0.271480
[epoch5, step253]: loss 0.325654
[epoch5, step254]: loss 0.308101
[epoch5, step255]: loss 0.303267
[epoch5, step256]: loss 0.285270
[epoch5, step257]: loss 0.326209
[epoch5, step258]: loss 0.287507
[epoch5, step259]: loss 0.271801
[epoch5, step260]: loss 0.316545
[epoch5, step261]: loss 0.266804
[epoch5, step262]: loss 0.315240
[epoch5, step263]: loss 0.308157
[epoch5, step264]: loss 0.307456
[epoch5, step265]: loss 0.280320
[epoch5, step266]: loss 0.324732
[epoch5, step267]: loss 0.300905
[epoch5, step268]: loss 0.274362
[epoch5, step269]: loss 0.309473
[epoch5, step270]: loss 0.277898
[epoch5, step271]: loss 0.317916
[epoch5, step272]: loss 0.301087
[epoch5, step273]: loss 0.307409
[epoch5, step274]: loss 0.273648
[epoch5, step275]: loss 0.329948
[epoch5, step276]: loss 0.297742
[epoch5, step277]: loss 0.271180
[epoch5, step278]: loss 0.308354
[epoch5, step279]: loss 0.273056
[epoch5, step280]: loss 0.317703
[epoch5, step281]: loss 0.302377
[epoch5, step282]: loss 0.299324
[epoch5, step283]: loss 0.283425
[epoch5, step284]: loss 0.327929
[epoch5, step285]: loss 0.285064
[epoch5, step286]: loss 0.288737
[epoch5, step287]: loss 0.308204
[epoch5, step288]: loss 0.278879
[epoch5, step289]: loss 0.314260
[epoch5, step290]: loss 0.300058
[epoch5, step291]: loss 0.301451
[epoch5, step292]: loss 0.285993
[epoch5, step293]: loss 0.325293
[epoch5, step294]: loss 0.297181
[epoch5, step295]: loss 0.276710
[epoch5, step296]: loss 0.302500
[epoch5, step297]: loss 0.277787
[epoch5, step298]: loss 0.317304
[epoch5, step299]: loss 0.308006
[epoch5, step300]: loss 0.300313
[epoch5, step301]: loss 0.283202
[epoch5, step302]: loss 0.318610
[epoch5, step303]: loss 0.288147
[epoch5, step304]: loss 0.272738
[epoch5, step305]: loss 0.312537
[epoch5, step306]: loss 0.273740
[epoch5, step307]: loss 0.323244
[epoch5, step308]: loss 0.294384
[epoch5, step309]: loss 0.298869
[epoch5, step310]: loss 0.279375
[epoch5, step311]: loss 0.317759
[epoch5, step312]: loss 0.294154
[epoch5, step313]: loss 0.273551
[epoch5, step314]: loss 0.308363
[epoch5, step315]: loss 0.269605
[epoch5, step316]: loss 0.321204
[epoch5, step317]: loss 0.297160
[epoch5, step318]: loss 0.302494
[epoch5, step319]: loss 0.284416
[epoch5, step320]: loss 0.331436
[epoch5, step321]: loss 0.295192
[epoch5, step322]: loss 0.280703
[epoch5, step323]: loss 0.314977
[epoch5, step324]: loss 0.268386
[epoch5, step325]: loss 0.316669
[epoch5, step326]: loss 0.301258
[epoch5, step327]: loss 0.308919
[epoch5, step328]: loss 0.279412
[epoch5, step329]: loss 0.325387
[epoch5, step330]: loss 0.297623
[epoch5, step331]: loss 0.275180
[epoch5, step332]: loss 0.313841
[epoch5, step333]: loss 0.276476
[epoch5, step334]: loss 0.315996
[epoch5, step335]: loss 0.297779
[epoch5, step336]: loss 0.294872
[epoch5, step337]: loss 0.273710
[epoch5, step338]: loss 0.326648
[epoch5, step339]: loss 0.293711
[epoch5, step340]: loss 0.273139
[epoch5, step341]: loss 0.312361
[epoch5, step342]: loss 0.273354
[epoch5, step343]: loss 0.314652
[epoch5, step344]: loss 0.300885
[epoch5, step345]: loss 0.308595
[epoch5, step346]: loss 0.282499
[epoch5, step347]: loss 0.324667
[epoch5, step348]: loss 0.288588
[epoch5, step349]: loss 0.268962
[epoch5, step350]: loss 0.312865
[epoch5, step351]: loss 0.275989
[epoch5, step352]: loss 0.317262
[epoch5, step353]: loss 0.299277
[epoch5, step354]: loss 0.311732
[epoch5, step355]: loss 0.284299
[epoch5, step356]: loss 0.315084
[epoch5, step357]: loss 0.289741
[epoch5, step358]: loss 0.285482
[epoch5, step359]: loss 0.300081
[epoch5, step360]: loss 0.275751
[epoch5, step361]: loss 0.321614
[epoch5, step362]: loss 0.292987
[epoch5, step363]: loss 0.304965
[epoch5, step364]: loss 0.279154
[epoch5, step365]: loss 0.322529
[epoch5, step366]: loss 0.287105
[epoch5, step367]: loss 0.275450
[epoch5, step368]: loss 0.312611
[epoch5, step369]: loss 0.274876
[epoch5, step370]: loss 0.311283
[epoch5, step371]: loss 0.289607
[epoch5, step372]: loss 0.304865
[epoch5, step373]: loss 0.278674
[epoch5, step374]: loss 0.326493
[epoch5, step375]: loss 0.283994
[epoch5, step376]: loss 0.266864
[epoch5, step377]: loss 0.305034
[epoch5, step378]: loss 0.272197
[epoch5, step379]: loss 0.310559
[epoch5, step380]: loss 0.292175
[epoch5, step381]: loss 0.304096
[epoch5, step382]: loss 0.282714
[epoch5, step383]: loss 0.330556
[epoch5, step384]: loss 0.296174
[epoch5, step385]: loss 0.267709
[epoch5, step386]: loss 0.304854
[epoch5, step387]: loss 0.268610
[epoch5, step388]: loss 0.307879
[epoch5, step389]: loss 0.296577
[epoch5, step390]: loss 0.291080
[epoch5, step391]: loss 0.277227
[epoch5, step392]: loss 0.313379
[epoch5, step393]: loss 0.293717
[epoch5, step394]: loss 0.275162
[epoch5, step395]: loss 0.308666
[epoch5, step396]: loss 0.269968
[epoch5, step397]: loss 0.320868
[epoch5, step398]: loss 0.295175
[epoch5, step399]: loss 0.301189
[epoch5, step400]: loss 0.275893
[epoch5, step401]: loss 0.320801
[epoch5, step402]: loss 0.291082
[epoch5, step403]: loss 0.269197
[epoch5, step404]: loss 0.303406
[epoch5, step405]: loss 0.267433
[epoch5, step406]: loss 0.310767
[epoch5, step407]: loss 0.298531
[epoch5, step408]: loss 0.299264
[epoch5, step409]: loss 0.262889
[epoch5, step410]: loss 0.313103
[epoch5, step411]: loss 0.288998
[epoch5, step412]: loss 0.271763
[epoch5, step413]: loss 0.305936
[epoch5, step414]: loss 0.277986
[epoch5, step415]: loss 0.312902
[epoch5, step416]: loss 0.301280
[epoch5, step417]: loss 0.297804
[epoch5, step418]: loss 0.274369
[epoch5, step419]: loss 0.324788
[epoch5, step420]: loss 0.284969
[epoch5, step421]: loss 0.271708
[epoch5, step422]: loss 0.304938
[epoch5, step423]: loss 0.269533
[epoch5, step424]: loss 0.311335
[epoch5, step425]: loss 0.293580
[epoch5, step426]: loss 0.296102
[epoch5, step427]: loss 0.278202
[epoch5, step428]: loss 0.319346
[epoch5, step429]: loss 0.279968
[epoch5, step430]: loss 0.269971
[epoch5, step431]: loss 0.301469
[epoch5, step432]: loss 0.268328
[epoch5, step433]: loss 0.304968
[epoch5, step434]: loss 0.295708
[epoch5, step435]: loss 0.295234
[epoch5, step436]: loss 0.281940
[epoch5, step437]: loss 0.315951
[epoch5, step438]: loss 0.280637
[epoch5, step439]: loss 0.271041
[epoch5, step440]: loss 0.304178
[epoch5, step441]: loss 0.266311
[epoch5, step442]: loss 0.312670
[epoch5, step443]: loss 0.289513
[epoch5, step444]: loss 0.302434
[epoch5, step445]: loss 0.272433
[epoch5, step446]: loss 0.313664
[epoch5, step447]: loss 0.280892
[epoch5, step448]: loss 0.265060
[epoch5, step449]: loss 0.305715
[epoch5, step450]: loss 0.276325
[epoch5, step451]: loss 0.314084
[epoch5, step452]: loss 0.304635
[epoch5, step453]: loss 0.296417
[epoch5, step454]: loss 0.277260
[epoch5, step455]: loss 0.314761
[epoch5, step456]: loss 0.293499
[epoch5, step457]: loss 0.265385
[epoch5, step458]: loss 0.305756
[epoch5, step459]: loss 0.262472
[epoch5, step460]: loss 0.313095
[epoch5, step461]: loss 0.287224
[epoch5, step462]: loss 0.304016
[epoch5, step463]: loss 0.273853
[epoch5, step464]: loss 0.318126
[epoch5, step465]: loss 0.273519
[epoch5, step466]: loss 0.266660
[epoch5, step467]: loss 0.306203
[epoch5, step468]: loss 0.270751
[epoch5, step469]: loss 0.310773
[epoch5, step470]: loss 0.291228
[epoch5, step471]: loss 0.300793
[epoch5, step472]: loss 0.274928
[epoch5, step473]: loss 0.319667
[epoch5, step474]: loss 0.288036
[epoch5, step475]: loss 0.267804
[epoch5, step476]: loss 0.298349
[epoch5, step477]: loss 0.269082
[epoch5, step478]: loss 0.315649
[epoch5, step479]: loss 0.293354
[epoch5, step480]: loss 0.304776
[epoch5, step481]: loss 0.275873
[epoch5, step482]: loss 0.321789
[epoch5, step483]: loss 0.281356
[epoch5, step484]: loss 0.260483
[epoch5, step485]: loss 0.301168
[epoch5, step486]: loss 0.264926
[epoch5, step487]: loss 0.316281
[epoch5, step488]: loss 0.289408
[epoch5, step489]: loss 0.304464
[epoch5, step490]: loss 0.273100
[epoch5, step491]: loss 0.312439
[epoch5, step492]: loss 0.287154
[epoch5, step493]: loss 0.266615
[epoch5, step494]: loss 0.307650
[epoch5, step495]: loss 0.255815
[epoch5, step496]: loss 0.312198
[epoch5, step497]: loss 0.290556
[epoch5, step498]: loss 0.296916
[epoch5, step499]: loss 0.272981
[epoch5, step500]: loss 0.319627
[epoch5, step501]: loss 0.290405
[epoch5, step502]: loss 0.267168
[epoch5, step503]: loss 0.300240
[epoch5, step504]: loss 0.274763
[epoch5, step505]: loss 0.319635
[epoch5, step506]: loss 0.286161
[epoch5, step507]: loss 0.292664
[epoch5, step508]: loss 0.269671
[epoch5, step509]: loss 0.317408
[epoch5, step510]: loss 0.283469
[epoch5, step511]: loss 0.269323
[epoch5, step512]: loss 0.297968
[epoch5, step513]: loss 0.267775
[epoch5, step514]: loss 0.308219
[epoch5, step515]: loss 0.291633
[epoch5, step516]: loss 0.291860
[epoch5, step517]: loss 0.274564
[epoch5, step518]: loss 0.313825
[epoch5, step519]: loss 0.283453
[epoch5, step520]: loss 0.265738
[epoch5, step521]: loss 0.304742
[epoch5, step522]: loss 0.269786
[epoch5, step523]: loss 0.309757
[epoch5, step524]: loss 0.298481
[epoch5, step525]: loss 0.292066
[epoch5, step526]: loss 0.266700
[epoch5, step527]: loss 0.318004
[epoch5, step528]: loss 0.280778
[epoch5, step529]: loss 0.271275
[epoch5, step530]: loss 0.297859
[epoch5, step531]: loss 0.266497
[epoch5, step532]: loss 0.313769
[epoch5, step533]: loss 0.281684
[epoch5, step534]: loss 0.295816
[epoch5, step535]: loss 0.269718
[epoch5, step536]: loss 0.312014
[epoch5, step537]: loss 0.282052
[epoch5, step538]: loss 0.270685
[epoch5, step539]: loss 0.302320
[epoch5, step540]: loss 0.274799
[epoch5, step541]: loss 0.313659
[epoch5, step542]: loss 0.291369
[epoch5, step543]: loss 0.296252
[epoch5, step544]: loss 0.266516
[epoch5, step545]: loss 0.321516
[epoch5, step546]: loss 0.278451
[epoch5, step547]: loss 0.272523
[epoch5, step548]: loss 0.301716
[epoch5, step549]: loss 0.264702
[epoch5, step550]: loss 0.308145
[epoch5, step551]: loss 0.290776
[epoch5, step552]: loss 0.298980
[epoch5, step553]: loss 0.269427
[epoch5, step554]: loss 0.316498
[epoch5, step555]: loss 0.286831
[epoch5, step556]: loss 0.263407
[epoch5, step557]: loss 0.304892
[epoch5, step558]: loss 0.264026
[epoch5, step559]: loss 0.313631
[epoch5, step560]: loss 0.289030
[epoch5, step561]: loss 0.295978
[epoch5, step562]: loss 0.268045
[epoch5, step563]: loss 0.370145
[epoch5, step564]: loss 0.280330
[epoch5, step565]: loss 0.221133
[epoch5, step566]: loss 0.234024
[epoch5, step567]: loss 0.229463
[epoch5, step568]: loss 0.259821
[epoch5, step569]: loss 0.310209
[epoch5, step570]: loss 0.261955
[epoch5, step571]: loss 0.184051
[epoch5, step572]: loss 0.258787
[epoch5, step573]: loss 0.269944
[epoch5, step574]: loss 0.331329
[epoch5, step575]: loss 0.288050
[epoch5, step576]: loss 0.296190
[epoch5, step577]: loss 0.248368
[epoch5, step578]: loss 0.296930
[epoch5, step579]: loss 0.233327
[epoch5, step580]: loss 0.337135
[epoch5, step581]: loss 0.293191
[epoch5, step582]: loss 0.284670
[epoch5, step583]: loss 0.290538
[epoch5, step584]: loss 0.270638
[epoch5, step585]: loss 0.321184
[epoch5, step586]: loss 0.284330
[epoch5, step587]: loss 0.201006
[epoch5, step588]: loss 0.286293
[epoch5, step589]: loss 0.376361
[epoch5, step590]: loss 0.214354
[epoch5, step591]: loss 0.278540
[epoch5, step592]: loss 0.305877
[epoch5, step593]: loss 0.371209
[epoch5, step594]: loss 0.219144
[epoch5, step595]: loss 0.220140
[epoch5, step596]: loss 0.311256
[epoch5, step597]: loss 0.321218
[epoch5, step598]: loss 0.236435
[epoch5, step599]: loss 0.219672
[epoch5, step600]: loss 0.213075
[epoch5, step601]: loss 0.280972
[epoch5, step602]: loss 0.335193
[epoch5, step603]: loss 0.245440
[epoch5, step604]: loss 0.239985
[epoch5, step605]: loss 0.212339
[epoch5, step606]: loss 0.270508
[epoch5, step607]: loss 0.296049
[epoch5, step608]: loss 0.184730
[epoch5, step609]: loss 0.279151
[epoch5, step610]: loss 0.245300
[epoch5, step611]: loss 0.308152
[epoch5, step612]: loss 0.281381
[epoch5, step613]: loss 0.312419
[epoch5, step614]: loss 0.272365
[epoch5, step615]: loss 0.279037
[epoch5, step616]: loss 0.222831
[epoch5, step617]: loss 0.257619
[epoch5, step618]: loss 0.303289
[epoch5, step619]: loss 0.227793
[epoch5, step620]: loss 0.211314
[epoch5, step621]: loss 0.205299
[epoch5, step622]: loss 0.297287
[epoch5, step623]: loss 0.285163
[epoch5, step624]: loss 0.284944
[epoch5, step625]: loss 0.209250
[epoch5, step626]: loss 0.285816
[epoch5, step627]: loss 0.331918
[epoch5, step628]: loss 0.301717
[epoch5, step629]: loss 0.166024
[epoch5, step630]: loss 0.238218
[epoch5, step631]: loss 0.233372
[epoch5, step632]: loss 0.286970
[epoch5, step633]: loss 0.233327
[epoch5, step634]: loss 0.268667
[epoch5, step635]: loss 0.256887
[epoch5, step636]: loss 0.226808
[epoch5, step637]: loss 0.302254
[epoch5, step638]: loss 0.278473
[epoch5, step639]: loss 0.215293
[epoch5, step640]: loss 0.287876
[epoch5, step641]: loss 0.220236
[epoch5, step642]: loss 0.216729
[epoch5, step643]: loss 0.291438
[epoch5, step644]: loss 0.254504
[epoch5, step645]: loss 0.196814
[epoch5, step646]: loss 0.263137
[epoch5, step647]: loss 0.202986
[epoch5, step648]: loss 0.332110
[epoch5, step649]: loss 0.279842
[epoch5, step650]: loss 0.302533
[epoch5, step651]: loss 0.250616
[epoch5, step652]: loss 0.317137
[epoch5, step653]: loss 0.304312
[epoch5, step654]: loss 0.294937
[epoch5, step655]: loss 0.222938
[epoch5, step656]: loss 0.311305
[epoch5, step657]: loss 0.305517
[epoch5, step658]: loss 0.235971
[epoch5, step659]: loss 0.201512
[epoch5, step660]: loss 0.265516
[epoch5, step661]: loss 0.283048
[epoch5, step662]: loss 0.205691
[epoch5, step663]: loss 0.260621
[epoch5, step664]: loss 0.250207
[epoch5, step665]: loss 0.319479
[epoch5, step666]: loss 0.212368
[epoch5, step667]: loss 0.280204
[epoch5, step668]: loss 0.326326
[epoch5, step669]: loss 0.215640
[epoch5, step670]: loss 0.270108
[epoch5, step671]: loss 0.280764
[epoch5, step672]: loss 0.338131
[epoch5, step673]: loss 0.311523
[epoch5, step674]: loss 0.258014
[epoch5, step675]: loss 0.300824
[epoch5, step676]: loss 0.289515
[epoch5, step677]: loss 0.245853
[epoch5, step678]: loss 0.213087
[epoch5, step679]: loss 0.261873
[epoch5, step680]: loss 0.207769
[epoch5, step681]: loss 0.216660
[epoch5, step682]: loss 0.221665
[epoch5, step683]: loss 0.267827
[epoch5, step684]: loss 0.221242
[epoch5, step685]: loss 0.223234
[epoch5, step686]: loss 0.212886
[epoch5, step687]: loss 0.234450
[epoch5, step688]: loss 0.289153
[epoch5, step689]: loss 0.222821
[epoch5, step690]: loss 0.299419
[epoch5, step691]: loss 0.312280
[epoch5, step692]: loss 0.301615
[epoch5, step693]: loss 0.272940
[epoch5, step694]: loss 0.206414
[epoch5, step695]: loss 0.241324
[epoch5, step696]: loss 0.221442
[epoch5, step697]: loss 0.272806
[epoch5, step698]: loss 0.243325
[epoch5, step699]: loss 0.249016
[epoch5, step700]: loss 0.333955
[epoch5, step701]: loss 0.284344
[epoch5, step702]: loss 0.243576
[epoch5, step703]: loss 0.325537
[epoch5, step704]: loss 0.299280
[epoch5, step705]: loss 0.223994
[epoch5, step706]: loss 0.232822
[epoch5, step707]: loss 0.240785
[epoch5, step708]: loss 0.265818
[epoch5, step709]: loss 0.228551
[epoch5, step710]: loss 0.273929
[epoch5, step711]: loss 0.301182
[epoch5, step712]: loss 0.203093
[epoch5, step713]: loss 0.237082
[epoch5, step714]: loss 0.285181
[epoch5, step715]: loss 0.234003
[epoch5, step716]: loss 0.272697
[epoch5, step717]: loss 0.228469
[epoch5, step718]: loss 0.255073
[epoch5, step719]: loss 0.255339
[epoch5, step720]: loss 0.226200
[epoch5, step721]: loss 0.250978
[epoch5, step722]: loss 0.262238
[epoch5, step723]: loss 0.253526
[epoch5, step724]: loss 0.277315
[epoch5, step725]: loss 0.272895
[epoch5, step726]: loss 0.191121
[epoch5, step727]: loss 0.269340
[epoch5, step728]: loss 0.273945
[epoch5, step729]: loss 0.220982
[epoch5, step730]: loss 0.274842
[epoch5, step731]: loss 0.297766
[epoch5, step732]: loss 0.248576
[epoch5, step733]: loss 0.202135
[epoch5, step734]: loss 0.231738
[epoch5, step735]: loss 0.227709
[epoch5, step736]: loss 0.243737
[epoch5, step737]: loss 0.213397
[epoch5, step738]: loss 0.233329
[epoch5, step739]: loss 0.327098
[epoch5, step740]: loss 0.351343
[epoch5, step741]: loss 0.266002
[epoch5, step742]: loss 0.307622
[epoch5, step743]: loss 0.261495
[epoch5, step744]: loss 0.253565
[epoch5, step745]: loss 0.257031
[epoch5, step746]: loss 0.279068
[epoch5, step747]: loss 0.248462
[epoch5, step748]: loss 0.223559
[epoch5, step749]: loss 0.329575
[epoch5, step750]: loss 0.276306
[epoch5, step751]: loss 0.243872
[epoch5, step752]: loss 0.215573
[epoch5, step753]: loss 0.221492
[epoch5, step754]: loss 0.304340
[epoch5, step755]: loss 0.273247
[epoch5, step756]: loss 0.201856
[epoch5, step757]: loss 0.257208
[epoch5, step758]: loss 0.283070
[epoch5, step759]: loss 0.224249
[epoch5, step760]: loss 0.272698
[epoch5, step761]: loss 0.244903
[epoch5, step762]: loss 0.233664
[epoch5, step763]: loss 0.233475
[epoch5, step764]: loss 0.268842
[epoch5, step765]: loss 0.230839
[epoch5, step766]: loss 0.214776
[epoch5, step767]: loss 0.277957
[epoch5, step768]: loss 0.258828
[epoch5, step769]: loss 0.256432
[epoch5, step770]: loss 0.321338
[epoch5, step771]: loss 0.214325
[epoch5, step772]: loss 0.212578
[epoch5, step773]: loss 0.245763
[epoch5, step774]: loss 0.256995
[epoch5, step775]: loss 0.317500
[epoch5, step776]: loss 0.272235
[epoch5, step777]: loss 0.238706
[epoch5, step778]: loss 0.289157
[epoch5, step779]: loss 0.246742
[epoch5, step780]: loss 0.282425
[epoch5, step781]: loss 0.321088
[epoch5, step782]: loss 0.304165
[epoch5, step783]: loss 0.263815
[epoch5, step784]: loss 0.301219
[epoch5, step785]: loss 0.291849
[epoch5, step786]: loss 0.253530
[epoch5, step787]: loss 0.317162
[epoch5, step788]: loss 0.261990
[epoch5, step789]: loss 0.303741
[epoch5, step790]: loss 0.212774
[epoch5, step791]: loss 0.273484
[epoch5, step792]: loss 0.277019
[epoch5, step793]: loss 0.279532
[epoch5, step794]: loss 0.265287
[epoch5, step795]: loss 0.252533
[epoch5, step796]: loss 0.241091
[epoch5, step797]: loss 0.220230
[epoch5, step798]: loss 0.221046
[epoch5, step799]: loss 0.188446
[epoch5, step800]: loss 0.333265
[epoch5, step801]: loss 0.310547
[epoch5, step802]: loss 0.252391
[epoch5, step803]: loss 0.230947
[epoch5, step804]: loss 0.272160
[epoch5, step805]: loss 0.240935
[epoch5, step806]: loss 0.261813
[epoch5, step807]: loss 0.288129
[epoch5, step808]: loss 0.317679
[epoch5, step809]: loss 0.235303
[epoch5, step810]: loss 0.196791
[epoch5, step811]: loss 0.253598
[epoch5, step812]: loss 0.278847
[epoch5, step813]: loss 0.233820
[epoch5, step814]: loss 0.263666
[epoch5, step815]: loss 0.248785
[epoch5, step816]: loss 0.257239
[epoch5, step817]: loss 0.220982
[epoch5, step818]: loss 0.242246
[epoch5, step819]: loss 0.373603
[epoch5, step820]: loss 0.228347
[epoch5, step821]: loss 0.223522
[epoch5, step822]: loss 0.260898
[epoch5, step823]: loss 0.220401
[epoch5, step824]: loss 0.254436
[epoch5, step825]: loss 0.268890
[epoch5, step826]: loss 0.183629
[epoch5, step827]: loss 0.227037
[epoch5, step828]: loss 0.249196
[epoch5, step829]: loss 0.232102
[epoch5, step830]: loss 0.176374
[epoch5, step831]: loss 0.218417
[epoch5, step832]: loss 0.319715
[epoch5, step833]: loss 0.259958
[epoch5, step834]: loss 0.255388
[epoch5, step835]: loss 0.267985
[epoch5, step836]: loss 0.223469
[epoch5, step837]: loss 0.209213
[epoch5, step838]: loss 0.287266
[epoch5, step839]: loss 0.250768
[epoch5, step840]: loss 0.232582
[epoch5, step841]: loss 0.249709
[epoch5, step842]: loss 0.246901
[epoch5, step843]: loss 0.283346
[epoch5, step844]: loss 0.284990
[epoch5, step845]: loss 0.272014
[epoch5, step846]: loss 0.335965
[epoch5, step847]: loss 0.252836
[epoch5, step848]: loss 0.138221
[epoch5, step849]: loss 0.231196
[epoch5, step850]: loss 0.286826
[epoch5, step851]: loss 0.243883
[epoch5, step852]: loss 0.251804
[epoch5, step853]: loss 0.272028
[epoch5, step854]: loss 0.286764
[epoch5, step855]: loss 0.224908
[epoch5, step856]: loss 0.205039
[epoch5, step857]: loss 0.267626
[epoch5, step858]: loss 0.277416
[epoch5, step859]: loss 0.227704
[epoch5, step860]: loss 0.290262
[epoch5, step861]: loss 0.260639
[epoch5, step862]: loss 0.205407
[epoch5, step863]: loss 0.285608
[epoch5, step864]: loss 0.292052
[epoch5, step865]: loss 0.269675
[epoch5, step866]: loss 0.282913
[epoch5, step867]: loss 0.235494
[epoch5, step868]: loss 0.262433
[epoch5, step869]: loss 0.222688
[epoch5, step870]: loss 0.204237
[epoch5, step871]: loss 0.318764
[epoch5, step872]: loss 0.274995
[epoch5, step873]: loss 0.210512
[epoch5, step874]: loss 0.248944
[epoch5, step875]: loss 0.324085
[epoch5, step876]: loss 0.291743
[epoch5, step877]: loss 0.160259
[epoch5, step878]: loss 0.226073
[epoch5, step879]: loss 0.238760
[epoch5, step880]: loss 0.230289
[epoch5, step881]: loss 0.293789
[epoch5, step882]: loss 0.225946
[epoch5, step883]: loss 0.236865
[epoch5, step884]: loss 0.310824
[epoch5, step885]: loss 0.313514
[epoch5, step886]: loss 0.297371
[epoch5, step887]: loss 0.318002
[epoch5, step888]: loss 0.239144
[epoch5, step889]: loss 0.278048
[epoch5, step890]: loss 0.280676
[epoch5, step891]: loss 0.236168
[epoch5, step892]: loss 0.283731
[epoch5, step893]: loss 0.270594
[epoch5, step894]: loss 0.273996
[epoch5, step895]: loss 0.211791
[epoch5, step896]: loss 0.346224
[epoch5, step897]: loss 0.341575
[epoch5, step898]: loss 0.220701
[epoch5, step899]: loss 0.155608
[epoch5, step900]: loss 0.251149
[epoch5, step901]: loss 0.295693
[epoch5, step902]: loss 0.225923
[epoch5, step903]: loss 0.304087
[epoch5, step904]: loss 0.218418
[epoch5, step905]: loss 0.207292
[epoch5, step906]: loss 0.200727
[epoch5, step907]: loss 0.279387
[epoch5, step908]: loss 0.307099
[epoch5, step909]: loss 0.243783
[epoch5, step910]: loss 0.205041
[epoch5, step911]: loss 0.195069
[epoch5, step912]: loss 0.282329
[epoch5, step913]: loss 0.288214
[epoch5, step914]: loss 0.248092
[epoch5, step915]: loss 0.225594
[epoch5, step916]: loss 0.264069
[epoch5, step917]: loss 0.253908
[epoch5, step918]: loss 0.284871
[epoch5, step919]: loss 0.209864
[epoch5, step920]: loss 0.292281
[epoch5, step921]: loss 0.230890
[epoch5, step922]: loss 0.239148
[epoch5, step923]: loss 0.304419
[epoch5, step924]: loss 0.234655
[epoch5, step925]: loss 0.232078
[epoch5, step926]: loss 0.235483
[epoch5, step927]: loss 0.297715
[epoch5, step928]: loss 0.227304
[epoch5, step929]: loss 0.240073
[epoch5, step930]: loss 0.251087
[epoch5, step931]: loss 0.277074
[epoch5, step932]: loss 0.229040
[epoch5, step933]: loss 0.232787
[epoch5, step934]: loss 0.308620
[epoch5, step935]: loss 0.261508
[epoch5, step936]: loss 0.227138
[epoch5, step937]: loss 0.201242
[epoch5, step938]: loss 0.319651
[epoch5, step939]: loss 0.237165
[epoch5, step940]: loss 0.286200
[epoch5, step941]: loss 0.260718
[epoch5, step942]: loss 0.257311
[epoch5, step943]: loss 0.301113
[epoch5, step944]: loss 0.257899
[epoch5, step945]: loss 0.292660
[epoch5, step946]: loss 0.251112
[epoch5, step947]: loss 0.222051
[epoch5, step948]: loss 0.361771
[epoch5, step949]: loss 0.257741
[epoch5, step950]: loss 0.243280
[epoch5, step951]: loss 0.265069
[epoch5, step952]: loss 0.280311
[epoch5, step953]: loss 0.249159
[epoch5, step954]: loss 0.274858
[epoch5, step955]: loss 0.194093
[epoch5, step956]: loss 0.290049
[epoch5, step957]: loss 0.263762
[epoch5, step958]: loss 0.310506
[epoch5, step959]: loss 0.278651
[epoch5, step960]: loss 0.255693
[epoch5, step961]: loss 0.279561
[epoch5, step962]: loss 0.281302
[epoch5, step963]: loss 0.292367
[epoch5, step964]: loss 0.265052
[epoch5, step965]: loss 0.298660
[epoch5, step966]: loss 0.259498
[epoch5, step967]: loss 0.299020
[epoch5, step968]: loss 0.275974
[epoch5, step969]: loss 0.242128
[epoch5, step970]: loss 0.276421
[epoch5, step971]: loss 0.279320
[epoch5, step972]: loss 0.281510
[epoch5, step973]: loss 0.271098
[epoch5, step974]: loss 0.282091
[epoch5, step975]: loss 0.256810
[epoch5, step976]: loss 0.300698
[epoch5, step977]: loss 0.267038
[epoch5, step978]: loss 0.241520
[epoch5, step979]: loss 0.280629
[epoch5, step980]: loss 0.279905
[epoch5, step981]: loss 0.286089
[epoch5, step982]: loss 0.262697
[epoch5, step983]: loss 0.284416
[epoch5, step984]: loss 0.259284
[epoch5, step985]: loss 0.300023
[epoch5, step986]: loss 0.264095
[epoch5, step987]: loss 0.235777
[epoch5, step988]: loss 0.268541
[epoch5, step989]: loss 0.273024
[epoch5, step990]: loss 0.285381
[epoch5, step991]: loss 0.257024
[epoch5, step992]: loss 0.285493
[epoch5, step993]: loss 0.259022
[epoch5, step994]: loss 0.303412
[epoch5, step995]: loss 0.269580
[epoch5, step996]: loss 0.241904
[epoch5, step997]: loss 0.271638
[epoch5, step998]: loss 0.271495
[epoch5, step999]: loss 0.281883
[epoch5, step1000]: loss 0.262137
[epoch5, step1001]: loss 0.283220
[epoch5, step1002]: loss 0.252175
[epoch5, step1003]: loss 0.299187
[epoch5, step1004]: loss 0.265603
[epoch5, step1005]: loss 0.244764
[epoch5, step1006]: loss 0.272566
[epoch5, step1007]: loss 0.277771
[epoch5, step1008]: loss 0.285645
[epoch5, step1009]: loss 0.261622
[epoch5, step1010]: loss 0.277950
[epoch5, step1011]: loss 0.254432
[epoch5, step1012]: loss 0.292175
[epoch5, step1013]: loss 0.266962
[epoch5, step1014]: loss 0.237143
[epoch5, step1015]: loss 0.269298
[epoch5, step1016]: loss 0.277048
[epoch5, step1017]: loss 0.285900
[epoch5, step1018]: loss 0.260852
[epoch5, step1019]: loss 0.282292
[epoch5, step1020]: loss 0.257788
[epoch5, step1021]: loss 0.297700
[epoch5, step1022]: loss 0.268327
[epoch5, step1023]: loss 0.240696
[epoch5, step1024]: loss 0.263307
[epoch5, step1025]: loss 0.279891
[epoch5, step1026]: loss 0.288461
[epoch5, step1027]: loss 0.258952
[epoch5, step1028]: loss 0.282594
[epoch5, step1029]: loss 0.254722
[epoch5, step1030]: loss 0.299369
[epoch5, step1031]: loss 0.280436
[epoch5, step1032]: loss 0.238631
[epoch5, step1033]: loss 0.277913
[epoch5, step1034]: loss 0.277439
[epoch5, step1035]: loss 0.288740
[epoch5, step1036]: loss 0.262519
[epoch5, step1037]: loss 0.284675
[epoch5, step1038]: loss 0.255522
[epoch5, step1039]: loss 0.294442
[epoch5, step1040]: loss 0.272815
[epoch5, step1041]: loss 0.242635
[epoch5, step1042]: loss 0.274676
[epoch5, step1043]: loss 0.275712
[epoch5, step1044]: loss 0.280908
[epoch5, step1045]: loss 0.258496
[epoch5, step1046]: loss 0.281216
[epoch5, step1047]: loss 0.251760
[epoch5, step1048]: loss 0.300277
[epoch5, step1049]: loss 0.267386
[epoch5, step1050]: loss 0.239030
[epoch5, step1051]: loss 0.270175
[epoch5, step1052]: loss 0.272478
[epoch5, step1053]: loss 0.282407
[epoch5, step1054]: loss 0.262109
[epoch5, step1055]: loss 0.286406
[epoch5, step1056]: loss 0.258731
[epoch5, step1057]: loss 0.289534
[epoch5, step1058]: loss 0.260047
[epoch5, step1059]: loss 0.238668
[epoch5, step1060]: loss 0.266239
[epoch5, step1061]: loss 0.281084
[epoch5, step1062]: loss 0.278255
[epoch5, step1063]: loss 0.260965
[epoch5, step1064]: loss 0.282251
[epoch5, step1065]: loss 0.257346
[epoch5, step1066]: loss 0.298335
[epoch5, step1067]: loss 0.266923
[epoch5, step1068]: loss 0.252407
[epoch5, step1069]: loss 0.267547
[epoch5, step1070]: loss 0.273926
[epoch5, step1071]: loss 0.276218
[epoch5, step1072]: loss 0.253594
[epoch5, step1073]: loss 0.282717
[epoch5, step1074]: loss 0.257024
[epoch5, step1075]: loss 0.291797
[epoch5, step1076]: loss 0.265348
[epoch5, step1077]: loss 0.238349
[epoch5, step1078]: loss 0.272282
[epoch5, step1079]: loss 0.265968
[epoch5, step1080]: loss 0.278292
[epoch5, step1081]: loss 0.263998
[epoch5, step1082]: loss 0.282593
[epoch5, step1083]: loss 0.250172
[epoch5, step1084]: loss 0.292151
[epoch5, step1085]: loss 0.271071
[epoch5, step1086]: loss 0.243270
[epoch5, step1087]: loss 0.270393
[epoch5, step1088]: loss 0.275731
[epoch5, step1089]: loss 0.277429
[epoch5, step1090]: loss 0.255057
[epoch5, step1091]: loss 0.278865
[epoch5, step1092]: loss 0.254854
[epoch5, step1093]: loss 0.293111
[epoch5, step1094]: loss 0.274292
[epoch5, step1095]: loss 0.239803
[epoch5, step1096]: loss 0.274253
[epoch5, step1097]: loss 0.271829
[epoch5, step1098]: loss 0.281806
[epoch5, step1099]: loss 0.262608
[epoch5, step1100]: loss 0.275671
[epoch5, step1101]: loss 0.255045
[epoch5, step1102]: loss 0.295431
[epoch5, step1103]: loss 0.270278
[epoch5, step1104]: loss 0.238649
[epoch5, step1105]: loss 0.266283
[epoch5, step1106]: loss 0.280372
[epoch5, step1107]: loss 0.279373
[epoch5, step1108]: loss 0.262451
[epoch5, step1109]: loss 0.276444
[epoch5, step1110]: loss 0.247388
[epoch5, step1111]: loss 0.291659
[epoch5, step1112]: loss 0.262458
[epoch5, step1113]: loss 0.239109
[epoch5, step1114]: loss 0.267072
[epoch5, step1115]: loss 0.270139
[epoch5, step1116]: loss 0.278529
[epoch5, step1117]: loss 0.257499
[epoch5, step1118]: loss 0.281066
[epoch5, step1119]: loss 0.258044
[epoch5, step1120]: loss 0.294894
[epoch5, step1121]: loss 0.266190
[epoch5, step1122]: loss 0.239714
[epoch5, step1123]: loss 0.273374
[epoch5, step1124]: loss 0.267487
[epoch5, step1125]: loss 0.276626
[epoch5, step1126]: loss 0.251843
[epoch5, step1127]: loss 0.278538
[epoch5, step1128]: loss 0.253110
[epoch5, step1129]: loss 0.293837
[epoch5, step1130]: loss 0.257380
[epoch5, step1131]: loss 0.234490
[epoch5, step1132]: loss 0.264900
[epoch5, step1133]: loss 0.275940
[epoch5, step1134]: loss 0.280579
[epoch5, step1135]: loss 0.248246
[epoch5, step1136]: loss 0.273386
[epoch5, step1137]: loss 0.248883
[epoch5, step1138]: loss 0.289740
[epoch5, step1139]: loss 0.266514
[epoch5, step1140]: loss 0.237981
[epoch5, step1141]: loss 0.265558
[epoch5, step1142]: loss 0.274986
[epoch5, step1143]: loss 0.282667
[epoch5, step1144]: loss 0.258708
[epoch5, step1145]: loss 0.283223
[epoch5, step1146]: loss 0.250855
[epoch5, step1147]: loss 0.283885
[epoch5, step1148]: loss 0.264908
[epoch5, step1149]: loss 0.236817
[epoch5, step1150]: loss 0.270721
[epoch5, step1151]: loss 0.269923
[epoch5, step1152]: loss 0.272864
[epoch5, step1153]: loss 0.260994
[epoch5, step1154]: loss 0.275503
[epoch5, step1155]: loss 0.249486
[epoch5, step1156]: loss 0.297053
[epoch5, step1157]: loss 0.267546
[epoch5, step1158]: loss 0.233622
[epoch5, step1159]: loss 0.264389
[epoch5, step1160]: loss 0.265444
[epoch5, step1161]: loss 0.273221
[epoch5, step1162]: loss 0.258099
[epoch5, step1163]: loss 0.283636
[epoch5, step1164]: loss 0.248953
[epoch5, step1165]: loss 0.281346
[epoch5, step1166]: loss 0.261917
[epoch5, step1167]: loss 0.238686
[epoch5, step1168]: loss 0.265106
[epoch5, step1169]: loss 0.272217
[epoch5, step1170]: loss 0.277472
[epoch5, step1171]: loss 0.258161
[epoch5, step1172]: loss 0.278732
[epoch5, step1173]: loss 0.250706
[epoch5, step1174]: loss 0.286596
[epoch5, step1175]: loss 0.265702
[epoch5, step1176]: loss 0.237415
[epoch5, step1177]: loss 0.261634
[epoch5, step1178]: loss 0.267853
[epoch5, step1179]: loss 0.277916
[epoch5, step1180]: loss 0.254997
[epoch5, step1181]: loss 0.272900
[epoch5, step1182]: loss 0.253271
[epoch5, step1183]: loss 0.284470
[epoch5, step1184]: loss 0.268507
[epoch5, step1185]: loss 0.238000
[epoch5, step1186]: loss 0.268264
[epoch5, step1187]: loss 0.277505
[epoch5, step1188]: loss 0.280744
[epoch5, step1189]: loss 0.256618
[epoch5, step1190]: loss 0.280499
[epoch5, step1191]: loss 0.248478
[epoch5, step1192]: loss 0.286758
[epoch5, step1193]: loss 0.262544
[epoch5, step1194]: loss 0.236605
[epoch5, step1195]: loss 0.276102
[epoch5, step1196]: loss 0.275376
[epoch5, step1197]: loss 0.275086
[epoch5, step1198]: loss 0.254214
[epoch5, step1199]: loss 0.279443
[epoch5, step1200]: loss 0.249764
[epoch5, step1201]: loss 0.284927
[epoch5, step1202]: loss 0.255430
[epoch5, step1203]: loss 0.239011
[epoch5, step1204]: loss 0.267704
[epoch5, step1205]: loss 0.271169
[epoch5, step1206]: loss 0.280487
[epoch5, step1207]: loss 0.249990
[epoch5, step1208]: loss 0.274250
[epoch5, step1209]: loss 0.253970
[epoch5, step1210]: loss 0.283920
[epoch5, step1211]: loss 0.267272
[epoch5, step1212]: loss 0.238551
[epoch5, step1213]: loss 0.270119
[epoch5, step1214]: loss 0.267684
[epoch5, step1215]: loss 0.270160
[epoch5, step1216]: loss 0.255283
[epoch5, step1217]: loss 0.271413
[epoch5, step1218]: loss 0.248829
[epoch5, step1219]: loss 0.283071
[epoch5, step1220]: loss 0.258595
[epoch5, step1221]: loss 0.238792
[epoch5, step1222]: loss 0.263893
[epoch5, step1223]: loss 0.268664
[epoch5, step1224]: loss 0.270451
[epoch5, step1225]: loss 0.254252
[epoch5, step1226]: loss 0.279396
[epoch5, step1227]: loss 0.245683
[epoch5, step1228]: loss 0.290012
[epoch5, step1229]: loss 0.266314
[epoch5, step1230]: loss 0.237219
[epoch5, step1231]: loss 0.267436
[epoch5, step1232]: loss 0.261262
[epoch5, step1233]: loss 0.276230
[epoch5, step1234]: loss 0.255602
[epoch5, step1235]: loss 0.271839
[epoch5, step1236]: loss 0.251554
[epoch5, step1237]: loss 0.291291
[epoch5, step1238]: loss 0.266998
[epoch5, step1239]: loss 0.230578
[epoch5, step1240]: loss 0.260325
[epoch5, step1241]: loss 0.274263
[epoch5, step1242]: loss 0.275854
[epoch5, step1243]: loss 0.251959
[epoch5, step1244]: loss 0.273167
[epoch5, step1245]: loss 0.243194
[epoch5, step1246]: loss 0.285030
[epoch5, step1247]: loss 0.268882
[epoch5, step1248]: loss 0.235357
[epoch5, step1249]: loss 0.259265
[epoch5, step1250]: loss 0.268659
[epoch5, step1251]: loss 0.272937
[epoch5, step1252]: loss 0.250497
[epoch5, step1253]: loss 0.272304
[epoch5, step1254]: loss 0.246707
[epoch5, step1255]: loss 0.286122
[epoch5, step1256]: loss 0.257101
[epoch5, step1257]: loss 0.231946
[epoch5, step1258]: loss 0.263459
[epoch5, step1259]: loss 0.269404
[epoch5, step1260]: loss 0.273444
[epoch5, step1261]: loss 0.255315
[epoch5, step1262]: loss 0.283221
[epoch5, step1263]: loss 0.240890
[epoch5, step1264]: loss 0.288239
[epoch5, step1265]: loss 0.272190
[epoch5, step1266]: loss 0.235717
[epoch5, step1267]: loss 0.263015
[epoch5, step1268]: loss 0.266040
[epoch5, step1269]: loss 0.272182
[epoch5, step1270]: loss 0.258163
[epoch5, step1271]: loss 0.270667
[epoch5, step1272]: loss 0.245461
[epoch5, step1273]: loss 0.288986
[epoch5, step1274]: loss 0.264337
[epoch5, step1275]: loss 0.233359
[epoch5, step1276]: loss 0.263389
[epoch5, step1277]: loss 0.267630
[epoch5, step1278]: loss 0.268139
[epoch5, step1279]: loss 0.250952
[epoch5, step1280]: loss 0.272274
[epoch5, step1281]: loss 0.247187
[epoch5, step1282]: loss 0.285312
[epoch5, step1283]: loss 0.265165
[epoch5, step1284]: loss 0.232225
[epoch5, step1285]: loss 0.261144
[epoch5, step1286]: loss 0.271167
[epoch5, step1287]: loss 0.266290
[epoch5, step1288]: loss 0.247192
[epoch5, step1289]: loss 0.265990
[epoch5, step1290]: loss 0.248618
[epoch5, step1291]: loss 0.287167
[epoch5, step1292]: loss 0.253978
[epoch5, step1293]: loss 0.235291
[epoch5, step1294]: loss 0.260693
[epoch5, step1295]: loss 0.261697
[epoch5, step1296]: loss 0.270268
[epoch5, step1297]: loss 0.249425
[epoch5, step1298]: loss 0.268194
[epoch5, step1299]: loss 0.246427
[epoch5, step1300]: loss 0.280674
[epoch5, step1301]: loss 0.268780
[epoch5, step1302]: loss 0.231831
[epoch5, step1303]: loss 0.263936
[epoch5, step1304]: loss 0.270609
[epoch5, step1305]: loss 0.267555
[epoch5, step1306]: loss 0.252817
[epoch5, step1307]: loss 0.277350
[epoch5, step1308]: loss 0.247156
[epoch5, step1309]: loss 0.289979
[epoch5, step1310]: loss 0.260488
[epoch5, step1311]: loss 0.237559
[epoch5, step1312]: loss 0.259950
[epoch5, step1313]: loss 0.265004
[epoch5, step1314]: loss 0.273752
[epoch5, step1315]: loss 0.252149
[epoch5, step1316]: loss 0.261238
[epoch5, step1317]: loss 0.249423
[epoch5, step1318]: loss 0.289542
[epoch5, step1319]: loss 0.262529
[epoch5, step1320]: loss 0.231814
[epoch5, step1321]: loss 0.255793
[epoch5, step1322]: loss 0.268860
[epoch5, step1323]: loss 0.268001
[epoch5, step1324]: loss 0.253752
[epoch5, step1325]: loss 0.272573
[epoch5, step1326]: loss 0.249760
[epoch5, step1327]: loss 0.284117
[epoch5, step1328]: loss 0.259357
[epoch5, step1329]: loss 0.232731
[epoch5, step1330]: loss 0.259661
[epoch5, step1331]: loss 0.268286
[epoch5, step1332]: loss 0.273188
[epoch5, step1333]: loss 0.260425
[epoch5, step1334]: loss 0.268468
[epoch5, step1335]: loss 0.244202
[epoch5, step1336]: loss 0.282545
[epoch5, step1337]: loss 0.265327
[epoch5, step1338]: loss 0.231834
[epoch5, step1339]: loss 0.263161
[epoch5, step1340]: loss 0.269241
[epoch5, step1341]: loss 0.270679
[epoch5, step1342]: loss 0.251111
[epoch5, step1343]: loss 0.269290
[epoch5, step1344]: loss 0.242505
[epoch5, step1345]: loss 0.282394
[epoch5, step1346]: loss 0.262011
[epoch5, step1347]: loss 0.227499
[epoch5, step1348]: loss 0.264260
[epoch5, step1349]: loss 0.264413
[epoch5, step1350]: loss 0.267918
[epoch5, step1351]: loss 0.257538
[epoch5, step1352]: loss 0.274719
[epoch5, step1353]: loss 0.249717
[epoch5, step1354]: loss 0.286499
[epoch5, step1355]: loss 0.258274
[epoch5, step1356]: loss 0.237859
[epoch5, step1357]: loss 0.265611
[epoch5, step1358]: loss 0.265196
[epoch5, step1359]: loss 0.272874
[epoch5, step1360]: loss 0.246770
[epoch5, step1361]: loss 0.268371
[epoch5, step1362]: loss 0.242368
[epoch5, step1363]: loss 0.277335
[epoch5, step1364]: loss 0.258220
[epoch5, step1365]: loss 0.232036
[epoch5, step1366]: loss 0.260286
[epoch5, step1367]: loss 0.269358
[epoch5, step1368]: loss 0.260876
[epoch5, step1369]: loss 0.251197
[epoch5, step1370]: loss 0.272737
[epoch5, step1371]: loss 0.242073
[epoch5, step1372]: loss 0.282285
[epoch5, step1373]: loss 0.258233
[epoch5, step1374]: loss 0.225615
[epoch5, step1375]: loss 0.255222
[epoch5, step1376]: loss 0.264313
[epoch5, step1377]: loss 0.277074
[epoch5, step1378]: loss 0.250335
[epoch5, step1379]: loss 0.273544
[epoch5, step1380]: loss 0.238528
[epoch5, step1381]: loss 0.281080
[epoch5, step1382]: loss 0.256309
[epoch5, step1383]: loss 0.230939
[epoch5, step1384]: loss 0.257326
[epoch5, step1385]: loss 0.266944
[epoch5, step1386]: loss 0.267069
[epoch5, step1387]: loss 0.244004
[epoch5, step1388]: loss 0.278081
[epoch5, step1389]: loss 0.247247
[epoch5, step1390]: loss 0.279956
[epoch5, step1391]: loss 0.258566
[epoch5, step1392]: loss 0.232496
[epoch5, step1393]: loss 0.255262
[epoch5, step1394]: loss 0.258119
[epoch5, step1395]: loss 0.267350
[epoch5, step1396]: loss 0.249438
[epoch5, step1397]: loss 0.271339
[epoch5, step1398]: loss 0.242183
[epoch5, step1399]: loss 0.272527
[epoch5, step1400]: loss 0.255446
[epoch5, step1401]: loss 0.228328
[epoch5, step1402]: loss 0.257888
[epoch5, step1403]: loss 0.270185
[epoch5, step1404]: loss 0.271507
[epoch5, step1405]: loss 0.245594
[epoch5, step1406]: loss 0.271738
[epoch5, step1407]: loss 0.235498
[epoch5, step1408]: loss 0.285809
[epoch5, step1409]: loss 0.260615
[epoch5, step1410]: loss 0.227278
[epoch5, step1411]: loss 0.266862
[epoch5, step1412]: loss 0.262037
[epoch5, step1413]: loss 0.267960
[epoch5, step1414]: loss 0.251403
[epoch5, step1415]: loss 0.271246
[epoch5, step1416]: loss 0.240792
[epoch5, step1417]: loss 0.281909
[epoch5, step1418]: loss 0.257561
[epoch5, step1419]: loss 0.224962
[epoch5, step1420]: loss 0.258248
[epoch5, step1421]: loss 0.259057
[epoch5, step1422]: loss 0.264571
[epoch5, step1423]: loss 0.250718
[epoch5, step1424]: loss 0.268072
[epoch5, step1425]: loss 0.246097
[epoch5, step1426]: loss 0.279970
[epoch5, step1427]: loss 0.250281
[epoch5, step1428]: loss 0.228909
[epoch5, step1429]: loss 0.255692
[epoch5, step1430]: loss 0.263861
[epoch5, step1431]: loss 0.266632
[epoch5, step1432]: loss 0.249520
[epoch5, step1433]: loss 0.267673
[epoch5, step1434]: loss 0.250426
[epoch5, step1435]: loss 0.275764
[epoch5, step1436]: loss 0.253590
[epoch5, step1437]: loss 0.226444
[epoch5, step1438]: loss 0.255414
[epoch5, step1439]: loss 0.264082
[epoch5, step1440]: loss 0.268958
[epoch5, step1441]: loss 0.242830
[epoch5, step1442]: loss 0.274568
[epoch5, step1443]: loss 0.249095
[epoch5, step1444]: loss 0.284634
[epoch5, step1445]: loss 0.253182
[epoch5, step1446]: loss 0.225418
[epoch5, step1447]: loss 0.253383
[epoch5, step1448]: loss 0.262711
[epoch5, step1449]: loss 0.270362
[epoch5, step1450]: loss 0.248028
[epoch5, step1451]: loss 0.265213
[epoch5, step1452]: loss 0.243994
[epoch5, step1453]: loss 0.271039
[epoch5, step1454]: loss 0.252081
[epoch5, step1455]: loss 0.222022
[epoch5, step1456]: loss 0.259621
[epoch5, step1457]: loss 0.255833
[epoch5, step1458]: loss 0.265628
[epoch5, step1459]: loss 0.250566
[epoch5, step1460]: loss 0.263653
[epoch5, step1461]: loss 0.236428
[epoch5, step1462]: loss 0.272012
[epoch5, step1463]: loss 0.257060
[epoch5, step1464]: loss 0.224230
[epoch5, step1465]: loss 0.261407
[epoch5, step1466]: loss 0.262657
[epoch5, step1467]: loss 0.269515
[epoch5, step1468]: loss 0.249309
[epoch5, step1469]: loss 0.268066
[epoch5, step1470]: loss 0.239600
[epoch5, step1471]: loss 0.282585
[epoch5, step1472]: loss 0.257115
[epoch5, step1473]: loss 0.225854
[epoch5, step1474]: loss 0.251339
[epoch5, step1475]: loss 0.262868
[epoch5, step1476]: loss 0.260902
[epoch5, step1477]: loss 0.250936
[epoch5, step1478]: loss 0.266555
[epoch5, step1479]: loss 0.240697
[epoch5, step1480]: loss 0.277785
[epoch5, step1481]: loss 0.263391
[epoch5, step1482]: loss 0.228160
[epoch5, step1483]: loss 0.256380
[epoch5, step1484]: loss 0.258572
[epoch5, step1485]: loss 0.265496
[epoch5, step1486]: loss 0.253706
[epoch5, step1487]: loss 0.267527
[epoch5, step1488]: loss 0.239162
[epoch5, step1489]: loss 0.278918
[epoch5, step1490]: loss 0.253043
[epoch5, step1491]: loss 0.228757
[epoch5, step1492]: loss 0.259551
[epoch5, step1493]: loss 0.260865
[epoch5, step1494]: loss 0.265173
[epoch5, step1495]: loss 0.251771
[epoch5, step1496]: loss 0.273099
[epoch5, step1497]: loss 0.238159
[epoch5, step1498]: loss 0.273600
[epoch5, step1499]: loss 0.259315
[epoch5, step1500]: loss 0.225956
[epoch5, step1501]: loss 0.255527
[epoch5, step1502]: loss 0.260793
[epoch5, step1503]: loss 0.267120
[epoch5, step1504]: loss 0.251141
[epoch5, step1505]: loss 0.264289
[epoch5, step1506]: loss 0.242261
[epoch5, step1507]: loss 0.273995
[epoch5, step1508]: loss 0.250674
[epoch5, step1509]: loss 0.229849
[epoch5, step1510]: loss 0.264380
[epoch5, step1511]: loss 0.254249
[epoch5, step1512]: loss 0.262552
[epoch5, step1513]: loss 0.255690
[epoch5, step1514]: loss 0.266349
[epoch5, step1515]: loss 0.238965
[epoch5, step1516]: loss 0.276351

[epoch5]: avg loss 0.275616

[epoch6, step1]: loss 0.294743
[epoch6, step2]: loss 0.262189
[epoch6, step3]: loss 0.265402
[epoch6, step4]: loss 0.248429
[epoch6, step5]: loss 0.276686
[epoch6, step6]: loss 0.254516
[epoch6, step7]: loss 0.233087
[epoch6, step8]: loss 0.266585
[epoch6, step9]: loss 0.239254
[epoch6, step10]: loss 0.267645
[epoch6, step11]: loss 0.260840
[epoch6, step12]: loss 0.263160
[epoch6, step13]: loss 0.238065
[epoch6, step14]: loss 0.275773
[epoch6, step15]: loss 0.254741
[epoch6, step16]: loss 0.233966
[epoch6, step17]: loss 0.262958
[epoch6, step18]: loss 0.230440
[epoch6, step19]: loss 0.271588
[epoch6, step20]: loss 0.253162
[epoch6, step21]: loss 0.264044
[epoch6, step22]: loss 0.243913
[epoch6, step23]: loss 0.285408
[epoch6, step24]: loss 0.251761
[epoch6, step25]: loss 0.235218
[epoch6, step26]: loss 0.271700
[epoch6, step27]: loss 0.239068
[epoch6, step28]: loss 0.270301
[epoch6, step29]: loss 0.257788
[epoch6, step30]: loss 0.256975
[epoch6, step31]: loss 0.241816
[epoch6, step32]: loss 0.273241
[epoch6, step33]: loss 0.248468
[epoch6, step34]: loss 0.230309
[epoch6, step35]: loss 0.263027
[epoch6, step36]: loss 0.238161
[epoch6, step37]: loss 0.271742
[epoch6, step38]: loss 0.260449
[epoch6, step39]: loss 0.262390
[epoch6, step40]: loss 0.236015
[epoch6, step41]: loss 0.281546
[epoch6, step42]: loss 0.249571
[epoch6, step43]: loss 0.236170
[epoch6, step44]: loss 0.263766
[epoch6, step45]: loss 0.237789
[epoch6, step46]: loss 0.271463
[epoch6, step47]: loss 0.262591
[epoch6, step48]: loss 0.264404
[epoch6, step49]: loss 0.246302
[epoch6, step50]: loss 0.276075
[epoch6, step51]: loss 0.252971
[epoch6, step52]: loss 0.236759
[epoch6, step53]: loss 0.259910
[epoch6, step54]: loss 0.234927
[epoch6, step55]: loss 0.267300
[epoch6, step56]: loss 0.249609
[epoch6, step57]: loss 0.258053
[epoch6, step58]: loss 0.237496
[epoch6, step59]: loss 0.284561
[epoch6, step60]: loss 0.246471
[epoch6, step61]: loss 0.237709
[epoch6, step62]: loss 0.269044
[epoch6, step63]: loss 0.241657
[epoch6, step64]: loss 0.276864
[epoch6, step65]: loss 0.256064
[epoch6, step66]: loss 0.261229
[epoch6, step67]: loss 0.240410
[epoch6, step68]: loss 0.276764
[epoch6, step69]: loss 0.251779
[epoch6, step70]: loss 0.235628
[epoch6, step71]: loss 0.267994
[epoch6, step72]: loss 0.234996
[epoch6, step73]: loss 0.272052
[epoch6, step74]: loss 0.256021
[epoch6, step75]: loss 0.258940
[epoch6, step76]: loss 0.238192
[epoch6, step77]: loss 0.270404
[epoch6, step78]: loss 0.249256
[epoch6, step79]: loss 0.237466
[epoch6, step80]: loss 0.257534
[epoch6, step81]: loss 0.233268
[epoch6, step82]: loss 0.275267
[epoch6, step83]: loss 0.263736
[epoch6, step84]: loss 0.258974
[epoch6, step85]: loss 0.233669
[epoch6, step86]: loss 0.272261
[epoch6, step87]: loss 0.243582
[epoch6, step88]: loss 0.247614
[epoch6, step89]: loss 0.267512
[epoch6, step90]: loss 0.236869
[epoch6, step91]: loss 0.278612
[epoch6, step92]: loss 0.255553
[epoch6, step93]: loss 0.258637
[epoch6, step94]: loss 0.241144
[epoch6, step95]: loss 0.271111
[epoch6, step96]: loss 0.252506
[epoch6, step97]: loss 0.229875
[epoch6, step98]: loss 0.263866
[epoch6, step99]: loss 0.235940
[epoch6, step100]: loss 0.278415
[epoch6, step101]: loss 0.250954
[epoch6, step102]: loss 0.260771
[epoch6, step103]: loss 0.239801
[epoch6, step104]: loss 0.274598
[epoch6, step105]: loss 0.246772
[epoch6, step106]: loss 0.234751
[epoch6, step107]: loss 0.264158
[epoch6, step108]: loss 0.233339
[epoch6, step109]: loss 0.272492
[epoch6, step110]: loss 0.251090
[epoch6, step111]: loss 0.260810
[epoch6, step112]: loss 0.240338
[epoch6, step113]: loss 0.267389
[epoch6, step114]: loss 0.251573
[epoch6, step115]: loss 0.234049
[epoch6, step116]: loss 0.257126
[epoch6, step117]: loss 0.233174
[epoch6, step118]: loss 0.263547
[epoch6, step119]: loss 0.252101
[epoch6, step120]: loss 0.256613
[epoch6, step121]: loss 0.239501
[epoch6, step122]: loss 0.273568
[epoch6, step123]: loss 0.246218
[epoch6, step124]: loss 0.233221
[epoch6, step125]: loss 0.258668
[epoch6, step126]: loss 0.235715
[epoch6, step127]: loss 0.271308
[epoch6, step128]: loss 0.256145
[epoch6, step129]: loss 0.258294
[epoch6, step130]: loss 0.233979
[epoch6, step131]: loss 0.277988
[epoch6, step132]: loss 0.247534
[epoch6, step133]: loss 0.231801
[epoch6, step134]: loss 0.267555
[epoch6, step135]: loss 0.230173
[epoch6, step136]: loss 0.259588
[epoch6, step137]: loss 0.257252
[epoch6, step138]: loss 0.258529
[epoch6, step139]: loss 0.236937
[epoch6, step140]: loss 0.268955
[epoch6, step141]: loss 0.246096
[epoch6, step142]: loss 0.232272
[epoch6, step143]: loss 0.265236
[epoch6, step144]: loss 0.237138
[epoch6, step145]: loss 0.269212
[epoch6, step146]: loss 0.254669
[epoch6, step147]: loss 0.248188
[epoch6, step148]: loss 0.236049
[epoch6, step149]: loss 0.277212
[epoch6, step150]: loss 0.251129
[epoch6, step151]: loss 0.228548
[epoch6, step152]: loss 0.261541
[epoch6, step153]: loss 0.230499
[epoch6, step154]: loss 0.273337
[epoch6, step155]: loss 0.253677
[epoch6, step156]: loss 0.261267
[epoch6, step157]: loss 0.233847
[epoch6, step158]: loss 0.269204
[epoch6, step159]: loss 0.246104
[epoch6, step160]: loss 0.228897
[epoch6, step161]: loss 0.256084
[epoch6, step162]: loss 0.230850
[epoch6, step163]: loss 0.269236
[epoch6, step164]: loss 0.250176
[epoch6, step165]: loss 0.256755
[epoch6, step166]: loss 0.231397
[epoch6, step167]: loss 0.275259
[epoch6, step168]: loss 0.241158
[epoch6, step169]: loss 0.234096
[epoch6, step170]: loss 0.258135
[epoch6, step171]: loss 0.230671
[epoch6, step172]: loss 0.267428
[epoch6, step173]: loss 0.250814
[epoch6, step174]: loss 0.258780
[epoch6, step175]: loss 0.228101
[epoch6, step176]: loss 0.270118
[epoch6, step177]: loss 0.244203
[epoch6, step178]: loss 0.225983
[epoch6, step179]: loss 0.266522
[epoch6, step180]: loss 0.226717
[epoch6, step181]: loss 0.265507
[epoch6, step182]: loss 0.249684
[epoch6, step183]: loss 0.251234
[epoch6, step184]: loss 0.227884
[epoch6, step185]: loss 0.269219
[epoch6, step186]: loss 0.243683
[epoch6, step187]: loss 0.231584
[epoch6, step188]: loss 0.261682
[epoch6, step189]: loss 0.228842
[epoch6, step190]: loss 0.272207
[epoch6, step191]: loss 0.253648
[epoch6, step192]: loss 0.251113
[epoch6, step193]: loss 0.247267
[epoch6, step194]: loss 0.276707
[epoch6, step195]: loss 0.243152
[epoch6, step196]: loss 0.227624
[epoch6, step197]: loss 0.260763
[epoch6, step198]: loss 0.235572
[epoch6, step199]: loss 0.266097
[epoch6, step200]: loss 0.246709
[epoch6, step201]: loss 0.251206
[epoch6, step202]: loss 0.235130
[epoch6, step203]: loss 0.270268
[epoch6, step204]: loss 0.241752
[epoch6, step205]: loss 0.235113
[epoch6, step206]: loss 0.261653
[epoch6, step207]: loss 0.229557
[epoch6, step208]: loss 0.262094
[epoch6, step209]: loss 0.248383
[epoch6, step210]: loss 0.247907
[epoch6, step211]: loss 0.231979
[epoch6, step212]: loss 0.267477
[epoch6, step213]: loss 0.247155
[epoch6, step214]: loss 0.236600
[epoch6, step215]: loss 0.257179
[epoch6, step216]: loss 0.228513
[epoch6, step217]: loss 0.272667
[epoch6, step218]: loss 0.247800
[epoch6, step219]: loss 0.256299
[epoch6, step220]: loss 0.236265
[epoch6, step221]: loss 0.267247
[epoch6, step222]: loss 0.241439
[epoch6, step223]: loss 0.223972
[epoch6, step224]: loss 0.260970
[epoch6, step225]: loss 0.228554
[epoch6, step226]: loss 0.268697
[epoch6, step227]: loss 0.257764
[epoch6, step228]: loss 0.249868
[epoch6, step229]: loss 0.239089
[epoch6, step230]: loss 0.265717
[epoch6, step231]: loss 0.240326
[epoch6, step232]: loss 0.230850
[epoch6, step233]: loss 0.264303
[epoch6, step234]: loss 0.232720
[epoch6, step235]: loss 0.265969
[epoch6, step236]: loss 0.249285
[epoch6, step237]: loss 0.253671
[epoch6, step238]: loss 0.232207
[epoch6, step239]: loss 0.273858
[epoch6, step240]: loss 0.250525
[epoch6, step241]: loss 0.227077
[epoch6, step242]: loss 0.259542
[epoch6, step243]: loss 0.227171
[epoch6, step244]: loss 0.267344
[epoch6, step245]: loss 0.253349
[epoch6, step246]: loss 0.253958
[epoch6, step247]: loss 0.232747
[epoch6, step248]: loss 0.271232
[epoch6, step249]: loss 0.247552
[epoch6, step250]: loss 0.227117
[epoch6, step251]: loss 0.253475
[epoch6, step252]: loss 0.225521
[epoch6, step253]: loss 0.269409
[epoch6, step254]: loss 0.255389
[epoch6, step255]: loss 0.251472
[epoch6, step256]: loss 0.236565
[epoch6, step257]: loss 0.269771
[epoch6, step258]: loss 0.239050
[epoch6, step259]: loss 0.225554
[epoch6, step260]: loss 0.262118
[epoch6, step261]: loss 0.221725
[epoch6, step262]: loss 0.261034
[epoch6, step263]: loss 0.255421
[epoch6, step264]: loss 0.254773
[epoch6, step265]: loss 0.232596
[epoch6, step266]: loss 0.268616
[epoch6, step267]: loss 0.249664
[epoch6, step268]: loss 0.227880
[epoch6, step269]: loss 0.256487
[epoch6, step270]: loss 0.230547
[epoch6, step271]: loss 0.263195
[epoch6, step272]: loss 0.249786
[epoch6, step273]: loss 0.254743
[epoch6, step274]: loss 0.227127
[epoch6, step275]: loss 0.272752
[epoch6, step276]: loss 0.247173
[epoch6, step277]: loss 0.225351
[epoch6, step278]: loss 0.255580
[epoch6, step279]: loss 0.226710
[epoch6, step280]: loss 0.262965
[epoch6, step281]: loss 0.250791
[epoch6, step282]: loss 0.248264
[epoch6, step283]: loss 0.234990
[epoch6, step284]: loss 0.271127
[epoch6, step285]: loss 0.237078
[epoch6, step286]: loss 0.239400
[epoch6, step287]: loss 0.255454
[epoch6, step288]: loss 0.231305
[epoch6, step289]: loss 0.260295
[epoch6, step290]: loss 0.248944
[epoch6, step291]: loss 0.249974
[epoch6, step292]: loss 0.237048
[epoch6, step293]: loss 0.268964
[epoch6, step294]: loss 0.246516
[epoch6, step295]: loss 0.229579
[epoch6, step296]: loss 0.250903
[epoch6, step297]: loss 0.230573
[epoch6, step298]: loss 0.262647
[epoch6, step299]: loss 0.255240
[epoch6, step300]: loss 0.249041
[epoch6, step301]: loss 0.234911
[epoch6, step302]: loss 0.263658
[epoch6, step303]: loss 0.239434
[epoch6, step304]: loss 0.226263
[epoch6, step305]: loss 0.258869
[epoch6, step306]: loss 0.227231
[epoch6, step307]: loss 0.267353
[epoch6, step308]: loss 0.244387
[epoch6, step309]: loss 0.247868
[epoch6, step310]: loss 0.231789
[epoch6, step311]: loss 0.262970
[epoch6, step312]: loss 0.244219
[epoch6, step313]: loss 0.227245
[epoch6, step314]: loss 0.255521
[epoch6, step315]: loss 0.224079
[epoch6, step316]: loss 0.265737
[epoch6, step317]: loss 0.246592
[epoch6, step318]: loss 0.250752
[epoch6, step319]: loss 0.235769
[epoch6, step320]: loss 0.273848
[epoch6, step321]: loss 0.245022
[epoch6, step322]: loss 0.232932
[epoch6, step323]: loss 0.260792
[epoch6, step324]: loss 0.223050
[epoch6, step325]: loss 0.262114
[epoch6, step326]: loss 0.249832
[epoch6, step327]: loss 0.255868
[epoch6, step328]: loss 0.231815
[epoch6, step329]: loss 0.269024
[epoch6, step330]: loss 0.246980
[epoch6, step331]: loss 0.228463
[epoch6, step332]: loss 0.259862
[epoch6, step333]: loss 0.229389
[epoch6, step334]: loss 0.261500
[epoch6, step335]: loss 0.247060
[epoch6, step336]: loss 0.244676
[epoch6, step337]: loss 0.226966
[epoch6, step338]: loss 0.270036
[epoch6, step339]: loss 0.243838
[epoch6, step340]: loss 0.226852
[epoch6, step341]: loss 0.258677
[epoch6, step342]: loss 0.226786
[epoch6, step343]: loss 0.260507
[epoch6, step344]: loss 0.249494
[epoch6, step345]: loss 0.255577
[epoch6, step346]: loss 0.234192
[epoch6, step347]: loss 0.268409
[epoch6, step348]: loss 0.239716
[epoch6, step349]: loss 0.223393
[epoch6, step350]: loss 0.259061
[epoch6, step351]: loss 0.228972
[epoch6, step352]: loss 0.262474
[epoch6, step353]: loss 0.248197
[epoch6, step354]: loss 0.258057
[epoch6, step355]: loss 0.235577
[epoch6, step356]: loss 0.260784
[epoch6, step357]: loss 0.240615
[epoch6, step358]: loss 0.236594
[epoch6, step359]: loss 0.248895
[epoch6, step360]: loss 0.228718
[epoch6, step361]: loss 0.265954
[epoch6, step362]: loss 0.243192
[epoch6, step363]: loss 0.252676
[epoch6, step364]: loss 0.231504
[epoch6, step365]: loss 0.266681
[epoch6, step366]: loss 0.238538
[epoch6, step367]: loss 0.228611
[epoch6, step368]: loss 0.258818
[epoch6, step369]: loss 0.228025
[epoch6, step370]: loss 0.257740
[epoch6, step371]: loss 0.240500
[epoch6, step372]: loss 0.252551
[epoch6, step373]: loss 0.230974
[epoch6, step374]: loss 0.269794
[epoch6, step375]: loss 0.235989
[epoch6, step376]: loss 0.221595
[epoch6, step377]: loss 0.252788
[epoch6, step378]: loss 0.226073
[epoch6, step379]: loss 0.257156
[epoch6, step380]: loss 0.242517
[epoch6, step381]: loss 0.251953
[epoch6, step382]: loss 0.234463
[epoch6, step383]: loss 0.273045
[epoch6, step384]: loss 0.245703
[epoch6, step385]: loss 0.222110
[epoch6, step386]: loss 0.252622
[epoch6, step387]: loss 0.222979
[epoch6, step388]: loss 0.254978
[epoch6, step389]: loss 0.246013
[epoch6, step390]: loss 0.241537
[epoch6, step391]: loss 0.229699
[epoch6, step392]: loss 0.259350
[epoch6, step393]: loss 0.243681
[epoch6, step394]: loss 0.228432
[epoch6, step395]: loss 0.255661
[epoch6, step396]: loss 0.224172
[epoch6, step397]: loss 0.265361
[epoch6, step398]: loss 0.244882
[epoch6, step399]: loss 0.249593
[epoch6, step400]: loss 0.228609
[epoch6, step401]: loss 0.265231
[epoch6, step402]: loss 0.241614
[epoch6, step403]: loss 0.223416
[epoch6, step404]: loss 0.251452
[epoch6, step405]: loss 0.222018
[epoch6, step406]: loss 0.257254
[epoch6, step407]: loss 0.247540
[epoch6, step408]: loss 0.248038
[epoch6, step409]: loss 0.218389
[epoch6, step410]: loss 0.259105
[epoch6, step411]: loss 0.239951
[epoch6, step412]: loss 0.225334
[epoch6, step413]: loss 0.253433
[epoch6, step414]: loss 0.230505
[epoch6, step415]: loss 0.258979
[epoch6, step416]: loss 0.249695
[epoch6, step417]: loss 0.246897
[epoch6, step418]: loss 0.227490
[epoch6, step419]: loss 0.268351
[epoch6, step420]: loss 0.236673
[epoch6, step421]: loss 0.225469
[epoch6, step422]: loss 0.252637
[epoch6, step423]: loss 0.223703
[epoch6, step424]: loss 0.257671
[epoch6, step425]: loss 0.243573
[epoch6, step426]: loss 0.245490
[epoch6, step427]: loss 0.230727
[epoch6, step428]: loss 0.264025
[epoch6, step429]: loss 0.232685
[epoch6, step430]: loss 0.224052
[epoch6, step431]: loss 0.249838
[epoch6, step432]: loss 0.222703
[epoch6, step433]: loss 0.252633
[epoch6, step434]: loss 0.245251
[epoch6, step435]: loss 0.244825
[epoch6, step436]: loss 0.233659
[epoch6, step437]: loss 0.261336
[epoch6, step438]: loss 0.233225
[epoch6, step439]: loss 0.225058
[epoch6, step440]: loss 0.251996
[epoch6, step441]: loss 0.221203
[epoch6, step442]: loss 0.258688
[epoch6, step443]: loss 0.240305
[epoch6, step444]: loss 0.250517
[epoch6, step445]: loss 0.226083
[epoch6, step446]: loss 0.259503
[epoch6, step447]: loss 0.233486
[epoch6, step448]: loss 0.220026
[epoch6, step449]: loss 0.253200
[epoch6, step450]: loss 0.229176
[epoch6, step451]: loss 0.259836
[epoch6, step452]: loss 0.252293
[epoch6, step453]: loss 0.245729
[epoch6, step454]: loss 0.229893
[epoch6, step455]: loss 0.260355
[epoch6, step456]: loss 0.243476
[epoch6, step457]: loss 0.220513
[epoch6, step458]: loss 0.253216
[epoch6, step459]: loss 0.217998
[epoch6, step460]: loss 0.259047
[epoch6, step461]: loss 0.238482
[epoch6, step462]: loss 0.251716
[epoch6, step463]: loss 0.227192
[epoch6, step464]: loss 0.263011
[epoch6, step465]: loss 0.227549
[epoch6, step466]: loss 0.221372
[epoch6, step467]: loss 0.253570
[epoch6, step468]: loss 0.224667
[epoch6, step469]: loss 0.257174
[epoch6, step470]: loss 0.241632
[epoch6, step471]: loss 0.249175
[epoch6, step472]: loss 0.228089
[epoch6, step473]: loss 0.264200
[epoch6, step474]: loss 0.239100
[epoch6, step475]: loss 0.222366
[epoch6, step476]: loss 0.247303
[epoch6, step477]: loss 0.223225
[epoch6, step478]: loss 0.260989
[epoch6, step479]: loss 0.243294
[epoch6, step480]: loss 0.252271
[epoch6, step481]: loss 0.228676
[epoch6, step482]: loss 0.265899
[epoch6, step483]: loss 0.233756
[epoch6, step484]: loss 0.216318
[epoch6, step485]: loss 0.249544
[epoch6, step486]: loss 0.219989
[epoch6, step487]: loss 0.261536
[epoch6, step488]: loss 0.240165
[epoch6, step489]: loss 0.252084
[epoch6, step490]: loss 0.226571
[epoch6, step491]: loss 0.258413
[epoch6, step492]: loss 0.238372
[epoch6, step493]: loss 0.221211
[epoch6, step494]: loss 0.254657
[epoch6, step495]: loss 0.212663
[epoch6, step496]: loss 0.258240
[epoch6, step497]: loss 0.241045
[epoch6, step498]: loss 0.245990
[epoch6, step499]: loss 0.226453
[epoch6, step500]: loss 0.264154
[epoch6, step501]: loss 0.240918
[epoch6, step502]: loss 0.221762
[epoch6, step503]: loss 0.248776
[epoch6, step504]: loss 0.227859
[epoch6, step505]: loss 0.264190
[epoch6, step506]: loss 0.237520
[epoch6, step507]: loss 0.242644
[epoch6, step508]: loss 0.223822
[epoch6, step509]: loss 0.262369
[epoch6, step510]: loss 0.235419
[epoch6, step511]: loss 0.223609
[epoch6, step512]: loss 0.246938
[epoch6, step513]: loss 0.222201
[epoch6, step514]: loss 0.255046
[epoch6, step515]: loss 0.241888
[epoch6, step516]: loss 0.241984
[epoch6, step517]: loss 0.227660
[epoch6, step518]: loss 0.259534
[epoch6, step519]: loss 0.235382
[epoch6, step520]: loss 0.220435
[epoch6, step521]: loss 0.252325
[epoch6, step522]: loss 0.223718
[epoch6, step523]: loss 0.256348
[epoch6, step524]: loss 0.247323
[epoch6, step525]: loss 0.242152
[epoch6, step526]: loss 0.221212
[epoch6, step527]: loss 0.262803
[epoch6, step528]: loss 0.233219
[epoch6, step529]: loss 0.224998
[epoch6, step530]: loss 0.246827
[epoch6, step531]: loss 0.221095
[epoch6, step532]: loss 0.259387
[epoch6, step533]: loss 0.233955
[epoch6, step534]: loss 0.245095
[epoch6, step535]: loss 0.223779
[epoch6, step536]: loss 0.258039
[epoch6, step537]: loss 0.234157
[epoch6, step538]: loss 0.224683
[epoch6, step539]: loss 0.250372
[epoch6, step540]: loss 0.227910
[epoch6, step541]: loss 0.259404
[epoch6, step542]: loss 0.241640
[epoch6, step543]: loss 0.245427
[epoch6, step544]: loss 0.220905
[epoch6, step545]: loss 0.265557
[epoch6, step546]: loss 0.231416
[epoch6, step547]: loss 0.225971
[epoch6, step548]: loss 0.249849
[epoch6, step549]: loss 0.219680
[epoch6, step550]: loss 0.254895
[epoch6, step551]: loss 0.241177
[epoch6, step552]: loss 0.247569
[epoch6, step553]: loss 0.223546
[epoch6, step554]: loss 0.261594
[epoch6, step555]: loss 0.238003
[epoch6, step556]: loss 0.218673
[epoch6, step557]: loss 0.252375
[epoch6, step558]: loss 0.219188
[epoch6, step559]: loss 0.259252
[epoch6, step560]: loss 0.239730
[epoch6, step561]: loss 0.245217
[epoch6, step562]: loss 0.222248
[epoch6, step563]: loss 0.303434
[epoch6, step564]: loss 0.231117
[epoch6, step565]: loss 0.183340
[epoch6, step566]: loss 0.194500
[epoch6, step567]: loss 0.189653
[epoch6, step568]: loss 0.213455
[epoch6, step569]: loss 0.254330
[epoch6, step570]: loss 0.215643
[epoch6, step571]: loss 0.152612
[epoch6, step572]: loss 0.212949
[epoch6, step573]: loss 0.222358
[epoch6, step574]: loss 0.273160
[epoch6, step575]: loss 0.236069
[epoch6, step576]: loss 0.243097
[epoch6, step577]: loss 0.204609
[epoch6, step578]: loss 0.243200
[epoch6, step579]: loss 0.192439
[epoch6, step580]: loss 0.275551
[epoch6, step581]: loss 0.240943
[epoch6, step582]: loss 0.233854
[epoch6, step583]: loss 0.238318
[epoch6, step584]: loss 0.222574
[epoch6, step585]: loss 0.263766
[epoch6, step586]: loss 0.233432
[epoch6, step587]: loss 0.166510
[epoch6, step588]: loss 0.235456
[epoch6, step589]: loss 0.307985
[epoch6, step590]: loss 0.177200
[epoch6, step591]: loss 0.228280
[epoch6, step592]: loss 0.251433
[epoch6, step593]: loss 0.303491
[epoch6, step594]: loss 0.180845
[epoch6, step595]: loss 0.181558
[epoch6, step596]: loss 0.255396
[epoch6, step597]: loss 0.263639
[epoch6, step598]: loss 0.195366
[epoch6, step599]: loss 0.181038
[epoch6, step600]: loss 0.175835
[epoch6, step601]: loss 0.230341
[epoch6, step602]: loss 0.274716
[epoch6, step603]: loss 0.202145
[epoch6, step604]: loss 0.197947
[epoch6, step605]: loss 0.175338
[epoch6, step606]: loss 0.222720
[epoch6, step607]: loss 0.243319
[epoch6, step608]: loss 0.153180
[epoch6, step609]: loss 0.229497
[epoch6, step610]: loss 0.203480
[epoch6, step611]: loss 0.253317
[epoch6, step612]: loss 0.231455
[epoch6, step613]: loss 0.255750
[epoch6, step614]: loss 0.224510
[epoch6, step615]: loss 0.229729
[epoch6, step616]: loss 0.183871
[epoch6, step617]: loss 0.211768
[epoch6, step618]: loss 0.249469
[epoch6, step619]: loss 0.188364
[epoch6, step620]: loss 0.174439
[epoch6, step621]: loss 0.169024
[epoch6, step622]: loss 0.243691
[epoch6, step623]: loss 0.234578
[epoch6, step624]: loss 0.234679
[epoch6, step625]: loss 0.172421
[epoch6, step626]: loss 0.234910
[epoch6, step627]: loss 0.272196
[epoch6, step628]: loss 0.247535
[epoch6, step629]: loss 0.136798
[epoch6, step630]: loss 0.196141
[epoch6, step631]: loss 0.193820
[epoch6, step632]: loss 0.235505
[epoch6, step633]: loss 0.192157
[epoch6, step634]: loss 0.222046
[epoch6, step635]: loss 0.211294
[epoch6, step636]: loss 0.186377
[epoch6, step637]: loss 0.248388
[epoch6, step638]: loss 0.229339
[epoch6, step639]: loss 0.177418
[epoch6, step640]: loss 0.237291
[epoch6, step641]: loss 0.182705
[epoch6, step642]: loss 0.178947
[epoch6, step643]: loss 0.239670
[epoch6, step644]: loss 0.209666
[epoch6, step645]: loss 0.162031
[epoch6, step646]: loss 0.216826
[epoch6, step647]: loss 0.167272
[epoch6, step648]: loss 0.272305
[epoch6, step649]: loss 0.230568
[epoch6, step650]: loss 0.247737
[epoch6, step651]: loss 0.206453
[epoch6, step652]: loss 0.260757
[epoch6, step653]: loss 0.250493
[epoch6, step654]: loss 0.241815
[epoch6, step655]: loss 0.184268
[epoch6, step656]: loss 0.255476
[epoch6, step657]: loss 0.251168
[epoch6, step658]: loss 0.194601
[epoch6, step659]: loss 0.166319
[epoch6, step660]: loss 0.218393
[epoch6, step661]: loss 0.233166
[epoch6, step662]: loss 0.169793
[epoch6, step663]: loss 0.213702
[epoch6, step664]: loss 0.205891
[epoch6, step665]: loss 0.262509
[epoch6, step666]: loss 0.175138
[epoch6, step667]: loss 0.230411
[epoch6, step668]: loss 0.267114
[epoch6, step669]: loss 0.177882
[epoch6, step670]: loss 0.222233
[epoch6, step671]: loss 0.230652
[epoch6, step672]: loss 0.277271
[epoch6, step673]: loss 0.255771
[epoch6, step674]: loss 0.211772
[epoch6, step675]: loss 0.246643
[epoch6, step676]: loss 0.238464
[epoch6, step677]: loss 0.202536
[epoch6, step678]: loss 0.175286
[epoch6, step679]: loss 0.215543
[epoch6, step680]: loss 0.172780
[epoch6, step681]: loss 0.178615
[epoch6, step682]: loss 0.183593
[epoch6, step683]: loss 0.220670
[epoch6, step684]: loss 0.182270
[epoch6, step685]: loss 0.184064
[epoch6, step686]: loss 0.175959
[epoch6, step687]: loss 0.193771
[epoch6, step688]: loss 0.237108
[epoch6, step689]: loss 0.183449
[epoch6, step690]: loss 0.245480
[epoch6, step691]: loss 0.256379
[epoch6, step692]: loss 0.247056
[epoch6, step693]: loss 0.224552
[epoch6, step694]: loss 0.170340
[epoch6, step695]: loss 0.198705
[epoch6, step696]: loss 0.183259
[epoch6, step697]: loss 0.223907
[epoch6, step698]: loss 0.200341
[epoch6, step699]: loss 0.205355
[epoch6, step700]: loss 0.273469
[epoch6, step701]: loss 0.233964
[epoch6, step702]: loss 0.200435
[epoch6, step703]: loss 0.266948
[epoch6, step704]: loss 0.245235
[epoch6, step705]: loss 0.184513
[epoch6, step706]: loss 0.192110
[epoch6, step707]: loss 0.198891
[epoch6, step708]: loss 0.218490
[epoch6, step709]: loss 0.189211
[epoch6, step710]: loss 0.224528
[epoch6, step711]: loss 0.246838
[epoch6, step712]: loss 0.168208
[epoch6, step713]: loss 0.195435
[epoch6, step714]: loss 0.233437
[epoch6, step715]: loss 0.192880
[epoch6, step716]: loss 0.224539
[epoch6, step717]: loss 0.188218
[epoch6, step718]: loss 0.209881
[epoch6, step719]: loss 0.211505
[epoch6, step720]: loss 0.185955
[epoch6, step721]: loss 0.206210
[epoch6, step722]: loss 0.216858
[epoch6, step723]: loss 0.208930
[epoch6, step724]: loss 0.227584
[epoch6, step725]: loss 0.224941
[epoch6, step726]: loss 0.157908
[epoch6, step727]: loss 0.221699
[epoch6, step728]: loss 0.225310
[epoch6, step729]: loss 0.181387
[epoch6, step730]: loss 0.225690
[epoch6, step731]: loss 0.244425
[epoch6, step732]: loss 0.204640
[epoch6, step733]: loss 0.166288
[epoch6, step734]: loss 0.190516
[epoch6, step735]: loss 0.188263
[epoch6, step736]: loss 0.200446
[epoch6, step737]: loss 0.176008
[epoch6, step738]: loss 0.191791
[epoch6, step739]: loss 0.268343
[epoch6, step740]: loss 0.287344
[epoch6, step741]: loss 0.218538
[epoch6, step742]: loss 0.251822
[epoch6, step743]: loss 0.214582
[epoch6, step744]: loss 0.208841
[epoch6, step745]: loss 0.211812
[epoch6, step746]: loss 0.228925
[epoch6, step747]: loss 0.204692
[epoch6, step748]: loss 0.184250
[epoch6, step749]: loss 0.270322
[epoch6, step750]: loss 0.227519
[epoch6, step751]: loss 0.200018
[epoch6, step752]: loss 0.177882
[epoch6, step753]: loss 0.182673
[epoch6, step754]: loss 0.249286
[epoch6, step755]: loss 0.224900
[epoch6, step756]: loss 0.166541
[epoch6, step757]: loss 0.211159
[epoch6, step758]: loss 0.232634
[epoch6, step759]: loss 0.184094
[epoch6, step760]: loss 0.224150
[epoch6, step761]: loss 0.202300
[epoch6, step762]: loss 0.191897
[epoch6, step763]: loss 0.192499
[epoch6, step764]: loss 0.220865
[epoch6, step765]: loss 0.189791
[epoch6, step766]: loss 0.177181
[epoch6, step767]: loss 0.228475
[epoch6, step768]: loss 0.212573
[epoch6, step769]: loss 0.211599
[epoch6, step770]: loss 0.263362
[epoch6, step771]: loss 0.176835
[epoch6, step772]: loss 0.176235
[epoch6, step773]: loss 0.202502
[epoch6, step774]: loss 0.211104
[epoch6, step775]: loss 0.259909
[epoch6, step776]: loss 0.223681
[epoch6, step777]: loss 0.196375
[epoch6, step778]: loss 0.237980
[epoch6, step779]: loss 0.202638
[epoch6, step780]: loss 0.231303
[epoch6, step781]: loss 0.263195
[epoch6, step782]: loss 0.249253
[epoch6, step783]: loss 0.215931
[epoch6, step784]: loss 0.246072
[epoch6, step785]: loss 0.239590
[epoch6, step786]: loss 0.208527
[epoch6, step787]: loss 0.259493
[epoch6, step788]: loss 0.215524
[epoch6, step789]: loss 0.248873
[epoch6, step790]: loss 0.175561
[epoch6, step791]: loss 0.225220
[epoch6, step792]: loss 0.227734
[epoch6, step793]: loss 0.229790
[epoch6, step794]: loss 0.217263
[epoch6, step795]: loss 0.207860
[epoch6, step796]: loss 0.198666
[epoch6, step797]: loss 0.181729
[epoch6, step798]: loss 0.182808
[epoch6, step799]: loss 0.156019
[epoch6, step800]: loss 0.272652
[epoch6, step801]: loss 0.254236
[epoch6, step802]: loss 0.207359
[epoch6, step803]: loss 0.190374
[epoch6, step804]: loss 0.224180
[epoch6, step805]: loss 0.198616
[epoch6, step806]: loss 0.214576
[epoch6, step807]: loss 0.236329
[epoch6, step808]: loss 0.259982
[epoch6, step809]: loss 0.193455
[epoch6, step810]: loss 0.162728
[epoch6, step811]: loss 0.209121
[epoch6, step812]: loss 0.229021
[epoch6, step813]: loss 0.192172
[epoch6, step814]: loss 0.217186
[epoch6, step815]: loss 0.205258
[epoch6, step816]: loss 0.211207
[epoch6, step817]: loss 0.181753
[epoch6, step818]: loss 0.199103
[epoch6, step819]: loss 0.305069
[epoch6, step820]: loss 0.187580
[epoch6, step821]: loss 0.183950
[epoch6, step822]: loss 0.215277
[epoch6, step823]: loss 0.181486
[epoch6, step824]: loss 0.209841
[epoch6, step825]: loss 0.221256
[epoch6, step826]: loss 0.151822
[epoch6, step827]: loss 0.187112
[epoch6, step828]: loss 0.205831
[epoch6, step829]: loss 0.191425
[epoch6, step830]: loss 0.145779
[epoch6, step831]: loss 0.180079
[epoch6, step832]: loss 0.261660
[epoch6, step833]: loss 0.214218
[epoch6, step834]: loss 0.209932
[epoch6, step835]: loss 0.219542
[epoch6, step836]: loss 0.184165
[epoch6, step837]: loss 0.173085
[epoch6, step838]: loss 0.236256
[epoch6, step839]: loss 0.206706
[epoch6, step840]: loss 0.191153
[epoch6, step841]: loss 0.205509
[epoch6, step842]: loss 0.203942
[epoch6, step843]: loss 0.232756
[epoch6, step844]: loss 0.233753
[epoch6, step845]: loss 0.222763
[epoch6, step846]: loss 0.275140
[epoch6, step847]: loss 0.208378
[epoch6, step848]: loss 0.114955
[epoch6, step849]: loss 0.190721
[epoch6, step850]: loss 0.235196
[epoch6, step851]: loss 0.200555
[epoch6, step852]: loss 0.207246
[epoch6, step853]: loss 0.224384
[epoch6, step854]: loss 0.235360
[epoch6, step855]: loss 0.185519
[epoch6, step856]: loss 0.168810
[epoch6, step857]: loss 0.220432
[epoch6, step858]: loss 0.227728
[epoch6, step859]: loss 0.187227
[epoch6, step860]: loss 0.238182
[epoch6, step861]: loss 0.214014
[epoch6, step862]: loss 0.169332
[epoch6, step863]: loss 0.234060
[epoch6, step864]: loss 0.239920
[epoch6, step865]: loss 0.221459
[epoch6, step866]: loss 0.232213
[epoch6, step867]: loss 0.194113
[epoch6, step868]: loss 0.216134
[epoch6, step869]: loss 0.183407
[epoch6, step870]: loss 0.169677
[epoch6, step871]: loss 0.260743
[epoch6, step872]: loss 0.225858
[epoch6, step873]: loss 0.173646
[epoch6, step874]: loss 0.204767
[epoch6, step875]: loss 0.265671
[epoch6, step876]: loss 0.239258
[epoch6, step877]: loss 0.131815
[epoch6, step878]: loss 0.186302
[epoch6, step879]: loss 0.197257
[epoch6, step880]: loss 0.189573
[epoch6, step881]: loss 0.240657
[epoch6, step882]: loss 0.185796
[epoch6, step883]: loss 0.194797
[epoch6, step884]: loss 0.255322
[epoch6, step885]: loss 0.257315
[epoch6, step886]: loss 0.244440
[epoch6, step887]: loss 0.260795
[epoch6, step888]: loss 0.196547
[epoch6, step889]: loss 0.228133
[epoch6, step890]: loss 0.230239
[epoch6, step891]: loss 0.194299
[epoch6, step892]: loss 0.232631
[epoch6, step893]: loss 0.222924
[epoch6, step894]: loss 0.225353
[epoch6, step895]: loss 0.174281
[epoch6, step896]: loss 0.282988
[epoch6, step897]: loss 0.279707
[epoch6, step898]: loss 0.181915
[epoch6, step899]: loss 0.129515
[epoch6, step900]: loss 0.206990
[epoch6, step901]: loss 0.242540
[epoch6, step902]: loss 0.185885
[epoch6, step903]: loss 0.249194
[epoch6, step904]: loss 0.180813
[epoch6, step905]: loss 0.171236
[epoch6, step906]: loss 0.165094
[epoch6, step907]: loss 0.229809
[epoch6, step908]: loss 0.251453
[epoch6, step909]: loss 0.200454
[epoch6, step910]: loss 0.168435
[epoch6, step911]: loss 0.161309
[epoch6, step912]: loss 0.231897
[epoch6, step913]: loss 0.236254
[epoch6, step914]: loss 0.205405
[epoch6, step915]: loss 0.185429
[epoch6, step916]: loss 0.217174
[epoch6, step917]: loss 0.209000
[epoch6, step918]: loss 0.234313
[epoch6, step919]: loss 0.172911
[epoch6, step920]: loss 0.240390
[epoch6, step921]: loss 0.189933
[epoch6, step922]: loss 0.196357
[epoch6, step923]: loss 0.249439
[epoch6, step924]: loss 0.192192
[epoch6, step925]: loss 0.191288
[epoch6, step926]: loss 0.194134
[epoch6, step927]: loss 0.243977
[epoch6, step928]: loss 0.187249
[epoch6, step929]: loss 0.197848
[epoch6, step930]: loss 0.206734
[epoch6, step931]: loss 0.227907
[epoch6, step932]: loss 0.188367
[epoch6, step933]: loss 0.192185
[epoch6, step934]: loss 0.252519
[epoch6, step935]: loss 0.214369
[epoch6, step936]: loss 0.186772
[epoch6, step937]: loss 0.166643
[epoch6, step938]: loss 0.261956
[epoch6, step939]: loss 0.194630
[epoch6, step940]: loss 0.234716
[epoch6, step941]: loss 0.214574
[epoch6, step942]: loss 0.211474
[epoch6, step943]: loss 0.246675
[epoch6, step944]: loss 0.212153
[epoch6, step945]: loss 0.239690
[epoch6, step946]: loss 0.206792
[epoch6, step947]: loss 0.183272
[epoch6, step948]: loss 0.295538
[epoch6, step949]: loss 0.211326
[epoch6, step950]: loss 0.201009
[epoch6, step951]: loss 0.219045
[epoch6, step952]: loss 0.230283
[epoch6, step953]: loss 0.205845
[epoch6, step954]: loss 0.225041
[epoch6, step955]: loss 0.161988
[epoch6, step956]: loss 0.241740
[epoch6, step957]: loss 0.219606
[epoch6, step958]: loss 0.257647
[epoch6, step959]: loss 0.233051
[epoch6, step960]: loss 0.213919
[epoch6, step961]: loss 0.233981
[epoch6, step962]: loss 0.234853
[epoch6, step963]: loss 0.243031
[epoch6, step964]: loss 0.220543
[epoch6, step965]: loss 0.246207
[epoch6, step966]: loss 0.215541
[epoch6, step967]: loss 0.248764
[epoch6, step968]: loss 0.230755
[epoch6, step969]: loss 0.203589
[epoch6, step970]: loss 0.231118
[epoch6, step971]: loss 0.233175
[epoch6, step972]: loss 0.235140
[epoch6, step973]: loss 0.226812
[epoch6, step974]: loss 0.235000
[epoch6, step975]: loss 0.213575
[epoch6, step976]: loss 0.248613
[epoch6, step977]: loss 0.222293
[epoch6, step978]: loss 0.202632
[epoch6, step979]: loss 0.233668
[epoch6, step980]: loss 0.231409
[epoch6, step981]: loss 0.237044
[epoch6, step982]: loss 0.218671
[epoch6, step983]: loss 0.236522
[epoch6, step984]: loss 0.215327
[epoch6, step985]: loss 0.247833
[epoch6, step986]: loss 0.220158
[epoch6, step987]: loss 0.198229
[epoch6, step988]: loss 0.224484
[epoch6, step989]: loss 0.226359
[epoch6, step990]: loss 0.236712
[epoch6, step991]: loss 0.214115
[epoch6, step992]: loss 0.237281
[epoch6, step993]: loss 0.215374
[epoch6, step994]: loss 0.250649
[epoch6, step995]: loss 0.224516
[epoch6, step996]: loss 0.202873
[epoch6, step997]: loss 0.226594
[epoch6, step998]: loss 0.225154
[epoch6, step999]: loss 0.233919
[epoch6, step1000]: loss 0.218351
[epoch6, step1001]: loss 0.235310
[epoch6, step1002]: loss 0.209776
[epoch6, step1003]: loss 0.247323
[epoch6, step1004]: loss 0.221406
[epoch6, step1005]: loss 0.204927
[epoch6, step1006]: loss 0.226899
[epoch6, step1007]: loss 0.230071
[epoch6, step1008]: loss 0.237045
[epoch6, step1009]: loss 0.217838
[epoch6, step1010]: loss 0.230853
[epoch6, step1011]: loss 0.211619
[epoch6, step1012]: loss 0.241754
[epoch6, step1013]: loss 0.222601
[epoch6, step1014]: loss 0.198451
[epoch6, step1015]: loss 0.223606
[epoch6, step1016]: loss 0.229844
[epoch6, step1017]: loss 0.237752
[epoch6, step1018]: loss 0.217097
[epoch6, step1019]: loss 0.234250
[epoch6, step1020]: loss 0.214058
[epoch6, step1021]: loss 0.245966
[epoch6, step1022]: loss 0.223596
[epoch6, step1023]: loss 0.200741
[epoch6, step1024]: loss 0.218752
[epoch6, step1025]: loss 0.232259
[epoch6, step1026]: loss 0.239576
[epoch6, step1027]: loss 0.215401
[epoch6, step1028]: loss 0.234330
[epoch6, step1029]: loss 0.211742
[epoch6, step1030]: loss 0.247362
[epoch6, step1031]: loss 0.232818
[epoch6, step1032]: loss 0.198841
[epoch6, step1033]: loss 0.230405
[epoch6, step1034]: loss 0.230092
[epoch6, step1035]: loss 0.239445
[epoch6, step1036]: loss 0.218178
[epoch6, step1037]: loss 0.236171
[epoch6, step1038]: loss 0.212249
[epoch6, step1039]: loss 0.243683
[epoch6, step1040]: loss 0.226736
[epoch6, step1041]: loss 0.201781
[epoch6, step1042]: loss 0.227695
[epoch6, step1043]: loss 0.228521
[epoch6, step1044]: loss 0.232961
[epoch6, step1045]: loss 0.214931
[epoch6, step1046]: loss 0.233178
[epoch6, step1047]: loss 0.209249
[epoch6, step1048]: loss 0.248380
[epoch6, step1049]: loss 0.222245
[epoch6, step1050]: loss 0.199209
[epoch6, step1051]: loss 0.224172
[epoch6, step1052]: loss 0.225963
[epoch6, step1053]: loss 0.234481
[epoch6, step1054]: loss 0.217770
[epoch6, step1055]: loss 0.237256
[epoch6, step1056]: loss 0.214734
[epoch6, step1057]: loss 0.239645
[epoch6, step1058]: loss 0.216532
[epoch6, step1059]: loss 0.198721
[epoch6, step1060]: loss 0.220924
[epoch6, step1061]: loss 0.232771
[epoch6, step1062]: loss 0.231023
[epoch6, step1063]: loss 0.216859
[epoch6, step1064]: loss 0.234013
[epoch6, step1065]: loss 0.213617
[epoch6, step1066]: loss 0.246697
[epoch6, step1067]: loss 0.221881
[epoch6, step1068]: loss 0.209584
[epoch6, step1069]: loss 0.221913
[epoch6, step1070]: loss 0.227081
[epoch6, step1071]: loss 0.229373
[epoch6, step1072]: loss 0.210972
[epoch6, step1073]: loss 0.234275
[epoch6, step1074]: loss 0.213336
[epoch6, step1075]: loss 0.241441
[epoch6, step1076]: loss 0.220619
[epoch6, step1077]: loss 0.198547
[epoch6, step1078]: loss 0.225677
[epoch6, step1079]: loss 0.220801
[epoch6, step1080]: loss 0.230925
[epoch6, step1081]: loss 0.219264
[epoch6, step1082]: loss 0.234224
[epoch6, step1083]: loss 0.207894
[epoch6, step1084]: loss 0.241802
[epoch6, step1085]: loss 0.225120
[epoch6, step1086]: loss 0.202411
[epoch6, step1087]: loss 0.224227
[epoch6, step1088]: loss 0.228467
[epoch6, step1089]: loss 0.230403
[epoch6, step1090]: loss 0.212076
[epoch6, step1091]: loss 0.231225
[epoch6, step1092]: loss 0.211545
[epoch6, step1093]: loss 0.242418
[epoch6, step1094]: loss 0.227734
[epoch6, step1095]: loss 0.199520
[epoch6, step1096]: loss 0.227206
[epoch6, step1097]: loss 0.225379
[epoch6, step1098]: loss 0.233745
[epoch6, step1099]: loss 0.218079
[epoch6, step1100]: loss 0.228700
[epoch6, step1101]: loss 0.211742
[epoch6, step1102]: loss 0.244426
[epoch6, step1103]: loss 0.224513
[epoch6, step1104]: loss 0.198694
[epoch6, step1105]: loss 0.220882
[epoch6, step1106]: loss 0.232093
[epoch6, step1107]: loss 0.231851
[epoch6, step1108]: loss 0.217911
[epoch6, step1109]: loss 0.229233
[epoch6, step1110]: loss 0.205627
[epoch6, step1111]: loss 0.241339
[epoch6, step1112]: loss 0.218383
[epoch6, step1113]: loss 0.199025
[epoch6, step1114]: loss 0.221497
[epoch6, step1115]: loss 0.223992
[epoch6, step1116]: loss 0.231246
[epoch6, step1117]: loss 0.213991
[epoch6, step1118]: loss 0.232938
[epoch6, step1119]: loss 0.214095
[epoch6, step1120]: loss 0.243988
[epoch6, step1121]: loss 0.221203
[epoch6, step1122]: loss 0.199367
[epoch6, step1123]: loss 0.226471
[epoch6, step1124]: loss 0.221891
[epoch6, step1125]: loss 0.229685
[epoch6, step1126]: loss 0.209510
[epoch6, step1127]: loss 0.230874
[epoch6, step1128]: loss 0.210126
[epoch6, step1129]: loss 0.243104
[epoch6, step1130]: loss 0.214182
[epoch6, step1131]: loss 0.195254
[epoch6, step1132]: loss 0.219752
[epoch6, step1133]: loss 0.228544
[epoch6, step1134]: loss 0.232780
[epoch6, step1135]: loss 0.206612
[epoch6, step1136]: loss 0.226804
[epoch6, step1137]: loss 0.206766
[epoch6, step1138]: loss 0.239788
[epoch6, step1139]: loss 0.221556
[epoch6, step1140]: loss 0.197939
[epoch6, step1141]: loss 0.220215
[epoch6, step1142]: loss 0.227792
[epoch6, step1143]: loss 0.234461
[epoch6, step1144]: loss 0.214916
[epoch6, step1145]: loss 0.234564
[epoch6, step1146]: loss 0.208329
[epoch6, step1147]: loss 0.235168
[epoch6, step1148]: loss 0.220301
[epoch6, step1149]: loss 0.197179
[epoch6, step1150]: loss 0.224334
[epoch6, step1151]: loss 0.223771
[epoch6, step1152]: loss 0.226624
[epoch6, step1153]: loss 0.216650
[epoch6, step1154]: loss 0.228451
[epoch6, step1155]: loss 0.207227
[epoch6, step1156]: loss 0.245596
[epoch6, step1157]: loss 0.222389
[epoch6, step1158]: loss 0.194662
[epoch6, step1159]: loss 0.219303
[epoch6, step1160]: loss 0.220235
[epoch6, step1161]: loss 0.226987
[epoch6, step1162]: loss 0.214369
[epoch6, step1163]: loss 0.234852
[epoch6, step1164]: loss 0.206793
[epoch6, step1165]: loss 0.233124
[epoch6, step1166]: loss 0.217749
[epoch6, step1167]: loss 0.198579
[epoch6, step1168]: loss 0.219853
[epoch6, step1169]: loss 0.225528
[epoch6, step1170]: loss 0.230334
[epoch6, step1171]: loss 0.214413
[epoch6, step1172]: loss 0.231004
[epoch6, step1173]: loss 0.208167
[epoch6, step1174]: loss 0.237322
[epoch6, step1175]: loss 0.220885
[epoch6, step1176]: loss 0.197590
[epoch6, step1177]: loss 0.217110
[epoch6, step1178]: loss 0.222083
[epoch6, step1179]: loss 0.230623
[epoch6, step1180]: loss 0.211877
[epoch6, step1181]: loss 0.226341
[epoch6, step1182]: loss 0.210175
[epoch6, step1183]: loss 0.235519
[epoch6, step1184]: loss 0.223087
[epoch6, step1185]: loss 0.197953
[epoch6, step1186]: loss 0.222287
[epoch6, step1187]: loss 0.229744
[epoch6, step1188]: loss 0.232858
[epoch6, step1189]: loss 0.213135
[epoch6, step1190]: loss 0.232333
[epoch6, step1191]: loss 0.206396
[epoch6, step1192]: loss 0.237322
[epoch6, step1193]: loss 0.218294
[epoch6, step1194]: loss 0.196855
[epoch6, step1195]: loss 0.228544
[epoch6, step1196]: loss 0.228025
[epoch6, step1197]: loss 0.228418
[epoch6, step1198]: loss 0.211227
[epoch6, step1199]: loss 0.231453
[epoch6, step1200]: loss 0.207377
[epoch6, step1201]: loss 0.235907
[epoch6, step1202]: loss 0.212691
[epoch6, step1203]: loss 0.198847
[epoch6, step1204]: loss 0.221828
[epoch6, step1205]: loss 0.224674
[epoch6, step1206]: loss 0.232657
[epoch6, step1207]: loss 0.207860
[epoch6, step1208]: loss 0.227347
[epoch6, step1209]: loss 0.210688
[epoch6, step1210]: loss 0.235131
[epoch6, step1211]: loss 0.222046
[epoch6, step1212]: loss 0.198436
[epoch6, step1213]: loss 0.223802
[epoch6, step1214]: loss 0.221873
[epoch6, step1215]: loss 0.224454
[epoch6, step1216]: loss 0.212023
[epoch6, step1217]: loss 0.225083
[epoch6, step1218]: loss 0.206611
[epoch6, step1219]: loss 0.234508
[epoch6, step1220]: loss 0.215190
[epoch6, step1221]: loss 0.198632
[epoch6, step1222]: loss 0.218823
[epoch6, step1223]: loss 0.222640
[epoch6, step1224]: loss 0.224665
[epoch6, step1225]: loss 0.211237
[epoch6, step1226]: loss 0.231424
[epoch6, step1227]: loss 0.204135
[epoch6, step1228]: loss 0.239949
[epoch6, step1229]: loss 0.221356
[epoch6, step1230]: loss 0.197400
[epoch6, step1231]: loss 0.221650
[epoch6, step1232]: loss 0.216801
[epoch6, step1233]: loss 0.229292
[epoch6, step1234]: loss 0.212281
[epoch6, step1235]: loss 0.225422
[epoch6, step1236]: loss 0.208803
[epoch6, step1237]: loss 0.240964
[epoch6, step1238]: loss 0.221717
[epoch6, step1239]: loss 0.192165
[epoch6, step1240]: loss 0.215969
[epoch6, step1241]: loss 0.227076
[epoch6, step1242]: loss 0.228975
[epoch6, step1243]: loss 0.209374
[epoch6, step1244]: loss 0.226455
[epoch6, step1245]: loss 0.202165
[epoch6, step1246]: loss 0.235976
[epoch6, step1247]: loss 0.223313
[epoch6, step1248]: loss 0.195953
[epoch6, step1249]: loss 0.215148
[epoch6, step1250]: loss 0.222614
[epoch6, step1251]: loss 0.226605
[epoch6, step1252]: loss 0.208417
[epoch6, step1253]: loss 0.225730
[epoch6, step1254]: loss 0.204910
[epoch6, step1255]: loss 0.236826
[epoch6, step1256]: loss 0.213966
[epoch6, step1257]: loss 0.193075
[epoch6, step1258]: loss 0.218462
[epoch6, step1259]: loss 0.223149
[epoch6, step1260]: loss 0.227019
[epoch6, step1261]: loss 0.212051
[epoch6, step1262]: loss 0.234360
[epoch6, step1263]: loss 0.200316
[epoch6, step1264]: loss 0.238559
[epoch6, step1265]: loss 0.225887
[epoch6, step1266]: loss 0.196146
[epoch6, step1267]: loss 0.218108
[epoch6, step1268]: loss 0.220497
[epoch6, step1269]: loss 0.225982
[epoch6, step1270]: loss 0.214264
[epoch6, step1271]: loss 0.224429
[epoch6, step1272]: loss 0.203904
[epoch6, step1273]: loss 0.239071
[epoch6, step1274]: loss 0.219696
[epoch6, step1275]: loss 0.194336
[epoch6, step1276]: loss 0.218331
[epoch6, step1277]: loss 0.221773
[epoch6, step1278]: loss 0.222796
[epoch6, step1279]: loss 0.208580
[epoch6, step1280]: loss 0.225710
[epoch6, step1281]: loss 0.205262
[epoch6, step1282]: loss 0.236079
[epoch6, step1283]: loss 0.220252
[epoch6, step1284]: loss 0.193225
[epoch6, step1285]: loss 0.216616
[epoch6, step1286]: loss 0.224540
[epoch6, step1287]: loss 0.221367
[epoch6, step1288]: loss 0.205595
[epoch6, step1289]: loss 0.220708
[epoch6, step1290]: loss 0.206388
[epoch6, step1291]: loss 0.237572
[epoch6, step1292]: loss 0.211356
[epoch6, step1293]: loss 0.195757
[epoch6, step1294]: loss 0.216190
[epoch6, step1295]: loss 0.217068
[epoch6, step1296]: loss 0.224466
[epoch6, step1297]: loss 0.207261
[epoch6, step1298]: loss 0.222426
[epoch6, step1299]: loss 0.204664
[epoch6, step1300]: loss 0.232512
[epoch6, step1301]: loss 0.223034
[epoch6, step1302]: loss 0.193000
[epoch6, step1303]: loss 0.218808
[epoch6, step1304]: loss 0.224089
[epoch6, step1305]: loss 0.222263
[epoch6, step1306]: loss 0.210001
[epoch6, step1307]: loss 0.229667
[epoch6, step1308]: loss 0.205232
[epoch6, step1309]: loss 0.239815
[epoch6, step1310]: loss 0.216453
[epoch6, step1311]: loss 0.197505
[epoch6, step1312]: loss 0.215658
[epoch6, step1313]: loss 0.219616
[epoch6, step1314]: loss 0.227266
[epoch6, step1315]: loss 0.209429
[epoch6, step1316]: loss 0.216924
[epoch6, step1317]: loss 0.206955
[epoch6, step1318]: loss 0.239464
[epoch6, step1319]: loss 0.218012
[epoch6, step1320]: loss 0.192868
[epoch6, step1321]: loss 0.212279
[epoch6, step1322]: loss 0.222727
[epoch6, step1323]: loss 0.222653
[epoch6, step1324]: loss 0.210696
[epoch6, step1325]: loss 0.225866
[epoch6, step1326]: loss 0.207280
[epoch6, step1327]: loss 0.235098
[epoch6, step1328]: loss 0.215548
[epoch6, step1329]: loss 0.193684
[epoch6, step1330]: loss 0.215369
[epoch6, step1331]: loss 0.222247
[epoch6, step1332]: loss 0.226790
[epoch6, step1333]: loss 0.215975
[epoch6, step1334]: loss 0.222589
[epoch6, step1335]: loss 0.202862
[epoch6, step1336]: loss 0.233789
[epoch6, step1337]: loss 0.220562
[epoch6, step1338]: loss 0.192993
[epoch6, step1339]: loss 0.218148
[epoch6, step1340]: loss 0.222953
[epoch6, step1341]: loss 0.224814
[epoch6, step1342]: loss 0.208604
[epoch6, step1343]: loss 0.223228
[epoch6, step1344]: loss 0.201492
[epoch6, step1345]: loss 0.233709
[epoch6, step1346]: loss 0.217612
[epoch6, step1347]: loss 0.189561
[epoch6, step1348]: loss 0.218956
[epoch6, step1349]: loss 0.219168
[epoch6, step1350]: loss 0.222466
[epoch6, step1351]: loss 0.213723
[epoch6, step1352]: loss 0.227474
[epoch6, step1353]: loss 0.207198
[epoch6, step1354]: loss 0.236971
[epoch6, step1355]: loss 0.214799
[epoch6, step1356]: loss 0.197741
[epoch6, step1357]: loss 0.220020
[epoch6, step1358]: loss 0.219753
[epoch6, step1359]: loss 0.226441
[epoch6, step1360]: loss 0.205135
[epoch6, step1361]: loss 0.222498
[epoch6, step1362]: loss 0.201377
[epoch6, step1363]: loss 0.229644
[epoch6, step1364]: loss 0.214748
[epoch6, step1365]: loss 0.193097
[epoch6, step1366]: loss 0.215787
[epoch6, step1367]: loss 0.222976
[epoch6, step1368]: loss 0.216922
[epoch6, step1369]: loss 0.208657
[epoch6, step1370]: loss 0.225925
[epoch6, step1371]: loss 0.201084
[epoch6, step1372]: loss 0.233539
[epoch6, step1373]: loss 0.214745
[epoch6, step1374]: loss 0.188069
[epoch6, step1375]: loss 0.211812
[epoch6, step1376]: loss 0.219031
[epoch6, step1377]: loss 0.229739
[epoch6, step1378]: loss 0.207970
[epoch6, step1379]: loss 0.226552
[epoch6, step1380]: loss 0.198302
[epoch6, step1381]: loss 0.232610
[epoch6, step1382]: loss 0.213249
[epoch6, step1383]: loss 0.192230
[epoch6, step1384]: loss 0.213410
[epoch6, step1385]: loss 0.221052
[epoch6, step1386]: loss 0.221909
[epoch6, step1387]: loss 0.202914
[epoch6, step1388]: loss 0.230117
[epoch6, step1389]: loss 0.205143
[epoch6, step1390]: loss 0.231731
[epoch6, step1391]: loss 0.214930
[epoch6, step1392]: loss 0.193296
[epoch6, step1393]: loss 0.211778
[epoch6, step1394]: loss 0.214081
[epoch6, step1395]: loss 0.222071
[epoch6, step1396]: loss 0.207182
[epoch6, step1397]: loss 0.224761
[epoch6, step1398]: loss 0.201147
[epoch6, step1399]: loss 0.225838
[epoch6, step1400]: loss 0.212700
[epoch6, step1401]: loss 0.190119
[epoch6, step1402]: loss 0.213862
[epoch6, step1403]: loss 0.223604
[epoch6, step1404]: loss 0.225344
[epoch6, step1405]: loss 0.204114
[epoch6, step1406]: loss 0.225073
[epoch6, step1407]: loss 0.195877
[epoch6, step1408]: loss 0.236319
[epoch6, step1409]: loss 0.216466
[epoch6, step1410]: loss 0.189300
[epoch6, step1411]: loss 0.220925
[epoch6, step1412]: loss 0.217153
[epoch6, step1413]: loss 0.222510
[epoch6, step1414]: loss 0.208743
[epoch6, step1415]: loss 0.224666
[epoch6, step1416]: loss 0.200024
[epoch6, step1417]: loss 0.233331
[epoch6, step1418]: loss 0.214185
[epoch6, step1419]: loss 0.187333
[epoch6, step1420]: loss 0.214154
[epoch6, step1421]: loss 0.214779
[epoch6, step1422]: loss 0.219736
[epoch6, step1423]: loss 0.208159
[epoch6, step1424]: loss 0.222172
[epoch6, step1425]: loss 0.204159
[epoch6, step1426]: loss 0.231729
[epoch6, step1427]: loss 0.208242
[epoch6, step1428]: loss 0.190488
[epoch6, step1429]: loss 0.212049
[epoch6, step1430]: loss 0.218629
[epoch6, step1431]: loss 0.221467
[epoch6, step1432]: loss 0.207225
[epoch6, step1433]: loss 0.221867
[epoch6, step1434]: loss 0.207663
[epoch6, step1435]: loss 0.228412
[epoch6, step1436]: loss 0.210887
[epoch6, step1437]: loss 0.188494
[epoch6, step1438]: loss 0.211893
[epoch6, step1439]: loss 0.218724
[epoch6, step1440]: loss 0.223204
[epoch6, step1441]: loss 0.201958
[epoch6, step1442]: loss 0.227271
[epoch6, step1443]: loss 0.206611
[epoch6, step1444]: loss 0.235325
[epoch6, step1445]: loss 0.210672
[epoch6, step1446]: loss 0.187794
[epoch6, step1447]: loss 0.210252
[epoch6, step1448]: loss 0.217678
[epoch6, step1449]: loss 0.224335
[epoch6, step1450]: loss 0.206067
[epoch6, step1451]: loss 0.219861
[epoch6, step1452]: loss 0.202525
[epoch6, step1453]: loss 0.224713
[epoch6, step1454]: loss 0.209684
[epoch6, step1455]: loss 0.184952
[epoch6, step1456]: loss 0.215168
[epoch6, step1457]: loss 0.212196
[epoch6, step1458]: loss 0.220608
[epoch6, step1459]: loss 0.208070
[epoch6, step1460]: loss 0.218626
[epoch6, step1461]: loss 0.196574
[epoch6, step1462]: loss 0.225273
[epoch6, step1463]: loss 0.213744
[epoch6, step1464]: loss 0.186729
[epoch6, step1465]: loss 0.216556
[epoch6, step1466]: loss 0.217568
[epoch6, step1467]: loss 0.223741
[epoch6, step1468]: loss 0.207010
[epoch6, step1469]: loss 0.222125
[epoch6, step1470]: loss 0.199032
[epoch6, step1471]: loss 0.233756
[epoch6, step1472]: loss 0.213727
[epoch6, step1473]: loss 0.188098
[epoch6, step1474]: loss 0.208600
[epoch6, step1475]: loss 0.217702
[epoch6, step1476]: loss 0.216937
[epoch6, step1477]: loss 0.208312
[epoch6, step1478]: loss 0.220906
[epoch6, step1479]: loss 0.199874
[epoch6, step1480]: loss 0.229861
[epoch6, step1481]: loss 0.218652
[epoch6, step1482]: loss 0.189917
[epoch6, step1483]: loss 0.212570
[epoch6, step1484]: loss 0.214363
[epoch6, step1485]: loss 0.220375
[epoch6, step1486]: loss 0.210444
[epoch6, step1487]: loss 0.221636
[epoch6, step1488]: loss 0.198648
[epoch6, step1489]: loss 0.230804
[epoch6, step1490]: loss 0.210389
[epoch6, step1491]: loss 0.190247
[epoch6, step1492]: loss 0.215083
[epoch6, step1493]: loss 0.216097
[epoch6, step1494]: loss 0.220245
[epoch6, step1495]: loss 0.208968
[epoch6, step1496]: loss 0.226017
[epoch6, step1497]: loss 0.197898
[epoch6, step1498]: loss 0.226428
[epoch6, step1499]: loss 0.215317
[epoch6, step1500]: loss 0.188012
[epoch6, step1501]: loss 0.211856
[epoch6, step1502]: loss 0.216062
[epoch6, step1503]: loss 0.221795
[epoch6, step1504]: loss 0.208427
[epoch6, step1505]: loss 0.219098
[epoch6, step1506]: loss 0.201053
[epoch6, step1507]: loss 0.226914
[epoch6, step1508]: loss 0.208648
[epoch6, step1509]: loss 0.191066
[epoch6, step1510]: loss 0.218874
[epoch6, step1511]: loss 0.210895
[epoch6, step1512]: loss 0.218064
[epoch6, step1513]: loss 0.211986
[epoch6, step1514]: loss 0.220674
[epoch6, step1515]: loss 0.198499
[epoch6, step1516]: loss 0.228637

[epoch6]: avg loss 0.228147

[epoch7, step1]: loss 0.236886
[epoch7, step2]: loss 0.217516
[epoch7, step3]: loss 0.219790
[epoch7, step4]: loss 0.205899
[epoch7, step5]: loss 0.228813
[epoch7, step6]: loss 0.211721
[epoch7, step7]: loss 0.193800
[epoch7, step8]: loss 0.221000
[epoch7, step9]: loss 0.198760
[epoch7, step10]: loss 0.222109
[epoch7, step11]: loss 0.216562
[epoch7, step12]: loss 0.218094
[epoch7, step13]: loss 0.197749
[epoch7, step14]: loss 0.228175
[epoch7, step15]: loss 0.211975
[epoch7, step16]: loss 0.194289
[epoch7, step17]: loss 0.218109
[epoch7, step18]: loss 0.191719
[epoch7, step19]: loss 0.225130
[epoch7, step20]: loss 0.210489
[epoch7, step21]: loss 0.218786
[epoch7, step22]: loss 0.202275
[epoch7, step23]: loss 0.235926
[epoch7, step24]: loss 0.209397
[epoch7, step25]: loss 0.195362
[epoch7, step26]: loss 0.225060
[epoch7, step27]: loss 0.198526
[epoch7, step28]: loss 0.224091
[epoch7, step29]: loss 0.214082
[epoch7, step30]: loss 0.213152
[epoch7, step31]: loss 0.200639
[epoch7, step32]: loss 0.226110
[epoch7, step33]: loss 0.206852
[epoch7, step34]: loss 0.191460
[epoch7, step35]: loss 0.218156
[epoch7, step36]: loss 0.197865
[epoch7, step37]: loss 0.225198
[epoch7, step38]: loss 0.216182
[epoch7, step39]: loss 0.217457
[epoch7, step40]: loss 0.196047
[epoch7, step41]: loss 0.232824
[epoch7, step42]: loss 0.207702
[epoch7, step43]: loss 0.196110
[epoch7, step44]: loss 0.218816
[epoch7, step45]: loss 0.197535
[epoch7, step46]: loss 0.225027
[epoch7, step47]: loss 0.217880
[epoch7, step48]: loss 0.218994
[epoch7, step49]: loss 0.204129
[epoch7, step50]: loss 0.228360
[epoch7, step51]: loss 0.210286
[epoch7, step52]: loss 0.196546
[epoch7, step53]: loss 0.215666
[epoch7, step54]: loss 0.195262
[epoch7, step55]: loss 0.221616
[epoch7, step56]: loss 0.207594
[epoch7, step57]: loss 0.214029
[epoch7, step58]: loss 0.197166
[epoch7, step59]: loss 0.235139
[epoch7, step60]: loss 0.205204
[epoch7, step61]: loss 0.197385
[epoch7, step62]: loss 0.222926
[epoch7, step63]: loss 0.200563
[epoch7, step64]: loss 0.229278
[epoch7, step65]: loss 0.212678
[epoch7, step66]: loss 0.216466
[epoch7, step67]: loss 0.199549
[epoch7, step68]: loss 0.228898
[epoch7, step69]: loss 0.209484
[epoch7, step70]: loss 0.195729
[epoch7, step71]: loss 0.222007
[epoch7, step72]: loss 0.195378
[epoch7, step73]: loss 0.225317
[epoch7, step74]: loss 0.212630
[epoch7, step75]: loss 0.214676
[epoch7, step76]: loss 0.197758
[epoch7, step77]: loss 0.223982
[epoch7, step78]: loss 0.207521
[epoch7, step79]: loss 0.197200
[epoch7, step80]: loss 0.213806
[epoch7, step81]: loss 0.193913
[epoch7, step82]: loss 0.227953
[epoch7, step83]: loss 0.218710
[epoch7, step84]: loss 0.214680
[epoch7, step85]: loss 0.194247
[epoch7, step86]: loss 0.225273
[epoch7, step87]: loss 0.202966
[epoch7, step88]: loss 0.205231
[epoch7, step89]: loss 0.221624
[epoch7, step90]: loss 0.196847
[epoch7, step91]: loss 0.230597
[epoch7, step92]: loss 0.212242
[epoch7, step93]: loss 0.214397
[epoch7, step94]: loss 0.200046
[epoch7, step95]: loss 0.224468
[epoch7, step96]: loss 0.209986
[epoch7, step97]: loss 0.191100
[epoch7, step98]: loss 0.218755
[epoch7, step99]: loss 0.196087
[epoch7, step100]: loss 0.230367
[epoch7, step101]: loss 0.208585
[epoch7, step102]: loss 0.216095
[epoch7, step103]: loss 0.199008
[epoch7, step104]: loss 0.227168
[epoch7, step105]: loss 0.205333
[epoch7, step106]: loss 0.195023
[epoch7, step107]: loss 0.218951
[epoch7, step108]: loss 0.193971
[epoch7, step109]: loss 0.225640
[epoch7, step110]: loss 0.208707
[epoch7, step111]: loss 0.216112
[epoch7, step112]: loss 0.199422
[epoch7, step113]: loss 0.221498
[epoch7, step114]: loss 0.209317
[epoch7, step115]: loss 0.194471
[epoch7, step116]: loss 0.213398
[epoch7, step117]: loss 0.193841
[epoch7, step118]: loss 0.218581
[epoch7, step119]: loss 0.209488
[epoch7, step120]: loss 0.212745
[epoch7, step121]: loss 0.198729
[epoch7, step122]: loss 0.226269
[epoch7, step123]: loss 0.204955
[epoch7, step124]: loss 0.193701
[epoch7, step125]: loss 0.214594
[epoch7, step126]: loss 0.195844
[epoch7, step127]: loss 0.224775
[epoch7, step128]: loss 0.212657
[epoch7, step129]: loss 0.214036
[epoch7, step130]: loss 0.194376
[epoch7, step131]: loss 0.229752
[epoch7, step132]: loss 0.206021
[epoch7, step133]: loss 0.192671
[epoch7, step134]: loss 0.221630
[epoch7, step135]: loss 0.191449
[epoch7, step136]: loss 0.215458
[epoch7, step137]: loss 0.213514
[epoch7, step138]: loss 0.214236
[epoch7, step139]: loss 0.196667
[epoch7, step140]: loss 0.222619
[epoch7, step141]: loss 0.204943
[epoch7, step142]: loss 0.192881
[epoch7, step143]: loss 0.219742
[epoch7, step144]: loss 0.197010
[epoch7, step145]: loss 0.223109
[epoch7, step146]: loss 0.211495
[epoch7, step147]: loss 0.206140
[epoch7, step148]: loss 0.195922
[epoch7, step149]: loss 0.229173
[epoch7, step150]: loss 0.208908
[epoch7, step151]: loss 0.190080
[epoch7, step152]: loss 0.216851
[epoch7, step153]: loss 0.191689
[epoch7, step154]: loss 0.226287
[epoch7, step155]: loss 0.210674
[epoch7, step156]: loss 0.216407
[epoch7, step157]: loss 0.194242
[epoch7, step158]: loss 0.222826
[epoch7, step159]: loss 0.204838
[epoch7, step160]: loss 0.190201
[epoch7, step161]: loss 0.212501
[epoch7, step162]: loss 0.191961
[epoch7, step163]: loss 0.223021
[epoch7, step164]: loss 0.207888
[epoch7, step165]: loss 0.212847
[epoch7, step166]: loss 0.192314
[epoch7, step167]: loss 0.227574
[epoch7, step168]: loss 0.200980
[epoch7, step169]: loss 0.194295
[epoch7, step170]: loss 0.214142
[epoch7, step171]: loss 0.191815
[epoch7, step172]: loss 0.221599
[epoch7, step173]: loss 0.208410
[epoch7, step174]: loss 0.214417
[epoch7, step175]: loss 0.189691
[epoch7, step176]: loss 0.223548
[epoch7, step177]: loss 0.203433
[epoch7, step178]: loss 0.187858
[epoch7, step179]: loss 0.220691
[epoch7, step180]: loss 0.188639
[epoch7, step181]: loss 0.220071
[epoch7, step182]: loss 0.207482
[epoch7, step183]: loss 0.208475
[epoch7, step184]: loss 0.189518
[epoch7, step185]: loss 0.222860
[epoch7, step186]: loss 0.202846
[epoch7, step187]: loss 0.192428
[epoch7, step188]: loss 0.216900
[epoch7, step189]: loss 0.190279
[epoch7, step190]: loss 0.225366
[epoch7, step191]: loss 0.210576
[epoch7, step192]: loss 0.208320
[epoch7, step193]: loss 0.204723
[epoch7, step194]: loss 0.228649
[epoch7, step195]: loss 0.202469
[epoch7, step196]: loss 0.189310
[epoch7, step197]: loss 0.216135
[epoch7, step198]: loss 0.195605
[epoch7, step199]: loss 0.220457
[epoch7, step200]: loss 0.205095
[epoch7, step201]: loss 0.208416
[epoch7, step202]: loss 0.195135
[epoch7, step203]: loss 0.223642
[epoch7, step204]: loss 0.201441
[epoch7, step205]: loss 0.195069
[epoch7, step206]: loss 0.216860
[epoch7, step207]: loss 0.190856
[epoch7, step208]: loss 0.217333
[epoch7, step209]: loss 0.206401
[epoch7, step210]: loss 0.205790
[epoch7, step211]: loss 0.192727
[epoch7, step212]: loss 0.221402
[epoch7, step213]: loss 0.205569
[epoch7, step214]: loss 0.196345
[epoch7, step215]: loss 0.213282
[epoch7, step216]: loss 0.190061
[epoch7, step217]: loss 0.225516
[epoch7, step218]: loss 0.205933
[epoch7, step219]: loss 0.212402
[epoch7, step220]: loss 0.196085
[epoch7, step221]: loss 0.221240
[epoch7, step222]: loss 0.200983
[epoch7, step223]: loss 0.186263
[epoch7, step224]: loss 0.216288
[epoch7, step225]: loss 0.190062
[epoch7, step226]: loss 0.222621
[epoch7, step227]: loss 0.213780
[epoch7, step228]: loss 0.207319
[epoch7, step229]: loss 0.198258
[epoch7, step230]: loss 0.219960
[epoch7, step231]: loss 0.200276
[epoch7, step232]: loss 0.191785
[epoch7, step233]: loss 0.218860
[epoch7, step234]: loss 0.193302
[epoch7, step235]: loss 0.220414
[epoch7, step236]: loss 0.207110
[epoch7, step237]: loss 0.210331
[epoch7, step238]: loss 0.192854
[epoch7, step239]: loss 0.226409
[epoch7, step240]: loss 0.208404
[epoch7, step241]: loss 0.188728
[epoch7, step242]: loss 0.215158
[epoch7, step243]: loss 0.189018
[epoch7, step244]: loss 0.221509
[epoch7, step245]: loss 0.210290
[epoch7, step246]: loss 0.210534
[epoch7, step247]: loss 0.193270
[epoch7, step248]: loss 0.224278
[epoch7, step249]: loss 0.205834
[epoch7, step250]: loss 0.188738
[epoch7, step251]: loss 0.210333
[epoch7, step252]: loss 0.187715
[epoch7, step253]: loss 0.223073
[epoch7, step254]: loss 0.211890
[epoch7, step255]: loss 0.208531
[epoch7, step256]: loss 0.196262
[epoch7, step257]: loss 0.223184
[epoch7, step258]: loss 0.199334
[epoch7, step259]: loss 0.187506
[epoch7, step260]: loss 0.217145
[epoch7, step261]: loss 0.184669
[epoch7, step262]: loss 0.216498
[epoch7, step263]: loss 0.211888
[epoch7, step264]: loss 0.211131
[epoch7, step265]: loss 0.193135
[epoch7, step266]: loss 0.222220
[epoch7, step267]: loss 0.207624
[epoch7, step268]: loss 0.189362
[epoch7, step269]: loss 0.212661
[epoch7, step270]: loss 0.191604
[epoch7, step271]: loss 0.218069
[epoch7, step272]: loss 0.207477
[epoch7, step273]: loss 0.211104
[epoch7, step274]: loss 0.188795
[epoch7, step275]: loss 0.225526
[epoch7, step276]: loss 0.205651
[epoch7, step277]: loss 0.187428
[epoch7, step278]: loss 0.211972
[epoch7, step279]: loss 0.188500
[epoch7, step280]: loss 0.217848
[epoch7, step281]: loss 0.208233
[epoch7, step282]: loss 0.205972
[epoch7, step283]: loss 0.194941
[epoch7, step284]: loss 0.224117
[epoch7, step285]: loss 0.197712
[epoch7, step286]: loss 0.198481
[epoch7, step287]: loss 0.211837
[epoch7, step288]: loss 0.192154
[epoch7, step289]: loss 0.215939
[epoch7, step290]: loss 0.206802
[epoch7, step291]: loss 0.207319
[epoch7, step292]: loss 0.196526
[epoch7, step293]: loss 0.222464
[epoch7, step294]: loss 0.204872
[epoch7, step295]: loss 0.190621
[epoch7, step296]: loss 0.208269
[epoch7, step297]: loss 0.191577
[epoch7, step298]: loss 0.217761
[epoch7, step299]: loss 0.211718
[epoch7, step300]: loss 0.206566
[epoch7, step301]: loss 0.194916
[epoch7, step302]: loss 0.218296
[epoch7, step303]: loss 0.199429
[epoch7, step304]: loss 0.187969
[epoch7, step305]: loss 0.214513
[epoch7, step306]: loss 0.188985
[epoch7, step307]: loss 0.221325
[epoch7, step308]: loss 0.203180
[epoch7, step309]: loss 0.205614
[epoch7, step310]: loss 0.192422
[epoch7, step311]: loss 0.217725
[epoch7, step312]: loss 0.203152
[epoch7, step313]: loss 0.188900
[epoch7, step314]: loss 0.211858
[epoch7, step315]: loss 0.186486
[epoch7, step316]: loss 0.220100
[epoch7, step317]: loss 0.204891
[epoch7, step318]: loss 0.207924
[epoch7, step319]: loss 0.195536
[epoch7, step320]: loss 0.226254
[epoch7, step321]: loss 0.203792
[epoch7, step322]: loss 0.193262
[epoch7, step323]: loss 0.216005
[epoch7, step324]: loss 0.185632
[epoch7, step325]: loss 0.217217
[epoch7, step326]: loss 0.207428
[epoch7, step327]: loss 0.211922
[epoch7, step328]: loss 0.192439
[epoch7, step329]: loss 0.222467
[epoch7, step330]: loss 0.205463
[epoch7, step331]: loss 0.189717
[epoch7, step332]: loss 0.215253
[epoch7, step333]: loss 0.190651
[epoch7, step334]: loss 0.216604
[epoch7, step335]: loss 0.205245
[epoch7, step336]: loss 0.203134
[epoch7, step337]: loss 0.188634
[epoch7, step338]: loss 0.223253
[epoch7, step339]: loss 0.202908
[epoch7, step340]: loss 0.188429
[epoch7, step341]: loss 0.214307
[epoch7, step342]: loss 0.188542
[epoch7, step343]: loss 0.215873
[epoch7, step344]: loss 0.207108
[epoch7, step345]: loss 0.211655
[epoch7, step346]: loss 0.194259
[epoch7, step347]: loss 0.221925
[epoch7, step348]: loss 0.199538
[epoch7, step349]: loss 0.185823
[epoch7, step350]: loss 0.214588
[epoch7, step351]: loss 0.190197
[epoch7, step352]: loss 0.217427
[epoch7, step353]: loss 0.206083
[epoch7, step354]: loss 0.213612
[epoch7, step355]: loss 0.195305
[epoch7, step356]: loss 0.215988
[epoch7, step357]: loss 0.200254
[epoch7, step358]: loss 0.196041
[epoch7, step359]: loss 0.206618
[epoch7, step360]: loss 0.189951
[epoch7, step361]: loss 0.220172
[epoch7, step362]: loss 0.202173
[epoch7, step363]: loss 0.209367
[epoch7, step364]: loss 0.192125
[epoch7, step365]: loss 0.220506
[epoch7, step366]: loss 0.198747
[epoch7, step367]: loss 0.189758
[epoch7, step368]: loss 0.214349
[epoch7, step369]: loss 0.189505
[epoch7, step370]: loss 0.213715
[epoch7, step371]: loss 0.200039
[epoch7, step372]: loss 0.209245
[epoch7, step373]: loss 0.191652
[epoch7, step374]: loss 0.223012
[epoch7, step375]: loss 0.196679
[epoch7, step376]: loss 0.184206
[epoch7, step377]: loss 0.209638
[epoch7, step378]: loss 0.187971
[epoch7, step379]: loss 0.213340
[epoch7, step380]: loss 0.201618
[epoch7, step381]: loss 0.208747
[epoch7, step382]: loss 0.194524
[epoch7, step383]: loss 0.225537
[epoch7, step384]: loss 0.204308
[epoch7, step385]: loss 0.184483
[epoch7, step386]: loss 0.209447
[epoch7, step387]: loss 0.185469
[epoch7, step388]: loss 0.211450
[epoch7, step389]: loss 0.204348
[epoch7, step390]: loss 0.200526
[epoch7, step391]: loss 0.190681
[epoch7, step392]: loss 0.214814
[epoch7, step393]: loss 0.202563
[epoch7, step394]: loss 0.189764
[epoch7, step395]: loss 0.211905
[epoch7, step396]: loss 0.186395
[epoch7, step397]: loss 0.219788
[epoch7, step398]: loss 0.203455
[epoch7, step399]: loss 0.206858
[epoch7, step400]: loss 0.189846
[epoch7, step401]: loss 0.219304
[epoch7, step402]: loss 0.201017
[epoch7, step403]: loss 0.185599
[epoch7, step404]: loss 0.208510
[epoch7, step405]: loss 0.184687
[epoch7, step406]: loss 0.213229
[epoch7, step407]: loss 0.205524
[epoch7, step408]: loss 0.205650
[epoch7, step409]: loss 0.181754
[epoch7, step410]: loss 0.214614
[epoch7, step411]: loss 0.199672
[epoch7, step412]: loss 0.187184
[epoch7, step413]: loss 0.210145
[epoch7, step414]: loss 0.191377
[epoch7, step415]: loss 0.214707
[epoch7, step416]: loss 0.207210
[epoch7, step417]: loss 0.204716
[epoch7, step418]: loss 0.188916
[epoch7, step419]: loss 0.221714
[epoch7, step420]: loss 0.197028
[epoch7, step421]: loss 0.187155
[epoch7, step422]: loss 0.209393
[epoch7, step423]: loss 0.185999
[epoch7, step424]: loss 0.213545
[epoch7, step425]: loss 0.202399
[epoch7, step426]: loss 0.203648
[epoch7, step427]: loss 0.191448
[epoch7, step428]: loss 0.218401
[epoch7, step429]: loss 0.193946
[epoch7, step430]: loss 0.186266
[epoch7, step431]: loss 0.207346
[epoch7, step432]: loss 0.185187
[epoch7, step433]: loss 0.209670
[epoch7, step434]: loss 0.203719
[epoch7, step435]: loss 0.203059
[epoch7, step436]: loss 0.193767
[epoch7, step437]: loss 0.216169
[epoch7, step438]: loss 0.194283
[epoch7, step439]: loss 0.187004
[epoch7, step440]: loss 0.208866
[epoch7, step441]: loss 0.183984
[epoch7, step442]: loss 0.214329
[epoch7, step443]: loss 0.199814
[epoch7, step444]: loss 0.207638
[epoch7, step445]: loss 0.187762
[epoch7, step446]: loss 0.214889
[epoch7, step447]: loss 0.194642
[epoch7, step448]: loss 0.183127
[epoch7, step449]: loss 0.209990
[epoch7, step450]: loss 0.190238
[epoch7, step451]: loss 0.215226
[epoch7, step452]: loss 0.209199
[epoch7, step453]: loss 0.203748
[epoch7, step454]: loss 0.190790
[epoch7, step455]: loss 0.215337
[epoch7, step456]: loss 0.202297
[epoch7, step457]: loss 0.183413
[epoch7, step458]: loss 0.209809
[epoch7, step459]: loss 0.181538
[epoch7, step460]: loss 0.214650
[epoch7, step461]: loss 0.198399
[epoch7, step462]: loss 0.208521
[epoch7, step463]: loss 0.188613
[epoch7, step464]: loss 0.217614
[epoch7, step465]: loss 0.189916
[epoch7, step466]: loss 0.184137
[epoch7, step467]: loss 0.210275
[epoch7, step468]: loss 0.186684
[epoch7, step469]: loss 0.213104
[epoch7, step470]: loss 0.200863
[epoch7, step471]: loss 0.206415
[epoch7, step472]: loss 0.189386
[epoch7, step473]: loss 0.218411
[epoch7, step474]: loss 0.198943
[epoch7, step475]: loss 0.184851
[epoch7, step476]: loss 0.205177
[epoch7, step477]: loss 0.185635
[epoch7, step478]: loss 0.216098
[epoch7, step479]: loss 0.202115
[epoch7, step480]: loss 0.208918
[epoch7, step481]: loss 0.189730
[epoch7, step482]: loss 0.219878
[epoch7, step483]: loss 0.194867
[epoch7, step484]: loss 0.180164
[epoch7, step485]: loss 0.207086
[epoch7, step486]: loss 0.183027
[epoch7, step487]: loss 0.216534
[epoch7, step488]: loss 0.199686
[epoch7, step489]: loss 0.208745
[epoch7, step490]: loss 0.188171
[epoch7, step491]: loss 0.213792
[epoch7, step492]: loss 0.198321
[epoch7, step493]: loss 0.183890
[epoch7, step494]: loss 0.210929
[epoch7, step495]: loss 0.177315
[epoch7, step496]: loss 0.213971
[epoch7, step497]: loss 0.200334
[epoch7, step498]: loss 0.203937
[epoch7, step499]: loss 0.188021
[epoch7, step500]: loss 0.218502
[epoch7, step501]: loss 0.200503
[epoch7, step502]: loss 0.184427
[epoch7, step503]: loss 0.206444
[epoch7, step504]: loss 0.189250
[epoch7, step505]: loss 0.218715
[epoch7, step506]: loss 0.197543
[epoch7, step507]: loss 0.201249
[epoch7, step508]: loss 0.185979
[epoch7, step509]: loss 0.217000
[epoch7, step510]: loss 0.195990
[epoch7, step511]: loss 0.185840
[epoch7, step512]: loss 0.204851
[epoch7, step513]: loss 0.184813
[epoch7, step514]: loss 0.211462
[epoch7, step515]: loss 0.200997
[epoch7, step516]: loss 0.200826
[epoch7, step517]: loss 0.188965
[epoch7, step518]: loss 0.214810
[epoch7, step519]: loss 0.195936
[epoch7, step520]: loss 0.183358
[epoch7, step521]: loss 0.209197
[epoch7, step522]: loss 0.185903
[epoch7, step523]: loss 0.212471
[epoch7, step524]: loss 0.205273
[epoch7, step525]: loss 0.200870
[epoch7, step526]: loss 0.183879
[epoch7, step527]: loss 0.217266
[epoch7, step528]: loss 0.194215
[epoch7, step529]: loss 0.186862
[epoch7, step530]: loss 0.204768
[epoch7, step531]: loss 0.183896
[epoch7, step532]: loss 0.214828
[epoch7, step533]: loss 0.194768
[epoch7, step534]: loss 0.203247
[epoch7, step535]: loss 0.185884
[epoch7, step536]: loss 0.213587
[epoch7, step537]: loss 0.194959
[epoch7, step538]: loss 0.186623
[epoch7, step539]: loss 0.207646
[epoch7, step540]: loss 0.189217
[epoch7, step541]: loss 0.214792
[epoch7, step542]: loss 0.200796
[epoch7, step543]: loss 0.203395
[epoch7, step544]: loss 0.183636
[epoch7, step545]: loss 0.219383
[epoch7, step546]: loss 0.192997
[epoch7, step547]: loss 0.187509
[epoch7, step548]: loss 0.207104
[epoch7, step549]: loss 0.182759
[epoch7, step550]: loss 0.211276
[epoch7, step551]: loss 0.200522
[epoch7, step552]: loss 0.205141
[epoch7, step553]: loss 0.185709
[epoch7, step554]: loss 0.216427
[epoch7, step555]: loss 0.198173
[epoch7, step556]: loss 0.181946
[epoch7, step557]: loss 0.209192
[epoch7, step558]: loss 0.182391
[epoch7, step559]: loss 0.214636
[epoch7, step560]: loss 0.199243
[epoch7, step561]: loss 0.203270
[epoch7, step562]: loss 0.184654
[epoch7, step563]: loss 0.248437
[epoch7, step564]: loss 0.190576
[epoch7, step565]: loss 0.152244
[epoch7, step566]: loss 0.162789
[epoch7, step567]: loss 0.156880
[epoch7, step568]: loss 0.176289
[epoch7, step569]: loss 0.208959
[epoch7, step570]: loss 0.178881
[epoch7, step571]: loss 0.127211
[epoch7, step572]: loss 0.175701
[epoch7, step573]: loss 0.184436
[epoch7, step574]: loss 0.223181
[epoch7, step575]: loss 0.192743
[epoch7, step576]: loss 0.198808
[epoch7, step577]: loss 0.168880
[epoch7, step578]: loss 0.198714
[epoch7, step579]: loss 0.159841
[epoch7, step580]: loss 0.225338
[epoch7, step581]: loss 0.198108
[epoch7, step582]: loss 0.192116
[epoch7, step583]: loss 0.195251
[epoch7, step584]: loss 0.183215
[epoch7, step585]: loss 0.216637
[epoch7, step586]: loss 0.191303
[epoch7, step587]: loss 0.138368
[epoch7, step588]: loss 0.193221
[epoch7, step589]: loss 0.251494
[epoch7, step590]: loss 0.146767
[epoch7, step591]: loss 0.187042
[epoch7, step592]: loss 0.206275
[epoch7, step593]: loss 0.247769
[epoch7, step594]: loss 0.149292
[epoch7, step595]: loss 0.150272
[epoch7, step596]: loss 0.208902
[epoch7, step597]: loss 0.215958
[epoch7, step598]: loss 0.161309
[epoch7, step599]: loss 0.149334
[epoch7, step600]: loss 0.145813
[epoch7, step601]: loss 0.188518
[epoch7, step602]: loss 0.224739
[epoch7, step603]: loss 0.166746
[epoch7, step604]: loss 0.163425
[epoch7, step605]: loss 0.145271
[epoch7, step606]: loss 0.182982
[epoch7, step607]: loss 0.200135
[epoch7, step608]: loss 0.127236
[epoch7, step609]: loss 0.189112
[epoch7, step610]: loss 0.167274
[epoch7, step611]: loss 0.207894
[epoch7, step612]: loss 0.190449
[epoch7, step613]: loss 0.208929
[epoch7, step614]: loss 0.184884
[epoch7, step615]: loss 0.189337
[epoch7, step616]: loss 0.151763
[epoch7, step617]: loss 0.174314
[epoch7, step618]: loss 0.204582
[epoch7, step619]: loss 0.155342
[epoch7, step620]: loss 0.144073
[epoch7, step621]: loss 0.140139
[epoch7, step622]: loss 0.199393
[epoch7, step623]: loss 0.192523
[epoch7, step624]: loss 0.192665
[epoch7, step625]: loss 0.142565
[epoch7, step626]: loss 0.193599
[epoch7, step627]: loss 0.222680
[epoch7, step628]: loss 0.203204
[epoch7, step629]: loss 0.113313
[epoch7, step630]: loss 0.161675
[epoch7, step631]: loss 0.160735
[epoch7, step632]: loss 0.193281
[epoch7, step633]: loss 0.158522
[epoch7, step634]: loss 0.182676
[epoch7, step635]: loss 0.173859
[epoch7, step636]: loss 0.153282
[epoch7, step637]: loss 0.204348
[epoch7, step638]: loss 0.188921
[epoch7, step639]: loss 0.146474
[epoch7, step640]: loss 0.195651
[epoch7, step641]: loss 0.151665
[epoch7, step642]: loss 0.147776
[epoch7, step643]: loss 0.196838
[epoch7, step644]: loss 0.172467
[epoch7, step645]: loss 0.134126
[epoch7, step646]: loss 0.178630
[epoch7, step647]: loss 0.138309
[epoch7, step648]: loss 0.222886
[epoch7, step649]: loss 0.190043
[epoch7, step650]: loss 0.202652
[epoch7, step651]: loss 0.170049
[epoch7, step652]: loss 0.214126
[epoch7, step653]: loss 0.206244
[epoch7, step654]: loss 0.198198
[epoch7, step655]: loss 0.152027
[epoch7, step656]: loss 0.208998
[epoch7, step657]: loss 0.206510
[epoch7, step658]: loss 0.160542
[epoch7, step659]: loss 0.138150
[epoch7, step660]: loss 0.179541
[epoch7, step661]: loss 0.191673
[epoch7, step662]: loss 0.140391
[epoch7, step663]: loss 0.175453
[epoch7, step664]: loss 0.169575
[epoch7, step665]: loss 0.215396
[epoch7, step666]: loss 0.145155
[epoch7, step667]: loss 0.189740
[epoch7, step668]: loss 0.218343
[epoch7, step669]: loss 0.147138
[epoch7, step670]: loss 0.183020
[epoch7, step671]: loss 0.188842
[epoch7, step672]: loss 0.227076
[epoch7, step673]: loss 0.209016
[epoch7, step674]: loss 0.173563
[epoch7, step675]: loss 0.201846
[epoch7, step676]: loss 0.195644
[epoch7, step677]: loss 0.166662
[epoch7, step678]: loss 0.144756
[epoch7, step679]: loss 0.177227
[epoch7, step680]: loss 0.143779
[epoch7, step681]: loss 0.147334
[epoch7, step682]: loss 0.151770
[epoch7, step683]: loss 0.181400
[epoch7, step684]: loss 0.150473
[epoch7, step685]: loss 0.151715
[epoch7, step686]: loss 0.145796
[epoch7, step687]: loss 0.160153
[epoch7, step688]: loss 0.194316
[epoch7, step689]: loss 0.151260
[epoch7, step690]: loss 0.201457
[epoch7, step691]: loss 0.210211
[epoch7, step692]: loss 0.202335
[epoch7, step693]: loss 0.184843
[epoch7, step694]: loss 0.140680
[epoch7, step695]: loss 0.164171
[epoch7, step696]: loss 0.151464
[epoch7, step697]: loss 0.184361
[epoch7, step698]: loss 0.164899
[epoch7, step699]: loss 0.169042
[epoch7, step700]: loss 0.223476
[epoch7, step701]: loss 0.192168
[epoch7, step702]: loss 0.164797
[epoch7, step703]: loss 0.218390
[epoch7, step704]: loss 0.201312
[epoch7, step705]: loss 0.152273
[epoch7, step706]: loss 0.158453
[epoch7, step707]: loss 0.163678
[epoch7, step708]: loss 0.179815
[epoch7, step709]: loss 0.156588
[epoch7, step710]: loss 0.184330
[epoch7, step711]: loss 0.202195
[epoch7, step712]: loss 0.139623
[epoch7, step713]: loss 0.161198
[epoch7, step714]: loss 0.191199
[epoch7, step715]: loss 0.158883
[epoch7, step716]: loss 0.184691
[epoch7, step717]: loss 0.155140
[epoch7, step718]: loss 0.172791
[epoch7, step719]: loss 0.175544
[epoch7, step720]: loss 0.153194
[epoch7, step721]: loss 0.169636
[epoch7, step722]: loss 0.179633
[epoch7, step723]: loss 0.172117
[epoch7, step724]: loss 0.186786
[epoch7, step725]: loss 0.185257
[epoch7, step726]: loss 0.130677
[epoch7, step727]: loss 0.182309
[epoch7, step728]: loss 0.185302
[epoch7, step729]: loss 0.149380
[epoch7, step730]: loss 0.185343
[epoch7, step731]: loss 0.200638
[epoch7, step732]: loss 0.168441
[epoch7, step733]: loss 0.137449
[epoch7, step734]: loss 0.157012
[epoch7, step735]: loss 0.155852
[epoch7, step736]: loss 0.165109
[epoch7, step737]: loss 0.145604
[epoch7, step738]: loss 0.157740
[epoch7, step739]: loss 0.220065
[epoch7, step740]: loss 0.234602
[epoch7, step741]: loss 0.179712
[epoch7, step742]: loss 0.206003
[epoch7, step743]: loss 0.176190
[epoch7, step744]: loss 0.171887
[epoch7, step745]: loss 0.174307
[epoch7, step746]: loss 0.188069
[epoch7, step747]: loss 0.168870
[epoch7, step748]: loss 0.152169
[epoch7, step749]: loss 0.221548
[epoch7, step750]: loss 0.187228
[epoch7, step751]: loss 0.164165
[epoch7, step752]: loss 0.147164
[epoch7, step753]: loss 0.150801
[epoch7, step754]: loss 0.203960
[epoch7, step755]: loss 0.185045
[epoch7, step756]: loss 0.137502
[epoch7, step757]: loss 0.173327
[epoch7, step758]: loss 0.191018
[epoch7, step759]: loss 0.151604
[epoch7, step760]: loss 0.184223
[epoch7, step761]: loss 0.166761
[epoch7, step762]: loss 0.157612
[epoch7, step763]: loss 0.158788
[epoch7, step764]: loss 0.181427
[epoch7, step765]: loss 0.156607
[epoch7, step766]: loss 0.146411
[epoch7, step767]: loss 0.188046
[epoch7, step768]: loss 0.174541
[epoch7, step769]: loss 0.174481
[epoch7, step770]: loss 0.215862
[epoch7, step771]: loss 0.145929
[epoch7, step772]: loss 0.146351
[epoch7, step773]: loss 0.166802
[epoch7, step774]: loss 0.173374
[epoch7, step775]: loss 0.212332
[epoch7, step776]: loss 0.183914
[epoch7, step777]: loss 0.161607
[epoch7, step778]: loss 0.195787
[epoch7, step779]: loss 0.166715
[epoch7, step780]: loss 0.189421
[epoch7, step781]: loss 0.215761
[epoch7, step782]: loss 0.203899
[epoch7, step783]: loss 0.176698
[epoch7, step784]: loss 0.201214
[epoch7, step785]: loss 0.196017
[epoch7, step786]: loss 0.171526
[epoch7, step787]: loss 0.212529
[epoch7, step788]: loss 0.177080
[epoch7, step789]: loss 0.203654
[epoch7, step790]: loss 0.144978
[epoch7, step791]: loss 0.185536
[epoch7, step792]: loss 0.186994
[epoch7, step793]: loss 0.188966
[epoch7, step794]: loss 0.177891
[epoch7, step795]: loss 0.171124
[epoch7, step796]: loss 0.163995
[epoch7, step797]: loss 0.150413
[epoch7, step798]: loss 0.151349
[epoch7, step799]: loss 0.129570
[epoch7, step800]: loss 0.222626
[epoch7, step801]: loss 0.207884
[epoch7, step802]: loss 0.170281
[epoch7, step803]: loss 0.157348
[epoch7, step804]: loss 0.184671
[epoch7, step805]: loss 0.164088
[epoch7, step806]: loss 0.175924
[epoch7, step807]: loss 0.193481
[epoch7, step808]: loss 0.212599
[epoch7, step809]: loss 0.159213
[epoch7, step810]: loss 0.134967
[epoch7, step811]: loss 0.172549
[epoch7, step812]: loss 0.188109
[epoch7, step813]: loss 0.158217
[epoch7, step814]: loss 0.178704
[epoch7, step815]: loss 0.168977
[epoch7, step816]: loss 0.173457
[epoch7, step817]: loss 0.150045
[epoch7, step818]: loss 0.163741
[epoch7, step819]: loss 0.248532
[epoch7, step820]: loss 0.154445
[epoch7, step821]: loss 0.151644
[epoch7, step822]: loss 0.177878
[epoch7, step823]: loss 0.149688
[epoch7, step824]: loss 0.173197
[epoch7, step825]: loss 0.181781
[epoch7, step826]: loss 0.125767
[epoch7, step827]: loss 0.154656
[epoch7, step828]: loss 0.170138
[epoch7, step829]: loss 0.157915
[epoch7, step830]: loss 0.120816
[epoch7, step831]: loss 0.148858
[epoch7, step832]: loss 0.213767
[epoch7, step833]: loss 0.176894
[epoch7, step834]: loss 0.172617
[epoch7, step835]: loss 0.179792
[epoch7, step836]: loss 0.152337
[epoch7, step837]: loss 0.143368
[epoch7, step838]: loss 0.194045
[epoch7, step839]: loss 0.170558
[epoch7, step840]: loss 0.157011
[epoch7, step841]: loss 0.169192
[epoch7, step842]: loss 0.168580
[epoch7, step843]: loss 0.191131
[epoch7, step844]: loss 0.191678
[epoch7, step845]: loss 0.182460
[epoch7, step846]: loss 0.225282
[epoch7, step847]: loss 0.171815
[epoch7, step848]: loss 0.096354
[epoch7, step849]: loss 0.157453
[epoch7, step850]: loss 0.192582
[epoch7, step851]: loss 0.164958
[epoch7, step852]: loss 0.170473
[epoch7, step853]: loss 0.185096
[epoch7, step854]: loss 0.192807
[epoch7, step855]: loss 0.153172
[epoch7, step856]: loss 0.139332
[epoch7, step857]: loss 0.181510
[epoch7, step858]: loss 0.186933
[epoch7, step859]: loss 0.154318
[epoch7, step860]: loss 0.195173
[epoch7, step861]: loss 0.175570
[epoch7, step862]: loss 0.139828
[epoch7, step863]: loss 0.191672
[epoch7, step864]: loss 0.197112
[epoch7, step865]: loss 0.181776
[epoch7, step866]: loss 0.190550
[epoch7, step867]: loss 0.160335
[epoch7, step868]: loss 0.178175
[epoch7, step869]: loss 0.151250
[epoch7, step870]: loss 0.141393
[epoch7, step871]: loss 0.212943
[epoch7, step872]: loss 0.185429
[epoch7, step873]: loss 0.143613
[epoch7, step874]: loss 0.168522
[epoch7, step875]: loss 0.217438
[epoch7, step876]: loss 0.195989
[epoch7, step877]: loss 0.109039
[epoch7, step878]: loss 0.153715
[epoch7, step879]: loss 0.163115
[epoch7, step880]: loss 0.156179
[epoch7, step881]: loss 0.197151
[epoch7, step882]: loss 0.152947
[epoch7, step883]: loss 0.160570
[epoch7, step884]: loss 0.209489
[epoch7, step885]: loss 0.210909
[epoch7, step886]: loss 0.200694
[epoch7, step887]: loss 0.213354
[epoch7, step888]: loss 0.161781
[epoch7, step889]: loss 0.187354
[epoch7, step890]: loss 0.188781
[epoch7, step891]: loss 0.160025
[epoch7, step892]: loss 0.190543
[epoch7, step893]: loss 0.183090
[epoch7, step894]: loss 0.184889
[epoch7, step895]: loss 0.143669
[epoch7, step896]: loss 0.230997
[epoch7, step897]: loss 0.228649
[epoch7, step898]: loss 0.150394
[epoch7, step899]: loss 0.108579
[epoch7, step900]: loss 0.170684
[epoch7, step901]: loss 0.198872
[epoch7, step902]: loss 0.153138
[epoch7, step903]: loss 0.204139
[epoch7, step904]: loss 0.149815
[epoch7, step905]: loss 0.141936
[epoch7, step906]: loss 0.136142
[epoch7, step907]: loss 0.188585
[epoch7, step908]: loss 0.205758
[epoch7, step909]: loss 0.165000
[epoch7, step910]: loss 0.138888
[epoch7, step911]: loss 0.133691
[epoch7, step912]: loss 0.190177
[epoch7, step913]: loss 0.193609
[epoch7, step914]: loss 0.169995
[epoch7, step915]: loss 0.152616
[epoch7, step916]: loss 0.178473
[epoch7, step917]: loss 0.172024
[epoch7, step918]: loss 0.192706
[epoch7, step919]: loss 0.142737
[epoch7, step920]: loss 0.197658
[epoch7, step921]: loss 0.156373
[epoch7, step922]: loss 0.161402
[epoch7, step923]: loss 0.204128
[epoch7, step924]: loss 0.157407
[epoch7, step925]: loss 0.157973
[epoch7, step926]: loss 0.160220
[epoch7, step927]: loss 0.200041
[epoch7, step928]: loss 0.154492
[epoch7, step929]: loss 0.163470
[epoch7, step930]: loss 0.170529
[epoch7, step931]: loss 0.187545
[epoch7, step932]: loss 0.155011
[epoch7, step933]: loss 0.159320
[epoch7, step934]: loss 0.206360
[epoch7, step935]: loss 0.175571
[epoch7, step936]: loss 0.153511
[epoch7, step937]: loss 0.138633
[epoch7, step938]: loss 0.214404
[epoch7, step939]: loss 0.159615
[epoch7, step940]: loss 0.192480
[epoch7, step941]: loss 0.176701
[epoch7, step942]: loss 0.173862
[epoch7, step943]: loss 0.201890
[epoch7, step944]: loss 0.174799
[epoch7, step945]: loss 0.195980
[epoch7, step946]: loss 0.170328
[epoch7, step947]: loss 0.151392
[epoch7, step948]: loss 0.240745
[epoch7, step949]: loss 0.173397
[epoch7, step950]: loss 0.165845
[epoch7, step951]: loss 0.180745
[epoch7, step952]: loss 0.189045
[epoch7, step953]: loss 0.169707
[epoch7, step954]: loss 0.184286
[epoch7, step955]: loss 0.136164
[epoch7, step956]: loss 0.201614
[epoch7, step957]: loss 0.182729
[epoch7, step958]: loss 0.213047
[epoch7, step959]: loss 0.193902
[epoch7, step960]: loss 0.177859
[epoch7, step961]: loss 0.194073
[epoch7, step962]: loss 0.194631
[epoch7, step963]: loss 0.201423
[epoch7, step964]: loss 0.183848
[epoch7, step965]: loss 0.205696
[epoch7, step966]: loss 0.180328
[epoch7, step967]: loss 0.205499
[epoch7, step968]: loss 0.190816
[epoch7, step969]: loss 0.168400
[epoch7, step970]: loss 0.190288
[epoch7, step971]: loss 0.192074
[epoch7, step972]: loss 0.193792
[epoch7, step973]: loss 0.186780
[epoch7, step974]: loss 0.195097
[epoch7, step975]: loss 0.177951
[epoch7, step976]: loss 0.205071
[epoch7, step977]: loss 0.184449
[epoch7, step978]: loss 0.167864
[epoch7, step979]: loss 0.192421
[epoch7, step980]: loss 0.191548
[epoch7, step981]: loss 0.196023
[epoch7, step982]: loss 0.181393
[epoch7, step983]: loss 0.195224
[epoch7, step984]: loss 0.178449
[epoch7, step985]: loss 0.205392
[epoch7, step986]: loss 0.182679
[epoch7, step987]: loss 0.163493
[epoch7, step988]: loss 0.185090
[epoch7, step989]: loss 0.187229
[epoch7, step990]: loss 0.196201
[epoch7, step991]: loss 0.177521
[epoch7, step992]: loss 0.195654
[epoch7, step993]: loss 0.178447
[epoch7, step994]: loss 0.206932
[epoch7, step995]: loss 0.186183
[epoch7, step996]: loss 0.167353
[epoch7, step997]: loss 0.186721
[epoch7, step998]: loss 0.186478
[epoch7, step999]: loss 0.193774
[epoch7, step1000]: loss 0.180936
[epoch7, step1001]: loss 0.194531
[epoch7, step1002]: loss 0.173939
[epoch7, step1003]: loss 0.204605
[epoch7, step1004]: loss 0.183452
[epoch7, step1005]: loss 0.169042
[epoch7, step1006]: loss 0.187510
[epoch7, step1007]: loss 0.190301
[epoch7, step1008]: loss 0.196191
[epoch7, step1009]: loss 0.180384
[epoch7, step1010]: loss 0.191144
[epoch7, step1011]: loss 0.175531
[epoch7, step1012]: loss 0.199931
[epoch7, step1013]: loss 0.184380
[epoch7, step1014]: loss 0.164624
[epoch7, step1015]: loss 0.185225
[epoch7, step1016]: loss 0.189936
[epoch7, step1017]: loss 0.196277
[epoch7, step1018]: loss 0.179761
[epoch7, step1019]: loss 0.193941
[epoch7, step1020]: loss 0.177484
[epoch7, step1021]: loss 0.203556
[epoch7, step1022]: loss 0.185260
[epoch7, step1023]: loss 0.166675
[epoch7, step1024]: loss 0.181529
[epoch7, step1025]: loss 0.191736
[epoch7, step1026]: loss 0.198019
[epoch7, step1027]: loss 0.178472
[epoch7, step1028]: loss 0.194083
[epoch7, step1029]: loss 0.175537
[epoch7, step1030]: loss 0.204374
[epoch7, step1031]: loss 0.192710
[epoch7, step1032]: loss 0.165182
[epoch7, step1033]: loss 0.190638
[epoch7, step1034]: loss 0.190252
[epoch7, step1035]: loss 0.197971
[epoch7, step1036]: loss 0.180896
[epoch7, step1037]: loss 0.195344
[epoch7, step1038]: loss 0.176064
[epoch7, step1039]: loss 0.201384
[epoch7, step1040]: loss 0.187954
[epoch7, step1041]: loss 0.167985
[epoch7, step1042]: loss 0.188432
[epoch7, step1043]: loss 0.189075
[epoch7, step1044]: loss 0.193237
[epoch7, step1045]: loss 0.178284
[epoch7, step1046]: loss 0.193270
[epoch7, step1047]: loss 0.173583
[epoch7, step1048]: loss 0.204894
[epoch7, step1049]: loss 0.184551
[epoch7, step1050]: loss 0.165531
[epoch7, step1051]: loss 0.185716
[epoch7, step1052]: loss 0.187214
[epoch7, step1053]: loss 0.194048
[epoch7, step1054]: loss 0.180617
[epoch7, step1055]: loss 0.196339
[epoch7, step1056]: loss 0.177871
[epoch7, step1057]: loss 0.198305
[epoch7, step1058]: loss 0.180071
[epoch7, step1059]: loss 0.165386
[epoch7, step1060]: loss 0.183203
[epoch7, step1061]: loss 0.192406
[epoch7, step1062]: loss 0.191577
[epoch7, step1063]: loss 0.179887
[epoch7, step1064]: loss 0.193849
[epoch7, step1065]: loss 0.177275
[epoch7, step1066]: loss 0.203631
[epoch7, step1067]: loss 0.184285
[epoch7, step1068]: loss 0.173860
[epoch7, step1069]: loss 0.183769
[epoch7, step1070]: loss 0.187847
[epoch7, step1071]: loss 0.190127
[epoch7, step1072]: loss 0.175282
[epoch7, step1073]: loss 0.193992
[epoch7, step1074]: loss 0.177063
[epoch7, step1075]: loss 0.199678
[epoch7, step1076]: loss 0.183251
[epoch7, step1077]: loss 0.164991
[epoch7, step1078]: loss 0.187033
[epoch7, step1079]: loss 0.183035
[epoch7, step1080]: loss 0.191554
[epoch7, step1081]: loss 0.181728
[epoch7, step1082]: loss 0.194002
[epoch7, step1083]: loss 0.172823
[epoch7, step1084]: loss 0.199773
[epoch7, step1085]: loss 0.186797
[epoch7, step1086]: loss 0.168236
[epoch7, step1087]: loss 0.185805
[epoch7, step1088]: loss 0.188997
[epoch7, step1089]: loss 0.190822
[epoch7, step1090]: loss 0.176165
[epoch7, step1091]: loss 0.191641
[epoch7, step1092]: loss 0.175618
[epoch7, step1093]: loss 0.200454
[epoch7, step1094]: loss 0.188808
[epoch7, step1095]: loss 0.165766
[epoch7, step1096]: loss 0.188207
[epoch7, step1097]: loss 0.186553
[epoch7, step1098]: loss 0.193718
[epoch7, step1099]: loss 0.180796
[epoch7, step1100]: loss 0.189691
[epoch7, step1101]: loss 0.175888
[epoch7, step1102]: loss 0.201789
[epoch7, step1103]: loss 0.186285
[epoch7, step1104]: loss 0.165105
[epoch7, step1105]: loss 0.183140
[epoch7, step1106]: loss 0.191782
[epoch7, step1107]: loss 0.192064
[epoch7, step1108]: loss 0.180679
[epoch7, step1109]: loss 0.190053
[epoch7, step1110]: loss 0.170825
[epoch7, step1111]: loss 0.199524
[epoch7, step1112]: loss 0.181475
[epoch7, step1113]: loss 0.165472
[epoch7, step1114]: loss 0.183732
[epoch7, step1115]: loss 0.185457
[epoch7, step1116]: loss 0.191621
[epoch7, step1117]: loss 0.177587
[epoch7, step1118]: loss 0.193012
[epoch7, step1119]: loss 0.177681
[epoch7, step1120]: loss 0.201406
[epoch7, step1121]: loss 0.183737
[epoch7, step1122]: loss 0.165787
[epoch7, step1123]: loss 0.187479
[epoch7, step1124]: loss 0.183842
[epoch7, step1125]: loss 0.190315
[epoch7, step1126]: loss 0.174174
[epoch7, step1127]: loss 0.191313
[epoch7, step1128]: loss 0.174547
[epoch7, step1129]: loss 0.200839
[epoch7, step1130]: loss 0.178190
[epoch7, step1131]: loss 0.162623
[epoch7, step1132]: loss 0.182354
[epoch7, step1133]: loss 0.189071
[epoch7, step1134]: loss 0.192905
[epoch7, step1135]: loss 0.171819
[epoch7, step1136]: loss 0.188173
[epoch7, step1137]: loss 0.171511
[epoch7, step1138]: loss 0.198155
[epoch7, step1139]: loss 0.183944
[epoch7, step1140]: loss 0.164430
[epoch7, step1141]: loss 0.182509
[epoch7, step1142]: loss 0.188450
[epoch7, step1143]: loss 0.193992
[epoch7, step1144]: loss 0.178400
[epoch7, step1145]: loss 0.194186
[epoch7, step1146]: loss 0.172647
[epoch7, step1147]: loss 0.194666
[epoch7, step1148]: loss 0.182972
[epoch7, step1149]: loss 0.163803
[epoch7, step1150]: loss 0.185968
[epoch7, step1151]: loss 0.185514
[epoch7, step1152]: loss 0.188114
[epoch7, step1153]: loss 0.179667
[epoch7, step1154]: loss 0.189445
[epoch7, step1155]: loss 0.172222
[epoch7, step1156]: loss 0.202630
[epoch7, step1157]: loss 0.184595
[epoch7, step1158]: loss 0.161707
[epoch7, step1159]: loss 0.181868
[epoch7, step1160]: loss 0.182531
[epoch7, step1161]: loss 0.188103
[epoch7, step1162]: loss 0.177935
[epoch7, step1163]: loss 0.194407
[epoch7, step1164]: loss 0.171617
[epoch7, step1165]: loss 0.193064
[epoch7, step1166]: loss 0.180964
[epoch7, step1167]: loss 0.165028
[epoch7, step1168]: loss 0.182399
[epoch7, step1169]: loss 0.186836
[epoch7, step1170]: loss 0.190918
[epoch7, step1171]: loss 0.177925
[epoch7, step1172]: loss 0.191435
[epoch7, step1173]: loss 0.172986
[epoch7, step1174]: loss 0.196142
[epoch7, step1175]: loss 0.183418
[epoch7, step1176]: loss 0.164180
[epoch7, step1177]: loss 0.180091
[epoch7, step1178]: loss 0.183912
[epoch7, step1179]: loss 0.190986
[epoch7, step1180]: loss 0.175967
[epoch7, step1181]: loss 0.187751
[epoch7, step1182]: loss 0.174271
[epoch7, step1183]: loss 0.194978
[epoch7, step1184]: loss 0.185119
[epoch7, step1185]: loss 0.164884
[epoch7, step1186]: loss 0.184197
[epoch7, step1187]: loss 0.189948
[epoch7, step1188]: loss 0.192825
[epoch7, step1189]: loss 0.176847
[epoch7, step1190]: loss 0.192446
[epoch7, step1191]: loss 0.171652
[epoch7, step1192]: loss 0.196199
[epoch7, step1193]: loss 0.181367
[epoch7, step1194]: loss 0.163532
[epoch7, step1195]: loss 0.189078
[epoch7, step1196]: loss 0.188559
[epoch7, step1197]: loss 0.189230
[epoch7, step1198]: loss 0.175388
[epoch7, step1199]: loss 0.191721
[epoch7, step1200]: loss 0.172088
[epoch7, step1201]: loss 0.195181
[epoch7, step1202]: loss 0.176936
[epoch7, step1203]: loss 0.165603
[epoch7, step1204]: loss 0.183836
[epoch7, step1205]: loss 0.185914
[epoch7, step1206]: loss 0.192676
[epoch7, step1207]: loss 0.172682
[epoch7, step1208]: loss 0.188534
[epoch7, step1209]: loss 0.174430
[epoch7, step1210]: loss 0.194409
[epoch7, step1211]: loss 0.184285
[epoch7, step1212]: loss 0.165058
[epoch7, step1213]: loss 0.185368
[epoch7, step1214]: loss 0.183928
[epoch7, step1215]: loss 0.186137
[epoch7, step1216]: loss 0.175980
[epoch7, step1217]: loss 0.186748
[epoch7, step1218]: loss 0.171436
[epoch7, step1219]: loss 0.194024
[epoch7, step1220]: loss 0.178899
[epoch7, step1221]: loss 0.164859
[epoch7, step1222]: loss 0.181557
[epoch7, step1223]: loss 0.184366
[epoch7, step1224]: loss 0.186464
[epoch7, step1225]: loss 0.175393
[epoch7, step1226]: loss 0.191710
[epoch7, step1227]: loss 0.169325
[epoch7, step1228]: loss 0.198119
[epoch7, step1229]: loss 0.183718
[epoch7, step1230]: loss 0.164319
[epoch7, step1231]: loss 0.183684
[epoch7, step1232]: loss 0.180003
[epoch7, step1233]: loss 0.189845
[epoch7, step1234]: loss 0.176220
[epoch7, step1235]: loss 0.186989
[epoch7, step1236]: loss 0.173523
[epoch7, step1237]: loss 0.199062
[epoch7, step1238]: loss 0.184024
[epoch7, step1239]: loss 0.159902
[epoch7, step1240]: loss 0.179292
[epoch7, step1241]: loss 0.188053
[epoch7, step1242]: loss 0.189781
[epoch7, step1243]: loss 0.173839
[epoch7, step1244]: loss 0.187793
[epoch7, step1245]: loss 0.167815
[epoch7, step1246]: loss 0.195061
[epoch7, step1247]: loss 0.185218
[epoch7, step1248]: loss 0.162761
[epoch7, step1249]: loss 0.178517
[epoch7, step1250]: loss 0.184311
[epoch7, step1251]: loss 0.187813
[epoch7, step1252]: loss 0.173258
[epoch7, step1253]: loss 0.187186
[epoch7, step1254]: loss 0.170309
[epoch7, step1255]: loss 0.195848
[epoch7, step1256]: loss 0.177948
[epoch7, step1257]: loss 0.160791
[epoch7, step1258]: loss 0.181269
[epoch7, step1259]: loss 0.184902
[epoch7, step1260]: loss 0.188270
[epoch7, step1261]: loss 0.175996
[epoch7, step1262]: loss 0.193926
[epoch7, step1263]: loss 0.166525
[epoch7, step1264]: loss 0.197001
[epoch7, step1265]: loss 0.187248
[epoch7, step1266]: loss 0.163233
[epoch7, step1267]: loss 0.180834
[epoch7, step1268]: loss 0.182825
[epoch7, step1269]: loss 0.187291
[epoch7, step1270]: loss 0.177743
[epoch7, step1271]: loss 0.186183
[epoch7, step1272]: loss 0.169491
[epoch7, step1273]: loss 0.197571
[epoch7, step1274]: loss 0.182410
[epoch7, step1275]: loss 0.161811
[epoch7, step1276]: loss 0.181052
[epoch7, step1277]: loss 0.183701
[epoch7, step1278]: loss 0.184939
[epoch7, step1279]: loss 0.173228
[epoch7, step1280]: loss 0.187208
[epoch7, step1281]: loss 0.170537
[epoch7, step1282]: loss 0.195116
[epoch7, step1283]: loss 0.182800
[epoch7, step1284]: loss 0.160549
[epoch7, step1285]: loss 0.179725
[epoch7, step1286]: loss 0.185775
[epoch7, step1287]: loss 0.183597
[epoch7, step1288]: loss 0.170980
[epoch7, step1289]: loss 0.183264
[epoch7, step1290]: loss 0.171515
[epoch7, step1291]: loss 0.196371
[epoch7, step1292]: loss 0.175855
[epoch7, step1293]: loss 0.162569
[epoch7, step1294]: loss 0.179348
[epoch7, step1295]: loss 0.179966
[epoch7, step1296]: loss 0.186178
[epoch7, step1297]: loss 0.172111
[epoch7, step1298]: loss 0.184644
[epoch7, step1299]: loss 0.170142
[epoch7, step1300]: loss 0.192297
[epoch7, step1301]: loss 0.184985
[epoch7, step1302]: loss 0.160713
[epoch7, step1303]: loss 0.181454
[epoch7, step1304]: loss 0.185417
[epoch7, step1305]: loss 0.184361
[epoch7, step1306]: loss 0.174334
[epoch7, step1307]: loss 0.190229
[epoch7, step1308]: loss 0.170577
[epoch7, step1309]: loss 0.198059
[epoch7, step1310]: loss 0.179823
[epoch7, step1311]: loss 0.164093
[epoch7, step1312]: loss 0.179044
[epoch7, step1313]: loss 0.182149
[epoch7, step1314]: loss 0.188340
[epoch7, step1315]: loss 0.173881
[epoch7, step1316]: loss 0.180355
[epoch7, step1317]: loss 0.171849
[epoch7, step1318]: loss 0.197731
[epoch7, step1319]: loss 0.181037
[epoch7, step1320]: loss 0.160660
[epoch7, step1321]: loss 0.176224
[epoch7, step1322]: loss 0.184356
[epoch7, step1323]: loss 0.184624
[epoch7, step1324]: loss 0.174899
[epoch7, step1325]: loss 0.187244
[epoch7, step1326]: loss 0.172131
[epoch7, step1327]: loss 0.194407
[epoch7, step1328]: loss 0.179108
[epoch7, step1329]: loss 0.161336
[epoch7, step1330]: loss 0.178718
[epoch7, step1331]: loss 0.184044
[epoch7, step1332]: loss 0.187960
[epoch7, step1333]: loss 0.179043
[epoch7, step1334]: loss 0.184739
[epoch7, step1335]: loss 0.168749
[epoch7, step1336]: loss 0.193338
[epoch7, step1337]: loss 0.182966
[epoch7, step1338]: loss 0.160360
[epoch7, step1339]: loss 0.180898
[epoch7, step1340]: loss 0.184688
[epoch7, step1341]: loss 0.186267
[epoch7, step1342]: loss 0.173210
[epoch7, step1343]: loss 0.185171
[epoch7, step1344]: loss 0.167284
[epoch7, step1345]: loss 0.193281
[epoch7, step1346]: loss 0.180689
[epoch7, step1347]: loss 0.158003
[epoch7, step1348]: loss 0.181485
[epoch7, step1349]: loss 0.181603
[epoch7, step1350]: loss 0.184627
[epoch7, step1351]: loss 0.177262
[epoch7, step1352]: loss 0.188520
[epoch7, step1353]: loss 0.172082
[epoch7, step1354]: loss 0.195766
[epoch7, step1355]: loss 0.178527
[epoch7, step1356]: loss 0.164443
[epoch7, step1357]: loss 0.182287
[epoch7, step1358]: loss 0.181965
[epoch7, step1359]: loss 0.187540
[epoch7, step1360]: loss 0.170454
[epoch7, step1361]: loss 0.184596
[epoch7, step1362]: loss 0.167555
[epoch7, step1363]: loss 0.190164
[epoch7, step1364]: loss 0.178421
[epoch7, step1365]: loss 0.160870
[epoch7, step1366]: loss 0.179000
[epoch7, step1367]: loss 0.184529
[epoch7, step1368]: loss 0.180249
[epoch7, step1369]: loss 0.173309
[epoch7, step1370]: loss 0.187311
[epoch7, step1371]: loss 0.167261
[epoch7, step1372]: loss 0.193050
[epoch7, step1373]: loss 0.178442
[epoch7, step1374]: loss 0.156566
[epoch7, step1375]: loss 0.175887
[epoch7, step1376]: loss 0.181398
[epoch7, step1377]: loss 0.190099
[epoch7, step1378]: loss 0.172790
[epoch7, step1379]: loss 0.187743
[epoch7, step1380]: loss 0.164722
[epoch7, step1381]: loss 0.192426
[epoch7, step1382]: loss 0.177256
[epoch7, step1383]: loss 0.159847
[epoch7, step1384]: loss 0.177096
[epoch7, step1385]: loss 0.182995
[epoch7, step1386]: loss 0.184064
[epoch7, step1387]: loss 0.168744
[epoch7, step1388]: loss 0.190550
[epoch7, step1389]: loss 0.170198
[epoch7, step1390]: loss 0.191592
[epoch7, step1391]: loss 0.178538
[epoch7, step1392]: loss 0.160958
[epoch7, step1393]: loss 0.175762
[epoch7, step1394]: loss 0.177537
[epoch7, step1395]: loss 0.184081
[epoch7, step1396]: loss 0.172059
[epoch7, step1397]: loss 0.186318
[epoch7, step1398]: loss 0.167070
[epoch7, step1399]: loss 0.187181
[epoch7, step1400]: loss 0.176805
[epoch7, step1401]: loss 0.158102
[epoch7, step1402]: loss 0.177525
[epoch7, step1403]: loss 0.184938
[epoch7, step1404]: loss 0.186756
[epoch7, step1405]: loss 0.169607
[epoch7, step1406]: loss 0.186579
[epoch7, step1407]: loss 0.163228
[epoch7, step1408]: loss 0.195207
[epoch7, step1409]: loss 0.179787
[epoch7, step1410]: loss 0.157346
[epoch7, step1411]: loss 0.182927
[epoch7, step1412]: loss 0.180091
[epoch7, step1413]: loss 0.184462
[epoch7, step1414]: loss 0.173312
[epoch7, step1415]: loss 0.186217
[epoch7, step1416]: loss 0.165987
[epoch7, step1417]: loss 0.192903
[epoch7, step1418]: loss 0.177947
[epoch7, step1419]: loss 0.156259
[epoch7, step1420]: loss 0.177790
[epoch7, step1421]: loss 0.178106
[epoch7, step1422]: loss 0.182473
[epoch7, step1423]: loss 0.172836
[epoch7, step1424]: loss 0.184331
[epoch7, step1425]: loss 0.169500
[epoch7, step1426]: loss 0.191546
[epoch7, step1427]: loss 0.173324
[epoch7, step1428]: loss 0.158890
[epoch7, step1429]: loss 0.175953
[epoch7, step1430]: loss 0.181102
[epoch7, step1431]: loss 0.183561
[epoch7, step1432]: loss 0.172109
[epoch7, step1433]: loss 0.184048
[epoch7, step1434]: loss 0.172386
[epoch7, step1435]: loss 0.189096
[epoch7, step1436]: loss 0.175385
[epoch7, step1437]: loss 0.156934
[epoch7, step1438]: loss 0.176004
[epoch7, step1439]: loss 0.181338
[epoch7, step1440]: loss 0.185151
[epoch7, step1441]: loss 0.167981
[epoch7, step1442]: loss 0.188275
[epoch7, step1443]: loss 0.171587
[epoch7, step1444]: loss 0.194361
[epoch7, step1445]: loss 0.175175
[epoch7, step1446]: loss 0.156210
[epoch7, step1447]: loss 0.174621
[epoch7, step1448]: loss 0.180303
[epoch7, step1449]: loss 0.185784
[epoch7, step1450]: loss 0.171205
[epoch7, step1451]: loss 0.182439
[epoch7, step1452]: loss 0.168279
[epoch7, step1453]: loss 0.186143
[epoch7, step1454]: loss 0.174455
[epoch7, step1455]: loss 0.154321
[epoch7, step1456]: loss 0.178468
[epoch7, step1457]: loss 0.176049
[epoch7, step1458]: loss 0.183047
[epoch7, step1459]: loss 0.172771
[epoch7, step1460]: loss 0.181536
[epoch7, step1461]: loss 0.163331
[epoch7, step1462]: loss 0.186576
[epoch7, step1463]: loss 0.177600
[epoch7, step1464]: loss 0.155370
[epoch7, step1465]: loss 0.179483
[epoch7, step1466]: loss 0.180164
[epoch7, step1467]: loss 0.185314
[epoch7, step1468]: loss 0.172530
[epoch7, step1469]: loss 0.184158
[epoch7, step1470]: loss 0.165415
[epoch7, step1471]: loss 0.193242
[epoch7, step1472]: loss 0.177563
[epoch7, step1473]: loss 0.156615
[epoch7, step1474]: loss 0.173416
[epoch7, step1475]: loss 0.180379
[epoch7, step1476]: loss 0.180185
[epoch7, step1477]: loss 0.173030
[epoch7, step1478]: loss 0.183295
[epoch7, step1479]: loss 0.166115
[epoch7, step1480]: loss 0.190028
[epoch7, step1481]: loss 0.181369
[epoch7, step1482]: loss 0.158082
[epoch7, step1483]: loss 0.176449
[epoch7, step1484]: loss 0.177748
[epoch7, step1485]: loss 0.182638
[epoch7, step1486]: loss 0.174582
[epoch7, step1487]: loss 0.183839
[epoch7, step1488]: loss 0.165304
[epoch7, step1489]: loss 0.190895
[epoch7, step1490]: loss 0.174953
[epoch7, step1491]: loss 0.158715
[epoch7, step1492]: loss 0.178511
[epoch7, step1493]: loss 0.179296
[epoch7, step1494]: loss 0.182730
[epoch7, step1495]: loss 0.173475
[epoch7, step1496]: loss 0.187269
[epoch7, step1497]: loss 0.164515
[epoch7, step1498]: loss 0.187462
[epoch7, step1499]: loss 0.178793
[epoch7, step1500]: loss 0.156619
[epoch7, step1501]: loss 0.175825
[epoch7, step1502]: loss 0.179005
[epoch7, step1503]: loss 0.183744
[epoch7, step1504]: loss 0.173044
[epoch7, step1505]: loss 0.181869
[epoch7, step1506]: loss 0.166918
[epoch7, step1507]: loss 0.187842
[epoch7, step1508]: loss 0.173557
[epoch7, step1509]: loss 0.159269
[epoch7, step1510]: loss 0.181382
[epoch7, step1511]: loss 0.175001
[epoch7, step1512]: loss 0.181016
[epoch7, step1513]: loss 0.175744
[epoch7, step1514]: loss 0.183107
[epoch7, step1515]: loss 0.165183
[epoch7, step1516]: loss 0.189168

[epoch7]: avg loss 0.188872

[epoch8, step1]: loss 0.182009
[epoch8, step2]: loss 0.180657
[epoch8, step3]: loss 0.182508
[epoch8, step4]: loss 0.170947
[epoch8, step5]: loss 0.189616
[epoch8, step6]: loss 0.176154
[epoch8, step7]: loss 0.161000
[epoch8, step8]: loss 0.183498
[epoch8, step9]: loss 0.165000
[epoch8, step10]: loss 0.183769
[epoch8, step11]: loss 0.179752
[epoch8, step12]: loss 0.180927
[epoch8, step13]: loss 0.164245
[epoch8, step14]: loss 0.188875
[epoch8, step15]: loss 0.176054
[epoch8, step16]: loss 0.161710
[epoch8, step17]: loss 0.181091
[epoch8, step18]: loss 0.159790
[epoch8, step19]: loss 0.186270
[epoch8, step20]: loss 0.174988
[epoch8, step21]: loss 0.181533
[epoch8, step22]: loss 0.168049
[epoch8, step23]: loss 0.194909
[epoch8, step24]: loss 0.174143
[epoch8, step25]: loss 0.162304
[epoch8, step26]: loss 0.186622
[epoch8, step27]: loss 0.164799
[epoch8, step28]: loss 0.185477
[epoch8, step29]: loss 0.177799
[epoch8, step30]: loss 0.177074
[epoch8, step31]: loss 0.166632
[epoch8, step32]: loss 0.187315
[epoch8, step33]: loss 0.172148
[epoch8, step34]: loss 0.159499
[epoch8, step35]: loss 0.181082
[epoch8, step36]: loss 0.164363
[epoch8, step37]: loss 0.186335
[epoch8, step38]: loss 0.179400
[epoch8, step39]: loss 0.180451
[epoch8, step40]: loss 0.162956
[epoch8, step41]: loss 0.192467
[epoch8, step42]: loss 0.172792
[epoch8, step43]: loss 0.163160
[epoch8, step44]: loss 0.181736
[epoch8, step45]: loss 0.164073
[epoch8, step46]: loss 0.186206
[epoch8, step47]: loss 0.180749
[epoch8, step48]: loss 0.181636
[epoch8, step49]: loss 0.169052
[epoch8, step50]: loss 0.189039
[epoch8, step51]: loss 0.174843
[epoch8, step52]: loss 0.163427
[epoch8, step53]: loss 0.179148
[epoch8, step54]: loss 0.162196
[epoch8, step55]: loss 0.183601
[epoch8, step56]: loss 0.172691
[epoch8, step57]: loss 0.177783
[epoch8, step58]: loss 0.163957
[epoch8, step59]: loss 0.194307
[epoch8, step60]: loss 0.170845
[epoch8, step61]: loss 0.163993
[epoch8, step62]: loss 0.184874
[epoch8, step63]: loss 0.166359
[epoch8, step64]: loss 0.189514
[epoch8, step65]: loss 0.176673
[epoch8, step66]: loss 0.179666
[epoch8, step67]: loss 0.165893
[epoch8, step68]: loss 0.189444
[epoch8, step69]: loss 0.174152
[epoch8, step70]: loss 0.162729
[epoch8, step71]: loss 0.184077
[epoch8, step72]: loss 0.162295
[epoch8, step73]: loss 0.186494
[epoch8, step74]: loss 0.176597
[epoch8, step75]: loss 0.178259
[epoch8, step76]: loss 0.164547
[epoch8, step77]: loss 0.185542
[epoch8, step78]: loss 0.172579
[epoch8, step79]: loss 0.163836
[epoch8, step80]: loss 0.177726
[epoch8, step81]: loss 0.161291
[epoch8, step82]: loss 0.188501
[epoch8, step83]: loss 0.181344
[epoch8, step84]: loss 0.178288
[epoch8, step85]: loss 0.161338
[epoch8, step86]: loss 0.186598
[epoch8, step87]: loss 0.169156
[epoch8, step88]: loss 0.170197
[epoch8, step89]: loss 0.183780
[epoch8, step90]: loss 0.163613
[epoch8, step91]: loss 0.190588
[epoch8, step92]: loss 0.176278
[epoch8, step93]: loss 0.178015
[epoch8, step94]: loss 0.166223
[epoch8, step95]: loss 0.185918
[epoch8, step96]: loss 0.174559
[epoch8, step97]: loss 0.159170
[epoch8, step98]: loss 0.181510
[epoch8, step99]: loss 0.162918
[epoch8, step100]: loss 0.190389
[epoch8, step101]: loss 0.173434
[epoch8, step102]: loss 0.179405
[epoch8, step103]: loss 0.165387
[epoch8, step104]: loss 0.188050
[epoch8, step105]: loss 0.170989
[epoch8, step106]: loss 0.162122
[epoch8, step107]: loss 0.181679
[epoch8, step108]: loss 0.161384
[epoch8, step109]: loss 0.186675
[epoch8, step110]: loss 0.173514
[epoch8, step111]: loss 0.179331
[epoch8, step112]: loss 0.165784
[epoch8, step113]: loss 0.183566
[epoch8, step114]: loss 0.174006
[epoch8, step115]: loss 0.161710
[epoch8, step116]: loss 0.177306
[epoch8, step117]: loss 0.161125
[epoch8, step118]: loss 0.181218
[epoch8, step119]: loss 0.174120
[epoch8, step120]: loss 0.176763
[epoch8, step121]: loss 0.165137
[epoch8, step122]: loss 0.187335
[epoch8, step123]: loss 0.170639
[epoch8, step124]: loss 0.161169
[epoch8, step125]: loss 0.178267
[epoch8, step126]: loss 0.162719
[epoch8, step127]: loss 0.185918
[epoch8, step128]: loss 0.176568
[epoch8, step129]: loss 0.177640
[epoch8, step130]: loss 0.161384
[epoch8, step131]: loss 0.190001
[epoch8, step132]: loss 0.171422
[epoch8, step133]: loss 0.159895
[epoch8, step134]: loss 0.183681
[epoch8, step135]: loss 0.159306
[epoch8, step136]: loss 0.178709
[epoch8, step137]: loss 0.177228
[epoch8, step138]: loss 0.177909
[epoch8, step139]: loss 0.163478
[epoch8, step140]: loss 0.184497
[epoch8, step141]: loss 0.170628
[epoch8, step142]: loss 0.160463
[epoch8, step143]: loss 0.182252
[epoch8, step144]: loss 0.163695
[epoch8, step145]: loss 0.184629
[epoch8, step146]: loss 0.175657
[epoch8, step147]: loss 0.171553
[epoch8, step148]: loss 0.162875
[epoch8, step149]: loss 0.189515
[epoch8, step150]: loss 0.173599
[epoch8, step151]: loss 0.157838
[epoch8, step152]: loss 0.179945
[epoch8, step153]: loss 0.159376
[epoch8, step154]: loss 0.187135
[epoch8, step155]: loss 0.175004
[epoch8, step156]: loss 0.179575
[epoch8, step157]: loss 0.161405
[epoch8, step158]: loss 0.184557
[epoch8, step159]: loss 0.170499
[epoch8, step160]: loss 0.158390
[epoch8, step161]: loss 0.176574
[epoch8, step162]: loss 0.159574
[epoch8, step163]: loss 0.184580
[epoch8, step164]: loss 0.172820
[epoch8, step165]: loss 0.176746
[epoch8, step166]: loss 0.159665
[epoch8, step167]: loss 0.188288
[epoch8, step168]: loss 0.167454
[epoch8, step169]: loss 0.161591
[epoch8, step170]: loss 0.177817
[epoch8, step171]: loss 0.159685
[epoch8, step172]: loss 0.183457
[epoch8, step173]: loss 0.173229
[epoch8, step174]: loss 0.178011
[epoch8, step175]: loss 0.157874
[epoch8, step176]: loss 0.185130
[epoch8, step177]: loss 0.169335
[epoch8, step178]: loss 0.156233
[epoch8, step179]: loss 0.182924
[epoch8, step180]: loss 0.157118
[epoch8, step181]: loss 0.182183
[epoch8, step182]: loss 0.172481
[epoch8, step183]: loss 0.173304
[epoch8, step184]: loss 0.157769
[epoch8, step185]: loss 0.184539
[epoch8, step186]: loss 0.168845
[epoch8, step187]: loss 0.160151
[epoch8, step188]: loss 0.179927
[epoch8, step189]: loss 0.158420
[epoch8, step190]: loss 0.186379
[epoch8, step191]: loss 0.174884
[epoch8, step192]: loss 0.173225
[epoch8, step193]: loss 0.169657
[epoch8, step194]: loss 0.189050
[epoch8, step195]: loss 0.168655
[epoch8, step196]: loss 0.157169
[epoch8, step197]: loss 0.179349
[epoch8, step198]: loss 0.162292
[epoch8, step199]: loss 0.182524
[epoch8, step200]: loss 0.170610
[epoch8, step201]: loss 0.173222
[epoch8, step202]: loss 0.162208
[epoch8, step203]: loss 0.185142
[epoch8, step204]: loss 0.167782
[epoch8, step205]: loss 0.162145
[epoch8, step206]: loss 0.179889
[epoch8, step207]: loss 0.158819
[epoch8, step208]: loss 0.180153
[epoch8, step209]: loss 0.171622
[epoch8, step210]: loss 0.171240
[epoch8, step211]: loss 0.160481
[epoch8, step212]: loss 0.183405
[epoch8, step213]: loss 0.170981
[epoch8, step214]: loss 0.163071
[epoch8, step215]: loss 0.177108
[epoch8, step216]: loss 0.158084
[epoch8, step217]: loss 0.186487
[epoch8, step218]: loss 0.171239
[epoch8, step219]: loss 0.176295
[epoch8, step220]: loss 0.163116
[epoch8, step221]: loss 0.183243
[epoch8, step222]: loss 0.167366
[epoch8, step223]: loss 0.155054
[epoch8, step224]: loss 0.179429
[epoch8, step225]: loss 0.158110
[epoch8, step226]: loss 0.184180
[epoch8, step227]: loss 0.177338
[epoch8, step228]: loss 0.172399
[epoch8, step229]: loss 0.164649
[epoch8, step230]: loss 0.182213
[epoch8, step231]: loss 0.166813
[epoch8, step232]: loss 0.159092
[epoch8, step233]: loss 0.181413
[epoch8, step234]: loss 0.160729
[epoch8, step235]: loss 0.182413
[epoch8, step236]: loss 0.172140
[epoch8, step237]: loss 0.174663
[epoch8, step238]: loss 0.160004
[epoch8, step239]: loss 0.187232
[epoch8, step240]: loss 0.173122
[epoch8, step241]: loss 0.157265
[epoch8, step242]: loss 0.178518
[epoch8, step243]: loss 0.157336
[epoch8, step244]: loss 0.183306
[epoch8, step245]: loss 0.174605
[epoch8, step246]: loss 0.174869
[epoch8, step247]: loss 0.160824
[epoch8, step248]: loss 0.185617
[epoch8, step249]: loss 0.171170
[epoch8, step250]: loss 0.156737
[epoch8, step251]: loss 0.174764
[epoch8, step252]: loss 0.156155
[epoch8, step253]: loss 0.184445
[epoch8, step254]: loss 0.175837
[epoch8, step255]: loss 0.173219
[epoch8, step256]: loss 0.163099
[epoch8, step257]: loss 0.184724
[epoch8, step258]: loss 0.166031
[epoch8, step259]: loss 0.155752
[epoch8, step260]: loss 0.180056
[epoch8, step261]: loss 0.153814
[epoch8, step262]: loss 0.179380
[epoch8, step263]: loss 0.175818
[epoch8, step264]: loss 0.175271
[epoch8, step265]: loss 0.160720
[epoch8, step266]: loss 0.183955
[epoch8, step267]: loss 0.172484
[epoch8, step268]: loss 0.157524
[epoch8, step269]: loss 0.176533
[epoch8, step270]: loss 0.159131
[epoch8, step271]: loss 0.180543
[epoch8, step272]: loss 0.172377
[epoch8, step273]: loss 0.175194
[epoch8, step274]: loss 0.157040
[epoch8, step275]: loss 0.186533
[epoch8, step276]: loss 0.170923
[epoch8, step277]: loss 0.156165
[epoch8, step278]: loss 0.176010
[epoch8, step279]: loss 0.156886
[epoch8, step280]: loss 0.180615
[epoch8, step281]: loss 0.172950
[epoch8, step282]: loss 0.171237
[epoch8, step283]: loss 0.162070
[epoch8, step284]: loss 0.185393
[epoch8, step285]: loss 0.164771
[epoch8, step286]: loss 0.164755
[epoch8, step287]: loss 0.175872
[epoch8, step288]: loss 0.159672
[epoch8, step289]: loss 0.178775
[epoch8, step290]: loss 0.171834
[epoch8, step291]: loss 0.172225
[epoch8, step292]: loss 0.163240
[epoch8, step293]: loss 0.184093
[epoch8, step294]: loss 0.170253
[epoch8, step295]: loss 0.158431
[epoch8, step296]: loss 0.173156
[epoch8, step297]: loss 0.159377
[epoch8, step298]: loss 0.180314
[epoch8, step299]: loss 0.175639
[epoch8, step300]: loss 0.171661
[epoch8, step301]: loss 0.162098
[epoch8, step302]: loss 0.180794
[epoch8, step303]: loss 0.166110
[epoch8, step304]: loss 0.156023
[epoch8, step305]: loss 0.177921
[epoch8, step306]: loss 0.157111
[epoch8, step307]: loss 0.183005
[epoch8, step308]: loss 0.168997
[epoch8, step309]: loss 0.170850
[epoch8, step310]: loss 0.160064
[epoch8, step311]: loss 0.180444
[epoch8, step312]: loss 0.168955
[epoch8, step313]: loss 0.157354
[epoch8, step314]: loss 0.175963
[epoch8, step315]: loss 0.155471
[epoch8, step316]: loss 0.182150
[epoch8, step317]: loss 0.170312
[epoch8, step318]: loss 0.172695
[epoch8, step319]: loss 0.162489
[epoch8, step320]: loss 0.186964
[epoch8, step321]: loss 0.169454
[epoch8, step322]: loss 0.160649
[epoch8, step323]: loss 0.179060
[epoch8, step324]: loss 0.154699
[epoch8, step325]: loss 0.179745
[epoch8, step326]: loss 0.172277
[epoch8, step327]: loss 0.175764
[epoch8, step328]: loss 0.160087
[epoch8, step329]: loss 0.184120
[epoch8, step330]: loss 0.170646
[epoch8, step331]: loss 0.157982
[epoch8, step332]: loss 0.178590
[epoch8, step333]: loss 0.158482
[epoch8, step334]: loss 0.179496
[epoch8, step335]: loss 0.170577
[epoch8, step336]: loss 0.168953
[epoch8, step337]: loss 0.156737
[epoch8, step338]: loss 0.184613
[epoch8, step339]: loss 0.168669
[epoch8, step340]: loss 0.156860
[epoch8, step341]: loss 0.177722
[epoch8, step342]: loss 0.156720
[epoch8, step343]: loss 0.178685
[epoch8, step344]: loss 0.172010
[epoch8, step345]: loss 0.175547
[epoch8, step346]: loss 0.161437
[epoch8, step347]: loss 0.183690
[epoch8, step348]: loss 0.166089
[epoch8, step349]: loss 0.154721
[epoch8, step350]: loss 0.178099
[epoch8, step351]: loss 0.158116
[epoch8, step352]: loss 0.179998
[epoch8, step353]: loss 0.171206
[epoch8, step354]: loss 0.177062
[epoch8, step355]: loss 0.162202
[epoch8, step356]: loss 0.178924
[epoch8, step357]: loss 0.166665
[epoch8, step358]: loss 0.162665
[epoch8, step359]: loss 0.171730
[epoch8, step360]: loss 0.157824
[epoch8, step361]: loss 0.181990
[epoch8, step362]: loss 0.168156
[epoch8, step363]: loss 0.173760
[epoch8, step364]: loss 0.159769
[epoch8, step365]: loss 0.182597
[epoch8, step366]: loss 0.165358
[epoch8, step367]: loss 0.158039
[epoch8, step368]: loss 0.177910
[epoch8, step369]: loss 0.157529
[epoch8, step370]: loss 0.177094
[epoch8, step371]: loss 0.166484
[epoch8, step372]: loss 0.173656
[epoch8, step373]: loss 0.159206
[epoch8, step374]: loss 0.184327
[epoch8, step375]: loss 0.163782
[epoch8, step376]: loss 0.153188
[epoch8, step377]: loss 0.174049
[epoch8, step378]: loss 0.156535
[epoch8, step379]: loss 0.176551
[epoch8, step380]: loss 0.167709
[epoch8, step381]: loss 0.173253
[epoch8, step382]: loss 0.161802
[epoch8, step383]: loss 0.186449
[epoch8, step384]: loss 0.169683
[epoch8, step385]: loss 0.153522
[epoch8, step386]: loss 0.174112
[epoch8, step387]: loss 0.154261
[epoch8, step388]: loss 0.175371
[epoch8, step389]: loss 0.169817
[epoch8, step390]: loss 0.166835
[epoch8, step391]: loss 0.158237
[epoch8, step392]: loss 0.177931
[epoch8, step393]: loss 0.168439
[epoch8, step394]: loss 0.157787
[epoch8, step395]: loss 0.175768
[epoch8, step396]: loss 0.155198
[epoch8, step397]: loss 0.181552
[epoch8, step398]: loss 0.169118
[epoch8, step399]: loss 0.171780
[epoch8, step400]: loss 0.157545
[epoch8, step401]: loss 0.181624
[epoch8, step402]: loss 0.167126
[epoch8, step403]: loss 0.154523
[epoch8, step404]: loss 0.173412
[epoch8, step405]: loss 0.153637
[epoch8, step406]: loss 0.176673
[epoch8, step407]: loss 0.170709
[epoch8, step408]: loss 0.170798
[epoch8, step409]: loss 0.151555
[epoch8, step410]: loss 0.177746
[epoch8, step411]: loss 0.166106
[epoch8, step412]: loss 0.155265
[epoch8, step413]: loss 0.174363
[epoch8, step414]: loss 0.158969
[epoch8, step415]: loss 0.177599
[epoch8, step416]: loss 0.172008
[epoch8, step417]: loss 0.170101
[epoch8, step418]: loss 0.157007
[epoch8, step419]: loss 0.183493
[epoch8, step420]: loss 0.164033
[epoch8, step421]: loss 0.155962
[epoch8, step422]: loss 0.174082
[epoch8, step423]: loss 0.154659
[epoch8, step424]: loss 0.176915
[epoch8, step425]: loss 0.168263
[epoch8, step426]: loss 0.169231
[epoch8, step427]: loss 0.159411
[epoch8, step428]: loss 0.180722
[epoch8, step429]: loss 0.161600
[epoch8, step430]: loss 0.154725
[epoch8, step431]: loss 0.172154
[epoch8, step432]: loss 0.154002
[epoch8, step433]: loss 0.173631
[epoch8, step434]: loss 0.169284
[epoch8, step435]: loss 0.168814
[epoch8, step436]: loss 0.161103
[epoch8, step437]: loss 0.179202
[epoch8, step438]: loss 0.161893
[epoch8, step439]: loss 0.155875
[epoch8, step440]: loss 0.173691
[epoch8, step441]: loss 0.153283
[epoch8, step442]: loss 0.177465
[epoch8, step443]: loss 0.166248
[epoch8, step444]: loss 0.172292
[epoch8, step445]: loss 0.156468
[epoch8, step446]: loss 0.177908
[epoch8, step447]: loss 0.162145
[epoch8, step448]: loss 0.152054
[epoch8, step449]: loss 0.174174
[epoch8, step450]: loss 0.158159
[epoch8, step451]: loss 0.178054
[epoch8, step452]: loss 0.173518
[epoch8, step453]: loss 0.169316
[epoch8, step454]: loss 0.158746
[epoch8, step455]: loss 0.178543
[epoch8, step456]: loss 0.168107
[epoch8, step457]: loss 0.153080
[epoch8, step458]: loss 0.174413
[epoch8, step459]: loss 0.151211
[epoch8, step460]: loss 0.177705
[epoch8, step461]: loss 0.165117
[epoch8, step462]: loss 0.172973
[epoch8, step463]: loss 0.157107
[epoch8, step464]: loss 0.179993
[epoch8, step465]: loss 0.158447
[epoch8, step466]: loss 0.152981
[epoch8, step467]: loss 0.174353
[epoch8, step468]: loss 0.155319
[epoch8, step469]: loss 0.176324
[epoch8, step470]: loss 0.167025
[epoch8, step471]: loss 0.171356
[epoch8, step472]: loss 0.157715
[epoch8, step473]: loss 0.180838
[epoch8, step474]: loss 0.165428
[epoch8, step475]: loss 0.154118
[epoch8, step476]: loss 0.170790
[epoch8, step477]: loss 0.154330
[epoch8, step478]: loss 0.178848
[epoch8, step479]: loss 0.167976
[epoch8, step480]: loss 0.173239
[epoch8, step481]: loss 0.157801
[epoch8, step482]: loss 0.181720
[epoch8, step483]: loss 0.162236
[epoch8, step484]: loss 0.149650
[epoch8, step485]: loss 0.171883
[epoch8, step486]: loss 0.152389
[epoch8, step487]: loss 0.179004
[epoch8, step488]: loss 0.166099
[epoch8, step489]: loss 0.173150
[epoch8, step490]: loss 0.156708
[epoch8, step491]: loss 0.177279
[epoch8, step492]: loss 0.164943
[epoch8, step493]: loss 0.153077
[epoch8, step494]: loss 0.175253
[epoch8, step495]: loss 0.147861
[epoch8, step496]: loss 0.177135
[epoch8, step497]: loss 0.166576
[epoch8, step498]: loss 0.169354
[epoch8, step499]: loss 0.156634
[epoch8, step500]: loss 0.180622
[epoch8, step501]: loss 0.166545
[epoch8, step502]: loss 0.153191
[epoch8, step503]: loss 0.171380
[epoch8, step504]: loss 0.157286
[epoch8, step505]: loss 0.180562
[epoch8, step506]: loss 0.164419
[epoch8, step507]: loss 0.167274
[epoch8, step508]: loss 0.154992
[epoch8, step509]: loss 0.179699
[epoch8, step510]: loss 0.163157
[epoch8, step511]: loss 0.154964
[epoch8, step512]: loss 0.170524
[epoch8, step513]: loss 0.153679
[epoch8, step514]: loss 0.175181
[epoch8, step515]: loss 0.167093
[epoch8, step516]: loss 0.166926
[epoch8, step517]: loss 0.157294
[epoch8, step518]: loss 0.177777
[epoch8, step519]: loss 0.163210
[epoch8, step520]: loss 0.152084
[epoch8, step521]: loss 0.173495
[epoch8, step522]: loss 0.154491
[epoch8, step523]: loss 0.175735
[epoch8, step524]: loss 0.170399
[epoch8, step525]: loss 0.167023
[epoch8, step526]: loss 0.153034
[epoch8, step527]: loss 0.179941
[epoch8, step528]: loss 0.161716
[epoch8, step529]: loss 0.155576
[epoch8, step530]: loss 0.170480
[epoch8, step531]: loss 0.152886
[epoch8, step532]: loss 0.177723
[epoch8, step533]: loss 0.162253
[epoch8, step534]: loss 0.168787
[epoch8, step535]: loss 0.154929
[epoch8, step536]: loss 0.176817
[epoch8, step537]: loss 0.162305
[epoch8, step538]: loss 0.155255
[epoch8, step539]: loss 0.172282
[epoch8, step540]: loss 0.157389
[epoch8, step541]: loss 0.177578
[epoch8, step542]: loss 0.166922
[epoch8, step543]: loss 0.168926
[epoch8, step544]: loss 0.152668
[epoch8, step545]: loss 0.181551
[epoch8, step546]: loss 0.160637
[epoch8, step547]: loss 0.156262
[epoch8, step548]: loss 0.172284
[epoch8, step549]: loss 0.152104
[epoch8, step550]: loss 0.174965
[epoch8, step551]: loss 0.166635
[epoch8, step552]: loss 0.170244
[epoch8, step553]: loss 0.154793
[epoch8, step554]: loss 0.178976
[epoch8, step555]: loss 0.164685
[epoch8, step556]: loss 0.151188
[epoch8, step557]: loss 0.173466
[epoch8, step558]: loss 0.151810
[epoch8, step559]: loss 0.177463
[epoch8, step560]: loss 0.165710
[epoch8, step561]: loss 0.168811
[epoch8, step562]: loss 0.153677
[epoch8, step563]: loss 0.203156
[epoch8, step564]: loss 0.157792
[epoch8, step565]: loss 0.126699
[epoch8, step566]: loss 0.135995
[epoch8, step567]: loss 0.130722
[epoch8, step568]: loss 0.145106
[epoch8, step569]: loss 0.171494
[epoch8, step570]: loss 0.148450
[epoch8, step571]: loss 0.106510
[epoch8, step572]: loss 0.144887
[epoch8, step573]: loss 0.152569
[epoch8, step574]: loss 0.183301
[epoch8, step575]: loss 0.158001
[epoch8, step576]: loss 0.163071
[epoch8, step577]: loss 0.139752
[epoch8, step578]: loss 0.162701
[epoch8, step579]: loss 0.132450
[epoch8, step580]: loss 0.184027
[epoch8, step581]: loss 0.162884
[epoch8, step582]: loss 0.157794
[epoch8, step583]: loss 0.160087
[epoch8, step584]: loss 0.150705
[epoch8, step585]: loss 0.177752
[epoch8, step586]: loss 0.156839
[epoch8, step587]: loss 0.115161
[epoch8, step588]: loss 0.159010
[epoch8, step589]: loss 0.205584
[epoch8, step590]: loss 0.121988
[epoch8, step591]: loss 0.153275
[epoch8, step592]: loss 0.170050
[epoch8, step593]: loss 0.202141
[epoch8, step594]: loss 0.123824
[epoch8, step595]: loss 0.124292
[epoch8, step596]: loss 0.171312
[epoch8, step597]: loss 0.177137
[epoch8, step598]: loss 0.133627
[epoch8, step599]: loss 0.123564
[epoch8, step600]: loss 0.121327
[epoch8, step601]: loss 0.154321
[epoch8, step602]: loss 0.183672
[epoch8, step603]: loss 0.137806
[epoch8, step604]: loss 0.135135
[epoch8, step605]: loss 0.120382
[epoch8, step606]: loss 0.150860
[epoch8, step607]: loss 0.164642
[epoch8, step608]: loss 0.106034
[epoch8, step609]: loss 0.155929
[epoch8, step610]: loss 0.138538
[epoch8, step611]: loss 0.171054
[epoch8, step612]: loss 0.156758
[epoch8, step613]: loss 0.170515
[epoch8, step614]: loss 0.152307
[epoch8, step615]: loss 0.156197
[epoch8, step616]: loss 0.125502
[epoch8, step617]: loss 0.143413
[epoch8, step618]: loss 0.168056
[epoch8, step619]: loss 0.129066
[epoch8, step620]: loss 0.119324
[epoch8, step621]: loss 0.116417
[epoch8, step622]: loss 0.163081
[epoch8, step623]: loss 0.158206
[epoch8, step624]: loss 0.158656
[epoch8, step625]: loss 0.118185
[epoch8, step626]: loss 0.158971
[epoch8, step627]: loss 0.182123
[epoch8, step628]: loss 0.166776
[epoch8, step629]: loss 0.094175
[epoch8, step630]: loss 0.133157
[epoch8, step631]: loss 0.133798
[epoch8, step632]: loss 0.158617
[epoch8, step633]: loss 0.130790
[epoch8, step634]: loss 0.151120
[epoch8, step635]: loss 0.143268
[epoch8, step636]: loss 0.126095
[epoch8, step637]: loss 0.168469
[epoch8, step638]: loss 0.155704
[epoch8, step639]: loss 0.121189
[epoch8, step640]: loss 0.161925
[epoch8, step641]: loss 0.126434
[epoch8, step642]: loss 0.122047
[epoch8, step643]: loss 0.161982
[epoch8, step644]: loss 0.142046
[epoch8, step645]: loss 0.111038
[epoch8, step646]: loss 0.147473
[epoch8, step647]: loss 0.114520
[epoch8, step648]: loss 0.182355
[epoch8, step649]: loss 0.156806
[epoch8, step650]: loss 0.165845
[epoch8, step651]: loss 0.140500
[epoch8, step652]: loss 0.175862
[epoch8, step653]: loss 0.169584
[epoch8, step654]: loss 0.162397
[epoch8, step655]: loss 0.125769
[epoch8, step656]: loss 0.171070
[epoch8, step657]: loss 0.169881
[epoch8, step658]: loss 0.132663
[epoch8, step659]: loss 0.114725
[epoch8, step660]: loss 0.147849
[epoch8, step661]: loss 0.157691
[epoch8, step662]: loss 0.116303
[epoch8, step663]: loss 0.143788
[epoch8, step664]: loss 0.139871
[epoch8, step665]: loss 0.176938
[epoch8, step666]: loss 0.120164
[epoch8, step667]: loss 0.156424
[epoch8, step668]: loss 0.178341
[epoch8, step669]: loss 0.121879
[epoch8, step670]: loss 0.150892
[epoch8, step671]: loss 0.154960
[epoch8, step672]: loss 0.185878
[epoch8, step673]: loss 0.170916
[epoch8, step674]: loss 0.142354
[epoch8, step675]: loss 0.164932
[epoch8, step676]: loss 0.160610
[epoch8, step677]: loss 0.137386
[epoch8, step678]: loss 0.119590
[epoch8, step679]: loss 0.145821
[epoch8, step680]: loss 0.120256
[epoch8, step681]: loss 0.121628
[epoch8, step682]: loss 0.125925
[epoch8, step683]: loss 0.149319
[epoch8, step684]: loss 0.124131
[epoch8, step685]: loss 0.125520
[epoch8, step686]: loss 0.121000
[epoch8, step687]: loss 0.132548
[epoch8, step688]: loss 0.159229
[epoch8, step689]: loss 0.125040
[epoch8, step690]: loss 0.165559
[epoch8, step691]: loss 0.172335
[epoch8, step692]: loss 0.165506
[epoch8, step693]: loss 0.152238
[epoch8, step694]: loss 0.116340
[epoch8, step695]: loss 0.135813
[epoch8, step696]: loss 0.125204
[epoch8, step697]: loss 0.151947
[epoch8, step698]: loss 0.135985
[epoch8, step699]: loss 0.139253
[epoch8, step700]: loss 0.182338
[epoch8, step701]: loss 0.157875
[epoch8, step702]: loss 0.135567
[epoch8, step703]: loss 0.178516
[epoch8, step704]: loss 0.165077
[epoch8, step705]: loss 0.125737
[epoch8, step706]: loss 0.130798
[epoch8, step707]: loss 0.135016
[epoch8, step708]: loss 0.148129
[epoch8, step709]: loss 0.129896
[epoch8, step710]: loss 0.151182
[epoch8, step711]: loss 0.165567
[epoch8, step712]: loss 0.116184
[epoch8, step713]: loss 0.133231
[epoch8, step714]: loss 0.156275
[epoch8, step715]: loss 0.131073
[epoch8, step716]: loss 0.152047
[epoch8, step717]: loss 0.128034
[epoch8, step718]: loss 0.142643
[epoch8, step719]: loss 0.145787
[epoch8, step720]: loss 0.126515
[epoch8, step721]: loss 0.139629
[epoch8, step722]: loss 0.148749
[epoch8, step723]: loss 0.142132
[epoch8, step724]: loss 0.153038
[epoch8, step725]: loss 0.152902
[epoch8, step726]: loss 0.108162
[epoch8, step727]: loss 0.150025
[epoch8, step728]: loss 0.152353
[epoch8, step729]: loss 0.122821
[epoch8, step730]: loss 0.152234
[epoch8, step731]: loss 0.164606
[epoch8, step732]: loss 0.138671
[epoch8, step733]: loss 0.113649
[epoch8, step734]: loss 0.129463
[epoch8, step735]: loss 0.129217
[epoch8, step736]: loss 0.136093
[epoch8, step737]: loss 0.120760
[epoch8, step738]: loss 0.129682
[epoch8, step739]: loss 0.180299
[epoch8, step740]: loss 0.191256
[epoch8, step741]: loss 0.147737
[epoch8, step742]: loss 0.168404
[epoch8, step743]: loss 0.144607
[epoch8, step744]: loss 0.141667
[epoch8, step745]: loss 0.143492
[epoch8, step746]: loss 0.154585
[epoch8, step747]: loss 0.139396
[epoch8, step748]: loss 0.126063
[epoch8, step749]: loss 0.181717
[epoch8, step750]: loss 0.154421
[epoch8, step751]: loss 0.134695
[epoch8, step752]: loss 0.121848
[epoch8, step753]: loss 0.124578
[epoch8, step754]: loss 0.166823
[epoch8, step755]: loss 0.152422
[epoch8, step756]: loss 0.113702
[epoch8, step757]: loss 0.142230
[epoch8, step758]: loss 0.156852
[epoch8, step759]: loss 0.124832
[epoch8, step760]: loss 0.151361
[epoch8, step761]: loss 0.137876
[epoch8, step762]: loss 0.129522
[epoch8, step763]: loss 0.131134
[epoch8, step764]: loss 0.148790
[epoch8, step765]: loss 0.129154
[epoch8, step766]: loss 0.121078
[epoch8, step767]: loss 0.154643
[epoch8, step768]: loss 0.143132
[epoch8, step769]: loss 0.143973
[epoch8, step770]: loss 0.176798
[epoch8, step771]: loss 0.120569
[epoch8, step772]: loss 0.122181
[epoch8, step773]: loss 0.137679
[epoch8, step774]: loss 0.142347
[epoch8, step775]: loss 0.173433
[epoch8, step776]: loss 0.151258
[epoch8, step777]: loss 0.133327
[epoch8, step778]: loss 0.161177
[epoch8, step779]: loss 0.137047
[epoch8, step780]: loss 0.155015
[epoch8, step781]: loss 0.176580
[epoch8, step782]: loss 0.166762
[epoch8, step783]: loss 0.144434
[epoch8, step784]: loss 0.164364
[epoch8, step785]: loss 0.160238
[epoch8, step786]: loss 0.141130
[epoch8, step787]: loss 0.173817
[epoch8, step788]: loss 0.145570
[epoch8, step789]: loss 0.166653
[epoch8, step790]: loss 0.119902
[epoch8, step791]: loss 0.152818
[epoch8, step792]: loss 0.153754
[epoch8, step793]: loss 0.155475
[epoch8, step794]: loss 0.145585
[epoch8, step795]: loss 0.141195
[epoch8, step796]: loss 0.135513
[epoch8, step797]: loss 0.124674
[epoch8, step798]: loss 0.125331
[epoch8, step799]: loss 0.107786
[epoch8, step800]: loss 0.181514
[epoch8, step801]: loss 0.169844
[epoch8, step802]: loss 0.139903
[epoch8, step803]: loss 0.130137
[epoch8, step804]: loss 0.152300
[epoch8, step805]: loss 0.135737
[epoch8, step806]: loss 0.144094
[epoch8, step807]: loss 0.158266
[epoch8, step808]: loss 0.173633
[epoch8, step809]: loss 0.131023
[epoch8, step810]: loss 0.112071
[epoch8, step811]: loss 0.142479
[epoch8, step812]: loss 0.154316
[epoch8, step813]: loss 0.130328
[epoch8, step814]: loss 0.147281
[epoch8, step815]: loss 0.139448
[epoch8, step816]: loss 0.142450
[epoch8, step817]: loss 0.123875
[epoch8, step818]: loss 0.134685
[epoch8, step819]: loss 0.202088
[epoch8, step820]: loss 0.127121
[epoch8, step821]: loss 0.124978
[epoch8, step822]: loss 0.147101
[epoch8, step823]: loss 0.123540
[epoch8, step824]: loss 0.143155
[epoch8, step825]: loss 0.149541
[epoch8, step826]: loss 0.104542
[epoch8, step827]: loss 0.127980
[epoch8, step828]: loss 0.140601
[epoch8, step829]: loss 0.130830
[epoch8, step830]: loss 0.100348
[epoch8, step831]: loss 0.123283
[epoch8, step832]: loss 0.174415
[epoch8, step833]: loss 0.145968
[epoch8, step834]: loss 0.142036
[epoch8, step835]: loss 0.147205
[epoch8, step836]: loss 0.126087
[epoch8, step837]: loss 0.119035
[epoch8, step838]: loss 0.159476
[epoch8, step839]: loss 0.140790
[epoch8, step840]: loss 0.129003
[epoch8, step841]: loss 0.139364
[epoch8, step842]: loss 0.139524
[epoch8, step843]: loss 0.156948
[epoch8, step844]: loss 0.157256
[epoch8, step845]: loss 0.149347
[epoch8, step846]: loss 0.184477
[epoch8, step847]: loss 0.141632
[epoch8, step848]: loss 0.080905
[epoch8, step849]: loss 0.130223
[epoch8, step850]: loss 0.157750
[epoch8, step851]: loss 0.135981
[epoch8, step852]: loss 0.140256
[epoch8, step853]: loss 0.152967
[epoch8, step854]: loss 0.157920
[epoch8, step855]: loss 0.126743
[epoch8, step856]: loss 0.115145
[epoch8, step857]: loss 0.149494
[epoch8, step858]: loss 0.153306
[epoch8, step859]: loss 0.127193
[epoch8, step860]: loss 0.159952
[epoch8, step861]: loss 0.144092
[epoch8, step862]: loss 0.115659
[epoch8, step863]: loss 0.156699
[epoch8, step864]: loss 0.161916
[epoch8, step865]: loss 0.149116
[epoch8, step866]: loss 0.156396
[epoch8, step867]: loss 0.132448
[epoch8, step868]: loss 0.146895
[epoch8, step869]: loss 0.124704
[epoch8, step870]: loss 0.117945
[epoch8, step871]: loss 0.173818
[epoch8, step872]: loss 0.152395
[epoch8, step873]: loss 0.119009
[epoch8, step874]: loss 0.138569
[epoch8, step875]: loss 0.177677
[epoch8, step876]: loss 0.160676
[epoch8, step877]: loss 0.090174
[epoch8, step878]: loss 0.126801
[epoch8, step879]: loss 0.134799
[epoch8, step880]: loss 0.128996
[epoch8, step881]: loss 0.160953
[epoch8, step882]: loss 0.125948
[epoch8, step883]: loss 0.132135
[epoch8, step884]: loss 0.171908
[epoch8, step885]: loss 0.172803
[epoch8, step886]: loss 0.165117
[epoch8, step887]: loss 0.174706
[epoch8, step888]: loss 0.133253
[epoch8, step889]: loss 0.153856
[epoch8, step890]: loss 0.154917
[epoch8, step891]: loss 0.131691
[epoch8, step892]: loss 0.156001
[epoch8, step893]: loss 0.150547
[epoch8, step894]: loss 0.152098
[epoch8, step895]: loss 0.118486
[epoch8, step896]: loss 0.188189
[epoch8, step897]: loss 0.186495
[epoch8, step898]: loss 0.124278
[epoch8, step899]: loss 0.091209
[epoch8, step900]: loss 0.140823
[epoch8, step901]: loss 0.163181
[epoch8, step902]: loss 0.126263
[epoch8, step903]: loss 0.166994
[epoch8, step904]: loss 0.124412
[epoch8, step905]: loss 0.117949
[epoch8, step906]: loss 0.112563
[epoch8, step907]: loss 0.154845
[epoch8, step908]: loss 0.168059
[epoch8, step909]: loss 0.136080
[epoch8, step910]: loss 0.114700
[epoch8, step911]: loss 0.111257
[epoch8, step912]: loss 0.155893
[epoch8, step913]: loss 0.158580
[epoch8, step914]: loss 0.140991
[epoch8, step915]: loss 0.125762
[epoch8, step916]: loss 0.146577
[epoch8, step917]: loss 0.141566
[epoch8, step918]: loss 0.158698
[epoch8, step919]: loss 0.118198
[epoch8, step920]: loss 0.162515
[epoch8, step921]: loss 0.128849
[epoch8, step922]: loss 0.132789
[epoch8, step923]: loss 0.167005
[epoch8, step924]: loss 0.129032
[epoch8, step925]: loss 0.130421
[epoch8, step926]: loss 0.132421
[epoch8, step927]: loss 0.163913
[epoch8, step928]: loss 0.127468
[epoch8, step929]: loss 0.135173
[epoch8, step930]: loss 0.140653
[epoch8, step931]: loss 0.154394
[epoch8, step932]: loss 0.127588
[epoch8, step933]: loss 0.132151
[epoch8, step934]: loss 0.168454
[epoch8, step935]: loss 0.143848
[epoch8, step936]: loss 0.126291
[epoch8, step937]: loss 0.115521
[epoch8, step938]: loss 0.175492
[epoch8, step939]: loss 0.130894
[epoch8, step940]: loss 0.157776
[epoch8, step941]: loss 0.145569
[epoch8, step942]: loss 0.143096
[epoch8, step943]: loss 0.165304
[epoch8, step944]: loss 0.144038
[epoch8, step945]: loss 0.159986
[epoch8, step946]: loss 0.140439
[epoch8, step947]: loss 0.125380
[epoch8, step948]: loss 0.195549
[epoch8, step949]: loss 0.142233
[epoch8, step950]: loss 0.136875
[epoch8, step951]: loss 0.149029
[epoch8, step952]: loss 0.155150
[epoch8, step953]: loss 0.140250
[epoch8, step954]: loss 0.150781
[epoch8, step955]: loss 0.115227
[epoch8, step956]: loss 0.171296
[epoch8, step957]: loss 0.154671
[epoch8, step958]: loss 0.178355
[epoch8, step959]: loss 0.164008
[epoch8, step960]: loss 0.150691
[epoch8, step961]: loss 0.163855
[epoch8, step962]: loss 0.163270
[epoch8, step963]: loss 0.167750
[epoch8, step964]: loss 0.152889
[epoch8, step965]: loss 0.170214
[epoch8, step966]: loss 0.149884
[epoch8, step967]: loss 0.170825
[epoch8, step968]: loss 0.159489
[epoch8, step969]: loss 0.141030
[epoch8, step970]: loss 0.158000
[epoch8, step971]: loss 0.159214
[epoch8, step972]: loss 0.160890
[epoch8, step973]: loss 0.156144
[epoch8, step974]: loss 0.161872
[epoch8, step975]: loss 0.147612
[epoch8, step976]: loss 0.170727
[epoch8, step977]: loss 0.154780
[epoch8, step978]: loss 0.140580
[epoch8, step979]: loss 0.159933
[epoch8, step980]: loss 0.159073
[epoch8, step981]: loss 0.163367
[epoch8, step982]: loss 0.151918
[epoch8, step983]: loss 0.162720
[epoch8, step984]: loss 0.148829
[epoch8, step985]: loss 0.170561
[epoch8, step986]: loss 0.153347
[epoch8, step987]: loss 0.137050
[epoch8, step988]: loss 0.154165
[epoch8, step989]: loss 0.156074
[epoch8, step990]: loss 0.163185
[epoch8, step991]: loss 0.148841
[epoch8, step992]: loss 0.162948
[epoch8, step993]: loss 0.149137
[epoch8, step994]: loss 0.171927
[epoch8, step995]: loss 0.155931
[epoch8, step996]: loss 0.140159
[epoch8, step997]: loss 0.155707
[epoch8, step998]: loss 0.155341
[epoch8, step999]: loss 0.161469
[epoch8, step1000]: loss 0.151401
[epoch8, step1001]: loss 0.161919
[epoch8, step1002]: loss 0.145327
[epoch8, step1003]: loss 0.169848
[epoch8, step1004]: loss 0.153537
[epoch8, step1005]: loss 0.141038
[epoch8, step1006]: loss 0.156157
[epoch8, step1007]: loss 0.158170
[epoch8, step1008]: loss 0.163226
[epoch8, step1009]: loss 0.150797
[epoch8, step1010]: loss 0.159180
[epoch8, step1011]: loss 0.146727
[epoch8, step1012]: loss 0.166279
[epoch8, step1013]: loss 0.154288
[epoch8, step1014]: loss 0.138357
[epoch8, step1015]: loss 0.154455
[epoch8, step1016]: loss 0.157750
[epoch8, step1017]: loss 0.163622
[epoch8, step1018]: loss 0.150179
[epoch8, step1019]: loss 0.161331
[epoch8, step1020]: loss 0.147981
[epoch8, step1021]: loss 0.168508
[epoch8, step1022]: loss 0.154916
[epoch8, step1023]: loss 0.139543
[epoch8, step1024]: loss 0.151369
[epoch8, step1025]: loss 0.159171
[epoch8, step1026]: loss 0.164685
[epoch8, step1027]: loss 0.149087
[epoch8, step1028]: loss 0.161333
[epoch8, step1029]: loss 0.146497
[epoch8, step1030]: loss 0.169361
[epoch8, step1031]: loss 0.160587
[epoch8, step1032]: loss 0.138247
[epoch8, step1033]: loss 0.158423
[epoch8, step1034]: loss 0.158242
[epoch8, step1035]: loss 0.164735
[epoch8, step1036]: loss 0.151077
[epoch8, step1037]: loss 0.162343
[epoch8, step1038]: loss 0.146863
[epoch8, step1039]: loss 0.166982
[epoch8, step1040]: loss 0.156917
[epoch8, step1041]: loss 0.140375
[epoch8, step1042]: loss 0.156551
[epoch8, step1043]: loss 0.157104
[epoch8, step1044]: loss 0.160822
[epoch8, step1045]: loss 0.148995
[epoch8, step1046]: loss 0.160957
[epoch8, step1047]: loss 0.145018
[epoch8, step1048]: loss 0.169589
[epoch8, step1049]: loss 0.154135
[epoch8, step1050]: loss 0.138934
[epoch8, step1051]: loss 0.154819
[epoch8, step1052]: loss 0.155845
[epoch8, step1053]: loss 0.161250
[epoch8, step1054]: loss 0.150830
[epoch8, step1055]: loss 0.163351
[epoch8, step1056]: loss 0.148299
[epoch8, step1057]: loss 0.164466
[epoch8, step1058]: loss 0.150637
[epoch8, step1059]: loss 0.138650
[epoch8, step1060]: loss 0.152755
[epoch8, step1061]: loss 0.159735
[epoch8, step1062]: loss 0.159242
[epoch8, step1063]: loss 0.150169
[epoch8, step1064]: loss 0.161303
[epoch8, step1065]: loss 0.147787
[epoch8, step1066]: loss 0.168611
[epoch8, step1067]: loss 0.153820
[epoch8, step1068]: loss 0.145131
[epoch8, step1069]: loss 0.153046
[epoch8, step1070]: loss 0.156196
[epoch8, step1071]: loss 0.158296
[epoch8, step1072]: loss 0.146544
[epoch8, step1073]: loss 0.161391
[epoch8, step1074]: loss 0.147602
[epoch8, step1075]: loss 0.165538
[epoch8, step1076]: loss 0.153035
[epoch8, step1077]: loss 0.138059
[epoch8, step1078]: loss 0.155635
[epoch8, step1079]: loss 0.152407
[epoch8, step1080]: loss 0.159355
[epoch8, step1081]: loss 0.151489
[epoch8, step1082]: loss 0.161294
[epoch8, step1083]: loss 0.144309
[epoch8, step1084]: loss 0.165631
[epoch8, step1085]: loss 0.155711
[epoch8, step1086]: loss 0.140725
[epoch8, step1087]: loss 0.154695
[epoch8, step1088]: loss 0.157018
[epoch8, step1089]: loss 0.158789
[epoch8, step1090]: loss 0.147162
[epoch8, step1091]: loss 0.159510
[epoch8, step1092]: loss 0.146406
[epoch8, step1093]: loss 0.166070
[epoch8, step1094]: loss 0.157250
[epoch8, step1095]: loss 0.138501
[epoch8, step1096]: loss 0.156458
[epoch8, step1097]: loss 0.155035
[epoch8, step1098]: loss 0.160915
[epoch8, step1099]: loss 0.150700
[epoch8, step1100]: loss 0.157905
[epoch8, step1101]: loss 0.146693
[epoch8, step1102]: loss 0.167162
[epoch8, step1103]: loss 0.155263
[epoch8, step1104]: loss 0.138146
[epoch8, step1105]: loss 0.152531
[epoch8, step1106]: loss 0.159093
[epoch8, step1107]: loss 0.159741
[epoch8, step1108]: loss 0.150571
[epoch8, step1109]: loss 0.158178
[epoch8, step1110]: loss 0.142624
[epoch8, step1111]: loss 0.165346
[epoch8, step1112]: loss 0.151593
[epoch8, step1113]: loss 0.138296
[epoch8, step1114]: loss 0.152969
[epoch8, step1115]: loss 0.154151
[epoch8, step1116]: loss 0.159277
[epoch8, step1117]: loss 0.148176
[epoch8, step1118]: loss 0.160391
[epoch8, step1119]: loss 0.147993
[epoch8, step1120]: loss 0.166848
[epoch8, step1121]: loss 0.153282
[epoch8, step1122]: loss 0.138640
[epoch8, step1123]: loss 0.155802
[epoch8, step1124]: loss 0.152996
[epoch8, step1125]: loss 0.158391
[epoch8, step1126]: loss 0.145576
[epoch8, step1127]: loss 0.159109
[epoch8, step1128]: loss 0.145542
[epoch8, step1129]: loss 0.166337
[epoch8, step1130]: loss 0.148980
[epoch8, step1131]: loss 0.136074
[epoch8, step1132]: loss 0.151837
[epoch8, step1133]: loss 0.156921
[epoch8, step1134]: loss 0.160246
[epoch8, step1135]: loss 0.143686
[epoch8, step1136]: loss 0.156623
[epoch8, step1137]: loss 0.142932
[epoch8, step1138]: loss 0.164351
[epoch8, step1139]: loss 0.153448
[epoch8, step1140]: loss 0.137426
[epoch8, step1141]: loss 0.151895
[epoch8, step1142]: loss 0.156503
[epoch8, step1143]: loss 0.161222
[epoch8, step1144]: loss 0.148784
[epoch8, step1145]: loss 0.161292
[epoch8, step1146]: loss 0.143786
[epoch8, step1147]: loss 0.161557
[epoch8, step1148]: loss 0.152722
[epoch8, step1149]: loss 0.136836
[epoch8, step1150]: loss 0.154576
[epoch8, step1151]: loss 0.154257
[epoch8, step1152]: loss 0.156544
[epoch8, step1153]: loss 0.149674
[epoch8, step1154]: loss 0.157592
[epoch8, step1155]: loss 0.143616
[epoch8, step1156]: loss 0.167773
[epoch8, step1157]: loss 0.153937
[epoch8, step1158]: loss 0.135347
[epoch8, step1159]: loss 0.151425
[epoch8, step1160]: loss 0.151933
[epoch8, step1161]: loss 0.156664
[epoch8, step1162]: loss 0.148347
[epoch8, step1163]: loss 0.161421
[epoch8, step1164]: loss 0.143039
[epoch8, step1165]: loss 0.160294
[epoch8, step1166]: loss 0.151073
[epoch8, step1167]: loss 0.137781
[epoch8, step1168]: loss 0.151765
[epoch8, step1169]: loss 0.155213
[epoch8, step1170]: loss 0.158694
[epoch8, step1171]: loss 0.148337
[epoch8, step1172]: loss 0.159115
[epoch8, step1173]: loss 0.144223
[epoch8, step1174]: loss 0.162766
[epoch8, step1175]: loss 0.153003
[epoch8, step1176]: loss 0.137270
[epoch8, step1177]: loss 0.150021
[epoch8, step1178]: loss 0.152896
[epoch8, step1179]: loss 0.158880
[epoch8, step1180]: loss 0.146809
[epoch8, step1181]: loss 0.156282
[epoch8, step1182]: loss 0.145054
[epoch8, step1183]: loss 0.161736
[epoch8, step1184]: loss 0.154289
[epoch8, step1185]: loss 0.137843
[epoch8, step1186]: loss 0.153053
[epoch8, step1187]: loss 0.157533
[epoch8, step1188]: loss 0.160088
[epoch8, step1189]: loss 0.147438
[epoch8, step1190]: loss 0.159835
[epoch8, step1191]: loss 0.143253
[epoch8, step1192]: loss 0.162735
[epoch8, step1193]: loss 0.151334
[epoch8, step1194]: loss 0.136674
[epoch8, step1195]: loss 0.156943
[epoch8, step1196]: loss 0.156461
[epoch8, step1197]: loss 0.157484
[epoch8, step1198]: loss 0.146313
[epoch8, step1199]: loss 0.159276
[epoch8, step1200]: loss 0.143379
[epoch8, step1201]: loss 0.161854
[epoch8, step1202]: loss 0.147939
[epoch8, step1203]: loss 0.138440
[epoch8, step1204]: loss 0.152761
[epoch8, step1205]: loss 0.154355
[epoch8, step1206]: loss 0.159978
[epoch8, step1207]: loss 0.144192
[epoch8, step1208]: loss 0.156781
[epoch8, step1209]: loss 0.145017
[epoch8, step1210]: loss 0.161376
[epoch8, step1211]: loss 0.153583
[epoch8, step1212]: loss 0.138039
[epoch8, step1213]: loss 0.154084
[epoch8, step1214]: loss 0.152960
[epoch8, step1215]: loss 0.155097
[epoch8, step1216]: loss 0.146691
[epoch8, step1217]: loss 0.155442
[epoch8, step1218]: loss 0.142808
[epoch8, step1219]: loss 0.160979
[epoch8, step1220]: loss 0.149428
[epoch8, step1221]: loss 0.137524
[epoch8, step1222]: loss 0.151037
[epoch8, step1223]: loss 0.153147
[epoch8, step1224]: loss 0.155227
[epoch8, step1225]: loss 0.146294
[epoch8, step1226]: loss 0.159220
[epoch8, step1227]: loss 0.141094
[epoch8, step1228]: loss 0.164170
[epoch8, step1229]: loss 0.153171
[epoch8, step1230]: loss 0.137482
[epoch8, step1231]: loss 0.152746
[epoch8, step1232]: loss 0.149957
[epoch8, step1233]: loss 0.157906
[epoch8, step1234]: loss 0.146893
[epoch8, step1235]: loss 0.155614
[epoch8, step1236]: loss 0.144625
[epoch8, step1237]: loss 0.164815
[epoch8, step1238]: loss 0.153325
[epoch8, step1239]: loss 0.133790
[epoch8, step1240]: loss 0.149245
[epoch8, step1241]: loss 0.156118
[epoch8, step1242]: loss 0.157745
[epoch8, step1243]: loss 0.145005
[epoch8, step1244]: loss 0.156183
[epoch8, step1245]: loss 0.139929
[epoch8, step1246]: loss 0.161838
[epoch8, step1247]: loss 0.154256
[epoch8, step1248]: loss 0.136074
[epoch8, step1249]: loss 0.148709
[epoch8, step1250]: loss 0.153118
[epoch8, step1251]: loss 0.156337
[epoch8, step1252]: loss 0.144726
[epoch8, step1253]: loss 0.155706
[epoch8, step1254]: loss 0.142015
[epoch8, step1255]: loss 0.162323
[epoch8, step1256]: loss 0.148654
[epoch8, step1257]: loss 0.134477
[epoch8, step1258]: loss 0.150770
[epoch8, step1259]: loss 0.153599
[epoch8, step1260]: loss 0.156566
[epoch8, step1261]: loss 0.146704
[epoch8, step1262]: loss 0.160851
[epoch8, step1263]: loss 0.139006
[epoch8, step1264]: loss 0.163301
[epoch8, step1265]: loss 0.155803
[epoch8, step1266]: loss 0.136546
[epoch8, step1267]: loss 0.150481
[epoch8, step1268]: loss 0.152031
[epoch8, step1269]: loss 0.155890
[epoch8, step1270]: loss 0.148014
[epoch8, step1271]: loss 0.154919
[epoch8, step1272]: loss 0.141362
[epoch8, step1273]: loss 0.163639
[epoch8, step1274]: loss 0.152079
[epoch8, step1275]: loss 0.135354
[epoch8, step1276]: loss 0.150522
[epoch8, step1277]: loss 0.152594
[epoch8, step1278]: loss 0.153997
[epoch8, step1279]: loss 0.144542
[epoch8, step1280]: loss 0.155690
[epoch8, step1281]: loss 0.142148
[epoch8, step1282]: loss 0.161799
[epoch8, step1283]: loss 0.152309
[epoch8, step1284]: loss 0.134160
[epoch8, step1285]: loss 0.149656
[epoch8, step1286]: loss 0.154148
[epoch8, step1287]: loss 0.153032
[epoch8, step1288]: loss 0.142833
[epoch8, step1289]: loss 0.152650
[epoch8, step1290]: loss 0.142964
[epoch8, step1291]: loss 0.162668
[epoch8, step1292]: loss 0.146952
[epoch8, step1293]: loss 0.135663
[epoch8, step1294]: loss 0.149196
[epoch8, step1295]: loss 0.149670
[epoch8, step1296]: loss 0.154896
[epoch8, step1297]: loss 0.143564
[epoch8, step1298]: loss 0.153658
[epoch8, step1299]: loss 0.141874
[epoch8, step1300]: loss 0.159642
[epoch8, step1301]: loss 0.153951
[epoch8, step1302]: loss 0.134545
[epoch8, step1303]: loss 0.150961
[epoch8, step1304]: loss 0.153883
[epoch8, step1305]: loss 0.153592
[epoch8, step1306]: loss 0.145326
[epoch8, step1307]: loss 0.157974
[epoch8, step1308]: loss 0.142221
[epoch8, step1309]: loss 0.163942
[epoch8, step1310]: loss 0.149965
[epoch8, step1311]: loss 0.136912
[epoch8, step1312]: loss 0.149087
[epoch8, step1313]: loss 0.151418
[epoch8, step1314]: loss 0.156564
[epoch8, step1315]: loss 0.144969
[epoch8, step1316]: loss 0.150352
[epoch8, step1317]: loss 0.143107
[epoch8, step1318]: loss 0.163769
[epoch8, step1319]: loss 0.150843
[epoch8, step1320]: loss 0.134501
[epoch8, step1321]: loss 0.146817
[epoch8, step1322]: loss 0.153071
[epoch8, step1323]: loss 0.153757
[epoch8, step1324]: loss 0.145747
[epoch8, step1325]: loss 0.155658
[epoch8, step1326]: loss 0.143381
[epoch8, step1327]: loss 0.161107
[epoch8, step1328]: loss 0.149398
[epoch8, step1329]: loss 0.134931
[epoch8, step1330]: loss 0.148721
[epoch8, step1331]: loss 0.152785
[epoch8, step1332]: loss 0.156256
[epoch8, step1333]: loss 0.148961
[epoch8, step1334]: loss 0.153684
[epoch8, step1335]: loss 0.140793
[epoch8, step1336]: loss 0.160365
[epoch8, step1337]: loss 0.152437
[epoch8, step1338]: loss 0.134030
[epoch8, step1339]: loss 0.150476
[epoch8, step1340]: loss 0.153370
[epoch8, step1341]: loss 0.155029
[epoch8, step1342]: loss 0.144412
[epoch8, step1343]: loss 0.154022
[epoch8, step1344]: loss 0.139407
[epoch8, step1345]: loss 0.160206
[epoch8, step1346]: loss 0.150577
[epoch8, step1347]: loss 0.132299
[epoch8, step1348]: loss 0.150788
[epoch8, step1349]: loss 0.150886
[epoch8, step1350]: loss 0.153626
[epoch8, step1351]: loss 0.147601
[epoch8, step1352]: loss 0.156530
[epoch8, step1353]: loss 0.143300
[epoch8, step1354]: loss 0.162208
[epoch8, step1355]: loss 0.148964
[epoch8, step1356]: loss 0.137405
[epoch8, step1357]: loss 0.151469
[epoch8, step1358]: loss 0.151134
[epoch8, step1359]: loss 0.155933
[epoch8, step1360]: loss 0.142239
[epoch8, step1361]: loss 0.153565
[epoch8, step1362]: loss 0.139840
[epoch8, step1363]: loss 0.157768
[epoch8, step1364]: loss 0.148849
[epoch8, step1365]: loss 0.134529
[epoch8, step1366]: loss 0.148838
[epoch8, step1367]: loss 0.153045
[epoch8, step1368]: loss 0.150216
[epoch8, step1369]: loss 0.144533
[epoch8, step1370]: loss 0.155621
[epoch8, step1371]: loss 0.139515
[epoch8, step1372]: loss 0.160077
[epoch8, step1373]: loss 0.148868
[epoch8, step1374]: loss 0.131171
[epoch8, step1375]: loss 0.146570
[epoch8, step1376]: loss 0.150665
[epoch8, step1377]: loss 0.157909
[epoch8, step1378]: loss 0.144101
[epoch8, step1379]: loss 0.155952
[epoch8, step1380]: loss 0.137362
[epoch8, step1381]: loss 0.159477
[epoch8, step1382]: loss 0.147972
[epoch8, step1383]: loss 0.133506
[epoch8, step1384]: loss 0.147297
[epoch8, step1385]: loss 0.151824
[epoch8, step1386]: loss 0.153124
[epoch8, step1387]: loss 0.140939
[epoch8, step1388]: loss 0.158048
[epoch8, step1389]: loss 0.141610
[epoch8, step1390]: loss 0.158945
[epoch8, step1391]: loss 0.148870
[epoch8, step1392]: loss 0.134622
[epoch8, step1393]: loss 0.146367
[epoch8, step1394]: loss 0.147700
[epoch8, step1395]: loss 0.153282
[epoch8, step1396]: loss 0.143401
[epoch8, step1397]: loss 0.154826
[epoch8, step1398]: loss 0.139217
[epoch8, step1399]: loss 0.155444
[epoch8, step1400]: loss 0.147652
[epoch8, step1401]: loss 0.132119
[epoch8, step1402]: loss 0.147648
[epoch8, step1403]: loss 0.153310
[epoch8, step1404]: loss 0.155167
[epoch8, step1405]: loss 0.141495
[epoch8, step1406]: loss 0.154997
[epoch8, step1407]: loss 0.136408
[epoch8, step1408]: loss 0.161670
[epoch8, step1409]: loss 0.149813
[epoch8, step1410]: loss 0.131624
[epoch8, step1411]: loss 0.151841
[epoch8, step1412]: loss 0.149705
[epoch8, step1413]: loss 0.153523
[epoch8, step1414]: loss 0.144397
[epoch8, step1415]: loss 0.154702
[epoch8, step1416]: loss 0.138254
[epoch8, step1417]: loss 0.159815
[epoch8, step1418]: loss 0.148423
[epoch8, step1419]: loss 0.130831
[epoch8, step1420]: loss 0.147876
[epoch8, step1421]: loss 0.148070
[epoch8, step1422]: loss 0.151847
[epoch8, step1423]: loss 0.144028
[epoch8, step1424]: loss 0.153275
[epoch8, step1425]: loss 0.141054
[epoch8, step1426]: loss 0.158885
[epoch8, step1427]: loss 0.144813
[epoch8, step1428]: loss 0.133125
[epoch8, step1429]: loss 0.146473
[epoch8, step1430]: loss 0.150409
[epoch8, step1431]: loss 0.152825
[epoch8, step1432]: loss 0.143434
[epoch8, step1433]: loss 0.153047
[epoch8, step1434]: loss 0.143431
[epoch8, step1435]: loss 0.156833
[epoch8, step1436]: loss 0.146375
[epoch8, step1437]: loss 0.131205
[epoch8, step1438]: loss 0.146469
[epoch8, step1439]: loss 0.150634
[epoch8, step1440]: loss 0.153880
[epoch8, step1441]: loss 0.140307
[epoch8, step1442]: loss 0.156262
[epoch8, step1443]: loss 0.142825
[epoch8, step1444]: loss 0.160959
[epoch8, step1445]: loss 0.146255
[epoch8, step1446]: loss 0.130736
[epoch8, step1447]: loss 0.145495
[epoch8, step1448]: loss 0.149734
[epoch8, step1449]: loss 0.154450
[epoch8, step1450]: loss 0.142765
[epoch8, step1451]: loss 0.151757
[epoch8, step1452]: loss 0.140196
[epoch8, step1453]: loss 0.154575
[epoch8, step1454]: loss 0.145660
[epoch8, step1455]: loss 0.129271
[epoch8, step1456]: loss 0.148286
[epoch8, step1457]: loss 0.146429
[epoch8, step1458]: loss 0.152245
[epoch8, step1459]: loss 0.144005
[epoch8, step1460]: loss 0.151066
[epoch8, step1461]: loss 0.136220
[epoch8, step1462]: loss 0.154984
[epoch8, step1463]: loss 0.148124
[epoch8, step1464]: loss 0.130065
[epoch8, step1465]: loss 0.149167
[epoch8, step1466]: loss 0.149563
[epoch8, step1467]: loss 0.154147
[epoch8, step1468]: loss 0.143135
[epoch8, step1469]: loss 0.153108
[epoch8, step1470]: loss 0.137821
[epoch8, step1471]: loss 0.160004
[epoch8, step1472]: loss 0.148070
[epoch8, step1473]: loss 0.130822
[epoch8, step1474]: loss 0.144345
[epoch8, step1475]: loss 0.149661
[epoch8, step1476]: loss 0.150078
[epoch8, step1477]: loss 0.144100
[epoch8, step1478]: loss 0.152388
[epoch8, step1479]: loss 0.138302
[epoch8, step1480]: loss 0.157669
[epoch8, step1481]: loss 0.150940
[epoch8, step1482]: loss 0.132200
[epoch8, step1483]: loss 0.146776
[epoch8, step1484]: loss 0.147712
[epoch8, step1485]: loss 0.152125
[epoch8, step1486]: loss 0.145182
[epoch8, step1487]: loss 0.152743
[epoch8, step1488]: loss 0.137799
[epoch8, step1489]: loss 0.158132
[epoch8, step1490]: loss 0.145949
[epoch8, step1491]: loss 0.132693
[epoch8, step1492]: loss 0.148290
[epoch8, step1493]: loss 0.148966
[epoch8, step1494]: loss 0.151971
[epoch8, step1495]: loss 0.144452
[epoch8, step1496]: loss 0.155360
[epoch8, step1497]: loss 0.137154
[epoch8, step1498]: loss 0.155507
[epoch8, step1499]: loss 0.148892
[epoch8, step1500]: loss 0.131044
[epoch8, step1501]: loss 0.146271
[epoch8, step1502]: loss 0.148620
[epoch8, step1503]: loss 0.152865
[epoch8, step1504]: loss 0.144065
[epoch8, step1505]: loss 0.151236
[epoch8, step1506]: loss 0.138904
[epoch8, step1507]: loss 0.155780
[epoch8, step1508]: loss 0.144928
[epoch8, step1509]: loss 0.133088
[epoch8, step1510]: loss 0.150471
[epoch8, step1511]: loss 0.145544
[epoch8, step1512]: loss 0.150615
[epoch8, step1513]: loss 0.146096
[epoch8, step1514]: loss 0.152151
[epoch8, step1515]: loss 0.137768
[epoch8, step1516]: loss 0.156863

[epoch8]: avg loss 0.156651

[epoch9, step1]: loss 0.186433
[epoch9, step2]: loss 0.150260
[epoch9, step3]: loss 0.151460
[epoch9, step4]: loss 0.142166
[epoch9, step5]: loss 0.157101
[epoch9, step6]: loss 0.146845
[epoch9, step7]: loss 0.134527
[epoch9, step8]: loss 0.152576
[epoch9, step9]: loss 0.137374
[epoch9, step10]: loss 0.152848
[epoch9, step11]: loss 0.149685
[epoch9, step12]: loss 0.150431
[epoch9, step13]: loss 0.136832
[epoch9, step14]: loss 0.156607
[epoch9, step15]: loss 0.146946
[epoch9, step16]: loss 0.134920
[epoch9, step17]: loss 0.150699
[epoch9, step18]: loss 0.133461
[epoch9, step19]: loss 0.154626
[epoch9, step20]: loss 0.145991
[epoch9, step21]: loss 0.150836
[epoch9, step22]: loss 0.139811
[epoch9, step23]: loss 0.161167
[epoch9, step24]: loss 0.145293
[epoch9, step25]: loss 0.135245
[epoch9, step26]: loss 0.154822
[epoch9, step27]: loss 0.137260
[epoch9, step28]: loss 0.154061
[epoch9, step29]: loss 0.148091
[epoch9, step30]: loss 0.147514
[epoch9, step31]: loss 0.138674
[epoch9, step32]: loss 0.155442
[epoch9, step33]: loss 0.143893
[epoch9, step34]: loss 0.133300
[epoch9, step35]: loss 0.150760
[epoch9, step36]: loss 0.136900
[epoch9, step37]: loss 0.154691
[epoch9, step38]: loss 0.149318
[epoch9, step39]: loss 0.150005
[epoch9, step40]: loss 0.135798
[epoch9, step41]: loss 0.159257
[epoch9, step42]: loss 0.144304
[epoch9, step43]: loss 0.135990
[epoch9, step44]: loss 0.151098
[epoch9, step45]: loss 0.136743
[epoch9, step46]: loss 0.154559
[epoch9, step47]: loss 0.150350
[epoch9, step48]: loss 0.150954
[epoch9, step49]: loss 0.140315
[epoch9, step50]: loss 0.156748
[epoch9, step51]: loss 0.145866
[epoch9, step52]: loss 0.136281
[epoch9, step53]: loss 0.149247
[epoch9, step54]: loss 0.135164
[epoch9, step55]: loss 0.152585
[epoch9, step56]: loss 0.144160
[epoch9, step57]: loss 0.147972
[epoch9, step58]: loss 0.136611
[epoch9, step59]: loss 0.160667
[epoch9, step60]: loss 0.142776
[epoch9, step61]: loss 0.136575
[epoch9, step62]: loss 0.153500
[epoch9, step63]: loss 0.138405
[epoch9, step64]: loss 0.157054
[epoch9, step65]: loss 0.147194
[epoch9, step66]: loss 0.149398
[epoch9, step67]: loss 0.138168
[epoch9, step68]: loss 0.157007
[epoch9, step69]: loss 0.145345
[epoch9, step70]: loss 0.135733
[epoch9, step71]: loss 0.152968
[epoch9, step72]: loss 0.135269
[epoch9, step73]: loss 0.154725
[epoch9, step74]: loss 0.147133
[epoch9, step75]: loss 0.148283
[epoch9, step76]: loss 0.137172
[epoch9, step77]: loss 0.153949
[epoch9, step78]: loss 0.144110
[epoch9, step79]: loss 0.136487
[epoch9, step80]: loss 0.148034
[epoch9, step81]: loss 0.134558
[epoch9, step82]: loss 0.156246
[epoch9, step83]: loss 0.150743
[epoch9, step84]: loss 0.148332
[epoch9, step85]: loss 0.134469
[epoch9, step86]: loss 0.154758
[epoch9, step87]: loss 0.141526
[epoch9, step88]: loss 0.141495
[epoch9, step89]: loss 0.152735
[epoch9, step90]: loss 0.136361
[epoch9, step91]: loss 0.157878
[epoch9, step92]: loss 0.146873
[epoch9, step93]: loss 0.148053
[epoch9, step94]: loss 0.138383
[epoch9, step95]: loss 0.154213
[epoch9, step96]: loss 0.145593
[epoch9, step97]: loss 0.132956
[epoch9, step98]: loss 0.150935
[epoch9, step99]: loss 0.135753
[epoch9, step100]: loss 0.157603
[epoch9, step101]: loss 0.144673
[epoch9, step102]: loss 0.149142
[epoch9, step103]: loss 0.137696
[epoch9, step104]: loss 0.155892
[epoch9, step105]: loss 0.142797
[epoch9, step106]: loss 0.135274
[epoch9, step107]: loss 0.151104
[epoch9, step108]: loss 0.134649
[epoch9, step109]: loss 0.154813
[epoch9, step110]: loss 0.144746
[epoch9, step111]: loss 0.149088
[epoch9, step112]: loss 0.138101
[epoch9, step113]: loss 0.152399
[epoch9, step114]: loss 0.145196
[epoch9, step115]: loss 0.134877
[epoch9, step116]: loss 0.147721
[epoch9, step117]: loss 0.134289
[epoch9, step118]: loss 0.150563
[epoch9, step119]: loss 0.145191
[epoch9, step120]: loss 0.147057
[epoch9, step121]: loss 0.137476
[epoch9, step122]: loss 0.155279
[epoch9, step123]: loss 0.142517
[epoch9, step124]: loss 0.134571
[epoch9, step125]: loss 0.148468
[epoch9, step126]: loss 0.135592
[epoch9, step127]: loss 0.154230
[epoch9, step128]: loss 0.147049
[epoch9, step129]: loss 0.147720
[epoch9, step130]: loss 0.134438
[epoch9, step131]: loss 0.157273
[epoch9, step132]: loss 0.143175
[epoch9, step133]: loss 0.133232
[epoch9, step134]: loss 0.152594
[epoch9, step135]: loss 0.132923
[epoch9, step136]: loss 0.148627
[epoch9, step137]: loss 0.147536
[epoch9, step138]: loss 0.147906
[epoch9, step139]: loss 0.136165
[epoch9, step140]: loss 0.153103
[epoch9, step141]: loss 0.142539
[epoch9, step142]: loss 0.133902
[epoch9, step143]: loss 0.151475
[epoch9, step144]: loss 0.136424
[epoch9, step145]: loss 0.153232
[epoch9, step146]: loss 0.146350
[epoch9, step147]: loss 0.143121
[epoch9, step148]: loss 0.135700
[epoch9, step149]: loss 0.156900
[epoch9, step150]: loss 0.144820
[epoch9, step151]: loss 0.131643
[epoch9, step152]: loss 0.149707
[epoch9, step153]: loss 0.132928
[epoch9, step154]: loss 0.155056
[epoch9, step155]: loss 0.145818
[epoch9, step156]: loss 0.149191
[epoch9, step157]: loss 0.134500
[epoch9, step158]: loss 0.153110
[epoch9, step159]: loss 0.142393
[epoch9, step160]: loss 0.132299
[epoch9, step161]: loss 0.147126
[epoch9, step162]: loss 0.133135
[epoch9, step163]: loss 0.153152
[epoch9, step164]: loss 0.144134
[epoch9, step165]: loss 0.147056
[epoch9, step166]: loss 0.133101
[epoch9, step167]: loss 0.155944
[epoch9, step168]: loss 0.140107
[epoch9, step169]: loss 0.134658
[epoch9, step170]: loss 0.148072
[epoch9, step171]: loss 0.133258
[epoch9, step172]: loss 0.152201
[epoch9, step173]: loss 0.144453
[epoch9, step174]: loss 0.147964
[epoch9, step175]: loss 0.131800
[epoch9, step176]: loss 0.153560
[epoch9, step177]: loss 0.141490
[epoch9, step178]: loss 0.130479
[epoch9, step179]: loss 0.151936
[epoch9, step180]: loss 0.131288
[epoch9, step181]: loss 0.151278
[epoch9, step182]: loss 0.143852
[epoch9, step183]: loss 0.144424
[epoch9, step184]: loss 0.131782
[epoch9, step185]: loss 0.153085
[epoch9, step186]: loss 0.141101
[epoch9, step187]: loss 0.133620
[epoch9, step188]: loss 0.149653
[epoch9, step189]: loss 0.132204
[epoch9, step190]: loss 0.154432
[epoch9, step191]: loss 0.145661
[epoch9, step192]: loss 0.144282
[epoch9, step193]: loss 0.140802
[epoch9, step194]: loss 0.156503
[epoch9, step195]: loss 0.140957
[epoch9, step196]: loss 0.131132
[epoch9, step197]: loss 0.149219
[epoch9, step198]: loss 0.135080
[epoch9, step199]: loss 0.151523
[epoch9, step200]: loss 0.142393
[epoch9, step201]: loss 0.144323
[epoch9, step202]: loss 0.135162
[epoch9, step203]: loss 0.153511
[epoch9, step204]: loss 0.140328
[epoch9, step205]: loss 0.135040
[epoch9, step206]: loss 0.149598
[epoch9, step207]: loss 0.132498
[epoch9, step208]: loss 0.149641
[epoch9, step209]: loss 0.143146
[epoch9, step210]: loss 0.142763
[epoch9, step211]: loss 0.133932
[epoch9, step212]: loss 0.152208
[epoch9, step213]: loss 0.142664
[epoch9, step214]: loss 0.135891
[epoch9, step215]: loss 0.147485
[epoch9, step216]: loss 0.131947
[epoch9, step217]: loss 0.154491
[epoch9, step218]: loss 0.142847
[epoch9, step219]: loss 0.146644
[epoch9, step220]: loss 0.136013
[epoch9, step221]: loss 0.152034
[epoch9, step222]: loss 0.139896
[epoch9, step223]: loss 0.129504
[epoch9, step224]: loss 0.149215
[epoch9, step225]: loss 0.131881
[epoch9, step226]: loss 0.152699
[epoch9, step227]: loss 0.147494
[epoch9, step228]: loss 0.143620
[epoch9, step229]: loss 0.137002
[epoch9, step230]: loss 0.151252
[epoch9, step231]: loss 0.139492
[epoch9, step232]: loss 0.132584
[epoch9, step233]: loss 0.150741
[epoch9, step234]: loss 0.133991
[epoch9, step235]: loss 0.151441
[epoch9, step236]: loss 0.143528
[epoch9, step237]: loss 0.145396
[epoch9, step238]: loss 0.133261
[epoch9, step239]: loss 0.155035
[epoch9, step240]: loss 0.144384
[epoch9, step241]: loss 0.131327
[epoch9, step242]: loss 0.148511
[epoch9, step243]: loss 0.131341
[epoch9, step244]: loss 0.151982
[epoch9, step245]: loss 0.145403
[epoch9, step246]: loss 0.145484
[epoch9, step247]: loss 0.134131
[epoch9, step248]: loss 0.153859
[epoch9, step249]: loss 0.142753
[epoch9, step250]: loss 0.130807
[epoch9, step251]: loss 0.145686
[epoch9, step252]: loss 0.130452
[epoch9, step253]: loss 0.152938
[epoch9, step254]: loss 0.146325
[epoch9, step255]: loss 0.144246
[epoch9, step256]: loss 0.135889
[epoch9, step257]: loss 0.153091
[epoch9, step258]: loss 0.138930
[epoch9, step259]: loss 0.129866
[epoch9, step260]: loss 0.149643
[epoch9, step261]: loss 0.128568
[epoch9, step262]: loss 0.148940
[epoch9, step263]: loss 0.146295
[epoch9, step264]: loss 0.145763
[epoch9, step265]: loss 0.134050
[epoch9, step266]: loss 0.152540
[epoch9, step267]: loss 0.143759
[epoch9, step268]: loss 0.131558
[epoch9, step269]: loss 0.146980
[epoch9, step270]: loss 0.132670
[epoch9, step271]: loss 0.149918
[epoch9, step272]: loss 0.143671
[epoch9, step273]: loss 0.145773
[epoch9, step274]: loss 0.131122
[epoch9, step275]: loss 0.154452
[epoch9, step276]: loss 0.142611
[epoch9, step277]: loss 0.130453
[epoch9, step278]: loss 0.146532
[epoch9, step279]: loss 0.130892
[epoch9, step280]: loss 0.149875
[epoch9, step281]: loss 0.144088
[epoch9, step282]: loss 0.142671
[epoch9, step283]: loss 0.135006
[epoch9, step284]: loss 0.153579
[epoch9, step285]: loss 0.137833
[epoch9, step286]: loss 0.137249
[epoch9, step287]: loss 0.146460
[epoch9, step288]: loss 0.133109
[epoch9, step289]: loss 0.148582
[epoch9, step290]: loss 0.143244
[epoch9, step291]: loss 0.143506
[epoch9, step292]: loss 0.135911
[epoch9, step293]: loss 0.152520
[epoch9, step294]: loss 0.141985
[epoch9, step295]: loss 0.132013
[epoch9, step296]: loss 0.144325
[epoch9, step297]: loss 0.132898
[epoch9, step298]: loss 0.149612
[epoch9, step299]: loss 0.146116
[epoch9, step300]: loss 0.143021
[epoch9, step301]: loss 0.135103
[epoch9, step302]: loss 0.150076
[epoch9, step303]: loss 0.138843
[epoch9, step304]: loss 0.130131
[epoch9, step305]: loss 0.148020
[epoch9, step306]: loss 0.131100
[epoch9, step307]: loss 0.151756
[epoch9, step308]: loss 0.141049
[epoch9, step309]: loss 0.142393
[epoch9, step310]: loss 0.133509
[epoch9, step311]: loss 0.149723
[epoch9, step312]: loss 0.141036
[epoch9, step313]: loss 0.131347
[epoch9, step314]: loss 0.146368
[epoch9, step315]: loss 0.129996
[epoch9, step316]: loss 0.150958
[epoch9, step317]: loss 0.142053
[epoch9, step318]: loss 0.143770
[epoch9, step319]: loss 0.135300
[epoch9, step320]: loss 0.154754
[epoch9, step321]: loss 0.141339
[epoch9, step322]: loss 0.134063
[epoch9, step323]: loss 0.148896
[epoch9, step324]: loss 0.129330
[epoch9, step325]: loss 0.149272
[epoch9, step326]: loss 0.143510
[epoch9, step327]: loss 0.146136
[epoch9, step328]: loss 0.133521
[epoch9, step329]: loss 0.152472
[epoch9, step330]: loss 0.142320
[epoch9, step331]: loss 0.131770
[epoch9, step332]: loss 0.148334
[epoch9, step333]: loss 0.132135
[epoch9, step334]: loss 0.148878
[epoch9, step335]: loss 0.142238
[epoch9, step336]: loss 0.140925
[epoch9, step337]: loss 0.130719
[epoch9, step338]: loss 0.152945
[epoch9, step339]: loss 0.140711
[epoch9, step340]: loss 0.131168
[epoch9, step341]: loss 0.147872
[epoch9, step342]: loss 0.130703
[epoch9, step343]: loss 0.148425
[epoch9, step344]: loss 0.143269
[epoch9, step345]: loss 0.145947
[epoch9, step346]: loss 0.134484
[epoch9, step347]: loss 0.152085
[epoch9, step348]: loss 0.138775
[epoch9, step349]: loss 0.129150
[epoch9, step350]: loss 0.147907
[epoch9, step351]: loss 0.131805
[epoch9, step352]: loss 0.149197
[epoch9, step353]: loss 0.142678
[epoch9, step354]: loss 0.147063
[epoch9, step355]: loss 0.134984
[epoch9, step356]: loss 0.148617
[epoch9, step357]: loss 0.139165
[epoch9, step358]: loss 0.135480
[epoch9, step359]: loss 0.143334
[epoch9, step360]: loss 0.131476
[epoch9, step361]: loss 0.150943
[epoch9, step362]: loss 0.140347
[epoch9, step363]: loss 0.144575
[epoch9, step364]: loss 0.133198
[epoch9, step365]: loss 0.151226
[epoch9, step366]: loss 0.138252
[epoch9, step367]: loss 0.131721
[epoch9, step368]: loss 0.147731
[epoch9, step369]: loss 0.131357
[epoch9, step370]: loss 0.146965
[epoch9, step371]: loss 0.139098
[epoch9, step372]: loss 0.144420
[epoch9, step373]: loss 0.132607
[epoch9, step374]: loss 0.152662
[epoch9, step375]: loss 0.136954
[epoch9, step376]: loss 0.128100
[epoch9, step377]: loss 0.145055
[epoch9, step378]: loss 0.130710
[epoch9, step379]: loss 0.146799
[epoch9, step380]: loss 0.139971
[epoch9, step381]: loss 0.144167
[epoch9, step382]: loss 0.134871
[epoch9, step383]: loss 0.154167
[epoch9, step384]: loss 0.141515
[epoch9, step385]: loss 0.127988
[epoch9, step386]: loss 0.144822
[epoch9, step387]: loss 0.128804
[epoch9, step388]: loss 0.145668
[epoch9, step389]: loss 0.141608
[epoch9, step390]: loss 0.139225
[epoch9, step391]: loss 0.131795
[epoch9, step392]: loss 0.147826
[epoch9, step393]: loss 0.140503
[epoch9, step394]: loss 0.131823
[epoch9, step395]: loss 0.146378
[epoch9, step396]: loss 0.129558
[epoch9, step397]: loss 0.150607
[epoch9, step398]: loss 0.141034
[epoch9, step399]: loss 0.142991
[epoch9, step400]: loss 0.131237
[epoch9, step401]: loss 0.150422
[epoch9, step402]: loss 0.139545
[epoch9, step403]: loss 0.128800
[epoch9, step404]: loss 0.144228
[epoch9, step405]: loss 0.128323
[epoch9, step406]: loss 0.146601
[epoch9, step407]: loss 0.142280
[epoch9, step408]: loss 0.142218
[epoch9, step409]: loss 0.126828
[epoch9, step410]: loss 0.147677
[epoch9, step411]: loss 0.138694
[epoch9, step412]: loss 0.129642
[epoch9, step413]: loss 0.145302
[epoch9, step414]: loss 0.132409
[epoch9, step415]: loss 0.147599
[epoch9, step416]: loss 0.143206
[epoch9, step417]: loss 0.141716
[epoch9, step418]: loss 0.130898
[epoch9, step419]: loss 0.151819
[epoch9, step420]: loss 0.137155
[epoch9, step421]: loss 0.129937
[epoch9, step422]: loss 0.144704
[epoch9, step423]: loss 0.129119
[epoch9, step424]: loss 0.146779
[epoch9, step425]: loss 0.140399
[epoch9, step426]: loss 0.141023
[epoch9, step427]: loss 0.132935
[epoch9, step428]: loss 0.149903
[epoch9, step429]: loss 0.135248
[epoch9, step430]: loss 0.129338
[epoch9, step431]: loss 0.143615
[epoch9, step432]: loss 0.128525
[epoch9, step433]: loss 0.144534
[epoch9, step434]: loss 0.141128
[epoch9, step435]: loss 0.140719
[epoch9, step436]: loss 0.134163
[epoch9, step437]: loss 0.148537
[epoch9, step438]: loss 0.135503
[epoch9, step439]: loss 0.129989
[epoch9, step440]: loss 0.144363
[epoch9, step441]: loss 0.128131
[epoch9, step442]: loss 0.147180
[epoch9, step443]: loss 0.138841
[epoch9, step444]: loss 0.143387
[epoch9, step445]: loss 0.130650
[epoch9, step446]: loss 0.147784
[epoch9, step447]: loss 0.135696
[epoch9, step448]: loss 0.127243
[epoch9, step449]: loss 0.145178
[epoch9, step450]: loss 0.131763
[epoch9, step451]: loss 0.147898
[epoch9, step452]: loss 0.144306
[epoch9, step453]: loss 0.141078
[epoch9, step454]: loss 0.132355
[epoch9, step455]: loss 0.147974
[epoch9, step456]: loss 0.140208
[epoch9, step457]: loss 0.127810
[epoch9, step458]: loss 0.144890
[epoch9, step459]: loss 0.126482
[epoch9, step460]: loss 0.147333
[epoch9, step461]: loss 0.138022
[epoch9, step462]: loss 0.143805
[epoch9, step463]: loss 0.131154
[epoch9, step464]: loss 0.149313
[epoch9, step465]: loss 0.132832
[epoch9, step466]: loss 0.128033
[epoch9, step467]: loss 0.145285
[epoch9, step468]: loss 0.129547
[epoch9, step469]: loss 0.146576
[epoch9, step470]: loss 0.139372
[epoch9, step471]: loss 0.142644
[epoch9, step472]: loss 0.131611
[epoch9, step473]: loss 0.149761
[epoch9, step474]: loss 0.138230
[epoch9, step475]: loss 0.128569
[epoch9, step476]: loss 0.142159
[epoch9, step477]: loss 0.128845
[epoch9, step478]: loss 0.148192
[epoch9, step479]: loss 0.140108
[epoch9, step480]: loss 0.144020
[epoch9, step481]: loss 0.131533
[epoch9, step482]: loss 0.150625
[epoch9, step483]: loss 0.135722
[epoch9, step484]: loss 0.125314
[epoch9, step485]: loss 0.143382
[epoch9, step486]: loss 0.127300
[epoch9, step487]: loss 0.148558
[epoch9, step488]: loss 0.138646
[epoch9, step489]: loss 0.144007
[epoch9, step490]: loss 0.130783
[epoch9, step491]: loss 0.147012
[epoch9, step492]: loss 0.137802
[epoch9, step493]: loss 0.127600
[epoch9, step494]: loss 0.145494
[epoch9, step495]: loss 0.123922
[epoch9, step496]: loss 0.146888
[epoch9, step497]: loss 0.139052
[epoch9, step498]: loss 0.141021
[epoch9, step499]: loss 0.130765
[epoch9, step500]: loss 0.149794
[epoch9, step501]: loss 0.138998
[epoch9, step502]: loss 0.128157
[epoch9, step503]: loss 0.143015
[epoch9, step504]: loss 0.131067
[epoch9, step505]: loss 0.149778
[epoch9, step506]: loss 0.137329
[epoch9, step507]: loss 0.139498
[epoch9, step508]: loss 0.129445
[epoch9, step509]: loss 0.148876
[epoch9, step510]: loss 0.136435
[epoch9, step511]: loss 0.129228
[epoch9, step512]: loss 0.141878
[epoch9, step513]: loss 0.128368
[epoch9, step514]: loss 0.145369
[epoch9, step515]: loss 0.139435
[epoch9, step516]: loss 0.139226
[epoch9, step517]: loss 0.131255
[epoch9, step518]: loss 0.147602
[epoch9, step519]: loss 0.136386
[epoch9, step520]: loss 0.127156
[epoch9, step521]: loss 0.144604
[epoch9, step522]: loss 0.128764
[epoch9, step523]: loss 0.146046
[epoch9, step524]: loss 0.141894
[epoch9, step525]: loss 0.139265
[epoch9, step526]: loss 0.127764
[epoch9, step527]: loss 0.148975
[epoch9, step528]: loss 0.135280
[epoch9, step529]: loss 0.129577
[epoch9, step530]: loss 0.141814
[epoch9, step531]: loss 0.127674
[epoch9, step532]: loss 0.147257
[epoch9, step533]: loss 0.135771
[epoch9, step534]: loss 0.140602
[epoch9, step535]: loss 0.129457
[epoch9, step536]: loss 0.146847
[epoch9, step537]: loss 0.135677
[epoch9, step538]: loss 0.129923
[epoch9, step539]: loss 0.143668
[epoch9, step540]: loss 0.131163
[epoch9, step541]: loss 0.147460
[epoch9, step542]: loss 0.139231
[epoch9, step543]: loss 0.140707
[epoch9, step544]: loss 0.127366
[epoch9, step545]: loss 0.150175
[epoch9, step546]: loss 0.134565
[epoch9, step547]: loss 0.130100
[epoch9, step548]: loss 0.143149
[epoch9, step549]: loss 0.127078
[epoch9, step550]: loss 0.145143
[epoch9, step551]: loss 0.139109
[epoch9, step552]: loss 0.141659
[epoch9, step553]: loss 0.129360
[epoch9, step554]: loss 0.148467
[epoch9, step555]: loss 0.137551
[epoch9, step556]: loss 0.126617
[epoch9, step557]: loss 0.144501
[epoch9, step558]: loss 0.126832
[epoch9, step559]: loss 0.147326
[epoch9, step560]: loss 0.138252
[epoch9, step561]: loss 0.140697
[epoch9, step562]: loss 0.128211
[epoch9, step563]: loss 0.165753
[epoch9, step564]: loss 0.130672
[epoch9, step565]: loss 0.105574
[epoch9, step566]: loss 0.114197
[epoch9, step567]: loss 0.108669
[epoch9, step568]: loss 0.119689
[epoch9, step569]: loss 0.140328
[epoch9, step570]: loss 0.123192
[epoch9, step571]: loss 0.088941
[epoch9, step572]: loss 0.119276
[epoch9, step573]: loss 0.126145
[epoch9, step574]: loss 0.150275
[epoch9, step575]: loss 0.128871
[epoch9, step576]: loss 0.132921
[epoch9, step577]: loss 0.115334
[epoch9, step578]: loss 0.132639
[epoch9, step579]: loss 0.109866
[epoch9, step580]: loss 0.149874
[epoch9, step581]: loss 0.133484
[epoch9, step582]: loss 0.129359
[epoch9, step583]: loss 0.131045
[epoch9, step584]: loss 0.123974
[epoch9, step585]: loss 0.145689
[epoch9, step586]: loss 0.128340
[epoch9, step587]: loss 0.096011
[epoch9, step588]: loss 0.130368
[epoch9, step589]: loss 0.167174
[epoch9, step590]: loss 0.101054
[epoch9, step591]: loss 0.125331
[epoch9, step592]: loss 0.139343
[epoch9, step593]: loss 0.164299
[epoch9, step594]: loss 0.102340
[epoch9, step595]: loss 0.103138
[epoch9, step596]: loss 0.139730
[epoch9, step597]: loss 0.144967
[epoch9, step598]: loss 0.110830
[epoch9, step599]: loss 0.102162
[epoch9, step600]: loss 0.100683
[epoch9, step601]: loss 0.125974
[epoch9, step602]: loss 0.149839
[epoch9, step603]: loss 0.113707
[epoch9, step604]: loss 0.111809
[epoch9, step605]: loss 0.100086
[epoch9, step606]: loss 0.123982
[epoch9, step607]: loss 0.135307
[epoch9, step608]: loss 0.088628
[epoch9, step609]: loss 0.128463
[epoch9, step610]: loss 0.114598
[epoch9, step611]: loss 0.140305
[epoch9, step612]: loss 0.128924
[epoch9, step613]: loss 0.138825
[epoch9, step614]: loss 0.125525
[epoch9, step615]: loss 0.128846
[epoch9, step616]: loss 0.103819
[epoch9, step617]: loss 0.117948
[epoch9, step618]: loss 0.137957
[epoch9, step619]: loss 0.106911
[epoch9, step620]: loss 0.098936
[epoch9, step621]: loss 0.096762
[epoch9, step622]: loss 0.133099
[epoch9, step623]: loss 0.129822
[epoch9, step624]: loss 0.130555
[epoch9, step625]: loss 0.098030
[epoch9, step626]: loss 0.130921
[epoch9, step627]: loss 0.148659
[epoch9, step628]: loss 0.136765
[epoch9, step629]: loss 0.078286
[epoch9, step630]: loss 0.109708
[epoch9, step631]: loss 0.111283
[epoch9, step632]: loss 0.130070
[epoch9, step633]: loss 0.108068
[epoch9, step634]: loss 0.124467
[epoch9, step635]: loss 0.117848
[epoch9, step636]: loss 0.103628
[epoch9, step637]: loss 0.138639
[epoch9, step638]: loss 0.128406
[epoch9, step639]: loss 0.100187
[epoch9, step640]: loss 0.133894
[epoch9, step641]: loss 0.105534
[epoch9, step642]: loss 0.101045
[epoch9, step643]: loss 0.133202
[epoch9, step644]: loss 0.117020
[epoch9, step645]: loss 0.092086
[epoch9, step646]: loss 0.121720
[epoch9, step647]: loss 0.094905
[epoch9, step648]: loss 0.148930
[epoch9, step649]: loss 0.129363
[epoch9, step650]: loss 0.135367
[epoch9, step651]: loss 0.115959
[epoch9, step652]: loss 0.144337
[epoch9, step653]: loss 0.139649
[epoch9, step654]: loss 0.132802
[epoch9, step655]: loss 0.104097
[epoch9, step656]: loss 0.139712
[epoch9, step657]: loss 0.139529
[epoch9, step658]: loss 0.109658
[epoch9, step659]: loss 0.095748
[epoch9, step660]: loss 0.121599
[epoch9, step661]: loss 0.129830
[epoch9, step662]: loss 0.096521
[epoch9, step663]: loss 0.117882
[epoch9, step664]: loss 0.115253
[epoch9, step665]: loss 0.145098
[epoch9, step666]: loss 0.099962
[epoch9, step667]: loss 0.128553
[epoch9, step668]: loss 0.145327
[epoch9, step669]: loss 0.101117
[epoch9, step670]: loss 0.124450
[epoch9, step671]: loss 0.126856
[epoch9, step672]: loss 0.151581
[epoch9, step673]: loss 0.139609
[epoch9, step674]: loss 0.116670
[epoch9, step675]: loss 0.134578
[epoch9, step676]: loss 0.132129
[epoch9, step677]: loss 0.113275
[epoch9, step678]: loss 0.098800
[epoch9, step679]: loss 0.120200
[epoch9, step680]: loss 0.100877
[epoch9, step681]: loss 0.100510
[epoch9, step682]: loss 0.104791
[epoch9, step683]: loss 0.123124
[epoch9, step684]: loss 0.102647
[epoch9, step685]: loss 0.103900
[epoch9, step686]: loss 0.100694
[epoch9, step687]: loss 0.109883
[epoch9, step688]: loss 0.130222
[epoch9, step689]: loss 0.103367
[epoch9, step690]: loss 0.135596
[epoch9, step691]: loss 0.141182
[epoch9, step692]: loss 0.135302
[epoch9, step693]: loss 0.125476
[epoch9, step694]: loss 0.096382
[epoch9, step695]: loss 0.112286
[epoch9, step696]: loss 0.103950
[epoch9, step697]: loss 0.124904
[epoch9, step698]: loss 0.112225
[epoch9, step699]: loss 0.114912
[epoch9, step700]: loss 0.148543
[epoch9, step701]: loss 0.129772
[epoch9, step702]: loss 0.111616
[epoch9, step703]: loss 0.145721
[epoch9, step704]: loss 0.135282
[epoch9, step705]: loss 0.104059
[epoch9, step706]: loss 0.108016
[epoch9, step707]: loss 0.111353
[epoch9, step708]: loss 0.122001
[epoch9, step709]: loss 0.108008
[epoch9, step710]: loss 0.123992
[epoch9, step711]: loss 0.135496
[epoch9, step712]: loss 0.096882
[epoch9, step713]: loss 0.110174
[epoch9, step714]: loss 0.127647
[epoch9, step715]: loss 0.108128
[epoch9, step716]: loss 0.125208
[epoch9, step717]: loss 0.105673
[epoch9, step718]: loss 0.117673
[epoch9, step719]: loss 0.121548
[epoch9, step720]: loss 0.104487
[epoch9, step721]: loss 0.114893
[epoch9, step722]: loss 0.123587
[epoch9, step723]: loss 0.117279
[epoch9, step724]: loss 0.125518
[epoch9, step725]: loss 0.126214
[epoch9, step726]: loss 0.089872
[epoch9, step727]: loss 0.123467
[epoch9, step728]: loss 0.125357
[epoch9, step729]: loss 0.101113
[epoch9, step730]: loss 0.124908
[epoch9, step731]: loss 0.135028
[epoch9, step732]: loss 0.114247
[epoch9, step733]: loss 0.094171
[epoch9, step734]: loss 0.106754
[epoch9, step735]: loss 0.107285
[epoch9, step736]: loss 0.112224
[epoch9, step737]: loss 0.100574
[epoch9, step738]: loss 0.106686
[epoch9, step739]: loss 0.147578
[epoch9, step740]: loss 0.155645
[epoch9, step741]: loss 0.121506
[epoch9, step742]: loss 0.137408
[epoch9, step743]: loss 0.118733
[epoch9, step744]: loss 0.116673
[epoch9, step745]: loss 0.118316
[epoch9, step746]: loss 0.126973
[epoch9, step747]: loss 0.115213
[epoch9, step748]: loss 0.104404
[epoch9, step749]: loss 0.148671
[epoch9, step750]: loss 0.127405
[epoch9, step751]: loss 0.110566
[epoch9, step752]: loss 0.101135
[epoch9, step753]: loss 0.103187
[epoch9, step754]: loss 0.136189
[epoch9, step755]: loss 0.125656
[epoch9, step756]: loss 0.094146
[epoch9, step757]: loss 0.116684
[epoch9, step758]: loss 0.128760
[epoch9, step759]: loss 0.102988
[epoch9, step760]: loss 0.124430
[epoch9, step761]: loss 0.114023
[epoch9, step762]: loss 0.106457
[epoch9, step763]: loss 0.108455
[epoch9, step764]: loss 0.122252
[epoch9, step765]: loss 0.106731
[epoch9, step766]: loss 0.100304
[epoch9, step767]: loss 0.127292
[epoch9, step768]: loss 0.117558
[epoch9, step769]: loss 0.119071
[epoch9, step770]: loss 0.144619
[epoch9, step771]: loss 0.099797
[epoch9, step772]: loss 0.102056
[epoch9, step773]: loss 0.113768
[epoch9, step774]: loss 0.116969
[epoch9, step775]: loss 0.141307
[epoch9, step776]: loss 0.124493
[epoch9, step777]: loss 0.109851
[epoch9, step778]: loss 0.132941
[epoch9, step779]: loss 0.112816
[epoch9, step780]: loss 0.126657
[epoch9, step781]: loss 0.144551
[epoch9, step782]: loss 0.136228
[epoch9, step783]: loss 0.117902
[epoch9, step784]: loss 0.133886
[epoch9, step785]: loss 0.130935
[epoch9, step786]: loss 0.116224
[epoch9, step787]: loss 0.141962
[epoch9, step788]: loss 0.119757
[epoch9, step789]: loss 0.136144
[epoch9, step790]: loss 0.099322
[epoch9, step791]: loss 0.126085
[epoch9, step792]: loss 0.126280
[epoch9, step793]: loss 0.128044
[epoch9, step794]: loss 0.119038
[epoch9, step795]: loss 0.116536
[epoch9, step796]: loss 0.112074
[epoch9, step797]: loss 0.103690
[epoch9, step798]: loss 0.104285
[epoch9, step799]: loss 0.090020
[epoch9, step800]: loss 0.147849
[epoch9, step801]: loss 0.138510
[epoch9, step802]: loss 0.114960
[epoch9, step803]: loss 0.107943
[epoch9, step804]: loss 0.125674
[epoch9, step805]: loss 0.112505
[epoch9, step806]: loss 0.118015
[epoch9, step807]: loss 0.129393
[epoch9, step808]: loss 0.141720
[epoch9, step809]: loss 0.107860
[epoch9, step810]: loss 0.093462
[epoch9, step811]: loss 0.117837
[epoch9, step812]: loss 0.126647
[epoch9, step813]: loss 0.107527
[epoch9, step814]: loss 0.121395
[epoch9, step815]: loss 0.115002
[epoch9, step816]: loss 0.117150
[epoch9, step817]: loss 0.102471
[epoch9, step818]: loss 0.110825
[epoch9, step819]: loss 0.163960
[epoch9, step820]: loss 0.104775
[epoch9, step821]: loss 0.103180
[epoch9, step822]: loss 0.121936
[epoch9, step823]: loss 0.102169
[epoch9, step824]: loss 0.118456
[epoch9, step825]: loss 0.123061
[epoch9, step826]: loss 0.087121
[epoch9, step827]: loss 0.106128
[epoch9, step828]: loss 0.116643
[epoch9, step829]: loss 0.108370
[epoch9, step830]: loss 0.083532
[epoch9, step831]: loss 0.102203
[epoch9, step832]: loss 0.142121
[epoch9, step833]: loss 0.120757
[epoch9, step834]: loss 0.116976
[epoch9, step835]: loss 0.120353
[epoch9, step836]: loss 0.104585
[epoch9, step837]: loss 0.099095
[epoch9, step838]: loss 0.131208
[epoch9, step839]: loss 0.116517
[epoch9, step840]: loss 0.105988
[epoch9, step841]: loss 0.114938
[epoch9, step842]: loss 0.115697
[epoch9, step843]: loss 0.128910
[epoch9, step844]: loss 0.129137
[epoch9, step845]: loss 0.122156
[epoch9, step846]: loss 0.150896
[epoch9, step847]: loss 0.116994
[epoch9, step848]: loss 0.068403
[epoch9, step849]: loss 0.107797
[epoch9, step850]: loss 0.129109
[epoch9, step851]: loss 0.112190
[epoch9, step852]: loss 0.115475
[epoch9, step853]: loss 0.126744
[epoch9, step854]: loss 0.129230
[epoch9, step855]: loss 0.105100
[epoch9, step856]: loss 0.095301
[epoch9, step857]: loss 0.123291
[epoch9, step858]: loss 0.125768
[epoch9, step859]: loss 0.104881
[epoch9, step860]: loss 0.131061
[epoch9, step861]: loss 0.118221
[epoch9, step862]: loss 0.095749
[epoch9, step863]: loss 0.128092
[epoch9, step864]: loss 0.133127
[epoch9, step865]: loss 0.122307
[epoch9, step866]: loss 0.128282
[epoch9, step867]: loss 0.109601
[epoch9, step868]: loss 0.121251
[epoch9, step869]: loss 0.103020
[epoch9, step870]: loss 0.098973
[epoch9, step871]: loss 0.141585
[epoch9, step872]: loss 0.125172
[epoch9, step873]: loss 0.098809
[epoch9, step874]: loss 0.114259
[epoch9, step875]: loss 0.145218
[epoch9, step876]: loss 0.131604
[epoch9, step877]: loss 0.074773
[epoch9, step878]: loss 0.104825
[epoch9, step879]: loss 0.111810
[epoch9, step880]: loss 0.106595
[epoch9, step881]: loss 0.131578
[epoch9, step882]: loss 0.103883
[epoch9, step883]: loss 0.109029
[epoch9, step884]: loss 0.141200
[epoch9, step885]: loss 0.141629
[epoch9, step886]: loss 0.135632
[epoch9, step887]: loss 0.142947
[epoch9, step888]: loss 0.109885
[epoch9, step889]: loss 0.126281
[epoch9, step890]: loss 0.127003
[epoch9, step891]: loss 0.108668
[epoch9, step892]: loss 0.127608
[epoch9, step893]: loss 0.123907
[epoch9, step894]: loss 0.124939
[epoch9, step895]: loss 0.097921
[epoch9, step896]: loss 0.153182
[epoch9, step897]: loss 0.152136
[epoch9, step898]: loss 0.103057
[epoch9, step899]: loss 0.077181
[epoch9, step900]: loss 0.116405
[epoch9, step901]: loss 0.133719
[epoch9, step902]: loss 0.104249
[epoch9, step903]: loss 0.136706
[epoch9, step904]: loss 0.103549
[epoch9, step905]: loss 0.098385
[epoch9, step906]: loss 0.093066
[epoch9, step907]: loss 0.127260
[epoch9, step908]: loss 0.137188
[epoch9, step909]: loss 0.112207
[epoch9, step910]: loss 0.094772
[epoch9, step911]: loss 0.092771
[epoch9, step912]: loss 0.127874
[epoch9, step913]: loss 0.129886
[epoch9, step914]: loss 0.117391
[epoch9, step915]: loss 0.103729
[epoch9, step916]: loss 0.120488
[epoch9, step917]: loss 0.116642
[epoch9, step918]: loss 0.130745
[epoch9, step919]: loss 0.097963
[epoch9, step920]: loss 0.133844
[epoch9, step921]: loss 0.106325
[epoch9, step922]: loss 0.109247
[epoch9, step923]: loss 0.136494
[epoch9, step924]: loss 0.105708
[epoch9, step925]: loss 0.108030
[epoch9, step926]: loss 0.109709
[epoch9, step927]: loss 0.134307
[epoch9, step928]: loss 0.105397
[epoch9, step929]: loss 0.111930
[epoch9, step930]: loss 0.116185
[epoch9, step931]: loss 0.127278
[epoch9, step932]: loss 0.105117
[epoch9, step933]: loss 0.109925
[epoch9, step934]: loss 0.137422
[epoch9, step935]: loss 0.117910
[epoch9, step936]: loss 0.104071
[epoch9, step937]: loss 0.096628
[epoch9, step938]: loss 0.143575
[epoch9, step939]: loss 0.107502
[epoch9, step940]: loss 0.129362
[epoch9, step941]: loss 0.120068
[epoch9, step942]: loss 0.117770
[epoch9, step943]: loss 0.135165
[epoch9, step944]: loss 0.118997
[epoch9, step945]: loss 0.130526
[epoch9, step946]: loss 0.115807
[epoch9, step947]: loss 0.104202
[epoch9, step948]: loss 0.158506
[epoch9, step949]: loss 0.116694
[epoch9, step950]: loss 0.113276
[epoch9, step951]: loss 0.123535
[epoch9, step952]: loss 0.127464
[epoch9, step953]: loss 0.116195
[epoch9, step954]: loss 0.123264
[epoch9, step955]: loss 0.097420
[epoch9, step956]: loss 0.143721
[epoch9, step957]: loss 0.129404
[epoch9, step958]: loss 0.147847
[epoch9, step959]: loss 0.136777
[epoch9, step960]: loss 0.124941
[epoch9, step961]: loss 0.134950
[epoch9, step962]: loss 0.134381
[epoch9, step963]: loss 0.139012
[epoch9, step964]: loss 0.127120
[epoch9, step965]: loss 0.140523
[epoch9, step966]: loss 0.124285
[epoch9, step967]: loss 0.141008
[epoch9, step968]: loss 0.132630
[epoch9, step969]: loss 0.118043
[epoch9, step970]: loss 0.131504
[epoch9, step971]: loss 0.132374
[epoch9, step972]: loss 0.134679
[epoch9, step973]: loss 0.129938
[epoch9, step974]: loss 0.134507
[epoch9, step975]: loss 0.123745
[epoch9, step976]: loss 0.141808
[epoch9, step977]: loss 0.129372
[epoch9, step978]: loss 0.118103
[epoch9, step979]: loss 0.133380
[epoch9, step980]: loss 0.132423
[epoch9, step981]: loss 0.136583
[epoch9, step982]: loss 0.126387
[epoch9, step983]: loss 0.135270
[epoch9, step984]: loss 0.124139
[epoch9, step985]: loss 0.141081
[epoch9, step986]: loss 0.128210
[epoch9, step987]: loss 0.114994
[epoch9, step988]: loss 0.128631
[epoch9, step989]: loss 0.130194
[epoch9, step990]: loss 0.136087
[epoch9, step991]: loss 0.124314
[epoch9, step992]: loss 0.135700
[epoch9, step993]: loss 0.124432
[epoch9, step994]: loss 0.142352
[epoch9, step995]: loss 0.130213
[epoch9, step996]: loss 0.117511
[epoch9, step997]: loss 0.129922
[epoch9, step998]: loss 0.129660
[epoch9, step999]: loss 0.134733
[epoch9, step1000]: loss 0.126344
[epoch9, step1001]: loss 0.134917
[epoch9, step1002]: loss 0.121541
[epoch9, step1003]: loss 0.140599
[epoch9, step1004]: loss 0.128447
[epoch9, step1005]: loss 0.118175
[epoch9, step1006]: loss 0.130189
[epoch9, step1007]: loss 0.131714
[epoch9, step1008]: loss 0.135982
[epoch9, step1009]: loss 0.125980
[epoch9, step1010]: loss 0.132956
[epoch9, step1011]: loss 0.122567
[epoch9, step1012]: loss 0.138143
[epoch9, step1013]: loss 0.129109
[epoch9, step1014]: loss 0.116217
[epoch9, step1015]: loss 0.128982
[epoch9, step1016]: loss 0.131409
[epoch9, step1017]: loss 0.136070
[epoch9, step1018]: loss 0.125411
[epoch9, step1019]: loss 0.134679
[epoch9, step1020]: loss 0.123687
[epoch9, step1021]: loss 0.140251
[epoch9, step1022]: loss 0.129512
[epoch9, step1023]: loss 0.117043
[epoch9, step1024]: loss 0.126665
[epoch9, step1025]: loss 0.132451
[epoch9, step1026]: loss 0.136961
[epoch9, step1027]: loss 0.124555
[epoch9, step1028]: loss 0.134666
[epoch9, step1029]: loss 0.122475
[epoch9, step1030]: loss 0.140537
[epoch9, step1031]: loss 0.133869
[epoch9, step1032]: loss 0.116136
[epoch9, step1033]: loss 0.132119
[epoch9, step1034]: loss 0.131728
[epoch9, step1035]: loss 0.136936
[epoch9, step1036]: loss 0.126235
[epoch9, step1037]: loss 0.135335
[epoch9, step1038]: loss 0.122817
[epoch9, step1039]: loss 0.138713
[epoch9, step1040]: loss 0.131050
[epoch9, step1041]: loss 0.117859
[epoch9, step1042]: loss 0.130468
[epoch9, step1043]: loss 0.130844
[epoch9, step1044]: loss 0.134049
[epoch9, step1045]: loss 0.124597
[epoch9, step1046]: loss 0.134102
[epoch9, step1047]: loss 0.121206
[epoch9, step1048]: loss 0.140966
[epoch9, step1049]: loss 0.129010
[epoch9, step1050]: loss 0.116498
[epoch9, step1051]: loss 0.129091
[epoch9, step1052]: loss 0.129986
[epoch9, step1053]: loss 0.134899
[epoch9, step1054]: loss 0.126001
[epoch9, step1055]: loss 0.135872
[epoch9, step1056]: loss 0.123631
[epoch9, step1057]: loss 0.136938
[epoch9, step1058]: loss 0.126508
[epoch9, step1059]: loss 0.116172
[epoch9, step1060]: loss 0.127436
[epoch9, step1061]: loss 0.132751
[epoch9, step1062]: loss 0.133168
[epoch9, step1063]: loss 0.125547
[epoch9, step1064]: loss 0.134362
[epoch9, step1065]: loss 0.123520
[epoch9, step1066]: loss 0.140068
[epoch9, step1067]: loss 0.128855
[epoch9, step1068]: loss 0.121294
[epoch9, step1069]: loss 0.127576
[epoch9, step1070]: loss 0.130097
[epoch9, step1071]: loss 0.132408
[epoch9, step1072]: loss 0.122819
[epoch9, step1073]: loss 0.134422
[epoch9, step1074]: loss 0.123418
[epoch9, step1075]: loss 0.137728
[epoch9, step1076]: loss 0.128240
[epoch9, step1077]: loss 0.115786
[epoch9, step1078]: loss 0.129744
[epoch9, step1079]: loss 0.127315
[epoch9, step1080]: loss 0.133171
[epoch9, step1081]: loss 0.126623
[epoch9, step1082]: loss 0.134413
[epoch9, step1083]: loss 0.120950
[epoch9, step1084]: loss 0.137816
[epoch9, step1085]: loss 0.130277
[epoch9, step1086]: loss 0.118099
[epoch9, step1087]: loss 0.129085
[epoch9, step1088]: loss 0.130777
[epoch9, step1089]: loss 0.132833
[epoch9, step1090]: loss 0.123307
[epoch9, step1091]: loss 0.133073
[epoch9, step1092]: loss 0.122482
[epoch9, step1093]: loss 0.138021
[epoch9, step1094]: loss 0.131463
[epoch9, step1095]: loss 0.116087
[epoch9, step1096]: loss 0.130385
[epoch9, step1097]: loss 0.129244
[epoch9, step1098]: loss 0.134309
[epoch9, step1099]: loss 0.125993
[epoch9, step1100]: loss 0.131889
[epoch9, step1101]: loss 0.122811
[epoch9, step1102]: loss 0.138997
[epoch9, step1103]: loss 0.129941
[epoch9, step1104]: loss 0.116027
[epoch9, step1105]: loss 0.127403
[epoch9, step1106]: loss 0.132311
[epoch9, step1107]: loss 0.133476
[epoch9, step1108]: loss 0.125873
[epoch9, step1109]: loss 0.132090
[epoch9, step1110]: loss 0.119538
[epoch9, step1111]: loss 0.137565
[epoch9, step1112]: loss 0.127227
[epoch9, step1113]: loss 0.116095
[epoch9, step1114]: loss 0.127779
[epoch9, step1115]: loss 0.128551
[epoch9, step1116]: loss 0.133114
[epoch9, step1117]: loss 0.124063
[epoch9, step1118]: loss 0.133795
[epoch9, step1119]: loss 0.123745
[epoch9, step1120]: loss 0.138699
[epoch9, step1121]: loss 0.128424
[epoch9, step1122]: loss 0.116383
[epoch9, step1123]: loss 0.129872
[epoch9, step1124]: loss 0.127735
[epoch9, step1125]: loss 0.132400
[epoch9, step1126]: loss 0.122157
[epoch9, step1127]: loss 0.132805
[epoch9, step1128]: loss 0.121852
[epoch9, step1129]: loss 0.138304
[epoch9, step1130]: loss 0.125133
[epoch9, step1131]: loss 0.114461
[epoch9, step1132]: loss 0.126918
[epoch9, step1133]: loss 0.130664
[epoch9, step1134]: loss 0.133796
[epoch9, step1135]: loss 0.120660
[epoch9, step1136]: loss 0.130949
[epoch9, step1137]: loss 0.119617
[epoch9, step1138]: loss 0.136791
[epoch9, step1139]: loss 0.128603
[epoch9, step1140]: loss 0.115337
[epoch9, step1141]: loss 0.126853
[epoch9, step1142]: loss 0.130356
[epoch9, step1143]: loss 0.134542
[epoch9, step1144]: loss 0.124574
[epoch9, step1145]: loss 0.134432
[epoch9, step1146]: loss 0.120249
[epoch9, step1147]: loss 0.134647
[epoch9, step1148]: loss 0.128070
[epoch9, step1149]: loss 0.114889
[epoch9, step1150]: loss 0.128962
[epoch9, step1151]: loss 0.128748
[epoch9, step1152]: loss 0.130936
[epoch9, step1153]: loss 0.125156
[epoch9, step1154]: loss 0.131649
[epoch9, step1155]: loss 0.120345
[epoch9, step1156]: loss 0.139347
[epoch9, step1157]: loss 0.128971
[epoch9, step1158]: loss 0.113841
[epoch9, step1159]: loss 0.126558
[epoch9, step1160]: loss 0.126934
[epoch9, step1161]: loss 0.131085
[epoch9, step1162]: loss 0.124175
[epoch9, step1163]: loss 0.134552
[epoch9, step1164]: loss 0.119774
[epoch9, step1165]: loss 0.133677
[epoch9, step1166]: loss 0.126703
[epoch9, step1167]: loss 0.115634
[epoch9, step1168]: loss 0.126820
[epoch9, step1169]: loss 0.129398
[epoch9, step1170]: loss 0.132577
[epoch9, step1171]: loss 0.124153
[epoch9, step1172]: loss 0.132812
[epoch9, step1173]: loss 0.120810
[epoch9, step1174]: loss 0.135522
[epoch9, step1175]: loss 0.128220
[epoch9, step1176]: loss 0.115314
[epoch9, step1177]: loss 0.125457
[epoch9, step1178]: loss 0.127576
[epoch9, step1179]: loss 0.132725
[epoch9, step1180]: loss 0.123006
[epoch9, step1181]: loss 0.130675
[epoch9, step1182]: loss 0.121281
[epoch9, step1183]: loss 0.134751
[epoch9, step1184]: loss 0.129175
[epoch9, step1185]: loss 0.115894
[epoch9, step1186]: loss 0.127703
[epoch9, step1187]: loss 0.131100
[epoch9, step1188]: loss 0.133569
[epoch9, step1189]: loss 0.123414
[epoch9, step1190]: loss 0.133300
[epoch9, step1191]: loss 0.120134
[epoch9, step1192]: loss 0.135392
[epoch9, step1193]: loss 0.126889
[epoch9, step1194]: loss 0.114745
[epoch9, step1195]: loss 0.130692
[epoch9, step1196]: loss 0.130252
[epoch9, step1197]: loss 0.131627
[epoch9, step1198]: loss 0.122589
[epoch9, step1199]: loss 0.132847
[epoch9, step1200]: loss 0.120017
[epoch9, step1201]: loss 0.134807
[epoch9, step1202]: loss 0.124358
[epoch9, step1203]: loss 0.116403
[epoch9, step1204]: loss 0.127457
[epoch9, step1205]: loss 0.128631
[epoch9, step1206]: loss 0.133522
[epoch9, step1207]: loss 0.120930
[epoch9, step1208]: loss 0.130977
[epoch9, step1209]: loss 0.121085
[epoch9, step1210]: loss 0.134436
[epoch9, step1211]: loss 0.128602
[epoch9, step1212]: loss 0.116004
[epoch9, step1213]: loss 0.128550
[epoch9, step1214]: loss 0.127685
[epoch9, step1215]: loss 0.129811
[epoch9, step1216]: loss 0.122811
[epoch9, step1217]: loss 0.129979
[epoch9, step1218]: loss 0.119532
[epoch9, step1219]: loss 0.134162
[epoch9, step1220]: loss 0.125469
[epoch9, step1221]: loss 0.115329
[epoch9, step1222]: loss 0.126217
[epoch9, step1223]: loss 0.127686
[epoch9, step1224]: loss 0.129918
[epoch9, step1225]: loss 0.122563
[epoch9, step1226]: loss 0.132825
[epoch9, step1227]: loss 0.118155
[epoch9, step1228]: loss 0.136500
[epoch9, step1229]: loss 0.128328
[epoch9, step1230]: loss 0.115628
[epoch9, step1231]: loss 0.127521
[epoch9, step1232]: loss 0.125451
[epoch9, step1233]: loss 0.131879
[epoch9, step1234]: loss 0.123000
[epoch9, step1235]: loss 0.130100
[epoch9, step1236]: loss 0.121164
[epoch9, step1237]: loss 0.137002
[epoch9, step1238]: loss 0.128348
[epoch9, step1239]: loss 0.112647
[epoch9, step1240]: loss 0.124838
[epoch9, step1241]: loss 0.130105
[epoch9, step1242]: loss 0.131764
[epoch9, step1243]: loss 0.121505
[epoch9, step1244]: loss 0.130549
[epoch9, step1245]: loss 0.117308
[epoch9, step1246]: loss 0.134755
[epoch9, step1247]: loss 0.129076
[epoch9, step1248]: loss 0.114364
[epoch9, step1249]: loss 0.124443
[epoch9, step1250]: loss 0.127674
[epoch9, step1251]: loss 0.130680
[epoch9, step1252]: loss 0.121496
[epoch9, step1253]: loss 0.130126
[epoch9, step1254]: loss 0.119060
[epoch9, step1255]: loss 0.135094
[epoch9, step1256]: loss 0.124848
[epoch9, step1257]: loss 0.113148
[epoch9, step1258]: loss 0.126002
[epoch9, step1259]: loss 0.128089
[epoch9, step1260]: loss 0.130830
[epoch9, step1261]: loss 0.122851
[epoch9, step1262]: loss 0.133987
[epoch9, step1263]: loss 0.116686
[epoch9, step1264]: loss 0.135857
[epoch9, step1265]: loss 0.130221
[epoch9, step1266]: loss 0.114852
[epoch9, step1267]: loss 0.125776
[epoch9, step1268]: loss 0.126932
[epoch9, step1269]: loss 0.130320
[epoch9, step1270]: loss 0.123814
[epoch9, step1271]: loss 0.129562
[epoch9, step1272]: loss 0.118552
[epoch9, step1273]: loss 0.136094
[epoch9, step1274]: loss 0.127431
[epoch9, step1275]: loss 0.113919
[epoch9, step1276]: loss 0.125743
[epoch9, step1277]: loss 0.127273
[epoch9, step1278]: loss 0.128883
[epoch9, step1279]: loss 0.121184
[epoch9, step1280]: loss 0.130132
[epoch9, step1281]: loss 0.119128
[epoch9, step1282]: loss 0.134657
[epoch9, step1283]: loss 0.127537
[epoch9, step1284]: loss 0.112728
[epoch9, step1285]: loss 0.125181
[epoch9, step1286]: loss 0.128411
[epoch9, step1287]: loss 0.128154
[epoch9, step1288]: loss 0.119933
[epoch9, step1289]: loss 0.127822
[epoch9, step1290]: loss 0.119795
[epoch9, step1291]: loss 0.135304
[epoch9, step1292]: loss 0.123491
[epoch9, step1293]: loss 0.113868
[epoch9, step1294]: loss 0.124712
[epoch9, step1295]: loss 0.125054
[epoch9, step1296]: loss 0.129546
[epoch9, step1297]: loss 0.120326
[epoch9, step1298]: loss 0.128550
[epoch9, step1299]: loss 0.118979
[epoch9, step1300]: loss 0.133070
[epoch9, step1301]: loss 0.128756
[epoch9, step1302]: loss 0.113264
[epoch9, step1303]: loss 0.126152
[epoch9, step1304]: loss 0.128224
[epoch9, step1305]: loss 0.128550
[epoch9, step1306]: loss 0.121738
[epoch9, step1307]: loss 0.131797
[epoch9, step1308]: loss 0.119247
[epoch9, step1309]: loss 0.136255
[epoch9, step1310]: loss 0.125730
[epoch9, step1311]: loss 0.114890
[epoch9, step1312]: loss 0.124754
[epoch9, step1313]: loss 0.126451
[epoch9, step1314]: loss 0.130835
[epoch9, step1315]: loss 0.121444
[epoch9, step1316]: loss 0.126062
[epoch9, step1317]: loss 0.119819
[epoch9, step1318]: loss 0.136125
[epoch9, step1319]: loss 0.126343
[epoch9, step1320]: loss 0.113224
[epoch9, step1321]: loss 0.122901
[epoch9, step1322]: loss 0.127640
[epoch9, step1323]: loss 0.128659
[epoch9, step1324]: loss 0.122046
[epoch9, step1325]: loss 0.130025
[epoch9, step1326]: loss 0.120101
[epoch9, step1327]: loss 0.134085
[epoch9, step1328]: loss 0.125291
[epoch9, step1329]: loss 0.113561
[epoch9, step1330]: loss 0.124373
[epoch9, step1331]: loss 0.127421
[epoch9, step1332]: loss 0.130595
[epoch9, step1333]: loss 0.124489
[epoch9, step1334]: loss 0.128542
[epoch9, step1335]: loss 0.118147
[epoch9, step1336]: loss 0.133558
[epoch9, step1337]: loss 0.127695
[epoch9, step1338]: loss 0.112647
[epoch9, step1339]: loss 0.125737
[epoch9, step1340]: loss 0.127909
[epoch9, step1341]: loss 0.129630
[epoch9, step1342]: loss 0.121017
[epoch9, step1343]: loss 0.128753
[epoch9, step1344]: loss 0.116854
[epoch9, step1345]: loss 0.133345
[epoch9, step1346]: loss 0.126144
[epoch9, step1347]: loss 0.111512
[epoch9, step1348]: loss 0.125876
[epoch9, step1349]: loss 0.125978
[epoch9, step1350]: loss 0.128488
[epoch9, step1351]: loss 0.123502
[epoch9, step1352]: loss 0.130628
[epoch9, step1353]: loss 0.120025
[epoch9, step1354]: loss 0.134920
[epoch9, step1355]: loss 0.125001
[epoch9, step1356]: loss 0.115467
[epoch9, step1357]: loss 0.126428
[epoch9, step1358]: loss 0.126120
[epoch9, step1359]: loss 0.130275
[epoch9, step1360]: loss 0.119328
[epoch9, step1361]: loss 0.128438
[epoch9, step1362]: loss 0.117425
[epoch9, step1363]: loss 0.131479
[epoch9, step1364]: loss 0.124888
[epoch9, step1365]: loss 0.113195
[epoch9, step1366]: loss 0.124396
[epoch9, step1367]: loss 0.127486
[epoch9, step1368]: loss 0.125889
[epoch9, step1369]: loss 0.121150
[epoch9, step1370]: loss 0.129944
[epoch9, step1371]: loss 0.117081
[epoch9, step1372]: loss 0.133214
[epoch9, step1373]: loss 0.124890
[epoch9, step1374]: loss 0.110584
[epoch9, step1375]: loss 0.122736
[epoch9, step1376]: loss 0.125749
[epoch9, step1377]: loss 0.131718
[epoch9, step1378]: loss 0.120818
[epoch9, step1379]: loss 0.130215
[epoch9, step1380]: loss 0.115268
[epoch9, step1381]: loss 0.132818
[epoch9, step1382]: loss 0.124246
[epoch9, step1383]: loss 0.112249
[epoch9, step1384]: loss 0.123185
[epoch9, step1385]: loss 0.126551
[epoch9, step1386]: loss 0.128130
[epoch9, step1387]: loss 0.118352
[epoch9, step1388]: loss 0.131756
[epoch9, step1389]: loss 0.118503
[epoch9, step1390]: loss 0.132360
[epoch9, step1391]: loss 0.124827
[epoch9, step1392]: loss 0.113213
[epoch9, step1393]: loss 0.122489
[epoch9, step1394]: loss 0.123490
[epoch9, step1395]: loss 0.128218
[epoch9, step1396]: loss 0.120165
[epoch9, step1397]: loss 0.129312
[epoch9, step1398]: loss 0.116727
[epoch9, step1399]: loss 0.129762
[epoch9, step1400]: loss 0.124028
[epoch9, step1401]: loss 0.111169
[epoch9, step1402]: loss 0.123479
[epoch9, step1403]: loss 0.127692
[epoch9, step1404]: loss 0.129625
[epoch9, step1405]: loss 0.118687
[epoch9, step1406]: loss 0.129457
[epoch9, step1407]: loss 0.114763
[epoch9, step1408]: loss 0.134391
[epoch9, step1409]: loss 0.125531
[epoch9, step1410]: loss 0.110778
[epoch9, step1411]: loss 0.126622
[epoch9, step1412]: loss 0.125051
[epoch9, step1413]: loss 0.128369
[epoch9, step1414]: loss 0.120949
[epoch9, step1415]: loss 0.129191
[epoch9, step1416]: loss 0.115881
[epoch9, step1417]: loss 0.133017
[epoch9, step1418]: loss 0.124516
[epoch9, step1419]: loss 0.110303
[epoch9, step1420]: loss 0.123692
[epoch9, step1421]: loss 0.123738
[epoch9, step1422]: loss 0.127104
[epoch9, step1423]: loss 0.120656
[epoch9, step1424]: loss 0.128156
[epoch9, step1425]: loss 0.118103
[epoch9, step1426]: loss 0.132341
[epoch9, step1427]: loss 0.121722
[epoch9, step1428]: loss 0.112231
[epoch9, step1429]: loss 0.122547
[epoch9, step1430]: loss 0.125568
[epoch9, step1431]: loss 0.127892
[epoch9, step1432]: loss 0.120188
[epoch9, step1433]: loss 0.127970
[epoch9, step1434]: loss 0.120056
[epoch9, step1435]: loss 0.130752
[epoch9, step1436]: loss 0.122918
[epoch9, step1437]: loss 0.110418
[epoch9, step1438]: loss 0.122608
[epoch9, step1439]: loss 0.125741
[epoch9, step1440]: loss 0.128575
[epoch9, step1441]: loss 0.117872
[epoch9, step1442]: loss 0.130343
[epoch9, step1443]: loss 0.119617
[epoch9, step1444]: loss 0.133823
[epoch9, step1445]: loss 0.122850
[epoch9, step1446]: loss 0.110106
[epoch9, step1447]: loss 0.121856
[epoch9, step1448]: loss 0.125002
[epoch9, step1449]: loss 0.129009
[epoch9, step1450]: loss 0.119723
[epoch9, step1451]: loss 0.126948
[epoch9, step1452]: loss 0.117537
[epoch9, step1453]: loss 0.129077
[epoch9, step1454]: loss 0.122359
[epoch9, step1455]: loss 0.109077
[epoch9, step1456]: loss 0.123923
[epoch9, step1457]: loss 0.122477
[epoch9, step1458]: loss 0.127395
[epoch9, step1459]: loss 0.120664
[epoch9, step1460]: loss 0.126462
[epoch9, step1461]: loss 0.114387
[epoch9, step1462]: loss 0.129335
[epoch9, step1463]: loss 0.124253
[epoch9, step1464]: loss 0.109562
[epoch9, step1465]: loss 0.124567
[epoch9, step1466]: loss 0.124811
[epoch9, step1467]: loss 0.128804
[epoch9, step1468]: loss 0.119902
[epoch9, step1469]: loss 0.127966
[epoch9, step1470]: loss 0.115642
[epoch9, step1471]: loss 0.133099
[epoch9, step1472]: loss 0.124176
[epoch9, step1473]: loss 0.110145
[epoch9, step1474]: loss 0.120932
[epoch9, step1475]: loss 0.124870
[epoch9, step1476]: loss 0.125732
[epoch9, step1477]: loss 0.120710
[epoch9, step1478]: loss 0.127440
[epoch9, step1479]: loss 0.115973
[epoch9, step1480]: loss 0.131306
[epoch9, step1481]: loss 0.126289
[epoch9, step1482]: loss 0.111325
[epoch9, step1483]: loss 0.122801
[epoch9, step1484]: loss 0.123463
[epoch9, step1485]: loss 0.127281
[epoch9, step1486]: loss 0.121413
[epoch9, step1487]: loss 0.127672
[epoch9, step1488]: loss 0.115686
[epoch9, step1489]: loss 0.131653
[epoch9, step1490]: loss 0.122533
[epoch9, step1491]: loss 0.111698
[epoch9, step1492]: loss 0.123918
[epoch9, step1493]: loss 0.124425
[epoch9, step1494]: loss 0.127117
[epoch9, step1495]: loss 0.120957
[epoch9, step1496]: loss 0.129575
[epoch9, step1497]: loss 0.115153
[epoch9, step1498]: loss 0.129609
[epoch9, step1499]: loss 0.124714
[epoch9, step1500]: loss 0.110367
[epoch9, step1501]: loss 0.122353
[epoch9, step1502]: loss 0.124096
[epoch9, step1503]: loss 0.127836
[epoch9, step1504]: loss 0.120621
[epoch9, step1505]: loss 0.126545
[epoch9, step1506]: loss 0.116365
[epoch9, step1507]: loss 0.129898
[epoch9, step1508]: loss 0.121800
[epoch9, step1509]: loss 0.111990
[epoch9, step1510]: loss 0.125542
[epoch9, step1511]: loss 0.121783
[epoch9, step1512]: loss 0.126054
[epoch9, step1513]: loss 0.122094
[epoch9, step1514]: loss 0.127200
[epoch9, step1515]: loss 0.115724
[epoch9, step1516]: loss 0.130647

[epoch9]: avg loss 0.130285

[epoch10, step1]: loss 0.119803
[epoch10, step2]: loss 0.125751
[epoch10, step3]: loss 0.126526
[epoch10, step4]: loss 0.118958
[epoch10, step5]: loss 0.130808
[epoch10, step6]: loss 0.123320
[epoch10, step7]: loss 0.112938
[epoch10, step8]: loss 0.127448
[epoch10, step9]: loss 0.115216
[epoch10, step10]: loss 0.127623
[epoch10, step11]: loss 0.125359
[epoch10, step12]: loss 0.125886
[epoch10, step13]: loss 0.114673
[epoch10, step14]: loss 0.130668
[epoch10, step15]: loss 0.123374
[epoch10, step16]: loss 0.113365
[epoch10, step17]: loss 0.126263
[epoch10, step18]: loss 0.112312
[epoch10, step19]: loss 0.129111
[epoch10, step20]: loss 0.122565
[epoch10, step21]: loss 0.126199
[epoch10, step22]: loss 0.117105
[epoch10, step23]: loss 0.133919
[epoch10, step24]: loss 0.122058
[epoch10, step25]: loss 0.113291
[epoch10, step26]: loss 0.129234
[epoch10, step27]: loss 0.114940
[epoch10, step28]: loss 0.128417
[epoch10, step29]: loss 0.124102
[epoch10, step30]: loss 0.123592
[epoch10, step31]: loss 0.116147
[epoch10, step32]: loss 0.129630
[epoch10, step33]: loss 0.120953
[epoch10, step34]: loss 0.112209
[epoch10, step35]: loss 0.126199
[epoch10, step36]: loss 0.114838
[epoch10, step37]: loss 0.129021
[epoch10, step38]: loss 0.125030
[epoch10, step39]: loss 0.125496
[epoch10, step40]: loss 0.113974
[epoch10, step41]: loss 0.132512
[epoch10, step42]: loss 0.121273
[epoch10, step43]: loss 0.114137
[epoch10, step44]: loss 0.126481
[epoch10, step45]: loss 0.114655
[epoch10, step46]: loss 0.128906
[epoch10, step47]: loss 0.125809
[epoch10, step48]: loss 0.126209
[epoch10, step49]: loss 0.117191
[epoch10, step50]: loss 0.130602
[epoch10, step51]: loss 0.122405
[epoch10, step52]: loss 0.114341
[epoch10, step53]: loss 0.125063
[epoch10, step54]: loss 0.113381
[epoch10, step55]: loss 0.127381
[epoch10, step56]: loss 0.121131
[epoch10, step57]: loss 0.123923
[epoch10, step58]: loss 0.114611
[epoch10, step59]: loss 0.133488
[epoch10, step60]: loss 0.120081
[epoch10, step61]: loss 0.114487
[epoch10, step62]: loss 0.128166
[epoch10, step63]: loss 0.115850
[epoch10, step64]: loss 0.130729
[epoch10, step65]: loss 0.123399
[epoch10, step66]: loss 0.124992
[epoch10, step67]: loss 0.115853
[epoch10, step68]: loss 0.130805
[epoch10, step69]: loss 0.122029
[epoch10, step70]: loss 0.113968
[epoch10, step71]: loss 0.127823
[epoch10, step72]: loss 0.113535
[epoch10, step73]: loss 0.129015
[epoch10, step74]: loss 0.123339
[epoch10, step75]: loss 0.124178
[epoch10, step76]: loss 0.115147
[epoch10, step77]: loss 0.128471
[epoch10, step78]: loss 0.121114
[epoch10, step79]: loss 0.114411
[epoch10, step80]: loss 0.124100
[epoch10, step81]: loss 0.113003
[epoch10, step82]: loss 0.130070
[epoch10, step83]: loss 0.126032
[epoch10, step84]: loss 0.124214
[epoch10, step85]: loss 0.112893
[epoch10, step86]: loss 0.129051
[epoch10, step87]: loss 0.119168
[epoch10, step88]: loss 0.118318
[epoch10, step89]: loss 0.127626
[epoch10, step90]: loss 0.114413
[epoch10, step91]: loss 0.131339
[epoch10, step92]: loss 0.123125
[epoch10, step93]: loss 0.123931
[epoch10, step94]: loss 0.115974
[epoch10, step95]: loss 0.128629
[epoch10, step96]: loss 0.122175
[epoch10, step97]: loss 0.111842
[epoch10, step98]: loss 0.126254
[epoch10, step99]: loss 0.113906
[epoch10, step100]: loss 0.131063
[epoch10, step101]: loss 0.121459
[epoch10, step102]: loss 0.124795
[epoch10, step103]: loss 0.115436
[epoch10, step104]: loss 0.129908
[epoch10, step105]: loss 0.120042
[epoch10, step106]: loss 0.113583
[epoch10, step107]: loss 0.126386
[epoch10, step108]: loss 0.113128
[epoch10, step109]: loss 0.129003
[epoch10, step110]: loss 0.121517
[epoch10, step111]: loss 0.124729
[epoch10, step112]: loss 0.115806
[epoch10, step113]: loss 0.127260
[epoch10, step114]: loss 0.121893
[epoch10, step115]: loss 0.113237
[epoch10, step116]: loss 0.123818
[epoch10, step117]: loss 0.112718
[epoch10, step118]: loss 0.125803
[epoch10, step119]: loss 0.121843
[epoch10, step120]: loss 0.123144
[epoch10, step121]: loss 0.115249
[epoch10, step122]: loss 0.129390
[epoch10, step123]: loss 0.119825
[epoch10, step124]: loss 0.113055
[epoch10, step125]: loss 0.124358
[epoch10, step126]: loss 0.113771
[epoch10, step127]: loss 0.128559
[epoch10, step128]: loss 0.123215
[epoch10, step129]: loss 0.123609
[epoch10, step130]: loss 0.112801
[epoch10, step131]: loss 0.130857
[epoch10, step132]: loss 0.120346
[epoch10, step133]: loss 0.111816
[epoch10, step134]: loss 0.127483
[epoch10, step135]: loss 0.111741
[epoch10, step136]: loss 0.124318
[epoch10, step137]: loss 0.123563
[epoch10, step138]: loss 0.123807
[epoch10, step139]: loss 0.114233
[epoch10, step140]: loss 0.127720
[epoch10, step141]: loss 0.119865
[epoch10, step142]: loss 0.112447
[epoch10, step143]: loss 0.126614
[epoch10, step144]: loss 0.114431
[epoch10, step145]: loss 0.127782
[epoch10, step146]: loss 0.122694
[epoch10, step147]: loss 0.120235
[epoch10, step148]: loss 0.113848
[epoch10, step149]: loss 0.130535
[epoch10, step150]: loss 0.121512
[epoch10, step151]: loss 0.110576
[epoch10, step152]: loss 0.125274
[epoch10, step153]: loss 0.111668
[epoch10, step154]: loss 0.129070
[epoch10, step155]: loss 0.122260
[epoch10, step156]: loss 0.124778
[epoch10, step157]: loss 0.112907
[epoch10, step158]: loss 0.127724
[epoch10, step159]: loss 0.119688
[epoch10, step160]: loss 0.111259
[epoch10, step161]: loss 0.123361
[epoch10, step162]: loss 0.111800
[epoch10, step163]: loss 0.127700
[epoch10, step164]: loss 0.120974
[epoch10, step165]: loss 0.123169
[epoch10, step166]: loss 0.111753
[epoch10, step167]: loss 0.129840
[epoch10, step168]: loss 0.117978
[epoch10, step169]: loss 0.113020
[epoch10, step170]: loss 0.124037
[epoch10, step171]: loss 0.112069
[epoch10, step172]: loss 0.126960
[epoch10, step173]: loss 0.121227
[epoch10, step174]: loss 0.123825
[epoch10, step175]: loss 0.110889
[epoch10, step176]: loss 0.128035
[epoch10, step177]: loss 0.119058
[epoch10, step178]: loss 0.109643
[epoch10, step179]: loss 0.126870
[epoch10, step180]: loss 0.110489
[epoch10, step181]: loss 0.126210
[epoch10, step182]: loss 0.120746
[epoch10, step183]: loss 0.121161
[epoch10, step184]: loss 0.110932
[epoch10, step185]: loss 0.127697
[epoch10, step186]: loss 0.118631
[epoch10, step187]: loss 0.112325
[epoch10, step188]: loss 0.125247
[epoch10, step189]: loss 0.111136
[epoch10, step190]: loss 0.128628
[epoch10, step191]: loss 0.122062
[epoch10, step192]: loss 0.121093
[epoch10, step193]: loss 0.117627
[epoch10, step194]: loss 0.130176
[epoch10, step195]: loss 0.118613
[epoch10, step196]: loss 0.110125
[epoch10, step197]: loss 0.124861
[epoch10, step198]: loss 0.113115
[epoch10, step199]: loss 0.126306
[epoch10, step200]: loss 0.119628
[epoch10, step201]: loss 0.121035
[epoch10, step202]: loss 0.113443
[epoch10, step203]: loss 0.127915
[epoch10, step204]: loss 0.118074
[epoch10, step205]: loss 0.113286
[epoch10, step206]: loss 0.125141
[epoch10, step207]: loss 0.111369
[epoch10, step208]: loss 0.125072
[epoch10, step209]: loss 0.120170
[epoch10, step210]: loss 0.119941
[epoch10, step211]: loss 0.112631
[epoch10, step212]: loss 0.126998
[epoch10, step213]: loss 0.119842
[epoch10, step214]: loss 0.113952
[epoch10, step215]: loss 0.123547
[epoch10, step216]: loss 0.110882
[epoch10, step217]: loss 0.128545
[epoch10, step218]: loss 0.119945
[epoch10, step219]: loss 0.122790
[epoch10, step220]: loss 0.114236
[epoch10, step221]: loss 0.126870
[epoch10, step222]: loss 0.117715
[epoch10, step223]: loss 0.108939
[epoch10, step224]: loss 0.124832
[epoch10, step225]: loss 0.110788
[epoch10, step226]: loss 0.127277
[epoch10, step227]: loss 0.123413
[epoch10, step228]: loss 0.120529
[epoch10, step229]: loss 0.114831
[epoch10, step230]: loss 0.126297
[epoch10, step231]: loss 0.117487
[epoch10, step232]: loss 0.111234
[epoch10, step233]: loss 0.125994
[epoch10, step234]: loss 0.112435
[epoch10, step235]: loss 0.126358
[epoch10, step236]: loss 0.120446
[epoch10, step237]: loss 0.121912
[epoch10, step238]: loss 0.111839
[epoch10, step239]: loss 0.129048
[epoch10, step240]: loss 0.121134
[epoch10, step241]: loss 0.110509
[epoch10, step242]: loss 0.124325
[epoch10, step243]: loss 0.110426
[epoch10, step244]: loss 0.126650
[epoch10, step245]: loss 0.121856
[epoch10, step246]: loss 0.121930
[epoch10, step247]: loss 0.112762
[epoch10, step248]: loss 0.128144
[epoch10, step249]: loss 0.119826
[epoch10, step250]: loss 0.109900
[epoch10, step251]: loss 0.122198
[epoch10, step252]: loss 0.109804
[epoch10, step253]: loss 0.127466
[epoch10, step254]: loss 0.122519
[epoch10, step255]: loss 0.120989
[epoch10, step256]: loss 0.114038
[epoch10, step257]: loss 0.127647
[epoch10, step258]: loss 0.117096
[epoch10, step259]: loss 0.109089
[epoch10, step260]: loss 0.125149
[epoch10, step261]: loss 0.108245
[epoch10, step262]: loss 0.124486
[epoch10, step263]: loss 0.122489
[epoch10, step264]: loss 0.122133
[epoch10, step265]: loss 0.112688
[epoch10, step266]: loss 0.127163
[epoch10, step267]: loss 0.120646
[epoch10, step268]: loss 0.110575
[epoch10, step269]: loss 0.123132
[epoch10, step270]: loss 0.111360
[epoch10, step271]: loss 0.125132
[epoch10, step272]: loss 0.120538
[epoch10, step273]: loss 0.122125
[epoch10, step274]: loss 0.110334
[epoch10, step275]: loss 0.128566
[epoch10, step276]: loss 0.119734
[epoch10, step277]: loss 0.109848
[epoch10, step278]: loss 0.122818
[epoch10, step279]: loss 0.110048
[epoch10, step280]: loss 0.125173
[epoch10, step281]: loss 0.120821
[epoch10, step282]: loss 0.119790
[epoch10, step283]: loss 0.113266
[epoch10, step284]: loss 0.127861
[epoch10, step285]: loss 0.116241
[epoch10, step286]: loss 0.114946
[epoch10, step287]: loss 0.122703
[epoch10, step288]: loss 0.111637
[epoch10, step289]: loss 0.124250
[epoch10, step290]: loss 0.120225
[epoch10, step291]: loss 0.120349
[epoch10, step292]: loss 0.113900
[epoch10, step293]: loss 0.127187
[epoch10, step294]: loss 0.119198
[epoch10, step295]: loss 0.110783
[epoch10, step296]: loss 0.121133
[epoch10, step297]: loss 0.111681
[epoch10, step298]: loss 0.124933
[epoch10, step299]: loss 0.122341
[epoch10, step300]: loss 0.120064
[epoch10, step301]: loss 0.113476
[epoch10, step302]: loss 0.125372
[epoch10, step303]: loss 0.116926
[epoch10, step304]: loss 0.109247
[epoch10, step305]: loss 0.123958
[epoch10, step306]: loss 0.110219
[epoch10, step307]: loss 0.126503
[epoch10, step308]: loss 0.118556
[epoch10, step309]: loss 0.119558
[epoch10, step310]: loss 0.112215
[epoch10, step311]: loss 0.124994
[epoch10, step312]: loss 0.118488
[epoch10, step313]: loss 0.110470
[epoch10, step314]: loss 0.122626
[epoch10, step315]: loss 0.109451
[epoch10, step316]: loss 0.125886
[epoch10, step317]: loss 0.119304
[epoch10, step318]: loss 0.120550
[epoch10, step319]: loss 0.113507
[epoch10, step320]: loss 0.128767
[epoch10, step321]: loss 0.118783
[epoch10, step322]: loss 0.112518
[epoch10, step323]: loss 0.124501
[epoch10, step324]: loss 0.108998
[epoch10, step325]: loss 0.124702
[epoch10, step326]: loss 0.120365
[epoch10, step327]: loss 0.122381
[epoch10, step328]: loss 0.112173
[epoch10, step329]: loss 0.127065
[epoch10, step330]: loss 0.119549
[epoch10, step331]: loss 0.110730
[epoch10, step332]: loss 0.124113
[epoch10, step333]: loss 0.110908
[epoch10, step334]: loss 0.124359
[epoch10, step335]: loss 0.119435
[epoch10, step336]: loss 0.118427
[epoch10, step337]: loss 0.109903
[epoch10, step338]: loss 0.127453
[epoch10, step339]: loss 0.118435
[epoch10, step340]: loss 0.110215
[epoch10, step341]: loss 0.123630
[epoch10, step342]: loss 0.109876
[epoch10, step343]: loss 0.123832
[epoch10, step344]: loss 0.120158
[epoch10, step345]: loss 0.122190
[epoch10, step346]: loss 0.112879
[epoch10, step347]: loss 0.126789
[epoch10, step348]: loss 0.116771
[epoch10, step349]: loss 0.108799
[epoch10, step350]: loss 0.123898
[epoch10, step351]: loss 0.110620
[epoch10, step352]: loss 0.124599
[epoch10, step353]: loss 0.119653
[epoch10, step354]: loss 0.123021
[epoch10, step355]: loss 0.113191
[epoch10, step356]: loss 0.124128
[epoch10, step357]: loss 0.117096
[epoch10, step358]: loss 0.113233
[epoch10, step359]: loss 0.120226
[epoch10, step360]: loss 0.110291
[epoch10, step361]: loss 0.125721
[epoch10, step362]: loss 0.117987
[epoch10, step363]: loss 0.121090
[epoch10, step364]: loss 0.111910
[epoch10, step365]: loss 0.126141
[epoch10, step366]: loss 0.116469
[epoch10, step367]: loss 0.110753
[epoch10, step368]: loss 0.123640
[epoch10, step369]: loss 0.110377
[epoch10, step370]: loss 0.122951
[epoch10, step371]: loss 0.116991
[epoch10, step372]: loss 0.121074
[epoch10, step373]: loss 0.111207
[epoch10, step374]: loss 0.127226
[epoch10, step375]: loss 0.115519
[epoch10, step376]: loss 0.107595
[epoch10, step377]: loss 0.121527
[epoch10, step378]: loss 0.109962
[epoch10, step379]: loss 0.122766
[epoch10, step380]: loss 0.117680
[epoch10, step381]: loss 0.120828
[epoch10, step382]: loss 0.113272
[epoch10, step383]: loss 0.128287
[epoch10, step384]: loss 0.118809
[epoch10, step385]: loss 0.107573
[epoch10, step386]: loss 0.121454
[epoch10, step387]: loss 0.108247
[epoch10, step388]: loss 0.121835
[epoch10, step389]: loss 0.118864
[epoch10, step390]: loss 0.117085
[epoch10, step391]: loss 0.110559
[epoch10, step392]: loss 0.123624
[epoch10, step393]: loss 0.118110
[epoch10, step394]: loss 0.110664
[epoch10, step395]: loss 0.122454
[epoch10, step396]: loss 0.109035
[epoch10, step397]: loss 0.125586
[epoch10, step398]: loss 0.118429
[epoch10, step399]: loss 0.119918
[epoch10, step400]: loss 0.110082
[epoch10, step401]: loss 0.125551
[epoch10, step402]: loss 0.117386
[epoch10, step403]: loss 0.108319
[epoch10, step404]: loss 0.121036
[epoch10, step405]: loss 0.107893
[epoch10, step406]: loss 0.122725
[epoch10, step407]: loss 0.119291
[epoch10, step408]: loss 0.119413
[epoch10, step409]: loss 0.106994
[epoch10, step410]: loss 0.123371
[epoch10, step411]: loss 0.116725
[epoch10, step412]: loss 0.108586
[epoch10, step413]: loss 0.121618
[epoch10, step414]: loss 0.110991
[epoch10, step415]: loss 0.123160
[epoch10, step416]: loss 0.119987
[epoch10, step417]: loss 0.118954
[epoch10, step418]: loss 0.109964
[epoch10, step419]: loss 0.126588
[epoch10, step420]: loss 0.115503
[epoch10, step421]: loss 0.109238
[epoch10, step422]: loss 0.121296
[epoch10, step423]: loss 0.108470
[epoch10, step424]: loss 0.122736
[epoch10, step425]: loss 0.117896
[epoch10, step426]: loss 0.118459
[epoch10, step427]: loss 0.111720
[epoch10, step428]: loss 0.124976
[epoch10, step429]: loss 0.114121
[epoch10, step430]: loss 0.108600
[epoch10, step431]: loss 0.120477
[epoch10, step432]: loss 0.108122
[epoch10, step433]: loss 0.121078
[epoch10, step434]: loss 0.118435
[epoch10, step435]: loss 0.118198
[epoch10, step436]: loss 0.112606
[epoch10, step437]: loss 0.123922
[epoch10, step438]: loss 0.114272
[epoch10, step439]: loss 0.109407
[epoch10, step440]: loss 0.120979
[epoch10, step441]: loss 0.107783
[epoch10, step442]: loss 0.122887
[epoch10, step443]: loss 0.116755
[epoch10, step444]: loss 0.120186
[epoch10, step445]: loss 0.110011
[epoch10, step446]: loss 0.123371
[epoch10, step447]: loss 0.114381
[epoch10, step448]: loss 0.107051
[epoch10, step449]: loss 0.121668
[epoch10, step450]: loss 0.110644
[epoch10, step451]: loss 0.123454
[epoch10, step452]: loss 0.120664
[epoch10, step453]: loss 0.118446
[epoch10, step454]: loss 0.111206
[epoch10, step455]: loss 0.123520
[epoch10, step456]: loss 0.117697
[epoch10, step457]: loss 0.107619
[epoch10, step458]: loss 0.121331
[epoch10, step459]: loss 0.106840
[epoch10, step460]: loss 0.122914
[epoch10, step461]: loss 0.116230
[epoch10, step462]: loss 0.120443
[epoch10, step463]: loss 0.110266
[epoch10, step464]: loss 0.124582
[epoch10, step465]: loss 0.112341
[epoch10, step466]: loss 0.107654
[epoch10, step467]: loss 0.121690
[epoch10, step468]: loss 0.108811
[epoch10, step469]: loss 0.122436
[epoch10, step470]: loss 0.117086
[epoch10, step471]: loss 0.119574
[epoch10, step472]: loss 0.110674
[epoch10, step473]: loss 0.125119
[epoch10, step474]: loss 0.116217
[epoch10, step475]: loss 0.108075
[epoch10, step476]: loss 0.119350
[epoch10, step477]: loss 0.108537
[epoch10, step478]: loss 0.123698
[epoch10, step479]: loss 0.117623
[epoch10, step480]: loss 0.120627
[epoch10, step481]: loss 0.110478
[epoch10, step482]: loss 0.125544
[epoch10, step483]: loss 0.114410
[epoch10, step484]: loss 0.105573
[epoch10, step485]: loss 0.120334
[epoch10, step486]: loss 0.107168
[epoch10, step487]: loss 0.123922
[epoch10, step488]: loss 0.116634
[epoch10, step489]: loss 0.120654
[epoch10, step490]: loss 0.110086
[epoch10, step491]: loss 0.122724
[epoch10, step492]: loss 0.115919
[epoch10, step493]: loss 0.107176
[epoch10, step494]: loss 0.121823
[epoch10, step495]: loss 0.104680
[epoch10, step496]: loss 0.122519
[epoch10, step497]: loss 0.116785
[epoch10, step498]: loss 0.118294
[epoch10, step499]: loss 0.110071
[epoch10, step500]: loss 0.124894
[epoch10, step501]: loss 0.116728
[epoch10, step502]: loss 0.107881
[epoch10, step503]: loss 0.120010
[epoch10, step504]: loss 0.110074
[epoch10, step505]: loss 0.124796
[epoch10, step506]: loss 0.115444
[epoch10, step507]: loss 0.117211
[epoch10, step508]: loss 0.109015
[epoch10, step509]: loss 0.124137
[epoch10, step510]: loss 0.115047
[epoch10, step511]: loss 0.108655
[epoch10, step512]: loss 0.119067
[epoch10, step513]: loss 0.107914
[epoch10, step514]: loss 0.121288
[epoch10, step515]: loss 0.117086
[epoch10, step516]: loss 0.116951
[epoch10, step517]: loss 0.110488
[epoch10, step518]: loss 0.123260
[epoch10, step519]: loss 0.114686
[epoch10, step520]: loss 0.106914
[epoch10, step521]: loss 0.121236
[epoch10, step522]: loss 0.108204
[epoch10, step523]: loss 0.122167
[epoch10, step524]: loss 0.118840
[epoch10, step525]: loss 0.116986
[epoch10, step526]: loss 0.107489
[epoch10, step527]: loss 0.124172
[epoch10, step528]: loss 0.113998
[epoch10, step529]: loss 0.108854
[epoch10, step530]: loss 0.119015
[epoch10, step531]: loss 0.107361
[epoch10, step532]: loss 0.122811
[epoch10, step533]: loss 0.114507
[epoch10, step534]: loss 0.118068
[epoch10, step535]: loss 0.109044
[epoch10, step536]: loss 0.122736
[epoch10, step537]: loss 0.114329
[epoch10, step538]: loss 0.109224
[epoch10, step539]: loss 0.120610
[epoch10, step540]: loss 0.110070
[epoch10, step541]: loss 0.122915
[epoch10, step542]: loss 0.116901
[epoch10, step543]: loss 0.117957
[epoch10, step544]: loss 0.107200
[epoch10, step545]: loss 0.125231
[epoch10, step546]: loss 0.113431
[epoch10, step547]: loss 0.109140
[epoch10, step548]: loss 0.120020
[epoch10, step549]: loss 0.107002
[epoch10, step550]: loss 0.121758
[epoch10, step551]: loss 0.116728
[epoch10, step552]: loss 0.118753
[epoch10, step553]: loss 0.109091
[epoch10, step554]: loss 0.123847
[epoch10, step555]: loss 0.115584
[epoch10, step556]: loss 0.106669
[epoch10, step557]: loss 0.121251
[epoch10, step558]: loss 0.106746
[epoch10, step559]: loss 0.122917
[epoch10, step560]: loss 0.116252
[epoch10, step561]: loss 0.118057
[epoch10, step562]: loss 0.107922
[epoch10, step563]: loss 0.135618
[epoch10, step564]: loss 0.108270
[epoch10, step565]: loss 0.088759
[epoch10, step566]: loss 0.097342
[epoch10, step567]: loss 0.091115
[epoch10, step568]: loss 0.099407
[epoch10, step569]: loss 0.115435
[epoch10, step570]: loss 0.103168
[epoch10, step571]: loss 0.075055
[epoch10, step572]: loss 0.098597
[epoch10, step573]: loss 0.104785
[epoch10, step574]: loss 0.123535
[epoch10, step575]: loss 0.105528
[epoch10, step576]: loss 0.108641
[epoch10, step577]: loss 0.095665
[epoch10, step578]: loss 0.108121
[epoch10, step579]: loss 0.091518
[epoch10, step580]: loss 0.122200
[epoch10, step581]: loss 0.109856
[epoch10, step582]: loss 0.106411
[epoch10, step583]: loss 0.107042
[epoch10, step584]: loss 0.102521
[epoch10, step585]: loss 0.119457
[epoch10, step586]: loss 0.105319
[epoch10, step587]: loss 0.080445
[epoch10, step588]: loss 0.106926
[epoch10, step589]: loss 0.135906
[epoch10, step590]: loss 0.084491
[epoch10, step591]: loss 0.102780
[epoch10, step592]: loss 0.114834
[epoch10, step593]: loss 0.133814
[epoch10, step594]: loss 0.085210
[epoch10, step595]: loss 0.086246
[epoch10, step596]: loss 0.114519
[epoch10, step597]: loss 0.119020
[epoch10, step598]: loss 0.092652
[epoch10, step599]: loss 0.085072
[epoch10, step600]: loss 0.084371
[epoch10, step601]: loss 0.103228
[epoch10, step602]: loss 0.122512
[epoch10, step603]: loss 0.094439
[epoch10, step604]: loss 0.093114
[epoch10, step605]: loss 0.083848
[epoch10, step606]: loss 0.102293
[epoch10, step607]: loss 0.111806
[epoch10, step608]: loss 0.074474
[epoch10, step609]: loss 0.106622
[epoch10, step610]: loss 0.095571
[epoch10, step611]: loss 0.115581
[epoch10, step612]: loss 0.106506
[epoch10, step613]: loss 0.113336
[epoch10, step614]: loss 0.103912
[epoch10, step615]: loss 0.106899
[epoch10, step616]: loss 0.086321
[epoch10, step617]: loss 0.097457
[epoch10, step618]: loss 0.113598
[epoch10, step619]: loss 0.089133
[epoch10, step620]: loss 0.082513
[epoch10, step621]: loss 0.080832
[epoch10, step622]: loss 0.108986
[epoch10, step623]: loss 0.106926
[epoch10, step624]: loss 0.107819
[epoch10, step625]: loss 0.081800
[epoch10, step626]: loss 0.108546
[epoch10, step627]: loss 0.121638
[epoch10, step628]: loss 0.112494
[epoch10, step629]: loss 0.065507
[epoch10, step630]: loss 0.090862
[epoch10, step631]: loss 0.093579
[epoch10, step632]: loss 0.106943
[epoch10, step633]: loss 0.089741
[epoch10, step634]: loss 0.103169
[epoch10, step635]: loss 0.097496
[epoch10, step636]: loss 0.085663
[epoch10, step637]: loss 0.114463
[epoch10, step638]: loss 0.106306
[epoch10, step639]: loss 0.083406
[epoch10, step640]: loss 0.110948
[epoch10, step641]: loss 0.088859
[epoch10, step642]: loss 0.084232
[epoch10, step643]: loss 0.110097
[epoch10, step644]: loss 0.097017
[epoch10, step645]: loss 0.076872
[epoch10, step646]: loss 0.100930
[epoch10, step647]: loss 0.079143
[epoch10, step648]: loss 0.121873
[epoch10, step649]: loss 0.107267
[epoch10, step650]: loss 0.110830
[epoch10, step651]: loss 0.096170
[epoch10, step652]: loss 0.118801
[epoch10, step653]: loss 0.115316
[epoch10, step654]: loss 0.109007
[epoch10, step655]: loss 0.086689
[epoch10, step656]: loss 0.114474
[epoch10, step657]: loss 0.115187
[epoch10, step658]: loss 0.091271
[epoch10, step659]: loss 0.080496
[epoch10, step660]: loss 0.100319
[epoch10, step661]: loss 0.107342
[epoch10, step662]: loss 0.080530
[epoch10, step663]: loss 0.096998
[epoch10, step664]: loss 0.095506
[epoch10, step665]: loss 0.119412
[epoch10, step666]: loss 0.083608
[epoch10, step667]: loss 0.106254
[epoch10, step668]: loss 0.118745
[epoch10, step669]: loss 0.084522
[epoch10, step670]: loss 0.103119
[epoch10, step671]: loss 0.104002
[epoch10, step672]: loss 0.124188
[epoch10, step673]: loss 0.114279
[epoch10, step674]: loss 0.095956
[epoch10, step675]: loss 0.110095
[epoch10, step676]: loss 0.108791
[epoch10, step677]: loss 0.093877
[epoch10, step678]: loss 0.082225
[epoch10, step679]: loss 0.099318
[epoch10, step680]: loss 0.085082
[epoch10, step681]: loss 0.083432
[epoch10, step682]: loss 0.087621
[epoch10, step683]: loss 0.101820
[epoch10, step684]: loss 0.085326
[epoch10, step685]: loss 0.086217
[epoch10, step686]: loss 0.084328
[epoch10, step687]: loss 0.091647
[epoch10, step688]: loss 0.107007
[epoch10, step689]: loss 0.085826
[epoch10, step690]: loss 0.111737
[epoch10, step691]: loss 0.115990
[epoch10, step692]: loss 0.110853
[epoch10, step693]: loss 0.103941
[epoch10, step694]: loss 0.080298
[epoch10, step695]: loss 0.093427
[epoch10, step696]: loss 0.086787
[epoch10, step697]: loss 0.103439
[epoch10, step698]: loss 0.093075
[epoch10, step699]: loss 0.095125
[epoch10, step700]: loss 0.121303
[epoch10, step701]: loss 0.107143
[epoch10, step702]: loss 0.092166
[epoch10, step703]: loss 0.119423
[epoch10, step704]: loss 0.111297
[epoch10, step705]: loss 0.086475
[epoch10, step706]: loss 0.089862
[epoch10, step707]: loss 0.092494
[epoch10, step708]: loss 0.100967
[epoch10, step709]: loss 0.090384
[epoch10, step710]: loss 0.102098
[epoch10, step711]: loss 0.111173
[epoch10, step712]: loss 0.081493
[epoch10, step713]: loss 0.091640
[epoch10, step714]: loss 0.104661
[epoch10, step715]: loss 0.089740
[epoch10, step716]: loss 0.103636
[epoch10, step717]: loss 0.087792
[epoch10, step718]: loss 0.097410
[epoch10, step719]: loss 0.102202
[epoch10, step720]: loss 0.086658
[epoch10, step721]: loss 0.094947
[epoch10, step722]: loss 0.103413
[epoch10, step723]: loss 0.097439
[epoch10, step724]: loss 0.103308
[epoch10, step725]: loss 0.104786
[epoch10, step726]: loss 0.075054
[epoch10, step727]: loss 0.102082
[epoch10, step728]: loss 0.103755
[epoch10, step729]: loss 0.083679
[epoch10, step730]: loss 0.102986
[epoch10, step731]: loss 0.111246
[epoch10, step732]: loss 0.094811
[epoch10, step733]: loss 0.078563
[epoch10, step734]: loss 0.088505
[epoch10, step735]: loss 0.089809
[epoch10, step736]: loss 0.093090
[epoch10, step737]: loss 0.083808
[epoch10, step738]: loss 0.088093
[epoch10, step739]: loss 0.121320
[epoch10, step740]: loss 0.126944
[epoch10, step741]: loss 0.100529
[epoch10, step742]: loss 0.112486
[epoch10, step743]: loss 0.097881
[epoch10, step744]: loss 0.096765
[epoch10, step745]: loss 0.097957
[epoch10, step746]: loss 0.104808
[epoch10, step747]: loss 0.095874
[epoch10, step748]: loss 0.087090
[epoch10, step749]: loss 0.122395
[epoch10, step750]: loss 0.105464
[epoch10, step751]: loss 0.091058
[epoch10, step752]: loss 0.084482
[epoch10, step753]: loss 0.086040
[epoch10, step754]: loss 0.111743
[epoch10, step755]: loss 0.103965
[epoch10, step756]: loss 0.078557
[epoch10, step757]: loss 0.096093
[epoch10, step758]: loss 0.106244
[epoch10, step759]: loss 0.085286
[epoch10, step760]: loss 0.102795
[epoch10, step761]: loss 0.094861
[epoch10, step762]: loss 0.087978
[epoch10, step763]: loss 0.090347
[epoch10, step764]: loss 0.100852
[epoch10, step765]: loss 0.088694
[epoch10, step766]: loss 0.083716
[epoch10, step767]: loss 0.105323
[epoch10, step768]: loss 0.096820
[epoch10, step769]: loss 0.099036
[epoch10, step770]: loss 0.118891
[epoch10, step771]: loss 0.083077
[epoch10, step772]: loss 0.086066
[epoch10, step773]: loss 0.094476
[epoch10, step774]: loss 0.096465
[epoch10, step775]: loss 0.115465
[epoch10, step776]: loss 0.102887
[epoch10, step777]: loss 0.090949
[epoch10, step778]: loss 0.110097
[epoch10, step779]: loss 0.093284
[epoch10, step780]: loss 0.103856
[epoch10, step781]: loss 0.118670
[epoch10, step782]: loss 0.111584
[epoch10, step783]: loss 0.096637
[epoch10, step784]: loss 0.109496
[epoch10, step785]: loss 0.107351
[epoch10, step786]: loss 0.096169
[epoch10, step787]: loss 0.116360
[epoch10, step788]: loss 0.099004
[epoch10, step789]: loss 0.111631
[epoch10, step790]: loss 0.082707
[epoch10, step791]: loss 0.104466
[epoch10, step792]: loss 0.104219
[epoch10, step793]: loss 0.105897
[epoch10, step794]: loss 0.097680
[epoch10, step795]: loss 0.096536
[epoch10, step796]: loss 0.093378
[epoch10, step797]: loss 0.086781
[epoch10, step798]: loss 0.087255
[epoch10, step799]: loss 0.075702
[epoch10, step800]: loss 0.120643
[epoch10, step801]: loss 0.113414
[epoch10, step802]: loss 0.094838
[epoch10, step803]: loss 0.089943
[epoch10, step804]: loss 0.104278
[epoch10, step805]: loss 0.093887
[epoch10, step806]: loss 0.097068
[epoch10, step807]: loss 0.106084
[epoch10, step808]: loss 0.115993
[epoch10, step809]: loss 0.089419
[epoch10, step810]: loss 0.078471
[epoch10, step811]: loss 0.098014
[epoch10, step812]: loss 0.104578
[epoch10, step813]: loss 0.089119
[epoch10, step814]: loss 0.100493
[epoch10, step815]: loss 0.095390
[epoch10, step816]: loss 0.096695
[epoch10, step817]: loss 0.085217
[epoch10, step818]: loss 0.091609
[epoch10, step819]: loss 0.133176
[epoch10, step820]: loss 0.086896
[epoch10, step821]: loss 0.085593
[epoch10, step822]: loss 0.101885
[epoch10, step823]: loss 0.084929
[epoch10, step824]: loss 0.098581
[epoch10, step825]: loss 0.101662
[epoch10, step826]: loss 0.073051
[epoch10, step827]: loss 0.088542
[epoch10, step828]: loss 0.097385
[epoch10, step829]: loss 0.090198
[epoch10, step830]: loss 0.070075
[epoch10, step831]: loss 0.085420
[epoch10, step832]: loss 0.116163
[epoch10, step833]: loss 0.100601
[epoch10, step834]: loss 0.096869
[epoch10, step835]: loss 0.098851
[epoch10, step836]: loss 0.087326
[epoch10, step837]: loss 0.082969
[epoch10, step838]: loss 0.108392
[epoch10, step839]: loss 0.097012
[epoch10, step840]: loss 0.087609
[epoch10, step841]: loss 0.095072
[epoch10, step842]: loss 0.096519
[epoch10, step843]: loss 0.106249
[epoch10, step844]: loss 0.106195
[epoch10, step845]: loss 0.100290
[epoch10, step846]: loss 0.123617
[epoch10, step847]: loss 0.097352
[epoch10, step848]: loss 0.058551
[epoch10, step849]: loss 0.089774
[epoch10, step850]: loss 0.106042
[epoch10, step851]: loss 0.092738
[epoch10, step852]: loss 0.095561
[epoch10, step853]: loss 0.105349
[epoch10, step854]: loss 0.106226
[epoch10, step855]: loss 0.087673
[epoch10, step856]: loss 0.079224
[epoch10, step857]: loss 0.102227
[epoch10, step858]: loss 0.103745
[epoch10, step859]: loss 0.087121
[epoch10, step860]: loss 0.107612
[epoch10, step861]: loss 0.097422
[epoch10, step862]: loss 0.079837
[epoch10, step863]: loss 0.104989
[epoch10, step864]: loss 0.110004
[epoch10, step865]: loss 0.100849
[epoch10, step866]: loss 0.105810
[epoch10, step867]: loss 0.091344
[epoch10, step868]: loss 0.100654
[epoch10, step869]: loss 0.085588
[epoch10, step870]: loss 0.083937
[epoch10, step871]: loss 0.115756
[epoch10, step872]: loss 0.103364
[epoch10, step873]: loss 0.082547
[epoch10, step874]: loss 0.094631
[epoch10, step875]: loss 0.119056
[epoch10, step876]: loss 0.108258
[epoch10, step877]: loss 0.062408
[epoch10, step878]: loss 0.087235
[epoch10, step879]: loss 0.093360
[epoch10, step880]: loss 0.088659
[epoch10, step881]: loss 0.107959
[epoch10, step882]: loss 0.086236
[epoch10, step883]: loss 0.090494
[epoch10, step884]: loss 0.116337
[epoch10, step885]: loss 0.116536
[epoch10, step886]: loss 0.111920
[epoch10, step887]: loss 0.117054
[epoch10, step888]: loss 0.091067
[epoch10, step889]: loss 0.104186
[epoch10, step890]: loss 0.104609
[epoch10, step891]: loss 0.090336
[epoch10, step892]: loss 0.104735
[epoch10, step893]: loss 0.102306
[epoch10, step894]: loss 0.103182
[epoch10, step895]: loss 0.081443
[epoch10, step896]: loss 0.124979
[epoch10, step897]: loss 0.124460
[epoch10, step898]: loss 0.085978
[epoch10, step899]: loss 0.065977
[epoch10, step900]: loss 0.096847
[epoch10, step901]: loss 0.110172
[epoch10, step902]: loss 0.086585
[epoch10, step903]: loss 0.112276
[epoch10, step904]: loss 0.086916
[epoch10, step905]: loss 0.082417
[epoch10, step906]: loss 0.077402
[epoch10, step907]: loss 0.104754
[epoch10, step908]: loss 0.112457
[epoch10, step909]: loss 0.093107
[epoch10, step910]: loss 0.078776
[epoch10, step911]: loss 0.077870
[epoch10, step912]: loss 0.105297
[epoch10, step913]: loss 0.106844
[epoch10, step914]: loss 0.098413
[epoch10, step915]: loss 0.086071
[epoch10, step916]: loss 0.099559
[epoch10, step917]: loss 0.096651
[epoch10, step918]: loss 0.108230
[epoch10, step919]: loss 0.081531
[epoch10, step920]: loss 0.110659
[epoch10, step921]: loss 0.088273
[epoch10, step922]: loss 0.090456
[epoch10, step923]: loss 0.112068
[epoch10, step924]: loss 0.087026
[epoch10, step925]: loss 0.089952
[epoch10, step926]: loss 0.091543
[epoch10, step927]: loss 0.110496
[epoch10, step928]: loss 0.087660
[epoch10, step929]: loss 0.093354
[epoch10, step930]: loss 0.096560
[epoch10, step931]: loss 0.105472
[epoch10, step932]: loss 0.087084
[epoch10, step933]: loss 0.092142
[epoch10, step934]: loss 0.112439
[epoch10, step935]: loss 0.096918
[epoch10, step936]: loss 0.086170
[epoch10, step937]: loss 0.081508
[epoch10, step938]: loss 0.117771
[epoch10, step939]: loss 0.088541
[epoch10, step940]: loss 0.106375
[epoch10, step941]: loss 0.099681
[epoch10, step942]: loss 0.097524
[epoch10, step943]: loss 0.110967
[epoch10, step944]: loss 0.098877
[epoch10, step945]: loss 0.106838
[epoch10, step946]: loss 0.096106
[epoch10, step947]: loss 0.087143
[epoch10, step948]: loss 0.128836
[epoch10, step949]: loss 0.096120
[epoch10, step950]: loss 0.094411
[epoch10, step951]: loss 0.102761
[epoch10, step952]: loss 0.105125
[epoch10, step953]: loss 0.096765
[epoch10, step954]: loss 0.101267
[epoch10, step955]: loss 0.083835
[epoch10, step956]: loss 0.123193
[epoch10, step957]: loss 0.110635
[epoch10, step958]: loss 0.124920
[epoch10, step959]: loss 0.117187
[epoch10, step960]: loss 0.107332
[epoch10, step961]: loss 0.115512
[epoch10, step962]: loss 0.114829
[epoch10, step963]: loss 0.117878
[epoch10, step964]: loss 0.109226
[epoch10, step965]: loss 0.120202
[epoch10, step966]: loss 0.106601
[epoch10, step967]: loss 0.119008
[epoch10, step968]: loss 0.113040
[epoch10, step969]: loss 0.101669
[epoch10, step970]: loss 0.111944
[epoch10, step971]: loss 0.112434
[epoch10, step972]: loss 0.114111
[epoch10, step973]: loss 0.110088
[epoch10, step974]: loss 0.113967
[epoch10, step975]: loss 0.105255
[epoch10, step976]: loss 0.118247
[epoch10, step977]: loss 0.109917
[epoch10, step978]: loss 0.101005
[epoch10, step979]: loss 0.112532
[epoch10, step980]: loss 0.111722
[epoch10, step981]: loss 0.115149
[epoch10, step982]: loss 0.107168
[epoch10, step983]: loss 0.114160
[epoch10, step984]: loss 0.105049
[epoch10, step985]: loss 0.117962
[epoch10, step986]: loss 0.108720
[epoch10, step987]: loss 0.097920
[epoch10, step988]: loss 0.108812
[epoch10, step989]: loss 0.109828
[epoch10, step990]: loss 0.114253
[epoch10, step991]: loss 0.105395
[epoch10, step992]: loss 0.114440
[epoch10, step993]: loss 0.105117
[epoch10, step994]: loss 0.119175
[epoch10, step995]: loss 0.110217
[epoch10, step996]: loss 0.099662
[epoch10, step997]: loss 0.109520
[epoch10, step998]: loss 0.109244
[epoch10, step999]: loss 0.113622
[epoch10, step1000]: loss 0.106789
[epoch10, step1001]: loss 0.113534
[epoch10, step1002]: loss 0.102668
[epoch10, step1003]: loss 0.117668
[epoch10, step1004]: loss 0.108643
[epoch10, step1005]: loss 0.099994
[epoch10, step1006]: loss 0.109583
[epoch10, step1007]: loss 0.110620
[epoch10, step1008]: loss 0.114351
[epoch10, step1009]: loss 0.106605
[epoch10, step1010]: loss 0.112027
[epoch10, step1011]: loss 0.103617
[epoch10, step1012]: loss 0.116011
[epoch10, step1013]: loss 0.109232
[epoch10, step1014]: loss 0.099117
[epoch10, step1015]: loss 0.108739
[epoch10, step1016]: loss 0.110544
[epoch10, step1017]: loss 0.114548
[epoch10, step1018]: loss 0.105971
[epoch10, step1019]: loss 0.113465
[epoch10, step1020]: loss 0.104322
[epoch10, step1021]: loss 0.117394
[epoch10, step1022]: loss 0.109497
[epoch10, step1023]: loss 0.099317
[epoch10, step1024]: loss 0.106926
[epoch10, step1025]: loss 0.111205
[epoch10, step1026]: loss 0.114984
[epoch10, step1027]: loss 0.105267
[epoch10, step1028]: loss 0.113296
[epoch10, step1029]: loss 0.103353
[epoch10, step1030]: loss 0.117479
[epoch10, step1031]: loss 0.112672
[epoch10, step1032]: loss 0.098595
[epoch10, step1033]: loss 0.110973
[epoch10, step1034]: loss 0.110729
[epoch10, step1035]: loss 0.114882
[epoch10, step1036]: loss 0.106727
[epoch10, step1037]: loss 0.113812
[epoch10, step1038]: loss 0.103672
[epoch10, step1039]: loss 0.116241
[epoch10, step1040]: loss 0.110593
[epoch10, step1041]: loss 0.100123
[epoch10, step1042]: loss 0.109613
[epoch10, step1043]: loss 0.110062
[epoch10, step1044]: loss 0.112803
[epoch10, step1045]: loss 0.105466
[epoch10, step1046]: loss 0.112986
[epoch10, step1047]: loss 0.102387
[epoch10, step1048]: loss 0.117935
[epoch10, step1049]: loss 0.109039
[epoch10, step1050]: loss 0.099021
[epoch10, step1051]: loss 0.108745
[epoch10, step1052]: loss 0.109498
[epoch10, step1053]: loss 0.113514
[epoch10, step1054]: loss 0.106418
[epoch10, step1055]: loss 0.114226
[epoch10, step1056]: loss 0.104157
[epoch10, step1057]: loss 0.114834
[epoch10, step1058]: loss 0.107211
[epoch10, step1059]: loss 0.098640
[epoch10, step1060]: loss 0.107389
[epoch10, step1061]: loss 0.111365
[epoch10, step1062]: loss 0.112053
[epoch10, step1063]: loss 0.106080
[epoch10, step1064]: loss 0.113060
[epoch10, step1065]: loss 0.104182
[epoch10, step1066]: loss 0.117125
[epoch10, step1067]: loss 0.108905
[epoch10, step1068]: loss 0.102496
[epoch10, step1069]: loss 0.107333
[epoch10, step1070]: loss 0.109389
[epoch10, step1071]: loss 0.111457
[epoch10, step1072]: loss 0.104154
[epoch10, step1073]: loss 0.113072
[epoch10, step1074]: loss 0.104188
[epoch10, step1075]: loss 0.115490
[epoch10, step1076]: loss 0.108419
[epoch10, step1077]: loss 0.098372
[epoch10, step1078]: loss 0.109168
[epoch10, step1079]: loss 0.107424
[epoch10, step1080]: loss 0.112169
[epoch10, step1081]: loss 0.106860
[epoch10, step1082]: loss 0.113162
[epoch10, step1083]: loss 0.102295
[epoch10, step1084]: loss 0.115503
[epoch10, step1085]: loss 0.109938
[epoch10, step1086]: loss 0.100138
[epoch10, step1087]: loss 0.108714
[epoch10, step1088]: loss 0.109869
[epoch10, step1089]: loss 0.111775
[epoch10, step1090]: loss 0.104372
[epoch10, step1091]: loss 0.112105
[epoch10, step1092]: loss 0.103368
[epoch10, step1093]: loss 0.115550
[epoch10, step1094]: loss 0.110759
[epoch10, step1095]: loss 0.098385
[epoch10, step1096]: loss 0.109580
[epoch10, step1097]: loss 0.108689
[epoch10, step1098]: loss 0.112842
[epoch10, step1099]: loss 0.106397
[epoch10, step1100]: loss 0.111179
[epoch10, step1101]: loss 0.103775
[epoch10, step1102]: loss 0.116331
[epoch10, step1103]: loss 0.109646
[epoch10, step1104]: loss 0.098534
[epoch10, step1105]: loss 0.107331
[epoch10, step1106]: loss 0.111017
[epoch10, step1107]: loss 0.112313
[epoch10, step1108]: loss 0.106282
[epoch10, step1109]: loss 0.111378
[epoch10, step1110]: loss 0.101114
[epoch10, step1111]: loss 0.115345
[epoch10, step1112]: loss 0.107645
[epoch10, step1113]: loss 0.098524
[epoch10, step1114]: loss 0.107692
[epoch10, step1115]: loss 0.108164
[epoch10, step1116]: loss 0.112057
[epoch10, step1117]: loss 0.104861
[epoch10, step1118]: loss 0.112622
[epoch10, step1119]: loss 0.104340
[epoch10, step1120]: loss 0.116050
[epoch10, step1121]: loss 0.108526
[epoch10, step1122]: loss 0.098674
[epoch10, step1123]: loss 0.109097
[epoch10, step1124]: loss 0.107585
[epoch10, step1125]: loss 0.111461
[epoch10, step1126]: loss 0.103541
[epoch10, step1127]: loss 0.111766
[epoch10, step1128]: loss 0.102932
[epoch10, step1129]: loss 0.115727
[epoch10, step1130]: loss 0.106045
[epoch10, step1131]: loss 0.097303
[epoch10, step1132]: loss 0.106951
[epoch10, step1133]: loss 0.109766
[epoch10, step1134]: loss 0.112441
[epoch10, step1135]: loss 0.102486
[epoch10, step1136]: loss 0.110444
[epoch10, step1137]: loss 0.101052
[epoch10, step1138]: loss 0.114798
[epoch10, step1139]: loss 0.108640
[epoch10, step1140]: loss 0.097913
[epoch10, step1141]: loss 0.106875
[epoch10, step1142]: loss 0.109556
[epoch10, step1143]: loss 0.113160
[epoch10, step1144]: loss 0.105254
[epoch10, step1145]: loss 0.113074
[epoch10, step1146]: loss 0.101417
[epoch10, step1147]: loss 0.113032
[epoch10, step1148]: loss 0.108269
[epoch10, step1149]: loss 0.097368
[epoch10, step1150]: loss 0.108488
[epoch10, step1151]: loss 0.108369
[epoch10, step1152]: loss 0.110313
[epoch10, step1153]: loss 0.105597
[epoch10, step1154]: loss 0.110885
[epoch10, step1155]: loss 0.101715
[epoch10, step1156]: loss 0.116387
[epoch10, step1157]: loss 0.108892
[epoch10, step1158]: loss 0.096655
[epoch10, step1159]: loss 0.106611
[epoch10, step1160]: loss 0.107022
[epoch10, step1161]: loss 0.110322
[epoch10, step1162]: loss 0.105110
[epoch10, step1163]: loss 0.113057
[epoch10, step1164]: loss 0.101247
[epoch10, step1165]: loss 0.112490
[epoch10, step1166]: loss 0.107156
[epoch10, step1167]: loss 0.098150
[epoch10, step1168]: loss 0.106928
[epoch10, step1169]: loss 0.108858
[epoch10, step1170]: loss 0.111766
[epoch10, step1171]: loss 0.104851
[epoch10, step1172]: loss 0.111859
[epoch10, step1173]: loss 0.102087
[epoch10, step1174]: loss 0.113631
[epoch10, step1175]: loss 0.108365
[epoch10, step1176]: loss 0.097714
[epoch10, step1177]: loss 0.105764
[epoch10, step1178]: loss 0.107301
[epoch10, step1179]: loss 0.111628
[epoch10, step1180]: loss 0.104032
[epoch10, step1181]: loss 0.110134
[epoch10, step1182]: loss 0.102229
[epoch10, step1183]: loss 0.112981
[epoch10, step1184]: loss 0.109018
[epoch10, step1185]: loss 0.098411
[epoch10, step1186]: loss 0.107379
[epoch10, step1187]: loss 0.110018
[epoch10, step1188]: loss 0.112081
[epoch10, step1189]: loss 0.104454
[epoch10, step1190]: loss 0.112109
[epoch10, step1191]: loss 0.101764
[epoch10, step1192]: loss 0.113646
[epoch10, step1193]: loss 0.107255
[epoch10, step1194]: loss 0.097504
[epoch10, step1195]: loss 0.109771
[epoch10, step1196]: loss 0.109363
[epoch10, step1197]: loss 0.111011
[epoch10, step1198]: loss 0.103642
[epoch10, step1199]: loss 0.111828
[epoch10, step1200]: loss 0.101322
[epoch10, step1201]: loss 0.113047
[epoch10, step1202]: loss 0.105453
[epoch10, step1203]: loss 0.098731
[epoch10, step1204]: loss 0.107200
[epoch10, step1205]: loss 0.107998
[epoch10, step1206]: loss 0.112119
[epoch10, step1207]: loss 0.102372
[epoch10, step1208]: loss 0.110296
[epoch10, step1209]: loss 0.101897
[epoch10, step1210]: loss 0.112716
[epoch10, step1211]: loss 0.108550
[epoch10, step1212]: loss 0.098430
[epoch10, step1213]: loss 0.108084
[epoch10, step1214]: loss 0.107567
[epoch10, step1215]: loss 0.109352
[epoch10, step1216]: loss 0.103994
[epoch10, step1217]: loss 0.109692
[epoch10, step1218]: loss 0.100993
[epoch10, step1219]: loss 0.112837
[epoch10, step1220]: loss 0.106232
[epoch10, step1221]: loss 0.097757
[epoch10, step1222]: loss 0.106526
[epoch10, step1223]: loss 0.107352
[epoch10, step1224]: loss 0.109763
[epoch10, step1225]: loss 0.103655
[epoch10, step1226]: loss 0.111711
[epoch10, step1227]: loss 0.099855
[epoch10, step1228]: loss 0.114161
[epoch10, step1229]: loss 0.108365
[epoch10, step1230]: loss 0.098110
[epoch10, step1231]: loss 0.107296
[epoch10, step1232]: loss 0.105851
[epoch10, step1233]: loss 0.110850
[epoch10, step1234]: loss 0.103977
[epoch10, step1235]: loss 0.109635
[epoch10, step1236]: loss 0.102461
[epoch10, step1237]: loss 0.114580
[epoch10, step1238]: loss 0.108397
[epoch10, step1239]: loss 0.095830
[epoch10, step1240]: loss 0.105278
[epoch10, step1241]: loss 0.109426
[epoch10, step1242]: loss 0.110752
[epoch10, step1243]: loss 0.103031
[epoch10, step1244]: loss 0.110156
[epoch10, step1245]: loss 0.099209
[epoch10, step1246]: loss 0.113243
[epoch10, step1247]: loss 0.108913
[epoch10, step1248]: loss 0.097100
[epoch10, step1249]: loss 0.105119
[epoch10, step1250]: loss 0.107356
[epoch10, step1251]: loss 0.110290
[epoch10, step1252]: loss 0.102959
[epoch10, step1253]: loss 0.109704
[epoch10, step1254]: loss 0.100717
[epoch10, step1255]: loss 0.113174
[epoch10, step1256]: loss 0.105773
[epoch10, step1257]: loss 0.096040
[epoch10, step1258]: loss 0.106133
[epoch10, step1259]: loss 0.107664
[epoch10, step1260]: loss 0.110088
[epoch10, step1261]: loss 0.103829
[epoch10, step1262]: loss 0.112409
[epoch10, step1263]: loss 0.098858
[epoch10, step1264]: loss 0.113736
[epoch10, step1265]: loss 0.109723
[epoch10, step1266]: loss 0.097609
[epoch10, step1267]: loss 0.105961
[epoch10, step1268]: loss 0.106997
[epoch10, step1269]: loss 0.109667
[epoch10, step1270]: loss 0.104772
[epoch10, step1271]: loss 0.109400
[epoch10, step1272]: loss 0.100348
[epoch10, step1273]: loss 0.114205
[epoch10, step1274]: loss 0.107708
[epoch10, step1275]: loss 0.096892
[epoch10, step1276]: loss 0.106050
[epoch10, step1277]: loss 0.107016
[epoch10, step1278]: loss 0.108924
[epoch10, step1279]: loss 0.102563
[epoch10, step1280]: loss 0.109671
[epoch10, step1281]: loss 0.100749
[epoch10, step1282]: loss 0.112746
[epoch10, step1283]: loss 0.107687
[epoch10, step1284]: loss 0.095503
[epoch10, step1285]: loss 0.105519
[epoch10, step1286]: loss 0.107777
[epoch10, step1287]: loss 0.108045
[epoch10, step1288]: loss 0.101715
[epoch10, step1289]: loss 0.107893
[epoch10, step1290]: loss 0.101324
[epoch10, step1291]: loss 0.113304
[epoch10, step1292]: loss 0.104755
[epoch10, step1293]: loss 0.096547
[epoch10, step1294]: loss 0.105098
[epoch10, step1295]: loss 0.105497
[epoch10, step1296]: loss 0.109078
[epoch10, step1297]: loss 0.102052
[epoch10, step1298]: loss 0.108653
[epoch10, step1299]: loss 0.100693
[epoch10, step1300]: loss 0.111958
[epoch10, step1301]: loss 0.108628
[epoch10, step1302]: loss 0.096359
[epoch10, step1303]: loss 0.106451
[epoch10, step1304]: loss 0.107684
[epoch10, step1305]: loss 0.108627
[epoch10, step1306]: loss 0.102928
[epoch10, step1307]: loss 0.110882
[epoch10, step1308]: loss 0.100906
[epoch10, step1309]: loss 0.113921
[epoch10, step1310]: loss 0.106340
[epoch10, step1311]: loss 0.097222
[epoch10, step1312]: loss 0.105238
[epoch10, step1313]: loss 0.106446
[epoch10, step1314]: loss 0.110009
[epoch10, step1315]: loss 0.102713
[epoch10, step1316]: loss 0.106619
[epoch10, step1317]: loss 0.101212
[epoch10, step1318]: loss 0.113878
[epoch10, step1319]: loss 0.106770
[epoch10, step1320]: loss 0.096380
[epoch10, step1321]: loss 0.103775
[epoch10, step1322]: loss 0.107392
[epoch10, step1323]: loss 0.108411
[epoch10, step1324]: loss 0.103421
[epoch10, step1325]: loss 0.109714
[epoch10, step1326]: loss 0.101504
[epoch10, step1327]: loss 0.112634
[epoch10, step1328]: loss 0.106051
[epoch10, step1329]: loss 0.096580
[epoch10, step1330]: loss 0.105073
[epoch10, step1331]: loss 0.107082
[epoch10, step1332]: loss 0.110108
[epoch10, step1333]: loss 0.105006
[epoch10, step1334]: loss 0.108443
[epoch10, step1335]: loss 0.100097
[epoch10, step1336]: loss 0.111953
[epoch10, step1337]: loss 0.107818
[epoch10, step1338]: loss 0.095501
[epoch10, step1339]: loss 0.105928
[epoch10, step1340]: loss 0.107512
[epoch10, step1341]: loss 0.109124
[epoch10, step1342]: loss 0.102393
[epoch10, step1343]: loss 0.108541
[epoch10, step1344]: loss 0.098837
[epoch10, step1345]: loss 0.111776
[epoch10, step1346]: loss 0.106654
[epoch10, step1347]: loss 0.095023
[epoch10, step1348]: loss 0.105981
[epoch10, step1349]: loss 0.106155
[epoch10, step1350]: loss 0.108246
[epoch10, step1351]: loss 0.104558
[epoch10, step1352]: loss 0.110132
[epoch10, step1353]: loss 0.101420
[epoch10, step1354]: loss 0.113202
[epoch10, step1355]: loss 0.105852
[epoch10, step1356]: loss 0.098006
[epoch10, step1357]: loss 0.106553
[epoch10, step1358]: loss 0.106066
[epoch10, step1359]: loss 0.109785
[epoch10, step1360]: loss 0.101096
[epoch10, step1361]: loss 0.108378
[epoch10, step1362]: loss 0.099542
[epoch10, step1363]: loss 0.110375
[epoch10, step1364]: loss 0.105692
[epoch10, step1365]: loss 0.096139
[epoch10, step1366]: loss 0.104825
[epoch10, step1367]: loss 0.107000
[epoch10, step1368]: loss 0.106342
[epoch10, step1369]: loss 0.102547
[epoch10, step1370]: loss 0.109409
[epoch10, step1371]: loss 0.099183
[epoch10, step1372]: loss 0.111644
[epoch10, step1373]: loss 0.105720
[epoch10, step1374]: loss 0.094213
[epoch10, step1375]: loss 0.103680
[epoch10, step1376]: loss 0.105899
[epoch10, step1377]: loss 0.110594
[epoch10, step1378]: loss 0.102523
[epoch10, step1379]: loss 0.109766
[epoch10, step1380]: loss 0.097635
[epoch10, step1381]: loss 0.111650
[epoch10, step1382]: loss 0.105245
[epoch10, step1383]: loss 0.095415
[epoch10, step1384]: loss 0.104099
[epoch10, step1385]: loss 0.106317
[epoch10, step1386]: loss 0.108287
[epoch10, step1387]: loss 0.100395
[epoch10, step1388]: loss 0.110767
[epoch10, step1389]: loss 0.100072
[epoch10, step1390]: loss 0.110982
[epoch10, step1391]: loss 0.105625
[epoch10, step1392]: loss 0.096077
[epoch10, step1393]: loss 0.103383
[epoch10, step1394]: loss 0.104070
[epoch10, step1395]: loss 0.108041
[epoch10, step1396]: loss 0.101676
[epoch10, step1397]: loss 0.108876
[epoch10, step1398]: loss 0.098778
[epoch10, step1399]: loss 0.109119
[epoch10, step1400]: loss 0.105162
[epoch10, step1401]: loss 0.094500
[epoch10, step1402]: loss 0.104156
[epoch10, step1403]: loss 0.107290
[epoch10, step1404]: loss 0.109025
[epoch10, step1405]: loss 0.100821
[epoch10, step1406]: loss 0.109236
[epoch10, step1407]: loss 0.097513
[epoch10, step1408]: loss 0.112775
[epoch10, step1409]: loss 0.106132
[epoch10, step1410]: loss 0.094287
[epoch10, step1411]: loss 0.106634
[epoch10, step1412]: loss 0.105359
[epoch10, step1413]: loss 0.108434
[epoch10, step1414]: loss 0.102288
[epoch10, step1415]: loss 0.108874
[epoch10, step1416]: loss 0.098002
[epoch10, step1417]: loss 0.111496
[epoch10, step1418]: loss 0.105405
[epoch10, step1419]: loss 0.093855
[epoch10, step1420]: loss 0.104348
[epoch10, step1421]: loss 0.104221
[epoch10, step1422]: loss 0.107199
[epoch10, step1423]: loss 0.102059
[epoch10, step1424]: loss 0.108041
[epoch10, step1425]: loss 0.099778
[epoch10, step1426]: loss 0.110981
[epoch10, step1427]: loss 0.103315
[epoch10, step1428]: loss 0.095671
[epoch10, step1429]: loss 0.103392
[epoch10, step1430]: loss 0.105782
[epoch10, step1431]: loss 0.107733
[epoch10, step1432]: loss 0.101952
[epoch10, step1433]: loss 0.108129
[epoch10, step1434]: loss 0.101408
[epoch10, step1435]: loss 0.110126
[epoch10, step1436]: loss 0.104217
[epoch10, step1437]: loss 0.094044
[epoch10, step1438]: loss 0.103781
[epoch10, step1439]: loss 0.105821
[epoch10, step1440]: loss 0.108559
[epoch10, step1441]: loss 0.100039
[epoch10, step1442]: loss 0.109713
[epoch10, step1443]: loss 0.101088
[epoch10, step1444]: loss 0.111989
[epoch10, step1445]: loss 0.104175
[epoch10, step1446]: loss 0.093547
[epoch10, step1447]: loss 0.102968
[epoch10, step1448]: loss 0.105143
[epoch10, step1449]: loss 0.108549
[epoch10, step1450]: loss 0.101431
[epoch10, step1451]: loss 0.107106
[epoch10, step1452]: loss 0.099486
[epoch10, step1453]: loss 0.108602
[epoch10, step1454]: loss 0.103799
[epoch10, step1455]: loss 0.093080
[epoch10, step1456]: loss 0.104430
[epoch10, step1457]: loss 0.103453
[epoch10, step1458]: loss 0.107367
[epoch10, step1459]: loss 0.102420
[epoch10, step1460]: loss 0.107066
[epoch10, step1461]: loss 0.096924
[epoch10, step1462]: loss 0.109016
[epoch10, step1463]: loss 0.105246
[epoch10, step1464]: loss 0.093316
[epoch10, step1465]: loss 0.105126
[epoch10, step1466]: loss 0.104970
[epoch10, step1467]: loss 0.108698
[epoch10, step1468]: loss 0.101415
[epoch10, step1469]: loss 0.107962
[epoch10, step1470]: loss 0.097911
[epoch10, step1471]: loss 0.111496
[epoch10, step1472]: loss 0.105105
[epoch10, step1473]: loss 0.093551
[epoch10, step1474]: loss 0.102225
[epoch10, step1475]: loss 0.104980
[epoch10, step1476]: loss 0.106188
[epoch10, step1477]: loss 0.102135
[epoch10, step1478]: loss 0.107479
[epoch10, step1479]: loss 0.098151
[epoch10, step1480]: loss 0.110159
[epoch10, step1481]: loss 0.106690
[epoch10, step1482]: loss 0.094756
[epoch10, step1483]: loss 0.103630
[epoch10, step1484]: loss 0.104187
[epoch10, step1485]: loss 0.107281
[epoch10, step1486]: loss 0.102808
[epoch10, step1487]: loss 0.107890
[epoch10, step1488]: loss 0.098043
[epoch10, step1489]: loss 0.110698
[epoch10, step1490]: loss 0.103883
[epoch10, step1491]: loss 0.095159
[epoch10, step1492]: loss 0.104681
[epoch10, step1493]: loss 0.104807
[epoch10, step1494]: loss 0.107437
[epoch10, step1495]: loss 0.102301
[epoch10, step1496]: loss 0.109106
[epoch10, step1497]: loss 0.097606
[epoch10, step1498]: loss 0.108832
[epoch10, step1499]: loss 0.105479
[epoch10, step1500]: loss 0.093817
[epoch10, step1501]: loss 0.103268
[epoch10, step1502]: loss 0.104381
[epoch10, step1503]: loss 0.107680
[epoch10, step1504]: loss 0.102035
[epoch10, step1505]: loss 0.106811
[epoch10, step1506]: loss 0.098377
[epoch10, step1507]: loss 0.109135
[epoch10, step1508]: loss 0.103444
[epoch10, step1509]: loss 0.095318
[epoch10, step1510]: loss 0.105650
[epoch10, step1511]: loss 0.102955
[epoch10, step1512]: loss 0.106398
[epoch10, step1513]: loss 0.103358
[epoch10, step1514]: loss 0.107601
[epoch10, step1515]: loss 0.098126
[epoch10, step1516]: loss 0.109910

[epoch10]: avg loss 0.109114

[epoch11, step1]: loss 0.114753
[epoch11, step2]: loss 0.106289
[epoch11, step3]: loss 0.106873
[epoch11, step4]: loss 0.100445
[epoch11, step5]: loss 0.109909
[epoch11, step6]: loss 0.104453
[epoch11, step7]: loss 0.095786
[epoch11, step8]: loss 0.107589
[epoch11, step9]: loss 0.097325
[epoch11, step10]: loss 0.107432
[epoch11, step11]: loss 0.106071
[epoch11, step12]: loss 0.106301
[epoch11, step13]: loss 0.097087
[epoch11, step14]: loss 0.109804
[epoch11, step15]: loss 0.104473
[epoch11, step16]: loss 0.096387
[epoch11, step17]: loss 0.106685
[epoch11, step18]: loss 0.095484
[epoch11, step19]: loss 0.108737
[epoch11, step20]: loss 0.104008
[epoch11, step21]: loss 0.106625
[epoch11, step22]: loss 0.098970
[epoch11, step23]: loss 0.112313
[epoch11, step24]: loss 0.103456
[epoch11, step25]: loss 0.096107
[epoch11, step26]: loss 0.108889
[epoch11, step27]: loss 0.097191
[epoch11, step28]: loss 0.108184
[epoch11, step29]: loss 0.105068
[epoch11, step30]: loss 0.104720
[epoch11, step31]: loss 0.098220
[epoch11, step32]: loss 0.109016
[epoch11, step33]: loss 0.102753
[epoch11, step34]: loss 0.095394
[epoch11, step35]: loss 0.106634
[epoch11, step36]: loss 0.097097
[epoch11, step37]: loss 0.108566
[epoch11, step38]: loss 0.105771
[epoch11, step39]: loss 0.106004
[epoch11, step40]: loss 0.096560
[epoch11, step41]: loss 0.111199
[epoch11, step42]: loss 0.102882
[epoch11, step43]: loss 0.096889
[epoch11, step44]: loss 0.106839
[epoch11, step45]: loss 0.097063
[epoch11, step46]: loss 0.108455
[epoch11, step47]: loss 0.106337
[epoch11, step48]: loss 0.106575
[epoch11, step49]: loss 0.098710
[epoch11, step50]: loss 0.109742
[epoch11, step51]: loss 0.103698
[epoch11, step52]: loss 0.097007
[epoch11, step53]: loss 0.105807
[epoch11, step54]: loss 0.095989
[epoch11, step55]: loss 0.107285
[epoch11, step56]: loss 0.102886
[epoch11, step57]: loss 0.104920
[epoch11, step58]: loss 0.097075
[epoch11, step59]: loss 0.111827
[epoch11, step60]: loss 0.101979
[epoch11, step61]: loss 0.097064
[epoch11, step62]: loss 0.108124
[epoch11, step63]: loss 0.097827
[epoch11, step64]: loss 0.109846
[epoch11, step65]: loss 0.104492
[epoch11, step66]: loss 0.105700
[epoch11, step67]: loss 0.098092
[epoch11, step68]: loss 0.109785
[epoch11, step69]: loss 0.103587
[epoch11, step70]: loss 0.096624
[epoch11, step71]: loss 0.107769
[epoch11, step72]: loss 0.096266
[epoch11, step73]: loss 0.108297
[epoch11, step74]: loss 0.104510
[epoch11, step75]: loss 0.104952
[epoch11, step76]: loss 0.097583
[epoch11, step77]: loss 0.108142
[epoch11, step78]: loss 0.102828
[epoch11, step79]: loss 0.097096
[epoch11, step80]: loss 0.105041
[epoch11, step81]: loss 0.095892
[epoch11, step82]: loss 0.109307
[epoch11, step83]: loss 0.106463
[epoch11, step84]: loss 0.105130
[epoch11, step85]: loss 0.095635
[epoch11, step86]: loss 0.108577
[epoch11, step87]: loss 0.101333
[epoch11, step88]: loss 0.099983
[epoch11, step89]: loss 0.107631
[epoch11, step90]: loss 0.096882
[epoch11, step91]: loss 0.110179
[epoch11, step92]: loss 0.104295
[epoch11, step93]: loss 0.104830
[epoch11, step94]: loss 0.098106
[epoch11, step95]: loss 0.108316
[epoch11, step96]: loss 0.103473
[epoch11, step97]: loss 0.095279
[epoch11, step98]: loss 0.106778
[epoch11, step99]: loss 0.096441
[epoch11, step100]: loss 0.109962
[epoch11, step101]: loss 0.103035
[epoch11, step102]: loss 0.105500
[epoch11, step103]: loss 0.097685
[epoch11, step104]: loss 0.109163
[epoch11, step105]: loss 0.101933
[epoch11, step106]: loss 0.096393
[epoch11, step107]: loss 0.106639
[epoch11, step108]: loss 0.095857
[epoch11, step109]: loss 0.108293
[epoch11, step110]: loss 0.103183
[epoch11, step111]: loss 0.105366
[epoch11, step112]: loss 0.098068
[epoch11, step113]: loss 0.107250
[epoch11, step114]: loss 0.103281
[epoch11, step115]: loss 0.096277
[epoch11, step116]: loss 0.104875
[epoch11, step117]: loss 0.095589
[epoch11, step118]: loss 0.106430
[epoch11, step119]: loss 0.103302
[epoch11, step120]: loss 0.104339
[epoch11, step121]: loss 0.097552
[epoch11, step122]: loss 0.108759
[epoch11, step123]: loss 0.101881
[epoch11, step124]: loss 0.095996
[epoch11, step125]: loss 0.105227
[epoch11, step126]: loss 0.096210
[epoch11, step127]: loss 0.108114
[epoch11, step128]: loss 0.104369
[epoch11, step129]: loss 0.104508
[epoch11, step130]: loss 0.095474
[epoch11, step131]: loss 0.109762
[epoch11, step132]: loss 0.102069
[epoch11, step133]: loss 0.094780
[epoch11, step134]: loss 0.107467
[epoch11, step135]: loss 0.094740
[epoch11, step136]: loss 0.104831
[epoch11, step137]: loss 0.104634
[epoch11, step138]: loss 0.104682
[epoch11, step139]: loss 0.096932
[epoch11, step140]: loss 0.107470
[epoch11, step141]: loss 0.101668
[epoch11, step142]: loss 0.095653
[epoch11, step143]: loss 0.106934
[epoch11, step144]: loss 0.096944
[epoch11, step145]: loss 0.107879
[epoch11, step146]: loss 0.103914
[epoch11, step147]: loss 0.102214
[epoch11, step148]: loss 0.096471
[epoch11, step149]: loss 0.109534
[epoch11, step150]: loss 0.103235
[epoch11, step151]: loss 0.093818
[epoch11, step152]: loss 0.105887
[epoch11, step153]: loss 0.094682
[epoch11, step154]: loss 0.108323
[epoch11, step155]: loss 0.103573
[epoch11, step156]: loss 0.105422
[epoch11, step157]: loss 0.095682
[epoch11, step158]: loss 0.107586
[epoch11, step159]: loss 0.101644
[epoch11, step160]: loss 0.094619
[epoch11, step161]: loss 0.104379
[epoch11, step162]: loss 0.094785
[epoch11, step163]: loss 0.107300
[epoch11, step164]: loss 0.102789
[epoch11, step165]: loss 0.104244
[epoch11, step166]: loss 0.094873
[epoch11, step167]: loss 0.109050
[epoch11, step168]: loss 0.100316
[epoch11, step169]: loss 0.095978
[epoch11, step170]: loss 0.104989
[epoch11, step171]: loss 0.095348
[epoch11, step172]: loss 0.106878
[epoch11, step173]: loss 0.102869
[epoch11, step174]: loss 0.104785
[epoch11, step175]: loss 0.094287
[epoch11, step176]: loss 0.107774
[epoch11, step177]: loss 0.101329
[epoch11, step178]: loss 0.093245
[epoch11, step179]: loss 0.107015
[epoch11, step180]: loss 0.093887
[epoch11, step181]: loss 0.106341
[epoch11, step182]: loss 0.102529
[epoch11, step183]: loss 0.102826
[epoch11, step184]: loss 0.094340
[epoch11, step185]: loss 0.107509
[epoch11, step186]: loss 0.100810
[epoch11, step187]: loss 0.095454
[epoch11, step188]: loss 0.105792
[epoch11, step189]: loss 0.094364
[epoch11, step190]: loss 0.108090
[epoch11, step191]: loss 0.103407
[epoch11, step192]: loss 0.102735
[epoch11, step193]: loss 0.099117
[epoch11, step194]: loss 0.109271
[epoch11, step195]: loss 0.100741
[epoch11, step196]: loss 0.093540
[epoch11, step197]: loss 0.105577
[epoch11, step198]: loss 0.095670
[epoch11, step199]: loss 0.106422
[epoch11, step200]: loss 0.101670
[epoch11, step201]: loss 0.102762
[epoch11, step202]: loss 0.096123
[epoch11, step203]: loss 0.107702
[epoch11, step204]: loss 0.100485
[epoch11, step205]: loss 0.095991
[epoch11, step206]: loss 0.105714
[epoch11, step207]: loss 0.094462
[epoch11, step208]: loss 0.105239
[epoch11, step209]: loss 0.102051
[epoch11, step210]: loss 0.101864
[epoch11, step211]: loss 0.095717
[epoch11, step212]: loss 0.106945
[epoch11, step213]: loss 0.101752
[epoch11, step214]: loss 0.096637
[epoch11, step215]: loss 0.104543
[epoch11, step216]: loss 0.094093
[epoch11, step217]: loss 0.107968
[epoch11, step218]: loss 0.101843
[epoch11, step219]: loss 0.103980
[epoch11, step220]: loss 0.096859
[epoch11, step221]: loss 0.106806
[epoch11, step222]: loss 0.100063
[epoch11, step223]: loss 0.092708
[epoch11, step224]: loss 0.105543
[epoch11, step225]: loss 0.093942
[epoch11, step226]: loss 0.106993
[epoch11, step227]: loss 0.104310
[epoch11, step228]: loss 0.102323
[epoch11, step229]: loss 0.097211
[epoch11, step230]: loss 0.106394
[epoch11, step231]: loss 0.100102
[epoch11, step232]: loss 0.094188
[epoch11, step233]: loss 0.106233
[epoch11, step234]: loss 0.095246
[epoch11, step235]: loss 0.106385
[epoch11, step236]: loss 0.102240
[epoch11, step237]: loss 0.103248
[epoch11, step238]: loss 0.094796
[epoch11, step239]: loss 0.108376
[epoch11, step240]: loss 0.102492
[epoch11, step241]: loss 0.094124
[epoch11, step242]: loss 0.105065
[epoch11, step243]: loss 0.093892
[epoch11, step244]: loss 0.106622
[epoch11, step245]: loss 0.103279
[epoch11, step246]: loss 0.103336
[epoch11, step247]: loss 0.095712
[epoch11, step248]: loss 0.107764
[epoch11, step249]: loss 0.101679
[epoch11, step250]: loss 0.093431
[epoch11, step251]: loss 0.103694
[epoch11, step252]: loss 0.093363
[epoch11, step253]: loss 0.107261
[epoch11, step254]: loss 0.103705
[epoch11, step255]: loss 0.102545
[epoch11, step256]: loss 0.096598
[epoch11, step257]: loss 0.107381
[epoch11, step258]: loss 0.099541
[epoch11, step259]: loss 0.092622
[epoch11, step260]: loss 0.105590
[epoch11, step261]: loss 0.092124
[epoch11, step262]: loss 0.104999
[epoch11, step263]: loss 0.103701
[epoch11, step264]: loss 0.103329
[epoch11, step265]: loss 0.095670
[epoch11, step266]: loss 0.106996
[epoch11, step267]: loss 0.102150
[epoch11, step268]: loss 0.094061
[epoch11, step269]: loss 0.104172
[epoch11, step270]: loss 0.094550
[epoch11, step271]: loss 0.105366
[epoch11, step272]: loss 0.102368
[epoch11, step273]: loss 0.103407
[epoch11, step274]: loss 0.093820
[epoch11, step275]: loss 0.108073
[epoch11, step276]: loss 0.101666
[epoch11, step277]: loss 0.093611
[epoch11, step278]: loss 0.104058
[epoch11, step279]: loss 0.093433
[epoch11, step280]: loss 0.105497
[epoch11, step281]: loss 0.102406
[epoch11, step282]: loss 0.101720
[epoch11, step283]: loss 0.095980
[epoch11, step284]: loss 0.107473
[epoch11, step285]: loss 0.099206
[epoch11, step286]: loss 0.097154
[epoch11, step287]: loss 0.103941
[epoch11, step288]: loss 0.094476
[epoch11, step289]: loss 0.104584
[epoch11, step290]: loss 0.102012
[epoch11, step291]: loss 0.102100
[epoch11, step292]: loss 0.096422
[epoch11, step293]: loss 0.107106
[epoch11, step294]: loss 0.101008
[epoch11, step295]: loss 0.094214
[epoch11, step296]: loss 0.102896
[epoch11, step297]: loss 0.094700
[epoch11, step298]: loss 0.105320
[epoch11, step299]: loss 0.103524
[epoch11, step300]: loss 0.101867
[epoch11, step301]: loss 0.096196
[epoch11, step302]: loss 0.105795
[epoch11, step303]: loss 0.099637
[epoch11, step304]: loss 0.092630
[epoch11, step305]: loss 0.104629
[epoch11, step306]: loss 0.093538
[epoch11, step307]: loss 0.106192
[epoch11, step308]: loss 0.100963
[epoch11, step309]: loss 0.101371
[epoch11, step310]: loss 0.095290
[epoch11, step311]: loss 0.105361
[epoch11, step312]: loss 0.100671
[epoch11, step313]: loss 0.094090
[epoch11, step314]: loss 0.103796
[epoch11, step315]: loss 0.093352
[epoch11, step316]: loss 0.105989
[epoch11, step317]: loss 0.101409
[epoch11, step318]: loss 0.102386
[epoch11, step319]: loss 0.096200
[epoch11, step320]: loss 0.108384
[epoch11, step321]: loss 0.100817
[epoch11, step322]: loss 0.095576
[epoch11, step323]: loss 0.105450
[epoch11, step324]: loss 0.092670
[epoch11, step325]: loss 0.105049
[epoch11, step326]: loss 0.102053
[epoch11, step327]: loss 0.103492
[epoch11, step328]: loss 0.095294
[epoch11, step329]: loss 0.106937
[epoch11, step330]: loss 0.101263
[epoch11, step331]: loss 0.094054
[epoch11, step332]: loss 0.104864
[epoch11, step333]: loss 0.093997
[epoch11, step334]: loss 0.104691
[epoch11, step335]: loss 0.101574
[epoch11, step336]: loss 0.100719
[epoch11, step337]: loss 0.093371
[epoch11, step338]: loss 0.107249
[epoch11, step339]: loss 0.100750
[epoch11, step340]: loss 0.093806
[epoch11, step341]: loss 0.104484
[epoch11, step342]: loss 0.093162
[epoch11, step343]: loss 0.104271
[epoch11, step344]: loss 0.101993
[epoch11, step345]: loss 0.103362
[epoch11, step346]: loss 0.095831
[epoch11, step347]: loss 0.106717
[epoch11, step348]: loss 0.099202
[epoch11, step349]: loss 0.092683
[epoch11, step350]: loss 0.104713
[epoch11, step351]: loss 0.093954
[epoch11, step352]: loss 0.105051
[epoch11, step353]: loss 0.101477
[epoch11, step354]: loss 0.104128
[epoch11, step355]: loss 0.096019
[epoch11, step356]: loss 0.104866
[epoch11, step357]: loss 0.099514
[epoch11, step358]: loss 0.095828
[epoch11, step359]: loss 0.102079
[epoch11, step360]: loss 0.093430
[epoch11, step361]: loss 0.105626
[epoch11, step362]: loss 0.100352
[epoch11, step363]: loss 0.102622
[epoch11, step364]: loss 0.094923
[epoch11, step365]: loss 0.106044
[epoch11, step366]: loss 0.099285
[epoch11, step367]: loss 0.094174
[epoch11, step368]: loss 0.104427
[epoch11, step369]: loss 0.093579
[epoch11, step370]: loss 0.103741
[epoch11, step371]: loss 0.099762
[epoch11, step372]: loss 0.102513
[epoch11, step373]: loss 0.094290
[epoch11, step374]: loss 0.107027
[epoch11, step375]: loss 0.098554
[epoch11, step376]: loss 0.091737
[epoch11, step377]: loss 0.103041
[epoch11, step378]: loss 0.093568
[epoch11, step379]: loss 0.103883
[epoch11, step380]: loss 0.100120
[epoch11, step381]: loss 0.102452
[epoch11, step382]: loss 0.096115
[epoch11, step383]: loss 0.107745
[epoch11, step384]: loss 0.100962
[epoch11, step385]: loss 0.091318
[epoch11, step386]: loss 0.102936
[epoch11, step387]: loss 0.092016
[epoch11, step388]: loss 0.103078
[epoch11, step389]: loss 0.100980
[epoch11, step390]: loss 0.099619
[epoch11, step391]: loss 0.093648
[epoch11, step392]: loss 0.104305
[epoch11, step393]: loss 0.100362
[epoch11, step394]: loss 0.094103
[epoch11, step395]: loss 0.103610
[epoch11, step396]: loss 0.092707
[epoch11, step397]: loss 0.105635
[epoch11, step398]: loss 0.100740
[epoch11, step399]: loss 0.101708
[epoch11, step400]: loss 0.093340
[epoch11, step401]: loss 0.105749
[epoch11, step402]: loss 0.099786
[epoch11, step403]: loss 0.092217
[epoch11, step404]: loss 0.102676
[epoch11, step405]: loss 0.091769
[epoch11, step406]: loss 0.103718
[epoch11, step407]: loss 0.101232
[epoch11, step408]: loss 0.101321
[epoch11, step409]: loss 0.091234
[epoch11, step410]: loss 0.104082
[epoch11, step411]: loss 0.099257
[epoch11, step412]: loss 0.092144
[epoch11, step413]: loss 0.102943
[epoch11, step414]: loss 0.094178
[epoch11, step415]: loss 0.103994
[epoch11, step416]: loss 0.101770
[epoch11, step417]: loss 0.101012
[epoch11, step418]: loss 0.093283
[epoch11, step419]: loss 0.106470
[epoch11, step420]: loss 0.098385
[epoch11, step421]: loss 0.092912
[epoch11, step422]: loss 0.102746
[epoch11, step423]: loss 0.092300
[epoch11, step424]: loss 0.103600
[epoch11, step425]: loss 0.100276
[epoch11, step426]: loss 0.100669
[epoch11, step427]: loss 0.094802
[epoch11, step428]: loss 0.105335
[epoch11, step429]: loss 0.097401
[epoch11, step430]: loss 0.092382
[epoch11, step431]: loss 0.102248
[epoch11, step432]: loss 0.091854
[epoch11, step433]: loss 0.102356
[epoch11, step434]: loss 0.100660
[epoch11, step435]: loss 0.100436
[epoch11, step436]: loss 0.095383
[epoch11, step437]: loss 0.104598
[epoch11, step438]: loss 0.097524
[epoch11, step439]: loss 0.093164
[epoch11, step440]: loss 0.102467
[epoch11, step441]: loss 0.091841
[epoch11, step442]: loss 0.103690
[epoch11, step443]: loss 0.099435
[epoch11, step444]: loss 0.101894
[epoch11, step445]: loss 0.093527
[epoch11, step446]: loss 0.104153
[epoch11, step447]: loss 0.097674
[epoch11, step448]: loss 0.091080
[epoch11, step449]: loss 0.102916
[epoch11, step450]: loss 0.093984
[epoch11, step451]: loss 0.104244
[epoch11, step452]: loss 0.102210
[epoch11, step453]: loss 0.100720
[epoch11, step454]: loss 0.094485
[epoch11, step455]: loss 0.104208
[epoch11, step456]: loss 0.099996
[epoch11, step457]: loss 0.091819
[epoch11, step458]: loss 0.102818
[epoch11, step459]: loss 0.090852
[epoch11, step460]: loss 0.103555
[epoch11, step461]: loss 0.098991
[epoch11, step462]: loss 0.102029
[epoch11, step463]: loss 0.093695
[epoch11, step464]: loss 0.104963
[epoch11, step465]: loss 0.095966
[epoch11, step466]: loss 0.091485
[epoch11, step467]: loss 0.102817
[epoch11, step468]: loss 0.092491
[epoch11, step469]: loss 0.102929
[epoch11, step470]: loss 0.099821
[epoch11, step471]: loss 0.101375
[epoch11, step472]: loss 0.094252
[epoch11, step473]: loss 0.105700
[epoch11, step474]: loss 0.098918
[epoch11, step475]: loss 0.092515
[epoch11, step476]: loss 0.101839
[epoch11, step477]: loss 0.092135
[epoch11, step478]: loss 0.104329
[epoch11, step479]: loss 0.099978
[epoch11, step480]: loss 0.102108
[epoch11, step481]: loss 0.093802
[epoch11, step482]: loss 0.105647
[epoch11, step483]: loss 0.097927
[epoch11, step484]: loss 0.089681
[epoch11, step485]: loss 0.101808
[epoch11, step486]: loss 0.091177
[epoch11, step487]: loss 0.104031
[epoch11, step488]: loss 0.099295
[epoch11, step489]: loss 0.102118
[epoch11, step490]: loss 0.093576
[epoch11, step491]: loss 0.103489
[epoch11, step492]: loss 0.098541
[epoch11, step493]: loss 0.091296
[epoch11, step494]: loss 0.103051
[epoch11, step495]: loss 0.089711
[epoch11, step496]: loss 0.103612
[epoch11, step497]: loss 0.099471
[epoch11, step498]: loss 0.100626
[epoch11, step499]: loss 0.093492
[epoch11, step500]: loss 0.105350
[epoch11, step501]: loss 0.099331
[epoch11, step502]: loss 0.091737
[epoch11, step503]: loss 0.101976
[epoch11, step504]: loss 0.093337
[epoch11, step505]: loss 0.105039
[epoch11, step506]: loss 0.098566
[epoch11, step507]: loss 0.099560
[epoch11, step508]: loss 0.092935
[epoch11, step509]: loss 0.104578
[epoch11, step510]: loss 0.098096
[epoch11, step511]: loss 0.092533
[epoch11, step512]: loss 0.101055
[epoch11, step513]: loss 0.091688
[epoch11, step514]: loss 0.102336
[epoch11, step515]: loss 0.099584
[epoch11, step516]: loss 0.099438
[epoch11, step517]: loss 0.093898
[epoch11, step518]: loss 0.103876
[epoch11, step519]: loss 0.097861
[epoch11, step520]: loss 0.090729
[epoch11, step521]: loss 0.102428
[epoch11, step522]: loss 0.092081
[epoch11, step523]: loss 0.102996
[epoch11, step524]: loss 0.101335
[epoch11, step525]: loss 0.100018
[epoch11, step526]: loss 0.091483
[epoch11, step527]: loss 0.105091
[epoch11, step528]: loss 0.097789
[epoch11, step529]: loss 0.092460
[epoch11, step530]: loss 0.101213
[epoch11, step531]: loss 0.091293
[epoch11, step532]: loss 0.103706
[epoch11, step533]: loss 0.097637
[epoch11, step534]: loss 0.100202
[epoch11, step535]: loss 0.092670
[epoch11, step536]: loss 0.103407
[epoch11, step537]: loss 0.097447
[epoch11, step538]: loss 0.092659
[epoch11, step539]: loss 0.101817
[epoch11, step540]: loss 0.093454
[epoch11, step541]: loss 0.103472
[epoch11, step542]: loss 0.099586
[epoch11, step543]: loss 0.100092
[epoch11, step544]: loss 0.091179
[epoch11, step545]: loss 0.105260
[epoch11, step546]: loss 0.096883
[epoch11, step547]: loss 0.093156
[epoch11, step548]: loss 0.101765
[epoch11, step549]: loss 0.091273
[epoch11, step550]: loss 0.102850
[epoch11, step551]: loss 0.099184
[epoch11, step552]: loss 0.100916
[epoch11, step553]: loss 0.092830
[epoch11, step554]: loss 0.104376
[epoch11, step555]: loss 0.098421
[epoch11, step556]: loss 0.090615
[epoch11, step557]: loss 0.102364
[epoch11, step558]: loss 0.091037
[epoch11, step559]: loss 0.103315
[epoch11, step560]: loss 0.098866
[epoch11, step561]: loss 0.100262
[epoch11, step562]: loss 0.091710
[epoch11, step563]: loss 0.111928
[epoch11, step564]: loss 0.092388
[epoch11, step565]: loss 0.075488
[epoch11, step566]: loss 0.084443
[epoch11, step567]: loss 0.077516
[epoch11, step568]: loss 0.083447
[epoch11, step569]: loss 0.095635
[epoch11, step570]: loss 0.086900
[epoch11, step571]: loss 0.064216
[epoch11, step572]: loss 0.082554
[epoch11, step573]: loss 0.088527
[epoch11, step574]: loss 0.103318
[epoch11, step575]: loss 0.087259
[epoch11, step576]: loss 0.090799
[epoch11, step577]: loss 0.080324
[epoch11, step578]: loss 0.089360
[epoch11, step579]: loss 0.077555
[epoch11, step580]: loss 0.100488
[epoch11, step581]: loss 0.091431
[epoch11, step582]: loss 0.088495
[epoch11, step583]: loss 0.088638
[epoch11, step584]: loss 0.085407
[epoch11, step585]: loss 0.099137
[epoch11, step586]: loss 0.087285
[epoch11, step587]: loss 0.068413
[epoch11, step588]: loss 0.088797
[epoch11, step589]: loss 0.111434
[epoch11, step590]: loss 0.071580
[epoch11, step591]: loss 0.085114
[epoch11, step592]: loss 0.095457
[epoch11, step593]: loss 0.109801
[epoch11, step594]: loss 0.071854
[epoch11, step595]: loss 0.072821
[epoch11, step596]: loss 0.094644
[epoch11, step597]: loss 0.098615
[epoch11, step598]: loss 0.078234
[epoch11, step599]: loss 0.071737
[epoch11, step600]: loss 0.071509
[epoch11, step601]: loss 0.085111
[epoch11, step602]: loss 0.100798
[epoch11, step603]: loss 0.079363
[epoch11, step604]: loss 0.078553
[epoch11, step605]: loss 0.070928
[epoch11, step606]: loss 0.085137
[epoch11, step607]: loss 0.093314
[epoch11, step608]: loss 0.063450
[epoch11, step609]: loss 0.089148
[epoch11, step610]: loss 0.080270
[epoch11, step611]: loss 0.096206
[epoch11, step612]: loss 0.088824
[epoch11, step613]: loss 0.093188
[epoch11, step614]: loss 0.086955
[epoch11, step615]: loss 0.089535
[epoch11, step616]: loss 0.072585
[epoch11, step617]: loss 0.081391
[epoch11, step618]: loss 0.094433
[epoch11, step619]: loss 0.075145
[epoch11, step620]: loss 0.069562
[epoch11, step621]: loss 0.068503
[epoch11, step622]: loss 0.089867
[epoch11, step623]: loss 0.088853
[epoch11, step624]: loss 0.089864
[epoch11, step625]: loss 0.069097
[epoch11, step626]: loss 0.090979
[epoch11, step627]: loss 0.100196
[epoch11, step628]: loss 0.093350
[epoch11, step629]: loss 0.055360
[epoch11, step630]: loss 0.076300
[epoch11, step631]: loss 0.079639
[epoch11, step632]: loss 0.088842
[epoch11, step633]: loss 0.075322
[epoch11, step634]: loss 0.086483
[epoch11, step635]: loss 0.081522
[epoch11, step636]: loss 0.071330
[epoch11, step637]: loss 0.095472
[epoch11, step638]: loss 0.088890
[epoch11, step639]: loss 0.069901
[epoch11, step640]: loss 0.093396
[epoch11, step641]: loss 0.075488
[epoch11, step642]: loss 0.071166
[epoch11, step643]: loss 0.091385
[epoch11, step644]: loss 0.081390
[epoch11, step645]: loss 0.065082
[epoch11, step646]: loss 0.084531
[epoch11, step647]: loss 0.067059
[epoch11, step648]: loss 0.100611
[epoch11, step649]: loss 0.089862
[epoch11, step650]: loss 0.091612
[epoch11, step651]: loss 0.080888
[epoch11, step652]: loss 0.098889
[epoch11, step653]: loss 0.096102
[epoch11, step654]: loss 0.090248
[epoch11, step655]: loss 0.072984
[epoch11, step656]: loss 0.094396
[epoch11, step657]: loss 0.095937
[epoch11, step658]: loss 0.076699
[epoch11, step659]: loss 0.068385
[epoch11, step660]: loss 0.083646
[epoch11, step661]: loss 0.089694
[epoch11, step662]: loss 0.067861
[epoch11, step663]: loss 0.080372
[epoch11, step664]: loss 0.079998
[epoch11, step665]: loss 0.099260
[epoch11, step666]: loss 0.070676
[epoch11, step667]: loss 0.089029
[epoch11, step668]: loss 0.097776
[epoch11, step669]: loss 0.071190
[epoch11, step670]: loss 0.086445
[epoch11, step671]: loss 0.086240
[epoch11, step672]: loss 0.102675
[epoch11, step673]: loss 0.094283
[epoch11, step674]: loss 0.079567
[epoch11, step675]: loss 0.090704
[epoch11, step676]: loss 0.090531
[epoch11, step677]: loss 0.078665
[epoch11, step678]: loss 0.069042
[epoch11, step679]: loss 0.082912
[epoch11, step680]: loss 0.072866
[epoch11, step681]: loss 0.070088
[epoch11, step682]: loss 0.074021
[epoch11, step683]: loss 0.084989
[epoch11, step684]: loss 0.071860
[epoch11, step685]: loss 0.072574
[epoch11, step686]: loss 0.071517
[epoch11, step687]: loss 0.077336
[epoch11, step688]: loss 0.088663
[epoch11, step689]: loss 0.072206
[epoch11, step690]: loss 0.092769
[epoch11, step691]: loss 0.096085
[epoch11, step692]: loss 0.091564
[epoch11, step693]: loss 0.086899
[epoch11, step694]: loss 0.067568
[epoch11, step695]: loss 0.078746
[epoch11, step696]: loss 0.073159
[epoch11, step697]: loss 0.086554
[epoch11, step698]: loss 0.077944
[epoch11, step699]: loss 0.079546
[epoch11, step700]: loss 0.099721
[epoch11, step701]: loss 0.089173
[epoch11, step702]: loss 0.076843
[epoch11, step703]: loss 0.098434
[epoch11, step704]: loss 0.092432
[epoch11, step705]: loss 0.072717
[epoch11, step706]: loss 0.075375
[epoch11, step707]: loss 0.077390
[epoch11, step708]: loss 0.084398
[epoch11, step709]: loss 0.076519
[epoch11, step710]: loss 0.084779
[epoch11, step711]: loss 0.091985
[epoch11, step712]: loss 0.069253
[epoch11, step713]: loss 0.077098
[epoch11, step714]: loss 0.086400
[epoch11, step715]: loss 0.075158
[epoch11, step716]: loss 0.086578
[epoch11, step717]: loss 0.073626
[epoch11, step718]: loss 0.081671
[epoch11, step719]: loss 0.086690
[epoch11, step720]: loss 0.072869
[epoch11, step721]: loss 0.079236
[epoch11, step722]: loss 0.087308
[epoch11, step723]: loss 0.081728
[epoch11, step724]: loss 0.085720
[epoch11, step725]: loss 0.087896
[epoch11, step726]: loss 0.063431
[epoch11, step727]: loss 0.085142
[epoch11, step728]: loss 0.086663
[epoch11, step729]: loss 0.069952
[epoch11, step730]: loss 0.085477
[epoch11, step731]: loss 0.092471
[epoch11, step732]: loss 0.079376
[epoch11, step733]: loss 0.066130
[epoch11, step734]: loss 0.074109
[epoch11, step735]: loss 0.075883
[epoch11, step736]: loss 0.077927
[epoch11, step737]: loss 0.071020
[epoch11, step738]: loss 0.073410
[epoch11, step739]: loss 0.100591
[epoch11, step740]: loss 0.104268
[epoch11, step741]: loss 0.083761
[epoch11, step742]: loss 0.092754
[epoch11, step743]: loss 0.081420
[epoch11, step744]: loss 0.080762
[epoch11, step745]: loss 0.081879
[epoch11, step746]: loss 0.087295
[epoch11, step747]: loss 0.080578
[epoch11, step748]: loss 0.073457
[epoch11, step749]: loss 0.101282
[epoch11, step750]: loss 0.088320
[epoch11, step751]: loss 0.075709
[epoch11, step752]: loss 0.071423
[epoch11, step753]: loss 0.072511
[epoch11, step754]: loss 0.092295
[epoch11, step755]: loss 0.086898
[epoch11, step756]: loss 0.066293
[epoch11, step757]: loss 0.079754
[epoch11, step758]: loss 0.088391
[epoch11, step759]: loss 0.071444
[epoch11, step760]: loss 0.085681
[epoch11, step761]: loss 0.079727
[epoch11, step762]: loss 0.073243
[epoch11, step763]: loss 0.075949
[epoch11, step764]: loss 0.083994
[epoch11, step765]: loss 0.074541
[epoch11, step766]: loss 0.070562
[epoch11, step767]: loss 0.087969
[epoch11, step768]: loss 0.080464
[epoch11, step769]: loss 0.083246
[epoch11, step770]: loss 0.098503
[epoch11, step771]: loss 0.069767
[epoch11, step772]: loss 0.073440
[epoch11, step773]: loss 0.079336
[epoch11, step774]: loss 0.080311
[epoch11, step775]: loss 0.094945
[epoch11, step776]: loss 0.085831
[epoch11, step777]: loss 0.076063
[epoch11, step778]: loss 0.092113
[epoch11, step779]: loss 0.077972
[epoch11, step780]: loss 0.085675
[epoch11, step781]: loss 0.098152
[epoch11, step782]: loss 0.092136
[epoch11, step783]: loss 0.079795
[epoch11, step784]: loss 0.090109
[epoch11, step785]: loss 0.088679
[epoch11, step786]: loss 0.080359
[epoch11, step787]: loss 0.096076
[epoch11, step788]: loss 0.082494
[epoch11, step789]: loss 0.092190
[epoch11, step790]: loss 0.069653
[epoch11, step791]: loss 0.087474
[epoch11, step792]: loss 0.086787
[epoch11, step793]: loss 0.088392
[epoch11, step794]: loss 0.080748
[epoch11, step795]: loss 0.080945
[epoch11, step796]: loss 0.078586
[epoch11, step797]: loss 0.073465
[epoch11, step798]: loss 0.073839
[epoch11, step799]: loss 0.064475
[epoch11, step800]: loss 0.099113
[epoch11, step801]: loss 0.093419
[epoch11, step802]: loss 0.078989
[epoch11, step803]: loss 0.075968
[epoch11, step804]: loss 0.087372
[epoch11, step805]: loss 0.079231
[epoch11, step806]: loss 0.080572
[epoch11, step807]: loss 0.087664
[epoch11, step808]: loss 0.095670
[epoch11, step809]: loss 0.074618
[epoch11, step810]: loss 0.066577
[epoch11, step811]: loss 0.082247
[epoch11, step812]: loss 0.086949
[epoch11, step813]: loss 0.074611
[epoch11, step814]: loss 0.083975
[epoch11, step815]: loss 0.079923
[epoch11, step816]: loss 0.080529
[epoch11, step817]: loss 0.071712
[epoch11, step818]: loss 0.076482
[epoch11, step819]: loss 0.108833
[epoch11, step820]: loss 0.072716
[epoch11, step821]: loss 0.071694
[epoch11, step822]: loss 0.085826
[epoch11, step823]: loss 0.071327
[epoch11, step824]: loss 0.082961
[epoch11, step825]: loss 0.084864
[epoch11, step826]: loss 0.062046
[epoch11, step827]: loss 0.074680
[epoch11, step828]: loss 0.082128
[epoch11, step829]: loss 0.076103
[epoch11, step830]: loss 0.059475
[epoch11, step831]: loss 0.072095
[epoch11, step832]: loss 0.095472
[epoch11, step833]: loss 0.084589
[epoch11, step834]: loss 0.080966
[epoch11, step835]: loss 0.081793
[epoch11, step836]: loss 0.073768
[epoch11, step837]: loss 0.070285
[epoch11, step838]: loss 0.090306
[epoch11, step839]: loss 0.081614
[epoch11, step840]: loss 0.072909
[epoch11, step841]: loss 0.079560
[epoch11, step842]: loss 0.081376
[epoch11, step843]: loss 0.088456
[epoch11, step844]: loss 0.088198
[epoch11, step845]: loss 0.082933
[epoch11, step846]: loss 0.102338
[epoch11, step847]: loss 0.081672
[epoch11, step848]: loss 0.050699
[epoch11, step849]: loss 0.075495
[epoch11, step850]: loss 0.087757
[epoch11, step851]: loss 0.077625
[epoch11, step852]: loss 0.079736
[epoch11, step853]: loss 0.088617
[epoch11, step854]: loss 0.087885
[epoch11, step855]: loss 0.073998
[epoch11, step856]: loss 0.066599
[epoch11, step857]: loss 0.085555
[epoch11, step858]: loss 0.086196
[epoch11, step859]: loss 0.073015
[epoch11, step860]: loss 0.089074
[epoch11, step861]: loss 0.081062
[epoch11, step862]: loss 0.067239
[epoch11, step863]: loss 0.086712
[epoch11, step864]: loss 0.091668
[epoch11, step865]: loss 0.083815
[epoch11, step866]: loss 0.087979
[epoch11, step867]: loss 0.076865
[epoch11, step868]: loss 0.084296
[epoch11, step869]: loss 0.071892
[epoch11, step870]: loss 0.071922
[epoch11, step871]: loss 0.095236
[epoch11, step872]: loss 0.086107
[epoch11, step873]: loss 0.069756
[epoch11, step874]: loss 0.078994
[epoch11, step875]: loss 0.098287
[epoch11, step876]: loss 0.089755
[epoch11, step877]: loss 0.052721
[epoch11, step878]: loss 0.073218
[epoch11, step879]: loss 0.078775
[epoch11, step880]: loss 0.074498
[epoch11, step881]: loss 0.089187
[epoch11, step882]: loss 0.072344
[epoch11, step883]: loss 0.075775
[epoch11, step884]: loss 0.096788
[epoch11, step885]: loss 0.096650
[epoch11, step886]: loss 0.093185
[epoch11, step887]: loss 0.096822
[epoch11, step888]: loss 0.076319
[epoch11, step889]: loss 0.086636
[epoch11, step890]: loss 0.086790
[epoch11, step891]: loss 0.075760
[epoch11, step892]: loss 0.086595
[epoch11, step893]: loss 0.085332
[epoch11, step894]: loss 0.085865
[epoch11, step895]: loss 0.068327
[epoch11, step896]: loss 0.102571
[epoch11, step897]: loss 0.102521
[epoch11, step898]: loss 0.072589
[epoch11, step899]: loss 0.057070
[epoch11, step900]: loss 0.081375
[epoch11, step901]: loss 0.091469
[epoch11, step902]: loss 0.072616
[epoch11, step903]: loss 0.092999
[epoch11, step904]: loss 0.073759
[epoch11, step905]: loss 0.070003
[epoch11, step906]: loss 0.065011
[epoch11, step907]: loss 0.087252
[epoch11, step908]: loss 0.092807
[epoch11, step909]: loss 0.077978
[epoch11, step910]: loss 0.066204
[epoch11, step911]: loss 0.066100
[epoch11, step912]: loss 0.087407
[epoch11, step913]: loss 0.088664
[epoch11, step914]: loss 0.083253
[epoch11, step915]: loss 0.072126
[epoch11, step916]: loss 0.082972
[epoch11, step917]: loss 0.080829
[epoch11, step918]: loss 0.090544
[epoch11, step919]: loss 0.068823
[epoch11, step920]: loss 0.092441
[epoch11, step921]: loss 0.073990
[epoch11, step922]: loss 0.075441
[epoch11, step923]: loss 0.092550
[epoch11, step924]: loss 0.072279
[epoch11, step925]: loss 0.075655
[epoch11, step926]: loss 0.077008
[epoch11, step927]: loss 0.091664
[epoch11, step928]: loss 0.073684
[epoch11, step929]: loss 0.078588
[epoch11, step930]: loss 0.081002
[epoch11, step931]: loss 0.088246
[epoch11, step932]: loss 0.072702
[epoch11, step933]: loss 0.077881
[epoch11, step934]: loss 0.092711
[epoch11, step935]: loss 0.080511
[epoch11, step936]: loss 0.072120
[epoch11, step937]: loss 0.069575
[epoch11, step938]: loss 0.097566
[epoch11, step939]: loss 0.073611
[epoch11, step940]: loss 0.088289
[epoch11, step941]: loss 0.083468
[epoch11, step942]: loss 0.081450
[epoch11, step943]: loss 0.091699
[epoch11, step944]: loss 0.082992
[epoch11, step945]: loss 0.088039
[epoch11, step946]: loss 0.080458
[epoch11, step947]: loss 0.073576
[epoch11, step948]: loss 0.105320
[epoch11, step949]: loss 0.079813
[epoch11, step950]: loss 0.079476
[epoch11, step951]: loss 0.086783
[epoch11, step952]: loss 0.087534
[epoch11, step953]: loss 0.081416
[epoch11, step954]: loss 0.083795
[epoch11, step955]: loss 0.072658
[epoch11, step956]: loss 0.106091
[epoch11, step957]: loss 0.095032
[epoch11, step958]: loss 0.105807
[epoch11, step959]: loss 0.100557
[epoch11, step960]: loss 0.092565
[epoch11, step961]: loss 0.099193
[epoch11, step962]: loss 0.098226
[epoch11, step963]: loss 0.100270
[epoch11, step964]: loss 0.093611
[epoch11, step965]: loss 0.102004
[epoch11, step966]: loss 0.091126
[epoch11, step967]: loss 0.100367
[epoch11, step968]: loss 0.096360
[epoch11, step969]: loss 0.087854
[epoch11, step970]: loss 0.095485
[epoch11, step971]: loss 0.095515
[epoch11, step972]: loss 0.096739
[epoch11, step973]: loss 0.094409
[epoch11, step974]: loss 0.097510
[epoch11, step975]: loss 0.090469
[epoch11, step976]: loss 0.100316
[epoch11, step977]: loss 0.094519
[epoch11, step978]: loss 0.087409
[epoch11, step979]: loss 0.095996
[epoch11, step980]: loss 0.095135
[epoch11, step981]: loss 0.097694
[epoch11, step982]: loss 0.091959
[epoch11, step983]: loss 0.097655
[epoch11, step984]: loss 0.089794
[epoch11, step985]: loss 0.100098
[epoch11, step986]: loss 0.093421
[epoch11, step987]: loss 0.084727
[epoch11, step988]: loss 0.093059
[epoch11, step989]: loss 0.093584
[epoch11, step990]: loss 0.097890
[epoch11, step991]: loss 0.090373
[epoch11, step992]: loss 0.097376
[epoch11, step993]: loss 0.089838
[epoch11, step994]: loss 0.100910
[epoch11, step995]: loss 0.094933
[epoch11, step996]: loss 0.085700
[epoch11, step997]: loss 0.093437
[epoch11, step998]: loss 0.093291
[epoch11, step999]: loss 0.097330
[epoch11, step1000]: loss 0.091460
[epoch11, step1001]: loss 0.096949
[epoch11, step1002]: loss 0.088036
[epoch11, step1003]: loss 0.099874
[epoch11, step1004]: loss 0.093218
[epoch11, step1005]: loss 0.085878
[epoch11, step1006]: loss 0.093658
[epoch11, step1007]: loss 0.094151
[epoch11, step1008]: loss 0.097353
[epoch11, step1009]: loss 0.091005
[epoch11, step1010]: loss 0.095671
[epoch11, step1011]: loss 0.088663
[epoch11, step1012]: loss 0.098287
[epoch11, step1013]: loss 0.093669
[epoch11, step1014]: loss 0.085187
[epoch11, step1015]: loss 0.092815
[epoch11, step1016]: loss 0.094062
[epoch11, step1017]: loss 0.097372
[epoch11, step1018]: loss 0.090691
[epoch11, step1019]: loss 0.096536
[epoch11, step1020]: loss 0.089230
[epoch11, step1021]: loss 0.099451
[epoch11, step1022]: loss 0.093817
[epoch11, step1023]: loss 0.085447
[epoch11, step1024]: loss 0.091504
[epoch11, step1025]: loss 0.094658
[epoch11, step1026]: loss 0.097970
[epoch11, step1027]: loss 0.090044
[epoch11, step1028]: loss 0.096416
[epoch11, step1029]: loss 0.088514
[epoch11, step1030]: loss 0.099486
[epoch11, step1031]: loss 0.096171
[epoch11, step1032]: loss 0.084712
[epoch11, step1033]: loss 0.094418
[epoch11, step1034]: loss 0.094296
[epoch11, step1035]: loss 0.097785
[epoch11, step1036]: loss 0.091230
[epoch11, step1037]: loss 0.096741
[epoch11, step1038]: loss 0.088660
[epoch11, step1039]: loss 0.098673
[epoch11, step1040]: loss 0.094615
[epoch11, step1041]: loss 0.085873
[epoch11, step1042]: loss 0.093244
[epoch11, step1043]: loss 0.093703
[epoch11, step1044]: loss 0.096308
[epoch11, step1045]: loss 0.090171
[epoch11, step1046]: loss 0.096145
[epoch11, step1047]: loss 0.087658
[epoch11, step1048]: loss 0.099836
[epoch11, step1049]: loss 0.093471
[epoch11, step1050]: loss 0.085032
[epoch11, step1051]: loss 0.092708
[epoch11, step1052]: loss 0.093395
[epoch11, step1053]: loss 0.096806
[epoch11, step1054]: loss 0.090995
[epoch11, step1055]: loss 0.096942
[epoch11, step1056]: loss 0.088927
[epoch11, step1057]: loss 0.097556
[epoch11, step1058]: loss 0.092192
[epoch11, step1059]: loss 0.084841
[epoch11, step1060]: loss 0.091678
[epoch11, step1061]: loss 0.094676
[epoch11, step1062]: loss 0.095667
[epoch11, step1063]: loss 0.090753
[epoch11, step1064]: loss 0.096227
[epoch11, step1065]: loss 0.089101
[epoch11, step1066]: loss 0.099262
[epoch11, step1067]: loss 0.093352
[epoch11, step1068]: loss 0.087645
[epoch11, step1069]: loss 0.091527
[epoch11, step1070]: loss 0.093208
[epoch11, step1071]: loss 0.095326
[epoch11, step1072]: loss 0.089220
[epoch11, step1073]: loss 0.096167
[epoch11, step1074]: loss 0.089033
[epoch11, step1075]: loss 0.097928
[epoch11, step1076]: loss 0.092949
[epoch11, step1077]: loss 0.084418
[epoch11, step1078]: loss 0.092966
[epoch11, step1079]: loss 0.091786
[epoch11, step1080]: loss 0.095548
[epoch11, step1081]: loss 0.091290
[epoch11, step1082]: loss 0.096156
[epoch11, step1083]: loss 0.087738
[epoch11, step1084]: loss 0.097933
[epoch11, step1085]: loss 0.093993
[epoch11, step1086]: loss 0.086031
[epoch11, step1087]: loss 0.092628
[epoch11, step1088]: loss 0.093586
[epoch11, step1089]: loss 0.095382
[epoch11, step1090]: loss 0.089488
[epoch11, step1091]: loss 0.095510
[epoch11, step1092]: loss 0.088393
[epoch11, step1093]: loss 0.098027
[epoch11, step1094]: loss 0.094616
[epoch11, step1095]: loss 0.084509
[epoch11, step1096]: loss 0.093227
[epoch11, step1097]: loss 0.092644
[epoch11, step1098]: loss 0.096188
[epoch11, step1099]: loss 0.090839
[epoch11, step1100]: loss 0.094812
[epoch11, step1101]: loss 0.088728
[epoch11, step1102]: loss 0.098527
[epoch11, step1103]: loss 0.093768
[epoch11, step1104]: loss 0.084596
[epoch11, step1105]: loss 0.091538
[epoch11, step1106]: loss 0.094208
[epoch11, step1107]: loss 0.095684
[epoch11, step1108]: loss 0.090756
[epoch11, step1109]: loss 0.094822
[epoch11, step1110]: loss 0.086689
[epoch11, step1111]: loss 0.097737
[epoch11, step1112]: loss 0.092396
[epoch11, step1113]: loss 0.084608
[epoch11, step1114]: loss 0.091807
[epoch11, step1115]: loss 0.092212
[epoch11, step1116]: loss 0.095478
[epoch11, step1117]: loss 0.089782
[epoch11, step1118]: loss 0.095785
[epoch11, step1119]: loss 0.089126
[epoch11, step1120]: loss 0.098347
[epoch11, step1121]: loss 0.092938
[epoch11, step1122]: loss 0.084769
[epoch11, step1123]: loss 0.092771
[epoch11, step1124]: loss 0.091879
[epoch11, step1125]: loss 0.095101
[epoch11, step1126]: loss 0.088867
[epoch11, step1127]: loss 0.095178
[epoch11, step1128]: loss 0.088030
[epoch11, step1129]: loss 0.098080
[epoch11, step1130]: loss 0.091116
[epoch11, step1131]: loss 0.083755
[epoch11, step1132]: loss 0.091294
[epoch11, step1133]: loss 0.093289
[epoch11, step1134]: loss 0.095778
[epoch11, step1135]: loss 0.087931
[epoch11, step1136]: loss 0.094189
[epoch11, step1137]: loss 0.086436
[epoch11, step1138]: loss 0.097229
[epoch11, step1139]: loss 0.093074
[epoch11, step1140]: loss 0.083955
[epoch11, step1141]: loss 0.091050
[epoch11, step1142]: loss 0.093167
[epoch11, step1143]: loss 0.096147
[epoch11, step1144]: loss 0.090080
[epoch11, step1145]: loss 0.096045
[epoch11, step1146]: loss 0.086746
[epoch11, step1147]: loss 0.096103
[epoch11, step1148]: loss 0.092783
[epoch11, step1149]: loss 0.083754
[epoch11, step1150]: loss 0.092382
[epoch11, step1151]: loss 0.092438
[epoch11, step1152]: loss 0.094177
[epoch11, step1153]: loss 0.090207
[epoch11, step1154]: loss 0.094561
[epoch11, step1155]: loss 0.087120
[epoch11, step1156]: loss 0.098506
[epoch11, step1157]: loss 0.093222
[epoch11, step1158]: loss 0.083253
[epoch11, step1159]: loss 0.090981
[epoch11, step1160]: loss 0.091383
[epoch11, step1161]: loss 0.094276
[epoch11, step1162]: loss 0.089745
[epoch11, step1163]: loss 0.096056
[epoch11, step1164]: loss 0.086580
[epoch11, step1165]: loss 0.095532
[epoch11, step1166]: loss 0.091872
[epoch11, step1167]: loss 0.084121
[epoch11, step1168]: loss 0.091128
[epoch11, step1169]: loss 0.092633
[epoch11, step1170]: loss 0.095072
[epoch11, step1171]: loss 0.089695
[epoch11, step1172]: loss 0.095183
[epoch11, step1173]: loss 0.087370
[epoch11, step1174]: loss 0.096486
[epoch11, step1175]: loss 0.092770
[epoch11, step1176]: loss 0.084053
[epoch11, step1177]: loss 0.090341
[epoch11, step1178]: loss 0.091531
[epoch11, step1179]: loss 0.095094
[epoch11, step1180]: loss 0.089087
[epoch11, step1181]: loss 0.094050
[epoch11, step1182]: loss 0.087356
[epoch11, step1183]: loss 0.095986
[epoch11, step1184]: loss 0.093220
[epoch11, step1185]: loss 0.084599
[epoch11, step1186]: loss 0.091410
[epoch11, step1187]: loss 0.093415
[epoch11, step1188]: loss 0.095434
[epoch11, step1189]: loss 0.089174
[epoch11, step1190]: loss 0.095328
[epoch11, step1191]: loss 0.087104
[epoch11, step1192]: loss 0.096310
[epoch11, step1193]: loss 0.091934
[epoch11, step1194]: loss 0.083629
[epoch11, step1195]: loss 0.093128
[epoch11, step1196]: loss 0.092929
[epoch11, step1197]: loss 0.094494
[epoch11, step1198]: loss 0.088759
[epoch11, step1199]: loss 0.095073
[epoch11, step1200]: loss 0.086667
[epoch11, step1201]: loss 0.096012
[epoch11, step1202]: loss 0.090636
[epoch11, step1203]: loss 0.084951
[epoch11, step1204]: loss 0.091276
[epoch11, step1205]: loss 0.091964
[epoch11, step1206]: loss 0.095464
[epoch11, step1207]: loss 0.087764
[epoch11, step1208]: loss 0.094064
[epoch11, step1209]: loss 0.086929
[epoch11, step1210]: loss 0.095792
[epoch11, step1211]: loss 0.092821
[epoch11, step1212]: loss 0.084554
[epoch11, step1213]: loss 0.091986
[epoch11, step1214]: loss 0.091636
[epoch11, step1215]: loss 0.093489
[epoch11, step1216]: loss 0.088750
[epoch11, step1217]: loss 0.093556
[epoch11, step1218]: loss 0.086302
[epoch11, step1219]: loss 0.095719
[epoch11, step1220]: loss 0.091183
[epoch11, step1221]: loss 0.083745
[epoch11, step1222]: loss 0.090686
[epoch11, step1223]: loss 0.091409
[epoch11, step1224]: loss 0.093517
[epoch11, step1225]: loss 0.088731
[epoch11, step1226]: loss 0.095042
[epoch11, step1227]: loss 0.085443
[epoch11, step1228]: loss 0.096811
[epoch11, step1229]: loss 0.092723
[epoch11, step1230]: loss 0.084500
[epoch11, step1231]: loss 0.091433
[epoch11, step1232]: loss 0.090543
[epoch11, step1233]: loss 0.094497
[epoch11, step1234]: loss 0.088941
[epoch11, step1235]: loss 0.093636
[epoch11, step1236]: loss 0.087632
[epoch11, step1237]: loss 0.097147
[epoch11, step1238]: loss 0.092603
[epoch11, step1239]: loss 0.082567
[epoch11, step1240]: loss 0.089916
[epoch11, step1241]: loss 0.092950
[epoch11, step1242]: loss 0.094453
[epoch11, step1243]: loss 0.087996
[epoch11, step1244]: loss 0.093817
[epoch11, step1245]: loss 0.085023
[epoch11, step1246]: loss 0.095920
[epoch11, step1247]: loss 0.093020
[epoch11, step1248]: loss 0.083473
[epoch11, step1249]: loss 0.089681
[epoch11, step1250]: loss 0.091377
[epoch11, step1251]: loss 0.093880
[epoch11, step1252]: loss 0.088357
[epoch11, step1253]: loss 0.093542
[epoch11, step1254]: loss 0.086283
[epoch11, step1255]: loss 0.096066
[epoch11, step1256]: loss 0.090776
[epoch11, step1257]: loss 0.082817
[epoch11, step1258]: loss 0.090570
[epoch11, step1259]: loss 0.091649
[epoch11, step1260]: loss 0.093852
[epoch11, step1261]: loss 0.088833
[epoch11, step1262]: loss 0.095494
[epoch11, step1263]: loss 0.084909
[epoch11, step1264]: loss 0.096512
[epoch11, step1265]: loss 0.093542
[epoch11, step1266]: loss 0.083946
[epoch11, step1267]: loss 0.090394
[epoch11, step1268]: loss 0.091113
[epoch11, step1269]: loss 0.093575
[epoch11, step1270]: loss 0.089309
[epoch11, step1271]: loss 0.093281
[epoch11, step1272]: loss 0.085993
[epoch11, step1273]: loss 0.096593
[epoch11, step1274]: loss 0.092123
[epoch11, step1275]: loss 0.083407
[epoch11, step1276]: loss 0.090249
[epoch11, step1277]: loss 0.091105
[epoch11, step1278]: loss 0.092851
[epoch11, step1279]: loss 0.087856
[epoch11, step1280]: loss 0.093553
[epoch11, step1281]: loss 0.086273
[epoch11, step1282]: loss 0.095703
[epoch11, step1283]: loss 0.092090
[epoch11, step1284]: loss 0.082243
[epoch11, step1285]: loss 0.090137
[epoch11, step1286]: loss 0.091667
[epoch11, step1287]: loss 0.092448
[epoch11, step1288]: loss 0.087339
[epoch11, step1289]: loss 0.092303
[epoch11, step1290]: loss 0.086666
[epoch11, step1291]: loss 0.096056
[epoch11, step1292]: loss 0.089926
[epoch11, step1293]: loss 0.082859
[epoch11, step1294]: loss 0.089696
[epoch11, step1295]: loss 0.089981
[epoch11, step1296]: loss 0.093103
[epoch11, step1297]: loss 0.087213
[epoch11, step1298]: loss 0.092667
[epoch11, step1299]: loss 0.086322
[epoch11, step1300]: loss 0.094992
[epoch11, step1301]: loss 0.092703
[epoch11, step1302]: loss 0.083002
[epoch11, step1303]: loss 0.090674
[epoch11, step1304]: loss 0.091560
[epoch11, step1305]: loss 0.092724
[epoch11, step1306]: loss 0.088079
[epoch11, step1307]: loss 0.094374
[epoch11, step1308]: loss 0.086386
[epoch11, step1309]: loss 0.096519
[epoch11, step1310]: loss 0.091099
[epoch11, step1311]: loss 0.083548
[epoch11, step1312]: loss 0.089964
[epoch11, step1313]: loss 0.090756
[epoch11, step1314]: loss 0.093715
[epoch11, step1315]: loss 0.087910
[epoch11, step1316]: loss 0.091369
[epoch11, step1317]: loss 0.086508
[epoch11, step1318]: loss 0.096384
[epoch11, step1319]: loss 0.091347
[epoch11, step1320]: loss 0.083027
[epoch11, step1321]: loss 0.088778
[epoch11, step1322]: loss 0.091408
[epoch11, step1323]: loss 0.092552
[epoch11, step1324]: loss 0.088312
[epoch11, step1325]: loss 0.093439
[epoch11, step1326]: loss 0.086836
[epoch11, step1327]: loss 0.095395
[epoch11, step1328]: loss 0.090842
[epoch11, step1329]: loss 0.083152
[epoch11, step1330]: loss 0.089584
[epoch11, step1331]: loss 0.091148
[epoch11, step1332]: loss 0.093681
[epoch11, step1333]: loss 0.089524
[epoch11, step1334]: loss 0.092600
[epoch11, step1335]: loss 0.085705
[epoch11, step1336]: loss 0.095071
[epoch11, step1337]: loss 0.092082
[epoch11, step1338]: loss 0.082259
[epoch11, step1339]: loss 0.090400
[epoch11, step1340]: loss 0.091398
[epoch11, step1341]: loss 0.092910
[epoch11, step1342]: loss 0.087642
[epoch11, step1343]: loss 0.092701
[epoch11, step1344]: loss 0.084637
[epoch11, step1345]: loss 0.094890
[epoch11, step1346]: loss 0.091192
[epoch11, step1347]: loss 0.082060
[epoch11, step1348]: loss 0.090458
[epoch11, step1349]: loss 0.090765
[epoch11, step1350]: loss 0.092679
[epoch11, step1351]: loss 0.089313
[epoch11, step1352]: loss 0.093920
[epoch11, step1353]: loss 0.086613
[epoch11, step1354]: loss 0.095873
[epoch11, step1355]: loss 0.090902
[epoch11, step1356]: loss 0.084162
[epoch11, step1357]: loss 0.090630
[epoch11, step1358]: loss 0.090385
[epoch11, step1359]: loss 0.093360
[epoch11, step1360]: loss 0.086795
[epoch11, step1361]: loss 0.092436
[epoch11, step1362]: loss 0.085348
[epoch11, step1363]: loss 0.093682
[epoch11, step1364]: loss 0.090592
[epoch11, step1365]: loss 0.082757
[epoch11, step1366]: loss 0.089647
[epoch11, step1367]: loss 0.090922
[epoch11, step1368]: loss 0.090906
[epoch11, step1369]: loss 0.088058
[epoch11, step1370]: loss 0.093578
[epoch11, step1371]: loss 0.084938
[epoch11, step1372]: loss 0.094888
[epoch11, step1373]: loss 0.090678
[epoch11, step1374]: loss 0.081272
[epoch11, step1375]: loss 0.088976
[epoch11, step1376]: loss 0.090171
[epoch11, step1377]: loss 0.093762
[epoch11, step1378]: loss 0.087646
[epoch11, step1379]: loss 0.093441
[epoch11, step1380]: loss 0.083663
[epoch11, step1381]: loss 0.094218
[epoch11, step1382]: loss 0.090310
[epoch11, step1383]: loss 0.081909
[epoch11, step1384]: loss 0.088809
[epoch11, step1385]: loss 0.090337
[epoch11, step1386]: loss 0.092141
[epoch11, step1387]: loss 0.086343
[epoch11, step1388]: loss 0.094166
[epoch11, step1389]: loss 0.085540
[epoch11, step1390]: loss 0.094433
[epoch11, step1391]: loss 0.090466
[epoch11, step1392]: loss 0.082938
[epoch11, step1393]: loss 0.088461
[epoch11, step1394]: loss 0.088852
[epoch11, step1395]: loss 0.092366
[epoch11, step1396]: loss 0.086947
[epoch11, step1397]: loss 0.092859
[epoch11, step1398]: loss 0.084497
[epoch11, step1399]: loss 0.092753
[epoch11, step1400]: loss 0.090039
[epoch11, step1401]: loss 0.081248
[epoch11, step1402]: loss 0.088963
[epoch11, step1403]: loss 0.090827
[epoch11, step1404]: loss 0.092997
[epoch11, step1405]: loss 0.086281
[epoch11, step1406]: loss 0.092958
[epoch11, step1407]: loss 0.083884
[epoch11, step1408]: loss 0.095423
[epoch11, step1409]: loss 0.090669
[epoch11, step1410]: loss 0.081279
[epoch11, step1411]: loss 0.090576
[epoch11, step1412]: loss 0.089723
[epoch11, step1413]: loss 0.092388
[epoch11, step1414]: loss 0.087405
[epoch11, step1415]: loss 0.092821
[epoch11, step1416]: loss 0.083794
[epoch11, step1417]: loss 0.094651
[epoch11, step1418]: loss 0.090246
[epoch11, step1419]: loss 0.081071
[epoch11, step1420]: loss 0.089116
[epoch11, step1421]: loss 0.088817
[epoch11, step1422]: loss 0.091422
[epoch11, step1423]: loss 0.087300
[epoch11, step1424]: loss 0.092267
[epoch11, step1425]: loss 0.085201
[epoch11, step1426]: loss 0.094188
[epoch11, step1427]: loss 0.088695
[epoch11, step1428]: loss 0.082559
[epoch11, step1429]: loss 0.088318
[epoch11, step1430]: loss 0.089911
[epoch11, step1431]: loss 0.091887
[epoch11, step1432]: loss 0.087043
[epoch11, step1433]: loss 0.092229
[epoch11, step1434]: loss 0.086485
[epoch11, step1435]: loss 0.093366
[epoch11, step1436]: loss 0.089347
[epoch11, step1437]: loss 0.081086
[epoch11, step1438]: loss 0.088545
[epoch11, step1439]: loss 0.090038
[epoch11, step1440]: loss 0.092192
[epoch11, step1441]: loss 0.085827
[epoch11, step1442]: loss 0.093387
[epoch11, step1443]: loss 0.086279
[epoch11, step1444]: loss 0.094839
[epoch11, step1445]: loss 0.089319
[epoch11, step1446]: loss 0.080805
[epoch11, step1447]: loss 0.088134
[epoch11, step1448]: loss 0.089466
[epoch11, step1449]: loss 0.092473
[epoch11, step1450]: loss 0.086890
[epoch11, step1451]: loss 0.091577
[epoch11, step1452]: loss 0.085059
[epoch11, step1453]: loss 0.092593
[epoch11, step1454]: loss 0.088961
[epoch11, step1455]: loss 0.080455
[epoch11, step1456]: loss 0.089072
[epoch11, step1457]: loss 0.088105
[epoch11, step1458]: loss 0.091653
[epoch11, step1459]: loss 0.087313
[epoch11, step1460]: loss 0.091373
[epoch11, step1461]: loss 0.083103
[epoch11, step1462]: loss 0.092426
[epoch11, step1463]: loss 0.090003
[epoch11, step1464]: loss 0.080468
[epoch11, step1465]: loss 0.089454
[epoch11, step1466]: loss 0.089170
[epoch11, step1467]: loss 0.092208
[epoch11, step1468]: loss 0.086689
[epoch11, step1469]: loss 0.092126
[epoch11, step1470]: loss 0.083826
[epoch11, step1471]: loss 0.094485
[epoch11, step1472]: loss 0.089902
[epoch11, step1473]: loss 0.080747
[epoch11, step1474]: loss 0.087565
[epoch11, step1475]: loss 0.089279
[epoch11, step1476]: loss 0.090625
[epoch11, step1477]: loss 0.087369
[epoch11, step1478]: loss 0.091912
[epoch11, step1479]: loss 0.084019
[epoch11, step1480]: loss 0.093757
[epoch11, step1481]: loss 0.091395
[epoch11, step1482]: loss 0.081624
[epoch11, step1483]: loss 0.088728
[epoch11, step1484]: loss 0.088622
[epoch11, step1485]: loss 0.092217
[epoch11, step1486]: loss 0.087540
[epoch11, step1487]: loss 0.092084
[epoch11, step1488]: loss 0.083966
[epoch11, step1489]: loss 0.093977
[epoch11, step1490]: loss 0.088980
[epoch11, step1491]: loss 0.081920
[epoch11, step1492]: loss 0.089242
[epoch11, step1493]: loss 0.089188
[epoch11, step1494]: loss 0.091665
[epoch11, step1495]: loss 0.087304
[epoch11, step1496]: loss 0.092796
[epoch11, step1497]: loss 0.083658
[epoch11, step1498]: loss 0.092665
[epoch11, step1499]: loss 0.090185
[epoch11, step1500]: loss 0.080752
[epoch11, step1501]: loss 0.088223
[epoch11, step1502]: loss 0.088791
[epoch11, step1503]: loss 0.091820
[epoch11, step1504]: loss 0.087303
[epoch11, step1505]: loss 0.091240
[epoch11, step1506]: loss 0.084197
[epoch11, step1507]: loss 0.092932
[epoch11, step1508]: loss 0.088775
[epoch11, step1509]: loss 0.082146
[epoch11, step1510]: loss 0.089944
[epoch11, step1511]: loss 0.087774
[epoch11, step1512]: loss 0.090833
[epoch11, step1513]: loss 0.087831
[epoch11, step1514]: loss 0.091695
[epoch11, step1515]: loss 0.084079
[epoch11, step1516]: loss 0.093016

[epoch11]: avg loss 0.092400

[epoch12, step1]: loss 0.092304
[epoch12, step2]: loss 0.090833
[epoch12, step3]: loss 0.091153
[epoch12, step4]: loss 0.085792
[epoch12, step5]: loss 0.093228
[epoch12, step6]: loss 0.089535
[epoch12, step7]: loss 0.082187
[epoch12, step8]: loss 0.091867
[epoch12, step9]: loss 0.083197
[epoch12, step10]: loss 0.091245
[epoch12, step11]: loss 0.090760
[epoch12, step12]: loss 0.090762
[epoch12, step13]: loss 0.083195
[epoch12, step14]: loss 0.093235
[epoch12, step15]: loss 0.089410
[epoch12, step16]: loss 0.082774
[epoch12, step17]: loss 0.091388
[epoch12, step18]: loss 0.081923
[epoch12, step19]: loss 0.092422
[epoch12, step20]: loss 0.089125
[epoch12, step21]: loss 0.091109
[epoch12, step22]: loss 0.084675
[epoch12, step23]: loss 0.094810
[epoch12, step24]: loss 0.088627
[epoch12, step25]: loss 0.082147
[epoch12, step26]: loss 0.092718
[epoch12, step27]: loss 0.083003
[epoch12, step28]: loss 0.091496
[epoch12, step29]: loss 0.089847
[epoch12, step30]: loss 0.089580
[epoch12, step31]: loss 0.084098
[epoch12, step32]: loss 0.092558
[epoch12, step33]: loss 0.088164
[epoch12, step34]: loss 0.082085
[epoch12, step35]: loss 0.091216
[epoch12, step36]: loss 0.083063
[epoch12, step37]: loss 0.092235
[epoch12, step38]: loss 0.090533
[epoch12, step39]: loss 0.090580
[epoch12, step40]: loss 0.082855
[epoch12, step41]: loss 0.094350
[epoch12, step42]: loss 0.088332
[epoch12, step43]: loss 0.083067
[epoch12, step44]: loss 0.091527
[epoch12, step45]: loss 0.083043
[epoch12, step46]: loss 0.092257
[epoch12, step47]: loss 0.090773
[epoch12, step48]: loss 0.090891
[epoch12, step49]: loss 0.084135
[epoch12, step50]: loss 0.093091
[epoch12, step51]: loss 0.088852
[epoch12, step52]: loss 0.082919
[epoch12, step53]: loss 0.090526
[epoch12, step54]: loss 0.082084
[epoch12, step55]: loss 0.091210
[epoch12, step56]: loss 0.088321
[epoch12, step57]: loss 0.089687
[epoch12, step58]: loss 0.083220
[epoch12, step59]: loss 0.094600
[epoch12, step60]: loss 0.087555
[epoch12, step61]: loss 0.083012
[epoch12, step62]: loss 0.092092
[epoch12, step63]: loss 0.083587
[epoch12, step64]: loss 0.093009
[epoch12, step65]: loss 0.089511
[epoch12, step66]: loss 0.090323
[epoch12, step67]: loss 0.084019
[epoch12, step68]: loss 0.093284
[epoch12, step69]: loss 0.088882
[epoch12, step70]: loss 0.082936
[epoch12, step71]: loss 0.092108
[epoch12, step72]: loss 0.082364
[epoch12, step73]: loss 0.092025
[epoch12, step74]: loss 0.089366
[epoch12, step75]: loss 0.089832
[epoch12, step76]: loss 0.083705
[epoch12, step77]: loss 0.091940
[epoch12, step78]: loss 0.088375
[epoch12, step79]: loss 0.082957
[epoch12, step80]: loss 0.089985
[epoch12, step81]: loss 0.082069
[epoch12, step82]: loss 0.092681
[epoch12, step83]: loss 0.090797
[epoch12, step84]: loss 0.089866
[epoch12, step85]: loss 0.082117
[epoch12, step86]: loss 0.092098
[epoch12, step87]: loss 0.087244
[epoch12, step88]: loss 0.085236
[epoch12, step89]: loss 0.091779
[epoch12, step90]: loss 0.083017
[epoch12, step91]: loss 0.093113
[epoch12, step92]: loss 0.089338
[epoch12, step93]: loss 0.089623
[epoch12, step94]: loss 0.084045
[epoch12, step95]: loss 0.092079
[epoch12, step96]: loss 0.088606
[epoch12, step97]: loss 0.081966
[epoch12, step98]: loss 0.091296
[epoch12, step99]: loss 0.082566
[epoch12, step100]: loss 0.093113
[epoch12, step101]: loss 0.088342
[epoch12, step102]: loss 0.090270
[epoch12, step103]: loss 0.083704
[epoch12, step104]: loss 0.092743
[epoch12, step105]: loss 0.087529
[epoch12, step106]: loss 0.082577
[epoch12, step107]: loss 0.091202
[epoch12, step108]: loss 0.082125
[epoch12, step109]: loss 0.091886
[epoch12, step110]: loss 0.088406
[epoch12, step111]: loss 0.090047
[epoch12, step112]: loss 0.084016
[epoch12, step113]: loss 0.091234
[epoch12, step114]: loss 0.088789
[epoch12, step115]: loss 0.082385
[epoch12, step116]: loss 0.089833
[epoch12, step117]: loss 0.081791
[epoch12, step118]: loss 0.090680
[epoch12, step119]: loss 0.088711
[epoch12, step120]: loss 0.089238
[epoch12, step121]: loss 0.083525
[epoch12, step122]: loss 0.092632
[epoch12, step123]: loss 0.087565
[epoch12, step124]: loss 0.082509
[epoch12, step125]: loss 0.090317
[epoch12, step126]: loss 0.082282
[epoch12, step127]: loss 0.092071
[epoch12, step128]: loss 0.089289
[epoch12, step129]: loss 0.089235
[epoch12, step130]: loss 0.081847
[epoch12, step131]: loss 0.093090
[epoch12, step132]: loss 0.087750
[epoch12, step133]: loss 0.081024
[epoch12, step134]: loss 0.091606
[epoch12, step135]: loss 0.081231
[epoch12, step136]: loss 0.089487
[epoch12, step137]: loss 0.089462
[epoch12, step138]: loss 0.089448
[epoch12, step139]: loss 0.083028
[epoch12, step140]: loss 0.091330
[epoch12, step141]: loss 0.087449
[epoch12, step142]: loss 0.081899
[epoch12, step143]: loss 0.091202
[epoch12, step144]: loss 0.083048
[epoch12, step145]: loss 0.091350
[epoch12, step146]: loss 0.089292
[epoch12, step147]: loss 0.087930
[epoch12, step148]: loss 0.082786
[epoch12, step149]: loss 0.093128
[epoch12, step150]: loss 0.088487
[epoch12, step151]: loss 0.080775
[epoch12, step152]: loss 0.091046
[epoch12, step153]: loss 0.081221
[epoch12, step154]: loss 0.092001
[epoch12, step155]: loss 0.088867
[epoch12, step156]: loss 0.090021
[epoch12, step157]: loss 0.082205
[epoch12, step158]: loss 0.091360
[epoch12, step159]: loss 0.087335
[epoch12, step160]: loss 0.081099
[epoch12, step161]: loss 0.089469
[epoch12, step162]: loss 0.081273
[epoch12, step163]: loss 0.090990
[epoch12, step164]: loss 0.088194
[epoch12, step165]: loss 0.089134
[epoch12, step166]: loss 0.081580
[epoch12, step167]: loss 0.092467
[epoch12, step168]: loss 0.086328
[epoch12, step169]: loss 0.082333
[epoch12, step170]: loss 0.089839
[epoch12, step171]: loss 0.081822
[epoch12, step172]: loss 0.090864
[epoch12, step173]: loss 0.088256
[epoch12, step174]: loss 0.089622
[epoch12, step175]: loss 0.081078
[epoch12, step176]: loss 0.091666
[epoch12, step177]: loss 0.087199
[epoch12, step178]: loss 0.080149
[epoch12, step179]: loss 0.091251
[epoch12, step180]: loss 0.080677
[epoch12, step181]: loss 0.090404
[epoch12, step182]: loss 0.087946
[epoch12, step183]: loss 0.088188
[epoch12, step184]: loss 0.081236
[epoch12, step185]: loss 0.091434
[epoch12, step186]: loss 0.086625
[epoch12, step187]: loss 0.081906
[epoch12, step188]: loss 0.090401
[epoch12, step189]: loss 0.081022
[epoch12, step190]: loss 0.091593
[epoch12, step191]: loss 0.088570
[epoch12, step192]: loss 0.088133
[epoch12, step193]: loss 0.084446
[epoch12, step194]: loss 0.092581
[epoch12, step195]: loss 0.086609
[epoch12, step196]: loss 0.080285
[epoch12, step197]: loss 0.090263
[epoch12, step198]: loss 0.081810
[epoch12, step199]: loss 0.090512
[epoch12, step200]: loss 0.087337
[epoch12, step201]: loss 0.088141
[epoch12, step202]: loss 0.082376
[epoch12, step203]: loss 0.091587
[epoch12, step204]: loss 0.086536
[epoch12, step205]: loss 0.082139
[epoch12, step206]: loss 0.090339
[epoch12, step207]: loss 0.081006
[epoch12, step208]: loss 0.089592
[epoch12, step209]: loss 0.087607
[epoch12, step210]: loss 0.087499
[epoch12, step211]: loss 0.082292
[epoch12, step212]: loss 0.091035
[epoch12, step213]: loss 0.087367
[epoch12, step214]: loss 0.082751
[epoch12, step215]: loss 0.089511
[epoch12, step216]: loss 0.080875
[epoch12, step217]: loss 0.091469
[epoch12, step218]: loss 0.087434
[epoch12, step219]: loss 0.088942
[epoch12, step220]: loss 0.083143
[epoch12, step221]: loss 0.090858
[epoch12, step222]: loss 0.086055
[epoch12, step223]: loss 0.079753
[epoch12, step224]: loss 0.090157
[epoch12, step225]: loss 0.080685
[epoch12, step226]: loss 0.090816
[epoch12, step227]: loss 0.089168
[epoch12, step228]: loss 0.087809
[epoch12, step229]: loss 0.083151
[epoch12, step230]: loss 0.090596
[epoch12, step231]: loss 0.086240
[epoch12, step232]: loss 0.080780
[epoch12, step233]: loss 0.090740
[epoch12, step234]: loss 0.081675
[epoch12, step235]: loss 0.090631
[epoch12, step236]: loss 0.087639
[epoch12, step237]: loss 0.088538
[epoch12, step238]: loss 0.081218
[epoch12, step239]: loss 0.091883
[epoch12, step240]: loss 0.087887
[epoch12, step241]: loss 0.080863
[epoch12, step242]: loss 0.089861
[epoch12, step243]: loss 0.080670
[epoch12, step244]: loss 0.090599
[epoch12, step245]: loss 0.088370
[epoch12, step246]: loss 0.088459
[epoch12, step247]: loss 0.082168
[epoch12, step248]: loss 0.091414
[epoch12, step249]: loss 0.087242
[epoch12, step250]: loss 0.080165
[epoch12, step251]: loss 0.088763
[epoch12, step252]: loss 0.080291
[epoch12, step253]: loss 0.090968
[epoch12, step254]: loss 0.088773
[epoch12, step255]: loss 0.087893
[epoch12, step256]: loss 0.082847
[epoch12, step257]: loss 0.091228
[epoch12, step258]: loss 0.085647
[epoch12, step259]: loss 0.079724
[epoch12, step260]: loss 0.090267
[epoch12, step261]: loss 0.079428
[epoch12, step262]: loss 0.089520
[epoch12, step263]: loss 0.088591
[epoch12, step264]: loss 0.088535
[epoch12, step265]: loss 0.082124
[epoch12, step266]: loss 0.090987
[epoch12, step267]: loss 0.087572
[epoch12, step268]: loss 0.080706
[epoch12, step269]: loss 0.089197
[epoch12, step270]: loss 0.080883
[epoch12, step271]: loss 0.089472
[epoch12, step272]: loss 0.087727
[epoch12, step273]: loss 0.088476
[epoch12, step274]: loss 0.080661
[epoch12, step275]: loss 0.091637
[epoch12, step276]: loss 0.087362
[epoch12, step277]: loss 0.080422
[epoch12, step278]: loss 0.089014
[epoch12, step279]: loss 0.080206
[epoch12, step280]: loss 0.089814
[epoch12, step281]: loss 0.087790
[epoch12, step282]: loss 0.087273
[epoch12, step283]: loss 0.082268
[epoch12, step284]: loss 0.091314
[epoch12, step285]: loss 0.085539
[epoch12, step286]: loss 0.083185
[epoch12, step287]: loss 0.089092
[epoch12, step288]: loss 0.081046
[epoch12, step289]: loss 0.089280
[epoch12, step290]: loss 0.087488
[epoch12, step291]: loss 0.087669
[epoch12, step292]: loss 0.082490
[epoch12, step293]: loss 0.090906
[epoch12, step294]: loss 0.086724
[epoch12, step295]: loss 0.080573
[epoch12, step296]: loss 0.088218
[epoch12, step297]: loss 0.081141
[epoch12, step298]: loss 0.089595
[epoch12, step299]: loss 0.088532
[epoch12, step300]: loss 0.087366
[epoch12, step301]: loss 0.082535
[epoch12, step302]: loss 0.090052
[epoch12, step303]: loss 0.085853
[epoch12, step304]: loss 0.079510
[epoch12, step305]: loss 0.089469
[epoch12, step306]: loss 0.080348
[epoch12, step307]: loss 0.090089
[epoch12, step308]: loss 0.086776
[epoch12, step309]: loss 0.086978
[epoch12, step310]: loss 0.081898
[epoch12, step311]: loss 0.089728
[epoch12, step312]: loss 0.086546
[epoch12, step313]: loss 0.080975
[epoch12, step314]: loss 0.088931
[epoch12, step315]: loss 0.080440
[epoch12, step316]: loss 0.090175
[epoch12, step317]: loss 0.086901
[epoch12, step318]: loss 0.087826
[epoch12, step319]: loss 0.082395
[epoch12, step320]: loss 0.091710
[epoch12, step321]: loss 0.086580
[epoch12, step322]: loss 0.081770
[epoch12, step323]: loss 0.089866
[epoch12, step324]: loss 0.079750
[epoch12, step325]: loss 0.089262
[epoch12, step326]: loss 0.087451
[epoch12, step327]: loss 0.088514
[epoch12, step328]: loss 0.081814
[epoch12, step329]: loss 0.090889
[epoch12, step330]: loss 0.086892
[epoch12, step331]: loss 0.080851
[epoch12, step332]: loss 0.089582
[epoch12, step333]: loss 0.080732
[epoch12, step334]: loss 0.089348
[epoch12, step335]: loss 0.087180
[epoch12, step336]: loss 0.086706
[epoch12, step337]: loss 0.080242
[epoch12, step338]: loss 0.091144
[epoch12, step339]: loss 0.086641
[epoch12, step340]: loss 0.080722
[epoch12, step341]: loss 0.089383
[epoch12, step342]: loss 0.079917
[epoch12, step343]: loss 0.088814
[epoch12, step344]: loss 0.087307
[epoch12, step345]: loss 0.088414
[epoch12, step346]: loss 0.082032
[epoch12, step347]: loss 0.090610
[epoch12, step348]: loss 0.085418
[epoch12, step349]: loss 0.079558
[epoch12, step350]: loss 0.089381
[epoch12, step351]: loss 0.080395
[epoch12, step352]: loss 0.089094
[epoch12, step353]: loss 0.087066
[epoch12, step354]: loss 0.088791
[epoch12, step355]: loss 0.082102
[epoch12, step356]: loss 0.089398
[epoch12, step357]: loss 0.085550
[epoch12, step358]: loss 0.082065
[epoch12, step359]: loss 0.087657
[epoch12, step360]: loss 0.080131
[epoch12, step361]: loss 0.090002
[epoch12, step362]: loss 0.086231
[epoch12, step363]: loss 0.087965
[epoch12, step364]: loss 0.081471
[epoch12, step365]: loss 0.090150
[epoch12, step366]: loss 0.085555
[epoch12, step367]: loss 0.080929
[epoch12, step368]: loss 0.089276
[epoch12, step369]: loss 0.080312
[epoch12, step370]: loss 0.088549
[epoch12, step371]: loss 0.085763
[epoch12, step372]: loss 0.087754
[epoch12, step373]: loss 0.080873
[epoch12, step374]: loss 0.090734
[epoch12, step375]: loss 0.085111
[epoch12, step376]: loss 0.078726
[epoch12, step377]: loss 0.088164
[epoch12, step378]: loss 0.080382
[epoch12, step379]: loss 0.088413
[epoch12, step380]: loss 0.086159
[epoch12, step381]: loss 0.087605
[epoch12, step382]: loss 0.082591
[epoch12, step383]: loss 0.091385
[epoch12, step384]: loss 0.086633
[epoch12, step385]: loss 0.078810
[epoch12, step386]: loss 0.088387
[epoch12, step387]: loss 0.079122
[epoch12, step388]: loss 0.088129
[epoch12, step389]: loss 0.086610
[epoch12, step390]: loss 0.085713
[epoch12, step391]: loss 0.080368
[epoch12, step392]: loss 0.088865
[epoch12, step393]: loss 0.086077
[epoch12, step394]: loss 0.080594
[epoch12, step395]: loss 0.088586
[epoch12, step396]: loss 0.079613
[epoch12, step397]: loss 0.089654
[epoch12, step398]: loss 0.086454
[epoch12, step399]: loss 0.087090
[epoch12, step400]: loss 0.080180
[epoch12, step401]: loss 0.089901
[epoch12, step402]: loss 0.085775
[epoch12, step403]: loss 0.079208
[epoch12, step404]: loss 0.087897
[epoch12, step405]: loss 0.079033
[epoch12, step406]: loss 0.088224
[epoch12, step407]: loss 0.086820
[epoch12, step408]: loss 0.086994
[epoch12, step409]: loss 0.078811
[epoch12, step410]: loss 0.088928
[epoch12, step411]: loss 0.085398
[epoch12, step412]: loss 0.079164
[epoch12, step413]: loss 0.088318
[epoch12, step414]: loss 0.080718
[epoch12, step415]: loss 0.088797
[epoch12, step416]: loss 0.087069
[epoch12, step417]: loss 0.086733
[epoch12, step418]: loss 0.080156
[epoch12, step419]: loss 0.090196
[epoch12, step420]: loss 0.084706
[epoch12, step421]: loss 0.079638
[epoch12, step422]: loss 0.087972
[epoch12, step423]: loss 0.079229
[epoch12, step424]: loss 0.088159
[epoch12, step425]: loss 0.086076
[epoch12, step426]: loss 0.086367
[epoch12, step427]: loss 0.081495
[epoch12, step428]: loss 0.089459
[epoch12, step429]: loss 0.084099
[epoch12, step430]: loss 0.079361
[epoch12, step431]: loss 0.087601
[epoch12, step432]: loss 0.079094
[epoch12, step433]: loss 0.087444
[epoch12, step434]: loss 0.086345
[epoch12, step435]: loss 0.086365
[epoch12, step436]: loss 0.081787
[epoch12, step437]: loss 0.089131
[epoch12, step438]: loss 0.084026
[epoch12, step439]: loss 0.080093
[epoch12, step440]: loss 0.087822
[epoch12, step441]: loss 0.079074
[epoch12, step442]: loss 0.088263
[epoch12, step443]: loss 0.085445
[epoch12, step444]: loss 0.087368
[epoch12, step445]: loss 0.080489
[epoch12, step446]: loss 0.088847
[epoch12, step447]: loss 0.084323
[epoch12, step448]: loss 0.078270
[epoch12, step449]: loss 0.088127
[epoch12, step450]: loss 0.080466
[epoch12, step451]: loss 0.088606
[epoch12, step452]: loss 0.087410
[epoch12, step453]: loss 0.086457
[epoch12, step454]: loss 0.081061
[epoch12, step455]: loss 0.088743
[epoch12, step456]: loss 0.085684
[epoch12, step457]: loss 0.079240
[epoch12, step458]: loss 0.088001
[epoch12, step459]: loss 0.078287
[epoch12, step460]: loss 0.088198
[epoch12, step461]: loss 0.085195
[epoch12, step462]: loss 0.087333
[epoch12, step463]: loss 0.080684
[epoch12, step464]: loss 0.089331
[epoch12, step465]: loss 0.082972
[epoch12, step466]: loss 0.078657
[epoch12, step467]: loss 0.088027
[epoch12, step468]: loss 0.079516
[epoch12, step469]: loss 0.087673
[epoch12, step470]: loss 0.085721
[epoch12, step471]: loss 0.086822
[epoch12, step472]: loss 0.081080
[epoch12, step473]: loss 0.089732
[epoch12, step474]: loss 0.085038
[epoch12, step475]: loss 0.079576
[epoch12, step476]: loss 0.087317
[epoch12, step477]: loss 0.079150
[epoch12, step478]: loss 0.088787
[epoch12, step479]: loss 0.085769
[epoch12, step480]: loss 0.087360
[epoch12, step481]: loss 0.080480
[epoch12, step482]: loss 0.089701
[epoch12, step483]: loss 0.084368
[epoch12, step484]: loss 0.077178
[epoch12, step485]: loss 0.087295
[epoch12, step486]: loss 0.078536
[epoch12, step487]: loss 0.088415
[epoch12, step488]: loss 0.085413
[epoch12, step489]: loss 0.087367
[epoch12, step490]: loss 0.080550
[epoch12, step491]: loss 0.088235
[epoch12, step492]: loss 0.084790
[epoch12, step493]: loss 0.078576
[epoch12, step494]: loss 0.088177
[epoch12, step495]: loss 0.077401
[epoch12, step496]: loss 0.088292
[epoch12, step497]: loss 0.085324
[epoch12, step498]: loss 0.086234
[epoch12, step499]: loss 0.080400
[epoch12, step500]: loss 0.089390
[epoch12, step501]: loss 0.085370
[epoch12, step502]: loss 0.078731
[epoch12, step503]: loss 0.087107
[epoch12, step504]: loss 0.080074
[epoch12, step505]: loss 0.089065
[epoch12, step506]: loss 0.084719
[epoch12, step507]: loss 0.085563
[epoch12, step508]: loss 0.079962
[epoch12, step509]: loss 0.088954
[epoch12, step510]: loss 0.084361
[epoch12, step511]: loss 0.079698
[epoch12, step512]: loss 0.086731
[epoch12, step513]: loss 0.078892
[epoch12, step514]: loss 0.087225
[epoch12, step515]: loss 0.085710
[epoch12, step516]: loss 0.085610
[epoch12, step517]: loss 0.080647
[epoch12, step518]: loss 0.088749
[epoch12, step519]: loss 0.084219
[epoch12, step520]: loss 0.078003
[epoch12, step521]: loss 0.087909
[epoch12, step522]: loss 0.078690
[epoch12, step523]: loss 0.087851
[epoch12, step524]: loss 0.086410
[epoch12, step525]: loss 0.085547
[epoch12, step526]: loss 0.078770
[epoch12, step527]: loss 0.089089
[epoch12, step528]: loss 0.083923
[epoch12, step529]: loss 0.079345
[epoch12, step530]: loss 0.086739
[epoch12, step531]: loss 0.078380
[epoch12, step532]: loss 0.088155
[epoch12, step533]: loss 0.084209
[epoch12, step534]: loss 0.085971
[epoch12, step535]: loss 0.079890
[epoch12, step536]: loss 0.088121
[epoch12, step537]: loss 0.083820
[epoch12, step538]: loss 0.079866
[epoch12, step539]: loss 0.087280
[epoch12, step540]: loss 0.080312
[epoch12, step541]: loss 0.088061
[epoch12, step542]: loss 0.085430
[epoch12, step543]: loss 0.085957
[epoch12, step544]: loss 0.078270
[epoch12, step545]: loss 0.089498
[epoch12, step546]: loss 0.083519
[epoch12, step547]: loss 0.079887
[epoch12, step548]: loss 0.087313
[epoch12, step549]: loss 0.078367
[epoch12, step550]: loss 0.087467
[epoch12, step551]: loss 0.085180
[epoch12, step552]: loss 0.086350
[epoch12, step553]: loss 0.079863
[epoch12, step554]: loss 0.088721
[epoch12, step555]: loss 0.084626
[epoch12, step556]: loss 0.077800
[epoch12, step557]: loss 0.087521
[epoch12, step558]: loss 0.078321
[epoch12, step559]: loss 0.087762
[epoch12, step560]: loss 0.084954
[epoch12, step561]: loss 0.085940
[epoch12, step562]: loss 0.078937
[epoch12, step563]: loss 0.092668
[epoch12, step564]: loss 0.077864
[epoch12, step565]: loss 0.064718
[epoch12, step566]: loss 0.073717
[epoch12, step567]: loss 0.066138
[epoch12, step568]: loss 0.070211
[epoch12, step569]: loss 0.080004
[epoch12, step570]: loss 0.074809
[epoch12, step571]: loss 0.055638
[epoch12, step572]: loss 0.069870
[epoch12, step573]: loss 0.075264
[epoch12, step574]: loss 0.085982
[epoch12, step575]: loss 0.072400
[epoch12, step576]: loss 0.074987
[epoch12, step577]: loss 0.067637
[epoch12, step578]: loss 0.074024
[epoch12, step579]: loss 0.065983
[epoch12, step580]: loss 0.082558
[epoch12, step581]: loss 0.076221
[epoch12, step582]: loss 0.074076
[epoch12, step583]: loss 0.073757
[epoch12, step584]: loss 0.071679
[epoch12, step585]: loss 0.082607
[epoch12, step586]: loss 0.072829
[epoch12, step587]: loss 0.058914
[epoch12, step588]: loss 0.074200
[epoch12, step589]: loss 0.091914
[epoch12, step590]: loss 0.061040
[epoch12, step591]: loss 0.070592
[epoch12, step592]: loss 0.079897
[epoch12, step593]: loss 0.090300
[epoch12, step594]: loss 0.060999
[epoch12, step595]: loss 0.061837
[epoch12, step596]: loss 0.078573
[epoch12, step597]: loss 0.082024
[epoch12, step598]: loss 0.066405
[epoch12, step599]: loss 0.060805
[epoch12, step600]: loss 0.061027
[epoch12, step601]: loss 0.070443
[epoch12, step602]: loss 0.083452
[epoch12, step603]: loss 0.066961
[epoch12, step604]: loss 0.066456
[epoch12, step605]: loss 0.060356
[epoch12, step606]: loss 0.071645
[epoch12, step607]: loss 0.078203
[epoch12, step608]: loss 0.054666
[epoch12, step609]: loss 0.074829
[epoch12, step610]: loss 0.068025
[epoch12, step611]: loss 0.080369
[epoch12, step612]: loss 0.074330
[epoch12, step613]: loss 0.076721
[epoch12, step614]: loss 0.072956
[epoch12, step615]: loss 0.075413
[epoch12, step616]: loss 0.061460
[epoch12, step617]: loss 0.068280
[epoch12, step618]: loss 0.078936
[epoch12, step619]: loss 0.064110
[epoch12, step620]: loss 0.059147
[epoch12, step621]: loss 0.058746
[epoch12, step622]: loss 0.074424
[epoch12, step623]: loss 0.074251
[epoch12, step624]: loss 0.075620
[epoch12, step625]: loss 0.058920
[epoch12, step626]: loss 0.076327
[epoch12, step627]: loss 0.082965
[epoch12, step628]: loss 0.077973
[epoch12, step629]: loss 0.047401
[epoch12, step630]: loss 0.064192
[epoch12, step631]: loss 0.068188
[epoch12, step632]: loss 0.073947
[epoch12, step633]: loss 0.063650
[epoch12, step634]: loss 0.073062
[epoch12, step635]: loss 0.068560
[epoch12, step636]: loss 0.059952
[epoch12, step637]: loss 0.080144
[epoch12, step638]: loss 0.074842
[epoch12, step639]: loss 0.059213
[epoch12, step640]: loss 0.079236
[epoch12, step641]: loss 0.065085
[epoch12, step642]: loss 0.060284
[epoch12, step643]: loss 0.076780
[epoch12, step644]: loss 0.068449
[epoch12, step645]: loss 0.055245
[epoch12, step646]: loss 0.071336
[epoch12, step647]: loss 0.056802
[epoch12, step648]: loss 0.083252
[epoch12, step649]: loss 0.075823
[epoch12, step650]: loss 0.075861
[epoch12, step651]: loss 0.068387
[epoch12, step652]: loss 0.082676
[epoch12, step653]: loss 0.080883
[epoch12, step654]: loss 0.075042
[epoch12, step655]: loss 0.061888
[epoch12, step656]: loss 0.078216
[epoch12, step657]: loss 0.080436
[epoch12, step658]: loss 0.064938
[epoch12, step659]: loss 0.058794
[epoch12, step660]: loss 0.070350
[epoch12, step661]: loss 0.075324
[epoch12, step662]: loss 0.057841
[epoch12, step663]: loss 0.067042
[epoch12, step664]: loss 0.067320
[epoch12, step665]: loss 0.083021
[epoch12, step666]: loss 0.060372
[epoch12, step667]: loss 0.074526
[epoch12, step668]: loss 0.080788
[epoch12, step669]: loss 0.060815
[epoch12, step670]: loss 0.072876
[epoch12, step671]: loss 0.071905
[epoch12, step672]: loss 0.084894
[epoch12, step673]: loss 0.078179
[epoch12, step674]: loss 0.066386
[epoch12, step675]: loss 0.074988
[epoch12, step676]: loss 0.075839
[epoch12, step677]: loss 0.066323
[epoch12, step678]: loss 0.058481
[epoch12, step679]: loss 0.069599
[epoch12, step680]: loss 0.063151
[epoch12, step681]: loss 0.059168
[epoch12, step682]: loss 0.063279
[epoch12, step683]: loss 0.071564
[epoch12, step684]: loss 0.060842
[epoch12, step685]: loss 0.061824
[epoch12, step686]: loss 0.061156
[epoch12, step687]: loss 0.065611
[epoch12, step688]: loss 0.073750
[epoch12, step689]: loss 0.061345
[epoch12, step690]: loss 0.077464
[epoch12, step691]: loss 0.079859
[epoch12, step692]: loss 0.075980
[epoch12, step693]: loss 0.073275
[epoch12, step694]: loss 0.057472
[epoch12, step695]: loss 0.066622
[epoch12, step696]: loss 0.062261
[epoch12, step697]: loss 0.072978
[epoch12, step698]: loss 0.065821
[epoch12, step699]: loss 0.066864
[epoch12, step700]: loss 0.082238
[epoch12, step701]: loss 0.074788
[epoch12, step702]: loss 0.064502
[epoch12, step703]: loss 0.081499
[epoch12, step704]: loss 0.077116
[epoch12, step705]: loss 0.061804
[epoch12, step706]: loss 0.063686
[epoch12, step707]: loss 0.065337
[epoch12, step708]: loss 0.071112
[epoch12, step709]: loss 0.065232
[epoch12, step710]: loss 0.070903
[epoch12, step711]: loss 0.076568
[epoch12, step712]: loss 0.059429
[epoch12, step713]: loss 0.065421
[epoch12, step714]: loss 0.071738
[epoch12, step715]: loss 0.063348
[epoch12, step716]: loss 0.072831
[epoch12, step717]: loss 0.062182
[epoch12, step718]: loss 0.069040
[epoch12, step719]: loss 0.074351
[epoch12, step720]: loss 0.061793
[epoch12, step721]: loss 0.066593
[epoch12, step722]: loss 0.074399
[epoch12, step723]: loss 0.069036
[epoch12, step724]: loss 0.071522
[epoch12, step725]: loss 0.074304
[epoch12, step726]: loss 0.053986
[epoch12, step727]: loss 0.071449
[epoch12, step728]: loss 0.072802
[epoch12, step729]: loss 0.058756
[epoch12, step730]: loss 0.071469
[epoch12, step731]: loss 0.077343
[epoch12, step732]: loss 0.066915
[epoch12, step733]: loss 0.056202
[epoch12, step734]: loss 0.062426
[epoch12, step735]: loss 0.064672
[epoch12, step736]: loss 0.065733
[epoch12, step737]: loss 0.060807
[epoch12, step738]: loss 0.061555
[epoch12, step739]: loss 0.083592
[epoch12, step740]: loss 0.085902
[epoch12, step741]: loss 0.070375
[epoch12, step742]: loss 0.076870
[epoch12, step743]: loss 0.068140
[epoch12, step744]: loss 0.068000
[epoch12, step745]: loss 0.068919
[epoch12, step746]: loss 0.073145
[epoch12, step747]: loss 0.068331
[epoch12, step748]: loss 0.062590
[epoch12, step749]: loss 0.084430
[epoch12, step750]: loss 0.074671
[epoch12, step751]: loss 0.063380
[epoch12, step752]: loss 0.060746
[epoch12, step753]: loss 0.061542
[epoch12, step754]: loss 0.076565
[epoch12, step755]: loss 0.073146
[epoch12, step756]: loss 0.056275
[epoch12, step757]: loss 0.066569
[epoch12, step758]: loss 0.073986
[epoch12, step759]: loss 0.060322
[epoch12, step760]: loss 0.071737
[epoch12, step761]: loss 0.067557
[epoch12, step762]: loss 0.061507
[epoch12, step763]: loss 0.064300
[epoch12, step764]: loss 0.070279
[epoch12, step765]: loss 0.063199
[epoch12, step766]: loss 0.059956
[epoch12, step767]: loss 0.073977
[epoch12, step768]: loss 0.067238
[epoch12, step769]: loss 0.070318
[epoch12, step770]: loss 0.082154
[epoch12, step771]: loss 0.059174
[epoch12, step772]: loss 0.063336
[epoch12, step773]: loss 0.067292
[epoch12, step774]: loss 0.067474
[epoch12, step775]: loss 0.078383
[epoch12, step776]: loss 0.072099
[epoch12, step777]: loss 0.064158
[epoch12, step778]: loss 0.077567
[epoch12, step779]: loss 0.065540
[epoch12, step780]: loss 0.071099
[epoch12, step781]: loss 0.081642
[epoch12, step782]: loss 0.076589
[epoch12, step783]: loss 0.066139
[epoch12, step784]: loss 0.074462
[epoch12, step785]: loss 0.073525
[epoch12, step786]: loss 0.067547
[epoch12, step787]: loss 0.079697
[epoch12, step788]: loss 0.069369
[epoch12, step789]: loss 0.076562
[epoch12, step790]: loss 0.059077
[epoch12, step791]: loss 0.073633
[epoch12, step792]: loss 0.072757
[epoch12, step793]: loss 0.074385
[epoch12, step794]: loss 0.067121
[epoch12, step795]: loss 0.068444
[epoch12, step796]: loss 0.066742
[epoch12, step797]: loss 0.062793
[epoch12, step798]: loss 0.063084
[epoch12, step799]: loss 0.055396
[epoch12, step800]: loss 0.081753
[epoch12, step801]: loss 0.077376
[epoch12, step802]: loss 0.066274
[epoch12, step803]: loss 0.064418
[epoch12, step804]: loss 0.073733
[epoch12, step805]: loss 0.067428
[epoch12, step806]: loss 0.067157
[epoch12, step807]: loss 0.072730
[epoch12, step808]: loss 0.079276
[epoch12, step809]: loss 0.062894
[epoch12, step810]: loss 0.057154
[epoch12, step811]: loss 0.069536
[epoch12, step812]: loss 0.072784
[epoch12, step813]: loss 0.062979
[epoch12, step814]: loss 0.070718
[epoch12, step815]: loss 0.067422
[epoch12, step816]: loss 0.067709
[epoch12, step817]: loss 0.060830
[epoch12, step818]: loss 0.064228
[epoch12, step819]: loss 0.089137
[epoch12, step820]: loss 0.061325
[epoch12, step821]: loss 0.060449
[epoch12, step822]: loss 0.073079
[epoch12, step823]: loss 0.060431
[epoch12, step824]: loss 0.070314
[epoch12, step825]: loss 0.071414
[epoch12, step826]: loss 0.053243
[epoch12, step827]: loss 0.063590
[epoch12, step828]: loss 0.069888
[epoch12, step829]: loss 0.064809
[epoch12, step830]: loss 0.050903
[epoch12, step831]: loss 0.061423
[epoch12, step832]: loss 0.078876
[epoch12, step833]: loss 0.071730
[epoch12, step834]: loss 0.068236
[epoch12, step835]: loss 0.067997
[epoch12, step836]: loss 0.062833
[epoch12, step837]: loss 0.060246
[epoch12, step838]: loss 0.075837
[epoch12, step839]: loss 0.069237
[epoch12, step840]: loss 0.061101
[epoch12, step841]: loss 0.067204
[epoch12, step842]: loss 0.069175
[epoch12, step843]: loss 0.074104
[epoch12, step844]: loss 0.073902
[epoch12, step845]: loss 0.068997
[epoch12, step846]: loss 0.085152
[epoch12, step847]: loss 0.069104
[epoch12, step848]: loss 0.044473
[epoch12, step849]: loss 0.064079
[epoch12, step850]: loss 0.073186
[epoch12, step851]: loss 0.065579
[epoch12, step852]: loss 0.067014
[epoch12, step853]: loss 0.075080
[epoch12, step854]: loss 0.073254
[epoch12, step855]: loss 0.063075
[epoch12, step856]: loss 0.056488
[epoch12, step857]: loss 0.072056
[epoch12, step858]: loss 0.072090
[epoch12, step859]: loss 0.061668
[epoch12, step860]: loss 0.074243
[epoch12, step861]: loss 0.067878
[epoch12, step862]: loss 0.057102
[epoch12, step863]: loss 0.071951
[epoch12, step864]: loss 0.076904
[epoch12, step865]: loss 0.070154
[epoch12, step866]: loss 0.073631
[epoch12, step867]: loss 0.065144
[epoch12, step868]: loss 0.071225
[epoch12, step869]: loss 0.060784
[epoch12, step870]: loss 0.062198
[epoch12, step871]: loss 0.078771
[epoch12, step872]: loss 0.072217
[epoch12, step873]: loss 0.059528
[epoch12, step874]: loss 0.066525
[epoch12, step875]: loss 0.081663
[epoch12, step876]: loss 0.074923
[epoch12, step877]: loss 0.044831
[epoch12, step878]: loss 0.061890
[epoch12, step879]: loss 0.067002
[epoch12, step880]: loss 0.063162
[epoch12, step881]: loss 0.073975
[epoch12, step882]: loss 0.061080
[epoch12, step883]: loss 0.063871
[epoch12, step884]: loss 0.080989
[epoch12, step885]: loss 0.080667
[epoch12, step886]: loss 0.078242
[epoch12, step887]: loss 0.080848
[epoch12, step888]: loss 0.064468
[epoch12, step889]: loss 0.072438
[epoch12, step890]: loss 0.072485
[epoch12, step891]: loss 0.063986
[epoch12, step892]: loss 0.071969
[epoch12, step893]: loss 0.071746
[epoch12, step894]: loss 0.072058
[epoch12, step895]: loss 0.057869
[epoch12, step896]: loss 0.084497
[epoch12, step897]: loss 0.084775
[epoch12, step898]: loss 0.061777
[epoch12, step899]: loss 0.050055
[epoch12, step900]: loss 0.068969
[epoch12, step901]: loss 0.076518
[epoch12, step902]: loss 0.061433
[epoch12, step903]: loss 0.077478
[epoch12, step904]: loss 0.063215
[epoch12, step905]: loss 0.060118
[epoch12, step906]: loss 0.055215
[epoch12, step907]: loss 0.073192
[epoch12, step908]: loss 0.076932
[epoch12, step909]: loss 0.065890
[epoch12, step910]: loss 0.056179
[epoch12, step911]: loss 0.056837
[epoch12, step912]: loss 0.073052
[epoch12, step913]: loss 0.073925
[epoch12, step914]: loss 0.071342
[epoch12, step915]: loss 0.060982
[epoch12, step916]: loss 0.069558
[epoch12, step917]: loss 0.068042
[epoch12, step918]: loss 0.076467
[epoch12, step919]: loss 0.058664
[epoch12, step920]: loss 0.077831
[epoch12, step921]: loss 0.062477
[epoch12, step922]: loss 0.063487
[epoch12, step923]: loss 0.076909
[epoch12, step924]: loss 0.060468
[epoch12, step925]: loss 0.064167
[epoch12, step926]: loss 0.065486
[epoch12, step927]: loss 0.076678
[epoch12, step928]: loss 0.062433
[epoch12, step929]: loss 0.066829
[epoch12, step930]: loss 0.068448
[epoch12, step931]: loss 0.074415
[epoch12, step932]: loss 0.061153
[epoch12, step933]: loss 0.066560
[epoch12, step934]: loss 0.076781
[epoch12, step935]: loss 0.067253
[epoch12, step936]: loss 0.060710
[epoch12, step937]: loss 0.059953
[epoch12, step938]: loss 0.081344
[epoch12, step939]: loss 0.061646
[epoch12, step940]: loss 0.073757
[epoch12, step941]: loss 0.070516
[epoch12, step942]: loss 0.068587
[epoch12, step943]: loss 0.076361
[epoch12, step944]: loss 0.070187
[epoch12, step945]: loss 0.072900
[epoch12, step946]: loss 0.067995
[epoch12, step947]: loss 0.062999
[epoch12, step948]: loss 0.086112
[epoch12, step949]: loss 0.066842
[epoch12, step950]: loss 0.067326
[epoch12, step951]: loss 0.073457
[epoch12, step952]: loss 0.073284
[epoch12, step953]: loss 0.069110
[epoch12, step954]: loss 0.069794
[epoch12, step955]: loss 0.063970
[epoch12, step956]: loss 0.093246
[epoch12, step957]: loss 0.083267
[epoch12, step958]: loss 0.091501
[epoch12, step959]: loss 0.088455
[epoch12, step960]: loss 0.081393
[epoch12, step961]: loss 0.086947
[epoch12, step962]: loss 0.085732
[epoch12, step963]: loss 0.087369
[epoch12, step964]: loss 0.082226
[epoch12, step965]: loss 0.089268
[epoch12, step966]: loss 0.079747
[epoch12, step967]: loss 0.086774
[epoch12, step968]: loss 0.084139
[epoch12, step969]: loss 0.076812
[epoch12, step970]: loss 0.082931
[epoch12, step971]: loss 0.082561
[epoch12, step972]: loss 0.083501
[epoch12, step973]: loss 0.081134
[epoch12, step974]: loss 0.084234
[epoch12, step975]: loss 0.078017
[epoch12, step976]: loss 0.085657
[epoch12, step977]: loss 0.081879
[epoch12, step978]: loss 0.075890
[epoch12, step979]: loss 0.082286
[epoch12, step980]: loss 0.081659
[epoch12, step981]: loss 0.084276
[epoch12, step982]: loss 0.079824
[epoch12, step983]: loss 0.084080
[epoch12, step984]: loss 0.077576
[epoch12, step985]: loss 0.085782
[epoch12, step986]: loss 0.081225
[epoch12, step987]: loss 0.073991
[epoch12, step988]: loss 0.080185
[epoch12, step989]: loss 0.080510
[epoch12, step990]: loss 0.084021
[epoch12, step991]: loss 0.078188
[epoch12, step992]: loss 0.083757
[epoch12, step993]: loss 0.077672
[epoch12, step994]: loss 0.085815
[epoch12, step995]: loss 0.081742
[epoch12, step996]: loss 0.074463
[epoch12, step997]: loss 0.080564
[epoch12, step998]: loss 0.080353
[epoch12, step999]: loss 0.083242
[epoch12, step1000]: loss 0.079142
[epoch12, step1001]: loss 0.083674
[epoch12, step1002]: loss 0.076358
[epoch12, step1003]: loss 0.085279
[epoch12, step1004]: loss 0.080779
[epoch12, step1005]: loss 0.074511
[epoch12, step1006]: loss 0.080731
[epoch12, step1007]: loss 0.080802
[epoch12, step1008]: loss 0.083664
[epoch12, step1009]: loss 0.078702
[epoch12, step1010]: loss 0.082681
[epoch12, step1011]: loss 0.076731
[epoch12, step1012]: loss 0.084063
[epoch12, step1013]: loss 0.081111
[epoch12, step1014]: loss 0.074295
[epoch12, step1015]: loss 0.080055
[epoch12, step1016]: loss 0.080640
[epoch12, step1017]: loss 0.083448
[epoch12, step1018]: loss 0.078366
[epoch12, step1019]: loss 0.083175
[epoch12, step1020]: loss 0.077031
[epoch12, step1021]: loss 0.085055
[epoch12, step1022]: loss 0.081106
[epoch12, step1023]: loss 0.074267
[epoch12, step1024]: loss 0.078977
[epoch12, step1025]: loss 0.081134
[epoch12, step1026]: loss 0.083772
[epoch12, step1027]: loss 0.077905
[epoch12, step1028]: loss 0.083137
[epoch12, step1029]: loss 0.076484
[epoch12, step1030]: loss 0.085030
[epoch12, step1031]: loss 0.082665
[epoch12, step1032]: loss 0.073941
[epoch12, step1033]: loss 0.081140
[epoch12, step1034]: loss 0.081011
[epoch12, step1035]: loss 0.083861
[epoch12, step1036]: loss 0.078798
[epoch12, step1037]: loss 0.083427
[epoch12, step1038]: loss 0.076540
[epoch12, step1039]: loss 0.084372
[epoch12, step1040]: loss 0.081600
[epoch12, step1041]: loss 0.074632
[epoch12, step1042]: loss 0.080037
[epoch12, step1043]: loss 0.080385
[epoch12, step1044]: loss 0.082664
[epoch12, step1045]: loss 0.077989
[epoch12, step1046]: loss 0.082852
[epoch12, step1047]: loss 0.075761
[epoch12, step1048]: loss 0.085090
[epoch12, step1049]: loss 0.080804
[epoch12, step1050]: loss 0.074027
[epoch12, step1051]: loss 0.079754
[epoch12, step1052]: loss 0.080436
[epoch12, step1053]: loss 0.083094
[epoch12, step1054]: loss 0.078720
[epoch12, step1055]: loss 0.083362
[epoch12, step1056]: loss 0.076681
[epoch12, step1057]: loss 0.083683
[epoch12, step1058]: loss 0.079961
[epoch12, step1059]: loss 0.073990
[epoch12, step1060]: loss 0.078976
[epoch12, step1061]: loss 0.081184
[epoch12, step1062]: loss 0.082381
[epoch12, step1063]: loss 0.078436
[epoch12, step1064]: loss 0.082979
[epoch12, step1065]: loss 0.076915
[epoch12, step1066]: loss 0.084755
[epoch12, step1067]: loss 0.080729
[epoch12, step1068]: loss 0.075823
[epoch12, step1069]: loss 0.078705
[epoch12, step1070]: loss 0.080036
[epoch12, step1071]: loss 0.082035
[epoch12, step1072]: loss 0.077373
[epoch12, step1073]: loss 0.082838
[epoch12, step1074]: loss 0.076897
[epoch12, step1075]: loss 0.083817
[epoch12, step1076]: loss 0.080415
[epoch12, step1077]: loss 0.073425
[epoch12, step1078]: loss 0.079957
[epoch12, step1079]: loss 0.079125
[epoch12, step1080]: loss 0.082261
[epoch12, step1081]: loss 0.078827
[epoch12, step1082]: loss 0.082845
[epoch12, step1083]: loss 0.076074
[epoch12, step1084]: loss 0.083815
[epoch12, step1085]: loss 0.081122
[epoch12, step1086]: loss 0.074793
[epoch12, step1087]: loss 0.079773
[epoch12, step1088]: loss 0.080333
[epoch12, step1089]: loss 0.082033
[epoch12, step1090]: loss 0.077556
[epoch12, step1091]: loss 0.082443
[epoch12, step1092]: loss 0.076478
[epoch12, step1093]: loss 0.083798
[epoch12, step1094]: loss 0.081490
[epoch12, step1095]: loss 0.073469
[epoch12, step1096]: loss 0.080148
[epoch12, step1097]: loss 0.079621
[epoch12, step1098]: loss 0.082571
[epoch12, step1099]: loss 0.078428
[epoch12, step1100]: loss 0.081943
[epoch12, step1101]: loss 0.076845
[epoch12, step1102]: loss 0.084225
[epoch12, step1103]: loss 0.080919
[epoch12, step1104]: loss 0.073611
[epoch12, step1105]: loss 0.078938
[epoch12, step1106]: loss 0.080667
[epoch12, step1107]: loss 0.082254
[epoch12, step1108]: loss 0.078354
[epoch12, step1109]: loss 0.081866
[epoch12, step1110]: loss 0.075250
[epoch12, step1111]: loss 0.083645
[epoch12, step1112]: loss 0.080020
[epoch12, step1113]: loss 0.073566
[epoch12, step1114]: loss 0.079174
[epoch12, step1115]: loss 0.079284
[epoch12, step1116]: loss 0.082057
[epoch12, step1117]: loss 0.077723
[epoch12, step1118]: loss 0.082531
[epoch12, step1119]: loss 0.077102
[epoch12, step1120]: loss 0.084066
[epoch12, step1121]: loss 0.080362
[epoch12, step1122]: loss 0.073785
[epoch12, step1123]: loss 0.079740
[epoch12, step1124]: loss 0.079169
[epoch12, step1125]: loss 0.081850
[epoch12, step1126]: loss 0.077146
[epoch12, step1127]: loss 0.082121
[epoch12, step1128]: loss 0.076317
[epoch12, step1129]: loss 0.083873
[epoch12, step1130]: loss 0.079040
[epoch12, step1131]: loss 0.073088
[epoch12, step1132]: loss 0.078805
[epoch12, step1133]: loss 0.080038
[epoch12, step1134]: loss 0.082271
[epoch12, step1135]: loss 0.076359
[epoch12, step1136]: loss 0.081455
[epoch12, step1137]: loss 0.074913
[epoch12, step1138]: loss 0.083244
[epoch12, step1139]: loss 0.080459
[epoch12, step1140]: loss 0.072979
[epoch12, step1141]: loss 0.078468
[epoch12, step1142]: loss 0.079969
[epoch12, step1143]: loss 0.082488
[epoch12, step1144]: loss 0.077951
[epoch12, step1145]: loss 0.082649
[epoch12, step1146]: loss 0.075113
[epoch12, step1147]: loss 0.082501
[epoch12, step1148]: loss 0.080285
[epoch12, step1149]: loss 0.072898
[epoch12, step1150]: loss 0.079527
[epoch12, step1151]: loss 0.079551
[epoch12, step1152]: loss 0.081166
[epoch12, step1153]: loss 0.077894
[epoch12, step1154]: loss 0.081696
[epoch12, step1155]: loss 0.075616
[epoch12, step1156]: loss 0.084126
[epoch12, step1157]: loss 0.080527
[epoch12, step1158]: loss 0.072657
[epoch12, step1159]: loss 0.078555
[epoch12, step1160]: loss 0.078747
[epoch12, step1161]: loss 0.081314
[epoch12, step1162]: loss 0.077504
[epoch12, step1163]: loss 0.082744
[epoch12, step1164]: loss 0.074996
[epoch12, step1165]: loss 0.082066
[epoch12, step1166]: loss 0.079517
[epoch12, step1167]: loss 0.073080
[epoch12, step1168]: loss 0.078623
[epoch12, step1169]: loss 0.079528
[epoch12, step1170]: loss 0.081741
[epoch12, step1171]: loss 0.077510
[epoch12, step1172]: loss 0.082110
[epoch12, step1173]: loss 0.075777
[epoch12, step1174]: loss 0.082647
[epoch12, step1175]: loss 0.080209
[epoch12, step1176]: loss 0.073123
[epoch12, step1177]: loss 0.078030
[epoch12, step1178]: loss 0.078733
[epoch12, step1179]: loss 0.081732
[epoch12, step1180]: loss 0.077241
[epoch12, step1181]: loss 0.081384
[epoch12, step1182]: loss 0.075615
[epoch12, step1183]: loss 0.082518
[epoch12, step1184]: loss 0.080467
[epoch12, step1185]: loss 0.073865
[epoch12, step1186]: loss 0.078816
[epoch12, step1187]: loss 0.079996
[epoch12, step1188]: loss 0.082123
[epoch12, step1189]: loss 0.076969
[epoch12, step1190]: loss 0.082290
[epoch12, step1191]: loss 0.075607
[epoch12, step1192]: loss 0.082394
[epoch12, step1193]: loss 0.079536
[epoch12, step1194]: loss 0.072675
[epoch12, step1195]: loss 0.079946
[epoch12, step1196]: loss 0.079513
[epoch12, step1197]: loss 0.081329
[epoch12, step1198]: loss 0.076745
[epoch12, step1199]: loss 0.081916
[epoch12, step1200]: loss 0.075042
[epoch12, step1201]: loss 0.082179
[epoch12, step1202]: loss 0.078742
[epoch12, step1203]: loss 0.073844
[epoch12, step1204]: loss 0.078689
[epoch12, step1205]: loss 0.078916
[epoch12, step1206]: loss 0.081853
[epoch12, step1207]: loss 0.076409
[epoch12, step1208]: loss 0.081361
[epoch12, step1209]: loss 0.075290
[epoch12, step1210]: loss 0.082546
[epoch12, step1211]: loss 0.080191
[epoch12, step1212]: loss 0.073954
[epoch12, step1213]: loss 0.079819
[epoch12, step1214]: loss 0.078769
[epoch12, step1215]: loss 0.080935
[epoch12, step1216]: loss 0.076901
[epoch12, step1217]: loss 0.080894
[epoch12, step1218]: loss 0.074863
[epoch12, step1219]: loss 0.082047
[epoch12, step1220]: loss 0.079034
[epoch12, step1221]: loss 0.072562
[epoch12, step1222]: loss 0.078391
[epoch12, step1223]: loss 0.078456
[epoch12, step1224]: loss 0.080619
[epoch12, step1225]: loss 0.076847
[epoch12, step1226]: loss 0.081974
[epoch12, step1227]: loss 0.074409
[epoch12, step1228]: loss 0.082754
[epoch12, step1229]: loss 0.080457
[epoch12, step1230]: loss 0.074069
[epoch12, step1231]: loss 0.078861
[epoch12, step1232]: loss 0.078488
[epoch12, step1233]: loss 0.081710
[epoch12, step1234]: loss 0.076818
[epoch12, step1235]: loss 0.081327
[epoch12, step1236]: loss 0.076007
[epoch12, step1237]: loss 0.083035
[epoch12, step1238]: loss 0.080094
[epoch12, step1239]: loss 0.071915
[epoch12, step1240]: loss 0.077757
[epoch12, step1241]: loss 0.079693
[epoch12, step1242]: loss 0.081287
[epoch12, step1243]: loss 0.076138
[epoch12, step1244]: loss 0.081058
[epoch12, step1245]: loss 0.073816
[epoch12, step1246]: loss 0.082138
[epoch12, step1247]: loss 0.080298
[epoch12, step1248]: loss 0.072582
[epoch12, step1249]: loss 0.077609
[epoch12, step1250]: loss 0.078554
[epoch12, step1251]: loss 0.080786
[epoch12, step1252]: loss 0.076930
[epoch12, step1253]: loss 0.080868
[epoch12, step1254]: loss 0.075099
[epoch12, step1255]: loss 0.082447
[epoch12, step1256]: loss 0.078862
[epoch12, step1257]: loss 0.072416
[epoch12, step1258]: loss 0.078240
[epoch12, step1259]: loss 0.078973
[epoch12, step1260]: loss 0.081028
[epoch12, step1261]: loss 0.076911
[epoch12, step1262]: loss 0.082295
[epoch12, step1263]: loss 0.073854
[epoch12, step1264]: loss 0.082778
[epoch12, step1265]: loss 0.080660
[epoch12, step1266]: loss 0.073273
[epoch12, step1267]: loss 0.078152
[epoch12, step1268]: loss 0.078502
[epoch12, step1269]: loss 0.080840
[epoch12, step1270]: loss 0.077069
[epoch12, step1271]: loss 0.080802
[epoch12, step1272]: loss 0.074620
[epoch12, step1273]: loss 0.082645
[epoch12, step1274]: loss 0.079760
[epoch12, step1275]: loss 0.072663
[epoch12, step1276]: loss 0.077879
[epoch12, step1277]: loss 0.078334
[epoch12, step1278]: loss 0.080147
[epoch12, step1279]: loss 0.076152
[epoch12, step1280]: loss 0.080886
[epoch12, step1281]: loss 0.074854
[epoch12, step1282]: loss 0.081927
[epoch12, step1283]: loss 0.079650
[epoch12, step1284]: loss 0.071555
[epoch12, step1285]: loss 0.078031
[epoch12, step1286]: loss 0.078788
[epoch12, step1287]: loss 0.079773
[epoch12, step1288]: loss 0.076229
[epoch12, step1289]: loss 0.080352
[epoch12, step1290]: loss 0.075304
[epoch12, step1291]: loss 0.082601
[epoch12, step1292]: loss 0.078233
[epoch12, step1293]: loss 0.072227
[epoch12, step1294]: loss 0.077924
[epoch12, step1295]: loss 0.077448
[epoch12, step1296]: loss 0.080556
[epoch12, step1297]: loss 0.075571
[epoch12, step1298]: loss 0.080270
[epoch12, step1299]: loss 0.074967
[epoch12, step1300]: loss 0.081479
[epoch12, step1301]: loss 0.080041
[epoch12, step1302]: loss 0.072249
[epoch12, step1303]: loss 0.078355
[epoch12, step1304]: loss 0.078557
[epoch12, step1305]: loss 0.079820
[epoch12, step1306]: loss 0.076246
[epoch12, step1307]: loss 0.081396
[epoch12, step1308]: loss 0.075164
[epoch12, step1309]: loss 0.082416
[epoch12, step1310]: loss 0.079123
[epoch12, step1311]: loss 0.072707
[epoch12, step1312]: loss 0.077961
[epoch12, step1313]: loss 0.078487
[epoch12, step1314]: loss 0.080794
[epoch12, step1315]: loss 0.076491
[epoch12, step1316]: loss 0.080013
[epoch12, step1317]: loss 0.074972
[epoch12, step1318]: loss 0.082848
[epoch12, step1319]: loss 0.079237
[epoch12, step1320]: loss 0.072415
[epoch12, step1321]: loss 0.077044
[epoch12, step1322]: loss 0.078444
[epoch12, step1323]: loss 0.080104
[epoch12, step1324]: loss 0.076304
[epoch12, step1325]: loss 0.080799
[epoch12, step1326]: loss 0.075242
[epoch12, step1327]: loss 0.081639
[epoch12, step1328]: loss 0.078760
[epoch12, step1329]: loss 0.072366
[epoch12, step1330]: loss 0.077462
[epoch12, step1331]: loss 0.078323
[epoch12, step1332]: loss 0.080649
[epoch12, step1333]: loss 0.077308
[epoch12, step1334]: loss 0.080180
[epoch12, step1335]: loss 0.074737
[epoch12, step1336]: loss 0.081523
[epoch12, step1337]: loss 0.079880
[epoch12, step1338]: loss 0.071672
[epoch12, step1339]: loss 0.078263
[epoch12, step1340]: loss 0.078912
[epoch12, step1341]: loss 0.080289
[epoch12, step1342]: loss 0.076399
[epoch12, step1343]: loss 0.080705
[epoch12, step1344]: loss 0.073580
[epoch12, step1345]: loss 0.081720
[epoch12, step1346]: loss 0.079181
[epoch12, step1347]: loss 0.071717
[epoch12, step1348]: loss 0.078175
[epoch12, step1349]: loss 0.077777
[epoch12, step1350]: loss 0.079937
[epoch12, step1351]: loss 0.076959
[epoch12, step1352]: loss 0.080829
[epoch12, step1353]: loss 0.075197
[epoch12, step1354]: loss 0.081952
[epoch12, step1355]: loss 0.078707
[epoch12, step1356]: loss 0.073108
[epoch12, step1357]: loss 0.078124
[epoch12, step1358]: loss 0.077689
[epoch12, step1359]: loss 0.080345
[epoch12, step1360]: loss 0.075228
[epoch12, step1361]: loss 0.080136
[epoch12, step1362]: loss 0.074410
[epoch12, step1363]: loss 0.080617
[epoch12, step1364]: loss 0.078707
[epoch12, step1365]: loss 0.072283
[epoch12, step1366]: loss 0.077527
[epoch12, step1367]: loss 0.078362
[epoch12, step1368]: loss 0.078762
[epoch12, step1369]: loss 0.076658
[epoch12, step1370]: loss 0.081176
[epoch12, step1371]: loss 0.073975
[epoch12, step1372]: loss 0.081605
[epoch12, step1373]: loss 0.078866
[epoch12, step1374]: loss 0.071061
[epoch12, step1375]: loss 0.077109
[epoch12, step1376]: loss 0.077520
[epoch12, step1377]: loss 0.081057
[epoch12, step1378]: loss 0.075940
[epoch12, step1379]: loss 0.080724
[epoch12, step1380]: loss 0.072837
[epoch12, step1381]: loss 0.081098
[epoch12, step1382]: loss 0.078414
[epoch12, step1383]: loss 0.071370
[epoch12, step1384]: loss 0.076751
[epoch12, step1385]: loss 0.077709
[epoch12, step1386]: loss 0.079643
[epoch12, step1387]: loss 0.074949
[epoch12, step1388]: loss 0.081164
[epoch12, step1389]: loss 0.074193
[epoch12, step1390]: loss 0.080916
[epoch12, step1391]: loss 0.078581
[epoch12, step1392]: loss 0.072189
[epoch12, step1393]: loss 0.076745
[epoch12, step1394]: loss 0.076994
[epoch12, step1395]: loss 0.079633
[epoch12, step1396]: loss 0.075906
[epoch12, step1397]: loss 0.080772
[epoch12, step1398]: loss 0.073500
[epoch12, step1399]: loss 0.080441
[epoch12, step1400]: loss 0.078655
[epoch12, step1401]: loss 0.070943
[epoch12, step1402]: loss 0.077169
[epoch12, step1403]: loss 0.078096
[epoch12, step1404]: loss 0.080254
[epoch12, step1405]: loss 0.074768
[epoch12, step1406]: loss 0.080400
[epoch12, step1407]: loss 0.073209
[epoch12, step1408]: loss 0.081640
[epoch12, step1409]: loss 0.078689
[epoch12, step1410]: loss 0.070753
[epoch12, step1411]: loss 0.078020
[epoch12, step1412]: loss 0.077428
[epoch12, step1413]: loss 0.079715
[epoch12, step1414]: loss 0.075811
[epoch12, step1415]: loss 0.080198
[epoch12, step1416]: loss 0.072984
[epoch12, step1417]: loss 0.081161
[epoch12, step1418]: loss 0.078494
[epoch12, step1419]: loss 0.070971
[epoch12, step1420]: loss 0.077355
[epoch12, step1421]: loss 0.076985
[epoch12, step1422]: loss 0.079181
[epoch12, step1423]: loss 0.076181
[epoch12, step1424]: loss 0.080393
[epoch12, step1425]: loss 0.073918
[epoch12, step1426]: loss 0.081287
[epoch12, step1427]: loss 0.077489
[epoch12, step1428]: loss 0.072221
[epoch12, step1429]: loss 0.076729
[epoch12, step1430]: loss 0.077511
[epoch12, step1431]: loss 0.079664
[epoch12, step1432]: loss 0.075454
[epoch12, step1433]: loss 0.079902
[epoch12, step1434]: loss 0.075048
[epoch12, step1435]: loss 0.080328
[epoch12, step1436]: loss 0.077745
[epoch12, step1437]: loss 0.070643
[epoch12, step1438]: loss 0.076757
[epoch12, step1439]: loss 0.077655
[epoch12, step1440]: loss 0.079623
[epoch12, step1441]: loss 0.074756
[epoch12, step1442]: loss 0.080611
[epoch12, step1443]: loss 0.075033
[epoch12, step1444]: loss 0.081237
[epoch12, step1445]: loss 0.077914
[epoch12, step1446]: loss 0.070581
[epoch12, step1447]: loss 0.076671
[epoch12, step1448]: loss 0.077431
[epoch12, step1449]: loss 0.079676
[epoch12, step1450]: loss 0.075966
[epoch12, step1451]: loss 0.079861
[epoch12, step1452]: loss 0.073964
[epoch12, step1453]: loss 0.080178
[epoch12, step1454]: loss 0.077730
[epoch12, step1455]: loss 0.070427
[epoch12, step1456]: loss 0.077183
[epoch12, step1457]: loss 0.076238
[epoch12, step1458]: loss 0.079389
[epoch12, step1459]: loss 0.075751
[epoch12, step1460]: loss 0.079321
[epoch12, step1461]: loss 0.072483
[epoch12, step1462]: loss 0.079703
[epoch12, step1463]: loss 0.078283
[epoch12, step1464]: loss 0.070271
[epoch12, step1465]: loss 0.077268
[epoch12, step1466]: loss 0.076930
[epoch12, step1467]: loss 0.079798
[epoch12, step1468]: loss 0.075216
[epoch12, step1469]: loss 0.079751
[epoch12, step1470]: loss 0.073064
[epoch12, step1471]: loss 0.081081
[epoch12, step1472]: loss 0.078248
[epoch12, step1473]: loss 0.070462
[epoch12, step1474]: loss 0.076115
[epoch12, step1475]: loss 0.077137
[epoch12, step1476]: loss 0.078682
[epoch12, step1477]: loss 0.076202
[epoch12, step1478]: loss 0.079874
[epoch12, step1479]: loss 0.073153
[epoch12, step1480]: loss 0.080810
[epoch12, step1481]: loss 0.078914
[epoch12, step1482]: loss 0.071453
[epoch12, step1483]: loss 0.077127
[epoch12, step1484]: loss 0.076618
[epoch12, step1485]: loss 0.079489
[epoch12, step1486]: loss 0.075740
[epoch12, step1487]: loss 0.079504
[epoch12, step1488]: loss 0.073246
[epoch12, step1489]: loss 0.080479
[epoch12, step1490]: loss 0.077388
[epoch12, step1491]: loss 0.071462
[epoch12, step1492]: loss 0.077115
[epoch12, step1493]: loss 0.077043
[epoch12, step1494]: loss 0.079152
[epoch12, step1495]: loss 0.075773
[epoch12, step1496]: loss 0.080191
[epoch12, step1497]: loss 0.073082
[epoch12, step1498]: loss 0.079559
[epoch12, step1499]: loss 0.078458
[epoch12, step1500]: loss 0.070981
[epoch12, step1501]: loss 0.076468
[epoch12, step1502]: loss 0.076997
[epoch12, step1503]: loss 0.079460
[epoch12, step1504]: loss 0.075888
[epoch12, step1505]: loss 0.079750
[epoch12, step1506]: loss 0.073051
[epoch12, step1507]: loss 0.080190
[epoch12, step1508]: loss 0.077561
[epoch12, step1509]: loss 0.071531
[epoch12, step1510]: loss 0.077720
[epoch12, step1511]: loss 0.075934
[epoch12, step1512]: loss 0.078699
[epoch12, step1513]: loss 0.075904
[epoch12, step1514]: loss 0.079389
[epoch12, step1515]: loss 0.073342
[epoch12, step1516]: loss 0.080027

[epoch12]: avg loss 0.079059

[epoch13, step1]: loss 0.080406
[epoch13, step2]: loss 0.078804
[epoch13, step3]: loss 0.079009
[epoch13, step4]: loss 0.074404
[epoch13, step5]: loss 0.080290
[epoch13, step6]: loss 0.077968
[epoch13, step7]: loss 0.071519
[epoch13, step8]: loss 0.079647
[epoch13, step9]: loss 0.072235
[epoch13, step10]: loss 0.078770
[epoch13, step11]: loss 0.078986
[epoch13, step12]: loss 0.078837
[epoch13, step13]: loss 0.072481
[epoch13, step14]: loss 0.080590
[epoch13, step15]: loss 0.077897
[epoch13, step16]: loss 0.072239
[epoch13, step17]: loss 0.079729
[epoch13, step18]: loss 0.071477
[epoch13, step19]: loss 0.079824
[epoch13, step20]: loss 0.077867
[epoch13, step21]: loss 0.078906
[epoch13, step22]: loss 0.073643
[epoch13, step23]: loss 0.081438
[epoch13, step24]: loss 0.077286
[epoch13, step25]: loss 0.071301
[epoch13, step26]: loss 0.080100
[epoch13, step27]: loss 0.072060
[epoch13, step28]: loss 0.079061
[epoch13, step29]: loss 0.078075
[epoch13, step30]: loss 0.077953
[epoch13, step31]: loss 0.073041
[epoch13, step32]: loss 0.079782
[epoch13, step33]: loss 0.077065
[epoch13, step34]: loss 0.071501
[epoch13, step35]: loss 0.079325
[epoch13, step36]: loss 0.072392
[epoch13, step37]: loss 0.079384
[epoch13, step38]: loss 0.079047
[epoch13, step39]: loss 0.079027
[epoch13, step40]: loss 0.072134
[epoch13, step41]: loss 0.081278
[epoch13, step42]: loss 0.077247
[epoch13, step43]: loss 0.072150
[epoch13, step44]: loss 0.079432
[epoch13, step45]: loss 0.072153
[epoch13, step46]: loss 0.079455
[epoch13, step47]: loss 0.078698
[epoch13, step48]: loss 0.078816
[epoch13, step49]: loss 0.072783
[epoch13, step50]: loss 0.080200
[epoch13, step51]: loss 0.077327
[epoch13, step52]: loss 0.072097
[epoch13, step53]: loss 0.078669
[epoch13, step54]: loss 0.071391
[epoch13, step55]: loss 0.078724
[epoch13, step56]: loss 0.077008
[epoch13, step57]: loss 0.078032
[epoch13, step58]: loss 0.072476
[epoch13, step59]: loss 0.081107
[epoch13, step60]: loss 0.076489
[epoch13, step61]: loss 0.071986
[epoch13, step62]: loss 0.079807
[epoch13, step63]: loss 0.072567
[epoch13, step64]: loss 0.079856
[epoch13, step65]: loss 0.078240
[epoch13, step66]: loss 0.078635
[epoch13, step67]: loss 0.073164
[epoch13, step68]: loss 0.080597
[epoch13, step69]: loss 0.077450
[epoch13, step70]: loss 0.072288
[epoch13, step71]: loss 0.080167
[epoch13, step72]: loss 0.071714
[epoch13, step73]: loss 0.079480
[epoch13, step74]: loss 0.077981
[epoch13, step75]: loss 0.078015
[epoch13, step76]: loss 0.073111
[epoch13, step77]: loss 0.079440
[epoch13, step78]: loss 0.076953
[epoch13, step79]: loss 0.072053
[epoch13, step80]: loss 0.078324
[epoch13, step81]: loss 0.071479
[epoch13, step82]: loss 0.079652
[epoch13, step83]: loss 0.078693
[epoch13, step84]: loss 0.078166
[epoch13, step85]: loss 0.071834
[epoch13, step86]: loss 0.079458
[epoch13, step87]: loss 0.076591
[epoch13, step88]: loss 0.074011
[epoch13, step89]: loss 0.079526
[epoch13, step90]: loss 0.072586
[epoch13, step91]: loss 0.080302
[epoch13, step92]: loss 0.077660
[epoch13, step93]: loss 0.078060
[epoch13, step94]: loss 0.073014
[epoch13, step95]: loss 0.079687
[epoch13, step96]: loss 0.077269
[epoch13, step97]: loss 0.071571
[epoch13, step98]: loss 0.079245
[epoch13, step99]: loss 0.071876
[epoch13, step100]: loss 0.080116
[epoch13, step101]: loss 0.076975
[epoch13, step102]: loss 0.078327
[epoch13, step103]: loss 0.072803
[epoch13, step104]: loss 0.079864
[epoch13, step105]: loss 0.076462
[epoch13, step106]: loss 0.071774
[epoch13, step107]: loss 0.078981
[epoch13, step108]: loss 0.071623
[epoch13, step109]: loss 0.079106
[epoch13, step110]: loss 0.077052
[epoch13, step111]: loss 0.078161
[epoch13, step112]: loss 0.073115
[epoch13, step113]: loss 0.078875
[epoch13, step114]: loss 0.077166
[epoch13, step115]: loss 0.071700
[epoch13, step116]: loss 0.078231
[epoch13, step117]: loss 0.071363
[epoch13, step118]: loss 0.078098
[epoch13, step119]: loss 0.077584
[epoch13, step120]: loss 0.077784
[epoch13, step121]: loss 0.072773
[epoch13, step122]: loss 0.079912
[epoch13, step123]: loss 0.076452
[epoch13, step124]: loss 0.072084
[epoch13, step125]: loss 0.078897
[epoch13, step126]: loss 0.071752
[epoch13, step127]: loss 0.079293
[epoch13, step128]: loss 0.077860
[epoch13, step129]: loss 0.077583
[epoch13, step130]: loss 0.071523
[epoch13, step131]: loss 0.080180
[epoch13, step132]: loss 0.076502
[epoch13, step133]: loss 0.070595
[epoch13, step134]: loss 0.079487
[epoch13, step135]: loss 0.070996
[epoch13, step136]: loss 0.077497
[epoch13, step137]: loss 0.077665
[epoch13, step138]: loss 0.077882
[epoch13, step139]: loss 0.072645
[epoch13, step140]: loss 0.078940
[epoch13, step141]: loss 0.076715
[epoch13, step142]: loss 0.071741
[epoch13, step143]: loss 0.079123
[epoch13, step144]: loss 0.072713
[epoch13, step145]: loss 0.079639
[epoch13, step146]: loss 0.077391
[epoch13, step147]: loss 0.077035
[epoch13, step148]: loss 0.072298
[epoch13, step149]: loss 0.079928
[epoch13, step150]: loss 0.077150
[epoch13, step151]: loss 0.070118
[epoch13, step152]: loss 0.078596
[epoch13, step153]: loss 0.070838
[epoch13, step154]: loss 0.079148
[epoch13, step155]: loss 0.077205
[epoch13, step156]: loss 0.078186
[epoch13, step157]: loss 0.071575
[epoch13, step158]: loss 0.078888
[epoch13, step159]: loss 0.076288
[epoch13, step160]: loss 0.070837
[epoch13, step161]: loss 0.077895
[epoch13, step162]: loss 0.070926
[epoch13, step163]: loss 0.078497
[epoch13, step164]: loss 0.076899
[epoch13, step165]: loss 0.077585
[epoch13, step166]: loss 0.071170
[epoch13, step167]: loss 0.079647
[epoch13, step168]: loss 0.075689
[epoch13, step169]: loss 0.071611
[epoch13, step170]: loss 0.078139
[epoch13, step171]: loss 0.071538
[epoch13, step172]: loss 0.078367
[epoch13, step173]: loss 0.077151
[epoch13, step174]: loss 0.078007
[epoch13, step175]: loss 0.070982
[epoch13, step176]: loss 0.079322
[epoch13, step177]: loss 0.076105
[epoch13, step178]: loss 0.070108
[epoch13, step179]: loss 0.079278
[epoch13, step180]: loss 0.070491
[epoch13, step181]: loss 0.078315
[epoch13, step182]: loss 0.076612
[epoch13, step183]: loss 0.076960
[epoch13, step184]: loss 0.071092
[epoch13, step185]: loss 0.078897
[epoch13, step186]: loss 0.075827
[epoch13, step187]: loss 0.071230
[epoch13, step188]: loss 0.078421
[epoch13, step189]: loss 0.070665
[epoch13, step190]: loss 0.078840
[epoch13, step191]: loss 0.076988
[epoch13, step192]: loss 0.076772
[epoch13, step193]: loss 0.073114
[epoch13, step194]: loss 0.079607
[epoch13, step195]: loss 0.075755
[epoch13, step196]: loss 0.069908
[epoch13, step197]: loss 0.078402
[epoch13, step198]: loss 0.071186
[epoch13, step199]: loss 0.078016
[epoch13, step200]: loss 0.076508
[epoch13, step201]: loss 0.076892
[epoch13, step202]: loss 0.072032
[epoch13, step203]: loss 0.079277
[epoch13, step204]: loss 0.075710
[epoch13, step205]: loss 0.071801
[epoch13, step206]: loss 0.078867
[epoch13, step207]: loss 0.070676
[epoch13, step208]: loss 0.077789
[epoch13, step209]: loss 0.076423
[epoch13, step210]: loss 0.076453
[epoch13, step211]: loss 0.071966
[epoch13, step212]: loss 0.078627
[epoch13, step213]: loss 0.076248
[epoch13, step214]: loss 0.071801
[epoch13, step215]: loss 0.077831
[epoch13, step216]: loss 0.070517
[epoch13, step217]: loss 0.078608
[epoch13, step218]: loss 0.076214
[epoch13, step219]: loss 0.077342
[epoch13, step220]: loss 0.072566
[epoch13, step221]: loss 0.078532
[epoch13, step222]: loss 0.075265
[epoch13, step223]: loss 0.069557
[epoch13, step224]: loss 0.078437
[epoch13, step225]: loss 0.070515
[epoch13, step226]: loss 0.078140
[epoch13, step227]: loss 0.077907
[epoch13, step228]: loss 0.076876
[epoch13, step229]: loss 0.072494
[epoch13, step230]: loss 0.078806
[epoch13, step231]: loss 0.075554
[epoch13, step232]: loss 0.070593
[epoch13, step233]: loss 0.079305
[epoch13, step234]: loss 0.071276
[epoch13, step235]: loss 0.078452
[epoch13, step236]: loss 0.076867
[epoch13, step237]: loss 0.077221
[epoch13, step238]: loss 0.070964
[epoch13, step239]: loss 0.079470
[epoch13, step240]: loss 0.076753
[epoch13, step241]: loss 0.070612
[epoch13, step242]: loss 0.078516
[epoch13, step243]: loss 0.070748
[epoch13, step244]: loss 0.077978
[epoch13, step245]: loss 0.077629
[epoch13, step246]: loss 0.077505
[epoch13, step247]: loss 0.071866
[epoch13, step248]: loss 0.079387
[epoch13, step249]: loss 0.076369
[epoch13, step250]: loss 0.069876
[epoch13, step251]: loss 0.077700
[epoch13, step252]: loss 0.070301
[epoch13, step253]: loss 0.078394
[epoch13, step254]: loss 0.076992
[epoch13, step255]: loss 0.076654
[epoch13, step256]: loss 0.072189
[epoch13, step257]: loss 0.078813
[epoch13, step258]: loss 0.075106
[epoch13, step259]: loss 0.069356
[epoch13, step260]: loss 0.078243
[epoch13, step261]: loss 0.069571
[epoch13, step262]: loss 0.077418
[epoch13, step263]: loss 0.077030
[epoch13, step264]: loss 0.077001
[epoch13, step265]: loss 0.071773
[epoch13, step266]: loss 0.078465
[epoch13, step267]: loss 0.076290
[epoch13, step268]: loss 0.070446
[epoch13, step269]: loss 0.077680
[epoch13, step270]: loss 0.070750
[epoch13, step271]: loss 0.077469
[epoch13, step272]: loss 0.076913
[epoch13, step273]: loss 0.077343
[epoch13, step274]: loss 0.070675
[epoch13, step275]: loss 0.079348
[epoch13, step276]: loss 0.076187
[epoch13, step277]: loss 0.070503
[epoch13, step278]: loss 0.078089
[epoch13, step279]: loss 0.070051
[epoch13, step280]: loss 0.077726
[epoch13, step281]: loss 0.076634
[epoch13, step282]: loss 0.076176
[epoch13, step283]: loss 0.071853
[epoch13, step284]: loss 0.078862
[epoch13, step285]: loss 0.074911
[epoch13, step286]: loss 0.072085
[epoch13, step287]: loss 0.077459
[epoch13, step288]: loss 0.070668
[epoch13, step289]: loss 0.077139
[epoch13, step290]: loss 0.076371
[epoch13, step291]: loss 0.076579
[epoch13, step292]: loss 0.072003
[epoch13, step293]: loss 0.078691
[epoch13, step294]: loss 0.075834
[epoch13, step295]: loss 0.070422
[epoch13, step296]: loss 0.077056
[epoch13, step297]: loss 0.071522
[epoch13, step298]: loss 0.077926
[epoch13, step299]: loss 0.076991
[epoch13, step300]: loss 0.076512
[epoch13, step301]: loss 0.072122
[epoch13, step302]: loss 0.078547
[epoch13, step303]: loss 0.075340
[epoch13, step304]: loss 0.069493
[epoch13, step305]: loss 0.077966
[epoch13, step306]: loss 0.070307
[epoch13, step307]: loss 0.078133
[epoch13, step308]: loss 0.075943
[epoch13, step309]: loss 0.076071
[epoch13, step310]: loss 0.071511
[epoch13, step311]: loss 0.077763
[epoch13, step312]: loss 0.075705
[epoch13, step313]: loss 0.070617
[epoch13, step314]: loss 0.077342
[epoch13, step315]: loss 0.070429
[epoch13, step316]: loss 0.077783
[epoch13, step317]: loss 0.075973
[epoch13, step318]: loss 0.076504
[epoch13, step319]: loss 0.071880
[epoch13, step320]: loss 0.078868
[epoch13, step321]: loss 0.075630
[epoch13, step322]: loss 0.071356
[epoch13, step323]: loss 0.078040
[epoch13, step324]: loss 0.070175
[epoch13, step325]: loss 0.077195
[epoch13, step326]: loss 0.076605
[epoch13, step327]: loss 0.077303
[epoch13, step328]: loss 0.071533
[epoch13, step329]: loss 0.078743
[epoch13, step330]: loss 0.076002
[epoch13, step331]: loss 0.070814
[epoch13, step332]: loss 0.078261
[epoch13, step333]: loss 0.070501
[epoch13, step334]: loss 0.077295
[epoch13, step335]: loss 0.076110
[epoch13, step336]: loss 0.075773
[epoch13, step337]: loss 0.070229
[epoch13, step338]: loss 0.078613
[epoch13, step339]: loss 0.075677
[epoch13, step340]: loss 0.070322
[epoch13, step341]: loss 0.077680
[epoch13, step342]: loss 0.069792
[epoch13, step343]: loss 0.076884
[epoch13, step344]: loss 0.076059
[epoch13, step345]: loss 0.076963
[epoch13, step346]: loss 0.071740
[epoch13, step347]: loss 0.078226
[epoch13, step348]: loss 0.074987
[epoch13, step349]: loss 0.069729
[epoch13, step350]: loss 0.077787
[epoch13, step351]: loss 0.070493
[epoch13, step352]: loss 0.077121
[epoch13, step353]: loss 0.076285
[epoch13, step354]: loss 0.077692
[epoch13, step355]: loss 0.071504
[epoch13, step356]: loss 0.077728
[epoch13, step357]: loss 0.075306
[epoch13, step358]: loss 0.071116
[epoch13, step359]: loss 0.076818
[epoch13, step360]: loss 0.069813
[epoch13, step361]: loss 0.077521
[epoch13, step362]: loss 0.075376
[epoch13, step363]: loss 0.076614
[epoch13, step364]: loss 0.071175
[epoch13, step365]: loss 0.077914
[epoch13, step366]: loss 0.074796
[epoch13, step367]: loss 0.070380
[epoch13, step368]: loss 0.077543
[epoch13, step369]: loss 0.070095
[epoch13, step370]: loss 0.076497
[epoch13, step371]: loss 0.075004
[epoch13, step372]: loss 0.076479
[epoch13, step373]: loss 0.070606
[epoch13, step374]: loss 0.078348
[epoch13, step375]: loss 0.074607
[epoch13, step376]: loss 0.068816
[epoch13, step377]: loss 0.077008
[epoch13, step378]: loss 0.070559
[epoch13, step379]: loss 0.076390
[epoch13, step380]: loss 0.075750
[epoch13, step381]: loss 0.076799
[epoch13, step382]: loss 0.072079
[epoch13, step383]: loss 0.078972
[epoch13, step384]: loss 0.075682
[epoch13, step385]: loss 0.068765
[epoch13, step386]: loss 0.077081
[epoch13, step387]: loss 0.069272
[epoch13, step388]: loss 0.076226
[epoch13, step389]: loss 0.075622
[epoch13, step390]: loss 0.075117
[epoch13, step391]: loss 0.070181
[epoch13, step392]: loss 0.077009
[epoch13, step393]: loss 0.075474
[epoch13, step394]: loss 0.070288
[epoch13, step395]: loss 0.077146
[epoch13, step396]: loss 0.069695
[epoch13, step397]: loss 0.077309
[epoch13, step398]: loss 0.075345
[epoch13, step399]: loss 0.076069
[epoch13, step400]: loss 0.070053
[epoch13, step401]: loss 0.077767
[epoch13, step402]: loss 0.075393
[epoch13, step403]: loss 0.069142
[epoch13, step404]: loss 0.076821
[epoch13, step405]: loss 0.069382
[epoch13, step406]: loss 0.076368
[epoch13, step407]: loss 0.076209
[epoch13, step408]: loss 0.076432
[epoch13, step409]: loss 0.069310
[epoch13, step410]: loss 0.077330
[epoch13, step411]: loss 0.075181
[epoch13, step412]: loss 0.068914
[epoch13, step413]: loss 0.077041
[epoch13, step414]: loss 0.070561
[epoch13, step415]: loss 0.076802
[epoch13, step416]: loss 0.076095
[epoch13, step417]: loss 0.075769
[epoch13, step418]: loss 0.070107
[epoch13, step419]: loss 0.077947
[epoch13, step420]: loss 0.074321
[epoch13, step421]: loss 0.069520
[epoch13, step422]: loss 0.076738
[epoch13, step423]: loss 0.069355
[epoch13, step424]: loss 0.076302
[epoch13, step425]: loss 0.075310
[epoch13, step426]: loss 0.075595
[epoch13, step427]: loss 0.071517
[epoch13, step428]: loss 0.077434
[epoch13, step429]: loss 0.074015
[epoch13, step430]: loss 0.069478
[epoch13, step431]: loss 0.076413
[epoch13, step432]: loss 0.069576
[epoch13, step433]: loss 0.076077
[epoch13, step434]: loss 0.075424
[epoch13, step435]: loss 0.075627
[epoch13, step436]: loss 0.071442
[epoch13, step437]: loss 0.077356
[epoch13, step438]: loss 0.073795
[epoch13, step439]: loss 0.070558
[epoch13, step440]: loss 0.076687
[epoch13, step441]: loss 0.069433
[epoch13, step442]: loss 0.076598
[epoch13, step443]: loss 0.074752
[epoch13, step444]: loss 0.076270
[epoch13, step445]: loss 0.070563
[epoch13, step446]: loss 0.076939
[epoch13, step447]: loss 0.074215
[epoch13, step448]: loss 0.068345
[epoch13, step449]: loss 0.076714
[epoch13, step450]: loss 0.070167
[epoch13, step451]: loss 0.076427
[epoch13, step452]: loss 0.075972
[epoch13, step453]: loss 0.075475
[epoch13, step454]: loss 0.070915
[epoch13, step455]: loss 0.076863
[epoch13, step456]: loss 0.074847
[epoch13, step457]: loss 0.069289
[epoch13, step458]: loss 0.076704
[epoch13, step459]: loss 0.069145
[epoch13, step460]: loss 0.076320
[epoch13, step461]: loss 0.075022
[epoch13, step462]: loss 0.076287
[epoch13, step463]: loss 0.070673
[epoch13, step464]: loss 0.077671
[epoch13, step465]: loss 0.073207
[epoch13, step466]: loss 0.069007
[epoch13, step467]: loss 0.077126
[epoch13, step468]: loss 0.069473
[epoch13, step469]: loss 0.076163
[epoch13, step470]: loss 0.074977
[epoch13, step471]: loss 0.075702
[epoch13, step472]: loss 0.071028
[epoch13, step473]: loss 0.077647
[epoch13, step474]: loss 0.074465
[epoch13, step475]: loss 0.069256
[epoch13, step476]: loss 0.075960
[epoch13, step477]: loss 0.069322
[epoch13, step478]: loss 0.076696
[epoch13, step479]: loss 0.075016
[epoch13, step480]: loss 0.076037
[epoch13, step481]: loss 0.070410
[epoch13, step482]: loss 0.077448
[epoch13, step483]: loss 0.073942
[epoch13, step484]: loss 0.067970
[epoch13, step485]: loss 0.076251
[epoch13, step486]: loss 0.069102
[epoch13, step487]: loss 0.076408
[epoch13, step488]: loss 0.075290
[epoch13, step489]: loss 0.076471
[epoch13, step490]: loss 0.070583
[epoch13, step491]: loss 0.076862
[epoch13, step492]: loss 0.074425
[epoch13, step493]: loss 0.068783
[epoch13, step494]: loss 0.077261
[epoch13, step495]: loss 0.068050
[epoch13, step496]: loss 0.076377
[epoch13, step497]: loss 0.074794
[epoch13, step498]: loss 0.075258
[epoch13, step499]: loss 0.070583
[epoch13, step500]: loss 0.077204
[epoch13, step501]: loss 0.074608
[epoch13, step502]: loss 0.068823
[epoch13, step503]: loss 0.076067
[epoch13, step504]: loss 0.069986
[epoch13, step505]: loss 0.076691
[epoch13, step506]: loss 0.074253
[epoch13, step507]: loss 0.074906
[epoch13, step508]: loss 0.070278
[epoch13, step509]: loss 0.077017
[epoch13, step510]: loss 0.074403
[epoch13, step511]: loss 0.069834
[epoch13, step512]: loss 0.075881
[epoch13, step513]: loss 0.069536
[epoch13, step514]: loss 0.075802
[epoch13, step515]: loss 0.075172
[epoch13, step516]: loss 0.075656
[epoch13, step517]: loss 0.070607
[epoch13, step518]: loss 0.077062
[epoch13, step519]: loss 0.074499
[epoch13, step520]: loss 0.067853
[epoch13, step521]: loss 0.076477
[epoch13, step522]: loss 0.068940
[epoch13, step523]: loss 0.075881
[epoch13, step524]: loss 0.075340
[epoch13, step525]: loss 0.074883
[epoch13, step526]: loss 0.069028
[epoch13, step527]: loss 0.077063
[epoch13, step528]: loss 0.073663
[epoch13, step529]: loss 0.069272
[epoch13, step530]: loss 0.075885
[epoch13, step531]: loss 0.068756
[epoch13, step532]: loss 0.076200
[epoch13, step533]: loss 0.074274
[epoch13, step534]: loss 0.075302
[epoch13, step535]: loss 0.070285
[epoch13, step536]: loss 0.076866
[epoch13, step537]: loss 0.073700
[epoch13, step538]: loss 0.070187
[epoch13, step539]: loss 0.077028
[epoch13, step540]: loss 0.070324
[epoch13, step541]: loss 0.076331
[epoch13, step542]: loss 0.075000
[epoch13, step543]: loss 0.075145
[epoch13, step544]: loss 0.068701
[epoch13, step545]: loss 0.077464
[epoch13, step546]: loss 0.073402
[epoch13, step547]: loss 0.069567
[epoch13, step548]: loss 0.076182
[epoch13, step549]: loss 0.068751
[epoch13, step550]: loss 0.075676
[epoch13, step551]: loss 0.074756
[epoch13, step552]: loss 0.075335
[epoch13, step553]: loss 0.070394
[epoch13, step554]: loss 0.076984
[epoch13, step555]: loss 0.074100
[epoch13, step556]: loss 0.068711
[epoch13, step557]: loss 0.076443
[epoch13, step558]: loss 0.068978
[epoch13, step559]: loss 0.076347
[epoch13, step560]: loss 0.074306
[epoch13, step561]: loss 0.075372
[epoch13, step562]: loss 0.069287
[epoch13, step563]: loss 0.077997
[epoch13, step564]: loss 0.067344
[epoch13, step565]: loss 0.056813
[epoch13, step566]: loss 0.065038
[epoch13, step567]: loss 0.057841
[epoch13, step568]: loss 0.060775
[epoch13, step569]: loss 0.067559
[epoch13, step570]: loss 0.065217
[epoch13, step571]: loss 0.049080
[epoch13, step572]: loss 0.059705
[epoch13, step573]: loss 0.065110
[epoch13, step574]: loss 0.072976
[epoch13, step575]: loss 0.060780
[epoch13, step576]: loss 0.062773
[epoch13, step577]: loss 0.058273
[epoch13, step578]: loss 0.061689
[epoch13, step579]: loss 0.057066
[epoch13, step580]: loss 0.068960
[epoch13, step581]: loss 0.064757
[epoch13, step582]: loss 0.062818
[epoch13, step583]: loss 0.062377
[epoch13, step584]: loss 0.060889
[epoch13, step585]: loss 0.070384
[epoch13, step586]: loss 0.061499
[epoch13, step587]: loss 0.051670
[epoch13, step588]: loss 0.063099
[epoch13, step589]: loss 0.076955
[epoch13, step590]: loss 0.053126
[epoch13, step591]: loss 0.059262
[epoch13, step592]: loss 0.067843
[epoch13, step593]: loss 0.075170
[epoch13, step594]: loss 0.053129
[epoch13, step595]: loss 0.053489
[epoch13, step596]: loss 0.065911
[epoch13, step597]: loss 0.069233
[epoch13, step598]: loss 0.057205
[epoch13, step599]: loss 0.052727
[epoch13, step600]: loss 0.053087
[epoch13, step601]: loss 0.059243
[epoch13, step602]: loss 0.070015
[epoch13, step603]: loss 0.057664
[epoch13, step604]: loss 0.057370
[epoch13, step605]: loss 0.052303
[epoch13, step606]: loss 0.061182
[epoch13, step607]: loss 0.066713
[epoch13, step608]: loss 0.047889
[epoch13, step609]: loss 0.063932
[epoch13, step610]: loss 0.058691
[epoch13, step611]: loss 0.068324
[epoch13, step612]: loss 0.063402
[epoch13, step613]: loss 0.064148
[epoch13, step614]: loss 0.062335
[epoch13, step615]: loss 0.064709
[epoch13, step616]: loss 0.052997
[epoch13, step617]: loss 0.058238
[epoch13, step618]: loss 0.067086
[epoch13, step619]: loss 0.055647
[epoch13, step620]: loss 0.051163
[epoch13, step621]: loss 0.051067
[epoch13, step622]: loss 0.062503
[epoch13, step623]: loss 0.063194
[epoch13, step624]: loss 0.064553
[epoch13, step625]: loss 0.051159
[epoch13, step626]: loss 0.065341
[epoch13, step627]: loss 0.069786
[epoch13, step628]: loss 0.066244
[epoch13, step629]: loss 0.041143
[epoch13, step630]: loss 0.054998
[epoch13, step631]: loss 0.059782
[epoch13, step632]: loss 0.062641
[epoch13, step633]: loss 0.054780
[epoch13, step634]: loss 0.062867
[epoch13, step635]: loss 0.058777
[epoch13, step636]: loss 0.051100
[epoch13, step637]: loss 0.068381
[epoch13, step638]: loss 0.064161
[epoch13, step639]: loss 0.050990
[epoch13, step640]: loss 0.068021
[epoch13, step641]: loss 0.056984
[epoch13, step642]: loss 0.052194
[epoch13, step643]: loss 0.065265
[epoch13, step644]: loss 0.058813
[epoch13, step645]: loss 0.047960
[epoch13, step646]: loss 0.061218
[epoch13, step647]: loss 0.049240
[epoch13, step648]: loss 0.069990
[epoch13, step649]: loss 0.065040
[epoch13, step650]: loss 0.063937
[epoch13, step651]: loss 0.058839
[epoch13, step652]: loss 0.070251
[epoch13, step653]: loss 0.069072
[epoch13, step654]: loss 0.063407
[epoch13, step655]: loss 0.053406
[epoch13, step656]: loss 0.065810
[epoch13, step657]: loss 0.068524
[epoch13, step658]: loss 0.055945
[epoch13, step659]: loss 0.051356
[epoch13, step660]: loss 0.059944
[epoch13, step661]: loss 0.064340
[epoch13, step662]: loss 0.050114
[epoch13, step663]: loss 0.056798
[epoch13, step664]: loss 0.057711
[epoch13, step665]: loss 0.070618
[epoch13, step666]: loss 0.052494
[epoch13, step667]: loss 0.063795
[epoch13, step668]: loss 0.067716
[epoch13, step669]: loss 0.052776
[epoch13, step670]: loss 0.062444
[epoch13, step671]: loss 0.060735
[epoch13, step672]: loss 0.071480
[epoch13, step673]: loss 0.065778
[epoch13, step674]: loss 0.056258
[epoch13, step675]: loss 0.062894
[epoch13, step676]: loss 0.064469
[epoch13, step677]: loss 0.056927
[epoch13, step678]: loss 0.050371
[epoch13, step679]: loss 0.059361
[epoch13, step680]: loss 0.055540
[epoch13, step681]: loss 0.050826
[epoch13, step682]: loss 0.054929
[epoch13, step683]: loss 0.061107
[epoch13, step684]: loss 0.052547
[epoch13, step685]: loss 0.053292
[epoch13, step686]: loss 0.053292
[epoch13, step687]: loss 0.056817
[epoch13, step688]: loss 0.062386
[epoch13, step689]: loss 0.052914
[epoch13, step690]: loss 0.065688
[epoch13, step691]: loss 0.067492
[epoch13, step692]: loss 0.064002
[epoch13, step693]: loss 0.062874
[epoch13, step694]: loss 0.049642
[epoch13, step695]: loss 0.057408
[epoch13, step696]: loss 0.053938
[epoch13, step697]: loss 0.062403
[epoch13, step698]: loss 0.056508
[epoch13, step699]: loss 0.057132
[epoch13, step700]: loss 0.068840
[epoch13, step701]: loss 0.063780
[epoch13, step702]: loss 0.055009
[epoch13, step703]: loss 0.068607
[epoch13, step704]: loss 0.065394
[epoch13, step705]: loss 0.053251
[epoch13, step706]: loss 0.054733
[epoch13, step707]: loss 0.056128
[epoch13, step708]: loss 0.060793
[epoch13, step709]: loss 0.056633
[epoch13, step710]: loss 0.060256
[epoch13, step711]: loss 0.064722
[epoch13, step712]: loss 0.051905
[epoch13, step713]: loss 0.056413
[epoch13, step714]: loss 0.060461
[epoch13, step715]: loss 0.054332
[epoch13, step716]: loss 0.062249
[epoch13, step717]: loss 0.053456
[epoch13, step718]: loss 0.059160
[epoch13, step719]: loss 0.064954
[epoch13, step720]: loss 0.053225
[epoch13, step721]: loss 0.056816
[epoch13, step722]: loss 0.064643
[epoch13, step723]: loss 0.059278
[epoch13, step724]: loss 0.060692
[epoch13, step725]: loss 0.063823
[epoch13, step726]: loss 0.046794
[epoch13, step727]: loss 0.060998
[epoch13, step728]: loss 0.062350
[epoch13, step729]: loss 0.050307
[epoch13, step730]: loss 0.060633
[epoch13, step731]: loss 0.065758
[epoch13, step732]: loss 0.057507
[epoch13, step733]: loss 0.048682
[epoch13, step734]: loss 0.053501
[epoch13, step735]: loss 0.056134
[epoch13, step736]: loss 0.056433
[epoch13, step737]: loss 0.052876
[epoch13, step738]: loss 0.052420
[epoch13, step739]: loss 0.070646
[epoch13, step740]: loss 0.071784
[epoch13, step741]: loss 0.060124
[epoch13, step742]: loss 0.064605
[epoch13, step743]: loss 0.057977
[epoch13, step744]: loss 0.058102
[epoch13, step745]: loss 0.058947
[epoch13, step746]: loss 0.062300
[epoch13, step747]: loss 0.058927
[epoch13, step748]: loss 0.054154
[epoch13, step749]: loss 0.071450
[epoch13, step750]: loss 0.064038
[epoch13, step751]: loss 0.053955
[epoch13, step752]: loss 0.052661
[epoch13, step753]: loss 0.053186
[epoch13, step754]: loss 0.064465
[epoch13, step755]: loss 0.062633
[epoch13, step756]: loss 0.048709
[epoch13, step757]: loss 0.056395
[epoch13, step758]: loss 0.062959
[epoch13, step759]: loss 0.051733
[epoch13, step760]: loss 0.061095
[epoch13, step761]: loss 0.058278
[epoch13, step762]: loss 0.052435
[epoch13, step763]: loss 0.055477
[epoch13, step764]: loss 0.059779
[epoch13, step765]: loss 0.054501
[epoch13, step766]: loss 0.051888
[epoch13, step767]: loss 0.063344
[epoch13, step768]: loss 0.057031
[epoch13, step769]: loss 0.060586
[epoch13, step770]: loss 0.069563
[epoch13, step771]: loss 0.051006
[epoch13, step772]: loss 0.055504
[epoch13, step773]: loss 0.057987
[epoch13, step774]: loss 0.057550
[epoch13, step775]: loss 0.065638
[epoch13, step776]: loss 0.061552
[epoch13, step777]: loss 0.054893
[epoch13, step778]: loss 0.066412
[epoch13, step779]: loss 0.056073
[epoch13, step780]: loss 0.059836
[epoch13, step781]: loss 0.068906
[epoch13, step782]: loss 0.064560
[epoch13, step783]: loss 0.055733
[epoch13, step784]: loss 0.062425
[epoch13, step785]: loss 0.061959
[epoch13, step786]: loss 0.057810
[epoch13, step787]: loss 0.067102
[epoch13, step788]: loss 0.059233
[epoch13, step789]: loss 0.064493
[epoch13, step790]: loss 0.050994
[epoch13, step791]: loss 0.063142
[epoch13, step792]: loss 0.061977
[epoch13, step793]: loss 0.063598
[epoch13, step794]: loss 0.056606
[epoch13, step795]: loss 0.058690
[epoch13, step796]: loss 0.057697
[epoch13, step797]: loss 0.054691
[epoch13, step798]: loss 0.054826
[epoch13, step799]: loss 0.048519
[epoch13, step800]: loss 0.068394
[epoch13, step801]: loss 0.065024
[epoch13, step802]: loss 0.056457
[epoch13, step803]: loss 0.055753
[epoch13, step804]: loss 0.063236
[epoch13, step805]: loss 0.058422
[epoch13, step806]: loss 0.056866
[epoch13, step807]: loss 0.061205
[epoch13, step808]: loss 0.066601
[epoch13, step809]: loss 0.053868
[epoch13, step810]: loss 0.049891
[epoch13, step811]: loss 0.059747
[epoch13, step812]: loss 0.061904
[epoch13, step813]: loss 0.053959
[epoch13, step814]: loss 0.060483
[epoch13, step815]: loss 0.057831
[epoch13, step816]: loss 0.057860
[epoch13, step817]: loss 0.052520
[epoch13, step818]: loss 0.054823
[epoch13, step819]: loss 0.073899
[epoch13, step820]: loss 0.052602
[epoch13, step821]: loss 0.051782
[epoch13, step822]: loss 0.063271
[epoch13, step823]: loss 0.052063
[epoch13, step824]: loss 0.060609
[epoch13, step825]: loss 0.061039
[epoch13, step826]: loss 0.046549
[epoch13, step827]: loss 0.055047
[epoch13, step828]: loss 0.060511
[epoch13, step829]: loss 0.056113
[epoch13, step830]: loss 0.044344
[epoch13, step831]: loss 0.053311
[epoch13, step832]: loss 0.066056
[epoch13, step833]: loss 0.061806
[epoch13, step834]: loss 0.058465
[epoch13, step835]: loss 0.057454
[epoch13, step836]: loss 0.054540
[epoch13, step837]: loss 0.052297
[epoch13, step838]: loss 0.064729
[epoch13, step839]: loss 0.059859
[epoch13, step840]: loss 0.052059
[epoch13, step841]: loss 0.057488
[epoch13, step842]: loss 0.059797
[epoch13, step843]: loss 0.063019
[epoch13, step844]: loss 0.062963
[epoch13, step845]: loss 0.058300
[epoch13, step846]: loss 0.071876
[epoch13, step847]: loss 0.059446
[epoch13, step848]: loss 0.039746
[epoch13, step849]: loss 0.055217
[epoch13, step850]: loss 0.061914
[epoch13, step851]: loss 0.056230
[epoch13, step852]: loss 0.057196
[epoch13, step853]: loss 0.064838
[epoch13, step854]: loss 0.061930
[epoch13, step855]: loss 0.054704
[epoch13, step856]: loss 0.048651
[epoch13, step857]: loss 0.061712
[epoch13, step858]: loss 0.061357
[epoch13, step859]: loss 0.052931
[epoch13, step860]: loss 0.062777
[epoch13, step861]: loss 0.057742
[epoch13, step862]: loss 0.049331
[epoch13, step863]: loss 0.060568
[epoch13, step864]: loss 0.065585
[epoch13, step865]: loss 0.059627
[epoch13, step866]: loss 0.062637
[epoch13, step867]: loss 0.056228
[epoch13, step868]: loss 0.061170
[epoch13, step869]: loss 0.052330
[epoch13, step870]: loss 0.054924
[epoch13, step871]: loss 0.066065
[epoch13, step872]: loss 0.061574
[epoch13, step873]: loss 0.051707
[epoch13, step874]: loss 0.056909
[epoch13, step875]: loss 0.068797
[epoch13, step876]: loss 0.063535
[epoch13, step877]: loss 0.038872
[epoch13, step878]: loss 0.053249
[epoch13, step879]: loss 0.057998
[epoch13, step880]: loss 0.054554
[epoch13, step881]: loss 0.062382
[epoch13, step882]: loss 0.052531
[epoch13, step883]: loss 0.054789
[epoch13, step884]: loss 0.068775
[epoch13, step885]: loss 0.068390
[epoch13, step886]: loss 0.066641
[epoch13, step887]: loss 0.068170
[epoch13, step888]: loss 0.055319
[epoch13, step889]: loss 0.061516
[epoch13, step890]: loss 0.061522
[epoch13, step891]: loss 0.055097
[epoch13, step892]: loss 0.060703
[epoch13, step893]: loss 0.061170
[epoch13, step894]: loss 0.061451
[epoch13, step895]: loss 0.049852
[epoch13, step896]: loss 0.070586
[epoch13, step897]: loss 0.071168
[epoch13, step898]: loss 0.053503
[epoch13, step899]: loss 0.044715
[epoch13, step900]: loss 0.059391
[epoch13, step901]: loss 0.064967
[epoch13, step902]: loss 0.052832
[epoch13, step903]: loss 0.065502
[epoch13, step904]: loss 0.055180
[epoch13, step905]: loss 0.052576
[epoch13, step906]: loss 0.047634
[epoch13, step907]: loss 0.062091
[epoch13, step908]: loss 0.064754
[epoch13, step909]: loss 0.056660
[epoch13, step910]: loss 0.048476
[epoch13, step911]: loss 0.049643
[epoch13, step912]: loss 0.062029
[epoch13, step913]: loss 0.062685
[epoch13, step914]: loss 0.062086
[epoch13, step915]: loss 0.052377
[epoch13, step916]: loss 0.059228
[epoch13, step917]: loss 0.058295
[epoch13, step918]: loss 0.065529
[epoch13, step919]: loss 0.050691
[epoch13, step920]: loss 0.066499
[epoch13, step921]: loss 0.053728
[epoch13, step922]: loss 0.054305
[epoch13, step923]: loss 0.064835
[epoch13, step924]: loss 0.051389
[epoch13, step925]: loss 0.055421
[epoch13, step926]: loss 0.056663
[epoch13, step927]: loss 0.065028
[epoch13, step928]: loss 0.053838
[epoch13, step929]: loss 0.057809
[epoch13, step930]: loss 0.058783
[epoch13, step931]: loss 0.063775
[epoch13, step932]: loss 0.052246
[epoch13, step933]: loss 0.057846
[epoch13, step934]: loss 0.064489
[epoch13, step935]: loss 0.057089
[epoch13, step936]: loss 0.052047
[epoch13, step937]: loss 0.052481
[epoch13, step938]: loss 0.068737
[epoch13, step939]: loss 0.052374
[epoch13, step940]: loss 0.062499
[epoch13, step941]: loss 0.060456
[epoch13, step942]: loss 0.058712
[epoch13, step943]: loss 0.064483
[epoch13, step944]: loss 0.060378
[epoch13, step945]: loss 0.061221
[epoch13, step946]: loss 0.058386
[epoch13, step947]: loss 0.054737
[epoch13, step948]: loss 0.071580
[epoch13, step949]: loss 0.056795
[epoch13, step950]: loss 0.058181
[epoch13, step951]: loss 0.063482
[epoch13, step952]: loss 0.062453
[epoch13, step953]: loss 0.059642
[epoch13, step954]: loss 0.059073
[epoch13, step955]: loss 0.057391
[epoch13, step956]: loss 0.083231
[epoch13, step957]: loss 0.074235
[epoch13, step958]: loss 0.079979
[epoch13, step959]: loss 0.078366
[epoch13, step960]: loss 0.072021
[epoch13, step961]: loss 0.076175
[epoch13, step962]: loss 0.074626
[epoch13, step963]: loss 0.075582
[epoch13, step964]: loss 0.071742
[epoch13, step965]: loss 0.077129
[epoch13, step966]: loss 0.069622
[epoch13, step967]: loss 0.074683
[epoch13, step968]: loss 0.073451
[epoch13, step969]: loss 0.068255
[epoch13, step970]: loss 0.072505
[epoch13, step971]: loss 0.072240
[epoch13, step972]: loss 0.073283
[epoch13, step973]: loss 0.071751
[epoch13, step974]: loss 0.074517
[epoch13, step975]: loss 0.069283
[epoch13, step976]: loss 0.074954
[epoch13, step977]: loss 0.072587
[epoch13, step978]: loss 0.067860
[epoch13, step979]: loss 0.072677
[epoch13, step980]: loss 0.071512
[epoch13, step981]: loss 0.073546
[epoch13, step982]: loss 0.070283
[epoch13, step983]: loss 0.074171
[epoch13, step984]: loss 0.068246
[epoch13, step985]: loss 0.074511
[epoch13, step986]: loss 0.071960
[epoch13, step987]: loss 0.065962
[epoch13, step988]: loss 0.071187
[epoch13, step989]: loss 0.070889
[epoch13, step990]: loss 0.073837
[epoch13, step991]: loss 0.069339
[epoch13, step992]: loss 0.073919
[epoch13, step993]: loss 0.068745
[epoch13, step994]: loss 0.074764
[epoch13, step995]: loss 0.072279
[epoch13, step996]: loss 0.066356
[epoch13, step997]: loss 0.071335
[epoch13, step998]: loss 0.070668
[epoch13, step999]: loss 0.073004
[epoch13, step1000]: loss 0.069952
[epoch13, step1001]: loss 0.073730
[epoch13, step1002]: loss 0.067609
[epoch13, step1003]: loss 0.074210
[epoch13, step1004]: loss 0.071537
[epoch13, step1005]: loss 0.066334
[epoch13, step1006]: loss 0.071192
[epoch13, step1007]: loss 0.070799
[epoch13, step1008]: loss 0.073350
[epoch13, step1009]: loss 0.069626
[epoch13, step1010]: loss 0.073022
[epoch13, step1011]: loss 0.067860
[epoch13, step1012]: loss 0.073380
[epoch13, step1013]: loss 0.071902
[epoch13, step1014]: loss 0.066611
[epoch13, step1015]: loss 0.070652
[epoch13, step1016]: loss 0.070721
[epoch13, step1017]: loss 0.073301
[epoch13, step1018]: loss 0.069199
[epoch13, step1019]: loss 0.073277
[epoch13, step1020]: loss 0.067951
[epoch13, step1021]: loss 0.073932
[epoch13, step1022]: loss 0.071798
[epoch13, step1023]: loss 0.065950
[epoch13, step1024]: loss 0.069840
[epoch13, step1025]: loss 0.071001
[epoch13, step1026]: loss 0.073211
[epoch13, step1027]: loss 0.068698
[epoch13, step1028]: loss 0.073137
[epoch13, step1029]: loss 0.067462
[epoch13, step1030]: loss 0.073870
[epoch13, step1031]: loss 0.072589
[epoch13, step1032]: loss 0.065513
[epoch13, step1033]: loss 0.071127
[epoch13, step1034]: loss 0.070803
[epoch13, step1035]: loss 0.073165
[epoch13, step1036]: loss 0.069420
[epoch13, step1037]: loss 0.073030
[epoch13, step1038]: loss 0.067540
[epoch13, step1039]: loss 0.073430
[epoch13, step1040]: loss 0.071844
[epoch13, step1041]: loss 0.066084
[epoch13, step1042]: loss 0.070132
[epoch13, step1043]: loss 0.070396
[epoch13, step1044]: loss 0.072351
[epoch13, step1045]: loss 0.069038
[epoch13, step1046]: loss 0.072748
[epoch13, step1047]: loss 0.067268
[epoch13, step1048]: loss 0.074458
[epoch13, step1049]: loss 0.071302
[epoch13, step1050]: loss 0.066059
[epoch13, step1051]: loss 0.070642
[epoch13, step1052]: loss 0.070424
[epoch13, step1053]: loss 0.073113
[epoch13, step1054]: loss 0.069315
[epoch13, step1055]: loss 0.072886
[epoch13, step1056]: loss 0.067381
[epoch13, step1057]: loss 0.072868
[epoch13, step1058]: loss 0.070787
[epoch13, step1059]: loss 0.065359
[epoch13, step1060]: loss 0.069520
[epoch13, step1061]: loss 0.070686
[epoch13, step1062]: loss 0.072227
[epoch13, step1063]: loss 0.069242
[epoch13, step1064]: loss 0.072596
[epoch13, step1065]: loss 0.068082
[epoch13, step1066]: loss 0.073671
[epoch13, step1067]: loss 0.071281
[epoch13, step1068]: loss 0.067031
[epoch13, step1069]: loss 0.069101
[epoch13, step1070]: loss 0.070278
[epoch13, step1071]: loss 0.072196
[epoch13, step1072]: loss 0.068357
[epoch13, step1073]: loss 0.072704
[epoch13, step1074]: loss 0.067801
[epoch13, step1075]: loss 0.073153
[epoch13, step1076]: loss 0.070963
[epoch13, step1077]: loss 0.065113
[epoch13, step1078]: loss 0.070160
[epoch13, step1079]: loss 0.069575
[epoch13, step1080]: loss 0.072115
[epoch13, step1081]: loss 0.069260
[epoch13, step1082]: loss 0.072583
[epoch13, step1083]: loss 0.067309
[epoch13, step1084]: loss 0.073008
[epoch13, step1085]: loss 0.071360
[epoch13, step1086]: loss 0.066143
[epoch13, step1087]: loss 0.070051
[epoch13, step1088]: loss 0.070288
[epoch13, step1089]: loss 0.072052
[epoch13, step1090]: loss 0.068490
[epoch13, step1091]: loss 0.072343
[epoch13, step1092]: loss 0.067535
[epoch13, step1093]: loss 0.073032
[epoch13, step1094]: loss 0.071647
[epoch13, step1095]: loss 0.065116
[epoch13, step1096]: loss 0.070280
[epoch13, step1097]: loss 0.069846
[epoch13, step1098]: loss 0.072399
[epoch13, step1099]: loss 0.068924
[epoch13, step1100]: loss 0.072134
[epoch13, step1101]: loss 0.067840
[epoch13, step1102]: loss 0.073334
[epoch13, step1103]: loss 0.071267
[epoch13, step1104]: loss 0.065253
[epoch13, step1105]: loss 0.069431
[epoch13, step1106]: loss 0.070375
[epoch13, step1107]: loss 0.072146
[epoch13, step1108]: loss 0.068833
[epoch13, step1109]: loss 0.071954
[epoch13, step1110]: loss 0.066573
[epoch13, step1111]: loss 0.072865
[epoch13, step1112]: loss 0.070736
[epoch13, step1113]: loss 0.065150
[epoch13, step1114]: loss 0.069638
[epoch13, step1115]: loss 0.069546
[epoch13, step1116]: loss 0.072030
[epoch13, step1117]: loss 0.068532
[epoch13, step1118]: loss 0.072404
[epoch13, step1119]: loss 0.068064
[epoch13, step1120]: loss 0.073246
[epoch13, step1121]: loss 0.070877
[epoch13, step1122]: loss 0.065454
[epoch13, step1123]: loss 0.069917
[epoch13, step1124]: loss 0.069569
[epoch13, step1125]: loss 0.071909
[epoch13, step1126]: loss 0.068168
[epoch13, step1127]: loss 0.072168
[epoch13, step1128]: loss 0.067325
[epoch13, step1129]: loss 0.073083
[epoch13, step1130]: loss 0.069999
[epoch13, step1131]: loss 0.064908
[epoch13, step1132]: loss 0.069379
[epoch13, step1133]: loss 0.069947
[epoch13, step1134]: loss 0.072093
[epoch13, step1135]: loss 0.067561
[epoch13, step1136]: loss 0.071695
[epoch13, step1137]: loss 0.066112
[epoch13, step1138]: loss 0.072547
[epoch13, step1139]: loss 0.071028
[epoch13, step1140]: loss 0.064580
[epoch13, step1141]: loss 0.068961
[epoch13, step1142]: loss 0.069973
[epoch13, step1143]: loss 0.072233
[epoch13, step1144]: loss 0.068723
[epoch13, step1145]: loss 0.072397
[epoch13, step1146]: loss 0.066288
[epoch13, step1147]: loss 0.072222
[epoch13, step1148]: loss 0.070911
[epoch13, step1149]: loss 0.064687
[epoch13, step1150]: loss 0.069803
[epoch13, step1151]: loss 0.069856
[epoch13, step1152]: loss 0.071427
[epoch13, step1153]: loss 0.068443
[epoch13, step1154]: loss 0.071856
[epoch13, step1155]: loss 0.066798
[epoch13, step1156]: loss 0.073127
[epoch13, step1157]: loss 0.071026
[epoch13, step1158]: loss 0.064463
[epoch13, step1159]: loss 0.069079
[epoch13, step1160]: loss 0.069211
[epoch13, step1161]: loss 0.071449
[epoch13, step1162]: loss 0.068304
[epoch13, step1163]: loss 0.072397
[epoch13, step1164]: loss 0.066257
[epoch13, step1165]: loss 0.071824
[epoch13, step1166]: loss 0.070256
[epoch13, step1167]: loss 0.064681
[epoch13, step1168]: loss 0.069142
[epoch13, step1169]: loss 0.069725
[epoch13, step1170]: loss 0.071739
[epoch13, step1171]: loss 0.068331
[epoch13, step1172]: loss 0.072063
[epoch13, step1173]: loss 0.067011
[epoch13, step1174]: loss 0.072269
[epoch13, step1175]: loss 0.070834
[epoch13, step1176]: loss 0.064904
[epoch13, step1177]: loss 0.068728
[epoch13, step1178]: loss 0.069145
[epoch13, step1179]: loss 0.071780
[epoch13, step1180]: loss 0.067986
[epoch13, step1181]: loss 0.071612
[epoch13, step1182]: loss 0.066535
[epoch13, step1183]: loss 0.072035
[epoch13, step1184]: loss 0.070886
[epoch13, step1185]: loss 0.065407
[epoch13, step1186]: loss 0.069049
[epoch13, step1187]: loss 0.069921
[epoch13, step1188]: loss 0.071836
[epoch13, step1189]: loss 0.067797
[epoch13, step1190]: loss 0.072042
[epoch13, step1191]: loss 0.066885
[epoch13, step1192]: loss 0.071917
[epoch13, step1193]: loss 0.070180
[epoch13, step1194]: loss 0.064441
[epoch13, step1195]: loss 0.069923
[epoch13, step1196]: loss 0.069639
[epoch13, step1197]: loss 0.071419
[epoch13, step1198]: loss 0.067693
[epoch13, step1199]: loss 0.071803
[epoch13, step1200]: loss 0.066311
[epoch13, step1201]: loss 0.071915
[epoch13, step1202]: loss 0.069757
[epoch13, step1203]: loss 0.065598
[epoch13, step1204]: loss 0.068973
[epoch13, step1205]: loss 0.069263
[epoch13, step1206]: loss 0.071702
[epoch13, step1207]: loss 0.067251
[epoch13, step1208]: loss 0.071477
[epoch13, step1209]: loss 0.066157
[epoch13, step1210]: loss 0.071991
[epoch13, step1211]: loss 0.070555
[epoch13, step1212]: loss 0.065375
[epoch13, step1213]: loss 0.069687
[epoch13, step1214]: loss 0.069202
[epoch13, step1215]: loss 0.071029
[epoch13, step1216]: loss 0.067488
[epoch13, step1217]: loss 0.071328
[epoch13, step1218]: loss 0.065971
[epoch13, step1219]: loss 0.071691
[epoch13, step1220]: loss 0.069858
[epoch13, step1221]: loss 0.064158
[epoch13, step1222]: loss 0.068877
[epoch13, step1223]: loss 0.068817
[epoch13, step1224]: loss 0.070725
[epoch13, step1225]: loss 0.067603
[epoch13, step1226]: loss 0.071809
[epoch13, step1227]: loss 0.065509
[epoch13, step1228]: loss 0.072155
[epoch13, step1229]: loss 0.070703
[epoch13, step1230]: loss 0.065222
[epoch13, step1231]: loss 0.069391
[epoch13, step1232]: loss 0.069073
[epoch13, step1233]: loss 0.071204
[epoch13, step1234]: loss 0.068101
[epoch13, step1235]: loss 0.071816
[epoch13, step1236]: loss 0.067089
[epoch13, step1237]: loss 0.072576
[epoch13, step1238]: loss 0.070658
[epoch13, step1239]: loss 0.063928
[epoch13, step1240]: loss 0.068625
[epoch13, step1241]: loss 0.069761
[epoch13, step1242]: loss 0.071225
[epoch13, step1243]: loss 0.067042
[epoch13, step1244]: loss 0.071277
[epoch13, step1245]: loss 0.065309
[epoch13, step1246]: loss 0.071736
[epoch13, step1247]: loss 0.070533
[epoch13, step1248]: loss 0.064297
[epoch13, step1249]: loss 0.068394
[epoch13, step1250]: loss 0.068854
[epoch13, step1251]: loss 0.070887
[epoch13, step1252]: loss 0.067722
[epoch13, step1253]: loss 0.071066
[epoch13, step1254]: loss 0.066514
[epoch13, step1255]: loss 0.071934
[epoch13, step1256]: loss 0.069756
[epoch13, step1257]: loss 0.064426
[epoch13, step1258]: loss 0.068856
[epoch13, step1259]: loss 0.069258
[epoch13, step1260]: loss 0.071076
[epoch13, step1261]: loss 0.067638
[epoch13, step1262]: loss 0.071993
[epoch13, step1263]: loss 0.065472
[epoch13, step1264]: loss 0.072033
[epoch13, step1265]: loss 0.070815
[epoch13, step1266]: loss 0.064845
[epoch13, step1267]: loss 0.068674
[epoch13, step1268]: loss 0.068932
[epoch13, step1269]: loss 0.070791
[epoch13, step1270]: loss 0.067755
[epoch13, step1271]: loss 0.071050
[epoch13, step1272]: loss 0.066144
[epoch13, step1273]: loss 0.072020
[epoch13, step1274]: loss 0.070243
[epoch13, step1275]: loss 0.064565
[epoch13, step1276]: loss 0.068481
[epoch13, step1277]: loss 0.068836
[epoch13, step1278]: loss 0.070526
[epoch13, step1279]: loss 0.067244
[epoch13, step1280]: loss 0.071251
[epoch13, step1281]: loss 0.066348
[epoch13, step1282]: loss 0.071853
[epoch13, step1283]: loss 0.070081
[epoch13, step1284]: loss 0.063699
[epoch13, step1285]: loss 0.068948
[epoch13, step1286]: loss 0.068799
[epoch13, step1287]: loss 0.070427
[epoch13, step1288]: loss 0.066975
[epoch13, step1289]: loss 0.070655
[epoch13, step1290]: loss 0.066509
[epoch13, step1291]: loss 0.071654
[epoch13, step1292]: loss 0.069239
[epoch13, step1293]: loss 0.063607
[epoch13, step1294]: loss 0.068221
[epoch13, step1295]: loss 0.068127
[epoch13, step1296]: loss 0.070400
[epoch13, step1297]: loss 0.066554
[epoch13, step1298]: loss 0.070669
[epoch13, step1299]: loss 0.066491
[epoch13, step1300]: loss 0.071239
[epoch13, step1301]: loss 0.070630
[epoch13, step1302]: loss 0.064460
[epoch13, step1303]: loss 0.068935
[epoch13, step1304]: loss 0.069100
[epoch13, step1305]: loss 0.070423
[epoch13, step1306]: loss 0.067157
[epoch13, step1307]: loss 0.071613
[epoch13, step1308]: loss 0.066387
[epoch13, step1309]: loss 0.072028
[epoch13, step1310]: loss 0.069627
[epoch13, step1311]: loss 0.064204
[epoch13, step1312]: loss 0.068679
[epoch13, step1313]: loss 0.068691
[epoch13, step1314]: loss 0.070802
[epoch13, step1315]: loss 0.067022
[epoch13, step1316]: loss 0.070246
[epoch13, step1317]: loss 0.066128
[epoch13, step1318]: loss 0.071812
[epoch13, step1319]: loss 0.069628
[epoch13, step1320]: loss 0.064245
[epoch13, step1321]: loss 0.067804
[epoch13, step1322]: loss 0.068763
[epoch13, step1323]: loss 0.070203
[epoch13, step1324]: loss 0.067255
[epoch13, step1325]: loss 0.070915
[epoch13, step1326]: loss 0.066649
[epoch13, step1327]: loss 0.071419
[epoch13, step1328]: loss 0.069530
[epoch13, step1329]: loss 0.064535
[epoch13, step1330]: loss 0.068243
[epoch13, step1331]: loss 0.068829
[epoch13, step1332]: loss 0.070926
[epoch13, step1333]: loss 0.067815
[epoch13, step1334]: loss 0.070748
[epoch13, step1335]: loss 0.066136
[epoch13, step1336]: loss 0.071256
[epoch13, step1337]: loss 0.070043
[epoch13, step1338]: loss 0.063570
[epoch13, step1339]: loss 0.068714
[epoch13, step1340]: loss 0.068968
[epoch13, step1341]: loss 0.070421
[epoch13, step1342]: loss 0.066777
[epoch13, step1343]: loss 0.070638
[epoch13, step1344]: loss 0.065085
[epoch13, step1345]: loss 0.071227
[epoch13, step1346]: loss 0.069547
[epoch13, step1347]: loss 0.063772
[epoch13, step1348]: loss 0.068434
[epoch13, step1349]: loss 0.068497
[epoch13, step1350]: loss 0.069995
[epoch13, step1351]: loss 0.067662
[epoch13, step1352]: loss 0.070947
[epoch13, step1353]: loss 0.066480
[epoch13, step1354]: loss 0.071728
[epoch13, step1355]: loss 0.069488
[epoch13, step1356]: loss 0.064823
[epoch13, step1357]: loss 0.068605
[epoch13, step1358]: loss 0.068237
[epoch13, step1359]: loss 0.070630
[epoch13, step1360]: loss 0.066394
[epoch13, step1361]: loss 0.070518
[epoch13, step1362]: loss 0.065904
[epoch13, step1363]: loss 0.070641
[epoch13, step1364]: loss 0.069309
[epoch13, step1365]: loss 0.064251
[epoch13, step1366]: loss 0.068069
[epoch13, step1367]: loss 0.068491
[epoch13, step1368]: loss 0.069475
[epoch13, step1369]: loss 0.067260
[epoch13, step1370]: loss 0.071080
[epoch13, step1371]: loss 0.065564
[epoch13, step1372]: loss 0.071146
[epoch13, step1373]: loss 0.069346
[epoch13, step1374]: loss 0.063406
[epoch13, step1375]: loss 0.068208
[epoch13, step1376]: loss 0.067999
[epoch13, step1377]: loss 0.070857
[epoch13, step1378]: loss 0.067037
[epoch13, step1379]: loss 0.070857
[epoch13, step1380]: loss 0.064518
[epoch13, step1381]: loss 0.070787
[epoch13, step1382]: loss 0.069278
[epoch13, step1383]: loss 0.063227
[epoch13, step1384]: loss 0.067655
[epoch13, step1385]: loss 0.068026
[epoch13, step1386]: loss 0.069912
[epoch13, step1387]: loss 0.066305
[epoch13, step1388]: loss 0.071079
[epoch13, step1389]: loss 0.065606
[epoch13, step1390]: loss 0.070958
[epoch13, step1391]: loss 0.069360
[epoch13, step1392]: loss 0.064503
[epoch13, step1393]: loss 0.067681
[epoch13, step1394]: loss 0.067722
[epoch13, step1395]: loss 0.070352
[epoch13, step1396]: loss 0.066376
[epoch13, step1397]: loss 0.070757
[epoch13, step1398]: loss 0.065068
[epoch13, step1399]: loss 0.070115
[epoch13, step1400]: loss 0.069260
[epoch13, step1401]: loss 0.062977
[epoch13, step1402]: loss 0.067795
[epoch13, step1403]: loss 0.068255
[epoch13, step1404]: loss 0.070124
[epoch13, step1405]: loss 0.065921
[epoch13, step1406]: loss 0.070553
[epoch13, step1407]: loss 0.065075
[epoch13, step1408]: loss 0.071116
[epoch13, step1409]: loss 0.069322
[epoch13, step1410]: loss 0.062825
[epoch13, step1411]: loss 0.068530
[epoch13, step1412]: loss 0.068231
[epoch13, step1413]: loss 0.069992
[epoch13, step1414]: loss 0.067010
[epoch13, step1415]: loss 0.070758
[epoch13, step1416]: loss 0.064547
[epoch13, step1417]: loss 0.071339
[epoch13, step1418]: loss 0.069250
[epoch13, step1419]: loss 0.063452
[epoch13, step1420]: loss 0.068443
[epoch13, step1421]: loss 0.067516
[epoch13, step1422]: loss 0.069693
[epoch13, step1423]: loss 0.066718
[epoch13, step1424]: loss 0.070321
[epoch13, step1425]: loss 0.065206
[epoch13, step1426]: loss 0.070657
[epoch13, step1427]: loss 0.068423
[epoch13, step1428]: loss 0.064165
[epoch13, step1429]: loss 0.067522
[epoch13, step1430]: loss 0.067958
[epoch13, step1431]: loss 0.069743
[epoch13, step1432]: loss 0.066557
[epoch13, step1433]: loss 0.070270
[epoch13, step1434]: loss 0.066468
[epoch13, step1435]: loss 0.070497
[epoch13, step1436]: loss 0.068843
[epoch13, step1437]: loss 0.063279
[epoch13, step1438]: loss 0.067822
[epoch13, step1439]: loss 0.068454
[epoch13, step1440]: loss 0.070297
[epoch13, step1441]: loss 0.066006
[epoch13, step1442]: loss 0.070936
[epoch13, step1443]: loss 0.066195
[epoch13, step1444]: loss 0.070840
[epoch13, step1445]: loss 0.068698
[epoch13, step1446]: loss 0.062601
[epoch13, step1447]: loss 0.067522
[epoch13, step1448]: loss 0.067666
[epoch13, step1449]: loss 0.069933
[epoch13, step1450]: loss 0.066464
[epoch13, step1451]: loss 0.069870
[epoch13, step1452]: loss 0.065414
[epoch13, step1453]: loss 0.069920
[epoch13, step1454]: loss 0.068591
[epoch13, step1455]: loss 0.062813
[epoch13, step1456]: loss 0.067814
[epoch13, step1457]: loss 0.067321
[epoch13, step1458]: loss 0.069538
[epoch13, step1459]: loss 0.067062
[epoch13, step1460]: loss 0.070329
[epoch13, step1461]: loss 0.064266
[epoch13, step1462]: loss 0.070101
[epoch13, step1463]: loss 0.069230
[epoch13, step1464]: loss 0.062580
[epoch13, step1465]: loss 0.068064
[epoch13, step1466]: loss 0.067429
[epoch13, step1467]: loss 0.069915
[epoch13, step1468]: loss 0.066322
[epoch13, step1469]: loss 0.070171
[epoch13, step1470]: loss 0.064590
[epoch13, step1471]: loss 0.070705
[epoch13, step1472]: loss 0.069095
[epoch13, step1473]: loss 0.062446
[epoch13, step1474]: loss 0.067209
[epoch13, step1475]: loss 0.067561
[epoch13, step1476]: loss 0.069225
[epoch13, step1477]: loss 0.066983
[epoch13, step1478]: loss 0.070205
[epoch13, step1479]: loss 0.064905
[epoch13, step1480]: loss 0.070933
[epoch13, step1481]: loss 0.069437
[epoch13, step1482]: loss 0.063607
[epoch13, step1483]: loss 0.068376
[epoch13, step1484]: loss 0.067605
[epoch13, step1485]: loss 0.069608
[epoch13, step1486]: loss 0.066619
[epoch13, step1487]: loss 0.069946
[epoch13, step1488]: loss 0.064845
[epoch13, step1489]: loss 0.070404
[epoch13, step1490]: loss 0.068423
[epoch13, step1491]: loss 0.063569
[epoch13, step1492]: loss 0.068118
[epoch13, step1493]: loss 0.067775
[epoch13, step1494]: loss 0.069787
[epoch13, step1495]: loss 0.066918
[epoch13, step1496]: loss 0.070326
[epoch13, step1497]: loss 0.065011
[epoch13, step1498]: loss 0.070027
[epoch13, step1499]: loss 0.068945
[epoch13, step1500]: loss 0.063468
[epoch13, step1501]: loss 0.068008
[epoch13, step1502]: loss 0.067300
[epoch13, step1503]: loss 0.069909
[epoch13, step1504]: loss 0.066603
[epoch13, step1505]: loss 0.069820
[epoch13, step1506]: loss 0.064586
[epoch13, step1507]: loss 0.069822
[epoch13, step1508]: loss 0.068530
[epoch13, step1509]: loss 0.063478
[epoch13, step1510]: loss 0.068171
[epoch13, step1511]: loss 0.066950
[epoch13, step1512]: loss 0.069026
[epoch13, step1513]: loss 0.066881
[epoch13, step1514]: loss 0.069885
[epoch13, step1515]: loss 0.065263
[epoch13, step1516]: loss 0.070269

[epoch13]: avg loss 0.068841

[epoch14, step1]: loss 0.067327
[epoch14, step2]: loss 0.070062
[epoch14, step3]: loss 0.070588
[epoch14, step4]: loss 0.065893
[epoch14, step5]: loss 0.070391
[epoch14, step6]: loss 0.069421
[epoch14, step7]: loss 0.063360
[epoch14, step8]: loss 0.070195
[epoch14, step9]: loss 0.064068
[epoch14, step10]: loss 0.069023
[epoch14, step11]: loss 0.069440
[epoch14, step12]: loss 0.069623
[epoch14, step13]: loss 0.064128
[epoch14, step14]: loss 0.070125
[epoch14, step15]: loss 0.068880
[epoch14, step16]: loss 0.063757
[epoch14, step17]: loss 0.069902
[epoch14, step18]: loss 0.063906
[epoch14, step19]: loss 0.069718
[epoch14, step20]: loss 0.068806
[epoch14, step21]: loss 0.069884
[epoch14, step22]: loss 0.064919
[epoch14, step23]: loss 0.071183
[epoch14, step24]: loss 0.068430
[epoch14, step25]: loss 0.063089
[epoch14, step26]: loss 0.070592
[epoch14, step27]: loss 0.063690
[epoch14, step28]: loss 0.069338
[epoch14, step29]: loss 0.068825
[epoch14, step30]: loss 0.068927
[epoch14, step31]: loss 0.064476
[epoch14, step32]: loss 0.070076
[epoch14, step33]: loss 0.068426
[epoch14, step34]: loss 0.063327
[epoch14, step35]: loss 0.069811
[epoch14, step36]: loss 0.063758
[epoch14, step37]: loss 0.069391
[epoch14, step38]: loss 0.068998
[epoch14, step39]: loss 0.069214
[epoch14, step40]: loss 0.064077
[epoch14, step41]: loss 0.070611
[epoch14, step42]: loss 0.068263
[epoch14, step43]: loss 0.063977
[epoch14, step44]: loss 0.069937
[epoch14, step45]: loss 0.064218
[epoch14, step46]: loss 0.069645
[epoch14, step47]: loss 0.069176
[epoch14, step48]: loss 0.069548
[epoch14, step49]: loss 0.064024
[epoch14, step50]: loss 0.070345
[epoch14, step51]: loss 0.068367
[epoch14, step52]: loss 0.063765
[epoch14, step53]: loss 0.069565
[epoch14, step54]: loss 0.063193
[epoch14, step55]: loss 0.069079
[epoch14, step56]: loss 0.068120
[epoch14, step57]: loss 0.068970
[epoch14, step58]: loss 0.064149
[epoch14, step59]: loss 0.070759
[epoch14, step60]: loss 0.067795
[epoch14, step61]: loss 0.063559
[epoch14, step62]: loss 0.070093
[epoch14, step63]: loss 0.063970
[epoch14, step64]: loss 0.069599
[epoch14, step65]: loss 0.068672
[epoch14, step66]: loss 0.069111
[epoch14, step67]: loss 0.064848
[epoch14, step68]: loss 0.070371
[epoch14, step69]: loss 0.068302
[epoch14, step70]: loss 0.063892
[epoch14, step71]: loss 0.070303
[epoch14, step72]: loss 0.063510
[epoch14, step73]: loss 0.069451
[epoch14, step74]: loss 0.068496
[epoch14, step75]: loss 0.068940
[epoch14, step76]: loss 0.064694
[epoch14, step77]: loss 0.069587
[epoch14, step78]: loss 0.068095
[epoch14, step79]: loss 0.063758
[epoch14, step80]: loss 0.069224
[epoch14, step81]: loss 0.063319
[epoch14, step82]: loss 0.069493
[epoch14, step83]: loss 0.069116
[epoch14, step84]: loss 0.068930
[epoch14, step85]: loss 0.063572
[epoch14, step86]: loss 0.069627
[epoch14, step87]: loss 0.068010
[epoch14, step88]: loss 0.064830
[epoch14, step89]: loss 0.069993
[epoch14, step90]: loss 0.064172
[epoch14, step91]: loss 0.069739
[epoch14, step92]: loss 0.068701
[epoch14, step93]: loss 0.068968
[epoch14, step94]: loss 0.064664
[epoch14, step95]: loss 0.070068
[epoch14, step96]: loss 0.068380
[epoch14, step97]: loss 0.063518
[epoch14, step98]: loss 0.070346
[epoch14, step99]: loss 0.063668
[epoch14, step100]: loss 0.069721
[epoch14, step101]: loss 0.068353
[epoch14, step102]: loss 0.069088
[epoch14, step103]: loss 0.064519
[epoch14, step104]: loss 0.070035
[epoch14, step105]: loss 0.067705
[epoch14, step106]: loss 0.063406
[epoch14, step107]: loss 0.069845
[epoch14, step108]: loss 0.063468
[epoch14, step109]: loss 0.069090
[epoch14, step110]: loss 0.068463
[epoch14, step111]: loss 0.068935
[epoch14, step112]: loss 0.065023
[epoch14, step113]: loss 0.069689
[epoch14, step114]: loss 0.068215
[epoch14, step115]: loss 0.063821
[epoch14, step116]: loss 0.069947
[epoch14, step117]: loss 0.063118
[epoch14, step118]: loss 0.068821
[epoch14, step119]: loss 0.068367
[epoch14, step120]: loss 0.068531
[epoch14, step121]: loss 0.064346
[epoch14, step122]: loss 0.069581
[epoch14, step123]: loss 0.067702
[epoch14, step124]: loss 0.063410
[epoch14, step125]: loss 0.069302
[epoch14, step126]: loss 0.063477
[epoch14, step127]: loss 0.068924
[epoch14, step128]: loss 0.068587
[epoch14, step129]: loss 0.068424
[epoch14, step130]: loss 0.063458
[epoch14, step131]: loss 0.070058
[epoch14, step132]: loss 0.067729
[epoch14, step133]: loss 0.062848
[epoch14, step134]: loss 0.070089
[epoch14, step135]: loss 0.063094
[epoch14, step136]: loss 0.068361
[epoch14, step137]: loss 0.068398
[epoch14, step138]: loss 0.068765
[epoch14, step139]: loss 0.064023
[epoch14, step140]: loss 0.069343
[epoch14, step141]: loss 0.067785
[epoch14, step142]: loss 0.063002
[epoch14, step143]: loss 0.069571
[epoch14, step144]: loss 0.063976
[epoch14, step145]: loss 0.068961
[epoch14, step146]: loss 0.068503
[epoch14, step147]: loss 0.068052
[epoch14, step148]: loss 0.063789
[epoch14, step149]: loss 0.069819
[epoch14, step150]: loss 0.067941
[epoch14, step151]: loss 0.062072
[epoch14, step152]: loss 0.069359
[epoch14, step153]: loss 0.063000
[epoch14, step154]: loss 0.069050
[epoch14, step155]: loss 0.068447
[epoch14, step156]: loss 0.069096
[epoch14, step157]: loss 0.063598
[epoch14, step158]: loss 0.069626
[epoch14, step159]: loss 0.067606
[epoch14, step160]: loss 0.063104
[epoch14, step161]: loss 0.069333
[epoch14, step162]: loss 0.062978
[epoch14, step163]: loss 0.068882
[epoch14, step164]: loss 0.068056
[epoch14, step165]: loss 0.068529
[epoch14, step166]: loss 0.063085
[epoch14, step167]: loss 0.069847
[epoch14, step168]: loss 0.067255
[epoch14, step169]: loss 0.063124
[epoch14, step170]: loss 0.069123
[epoch14, step171]: loss 0.063226
[epoch14, step172]: loss 0.068657
[epoch14, step173]: loss 0.068314
[epoch14, step174]: loss 0.068760
[epoch14, step175]: loss 0.063539
[epoch14, step176]: loss 0.069491
[epoch14, step177]: loss 0.067514
[epoch14, step178]: loss 0.062588
[epoch14, step179]: loss 0.070097
[epoch14, step180]: loss 0.062767
[epoch14, step181]: loss 0.068742
[epoch14, step182]: loss 0.067801
[epoch14, step183]: loss 0.068279
[epoch14, step184]: loss 0.063306
[epoch14, step185]: loss 0.069145
[epoch14, step186]: loss 0.067172
[epoch14, step187]: loss 0.063070
[epoch14, step188]: loss 0.069169
[epoch14, step189]: loss 0.062839
[epoch14, step190]: loss 0.068940
[epoch14, step191]: loss 0.067987
[epoch14, step192]: loss 0.068007
[epoch14, step193]: loss 0.064322
[epoch14, step194]: loss 0.069525
[epoch14, step195]: loss 0.067223
[epoch14, step196]: loss 0.061855
[epoch14, step197]: loss 0.069124
[epoch14, step198]: loss 0.062904
[epoch14, step199]: loss 0.068317
[epoch14, step200]: loss 0.067684
[epoch14, step201]: loss 0.068065
[epoch14, step202]: loss 0.063874
[epoch14, step203]: loss 0.069455
[epoch14, step204]: loss 0.067256
[epoch14, step205]: loss 0.063438
[epoch14, step206]: loss 0.069603
[epoch14, step207]: loss 0.062709
[epoch14, step208]: loss 0.068287
[epoch14, step209]: loss 0.067581
[epoch14, step210]: loss 0.067849
[epoch14, step211]: loss 0.063926
[epoch14, step212]: loss 0.069039
[epoch14, step213]: loss 0.067459
[epoch14, step214]: loss 0.063434
[epoch14, step215]: loss 0.068827
[epoch14, step216]: loss 0.062663
[epoch14, step217]: loss 0.068648
[epoch14, step218]: loss 0.067529
[epoch14, step219]: loss 0.068293
[epoch14, step220]: loss 0.064500
[epoch14, step221]: loss 0.068903
[epoch14, step222]: loss 0.066913
[epoch14, step223]: loss 0.062030
[epoch14, step224]: loss 0.069085
[epoch14, step225]: loss 0.062786
[epoch14, step226]: loss 0.068755
[epoch14, step227]: loss 0.068127
[epoch14, step228]: loss 0.068131
[epoch14, step229]: loss 0.064023
[epoch14, step230]: loss 0.068741
[epoch14, step231]: loss 0.066989
[epoch14, step232]: loss 0.062012
[epoch14, step233]: loss 0.069196
[epoch14, step234]: loss 0.063091
[epoch14, step235]: loss 0.068657
[epoch14, step236]: loss 0.067587
[epoch14, step237]: loss 0.068121
[epoch14, step238]: loss 0.062777
[epoch14, step239]: loss 0.069185
[epoch14, step240]: loss 0.067667
[epoch14, step241]: loss 0.062584
[epoch14, step242]: loss 0.068926
[epoch14, step243]: loss 0.062717
[epoch14, step244]: loss 0.068181
[epoch14, step245]: loss 0.067960
[epoch14, step246]: loss 0.068070
[epoch14, step247]: loss 0.064033
[epoch14, step248]: loss 0.069269
[epoch14, step249]: loss 0.067277
[epoch14, step250]: loss 0.062359
[epoch14, step251]: loss 0.068851
[epoch14, step252]: loss 0.062545
[epoch14, step253]: loss 0.068560
[epoch14, step254]: loss 0.067873
[epoch14, step255]: loss 0.067857
[epoch14, step256]: loss 0.063950
[epoch14, step257]: loss 0.069010
[epoch14, step258]: loss 0.066755
[epoch14, step259]: loss 0.061456
[epoch14, step260]: loss 0.068941
[epoch14, step261]: loss 0.062038
[epoch14, step262]: loss 0.067913
[epoch14, step263]: loss 0.067841
[epoch14, step264]: loss 0.067998
[epoch14, step265]: loss 0.063731
[epoch14, step266]: loss 0.068751
[epoch14, step267]: loss 0.067371
[epoch14, step268]: loss 0.062400
[epoch14, step269]: loss 0.068602
[epoch14, step270]: loss 0.062722
[epoch14, step271]: loss 0.067808
[epoch14, step272]: loss 0.067940
[epoch14, step273]: loss 0.068439
[epoch14, step274]: loss 0.062814
[epoch14, step275]: loss 0.069416
[epoch14, step276]: loss 0.067497
[epoch14, step277]: loss 0.062363
[epoch14, step278]: loss 0.068724
[epoch14, step279]: loss 0.062121
[epoch14, step280]: loss 0.067960
[epoch14, step281]: loss 0.067496
[epoch14, step282]: loss 0.067552
[epoch14, step283]: loss 0.063620
[epoch14, step284]: loss 0.068986
[epoch14, step285]: loss 0.066677
[epoch14, step286]: loss 0.063468
[epoch14, step287]: loss 0.068450
[epoch14, step288]: loss 0.062650
[epoch14, step289]: loss 0.067569
[epoch14, step290]: loss 0.067643
[epoch14, step291]: loss 0.067721
[epoch14, step292]: loss 0.063678
[epoch14, step293]: loss 0.068817
[epoch14, step294]: loss 0.067139
[epoch14, step295]: loss 0.062348
[epoch14, step296]: loss 0.068298
[epoch14, step297]: loss 0.063363
[epoch14, step298]: loss 0.068173
[epoch14, step299]: loss 0.067702
[epoch14, step300]: loss 0.067917
[epoch14, step301]: loss 0.064010
[epoch14, step302]: loss 0.068544
[epoch14, step303]: loss 0.066708
[epoch14, step304]: loss 0.061319
[epoch14, step305]: loss 0.068662
[epoch14, step306]: loss 0.062377
[epoch14, step307]: loss 0.067937
[epoch14, step308]: loss 0.067479
[epoch14, step309]: loss 0.067392
[epoch14, step310]: loss 0.063478
[epoch14, step311]: loss 0.068244
[epoch14, step312]: loss 0.067090
[epoch14, step313]: loss 0.062492
[epoch14, step314]: loss 0.068401
[epoch14, step315]: loss 0.062816
[epoch14, step316]: loss 0.068021
[epoch14, step317]: loss 0.067247
[epoch14, step318]: loss 0.067694
[epoch14, step319]: loss 0.063890
[epoch14, step320]: loss 0.069202
[epoch14, step321]: loss 0.066834
[epoch14, step322]: loss 0.063527
[epoch14, step323]: loss 0.069289
[epoch14, step324]: loss 0.062279
[epoch14, step325]: loss 0.067810
[epoch14, step326]: loss 0.067309
[epoch14, step327]: loss 0.068026
[epoch14, step328]: loss 0.063566
[epoch14, step329]: loss 0.068725
[epoch14, step330]: loss 0.067064
[epoch14, step331]: loss 0.062453
[epoch14, step332]: loss 0.068588
[epoch14, step333]: loss 0.062608
[epoch14, step334]: loss 0.067579
[epoch14, step335]: loss 0.067571
[epoch14, step336]: loss 0.067313
[epoch14, step337]: loss 0.062350
[epoch14, step338]: loss 0.068582
[epoch14, step339]: loss 0.066790
[epoch14, step340]: loss 0.062473
[epoch14, step341]: loss 0.068598
[epoch14, step342]: loss 0.062168
[epoch14, step343]: loss 0.067416
[epoch14, step344]: loss 0.067679
[epoch14, step345]: loss 0.068269
[epoch14, step346]: loss 0.063469
[epoch14, step347]: loss 0.068861
[epoch14, step348]: loss 0.066717
[epoch14, step349]: loss 0.062044
[epoch14, step350]: loss 0.068791
[epoch14, step351]: loss 0.062145
[epoch14, step352]: loss 0.067678
[epoch14, step353]: loss 0.067117
[epoch14, step354]: loss 0.068034
[epoch14, step355]: loss 0.063261
[epoch14, step356]: loss 0.067986
[epoch14, step357]: loss 0.066642
[epoch14, step358]: loss 0.062611
[epoch14, step359]: loss 0.067858
[epoch14, step360]: loss 0.061800
[epoch14, step361]: loss 0.067625
[epoch14, step362]: loss 0.066839
[epoch14, step363]: loss 0.067693
[epoch14, step364]: loss 0.063319
[epoch14, step365]: loss 0.068299
[epoch14, step366]: loss 0.066450
[epoch14, step367]: loss 0.062570
[epoch14, step368]: loss 0.068400
[epoch14, step369]: loss 0.062488
[epoch14, step370]: loss 0.067301
[epoch14, step371]: loss 0.066727
[epoch14, step372]: loss 0.067854
[epoch14, step373]: loss 0.062547
[epoch14, step374]: loss 0.068726
[epoch14, step375]: loss 0.066356
[epoch14, step376]: loss 0.061197
[epoch14, step377]: loss 0.068228
[epoch14, step378]: loss 0.062507
[epoch14, step379]: loss 0.067234
[epoch14, step380]: loss 0.066670
[epoch14, step381]: loss 0.067536
[epoch14, step382]: loss 0.063958
[epoch14, step383]: loss 0.068645
[epoch14, step384]: loss 0.066884
[epoch14, step385]: loss 0.060846
[epoch14, step386]: loss 0.067945
[epoch14, step387]: loss 0.061607
[epoch14, step388]: loss 0.066867
[epoch14, step389]: loss 0.066865
[epoch14, step390]: loss 0.066696
[epoch14, step391]: loss 0.062303
[epoch14, step392]: loss 0.067864
[epoch14, step393]: loss 0.066988
[epoch14, step394]: loss 0.062533
[epoch14, step395]: loss 0.068136
[epoch14, step396]: loss 0.062306
[epoch14, step397]: loss 0.067769
[epoch14, step398]: loss 0.066838
[epoch14, step399]: loss 0.067461
[epoch14, step400]: loss 0.062117
[epoch14, step401]: loss 0.068314
[epoch14, step402]: loss 0.066518
[epoch14, step403]: loss 0.061508
[epoch14, step404]: loss 0.068187
[epoch14, step405]: loss 0.061581
[epoch14, step406]: loss 0.067196
[epoch14, step407]: loss 0.067008
[epoch14, step408]: loss 0.067197
[epoch14, step409]: loss 0.061990
[epoch14, step410]: loss 0.067715
[epoch14, step411]: loss 0.066394
[epoch14, step412]: loss 0.061000
[epoch14, step413]: loss 0.067878
[epoch14, step414]: loss 0.062562
[epoch14, step415]: loss 0.067199
[epoch14, step416]: loss 0.066955
[epoch14, step417]: loss 0.067116
[epoch14, step418]: loss 0.062258
[epoch14, step419]: loss 0.068223
[epoch14, step420]: loss 0.066084
[epoch14, step421]: loss 0.061761
[epoch14, step422]: loss 0.067858
[epoch14, step423]: loss 0.062002
[epoch14, step424]: loss 0.066977
[epoch14, step425]: loss 0.066951
[epoch14, step426]: loss 0.067505
[epoch14, step427]: loss 0.063341
[epoch14, step428]: loss 0.068209
[epoch14, step429]: loss 0.066086
[epoch14, step430]: loss 0.061202
[epoch14, step431]: loss 0.067751
[epoch14, step432]: loss 0.061419
[epoch14, step433]: loss 0.066522
[epoch14, step434]: loss 0.066829
[epoch14, step435]: loss 0.066930
[epoch14, step436]: loss 0.063236
[epoch14, step437]: loss 0.067882
[epoch14, step438]: loss 0.065681
[epoch14, step439]: loss 0.062438
[epoch14, step440]: loss 0.067762
[epoch14, step441]: loss 0.061863
[epoch14, step442]: loss 0.066835
[epoch14, step443]: loss 0.066665
[epoch14, step444]: loss 0.067499
[epoch14, step445]: loss 0.063043
[epoch14, step446]: loss 0.068255
[epoch14, step447]: loss 0.066172
[epoch14, step448]: loss 0.060958
[epoch14, step449]: loss 0.068625
[epoch14, step450]: loss 0.062364
[epoch14, step451]: loss 0.067345
[epoch14, step452]: loss 0.067270
[epoch14, step453]: loss 0.066953
[epoch14, step454]: loss 0.062969
[epoch14, step455]: loss 0.067753
[epoch14, step456]: loss 0.066241
[epoch14, step457]: loss 0.061544
[epoch14, step458]: loss 0.067890
[epoch14, step459]: loss 0.061410
[epoch14, step460]: loss 0.066983
[epoch14, step461]: loss 0.067014
[epoch14, step462]: loss 0.067382
[epoch14, step463]: loss 0.063065
[epoch14, step464]: loss 0.068370
[epoch14, step465]: loss 0.065571
[epoch14, step466]: loss 0.061353
[epoch14, step467]: loss 0.068519
[epoch14, step468]: loss 0.062042
[epoch14, step469]: loss 0.066865
[epoch14, step470]: loss 0.066660
[epoch14, step471]: loss 0.067072
[epoch14, step472]: loss 0.063160
[epoch14, step473]: loss 0.067891
[epoch14, step474]: loss 0.066099
[epoch14, step475]: loss 0.061472
[epoch14, step476]: loss 0.067547
[epoch14, step477]: loss 0.061792
[epoch14, step478]: loss 0.067027
[epoch14, step479]: loss 0.067050
[epoch14, step480]: loss 0.067433
[epoch14, step481]: loss 0.062531
[epoch14, step482]: loss 0.068327
[epoch14, step483]: loss 0.066051
[epoch14, step484]: loss 0.060300
[epoch14, step485]: loss 0.067658
[epoch14, step486]: loss 0.061357
[epoch14, step487]: loss 0.067081
[epoch14, step488]: loss 0.066351
[epoch14, step489]: loss 0.067272
[epoch14, step490]: loss 0.062748
[epoch14, step491]: loss 0.067271
[epoch14, step492]: loss 0.065974
[epoch14, step493]: loss 0.060709
[epoch14, step494]: loss 0.067723
[epoch14, step495]: loss 0.060954
[epoch14, step496]: loss 0.066698
[epoch14, step497]: loss 0.066436
[epoch14, step498]: loss 0.066647
[epoch14, step499]: loss 0.062854
[epoch14, step500]: loss 0.067867
[epoch14, step501]: loss 0.066171
[epoch14, step502]: loss 0.061497
[epoch14, step503]: loss 0.067604
[epoch14, step504]: loss 0.062155
[epoch14, step505]: loss 0.067271
[epoch14, step506]: loss 0.065988
[epoch14, step507]: loss 0.066543
[epoch14, step508]: loss 0.062534
[epoch14, step509]: loss 0.067592
[epoch14, step510]: loss 0.066189
[epoch14, step511]: loss 0.061819
[epoch14, step512]: loss 0.067194
[epoch14, step513]: loss 0.061465
[epoch14, step514]: loss 0.066445
[epoch14, step515]: loss 0.066296
[epoch14, step516]: loss 0.066523
[epoch14, step517]: loss 0.062877
[epoch14, step518]: loss 0.067518
[epoch14, step519]: loss 0.065996
[epoch14, step520]: loss 0.060570
[epoch14, step521]: loss 0.067593
[epoch14, step522]: loss 0.061514
[epoch14, step523]: loss 0.067001
[epoch14, step524]: loss 0.066545
[epoch14, step525]: loss 0.066680
[epoch14, step526]: loss 0.061580
[epoch14, step527]: loss 0.067668
[epoch14, step528]: loss 0.065656
[epoch14, step529]: loss 0.061376
[epoch14, step530]: loss 0.067205
[epoch14, step531]: loss 0.061120
[epoch14, step532]: loss 0.066791
[epoch14, step533]: loss 0.065756
[epoch14, step534]: loss 0.066652
[epoch14, step535]: loss 0.062420
[epoch14, step536]: loss 0.067291
[epoch14, step537]: loss 0.065512
[epoch14, step538]: loss 0.061977
[epoch14, step539]: loss 0.067309
[epoch14, step540]: loss 0.062335
[epoch14, step541]: loss 0.066785
[epoch14, step542]: loss 0.066371
[epoch14, step543]: loss 0.066531
[epoch14, step544]: loss 0.061179
[epoch14, step545]: loss 0.067844
[epoch14, step546]: loss 0.065478
[epoch14, step547]: loss 0.062084
[epoch14, step548]: loss 0.067665
[epoch14, step549]: loss 0.061297
[epoch14, step550]: loss 0.066717
[epoch14, step551]: loss 0.066192
[epoch14, step552]: loss 0.066692
[epoch14, step553]: loss 0.062515
[epoch14, step554]: loss 0.067519
[epoch14, step555]: loss 0.065891
[epoch14, step556]: loss 0.060461
[epoch14, step557]: loss 0.067344
[epoch14, step558]: loss 0.061213
[epoch14, step559]: loss 0.066765
[epoch14, step560]: loss 0.065972
[epoch14, step561]: loss 0.066586
[epoch14, step562]: loss 0.061700
[epoch14, step563]: loss 0.066178
[epoch14, step564]: loss 0.058455
[epoch14, step565]: loss 0.050245
[epoch14, step566]: loss 0.059314
[epoch14, step567]: loss 0.050870
[epoch14, step568]: loss 0.052025
[epoch14, step569]: loss 0.058401
[epoch14, step570]: loss 0.057735
[epoch14, step571]: loss 0.044856
[epoch14, step572]: loss 0.052519
[epoch14, step573]: loss 0.057174
[epoch14, step574]: loss 0.062679
[epoch14, step575]: loss 0.051710
[epoch14, step576]: loss 0.053649
[epoch14, step577]: loss 0.051035
[epoch14, step578]: loss 0.052490
[epoch14, step579]: loss 0.050788
[epoch14, step580]: loss 0.058446
[epoch14, step581]: loss 0.056264
[epoch14, step582]: loss 0.054461
[epoch14, step583]: loss 0.052979
[epoch14, step584]: loss 0.052678
[epoch14, step585]: loss 0.060034
[epoch14, step586]: loss 0.052274
[epoch14, step587]: loss 0.045810
[epoch14, step588]: loss 0.053961
[epoch14, step589]: loss 0.064588
[epoch14, step590]: loss 0.047396
[epoch14, step591]: loss 0.050739
[epoch14, step592]: loss 0.058228
[epoch14, step593]: loss 0.063342
[epoch14, step594]: loss 0.046919
[epoch14, step595]: loss 0.047377
[epoch14, step596]: loss 0.056129
[epoch14, step597]: loss 0.059070
[epoch14, step598]: loss 0.050231
[epoch14, step599]: loss 0.046359
[epoch14, step600]: loss 0.047267
[epoch14, step601]: loss 0.050198
[epoch14, step602]: loss 0.059318
[epoch14, step603]: loss 0.050097
[epoch14, step604]: loss 0.050081
[epoch14, step605]: loss 0.046200
[epoch14, step606]: loss 0.052937
[epoch14, step607]: loss 0.057613
[epoch14, step608]: loss 0.042574
[epoch14, step609]: loss 0.055619
[epoch14, step610]: loss 0.051004
[epoch14, step611]: loss 0.058689
[epoch14, step612]: loss 0.054724
[epoch14, step613]: loss 0.053946
[epoch14, step614]: loss 0.053931
[epoch14, step615]: loss 0.056079
[epoch14, step616]: loss 0.046369
[epoch14, step617]: loss 0.050270
[epoch14, step618]: loss 0.057623
[epoch14, step619]: loss 0.049046
[epoch14, step620]: loss 0.044870
[epoch14, step621]: loss 0.045338
[epoch14, step622]: loss 0.052877
[epoch14, step623]: loss 0.054120
[epoch14, step624]: loss 0.055918
[epoch14, step625]: loss 0.045058
[epoch14, step626]: loss 0.056815
[epoch14, step627]: loss 0.059006
[epoch14, step628]: loss 0.056821
[epoch14, step629]: loss 0.036312
[epoch14, step630]: loss 0.047790
[epoch14, step631]: loss 0.052870
[epoch14, step632]: loss 0.053743
[epoch14, step633]: loss 0.047738
[epoch14, step634]: loss 0.054536
[epoch14, step635]: loss 0.050955
[epoch14, step636]: loss 0.044161
[epoch14, step637]: loss 0.058995
[epoch14, step638]: loss 0.055419
[epoch14, step639]: loss 0.044473
[epoch14, step640]: loss 0.059335
[epoch14, step641]: loss 0.050589
[epoch14, step642]: loss 0.045858
[epoch14, step643]: loss 0.056108
[epoch14, step644]: loss 0.050956
[epoch14, step645]: loss 0.042137
[epoch14, step646]: loss 0.052989
[epoch14, step647]: loss 0.043233
[epoch14, step648]: loss 0.059403
[epoch14, step649]: loss 0.056517
[epoch14, step650]: loss 0.054275
[epoch14, step651]: loss 0.051409
[epoch14, step652]: loss 0.060370
[epoch14, step653]: loss 0.059606
[epoch14, step654]: loss 0.054163
[epoch14, step655]: loss 0.046603
[epoch14, step656]: loss 0.055638
[epoch14, step657]: loss 0.058877
[epoch14, step658]: loss 0.048848
[epoch14, step659]: loss 0.045740
[epoch14, step660]: loss 0.051689
[epoch14, step661]: loss 0.055550
[epoch14, step662]: loss 0.044039
[epoch14, step663]: loss 0.048512
[epoch14, step664]: loss 0.050117
[epoch14, step665]: loss 0.060951
[epoch14, step666]: loss 0.046268
[epoch14, step667]: loss 0.055129
[epoch14, step668]: loss 0.057154
[epoch14, step669]: loss 0.046487
[epoch14, step670]: loss 0.054351
[epoch14, step671]: loss 0.051806
[epoch14, step672]: loss 0.060804
[epoch14, step673]: loss 0.055777
[epoch14, step674]: loss 0.048269
[epoch14, step675]: loss 0.053274
[epoch14, step676]: loss 0.055176
[epoch14, step677]: loss 0.049510
[epoch14, step678]: loss 0.044095
[epoch14, step679]: loss 0.051356
[epoch14, step680]: loss 0.049697
[epoch14, step681]: loss 0.044099
[epoch14, step682]: loss 0.048194
[epoch14, step683]: loss 0.053026
[epoch14, step684]: loss 0.046011
[epoch14, step685]: loss 0.046650
[epoch14, step686]: loss 0.046965
[epoch14, step687]: loss 0.049640
[epoch14, step688]: loss 0.053303
[epoch14, step689]: loss 0.046217
[epoch14, step690]: loss 0.056462
[epoch14, step691]: loss 0.057687
[epoch14, step692]: loss 0.054525
[epoch14, step693]: loss 0.054496
[epoch14, step694]: loss 0.043349
[epoch14, step695]: loss 0.050137
[epoch14, step696]: loss 0.047308
[epoch14, step697]: loss 0.054058
[epoch14, step698]: loss 0.049075
[epoch14, step699]: loss 0.049470
[epoch14, step700]: loss 0.058119
[epoch14, step701]: loss 0.054861
[epoch14, step702]: loss 0.047319
[epoch14, step703]: loss 0.058175
[epoch14, step704]: loss 0.056014
[epoch14, step705]: loss 0.046385
[epoch14, step706]: loss 0.047533
[epoch14, step707]: loss 0.048670
[epoch14, step708]: loss 0.052782
[epoch14, step709]: loss 0.049700
[epoch14, step710]: loss 0.051743
[epoch14, step711]: loss 0.055304
[epoch14, step712]: loss 0.046059
[epoch14, step713]: loss 0.049235
[epoch14, step714]: loss 0.051427
[epoch14, step715]: loss 0.047163
[epoch14, step716]: loss 0.053893
[epoch14, step717]: loss 0.046626
[epoch14, step718]: loss 0.051488
[epoch14, step719]: loss 0.057524
[epoch14, step720]: loss 0.046327
[epoch14, step721]: loss 0.048974
[epoch14, step722]: loss 0.056682
[epoch14, step723]: loss 0.051385
[epoch14, step724]: loss 0.052053
[epoch14, step725]: loss 0.055594
[epoch14, step726]: loss 0.040984
[epoch14, step727]: loss 0.052541
[epoch14, step728]: loss 0.053728
[epoch14, step729]: loss 0.043588
[epoch14, step730]: loss 0.051795
[epoch14, step731]: loss 0.056377
[epoch14, step732]: loss 0.050077
[epoch14, step733]: loss 0.042988
[epoch14, step734]: loss 0.046366
[epoch14, step735]: loss 0.049261
[epoch14, step736]: loss 0.049035
[epoch14, step737]: loss 0.046610
[epoch14, step738]: loss 0.045003
[epoch14, step739]: loss 0.060316
[epoch14, step740]: loss 0.060487
[epoch14, step741]: loss 0.051897
[epoch14, step742]: loss 0.054833
[epoch14, step743]: loss 0.050039
[epoch14, step744]: loss 0.050321
[epoch14, step745]: loss 0.051080
[epoch14, step746]: loss 0.053605
[epoch14, step747]: loss 0.051405
[epoch14, step748]: loss 0.047407
[epoch14, step749]: loss 0.061074
[epoch14, step750]: loss 0.055483
[epoch14, step751]: loss 0.046454
[epoch14, step752]: loss 0.046023
[epoch14, step753]: loss 0.046624
[epoch14, step754]: loss 0.054831
[epoch14, step755]: loss 0.054262
[epoch14, step756]: loss 0.042736
[epoch14, step757]: loss 0.048307
[epoch14, step758]: loss 0.054166
[epoch14, step759]: loss 0.044861
[epoch14, step760]: loss 0.052437
[epoch14, step761]: loss 0.050732
[epoch14, step762]: loss 0.045142
[epoch14, step763]: loss 0.048334
[epoch14, step764]: loss 0.051359
[epoch14, step765]: loss 0.047742
[epoch14, step766]: loss 0.045536
[epoch14, step767]: loss 0.054808
[epoch14, step768]: loss 0.048866
[epoch14, step769]: loss 0.052531
[epoch14, step770]: loss 0.059308
[epoch14, step771]: loss 0.044439
[epoch14, step772]: loss 0.049152
[epoch14, step773]: loss 0.050597
[epoch14, step774]: loss 0.049656
[epoch14, step775]: loss 0.055512
[epoch14, step776]: loss 0.053050
[epoch14, step777]: loss 0.047623
[epoch14, step778]: loss 0.057554
[epoch14, step779]: loss 0.048731
[epoch14, step780]: loss 0.050888
[epoch14, step781]: loss 0.058534
[epoch14, step782]: loss 0.054874
[epoch14, step783]: loss 0.047363
[epoch14, step784]: loss 0.052744
[epoch14, step785]: loss 0.052682
[epoch14, step786]: loss 0.049878
[epoch14, step787]: loss 0.056951
[epoch14, step788]: loss 0.051065
[epoch14, step789]: loss 0.055117
[epoch14, step790]: loss 0.044506
[epoch14, step791]: loss 0.054659
[epoch14, step792]: loss 0.053413
[epoch14, step793]: loss 0.054931
[epoch14, step794]: loss 0.048312
[epoch14, step795]: loss 0.050829
[epoch14, step796]: loss 0.050439
[epoch14, step797]: loss 0.048269
[epoch14, step798]: loss 0.048167
[epoch14, step799]: loss 0.043009
[epoch14, step800]: loss 0.057570
[epoch14, step801]: loss 0.055135
[epoch14, step802]: loss 0.048644
[epoch14, step803]: loss 0.048723
[epoch14, step804]: loss 0.054790
[epoch14, step805]: loss 0.051187
[epoch14, step806]: loss 0.048794
[epoch14, step807]: loss 0.051901
[epoch14, step808]: loss 0.056505
[epoch14, step809]: loss 0.046649
[epoch14, step810]: loss 0.043969
[epoch14, step811]: loss 0.051830
[epoch14, step812]: loss 0.053152
[epoch14, step813]: loss 0.046816
[epoch14, step814]: loss 0.052295
[epoch14, step815]: loss 0.050208
[epoch14, step816]: loss 0.049896
[epoch14, step817]: loss 0.045827
[epoch14, step818]: loss 0.047400
[epoch14, step819]: loss 0.061710
[epoch14, step820]: loss 0.045600
[epoch14, step821]: loss 0.044756
[epoch14, step822]: loss 0.055461
[epoch14, step823]: loss 0.045391
[epoch14, step824]: loss 0.052615
[epoch14, step825]: loss 0.052610
[epoch14, step826]: loss 0.041238
[epoch14, step827]: loss 0.048167
[epoch14, step828]: loss 0.052967
[epoch14, step829]: loss 0.049148
[epoch14, step830]: loss 0.039126
[epoch14, step831]: loss 0.046663
[epoch14, step832]: loss 0.055792
[epoch14, step833]: loss 0.053879
[epoch14, step834]: loss 0.050651
[epoch14, step835]: loss 0.049016
[epoch14, step836]: loss 0.047696
[epoch14, step837]: loss 0.045929
[epoch14, step838]: loss 0.055955
[epoch14, step839]: loss 0.052295
[epoch14, step840]: loss 0.044728
[epoch14, step841]: loss 0.049703
[epoch14, step842]: loss 0.052268
[epoch14, step843]: loss 0.054118
[epoch14, step844]: loss 0.054112
[epoch14, step845]: loss 0.049610
[epoch14, step846]: loss 0.061243
[epoch14, step847]: loss 0.051625
[epoch14, step848]: loss 0.036152
[epoch14, step849]: loss 0.048273
[epoch14, step850]: loss 0.052997
[epoch14, step851]: loss 0.048884
[epoch14, step852]: loss 0.049221
[epoch14, step853]: loss 0.056626
[epoch14, step854]: loss 0.052933
[epoch14, step855]: loss 0.048182
[epoch14, step856]: loss 0.042436
[epoch14, step857]: loss 0.053395
[epoch14, step858]: loss 0.052693
[epoch14, step859]: loss 0.045873
[epoch14, step860]: loss 0.053623
[epoch14, step861]: loss 0.049614
[epoch14, step862]: loss 0.043090
[epoch14, step863]: loss 0.051355
[epoch14, step864]: loss 0.056361
[epoch14, step865]: loss 0.051108
[epoch14, step866]: loss 0.053843
[epoch14, step867]: loss 0.049166
[epoch14, step868]: loss 0.053194
[epoch14, step869]: loss 0.045547
[epoch14, step870]: loss 0.049050
[epoch14, step871]: loss 0.056009
[epoch14, step872]: loss 0.053041
[epoch14, step873]: loss 0.045375
[epoch14, step874]: loss 0.049149
[epoch14, step875]: loss 0.058596
[epoch14, step876]: loss 0.054242
[epoch14, step877]: loss 0.034102
[epoch14, step878]: loss 0.046244
[epoch14, step879]: loss 0.050754
[epoch14, step880]: loss 0.047546
[epoch14, step881]: loss 0.053272
[epoch14, step882]: loss 0.045657
[epoch14, step883]: loss 0.047620
[epoch14, step884]: loss 0.059098
[epoch14, step885]: loss 0.058554
[epoch14, step886]: loss 0.057320
[epoch14, step887]: loss 0.058117
[epoch14, step888]: loss 0.048027
[epoch14, step889]: loss 0.052621
[epoch14, step890]: loss 0.052608
[epoch14, step891]: loss 0.047982
[epoch14, step892]: loss 0.051626
[epoch14, step893]: loss 0.052933
[epoch14, step894]: loss 0.052779
[epoch14, step895]: loss 0.043413
[epoch14, step896]: loss 0.059350
[epoch14, step897]: loss 0.060324
[epoch14, step898]: loss 0.046914
[epoch14, step899]: loss 0.040489
[epoch14, step900]: loss 0.051615
[epoch14, step901]: loss 0.055551
[epoch14, step902]: loss 0.046059
[epoch14, step903]: loss 0.055952
[epoch14, step904]: loss 0.048618
[epoch14, step905]: loss 0.046702
[epoch14, step906]: loss 0.041605
[epoch14, step907]: loss 0.053215
[epoch14, step908]: loss 0.055041
[epoch14, step909]: loss 0.049365
[epoch14, step910]: loss 0.042295
[epoch14, step911]: loss 0.043613
[epoch14, step912]: loss 0.053079
[epoch14, step913]: loss 0.053574
[epoch14, step914]: loss 0.054655
[epoch14, step915]: loss 0.045506
[epoch14, step916]: loss 0.051026
[epoch14, step917]: loss 0.050479
[epoch14, step918]: loss 0.056714
[epoch14, step919]: loss 0.044449
[epoch14, step920]: loss 0.057393
[epoch14, step921]: loss 0.046637
[epoch14, step922]: loss 0.046912
[epoch14, step923]: loss 0.055243
[epoch14, step924]: loss 0.044286
[epoch14, step925]: loss 0.048570
[epoch14, step926]: loss 0.049828
[epoch14, step927]: loss 0.055755
[epoch14, step928]: loss 0.046909
[epoch14, step929]: loss 0.050720
[epoch14, step930]: loss 0.051086
[epoch14, step931]: loss 0.055325
[epoch14, step932]: loss 0.045342
[epoch14, step933]: loss 0.050777
[epoch14, step934]: loss 0.054846
[epoch14, step935]: loss 0.048905
[epoch14, step936]: loss 0.045150
[epoch14, step937]: loss 0.046167
[epoch14, step938]: loss 0.058565
[epoch14, step939]: loss 0.045227
[epoch14, step940]: loss 0.053365
[epoch14, step941]: loss 0.052438
[epoch14, step942]: loss 0.050780
[epoch14, step943]: loss 0.054944
[epoch14, step944]: loss 0.052659
[epoch14, step945]: loss 0.051818
[epoch14, step946]: loss 0.050681
[epoch14, step947]: loss 0.048415
[epoch14, step948]: loss 0.059673
[epoch14, step949]: loss 0.048720
[epoch14, step950]: loss 0.050614
[epoch14, step951]: loss 0.055284
[epoch14, step952]: loss 0.053686
[epoch14, step953]: loss 0.052342
[epoch14, step954]: loss 0.050521
[epoch14, step955]: loss 0.052280
[epoch14, step956]: loss 0.075800
[epoch14, step957]: loss 0.066971
[epoch14, step958]: loss 0.070512
[epoch14, step959]: loss 0.069470
[epoch14, step960]: loss 0.063543
[epoch14, step961]: loss 0.066602
[epoch14, step962]: loss 0.065114
[epoch14, step963]: loss 0.067085
[epoch14, step964]: loss 0.063535
[epoch14, step965]: loss 0.067544
[epoch14, step966]: loss 0.061505
[epoch14, step967]: loss 0.066280
[epoch14, step968]: loss 0.066193
[epoch14, step969]: loss 0.061548
[epoch14, step970]: loss 0.064326
[epoch14, step971]: loss 0.064093
[epoch14, step972]: loss 0.066434
[epoch14, step973]: loss 0.063949
[epoch14, step974]: loss 0.066516
[epoch14, step975]: loss 0.062042
[epoch14, step976]: loss 0.066321
[epoch14, step977]: loss 0.065359
[epoch14, step978]: loss 0.061072
[epoch14, step979]: loss 0.064372
[epoch14, step980]: loss 0.063467
[epoch14, step981]: loss 0.065793
[epoch14, step982]: loss 0.062729
[epoch14, step983]: loss 0.065955
[epoch14, step984]: loss 0.061089
[epoch14, step985]: loss 0.065985
[epoch14, step986]: loss 0.064590
[epoch14, step987]: loss 0.059538
[epoch14, step988]: loss 0.063353
[epoch14, step989]: loss 0.063300
[epoch14, step990]: loss 0.065290
[epoch14, step991]: loss 0.062079
[epoch14, step992]: loss 0.065576
[epoch14, step993]: loss 0.061311
[epoch14, step994]: loss 0.065573
[epoch14, step995]: loss 0.064730
[epoch14, step996]: loss 0.059583
[epoch14, step997]: loss 0.062974
[epoch14, step998]: loss 0.063126
[epoch14, step999]: loss 0.064853
[epoch14, step1000]: loss 0.062468
[epoch14, step1001]: loss 0.065426
[epoch14, step1002]: loss 0.060374
[epoch14, step1003]: loss 0.065628
[epoch14, step1004]: loss 0.063896
[epoch14, step1005]: loss 0.059408
[epoch14, step1006]: loss 0.062970
[epoch14, step1007]: loss 0.062771
[epoch14, step1008]: loss 0.065008
[epoch14, step1009]: loss 0.061894
[epoch14, step1010]: loss 0.064834
[epoch14, step1011]: loss 0.060412
[epoch14, step1012]: loss 0.065035
[epoch14, step1013]: loss 0.064109
[epoch14, step1014]: loss 0.059675
[epoch14, step1015]: loss 0.062575
[epoch14, step1016]: loss 0.062672
[epoch14, step1017]: loss 0.064821
[epoch14, step1018]: loss 0.061697
[epoch14, step1019]: loss 0.064927
[epoch14, step1020]: loss 0.060611
[epoch14, step1021]: loss 0.065234
[epoch14, step1022]: loss 0.064044
[epoch14, step1023]: loss 0.059338
[epoch14, step1024]: loss 0.062052
[epoch14, step1025]: loss 0.062952
[epoch14, step1026]: loss 0.064853
[epoch14, step1027]: loss 0.061332
[epoch14, step1028]: loss 0.064827
[epoch14, step1029]: loss 0.060244
[epoch14, step1030]: loss 0.065261
[epoch14, step1031]: loss 0.064503
[epoch14, step1032]: loss 0.059169
[epoch14, step1033]: loss 0.063062
[epoch14, step1034]: loss 0.062875
[epoch14, step1035]: loss 0.064974
[epoch14, step1036]: loss 0.061920
[epoch14, step1037]: loss 0.064960
[epoch14, step1038]: loss 0.060276
[epoch14, step1039]: loss 0.064935
[epoch14, step1040]: loss 0.064077
[epoch14, step1041]: loss 0.059342
[epoch14, step1042]: loss 0.062150
[epoch14, step1043]: loss 0.062422
[epoch14, step1044]: loss 0.064340
[epoch14, step1045]: loss 0.061428
[epoch14, step1046]: loss 0.064683
[epoch14, step1047]: loss 0.059889
[epoch14, step1048]: loss 0.065187
[epoch14, step1049]: loss 0.063780
[epoch14, step1050]: loss 0.059173
[epoch14, step1051]: loss 0.062302
[epoch14, step1052]: loss 0.062793
[epoch14, step1053]: loss 0.064750
[epoch14, step1054]: loss 0.061962
[epoch14, step1055]: loss 0.064730
[epoch14, step1056]: loss 0.060227
[epoch14, step1057]: loss 0.064750
[epoch14, step1058]: loss 0.063582
[epoch14, step1059]: loss 0.059239
[epoch14, step1060]: loss 0.061867
[epoch14, step1061]: loss 0.062858
[epoch14, step1062]: loss 0.064442
[epoch14, step1063]: loss 0.061709
[epoch14, step1064]: loss 0.064819
[epoch14, step1065]: loss 0.060529
[epoch14, step1066]: loss 0.064999
[epoch14, step1067]: loss 0.063748
[epoch14, step1068]: loss 0.059688
[epoch14, step1069]: loss 0.061478
[epoch14, step1070]: loss 0.062244
[epoch14, step1071]: loss 0.064211
[epoch14, step1072]: loss 0.061231
[epoch14, step1073]: loss 0.064504
[epoch14, step1074]: loss 0.060544
[epoch14, step1075]: loss 0.064577
[epoch14, step1076]: loss 0.063525
[epoch14, step1077]: loss 0.058558
[epoch14, step1078]: loss 0.062302
[epoch14, step1079]: loss 0.062085
[epoch14, step1080]: loss 0.064083
[epoch14, step1081]: loss 0.061832
[epoch14, step1082]: loss 0.064488
[epoch14, step1083]: loss 0.060322
[epoch14, step1084]: loss 0.064601
[epoch14, step1085]: loss 0.063822
[epoch14, step1086]: loss 0.059507
[epoch14, step1087]: loss 0.062287
[epoch14, step1088]: loss 0.062548
[epoch14, step1089]: loss 0.064098
[epoch14, step1090]: loss 0.061410
[epoch14, step1091]: loss 0.064544
[epoch14, step1092]: loss 0.060338
[epoch14, step1093]: loss 0.064680
[epoch14, step1094]: loss 0.063856
[epoch14, step1095]: loss 0.058607
[epoch14, step1096]: loss 0.062486
[epoch14, step1097]: loss 0.062079
[epoch14, step1098]: loss 0.064464
[epoch14, step1099]: loss 0.061479
[epoch14, step1100]: loss 0.064372
[epoch14, step1101]: loss 0.060645
[epoch14, step1102]: loss 0.064729
[epoch14, step1103]: loss 0.063661
[epoch14, step1104]: loss 0.058608
[epoch14, step1105]: loss 0.061816
[epoch14, step1106]: loss 0.062299
[epoch14, step1107]: loss 0.064143
[epoch14, step1108]: loss 0.061407
[epoch14, step1109]: loss 0.064105
[epoch14, step1110]: loss 0.059715
[epoch14, step1111]: loss 0.064418
[epoch14, step1112]: loss 0.063437
[epoch14, step1113]: loss 0.058570
[epoch14, step1114]: loss 0.062001
[epoch14, step1115]: loss 0.061949
[epoch14, step1116]: loss 0.063942
[epoch14, step1117]: loss 0.061376
[epoch14, step1118]: loss 0.064410
[epoch14, step1119]: loss 0.060768
[epoch14, step1120]: loss 0.064724
[epoch14, step1121]: loss 0.063480
[epoch14, step1122]: loss 0.058941
[epoch14, step1123]: loss 0.062046
[epoch14, step1124]: loss 0.062177
[epoch14, step1125]: loss 0.064173
[epoch14, step1126]: loss 0.061171
[epoch14, step1127]: loss 0.064378
[epoch14, step1128]: loss 0.060227
[epoch14, step1129]: loss 0.064556
[epoch14, step1130]: loss 0.062892
[epoch14, step1131]: loss 0.058535
[epoch14, step1132]: loss 0.061809
[epoch14, step1133]: loss 0.062196
[epoch14, step1134]: loss 0.064074
[epoch14, step1135]: loss 0.060711
[epoch14, step1136]: loss 0.064006
[epoch14, step1137]: loss 0.059280
[epoch14, step1138]: loss 0.064278
[epoch14, step1139]: loss 0.063561
[epoch14, step1140]: loss 0.058103
[epoch14, step1141]: loss 0.061322
[epoch14, step1142]: loss 0.062319
[epoch14, step1143]: loss 0.064084
[epoch14, step1144]: loss 0.061466
[epoch14, step1145]: loss 0.064339
[epoch14, step1146]: loss 0.059289
[epoch14, step1147]: loss 0.064120
[epoch14, step1148]: loss 0.063530
[epoch14, step1149]: loss 0.058304
[epoch14, step1150]: loss 0.062040
[epoch14, step1151]: loss 0.062297
[epoch14, step1152]: loss 0.063761
[epoch14, step1153]: loss 0.061097
[epoch14, step1154]: loss 0.064191
[epoch14, step1155]: loss 0.059735
[epoch14, step1156]: loss 0.064535
[epoch14, step1157]: loss 0.063540
[epoch14, step1158]: loss 0.058188
[epoch14, step1159]: loss 0.061575
[epoch14, step1160]: loss 0.061856
[epoch14, step1161]: loss 0.063695
[epoch14, step1162]: loss 0.061066
[epoch14, step1163]: loss 0.064356
[epoch14, step1164]: loss 0.059283
[epoch14, step1165]: loss 0.063902
[epoch14, step1166]: loss 0.063010
[epoch14, step1167]: loss 0.058170
[epoch14, step1168]: loss 0.061558
[epoch14, step1169]: loss 0.062042
[epoch14, step1170]: loss 0.063796
[epoch14, step1171]: loss 0.061056
[epoch14, step1172]: loss 0.064206
[epoch14, step1173]: loss 0.059918
[epoch14, step1174]: loss 0.064066
[epoch14, step1175]: loss 0.063384
[epoch14, step1176]: loss 0.058422
[epoch14, step1177]: loss 0.061288
[epoch14, step1178]: loss 0.061677
[epoch14, step1179]: loss 0.063786
[epoch14, step1180]: loss 0.060909
[epoch14, step1181]: loss 0.063990
[epoch14, step1182]: loss 0.059435
[epoch14, step1183]: loss 0.064013
[epoch14, step1184]: loss 0.063404
[epoch14, step1185]: loss 0.058950
[epoch14, step1186]: loss 0.061399
[epoch14, step1187]: loss 0.062049
[epoch14, step1188]: loss 0.063773
[epoch14, step1189]: loss 0.060629
[epoch14, step1190]: loss 0.064130
[epoch14, step1191]: loss 0.060031
[epoch14, step1192]: loss 0.063733
[epoch14, step1193]: loss 0.062898
[epoch14, step1194]: loss 0.058059
[epoch14, step1195]: loss 0.061920
[epoch14, step1196]: loss 0.061805
[epoch14, step1197]: loss 0.063664
[epoch14, step1198]: loss 0.060628
[epoch14, step1199]: loss 0.063897
[epoch14, step1200]: loss 0.059288
[epoch14, step1201]: loss 0.063805
[epoch14, step1202]: loss 0.062735
[epoch14, step1203]: loss 0.059049
[epoch14, step1204]: loss 0.061252
[epoch14, step1205]: loss 0.061537
[epoch14, step1206]: loss 0.063684
[epoch14, step1207]: loss 0.060339
[epoch14, step1208]: loss 0.063708
[epoch14, step1209]: loss 0.058980
[epoch14, step1210]: loss 0.063867
[epoch14, step1211]: loss 0.063140
[epoch14, step1212]: loss 0.058852
[epoch14, step1213]: loss 0.061818
[epoch14, step1214]: loss 0.061782
[epoch14, step1215]: loss 0.063523
[epoch14, step1216]: loss 0.060401
[epoch14, step1217]: loss 0.063782
[epoch14, step1218]: loss 0.059014
[epoch14, step1219]: loss 0.063756
[epoch14, step1220]: loss 0.062745
[epoch14, step1221]: loss 0.057791
[epoch14, step1222]: loss 0.061333
[epoch14, step1223]: loss 0.061408
[epoch14, step1224]: loss 0.063250
[epoch14, step1225]: loss 0.060587
[epoch14, step1226]: loss 0.063944
[epoch14, step1227]: loss 0.058715
[epoch14, step1228]: loss 0.063752
[epoch14, step1229]: loss 0.063248
[epoch14, step1230]: loss 0.058843
[epoch14, step1231]: loss 0.061532
[epoch14, step1232]: loss 0.061657
[epoch14, step1233]: loss 0.063387
[epoch14, step1234]: loss 0.060664
[epoch14, step1235]: loss 0.063664
[epoch14, step1236]: loss 0.060195
[epoch14, step1237]: loss 0.064023
[epoch14, step1238]: loss 0.063019
[epoch14, step1239]: loss 0.058046
[epoch14, step1240]: loss 0.061117
[epoch14, step1241]: loss 0.062165
[epoch14, step1242]: loss 0.063564
[epoch14, step1243]: loss 0.060157
[epoch14, step1244]: loss 0.063745
[epoch14, step1245]: loss 0.058675
[epoch14, step1246]: loss 0.063788
[epoch14, step1247]: loss 0.063052
[epoch14, step1248]: loss 0.058183
[epoch14, step1249]: loss 0.061015
[epoch14, step1250]: loss 0.061456
[epoch14, step1251]: loss 0.063359
[epoch14, step1252]: loss 0.060844
[epoch14, step1253]: loss 0.063510
[epoch14, step1254]: loss 0.059306
[epoch14, step1255]: loss 0.063654
[epoch14, step1256]: loss 0.062596
[epoch14, step1257]: loss 0.057896
[epoch14, step1258]: loss 0.061272
[epoch14, step1259]: loss 0.061574
[epoch14, step1260]: loss 0.063221
[epoch14, step1261]: loss 0.060583
[epoch14, step1262]: loss 0.063766
[epoch14, step1263]: loss 0.058885
[epoch14, step1264]: loss 0.063778
[epoch14, step1265]: loss 0.063212
[epoch14, step1266]: loss 0.058539
[epoch14, step1267]: loss 0.061161
[epoch14, step1268]: loss 0.061635
[epoch14, step1269]: loss 0.063212
[epoch14, step1270]: loss 0.060606
[epoch14, step1271]: loss 0.063570
[epoch14, step1272]: loss 0.059242
[epoch14, step1273]: loss 0.063904
[epoch14, step1274]: loss 0.062978
[epoch14, step1275]: loss 0.058448
[epoch14, step1276]: loss 0.061018
[epoch14, step1277]: loss 0.061355
[epoch14, step1278]: loss 0.063198
[epoch14, step1279]: loss 0.060199
[epoch14, step1280]: loss 0.063587
[epoch14, step1281]: loss 0.059184
[epoch14, step1282]: loss 0.063331
[epoch14, step1283]: loss 0.062665
[epoch14, step1284]: loss 0.057203
[epoch14, step1285]: loss 0.061208
[epoch14, step1286]: loss 0.061210
[epoch14, step1287]: loss 0.062772
[epoch14, step1288]: loss 0.060244
[epoch14, step1289]: loss 0.063191
[epoch14, step1290]: loss 0.059657
[epoch14, step1291]: loss 0.063499
[epoch14, step1292]: loss 0.062190
[epoch14, step1293]: loss 0.057448
[epoch14, step1294]: loss 0.060749
[epoch14, step1295]: loss 0.061006
[epoch14, step1296]: loss 0.062878
[epoch14, step1297]: loss 0.059762
[epoch14, step1298]: loss 0.063239
[epoch14, step1299]: loss 0.059484
[epoch14, step1300]: loss 0.063462
[epoch14, step1301]: loss 0.062841
[epoch14, step1302]: loss 0.058160
[epoch14, step1303]: loss 0.061407
[epoch14, step1304]: loss 0.061321
[epoch14, step1305]: loss 0.062845
[epoch14, step1306]: loss 0.060131
[epoch14, step1307]: loss 0.063646
[epoch14, step1308]: loss 0.059426
[epoch14, step1309]: loss 0.063537
[epoch14, step1310]: loss 0.062401
[epoch14, step1311]: loss 0.057706
[epoch14, step1312]: loss 0.061256
[epoch14, step1313]: loss 0.061286
[epoch14, step1314]: loss 0.063146
[epoch14, step1315]: loss 0.060012
[epoch14, step1316]: loss 0.063032
[epoch14, step1317]: loss 0.059191
[epoch14, step1318]: loss 0.063655
[epoch14, step1319]: loss 0.062283
[epoch14, step1320]: loss 0.058068
[epoch14, step1321]: loss 0.060529
[epoch14, step1322]: loss 0.061294
[epoch14, step1323]: loss 0.062745
[epoch14, step1324]: loss 0.060205
[epoch14, step1325]: loss 0.063317
[epoch14, step1326]: loss 0.059518
[epoch14, step1327]: loss 0.063241
[epoch14, step1328]: loss 0.062345
[epoch14, step1329]: loss 0.058154
[epoch14, step1330]: loss 0.060885
[epoch14, step1331]: loss 0.061273
[epoch14, step1332]: loss 0.063190
[epoch14, step1333]: loss 0.060495
[epoch14, step1334]: loss 0.063203
[epoch14, step1335]: loss 0.059439
[epoch14, step1336]: loss 0.063149
[epoch14, step1337]: loss 0.062759
[epoch14, step1338]: loss 0.057413
[epoch14, step1339]: loss 0.061189
[epoch14, step1340]: loss 0.061407
[epoch14, step1341]: loss 0.062973
[epoch14, step1342]: loss 0.059912
[epoch14, step1343]: loss 0.063092
[epoch14, step1344]: loss 0.058603
[epoch14, step1345]: loss 0.062963
[epoch14, step1346]: loss 0.062302
[epoch14, step1347]: loss 0.057713
[epoch14, step1348]: loss 0.060838
[epoch14, step1349]: loss 0.061029
[epoch14, step1350]: loss 0.062462
[epoch14, step1351]: loss 0.060564
[epoch14, step1352]: loss 0.063148
[epoch14, step1353]: loss 0.059458
[epoch14, step1354]: loss 0.063433
[epoch14, step1355]: loss 0.062403
[epoch14, step1356]: loss 0.058450
[epoch14, step1357]: loss 0.061006
[epoch14, step1358]: loss 0.060887
[epoch14, step1359]: loss 0.062743
[epoch14, step1360]: loss 0.059630
[epoch14, step1361]: loss 0.063161
[epoch14, step1362]: loss 0.059185
[epoch14, step1363]: loss 0.062925
[epoch14, step1364]: loss 0.062166
[epoch14, step1365]: loss 0.057991
[epoch14, step1366]: loss 0.060680
[epoch14, step1367]: loss 0.060920
[epoch14, step1368]: loss 0.062285
[epoch14, step1369]: loss 0.060087
[epoch14, step1370]: loss 0.063259
[epoch14, step1371]: loss 0.058904
[epoch14, step1372]: loss 0.062861
[epoch14, step1373]: loss 0.062233
[epoch14, step1374]: loss 0.057356
[epoch14, step1375]: loss 0.060669
[epoch14, step1376]: loss 0.060701
[epoch14, step1377]: loss 0.062949
[epoch14, step1378]: loss 0.060055
[epoch14, step1379]: loss 0.063132
[epoch14, step1380]: loss 0.058093
[epoch14, step1381]: loss 0.062798
[epoch14, step1382]: loss 0.062258
[epoch14, step1383]: loss 0.057260
[epoch14, step1384]: loss 0.060262
[epoch14, step1385]: loss 0.060819
[epoch14, step1386]: loss 0.062420
[epoch14, step1387]: loss 0.059642
[epoch14, step1388]: loss 0.063277
[epoch14, step1389]: loss 0.058666
[epoch14, step1390]: loss 0.062936
[epoch14, step1391]: loss 0.061997
[epoch14, step1392]: loss 0.057951
[epoch14, step1393]: loss 0.060540
[epoch14, step1394]: loss 0.060406
[epoch14, step1395]: loss 0.062650
[epoch14, step1396]: loss 0.059472
[epoch14, step1397]: loss 0.062993
[epoch14, step1398]: loss 0.058364
[epoch14, step1399]: loss 0.062389
[epoch14, step1400]: loss 0.062350
[epoch14, step1401]: loss 0.056799
[epoch14, step1402]: loss 0.060447
[epoch14, step1403]: loss 0.060663
[epoch14, step1404]: loss 0.062397
[epoch14, step1405]: loss 0.059240
[epoch14, step1406]: loss 0.062890
[epoch14, step1407]: loss 0.058687
[epoch14, step1408]: loss 0.062967
[epoch14, step1409]: loss 0.062202
[epoch14, step1410]: loss 0.056920
[epoch14, step1411]: loss 0.060740
[epoch14, step1412]: loss 0.060898
[epoch14, step1413]: loss 0.062506
[epoch14, step1414]: loss 0.059922
[epoch14, step1415]: loss 0.062911
[epoch14, step1416]: loss 0.058207
[epoch14, step1417]: loss 0.063139
[epoch14, step1418]: loss 0.062037
[epoch14, step1419]: loss 0.057567
[epoch14, step1420]: loss 0.061095
[epoch14, step1421]: loss 0.060388
[epoch14, step1422]: loss 0.062411
[epoch14, step1423]: loss 0.059689
[epoch14, step1424]: loss 0.062853
[epoch14, step1425]: loss 0.058329
[epoch14, step1426]: loss 0.062559
[epoch14, step1427]: loss 0.061621
[epoch14, step1428]: loss 0.057876
[epoch14, step1429]: loss 0.060163
[epoch14, step1430]: loss 0.060645
[epoch14, step1431]: loss 0.062271
[epoch14, step1432]: loss 0.059588
[epoch14, step1433]: loss 0.062751
[epoch14, step1434]: loss 0.059242
[epoch14, step1435]: loss 0.062410
[epoch14, step1436]: loss 0.061995
[epoch14, step1437]: loss 0.056998
[epoch14, step1438]: loss 0.060515
[epoch14, step1439]: loss 0.061109
[epoch14, step1440]: loss 0.062430
[epoch14, step1441]: loss 0.059693
[epoch14, step1442]: loss 0.063193
[epoch14, step1443]: loss 0.059192
[epoch14, step1444]: loss 0.062906
[epoch14, step1445]: loss 0.061891
[epoch14, step1446]: loss 0.057006
[epoch14, step1447]: loss 0.060736
[epoch14, step1448]: loss 0.060358
[epoch14, step1449]: loss 0.062328
[epoch14, step1450]: loss 0.059655
[epoch14, step1451]: loss 0.062542
[epoch14, step1452]: loss 0.058572
[epoch14, step1453]: loss 0.062236
[epoch14, step1454]: loss 0.061794
[epoch14, step1455]: loss 0.056793
[epoch14, step1456]: loss 0.060362
[epoch14, step1457]: loss 0.060037
[epoch14, step1458]: loss 0.061989
[epoch14, step1459]: loss 0.059882
[epoch14, step1460]: loss 0.062532
[epoch14, step1461]: loss 0.058084
[epoch14, step1462]: loss 0.062099
[epoch14, step1463]: loss 0.062208
[epoch14, step1464]: loss 0.056884
[epoch14, step1465]: loss 0.060481
[epoch14, step1466]: loss 0.060444
[epoch14, step1467]: loss 0.062511
[epoch14, step1468]: loss 0.059469
[epoch14, step1469]: loss 0.062881
[epoch14, step1470]: loss 0.058105
[epoch14, step1471]: loss 0.062976
[epoch14, step1472]: loss 0.061957
[epoch14, step1473]: loss 0.056817
[epoch14, step1474]: loss 0.060244
[epoch14, step1475]: loss 0.060328
[epoch14, step1476]: loss 0.062319
[epoch14, step1477]: loss 0.059674
[epoch14, step1478]: loss 0.062730
[epoch14, step1479]: loss 0.058206
[epoch14, step1480]: loss 0.062416
[epoch14, step1481]: loss 0.062008
[epoch14, step1482]: loss 0.057050
[epoch14, step1483]: loss 0.060322
[epoch14, step1484]: loss 0.060199
[epoch14, step1485]: loss 0.061938
[epoch14, step1486]: loss 0.059364
[epoch14, step1487]: loss 0.062450
[epoch14, step1488]: loss 0.058238
[epoch14, step1489]: loss 0.062271
[epoch14, step1490]: loss 0.061474
[epoch14, step1491]: loss 0.057487
[epoch14, step1492]: loss 0.060438
[epoch14, step1493]: loss 0.060687
[epoch14, step1494]: loss 0.062199
[epoch14, step1495]: loss 0.059844
[epoch14, step1496]: loss 0.062687
[epoch14, step1497]: loss 0.058182
[epoch14, step1498]: loss 0.062342
[epoch14, step1499]: loss 0.061718
[epoch14, step1500]: loss 0.057144
[epoch14, step1501]: loss 0.060261
[epoch14, step1502]: loss 0.060119
[epoch14, step1503]: loss 0.062289
[epoch14, step1504]: loss 0.059472
[epoch14, step1505]: loss 0.062603
[epoch14, step1506]: loss 0.057963
[epoch14, step1507]: loss 0.062188
[epoch14, step1508]: loss 0.061649
[epoch14, step1509]: loss 0.057333
[epoch14, step1510]: loss 0.060528
[epoch14, step1511]: loss 0.059922
[epoch14, step1512]: loss 0.061778
[epoch14, step1513]: loss 0.059464
[epoch14, step1514]: loss 0.062434
[epoch14, step1515]: loss 0.058430
[epoch14, step1516]: loss 0.062229

[epoch14]: avg loss 0.060760

[epoch15, step1]: loss 0.061463
[epoch15, step2]: loss 0.062006
[epoch15, step3]: loss 0.062118
[epoch15, step4]: loss 0.058641
[epoch15, step5]: loss 0.062477
[epoch15, step6]: loss 0.062035
[epoch15, step7]: loss 0.056898
[epoch15, step8]: loss 0.062644
[epoch15, step9]: loss 0.057438
[epoch15, step10]: loss 0.061334
[epoch15, step11]: loss 0.062516
[epoch15, step12]: loss 0.062221
[epoch15, step13]: loss 0.057627
[epoch15, step14]: loss 0.062837
[epoch15, step15]: loss 0.061782
[epoch15, step16]: loss 0.057497
[epoch15, step17]: loss 0.063263
[epoch15, step18]: loss 0.057369
[epoch15, step19]: loss 0.061928
[epoch15, step20]: loss 0.062094
[epoch15, step21]: loss 0.062204
[epoch15, step22]: loss 0.058250
[epoch15, step23]: loss 0.062747
[epoch15, step24]: loss 0.061386
[epoch15, step25]: loss 0.056505
[epoch15, step26]: loss 0.062759
[epoch15, step27]: loss 0.057279
[epoch15, step28]: loss 0.061415
[epoch15, step29]: loss 0.061936
[epoch15, step30]: loss 0.061831
[epoch15, step31]: loss 0.057947
[epoch15, step32]: loss 0.062465
[epoch15, step33]: loss 0.061557
[epoch15, step34]: loss 0.057521
[epoch15, step35]: loss 0.062530
[epoch15, step36]: loss 0.057699
[epoch15, step37]: loss 0.062098
[epoch15, step38]: loss 0.061846
[epoch15, step39]: loss 0.062211
[epoch15, step40]: loss 0.057554
[epoch15, step41]: loss 0.062456
[epoch15, step42]: loss 0.061485
[epoch15, step43]: loss 0.057191
[epoch15, step44]: loss 0.062547
[epoch15, step45]: loss 0.057593
[epoch15, step46]: loss 0.061705
[epoch15, step47]: loss 0.062019
[epoch15, step48]: loss 0.062008
[epoch15, step49]: loss 0.057113
[epoch15, step50]: loss 0.062471
[epoch15, step51]: loss 0.061454
[epoch15, step52]: loss 0.057239
[epoch15, step53]: loss 0.062277
[epoch15, step54]: loss 0.056860
[epoch15, step55]: loss 0.061404
[epoch15, step56]: loss 0.061527
[epoch15, step57]: loss 0.061850
[epoch15, step58]: loss 0.057703
[epoch15, step59]: loss 0.062660
[epoch15, step60]: loss 0.061131
[epoch15, step61]: loss 0.057262
[epoch15, step62]: loss 0.062606
[epoch15, step63]: loss 0.057654
[epoch15, step64]: loss 0.062150
[epoch15, step65]: loss 0.061610
[epoch15, step66]: loss 0.062087
[epoch15, step67]: loss 0.058056
[epoch15, step68]: loss 0.062444
[epoch15, step69]: loss 0.061470
[epoch15, step70]: loss 0.057132
[epoch15, step71]: loss 0.062534
[epoch15, step72]: loss 0.057073
[epoch15, step73]: loss 0.061568
[epoch15, step74]: loss 0.061586
[epoch15, step75]: loss 0.061710
[epoch15, step76]: loss 0.058124
[epoch15, step77]: loss 0.061953
[epoch15, step78]: loss 0.061229
[epoch15, step79]: loss 0.057073
[epoch15, step80]: loss 0.062058
[epoch15, step81]: loss 0.057081
[epoch15, step82]: loss 0.061797
[epoch15, step83]: loss 0.061975
[epoch15, step84]: loss 0.061818
[epoch15, step85]: loss 0.057273
[epoch15, step86]: loss 0.062033
[epoch15, step87]: loss 0.061438
[epoch15, step88]: loss 0.058050
[epoch15, step89]: loss 0.062429
[epoch15, step90]: loss 0.057840
[epoch15, step91]: loss 0.062054
[epoch15, step92]: loss 0.061578
[epoch15, step93]: loss 0.061742
[epoch15, step94]: loss 0.057921
[epoch15, step95]: loss 0.062100
[epoch15, step96]: loss 0.061308
[epoch15, step97]: loss 0.057206
[epoch15, step98]: loss 0.062433
[epoch15, step99]: loss 0.057258
[epoch15, step100]: loss 0.061684
[epoch15, step101]: loss 0.061317
[epoch15, step102]: loss 0.061912
[epoch15, step103]: loss 0.057816
[epoch15, step104]: loss 0.062064
[epoch15, step105]: loss 0.061064
[epoch15, step106]: loss 0.057068
[epoch15, step107]: loss 0.062223
[epoch15, step108]: loss 0.057192
[epoch15, step109]: loss 0.061225
[epoch15, step110]: loss 0.061434
[epoch15, step111]: loss 0.061688
[epoch15, step112]: loss 0.058121
[epoch15, step113]: loss 0.061766
[epoch15, step114]: loss 0.061386
[epoch15, step115]: loss 0.057107
[epoch15, step116]: loss 0.061957
[epoch15, step117]: loss 0.056919
[epoch15, step118]: loss 0.061129
[epoch15, step119]: loss 0.061645
[epoch15, step120]: loss 0.061596
[epoch15, step121]: loss 0.057719
[epoch15, step122]: loss 0.062175
[epoch15, step123]: loss 0.061066
[epoch15, step124]: loss 0.057456
[epoch15, step125]: loss 0.062435
[epoch15, step126]: loss 0.057168
[epoch15, step127]: loss 0.061532
[epoch15, step128]: loss 0.061566
[epoch15, step129]: loss 0.061283
[epoch15, step130]: loss 0.056952
[epoch15, step131]: loss 0.062118
[epoch15, step132]: loss 0.061069
[epoch15, step133]: loss 0.056064
[epoch15, step134]: loss 0.062268
[epoch15, step135]: loss 0.056953
[epoch15, step136]: loss 0.060702
[epoch15, step137]: loss 0.061436
[epoch15, step138]: loss 0.061501
[epoch15, step139]: loss 0.057535
[epoch15, step140]: loss 0.061794
[epoch15, step141]: loss 0.060953
[epoch15, step142]: loss 0.056867
[epoch15, step143]: loss 0.062103
[epoch15, step144]: loss 0.057916
[epoch15, step145]: loss 0.061365
[epoch15, step146]: loss 0.061741
[epoch15, step147]: loss 0.061685
[epoch15, step148]: loss 0.057250
[epoch15, step149]: loss 0.062207
[epoch15, step150]: loss 0.061136
[epoch15, step151]: loss 0.056170
[epoch15, step152]: loss 0.062339
[epoch15, step153]: loss 0.056607
[epoch15, step154]: loss 0.061441
[epoch15, step155]: loss 0.061302
[epoch15, step156]: loss 0.061668
[epoch15, step157]: loss 0.057098
[epoch15, step158]: loss 0.061571
[epoch15, step159]: loss 0.060966
[epoch15, step160]: loss 0.056526
[epoch15, step161]: loss 0.061784
[epoch15, step162]: loss 0.056831
[epoch15, step163]: loss 0.060878
[epoch15, step164]: loss 0.061170
[epoch15, step165]: loss 0.061443
[epoch15, step166]: loss 0.056873
[epoch15, step167]: loss 0.061914
[epoch15, step168]: loss 0.060703
[epoch15, step169]: loss 0.056933
[epoch15, step170]: loss 0.061862
[epoch15, step171]: loss 0.057380
[epoch15, step172]: loss 0.061131
[epoch15, step173]: loss 0.061360
[epoch15, step174]: loss 0.061711
[epoch15, step175]: loss 0.056945
[epoch15, step176]: loss 0.061960
[epoch15, step177]: loss 0.060889
[epoch15, step178]: loss 0.056048
[epoch15, step179]: loss 0.062177
[epoch15, step180]: loss 0.056642
[epoch15, step181]: loss 0.060928
[epoch15, step182]: loss 0.061025
[epoch15, step183]: loss 0.061374
[epoch15, step184]: loss 0.057109
[epoch15, step185]: loss 0.061580
[epoch15, step186]: loss 0.060633
[epoch15, step187]: loss 0.056784
[epoch15, step188]: loss 0.061834
[epoch15, step189]: loss 0.056706
[epoch15, step190]: loss 0.061174
[epoch15, step191]: loss 0.061019
[epoch15, step192]: loss 0.061157
[epoch15, step193]: loss 0.057337
[epoch15, step194]: loss 0.061591
[epoch15, step195]: loss 0.060690
[epoch15, step196]: loss 0.055931
[epoch15, step197]: loss 0.061808
[epoch15, step198]: loss 0.056645
[epoch15, step199]: loss 0.060779
[epoch15, step200]: loss 0.060943
[epoch15, step201]: loss 0.061232
[epoch15, step202]: loss 0.057230
[epoch15, step203]: loss 0.061763
[epoch15, step204]: loss 0.060702
[epoch15, step205]: loss 0.056809
[epoch15, step206]: loss 0.061881
[epoch15, step207]: loss 0.056760
[epoch15, step208]: loss 0.060842
[epoch15, step209]: loss 0.060881
[epoch15, step210]: loss 0.061270
[epoch15, step211]: loss 0.057528
[epoch15, step212]: loss 0.061699
[epoch15, step213]: loss 0.060831
[epoch15, step214]: loss 0.057007
[epoch15, step215]: loss 0.061749
[epoch15, step216]: loss 0.056681
[epoch15, step217]: loss 0.061103
[epoch15, step218]: loss 0.060797
[epoch15, step219]: loss 0.061287
[epoch15, step220]: loss 0.057804
[epoch15, step221]: loss 0.061306
[epoch15, step222]: loss 0.060447
[epoch15, step223]: loss 0.055727
[epoch15, step224]: loss 0.061697
[epoch15, step225]: loss 0.056444
[epoch15, step226]: loss 0.060869
[epoch15, step227]: loss 0.061077
[epoch15, step228]: loss 0.061080
[epoch15, step229]: loss 0.057324
[epoch15, step230]: loss 0.061255
[epoch15, step231]: loss 0.060399
[epoch15, step232]: loss 0.056021
[epoch15, step233]: loss 0.061775
[epoch15, step234]: loss 0.056964
[epoch15, step235]: loss 0.061030
[epoch15, step236]: loss 0.060917
[epoch15, step237]: loss 0.061360
[epoch15, step238]: loss 0.056510
[epoch15, step239]: loss 0.061552
[epoch15, step240]: loss 0.060974
[epoch15, step241]: loss 0.056665
[epoch15, step242]: loss 0.061697
[epoch15, step243]: loss 0.056846
[epoch15, step244]: loss 0.060813
[epoch15, step245]: loss 0.060953
[epoch15, step246]: loss 0.061233
[epoch15, step247]: loss 0.057362
[epoch15, step248]: loss 0.061374
[epoch15, step249]: loss 0.060530
[epoch15, step250]: loss 0.055901
[epoch15, step251]: loss 0.061506
[epoch15, step252]: loss 0.056626
[epoch15, step253]: loss 0.060760
[epoch15, step254]: loss 0.061087
[epoch15, step255]: loss 0.060994
[epoch15, step256]: loss 0.057457
[epoch15, step257]: loss 0.061528
[epoch15, step258]: loss 0.060359
[epoch15, step259]: loss 0.055684
[epoch15, step260]: loss 0.061748
[epoch15, step261]: loss 0.056307
[epoch15, step262]: loss 0.060852
[epoch15, step263]: loss 0.060859
[epoch15, step264]: loss 0.061129
[epoch15, step265]: loss 0.057375
[epoch15, step266]: loss 0.061175
[epoch15, step267]: loss 0.060678
[epoch15, step268]: loss 0.056097
[epoch15, step269]: loss 0.061417
[epoch15, step270]: loss 0.056305
[epoch15, step271]: loss 0.060382
[epoch15, step272]: loss 0.060862
[epoch15, step273]: loss 0.061029
[epoch15, step274]: loss 0.056730
[epoch15, step275]: loss 0.061479
[epoch15, step276]: loss 0.060697
[epoch15, step277]: loss 0.056224
[epoch15, step278]: loss 0.061404
[epoch15, step279]: loss 0.056184
[epoch15, step280]: loss 0.060410
[epoch15, step281]: loss 0.061046
[epoch15, step282]: loss 0.060950
[epoch15, step283]: loss 0.057196
[epoch15, step284]: loss 0.061720
[epoch15, step285]: loss 0.060438
[epoch15, step286]: loss 0.057209
[epoch15, step287]: loss 0.062005
[epoch15, step288]: loss 0.056484
[epoch15, step289]: loss 0.060721
[epoch15, step290]: loss 0.061069
[epoch15, step291]: loss 0.060888
[epoch15, step292]: loss 0.057091
[epoch15, step293]: loss 0.061160
[epoch15, step294]: loss 0.060187
[epoch15, step295]: loss 0.055728
[epoch15, step296]: loss 0.061319
[epoch15, step297]: loss 0.056515
[epoch15, step298]: loss 0.060553
[epoch15, step299]: loss 0.060924
[epoch15, step300]: loss 0.060774
[epoch15, step301]: loss 0.057663
[epoch15, step302]: loss 0.061101
[epoch15, step303]: loss 0.060580
[epoch15, step304]: loss 0.055624
[epoch15, step305]: loss 0.061440
[epoch15, step306]: loss 0.056814
[epoch15, step307]: loss 0.060891
[epoch15, step308]: loss 0.060608
[epoch15, step309]: loss 0.060942
[epoch15, step310]: loss 0.057178
[epoch15, step311]: loss 0.060951
[epoch15, step312]: loss 0.060558
[epoch15, step313]: loss 0.056381
[epoch15, step314]: loss 0.061279
[epoch15, step315]: loss 0.056843
[epoch15, step316]: loss 0.060477
[epoch15, step317]: loss 0.060559
[epoch15, step318]: loss 0.060862
[epoch15, step319]: loss 0.057086
[epoch15, step320]: loss 0.061101
[epoch15, step321]: loss 0.060291
[epoch15, step322]: loss 0.056679
[epoch15, step323]: loss 0.061369
[epoch15, step324]: loss 0.056486
[epoch15, step325]: loss 0.060217
[epoch15, step326]: loss 0.060809
[epoch15, step327]: loss 0.060949
[epoch15, step328]: loss 0.057215
[epoch15, step329]: loss 0.061321
[epoch15, step330]: loss 0.060535
[epoch15, step331]: loss 0.056560
[epoch15, step332]: loss 0.061507
[epoch15, step333]: loss 0.056645
[epoch15, step334]: loss 0.060461
[epoch15, step335]: loss 0.060596
[epoch15, step336]: loss 0.060872
[epoch15, step337]: loss 0.056253
[epoch15, step338]: loss 0.060981
[epoch15, step339]: loss 0.060253
[epoch15, step340]: loss 0.056387
[epoch15, step341]: loss 0.061285
[epoch15, step342]: loss 0.055845
[epoch15, step343]: loss 0.060336
[epoch15, step344]: loss 0.060443
[epoch15, step345]: loss 0.060820
[epoch15, step346]: loss 0.056918
[epoch15, step347]: loss 0.061016
[epoch15, step348]: loss 0.060183
[epoch15, step349]: loss 0.055801
[epoch15, step350]: loss 0.061230
[epoch15, step351]: loss 0.055925
[epoch15, step352]: loss 0.060046
[epoch15, step353]: loss 0.060510
[epoch15, step354]: loss 0.060834
[epoch15, step355]: loss 0.056904
[epoch15, step356]: loss 0.060956
[epoch15, step357]: loss 0.060234
[epoch15, step358]: loss 0.056476
[epoch15, step359]: loss 0.061121
[epoch15, step360]: loss 0.056021
[epoch15, step361]: loss 0.060729
[epoch15, step362]: loss 0.060370
[epoch15, step363]: loss 0.061031
[epoch15, step364]: loss 0.056899
[epoch15, step365]: loss 0.060797
[epoch15, step366]: loss 0.060175
[epoch15, step367]: loss 0.056197
[epoch15, step368]: loss 0.061145
[epoch15, step369]: loss 0.056068
[epoch15, step370]: loss 0.060082
[epoch15, step371]: loss 0.060274
[epoch15, step372]: loss 0.060641
[epoch15, step373]: loss 0.056226
[epoch15, step374]: loss 0.060787
[epoch15, step375]: loss 0.059918
[epoch15, step376]: loss 0.055123
[epoch15, step377]: loss 0.061000
[epoch15, step378]: loss 0.056574
[epoch15, step379]: loss 0.059952
[epoch15, step380]: loss 0.060663
[epoch15, step381]: loss 0.060763
[epoch15, step382]: loss 0.057739
[epoch15, step383]: loss 0.061364
[epoch15, step384]: loss 0.060150
[epoch15, step385]: loss 0.055376
[epoch15, step386]: loss 0.061592
[epoch15, step387]: loss 0.055690
[epoch15, step388]: loss 0.060057
[epoch15, step389]: loss 0.060595
[epoch15, step390]: loss 0.060258
[epoch15, step391]: loss 0.056037
[epoch15, step392]: loss 0.060592
[epoch15, step393]: loss 0.060128
[epoch15, step394]: loss 0.056129
[epoch15, step395]: loss 0.061084
[epoch15, step396]: loss 0.055923
[epoch15, step397]: loss 0.060172
[epoch15, step398]: loss 0.060493
[epoch15, step399]: loss 0.060492
[epoch15, step400]: loss 0.056135
[epoch15, step401]: loss 0.060782
[epoch15, step402]: loss 0.059928
[epoch15, step403]: loss 0.055860
[epoch15, step404]: loss 0.061211
[epoch15, step405]: loss 0.055777
[epoch15, step406]: loss 0.060276
[epoch15, step407]: loss 0.060264
[epoch15, step408]: loss 0.060591
[epoch15, step409]: loss 0.056237
[epoch15, step410]: loss 0.060433
[epoch15, step411]: loss 0.059781
[epoch15, step412]: loss 0.054929
[epoch15, step413]: loss 0.060863
[epoch15, step414]: loss 0.056416
[epoch15, step415]: loss 0.060045
[epoch15, step416]: loss 0.060234
[epoch15, step417]: loss 0.060429
[epoch15, step418]: loss 0.056035
[epoch15, step419]: loss 0.060618
[epoch15, step420]: loss 0.059669
[epoch15, step421]: loss 0.055552
[epoch15, step422]: loss 0.060794
[epoch15, step423]: loss 0.055841
[epoch15, step424]: loss 0.059600
[epoch15, step425]: loss 0.060401
[epoch15, step426]: loss 0.060450
[epoch15, step427]: loss 0.057112
[epoch15, step428]: loss 0.060853
[epoch15, step429]: loss 0.059626
[epoch15, step430]: loss 0.055690
[epoch15, step431]: loss 0.061363
[epoch15, step432]: loss 0.055544
[epoch15, step433]: loss 0.059749
[epoch15, step434]: loss 0.060251
[epoch15, step435]: loss 0.060350
[epoch15, step436]: loss 0.056873
[epoch15, step437]: loss 0.060569
[epoch15, step438]: loss 0.059592
[epoch15, step439]: loss 0.056020
[epoch15, step440]: loss 0.060717
[epoch15, step441]: loss 0.056051
[epoch15, step442]: loss 0.059612
[epoch15, step443]: loss 0.060001
[epoch15, step444]: loss 0.060523
[epoch15, step445]: loss 0.056744
[epoch15, step446]: loss 0.060463
[epoch15, step447]: loss 0.059924
[epoch15, step448]: loss 0.054990
[epoch15, step449]: loss 0.060819
[epoch15, step450]: loss 0.056329
[epoch15, step451]: loss 0.059866
[epoch15, step452]: loss 0.060457
[epoch15, step453]: loss 0.060671
[epoch15, step454]: loss 0.056679
[epoch15, step455]: loss 0.060693
[epoch15, step456]: loss 0.059951
[epoch15, step457]: loss 0.055987
[epoch15, step458]: loss 0.061057
[epoch15, step459]: loss 0.055607
[epoch15, step460]: loss 0.059768
[epoch15, step461]: loss 0.060055
[epoch15, step462]: loss 0.060418
[epoch15, step463]: loss 0.056650
[epoch15, step464]: loss 0.060518
[epoch15, step465]: loss 0.059570
[epoch15, step466]: loss 0.054973
[epoch15, step467]: loss 0.060718
[epoch15, step468]: loss 0.055800
[epoch15, step469]: loss 0.059715
[epoch15, step470]: loss 0.060014
[epoch15, step471]: loss 0.060211
[epoch15, step472]: loss 0.056906
[epoch15, step473]: loss 0.060511
[epoch15, step474]: loss 0.059781
[epoch15, step475]: loss 0.055883
[epoch15, step476]: loss 0.060672
[epoch15, step477]: loss 0.056144
[epoch15, step478]: loss 0.059993
[epoch15, step479]: loss 0.059895
[epoch15, step480]: loss 0.060502
[epoch15, step481]: loss 0.056183
[epoch15, step482]: loss 0.060507
[epoch15, step483]: loss 0.059556
[epoch15, step484]: loss 0.054666
[epoch15, step485]: loss 0.060727
[epoch15, step486]: loss 0.055640
[epoch15, step487]: loss 0.059612
[epoch15, step488]: loss 0.060020
[epoch15, step489]: loss 0.060417
[epoch15, step490]: loss 0.056603
[epoch15, step491]: loss 0.060054
[epoch15, step492]: loss 0.059496
[epoch15, step493]: loss 0.054910
[epoch15, step494]: loss 0.060618
[epoch15, step495]: loss 0.055477
[epoch15, step496]: loss 0.059404
[epoch15, step497]: loss 0.059829
[epoch15, step498]: loss 0.059999
[epoch15, step499]: loss 0.056648
[epoch15, step500]: loss 0.060318
[epoch15, step501]: loss 0.059522
[epoch15, step502]: loss 0.055507
[epoch15, step503]: loss 0.060639
[epoch15, step504]: loss 0.056313
[epoch15, step505]: loss 0.059967
[epoch15, step506]: loss 0.059566
[epoch15, step507]: loss 0.060166
[epoch15, step508]: loss 0.056627
[epoch15, step509]: loss 0.060265
[epoch15, step510]: loss 0.059957
[epoch15, step511]: loss 0.055899
[epoch15, step512]: loss 0.060450
[epoch15, step513]: loss 0.055525
[epoch15, step514]: loss 0.059171
[epoch15, step515]: loss 0.059815
[epoch15, step516]: loss 0.060074
[epoch15, step517]: loss 0.056582
[epoch15, step518]: loss 0.060358
[epoch15, step519]: loss 0.059732
[epoch15, step520]: loss 0.054337
[epoch15, step521]: loss 0.060561
[epoch15, step522]: loss 0.055313
[epoch15, step523]: loss 0.059206
[epoch15, step524]: loss 0.060332
[epoch15, step525]: loss 0.060289
[epoch15, step526]: loss 0.055732
[epoch15, step527]: loss 0.060841
[epoch15, step528]: loss 0.059629
[epoch15, step529]: loss 0.055468
[epoch15, step530]: loss 0.060968
[epoch15, step531]: loss 0.055163
[epoch15, step532]: loss 0.059473
[epoch15, step533]: loss 0.059624
[epoch15, step534]: loss 0.060067
[epoch15, step535]: loss 0.056340
[epoch15, step536]: loss 0.060384
[epoch15, step537]: loss 0.059327
[epoch15, step538]: loss 0.055748
[epoch15, step539]: loss 0.060419
[epoch15, step540]: loss 0.055970
[epoch15, step541]: loss 0.059857
[epoch15, step542]: loss 0.059811
[epoch15, step543]: loss 0.059838
[epoch15, step544]: loss 0.055230
[epoch15, step545]: loss 0.060283
[epoch15, step546]: loss 0.059281
[epoch15, step547]: loss 0.055746
[epoch15, step548]: loss 0.060433
[epoch15, step549]: loss 0.055785
[epoch15, step550]: loss 0.059410
[epoch15, step551]: loss 0.059892
[epoch15, step552]: loss 0.060397
[epoch15, step553]: loss 0.056455
[epoch15, step554]: loss 0.060413
[epoch15, step555]: loss 0.059565
[epoch15, step556]: loss 0.054789
[epoch15, step557]: loss 0.060619
[epoch15, step558]: loss 0.055424
[epoch15, step559]: loss 0.059578
[epoch15, step560]: loss 0.059562
[epoch15, step561]: loss 0.060026
[epoch15, step562]: loss 0.055734
[epoch15, step563]: loss 0.056972
[epoch15, step564]: loss 0.051676
[epoch15, step565]: loss 0.044488
[epoch15, step566]: loss 0.052468
[epoch15, step567]: loss 0.044827
[epoch15, step568]: loss 0.045915
[epoch15, step569]: loss 0.049574
[epoch15, step570]: loss 0.050909
[epoch15, step571]: loss 0.039839
[epoch15, step572]: loss 0.045398
[epoch15, step573]: loss 0.050401
[epoch15, step574]: loss 0.055022
[epoch15, step575]: loss 0.044497
[epoch15, step576]: loss 0.045960
[epoch15, step577]: loss 0.045341
[epoch15, step578]: loss 0.044694
[epoch15, step579]: loss 0.044819
[epoch15, step580]: loss 0.049486
[epoch15, step581]: loss 0.048666
[epoch15, step582]: loss 0.047321
[epoch15, step583]: loss 0.045586
[epoch15, step584]: loss 0.045884
[epoch15, step585]: loss 0.052030
[epoch15, step586]: loss 0.045172
[epoch15, step587]: loss 0.041122
[epoch15, step588]: loss 0.046670
[epoch15, step589]: loss 0.054693
[epoch15, step590]: loss 0.042138
[epoch15, step591]: loss 0.043342
[epoch15, step592]: loss 0.050543
[epoch15, step593]: loss 0.053552
[epoch15, step594]: loss 0.041546
[epoch15, step595]: loss 0.041996
[epoch15, step596]: loss 0.048048
[epoch15, step597]: loss 0.051051
[epoch15, step598]: loss 0.044899
[epoch15, step599]: loss 0.041128
[epoch15, step600]: loss 0.041925
[epoch15, step601]: loss 0.043051
[epoch15, step602]: loss 0.050767
[epoch15, step603]: loss 0.044145
[epoch15, step604]: loss 0.044588
[epoch15, step605]: loss 0.041299
[epoch15, step606]: loss 0.046141
[epoch15, step607]: loss 0.050176
[epoch15, step608]: loss 0.038388
[epoch15, step609]: loss 0.048481
[epoch15, step610]: loss 0.045546
[epoch15, step611]: loss 0.051075
[epoch15, step612]: loss 0.047803
[epoch15, step613]: loss 0.046085
[epoch15, step614]: loss 0.047128
[epoch15, step615]: loss 0.049103
[epoch15, step616]: loss 0.041174
[epoch15, step617]: loss 0.043929
[epoch15, step618]: loss 0.050053
[epoch15, step619]: loss 0.043563
[epoch15, step620]: loss 0.039845
[epoch15, step621]: loss 0.040169
[epoch15, step622]: loss 0.045320
[epoch15, step623]: loss 0.047258
[epoch15, step624]: loss 0.048860
[epoch15, step625]: loss 0.039917
[epoch15, step626]: loss 0.049857
[epoch15, step627]: loss 0.050941
[epoch15, step628]: loss 0.049243
[epoch15, step629]: loss 0.032231
[epoch15, step630]: loss 0.041748
[epoch15, step631]: loss 0.047727
[epoch15, step632]: loss 0.046411
[epoch15, step633]: loss 0.042064
[epoch15, step634]: loss 0.048309
[epoch15, step635]: loss 0.044714
[epoch15, step636]: loss 0.038514
[epoch15, step637]: loss 0.051273
[epoch15, step638]: loss 0.048469
[epoch15, step639]: loss 0.039259
[epoch15, step640]: loss 0.051847
[epoch15, step641]: loss 0.045627
[epoch15, step642]: loss 0.040901
[epoch15, step643]: loss 0.049183
[epoch15, step644]: loss 0.045065
[epoch15, step645]: loss 0.037544
[epoch15, step646]: loss 0.046589
[epoch15, step647]: loss 0.038301
[epoch15, step648]: loss 0.050885
[epoch15, step649]: loss 0.049788
[epoch15, step650]: loss 0.046699
[epoch15, step651]: loss 0.045235
[epoch15, step652]: loss 0.052557
[epoch15, step653]: loss 0.052252
[epoch15, step654]: loss 0.046720
[epoch15, step655]: loss 0.041171
[epoch15, step656]: loss 0.047734
[epoch15, step657]: loss 0.051512
[epoch15, step658]: loss 0.042902
[epoch15, step659]: loss 0.041036
[epoch15, step660]: loss 0.045120
[epoch15, step661]: loss 0.048746
[epoch15, step662]: loss 0.038991
[epoch15, step663]: loss 0.042026
[epoch15, step664]: loss 0.043990
[epoch15, step665]: loss 0.052786
[epoch15, step666]: loss 0.041301
[epoch15, step667]: loss 0.048159
[epoch15, step668]: loss 0.048901
[epoch15, step669]: loss 0.041461
[epoch15, step670]: loss 0.047810
[epoch15, step671]: loss 0.044600
[epoch15, step672]: loss 0.051993
[epoch15, step673]: loss 0.047837
[epoch15, step674]: loss 0.041883
[epoch15, step675]: loss 0.045366
[epoch15, step676]: loss 0.048070
[epoch15, step677]: loss 0.043598
[epoch15, step678]: loss 0.038947
[epoch15, step679]: loss 0.044651
[epoch15, step680]: loss 0.044632
[epoch15, step681]: loss 0.038829
[epoch15, step682]: loss 0.042844
[epoch15, step683]: loss 0.046319
[epoch15, step684]: loss 0.040918
[epoch15, step685]: loss 0.041267
[epoch15, step686]: loss 0.042433
[epoch15, step687]: loss 0.044350
[epoch15, step688]: loss 0.045839
[epoch15, step689]: loss 0.040729
[epoch15, step690]: loss 0.049110
[epoch15, step691]: loss 0.049990
[epoch15, step692]: loss 0.047033
[epoch15, step693]: loss 0.048027
[epoch15, step694]: loss 0.038345
[epoch15, step695]: loss 0.044426
[epoch15, step696]: loss 0.042151
[epoch15, step697]: loss 0.047649
[epoch15, step698]: loss 0.043348
[epoch15, step699]: loss 0.043231
[epoch15, step700]: loss 0.049697
[epoch15, step701]: loss 0.047974
[epoch15, step702]: loss 0.041250
[epoch15, step703]: loss 0.050032
[epoch15, step704]: loss 0.048568
[epoch15, step705]: loss 0.041211
[epoch15, step706]: loss 0.041970
[epoch15, step707]: loss 0.043127
[epoch15, step708]: loss 0.046257
[epoch15, step709]: loss 0.044359
[epoch15, step710]: loss 0.044979
[epoch15, step711]: loss 0.047759
[epoch15, step712]: loss 0.041267
[epoch15, step713]: loss 0.043668
[epoch15, step714]: loss 0.044285
[epoch15, step715]: loss 0.041458
[epoch15, step716]: loss 0.047144
[epoch15, step717]: loss 0.041094
[epoch15, step718]: loss 0.045116
[epoch15, step719]: loss 0.051438
[epoch15, step720]: loss 0.040933
[epoch15, step721]: loss 0.042811
[epoch15, step722]: loss 0.050613
[epoch15, step723]: loss 0.045216
[epoch15, step724]: loss 0.045306
[epoch15, step725]: loss 0.048939
[epoch15, step726]: loss 0.036594
[epoch15, step727]: loss 0.045979
[epoch15, step728]: loss 0.047178
[epoch15, step729]: loss 0.038362
[epoch15, step730]: loss 0.045037
[epoch15, step731]: loss 0.049096
[epoch15, step732]: loss 0.044009
[epoch15, step733]: loss 0.038177
[epoch15, step734]: loss 0.040687
[epoch15, step735]: loss 0.043951
[epoch15, step736]: loss 0.043163
[epoch15, step737]: loss 0.041699
[epoch15, step738]: loss 0.039164
[epoch15, step739]: loss 0.052200
[epoch15, step740]: loss 0.051599
[epoch15, step741]: loss 0.045609
[epoch15, step742]: loss 0.046915
[epoch15, step743]: loss 0.043764
[epoch15, step744]: loss 0.043929
[epoch15, step745]: loss 0.044722
[epoch15, step746]: loss 0.046526
[epoch15, step747]: loss 0.045458
[epoch15, step748]: loss 0.042196
[epoch15, step749]: loss 0.052738
[epoch15, step750]: loss 0.048673
[epoch15, step751]: loss 0.040698
[epoch15, step752]: loss 0.040947
[epoch15, step753]: loss 0.041394
[epoch15, step754]: loss 0.047210
[epoch15, step755]: loss 0.047683
[epoch15, step756]: loss 0.038047
[epoch15, step757]: loss 0.041842
[epoch15, step758]: loss 0.047255
[epoch15, step759]: loss 0.039425
[epoch15, step760]: loss 0.045772
[epoch15, step761]: loss 0.044842
[epoch15, step762]: loss 0.039386
[epoch15, step763]: loss 0.042668
[epoch15, step764]: loss 0.044707
[epoch15, step765]: loss 0.042235
[epoch15, step766]: loss 0.040486
[epoch15, step767]: loss 0.047957
[epoch15, step768]: loss 0.042397
[epoch15, step769]: loss 0.046468
[epoch15, step770]: loss 0.051376
[epoch15, step771]: loss 0.039233
[epoch15, step772]: loss 0.044271
[epoch15, step773]: loss 0.044759
[epoch15, step774]: loss 0.043562
[epoch15, step775]: loss 0.047386
[epoch15, step776]: loss 0.046387
[epoch15, step777]: loss 0.041774
[epoch15, step778]: loss 0.050644
[epoch15, step779]: loss 0.042759
[epoch15, step780]: loss 0.043649
[epoch15, step781]: loss 0.050537
[epoch15, step782]: loss 0.047281
[epoch15, step783]: loss 0.040763
[epoch15, step784]: loss 0.045037
[epoch15, step785]: loss 0.045386
[epoch15, step786]: loss 0.043704
[epoch15, step787]: loss 0.049042
[epoch15, step788]: loss 0.044768
[epoch15, step789]: loss 0.047372
[epoch15, step790]: loss 0.039342
[epoch15, step791]: loss 0.048162
[epoch15, step792]: loss 0.046523
[epoch15, step793]: loss 0.048208
[epoch15, step794]: loss 0.041717
[epoch15, step795]: loss 0.044653
[epoch15, step796]: loss 0.044784
[epoch15, step797]: loss 0.043247
[epoch15, step798]: loss 0.042888
[epoch15, step799]: loss 0.038661
[epoch15, step800]: loss 0.049025
[epoch15, step801]: loss 0.047322
[epoch15, step802]: loss 0.042422
[epoch15, step803]: loss 0.043002
[epoch15, step804]: loss 0.048245
[epoch15, step805]: loss 0.045570
[epoch15, step806]: loss 0.042310
[epoch15, step807]: loss 0.044632
[epoch15, step808]: loss 0.048550
[epoch15, step809]: loss 0.041086
[epoch15, step810]: loss 0.039537
[epoch15, step811]: loss 0.045721
[epoch15, step812]: loss 0.046231
[epoch15, step813]: loss 0.041162
[epoch15, step814]: loss 0.045830
[epoch15, step815]: loss 0.044145
[epoch15, step816]: loss 0.043723
[epoch15, step817]: loss 0.040808
[epoch15, step818]: loss 0.041574
[epoch15, step819]: loss 0.052044
[epoch15, step820]: loss 0.040077
[epoch15, step821]: loss 0.039222
[epoch15, step822]: loss 0.049405
[epoch15, step823]: loss 0.040202
[epoch15, step824]: loss 0.046481
[epoch15, step825]: loss 0.046029
[epoch15, step826]: loss 0.037106
[epoch15, step827]: loss 0.042847
[epoch15, step828]: loss 0.047246
[epoch15, step829]: loss 0.043514
[epoch15, step830]: loss 0.035061
[epoch15, step831]: loss 0.041746
[epoch15, step832]: loss 0.047706
[epoch15, step833]: loss 0.047955
[epoch15, step834]: loss 0.044545
[epoch15, step835]: loss 0.042386
[epoch15, step836]: loss 0.042549
[epoch15, step837]: loss 0.040982
[epoch15, step838]: loss 0.048854
[epoch15, step839]: loss 0.046409
[epoch15, step840]: loss 0.039045
[epoch15, step841]: loss 0.043663
[epoch15, step842]: loss 0.046308
[epoch15, step843]: loss 0.047053
[epoch15, step844]: loss 0.047256
[epoch15, step845]: loss 0.042963
[epoch15, step846]: loss 0.053034
[epoch15, step847]: loss 0.045624
[epoch15, step848]: loss 0.033353
[epoch15, step849]: loss 0.042760
[epoch15, step850]: loss 0.045896
[epoch15, step851]: loss 0.043079
[epoch15, step852]: loss 0.043149
[epoch15, step853]: loss 0.049983
[epoch15, step854]: loss 0.045818
[epoch15, step855]: loss 0.043071
[epoch15, step856]: loss 0.037597
[epoch15, step857]: loss 0.046709
[epoch15, step858]: loss 0.045845
[epoch15, step859]: loss 0.040474
[epoch15, step860]: loss 0.046286
[epoch15, step861]: loss 0.043245
[epoch15, step862]: loss 0.038269
[epoch15, step863]: loss 0.044105
[epoch15, step864]: loss 0.049519
[epoch15, step865]: loss 0.044491
[epoch15, step866]: loss 0.046895
[epoch15, step867]: loss 0.043593
[epoch15, step868]: loss 0.046897
[epoch15, step869]: loss 0.040384
[epoch15, step870]: loss 0.044482
[epoch15, step871]: loss 0.048010
[epoch15, step872]: loss 0.046408
[epoch15, step873]: loss 0.040547
[epoch15, step874]: loss 0.043115
[epoch15, step875]: loss 0.050456
[epoch15, step876]: loss 0.047141
[epoch15, step877]: loss 0.030400
[epoch15, step878]: loss 0.040892
[epoch15, step879]: loss 0.045156
[epoch15, step880]: loss 0.042262
[epoch15, step881]: loss 0.045853
[epoch15, step882]: loss 0.040398
[epoch15, step883]: loss 0.041885
[epoch15, step884]: loss 0.051497
[epoch15, step885]: loss 0.050875
[epoch15, step886]: loss 0.049982
[epoch15, step887]: loss 0.050141
[epoch15, step888]: loss 0.042377
[epoch15, step889]: loss 0.045804
[epoch15, step890]: loss 0.045739
[epoch15, step891]: loss 0.042307
[epoch15, step892]: loss 0.044412
[epoch15, step893]: loss 0.046156
[epoch15, step894]: loss 0.046370
[epoch15, step895]: loss 0.038255
[epoch15, step896]: loss 0.050529
[epoch15, step897]: loss 0.051576
[epoch15, step898]: loss 0.041687
[epoch15, step899]: loss 0.037185
[epoch15, step900]: loss 0.045777
[epoch15, step901]: loss 0.048366
[epoch15, step902]: loss 0.040603
[epoch15, step903]: loss 0.048521
[epoch15, step904]: loss 0.043691
[epoch15, step905]: loss 0.041983
[epoch15, step906]: loss 0.036857
[epoch15, step907]: loss 0.046465
[epoch15, step908]: loss 0.047464
[epoch15, step909]: loss 0.043488
[epoch15, step910]: loss 0.037541
[epoch15, step911]: loss 0.039091
[epoch15, step912]: loss 0.046167
[epoch15, step913]: loss 0.046517
[epoch15, step914]: loss 0.048875
[epoch15, step915]: loss 0.040240
[epoch15, step916]: loss 0.044599
[epoch15, step917]: loss 0.044346
[epoch15, step918]: loss 0.050041
[epoch15, step919]: loss 0.039770
[epoch15, step920]: loss 0.050422
[epoch15, step921]: loss 0.041281
[epoch15, step922]: loss 0.041129
[epoch15, step923]: loss 0.047369
[epoch15, step924]: loss 0.038929
[epoch15, step925]: loss 0.042728
[epoch15, step926]: loss 0.043935
[epoch15, step927]: loss 0.048493
[epoch15, step928]: loss 0.041614
[epoch15, step929]: loss 0.045055
[epoch15, step930]: loss 0.045178
[epoch15, step931]: loss 0.048447
[epoch15, step932]: loss 0.039544
[epoch15, step933]: loss 0.045306
[epoch15, step934]: loss 0.046971
[epoch15, step935]: loss 0.042493
[epoch15, step936]: loss 0.039726
[epoch15, step937]: loss 0.041523
[epoch15, step938]: loss 0.050653
[epoch15, step939]: loss 0.039339
[epoch15, step940]: loss 0.046247
[epoch15, step941]: loss 0.046185
[epoch15, step942]: loss 0.044573
[epoch15, step943]: loss 0.047547
[epoch15, step944]: loss 0.046680
[epoch15, step945]: loss 0.044365
[epoch15, step946]: loss 0.044638
[epoch15, step947]: loss 0.043431
[epoch15, step948]: loss 0.050305
[epoch15, step949]: loss 0.042428
[epoch15, step950]: loss 0.044730
[epoch15, step951]: loss 0.048926
[epoch15, step952]: loss 0.046806
[epoch15, step953]: loss 0.046394
[epoch15, step954]: loss 0.043883
[epoch15, step955]: loss 0.048323
[epoch15, step956]: loss 0.069720
[epoch15, step957]: loss 0.061615
[epoch15, step958]: loss 0.064114
[epoch15, step959]: loss 0.064524
[epoch15, step960]: loss 0.059590
[epoch15, step961]: loss 0.062574
[epoch15, step962]: loss 0.061059
[epoch15, step963]: loss 0.061006
[epoch15, step964]: loss 0.058793
[epoch15, step965]: loss 0.062317
[epoch15, step966]: loss 0.057258
[epoch15, step967]: loss 0.059961
[epoch15, step968]: loss 0.060050
[epoch15, step969]: loss 0.056220
[epoch15, step970]: loss 0.058364
[epoch15, step971]: loss 0.058216
[epoch15, step972]: loss 0.059258
[epoch15, step973]: loss 0.057334
[epoch15, step974]: loss 0.060106
[epoch15, step975]: loss 0.056160
[epoch15, step976]: loss 0.058921
[epoch15, step977]: loss 0.058700
[epoch15, step978]: loss 0.054781
[epoch15, step979]: loss 0.057221
[epoch15, step980]: loss 0.056697
[epoch15, step981]: loss 0.058927
[epoch15, step982]: loss 0.056475
[epoch15, step983]: loss 0.058914
[epoch15, step984]: loss 0.054919
[epoch15, step985]: loss 0.058804
[epoch15, step986]: loss 0.058701
[epoch15, step987]: loss 0.054190
[epoch15, step988]: loss 0.056762
[epoch15, step989]: loss 0.056891
[epoch15, step990]: loss 0.058869
[epoch15, step991]: loss 0.056133
[epoch15, step992]: loss 0.058555
[epoch15, step993]: loss 0.055367
[epoch15, step994]: loss 0.058612
[epoch15, step995]: loss 0.058560
[epoch15, step996]: loss 0.053913
[epoch15, step997]: loss 0.056384
[epoch15, step998]: loss 0.056656
[epoch15, step999]: loss 0.058717
[epoch15, step1000]: loss 0.056273
[epoch15, step1001]: loss 0.058573
[epoch15, step1002]: loss 0.054801
[epoch15, step1003]: loss 0.058692
[epoch15, step1004]: loss 0.057905
[epoch15, step1005]: loss 0.053809
[epoch15, step1006]: loss 0.056559
[epoch15, step1007]: loss 0.056479
[epoch15, step1008]: loss 0.058725
[epoch15, step1009]: loss 0.055850
[epoch15, step1010]: loss 0.058540
[epoch15, step1011]: loss 0.054758
[epoch15, step1012]: loss 0.058381
[epoch15, step1013]: loss 0.058254
[epoch15, step1014]: loss 0.054277
[epoch15, step1015]: loss 0.056469
[epoch15, step1016]: loss 0.056325
[epoch15, step1017]: loss 0.058403
[epoch15, step1018]: loss 0.055584
[epoch15, step1019]: loss 0.058527
[epoch15, step1020]: loss 0.054781
[epoch15, step1021]: loss 0.058349
[epoch15, step1022]: loss 0.057935
[epoch15, step1023]: loss 0.053868
[epoch15, step1024]: loss 0.056096
[epoch15, step1025]: loss 0.056523
[epoch15, step1026]: loss 0.058278
[epoch15, step1027]: loss 0.055288
[epoch15, step1028]: loss 0.058382
[epoch15, step1029]: loss 0.054642
[epoch15, step1030]: loss 0.058291
[epoch15, step1031]: loss 0.058062
[epoch15, step1032]: loss 0.053897
[epoch15, step1033]: loss 0.056659
[epoch15, step1034]: loss 0.056613
[epoch15, step1035]: loss 0.058220
[epoch15, step1036]: loss 0.055863
[epoch15, step1037]: loss 0.058520
[epoch15, step1038]: loss 0.054699
[epoch15, step1039]: loss 0.058144
[epoch15, step1040]: loss 0.057780
[epoch15, step1041]: loss 0.054018
[epoch15, step1042]: loss 0.055873
[epoch15, step1043]: loss 0.056247
[epoch15, step1044]: loss 0.057940
[epoch15, step1045]: loss 0.055403
[epoch15, step1046]: loss 0.058381
[epoch15, step1047]: loss 0.054430
[epoch15, step1048]: loss 0.058174
[epoch15, step1049]: loss 0.057668
[epoch15, step1050]: loss 0.053850
[epoch15, step1051]: loss 0.056158
[epoch15, step1052]: loss 0.056638
[epoch15, step1053]: loss 0.058348
[epoch15, step1054]: loss 0.055712
[epoch15, step1055]: loss 0.058245
[epoch15, step1056]: loss 0.054468
[epoch15, step1057]: loss 0.058040
[epoch15, step1058]: loss 0.057672
[epoch15, step1059]: loss 0.053839
[epoch15, step1060]: loss 0.055816
[epoch15, step1061]: loss 0.056411
[epoch15, step1062]: loss 0.057948
[epoch15, step1063]: loss 0.055592
[epoch15, step1064]: loss 0.058375
[epoch15, step1065]: loss 0.054898
[epoch15, step1066]: loss 0.058135
[epoch15, step1067]: loss 0.057688
[epoch15, step1068]: loss 0.054034
[epoch15, step1069]: loss 0.055364
[epoch15, step1070]: loss 0.056126
[epoch15, step1071]: loss 0.057912
[epoch15, step1072]: loss 0.055382
[epoch15, step1073]: loss 0.058145
[epoch15, step1074]: loss 0.054927
[epoch15, step1075]: loss 0.057912
[epoch15, step1076]: loss 0.057529
[epoch15, step1077]: loss 0.053308
[epoch15, step1078]: loss 0.056128
[epoch15, step1079]: loss 0.056151
[epoch15, step1080]: loss 0.057744
[epoch15, step1081]: loss 0.055762
[epoch15, step1082]: loss 0.058125
[epoch15, step1083]: loss 0.054903
[epoch15, step1084]: loss 0.057866
[epoch15, step1085]: loss 0.057674
[epoch15, step1086]: loss 0.053992
[epoch15, step1087]: loss 0.056166
[epoch15, step1088]: loss 0.056254
[epoch15, step1089]: loss 0.057653
[epoch15, step1090]: loss 0.055454
[epoch15, step1091]: loss 0.058231
[epoch15, step1092]: loss 0.054795
[epoch15, step1093]: loss 0.057971
[epoch15, step1094]: loss 0.057504
[epoch15, step1095]: loss 0.053381
[epoch15, step1096]: loss 0.056259
[epoch15, step1097]: loss 0.056005
[epoch15, step1098]: loss 0.058099
[epoch15, step1099]: loss 0.055360
[epoch15, step1100]: loss 0.058246
[epoch15, step1101]: loss 0.055134
[epoch15, step1102]: loss 0.057879
[epoch15, step1103]: loss 0.057519
[epoch15, step1104]: loss 0.053243
[epoch15, step1105]: loss 0.055840
[epoch15, step1106]: loss 0.055913
[epoch15, step1107]: loss 0.057846
[epoch15, step1108]: loss 0.055334
[epoch15, step1109]: loss 0.057878
[epoch15, step1110]: loss 0.054389
[epoch15, step1111]: loss 0.057701
[epoch15, step1112]: loss 0.057465
[epoch15, step1113]: loss 0.053197
[epoch15, step1114]: loss 0.056009
[epoch15, step1115]: loss 0.055917
[epoch15, step1116]: loss 0.057512
[epoch15, step1117]: loss 0.055486
[epoch15, step1118]: loss 0.058129
[epoch15, step1119]: loss 0.055191
[epoch15, step1120]: loss 0.058151
[epoch15, step1121]: loss 0.057467
[epoch15, step1122]: loss 0.053795
[epoch15, step1123]: loss 0.056259
[epoch15, step1124]: loss 0.055987
[epoch15, step1125]: loss 0.057934
[epoch15, step1126]: loss 0.055521
[epoch15, step1127]: loss 0.057935
[epoch15, step1128]: loss 0.054830
[epoch15, step1129]: loss 0.057635
[epoch15, step1130]: loss 0.057208
[epoch15, step1131]: loss 0.053246
[epoch15, step1132]: loss 0.055839
[epoch15, step1133]: loss 0.055879
[epoch15, step1134]: loss 0.057481
[epoch15, step1135]: loss 0.055073
[epoch15, step1136]: loss 0.057809
[epoch15, step1137]: loss 0.053936
[epoch15, step1138]: loss 0.057651
[epoch15, step1139]: loss 0.057582
[epoch15, step1140]: loss 0.052906
[epoch15, step1141]: loss 0.055396
[epoch15, step1142]: loss 0.056203
[epoch15, step1143]: loss 0.057598
[epoch15, step1144]: loss 0.055672
[epoch15, step1145]: loss 0.058071
[epoch15, step1146]: loss 0.053897
[epoch15, step1147]: loss 0.057892
[epoch15, step1148]: loss 0.057461
[epoch15, step1149]: loss 0.053184
[epoch15, step1150]: loss 0.056333
[epoch15, step1151]: loss 0.056135
[epoch15, step1152]: loss 0.057651
[epoch15, step1153]: loss 0.055112
[epoch15, step1154]: loss 0.057920
[epoch15, step1155]: loss 0.054447
[epoch15, step1156]: loss 0.057481
[epoch15, step1157]: loss 0.057457
[epoch15, step1158]: loss 0.052822
[epoch15, step1159]: loss 0.055601
[epoch15, step1160]: loss 0.055882
[epoch15, step1161]: loss 0.057242
[epoch15, step1162]: loss 0.055154
[epoch15, step1163]: loss 0.057822
[epoch15, step1164]: loss 0.054016
[epoch15, step1165]: loss 0.057508
[epoch15, step1166]: loss 0.057199
[epoch15, step1167]: loss 0.052987
[epoch15, step1168]: loss 0.055648
[epoch15, step1169]: loss 0.056117
[epoch15, step1170]: loss 0.057664
[epoch15, step1171]: loss 0.055225
[epoch15, step1172]: loss 0.058152
[epoch15, step1173]: loss 0.054503
[epoch15, step1174]: loss 0.057699
[epoch15, step1175]: loss 0.057485
[epoch15, step1176]: loss 0.053181
[epoch15, step1177]: loss 0.055598
[epoch15, step1178]: loss 0.055638
[epoch15, step1179]: loss 0.057654
[epoch15, step1180]: loss 0.055069
[epoch15, step1181]: loss 0.057919
[epoch15, step1182]: loss 0.053924
[epoch15, step1183]: loss 0.057404
[epoch15, step1184]: loss 0.057321
[epoch15, step1185]: loss 0.053578
[epoch15, step1186]: loss 0.055344
[epoch15, step1187]: loss 0.055740
[epoch15, step1188]: loss 0.057077
[epoch15, step1189]: loss 0.054785
[epoch15, step1190]: loss 0.057728
[epoch15, step1191]: loss 0.054810
[epoch15, step1192]: loss 0.057278
[epoch15, step1193]: loss 0.056990
[epoch15, step1194]: loss 0.053049
[epoch15, step1195]: loss 0.055709
[epoch15, step1196]: loss 0.055776
[epoch15, step1197]: loss 0.057551
[epoch15, step1198]: loss 0.054990
[epoch15, step1199]: loss 0.057782
[epoch15, step1200]: loss 0.053905
[epoch15, step1201]: loss 0.057472
[epoch15, step1202]: loss 0.057186
[epoch15, step1203]: loss 0.053932
[epoch15, step1204]: loss 0.055330
[epoch15, step1205]: loss 0.055399
[epoch15, step1206]: loss 0.057558
[epoch15, step1207]: loss 0.054573
[epoch15, step1208]: loss 0.057625
[epoch15, step1209]: loss 0.053282
[epoch15, step1210]: loss 0.057289
[epoch15, step1211]: loss 0.057139
[epoch15, step1212]: loss 0.053298
[epoch15, step1213]: loss 0.055649
[epoch15, step1214]: loss 0.055746
[epoch15, step1215]: loss 0.057187
[epoch15, step1216]: loss 0.054644
[epoch15, step1217]: loss 0.057611
[epoch15, step1218]: loss 0.053763
[epoch15, step1219]: loss 0.057426
[epoch15, step1220]: loss 0.056947
[epoch15, step1221]: loss 0.052680
[epoch15, step1222]: loss 0.055539
[epoch15, step1223]: loss 0.055532
[epoch15, step1224]: loss 0.057363
[epoch15, step1225]: loss 0.054833
[epoch15, step1226]: loss 0.057843
[epoch15, step1227]: loss 0.053412
[epoch15, step1228]: loss 0.057206
[epoch15, step1229]: loss 0.057347
[epoch15, step1230]: loss 0.053688
[epoch15, step1231]: loss 0.055627
[epoch15, step1232]: loss 0.055885
[epoch15, step1233]: loss 0.057104
[epoch15, step1234]: loss 0.054755
[epoch15, step1235]: loss 0.057660
[epoch15, step1236]: loss 0.054700
[epoch15, step1237]: loss 0.057233
[epoch15, step1238]: loss 0.057119
[epoch15, step1239]: loss 0.052829
[epoch15, step1240]: loss 0.055338
[epoch15, step1241]: loss 0.056045
[epoch15, step1242]: loss 0.057061
[epoch15, step1243]: loss 0.054631
[epoch15, step1244]: loss 0.057598
[epoch15, step1245]: loss 0.053633
[epoch15, step1246]: loss 0.057572
[epoch15, step1247]: loss 0.056979
[epoch15, step1248]: loss 0.053314
[epoch15, step1249]: loss 0.055610
[epoch15, step1250]: loss 0.055443
[epoch15, step1251]: loss 0.057441
[epoch15, step1252]: loss 0.055210
[epoch15, step1253]: loss 0.057504
[epoch15, step1254]: loss 0.054130
[epoch15, step1255]: loss 0.057120
[epoch15, step1256]: loss 0.056934
[epoch15, step1257]: loss 0.052799
[epoch15, step1258]: loss 0.055493
[epoch15, step1259]: loss 0.055499
[epoch15, step1260]: loss 0.056902
[epoch15, step1261]: loss 0.054751
[epoch15, step1262]: loss 0.057354
[epoch15, step1263]: loss 0.053851
[epoch15, step1264]: loss 0.057120
[epoch15, step1265]: loss 0.057096
[epoch15, step1266]: loss 0.053403
[epoch15, step1267]: loss 0.055405
[epoch15, step1268]: loss 0.055909
[epoch15, step1269]: loss 0.056975
[epoch15, step1270]: loss 0.055000
[epoch15, step1271]: loss 0.057918
[epoch15, step1272]: loss 0.054017
[epoch15, step1273]: loss 0.057392
[epoch15, step1274]: loss 0.057168
[epoch15, step1275]: loss 0.053374
[epoch15, step1276]: loss 0.055241
[epoch15, step1277]: loss 0.055377
[epoch15, step1278]: loss 0.057132
[epoch15, step1279]: loss 0.054662
[epoch15, step1280]: loss 0.057502
[epoch15, step1281]: loss 0.053952
[epoch15, step1282]: loss 0.056866
[epoch15, step1283]: loss 0.056750
[epoch15, step1284]: loss 0.052098
[epoch15, step1285]: loss 0.055504
[epoch15, step1286]: loss 0.055133
[epoch15, step1287]: loss 0.056704
[epoch15, step1288]: loss 0.054784
[epoch15, step1289]: loss 0.057357
[epoch15, step1290]: loss 0.054396
[epoch15, step1291]: loss 0.057103
[epoch15, step1292]: loss 0.056788
[epoch15, step1293]: loss 0.052530
[epoch15, step1294]: loss 0.055132
[epoch15, step1295]: loss 0.055390
[epoch15, step1296]: loss 0.057003
[epoch15, step1297]: loss 0.054091
[epoch15, step1298]: loss 0.057578
[epoch15, step1299]: loss 0.054167
[epoch15, step1300]: loss 0.057055
[epoch15, step1301]: loss 0.057041
[epoch15, step1302]: loss 0.052977
[epoch15, step1303]: loss 0.055563
[epoch15, step1304]: loss 0.055199
[epoch15, step1305]: loss 0.056828
[epoch15, step1306]: loss 0.054442
[epoch15, step1307]: loss 0.057329
[epoch15, step1308]: loss 0.054201
[epoch15, step1309]: loss 0.056846
[epoch15, step1310]: loss 0.056676
[epoch15, step1311]: loss 0.052422
[epoch15, step1312]: loss 0.055588
[epoch15, step1313]: loss 0.055551
[epoch15, step1314]: loss 0.056776
[epoch15, step1315]: loss 0.054565
[epoch15, step1316]: loss 0.057441
[epoch15, step1317]: loss 0.053987
[epoch15, step1318]: loss 0.057403
[epoch15, step1319]: loss 0.056561
[epoch15, step1320]: loss 0.053477
[epoch15, step1321]: loss 0.055495
[epoch15, step1322]: loss 0.055219
[epoch15, step1323]: loss 0.057152
[epoch15, step1324]: loss 0.054586
[epoch15, step1325]: loss 0.057224
[epoch15, step1326]: loss 0.054142
[epoch15, step1327]: loss 0.056762
[epoch15, step1328]: loss 0.056708
[epoch15, step1329]: loss 0.052843
[epoch15, step1330]: loss 0.055182
[epoch15, step1331]: loss 0.055210
[epoch15, step1332]: loss 0.056910
[epoch15, step1333]: loss 0.054628
[epoch15, step1334]: loss 0.057151
[epoch15, step1335]: loss 0.054435
[epoch15, step1336]: loss 0.056818
[epoch15, step1337]: loss 0.056885
[epoch15, step1338]: loss 0.052703
[epoch15, step1339]: loss 0.055470
[epoch15, step1340]: loss 0.055780
[epoch15, step1341]: loss 0.057018
[epoch15, step1342]: loss 0.054373
[epoch15, step1343]: loss 0.057531
[epoch15, step1344]: loss 0.053399
[epoch15, step1345]: loss 0.056764
[epoch15, step1346]: loss 0.056662
[epoch15, step1347]: loss 0.052879
[epoch15, step1348]: loss 0.055094
[epoch15, step1349]: loss 0.055217
[epoch15, step1350]: loss 0.056641
[epoch15, step1351]: loss 0.054675
[epoch15, step1352]: loss 0.057049
[epoch15, step1353]: loss 0.054047
[epoch15, step1354]: loss 0.056753
[epoch15, step1355]: loss 0.056703
[epoch15, step1356]: loss 0.053005
[epoch15, step1357]: loss 0.055121
[epoch15, step1358]: loss 0.054997
[epoch15, step1359]: loss 0.056437
[epoch15, step1360]: loss 0.054331
[epoch15, step1361]: loss 0.057168
[epoch15, step1362]: loss 0.054286
[epoch15, step1363]: loss 0.056922
[epoch15, step1364]: loss 0.056488
[epoch15, step1365]: loss 0.053400
[epoch15, step1366]: loss 0.055262
[epoch15, step1367]: loss 0.054929
[epoch15, step1368]: loss 0.056811
[epoch15, step1369]: loss 0.054570
[epoch15, step1370]: loss 0.057280
[epoch15, step1371]: loss 0.053799
[epoch15, step1372]: loss 0.056456
[epoch15, step1373]: loss 0.056700
[epoch15, step1374]: loss 0.052447
[epoch15, step1375]: loss 0.055127
[epoch15, step1376]: loss 0.054920
[epoch15, step1377]: loss 0.056643
[epoch15, step1378]: loss 0.054492
[epoch15, step1379]: loss 0.057035
[epoch15, step1380]: loss 0.053083
[epoch15, step1381]: loss 0.056448
[epoch15, step1382]: loss 0.056754
[epoch15, step1383]: loss 0.052236
[epoch15, step1384]: loss 0.054785
[epoch15, step1385]: loss 0.055080
[epoch15, step1386]: loss 0.056417
[epoch15, step1387]: loss 0.054688
[epoch15, step1388]: loss 0.057735
[epoch15, step1389]: loss 0.053255
[epoch15, step1390]: loss 0.056846
[epoch15, step1391]: loss 0.056743
[epoch15, step1392]: loss 0.052708
[epoch15, step1393]: loss 0.054969
[epoch15, step1394]: loss 0.054823
[epoch15, step1395]: loss 0.056587
[epoch15, step1396]: loss 0.054023
[epoch15, step1397]: loss 0.056939
[epoch15, step1398]: loss 0.053248
[epoch15, step1399]: loss 0.056473
[epoch15, step1400]: loss 0.056616
[epoch15, step1401]: loss 0.051913
[epoch15, step1402]: loss 0.054915
[epoch15, step1403]: loss 0.054688
[epoch15, step1404]: loss 0.056277
[epoch15, step1405]: loss 0.053930
[epoch15, step1406]: loss 0.056939
[epoch15, step1407]: loss 0.054059
[epoch15, step1408]: loss 0.056722
[epoch15, step1409]: loss 0.056457
[epoch15, step1410]: loss 0.052519
[epoch15, step1411]: loss 0.055089
[epoch15, step1412]: loss 0.055307
[epoch15, step1413]: loss 0.056931
[epoch15, step1414]: loss 0.054145
[epoch15, step1415]: loss 0.057168
[epoch15, step1416]: loss 0.052972
[epoch15, step1417]: loss 0.056538
[epoch15, step1418]: loss 0.056529
[epoch15, step1419]: loss 0.052494
[epoch15, step1420]: loss 0.055084
[epoch15, step1421]: loss 0.054814
[epoch15, step1422]: loss 0.056265
[epoch15, step1423]: loss 0.054090
[epoch15, step1424]: loss 0.056947
[epoch15, step1425]: loss 0.053082
[epoch15, step1426]: loss 0.056349
[epoch15, step1427]: loss 0.056293
[epoch15, step1428]: loss 0.053219
[epoch15, step1429]: loss 0.054704
[epoch15, step1430]: loss 0.055152
[epoch15, step1431]: loss 0.056296
[epoch15, step1432]: loss 0.054509
[epoch15, step1433]: loss 0.057325
[epoch15, step1434]: loss 0.053854
[epoch15, step1435]: loss 0.056892
[epoch15, step1436]: loss 0.056655
[epoch15, step1437]: loss 0.052321
[epoch15, step1438]: loss 0.055474
[epoch15, step1439]: loss 0.055063
[epoch15, step1440]: loss 0.056716
[epoch15, step1441]: loss 0.054403
[epoch15, step1442]: loss 0.056855
[epoch15, step1443]: loss 0.053966
[epoch15, step1444]: loss 0.056388
[epoch15, step1445]: loss 0.056367
[epoch15, step1446]: loss 0.051952
[epoch15, step1447]: loss 0.055111
[epoch15, step1448]: loss 0.054709
[epoch15, step1449]: loss 0.056181
[epoch15, step1450]: loss 0.054399
[epoch15, step1451]: loss 0.056720
[epoch15, step1452]: loss 0.053860
[epoch15, step1453]: loss 0.056826
[epoch15, step1454]: loss 0.056324
[epoch15, step1455]: loss 0.053046
[epoch15, step1456]: loss 0.055344
[epoch15, step1457]: loss 0.054649
[epoch15, step1458]: loss 0.056536
[epoch15, step1459]: loss 0.054428
[epoch15, step1460]: loss 0.056969
[epoch15, step1461]: loss 0.053047
[epoch15, step1462]: loss 0.056147
[epoch15, step1463]: loss 0.056422
[epoch15, step1464]: loss 0.051937
[epoch15, step1465]: loss 0.054783
[epoch15, step1466]: loss 0.054468
[epoch15, step1467]: loss 0.056297
[epoch15, step1468]: loss 0.053920
[epoch15, step1469]: loss 0.056795
[epoch15, step1470]: loss 0.053116
[epoch15, step1471]: loss 0.056356
[epoch15, step1472]: loss 0.056356
[epoch15, step1473]: loss 0.051864
[epoch15, step1474]: loss 0.054726
[epoch15, step1475]: loss 0.054709
[epoch15, step1476]: loss 0.056250
[epoch15, step1477]: loss 0.054544
[epoch15, step1478]: loss 0.057187
[epoch15, step1479]: loss 0.053078
[epoch15, step1480]: loss 0.056637
[epoch15, step1481]: loss 0.056385
[epoch15, step1482]: loss 0.052493
[epoch15, step1483]: loss 0.055157
[epoch15, step1484]: loss 0.054673
[epoch15, step1485]: loss 0.056438
[epoch15, step1486]: loss 0.053764
[epoch15, step1487]: loss 0.056626
[epoch15, step1488]: loss 0.053278
[epoch15, step1489]: loss 0.056172
[epoch15, step1490]: loss 0.056038
[epoch15, step1491]: loss 0.052520
[epoch15, step1492]: loss 0.054834
[epoch15, step1493]: loss 0.054801
[epoch15, step1494]: loss 0.056428
[epoch15, step1495]: loss 0.054254
[epoch15, step1496]: loss 0.056568
[epoch15, step1497]: loss 0.053261
[epoch15, step1498]: loss 0.056168
[epoch15, step1499]: loss 0.056184
[epoch15, step1500]: loss 0.052497
[epoch15, step1501]: loss 0.054649
[epoch15, step1502]: loss 0.054704
[epoch15, step1503]: loss 0.056633
[epoch15, step1504]: loss 0.053994
[epoch15, step1505]: loss 0.057077
[epoch15, step1506]: loss 0.052770
[epoch15, step1507]: loss 0.056250
[epoch15, step1508]: loss 0.056416
[epoch15, step1509]: loss 0.052510
[epoch15, step1510]: loss 0.054766
[epoch15, step1511]: loss 0.054491
[epoch15, step1512]: loss 0.055995
[epoch15, step1513]: loss 0.053780
[epoch15, step1514]: loss 0.056630
[epoch15, step1515]: loss 0.053480
[epoch15, step1516]: loss 0.056003

[epoch15]: avg loss 0.054435

[epoch16, step1]: loss 0.054795
[epoch16, step2]: loss 0.056705
[epoch16, step3]: loss 0.056609
[epoch16, step4]: loss 0.053441
[epoch16, step5]: loss 0.056763
[epoch16, step6]: loss 0.056618
[epoch16, step7]: loss 0.052164
[epoch16, step8]: loss 0.057277
[epoch16, step9]: loss 0.052221
[epoch16, step10]: loss 0.055546
[epoch16, step11]: loss 0.056687
[epoch16, step12]: loss 0.056376
[epoch16, step13]: loss 0.052553
[epoch16, step14]: loss 0.056286
[epoch16, step15]: loss 0.056202
[epoch16, step16]: loss 0.052048
[epoch16, step17]: loss 0.056790
[epoch16, step18]: loss 0.052548
[epoch16, step19]: loss 0.055558
[epoch16, step20]: loss 0.056473
[epoch16, step21]: loss 0.056452
[epoch16, step22]: loss 0.053023
[epoch16, step23]: loss 0.056447
[epoch16, step24]: loss 0.055979
[epoch16, step25]: loss 0.051820
[epoch16, step26]: loss 0.056824
[epoch16, step27]: loss 0.052446
[epoch16, step28]: loss 0.055737
[epoch16, step29]: loss 0.056110
[epoch16, step30]: loss 0.056622
[epoch16, step31]: loss 0.052611
[epoch16, step32]: loss 0.056390
[epoch16, step33]: loss 0.056470
[epoch16, step34]: loss 0.052190
[epoch16, step35]: loss 0.056772
[epoch16, step36]: loss 0.052389
[epoch16, step37]: loss 0.055650
[epoch16, step38]: loss 0.056119
[epoch16, step39]: loss 0.056239
[epoch16, step40]: loss 0.052531
[epoch16, step41]: loss 0.056240
[epoch16, step42]: loss 0.056032
[epoch16, step43]: loss 0.052013
[epoch16, step44]: loss 0.056833
[epoch16, step45]: loss 0.052560
[epoch16, step46]: loss 0.055462
[epoch16, step47]: loss 0.056531
[epoch16, step48]: loss 0.056308
[epoch16, step49]: loss 0.052052
[epoch16, step50]: loss 0.056723
[epoch16, step51]: loss 0.055886
[epoch16, step52]: loss 0.052577
[epoch16, step53]: loss 0.057315
[epoch16, step54]: loss 0.051927
[epoch16, step55]: loss 0.055695
[epoch16, step56]: loss 0.056171
[epoch16, step57]: loss 0.056329
[epoch16, step58]: loss 0.052727
[epoch16, step59]: loss 0.056320
[epoch16, step60]: loss 0.055939
[epoch16, step61]: loss 0.051671
[epoch16, step62]: loss 0.056656
[epoch16, step63]: loss 0.052219
[epoch16, step64]: loss 0.055506
[epoch16, step65]: loss 0.056000
[epoch16, step66]: loss 0.056236
[epoch16, step67]: loss 0.053123
[epoch16, step68]: loss 0.056270
[epoch16, step69]: loss 0.056062
[epoch16, step70]: loss 0.052261
[epoch16, step71]: loss 0.056676
[epoch16, step72]: loss 0.052673
[epoch16, step73]: loss 0.055722
[epoch16, step74]: loss 0.056000
[epoch16, step75]: loss 0.056541
[epoch16, step76]: loss 0.053179
[epoch16, step77]: loss 0.056278
[epoch16, step78]: loss 0.056091
[epoch16, step79]: loss 0.051940
[epoch16, step80]: loss 0.056669
[epoch16, step81]: loss 0.052183
[epoch16, step82]: loss 0.055580
[epoch16, step83]: loss 0.056056
[epoch16, step84]: loss 0.056241
[epoch16, step85]: loss 0.052324
[epoch16, step86]: loss 0.056005
[epoch16, step87]: loss 0.056330
[epoch16, step88]: loss 0.052329
[epoch16, step89]: loss 0.056592
[epoch16, step90]: loss 0.052601
[epoch16, step91]: loss 0.055491
[epoch16, step92]: loss 0.056055
[epoch16, step93]: loss 0.056017
[epoch16, step94]: loss 0.052976
[epoch16, step95]: loss 0.056215
[epoch16, step96]: loss 0.055885
[epoch16, step97]: loss 0.052577
[epoch16, step98]: loss 0.056750
[epoch16, step99]: loss 0.052695
[epoch16, step100]: loss 0.055750
[epoch16, step101]: loss 0.055935
[epoch16, step102]: loss 0.056536
[epoch16, step103]: loss 0.052972
[epoch16, step104]: loss 0.056116
[epoch16, step105]: loss 0.056056
[epoch16, step106]: loss 0.051878
[epoch16, step107]: loss 0.056508
[epoch16, step108]: loss 0.052476
[epoch16, step109]: loss 0.055167
[epoch16, step110]: loss 0.056001
[epoch16, step111]: loss 0.056108
[epoch16, step112]: loss 0.053036
[epoch16, step113]: loss 0.055996
[epoch16, step114]: loss 0.055837
[epoch16, step115]: loss 0.051912
[epoch16, step116]: loss 0.056581
[epoch16, step117]: loss 0.052091
[epoch16, step118]: loss 0.055536
[epoch16, step119]: loss 0.056430
[epoch16, step120]: loss 0.056230
[epoch16, step121]: loss 0.052707
[epoch16, step122]: loss 0.056563
[epoch16, step123]: loss 0.056156
[epoch16, step124]: loss 0.052398
[epoch16, step125]: loss 0.057273
[epoch16, step126]: loss 0.052306
[epoch16, step127]: loss 0.055290
[epoch16, step128]: loss 0.056213
[epoch16, step129]: loss 0.055707
[epoch16, step130]: loss 0.052088
[epoch16, step131]: loss 0.056205
[epoch16, step132]: loss 0.055784
[epoch16, step133]: loss 0.051163
[epoch16, step134]: loss 0.056671
[epoch16, step135]: loss 0.052123
[epoch16, step136]: loss 0.055178
[epoch16, step137]: loss 0.056031
[epoch16, step138]: loss 0.055963
[epoch16, step139]: loss 0.052808
[epoch16, step140]: loss 0.056209
[epoch16, step141]: loss 0.055660
[epoch16, step142]: loss 0.052355
[epoch16, step143]: loss 0.057011
[epoch16, step144]: loss 0.052653
[epoch16, step145]: loss 0.055647
[epoch16, step146]: loss 0.056045
[epoch16, step147]: loss 0.056223
[epoch16, step148]: loss 0.052412
[epoch16, step149]: loss 0.055849
[epoch16, step150]: loss 0.055735
[epoch16, step151]: loss 0.050999
[epoch16, step152]: loss 0.056389
[epoch16, step153]: loss 0.051956
[epoch16, step154]: loss 0.055042
[epoch16, step155]: loss 0.055731
[epoch16, step156]: loss 0.056022
[epoch16, step157]: loss 0.052279
[epoch16, step158]: loss 0.055815
[epoch16, step159]: loss 0.055756
[epoch16, step160]: loss 0.051751
[epoch16, step161]: loss 0.056353
[epoch16, step162]: loss 0.052167
[epoch16, step163]: loss 0.055110
[epoch16, step164]: loss 0.055977
[epoch16, step165]: loss 0.056164
[epoch16, step166]: loss 0.052026
[epoch16, step167]: loss 0.056199
[epoch16, step168]: loss 0.055700
[epoch16, step169]: loss 0.051937
[epoch16, step170]: loss 0.056668
[epoch16, step171]: loss 0.052303
[epoch16, step172]: loss 0.055165
[epoch16, step173]: loss 0.056116
[epoch16, step174]: loss 0.055926
[epoch16, step175]: loss 0.052381
[epoch16, step176]: loss 0.055992
[epoch16, step177]: loss 0.055835
[epoch16, step178]: loss 0.051024
[epoch16, step179]: loss 0.056251
[epoch16, step180]: loss 0.051972
[epoch16, step181]: loss 0.054848
[epoch16, step182]: loss 0.055705
[epoch16, step183]: loss 0.056003
[epoch16, step184]: loss 0.052699
[epoch16, step185]: loss 0.055948
[epoch16, step186]: loss 0.055471
[epoch16, step187]: loss 0.052260
[epoch16, step188]: loss 0.056485
[epoch16, step189]: loss 0.052238
[epoch16, step190]: loss 0.055544
[epoch16, step191]: loss 0.055604
[epoch16, step192]: loss 0.056188
[epoch16, step193]: loss 0.052265
[epoch16, step194]: loss 0.055600
[epoch16, step195]: loss 0.055805
[epoch16, step196]: loss 0.050921
[epoch16, step197]: loss 0.056204
[epoch16, step198]: loss 0.051645
[epoch16, step199]: loss 0.054882
[epoch16, step200]: loss 0.055602
[epoch16, step201]: loss 0.055887
[epoch16, step202]: loss 0.052229
[epoch16, step203]: loss 0.055740
[epoch16, step204]: loss 0.055564
[epoch16, step205]: loss 0.051427
[epoch16, step206]: loss 0.056263
[epoch16, step207]: loss 0.051959
[epoch16, step208]: loss 0.054987
[epoch16, step209]: loss 0.055964
[epoch16, step210]: loss 0.056108
[epoch16, step211]: loss 0.053003
[epoch16, step212]: loss 0.056351
[epoch16, step213]: loss 0.055750
[epoch16, step214]: loss 0.052195
[epoch16, step215]: loss 0.057040
[epoch16, step216]: loss 0.052037
[epoch16, step217]: loss 0.055054
[epoch16, step218]: loss 0.055956
[epoch16, step219]: loss 0.055866
[epoch16, step220]: loss 0.052988
[epoch16, step221]: loss 0.055991
[epoch16, step222]: loss 0.055456
[epoch16, step223]: loss 0.050993
[epoch16, step224]: loss 0.056482
[epoch16, step225]: loss 0.051736
[epoch16, step226]: loss 0.054837
[epoch16, step227]: loss 0.055966
[epoch16, step228]: loss 0.055968
[epoch16, step229]: loss 0.052573
[epoch16, step230]: loss 0.056350
[epoch16, step231]: loss 0.055853
[epoch16, step232]: loss 0.050943
[epoch16, step233]: loss 0.056729
[epoch16, step234]: loss 0.051961
[epoch16, step235]: loss 0.055256
[epoch16, step236]: loss 0.055709
[epoch16, step237]: loss 0.055822
[epoch16, step238]: loss 0.051727
[epoch16, step239]: loss 0.055487
[epoch16, step240]: loss 0.055388
[epoch16, step241]: loss 0.051650
[epoch16, step242]: loss 0.056166
[epoch16, step243]: loss 0.052066
[epoch16, step244]: loss 0.054714
[epoch16, step245]: loss 0.055593
[epoch16, step246]: loss 0.055744
[epoch16, step247]: loss 0.052772
[epoch16, step248]: loss 0.055651
[epoch16, step249]: loss 0.055327
[epoch16, step250]: loss 0.051399
[epoch16, step251]: loss 0.056325
[epoch16, step252]: loss 0.052232
[epoch16, step253]: loss 0.055231
[epoch16, step254]: loss 0.055433
[epoch16, step255]: loss 0.055864
[epoch16, step256]: loss 0.052566
[epoch16, step257]: loss 0.055536
[epoch16, step258]: loss 0.055421
[epoch16, step259]: loss 0.050565
[epoch16, step260]: loss 0.055993
[epoch16, step261]: loss 0.051734
[epoch16, step262]: loss 0.054861
[epoch16, step263]: loss 0.055353
[epoch16, step264]: loss 0.055602
[epoch16, step265]: loss 0.052543
[epoch16, step266]: loss 0.055470
[epoch16, step267]: loss 0.055201
[epoch16, step268]: loss 0.051288
[epoch16, step269]: loss 0.056038
[epoch16, step270]: loss 0.051580
[epoch16, step271]: loss 0.054491
[epoch16, step272]: loss 0.055713
[epoch16, step273]: loss 0.055673
[epoch16, step274]: loss 0.052278
[epoch16, step275]: loss 0.055753
[epoch16, step276]: loss 0.055284
[epoch16, step277]: loss 0.051902
[epoch16, step278]: loss 0.056426
[epoch16, step279]: loss 0.051451
[epoch16, step280]: loss 0.054884
[epoch16, step281]: loss 0.055326
[epoch16, step282]: loss 0.055630
[epoch16, step283]: loss 0.052306
[epoch16, step284]: loss 0.055338
[epoch16, step285]: loss 0.055478
[epoch16, step286]: loss 0.051717
[epoch16, step287]: loss 0.055965
[epoch16, step288]: loss 0.051663
[epoch16, step289]: loss 0.054714
[epoch16, step290]: loss 0.055507
[epoch16, step291]: loss 0.055596
[epoch16, step292]: loss 0.052064
[epoch16, step293]: loss 0.055403
[epoch16, step294]: loss 0.055053
[epoch16, step295]: loss 0.051111
[epoch16, step296]: loss 0.056049
[epoch16, step297]: loss 0.052225
[epoch16, step298]: loss 0.054891
[epoch16, step299]: loss 0.055458
[epoch16, step300]: loss 0.055841
[epoch16, step301]: loss 0.052524
[epoch16, step302]: loss 0.055752
[epoch16, step303]: loss 0.055513
[epoch16, step304]: loss 0.050517
[epoch16, step305]: loss 0.055990
[epoch16, step306]: loss 0.051669
[epoch16, step307]: loss 0.054748
[epoch16, step308]: loss 0.055654
[epoch16, step309]: loss 0.055419
[epoch16, step310]: loss 0.052331
[epoch16, step311]: loss 0.055381
[epoch16, step312]: loss 0.055329
[epoch16, step313]: loss 0.051497
[epoch16, step314]: loss 0.055834
[epoch16, step315]: loss 0.052294
[epoch16, step316]: loss 0.054666
[epoch16, step317]: loss 0.055291
[epoch16, step318]: loss 0.055546
[epoch16, step319]: loss 0.052290
[epoch16, step320]: loss 0.055277
[epoch16, step321]: loss 0.055160
[epoch16, step322]: loss 0.051874
[epoch16, step323]: loss 0.055860
[epoch16, step324]: loss 0.052222
[epoch16, step325]: loss 0.054623
[epoch16, step326]: loss 0.055361
[epoch16, step327]: loss 0.055617
[epoch16, step328]: loss 0.052459
[epoch16, step329]: loss 0.055648
[epoch16, step330]: loss 0.055086
[epoch16, step331]: loss 0.051711
[epoch16, step332]: loss 0.055996
[epoch16, step333]: loss 0.051732
[epoch16, step334]: loss 0.054724
[epoch16, step335]: loss 0.055424
[epoch16, step336]: loss 0.055630
[epoch16, step337]: loss 0.051676
[epoch16, step338]: loss 0.055322
[epoch16, step339]: loss 0.055183
[epoch16, step340]: loss 0.051510
[epoch16, step341]: loss 0.055760
[epoch16, step342]: loss 0.051232
[epoch16, step343]: loss 0.054314
[epoch16, step344]: loss 0.055092
[epoch16, step345]: loss 0.055381
[epoch16, step346]: loss 0.052159
[epoch16, step347]: loss 0.055218
[epoch16, step348]: loss 0.054987
[epoch16, step349]: loss 0.051448
[epoch16, step350]: loss 0.055764
[epoch16, step351]: loss 0.051543
[epoch16, step352]: loss 0.054368
[epoch16, step353]: loss 0.055179
[epoch16, step354]: loss 0.055540
[epoch16, step355]: loss 0.051800
[epoch16, step356]: loss 0.055525
[epoch16, step357]: loss 0.055003
[epoch16, step358]: loss 0.051216
[epoch16, step359]: loss 0.055955
[epoch16, step360]: loss 0.050927
[epoch16, step361]: loss 0.054506
[epoch16, step362]: loss 0.055286
[epoch16, step363]: loss 0.055435
[epoch16, step364]: loss 0.052036
[epoch16, step365]: loss 0.055068
[epoch16, step366]: loss 0.055289
[epoch16, step367]: loss 0.051264
[epoch16, step368]: loss 0.055612
[epoch16, step369]: loss 0.051438
[epoch16, step370]: loss 0.054347
[epoch16, step371]: loss 0.055200
[epoch16, step372]: loss 0.055284
[epoch16, step373]: loss 0.051547
[epoch16, step374]: loss 0.055062
[epoch16, step375]: loss 0.055039
[epoch16, step376]: loss 0.050788
[epoch16, step377]: loss 0.055758
[epoch16, step378]: loss 0.052240
[epoch16, step379]: loss 0.054702
[epoch16, step380]: loss 0.055137
[epoch16, step381]: loss 0.055607
[epoch16, step382]: loss 0.052713
[epoch16, step383]: loss 0.055091
[epoch16, step384]: loss 0.055087
[epoch16, step385]: loss 0.050454
[epoch16, step386]: loss 0.055724
[epoch16, step387]: loss 0.051180
[epoch16, step388]: loss 0.054335
[epoch16, step389]: loss 0.055116
[epoch16, step390]: loss 0.055258
[epoch16, step391]: loss 0.051253
[epoch16, step392]: loss 0.055035
[epoch16, step393]: loss 0.055077
[epoch16, step394]: loss 0.051199
[epoch16, step395]: loss 0.055609
[epoch16, step396]: loss 0.051431
[epoch16, step397]: loss 0.054317
[epoch16, step398]: loss 0.055185
[epoch16, step399]: loss 0.055252
[epoch16, step400]: loss 0.051349
[epoch16, step401]: loss 0.055090
[epoch16, step402]: loss 0.054838
[epoch16, step403]: loss 0.051032
[epoch16, step404]: loss 0.055887
[epoch16, step405]: loss 0.051330
[epoch16, step406]: loss 0.054517
[epoch16, step407]: loss 0.054920
[epoch16, step408]: loss 0.055399
[epoch16, step409]: loss 0.051831
[epoch16, step410]: loss 0.055083
[epoch16, step411]: loss 0.054999
[epoch16, step412]: loss 0.050136
[epoch16, step413]: loss 0.055508
[epoch16, step414]: loss 0.051569
[epoch16, step415]: loss 0.054529
[epoch16, step416]: loss 0.054871
[epoch16, step417]: loss 0.055229
[epoch16, step418]: loss 0.051383
[epoch16, step419]: loss 0.054744
[epoch16, step420]: loss 0.054742
[epoch16, step421]: loss 0.050699
[epoch16, step422]: loss 0.055556
[epoch16, step423]: loss 0.051346
[epoch16, step424]: loss 0.054001
[epoch16, step425]: loss 0.055398
[epoch16, step426]: loss 0.055410
[epoch16, step427]: loss 0.052456
[epoch16, step428]: loss 0.055478
[epoch16, step429]: loss 0.055105
[epoch16, step430]: loss 0.050804
[epoch16, step431]: loss 0.056365
[epoch16, step432]: loss 0.051210
[epoch16, step433]: loss 0.054257
[epoch16, step434]: loss 0.055297
[epoch16, step435]: loss 0.055288
[epoch16, step436]: loss 0.052054
[epoch16, step437]: loss 0.055264
[epoch16, step438]: loss 0.054793
[epoch16, step439]: loss 0.051436
[epoch16, step440]: loss 0.055692
[epoch16, step441]: loss 0.051470
[epoch16, step442]: loss 0.053979
[epoch16, step443]: loss 0.055299
[epoch16, step444]: loss 0.055322
[epoch16, step445]: loss 0.052338
[epoch16, step446]: loss 0.055525
[epoch16, step447]: loss 0.055154
[epoch16, step448]: loss 0.050687
[epoch16, step449]: loss 0.056450
[epoch16, step450]: loss 0.051438
[epoch16, step451]: loss 0.054358
[epoch16, step452]: loss 0.055029
[epoch16, step453]: loss 0.055162
[epoch16, step454]: loss 0.051998
[epoch16, step455]: loss 0.054914
[epoch16, step456]: loss 0.054541
[epoch16, step457]: loss 0.051116
[epoch16, step458]: loss 0.055508
[epoch16, step459]: loss 0.051421
[epoch16, step460]: loss 0.054063
[epoch16, step461]: loss 0.055558
[epoch16, step462]: loss 0.055038
[epoch16, step463]: loss 0.052228
[epoch16, step464]: loss 0.055257
[epoch16, step465]: loss 0.054965
[epoch16, step466]: loss 0.050925
[epoch16, step467]: loss 0.055924
[epoch16, step468]: loss 0.051232
[epoch16, step469]: loss 0.054195
[epoch16, step470]: loss 0.055072
[epoch16, step471]: loss 0.054984
[epoch16, step472]: loss 0.052278
[epoch16, step473]: loss 0.054911
[epoch16, step474]: loss 0.054856
[epoch16, step475]: loss 0.050752
[epoch16, step476]: loss 0.055460
[epoch16, step477]: loss 0.051299
[epoch16, step478]: loss 0.054024
[epoch16, step479]: loss 0.054904
[epoch16, step480]: loss 0.054865
[epoch16, step481]: loss 0.051548
[epoch16, step482]: loss 0.054826
[epoch16, step483]: loss 0.054679
[epoch16, step484]: loss 0.050328
[epoch16, step485]: loss 0.055467
[epoch16, step486]: loss 0.051391
[epoch16, step487]: loss 0.054191
[epoch16, step488]: loss 0.055060
[epoch16, step489]: loss 0.055227
[epoch16, step490]: loss 0.051966
[epoch16, step491]: loss 0.054849
[epoch16, step492]: loss 0.054692
[epoch16, step493]: loss 0.050194
[epoch16, step494]: loss 0.055322
[epoch16, step495]: loss 0.051232
[epoch16, step496]: loss 0.054009
[epoch16, step497]: loss 0.054644
[epoch16, step498]: loss 0.054837
[epoch16, step499]: loss 0.051956
[epoch16, step500]: loss 0.054651
[epoch16, step501]: loss 0.054480
[epoch16, step502]: loss 0.050501
[epoch16, step503]: loss 0.055332
[epoch16, step504]: loss 0.051371
[epoch16, step505]: loss 0.053799
[epoch16, step506]: loss 0.054695
[epoch16, step507]: loss 0.054877
[epoch16, step508]: loss 0.052036
[epoch16, step509]: loss 0.054749
[epoch16, step510]: loss 0.054959
[epoch16, step511]: loss 0.051411
[epoch16, step512]: loss 0.055327
[epoch16, step513]: loss 0.051390
[epoch16, step514]: loss 0.053845
[epoch16, step515]: loss 0.054823
[epoch16, step516]: loss 0.055136
[epoch16, step517]: loss 0.051935
[epoch16, step518]: loss 0.054933
[epoch16, step519]: loss 0.054610
[epoch16, step520]: loss 0.050031
[epoch16, step521]: loss 0.055311
[epoch16, step522]: loss 0.050763
[epoch16, step523]: loss 0.054037
[epoch16, step524]: loss 0.054695
[epoch16, step525]: loss 0.054980
[epoch16, step526]: loss 0.051140
[epoch16, step527]: loss 0.054726
[epoch16, step528]: loss 0.054557
[epoch16, step529]: loss 0.050504
[epoch16, step530]: loss 0.055321
[epoch16, step531]: loss 0.050848
[epoch16, step532]: loss 0.053804
[epoch16, step533]: loss 0.054837
[epoch16, step534]: loss 0.054919
[epoch16, step535]: loss 0.051908
[epoch16, step536]: loss 0.054695
[epoch16, step537]: loss 0.054388
[epoch16, step538]: loss 0.051298
[epoch16, step539]: loss 0.055230
[epoch16, step540]: loss 0.051649
[epoch16, step541]: loss 0.053908
[epoch16, step542]: loss 0.054786
[epoch16, step543]: loss 0.054837
[epoch16, step544]: loss 0.050711
[epoch16, step545]: loss 0.054594
[epoch16, step546]: loss 0.054586
[epoch16, step547]: loss 0.050952
[epoch16, step548]: loss 0.055194
[epoch16, step549]: loss 0.051119
[epoch16, step550]: loss 0.053848
[epoch16, step551]: loss 0.054393
[epoch16, step552]: loss 0.054733
[epoch16, step553]: loss 0.051862
[epoch16, step554]: loss 0.054602
[epoch16, step555]: loss 0.054322
[epoch16, step556]: loss 0.050237
[epoch16, step557]: loss 0.055026
[epoch16, step558]: loss 0.051066
[epoch16, step559]: loss 0.053615
[epoch16, step560]: loss 0.054537
[epoch16, step561]: loss 0.054838
[epoch16, step562]: loss 0.051182
[epoch16, step563]: loss 0.049992
[epoch16, step564]: loss 0.046842
[epoch16, step565]: loss 0.040814
[epoch16, step566]: loss 0.049387
[epoch16, step567]: loss 0.041107
[epoch16, step568]: loss 0.041287
[epoch16, step569]: loss 0.044093
[epoch16, step570]: loss 0.046802
[epoch16, step571]: loss 0.036359
[epoch16, step572]: loss 0.041259
[epoch16, step573]: loss 0.045625
[epoch16, step574]: loss 0.048361
[epoch16, step575]: loss 0.038819
[epoch16, step576]: loss 0.040360
[epoch16, step577]: loss 0.040053
[epoch16, step578]: loss 0.038789
[epoch16, step579]: loss 0.040474
[epoch16, step580]: loss 0.042723
[epoch16, step581]: loss 0.042962
[epoch16, step582]: loss 0.042098
[epoch16, step583]: loss 0.040481
[epoch16, step584]: loss 0.040728
[epoch16, step585]: loss 0.046481
[epoch16, step586]: loss 0.040164
[epoch16, step587]: loss 0.038188
[epoch16, step588]: loss 0.041430
[epoch16, step589]: loss 0.047537
[epoch16, step590]: loss 0.038666
[epoch16, step591]: loss 0.038145
[epoch16, step592]: loss 0.044874
[epoch16, step593]: loss 0.046438
[epoch16, step594]: loss 0.037887
[epoch16, step595]: loss 0.038314
[epoch16, step596]: loss 0.042163
[epoch16, step597]: loss 0.045014
[epoch16, step598]: loss 0.040777
[epoch16, step599]: loss 0.037391
[epoch16, step600]: loss 0.038283
[epoch16, step601]: loss 0.037504
[epoch16, step602]: loss 0.044539
[epoch16, step603]: loss 0.039779
[epoch16, step604]: loss 0.040198
[epoch16, step605]: loss 0.037304
[epoch16, step606]: loss 0.041427
[epoch16, step607]: loss 0.045012
[epoch16, step608]: loss 0.035218
[epoch16, step609]: loss 0.043323
[epoch16, step610]: loss 0.041239
[epoch16, step611]: loss 0.045199
[epoch16, step612]: loss 0.042441
[epoch16, step613]: loss 0.039739
[epoch16, step614]: loss 0.042243
[epoch16, step615]: loss 0.044119
[epoch16, step616]: loss 0.037057
[epoch16, step617]: loss 0.038994
[epoch16, step618]: loss 0.044255
[epoch16, step619]: loss 0.039841
[epoch16, step620]: loss 0.036031
[epoch16, step621]: loss 0.036938
[epoch16, step622]: loss 0.039684
[epoch16, step623]: loss 0.041795
[epoch16, step624]: loss 0.043624
[epoch16, step625]: loss 0.036527
[epoch16, step626]: loss 0.044642
[epoch16, step627]: loss 0.044276
[epoch16, step628]: loss 0.043691
[epoch16, step629]: loss 0.029464
[epoch16, step630]: loss 0.037457
[epoch16, step631]: loss 0.043739
[epoch16, step632]: loss 0.040855
[epoch16, step633]: loss 0.037863
[epoch16, step634]: loss 0.043548
[epoch16, step635]: loss 0.040234
[epoch16, step636]: loss 0.034508
[epoch16, step637]: loss 0.045500
[epoch16, step638]: loss 0.043454
[epoch16, step639]: loss 0.035343
[epoch16, step640]: loss 0.046708
[epoch16, step641]: loss 0.042097
[epoch16, step642]: loss 0.036969
[epoch16, step643]: loss 0.043583
[epoch16, step644]: loss 0.040292
[epoch16, step645]: loss 0.034082
[epoch16, step646]: loss 0.041622
[epoch16, step647]: loss 0.034656
[epoch16, step648]: loss 0.044566
[epoch16, step649]: loss 0.044594
[epoch16, step650]: loss 0.040891
[epoch16, step651]: loss 0.040810
[epoch16, step652]: loss 0.046565
[epoch16, step653]: loss 0.046575
[epoch16, step654]: loss 0.041252
[epoch16, step655]: loss 0.037235
[epoch16, step656]: loss 0.041723
[epoch16, step657]: loss 0.045885
[epoch16, step658]: loss 0.038843
[epoch16, step659]: loss 0.037675
[epoch16, step660]: loss 0.040207
[epoch16, step661]: loss 0.043569
[epoch16, step662]: loss 0.035570
[epoch16, step663]: loss 0.037019
[epoch16, step664]: loss 0.039483
[epoch16, step665]: loss 0.047160
[epoch16, step666]: loss 0.037691
[epoch16, step667]: loss 0.043107
[epoch16, step668]: loss 0.042524
[epoch16, step669]: loss 0.037841
[epoch16, step670]: loss 0.042999
[epoch16, step671]: loss 0.039270
[epoch16, step672]: loss 0.045646
[epoch16, step673]: loss 0.041886
[epoch16, step674]: loss 0.036944
[epoch16, step675]: loss 0.039635
[epoch16, step676]: loss 0.042497
[epoch16, step677]: loss 0.039175
[epoch16, step678]: loss 0.035061
[epoch16, step679]: loss 0.039811
[epoch16, step680]: loss 0.041382
[epoch16, step681]: loss 0.034800
[epoch16, step682]: loss 0.038864
[epoch16, step683]: loss 0.041481
[epoch16, step684]: loss 0.037039
[epoch16, step685]: loss 0.037344
[epoch16, step686]: loss 0.038580
[epoch16, step687]: loss 0.040069
[epoch16, step688]: loss 0.040536
[epoch16, step689]: loss 0.036864
[epoch16, step690]: loss 0.043408
[epoch16, step691]: loss 0.043773
[epoch16, step692]: loss 0.041206
[epoch16, step693]: loss 0.043043
[epoch16, step694]: loss 0.034724
[epoch16, step695]: loss 0.040037
[epoch16, step696]: loss 0.038288
[epoch16, step697]: loss 0.042690
[epoch16, step698]: loss 0.038864
[epoch16, step699]: loss 0.038564
[epoch16, step700]: loss 0.043090
[epoch16, step701]: loss 0.042641
[epoch16, step702]: loss 0.036668
[epoch16, step703]: loss 0.043669
[epoch16, step704]: loss 0.043040
[epoch16, step705]: loss 0.037317
[epoch16, step706]: loss 0.037605
[epoch16, step707]: loss 0.038518
[epoch16, step708]: loss 0.041407
[epoch16, step709]: loss 0.040259
[epoch16, step710]: loss 0.039936
[epoch16, step711]: loss 0.042171
[epoch16, step712]: loss 0.037807
[epoch16, step713]: loss 0.039455
[epoch16, step714]: loss 0.039035
[epoch16, step715]: loss 0.037116
[epoch16, step716]: loss 0.042191
[epoch16, step717]: loss 0.036840
[epoch16, step718]: loss 0.040523
[epoch16, step719]: loss 0.047176
[epoch16, step720]: loss 0.037128
[epoch16, step721]: loss 0.038179
[epoch16, step722]: loss 0.045735
[epoch16, step723]: loss 0.040613
[epoch16, step724]: loss 0.039950
[epoch16, step725]: loss 0.044228
[epoch16, step726]: loss 0.033203
[epoch16, step727]: loss 0.040763
[epoch16, step728]: loss 0.042201
[epoch16, step729]: loss 0.034303
[epoch16, step730]: loss 0.039613
[epoch16, step731]: loss 0.043576
[epoch16, step732]: loss 0.039749
[epoch16, step733]: loss 0.034650
[epoch16, step734]: loss 0.036405
[epoch16, step735]: loss 0.039762
[epoch16, step736]: loss 0.038796
[epoch16, step737]: loss 0.038021
[epoch16, step738]: loss 0.034849
[epoch16, step739]: loss 0.045990
[epoch16, step740]: loss 0.044832
[epoch16, step741]: loss 0.040616
[epoch16, step742]: loss 0.041042
[epoch16, step743]: loss 0.038817
[epoch16, step744]: loss 0.039252
[epoch16, step745]: loss 0.040255
[epoch16, step746]: loss 0.041545
[epoch16, step747]: loss 0.041174
[epoch16, step748]: loss 0.038093
[epoch16, step749]: loss 0.046560
[epoch16, step750]: loss 0.043652
[epoch16, step751]: loss 0.035966
[epoch16, step752]: loss 0.037175
[epoch16, step753]: loss 0.037605
[epoch16, step754]: loss 0.041312
[epoch16, step755]: loss 0.042643
[epoch16, step756]: loss 0.034517
[epoch16, step757]: loss 0.036888
[epoch16, step758]: loss 0.041987
[epoch16, step759]: loss 0.035526
[epoch16, step760]: loss 0.040656
[epoch16, step761]: loss 0.040510
[epoch16, step762]: loss 0.035164
[epoch16, step763]: loss 0.038573
[epoch16, step764]: loss 0.039913
[epoch16, step765]: loss 0.038243
[epoch16, step766]: loss 0.036781
[epoch16, step767]: loss 0.042964
[epoch16, step768]: loss 0.037497
[epoch16, step769]: loss 0.041873
[epoch16, step770]: loss 0.045454
[epoch16, step771]: loss 0.035419
[epoch16, step772]: loss 0.040524
[epoch16, step773]: loss 0.040482
[epoch16, step774]: loss 0.038936
[epoch16, step775]: loss 0.041141
[epoch16, step776]: loss 0.041419
[epoch16, step777]: loss 0.037289
[epoch16, step778]: loss 0.045314
[epoch16, step779]: loss 0.038280
[epoch16, step780]: loss 0.038192
[epoch16, step781]: loss 0.044313
[epoch16, step782]: loss 0.041570
[epoch16, step783]: loss 0.035825
[epoch16, step784]: loss 0.039131
[epoch16, step785]: loss 0.039840
[epoch16, step786]: loss 0.039124
[epoch16, step787]: loss 0.042924
[epoch16, step788]: loss 0.040220
[epoch16, step789]: loss 0.041603
[epoch16, step790]: loss 0.035487
[epoch16, step791]: loss 0.043007
[epoch16, step792]: loss 0.041421
[epoch16, step793]: loss 0.043100
[epoch16, step794]: loss 0.036663
[epoch16, step795]: loss 0.040172
[epoch16, step796]: loss 0.040556
[epoch16, step797]: loss 0.039521
[epoch16, step798]: loss 0.039176
[epoch16, step799]: loss 0.035433
[epoch16, step800]: loss 0.042685
[epoch16, step801]: loss 0.041365
[epoch16, step802]: loss 0.037803
[epoch16, step803]: loss 0.039157
[epoch16, step804]: loss 0.043196
[epoch16, step805]: loss 0.041405
[epoch16, step806]: loss 0.037450
[epoch16, step807]: loss 0.039077
[epoch16, step808]: loss 0.042581
[epoch16, step809]: loss 0.036659
[epoch16, step810]: loss 0.036148
[epoch16, step811]: loss 0.040898
[epoch16, step812]: loss 0.041169
[epoch16, step813]: loss 0.036906
[epoch16, step814]: loss 0.040976
[epoch16, step815]: loss 0.039631
[epoch16, step816]: loss 0.039053
[epoch16, step817]: loss 0.036791
[epoch16, step818]: loss 0.037042
[epoch16, step819]: loss 0.044724
[epoch16, step820]: loss 0.035990
[epoch16, step821]: loss 0.035176
[epoch16, step822]: loss 0.044915
[epoch16, step823]: loss 0.036245
[epoch16, step824]: loss 0.041963
[epoch16, step825]: loss 0.041139
[epoch16, step826]: loss 0.033916
[epoch16, step827]: loss 0.038960
[epoch16, step828]: loss 0.042966
[epoch16, step829]: loss 0.039484
[epoch16, step830]: loss 0.031962
[epoch16, step831]: loss 0.037912
[epoch16, step832]: loss 0.041413
[epoch16, step833]: loss 0.043332
[epoch16, step834]: loss 0.039918
[epoch16, step835]: loss 0.037191
[epoch16, step836]: loss 0.038660
[epoch16, step837]: loss 0.037445
[epoch16, step838]: loss 0.043610
[epoch16, step839]: loss 0.041991
[epoch16, step840]: loss 0.034691
[epoch16, step841]: loss 0.039128
[epoch16, step842]: loss 0.041826
[epoch16, step843]: loss 0.041842
[epoch16, step844]: loss 0.042013
[epoch16, step845]: loss 0.037741
[epoch16, step846]: loss 0.046396
[epoch16, step847]: loss 0.041166
[epoch16, step848]: loss 0.031433
[epoch16, step849]: loss 0.038468
[epoch16, step850]: loss 0.040549
[epoch16, step851]: loss 0.038636
[epoch16, step852]: loss 0.038365
[epoch16, step853]: loss 0.044993
[epoch16, step854]: loss 0.040376
[epoch16, step855]: loss 0.039118
[epoch16, step856]: loss 0.033821
[epoch16, step857]: loss 0.041882
[epoch16, step858]: loss 0.040719
[epoch16, step859]: loss 0.036316
[epoch16, step860]: loss 0.040804
[epoch16, step861]: loss 0.038481
[epoch16, step862]: loss 0.034554
[epoch16, step863]: loss 0.038654
[epoch16, step864]: loss 0.044122
[epoch16, step865]: loss 0.039422
[epoch16, step866]: loss 0.041661
[epoch16, step867]: loss 0.039305
[epoch16, step868]: loss 0.042186
[epoch16, step869]: loss 0.036202
[epoch16, step870]: loss 0.041136
[epoch16, step871]: loss 0.041849
[epoch16, step872]: loss 0.041358
[epoch16, step873]: loss 0.036881
[epoch16, step874]: loss 0.038481
[epoch16, step875]: loss 0.044286
[epoch16, step876]: loss 0.041688
[epoch16, step877]: loss 0.027556
[epoch16, step878]: loss 0.036693
[epoch16, step879]: loss 0.040898
[epoch16, step880]: loss 0.038184
[epoch16, step881]: loss 0.040240
[epoch16, step882]: loss 0.036395
[epoch16, step883]: loss 0.037603
[epoch16, step884]: loss 0.045543
[epoch16, step885]: loss 0.044874
[epoch16, step886]: loss 0.044307
[epoch16, step887]: loss 0.044080
[epoch16, step888]: loss 0.038130
[epoch16, step889]: loss 0.040612
[epoch16, step890]: loss 0.040534
[epoch16, step891]: loss 0.038189
[epoch16, step892]: loss 0.038956
[epoch16, step893]: loss 0.041080
[epoch16, step894]: loss 0.041172
[epoch16, step895]: loss 0.034626
[epoch16, step896]: loss 0.043967
[epoch16, step897]: loss 0.045068
[epoch16, step898]: loss 0.037856
[epoch16, step899]: loss 0.034981
[epoch16, step900]: loss 0.041276
[epoch16, step901]: loss 0.042798
[epoch16, step902]: loss 0.036590
[epoch16, step903]: loss 0.042870
[epoch16, step904]: loss 0.039936
[epoch16, step905]: loss 0.038511
[epoch16, step906]: loss 0.033329
[epoch16, step907]: loss 0.041173
[epoch16, step908]: loss 0.041619
[epoch16, step909]: loss 0.039198
[epoch16, step910]: loss 0.034010
[epoch16, step911]: loss 0.035769
[epoch16, step912]: loss 0.040952
[epoch16, step913]: loss 0.041185
[epoch16, step914]: loss 0.044449
[epoch16, step915]: loss 0.036238
[epoch16, step916]: loss 0.039626
[epoch16, step917]: loss 0.039802
[epoch16, step918]: loss 0.044873
[epoch16, step919]: loss 0.035899
[epoch16, step920]: loss 0.044960
[epoch16, step921]: loss 0.037108
[epoch16, step922]: loss 0.036700
[epoch16, step923]: loss 0.041596
[epoch16, step924]: loss 0.034597
[epoch16, step925]: loss 0.038500
[epoch16, step926]: loss 0.039794
[epoch16, step927]: loss 0.043001
[epoch16, step928]: loss 0.037551
[epoch16, step929]: loss 0.040813
[epoch16, step930]: loss 0.040288
[epoch16, step931]: loss 0.043596
[epoch16, step932]: loss 0.035357
[epoch16, step933]: loss 0.041027
[epoch16, step934]: loss 0.041287
[epoch16, step935]: loss 0.037782
[epoch16, step936]: loss 0.035635
[epoch16, step937]: loss 0.038064
[epoch16, step938]: loss 0.044848
[epoch16, step939]: loss 0.035004
[epoch16, step940]: loss 0.040815
[epoch16, step941]: loss 0.041487
[epoch16, step942]: loss 0.039937
[epoch16, step943]: loss 0.041764
[epoch16, step944]: loss 0.042088
[epoch16, step945]: loss 0.038754
[epoch16, step946]: loss 0.040065
[epoch16, step947]: loss 0.039497
[epoch16, step948]: loss 0.043287
[epoch16, step949]: loss 0.037609
[epoch16, step950]: loss 0.040574
[epoch16, step951]: loss 0.044385
[epoch16, step952]: loss 0.041747
[epoch16, step953]: loss 0.041849
[epoch16, step954]: loss 0.038660
[epoch16, step955]: loss 0.044849
[epoch16, step956]: loss 0.064340
[epoch16, step957]: loss 0.056735
[epoch16, step958]: loss 0.058408
[epoch16, step959]: loss 0.059605
[epoch16, step960]: loss 0.054977
[epoch16, step961]: loss 0.056457
[epoch16, step962]: loss 0.055229
[epoch16, step963]: loss 0.055394
[epoch16, step964]: loss 0.053366
[epoch16, step965]: loss 0.055920
[epoch16, step966]: loss 0.051837
[epoch16, step967]: loss 0.053996
[epoch16, step968]: loss 0.054500
[epoch16, step969]: loss 0.051375
[epoch16, step970]: loss 0.052916
[epoch16, step971]: loss 0.052824
[epoch16, step972]: loss 0.053827
[epoch16, step973]: loss 0.052054
[epoch16, step974]: loss 0.054522
[epoch16, step975]: loss 0.051803
[epoch16, step976]: loss 0.054087
[epoch16, step977]: loss 0.054342
[epoch16, step978]: loss 0.050784
[epoch16, step979]: loss 0.052523
[epoch16, step980]: loss 0.052086
[epoch16, step981]: loss 0.054952
[epoch16, step982]: loss 0.052008
[epoch16, step983]: loss 0.054117
[epoch16, step984]: loss 0.050896
[epoch16, step985]: loss 0.053732
[epoch16, step986]: loss 0.054255
[epoch16, step987]: loss 0.049927
[epoch16, step988]: loss 0.052216
[epoch16, step989]: loss 0.052428
[epoch16, step990]: loss 0.053481
[epoch16, step991]: loss 0.051409
[epoch16, step992]: loss 0.053849
[epoch16, step993]: loss 0.051428
[epoch16, step994]: loss 0.053207
[epoch16, step995]: loss 0.053560
[epoch16, step996]: loss 0.049773
[epoch16, step997]: loss 0.052035
[epoch16, step998]: loss 0.052282
[epoch16, step999]: loss 0.053169
[epoch16, step1000]: loss 0.051615
[epoch16, step1001]: loss 0.053935
[epoch16, step1002]: loss 0.050815
[epoch16, step1003]: loss 0.053229
[epoch16, step1004]: loss 0.053294
[epoch16, step1005]: loss 0.049370
[epoch16, step1006]: loss 0.051998
[epoch16, step1007]: loss 0.051763
[epoch16, step1008]: loss 0.053161
[epoch16, step1009]: loss 0.051387
[epoch16, step1010]: loss 0.053807
[epoch16, step1011]: loss 0.050887
[epoch16, step1012]: loss 0.053204
[epoch16, step1013]: loss 0.053527
[epoch16, step1014]: loss 0.050704
[epoch16, step1015]: loss 0.051983
[epoch16, step1016]: loss 0.051799
[epoch16, step1017]: loss 0.053068
[epoch16, step1018]: loss 0.051266
[epoch16, step1019]: loss 0.053910
[epoch16, step1020]: loss 0.050916
[epoch16, step1021]: loss 0.053439
[epoch16, step1022]: loss 0.053183
[epoch16, step1023]: loss 0.050289
[epoch16, step1024]: loss 0.052111
[epoch16, step1025]: loss 0.051672
[epoch16, step1026]: loss 0.053348
[epoch16, step1027]: loss 0.050767
[epoch16, step1028]: loss 0.053758
[epoch16, step1029]: loss 0.050653
[epoch16, step1030]: loss 0.052824
[epoch16, step1031]: loss 0.053363
[epoch16, step1032]: loss 0.049657
[epoch16, step1033]: loss 0.051875
[epoch16, step1034]: loss 0.051803
[epoch16, step1035]: loss 0.053013
[epoch16, step1036]: loss 0.051512
[epoch16, step1037]: loss 0.053555
[epoch16, step1038]: loss 0.050578
[epoch16, step1039]: loss 0.052862
[epoch16, step1040]: loss 0.053036
[epoch16, step1041]: loss 0.049970
[epoch16, step1042]: loss 0.051248
[epoch16, step1043]: loss 0.051544
[epoch16, step1044]: loss 0.052821
[epoch16, step1045]: loss 0.051294
[epoch16, step1046]: loss 0.053669
[epoch16, step1047]: loss 0.050645
[epoch16, step1048]: loss 0.053129
[epoch16, step1049]: loss 0.053158
[epoch16, step1050]: loss 0.050456
[epoch16, step1051]: loss 0.051864
[epoch16, step1052]: loss 0.052105
[epoch16, step1053]: loss 0.053873
[epoch16, step1054]: loss 0.051290
[epoch16, step1055]: loss 0.053620
[epoch16, step1056]: loss 0.050217
[epoch16, step1057]: loss 0.052967
[epoch16, step1058]: loss 0.053425
[epoch16, step1059]: loss 0.049951
[epoch16, step1060]: loss 0.051456
[epoch16, step1061]: loss 0.051480
[epoch16, step1062]: loss 0.053021
[epoch16, step1063]: loss 0.051244
[epoch16, step1064]: loss 0.053560
[epoch16, step1065]: loss 0.050728
[epoch16, step1066]: loss 0.052612
[epoch16, step1067]: loss 0.053162
[epoch16, step1068]: loss 0.049677
[epoch16, step1069]: loss 0.050798
[epoch16, step1070]: loss 0.051384
[epoch16, step1071]: loss 0.052985
[epoch16, step1072]: loss 0.051402
[epoch16, step1073]: loss 0.053294
[epoch16, step1074]: loss 0.050921
[epoch16, step1075]: loss 0.052964
[epoch16, step1076]: loss 0.053116
[epoch16, step1077]: loss 0.049756
[epoch16, step1078]: loss 0.051546
[epoch16, step1079]: loss 0.051928
[epoch16, step1080]: loss 0.053037
[epoch16, step1081]: loss 0.051459
[epoch16, step1082]: loss 0.053571
[epoch16, step1083]: loss 0.050945
[epoch16, step1084]: loss 0.053096
[epoch16, step1085]: loss 0.053057
[epoch16, step1086]: loss 0.050209
[epoch16, step1087]: loss 0.051804
[epoch16, step1088]: loss 0.051492
[epoch16, step1089]: loss 0.053160
[epoch16, step1090]: loss 0.051148
[epoch16, step1091]: loss 0.053723
[epoch16, step1092]: loss 0.050577
[epoch16, step1093]: loss 0.052641
[epoch16, step1094]: loss 0.052978
[epoch16, step1095]: loss 0.049166
[epoch16, step1096]: loss 0.051478
[epoch16, step1097]: loss 0.051226
[epoch16, step1098]: loss 0.053078
[epoch16, step1099]: loss 0.051074
[epoch16, step1100]: loss 0.053511
[epoch16, step1101]: loss 0.050957
[epoch16, step1102]: loss 0.052626
[epoch16, step1103]: loss 0.052844
[epoch16, step1104]: loss 0.049459
[epoch16, step1105]: loss 0.051414
[epoch16, step1106]: loss 0.051171
[epoch16, step1107]: loss 0.052933
[epoch16, step1108]: loss 0.051129
[epoch16, step1109]: loss 0.053387
[epoch16, step1110]: loss 0.050675
[epoch16, step1111]: loss 0.052907
[epoch16, step1112]: loss 0.053150
[epoch16, step1113]: loss 0.049705
[epoch16, step1114]: loss 0.051601
[epoch16, step1115]: loss 0.051447
[epoch16, step1116]: loss 0.052895
[epoch16, step1117]: loss 0.051113
[epoch16, step1118]: loss 0.053650
[epoch16, step1119]: loss 0.050781
[epoch16, step1120]: loss 0.052899
[epoch16, step1121]: loss 0.053052
[epoch16, step1122]: loss 0.049768
[epoch16, step1123]: loss 0.051347
[epoch16, step1124]: loss 0.051560
[epoch16, step1125]: loss 0.053166
[epoch16, step1126]: loss 0.051381
[epoch16, step1127]: loss 0.053444
[epoch16, step1128]: loss 0.050709
[epoch16, step1129]: loss 0.052591
[epoch16, step1130]: loss 0.053053
[epoch16, step1131]: loss 0.049615
[epoch16, step1132]: loss 0.051511
[epoch16, step1133]: loss 0.051128
[epoch16, step1134]: loss 0.052752
[epoch16, step1135]: loss 0.051046
[epoch16, step1136]: loss 0.053407
[epoch16, step1137]: loss 0.049856
[epoch16, step1138]: loss 0.052526
[epoch16, step1139]: loss 0.053039
[epoch16, step1140]: loss 0.048969
[epoch16, step1141]: loss 0.051039
[epoch16, step1142]: loss 0.051388
[epoch16, step1143]: loss 0.052571
[epoch16, step1144]: loss 0.051383
[epoch16, step1145]: loss 0.053277
[epoch16, step1146]: loss 0.049899
[epoch16, step1147]: loss 0.053032
[epoch16, step1148]: loss 0.053038
[epoch16, step1149]: loss 0.049423
[epoch16, step1150]: loss 0.051590
[epoch16, step1151]: loss 0.051758
[epoch16, step1152]: loss 0.053149
[epoch16, step1153]: loss 0.050661
[epoch16, step1154]: loss 0.053599
[epoch16, step1155]: loss 0.050429
[epoch16, step1156]: loss 0.052436
[epoch16, step1157]: loss 0.053206
[epoch16, step1158]: loss 0.049164
[epoch16, step1159]: loss 0.051281
[epoch16, step1160]: loss 0.051481
[epoch16, step1161]: loss 0.052802
[epoch16, step1162]: loss 0.050879
[epoch16, step1163]: loss 0.053142
[epoch16, step1164]: loss 0.049897
[epoch16, step1165]: loss 0.052628
[epoch16, step1166]: loss 0.052829
[epoch16, step1167]: loss 0.048845
[epoch16, step1168]: loss 0.051280
[epoch16, step1169]: loss 0.051256
[epoch16, step1170]: loss 0.052753
[epoch16, step1171]: loss 0.050956
[epoch16, step1172]: loss 0.053340
[epoch16, step1173]: loss 0.050662
[epoch16, step1174]: loss 0.052688
[epoch16, step1175]: loss 0.053129
[epoch16, step1176]: loss 0.049553
[epoch16, step1177]: loss 0.051183
[epoch16, step1178]: loss 0.051373
[epoch16, step1179]: loss 0.052728
[epoch16, step1180]: loss 0.051065
[epoch16, step1181]: loss 0.053635
[epoch16, step1182]: loss 0.049823
[epoch16, step1183]: loss 0.052939
[epoch16, step1184]: loss 0.052850
[epoch16, step1185]: loss 0.050122
[epoch16, step1186]: loss 0.051046
[epoch16, step1187]: loss 0.051013
[epoch16, step1188]: loss 0.052652
[epoch16, step1189]: loss 0.050594
[epoch16, step1190]: loss 0.053212
[epoch16, step1191]: loss 0.050821
[epoch16, step1192]: loss 0.052369
[epoch16, step1193]: loss 0.052912
[epoch16, step1194]: loss 0.049027
[epoch16, step1195]: loss 0.050993
[epoch16, step1196]: loss 0.050857
[epoch16, step1197]: loss 0.052900
[epoch16, step1198]: loss 0.050795
[epoch16, step1199]: loss 0.053008
[epoch16, step1200]: loss 0.049813
[epoch16, step1201]: loss 0.052365
[epoch16, step1202]: loss 0.052985
[epoch16, step1203]: loss 0.049863
[epoch16, step1204]: loss 0.050960
[epoch16, step1205]: loss 0.050940
[epoch16, step1206]: loss 0.052372
[epoch16, step1207]: loss 0.050900
[epoch16, step1208]: loss 0.053285
[epoch16, step1209]: loss 0.049497
[epoch16, step1210]: loss 0.053041
[epoch16, step1211]: loss 0.052730
[epoch16, step1212]: loss 0.050163
[epoch16, step1213]: loss 0.052059
[epoch16, step1214]: loss 0.051399
[epoch16, step1215]: loss 0.053003
[epoch16, step1216]: loss 0.050993
[epoch16, step1217]: loss 0.053366
[epoch16, step1218]: loss 0.049807
[epoch16, step1219]: loss 0.052704
[epoch16, step1220]: loss 0.052802
[epoch16, step1221]: loss 0.048650
[epoch16, step1222]: loss 0.051487
[epoch16, step1223]: loss 0.050851
[epoch16, step1224]: loss 0.052842
[epoch16, step1225]: loss 0.051166
[epoch16, step1226]: loss 0.053088
[epoch16, step1227]: loss 0.049790
[epoch16, step1228]: loss 0.052633
[epoch16, step1229]: loss 0.052965
[epoch16, step1230]: loss 0.050503
[epoch16, step1231]: loss 0.051801
[epoch16, step1232]: loss 0.051547
[epoch16, step1233]: loss 0.052770
[epoch16, step1234]: loss 0.050755
[epoch16, step1235]: loss 0.053350
[epoch16, step1236]: loss 0.050759
[epoch16, step1237]: loss 0.052176
[epoch16, step1238]: loss 0.052727
[epoch16, step1239]: loss 0.049157
[epoch16, step1240]: loss 0.051102
[epoch16, step1241]: loss 0.051312
[epoch16, step1242]: loss 0.052351
[epoch16, step1243]: loss 0.050374
[epoch16, step1244]: loss 0.053108
[epoch16, step1245]: loss 0.049661
[epoch16, step1246]: loss 0.052324
[epoch16, step1247]: loss 0.052567
[epoch16, step1248]: loss 0.049287
[epoch16, step1249]: loss 0.051151
[epoch16, step1250]: loss 0.051116
[epoch16, step1251]: loss 0.052455
[epoch16, step1252]: loss 0.051657
[epoch16, step1253]: loss 0.053319
[epoch16, step1254]: loss 0.050224
[epoch16, step1255]: loss 0.052811
[epoch16, step1256]: loss 0.052935
[epoch16, step1257]: loss 0.049625
[epoch16, step1258]: loss 0.051812
[epoch16, step1259]: loss 0.051063
[epoch16, step1260]: loss 0.052749
[epoch16, step1261]: loss 0.050960
[epoch16, step1262]: loss 0.052712
[epoch16, step1263]: loss 0.050091
[epoch16, step1264]: loss 0.052389
[epoch16, step1265]: loss 0.052520
[epoch16, step1266]: loss 0.049551
[epoch16, step1267]: loss 0.051208
[epoch16, step1268]: loss 0.051143
[epoch16, step1269]: loss 0.052450
[epoch16, step1270]: loss 0.050589
[epoch16, step1271]: loss 0.053139
[epoch16, step1272]: loss 0.050355
[epoch16, step1273]: loss 0.052377
[epoch16, step1274]: loss 0.053058
[epoch16, step1275]: loss 0.050165
[epoch16, step1276]: loss 0.050843
[epoch16, step1277]: loss 0.051245
[epoch16, step1278]: loss 0.053056
[epoch16, step1279]: loss 0.050697
[epoch16, step1280]: loss 0.053438
[epoch16, step1281]: loss 0.050064
[epoch16, step1282]: loss 0.052057
[epoch16, step1283]: loss 0.052569
[epoch16, step1284]: loss 0.048542
[epoch16, step1285]: loss 0.051279
[epoch16, step1286]: loss 0.050590
[epoch16, step1287]: loss 0.052448
[epoch16, step1288]: loss 0.050807
[epoch16, step1289]: loss 0.053133
[epoch16, step1290]: loss 0.050252
[epoch16, step1291]: loss 0.052066
[epoch16, step1292]: loss 0.052704
[epoch16, step1293]: loss 0.048392
[epoch16, step1294]: loss 0.050788
[epoch16, step1295]: loss 0.050847
[epoch16, step1296]: loss 0.052211
[epoch16, step1297]: loss 0.050115
[epoch16, step1298]: loss 0.053040
[epoch16, step1299]: loss 0.050399
[epoch16, step1300]: loss 0.052410
[epoch16, step1301]: loss 0.052607
[epoch16, step1302]: loss 0.049626
[epoch16, step1303]: loss 0.051264
[epoch16, step1304]: loss 0.050950
[epoch16, step1305]: loss 0.052553
[epoch16, step1306]: loss 0.050494
[epoch16, step1307]: loss 0.053083
[epoch16, step1308]: loss 0.050250
[epoch16, step1309]: loss 0.052253
[epoch16, step1310]: loss 0.052563
[epoch16, step1311]: loss 0.048844
[epoch16, step1312]: loss 0.051544
[epoch16, step1313]: loss 0.051072
[epoch16, step1314]: loss 0.052474
[epoch16, step1315]: loss 0.050342
[epoch16, step1316]: loss 0.053321
[epoch16, step1317]: loss 0.049849
[epoch16, step1318]: loss 0.052042
[epoch16, step1319]: loss 0.052407
[epoch16, step1320]: loss 0.049413
[epoch16, step1321]: loss 0.050811
[epoch16, step1322]: loss 0.050790
[epoch16, step1323]: loss 0.052393
[epoch16, step1324]: loss 0.050369
[epoch16, step1325]: loss 0.052833
[epoch16, step1326]: loss 0.050096
[epoch16, step1327]: loss 0.051845
[epoch16, step1328]: loss 0.052562
[epoch16, step1329]: loss 0.049318
[epoch16, step1330]: loss 0.051046
[epoch16, step1331]: loss 0.051064
[epoch16, step1332]: loss 0.052167
[epoch16, step1333]: loss 0.050797
[epoch16, step1334]: loss 0.053285
[epoch16, step1335]: loss 0.050474
[epoch16, step1336]: loss 0.052517
[epoch16, step1337]: loss 0.052478
[epoch16, step1338]: loss 0.049017
[epoch16, step1339]: loss 0.051677
[epoch16, step1340]: loss 0.051017
[epoch16, step1341]: loss 0.052472
[epoch16, step1342]: loss 0.050539
[epoch16, step1343]: loss 0.052873
[epoch16, step1344]: loss 0.049746
[epoch16, step1345]: loss 0.052021
[epoch16, step1346]: loss 0.052356
[epoch16, step1347]: loss 0.049296
[epoch16, step1348]: loss 0.050745
[epoch16, step1349]: loss 0.050769
[epoch16, step1350]: loss 0.052326
[epoch16, step1351]: loss 0.050652
[epoch16, step1352]: loss 0.052575
[epoch16, step1353]: loss 0.050233
[epoch16, step1354]: loss 0.052007
[epoch16, step1355]: loss 0.052743
[epoch16, step1356]: loss 0.049668
[epoch16, step1357]: loss 0.050749
[epoch16, step1358]: loss 0.050952
[epoch16, step1359]: loss 0.052202
[epoch16, step1360]: loss 0.050340
[epoch16, step1361]: loss 0.053243
[epoch16, step1362]: loss 0.050266
[epoch16, step1363]: loss 0.052330
[epoch16, step1364]: loss 0.052401
[epoch16, step1365]: loss 0.049414
[epoch16, step1366]: loss 0.050841
[epoch16, step1367]: loss 0.050408
[epoch16, step1368]: loss 0.052441
[epoch16, step1369]: loss 0.050548
[epoch16, step1370]: loss 0.052826
[epoch16, step1371]: loss 0.049966
[epoch16, step1372]: loss 0.051790
[epoch16, step1373]: loss 0.052516
[epoch16, step1374]: loss 0.049027
[epoch16, step1375]: loss 0.051025
[epoch16, step1376]: loss 0.050501
[epoch16, step1377]: loss 0.051993
[epoch16, step1378]: loss 0.050472
[epoch16, step1379]: loss 0.052654
[epoch16, step1380]: loss 0.049302
[epoch16, step1381]: loss 0.051818
[epoch16, step1382]: loss 0.052629
[epoch16, step1383]: loss 0.048600
[epoch16, step1384]: loss 0.050554
[epoch16, step1385]: loss 0.050518
[epoch16, step1386]: loss 0.051978
[epoch16, step1387]: loss 0.050690
[epoch16, step1388]: loss 0.052821
[epoch16, step1389]: loss 0.049295
[epoch16, step1390]: loss 0.052327
[epoch16, step1391]: loss 0.052378
[epoch16, step1392]: loss 0.049423
[epoch16, step1393]: loss 0.051106
[epoch16, step1394]: loss 0.050659
[epoch16, step1395]: loss 0.052362
[epoch16, step1396]: loss 0.050164
[epoch16, step1397]: loss 0.052546
[epoch16, step1398]: loss 0.049531
[epoch16, step1399]: loss 0.052068
[epoch16, step1400]: loss 0.052598
[epoch16, step1401]: loss 0.048470
[epoch16, step1402]: loss 0.050778
[epoch16, step1403]: loss 0.050191
[epoch16, step1404]: loss 0.051858
[epoch16, step1405]: loss 0.049962
[epoch16, step1406]: loss 0.052616
[epoch16, step1407]: loss 0.050415
[epoch16, step1408]: loss 0.051826
[epoch16, step1409]: loss 0.052336
[epoch16, step1410]: loss 0.048915
[epoch16, step1411]: loss 0.050505
[epoch16, step1412]: loss 0.051109
[epoch16, step1413]: loss 0.052484
[epoch16, step1414]: loss 0.050118
[epoch16, step1415]: loss 0.052881
[epoch16, step1416]: loss 0.049100
[epoch16, step1417]: loss 0.051891
[epoch16, step1418]: loss 0.052386
[epoch16, step1419]: loss 0.049112
[epoch16, step1420]: loss 0.050962
[epoch16, step1421]: loss 0.050516
[epoch16, step1422]: loss 0.052116
[epoch16, step1423]: loss 0.050048
[epoch16, step1424]: loss 0.052692
[epoch16, step1425]: loss 0.049098
[epoch16, step1426]: loss 0.051718
[epoch16, step1427]: loss 0.052463
[epoch16, step1428]: loss 0.049675
[epoch16, step1429]: loss 0.050449
[epoch16, step1430]: loss 0.050565
[epoch16, step1431]: loss 0.051957
[epoch16, step1432]: loss 0.050114
[epoch16, step1433]: loss 0.052686
[epoch16, step1434]: loss 0.049858
[epoch16, step1435]: loss 0.051856
[epoch16, step1436]: loss 0.052375
[epoch16, step1437]: loss 0.048881
[epoch16, step1438]: loss 0.050924
[epoch16, step1439]: loss 0.050982
[epoch16, step1440]: loss 0.051843
[epoch16, step1441]: loss 0.050594
[epoch16, step1442]: loss 0.052792
[epoch16, step1443]: loss 0.049933
[epoch16, step1444]: loss 0.051866
[epoch16, step1445]: loss 0.052369
[epoch16, step1446]: loss 0.048763
[epoch16, step1447]: loss 0.051212
[epoch16, step1448]: loss 0.050408
[epoch16, step1449]: loss 0.051867
[epoch16, step1450]: loss 0.050347
[epoch16, step1451]: loss 0.052570
[epoch16, step1452]: loss 0.049669
[epoch16, step1453]: loss 0.051905
[epoch16, step1454]: loss 0.052341
[epoch16, step1455]: loss 0.048891
[epoch16, step1456]: loss 0.050447
[epoch16, step1457]: loss 0.050417
[epoch16, step1458]: loss 0.051862
[epoch16, step1459]: loss 0.050413
[epoch16, step1460]: loss 0.052674
[epoch16, step1461]: loss 0.049373
[epoch16, step1462]: loss 0.051733
[epoch16, step1463]: loss 0.052427
[epoch16, step1464]: loss 0.048728
[epoch16, step1465]: loss 0.050568
[epoch16, step1466]: loss 0.050525
[epoch16, step1467]: loss 0.051850
[epoch16, step1468]: loss 0.050168
[epoch16, step1469]: loss 0.053098
[epoch16, step1470]: loss 0.049274
[epoch16, step1471]: loss 0.051947
[epoch16, step1472]: loss 0.052344
[epoch16, step1473]: loss 0.048409
[epoch16, step1474]: loss 0.050867
[epoch16, step1475]: loss 0.050181
[epoch16, step1476]: loss 0.052232
[epoch16, step1477]: loss 0.050225
[epoch16, step1478]: loss 0.052588
[epoch16, step1479]: loss 0.049295
[epoch16, step1480]: loss 0.051630
[epoch16, step1481]: loss 0.051951
[epoch16, step1482]: loss 0.048735
[epoch16, step1483]: loss 0.050635
[epoch16, step1484]: loss 0.050458
[epoch16, step1485]: loss 0.051777
[epoch16, step1486]: loss 0.049621
[epoch16, step1487]: loss 0.052339
[epoch16, step1488]: loss 0.049584
[epoch16, step1489]: loss 0.051497
[epoch16, step1490]: loss 0.052118
[epoch16, step1491]: loss 0.049311
[epoch16, step1492]: loss 0.050592
[epoch16, step1493]: loss 0.050845
[epoch16, step1494]: loss 0.052104
[epoch16, step1495]: loss 0.050438
[epoch16, step1496]: loss 0.052501
[epoch16, step1497]: loss 0.049376
[epoch16, step1498]: loss 0.051831
[epoch16, step1499]: loss 0.052025
[epoch16, step1500]: loss 0.048928
[epoch16, step1501]: loss 0.050691
[epoch16, step1502]: loss 0.050136
[epoch16, step1503]: loss 0.052039
[epoch16, step1504]: loss 0.049969
[epoch16, step1505]: loss 0.052579
[epoch16, step1506]: loss 0.049015
[epoch16, step1507]: loss 0.051563
[epoch16, step1508]: loss 0.052383
[epoch16, step1509]: loss 0.048924
[epoch16, step1510]: loss 0.050386
[epoch16, step1511]: loss 0.050384
[epoch16, step1512]: loss 0.051566
[epoch16, step1513]: loss 0.049579
[epoch16, step1514]: loss 0.052383
[epoch16, step1515]: loss 0.049792
[epoch16, step1516]: loss 0.051431

[epoch16]: avg loss 0.049650

[epoch17, step1]: loss 0.050487
[epoch17, step2]: loss 0.053088
[epoch17, step3]: loss 0.052905
[epoch17, step4]: loss 0.049295
[epoch17, step5]: loss 0.052376
[epoch17, step6]: loss 0.053037
[epoch17, step7]: loss 0.048179
[epoch17, step8]: loss 0.052924
[epoch17, step9]: loss 0.048519
[epoch17, step10]: loss 0.051043
[epoch17, step11]: loss 0.052586
[epoch17, step12]: loss 0.052213
[epoch17, step13]: loss 0.048692
[epoch17, step14]: loss 0.051943
[epoch17, step15]: loss 0.052021
[epoch17, step16]: loss 0.048368
[epoch17, step17]: loss 0.052692
[epoch17, step18]: loss 0.048958
[epoch17, step19]: loss 0.051012
[epoch17, step20]: loss 0.052550
[epoch17, step21]: loss 0.052338
[epoch17, step22]: loss 0.049290
[epoch17, step23]: loss 0.051716
[epoch17, step24]: loss 0.052078
[epoch17, step25]: loss 0.048272
[epoch17, step26]: loss 0.052524
[epoch17, step27]: loss 0.048662
[epoch17, step28]: loss 0.051556
[epoch17, step29]: loss 0.052146
[epoch17, step30]: loss 0.052643
[epoch17, step31]: loss 0.048989
[epoch17, step32]: loss 0.051861
[epoch17, step33]: loss 0.052618
[epoch17, step34]: loss 0.048646
[epoch17, step35]: loss 0.052552
[epoch17, step36]: loss 0.048599
[epoch17, step37]: loss 0.051022
[epoch17, step38]: loss 0.052023
[epoch17, step39]: loss 0.052162
[epoch17, step40]: loss 0.048787
[epoch17, step41]: loss 0.051551
[epoch17, step42]: loss 0.052147
[epoch17, step43]: loss 0.048328
[epoch17, step44]: loss 0.052608
[epoch17, step45]: loss 0.048752
[epoch17, step46]: loss 0.050885
[epoch17, step47]: loss 0.052264
[epoch17, step48]: loss 0.052093
[epoch17, step49]: loss 0.048036
[epoch17, step50]: loss 0.052048
[epoch17, step51]: loss 0.051890
[epoch17, step52]: loss 0.048911
[epoch17, step53]: loss 0.052998
[epoch17, step54]: loss 0.048241
[epoch17, step55]: loss 0.051288
[epoch17, step56]: loss 0.052192
[epoch17, step57]: loss 0.052423
[epoch17, step58]: loss 0.048916
[epoch17, step59]: loss 0.051440
[epoch17, step60]: loss 0.052250
[epoch17, step61]: loss 0.047986
[epoch17, step62]: loss 0.052247
[epoch17, step63]: loss 0.048287
[epoch17, step64]: loss 0.050839
[epoch17, step65]: loss 0.052024
[epoch17, step66]: loss 0.052114
[epoch17, step67]: loss 0.049200
[epoch17, step68]: loss 0.051670
[epoch17, step69]: loss 0.051896
[epoch17, step70]: loss 0.048174
[epoch17, step71]: loss 0.052270
[epoch17, step72]: loss 0.048465
[epoch17, step73]: loss 0.050707
[epoch17, step74]: loss 0.052115
[epoch17, step75]: loss 0.052095
[epoch17, step76]: loss 0.049561
[epoch17, step77]: loss 0.051947
[epoch17, step78]: loss 0.051905
[epoch17, step79]: loss 0.048625
[epoch17, step80]: loss 0.052754
[epoch17, step81]: loss 0.048678
[epoch17, step82]: loss 0.051232
[epoch17, step83]: loss 0.051815
[epoch17, step84]: loss 0.052346
[epoch17, step85]: loss 0.048753
[epoch17, step86]: loss 0.051565
[epoch17, step87]: loss 0.052588
[epoch17, step88]: loss 0.048297
[epoch17, step89]: loss 0.052258
[epoch17, step90]: loss 0.048942
[epoch17, step91]: loss 0.050766
[epoch17, step92]: loss 0.051975
[epoch17, step93]: loss 0.052000
[epoch17, step94]: loss 0.049024
[epoch17, step95]: loss 0.051662
[epoch17, step96]: loss 0.051835
[epoch17, step97]: loss 0.048540
[epoch17, step98]: loss 0.052346
[epoch17, step99]: loss 0.048629
[epoch17, step100]: loss 0.050466
[epoch17, step101]: loss 0.052208
[epoch17, step102]: loss 0.052151
[epoch17, step103]: loss 0.049102
[epoch17, step104]: loss 0.051875
[epoch17, step105]: loss 0.051916
[epoch17, step106]: loss 0.048687
[epoch17, step107]: loss 0.052605
[epoch17, step108]: loss 0.048678
[epoch17, step109]: loss 0.050864
[epoch17, step110]: loss 0.052185
[epoch17, step111]: loss 0.052032
[epoch17, step112]: loss 0.049311
[epoch17, step113]: loss 0.051696
[epoch17, step114]: loss 0.051953
[epoch17, step115]: loss 0.048254
[epoch17, step116]: loss 0.052404
[epoch17, step117]: loss 0.048278
[epoch17, step118]: loss 0.051170
[epoch17, step119]: loss 0.052017
[epoch17, step120]: loss 0.051992
[epoch17, step121]: loss 0.048781
[epoch17, step122]: loss 0.051419
[epoch17, step123]: loss 0.051973
[epoch17, step124]: loss 0.048478
[epoch17, step125]: loss 0.052411
[epoch17, step126]: loss 0.048630
[epoch17, step127]: loss 0.050490
[epoch17, step128]: loss 0.052171
[epoch17, step129]: loss 0.051845
[epoch17, step130]: loss 0.048529
[epoch17, step131]: loss 0.051736
[epoch17, step132]: loss 0.051912
[epoch17, step133]: loss 0.047964
[epoch17, step134]: loss 0.052854
[epoch17, step135]: loss 0.048651
[epoch17, step136]: loss 0.051120
[epoch17, step137]: loss 0.052188
[epoch17, step138]: loss 0.051964
[epoch17, step139]: loss 0.048838
[epoch17, step140]: loss 0.051870
[epoch17, step141]: loss 0.051839
[epoch17, step142]: loss 0.048136
[epoch17, step143]: loss 0.052247
[epoch17, step144]: loss 0.048808
[epoch17, step145]: loss 0.050945
[epoch17, step146]: loss 0.052354
[epoch17, step147]: loss 0.052377
[epoch17, step148]: loss 0.048902
[epoch17, step149]: loss 0.051460
[epoch17, step150]: loss 0.051686
[epoch17, step151]: loss 0.048122
[epoch17, step152]: loss 0.052596
[epoch17, step153]: loss 0.048451
[epoch17, step154]: loss 0.050861
[epoch17, step155]: loss 0.051801
[epoch17, step156]: loss 0.052125
[epoch17, step157]: loss 0.048632
[epoch17, step158]: loss 0.051426
[epoch17, step159]: loss 0.052015
[epoch17, step160]: loss 0.048144
[epoch17, step161]: loss 0.052311
[epoch17, step162]: loss 0.048361
[epoch17, step163]: loss 0.050519
[epoch17, step164]: loss 0.051856
[epoch17, step165]: loss 0.051950
[epoch17, step166]: loss 0.048307
[epoch17, step167]: loss 0.051272
[epoch17, step168]: loss 0.051972
[epoch17, step169]: loss 0.047930
[epoch17, step170]: loss 0.052215
[epoch17, step171]: loss 0.048627
[epoch17, step172]: loss 0.050451
[epoch17, step173]: loss 0.052150
[epoch17, step174]: loss 0.051909
[epoch17, step175]: loss 0.048861
[epoch17, step176]: loss 0.051505
[epoch17, step177]: loss 0.051873
[epoch17, step178]: loss 0.047802
[epoch17, step179]: loss 0.051912
[epoch17, step180]: loss 0.048746
[epoch17, step181]: loss 0.050680
[epoch17, step182]: loss 0.051875
[epoch17, step183]: loss 0.052350
[epoch17, step184]: loss 0.048961
[epoch17, step185]: loss 0.051623
[epoch17, step186]: loss 0.051718
[epoch17, step187]: loss 0.048332
[epoch17, step188]: loss 0.052135
[epoch17, step189]: loss 0.048328
[epoch17, step190]: loss 0.050691
[epoch17, step191]: loss 0.051630
[epoch17, step192]: loss 0.052018
[epoch17, step193]: loss 0.048122
[epoch17, step194]: loss 0.051005
[epoch17, step195]: loss 0.051968
[epoch17, step196]: loss 0.047438
[epoch17, step197]: loss 0.052029
[epoch17, step198]: loss 0.047760
[epoch17, step199]: loss 0.050368
[epoch17, step200]: loss 0.051733
[epoch17, step201]: loss 0.052011
[epoch17, step202]: loss 0.048550
[epoch17, step203]: loss 0.051251
[epoch17, step204]: loss 0.051732
[epoch17, step205]: loss 0.047865
[epoch17, step206]: loss 0.051992
[epoch17, step207]: loss 0.048413
[epoch17, step208]: loss 0.050732
[epoch17, step209]: loss 0.051968
[epoch17, step210]: loss 0.052311
[epoch17, step211]: loss 0.049264
[epoch17, step212]: loss 0.051780
[epoch17, step213]: loss 0.051800
[epoch17, step214]: loss 0.048398
[epoch17, step215]: loss 0.052535
[epoch17, step216]: loss 0.048321
[epoch17, step217]: loss 0.050587
[epoch17, step218]: loss 0.051898
[epoch17, step219]: loss 0.051803
[epoch17, step220]: loss 0.049487
[epoch17, step221]: loss 0.051466
[epoch17, step222]: loss 0.051742
[epoch17, step223]: loss 0.047698
[epoch17, step224]: loss 0.052006
[epoch17, step225]: loss 0.048144
[epoch17, step226]: loss 0.050357
[epoch17, step227]: loss 0.051374
[epoch17, step228]: loss 0.052080
[epoch17, step229]: loss 0.048649
[epoch17, step230]: loss 0.051241
[epoch17, step231]: loss 0.051678
[epoch17, step232]: loss 0.047539
[epoch17, step233]: loss 0.051840
[epoch17, step234]: loss 0.048675
[epoch17, step235]: loss 0.050908
[epoch17, step236]: loss 0.051648
[epoch17, step237]: loss 0.052284
[epoch17, step238]: loss 0.048121
[epoch17, step239]: loss 0.051095
[epoch17, step240]: loss 0.051544
[epoch17, step241]: loss 0.048295
[epoch17, step242]: loss 0.052078
[epoch17, step243]: loss 0.048615
[epoch17, step244]: loss 0.050345
[epoch17, step245]: loss 0.051540
[epoch17, step246]: loss 0.051823
[epoch17, step247]: loss 0.049042
[epoch17, step248]: loss 0.051065
[epoch17, step249]: loss 0.051441
[epoch17, step250]: loss 0.047435
[epoch17, step251]: loss 0.052111
[epoch17, step252]: loss 0.048358
[epoch17, step253]: loss 0.050283
[epoch17, step254]: loss 0.051515
[epoch17, step255]: loss 0.051738
[epoch17, step256]: loss 0.048826
[epoch17, step257]: loss 0.051086
[epoch17, step258]: loss 0.051644
[epoch17, step259]: loss 0.047302
[epoch17, step260]: loss 0.051766
[epoch17, step261]: loss 0.048570
[epoch17, step262]: loss 0.050468
[epoch17, step263]: loss 0.051540
[epoch17, step264]: loss 0.051863
[epoch17, step265]: loss 0.048939
[epoch17, step266]: loss 0.051410
[epoch17, step267]: loss 0.051387
[epoch17, step268]: loss 0.047971
[epoch17, step269]: loss 0.052169
[epoch17, step270]: loss 0.047897
[epoch17, step271]: loss 0.050430
[epoch17, step272]: loss 0.051669
[epoch17, step273]: loss 0.051670
[epoch17, step274]: loss 0.048612
[epoch17, step275]: loss 0.051160
[epoch17, step276]: loss 0.051566
[epoch17, step277]: loss 0.048000
[epoch17, step278]: loss 0.051918
[epoch17, step279]: loss 0.047896
[epoch17, step280]: loss 0.050529
[epoch17, step281]: loss 0.051391
[epoch17, step282]: loss 0.051793
[epoch17, step283]: loss 0.048518
[epoch17, step284]: loss 0.050889
[epoch17, step285]: loss 0.051699
[epoch17, step286]: loss 0.048029
[epoch17, step287]: loss 0.051951
[epoch17, step288]: loss 0.048253
[epoch17, step289]: loss 0.050530
[epoch17, step290]: loss 0.052027
[epoch17, step291]: loss 0.052159
[epoch17, step292]: loss 0.048302
[epoch17, step293]: loss 0.051355
[epoch17, step294]: loss 0.051354
[epoch17, step295]: loss 0.047529
[epoch17, step296]: loss 0.052511
[epoch17, step297]: loss 0.048229
[epoch17, step298]: loss 0.050501
[epoch17, step299]: loss 0.051423
[epoch17, step300]: loss 0.051761
[epoch17, step301]: loss 0.049099
[epoch17, step302]: loss 0.051274
[epoch17, step303]: loss 0.051688
[epoch17, step304]: loss 0.046998
[epoch17, step305]: loss 0.051809
[epoch17, step306]: loss 0.048102
[epoch17, step307]: loss 0.050019
[epoch17, step308]: loss 0.051866
[epoch17, step309]: loss 0.051694
[epoch17, step310]: loss 0.048862
[epoch17, step311]: loss 0.051073
[epoch17, step312]: loss 0.051514
[epoch17, step313]: loss 0.048378
[epoch17, step314]: loss 0.051794
[epoch17, step315]: loss 0.049214
[epoch17, step316]: loss 0.050544
[epoch17, step317]: loss 0.051646
[epoch17, step318]: loss 0.052012
[epoch17, step319]: loss 0.048465
[epoch17, step320]: loss 0.050880
[epoch17, step321]: loss 0.051402
[epoch17, step322]: loss 0.048185
[epoch17, step323]: loss 0.051780
[epoch17, step324]: loss 0.048446
[epoch17, step325]: loss 0.050397
[epoch17, step326]: loss 0.051411
[epoch17, step327]: loss 0.051483
[epoch17, step328]: loss 0.048853
[epoch17, step329]: loss 0.050982
[epoch17, step330]: loss 0.051471
[epoch17, step331]: loss 0.047937
[epoch17, step332]: loss 0.051603
[epoch17, step333]: loss 0.048173
[epoch17, step334]: loss 0.050135
[epoch17, step335]: loss 0.051599
[epoch17, step336]: loss 0.051920
[epoch17, step337]: loss 0.048077
[epoch17, step338]: loss 0.050711
[epoch17, step339]: loss 0.051261
[epoch17, step340]: loss 0.048108
[epoch17, step341]: loss 0.051643
[epoch17, step342]: loss 0.047937
[epoch17, step343]: loss 0.050168
[epoch17, step344]: loss 0.051486
[epoch17, step345]: loss 0.051597
[epoch17, step346]: loss 0.048418
[epoch17, step347]: loss 0.051179
[epoch17, step348]: loss 0.051459
[epoch17, step349]: loss 0.048059
[epoch17, step350]: loss 0.052010
[epoch17, step351]: loss 0.047600
[epoch17, step352]: loss 0.050128
[epoch17, step353]: loss 0.051447
[epoch17, step354]: loss 0.051269
[epoch17, step355]: loss 0.048190
[epoch17, step356]: loss 0.051142
[epoch17, step357]: loss 0.051352
[epoch17, step358]: loss 0.047332
[epoch17, step359]: loss 0.052035
[epoch17, step360]: loss 0.047238
[epoch17, step361]: loss 0.049927
[epoch17, step362]: loss 0.051638
[epoch17, step363]: loss 0.051573
[epoch17, step364]: loss 0.048638
[epoch17, step365]: loss 0.050832
[epoch17, step366]: loss 0.051463
[epoch17, step367]: loss 0.048204
[epoch17, step368]: loss 0.051566
[epoch17, step369]: loss 0.048378
[epoch17, step370]: loss 0.050545
[epoch17, step371]: loss 0.051507
[epoch17, step372]: loss 0.051758
[epoch17, step373]: loss 0.048021
[epoch17, step374]: loss 0.050561
[epoch17, step375]: loss 0.051502
[epoch17, step376]: loss 0.047072
[epoch17, step377]: loss 0.051748
[epoch17, step378]: loss 0.048397
[epoch17, step379]: loss 0.050197
[epoch17, step380]: loss 0.051549
[epoch17, step381]: loss 0.051395
[epoch17, step382]: loss 0.049030
[epoch17, step383]: loss 0.050462
[epoch17, step384]: loss 0.050957
[epoch17, step385]: loss 0.046935
[epoch17, step386]: loss 0.051679
[epoch17, step387]: loss 0.047665
[epoch17, step388]: loss 0.050021
[epoch17, step389]: loss 0.051395
[epoch17, step390]: loss 0.051607
[epoch17, step391]: loss 0.047786
[epoch17, step392]: loss 0.050993
[epoch17, step393]: loss 0.051309
[epoch17, step394]: loss 0.048145
[epoch17, step395]: loss 0.051599
[epoch17, step396]: loss 0.048355
[epoch17, step397]: loss 0.050272
[epoch17, step398]: loss 0.051273
[epoch17, step399]: loss 0.051685
[epoch17, step400]: loss 0.047670
[epoch17, step401]: loss 0.050694
[epoch17, step402]: loss 0.051165
[epoch17, step403]: loss 0.047141
[epoch17, step404]: loss 0.051730
[epoch17, step405]: loss 0.047740
[epoch17, step406]: loss 0.050043
[epoch17, step407]: loss 0.051175
[epoch17, step408]: loss 0.051394
[epoch17, step409]: loss 0.048492
[epoch17, step410]: loss 0.050799
[epoch17, step411]: loss 0.051031
[epoch17, step412]: loss 0.046594
[epoch17, step413]: loss 0.051470
[epoch17, step414]: loss 0.047869
[epoch17, step415]: loss 0.050185
[epoch17, step416]: loss 0.051093
[epoch17, step417]: loss 0.051453
[epoch17, step418]: loss 0.047898
[epoch17, step419]: loss 0.050501
[epoch17, step420]: loss 0.051185
[epoch17, step421]: loss 0.047518
[epoch17, step422]: loss 0.051488
[epoch17, step423]: loss 0.047965
[epoch17, step424]: loss 0.049930
[epoch17, step425]: loss 0.051426
[epoch17, step426]: loss 0.051683
[epoch17, step427]: loss 0.048725
[epoch17, step428]: loss 0.050856
[epoch17, step429]: loss 0.051333
[epoch17, step430]: loss 0.047275
[epoch17, step431]: loss 0.051816
[epoch17, step432]: loss 0.047555
[epoch17, step433]: loss 0.050205
[epoch17, step434]: loss 0.051323
[epoch17, step435]: loss 0.051530
[epoch17, step436]: loss 0.048454
[epoch17, step437]: loss 0.050742
[epoch17, step438]: loss 0.051375
[epoch17, step439]: loss 0.047991
[epoch17, step440]: loss 0.051431
[epoch17, step441]: loss 0.048131
[epoch17, step442]: loss 0.049659
[epoch17, step443]: loss 0.051212
[epoch17, step444]: loss 0.051390
[epoch17, step445]: loss 0.048604
[epoch17, step446]: loss 0.050697
[epoch17, step447]: loss 0.051412
[epoch17, step448]: loss 0.046924
[epoch17, step449]: loss 0.051477
[epoch17, step450]: loss 0.047939
[epoch17, step451]: loss 0.049929
[epoch17, step452]: loss 0.051016
[epoch17, step453]: loss 0.051661
[epoch17, step454]: loss 0.048456
[epoch17, step455]: loss 0.051017
[epoch17, step456]: loss 0.050944
[epoch17, step457]: loss 0.048145
[epoch17, step458]: loss 0.051810
[epoch17, step459]: loss 0.047974
[epoch17, step460]: loss 0.049875
[epoch17, step461]: loss 0.051842
[epoch17, step462]: loss 0.051164
[epoch17, step463]: loss 0.048680
[epoch17, step464]: loss 0.050800
[epoch17, step465]: loss 0.051566
[epoch17, step466]: loss 0.047112
[epoch17, step467]: loss 0.051456
[epoch17, step468]: loss 0.047827
[epoch17, step469]: loss 0.049851
[epoch17, step470]: loss 0.051227
[epoch17, step471]: loss 0.051259
[epoch17, step472]: loss 0.048958
[epoch17, step473]: loss 0.050592
[epoch17, step474]: loss 0.051204
[epoch17, step475]: loss 0.047987
[epoch17, step476]: loss 0.051787
[epoch17, step477]: loss 0.048327
[epoch17, step478]: loss 0.050381
[epoch17, step479]: loss 0.051128
[epoch17, step480]: loss 0.051385
[epoch17, step481]: loss 0.048365
[epoch17, step482]: loss 0.050335
[epoch17, step483]: loss 0.051222
[epoch17, step484]: loss 0.046720
[epoch17, step485]: loss 0.051463
[epoch17, step486]: loss 0.047886
[epoch17, step487]: loss 0.049463
[epoch17, step488]: loss 0.051356
[epoch17, step489]: loss 0.051182
[epoch17, step490]: loss 0.048528
[epoch17, step491]: loss 0.050426
[epoch17, step492]: loss 0.050864
[epoch17, step493]: loss 0.046752
[epoch17, step494]: loss 0.051230
[epoch17, step495]: loss 0.048105
[epoch17, step496]: loss 0.049654
[epoch17, step497]: loss 0.051353
[epoch17, step498]: loss 0.051189
[epoch17, step499]: loss 0.048549
[epoch17, step500]: loss 0.050769
[epoch17, step501]: loss 0.050845
[epoch17, step502]: loss 0.047499
[epoch17, step503]: loss 0.052144
[epoch17, step504]: loss 0.047874
[epoch17, step505]: loss 0.049622
[epoch17, step506]: loss 0.051385
[epoch17, step507]: loss 0.051221
[epoch17, step508]: loss 0.048688
[epoch17, step509]: loss 0.050572
[epoch17, step510]: loss 0.051254
[epoch17, step511]: loss 0.047835
[epoch17, step512]: loss 0.051605
[epoch17, step513]: loss 0.047715
[epoch17, step514]: loss 0.049711
[epoch17, step515]: loss 0.051165
[epoch17, step516]: loss 0.051441
[epoch17, step517]: loss 0.048696
[epoch17, step518]: loss 0.050697
[epoch17, step519]: loss 0.051127
[epoch17, step520]: loss 0.046950
[epoch17, step521]: loss 0.051559
[epoch17, step522]: loss 0.047377
[epoch17, step523]: loss 0.049949
[epoch17, step524]: loss 0.050909
[epoch17, step525]: loss 0.051543
[epoch17, step526]: loss 0.047779
[epoch17, step527]: loss 0.050376
[epoch17, step528]: loss 0.051089
[epoch17, step529]: loss 0.047120
[epoch17, step530]: loss 0.051524
[epoch17, step531]: loss 0.047379
[epoch17, step532]: loss 0.049449
[epoch17, step533]: loss 0.051398
[epoch17, step534]: loss 0.051164
[epoch17, step535]: loss 0.048393
[epoch17, step536]: loss 0.050473
[epoch17, step537]: loss 0.050904
[epoch17, step538]: loss 0.047616
[epoch17, step539]: loss 0.051202
[epoch17, step540]: loss 0.047795
[epoch17, step541]: loss 0.049602
[epoch17, step542]: loss 0.051145
[epoch17, step543]: loss 0.050958
[epoch17, step544]: loss 0.047408
[epoch17, step545]: loss 0.050148
[epoch17, step546]: loss 0.050990
[epoch17, step547]: loss 0.047627
[epoch17, step548]: loss 0.051273
[epoch17, step549]: loss 0.047949
[epoch17, step550]: loss 0.049795
[epoch17, step551]: loss 0.050844
[epoch17, step552]: loss 0.051157
[epoch17, step553]: loss 0.048468
[epoch17, step554]: loss 0.050446
[epoch17, step555]: loss 0.050765
[epoch17, step556]: loss 0.046939
[epoch17, step557]: loss 0.051153
[epoch17, step558]: loss 0.047705
[epoch17, step559]: loss 0.049505
[epoch17, step560]: loss 0.050928
[epoch17, step561]: loss 0.051100
[epoch17, step562]: loss 0.047785
[epoch17, step563]: loss 0.044473
[epoch17, step564]: loss 0.042996
[epoch17, step565]: loss 0.037993
[epoch17, step566]: loss 0.045930
[epoch17, step567]: loss 0.037981
[epoch17, step568]: loss 0.038088
[epoch17, step569]: loss 0.039402
[epoch17, step570]: loss 0.043670
[epoch17, step571]: loss 0.034615
[epoch17, step572]: loss 0.037908
[epoch17, step573]: loss 0.042523
[epoch17, step574]: loss 0.043692
[epoch17, step575]: loss 0.034861
[epoch17, step576]: loss 0.035729
[epoch17, step577]: loss 0.036852
[epoch17, step578]: loss 0.034338
[epoch17, step579]: loss 0.037759
[epoch17, step580]: loss 0.037352
[epoch17, step581]: loss 0.038908
[epoch17, step582]: loss 0.037940
[epoch17, step583]: loss 0.036022
[epoch17, step584]: loss 0.036337
[epoch17, step585]: loss 0.041521
[epoch17, step586]: loss 0.035789
[epoch17, step587]: loss 0.035718
[epoch17, step588]: loss 0.036848
[epoch17, step589]: loss 0.041958
[epoch17, step590]: loss 0.036008
[epoch17, step591]: loss 0.034173
[epoch17, step592]: loss 0.040485
[epoch17, step593]: loss 0.040799
[epoch17, step594]: loss 0.035207
[epoch17, step595]: loss 0.035389
[epoch17, step596]: loss 0.037796
[epoch17, step597]: loss 0.040196
[epoch17, step598]: loss 0.036641
[epoch17, step599]: loss 0.034769
[epoch17, step600]: loss 0.035882
[epoch17, step601]: loss 0.033174
[epoch17, step602]: loss 0.038987
[epoch17, step603]: loss 0.036707
[epoch17, step604]: loss 0.036833
[epoch17, step605]: loss 0.034140
[epoch17, step606]: loss 0.037318
[epoch17, step607]: loss 0.040742
[epoch17, step608]: loss 0.033013
[epoch17, step609]: loss 0.038983
[epoch17, step610]: loss 0.037589
[epoch17, step611]: loss 0.040695
[epoch17, step612]: loss 0.038144
[epoch17, step613]: loss 0.035018
[epoch17, step614]: loss 0.038107
[epoch17, step615]: loss 0.040019
[epoch17, step616]: loss 0.033872
[epoch17, step617]: loss 0.035361
[epoch17, step618]: loss 0.039714
[epoch17, step619]: loss 0.036658
[epoch17, step620]: loss 0.032961
[epoch17, step621]: loss 0.034532
[epoch17, step622]: loss 0.035166
[epoch17, step623]: loss 0.037611
[epoch17, step624]: loss 0.039608
[epoch17, step625]: loss 0.033845
[epoch17, step626]: loss 0.041157
[epoch17, step627]: loss 0.039175
[epoch17, step628]: loss 0.039055
[epoch17, step629]: loss 0.027249
[epoch17, step630]: loss 0.034169
[epoch17, step631]: loss 0.040826
[epoch17, step632]: loss 0.036579
[epoch17, step633]: loss 0.034747
[epoch17, step634]: loss 0.039839
[epoch17, step635]: loss 0.036712
[epoch17, step636]: loss 0.031231
[epoch17, step637]: loss 0.041249
[epoch17, step638]: loss 0.039532
[epoch17, step639]: loss 0.031997
[epoch17, step640]: loss 0.042588
[epoch17, step641]: loss 0.039267
[epoch17, step642]: loss 0.034031
[epoch17, step643]: loss 0.039374
[epoch17, step644]: loss 0.037014
[epoch17, step645]: loss 0.031511
[epoch17, step646]: loss 0.037809
[epoch17, step647]: loss 0.032125
[epoch17, step648]: loss 0.039384
[epoch17, step649]: loss 0.040455
[epoch17, step650]: loss 0.036631
[epoch17, step651]: loss 0.037292
[epoch17, step652]: loss 0.041963
[epoch17, step653]: loss 0.042121
[epoch17, step654]: loss 0.036783
[epoch17, step655]: loss 0.034012
[epoch17, step656]: loss 0.037001
[epoch17, step657]: loss 0.041332
[epoch17, step658]: loss 0.035442
[epoch17, step659]: loss 0.035294
[epoch17, step660]: loss 0.036471
[epoch17, step661]: loss 0.039815
[epoch17, step662]: loss 0.032879
[epoch17, step663]: loss 0.033407
[epoch17, step664]: loss 0.035896
[epoch17, step665]: loss 0.042233
[epoch17, step666]: loss 0.035162
[epoch17, step667]: loss 0.038847
[epoch17, step668]: loss 0.037679
[epoch17, step669]: loss 0.034938
[epoch17, step670]: loss 0.039205
[epoch17, step671]: loss 0.035039
[epoch17, step672]: loss 0.040250
[epoch17, step673]: loss 0.037262
[epoch17, step674]: loss 0.033311
[epoch17, step675]: loss 0.034872
[epoch17, step676]: loss 0.038391
[epoch17, step677]: loss 0.035846
[epoch17, step678]: loss 0.032067
[epoch17, step679]: loss 0.036050
[epoch17, step680]: loss 0.038762
[epoch17, step681]: loss 0.031711
[epoch17, step682]: loss 0.035871
[epoch17, step683]: loss 0.037656
[epoch17, step684]: loss 0.034078
[epoch17, step685]: loss 0.034402
[epoch17, step686]: loss 0.035866
[epoch17, step687]: loss 0.036961
[epoch17, step688]: loss 0.036052
[epoch17, step689]: loss 0.033878
[epoch17, step690]: loss 0.038771
[epoch17, step691]: loss 0.039283
[epoch17, step692]: loss 0.036760
[epoch17, step693]: loss 0.039223
[epoch17, step694]: loss 0.031824
[epoch17, step695]: loss 0.036708
[epoch17, step696]: loss 0.035318
[epoch17, step697]: loss 0.038777
[epoch17, step698]: loss 0.035500
[epoch17, step699]: loss 0.034880
[epoch17, step700]: loss 0.038062
[epoch17, step701]: loss 0.038481
[epoch17, step702]: loss 0.033011
[epoch17, step703]: loss 0.038777
[epoch17, step704]: loss 0.038663
[epoch17, step705]: loss 0.034113
[epoch17, step706]: loss 0.034219
[epoch17, step707]: loss 0.035171
[epoch17, step708]: loss 0.037545
[epoch17, step709]: loss 0.037023
[epoch17, step710]: loss 0.036038
[epoch17, step711]: loss 0.037819
[epoch17, step712]: loss 0.034950
[epoch17, step713]: loss 0.036317
[epoch17, step714]: loss 0.034776
[epoch17, step715]: loss 0.033907
[epoch17, step716]: loss 0.038261
[epoch17, step717]: loss 0.033674
[epoch17, step718]: loss 0.036932
[epoch17, step719]: loss 0.043636
[epoch17, step720]: loss 0.034035
[epoch17, step721]: loss 0.034542
[epoch17, step722]: loss 0.042306
[epoch17, step723]: loss 0.036999
[epoch17, step724]: loss 0.035942
[epoch17, step725]: loss 0.040261
[epoch17, step726]: loss 0.030575
[epoch17, step727]: loss 0.037055
[epoch17, step728]: loss 0.038412
[epoch17, step729]: loss 0.031196
[epoch17, step730]: loss 0.035644
[epoch17, step731]: loss 0.039208
[epoch17, step732]: loss 0.036305
[epoch17, step733]: loss 0.031903
[epoch17, step734]: loss 0.033005
[epoch17, step735]: loss 0.036717
[epoch17, step736]: loss 0.035320
[epoch17, step737]: loss 0.035202
[epoch17, step738]: loss 0.031335
[epoch17, step739]: loss 0.041236
[epoch17, step740]: loss 0.039612
[epoch17, step741]: loss 0.037176
[epoch17, step742]: loss 0.036522
[epoch17, step743]: loss 0.035079
[epoch17, step744]: loss 0.035645
[epoch17, step745]: loss 0.036340
[epoch17, step746]: loss 0.037651
[epoch17, step747]: loss 0.037760
[epoch17, step748]: loss 0.035017
[epoch17, step749]: loss 0.041565
[epoch17, step750]: loss 0.039983
[epoch17, step751]: loss 0.032625
[epoch17, step752]: loss 0.034175
[epoch17, step753]: loss 0.034646
[epoch17, step754]: loss 0.036984
[epoch17, step755]: loss 0.038617
[epoch17, step756]: loss 0.031726
[epoch17, step757]: loss 0.033057
[epoch17, step758]: loss 0.038053
[epoch17, step759]: loss 0.032312
[epoch17, step760]: loss 0.036619
[epoch17, step761]: loss 0.037094
[epoch17, step762]: loss 0.031823
[epoch17, step763]: loss 0.035237
[epoch17, step764]: loss 0.035913
[epoch17, step765]: loss 0.035068
[epoch17, step766]: loss 0.033655
[epoch17, step767]: loss 0.038903
[epoch17, step768]: loss 0.033712
[epoch17, step769]: loss 0.038060
[epoch17, step770]: loss 0.040738
[epoch17, step771]: loss 0.032296
[epoch17, step772]: loss 0.037750
[epoch17, step773]: loss 0.037116
[epoch17, step774]: loss 0.035322
[epoch17, step775]: loss 0.036373
[epoch17, step776]: loss 0.037580
[epoch17, step777]: loss 0.033784
[epoch17, step778]: loss 0.041245
[epoch17, step779]: loss 0.034796
[epoch17, step780]: loss 0.033948
[epoch17, step781]: loss 0.039567
[epoch17, step782]: loss 0.037098
[epoch17, step783]: loss 0.031941
[epoch17, step784]: loss 0.034526
[epoch17, step785]: loss 0.035562
[epoch17, step786]: loss 0.035420
[epoch17, step787]: loss 0.038136
[epoch17, step788]: loss 0.036459
[epoch17, step789]: loss 0.037088
[epoch17, step790]: loss 0.032549
[epoch17, step791]: loss 0.039222
[epoch17, step792]: loss 0.037472
[epoch17, step793]: loss 0.039245
[epoch17, step794]: loss 0.032780
[epoch17, step795]: loss 0.036556
[epoch17, step796]: loss 0.037352
[epoch17, step797]: loss 0.036712
[epoch17, step798]: loss 0.036068
[epoch17, step799]: loss 0.032977
[epoch17, step800]: loss 0.037587
[epoch17, step801]: loss 0.036748
[epoch17, step802]: loss 0.034181
[epoch17, step803]: loss 0.035816
[epoch17, step804]: loss 0.039446
[epoch17, step805]: loss 0.038217
[epoch17, step806]: loss 0.033652
[epoch17, step807]: loss 0.034719
[epoch17, step808]: loss 0.037816
[epoch17, step809]: loss 0.033425
[epoch17, step810]: loss 0.033488
[epoch17, step811]: loss 0.037308
[epoch17, step812]: loss 0.037074
[epoch17, step813]: loss 0.033650
[epoch17, step814]: loss 0.037206
[epoch17, step815]: loss 0.036089
[epoch17, step816]: loss 0.035513
[epoch17, step817]: loss 0.033792
[epoch17, step818]: loss 0.033531
[epoch17, step819]: loss 0.038910
[epoch17, step820]: loss 0.032844
[epoch17, step821]: loss 0.031844
[epoch17, step822]: loss 0.041386
[epoch17, step823]: loss 0.033229
[epoch17, step824]: loss 0.038418
[epoch17, step825]: loss 0.037330
[epoch17, step826]: loss 0.031707
[epoch17, step827]: loss 0.035738
[epoch17, step828]: loss 0.039545
[epoch17, step829]: loss 0.036386
[epoch17, step830]: loss 0.029570
[epoch17, step831]: loss 0.035172
[epoch17, step832]: loss 0.036614
[epoch17, step833]: loss 0.039828
[epoch17, step834]: loss 0.036493
[epoch17, step835]: loss 0.033246
[epoch17, step836]: loss 0.035656
[epoch17, step837]: loss 0.034463
[epoch17, step838]: loss 0.039562
[epoch17, step839]: loss 0.038701
[epoch17, step840]: loss 0.031306
[epoch17, step841]: loss 0.035511
[epoch17, step842]: loss 0.038330
[epoch17, step843]: loss 0.037705
[epoch17, step844]: loss 0.038069
[epoch17, step845]: loss 0.033829
[epoch17, step846]: loss 0.041666
[epoch17, step847]: loss 0.037617
[epoch17, step848]: loss 0.029940
[epoch17, step849]: loss 0.035336
[epoch17, step850]: loss 0.036351
[epoch17, step851]: loss 0.035312
[epoch17, step852]: loss 0.034668
[epoch17, step853]: loss 0.041391
[epoch17, step854]: loss 0.036132
[epoch17, step855]: loss 0.036205
[epoch17, step856]: loss 0.030999
[epoch17, step857]: loss 0.038154
[epoch17, step858]: loss 0.036769
[epoch17, step859]: loss 0.033204
[epoch17, step860]: loss 0.036429
[epoch17, step861]: loss 0.034755
[epoch17, step862]: loss 0.031806
[epoch17, step863]: loss 0.034255
[epoch17, step864]: loss 0.039870
[epoch17, step865]: loss 0.035525
[epoch17, step866]: loss 0.037592
[epoch17, step867]: loss 0.036123
[epoch17, step868]: loss 0.038280
[epoch17, step869]: loss 0.033220
[epoch17, step870]: loss 0.038560
[epoch17, step871]: loss 0.037219
[epoch17, step872]: loss 0.037541
[epoch17, step873]: loss 0.034173
[epoch17, step874]: loss 0.034974
[epoch17, step875]: loss 0.039545
[epoch17, step876]: loss 0.037534
[epoch17, step877]: loss 0.025331
[epoch17, step878]: loss 0.033488
[epoch17, step879]: loss 0.037814
[epoch17, step880]: loss 0.035070
[epoch17, step881]: loss 0.035886
[epoch17, step882]: loss 0.033361
[epoch17, step883]: loss 0.034354
[epoch17, step884]: loss 0.041203
[epoch17, step885]: loss 0.040467
[epoch17, step886]: loss 0.040187
[epoch17, step887]: loss 0.039509
[epoch17, step888]: loss 0.034861
[epoch17, step889]: loss 0.036581
[epoch17, step890]: loss 0.036454
[epoch17, step891]: loss 0.035014
[epoch17, step892]: loss 0.034699
[epoch17, step893]: loss 0.037341
[epoch17, step894]: loss 0.037429
[epoch17, step895]: loss 0.031551
[epoch17, step896]: loss 0.038604
[epoch17, step897]: loss 0.039906
[epoch17, step898]: loss 0.034996
[epoch17, step899]: loss 0.033036
[epoch17, step900]: loss 0.037864
[epoch17, step901]: loss 0.038644
[epoch17, step902]: loss 0.033525
[epoch17, step903]: loss 0.038437
[epoch17, step904]: loss 0.037022
[epoch17, step905]: loss 0.035908
[epoch17, step906]: loss 0.030568
[epoch17, step907]: loss 0.037190
[epoch17, step908]: loss 0.036908
[epoch17, step909]: loss 0.035839
[epoch17, step910]: loss 0.031264
[epoch17, step911]: loss 0.033269
[epoch17, step912]: loss 0.036800
[epoch17, step913]: loss 0.036966
[epoch17, step914]: loss 0.041215
[epoch17, step915]: loss 0.033237
[epoch17, step916]: loss 0.035763
[epoch17, step917]: loss 0.036194
[epoch17, step918]: loss 0.040965
[epoch17, step919]: loss 0.033155
[epoch17, step920]: loss 0.040660
[epoch17, step921]: loss 0.033971
[epoch17, step922]: loss 0.033355
[epoch17, step923]: loss 0.037079
[epoch17, step924]: loss 0.031371
[epoch17, step925]: loss 0.035330
[epoch17, step926]: loss 0.036490
[epoch17, step927]: loss 0.038834
[epoch17, step928]: loss 0.034486
[epoch17, step929]: loss 0.037641
[epoch17, step930]: loss 0.036859
[epoch17, step931]: loss 0.039568
[epoch17, step932]: loss 0.031995
[epoch17, step933]: loss 0.037862
[epoch17, step934]: loss 0.036741
[epoch17, step935]: loss 0.033976
[epoch17, step936]: loss 0.032418
[epoch17, step937]: loss 0.035256
[epoch17, step938]: loss 0.040184
[epoch17, step939]: loss 0.031652
[epoch17, step940]: loss 0.036576
[epoch17, step941]: loss 0.037893
[epoch17, step942]: loss 0.036411
[epoch17, step943]: loss 0.037360
[epoch17, step944]: loss 0.038559
[epoch17, step945]: loss 0.034406
[epoch17, step946]: loss 0.036683
[epoch17, step947]: loss 0.036878
[epoch17, step948]: loss 0.037691
[epoch17, step949]: loss 0.034044
[epoch17, step950]: loss 0.037037
[epoch17, step951]: loss 0.040405
[epoch17, step952]: loss 0.037570
[epoch17, step953]: loss 0.038483
[epoch17, step954]: loss 0.034793
[epoch17, step955]: loss 0.042877
[epoch17, step956]: loss 0.061599
[epoch17, step957]: loss 0.054619
[epoch17, step958]: loss 0.055400
[epoch17, step959]: loss 0.057529
[epoch17, step960]: loss 0.053210
[epoch17, step961]: loss 0.055275
[epoch17, step962]: loss 0.053496
[epoch17, step963]: loss 0.053003
[epoch17, step964]: loss 0.051876
[epoch17, step965]: loss 0.054094
[epoch17, step966]: loss 0.049781
[epoch17, step967]: loss 0.050627
[epoch17, step968]: loss 0.051762
[epoch17, step969]: loss 0.049013
[epoch17, step970]: loss 0.049766
[epoch17, step971]: loss 0.049319
[epoch17, step972]: loss 0.050230
[epoch17, step973]: loss 0.048717
[epoch17, step974]: loss 0.051068
[epoch17, step975]: loss 0.048228
[epoch17, step976]: loss 0.050042
[epoch17, step977]: loss 0.051243
[epoch17, step978]: loss 0.049179
[epoch17, step979]: loss 0.049267
[epoch17, step980]: loss 0.048766
[epoch17, step981]: loss 0.050719
[epoch17, step982]: loss 0.049074
[epoch17, step983]: loss 0.050594
[epoch17, step984]: loss 0.047589
[epoch17, step985]: loss 0.049774
[epoch17, step986]: loss 0.051112
[epoch17, step987]: loss 0.047954
[epoch17, step988]: loss 0.048765
[epoch17, step989]: loss 0.048996
[epoch17, step990]: loss 0.049971
[epoch17, step991]: loss 0.048759
[epoch17, step992]: loss 0.050148
[epoch17, step993]: loss 0.047836
[epoch17, step994]: loss 0.049422
[epoch17, step995]: loss 0.050666
[epoch17, step996]: loss 0.047156
[epoch17, step997]: loss 0.048490
[epoch17, step998]: loss 0.048903
[epoch17, step999]: loss 0.050482
[epoch17, step1000]: loss 0.048543
[epoch17, step1001]: loss 0.050387
[epoch17, step1002]: loss 0.047641
[epoch17, step1003]: loss 0.049546
[epoch17, step1004]: loss 0.050392
[epoch17, step1005]: loss 0.046615
[epoch17, step1006]: loss 0.048484
[epoch17, step1007]: loss 0.048200
[epoch17, step1008]: loss 0.049851
[epoch17, step1009]: loss 0.048225
[epoch17, step1010]: loss 0.050230
[epoch17, step1011]: loss 0.047447
[epoch17, step1012]: loss 0.049717
[epoch17, step1013]: loss 0.050624
[epoch17, step1014]: loss 0.047597
[epoch17, step1015]: loss 0.048588
[epoch17, step1016]: loss 0.048106
[epoch17, step1017]: loss 0.049482
[epoch17, step1018]: loss 0.047980
[epoch17, step1019]: loss 0.050318
[epoch17, step1020]: loss 0.047647
[epoch17, step1021]: loss 0.049719
[epoch17, step1022]: loss 0.050250
[epoch17, step1023]: loss 0.047268
[epoch17, step1024]: loss 0.048806
[epoch17, step1025]: loss 0.048411
[epoch17, step1026]: loss 0.049952
[epoch17, step1027]: loss 0.047740
[epoch17, step1028]: loss 0.050264
[epoch17, step1029]: loss 0.047499
[epoch17, step1030]: loss 0.049327
[epoch17, step1031]: loss 0.049849
[epoch17, step1032]: loss 0.047061
[epoch17, step1033]: loss 0.048572
[epoch17, step1034]: loss 0.048170
[epoch17, step1035]: loss 0.049727
[epoch17, step1036]: loss 0.048243
[epoch17, step1037]: loss 0.050096
[epoch17, step1038]: loss 0.047270
[epoch17, step1039]: loss 0.049419
[epoch17, step1040]: loss 0.049998
[epoch17, step1041]: loss 0.047181
[epoch17, step1042]: loss 0.047800
[epoch17, step1043]: loss 0.047952
[epoch17, step1044]: loss 0.049830
[epoch17, step1045]: loss 0.048058
[epoch17, step1046]: loss 0.050260
[epoch17, step1047]: loss 0.047216
[epoch17, step1048]: loss 0.049017
[epoch17, step1049]: loss 0.050140
[epoch17, step1050]: loss 0.047234
[epoch17, step1051]: loss 0.048324
[epoch17, step1052]: loss 0.048558
[epoch17, step1053]: loss 0.049934
[epoch17, step1054]: loss 0.048106
[epoch17, step1055]: loss 0.049832
[epoch17, step1056]: loss 0.047090
[epoch17, step1057]: loss 0.049415
[epoch17, step1058]: loss 0.050355
[epoch17, step1059]: loss 0.047097
[epoch17, step1060]: loss 0.048065
[epoch17, step1061]: loss 0.047855
[epoch17, step1062]: loss 0.049600
[epoch17, step1063]: loss 0.048106
[epoch17, step1064]: loss 0.050006
[epoch17, step1065]: loss 0.047487
[epoch17, step1066]: loss 0.048898
[epoch17, step1067]: loss 0.049929
[epoch17, step1068]: loss 0.046730
[epoch17, step1069]: loss 0.047479
[epoch17, step1070]: loss 0.047874
[epoch17, step1071]: loss 0.049601
[epoch17, step1072]: loss 0.048273
[epoch17, step1073]: loss 0.049764
[epoch17, step1074]: loss 0.047593
[epoch17, step1075]: loss 0.049344
[epoch17, step1076]: loss 0.049929
[epoch17, step1077]: loss 0.046752
[epoch17, step1078]: loss 0.048123
[epoch17, step1079]: loss 0.048305
[epoch17, step1080]: loss 0.049649
[epoch17, step1081]: loss 0.047897
[epoch17, step1082]: loss 0.049918
[epoch17, step1083]: loss 0.047570
[epoch17, step1084]: loss 0.049266
[epoch17, step1085]: loss 0.049766
[epoch17, step1086]: loss 0.047045
[epoch17, step1087]: loss 0.048258
[epoch17, step1088]: loss 0.047814
[epoch17, step1089]: loss 0.049437
[epoch17, step1090]: loss 0.048098
[epoch17, step1091]: loss 0.050108
[epoch17, step1092]: loss 0.047338
[epoch17, step1093]: loss 0.049024
[epoch17, step1094]: loss 0.049485
[epoch17, step1095]: loss 0.046353
[epoch17, step1096]: loss 0.047951
[epoch17, step1097]: loss 0.047683
[epoch17, step1098]: loss 0.049493
[epoch17, step1099]: loss 0.047785
[epoch17, step1100]: loss 0.050132
[epoch17, step1101]: loss 0.047691
[epoch17, step1102]: loss 0.049094
[epoch17, step1103]: loss 0.049622
[epoch17, step1104]: loss 0.046779
[epoch17, step1105]: loss 0.048026
[epoch17, step1106]: loss 0.047432
[epoch17, step1107]: loss 0.049474
[epoch17, step1108]: loss 0.047711
[epoch17, step1109]: loss 0.049953
[epoch17, step1110]: loss 0.047286
[epoch17, step1111]: loss 0.049117
[epoch17, step1112]: loss 0.049903
[epoch17, step1113]: loss 0.046602
[epoch17, step1114]: loss 0.048202
[epoch17, step1115]: loss 0.047683
[epoch17, step1116]: loss 0.049300
[epoch17, step1117]: loss 0.047933
[epoch17, step1118]: loss 0.049929
[epoch17, step1119]: loss 0.047416
[epoch17, step1120]: loss 0.048870
[epoch17, step1121]: loss 0.049788
[epoch17, step1122]: loss 0.046737
[epoch17, step1123]: loss 0.047652
[epoch17, step1124]: loss 0.048092
[epoch17, step1125]: loss 0.049506
[epoch17, step1126]: loss 0.048353
[epoch17, step1127]: loss 0.049855
[epoch17, step1128]: loss 0.047523
[epoch17, step1129]: loss 0.048872
[epoch17, step1130]: loss 0.049780
[epoch17, step1131]: loss 0.047124
[epoch17, step1132]: loss 0.048195
[epoch17, step1133]: loss 0.047760
[epoch17, step1134]: loss 0.049191
[epoch17, step1135]: loss 0.048085
[epoch17, step1136]: loss 0.050146
[epoch17, step1137]: loss 0.046838
[epoch17, step1138]: loss 0.049087
[epoch17, step1139]: loss 0.049847
[epoch17, step1140]: loss 0.046214
[epoch17, step1141]: loss 0.047660
[epoch17, step1142]: loss 0.047805
[epoch17, step1143]: loss 0.049136
[epoch17, step1144]: loss 0.047943
[epoch17, step1145]: loss 0.049711
[epoch17, step1146]: loss 0.046391
[epoch17, step1147]: loss 0.049089
[epoch17, step1148]: loss 0.049879
[epoch17, step1149]: loss 0.046181
[epoch17, step1150]: loss 0.047937
[epoch17, step1151]: loss 0.047990
[epoch17, step1152]: loss 0.049474
[epoch17, step1153]: loss 0.047473
[epoch17, step1154]: loss 0.049906
[epoch17, step1155]: loss 0.047172
[epoch17, step1156]: loss 0.048450
[epoch17, step1157]: loss 0.049619
[epoch17, step1158]: loss 0.046584
[epoch17, step1159]: loss 0.047888
[epoch17, step1160]: loss 0.048134
[epoch17, step1161]: loss 0.049131
[epoch17, step1162]: loss 0.047904
[epoch17, step1163]: loss 0.049567
[epoch17, step1164]: loss 0.046797
[epoch17, step1165]: loss 0.049329
[epoch17, step1166]: loss 0.049589
[epoch17, step1167]: loss 0.046273
[epoch17, step1168]: loss 0.047928
[epoch17, step1169]: loss 0.047709
[epoch17, step1170]: loss 0.049291
[epoch17, step1171]: loss 0.047680
[epoch17, step1172]: loss 0.049933
[epoch17, step1173]: loss 0.047163
[epoch17, step1174]: loss 0.048867
[epoch17, step1175]: loss 0.049769
[epoch17, step1176]: loss 0.046417
[epoch17, step1177]: loss 0.047869
[epoch17, step1178]: loss 0.047557
[epoch17, step1179]: loss 0.048981
[epoch17, step1180]: loss 0.047751
[epoch17, step1181]: loss 0.050031
[epoch17, step1182]: loss 0.046500
[epoch17, step1183]: loss 0.048975
[epoch17, step1184]: loss 0.049463
[epoch17, step1185]: loss 0.047048
[epoch17, step1186]: loss 0.047370
[epoch17, step1187]: loss 0.047409
[epoch17, step1188]: loss 0.048606
[epoch17, step1189]: loss 0.047546
[epoch17, step1190]: loss 0.049592
[epoch17, step1191]: loss 0.047704
[epoch17, step1192]: loss 0.048764
[epoch17, step1193]: loss 0.049377
[epoch17, step1194]: loss 0.046614
[epoch17, step1195]: loss 0.047489
[epoch17, step1196]: loss 0.047330
[epoch17, step1197]: loss 0.049389
[epoch17, step1198]: loss 0.047549
[epoch17, step1199]: loss 0.049594
[epoch17, step1200]: loss 0.046565
[epoch17, step1201]: loss 0.048853
[epoch17, step1202]: loss 0.049935
[epoch17, step1203]: loss 0.047049
[epoch17, step1204]: loss 0.047396
[epoch17, step1205]: loss 0.047136
[epoch17, step1206]: loss 0.048828
[epoch17, step1207]: loss 0.047461
[epoch17, step1208]: loss 0.049686
[epoch17, step1209]: loss 0.045837
[epoch17, step1210]: loss 0.048838
[epoch17, step1211]: loss 0.049368
[epoch17, step1212]: loss 0.046718
[epoch17, step1213]: loss 0.047704
[epoch17, step1214]: loss 0.047813
[epoch17, step1215]: loss 0.049184
[epoch17, step1216]: loss 0.047421
[epoch17, step1217]: loss 0.049869
[epoch17, step1218]: loss 0.046564
[epoch17, step1219]: loss 0.048937
[epoch17, step1220]: loss 0.049545
[epoch17, step1221]: loss 0.046019
[epoch17, step1222]: loss 0.047787
[epoch17, step1223]: loss 0.047555
[epoch17, step1224]: loss 0.049211
[epoch17, step1225]: loss 0.047649
[epoch17, step1226]: loss 0.049650
[epoch17, step1227]: loss 0.046365
[epoch17, step1228]: loss 0.048430
[epoch17, step1229]: loss 0.049552
[epoch17, step1230]: loss 0.047133
[epoch17, step1231]: loss 0.047760
[epoch17, step1232]: loss 0.048159
[epoch17, step1233]: loss 0.048840
[epoch17, step1234]: loss 0.047463
[epoch17, step1235]: loss 0.049930
[epoch17, step1236]: loss 0.047364
[epoch17, step1237]: loss 0.048439
[epoch17, step1238]: loss 0.049297
[epoch17, step1239]: loss 0.046648
[epoch17, step1240]: loss 0.047784
[epoch17, step1241]: loss 0.047727
[epoch17, step1242]: loss 0.048792
[epoch17, step1243]: loss 0.047386
[epoch17, step1244]: loss 0.049739
[epoch17, step1245]: loss 0.046610
[epoch17, step1246]: loss 0.048852
[epoch17, step1247]: loss 0.049065
[epoch17, step1248]: loss 0.046631
[epoch17, step1249]: loss 0.047821
[epoch17, step1250]: loss 0.047543
[epoch17, step1251]: loss 0.049224
[epoch17, step1252]: loss 0.048111
[epoch17, step1253]: loss 0.049712
[epoch17, step1254]: loss 0.046932
[epoch17, step1255]: loss 0.048583
[epoch17, step1256]: loss 0.049561
[epoch17, step1257]: loss 0.046606
[epoch17, step1258]: loss 0.047818
[epoch17, step1259]: loss 0.047508
[epoch17, step1260]: loss 0.048897
[epoch17, step1261]: loss 0.047470
[epoch17, step1262]: loss 0.049133
[epoch17, step1263]: loss 0.046893
[epoch17, step1264]: loss 0.048474
[epoch17, step1265]: loss 0.049026
[epoch17, step1266]: loss 0.046736
[epoch17, step1267]: loss 0.047692
[epoch17, step1268]: loss 0.047819
[epoch17, step1269]: loss 0.048850
[epoch17, step1270]: loss 0.047325
[epoch17, step1271]: loss 0.049805
[epoch17, step1272]: loss 0.046992
[epoch17, step1273]: loss 0.048483
[epoch17, step1274]: loss 0.049414
[epoch17, step1275]: loss 0.046988
[epoch17, step1276]: loss 0.047418
[epoch17, step1277]: loss 0.047588
[epoch17, step1278]: loss 0.049069
[epoch17, step1279]: loss 0.047600
[epoch17, step1280]: loss 0.049744
[epoch17, step1281]: loss 0.046869
[epoch17, step1282]: loss 0.048474
[epoch17, step1283]: loss 0.049105
[epoch17, step1284]: loss 0.046055
[epoch17, step1285]: loss 0.047971
[epoch17, step1286]: loss 0.047116
[epoch17, step1287]: loss 0.049060
[epoch17, step1288]: loss 0.047863
[epoch17, step1289]: loss 0.049982
[epoch17, step1290]: loss 0.047129
[epoch17, step1291]: loss 0.048469
[epoch17, step1292]: loss 0.049582
[epoch17, step1293]: loss 0.045784
[epoch17, step1294]: loss 0.047502
[epoch17, step1295]: loss 0.047504
[epoch17, step1296]: loss 0.048858
[epoch17, step1297]: loss 0.046984
[epoch17, step1298]: loss 0.049769
[epoch17, step1299]: loss 0.047063
[epoch17, step1300]: loss 0.048664
[epoch17, step1301]: loss 0.049174
[epoch17, step1302]: loss 0.046599
[epoch17, step1303]: loss 0.047863
[epoch17, step1304]: loss 0.047135
[epoch17, step1305]: loss 0.048876
[epoch17, step1306]: loss 0.047314
[epoch17, step1307]: loss 0.049319
[epoch17, step1308]: loss 0.047122
[epoch17, step1309]: loss 0.048140
[epoch17, step1310]: loss 0.049270
[epoch17, step1311]: loss 0.045947
[epoch17, step1312]: loss 0.048080
[epoch17, step1313]: loss 0.047691
[epoch17, step1314]: loss 0.048640
[epoch17, step1315]: loss 0.047330
[epoch17, step1316]: loss 0.050117
[epoch17, step1317]: loss 0.046629
[epoch17, step1318]: loss 0.048473
[epoch17, step1319]: loss 0.049002
[epoch17, step1320]: loss 0.046959
[epoch17, step1321]: loss 0.047692
[epoch17, step1322]: loss 0.047381
[epoch17, step1323]: loss 0.048965
[epoch17, step1324]: loss 0.047192
[epoch17, step1325]: loss 0.049561
[epoch17, step1326]: loss 0.046845
[epoch17, step1327]: loss 0.048297
[epoch17, step1328]: loss 0.049350
[epoch17, step1329]: loss 0.046538
[epoch17, step1330]: loss 0.047645
[epoch17, step1331]: loss 0.047274
[epoch17, step1332]: loss 0.048766
[epoch17, step1333]: loss 0.047034
[epoch17, step1334]: loss 0.049595
[epoch17, step1335]: loss 0.047359
[epoch17, step1336]: loss 0.048365
[epoch17, step1337]: loss 0.048980
[epoch17, step1338]: loss 0.046087
[epoch17, step1339]: loss 0.047756
[epoch17, step1340]: loss 0.047466
[epoch17, step1341]: loss 0.048707
[epoch17, step1342]: loss 0.047268
[epoch17, step1343]: loss 0.049538
[epoch17, step1344]: loss 0.046701
[epoch17, step1345]: loss 0.048415
[epoch17, step1346]: loss 0.049074
[epoch17, step1347]: loss 0.046876
[epoch17, step1348]: loss 0.047365
[epoch17, step1349]: loss 0.047426
[epoch17, step1350]: loss 0.048979
[epoch17, step1351]: loss 0.047280
[epoch17, step1352]: loss 0.049195
[epoch17, step1353]: loss 0.046782
[epoch17, step1354]: loss 0.048282
[epoch17, step1355]: loss 0.049401
[epoch17, step1356]: loss 0.046435
[epoch17, step1357]: loss 0.047343
[epoch17, step1358]: loss 0.047099
[epoch17, step1359]: loss 0.048363
[epoch17, step1360]: loss 0.047184
[epoch17, step1361]: loss 0.049579
[epoch17, step1362]: loss 0.047169
[epoch17, step1363]: loss 0.048517
[epoch17, step1364]: loss 0.049031
[epoch17, step1365]: loss 0.046570
[epoch17, step1366]: loss 0.047389
[epoch17, step1367]: loss 0.047059
[epoch17, step1368]: loss 0.048770
[epoch17, step1369]: loss 0.047607
[epoch17, step1370]: loss 0.049430
[epoch17, step1371]: loss 0.046961
[epoch17, step1372]: loss 0.048365
[epoch17, step1373]: loss 0.049133
[epoch17, step1374]: loss 0.046793
[epoch17, step1375]: loss 0.048092
[epoch17, step1376]: loss 0.047092
[epoch17, step1377]: loss 0.048627
[epoch17, step1378]: loss 0.047453
[epoch17, step1379]: loss 0.049317
[epoch17, step1380]: loss 0.046394
[epoch17, step1381]: loss 0.048200
[epoch17, step1382]: loss 0.049451
[epoch17, step1383]: loss 0.045800
[epoch17, step1384]: loss 0.047244
[epoch17, step1385]: loss 0.046853
[epoch17, step1386]: loss 0.048559
[epoch17, step1387]: loss 0.047291
[epoch17, step1388]: loss 0.048951
[epoch17, step1389]: loss 0.046105
[epoch17, step1390]: loss 0.048178
[epoch17, step1391]: loss 0.048998
[epoch17, step1392]: loss 0.046478
[epoch17, step1393]: loss 0.047478
[epoch17, step1394]: loss 0.047511
[epoch17, step1395]: loss 0.048532
[epoch17, step1396]: loss 0.047255
[epoch17, step1397]: loss 0.049375
[epoch17, step1398]: loss 0.046447
[epoch17, step1399]: loss 0.048882
[epoch17, step1400]: loss 0.049454
[epoch17, step1401]: loss 0.046097
[epoch17, step1402]: loss 0.047721
[epoch17, step1403]: loss 0.046633
[epoch17, step1404]: loss 0.048609
[epoch17, step1405]: loss 0.047065
[epoch17, step1406]: loss 0.049190
[epoch17, step1407]: loss 0.047392
[epoch17, step1408]: loss 0.048060
[epoch17, step1409]: loss 0.049123
[epoch17, step1410]: loss 0.045828
[epoch17, step1411]: loss 0.046985
[epoch17, step1412]: loss 0.047346
[epoch17, step1413]: loss 0.048724
[epoch17, step1414]: loss 0.046997
[epoch17, step1415]: loss 0.049095
[epoch17, step1416]: loss 0.046155
[epoch17, step1417]: loss 0.048095
[epoch17, step1418]: loss 0.049205
[epoch17, step1419]: loss 0.046683
[epoch17, step1420]: loss 0.047743
[epoch17, step1421]: loss 0.047680
[epoch17, step1422]: loss 0.048655
[epoch17, step1423]: loss 0.047437
[epoch17, step1424]: loss 0.050142
[epoch17, step1425]: loss 0.045991
[epoch17, step1426]: loss 0.048309
[epoch17, step1427]: loss 0.049708
[epoch17, step1428]: loss 0.047117
[epoch17, step1429]: loss 0.047473
[epoch17, step1430]: loss 0.047389
[epoch17, step1431]: loss 0.048577
[epoch17, step1432]: loss 0.047208
[epoch17, step1433]: loss 0.049395
[epoch17, step1434]: loss 0.046633
[epoch17, step1435]: loss 0.048280
[epoch17, step1436]: loss 0.049305
[epoch17, step1437]: loss 0.045970
[epoch17, step1438]: loss 0.047774
[epoch17, step1439]: loss 0.047268
[epoch17, step1440]: loss 0.048624
[epoch17, step1441]: loss 0.047558
[epoch17, step1442]: loss 0.048987
[epoch17, step1443]: loss 0.047046
[epoch17, step1444]: loss 0.048020
[epoch17, step1445]: loss 0.049449
[epoch17, step1446]: loss 0.046545
[epoch17, step1447]: loss 0.047863
[epoch17, step1448]: loss 0.047480
[epoch17, step1449]: loss 0.048763
[epoch17, step1450]: loss 0.047216
[epoch17, step1451]: loss 0.049594
[epoch17, step1452]: loss 0.046689
[epoch17, step1453]: loss 0.048431
[epoch17, step1454]: loss 0.049565
[epoch17, step1455]: loss 0.046510
[epoch17, step1456]: loss 0.047203
[epoch17, step1457]: loss 0.047436
[epoch17, step1458]: loss 0.048378
[epoch17, step1459]: loss 0.047274
[epoch17, step1460]: loss 0.049518
[epoch17, step1461]: loss 0.046380
[epoch17, step1462]: loss 0.048259
[epoch17, step1463]: loss 0.049211
[epoch17, step1464]: loss 0.045868
[epoch17, step1465]: loss 0.047438
[epoch17, step1466]: loss 0.047006
[epoch17, step1467]: loss 0.048418
[epoch17, step1468]: loss 0.047379
[epoch17, step1469]: loss 0.049493
[epoch17, step1470]: loss 0.046560
[epoch17, step1471]: loss 0.048794
[epoch17, step1472]: loss 0.049387
[epoch17, step1473]: loss 0.046015
[epoch17, step1474]: loss 0.048296
[epoch17, step1475]: loss 0.046998
[epoch17, step1476]: loss 0.048933
[epoch17, step1477]: loss 0.047483
[epoch17, step1478]: loss 0.049334
[epoch17, step1479]: loss 0.046380
[epoch17, step1480]: loss 0.048358
[epoch17, step1481]: loss 0.048640
[epoch17, step1482]: loss 0.046151
[epoch17, step1483]: loss 0.047668
[epoch17, step1484]: loss 0.047105
[epoch17, step1485]: loss 0.048518
[epoch17, step1486]: loss 0.046632
[epoch17, step1487]: loss 0.049078
[epoch17, step1488]: loss 0.046859
[epoch17, step1489]: loss 0.048135
[epoch17, step1490]: loss 0.048957
[epoch17, step1491]: loss 0.047074
[epoch17, step1492]: loss 0.047672
[epoch17, step1493]: loss 0.047436
[epoch17, step1494]: loss 0.048921
[epoch17, step1495]: loss 0.047038
[epoch17, step1496]: loss 0.049031
[epoch17, step1497]: loss 0.046535
[epoch17, step1498]: loss 0.047946
[epoch17, step1499]: loss 0.048905
[epoch17, step1500]: loss 0.046073
[epoch17, step1501]: loss 0.047330
[epoch17, step1502]: loss 0.046758
[epoch17, step1503]: loss 0.048410
[epoch17, step1504]: loss 0.046854
[epoch17, step1505]: loss 0.049278
[epoch17, step1506]: loss 0.045870
[epoch17, step1507]: loss 0.047987
[epoch17, step1508]: loss 0.049302
[epoch17, step1509]: loss 0.046125
[epoch17, step1510]: loss 0.047069
[epoch17, step1511]: loss 0.047147
[epoch17, step1512]: loss 0.048441
[epoch17, step1513]: loss 0.046605
[epoch17, step1514]: loss 0.049095
[epoch17, step1515]: loss 0.047053
[epoch17, step1516]: loss 0.048230

[epoch17]: avg loss 0.046022

[epoch18, step1]: loss 0.043907
[epoch18, step2]: loss 0.049496
[epoch18, step3]: loss 0.049243
[epoch18, step4]: loss 0.046303
[epoch18, step5]: loss 0.048715
[epoch18, step6]: loss 0.049360
[epoch18, step7]: loss 0.045749
[epoch18, step8]: loss 0.049705
[epoch18, step9]: loss 0.045399
[epoch18, step10]: loss 0.047873
[epoch18, step11]: loss 0.049468
[epoch18, step12]: loss 0.048941
[epoch18, step13]: loss 0.045937
[epoch18, step14]: loss 0.048554
[epoch18, step15]: loss 0.049040
[epoch18, step16]: loss 0.045684
[epoch18, step17]: loss 0.049360
[epoch18, step18]: loss 0.046104
[epoch18, step19]: loss 0.047555
[epoch18, step20]: loss 0.049420
[epoch18, step21]: loss 0.049126
[epoch18, step22]: loss 0.046054
[epoch18, step23]: loss 0.047833
[epoch18, step24]: loss 0.049212
[epoch18, step25]: loss 0.045045
[epoch18, step26]: loss 0.048943
[epoch18, step27]: loss 0.045723
[epoch18, step28]: loss 0.047676
[epoch18, step29]: loss 0.049279
[epoch18, step30]: loss 0.049798
[epoch18, step31]: loss 0.045702
[epoch18, step32]: loss 0.048674
[epoch18, step33]: loss 0.049592
[epoch18, step34]: loss 0.045961
[epoch18, step35]: loss 0.049510
[epoch18, step36]: loss 0.045653
[epoch18, step37]: loss 0.047581
[epoch18, step38]: loss 0.048974
[epoch18, step39]: loss 0.048959
[epoch18, step40]: loss 0.046075
[epoch18, step41]: loss 0.047942
[epoch18, step42]: loss 0.049175
[epoch18, step43]: loss 0.045543
[epoch18, step44]: loss 0.049332
[epoch18, step45]: loss 0.046110
[epoch18, step46]: loss 0.047397
[epoch18, step47]: loss 0.048845
[epoch18, step48]: loss 0.048874
[epoch18, step49]: loss 0.044774
[epoch18, step50]: loss 0.048317
[epoch18, step51]: loss 0.049001
[epoch18, step52]: loss 0.045702
[epoch18, step53]: loss 0.049462
[epoch18, step54]: loss 0.045663
[epoch18, step55]: loss 0.047676
[epoch18, step56]: loss 0.049528
[epoch18, step57]: loss 0.049609
[epoch18, step58]: loss 0.045914
[epoch18, step59]: loss 0.047973
[epoch18, step60]: loss 0.049290
[epoch18, step61]: loss 0.045220
[epoch18, step62]: loss 0.049121
[epoch18, step63]: loss 0.045356
[epoch18, step64]: loss 0.047472
[epoch18, step65]: loss 0.049166
[epoch18, step66]: loss 0.048977
[epoch18, step67]: loss 0.046497
[epoch18, step68]: loss 0.048298
[epoch18, step69]: loss 0.048923
[epoch18, step70]: loss 0.045480
[epoch18, step71]: loss 0.048929
[epoch18, step72]: loss 0.045617
[epoch18, step73]: loss 0.047243
[epoch18, step74]: loss 0.048869
[epoch18, step75]: loss 0.049027
[epoch18, step76]: loss 0.046561
[epoch18, step77]: loss 0.048272
[epoch18, step78]: loss 0.049013
[epoch18, step79]: loss 0.045442
[epoch18, step80]: loss 0.049421
[epoch18, step81]: loss 0.046127
[epoch18, step82]: loss 0.047680
[epoch18, step83]: loss 0.048692
[epoch18, step84]: loss 0.049355
[epoch18, step85]: loss 0.045922
[epoch18, step86]: loss 0.048283
[epoch18, step87]: loss 0.049520
[epoch18, step88]: loss 0.045370
[epoch18, step89]: loss 0.049010
[epoch18, step90]: loss 0.045989
[epoch18, step91]: loss 0.047335
[epoch18, step92]: loss 0.048953
[epoch18, step93]: loss 0.048868
[epoch18, step94]: loss 0.046114
[epoch18, step95]: loss 0.048232
[epoch18, step96]: loss 0.048838
[epoch18, step97]: loss 0.045770
[epoch18, step98]: loss 0.049064
[epoch18, step99]: loss 0.045589
[epoch18, step100]: loss 0.046870
[epoch18, step101]: loss 0.048989
[epoch18, step102]: loss 0.048965
[epoch18, step103]: loss 0.045975
[epoch18, step104]: loss 0.048037
[epoch18, step105]: loss 0.048999
[epoch18, step106]: loss 0.045444
[epoch18, step107]: loss 0.049010
[epoch18, step108]: loss 0.046026
[epoch18, step109]: loss 0.046958
[epoch18, step110]: loss 0.049427
[epoch18, step111]: loss 0.048999
[epoch18, step112]: loss 0.046318
[epoch18, step113]: loss 0.048645
[epoch18, step114]: loss 0.048747
[epoch18, step115]: loss 0.045675
[epoch18, step116]: loss 0.049509
[epoch18, step117]: loss 0.045474
[epoch18, step118]: loss 0.047868
[epoch18, step119]: loss 0.049096
[epoch18, step120]: loss 0.048925
[epoch18, step121]: loss 0.045925
[epoch18, step122]: loss 0.047930
[epoch18, step123]: loss 0.049164
[epoch18, step124]: loss 0.045650
[epoch18, step125]: loss 0.049178
[epoch18, step126]: loss 0.045652
[epoch18, step127]: loss 0.046990
[epoch18, step128]: loss 0.048731
[epoch18, step129]: loss 0.048524
[epoch18, step130]: loss 0.045541
[epoch18, step131]: loss 0.047739
[epoch18, step132]: loss 0.048810
[epoch18, step133]: loss 0.044721
[epoch18, step134]: loss 0.048830
[epoch18, step135]: loss 0.045908
[epoch18, step136]: loss 0.047658
[epoch18, step137]: loss 0.048947
[epoch18, step138]: loss 0.048987
[epoch18, step139]: loss 0.045865
[epoch18, step140]: loss 0.048582
[epoch18, step141]: loss 0.048933
[epoch18, step142]: loss 0.045579
[epoch18, step143]: loss 0.049165
[epoch18, step144]: loss 0.046013
[epoch18, step145]: loss 0.047584
[epoch18, step146]: loss 0.049322
[epoch18, step147]: loss 0.049456
[epoch18, step148]: loss 0.045970
[epoch18, step149]: loss 0.048069
[epoch18, step150]: loss 0.048557
[epoch18, step151]: loss 0.044969
[epoch18, step152]: loss 0.049057
[epoch18, step153]: loss 0.045493
[epoch18, step154]: loss 0.047107
[epoch18, step155]: loss 0.048757
[epoch18, step156]: loss 0.048822
[epoch18, step157]: loss 0.045997
[epoch18, step158]: loss 0.048094
[epoch18, step159]: loss 0.049224
[epoch18, step160]: loss 0.046050
[epoch18, step161]: loss 0.049344
[epoch18, step162]: loss 0.046129
[epoch18, step163]: loss 0.048001
[epoch18, step164]: loss 0.049096
[epoch18, step165]: loss 0.049256
[epoch18, step166]: loss 0.046080
[epoch18, step167]: loss 0.047945
[epoch18, step168]: loss 0.049243
[epoch18, step169]: loss 0.045353
[epoch18, step170]: loss 0.049083
[epoch18, step171]: loss 0.046015
[epoch18, step172]: loss 0.047246
[epoch18, step173]: loss 0.049081
[epoch18, step174]: loss 0.049014
[epoch18, step175]: loss 0.046138
[epoch18, step176]: loss 0.048009
[epoch18, step177]: loss 0.049039
[epoch18, step178]: loss 0.044913
[epoch18, step179]: loss 0.048679
[epoch18, step180]: loss 0.046052
[epoch18, step181]: loss 0.047018
[epoch18, step182]: loss 0.049407
[epoch18, step183]: loss 0.049803
[epoch18, step184]: loss 0.046300
[epoch18, step185]: loss 0.048440
[epoch18, step186]: loss 0.049233
[epoch18, step187]: loss 0.045347
[epoch18, step188]: loss 0.049126
[epoch18, step189]: loss 0.045591
[epoch18, step190]: loss 0.046978
[epoch18, step191]: loss 0.048743
[epoch18, step192]: loss 0.049037
[epoch18, step193]: loss 0.045051
[epoch18, step194]: loss 0.047622
[epoch18, step195]: loss 0.048916
[epoch18, step196]: loss 0.044804
[epoch18, step197]: loss 0.048946
[epoch18, step198]: loss 0.044828
[epoch18, step199]: loss 0.047061
[epoch18, step200]: loss 0.048881
[epoch18, step201]: loss 0.049086
[epoch18, step202]: loss 0.045852
[epoch18, step203]: loss 0.047938
[epoch18, step204]: loss 0.048983
[epoch18, step205]: loss 0.045340
[epoch18, step206]: loss 0.048815
[epoch18, step207]: loss 0.045902
[epoch18, step208]: loss 0.047752
[epoch18, step209]: loss 0.048726
[epoch18, step210]: loss 0.049588
[epoch18, step211]: loss 0.046481
[epoch18, step212]: loss 0.048059
[epoch18, step213]: loss 0.048895
[epoch18, step214]: loss 0.045184
[epoch18, step215]: loss 0.049055
[epoch18, step216]: loss 0.045727
[epoch18, step217]: loss 0.046699
[epoch18, step218]: loss 0.048890
[epoch18, step219]: loss 0.048739
[epoch18, step220]: loss 0.046434
[epoch18, step221]: loss 0.047993
[epoch18, step222]: loss 0.048800
[epoch18, step223]: loss 0.044981
[epoch18, step224]: loss 0.048762
[epoch18, step225]: loss 0.045320
[epoch18, step226]: loss 0.046846
[epoch18, step227]: loss 0.048292
[epoch18, step228]: loss 0.049078
[epoch18, step229]: loss 0.045701
[epoch18, step230]: loss 0.048069
[epoch18, step231]: loss 0.048921
[epoch18, step232]: loss 0.044856
[epoch18, step233]: loss 0.048681
[epoch18, step234]: loss 0.045667
[epoch18, step235]: loss 0.047748
[epoch18, step236]: loss 0.048713
[epoch18, step237]: loss 0.049144
[epoch18, step238]: loss 0.045387
[epoch18, step239]: loss 0.047500
[epoch18, step240]: loss 0.048667
[epoch18, step241]: loss 0.045619
[epoch18, step242]: loss 0.048788
[epoch18, step243]: loss 0.046017
[epoch18, step244]: loss 0.046911
[epoch18, step245]: loss 0.048574
[epoch18, step246]: loss 0.048867
[epoch18, step247]: loss 0.046142
[epoch18, step248]: loss 0.047694
[epoch18, step249]: loss 0.048460
[epoch18, step250]: loss 0.044711
[epoch18, step251]: loss 0.049183
[epoch18, step252]: loss 0.045787
[epoch18, step253]: loss 0.046788
[epoch18, step254]: loss 0.048800
[epoch18, step255]: loss 0.048918
[epoch18, step256]: loss 0.046131
[epoch18, step257]: loss 0.048385
[epoch18, step258]: loss 0.048972
[epoch18, step259]: loss 0.044928
[epoch18, step260]: loss 0.049590
[epoch18, step261]: loss 0.046094
[epoch18, step262]: loss 0.047187
[epoch18, step263]: loss 0.048639
[epoch18, step264]: loss 0.048823
[epoch18, step265]: loss 0.046153
[epoch18, step266]: loss 0.047990
[epoch18, step267]: loss 0.048426
[epoch18, step268]: loss 0.045013
[epoch18, step269]: loss 0.049141
[epoch18, step270]: loss 0.045248
[epoch18, step271]: loss 0.046921
[epoch18, step272]: loss 0.049255
[epoch18, step273]: loss 0.048893
[epoch18, step274]: loss 0.046004
[epoch18, step275]: loss 0.048155
[epoch18, step276]: loss 0.048644
[epoch18, step277]: loss 0.045452
[epoch18, step278]: loss 0.049335
[epoch18, step279]: loss 0.045125
[epoch18, step280]: loss 0.047269
[epoch18, step281]: loss 0.048574
[epoch18, step282]: loss 0.048874
[epoch18, step283]: loss 0.045731
[epoch18, step284]: loss 0.047550
[epoch18, step285]: loss 0.048833
[epoch18, step286]: loss 0.045044
[epoch18, step287]: loss 0.048833
[epoch18, step288]: loss 0.045399
[epoch18, step289]: loss 0.047265
[epoch18, step290]: loss 0.048748
[epoch18, step291]: loss 0.048911
[epoch18, step292]: loss 0.045423
[epoch18, step293]: loss 0.047570
[epoch18, step294]: loss 0.048301
[epoch18, step295]: loss 0.044793
[epoch18, step296]: loss 0.049132
[epoch18, step297]: loss 0.045711
[epoch18, step298]: loss 0.047153
[epoch18, step299]: loss 0.048343
[epoch18, step300]: loss 0.049094
[epoch18, step301]: loss 0.046049
[epoch18, step302]: loss 0.048109
[epoch18, step303]: loss 0.048898
[epoch18, step304]: loss 0.044344
[epoch18, step305]: loss 0.048771
[epoch18, step306]: loss 0.045307
[epoch18, step307]: loss 0.046918
[epoch18, step308]: loss 0.048936
[epoch18, step309]: loss 0.048734
[epoch18, step310]: loss 0.046072
[epoch18, step311]: loss 0.047887
[epoch18, step312]: loss 0.048575
[epoch18, step313]: loss 0.045425
[epoch18, step314]: loss 0.048722
[epoch18, step315]: loss 0.046192
[epoch18, step316]: loss 0.046799
[epoch18, step317]: loss 0.048600
[epoch18, step318]: loss 0.048775
[epoch18, step319]: loss 0.045729
[epoch18, step320]: loss 0.047201
[epoch18, step321]: loss 0.048408
[epoch18, step322]: loss 0.045590
[epoch18, step323]: loss 0.048485
[epoch18, step324]: loss 0.046254
[epoch18, step325]: loss 0.047162
[epoch18, step326]: loss 0.048445
[epoch18, step327]: loss 0.048702
[epoch18, step328]: loss 0.045998
[epoch18, step329]: loss 0.047606
[epoch18, step330]: loss 0.048493
[epoch18, step331]: loss 0.045289
[epoch18, step332]: loss 0.048543
[epoch18, step333]: loss 0.045466
[epoch18, step334]: loss 0.046895
[epoch18, step335]: loss 0.048748
[epoch18, step336]: loss 0.049105
[epoch18, step337]: loss 0.045546
[epoch18, step338]: loss 0.047380
[epoch18, step339]: loss 0.048303
[epoch18, step340]: loss 0.045360
[epoch18, step341]: loss 0.048470
[epoch18, step342]: loss 0.044948
[epoch18, step343]: loss 0.046946
[epoch18, step344]: loss 0.048247
[epoch18, step345]: loss 0.048377
[epoch18, step346]: loss 0.045649
[epoch18, step347]: loss 0.047467
[epoch18, step348]: loss 0.048572
[epoch18, step349]: loss 0.045345
[epoch18, step350]: loss 0.048445
[epoch18, step351]: loss 0.045221
[epoch18, step352]: loss 0.046736
[epoch18, step353]: loss 0.048446
[epoch18, step354]: loss 0.048405
[epoch18, step355]: loss 0.045159
[epoch18, step356]: loss 0.048033
[epoch18, step357]: loss 0.048493
[epoch18, step358]: loss 0.044537
[epoch18, step359]: loss 0.049133
[epoch18, step360]: loss 0.044504
[epoch18, step361]: loss 0.046631
[epoch18, step362]: loss 0.048788
[epoch18, step363]: loss 0.048519
[epoch18, step364]: loss 0.045735
[epoch18, step365]: loss 0.047430
[epoch18, step366]: loss 0.048604
[epoch18, step367]: loss 0.045071
[epoch18, step368]: loss 0.048320
[epoch18, step369]: loss 0.045173
[epoch18, step370]: loss 0.046781
[epoch18, step371]: loss 0.048735
[epoch18, step372]: loss 0.048428
[epoch18, step373]: loss 0.045135
[epoch18, step374]: loss 0.047175
[epoch18, step375]: loss 0.048646
[epoch18, step376]: loss 0.044663
[epoch18, step377]: loss 0.048685
[epoch18, step378]: loss 0.046083
[epoch18, step379]: loss 0.047023
[epoch18, step380]: loss 0.048898
[epoch18, step381]: loss 0.048788
[epoch18, step382]: loss 0.046192
[epoch18, step383]: loss 0.047264
[epoch18, step384]: loss 0.048191
[epoch18, step385]: loss 0.044518
[epoch18, step386]: loss 0.048815
[epoch18, step387]: loss 0.045067
[epoch18, step388]: loss 0.047166
[epoch18, step389]: loss 0.048571
[epoch18, step390]: loss 0.048816
[epoch18, step391]: loss 0.045052
[epoch18, step392]: loss 0.047799
[epoch18, step393]: loss 0.048443
[epoch18, step394]: loss 0.045101
[epoch18, step395]: loss 0.048470
[epoch18, step396]: loss 0.045265
[epoch18, step397]: loss 0.046563
[epoch18, step398]: loss 0.048490
[epoch18, step399]: loss 0.048526
[epoch18, step400]: loss 0.045092
[epoch18, step401]: loss 0.047398
[epoch18, step402]: loss 0.048321
[epoch18, step403]: loss 0.044964
[epoch18, step404]: loss 0.048765
[epoch18, step405]: loss 0.045509
[epoch18, step406]: loss 0.047284
[epoch18, step407]: loss 0.048184
[epoch18, step408]: loss 0.048835
[epoch18, step409]: loss 0.046178
[epoch18, step410]: loss 0.047626
[epoch18, step411]: loss 0.048419
[epoch18, step412]: loss 0.044066
[epoch18, step413]: loss 0.048465
[epoch18, step414]: loss 0.045419
[epoch18, step415]: loss 0.046846
[epoch18, step416]: loss 0.048193
[epoch18, step417]: loss 0.048679
[epoch18, step418]: loss 0.045180
[epoch18, step419]: loss 0.047166
[epoch18, step420]: loss 0.048415
[epoch18, step421]: loss 0.044602
[epoch18, step422]: loss 0.048578
[epoch18, step423]: loss 0.045075
[epoch18, step424]: loss 0.046545
[epoch18, step425]: loss 0.048841
[epoch18, step426]: loss 0.048718
[epoch18, step427]: loss 0.046215
[epoch18, step428]: loss 0.047895
[epoch18, step429]: loss 0.048651
[epoch18, step430]: loss 0.044993
[epoch18, step431]: loss 0.049731
[epoch18, step432]: loss 0.045192
[epoch18, step433]: loss 0.046903
[epoch18, step434]: loss 0.048733
[epoch18, step435]: loss 0.048772
[epoch18, step436]: loss 0.045587
[epoch18, step437]: loss 0.047778
[epoch18, step438]: loss 0.048568
[epoch18, step439]: loss 0.045330
[epoch18, step440]: loss 0.048632
[epoch18, step441]: loss 0.045489
[epoch18, step442]: loss 0.046461
[epoch18, step443]: loss 0.048705
[epoch18, step444]: loss 0.048463
[epoch18, step445]: loss 0.046175
[epoch18, step446]: loss 0.047807
[epoch18, step447]: loss 0.048737
[epoch18, step448]: loss 0.044825
[epoch18, step449]: loss 0.048707
[epoch18, step450]: loss 0.045110
[epoch18, step451]: loss 0.046922
[epoch18, step452]: loss 0.047678
[epoch18, step453]: loss 0.048783
[epoch18, step454]: loss 0.045686
[epoch18, step455]: loss 0.047434
[epoch18, step456]: loss 0.048013
[epoch18, step457]: loss 0.045247
[epoch18, step458]: loss 0.048354
[epoch18, step459]: loss 0.045549
[epoch18, step460]: loss 0.046479
[epoch18, step461]: loss 0.048767
[epoch18, step462]: loss 0.048216
[epoch18, step463]: loss 0.045772
[epoch18, step464]: loss 0.047289
[epoch18, step465]: loss 0.048867
[epoch18, step466]: loss 0.044335
[epoch18, step467]: loss 0.048326
[epoch18, step468]: loss 0.045082
[epoch18, step469]: loss 0.046617
[epoch18, step470]: loss 0.048524
[epoch18, step471]: loss 0.048248
[epoch18, step472]: loss 0.046170
[epoch18, step473]: loss 0.047400
[epoch18, step474]: loss 0.048316
[epoch18, step475]: loss 0.045318
[epoch18, step476]: loss 0.048892
[epoch18, step477]: loss 0.045335
[epoch18, step478]: loss 0.046752
[epoch18, step479]: loss 0.048147
[epoch18, step480]: loss 0.048152
[epoch18, step481]: loss 0.045316
[epoch18, step482]: loss 0.047030
[epoch18, step483]: loss 0.048632
[epoch18, step484]: loss 0.044265
[epoch18, step485]: loss 0.048514
[epoch18, step486]: loss 0.045393
[epoch18, step487]: loss 0.046248
[epoch18, step488]: loss 0.048528
[epoch18, step489]: loss 0.048205
[epoch18, step490]: loss 0.045839
[epoch18, step491]: loss 0.047335
[epoch18, step492]: loss 0.048064
[epoch18, step493]: loss 0.044096
[epoch18, step494]: loss 0.048207
[epoch18, step495]: loss 0.045766
[epoch18, step496]: loss 0.046334
[epoch18, step497]: loss 0.048623
[epoch18, step498]: loss 0.048376
[epoch18, step499]: loss 0.045987
[epoch18, step500]: loss 0.047659
[epoch18, step501]: loss 0.048060
[epoch18, step502]: loss 0.044896
[epoch18, step503]: loss 0.049306
[epoch18, step504]: loss 0.045340
[epoch18, step505]: loss 0.046208
[epoch18, step506]: loss 0.048770
[epoch18, step507]: loss 0.048561
[epoch18, step508]: loss 0.045974
[epoch18, step509]: loss 0.047496
[epoch18, step510]: loss 0.048746
[epoch18, step511]: loss 0.045278
[epoch18, step512]: loss 0.048939
[epoch18, step513]: loss 0.045215
[epoch18, step514]: loss 0.046529
[epoch18, step515]: loss 0.048901
[epoch18, step516]: loss 0.048905
[epoch18, step517]: loss 0.045756
[epoch18, step518]: loss 0.047997
[epoch18, step519]: loss 0.048822
[epoch18, step520]: loss 0.043805
[epoch18, step521]: loss 0.048654
[epoch18, step522]: loss 0.044551
[epoch18, step523]: loss 0.046415
[epoch18, step524]: loss 0.048025
[epoch18, step525]: loss 0.048539
[epoch18, step526]: loss 0.045211
[epoch18, step527]: loss 0.047217
[epoch18, step528]: loss 0.048283
[epoch18, step529]: loss 0.044358
[epoch18, step530]: loss 0.048563
[epoch18, step531]: loss 0.044757
[epoch18, step532]: loss 0.046126
[epoch18, step533]: loss 0.048690
[epoch18, step534]: loss 0.048371
[epoch18, step535]: loss 0.045879
[epoch18, step536]: loss 0.047361
[epoch18, step537]: loss 0.048219
[epoch18, step538]: loss 0.045218
[epoch18, step539]: loss 0.048240
[epoch18, step540]: loss 0.045394
[epoch18, step541]: loss 0.046397
[epoch18, step542]: loss 0.048355
[epoch18, step543]: loss 0.048248
[epoch18, step544]: loss 0.044844
[epoch18, step545]: loss 0.046944
[epoch18, step546]: loss 0.048315
[epoch18, step547]: loss 0.044832
[epoch18, step548]: loss 0.048353
[epoch18, step549]: loss 0.045220
[epoch18, step550]: loss 0.046507
[epoch18, step551]: loss 0.047964
[epoch18, step552]: loss 0.048082
[epoch18, step553]: loss 0.045910
[epoch18, step554]: loss 0.047095
[epoch18, step555]: loss 0.047995
[epoch18, step556]: loss 0.044272
[epoch18, step557]: loss 0.048022
[epoch18, step558]: loss 0.045133
[epoch18, step559]: loss 0.046181
[epoch18, step560]: loss 0.048069
[epoch18, step561]: loss 0.048273
[epoch18, step562]: loss 0.045094
[epoch18, step563]: loss 0.040228
[epoch18, step564]: loss 0.040324
[epoch18, step565]: loss 0.036062
[epoch18, step566]: loss 0.044365
[epoch18, step567]: loss 0.035986
[epoch18, step568]: loss 0.035598
[epoch18, step569]: loss 0.035731
[epoch18, step570]: loss 0.041094
[epoch18, step571]: loss 0.033415
[epoch18, step572]: loss 0.034882
[epoch18, step573]: loss 0.039239
[epoch18, step574]: loss 0.040488
[epoch18, step575]: loss 0.032209
[epoch18, step576]: loss 0.032684
[epoch18, step577]: loss 0.034568
[epoch18, step578]: loss 0.031493
[epoch18, step579]: loss 0.035972
[epoch18, step580]: loss 0.033842
[epoch18, step581]: loss 0.035856
[epoch18, step582]: loss 0.035600
[epoch18, step583]: loss 0.033250
[epoch18, step584]: loss 0.033755
[epoch18, step585]: loss 0.038295
[epoch18, step586]: loss 0.032446
[epoch18, step587]: loss 0.033825
[epoch18, step588]: loss 0.034132
[epoch18, step589]: loss 0.038129
[epoch18, step590]: loss 0.034078
[epoch18, step591]: loss 0.031047
[epoch18, step592]: loss 0.037398
[epoch18, step593]: loss 0.036643
[epoch18, step594]: loss 0.032906
[epoch18, step595]: loss 0.033024
[epoch18, step596]: loss 0.034258
[epoch18, step597]: loss 0.036618
[epoch18, step598]: loss 0.034085
[epoch18, step599]: loss 0.032228
[epoch18, step600]: loss 0.033772
[epoch18, step601]: loss 0.030076
[epoch18, step602]: loss 0.035253
[epoch18, step603]: loss 0.034049
[epoch18, step604]: loss 0.034368
[epoch18, step605]: loss 0.032450
[epoch18, step606]: loss 0.034325
[epoch18, step607]: loss 0.037354
[epoch18, step608]: loss 0.031455
[epoch18, step609]: loss 0.036471
[epoch18, step610]: loss 0.034696
[epoch18, step611]: loss 0.037248
[epoch18, step612]: loss 0.035200
[epoch18, step613]: loss 0.031525
[epoch18, step614]: loss 0.035155
[epoch18, step615]: loss 0.037455
[epoch18, step616]: loss 0.031625
[epoch18, step617]: loss 0.032734
[epoch18, step618]: loss 0.036232
[epoch18, step619]: loss 0.034032
[epoch18, step620]: loss 0.031274
[epoch18, step621]: loss 0.032555
[epoch18, step622]: loss 0.031708
[epoch18, step623]: loss 0.034720
[epoch18, step624]: loss 0.036386
[epoch18, step625]: loss 0.032007
[epoch18, step626]: loss 0.037694
[epoch18, step627]: loss 0.035514
[epoch18, step628]: loss 0.036235
[epoch18, step629]: loss 0.025680
[epoch18, step630]: loss 0.031504
[epoch18, step631]: loss 0.038348
[epoch18, step632]: loss 0.033421
[epoch18, step633]: loss 0.032241
[epoch18, step634]: loss 0.036639
[epoch18, step635]: loss 0.033855
[epoch18, step636]: loss 0.028487
[epoch18, step637]: loss 0.037946
[epoch18, step638]: loss 0.036719
[epoch18, step639]: loss 0.030054
[epoch18, step640]: loss 0.039588
[epoch18, step641]: loss 0.036904
[epoch18, step642]: loss 0.031765
[epoch18, step643]: loss 0.036366
[epoch18, step644]: loss 0.034367
[epoch18, step645]: loss 0.029551
[epoch18, step646]: loss 0.035389
[epoch18, step647]: loss 0.030078
[epoch18, step648]: loss 0.035585
[epoch18, step649]: loss 0.037774
[epoch18, step650]: loss 0.033281
[epoch18, step651]: loss 0.034656
[epoch18, step652]: loss 0.038346
[epoch18, step653]: loss 0.038872
[epoch18, step654]: loss 0.033670
[epoch18, step655]: loss 0.031653
[epoch18, step656]: loss 0.033292
[epoch18, step657]: loss 0.038197
[epoch18, step658]: loss 0.033119
[epoch18, step659]: loss 0.033481
[epoch18, step660]: loss 0.033417
[epoch18, step661]: loss 0.036522
[epoch18, step662]: loss 0.030597
[epoch18, step663]: loss 0.030497
[epoch18, step664]: loss 0.033378
[epoch18, step665]: loss 0.038875
[epoch18, step666]: loss 0.033058
[epoch18, step667]: loss 0.036020
[epoch18, step668]: loss 0.034019
[epoch18, step669]: loss 0.033003
[epoch18, step670]: loss 0.036251
[epoch18, step671]: loss 0.031838
[epoch18, step672]: loss 0.036596
[epoch18, step673]: loss 0.033641
[epoch18, step674]: loss 0.030364
[epoch18, step675]: loss 0.031508
[epoch18, step676]: loss 0.035043
[epoch18, step677]: loss 0.033175
[epoch18, step678]: loss 0.030087
[epoch18, step679]: loss 0.033182
[epoch18, step680]: loss 0.036738
[epoch18, step681]: loss 0.029367
[epoch18, step682]: loss 0.033459
[epoch18, step683]: loss 0.034717
[epoch18, step684]: loss 0.031928
[epoch18, step685]: loss 0.032076
[epoch18, step686]: loss 0.033781
[epoch18, step687]: loss 0.034494
[epoch18, step688]: loss 0.033039
[epoch18, step689]: loss 0.031595
[epoch18, step690]: loss 0.035944
[epoch18, step691]: loss 0.035745
[epoch18, step692]: loss 0.033594
[epoch18, step693]: loss 0.036442
[epoch18, step694]: loss 0.029606
[epoch18, step695]: loss 0.034383
[epoch18, step696]: loss 0.033203
[epoch18, step697]: loss 0.036038
[epoch18, step698]: loss 0.032898
[epoch18, step699]: loss 0.032144
[epoch18, step700]: loss 0.034359
[epoch18, step701]: loss 0.035468
[epoch18, step702]: loss 0.030316
[epoch18, step703]: loss 0.035205
[epoch18, step704]: loss 0.035499
[epoch18, step705]: loss 0.032241
[epoch18, step706]: loss 0.032073
[epoch18, step707]: loss 0.032798
[epoch18, step708]: loss 0.034818
[epoch18, step709]: loss 0.034924
[epoch18, step710]: loss 0.033136
[epoch18, step711]: loss 0.034468
[epoch18, step712]: loss 0.033198
[epoch18, step713]: loss 0.033853
[epoch18, step714]: loss 0.031725
[epoch18, step715]: loss 0.031238
[epoch18, step716]: loss 0.035478
[epoch18, step717]: loss 0.031284
[epoch18, step718]: loss 0.034228
[epoch18, step719]: loss 0.041027
[epoch18, step720]: loss 0.031960
[epoch18, step721]: loss 0.031897
[epoch18, step722]: loss 0.039623
[epoch18, step723]: loss 0.034440
[epoch18, step724]: loss 0.032932
[epoch18, step725]: loss 0.037246
[epoch18, step726]: loss 0.028714
[epoch18, step727]: loss 0.034143
[epoch18, step728]: loss 0.035428
[epoch18, step729]: loss 0.028991
[epoch18, step730]: loss 0.032577
[epoch18, step731]: loss 0.036228
[epoch18, step732]: loss 0.033793
[epoch18, step733]: loss 0.030270
[epoch18, step734]: loss 0.030650
[epoch18, step735]: loss 0.034419
[epoch18, step736]: loss 0.032923
[epoch18, step737]: loss 0.033184
[epoch18, step738]: loss 0.028826
[epoch18, step739]: loss 0.037427
[epoch18, step740]: loss 0.035604
[epoch18, step741]: loss 0.034400
[epoch18, step742]: loss 0.032884
[epoch18, step743]: loss 0.032370
[epoch18, step744]: loss 0.032848
[epoch18, step745]: loss 0.033891
[epoch18, step746]: loss 0.034643
[epoch18, step747]: loss 0.035309
[epoch18, step748]: loss 0.032976
[epoch18, step749]: loss 0.038356
[epoch18, step750]: loss 0.036940
[epoch18, step751]: loss 0.029947
[epoch18, step752]: loss 0.031963
[epoch18, step753]: loss 0.032388
[epoch18, step754]: loss 0.033465
[epoch18, step755]: loss 0.035718
[epoch18, step756]: loss 0.029739
[epoch18, step757]: loss 0.030103
[epoch18, step758]: loss 0.035028
[epoch18, step759]: loss 0.030160
[epoch18, step760]: loss 0.033717
[epoch18, step761]: loss 0.034528
[epoch18, step762]: loss 0.029469
[epoch18, step763]: loss 0.032970
[epoch18, step764]: loss 0.033089
[epoch18, step765]: loss 0.032886
[epoch18, step766]: loss 0.031620
[epoch18, step767]: loss 0.035997
[epoch18, step768]: loss 0.030737
[epoch18, step769]: loss 0.035367
[epoch18, step770]: loss 0.037274
[epoch18, step771]: loss 0.030128
[epoch18, step772]: loss 0.035653
[epoch18, step773]: loss 0.034700
[epoch18, step774]: loss 0.032574
[epoch18, step775]: loss 0.032596
[epoch18, step776]: loss 0.034842
[epoch18, step777]: loss 0.031183
[epoch18, step778]: loss 0.038150
[epoch18, step779]: loss 0.032291
[epoch18, step780]: loss 0.030525
[epoch18, step781]: loss 0.035914
[epoch18, step782]: loss 0.033719
[epoch18, step783]: loss 0.029026
[epoch18, step784]: loss 0.031331
[epoch18, step785]: loss 0.032111
[epoch18, step786]: loss 0.032865
[epoch18, step787]: loss 0.034597
[epoch18, step788]: loss 0.033824
[epoch18, step789]: loss 0.033635
[epoch18, step790]: loss 0.030299
[epoch18, step791]: loss 0.036247
[epoch18, step792]: loss 0.034564
[epoch18, step793]: loss 0.036196
[epoch18, step794]: loss 0.029871
[epoch18, step795]: loss 0.033875
[epoch18, step796]: loss 0.035112
[epoch18, step797]: loss 0.034565
[epoch18, step798]: loss 0.033937
[epoch18, step799]: loss 0.031340
[epoch18, step800]: loss 0.033795
[epoch18, step801]: loss 0.033399
[epoch18, step802]: loss 0.031452
[epoch18, step803]: loss 0.033374
[epoch18, step804]: loss 0.036586
[epoch18, step805]: loss 0.035968
[epoch18, step806]: loss 0.030784
[epoch18, step807]: loss 0.031384
[epoch18, step808]: loss 0.034345
[epoch18, step809]: loss 0.030894
[epoch18, step810]: loss 0.031570
[epoch18, step811]: loss 0.034559
[epoch18, step812]: loss 0.034222
[epoch18, step813]: loss 0.031133
[epoch18, step814]: loss 0.034469
[epoch18, step815]: loss 0.033621
[epoch18, step816]: loss 0.032901
[epoch18, step817]: loss 0.031784
[epoch18, step818]: loss 0.030982
[epoch18, step819]: loss 0.034519
[epoch18, step820]: loss 0.030574
[epoch18, step821]: loss 0.029506
[epoch18, step822]: loss 0.038773
[epoch18, step823]: loss 0.031101
[epoch18, step824]: loss 0.035377
[epoch18, step825]: loss 0.034532
[epoch18, step826]: loss 0.029966
[epoch18, step827]: loss 0.033511
[epoch18, step828]: loss 0.036904
[epoch18, step829]: loss 0.034172
[epoch18, step830]: loss 0.027958
[epoch18, step831]: loss 0.032827
[epoch18, step832]: loss 0.032928
[epoch18, step833]: loss 0.037183
[epoch18, step834]: loss 0.033904
[epoch18, step835]: loss 0.030401
[epoch18, step836]: loss 0.033434
[epoch18, step837]: loss 0.032458
[epoch18, step838]: loss 0.036535
[epoch18, step839]: loss 0.036201
[epoch18, step840]: loss 0.028772
[epoch18, step841]: loss 0.032864
[epoch18, step842]: loss 0.035766
[epoch18, step843]: loss 0.034794
[epoch18, step844]: loss 0.034993
[epoch18, step845]: loss 0.030800
[epoch18, step846]: loss 0.037855
[epoch18, step847]: loss 0.035092
[epoch18, step848]: loss 0.028875
[epoch18, step849]: loss 0.032898
[epoch18, step850]: loss 0.033240
[epoch18, step851]: loss 0.032695
[epoch18, step852]: loss 0.031877
[epoch18, step853]: loss 0.038387
[epoch18, step854]: loss 0.033169
[epoch18, step855]: loss 0.033915
[epoch18, step856]: loss 0.028893
[epoch18, step857]: loss 0.035259
[epoch18, step858]: loss 0.033823
[epoch18, step859]: loss 0.030829
[epoch18, step860]: loss 0.033212
[epoch18, step861]: loss 0.032078
[epoch18, step862]: loss 0.029568
[epoch18, step863]: loss 0.031021
[epoch18, step864]: loss 0.036591
[epoch18, step865]: loss 0.032759
[epoch18, step866]: loss 0.034627
[epoch18, step867]: loss 0.033666
[epoch18, step868]: loss 0.035726
[epoch18, step869]: loss 0.030859
[epoch18, step870]: loss 0.036679
[epoch18, step871]: loss 0.033664
[epoch18, step872]: loss 0.034589
[epoch18, step873]: loss 0.032011
[epoch18, step874]: loss 0.032284
[epoch18, step875]: loss 0.035935
[epoch18, step876]: loss 0.034415
[epoch18, step877]: loss 0.023692
[epoch18, step878]: loss 0.031118
[epoch18, step879]: loss 0.035391
[epoch18, step880]: loss 0.032824
[epoch18, step881]: loss 0.032786
[epoch18, step882]: loss 0.031001
[epoch18, step883]: loss 0.031866
[epoch18, step884]: loss 0.037626
[epoch18, step885]: loss 0.037107
[epoch18, step886]: loss 0.036951
[epoch18, step887]: loss 0.035925
[epoch18, step888]: loss 0.032524
[epoch18, step889]: loss 0.033326
[epoch18, step890]: loss 0.033318
[epoch18, step891]: loss 0.032627
[epoch18, step892]: loss 0.031485
[epoch18, step893]: loss 0.034242
[epoch18, step894]: loss 0.034286
[epoch18, step895]: loss 0.029569
[epoch18, step896]: loss 0.034571
[epoch18, step897]: loss 0.036195
[epoch18, step898]: loss 0.032757
[epoch18, step899]: loss 0.031745
[epoch18, step900]: loss 0.035204
[epoch18, step901]: loss 0.035512
[epoch18, step902]: loss 0.031127
[epoch18, step903]: loss 0.035048
[epoch18, step904]: loss 0.035089
[epoch18, step905]: loss 0.033929
[epoch18, step906]: loss 0.028605
[epoch18, step907]: loss 0.034026
[epoch18, step908]: loss 0.033808
[epoch18, step909]: loss 0.033481
[epoch18, step910]: loss 0.029323
[epoch18, step911]: loss 0.031206
[epoch18, step912]: loss 0.033803
[epoch18, step913]: loss 0.033959
[epoch18, step914]: loss 0.038558
[epoch18, step915]: loss 0.031086
[epoch18, step916]: loss 0.032933
[epoch18, step917]: loss 0.033741
[epoch18, step918]: loss 0.038001
[epoch18, step919]: loss 0.031027
[epoch18, step920]: loss 0.037565
[epoch18, step921]: loss 0.031691
[epoch18, step922]: loss 0.030966
[epoch18, step923]: loss 0.033589
[epoch18, step924]: loss 0.028978
[epoch18, step925]: loss 0.032853
[epoch18, step926]: loss 0.034153
[epoch18, step927]: loss 0.035687
[epoch18, step928]: loss 0.032163
[epoch18, step929]: loss 0.035224
[epoch18, step930]: loss 0.034082
[epoch18, step931]: loss 0.036832
[epoch18, step932]: loss 0.029445
[epoch18, step933]: loss 0.035564
[epoch18, step934]: loss 0.033300
[epoch18, step935]: loss 0.031227
[epoch18, step936]: loss 0.030090
[epoch18, step937]: loss 0.033274
[epoch18, step938]: loss 0.036687
[epoch18, step939]: loss 0.028987
[epoch18, step940]: loss 0.033432
[epoch18, step941]: loss 0.035258
[epoch18, step942]: loss 0.033768
[epoch18, step943]: loss 0.033935
[epoch18, step944]: loss 0.035953
[epoch18, step945]: loss 0.031112
[epoch18, step946]: loss 0.034040
[epoch18, step947]: loss 0.034621
[epoch18, step948]: loss 0.033781
[epoch18, step949]: loss 0.031297
[epoch18, step950]: loss 0.034850
[epoch18, step951]: loss 0.037879
[epoch18, step952]: loss 0.034644
[epoch18, step953]: loss 0.036033
[epoch18, step954]: loss 0.031793
[epoch18, step955]: loss 0.041837
[epoch18, step956]: loss 0.060277
[epoch18, step957]: loss 0.053208
[epoch18, step958]: loss 0.053095
[epoch18, step959]: loss 0.055685
[epoch18, step960]: loss 0.051626
[epoch18, step961]: loss 0.053649
[epoch18, step962]: loss 0.052444
[epoch18, step963]: loss 0.051632
[epoch18, step964]: loss 0.050789
[epoch18, step965]: loss 0.052825
[epoch18, step966]: loss 0.048703
[epoch18, step967]: loss 0.049154
[epoch18, step968]: loss 0.050662
[epoch18, step969]: loss 0.048457
[epoch18, step970]: loss 0.048530
[epoch18, step971]: loss 0.047523
[epoch18, step972]: loss 0.048771
[epoch18, step973]: loss 0.047392
[epoch18, step974]: loss 0.049364
[epoch18, step975]: loss 0.046493
[epoch18, step976]: loss 0.047767
[epoch18, step977]: loss 0.049837
[epoch18, step978]: loss 0.046485
[epoch18, step979]: loss 0.046927
[epoch18, step980]: loss 0.046146
[epoch18, step981]: loss 0.047992
[epoch18, step982]: loss 0.047260
[epoch18, step983]: loss 0.048563
[epoch18, step984]: loss 0.045517
[epoch18, step985]: loss 0.047340
[epoch18, step986]: loss 0.049476
[epoch18, step987]: loss 0.045976
[epoch18, step988]: loss 0.046846
[epoch18, step989]: loss 0.046624
[epoch18, step990]: loss 0.047389
[epoch18, step991]: loss 0.046972
[epoch18, step992]: loss 0.048111
[epoch18, step993]: loss 0.046082
[epoch18, step994]: loss 0.046523
[epoch18, step995]: loss 0.048427
[epoch18, step996]: loss 0.045542
[epoch18, step997]: loss 0.046630
[epoch18, step998]: loss 0.046444
[epoch18, step999]: loss 0.047375
[epoch18, step1000]: loss 0.046723
[epoch18, step1001]: loss 0.048130
[epoch18, step1002]: loss 0.045561
[epoch18, step1003]: loss 0.046447
[epoch18, step1004]: loss 0.048375
[epoch18, step1005]: loss 0.044918
[epoch18, step1006]: loss 0.046333
[epoch18, step1007]: loss 0.045860
[epoch18, step1008]: loss 0.047140
[epoch18, step1009]: loss 0.046207
[epoch18, step1010]: loss 0.048213
[epoch18, step1011]: loss 0.045466
[epoch18, step1012]: loss 0.046676
[epoch18, step1013]: loss 0.048378
[epoch18, step1014]: loss 0.046087
[epoch18, step1015]: loss 0.046384
[epoch18, step1016]: loss 0.045730
[epoch18, step1017]: loss 0.046778
[epoch18, step1018]: loss 0.045895
[epoch18, step1019]: loss 0.048024
[epoch18, step1020]: loss 0.045299
[epoch18, step1021]: loss 0.046456
[epoch18, step1022]: loss 0.047875
[epoch18, step1023]: loss 0.045397
[epoch18, step1024]: loss 0.046392
[epoch18, step1025]: loss 0.045781
[epoch18, step1026]: loss 0.046637
[epoch18, step1027]: loss 0.045588
[epoch18, step1028]: loss 0.047868
[epoch18, step1029]: loss 0.045189
[epoch18, step1030]: loss 0.046178
[epoch18, step1031]: loss 0.047366
[epoch18, step1032]: loss 0.045329
[epoch18, step1033]: loss 0.045949
[epoch18, step1034]: loss 0.045822
[epoch18, step1035]: loss 0.046569
[epoch18, step1036]: loss 0.046159
[epoch18, step1037]: loss 0.047603
[epoch18, step1038]: loss 0.045153
[epoch18, step1039]: loss 0.046421
[epoch18, step1040]: loss 0.047563
[epoch18, step1041]: loss 0.045311
[epoch18, step1042]: loss 0.045243
[epoch18, step1043]: loss 0.045623
[epoch18, step1044]: loss 0.046812
[epoch18, step1045]: loss 0.045886
[epoch18, step1046]: loss 0.047785
[epoch18, step1047]: loss 0.045145
[epoch18, step1048]: loss 0.046223
[epoch18, step1049]: loss 0.047859
[epoch18, step1050]: loss 0.045402
[epoch18, step1051]: loss 0.045920
[epoch18, step1052]: loss 0.046215
[epoch18, step1053]: loss 0.047159
[epoch18, step1054]: loss 0.045960
[epoch18, step1055]: loss 0.047348
[epoch18, step1056]: loss 0.044641
[epoch18, step1057]: loss 0.046677
[epoch18, step1058]: loss 0.048115
[epoch18, step1059]: loss 0.045395
[epoch18, step1060]: loss 0.045769
[epoch18, step1061]: loss 0.045338
[epoch18, step1062]: loss 0.047057
[epoch18, step1063]: loss 0.045899
[epoch18, step1064]: loss 0.047671
[epoch18, step1065]: loss 0.045228
[epoch18, step1066]: loss 0.046139
[epoch18, step1067]: loss 0.047739
[epoch18, step1068]: loss 0.044683
[epoch18, step1069]: loss 0.045125
[epoch18, step1070]: loss 0.045580
[epoch18, step1071]: loss 0.046989
[epoch18, step1072]: loss 0.046105
[epoch18, step1073]: loss 0.047391
[epoch18, step1074]: loss 0.045271
[epoch18, step1075]: loss 0.046338
[epoch18, step1076]: loss 0.047649
[epoch18, step1077]: loss 0.044888
[epoch18, step1078]: loss 0.045718
[epoch18, step1079]: loss 0.046088
[epoch18, step1080]: loss 0.046761
[epoch18, step1081]: loss 0.045854
[epoch18, step1082]: loss 0.047407
[epoch18, step1083]: loss 0.045651
[epoch18, step1084]: loss 0.046238
[epoch18, step1085]: loss 0.047444
[epoch18, step1086]: loss 0.045116
[epoch18, step1087]: loss 0.045852
[epoch18, step1088]: loss 0.045504
[epoch18, step1089]: loss 0.046845
[epoch18, step1090]: loss 0.046030
[epoch18, step1091]: loss 0.047733
[epoch18, step1092]: loss 0.045171
[epoch18, step1093]: loss 0.046160
[epoch18, step1094]: loss 0.047017
[epoch18, step1095]: loss 0.044725
[epoch18, step1096]: loss 0.045542
[epoch18, step1097]: loss 0.045541
[epoch18, step1098]: loss 0.046696
[epoch18, step1099]: loss 0.045513
[epoch18, step1100]: loss 0.047874
[epoch18, step1101]: loss 0.045555
[epoch18, step1102]: loss 0.046120
[epoch18, step1103]: loss 0.047299
[epoch18, step1104]: loss 0.044803
[epoch18, step1105]: loss 0.045733
[epoch18, step1106]: loss 0.044899
[epoch18, step1107]: loss 0.046854
[epoch18, step1108]: loss 0.045450
[epoch18, step1109]: loss 0.047571
[epoch18, step1110]: loss 0.045270
[epoch18, step1111]: loss 0.046177
[epoch18, step1112]: loss 0.047701
[epoch18, step1113]: loss 0.044620
[epoch18, step1114]: loss 0.045866
[epoch18, step1115]: loss 0.045438
[epoch18, step1116]: loss 0.046693
[epoch18, step1117]: loss 0.045750
[epoch18, step1118]: loss 0.047452
[epoch18, step1119]: loss 0.045374
[epoch18, step1120]: loss 0.046068
[epoch18, step1121]: loss 0.047474
[epoch18, step1122]: loss 0.044883
[epoch18, step1123]: loss 0.045206
[epoch18, step1124]: loss 0.045923
[epoch18, step1125]: loss 0.046788
[epoch18, step1126]: loss 0.046295
[epoch18, step1127]: loss 0.047488
[epoch18, step1128]: loss 0.045354
[epoch18, step1129]: loss 0.046154
[epoch18, step1130]: loss 0.047705
[epoch18, step1131]: loss 0.045313
[epoch18, step1132]: loss 0.045887
[epoch18, step1133]: loss 0.045205
[epoch18, step1134]: loss 0.046473
[epoch18, step1135]: loss 0.046004
[epoch18, step1136]: loss 0.047802
[epoch18, step1137]: loss 0.044680
[epoch18, step1138]: loss 0.046162
[epoch18, step1139]: loss 0.047573
[epoch18, step1140]: loss 0.044261
[epoch18, step1141]: loss 0.045279
[epoch18, step1142]: loss 0.045254
[epoch18, step1143]: loss 0.046371
[epoch18, step1144]: loss 0.045790
[epoch18, step1145]: loss 0.047141
[epoch18, step1146]: loss 0.044393
[epoch18, step1147]: loss 0.046503
[epoch18, step1148]: loss 0.047504
[epoch18, step1149]: loss 0.044345
[epoch18, step1150]: loss 0.045545
[epoch18, step1151]: loss 0.045770
[epoch18, step1152]: loss 0.046826
[epoch18, step1153]: loss 0.045324
[epoch18, step1154]: loss 0.047558
[epoch18, step1155]: loss 0.045315
[epoch18, step1156]: loss 0.045760
[epoch18, step1157]: loss 0.047295
[epoch18, step1158]: loss 0.044877
[epoch18, step1159]: loss 0.045592
[epoch18, step1160]: loss 0.045890
[epoch18, step1161]: loss 0.046749
[epoch18, step1162]: loss 0.045521
[epoch18, step1163]: loss 0.047141
[epoch18, step1164]: loss 0.044726
[epoch18, step1165]: loss 0.046583
[epoch18, step1166]: loss 0.047371
[epoch18, step1167]: loss 0.044232
[epoch18, step1168]: loss 0.045572
[epoch18, step1169]: loss 0.045284
[epoch18, step1170]: loss 0.046658
[epoch18, step1171]: loss 0.045408
[epoch18, step1172]: loss 0.047449
[epoch18, step1173]: loss 0.045125
[epoch18, step1174]: loss 0.046143
[epoch18, step1175]: loss 0.047471
[epoch18, step1176]: loss 0.044497
[epoch18, step1177]: loss 0.045558
[epoch18, step1178]: loss 0.045339
[epoch18, step1179]: loss 0.046516
[epoch18, step1180]: loss 0.045630
[epoch18, step1181]: loss 0.047667
[epoch18, step1182]: loss 0.044497
[epoch18, step1183]: loss 0.046384
[epoch18, step1184]: loss 0.047066
[epoch18, step1185]: loss 0.045263
[epoch18, step1186]: loss 0.044943
[epoch18, step1187]: loss 0.044994
[epoch18, step1188]: loss 0.046082
[epoch18, step1189]: loss 0.045224
[epoch18, step1190]: loss 0.047177
[epoch18, step1191]: loss 0.045559
[epoch18, step1192]: loss 0.046021
[epoch18, step1193]: loss 0.047112
[epoch18, step1194]: loss 0.044657
[epoch18, step1195]: loss 0.044906
[epoch18, step1196]: loss 0.044887
[epoch18, step1197]: loss 0.046754
[epoch18, step1198]: loss 0.045370
[epoch18, step1199]: loss 0.047075
[epoch18, step1200]: loss 0.044554
[epoch18, step1201]: loss 0.046105
[epoch18, step1202]: loss 0.047776
[epoch18, step1203]: loss 0.045104
[epoch18, step1204]: loss 0.044976
[epoch18, step1205]: loss 0.044859
[epoch18, step1206]: loss 0.046207
[epoch18, step1207]: loss 0.045445
[epoch18, step1208]: loss 0.047305
[epoch18, step1209]: loss 0.043893
[epoch18, step1210]: loss 0.046198
[epoch18, step1211]: loss 0.046974
[epoch18, step1212]: loss 0.044954
[epoch18, step1213]: loss 0.045268
[epoch18, step1214]: loss 0.045535
[epoch18, step1215]: loss 0.046710
[epoch18, step1216]: loss 0.045196
[epoch18, step1217]: loss 0.047627
[epoch18, step1218]: loss 0.044531
[epoch18, step1219]: loss 0.046408
[epoch18, step1220]: loss 0.047333
[epoch18, step1221]: loss 0.044052
[epoch18, step1222]: loss 0.045488
[epoch18, step1223]: loss 0.045065
[epoch18, step1224]: loss 0.046726
[epoch18, step1225]: loss 0.045337
[epoch18, step1226]: loss 0.047182
[epoch18, step1227]: loss 0.044330
[epoch18, step1228]: loss 0.045667
[epoch18, step1229]: loss 0.047245
[epoch18, step1230]: loss 0.045076
[epoch18, step1231]: loss 0.045350
[epoch18, step1232]: loss 0.045897
[epoch18, step1233]: loss 0.046224
[epoch18, step1234]: loss 0.045201
[epoch18, step1235]: loss 0.047534
[epoch18, step1236]: loss 0.045326
[epoch18, step1237]: loss 0.045703
[epoch18, step1238]: loss 0.047081
[epoch18, step1239]: loss 0.044826
[epoch18, step1240]: loss 0.045500
[epoch18, step1241]: loss 0.045355
[epoch18, step1242]: loss 0.046196
[epoch18, step1243]: loss 0.045294
[epoch18, step1244]: loss 0.047431
[epoch18, step1245]: loss 0.044853
[epoch18, step1246]: loss 0.046311
[epoch18, step1247]: loss 0.046670
[epoch18, step1248]: loss 0.044958
[epoch18, step1249]: loss 0.045706
[epoch18, step1250]: loss 0.045105
[epoch18, step1251]: loss 0.046679
[epoch18, step1252]: loss 0.045864
[epoch18, step1253]: loss 0.047410
[epoch18, step1254]: loss 0.044911
[epoch18, step1255]: loss 0.045874
[epoch18, step1256]: loss 0.047390
[epoch18, step1257]: loss 0.044628
[epoch18, step1258]: loss 0.045485
[epoch18, step1259]: loss 0.044955
[epoch18, step1260]: loss 0.046278
[epoch18, step1261]: loss 0.045151
[epoch18, step1262]: loss 0.046533
[epoch18, step1263]: loss 0.044970
[epoch18, step1264]: loss 0.045712
[epoch18, step1265]: loss 0.046584
[epoch18, step1266]: loss 0.044680
[epoch18, step1267]: loss 0.045451
[epoch18, step1268]: loss 0.045497
[epoch18, step1269]: loss 0.046317
[epoch18, step1270]: loss 0.045278
[epoch18, step1271]: loss 0.047551
[epoch18, step1272]: loss 0.045257
[epoch18, step1273]: loss 0.046159
[epoch18, step1274]: loss 0.047055
[epoch18, step1275]: loss 0.045394
[epoch18, step1276]: loss 0.045495
[epoch18, step1277]: loss 0.045017
[epoch18, step1278]: loss 0.046854
[epoch18, step1279]: loss 0.045383
[epoch18, step1280]: loss 0.047366
[epoch18, step1281]: loss 0.044838
[epoch18, step1282]: loss 0.045672
[epoch18, step1283]: loss 0.046792
[epoch18, step1284]: loss 0.043967
[epoch18, step1285]: loss 0.045679
[epoch18, step1286]: loss 0.044568
[epoch18, step1287]: loss 0.046517
[epoch18, step1288]: loss 0.045595
[epoch18, step1289]: loss 0.047645
[epoch18, step1290]: loss 0.045073
[epoch18, step1291]: loss 0.045597
[epoch18, step1292]: loss 0.047664
[epoch18, step1293]: loss 0.043802
[epoch18, step1294]: loss 0.045292
[epoch18, step1295]: loss 0.045706
[epoch18, step1296]: loss 0.046296
[epoch18, step1297]: loss 0.045248
[epoch18, step1298]: loss 0.048045
[epoch18, step1299]: loss 0.045012
[epoch18, step1300]: loss 0.046374
[epoch18, step1301]: loss 0.047082
[epoch18, step1302]: loss 0.044773
[epoch18, step1303]: loss 0.045665
[epoch18, step1304]: loss 0.044639
[epoch18, step1305]: loss 0.046652
[epoch18, step1306]: loss 0.045006
[epoch18, step1307]: loss 0.046872
[epoch18, step1308]: loss 0.045006
[epoch18, step1309]: loss 0.045347
[epoch18, step1310]: loss 0.047033
[epoch18, step1311]: loss 0.043704
[epoch18, step1312]: loss 0.045821
[epoch18, step1313]: loss 0.045147
[epoch18, step1314]: loss 0.046043
[epoch18, step1315]: loss 0.044915
[epoch18, step1316]: loss 0.047887
[epoch18, step1317]: loss 0.044541
[epoch18, step1318]: loss 0.045577
[epoch18, step1319]: loss 0.046832
[epoch18, step1320]: loss 0.045082
[epoch18, step1321]: loss 0.045408
[epoch18, step1322]: loss 0.045339
[epoch18, step1323]: loss 0.046379
[epoch18, step1324]: loss 0.045180
[epoch18, step1325]: loss 0.047415
[epoch18, step1326]: loss 0.044782
[epoch18, step1327]: loss 0.045788
[epoch18, step1328]: loss 0.047102
[epoch18, step1329]: loss 0.044821
[epoch18, step1330]: loss 0.045452
[epoch18, step1331]: loss 0.044898
[epoch18, step1332]: loss 0.046433
[epoch18, step1333]: loss 0.044688
[epoch18, step1334]: loss 0.047294
[epoch18, step1335]: loss 0.045374
[epoch18, step1336]: loss 0.045711
[epoch18, step1337]: loss 0.046611
[epoch18, step1338]: loss 0.043976
[epoch18, step1339]: loss 0.045419
[epoch18, step1340]: loss 0.044875
[epoch18, step1341]: loss 0.046187
[epoch18, step1342]: loss 0.044875
[epoch18, step1343]: loss 0.047178
[epoch18, step1344]: loss 0.044703
[epoch18, step1345]: loss 0.045611
[epoch18, step1346]: loss 0.046891
[epoch18, step1347]: loss 0.045004
[epoch18, step1348]: loss 0.044952
[epoch18, step1349]: loss 0.045408
[epoch18, step1350]: loss 0.046422
[epoch18, step1351]: loss 0.045226
[epoch18, step1352]: loss 0.046987
[epoch18, step1353]: loss 0.044721
[epoch18, step1354]: loss 0.045783
[epoch18, step1355]: loss 0.047147
[epoch18, step1356]: loss 0.044604
[epoch18, step1357]: loss 0.045005
[epoch18, step1358]: loss 0.044794
[epoch18, step1359]: loss 0.045907
[epoch18, step1360]: loss 0.045034
[epoch18, step1361]: loss 0.047273
[epoch18, step1362]: loss 0.045149
[epoch18, step1363]: loss 0.045915
[epoch18, step1364]: loss 0.046804
[epoch18, step1365]: loss 0.044459
[epoch18, step1366]: loss 0.045088
[epoch18, step1367]: loss 0.044417
[epoch18, step1368]: loss 0.046404
[epoch18, step1369]: loss 0.045228
[epoch18, step1370]: loss 0.046943
[epoch18, step1371]: loss 0.044953
[epoch18, step1372]: loss 0.045526
[epoch18, step1373]: loss 0.046878
[epoch18, step1374]: loss 0.044993
[epoch18, step1375]: loss 0.045630
[epoch18, step1376]: loss 0.045056
[epoch18, step1377]: loss 0.045710
[epoch18, step1378]: loss 0.045348
[epoch18, step1379]: loss 0.046931
[epoch18, step1380]: loss 0.044523
[epoch18, step1381]: loss 0.045711
[epoch18, step1382]: loss 0.047104
[epoch18, step1383]: loss 0.044140
[epoch18, step1384]: loss 0.044958
[epoch18, step1385]: loss 0.044499
[epoch18, step1386]: loss 0.046172
[epoch18, step1387]: loss 0.045233
[epoch18, step1388]: loss 0.046512
[epoch18, step1389]: loss 0.044033
[epoch18, step1390]: loss 0.045648
[epoch18, step1391]: loss 0.046703
[epoch18, step1392]: loss 0.044586
[epoch18, step1393]: loss 0.045206
[epoch18, step1394]: loss 0.045123
[epoch18, step1395]: loss 0.046102
[epoch18, step1396]: loss 0.044820
[epoch18, step1397]: loss 0.046817
[epoch18, step1398]: loss 0.044446
[epoch18, step1399]: loss 0.046233
[epoch18, step1400]: loss 0.047104
[epoch18, step1401]: loss 0.044183
[epoch18, step1402]: loss 0.045136
[epoch18, step1403]: loss 0.044324
[epoch18, step1404]: loss 0.045741
[epoch18, step1405]: loss 0.044817
[epoch18, step1406]: loss 0.046863
[epoch18, step1407]: loss 0.045344
[epoch18, step1408]: loss 0.045367
[epoch18, step1409]: loss 0.046649
[epoch18, step1410]: loss 0.044096
[epoch18, step1411]: loss 0.044563
[epoch18, step1412]: loss 0.045017
[epoch18, step1413]: loss 0.046283
[epoch18, step1414]: loss 0.044748
[epoch18, step1415]: loss 0.046763
[epoch18, step1416]: loss 0.044213
[epoch18, step1417]: loss 0.045547
[epoch18, step1418]: loss 0.046696
[epoch18, step1419]: loss 0.044888
[epoch18, step1420]: loss 0.045370
[epoch18, step1421]: loss 0.045093
[epoch18, step1422]: loss 0.046193
[epoch18, step1423]: loss 0.044893
[epoch18, step1424]: loss 0.047131
[epoch18, step1425]: loss 0.043987
[epoch18, step1426]: loss 0.045720
[epoch18, step1427]: loss 0.047177
[epoch18, step1428]: loss 0.045534
[epoch18, step1429]: loss 0.045066
[epoch18, step1430]: loss 0.044937
[epoch18, step1431]: loss 0.046040
[epoch18, step1432]: loss 0.044747
[epoch18, step1433]: loss 0.047123
[epoch18, step1434]: loss 0.044351
[epoch18, step1435]: loss 0.045701
[epoch18, step1436]: loss 0.047197
[epoch18, step1437]: loss 0.044257
[epoch18, step1438]: loss 0.045424
[epoch18, step1439]: loss 0.044889
[epoch18, step1440]: loss 0.045929
[epoch18, step1441]: loss 0.045309
[epoch18, step1442]: loss 0.046566
[epoch18, step1443]: loss 0.044598
[epoch18, step1444]: loss 0.045027
[epoch18, step1445]: loss 0.046998
[epoch18, step1446]: loss 0.044229
[epoch18, step1447]: loss 0.045600
[epoch18, step1448]: loss 0.044919
[epoch18, step1449]: loss 0.045594
[epoch18, step1450]: loss 0.045351
[epoch18, step1451]: loss 0.047207
[epoch18, step1452]: loss 0.044598
[epoch18, step1453]: loss 0.046481
[epoch18, step1454]: loss 0.047131
[epoch18, step1455]: loss 0.045018
[epoch18, step1456]: loss 0.045186
[epoch18, step1457]: loss 0.044916
[epoch18, step1458]: loss 0.046148
[epoch18, step1459]: loss 0.045046
[epoch18, step1460]: loss 0.047197
[epoch18, step1461]: loss 0.044514
[epoch18, step1462]: loss 0.045795
[epoch18, step1463]: loss 0.046941
[epoch18, step1464]: loss 0.044165
[epoch18, step1465]: loss 0.044858
[epoch18, step1466]: loss 0.044346
[epoch18, step1467]: loss 0.045908
[epoch18, step1468]: loss 0.044578
[epoch18, step1469]: loss 0.046916
[epoch18, step1470]: loss 0.044357
[epoch18, step1471]: loss 0.045302
[epoch18, step1472]: loss 0.046995
[epoch18, step1473]: loss 0.043938
[epoch18, step1474]: loss 0.045586
[epoch18, step1475]: loss 0.044937
[epoch18, step1476]: loss 0.046376
[epoch18, step1477]: loss 0.045406
[epoch18, step1478]: loss 0.047847
[epoch18, step1479]: loss 0.044239
[epoch18, step1480]: loss 0.045854
[epoch18, step1481]: loss 0.046776
[epoch18, step1482]: loss 0.044109
[epoch18, step1483]: loss 0.045364
[epoch18, step1484]: loss 0.044921
[epoch18, step1485]: loss 0.046029
[epoch18, step1486]: loss 0.044282
[epoch18, step1487]: loss 0.046726
[epoch18, step1488]: loss 0.044494
[epoch18, step1489]: loss 0.045377
[epoch18, step1490]: loss 0.046689
[epoch18, step1491]: loss 0.044501
[epoch18, step1492]: loss 0.045220
[epoch18, step1493]: loss 0.044861
[epoch18, step1494]: loss 0.046305
[epoch18, step1495]: loss 0.044969
[epoch18, step1496]: loss 0.046366
[epoch18, step1497]: loss 0.044936
[epoch18, step1498]: loss 0.045662
[epoch18, step1499]: loss 0.046657
[epoch18, step1500]: loss 0.045096
[epoch18, step1501]: loss 0.045336
[epoch18, step1502]: loss 0.044848
[epoch18, step1503]: loss 0.046486
[epoch18, step1504]: loss 0.044612
[epoch18, step1505]: loss 0.047355
[epoch18, step1506]: loss 0.044046
[epoch18, step1507]: loss 0.045498
[epoch18, step1508]: loss 0.047320
[epoch18, step1509]: loss 0.044312
[epoch18, step1510]: loss 0.044641
[epoch18, step1511]: loss 0.045028
[epoch18, step1512]: loss 0.045896
[epoch18, step1513]: loss 0.044118
[epoch18, step1514]: loss 0.046848
[epoch18, step1515]: loss 0.044763
[epoch18, step1516]: loss 0.045419

[epoch18]: avg loss 0.043370

[epoch19, step1]: loss 0.043942
[epoch19, step2]: loss 0.046547
[epoch19, step3]: loss 0.046609
[epoch19, step4]: loss 0.044111
[epoch19, step5]: loss 0.045767
[epoch19, step6]: loss 0.046955
[epoch19, step7]: loss 0.043675
[epoch19, step8]: loss 0.046953
[epoch19, step9]: loss 0.043664
[epoch19, step10]: loss 0.045069
[epoch19, step11]: loss 0.047387
[epoch19, step12]: loss 0.047031
[epoch19, step13]: loss 0.043784
[epoch19, step14]: loss 0.046086
[epoch19, step15]: loss 0.046790
[epoch19, step16]: loss 0.043836
[epoch19, step17]: loss 0.047255
[epoch19, step18]: loss 0.044160
[epoch19, step19]: loss 0.045196
[epoch19, step20]: loss 0.047383
[epoch19, step21]: loss 0.046767
[epoch19, step22]: loss 0.043924
[epoch19, step23]: loss 0.045255
[epoch19, step24]: loss 0.046843
[epoch19, step25]: loss 0.042862
[epoch19, step26]: loss 0.046474
[epoch19, step27]: loss 0.043289
[epoch19, step28]: loss 0.044847
[epoch19, step29]: loss 0.046632
[epoch19, step30]: loss 0.047068
[epoch19, step31]: loss 0.043613
[epoch19, step32]: loss 0.045934
[epoch19, step33]: loss 0.047316
[epoch19, step34]: loss 0.043977
[epoch19, step35]: loss 0.047043
[epoch19, step36]: loss 0.043669
[epoch19, step37]: loss 0.044932
[epoch19, step38]: loss 0.046885
[epoch19, step39]: loss 0.046733
[epoch19, step40]: loss 0.044237
[epoch19, step41]: loss 0.045692
[epoch19, step42]: loss 0.046935
[epoch19, step43]: loss 0.043906
[epoch19, step44]: loss 0.047311
[epoch19, step45]: loss 0.043962
[epoch19, step46]: loss 0.045165
[epoch19, step47]: loss 0.046562
[epoch19, step48]: loss 0.046592
[epoch19, step49]: loss 0.042636
[epoch19, step50]: loss 0.045844
[epoch19, step51]: loss 0.046795
[epoch19, step52]: loss 0.043495
[epoch19, step53]: loss 0.047169
[epoch19, step54]: loss 0.043256
[epoch19, step55]: loss 0.045062
[epoch19, step56]: loss 0.047094
[epoch19, step57]: loss 0.047009
[epoch19, step58]: loss 0.043886
[epoch19, step59]: loss 0.045037
[epoch19, step60]: loss 0.047024
[epoch19, step61]: loss 0.042971
[epoch19, step62]: loss 0.046569
[epoch19, step63]: loss 0.043261
[epoch19, step64]: loss 0.044519
[epoch19, step65]: loss 0.047038
[epoch19, step66]: loss 0.046735
[epoch19, step67]: loss 0.044447
[epoch19, step68]: loss 0.045962
[epoch19, step69]: loss 0.046591
[epoch19, step70]: loss 0.043788
[epoch19, step71]: loss 0.046945
[epoch19, step72]: loss 0.043542
[epoch19, step73]: loss 0.044857
[epoch19, step74]: loss 0.046727
[epoch19, step75]: loss 0.046767
[epoch19, step76]: loss 0.044537
[epoch19, step77]: loss 0.045881
[epoch19, step78]: loss 0.046810
[epoch19, step79]: loss 0.043162
[epoch19, step80]: loss 0.047162
[epoch19, step81]: loss 0.043631
[epoch19, step82]: loss 0.044877
[epoch19, step83]: loss 0.046143
[epoch19, step84]: loss 0.046885
[epoch19, step85]: loss 0.043970
[epoch19, step86]: loss 0.045597
[epoch19, step87]: loss 0.047568
[epoch19, step88]: loss 0.042980
[epoch19, step89]: loss 0.046694
[epoch19, step90]: loss 0.044106
[epoch19, step91]: loss 0.044506
[epoch19, step92]: loss 0.047143
[epoch19, step93]: loss 0.046781
[epoch19, step94]: loss 0.044247
[epoch19, step95]: loss 0.046605
[epoch19, step96]: loss 0.046781
[epoch19, step97]: loss 0.044398
[epoch19, step98]: loss 0.047812
[epoch19, step99]: loss 0.043966
[epoch19, step100]: loss 0.044309
[epoch19, step101]: loss 0.047397
[epoch19, step102]: loss 0.047015
[epoch19, step103]: loss 0.043915
[epoch19, step104]: loss 0.045975
[epoch19, step105]: loss 0.047141
[epoch19, step106]: loss 0.043281
[epoch19, step107]: loss 0.047177
[epoch19, step108]: loss 0.044047
[epoch19, step109]: loss 0.044467
[epoch19, step110]: loss 0.047709
[epoch19, step111]: loss 0.046952
[epoch19, step112]: loss 0.044273
[epoch19, step113]: loss 0.046553
[epoch19, step114]: loss 0.046733
[epoch19, step115]: loss 0.043535
[epoch19, step116]: loss 0.047503
[epoch19, step117]: loss 0.043451
[epoch19, step118]: loss 0.045426
[epoch19, step119]: loss 0.046936
[epoch19, step120]: loss 0.046698
[epoch19, step121]: loss 0.043820
[epoch19, step122]: loss 0.045481
[epoch19, step123]: loss 0.046962
[epoch19, step124]: loss 0.043702
[epoch19, step125]: loss 0.046994
[epoch19, step126]: loss 0.043615
[epoch19, step127]: loss 0.044524
[epoch19, step128]: loss 0.046470
[epoch19, step129]: loss 0.046376
[epoch19, step130]: loss 0.043716
[epoch19, step131]: loss 0.045130
[epoch19, step132]: loss 0.046736
[epoch19, step133]: loss 0.042806
[epoch19, step134]: loss 0.046484
[epoch19, step135]: loss 0.044108
[epoch19, step136]: loss 0.045200
[epoch19, step137]: loss 0.046766
[epoch19, step138]: loss 0.046906
[epoch19, step139]: loss 0.043829
[epoch19, step140]: loss 0.046124
[epoch19, step141]: loss 0.046788
[epoch19, step142]: loss 0.043609
[epoch19, step143]: loss 0.046798
[epoch19, step144]: loss 0.043926
[epoch19, step145]: loss 0.045026
[epoch19, step146]: loss 0.047054
[epoch19, step147]: loss 0.047365
[epoch19, step148]: loss 0.043866
[epoch19, step149]: loss 0.045435
[epoch19, step150]: loss 0.046398
[epoch19, step151]: loss 0.042948
[epoch19, step152]: loss 0.046774
[epoch19, step153]: loss 0.043530
[epoch19, step154]: loss 0.044583
[epoch19, step155]: loss 0.046506
[epoch19, step156]: loss 0.046602
[epoch19, step157]: loss 0.043948
[epoch19, step158]: loss 0.045593
[epoch19, step159]: loss 0.047082
[epoch19, step160]: loss 0.043851
[epoch19, step161]: loss 0.047010
[epoch19, step162]: loss 0.044100
[epoch19, step163]: loss 0.044771
[epoch19, step164]: loss 0.046926
[epoch19, step165]: loss 0.047094
[epoch19, step166]: loss 0.043633
[epoch19, step167]: loss 0.045459
[epoch19, step168]: loss 0.047090
[epoch19, step169]: loss 0.043287
[epoch19, step170]: loss 0.046960
[epoch19, step171]: loss 0.043885
[epoch19, step172]: loss 0.044688
[epoch19, step173]: loss 0.047082
[epoch19, step174]: loss 0.046551
[epoch19, step175]: loss 0.044224
[epoch19, step176]: loss 0.045762
[epoch19, step177]: loss 0.046850
[epoch19, step178]: loss 0.043029
[epoch19, step179]: loss 0.046248
[epoch19, step180]: loss 0.043741
[epoch19, step181]: loss 0.044639
[epoch19, step182]: loss 0.046660
[epoch19, step183]: loss 0.047115
[epoch19, step184]: loss 0.044610
[epoch19, step185]: loss 0.045557
[epoch19, step186]: loss 0.046835
[epoch19, step187]: loss 0.043685
[epoch19, step188]: loss 0.046506
[epoch19, step189]: loss 0.044009
[epoch19, step190]: loss 0.044520
[epoch19, step191]: loss 0.046405
[epoch19, step192]: loss 0.047183
[epoch19, step193]: loss 0.042686
[epoch19, step194]: loss 0.045050
[epoch19, step195]: loss 0.046838
[epoch19, step196]: loss 0.042976
[epoch19, step197]: loss 0.046609
[epoch19, step198]: loss 0.042846
[epoch19, step199]: loss 0.044632
[epoch19, step200]: loss 0.046784
[epoch19, step201]: loss 0.046935
[epoch19, step202]: loss 0.043677
[epoch19, step203]: loss 0.045493
[epoch19, step204]: loss 0.046793
[epoch19, step205]: loss 0.042874
[epoch19, step206]: loss 0.046473
[epoch19, step207]: loss 0.043393
[epoch19, step208]: loss 0.044877
[epoch19, step209]: loss 0.046570
[epoch19, step210]: loss 0.047157
[epoch19, step211]: loss 0.044524
[epoch19, step212]: loss 0.045601
[epoch19, step213]: loss 0.046607
[epoch19, step214]: loss 0.043231
[epoch19, step215]: loss 0.046775
[epoch19, step216]: loss 0.043953
[epoch19, step217]: loss 0.044015
[epoch19, step218]: loss 0.046923
[epoch19, step219]: loss 0.046682
[epoch19, step220]: loss 0.044534
[epoch19, step221]: loss 0.045883
[epoch19, step222]: loss 0.046716
[epoch19, step223]: loss 0.043539
[epoch19, step224]: loss 0.046791
[epoch19, step225]: loss 0.043488
[epoch19, step226]: loss 0.044577
[epoch19, step227]: loss 0.046117
[epoch19, step228]: loss 0.046957
[epoch19, step229]: loss 0.043605
[epoch19, step230]: loss 0.045597
[epoch19, step231]: loss 0.046747
[epoch19, step232]: loss 0.042487
[epoch19, step233]: loss 0.046196
[epoch19, step234]: loss 0.043370
[epoch19, step235]: loss 0.044892
[epoch19, step236]: loss 0.046496
[epoch19, step237]: loss 0.046741
[epoch19, step238]: loss 0.043309
[epoch19, step239]: loss 0.044943
[epoch19, step240]: loss 0.046360
[epoch19, step241]: loss 0.043703
[epoch19, step242]: loss 0.046662
[epoch19, step243]: loss 0.044179
[epoch19, step244]: loss 0.044327
[epoch19, step245]: loss 0.046716
[epoch19, step246]: loss 0.046927
[epoch19, step247]: loss 0.044302
[epoch19, step248]: loss 0.045640
[epoch19, step249]: loss 0.046422
[epoch19, step250]: loss 0.043201
[epoch19, step251]: loss 0.047379
[epoch19, step252]: loss 0.043799
[epoch19, step253]: loss 0.044420
[epoch19, step254]: loss 0.046342
[epoch19, step255]: loss 0.046621
[epoch19, step256]: loss 0.044044
[epoch19, step257]: loss 0.045572
[epoch19, step258]: loss 0.046757
[epoch19, step259]: loss 0.042718
[epoch19, step260]: loss 0.046436
[epoch19, step261]: loss 0.043805
[epoch19, step262]: loss 0.044944
[epoch19, step263]: loss 0.046013
[epoch19, step264]: loss 0.046483
[epoch19, step265]: loss 0.044485
[epoch19, step266]: loss 0.045322
[epoch19, step267]: loss 0.046265
[epoch19, step268]: loss 0.043654
[epoch19, step269]: loss 0.046653
[epoch19, step270]: loss 0.043755
[epoch19, step271]: loss 0.045145
[epoch19, step272]: loss 0.046498
[epoch19, step273]: loss 0.046856
[epoch19, step274]: loss 0.044253
[epoch19, step275]: loss 0.045040
[epoch19, step276]: loss 0.046438
[epoch19, step277]: loss 0.043438
[epoch19, step278]: loss 0.046615
[epoch19, step279]: loss 0.043325
[epoch19, step280]: loss 0.044820
[epoch19, step281]: loss 0.046291
[epoch19, step282]: loss 0.046937
[epoch19, step283]: loss 0.043606
[epoch19, step284]: loss 0.045136
[epoch19, step285]: loss 0.046794
[epoch19, step286]: loss 0.042826
[epoch19, step287]: loss 0.046811
[epoch19, step288]: loss 0.043290
[epoch19, step289]: loss 0.045035
[epoch19, step290]: loss 0.047060
[epoch19, step291]: loss 0.046778
[epoch19, step292]: loss 0.043686
[epoch19, step293]: loss 0.045746
[epoch19, step294]: loss 0.046071
[epoch19, step295]: loss 0.043329
[epoch19, step296]: loss 0.048036
[epoch19, step297]: loss 0.043581
[epoch19, step298]: loss 0.044694
[epoch19, step299]: loss 0.046370
[epoch19, step300]: loss 0.046812
[epoch19, step301]: loss 0.044156
[epoch19, step302]: loss 0.045810
[epoch19, step303]: loss 0.046765
[epoch19, step304]: loss 0.042515
[epoch19, step305]: loss 0.046674
[epoch19, step306]: loss 0.043462
[epoch19, step307]: loss 0.044273
[epoch19, step308]: loss 0.047234
[epoch19, step309]: loss 0.046673
[epoch19, step310]: loss 0.044334
[epoch19, step311]: loss 0.045899
[epoch19, step312]: loss 0.046360
[epoch19, step313]: loss 0.043829
[epoch19, step314]: loss 0.046816
[epoch19, step315]: loss 0.044293
[epoch19, step316]: loss 0.044616
[epoch19, step317]: loss 0.046486
[epoch19, step318]: loss 0.046694
[epoch19, step319]: loss 0.043642
[epoch19, step320]: loss 0.044619
[epoch19, step321]: loss 0.046246
[epoch19, step322]: loss 0.043255
[epoch19, step323]: loss 0.046126
[epoch19, step324]: loss 0.043897
[epoch19, step325]: loss 0.044434
[epoch19, step326]: loss 0.046188
[epoch19, step327]: loss 0.046227
[epoch19, step328]: loss 0.044009
[epoch19, step329]: loss 0.045056
[epoch19, step330]: loss 0.046124
[epoch19, step331]: loss 0.043251
[epoch19, step332]: loss 0.046201
[epoch19, step333]: loss 0.043463
[epoch19, step334]: loss 0.044481
[epoch19, step335]: loss 0.046821
[epoch19, step336]: loss 0.047080
[epoch19, step337]: loss 0.043858
[epoch19, step338]: loss 0.045180
[epoch19, step339]: loss 0.046127
[epoch19, step340]: loss 0.043912
[epoch19, step341]: loss 0.046421
[epoch19, step342]: loss 0.043176
[epoch19, step343]: loss 0.044660
[epoch19, step344]: loss 0.046088
[epoch19, step345]: loss 0.046205
[epoch19, step346]: loss 0.043557
[epoch19, step347]: loss 0.045022
[epoch19, step348]: loss 0.046550
[epoch19, step349]: loss 0.043336
[epoch19, step350]: loss 0.046145
[epoch19, step351]: loss 0.042888
[epoch19, step352]: loss 0.044164
[epoch19, step353]: loss 0.046115
[epoch19, step354]: loss 0.045971
[epoch19, step355]: loss 0.043145
[epoch19, step356]: loss 0.045471
[epoch19, step357]: loss 0.046420
[epoch19, step358]: loss 0.042301
[epoch19, step359]: loss 0.046992
[epoch19, step360]: loss 0.042683
[epoch19, step361]: loss 0.044003
[epoch19, step362]: loss 0.047144
[epoch19, step363]: loss 0.046519
[epoch19, step364]: loss 0.043902
[epoch19, step365]: loss 0.045542
[epoch19, step366]: loss 0.046648
[epoch19, step367]: loss 0.043542
[epoch19, step368]: loss 0.046682
[epoch19, step369]: loss 0.043340
[epoch19, step370]: loss 0.044639
[epoch19, step371]: loss 0.047217
[epoch19, step372]: loss 0.046383
[epoch19, step373]: loss 0.043221
[epoch19, step374]: loss 0.045108
[epoch19, step375]: loss 0.046753
[epoch19, step376]: loss 0.042756
[epoch19, step377]: loss 0.047015
[epoch19, step378]: loss 0.043974
[epoch19, step379]: loss 0.044738
[epoch19, step380]: loss 0.047362
[epoch19, step381]: loss 0.046639
[epoch19, step382]: loss 0.044360
[epoch19, step383]: loss 0.045151
[epoch19, step384]: loss 0.046239
[epoch19, step385]: loss 0.042701
[epoch19, step386]: loss 0.046914
[epoch19, step387]: loss 0.043174
[epoch19, step388]: loss 0.044694
[epoch19, step389]: loss 0.046471
[epoch19, step390]: loss 0.046797
[epoch19, step391]: loss 0.043044
[epoch19, step392]: loss 0.045532
[epoch19, step393]: loss 0.046378
[epoch19, step394]: loss 0.043118
[epoch19, step395]: loss 0.046324
[epoch19, step396]: loss 0.043317
[epoch19, step397]: loss 0.044214
[epoch19, step398]: loss 0.046401
[epoch19, step399]: loss 0.046442
[epoch19, step400]: loss 0.043216
[epoch19, step401]: loss 0.044970
[epoch19, step402]: loss 0.046283
[epoch19, step403]: loss 0.043031
[epoch19, step404]: loss 0.046553
[epoch19, step405]: loss 0.043564
[epoch19, step406]: loss 0.044778
[epoch19, step407]: loss 0.046057
[epoch19, step408]: loss 0.046707
[epoch19, step409]: loss 0.044256
[epoch19, step410]: loss 0.045421
[epoch19, step411]: loss 0.046265
[epoch19, step412]: loss 0.042177
[epoch19, step413]: loss 0.046298
[epoch19, step414]: loss 0.043262
[epoch19, step415]: loss 0.044480
[epoch19, step416]: loss 0.045972
[epoch19, step417]: loss 0.046503
[epoch19, step418]: loss 0.043297
[epoch19, step419]: loss 0.044689
[epoch19, step420]: loss 0.046367
[epoch19, step421]: loss 0.042697
[epoch19, step422]: loss 0.046356
[epoch19, step423]: loss 0.043153
[epoch19, step424]: loss 0.044176
[epoch19, step425]: loss 0.046578
[epoch19, step426]: loss 0.046577
[epoch19, step427]: loss 0.044288
[epoch19, step428]: loss 0.045106
[epoch19, step429]: loss 0.046719
[epoch19, step430]: loss 0.042963
[epoch19, step431]: loss 0.046612
[epoch19, step432]: loss 0.043420
[epoch19, step433]: loss 0.044928
[epoch19, step434]: loss 0.046265
[epoch19, step435]: loss 0.046837
[epoch19, step436]: loss 0.043575
[epoch19, step437]: loss 0.045158
[epoch19, step438]: loss 0.046750
[epoch19, step439]: loss 0.043439
[epoch19, step440]: loss 0.046253
[epoch19, step441]: loss 0.043774
[epoch19, step442]: loss 0.044086
[epoch19, step443]: loss 0.046462
[epoch19, step444]: loss 0.046324
[epoch19, step445]: loss 0.044024
[epoch19, step446]: loss 0.045298
[epoch19, step447]: loss 0.046751
[epoch19, step448]: loss 0.042495
[epoch19, step449]: loss 0.046287
[epoch19, step450]: loss 0.042927
[epoch19, step451]: loss 0.044307
[epoch19, step452]: loss 0.045669
[epoch19, step453]: loss 0.046488
[epoch19, step454]: loss 0.044025
[epoch19, step455]: loss 0.045312
[epoch19, step456]: loss 0.045779
[epoch19, step457]: loss 0.043972
[epoch19, step458]: loss 0.046409
[epoch19, step459]: loss 0.043898
[epoch19, step460]: loss 0.044361
[epoch19, step461]: loss 0.046713
[epoch19, step462]: loss 0.046116
[epoch19, step463]: loss 0.043888
[epoch19, step464]: loss 0.044921
[epoch19, step465]: loss 0.047131
[epoch19, step466]: loss 0.042561
[epoch19, step467]: loss 0.046117
[epoch19, step468]: loss 0.043277
[epoch19, step469]: loss 0.044208
[epoch19, step470]: loss 0.046385
[epoch19, step471]: loss 0.046120
[epoch19, step472]: loss 0.044087
[epoch19, step473]: loss 0.044823
[epoch19, step474]: loss 0.046258
[epoch19, step475]: loss 0.042936
[epoch19, step476]: loss 0.046642
[epoch19, step477]: loss 0.043272
[epoch19, step478]: loss 0.043902
[epoch19, step479]: loss 0.046407
[epoch19, step480]: loss 0.045796
[epoch19, step481]: loss 0.043405
[epoch19, step482]: loss 0.044982
[epoch19, step483]: loss 0.046393
[epoch19, step484]: loss 0.042890
[epoch19, step485]: loss 0.046723
[epoch19, step486]: loss 0.043354
[epoch19, step487]: loss 0.044019
[epoch19, step488]: loss 0.046594
[epoch19, step489]: loss 0.045941
[epoch19, step490]: loss 0.044004
[epoch19, step491]: loss 0.045076
[epoch19, step492]: loss 0.046036
[epoch19, step493]: loss 0.042288
[epoch19, step494]: loss 0.045932
[epoch19, step495]: loss 0.043890
[epoch19, step496]: loss 0.044021
[epoch19, step497]: loss 0.046102
[epoch19, step498]: loss 0.046162
[epoch19, step499]: loss 0.043976
[epoch19, step500]: loss 0.044609
[epoch19, step501]: loss 0.045900
[epoch19, step502]: loss 0.042830
[epoch19, step503]: loss 0.046424
[epoch19, step504]: loss 0.043579
[epoch19, step505]: loss 0.043647
[epoch19, step506]: loss 0.046681
[epoch19, step507]: loss 0.046728
[epoch19, step508]: loss 0.044066
[epoch19, step509]: loss 0.045178
[epoch19, step510]: loss 0.046736
[epoch19, step511]: loss 0.043449
[epoch19, step512]: loss 0.046561
[epoch19, step513]: loss 0.043236
[epoch19, step514]: loss 0.044253
[epoch19, step515]: loss 0.046095
[epoch19, step516]: loss 0.046604
[epoch19, step517]: loss 0.043711
[epoch19, step518]: loss 0.045133
[epoch19, step519]: loss 0.046540
[epoch19, step520]: loss 0.041906
[epoch19, step521]: loss 0.046005
[epoch19, step522]: loss 0.042587
[epoch19, step523]: loss 0.044008
[epoch19, step524]: loss 0.045718
[epoch19, step525]: loss 0.046544
[epoch19, step526]: loss 0.043417
[epoch19, step527]: loss 0.044757
[epoch19, step528]: loss 0.046398
[epoch19, step529]: loss 0.042573
[epoch19, step530]: loss 0.046473
[epoch19, step531]: loss 0.043326
[epoch19, step532]: loss 0.043880
[epoch19, step533]: loss 0.047020
[epoch19, step534]: loss 0.046581
[epoch19, step535]: loss 0.043921
[epoch19, step536]: loss 0.045293
[epoch19, step537]: loss 0.046329
[epoch19, step538]: loss 0.043347
[epoch19, step539]: loss 0.046255
[epoch19, step540]: loss 0.043140
[epoch19, step541]: loss 0.044065
[epoch19, step542]: loss 0.046345
[epoch19, step543]: loss 0.046006
[epoch19, step544]: loss 0.043105
[epoch19, step545]: loss 0.044636
[epoch19, step546]: loss 0.046443
[epoch19, step547]: loss 0.042843
[epoch19, step548]: loss 0.046173
[epoch19, step549]: loss 0.043381
[epoch19, step550]: loss 0.044063
[epoch19, step551]: loss 0.045879
[epoch19, step552]: loss 0.045939
[epoch19, step553]: loss 0.044178
[epoch19, step554]: loss 0.044725
[epoch19, step555]: loss 0.045966
[epoch19, step556]: loss 0.042816
[epoch19, step557]: loss 0.045826
[epoch19, step558]: loss 0.043862
[epoch19, step559]: loss 0.043854
[epoch19, step560]: loss 0.046162
[epoch19, step561]: loss 0.046402
[epoch19, step562]: loss 0.043271
[epoch19, step563]: loss 0.037339
[epoch19, step564]: loss 0.038552
[epoch19, step565]: loss 0.034577
[epoch19, step566]: loss 0.042915
[epoch19, step567]: loss 0.034408
[epoch19, step568]: loss 0.033668
[epoch19, step569]: loss 0.033217
[epoch19, step570]: loss 0.039458
[epoch19, step571]: loss 0.031655
[epoch19, step572]: loss 0.032665
[epoch19, step573]: loss 0.037065
[epoch19, step574]: loss 0.037638
[epoch19, step575]: loss 0.029246
[epoch19, step576]: loss 0.030086
[epoch19, step577]: loss 0.032586
[epoch19, step578]: loss 0.028355
[epoch19, step579]: loss 0.033792
[epoch19, step580]: loss 0.030724
[epoch19, step581]: loss 0.033509
[epoch19, step582]: loss 0.032888
[epoch19, step583]: loss 0.030167
[epoch19, step584]: loss 0.031746
[epoch19, step585]: loss 0.035579
[epoch19, step586]: loss 0.029992
[epoch19, step587]: loss 0.032205
[epoch19, step588]: loss 0.031303
[epoch19, step589]: loss 0.034344
[epoch19, step590]: loss 0.032112
[epoch19, step591]: loss 0.028200
[epoch19, step592]: loss 0.034251
[epoch19, step593]: loss 0.033090
[epoch19, step594]: loss 0.031657
[epoch19, step595]: loss 0.031647
[epoch19, step596]: loss 0.031239
[epoch19, step597]: loss 0.033985
[epoch19, step598]: loss 0.032571
[epoch19, step599]: loss 0.030533
[epoch19, step600]: loss 0.031972
[epoch19, step601]: loss 0.027564
[epoch19, step602]: loss 0.032349
[epoch19, step603]: loss 0.032118
[epoch19, step604]: loss 0.032817
[epoch19, step605]: loss 0.030662
[epoch19, step606]: loss 0.031962
[epoch19, step607]: loss 0.035166
[epoch19, step608]: loss 0.029906
[epoch19, step609]: loss 0.033709
[epoch19, step610]: loss 0.032357
[epoch19, step611]: loss 0.034692
[epoch19, step612]: loss 0.033094
[epoch19, step613]: loss 0.028708
[epoch19, step614]: loss 0.032575
[epoch19, step615]: loss 0.034679
[epoch19, step616]: loss 0.029888
[epoch19, step617]: loss 0.030583
[epoch19, step618]: loss 0.033846
[epoch19, step619]: loss 0.032334
[epoch19, step620]: loss 0.029378
[epoch19, step621]: loss 0.030908
[epoch19, step622]: loss 0.028913
[epoch19, step623]: loss 0.032449
[epoch19, step624]: loss 0.034205
[epoch19, step625]: loss 0.030522
[epoch19, step626]: loss 0.035657
[epoch19, step627]: loss 0.032486
[epoch19, step628]: loss 0.033571
[epoch19, step629]: loss 0.024330
[epoch19, step630]: loss 0.029490
[epoch19, step631]: loss 0.036438
[epoch19, step632]: loss 0.031091
[epoch19, step633]: loss 0.030611
[epoch19, step634]: loss 0.034305
[epoch19, step635]: loss 0.031831
[epoch19, step636]: loss 0.026643
[epoch19, step637]: loss 0.035272
[epoch19, step638]: loss 0.034167
[epoch19, step639]: loss 0.028225
[epoch19, step640]: loss 0.037084
[epoch19, step641]: loss 0.035216
[epoch19, step642]: loss 0.030677
[epoch19, step643]: loss 0.033701
[epoch19, step644]: loss 0.032449
[epoch19, step645]: loss 0.027835
[epoch19, step646]: loss 0.032991
[epoch19, step647]: loss 0.028226
[epoch19, step648]: loss 0.032786
[epoch19, step649]: loss 0.035599
[epoch19, step650]: loss 0.030555
[epoch19, step651]: loss 0.032649
[epoch19, step652]: loss 0.036071
[epoch19, step653]: loss 0.036859
[epoch19, step654]: loss 0.031158
[epoch19, step655]: loss 0.029985
[epoch19, step656]: loss 0.030782
[epoch19, step657]: loss 0.035906
[epoch19, step658]: loss 0.031132
[epoch19, step659]: loss 0.031783
[epoch19, step660]: loss 0.031100
[epoch19, step661]: loss 0.034300
[epoch19, step662]: loss 0.028962
[epoch19, step663]: loss 0.028269
[epoch19, step664]: loss 0.031284
[epoch19, step665]: loss 0.036072
[epoch19, step666]: loss 0.031565
[epoch19, step667]: loss 0.033516
[epoch19, step668]: loss 0.031184
[epoch19, step669]: loss 0.031620
[epoch19, step670]: loss 0.034236
[epoch19, step671]: loss 0.029383
[epoch19, step672]: loss 0.033328
[epoch19, step673]: loss 0.031096
[epoch19, step674]: loss 0.028238
[epoch19, step675]: loss 0.028541
[epoch19, step676]: loss 0.032547
[epoch19, step677]: loss 0.031423
[epoch19, step678]: loss 0.028408
[epoch19, step679]: loss 0.030982
[epoch19, step680]: loss 0.035109
[epoch19, step681]: loss 0.027570
[epoch19, step682]: loss 0.031851
[epoch19, step683]: loss 0.032717
[epoch19, step684]: loss 0.030336
[epoch19, step685]: loss 0.030265
[epoch19, step686]: loss 0.032157
[epoch19, step687]: loss 0.032605
[epoch19, step688]: loss 0.030595
[epoch19, step689]: loss 0.029804
[epoch19, step690]: loss 0.033217
[epoch19, step691]: loss 0.033142
[epoch19, step692]: loss 0.030885
[epoch19, step693]: loss 0.034360
[epoch19, step694]: loss 0.027931
[epoch19, step695]: loss 0.032386
[epoch19, step696]: loss 0.031537
[epoch19, step697]: loss 0.033908
[epoch19, step698]: loss 0.031071
[epoch19, step699]: loss 0.030210
[epoch19, step700]: loss 0.031300
[epoch19, step701]: loss 0.033308
[epoch19, step702]: loss 0.028236
[epoch19, step703]: loss 0.032318
[epoch19, step704]: loss 0.033087
[epoch19, step705]: loss 0.030220
[epoch19, step706]: loss 0.029953
[epoch19, step707]: loss 0.030834
[epoch19, step708]: loss 0.032661
[epoch19, step709]: loss 0.032917
[epoch19, step710]: loss 0.030970
[epoch19, step711]: loss 0.031881
[epoch19, step712]: loss 0.031605
[epoch19, step713]: loss 0.032286
[epoch19, step714]: loss 0.029396
[epoch19, step715]: loss 0.029492
[epoch19, step716]: loss 0.032963
[epoch19, step717]: loss 0.029512
[epoch19, step718]: loss 0.031911
[epoch19, step719]: loss 0.039206
[epoch19, step720]: loss 0.030101
[epoch19, step721]: loss 0.029579
[epoch19, step722]: loss 0.037459
[epoch19, step723]: loss 0.032427
[epoch19, step724]: loss 0.030561
[epoch19, step725]: loss 0.035241
[epoch19, step726]: loss 0.026863
[epoch19, step727]: loss 0.031694
[epoch19, step728]: loss 0.033308
[epoch19, step729]: loss 0.027021
[epoch19, step730]: loss 0.030076
[epoch19, step731]: loss 0.033665
[epoch19, step732]: loss 0.031823
[epoch19, step733]: loss 0.028473
[epoch19, step734]: loss 0.028671
[epoch19, step735]: loss 0.032784
[epoch19, step736]: loss 0.030954
[epoch19, step737]: loss 0.031485
[epoch19, step738]: loss 0.026820
[epoch19, step739]: loss 0.034546
[epoch19, step740]: loss 0.032504
[epoch19, step741]: loss 0.032092
[epoch19, step742]: loss 0.030347
[epoch19, step743]: loss 0.030234
[epoch19, step744]: loss 0.030675
[epoch19, step745]: loss 0.031584
[epoch19, step746]: loss 0.032272
[epoch19, step747]: loss 0.033412
[epoch19, step748]: loss 0.031056
[epoch19, step749]: loss 0.035247
[epoch19, step750]: loss 0.034731
[epoch19, step751]: loss 0.028018
[epoch19, step752]: loss 0.030246
[epoch19, step753]: loss 0.030841
[epoch19, step754]: loss 0.031027
[epoch19, step755]: loss 0.033418
[epoch19, step756]: loss 0.028284
[epoch19, step757]: loss 0.027868
[epoch19, step758]: loss 0.032699
[epoch19, step759]: loss 0.028437
[epoch19, step760]: loss 0.031405
[epoch19, step761]: loss 0.032691
[epoch19, step762]: loss 0.027590
[epoch19, step763]: loss 0.031143
[epoch19, step764]: loss 0.030864
[epoch19, step765]: loss 0.031166
[epoch19, step766]: loss 0.029892
[epoch19, step767]: loss 0.033861
[epoch19, step768]: loss 0.028591
[epoch19, step769]: loss 0.033372
[epoch19, step770]: loss 0.034639
[epoch19, step771]: loss 0.028327
[epoch19, step772]: loss 0.034041
[epoch19, step773]: loss 0.032848
[epoch19, step774]: loss 0.030493
[epoch19, step775]: loss 0.029868
[epoch19, step776]: loss 0.032757
[epoch19, step777]: loss 0.029196
[epoch19, step778]: loss 0.035846
[epoch19, step779]: loss 0.030324
[epoch19, step780]: loss 0.028116
[epoch19, step781]: loss 0.033128
[epoch19, step782]: loss 0.031172
[epoch19, step783]: loss 0.026919
[epoch19, step784]: loss 0.028650
[epoch19, step785]: loss 0.029706
[epoch19, step786]: loss 0.030802
[epoch19, step787]: loss 0.031884
[epoch19, step788]: loss 0.031636
[epoch19, step789]: loss 0.031083
[epoch19, step790]: loss 0.028585
[epoch19, step791]: loss 0.033824
[epoch19, step792]: loss 0.032261
[epoch19, step793]: loss 0.034071
[epoch19, step794]: loss 0.027588
[epoch19, step795]: loss 0.031846
[epoch19, step796]: loss 0.033304
[epoch19, step797]: loss 0.033106
[epoch19, step798]: loss 0.032310
[epoch19, step799]: loss 0.029933
[epoch19, step800]: loss 0.030926
[epoch19, step801]: loss 0.030690
[epoch19, step802]: loss 0.029424
[epoch19, step803]: loss 0.031695
[epoch19, step804]: loss 0.034436
[epoch19, step805]: loss 0.034178
[epoch19, step806]: loss 0.028727
[epoch19, step807]: loss 0.028889
[epoch19, step808]: loss 0.031691
[epoch19, step809]: loss 0.029122
[epoch19, step810]: loss 0.030172
[epoch19, step811]: loss 0.032487
[epoch19, step812]: loss 0.031845
[epoch19, step813]: loss 0.029374
[epoch19, step814]: loss 0.032164
[epoch19, step815]: loss 0.031628
[epoch19, step816]: loss 0.030880
[epoch19, step817]: loss 0.030042
[epoch19, step818]: loss 0.029000
[epoch19, step819]: loss 0.031231
[epoch19, step820]: loss 0.028747
[epoch19, step821]: loss 0.027575
[epoch19, step822]: loss 0.036801
[epoch19, step823]: loss 0.029339
[epoch19, step824]: loss 0.033383
[epoch19, step825]: loss 0.032389
[epoch19, step826]: loss 0.028641
[epoch19, step827]: loss 0.031737
[epoch19, step828]: loss 0.035064
[epoch19, step829]: loss 0.032282
[epoch19, step830]: loss 0.026625
[epoch19, step831]: loss 0.031180
[epoch19, step832]: loss 0.030082
[epoch19, step833]: loss 0.035100
[epoch19, step834]: loss 0.032002
[epoch19, step835]: loss 0.028145
[epoch19, step836]: loss 0.031701
[epoch19, step837]: loss 0.030713
[epoch19, step838]: loss 0.034076
[epoch19, step839]: loss 0.034421
[epoch19, step840]: loss 0.026812
[epoch19, step841]: loss 0.030870
[epoch19, step842]: loss 0.033784
[epoch19, step843]: loss 0.032433
[epoch19, step844]: loss 0.032651
[epoch19, step845]: loss 0.028442
[epoch19, step846]: loss 0.034926
[epoch19, step847]: loss 0.033159
[epoch19, step848]: loss 0.027925
[epoch19, step849]: loss 0.031131
[epoch19, step850]: loss 0.030824
[epoch19, step851]: loss 0.030698
[epoch19, step852]: loss 0.029893
[epoch19, step853]: loss 0.036294
[epoch19, step854]: loss 0.030773
[epoch19, step855]: loss 0.032338
[epoch19, step856]: loss 0.027266
[epoch19, step857]: loss 0.033166
[epoch19, step858]: loss 0.031579
[epoch19, step859]: loss 0.029000
[epoch19, step860]: loss 0.030646
[epoch19, step861]: loss 0.030110
[epoch19, step862]: loss 0.028005
[epoch19, step863]: loss 0.028533
[epoch19, step864]: loss 0.034177
[epoch19, step865]: loss 0.030444
[epoch19, step866]: loss 0.032335
[epoch19, step867]: loss 0.031795
[epoch19, step868]: loss 0.033589
[epoch19, step869]: loss 0.029072
[epoch19, step870]: loss 0.035235
[epoch19, step871]: loss 0.030946
[epoch19, step872]: loss 0.032427
[epoch19, step873]: loss 0.030460
[epoch19, step874]: loss 0.030214
[epoch19, step875]: loss 0.033217
[epoch19, step876]: loss 0.032065
[epoch19, step877]: loss 0.022521
[epoch19, step878]: loss 0.029267
[epoch19, step879]: loss 0.033467
[epoch19, step880]: loss 0.031164
[epoch19, step881]: loss 0.030177
[epoch19, step882]: loss 0.029402
[epoch19, step883]: loss 0.029886
[epoch19, step884]: loss 0.035036
[epoch19, step885]: loss 0.034443
[epoch19, step886]: loss 0.034349
[epoch19, step887]: loss 0.033120
[epoch19, step888]: loss 0.030663
[epoch19, step889]: loss 0.030986
[epoch19, step890]: loss 0.031024
[epoch19, step891]: loss 0.030854
[epoch19, step892]: loss 0.029036
[epoch19, step893]: loss 0.031996
[epoch19, step894]: loss 0.032114
[epoch19, step895]: loss 0.027918
[epoch19, step896]: loss 0.031492
[epoch19, step897]: loss 0.033326
[epoch19, step898]: loss 0.031058
[epoch19, step899]: loss 0.030827
[epoch19, step900]: loss 0.033215
[epoch19, step901]: loss 0.033090
[epoch19, step902]: loss 0.029430
[epoch19, step903]: loss 0.032648
[epoch19, step904]: loss 0.033411
[epoch19, step905]: loss 0.032499
[epoch19, step906]: loss 0.027063
[epoch19, step907]: loss 0.031616
[epoch19, step908]: loss 0.031115
[epoch19, step909]: loss 0.031667
[epoch19, step910]: loss 0.027868
[epoch19, step911]: loss 0.029635
[epoch19, step912]: loss 0.031503
[epoch19, step913]: loss 0.031661
[epoch19, step914]: loss 0.036642
[epoch19, step915]: loss 0.029432
[epoch19, step916]: loss 0.030717
[epoch19, step917]: loss 0.031696
[epoch19, step918]: loss 0.035721
[epoch19, step919]: loss 0.029282
[epoch19, step920]: loss 0.035202
[epoch19, step921]: loss 0.029935
[epoch19, step922]: loss 0.029048
[epoch19, step923]: loss 0.030933
[epoch19, step924]: loss 0.027173
[epoch19, step925]: loss 0.031010
[epoch19, step926]: loss 0.032409
[epoch19, step927]: loss 0.033298
[epoch19, step928]: loss 0.030409
[epoch19, step929]: loss 0.033393
[epoch19, step930]: loss 0.032058
[epoch19, step931]: loss 0.034589
[epoch19, step932]: loss 0.027539
[epoch19, step933]: loss 0.033642
[epoch19, step934]: loss 0.030708
[epoch19, step935]: loss 0.029082
[epoch19, step936]: loss 0.028370
[epoch19, step937]: loss 0.031831
[epoch19, step938]: loss 0.034058
[epoch19, step939]: loss 0.027172
[epoch19, step940]: loss 0.030915
[epoch19, step941]: loss 0.033229
[epoch19, step942]: loss 0.031776
[epoch19, step943]: loss 0.031385
[epoch19, step944]: loss 0.033872
[epoch19, step945]: loss 0.028594
[epoch19, step946]: loss 0.032074
[epoch19, step947]: loss 0.033027
[epoch19, step948]: loss 0.030567
[epoch19, step949]: loss 0.029139
[epoch19, step950]: loss 0.033017
[epoch19, step951]: loss 0.035854
[epoch19, step952]: loss 0.032425
[epoch19, step953]: loss 0.034203
[epoch19, step954]: loss 0.029475
[epoch19, step955]: loss 0.040272
[epoch19, step956]: loss 0.057907
[epoch19, step957]: loss 0.051143
[epoch19, step958]: loss 0.050613
[epoch19, step959]: loss 0.053511
[epoch19, step960]: loss 0.049942
[epoch19, step961]: loss 0.051546
[epoch19, step962]: loss 0.049481
[epoch19, step963]: loss 0.048590
[epoch19, step964]: loss 0.047858
[epoch19, step965]: loss 0.049487
[epoch19, step966]: loss 0.045606
[epoch19, step967]: loss 0.045809
[epoch19, step968]: loss 0.047406
[epoch19, step969]: loss 0.045893
[epoch19, step970]: loss 0.045657
[epoch19, step971]: loss 0.044823
[epoch19, step972]: loss 0.046590
[epoch19, step973]: loss 0.045166
[epoch19, step974]: loss 0.047315
[epoch19, step975]: loss 0.045044
[epoch19, step976]: loss 0.045432
[epoch19, step977]: loss 0.047834
[epoch19, step978]: loss 0.045262
[epoch19, step979]: loss 0.044657
[epoch19, step980]: loss 0.044168
[epoch19, step981]: loss 0.046034
[epoch19, step982]: loss 0.044706
[epoch19, step983]: loss 0.046549
[epoch19, step984]: loss 0.043302
[epoch19, step985]: loss 0.044829
[epoch19, step986]: loss 0.047347
[epoch19, step987]: loss 0.044205
[epoch19, step988]: loss 0.045009
[epoch19, step989]: loss 0.044601
[epoch19, step990]: loss 0.045371
[epoch19, step991]: loss 0.045002
[epoch19, step992]: loss 0.045819
[epoch19, step993]: loss 0.044020
[epoch19, step994]: loss 0.044479
[epoch19, step995]: loss 0.046664
[epoch19, step996]: loss 0.043502
[epoch19, step997]: loss 0.044365
[epoch19, step998]: loss 0.044477
[epoch19, step999]: loss 0.045695
[epoch19, step1000]: loss 0.044611
[epoch19, step1001]: loss 0.045859
[epoch19, step1002]: loss 0.043732
[epoch19, step1003]: loss 0.044501
[epoch19, step1004]: loss 0.046443
[epoch19, step1005]: loss 0.042863
[epoch19, step1006]: loss 0.044369
[epoch19, step1007]: loss 0.043760
[epoch19, step1008]: loss 0.045045
[epoch19, step1009]: loss 0.044224
[epoch19, step1010]: loss 0.046086
[epoch19, step1011]: loss 0.043735
[epoch19, step1012]: loss 0.044857
[epoch19, step1013]: loss 0.046622
[epoch19, step1014]: loss 0.044369
[epoch19, step1015]: loss 0.044491
[epoch19, step1016]: loss 0.043771
[epoch19, step1017]: loss 0.045070
[epoch19, step1018]: loss 0.043962
[epoch19, step1019]: loss 0.045871
[epoch19, step1020]: loss 0.043385
[epoch19, step1021]: loss 0.044395
[epoch19, step1022]: loss 0.046172
[epoch19, step1023]: loss 0.043503
[epoch19, step1024]: loss 0.044564
[epoch19, step1025]: loss 0.043750
[epoch19, step1026]: loss 0.044705
[epoch19, step1027]: loss 0.043731
[epoch19, step1028]: loss 0.045604
[epoch19, step1029]: loss 0.043330
[epoch19, step1030]: loss 0.043994
[epoch19, step1031]: loss 0.045407
[epoch19, step1032]: loss 0.043584
[epoch19, step1033]: loss 0.043929
[epoch19, step1034]: loss 0.043859
[epoch19, step1035]: loss 0.044645
[epoch19, step1036]: loss 0.044306
[epoch19, step1037]: loss 0.045445
[epoch19, step1038]: loss 0.043361
[epoch19, step1039]: loss 0.044492
[epoch19, step1040]: loss 0.045801
[epoch19, step1041]: loss 0.043574
[epoch19, step1042]: loss 0.043297
[epoch19, step1043]: loss 0.043688
[epoch19, step1044]: loss 0.045175
[epoch19, step1045]: loss 0.044070
[epoch19, step1046]: loss 0.045672
[epoch19, step1047]: loss 0.043340
[epoch19, step1048]: loss 0.044143
[epoch19, step1049]: loss 0.046175
[epoch19, step1050]: loss 0.043651
[epoch19, step1051]: loss 0.044034
[epoch19, step1052]: loss 0.044355
[epoch19, step1053]: loss 0.045435
[epoch19, step1054]: loss 0.044133
[epoch19, step1055]: loss 0.045126
[epoch19, step1056]: loss 0.042946
[epoch19, step1057]: loss 0.044658
[epoch19, step1058]: loss 0.046442
[epoch19, step1059]: loss 0.043692
[epoch19, step1060]: loss 0.043924
[epoch19, step1061]: loss 0.043463
[epoch19, step1062]: loss 0.045286
[epoch19, step1063]: loss 0.044123
[epoch19, step1064]: loss 0.045533
[epoch19, step1065]: loss 0.043449
[epoch19, step1066]: loss 0.044029
[epoch19, step1067]: loss 0.046080
[epoch19, step1068]: loss 0.042793
[epoch19, step1069]: loss 0.043249
[epoch19, step1070]: loss 0.043745
[epoch19, step1071]: loss 0.045208
[epoch19, step1072]: loss 0.044432
[epoch19, step1073]: loss 0.045238
[epoch19, step1074]: loss 0.043543
[epoch19, step1075]: loss 0.044383
[epoch19, step1076]: loss 0.045970
[epoch19, step1077]: loss 0.043298
[epoch19, step1078]: loss 0.043797
[epoch19, step1079]: loss 0.044365
[epoch19, step1080]: loss 0.045002
[epoch19, step1081]: loss 0.044123
[epoch19, step1082]: loss 0.045304
[epoch19, step1083]: loss 0.043908
[epoch19, step1084]: loss 0.044406
[epoch19, step1085]: loss 0.045782
[epoch19, step1086]: loss 0.043388
[epoch19, step1087]: loss 0.043986
[epoch19, step1088]: loss 0.043656
[epoch19, step1089]: loss 0.045132
[epoch19, step1090]: loss 0.044291
[epoch19, step1091]: loss 0.045691
[epoch19, step1092]: loss 0.043382
[epoch19, step1093]: loss 0.044160
[epoch19, step1094]: loss 0.045253
[epoch19, step1095]: loss 0.042968
[epoch19, step1096]: loss 0.043616
[epoch19, step1097]: loss 0.043709
[epoch19, step1098]: loss 0.044886
[epoch19, step1099]: loss 0.043737
[epoch19, step1100]: loss 0.045774
[epoch19, step1101]: loss 0.043797
[epoch19, step1102]: loss 0.044156
[epoch19, step1103]: loss 0.045579
[epoch19, step1104]: loss 0.043119
[epoch19, step1105]: loss 0.043884
[epoch19, step1106]: loss 0.043064
[epoch19, step1107]: loss 0.045081
[epoch19, step1108]: loss 0.043717
[epoch19, step1109]: loss 0.045552
[epoch19, step1110]: loss 0.043654
[epoch19, step1111]: loss 0.044318
[epoch19, step1112]: loss 0.046092
[epoch19, step1113]: loss 0.043041
[epoch19, step1114]: loss 0.044055
[epoch19, step1115]: loss 0.043782
[epoch19, step1116]: loss 0.045017
[epoch19, step1117]: loss 0.043997
[epoch19, step1118]: loss 0.045465
[epoch19, step1119]: loss 0.043513
[epoch19, step1120]: loss 0.044137
[epoch19, step1121]: loss 0.045874
[epoch19, step1122]: loss 0.043130
[epoch19, step1123]: loss 0.043323
[epoch19, step1124]: loss 0.044126
[epoch19, step1125]: loss 0.045069
[epoch19, step1126]: loss 0.044644
[epoch19, step1127]: loss 0.045411
[epoch19, step1128]: loss 0.043579
[epoch19, step1129]: loss 0.044120
[epoch19, step1130]: loss 0.046213
[epoch19, step1131]: loss 0.043643
[epoch19, step1132]: loss 0.044065
[epoch19, step1133]: loss 0.043405
[epoch19, step1134]: loss 0.044616
[epoch19, step1135]: loss 0.044472
[epoch19, step1136]: loss 0.045801
[epoch19, step1137]: loss 0.043048
[epoch19, step1138]: loss 0.044377
[epoch19, step1139]: loss 0.046024
[epoch19, step1140]: loss 0.042672
[epoch19, step1141]: loss 0.043474
[epoch19, step1142]: loss 0.043536
[epoch19, step1143]: loss 0.044607
[epoch19, step1144]: loss 0.044121
[epoch19, step1145]: loss 0.045094
[epoch19, step1146]: loss 0.042727
[epoch19, step1147]: loss 0.044698
[epoch19, step1148]: loss 0.045893
[epoch19, step1149]: loss 0.042775
[epoch19, step1150]: loss 0.043681
[epoch19, step1151]: loss 0.044084
[epoch19, step1152]: loss 0.045099
[epoch19, step1153]: loss 0.043517
[epoch19, step1154]: loss 0.045605
[epoch19, step1155]: loss 0.043533
[epoch19, step1156]: loss 0.043670
[epoch19, step1157]: loss 0.045660
[epoch19, step1158]: loss 0.043260
[epoch19, step1159]: loss 0.043804
[epoch19, step1160]: loss 0.044222
[epoch19, step1161]: loss 0.045026
[epoch19, step1162]: loss 0.043834
[epoch19, step1163]: loss 0.045021
[epoch19, step1164]: loss 0.043016
[epoch19, step1165]: loss 0.044801
[epoch19, step1166]: loss 0.045825
[epoch19, step1167]: loss 0.042549
[epoch19, step1168]: loss 0.043794
[epoch19, step1169]: loss 0.043493
[epoch19, step1170]: loss 0.045009
[epoch19, step1171]: loss 0.043767
[epoch19, step1172]: loss 0.045439
[epoch19, step1173]: loss 0.043362
[epoch19, step1174]: loss 0.044292
[epoch19, step1175]: loss 0.045964
[epoch19, step1176]: loss 0.042926
[epoch19, step1177]: loss 0.043823
[epoch19, step1178]: loss 0.043623
[epoch19, step1179]: loss 0.044912
[epoch19, step1180]: loss 0.043930
[epoch19, step1181]: loss 0.045775
[epoch19, step1182]: loss 0.042686
[epoch19, step1183]: loss 0.044473
[epoch19, step1184]: loss 0.045423
[epoch19, step1185]: loss 0.043575
[epoch19, step1186]: loss 0.043143
[epoch19, step1187]: loss 0.043153
[epoch19, step1188]: loss 0.044240
[epoch19, step1189]: loss 0.043512
[epoch19, step1190]: loss 0.045102
[epoch19, step1191]: loss 0.043923
[epoch19, step1192]: loss 0.044196
[epoch19, step1193]: loss 0.045509
[epoch19, step1194]: loss 0.043028
[epoch19, step1195]: loss 0.042992
[epoch19, step1196]: loss 0.043069
[epoch19, step1197]: loss 0.045178
[epoch19, step1198]: loss 0.043799
[epoch19, step1199]: loss 0.045041
[epoch19, step1200]: loss 0.042848
[epoch19, step1201]: loss 0.044382
[epoch19, step1202]: loss 0.046398
[epoch19, step1203]: loss 0.043574
[epoch19, step1204]: loss 0.043162
[epoch19, step1205]: loss 0.043158
[epoch19, step1206]: loss 0.044471
[epoch19, step1207]: loss 0.043817
[epoch19, step1208]: loss 0.045401
[epoch19, step1209]: loss 0.041957
[epoch19, step1210]: loss 0.044505
[epoch19, step1211]: loss 0.045384
[epoch19, step1212]: loss 0.043229
[epoch19, step1213]: loss 0.043464
[epoch19, step1214]: loss 0.043769
[epoch19, step1215]: loss 0.045203
[epoch19, step1216]: loss 0.043454
[epoch19, step1217]: loss 0.045694
[epoch19, step1218]: loss 0.042688
[epoch19, step1219]: loss 0.044538
[epoch19, step1220]: loss 0.045831
[epoch19, step1221]: loss 0.042297
[epoch19, step1222]: loss 0.043685
[epoch19, step1223]: loss 0.043411
[epoch19, step1224]: loss 0.044975
[epoch19, step1225]: loss 0.043759
[epoch19, step1226]: loss 0.045104
[epoch19, step1227]: loss 0.042734
[epoch19, step1228]: loss 0.043733
[epoch19, step1229]: loss 0.045705
[epoch19, step1230]: loss 0.043609
[epoch19, step1231]: loss 0.043547
[epoch19, step1232]: loss 0.044358
[epoch19, step1233]: loss 0.044470
[epoch19, step1234]: loss 0.043637
[epoch19, step1235]: loss 0.045676
[epoch19, step1236]: loss 0.043590
[epoch19, step1237]: loss 0.043879
[epoch19, step1238]: loss 0.045483
[epoch19, step1239]: loss 0.043410
[epoch19, step1240]: loss 0.043792
[epoch19, step1241]: loss 0.043477
[epoch19, step1242]: loss 0.044603
[epoch19, step1243]: loss 0.043489
[epoch19, step1244]: loss 0.045501
[epoch19, step1245]: loss 0.042941
[epoch19, step1246]: loss 0.044284
[epoch19, step1247]: loss 0.045101
[epoch19, step1248]: loss 0.043028
[epoch19, step1249]: loss 0.043829
[epoch19, step1250]: loss 0.043343
[epoch19, step1251]: loss 0.044977
[epoch19, step1252]: loss 0.044411
[epoch19, step1253]: loss 0.045346
[epoch19, step1254]: loss 0.043285
[epoch19, step1255]: loss 0.044066
[epoch19, step1256]: loss 0.045802
[epoch19, step1257]: loss 0.043292
[epoch19, step1258]: loss 0.043699
[epoch19, step1259]: loss 0.043393
[epoch19, step1260]: loss 0.044546
[epoch19, step1261]: loss 0.043693
[epoch19, step1262]: loss 0.044520
[epoch19, step1263]: loss 0.043478
[epoch19, step1264]: loss 0.044005
[epoch19, step1265]: loss 0.044831
[epoch19, step1266]: loss 0.043293
[epoch19, step1267]: loss 0.043587
[epoch19, step1268]: loss 0.043777
[epoch19, step1269]: loss 0.044678
[epoch19, step1270]: loss 0.043336
[epoch19, step1271]: loss 0.045644
[epoch19, step1272]: loss 0.043321
[epoch19, step1273]: loss 0.043910
[epoch19, step1274]: loss 0.045420
[epoch19, step1275]: loss 0.043518
[epoch19, step1276]: loss 0.043299
[epoch19, step1277]: loss 0.043392
[epoch19, step1278]: loss 0.045018
[epoch19, step1279]: loss 0.043699
[epoch19, step1280]: loss 0.045447
[epoch19, step1281]: loss 0.043121
[epoch19, step1282]: loss 0.043978
[epoch19, step1283]: loss 0.045188
[epoch19, step1284]: loss 0.042614
[epoch19, step1285]: loss 0.043884
[epoch19, step1286]: loss 0.042945
[epoch19, step1287]: loss 0.044971
[epoch19, step1288]: loss 0.044202
[epoch19, step1289]: loss 0.045789
[epoch19, step1290]: loss 0.043354
[epoch19, step1291]: loss 0.043766
[epoch19, step1292]: loss 0.046075
[epoch19, step1293]: loss 0.042324
[epoch19, step1294]: loss 0.043395
[epoch19, step1295]: loss 0.043665
[epoch19, step1296]: loss 0.044601
[epoch19, step1297]: loss 0.043254
[epoch19, step1298]: loss 0.045580
[epoch19, step1299]: loss 0.043432
[epoch19, step1300]: loss 0.044329
[epoch19, step1301]: loss 0.045344
[epoch19, step1302]: loss 0.043281
[epoch19, step1303]: loss 0.043746
[epoch19, step1304]: loss 0.042989
[epoch19, step1305]: loss 0.044837
[epoch19, step1306]: loss 0.043406
[epoch19, step1307]: loss 0.044930
[epoch19, step1308]: loss 0.043246
[epoch19, step1309]: loss 0.043621
[epoch19, step1310]: loss 0.045682
[epoch19, step1311]: loss 0.042965
[epoch19, step1312]: loss 0.044279
[epoch19, step1313]: loss 0.043800
[epoch19, step1314]: loss 0.044788
[epoch19, step1315]: loss 0.043615
[epoch19, step1316]: loss 0.046115
[epoch19, step1317]: loss 0.043090
[epoch19, step1318]: loss 0.043811
[epoch19, step1319]: loss 0.045232
[epoch19, step1320]: loss 0.043457
[epoch19, step1321]: loss 0.043753
[epoch19, step1322]: loss 0.043451
[epoch19, step1323]: loss 0.045051
[epoch19, step1324]: loss 0.043488
[epoch19, step1325]: loss 0.045073
[epoch19, step1326]: loss 0.043217
[epoch19, step1327]: loss 0.044022
[epoch19, step1328]: loss 0.045700
[epoch19, step1329]: loss 0.043304
[epoch19, step1330]: loss 0.043566
[epoch19, step1331]: loss 0.043572
[epoch19, step1332]: loss 0.044999
[epoch19, step1333]: loss 0.043235
[epoch19, step1334]: loss 0.045473
[epoch19, step1335]: loss 0.043716
[epoch19, step1336]: loss 0.044187
[epoch19, step1337]: loss 0.045408
[epoch19, step1338]: loss 0.042970
[epoch19, step1339]: loss 0.043665
[epoch19, step1340]: loss 0.043318
[epoch19, step1341]: loss 0.045182
[epoch19, step1342]: loss 0.043520
[epoch19, step1343]: loss 0.045334
[epoch19, step1344]: loss 0.043006
[epoch19, step1345]: loss 0.043950
[epoch19, step1346]: loss 0.045457
[epoch19, step1347]: loss 0.043448
[epoch19, step1348]: loss 0.043062
[epoch19, step1349]: loss 0.043434
[epoch19, step1350]: loss 0.044756
[epoch19, step1351]: loss 0.043450
[epoch19, step1352]: loss 0.044600
[epoch19, step1353]: loss 0.042907
[epoch19, step1354]: loss 0.043820
[epoch19, step1355]: loss 0.045745
[epoch19, step1356]: loss 0.042904
[epoch19, step1357]: loss 0.043056
[epoch19, step1358]: loss 0.043250
[epoch19, step1359]: loss 0.044414
[epoch19, step1360]: loss 0.043726
[epoch19, step1361]: loss 0.045317
[epoch19, step1362]: loss 0.043646
[epoch19, step1363]: loss 0.044376
[epoch19, step1364]: loss 0.045490
[epoch19, step1365]: loss 0.043327
[epoch19, step1366]: loss 0.043303
[epoch19, step1367]: loss 0.042835
[epoch19, step1368]: loss 0.045332
[epoch19, step1369]: loss 0.043726
[epoch19, step1370]: loss 0.045156
[epoch19, step1371]: loss 0.043176
[epoch19, step1372]: loss 0.043734
[epoch19, step1373]: loss 0.045504
[epoch19, step1374]: loss 0.043482
[epoch19, step1375]: loss 0.043976
[epoch19, step1376]: loss 0.043084
[epoch19, step1377]: loss 0.044150
[epoch19, step1378]: loss 0.043762
[epoch19, step1379]: loss 0.044869
[epoch19, step1380]: loss 0.042904
[epoch19, step1381]: loss 0.043775
[epoch19, step1382]: loss 0.045679
[epoch19, step1383]: loss 0.042658
[epoch19, step1384]: loss 0.043235
[epoch19, step1385]: loss 0.042737
[epoch19, step1386]: loss 0.044766
[epoch19, step1387]: loss 0.043897
[epoch19, step1388]: loss 0.044456
[epoch19, step1389]: loss 0.042432
[epoch19, step1390]: loss 0.043948
[epoch19, step1391]: loss 0.045377
[epoch19, step1392]: loss 0.043163
[epoch19, step1393]: loss 0.043498
[epoch19, step1394]: loss 0.043497
[epoch19, step1395]: loss 0.044796
[epoch19, step1396]: loss 0.043188
[epoch19, step1397]: loss 0.044979
[epoch19, step1398]: loss 0.042666
[epoch19, step1399]: loss 0.044393
[epoch19, step1400]: loss 0.045770
[epoch19, step1401]: loss 0.042646
[epoch19, step1402]: loss 0.043435
[epoch19, step1403]: loss 0.042335
[epoch19, step1404]: loss 0.044326
[epoch19, step1405]: loss 0.043233
[epoch19, step1406]: loss 0.044907
[epoch19, step1407]: loss 0.043676
[epoch19, step1408]: loss 0.043425
[epoch19, step1409]: loss 0.045088
[epoch19, step1410]: loss 0.042687
[epoch19, step1411]: loss 0.042731
[epoch19, step1412]: loss 0.043221
[epoch19, step1413]: loss 0.044645
[epoch19, step1414]: loss 0.043225
[epoch19, step1415]: loss 0.044812
[epoch19, step1416]: loss 0.042585
[epoch19, step1417]: loss 0.043810
[epoch19, step1418]: loss 0.045230
[epoch19, step1419]: loss 0.043517
[epoch19, step1420]: loss 0.043639
[epoch19, step1421]: loss 0.043327
[epoch19, step1422]: loss 0.044576
[epoch19, step1423]: loss 0.043280
[epoch19, step1424]: loss 0.045272
[epoch19, step1425]: loss 0.042315
[epoch19, step1426]: loss 0.043825
[epoch19, step1427]: loss 0.045782
[epoch19, step1428]: loss 0.043928
[epoch19, step1429]: loss 0.043315
[epoch19, step1430]: loss 0.043197
[epoch19, step1431]: loss 0.044506
[epoch19, step1432]: loss 0.043222
[epoch19, step1433]: loss 0.045277
[epoch19, step1434]: loss 0.042610
[epoch19, step1435]: loss 0.044048
[epoch19, step1436]: loss 0.045731
[epoch19, step1437]: loss 0.042992
[epoch19, step1438]: loss 0.043734
[epoch19, step1439]: loss 0.043139
[epoch19, step1440]: loss 0.044383
[epoch19, step1441]: loss 0.043853
[epoch19, step1442]: loss 0.044635
[epoch19, step1443]: loss 0.042826
[epoch19, step1444]: loss 0.043260
[epoch19, step1445]: loss 0.045639
[epoch19, step1446]: loss 0.042860
[epoch19, step1447]: loss 0.043827
[epoch19, step1448]: loss 0.043001
[epoch19, step1449]: loss 0.044166
[epoch19, step1450]: loss 0.043493
[epoch19, step1451]: loss 0.045115
[epoch19, step1452]: loss 0.042769
[epoch19, step1453]: loss 0.044464
[epoch19, step1454]: loss 0.045546
[epoch19, step1455]: loss 0.043370
[epoch19, step1456]: loss 0.043085
[epoch19, step1457]: loss 0.043358
[epoch19, step1458]: loss 0.044392
[epoch19, step1459]: loss 0.043551
[epoch19, step1460]: loss 0.045380
[epoch19, step1461]: loss 0.043045
[epoch19, step1462]: loss 0.044074
[epoch19, step1463]: loss 0.045321
[epoch19, step1464]: loss 0.042977
[epoch19, step1465]: loss 0.043062
[epoch19, step1466]: loss 0.042664
[epoch19, step1467]: loss 0.044373
[epoch19, step1468]: loss 0.042922
[epoch19, step1469]: loss 0.045089
[epoch19, step1470]: loss 0.042720
[epoch19, step1471]: loss 0.043521
[epoch19, step1472]: loss 0.045073
[epoch19, step1473]: loss 0.042616
[epoch19, step1474]: loss 0.043681
[epoch19, step1475]: loss 0.042601
[epoch19, step1476]: loss 0.044916
[epoch19, step1477]: loss 0.043235
[epoch19, step1478]: loss 0.045160
[epoch19, step1479]: loss 0.042571
[epoch19, step1480]: loss 0.043643
[epoch19, step1481]: loss 0.044641
[epoch19, step1482]: loss 0.042869
[epoch19, step1483]: loss 0.043441
[epoch19, step1484]: loss 0.043247
[epoch19, step1485]: loss 0.044233
[epoch19, step1486]: loss 0.042583
[epoch19, step1487]: loss 0.044847
[epoch19, step1488]: loss 0.042891
[epoch19, step1489]: loss 0.043492
[epoch19, step1490]: loss 0.045116
[epoch19, step1491]: loss 0.043193
[epoch19, step1492]: loss 0.043228
[epoch19, step1493]: loss 0.043236
[epoch19, step1494]: loss 0.044645
[epoch19, step1495]: loss 0.043254
[epoch19, step1496]: loss 0.044432
[epoch19, step1497]: loss 0.042911
[epoch19, step1498]: loss 0.043689
[epoch19, step1499]: loss 0.044893
[epoch19, step1500]: loss 0.042965
[epoch19, step1501]: loss 0.043321
[epoch19, step1502]: loss 0.042765
[epoch19, step1503]: loss 0.044339
[epoch19, step1504]: loss 0.042966
[epoch19, step1505]: loss 0.045256
[epoch19, step1506]: loss 0.042234
[epoch19, step1507]: loss 0.043820
[epoch19, step1508]: loss 0.045761
[epoch19, step1509]: loss 0.042910
[epoch19, step1510]: loss 0.042793
[epoch19, step1511]: loss 0.043313
[epoch19, step1512]: loss 0.044343
[epoch19, step1513]: loss 0.042402
[epoch19, step1514]: loss 0.044931
[epoch19, step1515]: loss 0.043150
[epoch19, step1516]: loss 0.043584

[epoch19]: avg loss 0.041359

[epoch20, step1]: loss 0.043417
[epoch20, step2]: loss 0.044887
[epoch20, step3]: loss 0.044674
[epoch20, step4]: loss 0.042329
[epoch20, step5]: loss 0.043859
[epoch20, step6]: loss 0.045414
[epoch20, step7]: loss 0.042015
[epoch20, step8]: loss 0.045173
[epoch20, step9]: loss 0.041904
[epoch20, step10]: loss 0.043299
[epoch20, step11]: loss 0.045446
[epoch20, step12]: loss 0.044867
[epoch20, step13]: loss 0.042399
[epoch20, step14]: loss 0.044009
[epoch20, step15]: loss 0.045212
[epoch20, step16]: loss 0.042390
[epoch20, step17]: loss 0.045409
[epoch20, step18]: loss 0.042831
[epoch20, step19]: loss 0.043572
[epoch20, step20]: loss 0.045660
[epoch20, step21]: loss 0.045094
[epoch20, step22]: loss 0.042199
[epoch20, step23]: loss 0.043289
[epoch20, step24]: loss 0.045371
[epoch20, step25]: loss 0.041336
[epoch20, step26]: loss 0.044670
[epoch20, step27]: loss 0.041672
[epoch20, step28]: loss 0.043117
[epoch20, step29]: loss 0.045049
[epoch20, step30]: loss 0.045285
[epoch20, step31]: loss 0.041988
[epoch20, step32]: loss 0.044071
[epoch20, step33]: loss 0.045836
[epoch20, step34]: loss 0.042558
[epoch20, step35]: loss 0.045283
[epoch20, step36]: loss 0.042257
[epoch20, step37]: loss 0.043064
[epoch20, step38]: loss 0.044916
[epoch20, step39]: loss 0.044877
[epoch20, step40]: loss 0.042648
[epoch20, step41]: loss 0.043374
[epoch20, step42]: loss 0.045411
[epoch20, step43]: loss 0.042091
[epoch20, step44]: loss 0.045284
[epoch20, step45]: loss 0.042651
[epoch20, step46]: loss 0.043215
[epoch20, step47]: loss 0.044865
[epoch20, step48]: loss 0.044758
[epoch20, step49]: loss 0.040985
[epoch20, step50]: loss 0.043955
[epoch20, step51]: loss 0.045139
[epoch20, step52]: loss 0.042007
[epoch20, step53]: loss 0.045526
[epoch20, step54]: loss 0.041888
[epoch20, step55]: loss 0.043524
[epoch20, step56]: loss 0.045605
[epoch20, step57]: loss 0.045272
[epoch20, step58]: loss 0.042259
[epoch20, step59]: loss 0.043166
[epoch20, step60]: loss 0.045627
[epoch20, step61]: loss 0.041411
[epoch20, step62]: loss 0.044699
[epoch20, step63]: loss 0.041578
[epoch20, step64]: loss 0.042861
[epoch20, step65]: loss 0.045106
[epoch20, step66]: loss 0.044891
[epoch20, step67]: loss 0.042506
[epoch20, step68]: loss 0.043721
[epoch20, step69]: loss 0.045258
[epoch20, step70]: loss 0.041842
[epoch20, step71]: loss 0.044739
[epoch20, step72]: loss 0.042229
[epoch20, step73]: loss 0.042967
[epoch20, step74]: loss 0.045103
[epoch20, step75]: loss 0.044929
[epoch20, step76]: loss 0.042861
[epoch20, step77]: loss 0.044029
[epoch20, step78]: loss 0.045299
[epoch20, step79]: loss 0.041740
[epoch20, step80]: loss 0.045454
[epoch20, step81]: loss 0.042161
[epoch20, step82]: loss 0.043078
[epoch20, step83]: loss 0.044602
[epoch20, step84]: loss 0.045070
[epoch20, step85]: loss 0.042555
[epoch20, step86]: loss 0.043744
[epoch20, step87]: loss 0.046045
[epoch20, step88]: loss 0.041484
[epoch20, step89]: loss 0.044770
[epoch20, step90]: loss 0.042567
[epoch20, step91]: loss 0.042701
[epoch20, step92]: loss 0.045093
[epoch20, step93]: loss 0.044929
[epoch20, step94]: loss 0.042281
[epoch20, step95]: loss 0.044077
[epoch20, step96]: loss 0.045114
[epoch20, step97]: loss 0.042547
[epoch20, step98]: loss 0.045026
[epoch20, step99]: loss 0.042168
[epoch20, step100]: loss 0.042409
[epoch20, step101]: loss 0.045350
[epoch20, step102]: loss 0.044914
[epoch20, step103]: loss 0.042280
[epoch20, step104]: loss 0.043659
[epoch20, step105]: loss 0.045324
[epoch20, step106]: loss 0.041874
[epoch20, step107]: loss 0.044891
[epoch20, step108]: loss 0.042334
[epoch20, step109]: loss 0.042639
[epoch20, step110]: loss 0.045463
[epoch20, step111]: loss 0.044706
[epoch20, step112]: loss 0.042648
[epoch20, step113]: loss 0.044141
[epoch20, step114]: loss 0.044991
[epoch20, step115]: loss 0.041983
[epoch20, step116]: loss 0.045407
[epoch20, step117]: loss 0.042058
[epoch20, step118]: loss 0.043416
[epoch20, step119]: loss 0.045337
[epoch20, step120]: loss 0.044990
[epoch20, step121]: loss 0.042237
[epoch20, step122]: loss 0.043591
[epoch20, step123]: loss 0.045451
[epoch20, step124]: loss 0.042395
[epoch20, step125]: loss 0.045286
[epoch20, step126]: loss 0.042144
[epoch20, step127]: loss 0.042945
[epoch20, step128]: loss 0.044874
[epoch20, step129]: loss 0.044621
[epoch20, step130]: loss 0.042031
[epoch20, step131]: loss 0.043251
[epoch20, step132]: loss 0.045234
[epoch20, step133]: loss 0.041314
[epoch20, step134]: loss 0.044664
[epoch20, step135]: loss 0.042298
[epoch20, step136]: loss 0.043572
[epoch20, step137]: loss 0.044707
[epoch20, step138]: loss 0.044797
[epoch20, step139]: loss 0.042063
[epoch20, step140]: loss 0.043946
[epoch20, step141]: loss 0.045211
[epoch20, step142]: loss 0.041858
[epoch20, step143]: loss 0.044648
[epoch20, step144]: loss 0.042474
[epoch20, step145]: loss 0.042942
[epoch20, step146]: loss 0.045157
[epoch20, step147]: loss 0.045773
[epoch20, step148]: loss 0.042206
[epoch20, step149]: loss 0.043248
[epoch20, step150]: loss 0.044770
[epoch20, step151]: loss 0.041980
[epoch20, step152]: loss 0.044955
[epoch20, step153]: loss 0.042567
[epoch20, step154]: loss 0.042574
[epoch20, step155]: loss 0.045007
[epoch20, step156]: loss 0.044714
[epoch20, step157]: loss 0.042437
[epoch20, step158]: loss 0.043803
[epoch20, step159]: loss 0.045334
[epoch20, step160]: loss 0.042196
[epoch20, step161]: loss 0.045281
[epoch20, step162]: loss 0.042408
[epoch20, step163]: loss 0.042726
[epoch20, step164]: loss 0.045207
[epoch20, step165]: loss 0.044960
[epoch20, step166]: loss 0.042263
[epoch20, step167]: loss 0.043396
[epoch20, step168]: loss 0.045646
[epoch20, step169]: loss 0.041677
[epoch20, step170]: loss 0.045177
[epoch20, step171]: loss 0.042462
[epoch20, step172]: loss 0.042988
[epoch20, step173]: loss 0.045414
[epoch20, step174]: loss 0.044806
[epoch20, step175]: loss 0.042678
[epoch20, step176]: loss 0.043832
[epoch20, step177]: loss 0.045488
[epoch20, step178]: loss 0.041551
[epoch20, step179]: loss 0.044381
[epoch20, step180]: loss 0.042243
[epoch20, step181]: loss 0.042959
[epoch20, step182]: loss 0.045163
[epoch20, step183]: loss 0.045344
[epoch20, step184]: loss 0.042956
[epoch20, step185]: loss 0.043741
[epoch20, step186]: loss 0.045221
[epoch20, step187]: loss 0.041976
[epoch20, step188]: loss 0.044724
[epoch20, step189]: loss 0.042197
[epoch20, step190]: loss 0.042572
[epoch20, step191]: loss 0.044752
[epoch20, step192]: loss 0.045206
[epoch20, step193]: loss 0.041002
[epoch20, step194]: loss 0.043059
[epoch20, step195]: loss 0.045290
[epoch20, step196]: loss 0.041646
[epoch20, step197]: loss 0.044855
[epoch20, step198]: loss 0.041451
[epoch20, step199]: loss 0.042944
[epoch20, step200]: loss 0.045248
[epoch20, step201]: loss 0.045361
[epoch20, step202]: loss 0.042064
[epoch20, step203]: loss 0.043635
[epoch20, step204]: loss 0.045468
[epoch20, step205]: loss 0.041319
[epoch20, step206]: loss 0.044765
[epoch20, step207]: loss 0.041857
[epoch20, step208]: loss 0.043006
[epoch20, step209]: loss 0.045080
[epoch20, step210]: loss 0.045496
[epoch20, step211]: loss 0.042915
[epoch20, step212]: loss 0.043837
[epoch20, step213]: loss 0.044987
[epoch20, step214]: loss 0.041550
[epoch20, step215]: loss 0.045017
[epoch20, step216]: loss 0.042248
[epoch20, step217]: loss 0.042152
[epoch20, step218]: loss 0.045141
[epoch20, step219]: loss 0.044742
[epoch20, step220]: loss 0.042750
[epoch20, step221]: loss 0.043724
[epoch20, step222]: loss 0.045192
[epoch20, step223]: loss 0.041891
[epoch20, step224]: loss 0.044680
[epoch20, step225]: loss 0.042080
[epoch20, step226]: loss 0.042667
[epoch20, step227]: loss 0.044310
[epoch20, step228]: loss 0.045351
[epoch20, step229]: loss 0.041842
[epoch20, step230]: loss 0.043726
[epoch20, step231]: loss 0.045326
[epoch20, step232]: loss 0.041123
[epoch20, step233]: loss 0.044388
[epoch20, step234]: loss 0.041821
[epoch20, step235]: loss 0.043188
[epoch20, step236]: loss 0.044967
[epoch20, step237]: loss 0.045039
[epoch20, step238]: loss 0.041812
[epoch20, step239]: loss 0.043008
[epoch20, step240]: loss 0.044629
[epoch20, step241]: loss 0.042196
[epoch20, step242]: loss 0.044801
[epoch20, step243]: loss 0.042444
[epoch20, step244]: loss 0.042564
[epoch20, step245]: loss 0.044660
[epoch20, step246]: loss 0.044896
[epoch20, step247]: loss 0.042650
[epoch20, step248]: loss 0.043198
[epoch20, step249]: loss 0.044714
[epoch20, step250]: loss 0.041605
[epoch20, step251]: loss 0.045243
[epoch20, step252]: loss 0.042568
[epoch20, step253]: loss 0.042430
[epoch20, step254]: loss 0.044575
[epoch20, step255]: loss 0.044900
[epoch20, step256]: loss 0.042403
[epoch20, step257]: loss 0.043489
[epoch20, step258]: loss 0.045274
[epoch20, step259]: loss 0.041368
[epoch20, step260]: loss 0.044430
[epoch20, step261]: loss 0.042567
[epoch20, step262]: loss 0.043088
[epoch20, step263]: loss 0.044398
[epoch20, step264]: loss 0.044695
[epoch20, step265]: loss 0.042703
[epoch20, step266]: loss 0.043527
[epoch20, step267]: loss 0.044505
[epoch20, step268]: loss 0.041896
[epoch20, step269]: loss 0.044903
[epoch20, step270]: loss 0.041759
[epoch20, step271]: loss 0.042695
[epoch20, step272]: loss 0.044878
[epoch20, step273]: loss 0.044785
[epoch20, step274]: loss 0.042543
[epoch20, step275]: loss 0.043230
[epoch20, step276]: loss 0.044713
[epoch20, step277]: loss 0.041959
[epoch20, step278]: loss 0.044970
[epoch20, step279]: loss 0.041642
[epoch20, step280]: loss 0.042544
[epoch20, step281]: loss 0.044642
[epoch20, step282]: loss 0.045101
[epoch20, step283]: loss 0.042049
[epoch20, step284]: loss 0.043129
[epoch20, step285]: loss 0.045320
[epoch20, step286]: loss 0.041355
[epoch20, step287]: loss 0.044905
[epoch20, step288]: loss 0.041773
[epoch20, step289]: loss 0.043130
[epoch20, step290]: loss 0.045098
[epoch20, step291]: loss 0.045092
[epoch20, step292]: loss 0.041744
[epoch20, step293]: loss 0.043397
[epoch20, step294]: loss 0.044450
[epoch20, step295]: loss 0.041329
[epoch20, step296]: loss 0.045364
[epoch20, step297]: loss 0.041995
[epoch20, step298]: loss 0.042876
[epoch20, step299]: loss 0.044296
[epoch20, step300]: loss 0.045088
[epoch20, step301]: loss 0.042488
[epoch20, step302]: loss 0.043845
[epoch20, step303]: loss 0.045269
[epoch20, step304]: loss 0.040949
[epoch20, step305]: loss 0.044590
[epoch20, step306]: loss 0.042033
[epoch20, step307]: loss 0.042220
[epoch20, step308]: loss 0.045393
[epoch20, step309]: loss 0.044901
[epoch20, step310]: loss 0.042497
[epoch20, step311]: loss 0.043702
[epoch20, step312]: loss 0.044877
[epoch20, step313]: loss 0.042018
[epoch20, step314]: loss 0.044781
[epoch20, step315]: loss 0.042928
[epoch20, step316]: loss 0.042637
[epoch20, step317]: loss 0.045108
[epoch20, step318]: loss 0.044955
[epoch20, step319]: loss 0.041929
[epoch20, step320]: loss 0.042890
[epoch20, step321]: loss 0.044657
[epoch20, step322]: loss 0.044152
[epoch20, step323]: loss 0.044631
[epoch20, step324]: loss 0.042348
[epoch20, step325]: loss 0.043602
[epoch20, step326]: loss 0.044693
[epoch20, step327]: loss 0.044489
[epoch20, step328]: loss 0.044793
[epoch20, step329]: loss 0.043570
[epoch20, step330]: loss 0.045611
[epoch20, step331]: loss 0.044008
[epoch20, step332]: loss 0.044455
[epoch20, step333]: loss 0.041872
[epoch20, step334]: loss 0.045606
[epoch20, step335]: loss 0.045179
[epoch20, step336]: loss 0.045352
[epoch20, step337]: loss 0.042196
[epoch20, step338]: loss 0.043320
[epoch20, step339]: loss 0.046151
[epoch20, step340]: loss 0.044462
[epoch20, step341]: loss 0.044479
[epoch20, step342]: loss 0.041679
[epoch20, step343]: loss 0.043838
[epoch20, step344]: loss 0.044521
[epoch20, step345]: loss 0.044366
[epoch20, step346]: loss 0.044159
[epoch20, step347]: loss 0.043203
[epoch20, step348]: loss 0.045182
[epoch20, step349]: loss 0.043348
[epoch20, step350]: loss 0.044493
[epoch20, step351]: loss 0.042638
[epoch20, step352]: loss 0.042453
[epoch20, step353]: loss 0.044850
[epoch20, step354]: loss 0.044269
[epoch20, step355]: loss 0.042909
[epoch20, step356]: loss 0.044211
[epoch20, step357]: loss 0.045102
[epoch20, step358]: loss 0.041280
[epoch20, step359]: loss 0.045956
[epoch20, step360]: loss 0.041871
[epoch20, step361]: loss 0.043713
[epoch20, step362]: loss 0.045153
[epoch20, step363]: loss 0.044672
[epoch20, step364]: loss 0.042363
[epoch20, step365]: loss 0.043604
[epoch20, step366]: loss 0.045701
[epoch20, step367]: loss 0.044100
[epoch20, step368]: loss 0.044465
[epoch20, step369]: loss 0.042010
[epoch20, step370]: loss 0.043283
[epoch20, step371]: loss 0.045764
[epoch20, step372]: loss 0.044557
[epoch20, step373]: loss 0.042664
[epoch20, step374]: loss 0.042972
[epoch20, step375]: loss 0.045440
[epoch20, step376]: loss 0.041273
[epoch20, step377]: loss 0.044938
[epoch20, step378]: loss 0.044212
[epoch20, step379]: loss 0.043536
[epoch20, step380]: loss 0.045621
[epoch20, step381]: loss 0.044935
[epoch20, step382]: loss 0.045056
[epoch20, step383]: loss 0.043043
[epoch20, step384]: loss 0.044426
[epoch20, step385]: loss 0.041427
[epoch20, step386]: loss 0.045182
[epoch20, step387]: loss 0.041720
[epoch20, step388]: loss 0.043079
[epoch20, step389]: loss 0.044981
[epoch20, step390]: loss 0.045284
[epoch20, step391]: loss 0.041611
[epoch20, step392]: loss 0.043830
[epoch20, step393]: loss 0.044697
[epoch20, step394]: loss 0.043538
[epoch20, step395]: loss 0.044704
[epoch20, step396]: loss 0.042746
[epoch20, step397]: loss 0.042315
[epoch20, step398]: loss 0.044981
[epoch20, step399]: loss 0.044761
[epoch20, step400]: loss 0.041919
[epoch20, step401]: loss 0.043264
[epoch20, step402]: loss 0.044821
[epoch20, step403]: loss 0.042256
[epoch20, step404]: loss 0.045031
[epoch20, step405]: loss 0.042197
[epoch20, step406]: loss 0.043525
[epoch20, step407]: loss 0.044469
[epoch20, step408]: loss 0.045134
[epoch20, step409]: loss 0.042795
[epoch20, step410]: loss 0.043646
[epoch20, step411]: loss 0.044922
[epoch20, step412]: loss 0.040726
[epoch20, step413]: loss 0.044608
[epoch20, step414]: loss 0.041800
[epoch20, step415]: loss 0.042679
[epoch20, step416]: loss 0.044322
[epoch20, step417]: loss 0.044908
[epoch20, step418]: loss 0.041424
[epoch20, step419]: loss 0.042875
[epoch20, step420]: loss 0.044962
[epoch20, step421]: loss 0.041167
[epoch20, step422]: loss 0.044811
[epoch20, step423]: loss 0.041894
[epoch20, step424]: loss 0.042475
[epoch20, step425]: loss 0.045681
[epoch20, step426]: loss 0.045273
[epoch20, step427]: loss 0.043147
[epoch20, step428]: loss 0.044277
[epoch20, step429]: loss 0.046407
[epoch20, step430]: loss 0.040944
[epoch20, step431]: loss 0.045641
[epoch20, step432]: loss 0.042359
[epoch20, step433]: loss 0.043702
[epoch20, step434]: loss 0.044945
[epoch20, step435]: loss 0.045119
[epoch20, step436]: loss 0.041866
[epoch20, step437]: loss 0.043994
[epoch20, step438]: loss 0.046395
[epoch20, step439]: loss 0.041896
[epoch20, step440]: loss 0.044923
[epoch20, step441]: loss 0.042225
[epoch20, step442]: loss 0.043155
[epoch20, step443]: loss 0.045377
[epoch20, step444]: loss 0.044638
[epoch20, step445]: loss 0.042473
[epoch20, step446]: loss 0.043655
[epoch20, step447]: loss 0.045302
[epoch20, step448]: loss 0.041696
[epoch20, step449]: loss 0.044737
[epoch20, step450]: loss 0.041751
[epoch20, step451]: loss 0.044192
[epoch20, step452]: loss 0.043872
[epoch20, step453]: loss 0.045110
[epoch20, step454]: loss 0.041841
[epoch20, step455]: loss 0.043600
[epoch20, step456]: loss 0.044630
[epoch20, step457]: loss 0.041708
[epoch20, step458]: loss 0.044488
[epoch20, step459]: loss 0.042564
[epoch20, step460]: loss 0.042354
[epoch20, step461]: loss 0.045340
[epoch20, step462]: loss 0.044301
[epoch20, step463]: loss 0.042432
[epoch20, step464]: loss 0.043163
[epoch20, step465]: loss 0.045431
[epoch20, step466]: loss 0.040944
[epoch20, step467]: loss 0.044567
[epoch20, step468]: loss 0.041934
[epoch20, step469]: loss 0.042377
[epoch20, step470]: loss 0.044779
[epoch20, step471]: loss 0.044549
[epoch20, step472]: loss 0.042867
[epoch20, step473]: loss 0.043327
[epoch20, step474]: loss 0.044749
[epoch20, step475]: loss 0.041833
[epoch20, step476]: loss 0.045620
[epoch20, step477]: loss 0.041915
[epoch20, step478]: loss 0.042254
[epoch20, step479]: loss 0.044528
[epoch20, step480]: loss 0.044020
[epoch20, step481]: loss 0.041579
[epoch20, step482]: loss 0.042803
[epoch20, step483]: loss 0.045500
[epoch20, step484]: loss 0.042068
[epoch20, step485]: loss 0.044816
[epoch20, step486]: loss 0.042264
[epoch20, step487]: loss 0.042411
[epoch20, step488]: loss 0.045651
[epoch20, step489]: loss 0.044259
[epoch20, step490]: loss 0.042776
[epoch20, step491]: loss 0.043365
[epoch20, step492]: loss 0.044646
[epoch20, step493]: loss 0.041665
[epoch20, step494]: loss 0.044343
[epoch20, step495]: loss 0.043189
[epoch20, step496]: loss 0.042816
[epoch20, step497]: loss 0.044823
[epoch20, step498]: loss 0.044816
[epoch20, step499]: loss 0.042506
[epoch20, step500]: loss 0.042928
[epoch20, step501]: loss 0.044255
[epoch20, step502]: loss 0.041444
[epoch20, step503]: loss 0.044872
[epoch20, step504]: loss 0.041828
[epoch20, step505]: loss 0.042005
[epoch20, step506]: loss 0.044806
[epoch20, step507]: loss 0.044793
[epoch20, step508]: loss 0.042360
[epoch20, step509]: loss 0.043128
[epoch20, step510]: loss 0.045141
[epoch20, step511]: loss 0.041466
[epoch20, step512]: loss 0.045171
[epoch20, step513]: loss 0.042193
[epoch20, step514]: loss 0.042583
[epoch20, step515]: loss 0.045348
[epoch20, step516]: loss 0.045422
[epoch20, step517]: loss 0.042513
[epoch20, step518]: loss 0.045118
[epoch20, step519]: loss 0.048237
[epoch20, step520]: loss 0.041186
[epoch20, step521]: loss 0.044767
[epoch20, step522]: loss 0.042100
[epoch20, step523]: loss 0.043175
[epoch20, step524]: loss 0.044128
[epoch20, step525]: loss 0.045101
[epoch20, step526]: loss 0.043577
[epoch20, step527]: loss 0.043177
[epoch20, step528]: loss 0.045420
[epoch20, step529]: loss 0.043628
[epoch20, step530]: loss 0.044932
[epoch20, step531]: loss 0.042154
[epoch20, step532]: loss 0.042424
[epoch20, step533]: loss 0.045455
[epoch20, step534]: loss 0.044653
[epoch20, step535]: loss 0.042104
[epoch20, step536]: loss 0.043559
[epoch20, step537]: loss 0.044990
[epoch20, step538]: loss 0.041490
[epoch20, step539]: loss 0.044430
[epoch20, step540]: loss 0.041653
[epoch20, step541]: loss 0.042701
[epoch20, step542]: loss 0.044663
[epoch20, step543]: loss 0.044378
[epoch20, step544]: loss 0.041950
[epoch20, step545]: loss 0.042698
[epoch20, step546]: loss 0.045059
[epoch20, step547]: loss 0.041148
[epoch20, step548]: loss 0.044623
[epoch20, step549]: loss 0.042164
[epoch20, step550]: loss 0.042602
[epoch20, step551]: loss 0.044326
[epoch20, step552]: loss 0.044375
[epoch20, step553]: loss 0.042592
[epoch20, step554]: loss 0.042935
[epoch20, step555]: loss 0.044275
[epoch20, step556]: loss 0.041558
[epoch20, step557]: loss 0.044161
[epoch20, step558]: loss 0.042159
[epoch20, step559]: loss 0.041947
[epoch20, step560]: loss 0.044649
[epoch20, step561]: loss 0.044560
[epoch20, step562]: loss 0.041904
[epoch20, step563]: loss 0.034931
[epoch20, step564]: loss 0.035636
[epoch20, step565]: loss 0.032989
[epoch20, step566]: loss 0.040928
[epoch20, step567]: loss 0.031664
[epoch20, step568]: loss 0.031866
[epoch20, step569]: loss 0.032354
[epoch20, step570]: loss 0.037344
[epoch20, step571]: loss 0.031261
[epoch20, step572]: loss 0.030531
[epoch20, step573]: loss 0.034926
[epoch20, step574]: loss 0.035265
[epoch20, step575]: loss 0.027225
[epoch20, step576]: loss 0.028145
[epoch20, step577]: loss 0.031348
[epoch20, step578]: loss 0.026539
[epoch20, step579]: loss 0.032669
[epoch20, step580]: loss 0.028460
[epoch20, step581]: loss 0.031764
[epoch20, step582]: loss 0.031069
[epoch20, step583]: loss 0.028851
[epoch20, step584]: loss 0.029206
[epoch20, step585]: loss 0.033123
[epoch20, step586]: loss 0.028508
[epoch20, step587]: loss 0.031600
[epoch20, step588]: loss 0.029609
[epoch20, step589]: loss 0.032155
[epoch20, step590]: loss 0.031023
[epoch20, step591]: loss 0.026592
[epoch20, step592]: loss 0.032906
[epoch20, step593]: loss 0.030631
[epoch20, step594]: loss 0.030054
[epoch20, step595]: loss 0.030326
[epoch20, step596]: loss 0.029673
[epoch20, step597]: loss 0.031926
[epoch20, step598]: loss 0.030857
[epoch20, step599]: loss 0.029237
[epoch20, step600]: loss 0.031629
[epoch20, step601]: loss 0.025696
[epoch20, step602]: loss 0.030105
[epoch20, step603]: loss 0.030490
[epoch20, step604]: loss 0.030874
[epoch20, step605]: loss 0.029411
[epoch20, step606]: loss 0.030469
[epoch20, step607]: loss 0.033314
[epoch20, step608]: loss 0.028857
[epoch20, step609]: loss 0.032623
[epoch20, step610]: loss 0.031629
[epoch20, step611]: loss 0.032460
[epoch20, step612]: loss 0.030947
[epoch20, step613]: loss 0.026533
[epoch20, step614]: loss 0.030981
[epoch20, step615]: loss 0.033369
[epoch20, step616]: loss 0.028441
[epoch20, step617]: loss 0.029085
[epoch20, step618]: loss 0.031838
[epoch20, step619]: loss 0.031282
[epoch20, step620]: loss 0.028254
[epoch20, step621]: loss 0.030186
[epoch20, step622]: loss 0.027306
[epoch20, step623]: loss 0.030288
[epoch20, step624]: loss 0.032189
[epoch20, step625]: loss 0.029284
[epoch20, step626]: loss 0.034116
[epoch20, step627]: loss 0.030213
[epoch20, step628]: loss 0.031723
[epoch20, step629]: loss 0.023676
[epoch20, step630]: loss 0.028175
[epoch20, step631]: loss 0.035559
[epoch20, step632]: loss 0.029155
[epoch20, step633]: loss 0.029111
[epoch20, step634]: loss 0.033095
[epoch20, step635]: loss 0.030448
[epoch20, step636]: loss 0.025401
[epoch20, step637]: loss 0.033569
[epoch20, step638]: loss 0.032506
[epoch20, step639]: loss 0.027093
[epoch20, step640]: loss 0.035423
[epoch20, step641]: loss 0.033937
[epoch20, step642]: loss 0.029175
[epoch20, step643]: loss 0.032214
[epoch20, step644]: loss 0.030937
[epoch20, step645]: loss 0.027237
[epoch20, step646]: loss 0.031930
[epoch20, step647]: loss 0.027427
[epoch20, step648]: loss 0.030230
[epoch20, step649]: loss 0.033569
[epoch20, step650]: loss 0.028630
[epoch20, step651]: loss 0.031522
[epoch20, step652]: loss 0.033763
[epoch20, step653]: loss 0.034739
[epoch20, step654]: loss 0.029168
[epoch20, step655]: loss 0.028482
[epoch20, step656]: loss 0.028370
[epoch20, step657]: loss 0.033708
[epoch20, step658]: loss 0.029629
[epoch20, step659]: loss 0.031174
[epoch20, step660]: loss 0.029731
[epoch20, step661]: loss 0.032543
[epoch20, step662]: loss 0.027919
[epoch20, step663]: loss 0.026717
[epoch20, step664]: loss 0.029924
[epoch20, step665]: loss 0.034352
[epoch20, step666]: loss 0.030431
[epoch20, step667]: loss 0.032085
[epoch20, step668]: loss 0.029133
[epoch20, step669]: loss 0.030158
[epoch20, step670]: loss 0.032717
[epoch20, step671]: loss 0.027556
[epoch20, step672]: loss 0.031450
[epoch20, step673]: loss 0.028863
[epoch20, step674]: loss 0.026648
[epoch20, step675]: loss 0.026843
[epoch20, step676]: loss 0.030650
[epoch20, step677]: loss 0.030121
[epoch20, step678]: loss 0.027346
[epoch20, step679]: loss 0.029524
[epoch20, step680]: loss 0.034170
[epoch20, step681]: loss 0.026288
[epoch20, step682]: loss 0.030481
[epoch20, step683]: loss 0.031054
[epoch20, step684]: loss 0.029037
[epoch20, step685]: loss 0.028972
[epoch20, step686]: loss 0.031406
[epoch20, step687]: loss 0.031508
[epoch20, step688]: loss 0.028632
[epoch20, step689]: loss 0.028732
[epoch20, step690]: loss 0.031515
[epoch20, step691]: loss 0.030899
[epoch20, step692]: loss 0.028986
[epoch20, step693]: loss 0.032867
[epoch20, step694]: loss 0.026839
[epoch20, step695]: loss 0.031150
[epoch20, step696]: loss 0.030135
[epoch20, step697]: loss 0.032367
[epoch20, step698]: loss 0.029658
[epoch20, step699]: loss 0.028462
[epoch20, step700]: loss 0.029170
[epoch20, step701]: loss 0.031456
[epoch20, step702]: loss 0.026703
[epoch20, step703]: loss 0.030157
[epoch20, step704]: loss 0.031177
[epoch20, step705]: loss 0.029137
[epoch20, step706]: loss 0.028615
[epoch20, step707]: loss 0.029381
[epoch20, step708]: loss 0.031118
[epoch20, step709]: loss 0.031793
[epoch20, step710]: loss 0.029173
[epoch20, step711]: loss 0.030153
[epoch20, step712]: loss 0.030437
[epoch20, step713]: loss 0.030838
[epoch20, step714]: loss 0.027610
[epoch20, step715]: loss 0.027840
[epoch20, step716]: loss 0.031452
[epoch20, step717]: loss 0.028121
[epoch20, step718]: loss 0.030528
[epoch20, step719]: loss 0.037783
[epoch20, step720]: loss 0.028910
[epoch20, step721]: loss 0.028317
[epoch20, step722]: loss 0.036284
[epoch20, step723]: loss 0.031110
[epoch20, step724]: loss 0.029058
[epoch20, step725]: loss 0.033707
[epoch20, step726]: loss 0.026202
[epoch20, step727]: loss 0.030166
[epoch20, step728]: loss 0.031805
[epoch20, step729]: loss 0.026028
[epoch20, step730]: loss 0.028586
[epoch20, step731]: loss 0.032035
[epoch20, step732]: loss 0.030400
[epoch20, step733]: loss 0.027612
[epoch20, step734]: loss 0.027519
[epoch20, step735]: loss 0.031616
[epoch20, step736]: loss 0.029516
[epoch20, step737]: loss 0.030514
[epoch20, step738]: loss 0.025449
[epoch20, step739]: loss 0.032528
[epoch20, step740]: loss 0.030263
[epoch20, step741]: loss 0.030369
[epoch20, step742]: loss 0.028377
[epoch20, step743]: loss 0.028739
[epoch20, step744]: loss 0.029141
[epoch20, step745]: loss 0.030020
[epoch20, step746]: loss 0.030550
[epoch20, step747]: loss 0.032127
[epoch20, step748]: loss 0.030137
[epoch20, step749]: loss 0.033351
[epoch20, step750]: loss 0.033059
[epoch20, step751]: loss 0.026705
[epoch20, step752]: loss 0.029037
[epoch20, step753]: loss 0.029615
[epoch20, step754]: loss 0.029113
[epoch20, step755]: loss 0.031888
[epoch20, step756]: loss 0.027122
[epoch20, step757]: loss 0.026246
[epoch20, step758]: loss 0.030810
[epoch20, step759]: loss 0.027276
[epoch20, step760]: loss 0.029701
[epoch20, step761]: loss 0.030961
[epoch20, step762]: loss 0.026299
[epoch20, step763]: loss 0.029792
[epoch20, step764]: loss 0.029464
[epoch20, step765]: loss 0.029814
[epoch20, step766]: loss 0.028926
[epoch20, step767]: loss 0.031945
[epoch20, step768]: loss 0.026924
[epoch20, step769]: loss 0.032001
[epoch20, step770]: loss 0.032613
[epoch20, step771]: loss 0.027241
[epoch20, step772]: loss 0.033020
[epoch20, step773]: loss 0.031340
[epoch20, step774]: loss 0.029063
[epoch20, step775]: loss 0.027810
[epoch20, step776]: loss 0.031129
[epoch20, step777]: loss 0.027925
[epoch20, step778]: loss 0.034284
[epoch20, step779]: loss 0.028812
[epoch20, step780]: loss 0.026367
[epoch20, step781]: loss 0.031370
[epoch20, step782]: loss 0.029396
[epoch20, step783]: loss 0.025210
[epoch20, step784]: loss 0.026834
[epoch20, step785]: loss 0.027645
[epoch20, step786]: loss 0.029169
[epoch20, step787]: loss 0.030171
[epoch20, step788]: loss 0.030185
[epoch20, step789]: loss 0.029043
[epoch20, step790]: loss 0.027390
[epoch20, step791]: loss 0.032392
[epoch20, step792]: loss 0.030448
[epoch20, step793]: loss 0.032395
[epoch20, step794]: loss 0.026033
[epoch20, step795]: loss 0.030628
[epoch20, step796]: loss 0.031939
[epoch20, step797]: loss 0.031785
[epoch20, step798]: loss 0.031232
[epoch20, step799]: loss 0.028945
[epoch20, step800]: loss 0.028847
[epoch20, step801]: loss 0.028696
[epoch20, step802]: loss 0.027824
[epoch20, step803]: loss 0.030531
[epoch20, step804]: loss 0.032862
[epoch20, step805]: loss 0.032822
[epoch20, step806]: loss 0.027074
[epoch20, step807]: loss 0.026979
[epoch20, step808]: loss 0.029780
[epoch20, step809]: loss 0.027812
[epoch20, step810]: loss 0.029202
[epoch20, step811]: loss 0.031100
[epoch20, step812]: loss 0.030210
[epoch20, step813]: loss 0.028113
[epoch20, step814]: loss 0.030582
[epoch20, step815]: loss 0.029927
[epoch20, step816]: loss 0.029364
[epoch20, step817]: loss 0.028877
[epoch20, step818]: loss 0.027690
[epoch20, step819]: loss 0.028854
[epoch20, step820]: loss 0.027510
[epoch20, step821]: loss 0.026400
[epoch20, step822]: loss 0.035836
[epoch20, step823]: loss 0.028305
[epoch20, step824]: loss 0.032126
[epoch20, step825]: loss 0.030674
[epoch20, step826]: loss 0.027855
[epoch20, step827]: loss 0.030831
[epoch20, step828]: loss 0.033707
[epoch20, step829]: loss 0.030691
[epoch20, step830]: loss 0.025847
[epoch20, step831]: loss 0.030234
[epoch20, step832]: loss 0.028030
[epoch20, step833]: loss 0.033867
[epoch20, step834]: loss 0.030422
[epoch20, step835]: loss 0.026536
[epoch20, step836]: loss 0.030791
[epoch20, step837]: loss 0.029720
[epoch20, step838]: loss 0.032308
[epoch20, step839]: loss 0.032980
[epoch20, step840]: loss 0.025432
[epoch20, step841]: loss 0.029409
[epoch20, step842]: loss 0.032492
[epoch20, step843]: loss 0.030549
[epoch20, step844]: loss 0.031065
[epoch20, step845]: loss 0.026972
[epoch20, step846]: loss 0.033152
[epoch20, step847]: loss 0.031646
[epoch20, step848]: loss 0.027562
[epoch20, step849]: loss 0.029816
[epoch20, step850]: loss 0.029164
[epoch20, step851]: loss 0.029447
[epoch20, step852]: loss 0.028368
[epoch20, step853]: loss 0.034616
[epoch20, step854]: loss 0.028735
[epoch20, step855]: loss 0.031268
[epoch20, step856]: loss 0.026280
[epoch20, step857]: loss 0.031379
[epoch20, step858]: loss 0.029839
[epoch20, step859]: loss 0.027757
[epoch20, step860]: loss 0.028864
[epoch20, step861]: loss 0.028416
[epoch20, step862]: loss 0.026990
[epoch20, step863]: loss 0.026722
[epoch20, step864]: loss 0.032696
[epoch20, step865]: loss 0.028762
[epoch20, step866]: loss 0.030654
[epoch20, step867]: loss 0.030666
[epoch20, step868]: loss 0.032211
[epoch20, step869]: loss 0.027812
[epoch20, step870]: loss 0.034199
[epoch20, step871]: loss 0.028907
[epoch20, step872]: loss 0.030752
[epoch20, step873]: loss 0.029468
[epoch20, step874]: loss 0.028728
[epoch20, step875]: loss 0.031073
[epoch20, step876]: loss 0.030115
[epoch20, step877]: loss 0.021915
[epoch20, step878]: loss 0.028035
[epoch20, step879]: loss 0.032147
[epoch20, step880]: loss 0.029861
[epoch20, step881]: loss 0.028606
[epoch20, step882]: loss 0.028184
[epoch20, step883]: loss 0.028851
[epoch20, step884]: loss 0.032849
[epoch20, step885]: loss 0.032484
[epoch20, step886]: loss 0.032603
[epoch20, step887]: loss 0.030932
[epoch20, step888]: loss 0.029300
[epoch20, step889]: loss 0.029503
[epoch20, step890]: loss 0.029357
[epoch20, step891]: loss 0.029391
[epoch20, step892]: loss 0.027259
[epoch20, step893]: loss 0.030296
[epoch20, step894]: loss 0.030496
[epoch20, step895]: loss 0.026598
[epoch20, step896]: loss 0.029650
[epoch20, step897]: loss 0.030819
[epoch20, step898]: loss 0.029928
[epoch20, step899]: loss 0.030407
[epoch20, step900]: loss 0.031988
[epoch20, step901]: loss 0.031193
[epoch20, step902]: loss 0.028226
[epoch20, step903]: loss 0.030992
[epoch20, step904]: loss 0.032381
[epoch20, step905]: loss 0.031402
[epoch20, step906]: loss 0.026074
[epoch20, step907]: loss 0.029638
[epoch20, step908]: loss 0.029243
[epoch20, step909]: loss 0.030183
[epoch20, step910]: loss 0.026860
[epoch20, step911]: loss 0.028642
[epoch20, step912]: loss 0.029557
[epoch20, step913]: loss 0.029696
[epoch20, step914]: loss 0.035250
[epoch20, step915]: loss 0.028118
[epoch20, step916]: loss 0.029212
[epoch20, step917]: loss 0.030127
[epoch20, step918]: loss 0.034129
[epoch20, step919]: loss 0.028328
[epoch20, step920]: loss 0.033586
[epoch20, step921]: loss 0.028711
[epoch20, step922]: loss 0.027848
[epoch20, step923]: loss 0.029135
[epoch20, step924]: loss 0.025935
[epoch20, step925]: loss 0.029780
[epoch20, step926]: loss 0.031066
[epoch20, step927]: loss 0.031607
[epoch20, step928]: loss 0.029015
[epoch20, step929]: loss 0.032133
[epoch20, step930]: loss 0.030825
[epoch20, step931]: loss 0.032966
[epoch20, step932]: loss 0.026193
[epoch20, step933]: loss 0.032454
[epoch20, step934]: loss 0.028754
[epoch20, step935]: loss 0.027925
[epoch20, step936]: loss 0.027410
[epoch20, step937]: loss 0.030832
[epoch20, step938]: loss 0.031923
[epoch20, step939]: loss 0.025627
[epoch20, step940]: loss 0.029198
[epoch20, step941]: loss 0.031839
[epoch20, step942]: loss 0.030146
[epoch20, step943]: loss 0.029562
[epoch20, step944]: loss 0.032668
[epoch20, step945]: loss 0.026645
[epoch20, step946]: loss 0.030444
[epoch20, step947]: loss 0.032016
[epoch20, step948]: loss 0.028137
[epoch20, step949]: loss 0.027715
[epoch20, step950]: loss 0.031558
[epoch20, step951]: loss 0.034202
[epoch20, step952]: loss 0.030738
[epoch20, step953]: loss 0.032599
[epoch20, step954]: loss 0.027997
[epoch20, step955]: loss 0.039388
[epoch20, step956]: loss 0.056262
[epoch20, step957]: loss 0.049453
[epoch20, step958]: loss 0.048322
[epoch20, step959]: loss 0.051081
[epoch20, step960]: loss 0.046976
[epoch20, step961]: loss 0.047971
[epoch20, step962]: loss 0.046346
[epoch20, step963]: loss 0.045758
[epoch20, step964]: loss 0.045045
[epoch20, step965]: loss 0.046080
[epoch20, step966]: loss 0.043838
[epoch20, step967]: loss 0.043556
[epoch20, step968]: loss 0.045823
[epoch20, step969]: loss 0.044562
[epoch20, step970]: loss 0.043935
[epoch20, step971]: loss 0.043767
[epoch20, step972]: loss 0.045417
[epoch20, step973]: loss 0.043877
[epoch20, step974]: loss 0.045857
[epoch20, step975]: loss 0.043925
[epoch20, step976]: loss 0.043831
[epoch20, step977]: loss 0.046718
[epoch20, step978]: loss 0.044425
[epoch20, step979]: loss 0.043467
[epoch20, step980]: loss 0.043106
[epoch20, step981]: loss 0.044491
[epoch20, step982]: loss 0.043903
[epoch20, step983]: loss 0.045057
[epoch20, step984]: loss 0.042408
[epoch20, step985]: loss 0.043207
[epoch20, step986]: loss 0.046057
[epoch20, step987]: loss 0.043804
[epoch20, step988]: loss 0.043818
[epoch20, step989]: loss 0.043675
[epoch20, step990]: loss 0.043833
[epoch20, step991]: loss 0.044033
[epoch20, step992]: loss 0.044849
[epoch20, step993]: loss 0.042999
[epoch20, step994]: loss 0.042490
[epoch20, step995]: loss 0.045257
[epoch20, step996]: loss 0.042926
[epoch20, step997]: loss 0.043175
[epoch20, step998]: loss 0.043443
[epoch20, step999]: loss 0.043751
[epoch20, step1000]: loss 0.043430
[epoch20, step1001]: loss 0.044812
[epoch20, step1002]: loss 0.042650
[epoch20, step1003]: loss 0.042674
[epoch20, step1004]: loss 0.045125
[epoch20, step1005]: loss 0.042187
[epoch20, step1006]: loss 0.042872
[epoch20, step1007]: loss 0.042315
[epoch20, step1008]: loss 0.043225
[epoch20, step1009]: loss 0.042989
[epoch20, step1010]: loss 0.044692
[epoch20, step1011]: loss 0.042416
[epoch20, step1012]: loss 0.043104
[epoch20, step1013]: loss 0.044991
[epoch20, step1014]: loss 0.043298
[epoch20, step1015]: loss 0.042976
[epoch20, step1016]: loss 0.042350
[epoch20, step1017]: loss 0.043349
[epoch20, step1018]: loss 0.042764
[epoch20, step1019]: loss 0.044512
[epoch20, step1020]: loss 0.042037
[epoch20, step1021]: loss 0.042665
[epoch20, step1022]: loss 0.044684
[epoch20, step1023]: loss 0.042598
[epoch20, step1024]: loss 0.043107
[epoch20, step1025]: loss 0.042021
[epoch20, step1026]: loss 0.043039
[epoch20, step1027]: loss 0.042357
[epoch20, step1028]: loss 0.044160
[epoch20, step1029]: loss 0.041861
[epoch20, step1030]: loss 0.042241
[epoch20, step1031]: loss 0.043784
[epoch20, step1032]: loss 0.042537
[epoch20, step1033]: loss 0.042304
[epoch20, step1034]: loss 0.042174
[epoch20, step1035]: loss 0.042787
[epoch20, step1036]: loss 0.043095
[epoch20, step1037]: loss 0.043969
[epoch20, step1038]: loss 0.041960
[epoch20, step1039]: loss 0.042679
[epoch20, step1040]: loss 0.044293
[epoch20, step1041]: loss 0.042498
[epoch20, step1042]: loss 0.041722
[epoch20, step1043]: loss 0.042156
[epoch20, step1044]: loss 0.043346
[epoch20, step1045]: loss 0.042749
[epoch20, step1046]: loss 0.044315
[epoch20, step1047]: loss 0.041984
[epoch20, step1048]: loss 0.042447
[epoch20, step1049]: loss 0.044761
[epoch20, step1050]: loss 0.042571
[epoch20, step1051]: loss 0.042519
[epoch20, step1052]: loss 0.042647
[epoch20, step1053]: loss 0.043689
[epoch20, step1054]: loss 0.042624
[epoch20, step1055]: loss 0.043639
[epoch20, step1056]: loss 0.041459
[epoch20, step1057]: loss 0.042913
[epoch20, step1058]: loss 0.045040
[epoch20, step1059]: loss 0.042610
[epoch20, step1060]: loss 0.042451
[epoch20, step1061]: loss 0.041755
[epoch20, step1062]: loss 0.043631
[epoch20, step1063]: loss 0.042756
[epoch20, step1064]: loss 0.044104
[epoch20, step1065]: loss 0.042011
[epoch20, step1066]: loss 0.042216
[epoch20, step1067]: loss 0.044542
[epoch20, step1068]: loss 0.041634
[epoch20, step1069]: loss 0.041734
[epoch20, step1070]: loss 0.042174
[epoch20, step1071]: loss 0.043624
[epoch20, step1072]: loss 0.043155
[epoch20, step1073]: loss 0.043833
[epoch20, step1074]: loss 0.042041
[epoch20, step1075]: loss 0.042663
[epoch20, step1076]: loss 0.044529
[epoch20, step1077]: loss 0.042271
[epoch20, step1078]: loss 0.042275
[epoch20, step1079]: loss 0.042896
[epoch20, step1080]: loss 0.043364
[epoch20, step1081]: loss 0.042784
[epoch20, step1082]: loss 0.043868
[epoch20, step1083]: loss 0.042628
[epoch20, step1084]: loss 0.042628
[epoch20, step1085]: loss 0.044100
[epoch20, step1086]: loss 0.042260
[epoch20, step1087]: loss 0.042487
[epoch20, step1088]: loss 0.042145
[epoch20, step1089]: loss 0.043506
[epoch20, step1090]: loss 0.042950
[epoch20, step1091]: loss 0.044326
[epoch20, step1092]: loss 0.041961
[epoch20, step1093]: loss 0.042498
[epoch20, step1094]: loss 0.043668
[epoch20, step1095]: loss 0.041913
[epoch20, step1096]: loss 0.042062
[epoch20, step1097]: loss 0.042157
[epoch20, step1098]: loss 0.043154
[epoch20, step1099]: loss 0.042304
[epoch20, step1100]: loss 0.044410
[epoch20, step1101]: loss 0.042438
[epoch20, step1102]: loss 0.042363
[epoch20, step1103]: loss 0.044024
[epoch20, step1104]: loss 0.042026
[epoch20, step1105]: loss 0.042432
[epoch20, step1106]: loss 0.041442
[epoch20, step1107]: loss 0.043340
[epoch20, step1108]: loss 0.042315
[epoch20, step1109]: loss 0.044177
[epoch20, step1110]: loss 0.042440
[epoch20, step1111]: loss 0.042560
[epoch20, step1112]: loss 0.044592
[epoch20, step1113]: loss 0.042000
[epoch20, step1114]: loss 0.042595
[epoch20, step1115]: loss 0.042257
[epoch20, step1116]: loss 0.043298
[epoch20, step1117]: loss 0.042642
[epoch20, step1118]: loss 0.044057
[epoch20, step1119]: loss 0.042109
[epoch20, step1120]: loss 0.042370
[epoch20, step1121]: loss 0.044323
[epoch20, step1122]: loss 0.042018
[epoch20, step1123]: loss 0.041806
[epoch20, step1124]: loss 0.042601
[epoch20, step1125]: loss 0.043359
[epoch20, step1126]: loss 0.043270
[epoch20, step1127]: loss 0.044033
[epoch20, step1128]: loss 0.042179
[epoch20, step1129]: loss 0.042349
[epoch20, step1130]: loss 0.044738
[epoch20, step1131]: loss 0.042543
[epoch20, step1132]: loss 0.042660
[epoch20, step1133]: loss 0.041739
[epoch20, step1134]: loss 0.042902
[epoch20, step1135]: loss 0.043176
[epoch20, step1136]: loss 0.044444
[epoch20, step1137]: loss 0.041794
[epoch20, step1138]: loss 0.042579
[epoch20, step1139]: loss 0.044485
[epoch20, step1140]: loss 0.041640
[epoch20, step1141]: loss 0.042032
[epoch20, step1142]: loss 0.041954
[epoch20, step1143]: loss 0.042854
[epoch20, step1144]: loss 0.042720
[epoch20, step1145]: loss 0.043662
[epoch20, step1146]: loss 0.041466
[epoch20, step1147]: loss 0.043001
[epoch20, step1148]: loss 0.044397
[epoch20, step1149]: loss 0.041773
[epoch20, step1150]: loss 0.042202
[epoch20, step1151]: loss 0.042419
[epoch20, step1152]: loss 0.043438
[epoch20, step1153]: loss 0.042050
[epoch20, step1154]: loss 0.044235
[epoch20, step1155]: loss 0.042194
[epoch20, step1156]: loss 0.041870
[epoch20, step1157]: loss 0.044126
[epoch20, step1158]: loss 0.042211
[epoch20, step1159]: loss 0.042386
[epoch20, step1160]: loss 0.042701
[epoch20, step1161]: loss 0.043390
[epoch20, step1162]: loss 0.042446
[epoch20, step1163]: loss 0.043571
[epoch20, step1164]: loss 0.041793
[epoch20, step1165]: loss 0.043100
[epoch20, step1166]: loss 0.044309
[epoch20, step1167]: loss 0.041502
[epoch20, step1168]: loss 0.042376
[epoch20, step1169]: loss 0.041956
[epoch20, step1170]: loss 0.043316
[epoch20, step1171]: loss 0.042308
[epoch20, step1172]: loss 0.044065
[epoch20, step1173]: loss 0.042122
[epoch20, step1174]: loss 0.042615
[epoch20, step1175]: loss 0.044316
[epoch20, step1176]: loss 0.041786
[epoch20, step1177]: loss 0.042447
[epoch20, step1178]: loss 0.042115
[epoch20, step1179]: loss 0.043171
[epoch20, step1180]: loss 0.042560
[epoch20, step1181]: loss 0.044414
[epoch20, step1182]: loss 0.041403
[epoch20, step1183]: loss 0.042911
[epoch20, step1184]: loss 0.043829
[epoch20, step1185]: loss 0.042461
[epoch20, step1186]: loss 0.041674
[epoch20, step1187]: loss 0.041558
[epoch20, step1188]: loss 0.042626
[epoch20, step1189]: loss 0.042114
[epoch20, step1190]: loss 0.043694
[epoch20, step1191]: loss 0.042573
[epoch20, step1192]: loss 0.042477
[epoch20, step1193]: loss 0.043992
[epoch20, step1194]: loss 0.041983
[epoch20, step1195]: loss 0.041489
[epoch20, step1196]: loss 0.041522
[epoch20, step1197]: loss 0.043367
[epoch20, step1198]: loss 0.042372
[epoch20, step1199]: loss 0.043630
[epoch20, step1200]: loss 0.041662
[epoch20, step1201]: loss 0.042558
[epoch20, step1202]: loss 0.044962
[epoch20, step1203]: loss 0.042417
[epoch20, step1204]: loss 0.041761
[epoch20, step1205]: loss 0.041663
[epoch20, step1206]: loss 0.042733
[epoch20, step1207]: loss 0.042503
[epoch20, step1208]: loss 0.044048
[epoch20, step1209]: loss 0.040842
[epoch20, step1210]: loss 0.042677
[epoch20, step1211]: loss 0.043712
[epoch20, step1212]: loss 0.042167
[epoch20, step1213]: loss 0.041996
[epoch20, step1214]: loss 0.042192
[epoch20, step1215]: loss 0.043420
[epoch20, step1216]: loss 0.042053
[epoch20, step1217]: loss 0.044382
[epoch20, step1218]: loss 0.041466
[epoch20, step1219]: loss 0.042879
[epoch20, step1220]: loss 0.044338
[epoch20, step1221]: loss 0.041193
[epoch20, step1222]: loss 0.042303
[epoch20, step1223]: loss 0.041715
[epoch20, step1224]: loss 0.043409
[epoch20, step1225]: loss 0.042343
[epoch20, step1226]: loss 0.043701
[epoch20, step1227]: loss 0.041541
[epoch20, step1228]: loss 0.042025
[epoch20, step1229]: loss 0.044131
[epoch20, step1230]: loss 0.042480
[epoch20, step1231]: loss 0.042154
[epoch20, step1232]: loss 0.042888
[epoch20, step1233]: loss 0.042829
[epoch20, step1234]: loss 0.042258
[epoch20, step1235]: loss 0.044325
[epoch20, step1236]: loss 0.042352
[epoch20, step1237]: loss 0.042140
[epoch20, step1238]: loss 0.043913
[epoch20, step1239]: loss 0.042421
[epoch20, step1240]: loss 0.042430
[epoch20, step1241]: loss 0.041860
[epoch20, step1242]: loss 0.042856
[epoch20, step1243]: loss 0.042174
[epoch20, step1244]: loss 0.044144
[epoch20, step1245]: loss 0.041897
[epoch20, step1246]: loss 0.042543
[epoch20, step1247]: loss 0.043479
[epoch20, step1248]: loss 0.042154
[epoch20, step1249]: loss 0.042477
[epoch20, step1250]: loss 0.041793
[epoch20, step1251]: loss 0.043106
[epoch20, step1252]: loss 0.043013
[epoch20, step1253]: loss 0.044051
[epoch20, step1254]: loss 0.042040
[epoch20, step1255]: loss 0.042378
[epoch20, step1256]: loss 0.044348
[epoch20, step1257]: loss 0.042218
[epoch20, step1258]: loss 0.042340
[epoch20, step1259]: loss 0.041712
[epoch20, step1260]: loss 0.042916
[epoch20, step1261]: loss 0.042269
[epoch20, step1262]: loss 0.043039
[epoch20, step1263]: loss 0.042295
[epoch20, step1264]: loss 0.042291
[epoch20, step1265]: loss 0.043216
[epoch20, step1266]: loss 0.042172
[epoch20, step1267]: loss 0.042235
[epoch20, step1268]: loss 0.042197
[epoch20, step1269]: loss 0.042942
[epoch20, step1270]: loss 0.041991
[epoch20, step1271]: loss 0.044270
[epoch20, step1272]: loss 0.042126
[epoch20, step1273]: loss 0.042216
[epoch20, step1274]: loss 0.043905
[epoch20, step1275]: loss 0.042520
[epoch20, step1276]: loss 0.041898
[epoch20, step1277]: loss 0.041877
[epoch20, step1278]: loss 0.043300
[epoch20, step1279]: loss 0.042405
[epoch20, step1280]: loss 0.044118
[epoch20, step1281]: loss 0.041903
[epoch20, step1282]: loss 0.042238
[epoch20, step1283]: loss 0.043655
[epoch20, step1284]: loss 0.041638
[epoch20, step1285]: loss 0.042542
[epoch20, step1286]: loss 0.041418
[epoch20, step1287]: loss 0.043395
[epoch20, step1288]: loss 0.042923
[epoch20, step1289]: loss 0.044542
[epoch20, step1290]: loss 0.042040
[epoch20, step1291]: loss 0.042113
[epoch20, step1292]: loss 0.044466
[epoch20, step1293]: loss 0.041223
[epoch20, step1294]: loss 0.042055
[epoch20, step1295]: loss 0.042209
[epoch20, step1296]: loss 0.042951
[epoch20, step1297]: loss 0.041919
[epoch20, step1298]: loss 0.044259
[epoch20, step1299]: loss 0.042210
[epoch20, step1300]: loss 0.042727
[epoch20, step1301]: loss 0.043708
[epoch20, step1302]: loss 0.042150
[epoch20, step1303]: loss 0.042393
[epoch20, step1304]: loss 0.041437
[epoch20, step1305]: loss 0.043148
[epoch20, step1306]: loss 0.042122
[epoch20, step1307]: loss 0.043527
[epoch20, step1308]: loss 0.042207
[epoch20, step1309]: loss 0.041827
[epoch20, step1310]: loss 0.044067
[epoch20, step1311]: loss 0.041279
[epoch20, step1312]: loss 0.042754
[epoch20, step1313]: loss 0.042056
[epoch20, step1314]: loss 0.042787
[epoch20, step1315]: loss 0.042075
[epoch20, step1316]: loss 0.044934
[epoch20, step1317]: loss 0.041461
[epoch20, step1318]: loss 0.041950
[epoch20, step1319]: loss 0.043711
[epoch20, step1320]: loss 0.042411
[epoch20, step1321]: loss 0.042407
[epoch20, step1322]: loss 0.041733
[epoch20, step1323]: loss 0.043025
[epoch20, step1324]: loss 0.041985
[epoch20, step1325]: loss 0.043837
[epoch20, step1326]: loss 0.041827
[epoch20, step1327]: loss 0.042078
[epoch20, step1328]: loss 0.044108
[epoch20, step1329]: loss 0.042082
[epoch20, step1330]: loss 0.042279
[epoch20, step1331]: loss 0.041734
[epoch20, step1332]: loss 0.042918
[epoch20, step1333]: loss 0.041631
[epoch20, step1334]: loss 0.044097
[epoch20, step1335]: loss 0.042380
[epoch20, step1336]: loss 0.042326
[epoch20, step1337]: loss 0.043403
[epoch20, step1338]: loss 0.041685
[epoch20, step1339]: loss 0.042291
[epoch20, step1340]: loss 0.041743
[epoch20, step1341]: loss 0.042911
[epoch20, step1342]: loss 0.042060
[epoch20, step1343]: loss 0.044020
[epoch20, step1344]: loss 0.041789
[epoch20, step1345]: loss 0.042246
[epoch20, step1346]: loss 0.043769
[epoch20, step1347]: loss 0.042569
[epoch20, step1348]: loss 0.041747
[epoch20, step1349]: loss 0.042025
[epoch20, step1350]: loss 0.043033
[epoch20, step1351]: loss 0.041917
[epoch20, step1352]: loss 0.043401
[epoch20, step1353]: loss 0.041689
[epoch20, step1354]: loss 0.041931
[epoch20, step1355]: loss 0.043990
[epoch20, step1356]: loss 0.041734
[epoch20, step1357]: loss 0.041709
[epoch20, step1358]: loss 0.041651
[epoch20, step1359]: loss 0.042486
[epoch20, step1360]: loss 0.042228
[epoch20, step1361]: loss 0.044073
[epoch20, step1362]: loss 0.042400
[epoch20, step1363]: loss 0.042614
[epoch20, step1364]: loss 0.043802
[epoch20, step1365]: loss 0.042137
[epoch20, step1366]: loss 0.041969
[epoch20, step1367]: loss 0.041246
[epoch20, step1368]: loss 0.043388
[epoch20, step1369]: loss 0.042409
[epoch20, step1370]: loss 0.043757
[epoch20, step1371]: loss 0.042021
[epoch20, step1372]: loss 0.042065
[epoch20, step1373]: loss 0.043768
[epoch20, step1374]: loss 0.042559
[epoch20, step1375]: loss 0.042671
[epoch20, step1376]: loss 0.041726
[epoch20, step1377]: loss 0.042152
[epoch20, step1378]: loss 0.042329
[epoch20, step1379]: loss 0.043568
[epoch20, step1380]: loss 0.041727
[epoch20, step1381]: loss 0.042075
[epoch20, step1382]: loss 0.044089
[epoch20, step1383]: loss 0.041482
[epoch20, step1384]: loss 0.041937
[epoch20, step1385]: loss 0.041192
[epoch20, step1386]: loss 0.042911
[epoch20, step1387]: loss 0.042489
[epoch20, step1388]: loss 0.043093
[epoch20, step1389]: loss 0.041109
[epoch20, step1390]: loss 0.042231
[epoch20, step1391]: loss 0.043728
[epoch20, step1392]: loss 0.042110
[epoch20, step1393]: loss 0.042208
[epoch20, step1394]: loss 0.042127
[epoch20, step1395]: loss 0.042861
[epoch20, step1396]: loss 0.041824
[epoch20, step1397]: loss 0.043607
[epoch20, step1398]: loss 0.041485
[epoch20, step1399]: loss 0.042845
[epoch20, step1400]: loss 0.044061
[epoch20, step1401]: loss 0.041589
[epoch20, step1402]: loss 0.042097
[epoch20, step1403]: loss 0.040897
[epoch20, step1404]: loss 0.042369
[epoch20, step1405]: loss 0.041907
[epoch20, step1406]: loss 0.043549
[epoch20, step1407]: loss 0.042665
[epoch20, step1408]: loss 0.041683
[epoch20, step1409]: loss 0.043519
[epoch20, step1410]: loss 0.041635
[epoch20, step1411]: loss 0.041335
[epoch20, step1412]: loss 0.041972
[epoch20, step1413]: loss 0.042920
[epoch20, step1414]: loss 0.041882
[epoch20, step1415]: loss 0.043514
[epoch20, step1416]: loss 0.041369
[epoch20, step1417]: loss 0.042223
[epoch20, step1418]: loss 0.043676
[epoch20, step1419]: loss 0.042597
[epoch20, step1420]: loss 0.042320
[epoch20, step1421]: loss 0.041937
[epoch20, step1422]: loss 0.042972
[epoch20, step1423]: loss 0.041807
[epoch20, step1424]: loss 0.043992
[epoch20, step1425]: loss 0.040873
[epoch20, step1426]: loss 0.042126
[epoch20, step1427]: loss 0.044368
[epoch20, step1428]: loss 0.042833
[epoch20, step1429]: loss 0.041995
[epoch20, step1430]: loss 0.041683
[epoch20, step1431]: loss 0.042650
[epoch20, step1432]: loss 0.041807
[epoch20, step1433]: loss 0.043900
[epoch20, step1434]: loss 0.041389
[epoch20, step1435]: loss 0.042356
[epoch20, step1436]: loss 0.044275
[epoch20, step1437]: loss 0.041849
[epoch20, step1438]: loss 0.042467
[epoch20, step1439]: loss 0.041724
[epoch20, step1440]: loss 0.042549
[epoch20, step1441]: loss 0.042667
[epoch20, step1442]: loss 0.043242
[epoch20, step1443]: loss 0.041660
[epoch20, step1444]: loss 0.041624
[epoch20, step1445]: loss 0.044099
[epoch20, step1446]: loss 0.041979
[epoch20, step1447]: loss 0.042558
[epoch20, step1448]: loss 0.041713
[epoch20, step1449]: loss 0.042360
[epoch20, step1450]: loss 0.042209
[epoch20, step1451]: loss 0.043943
[epoch20, step1452]: loss 0.041520
[epoch20, step1453]: loss 0.042881
[epoch20, step1454]: loss 0.044167
[epoch20, step1455]: loss 0.042415
[epoch20, step1456]: loss 0.041767
[epoch20, step1457]: loss 0.041965
[epoch20, step1458]: loss 0.042602
[epoch20, step1459]: loss 0.042035
[epoch20, step1460]: loss 0.044133
[epoch20, step1461]: loss 0.041848
[epoch20, step1462]: loss 0.042483
[epoch20, step1463]: loss 0.043796
[epoch20, step1464]: loss 0.041919
[epoch20, step1465]: loss 0.041755
[epoch20, step1466]: loss 0.041394
[epoch20, step1467]: loss 0.042442
[epoch20, step1468]: loss 0.041910
[epoch20, step1469]: loss 0.043713
[epoch20, step1470]: loss 0.041645
[epoch20, step1471]: loss 0.041928
[epoch20, step1472]: loss 0.043719
[epoch20, step1473]: loss 0.041657
[epoch20, step1474]: loss 0.042411
[epoch20, step1475]: loss 0.041356
[epoch20, step1476]: loss 0.043207
[epoch20, step1477]: loss 0.041924
[epoch20, step1478]: loss 0.043918
[epoch20, step1479]: loss 0.041352
[epoch20, step1480]: loss 0.042117
[epoch20, step1481]: loss 0.043091
[epoch20, step1482]: loss 0.041819
[epoch20, step1483]: loss 0.042154
[epoch20, step1484]: loss 0.041848
[epoch20, step1485]: loss 0.042749
[epoch20, step1486]: loss 0.041117
[epoch20, step1487]: loss 0.043546
[epoch20, step1488]: loss 0.041697
[epoch20, step1489]: loss 0.041837
[epoch20, step1490]: loss 0.043709
[epoch20, step1491]: loss 0.042068
[epoch20, step1492]: loss 0.041921
[epoch20, step1493]: loss 0.041710
[epoch20, step1494]: loss 0.042811
[epoch20, step1495]: loss 0.041793
[epoch20, step1496]: loss 0.043037
[epoch20, step1497]: loss 0.041863
[epoch20, step1498]: loss 0.042109
[epoch20, step1499]: loss 0.043447
[epoch20, step1500]: loss 0.041991
[epoch20, step1501]: loss 0.042038
[epoch20, step1502]: loss 0.041578
[epoch20, step1503]: loss 0.042612
[epoch20, step1504]: loss 0.041808
[epoch20, step1505]: loss 0.043973
[epoch20, step1506]: loss 0.041045
[epoch20, step1507]: loss 0.042404
[epoch20, step1508]: loss 0.044300
[epoch20, step1509]: loss 0.042033
[epoch20, step1510]: loss 0.041433
[epoch20, step1511]: loss 0.042068
[epoch20, step1512]: loss 0.042774
[epoch20, step1513]: loss 0.041050
[epoch20, step1514]: loss 0.043693
[epoch20, step1515]: loss 0.041974
[epoch20, step1516]: loss 0.041949

[epoch20]: avg loss 0.039849

